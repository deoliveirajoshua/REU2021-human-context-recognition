{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 8)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.5260549783706665, Final Batch Loss: 1.1038373708724976\n",
      "Epoch 2, Loss: 5.4631288051605225, Final Batch Loss: 1.0745130777359009\n",
      "Epoch 3, Loss: 5.442604660987854, Final Batch Loss: 1.0832622051239014\n",
      "Epoch 4, Loss: 5.413184881210327, Final Batch Loss: 1.0796797275543213\n",
      "Epoch 5, Loss: 5.3868032693862915, Final Batch Loss: 1.0899728536605835\n",
      "Epoch 6, Loss: 5.317664980888367, Final Batch Loss: 1.0594345331192017\n",
      "Epoch 7, Loss: 5.269097685813904, Final Batch Loss: 1.0565522909164429\n",
      "Epoch 8, Loss: 5.180958271026611, Final Batch Loss: 1.0290712118148804\n",
      "Epoch 9, Loss: 5.090502381324768, Final Batch Loss: 0.9982953071594238\n",
      "Epoch 10, Loss: 4.958275198936462, Final Batch Loss: 0.9490897059440613\n",
      "Epoch 11, Loss: 4.8705931305885315, Final Batch Loss: 0.957165539264679\n",
      "Epoch 12, Loss: 4.748427450656891, Final Batch Loss: 0.9625047445297241\n",
      "Epoch 13, Loss: 4.559790074825287, Final Batch Loss: 0.9115270376205444\n",
      "Epoch 14, Loss: 4.420786023139954, Final Batch Loss: 0.9261564612388611\n",
      "Epoch 15, Loss: 4.188306450843811, Final Batch Loss: 0.8481027483940125\n",
      "Epoch 16, Loss: 3.951836347579956, Final Batch Loss: 0.7835023999214172\n",
      "Epoch 17, Loss: 3.79960173368454, Final Batch Loss: 0.8034400343894958\n",
      "Epoch 18, Loss: 3.4934829473495483, Final Batch Loss: 0.6520354151725769\n",
      "Epoch 19, Loss: 3.352058708667755, Final Batch Loss: 0.6849365234375\n",
      "Epoch 20, Loss: 2.973117768764496, Final Batch Loss: 0.46242356300354004\n",
      "Epoch 21, Loss: 2.8703508377075195, Final Batch Loss: 0.522788941860199\n",
      "Epoch 22, Loss: 2.7741333842277527, Final Batch Loss: 0.580862820148468\n",
      "Epoch 23, Loss: 2.4195178151130676, Final Batch Loss: 0.3847185969352722\n",
      "Epoch 24, Loss: 2.393300414085388, Final Batch Loss: 0.4956154525279999\n",
      "Epoch 25, Loss: 2.172771394252777, Final Batch Loss: 0.4140552580356598\n",
      "Epoch 26, Loss: 2.1310168504714966, Final Batch Loss: 0.5116595029830933\n",
      "Epoch 27, Loss: 1.8366160094738007, Final Batch Loss: 0.2627509832382202\n",
      "Epoch 28, Loss: 1.7491559386253357, Final Batch Loss: 0.32394224405288696\n",
      "Epoch 29, Loss: 1.7069172859191895, Final Batch Loss: 0.2982679009437561\n",
      "Epoch 30, Loss: 1.3540603518486023, Final Batch Loss: 0.16900953650474548\n",
      "Epoch 31, Loss: 1.4302658885717392, Final Batch Loss: 0.24389149248600006\n",
      "Epoch 32, Loss: 1.2449656873941422, Final Batch Loss: 0.11295370757579803\n",
      "Epoch 33, Loss: 1.2167945355176926, Final Batch Loss: 0.13027192652225494\n",
      "Epoch 34, Loss: 1.0500084906816483, Final Batch Loss: 0.14713464677333832\n",
      "Epoch 35, Loss: 1.026913657784462, Final Batch Loss: 0.19349797070026398\n",
      "Epoch 36, Loss: 1.0406566262245178, Final Batch Loss: 0.2379026561975479\n",
      "Epoch 37, Loss: 1.0625051110982895, Final Batch Loss: 0.2990984320640564\n",
      "Epoch 38, Loss: 0.8240091390907764, Final Batch Loss: 0.06050010398030281\n",
      "Epoch 39, Loss: 0.9875695109367371, Final Batch Loss: 0.356393426656723\n",
      "Epoch 40, Loss: 0.691335704177618, Final Batch Loss: 0.04360615834593773\n",
      "Epoch 41, Loss: 0.9883303642272949, Final Batch Loss: 0.36711665987968445\n",
      "Epoch 42, Loss: 0.7285876199603081, Final Batch Loss: 0.10526622086763382\n",
      "Epoch 43, Loss: 0.6759329363703728, Final Batch Loss: 0.04853136092424393\n",
      "Epoch 44, Loss: 0.6024735262617469, Final Batch Loss: 0.015018551610410213\n",
      "Epoch 45, Loss: 0.5943620800971985, Final Batch Loss: 0.0717887282371521\n",
      "Epoch 46, Loss: 0.6872955113649368, Final Batch Loss: 0.12018293142318726\n",
      "Epoch 47, Loss: 0.5740485452115536, Final Batch Loss: 0.062130387872457504\n",
      "Epoch 48, Loss: 0.4580151457339525, Final Batch Loss: 0.018806802108883858\n",
      "Epoch 49, Loss: 0.5501930490136147, Final Batch Loss: 0.11709768325090408\n",
      "Epoch 50, Loss: 0.8437109664082527, Final Batch Loss: 0.34654468297958374\n",
      "Epoch 51, Loss: 0.5373745337128639, Final Batch Loss: 0.09526628255844116\n",
      "Epoch 52, Loss: 0.4377662129700184, Final Batch Loss: 0.022840876132249832\n",
      "Epoch 53, Loss: 0.4931429736316204, Final Batch Loss: 0.021936532109975815\n",
      "Epoch 54, Loss: 0.9319682493805885, Final Batch Loss: 0.5375852584838867\n",
      "Epoch 55, Loss: 0.47311145067214966, Final Batch Loss: 0.033164121210575104\n",
      "Epoch 56, Loss: 0.5575316995382309, Final Batch Loss: 0.08350033313035965\n",
      "Epoch 57, Loss: 0.6474490985274315, Final Batch Loss: 0.22052595019340515\n",
      "Epoch 58, Loss: 0.4543954208493233, Final Batch Loss: 0.08398499339818954\n",
      "Epoch 59, Loss: 0.4299507364630699, Final Batch Loss: 0.03240681439638138\n",
      "Epoch 60, Loss: 0.5445276498794556, Final Batch Loss: 0.09537018835544586\n",
      "Epoch 61, Loss: 0.40960703138262033, Final Batch Loss: 0.012062584049999714\n",
      "Epoch 62, Loss: 0.5470037534832954, Final Batch Loss: 0.20363669097423553\n",
      "Epoch 63, Loss: 0.5007185153663158, Final Batch Loss: 0.14476215839385986\n",
      "Epoch 64, Loss: 0.39497741870582104, Final Batch Loss: 0.02349659986793995\n",
      "Epoch 65, Loss: 0.453896377235651, Final Batch Loss: 0.07161439210176468\n",
      "Epoch 66, Loss: 0.4108276180922985, Final Batch Loss: 0.007884129881858826\n",
      "Epoch 67, Loss: 0.663013081997633, Final Batch Loss: 0.2968294024467468\n",
      "Epoch 68, Loss: 0.4131193272769451, Final Batch Loss: 0.060676731169223785\n",
      "Epoch 69, Loss: 0.38511576503515244, Final Batch Loss: 0.09894274920225143\n",
      "Epoch 70, Loss: 0.40107611566782, Final Batch Loss: 0.06498417258262634\n",
      "Epoch 71, Loss: 0.4127830043435097, Final Batch Loss: 0.08519218862056732\n",
      "Epoch 72, Loss: 0.3934897370636463, Final Batch Loss: 0.041332971304655075\n",
      "Epoch 73, Loss: 0.3386115003377199, Final Batch Loss: 0.015527518466114998\n",
      "Epoch 74, Loss: 0.3930113259702921, Final Batch Loss: 0.02281193621456623\n",
      "Epoch 75, Loss: 0.6398801282048225, Final Batch Loss: 0.3040944039821625\n",
      "Epoch 76, Loss: 0.3537189308553934, Final Batch Loss: 0.02580765075981617\n",
      "Epoch 77, Loss: 0.3922379668802023, Final Batch Loss: 0.026282181963324547\n",
      "Epoch 78, Loss: 0.771907664835453, Final Batch Loss: 0.39609667658805847\n",
      "Epoch 79, Loss: 0.3245711140334606, Final Batch Loss: 0.01935291662812233\n",
      "Epoch 80, Loss: 0.369478989392519, Final Batch Loss: 0.061756815761327744\n",
      "Epoch 81, Loss: 0.3379163518548012, Final Batch Loss: 0.062384992837905884\n",
      "Epoch 82, Loss: 0.4139261543750763, Final Batch Loss: 0.09469397366046906\n",
      "Epoch 83, Loss: 0.3499983176589012, Final Batch Loss: 0.013976015150547028\n",
      "Epoch 84, Loss: 0.35097974399104714, Final Batch Loss: 0.0057749361731112\n",
      "Epoch 85, Loss: 0.6144872307777405, Final Batch Loss: 0.30959203839302063\n",
      "Epoch 86, Loss: 0.4205416478216648, Final Batch Loss: 0.13242129981517792\n",
      "Epoch 87, Loss: 0.33767249435186386, Final Batch Loss: 0.06073171645402908\n",
      "Epoch 88, Loss: 0.2599532688036561, Final Batch Loss: 0.013276421464979649\n",
      "Epoch 89, Loss: 0.28374709747731686, Final Batch Loss: 0.017027871683239937\n",
      "Epoch 90, Loss: 0.2709866911172867, Final Batch Loss: 0.006176948547363281\n",
      "Epoch 91, Loss: 0.264402536675334, Final Batch Loss: 0.01573946140706539\n",
      "Epoch 92, Loss: 0.31148722395300865, Final Batch Loss: 0.0370824858546257\n",
      "Epoch 93, Loss: 0.25551721826195717, Final Batch Loss: 0.018906861543655396\n",
      "Epoch 94, Loss: 0.2978183925151825, Final Batch Loss: 0.02422233298420906\n",
      "Epoch 95, Loss: 0.420609425753355, Final Batch Loss: 0.13945132493972778\n",
      "Epoch 96, Loss: 0.23532643169164658, Final Batch Loss: 0.027587099000811577\n",
      "Epoch 97, Loss: 0.29103352688252926, Final Batch Loss: 0.016969745978713036\n",
      "Epoch 98, Loss: 0.35120221972465515, Final Batch Loss: 0.07874741405248642\n",
      "Epoch 99, Loss: 0.2893907893449068, Final Batch Loss: 0.01711728610098362\n",
      "Epoch 100, Loss: 0.25118663208559155, Final Batch Loss: 0.006742399651557207\n",
      "Epoch 101, Loss: 0.3143950328230858, Final Batch Loss: 0.04608101397752762\n",
      "Epoch 102, Loss: 0.23649767134338617, Final Batch Loss: 0.014911643229424953\n",
      "Epoch 103, Loss: 0.2792510353028774, Final Batch Loss: 0.02903808280825615\n",
      "Epoch 104, Loss: 0.20389215648174286, Final Batch Loss: 0.010308541357517242\n",
      "Epoch 105, Loss: 0.2341499775648117, Final Batch Loss: 0.0388183668255806\n",
      "Epoch 106, Loss: 0.18925093859434128, Final Batch Loss: 0.0086748655885458\n",
      "Epoch 107, Loss: 0.2919998876750469, Final Batch Loss: 0.04168141260743141\n",
      "Epoch 108, Loss: 0.2600501384586096, Final Batch Loss: 0.016406452283263206\n",
      "Epoch 109, Loss: 0.28451296500861645, Final Batch Loss: 0.02846585400402546\n",
      "Epoch 110, Loss: 0.3597802296280861, Final Batch Loss: 0.14050395786762238\n",
      "Epoch 111, Loss: 0.39286790043115616, Final Batch Loss: 0.17575640976428986\n",
      "Epoch 112, Loss: 0.33164736069738865, Final Batch Loss: 0.024594860151410103\n",
      "Epoch 113, Loss: 0.5894766971468925, Final Batch Loss: 0.23336060345172882\n",
      "Epoch 114, Loss: 0.2975368555635214, Final Batch Loss: 0.017081303521990776\n",
      "Epoch 115, Loss: 0.2450231333496049, Final Batch Loss: 0.0015550461830571294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Loss: 0.20851951371878386, Final Batch Loss: 0.008350147865712643\n",
      "Epoch 117, Loss: 0.24846151936799288, Final Batch Loss: 0.013700718991458416\n",
      "Epoch 118, Loss: 0.28115879371762276, Final Batch Loss: 0.08708126842975616\n",
      "Epoch 119, Loss: 0.2060434091836214, Final Batch Loss: 0.0309994388371706\n",
      "Epoch 120, Loss: 0.2172501478344202, Final Batch Loss: 0.008839046582579613\n",
      "Epoch 121, Loss: 0.30754023790359497, Final Batch Loss: 0.13305208086967468\n",
      "Epoch 122, Loss: 0.42826151847839355, Final Batch Loss: 0.21310582756996155\n",
      "Epoch 123, Loss: 0.7400017473846674, Final Batch Loss: 0.537044107913971\n",
      "Epoch 124, Loss: 0.17993657756596804, Final Batch Loss: 0.005505654029548168\n",
      "Epoch 125, Loss: 0.2949969843029976, Final Batch Loss: 0.04837304353713989\n",
      "Epoch 126, Loss: 0.2725783474743366, Final Batch Loss: 0.04187483713030815\n",
      "Epoch 127, Loss: 0.5831818655133247, Final Batch Loss: 0.3539762496948242\n",
      "Epoch 128, Loss: 0.23075782880187035, Final Batch Loss: 0.03239636868238449\n",
      "Epoch 129, Loss: 0.24906124453991652, Final Batch Loss: 0.012079362757503986\n",
      "Epoch 130, Loss: 0.2207062728703022, Final Batch Loss: 0.03161865100264549\n",
      "Epoch 131, Loss: 0.30801741406321526, Final Batch Loss: 0.12033148109912872\n",
      "Epoch 132, Loss: 0.5378903280943632, Final Batch Loss: 0.3634282946586609\n",
      "Epoch 133, Loss: 0.2761136908084154, Final Batch Loss: 0.09711521863937378\n",
      "Epoch 134, Loss: 0.21556015126407146, Final Batch Loss: 0.00950462557375431\n",
      "Epoch 135, Loss: 0.2051112800836563, Final Batch Loss: 0.026612022891640663\n",
      "Epoch 136, Loss: 0.21082096081227064, Final Batch Loss: 0.01218442339450121\n",
      "Epoch 137, Loss: 0.19177968287840486, Final Batch Loss: 0.005554141942411661\n",
      "Epoch 138, Loss: 0.18957127816975117, Final Batch Loss: 0.012383973225951195\n",
      "Epoch 139, Loss: 0.17915257927961648, Final Batch Loss: 0.003324860008433461\n",
      "Epoch 140, Loss: 0.1973581500351429, Final Batch Loss: 0.01254606805741787\n",
      "Epoch 141, Loss: 0.2125364365056157, Final Batch Loss: 0.013106041587889194\n",
      "Epoch 142, Loss: 0.212368406355381, Final Batch Loss: 0.008468357846140862\n",
      "Epoch 143, Loss: 0.43864816799759865, Final Batch Loss: 0.2392066866159439\n",
      "Epoch 144, Loss: 0.23249777546152472, Final Batch Loss: 0.006097038742154837\n",
      "Epoch 145, Loss: 0.4974097218364477, Final Batch Loss: 0.2994350790977478\n",
      "Epoch 146, Loss: 0.24115031585097313, Final Batch Loss: 0.0481845960021019\n",
      "Epoch 147, Loss: 0.1995194461196661, Final Batch Loss: 0.008572328835725784\n",
      "Epoch 148, Loss: 0.24945477209985256, Final Batch Loss: 0.08080494403839111\n",
      "Epoch 149, Loss: 0.2145439377054572, Final Batch Loss: 0.011962114833295345\n",
      "Epoch 150, Loss: 0.20160252042114735, Final Batch Loss: 0.023521607741713524\n",
      "Epoch 151, Loss: 0.26460709422826767, Final Batch Loss: 0.03335016593337059\n",
      "Epoch 152, Loss: 0.37758439406752586, Final Batch Loss: 0.20120923221111298\n",
      "Epoch 153, Loss: 0.2049142448231578, Final Batch Loss: 0.011026292107999325\n",
      "Epoch 154, Loss: 0.3530406393110752, Final Batch Loss: 0.14559124410152435\n",
      "Epoch 155, Loss: 0.207881361246109, Final Batch Loss: 0.008305354043841362\n",
      "Epoch 156, Loss: 0.3786432445049286, Final Batch Loss: 0.16438885033130646\n",
      "Epoch 157, Loss: 0.2227802025154233, Final Batch Loss: 0.009141632355749607\n",
      "Epoch 158, Loss: 0.4870309438556433, Final Batch Loss: 0.33901447057724\n",
      "Epoch 159, Loss: 0.21326747070997953, Final Batch Loss: 0.011867920868098736\n",
      "Epoch 160, Loss: 0.24167440086603165, Final Batch Loss: 0.06787915527820587\n",
      "Epoch 161, Loss: 0.21516700647771358, Final Batch Loss: 0.022610889747738838\n",
      "Epoch 162, Loss: 0.20975379925221205, Final Batch Loss: 0.027396980673074722\n",
      "Epoch 163, Loss: 0.18673979118466377, Final Batch Loss: 0.035732388496398926\n",
      "Epoch 164, Loss: 0.15152623842004687, Final Batch Loss: 0.0017942056292667985\n",
      "Epoch 165, Loss: 0.14895331673324108, Final Batch Loss: 0.0032210592180490494\n",
      "Epoch 166, Loss: 0.13520924956537783, Final Batch Loss: 0.0027852302882820368\n",
      "Epoch 167, Loss: 0.21542679518461227, Final Batch Loss: 0.01507699303328991\n",
      "Epoch 168, Loss: 0.178533345926553, Final Batch Loss: 0.0032421336509287357\n",
      "Epoch 169, Loss: 0.1562525457702577, Final Batch Loss: 0.005790153052657843\n",
      "Epoch 170, Loss: 0.17078667227178812, Final Batch Loss: 0.009624545462429523\n",
      "Epoch 171, Loss: 0.16762319020926952, Final Batch Loss: 0.03029942512512207\n",
      "Epoch 172, Loss: 0.18431804794818163, Final Batch Loss: 0.00937167089432478\n",
      "Epoch 173, Loss: 0.17024050489999354, Final Batch Loss: 0.0012149868998676538\n",
      "Epoch 174, Loss: 0.352503914386034, Final Batch Loss: 0.18200251460075378\n",
      "Epoch 175, Loss: 0.1765419151633978, Final Batch Loss: 0.016255464404821396\n",
      "Epoch 176, Loss: 0.15518007287755609, Final Batch Loss: 0.00752342538908124\n",
      "Epoch 177, Loss: 0.16143992077559233, Final Batch Loss: 0.007899039424955845\n",
      "Epoch 178, Loss: 0.244405179284513, Final Batch Loss: 0.010054676793515682\n",
      "Epoch 179, Loss: 0.1797645348124206, Final Batch Loss: 0.007134351413697004\n",
      "Epoch 180, Loss: 0.18935234192758799, Final Batch Loss: 0.012402175925672054\n",
      "Epoch 181, Loss: 0.19882066175341606, Final Batch Loss: 0.03555714339017868\n",
      "Epoch 182, Loss: 0.16452148370444775, Final Batch Loss: 0.004990801215171814\n",
      "Epoch 183, Loss: 0.17302386392839253, Final Batch Loss: 0.0033363003749400377\n",
      "Epoch 184, Loss: 0.15399827435612679, Final Batch Loss: 0.01836833730340004\n",
      "Epoch 185, Loss: 0.14732296287547797, Final Batch Loss: 0.001511349226348102\n",
      "Epoch 186, Loss: 0.1681934306398034, Final Batch Loss: 0.01266991626471281\n",
      "Epoch 187, Loss: 0.11771850264631212, Final Batch Loss: 0.0013839842285960913\n",
      "Epoch 188, Loss: 0.19398074876517057, Final Batch Loss: 0.012243802659213543\n",
      "Epoch 189, Loss: 0.15174603182822466, Final Batch Loss: 0.008550303988158703\n",
      "Epoch 190, Loss: 0.18120537139475346, Final Batch Loss: 0.053796205669641495\n",
      "Epoch 191, Loss: 0.1647686855867505, Final Batch Loss: 0.012770897708833218\n",
      "Epoch 192, Loss: 0.190276785986498, Final Batch Loss: 0.0038809955585747957\n",
      "Epoch 193, Loss: 0.19373027049005032, Final Batch Loss: 0.03821508213877678\n",
      "Epoch 194, Loss: 0.17661267146468163, Final Batch Loss: 0.025937097147107124\n",
      "Epoch 195, Loss: 0.15762941911816597, Final Batch Loss: 0.011679798364639282\n",
      "Epoch 196, Loss: 0.16563583491370082, Final Batch Loss: 0.002718301024287939\n",
      "Epoch 197, Loss: 0.16679965727962554, Final Batch Loss: 0.003096852684393525\n",
      "Epoch 198, Loss: 0.12911311257630587, Final Batch Loss: 0.005983362905681133\n",
      "Epoch 199, Loss: 0.1517864391207695, Final Batch Loss: 0.017394796013832092\n",
      "Epoch 200, Loss: 0.16762398416176438, Final Batch Loss: 0.00500446604564786\n",
      "Epoch 201, Loss: 0.13619869016110897, Final Batch Loss: 0.005588509142398834\n",
      "Epoch 202, Loss: 0.19381612353026867, Final Batch Loss: 0.07164646685123444\n",
      "Epoch 203, Loss: 0.1602665209211409, Final Batch Loss: 0.0062062242068350315\n",
      "Epoch 204, Loss: 0.14423245750367641, Final Batch Loss: 0.01253914088010788\n",
      "Epoch 205, Loss: 0.161317691905424, Final Batch Loss: 0.0014319939073175192\n",
      "Epoch 206, Loss: 0.17451465036720037, Final Batch Loss: 0.004371895454823971\n",
      "Epoch 207, Loss: 0.1570175401866436, Final Batch Loss: 0.02776758186519146\n",
      "Epoch 208, Loss: 0.11531974968966097, Final Batch Loss: 0.0012658959021791816\n",
      "Epoch 209, Loss: 0.153120132163167, Final Batch Loss: 0.020875459536910057\n",
      "Epoch 210, Loss: 0.13319705286994576, Final Batch Loss: 0.0035551604814827442\n",
      "Epoch 211, Loss: 0.13288625748828053, Final Batch Loss: 0.004024373833090067\n",
      "Epoch 212, Loss: 0.11998117878101766, Final Batch Loss: 0.002162148943170905\n",
      "Epoch 213, Loss: 0.13361553475260735, Final Batch Loss: 0.0170008335262537\n",
      "Epoch 214, Loss: 0.13766527362167835, Final Batch Loss: 0.0020864997059106827\n",
      "Epoch 215, Loss: 0.1464326260611415, Final Batch Loss: 0.010637558065354824\n",
      "Epoch 216, Loss: 0.11933971522375941, Final Batch Loss: 0.0010512187145650387\n",
      "Epoch 217, Loss: 0.10580787598155439, Final Batch Loss: 0.002113776048645377\n",
      "Epoch 218, Loss: 0.15680311154574156, Final Batch Loss: 0.011404581367969513\n",
      "Epoch 219, Loss: 0.1557672843337059, Final Batch Loss: 0.014846966601908207\n",
      "Epoch 220, Loss: 0.14735004026442766, Final Batch Loss: 0.016145270317792892\n",
      "Epoch 221, Loss: 0.13544851541519165, Final Batch Loss: 0.005961772985756397\n",
      "Epoch 222, Loss: 0.17884764820337296, Final Batch Loss: 0.02288244478404522\n",
      "Epoch 223, Loss: 0.13206172036007047, Final Batch Loss: 0.0025428165681660175\n",
      "Epoch 224, Loss: 0.1615726463496685, Final Batch Loss: 0.043151143938302994\n",
      "Epoch 225, Loss: 0.15501983743160963, Final Batch Loss: 0.0093385623767972\n",
      "Epoch 226, Loss: 0.19814208336174488, Final Batch Loss: 0.026860523968935013\n",
      "Epoch 227, Loss: 0.12382241571322083, Final Batch Loss: 0.002420476172119379\n",
      "Epoch 228, Loss: 0.16617046017199755, Final Batch Loss: 0.03333776444196701\n",
      "Epoch 229, Loss: 0.1337579470127821, Final Batch Loss: 0.019580909982323647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230, Loss: 0.14665338164195418, Final Batch Loss: 0.0036105229519307613\n",
      "Epoch 231, Loss: 0.13763092644512653, Final Batch Loss: 0.003159893676638603\n",
      "Epoch 232, Loss: 0.1745385369285941, Final Batch Loss: 0.013011838309466839\n",
      "Epoch 233, Loss: 0.1386047305422835, Final Batch Loss: 0.0007981007802300155\n",
      "Epoch 234, Loss: 0.1439234963618219, Final Batch Loss: 0.002522596623748541\n",
      "Epoch 235, Loss: 0.11398785869823769, Final Batch Loss: 0.0008531634812243283\n",
      "Epoch 236, Loss: 0.13359392900019884, Final Batch Loss: 0.003857007250189781\n",
      "Epoch 237, Loss: 0.12471418653149158, Final Batch Loss: 0.0012262683594599366\n",
      "Epoch 238, Loss: 0.1334346178919077, Final Batch Loss: 0.011224491521716118\n",
      "Epoch 239, Loss: 0.12637184537015855, Final Batch Loss: 0.0033129050862044096\n",
      "Epoch 240, Loss: 0.13390625175088644, Final Batch Loss: 0.009476668201386929\n",
      "Epoch 241, Loss: 0.1019704407081008, Final Batch Loss: 0.0015524337068200111\n",
      "Epoch 242, Loss: 0.13746387045830488, Final Batch Loss: 0.0059926072135567665\n",
      "Epoch 243, Loss: 0.13447009213268757, Final Batch Loss: 0.018898192793130875\n",
      "Epoch 244, Loss: 0.13634431222453713, Final Batch Loss: 0.00425605708733201\n",
      "Epoch 245, Loss: 0.12984277866780758, Final Batch Loss: 0.0010282527655363083\n",
      "Epoch 246, Loss: 0.14946030732244253, Final Batch Loss: 0.004510813392698765\n",
      "Epoch 247, Loss: 0.11378833744674921, Final Batch Loss: 0.00982211995869875\n",
      "Epoch 248, Loss: 0.10379731631837785, Final Batch Loss: 0.002428575186058879\n",
      "Epoch 249, Loss: 0.12502603884786367, Final Batch Loss: 0.011519593186676502\n",
      "Epoch 250, Loss: 0.1294890628196299, Final Batch Loss: 0.004328838083893061\n",
      "Epoch 251, Loss: 0.18973511457443237, Final Batch Loss: 0.055161379277706146\n",
      "Epoch 252, Loss: 0.11073239636607468, Final Batch Loss: 0.0010167977306991816\n",
      "Epoch 253, Loss: 0.16467228718101978, Final Batch Loss: 0.00413617305457592\n",
      "Epoch 254, Loss: 0.3732954226434231, Final Batch Loss: 0.23525948822498322\n",
      "Epoch 255, Loss: 0.12629881501197815, Final Batch Loss: 0.025252392515540123\n",
      "Epoch 256, Loss: 0.16457592486403883, Final Batch Loss: 0.0024732386227697134\n",
      "Epoch 257, Loss: 0.13337897090241313, Final Batch Loss: 0.007325792219489813\n",
      "Epoch 258, Loss: 0.15583982458338141, Final Batch Loss: 0.006441228557378054\n",
      "Epoch 259, Loss: 0.09836371568962932, Final Batch Loss: 0.002659053076058626\n",
      "Epoch 260, Loss: 0.15542842168360949, Final Batch Loss: 0.044880449771881104\n",
      "Epoch 261, Loss: 0.1278710956685245, Final Batch Loss: 0.005007758270949125\n",
      "Epoch 262, Loss: 0.24614050053060055, Final Batch Loss: 0.11366324126720428\n",
      "Epoch 263, Loss: 0.09799354220740497, Final Batch Loss: 0.0014068789314478636\n",
      "Epoch 264, Loss: 0.11626682849600911, Final Batch Loss: 0.003524975385516882\n",
      "Epoch 265, Loss: 0.13335110107436776, Final Batch Loss: 0.002824824769049883\n",
      "Epoch 266, Loss: 0.1612607748247683, Final Batch Loss: 0.0026834201999008656\n",
      "Epoch 267, Loss: 0.11249403224792331, Final Batch Loss: 0.0013649588217958808\n",
      "Epoch 268, Loss: 0.12670860579237342, Final Batch Loss: 0.004473941866308451\n",
      "Epoch 269, Loss: 0.07312002463731915, Final Batch Loss: 0.001853325986303389\n",
      "Epoch 270, Loss: 0.11988621903583407, Final Batch Loss: 0.022973330691456795\n",
      "Epoch 271, Loss: 0.13529494032263756, Final Batch Loss: 0.028089534491300583\n",
      "Epoch 272, Loss: 0.12294618529267609, Final Batch Loss: 0.0012264226097613573\n",
      "Epoch 273, Loss: 0.14966490562073886, Final Batch Loss: 0.0022490236442536116\n",
      "Epoch 274, Loss: 0.08772133477032185, Final Batch Loss: 0.0044026621617376804\n",
      "Epoch 275, Loss: 0.11415397562086582, Final Batch Loss: 0.0021695736795663834\n",
      "Epoch 276, Loss: 0.14018334029242396, Final Batch Loss: 0.004220010247081518\n",
      "Epoch 277, Loss: 0.11719977762550116, Final Batch Loss: 0.00848111230880022\n",
      "Epoch 278, Loss: 0.12425950355827808, Final Batch Loss: 0.014619837515056133\n",
      "Epoch 279, Loss: 0.11542632523924112, Final Batch Loss: 0.011727065779268742\n",
      "Epoch 280, Loss: 0.13797150319442153, Final Batch Loss: 0.005978376138955355\n",
      "Epoch 281, Loss: 0.10155326189124025, Final Batch Loss: 0.0002744180674199015\n",
      "Epoch 282, Loss: 0.13253321638330817, Final Batch Loss: 0.007025034632533789\n",
      "Epoch 283, Loss: 0.10376324830576777, Final Batch Loss: 0.004986960906535387\n",
      "Epoch 284, Loss: 0.12033952446654439, Final Batch Loss: 0.004362403880804777\n",
      "Epoch 285, Loss: 0.09455765504390001, Final Batch Loss: 0.0030189878307282925\n",
      "Epoch 286, Loss: 0.10351300542242825, Final Batch Loss: 0.001120476284995675\n",
      "Epoch 287, Loss: 0.09344841411802918, Final Batch Loss: 0.000990971107967198\n",
      "Epoch 288, Loss: 0.12739583430811763, Final Batch Loss: 0.004726511891931295\n",
      "Epoch 289, Loss: 0.13153621926903725, Final Batch Loss: 0.006707344204187393\n",
      "Epoch 290, Loss: 0.08455830253660679, Final Batch Loss: 0.0050468891859054565\n",
      "Epoch 291, Loss: 0.12076883786357939, Final Batch Loss: 0.0032582965213805437\n",
      "Epoch 292, Loss: 0.09714688558597118, Final Batch Loss: 0.0012299941154196858\n",
      "Epoch 293, Loss: 0.10006318800151348, Final Batch Loss: 0.01204865612089634\n",
      "Epoch 294, Loss: 0.10122743062674999, Final Batch Loss: 0.009624132886528969\n",
      "Epoch 295, Loss: 0.13042933214455843, Final Batch Loss: 0.01108705997467041\n",
      "Epoch 296, Loss: 0.1286032209172845, Final Batch Loss: 0.00973846297711134\n",
      "Epoch 297, Loss: 0.18372720666229725, Final Batch Loss: 0.0732070580124855\n",
      "Epoch 298, Loss: 0.12914174143224955, Final Batch Loss: 0.017544984817504883\n",
      "Epoch 299, Loss: 0.11270749662071466, Final Batch Loss: 0.011027075350284576\n",
      "Epoch 300, Loss: 0.13723161816596985, Final Batch Loss: 0.017514577135443687\n",
      "Epoch 301, Loss: 0.0929298554547131, Final Batch Loss: 0.018889963626861572\n",
      "Epoch 302, Loss: 0.10474086250178516, Final Batch Loss: 0.002420680830255151\n",
      "Epoch 303, Loss: 0.12734469026327133, Final Batch Loss: 0.003926929086446762\n",
      "Epoch 304, Loss: 0.09664555988274515, Final Batch Loss: 0.0022238988894969225\n",
      "Epoch 305, Loss: 0.13545989524573088, Final Batch Loss: 0.00583280622959137\n",
      "Epoch 306, Loss: 0.07356178935151547, Final Batch Loss: 0.0013894991716369987\n",
      "Epoch 307, Loss: 0.09731821296736598, Final Batch Loss: 0.002593612764030695\n",
      "Epoch 308, Loss: 0.11190219083800912, Final Batch Loss: 0.004454370122402906\n",
      "Epoch 309, Loss: 0.09653246600646526, Final Batch Loss: 0.0008944716537371278\n",
      "Epoch 310, Loss: 0.08864146191626787, Final Batch Loss: 0.004865736234933138\n",
      "Epoch 311, Loss: 0.08372042700648308, Final Batch Loss: 0.0024942257441580296\n",
      "Epoch 312, Loss: 0.10262070270255208, Final Batch Loss: 0.0033567394129931927\n",
      "Epoch 313, Loss: 0.08953646407462656, Final Batch Loss: 0.0018089099321514368\n",
      "Epoch 314, Loss: 0.1038939617574215, Final Batch Loss: 0.003204530104994774\n",
      "Epoch 315, Loss: 0.11691140523180366, Final Batch Loss: 0.0071477689780294895\n",
      "Epoch 316, Loss: 0.3427597866393626, Final Batch Loss: 0.2739047408103943\n",
      "Epoch 317, Loss: 0.27274380810558796, Final Batch Loss: 0.17440912127494812\n",
      "Epoch 318, Loss: 0.1098647911567241, Final Batch Loss: 0.0011125749442726374\n",
      "Epoch 319, Loss: 0.26850130409002304, Final Batch Loss: 0.08943444490432739\n",
      "Epoch 320, Loss: 0.09909350523957983, Final Batch Loss: 0.0005324138910509646\n",
      "Epoch 321, Loss: 0.14078703615814447, Final Batch Loss: 0.005246561951935291\n",
      "Epoch 322, Loss: 0.12225040001794696, Final Batch Loss: 0.004701205994933844\n",
      "Epoch 323, Loss: 0.10227038990706205, Final Batch Loss: 0.014580353163182735\n",
      "Epoch 324, Loss: 0.08859911665786058, Final Batch Loss: 0.0009861496509984136\n",
      "Epoch 325, Loss: 0.09806308592669666, Final Batch Loss: 0.0029016321059316397\n",
      "Epoch 326, Loss: 0.14460766641423106, Final Batch Loss: 0.04508427903056145\n",
      "Epoch 327, Loss: 0.12450524582527578, Final Batch Loss: 0.003438435262069106\n",
      "Epoch 328, Loss: 0.09537532646209002, Final Batch Loss: 0.008074759505689144\n",
      "Epoch 329, Loss: 0.09911994310095906, Final Batch Loss: 0.005633108783513308\n",
      "Epoch 330, Loss: 0.09272370580583811, Final Batch Loss: 0.013630187138915062\n",
      "Epoch 331, Loss: 0.12401310447603464, Final Batch Loss: 0.011033800430595875\n",
      "Epoch 332, Loss: 0.09735794109292328, Final Batch Loss: 0.0016735049430280924\n",
      "Epoch 333, Loss: 0.09702609991654754, Final Batch Loss: 0.002816466148942709\n",
      "Epoch 334, Loss: 0.09136508451774716, Final Batch Loss: 0.0022275117225944996\n",
      "Epoch 335, Loss: 0.08013039641082287, Final Batch Loss: 0.0026536881923675537\n",
      "Epoch 336, Loss: 0.07241638933192007, Final Batch Loss: 0.000331112154526636\n",
      "Epoch 337, Loss: 0.07561991366674192, Final Batch Loss: 0.00029302670736797154\n",
      "Epoch 338, Loss: 0.10381587804295123, Final Batch Loss: 0.002152060391381383\n",
      "Epoch 339, Loss: 0.3727785302326083, Final Batch Loss: 0.2689695656299591\n",
      "Epoch 340, Loss: 0.08941759774461389, Final Batch Loss: 0.01894032396376133\n",
      "Epoch 341, Loss: 0.17079434171319008, Final Batch Loss: 0.0046190060675144196\n",
      "Epoch 342, Loss: 0.13287973986007273, Final Batch Loss: 0.0023111721966415644\n",
      "Epoch 343, Loss: 0.08520122221671045, Final Batch Loss: 0.0022846225183457136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344, Loss: 0.08419952588155866, Final Batch Loss: 0.005696043837815523\n",
      "Epoch 345, Loss: 0.08502784604206681, Final Batch Loss: 0.005151368677616119\n",
      "Epoch 346, Loss: 0.08499720378313214, Final Batch Loss: 0.0011853507021442056\n",
      "Epoch 347, Loss: 0.09162591048516333, Final Batch Loss: 0.0027148958761245012\n",
      "Epoch 348, Loss: 0.08886078977957368, Final Batch Loss: 0.006710080895572901\n",
      "Epoch 349, Loss: 0.10379112511873245, Final Batch Loss: 0.020103832706809044\n",
      "Epoch 350, Loss: 0.06163381738588214, Final Batch Loss: 0.006490828935056925\n",
      "Epoch 351, Loss: 0.12541488325223327, Final Batch Loss: 0.006869447883218527\n",
      "Epoch 352, Loss: 0.12425034120678902, Final Batch Loss: 0.022944988682866096\n",
      "Epoch 353, Loss: 0.08497147727757692, Final Batch Loss: 0.013967441394925117\n",
      "Epoch 354, Loss: 0.12968688318505883, Final Batch Loss: 0.047389090061187744\n",
      "Epoch 355, Loss: 0.08520161383785307, Final Batch Loss: 0.002665154868736863\n",
      "Epoch 356, Loss: 0.06568575359415263, Final Batch Loss: 0.0014279017923399806\n",
      "Epoch 357, Loss: 0.07141246841638349, Final Batch Loss: 0.000284016685327515\n",
      "Epoch 358, Loss: 0.05889442563056946, Final Batch Loss: 0.0007522031664848328\n",
      "Epoch 359, Loss: 0.06600773186073638, Final Batch Loss: 0.0003999452164862305\n",
      "Epoch 360, Loss: 0.06610670685768127, Final Batch Loss: 0.011903365142643452\n",
      "Epoch 361, Loss: 0.055873178876936436, Final Batch Loss: 0.002000290434807539\n",
      "Epoch 362, Loss: 0.10846305498853326, Final Batch Loss: 0.01062035746872425\n",
      "Epoch 363, Loss: 0.0694817726034671, Final Batch Loss: 0.0029183446895331144\n",
      "Epoch 364, Loss: 0.0774537029210478, Final Batch Loss: 0.0013246063608676195\n",
      "Epoch 365, Loss: 0.09894558601081371, Final Batch Loss: 0.00555795431137085\n",
      "Epoch 366, Loss: 0.09672457817941904, Final Batch Loss: 0.038099970668554306\n",
      "Epoch 367, Loss: 0.05666446825489402, Final Batch Loss: 0.0028108241967856884\n",
      "Epoch 368, Loss: 0.0818608591798693, Final Batch Loss: 0.004950694274157286\n",
      "Epoch 369, Loss: 0.08851616457104683, Final Batch Loss: 0.007123132236301899\n",
      "Epoch 370, Loss: 0.13726935675367713, Final Batch Loss: 0.05234822258353233\n",
      "Epoch 371, Loss: 0.11861542612314224, Final Batch Loss: 0.005496285855770111\n",
      "Epoch 372, Loss: 0.09940873272716999, Final Batch Loss: 0.0042034657672047615\n",
      "Epoch 373, Loss: 0.09042444732040167, Final Batch Loss: 0.01262354850769043\n",
      "Epoch 374, Loss: 0.06783067714422941, Final Batch Loss: 0.002134452573955059\n",
      "Epoch 375, Loss: 0.0700996327213943, Final Batch Loss: 0.0022722245194017887\n",
      "Epoch 376, Loss: 0.09851409727707505, Final Batch Loss: 0.005944591481238604\n",
      "Epoch 377, Loss: 0.1090586957288906, Final Batch Loss: 0.0016443644417449832\n",
      "Epoch 378, Loss: 0.06404985603876412, Final Batch Loss: 0.0003954244311898947\n",
      "Epoch 379, Loss: 0.06602230481803417, Final Batch Loss: 0.01040027104318142\n",
      "Epoch 380, Loss: 0.04870504362042993, Final Batch Loss: 0.0010065872920677066\n",
      "Epoch 381, Loss: 0.061485917307436466, Final Batch Loss: 0.007618182338774204\n",
      "Epoch 382, Loss: 0.08226564631331712, Final Batch Loss: 0.0011976455571129918\n",
      "Epoch 383, Loss: 0.06497411988675594, Final Batch Loss: 0.010592327453196049\n",
      "Epoch 384, Loss: 0.06462312376243062, Final Batch Loss: 0.00036064235609956086\n",
      "Epoch 385, Loss: 0.13281332235783339, Final Batch Loss: 0.0866498127579689\n",
      "Epoch 386, Loss: 0.06775380158796906, Final Batch Loss: 0.009368126280605793\n",
      "Epoch 387, Loss: 0.0584468408342218, Final Batch Loss: 9.272106399293989e-05\n",
      "Epoch 388, Loss: 0.11509759403998032, Final Batch Loss: 0.00039260234916582704\n",
      "Epoch 389, Loss: 0.09973148046992719, Final Batch Loss: 0.003464482491835952\n",
      "Epoch 390, Loss: 0.04735477175563574, Final Batch Loss: 0.003238507080823183\n",
      "Epoch 391, Loss: 0.12304117390885949, Final Batch Loss: 0.07696240395307541\n",
      "Epoch 392, Loss: 0.07217122660949826, Final Batch Loss: 0.002495488617569208\n",
      "Epoch 393, Loss: 0.07966597285121679, Final Batch Loss: 0.011078673414885998\n",
      "Epoch 394, Loss: 0.08620146926841699, Final Batch Loss: 0.0003304629062768072\n",
      "Epoch 395, Loss: 0.28085493575781584, Final Batch Loss: 0.21852029860019684\n",
      "Epoch 396, Loss: 0.06801212206482887, Final Batch Loss: 0.004688330926001072\n",
      "Epoch 397, Loss: 0.07442906778305769, Final Batch Loss: 0.0032636914402246475\n",
      "Epoch 398, Loss: 0.08399951731553301, Final Batch Loss: 0.0005786688416264951\n",
      "Epoch 399, Loss: 0.09549534798134118, Final Batch Loss: 0.0011123950826004148\n",
      "Epoch 400, Loss: 0.07166219130158424, Final Batch Loss: 0.007740774191915989\n",
      "Epoch 401, Loss: 0.09314748831093311, Final Batch Loss: 0.036723505705595016\n",
      "Epoch 402, Loss: 0.06726951338350773, Final Batch Loss: 0.02004183642566204\n",
      "Epoch 403, Loss: 0.08001170959323645, Final Batch Loss: 0.0015575066208839417\n",
      "Epoch 404, Loss: 0.12721318053081632, Final Batch Loss: 0.005873230751603842\n",
      "Epoch 405, Loss: 0.06975872139446437, Final Batch Loss: 0.0011640733573585749\n",
      "Epoch 406, Loss: 0.04461462062317878, Final Batch Loss: 0.0010303944582119584\n",
      "Epoch 407, Loss: 0.058087803423404694, Final Batch Loss: 0.004382586572319269\n",
      "Epoch 408, Loss: 0.046871289174305275, Final Batch Loss: 0.0002864413254428655\n",
      "Epoch 409, Loss: 0.05563567047647666, Final Batch Loss: 0.00022716708190273494\n",
      "Epoch 410, Loss: 0.04629042197484523, Final Batch Loss: 0.0017880952218547463\n",
      "Epoch 411, Loss: 0.055842968220531475, Final Batch Loss: 8.001137030078098e-05\n",
      "Epoch 412, Loss: 0.08926826529204845, Final Batch Loss: 0.0290969330817461\n",
      "Epoch 413, Loss: 0.08611621311865747, Final Batch Loss: 0.04127718135714531\n",
      "Epoch 414, Loss: 0.09349428047426045, Final Batch Loss: 0.0018576656002551317\n",
      "Epoch 415, Loss: 0.04100789991207421, Final Batch Loss: 0.0020994236692786217\n",
      "Epoch 416, Loss: 0.043853772920556366, Final Batch Loss: 0.0011474710190668702\n",
      "Epoch 417, Loss: 0.07854205183684826, Final Batch Loss: 0.0021244478411972523\n",
      "Epoch 418, Loss: 0.029718218371272087, Final Batch Loss: 0.0031505811493843794\n",
      "Epoch 419, Loss: 0.05168695840984583, Final Batch Loss: 0.008271357044577599\n",
      "Epoch 420, Loss: 0.03937174013117328, Final Batch Loss: 0.0006142026395536959\n",
      "Epoch 421, Loss: 0.08048126261564903, Final Batch Loss: 0.0003761143598239869\n",
      "Epoch 422, Loss: 0.04577716067433357, Final Batch Loss: 0.004216462839394808\n",
      "Epoch 423, Loss: 0.04922235896810889, Final Batch Loss: 0.0022773942910134792\n",
      "Epoch 424, Loss: 0.09471669001504779, Final Batch Loss: 0.04525601118803024\n",
      "Epoch 425, Loss: 0.06298809545114636, Final Batch Loss: 0.003052517306059599\n",
      "Epoch 426, Loss: 0.04327864351216704, Final Batch Loss: 0.001122735091485083\n",
      "Epoch 427, Loss: 0.05172736686654389, Final Batch Loss: 0.00021761911921203136\n",
      "Epoch 428, Loss: 0.027292696409858763, Final Batch Loss: 0.0006672694580629468\n",
      "Epoch 429, Loss: 0.10407145833596587, Final Batch Loss: 0.0032135285437107086\n",
      "Epoch 430, Loss: 0.04309272096725181, Final Batch Loss: 0.0003140369080938399\n",
      "Epoch 431, Loss: 0.05869300232734531, Final Batch Loss: 0.0015107173239812255\n",
      "Epoch 432, Loss: 0.06574055971577764, Final Batch Loss: 0.00903277937322855\n",
      "Epoch 433, Loss: 0.024220115272328258, Final Batch Loss: 0.0041036056354641914\n",
      "Epoch 434, Loss: 0.040363514388445765, Final Batch Loss: 0.0008787213009782135\n",
      "Epoch 435, Loss: 0.071282111806795, Final Batch Loss: 0.024656672030687332\n",
      "Epoch 436, Loss: 0.034027687506750226, Final Batch Loss: 0.005339439958333969\n",
      "Epoch 437, Loss: 0.07214833117905073, Final Batch Loss: 0.0003735234204214066\n",
      "Epoch 438, Loss: 0.0767563870176673, Final Batch Loss: 0.006260644644498825\n",
      "Epoch 439, Loss: 0.04196766737368307, Final Batch Loss: 3.15110337396618e-05\n",
      "Epoch 440, Loss: 0.05586626738659106, Final Batch Loss: 0.00037052747211419046\n",
      "Epoch 441, Loss: 0.022942864277865738, Final Batch Loss: 0.0005734902224503458\n",
      "Epoch 442, Loss: 0.06594108372519258, Final Batch Loss: 7.670513878110796e-05\n",
      "Epoch 443, Loss: 0.0573241556994617, Final Batch Loss: 0.00638594338670373\n",
      "Epoch 444, Loss: 0.030763981631025672, Final Batch Loss: 0.005568427499383688\n",
      "Epoch 445, Loss: 0.029756494681350887, Final Batch Loss: 0.001179688610136509\n",
      "Epoch 446, Loss: 0.08183111436665058, Final Batch Loss: 0.0246602650731802\n",
      "Epoch 447, Loss: 0.020603807759471238, Final Batch Loss: 0.0012675559846684337\n",
      "Epoch 448, Loss: 0.037830506335012615, Final Batch Loss: 0.001949343946762383\n",
      "Epoch 449, Loss: 0.05582522985059768, Final Batch Loss: 0.0005447055445984006\n",
      "Epoch 450, Loss: 0.04586136434227228, Final Batch Loss: 0.013046556152403355\n",
      "Epoch 451, Loss: 0.05152431153692305, Final Batch Loss: 0.003303301753476262\n",
      "Epoch 452, Loss: 0.03460889938287437, Final Batch Loss: 0.0017099117394536734\n",
      "Epoch 453, Loss: 0.04100710488273762, Final Batch Loss: 0.00033901489223353565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454, Loss: 0.046372735407203436, Final Batch Loss: 0.0028944879304617643\n",
      "Epoch 455, Loss: 0.05534877604804933, Final Batch Loss: 0.016751907765865326\n",
      "Epoch 456, Loss: 0.07807642221450806, Final Batch Loss: 0.014900117181241512\n",
      "Epoch 457, Loss: 0.04211545264843153, Final Batch Loss: 9.527238580631092e-05\n",
      "Epoch 458, Loss: 0.028631387394852936, Final Batch Loss: 0.0016137250931933522\n",
      "Epoch 459, Loss: 0.11098284786567092, Final Batch Loss: 0.0644378736615181\n",
      "Epoch 460, Loss: 0.04984884965233505, Final Batch Loss: 0.0010071768192574382\n",
      "Epoch 461, Loss: 0.044690490496577695, Final Batch Loss: 0.0003540953912306577\n",
      "Epoch 462, Loss: 0.05360722031764453, Final Batch Loss: 6.960474274819717e-05\n",
      "Epoch 463, Loss: 0.0690168896690011, Final Batch Loss: 0.003319604555144906\n",
      "Epoch 464, Loss: 0.030288174835732207, Final Batch Loss: 0.00027151298127137125\n",
      "Epoch 465, Loss: 0.07593590952455997, Final Batch Loss: 0.0005346949910745025\n",
      "Epoch 466, Loss: 0.03900099662132561, Final Batch Loss: 0.0020028299186378717\n",
      "Epoch 467, Loss: 0.033861309828353114, Final Batch Loss: 0.00018061960872728378\n",
      "Epoch 468, Loss: 0.05272041400894523, Final Batch Loss: 0.0034427554346621037\n",
      "Epoch 469, Loss: 0.035795586940366775, Final Batch Loss: 0.0006180981290526688\n",
      "Epoch 470, Loss: 0.030324971303343773, Final Batch Loss: 0.006783634424209595\n",
      "Epoch 471, Loss: 0.05719399219378829, Final Batch Loss: 0.002645135158672929\n",
      "Epoch 472, Loss: 0.04121137014590204, Final Batch Loss: 0.0010486722458153963\n",
      "Epoch 473, Loss: 0.028207352093886584, Final Batch Loss: 0.00028327846666797996\n",
      "Epoch 474, Loss: 0.07133458193857223, Final Batch Loss: 0.0005548595217987895\n",
      "Epoch 475, Loss: 0.07639887044206262, Final Batch Loss: 0.049116361886262894\n",
      "Epoch 476, Loss: 0.0504513387568295, Final Batch Loss: 0.007504356559365988\n",
      "Epoch 477, Loss: 0.04664903169032186, Final Batch Loss: 0.004920727573335171\n",
      "Epoch 478, Loss: 0.03523365706496406, Final Batch Loss: 0.00024360087991226465\n",
      "Epoch 479, Loss: 0.04056387580931187, Final Batch Loss: 0.002260028850287199\n",
      "Epoch 480, Loss: 0.026810552823008038, Final Batch Loss: 6.69330038363114e-05\n",
      "Epoch 481, Loss: 0.027543839692953043, Final Batch Loss: 0.00017110274347942322\n",
      "Epoch 482, Loss: 0.03426259272964671, Final Batch Loss: 0.00029805960366502404\n",
      "Epoch 483, Loss: 0.03208170356811024, Final Batch Loss: 0.00025845030904747546\n",
      "Epoch 484, Loss: 0.03265440324321389, Final Batch Loss: 0.009591972455382347\n",
      "Epoch 485, Loss: 0.04647878522519022, Final Batch Loss: 0.0017207128694280982\n",
      "Epoch 486, Loss: 0.025176619295962155, Final Batch Loss: 0.0015253720339387655\n",
      "Epoch 487, Loss: 0.03605243260972202, Final Batch Loss: 0.00010296981781721115\n",
      "Epoch 488, Loss: 0.037741089530754834, Final Batch Loss: 0.0006977022276259959\n",
      "Epoch 489, Loss: 0.02676567509843153, Final Batch Loss: 4.2494433728279546e-05\n",
      "Epoch 490, Loss: 0.06911661452613771, Final Batch Loss: 0.003796855453401804\n",
      "Epoch 491, Loss: 0.010785156540805474, Final Batch Loss: 6.142482743598521e-05\n",
      "Epoch 492, Loss: 0.026599488861393183, Final Batch Loss: 0.0008366350084543228\n",
      "Epoch 493, Loss: 0.023612034536199644, Final Batch Loss: 0.000294907164061442\n",
      "Epoch 494, Loss: 0.021044710112619214, Final Batch Loss: 0.0002288452087668702\n",
      "Epoch 495, Loss: 0.052140715066343546, Final Batch Loss: 0.026885073632001877\n",
      "Epoch 496, Loss: 0.06583146538469009, Final Batch Loss: 0.0002760074276011437\n",
      "Epoch 497, Loss: 0.0685034568887204, Final Batch Loss: 0.002608616603538394\n",
      "Epoch 498, Loss: 0.026418425724841654, Final Batch Loss: 0.0008349342970177531\n",
      "Epoch 499, Loss: 0.06606916547752917, Final Batch Loss: 0.0017773143481463194\n",
      "Epoch 500, Loss: 0.034233201840834226, Final Batch Loss: 9.258949285140261e-05\n",
      "Epoch 501, Loss: 0.09094069758430123, Final Batch Loss: 0.03749948367476463\n",
      "Epoch 502, Loss: 0.042130141344387084, Final Batch Loss: 0.0003902025637216866\n",
      "Epoch 503, Loss: 0.05604343116283417, Final Batch Loss: 0.002077551791444421\n",
      "Epoch 504, Loss: 0.023146270192228258, Final Batch Loss: 0.0015138710150495172\n",
      "Epoch 505, Loss: 0.03358924118219875, Final Batch Loss: 0.00041855135350488126\n",
      "Epoch 506, Loss: 0.04796530643943697, Final Batch Loss: 0.0010724408784881234\n",
      "Epoch 507, Loss: 0.06736541743885027, Final Batch Loss: 6.1493665270973e-05\n",
      "Epoch 508, Loss: 0.04085036538890563, Final Batch Loss: 0.00014982136781327426\n",
      "Epoch 509, Loss: 0.06547526235226542, Final Batch Loss: 0.0009994873544201255\n",
      "Epoch 510, Loss: 0.014690356707433239, Final Batch Loss: 3.272868343628943e-05\n",
      "Epoch 511, Loss: 0.041925946017727256, Final Batch Loss: 0.017616141587495804\n",
      "Epoch 512, Loss: 0.0254028505878523, Final Batch Loss: 0.013429307378828526\n",
      "Epoch 513, Loss: 0.04170737060485408, Final Batch Loss: 0.0008067448507063091\n",
      "Epoch 514, Loss: 0.03972221398726106, Final Batch Loss: 0.010200747288763523\n",
      "Epoch 515, Loss: 0.030001168488524854, Final Batch Loss: 0.0014123170403763652\n",
      "Epoch 516, Loss: 0.04039076017215848, Final Batch Loss: 0.0013094462919980288\n",
      "Epoch 517, Loss: 0.026843179774004966, Final Batch Loss: 0.0007045595557428896\n",
      "Epoch 518, Loss: 0.05730191036127508, Final Batch Loss: 0.007379296235740185\n",
      "Epoch 519, Loss: 0.024504801025614142, Final Batch Loss: 0.0015162505442276597\n",
      "Epoch 520, Loss: 0.06126834967290051, Final Batch Loss: 0.00036492643994279206\n",
      "Epoch 521, Loss: 0.017176397544972133, Final Batch Loss: 6.024474714649841e-05\n",
      "Epoch 522, Loss: 0.02002116688527167, Final Batch Loss: 0.003109507029876113\n",
      "Epoch 523, Loss: 0.03415264282375574, Final Batch Loss: 0.0031632320024073124\n",
      "Epoch 524, Loss: 0.02180586033500731, Final Batch Loss: 0.0006662821397185326\n",
      "Epoch 525, Loss: 0.018350788159295917, Final Batch Loss: 0.0027054250240325928\n",
      "Epoch 526, Loss: 0.02639139738494123, Final Batch Loss: 2.5968454792746343e-05\n",
      "Epoch 527, Loss: 0.01532088071689941, Final Batch Loss: 0.0001567040162626654\n",
      "Epoch 528, Loss: 0.26583054510410875, Final Batch Loss: 0.22839835286140442\n",
      "Epoch 529, Loss: 0.09599896389408968, Final Batch Loss: 0.00026004257961176336\n",
      "Epoch 530, Loss: 0.03162364463787526, Final Batch Loss: 0.000616304692812264\n",
      "Epoch 531, Loss: 0.07493058638647199, Final Batch Loss: 0.015404901467263699\n",
      "Epoch 532, Loss: 0.02804123522946611, Final Batch Loss: 0.0004120332305319607\n",
      "Epoch 533, Loss: 0.03185056848451495, Final Batch Loss: 0.006274583283811808\n",
      "Epoch 534, Loss: 0.020639880618546158, Final Batch Loss: 0.0007118476205505431\n",
      "Epoch 535, Loss: 0.012302572838962078, Final Batch Loss: 0.00015041825827211142\n",
      "Epoch 536, Loss: 0.037771844887174666, Final Batch Loss: 0.006952006835490465\n",
      "Epoch 537, Loss: 0.03123845753725618, Final Batch Loss: 0.0016864935168996453\n",
      "Epoch 538, Loss: 0.031681762397056445, Final Batch Loss: 0.00032399952760897577\n",
      "Epoch 539, Loss: 0.08455539413262159, Final Batch Loss: 0.05072909593582153\n",
      "Epoch 540, Loss: 0.0840321232099086, Final Batch Loss: 0.002028555842116475\n",
      "Epoch 541, Loss: 0.21064187760930508, Final Batch Loss: 0.0006383302388712764\n",
      "Epoch 542, Loss: 0.07909208722412586, Final Batch Loss: 0.0017924013081938028\n",
      "Epoch 543, Loss: 0.4232540677767247, Final Batch Loss: 0.39119020104408264\n",
      "Epoch 544, Loss: 0.053064224164700136, Final Batch Loss: 0.0002834119077306241\n",
      "Epoch 545, Loss: 0.07233658398035914, Final Batch Loss: 0.001250591711141169\n",
      "Epoch 546, Loss: 0.19756665267050266, Final Batch Loss: 0.10355373471975327\n",
      "Epoch 547, Loss: 0.06946453778073192, Final Batch Loss: 0.01872069016098976\n",
      "Epoch 548, Loss: 0.0668009521177737, Final Batch Loss: 0.0001668682525632903\n",
      "Epoch 549, Loss: 0.06186336721293628, Final Batch Loss: 0.009137488901615143\n",
      "Epoch 550, Loss: 0.019546938681742176, Final Batch Loss: 0.00022607643040828407\n",
      "Epoch 551, Loss: 0.03614278323948383, Final Batch Loss: 0.013964793644845486\n",
      "Epoch 552, Loss: 0.04573127627372742, Final Batch Loss: 0.0020804498344659805\n",
      "Epoch 553, Loss: 0.05961635755375028, Final Batch Loss: 0.0010109874419867992\n",
      "Epoch 554, Loss: 0.02633026917465031, Final Batch Loss: 0.005246961023658514\n",
      "Epoch 555, Loss: 0.19017168402206153, Final Batch Loss: 0.1255456656217575\n",
      "Epoch 556, Loss: 0.06514416867867112, Final Batch Loss: 0.004685628227889538\n",
      "Epoch 557, Loss: 0.23589595220983028, Final Batch Loss: 0.17525209486484528\n",
      "Epoch 558, Loss: 0.047376842001540354, Final Batch Loss: 5.857692667632364e-05\n",
      "Epoch 559, Loss: 0.07401544685126282, Final Batch Loss: 0.0003692767641041428\n",
      "Epoch 560, Loss: 0.12498131580650806, Final Batch Loss: 0.04280829802155495\n",
      "Epoch 561, Loss: 0.11967823604209116, Final Batch Loss: 0.00011053724301746115\n",
      "Epoch 562, Loss: 0.03642509947530925, Final Batch Loss: 0.00970364362001419\n",
      "Epoch 563, Loss: 0.056666999065782875, Final Batch Loss: 0.0006660494836978614\n",
      "Epoch 564, Loss: 0.052886418998241425, Final Batch Loss: 0.005583728197962046\n",
      "Epoch 565, Loss: 0.07580138184130192, Final Batch Loss: 0.026064429432153702\n",
      "Epoch 566, Loss: 0.03306900104507804, Final Batch Loss: 0.0006718076765537262\n",
      "Epoch 567, Loss: 0.04557523569383193, Final Batch Loss: 0.00023338962637353688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 568, Loss: 0.05210270227325964, Final Batch Loss: 3.136468512821011e-05\n",
      "Epoch 569, Loss: 0.028508445248007774, Final Batch Loss: 0.0003594360314309597\n",
      "Epoch 570, Loss: 0.04572342592291534, Final Batch Loss: 0.0037122201174497604\n",
      "Epoch 571, Loss: 0.057043771259486675, Final Batch Loss: 0.03754323720932007\n",
      "Epoch 572, Loss: 0.0322329515038291, Final Batch Loss: 0.00018376125080976635\n",
      "Epoch 573, Loss: 0.039968227269127965, Final Batch Loss: 0.0030178867746144533\n",
      "Epoch 574, Loss: 0.04697476280853152, Final Batch Loss: 0.0005789041751995683\n",
      "Epoch 575, Loss: 0.04528435366228223, Final Batch Loss: 0.005941917188465595\n",
      "Epoch 576, Loss: 0.04299092979999841, Final Batch Loss: 5.9824789786944166e-05\n",
      "Epoch 577, Loss: 0.020824738836381584, Final Batch Loss: 0.0005402637762017548\n",
      "Epoch 578, Loss: 0.04638077551499009, Final Batch Loss: 0.025760585442185402\n",
      "Epoch 579, Loss: 0.021908921422436833, Final Batch Loss: 0.0016721256542950869\n",
      "Epoch 580, Loss: 0.1331571564078331, Final Batch Loss: 0.09138776361942291\n",
      "Epoch 581, Loss: 0.058646726654842496, Final Batch Loss: 0.0028223847039043903\n",
      "Epoch 582, Loss: 0.12838105112314224, Final Batch Loss: 0.0038180905394256115\n",
      "Epoch 583, Loss: 0.16139442386338487, Final Batch Loss: 0.0006173181463964283\n",
      "Epoch 584, Loss: 0.10750781372189522, Final Batch Loss: 0.03876086696982384\n",
      "Epoch 585, Loss: 0.052773209754377604, Final Batch Loss: 0.0002355391625314951\n",
      "Epoch 586, Loss: 0.054602714255452156, Final Batch Loss: 0.004317606333643198\n",
      "Epoch 587, Loss: 0.05209330181241967, Final Batch Loss: 6.433381349779665e-05\n",
      "Epoch 588, Loss: 0.04840999352745712, Final Batch Loss: 0.0013900483027100563\n",
      "Epoch 589, Loss: 0.045931184460641816, Final Batch Loss: 0.0002215132408309728\n",
      "Epoch 590, Loss: 0.21004669985268265, Final Batch Loss: 0.18294882774353027\n",
      "Epoch 591, Loss: 0.04071563866455108, Final Batch Loss: 0.0010147891007363796\n",
      "Epoch 592, Loss: 0.04418754460130003, Final Batch Loss: 3.839981582132168e-05\n",
      "Epoch 593, Loss: 0.06871640239842236, Final Batch Loss: 0.0033140426967293024\n",
      "Epoch 594, Loss: 0.05023167694162112, Final Batch Loss: 0.00024183692585211247\n",
      "Epoch 595, Loss: 0.024910898529924452, Final Batch Loss: 0.0013766303891316056\n",
      "Epoch 596, Loss: 0.035954382678028196, Final Batch Loss: 0.0002700858167372644\n",
      "Epoch 597, Loss: 0.12055739294737577, Final Batch Loss: 0.09841900318861008\n",
      "Epoch 598, Loss: 0.053816732950508595, Final Batch Loss: 0.013292529620230198\n",
      "Epoch 599, Loss: 0.07014313666149974, Final Batch Loss: 0.0047701699659228325\n",
      "Epoch 600, Loss: 0.12537731602787971, Final Batch Loss: 0.004048838280141354\n",
      "Epoch 601, Loss: 0.06347851478494704, Final Batch Loss: 0.0012039367575198412\n",
      "Epoch 602, Loss: 0.07965817453805357, Final Batch Loss: 0.04488008841872215\n",
      "Epoch 603, Loss: 0.032554933830397204, Final Batch Loss: 0.00033373924088664353\n",
      "Epoch 604, Loss: 0.033357130363583565, Final Batch Loss: 0.008472975343465805\n",
      "Epoch 605, Loss: 0.024835327509208582, Final Batch Loss: 0.00013860930630471557\n",
      "Epoch 606, Loss: 0.023236354463733733, Final Batch Loss: 0.0010278496192768216\n",
      "Epoch 607, Loss: 0.021654300624504685, Final Batch Loss: 0.000303393229842186\n",
      "Epoch 608, Loss: 0.02520701941102743, Final Batch Loss: 0.002098040422424674\n",
      "Epoch 609, Loss: 0.03363752691075206, Final Batch Loss: 0.004844778683036566\n",
      "Epoch 610, Loss: 0.036240077955881134, Final Batch Loss: 0.00029108478338457644\n",
      "Epoch 611, Loss: 0.025516567460726947, Final Batch Loss: 0.0008691260009072721\n",
      "Epoch 612, Loss: 0.031926730647683144, Final Batch Loss: 0.0032386500388383865\n",
      "Epoch 613, Loss: 0.028488696494605392, Final Batch Loss: 0.0007080244249664247\n",
      "Epoch 614, Loss: 0.024054792884271592, Final Batch Loss: 0.0006421153084374964\n",
      "Epoch 615, Loss: 0.02626712655182928, Final Batch Loss: 0.0018443189328536391\n",
      "Epoch 616, Loss: 0.03875887652975507, Final Batch Loss: 0.0003726373251993209\n",
      "Epoch 617, Loss: 0.02157179176720092, Final Batch Loss: 8.364234963664785e-05\n",
      "Epoch 618, Loss: 0.025007967011333676, Final Batch Loss: 4.308949064579792e-05\n",
      "Epoch 619, Loss: 0.019412188499700278, Final Batch Loss: 0.0005908207385800779\n",
      "Epoch 620, Loss: 0.02165297482861206, Final Batch Loss: 0.0009041220764629543\n",
      "Epoch 621, Loss: 0.07587724179029465, Final Batch Loss: 0.06316082924604416\n",
      "Epoch 622, Loss: 0.04036518043722026, Final Batch Loss: 0.00021498717251233757\n",
      "Epoch 623, Loss: 0.017211654281709343, Final Batch Loss: 0.000601234205532819\n",
      "Epoch 624, Loss: 0.040223435731604695, Final Batch Loss: 0.03336716815829277\n",
      "Epoch 625, Loss: 0.035329535079654306, Final Batch Loss: 0.0005248574889265001\n",
      "Epoch 626, Loss: 0.04848190259144758, Final Batch Loss: 3.273577385698445e-05\n",
      "Epoch 627, Loss: 0.02749306513578631, Final Batch Loss: 0.000280109146842733\n",
      "Epoch 628, Loss: 0.04466193949338049, Final Batch Loss: 0.001607167418114841\n",
      "Epoch 629, Loss: 0.04583183147769887, Final Batch Loss: 0.00016903418872971088\n",
      "Epoch 630, Loss: 0.01834951143246144, Final Batch Loss: 0.002482672454789281\n",
      "Epoch 631, Loss: 0.03835508436895907, Final Batch Loss: 0.0068491543643176556\n",
      "Epoch 632, Loss: 0.027307745593134314, Final Batch Loss: 0.0003451610100455582\n",
      "Epoch 633, Loss: 0.037554601673036814, Final Batch Loss: 0.003153175814077258\n",
      "Epoch 634, Loss: 0.030109794985037297, Final Batch Loss: 0.00039054109947755933\n",
      "Epoch 635, Loss: 0.04219762544380501, Final Batch Loss: 0.0002660360769368708\n",
      "Epoch 636, Loss: 0.023380181286484003, Final Batch Loss: 0.009200108237564564\n",
      "Epoch 637, Loss: 0.015477880486287177, Final Batch Loss: 0.0010907870018854737\n",
      "Epoch 638, Loss: 0.01518894117907621, Final Batch Loss: 0.00043708275188691914\n",
      "Epoch 639, Loss: 0.025199077783327084, Final Batch Loss: 5.852791218785569e-05\n",
      "Epoch 640, Loss: 0.03928095696028322, Final Batch Loss: 0.0005226485664024949\n",
      "Epoch 641, Loss: 0.022483326960355043, Final Batch Loss: 0.0003684554249048233\n",
      "Epoch 642, Loss: 0.020889181760139763, Final Batch Loss: 0.00031773815862834454\n",
      "Epoch 643, Loss: 0.021893776873184834, Final Batch Loss: 0.00011884005652973428\n",
      "Epoch 644, Loss: 0.013684674282558262, Final Batch Loss: 0.0009652156149968505\n",
      "Epoch 645, Loss: 0.02309953541680443, Final Batch Loss: 1.1877894394274335e-05\n",
      "Epoch 646, Loss: 0.029277106863446534, Final Batch Loss: 0.0005359319038689137\n",
      "Epoch 647, Loss: 0.03217122331261635, Final Batch Loss: 0.004951827228069305\n",
      "Epoch 648, Loss: 0.007547096451162361, Final Batch Loss: 0.00020504624990280718\n",
      "Epoch 649, Loss: 0.022403229435440153, Final Batch Loss: 0.0029902381356805563\n",
      "Epoch 650, Loss: 0.03573433996643871, Final Batch Loss: 0.0005726186791434884\n",
      "Epoch 651, Loss: 0.01836026622913778, Final Batch Loss: 0.0032408914994448423\n",
      "Epoch 652, Loss: 0.040822526018018834, Final Batch Loss: 0.00014194850518833846\n",
      "Epoch 653, Loss: 0.01696919376263395, Final Batch Loss: 0.0002926709712482989\n",
      "Epoch 654, Loss: 0.012373197125270963, Final Batch Loss: 0.0025319948326796293\n",
      "Epoch 655, Loss: 0.01254188884922769, Final Batch Loss: 0.00022636096400674433\n",
      "Epoch 656, Loss: 0.012334311380982399, Final Batch Loss: 7.915205787867308e-05\n",
      "Epoch 657, Loss: 0.029365580470766872, Final Batch Loss: 9.891012450680137e-05\n",
      "Epoch 658, Loss: 0.023240873735630885, Final Batch Loss: 0.00030291746952570975\n",
      "Epoch 659, Loss: 0.029406154935713857, Final Batch Loss: 0.0045699505135416985\n",
      "Epoch 660, Loss: 0.015324686712119728, Final Batch Loss: 0.0019444571807980537\n",
      "Epoch 661, Loss: 0.0098924400517717, Final Batch Loss: 0.001284269499592483\n",
      "Epoch 662, Loss: 0.00632024216974969, Final Batch Loss: 3.2976018701447174e-05\n",
      "Epoch 663, Loss: 0.032759223380708136, Final Batch Loss: 0.00017742575437296182\n",
      "Epoch 664, Loss: 0.015302030311431736, Final Batch Loss: 0.0010486061219125986\n",
      "Epoch 665, Loss: 0.01566348352935165, Final Batch Loss: 0.00035784865031018853\n",
      "Epoch 666, Loss: 0.030355430440977216, Final Batch Loss: 0.001432751421816647\n",
      "Epoch 667, Loss: 0.03239735175156966, Final Batch Loss: 0.0006800112314522266\n",
      "Epoch 668, Loss: 0.06196585651196074, Final Batch Loss: 0.0001680525456322357\n",
      "Epoch 669, Loss: 0.02123222230875399, Final Batch Loss: 0.0001973127800738439\n",
      "Epoch 670, Loss: 0.05282827059272677, Final Batch Loss: 0.03027382679283619\n",
      "Epoch 671, Loss: 0.017036494507919997, Final Batch Loss: 0.0050870561972260475\n",
      "Epoch 672, Loss: 0.037725327943917364, Final Batch Loss: 0.0009305716375820339\n",
      "Epoch 673, Loss: 0.04979976505273953, Final Batch Loss: 0.0003315796493552625\n",
      "Epoch 674, Loss: 0.06672361813252792, Final Batch Loss: 0.001585659570991993\n",
      "Epoch 675, Loss: 0.012916490692077787, Final Batch Loss: 1.6262138160527684e-05\n",
      "Epoch 676, Loss: 0.029311610294826096, Final Batch Loss: 4.905639434582554e-05\n",
      "Epoch 677, Loss: 0.031004145741462708, Final Batch Loss: 0.004866320639848709\n",
      "Epoch 678, Loss: 0.031324506213422865, Final Batch Loss: 4.8706482630223036e-05\n",
      "Epoch 679, Loss: 0.023972130147740245, Final Batch Loss: 0.0011237106518819928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 680, Loss: 0.013970704167149961, Final Batch Loss: 0.0008994812378659844\n",
      "Epoch 681, Loss: 0.01229016350407619, Final Batch Loss: 0.00020542235870379955\n",
      "Epoch 682, Loss: 0.02689251018455252, Final Batch Loss: 0.0005298444884829223\n",
      "Epoch 683, Loss: 0.00883709132176591, Final Batch Loss: 7.479701162083074e-05\n",
      "Epoch 684, Loss: 0.01188715977332322, Final Batch Loss: 0.00011091829946963117\n",
      "Epoch 685, Loss: 0.0058933092319648495, Final Batch Loss: 1.004761202239024e-06\n",
      "Epoch 686, Loss: 0.0875245250063017, Final Batch Loss: 0.048106200993061066\n",
      "Epoch 687, Loss: 0.07625738740898669, Final Batch Loss: 0.007352686021476984\n",
      "Epoch 688, Loss: 0.8834199956618249, Final Batch Loss: 0.8623761534690857\n",
      "Epoch 689, Loss: 0.07750052071060054, Final Batch Loss: 0.0002703193749766797\n",
      "Epoch 690, Loss: 0.2521840014960617, Final Batch Loss: 0.003617716720327735\n",
      "Epoch 691, Loss: 0.20295895636081696, Final Batch Loss: 0.004725337028503418\n",
      "Epoch 692, Loss: 0.14246467873454094, Final Batch Loss: 0.028221318498253822\n",
      "Epoch 693, Loss: 0.030714774038642645, Final Batch Loss: 0.0023011150769889355\n",
      "Epoch 694, Loss: 0.12131595460959943, Final Batch Loss: 4.539441579254344e-05\n",
      "Epoch 695, Loss: 0.13612446471233852, Final Batch Loss: 0.0002970975183416158\n",
      "Epoch 696, Loss: 0.03979365425766446, Final Batch Loss: 0.0002763449738267809\n",
      "Epoch 697, Loss: 0.04402112867683172, Final Batch Loss: 0.0020151652861386538\n",
      "Epoch 698, Loss: 0.060982304625213146, Final Batch Loss: 0.0021705185063183308\n",
      "Epoch 699, Loss: 0.038896227488294244, Final Batch Loss: 0.0013416232541203499\n",
      "Epoch 700, Loss: 0.02372676832601428, Final Batch Loss: 0.005901961587369442\n",
      "Epoch 701, Loss: 0.05974395922385156, Final Batch Loss: 0.0371096134185791\n",
      "Epoch 702, Loss: 0.1031335205771029, Final Batch Loss: 0.07647876441478729\n",
      "Epoch 703, Loss: 0.06865385768469423, Final Batch Loss: 0.0017907604342326522\n",
      "Epoch 704, Loss: 0.02738622552715242, Final Batch Loss: 0.001241042511537671\n",
      "Epoch 705, Loss: 0.039266658464839566, Final Batch Loss: 1.723364221106749e-05\n",
      "Epoch 706, Loss: 0.03520983597263694, Final Batch Loss: 0.007974847219884396\n",
      "Epoch 707, Loss: 0.03954372217413038, Final Batch Loss: 0.0010147689608857036\n",
      "Epoch 708, Loss: 0.04167574690654874, Final Batch Loss: 0.002297446597367525\n",
      "Epoch 709, Loss: 0.02021076309029013, Final Batch Loss: 0.0017403251258656383\n",
      "Epoch 710, Loss: 0.018966481555253267, Final Batch Loss: 0.0023587916512042284\n",
      "Epoch 711, Loss: 0.012294756350456737, Final Batch Loss: 6.90169254085049e-05\n",
      "Epoch 712, Loss: 0.024720714311115444, Final Batch Loss: 0.003165619447827339\n",
      "Epoch 713, Loss: 0.047914543603837956, Final Batch Loss: 0.00010149920854019001\n",
      "Epoch 714, Loss: 0.020130933495238423, Final Batch Loss: 0.0012924231123179197\n",
      "Epoch 715, Loss: 0.04627055590390228, Final Batch Loss: 0.000131280132336542\n",
      "Epoch 716, Loss: 0.021255682688206434, Final Batch Loss: 0.0014986582100391388\n",
      "Epoch 717, Loss: 0.02552523440681398, Final Batch Loss: 0.0059693073853850365\n",
      "Epoch 718, Loss: 0.024184085878005135, Final Batch Loss: 1.6484160369145684e-05\n",
      "Epoch 719, Loss: 0.022312838584184647, Final Batch Loss: 0.0014028104487806559\n",
      "Epoch 720, Loss: 0.03664583107456565, Final Batch Loss: 0.004813569597899914\n",
      "Epoch 721, Loss: 0.016001797150238417, Final Batch Loss: 0.0001778460427885875\n",
      "Epoch 722, Loss: 0.012873030107584782, Final Batch Loss: 8.324645750690252e-05\n",
      "Epoch 723, Loss: 0.03991686092922464, Final Batch Loss: 5.830958252772689e-05\n",
      "Epoch 724, Loss: 0.021983501210343093, Final Batch Loss: 0.004496378358453512\n",
      "Epoch 725, Loss: 0.017935610112544964, Final Batch Loss: 1.2703674656222574e-05\n",
      "Epoch 726, Loss: 0.3959654187783599, Final Batch Loss: 0.38086405396461487\n",
      "Epoch 727, Loss: 0.05247731669805944, Final Batch Loss: 0.030999230220913887\n",
      "Epoch 728, Loss: 0.05388451740145683, Final Batch Loss: 0.006001812405884266\n",
      "Epoch 729, Loss: 0.025540510687278584, Final Batch Loss: 0.0001349253871012479\n",
      "Epoch 730, Loss: 0.026589845787384547, Final Batch Loss: 0.0001283476740354672\n",
      "Epoch 731, Loss: 0.041523782652802765, Final Batch Loss: 0.0006627860711887479\n",
      "Epoch 732, Loss: 0.02446305236662738, Final Batch Loss: 0.00032265877234749496\n",
      "Epoch 733, Loss: 0.027112428768305108, Final Batch Loss: 0.00019922919454984367\n",
      "Epoch 734, Loss: 0.024474157422446297, Final Batch Loss: 2.9577809982583858e-05\n",
      "Epoch 735, Loss: 0.013643750455230474, Final Batch Loss: 0.0033516515977680683\n",
      "Epoch 736, Loss: 0.01583155896514654, Final Batch Loss: 0.00312528177164495\n",
      "Epoch 737, Loss: 0.01946875627618283, Final Batch Loss: 0.0004982327809557319\n",
      "Epoch 738, Loss: 0.038536208448931575, Final Batch Loss: 0.012129316106438637\n",
      "Epoch 739, Loss: 0.06803312245756388, Final Batch Loss: 0.04749680310487747\n",
      "Epoch 740, Loss: 0.03530447985394858, Final Batch Loss: 0.0001484821259509772\n",
      "Epoch 741, Loss: 0.03820028158952482, Final Batch Loss: 0.00037799091660417616\n",
      "Epoch 742, Loss: 0.05305054027121514, Final Batch Loss: 0.0016354640247300267\n",
      "Epoch 743, Loss: 0.03240843411185779, Final Batch Loss: 0.0002886132861021906\n",
      "Epoch 744, Loss: 0.021614335437334375, Final Batch Loss: 3.549557368387468e-05\n",
      "Epoch 745, Loss: 0.016061860718764365, Final Batch Loss: 0.0013331081718206406\n",
      "Epoch 746, Loss: 0.01366863820294384, Final Batch Loss: 7.879444456193596e-05\n",
      "Epoch 747, Loss: 0.0397808994166553, Final Batch Loss: 0.003984748385846615\n",
      "Epoch 748, Loss: 0.01209516468225047, Final Batch Loss: 0.00047839205944910645\n",
      "Epoch 749, Loss: 0.04128986597061157, Final Batch Loss: 0.0005895808571949601\n",
      "Epoch 750, Loss: 0.020351929124444723, Final Batch Loss: 0.0016922148643061519\n",
      "Epoch 751, Loss: 0.025782347714994103, Final Batch Loss: 0.0006128035602159798\n",
      "Epoch 752, Loss: 0.006959497521165758, Final Batch Loss: 0.0004442765493877232\n",
      "Epoch 753, Loss: 0.020476166537264362, Final Batch Loss: 0.0002591713855508715\n",
      "Epoch 754, Loss: 0.015661160636227578, Final Batch Loss: 0.00035322405165061355\n",
      "Epoch 755, Loss: 0.016791856614872813, Final Batch Loss: 0.00042622932232916355\n",
      "Epoch 756, Loss: 0.030323560829856433, Final Batch Loss: 0.00019347436318639666\n",
      "Epoch 757, Loss: 0.029907071992056444, Final Batch Loss: 0.0002467544109094888\n",
      "Epoch 758, Loss: 0.03194541437551379, Final Batch Loss: 0.001364685595035553\n",
      "Epoch 759, Loss: 0.010067945113405585, Final Batch Loss: 0.0013795506674796343\n",
      "Epoch 760, Loss: 0.012660319320275448, Final Batch Loss: 0.00021388880850281566\n",
      "Epoch 761, Loss: 0.05538117082323879, Final Batch Loss: 0.04342124983668327\n",
      "Epoch 762, Loss: 0.3967282755766064, Final Batch Loss: 0.3697083294391632\n",
      "Epoch 763, Loss: 0.05961419513914734, Final Batch Loss: 0.0006674655014649034\n",
      "Epoch 764, Loss: 0.2075946033000946, Final Batch Loss: 0.023983290418982506\n",
      "Epoch 765, Loss: 0.09204737574327737, Final Batch Loss: 0.000518734217621386\n",
      "Epoch 766, Loss: 0.01785267388675038, Final Batch Loss: 1.7966352743314928e-06\n",
      "Epoch 767, Loss: 0.03000044298823923, Final Batch Loss: 0.0013448685640469193\n",
      "Epoch 768, Loss: 0.029581215188954957, Final Batch Loss: 0.00014307904348243028\n",
      "Epoch 769, Loss: 0.023435613235051278, Final Batch Loss: 0.00011745104711735621\n",
      "Epoch 770, Loss: 0.034350621746852994, Final Batch Loss: 0.0038619537372142076\n",
      "Epoch 771, Loss: 0.028674710483755916, Final Batch Loss: 0.0006047968636266887\n",
      "Epoch 772, Loss: 0.033385350136086345, Final Batch Loss: 0.01002795435488224\n",
      "Epoch 773, Loss: 0.04243667400442064, Final Batch Loss: 0.001573318848386407\n",
      "Epoch 774, Loss: 0.01722241216339171, Final Batch Loss: 0.002300235675647855\n",
      "Epoch 775, Loss: 0.013483661023201421, Final Batch Loss: 0.00022680455003865063\n",
      "Epoch 776, Loss: 0.013526676452329411, Final Batch Loss: 6.564889645233052e-06\n",
      "Epoch 777, Loss: 0.02291494187011267, Final Batch Loss: 4.5328324631555006e-05\n",
      "Epoch 778, Loss: 0.03668444027425721, Final Batch Loss: 0.01699194684624672\n",
      "Epoch 779, Loss: 0.021001082728616893, Final Batch Loss: 0.0015638041077181697\n",
      "Epoch 780, Loss: 0.02790106402244419, Final Batch Loss: 0.0039047447498887777\n",
      "Epoch 781, Loss: 0.019975465431343764, Final Batch Loss: 0.0005979125271551311\n",
      "Epoch 782, Loss: 0.2253671435173601, Final Batch Loss: 0.219882532954216\n",
      "Epoch 783, Loss: 0.03452330571599305, Final Batch Loss: 0.00043241027742624283\n",
      "Epoch 784, Loss: 0.07049692631699145, Final Batch Loss: 0.010570990853011608\n",
      "Epoch 785, Loss: 0.012265083147212863, Final Batch Loss: 0.0018694259924814105\n",
      "Epoch 786, Loss: 0.04683470475720242, Final Batch Loss: 0.0006877428968437016\n",
      "Epoch 787, Loss: 0.014855390996672213, Final Batch Loss: 0.0006858754786662757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 788, Loss: 0.04286494920961559, Final Batch Loss: 0.00022218655794858932\n",
      "Epoch 789, Loss: 0.020844734099227935, Final Batch Loss: 0.0008004808914847672\n",
      "Epoch 790, Loss: 0.013589284266345203, Final Batch Loss: 0.0004947430570609868\n",
      "Epoch 791, Loss: 0.018785482039675117, Final Batch Loss: 0.004991242196410894\n",
      "Epoch 792, Loss: 0.020966169083294517, Final Batch Loss: 1.1017670658475254e-05\n",
      "Epoch 793, Loss: 0.016415608872193843, Final Batch Loss: 0.0002576516126282513\n",
      "Epoch 794, Loss: 0.013705135905183852, Final Batch Loss: 0.0015372858615592122\n",
      "Epoch 795, Loss: 0.014283047174103558, Final Batch Loss: 0.003131714416667819\n",
      "Epoch 796, Loss: 0.025798495535127586, Final Batch Loss: 4.587313378578983e-05\n",
      "Epoch 797, Loss: 0.027285624732030556, Final Batch Loss: 0.00035083197872154415\n",
      "Epoch 798, Loss: 0.0072693330876063555, Final Batch Loss: 0.00026513912598602474\n",
      "Epoch 799, Loss: 0.020653787869377993, Final Batch Loss: 0.00015563516353722662\n",
      "Epoch 800, Loss: 0.027074333047494292, Final Batch Loss: 0.00035548838786780834\n",
      "Epoch 801, Loss: 0.041550188325345516, Final Batch Loss: 0.011253667995333672\n",
      "Epoch 802, Loss: 0.025244174724321056, Final Batch Loss: 1.5257533050316852e-05\n",
      "Epoch 803, Loss: 0.026784130721352994, Final Batch Loss: 0.005039697978645563\n",
      "Epoch 804, Loss: 0.0283045272808522, Final Batch Loss: 0.0025822839234024286\n",
      "Epoch 805, Loss: 0.014238537638448179, Final Batch Loss: 0.0017424783436581492\n",
      "Epoch 806, Loss: 0.01390646267827833, Final Batch Loss: 9.707417484605685e-05\n",
      "Epoch 807, Loss: 0.006970920992898755, Final Batch Loss: 0.0001982105168281123\n",
      "Epoch 808, Loss: 0.016981331864371896, Final Batch Loss: 0.007510433904826641\n",
      "Epoch 809, Loss: 0.03460066475963686, Final Batch Loss: 0.00021302934328559786\n",
      "Epoch 810, Loss: 0.009982939809560776, Final Batch Loss: 0.001417413353919983\n",
      "Epoch 811, Loss: 0.021282586007146165, Final Batch Loss: 0.0003487830690573901\n",
      "Epoch 812, Loss: 0.007896218317910098, Final Batch Loss: 7.310973887797445e-05\n",
      "Epoch 813, Loss: 0.008975066361017525, Final Batch Loss: 0.002612029667943716\n",
      "Epoch 814, Loss: 0.008370313793420792, Final Batch Loss: 0.0015185136580839753\n",
      "Epoch 815, Loss: 0.009451859397813678, Final Batch Loss: 0.0024873719085007906\n",
      "Epoch 816, Loss: 0.017542655288707465, Final Batch Loss: 0.0005712059210054576\n",
      "Epoch 817, Loss: 0.018028207181487232, Final Batch Loss: 0.0075449831783771515\n",
      "Epoch 818, Loss: 0.017991438384342473, Final Batch Loss: 9.972659609047696e-05\n",
      "Epoch 819, Loss: 0.010542390198679641, Final Batch Loss: 0.00030178451561369\n",
      "Epoch 820, Loss: 0.031339507666416466, Final Batch Loss: 0.002281004097312689\n",
      "Epoch 821, Loss: 0.026818302314495668, Final Batch Loss: 0.00026457165949977934\n",
      "Epoch 822, Loss: 0.009007465647300705, Final Batch Loss: 0.00047210833872668445\n",
      "Epoch 823, Loss: 0.01948117408755934, Final Batch Loss: 9.906299965223297e-05\n",
      "Epoch 824, Loss: 0.011071582623117138, Final Batch Loss: 5.7246834330726415e-05\n",
      "Epoch 825, Loss: 0.016979325693682767, Final Batch Loss: 4.65761695522815e-06\n",
      "Epoch 826, Loss: 0.013715700944885612, Final Batch Loss: 0.003268252592533827\n",
      "Epoch 827, Loss: 0.0222004356328398, Final Batch Loss: 0.006104611326009035\n",
      "Epoch 828, Loss: 0.03387300006579608, Final Batch Loss: 0.0003097762819379568\n",
      "Epoch 829, Loss: 0.009663111995905638, Final Batch Loss: 0.0011755643645301461\n",
      "Epoch 830, Loss: 0.008070846553891897, Final Batch Loss: 0.0009009665227495134\n",
      "Epoch 831, Loss: 0.004992393443899346, Final Batch Loss: 1.4219565855455585e-05\n",
      "Epoch 832, Loss: 0.032939737488050014, Final Batch Loss: 0.0005043227574788034\n",
      "Epoch 833, Loss: 0.020200513285089983, Final Batch Loss: 6.0946487792534754e-05\n",
      "Epoch 834, Loss: 0.015942983503919095, Final Batch Loss: 0.003317400813102722\n",
      "Epoch 835, Loss: 0.019775159773416817, Final Batch Loss: 0.0018460826249793172\n",
      "Epoch 836, Loss: 0.004410091475847366, Final Batch Loss: 2.3501136183767812e-06\n",
      "Epoch 837, Loss: 0.009199400414217962, Final Batch Loss: 3.5678251151693985e-05\n",
      "Epoch 838, Loss: 0.02157085732324049, Final Batch Loss: 0.005639180541038513\n",
      "Epoch 839, Loss: 0.016484299514559098, Final Batch Loss: 7.098047353792936e-05\n",
      "Epoch 840, Loss: 0.013683775352546945, Final Batch Loss: 0.0003897904243785888\n",
      "Epoch 841, Loss: 0.003974171910158475, Final Batch Loss: 8.054865247686394e-06\n",
      "Epoch 842, Loss: 0.005299735923472326, Final Batch Loss: 0.00010071589349536225\n",
      "Epoch 843, Loss: 0.00496344652492553, Final Batch Loss: 0.0002204515039920807\n",
      "Epoch 844, Loss: 0.009799018752801203, Final Batch Loss: 4.819379228138132e-06\n",
      "Epoch 845, Loss: 0.005140360910445452, Final Batch Loss: 0.0007635470828972757\n",
      "Epoch 846, Loss: 0.00878758194448892, Final Batch Loss: 0.0002256855514133349\n",
      "Epoch 847, Loss: 0.008187571625967394, Final Batch Loss: 1.0166635547648184e-05\n",
      "Epoch 848, Loss: 0.026908792438916862, Final Batch Loss: 0.0019615893252193928\n",
      "Epoch 849, Loss: 0.028506561586254975, Final Batch Loss: 5.441254688776098e-05\n",
      "Epoch 850, Loss: 0.00860354898031801, Final Batch Loss: 0.001315823057666421\n",
      "Epoch 851, Loss: 0.00987089506816119, Final Batch Loss: 0.00404347013682127\n",
      "Epoch 852, Loss: 0.01155015267431736, Final Batch Loss: 0.0006600795313715935\n",
      "Epoch 853, Loss: 0.005179396859603003, Final Batch Loss: 0.0003668589342851192\n",
      "Epoch 854, Loss: 0.011079253410571255, Final Batch Loss: 6.984588981140405e-05\n",
      "Epoch 855, Loss: 0.006430253240978345, Final Batch Loss: 0.00014251642278395593\n",
      "Epoch 856, Loss: 0.011689871840644628, Final Batch Loss: 0.0008681900799274445\n",
      "Epoch 857, Loss: 0.010405676985101309, Final Batch Loss: 9.970648534363136e-05\n",
      "Epoch 858, Loss: 0.007061702926876023, Final Batch Loss: 0.00035795176518149674\n",
      "Epoch 859, Loss: 0.005930464583798312, Final Batch Loss: 0.00017638235294725746\n",
      "Epoch 860, Loss: 0.03447572642471641, Final Batch Loss: 0.0009996198350563645\n",
      "Epoch 861, Loss: 0.010413656382297631, Final Batch Loss: 5.2578245231416076e-05\n",
      "Epoch 862, Loss: 0.009763082787685562, Final Batch Loss: 4.722213634522632e-05\n",
      "Epoch 863, Loss: 0.0035589362705650274, Final Batch Loss: 1.8970491510117427e-05\n",
      "Epoch 864, Loss: 0.00803528557298705, Final Batch Loss: 5.915798828937113e-05\n",
      "Epoch 865, Loss: 0.016554719238229154, Final Batch Loss: 1.1724762771336827e-05\n",
      "Epoch 866, Loss: 0.03260122233768925, Final Batch Loss: 0.0018391319317743182\n",
      "Epoch 867, Loss: 0.04153353243600577, Final Batch Loss: 0.005238145124167204\n",
      "Epoch 868, Loss: 0.01718673091454548, Final Batch Loss: 4.1758456063689664e-05\n",
      "Epoch 869, Loss: 0.004133722890401259, Final Batch Loss: 0.0005085386801511049\n",
      "Epoch 870, Loss: 0.004379679565317929, Final Batch Loss: 0.0005713941645808518\n",
      "Epoch 871, Loss: 0.023549778969027102, Final Batch Loss: 0.0006560851470567286\n",
      "Epoch 872, Loss: 0.009824692824622616, Final Batch Loss: 0.00024943615426309407\n",
      "Epoch 873, Loss: 0.027394384391300264, Final Batch Loss: 2.6095845896634273e-05\n",
      "Epoch 874, Loss: 0.007063898490741849, Final Batch Loss: 0.0021496941335499287\n",
      "Epoch 875, Loss: 0.016615510470728623, Final Batch Loss: 4.953823008690961e-05\n",
      "Epoch 876, Loss: 0.017181895178509876, Final Batch Loss: 0.00021122637554071844\n",
      "Epoch 877, Loss: 0.017726165999192744, Final Batch Loss: 0.0011376881739124656\n",
      "Epoch 878, Loss: 0.004042116168420762, Final Batch Loss: 0.00025225465651601553\n",
      "Epoch 879, Loss: 0.0038668126362608746, Final Batch Loss: 0.00014801973884459585\n",
      "Epoch 880, Loss: 0.00927379506174475, Final Batch Loss: 0.002578764921054244\n",
      "Epoch 881, Loss: 0.007039474148768932, Final Batch Loss: 0.0015199767658486962\n",
      "Epoch 882, Loss: 0.007972515508299693, Final Batch Loss: 1.9497732864692807e-05\n",
      "Epoch 883, Loss: 0.014073382131755352, Final Batch Loss: 0.000991174252703786\n",
      "Epoch 884, Loss: 0.003923857650875107, Final Batch Loss: 1.6178317991943914e-06\n",
      "Epoch 885, Loss: 0.021595472724584397, Final Batch Loss: 0.0001192516865557991\n",
      "Epoch 886, Loss: 0.006521384493680671, Final Batch Loss: 4.110592999495566e-05\n",
      "Epoch 887, Loss: 0.01014241408847738, Final Batch Loss: 0.00021655474847648293\n",
      "Epoch 888, Loss: 0.005134232254931703, Final Batch Loss: 1.9226135918870568e-05\n",
      "Epoch 889, Loss: 0.022801943181548268, Final Batch Loss: 0.0004949911381118\n",
      "Epoch 890, Loss: 0.005771255338913761, Final Batch Loss: 0.000122837649541907\n",
      "Epoch 891, Loss: 0.006472672044765204, Final Batch Loss: 0.000476965622510761\n",
      "Epoch 892, Loss: 0.03378978656837717, Final Batch Loss: 0.006968281231820583\n",
      "Epoch 893, Loss: 0.006854883900814457, Final Batch Loss: 1.56414280354511e-05\n",
      "Epoch 894, Loss: 0.011702569347107783, Final Batch Loss: 0.0010921017965301871\n",
      "Epoch 895, Loss: 0.02854835518519394, Final Batch Loss: 0.0009095282875932753\n",
      "Epoch 896, Loss: 0.0064048790954984725, Final Batch Loss: 0.0012037726119160652\n",
      "Epoch 897, Loss: 0.008581132303334016, Final Batch Loss: 1.383563630952267e-05\n",
      "Epoch 898, Loss: 0.005596941532218125, Final Batch Loss: 3.235678889268456e-07\n",
      "Epoch 899, Loss: 0.011007924596924568, Final Batch Loss: 3.912291504093446e-05\n",
      "Epoch 900, Loss: 0.008927046146709472, Final Batch Loss: 0.0007834662683308125\n",
      "Epoch 901, Loss: 0.029993058655236382, Final Batch Loss: 0.00011731711128959432\n",
      "Epoch 902, Loss: 0.006940169259905815, Final Batch Loss: 0.0006905287737026811\n",
      "Epoch 903, Loss: 0.011840016726637259, Final Batch Loss: 0.00033172903931699693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904, Loss: 0.11639203480444849, Final Batch Loss: 0.11128922551870346\n",
      "Epoch 905, Loss: 0.09329607873223722, Final Batch Loss: 0.030627544969320297\n",
      "Epoch 906, Loss: 0.2066130168568634, Final Batch Loss: 6.300939276115969e-06\n",
      "Epoch 907, Loss: 0.38850156776607037, Final Batch Loss: 0.3079126477241516\n",
      "Epoch 908, Loss: 0.07540744575635472, Final Batch Loss: 1.7054006093530916e-05\n",
      "Epoch 909, Loss: 0.0754019337327918, Final Batch Loss: 0.0001514603936811909\n",
      "Epoch 910, Loss: 0.10124046934652142, Final Batch Loss: 0.0002415172930341214\n",
      "Epoch 911, Loss: 0.04075257774093188, Final Batch Loss: 0.00034796461113728583\n",
      "Epoch 912, Loss: 0.060444796457886696, Final Batch Loss: 0.001781717175617814\n",
      "Epoch 913, Loss: 0.035712061217054725, Final Batch Loss: 0.0012865522876381874\n",
      "Epoch 914, Loss: 0.009828416135860607, Final Batch Loss: 0.00041547566070221364\n",
      "Epoch 915, Loss: 0.01639881543815136, Final Batch Loss: 0.0003994647413492203\n",
      "Epoch 916, Loss: 0.030653028486995026, Final Batch Loss: 0.00039282263605855405\n",
      "Epoch 917, Loss: 0.015756574517581612, Final Batch Loss: 0.0008667477522976696\n",
      "Epoch 918, Loss: 0.011443147959653288, Final Batch Loss: 0.002282800618559122\n",
      "Epoch 919, Loss: 0.02302459313068539, Final Batch Loss: 0.0012281766394153237\n",
      "Epoch 920, Loss: 0.03486549039371312, Final Batch Loss: 0.004044462461024523\n",
      "Epoch 921, Loss: 0.009953290864359587, Final Batch Loss: 0.0005727653042413294\n",
      "Epoch 922, Loss: 0.02275092212948948, Final Batch Loss: 0.0063360026106238365\n",
      "Epoch 923, Loss: 0.011178095825016499, Final Batch Loss: 0.001280126511119306\n",
      "Epoch 924, Loss: 0.011501107132062316, Final Batch Loss: 0.0007017116295173764\n",
      "Epoch 925, Loss: 0.04881898935127538, Final Batch Loss: 0.00014678148727398366\n",
      "Epoch 926, Loss: 0.009442881331779063, Final Batch Loss: 0.0024338525254279375\n",
      "Epoch 927, Loss: 0.006528003419589368, Final Batch Loss: 1.1877900760737248e-05\n",
      "Epoch 928, Loss: 0.013859624086762778, Final Batch Loss: 0.0001673320512054488\n",
      "Epoch 929, Loss: 0.006222362106200308, Final Batch Loss: 0.0005642902106046677\n",
      "Epoch 930, Loss: 0.03856416029157117, Final Batch Loss: 0.0008785537211224437\n",
      "Epoch 931, Loss: 0.010415085271233693, Final Batch Loss: 0.0003477884747553617\n",
      "Epoch 932, Loss: 0.013747962075285614, Final Batch Loss: 0.0006151801208034158\n",
      "Epoch 933, Loss: 0.024974240688607097, Final Batch Loss: 0.0002317456528544426\n",
      "Epoch 934, Loss: 0.016458701516967267, Final Batch Loss: 0.0004247996839694679\n",
      "Epoch 935, Loss: 0.007419813598971814, Final Batch Loss: 0.0009660856449045241\n",
      "Epoch 936, Loss: 0.015870289411395788, Final Batch Loss: 0.0004310577642172575\n",
      "Epoch 937, Loss: 0.013691797372302972, Final Batch Loss: 0.00015526950301136822\n",
      "Epoch 938, Loss: 0.015034553391387817, Final Batch Loss: 1.6263513771264115e-06\n",
      "Epoch 939, Loss: 0.012465959414839745, Final Batch Loss: 0.004689601715654135\n",
      "Epoch 940, Loss: 0.02972851423692191, Final Batch Loss: 4.914167948300019e-05\n",
      "Epoch 941, Loss: 0.005117601665915572, Final Batch Loss: 1.7155669411295094e-05\n",
      "Epoch 942, Loss: 0.006813529776991345, Final Batch Loss: 0.00015408599574584514\n",
      "Epoch 943, Loss: 0.010313483871868812, Final Batch Loss: 6.30796275800094e-05\n",
      "Epoch 944, Loss: 0.007969144254275307, Final Batch Loss: 1.5198706933006179e-05\n",
      "Epoch 945, Loss: 0.0049960066680796444, Final Batch Loss: 0.0007082517258822918\n",
      "Epoch 946, Loss: 0.02455980281229131, Final Batch Loss: 0.00018215921591036022\n",
      "Epoch 947, Loss: 0.007054370069454308, Final Batch Loss: 2.9660934160347097e-05\n",
      "Epoch 948, Loss: 0.034589357557706535, Final Batch Loss: 0.00030940218130126595\n",
      "Epoch 949, Loss: 0.01160209981026128, Final Batch Loss: 0.006142767611891031\n",
      "Epoch 950, Loss: 0.012443140149116516, Final Batch Loss: 0.002026553964242339\n",
      "Epoch 951, Loss: 0.007339872885495424, Final Batch Loss: 0.0012551918625831604\n",
      "Epoch 952, Loss: 0.022736495302524418, Final Batch Loss: 0.0007583454134874046\n",
      "Epoch 953, Loss: 0.026977698842529207, Final Batch Loss: 0.019806131720542908\n",
      "Epoch 954, Loss: 0.01746583211934194, Final Batch Loss: 0.008641280233860016\n",
      "Epoch 955, Loss: 0.010177886477322318, Final Batch Loss: 0.00020722871704492718\n",
      "Epoch 956, Loss: 0.030182817703462206, Final Batch Loss: 0.0001679521956248209\n",
      "Epoch 957, Loss: 0.00348367684182449, Final Batch Loss: 1.3734296771872323e-05\n",
      "Epoch 958, Loss: 0.02711623185314238, Final Batch Loss: 0.0045711868442595005\n",
      "Epoch 959, Loss: 0.008973868960310938, Final Batch Loss: 4.069488568347879e-05\n",
      "Epoch 960, Loss: 0.021647784276865423, Final Batch Loss: 0.0018498405115678906\n",
      "Epoch 961, Loss: 0.004049872879477334, Final Batch Loss: 2.9851611543563195e-05\n",
      "Epoch 962, Loss: 0.002512926992494613, Final Batch Loss: 0.00012445187894627452\n",
      "Epoch 963, Loss: 0.011562309344299138, Final Batch Loss: 0.0014304786454886198\n",
      "Epoch 964, Loss: 0.009248141519492492, Final Batch Loss: 0.0007688606274314225\n",
      "Epoch 965, Loss: 0.01454882692269166, Final Batch Loss: 3.7024747143732384e-05\n",
      "Epoch 966, Loss: 0.02420575311407447, Final Batch Loss: 0.005065604578703642\n",
      "Epoch 967, Loss: 0.006731476227287203, Final Batch Loss: 0.00032325665233656764\n",
      "Epoch 968, Loss: 0.003437946375925094, Final Batch Loss: 0.0005827229470014572\n",
      "Epoch 969, Loss: 0.0104231191216968, Final Batch Loss: 0.00016011492698453367\n",
      "Epoch 970, Loss: 0.01494505666596524, Final Batch Loss: 1.3938521078671329e-05\n",
      "Epoch 971, Loss: 0.02008868008852005, Final Batch Loss: 0.004960798658430576\n",
      "Epoch 972, Loss: 0.010810078391841671, Final Batch Loss: 9.809075891098473e-06\n",
      "Epoch 973, Loss: 0.01164875051472336, Final Batch Loss: 0.0012569873360916972\n",
      "Epoch 974, Loss: 0.019830767458188348, Final Batch Loss: 0.00017677094729151577\n",
      "Epoch 975, Loss: 0.03006027263472788, Final Batch Loss: 0.0002580700966063887\n",
      "Epoch 976, Loss: 0.008693268442584667, Final Batch Loss: 3.380919952178374e-05\n",
      "Epoch 977, Loss: 0.011728595884051174, Final Batch Loss: 0.0006708036526106298\n",
      "Epoch 978, Loss: 0.004508151418121997, Final Batch Loss: 5.629668157780543e-05\n",
      "Epoch 979, Loss: 0.00395357502202387, Final Batch Loss: 5.3140753152547404e-05\n",
      "Epoch 980, Loss: 0.01329463794536423, Final Batch Loss: 0.00016571786545682698\n",
      "Epoch 981, Loss: 0.014330011523270514, Final Batch Loss: 0.00011686301877489313\n",
      "Epoch 982, Loss: 0.007169375880039297, Final Batch Loss: 0.00022149788856040686\n",
      "Epoch 983, Loss: 0.023488966638979036, Final Batch Loss: 6.885609036544338e-05\n",
      "Epoch 984, Loss: 0.003511646995320916, Final Batch Loss: 0.00030101099400781095\n",
      "Epoch 985, Loss: 0.007231772484374233, Final Batch Loss: 0.0001867456448962912\n",
      "Epoch 986, Loss: 0.018474940356099978, Final Batch Loss: 0.0003866402548737824\n",
      "Epoch 987, Loss: 0.02007368256454356, Final Batch Loss: 0.0015851324424147606\n",
      "Epoch 988, Loss: 0.011388113751308993, Final Batch Loss: 0.00042924334411509335\n",
      "Epoch 989, Loss: 0.022927571044419892, Final Batch Loss: 0.0002302998909726739\n",
      "Epoch 990, Loss: 0.0038362369159585796, Final Batch Loss: 7.52452397136949e-05\n",
      "Epoch 991, Loss: 0.007408590800878301, Final Batch Loss: 1.0225851838185918e-05\n",
      "Epoch 992, Loss: 0.031327326206564976, Final Batch Loss: 2.8779970762116136e-06\n",
      "Epoch 993, Loss: 0.006593925761990249, Final Batch Loss: 0.0013099011266604066\n",
      "Epoch 994, Loss: 0.004403377604830894, Final Batch Loss: 2.631086317705922e-06\n",
      "Epoch 995, Loss: 0.022160708205774426, Final Batch Loss: 0.016946768388152122\n",
      "Epoch 996, Loss: 0.008061885368078947, Final Batch Loss: 0.00233737425878644\n",
      "Epoch 997, Loss: 0.029193884371125023, Final Batch Loss: 1.8740332961897366e-05\n",
      "Epoch 998, Loss: 0.004805601667612791, Final Batch Loss: 2.4527471396140754e-05\n",
      "Epoch 999, Loss: 0.005337323033018038, Final Batch Loss: 0.00022522322251461446\n",
      "Epoch 1000, Loss: 0.00548026041360572, Final Batch Loss: 0.0011088975006714463\n",
      "Epoch 1001, Loss: 0.014133526587102097, Final Batch Loss: 1.3639677490573376e-05\n",
      "Epoch 1002, Loss: 0.010646365786669776, Final Batch Loss: 0.0004300831933505833\n",
      "Epoch 1003, Loss: 0.3130001386452932, Final Batch Loss: 0.3006357252597809\n",
      "Epoch 1004, Loss: 0.05945526594950934, Final Batch Loss: 2.2655749489786103e-05\n",
      "Epoch 1005, Loss: 0.1520019380550366, Final Batch Loss: 0.000325272063491866\n",
      "Epoch 1006, Loss: 0.12376116323866881, Final Batch Loss: 0.0002606950292829424\n",
      "Epoch 1007, Loss: 0.018488974950741976, Final Batch Loss: 0.0005669669480994344\n",
      "Epoch 1008, Loss: 0.020612713822629303, Final Batch Loss: 0.00117585901170969\n",
      "Epoch 1009, Loss: 0.044347712537273765, Final Batch Loss: 0.000398527889046818\n",
      "Epoch 1010, Loss: 0.039618947957933415, Final Batch Loss: 4.313950921641663e-05\n",
      "Epoch 1011, Loss: 0.02862832200480625, Final Batch Loss: 0.001013356726616621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1012, Loss: 0.009206402974086814, Final Batch Loss: 0.00016956664330791682\n",
      "Epoch 1013, Loss: 0.01215508426685119, Final Batch Loss: 7.038602052489296e-05\n",
      "Epoch 1014, Loss: 0.011685749268508516, Final Batch Loss: 6.76282070344314e-05\n",
      "Epoch 1015, Loss: 0.0053501157817663625, Final Batch Loss: 0.00018114114936906844\n",
      "Epoch 1016, Loss: 0.010521697971853428, Final Batch Loss: 0.00020426527771633118\n",
      "Epoch 1017, Loss: 0.007978852147061843, Final Batch Loss: 0.00010959152859868482\n",
      "Epoch 1018, Loss: 0.00826062262058258, Final Batch Loss: 0.0022916793823242188\n",
      "Epoch 1019, Loss: 0.007688859244808555, Final Batch Loss: 0.0010256202658638358\n",
      "Epoch 1020, Loss: 0.009432762308279052, Final Batch Loss: 0.000354141608113423\n",
      "Epoch 1021, Loss: 0.010416709817945957, Final Batch Loss: 0.0003200571518391371\n",
      "Epoch 1022, Loss: 0.00822516018524766, Final Batch Loss: 0.0011471736943349242\n",
      "Epoch 1023, Loss: 0.009490188211202621, Final Batch Loss: 0.0010892439167946577\n",
      "Epoch 1024, Loss: 0.004816259490326047, Final Batch Loss: 0.0005364994867704809\n",
      "Epoch 1025, Loss: 0.020413109101355076, Final Batch Loss: 0.00034130195854231715\n",
      "Epoch 1026, Loss: 0.005260123893094715, Final Batch Loss: 7.050480780890211e-05\n",
      "Epoch 1027, Loss: 0.0074553900958562735, Final Batch Loss: 3.408283009775914e-05\n",
      "Epoch 1028, Loss: 0.013218083273386583, Final Batch Loss: 0.00039683477370999753\n",
      "Epoch 1029, Loss: 0.009945429970684927, Final Batch Loss: 1.4901088434271514e-06\n",
      "Epoch 1030, Loss: 0.007515169039834291, Final Batch Loss: 0.0006140785408206284\n",
      "Epoch 1031, Loss: 0.007992119684786303, Final Batch Loss: 3.3810018067015335e-05\n",
      "Epoch 1032, Loss: 0.007113329949788749, Final Batch Loss: 6.036949343979359e-06\n",
      "Epoch 1033, Loss: 0.0048585174372419715, Final Batch Loss: 0.0005809189169667661\n",
      "Epoch 1034, Loss: 0.0040701917168917134, Final Batch Loss: 1.5410842024721205e-05\n",
      "Epoch 1035, Loss: 0.017669056065642508, Final Batch Loss: 1.7590926290722564e-05\n",
      "Epoch 1036, Loss: 0.0890857450576732, Final Batch Loss: 0.08439987897872925\n",
      "Epoch 1037, Loss: 0.06330322999338023, Final Batch Loss: 5.568680990108987e-06\n",
      "Epoch 1038, Loss: 0.17886003491003066, Final Batch Loss: 0.000274909776635468\n",
      "Epoch 1039, Loss: 0.07006878033280373, Final Batch Loss: 0.0016048823017627\n",
      "Epoch 1040, Loss: 0.023919425904750824, Final Batch Loss: 0.0024404353462159634\n",
      "Epoch 1041, Loss: 0.01428452495019883, Final Batch Loss: 0.0010017635067924857\n",
      "Epoch 1042, Loss: 0.035467023801174946, Final Batch Loss: 0.0001232531649293378\n",
      "Epoch 1043, Loss: 0.041266276966780424, Final Batch Loss: 0.0010492794681340456\n",
      "Epoch 1044, Loss: 0.01072475813998608, Final Batch Loss: 9.108130325330421e-05\n",
      "Epoch 1045, Loss: 0.008411249473283533, Final Batch Loss: 8.38582418509759e-05\n",
      "Epoch 1046, Loss: 0.027329901848133886, Final Batch Loss: 4.476160756894387e-05\n",
      "Epoch 1047, Loss: 0.021722678560763597, Final Batch Loss: 0.003688722150400281\n",
      "Epoch 1048, Loss: 0.0071764871827326715, Final Batch Loss: 0.0005191747914068401\n",
      "Epoch 1049, Loss: 0.01450434175785631, Final Batch Loss: 0.0010919783962890506\n",
      "Epoch 1050, Loss: 0.028987323348701466, Final Batch Loss: 9.865657921181992e-05\n",
      "Epoch 1051, Loss: 0.010615567429340445, Final Batch Loss: 0.00022238575911615044\n",
      "Epoch 1052, Loss: 0.006505537610792089, Final Batch Loss: 7.041737262625247e-06\n",
      "Epoch 1053, Loss: 0.012166825239546597, Final Batch Loss: 0.000850669399369508\n",
      "Epoch 1054, Loss: 0.014127342845313251, Final Batch Loss: 0.010643407702445984\n",
      "Epoch 1055, Loss: 0.010347763903837404, Final Batch Loss: 2.3415902887791162e-06\n",
      "Epoch 1056, Loss: 0.014828810381004587, Final Batch Loss: 0.00011131970677524805\n",
      "Epoch 1057, Loss: 0.008353184675115699, Final Batch Loss: 4.1723183130670805e-07\n",
      "Epoch 1058, Loss: 0.00705881422618404, Final Batch Loss: 0.0008511623018421233\n",
      "Epoch 1059, Loss: 0.0036348723515402526, Final Batch Loss: 2.9802031349390745e-06\n",
      "Epoch 1060, Loss: 0.0059368436377553735, Final Batch Loss: 3.782735802815296e-05\n",
      "Epoch 1061, Loss: 0.004343296372098848, Final Batch Loss: 0.00032221744186244905\n",
      "Epoch 1062, Loss: 0.011022100690752268, Final Batch Loss: 0.0015274633187800646\n",
      "Epoch 1063, Loss: 0.018261448887642473, Final Batch Loss: 0.0013481738278642297\n",
      "Epoch 1064, Loss: 0.0065981416701106355, Final Batch Loss: 7.73188512539491e-05\n",
      "Epoch 1065, Loss: 0.0069818841584492475, Final Batch Loss: 0.00025176789495162666\n",
      "Epoch 1066, Loss: 0.041636380017735064, Final Batch Loss: 0.03798088803887367\n",
      "Epoch 1067, Loss: 0.03315249131992459, Final Batch Loss: 0.023825248703360558\n",
      "Epoch 1068, Loss: 0.052787768871098706, Final Batch Loss: 1.9073323755947058e-06\n",
      "Epoch 1069, Loss: 0.03322940142243169, Final Batch Loss: 0.00013118083006702363\n",
      "Epoch 1070, Loss: 0.012910189223475754, Final Batch Loss: 0.0017856957856565714\n",
      "Epoch 1071, Loss: 0.010777949530165642, Final Batch Loss: 0.0030960682779550552\n",
      "Epoch 1072, Loss: 0.012448880646843463, Final Batch Loss: 9.290751768276095e-05\n",
      "Epoch 1073, Loss: 0.004797751697878994, Final Batch Loss: 1.2030944162688684e-05\n",
      "Epoch 1074, Loss: 0.005354175947331896, Final Batch Loss: 3.4229808534291806e-06\n",
      "Epoch 1075, Loss: 0.008968033202108927, Final Batch Loss: 0.00023220946604851633\n",
      "Epoch 1076, Loss: 0.00549010033137165, Final Batch Loss: 0.0003316056390758604\n",
      "Epoch 1077, Loss: 0.008803833115962334, Final Batch Loss: 0.0001578088995302096\n",
      "Epoch 1078, Loss: 0.009026810264913365, Final Batch Loss: 0.0005516036180779338\n",
      "Epoch 1079, Loss: 0.011917589541553752, Final Batch Loss: 2.7175254217581823e-05\n",
      "Epoch 1080, Loss: 0.014306936238426715, Final Batch Loss: 0.0008428911096416414\n",
      "Epoch 1081, Loss: 0.009148642551735975, Final Batch Loss: 0.00018025936151389033\n",
      "Epoch 1082, Loss: 0.01470089932990959, Final Batch Loss: 8.005843119462952e-05\n",
      "Epoch 1083, Loss: 0.015954048343701288, Final Batch Loss: 0.00021516907145269215\n",
      "Epoch 1084, Loss: 0.012372921482892707, Final Batch Loss: 0.0006331544718705118\n",
      "Epoch 1085, Loss: 0.017860990279586986, Final Batch Loss: 0.007513771299272776\n",
      "Epoch 1086, Loss: 0.009787239716388285, Final Batch Loss: 0.005073457956314087\n",
      "Epoch 1087, Loss: 0.00590316005400382, Final Batch Loss: 0.00034390229848213494\n",
      "Epoch 1088, Loss: 0.004589223608491011, Final Batch Loss: 1.374278508592397e-05\n",
      "Epoch 1089, Loss: 0.010086532158311456, Final Batch Loss: 0.0014609592035412788\n",
      "Epoch 1090, Loss: 0.003794891006691614, Final Batch Loss: 3.507855944917537e-05\n",
      "Epoch 1091, Loss: 0.005587705614743754, Final Batch Loss: 0.0003416831896174699\n",
      "Epoch 1092, Loss: 0.011865114982356317, Final Batch Loss: 9.862527076620609e-05\n",
      "Epoch 1093, Loss: 0.009669141690210381, Final Batch Loss: 1.3257135833555367e-05\n",
      "Epoch 1094, Loss: 0.004590989239659393, Final Batch Loss: 3.9311857108259574e-05\n",
      "Epoch 1095, Loss: 0.005557024775043828, Final Batch Loss: 5.97585276409518e-05\n",
      "Epoch 1096, Loss: 0.00979846008704044, Final Batch Loss: 0.00026785137015394866\n",
      "Epoch 1097, Loss: 0.007482711094780825, Final Batch Loss: 9.088787192013115e-05\n",
      "Epoch 1098, Loss: 0.01817547153518717, Final Batch Loss: 1.1750573776225792e-06\n",
      "Epoch 1099, Loss: 0.004803866611837293, Final Batch Loss: 1.9139055439154617e-05\n",
      "Epoch 1100, Loss: 0.008950495554017834, Final Batch Loss: 0.00019976157636847347\n",
      "Epoch 1101, Loss: 0.010901372064836323, Final Batch Loss: 0.0012060280423611403\n",
      "Epoch 1102, Loss: 0.005294766649967642, Final Batch Loss: 2.6682619136408903e-05\n",
      "Epoch 1103, Loss: 0.024951527593657374, Final Batch Loss: 0.0005351086147129536\n",
      "Epoch 1104, Loss: 0.00790363680334849, Final Batch Loss: 1.298498591495445e-05\n",
      "Epoch 1105, Loss: 0.037698570638895035, Final Batch Loss: 0.00026311635156162083\n",
      "Epoch 1106, Loss: 0.00787474584649317, Final Batch Loss: 0.00046054626000113785\n",
      "Epoch 1107, Loss: 0.00440176344432075, Final Batch Loss: 2.222377361249528e-06\n",
      "Epoch 1108, Loss: 0.01525324085378088, Final Batch Loss: 0.00033589478698559105\n",
      "Epoch 1109, Loss: 0.0065543935634195805, Final Batch Loss: 0.0006186325917951763\n",
      "Epoch 1110, Loss: 0.012398925726301968, Final Batch Loss: 0.0035925875417888165\n",
      "Epoch 1111, Loss: 0.008747828473133268, Final Batch Loss: 4.703841477748938e-05\n",
      "Epoch 1112, Loss: 0.00843750685453415, Final Batch Loss: 0.004301972221583128\n",
      "Epoch 1113, Loss: 0.005168969189980999, Final Batch Loss: 0.00025455819559283555\n",
      "Epoch 1114, Loss: 0.011928335748962127, Final Batch Loss: 0.0001737382699502632\n",
      "Epoch 1115, Loss: 0.004872265795711428, Final Batch Loss: 0.00019420069293119013\n",
      "Epoch 1116, Loss: 0.002778684822260402, Final Batch Loss: 0.00014789596025366336\n",
      "Epoch 1117, Loss: 0.021378125733463094, Final Batch Loss: 0.01424245536327362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118, Loss: 0.00398267369291716, Final Batch Loss: 9.017009688250255e-06\n",
      "Epoch 1119, Loss: 0.003105954622697027, Final Batch Loss: 8.32745627121767e-06\n",
      "Epoch 1120, Loss: 0.03612823033472523, Final Batch Loss: 0.026615964248776436\n",
      "Epoch 1121, Loss: 0.003648514859378338, Final Batch Loss: 0.0007868538377806544\n",
      "Epoch 1122, Loss: 0.013503757043508813, Final Batch Loss: 0.00025043796631507576\n",
      "Epoch 1123, Loss: 0.002584254354587756, Final Batch Loss: 8.538003021385521e-05\n",
      "Epoch 1124, Loss: 0.008069213377893902, Final Batch Loss: 0.004857798106968403\n",
      "Epoch 1125, Loss: 0.0019816160383925308, Final Batch Loss: 4.084910688106902e-05\n",
      "Epoch 1126, Loss: 0.003246356704039499, Final Batch Loss: 0.00012250053987372667\n",
      "Epoch 1127, Loss: 0.004824540235404129, Final Batch Loss: 4.4276889639149886e-06\n",
      "Epoch 1128, Loss: 0.007416958253088524, Final Batch Loss: 2.6596915631671436e-05\n",
      "Epoch 1129, Loss: 0.0033335930902467226, Final Batch Loss: 1.2047658856317867e-05\n",
      "Epoch 1130, Loss: 0.00137407603142492, Final Batch Loss: 1.606612750038039e-05\n",
      "Epoch 1131, Loss: 0.043824789056088775, Final Batch Loss: 0.04040348157286644\n",
      "Epoch 1132, Loss: 0.0054087203679955564, Final Batch Loss: 5.546703323489055e-05\n",
      "Epoch 1133, Loss: 0.0029741776234004647, Final Batch Loss: 0.0004895263118669391\n",
      "Epoch 1134, Loss: 0.03682765905978158, Final Batch Loss: 0.0003048546495847404\n",
      "Epoch 1135, Loss: 0.014892988323481404, Final Batch Loss: 2.7370473617338575e-05\n",
      "Epoch 1136, Loss: 0.018185587599873543, Final Batch Loss: 0.0010078448103740811\n",
      "Epoch 1137, Loss: 0.006921132444404066, Final Batch Loss: 0.0009095620480366051\n",
      "Epoch 1138, Loss: 0.0039002089761197567, Final Batch Loss: 0.0002933577634394169\n",
      "Epoch 1139, Loss: 0.0021736712769779842, Final Batch Loss: 3.925169221474789e-05\n",
      "Epoch 1140, Loss: 0.026550777969532646, Final Batch Loss: 1.672141661401838e-05\n",
      "Epoch 1141, Loss: 0.0022441216788138263, Final Batch Loss: 7.407785597024485e-05\n",
      "Epoch 1142, Loss: 0.002791740116663277, Final Batch Loss: 0.0003031762898899615\n",
      "Epoch 1143, Loss: 0.008192191680791439, Final Batch Loss: 8.361379514099099e-06\n",
      "Epoch 1144, Loss: 0.009571397953550331, Final Batch Loss: 0.0038831799756735563\n",
      "Epoch 1145, Loss: 0.005678845410614031, Final Batch Loss: 9.196094765684393e-07\n",
      "Epoch 1146, Loss: 0.004394879360916093, Final Batch Loss: 0.003419082146137953\n",
      "Epoch 1147, Loss: 0.0010198003974437597, Final Batch Loss: 1.4900676433171611e-05\n",
      "Epoch 1148, Loss: 0.001888549650175264, Final Batch Loss: 2.1463387383846566e-05\n",
      "Epoch 1149, Loss: 0.005900088784983382, Final Batch Loss: 0.000683790014591068\n",
      "Epoch 1150, Loss: 0.0029442264130921103, Final Batch Loss: 5.242479528533295e-05\n",
      "Epoch 1151, Loss: 0.022482130538264755, Final Batch Loss: 6.54441028018482e-05\n",
      "Epoch 1152, Loss: 0.007363323886238504, Final Batch Loss: 0.00010916282917605713\n",
      "Epoch 1153, Loss: 0.008313506077683996, Final Batch Loss: 7.38770977477543e-05\n",
      "Epoch 1154, Loss: 0.007646283182111802, Final Batch Loss: 2.8283091523917392e-05\n",
      "Epoch 1155, Loss: 0.010508266488614026, Final Batch Loss: 6.869759090477601e-05\n",
      "Epoch 1156, Loss: 0.003850889639579691, Final Batch Loss: 0.0009965312201529741\n",
      "Epoch 1157, Loss: 0.003409265249501914, Final Batch Loss: 0.0005440804525278509\n",
      "Epoch 1158, Loss: 0.006338199904348585, Final Batch Loss: 2.3387065084534697e-05\n",
      "Epoch 1159, Loss: 0.002138657058821991, Final Batch Loss: 0.0002762114454526454\n",
      "Epoch 1160, Loss: 0.015724525545010692, Final Batch Loss: 1.7624746760702692e-05\n",
      "Epoch 1161, Loss: 0.01171757000429352, Final Batch Loss: 1.0600405403238256e-05\n",
      "Epoch 1162, Loss: 0.00477955265523633, Final Batch Loss: 0.000226453339564614\n",
      "Epoch 1163, Loss: 0.027659286235575564, Final Batch Loss: 0.00023837039771024138\n",
      "Epoch 1164, Loss: 0.005430104791230406, Final Batch Loss: 1.608393904461991e-05\n",
      "Epoch 1165, Loss: 0.016941764471994247, Final Batch Loss: 9.64080318226479e-05\n",
      "Epoch 1166, Loss: 0.004890906147920759, Final Batch Loss: 2.2807933419244364e-05\n",
      "Epoch 1167, Loss: 0.004391401540488005, Final Batch Loss: 0.0005221480969339609\n",
      "Epoch 1168, Loss: 0.019693881812827385, Final Batch Loss: 1.7455470242566662e-06\n",
      "Epoch 1169, Loss: 0.004151499277213588, Final Batch Loss: 0.00018424192967358977\n",
      "Epoch 1170, Loss: 0.010966669668277973, Final Batch Loss: 2.6736690870166058e-06\n",
      "Epoch 1171, Loss: 0.003647222532890737, Final Batch Loss: 0.0007887901738286018\n",
      "Epoch 1172, Loss: 0.005768632065155543, Final Batch Loss: 0.0005738291656598449\n",
      "Epoch 1173, Loss: 0.0047150228201644495, Final Batch Loss: 2.4962195311672986e-05\n",
      "Epoch 1174, Loss: 0.0038425992825068533, Final Batch Loss: 3.9448816096410155e-05\n",
      "Epoch 1175, Loss: 0.003737755618203664, Final Batch Loss: 3.183077569701709e-05\n",
      "Epoch 1176, Loss: 0.00779516279726522, Final Batch Loss: 0.005153297912329435\n",
      "Epoch 1177, Loss: 0.0039581552482559346, Final Batch Loss: 7.177204679464921e-05\n",
      "Epoch 1178, Loss: 0.002911144845711533, Final Batch Loss: 1.0898838809225708e-05\n",
      "Epoch 1179, Loss: 0.003939952571045069, Final Batch Loss: 2.8524525532702683e-06\n",
      "Epoch 1180, Loss: 0.0018245831452077255, Final Batch Loss: 0.0004294764075893909\n",
      "Epoch 1181, Loss: 0.0016284369512504782, Final Batch Loss: 1.1886378160852473e-05\n",
      "Epoch 1182, Loss: 0.002239902309156605, Final Batch Loss: 2.089420195261482e-05\n",
      "Epoch 1183, Loss: 0.002007623639656231, Final Batch Loss: 1.0839183232747018e-05\n",
      "Epoch 1184, Loss: 0.004242562026604446, Final Batch Loss: 7.578271947750181e-07\n",
      "Epoch 1185, Loss: 0.006207779922988266, Final Batch Loss: 0.00021983729675412178\n",
      "Epoch 1186, Loss: 0.0033786872299970128, Final Batch Loss: 4.061969957547262e-05\n",
      "Epoch 1187, Loss: 0.008741220780393633, Final Batch Loss: 8.293253813462798e-06\n",
      "Epoch 1188, Loss: 0.0025362473579662037, Final Batch Loss: 7.961255505506415e-06\n",
      "Epoch 1189, Loss: 0.020701094370451756, Final Batch Loss: 0.0001765182096278295\n",
      "Epoch 1190, Loss: 0.009845583913374867, Final Batch Loss: 1.1945939149882179e-05\n",
      "Epoch 1191, Loss: 0.004057763882428844, Final Batch Loss: 2.562966528785182e-06\n",
      "Epoch 1192, Loss: 0.021101799697817114, Final Batch Loss: 3.5762120660365326e-06\n",
      "Epoch 1193, Loss: 0.0056274820963153616, Final Batch Loss: 0.0002543750451877713\n",
      "Epoch 1194, Loss: 0.004523392954752126, Final Batch Loss: 1.1409999842726393e-06\n",
      "Epoch 1195, Loss: 0.010419891728247421, Final Batch Loss: 1.3198072110753856e-06\n",
      "Epoch 1196, Loss: 0.005457189694425324, Final Batch Loss: 5.835784031660296e-05\n",
      "Epoch 1197, Loss: 0.05437759030610323, Final Batch Loss: 0.001095026615075767\n",
      "Epoch 1198, Loss: 0.0011407355049897205, Final Batch Loss: 1.7881389169360773e-07\n",
      "Epoch 1199, Loss: 0.021980489342240617, Final Batch Loss: 0.003032530890777707\n",
      "Epoch 1200, Loss: 0.025520913608488627, Final Batch Loss: 0.00379287195391953\n",
      "Epoch 1201, Loss: 0.003285617490405457, Final Batch Loss: 1.1920884617211414e-06\n",
      "Epoch 1202, Loss: 0.00664220691396622, Final Batch Loss: 0.002629390684887767\n",
      "Epoch 1203, Loss: 0.0028330165368970484, Final Batch Loss: 0.00016094170860014856\n",
      "Epoch 1204, Loss: 0.02544983014013269, Final Batch Loss: 9.031485387822613e-05\n",
      "Epoch 1205, Loss: 0.011540410327143036, Final Batch Loss: 6.439669232349843e-05\n",
      "Epoch 1206, Loss: 0.01610935375038025, Final Batch Loss: 5.713318842026638e-06\n",
      "Epoch 1207, Loss: 0.005304149759467691, Final Batch Loss: 0.0004921933286823332\n",
      "Epoch 1208, Loss: 0.0037197167694102973, Final Batch Loss: 0.00026318858726881444\n",
      "Epoch 1209, Loss: 0.004820563991415838, Final Batch Loss: 1.0984231266775168e-06\n",
      "Epoch 1210, Loss: 0.002659475569089409, Final Batch Loss: 4.07544503104873e-05\n",
      "Epoch 1211, Loss: 0.018089630325448525, Final Batch Loss: 1.3546047739509959e-05\n",
      "Epoch 1212, Loss: 0.0022173515462782234, Final Batch Loss: 0.0002726666280068457\n",
      "Epoch 1213, Loss: 0.006051718140952289, Final Batch Loss: 0.00019765563774853945\n",
      "Epoch 1214, Loss: 0.030523156572598964, Final Batch Loss: 0.007323401514440775\n",
      "Epoch 1215, Loss: 0.005972798725451867, Final Batch Loss: 1.3486526768247131e-05\n",
      "Epoch 1216, Loss: 0.0015512065147049725, Final Batch Loss: 0.00017559748084750026\n",
      "Epoch 1217, Loss: 0.001395959735134511, Final Batch Loss: 3.320826067465532e-07\n",
      "Epoch 1218, Loss: 0.0048343666130676866, Final Batch Loss: 0.0007932960870675743\n",
      "Epoch 1219, Loss: 0.02293906379782129, Final Batch Loss: 0.00013732806837651879\n",
      "Epoch 1220, Loss: 0.001828750544518698, Final Batch Loss: 9.864396270131692e-05\n",
      "Epoch 1221, Loss: 0.0035321983450558037, Final Batch Loss: 0.00025958489277400076\n",
      "Epoch 1222, Loss: 0.0025487084640190005, Final Batch Loss: 0.00019310889183543622\n",
      "Epoch 1223, Loss: 0.01868070976343006, Final Batch Loss: 0.011938819661736488\n",
      "Epoch 1224, Loss: 0.0023838659399189055, Final Batch Loss: 0.0005304994410835207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1225, Loss: 0.0058541181297186995, Final Batch Loss: 1.6048996258177795e-05\n",
      "Epoch 1226, Loss: 0.0052493834990627875, Final Batch Loss: 1.2176350310255657e-06\n",
      "Epoch 1227, Loss: 0.0011207521747564897, Final Batch Loss: 1.0464143997523934e-05\n",
      "Epoch 1228, Loss: 0.0030069213644310366, Final Batch Loss: 3.0352366593433544e-05\n",
      "Epoch 1229, Loss: 0.0014192846776950319, Final Batch Loss: 2.3926897938508773e-06\n",
      "Epoch 1230, Loss: 0.0015591078145007486, Final Batch Loss: 1.0847262274182867e-05\n",
      "Epoch 1231, Loss: 0.0027980010854662396, Final Batch Loss: 0.0009757443913258612\n",
      "Epoch 1232, Loss: 0.009905943883495638, Final Batch Loss: 5.5306973081314936e-05\n",
      "Epoch 1233, Loss: 0.0007948832068223055, Final Batch Loss: 1.8051583765554824e-06\n",
      "Epoch 1234, Loss: 0.009083635311981197, Final Batch Loss: 0.003088562050834298\n",
      "Epoch 1235, Loss: 0.0010271943274346995, Final Batch Loss: 1.5053529750730377e-05\n",
      "Epoch 1236, Loss: 0.006484357533622642, Final Batch Loss: 1.8221861637357506e-06\n",
      "Epoch 1237, Loss: 0.002373371084104292, Final Batch Loss: 6.379638944054022e-05\n",
      "Epoch 1238, Loss: 0.0011197555386388558, Final Batch Loss: 4.300013642932754e-06\n",
      "Epoch 1239, Loss: 0.11056402421672828, Final Batch Loss: 0.08384327590465546\n",
      "Epoch 1240, Loss: 0.13992663868702948, Final Batch Loss: 1.1877506040036678e-05\n",
      "Epoch 1241, Loss: 0.41005282423213885, Final Batch Loss: 5.619855301119969e-07\n",
      "Epoch 1242, Loss: 0.15367577990855352, Final Batch Loss: 1.2558802154671866e-05\n",
      "Epoch 1243, Loss: 0.08668106255936436, Final Batch Loss: 0.00025492600980214775\n",
      "Epoch 1244, Loss: 0.07077744793423335, Final Batch Loss: 4.3868825741810724e-05\n",
      "Epoch 1245, Loss: 0.055409155174857005, Final Batch Loss: 0.00046409465721808374\n",
      "Epoch 1246, Loss: 0.020495105622103438, Final Batch Loss: 2.594097168184817e-05\n",
      "Epoch 1247, Loss: 0.023453742323908955, Final Batch Loss: 0.00026186066679656506\n",
      "Epoch 1248, Loss: 0.011982654003077187, Final Batch Loss: 6.495141133200377e-05\n",
      "Epoch 1249, Loss: 0.03077707055126666, Final Batch Loss: 8.702070772415027e-06\n",
      "Epoch 1250, Loss: 0.007459651213139296, Final Batch Loss: 0.001131511409766972\n",
      "Epoch 1251, Loss: 0.007077702146489173, Final Batch Loss: 0.0037212262395769358\n",
      "Epoch 1252, Loss: 0.003936097949917894, Final Batch Loss: 3.5467724956106395e-05\n",
      "Epoch 1253, Loss: 0.0059625572214798694, Final Batch Loss: 1.9584358312840777e-07\n",
      "Epoch 1254, Loss: 0.0034727357215160737, Final Batch Loss: 2.0180250430712476e-06\n",
      "Epoch 1255, Loss: 0.010388001746377995, Final Batch Loss: 5.40679820915102e-06\n",
      "Epoch 1256, Loss: 0.0034116815077140927, Final Batch Loss: 0.0016531154979020357\n",
      "Epoch 1257, Loss: 0.009495182428508997, Final Batch Loss: 3.6541023291647434e-05\n",
      "Epoch 1258, Loss: 0.029378638937487267, Final Batch Loss: 0.001159273786470294\n",
      "Epoch 1259, Loss: 0.0029239468294690596, Final Batch Loss: 1.927551238622982e-05\n",
      "Epoch 1260, Loss: 0.005045315068855416, Final Batch Loss: 0.00011682317563099787\n",
      "Epoch 1261, Loss: 0.02419667789945379, Final Batch Loss: 0.0006359162507578731\n",
      "Epoch 1262, Loss: 0.004782365882419981, Final Batch Loss: 0.00011394360626582056\n",
      "Epoch 1263, Loss: 0.013260110834380612, Final Batch Loss: 0.010771977715194225\n",
      "Epoch 1264, Loss: 0.013230282522272319, Final Batch Loss: 0.0031365409959107637\n",
      "Epoch 1265, Loss: 0.0030552575190085918, Final Batch Loss: 0.0002549952478148043\n",
      "Epoch 1266, Loss: 0.030394086221349426, Final Batch Loss: 0.0001442798675270751\n",
      "Epoch 1267, Loss: 0.007638777606189251, Final Batch Loss: 0.004350222647190094\n",
      "Epoch 1268, Loss: 0.0024633225539218984, Final Batch Loss: 8.880872883310076e-06\n",
      "Epoch 1269, Loss: 0.0030813517387286993, Final Batch Loss: 1.2286300261621363e-05\n",
      "Epoch 1270, Loss: 0.002891120810090797, Final Batch Loss: 5.450989192468114e-05\n",
      "Epoch 1271, Loss: 0.005103385716211051, Final Batch Loss: 0.0023865250404924154\n",
      "Epoch 1272, Loss: 0.002027737618846004, Final Batch Loss: 1.9914457880076952e-05\n",
      "Epoch 1273, Loss: 0.0013713660300709307, Final Batch Loss: 0.00014030086458660662\n",
      "Epoch 1274, Loss: 0.0035259080266314413, Final Batch Loss: 1.4560444014932727e-06\n",
      "Epoch 1275, Loss: 0.024786481225419266, Final Batch Loss: 5.449414857139345e-06\n",
      "Epoch 1276, Loss: 0.003032860686971617, Final Batch Loss: 1.7285262856603367e-06\n",
      "Epoch 1277, Loss: 0.004196003908873536, Final Batch Loss: 0.0001629621401662007\n",
      "Epoch 1278, Loss: 0.0027681466890498996, Final Batch Loss: 0.0005487440503202379\n",
      "Epoch 1279, Loss: 0.0030254385783337057, Final Batch Loss: 0.0005631325184367597\n",
      "Epoch 1280, Loss: 0.0015586967638228089, Final Batch Loss: 0.0002831836754921824\n",
      "Epoch 1281, Loss: 0.0025606841809349135, Final Batch Loss: 0.00014374939200934023\n",
      "Epoch 1282, Loss: 0.004107312735868618, Final Batch Loss: 0.0014464169507846236\n",
      "Epoch 1283, Loss: 0.002292841209055041, Final Batch Loss: 1.629581856832374e-05\n",
      "Epoch 1284, Loss: 0.005161272817531426, Final Batch Loss: 8.999942110676784e-06\n",
      "Epoch 1285, Loss: 0.0033100146383731044, Final Batch Loss: 1.4159390957502183e-05\n",
      "Epoch 1286, Loss: 0.0065279142829837156, Final Batch Loss: 2.2138853239539458e-07\n",
      "Epoch 1287, Loss: 0.003901932272128761, Final Batch Loss: 0.0010143243707716465\n",
      "Epoch 1288, Loss: 0.005216080317040905, Final Batch Loss: 0.00259447586722672\n",
      "Epoch 1289, Loss: 0.0020715459249913692, Final Batch Loss: 0.00014183748862706125\n",
      "Epoch 1290, Loss: 0.012699761340627447, Final Batch Loss: 0.00012263722601346672\n",
      "Epoch 1291, Loss: 0.002500249131117016, Final Batch Loss: 0.00014705664943903685\n",
      "Epoch 1292, Loss: 0.008666101668495685, Final Batch Loss: 0.0006007320480421185\n",
      "Epoch 1293, Loss: 0.0055171598214656115, Final Batch Loss: 0.0007928932318463922\n",
      "Epoch 1294, Loss: 0.011434633605858835, Final Batch Loss: 6.369104994519148e-06\n",
      "Epoch 1295, Loss: 0.0068412747599566615, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 1296, Loss: 0.0040971730049932376, Final Batch Loss: 0.0001806997024687007\n",
      "Epoch 1297, Loss: 0.011422745214076713, Final Batch Loss: 0.0002198782894993201\n",
      "Epoch 1298, Loss: 0.002914613003440536, Final Batch Loss: 3.652828809208586e-06\n",
      "Epoch 1299, Loss: 0.001953927567228675, Final Batch Loss: 0.0003191593277733773\n",
      "Epoch 1300, Loss: 0.005591647219262086, Final Batch Loss: 0.0003434760437812656\n",
      "Epoch 1301, Loss: 0.0018882580552599393, Final Batch Loss: 7.699717389186844e-05\n",
      "Epoch 1302, Loss: 0.0015726152996649034, Final Batch Loss: 3.493812255328521e-05\n",
      "Epoch 1303, Loss: 0.0029654272375410073, Final Batch Loss: 7.918870323919691e-07\n",
      "Epoch 1304, Loss: 0.002052035796623386, Final Batch Loss: 7.17786588211311e-06\n",
      "Epoch 1305, Loss: 0.001958375574758975, Final Batch Loss: 4.895944584859535e-06\n",
      "Epoch 1306, Loss: 0.003479472021354013, Final Batch Loss: 3.4229760785819963e-06\n",
      "Epoch 1307, Loss: 0.02234726999722625, Final Batch Loss: 9.391757885168772e-06\n",
      "Epoch 1308, Loss: 0.015357799486082513, Final Batch Loss: 5.666772631229833e-05\n",
      "Epoch 1309, Loss: 0.002825004939950304, Final Batch Loss: 2.4128432414727286e-05\n",
      "Epoch 1310, Loss: 0.0038350582763087004, Final Batch Loss: 0.000446363992523402\n",
      "Epoch 1311, Loss: 0.002239672146970406, Final Batch Loss: 0.00013856313307769597\n",
      "Epoch 1312, Loss: 0.0025695973163237795, Final Batch Loss: 0.0008446770953014493\n",
      "Epoch 1313, Loss: 0.0026790166593855247, Final Batch Loss: 8.309689292218536e-05\n",
      "Epoch 1314, Loss: 0.002072337309073191, Final Batch Loss: 9.077815775526688e-05\n",
      "Epoch 1315, Loss: 0.0072260220204043435, Final Batch Loss: 2.4144437702489085e-05\n",
      "Epoch 1316, Loss: 0.002348572190385312, Final Batch Loss: 0.00025911282864399254\n",
      "Epoch 1317, Loss: 0.014877380570396781, Final Batch Loss: 0.004452867899090052\n",
      "Epoch 1318, Loss: 0.025368785340106115, Final Batch Loss: 0.009587001986801624\n",
      "Epoch 1319, Loss: 0.00474529744505503, Final Batch Loss: 3.235673773360759e-07\n",
      "Epoch 1320, Loss: 0.009448784553569567, Final Batch Loss: 9.621556273486931e-06\n",
      "Epoch 1321, Loss: 0.006317100196611136, Final Batch Loss: 0.002700926037505269\n",
      "Epoch 1322, Loss: 0.003915606648661196, Final Batch Loss: 9.692623279988766e-05\n",
      "Epoch 1323, Loss: 0.004451927943591727, Final Batch Loss: 3.0553648684872314e-05\n",
      "Epoch 1324, Loss: 0.006314211117569357, Final Batch Loss: 0.004211388062685728\n",
      "Epoch 1325, Loss: 0.05173499323427677, Final Batch Loss: 0.00020573113579303026\n",
      "Epoch 1326, Loss: 0.002808457145874854, Final Batch Loss: 8.229670493165031e-05\n",
      "Epoch 1327, Loss: 0.0200818794692168, Final Batch Loss: 0.009009427390992641\n",
      "Epoch 1328, Loss: 0.017482271722201403, Final Batch Loss: 2.7247428988630418e-06\n",
      "Epoch 1329, Loss: 0.005244275293080136, Final Batch Loss: 4.8068963224068284e-05\n",
      "Epoch 1330, Loss: 0.0018317568174097687, Final Batch Loss: 0.00039798588841222227\n",
      "Epoch 1331, Loss: 0.015024445125163766, Final Batch Loss: 5.697763481293805e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1332, Loss: 0.02870050907949917, Final Batch Loss: 0.01158087607473135\n",
      "Epoch 1333, Loss: 0.011381918505776412, Final Batch Loss: 2.060608949250309e-06\n",
      "Epoch 1334, Loss: 0.013982809003209695, Final Batch Loss: 0.005684423726052046\n",
      "Epoch 1335, Loss: 0.011180222506908422, Final Batch Loss: 2.980227407078928e-07\n",
      "Epoch 1336, Loss: 0.002759622730081901, Final Batch Loss: 4.0428334614261985e-05\n",
      "Epoch 1337, Loss: 0.003457168204477057, Final Batch Loss: 0.0008968618931248784\n",
      "Epoch 1338, Loss: 0.017505998635897413, Final Batch Loss: 0.005928016733378172\n",
      "Epoch 1339, Loss: 0.010613821923470823, Final Batch Loss: 2.2460106265498325e-05\n",
      "Epoch 1340, Loss: 0.00335441307106521, Final Batch Loss: 0.0004550477606244385\n",
      "Epoch 1341, Loss: 0.010570062047918327, Final Batch Loss: 0.0001667969481786713\n",
      "Epoch 1342, Loss: 0.004762426384516516, Final Batch Loss: 1.277241636898907e-07\n",
      "Epoch 1343, Loss: 0.0026398594200145453, Final Batch Loss: 0.0005956246750429273\n",
      "Epoch 1344, Loss: 0.0016300332254104433, Final Batch Loss: 1.008133858704241e-05\n",
      "Epoch 1345, Loss: 0.0025861314570647664, Final Batch Loss: 0.0009886580519378185\n",
      "Epoch 1346, Loss: 0.011801202681454015, Final Batch Loss: 8.906341463443823e-06\n",
      "Epoch 1347, Loss: 0.0018042365554720163, Final Batch Loss: 9.42834303714335e-05\n",
      "Epoch 1348, Loss: 0.012096172955352813, Final Batch Loss: 0.010592587292194366\n",
      "Epoch 1349, Loss: 0.0008333290605833099, Final Batch Loss: 2.3841846541472478e-07\n",
      "Epoch 1350, Loss: 0.005907954357098788, Final Batch Loss: 0.0008418640936724842\n",
      "Epoch 1351, Loss: 0.06720325260266691, Final Batch Loss: 1.4219008335203398e-05\n",
      "Epoch 1352, Loss: 0.004146773692809802, Final Batch Loss: 8.131556569423992e-06\n",
      "Epoch 1353, Loss: 0.0034454738488420844, Final Batch Loss: 0.0011919186217710376\n",
      "Epoch 1354, Loss: 0.0023830149875720963, Final Batch Loss: 0.00023523405252490193\n",
      "Epoch 1355, Loss: 0.0013090880238451064, Final Batch Loss: 9.935993875842541e-05\n",
      "Epoch 1356, Loss: 0.0053800833120476454, Final Batch Loss: 0.003267067950218916\n",
      "Epoch 1357, Loss: 0.004210640170640545, Final Batch Loss: 8.395381883019581e-06\n",
      "Epoch 1358, Loss: 0.0014733773859916255, Final Batch Loss: 0.00019282510038465261\n",
      "Epoch 1359, Loss: 0.006052146250567603, Final Batch Loss: 2.1372320588852745e-06\n",
      "Epoch 1360, Loss: 0.0013788503565592691, Final Batch Loss: 0.0003454273974057287\n",
      "Epoch 1361, Loss: 0.006098366764490493, Final Batch Loss: 0.00015606895613018423\n",
      "Epoch 1362, Loss: 0.0021623576612910256, Final Batch Loss: 0.000296150945359841\n",
      "Epoch 1363, Loss: 0.004051621945109218, Final Batch Loss: 0.000925850123167038\n",
      "Epoch 1364, Loss: 0.011072726076235995, Final Batch Loss: 0.0007233237847685814\n",
      "Epoch 1365, Loss: 0.003224382220651023, Final Batch Loss: 6.679240323137492e-05\n",
      "Epoch 1366, Loss: 0.0018122792553185718, Final Batch Loss: 1.0736579497461207e-05\n",
      "Epoch 1367, Loss: 0.008716002019355074, Final Batch Loss: 8.178653661161661e-05\n",
      "Epoch 1368, Loss: 0.002625135690323077, Final Batch Loss: 6.159373151604086e-05\n",
      "Epoch 1369, Loss: 0.015435372984939022, Final Batch Loss: 3.168095645378344e-05\n",
      "Epoch 1370, Loss: 0.005064513738034293, Final Batch Loss: 0.000448647333541885\n",
      "Epoch 1371, Loss: 0.014738404366653413, Final Batch Loss: 0.013287687674164772\n",
      "Epoch 1372, Loss: 0.004747437216792605, Final Batch Loss: 2.5236184228560887e-05\n",
      "Epoch 1373, Loss: 0.003091323376793298, Final Batch Loss: 2.0452191165531985e-05\n",
      "Epoch 1374, Loss: 0.004864658243604936, Final Batch Loss: 1.2720833183266222e-05\n",
      "Epoch 1375, Loss: 0.04028317524353042, Final Batch Loss: 0.00097472412744537\n",
      "Epoch 1376, Loss: 0.0013369739972404204, Final Batch Loss: 0.00016643924755044281\n",
      "Epoch 1377, Loss: 0.010975441029586364, Final Batch Loss: 4.208669997751713e-05\n",
      "Epoch 1378, Loss: 0.0024591919063823298, Final Batch Loss: 0.00012287388381082565\n",
      "Epoch 1379, Loss: 0.0025006748765008524, Final Batch Loss: 0.00010604855924611911\n",
      "Epoch 1380, Loss: 0.01850536906567868, Final Batch Loss: 2.1931438823230565e-05\n",
      "Epoch 1381, Loss: 0.0029052386817056686, Final Batch Loss: 0.00012149977555964142\n",
      "Epoch 1382, Loss: 0.002421418458283142, Final Batch Loss: 2.0435854253264552e-07\n",
      "Epoch 1383, Loss: 0.008379330512980232, Final Batch Loss: 6.102156839915551e-05\n",
      "Epoch 1384, Loss: 0.0014145642016956117, Final Batch Loss: 1.77102665475104e-05\n",
      "Epoch 1385, Loss: 0.0034492315999159473, Final Batch Loss: 1.3861043953511398e-05\n",
      "Epoch 1386, Loss: 0.00456943605968263, Final Batch Loss: 2.88357405224815e-05\n",
      "Epoch 1387, Loss: 0.004286724972644151, Final Batch Loss: 4.112604528927477e-06\n",
      "Epoch 1388, Loss: 0.0016211410766118206, Final Batch Loss: 5.517352110473439e-05\n",
      "Epoch 1389, Loss: 0.002869828611437697, Final Batch Loss: 7.963969983393326e-05\n",
      "Epoch 1390, Loss: 0.002650630922289565, Final Batch Loss: 6.308146112132818e-05\n",
      "Epoch 1391, Loss: 0.002030155126703903, Final Batch Loss: 0.00030115267145447433\n",
      "Epoch 1392, Loss: 0.0024758262115938123, Final Batch Loss: 5.3016086894785985e-05\n",
      "Epoch 1393, Loss: 0.013814268893838744, Final Batch Loss: 1.8859353076550178e-05\n",
      "Epoch 1394, Loss: 0.004355159355327487, Final Batch Loss: 9.733092883834615e-05\n",
      "Epoch 1395, Loss: 0.0018757699726847932, Final Batch Loss: 0.0007388392114080489\n",
      "Epoch 1396, Loss: 0.005171800705781493, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 1397, Loss: 0.005323660348949488, Final Batch Loss: 0.0001569978048792109\n",
      "Epoch 1398, Loss: 0.008376592966669705, Final Batch Loss: 0.0006784978904761374\n",
      "Epoch 1399, Loss: 0.002043907566985581, Final Batch Loss: 7.419838948408142e-05\n",
      "Epoch 1400, Loss: 0.004815275668079266, Final Batch Loss: 5.299445547279902e-05\n",
      "Epoch 1401, Loss: 0.0066891864053104655, Final Batch Loss: 5.9772946769953705e-06\n",
      "Epoch 1402, Loss: 0.03947358608729701, Final Batch Loss: 8.838088433549274e-06\n",
      "Epoch 1403, Loss: 0.012516953531303443, Final Batch Loss: 0.009579180739820004\n",
      "Epoch 1404, Loss: 0.0046727129083592445, Final Batch Loss: 0.0006387901376001537\n",
      "Epoch 1405, Loss: 0.014462459621427115, Final Batch Loss: 0.0017799072666093707\n",
      "Epoch 1406, Loss: 0.0037673571896448266, Final Batch Loss: 3.545284198480658e-05\n",
      "Epoch 1407, Loss: 0.002154766636522254, Final Batch Loss: 4.0128757973434404e-05\n",
      "Epoch 1408, Loss: 0.0026339440710216877, Final Batch Loss: 6.173232577566523e-06\n",
      "Epoch 1409, Loss: 0.003353289095684886, Final Batch Loss: 0.00011583918239921331\n",
      "Epoch 1410, Loss: 0.0015023365886008833, Final Batch Loss: 1.9820090528810397e-05\n",
      "Epoch 1411, Loss: 0.003819029054056955, Final Batch Loss: 3.210068598491489e-06\n",
      "Epoch 1412, Loss: 0.0010755074981716461, Final Batch Loss: 7.59142785682343e-05\n",
      "Epoch 1413, Loss: 0.003179351474784653, Final Batch Loss: 9.451571827412408e-07\n",
      "Epoch 1414, Loss: 0.02118483477488553, Final Batch Loss: 4.7342323341581505e-06\n",
      "Epoch 1415, Loss: 0.008994560717837885, Final Batch Loss: 0.0001713249512249604\n",
      "Epoch 1416, Loss: 0.007085984201694373, Final Batch Loss: 0.0001176958394353278\n",
      "Epoch 1417, Loss: 0.015426091151311994, Final Batch Loss: 0.004685584455728531\n",
      "Epoch 1418, Loss: 0.015179094179984531, Final Batch Loss: 1.5989286112016998e-05\n",
      "Epoch 1419, Loss: 0.007623708821483888, Final Batch Loss: 8.310216071549803e-05\n",
      "Epoch 1420, Loss: 0.002443261670237007, Final Batch Loss: 1.2687161188296159e-06\n",
      "Epoch 1421, Loss: 0.0017474182095611468, Final Batch Loss: 0.0001275004615308717\n",
      "Epoch 1422, Loss: 0.0030125095352104836, Final Batch Loss: 2.5459437438257737e-06\n",
      "Epoch 1423, Loss: 0.002978873942993232, Final Batch Loss: 1.6219195458688773e-05\n",
      "Epoch 1424, Loss: 0.0019867905148203135, Final Batch Loss: 9.74076920101652e-06\n",
      "Epoch 1425, Loss: 0.0023198242834041594, Final Batch Loss: 1.6627991499262862e-05\n",
      "Epoch 1426, Loss: 0.00971356903232845, Final Batch Loss: 2.0350510112621123e-06\n",
      "Epoch 1427, Loss: 0.0013831300971673954, Final Batch Loss: 7.578278768960445e-07\n",
      "Epoch 1428, Loss: 0.0019143530080327764, Final Batch Loss: 0.0005019803065806627\n",
      "Epoch 1429, Loss: 0.0006291491854426567, Final Batch Loss: 5.4750280469306745e-06\n",
      "Epoch 1430, Loss: 0.005353189022571314, Final Batch Loss: 7.168626325437799e-05\n",
      "Epoch 1431, Loss: 0.015055891708470881, Final Batch Loss: 0.00024893617955967784\n",
      "Epoch 1432, Loss: 0.0019031163938052487, Final Batch Loss: 3.252647729823366e-06\n",
      "Epoch 1433, Loss: 0.003348561140228412, Final Batch Loss: 2.3182443328551017e-05\n",
      "Epoch 1434, Loss: 0.0102458223777262, Final Batch Loss: 4.51291668923659e-07\n",
      "Epoch 1435, Loss: 0.0024095476292131934, Final Batch Loss: 0.00021749890584032983\n",
      "Epoch 1436, Loss: 0.02297968070342904, Final Batch Loss: 2.1531435777433217e-05\n",
      "Epoch 1437, Loss: 0.0004781484959721638, Final Batch Loss: 1.1665389365589363e-06\n",
      "Epoch 1438, Loss: 0.08422099357994739, Final Batch Loss: 0.00018712952442001551\n",
      "Epoch 1439, Loss: 0.0018303025062778033, Final Batch Loss: 0.0005443246918730438\n",
      "Epoch 1440, Loss: 0.010801419977042315, Final Batch Loss: 3.720994982359116e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1441, Loss: 0.0033689594856696203, Final Batch Loss: 7.901982462499291e-05\n",
      "Epoch 1442, Loss: 0.002163806202588603, Final Batch Loss: 0.00031964879599399865\n",
      "Epoch 1443, Loss: 0.001925501402183727, Final Batch Loss: 1.4108297364145983e-05\n",
      "Epoch 1444, Loss: 0.0034802111840690486, Final Batch Loss: 7.72673447499983e-05\n",
      "Epoch 1445, Loss: 0.005918382417121393, Final Batch Loss: 3.252692522437428e-06\n",
      "Epoch 1446, Loss: 0.0022866790895932354, Final Batch Loss: 9.146545926341787e-05\n",
      "Epoch 1447, Loss: 0.0016058603473538824, Final Batch Loss: 2.682176727830665e-06\n",
      "Epoch 1448, Loss: 0.009227538460123696, Final Batch Loss: 3.320825783248438e-07\n",
      "Epoch 1449, Loss: 0.0053933068993501365, Final Batch Loss: 0.000530615565367043\n",
      "Epoch 1450, Loss: 0.001483827285028383, Final Batch Loss: 2.103167844325071e-06\n",
      "Epoch 1451, Loss: 0.0023751995568090933, Final Batch Loss: 9.272635907109361e-06\n",
      "Epoch 1452, Loss: 0.0029293306870386004, Final Batch Loss: 0.0011750685516744852\n",
      "Epoch 1453, Loss: 0.003156724967993796, Final Batch Loss: 0.00027464356389828026\n",
      "Epoch 1454, Loss: 0.00091739423078252, Final Batch Loss: 5.709911783924326e-05\n",
      "Epoch 1455, Loss: 0.001762424966727849, Final Batch Loss: 3.2111995096784085e-05\n",
      "Epoch 1456, Loss: 0.0013329321518540382, Final Batch Loss: 6.549330282723531e-05\n",
      "Epoch 1457, Loss: 0.0015127279912121594, Final Batch Loss: 0.0003528018423821777\n",
      "Epoch 1458, Loss: 0.0043556238006203785, Final Batch Loss: 9.093410881177988e-06\n",
      "Epoch 1459, Loss: 0.0017920643440447748, Final Batch Loss: 0.00017903736443258822\n",
      "Epoch 1460, Loss: 0.002736581111093983, Final Batch Loss: 0.0006409339257515967\n",
      "Epoch 1461, Loss: 0.0042571332470942025, Final Batch Loss: 1.873287800435719e-07\n",
      "Epoch 1462, Loss: 0.0015218193439068273, Final Batch Loss: 0.00024109527294058353\n",
      "Epoch 1463, Loss: 0.000945148655318917, Final Batch Loss: 2.62259027294931e-06\n",
      "Epoch 1464, Loss: 0.003080426707128936, Final Batch Loss: 7.612098670506384e-06\n",
      "Epoch 1465, Loss: 0.0015841149433981627, Final Batch Loss: 4.328617797000334e-05\n",
      "Epoch 1466, Loss: 0.0010555877579463413, Final Batch Loss: 1.9454184439382516e-05\n",
      "Epoch 1467, Loss: 0.08125156981986947, Final Batch Loss: 0.08052407205104828\n",
      "Epoch 1468, Loss: 0.07179110019569634, Final Batch Loss: 0.012489375658333302\n",
      "Epoch 1469, Loss: 0.43245767831103876, Final Batch Loss: 0.3988843560218811\n",
      "Epoch 1470, Loss: 0.11587378603871912, Final Batch Loss: 0.0006834901869297028\n",
      "Epoch 1471, Loss: 0.16828821669241734, Final Batch Loss: 9.749200216901954e-06\n",
      "Epoch 1472, Loss: 0.05675418127793819, Final Batch Loss: 0.004147243220359087\n",
      "Epoch 1473, Loss: 0.06439968772610882, Final Batch Loss: 7.989854930201545e-05\n",
      "Epoch 1474, Loss: 0.047961395408492535, Final Batch Loss: 0.0007299234275706112\n",
      "Epoch 1475, Loss: 0.01025043337722309, Final Batch Loss: 0.0033786469139158726\n",
      "Epoch 1476, Loss: 0.025057747756363824, Final Batch Loss: 0.0018780281534418464\n",
      "Epoch 1477, Loss: 0.013321998811704816, Final Batch Loss: 2.6396327257316443e-07\n",
      "Epoch 1478, Loss: 0.0032459032954648137, Final Batch Loss: 0.0003973054699599743\n",
      "Epoch 1479, Loss: 0.012991282550501637, Final Batch Loss: 9.272007446270436e-05\n",
      "Epoch 1480, Loss: 0.015150252591411117, Final Batch Loss: 5.784977838629857e-05\n",
      "Epoch 1481, Loss: 0.01560193252572617, Final Batch Loss: 8.600071055298031e-07\n",
      "Epoch 1482, Loss: 0.005974858482886702, Final Batch Loss: 1.4815962003922323e-06\n",
      "Epoch 1483, Loss: 0.0031278554815799, Final Batch Loss: 0.0006860370049253106\n",
      "Epoch 1484, Loss: 0.009967083227820694, Final Batch Loss: 0.003932283725589514\n",
      "Epoch 1485, Loss: 0.0028490430195233785, Final Batch Loss: 5.037496885051951e-05\n",
      "Epoch 1486, Loss: 0.008449152701359708, Final Batch Loss: 1.54700901475735e-05\n",
      "Epoch 1487, Loss: 0.004155539732892066, Final Batch Loss: 0.00048051294288598\n",
      "Epoch 1488, Loss: 0.004893868046565331, Final Batch Loss: 1.1392219676054083e-05\n",
      "Epoch 1489, Loss: 0.0022807844604813, Final Batch Loss: 2.14574788515165e-06\n",
      "Epoch 1490, Loss: 0.012192316144137294, Final Batch Loss: 2.514116386009846e-05\n",
      "Epoch 1491, Loss: 0.005574483016971499, Final Batch Loss: 0.0004297342093195766\n",
      "Epoch 1492, Loss: 0.003391597731933871, Final Batch Loss: 1.0200476936006453e-05\n",
      "Epoch 1493, Loss: 0.017067254928406328, Final Batch Loss: 0.00027252172003500164\n",
      "Epoch 1494, Loss: 0.007186712420661934, Final Batch Loss: 2.017767110373825e-05\n",
      "Epoch 1495, Loss: 0.008567922952352092, Final Batch Loss: 0.006077819503843784\n",
      "Epoch 1496, Loss: 0.004932686308166012, Final Batch Loss: 0.00015643914230167866\n",
      "Epoch 1497, Loss: 0.008197850152100727, Final Batch Loss: 1.2993154996365774e-05\n",
      "Epoch 1498, Loss: 0.004037482414787519, Final Batch Loss: 1.3240131011116318e-05\n",
      "Epoch 1499, Loss: 0.0037593157358060125, Final Batch Loss: 5.2785708248848096e-05\n",
      "Epoch 1500, Loss: 0.004065096938575152, Final Batch Loss: 3.7128695112187415e-05\n",
      "Epoch 1501, Loss: 0.018533552763983607, Final Batch Loss: 0.00013833522098138928\n",
      "Epoch 1502, Loss: 0.007544407970272005, Final Batch Loss: 0.0030137712601572275\n",
      "Epoch 1503, Loss: 0.015448141304659657, Final Batch Loss: 0.00045261337072588503\n",
      "Epoch 1504, Loss: 0.0028398614304023795, Final Batch Loss: 0.0001014612425933592\n",
      "Epoch 1505, Loss: 0.008161568188370438, Final Batch Loss: 2.947329994640313e-05\n",
      "Epoch 1506, Loss: 0.004943202970025595, Final Batch Loss: 0.0034654433839023113\n",
      "Epoch 1507, Loss: 0.024898173956557912, Final Batch Loss: 1.7199996591443778e-06\n",
      "Epoch 1508, Loss: 0.011394274346457678, Final Batch Loss: 1.0600791938486509e-05\n",
      "Epoch 1509, Loss: 0.0040141295503417496, Final Batch Loss: 5.352603693609126e-05\n",
      "Epoch 1510, Loss: 0.002342770549148554, Final Batch Loss: 5.628129656543024e-05\n",
      "Epoch 1511, Loss: 0.009885927589493804, Final Batch Loss: 0.00014048771117813885\n",
      "Epoch 1512, Loss: 0.004423749014677014, Final Batch Loss: 5.2561423217412084e-05\n",
      "Epoch 1513, Loss: 0.0019704516150795826, Final Batch Loss: 3.6358239867695374e-06\n",
      "Epoch 1514, Loss: 0.005432381738501135, Final Batch Loss: 3.648360871011391e-05\n",
      "Epoch 1515, Loss: 0.0075499590166145936, Final Batch Loss: 0.004339396487921476\n",
      "Epoch 1516, Loss: 0.007365366036538035, Final Batch Loss: 0.001930186408571899\n",
      "Epoch 1517, Loss: 0.008633998164441437, Final Batch Loss: 0.0010720905847847462\n",
      "Epoch 1518, Loss: 0.006831154183601029, Final Batch Loss: 0.0024734572507441044\n",
      "Epoch 1519, Loss: 0.004909932191367261, Final Batch Loss: 0.001103467307984829\n",
      "Epoch 1520, Loss: 0.0015656279659879146, Final Batch Loss: 1.6859497691257275e-06\n",
      "Epoch 1521, Loss: 0.001164101529866457, Final Batch Loss: 0.0002461103140376508\n",
      "Epoch 1522, Loss: 0.003227786277420819, Final Batch Loss: 0.001265684375539422\n",
      "Epoch 1523, Loss: 0.005207087015151046, Final Batch Loss: 0.0001880034542409703\n",
      "Epoch 1524, Loss: 0.0017990172636928037, Final Batch Loss: 0.0001303071912843734\n",
      "Epoch 1525, Loss: 0.0020630443759728223, Final Batch Loss: 0.0002966852916870266\n",
      "Epoch 1526, Loss: 0.002756951586889045, Final Batch Loss: 6.76075342198601e-06\n",
      "Epoch 1527, Loss: 0.012851367987195772, Final Batch Loss: 3.0057478852540953e-06\n",
      "Epoch 1528, Loss: 0.002050175711246993, Final Batch Loss: 6.794814453314757e-06\n",
      "Epoch 1529, Loss: 0.003344944994751131, Final Batch Loss: 3.746906804735772e-05\n",
      "Epoch 1530, Loss: 0.000979757501909262, Final Batch Loss: 1.7710970041662222e-06\n",
      "Epoch 1531, Loss: 0.0026350630269007524, Final Batch Loss: 2.5114901291090064e-05\n",
      "Epoch 1532, Loss: 0.001506033178884536, Final Batch Loss: 9.758200030773878e-05\n",
      "Epoch 1533, Loss: 0.002775015955847948, Final Batch Loss: 2.0435865621948324e-07\n",
      "Epoch 1534, Loss: 0.0023082429106580094, Final Batch Loss: 0.00010140515223611146\n",
      "Epoch 1535, Loss: 0.0012737839060719125, Final Batch Loss: 0.0002875080972444266\n",
      "Epoch 1536, Loss: 0.0013846497254235146, Final Batch Loss: 6.837342425569659e-06\n",
      "Epoch 1537, Loss: 0.001183654802844103, Final Batch Loss: 3.908305188815575e-06\n",
      "Epoch 1538, Loss: 0.0034349530324107036, Final Batch Loss: 0.0002864678972400725\n",
      "Epoch 1539, Loss: 0.0028367016020638403, Final Batch Loss: 3.212241063010879e-05\n",
      "Epoch 1540, Loss: 0.005810476435726741, Final Batch Loss: 3.6915418604621664e-05\n",
      "Epoch 1541, Loss: 0.001319613810210285, Final Batch Loss: 3.176028712914558e-06\n",
      "Epoch 1542, Loss: 0.0015891729030954593, Final Batch Loss: 4.896011432720115e-06\n",
      "Epoch 1543, Loss: 0.014584480566554703, Final Batch Loss: 0.00027235993184149265\n",
      "Epoch 1544, Loss: 0.008126212362640217, Final Batch Loss: 9.366399353893939e-07\n",
      "Epoch 1545, Loss: 0.007836814591428265, Final Batch Loss: 0.0018003538716584444\n",
      "Epoch 1546, Loss: 0.001846949247919838, Final Batch Loss: 1.3307695553521626e-05\n",
      "Epoch 1547, Loss: 0.0014154655291349627, Final Batch Loss: 7.130188896553591e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1548, Loss: 0.0008162092417478561, Final Batch Loss: 0.00014164733875077218\n",
      "Epoch 1549, Loss: 0.003931527740405727, Final Batch Loss: 4.095645181223517e-06\n",
      "Epoch 1550, Loss: 0.0011750865778594743, Final Batch Loss: 5.4339103371603414e-05\n",
      "Epoch 1551, Loss: 0.0013498514403522677, Final Batch Loss: 6.726790502398217e-07\n",
      "Epoch 1552, Loss: 0.005174330981390085, Final Batch Loss: 7.574015035061166e-05\n",
      "Epoch 1553, Loss: 0.006756131114343589, Final Batch Loss: 3.840140379907098e-06\n",
      "Epoch 1554, Loss: 0.0016195538773899898, Final Batch Loss: 0.00014238983567338437\n",
      "Epoch 1555, Loss: 0.0034225669151055627, Final Batch Loss: 4.660634294850752e-05\n",
      "Epoch 1556, Loss: 0.0030757097010791767, Final Batch Loss: 3.6783832911169156e-05\n",
      "Epoch 1557, Loss: 0.0019231638289056718, Final Batch Loss: 0.00010175297211389989\n",
      "Epoch 1558, Loss: 0.006240655270858042, Final Batch Loss: 1.7114900856540771e-06\n",
      "Epoch 1559, Loss: 0.00448963346570963, Final Batch Loss: 0.00010649211617419496\n",
      "Epoch 1560, Loss: 0.0012806199883925728, Final Batch Loss: 4.593091580318287e-05\n",
      "Epoch 1561, Loss: 0.00303968318621628, Final Batch Loss: 0.00023526781296823174\n",
      "Epoch 1562, Loss: 0.0015800523180473647, Final Batch Loss: 7.237687782435387e-07\n",
      "Epoch 1563, Loss: 0.002634772754390724, Final Batch Loss: 0.00025581158115528524\n",
      "Epoch 1564, Loss: 0.0023133191352826543, Final Batch Loss: 9.133102867053822e-05\n",
      "Epoch 1565, Loss: 0.004540773666121822, Final Batch Loss: 1.4193040442478377e-05\n",
      "Epoch 1566, Loss: 0.0014862401585560292, Final Batch Loss: 1.1145530152134597e-05\n",
      "Epoch 1567, Loss: 0.005010458096876391, Final Batch Loss: 1.0285335520165972e-05\n",
      "Epoch 1568, Loss: 0.002517199201975018, Final Batch Loss: 0.00040082327905111015\n",
      "Epoch 1569, Loss: 0.005492579162819311, Final Batch Loss: 0.0007285110768862069\n",
      "Epoch 1570, Loss: 0.0024933067694803412, Final Batch Loss: 3.916872231002344e-07\n",
      "Epoch 1571, Loss: 0.002304497607809708, Final Batch Loss: 3.9168659782262694e-07\n",
      "Epoch 1572, Loss: 0.0019060970589634962, Final Batch Loss: 0.0007817444275133312\n",
      "Epoch 1573, Loss: 0.0022737583367415937, Final Batch Loss: 3.042638309125323e-05\n",
      "Epoch 1574, Loss: 0.012694220467892592, Final Batch Loss: 1.5470739526790567e-05\n",
      "Epoch 1575, Loss: 0.0030759147950902843, Final Batch Loss: 2.6481313852855237e-06\n",
      "Epoch 1576, Loss: 0.00205749410719136, Final Batch Loss: 4.1723154708961374e-07\n",
      "Epoch 1577, Loss: 0.0010331058526276138, Final Batch Loss: 5.790149657514121e-07\n",
      "Epoch 1578, Loss: 0.007772033175569959, Final Batch Loss: 0.0004269164346624166\n",
      "Epoch 1579, Loss: 0.0024267807020805776, Final Batch Loss: 0.0001219475525431335\n",
      "Epoch 1580, Loss: 0.00308393685190822, Final Batch Loss: 3.741347973118536e-05\n",
      "Epoch 1581, Loss: 0.0018361396723776124, Final Batch Loss: 0.00109606864862144\n",
      "Epoch 1582, Loss: 0.0013549230257012823, Final Batch Loss: 2.716250946832588e-06\n",
      "Epoch 1583, Loss: 0.001460123276046943, Final Batch Loss: 0.0003103927883785218\n",
      "Epoch 1584, Loss: 0.0013197559892432764, Final Batch Loss: 0.00013571607996709645\n",
      "Epoch 1585, Loss: 0.0014254475754569285, Final Batch Loss: 8.88054637471214e-06\n",
      "Epoch 1586, Loss: 0.0019838549342239276, Final Batch Loss: 1.328327925875783e-06\n",
      "Epoch 1587, Loss: 0.006475492846220732, Final Batch Loss: 0.0018575807334855199\n",
      "Epoch 1588, Loss: 0.003951999417040497, Final Batch Loss: 7.844057108741254e-05\n",
      "Epoch 1589, Loss: 0.0020308190787545755, Final Batch Loss: 9.170012162940111e-06\n",
      "Epoch 1590, Loss: 0.001216625067172572, Final Batch Loss: 0.00018928277131635696\n",
      "Epoch 1591, Loss: 0.001182475927635096, Final Batch Loss: 0.00022586018894799054\n",
      "Epoch 1592, Loss: 0.07593398861354217, Final Batch Loss: 0.07404523342847824\n",
      "Epoch 1593, Loss: 0.00222098533231474, Final Batch Loss: 9.280947779188864e-06\n",
      "Epoch 1594, Loss: 0.009458828898573302, Final Batch Loss: 1.1665389365589363e-06\n",
      "Epoch 1595, Loss: 0.0012243004603078589, Final Batch Loss: 0.00012632753350771964\n",
      "Epoch 1596, Loss: 0.011191383142431732, Final Batch Loss: 0.0002150309010175988\n",
      "Epoch 1597, Loss: 0.003091845258950343, Final Batch Loss: 7.331085271289339e-06\n",
      "Epoch 1598, Loss: 0.001322076665928762, Final Batch Loss: 4.002022251370363e-07\n",
      "Epoch 1599, Loss: 0.004225577788929513, Final Batch Loss: 9.681040864961687e-06\n",
      "Epoch 1600, Loss: 0.007667194944588118, Final Batch Loss: 6.897080311318859e-07\n",
      "Epoch 1601, Loss: 0.027829390674014576, Final Batch Loss: 0.0013757582055404782\n",
      "Epoch 1602, Loss: 0.00404351984616369, Final Batch Loss: 0.00044208718463778496\n",
      "Epoch 1603, Loss: 0.014392629462236073, Final Batch Loss: 7.294696843018755e-05\n",
      "Epoch 1604, Loss: 0.020912896594357022, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 1605, Loss: 0.0014462836916209199, Final Batch Loss: 9.580688492860645e-05\n",
      "Epoch 1606, Loss: 0.0014476816222668276, Final Batch Loss: 1.1469172932265792e-05\n",
      "Epoch 1607, Loss: 0.01708794161095284, Final Batch Loss: 9.851326467469335e-06\n",
      "Epoch 1608, Loss: 0.0055933955882210284, Final Batch Loss: 0.00015157625603023916\n",
      "Epoch 1609, Loss: 0.0008953196120273788, Final Batch Loss: 3.127234595012851e-05\n",
      "Epoch 1610, Loss: 0.00154442414350342, Final Batch Loss: 0.0003513151896186173\n",
      "Epoch 1611, Loss: 0.0015355511072812078, Final Batch Loss: 2.9290945349202957e-06\n",
      "Epoch 1612, Loss: 0.0033210196052095853, Final Batch Loss: 7.91175989434123e-05\n",
      "Epoch 1613, Loss: 0.0009647187507653143, Final Batch Loss: 2.1064366592327133e-05\n",
      "Epoch 1614, Loss: 0.002657630670000799, Final Batch Loss: 0.0002872779150493443\n",
      "Epoch 1615, Loss: 0.0018772078547044657, Final Batch Loss: 0.0002521969727240503\n",
      "Epoch 1616, Loss: 0.001552316010929644, Final Batch Loss: 0.00012601728667505085\n",
      "Epoch 1617, Loss: 0.0022189273731783032, Final Batch Loss: 9.33064948185347e-05\n",
      "Epoch 1618, Loss: 0.007092203402329744, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 1619, Loss: 0.0021824355062562972, Final Batch Loss: 3.5739445593208075e-05\n",
      "Epoch 1620, Loss: 0.007140947796870023, Final Batch Loss: 2.7533038519322872e-05\n",
      "Epoch 1621, Loss: 0.004170273383692802, Final Batch Loss: 1.6093075601020246e-06\n",
      "Epoch 1622, Loss: 0.004240972091793083, Final Batch Loss: 0.0020212549716234207\n",
      "Epoch 1623, Loss: 0.0012315223066252656, Final Batch Loss: 0.000529413518961519\n",
      "Epoch 1624, Loss: 0.022368353904312244, Final Batch Loss: 3.572125206119381e-05\n",
      "Epoch 1625, Loss: 0.0029009602400265067, Final Batch Loss: 6.641636218773783e-07\n",
      "Epoch 1626, Loss: 0.004259996279870393, Final Batch Loss: 5.301146666170098e-05\n",
      "Epoch 1627, Loss: 0.03480146090441849, Final Batch Loss: 0.014220841228961945\n",
      "Epoch 1628, Loss: 0.0024160387038136832, Final Batch Loss: 5.3737843700218946e-05\n",
      "Epoch 1629, Loss: 0.06619291177298692, Final Batch Loss: 2.3841664642532123e-06\n",
      "Epoch 1630, Loss: 0.027658105104137576, Final Batch Loss: 1.95842972061655e-06\n",
      "Epoch 1631, Loss: 0.05212391093664337, Final Batch Loss: 0.0004651414346881211\n",
      "Epoch 1632, Loss: 0.10725086150341667, Final Batch Loss: 0.09030690044164658\n",
      "Epoch 1633, Loss: 0.32341500831535086, Final Batch Loss: 0.2683921158313751\n",
      "Epoch 1634, Loss: 0.03656266820922838, Final Batch Loss: 2.639631588863267e-07\n",
      "Epoch 1635, Loss: 0.05320978983945679, Final Batch Loss: 0.00010301718430127949\n",
      "Epoch 1636, Loss: 0.0582460242731031, Final Batch Loss: 0.024859318509697914\n",
      "Epoch 1637, Loss: 0.027293770781398052, Final Batch Loss: 4.2737610783660784e-05\n",
      "Epoch 1638, Loss: 0.09742694860324264, Final Batch Loss: 0.0026449919678270817\n",
      "Epoch 1639, Loss: 0.050336842106844415, Final Batch Loss: 1.3359736840357073e-05\n",
      "Epoch 1640, Loss: 0.058461067641019326, Final Batch Loss: 2.9631878533109557e-06\n",
      "Epoch 1641, Loss: 0.034021748248051153, Final Batch Loss: 4.49100807600189e-05\n",
      "Epoch 1642, Loss: 0.01094669831218198, Final Batch Loss: 0.00045206068898551166\n",
      "Epoch 1643, Loss: 0.012473582522943616, Final Batch Loss: 0.0013411088148131967\n",
      "Epoch 1644, Loss: 0.012973495739061036, Final Batch Loss: 8.463373887934722e-06\n",
      "Epoch 1645, Loss: 0.011810009251348674, Final Batch Loss: 0.0015265012625604868\n",
      "Epoch 1646, Loss: 0.01344726502429694, Final Batch Loss: 0.0004186844453215599\n",
      "Epoch 1647, Loss: 0.05510424874955788, Final Batch Loss: 0.051262419670820236\n",
      "Epoch 1648, Loss: 0.011699105656589381, Final Batch Loss: 0.00014943625137675554\n",
      "Epoch 1649, Loss: 0.008302825576720352, Final Batch Loss: 1.0855744221771602e-05\n",
      "Epoch 1650, Loss: 0.041240603663027287, Final Batch Loss: 0.00677145179361105\n",
      "Epoch 1651, Loss: 0.018966493917105254, Final Batch Loss: 4.743845056509599e-05\n",
      "Epoch 1652, Loss: 0.02158785198116675, Final Batch Loss: 0.00835153553634882\n",
      "Epoch 1653, Loss: 0.02930366855844113, Final Batch Loss: 5.730511929868953e-06\n",
      "Epoch 1654, Loss: 0.0030048224380152533, Final Batch Loss: 1.4372571968124248e-05\n",
      "Epoch 1655, Loss: 0.004965957225067541, Final Batch Loss: 0.0021437930408865213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1656, Loss: 0.015055658208439127, Final Batch Loss: 0.00026098659145645797\n",
      "Epoch 1657, Loss: 0.00333687337115407, Final Batch Loss: 0.00010242161806672812\n",
      "Epoch 1658, Loss: 0.004635532095562667, Final Batch Loss: 0.0017105165170505643\n",
      "Epoch 1659, Loss: 0.02495985863788519, Final Batch Loss: 0.0007866273517720401\n",
      "Epoch 1660, Loss: 0.006260716530960053, Final Batch Loss: 0.0012261855881661177\n",
      "Epoch 1661, Loss: 0.0047360158837364, Final Batch Loss: 2.4693049454072025e-06\n",
      "Epoch 1662, Loss: 0.03582665883095615, Final Batch Loss: 1.5019454622233752e-05\n",
      "Epoch 1663, Loss: 0.002819426245196155, Final Batch Loss: 3.525147121763439e-06\n",
      "Epoch 1664, Loss: 0.018317871014005505, Final Batch Loss: 0.00014631984231527895\n",
      "Epoch 1665, Loss: 0.0075825062522199005, Final Batch Loss: 2.4895794922485948e-05\n",
      "Epoch 1666, Loss: 0.00792052419274114, Final Batch Loss: 0.0004659283149521798\n",
      "Epoch 1667, Loss: 0.010164897743379697, Final Batch Loss: 0.0003568038227967918\n",
      "Epoch 1668, Loss: 0.004296557366615161, Final Batch Loss: 0.0008317322353832424\n",
      "Epoch 1669, Loss: 0.009758678846992552, Final Batch Loss: 0.0011770193232223392\n",
      "Epoch 1670, Loss: 0.013556912759668194, Final Batch Loss: 0.00019025964138563722\n",
      "Epoch 1671, Loss: 0.010216186787147308, Final Batch Loss: 5.015204806113616e-06\n",
      "Epoch 1672, Loss: 0.0026251534291077405, Final Batch Loss: 0.0008123306324705482\n",
      "Epoch 1673, Loss: 0.0034171705483458936, Final Batch Loss: 0.0008246622746810317\n",
      "Epoch 1674, Loss: 0.005963742813037243, Final Batch Loss: 5.092255742056295e-05\n",
      "Epoch 1675, Loss: 0.005271540430840105, Final Batch Loss: 4.379637539386749e-05\n",
      "Epoch 1676, Loss: 0.007225919282063842, Final Batch Loss: 0.00015026668552309275\n",
      "Epoch 1677, Loss: 0.003891152678988874, Final Batch Loss: 0.0016624762210994959\n",
      "Epoch 1678, Loss: 0.008777603772614384, Final Batch Loss: 4.0646442357683554e-05\n",
      "Epoch 1679, Loss: 0.006282197602558881, Final Batch Loss: 1.4611141523346305e-05\n",
      "Epoch 1680, Loss: 0.007888558990089223, Final Batch Loss: 0.0003118078748229891\n",
      "Epoch 1681, Loss: 0.017865477042505518, Final Batch Loss: 0.012684320099651814\n",
      "Epoch 1682, Loss: 0.043937870097579435, Final Batch Loss: 0.03485729917883873\n",
      "Epoch 1683, Loss: 0.013686838314583838, Final Batch Loss: 1.0984243772327318e-06\n",
      "Epoch 1684, Loss: 0.07136187410537786, Final Batch Loss: 1.6263427369267447e-06\n",
      "Epoch 1685, Loss: 0.09938942442749976, Final Batch Loss: 2.0851144654443488e-05\n",
      "Epoch 1686, Loss: 0.071304986900941, Final Batch Loss: 6.381127604981884e-05\n",
      "Epoch 1687, Loss: 0.0387252640502993, Final Batch Loss: 0.0004248448822181672\n",
      "Epoch 1688, Loss: 0.005199859455387923, Final Batch Loss: 2.970314926642459e-05\n",
      "Epoch 1689, Loss: 0.04028729416313581, Final Batch Loss: 0.0002601150481496006\n",
      "Epoch 1690, Loss: 0.006927437680133153, Final Batch Loss: 5.0594804633874446e-05\n",
      "Epoch 1691, Loss: 0.006975755415624008, Final Batch Loss: 0.0003686707641463727\n",
      "Epoch 1692, Loss: 0.006410006542864721, Final Batch Loss: 6.620241765631363e-05\n",
      "Epoch 1693, Loss: 0.009338622621726245, Final Batch Loss: 0.0014041524846106768\n",
      "Epoch 1694, Loss: 0.013053142814897, Final Batch Loss: 0.007882587611675262\n",
      "Epoch 1695, Loss: 0.005391483825405885, Final Batch Loss: 1.513866754976334e-05\n",
      "Epoch 1696, Loss: 0.008135686512105167, Final Batch Loss: 0.005571846384555101\n",
      "Epoch 1697, Loss: 0.004381639599159826, Final Batch Loss: 9.759312524693087e-05\n",
      "Epoch 1698, Loss: 0.006154199043521658, Final Batch Loss: 0.0002759145281743258\n",
      "Epoch 1699, Loss: 0.0034190590158686973, Final Batch Loss: 4.636566882254556e-05\n",
      "Epoch 1700, Loss: 0.008560304180718958, Final Batch Loss: 0.00015963346231728792\n",
      "Epoch 1701, Loss: 0.005131370669914759, Final Batch Loss: 1.905559292936232e-05\n",
      "Epoch 1702, Loss: 0.004141752506257035, Final Batch Loss: 0.00018142974295187742\n",
      "Epoch 1703, Loss: 0.003278858319390565, Final Batch Loss: 0.0003722354304045439\n",
      "Epoch 1704, Loss: 0.0036642125924117863, Final Batch Loss: 0.0006133542046882212\n",
      "Epoch 1705, Loss: 0.004342825341154821, Final Batch Loss: 0.00016756333934608847\n",
      "Epoch 1706, Loss: 0.004424701300081324, Final Batch Loss: 9.707008530313033e-07\n",
      "Epoch 1707, Loss: 0.003953672478246517, Final Batch Loss: 2.4097191726468736e-06\n",
      "Epoch 1708, Loss: 0.010436717318953015, Final Batch Loss: 0.0007175616337917745\n",
      "Epoch 1709, Loss: 0.003224201513148728, Final Batch Loss: 2.6068371880683117e-05\n",
      "Epoch 1710, Loss: 0.0031239625973285, Final Batch Loss: 3.865687631332548e-06\n",
      "Epoch 1711, Loss: 0.007379841299552936, Final Batch Loss: 0.00011672596883727238\n",
      "Epoch 1712, Loss: 0.004037679886096157, Final Batch Loss: 0.000158030612510629\n",
      "Epoch 1713, Loss: 0.009010396708617918, Final Batch Loss: 0.00022023303608875722\n",
      "Epoch 1714, Loss: 0.0021055421734672564, Final Batch Loss: 6.777705948479706e-06\n",
      "Epoch 1715, Loss: 0.003657781984657049, Final Batch Loss: 0.0007089408463798463\n",
      "Epoch 1716, Loss: 0.0018881812648032792, Final Batch Loss: 0.0002821785747073591\n",
      "Epoch 1717, Loss: 0.006272493919823319, Final Batch Loss: 0.0013502886286005378\n",
      "Epoch 1718, Loss: 0.0020688839213107713, Final Batch Loss: 6.825893797213212e-05\n",
      "Epoch 1719, Loss: 0.0021105048879235255, Final Batch Loss: 1.6603960375505267e-06\n",
      "Epoch 1720, Loss: 0.004285586385861961, Final Batch Loss: 3.5762704442277027e-07\n",
      "Epoch 1721, Loss: 0.005364300095607177, Final Batch Loss: 9.536352081340738e-06\n",
      "Epoch 1722, Loss: 0.0016284822904708562, Final Batch Loss: 2.3771672204020433e-05\n",
      "Epoch 1723, Loss: 0.002890605290701842, Final Batch Loss: 6.641643608418235e-07\n",
      "Epoch 1724, Loss: 0.005929273256924716, Final Batch Loss: 2.469309265507036e-06\n",
      "Epoch 1725, Loss: 0.004049003851832822, Final Batch Loss: 0.00010788219515234232\n",
      "Epoch 1726, Loss: 0.0030835627076157834, Final Batch Loss: 1.79898452188354e-05\n",
      "Epoch 1727, Loss: 0.004974653929821216, Final Batch Loss: 0.0014672409743070602\n",
      "Epoch 1728, Loss: 0.006059710006411478, Final Batch Loss: 1.1486071343824733e-05\n",
      "Epoch 1729, Loss: 0.0016237676900345832, Final Batch Loss: 0.0004058121994603425\n",
      "Epoch 1730, Loss: 0.002164982332033105, Final Batch Loss: 0.0005104305455461144\n",
      "Epoch 1731, Loss: 0.025682477820737404, Final Batch Loss: 2.3618575141881593e-05\n",
      "Epoch 1732, Loss: 0.013735836735577323, Final Batch Loss: 0.012114052660763264\n",
      "Epoch 1733, Loss: 0.0022112909173301887, Final Batch Loss: 5.481093467096798e-05\n",
      "Epoch 1734, Loss: 0.015394139249110594, Final Batch Loss: 5.305255763232708e-05\n",
      "Epoch 1735, Loss: 0.0020416652296262328, Final Batch Loss: 3.306608778075315e-05\n",
      "Epoch 1736, Loss: 0.016670084340148605, Final Batch Loss: 0.0002677336160559207\n",
      "Epoch 1737, Loss: 0.0013282897371027502, Final Batch Loss: 1.1690334758895915e-05\n",
      "Epoch 1738, Loss: 0.003703982481965795, Final Batch Loss: 0.00013857489102520049\n",
      "Epoch 1739, Loss: 0.0034596677742229076, Final Batch Loss: 1.341848292213399e-05\n",
      "Epoch 1740, Loss: 0.0042358109494671226, Final Batch Loss: 0.00013072151341475546\n",
      "Epoch 1741, Loss: 0.015072177084221039, Final Batch Loss: 6.28645284450613e-05\n",
      "Epoch 1742, Loss: 0.0019023584318347275, Final Batch Loss: 3.5474105970934033e-05\n",
      "Epoch 1743, Loss: 0.0031986141693778336, Final Batch Loss: 0.00032746497890911996\n",
      "Epoch 1744, Loss: 0.0013737387598666828, Final Batch Loss: 4.263939263182692e-05\n",
      "Epoch 1745, Loss: 0.0029785393562633544, Final Batch Loss: 0.00013166609278414398\n",
      "Epoch 1746, Loss: 0.0017750672923284583, Final Batch Loss: 0.00011902312689926475\n",
      "Epoch 1747, Loss: 0.004116177631658502, Final Batch Loss: 0.00015769469609949738\n",
      "Epoch 1748, Loss: 0.004857050720602274, Final Batch Loss: 0.00010703456064220518\n",
      "Epoch 1749, Loss: 0.0015837415681545508, Final Batch Loss: 2.2990350601048704e-07\n",
      "Epoch 1750, Loss: 0.006205397105077282, Final Batch Loss: 0.0011670856038108468\n",
      "Epoch 1751, Loss: 0.0020074835083505604, Final Batch Loss: 5.023613994126208e-05\n",
      "Epoch 1752, Loss: 0.007860999075735009, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 1753, Loss: 0.01568062146543525, Final Batch Loss: 0.014238854870200157\n",
      "Epoch 1754, Loss: 0.0014346627358463593, Final Batch Loss: 2.790764847304672e-05\n",
      "Epoch 1755, Loss: 0.0018876266331062652, Final Batch Loss: 0.00010865696094697341\n",
      "Epoch 1756, Loss: 0.0034600129729369655, Final Batch Loss: 7.377234578598291e-05\n",
      "Epoch 1757, Loss: 0.00395753352495376, Final Batch Loss: 0.00018343992996960878\n",
      "Epoch 1758, Loss: 0.0020439106883713976, Final Batch Loss: 0.00022228083980735391\n",
      "Epoch 1759, Loss: 0.002729806255956646, Final Batch Loss: 5.269030953058973e-05\n",
      "Epoch 1760, Loss: 0.0005943637042946648, Final Batch Loss: 3.60887534043286e-05\n",
      "Epoch 1761, Loss: 0.0023889353374215716, Final Batch Loss: 2.682177637325367e-06\n",
      "Epoch 1762, Loss: 0.14293936270405538, Final Batch Loss: 0.14185793697834015\n",
      "Epoch 1763, Loss: 0.03672601576727175, Final Batch Loss: 1.2405356756062247e-05\n",
      "Epoch 1764, Loss: 0.10565373041754356, Final Batch Loss: 5.914965731790289e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1765, Loss: 0.05497674785328854, Final Batch Loss: 3.899769581039436e-06\n",
      "Epoch 1766, Loss: 0.035837622242979705, Final Batch Loss: 1.4354940503835678e-05\n",
      "Epoch 1767, Loss: 0.04343507837620564, Final Batch Loss: 0.00020733926794491708\n",
      "Epoch 1768, Loss: 0.034686143044382334, Final Batch Loss: 3.6564539186656475e-05\n",
      "Epoch 1769, Loss: 0.06049513563448272, Final Batch Loss: 2.0697041691164486e-05\n",
      "Epoch 1770, Loss: 0.048744143976364285, Final Batch Loss: 0.005447119474411011\n",
      "Epoch 1771, Loss: 0.020567398983985186, Final Batch Loss: 0.0005584764294326305\n",
      "Epoch 1772, Loss: 0.03629743092460558, Final Batch Loss: 0.0\n",
      "Epoch 1773, Loss: 0.032424645833089016, Final Batch Loss: 0.00016961210349109024\n",
      "Epoch 1774, Loss: 0.010437510180054232, Final Batch Loss: 0.0013056991156190634\n",
      "Epoch 1775, Loss: 0.0037058601737953722, Final Batch Loss: 0.0002617585123516619\n",
      "Epoch 1776, Loss: 0.021168683381347364, Final Batch Loss: 3.6613951124309096e-06\n",
      "Epoch 1777, Loss: 0.008887179952580482, Final Batch Loss: 0.00013050390407443047\n",
      "Epoch 1778, Loss: 0.010558115434832871, Final Batch Loss: 0.002436923561617732\n",
      "Epoch 1779, Loss: 0.004862863745074719, Final Batch Loss: 5.9679849073290825e-05\n",
      "Epoch 1780, Loss: 0.0029201384568295907, Final Batch Loss: 5.605864498647861e-05\n",
      "Epoch 1781, Loss: 0.013383233687818574, Final Batch Loss: 1.0949618626909796e-05\n",
      "Epoch 1782, Loss: 0.02859332342268317, Final Batch Loss: 5.238179801381193e-05\n",
      "Epoch 1783, Loss: 0.002966950109069444, Final Batch Loss: 1.192092469182171e-07\n",
      "Epoch 1784, Loss: 0.002185149114666274, Final Batch Loss: 3.173303775838576e-05\n",
      "Epoch 1785, Loss: 0.006885174261697102, Final Batch Loss: 0.00011323084618197754\n",
      "Epoch 1786, Loss: 0.0276939713221509, Final Batch Loss: 0.0011000036029145122\n",
      "Epoch 1787, Loss: 0.007186216440459248, Final Batch Loss: 3.7929385143797845e-05\n",
      "Epoch 1788, Loss: 0.0024116933345794678, Final Batch Loss: 0.000528298201970756\n",
      "Epoch 1789, Loss: 0.0022859162163513247, Final Batch Loss: 5.2282008255133405e-05\n",
      "Epoch 1790, Loss: 0.00330284537631087, Final Batch Loss: 0.000713018816895783\n",
      "Epoch 1791, Loss: 0.0020743166023748927, Final Batch Loss: 3.641415241872892e-05\n",
      "Epoch 1792, Loss: 0.00398678082274273, Final Batch Loss: 0.00016015698201954365\n",
      "Epoch 1793, Loss: 0.003662677227111999, Final Batch Loss: 9.444473107578233e-05\n",
      "Epoch 1794, Loss: 0.003476644749753177, Final Batch Loss: 0.0005832234746776521\n",
      "Epoch 1795, Loss: 0.0023277228629012825, Final Batch Loss: 2.6130133846891113e-05\n",
      "Epoch 1796, Loss: 0.08896685007493943, Final Batch Loss: 0.0005594849935732782\n",
      "Epoch 1797, Loss: 0.003470120922429487, Final Batch Loss: 0.00029937969520688057\n",
      "Epoch 1798, Loss: 0.001919400838232832, Final Batch Loss: 4.854183134739287e-05\n",
      "Epoch 1799, Loss: 0.008477577765006572, Final Batch Loss: 0.005009409971535206\n",
      "Epoch 1800, Loss: 0.007927935774205253, Final Batch Loss: 0.005491063464432955\n",
      "Epoch 1801, Loss: 0.0012376299264360568, Final Batch Loss: 4.4788093873648904e-06\n",
      "Epoch 1802, Loss: 0.007215949706733227, Final Batch Loss: 0.003472021082416177\n",
      "Epoch 1803, Loss: 0.005430663377637757, Final Batch Loss: 2.5629799438320333e-06\n",
      "Epoch 1804, Loss: 0.00547657156130299, Final Batch Loss: 0.001817546784877777\n",
      "Epoch 1805, Loss: 0.008905295577278594, Final Batch Loss: 1.942123708431609e-05\n",
      "Epoch 1806, Loss: 0.0039047769696480827, Final Batch Loss: 1.6296546164085157e-05\n",
      "Epoch 1807, Loss: 0.0027702992538252147, Final Batch Loss: 3.0266806788858958e-05\n",
      "Epoch 1808, Loss: 0.024685707303433446, Final Batch Loss: 1.8602888303576037e-05\n",
      "Epoch 1809, Loss: 0.007922580320155248, Final Batch Loss: 0.00014472761540673673\n",
      "Epoch 1810, Loss: 0.0034106250714103226, Final Batch Loss: 5.725394657929428e-05\n",
      "Epoch 1811, Loss: 0.003210742310329806, Final Batch Loss: 8.561801951145753e-05\n",
      "Epoch 1812, Loss: 0.0009320863282482605, Final Batch Loss: 3.437990017118864e-05\n",
      "Epoch 1813, Loss: 0.005778872181849692, Final Batch Loss: 1.336840227850189e-06\n",
      "Epoch 1814, Loss: 0.003910730963980313, Final Batch Loss: 0.0028512575663626194\n",
      "Epoch 1815, Loss: 0.0009588902413923961, Final Batch Loss: 1.2772413526818127e-07\n",
      "Epoch 1816, Loss: 0.0016909019905142486, Final Batch Loss: 0.00013467471580952406\n",
      "Epoch 1817, Loss: 0.005937058636845904, Final Batch Loss: 2.172714266635012e-05\n",
      "Epoch 1818, Loss: 0.022765506932046264, Final Batch Loss: 0.00019217563385609537\n",
      "Epoch 1819, Loss: 0.0034801893543772167, Final Batch Loss: 2.652264629432466e-05\n",
      "Epoch 1820, Loss: 0.0008415499073635146, Final Batch Loss: 4.351070401753532e-06\n",
      "Epoch 1821, Loss: 0.0032502342028806197, Final Batch Loss: 3.4059763720506453e-07\n",
      "Epoch 1822, Loss: 0.001777360579581, Final Batch Loss: 0.00014501626719720662\n",
      "Epoch 1823, Loss: 0.011761224042857066, Final Batch Loss: 0.009159582667052746\n",
      "Epoch 1824, Loss: 0.0017563663786859252, Final Batch Loss: 0.00010388445662101731\n",
      "Epoch 1825, Loss: 0.0012751202530125738, Final Batch Loss: 5.764443812950049e-06\n",
      "Epoch 1826, Loss: 0.012432278774213046, Final Batch Loss: 0.0003409622877370566\n",
      "Epoch 1827, Loss: 0.0024261373225726857, Final Batch Loss: 1.7285244666709332e-06\n",
      "Epoch 1828, Loss: 0.0021550157252931967, Final Batch Loss: 0.00025034151622094214\n",
      "Epoch 1829, Loss: 0.0013892813472011767, Final Batch Loss: 7.748562893539201e-07\n",
      "Epoch 1830, Loss: 0.002537627602578141, Final Batch Loss: 0.0009903042810037732\n",
      "Epoch 1831, Loss: 0.005648339854815276, Final Batch Loss: 0.004686103202402592\n",
      "Epoch 1832, Loss: 0.03475361987273118, Final Batch Loss: 8.685213970238692e-07\n",
      "Epoch 1833, Loss: 0.002357216128075379, Final Batch Loss: 4.061525032739155e-06\n",
      "Epoch 1834, Loss: 0.007717677060419703, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 1835, Loss: 0.006744919188776066, Final Batch Loss: 1.3623909467241901e-07\n",
      "Epoch 1836, Loss: 0.004798958805622533, Final Batch Loss: 0.0002455935173202306\n",
      "Epoch 1837, Loss: 0.0012691242211531062, Final Batch Loss: 3.8317216422001366e-07\n",
      "Epoch 1838, Loss: 0.001458337583244429, Final Batch Loss: 2.4161499823094346e-05\n",
      "Epoch 1839, Loss: 0.001596491136297118, Final Batch Loss: 7.305613689823076e-05\n",
      "Epoch 1840, Loss: 0.003008049119671341, Final Batch Loss: 0.0001219035912072286\n",
      "Epoch 1841, Loss: 0.002443866888086177, Final Batch Loss: 4.3426206275398727e-07\n",
      "Epoch 1842, Loss: 0.0023569375480292365, Final Batch Loss: 0.0009366085869260132\n",
      "Epoch 1843, Loss: 0.0007708177654421888, Final Batch Loss: 0.00011796901526395231\n",
      "Epoch 1844, Loss: 0.0008550725298270834, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 1845, Loss: 0.0044419722856083865, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1846, Loss: 0.0005718816537410021, Final Batch Loss: 9.61723126238212e-05\n",
      "Epoch 1847, Loss: 0.0027758641153923236, Final Batch Loss: 0.0012445293832570314\n",
      "Epoch 1848, Loss: 0.0009252927588931925, Final Batch Loss: 4.810873633687152e-06\n",
      "Epoch 1849, Loss: 0.0014917215918899274, Final Batch Loss: 5.875296551494102e-07\n",
      "Epoch 1850, Loss: 0.002093810668156948, Final Batch Loss: 0.0003125572402495891\n",
      "Epoch 1851, Loss: 0.0028839529425326305, Final Batch Loss: 6.81195828633463e-08\n",
      "Epoch 1852, Loss: 0.0016365965909699298, Final Batch Loss: 1.0558485428191489e-06\n",
      "Epoch 1853, Loss: 0.009781629885594612, Final Batch Loss: 3.8317176631608163e-07\n",
      "Epoch 1854, Loss: 0.0011881072650794522, Final Batch Loss: 8.30186309030978e-06\n",
      "Epoch 1855, Loss: 0.003470825255874388, Final Batch Loss: 7.493134148717218e-07\n",
      "Epoch 1856, Loss: 0.002383480103731017, Final Batch Loss: 6.386186441886821e-07\n",
      "Epoch 1857, Loss: 0.010039534274255857, Final Batch Loss: 0.0006347161834128201\n",
      "Epoch 1858, Loss: 0.00259933975758031, Final Batch Loss: 5.1013834308832884e-05\n",
      "Epoch 1859, Loss: 0.0029721039900323376, Final Batch Loss: 8.281123882625252e-05\n",
      "Epoch 1860, Loss: 0.0011595388605201151, Final Batch Loss: 5.778462582384236e-05\n",
      "Epoch 1861, Loss: 0.0010871151316678151, Final Batch Loss: 0.0002302827051607892\n",
      "Epoch 1862, Loss: 0.001419175197952427, Final Batch Loss: 0.0003112177364528179\n",
      "Epoch 1863, Loss: 0.0019111378401248658, Final Batch Loss: 6.019957709213486e-06\n",
      "Epoch 1864, Loss: 0.005167446197447134, Final Batch Loss: 1.8628797988640144e-05\n",
      "Epoch 1865, Loss: 0.002516017686062355, Final Batch Loss: 1.7029880439167755e-07\n",
      "Epoch 1866, Loss: 0.0022761553336749785, Final Batch Loss: 0.0003898227587342262\n",
      "Epoch 1867, Loss: 0.0026013253154815175, Final Batch Loss: 9.319443051936105e-05\n",
      "Epoch 1868, Loss: 0.0028438888202799717, Final Batch Loss: 2.350753675273154e-05\n",
      "Epoch 1869, Loss: 0.0021003779106649745, Final Batch Loss: 4.001965407951502e-06\n",
      "Epoch 1870, Loss: 0.0014101000215305248, Final Batch Loss: 1.615104883967433e-05\n",
      "Epoch 1871, Loss: 0.0013952052995591657, Final Batch Loss: 9.94486799754668e-06\n",
      "Epoch 1872, Loss: 0.002965407644555995, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1873, Loss: 0.0017119526792157558, Final Batch Loss: 8.523032192897517e-06\n",
      "Epoch 1874, Loss: 0.0011932169873034582, Final Batch Loss: 2.552376827225089e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1875, Loss: 0.0004315277793978112, Final Batch Loss: 2.809930776948022e-07\n",
      "Epoch 1876, Loss: 0.0005200217362428816, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 1877, Loss: 0.001046652662807901, Final Batch Loss: 7.748186362732667e-06\n",
      "Epoch 1878, Loss: 0.0005243719372174382, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 1879, Loss: 0.003992602980815718, Final Batch Loss: 5.781572781415889e-06\n",
      "Epoch 1880, Loss: 0.022264497805736028, Final Batch Loss: 0.00033225869992747903\n",
      "Epoch 1881, Loss: 0.0037282229587844995, Final Batch Loss: 1.030302996696264e-06\n",
      "Epoch 1882, Loss: 0.004362975865642937, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 1883, Loss: 0.001023997135234822, Final Batch Loss: 6.6074835558538325e-06\n",
      "Epoch 1884, Loss: 0.0019544032293197233, Final Batch Loss: 5.04879244545009e-05\n",
      "Epoch 1885, Loss: 0.0015883555024629459, Final Batch Loss: 0.0002875500067602843\n",
      "Epoch 1886, Loss: 0.013213385256676702, Final Batch Loss: 2.401090387138538e-05\n",
      "Epoch 1887, Loss: 0.0011782474575738888, Final Batch Loss: 2.920594852184877e-06\n",
      "Epoch 1888, Loss: 0.0008221731513913255, Final Batch Loss: 2.671501351869665e-05\n",
      "Epoch 1889, Loss: 0.0011914036185771693, Final Batch Loss: 1.9888164388248697e-05\n",
      "Epoch 1890, Loss: 0.01193974278976384, Final Batch Loss: 0.0017145045567303896\n",
      "Epoch 1891, Loss: 0.008679174456361238, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 1892, Loss: 0.0006877458151848259, Final Batch Loss: 3.0994040116638644e-06\n",
      "Epoch 1893, Loss: 0.0022162444656466107, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 1894, Loss: 0.019546864199469383, Final Batch Loss: 1.4305031754702213e-06\n",
      "Epoch 1895, Loss: 0.0026504737325012684, Final Batch Loss: 0.002064708387479186\n",
      "Epoch 1896, Loss: 0.0036579680029262818, Final Batch Loss: 2.8950319119758205e-06\n",
      "Epoch 1897, Loss: 0.021439852181536878, Final Batch Loss: 1.021793636368784e-07\n",
      "Epoch 1898, Loss: 0.002398234257270815, Final Batch Loss: 4.5148310164222494e-05\n",
      "Epoch 1899, Loss: 0.0008474468268104829, Final Batch Loss: 0.00015248687122948468\n",
      "Epoch 1900, Loss: 0.004037458333186805, Final Batch Loss: 0.00038526003481820226\n",
      "Epoch 1901, Loss: 0.003527816135473927, Final Batch Loss: 1.7029888965680584e-07\n",
      "Epoch 1902, Loss: 0.0011313364162788275, Final Batch Loss: 4.853505970459082e-07\n",
      "Epoch 1903, Loss: 0.000741971160096, Final Batch Loss: 1.1597088814596646e-05\n",
      "Epoch 1904, Loss: 0.004039839215693064, Final Batch Loss: 0.0013778617139905691\n",
      "Epoch 1905, Loss: 0.003976375486672623, Final Batch Loss: 3.916797140846029e-06\n",
      "Epoch 1906, Loss: 0.002330998769252801, Final Batch Loss: 8.344605930687976e-07\n",
      "Epoch 1907, Loss: 0.00215757594560273, Final Batch Loss: 4.8909278120845556e-05\n",
      "Epoch 1908, Loss: 0.002100419649025298, Final Batch Loss: 6.130752012722951e-07\n",
      "Epoch 1909, Loss: 0.0013742038647706067, Final Batch Loss: 2.7077041977463523e-06\n",
      "Epoch 1910, Loss: 0.09022630644540186, Final Batch Loss: 0.08920574933290482\n",
      "Epoch 1911, Loss: 0.00433031031570863, Final Batch Loss: 1.3282726285979152e-05\n",
      "Epoch 1912, Loss: 0.0024079145513908884, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 1913, Loss: 0.0074176496751245935, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 1914, Loss: 0.0020867829213102596, Final Batch Loss: 9.621859362596297e-07\n",
      "Epoch 1915, Loss: 0.0009931253371178173, Final Batch Loss: 0.00011219119187444448\n",
      "Epoch 1916, Loss: 0.016221913455183312, Final Batch Loss: 3.0823910037725e-06\n",
      "Epoch 1917, Loss: 0.03822599410705152, Final Batch Loss: 7.548130088252947e-05\n",
      "Epoch 1918, Loss: 0.0025384300424775574, Final Batch Loss: 5.474449062603526e-05\n",
      "Epoch 1919, Loss: 0.002509559946247464, Final Batch Loss: 5.917686848988524e-06\n",
      "Epoch 1920, Loss: 0.0056427252347930335, Final Batch Loss: 0.004216268192976713\n",
      "Epoch 1921, Loss: 0.007735042641357381, Final Batch Loss: 2.2990344916706817e-07\n",
      "Epoch 1922, Loss: 0.0016691645186028836, Final Batch Loss: 1.2602075685208547e-06\n",
      "Epoch 1923, Loss: 0.024125753983753384, Final Batch Loss: 8.454868293483742e-06\n",
      "Epoch 1924, Loss: 0.03382736547200693, Final Batch Loss: 6.403098723239964e-06\n",
      "Epoch 1925, Loss: 0.0028700763796223328, Final Batch Loss: 3.113556158496067e-05\n",
      "Epoch 1926, Loss: 0.0033985436347307996, Final Batch Loss: 1.1920919007479824e-07\n",
      "Epoch 1927, Loss: 0.0017311125229753088, Final Batch Loss: 5.300763950799592e-05\n",
      "Epoch 1928, Loss: 0.002125456766748357, Final Batch Loss: 9.536719289826578e-07\n",
      "Epoch 1929, Loss: 0.007341873084442341, Final Batch Loss: 2.2223848645808175e-06\n",
      "Epoch 1930, Loss: 0.0024796985344437417, Final Batch Loss: 0.0012758261291310191\n",
      "Epoch 1931, Loss: 0.000829974960627311, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 1932, Loss: 0.0026071206375490874, Final Batch Loss: 7.403334166156128e-05\n",
      "Epoch 1933, Loss: 0.0009189919730658858, Final Batch Loss: 3.916868251963024e-07\n",
      "Epoch 1934, Loss: 0.0011701384042979157, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 1935, Loss: 0.014704708144034129, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 1936, Loss: 0.007082243966578972, Final Batch Loss: 5.8431913203094155e-05\n",
      "Epoch 1937, Loss: 0.001353276467852993, Final Batch Loss: 2.307515387656167e-06\n",
      "Epoch 1938, Loss: 0.0027996860144412494, Final Batch Loss: 8.386733497900423e-06\n",
      "Epoch 1939, Loss: 0.001312211050390033, Final Batch Loss: 2.07058728847187e-05\n",
      "Epoch 1940, Loss: 0.0026147197738737304, Final Batch Loss: 2.8865276817668928e-06\n",
      "Epoch 1941, Loss: 0.0009010512994791497, Final Batch Loss: 5.432445504993666e-06\n",
      "Epoch 1942, Loss: 0.0019047664536628872, Final Batch Loss: 0.00103478052187711\n",
      "Epoch 1943, Loss: 0.002421131068590654, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1944, Loss: 0.002432575364114342, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1945, Loss: 0.0031593835810781457, Final Batch Loss: 0.00010981567174894735\n",
      "Epoch 1946, Loss: 0.001862169659943902, Final Batch Loss: 0.0008559632697142661\n",
      "Epoch 1947, Loss: 0.006751260744749743, Final Batch Loss: 9.442467671760824e-06\n",
      "Epoch 1948, Loss: 0.0028917246563651133, Final Batch Loss: 0.0014785368693992496\n",
      "Epoch 1949, Loss: 0.0014375922310136957, Final Batch Loss: 2.6042527679237537e-05\n",
      "Epoch 1950, Loss: 0.0036984605353040934, Final Batch Loss: 6.81192830143118e-07\n",
      "Epoch 1951, Loss: 0.001256922928178028, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 1952, Loss: 0.004162919587543001, Final Batch Loss: 8.599222201155499e-05\n",
      "Epoch 1953, Loss: 0.0011265526945862803, Final Batch Loss: 5.875080205441918e-06\n",
      "Epoch 1954, Loss: 0.0015511146430071676, Final Batch Loss: 2.8700453185592778e-05\n",
      "Epoch 1955, Loss: 0.0015015796161605977, Final Batch Loss: 0.00046931675751693547\n",
      "Epoch 1956, Loss: 0.0077892289294112516, Final Batch Loss: 2.21388560817104e-07\n",
      "Epoch 1957, Loss: 0.0012794251761079067, Final Batch Loss: 1.461942338210065e-05\n",
      "Epoch 1958, Loss: 0.0012407214344420936, Final Batch Loss: 4.8331738071283326e-05\n",
      "Epoch 1959, Loss: 0.0027666555615724064, Final Batch Loss: 0.0012563660275191069\n",
      "Epoch 1960, Loss: 0.001289970350097036, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 1961, Loss: 0.022060222538129892, Final Batch Loss: 0.0008753069560043514\n",
      "Epoch 1962, Loss: 0.0025531978774644415, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 1963, Loss: 0.0011007164439433836, Final Batch Loss: 6.786213816667441e-06\n",
      "Epoch 1964, Loss: 0.013185284806240816, Final Batch Loss: 0.002446184167638421\n",
      "Epoch 1965, Loss: 0.0019589699422795093, Final Batch Loss: 1.7275064237765037e-05\n",
      "Epoch 1966, Loss: 0.0006952785593696831, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 1967, Loss: 0.004358550897450186, Final Batch Loss: 0.0034564570523798466\n",
      "Epoch 1968, Loss: 0.03614176120936463, Final Batch Loss: 2.7618576496024616e-05\n",
      "Epoch 1969, Loss: 0.003252224219522759, Final Batch Loss: 2.2734689082426485e-06\n",
      "Epoch 1970, Loss: 0.0016584848362981575, Final Batch Loss: 2.5387807909282856e-05\n",
      "Epoch 1971, Loss: 0.004772855262899611, Final Batch Loss: 3.7124766549823107e-06\n",
      "Epoch 1972, Loss: 0.0009013662966026459, Final Batch Loss: 2.751674401224591e-05\n",
      "Epoch 1973, Loss: 0.001006285529001616, Final Batch Loss: 0.0001279175776289776\n",
      "Epoch 1974, Loss: 0.007591516793581832, Final Batch Loss: 8.301833986479323e-06\n",
      "Epoch 1975, Loss: 0.002331611051630489, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 1976, Loss: 0.001122433493861763, Final Batch Loss: 4.4277649635660055e-07\n",
      "Epoch 1977, Loss: 0.0022999605050983973, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 1978, Loss: 0.000625709412684472, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 1979, Loss: 0.024044520722512175, Final Batch Loss: 2.0435864200862852e-07\n",
      "Epoch 1980, Loss: 0.001292774781177286, Final Batch Loss: 1.8986855138791725e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1981, Loss: 0.0007670740596950054, Final Batch Loss: 1.0149102308787405e-05\n",
      "Epoch 1982, Loss: 0.008317099080159096, Final Batch Loss: 0.0022535226307809353\n",
      "Epoch 1983, Loss: 0.006747998180799186, Final Batch Loss: 0.0016048472607508302\n",
      "Epoch 1984, Loss: 0.020576472037646454, Final Batch Loss: 0.0007112607709132135\n",
      "Epoch 1985, Loss: 0.004614907382347155, Final Batch Loss: 0.0022264618892222643\n",
      "Epoch 1986, Loss: 0.0009477420862822328, Final Batch Loss: 2.279955879203044e-05\n",
      "Epoch 1987, Loss: 0.0008321547338709934, Final Batch Loss: 8.179804717656225e-05\n",
      "Epoch 1988, Loss: 0.015213931648759171, Final Batch Loss: 0.0002518843684811145\n",
      "Epoch 1989, Loss: 0.0005848064273195064, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 1990, Loss: 0.011098954076317114, Final Batch Loss: 6.897089974700066e-07\n",
      "Epoch 1991, Loss: 0.004845580419896578, Final Batch Loss: 1.1920847100554965e-06\n",
      "Epoch 1992, Loss: 0.0010593879705993459, Final Batch Loss: 9.954829147318378e-05\n",
      "Epoch 1993, Loss: 0.016430103478342062, Final Batch Loss: 0.0035062183160334826\n",
      "Epoch 1994, Loss: 0.001428037484174638, Final Batch Loss: 2.2990013803791953e-06\n",
      "Epoch 1995, Loss: 0.005870049040822778, Final Batch Loss: 0.0013018163153901696\n",
      "Epoch 1996, Loss: 0.00151963195821736, Final Batch Loss: 0.00023227378551382571\n",
      "Epoch 1997, Loss: 0.01513180597947894, Final Batch Loss: 6.045590339454066e-07\n",
      "Epoch 1998, Loss: 0.001326303425230435, Final Batch Loss: 1.7913216652232222e-05\n",
      "Epoch 1999, Loss: 0.0035330016710304335, Final Batch Loss: 2.750277644736343e-06\n",
      "Epoch 2000, Loss: 0.002742733667673747, Final Batch Loss: 5.185469035495771e-06\n",
      "Epoch 2001, Loss: 0.01731121770308164, Final Batch Loss: 3.388911409274442e-06\n",
      "Epoch 2002, Loss: 0.004960173333529383, Final Batch Loss: 0.00016724133456591517\n",
      "Epoch 2003, Loss: 0.003874382389767561, Final Batch Loss: 1.7054477211786434e-05\n",
      "Epoch 2004, Loss: 0.0007700997239226126, Final Batch Loss: 5.883616722712759e-06\n",
      "Epoch 2005, Loss: 0.0014246079029227587, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2006, Loss: 0.027658319846523227, Final Batch Loss: 0.0015082710888236761\n",
      "Epoch 2007, Loss: 0.0014646398994955234, Final Batch Loss: 7.28110535419546e-05\n",
      "Epoch 2008, Loss: 0.0024396517392233363, Final Batch Loss: 5.151464392838534e-06\n",
      "Epoch 2009, Loss: 0.0010521817657718202, Final Batch Loss: 8.199733201763593e-06\n",
      "Epoch 2010, Loss: 0.0005653895423165523, Final Batch Loss: 5.524936568690464e-05\n",
      "Epoch 2011, Loss: 0.0010293510234760106, Final Batch Loss: 1.3027814702581964e-06\n",
      "Epoch 2012, Loss: 0.0010194786282227142, Final Batch Loss: 1.8477203411748633e-06\n",
      "Epoch 2013, Loss: 0.008525016951239195, Final Batch Loss: 1.4049591072762269e-06\n",
      "Epoch 2014, Loss: 0.0014695318241138011, Final Batch Loss: 7.09124724380672e-05\n",
      "Epoch 2015, Loss: 0.0013593878684332594, Final Batch Loss: 4.193262429907918e-05\n",
      "Epoch 2016, Loss: 0.00399627463411889, Final Batch Loss: 1.93782016140176e-05\n",
      "Epoch 2017, Loss: 0.0009165684296021936, Final Batch Loss: 8.6169002315728e-06\n",
      "Epoch 2018, Loss: 0.0014857288333587348, Final Batch Loss: 0.0005076347733847797\n",
      "Epoch 2019, Loss: 0.004382749321848678, Final Batch Loss: 9.144535397354048e-06\n",
      "Epoch 2020, Loss: 0.014626841802964918, Final Batch Loss: 0.00041067571146413684\n",
      "Epoch 2021, Loss: 0.0011938278730667662, Final Batch Loss: 0.0002777966146823019\n",
      "Epoch 2022, Loss: 0.013385366218301442, Final Batch Loss: 4.1723166077645146e-07\n",
      "Epoch 2023, Loss: 0.0019455584661045577, Final Batch Loss: 0.0008658790611661971\n",
      "Epoch 2024, Loss: 0.03550026168522891, Final Batch Loss: 0.0032805302180349827\n",
      "Epoch 2025, Loss: 0.0004713547817800645, Final Batch Loss: 1.7881169469546876e-06\n",
      "Epoch 2026, Loss: 0.007940782837977167, Final Batch Loss: 6.479079456767067e-05\n",
      "Epoch 2027, Loss: 0.001270017120987177, Final Batch Loss: 0.00022090553829912096\n",
      "Epoch 2028, Loss: 0.003056902962271124, Final Batch Loss: 0.0\n",
      "Epoch 2029, Loss: 0.0004369955918264168, Final Batch Loss: 4.972559054294834e-06\n",
      "Epoch 2030, Loss: 0.022103392868302763, Final Batch Loss: 5.628222425002605e-06\n",
      "Epoch 2031, Loss: 0.0029477289520514205, Final Batch Loss: 5.194108894102101e-07\n",
      "Epoch 2032, Loss: 0.002439775147649925, Final Batch Loss: 0.0\n",
      "Epoch 2033, Loss: 0.0033442694176528676, Final Batch Loss: 1.0558497933743638e-06\n",
      "Epoch 2034, Loss: 0.0026030881831502484, Final Batch Loss: 6.675426902802428e-06\n",
      "Epoch 2035, Loss: 0.002074747950814526, Final Batch Loss: 1.5241608934957185e-06\n",
      "Epoch 2036, Loss: 0.0018237364211017848, Final Batch Loss: 1.1605531653913204e-05\n",
      "Epoch 2037, Loss: 0.0010799312985909637, Final Batch Loss: 5.083264113636687e-06\n",
      "Epoch 2038, Loss: 0.006417536607841612, Final Batch Loss: 0.002964082872495055\n",
      "Epoch 2039, Loss: 0.01988387287627802, Final Batch Loss: 3.320826067465532e-07\n",
      "Epoch 2040, Loss: 0.0009630599142838037, Final Batch Loss: 2.7746018531615846e-05\n",
      "Epoch 2041, Loss: 0.0016729214366932865, Final Batch Loss: 3.244127583457157e-06\n",
      "Epoch 2042, Loss: 0.0007438842881128949, Final Batch Loss: 4.819311016035499e-06\n",
      "Epoch 2043, Loss: 0.07009837651139605, Final Batch Loss: 6.3860775298962835e-06\n",
      "Epoch 2044, Loss: 0.0026728984630608466, Final Batch Loss: 4.2545183532638475e-05\n",
      "Epoch 2045, Loss: 0.0010131453518624767, Final Batch Loss: 7.1693857535137795e-06\n",
      "Epoch 2046, Loss: 0.03189015259340522, Final Batch Loss: 3.594263762352057e-05\n",
      "Epoch 2047, Loss: 0.0029354615140846363, Final Batch Loss: 6.811930006733746e-07\n",
      "Epoch 2048, Loss: 0.023049954517773585, Final Batch Loss: 3.4314980439376086e-06\n",
      "Epoch 2049, Loss: 0.030761426452954765, Final Batch Loss: 6.42850500298664e-06\n",
      "Epoch 2050, Loss: 0.0064795126927492674, Final Batch Loss: 0.00045623318874277174\n",
      "Epoch 2051, Loss: 0.0036004040302941576, Final Batch Loss: 0.00022509794507641345\n",
      "Epoch 2052, Loss: 0.07842467828595545, Final Batch Loss: 0.001133098267018795\n",
      "Epoch 2053, Loss: 0.008006904481590027, Final Batch Loss: 1.7836940969573334e-05\n",
      "Epoch 2054, Loss: 0.001730991731164977, Final Batch Loss: 5.116910324431956e-05\n",
      "Epoch 2055, Loss: 0.04971805928505546, Final Batch Loss: 8.68522306518571e-07\n",
      "Epoch 2056, Loss: 0.004047162927008685, Final Batch Loss: 2.043563426923356e-06\n",
      "Epoch 2057, Loss: 0.002203779193223454, Final Batch Loss: 3.670743899419904e-05\n",
      "Epoch 2058, Loss: 0.00715633879735833, Final Batch Loss: 0.0003105713112745434\n",
      "Epoch 2059, Loss: 0.03912299988223822, Final Batch Loss: 4.105142943444662e-05\n",
      "Epoch 2060, Loss: 0.0053132909088162705, Final Batch Loss: 0.0015298804501071572\n",
      "Epoch 2061, Loss: 0.0026770069453050382, Final Batch Loss: 0.00011961643031099811\n",
      "Epoch 2062, Loss: 0.002553047251069529, Final Batch Loss: 9.110979704018973e-07\n",
      "Epoch 2063, Loss: 0.011397744881833205, Final Batch Loss: 2.4011860659811646e-06\n",
      "Epoch 2064, Loss: 0.002537706575822085, Final Batch Loss: 0.0012567073572427034\n",
      "Epoch 2065, Loss: 0.0011911994579349994, Final Batch Loss: 1.4465606909652706e-05\n",
      "Epoch 2066, Loss: 0.003412246100651828, Final Batch Loss: 3.193047177774133e-06\n",
      "Epoch 2067, Loss: 0.005861999297849252, Final Batch Loss: 1.3538719940697774e-06\n",
      "Epoch 2068, Loss: 0.0015155582500483433, Final Batch Loss: 3.031293545063818e-06\n",
      "Epoch 2069, Loss: 0.006433723261579871, Final Batch Loss: 0.0010485842358320951\n",
      "Epoch 2070, Loss: 0.010294589803379495, Final Batch Loss: 9.857312397798523e-05\n",
      "Epoch 2071, Loss: 0.0024921921867644414, Final Batch Loss: 0.0015114540001377463\n",
      "Epoch 2072, Loss: 0.0011596520289458567, Final Batch Loss: 9.442717782803811e-06\n",
      "Epoch 2073, Loss: 0.007657963349629426, Final Batch Loss: 2.2588039428228512e-05\n",
      "Epoch 2074, Loss: 0.004223397889290936, Final Batch Loss: 0.0005089106853120029\n",
      "Epoch 2075, Loss: 0.004905137689547701, Final Batch Loss: 5.832616352563491e-06\n",
      "Epoch 2076, Loss: 0.007279994428245118, Final Batch Loss: 3.3122487366199493e-06\n",
      "Epoch 2077, Loss: 0.00732387909832255, Final Batch Loss: 3.4911229818135325e-07\n",
      "Epoch 2078, Loss: 0.001057523315466824, Final Batch Loss: 2.004182715609204e-05\n",
      "Epoch 2079, Loss: 0.0013258524668344762, Final Batch Loss: 3.544760329532437e-05\n",
      "Epoch 2080, Loss: 0.005583159410150529, Final Batch Loss: 2.809931061165116e-07\n",
      "Epoch 2081, Loss: 0.003248793746024603, Final Batch Loss: 1.9727365724975243e-05\n",
      "Epoch 2082, Loss: 0.0011330645673979234, Final Batch Loss: 6.726794481437537e-07\n",
      "Epoch 2083, Loss: 0.00437667231017258, Final Batch Loss: 0.00013289711205288768\n",
      "Epoch 2084, Loss: 0.004038878018036485, Final Batch Loss: 0.00032711485982872546\n",
      "Epoch 2085, Loss: 0.0006746761482645525, Final Batch Loss: 1.1724388969014399e-05\n",
      "Epoch 2086, Loss: 0.001581754780090705, Final Batch Loss: 1.3920708624937106e-05\n",
      "Epoch 2087, Loss: 0.00032128176409429443, Final Batch Loss: 1.0217937784773312e-07\n",
      "Epoch 2088, Loss: 0.006310275524811004, Final Batch Loss: 2.6079478629981168e-05\n",
      "Epoch 2089, Loss: 0.0004534547146022305, Final Batch Loss: 5.875293709323159e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2090, Loss: 0.0012143378319251497, Final Batch Loss: 1.7796030533645535e-06\n",
      "Epoch 2091, Loss: 0.0030728988263035717, Final Batch Loss: 7.356682999670738e-06\n",
      "Epoch 2092, Loss: 0.002425894167970455, Final Batch Loss: 9.536719858260767e-07\n",
      "Epoch 2093, Loss: 0.002128416537289013, Final Batch Loss: 7.177944553404814e-06\n",
      "Epoch 2094, Loss: 0.001919973784879403, Final Batch Loss: 5.074774435342988e-06\n",
      "Epoch 2095, Loss: 0.001034035911288811, Final Batch Loss: 0.00017742345517035574\n",
      "Epoch 2096, Loss: 0.0031879362231848063, Final Batch Loss: 2.3073633201420307e-05\n",
      "Epoch 2097, Loss: 0.0038599258186877705, Final Batch Loss: 5.565615356317721e-05\n",
      "Epoch 2098, Loss: 0.0018086107027102116, Final Batch Loss: 2.7928851977776503e-06\n",
      "Epoch 2099, Loss: 0.0017672295944066718, Final Batch Loss: 0.0015138882445171475\n",
      "Epoch 2100, Loss: 0.029138937679533683, Final Batch Loss: 5.534708975574176e-07\n",
      "Epoch 2101, Loss: 0.0020230343943694606, Final Batch Loss: 5.064907600171864e-05\n",
      "Epoch 2102, Loss: 0.004286986557417549, Final Batch Loss: 0.0001652182691032067\n",
      "Epoch 2103, Loss: 0.002637207426232635, Final Batch Loss: 2.6145451556658372e-05\n",
      "Epoch 2104, Loss: 0.0005009847127439571, Final Batch Loss: 5.125865754962433e-06\n",
      "Epoch 2105, Loss: 0.0015081678693604772, Final Batch Loss: 8.344622983713634e-07\n",
      "Epoch 2106, Loss: 0.0024971362900032545, Final Batch Loss: 5.807119123346638e-06\n",
      "Epoch 2107, Loss: 0.0009859750513143695, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2108, Loss: 0.0027110024166177027, Final Batch Loss: 0.001976475352421403\n",
      "Epoch 2109, Loss: 0.0004981146557838656, Final Batch Loss: 5.3275900427252054e-05\n",
      "Epoch 2110, Loss: 0.0061728688451694325, Final Batch Loss: 0.005653751082718372\n",
      "Epoch 2111, Loss: 0.0016747558656788897, Final Batch Loss: 2.5287470634793863e-05\n",
      "Epoch 2112, Loss: 0.006637794192783986, Final Batch Loss: 3.7550141769315815e-06\n",
      "Epoch 2113, Loss: 0.01058935585024301, Final Batch Loss: 9.948122169589624e-05\n",
      "Epoch 2114, Loss: 0.014509022397987792, Final Batch Loss: 3.09090160044434e-06\n",
      "Epoch 2115, Loss: 0.0010493423476418684, Final Batch Loss: 3.252644773965585e-06\n",
      "Epoch 2116, Loss: 0.0006509312697744463, Final Batch Loss: 5.735611557611264e-05\n",
      "Epoch 2117, Loss: 0.018287859425072384, Final Batch Loss: 1.2643923582800198e-05\n",
      "Epoch 2118, Loss: 0.000607028301601531, Final Batch Loss: 2.574546670075506e-05\n",
      "Epoch 2119, Loss: 0.001996637918637134, Final Batch Loss: 9.94717629509978e-05\n",
      "Epoch 2120, Loss: 0.015872788434279528, Final Batch Loss: 2.72477990392872e-07\n",
      "Epoch 2121, Loss: 0.0009990063772420399, Final Batch Loss: 8.911728218663484e-05\n",
      "Epoch 2122, Loss: 0.011311839884001529, Final Batch Loss: 3.190690404153429e-05\n",
      "Epoch 2123, Loss: 0.0011959062035202805, Final Batch Loss: 7.322484179894673e-06\n",
      "Epoch 2124, Loss: 0.0037783311290695565, Final Batch Loss: 1.6857900845934637e-05\n",
      "Epoch 2125, Loss: 0.0027919529675273225, Final Batch Loss: 0.00048635495477356017\n",
      "Epoch 2126, Loss: 0.0033316933131573023, Final Batch Loss: 0.000116527451609727\n",
      "Epoch 2127, Loss: 0.03516951527922174, Final Batch Loss: 3.3122421427833615e-06\n",
      "Epoch 2128, Loss: 0.0027772641133196885, Final Batch Loss: 2.282527020724956e-05\n",
      "Epoch 2129, Loss: 0.001259122135479629, Final Batch Loss: 3.201549361619982e-06\n",
      "Epoch 2130, Loss: 0.0026606058325455706, Final Batch Loss: 2.4693309796930407e-07\n",
      "Epoch 2131, Loss: 0.000610076162047335, Final Batch Loss: 1.6960681023192592e-05\n",
      "Epoch 2132, Loss: 0.0005873134250578005, Final Batch Loss: 6.00283601670526e-06\n",
      "Epoch 2133, Loss: 0.0019301837892271578, Final Batch Loss: 0.00041975599015131593\n",
      "Epoch 2134, Loss: 0.0038786181030445732, Final Batch Loss: 0.0009832950308918953\n",
      "Epoch 2135, Loss: 0.007227899496257351, Final Batch Loss: 1.3623915151583788e-07\n",
      "Epoch 2136, Loss: 0.0013918691079197743, Final Batch Loss: 4.351034021965461e-06\n",
      "Epoch 2137, Loss: 0.030258157235948602, Final Batch Loss: 0.0011353862937539816\n",
      "Epoch 2138, Loss: 0.0008273579605884152, Final Batch Loss: 7.893135261838324e-06\n",
      "Epoch 2139, Loss: 0.0014418480295717018, Final Batch Loss: 2.2561320292879827e-05\n",
      "Epoch 2140, Loss: 0.0010741812483843205, Final Batch Loss: 4.683215024670062e-07\n",
      "Epoch 2141, Loss: 0.11497249592503067, Final Batch Loss: 0.11154843121767044\n",
      "Epoch 2142, Loss: 0.03607778951754881, Final Batch Loss: 1.163899196399143e-05\n",
      "Epoch 2143, Loss: 0.1272633043990936, Final Batch Loss: 4.739555879496038e-05\n",
      "Epoch 2144, Loss: 0.12544630436514126, Final Batch Loss: 1.0813767403305974e-05\n",
      "Epoch 2145, Loss: 0.06158201862581336, Final Batch Loss: 1.4482943697657902e-05\n",
      "Epoch 2146, Loss: 0.058005896062240936, Final Batch Loss: 0.03079971671104431\n",
      "Epoch 2147, Loss: 0.07880355192901334, Final Batch Loss: 0.00035212564398534596\n",
      "Epoch 2148, Loss: 0.060057740815693705, Final Batch Loss: 5.279260335555591e-07\n",
      "Epoch 2149, Loss: 0.015964186261044233, Final Batch Loss: 8.182460078387521e-06\n",
      "Epoch 2150, Loss: 0.0012115326752564215, Final Batch Loss: 1.0047587011285941e-06\n",
      "Epoch 2151, Loss: 0.05693365423576324, Final Batch Loss: 0.03848474472761154\n",
      "Epoch 2152, Loss: 0.41829363629221916, Final Batch Loss: 0.34643641114234924\n",
      "Epoch 2153, Loss: 0.030735701999674347, Final Batch Loss: 4.070091108587803e-06\n",
      "Epoch 2154, Loss: 0.04695340276521165, Final Batch Loss: 9.016341937240213e-05\n",
      "Epoch 2155, Loss: 0.010761473867091809, Final Batch Loss: 1.5241683968270081e-06\n",
      "Epoch 2156, Loss: 0.03310473449528217, Final Batch Loss: 0.003667940851300955\n",
      "Epoch 2157, Loss: 0.006363435539242346, Final Batch Loss: 7.373579137492925e-06\n",
      "Epoch 2158, Loss: 0.009775224141776562, Final Batch Loss: 0.0004917035112157464\n",
      "Epoch 2159, Loss: 0.008520342180418083, Final Batch Loss: 4.404169521876611e-05\n",
      "Epoch 2160, Loss: 0.014900821552146226, Final Batch Loss: 0.006444419268518686\n",
      "Epoch 2161, Loss: 0.009263207706680987, Final Batch Loss: 7.764300244161859e-05\n",
      "Epoch 2162, Loss: 0.010712606686865911, Final Batch Loss: 0.00028418353758752346\n",
      "Epoch 2163, Loss: 0.006295660082287213, Final Batch Loss: 1.0924334674200509e-05\n",
      "Epoch 2164, Loss: 0.012235957372467965, Final Batch Loss: 0.0070315031334757805\n",
      "Epoch 2165, Loss: 0.011265060064033605, Final Batch Loss: 0.00016659566608723253\n",
      "Epoch 2166, Loss: 0.0035754721830016933, Final Batch Loss: 0.0001060602007783018\n",
      "Epoch 2167, Loss: 0.004218349088660034, Final Batch Loss: 5.287701242195908e-06\n",
      "Epoch 2168, Loss: 0.005729677493945928, Final Batch Loss: 4.229839032632299e-05\n",
      "Epoch 2169, Loss: 0.005159669788554311, Final Batch Loss: 0.0004113794129807502\n",
      "Epoch 2170, Loss: 0.0028311843761912314, Final Batch Loss: 1.3546041373047046e-05\n",
      "Epoch 2171, Loss: 0.004486532576265745, Final Batch Loss: 0.00012508311192505062\n",
      "Epoch 2172, Loss: 0.008786901487837895, Final Batch Loss: 1.7650052541284822e-05\n",
      "Epoch 2173, Loss: 0.003899393370375037, Final Batch Loss: 0.0006205990212038159\n",
      "Epoch 2174, Loss: 0.005731448914048087, Final Batch Loss: 6.658538950432558e-06\n",
      "Epoch 2175, Loss: 0.005431490310002118, Final Batch Loss: 8.930847980082035e-05\n",
      "Epoch 2176, Loss: 0.0016193783085327595, Final Batch Loss: 0.00044474052265286446\n",
      "Epoch 2177, Loss: 0.005468553223181516, Final Batch Loss: 0.0005174129037186503\n",
      "Epoch 2178, Loss: 0.0028236842626938596, Final Batch Loss: 0.00033524009631946683\n",
      "Epoch 2179, Loss: 0.0018711738758838692, Final Batch Loss: 1.6263458064713632e-06\n",
      "Epoch 2180, Loss: 0.010058770822070073, Final Batch Loss: 0.0087242117151618\n",
      "Epoch 2181, Loss: 0.0014418940845644102, Final Batch Loss: 3.2460244256071746e-05\n",
      "Epoch 2182, Loss: 0.0019757025002036244, Final Batch Loss: 0.00034313343348912895\n",
      "Epoch 2183, Loss: 0.002755302016339556, Final Batch Loss: 1.1775356142607052e-05\n",
      "Epoch 2184, Loss: 0.001549226753468247, Final Batch Loss: 3.2867224035726395e-06\n",
      "Epoch 2185, Loss: 0.022341477622831007, Final Batch Loss: 5.872363908565603e-05\n",
      "Epoch 2186, Loss: 0.0027997985423553473, Final Batch Loss: 3.4655065519473283e-06\n",
      "Epoch 2187, Loss: 0.0032698815630283207, Final Batch Loss: 0.00043322666897438467\n",
      "Epoch 2188, Loss: 0.0022918447093616123, Final Batch Loss: 3.823111001111101e-06\n",
      "Epoch 2189, Loss: 0.006495198071775121, Final Batch Loss: 1.5922820466585108e-06\n",
      "Epoch 2190, Loss: 0.00157189613673836, Final Batch Loss: 0.0002696227456908673\n",
      "Epoch 2191, Loss: 0.0011317791359033436, Final Batch Loss: 0.00017948362801689655\n",
      "Epoch 2192, Loss: 0.02346312493318692, Final Batch Loss: 0.02032918855547905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2193, Loss: 0.005643785261781886, Final Batch Loss: 0.004023391753435135\n",
      "Epoch 2194, Loss: 0.0021009347183280624, Final Batch Loss: 6.123177445260808e-05\n",
      "Epoch 2195, Loss: 0.0026147413736907765, Final Batch Loss: 0.00014792627189308405\n",
      "Epoch 2196, Loss: 0.009680479170697254, Final Batch Loss: 1.2176338941571885e-06\n",
      "Epoch 2197, Loss: 0.0014521926932502538, Final Batch Loss: 0.00033229493419639766\n",
      "Epoch 2198, Loss: 0.0039627309088245966, Final Batch Loss: 0.003244108986109495\n",
      "Epoch 2199, Loss: 0.002199590673626517, Final Batch Loss: 1.907191654026974e-05\n",
      "Epoch 2200, Loss: 0.011920294738729353, Final Batch Loss: 2.4267353637696942e-06\n",
      "Epoch 2201, Loss: 0.0010812960153998574, Final Batch Loss: 1.8934782929136418e-05\n",
      "Epoch 2202, Loss: 0.001823178797167202, Final Batch Loss: 1.3188734556024428e-05\n",
      "Epoch 2203, Loss: 0.0010825209901668131, Final Batch Loss: 9.224401583196595e-05\n",
      "Epoch 2204, Loss: 0.005322384997271001, Final Batch Loss: 0.002152232686057687\n",
      "Epoch 2205, Loss: 0.003193359909346327, Final Batch Loss: 0.00025998865021392703\n",
      "Epoch 2206, Loss: 0.0018934662075480446, Final Batch Loss: 0.0010669471230357885\n",
      "Epoch 2207, Loss: 0.004040492698550224, Final Batch Loss: 0.0027437005192041397\n",
      "Epoch 2208, Loss: 0.002078850051475456, Final Batch Loss: 0.00016369635704904795\n",
      "Epoch 2209, Loss: 0.0008004978832332199, Final Batch Loss: 1.4304993101177388e-06\n",
      "Epoch 2210, Loss: 0.0020763521788467187, Final Batch Loss: 0.0011670921230688691\n",
      "Epoch 2211, Loss: 0.0030228223149606492, Final Batch Loss: 3.52860770362895e-05\n",
      "Epoch 2212, Loss: 0.0012532733767329773, Final Batch Loss: 4.197771431790898e-06\n",
      "Epoch 2213, Loss: 0.001331137807937921, Final Batch Loss: 2.2314294255920686e-05\n",
      "Epoch 2214, Loss: 0.00812488050723914, Final Batch Loss: 0.0071502807550132275\n",
      "Epoch 2215, Loss: 0.0016593807722529164, Final Batch Loss: 2.6955813154927455e-05\n",
      "Epoch 2216, Loss: 0.0010860452175620594, Final Batch Loss: 1.4967722563596908e-05\n",
      "Epoch 2217, Loss: 0.006184677222336177, Final Batch Loss: 8.160330617101863e-05\n",
      "Epoch 2218, Loss: 0.002781097437036806, Final Batch Loss: 2.4546401618863456e-05\n",
      "Epoch 2219, Loss: 0.001374093361391715, Final Batch Loss: 5.943188170931535e-06\n",
      "Epoch 2220, Loss: 0.006215759905899176, Final Batch Loss: 3.1569925340591e-05\n",
      "Epoch 2221, Loss: 0.0013406770085566677, Final Batch Loss: 0.00023243464238476008\n",
      "Epoch 2222, Loss: 0.0009686325065558776, Final Batch Loss: 0.00020779704209417105\n",
      "Epoch 2223, Loss: 0.002257673528220039, Final Batch Loss: 0.00010293832019669935\n",
      "Epoch 2224, Loss: 0.005764368615928106, Final Batch Loss: 0.004914934281259775\n",
      "Epoch 2225, Loss: 0.000752460442811298, Final Batch Loss: 7.833717177163635e-07\n",
      "Epoch 2226, Loss: 0.002075800302918651, Final Batch Loss: 8.931960110203363e-06\n",
      "Epoch 2227, Loss: 0.010108161353855394, Final Batch Loss: 0.008479142561554909\n",
      "Epoch 2228, Loss: 0.00037354905862230225, Final Batch Loss: 4.895953225059202e-06\n",
      "Epoch 2229, Loss: 0.005345535799278878, Final Batch Loss: 0.00025047536473721266\n",
      "Epoch 2230, Loss: 0.0015592071968058008, Final Batch Loss: 8.250567589129787e-06\n",
      "Epoch 2231, Loss: 0.0005777037931693485, Final Batch Loss: 2.181202216888778e-05\n",
      "Epoch 2232, Loss: 0.0017474281612521736, Final Batch Loss: 1.68497772392584e-05\n",
      "Epoch 2233, Loss: 0.00724834590171497, Final Batch Loss: 1.5326902769174922e-07\n",
      "Epoch 2234, Loss: 0.010460578261699993, Final Batch Loss: 0.00013949362619314343\n",
      "Epoch 2235, Loss: 0.0015966458686307305, Final Batch Loss: 2.3160300770541653e-06\n",
      "Epoch 2236, Loss: 0.0005217282594003336, Final Batch Loss: 2.980229965032777e-07\n",
      "Epoch 2237, Loss: 0.0008232252788502592, Final Batch Loss: 6.556496146004065e-07\n",
      "Epoch 2238, Loss: 0.01131720796576019, Final Batch Loss: 8.514910518897523e-07\n",
      "Epoch 2239, Loss: 0.009282724294280342, Final Batch Loss: 1.4193009519658517e-05\n",
      "Epoch 2240, Loss: 0.0025684619262165143, Final Batch Loss: 1.0558482017586357e-06\n",
      "Epoch 2241, Loss: 0.003072226563745062, Final Batch Loss: 8.727538443054073e-06\n",
      "Epoch 2242, Loss: 0.0006487169457614073, Final Batch Loss: 1.0149117770197336e-05\n",
      "Epoch 2243, Loss: 0.0004068905396934497, Final Batch Loss: 6.47134243081382e-07\n",
      "Epoch 2244, Loss: 0.0010905244344030507, Final Batch Loss: 4.409243774716742e-05\n",
      "Epoch 2245, Loss: 0.0018975812308781315, Final Batch Loss: 0.0006502981996163726\n",
      "Epoch 2246, Loss: 0.0012553853915022728, Final Batch Loss: 1.6178391604171338e-07\n",
      "Epoch 2247, Loss: 0.0011732672127493515, Final Batch Loss: 4.7683616344329494e-07\n",
      "Epoch 2248, Loss: 0.0006375247808136919, Final Batch Loss: 2.333073553018039e-06\n",
      "Epoch 2249, Loss: 0.00033337158015456225, Final Batch Loss: 3.2866962555999635e-06\n",
      "Epoch 2250, Loss: 0.0009664924000389874, Final Batch Loss: 0.00019709192565642297\n",
      "Epoch 2251, Loss: 0.005617728937068023, Final Batch Loss: 0.003577661234885454\n",
      "Epoch 2252, Loss: 0.0007058623705233913, Final Batch Loss: 8.69327413965948e-06\n",
      "Epoch 2253, Loss: 0.0012372936257634137, Final Batch Loss: 4.146714218222769e-06\n",
      "Epoch 2254, Loss: 0.0005159043437288346, Final Batch Loss: 4.1723137655935716e-07\n",
      "Epoch 2255, Loss: 0.0016947195982766061, Final Batch Loss: 1.7540588714837213e-06\n",
      "Epoch 2256, Loss: 0.0008103587861114647, Final Batch Loss: 5.74362748011481e-05\n",
      "Epoch 2257, Loss: 0.010611228901325376, Final Batch Loss: 1.684058406681288e-05\n",
      "Epoch 2258, Loss: 0.0020238118959241547, Final Batch Loss: 0.00163101009093225\n",
      "Epoch 2259, Loss: 0.0011030608441160439, Final Batch Loss: 2.6055352009279886e-06\n",
      "Epoch 2260, Loss: 0.0010080879073299798, Final Batch Loss: 1.1920922560193503e-07\n",
      "Epoch 2261, Loss: 0.0006298834146036825, Final Batch Loss: 6.4625551203789655e-06\n",
      "Epoch 2262, Loss: 0.002774126725853421, Final Batch Loss: 0.0014284912031143904\n",
      "Epoch 2263, Loss: 0.000973610814753556, Final Batch Loss: 2.682166950762621e-06\n",
      "Epoch 2264, Loss: 0.03530102899094345, Final Batch Loss: 4.962494131177664e-05\n",
      "Epoch 2265, Loss: 0.023845301996971102, Final Batch Loss: 2.2904982870386448e-06\n",
      "Epoch 2266, Loss: 0.0031106029982765904, Final Batch Loss: 1.0303047019988298e-06\n",
      "Epoch 2267, Loss: 0.013662386976648122, Final Batch Loss: 0.0010711053619161248\n",
      "Epoch 2268, Loss: 0.02004894560741377, Final Batch Loss: 0.0004205398145131767\n",
      "Epoch 2269, Loss: 0.002485072004283495, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 2270, Loss: 0.0012254455275666487, Final Batch Loss: 1.4475405407665676e-07\n",
      "Epoch 2271, Loss: 0.0043445013242262576, Final Batch Loss: 1.0047614296126994e-06\n",
      "Epoch 2272, Loss: 0.0022145437033032067, Final Batch Loss: 0.0015749039594084024\n",
      "Epoch 2273, Loss: 0.0016079410340807954, Final Batch Loss: 1.5071307188918581e-06\n",
      "Epoch 2274, Loss: 0.0009641726178415411, Final Batch Loss: 2.8184081202198286e-06\n",
      "Epoch 2275, Loss: 0.0025536155299050733, Final Batch Loss: 0.0002091553615173325\n",
      "Epoch 2276, Loss: 0.001763138294336386, Final Batch Loss: 0.0\n",
      "Epoch 2277, Loss: 0.014034428233571816, Final Batch Loss: 0.0001201794293592684\n",
      "Epoch 2278, Loss: 0.001524247669770773, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 2279, Loss: 0.0038880353640706744, Final Batch Loss: 2.918435711762868e-05\n",
      "Epoch 2280, Loss: 0.001243179485300061, Final Batch Loss: 5.492001491802512e-06\n",
      "Epoch 2281, Loss: 0.0007567683132947423, Final Batch Loss: 0.0001709203061182052\n",
      "Epoch 2282, Loss: 0.0010292576002157716, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2283, Loss: 0.0010506840044399723, Final Batch Loss: 0.00048464463907293975\n",
      "Epoch 2284, Loss: 0.0009295246617853081, Final Batch Loss: 2.469332116561418e-07\n",
      "Epoch 2285, Loss: 0.0007471638573406381, Final Batch Loss: 1.0149103218282107e-05\n",
      "Epoch 2286, Loss: 0.001777566102646233, Final Batch Loss: 1.472084750275826e-05\n",
      "Epoch 2287, Loss: 0.04626021359945298, Final Batch Loss: 0.00031174643663689494\n",
      "Epoch 2288, Loss: 0.0008644915071727155, Final Batch Loss: 1.9924702883145073e-06\n",
      "Epoch 2289, Loss: 0.0018239606288261712, Final Batch Loss: 0.0006772684282623231\n",
      "Epoch 2290, Loss: 0.0012005557291558944, Final Batch Loss: 0.0007947059348225594\n",
      "Epoch 2291, Loss: 0.001606641443800072, Final Batch Loss: 7.407990096908179e-07\n",
      "Epoch 2292, Loss: 0.0009648329601077421, Final Batch Loss: 5.091877483209828e-06\n",
      "Epoch 2293, Loss: 0.00464215587999206, Final Batch Loss: 0.00014410690346267074\n",
      "Epoch 2294, Loss: 0.0016078252765510115, Final Batch Loss: 1.7199990907101892e-06\n",
      "Epoch 2295, Loss: 0.0007735728941042908, Final Batch Loss: 3.0948220228310674e-05\n",
      "Epoch 2296, Loss: 0.0029702476094826125, Final Batch Loss: 0.001470194780267775\n",
      "Epoch 2297, Loss: 0.0018576258116809186, Final Batch Loss: 4.9686877900967374e-05\n",
      "Epoch 2298, Loss: 0.0006718409385939594, Final Batch Loss: 7.74856744101271e-07\n",
      "Epoch 2299, Loss: 0.0009473710597376339, Final Batch Loss: 0.00013778574066236615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2300, Loss: 0.0006646366955465055, Final Batch Loss: 4.521335540630389e-06\n",
      "Epoch 2301, Loss: 0.0004931604065063766, Final Batch Loss: 6.386192694662896e-07\n",
      "Epoch 2302, Loss: 0.0017739129143592436, Final Batch Loss: 2.599997606012039e-05\n",
      "Epoch 2303, Loss: 0.0016622899621552278, Final Batch Loss: 8.770349495534902e-07\n",
      "Epoch 2304, Loss: 0.0013630044650199125, Final Batch Loss: 0.0005563678569160402\n",
      "Epoch 2305, Loss: 0.0007269060497492319, Final Batch Loss: 1.7504851712146774e-05\n",
      "Epoch 2306, Loss: 0.02630434169259388, Final Batch Loss: 0.020795004442334175\n",
      "Epoch 2307, Loss: 0.0002476943471378945, Final Batch Loss: 7.918882261037652e-07\n",
      "Epoch 2308, Loss: 0.0031778885999429463, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 2309, Loss: 0.000479931574773218, Final Batch Loss: 2.254523860756308e-05\n",
      "Epoch 2310, Loss: 0.0005080791652289918, Final Batch Loss: 2.906441477534827e-05\n",
      "Epoch 2311, Loss: 0.0007657313508389052, Final Batch Loss: 2.1105443011038005e-05\n",
      "Epoch 2312, Loss: 0.0004783077725107887, Final Batch Loss: 1.7029881860253226e-07\n",
      "Epoch 2313, Loss: 0.0007839878471713746, Final Batch Loss: 1.6466858141939156e-05\n",
      "Epoch 2314, Loss: 0.0026327197033424454, Final Batch Loss: 2.4607784325780813e-06\n",
      "Epoch 2315, Loss: 0.0006924255289959547, Final Batch Loss: 5.823989795317175e-06\n",
      "Epoch 2316, Loss: 0.006765543024812359, Final Batch Loss: 0.0028014059644192457\n",
      "Epoch 2317, Loss: 0.001050220857507611, Final Batch Loss: 9.025794156514166e-07\n",
      "Epoch 2318, Loss: 0.0008018518315751066, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 2319, Loss: 0.0019088519209162769, Final Batch Loss: 2.222385546701844e-06\n",
      "Epoch 2320, Loss: 0.0013686433158, Final Batch Loss: 0.000153237022459507\n",
      "Epoch 2321, Loss: 0.0073249034840969784, Final Batch Loss: 9.366440423264066e-08\n",
      "Epoch 2322, Loss: 0.0036645194918492052, Final Batch Loss: 3.942313469451619e-06\n",
      "Epoch 2323, Loss: 0.0013877963310733321, Final Batch Loss: 1.2677900485869031e-05\n",
      "Epoch 2324, Loss: 0.0036906298064423027, Final Batch Loss: 2.2000896933604963e-05\n",
      "Epoch 2325, Loss: 0.0018038618726166078, Final Batch Loss: 1.7881379221762472e-07\n",
      "Epoch 2326, Loss: 0.0008618679581786637, Final Batch Loss: 1.2687174830716685e-06\n",
      "Epoch 2327, Loss: 0.0010303207470201414, Final Batch Loss: 5.449562081594195e-07\n",
      "Epoch 2328, Loss: 0.002195974378992105, Final Batch Loss: 1.2516866263467818e-06\n",
      "Epoch 2329, Loss: 0.0013523870820790762, Final Batch Loss: 2.5676514269434847e-05\n",
      "Epoch 2330, Loss: 0.0178803227172466, Final Batch Loss: 4.060129140270874e-05\n",
      "Epoch 2331, Loss: 0.003451385229709558, Final Batch Loss: 0.00033139094011858106\n",
      "Epoch 2332, Loss: 0.0005473796700243838, Final Batch Loss: 0.000152477397932671\n",
      "Epoch 2333, Loss: 0.021460728762122017, Final Batch Loss: 4.4106586756242905e-06\n",
      "Epoch 2334, Loss: 0.0006073365038901102, Final Batch Loss: 1.8221762729808688e-06\n",
      "Epoch 2335, Loss: 0.001188229082771386, Final Batch Loss: 4.6832153088871564e-07\n",
      "Epoch 2336, Loss: 0.008940900845118449, Final Batch Loss: 1.1469144737930037e-05\n",
      "Epoch 2337, Loss: 0.0009107919008783938, Final Batch Loss: 2.690675955818733e-06\n",
      "Epoch 2338, Loss: 0.0014973048091633245, Final Batch Loss: 8.401904779020697e-05\n",
      "Epoch 2339, Loss: 0.0030896012685843743, Final Batch Loss: 0.0012017196277156472\n",
      "Epoch 2340, Loss: 0.002910234567934822, Final Batch Loss: 4.63198284705868e-06\n",
      "Epoch 2341, Loss: 0.02850745582691161, Final Batch Loss: 0.00010087229748023674\n",
      "Epoch 2342, Loss: 0.0009610057759346091, Final Batch Loss: 6.607450814044569e-06\n",
      "Epoch 2343, Loss: 0.0013983634389660438, Final Batch Loss: 4.623489985533524e-06\n",
      "Epoch 2344, Loss: 0.0024479606092882022, Final Batch Loss: 1.3027768090978498e-06\n",
      "Epoch 2345, Loss: 0.001899602316683513, Final Batch Loss: 1.6178395867427753e-07\n",
      "Epoch 2346, Loss: 0.000890041045011003, Final Batch Loss: 3.831721073765948e-07\n",
      "Epoch 2347, Loss: 0.00080509726285527, Final Batch Loss: 2.261310328321997e-05\n",
      "Epoch 2348, Loss: 0.0007651908191519396, Final Batch Loss: 1.1324838169457507e-06\n",
      "Epoch 2349, Loss: 0.0005156644620001316, Final Batch Loss: 9.079726441996172e-05\n",
      "Epoch 2350, Loss: 0.00036893713786412263, Final Batch Loss: 6.28381621936569e-06\n",
      "Epoch 2351, Loss: 0.0009492209593418011, Final Batch Loss: 1.3879235893909936e-06\n",
      "Epoch 2352, Loss: 0.0005459242602228187, Final Batch Loss: 7.906208338681608e-05\n",
      "Epoch 2353, Loss: 0.0007556434270554746, Final Batch Loss: 3.763545919355238e-06\n",
      "Epoch 2354, Loss: 0.0009901843324939819, Final Batch Loss: 4.342611816809949e-07\n",
      "Epoch 2355, Loss: 0.0006040398379809631, Final Batch Loss: 6.803130872867769e-06\n",
      "Epoch 2356, Loss: 0.0018089527293341234, Final Batch Loss: 0.0008159003336913884\n",
      "Epoch 2357, Loss: 0.0035234627503086813, Final Batch Loss: 2.85023998003453e-05\n",
      "Epoch 2358, Loss: 0.0008923788991523907, Final Batch Loss: 0.00021551769168581814\n",
      "Epoch 2359, Loss: 0.00047685708341305144, Final Batch Loss: 0.0001357168221147731\n",
      "Epoch 2360, Loss: 0.0006067699198730736, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2361, Loss: 0.0006978835845075082, Final Batch Loss: 0.0002915015793405473\n",
      "Epoch 2362, Loss: 0.001683106751897867, Final Batch Loss: 4.410675046528922e-06\n",
      "Epoch 2363, Loss: 0.0007340553137282768, Final Batch Loss: 1.7029841501425835e-06\n",
      "Epoch 2364, Loss: 0.005086639726670228, Final Batch Loss: 1.7881373537420586e-07\n",
      "Epoch 2365, Loss: 0.0006966418612819325, Final Batch Loss: 1.1495093303892645e-06\n",
      "Epoch 2366, Loss: 0.00038378598264898756, Final Batch Loss: 6.87136935084709e-06\n",
      "Epoch 2367, Loss: 0.0005649726061562887, Final Batch Loss: 3.6614241594179475e-07\n",
      "Epoch 2368, Loss: 0.0007442424721375573, Final Batch Loss: 1.5496592823183164e-05\n",
      "Epoch 2369, Loss: 0.0014210028289198817, Final Batch Loss: 7.407975317619275e-07\n",
      "Epoch 2370, Loss: 0.001251618776336727, Final Batch Loss: 9.025808367368882e-07\n",
      "Epoch 2371, Loss: 0.0007162820329540409, Final Batch Loss: 5.7840112276608124e-05\n",
      "Epoch 2372, Loss: 0.00032168518447406313, Final Batch Loss: 8.770355748310976e-07\n",
      "Epoch 2373, Loss: 0.0009077487193280831, Final Batch Loss: 0.0005468652816489339\n",
      "Epoch 2374, Loss: 0.0027531039260111356, Final Batch Loss: 8.25947722660203e-07\n",
      "Epoch 2375, Loss: 0.00024415925281573436, Final Batch Loss: 3.857226602121955e-06\n",
      "Epoch 2376, Loss: 0.0003932546442229068, Final Batch Loss: 2.8290009140619077e-05\n",
      "Epoch 2377, Loss: 0.0028257339137098825, Final Batch Loss: 1.575258579578076e-06\n",
      "Epoch 2378, Loss: 0.015885488048297702, Final Batch Loss: 6.811937964812387e-07\n",
      "Epoch 2379, Loss: 0.0006515989989566151, Final Batch Loss: 7.21857650205493e-05\n",
      "Epoch 2380, Loss: 0.00048297172725142445, Final Batch Loss: 9.927758583216928e-06\n",
      "Epoch 2381, Loss: 0.0005562914532539764, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2382, Loss: 0.0010503671655897051, Final Batch Loss: 0.0003507423389237374\n",
      "Epoch 2383, Loss: 0.0029633813501277473, Final Batch Loss: 5.8346162404632196e-05\n",
      "Epoch 2384, Loss: 0.0009285539329226822, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 2385, Loss: 0.0028065764135760674, Final Batch Loss: 2.1287357299115683e-07\n",
      "Epoch 2386, Loss: 0.0014229445393993956, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 2387, Loss: 0.0011815083744295407, Final Batch Loss: 0.00035978370578959584\n",
      "Epoch 2388, Loss: 0.0007056287127227279, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 2389, Loss: 0.023615244535903912, Final Batch Loss: 7.143995753722265e-05\n",
      "Epoch 2390, Loss: 0.0003552826995338876, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2391, Loss: 0.0010821071726745402, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 2392, Loss: 0.0010843228947123862, Final Batch Loss: 6.530667633342091e-06\n",
      "Epoch 2393, Loss: 0.0005033037972452803, Final Batch Loss: 1.0132765737580485e-06\n",
      "Epoch 2394, Loss: 0.004393857940158341, Final Batch Loss: 0.0003056892310269177\n",
      "Epoch 2395, Loss: 0.0011511016354006642, Final Batch Loss: 7.152528951337445e-07\n",
      "Epoch 2396, Loss: 0.00036871799790105797, Final Batch Loss: 5.194106620365346e-07\n",
      "Epoch 2397, Loss: 0.0022609064443486204, Final Batch Loss: 5.704995373889687e-07\n",
      "Epoch 2398, Loss: 0.0061278962975990225, Final Batch Loss: 2.1287361562372098e-07\n",
      "Epoch 2399, Loss: 0.0022065333560021827, Final Batch Loss: 0.0016966939438134432\n",
      "Epoch 2400, Loss: 0.0004456583088252586, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2401, Loss: 0.0031860260060057044, Final Batch Loss: 0.0\n",
      "Epoch 2402, Loss: 0.00041381732626177836, Final Batch Loss: 1.5325762433349155e-05\n",
      "Epoch 2403, Loss: 0.005920682113242037, Final Batch Loss: 1.8817789850800182e-06\n",
      "Epoch 2404, Loss: 0.0007495732534152921, Final Batch Loss: 0.0003597307368181646\n",
      "Epoch 2405, Loss: 0.0013865937289665453, Final Batch Loss: 8.62483648234047e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2406, Loss: 0.00035117053425892664, Final Batch Loss: 3.3037265438906616e-06\n",
      "Epoch 2407, Loss: 0.0003990756624716596, Final Batch Loss: 2.6225673082080903e-06\n",
      "Epoch 2408, Loss: 0.0005708283242711332, Final Batch Loss: 0.00018735681078396738\n",
      "Epoch 2409, Loss: 0.0002899239243561169, Final Batch Loss: 2.166726153518539e-05\n",
      "Epoch 2410, Loss: 0.0005642578726110514, Final Batch Loss: 1.6883215721463785e-05\n",
      "Epoch 2411, Loss: 0.029844844492878053, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 2412, Loss: 0.001569267799691687, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 2413, Loss: 0.0010893825793303336, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 2414, Loss: 0.00043642966738843825, Final Batch Loss: 6.334994395729154e-06\n",
      "Epoch 2415, Loss: 0.022384534508091747, Final Batch Loss: 2.0518817109405063e-05\n",
      "Epoch 2416, Loss: 0.0036539264017108053, Final Batch Loss: 4.4277632582634396e-07\n",
      "Epoch 2417, Loss: 0.005538481495932501, Final Batch Loss: 1.3393427252594847e-05\n",
      "Epoch 2418, Loss: 0.0025528687983751297, Final Batch Loss: 0.0006117021548561752\n",
      "Epoch 2419, Loss: 0.0009461354966333602, Final Batch Loss: 5.3371706599136814e-05\n",
      "Epoch 2420, Loss: 0.0010717553341237362, Final Batch Loss: 0.00035563515848480165\n",
      "Epoch 2421, Loss: 0.0020648073532356648, Final Batch Loss: 1.5930620065773837e-05\n",
      "Epoch 2422, Loss: 0.0005905944889263992, Final Batch Loss: 1.87326429568202e-06\n",
      "Epoch 2423, Loss: 0.0025226050092896912, Final Batch Loss: 0.0017941441619768739\n",
      "Epoch 2424, Loss: 0.007336947939620586, Final Batch Loss: 2.7702397346729413e-05\n",
      "Epoch 2425, Loss: 0.0029501140191854347, Final Batch Loss: 1.0217932810974162e-07\n",
      "Epoch 2426, Loss: 0.005419836848432169, Final Batch Loss: 4.36804430137272e-06\n",
      "Epoch 2427, Loss: 0.00037150164121158014, Final Batch Loss: 3.7890915791649604e-06\n",
      "Epoch 2428, Loss: 0.0006535506772706867, Final Batch Loss: 1.2422628969943617e-05\n",
      "Epoch 2429, Loss: 0.0023487879288950353, Final Batch Loss: 1.2899047760583926e-05\n",
      "Epoch 2430, Loss: 0.0013093808109658767, Final Batch Loss: 2.809927934777079e-07\n",
      "Epoch 2431, Loss: 0.0031591899096383713, Final Batch Loss: 0.00015592189447488636\n",
      "Epoch 2432, Loss: 0.0010855182472369052, Final Batch Loss: 5.5005139074637555e-06\n",
      "Epoch 2433, Loss: 0.0006395853924914263, Final Batch Loss: 0.0\n",
      "Epoch 2434, Loss: 0.0003884792527060199, Final Batch Loss: 3.346336143295048e-06\n",
      "Epoch 2435, Loss: 0.0010689533155527897, Final Batch Loss: 0.0006631933501921594\n",
      "Epoch 2436, Loss: 0.023593953944612167, Final Batch Loss: 6.811927164562803e-07\n",
      "Epoch 2437, Loss: 0.009074348689864564, Final Batch Loss: 3.0051754947635345e-05\n",
      "Epoch 2438, Loss: 0.006618878442736786, Final Batch Loss: 1.2942606417709612e-06\n",
      "Epoch 2439, Loss: 0.000571074790059356, Final Batch Loss: 4.064115273649804e-05\n",
      "Epoch 2440, Loss: 0.0007527787893195637, Final Batch Loss: 6.7330060119275e-05\n",
      "Epoch 2441, Loss: 0.0023983963530156416, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 2442, Loss: 0.01335185826428642, Final Batch Loss: 2.903010135923978e-05\n",
      "Epoch 2443, Loss: 0.00035717703156734615, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 2444, Loss: 0.00037358227746153716, Final Batch Loss: 8.33585909276735e-06\n",
      "Epoch 2445, Loss: 0.00105788112080063, Final Batch Loss: 6.811943649154273e-07\n",
      "Epoch 2446, Loss: 0.001076993036008389, Final Batch Loss: 1.1580251566556399e-06\n",
      "Epoch 2447, Loss: 0.00077458232999561, Final Batch Loss: 4.9300601858703885e-06\n",
      "Epoch 2448, Loss: 0.0006048189843568252, Final Batch Loss: 4.6358291001524776e-05\n",
      "Epoch 2449, Loss: 0.000860353756976906, Final Batch Loss: 1.7881374958506058e-07\n",
      "Epoch 2450, Loss: 0.004860282799199922, Final Batch Loss: 0.0046569244004786015\n",
      "Epoch 2451, Loss: 0.00516060965401266, Final Batch Loss: 0.0047106510028243065\n",
      "Epoch 2452, Loss: 0.0005606773811450694, Final Batch Loss: 3.781339546549134e-05\n",
      "Epoch 2453, Loss: 0.0010720868989011478, Final Batch Loss: 2.2138858923881344e-07\n",
      "Epoch 2454, Loss: 0.002759737346991642, Final Batch Loss: 7.748591315248632e-07\n",
      "Epoch 2455, Loss: 0.0012880219146609306, Final Batch Loss: 0.0002953353396151215\n",
      "Epoch 2456, Loss: 0.0004688284570875112, Final Batch Loss: 0.00019515662279445678\n",
      "Epoch 2457, Loss: 0.0015514799391667111, Final Batch Loss: 1.1750538533306099e-06\n",
      "Epoch 2458, Loss: 0.002088075397296052, Final Batch Loss: 1.3937612493464258e-05\n",
      "Epoch 2459, Loss: 0.022331177555315662, Final Batch Loss: 0.020836813375353813\n",
      "Epoch 2460, Loss: 0.002368939865846187, Final Batch Loss: 0.00021989500964991748\n",
      "Epoch 2461, Loss: 0.0012222202096552337, Final Batch Loss: 3.1505280162491545e-07\n",
      "Epoch 2462, Loss: 0.019181904521246906, Final Batch Loss: 1.313737448072061e-05\n",
      "Epoch 2463, Loss: 0.0009207197539566891, Final Batch Loss: 1.021793636368784e-07\n",
      "Epoch 2464, Loss: 0.00019752235107262095, Final Batch Loss: 2.4267335447802907e-06\n",
      "Epoch 2465, Loss: 0.03998823045185418, Final Batch Loss: 5.290082117426209e-05\n",
      "Epoch 2466, Loss: 0.0005716979942604894, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 2467, Loss: 0.012547638929362392, Final Batch Loss: 3.1505257425124e-07\n",
      "Epoch 2468, Loss: 0.00077808999969875, Final Batch Loss: 1.353868469777808e-06\n",
      "Epoch 2469, Loss: 0.01159825596630526, Final Batch Loss: 6.045601139703649e-07\n",
      "Epoch 2470, Loss: 0.004327186651337911, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 2471, Loss: 0.0017723933087836485, Final Batch Loss: 5.663610136252828e-05\n",
      "Epoch 2472, Loss: 0.0072730064784991555, Final Batch Loss: 5.449546733871102e-07\n",
      "Epoch 2473, Loss: 0.006867274487376562, Final Batch Loss: 2.1779187591164373e-05\n",
      "Epoch 2474, Loss: 0.002308456553762994, Final Batch Loss: 2.21388361865138e-07\n",
      "Epoch 2475, Loss: 0.0007683223111598636, Final Batch Loss: 1.181807147077052e-05\n",
      "Epoch 2476, Loss: 0.010024240575148724, Final Batch Loss: 0.0001853087596828118\n",
      "Epoch 2477, Loss: 0.0004894982012046967, Final Batch Loss: 0.00017393880989402533\n",
      "Epoch 2478, Loss: 0.003627984767263115, Final Batch Loss: 1.0421540537208784e-05\n",
      "Epoch 2479, Loss: 0.0053983201632945566, Final Batch Loss: 3.927465149899945e-05\n",
      "Epoch 2480, Loss: 0.0012097081562387757, Final Batch Loss: 0.00022663544223178178\n",
      "Epoch 2481, Loss: 0.0012003970072562709, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 2482, Loss: 0.00042856363143073395, Final Batch Loss: 5.730063276132569e-05\n",
      "Epoch 2483, Loss: 0.008411226038457897, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 2484, Loss: 0.027282784276962957, Final Batch Loss: 1.6433665450676926e-06\n",
      "Epoch 2485, Loss: 0.011202380792383337, Final Batch Loss: 5.4302701755659655e-05\n",
      "Epoch 2486, Loss: 0.005013057475025562, Final Batch Loss: 5.628284725389676e-06\n",
      "Epoch 2487, Loss: 0.0008331239496328635, Final Batch Loss: 1.9199664166080765e-05\n",
      "Epoch 2488, Loss: 0.00048435855796924443, Final Batch Loss: 1.1230737982259598e-05\n",
      "Epoch 2489, Loss: 0.002348266353578765, Final Batch Loss: 1.3368379541134345e-06\n",
      "Epoch 2490, Loss: 0.0005455485752463574, Final Batch Loss: 1.9351859009475447e-05\n",
      "Epoch 2491, Loss: 0.0007654442842977005, Final Batch Loss: 4.921525942336302e-06\n",
      "Epoch 2492, Loss: 0.00035412025590630947, Final Batch Loss: 8.855272426444571e-06\n",
      "Epoch 2493, Loss: 0.0035931234395150113, Final Batch Loss: 1.7881373537420586e-07\n",
      "Epoch 2494, Loss: 0.02951615915480943, Final Batch Loss: 3.1082141504157335e-05\n",
      "Epoch 2495, Loss: 0.0010638299609126989, Final Batch Loss: 2.469776154612191e-05\n",
      "Epoch 2496, Loss: 0.0034811143423780777, Final Batch Loss: 2.8950768182767206e-07\n",
      "Epoch 2497, Loss: 0.004827504426884843, Final Batch Loss: 4.018942945549497e-06\n",
      "Epoch 2498, Loss: 0.0005512373951432892, Final Batch Loss: 1.5582205605824129e-06\n",
      "Epoch 2499, Loss: 0.0007747889176243916, Final Batch Loss: 9.945142664946616e-06\n",
      "Epoch 2500, Loss: 0.0018248531182507577, Final Batch Loss: 4.146672381466487e-06\n",
      "Epoch 2501, Loss: 0.003963715219077457, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2502, Loss: 0.0008061644000463275, Final Batch Loss: 2.622560486997827e-06\n",
      "Epoch 2503, Loss: 0.01980764810286928, Final Batch Loss: 0.0001482021907577291\n",
      "Epoch 2504, Loss: 0.0006675389749943861, Final Batch Loss: 5.790055183751974e-06\n",
      "Epoch 2505, Loss: 0.01935604032925653, Final Batch Loss: 3.8317168105095334e-07\n",
      "Epoch 2506, Loss: 0.0011925434686475, Final Batch Loss: 1.9584368260439078e-07\n",
      "Epoch 2507, Loss: 0.0013317424257230925, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2508, Loss: 0.002417141498881392, Final Batch Loss: 7.220594852697104e-05\n",
      "Epoch 2509, Loss: 0.0005327367604195388, Final Batch Loss: 1.8647612023414695e-06\n",
      "Epoch 2510, Loss: 0.0004961867334714043, Final Batch Loss: 1.1315852134430315e-05\n",
      "Epoch 2511, Loss: 0.0007365066339843906, Final Batch Loss: 0.0001160929023171775\n",
      "Epoch 2512, Loss: 0.004975707459379919, Final Batch Loss: 0.003601228119805455\n",
      "Epoch 2513, Loss: 0.018246517262014095, Final Batch Loss: 0.007649059407413006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2514, Loss: 0.0042780250254743635, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 2515, Loss: 0.0009472502279095352, Final Batch Loss: 0.00045887529267929494\n",
      "Epoch 2516, Loss: 0.0014877152352710254, Final Batch Loss: 0.0006108619854785502\n",
      "Epoch 2517, Loss: 0.00030563492146029603, Final Batch Loss: 1.4244646081351675e-05\n",
      "Epoch 2518, Loss: 0.023283839338319012, Final Batch Loss: 1.5752482340758434e-06\n",
      "Epoch 2519, Loss: 0.0002640822199282411, Final Batch Loss: 6.7862852120015305e-06\n",
      "Epoch 2520, Loss: 0.14224999663520066, Final Batch Loss: 0.13593615591526031\n",
      "Epoch 2521, Loss: 0.03788851729768794, Final Batch Loss: 0.00023477993090637028\n",
      "Epoch 2522, Loss: 0.18360796942579327, Final Batch Loss: 1.1324809747748077e-06\n",
      "Epoch 2523, Loss: 0.12039202571364171, Final Batch Loss: 4.3426157958492695e-07\n",
      "Epoch 2524, Loss: 0.10731443453062184, Final Batch Loss: 9.79215315055626e-07\n",
      "Epoch 2525, Loss: 0.0939065576530993, Final Batch Loss: 0.004321442451328039\n",
      "Epoch 2526, Loss: 0.016169353684745147, Final Batch Loss: 1.2098962542950176e-05\n",
      "Epoch 2527, Loss: 0.03918964808974579, Final Batch Loss: 1.0558461553955567e-06\n",
      "Epoch 2528, Loss: 0.044197252808771736, Final Batch Loss: 7.569439731014427e-06\n",
      "Epoch 2529, Loss: 0.009209554665346786, Final Batch Loss: 9.536681204735942e-07\n",
      "Epoch 2530, Loss: 0.014362505775352474, Final Batch Loss: 1.4448429283220321e-05\n",
      "Epoch 2531, Loss: 0.0018881501164287329, Final Batch Loss: 5.3557814680971205e-06\n",
      "Epoch 2532, Loss: 0.019266596426859905, Final Batch Loss: 1.313735901931068e-05\n",
      "Epoch 2533, Loss: 0.026472158290218317, Final Batch Loss: 1.958436968152455e-07\n",
      "Epoch 2534, Loss: 0.007883447033691482, Final Batch Loss: 5.0917592488985974e-06\n",
      "Epoch 2535, Loss: 0.004764349418110214, Final Batch Loss: 0.00010103881504619494\n",
      "Epoch 2536, Loss: 0.010419703568913974, Final Batch Loss: 4.599153180606663e-05\n",
      "Epoch 2537, Loss: 0.0011627649055299116, Final Batch Loss: 2.8204549380461685e-05\n",
      "Epoch 2538, Loss: 0.041501244201299414, Final Batch Loss: 3.2952143556030933e-06\n",
      "Epoch 2539, Loss: 0.012447549939679448, Final Batch Loss: 0.00023174464877229184\n",
      "Epoch 2540, Loss: 0.0007419101212917667, Final Batch Loss: 7.407990096908179e-07\n",
      "Epoch 2541, Loss: 0.0014053546474315226, Final Batch Loss: 0.00019548497220966965\n",
      "Epoch 2542, Loss: 0.0022381069138646126, Final Batch Loss: 9.326344297733158e-05\n",
      "Epoch 2543, Loss: 0.0047186368246912025, Final Batch Loss: 2.7843561838380992e-06\n",
      "Epoch 2544, Loss: 0.0007378611266233293, Final Batch Loss: 3.3208235095116834e-07\n",
      "Epoch 2545, Loss: 0.030460510024568066, Final Batch Loss: 0.028032779693603516\n",
      "Epoch 2546, Loss: 0.01038278349039956, Final Batch Loss: 5.449550144476234e-07\n",
      "Epoch 2547, Loss: 0.05014469178786385, Final Batch Loss: 4.963455648976378e-05\n",
      "Epoch 2548, Loss: 0.01679812390193547, Final Batch Loss: 5.755874553869944e-06\n",
      "Epoch 2549, Loss: 0.00832210983207915, Final Batch Loss: 8.575328683946282e-05\n",
      "Epoch 2550, Loss: 0.0013925381790613756, Final Batch Loss: 0.00015139520110096782\n",
      "Epoch 2551, Loss: 0.007757417799439281, Final Batch Loss: 0.0034277252852916718\n",
      "Epoch 2552, Loss: 0.017482159737483016, Final Batch Loss: 1.6441363186459057e-05\n",
      "Epoch 2553, Loss: 0.04021078932191813, Final Batch Loss: 3.6017568163515534e-06\n",
      "Epoch 2554, Loss: 0.0034237118920827925, Final Batch Loss: 5.3216604101180565e-06\n",
      "Epoch 2555, Loss: 0.0036518539927783422, Final Batch Loss: 0.0027367263101041317\n",
      "Epoch 2556, Loss: 0.0039885170554043725, Final Batch Loss: 0.0024302371311932802\n",
      "Epoch 2557, Loss: 0.010666968265468313, Final Batch Loss: 1.2039462490065489e-05\n",
      "Epoch 2558, Loss: 0.0031352109799627215, Final Batch Loss: 0.0012075110571458936\n",
      "Epoch 2559, Loss: 0.0030381154792848974, Final Batch Loss: 0.0004671762289945036\n",
      "Epoch 2560, Loss: 0.0008301914585899794, Final Batch Loss: 1.2303718904149719e-05\n",
      "Epoch 2561, Loss: 0.004685715735831764, Final Batch Loss: 0.002867477247491479\n",
      "Epoch 2562, Loss: 0.004280813024820418, Final Batch Loss: 1.234658270732325e-06\n",
      "Epoch 2563, Loss: 0.003265434058448591, Final Batch Loss: 6.437011506932322e-06\n",
      "Epoch 2564, Loss: 0.00221241796589311, Final Batch Loss: 7.944035132823046e-06\n",
      "Epoch 2565, Loss: 0.0013058071519935766, Final Batch Loss: 1.2261473329999717e-06\n",
      "Epoch 2566, Loss: 0.00229857160593383, Final Batch Loss: 0.00030180157045833766\n",
      "Epoch 2567, Loss: 0.004909404703084874, Final Batch Loss: 1.3623912309412844e-07\n",
      "Epoch 2568, Loss: 0.0038660623831674457, Final Batch Loss: 2.0092498743906617e-05\n",
      "Epoch 2569, Loss: 0.002278841112911323, Final Batch Loss: 1.7029879018082283e-07\n",
      "Epoch 2570, Loss: 0.0017704932779452065, Final Batch Loss: 2.648690679052379e-05\n",
      "Epoch 2571, Loss: 0.004358433191150368, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 2572, Loss: 0.003771439436604851, Final Batch Loss: 2.357416997256223e-05\n",
      "Epoch 2573, Loss: 0.00046969856191481085, Final Batch Loss: 9.70702217273356e-07\n",
      "Epoch 2574, Loss: 0.0013394999477895908, Final Batch Loss: 6.2627274019178e-05\n",
      "Epoch 2575, Loss: 0.0015410862615681253, Final Batch Loss: 0.00041055423207581043\n",
      "Epoch 2576, Loss: 0.008532733423635364, Final Batch Loss: 0.00015218197950161994\n",
      "Epoch 2577, Loss: 0.01882580649544252, Final Batch Loss: 0.004880076739937067\n",
      "Epoch 2578, Loss: 0.0021287316048983485, Final Batch Loss: 4.4400883780326694e-05\n",
      "Epoch 2579, Loss: 0.027171802834345726, Final Batch Loss: 5.467923983815126e-05\n",
      "Epoch 2580, Loss: 0.002262932181565702, Final Batch Loss: 3.9679348446952645e-06\n",
      "Epoch 2581, Loss: 0.021102105822137673, Final Batch Loss: 1.802521182980854e-05\n",
      "Epoch 2582, Loss: 0.05048439659503856, Final Batch Loss: 4.231862021697452e-06\n",
      "Epoch 2583, Loss: 0.0019368924549780786, Final Batch Loss: 0.00030265870736911893\n",
      "Epoch 2584, Loss: 0.012567871325700253, Final Batch Loss: 1.2209699889353942e-05\n",
      "Epoch 2585, Loss: 0.0017989873595070094, Final Batch Loss: 0.00016838488227222115\n",
      "Epoch 2586, Loss: 0.004997841497242916, Final Batch Loss: 0.0001256519608432427\n",
      "Epoch 2587, Loss: 0.002654615411277206, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2588, Loss: 0.008198472147341818, Final Batch Loss: 0.00020969998149666935\n",
      "Epoch 2589, Loss: 0.003596500522689894, Final Batch Loss: 0.00027080756262876093\n",
      "Epoch 2590, Loss: 0.0020180693499014524, Final Batch Loss: 8.8555304955662e-07\n",
      "Epoch 2591, Loss: 0.00619953188899558, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 2592, Loss: 0.0014081026311032474, Final Batch Loss: 6.679103535134345e-05\n",
      "Epoch 2593, Loss: 0.0033733102900441736, Final Batch Loss: 0.0004748289647977799\n",
      "Epoch 2594, Loss: 0.0031447997462237254, Final Batch Loss: 0.0015446457546204329\n",
      "Epoch 2595, Loss: 0.002073589760584582, Final Batch Loss: 9.996195331041235e-06\n",
      "Epoch 2596, Loss: 0.0016730452589399647, Final Batch Loss: 3.188989285263233e-05\n",
      "Epoch 2597, Loss: 0.002795523527311161, Final Batch Loss: 0.0006092716939747334\n",
      "Epoch 2598, Loss: 0.009724604344228283, Final Batch Loss: 0.00032527532312087715\n",
      "Epoch 2599, Loss: 0.006047305943866377, Final Batch Loss: 2.163427598134149e-05\n",
      "Epoch 2600, Loss: 0.0012678125661160777, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2601, Loss: 0.0013343872082174357, Final Batch Loss: 1.0217935653145105e-07\n",
      "Epoch 2602, Loss: 0.014644506081822328, Final Batch Loss: 0.00011023826664313674\n",
      "Epoch 2603, Loss: 0.0014310659607872367, Final Batch Loss: 0.00016549837891943753\n",
      "Epoch 2604, Loss: 0.003119792294455692, Final Batch Loss: 0.0010496253380551934\n",
      "Epoch 2605, Loss: 0.0025414252959308214, Final Batch Loss: 0.00013636573567055166\n",
      "Epoch 2606, Loss: 0.02546004767668819, Final Batch Loss: 3.048306325581507e-06\n",
      "Epoch 2607, Loss: 0.001250630859948032, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2608, Loss: 0.001029223644280819, Final Batch Loss: 1.9584373944780964e-07\n",
      "Epoch 2609, Loss: 0.0012486492187235854, Final Batch Loss: 9.493552170170005e-06\n",
      "Epoch 2610, Loss: 0.002735563895839732, Final Batch Loss: 8.773523586569354e-05\n",
      "Epoch 2611, Loss: 0.0015201073620119132, Final Batch Loss: 0.00013906069216318429\n",
      "Epoch 2612, Loss: 0.004420223311171867, Final Batch Loss: 6.951378600206226e-05\n",
      "Epoch 2613, Loss: 0.0013949188996775774, Final Batch Loss: 1.174154931504745e-05\n",
      "Epoch 2614, Loss: 0.0011783453010139056, Final Batch Loss: 0.00019273113866802305\n",
      "Epoch 2615, Loss: 0.002643135856715162, Final Batch Loss: 3.30373609358503e-06\n",
      "Epoch 2616, Loss: 0.0009320697242856113, Final Batch Loss: 2.8439715151762357e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2617, Loss: 0.0007796685422363225, Final Batch Loss: 9.153111022897065e-06\n",
      "Epoch 2618, Loss: 0.0026282771686965134, Final Batch Loss: 0.00018905129400081933\n",
      "Epoch 2619, Loss: 0.017431390279853076, Final Batch Loss: 8.3699469541898e-06\n",
      "Epoch 2620, Loss: 0.006964204622136094, Final Batch Loss: 3.0227531624404946e-06\n",
      "Epoch 2621, Loss: 0.008666401699883863, Final Batch Loss: 0.0003153535653837025\n",
      "Epoch 2622, Loss: 0.010297993459971622, Final Batch Loss: 0.0010637454688549042\n",
      "Epoch 2623, Loss: 0.001947347036548308, Final Batch Loss: 8.38675805425737e-06\n",
      "Epoch 2624, Loss: 0.0027753751492127776, Final Batch Loss: 0.00022345221077557653\n",
      "Epoch 2625, Loss: 0.0008836672004690627, Final Batch Loss: 2.9864322641515173e-05\n",
      "Epoch 2626, Loss: 0.0038306857723000576, Final Batch Loss: 6.40301459498005e-06\n",
      "Epoch 2627, Loss: 0.001999929540886569, Final Batch Loss: 3.3208283412022865e-07\n",
      "Epoch 2628, Loss: 0.005617813007637196, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2629, Loss: 0.0017632605449762195, Final Batch Loss: 0.0002703941136132926\n",
      "Epoch 2630, Loss: 0.0011289152689641924, Final Batch Loss: 5.653852895193268e-06\n",
      "Epoch 2631, Loss: 0.0026035637165477965, Final Batch Loss: 4.732935849460773e-05\n",
      "Epoch 2632, Loss: 0.001172193602542393, Final Batch Loss: 0.00015353018534369767\n",
      "Epoch 2633, Loss: 0.0008572527149226516, Final Batch Loss: 1.1145210009999573e-05\n",
      "Epoch 2634, Loss: 0.0013585296874225605, Final Batch Loss: 4.1736650018719956e-05\n",
      "Epoch 2635, Loss: 0.002682168823412212, Final Batch Loss: 8.063377208600286e-06\n",
      "Epoch 2636, Loss: 0.003389452610463195, Final Batch Loss: 3.491122697596438e-07\n",
      "Epoch 2637, Loss: 0.0007810188836856469, Final Batch Loss: 5.70500674257346e-07\n",
      "Epoch 2638, Loss: 0.001209800349897705, Final Batch Loss: 0.0002302976354258135\n",
      "Epoch 2639, Loss: 0.0009907139101414941, Final Batch Loss: 0.00015714515757281333\n",
      "Epoch 2640, Loss: 0.0012176302379884874, Final Batch Loss: 1.3912079339206684e-05\n",
      "Epoch 2641, Loss: 0.013113857799908146, Final Batch Loss: 1.3035285519436002e-05\n",
      "Epoch 2642, Loss: 0.001961859516086406, Final Batch Loss: 1.572624569234904e-05\n",
      "Epoch 2643, Loss: 0.0014332454447867349, Final Batch Loss: 5.0297618145123124e-05\n",
      "Epoch 2644, Loss: 0.0009696363199509506, Final Batch Loss: 4.189242190477671e-06\n",
      "Epoch 2645, Loss: 0.0006046617127140053, Final Batch Loss: 9.621871868148446e-07\n",
      "Epoch 2646, Loss: 0.0017304082407463284, Final Batch Loss: 4.785307737620315e-06\n",
      "Epoch 2647, Loss: 0.005138947886734968, Final Batch Loss: 0.00400462094694376\n",
      "Epoch 2648, Loss: 0.0014774555747862905, Final Batch Loss: 7.845858635846525e-05\n",
      "Epoch 2649, Loss: 0.008927430663646874, Final Batch Loss: 4.683214172018779e-07\n",
      "Epoch 2650, Loss: 0.0011397545749787241, Final Batch Loss: 0.000344257423421368\n",
      "Epoch 2651, Loss: 0.0018980784443556331, Final Batch Loss: 7.35678622731939e-05\n",
      "Epoch 2652, Loss: 0.017504348877992015, Final Batch Loss: 9.008268534671515e-06\n",
      "Epoch 2653, Loss: 0.002723035981262001, Final Batch Loss: 1.2687198704952607e-06\n",
      "Epoch 2654, Loss: 0.0003001642076014832, Final Batch Loss: 3.371882030478446e-06\n",
      "Epoch 2655, Loss: 0.0010624228198139463, Final Batch Loss: 6.001373185426928e-05\n",
      "Epoch 2656, Loss: 0.0007357781250902917, Final Batch Loss: 4.3875479605048895e-05\n",
      "Epoch 2657, Loss: 0.0011734787103705457, Final Batch Loss: 1.0047085197584238e-05\n",
      "Epoch 2658, Loss: 0.0004826288604817819, Final Batch Loss: 4.776742571266368e-06\n",
      "Epoch 2659, Loss: 0.017330983628198737, Final Batch Loss: 3.2928397558862343e-05\n",
      "Epoch 2660, Loss: 0.002192303214542335, Final Batch Loss: 3.9723639929434285e-05\n",
      "Epoch 2661, Loss: 0.001124047688691121, Final Batch Loss: 1.1920919007479824e-07\n",
      "Epoch 2662, Loss: 0.0009791090315047768, Final Batch Loss: 1.136670198320644e-05\n",
      "Epoch 2663, Loss: 0.0019744474011531565, Final Batch Loss: 5.053537097410299e-05\n",
      "Epoch 2664, Loss: 0.0005336735266610049, Final Batch Loss: 4.702689329860732e-05\n",
      "Epoch 2665, Loss: 0.0012404330638062788, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2666, Loss: 0.01569273554287065, Final Batch Loss: 9.979100468626712e-06\n",
      "Epoch 2667, Loss: 0.0011878672676175484, Final Batch Loss: 5.483570021169726e-06\n",
      "Epoch 2668, Loss: 0.0020648146128223743, Final Batch Loss: 0.001416006707586348\n",
      "Epoch 2669, Loss: 0.003174971090629697, Final Batch Loss: 0.002238514134660363\n",
      "Epoch 2670, Loss: 0.0006824542438153003, Final Batch Loss: 2.767341811704682e-06\n",
      "Epoch 2671, Loss: 0.0038014128294889815, Final Batch Loss: 0.0005365406395867467\n",
      "Epoch 2672, Loss: 0.0013011757741878682, Final Batch Loss: 7.084270237101009e-06\n",
      "Epoch 2673, Loss: 0.0019074681185884401, Final Batch Loss: 3.6802033719141036e-05\n",
      "Epoch 2674, Loss: 0.001687088427161143, Final Batch Loss: 1.9073256680712802e-06\n",
      "Epoch 2675, Loss: 0.0005489881755238457, Final Batch Loss: 4.904459729004884e-06\n",
      "Epoch 2676, Loss: 0.0017565839694100305, Final Batch Loss: 2.9802279755131167e-07\n",
      "Epoch 2677, Loss: 0.0005898414710827637, Final Batch Loss: 3.8729747757315636e-05\n",
      "Epoch 2678, Loss: 0.003273163886660768, Final Batch Loss: 8.735821211303119e-06\n",
      "Epoch 2679, Loss: 0.000761512684164245, Final Batch Loss: 9.451532037019206e-07\n",
      "Epoch 2680, Loss: 0.0009771399030853445, Final Batch Loss: 2.895079944664758e-07\n",
      "Epoch 2681, Loss: 0.0006859218265162781, Final Batch Loss: 0.00011179420835105702\n",
      "Epoch 2682, Loss: 0.0004270780424917575, Final Batch Loss: 5.023809421800252e-07\n",
      "Epoch 2683, Loss: 0.0034279698120371904, Final Batch Loss: 0.0008700928883627057\n",
      "Epoch 2684, Loss: 0.004521180955634918, Final Batch Loss: 0.002752817003056407\n",
      "Epoch 2685, Loss: 0.0006434141905629076, Final Batch Loss: 3.3544903999427333e-05\n",
      "Epoch 2686, Loss: 0.0031717882338853087, Final Batch Loss: 0.0\n",
      "Epoch 2687, Loss: 0.0005211959032749292, Final Batch Loss: 0.0\n",
      "Epoch 2688, Loss: 0.00024304280611886497, Final Batch Loss: 1.7796149904825143e-06\n",
      "Epoch 2689, Loss: 0.0011167684369866038, Final Batch Loss: 2.6878655262407847e-05\n",
      "Epoch 2690, Loss: 0.0011966436068178155, Final Batch Loss: 4.4501030060928315e-05\n",
      "Epoch 2691, Loss: 0.000709664633632201, Final Batch Loss: 6.198727078299271e-06\n",
      "Epoch 2692, Loss: 0.00043090293627301435, Final Batch Loss: 1.2602075685208547e-06\n",
      "Epoch 2693, Loss: 0.0013956378415969084, Final Batch Loss: 4.1892444642144255e-06\n",
      "Epoch 2694, Loss: 0.001330268492210962, Final Batch Loss: 3.039774355784175e-06\n",
      "Epoch 2695, Loss: 0.008549413134915085, Final Batch Loss: 2.1116943571541924e-06\n",
      "Epoch 2696, Loss: 0.0009411409543105265, Final Batch Loss: 2.0435858516520966e-07\n",
      "Epoch 2697, Loss: 0.0010927212715614587, Final Batch Loss: 0.00024170485266949981\n",
      "Epoch 2698, Loss: 0.001790898910186911, Final Batch Loss: 1.788138632718983e-07\n",
      "Epoch 2699, Loss: 0.0009687159565920922, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2700, Loss: 0.0011324636798235588, Final Batch Loss: 3.603510049288161e-05\n",
      "Epoch 2701, Loss: 0.0002491416628345178, Final Batch Loss: 1.541192659715307e-06\n",
      "Epoch 2702, Loss: 0.0006457876052081701, Final Batch Loss: 1.1443277799116913e-05\n",
      "Epoch 2703, Loss: 0.00276625720289303, Final Batch Loss: 0.00024035498790908605\n",
      "Epoch 2704, Loss: 0.00022786019690101966, Final Batch Loss: 3.003455094585661e-05\n",
      "Epoch 2705, Loss: 0.0006794196378905326, Final Batch Loss: 1.938591231009923e-05\n",
      "Epoch 2706, Loss: 0.0018463260767020984, Final Batch Loss: 2.5064060537260957e-05\n",
      "Epoch 2707, Loss: 0.0009236944284296555, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 2708, Loss: 0.0004993274419575755, Final Batch Loss: 3.184565230185399e-06\n",
      "Epoch 2709, Loss: 0.0002570056967670098, Final Batch Loss: 5.4728257964598015e-05\n",
      "Epoch 2710, Loss: 0.0007888976610956888, Final Batch Loss: 3.5762741390499286e-07\n",
      "Epoch 2711, Loss: 0.0014329682779532504, Final Batch Loss: 3.746571053397929e-07\n",
      "Epoch 2712, Loss: 0.0004348305374151096, Final Batch Loss: 6.590176781173795e-05\n",
      "Epoch 2713, Loss: 0.000917943534659571, Final Batch Loss: 1.5530333257629536e-05\n",
      "Epoch 2714, Loss: 0.0032730254726054397, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 2715, Loss: 0.009500313424723572, Final Batch Loss: 1.4304987416835502e-06\n",
      "Epoch 2716, Loss: 0.0007169566124503035, Final Batch Loss: 0.00027292087906971574\n",
      "Epoch 2717, Loss: 0.00022599946956347594, Final Batch Loss: 3.320825783248438e-07\n",
      "Epoch 2718, Loss: 0.00026595475952717607, Final Batch Loss: 6.045602845006215e-07\n",
      "Epoch 2719, Loss: 0.00047086410184249416, Final Batch Loss: 2.21388361865138e-07\n",
      "Epoch 2720, Loss: 0.006264622112212237, Final Batch Loss: 0.0036392740439623594\n",
      "Epoch 2721, Loss: 0.0009761980400071479, Final Batch Loss: 3.0196140869520605e-05\n",
      "Epoch 2722, Loss: 0.0008390026314373245, Final Batch Loss: 9.672378837422002e-06\n",
      "Epoch 2723, Loss: 0.0006723630262968072, Final Batch Loss: 3.491071311145788e-06\n",
      "Epoch 2724, Loss: 0.0003627950461009277, Final Batch Loss: 5.194103209760215e-07\n",
      "Epoch 2725, Loss: 0.0011064721356888185, Final Batch Loss: 1.207321747642709e-05\n",
      "Epoch 2726, Loss: 0.0009692788681263664, Final Batch Loss: 7.83371490342688e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2727, Loss: 0.0007090938163401006, Final Batch Loss: 2.077620820273296e-06\n",
      "Epoch 2728, Loss: 0.0009863983409559296, Final Batch Loss: 2.205340479122242e-06\n",
      "Epoch 2729, Loss: 0.0007829562712942106, Final Batch Loss: 1.958436115501172e-07\n",
      "Epoch 2730, Loss: 0.0018256742068842868, Final Batch Loss: 1.4219831427908503e-06\n",
      "Epoch 2731, Loss: 0.0012070262491121753, Final Batch Loss: 1.1920922560193503e-07\n",
      "Epoch 2732, Loss: 0.0006627372735010795, Final Batch Loss: 1.0813949984367355e-06\n",
      "Epoch 2733, Loss: 0.0014561683092324529, Final Batch Loss: 0.0006669051945209503\n",
      "Epoch 2734, Loss: 0.001989825550740676, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2735, Loss: 0.0024361808893331727, Final Batch Loss: 6.982238005548425e-07\n",
      "Epoch 2736, Loss: 0.0003528045858161022, Final Batch Loss: 5.108963136990496e-07\n",
      "Epoch 2737, Loss: 0.0010375348683737684, Final Batch Loss: 0.0\n",
      "Epoch 2738, Loss: 0.00023622407991297223, Final Batch Loss: 5.53469931219297e-07\n",
      "Epoch 2739, Loss: 0.0007960932581028146, Final Batch Loss: 1.873286947784436e-07\n",
      "Epoch 2740, Loss: 0.0001351288827748931, Final Batch Loss: 1.7881380642847944e-07\n",
      "Epoch 2741, Loss: 0.0003427575933017124, Final Batch Loss: 4.1723191657183634e-07\n",
      "Epoch 2742, Loss: 8.314104343298823e-05, Final Batch Loss: 0.0\n",
      "Epoch 2743, Loss: 0.0013251020975033612, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 2744, Loss: 0.000699403855833225, Final Batch Loss: 2.716242306632921e-06\n",
      "Epoch 2745, Loss: 0.00029901787911512656, Final Batch Loss: 3.850600478472188e-05\n",
      "Epoch 2746, Loss: 0.010434531886858167, Final Batch Loss: 1.9353154129930772e-05\n",
      "Epoch 2747, Loss: 0.0011913356192962965, Final Batch Loss: 8.948663889896125e-06\n",
      "Epoch 2748, Loss: 0.0025333068520509983, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 2749, Loss: 0.0011577546122545357, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2750, Loss: 0.0023974186515260953, Final Batch Loss: 5.108860932523385e-05\n",
      "Epoch 2751, Loss: 0.001305967576627154, Final Batch Loss: 0.00040962573257274926\n",
      "Epoch 2752, Loss: 0.001179961878733593, Final Batch Loss: 5.5478936701547354e-05\n",
      "Epoch 2753, Loss: 0.011456855768756213, Final Batch Loss: 7.237681529659312e-07\n",
      "Epoch 2754, Loss: 0.0008545263195287589, Final Batch Loss: 4.0020182723310427e-07\n",
      "Epoch 2755, Loss: 0.012344556080989832, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 2756, Loss: 0.001644765215132793, Final Batch Loss: 8.735986739338841e-06\n",
      "Epoch 2757, Loss: 0.002042882268142421, Final Batch Loss: 0.00013073447917122394\n",
      "Epoch 2758, Loss: 0.001960265635716496, Final Batch Loss: 0.0013144825352355838\n",
      "Epoch 2759, Loss: 0.002564975992413565, Final Batch Loss: 1.1069356560255983e-06\n",
      "Epoch 2760, Loss: 0.0004567103896988556, Final Batch Loss: 3.318359449622221e-05\n",
      "Epoch 2761, Loss: 0.0020460217062918673, Final Batch Loss: 1.4645645478594815e-06\n",
      "Epoch 2762, Loss: 0.001565232035943609, Final Batch Loss: 6.897095659041952e-07\n",
      "Epoch 2763, Loss: 0.0027367998745830846, Final Batch Loss: 7.262923645612318e-06\n",
      "Epoch 2764, Loss: 0.0019809991487420575, Final Batch Loss: 4.1723129129422887e-07\n",
      "Epoch 2765, Loss: 0.004485667418748562, Final Batch Loss: 2.903540689658257e-06\n",
      "Epoch 2766, Loss: 0.0008458623281910604, Final Batch Loss: 2.299032928476663e-07\n",
      "Epoch 2767, Loss: 0.0049720459910531645, Final Batch Loss: 0.0\n",
      "Epoch 2768, Loss: 0.0004979584982720553, Final Batch Loss: 4.904543857264798e-06\n",
      "Epoch 2769, Loss: 0.00145426020708328, Final Batch Loss: 5.86656051382306e-06\n",
      "Epoch 2770, Loss: 0.00042128964560106397, Final Batch Loss: 9.527640941087157e-06\n",
      "Epoch 2771, Loss: 0.0014059150562388822, Final Batch Loss: 0.00013811739336233586\n",
      "Epoch 2772, Loss: 0.0008236097658027575, Final Batch Loss: 9.87729663393111e-07\n",
      "Epoch 2773, Loss: 0.0003139623904644395, Final Batch Loss: 9.349088031740393e-06\n",
      "Epoch 2774, Loss: 0.0005527191869987291, Final Batch Loss: 8.190957487386186e-06\n",
      "Epoch 2775, Loss: 0.000562514489502064, Final Batch Loss: 8.961489947978407e-05\n",
      "Epoch 2776, Loss: 0.0205517668146058, Final Batch Loss: 0.0014689721865579486\n",
      "Epoch 2777, Loss: 0.002000351538299583, Final Batch Loss: 1.17073068395257e-05\n",
      "Epoch 2778, Loss: 0.00045366347746522706, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 2779, Loss: 0.0002754393659127885, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2780, Loss: 0.005766624675743515, Final Batch Loss: 0.0004977337084710598\n",
      "Epoch 2781, Loss: 0.0032384667410951806, Final Batch Loss: 9.893998139887117e-06\n",
      "Epoch 2782, Loss: 0.000677584039294743, Final Batch Loss: 1.913905180117581e-05\n",
      "Epoch 2783, Loss: 0.0012695048144450993, Final Batch Loss: 1.0080989341076929e-05\n",
      "Epoch 2784, Loss: 0.0004991743069524546, Final Batch Loss: 4.768360497564572e-07\n",
      "Epoch 2785, Loss: 0.00043065893623861484, Final Batch Loss: 0.0\n",
      "Epoch 2786, Loss: 0.0023786274177837186, Final Batch Loss: 9.139224857790396e-05\n",
      "Epoch 2787, Loss: 0.002078643985441886, Final Batch Loss: 0.0003200234204996377\n",
      "Epoch 2788, Loss: 0.0011097334557099714, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2789, Loss: 0.0004022771263407776, Final Batch Loss: 2.090973976009991e-05\n",
      "Epoch 2790, Loss: 0.0018435244037391385, Final Batch Loss: 0.0002504379372112453\n",
      "Epoch 2791, Loss: 0.000965936729699024, Final Batch Loss: 1.2797017916454934e-05\n",
      "Epoch 2792, Loss: 0.0006805749853810994, Final Batch Loss: 8.197518764063716e-05\n",
      "Epoch 2793, Loss: 0.001970513582904232, Final Batch Loss: 3.491123550247721e-07\n",
      "Epoch 2794, Loss: 0.0013677221231773729, Final Batch Loss: 6.956568540772423e-06\n",
      "Epoch 2795, Loss: 0.013957879991721711, Final Batch Loss: 0.010395966470241547\n",
      "Epoch 2796, Loss: 0.0006256796259549446, Final Batch Loss: 8.316522871609777e-05\n",
      "Epoch 2797, Loss: 0.018696068194913096, Final Batch Loss: 2.0178807972115465e-05\n",
      "Epoch 2798, Loss: 0.004294839902286185, Final Batch Loss: 1.7871800082502887e-05\n",
      "Epoch 2799, Loss: 0.002906347095631645, Final Batch Loss: 0.0004132166795898229\n",
      "Epoch 2800, Loss: 0.006252111943467753, Final Batch Loss: 2.9995604563737288e-05\n",
      "Epoch 2801, Loss: 0.0025188673214699975, Final Batch Loss: 4.5980576146575913e-07\n",
      "Epoch 2802, Loss: 0.04075299694659407, Final Batch Loss: 3.3803585210989695e-06\n",
      "Epoch 2803, Loss: 0.0025122761235252256, Final Batch Loss: 3.950941390939988e-05\n",
      "Epoch 2804, Loss: 0.003627969617280513, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 2805, Loss: 0.0005736692405662325, Final Batch Loss: 6.181595836096676e-06\n",
      "Epoch 2806, Loss: 0.004889306534096249, Final Batch Loss: 2.3191330910776742e-05\n",
      "Epoch 2807, Loss: 0.0038108428052510135, Final Batch Loss: 2.5642424589022994e-05\n",
      "Epoch 2808, Loss: 0.0007399320656986674, Final Batch Loss: 0.0001685450115473941\n",
      "Epoch 2809, Loss: 0.026210958785924277, Final Batch Loss: 3.320822372643306e-07\n",
      "Epoch 2810, Loss: 0.0006820021964273337, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 2811, Loss: 0.0006212179412159458, Final Batch Loss: 1.0217897852271562e-06\n",
      "Epoch 2812, Loss: 0.0017728418222304754, Final Batch Loss: 2.324564547961927e-06\n",
      "Epoch 2813, Loss: 0.0022756492980988696, Final Batch Loss: 0.00014487156295217574\n",
      "Epoch 2814, Loss: 0.006666584107733797, Final Batch Loss: 0.0001047711048158817\n",
      "Epoch 2815, Loss: 0.0006030069780535996, Final Batch Loss: 4.164309939369559e-05\n",
      "Epoch 2816, Loss: 0.0008668557334772231, Final Batch Loss: 3.2356780366171733e-07\n",
      "Epoch 2817, Loss: 0.007584162308717168, Final Batch Loss: 1.4645587498307577e-06\n",
      "Epoch 2818, Loss: 0.0009330767225037562, Final Batch Loss: 2.8779995773220435e-06\n",
      "Epoch 2819, Loss: 0.0005997694042889634, Final Batch Loss: 0.0001735195837682113\n",
      "Epoch 2820, Loss: 0.0008729327746550553, Final Batch Loss: 0.0002088216133415699\n",
      "Epoch 2821, Loss: 0.0030100769222372037, Final Batch Loss: 9.196087376039941e-07\n",
      "Epoch 2822, Loss: 0.000385371333322837, Final Batch Loss: 1.1902911865036003e-05\n",
      "Epoch 2823, Loss: 0.0020032038919453043, Final Batch Loss: 0.0001168017988675274\n",
      "Epoch 2824, Loss: 0.0011623743025666045, Final Batch Loss: 2.7928704184887465e-06\n",
      "Epoch 2825, Loss: 0.0012098800816602306, Final Batch Loss: 1.3708084225072525e-05\n",
      "Epoch 2826, Loss: 0.0036549336702016433, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 2827, Loss: 0.016755262316678454, Final Batch Loss: 1.0984200571328984e-06\n",
      "Epoch 2828, Loss: 0.004085217743067915, Final Batch Loss: 4.589414402289549e-06\n",
      "Epoch 2829, Loss: 0.001956902759957302, Final Batch Loss: 1.0966478839691263e-05\n",
      "Epoch 2830, Loss: 0.012690342303358193, Final Batch Loss: 6.028330062690657e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2831, Loss: 0.0026990981622816435, Final Batch Loss: 4.4277652477831e-07\n",
      "Epoch 2832, Loss: 0.0033011952086781093, Final Batch Loss: 5.883588073629653e-06\n",
      "Epoch 2833, Loss: 0.0010874023347540174, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2834, Loss: 0.001699491956969723, Final Batch Loss: 0.0\n",
      "Epoch 2835, Loss: 0.016917730066779768, Final Batch Loss: 0.00012177887401776388\n",
      "Epoch 2836, Loss: 0.001413672097669405, Final Batch Loss: 3.1930587738315808e-06\n",
      "Epoch 2837, Loss: 0.010099615485938074, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 2838, Loss: 0.001954683412805025, Final Batch Loss: 9.272179340769071e-06\n",
      "Epoch 2839, Loss: 0.00047698066191514954, Final Batch Loss: 6.191366264829412e-05\n",
      "Epoch 2840, Loss: 0.001921930217577028, Final Batch Loss: 0.00012555575813166797\n",
      "Epoch 2841, Loss: 0.000531423770617323, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 2842, Loss: 0.0013857496523996815, Final Batch Loss: 8.57759005157277e-05\n",
      "Epoch 2843, Loss: 0.0006924412912781008, Final Batch Loss: 6.811927164562803e-07\n",
      "Epoch 2844, Loss: 0.002918903357567615, Final Batch Loss: 2.2834819901618175e-05\n",
      "Epoch 2845, Loss: 0.0004895463152934099, Final Batch Loss: 0.0\n",
      "Epoch 2846, Loss: 0.0010657070947672764, Final Batch Loss: 7.30568217477412e-06\n",
      "Epoch 2847, Loss: 0.0004743026256619487, Final Batch Loss: 1.2405381312419195e-05\n",
      "Epoch 2848, Loss: 0.0003180614944540139, Final Batch Loss: 1.9924841581087094e-06\n",
      "Epoch 2849, Loss: 0.0033805772036430426, Final Batch Loss: 3.4395437978673726e-05\n",
      "Epoch 2850, Loss: 0.001723584940918954, Final Batch Loss: 6.011447112541646e-06\n",
      "Epoch 2851, Loss: 0.0005927600577706471, Final Batch Loss: 0.00010577384091448039\n",
      "Epoch 2852, Loss: 0.0014178722676660982, Final Batch Loss: 1.763341060723178e-05\n",
      "Epoch 2853, Loss: 0.0003921053366404692, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 2854, Loss: 0.002553946176021782, Final Batch Loss: 2.0095078525628196e-06\n",
      "Epoch 2855, Loss: 0.0015754513337924436, Final Batch Loss: 2.6225720830552746e-06\n",
      "Epoch 2856, Loss: 0.000673194164846791, Final Batch Loss: 8.923228597268462e-05\n",
      "Epoch 2857, Loss: 0.00025702134504967944, Final Batch Loss: 3.661420748812816e-07\n",
      "Epoch 2858, Loss: 0.0007723817925580079, Final Batch Loss: 5.191381569602527e-05\n",
      "Epoch 2859, Loss: 0.0003306365205162365, Final Batch Loss: 1.7114842876253533e-06\n",
      "Epoch 2860, Loss: 0.0009248787828255445, Final Batch Loss: 8.156857802532613e-06\n",
      "Epoch 2861, Loss: 0.005256342951724946, Final Batch Loss: 1.23122254080954e-05\n",
      "Epoch 2862, Loss: 0.01870718166901497, Final Batch Loss: 5.7664921769173816e-05\n",
      "Epoch 2863, Loss: 0.0008309080367077115, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 2864, Loss: 0.02050860789449871, Final Batch Loss: 5.492001491802512e-06\n",
      "Epoch 2865, Loss: 0.01973149856149803, Final Batch Loss: 3.8317176631608163e-07\n",
      "Epoch 2866, Loss: 0.002912973614115799, Final Batch Loss: 6.726787660227274e-07\n",
      "Epoch 2867, Loss: 0.008029822710071244, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 2868, Loss: 0.0010551883377161175, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 2869, Loss: 0.001423740144673502, Final Batch Loss: 0.0003411667130421847\n",
      "Epoch 2870, Loss: 0.0011093078418298319, Final Batch Loss: 1.6518814618393662e-06\n",
      "Epoch 2871, Loss: 0.0007291287747648312, Final Batch Loss: 9.340294127468951e-06\n",
      "Epoch 2872, Loss: 0.005151546560227871, Final Batch Loss: 0.0004923389642499387\n",
      "Epoch 2873, Loss: 0.008889829448889941, Final Batch Loss: 0.0\n",
      "Epoch 2874, Loss: 0.0003783360400575475, Final Batch Loss: 1.1920831184397684e-06\n",
      "Epoch 2875, Loss: 0.000842051241079389, Final Batch Loss: 2.409705075478996e-06\n",
      "Epoch 2876, Loss: 0.027743367314997158, Final Batch Loss: 5.543097813642817e-06\n",
      "Epoch 2877, Loss: 0.002837973382792569, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 2878, Loss: 0.0006463763338899753, Final Batch Loss: 3.1505263109465886e-07\n",
      "Epoch 2879, Loss: 0.005499075905390782, Final Batch Loss: 1.9839644664898515e-06\n",
      "Epoch 2880, Loss: 0.001909210786834592, Final Batch Loss: 4.460292620933615e-05\n",
      "Epoch 2881, Loss: 0.0013440487964544445, Final Batch Loss: 0.0005449592717923224\n",
      "Epoch 2882, Loss: 0.0012335608262219466, Final Batch Loss: 1.1119940609205514e-05\n",
      "Epoch 2883, Loss: 0.000767112183439167, Final Batch Loss: 3.857168394461041e-06\n",
      "Epoch 2884, Loss: 0.002245453188322699, Final Batch Loss: 4.002014861725911e-07\n",
      "Epoch 2885, Loss: 0.001517039010096255, Final Batch Loss: 1.0217935653145105e-07\n",
      "Epoch 2886, Loss: 0.0004459720739760087, Final Batch Loss: 3.89125580113614e-06\n",
      "Epoch 2887, Loss: 0.0015373375972558279, Final Batch Loss: 5.3434614528669044e-05\n",
      "Epoch 2888, Loss: 0.003658752198134607, Final Batch Loss: 1.0881675734708551e-05\n",
      "Epoch 2889, Loss: 0.001215182169403306, Final Batch Loss: 9.366442554892274e-08\n",
      "Epoch 2890, Loss: 0.0013303647375835226, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 2891, Loss: 0.002521156820876058, Final Batch Loss: 0.0010839460883289576\n",
      "Epoch 2892, Loss: 0.0017679729844530812, Final Batch Loss: 2.332715484953951e-05\n",
      "Epoch 2893, Loss: 0.0013190127901907545, Final Batch Loss: 0.00041843048529699445\n",
      "Epoch 2894, Loss: 0.0009692747735243756, Final Batch Loss: 0.0\n",
      "Epoch 2895, Loss: 0.0008637826022095396, Final Batch Loss: 6.351875526888762e-06\n",
      "Epoch 2896, Loss: 0.00024523384126950987, Final Batch Loss: 0.0\n",
      "Epoch 2897, Loss: 0.000733570528097971, Final Batch Loss: 8.089168090918974e-07\n",
      "Epoch 2898, Loss: 0.0005113554631179795, Final Batch Loss: 5.108955747346045e-07\n",
      "Epoch 2899, Loss: 0.041830206020677, Final Batch Loss: 7.527725392719731e-05\n",
      "Epoch 2900, Loss: 0.002879957503409969, Final Batch Loss: 5.406816399045056e-06\n",
      "Epoch 2901, Loss: 0.02359306333528366, Final Batch Loss: 0.0\n",
      "Epoch 2902, Loss: 0.033561476137947466, Final Batch Loss: 1.5206412172119599e-05\n",
      "Epoch 2903, Loss: 0.03696876119272474, Final Batch Loss: 5.279251809042762e-07\n",
      "Epoch 2904, Loss: 0.0013175616768421605, Final Batch Loss: 0.0010028672404587269\n",
      "Epoch 2905, Loss: 0.0009173995022138115, Final Batch Loss: 1.653493927733507e-05\n",
      "Epoch 2906, Loss: 0.0025010616456100365, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 2907, Loss: 0.0016485128880958655, Final Batch Loss: 4.9641030273051e-06\n",
      "Epoch 2908, Loss: 0.0043009588262066245, Final Batch Loss: 0.0001533127942821011\n",
      "Epoch 2909, Loss: 0.000857766534863913, Final Batch Loss: 4.63198284705868e-06\n",
      "Epoch 2910, Loss: 0.0006257681330392728, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2911, Loss: 0.0005727054760882311, Final Batch Loss: 1.1835729765152792e-06\n",
      "Epoch 2912, Loss: 0.002882922067195537, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 2913, Loss: 0.0014154888558550738, Final Batch Loss: 2.8008706067339517e-05\n",
      "Epoch 2914, Loss: 0.0010951296280836686, Final Batch Loss: 4.34514440712519e-05\n",
      "Epoch 2915, Loss: 0.00019443797655327444, Final Batch Loss: 9.366440423264066e-08\n",
      "Epoch 2916, Loss: 0.0007791054792498642, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 2917, Loss: 0.0005935729041368631, Final Batch Loss: 2.469332969212701e-07\n",
      "Epoch 2918, Loss: 0.0002696925010283735, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 2919, Loss: 0.0007516002338601169, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2920, Loss: 0.0007962991094245808, Final Batch Loss: 5.3139061492402107e-05\n",
      "Epoch 2921, Loss: 0.0007585368748550536, Final Batch Loss: 1.62617870955728e-05\n",
      "Epoch 2922, Loss: 0.00048508169493288733, Final Batch Loss: 0.0002219744201283902\n",
      "Epoch 2923, Loss: 0.0013204290685280284, Final Batch Loss: 7.739732609479688e-06\n",
      "Epoch 2924, Loss: 0.001055768953392544, Final Batch Loss: 5.543036877497798e-06\n",
      "Epoch 2925, Loss: 0.0003846577556032571, Final Batch Loss: 0.00011573678784770891\n",
      "Epoch 2926, Loss: 0.002814434281649625, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 2927, Loss: 0.0005513876376426197, Final Batch Loss: 0.00016606145072728395\n",
      "Epoch 2928, Loss: 0.00016779569750724477, Final Batch Loss: 3.976391326432349e-06\n",
      "Epoch 2929, Loss: 0.0030228716345845896, Final Batch Loss: 1.0303033377567772e-06\n",
      "Epoch 2930, Loss: 0.0031975342863006517, Final Batch Loss: 0.0\n",
      "Epoch 2931, Loss: 0.0009577597780374703, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2932, Loss: 0.0007443788854288869, Final Batch Loss: 0.0\n",
      "Epoch 2933, Loss: 0.0007007235658420541, Final Batch Loss: 5.253627477941336e-06\n",
      "Epoch 2934, Loss: 0.0002582955194156966, Final Batch Loss: 2.3225245968205854e-05\n",
      "Epoch 2935, Loss: 0.00040527841622406413, Final Batch Loss: 7.237678119054181e-07\n",
      "Epoch 2936, Loss: 0.0004344720291555859, Final Batch Loss: 2.2476018784800544e-05\n",
      "Epoch 2937, Loss: 0.00026857116267819947, Final Batch Loss: 1.3794144706480438e-06\n",
      "Epoch 2938, Loss: 0.0018483083658793475, Final Batch Loss: 3.476660276646726e-05\n",
      "Epoch 2939, Loss: 0.009413322811482772, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 2940, Loss: 0.0029904366339223998, Final Batch Loss: 9.792175887923804e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2941, Loss: 0.00035805822005841037, Final Batch Loss: 6.386184168150066e-07\n",
      "Epoch 2942, Loss: 0.001786285663637699, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 2943, Loss: 0.0009333475690311843, Final Batch Loss: 2.1287351614773797e-07\n",
      "Epoch 2944, Loss: 0.011118305490526836, Final Batch Loss: 0.010309000499546528\n",
      "Epoch 2945, Loss: 0.0005051102083726278, Final Batch Loss: 1.0217937784773312e-07\n",
      "Epoch 2946, Loss: 0.0015928491761769692, Final Batch Loss: 7.407636530842865e-06\n",
      "Epoch 2947, Loss: 0.0024326966001808614, Final Batch Loss: 2.7417615910962922e-06\n",
      "Epoch 2948, Loss: 0.0003633099609654522, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 2949, Loss: 0.0012133344964553316, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 2950, Loss: 0.0061170945093635964, Final Batch Loss: 3.661418759293156e-07\n",
      "Epoch 2951, Loss: 0.0002619558035803493, Final Batch Loss: 4.717157025879715e-06\n",
      "Epoch 2952, Loss: 0.0007484186062356457, Final Batch Loss: 0.00029971051844768226\n",
      "Epoch 2953, Loss: 0.003330974912387319, Final Batch Loss: 0.000227922442718409\n",
      "Epoch 2954, Loss: 0.0010533624363233685, Final Batch Loss: 4.9470827434561215e-06\n",
      "Epoch 2955, Loss: 0.0018094550277965027, Final Batch Loss: 8.624825568404049e-05\n",
      "Epoch 2956, Loss: 0.0010311252041148578, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2957, Loss: 0.0007222825734061189, Final Batch Loss: 0.0001482530788052827\n",
      "Epoch 2958, Loss: 0.0058362073964417505, Final Batch Loss: 0.005649189464747906\n",
      "Epoch 2959, Loss: 0.0038615814610238886, Final Batch Loss: 7.799268132657744e-06\n",
      "Epoch 2960, Loss: 0.0004254524792486336, Final Batch Loss: 5.2480801969068125e-05\n",
      "Epoch 2961, Loss: 0.005437121553420354, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 2962, Loss: 0.007066097251581027, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 2963, Loss: 0.002746554766034137, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 2964, Loss: 0.0039623362572456244, Final Batch Loss: 3.0996543500805274e-05\n",
      "Epoch 2965, Loss: 0.0072333519037783844, Final Batch Loss: 0.0\n",
      "Epoch 2966, Loss: 0.05081635123860906, Final Batch Loss: 0.00010964642569888383\n",
      "Epoch 2967, Loss: 0.003676734249893343, Final Batch Loss: 4.403721322887577e-05\n",
      "Epoch 2968, Loss: 0.0057853603229887085, Final Batch Loss: 7.149233715608716e-05\n",
      "Epoch 2969, Loss: 0.00030895408781361766, Final Batch Loss: 9.642812801757827e-05\n",
      "Epoch 2970, Loss: 0.0012175592746643815, Final Batch Loss: 0.0\n",
      "Epoch 2971, Loss: 0.0576846163294249, Final Batch Loss: 0.0006307500298134983\n",
      "Epoch 2972, Loss: 0.00048738215264165774, Final Batch Loss: 0.0001027866019285284\n",
      "Epoch 2973, Loss: 0.00029042855248917476, Final Batch Loss: 4.351014013082022e-06\n",
      "Epoch 2974, Loss: 0.0005224679514412855, Final Batch Loss: 3.099397645200952e-06\n",
      "Epoch 2975, Loss: 0.0008167684281943366, Final Batch Loss: 0.0003711255849339068\n",
      "Epoch 2976, Loss: 0.0004598288041961496, Final Batch Loss: 1.3009780559514184e-05\n",
      "Epoch 2977, Loss: 0.00034707276381595875, Final Batch Loss: 5.1598976824607234e-06\n",
      "Epoch 2978, Loss: 0.0044381535640241054, Final Batch Loss: 3.840149929601466e-06\n",
      "Epoch 2979, Loss: 0.055631584360526176, Final Batch Loss: 2.6085053832503036e-05\n",
      "Epoch 2980, Loss: 0.0019546154012459738, Final Batch Loss: 4.087063189217588e-06\n",
      "Epoch 2981, Loss: 0.0007663842741294502, Final Batch Loss: 2.5204105895682005e-06\n",
      "Epoch 2982, Loss: 0.018890349729190348, Final Batch Loss: 3.386636308277957e-05\n",
      "Epoch 2983, Loss: 0.0009305126186518464, Final Batch Loss: 0.00020340565242804587\n",
      "Epoch 2984, Loss: 0.002801524391543353, Final Batch Loss: 0.002249856712296605\n",
      "Epoch 2985, Loss: 0.0003798948446274153, Final Batch Loss: 1.3461735761666205e-05\n",
      "Epoch 2986, Loss: 0.0003592297452996718, Final Batch Loss: 2.930586379079614e-05\n",
      "Epoch 2987, Loss: 0.0006814375992689747, Final Batch Loss: 0.00010039895278168842\n",
      "Epoch 2988, Loss: 0.0034499217256893644, Final Batch Loss: 7.152542025323783e-07\n",
      "Epoch 2989, Loss: 0.002050132505246438, Final Batch Loss: 0.0005088428151793778\n",
      "Epoch 2990, Loss: 0.001003323663780975, Final Batch Loss: 0.00033814855851233006\n",
      "Epoch 2991, Loss: 0.0006464220933821707, Final Batch Loss: 1.5922779539323528e-06\n",
      "Epoch 2992, Loss: 0.004966137683368288, Final Batch Loss: 4.564067785395309e-05\n",
      "Epoch 2993, Loss: 0.0004095169460924808, Final Batch Loss: 0.00024603577912785113\n",
      "Epoch 2994, Loss: 0.00330160104931565, Final Batch Loss: 0.0020773436408489943\n",
      "Epoch 2995, Loss: 0.00041309369407827035, Final Batch Loss: 0.0\n",
      "Epoch 2996, Loss: 0.0016461174554933677, Final Batch Loss: 0.0014710944378748536\n",
      "Epoch 2997, Loss: 0.0252028147715464, Final Batch Loss: 8.514782166457735e-06\n",
      "Epoch 2998, Loss: 0.0046538901296386825, Final Batch Loss: 1.1920922560193503e-07\n",
      "Epoch 2999, Loss: 0.002654306925233385, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 3000, Loss: 0.0011648481513475417, Final Batch Loss: 4.912976692139637e-06\n",
      "Epoch 3001, Loss: 0.0008448407188552665, Final Batch Loss: 2.5371988158440217e-05\n",
      "Epoch 3002, Loss: 0.0005843307092163741, Final Batch Loss: 3.16749105877534e-06\n",
      "Epoch 3003, Loss: 0.0010573157370430408, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 3004, Loss: 0.0008986713064587093, Final Batch Loss: 0.00016958193737082183\n",
      "Epoch 3005, Loss: 0.00019027812743388495, Final Batch Loss: 1.498616825301724e-06\n",
      "Epoch 3006, Loss: 0.0005757728008575214, Final Batch Loss: 4.104114395886427e-06\n",
      "Epoch 3007, Loss: 0.0025151924783131108, Final Batch Loss: 0.0\n",
      "Epoch 3008, Loss: 0.0014478755715572333, Final Batch Loss: 2.1542496142501477e-06\n",
      "Epoch 3009, Loss: 0.0007287613670996507, Final Batch Loss: 8.259476089733653e-07\n",
      "Epoch 3010, Loss: 0.0028032618647557683, Final Batch Loss: 1.4201730664353818e-05\n",
      "Epoch 3011, Loss: 0.0010053113683170523, Final Batch Loss: 6.129709800006822e-05\n",
      "Epoch 3012, Loss: 0.0001166402635135455, Final Batch Loss: 1.846796840254683e-05\n",
      "Epoch 3013, Loss: 0.0002451783475407865, Final Batch Loss: 2.0450996089493856e-05\n",
      "Epoch 3014, Loss: 0.002133083494982202, Final Batch Loss: 2.7758449050452327e-06\n",
      "Epoch 3015, Loss: 0.0005164100803085603, Final Batch Loss: 3.23859385389369e-05\n",
      "Epoch 3016, Loss: 0.0005114901714478037, Final Batch Loss: 1.2550087376439478e-05\n",
      "Epoch 3017, Loss: 0.00016728258651710348, Final Batch Loss: 0.0\n",
      "Epoch 3018, Loss: 0.0002965800272889396, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3019, Loss: 0.00139998625672888, Final Batch Loss: 3.6878929677186534e-05\n",
      "Epoch 3020, Loss: 0.0011205353011973784, Final Batch Loss: 1.202226212626556e-05\n",
      "Epoch 3021, Loss: 0.00013750162264614119, Final Batch Loss: 3.405975235182268e-07\n",
      "Epoch 3022, Loss: 0.00013002697323827306, Final Batch Loss: 8.659179911774117e-06\n",
      "Epoch 3023, Loss: 0.00047799685580685036, Final Batch Loss: 0.00011816793994512409\n",
      "Epoch 3024, Loss: 0.0019627368698138525, Final Batch Loss: 1.2602055221577757e-06\n",
      "Epoch 3025, Loss: 0.0004453237185657599, Final Batch Loss: 9.025804388329561e-07\n",
      "Epoch 3026, Loss: 0.0004751613098825658, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3027, Loss: 0.013387085342856153, Final Batch Loss: 5.057708676758921e-06\n",
      "Epoch 3028, Loss: 0.013923877255365369, Final Batch Loss: 3.223420571885072e-05\n",
      "Epoch 3029, Loss: 0.02474685215520367, Final Batch Loss: 3.542183094396023e-06\n",
      "Epoch 3030, Loss: 0.0012485613229955561, Final Batch Loss: 1.498616825301724e-06\n",
      "Epoch 3031, Loss: 0.0003311847820945957, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3032, Loss: 0.0021315651542863634, Final Batch Loss: 4.359579634183319e-06\n",
      "Epoch 3033, Loss: 0.0012586049197125249, Final Batch Loss: 0.00020790845155715942\n",
      "Epoch 3034, Loss: 0.005586011233390309, Final Batch Loss: 6.26114197075367e-05\n",
      "Epoch 3035, Loss: 0.00265784415159942, Final Batch Loss: 3.3463488762208726e-06\n",
      "Epoch 3036, Loss: 0.0005126123364789237, Final Batch Loss: 4.504323896981077e-06\n",
      "Epoch 3037, Loss: 0.0011560605203726482, Final Batch Loss: 5.875304509572743e-07\n",
      "Epoch 3038, Loss: 0.013584219102995121, Final Batch Loss: 1.5615531083312817e-05\n",
      "Epoch 3039, Loss: 0.00788377461503842, Final Batch Loss: 2.8191154342493974e-05\n",
      "Epoch 3040, Loss: 0.0063240673844120465, Final Batch Loss: 1.8517719581723213e-05\n",
      "Epoch 3041, Loss: 0.0005912371198064648, Final Batch Loss: 6.483757169917226e-05\n",
      "Epoch 3042, Loss: 0.00693940524070058, Final Batch Loss: 0.0027909004129469395\n",
      "Epoch 3043, Loss: 0.049388028934117756, Final Batch Loss: 2.542987022025045e-05\n",
      "Epoch 3044, Loss: 0.003159977939503733, Final Batch Loss: 3.790332266362384e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3045, Loss: 0.01820507488992007, Final Batch Loss: 2.3823629817343317e-05\n",
      "Epoch 3046, Loss: 0.0012837534386562766, Final Batch Loss: 1.449990759283537e-05\n",
      "Epoch 3047, Loss: 0.006651392186540761, Final Batch Loss: 1.998198604269419e-05\n",
      "Epoch 3048, Loss: 0.0004961150252711377, Final Batch Loss: 4.129694389121141e-06\n",
      "Epoch 3049, Loss: 0.029523785054919927, Final Batch Loss: 4.3426175011518353e-07\n",
      "Epoch 3050, Loss: 0.00608998733722288, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3051, Loss: 0.000282089530628582, Final Batch Loss: 1.2422309737303294e-05\n",
      "Epoch 3052, Loss: 0.0012266528174222913, Final Batch Loss: 3.1439933081856e-05\n",
      "Epoch 3053, Loss: 0.006307334700636602, Final Batch Loss: 2.3841823804104934e-07\n",
      "Epoch 3054, Loss: 0.0009957226959933507, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3055, Loss: 0.0005685917794835404, Final Batch Loss: 1.2754557246807963e-05\n",
      "Epoch 3056, Loss: 0.004305166221456602, Final Batch Loss: 0.0006434762617573142\n",
      "Epoch 3057, Loss: 0.0010035117284132866, Final Batch Loss: 7.90152080298867e-06\n",
      "Epoch 3058, Loss: 0.006836523716629017, Final Batch Loss: 0.005916661582887173\n",
      "Epoch 3059, Loss: 0.0006771305010033757, Final Batch Loss: 7.748561756670824e-07\n",
      "Epoch 3060, Loss: 0.0013269827713884297, Final Batch Loss: 7.033021574898157e-06\n",
      "Epoch 3061, Loss: 0.001372266240650788, Final Batch Loss: 2.290493284817785e-06\n",
      "Epoch 3062, Loss: 0.0005450198841572274, Final Batch Loss: 2.4527358618797734e-05\n",
      "Epoch 3063, Loss: 0.0010883064169320278, Final Batch Loss: 0.0007843325147405267\n",
      "Epoch 3064, Loss: 0.0006973932004257222, Final Batch Loss: 2.3846501790103503e-05\n",
      "Epoch 3065, Loss: 0.005497142795187315, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3066, Loss: 0.0006006294747749052, Final Batch Loss: 6.096571723901434e-06\n",
      "Epoch 3067, Loss: 0.001572085871885065, Final Batch Loss: 0.0004957174533046782\n",
      "Epoch 3068, Loss: 0.000489169537104317, Final Batch Loss: 1.6032723578973673e-05\n",
      "Epoch 3069, Loss: 0.0007742241214145906, Final Batch Loss: 0.00011576170072657987\n",
      "Epoch 3070, Loss: 0.0012290554627725214, Final Batch Loss: 2.213852440036135e-06\n",
      "Epoch 3071, Loss: 0.0016534564419998787, Final Batch Loss: 8.183356112567708e-05\n",
      "Epoch 3072, Loss: 0.000404351152496929, Final Batch Loss: 1.8902936744780163e-06\n",
      "Epoch 3073, Loss: 0.0007265577003181534, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 3074, Loss: 0.0050182798353262115, Final Batch Loss: 1.1324794968459173e-06\n",
      "Epoch 3075, Loss: 0.0004748006995214382, Final Batch Loss: 0.0002564866153988987\n",
      "Epoch 3076, Loss: 0.00032329974510503234, Final Batch Loss: 4.5387354475678876e-05\n",
      "Epoch 3077, Loss: 0.0025052111434433755, Final Batch Loss: 2.7077023787569487e-06\n",
      "Epoch 3078, Loss: 0.008765949914959492, Final Batch Loss: 3.6903533327858895e-05\n",
      "Epoch 3079, Loss: 0.011592498934078321, Final Batch Loss: 5.798560778202955e-06\n",
      "Epoch 3080, Loss: 0.00833883710038208, Final Batch Loss: 0.00022750701464246958\n",
      "Epoch 3081, Loss: 0.008050169428315712, Final Batch Loss: 3.0844243156025186e-05\n",
      "Epoch 3082, Loss: 0.0028349317622087256, Final Batch Loss: 7.15236501491745e-06\n",
      "Epoch 3083, Loss: 0.0005122806023791782, Final Batch Loss: 4.0274853745359e-06\n",
      "Epoch 3084, Loss: 0.0006531595463457052, Final Batch Loss: 9.32832044782117e-05\n",
      "Epoch 3085, Loss: 0.0015383218388365094, Final Batch Loss: 4.768363055518421e-07\n",
      "Epoch 3086, Loss: 0.00032217448233495816, Final Batch Loss: 2.7843357202073094e-06\n",
      "Epoch 3087, Loss: 0.001202057464979589, Final Batch Loss: 1.665333184064366e-05\n",
      "Epoch 3088, Loss: 0.0014012933970661834, Final Batch Loss: 0.0002581448934506625\n",
      "Epoch 3089, Loss: 0.0009361263055325253, Final Batch Loss: 3.46931119565852e-05\n",
      "Epoch 3090, Loss: 0.0010981314044329338, Final Batch Loss: 0.0002038887032540515\n",
      "Epoch 3091, Loss: 0.0008732633941690437, Final Batch Loss: 7.124309922801331e-05\n",
      "Epoch 3092, Loss: 0.0012575457085404196, Final Batch Loss: 3.874240974255372e-06\n",
      "Epoch 3093, Loss: 0.001240436505213438, Final Batch Loss: 6.8967756305937655e-06\n",
      "Epoch 3094, Loss: 0.0018842220524675213, Final Batch Loss: 0.0\n",
      "Epoch 3095, Loss: 0.019926752080209553, Final Batch Loss: 6.769090396119282e-05\n",
      "Epoch 3096, Loss: 0.020472294356295606, Final Batch Loss: 0.0\n",
      "Epoch 3097, Loss: 0.030991736108717305, Final Batch Loss: 4.5213496377982665e-06\n",
      "Epoch 3098, Loss: 0.0004927369819824889, Final Batch Loss: 9.366442554892274e-08\n",
      "Epoch 3099, Loss: 0.0016704850133919535, Final Batch Loss: 2.3330578642344335e-06\n",
      "Epoch 3100, Loss: 0.0016292727121509643, Final Batch Loss: 2.3841842278216063e-07\n",
      "Epoch 3101, Loss: 0.0016771251398495224, Final Batch Loss: 2.0350566956039984e-06\n",
      "Epoch 3102, Loss: 0.0331131865241332, Final Batch Loss: 0.00011910016473848373\n",
      "Epoch 3103, Loss: 0.008284642410451681, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 3104, Loss: 0.0008677182800056471, Final Batch Loss: 7.4588701863831375e-06\n",
      "Epoch 3105, Loss: 0.013482913597272272, Final Batch Loss: 2.48632977672969e-06\n",
      "Epoch 3106, Loss: 0.001489367833983124, Final Batch Loss: 4.853357950196369e-06\n",
      "Epoch 3107, Loss: 0.0013022218082880954, Final Batch Loss: 3.746573895568872e-07\n",
      "Epoch 3108, Loss: 0.0011011436308763223, Final Batch Loss: 1.8220001948066056e-05\n",
      "Epoch 3109, Loss: 0.00294928661242011, Final Batch Loss: 0.0008642789325676858\n",
      "Epoch 3110, Loss: 0.0028883622708235634, Final Batch Loss: 1.9582037566578947e-05\n",
      "Epoch 3111, Loss: 0.0002584701074450635, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3112, Loss: 0.0004498335174503154, Final Batch Loss: 5.6026174206635915e-06\n",
      "Epoch 3113, Loss: 0.000612946898122857, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3114, Loss: 0.0005696718326362316, Final Batch Loss: 6.235974433366209e-05\n",
      "Epoch 3115, Loss: 0.002695694411158911, Final Batch Loss: 2.860999302356504e-06\n",
      "Epoch 3116, Loss: 0.001629368107904483, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3117, Loss: 0.0005906700653213193, Final Batch Loss: 1.2720222912321333e-05\n",
      "Epoch 3118, Loss: 0.0006610554937651614, Final Batch Loss: 0.0004967519198544323\n",
      "Epoch 3119, Loss: 0.0005195507012558664, Final Batch Loss: 2.1968419332552003e-06\n",
      "Epoch 3120, Loss: 0.0005142845776688887, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3121, Loss: 0.03354329137698642, Final Batch Loss: 6.64162939756352e-07\n",
      "Epoch 3122, Loss: 0.0013591312144853873, Final Batch Loss: 8.668410737300292e-05\n",
      "Epoch 3123, Loss: 0.0010700100433496118, Final Batch Loss: 5.500504357769387e-06\n",
      "Epoch 3124, Loss: 0.00311082185135092, Final Batch Loss: 7.382086096185958e-06\n",
      "Epoch 3125, Loss: 0.0003253013637731783, Final Batch Loss: 5.9707705077016726e-05\n",
      "Epoch 3126, Loss: 0.000564950646548823, Final Batch Loss: 7.714287676208187e-06\n",
      "Epoch 3127, Loss: 0.002198537810045309, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3128, Loss: 0.001865012636699248, Final Batch Loss: 0.0\n",
      "Epoch 3129, Loss: 0.0033890062947818933, Final Batch Loss: 4.683213035150402e-07\n",
      "Epoch 3130, Loss: 0.0018500012426514445, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3131, Loss: 0.001074248028345437, Final Batch Loss: 3.2356754786633246e-07\n",
      "Epoch 3132, Loss: 0.0005252224083349688, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3133, Loss: 0.00043200579602853395, Final Batch Loss: 7.479020860046148e-05\n",
      "Epoch 3134, Loss: 0.0005634040680888575, Final Batch Loss: 0.00022870000975672156\n",
      "Epoch 3135, Loss: 0.0014429411603487097, Final Batch Loss: 0.0005339495837688446\n",
      "Epoch 3136, Loss: 0.0006930971899237193, Final Batch Loss: 2.4522664716641884e-06\n",
      "Epoch 3137, Loss: 0.0006381581461027963, Final Batch Loss: 1.4696035577799194e-05\n",
      "Epoch 3138, Loss: 0.0007529280555900186, Final Batch Loss: 0.0\n",
      "Epoch 3139, Loss: 0.0011049786221519753, Final Batch Loss: 0.00018688468844629824\n",
      "Epoch 3140, Loss: 0.014021502776813577, Final Batch Loss: 0.0\n",
      "Epoch 3141, Loss: 0.0006387468502992988, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 3142, Loss: 0.0009836924354544863, Final Batch Loss: 4.5980681306900806e-07\n",
      "Epoch 3143, Loss: 0.0006236690675223144, Final Batch Loss: 1.0558466101429076e-06\n",
      "Epoch 3144, Loss: 0.00027159184173797257, Final Batch Loss: 2.234853855043184e-05\n",
      "Epoch 3145, Loss: 0.00037160310148465214, Final Batch Loss: 1.1451708815002348e-05\n",
      "Epoch 3146, Loss: 0.0018773112060443964, Final Batch Loss: 2.4893422960303724e-05\n",
      "Epoch 3147, Loss: 0.0015579435803516617, Final Batch Loss: 1.8732863793502474e-07\n",
      "Epoch 3148, Loss: 0.002881815796627052, Final Batch Loss: 5.440940640255576e-06\n",
      "Epoch 3149, Loss: 0.0013279505951686588, Final Batch Loss: 3.806090262514772e-06\n",
      "Epoch 3150, Loss: 0.001345362928589111, Final Batch Loss: 6.301048074419668e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3151, Loss: 0.0007559071631391134, Final Batch Loss: 1.0217935653145105e-07\n",
      "Epoch 3152, Loss: 0.0003622506706051354, Final Batch Loss: 6.437030151573708e-06\n",
      "Epoch 3153, Loss: 0.011356640358485492, Final Batch Loss: 1.5411957292599254e-06\n",
      "Epoch 3154, Loss: 0.030444966745108104, Final Batch Loss: 4.691620688390685e-06\n",
      "Epoch 3155, Loss: 0.0011299317275188514, Final Batch Loss: 6.897004823258612e-06\n",
      "Epoch 3156, Loss: 0.0008270852101759374, Final Batch Loss: 2.426751734674326e-06\n",
      "Epoch 3157, Loss: 0.027364584917904722, Final Batch Loss: 6.334858426271239e-06\n",
      "Epoch 3158, Loss: 0.0037644327749148943, Final Batch Loss: 0.00023667544883210212\n",
      "Epoch 3159, Loss: 0.0006696203981846338, Final Batch Loss: 5.194106051931158e-07\n",
      "Epoch 3160, Loss: 0.0021083458268549293, Final Batch Loss: 0.0001789129601093009\n",
      "Epoch 3161, Loss: 0.0006608564549424045, Final Batch Loss: 5.185419013287174e-06\n",
      "Epoch 3162, Loss: 0.008407354263965772, Final Batch Loss: 4.6832070665914216e-07\n",
      "Epoch 3163, Loss: 0.0009609108133190603, Final Batch Loss: 3.3207984415639658e-06\n",
      "Epoch 3164, Loss: 0.0007750181097776476, Final Batch Loss: 8.600067644692899e-07\n",
      "Epoch 3165, Loss: 0.017539823311381042, Final Batch Loss: 0.0003610917192418128\n",
      "Epoch 3166, Loss: 0.02170688339174376, Final Batch Loss: 2.2646203433396295e-05\n",
      "Epoch 3167, Loss: 0.0012117643018250135, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 3168, Loss: 0.0015685322765008891, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 3169, Loss: 0.0014406460483833428, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3170, Loss: 0.0010822965208490132, Final Batch Loss: 6.215899475137121e-07\n",
      "Epoch 3171, Loss: 0.00017820730954554165, Final Batch Loss: 1.1665442798403092e-06\n",
      "Epoch 3172, Loss: 0.003751679709239397, Final Batch Loss: 0.0\n",
      "Epoch 3173, Loss: 0.014073045193072176, Final Batch Loss: 5.159923603059724e-06\n",
      "Epoch 3174, Loss: 0.004861953973861688, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3175, Loss: 0.00463963508279619, Final Batch Loss: 1.2772413526818127e-07\n",
      "Epoch 3176, Loss: 0.0010586851349216886, Final Batch Loss: 1.8858134353649803e-05\n",
      "Epoch 3177, Loss: 0.0009087003418244421, Final Batch Loss: 0.00011621951125562191\n",
      "Epoch 3178, Loss: 0.0013999530347064137, Final Batch Loss: 0.0001688985648797825\n",
      "Epoch 3179, Loss: 0.0007592940455651842, Final Batch Loss: 6.792999192839488e-05\n",
      "Epoch 3180, Loss: 0.00046497684797941474, Final Batch Loss: 3.081750764977187e-05\n",
      "Epoch 3181, Loss: 0.0013624945013361867, Final Batch Loss: 4.904485649603885e-06\n",
      "Epoch 3182, Loss: 0.0005714251673651916, Final Batch Loss: 1.1920921849650767e-07\n",
      "Epoch 3183, Loss: 0.0007199790322331978, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3184, Loss: 0.01509602736814486, Final Batch Loss: 4.427646217664005e-06\n",
      "Epoch 3185, Loss: 0.0009046878076333087, Final Batch Loss: 4.887438990408555e-06\n",
      "Epoch 3186, Loss: 0.0008773695626587141, Final Batch Loss: 0.0\n",
      "Epoch 3187, Loss: 0.0002870460141366493, Final Batch Loss: 1.260203362107859e-06\n",
      "Epoch 3188, Loss: 0.0021955403790343553, Final Batch Loss: 0.0\n",
      "Epoch 3189, Loss: 0.003891115688929858, Final Batch Loss: 8.880638233677018e-06\n",
      "Epoch 3190, Loss: 0.00043315402729149355, Final Batch Loss: 1.047333739734313e-06\n",
      "Epoch 3191, Loss: 0.0013533200183246663, Final Batch Loss: 1.1920876659132773e-06\n",
      "Epoch 3192, Loss: 0.0016431746880698483, Final Batch Loss: 6.301722896751016e-05\n",
      "Epoch 3193, Loss: 0.00020714662900900294, Final Batch Loss: 1.0388177997810999e-06\n",
      "Epoch 3194, Loss: 0.0003761490370379761, Final Batch Loss: 8.31032775749918e-06\n",
      "Epoch 3195, Loss: 0.002159504247174482, Final Batch Loss: 0.0\n",
      "Epoch 3196, Loss: 0.0005116317589113351, Final Batch Loss: 7.152526109166502e-07\n",
      "Epoch 3197, Loss: 0.000980808184522175, Final Batch Loss: 1.7939175450010225e-05\n",
      "Epoch 3198, Loss: 0.0010142329533664451, Final Batch Loss: 2.6310949579055887e-06\n",
      "Epoch 3199, Loss: 0.00019085766507487278, Final Batch Loss: 5.23307899129577e-05\n",
      "Epoch 3200, Loss: 0.0010974499164149165, Final Batch Loss: 0.000468054466182366\n",
      "Epoch 3201, Loss: 0.0008957357184300463, Final Batch Loss: 2.128734450934644e-07\n",
      "Epoch 3202, Loss: 0.00010440694313729182, Final Batch Loss: 4.053688098792918e-05\n",
      "Epoch 3203, Loss: 0.0008141502403304912, Final Batch Loss: 2.750275598373264e-06\n",
      "Epoch 3204, Loss: 0.00034203732408855103, Final Batch Loss: 2.809929071645456e-07\n",
      "Epoch 3205, Loss: 0.0008814157736196648, Final Batch Loss: 1.663628609094303e-05\n",
      "Epoch 3206, Loss: 0.0011235696365474723, Final Batch Loss: 0.0\n",
      "Epoch 3207, Loss: 0.0006757398978152196, Final Batch Loss: 4.155176156928064e-06\n",
      "Epoch 3208, Loss: 0.0006017598357175302, Final Batch Loss: 7.67155688663479e-06\n",
      "Epoch 3209, Loss: 0.0006609252804992138, Final Batch Loss: 7.72264593251748e-06\n",
      "Epoch 3210, Loss: 0.009480399910870574, Final Batch Loss: 4.598059319960157e-07\n",
      "Epoch 3211, Loss: 0.0019877242393704364, Final Batch Loss: 0.0001617927773622796\n",
      "Epoch 3212, Loss: 0.0005736828443332342, Final Batch Loss: 0.0\n",
      "Epoch 3213, Loss: 0.004547873959381832, Final Batch Loss: 5.067154415883124e-05\n",
      "Epoch 3214, Loss: 0.000682867509148366, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 3215, Loss: 0.0004720540559901565, Final Batch Loss: 2.2564258870261256e-06\n",
      "Epoch 3216, Loss: 0.002837351088860629, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3217, Loss: 0.00044203880952409236, Final Batch Loss: 6.460338045144454e-05\n",
      "Epoch 3218, Loss: 0.000742624025273031, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3219, Loss: 0.0035039907543250592, Final Batch Loss: 1.400571818521712e-05\n",
      "Epoch 3220, Loss: 0.0004533627472937951, Final Batch Loss: 2.1968373857816914e-06\n",
      "Epoch 3221, Loss: 0.0008231738693780244, Final Batch Loss: 5.790143973172235e-07\n",
      "Epoch 3222, Loss: 0.0022987785436328068, Final Batch Loss: 3.06537828009823e-07\n",
      "Epoch 3223, Loss: 0.0003881580942106666, Final Batch Loss: 0.00018266738334205002\n",
      "Epoch 3224, Loss: 0.00042116564691241365, Final Batch Loss: 2.794060310407076e-05\n",
      "Epoch 3225, Loss: 0.002630624412176985, Final Batch Loss: 7.058549726934871e-06\n",
      "Epoch 3226, Loss: 0.00040574282161287556, Final Batch Loss: 2.707706016735756e-06\n",
      "Epoch 3227, Loss: 0.0030069416025071405, Final Batch Loss: 5.37943014933262e-05\n",
      "Epoch 3228, Loss: 0.0004124057245462609, Final Batch Loss: 8.255561988335103e-05\n",
      "Epoch 3229, Loss: 0.0012005441344626888, Final Batch Loss: 0.00010963547538267449\n",
      "Epoch 3230, Loss: 0.0001844267695858548, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3231, Loss: 0.0017424998683281956, Final Batch Loss: 7.407967359540635e-07\n",
      "Epoch 3232, Loss: 0.023533360831084593, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3233, Loss: 0.00018584342342364835, Final Batch Loss: 9.621487151889596e-06\n",
      "Epoch 3234, Loss: 0.0004836767847109513, Final Batch Loss: 1.8647523347681272e-06\n",
      "Epoch 3235, Loss: 0.0021464324405027213, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3236, Loss: 0.0046551496743632015, Final Batch Loss: 0.0005105222226120532\n",
      "Epoch 3237, Loss: 0.0031727790756121976, Final Batch Loss: 1.966687159438152e-05\n",
      "Epoch 3238, Loss: 0.0012312802800806821, Final Batch Loss: 0.00013257433602120727\n",
      "Epoch 3239, Loss: 0.008360668213185818, Final Batch Loss: 1.3623788390759728e-06\n",
      "Epoch 3240, Loss: 0.02253568037849618, Final Batch Loss: 0.0003958045563194901\n",
      "Epoch 3241, Loss: 0.0010683948182759195, Final Batch Loss: 2.077629460472963e-06\n",
      "Epoch 3242, Loss: 0.000962909196914552, Final Batch Loss: 9.281234270019922e-07\n",
      "Epoch 3243, Loss: 0.009371438668615895, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3244, Loss: 0.005745818119521573, Final Batch Loss: 3.3888695725181606e-06\n",
      "Epoch 3245, Loss: 0.012384718104840431, Final Batch Loss: 0.0026741556357592344\n",
      "Epoch 3246, Loss: 0.0015835794943086512, Final Batch Loss: 3.678363555081887e-06\n",
      "Epoch 3247, Loss: 0.0015134710474740132, Final Batch Loss: 7.910121894383337e-06\n",
      "Epoch 3248, Loss: 0.003101956888940549, Final Batch Loss: 2.5118681605817983e-06\n",
      "Epoch 3249, Loss: 0.002227421253337525, Final Batch Loss: 0.001837254618294537\n",
      "Epoch 3250, Loss: 0.016985320090107336, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3251, Loss: 0.029597829688327693, Final Batch Loss: 2.281976094309357e-06\n",
      "Epoch 3252, Loss: 0.002168878085740289, Final Batch Loss: 3.9763822314853314e-06\n",
      "Epoch 3253, Loss: 0.00040394297207058116, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 3254, Loss: 0.0004038766221583501, Final Batch Loss: 1.0984233540511923e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3255, Loss: 0.00011984784012852856, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3256, Loss: 0.003610941377701238, Final Batch Loss: 7.24204073776491e-05\n",
      "Epoch 3257, Loss: 0.0001897478205137304, Final Batch Loss: 6.121986189100426e-06\n",
      "Epoch 3258, Loss: 0.0013527183800761122, Final Batch Loss: 0.0\n",
      "Epoch 3259, Loss: 0.0025316279588878388, Final Batch Loss: 0.0\n",
      "Epoch 3260, Loss: 0.0005668979986239719, Final Batch Loss: 2.1116768493811833e-06\n",
      "Epoch 3261, Loss: 0.00019848117352694317, Final Batch Loss: 8.089156722235202e-07\n",
      "Epoch 3262, Loss: 0.00032495696476431135, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3263, Loss: 0.002371500764361656, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3264, Loss: 0.0003709498082571372, Final Batch Loss: 4.7341559366032016e-06\n",
      "Epoch 3265, Loss: 0.0008397222595561971, Final Batch Loss: 1.3623910888327373e-07\n",
      "Epoch 3266, Loss: 0.013847856429492822, Final Batch Loss: 0.01351266447454691\n",
      "Epoch 3267, Loss: 0.00014165155634771054, Final Batch Loss: 2.2990325021510216e-07\n",
      "Epoch 3268, Loss: 0.0009929833143544897, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 3269, Loss: 0.0016415718132805068, Final Batch Loss: 3.3208246463800606e-07\n",
      "Epoch 3270, Loss: 0.0007430767917071535, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 3271, Loss: 0.0005623013159947732, Final Batch Loss: 1.328325879512704e-06\n",
      "Epoch 3272, Loss: 0.003825441144449826, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3273, Loss: 0.00020865138883152667, Final Batch Loss: 1.2772413526818127e-07\n",
      "Epoch 3274, Loss: 0.00012859663070230454, Final Batch Loss: 1.5469990103156306e-05\n",
      "Epoch 3275, Loss: 0.00022107126233095187, Final Batch Loss: 0.0\n",
      "Epoch 3276, Loss: 0.007204328799389259, Final Batch Loss: 2.247915517727961e-06\n",
      "Epoch 3277, Loss: 0.001280045240491745, Final Batch Loss: 1.7317308447672985e-05\n",
      "Epoch 3278, Loss: 0.000490654564927695, Final Batch Loss: 1.0217932810974162e-07\n",
      "Epoch 3279, Loss: 0.0005894920941500459, Final Batch Loss: 2.0662957467720844e-05\n",
      "Epoch 3280, Loss: 0.001123830143029636, Final Batch Loss: 3.1505251740782114e-07\n",
      "Epoch 3281, Loss: 0.0016002640884380526, Final Batch Loss: 1.481593017160776e-06\n",
      "Epoch 3282, Loss: 0.0007770130509925366, Final Batch Loss: 4.436151812114986e-06\n",
      "Epoch 3283, Loss: 0.00037972348604853323, Final Batch Loss: 3.4399565720377723e-06\n",
      "Epoch 3284, Loss: 0.0007868729938991237, Final Batch Loss: 8.17430532151775e-07\n",
      "Epoch 3285, Loss: 0.0001757659138093004, Final Batch Loss: 1.3035883966949768e-05\n",
      "Epoch 3286, Loss: 0.002307818480403512, Final Batch Loss: 0.00209805672056973\n",
      "Epoch 3287, Loss: 0.00028713387996504025, Final Batch Loss: 8.83478278410621e-05\n",
      "Epoch 3288, Loss: 0.00020198966512907646, Final Batch Loss: 5.883719040866708e-06\n",
      "Epoch 3289, Loss: 0.000161007808856084, Final Batch Loss: 1.186050667456584e-05\n",
      "Epoch 3290, Loss: 0.000951015301325242, Final Batch Loss: 7.450192697433522e-06\n",
      "Epoch 3291, Loss: 0.0032702015469112666, Final Batch Loss: 0.0\n",
      "Epoch 3292, Loss: 0.0017944428423106729, Final Batch Loss: 2.2649423954135273e-06\n",
      "Epoch 3293, Loss: 0.0007163825619986852, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3294, Loss: 9.492035417224542e-05, Final Batch Loss: 1.1580237924135872e-06\n",
      "Epoch 3295, Loss: 0.00048275410816600584, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3296, Loss: 0.000578964477512045, Final Batch Loss: 1.5326904190260393e-07\n",
      "Epoch 3297, Loss: 0.00016679338477842975, Final Batch Loss: 0.0\n",
      "Epoch 3298, Loss: 0.0022030732054965085, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3299, Loss: 0.000822833220809116, Final Batch Loss: 1.8985820133821107e-05\n",
      "Epoch 3300, Loss: 0.000353650638317049, Final Batch Loss: 1.8221771824755706e-06\n",
      "Epoch 3301, Loss: 0.04679038734849428, Final Batch Loss: 4.7683653292551753e-07\n",
      "Epoch 3302, Loss: 0.0002959028261102503, Final Batch Loss: 0.0\n",
      "Epoch 3303, Loss: 0.026149829826213278, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3304, Loss: 0.0002453466372571711, Final Batch Loss: 2.290504653501557e-06\n",
      "Epoch 3305, Loss: 0.001770798222683112, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3306, Loss: 0.000440620353376886, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3307, Loss: 0.0009431760809093248, Final Batch Loss: 3.625807221396826e-05\n",
      "Epoch 3308, Loss: 0.0009396753661512491, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3309, Loss: 0.0018077027780236676, Final Batch Loss: 2.553177000663709e-05\n",
      "Epoch 3310, Loss: 0.000198653489210443, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3311, Loss: 0.0001250118090183605, Final Batch Loss: 1.6774334881120012e-06\n",
      "Epoch 3312, Loss: 0.0008147120942112451, Final Batch Loss: 9.792137234398979e-07\n",
      "Epoch 3313, Loss: 0.013726635623243055, Final Batch Loss: 0.009735642932355404\n",
      "Epoch 3314, Loss: 0.0007262583221745444, Final Batch Loss: 0.0003375431406311691\n",
      "Epoch 3315, Loss: 0.00015760891333727045, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3316, Loss: 0.00025917734052960384, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3317, Loss: 0.0001628811378147077, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3318, Loss: 0.003872038081226492, Final Batch Loss: 5.094379957881756e-05\n",
      "Epoch 3319, Loss: 0.00044406014265874205, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3320, Loss: 0.03792227365426548, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3321, Loss: 0.0005762968935414392, Final Batch Loss: 2.060588030872168e-06\n",
      "Epoch 3322, Loss: 0.007305196737888764, Final Batch Loss: 6.862720056233229e-06\n",
      "Epoch 3323, Loss: 0.0101169568606565, Final Batch Loss: 0.0025390214286744595\n",
      "Epoch 3324, Loss: 0.007005360457696952, Final Batch Loss: 0.0016864737262949347\n",
      "Epoch 3325, Loss: 0.02495104130866821, Final Batch Loss: 0.00021879847918171436\n",
      "Epoch 3326, Loss: 0.00506643674348517, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3327, Loss: 0.028203151183817, Final Batch Loss: 3.405971540360042e-07\n",
      "Epoch 3328, Loss: 0.0026184292920561347, Final Batch Loss: 9.792130413188715e-07\n",
      "Epoch 3329, Loss: 0.008962244651002038, Final Batch Loss: 2.7247340312896995e-06\n",
      "Epoch 3330, Loss: 0.03988595189366606, Final Batch Loss: 1.0353470315749291e-05\n",
      "Epoch 3331, Loss: 0.000926940640056273, Final Batch Loss: 3.851249857689254e-05\n",
      "Epoch 3332, Loss: 0.0204327122891641, Final Batch Loss: 7.493117095691559e-07\n",
      "Epoch 3333, Loss: 0.0008318890363625542, Final Batch Loss: 3.5761954677582253e-06\n",
      "Epoch 3334, Loss: 0.0023748888961563352, Final Batch Loss: 0.0013696170644834638\n",
      "Epoch 3335, Loss: 0.003976833192723461, Final Batch Loss: 4.853510517932591e-07\n",
      "Epoch 3336, Loss: 0.002020192605414195, Final Batch Loss: 0.0009136507869698107\n",
      "Epoch 3337, Loss: 0.0005290837045777153, Final Batch Loss: 2.486335915818927e-06\n",
      "Epoch 3338, Loss: 0.021038502381998114, Final Batch Loss: 1.5147292288020253e-05\n",
      "Epoch 3339, Loss: 0.005224643733527046, Final Batch Loss: 0.004349167924374342\n",
      "Epoch 3340, Loss: 0.01156890346152828, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3341, Loss: 0.04719902513170382, Final Batch Loss: 0.04678700119256973\n",
      "Epoch 3342, Loss: 0.024090757460044188, Final Batch Loss: 1.5922789771138923e-06\n",
      "Epoch 3343, Loss: 0.0007016172157818801, Final Batch Loss: 9.40003610594431e-06\n",
      "Epoch 3344, Loss: 0.012599638596707763, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3345, Loss: 0.005713056326371202, Final Batch Loss: 2.1287358720201155e-07\n",
      "Epoch 3346, Loss: 0.023234127154864836, Final Batch Loss: 5.4834308684803545e-06\n",
      "Epoch 3347, Loss: 0.0036680759570941746, Final Batch Loss: 1.9584366839353606e-07\n",
      "Epoch 3348, Loss: 0.0004130249881200143, Final Batch Loss: 4.478796654439066e-06\n",
      "Epoch 3349, Loss: 0.0027438622715010297, Final Batch Loss: 3.405971540360042e-07\n",
      "Epoch 3350, Loss: 0.016693739434174404, Final Batch Loss: 2.809928787428362e-07\n",
      "Epoch 3351, Loss: 0.0024033824192883912, Final Batch Loss: 4.611108670360409e-05\n",
      "Epoch 3352, Loss: 0.000595376720866625, Final Batch Loss: 3.141947217955021e-06\n",
      "Epoch 3353, Loss: 0.023417277413045667, Final Batch Loss: 2.903538643295178e-06\n",
      "Epoch 3354, Loss: 0.004371709792678757, Final Batch Loss: 7.152542025323783e-07\n",
      "Epoch 3355, Loss: 0.004026287840709131, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 3356, Loss: 0.000663065954540798, Final Batch Loss: 5.99890663579572e-05\n",
      "Epoch 3357, Loss: 0.011323562765539918, Final Batch Loss: 7.407994075947499e-07\n",
      "Epoch 3358, Loss: 0.0003274435688744859, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3359, Loss: 0.000655498140531563, Final Batch Loss: 2.0265447346901055e-06\n",
      "Epoch 3360, Loss: 0.00037982159372518254, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 3361, Loss: 0.0014266619504503808, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3362, Loss: 0.006136196780062164, Final Batch Loss: 6.642605876550078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3363, Loss: 0.007511420548325987, Final Batch Loss: 2.4511342417099513e-05\n",
      "Epoch 3364, Loss: 0.0010628822476839161, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3365, Loss: 0.013063477206742391, Final Batch Loss: 0.012731743976473808\n",
      "Epoch 3366, Loss: 0.0023218436676870624, Final Batch Loss: 3.712421403179178e-06\n",
      "Epoch 3367, Loss: 0.001781786196829671, Final Batch Loss: 6.386195536833839e-07\n",
      "Epoch 3368, Loss: 0.0003516987414187156, Final Batch Loss: 1.1069429461940672e-07\n",
      "Epoch 3369, Loss: 0.0008597784214998683, Final Batch Loss: 2.571468712631031e-06\n",
      "Epoch 3370, Loss: 0.0004906120254872803, Final Batch Loss: 1.3368432973948075e-06\n",
      "Epoch 3371, Loss: 0.00023954945345394663, Final Batch Loss: 6.556488187925424e-07\n",
      "Epoch 3372, Loss: 0.0003982578891736921, Final Batch Loss: 1.2005249118374195e-05\n",
      "Epoch 3373, Loss: 0.0013926150350016542, Final Batch Loss: 5.04758172610309e-05\n",
      "Epoch 3374, Loss: 0.0022186550482441447, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3375, Loss: 0.00032826585174916545, Final Batch Loss: 1.0455635674588848e-05\n",
      "Epoch 3376, Loss: 0.0010030954767898947, Final Batch Loss: 5.449551281344611e-07\n",
      "Epoch 3377, Loss: 0.00025460400956944795, Final Batch Loss: 4.649028596759308e-06\n",
      "Epoch 3378, Loss: 0.0009979888636735268, Final Batch Loss: 4.495752364164218e-06\n",
      "Epoch 3379, Loss: 0.0002545422835282807, Final Batch Loss: 3.3208243621629663e-07\n",
      "Epoch 3380, Loss: 0.00035308379756315844, Final Batch Loss: 3.3647476811893284e-05\n",
      "Epoch 3381, Loss: 0.002943145324024954, Final Batch Loss: 1.702787085378077e-05\n",
      "Epoch 3382, Loss: 0.0011984139955529827, Final Batch Loss: 0.0002056717494269833\n",
      "Epoch 3383, Loss: 0.00037098415441505495, Final Batch Loss: 3.567792009562254e-05\n",
      "Epoch 3384, Loss: 0.0005103352445985365, Final Batch Loss: 0.00030935401446186006\n",
      "Epoch 3385, Loss: 0.0012869229934437953, Final Batch Loss: 3.235676047097513e-07\n",
      "Epoch 3386, Loss: 0.0024073630424155112, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3387, Loss: 0.0008089494276646292, Final Batch Loss: 0.0006352533819153905\n",
      "Epoch 3388, Loss: 8.705120171725866e-05, Final Batch Loss: 5.330173280526651e-06\n",
      "Epoch 3389, Loss: 0.0003587803782920673, Final Batch Loss: 1.856234803199186e-06\n",
      "Epoch 3390, Loss: 0.11412618163376465, Final Batch Loss: 0.1137460246682167\n",
      "Epoch 3391, Loss: 0.04767682258383843, Final Batch Loss: 2.639629599343607e-07\n",
      "Epoch 3392, Loss: 0.1254653049800254, Final Batch Loss: 3.823119186563417e-06\n",
      "Epoch 3393, Loss: 0.06132753954859105, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3394, Loss: 0.01112509163795039, Final Batch Loss: 0.0026869105640798807\n",
      "Epoch 3395, Loss: 0.0008706097423782921, Final Batch Loss: 8.94019740371732e-06\n",
      "Epoch 3396, Loss: 0.01964646587795471, Final Batch Loss: 1.7029880439167755e-07\n",
      "Epoch 3397, Loss: 0.0016923409420996904, Final Batch Loss: 0.0009697971981950104\n",
      "Epoch 3398, Loss: 0.0020815721563849365, Final Batch Loss: 2.827255411830265e-05\n",
      "Epoch 3399, Loss: 0.0009541671668102936, Final Batch Loss: 2.8524725621537073e-06\n",
      "Epoch 3400, Loss: 0.0008868241087967021, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3401, Loss: 0.037457240556250326, Final Batch Loss: 0.03403616324067116\n",
      "Epoch 3402, Loss: 0.0004959335528660347, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 3403, Loss: 0.0010033273720182478, Final Batch Loss: 0.0\n",
      "Epoch 3404, Loss: 0.035323288885763304, Final Batch Loss: 8.429753393102146e-07\n",
      "Epoch 3405, Loss: 0.011165448895813057, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3406, Loss: 0.0019111721721856156, Final Batch Loss: 2.451311047479976e-05\n",
      "Epoch 3407, Loss: 0.0035957954792564806, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 3408, Loss: 0.0034782123711920576, Final Batch Loss: 0.003104999428614974\n",
      "Epoch 3409, Loss: 0.01176214148160426, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3410, Loss: 0.0011121772822662024, Final Batch Loss: 8.730158879188821e-05\n",
      "Epoch 3411, Loss: 0.0008911418293955364, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3412, Loss: 0.0024211201410935246, Final Batch Loss: 1.0899051403612248e-06\n",
      "Epoch 3413, Loss: 0.001889244211724872, Final Batch Loss: 7.509830993512878e-06\n",
      "Epoch 3414, Loss: 0.0008124107025651028, Final Batch Loss: 2.674900861165952e-05\n",
      "Epoch 3415, Loss: 0.00063964867661781, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 3416, Loss: 0.003947933340157306, Final Batch Loss: 7.322843771362386e-07\n",
      "Epoch 3417, Loss: 0.001273897661576484, Final Batch Loss: 0.0009342642151750624\n",
      "Epoch 3418, Loss: 0.0007678917113480566, Final Batch Loss: 5.3898670557828154e-06\n",
      "Epoch 3419, Loss: 0.000783074049000021, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3420, Loss: 0.0012723486113372928, Final Batch Loss: 0.0009865694446489215\n",
      "Epoch 3421, Loss: 0.0003394291534277727, Final Batch Loss: 2.0356354070827365e-05\n",
      "Epoch 3422, Loss: 0.0023413721573888324, Final Batch Loss: 3.29321701428853e-05\n",
      "Epoch 3423, Loss: 0.003043386612262111, Final Batch Loss: 7.654788350919262e-05\n",
      "Epoch 3424, Loss: 0.004706805203568365, Final Batch Loss: 8.846548553265166e-06\n",
      "Epoch 3425, Loss: 0.01984164725035953, Final Batch Loss: 0.00016398925799876451\n",
      "Epoch 3426, Loss: 0.0014289402263329976, Final Batch Loss: 1.9328674625285203e-06\n",
      "Epoch 3427, Loss: 0.11186618732244824, Final Batch Loss: 0.10515862703323364\n",
      "Epoch 3428, Loss: 0.0007344699970417423, Final Batch Loss: 1.627104757062625e-05\n",
      "Epoch 3429, Loss: 0.000396034130346834, Final Batch Loss: 8.259478931904596e-07\n",
      "Epoch 3430, Loss: 0.02794156393168734, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3431, Loss: 0.035435768768252274, Final Batch Loss: 4.0700301724427845e-06\n",
      "Epoch 3432, Loss: 0.03660885621388843, Final Batch Loss: 3.2356281280954136e-06\n",
      "Epoch 3433, Loss: 0.0575523576408159, Final Batch Loss: 0.0007795326528139412\n",
      "Epoch 3434, Loss: 0.010454577455675462, Final Batch Loss: 6.66696359985508e-06\n",
      "Epoch 3435, Loss: 0.0008894564962247387, Final Batch Loss: 0.00023239586153067648\n",
      "Epoch 3436, Loss: 0.024643400214699795, Final Batch Loss: 3.0653354770038277e-06\n",
      "Epoch 3437, Loss: 0.002261213649553895, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3438, Loss: 0.022265390758548165, Final Batch Loss: 0.00021971795649733394\n",
      "Epoch 3439, Loss: 0.0006362828448800428, Final Batch Loss: 3.082345301663736e-06\n",
      "Epoch 3440, Loss: 0.0009008800061565125, Final Batch Loss: 3.930393359041773e-05\n",
      "Epoch 3441, Loss: 0.0005974335708742728, Final Batch Loss: 1.9540069843060337e-05\n",
      "Epoch 3442, Loss: 0.0025510359337204136, Final Batch Loss: 0.00027330598095431924\n",
      "Epoch 3443, Loss: 0.005586876141023822, Final Batch Loss: 0.0004551894380711019\n",
      "Epoch 3444, Loss: 0.0020120539302297402, Final Batch Loss: 2.5319011911051348e-05\n",
      "Epoch 3445, Loss: 0.009922939145326382, Final Batch Loss: 7.074520544847474e-05\n",
      "Epoch 3446, Loss: 0.0012432614234967332, Final Batch Loss: 6.743669928255258e-06\n",
      "Epoch 3447, Loss: 0.004432968120454461, Final Batch Loss: 1.8407603420200758e-05\n",
      "Epoch 3448, Loss: 0.0008176683732017409, Final Batch Loss: 4.442593126441352e-05\n",
      "Epoch 3449, Loss: 0.0005198392182137468, Final Batch Loss: 7.722795999143273e-06\n",
      "Epoch 3450, Loss: 0.0015398505456687417, Final Batch Loss: 0.001011140993796289\n",
      "Epoch 3451, Loss: 0.003119840022009157, Final Batch Loss: 4.018945219286252e-06\n",
      "Epoch 3452, Loss: 0.0026621441284078173, Final Batch Loss: 0.0012011820217594504\n",
      "Epoch 3453, Loss: 0.0006813060963395401, Final Batch Loss: 9.433958439331036e-06\n",
      "Epoch 3454, Loss: 0.0002963431478519851, Final Batch Loss: 9.196090786645073e-07\n",
      "Epoch 3455, Loss: 0.001178810762212379, Final Batch Loss: 0.00030733030871488154\n",
      "Epoch 3456, Loss: 0.001036746214822415, Final Batch Loss: 3.754996441784897e-06\n",
      "Epoch 3457, Loss: 0.0012069836447992088, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 3458, Loss: 0.000890632945811376, Final Batch Loss: 0.0001289211941184476\n",
      "Epoch 3459, Loss: 0.0017026710184353533, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 3460, Loss: 0.00035242831134851826, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3461, Loss: 0.0012218108195156674, Final Batch Loss: 6.641630534431897e-07\n",
      "Epoch 3462, Loss: 0.007548172474344028, Final Batch Loss: 7.379510498140007e-05\n",
      "Epoch 3463, Loss: 0.0009404148741651852, Final Batch Loss: 1.873286947784436e-07\n",
      "Epoch 3464, Loss: 0.009370201034471393, Final Batch Loss: 0.008896213956177235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3465, Loss: 0.0011581332055357052, Final Batch Loss: 4.135197013965808e-05\n",
      "Epoch 3466, Loss: 0.001766611866059975, Final Batch Loss: 4.2744654820126016e-06\n",
      "Epoch 3467, Loss: 0.0009296088301198324, Final Batch Loss: 0.0\n",
      "Epoch 3468, Loss: 0.013676481749371305, Final Batch Loss: 3.5932221180701163e-06\n",
      "Epoch 3469, Loss: 0.001324064929576707, Final Batch Loss: 0.0005567159969359636\n",
      "Epoch 3470, Loss: 0.00036751086008735, Final Batch Loss: 4.063058440806344e-05\n",
      "Epoch 3471, Loss: 0.0010024846729379533, Final Batch Loss: 3.320824930597155e-07\n",
      "Epoch 3472, Loss: 0.000399625271533921, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3473, Loss: 0.00048473192828168976, Final Batch Loss: 4.376564447738929e-06\n",
      "Epoch 3474, Loss: 0.000755751632823376, Final Batch Loss: 5.293982758303173e-05\n",
      "Epoch 3475, Loss: 0.000555551684499278, Final Batch Loss: 7.23769460364565e-07\n",
      "Epoch 3476, Loss: 0.00035743107580188394, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3477, Loss: 0.0021506057377500554, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3478, Loss: 0.00030994619737612084, Final Batch Loss: 2.047591442533303e-05\n",
      "Epoch 3479, Loss: 0.0006563892911799485, Final Batch Loss: 1.1477519365143962e-05\n",
      "Epoch 3480, Loss: 0.0005979149364065961, Final Batch Loss: 1.0728043889685068e-05\n",
      "Epoch 3481, Loss: 0.0003156882312396192, Final Batch Loss: 1.5241612345562316e-06\n",
      "Epoch 3482, Loss: 0.0005055023132172209, Final Batch Loss: 1.2431771665433189e-06\n",
      "Epoch 3483, Loss: 0.0008650113131807302, Final Batch Loss: 2.147999475710094e-05\n",
      "Epoch 3484, Loss: 0.0005044350726848279, Final Batch Loss: 1.6433685914307716e-06\n",
      "Epoch 3485, Loss: 0.0003813733974311617, Final Batch Loss: 3.902323078364134e-05\n",
      "Epoch 3486, Loss: 0.0004238503204874178, Final Batch Loss: 7.748565735710145e-07\n",
      "Epoch 3487, Loss: 0.00017617629418964498, Final Batch Loss: 1.8773014744510874e-05\n",
      "Epoch 3488, Loss: 0.0013703386175620835, Final Batch Loss: 1.689260170678608e-05\n",
      "Epoch 3489, Loss: 0.00034511101421230705, Final Batch Loss: 8.940164661908057e-06\n",
      "Epoch 3490, Loss: 0.00041671754161143326, Final Batch Loss: 7.978288522281218e-06\n",
      "Epoch 3491, Loss: 0.0007182972933925669, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3492, Loss: 0.0002791626657199231, Final Batch Loss: 8.616766535851639e-06\n",
      "Epoch 3493, Loss: 0.0027023365364584606, Final Batch Loss: 0.0\n",
      "Epoch 3494, Loss: 0.00037170704700884016, Final Batch Loss: 2.554482421146531e-07\n",
      "Epoch 3495, Loss: 0.00032555224481711775, Final Batch Loss: 1.3112954775351682e-06\n",
      "Epoch 3496, Loss: 0.0010922548808594001, Final Batch Loss: 5.8660963986767456e-05\n",
      "Epoch 3497, Loss: 0.00024669599565640965, Final Batch Loss: 1.9924725620512618e-06\n",
      "Epoch 3498, Loss: 0.0005975514947067495, Final Batch Loss: 6.641645313720801e-07\n",
      "Epoch 3499, Loss: 0.00012677542054007063, Final Batch Loss: 7.254380307131214e-06\n",
      "Epoch 3500, Loss: 0.0010639030224410817, Final Batch Loss: 0.0\n",
      "Epoch 3501, Loss: 0.0007737483548559965, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3502, Loss: 0.0005804848738080182, Final Batch Loss: 6.06240473643993e-06\n",
      "Epoch 3503, Loss: 0.0012227035986143164, Final Batch Loss: 0.000965953222475946\n",
      "Epoch 3504, Loss: 0.0022513010044349357, Final Batch Loss: 0.001011317945085466\n",
      "Epoch 3505, Loss: 0.0017098090211220551, Final Batch Loss: 0.0\n",
      "Epoch 3506, Loss: 0.0003640557144990453, Final Batch Loss: 1.8136672679247567e-06\n",
      "Epoch 3507, Loss: 0.0051171896809592, Final Batch Loss: 1.2602065453393152e-06\n",
      "Epoch 3508, Loss: 0.0006674893757292466, Final Batch Loss: 1.8732865214587946e-07\n",
      "Epoch 3509, Loss: 0.041180360480893796, Final Batch Loss: 1.6603960375505267e-06\n",
      "Epoch 3510, Loss: 0.011083271676397999, Final Batch Loss: 2.802826747938525e-05\n",
      "Epoch 3511, Loss: 0.0012394054078868066, Final Batch Loss: 3.028154605999589e-05\n",
      "Epoch 3512, Loss: 0.00029772838294661597, Final Batch Loss: 3.4059755193993624e-07\n",
      "Epoch 3513, Loss: 0.0002769787024590187, Final Batch Loss: 1.2813849025405943e-05\n",
      "Epoch 3514, Loss: 0.0005267343992727547, Final Batch Loss: 2.9120626550138695e-06\n",
      "Epoch 3515, Loss: 0.001518759609098197, Final Batch Loss: 0.0009243100066669285\n",
      "Epoch 3516, Loss: 0.0004065373086632462, Final Batch Loss: 6.677493365714327e-05\n",
      "Epoch 3517, Loss: 0.00020819939618377248, Final Batch Loss: 1.5700086805736646e-05\n",
      "Epoch 3518, Loss: 0.0010129807312750927, Final Batch Loss: 3.6357912449602736e-06\n",
      "Epoch 3519, Loss: 0.0017036109466062044, Final Batch Loss: 1.0362061402702238e-05\n",
      "Epoch 3520, Loss: 0.0011979449014400956, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3521, Loss: 0.03212308391653096, Final Batch Loss: 4.768355665873969e-07\n",
      "Epoch 3522, Loss: 0.0002436164778600869, Final Batch Loss: 9.366395943288808e-07\n",
      "Epoch 3523, Loss: 0.0003994279348766838, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3524, Loss: 0.0006865317186566244, Final Batch Loss: 2.6821685423783492e-06\n",
      "Epoch 3525, Loss: 0.0006731118046445772, Final Batch Loss: 0.0\n",
      "Epoch 3526, Loss: 0.00020564038641168736, Final Batch Loss: 2.435917849652469e-05\n",
      "Epoch 3527, Loss: 0.00045167790173650246, Final Batch Loss: 2.1287357299115683e-07\n",
      "Epoch 3528, Loss: 0.0009045169026649091, Final Batch Loss: 0.0002642547187861055\n",
      "Epoch 3529, Loss: 0.007462063875209424, Final Batch Loss: 1.5674309906898998e-05\n",
      "Epoch 3530, Loss: 0.00100866053981008, Final Batch Loss: 0.00013752855011262\n",
      "Epoch 3531, Loss: 0.0010246682122669881, Final Batch Loss: 0.00012003361916868016\n",
      "Epoch 3532, Loss: 0.0002519503977964632, Final Batch Loss: 1.571686880197376e-05\n",
      "Epoch 3533, Loss: 0.0006415729058062425, Final Batch Loss: 2.4034850866883062e-05\n",
      "Epoch 3534, Loss: 0.0009777310829974795, Final Batch Loss: 2.6396318730803614e-07\n",
      "Epoch 3535, Loss: 0.0003222276193213247, Final Batch Loss: 1.2772419211160013e-07\n",
      "Epoch 3536, Loss: 0.0009322119329198131, Final Batch Loss: 1.7881374958506058e-07\n",
      "Epoch 3537, Loss: 0.0001476077100051043, Final Batch Loss: 3.7465679270098917e-07\n",
      "Epoch 3538, Loss: 0.00044832568755737157, Final Batch Loss: 7.1522031248605344e-06\n",
      "Epoch 3539, Loss: 0.0005416014355432708, Final Batch Loss: 0.00024375184148084372\n",
      "Epoch 3540, Loss: 0.0009970936004037867, Final Batch Loss: 1.31129638702987e-06\n",
      "Epoch 3541, Loss: 0.0006397382680916053, Final Batch Loss: 6.9479033300012816e-06\n",
      "Epoch 3542, Loss: 0.0002831506544680451, Final Batch Loss: 1.0642896995705087e-05\n",
      "Epoch 3543, Loss: 0.000468011478005792, Final Batch Loss: 1.1154497769894078e-06\n",
      "Epoch 3544, Loss: 0.001270422754322098, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3545, Loss: 0.0032445230903022093, Final Batch Loss: 1.6603956964900135e-06\n",
      "Epoch 3546, Loss: 0.0006827119254921854, Final Batch Loss: 5.926187895965995e-06\n",
      "Epoch 3547, Loss: 0.0005806619071790919, Final Batch Loss: 2.5374135930178454e-06\n",
      "Epoch 3548, Loss: 0.0003123761117080903, Final Batch Loss: 7.407971338579955e-07\n",
      "Epoch 3549, Loss: 0.002268235057044876, Final Batch Loss: 3.2441591883980436e-06\n",
      "Epoch 3550, Loss: 0.0005791289093437513, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3551, Loss: 0.0008762864352149791, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 3552, Loss: 0.0003550234529825502, Final Batch Loss: 8.174308163688693e-07\n",
      "Epoch 3553, Loss: 0.01447288463964469, Final Batch Loss: 1.3112919532431988e-06\n",
      "Epoch 3554, Loss: 0.004429873884873814, Final Batch Loss: 4.3680420276359655e-06\n",
      "Epoch 3555, Loss: 0.0008323524571096641, Final Batch Loss: 8.514898581779562e-07\n",
      "Epoch 3556, Loss: 0.00034670260902203154, Final Batch Loss: 7.307201303774491e-05\n",
      "Epoch 3557, Loss: 0.02669313645128568, Final Batch Loss: 1.2422873624018393e-05\n",
      "Epoch 3558, Loss: 0.004783294782100711, Final Batch Loss: 0.0007938736816868186\n",
      "Epoch 3559, Loss: 0.0004444960267449005, Final Batch Loss: 3.1505251740782114e-07\n",
      "Epoch 3560, Loss: 0.002706708187957929, Final Batch Loss: 2.5544810000610596e-07\n",
      "Epoch 3561, Loss: 0.0002151229643914121, Final Batch Loss: 2.2990177512838272e-06\n",
      "Epoch 3562, Loss: 0.0010450092395331012, Final Batch Loss: 4.058776539750397e-05\n",
      "Epoch 3563, Loss: 0.0206701642835867, Final Batch Loss: 3.0653777116640413e-07\n",
      "Epoch 3564, Loss: 0.00109194088690856, Final Batch Loss: 0.0007350234664045274\n",
      "Epoch 3565, Loss: 0.0023196588572318433, Final Batch Loss: 0.0015477286651730537\n",
      "Epoch 3566, Loss: 0.0003223457429371024, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 3567, Loss: 0.009207180500084178, Final Batch Loss: 6.64162939756352e-07\n",
      "Epoch 3568, Loss: 0.0009077176715663882, Final Batch Loss: 1.1920834595002816e-06\n",
      "Epoch 3569, Loss: 0.0010066560872807884, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3570, Loss: 0.0010820182633324293, Final Batch Loss: 0.0\n",
      "Epoch 3571, Loss: 0.0003492909306714864, Final Batch Loss: 1.3283204225444933e-06\n",
      "Epoch 3572, Loss: 0.00038703563002684405, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 3573, Loss: 0.0010870188601757036, Final Batch Loss: 1.251686967407295e-06\n",
      "Epoch 3574, Loss: 0.0005755293796028127, Final Batch Loss: 8.446358151559252e-06\n",
      "Epoch 3575, Loss: 0.0006627359025515034, Final Batch Loss: 9.72348152572522e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3576, Loss: 0.00179057918376202, Final Batch Loss: 0.0\n",
      "Epoch 3577, Loss: 0.0003318744459761547, Final Batch Loss: 6.386201789609913e-07\n",
      "Epoch 3578, Loss: 0.00021323160308384104, Final Batch Loss: 2.1753881810582243e-05\n",
      "Epoch 3579, Loss: 0.0004890306954621337, Final Batch Loss: 3.401140929781832e-05\n",
      "Epoch 3580, Loss: 0.0006834962869106675, Final Batch Loss: 7.841847036615945e-06\n",
      "Epoch 3581, Loss: 0.0003240316591472947, Final Batch Loss: 1.098422217182815e-06\n",
      "Epoch 3582, Loss: 0.0002401602887402987, Final Batch Loss: 2.5021054170792922e-05\n",
      "Epoch 3583, Loss: 0.0006406663242159993, Final Batch Loss: 0.0\n",
      "Epoch 3584, Loss: 0.00013270787724195543, Final Batch Loss: 5.108960294819553e-07\n",
      "Epoch 3585, Loss: 0.00021685174306185218, Final Batch Loss: 0.0\n",
      "Epoch 3586, Loss: 0.00030726059776498005, Final Batch Loss: 8.05949603090994e-05\n",
      "Epoch 3587, Loss: 0.00041354450877406634, Final Batch Loss: 3.300488242530264e-05\n",
      "Epoch 3588, Loss: 0.004058819710859751, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3589, Loss: 0.020408213374594197, Final Batch Loss: 0.0003913544933311641\n",
      "Epoch 3590, Loss: 0.002092839182296302, Final Batch Loss: 0.0\n",
      "Epoch 3591, Loss: 0.0002999670889778372, Final Batch Loss: 3.2356754786633246e-07\n",
      "Epoch 3592, Loss: 0.0025333317389595322, Final Batch Loss: 3.5192188079236075e-05\n",
      "Epoch 3593, Loss: 0.0015536140649601293, Final Batch Loss: 4.521295977610862e-06\n",
      "Epoch 3594, Loss: 0.0007253468013459496, Final Batch Loss: 3.0908634016668657e-06\n",
      "Epoch 3595, Loss: 0.0013345174707577456, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3596, Loss: 0.0004367305323285109, Final Batch Loss: 1.679081833572127e-05\n",
      "Epoch 3597, Loss: 0.00029661841927008936, Final Batch Loss: 0.0001539630611659959\n",
      "Epoch 3598, Loss: 0.00014438324228649435, Final Batch Loss: 3.593225983422599e-06\n",
      "Epoch 3599, Loss: 0.0015105762877283269, Final Batch Loss: 0.0006954761920496821\n",
      "Epoch 3600, Loss: 0.0003119569223599683, Final Batch Loss: 5.560144472838147e-06\n",
      "Epoch 3601, Loss: 0.0006845886455266736, Final Batch Loss: 2.484238939359784e-05\n",
      "Epoch 3602, Loss: 0.0007145876236904769, Final Batch Loss: 6.726780270582822e-07\n",
      "Epoch 3603, Loss: 0.0001487895503942127, Final Batch Loss: 1.362381226499565e-06\n",
      "Epoch 3604, Loss: 0.0003713246742336196, Final Batch Loss: 6.904841575305909e-05\n",
      "Epoch 3605, Loss: 0.0006398049163180985, Final Batch Loss: 1.201419308927143e-05\n",
      "Epoch 3606, Loss: 0.00020708619350173763, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3607, Loss: 0.0005560495633289975, Final Batch Loss: 4.478723440115573e-06\n",
      "Epoch 3608, Loss: 0.00019515231386790788, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3609, Loss: 0.00093079680971897, Final Batch Loss: 1.0217934942602369e-07\n",
      "Epoch 3610, Loss: 0.00045773925180014885, Final Batch Loss: 4.59805818309178e-07\n",
      "Epoch 3611, Loss: 0.0015862205275745112, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3612, Loss: 0.00469937681191368, Final Batch Loss: 0.0006224812241271138\n",
      "Epoch 3613, Loss: 0.0004032043498227722, Final Batch Loss: 1.0651504453562666e-05\n",
      "Epoch 3614, Loss: 0.002192840953284758, Final Batch Loss: 5.281575067783706e-05\n",
      "Epoch 3615, Loss: 0.0008581483734815265, Final Batch Loss: 0.0001007290484267287\n",
      "Epoch 3616, Loss: 0.01010976320165824, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3617, Loss: 0.0003252557299973091, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3618, Loss: 0.0010583502335066441, Final Batch Loss: 0.0\n",
      "Epoch 3619, Loss: 0.00043957609887002036, Final Batch Loss: 9.348847925139125e-06\n",
      "Epoch 3620, Loss: 0.0007031470886431634, Final Batch Loss: 0.00028709284379146993\n",
      "Epoch 3621, Loss: 0.0003537955478805088, Final Batch Loss: 1.3112901342537953e-06\n",
      "Epoch 3622, Loss: 0.0006588041968598191, Final Batch Loss: 1.566733658364683e-06\n",
      "Epoch 3623, Loss: 0.0004786820995832386, Final Batch Loss: 6.17307205175166e-06\n",
      "Epoch 3624, Loss: 0.001113768278628413, Final Batch Loss: 0.0009327596635557711\n",
      "Epoch 3625, Loss: 0.0010201628920185613, Final Batch Loss: 0.00011685374192893505\n",
      "Epoch 3626, Loss: 0.00019394563362595818, Final Batch Loss: 1.617839444634228e-07\n",
      "Epoch 3627, Loss: 0.0011963754113821778, Final Batch Loss: 0.0003256071940995753\n",
      "Epoch 3628, Loss: 0.001206857365104952, Final Batch Loss: 0.0008002515533007681\n",
      "Epoch 3629, Loss: 0.0002594313164081541, Final Batch Loss: 1.1758184882637579e-05\n",
      "Epoch 3630, Loss: 0.0007613124253111891, Final Batch Loss: 5.2883340686094016e-05\n",
      "Epoch 3631, Loss: 0.00011608485706915417, Final Batch Loss: 4.768363908169704e-07\n",
      "Epoch 3632, Loss: 0.0004496418229251731, Final Batch Loss: 1.1069427330312465e-07\n",
      "Epoch 3633, Loss: 0.0006677647273001242, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3634, Loss: 0.00023513076575909508, Final Batch Loss: 1.1758546861528885e-05\n",
      "Epoch 3635, Loss: 0.0009127878893195884, Final Batch Loss: 0.0007719799177721143\n",
      "Epoch 3636, Loss: 0.00042293426076867036, Final Batch Loss: 0.0\n",
      "Epoch 3637, Loss: 0.0004297282939660363, Final Batch Loss: 0.0\n",
      "Epoch 3638, Loss: 0.00024334424868754922, Final Batch Loss: 1.5326894242662092e-07\n",
      "Epoch 3639, Loss: 0.0001998550575592617, Final Batch Loss: 4.257468901869288e-07\n",
      "Epoch 3640, Loss: 0.001992074667597876, Final Batch Loss: 1.3623905203985487e-07\n",
      "Epoch 3641, Loss: 0.0001980157080936351, Final Batch Loss: 1.7029881860253226e-07\n",
      "Epoch 3642, Loss: 0.00037736858566717046, Final Batch Loss: 1.192091971802256e-07\n",
      "Epoch 3643, Loss: 0.0005407600675084723, Final Batch Loss: 6.130740644039179e-07\n",
      "Epoch 3644, Loss: 0.00020634588690882083, Final Batch Loss: 2.997484989464283e-05\n",
      "Epoch 3645, Loss: 0.0019375673637114232, Final Batch Loss: 8.820977200230118e-06\n",
      "Epoch 3646, Loss: 0.0013664070197592082, Final Batch Loss: 6.837299679318676e-06\n",
      "Epoch 3647, Loss: 0.0024236614553956315, Final Batch Loss: 0.0\n",
      "Epoch 3648, Loss: 0.00020114173927865409, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3649, Loss: 0.00022616117007601133, Final Batch Loss: 4.410624114825623e-06\n",
      "Epoch 3650, Loss: 0.00030621260921748217, Final Batch Loss: 3.3208235095116834e-07\n",
      "Epoch 3651, Loss: 0.0004556095178713804, Final Batch Loss: 9.2812354068883e-07\n",
      "Epoch 3652, Loss: 0.0001470405834922417, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3653, Loss: 0.00019275747513347596, Final Batch Loss: 3.5251439385319827e-06\n",
      "Epoch 3654, Loss: 0.0023331963584496407, Final Batch Loss: 1.3972034139442258e-05\n",
      "Epoch 3655, Loss: 0.00027117149420519127, Final Batch Loss: 3.1848092476138845e-05\n",
      "Epoch 3656, Loss: 8.1191062907493e-05, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 3657, Loss: 0.001613825716503925, Final Batch Loss: 0.000315594399580732\n",
      "Epoch 3658, Loss: 7.900968194007874e-05, Final Batch Loss: 0.0\n",
      "Epoch 3659, Loss: 0.0018745269347029136, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3660, Loss: 0.0007648679520571022, Final Batch Loss: 1.745545887388289e-06\n",
      "Epoch 3661, Loss: 0.0005749161013994808, Final Batch Loss: 2.2990342074535874e-07\n",
      "Epoch 3662, Loss: 0.00014903245896391581, Final Batch Loss: 1.7029883281338698e-07\n",
      "Epoch 3663, Loss: 0.0008872929765857407, Final Batch Loss: 6.156119525257964e-06\n",
      "Epoch 3664, Loss: 0.0015254892159930478, Final Batch Loss: 4.257463217527402e-07\n",
      "Epoch 3665, Loss: 0.010713426492202416, Final Batch Loss: 7.484261459467234e-06\n",
      "Epoch 3666, Loss: 9.39039602911862e-05, Final Batch Loss: 2.2138850397368515e-07\n",
      "Epoch 3667, Loss: 0.0018295290333298908, Final Batch Loss: 0.00016258731193374842\n",
      "Epoch 3668, Loss: 0.0005993462204969546, Final Batch Loss: 3.9764258872310165e-06\n",
      "Epoch 3669, Loss: 0.0002496543115739769, Final Batch Loss: 6.445526651077671e-06\n",
      "Epoch 3670, Loss: 0.006954255932214437, Final Batch Loss: 7.47366066207178e-05\n",
      "Epoch 3671, Loss: 0.006423027639357315, Final Batch Loss: 0.002235286170616746\n",
      "Epoch 3672, Loss: 0.005682576180134902, Final Batch Loss: 3.0653771432298527e-07\n",
      "Epoch 3673, Loss: 0.0012522222906525826, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3674, Loss: 0.011308627350615552, Final Batch Loss: 7.578275358355313e-07\n",
      "Epoch 3675, Loss: 0.00015659980199700385, Final Batch Loss: 1.192092469182171e-07\n",
      "Epoch 3676, Loss: 0.01322078409975802, Final Batch Loss: 1.295008223678451e-05\n",
      "Epoch 3677, Loss: 0.0017888382074318088, Final Batch Loss: 2.8950788077963807e-07\n",
      "Epoch 3678, Loss: 0.0015490029368265823, Final Batch Loss: 4.129684839426773e-06\n",
      "Epoch 3679, Loss: 0.003497894778774935, Final Batch Loss: 0.0\n",
      "Epoch 3680, Loss: 0.0004370211692190651, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 3681, Loss: 0.00016307368423440494, Final Batch Loss: 6.070970812288579e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3682, Loss: 0.0012954682097188197, Final Batch Loss: 0.0003151243145111948\n",
      "Epoch 3683, Loss: 0.00027124143480250495, Final Batch Loss: 6.897075763845351e-07\n",
      "Epoch 3684, Loss: 0.002838620882226195, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3685, Loss: 0.0017584336451363924, Final Batch Loss: 5.875073384231655e-06\n",
      "Epoch 3686, Loss: 0.0003405279385333415, Final Batch Loss: 1.277236151508987e-06\n",
      "Epoch 3687, Loss: 0.0002383912924415199, Final Batch Loss: 1.5582190826535225e-06\n",
      "Epoch 3688, Loss: 0.0002077423489481589, Final Batch Loss: 2.14574288293079e-06\n",
      "Epoch 3689, Loss: 0.00031735048628434015, Final Batch Loss: 3.644328671725816e-06\n",
      "Epoch 3690, Loss: 0.00015570143611398635, Final Batch Loss: 4.427760984526685e-07\n",
      "Epoch 3691, Loss: 0.0007992943819772336, Final Batch Loss: 1.0259788723487873e-05\n",
      "Epoch 3692, Loss: 0.00018058158971712146, Final Batch Loss: 4.1723129129422887e-07\n",
      "Epoch 3693, Loss: 0.03181423427467678, Final Batch Loss: 2.384183943604512e-07\n",
      "Epoch 3694, Loss: 0.001119500549066288, Final Batch Loss: 8.191183042072225e-06\n",
      "Epoch 3695, Loss: 0.00014233593152823687, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 3696, Loss: 0.0004955323056492489, Final Batch Loss: 1.386099847877631e-05\n",
      "Epoch 3697, Loss: 0.00033412685752409743, Final Batch Loss: 9.885172403301112e-06\n",
      "Epoch 3698, Loss: 0.0016211182097549681, Final Batch Loss: 1.2431761433617794e-06\n",
      "Epoch 3699, Loss: 0.00027455781581764427, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 3700, Loss: 0.00043160553622811904, Final Batch Loss: 5.1089678265725524e-08\n",
      "Epoch 3701, Loss: 0.0029686833113373723, Final Batch Loss: 1.65188976097852e-06\n",
      "Epoch 3702, Loss: 0.00030430159001149093, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3703, Loss: 0.0001887806095197675, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 3704, Loss: 0.00025195694092872145, Final Batch Loss: 3.797568069785484e-06\n",
      "Epoch 3705, Loss: 6.301737471403612e-05, Final Batch Loss: 2.7247801881458145e-07\n",
      "Epoch 3706, Loss: 0.0005321742810338037, Final Batch Loss: 2.3361240891972557e-05\n",
      "Epoch 3707, Loss: 0.0030683515592500044, Final Batch Loss: 9.638280971557833e-06\n",
      "Epoch 3708, Loss: 0.00038190469217624923, Final Batch Loss: 0.0002698575262911618\n",
      "Epoch 3709, Loss: 0.00023572890398781965, Final Batch Loss: 9.451532037019206e-07\n",
      "Epoch 3710, Loss: 0.00013796233770335675, Final Batch Loss: 5.253531071502948e-06\n",
      "Epoch 3711, Loss: 0.0002770051368656823, Final Batch Loss: 4.1723200183696463e-07\n",
      "Epoch 3712, Loss: 0.0012804062680515926, Final Batch Loss: 0.00108504353556782\n",
      "Epoch 3713, Loss: 0.00027808157677711165, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3714, Loss: 0.0021553188016696367, Final Batch Loss: 0.0\n",
      "Epoch 3715, Loss: 0.0009546786012428754, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3716, Loss: 0.001259489841231698, Final Batch Loss: 0.0011693809647113085\n",
      "Epoch 3717, Loss: 0.000274975606089356, Final Batch Loss: 2.316044856343069e-06\n",
      "Epoch 3718, Loss: 0.0019324015883945833, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3719, Loss: 0.0002489363268978195, Final Batch Loss: 1.9998824427602813e-05\n",
      "Epoch 3720, Loss: 0.000525984256000811, Final Batch Loss: 5.500579845829634e-06\n",
      "Epoch 3721, Loss: 0.0003226606913813157, Final Batch Loss: 2.4929231585701928e-05\n",
      "Epoch 3722, Loss: 0.00017836568400042552, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3723, Loss: 0.00017444411247957703, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3724, Loss: 0.027599729188295896, Final Batch Loss: 3.933674452127889e-05\n",
      "Epoch 3725, Loss: 0.005079185267277353, Final Batch Loss: 1.2277580026420765e-05\n",
      "Epoch 3726, Loss: 0.015562338401650777, Final Batch Loss: 0.0\n",
      "Epoch 3727, Loss: 0.004194168791855191, Final Batch Loss: 3.831723915936891e-07\n",
      "Epoch 3728, Loss: 0.000811674067193735, Final Batch Loss: 2.3841843699301535e-07\n",
      "Epoch 3729, Loss: 0.0010127294390258612, Final Batch Loss: 2.7840982511406764e-05\n",
      "Epoch 3730, Loss: 0.0009152856513168217, Final Batch Loss: 1.6178397288513224e-07\n",
      "Epoch 3731, Loss: 0.0006474118009123231, Final Batch Loss: 6.641649292760121e-07\n",
      "Epoch 3732, Loss: 0.0010816352724702938, Final Batch Loss: 1.8732870898929832e-07\n",
      "Epoch 3733, Loss: 0.00015333084436974787, Final Batch Loss: 4.002015714377194e-07\n",
      "Epoch 3734, Loss: 0.0006669258787663779, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3735, Loss: 0.0004656211067555205, Final Batch Loss: 1.5326897084833035e-07\n",
      "Epoch 3736, Loss: 0.00018730098628338965, Final Batch Loss: 2.6396293151265127e-07\n",
      "Epoch 3737, Loss: 0.0006971948550926754, Final Batch Loss: 0.00016410830721724778\n",
      "Epoch 3738, Loss: 0.0031786086954070925, Final Batch Loss: 1.6603960375505267e-06\n",
      "Epoch 3739, Loss: 0.00037062976219814914, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3740, Loss: 0.0009238149914381211, Final Batch Loss: 0.0006895431433804333\n",
      "Epoch 3741, Loss: 0.00014301352965517822, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3742, Loss: 0.0005306010502863501, Final Batch Loss: 3.380388534424128e-06\n",
      "Epoch 3743, Loss: 0.0001303136131198812, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3744, Loss: 0.00015095189360891936, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 3745, Loss: 0.001025517874754911, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3746, Loss: 0.0010841610206338004, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3747, Loss: 0.0001685111797087302, Final Batch Loss: 3.7379675177362515e-06\n",
      "Epoch 3748, Loss: 0.015686784481985683, Final Batch Loss: 1.0217932810974162e-07\n",
      "Epoch 3749, Loss: 0.0001659426299625011, Final Batch Loss: 5.70499821606063e-07\n",
      "Epoch 3750, Loss: 0.00037224507605060353, Final Batch Loss: 6.164585556689417e-06\n",
      "Epoch 3751, Loss: 0.0012916489515966134, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3752, Loss: 0.0043275663613258075, Final Batch Loss: 3.1589781883667456e-06\n",
      "Epoch 3753, Loss: 0.005765431324885384, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 3754, Loss: 0.007637675857040449, Final Batch Loss: 0.0\n",
      "Epoch 3755, Loss: 0.00034279512385637645, Final Batch Loss: 1.2091155667803832e-06\n",
      "Epoch 3756, Loss: 0.0037101291100043454, Final Batch Loss: 3.2817664759932086e-05\n",
      "Epoch 3757, Loss: 0.002591397561570119, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3758, Loss: 0.008262340655164735, Final Batch Loss: 3.0653195608465467e-06\n",
      "Epoch 3759, Loss: 0.0005433107444332563, Final Batch Loss: 1.199690541398013e-05\n",
      "Epoch 3760, Loss: 0.0008962036708908272, Final Batch Loss: 0.0\n",
      "Epoch 3761, Loss: 0.00016542725654744572, Final Batch Loss: 1.0473341944816639e-06\n",
      "Epoch 3762, Loss: 0.0013559059480030555, Final Batch Loss: 2.699212927836925e-06\n",
      "Epoch 3763, Loss: 0.0002394074467702012, Final Batch Loss: 3.5051587474299595e-05\n",
      "Epoch 3764, Loss: 0.0002818590346578276, Final Batch Loss: 0.0\n",
      "Epoch 3765, Loss: 0.0006613449701831087, Final Batch Loss: 6.726792776134971e-07\n",
      "Epoch 3766, Loss: 0.002115128055322657, Final Batch Loss: 8.344605362253787e-07\n",
      "Epoch 3767, Loss: 0.0003169925624888492, Final Batch Loss: 1.4390128626473597e-06\n",
      "Epoch 3768, Loss: 0.0002724217189324918, Final Batch Loss: 1.8477254570825608e-06\n",
      "Epoch 3769, Loss: 0.0036069200323254336, Final Batch Loss: 0.0031197811476886272\n",
      "Epoch 3770, Loss: 0.0003309800704300869, Final Batch Loss: 3.6443416320253164e-06\n",
      "Epoch 3771, Loss: 0.0015166852333550196, Final Batch Loss: 2.639606236698455e-06\n",
      "Epoch 3772, Loss: 0.000656446359016627, Final Batch Loss: 1.127291216107551e-05\n",
      "Epoch 3773, Loss: 0.0005543973634303256, Final Batch Loss: 3.8395381125155836e-05\n",
      "Epoch 3774, Loss: 0.0004756743535949681, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 3775, Loss: 0.00048369663909397786, Final Batch Loss: 0.0\n",
      "Epoch 3776, Loss: 0.000678273084382397, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 3777, Loss: 0.0005927148127451431, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3778, Loss: 0.0030018115765457765, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 3779, Loss: 0.0004772110369231086, Final Batch Loss: 2.046701956714969e-05\n",
      "Epoch 3780, Loss: 0.000592414565829813, Final Batch Loss: 2.554480431626871e-07\n",
      "Epoch 3781, Loss: 0.00027018849115734156, Final Batch Loss: 3.065376574795664e-07\n",
      "Epoch 3782, Loss: 0.00025064425987153527, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3783, Loss: 0.00015239378899423173, Final Batch Loss: 5.875074748473708e-06\n",
      "Epoch 3784, Loss: 0.008269728459708858, Final Batch Loss: 6.442644371418282e-05\n",
      "Epoch 3785, Loss: 0.005233645533280651, Final Batch Loss: 2.060599854303291e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3786, Loss: 0.019951039608926635, Final Batch Loss: 1.2772419211160013e-07\n",
      "Epoch 3787, Loss: 0.004851047628108063, Final Batch Loss: 6.67572530801408e-05\n",
      "Epoch 3788, Loss: 0.0006838915014668601, Final Batch Loss: 3.028989340236876e-05\n",
      "Epoch 3789, Loss: 0.0003762739106605295, Final Batch Loss: 5.508962203748524e-06\n",
      "Epoch 3790, Loss: 0.0020891726169338654, Final Batch Loss: 1.3964424852019874e-06\n",
      "Epoch 3791, Loss: 0.0004931378607579973, Final Batch Loss: 3.031269443454221e-06\n",
      "Epoch 3792, Loss: 0.0007561692909803241, Final Batch Loss: 5.875299393665045e-07\n",
      "Epoch 3793, Loss: 0.0031170437396212947, Final Batch Loss: 0.00010037232277682051\n",
      "Epoch 3794, Loss: 0.00015859930551265222, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3795, Loss: 0.0008356326347893628, Final Batch Loss: 2.1122776161064394e-05\n",
      "Epoch 3796, Loss: 0.0007164852912637798, Final Batch Loss: 2.1287348772602854e-07\n",
      "Epoch 3797, Loss: 0.012973038359632483, Final Batch Loss: 0.0\n",
      "Epoch 3798, Loss: 0.0018210984108009143, Final Batch Loss: 8.582554073655047e-06\n",
      "Epoch 3799, Loss: 0.004036374627110817, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3800, Loss: 0.000598078502662247, Final Batch Loss: 0.0002742163196671754\n",
      "Epoch 3801, Loss: 0.0009091867768802331, Final Batch Loss: 3.899636067217216e-05\n",
      "Epoch 3802, Loss: 0.0001716843285066716, Final Batch Loss: 4.913038992526708e-06\n",
      "Epoch 3803, Loss: 8.050825921657179e-05, Final Batch Loss: 1.8732875162186247e-07\n",
      "Epoch 3804, Loss: 0.00042388114017199996, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3805, Loss: 0.0016407451487054914, Final Batch Loss: 2.895078239362192e-07\n",
      "Epoch 3806, Loss: 0.0007014501907178783, Final Batch Loss: 9.783226232684683e-06\n",
      "Epoch 3807, Loss: 0.0005256019194348482, Final Batch Loss: 3.198715057806112e-05\n",
      "Epoch 3808, Loss: 0.00014652835852757562, Final Batch Loss: 0.0\n",
      "Epoch 3809, Loss: 0.004696203037582336, Final Batch Loss: 3.831721357983042e-07\n",
      "Epoch 3810, Loss: 0.0004963666169714998, Final Batch Loss: 8.005624840734527e-05\n",
      "Epoch 3811, Loss: 0.0026940554903376324, Final Batch Loss: 6.794768978579668e-06\n",
      "Epoch 3812, Loss: 5.937702821512403e-05, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 3813, Loss: 0.00015114083062783834, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 3814, Loss: 0.0008293195169244427, Final Batch Loss: 8.756517490837723e-05\n",
      "Epoch 3815, Loss: 0.00030334228358697146, Final Batch Loss: 0.0001829318207455799\n",
      "Epoch 3816, Loss: 0.00019888176711901906, Final Batch Loss: 0.0\n",
      "Epoch 3817, Loss: 0.0003768210455064036, Final Batch Loss: 9.366442554892274e-08\n",
      "Epoch 3818, Loss: 0.013144746391617446, Final Batch Loss: 1.0728792858571978e-06\n",
      "Epoch 3819, Loss: 0.00018165954156756925, Final Batch Loss: 3.68687801710621e-06\n",
      "Epoch 3820, Loss: 0.025760074082540996, Final Batch Loss: 5.108951199872536e-07\n",
      "Epoch 3821, Loss: 0.000506011584647581, Final Batch Loss: 1.7029888965680584e-07\n",
      "Epoch 3822, Loss: 9.756834538166004e-05, Final Batch Loss: 5.219485501584131e-06\n",
      "Epoch 3823, Loss: 0.00020322496358460285, Final Batch Loss: 1.3623913730498316e-07\n",
      "Epoch 3824, Loss: 0.00211267945792315, Final Batch Loss: 2.554441152824438e-06\n",
      "Epoch 3825, Loss: 0.000701281624060357, Final Batch Loss: 2.7758469514083117e-06\n",
      "Epoch 3826, Loss: 0.0005545825171964225, Final Batch Loss: 3.916868251963024e-07\n",
      "Epoch 3827, Loss: 0.0006843232113169506, Final Batch Loss: 7.892965186329093e-06\n",
      "Epoch 3828, Loss: 0.0008429420028726042, Final Batch Loss: 5.10896818184392e-08\n",
      "Epoch 3829, Loss: 0.0001776916342350887, Final Batch Loss: 2.1457349248521496e-06\n",
      "Epoch 3830, Loss: 0.0028692989308183314, Final Batch Loss: 0.0009221548098139465\n",
      "Epoch 3831, Loss: 0.001276433535943866, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 3832, Loss: 0.00021352435487642651, Final Batch Loss: 0.0\n",
      "Epoch 3833, Loss: 0.0005869341471846923, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3834, Loss: 0.005433113349681662, Final Batch Loss: 8.752877874940168e-06\n",
      "Epoch 3835, Loss: 0.0036850513561148546, Final Batch Loss: 3.43247338605579e-05\n",
      "Epoch 3836, Loss: 0.0017605142829779652, Final Batch Loss: 1.634854925214313e-06\n",
      "Epoch 3837, Loss: 0.0008225818432947563, Final Batch Loss: 0.0\n",
      "Epoch 3838, Loss: 0.000198125931319737, Final Batch Loss: 2.980229965032777e-07\n",
      "Epoch 3839, Loss: 0.00033249628070564086, Final Batch Loss: 8.514946614468499e-08\n",
      "Epoch 3840, Loss: 0.00019996958508272655, Final Batch Loss: 4.8016710934462026e-05\n",
      "Epoch 3841, Loss: 0.001375761911049267, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 3842, Loss: 0.00018205264056092574, Final Batch Loss: 1.1069429461940672e-07\n",
      "Epoch 3843, Loss: 0.00036681506571767386, Final Batch Loss: 3.0844657885609195e-05\n",
      "Epoch 3844, Loss: 0.0008453678290720745, Final Batch Loss: 5.449549576042045e-07\n",
      "Epoch 3845, Loss: 0.00011590841586439637, Final Batch Loss: 2.5643441404099576e-05\n",
      "Epoch 3846, Loss: 0.022960115039950324, Final Batch Loss: 1.3623912309412844e-07\n",
      "Epoch 3847, Loss: 0.00024319192357324937, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 3848, Loss: 0.0016526339886127062, Final Batch Loss: 5.619853595817403e-07\n",
      "Epoch 3849, Loss: 2.6198408964006603e-05, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3850, Loss: 0.00019009903735422995, Final Batch Loss: 9.655311259848531e-06\n",
      "Epoch 3851, Loss: 8.512767408319633e-05, Final Batch Loss: 7.458706477336818e-06\n",
      "Epoch 3852, Loss: 0.0023150350688183607, Final Batch Loss: 1.2754305316775572e-05\n",
      "Epoch 3853, Loss: 0.00015398218783957418, Final Batch Loss: 4.333978722570464e-06\n",
      "Epoch 3854, Loss: 9.862785562830823e-05, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 3855, Loss: 7.872790138208074e-05, Final Batch Loss: 0.0\n",
      "Epoch 3856, Loss: 0.00032440930901245224, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3857, Loss: 0.0012235640492690436, Final Batch Loss: 5.194100367589272e-07\n",
      "Epoch 3858, Loss: 0.00012478456915232528, Final Batch Loss: 1.166538595498423e-06\n",
      "Epoch 3859, Loss: 0.000277395421367288, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3860, Loss: 0.0002238124302778033, Final Batch Loss: 1.7029881860253226e-07\n",
      "Epoch 3861, Loss: 0.002399128676188411, Final Batch Loss: 8.77013553690631e-06\n",
      "Epoch 3862, Loss: 3.2363346726071995e-05, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 3863, Loss: 0.00025628024832258234, Final Batch Loss: 9.689366379461717e-06\n",
      "Epoch 3864, Loss: 0.00032460884085594444, Final Batch Loss: 0.0\n",
      "Epoch 3865, Loss: 0.00014941310132599028, Final Batch Loss: 7.560876383649884e-06\n",
      "Epoch 3866, Loss: 0.0002301713371224423, Final Batch Loss: 1.7029883281338698e-07\n",
      "Epoch 3867, Loss: 0.00040530727500254216, Final Batch Loss: 0.00010779565491247922\n",
      "Epoch 3868, Loss: 0.00011618623952358575, Final Batch Loss: 0.0\n",
      "Epoch 3869, Loss: 0.0008260645390691934, Final Batch Loss: 0.0\n",
      "Epoch 3870, Loss: 0.0004255005032973713, Final Batch Loss: 4.904471552436007e-06\n",
      "Epoch 3871, Loss: 0.00022487596275766464, Final Batch Loss: 1.7881380642847944e-07\n",
      "Epoch 3872, Loss: 0.00045430469708662713, Final Batch Loss: 1.1068576895922888e-05\n",
      "Epoch 3873, Loss: 0.00010135997904114902, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 3874, Loss: 0.00019416063810240303, Final Batch Loss: 3.661418759293156e-07\n",
      "Epoch 3875, Loss: 0.00012079192958935892, Final Batch Loss: 6.47134243081382e-07\n",
      "Epoch 3876, Loss: 0.0008924462058850224, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3877, Loss: 0.00041481653101982374, Final Batch Loss: 3.371843604327296e-06\n",
      "Epoch 3878, Loss: 9.099093182918239e-05, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3879, Loss: 0.00019593209188784044, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3880, Loss: 8.310082387197326e-05, Final Batch Loss: 1.2286014680285007e-05\n",
      "Epoch 3881, Loss: 9.962922672457353e-05, Final Batch Loss: 0.0\n",
      "Epoch 3882, Loss: 0.00018517326407163637, Final Batch Loss: 8.165373401425313e-06\n",
      "Epoch 3883, Loss: 0.004621071691349954, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3884, Loss: 0.00011811983381448954, Final Batch Loss: 4.01367069571279e-05\n",
      "Epoch 3885, Loss: 0.006690828354749101, Final Batch Loss: 6.564725936186733e-06\n",
      "Epoch 3886, Loss: 0.0013749857718146075, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3887, Loss: 0.002898509534134064, Final Batch Loss: 0.0014533960493281484\n",
      "Epoch 3888, Loss: 0.00029753888657069183, Final Batch Loss: 0.0\n",
      "Epoch 3889, Loss: 0.0016954597770428848, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3890, Loss: 0.0010833393893108223, Final Batch Loss: 1.805146325750684e-06\n",
      "Epoch 3891, Loss: 8.383946268963882e-05, Final Batch Loss: 3.6614196119444387e-07\n",
      "Epoch 3892, Loss: 0.00010055190914570744, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3893, Loss: 0.002065010944143353, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3894, Loss: 0.00010897258380282437, Final Batch Loss: 9.655349458626006e-06\n",
      "Epoch 3895, Loss: 0.00021767111204340495, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 3896, Loss: 0.00017321134419034934, Final Batch Loss: 9.919242984324228e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3897, Loss: 0.0002917059041465109, Final Batch Loss: 1.26020131574478e-06\n",
      "Epoch 3898, Loss: 0.0002912110501256393, Final Batch Loss: 4.2232900341332424e-06\n",
      "Epoch 3899, Loss: 0.000302640608879301, Final Batch Loss: 3.7039121707493905e-06\n",
      "Epoch 3900, Loss: 0.0002746840102645365, Final Batch Loss: 3.789052925640135e-06\n",
      "Epoch 3901, Loss: 0.0002920291346981685, Final Batch Loss: 2.622562988108257e-06\n",
      "Epoch 3902, Loss: 0.00022956380553296185, Final Batch Loss: 0.0\n",
      "Epoch 3903, Loss: 0.001650032728775841, Final Batch Loss: 0.00025679319514892995\n",
      "Epoch 3904, Loss: 0.00026250548422268594, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 3905, Loss: 0.00034763875902399377, Final Batch Loss: 7.578271947750181e-07\n",
      "Epoch 3906, Loss: 0.0008649886392504413, Final Batch Loss: 2.9971995445521316e-06\n",
      "Epoch 3907, Loss: 0.0047141237847938555, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 3908, Loss: 1.9530582374471805e-05, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 3909, Loss: 0.0003378395288891056, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 3910, Loss: 0.0008254358155106445, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3911, Loss: 0.0002236876293082446, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3912, Loss: 0.00012126176284255052, Final Batch Loss: 3.865683993353741e-06\n",
      "Epoch 3913, Loss: 0.0001282007988265832, Final Batch Loss: 1.01490995803033e-05\n",
      "Epoch 3914, Loss: 0.00018304408013136708, Final Batch Loss: 1.958420853043208e-06\n",
      "Epoch 3915, Loss: 0.00019944942187066772, Final Batch Loss: 4.385139163787244e-06\n",
      "Epoch 3916, Loss: 4.8285050070262514e-05, Final Batch Loss: 0.0\n",
      "Epoch 3917, Loss: 0.013178883174987277, Final Batch Loss: 0.0031864356715232134\n",
      "Epoch 3918, Loss: 0.007217783651668697, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 3919, Loss: 0.002258331704979355, Final Batch Loss: 0.0\n",
      "Epoch 3920, Loss: 0.04591713992795121, Final Batch Loss: 1.4210197150532622e-05\n",
      "Epoch 3921, Loss: 0.01305695008808172, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 3922, Loss: 0.054538490017868924, Final Batch Loss: 5.960463766996327e-08\n",
      "Epoch 3923, Loss: 0.030720537584784324, Final Batch Loss: 1.5164505384746008e-05\n",
      "Epoch 3924, Loss: 0.0009478370367403954, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 3925, Loss: 0.037998641382987586, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3926, Loss: 0.02223783999124862, Final Batch Loss: 8.557245564588811e-06\n",
      "Epoch 3927, Loss: 0.018566522965556942, Final Batch Loss: 0.0008384922402910888\n",
      "Epoch 3928, Loss: 0.00046652843229821883, Final Batch Loss: 0.00022616538626607507\n",
      "Epoch 3929, Loss: 0.0027974262920906767, Final Batch Loss: 1.5086938219610602e-05\n",
      "Epoch 3930, Loss: 0.0005650142616104858, Final Batch Loss: 3.431483946769731e-06\n",
      "Epoch 3931, Loss: 0.003942486133269085, Final Batch Loss: 1.1409991884647752e-06\n",
      "Epoch 3932, Loss: 0.002255022470080803, Final Batch Loss: 2.554441152824438e-06\n",
      "Epoch 3933, Loss: 0.0002050677576335147, Final Batch Loss: 6.496695277746767e-06\n",
      "Epoch 3934, Loss: 0.0008376107505227992, Final Batch Loss: 1.336836930931895e-06\n",
      "Epoch 3935, Loss: 0.0016253282437901362, Final Batch Loss: 0.0009240353247150779\n",
      "Epoch 3936, Loss: 0.0005350147662284144, Final Batch Loss: 0.0\n",
      "Epoch 3937, Loss: 0.00017440863712181454, Final Batch Loss: 6.766650767531246e-05\n",
      "Epoch 3938, Loss: 0.0004502271972963712, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3939, Loss: 0.0002283640983478108, Final Batch Loss: 3.882754299411317e-06\n",
      "Epoch 3940, Loss: 0.0003876515711453976, Final Batch Loss: 1.0643112545949407e-05\n",
      "Epoch 3941, Loss: 0.0010619502163535799, Final Batch Loss: 0.0008687698864378035\n",
      "Epoch 3942, Loss: 0.00035068858755948895, Final Batch Loss: 1.4049617220734945e-06\n",
      "Epoch 3943, Loss: 0.013563291873651906, Final Batch Loss: 8.804016033536755e-06\n",
      "Epoch 3944, Loss: 0.0014761475573124017, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 3945, Loss: 0.0024696224900253583, Final Batch Loss: 0.0004978164215572178\n",
      "Epoch 3946, Loss: 0.0010117290042757077, Final Batch Loss: 1.6178397288513224e-07\n",
      "Epoch 3947, Loss: 0.0003629574482602038, Final Batch Loss: 3.6272765555622755e-06\n",
      "Epoch 3948, Loss: 0.00445030434079996, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 3949, Loss: 0.028144620686362032, Final Batch Loss: 0.00042281619971618056\n",
      "Epoch 3950, Loss: 0.0031566508884566247, Final Batch Loss: 6.130737233434047e-07\n",
      "Epoch 3951, Loss: 0.0005220342923166754, Final Batch Loss: 3.882711553160334e-06\n",
      "Epoch 3952, Loss: 0.00098420894209994, Final Batch Loss: 0.0001963900140253827\n",
      "Epoch 3953, Loss: 0.0007710103697604609, Final Batch Loss: 7.91885838680173e-07\n",
      "Epoch 3954, Loss: 0.0007500639771258477, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 3955, Loss: 0.006490700885478873, Final Batch Loss: 0.0\n",
      "Epoch 3956, Loss: 0.00021180395538067387, Final Batch Loss: 3.0483072350762086e-06\n",
      "Epoch 3957, Loss: 0.001138372833139556, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 3958, Loss: 0.0011055072141061828, Final Batch Loss: 0.0009860238060355186\n",
      "Epoch 3959, Loss: 0.0014146021848233659, Final Batch Loss: 1.7881383485018887e-07\n",
      "Epoch 3960, Loss: 0.0003465024667406169, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 3961, Loss: 0.0004296922512594392, Final Batch Loss: 1.4219900776879513e-06\n",
      "Epoch 3962, Loss: 0.0013658737698278856, Final Batch Loss: 8.0801488365978e-05\n",
      "Epoch 3963, Loss: 0.0003980988456397938, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 3964, Loss: 0.00027351240987627534, Final Batch Loss: 0.0\n",
      "Epoch 3965, Loss: 0.0001111953449850489, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 3966, Loss: 0.001273299655203175, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 3967, Loss: 0.00035835686298923974, Final Batch Loss: 2.963140786960139e-06\n",
      "Epoch 3968, Loss: 0.0031051263049448607, Final Batch Loss: 2.576321094238665e-05\n",
      "Epoch 3969, Loss: 0.000313034892315045, Final Batch Loss: 2.1396637748694047e-05\n",
      "Epoch 3970, Loss: 0.0005564101938944077, Final Batch Loss: 4.461729986360297e-06\n",
      "Epoch 3971, Loss: 0.0003094616195085109, Final Batch Loss: 6.147532076283824e-06\n",
      "Epoch 3972, Loss: 0.002474451215675799, Final Batch Loss: 0.0\n",
      "Epoch 3973, Loss: 0.00023764889422750457, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 3974, Loss: 0.0008886696479066813, Final Batch Loss: 1.072875534191553e-06\n",
      "Epoch 3975, Loss: 0.00038731881795683876, Final Batch Loss: 2.446124744892586e-05\n",
      "Epoch 3976, Loss: 0.00026718641765910434, Final Batch Loss: 6.179100455483422e-05\n",
      "Epoch 3977, Loss: 0.0005237699847384647, Final Batch Loss: 2.2989993340161163e-06\n",
      "Epoch 3978, Loss: 0.0007629679990426297, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3979, Loss: 0.0006409333327610511, Final Batch Loss: 2.7310734367347322e-05\n",
      "Epoch 3980, Loss: 0.00024850784939189907, Final Batch Loss: 0.00010483667574590072\n",
      "Epoch 3981, Loss: 0.00020443562971195206, Final Batch Loss: 2.1660513084498234e-05\n",
      "Epoch 3982, Loss: 0.00043220824431955407, Final Batch Loss: 2.8609658784262137e-06\n",
      "Epoch 3983, Loss: 0.0003262792761233868, Final Batch Loss: 0.0001750146329868585\n",
      "Epoch 3984, Loss: 0.0021456280364873237, Final Batch Loss: 0.0009359026444144547\n",
      "Epoch 3985, Loss: 0.0014678486577395233, Final Batch Loss: 2.8099293558625504e-07\n",
      "Epoch 3986, Loss: 0.00016254214733635308, Final Batch Loss: 3.226798799005337e-05\n",
      "Epoch 3987, Loss: 0.0003278133375843595, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 3988, Loss: 7.215014966277522e-05, Final Batch Loss: 3.891226242558332e-06\n",
      "Epoch 3989, Loss: 0.00028532892480903627, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 3990, Loss: 0.012430317470716545, Final Batch Loss: 1.942096969287377e-05\n",
      "Epoch 3991, Loss: 6.049166540833539e-05, Final Batch Loss: 3.848697815556079e-06\n",
      "Epoch 3992, Loss: 0.021827322954777628, Final Batch Loss: 0.0\n",
      "Epoch 3993, Loss: 0.000337517188199854, Final Batch Loss: 0.0\n",
      "Epoch 3994, Loss: 8.997483917028148e-05, Final Batch Loss: 1.6433704104201752e-06\n",
      "Epoch 3995, Loss: 0.001275086122632274, Final Batch Loss: 1.975440909518511e-06\n",
      "Epoch 3996, Loss: 0.003817850934865419, Final Batch Loss: 0.0034702869597822428\n",
      "Epoch 3997, Loss: 0.0007461387541809472, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 3998, Loss: 0.00029181396582345087, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 3999, Loss: 0.00047071783592400607, Final Batch Loss: 0.00014069023018237203\n",
      "Epoch 4000, Loss: 0.0003052088392934138, Final Batch Loss: 1.447539972332379e-07\n",
      "Epoch 4001, Loss: 0.0015320650945795933, Final Batch Loss: 0.0009101151372306049\n",
      "Epoch 4002, Loss: 0.007301964549697004, Final Batch Loss: 0.00014657060091849416\n",
      "Epoch 4003, Loss: 0.0005116293318963017, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 4004, Loss: 0.0004314561547289486, Final Batch Loss: 7.434091094182804e-05\n",
      "Epoch 4005, Loss: 0.004272179895565387, Final Batch Loss: 1.1665389365589363e-06\n",
      "Epoch 4006, Loss: 9.532478361506946e-05, Final Batch Loss: 6.181712706165854e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4007, Loss: 0.00032683015524526127, Final Batch Loss: 0.00015038938727229834\n",
      "Epoch 4008, Loss: 0.002141602477422566, Final Batch Loss: 0.0016255296068266034\n",
      "Epoch 4009, Loss: 0.014382352272882315, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4010, Loss: 0.005406511624329369, Final Batch Loss: 4.6832124667162134e-07\n",
      "Epoch 4011, Loss: 0.014098548432230018, Final Batch Loss: 0.0\n",
      "Epoch 4012, Loss: 0.025566470832927735, Final Batch Loss: 0.02519725263118744\n",
      "Epoch 4013, Loss: 0.00020717816641990794, Final Batch Loss: 0.0\n",
      "Epoch 4014, Loss: 0.00011989275549240119, Final Batch Loss: 4.7852881834842265e-06\n",
      "Epoch 4015, Loss: 0.06327618477371288, Final Batch Loss: 0.0\n",
      "Epoch 4016, Loss: 0.026980410411852063, Final Batch Loss: 2.4001683414098807e-05\n",
      "Epoch 4017, Loss: 0.015086595292814309, Final Batch Loss: 4.350815652287565e-05\n",
      "Epoch 4018, Loss: 0.00020801320624741493, Final Batch Loss: 1.1485850336612202e-05\n",
      "Epoch 4019, Loss: 0.0009507997883702046, Final Batch Loss: 1.124755999626359e-05\n",
      "Epoch 4020, Loss: 0.00011498869661252797, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 4021, Loss: 0.0014245714909115748, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4022, Loss: 0.0004658214907067304, Final Batch Loss: 3.6953929338778835e-06\n",
      "Epoch 4023, Loss: 0.00016103750548168705, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4024, Loss: 0.0029342778145888815, Final Batch Loss: 6.811957575791894e-08\n",
      "Epoch 4025, Loss: 0.0011135350669064792, Final Batch Loss: 8.275653090095147e-05\n",
      "Epoch 4026, Loss: 0.00016585406183367013, Final Batch Loss: 5.0416791054885834e-05\n",
      "Epoch 4027, Loss: 0.00379839527522563, Final Batch Loss: 0.0034118567127734423\n",
      "Epoch 4028, Loss: 0.0008664110704330596, Final Batch Loss: 1.5071331063154503e-06\n",
      "Epoch 4029, Loss: 0.010855005127723416, Final Batch Loss: 2.2024783902452327e-05\n",
      "Epoch 4030, Loss: 0.00033273117628596083, Final Batch Loss: 2.3075328954291763e-06\n",
      "Epoch 4031, Loss: 0.0018236876369748245, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4032, Loss: 0.00043335018747825416, Final Batch Loss: 3.065379416966607e-07\n",
      "Epoch 4033, Loss: 0.0009168638571281917, Final Batch Loss: 1.3988727005198598e-05\n",
      "Epoch 4034, Loss: 0.0002953166786028305, Final Batch Loss: 0.0\n",
      "Epoch 4035, Loss: 0.0007602248062994477, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4036, Loss: 0.0029103208071319386, Final Batch Loss: 0.0\n",
      "Epoch 4037, Loss: 0.00025875691790133715, Final Batch Loss: 0.0\n",
      "Epoch 4038, Loss: 0.0005111930074690463, Final Batch Loss: 1.5156454082898563e-06\n",
      "Epoch 4039, Loss: 0.01110255413732375, Final Batch Loss: 1.6951253201114014e-05\n",
      "Epoch 4040, Loss: 0.00018843553152692039, Final Batch Loss: 4.879216430708766e-05\n",
      "Epoch 4041, Loss: 0.0012011487533527543, Final Batch Loss: 1.437197806808399e-05\n",
      "Epoch 4042, Loss: 0.012173426788649522, Final Batch Loss: 0.000996636226773262\n",
      "Epoch 4043, Loss: 0.0009926385846483754, Final Batch Loss: 0.0005695332074537873\n",
      "Epoch 4044, Loss: 0.00653141306111138, Final Batch Loss: 7.322667897824431e-06\n",
      "Epoch 4045, Loss: 0.0002763613277068089, Final Batch Loss: 3.66141904351025e-07\n",
      "Epoch 4046, Loss: 0.0010929523717209122, Final Batch Loss: 8.174332037924614e-07\n",
      "Epoch 4047, Loss: 0.0006084813996949379, Final Batch Loss: 0.00010868646495509893\n",
      "Epoch 4048, Loss: 0.0005506018187588779, Final Batch Loss: 1.7028136426233687e-05\n",
      "Epoch 4049, Loss: 0.00013169765065867978, Final Batch Loss: 3.3718654322001385e-06\n",
      "Epoch 4050, Loss: 0.0016575350814491685, Final Batch Loss: 4.095634267287096e-06\n",
      "Epoch 4051, Loss: 0.0013428287511487724, Final Batch Loss: 0.0006974707939662039\n",
      "Epoch 4052, Loss: 0.0020721125153499997, Final Batch Loss: 5.87530564644112e-07\n",
      "Epoch 4053, Loss: 0.00042669890331126226, Final Batch Loss: 2.435235501252464e-06\n",
      "Epoch 4054, Loss: 0.0005523549934878247, Final Batch Loss: 5.4919546528253704e-06\n",
      "Epoch 4055, Loss: 0.00021221994211373385, Final Batch Loss: 1.2754259842040483e-05\n",
      "Epoch 4056, Loss: 0.012050691549092107, Final Batch Loss: 3.491122413379344e-07\n",
      "Epoch 4057, Loss: 7.111258935310616e-05, Final Batch Loss: 8.259474952865276e-07\n",
      "Epoch 4058, Loss: 0.0009749420140252596, Final Batch Loss: 2.128734450934644e-07\n",
      "Epoch 4059, Loss: 0.0009244063940059277, Final Batch Loss: 1.1587934750423301e-05\n",
      "Epoch 4060, Loss: 0.0037254861554174568, Final Batch Loss: 1.3879243851988576e-06\n",
      "Epoch 4061, Loss: 0.002526901388971936, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4062, Loss: 0.00021913866760314704, Final Batch Loss: 6.726778565280256e-07\n",
      "Epoch 4063, Loss: 0.0004263104128767736, Final Batch Loss: 3.8571679397136904e-06\n",
      "Epoch 4064, Loss: 0.00034785709798157427, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4065, Loss: 0.0004050428913160431, Final Batch Loss: 4.165150676271878e-05\n",
      "Epoch 4066, Loss: 0.0030800931563135237, Final Batch Loss: 0.00024832395138219\n",
      "Epoch 4067, Loss: 0.0045632406267941406, Final Batch Loss: 6.411534286598908e-06\n",
      "Epoch 4068, Loss: 0.00021298516367096454, Final Batch Loss: 4.1072922613238916e-05\n",
      "Epoch 4069, Loss: 3.682690422834867e-05, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4070, Loss: 0.0014935850686015328, Final Batch Loss: 5.0237686082255095e-05\n",
      "Epoch 4071, Loss: 0.0006228124273093272, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 4072, Loss: 0.00011856830178658129, Final Batch Loss: 1.3299511010700371e-05\n",
      "Epoch 4073, Loss: 0.00018554697908257367, Final Batch Loss: 5.5376800446538255e-05\n",
      "Epoch 4074, Loss: 0.00016880455274836947, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4075, Loss: 9.266430515708635e-05, Final Batch Loss: 4.121146957913879e-06\n",
      "Epoch 4076, Loss: 0.00018934391851388455, Final Batch Loss: 7.663452805672932e-08\n",
      "Epoch 4077, Loss: 0.0003271965379099129, Final Batch Loss: 0.00018808597815223038\n",
      "Epoch 4078, Loss: 0.00028637870713055236, Final Batch Loss: 8.685196348778845e-07\n",
      "Epoch 4079, Loss: 0.0011249116822682481, Final Batch Loss: 1.8306906213183538e-06\n",
      "Epoch 4080, Loss: 0.00027204528532820405, Final Batch Loss: 1.1511692719068378e-05\n",
      "Epoch 4081, Loss: 0.0024366249244849314, Final Batch Loss: 0.0023191175423562527\n",
      "Epoch 4082, Loss: 0.0014368517645380052, Final Batch Loss: 4.223302767059067e-06\n",
      "Epoch 4083, Loss: 0.0020729094275111493, Final Batch Loss: 7.407969633277389e-07\n",
      "Epoch 4084, Loss: 0.0012798118961256932, Final Batch Loss: 4.1723174604157975e-07\n",
      "Epoch 4085, Loss: 0.007584252644178946, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 4086, Loss: 0.0016310080518451286, Final Batch Loss: 0.0006006158655509353\n",
      "Epoch 4087, Loss: 0.0028396592858825898, Final Batch Loss: 0.0\n",
      "Epoch 4088, Loss: 0.00043688699804533826, Final Batch Loss: 1.0728757615652285e-06\n",
      "Epoch 4089, Loss: 9.683919563485688e-05, Final Batch Loss: 1.421982801730337e-06\n",
      "Epoch 4090, Loss: 0.00017726062833389733, Final Batch Loss: 2.7855485313921236e-05\n",
      "Epoch 4091, Loss: 9.638565812153388e-05, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4092, Loss: 0.003817056253950568, Final Batch Loss: 4.172316891981609e-07\n",
      "Epoch 4093, Loss: 0.000280578033002854, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4094, Loss: 0.0055090797081902565, Final Batch Loss: 8.514903129253071e-07\n",
      "Epoch 4095, Loss: 0.009686752665771792, Final Batch Loss: 3.5762732863986457e-07\n",
      "Epoch 4096, Loss: 0.0002826397072297482, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4097, Loss: 0.001740212215736392, Final Batch Loss: 0.0001234155788552016\n",
      "Epoch 4098, Loss: 0.0005664199707098305, Final Batch Loss: 6.951268733246252e-05\n",
      "Epoch 4099, Loss: 0.006093396303697318, Final Batch Loss: 2.7247784828432486e-07\n",
      "Epoch 4100, Loss: 0.00028385482099224646, Final Batch Loss: 3.491120708076778e-07\n",
      "Epoch 4101, Loss: 0.0006336105542459336, Final Batch Loss: 1.847722046477429e-06\n",
      "Epoch 4102, Loss: 0.0014236758634069702, Final Batch Loss: 0.00021861276763956994\n",
      "Epoch 4103, Loss: 0.0048107101683854125, Final Batch Loss: 3.292034307378344e-05\n",
      "Epoch 4104, Loss: 0.0004447741132480587, Final Batch Loss: 1.9328738289914327e-06\n",
      "Epoch 4105, Loss: 0.0006057170604734097, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4106, Loss: 0.002264805304548645, Final Batch Loss: 5.5260834415093996e-06\n",
      "Epoch 4107, Loss: 0.0003198671695372468, Final Batch Loss: 1.7285140074818628e-06\n",
      "Epoch 4108, Loss: 0.00038944532051132796, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4109, Loss: 0.0015686048691350152, Final Batch Loss: 2.3429627617588267e-05\n",
      "Epoch 4110, Loss: 0.00010240184292342747, Final Batch Loss: 1.5478510249522515e-05\n",
      "Epoch 4111, Loss: 0.00018184167254275962, Final Batch Loss: 1.0047568821391906e-06\n",
      "Epoch 4112, Loss: 0.0020520519092315226, Final Batch Loss: 0.0015913036186248064\n",
      "Epoch 4113, Loss: 0.001864505329763233, Final Batch Loss: 1.2431756886144285e-06\n",
      "Epoch 4114, Loss: 0.0003833111048194837, Final Batch Loss: 8.514944482840292e-08\n",
      "Epoch 4115, Loss: 0.000957602882408537, Final Batch Loss: 9.383300493936986e-05\n",
      "Epoch 4116, Loss: 0.00019642292647858994, Final Batch Loss: 6.471333335866802e-07\n",
      "Epoch 4117, Loss: 0.0001829241297173212, Final Batch Loss: 2.3841823804104934e-07\n",
      "Epoch 4118, Loss: 0.00029350147974582796, Final Batch Loss: 1.8988209831150016e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4119, Loss: 0.00032761385873669724, Final Batch Loss: 9.366440423264066e-08\n",
      "Epoch 4120, Loss: 0.00016594649241596926, Final Batch Loss: 1.6568685168749653e-05\n",
      "Epoch 4121, Loss: 0.0026620174120921547, Final Batch Loss: 4.938655706610007e-07\n",
      "Epoch 4122, Loss: 0.00017119304338564234, Final Batch Loss: 1.7881374958506058e-07\n",
      "Epoch 4123, Loss: 0.0009898569505821797, Final Batch Loss: 5.696375410479959e-06\n",
      "Epoch 4124, Loss: 0.00027421692007578713, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 4125, Loss: 0.0019331482872075867, Final Batch Loss: 3.227345223422162e-05\n",
      "Epoch 4126, Loss: 0.0014918098377165734, Final Batch Loss: 5.492062882694881e-06\n",
      "Epoch 4127, Loss: 0.00037399061875476036, Final Batch Loss: 3.378364635864273e-05\n",
      "Epoch 4128, Loss: 6.566132287844084e-05, Final Batch Loss: 1.041326413542265e-05\n",
      "Epoch 4129, Loss: 0.00023965148199067698, Final Batch Loss: 2.5544801474097767e-07\n",
      "Epoch 4130, Loss: 0.002373746316152392, Final Batch Loss: 9.416922694072127e-06\n",
      "Epoch 4131, Loss: 0.00010308082879006975, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4132, Loss: 0.0003314948115562544, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4133, Loss: 0.0006621125066885725, Final Batch Loss: 3.49987531080842e-05\n",
      "Epoch 4134, Loss: 0.0007137179641176772, Final Batch Loss: 2.8524559638754e-06\n",
      "Epoch 4135, Loss: 0.00024557713538797543, Final Batch Loss: 1.5582253354295972e-06\n",
      "Epoch 4136, Loss: 0.0005593008506821207, Final Batch Loss: 0.0001759234583005309\n",
      "Epoch 4137, Loss: 0.0063109072851474934, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 4138, Loss: 7.393617285345044e-05, Final Batch Loss: 1.9584355470669834e-07\n",
      "Epoch 4139, Loss: 0.00019849628993462431, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4140, Loss: 0.0020005563782774516, Final Batch Loss: 7.152538614718651e-07\n",
      "Epoch 4141, Loss: 0.0002286995131726144, Final Batch Loss: 2.039057835645508e-05\n",
      "Epoch 4142, Loss: 0.018210663706927477, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4143, Loss: 0.0004787976698530372, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4144, Loss: 0.0013102448438075953, Final Batch Loss: 2.56339117186144e-05\n",
      "Epoch 4145, Loss: 0.011400932400050579, Final Batch Loss: 2.5544827053636254e-07\n",
      "Epoch 4146, Loss: 0.0981447037675025, Final Batch Loss: 1.3290621609485243e-05\n",
      "Epoch 4147, Loss: 0.00192329687615711, Final Batch Loss: 1.4048297998670023e-05\n",
      "Epoch 4148, Loss: 0.006425006316476356, Final Batch Loss: 6.8627864493464585e-06\n",
      "Epoch 4149, Loss: 0.0029242085283840424, Final Batch Loss: 0.0\n",
      "Epoch 4150, Loss: 0.0005249404908909128, Final Batch Loss: 1.6093086969704018e-06\n",
      "Epoch 4151, Loss: 0.000909505307770786, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4152, Loss: 0.015654969467504998, Final Batch Loss: 8.497745511704125e-06\n",
      "Epoch 4153, Loss: 0.021759371901310942, Final Batch Loss: 3.4059721087942307e-07\n",
      "Epoch 4154, Loss: 0.004115853218536358, Final Batch Loss: 0.0005655806744471192\n",
      "Epoch 4155, Loss: 0.012217909548326134, Final Batch Loss: 1.3623912309412844e-07\n",
      "Epoch 4156, Loss: 0.0019407352042435377, Final Batch Loss: 2.673646577022737e-06\n",
      "Epoch 4157, Loss: 0.03194403235477239, Final Batch Loss: 7.918862365841051e-07\n",
      "Epoch 4158, Loss: 0.02638245714842924, Final Batch Loss: 0.0\n",
      "Epoch 4159, Loss: 0.024270916745535942, Final Batch Loss: 7.603603535244474e-06\n",
      "Epoch 4160, Loss: 0.01931480198254576, Final Batch Loss: 0.00027454333030618727\n",
      "Epoch 4161, Loss: 0.0021791538005118127, Final Batch Loss: 7.237671297843917e-07\n",
      "Epoch 4162, Loss: 0.012639841297925614, Final Batch Loss: 6.386183599715878e-07\n",
      "Epoch 4163, Loss: 0.0009144845371338306, Final Batch Loss: 8.522960342816077e-06\n",
      "Epoch 4164, Loss: 0.03885478267940812, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 4165, Loss: 0.017824551918238285, Final Batch Loss: 1.3452352504828013e-05\n",
      "Epoch 4166, Loss: 0.00278292341931774, Final Batch Loss: 3.065319788220222e-06\n",
      "Epoch 4167, Loss: 0.00030040926412766567, Final Batch Loss: 1.2091177268303e-06\n",
      "Epoch 4168, Loss: 0.0006446154638979351, Final Batch Loss: 2.0435672922758386e-06\n",
      "Epoch 4169, Loss: 0.0010268690166412853, Final Batch Loss: 6.19628990534693e-05\n",
      "Epoch 4170, Loss: 0.0002943930888363866, Final Batch Loss: 6.386183599715878e-07\n",
      "Epoch 4171, Loss: 0.0013018023585438243, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4172, Loss: 0.0018256832081533503, Final Batch Loss: 7.628990715602413e-06\n",
      "Epoch 4173, Loss: 0.032804241265694145, Final Batch Loss: 0.0004911485011689365\n",
      "Epoch 4174, Loss: 0.0005027774132031482, Final Batch Loss: 0.0\n",
      "Epoch 4175, Loss: 0.003237583713712411, Final Batch Loss: 5.364410071706516e-07\n",
      "Epoch 4176, Loss: 0.0013347506210266147, Final Batch Loss: 3.359311449457891e-05\n",
      "Epoch 4177, Loss: 0.0006515777022286784, Final Batch Loss: 3.124737850157544e-05\n",
      "Epoch 4178, Loss: 0.00036939530673407717, Final Batch Loss: 9.323363883595448e-06\n",
      "Epoch 4179, Loss: 0.00035894452048523817, Final Batch Loss: 8.942759450292215e-05\n",
      "Epoch 4180, Loss: 0.0011054139495172421, Final Batch Loss: 1.0174818271480035e-05\n",
      "Epoch 4181, Loss: 0.0009716334061522502, Final Batch Loss: 0.00013338019198272377\n",
      "Epoch 4182, Loss: 0.0015819364266462799, Final Batch Loss: 1.506145690655103e-05\n",
      "Epoch 4183, Loss: 0.00039198964293518657, Final Batch Loss: 1.08990786884533e-06\n",
      "Epoch 4184, Loss: 0.0004949092539305866, Final Batch Loss: 1.0217935653145105e-07\n",
      "Epoch 4185, Loss: 0.0003123371414517351, Final Batch Loss: 4.93865456974163e-07\n",
      "Epoch 4186, Loss: 0.016749713343941153, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 4187, Loss: 0.005789905637925585, Final Batch Loss: 1.285745952372963e-06\n",
      "Epoch 4188, Loss: 0.0005569284274713482, Final Batch Loss: 4.59805818309178e-07\n",
      "Epoch 4189, Loss: 0.0008174397189577576, Final Batch Loss: 0.0002800805668812245\n",
      "Epoch 4190, Loss: 0.0004077414378116373, Final Batch Loss: 1.8689006537897512e-05\n",
      "Epoch 4191, Loss: 0.0006940873707694806, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4192, Loss: 0.0006648230664723087, Final Batch Loss: 6.058371582184918e-05\n",
      "Epoch 4193, Loss: 0.002457182629889587, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4194, Loss: 0.0010131862950828463, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 4195, Loss: 0.0003696268893946808, Final Batch Loss: 8.514946614468499e-08\n",
      "Epoch 4196, Loss: 0.0021190950101299677, Final Batch Loss: 0.0009342547855339944\n",
      "Epoch 4197, Loss: 0.00039561141022659285, Final Batch Loss: 1.1239677633057e-06\n",
      "Epoch 4198, Loss: 0.001858184182168543, Final Batch Loss: 2.809927934777079e-07\n",
      "Epoch 4199, Loss: 0.003767148877418691, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4200, Loss: 0.0002865221849788213, Final Batch Loss: 8.200766751542687e-05\n",
      "Epoch 4201, Loss: 0.004434434003997012, Final Batch Loss: 2.7106458219350316e-05\n",
      "Epoch 4202, Loss: 0.0006906144099048106, Final Batch Loss: 4.495752818911569e-06\n",
      "Epoch 4203, Loss: 0.002836738020430829, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4204, Loss: 0.00046142435166984797, Final Batch Loss: 0.0\n",
      "Epoch 4205, Loss: 0.001069841793118087, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4206, Loss: 0.008958414674452797, Final Batch Loss: 0.008638325147330761\n",
      "Epoch 4207, Loss: 0.0005805325814236539, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 4208, Loss: 0.07535127057866475, Final Batch Loss: 5.790142836303858e-07\n",
      "Epoch 4209, Loss: 0.0008910991868447127, Final Batch Loss: 2.63963045199489e-07\n",
      "Epoch 4210, Loss: 0.0004908783635695357, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4211, Loss: 0.0028371617936500115, Final Batch Loss: 0.0\n",
      "Epoch 4212, Loss: 0.0009636917793613975, Final Batch Loss: 9.961797331925482e-06\n",
      "Epoch 4213, Loss: 0.00037825951039849315, Final Batch Loss: 0.0\n",
      "Epoch 4214, Loss: 0.03585128896231282, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4215, Loss: 0.0012526299356068193, Final Batch Loss: 6.437034699047217e-06\n",
      "Epoch 4216, Loss: 0.0004644172156389459, Final Batch Loss: 1.4475402565494733e-07\n",
      "Epoch 4217, Loss: 0.0004297388550185133, Final Batch Loss: 0.0\n",
      "Epoch 4218, Loss: 0.0009904947507948236, Final Batch Loss: 1.7881370695249643e-07\n",
      "Epoch 4219, Loss: 0.0004060008795789827, Final Batch Loss: 2.1287358720201155e-07\n",
      "Epoch 4220, Loss: 0.0015753988764117821, Final Batch Loss: 0.0\n",
      "Epoch 4221, Loss: 0.00039359448510367656, Final Batch Loss: 1.6994728866848163e-05\n",
      "Epoch 4222, Loss: 0.00029010732941969763, Final Batch Loss: 0.0\n",
      "Epoch 4223, Loss: 0.0005854896162702516, Final Batch Loss: 2.128736298345757e-07\n",
      "Epoch 4224, Loss: 0.00042225500198433963, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4225, Loss: 0.003620456600401667, Final Batch Loss: 2.1609188479487784e-05\n",
      "Epoch 4226, Loss: 0.0007490070684070815, Final Batch Loss: 3.4825297916540876e-06\n",
      "Epoch 4227, Loss: 0.00048504574078833684, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4228, Loss: 0.0009220700558216777, Final Batch Loss: 0.00011434499901952222\n",
      "Epoch 4229, Loss: 0.0011623397917901457, Final Batch Loss: 4.981073743692832e-06\n",
      "Epoch 4230, Loss: 0.001084160140635504, Final Batch Loss: 3.239203942939639e-05\n",
      "Epoch 4231, Loss: 0.001219203362609278, Final Batch Loss: 9.451539995097846e-07\n",
      "Epoch 4232, Loss: 0.00022902550517756026, Final Batch Loss: 8.744317710807081e-06\n",
      "Epoch 4233, Loss: 0.0006941757448117869, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 4234, Loss: 0.0008691513999110612, Final Batch Loss: 6.879751254018629e-06\n",
      "Epoch 4235, Loss: 0.0003600645932237967, Final Batch Loss: 2.017050974245649e-05\n",
      "Epoch 4236, Loss: 0.0002780372076927051, Final Batch Loss: 9.28125984955841e-07\n",
      "Epoch 4237, Loss: 0.00012414838192853495, Final Batch Loss: 3.431468485359801e-06\n",
      "Epoch 4238, Loss: 0.00013374122325870985, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 4239, Loss: 0.46505923261429416, Final Batch Loss: 0.46473079919815063\n",
      "Epoch 4240, Loss: 0.0010819360722962301, Final Batch Loss: 0.0\n",
      "Epoch 4241, Loss: 0.08795891171394032, Final Batch Loss: 2.4793222110019997e-05\n",
      "Epoch 4242, Loss: 0.06238731398480013, Final Batch Loss: 0.0013235578080639243\n",
      "Epoch 4243, Loss: 0.0321581612989803, Final Batch Loss: 1.8392057654637028e-06\n",
      "Epoch 4244, Loss: 0.033071484713900645, Final Batch Loss: 9.877319371298654e-07\n",
      "Epoch 4245, Loss: 0.012708049644061248, Final Batch Loss: 1.5069874280015938e-05\n",
      "Epoch 4246, Loss: 0.013605821489363734, Final Batch Loss: 4.274440470908303e-06\n",
      "Epoch 4247, Loss: 0.010214850246200058, Final Batch Loss: 5.960443445474084e-07\n",
      "Epoch 4248, Loss: 0.0028783188172383234, Final Batch Loss: 0.00022775311663281173\n",
      "Epoch 4249, Loss: 0.002680217774468474, Final Batch Loss: 0.00016154699551407248\n",
      "Epoch 4250, Loss: 0.002002068780711852, Final Batch Loss: 4.6873814426362514e-05\n",
      "Epoch 4251, Loss: 0.00682979634439107, Final Batch Loss: 0.003325072815641761\n",
      "Epoch 4252, Loss: 0.003868278050504159, Final Batch Loss: 3.3548203646205366e-06\n",
      "Epoch 4253, Loss: 0.0020635065011447296, Final Batch Loss: 7.934348832350224e-05\n",
      "Epoch 4254, Loss: 0.0017579833620402496, Final Batch Loss: 2.7574755222303793e-05\n",
      "Epoch 4255, Loss: 0.035678244224982336, Final Batch Loss: 0.010366775095462799\n",
      "Epoch 4256, Loss: 0.0018215224595223845, Final Batch Loss: 6.9650745899707545e-06\n",
      "Epoch 4257, Loss: 0.014265872712712735, Final Batch Loss: 0.0025314788799732924\n",
      "Epoch 4258, Loss: 0.005307515802542184, Final Batch Loss: 6.650002887909068e-06\n",
      "Epoch 4259, Loss: 0.0014009462915396398, Final Batch Loss: 6.045606255611347e-07\n",
      "Epoch 4260, Loss: 0.0017766376113286242, Final Batch Loss: 0.00034643401158973575\n",
      "Epoch 4261, Loss: 0.0013809249727216866, Final Batch Loss: 2.724778767060343e-07\n",
      "Epoch 4262, Loss: 0.0012493637623265386, Final Batch Loss: 0.00018048725905828178\n",
      "Epoch 4263, Loss: 0.0028313001530477777, Final Batch Loss: 3.96032992284745e-05\n",
      "Epoch 4264, Loss: 0.003172446526150452, Final Batch Loss: 0.0019266157178208232\n",
      "Epoch 4265, Loss: 0.001196805626392461, Final Batch Loss: 2.6396301677777956e-07\n",
      "Epoch 4266, Loss: 0.0022632726995652774, Final Batch Loss: 2.0041386960656382e-05\n",
      "Epoch 4267, Loss: 0.0017464995798945893, Final Batch Loss: 0.00011008234287146479\n",
      "Epoch 4268, Loss: 0.0025487425009487197, Final Batch Loss: 0.0006053827819414437\n",
      "Epoch 4269, Loss: 0.001886718796868081, Final Batch Loss: 4.623543190973578e-06\n",
      "Epoch 4270, Loss: 0.0013137973487573618, Final Batch Loss: 7.493122211599257e-07\n",
      "Epoch 4271, Loss: 0.004586004215525463, Final Batch Loss: 0.0009953593835234642\n",
      "Epoch 4272, Loss: 0.0011131391293019988, Final Batch Loss: 6.138817116152495e-05\n",
      "Epoch 4273, Loss: 0.0017374763801853987, Final Batch Loss: 1.4832064152869862e-05\n",
      "Epoch 4274, Loss: 0.003369819419731357, Final Batch Loss: 7.4589220275811385e-06\n",
      "Epoch 4275, Loss: 0.0008018870221349061, Final Batch Loss: 8.352676559297834e-06\n",
      "Epoch 4276, Loss: 0.0009060809188667918, Final Batch Loss: 2.075643169519026e-05\n",
      "Epoch 4277, Loss: 0.0007166280167894001, Final Batch Loss: 3.4484958177927183e-06\n",
      "Epoch 4278, Loss: 0.007059588213451207, Final Batch Loss: 0.005151078570634127\n",
      "Epoch 4279, Loss: 0.0016346836637239903, Final Batch Loss: 0.00024274774477817118\n",
      "Epoch 4280, Loss: 0.0010796404712891672, Final Batch Loss: 0.00013214560749474913\n",
      "Epoch 4281, Loss: 0.00038735775888198987, Final Batch Loss: 2.0382325601531193e-05\n",
      "Epoch 4282, Loss: 0.005656219722627753, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4283, Loss: 0.0011010904452177783, Final Batch Loss: 1.7029703940352192e-06\n",
      "Epoch 4284, Loss: 0.0008852181966858552, Final Batch Loss: 5.279256356516271e-07\n",
      "Epoch 4285, Loss: 0.000710862894525377, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4286, Loss: 0.0004943086860293988, Final Batch Loss: 4.144004196859896e-05\n",
      "Epoch 4287, Loss: 0.003075138054555282, Final Batch Loss: 9.009092900669202e-05\n",
      "Epoch 4288, Loss: 0.0060708782366418745, Final Batch Loss: 0.0\n",
      "Epoch 4289, Loss: 0.0013593716103059705, Final Batch Loss: 0.0003708444710355252\n",
      "Epoch 4290, Loss: 0.0011120399285573512, Final Batch Loss: 0.0004224668664392084\n",
      "Epoch 4291, Loss: 0.001854222128258698, Final Batch Loss: 7.5779521466756705e-06\n",
      "Epoch 4292, Loss: 0.004564591567032039, Final Batch Loss: 0.0011293102288618684\n",
      "Epoch 4293, Loss: 0.0008206340990000172, Final Batch Loss: 2.761962059594225e-05\n",
      "Epoch 4294, Loss: 0.0008451212866020796, Final Batch Loss: 4.0701065699977335e-06\n",
      "Epoch 4295, Loss: 0.002059555457890383, Final Batch Loss: 1.7897275029099546e-05\n",
      "Epoch 4296, Loss: 0.0022963434748817235, Final Batch Loss: 9.713391773402691e-05\n",
      "Epoch 4297, Loss: 0.0007320968506974168, Final Batch Loss: 0.00013765160110779107\n",
      "Epoch 4298, Loss: 0.0013400315688159026, Final Batch Loss: 2.9802276912960224e-07\n",
      "Epoch 4299, Loss: 0.002774545945612772, Final Batch Loss: 8.923286259232555e-06\n",
      "Epoch 4300, Loss: 0.0008492793131154031, Final Batch Loss: 0.00010918634507106617\n",
      "Epoch 4301, Loss: 0.0005660992665070808, Final Batch Loss: 1.300967596762348e-05\n",
      "Epoch 4302, Loss: 0.0011945037548741766, Final Batch Loss: 1.7881384906104358e-07\n",
      "Epoch 4303, Loss: 0.0010598436565487646, Final Batch Loss: 0.00016160109953489155\n",
      "Epoch 4304, Loss: 0.0006562059310795121, Final Batch Loss: 6.81192830143118e-07\n",
      "Epoch 4305, Loss: 0.005896025919355452, Final Batch Loss: 0.004366341046988964\n",
      "Epoch 4306, Loss: 0.0008003985005871073, Final Batch Loss: 2.0009922536701197e-06\n",
      "Epoch 4307, Loss: 0.0015035841533972416, Final Batch Loss: 6.632186705246568e-05\n",
      "Epoch 4308, Loss: 0.0006002818165917745, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4309, Loss: 0.000781326449214248, Final Batch Loss: 5.994579260004684e-05\n",
      "Epoch 4310, Loss: 0.0005799580944767513, Final Batch Loss: 7.552360784757184e-06\n",
      "Epoch 4311, Loss: 0.0019268791859587964, Final Batch Loss: 3.2356754786633246e-07\n",
      "Epoch 4312, Loss: 0.00035111664510623086, Final Batch Loss: 1.3477896573022008e-05\n",
      "Epoch 4313, Loss: 0.0018060542424791493, Final Batch Loss: 0.001174222445115447\n",
      "Epoch 4314, Loss: 0.0005655343666148838, Final Batch Loss: 4.0856855775928125e-05\n",
      "Epoch 4315, Loss: 0.0007072019986367195, Final Batch Loss: 4.6832127509333077e-07\n",
      "Epoch 4316, Loss: 0.00040029860093682146, Final Batch Loss: 6.726789365529839e-07\n",
      "Epoch 4317, Loss: 0.002411519828456221, Final Batch Loss: 0.0002890398318413645\n",
      "Epoch 4318, Loss: 0.0007574697738164105, Final Batch Loss: 2.5714689400047064e-06\n",
      "Epoch 4319, Loss: 0.0008869643934303895, Final Batch Loss: 4.73969557788223e-05\n",
      "Epoch 4320, Loss: 0.0006292751075420711, Final Batch Loss: 9.196099313157902e-07\n",
      "Epoch 4321, Loss: 0.0006361794875147098, Final Batch Loss: 1.583772132107697e-06\n",
      "Epoch 4322, Loss: 0.000872728880494833, Final Batch Loss: 8.386197441723198e-05\n",
      "Epoch 4323, Loss: 0.00045680340605258607, Final Batch Loss: 8.68520658059424e-07\n",
      "Epoch 4324, Loss: 0.0028652597866312135, Final Batch Loss: 9.873079397948459e-05\n",
      "Epoch 4325, Loss: 0.0015190427667519657, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4326, Loss: 0.0006025872321515635, Final Batch Loss: 3.141948127449723e-06\n",
      "Epoch 4327, Loss: 0.0006982145223446423, Final Batch Loss: 1.2788537787855603e-05\n",
      "Epoch 4328, Loss: 0.0007959434501572105, Final Batch Loss: 3.1504646358371247e-06\n",
      "Epoch 4329, Loss: 0.0008193436898409345, Final Batch Loss: 6.982246532061254e-07\n",
      "Epoch 4330, Loss: 0.00046262704108812613, Final Batch Loss: 4.853357495449018e-06\n",
      "Epoch 4331, Loss: 0.00031427191743205185, Final Batch Loss: 1.319695820711786e-05\n",
      "Epoch 4332, Loss: 0.0004431676607055124, Final Batch Loss: 1.284791505895555e-05\n",
      "Epoch 4333, Loss: 0.002045244481962527, Final Batch Loss: 4.257468049218005e-07\n",
      "Epoch 4334, Loss: 0.0006882841807964724, Final Batch Loss: 3.861354343825951e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4335, Loss: 0.028609298861738353, Final Batch Loss: 4.697008989751339e-05\n",
      "Epoch 4336, Loss: 0.00018891625040851068, Final Batch Loss: 6.735174792993348e-06\n",
      "Epoch 4337, Loss: 0.001453707815016969, Final Batch Loss: 3.00174633593997e-05\n",
      "Epoch 4338, Loss: 0.0037410272170603776, Final Batch Loss: 1.5326894242662092e-07\n",
      "Epoch 4339, Loss: 0.00047418337999260984, Final Batch Loss: 0.0002590143703855574\n",
      "Epoch 4340, Loss: 0.0003819064222625457, Final Batch Loss: 3.885195837938227e-05\n",
      "Epoch 4341, Loss: 0.001071103376096616, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4342, Loss: 0.00022107711465935154, Final Batch Loss: 1.277241636898907e-07\n",
      "Epoch 4343, Loss: 0.0005988635373341822, Final Batch Loss: 2.4352546006412013e-06\n",
      "Epoch 4344, Loss: 0.0014280484392656945, Final Batch Loss: 0.0006382727879099548\n",
      "Epoch 4345, Loss: 0.0008065599345172814, Final Batch Loss: 2.1627661226375494e-06\n",
      "Epoch 4346, Loss: 0.0004472253529002046, Final Batch Loss: 2.443750190650462e-06\n",
      "Epoch 4347, Loss: 0.0015655228273772082, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4348, Loss: 0.0007906071605248144, Final Batch Loss: 1.7966358427656814e-06\n",
      "Epoch 4349, Loss: 0.0020118452287398725, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4350, Loss: 0.0007603778503835201, Final Batch Loss: 0.0003175321326125413\n",
      "Epoch 4351, Loss: 0.0006574307603059992, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4352, Loss: 0.00027766764313241765, Final Batch Loss: 2.554482136929437e-07\n",
      "Epoch 4353, Loss: 0.0007371029751084279, Final Batch Loss: 0.00010845789074664935\n",
      "Epoch 4354, Loss: 0.0011710926082741935, Final Batch Loss: 0.00029495335184037685\n",
      "Epoch 4355, Loss: 0.0017770534905139357, Final Batch Loss: 0.0001271597429877147\n",
      "Epoch 4356, Loss: 0.001284376128751319, Final Batch Loss: 3.4910844988189638e-06\n",
      "Epoch 4357, Loss: 0.0005071969790151343, Final Batch Loss: 4.10898428526707e-05\n",
      "Epoch 4358, Loss: 0.0013630285266117426, Final Batch Loss: 0.0\n",
      "Epoch 4359, Loss: 0.0005652291541764498, Final Batch Loss: 1.0217934232059633e-07\n",
      "Epoch 4360, Loss: 0.0009610998931748327, Final Batch Loss: 2.0314590074121952e-05\n",
      "Epoch 4361, Loss: 0.0004135115369194864, Final Batch Loss: 4.1723166077645146e-07\n",
      "Epoch 4362, Loss: 0.0009504266932420791, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4363, Loss: 0.0002051325445791008, Final Batch Loss: 9.612852409190964e-06\n",
      "Epoch 4364, Loss: 0.00045900046661984106, Final Batch Loss: 1.277241636898907e-07\n",
      "Epoch 4365, Loss: 0.0005509607645706183, Final Batch Loss: 3.5762704442277027e-07\n",
      "Epoch 4366, Loss: 0.0016045940249433954, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4367, Loss: 0.00016607377772714926, Final Batch Loss: 1.1069430883026143e-07\n",
      "Epoch 4368, Loss: 0.0003718841981026344, Final Batch Loss: 5.6261651479871944e-05\n",
      "Epoch 4369, Loss: 0.00021887162080247435, Final Batch Loss: 2.5544801474097767e-07\n",
      "Epoch 4370, Loss: 0.0032095205224322854, Final Batch Loss: 0.0002517385291866958\n",
      "Epoch 4371, Loss: 0.0013694626341020921, Final Batch Loss: 9.697874702396803e-06\n",
      "Epoch 4372, Loss: 0.0006004609986121068, Final Batch Loss: 0.0\n",
      "Epoch 4373, Loss: 0.0008625549053249415, Final Batch Loss: 2.9736718715867028e-05\n",
      "Epoch 4374, Loss: 0.00022809818165114848, Final Batch Loss: 0.0\n",
      "Epoch 4375, Loss: 0.01090782394434342, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 4376, Loss: 0.037572946496425175, Final Batch Loss: 1.5326755828937166e-06\n",
      "Epoch 4377, Loss: 0.0178341388800618, Final Batch Loss: 0.00015332855400629342\n",
      "Epoch 4378, Loss: 0.0005858521919890336, Final Batch Loss: 2.988695314343204e-06\n",
      "Epoch 4379, Loss: 0.005215720273554325, Final Batch Loss: 0.00043272640323266387\n",
      "Epoch 4380, Loss: 0.001268591417101561, Final Batch Loss: 1.9208009689464234e-05\n",
      "Epoch 4381, Loss: 0.0010145231367459928, Final Batch Loss: 4.512855866778409e-06\n",
      "Epoch 4382, Loss: 0.011963353510253683, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 4383, Loss: 0.003160483436886352, Final Batch Loss: 9.707002845971147e-07\n",
      "Epoch 4384, Loss: 0.008590978821302997, Final Batch Loss: 4.232995706843212e-05\n",
      "Epoch 4385, Loss: 0.00015266028397320497, Final Batch Loss: 1.617839444634228e-07\n",
      "Epoch 4386, Loss: 0.00040513328545443983, Final Batch Loss: 3.2356743417949474e-07\n",
      "Epoch 4387, Loss: 0.0004711627261713147, Final Batch Loss: 6.0364203818608075e-05\n",
      "Epoch 4388, Loss: 0.0007398471693704778, Final Batch Loss: 3.4825293369067367e-06\n",
      "Epoch 4389, Loss: 0.0006696023285712727, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4390, Loss: 0.000957770117825163, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4391, Loss: 0.002934979336689736, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4392, Loss: 0.001112689762521768, Final Batch Loss: 4.692046422860585e-05\n",
      "Epoch 4393, Loss: 0.0009674083333379713, Final Batch Loss: 6.811927164562803e-07\n",
      "Epoch 4394, Loss: 0.00022593787252844777, Final Batch Loss: 6.86234634486027e-05\n",
      "Epoch 4395, Loss: 0.0013948756713944022, Final Batch Loss: 0.00069631781661883\n",
      "Epoch 4396, Loss: 0.0004413823361346658, Final Batch Loss: 1.5667418438169989e-06\n",
      "Epoch 4397, Loss: 0.00023833443890453054, Final Batch Loss: 1.5071353800522047e-06\n",
      "Epoch 4398, Loss: 0.0005446731083047496, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4399, Loss: 0.019486110570142046, Final Batch Loss: 0.00016496700118295848\n",
      "Epoch 4400, Loss: 0.00027780797617538155, Final Batch Loss: 2.8099302085138333e-07\n",
      "Epoch 4401, Loss: 0.0012074117302063314, Final Batch Loss: 1.379416858071636e-06\n",
      "Epoch 4402, Loss: 0.0021191225949337422, Final Batch Loss: 3.8317176631608163e-07\n",
      "Epoch 4403, Loss: 0.018772585406622966, Final Batch Loss: 1.983846777875442e-05\n",
      "Epoch 4404, Loss: 0.0007754279095024685, Final Batch Loss: 1.1562365216377657e-05\n",
      "Epoch 4405, Loss: 0.0003482399061454089, Final Batch Loss: 6.982236868680047e-07\n",
      "Epoch 4406, Loss: 0.0012051185201471526, Final Batch Loss: 2.1883186036575353e-06\n",
      "Epoch 4407, Loss: 0.0005398025259637507, Final Batch Loss: 0.0\n",
      "Epoch 4408, Loss: 0.00038371447122109714, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4409, Loss: 0.0006461395350925159, Final Batch Loss: 0.00010608990851324052\n",
      "Epoch 4410, Loss: 0.00046895980540284654, Final Batch Loss: 1.4925323739589658e-05\n",
      "Epoch 4411, Loss: 0.0043333970507504205, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4412, Loss: 0.0004285026170691708, Final Batch Loss: 3.0053304726607166e-05\n",
      "Epoch 4413, Loss: 0.001607818236152525, Final Batch Loss: 0.0003520267200656235\n",
      "Epoch 4414, Loss: 0.0008115903001453262, Final Batch Loss: 6.283823313424364e-05\n",
      "Epoch 4415, Loss: 0.0011148481535201427, Final Batch Loss: 0.0008007166907191277\n",
      "Epoch 4416, Loss: 0.0007701248111686709, Final Batch Loss: 2.72477990392872e-07\n",
      "Epoch 4417, Loss: 0.020042001701483514, Final Batch Loss: 7.407967927974823e-07\n",
      "Epoch 4418, Loss: 0.0006341804310068255, Final Batch Loss: 2.6225618512398796e-06\n",
      "Epoch 4419, Loss: 0.0038407355275467125, Final Batch Loss: 6.581842626474099e-06\n",
      "Epoch 4420, Loss: 0.0007064342000688839, Final Batch Loss: 1.6178385919829452e-07\n",
      "Epoch 4421, Loss: 0.0006331139135973274, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4422, Loss: 0.0007745439761492889, Final Batch Loss: 0.0\n",
      "Epoch 4423, Loss: 0.001986554469112889, Final Batch Loss: 3.414437742321752e-06\n",
      "Epoch 4424, Loss: 0.0007291925921890652, Final Batch Loss: 2.837494139384944e-05\n",
      "Epoch 4425, Loss: 0.00018407065073233753, Final Batch Loss: 6.386188147189387e-07\n",
      "Epoch 4426, Loss: 0.00013336892088489094, Final Batch Loss: 2.2990325021510216e-07\n",
      "Epoch 4427, Loss: 0.0028116743715145276, Final Batch Loss: 1.3196951840654947e-05\n",
      "Epoch 4428, Loss: 0.0009468050047871657, Final Batch Loss: 0.00047935955808497965\n",
      "Epoch 4429, Loss: 0.00028017152778225807, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4430, Loss: 0.000784826731432986, Final Batch Loss: 1.0021581147157121e-05\n",
      "Epoch 4431, Loss: 0.0031221089288919757, Final Batch Loss: 4.21484992330079e-06\n",
      "Epoch 4432, Loss: 0.0008151092501975654, Final Batch Loss: 4.087064553459641e-06\n",
      "Epoch 4433, Loss: 0.0013423770251392853, Final Batch Loss: 0.0\n",
      "Epoch 4434, Loss: 0.0005321060126561861, Final Batch Loss: 1.2091132930436288e-06\n",
      "Epoch 4435, Loss: 0.0004299302759136481, Final Batch Loss: 2.358603069296805e-06\n",
      "Epoch 4436, Loss: 0.021882529675281148, Final Batch Loss: 5.364400976759498e-07\n",
      "Epoch 4437, Loss: 0.003862107216377808, Final Batch Loss: 1.302776695411012e-06\n",
      "Epoch 4438, Loss: 0.0004025312323392427, Final Batch Loss: 4.444677415449405e-06\n",
      "Epoch 4439, Loss: 0.0011760188062908128, Final Batch Loss: 0.0001135502097895369\n",
      "Epoch 4440, Loss: 0.0003736530925380066, Final Batch Loss: 0.00010372634278610349\n",
      "Epoch 4441, Loss: 0.0003762513002243395, Final Batch Loss: 2.7247784828432486e-07\n",
      "Epoch 4442, Loss: 0.000623031190571055, Final Batch Loss: 2.2904991965333465e-06\n",
      "Epoch 4443, Loss: 0.0007013199192442698, Final Batch Loss: 0.000473129766760394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4444, Loss: 0.0012551591789815575, Final Batch Loss: 0.0003694391925819218\n",
      "Epoch 4445, Loss: 0.0007991925462356164, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4446, Loss: 0.0009637540520088805, Final Batch Loss: 5.5175646593852434e-06\n",
      "Epoch 4447, Loss: 0.00014315237285700277, Final Batch Loss: 1.6908727047848515e-05\n",
      "Epoch 4448, Loss: 0.002610254219689523, Final Batch Loss: 0.0\n",
      "Epoch 4449, Loss: 0.0008743959200216977, Final Batch Loss: 1.6178395867427753e-07\n",
      "Epoch 4450, Loss: 0.0013759792930159165, Final Batch Loss: 2.19682647184527e-06\n",
      "Epoch 4451, Loss: 0.0003546249156762826, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4452, Loss: 0.0010218349343631417, Final Batch Loss: 0.0\n",
      "Epoch 4453, Loss: 0.00013132744970789645, Final Batch Loss: 2.017761107708793e-05\n",
      "Epoch 4454, Loss: 0.00022769233133068667, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4455, Loss: 0.00036175517427494697, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4456, Loss: 0.001028172509450087, Final Batch Loss: 5.253530162008246e-06\n",
      "Epoch 4457, Loss: 0.00032128192185609805, Final Batch Loss: 1.4475343732556212e-06\n",
      "Epoch 4458, Loss: 0.0002914554823458815, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4459, Loss: 0.0009619529760129808, Final Batch Loss: 2.6736438485386316e-06\n",
      "Epoch 4460, Loss: 0.0003773707248910796, Final Batch Loss: 7.01511962688528e-05\n",
      "Epoch 4461, Loss: 0.00015988308177838917, Final Batch Loss: 1.7029879018082283e-07\n",
      "Epoch 4462, Loss: 0.0002533188597624303, Final Batch Loss: 4.3426175011518353e-07\n",
      "Epoch 4463, Loss: 0.000956296491494868, Final Batch Loss: 0.0001475903409300372\n",
      "Epoch 4464, Loss: 0.0068082942214005016, Final Batch Loss: 2.6651302960090106e-06\n",
      "Epoch 4465, Loss: 0.0006146671998976672, Final Batch Loss: 1.1835682016680948e-06\n",
      "Epoch 4466, Loss: 0.0002268913312946097, Final Batch Loss: 0.0\n",
      "Epoch 4467, Loss: 0.0020486089124460705, Final Batch Loss: 0.0\n",
      "Epoch 4468, Loss: 0.000519987532243249, Final Batch Loss: 1.6220032193814404e-05\n",
      "Epoch 4469, Loss: 0.0005392267305524001, Final Batch Loss: 1.2431776212906698e-06\n",
      "Epoch 4470, Loss: 0.0012448484558262862, Final Batch Loss: 0.0006730508175678551\n",
      "Epoch 4471, Loss: 0.00021390129995779716, Final Batch Loss: 5.4579491006734315e-06\n",
      "Epoch 4472, Loss: 0.002490528898761113, Final Batch Loss: 1.2090205018466804e-05\n",
      "Epoch 4473, Loss: 0.0007815490577058881, Final Batch Loss: 0.000298862112686038\n",
      "Epoch 4474, Loss: 0.010822778589385962, Final Batch Loss: 1.1495138778627734e-06\n",
      "Epoch 4475, Loss: 0.00029439781837936607, Final Batch Loss: 0.00014510915207210928\n",
      "Epoch 4476, Loss: 0.0024204627679864643, Final Batch Loss: 0.001522729406133294\n",
      "Epoch 4477, Loss: 0.002509543235646561, Final Batch Loss: 0.00045809303992427886\n",
      "Epoch 4478, Loss: 0.00023322755308541332, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4479, Loss: 0.003540896131653426, Final Batch Loss: 2.290484644618118e-06\n",
      "Epoch 4480, Loss: 0.00019636093702501967, Final Batch Loss: 2.8098961593059357e-06\n",
      "Epoch 4481, Loss: 0.000422712669660541, Final Batch Loss: 2.7753349058912136e-05\n",
      "Epoch 4482, Loss: 0.0002521423079251406, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4483, Loss: 0.0005214824289012654, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 4484, Loss: 0.0019177113203276974, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4485, Loss: 0.00013977322487335186, Final Batch Loss: 2.1021825887146406e-05\n",
      "Epoch 4486, Loss: 0.0004248618579367758, Final Batch Loss: 2.211842729593627e-05\n",
      "Epoch 4487, Loss: 0.000978459989092073, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4488, Loss: 0.0003495638429740211, Final Batch Loss: 2.9261651434353553e-05\n",
      "Epoch 4489, Loss: 0.00020223222057325074, Final Batch Loss: 3.491120708076778e-07\n",
      "Epoch 4490, Loss: 0.00044413741807147744, Final Batch Loss: 2.375650637986837e-06\n",
      "Epoch 4491, Loss: 0.002552327702233015, Final Batch Loss: 2.3075140234141145e-06\n",
      "Epoch 4492, Loss: 6.891072445114332e-05, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 4493, Loss: 0.00021403052596724592, Final Batch Loss: 8.071883712545969e-06\n",
      "Epoch 4494, Loss: 0.00012623627986840802, Final Batch Loss: 3.0653751537101925e-07\n",
      "Epoch 4495, Loss: 0.00011435214739208277, Final Batch Loss: 2.0435848568922665e-07\n",
      "Epoch 4496, Loss: 0.00029291343142290316, Final Batch Loss: 2.8950788077963807e-07\n",
      "Epoch 4497, Loss: 0.00017399768414705363, Final Batch Loss: 4.257474373048353e-08\n",
      "Epoch 4498, Loss: 0.000473090467039583, Final Batch Loss: 6.0455886341515e-07\n",
      "Epoch 4499, Loss: 0.0006234327520360239, Final Batch Loss: 0.0\n",
      "Epoch 4500, Loss: 0.00031081573565927556, Final Batch Loss: 1.362390804615643e-07\n",
      "Epoch 4501, Loss: 0.019473455573916, Final Batch Loss: 0.01909255050122738\n",
      "Epoch 4502, Loss: 0.010224209122364769, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4503, Loss: 0.01668352500369963, Final Batch Loss: 9.366441133806802e-08\n",
      "Epoch 4504, Loss: 0.0001309095851809161, Final Batch Loss: 3.746571053397929e-07\n",
      "Epoch 4505, Loss: 8.839792576509353e-05, Final Batch Loss: 3.5336290693521732e-06\n",
      "Epoch 4506, Loss: 0.0035052237262789276, Final Batch Loss: 4.35952370025916e-06\n",
      "Epoch 4507, Loss: 0.011621612403814652, Final Batch Loss: 6.428673714253819e-06\n",
      "Epoch 4508, Loss: 0.00021187299719827024, Final Batch Loss: 4.087169429567439e-07\n",
      "Epoch 4509, Loss: 0.001199149587591819, Final Batch Loss: 2.5591361918486655e-05\n",
      "Epoch 4510, Loss: 0.00019219165028516727, Final Batch Loss: 1.1495092167024268e-06\n",
      "Epoch 4511, Loss: 0.002108051372715636, Final Batch Loss: 0.0\n",
      "Epoch 4512, Loss: 0.0007974371454793072, Final Batch Loss: 5.875293709323159e-07\n",
      "Epoch 4513, Loss: 0.00037220359548229, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4514, Loss: 9.232109624690565e-05, Final Batch Loss: 7.833721724637144e-07\n",
      "Epoch 4515, Loss: 0.000801375623268541, Final Batch Loss: 0.0\n",
      "Epoch 4516, Loss: 0.006258707905544725, Final Batch Loss: 2.230882728326833e-06\n",
      "Epoch 4517, Loss: 0.05077267645665984, Final Batch Loss: 4.4277604160924966e-07\n",
      "Epoch 4518, Loss: 0.015994320825939212, Final Batch Loss: 0.0004549268924165517\n",
      "Epoch 4519, Loss: 0.0006387075819702659, Final Batch Loss: 8.25945676297124e-07\n",
      "Epoch 4520, Loss: 0.0014614610411491924, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4521, Loss: 0.028250804333090684, Final Batch Loss: 6.811956865249158e-08\n",
      "Epoch 4522, Loss: 0.0031143109213189746, Final Batch Loss: 5.73895385969081e-06\n",
      "Epoch 4523, Loss: 0.0008486927581543569, Final Batch Loss: 0.0002024651475949213\n",
      "Epoch 4524, Loss: 0.0006254363734736756, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4525, Loss: 0.0005903877608943731, Final Batch Loss: 3.874960384564474e-05\n",
      "Epoch 4526, Loss: 0.0007988489123817999, Final Batch Loss: 2.4519413273083046e-05\n",
      "Epoch 4527, Loss: 0.011770903429493274, Final Batch Loss: 3.8317207895488536e-07\n",
      "Epoch 4528, Loss: 0.00012994881307193396, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 4529, Loss: 0.0005011873803368871, Final Batch Loss: 1.0899051403612248e-06\n",
      "Epoch 4530, Loss: 0.00043234607073827647, Final Batch Loss: 0.0\n",
      "Epoch 4531, Loss: 0.0019123260608466808, Final Batch Loss: 0.0017174804816022515\n",
      "Epoch 4532, Loss: 0.0013387440979215626, Final Batch Loss: 3.320822372643306e-07\n",
      "Epoch 4533, Loss: 0.0023615995574459703, Final Batch Loss: 6.556488756359613e-07\n",
      "Epoch 4534, Loss: 0.0013316762935460247, Final Batch Loss: 7.152531793508388e-07\n",
      "Epoch 4535, Loss: 0.00024199085055442993, Final Batch Loss: 6.044234032742679e-05\n",
      "Epoch 4536, Loss: 0.00028144406041974435, Final Batch Loss: 1.1485873073979747e-05\n",
      "Epoch 4537, Loss: 0.00012535546557046473, Final Batch Loss: 3.9593796827830374e-06\n",
      "Epoch 4538, Loss: 0.0001698183559710742, Final Batch Loss: 0.0\n",
      "Epoch 4539, Loss: 0.018474874825187726, Final Batch Loss: 0.010147624649107456\n",
      "Epoch 4540, Loss: 0.000962287167908471, Final Batch Loss: 9.196097607855336e-07\n",
      "Epoch 4541, Loss: 0.0010566516357357614, Final Batch Loss: 5.936215166002512e-05\n",
      "Epoch 4542, Loss: 0.0003700827201100765, Final Batch Loss: 0.0001258592092199251\n",
      "Epoch 4543, Loss: 0.0005947097723719708, Final Batch Loss: 1.106934973904572e-06\n",
      "Epoch 4544, Loss: 0.0006640470514867047, Final Batch Loss: 5.262062131805578e-06\n",
      "Epoch 4545, Loss: 0.0011507960487051605, Final Batch Loss: 0.0\n",
      "Epoch 4546, Loss: 0.0013347219664865406, Final Batch Loss: 1.59978026204044e-05\n",
      "Epoch 4547, Loss: 0.0006771701151304654, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4548, Loss: 5.6761469863886305e-05, Final Batch Loss: 1.6603963786110398e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4549, Loss: 0.0001480659598200873, Final Batch Loss: 2.2990343495621346e-07\n",
      "Epoch 4550, Loss: 0.0005236244205661933, Final Batch Loss: 6.121986189100426e-06\n",
      "Epoch 4551, Loss: 0.0005068366632059451, Final Batch Loss: 1.702988612350964e-07\n",
      "Epoch 4552, Loss: 0.00016756230979808606, Final Batch Loss: 0.0\n",
      "Epoch 4553, Loss: 0.0011075712523052061, Final Batch Loss: 2.409692115179496e-06\n",
      "Epoch 4554, Loss: 0.00041378304405270683, Final Batch Loss: 7.237670729409729e-07\n",
      "Epoch 4555, Loss: 0.0005916291616188118, Final Batch Loss: 2.639631304646173e-07\n",
      "Epoch 4556, Loss: 0.00022152468680758375, Final Batch Loss: 1.5326894242662092e-07\n",
      "Epoch 4557, Loss: 0.00010718291309785855, Final Batch Loss: 4.0020154301600996e-07\n",
      "Epoch 4558, Loss: 0.0010499987897674146, Final Batch Loss: 1.9839558262901846e-06\n",
      "Epoch 4559, Loss: 0.0010339181192513536, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4560, Loss: 0.00014757219469174743, Final Batch Loss: 6.360383849823847e-06\n",
      "Epoch 4561, Loss: 0.0005350518331397325, Final Batch Loss: 3.084307900280692e-05\n",
      "Epoch 4562, Loss: 0.0003507135561449104, Final Batch Loss: 5.1769720812444575e-06\n",
      "Epoch 4563, Loss: 0.00024050404772424372, Final Batch Loss: 0.0\n",
      "Epoch 4564, Loss: 0.0007454503995063533, Final Batch Loss: 7.15252269856137e-07\n",
      "Epoch 4565, Loss: 6.835937106508538e-05, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4566, Loss: 0.0002756396914129766, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4567, Loss: 0.0004473746469422224, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4568, Loss: 0.00015665496457728523, Final Batch Loss: 9.366440423264066e-08\n",
      "Epoch 4569, Loss: 8.125285381765934e-05, Final Batch Loss: 5.534707838705799e-07\n",
      "Epoch 4570, Loss: 0.0001797774192286994, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4571, Loss: 9.120178946275814e-05, Final Batch Loss: 5.960463411724959e-08\n",
      "Epoch 4572, Loss: 5.653172380348792e-05, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4573, Loss: 0.00024121493265738536, Final Batch Loss: 2.1883126919419738e-06\n",
      "Epoch 4574, Loss: 8.268048391357752e-05, Final Batch Loss: 2.2990339232364931e-07\n",
      "Epoch 4575, Loss: 0.0006010725282976637, Final Batch Loss: 0.0\n",
      "Epoch 4576, Loss: 0.00010593470733510912, Final Batch Loss: 2.775819439193583e-06\n",
      "Epoch 4577, Loss: 0.0002052729068964254, Final Batch Loss: 6.812116043874994e-05\n",
      "Epoch 4578, Loss: 0.00025342236199321633, Final Batch Loss: 3.66133622264897e-06\n",
      "Epoch 4579, Loss: 0.00016660727487760596, Final Batch Loss: 1.9402932593948208e-05\n",
      "Epoch 4580, Loss: 0.00010186394320044201, Final Batch Loss: 0.0\n",
      "Epoch 4581, Loss: 0.00018982894211205803, Final Batch Loss: 3.4059794984386826e-08\n",
      "Epoch 4582, Loss: 8.572214574087411e-05, Final Batch Loss: 1.036230878526112e-05\n",
      "Epoch 4583, Loss: 7.743896671996708e-05, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 4584, Loss: 0.0018084390806052397, Final Batch Loss: 2.4778175884421216e-06\n",
      "Epoch 4585, Loss: 0.000118297400863554, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4586, Loss: 0.00038735770249331836, Final Batch Loss: 1.8988084775628522e-06\n",
      "Epoch 4587, Loss: 9.970974003259414e-05, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4588, Loss: 0.0048329616874980275, Final Batch Loss: 0.0\n",
      "Epoch 4589, Loss: 0.015262646831331494, Final Batch Loss: 5.790149657514121e-07\n",
      "Epoch 4590, Loss: 0.2643446510664944, Final Batch Loss: 0.2611531913280487\n",
      "Epoch 4591, Loss: 0.00021662733377070253, Final Batch Loss: 1.490107365498261e-06\n",
      "Epoch 4592, Loss: 0.03443976204971477, Final Batch Loss: 3.823180577455787e-06\n",
      "Epoch 4593, Loss: 0.025351697739324663, Final Batch Loss: 1.9924775642721215e-06\n",
      "Epoch 4594, Loss: 0.009552026699690686, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4595, Loss: 0.012628221962870612, Final Batch Loss: 3.235675762880419e-07\n",
      "Epoch 4596, Loss: 0.02850679820858204, Final Batch Loss: 8.78558712429367e-05\n",
      "Epoch 4597, Loss: 0.0008913404990380513, Final Batch Loss: 1.4448854017246049e-05\n",
      "Epoch 4598, Loss: 0.000521432329946947, Final Batch Loss: 1.1750543080779607e-06\n",
      "Epoch 4599, Loss: 0.0008720889745745808, Final Batch Loss: 9.027779015013948e-05\n",
      "Epoch 4600, Loss: 0.0008751789428060874, Final Batch Loss: 0.0002824620169121772\n",
      "Epoch 4601, Loss: 0.010854680078409729, Final Batch Loss: 1.9070970665779896e-05\n",
      "Epoch 4602, Loss: 0.0013697883171914782, Final Batch Loss: 2.639629599343607e-07\n",
      "Epoch 4603, Loss: 0.001330240160939411, Final Batch Loss: 6.556480798280973e-07\n",
      "Epoch 4604, Loss: 0.000325674864143366, Final Batch Loss: 2.874976780731231e-05\n",
      "Epoch 4605, Loss: 0.0008055636286883328, Final Batch Loss: 4.5129186787562503e-07\n",
      "Epoch 4606, Loss: 0.01588056136824889, Final Batch Loss: 0.011615117080509663\n",
      "Epoch 4607, Loss: 0.0008399930387383847, Final Batch Loss: 4.0020162828113826e-07\n",
      "Epoch 4608, Loss: 0.02147019270486794, Final Batch Loss: 3.065375437927287e-07\n",
      "Epoch 4609, Loss: 0.021936671259027207, Final Batch Loss: 0.001305444398894906\n",
      "Epoch 4610, Loss: 0.01773266464806511, Final Batch Loss: 3.9154805563157424e-05\n",
      "Epoch 4611, Loss: 0.00959266100107925, Final Batch Loss: 0.0013057838659733534\n",
      "Epoch 4612, Loss: 0.056677215247223245, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4613, Loss: 0.036638117273611215, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 4614, Loss: 0.0008378676746847447, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4615, Loss: 0.01293879784134333, Final Batch Loss: 0.012475292198359966\n",
      "Epoch 4616, Loss: 0.0007412330924125854, Final Batch Loss: 1.733514727675356e-05\n",
      "Epoch 4617, Loss: 0.001110133807941338, Final Batch Loss: 4.4277678057369485e-07\n",
      "Epoch 4618, Loss: 0.0008730492563699954, Final Batch Loss: 2.1287360141286626e-07\n",
      "Epoch 4619, Loss: 0.0011970275757313686, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4620, Loss: 0.0006583481094821764, Final Batch Loss: 3.976370408054208e-06\n",
      "Epoch 4621, Loss: 0.005220666618924952, Final Batch Loss: 1.362383272862644e-06\n",
      "Epoch 4622, Loss: 0.0005513487067219103, Final Batch Loss: 2.9716557037318125e-06\n",
      "Epoch 4623, Loss: 0.0004247875403962098, Final Batch Loss: 0.0\n",
      "Epoch 4624, Loss: 0.0013418076471545248, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4625, Loss: 0.0003206563345372615, Final Batch Loss: 2.980226270210551e-07\n",
      "Epoch 4626, Loss: 0.0006547331577166915, Final Batch Loss: 2.3668340872973204e-05\n",
      "Epoch 4627, Loss: 0.02268892952477941, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4628, Loss: 0.0024352735781576484, Final Batch Loss: 0.000127571722259745\n",
      "Epoch 4629, Loss: 0.0017125463073170977, Final Batch Loss: 0.0\n",
      "Epoch 4630, Loss: 0.008163658391140416, Final Batch Loss: 3.022751343451091e-06\n",
      "Epoch 4631, Loss: 0.0012482677333665038, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4632, Loss: 0.0012611055790330283, Final Batch Loss: 0.0006913276156410575\n",
      "Epoch 4633, Loss: 0.0023546198062831536, Final Batch Loss: 0.001413975958712399\n",
      "Epoch 4634, Loss: 0.0007249579612107482, Final Batch Loss: 1.4645629562437534e-06\n",
      "Epoch 4635, Loss: 0.012989041151513447, Final Batch Loss: 2.290503971380531e-06\n",
      "Epoch 4636, Loss: 0.000845033199830425, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4637, Loss: 0.00047913526759657543, Final Batch Loss: 0.0\n",
      "Epoch 4638, Loss: 0.0033836844195320737, Final Batch Loss: 0.0003990698023699224\n",
      "Epoch 4639, Loss: 0.000480521292956837, Final Batch Loss: 0.00011320175690343603\n",
      "Epoch 4640, Loss: 0.0005711457251891261, Final Batch Loss: 7.921559881651774e-05\n",
      "Epoch 4641, Loss: 0.00046940494030422997, Final Batch Loss: 0.00014320611080620438\n",
      "Epoch 4642, Loss: 0.0009096406793105416, Final Batch Loss: 8.30758799565956e-05\n",
      "Epoch 4643, Loss: 0.001049089575076323, Final Batch Loss: 1.7200094362124219e-06\n",
      "Epoch 4644, Loss: 0.0006494004176147428, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4645, Loss: 0.0010726336304287543, Final Batch Loss: 0.00024725665571168065\n",
      "Epoch 4646, Loss: 0.0003639269353925556, Final Batch Loss: 5.108951199872536e-07\n",
      "Epoch 4647, Loss: 0.0008205630765587557, Final Batch Loss: 6.945909262867644e-05\n",
      "Epoch 4648, Loss: 0.0001533545600977959, Final Batch Loss: 0.0\n",
      "Epoch 4649, Loss: 0.00026494380847452703, Final Batch Loss: 1.004760747491673e-06\n",
      "Epoch 4650, Loss: 0.0006573156415470294, Final Batch Loss: 7.663429641979747e-07\n",
      "Epoch 4651, Loss: 0.000688283367708209, Final Batch Loss: 2.9447908673319034e-05\n",
      "Epoch 4652, Loss: 0.0008759644784532838, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 4653, Loss: 0.00025024856705613274, Final Batch Loss: 6.726780270582822e-07\n",
      "Epoch 4654, Loss: 0.002829159718054086, Final Batch Loss: 8.514947325011235e-08\n",
      "Epoch 4655, Loss: 8.276374624216487e-05, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 4656, Loss: 0.0004905886588435493, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4657, Loss: 0.002340969290571593, Final Batch Loss: 0.002166639780625701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4658, Loss: 0.000845074535391177, Final Batch Loss: 1.5172236089711078e-05\n",
      "Epoch 4659, Loss: 0.0006607837297565311, Final Batch Loss: 5.534696470022027e-07\n",
      "Epoch 4660, Loss: 0.003582148398436402, Final Batch Loss: 4.325499048718484e-06\n",
      "Epoch 4661, Loss: 0.011156239424117587, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4662, Loss: 0.0007660983455934911, Final Batch Loss: 6.624445632041898e-06\n",
      "Epoch 4663, Loss: 0.0005356562669476261, Final Batch Loss: 0.0\n",
      "Epoch 4664, Loss: 0.0006908131181262434, Final Batch Loss: 0.00020433870668057352\n",
      "Epoch 4665, Loss: 0.0005941734077623551, Final Batch Loss: 5.449553555081366e-07\n",
      "Epoch 4666, Loss: 0.00035543724516173825, Final Batch Loss: 1.8568713130662218e-05\n",
      "Epoch 4667, Loss: 0.0008456017421849538, Final Batch Loss: 8.940445695770904e-05\n",
      "Epoch 4668, Loss: 0.0009738857466459194, Final Batch Loss: 8.089178322734369e-07\n",
      "Epoch 4669, Loss: 0.0012807237671950134, Final Batch Loss: 0.0007155059138312936\n",
      "Epoch 4670, Loss: 0.0003736901956017391, Final Batch Loss: 1.9243627775722416e-06\n",
      "Epoch 4671, Loss: 0.000949951941947802, Final Batch Loss: 1.1494259524624795e-05\n",
      "Epoch 4672, Loss: 0.0031840744392326314, Final Batch Loss: 1.7029891807851527e-07\n",
      "Epoch 4673, Loss: 0.0005582604138396619, Final Batch Loss: 4.512915836585307e-07\n",
      "Epoch 4674, Loss: 0.0008735797346162144, Final Batch Loss: 0.00018819267279468477\n",
      "Epoch 4675, Loss: 0.0037005557787779253, Final Batch Loss: 0.003051640000194311\n",
      "Epoch 4676, Loss: 0.0010092433562931546, Final Batch Loss: 6.700994617858669e-06\n",
      "Epoch 4677, Loss: 0.000370632481804023, Final Batch Loss: 1.0643610721672303e-06\n",
      "Epoch 4678, Loss: 0.0005829405017721001, Final Batch Loss: 0.00015820612316019833\n",
      "Epoch 4679, Loss: 0.0013953696044453068, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4680, Loss: 0.0002902268397519947, Final Batch Loss: 0.0\n",
      "Epoch 4681, Loss: 0.000309707163586026, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4682, Loss: 0.002602275441859092, Final Batch Loss: 1.0353493962611537e-05\n",
      "Epoch 4683, Loss: 0.0007904830517873052, Final Batch Loss: 9.025816325447522e-07\n",
      "Epoch 4684, Loss: 0.0019069049812969752, Final Batch Loss: 0.0\n",
      "Epoch 4685, Loss: 0.0004982255686627468, Final Batch Loss: 3.224049214622937e-05\n",
      "Epoch 4686, Loss: 0.011176155944667698, Final Batch Loss: 4.708611413661856e-06\n",
      "Epoch 4687, Loss: 0.0005562926817219704, Final Batch Loss: 2.1999247110215947e-05\n",
      "Epoch 4688, Loss: 0.012276158101485635, Final Batch Loss: 8.837975656206254e-06\n",
      "Epoch 4689, Loss: 0.00038283213559076046, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4690, Loss: 0.0007042325100883318, Final Batch Loss: 4.061540948896436e-06\n",
      "Epoch 4691, Loss: 0.0012168570341373197, Final Batch Loss: 1.7285186686422094e-06\n",
      "Epoch 4692, Loss: 0.0007840002026568982, Final Batch Loss: 1.2992643860343378e-05\n",
      "Epoch 4693, Loss: 0.005397629731305642, Final Batch Loss: 0.0013991417363286018\n",
      "Epoch 4694, Loss: 0.00020854823287663748, Final Batch Loss: 9.332078661827836e-06\n",
      "Epoch 4695, Loss: 0.0007334865422308212, Final Batch Loss: 8.135662210406736e-05\n",
      "Epoch 4696, Loss: 0.0009875798129996838, Final Batch Loss: 1.23465702017711e-06\n",
      "Epoch 4697, Loss: 0.012668154439346324, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4698, Loss: 0.0011879699959536083, Final Batch Loss: 0.00021786688012070954\n",
      "Epoch 4699, Loss: 0.00697093297048923, Final Batch Loss: 2.8269073482078966e-06\n",
      "Epoch 4700, Loss: 0.005013047005245852, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4701, Loss: 0.0009514602433569053, Final Batch Loss: 5.023802600589988e-07\n",
      "Epoch 4702, Loss: 0.0012280177979846485, Final Batch Loss: 6.169694097479805e-05\n",
      "Epoch 4703, Loss: 0.0014007054141984554, Final Batch Loss: 0.0011673171538859606\n",
      "Epoch 4704, Loss: 0.001214920743905168, Final Batch Loss: 1.98395605366386e-06\n",
      "Epoch 4705, Loss: 0.0011446678622846207, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4706, Loss: 0.000258239138929639, Final Batch Loss: 3.6272904253564775e-06\n",
      "Epoch 4707, Loss: 0.001079521226529323, Final Batch Loss: 0.00024072894302662462\n",
      "Epoch 4708, Loss: 0.00016374808575392308, Final Batch Loss: 3.235675762880419e-07\n",
      "Epoch 4709, Loss: 0.0011035746792913415, Final Batch Loss: 0.0\n",
      "Epoch 4710, Loss: 0.0003188537806977365, Final Batch Loss: 2.63963045199489e-07\n",
      "Epoch 4711, Loss: 0.00028840507576433083, Final Batch Loss: 6.982225499996275e-07\n",
      "Epoch 4712, Loss: 0.000713218707460328, Final Batch Loss: 2.807022065098863e-05\n",
      "Epoch 4713, Loss: 0.0009907497278618393, Final Batch Loss: 2.4969980586320162e-05\n",
      "Epoch 4714, Loss: 0.00031771651083545294, Final Batch Loss: 8.369903298444115e-06\n",
      "Epoch 4715, Loss: 0.00019700091096197525, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4716, Loss: 0.007470018908861675, Final Batch Loss: 0.007120892405509949\n",
      "Epoch 4717, Loss: 0.0005390604783315212, Final Batch Loss: 0.00013867931556887925\n",
      "Epoch 4718, Loss: 0.0004162483216347823, Final Batch Loss: 1.1069430883026143e-07\n",
      "Epoch 4719, Loss: 0.000932771384100306, Final Batch Loss: 7.152538046284462e-07\n",
      "Epoch 4720, Loss: 0.000381624053716223, Final Batch Loss: 0.0\n",
      "Epoch 4721, Loss: 0.0002918361315096263, Final Batch Loss: 0.0\n",
      "Epoch 4722, Loss: 0.0002663830441633763, Final Batch Loss: 6.002863756293664e-06\n",
      "Epoch 4723, Loss: 0.00043282409598788263, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4724, Loss: 0.0013617682446351864, Final Batch Loss: 2.9802259859934566e-07\n",
      "Epoch 4725, Loss: 0.029420785186516696, Final Batch Loss: 1.6093125623228843e-06\n",
      "Epoch 4726, Loss: 0.0003820735610133852, Final Batch Loss: 0.00012503830657806247\n",
      "Epoch 4727, Loss: 0.0002756812489934646, Final Batch Loss: 1.4475411092007562e-07\n",
      "Epoch 4728, Loss: 0.0009091382145527405, Final Batch Loss: 1.2772412105732656e-07\n",
      "Epoch 4729, Loss: 0.00019860446838038115, Final Batch Loss: 4.683209340328176e-07\n",
      "Epoch 4730, Loss: 0.0006803104685388917, Final Batch Loss: 4.1723129129422887e-07\n",
      "Epoch 4731, Loss: 0.00031766937172506005, Final Batch Loss: 9.025789040606469e-07\n",
      "Epoch 4732, Loss: 0.00024304018214493794, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4733, Loss: 0.0009930034739227267, Final Batch Loss: 5.467911250889301e-05\n",
      "Epoch 4734, Loss: 0.00031662081525851704, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4735, Loss: 0.0006638988688791869, Final Batch Loss: 9.102285730477888e-06\n",
      "Epoch 4736, Loss: 0.0018288782393938163, Final Batch Loss: 0.001086498494260013\n",
      "Epoch 4737, Loss: 0.00025487419588898774, Final Batch Loss: 9.757473890203983e-06\n",
      "Epoch 4738, Loss: 0.00033462429450992204, Final Batch Loss: 2.4607913928775815e-06\n",
      "Epoch 4739, Loss: 0.0063717321754666045, Final Batch Loss: 0.0040328833274543285\n",
      "Epoch 4740, Loss: 0.00041404286788804257, Final Batch Loss: 2.0435858516520966e-07\n",
      "Epoch 4741, Loss: 0.0015632146025836846, Final Batch Loss: 0.0008670229581184685\n",
      "Epoch 4742, Loss: 0.012060746121278498, Final Batch Loss: 0.0\n",
      "Epoch 4743, Loss: 0.0005646157806040719, Final Batch Loss: 2.3330630938289687e-06\n",
      "Epoch 4744, Loss: 0.00020753915032400982, Final Batch Loss: 5.303573561832309e-05\n",
      "Epoch 4745, Loss: 0.00045914922520751134, Final Batch Loss: 0.0\n",
      "Epoch 4746, Loss: 0.0002887806667786208, Final Batch Loss: 2.3625076210009865e-05\n",
      "Epoch 4747, Loss: 0.0005975264643893752, Final Batch Loss: 0.0\n",
      "Epoch 4748, Loss: 0.00038214103142308886, Final Batch Loss: 4.683099632529775e-06\n",
      "Epoch 4749, Loss: 0.0013170079669180268, Final Batch Loss: 4.053000793646788e-06\n",
      "Epoch 4750, Loss: 0.0003068042715312913, Final Batch Loss: 0.0\n",
      "Epoch 4751, Loss: 0.00033194148856452443, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4752, Loss: 0.0005158955750914629, Final Batch Loss: 3.23567320492657e-07\n",
      "Epoch 4753, Loss: 0.0014144907181616873, Final Batch Loss: 0.0\n",
      "Epoch 4754, Loss: 0.0017734852935973322, Final Batch Loss: 1.0004398973251227e-05\n",
      "Epoch 4755, Loss: 0.039299310688875266, Final Batch Loss: 0.0005016383365727961\n",
      "Epoch 4756, Loss: 0.008920829989456536, Final Batch Loss: 8.514945903925764e-08\n",
      "Epoch 4757, Loss: 0.0001320622832281515, Final Batch Loss: 1.2200899618619587e-05\n",
      "Epoch 4758, Loss: 0.00044087991955166217, Final Batch Loss: 0.0\n",
      "Epoch 4759, Loss: 0.0018976178203047311, Final Batch Loss: 0.0\n",
      "Epoch 4760, Loss: 0.00026673370095409155, Final Batch Loss: 1.447540114440926e-07\n",
      "Epoch 4761, Loss: 0.0005802518665269929, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4762, Loss: 0.00031596410008205567, Final Batch Loss: 8.375501784030348e-05\n",
      "Epoch 4763, Loss: 0.00044345298147163703, Final Batch Loss: 0.00011865334090543911\n",
      "Epoch 4764, Loss: 0.000326664336171234, Final Batch Loss: 0.0\n",
      "Epoch 4765, Loss: 0.0011489577536849538, Final Batch Loss: 0.00033755431650206447\n",
      "Epoch 4766, Loss: 0.0008398565441893879, Final Batch Loss: 0.00028581073274835944\n",
      "Epoch 4767, Loss: 0.0005704762601581592, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4768, Loss: 0.0017752117200870998, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4769, Loss: 0.00030869612919559586, Final Batch Loss: 2.988684627780458e-06\n",
      "Epoch 4770, Loss: 0.0008768357879489486, Final Batch Loss: 1.5955232811393216e-05\n",
      "Epoch 4771, Loss: 0.00025127066919594654, Final Batch Loss: 3.9168708099168725e-07\n",
      "Epoch 4772, Loss: 0.00028153825223853346, Final Batch Loss: 4.1252576920669526e-05\n",
      "Epoch 4773, Loss: 0.0002885427502405946, Final Batch Loss: 5.528338806470856e-05\n",
      "Epoch 4774, Loss: 0.00012900173701702045, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4775, Loss: 0.0268456543656157, Final Batch Loss: 1.370894324281835e-06\n",
      "Epoch 4776, Loss: 0.047077045199330314, Final Batch Loss: 0.0\n",
      "Epoch 4777, Loss: 0.0002601782908016048, Final Batch Loss: 4.6832067823743273e-07\n",
      "Epoch 4778, Loss: 0.00023651886999687122, Final Batch Loss: 1.4475403986580204e-07\n",
      "Epoch 4779, Loss: 0.0002558969708843506, Final Batch Loss: 2.796614899125416e-05\n",
      "Epoch 4780, Loss: 0.0006229525733942864, Final Batch Loss: 3.9168662624433637e-07\n",
      "Epoch 4781, Loss: 0.0038782176259246626, Final Batch Loss: 1.9498972960718675e-06\n",
      "Epoch 4782, Loss: 0.0011958883551415056, Final Batch Loss: 9.765938011696562e-05\n",
      "Epoch 4783, Loss: 0.0004780711460625753, Final Batch Loss: 0.0\n",
      "Epoch 4784, Loss: 0.0007000571299968783, Final Batch Loss: 7.663451384587461e-08\n",
      "Epoch 4785, Loss: 0.0004827437824133085, Final Batch Loss: 8.710261681699194e-06\n",
      "Epoch 4786, Loss: 0.000766980208148027, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4787, Loss: 0.0003957534299843246, Final Batch Loss: 0.00016739635611884296\n",
      "Epoch 4788, Loss: 0.0011379156856037298, Final Batch Loss: 3.303732000858872e-06\n",
      "Epoch 4789, Loss: 0.0035242589729023166, Final Batch Loss: 0.0\n",
      "Epoch 4790, Loss: 0.0005190064398448158, Final Batch Loss: 7.126719992811559e-06\n",
      "Epoch 4791, Loss: 0.0008539312220818829, Final Batch Loss: 0.00016168609727174044\n",
      "Epoch 4792, Loss: 0.0007359799177493187, Final Batch Loss: 1.2176273003206006e-06\n",
      "Epoch 4793, Loss: 0.0006674352978279785, Final Batch Loss: 0.00014617123815696687\n",
      "Epoch 4794, Loss: 0.0002846463203241001, Final Batch Loss: 1.8647506294655614e-06\n",
      "Epoch 4795, Loss: 0.0007203018283234996, Final Batch Loss: 4.0871250348573085e-06\n",
      "Epoch 4796, Loss: 0.0017253619269013143, Final Batch Loss: 2.0435725218703737e-06\n",
      "Epoch 4797, Loss: 0.03332288135243289, Final Batch Loss: 1.0523979653953575e-05\n",
      "Epoch 4798, Loss: 0.007554961455753073, Final Batch Loss: 0.0\n",
      "Epoch 4799, Loss: 0.002235265377464657, Final Batch Loss: 3.06537629057857e-07\n",
      "Epoch 4800, Loss: 0.006459822901888401, Final Batch Loss: 0.0\n",
      "Epoch 4801, Loss: 0.0003476684528962437, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4802, Loss: 0.0006753617490176111, Final Batch Loss: 0.0002351746807107702\n",
      "Epoch 4803, Loss: 0.0005328532970452216, Final Batch Loss: 4.340453233453445e-05\n",
      "Epoch 4804, Loss: 0.0004918856207751787, Final Batch Loss: 2.384181954084852e-07\n",
      "Epoch 4805, Loss: 0.001694404345471412, Final Batch Loss: 0.00076273427112028\n",
      "Epoch 4806, Loss: 0.00017706189919408644, Final Batch Loss: 0.0\n",
      "Epoch 4807, Loss: 0.0004792125616575049, Final Batch Loss: 4.342616364283458e-07\n",
      "Epoch 4808, Loss: 0.0004936444274790119, Final Batch Loss: 1.5667374100303277e-06\n",
      "Epoch 4809, Loss: 0.0028275129627104434, Final Batch Loss: 7.748569146315276e-07\n",
      "Epoch 4810, Loss: 0.0010006471701267117, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4811, Loss: 0.00285427632968549, Final Batch Loss: 5.194100367589272e-07\n",
      "Epoch 4812, Loss: 0.01315993543175864, Final Batch Loss: 1.0899057087954134e-06\n",
      "Epoch 4813, Loss: 0.000453617633866088, Final Batch Loss: 6.0710071920766495e-06\n",
      "Epoch 4814, Loss: 0.0005019650372020124, Final Batch Loss: 1.8732875162186247e-07\n",
      "Epoch 4815, Loss: 0.0007526891458837781, Final Batch Loss: 5.394728577812202e-05\n",
      "Epoch 4816, Loss: 0.0009350856062155799, Final Batch Loss: 0.0002594640536699444\n",
      "Epoch 4817, Loss: 0.001133129382651532, Final Batch Loss: 8.162023004842922e-05\n",
      "Epoch 4818, Loss: 0.0018485880427761003, Final Batch Loss: 0.0\n",
      "Epoch 4819, Loss: 0.00018055241108783093, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4820, Loss: 0.0012994196513318457, Final Batch Loss: 0.00027047330513596535\n",
      "Epoch 4821, Loss: 0.011094660582784854, Final Batch Loss: 0.004330811090767384\n",
      "Epoch 4822, Loss: 0.0001725710303617234, Final Batch Loss: 5.457888164528413e-06\n",
      "Epoch 4823, Loss: 0.0009983883628592594, Final Batch Loss: 0.0007045555976219475\n",
      "Epoch 4824, Loss: 0.0002747984926827485, Final Batch Loss: 0.0001359989691991359\n",
      "Epoch 4825, Loss: 0.00902320526438416, Final Batch Loss: 0.0\n",
      "Epoch 4826, Loss: 0.0004943733254094695, Final Batch Loss: 0.0\n",
      "Epoch 4827, Loss: 0.00017536076708779547, Final Batch Loss: 1.3623909467241901e-07\n",
      "Epoch 4828, Loss: 0.0005883885460207239, Final Batch Loss: 0.00012347919982858002\n",
      "Epoch 4829, Loss: 0.001833768455981044, Final Batch Loss: 0.0009696367778815329\n",
      "Epoch 4830, Loss: 0.003839772036371869, Final Batch Loss: 0.0\n",
      "Epoch 4831, Loss: 0.00028673279406277175, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4832, Loss: 0.0005183203156775562, Final Batch Loss: 0.00027828876045532525\n",
      "Epoch 4833, Loss: 0.0003589447389913403, Final Batch Loss: 6.811956154706422e-08\n",
      "Epoch 4834, Loss: 0.002201496426096128, Final Batch Loss: 0.0\n",
      "Epoch 4835, Loss: 0.0005759837786172284, Final Batch Loss: 0.00019686533778440207\n",
      "Epoch 4836, Loss: 0.0021137578108323396, Final Batch Loss: 9.366415838485409e-07\n",
      "Epoch 4837, Loss: 0.001086316318648528, Final Batch Loss: 1.7881374958506058e-07\n",
      "Epoch 4838, Loss: 0.0003636401816038415, Final Batch Loss: 2.6809679184225388e-05\n",
      "Epoch 4839, Loss: 0.0021631369227606, Final Batch Loss: 2.2138833344342856e-07\n",
      "Epoch 4840, Loss: 0.00024010003744479036, Final Batch Loss: 6.709465196763631e-06\n",
      "Epoch 4841, Loss: 8.300553506046526e-05, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 4842, Loss: 0.004547759027900611, Final Batch Loss: 0.004411827307194471\n",
      "Epoch 4843, Loss: 0.0014621236459788634, Final Batch Loss: 8.412274837610312e-06\n",
      "Epoch 4844, Loss: 0.0002849460543075111, Final Batch Loss: 6.89832741045393e-05\n",
      "Epoch 4845, Loss: 0.0007297911479327013, Final Batch Loss: 0.0\n",
      "Epoch 4846, Loss: 0.0011027859763999004, Final Batch Loss: 0.0\n",
      "Epoch 4847, Loss: 0.0004632333100005326, Final Batch Loss: 4.1723134813764773e-07\n",
      "Epoch 4848, Loss: 0.0008309913391713053, Final Batch Loss: 6.796604429837316e-05\n",
      "Epoch 4849, Loss: 0.00018130060200860498, Final Batch Loss: 3.23567320492657e-07\n",
      "Epoch 4850, Loss: 0.0001494631377170208, Final Batch Loss: 4.427759847658308e-07\n",
      "Epoch 4851, Loss: 0.00021023147201049142, Final Batch Loss: 0.0\n",
      "Epoch 4852, Loss: 0.00022665274423161463, Final Batch Loss: 1.1069348602177342e-06\n",
      "Epoch 4853, Loss: 0.0002394499006186379, Final Batch Loss: 8.055721264099702e-05\n",
      "Epoch 4854, Loss: 0.00020890074014090487, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 4855, Loss: 6.842095172032714e-05, Final Batch Loss: 0.0\n",
      "Epoch 4856, Loss: 0.00038349890337485704, Final Batch Loss: 0.0\n",
      "Epoch 4857, Loss: 0.00026311082638130756, Final Batch Loss: 0.0\n",
      "Epoch 4858, Loss: 0.00019524552794791816, Final Batch Loss: 2.3926606900204206e-06\n",
      "Epoch 4859, Loss: 0.00022456254885128146, Final Batch Loss: 1.8647612023414695e-06\n",
      "Epoch 4860, Loss: 0.00013907903523247, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4861, Loss: 0.0008993447745524463, Final Batch Loss: 0.0\n",
      "Epoch 4862, Loss: 0.0007937911595945479, Final Batch Loss: 0.00012702563253697008\n",
      "Epoch 4863, Loss: 0.00033434977778057373, Final Batch Loss: 4.2574733072342497e-08\n",
      "Epoch 4864, Loss: 0.00021037296843928743, Final Batch Loss: 1.532689282157662e-07\n",
      "Epoch 4865, Loss: 0.0010281058894179296, Final Batch Loss: 0.0\n",
      "Epoch 4866, Loss: 0.00013765629904582966, Final Batch Loss: 7.918865208011994e-07\n",
      "Epoch 4867, Loss: 0.0002715968721531681, Final Batch Loss: 0.0\n",
      "Epoch 4868, Loss: 0.0008133462695241178, Final Batch Loss: 0.000714042573235929\n",
      "Epoch 4869, Loss: 7.000270966273092e-05, Final Batch Loss: 3.0823478027741658e-06\n",
      "Epoch 4870, Loss: 0.0002463872804696621, Final Batch Loss: 2.4693309796930407e-07\n",
      "Epoch 4871, Loss: 0.00014374138033446116, Final Batch Loss: 9.366437581093123e-08\n",
      "Epoch 4872, Loss: 0.0015871650430199225, Final Batch Loss: 3.782198837143369e-05\n",
      "Epoch 4873, Loss: 0.0006165369786685915, Final Batch Loss: 1.04984455902013e-05\n",
      "Epoch 4874, Loss: 0.00020298795243434142, Final Batch Loss: 5.449546733871102e-07\n",
      "Epoch 4875, Loss: 0.002754793050495863, Final Batch Loss: 3.405979143167315e-08\n",
      "Epoch 4876, Loss: 0.00015224869366647908, Final Batch Loss: 0.0\n",
      "Epoch 4877, Loss: 0.0003925334303858108, Final Batch Loss: 3.84015174859087e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4878, Loss: 0.0020691369791165926, Final Batch Loss: 3.984908289567102e-06\n",
      "Epoch 4879, Loss: 0.00046087592590993154, Final Batch Loss: 4.584680937114172e-05\n",
      "Epoch 4880, Loss: 0.0004629367875281787, Final Batch Loss: 5.279252377476951e-07\n",
      "Epoch 4881, Loss: 0.0003969475834022518, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4882, Loss: 2.9648416330019245e-05, Final Batch Loss: 0.0\n",
      "Epoch 4883, Loss: 0.0007770547701966279, Final Batch Loss: 1.94138306142122e-06\n",
      "Epoch 4884, Loss: 0.00011087692610090016, Final Batch Loss: 4.98967028761399e-06\n",
      "Epoch 4885, Loss: 0.00011351335331255541, Final Batch Loss: 8.344601383214467e-07\n",
      "Epoch 4886, Loss: 0.00022571583576791454, Final Batch Loss: 4.276676190784201e-05\n",
      "Epoch 4887, Loss: 0.00029537814348401525, Final Batch Loss: 1.0217932100431426e-07\n",
      "Epoch 4888, Loss: 0.00025418767108931206, Final Batch Loss: 0.0\n",
      "Epoch 4889, Loss: 0.000358556309947744, Final Batch Loss: 0.0\n",
      "Epoch 4890, Loss: 7.968453454409996e-05, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4891, Loss: 5.1181210693584944e-05, Final Batch Loss: 2.1287340246090025e-07\n",
      "Epoch 4892, Loss: 8.830517958813289e-05, Final Batch Loss: 9.707002845971147e-07\n",
      "Epoch 4893, Loss: 0.0008081647465587594, Final Batch Loss: 0.00018327076395507902\n",
      "Epoch 4894, Loss: 7.356205989594855e-05, Final Batch Loss: 2.2138848976283043e-07\n",
      "Epoch 4895, Loss: 0.00625403967484317, Final Batch Loss: 6.726777996846067e-07\n",
      "Epoch 4896, Loss: 0.0034015149549304624, Final Batch Loss: 0.0\n",
      "Epoch 4897, Loss: 0.007561167343389741, Final Batch Loss: 1.1069425198684257e-07\n",
      "Epoch 4898, Loss: 0.0003285730976898549, Final Batch Loss: 1.3623910888327373e-07\n",
      "Epoch 4899, Loss: 6.558371985931899e-05, Final Batch Loss: 1.277241636898907e-07\n",
      "Epoch 4900, Loss: 0.0003484305702841084, Final Batch Loss: 0.0\n",
      "Epoch 4901, Loss: 0.0003283253954577958, Final Batch Loss: 0.0\n",
      "Epoch 4902, Loss: 0.003285321532985108, Final Batch Loss: 5.806959507026477e-06\n",
      "Epoch 4903, Loss: 0.00014139074505692406, Final Batch Loss: 0.0\n",
      "Epoch 4904, Loss: 0.0002546338982938323, Final Batch Loss: 0.0\n",
      "Epoch 4905, Loss: 0.0011464386516308878, Final Batch Loss: 0.0\n",
      "Epoch 4906, Loss: 0.00040309238647751044, Final Batch Loss: 2.5719029508763924e-05\n",
      "Epoch 4907, Loss: 0.00010736798856214591, Final Batch Loss: 2.4693315481272293e-07\n",
      "Epoch 4908, Loss: 0.00024696057386108805, Final Batch Loss: 8.685197485647222e-07\n",
      "Epoch 4909, Loss: 8.37211321140785e-05, Final Batch Loss: 5.364399839891121e-07\n",
      "Epoch 4910, Loss: 0.001656090993037651, Final Batch Loss: 0.0\n",
      "Epoch 4911, Loss: 0.00016818109050831254, Final Batch Loss: 9.366439002178595e-08\n",
      "Epoch 4912, Loss: 0.00016763215223214445, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4913, Loss: 0.00014090858212512103, Final Batch Loss: 0.0\n",
      "Epoch 4914, Loss: 0.0005430760430797932, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4915, Loss: 0.0002917152489203545, Final Batch Loss: 8.004009828255221e-07\n",
      "Epoch 4916, Loss: 0.0007664712414712227, Final Batch Loss: 2.554484446193328e-08\n",
      "Epoch 4917, Loss: 0.000199745432837517, Final Batch Loss: 0.00013093085726723075\n",
      "Epoch 4918, Loss: 0.0005545227445509227, Final Batch Loss: 6.811942512285896e-07\n",
      "Epoch 4919, Loss: 0.0001290619292149131, Final Batch Loss: 1.2091167036487604e-06\n",
      "Epoch 4920, Loss: 0.00010363918956102225, Final Batch Loss: 1.6178388762000395e-07\n",
      "Epoch 4921, Loss: 9.286241834161046e-05, Final Batch Loss: 1.6348515146091813e-06\n",
      "Epoch 4922, Loss: 0.0001679701535977074, Final Batch Loss: 1.140994754678104e-06\n",
      "Epoch 4923, Loss: 0.0038626944156661125, Final Batch Loss: 1.7029897492193413e-08\n",
      "Epoch 4924, Loss: 0.0017494090670879814, Final Batch Loss: 0.001677999971434474\n",
      "Epoch 4925, Loss: 9.887174394407339e-05, Final Batch Loss: 1.0984200571328984e-06\n",
      "Epoch 4926, Loss: 7.276285475654731e-05, Final Batch Loss: 6.89680337018217e-06\n",
      "Epoch 4927, Loss: 0.0006718926493416433, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4928, Loss: 0.000346558570072375, Final Batch Loss: 7.186255515989615e-06\n",
      "Epoch 4929, Loss: 0.0005651165236031375, Final Batch Loss: 1.8653878214536235e-05\n",
      "Epoch 4930, Loss: 0.00010608375282572524, Final Batch Loss: 2.3415739178744843e-06\n",
      "Epoch 4931, Loss: 4.895754591416335e-05, Final Batch Loss: 1.785371932783164e-05\n",
      "Epoch 4932, Loss: 0.000596897433620569, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4933, Loss: 5.64144318389026e-05, Final Batch Loss: 0.0\n",
      "Epoch 4934, Loss: 0.00039434180871467106, Final Batch Loss: 0.0\n",
      "Epoch 4935, Loss: 0.00030932014124118723, Final Batch Loss: 0.00011256048310315236\n",
      "Epoch 4936, Loss: 6.0012075685733635e-05, Final Batch Loss: 7.663449963501989e-08\n",
      "Epoch 4937, Loss: 0.00012779684834640648, Final Batch Loss: 4.349815208115615e-05\n",
      "Epoch 4938, Loss: 0.00013533693241285505, Final Batch Loss: 2.554484623829012e-08\n",
      "Epoch 4939, Loss: 0.00016526546983186563, Final Batch Loss: 0.0\n",
      "Epoch 4940, Loss: 0.0009832466012085206, Final Batch Loss: 9.553455129207578e-06\n",
      "Epoch 4941, Loss: 0.0002525171015790306, Final Batch Loss: 1.192091971802256e-07\n",
      "Epoch 4942, Loss: 8.182883448171197e-05, Final Batch Loss: 0.0\n",
      "Epoch 4943, Loss: 0.00021434645453410894, Final Batch Loss: 1.1069426619769729e-07\n",
      "Epoch 4944, Loss: 2.936249939011759e-05, Final Batch Loss: 0.0\n",
      "Epoch 4945, Loss: 0.0006294984375472268, Final Batch Loss: 2.7077023787569487e-06\n",
      "Epoch 4946, Loss: 0.0004340089442393946, Final Batch Loss: 1.0899055951085757e-06\n",
      "Epoch 4947, Loss: 0.0020803721617994597, Final Batch Loss: 3.581377677619457e-05\n",
      "Epoch 4948, Loss: 0.00012795832367373805, Final Batch Loss: 5.057703674538061e-06\n",
      "Epoch 4949, Loss: 0.000610794475505827, Final Batch Loss: 2.164226862078067e-05\n",
      "Epoch 4950, Loss: 0.006259234594836016, Final Batch Loss: 0.0015052182134240866\n",
      "Epoch 4951, Loss: 0.00013663666993579682, Final Batch Loss: 1.5240143511618953e-05\n",
      "Epoch 4952, Loss: 3.64424095096183e-05, Final Batch Loss: 0.0\n",
      "Epoch 4953, Loss: 0.0006074688035369036, Final Batch Loss: 3.984939667134313e-06\n",
      "Epoch 4954, Loss: 0.00012125820235908691, Final Batch Loss: 5.108968892386656e-08\n",
      "Epoch 4955, Loss: 0.00037803852399065363, Final Batch Loss: 5.279251809042762e-07\n",
      "Epoch 4956, Loss: 2.9144951326998125e-05, Final Batch Loss: 0.0\n",
      "Epoch 4957, Loss: 0.0011144389430093327, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4958, Loss: 7.976057180059115e-05, Final Batch Loss: 3.405978787895947e-08\n",
      "Epoch 4959, Loss: 8.283129068331618e-05, Final Batch Loss: 4.410615929373307e-06\n",
      "Epoch 4960, Loss: 1.9787288692896254e-05, Final Batch Loss: 2.4267396838695277e-06\n",
      "Epoch 4961, Loss: 0.013053323954636653, Final Batch Loss: 0.0012584071373566985\n",
      "Epoch 4962, Loss: 0.0005136633817528491, Final Batch Loss: 0.0\n",
      "Epoch 4963, Loss: 9.936886247174925e-06, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4964, Loss: 0.0002588569150248077, Final Batch Loss: 1.1306963642709889e-05\n",
      "Epoch 4965, Loss: 0.0018257017584666357, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4966, Loss: 0.0007737986561551224, Final Batch Loss: 1.123964466387406e-06\n",
      "Epoch 4967, Loss: 0.0001415598310678945, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4968, Loss: 0.00038829810819152044, Final Batch Loss: 0.0\n",
      "Epoch 4969, Loss: 0.0009407043992837316, Final Batch Loss: 8.514945193383028e-08\n",
      "Epoch 4970, Loss: 0.0002379262614340405, Final Batch Loss: 3.5288045182824135e-05\n",
      "Epoch 4971, Loss: 0.00023059106311507094, Final Batch Loss: 2.6396301677777956e-07\n",
      "Epoch 4972, Loss: 0.0003989841973179864, Final Batch Loss: 0.00014653665130026639\n",
      "Epoch 4973, Loss: 0.00011380144781014678, Final Batch Loss: 1.8647534716365044e-06\n",
      "Epoch 4974, Loss: 0.00014199410435900006, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4975, Loss: 0.00012202703287300665, Final Batch Loss: 7.663452095130197e-08\n",
      "Epoch 4976, Loss: 0.00011693464318796032, Final Batch Loss: 1.277231262974965e-06\n",
      "Epoch 4977, Loss: 5.454178847230651e-05, Final Batch Loss: 1.7455469105698285e-06\n",
      "Epoch 4978, Loss: 0.00044453250848164316, Final Batch Loss: 1.0762085366877727e-05\n",
      "Epoch 4979, Loss: 0.0004985399810433222, Final Batch Loss: 1.7029895715836574e-08\n",
      "Epoch 4980, Loss: 0.00010896841240537469, Final Batch Loss: 4.291443019610597e-06\n",
      "Epoch 4981, Loss: 0.00026916536307908245, Final Batch Loss: 7.868729153415188e-05\n",
      "Epoch 4982, Loss: 0.000148162877650293, Final Batch Loss: 1.4475406828751147e-07\n",
      "Epoch 4983, Loss: 0.0006195650439444478, Final Batch Loss: 5.960462701182223e-08\n",
      "Epoch 4984, Loss: 0.00021936941720923642, Final Batch Loss: 0.0\n",
      "Epoch 4985, Loss: 7.890272380350893e-05, Final Batch Loss: 8.514948746096707e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4986, Loss: 0.0008122180170175852, Final Batch Loss: 0.0\n",
      "Epoch 4987, Loss: 0.0002473952226154097, Final Batch Loss: 1.958436968152455e-07\n",
      "Epoch 4988, Loss: 6.0882962088726345e-05, Final Batch Loss: 8.378317033930216e-06\n",
      "Epoch 4989, Loss: 0.00011861469943141856, Final Batch Loss: 4.8246438382193446e-05\n",
      "Epoch 4990, Loss: 0.0001354316455604021, Final Batch Loss: 3.9168668308775523e-07\n",
      "Epoch 4991, Loss: 0.00017778685810299066, Final Batch Loss: 0.0\n",
      "Epoch 4992, Loss: 0.00011212685152273139, Final Batch Loss: 8.514948746096707e-09\n",
      "Epoch 4993, Loss: 0.00011057917834023101, Final Batch Loss: 1.2346584981060005e-06\n",
      "Epoch 4994, Loss: 0.00019326698156874045, Final Batch Loss: 0.0\n",
      "Epoch 4995, Loss: 0.00010362007628827996, Final Batch Loss: 1.1026023457816336e-05\n",
      "Epoch 4996, Loss: 0.00030730073016727033, Final Batch Loss: 4.2574736625056175e-08\n",
      "Epoch 4997, Loss: 0.0003026049726031488, Final Batch Loss: 0.000104920742160175\n",
      "Epoch 4998, Loss: 0.00020376707084324153, Final Batch Loss: 0.00017852545715868473\n",
      "Epoch 4999, Loss: 7.145129984564846e-05, Final Batch Loss: 9.842609870247543e-06\n",
      "Epoch 5000, Loss: 0.001831650756230374, Final Batch Loss: 9.553188647259958e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107   1   1]\n",
      " [  3  64   0]\n",
      " [  0   0  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97273   0.98165   0.97717       109\n",
      "           1    0.98462   0.95522   0.96970        67\n",
      "           2    0.98734   1.00000   0.99363        78\n",
      "\n",
      "    accuracy                        0.98031       254\n",
      "   macro avg    0.98156   0.97896   0.98017       254\n",
      "weighted avg    0.98035   0.98031   0.98025       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U7A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 8)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_13 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_14 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_15 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U7A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_16 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 8)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_17 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_18 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_19 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_20 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_21 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_22 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_23 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U7A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_24 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 8) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12,\n",
    "                               fake_features_13, fake_features_14, fake_features_15, fake_features_16, fake_features_17, fake_features_18,\n",
    "                               fake_features_19, fake_features_20, fake_features_21, fake_features_22, fake_features_23, fake_features_24))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79  1  0]\n",
      " [ 1 79  0]\n",
      " [ 0  0 80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.98750   0.98750   0.98750        80\n",
      "         1.0    0.98750   0.98750   0.98750        80\n",
      "         2.0    1.00000   1.00000   1.00000        80\n",
      "\n",
      "    accuracy                        0.99167       240\n",
      "   macro avg    0.99167   0.99167   0.99167       240\n",
      "weighted avg    0.99167   0.99167   0.99167       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14, 17]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 4\n",
    "    elif y[k] == 11:\n",
    "        y[k] = 5\n",
    "    elif y[k] == 14:\n",
    "        y[k] = 6\n",
    "    else:\n",
    "        y[k] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 10.497875928878784, Final Batch Loss: 2.151634454727173\n",
      "Epoch 2, Loss: 10.444031953811646, Final Batch Loss: 2.102100372314453\n",
      "Epoch 3, Loss: 10.398757457733154, Final Batch Loss: 2.053673505783081\n",
      "Epoch 4, Loss: 10.360309600830078, Final Batch Loss: 2.018404722213745\n",
      "Epoch 5, Loss: 10.493115425109863, Final Batch Loss: 2.1646058559417725\n",
      "Epoch 6, Loss: 10.362724781036377, Final Batch Loss: 2.031015396118164\n",
      "Epoch 7, Loss: 10.413798809051514, Final Batch Loss: 2.0940566062927246\n",
      "Epoch 8, Loss: 10.35026216506958, Final Batch Loss: 2.0322203636169434\n",
      "Epoch 9, Loss: 10.290056109428406, Final Batch Loss: 1.980535626411438\n",
      "Epoch 10, Loss: 10.381834745407104, Final Batch Loss: 2.0816633701324463\n",
      "Epoch 11, Loss: 10.40854549407959, Final Batch Loss: 2.1174509525299072\n",
      "Epoch 12, Loss: 10.401481628417969, Final Batch Loss: 2.1154308319091797\n",
      "Epoch 13, Loss: 10.350509643554688, Final Batch Loss: 2.066988468170166\n",
      "Epoch 14, Loss: 10.33307433128357, Final Batch Loss: 2.069495439529419\n",
      "Epoch 15, Loss: 10.301460027694702, Final Batch Loss: 2.0509133338928223\n",
      "Epoch 16, Loss: 10.219354629516602, Final Batch Loss: 1.9838035106658936\n",
      "Epoch 17, Loss: 10.19834554195404, Final Batch Loss: 1.9819248914718628\n",
      "Epoch 18, Loss: 10.212260723114014, Final Batch Loss: 2.021742582321167\n",
      "Epoch 19, Loss: 10.175559043884277, Final Batch Loss: 2.011404514312744\n",
      "Epoch 20, Loss: 10.203375577926636, Final Batch Loss: 2.0903725624084473\n",
      "Epoch 21, Loss: 9.953136920928955, Final Batch Loss: 1.8905375003814697\n",
      "Epoch 22, Loss: 10.046622395515442, Final Batch Loss: 2.034278154373169\n",
      "Epoch 23, Loss: 9.950629949569702, Final Batch Loss: 2.006234645843506\n",
      "Epoch 24, Loss: 9.812174558639526, Final Batch Loss: 1.925033688545227\n",
      "Epoch 25, Loss: 9.664031267166138, Final Batch Loss: 1.883377194404602\n",
      "Epoch 26, Loss: 9.531125545501709, Final Batch Loss: 1.8272885084152222\n",
      "Epoch 27, Loss: 9.584502100944519, Final Batch Loss: 1.9639500379562378\n",
      "Epoch 28, Loss: 9.46108865737915, Final Batch Loss: 1.9156701564788818\n",
      "Epoch 29, Loss: 9.467189311981201, Final Batch Loss: 1.988312005996704\n",
      "Epoch 30, Loss: 9.069794178009033, Final Batch Loss: 1.7430322170257568\n",
      "Epoch 31, Loss: 8.72870671749115, Final Batch Loss: 1.4973174333572388\n",
      "Epoch 32, Loss: 9.155656576156616, Final Batch Loss: 2.0109336376190186\n",
      "Epoch 33, Loss: 8.649388670921326, Final Batch Loss: 1.6168321371078491\n",
      "Epoch 34, Loss: 8.538899779319763, Final Batch Loss: 1.6000996828079224\n",
      "Epoch 35, Loss: 8.656699657440186, Final Batch Loss: 1.769569993019104\n",
      "Epoch 36, Loss: 8.526558518409729, Final Batch Loss: 1.7599284648895264\n",
      "Epoch 37, Loss: 8.460961103439331, Final Batch Loss: 1.7526748180389404\n",
      "Epoch 38, Loss: 8.276859045028687, Final Batch Loss: 1.616013765335083\n",
      "Epoch 39, Loss: 8.499608159065247, Final Batch Loss: 1.8874075412750244\n",
      "Epoch 40, Loss: 8.426431775093079, Final Batch Loss: 1.8917992115020752\n",
      "Epoch 41, Loss: 8.46530830860138, Final Batch Loss: 2.061763286590576\n",
      "Epoch 42, Loss: 7.967969179153442, Final Batch Loss: 1.6156054735183716\n",
      "Epoch 43, Loss: 8.21475887298584, Final Batch Loss: 1.8179537057876587\n",
      "Epoch 44, Loss: 7.817363619804382, Final Batch Loss: 1.4269706010818481\n",
      "Epoch 45, Loss: 7.772496581077576, Final Batch Loss: 1.4818427562713623\n",
      "Epoch 46, Loss: 7.7271260023117065, Final Batch Loss: 1.4502532482147217\n",
      "Epoch 47, Loss: 7.906170845031738, Final Batch Loss: 1.733641505241394\n",
      "Epoch 48, Loss: 7.1083768010139465, Final Batch Loss: 0.9123850464820862\n",
      "Epoch 49, Loss: 7.87214195728302, Final Batch Loss: 1.707733154296875\n",
      "Epoch 50, Loss: 7.822851777076721, Final Batch Loss: 1.7234467267990112\n",
      "Epoch 51, Loss: 7.611385703086853, Final Batch Loss: 1.5533628463745117\n",
      "Epoch 52, Loss: 8.015643954277039, Final Batch Loss: 1.953426480293274\n",
      "Epoch 53, Loss: 7.5463632345199585, Final Batch Loss: 1.5573171377182007\n",
      "Epoch 54, Loss: 7.700423240661621, Final Batch Loss: 1.6308870315551758\n",
      "Epoch 55, Loss: 7.678617477416992, Final Batch Loss: 1.6612179279327393\n",
      "Epoch 56, Loss: 7.382089614868164, Final Batch Loss: 1.4105826616287231\n",
      "Epoch 57, Loss: 7.403681397438049, Final Batch Loss: 1.4937808513641357\n",
      "Epoch 58, Loss: 7.564937233924866, Final Batch Loss: 1.6290651559829712\n",
      "Epoch 59, Loss: 7.20960795879364, Final Batch Loss: 1.4068020582199097\n",
      "Epoch 60, Loss: 7.484771013259888, Final Batch Loss: 1.6386940479278564\n",
      "Epoch 61, Loss: 7.46377420425415, Final Batch Loss: 1.7034348249435425\n",
      "Epoch 62, Loss: 7.433448791503906, Final Batch Loss: 1.6931781768798828\n",
      "Epoch 63, Loss: 7.186607837677002, Final Batch Loss: 1.4227007627487183\n",
      "Epoch 64, Loss: 7.25935435295105, Final Batch Loss: 1.5443922281265259\n",
      "Epoch 65, Loss: 7.036030888557434, Final Batch Loss: 1.2773798704147339\n",
      "Epoch 66, Loss: 6.434948146343231, Final Batch Loss: 0.8702892661094666\n",
      "Epoch 67, Loss: 6.895544767379761, Final Batch Loss: 1.2231788635253906\n",
      "Epoch 68, Loss: 7.177189826965332, Final Batch Loss: 1.6238356828689575\n",
      "Epoch 69, Loss: 7.43958044052124, Final Batch Loss: 1.8101606369018555\n",
      "Epoch 70, Loss: 6.735073089599609, Final Batch Loss: 1.0831631422042847\n",
      "Epoch 71, Loss: 7.147384405136108, Final Batch Loss: 1.4852956533432007\n",
      "Epoch 72, Loss: 7.102783441543579, Final Batch Loss: 1.509137511253357\n",
      "Epoch 73, Loss: 6.894587159156799, Final Batch Loss: 1.353346586227417\n",
      "Epoch 74, Loss: 7.16889750957489, Final Batch Loss: 1.655135154724121\n",
      "Epoch 75, Loss: 6.887404203414917, Final Batch Loss: 1.3795994520187378\n",
      "Epoch 76, Loss: 6.7913578748703, Final Batch Loss: 1.2313716411590576\n",
      "Epoch 77, Loss: 6.762624025344849, Final Batch Loss: 1.2456105947494507\n",
      "Epoch 78, Loss: 7.112939953804016, Final Batch Loss: 1.5965850353240967\n",
      "Epoch 79, Loss: 6.657036781311035, Final Batch Loss: 1.1699550151824951\n",
      "Epoch 80, Loss: 6.474404692649841, Final Batch Loss: 1.0577424764633179\n",
      "Epoch 81, Loss: 6.525687336921692, Final Batch Loss: 1.1000614166259766\n",
      "Epoch 82, Loss: 6.831185340881348, Final Batch Loss: 1.4502136707305908\n",
      "Epoch 83, Loss: 6.535701155662537, Final Batch Loss: 1.2250213623046875\n",
      "Epoch 84, Loss: 6.748611688613892, Final Batch Loss: 1.380825400352478\n",
      "Epoch 85, Loss: 6.600218296051025, Final Batch Loss: 1.2898706197738647\n",
      "Epoch 86, Loss: 6.715333819389343, Final Batch Loss: 1.2673066854476929\n",
      "Epoch 87, Loss: 6.946746230125427, Final Batch Loss: 1.6269350051879883\n",
      "Epoch 88, Loss: 6.655306458473206, Final Batch Loss: 1.4467042684555054\n",
      "Epoch 89, Loss: 6.312124133110046, Final Batch Loss: 1.060314416885376\n",
      "Epoch 90, Loss: 6.672158122062683, Final Batch Loss: 1.5057162046432495\n",
      "Epoch 91, Loss: 6.881366968154907, Final Batch Loss: 1.685852289199829\n",
      "Epoch 92, Loss: 6.711043953895569, Final Batch Loss: 1.3610261678695679\n",
      "Epoch 93, Loss: 6.442000508308411, Final Batch Loss: 1.2561002969741821\n",
      "Epoch 94, Loss: 6.599918007850647, Final Batch Loss: 1.3919261693954468\n",
      "Epoch 95, Loss: 6.654631853103638, Final Batch Loss: 1.4509029388427734\n",
      "Epoch 96, Loss: 6.118120729923248, Final Batch Loss: 0.9737181067466736\n",
      "Epoch 97, Loss: 7.075221419334412, Final Batch Loss: 1.8511568307876587\n",
      "Epoch 98, Loss: 6.30301821231842, Final Batch Loss: 1.2394940853118896\n",
      "Epoch 99, Loss: 6.491039514541626, Final Batch Loss: 1.2821009159088135\n",
      "Epoch 100, Loss: 6.239145636558533, Final Batch Loss: 1.110307216644287\n",
      "Epoch 101, Loss: 6.001931071281433, Final Batch Loss: 0.958678126335144\n",
      "Epoch 102, Loss: 6.33905565738678, Final Batch Loss: 1.2000752687454224\n",
      "Epoch 103, Loss: 6.216202974319458, Final Batch Loss: 1.0482356548309326\n",
      "Epoch 104, Loss: 6.898528575897217, Final Batch Loss: 1.8437258005142212\n",
      "Epoch 105, Loss: 5.972623109817505, Final Batch Loss: 0.9546709060668945\n",
      "Epoch 106, Loss: 6.126020431518555, Final Batch Loss: 1.0575448274612427\n",
      "Epoch 107, Loss: 6.322506904602051, Final Batch Loss: 1.3022321462631226\n",
      "Epoch 108, Loss: 6.650900602340698, Final Batch Loss: 1.5866326093673706\n",
      "Epoch 109, Loss: 6.483623147010803, Final Batch Loss: 1.4798319339752197\n",
      "Epoch 110, Loss: 6.3287330865859985, Final Batch Loss: 1.3231829404830933\n",
      "Epoch 111, Loss: 6.254693388938904, Final Batch Loss: 1.1709429025650024\n",
      "Epoch 112, Loss: 6.710133671760559, Final Batch Loss: 1.597840428352356\n",
      "Epoch 113, Loss: 6.431358098983765, Final Batch Loss: 1.4361531734466553\n",
      "Epoch 114, Loss: 6.505521297454834, Final Batch Loss: 1.5487056970596313\n",
      "Epoch 115, Loss: 6.300875186920166, Final Batch Loss: 1.2623510360717773\n",
      "Epoch 116, Loss: 6.37152361869812, Final Batch Loss: 1.357716679573059\n",
      "Epoch 117, Loss: 6.314564347267151, Final Batch Loss: 1.4424552917480469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118, Loss: 6.037548899650574, Final Batch Loss: 1.139056921005249\n",
      "Epoch 119, Loss: 5.850765287876129, Final Batch Loss: 0.8910685181617737\n",
      "Epoch 120, Loss: 6.451813340187073, Final Batch Loss: 1.537274718284607\n",
      "Epoch 121, Loss: 6.0109909772872925, Final Batch Loss: 1.166136384010315\n",
      "Epoch 122, Loss: 6.280048966407776, Final Batch Loss: 1.432930588722229\n",
      "Epoch 123, Loss: 6.357967257499695, Final Batch Loss: 1.4379140138626099\n",
      "Epoch 124, Loss: 5.877367734909058, Final Batch Loss: 1.0233819484710693\n",
      "Epoch 125, Loss: 5.914841055870056, Final Batch Loss: 1.0986961126327515\n",
      "Epoch 126, Loss: 6.320856928825378, Final Batch Loss: 1.2924762964248657\n",
      "Epoch 127, Loss: 6.072306990623474, Final Batch Loss: 1.2312699556350708\n",
      "Epoch 128, Loss: 6.187567234039307, Final Batch Loss: 1.3317811489105225\n",
      "Epoch 129, Loss: 5.9934927225112915, Final Batch Loss: 1.1811354160308838\n",
      "Epoch 130, Loss: 5.787873268127441, Final Batch Loss: 0.8769019842147827\n",
      "Epoch 131, Loss: 5.863902926445007, Final Batch Loss: 1.0813478231430054\n",
      "Epoch 132, Loss: 5.898358702659607, Final Batch Loss: 1.042352318763733\n",
      "Epoch 133, Loss: 6.120527148246765, Final Batch Loss: 1.2126432657241821\n",
      "Epoch 134, Loss: 5.817925214767456, Final Batch Loss: 1.0690383911132812\n",
      "Epoch 135, Loss: 5.652955234050751, Final Batch Loss: 0.9117562174797058\n",
      "Epoch 136, Loss: 5.991376519203186, Final Batch Loss: 1.2461813688278198\n",
      "Epoch 137, Loss: 5.766280114650726, Final Batch Loss: 0.9621025919914246\n",
      "Epoch 138, Loss: 6.005194544792175, Final Batch Loss: 1.1570016145706177\n",
      "Epoch 139, Loss: 5.795047640800476, Final Batch Loss: 1.0434576272964478\n",
      "Epoch 140, Loss: 5.704085409641266, Final Batch Loss: 0.9392766356468201\n",
      "Epoch 141, Loss: 5.9941264390945435, Final Batch Loss: 1.2958613634109497\n",
      "Epoch 142, Loss: 5.774222016334534, Final Batch Loss: 1.051084041595459\n",
      "Epoch 143, Loss: 6.165198087692261, Final Batch Loss: 1.487227439880371\n",
      "Epoch 144, Loss: 5.5374215841293335, Final Batch Loss: 0.8044748306274414\n",
      "Epoch 145, Loss: 6.040985345840454, Final Batch Loss: 1.3769575357437134\n",
      "Epoch 146, Loss: 5.908114194869995, Final Batch Loss: 1.012423038482666\n",
      "Epoch 147, Loss: 5.934286594390869, Final Batch Loss: 1.1994556188583374\n",
      "Epoch 148, Loss: 5.556296408176422, Final Batch Loss: 0.9724289774894714\n",
      "Epoch 149, Loss: 6.1211230754852295, Final Batch Loss: 1.5011320114135742\n",
      "Epoch 150, Loss: 5.863233327865601, Final Batch Loss: 1.2940179109573364\n",
      "Epoch 151, Loss: 5.932826995849609, Final Batch Loss: 1.2292072772979736\n",
      "Epoch 152, Loss: 5.7399210929870605, Final Batch Loss: 1.0676394701004028\n",
      "Epoch 153, Loss: 5.849324107170105, Final Batch Loss: 1.1282671689987183\n",
      "Epoch 154, Loss: 5.910867929458618, Final Batch Loss: 1.329803228378296\n",
      "Epoch 155, Loss: 5.5814719796180725, Final Batch Loss: 0.9100390076637268\n",
      "Epoch 156, Loss: 5.9030574560165405, Final Batch Loss: 1.2231537103652954\n",
      "Epoch 157, Loss: 5.863215923309326, Final Batch Loss: 1.212542176246643\n",
      "Epoch 158, Loss: 6.0132129192352295, Final Batch Loss: 1.4283075332641602\n",
      "Epoch 159, Loss: 5.784100532531738, Final Batch Loss: 1.10843026638031\n",
      "Epoch 160, Loss: 6.059937834739685, Final Batch Loss: 1.3800264596939087\n",
      "Epoch 161, Loss: 5.798019289970398, Final Batch Loss: 1.1750906705856323\n",
      "Epoch 162, Loss: 6.009004354476929, Final Batch Loss: 1.4273672103881836\n",
      "Epoch 163, Loss: 5.849429488182068, Final Batch Loss: 1.0629112720489502\n",
      "Epoch 164, Loss: 5.910425543785095, Final Batch Loss: 1.283306360244751\n",
      "Epoch 165, Loss: 5.534312963485718, Final Batch Loss: 1.0150991678237915\n",
      "Epoch 166, Loss: 5.993993163108826, Final Batch Loss: 1.3616056442260742\n",
      "Epoch 167, Loss: 5.78502357006073, Final Batch Loss: 1.2945524454116821\n",
      "Epoch 168, Loss: 5.622855722904205, Final Batch Loss: 0.9512785077095032\n",
      "Epoch 169, Loss: 5.745986580848694, Final Batch Loss: 1.2357631921768188\n",
      "Epoch 170, Loss: 5.361170291900635, Final Batch Loss: 0.8136429786682129\n",
      "Epoch 171, Loss: 5.909873366355896, Final Batch Loss: 1.3192930221557617\n",
      "Epoch 172, Loss: 5.21870344877243, Final Batch Loss: 0.7154451012611389\n",
      "Epoch 173, Loss: 5.764453768730164, Final Batch Loss: 1.2241601943969727\n",
      "Epoch 174, Loss: 5.342923820018768, Final Batch Loss: 0.902052104473114\n",
      "Epoch 175, Loss: 5.781435608863831, Final Batch Loss: 1.2868163585662842\n",
      "Epoch 176, Loss: 5.514059901237488, Final Batch Loss: 1.0385278463363647\n",
      "Epoch 177, Loss: 5.7822723388671875, Final Batch Loss: 1.31088387966156\n",
      "Epoch 178, Loss: 5.736453056335449, Final Batch Loss: 1.2738406658172607\n",
      "Epoch 179, Loss: 5.599175214767456, Final Batch Loss: 1.0729424953460693\n",
      "Epoch 180, Loss: 5.741555213928223, Final Batch Loss: 1.2346080541610718\n",
      "Epoch 181, Loss: 5.494628667831421, Final Batch Loss: 1.0679891109466553\n",
      "Epoch 182, Loss: 6.093631863594055, Final Batch Loss: 1.6322301626205444\n",
      "Epoch 183, Loss: 5.525304436683655, Final Batch Loss: 1.0560258626937866\n",
      "Epoch 184, Loss: 5.573142647743225, Final Batch Loss: 1.1110681295394897\n",
      "Epoch 185, Loss: 5.282068252563477, Final Batch Loss: 0.8084850311279297\n",
      "Epoch 186, Loss: 5.445174336433411, Final Batch Loss: 1.0250602960586548\n",
      "Epoch 187, Loss: 5.311929881572723, Final Batch Loss: 0.8648225665092468\n",
      "Epoch 188, Loss: 5.565420389175415, Final Batch Loss: 1.0686700344085693\n",
      "Epoch 189, Loss: 5.43275910615921, Final Batch Loss: 0.993503987789154\n",
      "Epoch 190, Loss: 5.417139232158661, Final Batch Loss: 0.9316466450691223\n",
      "Epoch 191, Loss: 5.673207402229309, Final Batch Loss: 1.273874044418335\n",
      "Epoch 192, Loss: 5.210014164447784, Final Batch Loss: 0.8289435505867004\n",
      "Epoch 193, Loss: 5.3473705649375916, Final Batch Loss: 0.98438960313797\n",
      "Epoch 194, Loss: 5.341919004917145, Final Batch Loss: 0.9390464425086975\n",
      "Epoch 195, Loss: 5.379658401012421, Final Batch Loss: 0.9008137583732605\n",
      "Epoch 196, Loss: 5.381485819816589, Final Batch Loss: 0.9113894701004028\n",
      "Epoch 197, Loss: 5.87981903553009, Final Batch Loss: 1.3897672891616821\n",
      "Epoch 198, Loss: 5.230960547924042, Final Batch Loss: 0.8404017686843872\n",
      "Epoch 199, Loss: 5.5016703605651855, Final Batch Loss: 1.0253777503967285\n",
      "Epoch 200, Loss: 5.458601951599121, Final Batch Loss: 1.0856621265411377\n",
      "Epoch 201, Loss: 5.635552644729614, Final Batch Loss: 1.2923476696014404\n",
      "Epoch 202, Loss: 5.062688648700714, Final Batch Loss: 0.847907543182373\n",
      "Epoch 203, Loss: 5.546671628952026, Final Batch Loss: 1.219590187072754\n",
      "Epoch 204, Loss: 5.317159652709961, Final Batch Loss: 1.0000451803207397\n",
      "Epoch 205, Loss: 5.453739643096924, Final Batch Loss: 1.1447418928146362\n",
      "Epoch 206, Loss: 5.493837833404541, Final Batch Loss: 1.1247819662094116\n",
      "Epoch 207, Loss: 5.6385990381240845, Final Batch Loss: 1.3415148258209229\n",
      "Epoch 208, Loss: 5.775249004364014, Final Batch Loss: 1.3378099203109741\n",
      "Epoch 209, Loss: 5.819417238235474, Final Batch Loss: 1.443232536315918\n",
      "Epoch 210, Loss: 5.077936887741089, Final Batch Loss: 0.7630558013916016\n",
      "Epoch 211, Loss: 5.585683226585388, Final Batch Loss: 1.2750431299209595\n",
      "Epoch 212, Loss: 5.611145853996277, Final Batch Loss: 1.2693407535552979\n",
      "Epoch 213, Loss: 5.291472673416138, Final Batch Loss: 0.9726186990737915\n",
      "Epoch 214, Loss: 5.570446610450745, Final Batch Loss: 1.3069885969161987\n",
      "Epoch 215, Loss: 5.598738431930542, Final Batch Loss: 1.2272754907608032\n",
      "Epoch 216, Loss: 5.376664876937866, Final Batch Loss: 1.0627026557922363\n",
      "Epoch 217, Loss: 5.035614013671875, Final Batch Loss: 0.8081501126289368\n",
      "Epoch 218, Loss: 5.109784543514252, Final Batch Loss: 0.8247758746147156\n",
      "Epoch 219, Loss: 4.993335783481598, Final Batch Loss: 0.8166424632072449\n",
      "Epoch 220, Loss: 5.600806713104248, Final Batch Loss: 1.1970348358154297\n",
      "Epoch 221, Loss: 5.403578996658325, Final Batch Loss: 1.1425672769546509\n",
      "Epoch 222, Loss: 5.334981620311737, Final Batch Loss: 0.9778834581375122\n",
      "Epoch 223, Loss: 5.584240555763245, Final Batch Loss: 1.3165562152862549\n",
      "Epoch 224, Loss: 5.058202803134918, Final Batch Loss: 0.7214459776878357\n",
      "Epoch 225, Loss: 5.055334508419037, Final Batch Loss: 0.8384210467338562\n",
      "Epoch 226, Loss: 5.355643391609192, Final Batch Loss: 1.0483944416046143\n",
      "Epoch 227, Loss: 5.294529616832733, Final Batch Loss: 1.1058763265609741\n",
      "Epoch 228, Loss: 5.248907029628754, Final Batch Loss: 1.0065056085586548\n",
      "Epoch 229, Loss: 5.01405668258667, Final Batch Loss: 0.873467743396759\n",
      "Epoch 230, Loss: 5.00499951839447, Final Batch Loss: 0.8914756178855896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231, Loss: 4.95263808965683, Final Batch Loss: 0.6909805536270142\n",
      "Epoch 232, Loss: 5.0870720744133, Final Batch Loss: 0.9339126348495483\n",
      "Epoch 233, Loss: 5.1680238246917725, Final Batch Loss: 1.016680121421814\n",
      "Epoch 234, Loss: 4.965211868286133, Final Batch Loss: 0.8067859411239624\n",
      "Epoch 235, Loss: 5.070777535438538, Final Batch Loss: 0.9189243316650391\n",
      "Epoch 236, Loss: 4.91791957616806, Final Batch Loss: 0.7419517636299133\n",
      "Epoch 237, Loss: 4.975676774978638, Final Batch Loss: 0.7797425985336304\n",
      "Epoch 238, Loss: 5.126753985881805, Final Batch Loss: 0.9463316798210144\n",
      "Epoch 239, Loss: 5.179276823997498, Final Batch Loss: 1.0266671180725098\n",
      "Epoch 240, Loss: 5.33447802066803, Final Batch Loss: 1.197731375694275\n",
      "Epoch 241, Loss: 5.0882232785224915, Final Batch Loss: 1.0491443872451782\n",
      "Epoch 242, Loss: 5.063775897026062, Final Batch Loss: 0.963245689868927\n",
      "Epoch 243, Loss: 5.425624847412109, Final Batch Loss: 1.0650780200958252\n",
      "Epoch 244, Loss: 5.217303931713104, Final Batch Loss: 1.0957061052322388\n",
      "Epoch 245, Loss: 5.172256290912628, Final Batch Loss: 1.0989660024642944\n",
      "Epoch 246, Loss: 5.26838755607605, Final Batch Loss: 1.089986801147461\n",
      "Epoch 247, Loss: 5.461386799812317, Final Batch Loss: 1.3395367860794067\n",
      "Epoch 248, Loss: 5.322243094444275, Final Batch Loss: 1.2013607025146484\n",
      "Epoch 249, Loss: 5.129642426967621, Final Batch Loss: 1.0645333528518677\n",
      "Epoch 250, Loss: 4.93811172246933, Final Batch Loss: 0.8039015531539917\n",
      "Epoch 251, Loss: 5.629021048545837, Final Batch Loss: 1.461442232131958\n",
      "Epoch 252, Loss: 4.958544075489044, Final Batch Loss: 0.628849446773529\n",
      "Epoch 253, Loss: 4.980403244495392, Final Batch Loss: 0.8019548654556274\n",
      "Epoch 254, Loss: 5.271634995937347, Final Batch Loss: 1.1173702478408813\n",
      "Epoch 255, Loss: 5.071620523929596, Final Batch Loss: 1.0027153491973877\n",
      "Epoch 256, Loss: 5.417848646640778, Final Batch Loss: 1.2796274423599243\n",
      "Epoch 257, Loss: 5.299424886703491, Final Batch Loss: 1.2377259731292725\n",
      "Epoch 258, Loss: 5.107159197330475, Final Batch Loss: 1.001376986503601\n",
      "Epoch 259, Loss: 5.355489134788513, Final Batch Loss: 1.264142394065857\n",
      "Epoch 260, Loss: 4.815315365791321, Final Batch Loss: 0.7155722975730896\n",
      "Epoch 261, Loss: 4.984456658363342, Final Batch Loss: 0.915015697479248\n",
      "Epoch 262, Loss: 4.968561351299286, Final Batch Loss: 0.9582805037498474\n",
      "Epoch 263, Loss: 4.8613250851631165, Final Batch Loss: 0.8825784921646118\n",
      "Epoch 264, Loss: 5.126649439334869, Final Batch Loss: 0.985042929649353\n",
      "Epoch 265, Loss: 5.289357244968414, Final Batch Loss: 1.3031002283096313\n",
      "Epoch 266, Loss: 5.14764279127121, Final Batch Loss: 1.0980923175811768\n",
      "Epoch 267, Loss: 5.041528105735779, Final Batch Loss: 0.8729301691055298\n",
      "Epoch 268, Loss: 4.632245182991028, Final Batch Loss: 0.6016718745231628\n",
      "Epoch 269, Loss: 4.833215236663818, Final Batch Loss: 0.7709963917732239\n",
      "Epoch 270, Loss: 5.030787706375122, Final Batch Loss: 1.076025366783142\n",
      "Epoch 271, Loss: 5.181418180465698, Final Batch Loss: 1.1902881860733032\n",
      "Epoch 272, Loss: 5.209375977516174, Final Batch Loss: 1.2291104793548584\n",
      "Epoch 273, Loss: 5.139653146266937, Final Batch Loss: 1.0627286434173584\n",
      "Epoch 274, Loss: 4.93114572763443, Final Batch Loss: 0.8368942141532898\n",
      "Epoch 275, Loss: 5.045606255531311, Final Batch Loss: 1.047419786453247\n",
      "Epoch 276, Loss: 4.894088923931122, Final Batch Loss: 0.9869353175163269\n",
      "Epoch 277, Loss: 4.94781893491745, Final Batch Loss: 0.9268397092819214\n",
      "Epoch 278, Loss: 5.320995330810547, Final Batch Loss: 1.2701537609100342\n",
      "Epoch 279, Loss: 4.73693585395813, Final Batch Loss: 0.7323775291442871\n",
      "Epoch 280, Loss: 5.51268458366394, Final Batch Loss: 1.438071846961975\n",
      "Epoch 281, Loss: 4.944657206535339, Final Batch Loss: 0.9350606799125671\n",
      "Epoch 282, Loss: 5.002484083175659, Final Batch Loss: 0.9457292556762695\n",
      "Epoch 283, Loss: 5.087902545928955, Final Batch Loss: 1.0715886354446411\n",
      "Epoch 284, Loss: 5.253652274608612, Final Batch Loss: 1.2738906145095825\n",
      "Epoch 285, Loss: 5.216253399848938, Final Batch Loss: 1.1107170581817627\n",
      "Epoch 286, Loss: 5.446457624435425, Final Batch Loss: 1.4060611724853516\n",
      "Epoch 287, Loss: 4.936242580413818, Final Batch Loss: 1.0143543481826782\n",
      "Epoch 288, Loss: 4.970697045326233, Final Batch Loss: 0.8991684317588806\n",
      "Epoch 289, Loss: 5.107803106307983, Final Batch Loss: 1.1630226373672485\n",
      "Epoch 290, Loss: 4.986611783504486, Final Batch Loss: 1.015865683555603\n",
      "Epoch 291, Loss: 5.021844565868378, Final Batch Loss: 1.061425805091858\n",
      "Epoch 292, Loss: 4.610846400260925, Final Batch Loss: 0.6149036288261414\n",
      "Epoch 293, Loss: 5.0831350684165955, Final Batch Loss: 1.1300967931747437\n",
      "Epoch 294, Loss: 5.281461000442505, Final Batch Loss: 1.2335608005523682\n",
      "Epoch 295, Loss: 4.566078364849091, Final Batch Loss: 0.6713567972183228\n",
      "Epoch 296, Loss: 5.547661364078522, Final Batch Loss: 1.5884876251220703\n",
      "Epoch 297, Loss: 5.187119424343109, Final Batch Loss: 1.098091721534729\n",
      "Epoch 298, Loss: 5.067430078983307, Final Batch Loss: 1.1123840808868408\n",
      "Epoch 299, Loss: 5.37912791967392, Final Batch Loss: 1.4013677835464478\n",
      "Epoch 300, Loss: 5.158139705657959, Final Batch Loss: 1.079590082168579\n",
      "Epoch 301, Loss: 5.185023725032806, Final Batch Loss: 1.1470016241073608\n",
      "Epoch 302, Loss: 4.867003500461578, Final Batch Loss: 0.9993492960929871\n",
      "Epoch 303, Loss: 4.71705824136734, Final Batch Loss: 0.8072347044944763\n",
      "Epoch 304, Loss: 5.110656440258026, Final Batch Loss: 1.219069480895996\n",
      "Epoch 305, Loss: 5.028166890144348, Final Batch Loss: 1.1236222982406616\n",
      "Epoch 306, Loss: 4.953208088874817, Final Batch Loss: 1.0288416147232056\n",
      "Epoch 307, Loss: 4.9513378739356995, Final Batch Loss: 1.054009199142456\n",
      "Epoch 308, Loss: 4.618102490901947, Final Batch Loss: 0.7531226873397827\n",
      "Epoch 309, Loss: 4.70667290687561, Final Batch Loss: 0.8324162364006042\n",
      "Epoch 310, Loss: 4.543313205242157, Final Batch Loss: 0.5695218443870544\n",
      "Epoch 311, Loss: 4.758432865142822, Final Batch Loss: 0.900654673576355\n",
      "Epoch 312, Loss: 5.206097722053528, Final Batch Loss: 1.333364486694336\n",
      "Epoch 313, Loss: 5.0833046436309814, Final Batch Loss: 1.1334574222564697\n",
      "Epoch 314, Loss: 4.760956168174744, Final Batch Loss: 0.8965738415718079\n",
      "Epoch 315, Loss: 5.192010164260864, Final Batch Loss: 1.297641634941101\n",
      "Epoch 316, Loss: 4.930907785892487, Final Batch Loss: 0.9262648224830627\n",
      "Epoch 317, Loss: 4.75017637014389, Final Batch Loss: 0.938160240650177\n",
      "Epoch 318, Loss: 4.8586902022361755, Final Batch Loss: 1.022467851638794\n",
      "Epoch 319, Loss: 4.908239006996155, Final Batch Loss: 1.0546109676361084\n",
      "Epoch 320, Loss: 4.885008692741394, Final Batch Loss: 1.0153592824935913\n",
      "Epoch 321, Loss: 4.772305727005005, Final Batch Loss: 0.8617230653762817\n",
      "Epoch 322, Loss: 4.987853229045868, Final Batch Loss: 1.147772192955017\n",
      "Epoch 323, Loss: 4.77447646856308, Final Batch Loss: 0.9439458250999451\n",
      "Epoch 324, Loss: 4.281579434871674, Final Batch Loss: 0.3978269100189209\n",
      "Epoch 325, Loss: 4.632163405418396, Final Batch Loss: 0.8116694688796997\n",
      "Epoch 326, Loss: 4.610473334789276, Final Batch Loss: 0.7609254121780396\n",
      "Epoch 327, Loss: 4.5546844601631165, Final Batch Loss: 0.6804260015487671\n",
      "Epoch 328, Loss: 4.717826724052429, Final Batch Loss: 0.8915630578994751\n",
      "Epoch 329, Loss: 4.500295579433441, Final Batch Loss: 0.6660919785499573\n",
      "Epoch 330, Loss: 4.868075609207153, Final Batch Loss: 1.0037612915039062\n",
      "Epoch 331, Loss: 4.819933593273163, Final Batch Loss: 0.9044204950332642\n",
      "Epoch 332, Loss: 4.731886506080627, Final Batch Loss: 0.9033456444740295\n",
      "Epoch 333, Loss: 4.469910681247711, Final Batch Loss: 0.7171526551246643\n",
      "Epoch 334, Loss: 4.81510066986084, Final Batch Loss: 1.0112998485565186\n",
      "Epoch 335, Loss: 4.979735553264618, Final Batch Loss: 1.2506464719772339\n",
      "Epoch 336, Loss: 4.3012038469314575, Final Batch Loss: 0.5713180303573608\n",
      "Epoch 337, Loss: 4.549704372882843, Final Batch Loss: 0.740938127040863\n",
      "Epoch 338, Loss: 5.102562963962555, Final Batch Loss: 1.3319209814071655\n",
      "Epoch 339, Loss: 4.811352968215942, Final Batch Loss: 0.9468798041343689\n",
      "Epoch 340, Loss: 4.613710045814514, Final Batch Loss: 0.9462567567825317\n",
      "Epoch 341, Loss: 5.0290749073028564, Final Batch Loss: 1.2042734622955322\n",
      "Epoch 342, Loss: 4.763695299625397, Final Batch Loss: 0.8754190802574158\n",
      "Epoch 343, Loss: 4.873048961162567, Final Batch Loss: 0.9774669408798218\n",
      "Epoch 344, Loss: 4.939676582813263, Final Batch Loss: 1.1046099662780762\n",
      "Epoch 345, Loss: 4.703566193580627, Final Batch Loss: 0.8957066535949707\n",
      "Epoch 346, Loss: 4.528150022029877, Final Batch Loss: 0.6635830998420715\n",
      "Epoch 347, Loss: 4.467434644699097, Final Batch Loss: 0.7470536231994629\n",
      "Epoch 348, Loss: 4.784915924072266, Final Batch Loss: 0.9751056432723999\n",
      "Epoch 349, Loss: 4.672681927680969, Final Batch Loss: 0.9615036249160767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, Loss: 5.067755460739136, Final Batch Loss: 1.278025507926941\n",
      "Epoch 351, Loss: 4.554233014583588, Final Batch Loss: 0.8011160492897034\n",
      "Epoch 352, Loss: 4.859772741794586, Final Batch Loss: 1.0585157871246338\n",
      "Epoch 353, Loss: 4.669577419757843, Final Batch Loss: 0.9069703817367554\n",
      "Epoch 354, Loss: 5.123462080955505, Final Batch Loss: 1.3603605031967163\n",
      "Epoch 355, Loss: 4.882535696029663, Final Batch Loss: 1.0913054943084717\n",
      "Epoch 356, Loss: 4.728464305400848, Final Batch Loss: 0.9773097038269043\n",
      "Epoch 357, Loss: 4.726435363292694, Final Batch Loss: 0.998249351978302\n",
      "Epoch 358, Loss: 4.592511713504791, Final Batch Loss: 0.8678940534591675\n",
      "Epoch 359, Loss: 4.580190539360046, Final Batch Loss: 0.7535673379898071\n",
      "Epoch 360, Loss: 4.297568321228027, Final Batch Loss: 0.5550846457481384\n",
      "Epoch 361, Loss: 4.292354077100754, Final Batch Loss: 0.48244425654411316\n",
      "Epoch 362, Loss: 4.565742135047913, Final Batch Loss: 0.904232919216156\n",
      "Epoch 363, Loss: 4.6484562158584595, Final Batch Loss: 0.9240275025367737\n",
      "Epoch 364, Loss: 4.747954845428467, Final Batch Loss: 0.8927574157714844\n",
      "Epoch 365, Loss: 4.564792156219482, Final Batch Loss: 0.7216119766235352\n",
      "Epoch 366, Loss: 4.760780215263367, Final Batch Loss: 0.9682074785232544\n",
      "Epoch 367, Loss: 4.363093435764313, Final Batch Loss: 0.5697380900382996\n",
      "Epoch 368, Loss: 4.663097023963928, Final Batch Loss: 0.8811847567558289\n",
      "Epoch 369, Loss: 4.665445268154144, Final Batch Loss: 0.9809656739234924\n",
      "Epoch 370, Loss: 4.448836147785187, Final Batch Loss: 0.7853666543960571\n",
      "Epoch 371, Loss: 4.920820951461792, Final Batch Loss: 1.0819454193115234\n",
      "Epoch 372, Loss: 4.371728003025055, Final Batch Loss: 0.5929042100906372\n",
      "Epoch 373, Loss: 4.568114697933197, Final Batch Loss: 0.8799819946289062\n",
      "Epoch 374, Loss: 4.72381067276001, Final Batch Loss: 1.073211908340454\n",
      "Epoch 375, Loss: 4.897389233112335, Final Batch Loss: 1.1650663614273071\n",
      "Epoch 376, Loss: 4.838976442813873, Final Batch Loss: 1.114396572113037\n",
      "Epoch 377, Loss: 4.594187557697296, Final Batch Loss: 0.8512905836105347\n",
      "Epoch 378, Loss: 4.781940162181854, Final Batch Loss: 1.0241706371307373\n",
      "Epoch 379, Loss: 4.507852017879486, Final Batch Loss: 0.7803677916526794\n",
      "Epoch 380, Loss: 4.818721175193787, Final Batch Loss: 1.0992850065231323\n",
      "Epoch 381, Loss: 4.734082221984863, Final Batch Loss: 1.0449713468551636\n",
      "Epoch 382, Loss: 4.584296643733978, Final Batch Loss: 0.8889446258544922\n",
      "Epoch 383, Loss: 4.668037474155426, Final Batch Loss: 0.843254029750824\n",
      "Epoch 384, Loss: 4.636229753494263, Final Batch Loss: 0.952032208442688\n",
      "Epoch 385, Loss: 4.836367547512054, Final Batch Loss: 1.0686228275299072\n",
      "Epoch 386, Loss: 4.241589784622192, Final Batch Loss: 0.6009091138839722\n",
      "Epoch 387, Loss: 4.514808416366577, Final Batch Loss: 0.8295170664787292\n",
      "Epoch 388, Loss: 4.62262886762619, Final Batch Loss: 0.8794649243354797\n",
      "Epoch 389, Loss: 4.461534559726715, Final Batch Loss: 0.6809480786323547\n",
      "Epoch 390, Loss: 4.954371750354767, Final Batch Loss: 1.1941192150115967\n",
      "Epoch 391, Loss: 4.47131609916687, Final Batch Loss: 0.7093921899795532\n",
      "Epoch 392, Loss: 4.192700982093811, Final Batch Loss: 0.45981717109680176\n",
      "Epoch 393, Loss: 4.546890437602997, Final Batch Loss: 0.84538733959198\n",
      "Epoch 394, Loss: 4.863963782787323, Final Batch Loss: 1.1608787775039673\n",
      "Epoch 395, Loss: 4.477079272270203, Final Batch Loss: 0.656980037689209\n",
      "Epoch 396, Loss: 4.530102789402008, Final Batch Loss: 0.7962950468063354\n",
      "Epoch 397, Loss: 4.393050491809845, Final Batch Loss: 0.7107066512107849\n",
      "Epoch 398, Loss: 4.580126345157623, Final Batch Loss: 0.8189738392829895\n",
      "Epoch 399, Loss: 4.884301722049713, Final Batch Loss: 1.1992104053497314\n",
      "Epoch 400, Loss: 4.3102447390556335, Final Batch Loss: 0.6511384844779968\n",
      "Epoch 401, Loss: 4.505237340927124, Final Batch Loss: 0.8594167828559875\n",
      "Epoch 402, Loss: 4.806443989276886, Final Batch Loss: 1.052846074104309\n",
      "Epoch 403, Loss: 4.437985122203827, Final Batch Loss: 0.7557746767997742\n",
      "Epoch 404, Loss: 4.802764356136322, Final Batch Loss: 1.081512212753296\n",
      "Epoch 405, Loss: 4.849058926105499, Final Batch Loss: 1.234128713607788\n",
      "Epoch 406, Loss: 4.614084243774414, Final Batch Loss: 0.9789256453514099\n",
      "Epoch 407, Loss: 4.357057332992554, Final Batch Loss: 0.5818325281143188\n",
      "Epoch 408, Loss: 4.288893818855286, Final Batch Loss: 0.7036710381507874\n",
      "Epoch 409, Loss: 4.7238816022872925, Final Batch Loss: 1.132886290550232\n",
      "Epoch 410, Loss: 4.54815399646759, Final Batch Loss: 0.8667692542076111\n",
      "Epoch 411, Loss: 4.306736946105957, Final Batch Loss: 0.6753950119018555\n",
      "Epoch 412, Loss: 4.617216944694519, Final Batch Loss: 0.8596894145011902\n",
      "Epoch 413, Loss: 4.54336404800415, Final Batch Loss: 1.0706766843795776\n",
      "Epoch 414, Loss: 4.375060558319092, Final Batch Loss: 0.7478136420249939\n",
      "Epoch 415, Loss: 4.643009603023529, Final Batch Loss: 1.018612265586853\n",
      "Epoch 416, Loss: 4.491110920906067, Final Batch Loss: 0.7959882020950317\n",
      "Epoch 417, Loss: 4.291934669017792, Final Batch Loss: 0.6990020871162415\n",
      "Epoch 418, Loss: 4.6371065974235535, Final Batch Loss: 1.0105385780334473\n",
      "Epoch 419, Loss: 4.238269865512848, Final Batch Loss: 0.6181816458702087\n",
      "Epoch 420, Loss: 4.667558014392853, Final Batch Loss: 1.0336169004440308\n",
      "Epoch 421, Loss: 4.454282283782959, Final Batch Loss: 0.7828344702720642\n",
      "Epoch 422, Loss: 4.546888113021851, Final Batch Loss: 0.7676082849502563\n",
      "Epoch 423, Loss: 4.386132478713989, Final Batch Loss: 0.7607883214950562\n",
      "Epoch 424, Loss: 4.499743819236755, Final Batch Loss: 0.7482709288597107\n",
      "Epoch 425, Loss: 4.948071539402008, Final Batch Loss: 1.3442490100860596\n",
      "Epoch 426, Loss: 4.313237965106964, Final Batch Loss: 0.6303187608718872\n",
      "Epoch 427, Loss: 4.658950328826904, Final Batch Loss: 1.033936858177185\n",
      "Epoch 428, Loss: 4.532529950141907, Final Batch Loss: 0.9290902018547058\n",
      "Epoch 429, Loss: 5.348324179649353, Final Batch Loss: 1.5924519300460815\n",
      "Epoch 430, Loss: 4.281925320625305, Final Batch Loss: 0.731589138507843\n",
      "Epoch 431, Loss: 4.543102204799652, Final Batch Loss: 1.010428786277771\n",
      "Epoch 432, Loss: 4.805342614650726, Final Batch Loss: 1.1335513591766357\n",
      "Epoch 433, Loss: 4.495631396770477, Final Batch Loss: 0.9349158406257629\n",
      "Epoch 434, Loss: 4.381194889545441, Final Batch Loss: 0.6715589761734009\n",
      "Epoch 435, Loss: 4.201070070266724, Final Batch Loss: 0.5216818451881409\n",
      "Epoch 436, Loss: 4.678494930267334, Final Batch Loss: 1.1319910287857056\n",
      "Epoch 437, Loss: 4.127147972583771, Final Batch Loss: 0.5750541687011719\n",
      "Epoch 438, Loss: 4.2773831486701965, Final Batch Loss: 0.7317628860473633\n",
      "Epoch 439, Loss: 4.962413787841797, Final Batch Loss: 1.2818968296051025\n",
      "Epoch 440, Loss: 4.2301822900772095, Final Batch Loss: 0.6630535125732422\n",
      "Epoch 441, Loss: 4.609949350357056, Final Batch Loss: 1.0634585618972778\n",
      "Epoch 442, Loss: 4.700283408164978, Final Batch Loss: 1.0685832500457764\n",
      "Epoch 443, Loss: 4.457975089550018, Final Batch Loss: 0.9061161875724792\n",
      "Epoch 444, Loss: 4.593456745147705, Final Batch Loss: 0.9407088160514832\n",
      "Epoch 445, Loss: 4.365404903888702, Final Batch Loss: 0.82957524061203\n",
      "Epoch 446, Loss: 4.699466824531555, Final Batch Loss: 1.1777437925338745\n",
      "Epoch 447, Loss: 4.386094748973846, Final Batch Loss: 0.8697714805603027\n",
      "Epoch 448, Loss: 4.5159918665885925, Final Batch Loss: 0.8985975980758667\n",
      "Epoch 449, Loss: 4.385683059692383, Final Batch Loss: 0.751154363155365\n",
      "Epoch 450, Loss: 5.373062312602997, Final Batch Loss: 1.804327130317688\n",
      "Epoch 451, Loss: 4.091762542724609, Final Batch Loss: 0.5864951014518738\n",
      "Epoch 452, Loss: 4.530043840408325, Final Batch Loss: 1.0791066884994507\n",
      "Epoch 453, Loss: 4.20457923412323, Final Batch Loss: 0.6819597482681274\n",
      "Epoch 454, Loss: 4.457847774028778, Final Batch Loss: 0.8847604990005493\n",
      "Epoch 455, Loss: 4.199550926685333, Final Batch Loss: 0.5407003164291382\n",
      "Epoch 456, Loss: 4.183686792850494, Final Batch Loss: 0.5976413488388062\n",
      "Epoch 457, Loss: 4.505051255226135, Final Batch Loss: 0.9744523167610168\n",
      "Epoch 458, Loss: 4.489335298538208, Final Batch Loss: 0.9351688027381897\n",
      "Epoch 459, Loss: 4.183712601661682, Final Batch Loss: 0.6148213148117065\n",
      "Epoch 460, Loss: 4.60669881105423, Final Batch Loss: 1.0409433841705322\n",
      "Epoch 461, Loss: 4.310775637626648, Final Batch Loss: 0.8808373212814331\n",
      "Epoch 462, Loss: 3.9714888632297516, Final Batch Loss: 0.44953009486198425\n",
      "Epoch 463, Loss: 4.432223796844482, Final Batch Loss: 0.9915419816970825\n",
      "Epoch 464, Loss: 4.407924294471741, Final Batch Loss: 0.8437362909317017\n",
      "Epoch 465, Loss: 4.260161876678467, Final Batch Loss: 0.6657048463821411\n",
      "Epoch 466, Loss: 4.530057370662689, Final Batch Loss: 0.9608944654464722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467, Loss: 4.719544589519501, Final Batch Loss: 1.171708345413208\n",
      "Epoch 468, Loss: 4.267360210418701, Final Batch Loss: 0.6738290786743164\n",
      "Epoch 469, Loss: 4.1927215456962585, Final Batch Loss: 0.562298595905304\n",
      "Epoch 470, Loss: 4.689687371253967, Final Batch Loss: 1.1093677282333374\n",
      "Epoch 471, Loss: 4.500715732574463, Final Batch Loss: 1.0363491773605347\n",
      "Epoch 472, Loss: 4.5134599804878235, Final Batch Loss: 1.022659420967102\n",
      "Epoch 473, Loss: 4.3700650334358215, Final Batch Loss: 0.7756370902061462\n",
      "Epoch 474, Loss: 4.816839158535004, Final Batch Loss: 1.2872412204742432\n",
      "Epoch 475, Loss: 4.126678884029388, Final Batch Loss: 0.5835384130477905\n",
      "Epoch 476, Loss: 4.362617254257202, Final Batch Loss: 0.8004048466682434\n",
      "Epoch 477, Loss: 4.36678671836853, Final Batch Loss: 0.8093580007553101\n",
      "Epoch 478, Loss: 4.381381392478943, Final Batch Loss: 0.9428557753562927\n",
      "Epoch 479, Loss: 4.832939863204956, Final Batch Loss: 1.2317441701889038\n",
      "Epoch 480, Loss: 4.655331015586853, Final Batch Loss: 1.061224341392517\n",
      "Epoch 481, Loss: 4.183825194835663, Final Batch Loss: 0.628608763217926\n",
      "Epoch 482, Loss: 4.8666892647743225, Final Batch Loss: 1.1895742416381836\n",
      "Epoch 483, Loss: 4.42750871181488, Final Batch Loss: 0.8754101395606995\n",
      "Epoch 484, Loss: 4.765554785728455, Final Batch Loss: 1.1673595905303955\n",
      "Epoch 485, Loss: 4.107670187950134, Final Batch Loss: 0.5696467757225037\n",
      "Epoch 486, Loss: 4.421534776687622, Final Batch Loss: 0.898829460144043\n",
      "Epoch 487, Loss: 4.550965249538422, Final Batch Loss: 1.0549856424331665\n",
      "Epoch 488, Loss: 4.181085526943207, Final Batch Loss: 0.6721934080123901\n",
      "Epoch 489, Loss: 4.255874931812286, Final Batch Loss: 0.8046082854270935\n",
      "Epoch 490, Loss: 4.383494019508362, Final Batch Loss: 0.8151785731315613\n",
      "Epoch 491, Loss: 4.242326855659485, Final Batch Loss: 0.6448439359664917\n",
      "Epoch 492, Loss: 4.2432467341423035, Final Batch Loss: 0.7745633125305176\n",
      "Epoch 493, Loss: 4.3105469942092896, Final Batch Loss: 0.8153533339500427\n",
      "Epoch 494, Loss: 4.556027829647064, Final Batch Loss: 0.9680982828140259\n",
      "Epoch 495, Loss: 4.522639691829681, Final Batch Loss: 1.0371373891830444\n",
      "Epoch 496, Loss: 4.099617958068848, Final Batch Loss: 0.6485639214515686\n",
      "Epoch 497, Loss: 4.652200937271118, Final Batch Loss: 1.173553466796875\n",
      "Epoch 498, Loss: 4.1170724630355835, Final Batch Loss: 0.6182994246482849\n",
      "Epoch 499, Loss: 3.986614912748337, Final Batch Loss: 0.3707254230976105\n",
      "Epoch 500, Loss: 4.331274688243866, Final Batch Loss: 0.8841868042945862\n",
      "Epoch 501, Loss: 4.0990952253341675, Final Batch Loss: 0.5904744863510132\n",
      "Epoch 502, Loss: 4.669956982135773, Final Batch Loss: 1.1052734851837158\n",
      "Epoch 503, Loss: 4.3081254959106445, Final Batch Loss: 0.7679086327552795\n",
      "Epoch 504, Loss: 4.804224193096161, Final Batch Loss: 1.3261409997940063\n",
      "Epoch 505, Loss: 4.283965289592743, Final Batch Loss: 0.8670607209205627\n",
      "Epoch 506, Loss: 4.070133447647095, Final Batch Loss: 0.5928124785423279\n",
      "Epoch 507, Loss: 4.286844789981842, Final Batch Loss: 0.9421488642692566\n",
      "Epoch 508, Loss: 4.351976454257965, Final Batch Loss: 0.8347779512405396\n",
      "Epoch 509, Loss: 4.5381956696510315, Final Batch Loss: 1.0704176425933838\n",
      "Epoch 510, Loss: 4.431133389472961, Final Batch Loss: 0.9635787606239319\n",
      "Epoch 511, Loss: 4.333755314350128, Final Batch Loss: 0.7771868109703064\n",
      "Epoch 512, Loss: 3.976921498775482, Final Batch Loss: 0.4624791145324707\n",
      "Epoch 513, Loss: 4.067327976226807, Final Batch Loss: 0.5653784275054932\n",
      "Epoch 514, Loss: 4.257015228271484, Final Batch Loss: 0.7731871008872986\n",
      "Epoch 515, Loss: 4.139559626579285, Final Batch Loss: 0.6518511772155762\n",
      "Epoch 516, Loss: 4.393610775470734, Final Batch Loss: 0.9872819185256958\n",
      "Epoch 517, Loss: 4.698792219161987, Final Batch Loss: 1.2920790910720825\n",
      "Epoch 518, Loss: 4.977926194667816, Final Batch Loss: 1.4581040143966675\n",
      "Epoch 519, Loss: 4.309731662273407, Final Batch Loss: 0.8212548494338989\n",
      "Epoch 520, Loss: 4.309584379196167, Final Batch Loss: 0.8134046196937561\n",
      "Epoch 521, Loss: 4.361344635486603, Final Batch Loss: 0.9943507313728333\n",
      "Epoch 522, Loss: 4.081628918647766, Final Batch Loss: 0.6842026114463806\n",
      "Epoch 523, Loss: 4.072596549987793, Final Batch Loss: 0.6891081929206848\n",
      "Epoch 524, Loss: 4.253289103507996, Final Batch Loss: 0.7278210520744324\n",
      "Epoch 525, Loss: 4.2090771198272705, Final Batch Loss: 0.7173989415168762\n",
      "Epoch 526, Loss: 4.350500524044037, Final Batch Loss: 0.8460666537284851\n",
      "Epoch 527, Loss: 4.041097044944763, Final Batch Loss: 0.691729724407196\n",
      "Epoch 528, Loss: 4.268733978271484, Final Batch Loss: 0.7761157751083374\n",
      "Epoch 529, Loss: 4.359126091003418, Final Batch Loss: 1.004615068435669\n",
      "Epoch 530, Loss: 4.420104384422302, Final Batch Loss: 0.9069427847862244\n",
      "Epoch 531, Loss: 4.088416039943695, Final Batch Loss: 0.7719969749450684\n",
      "Epoch 532, Loss: 4.2129324078559875, Final Batch Loss: 0.8337122201919556\n",
      "Epoch 533, Loss: 4.106331050395966, Final Batch Loss: 0.7537723779678345\n",
      "Epoch 534, Loss: 3.866487741470337, Final Batch Loss: 0.5121489763259888\n",
      "Epoch 535, Loss: 4.1396960616111755, Final Batch Loss: 0.7603920698165894\n",
      "Epoch 536, Loss: 4.289612412452698, Final Batch Loss: 0.9273837208747864\n",
      "Epoch 537, Loss: 4.081782341003418, Final Batch Loss: 0.6302690505981445\n",
      "Epoch 538, Loss: 4.590360701084137, Final Batch Loss: 1.1095354557037354\n",
      "Epoch 539, Loss: 4.615409791469574, Final Batch Loss: 0.9713051915168762\n",
      "Epoch 540, Loss: 4.389007270336151, Final Batch Loss: 0.9757484197616577\n",
      "Epoch 541, Loss: 4.334253907203674, Final Batch Loss: 0.8804088234901428\n",
      "Epoch 542, Loss: 4.577623009681702, Final Batch Loss: 1.2133347988128662\n",
      "Epoch 543, Loss: 4.2006683349609375, Final Batch Loss: 0.710204541683197\n",
      "Epoch 544, Loss: 4.022452890872955, Final Batch Loss: 0.6585155129432678\n",
      "Epoch 545, Loss: 4.197496712207794, Final Batch Loss: 0.8181519508361816\n",
      "Epoch 546, Loss: 3.9186453223228455, Final Batch Loss: 0.5750210881233215\n",
      "Epoch 547, Loss: 4.325807332992554, Final Batch Loss: 0.9497798085212708\n",
      "Epoch 548, Loss: 4.42204350233078, Final Batch Loss: 1.0175721645355225\n",
      "Epoch 549, Loss: 4.618777394294739, Final Batch Loss: 1.2505863904953003\n",
      "Epoch 550, Loss: 4.315662980079651, Final Batch Loss: 0.8629608154296875\n",
      "Epoch 551, Loss: 4.4517622590065, Final Batch Loss: 1.0648837089538574\n",
      "Epoch 552, Loss: 4.062275946140289, Final Batch Loss: 0.648659348487854\n",
      "Epoch 553, Loss: 4.222113907337189, Final Batch Loss: 0.8442588448524475\n",
      "Epoch 554, Loss: 3.856299042701721, Final Batch Loss: 0.4859743118286133\n",
      "Epoch 555, Loss: 4.373036861419678, Final Batch Loss: 1.0678852796554565\n",
      "Epoch 556, Loss: 4.140659511089325, Final Batch Loss: 0.8321176767349243\n",
      "Epoch 557, Loss: 4.5071234703063965, Final Batch Loss: 1.2557014226913452\n",
      "Epoch 558, Loss: 4.076656818389893, Final Batch Loss: 0.801794171333313\n",
      "Epoch 559, Loss: 4.064800500869751, Final Batch Loss: 0.6312852501869202\n",
      "Epoch 560, Loss: 4.40673691034317, Final Batch Loss: 1.0610190629959106\n",
      "Epoch 561, Loss: 4.181399822235107, Final Batch Loss: 0.9015088677406311\n",
      "Epoch 562, Loss: 4.795477628707886, Final Batch Loss: 1.2821102142333984\n",
      "Epoch 563, Loss: 4.297249495983124, Final Batch Loss: 0.9630231261253357\n",
      "Epoch 564, Loss: 4.4019487500190735, Final Batch Loss: 0.9529432654380798\n",
      "Epoch 565, Loss: 4.233722567558289, Final Batch Loss: 0.9193819761276245\n",
      "Epoch 566, Loss: 4.403113484382629, Final Batch Loss: 1.1067816019058228\n",
      "Epoch 567, Loss: 3.8402536809444427, Final Batch Loss: 0.4655067026615143\n",
      "Epoch 568, Loss: 4.141160070896149, Final Batch Loss: 0.801092267036438\n",
      "Epoch 569, Loss: 3.9267431497573853, Final Batch Loss: 0.5927944779396057\n",
      "Epoch 570, Loss: 3.9120483994483948, Final Batch Loss: 0.465592622756958\n",
      "Epoch 571, Loss: 4.157739639282227, Final Batch Loss: 0.7183217406272888\n",
      "Epoch 572, Loss: 3.778548151254654, Final Batch Loss: 0.43175074458122253\n",
      "Epoch 573, Loss: 4.157325267791748, Final Batch Loss: 0.7554410696029663\n",
      "Epoch 574, Loss: 3.940814197063446, Final Batch Loss: 0.6154588460922241\n",
      "Epoch 575, Loss: 4.3587453961372375, Final Batch Loss: 0.949314534664154\n",
      "Epoch 576, Loss: 4.031036198139191, Final Batch Loss: 0.6318621039390564\n",
      "Epoch 577, Loss: 4.658872902393341, Final Batch Loss: 1.2230819463729858\n",
      "Epoch 578, Loss: 4.632285296916962, Final Batch Loss: 1.341868281364441\n",
      "Epoch 579, Loss: 4.04697847366333, Final Batch Loss: 0.7252362966537476\n",
      "Epoch 580, Loss: 4.059920072555542, Final Batch Loss: 0.7639843821525574\n",
      "Epoch 581, Loss: 4.061318218708038, Final Batch Loss: 0.6529148817062378\n",
      "Epoch 582, Loss: 4.098643898963928, Final Batch Loss: 0.8078087568283081\n",
      "Epoch 583, Loss: 4.091747999191284, Final Batch Loss: 0.8225045204162598\n",
      "Epoch 584, Loss: 4.219727575778961, Final Batch Loss: 0.9136480093002319\n",
      "Epoch 585, Loss: 3.9041537046432495, Final Batch Loss: 0.6017512083053589\n",
      "Epoch 586, Loss: 4.153513848781586, Final Batch Loss: 0.7580702900886536\n",
      "Epoch 587, Loss: 4.648523271083832, Final Batch Loss: 1.282456636428833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 588, Loss: 3.782878488302231, Final Batch Loss: 0.44358083605766296\n",
      "Epoch 589, Loss: 4.082894206047058, Final Batch Loss: 0.771245539188385\n",
      "Epoch 590, Loss: 4.175981402397156, Final Batch Loss: 0.892148494720459\n",
      "Epoch 591, Loss: 3.977993905544281, Final Batch Loss: 0.7125879526138306\n",
      "Epoch 592, Loss: 4.620426177978516, Final Batch Loss: 1.226976990699768\n",
      "Epoch 593, Loss: 4.4526060819625854, Final Batch Loss: 0.9834614992141724\n",
      "Epoch 594, Loss: 4.156012117862701, Final Batch Loss: 0.7257235646247864\n",
      "Epoch 595, Loss: 4.358668565750122, Final Batch Loss: 1.0357682704925537\n",
      "Epoch 596, Loss: 4.497501194477081, Final Batch Loss: 1.2880889177322388\n",
      "Epoch 597, Loss: 3.9360138177871704, Final Batch Loss: 0.638200581073761\n",
      "Epoch 598, Loss: 4.009994208812714, Final Batch Loss: 0.7199887037277222\n",
      "Epoch 599, Loss: 3.817993015050888, Final Batch Loss: 0.48533305525779724\n",
      "Epoch 600, Loss: 4.035410284996033, Final Batch Loss: 0.6705931425094604\n",
      "Epoch 601, Loss: 4.069282412528992, Final Batch Loss: 0.8403754830360413\n",
      "Epoch 602, Loss: 3.8917500972747803, Final Batch Loss: 0.5922799110412598\n",
      "Epoch 603, Loss: 4.443270921707153, Final Batch Loss: 1.1318303346633911\n",
      "Epoch 604, Loss: 4.934063374996185, Final Batch Loss: 1.5958592891693115\n",
      "Epoch 605, Loss: 3.9719952940940857, Final Batch Loss: 0.694614589214325\n",
      "Epoch 606, Loss: 4.241676390171051, Final Batch Loss: 0.8218890428543091\n",
      "Epoch 607, Loss: 4.5281031131744385, Final Batch Loss: 1.1622984409332275\n",
      "Epoch 608, Loss: 4.031752943992615, Final Batch Loss: 0.7825897932052612\n",
      "Epoch 609, Loss: 4.15274041891098, Final Batch Loss: 0.7537063956260681\n",
      "Epoch 610, Loss: 4.12882661819458, Final Batch Loss: 0.8187394738197327\n",
      "Epoch 611, Loss: 4.392168164253235, Final Batch Loss: 1.0081074237823486\n",
      "Epoch 612, Loss: 4.015707433223724, Final Batch Loss: 0.7303961515426636\n",
      "Epoch 613, Loss: 4.159914314746857, Final Batch Loss: 0.8867683410644531\n",
      "Epoch 614, Loss: 3.977205276489258, Final Batch Loss: 0.6401540040969849\n",
      "Epoch 615, Loss: 4.335600674152374, Final Batch Loss: 1.0817477703094482\n",
      "Epoch 616, Loss: 3.860218822956085, Final Batch Loss: 0.7183824777603149\n",
      "Epoch 617, Loss: 3.902679741382599, Final Batch Loss: 0.6782718300819397\n",
      "Epoch 618, Loss: 4.338960766792297, Final Batch Loss: 0.8913890719413757\n",
      "Epoch 619, Loss: 4.197349011898041, Final Batch Loss: 0.8413999676704407\n",
      "Epoch 620, Loss: 4.420870840549469, Final Batch Loss: 1.151107907295227\n",
      "Epoch 621, Loss: 3.7444970309734344, Final Batch Loss: 0.44925442337989807\n",
      "Epoch 622, Loss: 4.032253801822662, Final Batch Loss: 0.754896342754364\n",
      "Epoch 623, Loss: 3.907154083251953, Final Batch Loss: 0.7890638709068298\n",
      "Epoch 624, Loss: 4.190352559089661, Final Batch Loss: 0.9762929081916809\n",
      "Epoch 625, Loss: 4.176570117473602, Final Batch Loss: 0.9799247980117798\n",
      "Epoch 626, Loss: 3.8740317821502686, Final Batch Loss: 0.5594989657402039\n",
      "Epoch 627, Loss: 4.046682357788086, Final Batch Loss: 0.7179422378540039\n",
      "Epoch 628, Loss: 3.9940118193626404, Final Batch Loss: 0.6736597418785095\n",
      "Epoch 629, Loss: 4.136850953102112, Final Batch Loss: 0.9171205163002014\n",
      "Epoch 630, Loss: 4.340923547744751, Final Batch Loss: 1.1341041326522827\n",
      "Epoch 631, Loss: 4.191449522972107, Final Batch Loss: 0.9199985861778259\n",
      "Epoch 632, Loss: 3.839714765548706, Final Batch Loss: 0.550075352191925\n",
      "Epoch 633, Loss: 4.041257619857788, Final Batch Loss: 0.8377070426940918\n",
      "Epoch 634, Loss: 4.339036703109741, Final Batch Loss: 1.076743721961975\n",
      "Epoch 635, Loss: 3.9258894324302673, Final Batch Loss: 0.7227218747138977\n",
      "Epoch 636, Loss: 3.951449930667877, Final Batch Loss: 0.6857671141624451\n",
      "Epoch 637, Loss: 3.8579562306404114, Final Batch Loss: 0.5414884686470032\n",
      "Epoch 638, Loss: 4.157900273799896, Final Batch Loss: 0.9078224897384644\n",
      "Epoch 639, Loss: 4.391439616680145, Final Batch Loss: 1.1203948259353638\n",
      "Epoch 640, Loss: 3.9953152537345886, Final Batch Loss: 0.7447137236595154\n",
      "Epoch 641, Loss: 3.9834747910499573, Final Batch Loss: 0.8064332008361816\n",
      "Epoch 642, Loss: 3.8738341331481934, Final Batch Loss: 0.6591194868087769\n",
      "Epoch 643, Loss: 4.636327028274536, Final Batch Loss: 1.2908247709274292\n",
      "Epoch 644, Loss: 4.0815964341163635, Final Batch Loss: 0.8401555418968201\n",
      "Epoch 645, Loss: 4.4843244552612305, Final Batch Loss: 1.1599838733673096\n",
      "Epoch 646, Loss: 4.049369692802429, Final Batch Loss: 0.8501992225646973\n",
      "Epoch 647, Loss: 4.098975121974945, Final Batch Loss: 0.7636242508888245\n",
      "Epoch 648, Loss: 3.910348653793335, Final Batch Loss: 0.6142948269844055\n",
      "Epoch 649, Loss: 4.197261095046997, Final Batch Loss: 0.9662546515464783\n",
      "Epoch 650, Loss: 4.259163677692413, Final Batch Loss: 1.0199788808822632\n",
      "Epoch 651, Loss: 3.61044642329216, Final Batch Loss: 0.3528362810611725\n",
      "Epoch 652, Loss: 3.8807138800621033, Final Batch Loss: 0.8008699417114258\n",
      "Epoch 653, Loss: 4.252670645713806, Final Batch Loss: 1.0260175466537476\n",
      "Epoch 654, Loss: 4.034563720226288, Final Batch Loss: 0.8395274877548218\n",
      "Epoch 655, Loss: 4.219791948795319, Final Batch Loss: 1.0030467510223389\n",
      "Epoch 656, Loss: 4.015025973320007, Final Batch Loss: 0.9217419028282166\n",
      "Epoch 657, Loss: 4.367402791976929, Final Batch Loss: 1.10007643699646\n",
      "Epoch 658, Loss: 3.697257936000824, Final Batch Loss: 0.5636332631111145\n",
      "Epoch 659, Loss: 4.205415606498718, Final Batch Loss: 0.9642505645751953\n",
      "Epoch 660, Loss: 3.8676860332489014, Final Batch Loss: 0.7094210386276245\n",
      "Epoch 661, Loss: 4.125646770000458, Final Batch Loss: 0.8880747556686401\n",
      "Epoch 662, Loss: 4.156655490398407, Final Batch Loss: 0.9799591898918152\n",
      "Epoch 663, Loss: 4.169773697853088, Final Batch Loss: 1.0496399402618408\n",
      "Epoch 664, Loss: 4.29426109790802, Final Batch Loss: 1.036587119102478\n",
      "Epoch 665, Loss: 4.286445915699005, Final Batch Loss: 1.0037754774093628\n",
      "Epoch 666, Loss: 3.835174262523651, Final Batch Loss: 0.6279717683792114\n",
      "Epoch 667, Loss: 4.570290684700012, Final Batch Loss: 1.2500431537628174\n",
      "Epoch 668, Loss: 4.083681881427765, Final Batch Loss: 0.8829823732376099\n",
      "Epoch 669, Loss: 4.0956655740737915, Final Batch Loss: 0.9740921854972839\n",
      "Epoch 670, Loss: 4.145246863365173, Final Batch Loss: 0.8499357104301453\n",
      "Epoch 671, Loss: 4.045701205730438, Final Batch Loss: 0.9161645770072937\n",
      "Epoch 672, Loss: 4.043579578399658, Final Batch Loss: 0.7198262810707092\n",
      "Epoch 673, Loss: 4.027387797832489, Final Batch Loss: 0.8164777755737305\n",
      "Epoch 674, Loss: 4.197744309902191, Final Batch Loss: 0.9481138586997986\n",
      "Epoch 675, Loss: 4.168942749500275, Final Batch Loss: 0.8310492634773254\n",
      "Epoch 676, Loss: 4.271592020988464, Final Batch Loss: 1.0213167667388916\n",
      "Epoch 677, Loss: 4.247960090637207, Final Batch Loss: 1.0209285020828247\n",
      "Epoch 678, Loss: 4.080384790897369, Final Batch Loss: 0.8326281905174255\n",
      "Epoch 679, Loss: 4.56464809179306, Final Batch Loss: 1.4025472402572632\n",
      "Epoch 680, Loss: 4.161341071128845, Final Batch Loss: 1.0211085081100464\n",
      "Epoch 681, Loss: 3.8282273411750793, Final Batch Loss: 0.7006939649581909\n",
      "Epoch 682, Loss: 3.920686423778534, Final Batch Loss: 0.7515946626663208\n",
      "Epoch 683, Loss: 3.934256911277771, Final Batch Loss: 0.7967370748519897\n",
      "Epoch 684, Loss: 4.2592883706092834, Final Batch Loss: 0.9988974928855896\n",
      "Epoch 685, Loss: 3.900019407272339, Final Batch Loss: 0.697569727897644\n",
      "Epoch 686, Loss: 3.9280649423599243, Final Batch Loss: 0.7552314400672913\n",
      "Epoch 687, Loss: 4.5080437660217285, Final Batch Loss: 1.3396718502044678\n",
      "Epoch 688, Loss: 3.9483197927474976, Final Batch Loss: 0.724662184715271\n",
      "Epoch 689, Loss: 3.941374182701111, Final Batch Loss: 0.7856432795524597\n",
      "Epoch 690, Loss: 3.62831974029541, Final Batch Loss: 0.4644787311553955\n",
      "Epoch 691, Loss: 4.0117387771606445, Final Batch Loss: 0.8606069684028625\n",
      "Epoch 692, Loss: 4.274804592132568, Final Batch Loss: 1.0101754665374756\n",
      "Epoch 693, Loss: 3.6316977441310883, Final Batch Loss: 0.4219997823238373\n",
      "Epoch 694, Loss: 4.030830562114716, Final Batch Loss: 0.8842793107032776\n",
      "Epoch 695, Loss: 4.439775109291077, Final Batch Loss: 1.2349977493286133\n",
      "Epoch 696, Loss: 4.089529812335968, Final Batch Loss: 1.0020426511764526\n",
      "Epoch 697, Loss: 3.8730897903442383, Final Batch Loss: 0.546745240688324\n",
      "Epoch 698, Loss: 4.017414212226868, Final Batch Loss: 0.7934882044792175\n",
      "Epoch 699, Loss: 3.9113869667053223, Final Batch Loss: 0.7709580659866333\n",
      "Epoch 700, Loss: 3.9836052656173706, Final Batch Loss: 0.6851572394371033\n",
      "Epoch 701, Loss: 3.9199975728988647, Final Batch Loss: 0.7504339814186096\n",
      "Epoch 702, Loss: 4.240066647529602, Final Batch Loss: 1.0283080339431763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703, Loss: 4.055253505706787, Final Batch Loss: 0.8712610006332397\n",
      "Epoch 704, Loss: 4.216610789299011, Final Batch Loss: 1.013755440711975\n",
      "Epoch 705, Loss: 3.747701644897461, Final Batch Loss: 0.6397919058799744\n",
      "Epoch 706, Loss: 4.022428929805756, Final Batch Loss: 0.8941459655761719\n",
      "Epoch 707, Loss: 4.135144650936127, Final Batch Loss: 0.9462711215019226\n",
      "Epoch 708, Loss: 4.157490134239197, Final Batch Loss: 0.9571792483329773\n",
      "Epoch 709, Loss: 4.014263808727264, Final Batch Loss: 0.8677568435668945\n",
      "Epoch 710, Loss: 4.131896138191223, Final Batch Loss: 1.0289801359176636\n",
      "Epoch 711, Loss: 3.660758912563324, Final Batch Loss: 0.4936060905456543\n",
      "Epoch 712, Loss: 4.236860632896423, Final Batch Loss: 0.9661427736282349\n",
      "Epoch 713, Loss: 4.019576013088226, Final Batch Loss: 0.8826040029525757\n",
      "Epoch 714, Loss: 3.6090879440307617, Final Batch Loss: 0.5358545184135437\n",
      "Epoch 715, Loss: 3.98769748210907, Final Batch Loss: 0.6344371438026428\n",
      "Epoch 716, Loss: 3.9796640276908875, Final Batch Loss: 0.8007297515869141\n",
      "Epoch 717, Loss: 3.798169195652008, Final Batch Loss: 0.6574521660804749\n",
      "Epoch 718, Loss: 3.737703859806061, Final Batch Loss: 0.5971691012382507\n",
      "Epoch 719, Loss: 3.7115352153778076, Final Batch Loss: 0.6224393248558044\n",
      "Epoch 720, Loss: 3.8650338649749756, Final Batch Loss: 0.7165656089782715\n",
      "Epoch 721, Loss: 3.9544904828071594, Final Batch Loss: 0.6850000023841858\n",
      "Epoch 722, Loss: 4.274085164070129, Final Batch Loss: 1.053954005241394\n",
      "Epoch 723, Loss: 4.242712557315826, Final Batch Loss: 1.0997215509414673\n",
      "Epoch 724, Loss: 3.6815769374370575, Final Batch Loss: 0.44398877024650574\n",
      "Epoch 725, Loss: 3.7440256476402283, Final Batch Loss: 0.6132839918136597\n",
      "Epoch 726, Loss: 3.8731496930122375, Final Batch Loss: 0.7030700445175171\n",
      "Epoch 727, Loss: 3.601430594921112, Final Batch Loss: 0.5472087264060974\n",
      "Epoch 728, Loss: 4.080770969390869, Final Batch Loss: 0.945184588432312\n",
      "Epoch 729, Loss: 3.563843458890915, Final Batch Loss: 0.4695657193660736\n",
      "Epoch 730, Loss: 3.870618999004364, Final Batch Loss: 0.8784146308898926\n",
      "Epoch 731, Loss: 3.4871323108673096, Final Batch Loss: 0.40579599142074585\n",
      "Epoch 732, Loss: 4.228258490562439, Final Batch Loss: 1.1511423587799072\n",
      "Epoch 733, Loss: 4.126778542995453, Final Batch Loss: 1.0113887786865234\n",
      "Epoch 734, Loss: 4.3652374148368835, Final Batch Loss: 1.2521097660064697\n",
      "Epoch 735, Loss: 4.098435819149017, Final Batch Loss: 0.9749705195426941\n",
      "Epoch 736, Loss: 4.066655933856964, Final Batch Loss: 0.8146343231201172\n",
      "Epoch 737, Loss: 4.268399715423584, Final Batch Loss: 1.130516767501831\n",
      "Epoch 738, Loss: 4.05635803937912, Final Batch Loss: 0.9301682114601135\n",
      "Epoch 739, Loss: 3.7760645747184753, Final Batch Loss: 0.5139241814613342\n",
      "Epoch 740, Loss: 4.021645605564117, Final Batch Loss: 0.8724560141563416\n",
      "Epoch 741, Loss: 3.82138192653656, Final Batch Loss: 0.5862484574317932\n",
      "Epoch 742, Loss: 3.9392046332359314, Final Batch Loss: 0.8637086153030396\n",
      "Epoch 743, Loss: 3.719542145729065, Final Batch Loss: 0.6371298432350159\n",
      "Epoch 744, Loss: 3.90023410320282, Final Batch Loss: 0.9576091170310974\n",
      "Epoch 745, Loss: 3.706241488456726, Final Batch Loss: 0.6247416734695435\n",
      "Epoch 746, Loss: 4.528947472572327, Final Batch Loss: 1.5373687744140625\n",
      "Epoch 747, Loss: 3.7109328508377075, Final Batch Loss: 0.47988027334213257\n",
      "Epoch 748, Loss: 3.8164918422698975, Final Batch Loss: 0.7468357682228088\n",
      "Epoch 749, Loss: 3.795410633087158, Final Batch Loss: 0.6688750386238098\n",
      "Epoch 750, Loss: 4.130583584308624, Final Batch Loss: 0.9935826659202576\n",
      "Epoch 751, Loss: 3.7416443824768066, Final Batch Loss: 0.6274823546409607\n",
      "Epoch 752, Loss: 4.140028655529022, Final Batch Loss: 1.0585145950317383\n",
      "Epoch 753, Loss: 3.819813847541809, Final Batch Loss: 0.7462019324302673\n",
      "Epoch 754, Loss: 3.7587133646011353, Final Batch Loss: 0.6385064125061035\n",
      "Epoch 755, Loss: 3.861647307872772, Final Batch Loss: 0.7840991020202637\n",
      "Epoch 756, Loss: 4.093765199184418, Final Batch Loss: 1.0561977624893188\n",
      "Epoch 757, Loss: 3.7144221663475037, Final Batch Loss: 0.638115406036377\n",
      "Epoch 758, Loss: 3.845223128795624, Final Batch Loss: 0.6610087752342224\n",
      "Epoch 759, Loss: 3.93698787689209, Final Batch Loss: 0.9317580461502075\n",
      "Epoch 760, Loss: 3.880698025226593, Final Batch Loss: 0.7476770281791687\n",
      "Epoch 761, Loss: 3.7675670385360718, Final Batch Loss: 0.740788996219635\n",
      "Epoch 762, Loss: 3.878086805343628, Final Batch Loss: 0.8244616389274597\n",
      "Epoch 763, Loss: 4.23484992980957, Final Batch Loss: 1.076711893081665\n",
      "Epoch 764, Loss: 3.712453842163086, Final Batch Loss: 0.6178790330886841\n",
      "Epoch 765, Loss: 3.9097829461097717, Final Batch Loss: 0.8025860786437988\n",
      "Epoch 766, Loss: 3.9003198742866516, Final Batch Loss: 0.7326056361198425\n",
      "Epoch 767, Loss: 4.023912072181702, Final Batch Loss: 0.8129789233207703\n",
      "Epoch 768, Loss: 3.604690134525299, Final Batch Loss: 0.6032401919364929\n",
      "Epoch 769, Loss: 3.577313780784607, Final Batch Loss: 0.6157898902893066\n",
      "Epoch 770, Loss: 3.72445285320282, Final Batch Loss: 0.707226574420929\n",
      "Epoch 771, Loss: 3.457892507314682, Final Batch Loss: 0.39493927359580994\n",
      "Epoch 772, Loss: 3.651045501232147, Final Batch Loss: 0.7263150215148926\n",
      "Epoch 773, Loss: 3.5386339128017426, Final Batch Loss: 0.4813505709171295\n",
      "Epoch 774, Loss: 4.221323549747467, Final Batch Loss: 1.0336650609970093\n",
      "Epoch 775, Loss: 4.030083358287811, Final Batch Loss: 0.931613028049469\n",
      "Epoch 776, Loss: 3.5780671536922455, Final Batch Loss: 0.34517815709114075\n",
      "Epoch 777, Loss: 3.884398937225342, Final Batch Loss: 0.7786129117012024\n",
      "Epoch 778, Loss: 3.9909496307373047, Final Batch Loss: 0.8320881724357605\n",
      "Epoch 779, Loss: 3.965162694454193, Final Batch Loss: 0.8425260186195374\n",
      "Epoch 780, Loss: 3.7072638869285583, Final Batch Loss: 0.6431334614753723\n",
      "Epoch 781, Loss: 3.7518430948257446, Final Batch Loss: 0.5741594433784485\n",
      "Epoch 782, Loss: 3.9495270252227783, Final Batch Loss: 0.8602254986763\n",
      "Epoch 783, Loss: 3.544398546218872, Final Batch Loss: 0.4990299344062805\n",
      "Epoch 784, Loss: 3.9580662846565247, Final Batch Loss: 0.8763046860694885\n",
      "Epoch 785, Loss: 3.6589436531066895, Final Batch Loss: 0.6037747263908386\n",
      "Epoch 786, Loss: 4.688393473625183, Final Batch Loss: 1.715702772140503\n",
      "Epoch 787, Loss: 3.7201794385910034, Final Batch Loss: 0.6073163747787476\n",
      "Epoch 788, Loss: 3.8133533596992493, Final Batch Loss: 0.6949443221092224\n",
      "Epoch 789, Loss: 3.8259265422821045, Final Batch Loss: 0.6089274287223816\n",
      "Epoch 790, Loss: 3.71598082780838, Final Batch Loss: 0.6512236595153809\n",
      "Epoch 791, Loss: 3.970157504081726, Final Batch Loss: 0.8190602660179138\n",
      "Epoch 792, Loss: 3.3195317685604095, Final Batch Loss: 0.2702048718929291\n",
      "Epoch 793, Loss: 3.61773020029068, Final Batch Loss: 0.5466695427894592\n",
      "Epoch 794, Loss: 4.350445628166199, Final Batch Loss: 1.1557750701904297\n",
      "Epoch 795, Loss: 3.7104466557502747, Final Batch Loss: 0.6774995923042297\n",
      "Epoch 796, Loss: 3.919246017932892, Final Batch Loss: 0.9090602993965149\n",
      "Epoch 797, Loss: 3.940401256084442, Final Batch Loss: 0.8863525390625\n",
      "Epoch 798, Loss: 4.2858410477638245, Final Batch Loss: 1.3705883026123047\n",
      "Epoch 799, Loss: 3.8549915552139282, Final Batch Loss: 0.8868101835250854\n",
      "Epoch 800, Loss: 3.7889626026153564, Final Batch Loss: 0.5880715250968933\n",
      "Epoch 801, Loss: 3.782732129096985, Final Batch Loss: 0.6980937123298645\n",
      "Epoch 802, Loss: 4.149337291717529, Final Batch Loss: 1.1360160112380981\n",
      "Epoch 803, Loss: 3.8868024349212646, Final Batch Loss: 0.7028217911720276\n",
      "Epoch 804, Loss: 3.520208090543747, Final Batch Loss: 0.45192262530326843\n",
      "Epoch 805, Loss: 3.564897269010544, Final Batch Loss: 0.49183353781700134\n",
      "Epoch 806, Loss: 3.6047123670578003, Final Batch Loss: 0.5310793519020081\n",
      "Epoch 807, Loss: 3.7775996923446655, Final Batch Loss: 0.6824203729629517\n",
      "Epoch 808, Loss: 3.8117005228996277, Final Batch Loss: 0.8458385467529297\n",
      "Epoch 809, Loss: 4.397205293178558, Final Batch Loss: 1.469788908958435\n",
      "Epoch 810, Loss: 3.7408546209335327, Final Batch Loss: 0.7204445004463196\n",
      "Epoch 811, Loss: 3.6727095246315002, Final Batch Loss: 0.5877918004989624\n",
      "Epoch 812, Loss: 3.656643331050873, Final Batch Loss: 0.6372905373573303\n",
      "Epoch 813, Loss: 4.180275082588196, Final Batch Loss: 1.1829864978790283\n",
      "Epoch 814, Loss: 3.6079744696617126, Final Batch Loss: 0.5650231242179871\n",
      "Epoch 815, Loss: 3.7603179216384888, Final Batch Loss: 0.7014840245246887\n",
      "Epoch 816, Loss: 3.697979986667633, Final Batch Loss: 0.8064799308776855\n",
      "Epoch 817, Loss: 3.921709716320038, Final Batch Loss: 0.9289714694023132\n",
      "Epoch 818, Loss: 3.6328012347221375, Final Batch Loss: 0.5944368243217468\n",
      "Epoch 819, Loss: 3.6940742135047913, Final Batch Loss: 0.7642019987106323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820, Loss: 3.791377007961273, Final Batch Loss: 0.7132692337036133\n",
      "Epoch 821, Loss: 3.7487659454345703, Final Batch Loss: 0.7621158361434937\n",
      "Epoch 822, Loss: 3.752943694591522, Final Batch Loss: 0.7294084429740906\n",
      "Epoch 823, Loss: 3.888041079044342, Final Batch Loss: 0.7347227931022644\n",
      "Epoch 824, Loss: 3.6558903455734253, Final Batch Loss: 0.5415778160095215\n",
      "Epoch 825, Loss: 3.6807985305786133, Final Batch Loss: 0.6976938843727112\n",
      "Epoch 826, Loss: 3.641580641269684, Final Batch Loss: 0.6323002576828003\n",
      "Epoch 827, Loss: 4.0167805552482605, Final Batch Loss: 0.8522879481315613\n",
      "Epoch 828, Loss: 3.5855239033699036, Final Batch Loss: 0.633875846862793\n",
      "Epoch 829, Loss: 3.6128897070884705, Final Batch Loss: 0.5592778921127319\n",
      "Epoch 830, Loss: 3.466208755970001, Final Batch Loss: 0.5313628315925598\n",
      "Epoch 831, Loss: 3.502655506134033, Final Batch Loss: 0.43618232011795044\n",
      "Epoch 832, Loss: 3.7487178444862366, Final Batch Loss: 0.7574121356010437\n",
      "Epoch 833, Loss: 3.8132161498069763, Final Batch Loss: 0.8092261552810669\n",
      "Epoch 834, Loss: 3.678260326385498, Final Batch Loss: 0.660934567451477\n",
      "Epoch 835, Loss: 3.8181846141815186, Final Batch Loss: 0.7137817740440369\n",
      "Epoch 836, Loss: 3.8988897800445557, Final Batch Loss: 0.7634883522987366\n",
      "Epoch 837, Loss: 3.917297601699829, Final Batch Loss: 0.8842554688453674\n",
      "Epoch 838, Loss: 3.421466678380966, Final Batch Loss: 0.3876253664493561\n",
      "Epoch 839, Loss: 3.5067708790302277, Final Batch Loss: 0.4459063708782196\n",
      "Epoch 840, Loss: 4.284824311733246, Final Batch Loss: 1.2445684671401978\n",
      "Epoch 841, Loss: 3.795211672782898, Final Batch Loss: 0.7770275473594666\n",
      "Epoch 842, Loss: 4.017672657966614, Final Batch Loss: 1.0095759630203247\n",
      "Epoch 843, Loss: 3.852832794189453, Final Batch Loss: 0.7680832743644714\n",
      "Epoch 844, Loss: 4.328906774520874, Final Batch Loss: 1.2873395681381226\n",
      "Epoch 845, Loss: 3.7338231801986694, Final Batch Loss: 0.7360841631889343\n",
      "Epoch 846, Loss: 3.510404944419861, Final Batch Loss: 0.5389889478683472\n",
      "Epoch 847, Loss: 3.502607226371765, Final Batch Loss: 0.5174327492713928\n",
      "Epoch 848, Loss: 3.95152884721756, Final Batch Loss: 0.9050463438034058\n",
      "Epoch 849, Loss: 3.6478918194770813, Final Batch Loss: 0.6691340804100037\n",
      "Epoch 850, Loss: 3.608348846435547, Final Batch Loss: 0.6449898481369019\n",
      "Epoch 851, Loss: 3.7328564524650574, Final Batch Loss: 0.7828148603439331\n",
      "Epoch 852, Loss: 3.7725398540496826, Final Batch Loss: 0.7956895232200623\n",
      "Epoch 853, Loss: 3.9664825797080994, Final Batch Loss: 0.9884052872657776\n",
      "Epoch 854, Loss: 3.532834976911545, Final Batch Loss: 0.46334370970726013\n",
      "Epoch 855, Loss: 3.869267225265503, Final Batch Loss: 0.796125054359436\n",
      "Epoch 856, Loss: 3.668669819831848, Final Batch Loss: 0.7184857726097107\n",
      "Epoch 857, Loss: 3.6244285702705383, Final Batch Loss: 0.5639907121658325\n",
      "Epoch 858, Loss: 3.400442510843277, Final Batch Loss: 0.39192840456962585\n",
      "Epoch 859, Loss: 3.662906765937805, Final Batch Loss: 0.7258830070495605\n",
      "Epoch 860, Loss: 3.306784600019455, Final Batch Loss: 0.4052952229976654\n",
      "Epoch 861, Loss: 3.3723022639751434, Final Batch Loss: 0.3657732903957367\n",
      "Epoch 862, Loss: 3.393050193786621, Final Batch Loss: 0.41433024406433105\n",
      "Epoch 863, Loss: 3.6909337043762207, Final Batch Loss: 0.795931339263916\n",
      "Epoch 864, Loss: 3.668194055557251, Final Batch Loss: 0.6780358552932739\n",
      "Epoch 865, Loss: 3.193674549460411, Final Batch Loss: 0.19314490258693695\n",
      "Epoch 866, Loss: 3.772302746772766, Final Batch Loss: 0.7351120710372925\n",
      "Epoch 867, Loss: 3.3698047399520874, Final Batch Loss: 0.5251346826553345\n",
      "Epoch 868, Loss: 3.689586341381073, Final Batch Loss: 0.7793477773666382\n",
      "Epoch 869, Loss: 3.564901053905487, Final Batch Loss: 0.69707852602005\n",
      "Epoch 870, Loss: 3.651065707206726, Final Batch Loss: 0.6409257054328918\n",
      "Epoch 871, Loss: 3.383222609758377, Final Batch Loss: 0.364957720041275\n",
      "Epoch 872, Loss: 3.9261613488197327, Final Batch Loss: 0.9594970345497131\n",
      "Epoch 873, Loss: 4.357316255569458, Final Batch Loss: 1.3289575576782227\n",
      "Epoch 874, Loss: 3.802011013031006, Final Batch Loss: 0.8166416883468628\n",
      "Epoch 875, Loss: 3.6312752962112427, Final Batch Loss: 0.7268973588943481\n",
      "Epoch 876, Loss: 3.620859444141388, Final Batch Loss: 0.7093587517738342\n",
      "Epoch 877, Loss: 3.81251323223114, Final Batch Loss: 0.8106594681739807\n",
      "Epoch 878, Loss: 3.5880951285362244, Final Batch Loss: 0.7205021977424622\n",
      "Epoch 879, Loss: 3.561407446861267, Final Batch Loss: 0.5819136500358582\n",
      "Epoch 880, Loss: 3.764224350452423, Final Batch Loss: 0.849125325679779\n",
      "Epoch 881, Loss: 3.479644000530243, Final Batch Loss: 0.5816067457199097\n",
      "Epoch 882, Loss: 3.790833532810211, Final Batch Loss: 0.8197100758552551\n",
      "Epoch 883, Loss: 3.7813528180122375, Final Batch Loss: 0.8675671815872192\n",
      "Epoch 884, Loss: 3.6022515892982483, Final Batch Loss: 0.792427659034729\n",
      "Epoch 885, Loss: 3.4711875915527344, Final Batch Loss: 0.44315868616104126\n",
      "Epoch 886, Loss: 4.048077285289764, Final Batch Loss: 1.128682255744934\n",
      "Epoch 887, Loss: 4.160394310951233, Final Batch Loss: 1.0917986631393433\n",
      "Epoch 888, Loss: 4.03067272901535, Final Batch Loss: 0.9418842196464539\n",
      "Epoch 889, Loss: 3.5848572850227356, Final Batch Loss: 0.6534067988395691\n",
      "Epoch 890, Loss: 3.755088448524475, Final Batch Loss: 0.8556790351867676\n",
      "Epoch 891, Loss: 3.362007647752762, Final Batch Loss: 0.3364323675632477\n",
      "Epoch 892, Loss: 4.154755413532257, Final Batch Loss: 1.183924913406372\n",
      "Epoch 893, Loss: 3.800550401210785, Final Batch Loss: 0.8743425011634827\n",
      "Epoch 894, Loss: 3.4261574447155, Final Batch Loss: 0.33229056000709534\n",
      "Epoch 895, Loss: 3.88687402009964, Final Batch Loss: 0.9915578961372375\n",
      "Epoch 896, Loss: 3.4028970897197723, Final Batch Loss: 0.4631657302379608\n",
      "Epoch 897, Loss: 3.605813980102539, Final Batch Loss: 0.6154398322105408\n",
      "Epoch 898, Loss: 3.273471862077713, Final Batch Loss: 0.3800746500492096\n",
      "Epoch 899, Loss: 3.9810847640037537, Final Batch Loss: 0.972802996635437\n",
      "Epoch 900, Loss: 3.5801175832748413, Final Batch Loss: 0.6775166392326355\n",
      "Epoch 901, Loss: 3.807171106338501, Final Batch Loss: 0.8268418312072754\n",
      "Epoch 902, Loss: 3.6004573106765747, Final Batch Loss: 0.6853094696998596\n",
      "Epoch 903, Loss: 3.61207115650177, Final Batch Loss: 0.6878060698509216\n",
      "Epoch 904, Loss: 3.777581512928009, Final Batch Loss: 0.8461838960647583\n",
      "Epoch 905, Loss: 3.8806466460227966, Final Batch Loss: 0.8305643796920776\n",
      "Epoch 906, Loss: 3.9420876502990723, Final Batch Loss: 0.9326211214065552\n",
      "Epoch 907, Loss: 3.871287524700165, Final Batch Loss: 0.8256649374961853\n",
      "Epoch 908, Loss: 3.467563509941101, Final Batch Loss: 0.6161559224128723\n",
      "Epoch 909, Loss: 3.5974104404449463, Final Batch Loss: 0.758585512638092\n",
      "Epoch 910, Loss: 3.835764229297638, Final Batch Loss: 0.8284444808959961\n",
      "Epoch 911, Loss: 3.7025821805000305, Final Batch Loss: 0.8203237652778625\n",
      "Epoch 912, Loss: 3.871563673019409, Final Batch Loss: 0.9932931661605835\n",
      "Epoch 913, Loss: 3.8739342093467712, Final Batch Loss: 0.9036663770675659\n",
      "Epoch 914, Loss: 3.901254117488861, Final Batch Loss: 0.9651702642440796\n",
      "Epoch 915, Loss: 3.809618055820465, Final Batch Loss: 0.790538489818573\n",
      "Epoch 916, Loss: 3.783503293991089, Final Batch Loss: 0.8357542753219604\n",
      "Epoch 917, Loss: 3.3743784725666046, Final Batch Loss: 0.4524090588092804\n",
      "Epoch 918, Loss: 3.1643165349960327, Final Batch Loss: 0.2657923102378845\n",
      "Epoch 919, Loss: 3.708976447582245, Final Batch Loss: 0.885720431804657\n",
      "Epoch 920, Loss: 3.757350444793701, Final Batch Loss: 0.7066814303398132\n",
      "Epoch 921, Loss: 3.613344371318817, Final Batch Loss: 0.7321565747261047\n",
      "Epoch 922, Loss: 3.9688936471939087, Final Batch Loss: 1.081203579902649\n",
      "Epoch 923, Loss: 3.5084357261657715, Final Batch Loss: 0.5893619656562805\n",
      "Epoch 924, Loss: 3.729203760623932, Final Batch Loss: 0.7303107380867004\n",
      "Epoch 925, Loss: 3.8507052659988403, Final Batch Loss: 0.9027594327926636\n",
      "Epoch 926, Loss: 3.460322618484497, Final Batch Loss: 0.5553027987480164\n",
      "Epoch 927, Loss: 3.670229196548462, Final Batch Loss: 0.6623379588127136\n",
      "Epoch 928, Loss: 3.5728309750556946, Final Batch Loss: 0.6057958006858826\n",
      "Epoch 929, Loss: 4.090249955654144, Final Batch Loss: 1.1592363119125366\n",
      "Epoch 930, Loss: 3.5353753566741943, Final Batch Loss: 0.5967410802841187\n",
      "Epoch 931, Loss: 3.7736178636550903, Final Batch Loss: 0.8723679780960083\n",
      "Epoch 932, Loss: 3.6954398155212402, Final Batch Loss: 0.765424907207489\n",
      "Epoch 933, Loss: 4.043388783931732, Final Batch Loss: 1.0130670070648193\n",
      "Epoch 934, Loss: 3.538628041744232, Final Batch Loss: 0.6582989692687988\n",
      "Epoch 935, Loss: 3.9083192348480225, Final Batch Loss: 0.9553443789482117\n",
      "Epoch 936, Loss: 3.3018397092819214, Final Batch Loss: 0.40379709005355835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937, Loss: 3.4295803904533386, Final Batch Loss: 0.6062701344490051\n",
      "Epoch 938, Loss: 3.8772425055503845, Final Batch Loss: 0.8490621447563171\n",
      "Epoch 939, Loss: 3.6905933022499084, Final Batch Loss: 0.7695117592811584\n",
      "Epoch 940, Loss: 3.4806708097457886, Final Batch Loss: 0.5665688514709473\n",
      "Epoch 941, Loss: 3.6083062291145325, Final Batch Loss: 0.7024011611938477\n",
      "Epoch 942, Loss: 3.552562892436981, Final Batch Loss: 0.6204442977905273\n",
      "Epoch 943, Loss: 3.875252425670624, Final Batch Loss: 0.9076539874076843\n",
      "Epoch 944, Loss: 3.4571574926376343, Final Batch Loss: 0.5569911599159241\n",
      "Epoch 945, Loss: 4.097477734088898, Final Batch Loss: 1.201568365097046\n",
      "Epoch 946, Loss: 3.879823923110962, Final Batch Loss: 0.9287351965904236\n",
      "Epoch 947, Loss: 4.232167422771454, Final Batch Loss: 1.3573027849197388\n",
      "Epoch 948, Loss: 3.4748406410217285, Final Batch Loss: 0.5303671360015869\n",
      "Epoch 949, Loss: 3.788563311100006, Final Batch Loss: 0.8729733824729919\n",
      "Epoch 950, Loss: 4.067832112312317, Final Batch Loss: 1.1463449001312256\n",
      "Epoch 951, Loss: 3.438748776912689, Final Batch Loss: 0.5422195792198181\n",
      "Epoch 952, Loss: 3.827636182308197, Final Batch Loss: 0.9466965794563293\n",
      "Epoch 953, Loss: 3.7786887288093567, Final Batch Loss: 0.8805212378501892\n",
      "Epoch 954, Loss: 3.6397359371185303, Final Batch Loss: 0.7678393721580505\n",
      "Epoch 955, Loss: 3.334709107875824, Final Batch Loss: 0.35849183797836304\n",
      "Epoch 956, Loss: 3.272581249475479, Final Batch Loss: 0.42732998728752136\n",
      "Epoch 957, Loss: 3.8521345257759094, Final Batch Loss: 0.9263203740119934\n",
      "Epoch 958, Loss: 3.8530052304267883, Final Batch Loss: 0.8831502199172974\n",
      "Epoch 959, Loss: 3.4055580496788025, Final Batch Loss: 0.5950554013252258\n",
      "Epoch 960, Loss: 3.2846228778362274, Final Batch Loss: 0.3355692923069\n",
      "Epoch 961, Loss: 4.062162518501282, Final Batch Loss: 1.0725842714309692\n",
      "Epoch 962, Loss: 3.4477056860923767, Final Batch Loss: 0.6317335963249207\n",
      "Epoch 963, Loss: 3.2678018510341644, Final Batch Loss: 0.40084436535835266\n",
      "Epoch 964, Loss: 3.4214850664138794, Final Batch Loss: 0.5447065830230713\n",
      "Epoch 965, Loss: 3.4167327284812927, Final Batch Loss: 0.5513256788253784\n",
      "Epoch 966, Loss: 4.016553819179535, Final Batch Loss: 1.1009584665298462\n",
      "Epoch 967, Loss: 3.7874311804771423, Final Batch Loss: 0.9133396148681641\n",
      "Epoch 968, Loss: 3.5040064454078674, Final Batch Loss: 0.6162823438644409\n",
      "Epoch 969, Loss: 3.2429847419261932, Final Batch Loss: 0.3910277783870697\n",
      "Epoch 970, Loss: 3.5222030878067017, Final Batch Loss: 0.6335700750350952\n",
      "Epoch 971, Loss: 3.6511118412017822, Final Batch Loss: 0.8604413270950317\n",
      "Epoch 972, Loss: 3.8536194562911987, Final Batch Loss: 0.9798818826675415\n",
      "Epoch 973, Loss: 3.653159976005554, Final Batch Loss: 0.7452408671379089\n",
      "Epoch 974, Loss: 3.8538337349891663, Final Batch Loss: 1.0459556579589844\n",
      "Epoch 975, Loss: 3.66942036151886, Final Batch Loss: 0.7429799437522888\n",
      "Epoch 976, Loss: 3.6191934943199158, Final Batch Loss: 0.8597038388252258\n",
      "Epoch 977, Loss: 3.7891509532928467, Final Batch Loss: 0.7954009175300598\n",
      "Epoch 978, Loss: 3.2419135868549347, Final Batch Loss: 0.4071778357028961\n",
      "Epoch 979, Loss: 3.4106727838516235, Final Batch Loss: 0.567828357219696\n",
      "Epoch 980, Loss: 3.3103693425655365, Final Batch Loss: 0.4973931610584259\n",
      "Epoch 981, Loss: 3.4813623428344727, Final Batch Loss: 0.62412029504776\n",
      "Epoch 982, Loss: 3.9317389726638794, Final Batch Loss: 1.0417912006378174\n",
      "Epoch 983, Loss: 3.5747175812721252, Final Batch Loss: 0.754388689994812\n",
      "Epoch 984, Loss: 3.602985382080078, Final Batch Loss: 0.7556101083755493\n",
      "Epoch 985, Loss: 3.3991262912750244, Final Batch Loss: 0.6086373329162598\n",
      "Epoch 986, Loss: 3.4958027601242065, Final Batch Loss: 0.6549614667892456\n",
      "Epoch 987, Loss: 3.5487892627716064, Final Batch Loss: 0.600068211555481\n",
      "Epoch 988, Loss: 4.038854539394379, Final Batch Loss: 1.123404622077942\n",
      "Epoch 989, Loss: 3.5725935101509094, Final Batch Loss: 0.7055693864822388\n",
      "Epoch 990, Loss: 3.752696394920349, Final Batch Loss: 0.7777512669563293\n",
      "Epoch 991, Loss: 3.833274722099304, Final Batch Loss: 0.9243994355201721\n",
      "Epoch 992, Loss: 3.5012430548667908, Final Batch Loss: 0.6404238939285278\n",
      "Epoch 993, Loss: 3.333178371191025, Final Batch Loss: 0.4916621148586273\n",
      "Epoch 994, Loss: 3.308845967054367, Final Batch Loss: 0.49826255440711975\n",
      "Epoch 995, Loss: 3.8264747262001038, Final Batch Loss: 0.9833664894104004\n",
      "Epoch 996, Loss: 3.6416831016540527, Final Batch Loss: 0.7746977806091309\n",
      "Epoch 997, Loss: 3.3432272374629974, Final Batch Loss: 0.3702698051929474\n",
      "Epoch 998, Loss: 3.2456589937210083, Final Batch Loss: 0.4981994032859802\n",
      "Epoch 999, Loss: 3.450000524520874, Final Batch Loss: 0.5901719927787781\n",
      "Epoch 1000, Loss: 3.199828863143921, Final Batch Loss: 0.4247627258300781\n",
      "Epoch 1001, Loss: 3.6063365936279297, Final Batch Loss: 0.7591785192489624\n",
      "Epoch 1002, Loss: 3.394867241382599, Final Batch Loss: 0.6159490942955017\n",
      "Epoch 1003, Loss: 3.431790590286255, Final Batch Loss: 0.4478641152381897\n",
      "Epoch 1004, Loss: 3.5137410163879395, Final Batch Loss: 0.6704573631286621\n",
      "Epoch 1005, Loss: 3.5839694142341614, Final Batch Loss: 0.7256942987442017\n",
      "Epoch 1006, Loss: 3.324915111064911, Final Batch Loss: 0.3568890690803528\n",
      "Epoch 1007, Loss: 3.5218082666397095, Final Batch Loss: 0.706633448600769\n",
      "Epoch 1008, Loss: 3.2392264306545258, Final Batch Loss: 0.3366054594516754\n",
      "Epoch 1009, Loss: 3.220614016056061, Final Batch Loss: 0.37360984086990356\n",
      "Epoch 1010, Loss: 3.2641725838184357, Final Batch Loss: 0.41904571652412415\n",
      "Epoch 1011, Loss: 3.5126912593841553, Final Batch Loss: 0.7069078683853149\n",
      "Epoch 1012, Loss: 4.17251992225647, Final Batch Loss: 1.3727476596832275\n",
      "Epoch 1013, Loss: 3.3966139554977417, Final Batch Loss: 0.5444770455360413\n",
      "Epoch 1014, Loss: 3.581143319606781, Final Batch Loss: 0.7318614721298218\n",
      "Epoch 1015, Loss: 3.4930044412612915, Final Batch Loss: 0.7407902479171753\n",
      "Epoch 1016, Loss: 3.569675862789154, Final Batch Loss: 0.5926347374916077\n",
      "Epoch 1017, Loss: 3.6715539693832397, Final Batch Loss: 0.8708405494689941\n",
      "Epoch 1018, Loss: 3.6614280939102173, Final Batch Loss: 0.7175801992416382\n",
      "Epoch 1019, Loss: 3.8876630663871765, Final Batch Loss: 0.9342421889305115\n",
      "Epoch 1020, Loss: 3.5495917201042175, Final Batch Loss: 0.8121310472488403\n",
      "Epoch 1021, Loss: 3.771807849407196, Final Batch Loss: 0.9826759099960327\n",
      "Epoch 1022, Loss: 3.920090973377228, Final Batch Loss: 1.13701593875885\n",
      "Epoch 1023, Loss: 3.6375250816345215, Final Batch Loss: 0.6650689244270325\n",
      "Epoch 1024, Loss: 4.241474688053131, Final Batch Loss: 1.313642144203186\n",
      "Epoch 1025, Loss: 3.6949132680892944, Final Batch Loss: 0.8758940100669861\n",
      "Epoch 1026, Loss: 3.880370616912842, Final Batch Loss: 0.9818665385246277\n",
      "Epoch 1027, Loss: 3.620041847229004, Final Batch Loss: 0.7098687291145325\n",
      "Epoch 1028, Loss: 3.6658347845077515, Final Batch Loss: 0.8130879402160645\n",
      "Epoch 1029, Loss: 3.7238988280296326, Final Batch Loss: 0.8996550440788269\n",
      "Epoch 1030, Loss: 3.301444172859192, Final Batch Loss: 0.5718423128128052\n",
      "Epoch 1031, Loss: 3.456901431083679, Final Batch Loss: 0.5502898097038269\n",
      "Epoch 1032, Loss: 3.9944345355033875, Final Batch Loss: 1.0572272539138794\n",
      "Epoch 1033, Loss: 3.4469897747039795, Final Batch Loss: 0.6606622338294983\n",
      "Epoch 1034, Loss: 3.699345290660858, Final Batch Loss: 0.810970664024353\n",
      "Epoch 1035, Loss: 3.0360798239707947, Final Batch Loss: 0.26637357473373413\n",
      "Epoch 1036, Loss: 3.572513222694397, Final Batch Loss: 0.768302321434021\n",
      "Epoch 1037, Loss: 3.9082581400871277, Final Batch Loss: 1.1901681423187256\n",
      "Epoch 1038, Loss: 3.5556719303131104, Final Batch Loss: 0.7984277009963989\n",
      "Epoch 1039, Loss: 3.639816641807556, Final Batch Loss: 0.7737433314323425\n",
      "Epoch 1040, Loss: 3.6384934186935425, Final Batch Loss: 0.7406424283981323\n",
      "Epoch 1041, Loss: 3.484847128391266, Final Batch Loss: 0.7032042741775513\n",
      "Epoch 1042, Loss: 3.5568907260894775, Final Batch Loss: 0.7666357159614563\n",
      "Epoch 1043, Loss: 3.7599068880081177, Final Batch Loss: 0.8372655510902405\n",
      "Epoch 1044, Loss: 3.380526542663574, Final Batch Loss: 0.513574481010437\n",
      "Epoch 1045, Loss: 3.330447733402252, Final Batch Loss: 0.5086804628372192\n",
      "Epoch 1046, Loss: 3.650591790676117, Final Batch Loss: 0.8132373690605164\n",
      "Epoch 1047, Loss: 3.648345410823822, Final Batch Loss: 0.8505753874778748\n",
      "Epoch 1048, Loss: 3.5021037459373474, Final Batch Loss: 0.6848083138465881\n",
      "Epoch 1049, Loss: 3.581253409385681, Final Batch Loss: 0.8133800625801086\n",
      "Epoch 1050, Loss: 3.5586511492729187, Final Batch Loss: 0.6312471628189087\n",
      "Epoch 1051, Loss: 3.637982487678528, Final Batch Loss: 0.7809979319572449\n",
      "Epoch 1052, Loss: 3.3776761889457703, Final Batch Loss: 0.5911955237388611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1053, Loss: 3.781038224697113, Final Batch Loss: 0.8794142007827759\n",
      "Epoch 1054, Loss: 3.147393137216568, Final Batch Loss: 0.35621097683906555\n",
      "Epoch 1055, Loss: 3.5654938220977783, Final Batch Loss: 0.6788902282714844\n",
      "Epoch 1056, Loss: 3.4108216762542725, Final Batch Loss: 0.5537389516830444\n",
      "Epoch 1057, Loss: 3.6663018465042114, Final Batch Loss: 0.8218411803245544\n",
      "Epoch 1058, Loss: 3.249554753303528, Final Batch Loss: 0.45759207010269165\n",
      "Epoch 1059, Loss: 3.1471154987812042, Final Batch Loss: 0.3273750841617584\n",
      "Epoch 1060, Loss: 3.1945159137248993, Final Batch Loss: 0.422819048166275\n",
      "Epoch 1061, Loss: 3.7930113673210144, Final Batch Loss: 0.9059012532234192\n",
      "Epoch 1062, Loss: 3.203436315059662, Final Batch Loss: 0.4274601936340332\n",
      "Epoch 1063, Loss: 3.3724753856658936, Final Batch Loss: 0.5928431749343872\n",
      "Epoch 1064, Loss: 3.2211863100528717, Final Batch Loss: 0.4560997188091278\n",
      "Epoch 1065, Loss: 3.591982424259186, Final Batch Loss: 0.7933317422866821\n",
      "Epoch 1066, Loss: 3.7660807371139526, Final Batch Loss: 1.0420891046524048\n",
      "Epoch 1067, Loss: 3.5565131306648254, Final Batch Loss: 0.7095116376876831\n",
      "Epoch 1068, Loss: 3.425310254096985, Final Batch Loss: 0.668520450592041\n",
      "Epoch 1069, Loss: 3.178694039583206, Final Batch Loss: 0.45736828446388245\n",
      "Epoch 1070, Loss: 3.4955244660377502, Final Batch Loss: 0.8227480053901672\n",
      "Epoch 1071, Loss: 3.462174892425537, Final Batch Loss: 0.63849937915802\n",
      "Epoch 1072, Loss: 3.29619038105011, Final Batch Loss: 0.4535769820213318\n",
      "Epoch 1073, Loss: 3.450634241104126, Final Batch Loss: 0.6533258557319641\n",
      "Epoch 1074, Loss: 3.5694225430488586, Final Batch Loss: 0.7530911564826965\n",
      "Epoch 1075, Loss: 3.4785993099212646, Final Batch Loss: 0.6325498223304749\n",
      "Epoch 1076, Loss: 3.575683891773224, Final Batch Loss: 0.7901089787483215\n",
      "Epoch 1077, Loss: 3.7600513696670532, Final Batch Loss: 0.9971655011177063\n",
      "Epoch 1078, Loss: 3.504801094532013, Final Batch Loss: 0.7456092238426208\n",
      "Epoch 1079, Loss: 3.6167773604393005, Final Batch Loss: 0.9125577807426453\n",
      "Epoch 1080, Loss: 3.6286491751670837, Final Batch Loss: 0.74366295337677\n",
      "Epoch 1081, Loss: 3.3245869874954224, Final Batch Loss: 0.5344077348709106\n",
      "Epoch 1082, Loss: 3.6491698026657104, Final Batch Loss: 0.8162552118301392\n",
      "Epoch 1083, Loss: 3.506462812423706, Final Batch Loss: 0.6948550343513489\n",
      "Epoch 1084, Loss: 3.459734261035919, Final Batch Loss: 0.7491879463195801\n",
      "Epoch 1085, Loss: 3.5756553411483765, Final Batch Loss: 0.7910801768302917\n",
      "Epoch 1086, Loss: 3.604027509689331, Final Batch Loss: 0.8199009299278259\n",
      "Epoch 1087, Loss: 3.2657183408737183, Final Batch Loss: 0.4233514666557312\n",
      "Epoch 1088, Loss: 3.841200590133667, Final Batch Loss: 0.9928156137466431\n",
      "Epoch 1089, Loss: 3.6865533590316772, Final Batch Loss: 0.9485802054405212\n",
      "Epoch 1090, Loss: 3.4225574135780334, Final Batch Loss: 0.6805218458175659\n",
      "Epoch 1091, Loss: 3.6283568143844604, Final Batch Loss: 0.7491297721862793\n",
      "Epoch 1092, Loss: 3.321498453617096, Final Batch Loss: 0.50398850440979\n",
      "Epoch 1093, Loss: 3.517167806625366, Final Batch Loss: 0.7824639081954956\n",
      "Epoch 1094, Loss: 3.6013630032539368, Final Batch Loss: 0.8407958745956421\n",
      "Epoch 1095, Loss: 3.4851680397987366, Final Batch Loss: 0.7531542778015137\n",
      "Epoch 1096, Loss: 3.3483577966690063, Final Batch Loss: 0.5807546377182007\n",
      "Epoch 1097, Loss: 3.1135933101177216, Final Batch Loss: 0.3248220384120941\n",
      "Epoch 1098, Loss: 4.049136638641357, Final Batch Loss: 1.2461941242218018\n",
      "Epoch 1099, Loss: 3.3232966661453247, Final Batch Loss: 0.5458741188049316\n",
      "Epoch 1100, Loss: 3.628871977329254, Final Batch Loss: 0.8006211519241333\n",
      "Epoch 1101, Loss: 3.4120558500289917, Final Batch Loss: 0.6284645795822144\n",
      "Epoch 1102, Loss: 3.685521125793457, Final Batch Loss: 0.7250184416770935\n",
      "Epoch 1103, Loss: 3.2985831201076508, Final Batch Loss: 0.491414338350296\n",
      "Epoch 1104, Loss: 3.4157771468162537, Final Batch Loss: 0.7258457541465759\n",
      "Epoch 1105, Loss: 3.3159729838371277, Final Batch Loss: 0.5795052647590637\n",
      "Epoch 1106, Loss: 3.0836126804351807, Final Batch Loss: 0.4685838222503662\n",
      "Epoch 1107, Loss: 2.9689495861530304, Final Batch Loss: 0.1990080177783966\n",
      "Epoch 1108, Loss: 3.357004940509796, Final Batch Loss: 0.4511301517486572\n",
      "Epoch 1109, Loss: 3.5427831411361694, Final Batch Loss: 0.802270233631134\n",
      "Epoch 1110, Loss: 3.311752200126648, Final Batch Loss: 0.6785687804222107\n",
      "Epoch 1111, Loss: 3.699446201324463, Final Batch Loss: 0.8810232877731323\n",
      "Epoch 1112, Loss: 3.3268532752990723, Final Batch Loss: 0.5912267565727234\n",
      "Epoch 1113, Loss: 3.490156352519989, Final Batch Loss: 0.7899239659309387\n",
      "Epoch 1114, Loss: 3.5011101961135864, Final Batch Loss: 0.8791516423225403\n",
      "Epoch 1115, Loss: 3.6230247616767883, Final Batch Loss: 0.9074311852455139\n",
      "Epoch 1116, Loss: 3.426614373922348, Final Batch Loss: 0.47691401839256287\n",
      "Epoch 1117, Loss: 3.557323634624481, Final Batch Loss: 0.7704505324363708\n",
      "Epoch 1118, Loss: 3.341191351413727, Final Batch Loss: 0.5352995991706848\n",
      "Epoch 1119, Loss: 3.6722058057785034, Final Batch Loss: 0.8520178198814392\n",
      "Epoch 1120, Loss: 3.3541508316993713, Final Batch Loss: 0.6945726275444031\n",
      "Epoch 1121, Loss: 3.285913348197937, Final Batch Loss: 0.5269317626953125\n",
      "Epoch 1122, Loss: 3.4982064366340637, Final Batch Loss: 0.6828441023826599\n",
      "Epoch 1123, Loss: 3.2131366431713104, Final Batch Loss: 0.48216840624809265\n",
      "Epoch 1124, Loss: 3.1725302636623383, Final Batch Loss: 0.4297840893268585\n",
      "Epoch 1125, Loss: 3.657632291316986, Final Batch Loss: 0.9581945538520813\n",
      "Epoch 1126, Loss: 3.2281453609466553, Final Batch Loss: 0.40109783411026\n",
      "Epoch 1127, Loss: 3.412836968898773, Final Batch Loss: 0.6621332168579102\n",
      "Epoch 1128, Loss: 3.3604431748390198, Final Batch Loss: 0.6487354040145874\n",
      "Epoch 1129, Loss: 3.7145529985427856, Final Batch Loss: 0.7730850577354431\n",
      "Epoch 1130, Loss: 3.622257173061371, Final Batch Loss: 0.831107497215271\n",
      "Epoch 1131, Loss: 4.018421173095703, Final Batch Loss: 1.1910181045532227\n",
      "Epoch 1132, Loss: 3.466081976890564, Final Batch Loss: 0.6842687726020813\n",
      "Epoch 1133, Loss: 3.3742839694023132, Final Batch Loss: 0.5399529933929443\n",
      "Epoch 1134, Loss: 3.0574986934661865, Final Batch Loss: 0.2521842122077942\n",
      "Epoch 1135, Loss: 3.57718026638031, Final Batch Loss: 0.6946460604667664\n",
      "Epoch 1136, Loss: 4.1262319684028625, Final Batch Loss: 1.5634231567382812\n",
      "Epoch 1137, Loss: 3.7743366956710815, Final Batch Loss: 0.9170619249343872\n",
      "Epoch 1138, Loss: 3.885156512260437, Final Batch Loss: 0.8784250020980835\n",
      "Epoch 1139, Loss: 3.3022273778915405, Final Batch Loss: 0.5142148733139038\n",
      "Epoch 1140, Loss: 3.2646784484386444, Final Batch Loss: 0.43285778164863586\n",
      "Epoch 1141, Loss: 3.6106977462768555, Final Batch Loss: 0.7349284291267395\n",
      "Epoch 1142, Loss: 3.03190541267395, Final Batch Loss: 0.3582611680030823\n",
      "Epoch 1143, Loss: 3.039268136024475, Final Batch Loss: 0.36324816942214966\n",
      "Epoch 1144, Loss: 3.4299614429473877, Final Batch Loss: 0.6383180618286133\n",
      "Epoch 1145, Loss: 3.4389083981513977, Final Batch Loss: 0.6762203574180603\n",
      "Epoch 1146, Loss: 3.2497599720954895, Final Batch Loss: 0.5876479744911194\n",
      "Epoch 1147, Loss: 3.6276671290397644, Final Batch Loss: 0.9450865387916565\n",
      "Epoch 1148, Loss: 3.1311068534851074, Final Batch Loss: 0.3837628960609436\n",
      "Epoch 1149, Loss: 3.524499773979187, Final Batch Loss: 0.6388238668441772\n",
      "Epoch 1150, Loss: 3.240373909473419, Final Batch Loss: 0.5824111700057983\n",
      "Epoch 1151, Loss: 3.287733018398285, Final Batch Loss: 0.585066020488739\n",
      "Epoch 1152, Loss: 3.2312813997268677, Final Batch Loss: 0.5025371313095093\n",
      "Epoch 1153, Loss: 3.624957501888275, Final Batch Loss: 0.8370033502578735\n",
      "Epoch 1154, Loss: 3.1792691349983215, Final Batch Loss: 0.46157097816467285\n",
      "Epoch 1155, Loss: 3.628320276737213, Final Batch Loss: 0.9454780220985413\n",
      "Epoch 1156, Loss: 3.2556049823760986, Final Batch Loss: 0.5460041165351868\n",
      "Epoch 1157, Loss: 3.2148824334144592, Final Batch Loss: 0.50072181224823\n",
      "Epoch 1158, Loss: 3.3307936787605286, Final Batch Loss: 0.6503734588623047\n",
      "Epoch 1159, Loss: 3.6583959460258484, Final Batch Loss: 0.946527361869812\n",
      "Epoch 1160, Loss: 3.28472700715065, Final Batch Loss: 0.46683362126350403\n",
      "Epoch 1161, Loss: 3.371619462966919, Final Batch Loss: 0.6074419021606445\n",
      "Epoch 1162, Loss: 3.080085039138794, Final Batch Loss: 0.4771077036857605\n",
      "Epoch 1163, Loss: 3.063039004802704, Final Batch Loss: 0.3748035430908203\n",
      "Epoch 1164, Loss: 3.3862000703811646, Final Batch Loss: 0.6486167907714844\n",
      "Epoch 1165, Loss: 3.947323203086853, Final Batch Loss: 1.0844734907150269\n",
      "Epoch 1166, Loss: 3.122005373239517, Final Batch Loss: 0.42150941491127014\n",
      "Epoch 1167, Loss: 3.4879499673843384, Final Batch Loss: 0.8395373225212097\n",
      "Epoch 1168, Loss: 3.3598825931549072, Final Batch Loss: 0.6510197520256042\n",
      "Epoch 1169, Loss: 3.6486071348190308, Final Batch Loss: 0.9991666078567505\n",
      "Epoch 1170, Loss: 3.6188029050827026, Final Batch Loss: 0.8564237356185913\n",
      "Epoch 1171, Loss: 3.3844656944274902, Final Batch Loss: 0.65208899974823\n",
      "Epoch 1172, Loss: 3.4325197339057922, Final Batch Loss: 0.6926303505897522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1173, Loss: 2.9945525228977203, Final Batch Loss: 0.38030120730400085\n",
      "Epoch 1174, Loss: 3.035810738801956, Final Batch Loss: 0.40317943692207336\n",
      "Epoch 1175, Loss: 3.11273193359375, Final Batch Loss: 0.5894951224327087\n",
      "Epoch 1176, Loss: 3.289579451084137, Final Batch Loss: 0.662388265132904\n",
      "Epoch 1177, Loss: 3.5929214358329773, Final Batch Loss: 0.8785557150840759\n",
      "Epoch 1178, Loss: 3.196907699108124, Final Batch Loss: 0.5758424997329712\n",
      "Epoch 1179, Loss: 3.4527087211608887, Final Batch Loss: 0.6943592429161072\n",
      "Epoch 1180, Loss: 3.7720581889152527, Final Batch Loss: 0.9919842481613159\n",
      "Epoch 1181, Loss: 3.3559889793395996, Final Batch Loss: 0.5792588591575623\n",
      "Epoch 1182, Loss: 3.686074197292328, Final Batch Loss: 0.9917047619819641\n",
      "Epoch 1183, Loss: 3.467587947845459, Final Batch Loss: 0.6163110733032227\n",
      "Epoch 1184, Loss: 3.260232627391815, Final Batch Loss: 0.590081512928009\n",
      "Epoch 1185, Loss: 3.039773568511009, Final Batch Loss: 0.24718032777309418\n",
      "Epoch 1186, Loss: 3.3176847100257874, Final Batch Loss: 0.553828775882721\n",
      "Epoch 1187, Loss: 3.2981194853782654, Final Batch Loss: 0.557969868183136\n",
      "Epoch 1188, Loss: 3.1175697445869446, Final Batch Loss: 0.5539870262145996\n",
      "Epoch 1189, Loss: 3.568471610546112, Final Batch Loss: 0.8387187123298645\n",
      "Epoch 1190, Loss: 3.428073823451996, Final Batch Loss: 0.7701185941696167\n",
      "Epoch 1191, Loss: 3.382336378097534, Final Batch Loss: 0.6638554930686951\n",
      "Epoch 1192, Loss: 3.5300424695014954, Final Batch Loss: 0.8448603749275208\n",
      "Epoch 1193, Loss: 3.3813636898994446, Final Batch Loss: 0.7682731747627258\n",
      "Epoch 1194, Loss: 3.1172274947166443, Final Batch Loss: 0.42197275161743164\n",
      "Epoch 1195, Loss: 3.984015166759491, Final Batch Loss: 1.2479490041732788\n",
      "Epoch 1196, Loss: 2.948923707008362, Final Batch Loss: 0.2936258316040039\n",
      "Epoch 1197, Loss: 3.86201810836792, Final Batch Loss: 1.1210166215896606\n",
      "Epoch 1198, Loss: 3.5192342400550842, Final Batch Loss: 0.807282030582428\n",
      "Epoch 1199, Loss: 3.8043352365493774, Final Batch Loss: 1.1625412702560425\n",
      "Epoch 1200, Loss: 3.0475648939609528, Final Batch Loss: 0.434244304895401\n",
      "Epoch 1201, Loss: 3.286455512046814, Final Batch Loss: 0.5482167601585388\n",
      "Epoch 1202, Loss: 3.4132511615753174, Final Batch Loss: 0.7516111135482788\n",
      "Epoch 1203, Loss: 3.1899842023849487, Final Batch Loss: 0.5287019610404968\n",
      "Epoch 1204, Loss: 3.127849280834198, Final Batch Loss: 0.4333246350288391\n",
      "Epoch 1205, Loss: 3.2065303027629852, Final Batch Loss: 0.4863329827785492\n",
      "Epoch 1206, Loss: 3.087850332260132, Final Batch Loss: 0.41788387298583984\n",
      "Epoch 1207, Loss: 3.346301794052124, Final Batch Loss: 0.7079240679740906\n",
      "Epoch 1208, Loss: 3.237795114517212, Final Batch Loss: 0.4865111708641052\n",
      "Epoch 1209, Loss: 3.2897176146507263, Final Batch Loss: 0.6044744253158569\n",
      "Epoch 1210, Loss: 3.211243987083435, Final Batch Loss: 0.6718662977218628\n",
      "Epoch 1211, Loss: 3.215425044298172, Final Batch Loss: 0.4455864131450653\n",
      "Epoch 1212, Loss: 3.333004117012024, Final Batch Loss: 0.6402652859687805\n",
      "Epoch 1213, Loss: 3.549472391605377, Final Batch Loss: 0.8360666632652283\n",
      "Epoch 1214, Loss: 3.2525006532669067, Final Batch Loss: 0.6754559278488159\n",
      "Epoch 1215, Loss: 3.472038209438324, Final Batch Loss: 0.7016120553016663\n",
      "Epoch 1216, Loss: 3.2405493557453156, Final Batch Loss: 0.42767050862312317\n",
      "Epoch 1217, Loss: 3.2504236698150635, Final Batch Loss: 0.5034626126289368\n",
      "Epoch 1218, Loss: 3.2331843078136444, Final Batch Loss: 0.4960027039051056\n",
      "Epoch 1219, Loss: 3.353644847869873, Final Batch Loss: 0.654884934425354\n",
      "Epoch 1220, Loss: 3.8741270899772644, Final Batch Loss: 1.1817158460617065\n",
      "Epoch 1221, Loss: 3.047089099884033, Final Batch Loss: 0.42872148752212524\n",
      "Epoch 1222, Loss: 3.1430835127830505, Final Batch Loss: 0.46154332160949707\n",
      "Epoch 1223, Loss: 3.7473796010017395, Final Batch Loss: 0.9023035764694214\n",
      "Epoch 1224, Loss: 3.56328421831131, Final Batch Loss: 0.9520735144615173\n",
      "Epoch 1225, Loss: 3.537048876285553, Final Batch Loss: 0.8222590088844299\n",
      "Epoch 1226, Loss: 3.2996352314949036, Final Batch Loss: 0.6495302319526672\n",
      "Epoch 1227, Loss: 3.0024961829185486, Final Batch Loss: 0.25798624753952026\n",
      "Epoch 1228, Loss: 3.1887928545475006, Final Batch Loss: 0.47030285000801086\n",
      "Epoch 1229, Loss: 3.488112986087799, Final Batch Loss: 0.7540323138237\n",
      "Epoch 1230, Loss: 3.3280640244483948, Final Batch Loss: 0.5734663605690002\n",
      "Epoch 1231, Loss: 3.5530307292938232, Final Batch Loss: 0.8990244269371033\n",
      "Epoch 1232, Loss: 3.007289797067642, Final Batch Loss: 0.40884026885032654\n",
      "Epoch 1233, Loss: 3.043215662240982, Final Batch Loss: 0.29909971356391907\n",
      "Epoch 1234, Loss: 3.068956196308136, Final Batch Loss: 0.44360023736953735\n",
      "Epoch 1235, Loss: 3.5005545616149902, Final Batch Loss: 0.8475107550621033\n",
      "Epoch 1236, Loss: 3.294550597667694, Final Batch Loss: 0.6011815667152405\n",
      "Epoch 1237, Loss: 3.5951730608940125, Final Batch Loss: 0.7971706390380859\n",
      "Epoch 1238, Loss: 3.3920551538467407, Final Batch Loss: 0.6414218544960022\n",
      "Epoch 1239, Loss: 3.1261635422706604, Final Batch Loss: 0.46049875020980835\n",
      "Epoch 1240, Loss: 3.117052048444748, Final Batch Loss: 0.4346722662448883\n",
      "Epoch 1241, Loss: 3.715457558631897, Final Batch Loss: 0.9710299372673035\n",
      "Epoch 1242, Loss: 3.6538735032081604, Final Batch Loss: 0.9518269896507263\n",
      "Epoch 1243, Loss: 2.9752086997032166, Final Batch Loss: 0.3720690608024597\n",
      "Epoch 1244, Loss: 3.258954405784607, Final Batch Loss: 0.6533605456352234\n",
      "Epoch 1245, Loss: 3.0100395381450653, Final Batch Loss: 0.3358161747455597\n",
      "Epoch 1246, Loss: 3.447601795196533, Final Batch Loss: 0.7181326150894165\n",
      "Epoch 1247, Loss: 3.6206712126731873, Final Batch Loss: 1.0111274719238281\n",
      "Epoch 1248, Loss: 3.289086699485779, Final Batch Loss: 0.624659538269043\n",
      "Epoch 1249, Loss: 3.5111804008483887, Final Batch Loss: 0.877930760383606\n",
      "Epoch 1250, Loss: 3.259167194366455, Final Batch Loss: 0.6880456209182739\n",
      "Epoch 1251, Loss: 3.1931115984916687, Final Batch Loss: 0.577639102935791\n",
      "Epoch 1252, Loss: 3.3506534099578857, Final Batch Loss: 0.7467807531356812\n",
      "Epoch 1253, Loss: 3.116113930940628, Final Batch Loss: 0.4489916265010834\n",
      "Epoch 1254, Loss: 3.4688872694969177, Final Batch Loss: 0.8235788345336914\n",
      "Epoch 1255, Loss: 3.3353740572929382, Final Batch Loss: 0.7403259873390198\n",
      "Epoch 1256, Loss: 3.4606159925460815, Final Batch Loss: 0.7768092751502991\n",
      "Epoch 1257, Loss: 2.947225421667099, Final Batch Loss: 0.34646371006965637\n",
      "Epoch 1258, Loss: 3.239399790763855, Final Batch Loss: 0.6653230786323547\n",
      "Epoch 1259, Loss: 3.7684789896011353, Final Batch Loss: 1.1785402297973633\n",
      "Epoch 1260, Loss: 3.1667124330997467, Final Batch Loss: 0.43476077914237976\n",
      "Epoch 1261, Loss: 3.3813960552215576, Final Batch Loss: 0.7253212928771973\n",
      "Epoch 1262, Loss: 3.34347003698349, Final Batch Loss: 0.7304369211196899\n",
      "Epoch 1263, Loss: 3.3235241770744324, Final Batch Loss: 0.6949498057365417\n",
      "Epoch 1264, Loss: 3.2946205139160156, Final Batch Loss: 0.5617339015007019\n",
      "Epoch 1265, Loss: 3.6068214774131775, Final Batch Loss: 1.0132941007614136\n",
      "Epoch 1266, Loss: 3.4538822770118713, Final Batch Loss: 0.734097421169281\n",
      "Epoch 1267, Loss: 2.9933010041713715, Final Batch Loss: 0.4040248692035675\n",
      "Epoch 1268, Loss: 3.3247867822647095, Final Batch Loss: 0.5944060683250427\n",
      "Epoch 1269, Loss: 3.4296661019325256, Final Batch Loss: 0.7201662063598633\n",
      "Epoch 1270, Loss: 3.7350950837135315, Final Batch Loss: 1.0388175249099731\n",
      "Epoch 1271, Loss: 3.1008404791355133, Final Batch Loss: 0.47738656401634216\n",
      "Epoch 1272, Loss: 3.3502833247184753, Final Batch Loss: 0.756523609161377\n",
      "Epoch 1273, Loss: 3.3542850613594055, Final Batch Loss: 0.7569379806518555\n",
      "Epoch 1274, Loss: 3.3229517340660095, Final Batch Loss: 0.6654481887817383\n",
      "Epoch 1275, Loss: 3.7288578152656555, Final Batch Loss: 1.1409876346588135\n",
      "Epoch 1276, Loss: 3.0728319585323334, Final Batch Loss: 0.4914383590221405\n",
      "Epoch 1277, Loss: 3.4551652669906616, Final Batch Loss: 0.7624810338020325\n",
      "Epoch 1278, Loss: 3.2822194695472717, Final Batch Loss: 0.5230923891067505\n",
      "Epoch 1279, Loss: 3.4730011224746704, Final Batch Loss: 0.9484825134277344\n",
      "Epoch 1280, Loss: 3.099954217672348, Final Batch Loss: 0.41681137681007385\n",
      "Epoch 1281, Loss: 3.1611265540122986, Final Batch Loss: 0.5602614283561707\n",
      "Epoch 1282, Loss: 3.660529613494873, Final Batch Loss: 0.9416181445121765\n",
      "Epoch 1283, Loss: 3.267771393060684, Final Batch Loss: 0.4709862768650055\n",
      "Epoch 1284, Loss: 3.31055748462677, Final Batch Loss: 0.7572434544563293\n",
      "Epoch 1285, Loss: 2.97886061668396, Final Batch Loss: 0.34408754110336304\n",
      "Epoch 1286, Loss: 3.1369011402130127, Final Batch Loss: 0.6737068891525269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1287, Loss: 3.4660778045654297, Final Batch Loss: 0.8757268190383911\n",
      "Epoch 1288, Loss: 3.218647301197052, Final Batch Loss: 0.635757565498352\n",
      "Epoch 1289, Loss: 3.261207103729248, Final Batch Loss: 0.6029008626937866\n",
      "Epoch 1290, Loss: 3.8028029799461365, Final Batch Loss: 1.057334303855896\n",
      "Epoch 1291, Loss: 3.153068780899048, Final Batch Loss: 0.4071173667907715\n",
      "Epoch 1292, Loss: 3.8213337063789368, Final Batch Loss: 0.9986096620559692\n",
      "Epoch 1293, Loss: 3.015254497528076, Final Batch Loss: 0.4015932083129883\n",
      "Epoch 1294, Loss: 3.478261411190033, Final Batch Loss: 0.8037468791007996\n",
      "Epoch 1295, Loss: 3.587004244327545, Final Batch Loss: 0.9832166433334351\n",
      "Epoch 1296, Loss: 3.2281169295310974, Final Batch Loss: 0.6709204912185669\n",
      "Epoch 1297, Loss: 3.35213041305542, Final Batch Loss: 0.7335442304611206\n",
      "Epoch 1298, Loss: 3.529087245464325, Final Batch Loss: 0.923160195350647\n",
      "Epoch 1299, Loss: 3.0233704149723053, Final Batch Loss: 0.3183499872684479\n",
      "Epoch 1300, Loss: 3.292298436164856, Final Batch Loss: 0.6906131505966187\n",
      "Epoch 1301, Loss: 3.130467474460602, Final Batch Loss: 0.5468081831932068\n",
      "Epoch 1302, Loss: 3.007445126771927, Final Batch Loss: 0.36501386761665344\n",
      "Epoch 1303, Loss: 3.105019599199295, Final Batch Loss: 0.43514302372932434\n",
      "Epoch 1304, Loss: 3.407436728477478, Final Batch Loss: 0.8351296782493591\n",
      "Epoch 1305, Loss: 3.1827070116996765, Final Batch Loss: 0.46813011169433594\n",
      "Epoch 1306, Loss: 2.935529440641403, Final Batch Loss: 0.4454343616962433\n",
      "Epoch 1307, Loss: 3.0471091270446777, Final Batch Loss: 0.5404170155525208\n",
      "Epoch 1308, Loss: 3.3466907739639282, Final Batch Loss: 0.5977030396461487\n",
      "Epoch 1309, Loss: 3.234816014766693, Final Batch Loss: 0.6774254441261292\n",
      "Epoch 1310, Loss: 2.9397806525230408, Final Batch Loss: 0.3077123761177063\n",
      "Epoch 1311, Loss: 2.8332643657922745, Final Batch Loss: 0.2341756969690323\n",
      "Epoch 1312, Loss: 3.788800060749054, Final Batch Loss: 1.0938951969146729\n",
      "Epoch 1313, Loss: 3.2816330790519714, Final Batch Loss: 0.6660524010658264\n",
      "Epoch 1314, Loss: 3.3801074028015137, Final Batch Loss: 0.8007240295410156\n",
      "Epoch 1315, Loss: 3.2812864184379578, Final Batch Loss: 0.6825733184814453\n",
      "Epoch 1316, Loss: 3.309259831905365, Final Batch Loss: 0.7669455409049988\n",
      "Epoch 1317, Loss: 3.551019310951233, Final Batch Loss: 0.9744481444358826\n",
      "Epoch 1318, Loss: 3.1588565707206726, Final Batch Loss: 0.6546706557273865\n",
      "Epoch 1319, Loss: 2.8016373217105865, Final Batch Loss: 0.22872045636177063\n",
      "Epoch 1320, Loss: 3.273564636707306, Final Batch Loss: 0.6156463027000427\n",
      "Epoch 1321, Loss: 2.8556972295045853, Final Batch Loss: 0.2456413060426712\n",
      "Epoch 1322, Loss: 3.5493205189704895, Final Batch Loss: 0.99435955286026\n",
      "Epoch 1323, Loss: 3.3831987977027893, Final Batch Loss: 0.7214682698249817\n",
      "Epoch 1324, Loss: 3.4348666071891785, Final Batch Loss: 0.8443664908409119\n",
      "Epoch 1325, Loss: 3.3467766642570496, Final Batch Loss: 0.6188478469848633\n",
      "Epoch 1326, Loss: 2.8463810831308365, Final Batch Loss: 0.16262878477573395\n",
      "Epoch 1327, Loss: 3.185292899608612, Final Batch Loss: 0.5805333256721497\n",
      "Epoch 1328, Loss: 3.197208881378174, Final Batch Loss: 0.5692077279090881\n",
      "Epoch 1329, Loss: 3.229724198579788, Final Batch Loss: 0.4746731221675873\n",
      "Epoch 1330, Loss: 3.253359079360962, Final Batch Loss: 0.569758415222168\n",
      "Epoch 1331, Loss: 3.3369653820991516, Final Batch Loss: 0.7113493084907532\n",
      "Epoch 1332, Loss: 3.1916436553001404, Final Batch Loss: 0.4543116092681885\n",
      "Epoch 1333, Loss: 3.3130781650543213, Final Batch Loss: 0.7235340476036072\n",
      "Epoch 1334, Loss: 3.209290564060211, Final Batch Loss: 0.5366536378860474\n",
      "Epoch 1335, Loss: 2.828011393547058, Final Batch Loss: 0.23619818687438965\n",
      "Epoch 1336, Loss: 2.9063519537448883, Final Batch Loss: 0.47754982113838196\n",
      "Epoch 1337, Loss: 3.326789677143097, Final Batch Loss: 0.8042976260185242\n",
      "Epoch 1338, Loss: 3.1870316863059998, Final Batch Loss: 0.572797954082489\n",
      "Epoch 1339, Loss: 3.4997183680534363, Final Batch Loss: 1.0174427032470703\n",
      "Epoch 1340, Loss: 3.089442193508148, Final Batch Loss: 0.583858072757721\n",
      "Epoch 1341, Loss: 2.9324463307857513, Final Batch Loss: 0.40313759446144104\n",
      "Epoch 1342, Loss: 3.4804012775421143, Final Batch Loss: 0.7922204732894897\n",
      "Epoch 1343, Loss: 3.4478358030319214, Final Batch Loss: 0.8668131828308105\n",
      "Epoch 1344, Loss: 3.635570228099823, Final Batch Loss: 0.9587289690971375\n",
      "Epoch 1345, Loss: 3.226994752883911, Final Batch Loss: 0.5872666239738464\n",
      "Epoch 1346, Loss: 2.950083404779434, Final Batch Loss: 0.3106057941913605\n",
      "Epoch 1347, Loss: 2.830919474363327, Final Batch Loss: 0.21417352557182312\n",
      "Epoch 1348, Loss: 4.111448228359222, Final Batch Loss: 1.5637720823287964\n",
      "Epoch 1349, Loss: 3.2945427298545837, Final Batch Loss: 0.5658615827560425\n",
      "Epoch 1350, Loss: 3.2702062129974365, Final Batch Loss: 0.6651734709739685\n",
      "Epoch 1351, Loss: 2.7055719643831253, Final Batch Loss: 0.2458217293024063\n",
      "Epoch 1352, Loss: 3.2748501896858215, Final Batch Loss: 0.6571747660636902\n",
      "Epoch 1353, Loss: 3.4431838393211365, Final Batch Loss: 0.8338583707809448\n",
      "Epoch 1354, Loss: 3.2447261810302734, Final Batch Loss: 0.6926849484443665\n",
      "Epoch 1355, Loss: 3.0666324198246, Final Batch Loss: 0.45792844891548157\n",
      "Epoch 1356, Loss: 3.0450388193130493, Final Batch Loss: 0.5383512377738953\n",
      "Epoch 1357, Loss: 2.8317569494247437, Final Batch Loss: 0.3500449061393738\n",
      "Epoch 1358, Loss: 3.287416696548462, Final Batch Loss: 0.7024650573730469\n",
      "Epoch 1359, Loss: 3.323591470718384, Final Batch Loss: 0.8629850745201111\n",
      "Epoch 1360, Loss: 3.6766952872276306, Final Batch Loss: 1.1064879894256592\n",
      "Epoch 1361, Loss: 3.355410933494568, Final Batch Loss: 0.744184672832489\n",
      "Epoch 1362, Loss: 3.190167725086212, Final Batch Loss: 0.6052409410476685\n",
      "Epoch 1363, Loss: 3.0998313426971436, Final Batch Loss: 0.5014649033546448\n",
      "Epoch 1364, Loss: 3.2130857706069946, Final Batch Loss: 0.6497343182563782\n",
      "Epoch 1365, Loss: 3.055680215358734, Final Batch Loss: 0.6065226793289185\n",
      "Epoch 1366, Loss: 3.438007116317749, Final Batch Loss: 0.88285893201828\n",
      "Epoch 1367, Loss: 3.1491090655326843, Final Batch Loss: 0.5642115473747253\n",
      "Epoch 1368, Loss: 3.01106333732605, Final Batch Loss: 0.3923620581626892\n",
      "Epoch 1369, Loss: 3.032469719648361, Final Batch Loss: 0.3806562125682831\n",
      "Epoch 1370, Loss: 3.0481699109077454, Final Batch Loss: 0.45429450273513794\n",
      "Epoch 1371, Loss: 3.0990319550037384, Final Batch Loss: 0.48432907462120056\n",
      "Epoch 1372, Loss: 3.165514051914215, Final Batch Loss: 0.6976953148841858\n",
      "Epoch 1373, Loss: 2.9983710050582886, Final Batch Loss: 0.4636666774749756\n",
      "Epoch 1374, Loss: 3.2468583583831787, Final Batch Loss: 0.6756807565689087\n",
      "Epoch 1375, Loss: 3.011779010295868, Final Batch Loss: 0.633406937122345\n",
      "Epoch 1376, Loss: 3.186493694782257, Final Batch Loss: 0.6747394800186157\n",
      "Epoch 1377, Loss: 2.805266708135605, Final Batch Loss: 0.2785893380641937\n",
      "Epoch 1378, Loss: 3.1734848022460938, Final Batch Loss: 0.6311144828796387\n",
      "Epoch 1379, Loss: 3.1463852524757385, Final Batch Loss: 0.56008380651474\n",
      "Epoch 1380, Loss: 3.025646060705185, Final Batch Loss: 0.47343435883522034\n",
      "Epoch 1381, Loss: 3.4303387999534607, Final Batch Loss: 0.687301516532898\n",
      "Epoch 1382, Loss: 3.1581020057201385, Final Batch Loss: 0.4960298240184784\n",
      "Epoch 1383, Loss: 3.7080302238464355, Final Batch Loss: 0.9967895150184631\n",
      "Epoch 1384, Loss: 3.5869513154029846, Final Batch Loss: 1.0265743732452393\n",
      "Epoch 1385, Loss: 2.921693801879883, Final Batch Loss: 0.4724249839782715\n",
      "Epoch 1386, Loss: 2.969287097454071, Final Batch Loss: 0.5026021003723145\n",
      "Epoch 1387, Loss: 3.124753177165985, Final Batch Loss: 0.644037663936615\n",
      "Epoch 1388, Loss: 3.2755143642425537, Final Batch Loss: 0.7101765275001526\n",
      "Epoch 1389, Loss: 3.0240595936775208, Final Batch Loss: 0.5043115615844727\n",
      "Epoch 1390, Loss: 2.894389420747757, Final Batch Loss: 0.25814762711524963\n",
      "Epoch 1391, Loss: 3.309213936328888, Final Batch Loss: 0.7637681365013123\n",
      "Epoch 1392, Loss: 3.0279805064201355, Final Batch Loss: 0.3950057029724121\n",
      "Epoch 1393, Loss: 2.9180510342121124, Final Batch Loss: 0.2560904920101166\n",
      "Epoch 1394, Loss: 3.248895585536957, Final Batch Loss: 0.7141467332839966\n",
      "Epoch 1395, Loss: 3.0769912004470825, Final Batch Loss: 0.5704553723335266\n",
      "Epoch 1396, Loss: 3.517231583595276, Final Batch Loss: 0.9757890105247498\n",
      "Epoch 1397, Loss: 3.5017486810684204, Final Batch Loss: 0.8982513546943665\n",
      "Epoch 1398, Loss: 3.015717387199402, Final Batch Loss: 0.46007293462753296\n",
      "Epoch 1399, Loss: 3.0757909417152405, Final Batch Loss: 0.4344162344932556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1400, Loss: 3.040546238422394, Final Batch Loss: 0.6083307266235352\n",
      "Epoch 1401, Loss: 2.860153943300247, Final Batch Loss: 0.4131336510181427\n",
      "Epoch 1402, Loss: 3.221031963825226, Final Batch Loss: 0.7141131162643433\n",
      "Epoch 1403, Loss: 2.989686042070389, Final Batch Loss: 0.4947817623615265\n",
      "Epoch 1404, Loss: 3.2467974424362183, Final Batch Loss: 0.9675068855285645\n",
      "Epoch 1405, Loss: 3.200821876525879, Final Batch Loss: 0.736971914768219\n",
      "Epoch 1406, Loss: 3.2979312539100647, Final Batch Loss: 0.7429202198982239\n",
      "Epoch 1407, Loss: 2.835888296365738, Final Batch Loss: 0.35247573256492615\n",
      "Epoch 1408, Loss: 3.3813496232032776, Final Batch Loss: 0.8980316519737244\n",
      "Epoch 1409, Loss: 3.0610570907592773, Final Batch Loss: 0.5226970314979553\n",
      "Epoch 1410, Loss: 2.7745648324489594, Final Batch Loss: 0.31997695565223694\n",
      "Epoch 1411, Loss: 3.044649660587311, Final Batch Loss: 0.5270557999610901\n",
      "Epoch 1412, Loss: 3.2985668778419495, Final Batch Loss: 0.8140258193016052\n",
      "Epoch 1413, Loss: 3.0191555619239807, Final Batch Loss: 0.5913594961166382\n",
      "Epoch 1414, Loss: 2.866010993719101, Final Batch Loss: 0.2871885597705841\n",
      "Epoch 1415, Loss: 3.3147332668304443, Final Batch Loss: 0.7791094183921814\n",
      "Epoch 1416, Loss: 3.372639000415802, Final Batch Loss: 0.9205349087715149\n",
      "Epoch 1417, Loss: 3.0215662717819214, Final Batch Loss: 0.46345287561416626\n",
      "Epoch 1418, Loss: 2.9686706960201263, Final Batch Loss: 0.4745502769947052\n",
      "Epoch 1419, Loss: 3.03563916683197, Final Batch Loss: 0.48142772912979126\n",
      "Epoch 1420, Loss: 3.2281187772750854, Final Batch Loss: 0.7952772974967957\n",
      "Epoch 1421, Loss: 3.63213974237442, Final Batch Loss: 1.1494091749191284\n",
      "Epoch 1422, Loss: 2.8437651097774506, Final Batch Loss: 0.2139212191104889\n",
      "Epoch 1423, Loss: 3.0109089016914368, Final Batch Loss: 0.5147042274475098\n",
      "Epoch 1424, Loss: 3.0208300948143005, Final Batch Loss: 0.47615504264831543\n",
      "Epoch 1425, Loss: 2.8838053345680237, Final Batch Loss: 0.40862035751342773\n",
      "Epoch 1426, Loss: 2.8534757494926453, Final Batch Loss: 0.3202952742576599\n",
      "Epoch 1427, Loss: 3.0894886553287506, Final Batch Loss: 0.4755893647670746\n",
      "Epoch 1428, Loss: 2.97209233045578, Final Batch Loss: 0.49657177925109863\n",
      "Epoch 1429, Loss: 3.623777985572815, Final Batch Loss: 1.138687252998352\n",
      "Epoch 1430, Loss: 3.2851507663726807, Final Batch Loss: 0.773963451385498\n",
      "Epoch 1431, Loss: 2.81127667427063, Final Batch Loss: 0.2774907350540161\n",
      "Epoch 1432, Loss: 2.9240547716617584, Final Batch Loss: 0.3322587311267853\n",
      "Epoch 1433, Loss: 3.3555389046669006, Final Batch Loss: 0.8297826051712036\n",
      "Epoch 1434, Loss: 3.4052135348320007, Final Batch Loss: 0.9448262453079224\n",
      "Epoch 1435, Loss: 3.246160626411438, Final Batch Loss: 0.7255517244338989\n",
      "Epoch 1436, Loss: 2.812272012233734, Final Batch Loss: 0.34856438636779785\n",
      "Epoch 1437, Loss: 3.272775948047638, Final Batch Loss: 0.8948450684547424\n",
      "Epoch 1438, Loss: 2.8863682746887207, Final Batch Loss: 0.5424866080284119\n",
      "Epoch 1439, Loss: 3.128453552722931, Final Batch Loss: 0.6692706346511841\n",
      "Epoch 1440, Loss: 3.1070849299430847, Final Batch Loss: 0.5280597805976868\n",
      "Epoch 1441, Loss: 3.0912702083587646, Final Batch Loss: 0.5473736524581909\n",
      "Epoch 1442, Loss: 2.843629688024521, Final Batch Loss: 0.46530207991600037\n",
      "Epoch 1443, Loss: 2.831719249486923, Final Batch Loss: 0.3146815598011017\n",
      "Epoch 1444, Loss: 3.187136650085449, Final Batch Loss: 0.680419921875\n",
      "Epoch 1445, Loss: 3.140669286251068, Final Batch Loss: 0.7089882493019104\n",
      "Epoch 1446, Loss: 2.7947095036506653, Final Batch Loss: 0.279754102230072\n",
      "Epoch 1447, Loss: 3.13886296749115, Final Batch Loss: 0.7240822911262512\n",
      "Epoch 1448, Loss: 2.9175480604171753, Final Batch Loss: 0.4462504982948303\n",
      "Epoch 1449, Loss: 3.0773593187332153, Final Batch Loss: 0.7150822281837463\n",
      "Epoch 1450, Loss: 3.255756139755249, Final Batch Loss: 0.730854868888855\n",
      "Epoch 1451, Loss: 3.220465838909149, Final Batch Loss: 0.8310662508010864\n",
      "Epoch 1452, Loss: 3.7158294916152954, Final Batch Loss: 1.2441399097442627\n",
      "Epoch 1453, Loss: 3.116523027420044, Final Batch Loss: 0.5288432240486145\n",
      "Epoch 1454, Loss: 3.117518365383148, Final Batch Loss: 0.603150486946106\n",
      "Epoch 1455, Loss: 2.80842262506485, Final Batch Loss: 0.3013797402381897\n",
      "Epoch 1456, Loss: 3.285708963871002, Final Batch Loss: 0.8036078810691833\n",
      "Epoch 1457, Loss: 3.0542558431625366, Final Batch Loss: 0.5956215858459473\n",
      "Epoch 1458, Loss: 3.10902339220047, Final Batch Loss: 0.6751154065132141\n",
      "Epoch 1459, Loss: 3.183224856853485, Final Batch Loss: 0.6110448241233826\n",
      "Epoch 1460, Loss: 2.954123705625534, Final Batch Loss: 0.32310929894447327\n",
      "Epoch 1461, Loss: 2.9484186470508575, Final Batch Loss: 0.3209816515445709\n",
      "Epoch 1462, Loss: 2.817539155483246, Final Batch Loss: 0.2893807291984558\n",
      "Epoch 1463, Loss: 3.00833523273468, Final Batch Loss: 0.4792816638946533\n",
      "Epoch 1464, Loss: 3.525746703147888, Final Batch Loss: 1.1007702350616455\n",
      "Epoch 1465, Loss: 3.0300817489624023, Final Batch Loss: 0.5830407738685608\n",
      "Epoch 1466, Loss: 3.239190995693207, Final Batch Loss: 0.6837586760520935\n",
      "Epoch 1467, Loss: 3.6735681295394897, Final Batch Loss: 1.130933165550232\n",
      "Epoch 1468, Loss: 3.237074911594391, Final Batch Loss: 0.7357873916625977\n",
      "Epoch 1469, Loss: 3.688850522041321, Final Batch Loss: 0.9677190184593201\n",
      "Epoch 1470, Loss: 3.225727915763855, Final Batch Loss: 0.6432250142097473\n",
      "Epoch 1471, Loss: 2.944265693426132, Final Batch Loss: 0.4935435354709625\n",
      "Epoch 1472, Loss: 3.0940877199172974, Final Batch Loss: 0.5764122009277344\n",
      "Epoch 1473, Loss: 2.794776290655136, Final Batch Loss: 0.27656832337379456\n",
      "Epoch 1474, Loss: 3.335806429386139, Final Batch Loss: 0.902995765209198\n",
      "Epoch 1475, Loss: 3.6949959993362427, Final Batch Loss: 1.1568080186843872\n",
      "Epoch 1476, Loss: 2.9394845962524414, Final Batch Loss: 0.3674190640449524\n",
      "Epoch 1477, Loss: 3.2418020963668823, Final Batch Loss: 0.7711986303329468\n",
      "Epoch 1478, Loss: 3.3934479355812073, Final Batch Loss: 0.8448452353477478\n",
      "Epoch 1479, Loss: 3.2232695817947388, Final Batch Loss: 0.7648539543151855\n",
      "Epoch 1480, Loss: 3.4318423867225647, Final Batch Loss: 0.9089940786361694\n",
      "Epoch 1481, Loss: 2.9051575660705566, Final Batch Loss: 0.5180450677871704\n",
      "Epoch 1482, Loss: 3.327768623828888, Final Batch Loss: 0.8195828199386597\n",
      "Epoch 1483, Loss: 3.187517762184143, Final Batch Loss: 0.5922122597694397\n",
      "Epoch 1484, Loss: 3.0531582832336426, Final Batch Loss: 0.5725942254066467\n",
      "Epoch 1485, Loss: 3.3426840901374817, Final Batch Loss: 0.7946586012840271\n",
      "Epoch 1486, Loss: 3.040803909301758, Final Batch Loss: 0.5544386506080627\n",
      "Epoch 1487, Loss: 2.8121674358844757, Final Batch Loss: 0.3192692697048187\n",
      "Epoch 1488, Loss: 2.949572116136551, Final Batch Loss: 0.45018020272254944\n",
      "Epoch 1489, Loss: 3.10925829410553, Final Batch Loss: 0.6117681860923767\n",
      "Epoch 1490, Loss: 3.6387637853622437, Final Batch Loss: 1.1289652585983276\n",
      "Epoch 1491, Loss: 3.3295839428901672, Final Batch Loss: 0.7705449461936951\n",
      "Epoch 1492, Loss: 3.3656479120254517, Final Batch Loss: 0.910906195640564\n",
      "Epoch 1493, Loss: 3.0892744660377502, Final Batch Loss: 0.7099924087524414\n",
      "Epoch 1494, Loss: 2.8152149617671967, Final Batch Loss: 0.44889095425605774\n",
      "Epoch 1495, Loss: 3.0804291367530823, Final Batch Loss: 0.55238276720047\n",
      "Epoch 1496, Loss: 3.1824775338172913, Final Batch Loss: 0.6944507956504822\n",
      "Epoch 1497, Loss: 2.9134024679660797, Final Batch Loss: 0.3829323947429657\n",
      "Epoch 1498, Loss: 3.0562629103660583, Final Batch Loss: 0.5050446391105652\n",
      "Epoch 1499, Loss: 3.512304723262787, Final Batch Loss: 0.9997133016586304\n",
      "Epoch 1500, Loss: 2.7478781044483185, Final Batch Loss: 0.2501125633716583\n",
      "Epoch 1501, Loss: 3.460545063018799, Final Batch Loss: 0.6955398917198181\n",
      "Epoch 1502, Loss: 3.6319862008094788, Final Batch Loss: 0.8814352750778198\n",
      "Epoch 1503, Loss: 3.355711281299591, Final Batch Loss: 0.7922202348709106\n",
      "Epoch 1504, Loss: 3.3721105456352234, Final Batch Loss: 0.6753379702568054\n",
      "Epoch 1505, Loss: 4.14607971906662, Final Batch Loss: 1.4304040670394897\n",
      "Epoch 1506, Loss: 3.240041732788086, Final Batch Loss: 0.6757411956787109\n",
      "Epoch 1507, Loss: 3.223366916179657, Final Batch Loss: 0.6496087312698364\n",
      "Epoch 1508, Loss: 2.9020334780216217, Final Batch Loss: 0.4552637040615082\n",
      "Epoch 1509, Loss: 3.2807275652885437, Final Batch Loss: 0.6886819005012512\n",
      "Epoch 1510, Loss: 3.0259986519813538, Final Batch Loss: 0.5385127663612366\n",
      "Epoch 1511, Loss: 3.192531704902649, Final Batch Loss: 0.7234398722648621\n",
      "Epoch 1512, Loss: 3.5149776935577393, Final Batch Loss: 1.0635091066360474\n",
      "Epoch 1513, Loss: 3.051491141319275, Final Batch Loss: 0.7470971345901489\n",
      "Epoch 1514, Loss: 3.3897913694381714, Final Batch Loss: 0.933745265007019\n",
      "Epoch 1515, Loss: 2.8235746026039124, Final Batch Loss: 0.3635091781616211\n",
      "Epoch 1516, Loss: 2.9152853190898895, Final Batch Loss: 0.450712651014328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1517, Loss: 2.784877598285675, Final Batch Loss: 0.3119085431098938\n",
      "Epoch 1518, Loss: 3.4693185687065125, Final Batch Loss: 1.0033900737762451\n",
      "Epoch 1519, Loss: 2.9313069581985474, Final Batch Loss: 0.6208273768424988\n",
      "Epoch 1520, Loss: 3.2113091945648193, Final Batch Loss: 0.7424798607826233\n",
      "Epoch 1521, Loss: 2.789217472076416, Final Batch Loss: 0.4572831690311432\n",
      "Epoch 1522, Loss: 3.121763378381729, Final Batch Loss: 0.6168321967124939\n",
      "Epoch 1523, Loss: 2.903762698173523, Final Batch Loss: 0.5299695730209351\n",
      "Epoch 1524, Loss: 3.1224239468574524, Final Batch Loss: 0.6858885884284973\n",
      "Epoch 1525, Loss: 3.044375479221344, Final Batch Loss: 0.5399900674819946\n",
      "Epoch 1526, Loss: 2.930289328098297, Final Batch Loss: 0.5331859588623047\n",
      "Epoch 1527, Loss: 2.775359660387039, Final Batch Loss: 0.3653181493282318\n",
      "Epoch 1528, Loss: 3.040508806705475, Final Batch Loss: 0.6276277303695679\n",
      "Epoch 1529, Loss: 3.234332501888275, Final Batch Loss: 0.7590022683143616\n",
      "Epoch 1530, Loss: 3.3527257442474365, Final Batch Loss: 0.9907245635986328\n",
      "Epoch 1531, Loss: 3.1398544311523438, Final Batch Loss: 0.7380619049072266\n",
      "Epoch 1532, Loss: 2.476697862148285, Final Batch Loss: 0.15690934658050537\n",
      "Epoch 1533, Loss: 3.1531141996383667, Final Batch Loss: 0.8792626261711121\n",
      "Epoch 1534, Loss: 3.248466372489929, Final Batch Loss: 0.8345227837562561\n",
      "Epoch 1535, Loss: 2.7409353256225586, Final Batch Loss: 0.3880752921104431\n",
      "Epoch 1536, Loss: 2.660062551498413, Final Batch Loss: 0.20786738395690918\n",
      "Epoch 1537, Loss: 2.5942590087652206, Final Batch Loss: 0.17047236859798431\n",
      "Epoch 1538, Loss: 3.5282867550849915, Final Batch Loss: 1.0058372020721436\n",
      "Epoch 1539, Loss: 2.8208969235420227, Final Batch Loss: 0.27420949935913086\n",
      "Epoch 1540, Loss: 2.9368860721588135, Final Batch Loss: 0.5007795691490173\n",
      "Epoch 1541, Loss: 2.7862593829631805, Final Batch Loss: 0.2602802813053131\n",
      "Epoch 1542, Loss: 2.758026421070099, Final Batch Loss: 0.47686678171157837\n",
      "Epoch 1543, Loss: 2.7449673116207123, Final Batch Loss: 0.3167320787906647\n",
      "Epoch 1544, Loss: 2.9351561069488525, Final Batch Loss: 0.507165789604187\n",
      "Epoch 1545, Loss: 3.358104944229126, Final Batch Loss: 0.8839898109436035\n",
      "Epoch 1546, Loss: 3.044534742832184, Final Batch Loss: 0.5453542470932007\n",
      "Epoch 1547, Loss: 2.900362402200699, Final Batch Loss: 0.31650540232658386\n",
      "Epoch 1548, Loss: 2.8228124380111694, Final Batch Loss: 0.3302014470100403\n",
      "Epoch 1549, Loss: 3.487094759941101, Final Batch Loss: 0.8869943022727966\n",
      "Epoch 1550, Loss: 2.92026549577713, Final Batch Loss: 0.47696733474731445\n",
      "Epoch 1551, Loss: 3.486626923084259, Final Batch Loss: 0.997769296169281\n",
      "Epoch 1552, Loss: 3.1821581721305847, Final Batch Loss: 0.656432032585144\n",
      "Epoch 1553, Loss: 3.3340481519699097, Final Batch Loss: 0.7260742783546448\n",
      "Epoch 1554, Loss: 3.5265854001045227, Final Batch Loss: 0.9740833640098572\n",
      "Epoch 1555, Loss: 2.9170220494270325, Final Batch Loss: 0.43217188119888306\n",
      "Epoch 1556, Loss: 2.9448308050632477, Final Batch Loss: 0.4955691397190094\n",
      "Epoch 1557, Loss: 3.1336633265018463, Final Batch Loss: 0.7774507403373718\n",
      "Epoch 1558, Loss: 3.154740631580353, Final Batch Loss: 0.6171888113021851\n",
      "Epoch 1559, Loss: 3.632138967514038, Final Batch Loss: 1.1776145696640015\n",
      "Epoch 1560, Loss: 3.1180981397628784, Final Batch Loss: 0.5819464921951294\n",
      "Epoch 1561, Loss: 3.069981038570404, Final Batch Loss: 0.6531356573104858\n",
      "Epoch 1562, Loss: 3.129825711250305, Final Batch Loss: 0.6727151870727539\n",
      "Epoch 1563, Loss: 3.0947118997573853, Final Batch Loss: 0.7065553069114685\n",
      "Epoch 1564, Loss: 2.826794534921646, Final Batch Loss: 0.3282376229763031\n",
      "Epoch 1565, Loss: 2.8054989874362946, Final Batch Loss: 0.2883692681789398\n",
      "Epoch 1566, Loss: 3.6483585238456726, Final Batch Loss: 1.1165924072265625\n",
      "Epoch 1567, Loss: 2.878690242767334, Final Batch Loss: 0.5663390755653381\n",
      "Epoch 1568, Loss: 2.89217147231102, Final Batch Loss: 0.5820425152778625\n",
      "Epoch 1569, Loss: 2.683314234018326, Final Batch Loss: 0.3506263792514801\n",
      "Epoch 1570, Loss: 3.11559796333313, Final Batch Loss: 0.616388201713562\n",
      "Epoch 1571, Loss: 3.153301417827606, Final Batch Loss: 0.7419490218162537\n",
      "Epoch 1572, Loss: 3.154940664768219, Final Batch Loss: 0.7180017828941345\n",
      "Epoch 1573, Loss: 2.7927439361810684, Final Batch Loss: 0.24615968763828278\n",
      "Epoch 1574, Loss: 3.2749821543693542, Final Batch Loss: 0.7752460241317749\n",
      "Epoch 1575, Loss: 3.173919141292572, Final Batch Loss: 0.6735162138938904\n",
      "Epoch 1576, Loss: 2.8324987292289734, Final Batch Loss: 0.4419660270214081\n",
      "Epoch 1577, Loss: 2.7458722293376923, Final Batch Loss: 0.33628126978874207\n",
      "Epoch 1578, Loss: 2.960669994354248, Final Batch Loss: 0.5173259973526001\n",
      "Epoch 1579, Loss: 3.146229565143585, Final Batch Loss: 0.604289174079895\n",
      "Epoch 1580, Loss: 3.1857848167419434, Final Batch Loss: 0.760594367980957\n",
      "Epoch 1581, Loss: 3.134724974632263, Final Batch Loss: 0.6911335587501526\n",
      "Epoch 1582, Loss: 3.1191245913505554, Final Batch Loss: 0.6047782301902771\n",
      "Epoch 1583, Loss: 2.9348792731761932, Final Batch Loss: 0.4140430986881256\n",
      "Epoch 1584, Loss: 3.219612240791321, Final Batch Loss: 0.9246527552604675\n",
      "Epoch 1585, Loss: 3.293402910232544, Final Batch Loss: 0.8189137578010559\n",
      "Epoch 1586, Loss: 2.901322215795517, Final Batch Loss: 0.46873942017555237\n",
      "Epoch 1587, Loss: 3.7426173090934753, Final Batch Loss: 1.3253562450408936\n",
      "Epoch 1588, Loss: 2.9215066134929657, Final Batch Loss: 0.421212762594223\n",
      "Epoch 1589, Loss: 2.81137552857399, Final Batch Loss: 0.3403376638889313\n",
      "Epoch 1590, Loss: 3.1340636014938354, Final Batch Loss: 0.7296069860458374\n",
      "Epoch 1591, Loss: 3.130291998386383, Final Batch Loss: 0.5463733077049255\n",
      "Epoch 1592, Loss: 2.8786036372184753, Final Batch Loss: 0.3912662863731384\n",
      "Epoch 1593, Loss: 2.820252388715744, Final Batch Loss: 0.38372376561164856\n",
      "Epoch 1594, Loss: 3.0010892152786255, Final Batch Loss: 0.6706560254096985\n",
      "Epoch 1595, Loss: 3.322371542453766, Final Batch Loss: 0.7166463136672974\n",
      "Epoch 1596, Loss: 2.6672721803188324, Final Batch Loss: 0.2458193600177765\n",
      "Epoch 1597, Loss: 3.160899043083191, Final Batch Loss: 0.5998963117599487\n",
      "Epoch 1598, Loss: 3.3990142941474915, Final Batch Loss: 0.903370201587677\n",
      "Epoch 1599, Loss: 3.050525963306427, Final Batch Loss: 0.5879402160644531\n",
      "Epoch 1600, Loss: 3.2968501448631287, Final Batch Loss: 0.9823575019836426\n",
      "Epoch 1601, Loss: 3.192798435688019, Final Batch Loss: 0.8068084716796875\n",
      "Epoch 1602, Loss: 2.92050963640213, Final Batch Loss: 0.5060733556747437\n",
      "Epoch 1603, Loss: 2.869966149330139, Final Batch Loss: 0.5743936896324158\n",
      "Epoch 1604, Loss: 3.2860113978385925, Final Batch Loss: 0.7310222387313843\n",
      "Epoch 1605, Loss: 3.1577653288841248, Final Batch Loss: 0.7281875014305115\n",
      "Epoch 1606, Loss: 3.0554681420326233, Final Batch Loss: 0.5106323957443237\n",
      "Epoch 1607, Loss: 3.046711564064026, Final Batch Loss: 0.6686191558837891\n",
      "Epoch 1608, Loss: 2.9801870584487915, Final Batch Loss: 0.5443565249443054\n",
      "Epoch 1609, Loss: 2.9128436744213104, Final Batch Loss: 0.42854127287864685\n",
      "Epoch 1610, Loss: 2.6127026081085205, Final Batch Loss: 0.25196707248687744\n",
      "Epoch 1611, Loss: 2.739702522754669, Final Batch Loss: 0.44204026460647583\n",
      "Epoch 1612, Loss: 3.3594033122062683, Final Batch Loss: 0.9766918420791626\n",
      "Epoch 1613, Loss: 2.9398560523986816, Final Batch Loss: 0.5421128869056702\n",
      "Epoch 1614, Loss: 2.971579909324646, Final Batch Loss: 0.49996453523635864\n",
      "Epoch 1615, Loss: 3.367793083190918, Final Batch Loss: 0.8420886993408203\n",
      "Epoch 1616, Loss: 2.986879587173462, Final Batch Loss: 0.6029367446899414\n",
      "Epoch 1617, Loss: 2.6353526264429092, Final Batch Loss: 0.19993509352207184\n",
      "Epoch 1618, Loss: 2.899459570646286, Final Batch Loss: 0.47550168633461\n",
      "Epoch 1619, Loss: 2.898062437772751, Final Batch Loss: 0.39617374539375305\n",
      "Epoch 1620, Loss: 2.7707768976688385, Final Batch Loss: 0.2753731310367584\n",
      "Epoch 1621, Loss: 2.729540079832077, Final Batch Loss: 0.37540796399116516\n",
      "Epoch 1622, Loss: 2.7500739991664886, Final Batch Loss: 0.48123058676719666\n",
      "Epoch 1623, Loss: 2.964707165956497, Final Batch Loss: 0.6090518236160278\n",
      "Epoch 1624, Loss: 2.547897458076477, Final Batch Loss: 0.19698584079742432\n",
      "Epoch 1625, Loss: 2.863592565059662, Final Batch Loss: 0.43871331214904785\n",
      "Epoch 1626, Loss: 2.7541894614696503, Final Batch Loss: 0.3852996528148651\n",
      "Epoch 1627, Loss: 2.729071229696274, Final Batch Loss: 0.4276924431324005\n",
      "Epoch 1628, Loss: 2.914130687713623, Final Batch Loss: 0.4907722473144531\n",
      "Epoch 1629, Loss: 2.877882480621338, Final Batch Loss: 0.6012101173400879\n",
      "Epoch 1630, Loss: 3.2035813331604004, Final Batch Loss: 0.8067952990531921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1631, Loss: 3.4447020888328552, Final Batch Loss: 0.830483615398407\n",
      "Epoch 1632, Loss: 3.0845537185668945, Final Batch Loss: 0.6365631818771362\n",
      "Epoch 1633, Loss: 2.9685537815093994, Final Batch Loss: 0.5303491950035095\n",
      "Epoch 1634, Loss: 3.060244560241699, Final Batch Loss: 0.549038827419281\n",
      "Epoch 1635, Loss: 3.175348460674286, Final Batch Loss: 0.753120481967926\n",
      "Epoch 1636, Loss: 2.9236363768577576, Final Batch Loss: 0.6351239085197449\n",
      "Epoch 1637, Loss: 3.1154479384422302, Final Batch Loss: 0.6849541068077087\n",
      "Epoch 1638, Loss: 3.1501455307006836, Final Batch Loss: 0.6700124740600586\n",
      "Epoch 1639, Loss: 2.856352150440216, Final Batch Loss: 0.5597162842750549\n",
      "Epoch 1640, Loss: 2.8431282341480255, Final Batch Loss: 0.4607160687446594\n",
      "Epoch 1641, Loss: 2.54006427526474, Final Batch Loss: 0.2907014787197113\n",
      "Epoch 1642, Loss: 3.0730207562446594, Final Batch Loss: 0.7092951536178589\n",
      "Epoch 1643, Loss: 2.7137619256973267, Final Batch Loss: 0.3716098666191101\n",
      "Epoch 1644, Loss: 2.962375581264496, Final Batch Loss: 0.6092039942741394\n",
      "Epoch 1645, Loss: 2.663912445306778, Final Batch Loss: 0.3116365969181061\n",
      "Epoch 1646, Loss: 3.033202111721039, Final Batch Loss: 0.6379374265670776\n",
      "Epoch 1647, Loss: 3.0067747235298157, Final Batch Loss: 0.5984154343605042\n",
      "Epoch 1648, Loss: 2.858307808637619, Final Batch Loss: 0.3631167709827423\n",
      "Epoch 1649, Loss: 2.8774155378341675, Final Batch Loss: 0.42235875129699707\n",
      "Epoch 1650, Loss: 2.8529777824878693, Final Batch Loss: 0.49091872572898865\n",
      "Epoch 1651, Loss: 3.1411316990852356, Final Batch Loss: 0.6559160351753235\n",
      "Epoch 1652, Loss: 2.9398796558380127, Final Batch Loss: 0.6265054941177368\n",
      "Epoch 1653, Loss: 3.174346834421158, Final Batch Loss: 0.8516784310340881\n",
      "Epoch 1654, Loss: 3.2480294704437256, Final Batch Loss: 0.8930625915527344\n",
      "Epoch 1655, Loss: 3.164453238248825, Final Batch Loss: 0.9258661866188049\n",
      "Epoch 1656, Loss: 3.1339950561523438, Final Batch Loss: 0.6375574469566345\n",
      "Epoch 1657, Loss: 2.6215474903583527, Final Batch Loss: 0.34003493189811707\n",
      "Epoch 1658, Loss: 2.5730522125959396, Final Batch Loss: 0.20518533885478973\n",
      "Epoch 1659, Loss: 3.6811671257019043, Final Batch Loss: 1.3811742067337036\n",
      "Epoch 1660, Loss: 2.627429097890854, Final Batch Loss: 0.31518277525901794\n",
      "Epoch 1661, Loss: 3.0451478362083435, Final Batch Loss: 0.7334195375442505\n",
      "Epoch 1662, Loss: 2.995776116847992, Final Batch Loss: 0.5851799845695496\n",
      "Epoch 1663, Loss: 2.460367776453495, Final Batch Loss: 0.09391913563013077\n",
      "Epoch 1664, Loss: 2.963357836008072, Final Batch Loss: 0.40141329169273376\n",
      "Epoch 1665, Loss: 3.1254860758781433, Final Batch Loss: 0.8600873351097107\n",
      "Epoch 1666, Loss: 3.1276604533195496, Final Batch Loss: 0.7360695600509644\n",
      "Epoch 1667, Loss: 2.95095431804657, Final Batch Loss: 0.6992239356040955\n",
      "Epoch 1668, Loss: 2.5993506610393524, Final Batch Loss: 0.34101173281669617\n",
      "Epoch 1669, Loss: 2.8077012598514557, Final Batch Loss: 0.3648415505886078\n",
      "Epoch 1670, Loss: 2.67296901345253, Final Batch Loss: 0.3352365791797638\n",
      "Epoch 1671, Loss: 2.731448709964752, Final Batch Loss: 0.5110109448432922\n",
      "Epoch 1672, Loss: 3.189107894897461, Final Batch Loss: 0.7724261283874512\n",
      "Epoch 1673, Loss: 2.949421912431717, Final Batch Loss: 0.49882271885871887\n",
      "Epoch 1674, Loss: 2.9445318579673767, Final Batch Loss: 0.5635515451431274\n",
      "Epoch 1675, Loss: 2.94845712184906, Final Batch Loss: 0.6465368866920471\n",
      "Epoch 1676, Loss: 2.7958041429519653, Final Batch Loss: 0.47620242834091187\n",
      "Epoch 1677, Loss: 3.145109474658966, Final Batch Loss: 0.6877526640892029\n",
      "Epoch 1678, Loss: 2.9428685903549194, Final Batch Loss: 0.627255916595459\n",
      "Epoch 1679, Loss: 2.9195859134197235, Final Batch Loss: 0.4984348714351654\n",
      "Epoch 1680, Loss: 2.670733541250229, Final Batch Loss: 0.4112461507320404\n",
      "Epoch 1681, Loss: 3.1073914170265198, Final Batch Loss: 0.655330240726471\n",
      "Epoch 1682, Loss: 3.1837450861930847, Final Batch Loss: 0.6672741174697876\n",
      "Epoch 1683, Loss: 2.690861850976944, Final Batch Loss: 0.2711682915687561\n",
      "Epoch 1684, Loss: 2.6845416724681854, Final Batch Loss: 0.30461952090263367\n",
      "Epoch 1685, Loss: 2.895951211452484, Final Batch Loss: 0.581447184085846\n",
      "Epoch 1686, Loss: 2.995056450366974, Final Batch Loss: 0.6704030632972717\n",
      "Epoch 1687, Loss: 2.5430111587047577, Final Batch Loss: 0.26637712121009827\n",
      "Epoch 1688, Loss: 2.751564770936966, Final Batch Loss: 0.35768476128578186\n",
      "Epoch 1689, Loss: 3.1011101603507996, Final Batch Loss: 0.7529760003089905\n",
      "Epoch 1690, Loss: 3.290944755077362, Final Batch Loss: 0.9741134643554688\n",
      "Epoch 1691, Loss: 2.9746415615081787, Final Batch Loss: 0.6314314603805542\n",
      "Epoch 1692, Loss: 2.7725126147270203, Final Batch Loss: 0.38219738006591797\n",
      "Epoch 1693, Loss: 2.901966243982315, Final Batch Loss: 0.47095605731010437\n",
      "Epoch 1694, Loss: 3.6639909148216248, Final Batch Loss: 1.2578858137130737\n",
      "Epoch 1695, Loss: 2.979704737663269, Final Batch Loss: 0.5519514679908752\n",
      "Epoch 1696, Loss: 2.935195565223694, Final Batch Loss: 0.6066118478775024\n",
      "Epoch 1697, Loss: 2.8763003945350647, Final Batch Loss: 0.47608381509780884\n",
      "Epoch 1698, Loss: 3.4727607369422913, Final Batch Loss: 1.2199957370758057\n",
      "Epoch 1699, Loss: 3.0410754680633545, Final Batch Loss: 0.806980311870575\n",
      "Epoch 1700, Loss: 2.894664943218231, Final Batch Loss: 0.4976786971092224\n",
      "Epoch 1701, Loss: 2.798833340406418, Final Batch Loss: 0.49282142519950867\n",
      "Epoch 1702, Loss: 2.7500359416007996, Final Batch Loss: 0.34030914306640625\n",
      "Epoch 1703, Loss: 3.496089279651642, Final Batch Loss: 1.077665090560913\n",
      "Epoch 1704, Loss: 2.8969746828079224, Final Batch Loss: 0.6106058955192566\n",
      "Epoch 1705, Loss: 2.9287999272346497, Final Batch Loss: 0.5932086110115051\n",
      "Epoch 1706, Loss: 2.78476345539093, Final Batch Loss: 0.34684449434280396\n",
      "Epoch 1707, Loss: 2.9935047030448914, Final Batch Loss: 0.6956280469894409\n",
      "Epoch 1708, Loss: 3.200279176235199, Final Batch Loss: 0.9612098336219788\n",
      "Epoch 1709, Loss: 2.950052797794342, Final Batch Loss: 0.6101423501968384\n",
      "Epoch 1710, Loss: 2.795911580324173, Final Batch Loss: 0.4523579180240631\n",
      "Epoch 1711, Loss: 2.76870459318161, Final Batch Loss: 0.4286349415779114\n",
      "Epoch 1712, Loss: 3.1032127141952515, Final Batch Loss: 0.8831868767738342\n",
      "Epoch 1713, Loss: 2.5076979994773865, Final Batch Loss: 0.21709108352661133\n",
      "Epoch 1714, Loss: 3.0637098252773285, Final Batch Loss: 0.9118142127990723\n",
      "Epoch 1715, Loss: 3.0137035846710205, Final Batch Loss: 0.6256865859031677\n",
      "Epoch 1716, Loss: 3.3556917905807495, Final Batch Loss: 0.9014638662338257\n",
      "Epoch 1717, Loss: 2.731462776660919, Final Batch Loss: 0.4848727583885193\n",
      "Epoch 1718, Loss: 2.9839882254600525, Final Batch Loss: 0.5315867066383362\n",
      "Epoch 1719, Loss: 2.639332354068756, Final Batch Loss: 0.3892126679420471\n",
      "Epoch 1720, Loss: 2.852605938911438, Final Batch Loss: 0.623545229434967\n",
      "Epoch 1721, Loss: 3.047681510448456, Final Batch Loss: 0.7408685088157654\n",
      "Epoch 1722, Loss: 2.8899790048599243, Final Batch Loss: 0.531431257724762\n",
      "Epoch 1723, Loss: 3.3191715478897095, Final Batch Loss: 0.924880862236023\n",
      "Epoch 1724, Loss: 2.6948828399181366, Final Batch Loss: 0.39457908272743225\n",
      "Epoch 1725, Loss: 2.718048393726349, Final Batch Loss: 0.39723896980285645\n",
      "Epoch 1726, Loss: 3.0748499035835266, Final Batch Loss: 0.7088024020195007\n",
      "Epoch 1727, Loss: 2.9628955125808716, Final Batch Loss: 0.6055004000663757\n",
      "Epoch 1728, Loss: 2.9039018750190735, Final Batch Loss: 0.41177281737327576\n",
      "Epoch 1729, Loss: 2.383313976228237, Final Batch Loss: 0.11958571523427963\n",
      "Epoch 1730, Loss: 2.9454692602157593, Final Batch Loss: 0.511551022529602\n",
      "Epoch 1731, Loss: 2.84331077337265, Final Batch Loss: 0.574643611907959\n",
      "Epoch 1732, Loss: 2.757577210664749, Final Batch Loss: 0.37411466240882874\n",
      "Epoch 1733, Loss: 2.603288412094116, Final Batch Loss: 0.3958650231361389\n",
      "Epoch 1734, Loss: 2.9269155859947205, Final Batch Loss: 0.698419451713562\n",
      "Epoch 1735, Loss: 3.0583584308624268, Final Batch Loss: 0.6629428267478943\n",
      "Epoch 1736, Loss: 3.1998530626296997, Final Batch Loss: 0.8672587275505066\n",
      "Epoch 1737, Loss: 2.627444162964821, Final Batch Loss: 0.24690695106983185\n",
      "Epoch 1738, Loss: 2.8494689762592316, Final Batch Loss: 0.546697199344635\n",
      "Epoch 1739, Loss: 3.273600220680237, Final Batch Loss: 0.8900161981582642\n",
      "Epoch 1740, Loss: 3.0321719646453857, Final Batch Loss: 0.6457704305648804\n",
      "Epoch 1741, Loss: 2.8167116940021515, Final Batch Loss: 0.3980846107006073\n",
      "Epoch 1742, Loss: 2.741410553455353, Final Batch Loss: 0.4329351782798767\n",
      "Epoch 1743, Loss: 2.5567974150180817, Final Batch Loss: 0.3499455153942108\n",
      "Epoch 1744, Loss: 3.116903066635132, Final Batch Loss: 0.7939244508743286\n",
      "Epoch 1745, Loss: 2.862397015094757, Final Batch Loss: 0.545613706111908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1746, Loss: 3.0118433237075806, Final Batch Loss: 0.7144564986228943\n",
      "Epoch 1747, Loss: 3.233044385910034, Final Batch Loss: 0.8021149039268494\n",
      "Epoch 1748, Loss: 2.6831772327423096, Final Batch Loss: 0.4442380964756012\n",
      "Epoch 1749, Loss: 2.562313660979271, Final Batch Loss: 0.24454139173030853\n",
      "Epoch 1750, Loss: 2.750305086374283, Final Batch Loss: 0.3279518187046051\n",
      "Epoch 1751, Loss: 2.922155886888504, Final Batch Loss: 0.6901422142982483\n",
      "Epoch 1752, Loss: 2.3706020563840866, Final Batch Loss: 0.12767313420772552\n",
      "Epoch 1753, Loss: 3.1473018527030945, Final Batch Loss: 0.9734050631523132\n",
      "Epoch 1754, Loss: 3.3092379570007324, Final Batch Loss: 0.8041676878929138\n",
      "Epoch 1755, Loss: 3.065194070339203, Final Batch Loss: 0.8074740767478943\n",
      "Epoch 1756, Loss: 3.084087610244751, Final Batch Loss: 0.6735653281211853\n",
      "Epoch 1757, Loss: 2.573033481836319, Final Batch Loss: 0.22474780678749084\n",
      "Epoch 1758, Loss: 3.1290542483329773, Final Batch Loss: 0.8226739764213562\n",
      "Epoch 1759, Loss: 2.8692082464694977, Final Batch Loss: 0.4664800465106964\n",
      "Epoch 1760, Loss: 3.1529505252838135, Final Batch Loss: 0.7859141230583191\n",
      "Epoch 1761, Loss: 2.759467512369156, Final Batch Loss: 0.4196464717388153\n",
      "Epoch 1762, Loss: 3.3122065663337708, Final Batch Loss: 1.0008199214935303\n",
      "Epoch 1763, Loss: 2.5353260338306427, Final Batch Loss: 0.3399239480495453\n",
      "Epoch 1764, Loss: 2.8034526109695435, Final Batch Loss: 0.36142176389694214\n",
      "Epoch 1765, Loss: 2.7666328847408295, Final Batch Loss: 0.4796963632106781\n",
      "Epoch 1766, Loss: 3.133257806301117, Final Batch Loss: 0.7886661887168884\n",
      "Epoch 1767, Loss: 2.8510685563087463, Final Batch Loss: 0.508168637752533\n",
      "Epoch 1768, Loss: 2.728583335876465, Final Batch Loss: 0.3124348521232605\n",
      "Epoch 1769, Loss: 2.9746432304382324, Final Batch Loss: 0.5860377550125122\n",
      "Epoch 1770, Loss: 2.814626783132553, Final Batch Loss: 0.5586427450180054\n",
      "Epoch 1771, Loss: 2.7759438157081604, Final Batch Loss: 0.5000060200691223\n",
      "Epoch 1772, Loss: 2.6795487701892853, Final Batch Loss: 0.34608641266822815\n",
      "Epoch 1773, Loss: 3.096131145954132, Final Batch Loss: 0.681266188621521\n",
      "Epoch 1774, Loss: 2.8778753876686096, Final Batch Loss: 0.5804828405380249\n",
      "Epoch 1775, Loss: 3.205638110637665, Final Batch Loss: 0.6953727602958679\n",
      "Epoch 1776, Loss: 2.820302665233612, Final Batch Loss: 0.37563472986221313\n",
      "Epoch 1777, Loss: 3.2942962646484375, Final Batch Loss: 0.7933687567710876\n",
      "Epoch 1778, Loss: 2.7645600736141205, Final Batch Loss: 0.4692275822162628\n",
      "Epoch 1779, Loss: 2.6889597475528717, Final Batch Loss: 0.41885510087013245\n",
      "Epoch 1780, Loss: 3.2538950443267822, Final Batch Loss: 0.7749708294868469\n",
      "Epoch 1781, Loss: 3.2091866731643677, Final Batch Loss: 0.8416431546211243\n",
      "Epoch 1782, Loss: 3.0019338130950928, Final Batch Loss: 0.5592955350875854\n",
      "Epoch 1783, Loss: 2.69993032515049, Final Batch Loss: 0.21080006659030914\n",
      "Epoch 1784, Loss: 3.2417250871658325, Final Batch Loss: 1.0147711038589478\n",
      "Epoch 1785, Loss: 2.766593426465988, Final Batch Loss: 0.42923781275749207\n",
      "Epoch 1786, Loss: 2.609349340200424, Final Batch Loss: 0.3491728603839874\n",
      "Epoch 1787, Loss: 3.0094746947288513, Final Batch Loss: 0.6792668104171753\n",
      "Epoch 1788, Loss: 2.6188431680202484, Final Batch Loss: 0.3337291181087494\n",
      "Epoch 1789, Loss: 2.5336221158504486, Final Batch Loss: 0.21234187483787537\n",
      "Epoch 1790, Loss: 3.2313511967658997, Final Batch Loss: 0.8971629738807678\n",
      "Epoch 1791, Loss: 2.4966665506362915, Final Batch Loss: 0.4003927707672119\n",
      "Epoch 1792, Loss: 2.9486151337623596, Final Batch Loss: 0.7583519816398621\n",
      "Epoch 1793, Loss: 3.0471087396144867, Final Batch Loss: 0.6104318499565125\n",
      "Epoch 1794, Loss: 2.5531494170427322, Final Batch Loss: 0.24891920387744904\n",
      "Epoch 1795, Loss: 3.5794332027435303, Final Batch Loss: 1.1364079713821411\n",
      "Epoch 1796, Loss: 2.6982038617134094, Final Batch Loss: 0.434814989566803\n",
      "Epoch 1797, Loss: 3.3394965529441833, Final Batch Loss: 1.0968247652053833\n",
      "Epoch 1798, Loss: 2.923019230365753, Final Batch Loss: 0.5506752729415894\n",
      "Epoch 1799, Loss: 2.973273366689682, Final Batch Loss: 0.3315998613834381\n",
      "Epoch 1800, Loss: 3.1859706044197083, Final Batch Loss: 0.9029836654663086\n",
      "Epoch 1801, Loss: 3.187634825706482, Final Batch Loss: 0.9331784248352051\n",
      "Epoch 1802, Loss: 3.355484127998352, Final Batch Loss: 0.9120106101036072\n",
      "Epoch 1803, Loss: 2.708406776189804, Final Batch Loss: 0.35820576548576355\n",
      "Epoch 1804, Loss: 2.8240758776664734, Final Batch Loss: 0.5896987318992615\n",
      "Epoch 1805, Loss: 2.660982072353363, Final Batch Loss: 0.28340375423431396\n",
      "Epoch 1806, Loss: 2.780956119298935, Final Batch Loss: 0.4950030744075775\n",
      "Epoch 1807, Loss: 2.9220601320266724, Final Batch Loss: 0.6929482817649841\n",
      "Epoch 1808, Loss: 2.9836931824684143, Final Batch Loss: 0.6564875245094299\n",
      "Epoch 1809, Loss: 3.0988638401031494, Final Batch Loss: 0.8440157771110535\n",
      "Epoch 1810, Loss: 2.6717123985290527, Final Batch Loss: 0.3952926993370056\n",
      "Epoch 1811, Loss: 2.68206125497818, Final Batch Loss: 0.5508068203926086\n",
      "Epoch 1812, Loss: 2.917681396007538, Final Batch Loss: 0.5209335684776306\n",
      "Epoch 1813, Loss: 2.7410538494586945, Final Batch Loss: 0.4500638544559479\n",
      "Epoch 1814, Loss: 2.7168112993240356, Final Batch Loss: 0.42121052742004395\n",
      "Epoch 1815, Loss: 2.8090052604675293, Final Batch Loss: 0.5134949088096619\n",
      "Epoch 1816, Loss: 2.8097835779190063, Final Batch Loss: 0.6678518652915955\n",
      "Epoch 1817, Loss: 2.671442925930023, Final Batch Loss: 0.4455816149711609\n",
      "Epoch 1818, Loss: 3.025049388408661, Final Batch Loss: 0.8413135409355164\n",
      "Epoch 1819, Loss: 2.7831748723983765, Final Batch Loss: 0.6111405491828918\n",
      "Epoch 1820, Loss: 2.9041892290115356, Final Batch Loss: 0.5123865008354187\n",
      "Epoch 1821, Loss: 2.7546972930431366, Final Batch Loss: 0.42789342999458313\n",
      "Epoch 1822, Loss: 3.283832550048828, Final Batch Loss: 0.9092983603477478\n",
      "Epoch 1823, Loss: 2.56281054019928, Final Batch Loss: 0.3218570649623871\n",
      "Epoch 1824, Loss: 2.485144168138504, Final Batch Loss: 0.33104071021080017\n",
      "Epoch 1825, Loss: 3.0480018854141235, Final Batch Loss: 0.7847423553466797\n",
      "Epoch 1826, Loss: 2.745526909828186, Final Batch Loss: 0.5604687929153442\n",
      "Epoch 1827, Loss: 2.983397603034973, Final Batch Loss: 0.6556371450424194\n",
      "Epoch 1828, Loss: 3.0020546317100525, Final Batch Loss: 0.6416441798210144\n",
      "Epoch 1829, Loss: 2.7607668042182922, Final Batch Loss: 0.5083087086677551\n",
      "Epoch 1830, Loss: 2.752013385295868, Final Batch Loss: 0.5754765272140503\n",
      "Epoch 1831, Loss: 2.9279491305351257, Final Batch Loss: 0.7193928956985474\n",
      "Epoch 1832, Loss: 3.321821868419647, Final Batch Loss: 1.010131597518921\n",
      "Epoch 1833, Loss: 2.960304915904999, Final Batch Loss: 0.6317063570022583\n",
      "Epoch 1834, Loss: 3.0302703380584717, Final Batch Loss: 0.7671483159065247\n",
      "Epoch 1835, Loss: 3.0396265387535095, Final Batch Loss: 0.7901270985603333\n",
      "Epoch 1836, Loss: 2.93149733543396, Final Batch Loss: 0.7003948092460632\n",
      "Epoch 1837, Loss: 2.9302130341529846, Final Batch Loss: 0.6030505895614624\n",
      "Epoch 1838, Loss: 2.749990314245224, Final Batch Loss: 0.3810748755931854\n",
      "Epoch 1839, Loss: 2.680158168077469, Final Batch Loss: 0.3737657368183136\n",
      "Epoch 1840, Loss: 3.1945613622665405, Final Batch Loss: 0.8399227857589722\n",
      "Epoch 1841, Loss: 3.076851487159729, Final Batch Loss: 0.7650179862976074\n",
      "Epoch 1842, Loss: 3.0150962471961975, Final Batch Loss: 0.5518972277641296\n",
      "Epoch 1843, Loss: 3.242102324962616, Final Batch Loss: 0.9045295715332031\n",
      "Epoch 1844, Loss: 2.746319144964218, Final Batch Loss: 0.3303798735141754\n",
      "Epoch 1845, Loss: 2.5353152453899384, Final Batch Loss: 0.25261393189430237\n",
      "Epoch 1846, Loss: 2.6617865562438965, Final Batch Loss: 0.41576242446899414\n",
      "Epoch 1847, Loss: 3.0745421648025513, Final Batch Loss: 0.6430014371871948\n",
      "Epoch 1848, Loss: 2.661324143409729, Final Batch Loss: 0.3313276767730713\n",
      "Epoch 1849, Loss: 2.963638961315155, Final Batch Loss: 0.6202041506767273\n",
      "Epoch 1850, Loss: 2.9040064811706543, Final Batch Loss: 0.6011619567871094\n",
      "Epoch 1851, Loss: 2.6813912987709045, Final Batch Loss: 0.45428410172462463\n",
      "Epoch 1852, Loss: 2.7229101061820984, Final Batch Loss: 0.46826988458633423\n",
      "Epoch 1853, Loss: 2.7039128839969635, Final Batch Loss: 0.44802698493003845\n",
      "Epoch 1854, Loss: 2.935433030128479, Final Batch Loss: 0.7017550468444824\n",
      "Epoch 1855, Loss: 2.652119666337967, Final Batch Loss: 0.43375858664512634\n",
      "Epoch 1856, Loss: 2.779548078775406, Final Batch Loss: 0.572266161441803\n",
      "Epoch 1857, Loss: 2.8247697353363037, Final Batch Loss: 0.5045526623725891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1858, Loss: 2.97042715549469, Final Batch Loss: 0.7736212015151978\n",
      "Epoch 1859, Loss: 2.650772899389267, Final Batch Loss: 0.44976428151130676\n",
      "Epoch 1860, Loss: 2.798085540533066, Final Batch Loss: 0.36535629630088806\n",
      "Epoch 1861, Loss: 2.87729674577713, Final Batch Loss: 0.5100747346878052\n",
      "Epoch 1862, Loss: 2.9317829608917236, Final Batch Loss: 0.6105461120605469\n",
      "Epoch 1863, Loss: 2.543773055076599, Final Batch Loss: 0.2687132954597473\n",
      "Epoch 1864, Loss: 2.574534595012665, Final Batch Loss: 0.2898116707801819\n",
      "Epoch 1865, Loss: 2.8625277876853943, Final Batch Loss: 0.5613903999328613\n",
      "Epoch 1866, Loss: 2.9951244592666626, Final Batch Loss: 0.8135713338851929\n",
      "Epoch 1867, Loss: 2.6977566480636597, Final Batch Loss: 0.5113642811775208\n",
      "Epoch 1868, Loss: 2.7426725029945374, Final Batch Loss: 0.5184497237205505\n",
      "Epoch 1869, Loss: 2.885380208492279, Final Batch Loss: 0.5457205176353455\n",
      "Epoch 1870, Loss: 3.218846172094345, Final Batch Loss: 0.8533512949943542\n",
      "Epoch 1871, Loss: 2.569084197282791, Final Batch Loss: 0.271494597196579\n",
      "Epoch 1872, Loss: 2.6346533000469208, Final Batch Loss: 0.40074846148490906\n",
      "Epoch 1873, Loss: 2.7339807748794556, Final Batch Loss: 0.3975631594657898\n",
      "Epoch 1874, Loss: 2.9552499055862427, Final Batch Loss: 0.7727999091148376\n",
      "Epoch 1875, Loss: 2.834930717945099, Final Batch Loss: 0.5550594329833984\n",
      "Epoch 1876, Loss: 2.9097505807876587, Final Batch Loss: 0.6203465461730957\n",
      "Epoch 1877, Loss: 3.0965386033058167, Final Batch Loss: 0.8205523490905762\n",
      "Epoch 1878, Loss: 2.4750699400901794, Final Batch Loss: 0.16455447673797607\n",
      "Epoch 1879, Loss: 2.506359353661537, Final Batch Loss: 0.2429760843515396\n",
      "Epoch 1880, Loss: 2.768007755279541, Final Batch Loss: 0.5252500772476196\n",
      "Epoch 1881, Loss: 2.933807909488678, Final Batch Loss: 0.7714334726333618\n",
      "Epoch 1882, Loss: 2.767704099416733, Final Batch Loss: 0.6082691550254822\n",
      "Epoch 1883, Loss: 2.673658072948456, Final Batch Loss: 0.4865453541278839\n",
      "Epoch 1884, Loss: 2.526329666376114, Final Batch Loss: 0.41317299008369446\n",
      "Epoch 1885, Loss: 3.0071545243263245, Final Batch Loss: 0.7436485886573792\n",
      "Epoch 1886, Loss: 2.635463684797287, Final Batch Loss: 0.4148692786693573\n",
      "Epoch 1887, Loss: 2.746668368577957, Final Batch Loss: 0.3909647762775421\n",
      "Epoch 1888, Loss: 2.3782978653907776, Final Batch Loss: 0.15673133730888367\n",
      "Epoch 1889, Loss: 2.831394284963608, Final Batch Loss: 0.6613729596138\n",
      "Epoch 1890, Loss: 2.8330878019332886, Final Batch Loss: 0.607143223285675\n",
      "Epoch 1891, Loss: 2.7420659959316254, Final Batch Loss: 0.5739765167236328\n",
      "Epoch 1892, Loss: 2.9307283759117126, Final Batch Loss: 0.6380099058151245\n",
      "Epoch 1893, Loss: 2.7310441732406616, Final Batch Loss: 0.4869092106819153\n",
      "Epoch 1894, Loss: 2.7757362723350525, Final Batch Loss: 0.5422378182411194\n",
      "Epoch 1895, Loss: 3.063524305820465, Final Batch Loss: 0.7637726664543152\n",
      "Epoch 1896, Loss: 2.8954588770866394, Final Batch Loss: 0.6119785308837891\n",
      "Epoch 1897, Loss: 2.6838297247886658, Final Batch Loss: 0.3082859516143799\n",
      "Epoch 1898, Loss: 3.0238682627677917, Final Batch Loss: 0.5033825039863586\n",
      "Epoch 1899, Loss: 2.8624762296676636, Final Batch Loss: 0.6468868851661682\n",
      "Epoch 1900, Loss: 2.669202536344528, Final Batch Loss: 0.3588303029537201\n",
      "Epoch 1901, Loss: 2.937658667564392, Final Batch Loss: 0.6557034850120544\n",
      "Epoch 1902, Loss: 2.6479864567518234, Final Batch Loss: 0.2335437387228012\n",
      "Epoch 1903, Loss: 2.766323357820511, Final Batch Loss: 0.48155030608177185\n",
      "Epoch 1904, Loss: 3.1522712111473083, Final Batch Loss: 0.8816796541213989\n",
      "Epoch 1905, Loss: 2.999702751636505, Final Batch Loss: 0.8243985176086426\n",
      "Epoch 1906, Loss: 2.8893248438835144, Final Batch Loss: 0.6262699961662292\n",
      "Epoch 1907, Loss: 2.659307986497879, Final Batch Loss: 0.34294047951698303\n",
      "Epoch 1908, Loss: 2.81958270072937, Final Batch Loss: 0.5144344568252563\n",
      "Epoch 1909, Loss: 2.673561751842499, Final Batch Loss: 0.5844364762306213\n",
      "Epoch 1910, Loss: 3.347200930118561, Final Batch Loss: 1.0608611106872559\n",
      "Epoch 1911, Loss: 2.6898336112499237, Final Batch Loss: 0.45212283730506897\n",
      "Epoch 1912, Loss: 2.971920669078827, Final Batch Loss: 0.6218500733375549\n",
      "Epoch 1913, Loss: 2.44518506526947, Final Batch Loss: 0.2148505449295044\n",
      "Epoch 1914, Loss: 2.543927550315857, Final Batch Loss: 0.2710963189601898\n",
      "Epoch 1915, Loss: 2.3612825125455856, Final Batch Loss: 0.18437783420085907\n",
      "Epoch 1916, Loss: 2.746594339609146, Final Batch Loss: 0.7062253952026367\n",
      "Epoch 1917, Loss: 2.6091291904449463, Final Batch Loss: 0.4702368378639221\n",
      "Epoch 1918, Loss: 2.8298548460006714, Final Batch Loss: 0.588753342628479\n",
      "Epoch 1919, Loss: 2.5908188223838806, Final Batch Loss: 0.3214845657348633\n",
      "Epoch 1920, Loss: 2.811208128929138, Final Batch Loss: 0.6070902943611145\n",
      "Epoch 1921, Loss: 2.692368507385254, Final Batch Loss: 0.47296905517578125\n",
      "Epoch 1922, Loss: 3.039596736431122, Final Batch Loss: 0.5966065526008606\n",
      "Epoch 1923, Loss: 2.5557976961135864, Final Batch Loss: 0.4250478744506836\n",
      "Epoch 1924, Loss: 3.1903040409088135, Final Batch Loss: 0.9596409201622009\n",
      "Epoch 1925, Loss: 2.801153063774109, Final Batch Loss: 0.49892109632492065\n",
      "Epoch 1926, Loss: 2.729551374912262, Final Batch Loss: 0.4915483593940735\n",
      "Epoch 1927, Loss: 2.9442631602287292, Final Batch Loss: 0.6759368181228638\n",
      "Epoch 1928, Loss: 2.9082931876182556, Final Batch Loss: 0.7063862681388855\n",
      "Epoch 1929, Loss: 2.5879562199115753, Final Batch Loss: 0.45031505823135376\n",
      "Epoch 1930, Loss: 2.8174847662448883, Final Batch Loss: 0.6022204756736755\n",
      "Epoch 1931, Loss: 2.7701275050640106, Final Batch Loss: 0.5776160359382629\n",
      "Epoch 1932, Loss: 3.0396581888198853, Final Batch Loss: 0.692092776298523\n",
      "Epoch 1933, Loss: 2.4514641165733337, Final Batch Loss: 0.305527001619339\n",
      "Epoch 1934, Loss: 2.7989005148410797, Final Batch Loss: 0.660489022731781\n",
      "Epoch 1935, Loss: 3.006626456975937, Final Batch Loss: 0.8479604125022888\n",
      "Epoch 1936, Loss: 2.6882511973381042, Final Batch Loss: 0.5027993321418762\n",
      "Epoch 1937, Loss: 2.849944055080414, Final Batch Loss: 0.48577451705932617\n",
      "Epoch 1938, Loss: 2.8835480213165283, Final Batch Loss: 0.6177453994750977\n",
      "Epoch 1939, Loss: 3.0063023567199707, Final Batch Loss: 0.7334397435188293\n",
      "Epoch 1940, Loss: 2.531801462173462, Final Batch Loss: 0.3190775513648987\n",
      "Epoch 1941, Loss: 2.973706543445587, Final Batch Loss: 0.693934977054596\n",
      "Epoch 1942, Loss: 2.5982403457164764, Final Batch Loss: 0.4524400234222412\n",
      "Epoch 1943, Loss: 2.8277927339076996, Final Batch Loss: 0.6238985657691956\n",
      "Epoch 1944, Loss: 3.176684319972992, Final Batch Loss: 0.9175243377685547\n",
      "Epoch 1945, Loss: 2.587238162755966, Final Batch Loss: 0.2902356684207916\n",
      "Epoch 1946, Loss: 2.44196480512619, Final Batch Loss: 0.3025085926055908\n",
      "Epoch 1947, Loss: 2.7950755953788757, Final Batch Loss: 0.6411097645759583\n",
      "Epoch 1948, Loss: 2.816657066345215, Final Batch Loss: 0.6043791174888611\n",
      "Epoch 1949, Loss: 2.7389836609363556, Final Batch Loss: 0.43347856402397156\n",
      "Epoch 1950, Loss: 2.989616245031357, Final Batch Loss: 0.8290867209434509\n",
      "Epoch 1951, Loss: 2.8964706659317017, Final Batch Loss: 0.5382564663887024\n",
      "Epoch 1952, Loss: 2.579001158475876, Final Batch Loss: 0.3521483242511749\n",
      "Epoch 1953, Loss: 2.785910815000534, Final Batch Loss: 0.5539718270301819\n",
      "Epoch 1954, Loss: 3.0488871335983276, Final Batch Loss: 0.8027995228767395\n",
      "Epoch 1955, Loss: 2.884442389011383, Final Batch Loss: 0.6022986769676208\n",
      "Epoch 1956, Loss: 3.0329114198684692, Final Batch Loss: 0.6715356111526489\n",
      "Epoch 1957, Loss: 2.804172545671463, Final Batch Loss: 0.5186866521835327\n",
      "Epoch 1958, Loss: 2.4531587958335876, Final Batch Loss: 0.2846783995628357\n",
      "Epoch 1959, Loss: 2.502470165491104, Final Batch Loss: 0.31053945422172546\n",
      "Epoch 1960, Loss: 2.7589370012283325, Final Batch Loss: 0.556634247303009\n",
      "Epoch 1961, Loss: 2.5560486018657684, Final Batch Loss: 0.3332603871822357\n",
      "Epoch 1962, Loss: 2.629801630973816, Final Batch Loss: 0.41726523637771606\n",
      "Epoch 1963, Loss: 2.6910170912742615, Final Batch Loss: 0.5628434419631958\n",
      "Epoch 1964, Loss: 2.808794856071472, Final Batch Loss: 0.5338168740272522\n",
      "Epoch 1965, Loss: 2.7682211101055145, Final Batch Loss: 0.4633748233318329\n",
      "Epoch 1966, Loss: 2.800057053565979, Final Batch Loss: 0.4776759147644043\n",
      "Epoch 1967, Loss: 2.5158203840255737, Final Batch Loss: 0.3450510501861572\n",
      "Epoch 1968, Loss: 2.5715026259422302, Final Batch Loss: 0.5261973142623901\n",
      "Epoch 1969, Loss: 2.7603361010551453, Final Batch Loss: 0.40061020851135254\n",
      "Epoch 1970, Loss: 2.4277965128421783, Final Batch Loss: 0.23067137598991394\n",
      "Epoch 1971, Loss: 2.2826273292303085, Final Batch Loss: 0.17948342859745026\n",
      "Epoch 1972, Loss: 2.854557126760483, Final Batch Loss: 0.7008758187294006\n",
      "Epoch 1973, Loss: 2.771059960126877, Final Batch Loss: 0.44264480471611023\n",
      "Epoch 1974, Loss: 2.592376619577408, Final Batch Loss: 0.3537133038043976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1975, Loss: 2.653894543647766, Final Batch Loss: 0.5914047956466675\n",
      "Epoch 1976, Loss: 2.696541130542755, Final Batch Loss: 0.45174264907836914\n",
      "Epoch 1977, Loss: 2.551910549402237, Final Batch Loss: 0.41444066166877747\n",
      "Epoch 1978, Loss: 2.846627175807953, Final Batch Loss: 0.701494038105011\n",
      "Epoch 1979, Loss: 2.7779150307178497, Final Batch Loss: 0.6654771566390991\n",
      "Epoch 1980, Loss: 2.172080084681511, Final Batch Loss: 0.10290496051311493\n",
      "Epoch 1981, Loss: 3.3200344145298004, Final Batch Loss: 1.0450950860977173\n",
      "Epoch 1982, Loss: 2.6816761791706085, Final Batch Loss: 0.4550360143184662\n",
      "Epoch 1983, Loss: 2.6455734074115753, Final Batch Loss: 0.41019055247306824\n",
      "Epoch 1984, Loss: 2.4725742638111115, Final Batch Loss: 0.30888059735298157\n",
      "Epoch 1985, Loss: 2.538548618555069, Final Batch Loss: 0.4208659827709198\n",
      "Epoch 1986, Loss: 2.3635971546173096, Final Batch Loss: 0.2754749357700348\n",
      "Epoch 1987, Loss: 2.448933631181717, Final Batch Loss: 0.31239065527915955\n",
      "Epoch 1988, Loss: 2.9083005785942078, Final Batch Loss: 0.6147703528404236\n",
      "Epoch 1989, Loss: 2.9760109186172485, Final Batch Loss: 0.8565607070922852\n",
      "Epoch 1990, Loss: 2.8875014781951904, Final Batch Loss: 0.8483702540397644\n",
      "Epoch 1991, Loss: 2.4438447058200836, Final Batch Loss: 0.31446340680122375\n",
      "Epoch 1992, Loss: 2.534416377544403, Final Batch Loss: 0.4168713390827179\n",
      "Epoch 1993, Loss: 2.7195456624031067, Final Batch Loss: 0.49412158131599426\n",
      "Epoch 1994, Loss: 2.707501620054245, Final Batch Loss: 0.40750852227211\n",
      "Epoch 1995, Loss: 2.8209590315818787, Final Batch Loss: 0.5754753947257996\n",
      "Epoch 1996, Loss: 2.704718679189682, Final Batch Loss: 0.3378705680370331\n",
      "Epoch 1997, Loss: 3.32088166475296, Final Batch Loss: 0.6404295563697815\n",
      "Epoch 1998, Loss: 3.2098429203033447, Final Batch Loss: 0.8181257843971252\n",
      "Epoch 1999, Loss: 2.3107959665358067, Final Batch Loss: 0.051123443990945816\n",
      "Epoch 2000, Loss: 2.6100041568279266, Final Batch Loss: 0.34870174527168274\n",
      "Epoch 2001, Loss: 2.6247760951519012, Final Batch Loss: 0.47415605187416077\n",
      "Epoch 2002, Loss: 3.0024067163467407, Final Batch Loss: 0.7282811403274536\n",
      "Epoch 2003, Loss: 3.1024214923381805, Final Batch Loss: 0.9358978271484375\n",
      "Epoch 2004, Loss: 2.9892452359199524, Final Batch Loss: 0.6360582709312439\n",
      "Epoch 2005, Loss: 2.7797136306762695, Final Batch Loss: 0.46540021896362305\n",
      "Epoch 2006, Loss: 2.9858086705207825, Final Batch Loss: 0.7799844145774841\n",
      "Epoch 2007, Loss: 3.285468816757202, Final Batch Loss: 1.0482083559036255\n",
      "Epoch 2008, Loss: 2.629460096359253, Final Batch Loss: 0.3836974501609802\n",
      "Epoch 2009, Loss: 2.9148280024528503, Final Batch Loss: 0.6327832341194153\n",
      "Epoch 2010, Loss: 2.9224804639816284, Final Batch Loss: 0.5957155227661133\n",
      "Epoch 2011, Loss: 2.6200818717479706, Final Batch Loss: 0.38542240858078003\n",
      "Epoch 2012, Loss: 2.756018191576004, Final Batch Loss: 0.49933281540870667\n",
      "Epoch 2013, Loss: 2.98675274848938, Final Batch Loss: 0.8251089453697205\n",
      "Epoch 2014, Loss: 2.766214430332184, Final Batch Loss: 0.44158026576042175\n",
      "Epoch 2015, Loss: 2.4340579211711884, Final Batch Loss: 0.3038332760334015\n",
      "Epoch 2016, Loss: 2.8978899717330933, Final Batch Loss: 0.7958065271377563\n",
      "Epoch 2017, Loss: 2.5047502517700195, Final Batch Loss: 0.33576700091362\n",
      "Epoch 2018, Loss: 2.777936965227127, Final Batch Loss: 0.6424593925476074\n",
      "Epoch 2019, Loss: 2.7309999763965607, Final Batch Loss: 0.43624815344810486\n",
      "Epoch 2020, Loss: 2.24147991836071, Final Batch Loss: 0.07655487954616547\n",
      "Epoch 2021, Loss: 2.6973926424980164, Final Batch Loss: 0.6016685366630554\n",
      "Epoch 2022, Loss: 2.4122153222560883, Final Batch Loss: 0.41379761695861816\n",
      "Epoch 2023, Loss: 2.5797742903232574, Final Batch Loss: 0.5326520204544067\n",
      "Epoch 2024, Loss: 2.750601351261139, Final Batch Loss: 0.4387335777282715\n",
      "Epoch 2025, Loss: 2.474683851003647, Final Batch Loss: 0.20106390118598938\n",
      "Epoch 2026, Loss: 2.7688555121421814, Final Batch Loss: 0.6609982252120972\n",
      "Epoch 2027, Loss: 2.659889340400696, Final Batch Loss: 0.6130018830299377\n",
      "Epoch 2028, Loss: 2.521814078092575, Final Batch Loss: 0.3358289301395416\n",
      "Epoch 2029, Loss: 2.9298322200775146, Final Batch Loss: 0.6006633043289185\n",
      "Epoch 2030, Loss: 2.653062015771866, Final Batch Loss: 0.4599210321903229\n",
      "Epoch 2031, Loss: 2.5613615214824677, Final Batch Loss: 0.36960527300834656\n",
      "Epoch 2032, Loss: 2.5082387179136276, Final Batch Loss: 0.24987630546092987\n",
      "Epoch 2033, Loss: 2.2875045761466026, Final Batch Loss: 0.11229892820119858\n",
      "Epoch 2034, Loss: 2.76340451836586, Final Batch Loss: 0.49274328351020813\n",
      "Epoch 2035, Loss: 2.3711570501327515, Final Batch Loss: 0.3536853790283203\n",
      "Epoch 2036, Loss: 2.4850290417671204, Final Batch Loss: 0.3091217875480652\n",
      "Epoch 2037, Loss: 2.732286214828491, Final Batch Loss: 0.5861874222755432\n",
      "Epoch 2038, Loss: 2.545088529586792, Final Batch Loss: 0.42270779609680176\n",
      "Epoch 2039, Loss: 2.7053708136081696, Final Batch Loss: 0.6106501221656799\n",
      "Epoch 2040, Loss: 2.672861248254776, Final Batch Loss: 0.4062584340572357\n",
      "Epoch 2041, Loss: 2.708091139793396, Final Batch Loss: 0.49285608530044556\n",
      "Epoch 2042, Loss: 2.6424141228199005, Final Batch Loss: 0.4960777163505554\n",
      "Epoch 2043, Loss: 2.7742218375205994, Final Batch Loss: 0.6444769501686096\n",
      "Epoch 2044, Loss: 2.898751378059387, Final Batch Loss: 0.6621288657188416\n",
      "Epoch 2045, Loss: 2.712257981300354, Final Batch Loss: 0.5644840002059937\n",
      "Epoch 2046, Loss: 2.4422191083431244, Final Batch Loss: 0.31713175773620605\n",
      "Epoch 2047, Loss: 2.469517260789871, Final Batch Loss: 0.36368468403816223\n",
      "Epoch 2048, Loss: 2.6842972338199615, Final Batch Loss: 0.6252856850624084\n",
      "Epoch 2049, Loss: 2.9751638174057007, Final Batch Loss: 0.7840107679367065\n",
      "Epoch 2050, Loss: 2.576095312833786, Final Batch Loss: 0.45324772596359253\n",
      "Epoch 2051, Loss: 2.566798597574234, Final Batch Loss: 0.3523375988006592\n",
      "Epoch 2052, Loss: 2.433709979057312, Final Batch Loss: 0.3509993553161621\n",
      "Epoch 2053, Loss: 2.6411814093589783, Final Batch Loss: 0.4233393967151642\n",
      "Epoch 2054, Loss: 2.7069928646087646, Final Batch Loss: 0.5003780722618103\n",
      "Epoch 2055, Loss: 2.9508525729179382, Final Batch Loss: 0.6043913960456848\n",
      "Epoch 2056, Loss: 2.706128090620041, Final Batch Loss: 0.5947429537773132\n",
      "Epoch 2057, Loss: 2.9129003286361694, Final Batch Loss: 0.6326666474342346\n",
      "Epoch 2058, Loss: 2.840218663215637, Final Batch Loss: 0.6769105195999146\n",
      "Epoch 2059, Loss: 3.057809740304947, Final Batch Loss: 0.9178751111030579\n",
      "Epoch 2060, Loss: 2.4646469056606293, Final Batch Loss: 0.33034399151802063\n",
      "Epoch 2061, Loss: 2.478580802679062, Final Batch Loss: 0.36827734112739563\n",
      "Epoch 2062, Loss: 3.0010353326797485, Final Batch Loss: 0.8692197799682617\n",
      "Epoch 2063, Loss: 2.7158415019512177, Final Batch Loss: 0.5930942893028259\n",
      "Epoch 2064, Loss: 2.5940845608711243, Final Batch Loss: 0.47940942645072937\n",
      "Epoch 2065, Loss: 2.539426878094673, Final Batch Loss: 0.16905315220355988\n",
      "Epoch 2066, Loss: 2.728749603033066, Final Batch Loss: 0.2990168035030365\n",
      "Epoch 2067, Loss: 2.737673282623291, Final Batch Loss: 0.4464382529258728\n",
      "Epoch 2068, Loss: 3.33261376619339, Final Batch Loss: 1.20714271068573\n",
      "Epoch 2069, Loss: 2.6796799302101135, Final Batch Loss: 0.38659411668777466\n",
      "Epoch 2070, Loss: 2.9482255578041077, Final Batch Loss: 0.662112295627594\n",
      "Epoch 2071, Loss: 2.744428813457489, Final Batch Loss: 0.543380618095398\n",
      "Epoch 2072, Loss: 2.623834192752838, Final Batch Loss: 0.5239105224609375\n",
      "Epoch 2073, Loss: 2.567995071411133, Final Batch Loss: 0.367265522480011\n",
      "Epoch 2074, Loss: 2.534849464893341, Final Batch Loss: 0.37320801615715027\n",
      "Epoch 2075, Loss: 3.0085180401802063, Final Batch Loss: 0.8631930947303772\n",
      "Epoch 2076, Loss: 2.64694881439209, Final Batch Loss: 0.4935917854309082\n",
      "Epoch 2077, Loss: 2.426675945520401, Final Batch Loss: 0.3414219319820404\n",
      "Epoch 2078, Loss: 2.8232671320438385, Final Batch Loss: 0.6909103989601135\n",
      "Epoch 2079, Loss: 2.888196676969528, Final Batch Loss: 0.80746990442276\n",
      "Epoch 2080, Loss: 2.809279054403305, Final Batch Loss: 0.6756653189659119\n",
      "Epoch 2081, Loss: 3.0363189578056335, Final Batch Loss: 0.6982241868972778\n",
      "Epoch 2082, Loss: 2.421481430530548, Final Batch Loss: 0.28121134638786316\n",
      "Epoch 2083, Loss: 2.3230268955230713, Final Batch Loss: 0.3436165452003479\n",
      "Epoch 2084, Loss: 3.0471822023391724, Final Batch Loss: 0.9991078972816467\n",
      "Epoch 2085, Loss: 2.4337336122989655, Final Batch Loss: 0.2685312330722809\n",
      "Epoch 2086, Loss: 2.6746468544006348, Final Batch Loss: 0.5315843820571899\n",
      "Epoch 2087, Loss: 2.830508977174759, Final Batch Loss: 0.4920653998851776\n",
      "Epoch 2088, Loss: 2.548972249031067, Final Batch Loss: 0.4476526081562042\n",
      "Epoch 2089, Loss: 2.7118164896965027, Final Batch Loss: 0.4947705864906311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2090, Loss: 2.6715823113918304, Final Batch Loss: 0.31264474987983704\n",
      "Epoch 2091, Loss: 2.645209312438965, Final Batch Loss: 0.506808340549469\n",
      "Epoch 2092, Loss: 2.9170065820217133, Final Batch Loss: 0.6365582346916199\n",
      "Epoch 2093, Loss: 2.7140983641147614, Final Batch Loss: 0.4799109101295471\n",
      "Epoch 2094, Loss: 2.575097441673279, Final Batch Loss: 0.2939804196357727\n",
      "Epoch 2095, Loss: 2.7841323912143707, Final Batch Loss: 0.6689813733100891\n",
      "Epoch 2096, Loss: 2.401401787996292, Final Batch Loss: 0.37197446823120117\n",
      "Epoch 2097, Loss: 2.5048305690288544, Final Batch Loss: 0.22397494316101074\n",
      "Epoch 2098, Loss: 2.4234452843666077, Final Batch Loss: 0.21661734580993652\n",
      "Epoch 2099, Loss: 2.545465737581253, Final Batch Loss: 0.3936636447906494\n",
      "Epoch 2100, Loss: 3.048810303211212, Final Batch Loss: 0.7675557136535645\n",
      "Epoch 2101, Loss: 2.5458911061286926, Final Batch Loss: 0.28917592763900757\n",
      "Epoch 2102, Loss: 3.573880583047867, Final Batch Loss: 1.3980549573898315\n",
      "Epoch 2103, Loss: 2.8201780915260315, Final Batch Loss: 0.5244015455245972\n",
      "Epoch 2104, Loss: 2.6615514159202576, Final Batch Loss: 0.410645067691803\n",
      "Epoch 2105, Loss: 2.6381258368492126, Final Batch Loss: 0.3685837388038635\n",
      "Epoch 2106, Loss: 2.589652359485626, Final Batch Loss: 0.2774496078491211\n",
      "Epoch 2107, Loss: 2.6702516078948975, Final Batch Loss: 0.5676263570785522\n",
      "Epoch 2108, Loss: 2.834882974624634, Final Batch Loss: 0.7639538645744324\n",
      "Epoch 2109, Loss: 2.434088796377182, Final Batch Loss: 0.2036411464214325\n",
      "Epoch 2110, Loss: 2.8236111998558044, Final Batch Loss: 0.6160222291946411\n",
      "Epoch 2111, Loss: 2.3866695165634155, Final Batch Loss: 0.2350209653377533\n",
      "Epoch 2112, Loss: 2.654567778110504, Final Batch Loss: 0.5536586046218872\n",
      "Epoch 2113, Loss: 2.5775575935840607, Final Batch Loss: 0.43007779121398926\n",
      "Epoch 2114, Loss: 2.4988387525081635, Final Batch Loss: 0.32306137681007385\n",
      "Epoch 2115, Loss: 2.9241092801094055, Final Batch Loss: 0.7502384781837463\n",
      "Epoch 2116, Loss: 2.5527686178684235, Final Batch Loss: 0.4805581569671631\n",
      "Epoch 2117, Loss: 2.509051889181137, Final Batch Loss: 0.43197426199913025\n",
      "Epoch 2118, Loss: 2.772246390581131, Final Batch Loss: 0.6334196925163269\n",
      "Epoch 2119, Loss: 2.691303163766861, Final Batch Loss: 0.5092145800590515\n",
      "Epoch 2120, Loss: 2.578165739774704, Final Batch Loss: 0.4135740101337433\n",
      "Epoch 2121, Loss: 3.5847347378730774, Final Batch Loss: 1.423805832862854\n",
      "Epoch 2122, Loss: 2.468680903315544, Final Batch Loss: 0.2377057522535324\n",
      "Epoch 2123, Loss: 2.8520890176296234, Final Batch Loss: 0.6815587878227234\n",
      "Epoch 2124, Loss: 2.525061547756195, Final Batch Loss: 0.35334035754203796\n",
      "Epoch 2125, Loss: 2.8023806512355804, Final Batch Loss: 0.6277872920036316\n",
      "Epoch 2126, Loss: 2.6263014376163483, Final Batch Loss: 0.5369962453842163\n",
      "Epoch 2127, Loss: 2.7115805447101593, Final Batch Loss: 0.48214152455329895\n",
      "Epoch 2128, Loss: 2.5787622928619385, Final Batch Loss: 0.39728257060050964\n",
      "Epoch 2129, Loss: 2.8139693439006805, Final Batch Loss: 0.5855574607849121\n",
      "Epoch 2130, Loss: 2.621999889612198, Final Batch Loss: 0.3903539478778839\n",
      "Epoch 2131, Loss: 2.830664038658142, Final Batch Loss: 0.6422882676124573\n",
      "Epoch 2132, Loss: 2.961247831583023, Final Batch Loss: 0.7712827324867249\n",
      "Epoch 2133, Loss: 2.675639420747757, Final Batch Loss: 0.5802604556083679\n",
      "Epoch 2134, Loss: 2.462532877922058, Final Batch Loss: 0.30116820335388184\n",
      "Epoch 2135, Loss: 2.411600351333618, Final Batch Loss: 0.3024241328239441\n",
      "Epoch 2136, Loss: 2.3818070888519287, Final Batch Loss: 0.25067847967147827\n",
      "Epoch 2137, Loss: 3.2117013931274414, Final Batch Loss: 1.021775245666504\n",
      "Epoch 2138, Loss: 2.4504867494106293, Final Batch Loss: 0.2976211905479431\n",
      "Epoch 2139, Loss: 2.5019931495189667, Final Batch Loss: 0.40396547317504883\n",
      "Epoch 2140, Loss: 2.6366696059703827, Final Batch Loss: 0.5175197720527649\n",
      "Epoch 2141, Loss: 2.822385311126709, Final Batch Loss: 0.569200873374939\n",
      "Epoch 2142, Loss: 2.8959504067897797, Final Batch Loss: 0.8061538338661194\n",
      "Epoch 2143, Loss: 2.7336390018463135, Final Batch Loss: 0.6067853569984436\n",
      "Epoch 2144, Loss: 3.139253795146942, Final Batch Loss: 0.9316354990005493\n",
      "Epoch 2145, Loss: 2.63434836268425, Final Batch Loss: 0.5660637021064758\n",
      "Epoch 2146, Loss: 2.669128328561783, Final Batch Loss: 0.45189806818962097\n",
      "Epoch 2147, Loss: 2.6354661881923676, Final Batch Loss: 0.41034677624702454\n",
      "Epoch 2148, Loss: 3.2620846033096313, Final Batch Loss: 0.9283784627914429\n",
      "Epoch 2149, Loss: 2.1784216687083244, Final Batch Loss: 0.044773899018764496\n",
      "Epoch 2150, Loss: 2.312456466257572, Final Batch Loss: 0.06107119470834732\n",
      "Epoch 2151, Loss: 2.713476002216339, Final Batch Loss: 0.45653367042541504\n",
      "Epoch 2152, Loss: 2.421090990304947, Final Batch Loss: 0.18375203013420105\n",
      "Epoch 2153, Loss: 2.5659953355789185, Final Batch Loss: 0.4384104609489441\n",
      "Epoch 2154, Loss: 2.7600064277648926, Final Batch Loss: 0.5780566930770874\n",
      "Epoch 2155, Loss: 2.6117069125175476, Final Batch Loss: 0.4534807503223419\n",
      "Epoch 2156, Loss: 2.1791702061891556, Final Batch Loss: 0.11370481550693512\n",
      "Epoch 2157, Loss: 2.5252825021743774, Final Batch Loss: 0.433460533618927\n",
      "Epoch 2158, Loss: 3.0233173966407776, Final Batch Loss: 0.8808702230453491\n",
      "Epoch 2159, Loss: 2.961971879005432, Final Batch Loss: 0.7349820137023926\n",
      "Epoch 2160, Loss: 2.434929698705673, Final Batch Loss: 0.39323097467422485\n",
      "Epoch 2161, Loss: 2.611061930656433, Final Batch Loss: 0.5207632184028625\n",
      "Epoch 2162, Loss: 2.560491621494293, Final Batch Loss: 0.40165066719055176\n",
      "Epoch 2163, Loss: 2.8668254017829895, Final Batch Loss: 0.751159131526947\n",
      "Epoch 2164, Loss: 2.5599249601364136, Final Batch Loss: 0.48018163442611694\n",
      "Epoch 2165, Loss: 3.119638353586197, Final Batch Loss: 1.0017755031585693\n",
      "Epoch 2166, Loss: 2.6699926555156708, Final Batch Loss: 0.57428377866745\n",
      "Epoch 2167, Loss: 2.746108740568161, Final Batch Loss: 0.49159738421440125\n",
      "Epoch 2168, Loss: 2.8801850080490112, Final Batch Loss: 0.6767064332962036\n",
      "Epoch 2169, Loss: 2.742959588766098, Final Batch Loss: 0.5814026594161987\n",
      "Epoch 2170, Loss: 2.860170364379883, Final Batch Loss: 0.6407426595687866\n",
      "Epoch 2171, Loss: 2.993111103773117, Final Batch Loss: 0.8599443435668945\n",
      "Epoch 2172, Loss: 2.8605147898197174, Final Batch Loss: 0.7738231420516968\n",
      "Epoch 2173, Loss: 2.8018766343593597, Final Batch Loss: 0.34694889187812805\n",
      "Epoch 2174, Loss: 2.5463640987873077, Final Batch Loss: 0.43184229731559753\n",
      "Epoch 2175, Loss: 2.6197912395000458, Final Batch Loss: 0.41510009765625\n",
      "Epoch 2176, Loss: 2.9649811387062073, Final Batch Loss: 0.9403828978538513\n",
      "Epoch 2177, Loss: 2.6942408084869385, Final Batch Loss: 0.4762873649597168\n",
      "Epoch 2178, Loss: 3.0093706250190735, Final Batch Loss: 0.8279973864555359\n",
      "Epoch 2179, Loss: 2.5037632882595062, Final Batch Loss: 0.4642455279827118\n",
      "Epoch 2180, Loss: 2.6249722838401794, Final Batch Loss: 0.4551713466644287\n",
      "Epoch 2181, Loss: 2.7505910992622375, Final Batch Loss: 0.6317383050918579\n",
      "Epoch 2182, Loss: 2.5116816759109497, Final Batch Loss: 0.3775331676006317\n",
      "Epoch 2183, Loss: 2.5449602901935577, Final Batch Loss: 0.3623967170715332\n",
      "Epoch 2184, Loss: 2.45902019739151, Final Batch Loss: 0.4556560218334198\n",
      "Epoch 2185, Loss: 2.541869044303894, Final Batch Loss: 0.5764322280883789\n",
      "Epoch 2186, Loss: 2.390157073736191, Final Batch Loss: 0.29721707105636597\n",
      "Epoch 2187, Loss: 2.369644522666931, Final Batch Loss: 0.18607807159423828\n",
      "Epoch 2188, Loss: 2.8716765344142914, Final Batch Loss: 0.7238909006118774\n",
      "Epoch 2189, Loss: 2.6274032592773438, Final Batch Loss: 0.4979201853275299\n",
      "Epoch 2190, Loss: 2.4536190927028656, Final Batch Loss: 0.3637900948524475\n",
      "Epoch 2191, Loss: 2.122411474585533, Final Batch Loss: 0.1443232148885727\n",
      "Epoch 2192, Loss: 3.2727656960487366, Final Batch Loss: 1.243155598640442\n",
      "Epoch 2193, Loss: 2.758894979953766, Final Batch Loss: 0.7367424964904785\n",
      "Epoch 2194, Loss: 2.5974902510643005, Final Batch Loss: 0.5786466002464294\n",
      "Epoch 2195, Loss: 2.865295648574829, Final Batch Loss: 0.7786034941673279\n",
      "Epoch 2196, Loss: 2.315348505973816, Final Batch Loss: 0.22903063893318176\n",
      "Epoch 2197, Loss: 2.804993689060211, Final Batch Loss: 0.6335868835449219\n",
      "Epoch 2198, Loss: 2.523220270872116, Final Batch Loss: 0.31658729910850525\n",
      "Epoch 2199, Loss: 2.4776913225650787, Final Batch Loss: 0.4236082434654236\n",
      "Epoch 2200, Loss: 2.7758232951164246, Final Batch Loss: 0.6279374361038208\n",
      "Epoch 2201, Loss: 3.2187657952308655, Final Batch Loss: 0.86082524061203\n",
      "Epoch 2202, Loss: 2.973973870277405, Final Batch Loss: 0.8668385148048401\n",
      "Epoch 2203, Loss: 2.5696537792682648, Final Batch Loss: 0.44731494784355164\n",
      "Epoch 2204, Loss: 2.7539208829402924, Final Batch Loss: 0.653757631778717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2205, Loss: 2.5959098041057587, Final Batch Loss: 0.4510604441165924\n",
      "Epoch 2206, Loss: 2.487680435180664, Final Batch Loss: 0.41671591997146606\n",
      "Epoch 2207, Loss: 2.524685800075531, Final Batch Loss: 0.35204896330833435\n",
      "Epoch 2208, Loss: 2.514035224914551, Final Batch Loss: 0.38260310888290405\n",
      "Epoch 2209, Loss: 2.5232151448726654, Final Batch Loss: 0.35075297951698303\n",
      "Epoch 2210, Loss: 3.0778309106826782, Final Batch Loss: 0.8610659241676331\n",
      "Epoch 2211, Loss: 2.7056325376033783, Final Batch Loss: 0.4347268044948578\n",
      "Epoch 2212, Loss: 2.3405537605285645, Final Batch Loss: 0.40568849444389343\n",
      "Epoch 2213, Loss: 2.797744959592819, Final Batch Loss: 0.6970474123954773\n",
      "Epoch 2214, Loss: 2.5278115570545197, Final Batch Loss: 0.42066076397895813\n",
      "Epoch 2215, Loss: 2.353771358728409, Final Batch Loss: 0.17721125483512878\n",
      "Epoch 2216, Loss: 2.6076418459415436, Final Batch Loss: 0.5483986139297485\n",
      "Epoch 2217, Loss: 2.1607890874147415, Final Batch Loss: 0.12686274945735931\n",
      "Epoch 2218, Loss: 2.5099377930164337, Final Batch Loss: 0.28398969769477844\n",
      "Epoch 2219, Loss: 2.4808093309402466, Final Batch Loss: 0.4338633418083191\n",
      "Epoch 2220, Loss: 2.9063838124275208, Final Batch Loss: 0.6412922143936157\n",
      "Epoch 2221, Loss: 2.995970278978348, Final Batch Loss: 0.8819808959960938\n",
      "Epoch 2222, Loss: 2.6514048278331757, Final Batch Loss: 0.47496500611305237\n",
      "Epoch 2223, Loss: 3.2110978960990906, Final Batch Loss: 1.0225101709365845\n",
      "Epoch 2224, Loss: 2.664081424474716, Final Batch Loss: 0.44147875905036926\n",
      "Epoch 2225, Loss: 3.081715762615204, Final Batch Loss: 0.8237500190734863\n",
      "Epoch 2226, Loss: 2.9648237228393555, Final Batch Loss: 0.5671354532241821\n",
      "Epoch 2227, Loss: 3.149970829486847, Final Batch Loss: 0.7700842022895813\n",
      "Epoch 2228, Loss: 2.860015869140625, Final Batch Loss: 0.6018690466880798\n",
      "Epoch 2229, Loss: 2.5663163661956787, Final Batch Loss: 0.32570868730545044\n",
      "Epoch 2230, Loss: 2.9064644277095795, Final Batch Loss: 0.7831844091415405\n",
      "Epoch 2231, Loss: 2.5685484409332275, Final Batch Loss: 0.2843850255012512\n",
      "Epoch 2232, Loss: 2.9110592007637024, Final Batch Loss: 0.6411005854606628\n",
      "Epoch 2233, Loss: 2.76102477312088, Final Batch Loss: 0.5433529019355774\n",
      "Epoch 2234, Loss: 2.6640639305114746, Final Batch Loss: 0.5027931928634644\n",
      "Epoch 2235, Loss: 2.8914045691490173, Final Batch Loss: 0.6773382425308228\n",
      "Epoch 2236, Loss: 2.62489977478981, Final Batch Loss: 0.40494421124458313\n",
      "Epoch 2237, Loss: 2.5907465517520905, Final Batch Loss: 0.2939634621143341\n",
      "Epoch 2238, Loss: 2.706786274909973, Final Batch Loss: 0.5556445121765137\n",
      "Epoch 2239, Loss: 2.5660231709480286, Final Batch Loss: 0.4889555275440216\n",
      "Epoch 2240, Loss: 2.9929189682006836, Final Batch Loss: 0.9432732462882996\n",
      "Epoch 2241, Loss: 3.042220860719681, Final Batch Loss: 0.9338027834892273\n",
      "Epoch 2242, Loss: 2.443880647420883, Final Batch Loss: 0.26845234632492065\n",
      "Epoch 2243, Loss: 2.4251144528388977, Final Batch Loss: 0.36051151156425476\n",
      "Epoch 2244, Loss: 2.5928723514080048, Final Batch Loss: 0.5745701193809509\n",
      "Epoch 2245, Loss: 2.787968933582306, Final Batch Loss: 0.5462731122970581\n",
      "Epoch 2246, Loss: 2.659480780363083, Final Batch Loss: 0.35699692368507385\n",
      "Epoch 2247, Loss: 2.5828928649425507, Final Batch Loss: 0.5208815932273865\n",
      "Epoch 2248, Loss: 2.5153858363628387, Final Batch Loss: 0.3578992784023285\n",
      "Epoch 2249, Loss: 2.632845163345337, Final Batch Loss: 0.5314208269119263\n",
      "Epoch 2250, Loss: 2.4041404128074646, Final Batch Loss: 0.2316608428955078\n",
      "Epoch 2251, Loss: 2.6881295442581177, Final Batch Loss: 0.714516282081604\n",
      "Epoch 2252, Loss: 2.3649483621120453, Final Batch Loss: 0.3211762309074402\n",
      "Epoch 2253, Loss: 2.968069911003113, Final Batch Loss: 0.8556087613105774\n",
      "Epoch 2254, Loss: 2.6199351251125336, Final Batch Loss: 0.45248013734817505\n",
      "Epoch 2255, Loss: 3.324989438056946, Final Batch Loss: 1.1937284469604492\n",
      "Epoch 2256, Loss: 2.354123592376709, Final Batch Loss: 0.31898802518844604\n",
      "Epoch 2257, Loss: 2.6552446484565735, Final Batch Loss: 0.5332812666893005\n",
      "Epoch 2258, Loss: 2.5586203038692474, Final Batch Loss: 0.47485676407814026\n",
      "Epoch 2259, Loss: 2.5051551163196564, Final Batch Loss: 0.31321415305137634\n",
      "Epoch 2260, Loss: 2.502522051334381, Final Batch Loss: 0.34087973833084106\n",
      "Epoch 2261, Loss: 2.4761578142642975, Final Batch Loss: 0.4224150478839874\n",
      "Epoch 2262, Loss: 2.3736320436000824, Final Batch Loss: 0.2999420166015625\n",
      "Epoch 2263, Loss: 2.196116164326668, Final Batch Loss: 0.1512756198644638\n",
      "Epoch 2264, Loss: 2.4408492147922516, Final Batch Loss: 0.4179284870624542\n",
      "Epoch 2265, Loss: 2.576287120580673, Final Batch Loss: 0.4907999336719513\n",
      "Epoch 2266, Loss: 2.5174302458763123, Final Batch Loss: 0.48447543382644653\n",
      "Epoch 2267, Loss: 2.390455424785614, Final Batch Loss: 0.37586766481399536\n",
      "Epoch 2268, Loss: 2.50725194811821, Final Batch Loss: 0.3672456741333008\n",
      "Epoch 2269, Loss: 3.109863758087158, Final Batch Loss: 1.032769799232483\n",
      "Epoch 2270, Loss: 2.6431059539318085, Final Batch Loss: 0.6308807134628296\n",
      "Epoch 2271, Loss: 2.8358342051506042, Final Batch Loss: 0.7546907663345337\n",
      "Epoch 2272, Loss: 2.5177161395549774, Final Batch Loss: 0.45788294076919556\n",
      "Epoch 2273, Loss: 2.5253413021564484, Final Batch Loss: 0.34160223603248596\n",
      "Epoch 2274, Loss: 2.5934639871120453, Final Batch Loss: 0.5012425184249878\n",
      "Epoch 2275, Loss: 2.492980480194092, Final Batch Loss: 0.2873837649822235\n",
      "Epoch 2276, Loss: 2.78286275267601, Final Batch Loss: 0.7210990190505981\n",
      "Epoch 2277, Loss: 2.5233605802059174, Final Batch Loss: 0.3363131582736969\n",
      "Epoch 2278, Loss: 2.7905867397785187, Final Batch Loss: 0.735990583896637\n",
      "Epoch 2279, Loss: 3.0839430689811707, Final Batch Loss: 0.8273842930793762\n",
      "Epoch 2280, Loss: 2.659164071083069, Final Batch Loss: 0.5517672300338745\n",
      "Epoch 2281, Loss: 2.445914179086685, Final Batch Loss: 0.28614482283592224\n",
      "Epoch 2282, Loss: 2.343916594982147, Final Batch Loss: 0.20226526260375977\n",
      "Epoch 2283, Loss: 2.556103825569153, Final Batch Loss: 0.40646395087242126\n",
      "Epoch 2284, Loss: 2.3939573168754578, Final Batch Loss: 0.35617849230766296\n",
      "Epoch 2285, Loss: 2.6973257958889008, Final Batch Loss: 0.5922640562057495\n",
      "Epoch 2286, Loss: 2.6462028324604034, Final Batch Loss: 0.6416935920715332\n",
      "Epoch 2287, Loss: 2.587286412715912, Final Batch Loss: 0.4908197224140167\n",
      "Epoch 2288, Loss: 2.3923797756433487, Final Batch Loss: 0.22969575226306915\n",
      "Epoch 2289, Loss: 2.982219010591507, Final Batch Loss: 0.8416261076927185\n",
      "Epoch 2290, Loss: 2.3557917922735214, Final Batch Loss: 0.20590578019618988\n",
      "Epoch 2291, Loss: 2.9720884561538696, Final Batch Loss: 0.8627815246582031\n",
      "Epoch 2292, Loss: 2.9180920124053955, Final Batch Loss: 0.7499507665634155\n",
      "Epoch 2293, Loss: 2.651804208755493, Final Batch Loss: 0.3236299157142639\n",
      "Epoch 2294, Loss: 2.885795533657074, Final Batch Loss: 0.852892279624939\n",
      "Epoch 2295, Loss: 2.960893988609314, Final Batch Loss: 0.8880621790885925\n",
      "Epoch 2296, Loss: 2.4115345776081085, Final Batch Loss: 0.3674623668193817\n",
      "Epoch 2297, Loss: 2.395379453897476, Final Batch Loss: 0.34483909606933594\n",
      "Epoch 2298, Loss: 2.79130220413208, Final Batch Loss: 0.5795744061470032\n",
      "Epoch 2299, Loss: 2.669632703065872, Final Batch Loss: 0.5513429641723633\n",
      "Epoch 2300, Loss: 2.7287833094596863, Final Batch Loss: 0.6894384622573853\n",
      "Epoch 2301, Loss: 2.642585903406143, Final Batch Loss: 0.4530717432498932\n",
      "Epoch 2302, Loss: 2.7737233638763428, Final Batch Loss: 0.5932278037071228\n",
      "Epoch 2303, Loss: 2.613641381263733, Final Batch Loss: 0.555038332939148\n",
      "Epoch 2304, Loss: 2.4815811812877655, Final Batch Loss: 0.4128001630306244\n",
      "Epoch 2305, Loss: 2.5875419080257416, Final Batch Loss: 0.46106645464897156\n",
      "Epoch 2306, Loss: 2.902933120727539, Final Batch Loss: 0.8339999914169312\n",
      "Epoch 2307, Loss: 2.497578352689743, Final Batch Loss: 0.46959516406059265\n",
      "Epoch 2308, Loss: 3.0825774669647217, Final Batch Loss: 0.9296311140060425\n",
      "Epoch 2309, Loss: 2.996497333049774, Final Batch Loss: 1.0171582698822021\n",
      "Epoch 2310, Loss: 2.6059904992580414, Final Batch Loss: 0.4496431052684784\n",
      "Epoch 2311, Loss: 2.61774742603302, Final Batch Loss: 0.5347224473953247\n",
      "Epoch 2312, Loss: 2.735545724630356, Final Batch Loss: 0.5006598234176636\n",
      "Epoch 2313, Loss: 2.619572937488556, Final Batch Loss: 0.4733315110206604\n",
      "Epoch 2314, Loss: 2.6370905935764313, Final Batch Loss: 0.5024887919425964\n",
      "Epoch 2315, Loss: 2.741577059030533, Final Batch Loss: 0.4521503150463104\n",
      "Epoch 2316, Loss: 2.468197464942932, Final Batch Loss: 0.5457409024238586\n",
      "Epoch 2317, Loss: 2.6210113167762756, Final Batch Loss: 0.4454994201660156\n",
      "Epoch 2318, Loss: 2.3910790383815765, Final Batch Loss: 0.3446952998638153\n",
      "Epoch 2319, Loss: 2.470140218734741, Final Batch Loss: 0.35853835940361023\n",
      "Epoch 2320, Loss: 2.5336833000183105, Final Batch Loss: 0.4569604992866516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2321, Loss: 2.360274016857147, Final Batch Loss: 0.3133833706378937\n",
      "Epoch 2322, Loss: 2.4823280572891235, Final Batch Loss: 0.5212514400482178\n",
      "Epoch 2323, Loss: 2.556408256292343, Final Batch Loss: 0.48857221007347107\n",
      "Epoch 2324, Loss: 2.6677539944648743, Final Batch Loss: 0.5068044066429138\n",
      "Epoch 2325, Loss: 2.615145355463028, Final Batch Loss: 0.5617865920066833\n",
      "Epoch 2326, Loss: 2.752846449613571, Final Batch Loss: 0.6782817840576172\n",
      "Epoch 2327, Loss: 2.548077791929245, Final Batch Loss: 0.4090843200683594\n",
      "Epoch 2328, Loss: 2.231916055083275, Final Batch Loss: 0.06936715543270111\n",
      "Epoch 2329, Loss: 2.2698028683662415, Final Batch Loss: 0.25153595209121704\n",
      "Epoch 2330, Loss: 2.8907021582126617, Final Batch Loss: 0.9130274653434753\n",
      "Epoch 2331, Loss: 2.6041550040245056, Final Batch Loss: 0.5289536118507385\n",
      "Epoch 2332, Loss: 2.5769564509391785, Final Batch Loss: 0.5586305856704712\n",
      "Epoch 2333, Loss: 2.682424008846283, Final Batch Loss: 0.6763748526573181\n",
      "Epoch 2334, Loss: 2.886617511510849, Final Batch Loss: 0.6950898170471191\n",
      "Epoch 2335, Loss: 2.699822574853897, Final Batch Loss: 0.6485344767570496\n",
      "Epoch 2336, Loss: 2.5211311280727386, Final Batch Loss: 0.4579559862613678\n",
      "Epoch 2337, Loss: 2.6059359312057495, Final Batch Loss: 0.5728644728660583\n",
      "Epoch 2338, Loss: 2.2324167639017105, Final Batch Loss: 0.1124497801065445\n",
      "Epoch 2339, Loss: 2.670179694890976, Final Batch Loss: 0.6337915658950806\n",
      "Epoch 2340, Loss: 2.4446859061717987, Final Batch Loss: 0.40749087929725647\n",
      "Epoch 2341, Loss: 2.267891362309456, Final Batch Loss: 0.2029857188463211\n",
      "Epoch 2342, Loss: 2.5297928750514984, Final Batch Loss: 0.4725218415260315\n",
      "Epoch 2343, Loss: 2.8407064378261566, Final Batch Loss: 0.6388164162635803\n",
      "Epoch 2344, Loss: 2.4484415352344513, Final Batch Loss: 0.35405078530311584\n",
      "Epoch 2345, Loss: 2.4100093245506287, Final Batch Loss: 0.3082755506038666\n",
      "Epoch 2346, Loss: 2.7916229963302612, Final Batch Loss: 0.5861772894859314\n",
      "Epoch 2347, Loss: 2.886877417564392, Final Batch Loss: 0.7738927006721497\n",
      "Epoch 2348, Loss: 2.6130905747413635, Final Batch Loss: 0.5279194116592407\n",
      "Epoch 2349, Loss: 2.7578734755516052, Final Batch Loss: 0.5764325261116028\n",
      "Epoch 2350, Loss: 2.8690537810325623, Final Batch Loss: 0.6456418037414551\n",
      "Epoch 2351, Loss: 2.2635001987218857, Final Batch Loss: 0.15640480816364288\n",
      "Epoch 2352, Loss: 2.6514976024627686, Final Batch Loss: 0.5135486125946045\n",
      "Epoch 2353, Loss: 2.4048745930194855, Final Batch Loss: 0.3917510211467743\n",
      "Epoch 2354, Loss: 2.46865376830101, Final Batch Loss: 0.3238970637321472\n",
      "Epoch 2355, Loss: 2.667370468378067, Final Batch Loss: 0.6110163331031799\n",
      "Epoch 2356, Loss: 2.5291480123996735, Final Batch Loss: 0.5211736559867859\n",
      "Epoch 2357, Loss: 2.5766935646533966, Final Batch Loss: 0.5236773490905762\n",
      "Epoch 2358, Loss: 2.496898651123047, Final Batch Loss: 0.4582999646663666\n",
      "Epoch 2359, Loss: 2.5586869716644287, Final Batch Loss: 0.4527028203010559\n",
      "Epoch 2360, Loss: 2.479846030473709, Final Batch Loss: 0.48286816477775574\n",
      "Epoch 2361, Loss: 2.6208642423152924, Final Batch Loss: 0.5567225813865662\n",
      "Epoch 2362, Loss: 2.450244426727295, Final Batch Loss: 0.3535037040710449\n",
      "Epoch 2363, Loss: 2.577984005212784, Final Batch Loss: 0.5001824498176575\n",
      "Epoch 2364, Loss: 2.9353882372379303, Final Batch Loss: 0.8808279633522034\n",
      "Epoch 2365, Loss: 2.5472001433372498, Final Batch Loss: 0.4449135661125183\n",
      "Epoch 2366, Loss: 2.86602646112442, Final Batch Loss: 0.8193691372871399\n",
      "Epoch 2367, Loss: 2.533178925514221, Final Batch Loss: 0.44133302569389343\n",
      "Epoch 2368, Loss: 2.4602965712547302, Final Batch Loss: 0.46802225708961487\n",
      "Epoch 2369, Loss: 2.3732559382915497, Final Batch Loss: 0.3199191689491272\n",
      "Epoch 2370, Loss: 2.713990658521652, Final Batch Loss: 0.6678342223167419\n",
      "Epoch 2371, Loss: 2.850193977355957, Final Batch Loss: 0.6608259081840515\n",
      "Epoch 2372, Loss: 2.7819136679172516, Final Batch Loss: 0.5898452997207642\n",
      "Epoch 2373, Loss: 2.307652622461319, Final Batch Loss: 0.311907023191452\n",
      "Epoch 2374, Loss: 2.6881335973739624, Final Batch Loss: 0.5240246653556824\n",
      "Epoch 2375, Loss: 2.6897574067115784, Final Batch Loss: 0.5660573840141296\n",
      "Epoch 2376, Loss: 2.423630028963089, Final Batch Loss: 0.3152526915073395\n",
      "Epoch 2377, Loss: 2.7006004452705383, Final Batch Loss: 0.47396939992904663\n",
      "Epoch 2378, Loss: 3.2237056493759155, Final Batch Loss: 1.159629225730896\n",
      "Epoch 2379, Loss: 3.217134565114975, Final Batch Loss: 1.0338239669799805\n",
      "Epoch 2380, Loss: 2.632876753807068, Final Batch Loss: 0.4539462924003601\n",
      "Epoch 2381, Loss: 2.7190309166908264, Final Batch Loss: 0.5232766270637512\n",
      "Epoch 2382, Loss: 2.5937348306179047, Final Batch Loss: 0.44223853945732117\n",
      "Epoch 2383, Loss: 2.4769980013370514, Final Batch Loss: 0.4342409670352936\n",
      "Epoch 2384, Loss: 2.3696807622909546, Final Batch Loss: 0.32308250665664673\n",
      "Epoch 2385, Loss: 2.367294669151306, Final Batch Loss: 0.37545904517173767\n",
      "Epoch 2386, Loss: 2.351774722337723, Final Batch Loss: 0.2591991424560547\n",
      "Epoch 2387, Loss: 2.336555927991867, Final Batch Loss: 0.36529627442359924\n",
      "Epoch 2388, Loss: 2.5587612688541412, Final Batch Loss: 0.4593324363231659\n",
      "Epoch 2389, Loss: 2.5304181277751923, Final Batch Loss: 0.4583907723426819\n",
      "Epoch 2390, Loss: 2.5356337428092957, Final Batch Loss: 0.44469884037971497\n",
      "Epoch 2391, Loss: 2.7353836596012115, Final Batch Loss: 0.6432430148124695\n",
      "Epoch 2392, Loss: 2.866798162460327, Final Batch Loss: 0.7194228768348694\n",
      "Epoch 2393, Loss: 2.5852780044078827, Final Batch Loss: 0.46695464849472046\n",
      "Epoch 2394, Loss: 3.032965898513794, Final Batch Loss: 0.7197697758674622\n",
      "Epoch 2395, Loss: 2.7238014340400696, Final Batch Loss: 0.5199337601661682\n",
      "Epoch 2396, Loss: 2.5144848227500916, Final Batch Loss: 0.32391229271888733\n",
      "Epoch 2397, Loss: 2.351280063390732, Final Batch Loss: 0.30520033836364746\n",
      "Epoch 2398, Loss: 2.600069135427475, Final Batch Loss: 0.38030877709388733\n",
      "Epoch 2399, Loss: 2.203514486551285, Final Batch Loss: 0.11304038763046265\n",
      "Epoch 2400, Loss: 2.6930445432662964, Final Batch Loss: 0.3753381371498108\n",
      "Epoch 2401, Loss: 2.727749854326248, Final Batch Loss: 0.5798984169960022\n",
      "Epoch 2402, Loss: 3.2259098887443542, Final Batch Loss: 1.1587806940078735\n",
      "Epoch 2403, Loss: 2.5551284849643707, Final Batch Loss: 0.5056248307228088\n",
      "Epoch 2404, Loss: 2.612303286790848, Final Batch Loss: 0.4936324656009674\n",
      "Epoch 2405, Loss: 2.3408352732658386, Final Batch Loss: 0.3457086682319641\n",
      "Epoch 2406, Loss: 2.4159094095230103, Final Batch Loss: 0.38754454255104065\n",
      "Epoch 2407, Loss: 2.501772254705429, Final Batch Loss: 0.3690318167209625\n",
      "Epoch 2408, Loss: 2.6511749923229218, Final Batch Loss: 0.47205492854118347\n",
      "Epoch 2409, Loss: 2.765807718038559, Final Batch Loss: 0.5482831597328186\n",
      "Epoch 2410, Loss: 2.4301153123378754, Final Batch Loss: 0.5450294613838196\n",
      "Epoch 2411, Loss: 2.272386521100998, Final Batch Loss: 0.2663396894931793\n",
      "Epoch 2412, Loss: 2.9526997208595276, Final Batch Loss: 1.033718228340149\n",
      "Epoch 2413, Loss: 2.7281444668769836, Final Batch Loss: 0.6916714906692505\n",
      "Epoch 2414, Loss: 2.5099433958530426, Final Batch Loss: 0.4530799388885498\n",
      "Epoch 2415, Loss: 2.8614187836647034, Final Batch Loss: 0.7311887145042419\n",
      "Epoch 2416, Loss: 2.604242891073227, Final Batch Loss: 0.5507124662399292\n",
      "Epoch 2417, Loss: 2.600843131542206, Final Batch Loss: 0.4434928297996521\n",
      "Epoch 2418, Loss: 2.6070592999458313, Final Batch Loss: 0.43263760209083557\n",
      "Epoch 2419, Loss: 2.4441674649715424, Final Batch Loss: 0.4096139371395111\n",
      "Epoch 2420, Loss: 2.7987757325172424, Final Batch Loss: 0.6460188627243042\n",
      "Epoch 2421, Loss: 2.6217700242996216, Final Batch Loss: 0.44916605949401855\n",
      "Epoch 2422, Loss: 2.577935427427292, Final Batch Loss: 0.5548222661018372\n",
      "Epoch 2423, Loss: 2.7951861023902893, Final Batch Loss: 0.8777018189430237\n",
      "Epoch 2424, Loss: 2.6996015906333923, Final Batch Loss: 0.5525277256965637\n",
      "Epoch 2425, Loss: 2.7495980262756348, Final Batch Loss: 0.6267517805099487\n",
      "Epoch 2426, Loss: 2.5351088643074036, Final Batch Loss: 0.42800870537757874\n",
      "Epoch 2427, Loss: 2.5174716114997864, Final Batch Loss: 0.5027496218681335\n",
      "Epoch 2428, Loss: 2.548054575920105, Final Batch Loss: 0.40200075507164\n",
      "Epoch 2429, Loss: 2.1725401431322098, Final Batch Loss: 0.14427907764911652\n",
      "Epoch 2430, Loss: 2.2916385382413864, Final Batch Loss: 0.2284286767244339\n",
      "Epoch 2431, Loss: 2.7420381903648376, Final Batch Loss: 0.780843198299408\n",
      "Epoch 2432, Loss: 2.8784572184085846, Final Batch Loss: 0.761062741279602\n",
      "Epoch 2433, Loss: 2.54654598236084, Final Batch Loss: 0.5023885369300842\n",
      "Epoch 2434, Loss: 2.4334974884986877, Final Batch Loss: 0.43674707412719727\n",
      "Epoch 2435, Loss: 2.293452888727188, Final Batch Loss: 0.2953793406486511\n",
      "Epoch 2436, Loss: 3.21416699886322, Final Batch Loss: 1.0404709577560425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2437, Loss: 2.705548971891403, Final Batch Loss: 0.6831618547439575\n",
      "Epoch 2438, Loss: 2.825631618499756, Final Batch Loss: 0.7247974276542664\n",
      "Epoch 2439, Loss: 2.6006118059158325, Final Batch Loss: 0.530558168888092\n",
      "Epoch 2440, Loss: 3.1030645668506622, Final Batch Loss: 0.9246236681938171\n",
      "Epoch 2441, Loss: 2.7172447443008423, Final Batch Loss: 0.5249511003494263\n",
      "Epoch 2442, Loss: 2.8226802349090576, Final Batch Loss: 0.731052815914154\n",
      "Epoch 2443, Loss: 2.810136377811432, Final Batch Loss: 0.834595263004303\n",
      "Epoch 2444, Loss: 2.7724826633930206, Final Batch Loss: 0.6367397308349609\n",
      "Epoch 2445, Loss: 2.6829480826854706, Final Batch Loss: 0.5933247804641724\n",
      "Epoch 2446, Loss: 2.580808073282242, Final Batch Loss: 0.5906149744987488\n",
      "Epoch 2447, Loss: 2.771227240562439, Final Batch Loss: 0.6486331224441528\n",
      "Epoch 2448, Loss: 2.8111340403556824, Final Batch Loss: 0.708522379398346\n",
      "Epoch 2449, Loss: 2.554179936647415, Final Batch Loss: 0.5517638921737671\n",
      "Epoch 2450, Loss: 2.3041493594646454, Final Batch Loss: 0.2819152772426605\n",
      "Epoch 2451, Loss: 2.37220898270607, Final Batch Loss: 0.4363078474998474\n",
      "Epoch 2452, Loss: 2.548541247844696, Final Batch Loss: 0.5141240954399109\n",
      "Epoch 2453, Loss: 2.739435374736786, Final Batch Loss: 0.7483609318733215\n",
      "Epoch 2454, Loss: 2.2424516677856445, Final Batch Loss: 0.2834968864917755\n",
      "Epoch 2455, Loss: 2.4000885784626007, Final Batch Loss: 0.295219749212265\n",
      "Epoch 2456, Loss: 2.7382056415081024, Final Batch Loss: 0.7095828652381897\n",
      "Epoch 2457, Loss: 3.376431852579117, Final Batch Loss: 1.2587872743606567\n",
      "Epoch 2458, Loss: 2.4696557819843292, Final Batch Loss: 0.32419270277023315\n",
      "Epoch 2459, Loss: 2.300121307373047, Final Batch Loss: 0.28939753770828247\n",
      "Epoch 2460, Loss: 2.656686455011368, Final Batch Loss: 0.49362820386886597\n",
      "Epoch 2461, Loss: 2.6673688888549805, Final Batch Loss: 0.48305678367614746\n",
      "Epoch 2462, Loss: 2.296578288078308, Final Batch Loss: 0.29526716470718384\n",
      "Epoch 2463, Loss: 2.936527281999588, Final Batch Loss: 0.8063902258872986\n",
      "Epoch 2464, Loss: 2.9565941393375397, Final Batch Loss: 0.7966248393058777\n",
      "Epoch 2465, Loss: 2.4750408232212067, Final Batch Loss: 0.2950088679790497\n",
      "Epoch 2466, Loss: 2.95767804980278, Final Batch Loss: 0.7463628053665161\n",
      "Epoch 2467, Loss: 2.6890116035938263, Final Batch Loss: 0.6461602449417114\n",
      "Epoch 2468, Loss: 2.6124342679977417, Final Batch Loss: 0.5717563629150391\n",
      "Epoch 2469, Loss: 2.8126713633537292, Final Batch Loss: 0.6181143522262573\n",
      "Epoch 2470, Loss: 2.6663446128368378, Final Batch Loss: 0.5952221751213074\n",
      "Epoch 2471, Loss: 2.370866060256958, Final Batch Loss: 0.23133400082588196\n",
      "Epoch 2472, Loss: 2.638622522354126, Final Batch Loss: 0.5318289995193481\n",
      "Epoch 2473, Loss: 2.4928668439388275, Final Batch Loss: 0.5353718996047974\n",
      "Epoch 2474, Loss: 2.7395058274269104, Final Batch Loss: 0.6425232291221619\n",
      "Epoch 2475, Loss: 2.773801803588867, Final Batch Loss: 0.6865338683128357\n",
      "Epoch 2476, Loss: 2.426998555660248, Final Batch Loss: 0.3929622173309326\n",
      "Epoch 2477, Loss: 2.448767989873886, Final Batch Loss: 0.405818372964859\n",
      "Epoch 2478, Loss: 2.4747836887836456, Final Batch Loss: 0.40278223156929016\n",
      "Epoch 2479, Loss: 2.521053373813629, Final Batch Loss: 0.4216785132884979\n",
      "Epoch 2480, Loss: 2.5729640424251556, Final Batch Loss: 0.4673800468444824\n",
      "Epoch 2481, Loss: 2.547139495611191, Final Batch Loss: 0.4323747158050537\n",
      "Epoch 2482, Loss: 2.6532101035118103, Final Batch Loss: 0.6512120366096497\n",
      "Epoch 2483, Loss: 2.5643593668937683, Final Batch Loss: 0.6154156923294067\n",
      "Epoch 2484, Loss: 2.430458903312683, Final Batch Loss: 0.4607672095298767\n",
      "Epoch 2485, Loss: 2.5797718167304993, Final Batch Loss: 0.4950033724308014\n",
      "Epoch 2486, Loss: 2.357996016740799, Final Batch Loss: 0.30138111114501953\n",
      "Epoch 2487, Loss: 2.3040765821933746, Final Batch Loss: 0.29412075877189636\n",
      "Epoch 2488, Loss: 3.0736223757267, Final Batch Loss: 0.9626326560974121\n",
      "Epoch 2489, Loss: 3.1889900863170624, Final Batch Loss: 1.073652982711792\n",
      "Epoch 2490, Loss: 2.937886953353882, Final Batch Loss: 0.7735394239425659\n",
      "Epoch 2491, Loss: 2.9209561347961426, Final Batch Loss: 0.790528416633606\n",
      "Epoch 2492, Loss: 2.619551330804825, Final Batch Loss: 0.36522653698921204\n",
      "Epoch 2493, Loss: 2.9781389236450195, Final Batch Loss: 0.6431111693382263\n",
      "Epoch 2494, Loss: 2.8239588737487793, Final Batch Loss: 0.7094797492027283\n",
      "Epoch 2495, Loss: 2.573732078075409, Final Batch Loss: 0.4437529146671295\n",
      "Epoch 2496, Loss: 2.990974009037018, Final Batch Loss: 0.7198361754417419\n",
      "Epoch 2497, Loss: 2.6746711432933807, Final Batch Loss: 0.44636502861976624\n",
      "Epoch 2498, Loss: 2.8829586505889893, Final Batch Loss: 0.7035041451454163\n",
      "Epoch 2499, Loss: 2.7097322046756744, Final Batch Loss: 0.6286472082138062\n",
      "Epoch 2500, Loss: 2.44865345954895, Final Batch Loss: 0.38951462507247925\n",
      "Epoch 2501, Loss: 2.346183806657791, Final Batch Loss: 0.14593049883842468\n",
      "Epoch 2502, Loss: 2.174806624650955, Final Batch Loss: 0.16848549246788025\n",
      "Epoch 2503, Loss: 2.3357119858264923, Final Batch Loss: 0.3005252480506897\n",
      "Epoch 2504, Loss: 2.2970377802848816, Final Batch Loss: 0.2572229206562042\n",
      "Epoch 2505, Loss: 2.626336991786957, Final Batch Loss: 0.7587019205093384\n",
      "Epoch 2506, Loss: 2.6967017352581024, Final Batch Loss: 0.6816233396530151\n",
      "Epoch 2507, Loss: 2.3838441967964172, Final Batch Loss: 0.40640872716903687\n",
      "Epoch 2508, Loss: 2.939708173274994, Final Batch Loss: 0.8702090382575989\n",
      "Epoch 2509, Loss: 2.511363834142685, Final Batch Loss: 0.4993512034416199\n",
      "Epoch 2510, Loss: 2.548315644264221, Final Batch Loss: 0.45372411608695984\n",
      "Epoch 2511, Loss: 2.2305931746959686, Final Batch Loss: 0.21203458309173584\n",
      "Epoch 2512, Loss: 2.3455883264541626, Final Batch Loss: 0.44433489441871643\n",
      "Epoch 2513, Loss: 2.143658936023712, Final Batch Loss: 0.26620081067085266\n",
      "Epoch 2514, Loss: 2.5400678515434265, Final Batch Loss: 0.38918957114219666\n",
      "Epoch 2515, Loss: 2.542337030172348, Final Batch Loss: 0.612080991268158\n",
      "Epoch 2516, Loss: 2.708652138710022, Final Batch Loss: 0.7001480460166931\n",
      "Epoch 2517, Loss: 3.241654872894287, Final Batch Loss: 1.2844401597976685\n",
      "Epoch 2518, Loss: 2.1547192186117172, Final Batch Loss: 0.12823204696178436\n",
      "Epoch 2519, Loss: 2.3838341534137726, Final Batch Loss: 0.4151625633239746\n",
      "Epoch 2520, Loss: 2.379972070455551, Final Batch Loss: 0.34132686257362366\n",
      "Epoch 2521, Loss: 2.5127779841423035, Final Batch Loss: 0.5451329350471497\n",
      "Epoch 2522, Loss: 2.6319094598293304, Final Batch Loss: 0.4080618917942047\n",
      "Epoch 2523, Loss: 2.322516053915024, Final Batch Loss: 0.35316792130470276\n",
      "Epoch 2524, Loss: 2.464502304792404, Final Batch Loss: 0.43399742245674133\n",
      "Epoch 2525, Loss: 2.3505758941173553, Final Batch Loss: 0.3188474178314209\n",
      "Epoch 2526, Loss: 2.232576683163643, Final Batch Loss: 0.24801082909107208\n",
      "Epoch 2527, Loss: 2.512551426887512, Final Batch Loss: 0.4036087393760681\n",
      "Epoch 2528, Loss: 2.3029469549655914, Final Batch Loss: 0.26223257184028625\n",
      "Epoch 2529, Loss: 3.0550139248371124, Final Batch Loss: 0.9825935363769531\n",
      "Epoch 2530, Loss: 2.49897238612175, Final Batch Loss: 0.5561361312866211\n",
      "Epoch 2531, Loss: 2.667948395013809, Final Batch Loss: 0.5375498533248901\n",
      "Epoch 2532, Loss: 2.6227342784404755, Final Batch Loss: 0.5939832329750061\n",
      "Epoch 2533, Loss: 2.4311441481113434, Final Batch Loss: 0.46954622864723206\n",
      "Epoch 2534, Loss: 2.6935762763023376, Final Batch Loss: 0.6022226214408875\n",
      "Epoch 2535, Loss: 2.685173839330673, Final Batch Loss: 0.7781009078025818\n",
      "Epoch 2536, Loss: 3.0221565067768097, Final Batch Loss: 0.8996062278747559\n",
      "Epoch 2537, Loss: 2.6330240666866302, Final Batch Loss: 0.7084283232688904\n",
      "Epoch 2538, Loss: 2.805291563272476, Final Batch Loss: 0.8145098686218262\n",
      "Epoch 2539, Loss: 2.3736334145069122, Final Batch Loss: 0.3038986623287201\n",
      "Epoch 2540, Loss: 2.562553107738495, Final Batch Loss: 0.6029401421546936\n",
      "Epoch 2541, Loss: 2.4286795556545258, Final Batch Loss: 0.5369206666946411\n",
      "Epoch 2542, Loss: 2.6271196007728577, Final Batch Loss: 0.4824593663215637\n",
      "Epoch 2543, Loss: 2.295212611556053, Final Batch Loss: 0.11505971848964691\n",
      "Epoch 2544, Loss: 2.574457138776779, Final Batch Loss: 0.5236542820930481\n",
      "Epoch 2545, Loss: 2.4228285551071167, Final Batch Loss: 0.46402937173843384\n",
      "Epoch 2546, Loss: 2.1321901082992554, Final Batch Loss: 0.20804274082183838\n",
      "Epoch 2547, Loss: 2.4280893206596375, Final Batch Loss: 0.3815353214740753\n",
      "Epoch 2548, Loss: 2.618025988340378, Final Batch Loss: 0.592704176902771\n",
      "Epoch 2549, Loss: 2.225825071334839, Final Batch Loss: 0.3010193705558777\n",
      "Epoch 2550, Loss: 2.143312528729439, Final Batch Loss: 0.19295267760753632\n",
      "Epoch 2551, Loss: 2.580770254135132, Final Batch Loss: 0.6200289130210876\n",
      "Epoch 2552, Loss: 2.396907687187195, Final Batch Loss: 0.4019506573677063\n",
      "Epoch 2553, Loss: 2.5932624340057373, Final Batch Loss: 0.571426510810852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2554, Loss: 2.3966516852378845, Final Batch Loss: 0.2997789680957794\n",
      "Epoch 2555, Loss: 3.0908989906311035, Final Batch Loss: 1.0702577829360962\n",
      "Epoch 2556, Loss: 2.648671507835388, Final Batch Loss: 0.6847724318504333\n",
      "Epoch 2557, Loss: 2.8582924008369446, Final Batch Loss: 0.9653205275535583\n",
      "Epoch 2558, Loss: 2.568620264530182, Final Batch Loss: 0.6024520993232727\n",
      "Epoch 2559, Loss: 2.7457241117954254, Final Batch Loss: 0.620245635509491\n",
      "Epoch 2560, Loss: 2.2691691517829895, Final Batch Loss: 0.2278750240802765\n",
      "Epoch 2561, Loss: 2.450679272413254, Final Batch Loss: 0.4903678596019745\n",
      "Epoch 2562, Loss: 2.3850976526737213, Final Batch Loss: 0.35890933871269226\n",
      "Epoch 2563, Loss: 3.0134423971176147, Final Batch Loss: 0.925031304359436\n",
      "Epoch 2564, Loss: 2.561274468898773, Final Batch Loss: 0.5872008204460144\n",
      "Epoch 2565, Loss: 3.1669428050518036, Final Batch Loss: 1.0319167375564575\n",
      "Epoch 2566, Loss: 2.7292726635932922, Final Batch Loss: 0.6790231466293335\n",
      "Epoch 2567, Loss: 2.394240081310272, Final Batch Loss: 0.35787251591682434\n",
      "Epoch 2568, Loss: 2.139925494790077, Final Batch Loss: 0.11694671213626862\n",
      "Epoch 2569, Loss: 2.3290477097034454, Final Batch Loss: 0.31461387872695923\n",
      "Epoch 2570, Loss: 2.4158868491649628, Final Batch Loss: 0.351516455411911\n",
      "Epoch 2571, Loss: 2.238928884267807, Final Batch Loss: 0.29468145966529846\n",
      "Epoch 2572, Loss: 2.119859293103218, Final Batch Loss: 0.24119271337985992\n",
      "Epoch 2573, Loss: 2.188480883836746, Final Batch Loss: 0.3766036927700043\n",
      "Epoch 2574, Loss: 2.917959898710251, Final Batch Loss: 1.0208491086959839\n",
      "Epoch 2575, Loss: 2.4091664850711823, Final Batch Loss: 0.3544655442237854\n",
      "Epoch 2576, Loss: 2.280539959669113, Final Batch Loss: 0.3140663504600525\n",
      "Epoch 2577, Loss: 2.6086062490940094, Final Batch Loss: 0.6636290550231934\n",
      "Epoch 2578, Loss: 2.4459365606307983, Final Batch Loss: 0.450706422328949\n",
      "Epoch 2579, Loss: 2.3184635937213898, Final Batch Loss: 0.31811168789863586\n",
      "Epoch 2580, Loss: 2.1733013838529587, Final Batch Loss: 0.24769537150859833\n",
      "Epoch 2581, Loss: 2.2485454976558685, Final Batch Loss: 0.2822520136833191\n",
      "Epoch 2582, Loss: 2.842385858297348, Final Batch Loss: 0.8269082307815552\n",
      "Epoch 2583, Loss: 2.590647369623184, Final Batch Loss: 0.5483373999595642\n",
      "Epoch 2584, Loss: 2.4386492669582367, Final Batch Loss: 0.44052860140800476\n",
      "Epoch 2585, Loss: 2.6871284544467926, Final Batch Loss: 0.7107613682746887\n",
      "Epoch 2586, Loss: 2.3358322978019714, Final Batch Loss: 0.2632531523704529\n",
      "Epoch 2587, Loss: 2.276951938867569, Final Batch Loss: 0.21216630935668945\n",
      "Epoch 2588, Loss: 2.2419068813323975, Final Batch Loss: 0.2630936801433563\n",
      "Epoch 2589, Loss: 2.3517480343580246, Final Batch Loss: 0.19418220221996307\n",
      "Epoch 2590, Loss: 2.782802015542984, Final Batch Loss: 0.686919093132019\n",
      "Epoch 2591, Loss: 2.3456572890281677, Final Batch Loss: 0.33141207695007324\n",
      "Epoch 2592, Loss: 2.4815642535686493, Final Batch Loss: 0.416430801153183\n",
      "Epoch 2593, Loss: 2.8075596392154694, Final Batch Loss: 0.782313346862793\n",
      "Epoch 2594, Loss: 2.5699431896209717, Final Batch Loss: 0.51871657371521\n",
      "Epoch 2595, Loss: 2.3905146718025208, Final Batch Loss: 0.4335658550262451\n",
      "Epoch 2596, Loss: 2.52094766497612, Final Batch Loss: 0.42924103140830994\n",
      "Epoch 2597, Loss: 2.6627948880195618, Final Batch Loss: 0.5228213667869568\n",
      "Epoch 2598, Loss: 2.7551654875278473, Final Batch Loss: 0.608641505241394\n",
      "Epoch 2599, Loss: 2.765446722507477, Final Batch Loss: 0.675345242023468\n",
      "Epoch 2600, Loss: 2.335720404982567, Final Batch Loss: 0.21794234216213226\n",
      "Epoch 2601, Loss: 2.1708897054195404, Final Batch Loss: 0.29160457849502563\n",
      "Epoch 2602, Loss: 2.4571904242038727, Final Batch Loss: 0.4666106700897217\n",
      "Epoch 2603, Loss: 2.292140871286392, Final Batch Loss: 0.4074179530143738\n",
      "Epoch 2604, Loss: 2.4746307730674744, Final Batch Loss: 0.5002965331077576\n",
      "Epoch 2605, Loss: 2.308535113930702, Final Batch Loss: 0.23608113825321198\n",
      "Epoch 2606, Loss: 2.7610003054142, Final Batch Loss: 0.9196105599403381\n",
      "Epoch 2607, Loss: 2.5037554502487183, Final Batch Loss: 0.44005635380744934\n",
      "Epoch 2608, Loss: 2.3499011397361755, Final Batch Loss: 0.4247986674308777\n",
      "Epoch 2609, Loss: 2.5437992811203003, Final Batch Loss: 0.5336309671401978\n",
      "Epoch 2610, Loss: 2.422633796930313, Final Batch Loss: 0.3309319317340851\n",
      "Epoch 2611, Loss: 3.328272670507431, Final Batch Loss: 1.1759188175201416\n",
      "Epoch 2612, Loss: 2.3628124594688416, Final Batch Loss: 0.4475565552711487\n",
      "Epoch 2613, Loss: 2.381695717573166, Final Batch Loss: 0.43042466044425964\n",
      "Epoch 2614, Loss: 2.5985140204429626, Final Batch Loss: 0.6096558570861816\n",
      "Epoch 2615, Loss: 2.5052422285079956, Final Batch Loss: 0.43063732981681824\n",
      "Epoch 2616, Loss: 3.1064691245555878, Final Batch Loss: 1.0174700021743774\n",
      "Epoch 2617, Loss: 2.6607247292995453, Final Batch Loss: 0.7631731629371643\n",
      "Epoch 2618, Loss: 2.2124485969543457, Final Batch Loss: 0.27785536646842957\n",
      "Epoch 2619, Loss: 2.2799142003059387, Final Batch Loss: 0.2713377773761749\n",
      "Epoch 2620, Loss: 2.187307059764862, Final Batch Loss: 0.15565970540046692\n",
      "Epoch 2621, Loss: 2.6689208149909973, Final Batch Loss: 0.7049589157104492\n",
      "Epoch 2622, Loss: 2.7377606630325317, Final Batch Loss: 0.6919242739677429\n",
      "Epoch 2623, Loss: 2.7732191681861877, Final Batch Loss: 0.6544484496116638\n",
      "Epoch 2624, Loss: 2.361837148666382, Final Batch Loss: 0.29009580612182617\n",
      "Epoch 2625, Loss: 2.91527783870697, Final Batch Loss: 0.7587743997573853\n",
      "Epoch 2626, Loss: 2.5178670585155487, Final Batch Loss: 0.6394042372703552\n",
      "Epoch 2627, Loss: 2.5965701043605804, Final Batch Loss: 0.5684172511100769\n",
      "Epoch 2628, Loss: 2.9047752618789673, Final Batch Loss: 0.8911768198013306\n",
      "Epoch 2629, Loss: 2.7494446337223053, Final Batch Loss: 0.6692634224891663\n",
      "Epoch 2630, Loss: 2.704364448785782, Final Batch Loss: 0.5955933332443237\n",
      "Epoch 2631, Loss: 2.088767349720001, Final Batch Loss: 0.16231727600097656\n",
      "Epoch 2632, Loss: 2.369624763727188, Final Batch Loss: 0.5046592950820923\n",
      "Epoch 2633, Loss: 2.6289507150650024, Final Batch Loss: 0.6461287140846252\n",
      "Epoch 2634, Loss: 2.445593297481537, Final Batch Loss: 0.5102126598358154\n",
      "Epoch 2635, Loss: 2.319774568080902, Final Batch Loss: 0.3948512673377991\n",
      "Epoch 2636, Loss: 2.25064679980278, Final Batch Loss: 0.1906513273715973\n",
      "Epoch 2637, Loss: 2.5357137620449066, Final Batch Loss: 0.5821987986564636\n",
      "Epoch 2638, Loss: 2.3816181123256683, Final Batch Loss: 0.4211520254611969\n",
      "Epoch 2639, Loss: 2.3879238963127136, Final Batch Loss: 0.27558058500289917\n",
      "Epoch 2640, Loss: 2.5697547793388367, Final Batch Loss: 0.6393526792526245\n",
      "Epoch 2641, Loss: 2.6198574602603912, Final Batch Loss: 0.5418184995651245\n",
      "Epoch 2642, Loss: 2.460794061422348, Final Batch Loss: 0.4932235777378082\n",
      "Epoch 2643, Loss: 2.5797724425792694, Final Batch Loss: 0.5639281272888184\n",
      "Epoch 2644, Loss: 2.586637020111084, Final Batch Loss: 0.5708513855934143\n",
      "Epoch 2645, Loss: 2.3604576885700226, Final Batch Loss: 0.43709462881088257\n",
      "Epoch 2646, Loss: 2.400515556335449, Final Batch Loss: 0.48070499300956726\n",
      "Epoch 2647, Loss: 2.2797845005989075, Final Batch Loss: 0.3907034695148468\n",
      "Epoch 2648, Loss: 2.6995387077331543, Final Batch Loss: 0.7212509512901306\n",
      "Epoch 2649, Loss: 2.3083868622779846, Final Batch Loss: 0.43890318274497986\n",
      "Epoch 2650, Loss: 2.336814135313034, Final Batch Loss: 0.3336870074272156\n",
      "Epoch 2651, Loss: 2.475526601076126, Final Batch Loss: 0.37553003430366516\n",
      "Epoch 2652, Loss: 2.3272421956062317, Final Batch Loss: 0.4575049877166748\n",
      "Epoch 2653, Loss: 2.4558187425136566, Final Batch Loss: 0.5054428577423096\n",
      "Epoch 2654, Loss: 2.4776819348335266, Final Batch Loss: 0.6002162098884583\n",
      "Epoch 2655, Loss: 2.4909233450889587, Final Batch Loss: 0.46439889073371887\n",
      "Epoch 2656, Loss: 2.2882950603961945, Final Batch Loss: 0.28451788425445557\n",
      "Epoch 2657, Loss: 2.5759157240390778, Final Batch Loss: 0.6513010263442993\n",
      "Epoch 2658, Loss: 2.8658028841018677, Final Batch Loss: 0.8848938345909119\n",
      "Epoch 2659, Loss: 2.1460710614919662, Final Batch Loss: 0.11100126802921295\n",
      "Epoch 2660, Loss: 2.724825441837311, Final Batch Loss: 0.5988378524780273\n",
      "Epoch 2661, Loss: 2.5646009743213654, Final Batch Loss: 0.6300053596496582\n",
      "Epoch 2662, Loss: 2.580105721950531, Final Batch Loss: 0.38677290081977844\n",
      "Epoch 2663, Loss: 2.5940431654453278, Final Batch Loss: 0.6104956865310669\n",
      "Epoch 2664, Loss: 2.647024691104889, Final Batch Loss: 0.6150156855583191\n",
      "Epoch 2665, Loss: 2.671175390481949, Final Batch Loss: 0.634053111076355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2666, Loss: 2.465733826160431, Final Batch Loss: 0.4864061176776886\n",
      "Epoch 2667, Loss: 2.5964690446853638, Final Batch Loss: 0.38905930519104004\n",
      "Epoch 2668, Loss: 2.3746021389961243, Final Batch Loss: 0.2870919406414032\n",
      "Epoch 2669, Loss: 3.1066672801971436, Final Batch Loss: 0.8989566564559937\n",
      "Epoch 2670, Loss: 2.449272722005844, Final Batch Loss: 0.3952443599700928\n",
      "Epoch 2671, Loss: 2.4514507055282593, Final Batch Loss: 0.5289504528045654\n",
      "Epoch 2672, Loss: 2.2056958228349686, Final Batch Loss: 0.2445104867219925\n",
      "Epoch 2673, Loss: 2.6125676333904266, Final Batch Loss: 0.6724571585655212\n",
      "Epoch 2674, Loss: 2.5038507282733917, Final Batch Loss: 0.557945191860199\n",
      "Epoch 2675, Loss: 2.27340030670166, Final Batch Loss: 0.32132458686828613\n",
      "Epoch 2676, Loss: 2.3316135704517365, Final Batch Loss: 0.29959312081336975\n",
      "Epoch 2677, Loss: 2.2829537466168404, Final Batch Loss: 0.08408910781145096\n",
      "Epoch 2678, Loss: 2.51116144657135, Final Batch Loss: 0.4074545204639435\n",
      "Epoch 2679, Loss: 2.755366027355194, Final Batch Loss: 0.6269263029098511\n",
      "Epoch 2680, Loss: 2.4901594519615173, Final Batch Loss: 0.3929152488708496\n",
      "Epoch 2681, Loss: 2.3759706914424896, Final Batch Loss: 0.571594774723053\n",
      "Epoch 2682, Loss: 2.444121301174164, Final Batch Loss: 0.5403702259063721\n",
      "Epoch 2683, Loss: 2.816782236099243, Final Batch Loss: 0.8326019644737244\n",
      "Epoch 2684, Loss: 2.6504570841789246, Final Batch Loss: 0.5595622062683105\n",
      "Epoch 2685, Loss: 2.2642872780561447, Final Batch Loss: 0.20230554044246674\n",
      "Epoch 2686, Loss: 2.6312107741832733, Final Batch Loss: 0.6038236021995544\n",
      "Epoch 2687, Loss: 2.3173711597919464, Final Batch Loss: 0.42855048179626465\n",
      "Epoch 2688, Loss: 2.3792537599802017, Final Batch Loss: 0.21066604554653168\n",
      "Epoch 2689, Loss: 2.2989251911640167, Final Batch Loss: 0.3428003489971161\n",
      "Epoch 2690, Loss: 2.450903743505478, Final Batch Loss: 0.48330315947532654\n",
      "Epoch 2691, Loss: 2.270189195871353, Final Batch Loss: 0.35884055495262146\n",
      "Epoch 2692, Loss: 2.315063029527664, Final Batch Loss: 0.3128930926322937\n",
      "Epoch 2693, Loss: 2.8724456429481506, Final Batch Loss: 0.8635357022285461\n",
      "Epoch 2694, Loss: 2.481566607952118, Final Batch Loss: 0.5127748847007751\n",
      "Epoch 2695, Loss: 2.5500461757183075, Final Batch Loss: 0.6356282830238342\n",
      "Epoch 2696, Loss: 2.079729750752449, Final Batch Loss: 0.1806880086660385\n",
      "Epoch 2697, Loss: 2.3105204105377197, Final Batch Loss: 0.3078196942806244\n",
      "Epoch 2698, Loss: 2.4198972284793854, Final Batch Loss: 0.4971511960029602\n",
      "Epoch 2699, Loss: 2.2093356251716614, Final Batch Loss: 0.21027863025665283\n",
      "Epoch 2700, Loss: 2.1578918546438217, Final Batch Loss: 0.2404421716928482\n",
      "Epoch 2701, Loss: 2.343977764248848, Final Batch Loss: 0.22440530359745026\n",
      "Epoch 2702, Loss: 2.4033269584178925, Final Batch Loss: 0.3125557601451874\n",
      "Epoch 2703, Loss: 2.5080953240394592, Final Batch Loss: 0.5395128130912781\n",
      "Epoch 2704, Loss: 2.099994122982025, Final Batch Loss: 0.25540977716445923\n",
      "Epoch 2705, Loss: 2.403132677078247, Final Batch Loss: 0.43531301617622375\n",
      "Epoch 2706, Loss: 2.512688159942627, Final Batch Loss: 0.6556926369667053\n",
      "Epoch 2707, Loss: 2.5611466467380524, Final Batch Loss: 0.6098194122314453\n",
      "Epoch 2708, Loss: 2.4616787433624268, Final Batch Loss: 0.4678318202495575\n",
      "Epoch 2709, Loss: 2.306620240211487, Final Batch Loss: 0.3265475928783417\n",
      "Epoch 2710, Loss: 2.7018321752548218, Final Batch Loss: 0.7050939202308655\n",
      "Epoch 2711, Loss: 2.0597731918096542, Final Batch Loss: 0.20604301989078522\n",
      "Epoch 2712, Loss: 2.0844313949346542, Final Batch Loss: 0.21462659537792206\n",
      "Epoch 2713, Loss: 2.1535555124282837, Final Batch Loss: 0.3647071421146393\n",
      "Epoch 2714, Loss: 2.312696933746338, Final Batch Loss: 0.36529549956321716\n",
      "Epoch 2715, Loss: 2.6284516751766205, Final Batch Loss: 0.6719489097595215\n",
      "Epoch 2716, Loss: 2.443673700094223, Final Batch Loss: 0.5018852949142456\n",
      "Epoch 2717, Loss: 2.2897436320781708, Final Batch Loss: 0.24905931949615479\n",
      "Epoch 2718, Loss: 2.376870483160019, Final Batch Loss: 0.4154593050479889\n",
      "Epoch 2719, Loss: 2.7783158719539642, Final Batch Loss: 0.8022547960281372\n",
      "Epoch 2720, Loss: 2.279975265264511, Final Batch Loss: 0.25784021615982056\n",
      "Epoch 2721, Loss: 2.28102907538414, Final Batch Loss: 0.37904122471809387\n",
      "Epoch 2722, Loss: 2.5924947559833527, Final Batch Loss: 0.5247364044189453\n",
      "Epoch 2723, Loss: 2.355801045894623, Final Batch Loss: 0.4166698157787323\n",
      "Epoch 2724, Loss: 2.3915080428123474, Final Batch Loss: 0.43164876103401184\n",
      "Epoch 2725, Loss: 2.4037839770317078, Final Batch Loss: 0.39101192355155945\n",
      "Epoch 2726, Loss: 2.477849990129471, Final Batch Loss: 0.42613643407821655\n",
      "Epoch 2727, Loss: 2.418121188879013, Final Batch Loss: 0.2949903905391693\n",
      "Epoch 2728, Loss: 2.4816576540470123, Final Batch Loss: 0.5052741169929504\n",
      "Epoch 2729, Loss: 2.607771545648575, Final Batch Loss: 0.5184234976768494\n",
      "Epoch 2730, Loss: 2.5418148934841156, Final Batch Loss: 0.6042484641075134\n",
      "Epoch 2731, Loss: 2.3043462932109833, Final Batch Loss: 0.4545151889324188\n",
      "Epoch 2732, Loss: 2.6075426042079926, Final Batch Loss: 0.5905539393424988\n",
      "Epoch 2733, Loss: 2.3232165575027466, Final Batch Loss: 0.3578432500362396\n",
      "Epoch 2734, Loss: 2.1858310848474503, Final Batch Loss: 0.16412879526615143\n",
      "Epoch 2735, Loss: 2.488192617893219, Final Batch Loss: 0.5211573839187622\n",
      "Epoch 2736, Loss: 2.3658392131328583, Final Batch Loss: 0.5191178917884827\n",
      "Epoch 2737, Loss: 2.803717702627182, Final Batch Loss: 0.824362576007843\n",
      "Epoch 2738, Loss: 2.356467843055725, Final Batch Loss: 0.4001254141330719\n",
      "Epoch 2739, Loss: 2.4245765209198, Final Batch Loss: 0.32090431451797485\n",
      "Epoch 2740, Loss: 2.172833502292633, Final Batch Loss: 0.16639459133148193\n",
      "Epoch 2741, Loss: 2.3474476039409637, Final Batch Loss: 0.33460426330566406\n",
      "Epoch 2742, Loss: 2.4901881515979767, Final Batch Loss: 0.5042446851730347\n",
      "Epoch 2743, Loss: 2.540031313896179, Final Batch Loss: 0.6447299718856812\n",
      "Epoch 2744, Loss: 2.2650944590568542, Final Batch Loss: 0.3393220901489258\n",
      "Epoch 2745, Loss: 2.314163863658905, Final Batch Loss: 0.41210120916366577\n",
      "Epoch 2746, Loss: 2.6141703724861145, Final Batch Loss: 0.6946148872375488\n",
      "Epoch 2747, Loss: 2.5723403096199036, Final Batch Loss: 0.6542254686355591\n",
      "Epoch 2748, Loss: 2.1355322897434235, Final Batch Loss: 0.2606876492500305\n",
      "Epoch 2749, Loss: 2.467633455991745, Final Batch Loss: 0.544331967830658\n",
      "Epoch 2750, Loss: 2.1697909832000732, Final Batch Loss: 0.2113489806652069\n",
      "Epoch 2751, Loss: 2.5053544342517853, Final Batch Loss: 0.442752867937088\n",
      "Epoch 2752, Loss: 2.460041254758835, Final Batch Loss: 0.5274094939231873\n",
      "Epoch 2753, Loss: 2.44147527217865, Final Batch Loss: 0.33508771657943726\n",
      "Epoch 2754, Loss: 2.522320121526718, Final Batch Loss: 0.5552210807800293\n",
      "Epoch 2755, Loss: 3.6742481887340546, Final Batch Loss: 1.5661159753799438\n",
      "Epoch 2756, Loss: 2.763956904411316, Final Batch Loss: 0.6541242003440857\n",
      "Epoch 2757, Loss: 2.87067374587059, Final Batch Loss: 0.7554448246955872\n",
      "Epoch 2758, Loss: 2.3776041120290756, Final Batch Loss: 0.2133283168077469\n",
      "Epoch 2759, Loss: 2.544041335582733, Final Batch Loss: 0.4722291827201843\n",
      "Epoch 2760, Loss: 2.371872305870056, Final Batch Loss: 0.33732983469963074\n",
      "Epoch 2761, Loss: 2.722448915243149, Final Batch Loss: 0.6389021277427673\n",
      "Epoch 2762, Loss: 2.2959256768226624, Final Batch Loss: 0.40900006890296936\n",
      "Epoch 2763, Loss: 2.6488476991653442, Final Batch Loss: 0.603303074836731\n",
      "Epoch 2764, Loss: 2.238281860947609, Final Batch Loss: 0.19576849043369293\n",
      "Epoch 2765, Loss: 2.569768786430359, Final Batch Loss: 0.45186930894851685\n",
      "Epoch 2766, Loss: 2.2041484713554382, Final Batch Loss: 0.145654559135437\n",
      "Epoch 2767, Loss: 2.40134459733963, Final Batch Loss: 0.4710531234741211\n",
      "Epoch 2768, Loss: 2.938749223947525, Final Batch Loss: 0.8136833906173706\n",
      "Epoch 2769, Loss: 2.2878104150295258, Final Batch Loss: 0.4165665805339813\n",
      "Epoch 2770, Loss: 2.4931553304195404, Final Batch Loss: 0.3786306083202362\n",
      "Epoch 2771, Loss: 2.4709111154079437, Final Batch Loss: 0.4303758144378662\n",
      "Epoch 2772, Loss: 2.5211852490901947, Final Batch Loss: 0.480836421251297\n",
      "Epoch 2773, Loss: 2.5169105529785156, Final Batch Loss: 0.6094955801963806\n",
      "Epoch 2774, Loss: 2.3565445840358734, Final Batch Loss: 0.413399875164032\n",
      "Epoch 2775, Loss: 2.767320930957794, Final Batch Loss: 0.7570010423660278\n",
      "Epoch 2776, Loss: 2.2281663715839386, Final Batch Loss: 0.4443270266056061\n",
      "Epoch 2777, Loss: 2.139819383621216, Final Batch Loss: 0.24693796038627625\n",
      "Epoch 2778, Loss: 2.2497611343860626, Final Batch Loss: 0.40172886848449707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2779, Loss: 2.2159702330827713, Final Batch Loss: 0.18541838228702545\n",
      "Epoch 2780, Loss: 2.2461597621440887, Final Batch Loss: 0.38372889161109924\n",
      "Epoch 2781, Loss: 2.4824094474315643, Final Batch Loss: 0.5508633255958557\n",
      "Epoch 2782, Loss: 2.422090530395508, Final Batch Loss: 0.4747089445590973\n",
      "Epoch 2783, Loss: 2.551153540611267, Final Batch Loss: 0.7024261355400085\n",
      "Epoch 2784, Loss: 2.435018479824066, Final Batch Loss: 0.3575674593448639\n",
      "Epoch 2785, Loss: 2.3716706931591034, Final Batch Loss: 0.3742496073246002\n",
      "Epoch 2786, Loss: 2.6143453121185303, Final Batch Loss: 0.6069554686546326\n",
      "Epoch 2787, Loss: 2.1068968027830124, Final Batch Loss: 0.2003408521413803\n",
      "Epoch 2788, Loss: 2.549930691719055, Final Batch Loss: 0.642858624458313\n",
      "Epoch 2789, Loss: 2.1879805475473404, Final Batch Loss: 0.23662318289279938\n",
      "Epoch 2790, Loss: 2.7376765310764313, Final Batch Loss: 0.5794671773910522\n",
      "Epoch 2791, Loss: 2.4855563640594482, Final Batch Loss: 0.5410973429679871\n",
      "Epoch 2792, Loss: 2.7567051351070404, Final Batch Loss: 0.7134750485420227\n",
      "Epoch 2793, Loss: 2.4104426205158234, Final Batch Loss: 0.4652717411518097\n",
      "Epoch 2794, Loss: 3.1519916653633118, Final Batch Loss: 1.242102026939392\n",
      "Epoch 2795, Loss: 2.7658393681049347, Final Batch Loss: 0.8745599985122681\n",
      "Epoch 2796, Loss: 2.6316763758659363, Final Batch Loss: 0.5569532513618469\n",
      "Epoch 2797, Loss: 2.4189012944698334, Final Batch Loss: 0.5385843515396118\n",
      "Epoch 2798, Loss: 2.473159521818161, Final Batch Loss: 0.5683358311653137\n",
      "Epoch 2799, Loss: 2.5016456842422485, Final Batch Loss: 0.5056830644607544\n",
      "Epoch 2800, Loss: 2.3891243636608124, Final Batch Loss: 0.4623112082481384\n",
      "Epoch 2801, Loss: 2.380406439304352, Final Batch Loss: 0.5178002715110779\n",
      "Epoch 2802, Loss: 2.221448630094528, Final Batch Loss: 0.3056008219718933\n",
      "Epoch 2803, Loss: 2.485731214284897, Final Batch Loss: 0.5807390213012695\n",
      "Epoch 2804, Loss: 2.8958373963832855, Final Batch Loss: 0.9089099764823914\n",
      "Epoch 2805, Loss: 2.451447308063507, Final Batch Loss: 0.3365442752838135\n",
      "Epoch 2806, Loss: 2.4823068976402283, Final Batch Loss: 0.4940897822380066\n",
      "Epoch 2807, Loss: 3.0518137216567993, Final Batch Loss: 1.0625510215759277\n",
      "Epoch 2808, Loss: 2.3861208260059357, Final Batch Loss: 0.43021926283836365\n",
      "Epoch 2809, Loss: 2.2988330721855164, Final Batch Loss: 0.41704484820365906\n",
      "Epoch 2810, Loss: 2.2855774760246277, Final Batch Loss: 0.3713304400444031\n",
      "Epoch 2811, Loss: 2.2337458729743958, Final Batch Loss: 0.3059403896331787\n",
      "Epoch 2812, Loss: 2.497508615255356, Final Batch Loss: 0.5953583121299744\n",
      "Epoch 2813, Loss: 2.167503222823143, Final Batch Loss: 0.16578198969364166\n",
      "Epoch 2814, Loss: 2.6083182990550995, Final Batch Loss: 0.6465707421302795\n",
      "Epoch 2815, Loss: 2.3007839620113373, Final Batch Loss: 0.3730790317058563\n",
      "Epoch 2816, Loss: 2.254358261823654, Final Batch Loss: 0.37038078904151917\n",
      "Epoch 2817, Loss: 2.5033404529094696, Final Batch Loss: 0.4386550486087799\n",
      "Epoch 2818, Loss: 2.5081640779972076, Final Batch Loss: 0.5726813077926636\n",
      "Epoch 2819, Loss: 2.49590927362442, Final Batch Loss: 0.3120307922363281\n",
      "Epoch 2820, Loss: 2.421751320362091, Final Batch Loss: 0.5535821318626404\n",
      "Epoch 2821, Loss: 3.7124237716197968, Final Batch Loss: 1.8935977220535278\n",
      "Epoch 2822, Loss: 2.4659266769886017, Final Batch Loss: 0.43793749809265137\n",
      "Epoch 2823, Loss: 2.468655526638031, Final Batch Loss: 0.35633185505867004\n",
      "Epoch 2824, Loss: 2.4923160672187805, Final Batch Loss: 0.5368306636810303\n",
      "Epoch 2825, Loss: 2.559055060148239, Final Batch Loss: 0.6050488352775574\n",
      "Epoch 2826, Loss: 2.5631096959114075, Final Batch Loss: 0.7105568647384644\n",
      "Epoch 2827, Loss: 2.105893686413765, Final Batch Loss: 0.23144744336605072\n",
      "Epoch 2828, Loss: 2.5641003847122192, Final Batch Loss: 0.5425258278846741\n",
      "Epoch 2829, Loss: 2.4473075568675995, Final Batch Loss: 0.4526781439781189\n",
      "Epoch 2830, Loss: 2.473236083984375, Final Batch Loss: 0.5677616000175476\n",
      "Epoch 2831, Loss: 2.0407845824956894, Final Batch Loss: 0.09041859209537506\n",
      "Epoch 2832, Loss: 2.4170039296150208, Final Batch Loss: 0.608332097530365\n",
      "Epoch 2833, Loss: 2.2337237298488617, Final Batch Loss: 0.28930094838142395\n",
      "Epoch 2834, Loss: 2.5802950859069824, Final Batch Loss: 0.778166651725769\n",
      "Epoch 2835, Loss: 2.502714902162552, Final Batch Loss: 0.5991597771644592\n",
      "Epoch 2836, Loss: 2.5376402735710144, Final Batch Loss: 0.5204108953475952\n",
      "Epoch 2837, Loss: 2.2936461567878723, Final Batch Loss: 0.28066885471343994\n",
      "Epoch 2838, Loss: 2.331326723098755, Final Batch Loss: 0.42374470829963684\n",
      "Epoch 2839, Loss: 2.5087841153144836, Final Batch Loss: 0.5088523030281067\n",
      "Epoch 2840, Loss: 2.4536551237106323, Final Batch Loss: 0.5103330016136169\n",
      "Epoch 2841, Loss: 2.6433646082878113, Final Batch Loss: 0.6068022847175598\n",
      "Epoch 2842, Loss: 2.066265746951103, Final Batch Loss: 0.17310093343257904\n",
      "Epoch 2843, Loss: 2.4441314339637756, Final Batch Loss: 0.5761685371398926\n",
      "Epoch 2844, Loss: 2.651480346918106, Final Batch Loss: 0.7214309573173523\n",
      "Epoch 2845, Loss: 2.027113288640976, Final Batch Loss: 0.1465158760547638\n",
      "Epoch 2846, Loss: 2.322233736515045, Final Batch Loss: 0.3808324337005615\n",
      "Epoch 2847, Loss: 2.493025094270706, Final Batch Loss: 0.527021050453186\n",
      "Epoch 2848, Loss: 2.290948063135147, Final Batch Loss: 0.3258582651615143\n",
      "Epoch 2849, Loss: 2.4262720346450806, Final Batch Loss: 0.331336110830307\n",
      "Epoch 2850, Loss: 2.1927645802497864, Final Batch Loss: 0.29541876912117004\n",
      "Epoch 2851, Loss: 2.5024868845939636, Final Batch Loss: 0.6154398322105408\n",
      "Epoch 2852, Loss: 2.3605509400367737, Final Batch Loss: 0.5004643201828003\n",
      "Epoch 2853, Loss: 2.220738470554352, Final Batch Loss: 0.30939528346061707\n",
      "Epoch 2854, Loss: 2.2174607813358307, Final Batch Loss: 0.2749016582965851\n",
      "Epoch 2855, Loss: 2.4716259837150574, Final Batch Loss: 0.5683936476707458\n",
      "Epoch 2856, Loss: 2.324050158262253, Final Batch Loss: 0.440532386302948\n",
      "Epoch 2857, Loss: 2.527752250432968, Final Batch Loss: 0.5865405201911926\n",
      "Epoch 2858, Loss: 3.136420100927353, Final Batch Loss: 1.2324810028076172\n",
      "Epoch 2859, Loss: 2.305090218782425, Final Batch Loss: 0.35852620005607605\n",
      "Epoch 2860, Loss: 2.4899322390556335, Final Batch Loss: 0.4645404517650604\n",
      "Epoch 2861, Loss: 2.589269369840622, Final Batch Loss: 0.6380966901779175\n",
      "Epoch 2862, Loss: 2.7055538296699524, Final Batch Loss: 0.6044753193855286\n",
      "Epoch 2863, Loss: 1.999997440725565, Final Batch Loss: 0.042806778103113174\n",
      "Epoch 2864, Loss: 2.464859962463379, Final Batch Loss: 0.5026507377624512\n",
      "Epoch 2865, Loss: 2.169551372528076, Final Batch Loss: 0.33216041326522827\n",
      "Epoch 2866, Loss: 2.056843474507332, Final Batch Loss: 0.23839156329631805\n",
      "Epoch 2867, Loss: 2.257129281759262, Final Batch Loss: 0.3483178913593292\n",
      "Epoch 2868, Loss: 2.3247210681438446, Final Batch Loss: 0.4472416341304779\n",
      "Epoch 2869, Loss: 2.5490519404411316, Final Batch Loss: 0.7635948061943054\n",
      "Epoch 2870, Loss: 2.8079544603824615, Final Batch Loss: 0.7143973112106323\n",
      "Epoch 2871, Loss: 2.2320606410503387, Final Batch Loss: 0.2748841345310211\n",
      "Epoch 2872, Loss: 3.1176708340644836, Final Batch Loss: 1.1446813344955444\n",
      "Epoch 2873, Loss: 2.8671352863311768, Final Batch Loss: 0.8636382222175598\n",
      "Epoch 2874, Loss: 2.296425938606262, Final Batch Loss: 0.38127443194389343\n",
      "Epoch 2875, Loss: 2.2315509915351868, Final Batch Loss: 0.3117330074310303\n",
      "Epoch 2876, Loss: 2.5137330889701843, Final Batch Loss: 0.8097355961799622\n",
      "Epoch 2877, Loss: 2.4649315774440765, Final Batch Loss: 0.4329676926136017\n",
      "Epoch 2878, Loss: 2.4494744539260864, Final Batch Loss: 0.4917941987514496\n",
      "Epoch 2879, Loss: 2.4296896159648895, Final Batch Loss: 0.6367455124855042\n",
      "Epoch 2880, Loss: 2.240097790956497, Final Batch Loss: 0.2827950417995453\n",
      "Epoch 2881, Loss: 2.1622097492218018, Final Batch Loss: 0.247418612241745\n",
      "Epoch 2882, Loss: 2.6618888676166534, Final Batch Loss: 0.70504230260849\n",
      "Epoch 2883, Loss: 2.7709632217884064, Final Batch Loss: 0.8863667249679565\n",
      "Epoch 2884, Loss: 2.0325643122196198, Final Batch Loss: 0.12194311618804932\n",
      "Epoch 2885, Loss: 2.3245851695537567, Final Batch Loss: 0.38965871930122375\n",
      "Epoch 2886, Loss: 2.646091192960739, Final Batch Loss: 0.8771257996559143\n",
      "Epoch 2887, Loss: 2.6536470353603363, Final Batch Loss: 0.8834018707275391\n",
      "Epoch 2888, Loss: 3.0628319680690765, Final Batch Loss: 1.1306052207946777\n",
      "Epoch 2889, Loss: 2.4919681549072266, Final Batch Loss: 0.617155134677887\n",
      "Epoch 2890, Loss: 2.523651599884033, Final Batch Loss: 0.494276225566864\n",
      "Epoch 2891, Loss: 2.331570416688919, Final Batch Loss: 0.4196114242076874\n",
      "Epoch 2892, Loss: 2.421483129262924, Final Batch Loss: 0.4236021637916565\n",
      "Epoch 2893, Loss: 2.330259680747986, Final Batch Loss: 0.28277018666267395\n",
      "Epoch 2894, Loss: 2.7951721847057343, Final Batch Loss: 0.8634308576583862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2895, Loss: 2.241406947374344, Final Batch Loss: 0.1881624162197113\n",
      "Epoch 2896, Loss: 2.1919755041599274, Final Batch Loss: 0.34377971291542053\n",
      "Epoch 2897, Loss: 2.262488603591919, Final Batch Loss: 0.3036641776561737\n",
      "Epoch 2898, Loss: 2.65690541267395, Final Batch Loss: 0.6617079377174377\n",
      "Epoch 2899, Loss: 2.8258985579013824, Final Batch Loss: 0.7430326342582703\n",
      "Epoch 2900, Loss: 2.1027691811323166, Final Batch Loss: 0.13526298105716705\n",
      "Epoch 2901, Loss: 2.214030086994171, Final Batch Loss: 0.3266977369785309\n",
      "Epoch 2902, Loss: 2.469870686531067, Final Batch Loss: 0.4753454327583313\n",
      "Epoch 2903, Loss: 2.225282073020935, Final Batch Loss: 0.3243841528892517\n",
      "Epoch 2904, Loss: 2.469676434993744, Final Batch Loss: 0.4630601108074188\n",
      "Epoch 2905, Loss: 2.6482841074466705, Final Batch Loss: 0.7946115136146545\n",
      "Epoch 2906, Loss: 2.2918664813041687, Final Batch Loss: 0.3830254077911377\n",
      "Epoch 2907, Loss: 2.3172301650047302, Final Batch Loss: 0.3970458209514618\n",
      "Epoch 2908, Loss: 2.34537735581398, Final Batch Loss: 0.5503658652305603\n",
      "Epoch 2909, Loss: 2.37801057100296, Final Batch Loss: 0.49857547879219055\n",
      "Epoch 2910, Loss: 2.167101129889488, Final Batch Loss: 0.14606456458568573\n",
      "Epoch 2911, Loss: 2.4387928247451782, Final Batch Loss: 0.38587686419487\n",
      "Epoch 2912, Loss: 2.5943869948387146, Final Batch Loss: 0.6371997594833374\n",
      "Epoch 2913, Loss: 3.1348027288913727, Final Batch Loss: 0.9822658896446228\n",
      "Epoch 2914, Loss: 2.3380490839481354, Final Batch Loss: 0.43307656049728394\n",
      "Epoch 2915, Loss: 2.9032191336154938, Final Batch Loss: 0.8555728197097778\n",
      "Epoch 2916, Loss: 2.744266539812088, Final Batch Loss: 0.6066661477088928\n",
      "Epoch 2917, Loss: 2.4937442541122437, Final Batch Loss: 0.49968284368515015\n",
      "Epoch 2918, Loss: 2.357876256108284, Final Batch Loss: 0.24372519552707672\n",
      "Epoch 2919, Loss: 2.6138435006141663, Final Batch Loss: 0.7005599141120911\n",
      "Epoch 2920, Loss: 2.3529321253299713, Final Batch Loss: 0.480611652135849\n",
      "Epoch 2921, Loss: 2.483069121837616, Final Batch Loss: 0.474286288022995\n",
      "Epoch 2922, Loss: 2.240659713745117, Final Batch Loss: 0.3599720001220703\n",
      "Epoch 2923, Loss: 2.1364865750074387, Final Batch Loss: 0.167083278298378\n",
      "Epoch 2924, Loss: 2.518286347389221, Final Batch Loss: 0.6305274963378906\n",
      "Epoch 2925, Loss: 2.1926465034484863, Final Batch Loss: 0.2806416451931\n",
      "Epoch 2926, Loss: 2.6002710163593292, Final Batch Loss: 0.6598340272903442\n",
      "Epoch 2927, Loss: 2.4862970411777496, Final Batch Loss: 0.6018466949462891\n",
      "Epoch 2928, Loss: 2.6677455604076385, Final Batch Loss: 0.8091316223144531\n",
      "Epoch 2929, Loss: 2.3584392070770264, Final Batch Loss: 0.3024033010005951\n",
      "Epoch 2930, Loss: 2.303562730550766, Final Batch Loss: 0.4939747750759125\n",
      "Epoch 2931, Loss: 2.7252851724624634, Final Batch Loss: 0.7119513154029846\n",
      "Epoch 2932, Loss: 2.328021138906479, Final Batch Loss: 0.38244953751564026\n",
      "Epoch 2933, Loss: 2.6639550626277924, Final Batch Loss: 0.7074351906776428\n",
      "Epoch 2934, Loss: 2.1609126925468445, Final Batch Loss: 0.2665483057498932\n",
      "Epoch 2935, Loss: 2.5841486155986786, Final Batch Loss: 0.6234815716743469\n",
      "Epoch 2936, Loss: 2.4715161323547363, Final Batch Loss: 0.588618814945221\n",
      "Epoch 2937, Loss: 2.6677379310131073, Final Batch Loss: 0.6997752785682678\n",
      "Epoch 2938, Loss: 2.5195652544498444, Final Batch Loss: 0.5747531652450562\n",
      "Epoch 2939, Loss: 3.137488454580307, Final Batch Loss: 1.2208887338638306\n",
      "Epoch 2940, Loss: 2.67403307557106, Final Batch Loss: 0.4900546669960022\n",
      "Epoch 2941, Loss: 2.19396610558033, Final Batch Loss: 0.22361771762371063\n",
      "Epoch 2942, Loss: 2.584427684545517, Final Batch Loss: 0.5013070702552795\n",
      "Epoch 2943, Loss: 2.9096557199954987, Final Batch Loss: 1.0669691562652588\n",
      "Epoch 2944, Loss: 2.503432512283325, Final Batch Loss: 0.5941727757453918\n",
      "Epoch 2945, Loss: 2.4108435809612274, Final Batch Loss: 0.3974132537841797\n",
      "Epoch 2946, Loss: 2.35408017039299, Final Batch Loss: 0.40485629439353943\n",
      "Epoch 2947, Loss: 2.3444065749645233, Final Batch Loss: 0.4434216320514679\n",
      "Epoch 2948, Loss: 2.664874851703644, Final Batch Loss: 0.631642758846283\n",
      "Epoch 2949, Loss: 2.75898739695549, Final Batch Loss: 0.7498140335083008\n",
      "Epoch 2950, Loss: 2.25943723320961, Final Batch Loss: 0.1959066390991211\n",
      "Epoch 2951, Loss: 2.501640170812607, Final Batch Loss: 0.46022942662239075\n",
      "Epoch 2952, Loss: 2.3063620924949646, Final Batch Loss: 0.3825444281101227\n",
      "Epoch 2953, Loss: 2.65753710269928, Final Batch Loss: 0.7087804675102234\n",
      "Epoch 2954, Loss: 2.6156376898288727, Final Batch Loss: 0.61747807264328\n",
      "Epoch 2955, Loss: 2.3029319047927856, Final Batch Loss: 0.3135851323604584\n",
      "Epoch 2956, Loss: 2.5846690237522125, Final Batch Loss: 0.6277830004692078\n",
      "Epoch 2957, Loss: 2.5187359154224396, Final Batch Loss: 0.47145822644233704\n",
      "Epoch 2958, Loss: 2.569864571094513, Final Batch Loss: 0.4496157467365265\n",
      "Epoch 2959, Loss: 2.4441129565238953, Final Batch Loss: 0.5361319780349731\n",
      "Epoch 2960, Loss: 2.1682178378105164, Final Batch Loss: 0.31862229108810425\n",
      "Epoch 2961, Loss: 2.6201164722442627, Final Batch Loss: 0.670957624912262\n",
      "Epoch 2962, Loss: 2.363760828971863, Final Batch Loss: 0.531562864780426\n",
      "Epoch 2963, Loss: 2.3862938284873962, Final Batch Loss: 0.38789770007133484\n",
      "Epoch 2964, Loss: 1.98026754707098, Final Batch Loss: 0.102168969810009\n",
      "Epoch 2965, Loss: 2.191352903842926, Final Batch Loss: 0.43723419308662415\n",
      "Epoch 2966, Loss: 2.6398995220661163, Final Batch Loss: 0.5893571972846985\n",
      "Epoch 2967, Loss: 2.6540898978710175, Final Batch Loss: 0.7543081641197205\n",
      "Epoch 2968, Loss: 2.19105327129364, Final Batch Loss: 0.36654502153396606\n",
      "Epoch 2969, Loss: 2.377734422683716, Final Batch Loss: 0.5375090837478638\n",
      "Epoch 2970, Loss: 2.3519400358200073, Final Batch Loss: 0.45505380630493164\n",
      "Epoch 2971, Loss: 2.2936368882656097, Final Batch Loss: 0.307903528213501\n",
      "Epoch 2972, Loss: 2.483920931816101, Final Batch Loss: 0.6244437098503113\n",
      "Epoch 2973, Loss: 2.433672845363617, Final Batch Loss: 0.4507822096347809\n",
      "Epoch 2974, Loss: 2.3545630872249603, Final Batch Loss: 0.44713449478149414\n",
      "Epoch 2975, Loss: 2.3822211623191833, Final Batch Loss: 0.43427467346191406\n",
      "Epoch 2976, Loss: 2.207391530275345, Final Batch Loss: 0.41121912002563477\n",
      "Epoch 2977, Loss: 2.624794155359268, Final Batch Loss: 0.7655029892921448\n",
      "Epoch 2978, Loss: 2.6231188476085663, Final Batch Loss: 0.6808895468711853\n",
      "Epoch 2979, Loss: 2.43520325422287, Final Batch Loss: 0.5237919688224792\n",
      "Epoch 2980, Loss: 2.1868779063224792, Final Batch Loss: 0.24430525302886963\n",
      "Epoch 2981, Loss: 2.305363714694977, Final Batch Loss: 0.33969569206237793\n",
      "Epoch 2982, Loss: 2.627816379070282, Final Batch Loss: 0.7783302664756775\n",
      "Epoch 2983, Loss: 2.233431488275528, Final Batch Loss: 0.4397377073764801\n",
      "Epoch 2984, Loss: 2.300605833530426, Final Batch Loss: 0.48044353723526\n",
      "Epoch 2985, Loss: 2.341256409883499, Final Batch Loss: 0.4456516206264496\n",
      "Epoch 2986, Loss: 2.3518647253513336, Final Batch Loss: 0.5019587874412537\n",
      "Epoch 2987, Loss: 2.5089270770549774, Final Batch Loss: 0.6545409560203552\n",
      "Epoch 2988, Loss: 2.634097784757614, Final Batch Loss: 0.5664346218109131\n",
      "Epoch 2989, Loss: 2.3951521515846252, Final Batch Loss: 0.49021726846694946\n",
      "Epoch 2990, Loss: 2.2445128560066223, Final Batch Loss: 0.3587523400783539\n",
      "Epoch 2991, Loss: 2.285338193178177, Final Batch Loss: 0.3045117259025574\n",
      "Epoch 2992, Loss: 2.6795297265052795, Final Batch Loss: 0.7710420489311218\n",
      "Epoch 2993, Loss: 2.436425745487213, Final Batch Loss: 0.5452869534492493\n",
      "Epoch 2994, Loss: 2.393676519393921, Final Batch Loss: 0.4811641573905945\n",
      "Epoch 2995, Loss: 2.321530371904373, Final Batch Loss: 0.3844871520996094\n",
      "Epoch 2996, Loss: 2.2664583325386047, Final Batch Loss: 0.31495657563209534\n",
      "Epoch 2997, Loss: 2.059250771999359, Final Batch Loss: 0.06583797931671143\n",
      "Epoch 2998, Loss: 2.793861895799637, Final Batch Loss: 0.7388768196105957\n",
      "Epoch 2999, Loss: 2.414604753255844, Final Batch Loss: 0.45484378933906555\n",
      "Epoch 3000, Loss: 2.113897144794464, Final Batch Loss: 0.29434284567832947\n",
      "Epoch 3001, Loss: 2.480483591556549, Final Batch Loss: 0.5697906613349915\n",
      "Epoch 3002, Loss: 2.1522676944732666, Final Batch Loss: 0.3859427273273468\n",
      "Epoch 3003, Loss: 2.2823915481567383, Final Batch Loss: 0.30301809310913086\n",
      "Epoch 3004, Loss: 2.649232029914856, Final Batch Loss: 0.7796602249145508\n",
      "Epoch 3005, Loss: 2.233496218919754, Final Batch Loss: 0.35035988688468933\n",
      "Epoch 3006, Loss: 2.52262943983078, Final Batch Loss: 0.6481877565383911\n",
      "Epoch 3007, Loss: 2.285883456468582, Final Batch Loss: 0.44929423928260803\n",
      "Epoch 3008, Loss: 2.474791944026947, Final Batch Loss: 0.5879325270652771\n",
      "Epoch 3009, Loss: 2.0109085738658905, Final Batch Loss: 0.25692862272262573\n",
      "Epoch 3010, Loss: 1.8890885543078184, Final Batch Loss: 0.028374148532748222\n",
      "Epoch 3011, Loss: 2.1655542850494385, Final Batch Loss: 0.3082022964954376\n",
      "Epoch 3012, Loss: 2.1181696355342865, Final Batch Loss: 0.1506175994873047\n",
      "Epoch 3013, Loss: 2.106801748275757, Final Batch Loss: 0.31328415870666504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3014, Loss: 2.013684555888176, Final Batch Loss: 0.13105271756649017\n",
      "Epoch 3015, Loss: 2.095806896686554, Final Batch Loss: 0.3104681670665741\n",
      "Epoch 3016, Loss: 2.446853995323181, Final Batch Loss: 0.5082180500030518\n",
      "Epoch 3017, Loss: 2.3605858981609344, Final Batch Loss: 0.5328810811042786\n",
      "Epoch 3018, Loss: 2.311598479747772, Final Batch Loss: 0.29720601439476013\n",
      "Epoch 3019, Loss: 2.6458232700824738, Final Batch Loss: 0.7826640009880066\n",
      "Epoch 3020, Loss: 2.3162796795368195, Final Batch Loss: 0.38938644528388977\n",
      "Epoch 3021, Loss: 2.383005768060684, Final Batch Loss: 0.6070562601089478\n",
      "Epoch 3022, Loss: 2.2901145219802856, Final Batch Loss: 0.44026967883110046\n",
      "Epoch 3023, Loss: 2.5370370149612427, Final Batch Loss: 0.5157191157341003\n",
      "Epoch 3024, Loss: 2.068505823612213, Final Batch Loss: 0.19011589884757996\n",
      "Epoch 3025, Loss: 2.2403205037117004, Final Batch Loss: 0.3276817202568054\n",
      "Epoch 3026, Loss: 1.9537539035081863, Final Batch Loss: 0.20928649604320526\n",
      "Epoch 3027, Loss: 2.7986162304878235, Final Batch Loss: 0.8958436846733093\n",
      "Epoch 3028, Loss: 2.6791780591011047, Final Batch Loss: 0.8277350068092346\n",
      "Epoch 3029, Loss: 2.3188834190368652, Final Batch Loss: 0.34299734234809875\n",
      "Epoch 3030, Loss: 3.0404635965824127, Final Batch Loss: 1.0986357927322388\n",
      "Epoch 3031, Loss: 2.5477454662323, Final Batch Loss: 0.6998119354248047\n",
      "Epoch 3032, Loss: 2.2365795969963074, Final Batch Loss: 0.30925440788269043\n",
      "Epoch 3033, Loss: 2.2606430053710938, Final Batch Loss: 0.35423895716667175\n",
      "Epoch 3034, Loss: 2.4996482729911804, Final Batch Loss: 0.6005377769470215\n",
      "Epoch 3035, Loss: 2.483445644378662, Final Batch Loss: 0.45925024151802063\n",
      "Epoch 3036, Loss: 2.3922086656093597, Final Batch Loss: 0.5811482667922974\n",
      "Epoch 3037, Loss: 2.144338443875313, Final Batch Loss: 0.2098046988248825\n",
      "Epoch 3038, Loss: 2.7981112599372864, Final Batch Loss: 0.7511262893676758\n",
      "Epoch 3039, Loss: 2.373432159423828, Final Batch Loss: 0.500050961971283\n",
      "Epoch 3040, Loss: 2.1719828248023987, Final Batch Loss: 0.49923911690711975\n",
      "Epoch 3041, Loss: 2.6135187447071075, Final Batch Loss: 0.839999794960022\n",
      "Epoch 3042, Loss: 2.313969910144806, Final Batch Loss: 0.3512597382068634\n",
      "Epoch 3043, Loss: 2.5093241930007935, Final Batch Loss: 0.4676367938518524\n",
      "Epoch 3044, Loss: 2.7873216569423676, Final Batch Loss: 0.7977299690246582\n",
      "Epoch 3045, Loss: 2.2724344730377197, Final Batch Loss: 0.4691653847694397\n",
      "Epoch 3046, Loss: 2.925338476896286, Final Batch Loss: 0.9267369508743286\n",
      "Epoch 3047, Loss: 2.307148665189743, Final Batch Loss: 0.39676323533058167\n",
      "Epoch 3048, Loss: 2.3344653844833374, Final Batch Loss: 0.3789222240447998\n",
      "Epoch 3049, Loss: 2.6715520322322845, Final Batch Loss: 0.8842467665672302\n",
      "Epoch 3050, Loss: 2.2369642555713654, Final Batch Loss: 0.33705464005470276\n",
      "Epoch 3051, Loss: 2.1688691079616547, Final Batch Loss: 0.2900051772594452\n",
      "Epoch 3052, Loss: 2.2831714749336243, Final Batch Loss: 0.41488367319107056\n",
      "Epoch 3053, Loss: 2.350983142852783, Final Batch Loss: 0.3784935176372528\n",
      "Epoch 3054, Loss: 2.440600574016571, Final Batch Loss: 0.5031158328056335\n",
      "Epoch 3055, Loss: 2.2298409044742584, Final Batch Loss: 0.40262141823768616\n",
      "Epoch 3056, Loss: 2.05124893784523, Final Batch Loss: 0.3428082764148712\n",
      "Epoch 3057, Loss: 2.4667800664901733, Final Batch Loss: 0.6263764500617981\n",
      "Epoch 3058, Loss: 2.14979287981987, Final Batch Loss: 0.2688312828540802\n",
      "Epoch 3059, Loss: 2.242109000682831, Final Batch Loss: 0.3643978238105774\n",
      "Epoch 3060, Loss: 2.3380385637283325, Final Batch Loss: 0.4976852536201477\n",
      "Epoch 3061, Loss: 2.2713333666324615, Final Batch Loss: 0.4759689271450043\n",
      "Epoch 3062, Loss: 2.1446000039577484, Final Batch Loss: 0.1841369867324829\n",
      "Epoch 3063, Loss: 1.8372989185154438, Final Batch Loss: 0.04283704236149788\n",
      "Epoch 3064, Loss: 2.1640928983688354, Final Batch Loss: 0.277549684047699\n",
      "Epoch 3065, Loss: 2.541572391986847, Final Batch Loss: 0.6800016164779663\n",
      "Epoch 3066, Loss: 2.274296134710312, Final Batch Loss: 0.38767209649086\n",
      "Epoch 3067, Loss: 2.144669473171234, Final Batch Loss: 0.2729783356189728\n",
      "Epoch 3068, Loss: 2.581878274679184, Final Batch Loss: 0.4805435538291931\n",
      "Epoch 3069, Loss: 2.6416252851486206, Final Batch Loss: 0.8472422957420349\n",
      "Epoch 3070, Loss: 2.0796096324920654, Final Batch Loss: 0.26171934604644775\n",
      "Epoch 3071, Loss: 2.1521031856536865, Final Batch Loss: 0.40967100858688354\n",
      "Epoch 3072, Loss: 2.318701356649399, Final Batch Loss: 0.4513607919216156\n",
      "Epoch 3073, Loss: 2.2699732780456543, Final Batch Loss: 0.4954470992088318\n",
      "Epoch 3074, Loss: 2.6797625720500946, Final Batch Loss: 0.6266611218452454\n",
      "Epoch 3075, Loss: 2.6069831252098083, Final Batch Loss: 0.6934338808059692\n",
      "Epoch 3076, Loss: 2.3478029370307922, Final Batch Loss: 0.5956825613975525\n",
      "Epoch 3077, Loss: 2.0577968657016754, Final Batch Loss: 0.3054698407649994\n",
      "Epoch 3078, Loss: 2.587887018918991, Final Batch Loss: 0.6189189553260803\n",
      "Epoch 3079, Loss: 2.1627901196479797, Final Batch Loss: 0.2642104923725128\n",
      "Epoch 3080, Loss: 2.0042394250631332, Final Batch Loss: 0.12517713010311127\n",
      "Epoch 3081, Loss: 2.2950888872146606, Final Batch Loss: 0.4951610267162323\n",
      "Epoch 3082, Loss: 2.202406585216522, Final Batch Loss: 0.33925631642341614\n",
      "Epoch 3083, Loss: 2.0972006022930145, Final Batch Loss: 0.31057944893836975\n",
      "Epoch 3084, Loss: 2.2697966396808624, Final Batch Loss: 0.31340986490249634\n",
      "Epoch 3085, Loss: 2.1317591667175293, Final Batch Loss: 0.37687617540359497\n",
      "Epoch 3086, Loss: 2.1421987265348434, Final Batch Loss: 0.1547672301530838\n",
      "Epoch 3087, Loss: 2.132068172097206, Final Batch Loss: 0.21617282927036285\n",
      "Epoch 3088, Loss: 2.0552768111228943, Final Batch Loss: 0.25154730677604675\n",
      "Epoch 3089, Loss: 2.433425545692444, Final Batch Loss: 0.5427370071411133\n",
      "Epoch 3090, Loss: 2.0791203379631042, Final Batch Loss: 0.3035009801387787\n",
      "Epoch 3091, Loss: 2.1872672140598297, Final Batch Loss: 0.2500764727592468\n",
      "Epoch 3092, Loss: 2.268943339586258, Final Batch Loss: 0.48995521664619446\n",
      "Epoch 3093, Loss: 2.3323406279087067, Final Batch Loss: 0.34074434638023376\n",
      "Epoch 3094, Loss: 2.3066574037075043, Final Batch Loss: 0.3268583118915558\n",
      "Epoch 3095, Loss: 2.0919934660196304, Final Batch Loss: 0.23634181916713715\n",
      "Epoch 3096, Loss: 3.1243500113487244, Final Batch Loss: 1.1612509489059448\n",
      "Epoch 3097, Loss: 2.274855315685272, Final Batch Loss: 0.43067413568496704\n",
      "Epoch 3098, Loss: 2.3309753835201263, Final Batch Loss: 0.5216442346572876\n",
      "Epoch 3099, Loss: 2.172146797180176, Final Batch Loss: 0.29562854766845703\n",
      "Epoch 3100, Loss: 2.020965337753296, Final Batch Loss: 0.15549588203430176\n",
      "Epoch 3101, Loss: 2.1864328384399414, Final Batch Loss: 0.41106438636779785\n",
      "Epoch 3102, Loss: 2.364765226840973, Final Batch Loss: 0.6402230262756348\n",
      "Epoch 3103, Loss: 2.2595265805721283, Final Batch Loss: 0.2797929644584656\n",
      "Epoch 3104, Loss: 2.2008679807186127, Final Batch Loss: 0.4283948838710785\n",
      "Epoch 3105, Loss: 2.1177304685115814, Final Batch Loss: 0.32688847184181213\n",
      "Epoch 3106, Loss: 2.023248389363289, Final Batch Loss: 0.12910236418247223\n",
      "Epoch 3107, Loss: 2.2258929014205933, Final Batch Loss: 0.45859748125076294\n",
      "Epoch 3108, Loss: 2.363862305879593, Final Batch Loss: 0.5175039172172546\n",
      "Epoch 3109, Loss: 2.1976928412914276, Final Batch Loss: 0.2895612418651581\n",
      "Epoch 3110, Loss: 2.2711581885814667, Final Batch Loss: 0.4143579602241516\n",
      "Epoch 3111, Loss: 2.4447804391384125, Final Batch Loss: 0.5426182150840759\n",
      "Epoch 3112, Loss: 2.2011991143226624, Final Batch Loss: 0.15897846221923828\n",
      "Epoch 3113, Loss: 2.4312565326690674, Final Batch Loss: 0.5244444012641907\n",
      "Epoch 3114, Loss: 2.0692144632339478, Final Batch Loss: 0.2658913731575012\n",
      "Epoch 3115, Loss: 2.342543989419937, Final Batch Loss: 0.5051668286323547\n",
      "Epoch 3116, Loss: 2.369062751531601, Final Batch Loss: 0.5919474363327026\n",
      "Epoch 3117, Loss: 2.1253111362457275, Final Batch Loss: 0.3158279359340668\n",
      "Epoch 3118, Loss: 2.3603935539722443, Final Batch Loss: 0.5756579041481018\n",
      "Epoch 3119, Loss: 2.392783463001251, Final Batch Loss: 0.5112628936767578\n",
      "Epoch 3120, Loss: 2.3736099898815155, Final Batch Loss: 0.6064440011978149\n",
      "Epoch 3121, Loss: 2.3578725457191467, Final Batch Loss: 0.41790589690208435\n",
      "Epoch 3122, Loss: 2.4740810692310333, Final Batch Loss: 0.5671047568321228\n",
      "Epoch 3123, Loss: 2.2862204909324646, Final Batch Loss: 0.42143863439559937\n",
      "Epoch 3124, Loss: 2.6649403870105743, Final Batch Loss: 0.7708439230918884\n",
      "Epoch 3125, Loss: 2.1575747579336166, Final Batch Loss: 0.180861696600914\n",
      "Epoch 3126, Loss: 2.3503994047641754, Final Batch Loss: 0.5109127759933472\n",
      "Epoch 3127, Loss: 2.3840377032756805, Final Batch Loss: 0.36343488097190857\n",
      "Epoch 3128, Loss: 2.6591740250587463, Final Batch Loss: 0.5364037752151489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3129, Loss: 2.606017053127289, Final Batch Loss: 0.6957655549049377\n",
      "Epoch 3130, Loss: 2.5736598074436188, Final Batch Loss: 0.6800360679626465\n",
      "Epoch 3131, Loss: 2.4638908207416534, Final Batch Loss: 0.5066336989402771\n",
      "Epoch 3132, Loss: 2.1706650853157043, Final Batch Loss: 0.29084843397140503\n",
      "Epoch 3133, Loss: 2.5317901968955994, Final Batch Loss: 0.48680609464645386\n",
      "Epoch 3134, Loss: 2.5859562754631042, Final Batch Loss: 0.49107226729393005\n",
      "Epoch 3135, Loss: 2.3869540989398956, Final Batch Loss: 0.6261361837387085\n",
      "Epoch 3136, Loss: 2.476425349712372, Final Batch Loss: 0.5753392577171326\n",
      "Epoch 3137, Loss: 2.514766812324524, Final Batch Loss: 0.645797848701477\n",
      "Epoch 3138, Loss: 2.253927230834961, Final Batch Loss: 0.38552728295326233\n",
      "Epoch 3139, Loss: 2.0456400215625763, Final Batch Loss: 0.2650243043899536\n",
      "Epoch 3140, Loss: 2.2450180649757385, Final Batch Loss: 0.39356356859207153\n",
      "Epoch 3141, Loss: 2.1459790766239166, Final Batch Loss: 0.31430575251579285\n",
      "Epoch 3142, Loss: 2.0353614687919617, Final Batch Loss: 0.18743303418159485\n",
      "Epoch 3143, Loss: 2.1742094308137894, Final Batch Loss: 0.23797069489955902\n",
      "Epoch 3144, Loss: 2.4303763806819916, Final Batch Loss: 0.582512378692627\n",
      "Epoch 3145, Loss: 2.4585385024547577, Final Batch Loss: 0.6527795195579529\n",
      "Epoch 3146, Loss: 2.6545052230358124, Final Batch Loss: 0.7745606303215027\n",
      "Epoch 3147, Loss: 2.374232739210129, Final Batch Loss: 0.5202361345291138\n",
      "Epoch 3148, Loss: 2.580728679895401, Final Batch Loss: 0.7021856904029846\n",
      "Epoch 3149, Loss: 2.05811707675457, Final Batch Loss: 0.22710956633090973\n",
      "Epoch 3150, Loss: 2.2301333248615265, Final Batch Loss: 0.4511135518550873\n",
      "Epoch 3151, Loss: 2.358454167842865, Final Batch Loss: 0.4521767199039459\n",
      "Epoch 3152, Loss: 2.2670739889144897, Final Batch Loss: 0.42950281500816345\n",
      "Epoch 3153, Loss: 2.7134303152561188, Final Batch Loss: 0.9002890586853027\n",
      "Epoch 3154, Loss: 2.2186898291110992, Final Batch Loss: 0.3102893531322479\n",
      "Epoch 3155, Loss: 2.410482257604599, Final Batch Loss: 0.34318670630455017\n",
      "Epoch 3156, Loss: 3.020635575056076, Final Batch Loss: 1.258344054222107\n",
      "Epoch 3157, Loss: 2.4022080302238464, Final Batch Loss: 0.5783433318138123\n",
      "Epoch 3158, Loss: 2.6556585133075714, Final Batch Loss: 0.7412341237068176\n",
      "Epoch 3159, Loss: 2.1413144767284393, Final Batch Loss: 0.4102138578891754\n",
      "Epoch 3160, Loss: 2.186777710914612, Final Batch Loss: 0.4098626673221588\n",
      "Epoch 3161, Loss: 2.3169310688972473, Final Batch Loss: 0.4432510733604431\n",
      "Epoch 3162, Loss: 2.0148846805095673, Final Batch Loss: 0.2679564356803894\n",
      "Epoch 3163, Loss: 2.6389045119285583, Final Batch Loss: 0.8734185099601746\n",
      "Epoch 3164, Loss: 2.239844888448715, Final Batch Loss: 0.45405569672584534\n",
      "Epoch 3165, Loss: 2.106565088033676, Final Batch Loss: 0.26993849873542786\n",
      "Epoch 3166, Loss: 3.0098821222782135, Final Batch Loss: 1.1968085765838623\n",
      "Epoch 3167, Loss: 2.104664996266365, Final Batch Loss: 0.19277696311473846\n",
      "Epoch 3168, Loss: 2.142865389585495, Final Batch Loss: 0.36362263560295105\n",
      "Epoch 3169, Loss: 2.2616638243198395, Final Batch Loss: 0.3472735285758972\n",
      "Epoch 3170, Loss: 2.006837375462055, Final Batch Loss: 0.10092232376337051\n",
      "Epoch 3171, Loss: 1.956129550933838, Final Batch Loss: 0.25897520780563354\n",
      "Epoch 3172, Loss: 2.2071064114570618, Final Batch Loss: 0.4392883777618408\n",
      "Epoch 3173, Loss: 2.092507928609848, Final Batch Loss: 0.3402412235736847\n",
      "Epoch 3174, Loss: 2.2608102560043335, Final Batch Loss: 0.3205527365207672\n",
      "Epoch 3175, Loss: 2.3500656187534332, Final Batch Loss: 0.5371328592300415\n",
      "Epoch 3176, Loss: 2.1269440203905106, Final Batch Loss: 0.23116247355937958\n",
      "Epoch 3177, Loss: 2.0747056007385254, Final Batch Loss: 0.22718587517738342\n",
      "Epoch 3178, Loss: 2.1679108142852783, Final Batch Loss: 0.3883339762687683\n",
      "Epoch 3179, Loss: 2.1086649894714355, Final Batch Loss: 0.17034092545509338\n",
      "Epoch 3180, Loss: 2.7033369541168213, Final Batch Loss: 0.7797884345054626\n",
      "Epoch 3181, Loss: 2.268379271030426, Final Batch Loss: 0.4914276897907257\n",
      "Epoch 3182, Loss: 2.25540828704834, Final Batch Loss: 0.34969562292099\n",
      "Epoch 3183, Loss: 2.159236043691635, Final Batch Loss: 0.39963406324386597\n",
      "Epoch 3184, Loss: 2.486128121614456, Final Batch Loss: 0.6243585348129272\n",
      "Epoch 3185, Loss: 2.6089524626731873, Final Batch Loss: 0.7366470098495483\n",
      "Epoch 3186, Loss: 2.6705787777900696, Final Batch Loss: 0.8131726384162903\n",
      "Epoch 3187, Loss: 1.8684308789670467, Final Batch Loss: 0.059360530227422714\n",
      "Epoch 3188, Loss: 2.101131245493889, Final Batch Loss: 0.21934257447719574\n",
      "Epoch 3189, Loss: 2.08884796500206, Final Batch Loss: 0.3713230788707733\n",
      "Epoch 3190, Loss: 2.410577744245529, Final Batch Loss: 0.4883287847042084\n",
      "Epoch 3191, Loss: 2.084144741296768, Final Batch Loss: 0.26531267166137695\n",
      "Epoch 3192, Loss: 2.5887128114700317, Final Batch Loss: 0.6386309266090393\n",
      "Epoch 3193, Loss: 2.0319662019610405, Final Batch Loss: 0.10156764835119247\n",
      "Epoch 3194, Loss: 2.064607948064804, Final Batch Loss: 0.3251669108867645\n",
      "Epoch 3195, Loss: 2.237481713294983, Final Batch Loss: 0.3930582106113434\n",
      "Epoch 3196, Loss: 2.370607376098633, Final Batch Loss: 0.3901051878929138\n",
      "Epoch 3197, Loss: 2.3095127642154694, Final Batch Loss: 0.5319406986236572\n",
      "Epoch 3198, Loss: 2.3105060160160065, Final Batch Loss: 0.37610262632369995\n",
      "Epoch 3199, Loss: 1.976589534431696, Final Batch Loss: 0.05932179465889931\n",
      "Epoch 3200, Loss: 2.3640781939029694, Final Batch Loss: 0.43776288628578186\n",
      "Epoch 3201, Loss: 2.3653449416160583, Final Batch Loss: 0.4919113218784332\n",
      "Epoch 3202, Loss: 2.3461081981658936, Final Batch Loss: 0.43312761187553406\n",
      "Epoch 3203, Loss: 1.849615216255188, Final Batch Loss: 0.16222652792930603\n",
      "Epoch 3204, Loss: 2.0716256499290466, Final Batch Loss: 0.32043737173080444\n",
      "Epoch 3205, Loss: 2.171745389699936, Final Batch Loss: 0.33308476209640503\n",
      "Epoch 3206, Loss: 2.6549472510814667, Final Batch Loss: 0.9015229344367981\n",
      "Epoch 3207, Loss: 2.0681187212467194, Final Batch Loss: 0.25008586049079895\n",
      "Epoch 3208, Loss: 2.577064633369446, Final Batch Loss: 0.74473637342453\n",
      "Epoch 3209, Loss: 2.4988306760787964, Final Batch Loss: 0.6938529014587402\n",
      "Epoch 3210, Loss: 2.1763074696063995, Final Batch Loss: 0.24808427691459656\n",
      "Epoch 3211, Loss: 1.9037905484437943, Final Batch Loss: 0.17963041365146637\n",
      "Epoch 3212, Loss: 1.9960266053676605, Final Batch Loss: 0.21448740363121033\n",
      "Epoch 3213, Loss: 2.5504870116710663, Final Batch Loss: 0.715536892414093\n",
      "Epoch 3214, Loss: 2.40326327085495, Final Batch Loss: 0.5144210457801819\n",
      "Epoch 3215, Loss: 2.510549783706665, Final Batch Loss: 0.6865425109863281\n",
      "Epoch 3216, Loss: 1.9250717796385288, Final Batch Loss: 0.04862752929329872\n",
      "Epoch 3217, Loss: 2.3219338059425354, Final Batch Loss: 0.30730798840522766\n",
      "Epoch 3218, Loss: 2.4840041995048523, Final Batch Loss: 0.5632256865501404\n",
      "Epoch 3219, Loss: 2.708140194416046, Final Batch Loss: 0.7767937779426575\n",
      "Epoch 3220, Loss: 3.1167306900024414, Final Batch Loss: 1.226751685142517\n",
      "Epoch 3221, Loss: 2.1265378147363663, Final Batch Loss: 0.20145229995250702\n",
      "Epoch 3222, Loss: 2.5447496473789215, Final Batch Loss: 0.7451928853988647\n",
      "Epoch 3223, Loss: 2.273597627878189, Final Batch Loss: 0.47043412923812866\n",
      "Epoch 3224, Loss: 2.1112208366394043, Final Batch Loss: 0.36764591932296753\n",
      "Epoch 3225, Loss: 2.341824561357498, Final Batch Loss: 0.4624488055706024\n",
      "Epoch 3226, Loss: 2.3296697437763214, Final Batch Loss: 0.5923992395401001\n",
      "Epoch 3227, Loss: 2.243722289800644, Final Batch Loss: 0.4348315894603729\n",
      "Epoch 3228, Loss: 2.0404852479696274, Final Batch Loss: 0.24336425960063934\n",
      "Epoch 3229, Loss: 2.032319873571396, Final Batch Loss: 0.30828672647476196\n",
      "Epoch 3230, Loss: 2.2757538855075836, Final Batch Loss: 0.4515335261821747\n",
      "Epoch 3231, Loss: 2.2930992245674133, Final Batch Loss: 0.4093994200229645\n",
      "Epoch 3232, Loss: 2.229033797979355, Final Batch Loss: 0.35146600008010864\n",
      "Epoch 3233, Loss: 2.4084856510162354, Final Batch Loss: 0.4197075366973877\n",
      "Epoch 3234, Loss: 2.067087173461914, Final Batch Loss: 0.27031901478767395\n",
      "Epoch 3235, Loss: 2.3679228723049164, Final Batch Loss: 0.43937331438064575\n",
      "Epoch 3236, Loss: 2.4333311319351196, Final Batch Loss: 0.7126916646957397\n",
      "Epoch 3237, Loss: 2.3720300793647766, Final Batch Loss: 0.4161783754825592\n",
      "Epoch 3238, Loss: 2.1859995424747467, Final Batch Loss: 0.20174932479858398\n",
      "Epoch 3239, Loss: 2.393079698085785, Final Batch Loss: 0.5811904668807983\n",
      "Epoch 3240, Loss: 1.885903924703598, Final Batch Loss: 0.11955732107162476\n",
      "Epoch 3241, Loss: 2.165621817111969, Final Batch Loss: 0.32641997933387756\n",
      "Epoch 3242, Loss: 2.4282171428203583, Final Batch Loss: 0.30701711773872375\n",
      "Epoch 3243, Loss: 1.976971611380577, Final Batch Loss: 0.14573074877262115\n",
      "Epoch 3244, Loss: 2.295769840478897, Final Batch Loss: 0.47618773579597473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3245, Loss: 2.038609206676483, Final Batch Loss: 0.18671342730522156\n",
      "Epoch 3246, Loss: 2.4424783289432526, Final Batch Loss: 0.36548134684562683\n",
      "Epoch 3247, Loss: 2.0781445503234863, Final Batch Loss: 0.20978185534477234\n",
      "Epoch 3248, Loss: 2.3017238676548004, Final Batch Loss: 0.5768646001815796\n",
      "Epoch 3249, Loss: 2.4197184443473816, Final Batch Loss: 0.7530885934829712\n",
      "Epoch 3250, Loss: 2.3407124280929565, Final Batch Loss: 0.5497420430183411\n",
      "Epoch 3251, Loss: 2.429283231496811, Final Batch Loss: 0.4974520206451416\n",
      "Epoch 3252, Loss: 2.268385946750641, Final Batch Loss: 0.4841725826263428\n",
      "Epoch 3253, Loss: 2.1207250356674194, Final Batch Loss: 0.4726424515247345\n",
      "Epoch 3254, Loss: 2.1514038145542145, Final Batch Loss: 0.2632215917110443\n",
      "Epoch 3255, Loss: 2.2109363675117493, Final Batch Loss: 0.3774813115596771\n",
      "Epoch 3256, Loss: 2.0354101210832596, Final Batch Loss: 0.18581737577915192\n",
      "Epoch 3257, Loss: 2.207056015729904, Final Batch Loss: 0.3330405652523041\n",
      "Epoch 3258, Loss: 2.566479802131653, Final Batch Loss: 0.7269938588142395\n",
      "Epoch 3259, Loss: 2.281369984149933, Final Batch Loss: 0.3475339114665985\n",
      "Epoch 3260, Loss: 2.684871405363083, Final Batch Loss: 0.4590770900249481\n",
      "Epoch 3261, Loss: 2.725120723247528, Final Batch Loss: 0.8108987212181091\n",
      "Epoch 3262, Loss: 2.261927008628845, Final Batch Loss: 0.32503944635391235\n",
      "Epoch 3263, Loss: 2.191624402999878, Final Batch Loss: 0.30428576469421387\n",
      "Epoch 3264, Loss: 2.2398924827575684, Final Batch Loss: 0.4290800988674164\n",
      "Epoch 3265, Loss: 2.5207886695861816, Final Batch Loss: 0.6472694277763367\n",
      "Epoch 3266, Loss: 2.206624537706375, Final Batch Loss: 0.2784663140773773\n",
      "Epoch 3267, Loss: 2.4116863310337067, Final Batch Loss: 0.5886611342430115\n",
      "Epoch 3268, Loss: 3.086334675550461, Final Batch Loss: 1.2109105587005615\n",
      "Epoch 3269, Loss: 2.319318950176239, Final Batch Loss: 0.5753185153007507\n",
      "Epoch 3270, Loss: 2.278101474046707, Final Batch Loss: 0.40587902069091797\n",
      "Epoch 3271, Loss: 2.6871237456798553, Final Batch Loss: 0.8122320175170898\n",
      "Epoch 3272, Loss: 2.1602843105793, Final Batch Loss: 0.19436970353126526\n",
      "Epoch 3273, Loss: 2.3424538671970367, Final Batch Loss: 0.5968955755233765\n",
      "Epoch 3274, Loss: 2.1807006001472473, Final Batch Loss: 0.3838426470756531\n",
      "Epoch 3275, Loss: 1.7816348522901535, Final Batch Loss: 0.14999701082706451\n",
      "Epoch 3276, Loss: 2.2122121155261993, Final Batch Loss: 0.4503808319568634\n",
      "Epoch 3277, Loss: 2.5046361088752747, Final Batch Loss: 0.6160930395126343\n",
      "Epoch 3278, Loss: 2.8506697714328766, Final Batch Loss: 0.8016419410705566\n",
      "Epoch 3279, Loss: 2.1470298767089844, Final Batch Loss: 0.31993573904037476\n",
      "Epoch 3280, Loss: 2.2660961747169495, Final Batch Loss: 0.47769901156425476\n",
      "Epoch 3281, Loss: 2.429887056350708, Final Batch Loss: 0.46000275015830994\n",
      "Epoch 3282, Loss: 2.314467340707779, Final Batch Loss: 0.4884452819824219\n",
      "Epoch 3283, Loss: 2.269217163324356, Final Batch Loss: 0.341887891292572\n",
      "Epoch 3284, Loss: 2.208197444677353, Final Batch Loss: 0.3763957619667053\n",
      "Epoch 3285, Loss: 2.044153109192848, Final Batch Loss: 0.21901662647724152\n",
      "Epoch 3286, Loss: 2.233123391866684, Final Batch Loss: 0.4684426188468933\n",
      "Epoch 3287, Loss: 2.2431045472621918, Final Batch Loss: 0.3234390318393707\n",
      "Epoch 3288, Loss: 2.3254100680351257, Final Batch Loss: 0.4953496754169464\n",
      "Epoch 3289, Loss: 2.056877925992012, Final Batch Loss: 0.2369808405637741\n",
      "Epoch 3290, Loss: 2.104643791913986, Final Batch Loss: 0.31041741371154785\n",
      "Epoch 3291, Loss: 2.4827636182308197, Final Batch Loss: 0.677116334438324\n",
      "Epoch 3292, Loss: 2.168419659137726, Final Batch Loss: 0.1638653576374054\n",
      "Epoch 3293, Loss: 2.164201259613037, Final Batch Loss: 0.25818878412246704\n",
      "Epoch 3294, Loss: 2.063642829656601, Final Batch Loss: 0.16769829392433167\n",
      "Epoch 3295, Loss: 2.4556428492069244, Final Batch Loss: 0.8276504874229431\n",
      "Epoch 3296, Loss: 2.1563589572906494, Final Batch Loss: 0.31961002945899963\n",
      "Epoch 3297, Loss: 2.1163498163223267, Final Batch Loss: 0.30840441584587097\n",
      "Epoch 3298, Loss: 2.2982566952705383, Final Batch Loss: 0.4917440712451935\n",
      "Epoch 3299, Loss: 2.3225854337215424, Final Batch Loss: 0.4105583131313324\n",
      "Epoch 3300, Loss: 2.3230037689208984, Final Batch Loss: 0.48282456398010254\n",
      "Epoch 3301, Loss: 1.8426449596881866, Final Batch Loss: 0.12969312071800232\n",
      "Epoch 3302, Loss: 2.1739559173583984, Final Batch Loss: 0.3537604510784149\n",
      "Epoch 3303, Loss: 2.1754296123981476, Final Batch Loss: 0.47271278500556946\n",
      "Epoch 3304, Loss: 1.8446809276938438, Final Batch Loss: 0.0807357057929039\n",
      "Epoch 3305, Loss: 2.014516592025757, Final Batch Loss: 0.2912774682044983\n",
      "Epoch 3306, Loss: 1.9781387150287628, Final Batch Loss: 0.1849215030670166\n",
      "Epoch 3307, Loss: 1.842108741402626, Final Batch Loss: 0.15049462020397186\n",
      "Epoch 3308, Loss: 1.7647837698459625, Final Batch Loss: 0.1798003613948822\n",
      "Epoch 3309, Loss: 2.2685050070285797, Final Batch Loss: 0.4839380383491516\n",
      "Epoch 3310, Loss: 2.0017445534467697, Final Batch Loss: 0.10809703171253204\n",
      "Epoch 3311, Loss: 2.3306992948055267, Final Batch Loss: 0.48189958930015564\n",
      "Epoch 3312, Loss: 2.950914353132248, Final Batch Loss: 1.2401973009109497\n",
      "Epoch 3313, Loss: 2.832571804523468, Final Batch Loss: 0.9509872794151306\n",
      "Epoch 3314, Loss: 2.6884365379810333, Final Batch Loss: 0.7341335415840149\n",
      "Epoch 3315, Loss: 2.3332343995571136, Final Batch Loss: 0.38750410079956055\n",
      "Epoch 3316, Loss: 2.430765300989151, Final Batch Loss: 0.5123884081840515\n",
      "Epoch 3317, Loss: 2.7539537847042084, Final Batch Loss: 0.9506157040596008\n",
      "Epoch 3318, Loss: 2.1424602568149567, Final Batch Loss: 0.37129226326942444\n",
      "Epoch 3319, Loss: 2.269134074449539, Final Batch Loss: 0.39862707257270813\n",
      "Epoch 3320, Loss: 2.0217127799987793, Final Batch Loss: 0.20581689476966858\n",
      "Epoch 3321, Loss: 2.303512930870056, Final Batch Loss: 0.415559858083725\n",
      "Epoch 3322, Loss: 2.4212827682495117, Final Batch Loss: 0.6176410913467407\n",
      "Epoch 3323, Loss: 2.253078132867813, Final Batch Loss: 0.5004827976226807\n",
      "Epoch 3324, Loss: 1.9905409961938858, Final Batch Loss: 0.18434588611125946\n",
      "Epoch 3325, Loss: 2.0461878776550293, Final Batch Loss: 0.4017908573150635\n",
      "Epoch 3326, Loss: 2.2071436643600464, Final Batch Loss: 0.15592238306999207\n",
      "Epoch 3327, Loss: 3.300962507724762, Final Batch Loss: 1.3130414485931396\n",
      "Epoch 3328, Loss: 2.806705415248871, Final Batch Loss: 0.8783881068229675\n",
      "Epoch 3329, Loss: 2.3057129979133606, Final Batch Loss: 0.506816029548645\n",
      "Epoch 3330, Loss: 2.033275693655014, Final Batch Loss: 0.24758562445640564\n",
      "Epoch 3331, Loss: 2.961626887321472, Final Batch Loss: 1.1326943635940552\n",
      "Epoch 3332, Loss: 2.000541239976883, Final Batch Loss: 0.3070184886455536\n",
      "Epoch 3333, Loss: 2.089817062020302, Final Batch Loss: 0.23011259734630585\n",
      "Epoch 3334, Loss: 3.0517932772636414, Final Batch Loss: 0.9840491414070129\n",
      "Epoch 3335, Loss: 2.733092576265335, Final Batch Loss: 0.8818626403808594\n",
      "Epoch 3336, Loss: 2.2244628965854645, Final Batch Loss: 0.3227543234825134\n",
      "Epoch 3337, Loss: 2.198939800262451, Final Batch Loss: 0.478708952665329\n",
      "Epoch 3338, Loss: 2.49549064040184, Final Batch Loss: 0.6967641711235046\n",
      "Epoch 3339, Loss: 2.3671987652778625, Final Batch Loss: 0.5512523055076599\n",
      "Epoch 3340, Loss: 2.715166926383972, Final Batch Loss: 1.0885951519012451\n",
      "Epoch 3341, Loss: 1.9511565864086151, Final Batch Loss: 0.2270248830318451\n",
      "Epoch 3342, Loss: 2.0829752385616302, Final Batch Loss: 0.30970141291618347\n",
      "Epoch 3343, Loss: 2.3690631091594696, Final Batch Loss: 0.6011382937431335\n",
      "Epoch 3344, Loss: 2.32023024559021, Final Batch Loss: 0.4729926586151123\n",
      "Epoch 3345, Loss: 2.315756529569626, Final Batch Loss: 0.4377174377441406\n",
      "Epoch 3346, Loss: 2.4908449053764343, Final Batch Loss: 0.599606454372406\n",
      "Epoch 3347, Loss: 2.4902766346931458, Final Batch Loss: 0.7300300002098083\n",
      "Epoch 3348, Loss: 2.3114733397960663, Final Batch Loss: 0.3330360949039459\n",
      "Epoch 3349, Loss: 2.888152062892914, Final Batch Loss: 0.5189384818077087\n",
      "Epoch 3350, Loss: 2.7361848950386047, Final Batch Loss: 0.5179300904273987\n",
      "Epoch 3351, Loss: 2.8570423424243927, Final Batch Loss: 0.7724896669387817\n",
      "Epoch 3352, Loss: 2.4303309321403503, Final Batch Loss: 0.48004382848739624\n",
      "Epoch 3353, Loss: 2.1860066652297974, Final Batch Loss: 0.3143071234226227\n",
      "Epoch 3354, Loss: 2.4552724957466125, Final Batch Loss: 0.4455540180206299\n",
      "Epoch 3355, Loss: 2.534360498189926, Final Batch Loss: 0.5109168887138367\n",
      "Epoch 3356, Loss: 2.5667234659194946, Final Batch Loss: 0.5843167901039124\n",
      "Epoch 3357, Loss: 2.2995133996009827, Final Batch Loss: 0.4633811414241791\n",
      "Epoch 3358, Loss: 2.0791440308094025, Final Batch Loss: 0.23036623001098633\n",
      "Epoch 3359, Loss: 2.6071866154670715, Final Batch Loss: 0.7460542917251587\n",
      "Epoch 3360, Loss: 2.063499376177788, Final Batch Loss: 0.22740061581134796\n",
      "Epoch 3361, Loss: 2.0967723429203033, Final Batch Loss: 0.3077651858329773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3362, Loss: 2.256332904100418, Final Batch Loss: 0.3306756019592285\n",
      "Epoch 3363, Loss: 2.298678308725357, Final Batch Loss: 0.36126211285591125\n",
      "Epoch 3364, Loss: 2.144754081964493, Final Batch Loss: 0.3234695792198181\n",
      "Epoch 3365, Loss: 2.2309586703777313, Final Batch Loss: 0.46163439750671387\n",
      "Epoch 3366, Loss: 2.3854136168956757, Final Batch Loss: 0.5178834199905396\n",
      "Epoch 3367, Loss: 2.0595695078372955, Final Batch Loss: 0.31882476806640625\n",
      "Epoch 3368, Loss: 2.050745040178299, Final Batch Loss: 0.36282071471214294\n",
      "Epoch 3369, Loss: 2.8942647874355316, Final Batch Loss: 1.1754058599472046\n",
      "Epoch 3370, Loss: 2.510511040687561, Final Batch Loss: 0.6874803304672241\n",
      "Epoch 3371, Loss: 2.03316867351532, Final Batch Loss: 0.2653743028640747\n",
      "Epoch 3372, Loss: 1.9381449520587921, Final Batch Loss: 0.18486115336418152\n",
      "Epoch 3373, Loss: 2.5843292474746704, Final Batch Loss: 0.7649566531181335\n",
      "Epoch 3374, Loss: 1.9470258206129074, Final Batch Loss: 0.16679222881793976\n",
      "Epoch 3375, Loss: 2.3406976461410522, Final Batch Loss: 0.45032382011413574\n",
      "Epoch 3376, Loss: 2.3560779988765717, Final Batch Loss: 0.6097442507743835\n",
      "Epoch 3377, Loss: 2.7863809168338776, Final Batch Loss: 1.0557091236114502\n",
      "Epoch 3378, Loss: 2.0873288214206696, Final Batch Loss: 0.2994161546230316\n",
      "Epoch 3379, Loss: 2.065598279237747, Final Batch Loss: 0.3024654984474182\n",
      "Epoch 3380, Loss: 2.3276825547218323, Final Batch Loss: 0.3948959708213806\n",
      "Epoch 3381, Loss: 1.948330819606781, Final Batch Loss: 0.1759854257106781\n",
      "Epoch 3382, Loss: 2.417814403772354, Final Batch Loss: 0.623591959476471\n",
      "Epoch 3383, Loss: 2.060269683599472, Final Batch Loss: 0.2861185669898987\n",
      "Epoch 3384, Loss: 2.2646866142749786, Final Batch Loss: 0.46808648109436035\n",
      "Epoch 3385, Loss: 2.6328940093517303, Final Batch Loss: 0.6553053259849548\n",
      "Epoch 3386, Loss: 2.7785855531692505, Final Batch Loss: 1.0053802728652954\n",
      "Epoch 3387, Loss: 2.1591407656669617, Final Batch Loss: 0.22397351264953613\n",
      "Epoch 3388, Loss: 2.0699302405118942, Final Batch Loss: 0.13450108468532562\n",
      "Epoch 3389, Loss: 1.9642446637153625, Final Batch Loss: 0.1775740087032318\n",
      "Epoch 3390, Loss: 2.541883885860443, Final Batch Loss: 0.6337847709655762\n",
      "Epoch 3391, Loss: 2.536551207304001, Final Batch Loss: 0.586151123046875\n",
      "Epoch 3392, Loss: 2.481633633375168, Final Batch Loss: 0.6047027707099915\n",
      "Epoch 3393, Loss: 2.5734192430973053, Final Batch Loss: 0.8716406226158142\n",
      "Epoch 3394, Loss: 2.6240542232990265, Final Batch Loss: 0.8506736755371094\n",
      "Epoch 3395, Loss: 2.4021784961223602, Final Batch Loss: 0.5363153219223022\n",
      "Epoch 3396, Loss: 2.2761025428771973, Final Batch Loss: 0.42882129549980164\n",
      "Epoch 3397, Loss: 2.307089179754257, Final Batch Loss: 0.4387947916984558\n",
      "Epoch 3398, Loss: 2.1497134268283844, Final Batch Loss: 0.3887977600097656\n",
      "Epoch 3399, Loss: 2.213789790868759, Final Batch Loss: 0.4843900203704834\n",
      "Epoch 3400, Loss: 2.4919402301311493, Final Batch Loss: 0.5764913558959961\n",
      "Epoch 3401, Loss: 2.284548670053482, Final Batch Loss: 0.4144132137298584\n",
      "Epoch 3402, Loss: 2.314546138048172, Final Batch Loss: 0.45561423897743225\n",
      "Epoch 3403, Loss: 2.375223785638809, Final Batch Loss: 0.4275168776512146\n",
      "Epoch 3404, Loss: 2.2492440044879913, Final Batch Loss: 0.4244743883609772\n",
      "Epoch 3405, Loss: 2.67684543132782, Final Batch Loss: 0.9183560609817505\n",
      "Epoch 3406, Loss: 2.746551424264908, Final Batch Loss: 0.7015334367752075\n",
      "Epoch 3407, Loss: 2.083325758576393, Final Batch Loss: 0.18162252008914948\n",
      "Epoch 3408, Loss: 2.289558917284012, Final Batch Loss: 0.36351075768470764\n",
      "Epoch 3409, Loss: 2.381578743457794, Final Batch Loss: 0.43470853567123413\n",
      "Epoch 3410, Loss: 2.374260663986206, Final Batch Loss: 0.42669782042503357\n",
      "Epoch 3411, Loss: 2.6019040644168854, Final Batch Loss: 0.41610652208328247\n",
      "Epoch 3412, Loss: 2.830572187900543, Final Batch Loss: 0.9273257255554199\n",
      "Epoch 3413, Loss: 2.1083829402923584, Final Batch Loss: 0.24987781047821045\n",
      "Epoch 3414, Loss: 2.3392415940761566, Final Batch Loss: 0.4554004371166229\n",
      "Epoch 3415, Loss: 2.1292033791542053, Final Batch Loss: 0.2024441957473755\n",
      "Epoch 3416, Loss: 2.2717204093933105, Final Batch Loss: 0.348005086183548\n",
      "Epoch 3417, Loss: 2.4839709103107452, Final Batch Loss: 0.585734486579895\n",
      "Epoch 3418, Loss: 2.393539696931839, Final Batch Loss: 0.5919747352600098\n",
      "Epoch 3419, Loss: 2.865141361951828, Final Batch Loss: 0.8980833292007446\n",
      "Epoch 3420, Loss: 2.348430782556534, Final Batch Loss: 0.318147748708725\n",
      "Epoch 3421, Loss: 2.2551248371601105, Final Batch Loss: 0.1744842529296875\n",
      "Epoch 3422, Loss: 2.458056300878525, Final Batch Loss: 0.41873297095298767\n",
      "Epoch 3423, Loss: 2.428611844778061, Final Batch Loss: 0.3420744240283966\n",
      "Epoch 3424, Loss: 2.1697733998298645, Final Batch Loss: 0.19035080075263977\n",
      "Epoch 3425, Loss: 2.281546264886856, Final Batch Loss: 0.338209867477417\n",
      "Epoch 3426, Loss: 2.431455433368683, Final Batch Loss: 0.3909035325050354\n",
      "Epoch 3427, Loss: 1.9893075376749039, Final Batch Loss: 0.1763737052679062\n",
      "Epoch 3428, Loss: 2.5701454877853394, Final Batch Loss: 0.7112802863121033\n",
      "Epoch 3429, Loss: 2.689186990261078, Final Batch Loss: 0.7902716398239136\n",
      "Epoch 3430, Loss: 2.625987410545349, Final Batch Loss: 0.7185847163200378\n",
      "Epoch 3431, Loss: 2.1988212168216705, Final Batch Loss: 0.39418885111808777\n",
      "Epoch 3432, Loss: 2.441584438085556, Final Batch Loss: 0.5031550526618958\n",
      "Epoch 3433, Loss: 2.726275622844696, Final Batch Loss: 0.903926432132721\n",
      "Epoch 3434, Loss: 1.8910496979951859, Final Batch Loss: 0.1618039757013321\n",
      "Epoch 3435, Loss: 2.051561862230301, Final Batch Loss: 0.3192814886569977\n",
      "Epoch 3436, Loss: 2.348920464515686, Final Batch Loss: 0.47026345133781433\n",
      "Epoch 3437, Loss: 2.317742198705673, Final Batch Loss: 0.5714091658592224\n",
      "Epoch 3438, Loss: 2.1079463958740234, Final Batch Loss: 0.25164124369621277\n",
      "Epoch 3439, Loss: 2.002839595079422, Final Batch Loss: 0.23648831248283386\n",
      "Epoch 3440, Loss: 2.125670373439789, Final Batch Loss: 0.41987037658691406\n",
      "Epoch 3441, Loss: 2.7899199426174164, Final Batch Loss: 0.9074797034263611\n",
      "Epoch 3442, Loss: 1.994033306837082, Final Batch Loss: 0.3209594190120697\n",
      "Epoch 3443, Loss: 2.0656132996082306, Final Batch Loss: 0.34206318855285645\n",
      "Epoch 3444, Loss: 2.2542029917240143, Final Batch Loss: 0.39291903376579285\n",
      "Epoch 3445, Loss: 2.6135910749435425, Final Batch Loss: 0.6332424879074097\n",
      "Epoch 3446, Loss: 1.9955183118581772, Final Batch Loss: 0.24679069221019745\n",
      "Epoch 3447, Loss: 2.1553022265434265, Final Batch Loss: 0.3061155378818512\n",
      "Epoch 3448, Loss: 2.6901153326034546, Final Batch Loss: 0.8334080576896667\n",
      "Epoch 3449, Loss: 2.0615496188402176, Final Batch Loss: 0.1700267642736435\n",
      "Epoch 3450, Loss: 2.602946847677231, Final Batch Loss: 0.7665526270866394\n",
      "Epoch 3451, Loss: 2.1256465017795563, Final Batch Loss: 0.290280818939209\n",
      "Epoch 3452, Loss: 2.2796146869659424, Final Batch Loss: 0.3498307168483734\n",
      "Epoch 3453, Loss: 2.2040322721004486, Final Batch Loss: 0.3601367771625519\n",
      "Epoch 3454, Loss: 2.3368667364120483, Final Batch Loss: 0.6207351684570312\n",
      "Epoch 3455, Loss: 2.0735192000865936, Final Batch Loss: 0.36563840508461\n",
      "Epoch 3456, Loss: 1.915318638086319, Final Batch Loss: 0.22845116257667542\n",
      "Epoch 3457, Loss: 2.1047564148902893, Final Batch Loss: 0.47483426332473755\n",
      "Epoch 3458, Loss: 2.146016538143158, Final Batch Loss: 0.3864578306674957\n",
      "Epoch 3459, Loss: 2.384996384382248, Final Batch Loss: 0.6563011407852173\n",
      "Epoch 3460, Loss: 1.8786519393324852, Final Batch Loss: 0.119348905980587\n",
      "Epoch 3461, Loss: 1.9573370814323425, Final Batch Loss: 0.28339725732803345\n",
      "Epoch 3462, Loss: 2.652365505695343, Final Batch Loss: 0.782119631767273\n",
      "Epoch 3463, Loss: 2.471367299556732, Final Batch Loss: 0.6265138983726501\n",
      "Epoch 3464, Loss: 2.2566706836223602, Final Batch Loss: 0.44904497265815735\n",
      "Epoch 3465, Loss: 2.346993535757065, Final Batch Loss: 0.46179062128067017\n",
      "Epoch 3466, Loss: 2.123473644256592, Final Batch Loss: 0.32836851477622986\n",
      "Epoch 3467, Loss: 2.0318097174167633, Final Batch Loss: 0.29214221239089966\n",
      "Epoch 3468, Loss: 2.6845953464508057, Final Batch Loss: 0.8918991684913635\n",
      "Epoch 3469, Loss: 2.315045565366745, Final Batch Loss: 0.3985925614833832\n",
      "Epoch 3470, Loss: 2.0800883769989014, Final Batch Loss: 0.29615944623947144\n",
      "Epoch 3471, Loss: 2.2224245071411133, Final Batch Loss: 0.44266876578330994\n",
      "Epoch 3472, Loss: 2.2061717808246613, Final Batch Loss: 0.37693002820014954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3473, Loss: 2.249059706926346, Final Batch Loss: 0.3904211223125458\n",
      "Epoch 3474, Loss: 2.34451225399971, Final Batch Loss: 0.514064610004425\n",
      "Epoch 3475, Loss: 2.6173142194747925, Final Batch Loss: 0.7097097635269165\n",
      "Epoch 3476, Loss: 2.28193798661232, Final Batch Loss: 0.24581384658813477\n",
      "Epoch 3477, Loss: 2.195767343044281, Final Batch Loss: 0.2517586350440979\n",
      "Epoch 3478, Loss: 2.1937838196754456, Final Batch Loss: 0.45649319887161255\n",
      "Epoch 3479, Loss: 2.007022112607956, Final Batch Loss: 0.2657492160797119\n",
      "Epoch 3480, Loss: 2.8049988448619843, Final Batch Loss: 1.013637661933899\n",
      "Epoch 3481, Loss: 2.219303160905838, Final Batch Loss: 0.28999456763267517\n",
      "Epoch 3482, Loss: 2.318459302186966, Final Batch Loss: 0.4354874789714813\n",
      "Epoch 3483, Loss: 1.9920447915792465, Final Batch Loss: 0.21697752177715302\n",
      "Epoch 3484, Loss: 2.293437272310257, Final Batch Loss: 0.49612957239151\n",
      "Epoch 3485, Loss: 2.3213080167770386, Final Batch Loss: 0.7022647261619568\n",
      "Epoch 3486, Loss: 2.3554864525794983, Final Batch Loss: 0.47193512320518494\n",
      "Epoch 3487, Loss: 2.5505970120429993, Final Batch Loss: 0.7766542434692383\n",
      "Epoch 3488, Loss: 1.9971167147159576, Final Batch Loss: 0.16108575463294983\n",
      "Epoch 3489, Loss: 2.301103860139847, Final Batch Loss: 0.516614556312561\n",
      "Epoch 3490, Loss: 2.102483570575714, Final Batch Loss: 0.1434575617313385\n",
      "Epoch 3491, Loss: 2.062414199113846, Final Batch Loss: 0.2945994734764099\n",
      "Epoch 3492, Loss: 2.0798150300979614, Final Batch Loss: 0.30748844146728516\n",
      "Epoch 3493, Loss: 2.2039532363414764, Final Batch Loss: 0.43675848841667175\n",
      "Epoch 3494, Loss: 2.1044409573078156, Final Batch Loss: 0.38452592492103577\n",
      "Epoch 3495, Loss: 2.038463741540909, Final Batch Loss: 0.357793390750885\n",
      "Epoch 3496, Loss: 2.186046004295349, Final Batch Loss: 0.32982972264289856\n",
      "Epoch 3497, Loss: 2.234766036272049, Final Batch Loss: 0.45157358050346375\n",
      "Epoch 3498, Loss: 2.091830939054489, Final Batch Loss: 0.35996466875076294\n",
      "Epoch 3499, Loss: 2.336508572101593, Final Batch Loss: 0.3448452949523926\n",
      "Epoch 3500, Loss: 2.1380301415920258, Final Batch Loss: 0.3575833737850189\n",
      "Epoch 3501, Loss: 2.6123539805412292, Final Batch Loss: 0.8831009268760681\n",
      "Epoch 3502, Loss: 2.223265588283539, Final Batch Loss: 0.40666717290878296\n",
      "Epoch 3503, Loss: 2.53645983338356, Final Batch Loss: 0.6665247678756714\n",
      "Epoch 3504, Loss: 1.9016110450029373, Final Batch Loss: 0.14080210030078888\n",
      "Epoch 3505, Loss: 2.0330314934253693, Final Batch Loss: 0.3116285502910614\n",
      "Epoch 3506, Loss: 2.2468702495098114, Final Batch Loss: 0.45314353704452515\n",
      "Epoch 3507, Loss: 2.081054702401161, Final Batch Loss: 0.22655852138996124\n",
      "Epoch 3508, Loss: 2.049845814704895, Final Batch Loss: 0.20245647430419922\n",
      "Epoch 3509, Loss: 1.9844974279403687, Final Batch Loss: 0.2675643861293793\n",
      "Epoch 3510, Loss: 2.163372278213501, Final Batch Loss: 0.35328492522239685\n",
      "Epoch 3511, Loss: 2.2848833203315735, Final Batch Loss: 0.3434106707572937\n",
      "Epoch 3512, Loss: 1.9506256207823753, Final Batch Loss: 0.09589763730764389\n",
      "Epoch 3513, Loss: 2.046563684940338, Final Batch Loss: 0.29145368933677673\n",
      "Epoch 3514, Loss: 2.4645960330963135, Final Batch Loss: 0.6792903542518616\n",
      "Epoch 3515, Loss: 2.265272170305252, Final Batch Loss: 0.44458726048469543\n",
      "Epoch 3516, Loss: 2.368008077144623, Final Batch Loss: 0.5186627507209778\n",
      "Epoch 3517, Loss: 2.376662462949753, Final Batch Loss: 0.5804666876792908\n",
      "Epoch 3518, Loss: 2.694898635149002, Final Batch Loss: 0.7361146807670593\n",
      "Epoch 3519, Loss: 2.055147245526314, Final Batch Loss: 0.23671992123126984\n",
      "Epoch 3520, Loss: 2.2270455360412598, Final Batch Loss: 0.4072084426879883\n",
      "Epoch 3521, Loss: 2.061302661895752, Final Batch Loss: 0.30653366446495056\n",
      "Epoch 3522, Loss: 2.094960540533066, Final Batch Loss: 0.3384520709514618\n",
      "Epoch 3523, Loss: 2.09725421667099, Final Batch Loss: 0.3740417957305908\n",
      "Epoch 3524, Loss: 2.31893989443779, Final Batch Loss: 0.48109155893325806\n",
      "Epoch 3525, Loss: 2.39672189950943, Final Batch Loss: 0.6100685000419617\n",
      "Epoch 3526, Loss: 2.512960135936737, Final Batch Loss: 0.5316906571388245\n",
      "Epoch 3527, Loss: 2.2644134163856506, Final Batch Loss: 0.4108103811740875\n",
      "Epoch 3528, Loss: 2.399700850248337, Final Batch Loss: 0.6484102606773376\n",
      "Epoch 3529, Loss: 2.1938812732696533, Final Batch Loss: 0.30657896399497986\n",
      "Epoch 3530, Loss: 2.562317818403244, Final Batch Loss: 0.7456041574478149\n",
      "Epoch 3531, Loss: 2.627768814563751, Final Batch Loss: 0.8656357526779175\n",
      "Epoch 3532, Loss: 2.2129865884780884, Final Batch Loss: 0.31149744987487793\n",
      "Epoch 3533, Loss: 2.2104297876358032, Final Batch Loss: 0.3505273759365082\n",
      "Epoch 3534, Loss: 2.617214262485504, Final Batch Loss: 0.7771048545837402\n",
      "Epoch 3535, Loss: 2.483020067214966, Final Batch Loss: 0.6596546173095703\n",
      "Epoch 3536, Loss: 2.057085335254669, Final Batch Loss: 0.32411807775497437\n",
      "Epoch 3537, Loss: 2.4308101534843445, Final Batch Loss: 0.48974862694740295\n",
      "Epoch 3538, Loss: 2.258881688117981, Final Batch Loss: 0.328980952501297\n",
      "Epoch 3539, Loss: 2.4430387914180756, Final Batch Loss: 0.6165083050727844\n",
      "Epoch 3540, Loss: 2.357952296733856, Final Batch Loss: 0.6074333786964417\n",
      "Epoch 3541, Loss: 2.322658896446228, Final Batch Loss: 0.5197327733039856\n",
      "Epoch 3542, Loss: 2.2722000777721405, Final Batch Loss: 0.5144831538200378\n",
      "Epoch 3543, Loss: 2.2544227838516235, Final Batch Loss: 0.3911401331424713\n",
      "Epoch 3544, Loss: 1.9803782403469086, Final Batch Loss: 0.16562005877494812\n",
      "Epoch 3545, Loss: 2.3495165705680847, Final Batch Loss: 0.5175464749336243\n",
      "Epoch 3546, Loss: 2.1738200187683105, Final Batch Loss: 0.3956719934940338\n",
      "Epoch 3547, Loss: 2.1702151000499725, Final Batch Loss: 0.32497867941856384\n",
      "Epoch 3548, Loss: 2.3443032801151276, Final Batch Loss: 0.719481348991394\n",
      "Epoch 3549, Loss: 2.1471609473228455, Final Batch Loss: 0.2687053978443146\n",
      "Epoch 3550, Loss: 2.1562626361846924, Final Batch Loss: 0.3665914535522461\n",
      "Epoch 3551, Loss: 1.953739807009697, Final Batch Loss: 0.17655925452709198\n",
      "Epoch 3552, Loss: 2.2135381400585175, Final Batch Loss: 0.28218719363212585\n",
      "Epoch 3553, Loss: 2.067378520965576, Final Batch Loss: 0.3056562542915344\n",
      "Epoch 3554, Loss: 2.1617003679275513, Final Batch Loss: 0.42193058133125305\n",
      "Epoch 3555, Loss: 2.403710901737213, Final Batch Loss: 0.656906008720398\n",
      "Epoch 3556, Loss: 2.8723079562187195, Final Batch Loss: 0.9608935117721558\n",
      "Epoch 3557, Loss: 2.0361876785755157, Final Batch Loss: 0.3267931640148163\n",
      "Epoch 3558, Loss: 2.0593851506710052, Final Batch Loss: 0.400960236787796\n",
      "Epoch 3559, Loss: 2.3618387281894684, Final Batch Loss: 0.5924723744392395\n",
      "Epoch 3560, Loss: 2.597110003232956, Final Batch Loss: 0.8808466792106628\n",
      "Epoch 3561, Loss: 2.2916066348552704, Final Batch Loss: 0.45072171092033386\n",
      "Epoch 3562, Loss: 2.14193993806839, Final Batch Loss: 0.3527417778968811\n",
      "Epoch 3563, Loss: 2.3455404937267303, Final Batch Loss: 0.3997959494590759\n",
      "Epoch 3564, Loss: 2.116049975156784, Final Batch Loss: 0.35496827960014343\n",
      "Epoch 3565, Loss: 2.2455871403217316, Final Batch Loss: 0.4988672733306885\n",
      "Epoch 3566, Loss: 2.4867539405822754, Final Batch Loss: 0.7034367322921753\n",
      "Epoch 3567, Loss: 2.742838591337204, Final Batch Loss: 0.8356223702430725\n",
      "Epoch 3568, Loss: 2.0061516910791397, Final Batch Loss: 0.18020321428775787\n",
      "Epoch 3569, Loss: 2.377847969532013, Final Batch Loss: 0.6116107106208801\n",
      "Epoch 3570, Loss: 2.2150379419326782, Final Batch Loss: 0.5336319208145142\n",
      "Epoch 3571, Loss: 2.148055672645569, Final Batch Loss: 0.3769339621067047\n",
      "Epoch 3572, Loss: 2.0594788789749146, Final Batch Loss: 0.3027505874633789\n",
      "Epoch 3573, Loss: 1.9854563772678375, Final Batch Loss: 0.17938682436943054\n",
      "Epoch 3574, Loss: 1.9717991650104523, Final Batch Loss: 0.26691702008247375\n",
      "Epoch 3575, Loss: 2.407268136739731, Final Batch Loss: 0.7260228991508484\n",
      "Epoch 3576, Loss: 2.147046536207199, Final Batch Loss: 0.42535513639450073\n",
      "Epoch 3577, Loss: 1.930809646844864, Final Batch Loss: 0.18194320797920227\n",
      "Epoch 3578, Loss: 1.9405754655599594, Final Batch Loss: 0.23218365013599396\n",
      "Epoch 3579, Loss: 2.0016469061374664, Final Batch Loss: 0.2554602026939392\n",
      "Epoch 3580, Loss: 2.4593138992786407, Final Batch Loss: 0.6398496627807617\n",
      "Epoch 3581, Loss: 2.026022642850876, Final Batch Loss: 0.3953971266746521\n",
      "Epoch 3582, Loss: 2.2788599729537964, Final Batch Loss: 0.49883565306663513\n",
      "Epoch 3583, Loss: 1.92537060379982, Final Batch Loss: 0.21860453486442566\n",
      "Epoch 3584, Loss: 1.9906124770641327, Final Batch Loss: 0.27144312858581543\n",
      "Epoch 3585, Loss: 2.8588409423828125, Final Batch Loss: 1.1830103397369385\n",
      "Epoch 3586, Loss: 2.034167617559433, Final Batch Loss: 0.3693726062774658\n",
      "Epoch 3587, Loss: 2.2148660868406296, Final Batch Loss: 0.21721531450748444\n",
      "Epoch 3588, Loss: 2.2408776581287384, Final Batch Loss: 0.3891439139842987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3589, Loss: 2.06327223777771, Final Batch Loss: 0.413229376077652\n",
      "Epoch 3590, Loss: 2.214721292257309, Final Batch Loss: 0.3580973148345947\n",
      "Epoch 3591, Loss: 2.226833611726761, Final Batch Loss: 0.41032490134239197\n",
      "Epoch 3592, Loss: 2.0670333802700043, Final Batch Loss: 0.29153871536254883\n",
      "Epoch 3593, Loss: 2.3000711500644684, Final Batch Loss: 0.5196149945259094\n",
      "Epoch 3594, Loss: 2.734890937805176, Final Batch Loss: 0.8828632235527039\n",
      "Epoch 3595, Loss: 1.9799571931362152, Final Batch Loss: 0.21896842122077942\n",
      "Epoch 3596, Loss: 2.108865201473236, Final Batch Loss: 0.3666042983531952\n",
      "Epoch 3597, Loss: 2.083134353160858, Final Batch Loss: 0.4165908396244049\n",
      "Epoch 3598, Loss: 1.9858434200286865, Final Batch Loss: 0.2342069149017334\n",
      "Epoch 3599, Loss: 2.3638317584991455, Final Batch Loss: 0.536986768245697\n",
      "Epoch 3600, Loss: 2.124221831560135, Final Batch Loss: 0.4082467555999756\n",
      "Epoch 3601, Loss: 2.0129735618829727, Final Batch Loss: 0.2246636301279068\n",
      "Epoch 3602, Loss: 2.2239899337291718, Final Batch Loss: 0.2931976616382599\n",
      "Epoch 3603, Loss: 2.5417414605617523, Final Batch Loss: 0.779274582862854\n",
      "Epoch 3604, Loss: 2.245399594306946, Final Batch Loss: 0.6423377990722656\n",
      "Epoch 3605, Loss: 2.5600778460502625, Final Batch Loss: 0.8339254260063171\n",
      "Epoch 3606, Loss: 1.982665054500103, Final Batch Loss: 0.10635151714086533\n",
      "Epoch 3607, Loss: 2.1307790279388428, Final Batch Loss: 0.30864009261131287\n",
      "Epoch 3608, Loss: 2.1480690240859985, Final Batch Loss: 0.3623216152191162\n",
      "Epoch 3609, Loss: 2.0701074600219727, Final Batch Loss: 0.2695547640323639\n",
      "Epoch 3610, Loss: 2.00910347700119, Final Batch Loss: 0.3616940975189209\n",
      "Epoch 3611, Loss: 2.545373797416687, Final Batch Loss: 0.6777238249778748\n",
      "Epoch 3612, Loss: 2.305702656507492, Final Batch Loss: 0.4975707530975342\n",
      "Epoch 3613, Loss: 2.0731031000614166, Final Batch Loss: 0.3944067656993866\n",
      "Epoch 3614, Loss: 2.537566363811493, Final Batch Loss: 0.7326277494430542\n",
      "Epoch 3615, Loss: 2.182209700345993, Final Batch Loss: 0.3966120183467865\n",
      "Epoch 3616, Loss: 2.255566716194153, Final Batch Loss: 0.47101059556007385\n",
      "Epoch 3617, Loss: 2.407504290342331, Final Batch Loss: 0.508127748966217\n",
      "Epoch 3618, Loss: 2.083332270383835, Final Batch Loss: 0.3454051911830902\n",
      "Epoch 3619, Loss: 2.225554585456848, Final Batch Loss: 0.4092100262641907\n",
      "Epoch 3620, Loss: 2.0687389373779297, Final Batch Loss: 0.2850920855998993\n",
      "Epoch 3621, Loss: 2.457596242427826, Final Batch Loss: 0.7431396842002869\n",
      "Epoch 3622, Loss: 2.1659440994262695, Final Batch Loss: 0.4996929466724396\n",
      "Epoch 3623, Loss: 2.4246321618556976, Final Batch Loss: 0.5582738518714905\n",
      "Epoch 3624, Loss: 1.9595719575881958, Final Batch Loss: 0.21251940727233887\n",
      "Epoch 3625, Loss: 2.166358083486557, Final Batch Loss: 0.4276352524757385\n",
      "Epoch 3626, Loss: 2.0009476244449615, Final Batch Loss: 0.3599576950073242\n",
      "Epoch 3627, Loss: 2.3949877619743347, Final Batch Loss: 0.6480001211166382\n",
      "Epoch 3628, Loss: 2.8954689502716064, Final Batch Loss: 1.0558812618255615\n",
      "Epoch 3629, Loss: 2.0215565860271454, Final Batch Loss: 0.2887108623981476\n",
      "Epoch 3630, Loss: 1.95651113986969, Final Batch Loss: 0.3077157437801361\n",
      "Epoch 3631, Loss: 1.9711812883615494, Final Batch Loss: 0.24627484381198883\n",
      "Epoch 3632, Loss: 2.3298186361789703, Final Batch Loss: 0.5379483103752136\n",
      "Epoch 3633, Loss: 1.8547842651605606, Final Batch Loss: 0.21411831676959991\n",
      "Epoch 3634, Loss: 2.0973765552043915, Final Batch Loss: 0.2812122702598572\n",
      "Epoch 3635, Loss: 2.3513180911540985, Final Batch Loss: 0.6429362297058105\n",
      "Epoch 3636, Loss: 2.1909806430339813, Final Batch Loss: 0.33691146969795227\n",
      "Epoch 3637, Loss: 2.4262269735336304, Final Batch Loss: 0.6971468329429626\n",
      "Epoch 3638, Loss: 2.1836445033550262, Final Batch Loss: 0.38952818512916565\n",
      "Epoch 3639, Loss: 2.164450168609619, Final Batch Loss: 0.3069424629211426\n",
      "Epoch 3640, Loss: 1.9703836143016815, Final Batch Loss: 0.2664150893688202\n",
      "Epoch 3641, Loss: 2.09101602435112, Final Batch Loss: 0.3045329451560974\n",
      "Epoch 3642, Loss: 2.1456252336502075, Final Batch Loss: 0.26533856987953186\n",
      "Epoch 3643, Loss: 1.9166478663682938, Final Batch Loss: 0.13282038271427155\n",
      "Epoch 3644, Loss: 2.105068117380142, Final Batch Loss: 0.38877764344215393\n",
      "Epoch 3645, Loss: 2.415191262960434, Final Batch Loss: 0.6027815937995911\n",
      "Epoch 3646, Loss: 4.14281103014946, Final Batch Loss: 2.4270074367523193\n",
      "Epoch 3647, Loss: 2.2696451246738434, Final Batch Loss: 0.4805837571620941\n",
      "Epoch 3648, Loss: 2.21351757645607, Final Batch Loss: 0.5654157996177673\n",
      "Epoch 3649, Loss: 2.0524237528443336, Final Batch Loss: 0.10183728486299515\n",
      "Epoch 3650, Loss: 2.2019506990909576, Final Batch Loss: 0.4044335186481476\n",
      "Epoch 3651, Loss: 1.9346760958433151, Final Batch Loss: 0.20322446525096893\n",
      "Epoch 3652, Loss: 2.414147675037384, Final Batch Loss: 0.6506867408752441\n",
      "Epoch 3653, Loss: 2.2180537283420563, Final Batch Loss: 0.40857863426208496\n",
      "Epoch 3654, Loss: 2.278084307909012, Final Batch Loss: 0.43261241912841797\n",
      "Epoch 3655, Loss: 2.5395125448703766, Final Batch Loss: 0.8149141669273376\n",
      "Epoch 3656, Loss: 2.2553622126579285, Final Batch Loss: 0.5652522444725037\n",
      "Epoch 3657, Loss: 2.075987160205841, Final Batch Loss: 0.36535054445266724\n",
      "Epoch 3658, Loss: 2.175842732191086, Final Batch Loss: 0.38199129700660706\n",
      "Epoch 3659, Loss: 2.089146763086319, Final Batch Loss: 0.33531883358955383\n",
      "Epoch 3660, Loss: 2.250761955976486, Final Batch Loss: 0.4340377748012543\n",
      "Epoch 3661, Loss: 2.033126801252365, Final Batch Loss: 0.32424384355545044\n",
      "Epoch 3662, Loss: 2.264528661966324, Final Batch Loss: 0.5282017588615417\n",
      "Epoch 3663, Loss: 1.9509249329566956, Final Batch Loss: 0.3746013343334198\n",
      "Epoch 3664, Loss: 2.339691013097763, Final Batch Loss: 0.6777883172035217\n",
      "Epoch 3665, Loss: 2.0647267401218414, Final Batch Loss: 0.3546672463417053\n",
      "Epoch 3666, Loss: 2.0166279673576355, Final Batch Loss: 0.411758154630661\n",
      "Epoch 3667, Loss: 2.101503223180771, Final Batch Loss: 0.3439773619174957\n",
      "Epoch 3668, Loss: 2.023233562707901, Final Batch Loss: 0.38954028487205505\n",
      "Epoch 3669, Loss: 2.1712333261966705, Final Batch Loss: 0.43137630820274353\n",
      "Epoch 3670, Loss: 3.0669550597667694, Final Batch Loss: 1.2932507991790771\n",
      "Epoch 3671, Loss: 2.1339273750782013, Final Batch Loss: 0.2907932698726654\n",
      "Epoch 3672, Loss: 2.237847328186035, Final Batch Loss: 0.5166849493980408\n",
      "Epoch 3673, Loss: 2.462376981973648, Final Batch Loss: 0.6399309039115906\n",
      "Epoch 3674, Loss: 2.4671346247196198, Final Batch Loss: 0.7264552116394043\n",
      "Epoch 3675, Loss: 2.2119246125221252, Final Batch Loss: 0.518562376499176\n",
      "Epoch 3676, Loss: 1.922257199883461, Final Batch Loss: 0.22095899283885956\n",
      "Epoch 3677, Loss: 2.0375052094459534, Final Batch Loss: 0.23670890927314758\n",
      "Epoch 3678, Loss: 2.2243046164512634, Final Batch Loss: 0.4168507754802704\n",
      "Epoch 3679, Loss: 2.1882509291172028, Final Batch Loss: 0.3287675380706787\n",
      "Epoch 3680, Loss: 2.010103866457939, Final Batch Loss: 0.211426243185997\n",
      "Epoch 3681, Loss: 2.4159804582595825, Final Batch Loss: 0.6021119952201843\n",
      "Epoch 3682, Loss: 2.0528065860271454, Final Batch Loss: 0.37755224108695984\n",
      "Epoch 3683, Loss: 1.937620386481285, Final Batch Loss: 0.24018479883670807\n",
      "Epoch 3684, Loss: 2.0596406757831573, Final Batch Loss: 0.2788681089878082\n",
      "Epoch 3685, Loss: 1.8256015703082085, Final Batch Loss: 0.11185582727193832\n",
      "Epoch 3686, Loss: 2.324953466653824, Final Batch Loss: 0.6279234290122986\n",
      "Epoch 3687, Loss: 2.3429872393608093, Final Batch Loss: 0.5054457783699036\n",
      "Epoch 3688, Loss: 2.520223557949066, Final Batch Loss: 0.58637535572052\n",
      "Epoch 3689, Loss: 2.463106721639633, Final Batch Loss: 0.6985031962394714\n",
      "Epoch 3690, Loss: 1.879884660243988, Final Batch Loss: 0.25049856305122375\n",
      "Epoch 3691, Loss: 1.9177047461271286, Final Batch Loss: 0.1651441901922226\n",
      "Epoch 3692, Loss: 2.1026839315891266, Final Batch Loss: 0.39514827728271484\n",
      "Epoch 3693, Loss: 1.8229186981916428, Final Batch Loss: 0.16992969810962677\n",
      "Epoch 3694, Loss: 1.8463582172989845, Final Batch Loss: 0.11970365792512894\n",
      "Epoch 3695, Loss: 2.213643342256546, Final Batch Loss: 0.43391308188438416\n",
      "Epoch 3696, Loss: 2.370570123195648, Final Batch Loss: 0.5521209836006165\n",
      "Epoch 3697, Loss: 2.0995115637779236, Final Batch Loss: 0.23402127623558044\n",
      "Epoch 3698, Loss: 2.049298107624054, Final Batch Loss: 0.3458229601383209\n",
      "Epoch 3699, Loss: 2.2506528198719025, Final Batch Loss: 0.594066321849823\n",
      "Epoch 3700, Loss: 2.427885502576828, Final Batch Loss: 0.7133156061172485\n",
      "Epoch 3701, Loss: 2.1892338693141937, Final Batch Loss: 0.3260946571826935\n",
      "Epoch 3702, Loss: 2.261153131723404, Final Batch Loss: 0.47931474447250366\n",
      "Epoch 3703, Loss: 1.9434424489736557, Final Batch Loss: 0.12693189084529877\n",
      "Epoch 3704, Loss: 2.2951622307300568, Final Batch Loss: 0.4714950919151306\n",
      "Epoch 3705, Loss: 2.225187838077545, Final Batch Loss: 0.4451887905597687\n",
      "Epoch 3706, Loss: 2.3630312979221344, Final Batch Loss: 0.548911452293396\n",
      "Epoch 3707, Loss: 1.9440598785877228, Final Batch Loss: 0.25724342465400696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3708, Loss: 1.9567317515611649, Final Batch Loss: 0.23548711836338043\n",
      "Epoch 3709, Loss: 2.2285740971565247, Final Batch Loss: 0.36622995138168335\n",
      "Epoch 3710, Loss: 2.3279157876968384, Final Batch Loss: 0.548524796962738\n",
      "Epoch 3711, Loss: 1.9318258613348007, Final Batch Loss: 0.2129492312669754\n",
      "Epoch 3712, Loss: 2.1063026785850525, Final Batch Loss: 0.3456853926181793\n",
      "Epoch 3713, Loss: 2.1954641342163086, Final Batch Loss: 0.5200033783912659\n",
      "Epoch 3714, Loss: 2.910024583339691, Final Batch Loss: 1.0841926336288452\n",
      "Epoch 3715, Loss: 2.502486437559128, Final Batch Loss: 0.7958393692970276\n",
      "Epoch 3716, Loss: 2.0542365312576294, Final Batch Loss: 0.3561968505382538\n",
      "Epoch 3717, Loss: 2.2897236943244934, Final Batch Loss: 0.3545757830142975\n",
      "Epoch 3718, Loss: 2.2342012524604797, Final Batch Loss: 0.5443568825721741\n",
      "Epoch 3719, Loss: 2.3574215471744537, Final Batch Loss: 0.5759778022766113\n",
      "Epoch 3720, Loss: 2.0135313868522644, Final Batch Loss: 0.23923149704933167\n",
      "Epoch 3721, Loss: 2.2108685672283173, Final Batch Loss: 0.5746654868125916\n",
      "Epoch 3722, Loss: 2.1273680925369263, Final Batch Loss: 0.3782714903354645\n",
      "Epoch 3723, Loss: 1.9168186783790588, Final Batch Loss: 0.32868748903274536\n",
      "Epoch 3724, Loss: 1.9240496754646301, Final Batch Loss: 0.2463313341140747\n",
      "Epoch 3725, Loss: 2.0768268704414368, Final Batch Loss: 0.3236146867275238\n",
      "Epoch 3726, Loss: 2.4318665862083435, Final Batch Loss: 0.5243097543716431\n",
      "Epoch 3727, Loss: 2.2697746753692627, Final Batch Loss: 0.5375221371650696\n",
      "Epoch 3728, Loss: 2.0843091011047363, Final Batch Loss: 0.2707368731498718\n",
      "Epoch 3729, Loss: 2.1661630868911743, Final Batch Loss: 0.4186473488807678\n",
      "Epoch 3730, Loss: 2.343422770500183, Final Batch Loss: 0.6635491251945496\n",
      "Epoch 3731, Loss: 2.0358244702219963, Final Batch Loss: 0.0957607552409172\n",
      "Epoch 3732, Loss: 1.9753847420215607, Final Batch Loss: 0.2984175980091095\n",
      "Epoch 3733, Loss: 2.1257652044296265, Final Batch Loss: 0.36487630009651184\n",
      "Epoch 3734, Loss: 2.4187383949756622, Final Batch Loss: 0.5375927686691284\n",
      "Epoch 3735, Loss: 2.035657674074173, Final Batch Loss: 0.3525703549385071\n",
      "Epoch 3736, Loss: 1.84589122235775, Final Batch Loss: 0.22275884449481964\n",
      "Epoch 3737, Loss: 1.9140442162752151, Final Batch Loss: 0.1830119639635086\n",
      "Epoch 3738, Loss: 2.3897963762283325, Final Batch Loss: 0.5828045606613159\n",
      "Epoch 3739, Loss: 2.1668072640895844, Final Batch Loss: 0.4652896523475647\n",
      "Epoch 3740, Loss: 2.3241963386535645, Final Batch Loss: 0.5180824995040894\n",
      "Epoch 3741, Loss: 2.5160106420516968, Final Batch Loss: 0.595015823841095\n",
      "Epoch 3742, Loss: 1.98106050491333, Final Batch Loss: 0.2884860932826996\n",
      "Epoch 3743, Loss: 2.244088977575302, Final Batch Loss: 0.5271238088607788\n",
      "Epoch 3744, Loss: 2.4739683866500854, Final Batch Loss: 0.8004826307296753\n",
      "Epoch 3745, Loss: 2.0177590250968933, Final Batch Loss: 0.3716917335987091\n",
      "Epoch 3746, Loss: 2.397769421339035, Final Batch Loss: 0.4552934765815735\n",
      "Epoch 3747, Loss: 2.14298078417778, Final Batch Loss: 0.43997541069984436\n",
      "Epoch 3748, Loss: 2.232706516981125, Final Batch Loss: 0.3761318027973175\n",
      "Epoch 3749, Loss: 2.5431688129901886, Final Batch Loss: 0.8153771162033081\n",
      "Epoch 3750, Loss: 2.084645450115204, Final Batch Loss: 0.32574716210365295\n",
      "Epoch 3751, Loss: 1.9878591001033783, Final Batch Loss: 0.2996078133583069\n",
      "Epoch 3752, Loss: 2.0112182199954987, Final Batch Loss: 0.32576093077659607\n",
      "Epoch 3753, Loss: 2.3457190990448, Final Batch Loss: 0.5291000604629517\n",
      "Epoch 3754, Loss: 2.593856453895569, Final Batch Loss: 0.9135017395019531\n",
      "Epoch 3755, Loss: 1.9054172933101654, Final Batch Loss: 0.28073546290397644\n",
      "Epoch 3756, Loss: 1.8530557602643967, Final Batch Loss: 0.17133142054080963\n",
      "Epoch 3757, Loss: 2.184034913778305, Final Batch Loss: 0.4044143557548523\n",
      "Epoch 3758, Loss: 1.9865666776895523, Final Batch Loss: 0.24983088672161102\n",
      "Epoch 3759, Loss: 2.3269372284412384, Final Batch Loss: 0.553173303604126\n",
      "Epoch 3760, Loss: 2.283922016620636, Final Batch Loss: 0.5951887369155884\n",
      "Epoch 3761, Loss: 2.0323023796081543, Final Batch Loss: 0.2305281162261963\n",
      "Epoch 3762, Loss: 2.362083524465561, Final Batch Loss: 0.5094895362854004\n",
      "Epoch 3763, Loss: 2.0600351095199585, Final Batch Loss: 0.31808358430862427\n",
      "Epoch 3764, Loss: 2.2951272428035736, Final Batch Loss: 0.5551236867904663\n",
      "Epoch 3765, Loss: 2.2217149138450623, Final Batch Loss: 0.48631975054740906\n",
      "Epoch 3766, Loss: 2.5742250978946686, Final Batch Loss: 0.7527475953102112\n",
      "Epoch 3767, Loss: 2.134839177131653, Final Batch Loss: 0.44631314277648926\n",
      "Epoch 3768, Loss: 1.8805449903011322, Final Batch Loss: 0.16464665532112122\n",
      "Epoch 3769, Loss: 2.1954350769519806, Final Batch Loss: 0.31642913818359375\n",
      "Epoch 3770, Loss: 1.8611114472150803, Final Batch Loss: 0.18818049132823944\n",
      "Epoch 3771, Loss: 1.8782541304826736, Final Batch Loss: 0.224027618765831\n",
      "Epoch 3772, Loss: 1.9896741211414337, Final Batch Loss: 0.2661314606666565\n",
      "Epoch 3773, Loss: 1.927120953798294, Final Batch Loss: 0.32507190108299255\n",
      "Epoch 3774, Loss: 2.056103229522705, Final Batch Loss: 0.39066246151924133\n",
      "Epoch 3775, Loss: 2.3710331320762634, Final Batch Loss: 0.5027369260787964\n",
      "Epoch 3776, Loss: 1.8960746675729752, Final Batch Loss: 0.18752624094486237\n",
      "Epoch 3777, Loss: 2.137417823076248, Final Batch Loss: 0.31007423996925354\n",
      "Epoch 3778, Loss: 2.234732896089554, Final Batch Loss: 0.41138574481010437\n",
      "Epoch 3779, Loss: 2.4096128046512604, Final Batch Loss: 0.598398745059967\n",
      "Epoch 3780, Loss: 2.2228954434394836, Final Batch Loss: 0.3843158185482025\n",
      "Epoch 3781, Loss: 2.481457531452179, Final Batch Loss: 0.7092718482017517\n",
      "Epoch 3782, Loss: 2.266751855611801, Final Batch Loss: 0.49972179532051086\n",
      "Epoch 3783, Loss: 2.173056185245514, Final Batch Loss: 0.36571234464645386\n",
      "Epoch 3784, Loss: 1.989462286233902, Final Batch Loss: 0.3352053761482239\n",
      "Epoch 3785, Loss: 2.1557770520448685, Final Batch Loss: 0.24625520408153534\n",
      "Epoch 3786, Loss: 1.994829386472702, Final Batch Loss: 0.21820852160453796\n",
      "Epoch 3787, Loss: 2.071538671851158, Final Batch Loss: 0.2265065461397171\n",
      "Epoch 3788, Loss: 1.8890225291252136, Final Batch Loss: 0.2444765865802765\n",
      "Epoch 3789, Loss: 1.8259055763483047, Final Batch Loss: 0.14863871037960052\n",
      "Epoch 3790, Loss: 2.116733878850937, Final Batch Loss: 0.38250604271888733\n",
      "Epoch 3791, Loss: 2.245541572570801, Final Batch Loss: 0.3862648904323578\n",
      "Epoch 3792, Loss: 1.9126163348555565, Final Batch Loss: 0.1144985780119896\n",
      "Epoch 3793, Loss: 2.167587012052536, Final Batch Loss: 0.31159156560897827\n",
      "Epoch 3794, Loss: 2.2585262954235077, Final Batch Loss: 0.5718555450439453\n",
      "Epoch 3795, Loss: 2.1544069945812225, Final Batch Loss: 0.5266138315200806\n",
      "Epoch 3796, Loss: 1.996079683303833, Final Batch Loss: 0.2790862023830414\n",
      "Epoch 3797, Loss: 2.1907286643981934, Final Batch Loss: 0.5489511489868164\n",
      "Epoch 3798, Loss: 1.9678016006946564, Final Batch Loss: 0.15153896808624268\n",
      "Epoch 3799, Loss: 2.710413634777069, Final Batch Loss: 0.9368950724601746\n",
      "Epoch 3800, Loss: 2.318527400493622, Final Batch Loss: 0.5826819539070129\n",
      "Epoch 3801, Loss: 2.092072904109955, Final Batch Loss: 0.45070573687553406\n",
      "Epoch 3802, Loss: 2.1112945079803467, Final Batch Loss: 0.2833837568759918\n",
      "Epoch 3803, Loss: 2.10924369096756, Final Batch Loss: 0.4385688304901123\n",
      "Epoch 3804, Loss: 2.018697038292885, Final Batch Loss: 0.19201742112636566\n",
      "Epoch 3805, Loss: 2.4896274507045746, Final Batch Loss: 0.6855880618095398\n",
      "Epoch 3806, Loss: 2.093328893184662, Final Batch Loss: 0.4497620463371277\n",
      "Epoch 3807, Loss: 2.093382775783539, Final Batch Loss: 0.2881630063056946\n",
      "Epoch 3808, Loss: 2.3606692254543304, Final Batch Loss: 0.6951417326927185\n",
      "Epoch 3809, Loss: 2.0444163978099823, Final Batch Loss: 0.3012864887714386\n",
      "Epoch 3810, Loss: 2.2301381528377533, Final Batch Loss: 0.3952934741973877\n",
      "Epoch 3811, Loss: 2.0870845913887024, Final Batch Loss: 0.27555009722709656\n",
      "Epoch 3812, Loss: 3.2310052514076233, Final Batch Loss: 1.4675521850585938\n",
      "Epoch 3813, Loss: 1.9459754526615143, Final Batch Loss: 0.251430481672287\n",
      "Epoch 3814, Loss: 2.431710332632065, Final Batch Loss: 0.5398322939872742\n",
      "Epoch 3815, Loss: 2.311958819627762, Final Batch Loss: 0.6654202342033386\n",
      "Epoch 3816, Loss: 2.0088295340538025, Final Batch Loss: 0.3164644241333008\n",
      "Epoch 3817, Loss: 1.9902700185775757, Final Batch Loss: 0.18844640254974365\n",
      "Epoch 3818, Loss: 1.9942078441381454, Final Batch Loss: 0.22560225427150726\n",
      "Epoch 3819, Loss: 2.504245340824127, Final Batch Loss: 0.7913170456886292\n",
      "Epoch 3820, Loss: 2.371835708618164, Final Batch Loss: 0.6417475342750549\n",
      "Epoch 3821, Loss: 2.091337025165558, Final Batch Loss: 0.35132476687431335\n",
      "Epoch 3822, Loss: 2.1773889362812042, Final Batch Loss: 0.4680767357349396\n",
      "Epoch 3823, Loss: 2.179052084684372, Final Batch Loss: 0.5119501352310181\n",
      "Epoch 3824, Loss: 2.266848534345627, Final Batch Loss: 0.609161913394928\n",
      "Epoch 3825, Loss: 1.9844989776611328, Final Batch Loss: 0.27886271476745605\n",
      "Epoch 3826, Loss: 2.331486940383911, Final Batch Loss: 0.6240461468696594\n",
      "Epoch 3827, Loss: 2.3855954706668854, Final Batch Loss: 0.6929778456687927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3828, Loss: 2.6283363699913025, Final Batch Loss: 0.8186141848564148\n",
      "Epoch 3829, Loss: 1.9840206131339073, Final Batch Loss: 0.10174798220396042\n",
      "Epoch 3830, Loss: 2.7948631048202515, Final Batch Loss: 1.0133512020111084\n",
      "Epoch 3831, Loss: 2.2402539253234863, Final Batch Loss: 0.44959110021591187\n",
      "Epoch 3832, Loss: 2.1932594180107117, Final Batch Loss: 0.23553499579429626\n",
      "Epoch 3833, Loss: 2.3634080290794373, Final Batch Loss: 0.5900387763977051\n",
      "Epoch 3834, Loss: 1.9664436280727386, Final Batch Loss: 0.2901141345500946\n",
      "Epoch 3835, Loss: 2.230434477329254, Final Batch Loss: 0.5960785150527954\n",
      "Epoch 3836, Loss: 2.4710206985473633, Final Batch Loss: 0.8187945485115051\n",
      "Epoch 3837, Loss: 2.4560170471668243, Final Batch Loss: 0.6595436334609985\n",
      "Epoch 3838, Loss: 1.8916162848472595, Final Batch Loss: 0.18536648154258728\n",
      "Epoch 3839, Loss: 1.940772369503975, Final Batch Loss: 0.22499938309192657\n",
      "Epoch 3840, Loss: 2.1368715167045593, Final Batch Loss: 0.5165777802467346\n",
      "Epoch 3841, Loss: 2.17838454246521, Final Batch Loss: 0.39510560035705566\n",
      "Epoch 3842, Loss: 2.115969657897949, Final Batch Loss: 0.30112224817276\n",
      "Epoch 3843, Loss: 2.0202589333057404, Final Batch Loss: 0.28391361236572266\n",
      "Epoch 3844, Loss: 1.8781488724052906, Final Batch Loss: 0.04172717407345772\n",
      "Epoch 3845, Loss: 2.8387641310691833, Final Batch Loss: 0.87667316198349\n",
      "Epoch 3846, Loss: 2.5241691768169403, Final Batch Loss: 0.7728766202926636\n",
      "Epoch 3847, Loss: 2.255244731903076, Final Batch Loss: 0.42188769578933716\n",
      "Epoch 3848, Loss: 2.176426976919174, Final Batch Loss: 0.39094844460487366\n",
      "Epoch 3849, Loss: 2.2170235216617584, Final Batch Loss: 0.5210122466087341\n",
      "Epoch 3850, Loss: 2.210247576236725, Final Batch Loss: 0.3484325706958771\n",
      "Epoch 3851, Loss: 2.2681395411491394, Final Batch Loss: 0.49894970655441284\n",
      "Epoch 3852, Loss: 2.062723457813263, Final Batch Loss: 0.303867369890213\n",
      "Epoch 3853, Loss: 2.064867317676544, Final Batch Loss: 0.3025951683521271\n",
      "Epoch 3854, Loss: 2.1800352931022644, Final Batch Loss: 0.42890113592147827\n",
      "Epoch 3855, Loss: 2.0888188034296036, Final Batch Loss: 0.22146885097026825\n",
      "Epoch 3856, Loss: 2.187488168478012, Final Batch Loss: 0.4947236180305481\n",
      "Epoch 3857, Loss: 2.2618157863616943, Final Batch Loss: 0.45977118611335754\n",
      "Epoch 3858, Loss: 2.193865031003952, Final Batch Loss: 0.28850215673446655\n",
      "Epoch 3859, Loss: 2.337079554796219, Final Batch Loss: 0.34316226840019226\n",
      "Epoch 3860, Loss: 2.4599001705646515, Final Batch Loss: 0.6247671842575073\n",
      "Epoch 3861, Loss: 2.179554671049118, Final Batch Loss: 0.35794001817703247\n",
      "Epoch 3862, Loss: 2.2526758015155792, Final Batch Loss: 0.27279335260391235\n",
      "Epoch 3863, Loss: 1.9342314526438713, Final Batch Loss: 0.09845908731222153\n",
      "Epoch 3864, Loss: 2.173855811357498, Final Batch Loss: 0.43078920245170593\n",
      "Epoch 3865, Loss: 2.0972108840942383, Final Batch Loss: 0.3698479235172272\n",
      "Epoch 3866, Loss: 2.1889138519763947, Final Batch Loss: 0.3347788453102112\n",
      "Epoch 3867, Loss: 1.8007330931723118, Final Batch Loss: 0.05016351118683815\n",
      "Epoch 3868, Loss: 2.2359086871147156, Final Batch Loss: 0.34786278009414673\n",
      "Epoch 3869, Loss: 1.939360871911049, Final Batch Loss: 0.231988325715065\n",
      "Epoch 3870, Loss: 1.9152839854359627, Final Batch Loss: 0.11928645521402359\n",
      "Epoch 3871, Loss: 2.3423217236995697, Final Batch Loss: 0.5953237414360046\n",
      "Epoch 3872, Loss: 2.1691930890083313, Final Batch Loss: 0.3694498836994171\n",
      "Epoch 3873, Loss: 2.0661809146404266, Final Batch Loss: 0.3428865373134613\n",
      "Epoch 3874, Loss: 2.252936542034149, Final Batch Loss: 0.5318558216094971\n",
      "Epoch 3875, Loss: 2.0608295798301697, Final Batch Loss: 0.3403375744819641\n",
      "Epoch 3876, Loss: 2.3706535398960114, Final Batch Loss: 0.7066352963447571\n",
      "Epoch 3877, Loss: 2.036280393600464, Final Batch Loss: 0.22899129986763\n",
      "Epoch 3878, Loss: 2.0008150935173035, Final Batch Loss: 0.3094000220298767\n",
      "Epoch 3879, Loss: 1.8668899834156036, Final Batch Loss: 0.1514136791229248\n",
      "Epoch 3880, Loss: 2.3192009031772614, Final Batch Loss: 0.5679805874824524\n",
      "Epoch 3881, Loss: 1.95462766289711, Final Batch Loss: 0.2704940438270569\n",
      "Epoch 3882, Loss: 2.900488317012787, Final Batch Loss: 1.2168140411376953\n",
      "Epoch 3883, Loss: 2.126854747533798, Final Batch Loss: 0.30855950713157654\n",
      "Epoch 3884, Loss: 1.9659871459007263, Final Batch Loss: 0.3630464971065521\n",
      "Epoch 3885, Loss: 2.0090065002441406, Final Batch Loss: 0.2500297725200653\n",
      "Epoch 3886, Loss: 1.9737686961889267, Final Batch Loss: 0.2489459067583084\n",
      "Epoch 3887, Loss: 2.171944260597229, Final Batch Loss: 0.4044296145439148\n",
      "Epoch 3888, Loss: 2.0605292916297913, Final Batch Loss: 0.3845592141151428\n",
      "Epoch 3889, Loss: 2.2476555705070496, Final Batch Loss: 0.485168993473053\n",
      "Epoch 3890, Loss: 2.793944835662842, Final Batch Loss: 1.0127007961273193\n",
      "Epoch 3891, Loss: 2.298751473426819, Final Batch Loss: 0.47821569442749023\n",
      "Epoch 3892, Loss: 2.615160256624222, Final Batch Loss: 1.0424723625183105\n",
      "Epoch 3893, Loss: 2.198370635509491, Final Batch Loss: 0.5230768918991089\n",
      "Epoch 3894, Loss: 2.0866366028785706, Final Batch Loss: 0.2835668623447418\n",
      "Epoch 3895, Loss: 2.1715908646583557, Final Batch Loss: 0.3540341258049011\n",
      "Epoch 3896, Loss: 2.0319969952106476, Final Batch Loss: 0.25311073660850525\n",
      "Epoch 3897, Loss: 2.105647176504135, Final Batch Loss: 0.30216407775878906\n",
      "Epoch 3898, Loss: 2.158613830804825, Final Batch Loss: 0.37300294637680054\n",
      "Epoch 3899, Loss: 1.9788930118083954, Final Batch Loss: 0.23100361227989197\n",
      "Epoch 3900, Loss: 1.8391250520944595, Final Batch Loss: 0.1388794332742691\n",
      "Epoch 3901, Loss: 1.8721630424261093, Final Batch Loss: 0.13697771728038788\n",
      "Epoch 3902, Loss: 1.9735240787267685, Final Batch Loss: 0.22093994915485382\n",
      "Epoch 3903, Loss: 2.0630415976047516, Final Batch Loss: 0.2663026452064514\n",
      "Epoch 3904, Loss: 2.7772580087184906, Final Batch Loss: 1.0607138872146606\n",
      "Epoch 3905, Loss: 2.2154753506183624, Final Batch Loss: 0.46730294823646545\n",
      "Epoch 3906, Loss: 2.16689333319664, Final Batch Loss: 0.5376287698745728\n",
      "Epoch 3907, Loss: 2.119520217180252, Final Batch Loss: 0.4279935956001282\n",
      "Epoch 3908, Loss: 2.3066595792770386, Final Batch Loss: 0.6607275605201721\n",
      "Epoch 3909, Loss: 2.0824005901813507, Final Batch Loss: 0.2527182102203369\n",
      "Epoch 3910, Loss: 2.57589653134346, Final Batch Loss: 0.6793791055679321\n",
      "Epoch 3911, Loss: 2.078866183757782, Final Batch Loss: 0.26018673181533813\n",
      "Epoch 3912, Loss: 2.2565234303474426, Final Batch Loss: 0.3708019256591797\n",
      "Epoch 3913, Loss: 2.492310255765915, Final Batch Loss: 0.5817813873291016\n",
      "Epoch 3914, Loss: 2.6066976189613342, Final Batch Loss: 0.7235411405563354\n",
      "Epoch 3915, Loss: 2.012647122144699, Final Batch Loss: 0.15613803267478943\n",
      "Epoch 3916, Loss: 2.1962299942970276, Final Batch Loss: 0.3135210871696472\n",
      "Epoch 3917, Loss: 2.3834157288074493, Final Batch Loss: 0.6957052946090698\n",
      "Epoch 3918, Loss: 2.0764890909194946, Final Batch Loss: 0.3170982897281647\n",
      "Epoch 3919, Loss: 2.0669097900390625, Final Batch Loss: 0.43976855278015137\n",
      "Epoch 3920, Loss: 2.0923467576503754, Final Batch Loss: 0.31650510430336\n",
      "Epoch 3921, Loss: 1.9494235813617706, Final Batch Loss: 0.26867741346359253\n",
      "Epoch 3922, Loss: 1.9151867628097534, Final Batch Loss: 0.16269353032112122\n",
      "Epoch 3923, Loss: 1.803801704198122, Final Batch Loss: 0.05083640292286873\n",
      "Epoch 3924, Loss: 2.040751874446869, Final Batch Loss: 0.3108680844306946\n",
      "Epoch 3925, Loss: 2.4894725680351257, Final Batch Loss: 0.7965379953384399\n",
      "Epoch 3926, Loss: 2.0351392179727554, Final Batch Loss: 0.22722233831882477\n",
      "Epoch 3927, Loss: 2.5076098442077637, Final Batch Loss: 0.7733973264694214\n",
      "Epoch 3928, Loss: 1.866875797510147, Final Batch Loss: 0.25353991985321045\n",
      "Epoch 3929, Loss: 2.294155389070511, Final Batch Loss: 0.6153309941291809\n",
      "Epoch 3930, Loss: 2.458345204591751, Final Batch Loss: 0.6517354846000671\n",
      "Epoch 3931, Loss: 2.1516707241535187, Final Batch Loss: 0.3934411406517029\n",
      "Epoch 3932, Loss: 2.015812009572983, Final Batch Loss: 0.29629191756248474\n",
      "Epoch 3933, Loss: 2.3767570853233337, Final Batch Loss: 0.6534305214881897\n",
      "Epoch 3934, Loss: 2.247452884912491, Final Batch Loss: 0.6357194781303406\n",
      "Epoch 3935, Loss: 1.873383566737175, Final Batch Loss: 0.2280251830816269\n",
      "Epoch 3936, Loss: 2.5343047380447388, Final Batch Loss: 0.6601585745811462\n",
      "Epoch 3937, Loss: 2.0565679371356964, Final Batch Loss: 0.26647448539733887\n",
      "Epoch 3938, Loss: 2.1275770366191864, Final Batch Loss: 0.2776118814945221\n",
      "Epoch 3939, Loss: 2.298257976770401, Final Batch Loss: 0.5546335577964783\n",
      "Epoch 3940, Loss: 2.0501473248004913, Final Batch Loss: 0.27714642882347107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3941, Loss: 2.3466565907001495, Final Batch Loss: 0.7215143442153931\n",
      "Epoch 3942, Loss: 2.0379728227853775, Final Batch Loss: 0.22779320180416107\n",
      "Epoch 3943, Loss: 2.0282351821660995, Final Batch Loss: 0.1520131677389145\n",
      "Epoch 3944, Loss: 2.0268968641757965, Final Batch Loss: 0.33863165974617004\n",
      "Epoch 3945, Loss: 2.1198936700820923, Final Batch Loss: 0.5127567648887634\n",
      "Epoch 3946, Loss: 1.9656158983707428, Final Batch Loss: 0.2838478684425354\n",
      "Epoch 3947, Loss: 2.0543408542871475, Final Batch Loss: 0.19029439985752106\n",
      "Epoch 3948, Loss: 2.084034711122513, Final Batch Loss: 0.36690670251846313\n",
      "Epoch 3949, Loss: 1.7944587022066116, Final Batch Loss: 0.22339509427547455\n",
      "Epoch 3950, Loss: 2.3768360912799835, Final Batch Loss: 0.5677613019943237\n",
      "Epoch 3951, Loss: 2.019295245409012, Final Batch Loss: 0.4829099774360657\n",
      "Epoch 3952, Loss: 2.0837909877300262, Final Batch Loss: 0.3416723310947418\n",
      "Epoch 3953, Loss: 2.149747133255005, Final Batch Loss: 0.5911517143249512\n",
      "Epoch 3954, Loss: 2.345593899488449, Final Batch Loss: 0.7109966278076172\n",
      "Epoch 3955, Loss: 2.290637195110321, Final Batch Loss: 0.59097820520401\n",
      "Epoch 3956, Loss: 2.274874210357666, Final Batch Loss: 0.46685782074928284\n",
      "Epoch 3957, Loss: 1.8661224246025085, Final Batch Loss: 0.26456230878829956\n",
      "Epoch 3958, Loss: 2.1484617590904236, Final Batch Loss: 0.39007726311683655\n",
      "Epoch 3959, Loss: 2.0223821103572845, Final Batch Loss: 0.40486541390419006\n",
      "Epoch 3960, Loss: 2.4995226860046387, Final Batch Loss: 0.7416813969612122\n",
      "Epoch 3961, Loss: 2.13898703455925, Final Batch Loss: 0.3510316014289856\n",
      "Epoch 3962, Loss: 2.453011989593506, Final Batch Loss: 0.7327267527580261\n",
      "Epoch 3963, Loss: 1.976330727338791, Final Batch Loss: 0.2967185378074646\n",
      "Epoch 3964, Loss: 2.09319606423378, Final Batch Loss: 0.26620370149612427\n",
      "Epoch 3965, Loss: 2.4683369994163513, Final Batch Loss: 0.7016077637672424\n",
      "Epoch 3966, Loss: 1.86185784637928, Final Batch Loss: 0.18955688178539276\n",
      "Epoch 3967, Loss: 2.4256632924079895, Final Batch Loss: 0.4984522759914398\n",
      "Epoch 3968, Loss: 1.996725469827652, Final Batch Loss: 0.1922164261341095\n",
      "Epoch 3969, Loss: 2.383846163749695, Final Batch Loss: 0.5503674745559692\n",
      "Epoch 3970, Loss: 2.087687909603119, Final Batch Loss: 0.38265472650527954\n",
      "Epoch 3971, Loss: 2.1388765275478363, Final Batch Loss: 0.3626032769680023\n",
      "Epoch 3972, Loss: 2.2043055593967438, Final Batch Loss: 0.5055018663406372\n",
      "Epoch 3973, Loss: 2.2850878834724426, Final Batch Loss: 0.5967922806739807\n",
      "Epoch 3974, Loss: 1.8387185037136078, Final Batch Loss: 0.2380279004573822\n",
      "Epoch 3975, Loss: 2.380153387784958, Final Batch Loss: 0.6680101752281189\n",
      "Epoch 3976, Loss: 2.1572616696357727, Final Batch Loss: 0.30205124616622925\n",
      "Epoch 3977, Loss: 1.9384646564722061, Final Batch Loss: 0.17992420494556427\n",
      "Epoch 3978, Loss: 2.069995403289795, Final Batch Loss: 0.39187219738960266\n",
      "Epoch 3979, Loss: 2.0377146005630493, Final Batch Loss: 0.26960232853889465\n",
      "Epoch 3980, Loss: 2.844339519739151, Final Batch Loss: 1.2100393772125244\n",
      "Epoch 3981, Loss: 2.015808552503586, Final Batch Loss: 0.33234167098999023\n",
      "Epoch 3982, Loss: 2.3504673838615417, Final Batch Loss: 0.5155915021896362\n",
      "Epoch 3983, Loss: 2.04617840051651, Final Batch Loss: 0.25787779688835144\n",
      "Epoch 3984, Loss: 2.105232149362564, Final Batch Loss: 0.35165876150131226\n",
      "Epoch 3985, Loss: 2.1035643219947815, Final Batch Loss: 0.372432678937912\n",
      "Epoch 3986, Loss: 2.0812031030654907, Final Batch Loss: 0.3962130546569824\n",
      "Epoch 3987, Loss: 1.9819493889808655, Final Batch Loss: 0.2519131302833557\n",
      "Epoch 3988, Loss: 2.136316955089569, Final Batch Loss: 0.4416493773460388\n",
      "Epoch 3989, Loss: 2.1479239463806152, Final Batch Loss: 0.43344855308532715\n",
      "Epoch 3990, Loss: 2.1741314232349396, Final Batch Loss: 0.4058041572570801\n",
      "Epoch 3991, Loss: 2.2713010609149933, Final Batch Loss: 0.6226383447647095\n",
      "Epoch 3992, Loss: 1.9476770907640457, Final Batch Loss: 0.24235813319683075\n",
      "Epoch 3993, Loss: 2.2158605754375458, Final Batch Loss: 0.36887282133102417\n",
      "Epoch 3994, Loss: 2.0507753044366837, Final Batch Loss: 0.19028536975383759\n",
      "Epoch 3995, Loss: 2.054990530014038, Final Batch Loss: 0.31930801272392273\n",
      "Epoch 3996, Loss: 1.865849032998085, Final Batch Loss: 0.14891906082630157\n",
      "Epoch 3997, Loss: 1.8519016653299332, Final Batch Loss: 0.243496373295784\n",
      "Epoch 3998, Loss: 2.4691316187381744, Final Batch Loss: 0.6943779587745667\n",
      "Epoch 3999, Loss: 1.8331353329122066, Final Batch Loss: 0.050605352967977524\n",
      "Epoch 4000, Loss: 1.9624844789505005, Final Batch Loss: 0.252430260181427\n",
      "Epoch 4001, Loss: 1.9773660600185394, Final Batch Loss: 0.2705186903476715\n",
      "Epoch 4002, Loss: 2.2950653731822968, Final Batch Loss: 0.5169292688369751\n",
      "Epoch 4003, Loss: 1.964808389544487, Final Batch Loss: 0.18962730467319489\n",
      "Epoch 4004, Loss: 1.815657153725624, Final Batch Loss: 0.162506565451622\n",
      "Epoch 4005, Loss: 1.8606042861938477, Final Batch Loss: 0.1534193754196167\n",
      "Epoch 4006, Loss: 2.0944298803806305, Final Batch Loss: 0.40057530999183655\n",
      "Epoch 4007, Loss: 1.921062871813774, Final Batch Loss: 0.19137738645076752\n",
      "Epoch 4008, Loss: 1.9438623785972595, Final Batch Loss: 0.15219882130622864\n",
      "Epoch 4009, Loss: 1.7582975178956985, Final Batch Loss: 0.17988650500774384\n",
      "Epoch 4010, Loss: 2.077210694551468, Final Batch Loss: 0.38777559995651245\n",
      "Epoch 4011, Loss: 1.9678956270217896, Final Batch Loss: 0.30449870228767395\n",
      "Epoch 4012, Loss: 2.0693719387054443, Final Batch Loss: 0.3681468069553375\n",
      "Epoch 4013, Loss: 2.023617744445801, Final Batch Loss: 0.3616267740726471\n",
      "Epoch 4014, Loss: 1.7034621685743332, Final Batch Loss: 0.09089545905590057\n",
      "Epoch 4015, Loss: 2.10496985912323, Final Batch Loss: 0.4438355267047882\n",
      "Epoch 4016, Loss: 2.1429280042648315, Final Batch Loss: 0.3920963704586029\n",
      "Epoch 4017, Loss: 2.3840362429618835, Final Batch Loss: 0.8583139181137085\n",
      "Epoch 4018, Loss: 2.2175084054470062, Final Batch Loss: 0.43302011489868164\n",
      "Epoch 4019, Loss: 2.2352612912654877, Final Batch Loss: 0.43543341755867004\n",
      "Epoch 4020, Loss: 2.3271996080875397, Final Batch Loss: 0.6958779096603394\n",
      "Epoch 4021, Loss: 2.1294509768486023, Final Batch Loss: 0.38240736722946167\n",
      "Epoch 4022, Loss: 2.1727438271045685, Final Batch Loss: 0.38154906034469604\n",
      "Epoch 4023, Loss: 1.7406278774142265, Final Batch Loss: 0.0957346186041832\n",
      "Epoch 4024, Loss: 1.8678454160690308, Final Batch Loss: 0.28864341974258423\n",
      "Epoch 4025, Loss: 2.0808355510234833, Final Batch Loss: 0.4249671995639801\n",
      "Epoch 4026, Loss: 2.830837845802307, Final Batch Loss: 1.2144194841384888\n",
      "Epoch 4027, Loss: 2.235919088125229, Final Batch Loss: 0.42472508549690247\n",
      "Epoch 4028, Loss: 2.08492574095726, Final Batch Loss: 0.4348287284374237\n",
      "Epoch 4029, Loss: 2.335170179605484, Final Batch Loss: 0.6338306665420532\n",
      "Epoch 4030, Loss: 2.0476135909557343, Final Batch Loss: 0.35871362686157227\n",
      "Epoch 4031, Loss: 2.7069373726844788, Final Batch Loss: 0.835483968257904\n",
      "Epoch 4032, Loss: 2.038268268108368, Final Batch Loss: 0.3530004322528839\n",
      "Epoch 4033, Loss: 2.2631610929965973, Final Batch Loss: 0.6220690011978149\n",
      "Epoch 4034, Loss: 2.960974246263504, Final Batch Loss: 1.1230237483978271\n",
      "Epoch 4035, Loss: 2.412002354860306, Final Batch Loss: 0.6333723068237305\n",
      "Epoch 4036, Loss: 2.4965211153030396, Final Batch Loss: 0.7834573984146118\n",
      "Epoch 4037, Loss: 2.286303550004959, Final Batch Loss: 0.4012160301208496\n",
      "Epoch 4038, Loss: 2.1451760828495026, Final Batch Loss: 0.27699458599090576\n",
      "Epoch 4039, Loss: 2.224716305732727, Final Batch Loss: 0.3589155077934265\n",
      "Epoch 4040, Loss: 2.0952121913433075, Final Batch Loss: 0.4118528664112091\n",
      "Epoch 4041, Loss: 1.8148620873689651, Final Batch Loss: 0.12279339134693146\n",
      "Epoch 4042, Loss: 2.0139635652303696, Final Batch Loss: 0.2382085770368576\n",
      "Epoch 4043, Loss: 2.3463065922260284, Final Batch Loss: 0.7583624720573425\n",
      "Epoch 4044, Loss: 2.020130544900894, Final Batch Loss: 0.3243987560272217\n",
      "Epoch 4045, Loss: 2.100826323032379, Final Batch Loss: 0.4480176270008087\n",
      "Epoch 4046, Loss: 2.369347631931305, Final Batch Loss: 0.637140691280365\n",
      "Epoch 4047, Loss: 2.1621721982955933, Final Batch Loss: 0.3861328959465027\n",
      "Epoch 4048, Loss: 2.217511296272278, Final Batch Loss: 0.38453546166419983\n",
      "Epoch 4049, Loss: 1.9862447679042816, Final Batch Loss: 0.20575401186943054\n",
      "Epoch 4050, Loss: 2.091171056032181, Final Batch Loss: 0.4375964105129242\n",
      "Epoch 4051, Loss: 2.002399295568466, Final Batch Loss: 0.3328140377998352\n",
      "Epoch 4052, Loss: 2.2698846757411957, Final Batch Loss: 0.4900978207588196\n",
      "Epoch 4053, Loss: 2.188195824623108, Final Batch Loss: 0.35257166624069214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4054, Loss: 2.061814397573471, Final Batch Loss: 0.459058940410614\n",
      "Epoch 4055, Loss: 1.9308623969554901, Final Batch Loss: 0.1959318220615387\n",
      "Epoch 4056, Loss: 2.3156551122665405, Final Batch Loss: 0.605562686920166\n",
      "Epoch 4057, Loss: 2.0674036741256714, Final Batch Loss: 0.19652214646339417\n",
      "Epoch 4058, Loss: 2.2911343574523926, Final Batch Loss: 0.5179687142372131\n",
      "Epoch 4059, Loss: 1.9782643914222717, Final Batch Loss: 0.3420809209346771\n",
      "Epoch 4060, Loss: 2.1507119238376617, Final Batch Loss: 0.5797367691993713\n",
      "Epoch 4061, Loss: 2.1474732756614685, Final Batch Loss: 0.576198399066925\n",
      "Epoch 4062, Loss: 2.1752853989601135, Final Batch Loss: 0.4820074737071991\n",
      "Epoch 4063, Loss: 2.499788373708725, Final Batch Loss: 0.7287517189979553\n",
      "Epoch 4064, Loss: 2.0422382056713104, Final Batch Loss: 0.4231744408607483\n",
      "Epoch 4065, Loss: 1.8233460038900375, Final Batch Loss: 0.18907324969768524\n",
      "Epoch 4066, Loss: 2.0389272570610046, Final Batch Loss: 0.25660261511802673\n",
      "Epoch 4067, Loss: 1.876595214009285, Final Batch Loss: 0.24252553284168243\n",
      "Epoch 4068, Loss: 2.336823344230652, Final Batch Loss: 0.6418535113334656\n",
      "Epoch 4069, Loss: 2.1862156689167023, Final Batch Loss: 0.3891434669494629\n",
      "Epoch 4070, Loss: 1.8933667540550232, Final Batch Loss: 0.22405877709388733\n",
      "Epoch 4071, Loss: 1.9595001488924026, Final Batch Loss: 0.19386480748653412\n",
      "Epoch 4072, Loss: 2.0584970116615295, Final Batch Loss: 0.2091597318649292\n",
      "Epoch 4073, Loss: 1.9495906084775925, Final Batch Loss: 0.178316131234169\n",
      "Epoch 4074, Loss: 2.1054106056690216, Final Batch Loss: 0.5339128375053406\n",
      "Epoch 4075, Loss: 1.9477274119853973, Final Batch Loss: 0.3482758104801178\n",
      "Epoch 4076, Loss: 2.170294016599655, Final Batch Loss: 0.475711852312088\n",
      "Epoch 4077, Loss: 2.3755988776683807, Final Batch Loss: 0.6497079730033875\n",
      "Epoch 4078, Loss: 1.8345269411802292, Final Batch Loss: 0.21807129681110382\n",
      "Epoch 4079, Loss: 1.9086046516895294, Final Batch Loss: 0.25149014592170715\n",
      "Epoch 4080, Loss: 2.2090868949890137, Final Batch Loss: 0.49185115098953247\n",
      "Epoch 4081, Loss: 2.201070547103882, Final Batch Loss: 0.4699077904224396\n",
      "Epoch 4082, Loss: 2.2845068275928497, Final Batch Loss: 0.5235080718994141\n",
      "Epoch 4083, Loss: 1.9506841897964478, Final Batch Loss: 0.30950430035591125\n",
      "Epoch 4084, Loss: 1.9165227450430393, Final Batch Loss: 0.056876424700021744\n",
      "Epoch 4085, Loss: 2.5890208780765533, Final Batch Loss: 0.8467740416526794\n",
      "Epoch 4086, Loss: 1.8991489112377167, Final Batch Loss: 0.18130430579185486\n",
      "Epoch 4087, Loss: 2.275503784418106, Final Batch Loss: 0.47702160477638245\n",
      "Epoch 4088, Loss: 2.132657304406166, Final Batch Loss: 0.23075823485851288\n",
      "Epoch 4089, Loss: 1.790981687605381, Final Batch Loss: 0.0886482372879982\n",
      "Epoch 4090, Loss: 2.498251587152481, Final Batch Loss: 0.5452274084091187\n",
      "Epoch 4091, Loss: 2.1014779210090637, Final Batch Loss: 0.422707736492157\n",
      "Epoch 4092, Loss: 2.3635251224040985, Final Batch Loss: 0.8275595903396606\n",
      "Epoch 4093, Loss: 2.2930886447429657, Final Batch Loss: 0.5677831172943115\n",
      "Epoch 4094, Loss: 2.1654172092676163, Final Batch Loss: 0.2475067526102066\n",
      "Epoch 4095, Loss: 2.2810428142547607, Final Batch Loss: 0.7369843125343323\n",
      "Epoch 4096, Loss: 1.93241648375988, Final Batch Loss: 0.2266719788312912\n",
      "Epoch 4097, Loss: 2.0269192159175873, Final Batch Loss: 0.25839558243751526\n",
      "Epoch 4098, Loss: 2.156363785266876, Final Batch Loss: 0.38841351866722107\n",
      "Epoch 4099, Loss: 2.429250121116638, Final Batch Loss: 0.6783482432365417\n",
      "Epoch 4100, Loss: 2.0238498747348785, Final Batch Loss: 0.40648674964904785\n",
      "Epoch 4101, Loss: 1.9929167032241821, Final Batch Loss: 0.1991543471813202\n",
      "Epoch 4102, Loss: 2.068803131580353, Final Batch Loss: 0.46994420886039734\n",
      "Epoch 4103, Loss: 2.3309153020381927, Final Batch Loss: 0.5907577276229858\n",
      "Epoch 4104, Loss: 1.6846379339694977, Final Batch Loss: 0.18886682391166687\n",
      "Epoch 4105, Loss: 1.9467282444238663, Final Batch Loss: 0.2348947674036026\n",
      "Epoch 4106, Loss: 2.371714562177658, Final Batch Loss: 0.7078909277915955\n",
      "Epoch 4107, Loss: 2.117699056863785, Final Batch Loss: 0.47133103013038635\n",
      "Epoch 4108, Loss: 1.9588091373443604, Final Batch Loss: 0.29421859979629517\n",
      "Epoch 4109, Loss: 2.034433588385582, Final Batch Loss: 0.17058371007442474\n",
      "Epoch 4110, Loss: 1.99107426404953, Final Batch Loss: 0.23828449845314026\n",
      "Epoch 4111, Loss: 1.7664488777518272, Final Batch Loss: 0.09741675108671188\n",
      "Epoch 4112, Loss: 1.9669494479894638, Final Batch Loss: 0.21275560557842255\n",
      "Epoch 4113, Loss: 1.9968156069517136, Final Batch Loss: 0.20303015410900116\n",
      "Epoch 4114, Loss: 2.558591991662979, Final Batch Loss: 0.7870545387268066\n",
      "Epoch 4115, Loss: 2.0224579870700836, Final Batch Loss: 0.4910828471183777\n",
      "Epoch 4116, Loss: 1.816214181482792, Final Batch Loss: 0.09252060204744339\n",
      "Epoch 4117, Loss: 2.405935049057007, Final Batch Loss: 0.6466688513755798\n",
      "Epoch 4118, Loss: 2.2278588116168976, Final Batch Loss: 0.3301941752433777\n",
      "Epoch 4119, Loss: 2.364076167345047, Final Batch Loss: 0.6409331560134888\n",
      "Epoch 4120, Loss: 2.152904897928238, Final Batch Loss: 0.46056684851646423\n",
      "Epoch 4121, Loss: 2.018057197332382, Final Batch Loss: 0.32173582911491394\n",
      "Epoch 4122, Loss: 2.228499174118042, Final Batch Loss: 0.3329300880432129\n",
      "Epoch 4123, Loss: 1.8230225890874863, Final Batch Loss: 0.19056062400341034\n",
      "Epoch 4124, Loss: 2.2939546704292297, Final Batch Loss: 0.6576085090637207\n",
      "Epoch 4125, Loss: 1.8807823807001114, Final Batch Loss: 0.18424932658672333\n",
      "Epoch 4126, Loss: 2.2560854256153107, Final Batch Loss: 0.5314921140670776\n",
      "Epoch 4127, Loss: 2.3053038120269775, Final Batch Loss: 0.552822470664978\n",
      "Epoch 4128, Loss: 1.7805450409650803, Final Batch Loss: 0.1599426120519638\n",
      "Epoch 4129, Loss: 2.1220237612724304, Final Batch Loss: 0.49902620911598206\n",
      "Epoch 4130, Loss: 1.8665928095579147, Final Batch Loss: 0.09864695370197296\n",
      "Epoch 4131, Loss: 2.113166570663452, Final Batch Loss: 0.5335320830345154\n",
      "Epoch 4132, Loss: 2.1881567537784576, Final Batch Loss: 0.4730985760688782\n",
      "Epoch 4133, Loss: 2.030154138803482, Final Batch Loss: 0.4208938479423523\n",
      "Epoch 4134, Loss: 1.8774071037769318, Final Batch Loss: 0.17038694024085999\n",
      "Epoch 4135, Loss: 2.195836663246155, Final Batch Loss: 0.5229641199111938\n",
      "Epoch 4136, Loss: 1.84165059030056, Final Batch Loss: 0.18853290379047394\n",
      "Epoch 4137, Loss: 2.027228981256485, Final Batch Loss: 0.42412155866622925\n",
      "Epoch 4138, Loss: 1.796332098543644, Final Batch Loss: 0.09460077434778214\n",
      "Epoch 4139, Loss: 2.087692618370056, Final Batch Loss: 0.5313044190406799\n",
      "Epoch 4140, Loss: 2.046581417322159, Final Batch Loss: 0.39663049578666687\n",
      "Epoch 4141, Loss: 1.7935394197702408, Final Batch Loss: 0.17253361642360687\n",
      "Epoch 4142, Loss: 2.237802803516388, Final Batch Loss: 0.6103204488754272\n",
      "Epoch 4143, Loss: 1.8036647289991379, Final Batch Loss: 0.13795404136180878\n",
      "Epoch 4144, Loss: 2.015172690153122, Final Batch Loss: 0.2691367566585541\n",
      "Epoch 4145, Loss: 2.0869254171848297, Final Batch Loss: 0.5127331614494324\n",
      "Epoch 4146, Loss: 2.593236416578293, Final Batch Loss: 0.9190916419029236\n",
      "Epoch 4147, Loss: 2.411556661128998, Final Batch Loss: 0.7175756096839905\n",
      "Epoch 4148, Loss: 1.7367883771657944, Final Batch Loss: 0.11488108336925507\n",
      "Epoch 4149, Loss: 2.0393421053886414, Final Batch Loss: 0.2453676462173462\n",
      "Epoch 4150, Loss: 1.8965082168579102, Final Batch Loss: 0.28231585025787354\n",
      "Epoch 4151, Loss: 2.2522264420986176, Final Batch Loss: 0.5792762637138367\n",
      "Epoch 4152, Loss: 1.9450265169143677, Final Batch Loss: 0.17250144481658936\n",
      "Epoch 4153, Loss: 2.465531200170517, Final Batch Loss: 0.4632469117641449\n",
      "Epoch 4154, Loss: 2.329730212688446, Final Batch Loss: 0.6122156381607056\n",
      "Epoch 4155, Loss: 2.39875927567482, Final Batch Loss: 0.5812528729438782\n",
      "Epoch 4156, Loss: 2.1287126541137695, Final Batch Loss: 0.3816535472869873\n",
      "Epoch 4157, Loss: 2.289364218711853, Final Batch Loss: 0.4942595958709717\n",
      "Epoch 4158, Loss: 2.7297794818878174, Final Batch Loss: 1.025938630104065\n",
      "Epoch 4159, Loss: 2.228747457265854, Final Batch Loss: 0.5358965992927551\n",
      "Epoch 4160, Loss: 2.0038794577121735, Final Batch Loss: 0.1587449014186859\n",
      "Epoch 4161, Loss: 2.2686151564121246, Final Batch Loss: 0.5414071083068848\n",
      "Epoch 4162, Loss: 2.274729549884796, Final Batch Loss: 0.5523923635482788\n",
      "Epoch 4163, Loss: 1.8568836748600006, Final Batch Loss: 0.2898831367492676\n",
      "Epoch 4164, Loss: 1.747798003256321, Final Batch Loss: 0.08735407143831253\n",
      "Epoch 4165, Loss: 2.1451727151870728, Final Batch Loss: 0.42426785826683044\n",
      "Epoch 4166, Loss: 1.6980193480849266, Final Batch Loss: 0.11023782938718796\n",
      "Epoch 4167, Loss: 2.2836948335170746, Final Batch Loss: 0.6041312217712402\n",
      "Epoch 4168, Loss: 2.0949069261550903, Final Batch Loss: 0.5438286662101746\n",
      "Epoch 4169, Loss: 2.0291498601436615, Final Batch Loss: 0.46052902936935425\n",
      "Epoch 4170, Loss: 2.397298187017441, Final Batch Loss: 0.7061080932617188\n",
      "Epoch 4171, Loss: 2.3234431743621826, Final Batch Loss: 0.44769689440727234\n",
      "Epoch 4172, Loss: 2.7277498841285706, Final Batch Loss: 1.036920428276062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4173, Loss: 2.233597457408905, Final Batch Loss: 0.48137006163597107\n",
      "Epoch 4174, Loss: 2.8044473528862, Final Batch Loss: 0.9579534530639648\n",
      "Epoch 4175, Loss: 2.3994860649108887, Final Batch Loss: 0.5488188862800598\n",
      "Epoch 4176, Loss: 2.459634840488434, Final Batch Loss: 0.591803252696991\n",
      "Epoch 4177, Loss: 2.193654030561447, Final Batch Loss: 0.5161004662513733\n",
      "Epoch 4178, Loss: 2.46481454372406, Final Batch Loss: 0.4221269190311432\n",
      "Epoch 4179, Loss: 2.564570039510727, Final Batch Loss: 0.6626543402671814\n",
      "Epoch 4180, Loss: 2.2681702077388763, Final Batch Loss: 0.5453070402145386\n",
      "Epoch 4181, Loss: 2.745851367712021, Final Batch Loss: 0.8357782363891602\n",
      "Epoch 4182, Loss: 2.4086756706237793, Final Batch Loss: 0.438358336687088\n",
      "Epoch 4183, Loss: 2.478919267654419, Final Batch Loss: 0.7075293660163879\n",
      "Epoch 4184, Loss: 2.2552159428596497, Final Batch Loss: 0.5641334652900696\n",
      "Epoch 4185, Loss: 2.14304256439209, Final Batch Loss: 0.4039519429206848\n",
      "Epoch 4186, Loss: 2.1642472743988037, Final Batch Loss: 0.34876805543899536\n",
      "Epoch 4187, Loss: 2.6628383100032806, Final Batch Loss: 0.9262703657150269\n",
      "Epoch 4188, Loss: 1.9455296248197556, Final Batch Loss: 0.19637595117092133\n",
      "Epoch 4189, Loss: 2.207529693841934, Final Batch Loss: 0.3511180281639099\n",
      "Epoch 4190, Loss: 2.1121786534786224, Final Batch Loss: 0.4032602310180664\n",
      "Epoch 4191, Loss: 2.104318231344223, Final Batch Loss: 0.3845430016517639\n",
      "Epoch 4192, Loss: 2.056608721613884, Final Batch Loss: 0.20711477100849152\n",
      "Epoch 4193, Loss: 2.254500836133957, Final Batch Loss: 0.4522813856601715\n",
      "Epoch 4194, Loss: 2.3292192220687866, Final Batch Loss: 0.6057397723197937\n",
      "Epoch 4195, Loss: 1.9982966184616089, Final Batch Loss: 0.19252100586891174\n",
      "Epoch 4196, Loss: 2.234671652317047, Final Batch Loss: 0.5288991332054138\n",
      "Epoch 4197, Loss: 2.406142145395279, Final Batch Loss: 0.6670915484428406\n",
      "Epoch 4198, Loss: 2.3555534183979034, Final Batch Loss: 0.5960315465927124\n",
      "Epoch 4199, Loss: 2.246336132287979, Final Batch Loss: 0.37597617506980896\n",
      "Epoch 4200, Loss: 2.268322616815567, Final Batch Loss: 0.5769058465957642\n",
      "Epoch 4201, Loss: 2.0717073678970337, Final Batch Loss: 0.2603350281715393\n",
      "Epoch 4202, Loss: 2.1772029399871826, Final Batch Loss: 0.5447351336479187\n",
      "Epoch 4203, Loss: 2.18281352519989, Final Batch Loss: 0.48944586515426636\n",
      "Epoch 4204, Loss: 2.1703971922397614, Final Batch Loss: 0.46590757369995117\n",
      "Epoch 4205, Loss: 1.998225450515747, Final Batch Loss: 0.31847912073135376\n",
      "Epoch 4206, Loss: 2.066070944070816, Final Batch Loss: 0.2924564778804779\n",
      "Epoch 4207, Loss: 2.350724369287491, Final Batch Loss: 0.7102554440498352\n",
      "Epoch 4208, Loss: 2.0176586508750916, Final Batch Loss: 0.30582842230796814\n",
      "Epoch 4209, Loss: 2.192787528038025, Final Batch Loss: 0.5018643140792847\n",
      "Epoch 4210, Loss: 2.2373819053173065, Final Batch Loss: 0.4602213203907013\n",
      "Epoch 4211, Loss: 2.167905807495117, Final Batch Loss: 0.6832168698310852\n",
      "Epoch 4212, Loss: 2.6947294175624847, Final Batch Loss: 0.8590665459632874\n",
      "Epoch 4213, Loss: 1.8452258110046387, Final Batch Loss: 0.10857880115509033\n",
      "Epoch 4214, Loss: 2.0729693174362183, Final Batch Loss: 0.32452136278152466\n",
      "Epoch 4215, Loss: 2.4362862408161163, Final Batch Loss: 0.7281332612037659\n",
      "Epoch 4216, Loss: 2.253223568201065, Final Batch Loss: 0.6402072906494141\n",
      "Epoch 4217, Loss: 2.1482802033424377, Final Batch Loss: 0.42298048734664917\n",
      "Epoch 4218, Loss: 1.9686420559883118, Final Batch Loss: 0.3519946038722992\n",
      "Epoch 4219, Loss: 2.1354169845581055, Final Batch Loss: 0.37238994240760803\n",
      "Epoch 4220, Loss: 2.186970502138138, Final Batch Loss: 0.4639606773853302\n",
      "Epoch 4221, Loss: 2.1508684754371643, Final Batch Loss: 0.3384995460510254\n",
      "Epoch 4222, Loss: 2.4308508038520813, Final Batch Loss: 0.6573888659477234\n",
      "Epoch 4223, Loss: 2.289535641670227, Final Batch Loss: 0.6527618765830994\n",
      "Epoch 4224, Loss: 2.151082754135132, Final Batch Loss: 0.38417816162109375\n",
      "Epoch 4225, Loss: 2.8696762919425964, Final Batch Loss: 1.0248730182647705\n",
      "Epoch 4226, Loss: 2.2496828734874725, Final Batch Loss: 0.6380667090415955\n",
      "Epoch 4227, Loss: 2.244172304868698, Final Batch Loss: 0.5855702757835388\n",
      "Epoch 4228, Loss: 2.0449352860450745, Final Batch Loss: 0.27329739928245544\n",
      "Epoch 4229, Loss: 1.9390631765127182, Final Batch Loss: 0.22250385582447052\n",
      "Epoch 4230, Loss: 2.1914814114570618, Final Batch Loss: 0.5053547620773315\n",
      "Epoch 4231, Loss: 2.170935481786728, Final Batch Loss: 0.26676037907600403\n",
      "Epoch 4232, Loss: 2.841688334941864, Final Batch Loss: 1.2671977281570435\n",
      "Epoch 4233, Loss: 2.1986807584762573, Final Batch Loss: 0.46027475595474243\n",
      "Epoch 4234, Loss: 2.399894118309021, Final Batch Loss: 0.6087908744812012\n",
      "Epoch 4235, Loss: 1.8588186651468277, Final Batch Loss: 0.18369413912296295\n",
      "Epoch 4236, Loss: 2.2098951041698456, Final Batch Loss: 0.50005704164505\n",
      "Epoch 4237, Loss: 2.346856862306595, Final Batch Loss: 0.5297706127166748\n",
      "Epoch 4238, Loss: 1.7566054202616215, Final Batch Loss: 0.03889426961541176\n",
      "Epoch 4239, Loss: 1.9724797010421753, Final Batch Loss: 0.2637650966644287\n",
      "Epoch 4240, Loss: 1.9139798879623413, Final Batch Loss: 0.28748390078544617\n",
      "Epoch 4241, Loss: 1.9988999962806702, Final Batch Loss: 0.35334983468055725\n",
      "Epoch 4242, Loss: 1.7807271927595139, Final Batch Loss: 0.2137417048215866\n",
      "Epoch 4243, Loss: 2.1190502643585205, Final Batch Loss: 0.5058075189590454\n",
      "Epoch 4244, Loss: 2.2349850237369537, Final Batch Loss: 0.46571871638298035\n",
      "Epoch 4245, Loss: 2.508159428834915, Final Batch Loss: 0.736326277256012\n",
      "Epoch 4246, Loss: 2.223331540822983, Final Batch Loss: 0.3687177002429962\n",
      "Epoch 4247, Loss: 2.103931814432144, Final Batch Loss: 0.3685648441314697\n",
      "Epoch 4248, Loss: 2.071710169315338, Final Batch Loss: 0.42682260274887085\n",
      "Epoch 4249, Loss: 2.280174046754837, Final Batch Loss: 0.501200258731842\n",
      "Epoch 4250, Loss: 2.8798713982105255, Final Batch Loss: 1.129858374595642\n",
      "Epoch 4251, Loss: 2.0092195868492126, Final Batch Loss: 0.27442604303359985\n",
      "Epoch 4252, Loss: 2.264103651046753, Final Batch Loss: 0.5755837559700012\n",
      "Epoch 4253, Loss: 1.9970664978027344, Final Batch Loss: 0.32055869698524475\n",
      "Epoch 4254, Loss: 2.128860980272293, Final Batch Loss: 0.381413072347641\n",
      "Epoch 4255, Loss: 1.808567851781845, Final Batch Loss: 0.14327219128608704\n",
      "Epoch 4256, Loss: 1.8086892366409302, Final Batch Loss: 0.2281893491744995\n",
      "Epoch 4257, Loss: 2.4505751729011536, Final Batch Loss: 0.8580822348594666\n",
      "Epoch 4258, Loss: 2.1090227663517, Final Batch Loss: 0.4589480757713318\n",
      "Epoch 4259, Loss: 2.2744515240192413, Final Batch Loss: 0.5708286166191101\n",
      "Epoch 4260, Loss: 2.010532259941101, Final Batch Loss: 0.18738588690757751\n",
      "Epoch 4261, Loss: 2.2226534485816956, Final Batch Loss: 0.29072877764701843\n",
      "Epoch 4262, Loss: 3.0587083995342255, Final Batch Loss: 1.175369143486023\n",
      "Epoch 4263, Loss: 2.050626188516617, Final Batch Loss: 0.42682403326034546\n",
      "Epoch 4264, Loss: 2.196437746286392, Final Batch Loss: 0.5237292647361755\n",
      "Epoch 4265, Loss: 1.8791208416223526, Final Batch Loss: 0.18473689258098602\n",
      "Epoch 4266, Loss: 2.03028866648674, Final Batch Loss: 0.4039980471134186\n",
      "Epoch 4267, Loss: 1.9588283151388168, Final Batch Loss: 0.15529288351535797\n",
      "Epoch 4268, Loss: 1.9231898337602615, Final Batch Loss: 0.2303304523229599\n",
      "Epoch 4269, Loss: 1.9382147192955017, Final Batch Loss: 0.37771621346473694\n",
      "Epoch 4270, Loss: 2.1912421882152557, Final Batch Loss: 0.45172029733657837\n",
      "Epoch 4271, Loss: 1.7565695345401764, Final Batch Loss: 0.21222198009490967\n",
      "Epoch 4272, Loss: 1.8723564743995667, Final Batch Loss: 0.33503177762031555\n",
      "Epoch 4273, Loss: 2.412322849035263, Final Batch Loss: 0.7169999480247498\n",
      "Epoch 4274, Loss: 2.1440334916114807, Final Batch Loss: 0.6145215034484863\n",
      "Epoch 4275, Loss: 2.0805327594280243, Final Batch Loss: 0.42576995491981506\n",
      "Epoch 4276, Loss: 2.150406926870346, Final Batch Loss: 0.4157959520816803\n",
      "Epoch 4277, Loss: 2.171163946390152, Final Batch Loss: 0.5298345685005188\n",
      "Epoch 4278, Loss: 1.91523477435112, Final Batch Loss: 0.3313424289226532\n",
      "Epoch 4279, Loss: 2.041703701019287, Final Batch Loss: 0.3629738390445709\n",
      "Epoch 4280, Loss: 2.1293191611766815, Final Batch Loss: 0.46425238251686096\n",
      "Epoch 4281, Loss: 1.8091857731342316, Final Batch Loss: 0.24916434288024902\n",
      "Epoch 4282, Loss: 2.419031649827957, Final Batch Loss: 0.6259545087814331\n",
      "Epoch 4283, Loss: 2.0520245134830475, Final Batch Loss: 0.340670108795166\n",
      "Epoch 4284, Loss: 2.2261079847812653, Final Batch Loss: 0.4268398582935333\n",
      "Epoch 4285, Loss: 1.8355929553508759, Final Batch Loss: 0.24454441666603088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4286, Loss: 1.9641746282577515, Final Batch Loss: 0.464203417301178\n",
      "Epoch 4287, Loss: 1.9643099009990692, Final Batch Loss: 0.30897313356399536\n",
      "Epoch 4288, Loss: 2.046530067920685, Final Batch Loss: 0.3919912874698639\n",
      "Epoch 4289, Loss: 1.8042238131165504, Final Batch Loss: 0.0625980868935585\n",
      "Epoch 4290, Loss: 1.978301763534546, Final Batch Loss: 0.326095312833786\n",
      "Epoch 4291, Loss: 1.9013562053442001, Final Batch Loss: 0.22478951513767242\n",
      "Epoch 4292, Loss: 2.1990611851215363, Final Batch Loss: 0.5840404629707336\n",
      "Epoch 4293, Loss: 2.33065065741539, Final Batch Loss: 0.5596151947975159\n",
      "Epoch 4294, Loss: 2.0150248408317566, Final Batch Loss: 0.35487914085388184\n",
      "Epoch 4295, Loss: 1.8850995600223541, Final Batch Loss: 0.21747183799743652\n",
      "Epoch 4296, Loss: 1.9994085729122162, Final Batch Loss: 0.3965396583080292\n",
      "Epoch 4297, Loss: 2.104668378829956, Final Batch Loss: 0.4489184021949768\n",
      "Epoch 4298, Loss: 1.7043229453265667, Final Batch Loss: 0.028041701763868332\n",
      "Epoch 4299, Loss: 1.7675813660025597, Final Batch Loss: 0.11225547641515732\n",
      "Epoch 4300, Loss: 1.8044976145029068, Final Batch Loss: 0.16458721458911896\n",
      "Epoch 4301, Loss: 2.3971062302589417, Final Batch Loss: 0.6052411198616028\n",
      "Epoch 4302, Loss: 2.3135630786418915, Final Batch Loss: 0.5586541891098022\n",
      "Epoch 4303, Loss: 1.7394683137536049, Final Batch Loss: 0.04767540842294693\n",
      "Epoch 4304, Loss: 2.871742218732834, Final Batch Loss: 0.9634477496147156\n",
      "Epoch 4305, Loss: 2.413194000720978, Final Batch Loss: 0.6854574084281921\n",
      "Epoch 4306, Loss: 2.858195811510086, Final Batch Loss: 1.1232112646102905\n",
      "Epoch 4307, Loss: 1.911195307970047, Final Batch Loss: 0.1356814205646515\n",
      "Epoch 4308, Loss: 2.0873628556728363, Final Batch Loss: 0.31772899627685547\n",
      "Epoch 4309, Loss: 2.1508757770061493, Final Batch Loss: 0.32705074548721313\n",
      "Epoch 4310, Loss: 2.254007011651993, Final Batch Loss: 0.6080793142318726\n",
      "Epoch 4311, Loss: 1.9907038807868958, Final Batch Loss: 0.2655123174190521\n",
      "Epoch 4312, Loss: 2.2072871327400208, Final Batch Loss: 0.568649172782898\n",
      "Epoch 4313, Loss: 2.1436475217342377, Final Batch Loss: 0.42217373847961426\n",
      "Epoch 4314, Loss: 1.8132017403841019, Final Batch Loss: 0.19138549268245697\n",
      "Epoch 4315, Loss: 2.042314440011978, Final Batch Loss: 0.31921809911727905\n",
      "Epoch 4316, Loss: 2.2421185970306396, Final Batch Loss: 0.48877090215682983\n",
      "Epoch 4317, Loss: 1.8656116873025894, Final Batch Loss: 0.19458039104938507\n",
      "Epoch 4318, Loss: 1.8381511867046356, Final Batch Loss: 0.24437975883483887\n",
      "Epoch 4319, Loss: 2.286264330148697, Final Batch Loss: 0.5556519627571106\n",
      "Epoch 4320, Loss: 2.244454264640808, Final Batch Loss: 0.5698684453964233\n",
      "Epoch 4321, Loss: 1.9597483575344086, Final Batch Loss: 0.27637407183647156\n",
      "Epoch 4322, Loss: 1.7237138971686363, Final Batch Loss: 0.09739815443754196\n",
      "Epoch 4323, Loss: 2.334460496902466, Final Batch Loss: 0.7234544157981873\n",
      "Epoch 4324, Loss: 1.979427993297577, Final Batch Loss: 0.4425601065158844\n",
      "Epoch 4325, Loss: 1.9557523429393768, Final Batch Loss: 0.33339956402778625\n",
      "Epoch 4326, Loss: 1.7832846939563751, Final Batch Loss: 0.18519142270088196\n",
      "Epoch 4327, Loss: 1.9747020900249481, Final Batch Loss: 0.26314327120780945\n",
      "Epoch 4328, Loss: 1.9947187006473541, Final Batch Loss: 0.2981058955192566\n",
      "Epoch 4329, Loss: 2.156831830739975, Final Batch Loss: 0.3946528434753418\n",
      "Epoch 4330, Loss: 2.724768042564392, Final Batch Loss: 1.0538740158081055\n",
      "Epoch 4331, Loss: 2.337321937084198, Final Batch Loss: 0.833660900592804\n",
      "Epoch 4332, Loss: 1.813570261001587, Final Batch Loss: 0.21711549162864685\n",
      "Epoch 4333, Loss: 1.972525030374527, Final Batch Loss: 0.30886054039001465\n",
      "Epoch 4334, Loss: 1.8269609212875366, Final Batch Loss: 0.16374680399894714\n",
      "Epoch 4335, Loss: 2.8295958638191223, Final Batch Loss: 1.0086266994476318\n",
      "Epoch 4336, Loss: 1.8947054892778397, Final Batch Loss: 0.24763645231723785\n",
      "Epoch 4337, Loss: 2.0880708396434784, Final Batch Loss: 0.47384577989578247\n",
      "Epoch 4338, Loss: 2.140637546777725, Final Batch Loss: 0.4367080628871918\n",
      "Epoch 4339, Loss: 2.3499313592910767, Final Batch Loss: 0.5948968529701233\n",
      "Epoch 4340, Loss: 2.163783520460129, Final Batch Loss: 0.2668241262435913\n",
      "Epoch 4341, Loss: 2.7305777966976166, Final Batch Loss: 0.9377735257148743\n",
      "Epoch 4342, Loss: 2.02875354886055, Final Batch Loss: 0.26197293400764465\n",
      "Epoch 4343, Loss: 2.375136435031891, Final Batch Loss: 0.6932244896888733\n",
      "Epoch 4344, Loss: 2.1688713133335114, Final Batch Loss: 0.4502686858177185\n",
      "Epoch 4345, Loss: 1.7667073905467987, Final Batch Loss: 0.2085942029953003\n",
      "Epoch 4346, Loss: 2.0619004666805267, Final Batch Loss: 0.3802017271518707\n",
      "Epoch 4347, Loss: 2.2697921991348267, Final Batch Loss: 0.5910342931747437\n",
      "Epoch 4348, Loss: 1.7636743187904358, Final Batch Loss: 0.15768954157829285\n",
      "Epoch 4349, Loss: 2.1317093074321747, Final Batch Loss: 0.3697366714477539\n",
      "Epoch 4350, Loss: 1.9133630394935608, Final Batch Loss: 0.2622847855091095\n",
      "Epoch 4351, Loss: 2.1239705085754395, Final Batch Loss: 0.4347582459449768\n",
      "Epoch 4352, Loss: 1.9072138667106628, Final Batch Loss: 0.22692671418190002\n",
      "Epoch 4353, Loss: 2.1263299882411957, Final Batch Loss: 0.4543902575969696\n",
      "Epoch 4354, Loss: 2.267795741558075, Final Batch Loss: 0.5030750632286072\n",
      "Epoch 4355, Loss: 1.9538471698760986, Final Batch Loss: 0.20491886138916016\n",
      "Epoch 4356, Loss: 2.008317217230797, Final Batch Loss: 0.2101721614599228\n",
      "Epoch 4357, Loss: 2.1361236572265625, Final Batch Loss: 0.44405120611190796\n",
      "Epoch 4358, Loss: 1.9397899061441422, Final Batch Loss: 0.21429531276226044\n",
      "Epoch 4359, Loss: 1.80945336073637, Final Batch Loss: 0.11632358282804489\n",
      "Epoch 4360, Loss: 2.2002379298210144, Final Batch Loss: 0.44173237681388855\n",
      "Epoch 4361, Loss: 2.29495507478714, Final Batch Loss: 0.6361888647079468\n",
      "Epoch 4362, Loss: 2.173589825630188, Final Batch Loss: 0.5094428062438965\n",
      "Epoch 4363, Loss: 2.219466358423233, Final Batch Loss: 0.32669052481651306\n",
      "Epoch 4364, Loss: 2.6523241996765137, Final Batch Loss: 0.8781295418739319\n",
      "Epoch 4365, Loss: 2.5583507120609283, Final Batch Loss: 0.7086849212646484\n",
      "Epoch 4366, Loss: 2.2498671412467957, Final Batch Loss: 0.5200641751289368\n",
      "Epoch 4367, Loss: 1.823244884610176, Final Batch Loss: 0.14769555628299713\n",
      "Epoch 4368, Loss: 2.137286514043808, Final Batch Loss: 0.4558921158313751\n",
      "Epoch 4369, Loss: 1.8760669827461243, Final Batch Loss: 0.25214120745658875\n",
      "Epoch 4370, Loss: 1.916112519800663, Final Batch Loss: 0.11464560776948929\n",
      "Epoch 4371, Loss: 2.380968004465103, Final Batch Loss: 0.6876230835914612\n",
      "Epoch 4372, Loss: 2.039186507463455, Final Batch Loss: 0.3705432713031769\n",
      "Epoch 4373, Loss: 1.9789168536663055, Final Batch Loss: 0.44043517112731934\n",
      "Epoch 4374, Loss: 2.0508760809898376, Final Batch Loss: 0.37801989912986755\n",
      "Epoch 4375, Loss: 2.424086779356003, Final Batch Loss: 0.8100346326828003\n",
      "Epoch 4376, Loss: 2.0469882488250732, Final Batch Loss: 0.4054717421531677\n",
      "Epoch 4377, Loss: 1.7183842211961746, Final Batch Loss: 0.08737899363040924\n",
      "Epoch 4378, Loss: 1.629306584596634, Final Batch Loss: 0.11978328227996826\n",
      "Epoch 4379, Loss: 1.7786176353693008, Final Batch Loss: 0.23975004255771637\n",
      "Epoch 4380, Loss: 1.8945153057575226, Final Batch Loss: 0.28186213970184326\n",
      "Epoch 4381, Loss: 1.8674386739730835, Final Batch Loss: 0.40605369210243225\n",
      "Epoch 4382, Loss: 1.9648868441581726, Final Batch Loss: 0.3248007893562317\n",
      "Epoch 4383, Loss: 2.3085532784461975, Final Batch Loss: 0.7861508131027222\n",
      "Epoch 4384, Loss: 2.196909487247467, Final Batch Loss: 0.493106871843338\n",
      "Epoch 4385, Loss: 2.2584508657455444, Final Batch Loss: 0.6702834963798523\n",
      "Epoch 4386, Loss: 1.6982889138162136, Final Batch Loss: 0.05601182207465172\n",
      "Epoch 4387, Loss: 2.0072245597839355, Final Batch Loss: 0.4471299946308136\n",
      "Epoch 4388, Loss: 2.036987453699112, Final Batch Loss: 0.39153924584388733\n",
      "Epoch 4389, Loss: 1.9729311764240265, Final Batch Loss: 0.31003350019454956\n",
      "Epoch 4390, Loss: 1.6804580986499786, Final Batch Loss: 0.12711381912231445\n",
      "Epoch 4391, Loss: 2.2836445569992065, Final Batch Loss: 0.6606480479240417\n",
      "Epoch 4392, Loss: 1.9264420717954636, Final Batch Loss: 0.22469140589237213\n",
      "Epoch 4393, Loss: 2.5523565113544464, Final Batch Loss: 0.915498673915863\n",
      "Epoch 4394, Loss: 1.7098755240440369, Final Batch Loss: 0.16954341530799866\n",
      "Epoch 4395, Loss: 2.0124868750572205, Final Batch Loss: 0.4939025342464447\n",
      "Epoch 4396, Loss: 1.86285799741745, Final Batch Loss: 0.34008124470710754\n",
      "Epoch 4397, Loss: 2.0653666257858276, Final Batch Loss: 0.3726224899291992\n",
      "Epoch 4398, Loss: 2.3068066835403442, Final Batch Loss: 0.6810333132743835\n",
      "Epoch 4399, Loss: 2.2363273799419403, Final Batch Loss: 0.520572304725647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4400, Loss: 2.055110454559326, Final Batch Loss: 0.3443801999092102\n",
      "Epoch 4401, Loss: 2.0565569698810577, Final Batch Loss: 0.3648712933063507\n",
      "Epoch 4402, Loss: 2.5457085371017456, Final Batch Loss: 0.8250699639320374\n",
      "Epoch 4403, Loss: 2.109687238931656, Final Batch Loss: 0.4282352030277252\n",
      "Epoch 4404, Loss: 2.1822704076766968, Final Batch Loss: 0.516013503074646\n",
      "Epoch 4405, Loss: 1.8704508543014526, Final Batch Loss: 0.3456055223941803\n",
      "Epoch 4406, Loss: 2.0862047970294952, Final Batch Loss: 0.33318886160850525\n",
      "Epoch 4407, Loss: 1.8532610535621643, Final Batch Loss: 0.18993964791297913\n",
      "Epoch 4408, Loss: 1.8865392804145813, Final Batch Loss: 0.22868800163269043\n",
      "Epoch 4409, Loss: 2.536019891500473, Final Batch Loss: 0.8428545594215393\n",
      "Epoch 4410, Loss: 2.091250330209732, Final Batch Loss: 0.4371252954006195\n",
      "Epoch 4411, Loss: 2.0839082300662994, Final Batch Loss: 0.3319411873817444\n",
      "Epoch 4412, Loss: 1.8997548520565033, Final Batch Loss: 0.19412505626678467\n",
      "Epoch 4413, Loss: 1.6939171999692917, Final Batch Loss: 0.07853670418262482\n",
      "Epoch 4414, Loss: 1.8183397501707077, Final Batch Loss: 0.14197783172130585\n",
      "Epoch 4415, Loss: 2.0006364583969116, Final Batch Loss: 0.4382669925689697\n",
      "Epoch 4416, Loss: 2.1138043105602264, Final Batch Loss: 0.3943175673484802\n",
      "Epoch 4417, Loss: 1.9751873314380646, Final Batch Loss: 0.4216909408569336\n",
      "Epoch 4418, Loss: 2.292603939771652, Final Batch Loss: 0.4714839458465576\n",
      "Epoch 4419, Loss: 2.059463679790497, Final Batch Loss: 0.38337963819503784\n",
      "Epoch 4420, Loss: 2.1175478398799896, Final Batch Loss: 0.3459109365940094\n",
      "Epoch 4421, Loss: 1.8904301226139069, Final Batch Loss: 0.29700347781181335\n",
      "Epoch 4422, Loss: 2.1669238209724426, Final Batch Loss: 0.44499829411506653\n",
      "Epoch 4423, Loss: 2.141094744205475, Final Batch Loss: 0.35314440727233887\n",
      "Epoch 4424, Loss: 2.288573980331421, Final Batch Loss: 0.7270799279212952\n",
      "Epoch 4425, Loss: 2.3823196291923523, Final Batch Loss: 0.6097980737686157\n",
      "Epoch 4426, Loss: 2.026604264974594, Final Batch Loss: 0.41417255997657776\n",
      "Epoch 4427, Loss: 2.5131138265132904, Final Batch Loss: 0.9623208045959473\n",
      "Epoch 4428, Loss: 1.9606215059757233, Final Batch Loss: 0.4152929186820984\n",
      "Epoch 4429, Loss: 2.3561640977859497, Final Batch Loss: 0.7117828130722046\n",
      "Epoch 4430, Loss: 2.1956511735916138, Final Batch Loss: 0.640036940574646\n",
      "Epoch 4431, Loss: 2.0654748380184174, Final Batch Loss: 0.4409504234790802\n",
      "Epoch 4432, Loss: 2.295465052127838, Final Batch Loss: 0.5554274916648865\n",
      "Epoch 4433, Loss: 2.0711799561977386, Final Batch Loss: 0.5235075950622559\n",
      "Epoch 4434, Loss: 1.9562748968601227, Final Batch Loss: 0.322436660528183\n",
      "Epoch 4435, Loss: 1.9947528839111328, Final Batch Loss: 0.28305527567863464\n",
      "Epoch 4436, Loss: 2.3332027792930603, Final Batch Loss: 0.6839934587478638\n",
      "Epoch 4437, Loss: 1.98978653550148, Final Batch Loss: 0.29788801074028015\n",
      "Epoch 4438, Loss: 2.050181061029434, Final Batch Loss: 0.40944990515708923\n",
      "Epoch 4439, Loss: 2.2156927287578583, Final Batch Loss: 0.48064500093460083\n",
      "Epoch 4440, Loss: 1.9243338406085968, Final Batch Loss: 0.352539986371994\n",
      "Epoch 4441, Loss: 2.0700063705444336, Final Batch Loss: 0.5099764466285706\n",
      "Epoch 4442, Loss: 1.8393968045711517, Final Batch Loss: 0.3106522858142853\n",
      "Epoch 4443, Loss: 2.0024019479751587, Final Batch Loss: 0.37691619992256165\n",
      "Epoch 4444, Loss: 2.6419565677642822, Final Batch Loss: 0.8965343832969666\n",
      "Epoch 4445, Loss: 1.845617190003395, Final Batch Loss: 0.20879970490932465\n",
      "Epoch 4446, Loss: 1.8632997870445251, Final Batch Loss: 0.26147720217704773\n",
      "Epoch 4447, Loss: 1.7203124836087227, Final Batch Loss: 0.07950595766305923\n",
      "Epoch 4448, Loss: 2.1481940746307373, Final Batch Loss: 0.37672558426856995\n",
      "Epoch 4449, Loss: 1.9494900107383728, Final Batch Loss: 0.3583526611328125\n",
      "Epoch 4450, Loss: 2.3387626111507416, Final Batch Loss: 0.6569662690162659\n",
      "Epoch 4451, Loss: 2.3586832880973816, Final Batch Loss: 0.5818224549293518\n",
      "Epoch 4452, Loss: 2.232413500547409, Final Batch Loss: 0.6355038285255432\n",
      "Epoch 4453, Loss: 2.045878618955612, Final Batch Loss: 0.3544343411922455\n",
      "Epoch 4454, Loss: 2.2050833106040955, Final Batch Loss: 0.5836066603660583\n",
      "Epoch 4455, Loss: 2.137005776166916, Final Batch Loss: 0.4340207874774933\n",
      "Epoch 4456, Loss: 2.4298411905765533, Final Batch Loss: 0.7434506416320801\n",
      "Epoch 4457, Loss: 1.9055856615304947, Final Batch Loss: 0.22002090513706207\n",
      "Epoch 4458, Loss: 1.5221723169088364, Final Batch Loss: 0.06642381846904755\n",
      "Epoch 4459, Loss: 1.7375349551439285, Final Batch Loss: 0.17896784842014313\n",
      "Epoch 4460, Loss: 2.121869206428528, Final Batch Loss: 0.4303106665611267\n",
      "Epoch 4461, Loss: 2.2628527879714966, Final Batch Loss: 0.5845356583595276\n",
      "Epoch 4462, Loss: 1.7890124917030334, Final Batch Loss: 0.21894434094429016\n",
      "Epoch 4463, Loss: 1.9838137328624725, Final Batch Loss: 0.4055958688259125\n",
      "Epoch 4464, Loss: 2.012397527694702, Final Batch Loss: 0.4548272490501404\n",
      "Epoch 4465, Loss: 2.130619138479233, Final Batch Loss: 0.6031651496887207\n",
      "Epoch 4466, Loss: 2.381907433271408, Final Batch Loss: 0.5869609117507935\n",
      "Epoch 4467, Loss: 2.2745091915130615, Final Batch Loss: 0.5126700401306152\n",
      "Epoch 4468, Loss: 1.975511074066162, Final Batch Loss: 0.3018416464328766\n",
      "Epoch 4469, Loss: 1.8990800380706787, Final Batch Loss: 0.263528048992157\n",
      "Epoch 4470, Loss: 1.9590359330177307, Final Batch Loss: 0.44246718287467957\n",
      "Epoch 4471, Loss: 2.119355171918869, Final Batch Loss: 0.5991028547286987\n",
      "Epoch 4472, Loss: 2.2242180705070496, Final Batch Loss: 0.36332467198371887\n",
      "Epoch 4473, Loss: 2.356069326400757, Final Batch Loss: 0.5709508061408997\n",
      "Epoch 4474, Loss: 2.5793095529079437, Final Batch Loss: 0.8864740133285522\n",
      "Epoch 4475, Loss: 2.030340313911438, Final Batch Loss: 0.30691128969192505\n",
      "Epoch 4476, Loss: 1.9778718948364258, Final Batch Loss: 0.31085461378097534\n",
      "Epoch 4477, Loss: 2.5922942459583282, Final Batch Loss: 0.8507151007652283\n",
      "Epoch 4478, Loss: 1.838003009557724, Final Batch Loss: 0.422386109828949\n",
      "Epoch 4479, Loss: 2.0505668818950653, Final Batch Loss: 0.32119280099868774\n",
      "Epoch 4480, Loss: 1.9800367951393127, Final Batch Loss: 0.3518792688846588\n",
      "Epoch 4481, Loss: 2.0275306403636932, Final Batch Loss: 0.35828858613967896\n",
      "Epoch 4482, Loss: 1.892682895064354, Final Batch Loss: 0.2339705377817154\n",
      "Epoch 4483, Loss: 2.3426427841186523, Final Batch Loss: 0.5026196837425232\n",
      "Epoch 4484, Loss: 2.545086532831192, Final Batch Loss: 0.7510094046592712\n",
      "Epoch 4485, Loss: 2.2370326817035675, Final Batch Loss: 0.5801145434379578\n",
      "Epoch 4486, Loss: 1.948254406452179, Final Batch Loss: 0.25441882014274597\n",
      "Epoch 4487, Loss: 2.5023601353168488, Final Batch Loss: 0.7540568113327026\n",
      "Epoch 4488, Loss: 2.4137003421783447, Final Batch Loss: 0.7500104308128357\n",
      "Epoch 4489, Loss: 1.7955577224493027, Final Batch Loss: 0.17633531987667084\n",
      "Epoch 4490, Loss: 1.9088970869779587, Final Batch Loss: 0.22426213324069977\n",
      "Epoch 4491, Loss: 2.001857489347458, Final Batch Loss: 0.37102580070495605\n",
      "Epoch 4492, Loss: 1.946307897567749, Final Batch Loss: 0.39261505007743835\n",
      "Epoch 4493, Loss: 2.1240918338298798, Final Batch Loss: 0.32967108488082886\n",
      "Epoch 4494, Loss: 2.003840744495392, Final Batch Loss: 0.22075331211090088\n",
      "Epoch 4495, Loss: 1.940015658736229, Final Batch Loss: 0.1800146847963333\n",
      "Epoch 4496, Loss: 2.05788317322731, Final Batch Loss: 0.34132450819015503\n",
      "Epoch 4497, Loss: 1.9453817009925842, Final Batch Loss: 0.31784579157829285\n",
      "Epoch 4498, Loss: 2.2931990325450897, Final Batch Loss: 0.6496089100837708\n",
      "Epoch 4499, Loss: 2.1887584924697876, Final Batch Loss: 0.43603476881980896\n",
      "Epoch 4500, Loss: 2.0988632440567017, Final Batch Loss: 0.4050658047199249\n",
      "Epoch 4501, Loss: 2.008334994316101, Final Batch Loss: 0.23524808883666992\n",
      "Epoch 4502, Loss: 2.3269820511341095, Final Batch Loss: 0.7090963125228882\n",
      "Epoch 4503, Loss: 1.7745463326573372, Final Batch Loss: 0.12458661943674088\n",
      "Epoch 4504, Loss: 1.8121373802423477, Final Batch Loss: 0.23304428160190582\n",
      "Epoch 4505, Loss: 2.1715391278266907, Final Batch Loss: 0.5315057039260864\n",
      "Epoch 4506, Loss: 2.321452260017395, Final Batch Loss: 0.5005834698677063\n",
      "Epoch 4507, Loss: 2.472053498029709, Final Batch Loss: 0.9730974435806274\n",
      "Epoch 4508, Loss: 2.1124546825885773, Final Batch Loss: 0.4168311655521393\n",
      "Epoch 4509, Loss: 2.15040522813797, Final Batch Loss: 0.4124946594238281\n",
      "Epoch 4510, Loss: 2.266626924276352, Final Batch Loss: 0.37248438596725464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4511, Loss: 1.964159682393074, Final Batch Loss: 0.2087859958410263\n",
      "Epoch 4512, Loss: 2.069226622581482, Final Batch Loss: 0.35649606585502625\n",
      "Epoch 4513, Loss: 2.5922568440437317, Final Batch Loss: 0.927692711353302\n",
      "Epoch 4514, Loss: 2.0218682885169983, Final Batch Loss: 0.2419668436050415\n",
      "Epoch 4515, Loss: 2.0727131962776184, Final Batch Loss: 0.3172391951084137\n",
      "Epoch 4516, Loss: 2.1482867300510406, Final Batch Loss: 0.47198915481567383\n",
      "Epoch 4517, Loss: 2.4066110849380493, Final Batch Loss: 0.6899861097335815\n",
      "Epoch 4518, Loss: 1.8868167102336884, Final Batch Loss: 0.20807290077209473\n",
      "Epoch 4519, Loss: 2.428534358739853, Final Batch Loss: 0.6679189801216125\n",
      "Epoch 4520, Loss: 1.9836859107017517, Final Batch Loss: 0.33856505155563354\n",
      "Epoch 4521, Loss: 1.9363329708576202, Final Batch Loss: 0.24291881918907166\n",
      "Epoch 4522, Loss: 2.1447174549102783, Final Batch Loss: 0.45731857419013977\n",
      "Epoch 4523, Loss: 2.0932739675045013, Final Batch Loss: 0.48309269547462463\n",
      "Epoch 4524, Loss: 1.9531448185443878, Final Batch Loss: 0.2828782796859741\n",
      "Epoch 4525, Loss: 1.9421636462211609, Final Batch Loss: 0.2346835434436798\n",
      "Epoch 4526, Loss: 2.1247672140598297, Final Batch Loss: 0.6139827370643616\n",
      "Epoch 4527, Loss: 1.788441926240921, Final Batch Loss: 0.23282933235168457\n",
      "Epoch 4528, Loss: 1.8333136439323425, Final Batch Loss: 0.25705111026763916\n",
      "Epoch 4529, Loss: 1.999594807624817, Final Batch Loss: 0.4245278835296631\n",
      "Epoch 4530, Loss: 1.9599328339099884, Final Batch Loss: 0.3020535409450531\n",
      "Epoch 4531, Loss: 1.9547935724258423, Final Batch Loss: 0.2682156562805176\n",
      "Epoch 4532, Loss: 2.1035894453525543, Final Batch Loss: 0.31948333978652954\n",
      "Epoch 4533, Loss: 1.7462614327669144, Final Batch Loss: 0.20581860840320587\n",
      "Epoch 4534, Loss: 2.058210998773575, Final Batch Loss: 0.5470656156539917\n",
      "Epoch 4535, Loss: 1.9991493225097656, Final Batch Loss: 0.513471782207489\n",
      "Epoch 4536, Loss: 2.6991502940654755, Final Batch Loss: 1.0142239332199097\n",
      "Epoch 4537, Loss: 1.8818937838077545, Final Batch Loss: 0.1803102195262909\n",
      "Epoch 4538, Loss: 1.927887350320816, Final Batch Loss: 0.2483801543712616\n",
      "Epoch 4539, Loss: 2.2328662276268005, Final Batch Loss: 0.7039517760276794\n",
      "Epoch 4540, Loss: 1.9483166933059692, Final Batch Loss: 0.28088319301605225\n",
      "Epoch 4541, Loss: 1.9546783417463303, Final Batch Loss: 0.21464140713214874\n",
      "Epoch 4542, Loss: 1.8497401773929596, Final Batch Loss: 0.2745029628276825\n",
      "Epoch 4543, Loss: 2.002007007598877, Final Batch Loss: 0.377054899930954\n",
      "Epoch 4544, Loss: 1.919096827507019, Final Batch Loss: 0.4368755519390106\n",
      "Epoch 4545, Loss: 1.9036771953105927, Final Batch Loss: 0.3671376705169678\n",
      "Epoch 4546, Loss: 1.9820342659950256, Final Batch Loss: 0.44306865334510803\n",
      "Epoch 4547, Loss: 2.1417000591754913, Final Batch Loss: 0.5355193018913269\n",
      "Epoch 4548, Loss: 2.0039429366588593, Final Batch Loss: 0.5984718203544617\n",
      "Epoch 4549, Loss: 1.7279733419418335, Final Batch Loss: 0.13526159524917603\n",
      "Epoch 4550, Loss: 1.7199949771165848, Final Batch Loss: 0.17472152411937714\n",
      "Epoch 4551, Loss: 2.267569124698639, Final Batch Loss: 0.6674993634223938\n",
      "Epoch 4552, Loss: 1.8639085590839386, Final Batch Loss: 0.38059109449386597\n",
      "Epoch 4553, Loss: 2.352025717496872, Final Batch Loss: 0.6871562004089355\n",
      "Epoch 4554, Loss: 1.8872136175632477, Final Batch Loss: 0.33791783452033997\n",
      "Epoch 4555, Loss: 1.7884964793920517, Final Batch Loss: 0.14334146678447723\n",
      "Epoch 4556, Loss: 2.0073949992656708, Final Batch Loss: 0.24237343668937683\n",
      "Epoch 4557, Loss: 2.1779860854148865, Final Batch Loss: 0.6535715460777283\n",
      "Epoch 4558, Loss: 1.8675134181976318, Final Batch Loss: 0.3294287621974945\n",
      "Epoch 4559, Loss: 1.962435245513916, Final Batch Loss: 0.33686161041259766\n",
      "Epoch 4560, Loss: 1.7608706057071686, Final Batch Loss: 0.2952973544597626\n",
      "Epoch 4561, Loss: 1.9533962607383728, Final Batch Loss: 0.3686842918395996\n",
      "Epoch 4562, Loss: 2.338707983493805, Final Batch Loss: 0.6453707814216614\n",
      "Epoch 4563, Loss: 2.0026251822710037, Final Batch Loss: 0.18798570334911346\n",
      "Epoch 4564, Loss: 1.97495636343956, Final Batch Loss: 0.13565942645072937\n",
      "Epoch 4565, Loss: 2.1195872724056244, Final Batch Loss: 0.43841037154197693\n",
      "Epoch 4566, Loss: 1.795875608921051, Final Batch Loss: 0.2605907618999481\n",
      "Epoch 4567, Loss: 2.532750517129898, Final Batch Loss: 0.8136668801307678\n",
      "Epoch 4568, Loss: 2.4211248457431793, Final Batch Loss: 0.614521324634552\n",
      "Epoch 4569, Loss: 2.347556859254837, Final Batch Loss: 0.7299483418464661\n",
      "Epoch 4570, Loss: 2.0330958366394043, Final Batch Loss: 0.3930794298648834\n",
      "Epoch 4571, Loss: 2.334070771932602, Final Batch Loss: 0.6495378613471985\n",
      "Epoch 4572, Loss: 1.9113303124904633, Final Batch Loss: 0.3719145357608795\n",
      "Epoch 4573, Loss: 2.0426937639713287, Final Batch Loss: 0.26462653279304504\n",
      "Epoch 4574, Loss: 2.14687517285347, Final Batch Loss: 0.467439740896225\n",
      "Epoch 4575, Loss: 2.0538745522499084, Final Batch Loss: 0.44054287672042847\n",
      "Epoch 4576, Loss: 1.8279002010822296, Final Batch Loss: 0.3846719563007355\n",
      "Epoch 4577, Loss: 1.9500383138656616, Final Batch Loss: 0.3166680932044983\n",
      "Epoch 4578, Loss: 2.1373428106307983, Final Batch Loss: 0.4985073506832123\n",
      "Epoch 4579, Loss: 2.1539530754089355, Final Batch Loss: 0.5293526649475098\n",
      "Epoch 4580, Loss: 2.0323363542556763, Final Batch Loss: 0.45655718445777893\n",
      "Epoch 4581, Loss: 2.276553362607956, Final Batch Loss: 0.6823314428329468\n",
      "Epoch 4582, Loss: 1.875352293252945, Final Batch Loss: 0.2965202033519745\n",
      "Epoch 4583, Loss: 2.249904990196228, Final Batch Loss: 0.47131866216659546\n",
      "Epoch 4584, Loss: 2.0670224726200104, Final Batch Loss: 0.49521690607070923\n",
      "Epoch 4585, Loss: 2.2118844091892242, Final Batch Loss: 0.5410614609718323\n",
      "Epoch 4586, Loss: 2.001464009284973, Final Batch Loss: 0.36331915855407715\n",
      "Epoch 4587, Loss: 2.121187299489975, Final Batch Loss: 0.4252816140651703\n",
      "Epoch 4588, Loss: 2.0816609263420105, Final Batch Loss: 0.5631858110427856\n",
      "Epoch 4589, Loss: 2.0160343647003174, Final Batch Loss: 0.43405672907829285\n",
      "Epoch 4590, Loss: 1.683051660656929, Final Batch Loss: 0.22745348513126373\n",
      "Epoch 4591, Loss: 1.7345997393131256, Final Batch Loss: 0.1337704062461853\n",
      "Epoch 4592, Loss: 1.6632136553525925, Final Batch Loss: 0.15614710748195648\n",
      "Epoch 4593, Loss: 2.2177364230155945, Final Batch Loss: 0.5529896020889282\n",
      "Epoch 4594, Loss: 2.0577043890953064, Final Batch Loss: 0.5187174677848816\n",
      "Epoch 4595, Loss: 2.2116904854774475, Final Batch Loss: 0.42748573422431946\n",
      "Epoch 4596, Loss: 2.207140475511551, Final Batch Loss: 0.5424894690513611\n",
      "Epoch 4597, Loss: 1.7909744530916214, Final Batch Loss: 0.1258114129304886\n",
      "Epoch 4598, Loss: 1.9036811590194702, Final Batch Loss: 0.255438894033432\n",
      "Epoch 4599, Loss: 2.296223133802414, Final Batch Loss: 0.6314395666122437\n",
      "Epoch 4600, Loss: 1.783201515674591, Final Batch Loss: 0.27366000413894653\n",
      "Epoch 4601, Loss: 1.8055820763111115, Final Batch Loss: 0.2696070969104767\n",
      "Epoch 4602, Loss: 1.7558838948607445, Final Batch Loss: 0.11397796124219894\n",
      "Epoch 4603, Loss: 1.920402154326439, Final Batch Loss: 0.24794284999370575\n",
      "Epoch 4604, Loss: 2.1350872814655304, Final Batch Loss: 0.4352039396762848\n",
      "Epoch 4605, Loss: 1.690582886338234, Final Batch Loss: 0.2132556289434433\n",
      "Epoch 4606, Loss: 1.9977641999721527, Final Batch Loss: 0.28758785128593445\n",
      "Epoch 4607, Loss: 1.6850031018257141, Final Batch Loss: 0.21615800261497498\n",
      "Epoch 4608, Loss: 1.6239288970828056, Final Batch Loss: 0.1240142211318016\n",
      "Epoch 4609, Loss: 1.6977145373821259, Final Batch Loss: 0.1929399073123932\n",
      "Epoch 4610, Loss: 1.8699240386486053, Final Batch Loss: 0.38903719186782837\n",
      "Epoch 4611, Loss: 1.9181771874427795, Final Batch Loss: 0.4636729657649994\n",
      "Epoch 4612, Loss: 1.9838859140872955, Final Batch Loss: 0.4172172546386719\n",
      "Epoch 4613, Loss: 2.048662930727005, Final Batch Loss: 0.44742652773857117\n",
      "Epoch 4614, Loss: 1.8115763068199158, Final Batch Loss: 0.3995131552219391\n",
      "Epoch 4615, Loss: 1.6783547922968864, Final Batch Loss: 0.069823257625103\n",
      "Epoch 4616, Loss: 1.8133783638477325, Final Batch Loss: 0.31419578194618225\n",
      "Epoch 4617, Loss: 2.397511273622513, Final Batch Loss: 0.7753880620002747\n",
      "Epoch 4618, Loss: 1.894261047244072, Final Batch Loss: 0.20823408663272858\n",
      "Epoch 4619, Loss: 1.9837674498558044, Final Batch Loss: 0.3215651512145996\n",
      "Epoch 4620, Loss: 1.908915400505066, Final Batch Loss: 0.2707655131816864\n",
      "Epoch 4621, Loss: 1.868370160460472, Final Batch Loss: 0.1952049285173416\n",
      "Epoch 4622, Loss: 1.9885157644748688, Final Batch Loss: 0.28876250982284546\n",
      "Epoch 4623, Loss: 1.777134284377098, Final Batch Loss: 0.1646229773759842\n",
      "Epoch 4624, Loss: 1.9491789042949677, Final Batch Loss: 0.20452532172203064\n",
      "Epoch 4625, Loss: 2.4193849861621857, Final Batch Loss: 0.7844540476799011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4626, Loss: 2.1248431503772736, Final Batch Loss: 0.469221293926239\n",
      "Epoch 4627, Loss: 1.7815693467855453, Final Batch Loss: 0.1465885490179062\n",
      "Epoch 4628, Loss: 1.9876148104667664, Final Batch Loss: 0.4245476722717285\n",
      "Epoch 4629, Loss: 2.433813691139221, Final Batch Loss: 0.6561826467514038\n",
      "Epoch 4630, Loss: 2.214735060930252, Final Batch Loss: 0.5502678155899048\n",
      "Epoch 4631, Loss: 2.2249260246753693, Final Batch Loss: 0.5946188569068909\n",
      "Epoch 4632, Loss: 1.9059146344661713, Final Batch Loss: 0.17487618327140808\n",
      "Epoch 4633, Loss: 2.4994401931762695, Final Batch Loss: 0.622188150882721\n",
      "Epoch 4634, Loss: 1.9702368155121803, Final Batch Loss: 0.085464246571064\n",
      "Epoch 4635, Loss: 2.2020719051361084, Final Batch Loss: 0.34969907999038696\n",
      "Epoch 4636, Loss: 2.318197011947632, Final Batch Loss: 0.6503588557243347\n",
      "Epoch 4637, Loss: 2.1641846895217896, Final Batch Loss: 0.3280077576637268\n",
      "Epoch 4638, Loss: 2.265325754880905, Final Batch Loss: 0.372341126203537\n",
      "Epoch 4639, Loss: 2.1616027653217316, Final Batch Loss: 0.5758166909217834\n",
      "Epoch 4640, Loss: 1.8313963264226913, Final Batch Loss: 0.24638961255550385\n",
      "Epoch 4641, Loss: 1.7168260104954243, Final Batch Loss: 0.04387076571583748\n",
      "Epoch 4642, Loss: 2.03451344370842, Final Batch Loss: 0.3840976357460022\n",
      "Epoch 4643, Loss: 1.7971774339675903, Final Batch Loss: 0.2584973871707916\n",
      "Epoch 4644, Loss: 3.127775490283966, Final Batch Loss: 1.5629627704620361\n",
      "Epoch 4645, Loss: 1.8523830473423004, Final Batch Loss: 0.20402172207832336\n",
      "Epoch 4646, Loss: 1.82274030148983, Final Batch Loss: 0.17836426198482513\n",
      "Epoch 4647, Loss: 2.2676413655281067, Final Batch Loss: 0.681098461151123\n",
      "Epoch 4648, Loss: 2.102416068315506, Final Batch Loss: 0.43347111344337463\n",
      "Epoch 4649, Loss: 1.8066797256469727, Final Batch Loss: 0.17912551760673523\n",
      "Epoch 4650, Loss: 1.911864548921585, Final Batch Loss: 0.27186599373817444\n",
      "Epoch 4651, Loss: 2.2240520119667053, Final Batch Loss: 0.5025957226753235\n",
      "Epoch 4652, Loss: 1.9197162985801697, Final Batch Loss: 0.3682106137275696\n",
      "Epoch 4653, Loss: 2.0393171310424805, Final Batch Loss: 0.40887007117271423\n",
      "Epoch 4654, Loss: 1.6128020882606506, Final Batch Loss: 0.03920748829841614\n",
      "Epoch 4655, Loss: 2.102515399456024, Final Batch Loss: 0.4304918944835663\n",
      "Epoch 4656, Loss: 1.687946856021881, Final Batch Loss: 0.14716282486915588\n",
      "Epoch 4657, Loss: 2.0584148466587067, Final Batch Loss: 0.34234121441841125\n",
      "Epoch 4658, Loss: 1.9087108671665192, Final Batch Loss: 0.31158187985420227\n",
      "Epoch 4659, Loss: 1.886077493429184, Final Batch Loss: 0.19614669680595398\n",
      "Epoch 4660, Loss: 1.9835977256298065, Final Batch Loss: 0.27339282631874084\n",
      "Epoch 4661, Loss: 1.8753613829612732, Final Batch Loss: 0.3954712450504303\n",
      "Epoch 4662, Loss: 1.6773171722888947, Final Batch Loss: 0.245224267244339\n",
      "Epoch 4663, Loss: 1.9206545501947403, Final Batch Loss: 0.23956437408924103\n",
      "Epoch 4664, Loss: 1.6837605088949203, Final Batch Loss: 0.1586243063211441\n",
      "Epoch 4665, Loss: 1.8992913663387299, Final Batch Loss: 0.3716428279876709\n",
      "Epoch 4666, Loss: 1.9102142453193665, Final Batch Loss: 0.31473013758659363\n",
      "Epoch 4667, Loss: 1.9115517139434814, Final Batch Loss: 0.4281582236289978\n",
      "Epoch 4668, Loss: 2.36147540807724, Final Batch Loss: 0.6440812349319458\n",
      "Epoch 4669, Loss: 1.825645536184311, Final Batch Loss: 0.3762783706188202\n",
      "Epoch 4670, Loss: 1.7754203379154205, Final Batch Loss: 0.23860403895378113\n",
      "Epoch 4671, Loss: 1.8750348687171936, Final Batch Loss: 0.39849090576171875\n",
      "Epoch 4672, Loss: 1.8778159320354462, Final Batch Loss: 0.3920381963253021\n",
      "Epoch 4673, Loss: 1.6880019456148148, Final Batch Loss: 0.12116728723049164\n",
      "Epoch 4674, Loss: 2.0297708809375763, Final Batch Loss: 0.4518446922302246\n",
      "Epoch 4675, Loss: 1.8149587512016296, Final Batch Loss: 0.39957743883132935\n",
      "Epoch 4676, Loss: 1.7841914743185043, Final Batch Loss: 0.18887276947498322\n",
      "Epoch 4677, Loss: 2.2773369550704956, Final Batch Loss: 0.6344512701034546\n",
      "Epoch 4678, Loss: 2.2555831372737885, Final Batch Loss: 0.7159622311592102\n",
      "Epoch 4679, Loss: 1.9769128561019897, Final Batch Loss: 0.43132567405700684\n",
      "Epoch 4680, Loss: 2.3509432077407837, Final Batch Loss: 0.6572073101997375\n",
      "Epoch 4681, Loss: 1.736141249537468, Final Batch Loss: 0.17764247953891754\n",
      "Epoch 4682, Loss: 1.9838486909866333, Final Batch Loss: 0.3634192645549774\n",
      "Epoch 4683, Loss: 1.8760280013084412, Final Batch Loss: 0.3656701445579529\n",
      "Epoch 4684, Loss: 1.9935348331928253, Final Batch Loss: 0.4462936520576477\n",
      "Epoch 4685, Loss: 1.68202506005764, Final Batch Loss: 0.07703958451747894\n",
      "Epoch 4686, Loss: 1.918901652097702, Final Batch Loss: 0.31873518228530884\n",
      "Epoch 4687, Loss: 2.0265330374240875, Final Batch Loss: 0.5130459070205688\n",
      "Epoch 4688, Loss: 1.9315781891345978, Final Batch Loss: 0.40153592824935913\n",
      "Epoch 4689, Loss: 2.062562793493271, Final Batch Loss: 0.5091565847396851\n",
      "Epoch 4690, Loss: 2.143154591321945, Final Batch Loss: 0.5562312006950378\n",
      "Epoch 4691, Loss: 1.81913660466671, Final Batch Loss: 0.22440184652805328\n",
      "Epoch 4692, Loss: 1.9583130478858948, Final Batch Loss: 0.5021439790725708\n",
      "Epoch 4693, Loss: 1.945748582482338, Final Batch Loss: 0.18519602715969086\n",
      "Epoch 4694, Loss: 1.9374236464500427, Final Batch Loss: 0.36188745498657227\n",
      "Epoch 4695, Loss: 1.9678942561149597, Final Batch Loss: 0.42664578557014465\n",
      "Epoch 4696, Loss: 1.8705337345600128, Final Batch Loss: 0.23204278945922852\n",
      "Epoch 4697, Loss: 1.764412745833397, Final Batch Loss: 0.24043895304203033\n",
      "Epoch 4698, Loss: 1.9135485887527466, Final Batch Loss: 0.32164573669433594\n",
      "Epoch 4699, Loss: 1.6605460867285728, Final Batch Loss: 0.04175760596990585\n",
      "Epoch 4700, Loss: 2.024075299501419, Final Batch Loss: 0.6015152335166931\n",
      "Epoch 4701, Loss: 1.9652501195669174, Final Batch Loss: 0.15794529020786285\n",
      "Epoch 4702, Loss: 2.007656216621399, Final Batch Loss: 0.4209135174751282\n",
      "Epoch 4703, Loss: 2.0379148721694946, Final Batch Loss: 0.44849473237991333\n",
      "Epoch 4704, Loss: 1.7249427661299706, Final Batch Loss: 0.07520928233861923\n",
      "Epoch 4705, Loss: 2.562476694583893, Final Batch Loss: 0.9481492638587952\n",
      "Epoch 4706, Loss: 2.204854965209961, Final Batch Loss: 0.6168869733810425\n",
      "Epoch 4707, Loss: 2.4051308631896973, Final Batch Loss: 0.6652732491493225\n",
      "Epoch 4708, Loss: 2.4336487650871277, Final Batch Loss: 0.7332599759101868\n",
      "Epoch 4709, Loss: 2.415438622236252, Final Batch Loss: 0.7569433450698853\n",
      "Epoch 4710, Loss: 2.328716218471527, Final Batch Loss: 0.5319269299507141\n",
      "Epoch 4711, Loss: 2.125733584165573, Final Batch Loss: 0.2613706886768341\n",
      "Epoch 4712, Loss: 2.4238419234752655, Final Batch Loss: 0.5911868214607239\n",
      "Epoch 4713, Loss: 2.7388752698898315, Final Batch Loss: 1.0277199745178223\n",
      "Epoch 4714, Loss: 2.2449878454208374, Final Batch Loss: 0.4458419680595398\n",
      "Epoch 4715, Loss: 2.13235667347908, Final Batch Loss: 0.378030925989151\n",
      "Epoch 4716, Loss: 1.8987875878810883, Final Batch Loss: 0.2305619716644287\n",
      "Epoch 4717, Loss: 2.0938444435596466, Final Batch Loss: 0.5195661783218384\n",
      "Epoch 4718, Loss: 2.5506356358528137, Final Batch Loss: 0.9636855721473694\n",
      "Epoch 4719, Loss: 2.0287921726703644, Final Batch Loss: 0.1636209487915039\n",
      "Epoch 4720, Loss: 2.317869186401367, Final Batch Loss: 0.37354373931884766\n",
      "Epoch 4721, Loss: 2.170805811882019, Final Batch Loss: 0.44158920645713806\n",
      "Epoch 4722, Loss: 1.9110914468765259, Final Batch Loss: 0.3343907296657562\n",
      "Epoch 4723, Loss: 1.9231133162975311, Final Batch Loss: 0.15559503436088562\n",
      "Epoch 4724, Loss: 2.0523255467414856, Final Batch Loss: 0.4468289911746979\n",
      "Epoch 4725, Loss: 1.8900133669376373, Final Batch Loss: 0.31464308500289917\n",
      "Epoch 4726, Loss: 1.9668844938278198, Final Batch Loss: 0.37960007786750793\n",
      "Epoch 4727, Loss: 2.14639812707901, Final Batch Loss: 0.5613608956336975\n",
      "Epoch 4728, Loss: 1.8278798162937164, Final Batch Loss: 0.24423277378082275\n",
      "Epoch 4729, Loss: 1.9533831179141998, Final Batch Loss: 0.30842700600624084\n",
      "Epoch 4730, Loss: 1.8758484423160553, Final Batch Loss: 0.32127660512924194\n",
      "Epoch 4731, Loss: 1.606541845947504, Final Batch Loss: 0.01782912388443947\n",
      "Epoch 4732, Loss: 2.3075366020202637, Final Batch Loss: 0.5235615968704224\n",
      "Epoch 4733, Loss: 2.4704358875751495, Final Batch Loss: 0.8707606196403503\n",
      "Epoch 4734, Loss: 2.2349268198013306, Final Batch Loss: 0.33414506912231445\n",
      "Epoch 4735, Loss: 2.5256172716617584, Final Batch Loss: 0.7700415849685669\n",
      "Epoch 4736, Loss: 2.148057073354721, Final Batch Loss: 0.40737757086753845\n",
      "Epoch 4737, Loss: 2.39154976606369, Final Batch Loss: 0.7891968488693237\n",
      "Epoch 4738, Loss: 1.850678876042366, Final Batch Loss: 0.19042597711086273\n",
      "Epoch 4739, Loss: 1.9581641405820847, Final Batch Loss: 0.19988231360912323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4740, Loss: 1.988864779472351, Final Batch Loss: 0.3316541314125061\n",
      "Epoch 4741, Loss: 1.943661391735077, Final Batch Loss: 0.24247848987579346\n",
      "Epoch 4742, Loss: 1.9460584819316864, Final Batch Loss: 0.31314754486083984\n",
      "Epoch 4743, Loss: 1.9005275964736938, Final Batch Loss: 0.1715278923511505\n",
      "Epoch 4744, Loss: 2.1683252155780792, Final Batch Loss: 0.3701889216899872\n",
      "Epoch 4745, Loss: 1.91910220682621, Final Batch Loss: 0.19280339777469635\n",
      "Epoch 4746, Loss: 2.307113140821457, Final Batch Loss: 0.671108603477478\n",
      "Epoch 4747, Loss: 1.9739158749580383, Final Batch Loss: 0.45577892661094666\n",
      "Epoch 4748, Loss: 2.763256847858429, Final Batch Loss: 1.0689769983291626\n",
      "Epoch 4749, Loss: 1.7971859276294708, Final Batch Loss: 0.23282966017723083\n",
      "Epoch 4750, Loss: 1.8897165656089783, Final Batch Loss: 0.3639736771583557\n",
      "Epoch 4751, Loss: 1.8688844442367554, Final Batch Loss: 0.29161086678504944\n",
      "Epoch 4752, Loss: 2.0872673392295837, Final Batch Loss: 0.42984238266944885\n",
      "Epoch 4753, Loss: 2.3003913164138794, Final Batch Loss: 0.6857854723930359\n",
      "Epoch 4754, Loss: 2.332151383161545, Final Batch Loss: 0.6456776857376099\n",
      "Epoch 4755, Loss: 1.833540752530098, Final Batch Loss: 0.1673399955034256\n",
      "Epoch 4756, Loss: 2.0211254358291626, Final Batch Loss: 0.4106983244419098\n",
      "Epoch 4757, Loss: 1.8473471999168396, Final Batch Loss: 0.2622162103652954\n",
      "Epoch 4758, Loss: 2.2612405121326447, Final Batch Loss: 0.5474086403846741\n",
      "Epoch 4759, Loss: 1.8856585025787354, Final Batch Loss: 0.3883896768093109\n",
      "Epoch 4760, Loss: 2.449502319097519, Final Batch Loss: 1.0075558423995972\n",
      "Epoch 4761, Loss: 1.8250766694545746, Final Batch Loss: 0.32164138555526733\n",
      "Epoch 4762, Loss: 1.9103627502918243, Final Batch Loss: 0.22472432255744934\n",
      "Epoch 4763, Loss: 1.962219476699829, Final Batch Loss: 0.4183014929294586\n",
      "Epoch 4764, Loss: 2.109916865825653, Final Batch Loss: 0.48472270369529724\n",
      "Epoch 4765, Loss: 2.168054312467575, Final Batch Loss: 0.5020500421524048\n",
      "Epoch 4766, Loss: 2.037316173315048, Final Batch Loss: 0.33035287261009216\n",
      "Epoch 4767, Loss: 1.8798325061798096, Final Batch Loss: 0.26865243911743164\n",
      "Epoch 4768, Loss: 1.8615218102931976, Final Batch Loss: 0.42349711060523987\n",
      "Epoch 4769, Loss: 2.3943018317222595, Final Batch Loss: 0.860365092754364\n",
      "Epoch 4770, Loss: 2.0708054900169373, Final Batch Loss: 0.5599706768989563\n",
      "Epoch 4771, Loss: 1.9772735238075256, Final Batch Loss: 0.2773500978946686\n",
      "Epoch 4772, Loss: 1.7389963269233704, Final Batch Loss: 0.34051281213760376\n",
      "Epoch 4773, Loss: 2.1294220089912415, Final Batch Loss: 0.5114420056343079\n",
      "Epoch 4774, Loss: 1.9166441857814789, Final Batch Loss: 0.478423535823822\n",
      "Epoch 4775, Loss: 1.885331928730011, Final Batch Loss: 0.28755566477775574\n",
      "Epoch 4776, Loss: 1.9063626676797867, Final Batch Loss: 0.22682727873325348\n",
      "Epoch 4777, Loss: 2.1218879520893097, Final Batch Loss: 0.6783860921859741\n",
      "Epoch 4778, Loss: 1.7883304953575134, Final Batch Loss: 0.15821969509124756\n",
      "Epoch 4779, Loss: 1.8679286241531372, Final Batch Loss: 0.3487601578235626\n",
      "Epoch 4780, Loss: 1.8376296535134315, Final Batch Loss: 0.10520670562982559\n",
      "Epoch 4781, Loss: 1.8744491040706635, Final Batch Loss: 0.2588774561882019\n",
      "Epoch 4782, Loss: 2.283211201429367, Final Batch Loss: 0.5887411832809448\n",
      "Epoch 4783, Loss: 1.8336858004331589, Final Batch Loss: 0.21683497726917267\n",
      "Epoch 4784, Loss: 1.93450528383255, Final Batch Loss: 0.44433602690696716\n",
      "Epoch 4785, Loss: 2.4570454955101013, Final Batch Loss: 0.7836933135986328\n",
      "Epoch 4786, Loss: 1.7722437530755997, Final Batch Loss: 0.14270402491092682\n",
      "Epoch 4787, Loss: 2.039011150598526, Final Batch Loss: 0.3540995419025421\n",
      "Epoch 4788, Loss: 1.9233607351779938, Final Batch Loss: 0.3336915075778961\n",
      "Epoch 4789, Loss: 2.178348332643509, Final Batch Loss: 0.4672711193561554\n",
      "Epoch 4790, Loss: 1.8208384662866592, Final Batch Loss: 0.19203369319438934\n",
      "Epoch 4791, Loss: 1.57327139377594, Final Batch Loss: 0.09513020515441895\n",
      "Epoch 4792, Loss: 2.0756910741329193, Final Batch Loss: 0.37943169474601746\n",
      "Epoch 4793, Loss: 1.7468521744012833, Final Batch Loss: 0.16648928821086884\n",
      "Epoch 4794, Loss: 1.6747028231620789, Final Batch Loss: 0.13992729783058167\n",
      "Epoch 4795, Loss: 1.9981678426265717, Final Batch Loss: 0.3834887444972992\n",
      "Epoch 4796, Loss: 1.9363357424736023, Final Batch Loss: 0.4547230303287506\n",
      "Epoch 4797, Loss: 2.3202771842479706, Final Batch Loss: 0.6846533417701721\n",
      "Epoch 4798, Loss: 1.9294719994068146, Final Batch Loss: 0.35657379031181335\n",
      "Epoch 4799, Loss: 1.778677575290203, Final Batch Loss: 0.10530995577573776\n",
      "Epoch 4800, Loss: 1.537111297249794, Final Batch Loss: 0.06505753099918365\n",
      "Epoch 4801, Loss: 1.5688484236598015, Final Batch Loss: 0.12131043523550034\n",
      "Epoch 4802, Loss: 1.7634802609682083, Final Batch Loss: 0.17088119685649872\n",
      "Epoch 4803, Loss: 1.8609302341938019, Final Batch Loss: 0.3050527274608612\n",
      "Epoch 4804, Loss: 1.8172954618930817, Final Batch Loss: 0.2693157494068146\n",
      "Epoch 4805, Loss: 2.0753212571144104, Final Batch Loss: 0.5448818802833557\n",
      "Epoch 4806, Loss: 1.6182601377367973, Final Batch Loss: 0.04815562814474106\n",
      "Epoch 4807, Loss: 2.0418710708618164, Final Batch Loss: 0.4928077161312103\n",
      "Epoch 4808, Loss: 1.8904166519641876, Final Batch Loss: 0.2060263454914093\n",
      "Epoch 4809, Loss: 2.3365598022937775, Final Batch Loss: 0.8184910416603088\n",
      "Epoch 4810, Loss: 2.2356741428375244, Final Batch Loss: 0.6655250191688538\n",
      "Epoch 4811, Loss: 1.9231518507003784, Final Batch Loss: 0.34137001633644104\n",
      "Epoch 4812, Loss: 2.1459306478500366, Final Batch Loss: 0.5387561321258545\n",
      "Epoch 4813, Loss: 1.6628348231315613, Final Batch Loss: 0.12874555587768555\n",
      "Epoch 4814, Loss: 1.8301198482513428, Final Batch Loss: 0.24255311489105225\n",
      "Epoch 4815, Loss: 2.3977534472942352, Final Batch Loss: 0.765902042388916\n",
      "Epoch 4816, Loss: 1.686253011226654, Final Batch Loss: 0.21560898423194885\n",
      "Epoch 4817, Loss: 2.0654089748859406, Final Batch Loss: 0.5050433874130249\n",
      "Epoch 4818, Loss: 2.0991210341453552, Final Batch Loss: 0.5365048050880432\n",
      "Epoch 4819, Loss: 2.1547745168209076, Final Batch Loss: 0.5350310206413269\n",
      "Epoch 4820, Loss: 1.687467873096466, Final Batch Loss: 0.1593078076839447\n",
      "Epoch 4821, Loss: 1.8976445496082306, Final Batch Loss: 0.2448084056377411\n",
      "Epoch 4822, Loss: 1.7055327743291855, Final Batch Loss: 0.24873508512973785\n",
      "Epoch 4823, Loss: 1.7912943065166473, Final Batch Loss: 0.3340563178062439\n",
      "Epoch 4824, Loss: 1.9988183677196503, Final Batch Loss: 0.4263753294944763\n",
      "Epoch 4825, Loss: 2.0257084369659424, Final Batch Loss: 0.43772146105766296\n",
      "Epoch 4826, Loss: 2.181906759738922, Final Batch Loss: 0.46405288577079773\n",
      "Epoch 4827, Loss: 1.9951807260513306, Final Batch Loss: 0.3878374695777893\n",
      "Epoch 4828, Loss: 2.032970130443573, Final Batch Loss: 0.4069886803627014\n",
      "Epoch 4829, Loss: 2.201157569885254, Final Batch Loss: 0.504341185092926\n",
      "Epoch 4830, Loss: 1.9661257565021515, Final Batch Loss: 0.39656081795692444\n",
      "Epoch 4831, Loss: 1.9090735018253326, Final Batch Loss: 0.3487773537635803\n",
      "Epoch 4832, Loss: 1.721631482243538, Final Batch Loss: 0.18048782646656036\n",
      "Epoch 4833, Loss: 2.0454813838005066, Final Batch Loss: 0.36818429827690125\n",
      "Epoch 4834, Loss: 2.1164225935935974, Final Batch Loss: 0.47559982538223267\n",
      "Epoch 4835, Loss: 1.8475720882415771, Final Batch Loss: 0.21783533692359924\n",
      "Epoch 4836, Loss: 2.3420069217681885, Final Batch Loss: 0.5829606056213379\n",
      "Epoch 4837, Loss: 2.26497745513916, Final Batch Loss: 0.5917319655418396\n",
      "Epoch 4838, Loss: 2.00002658367157, Final Batch Loss: 0.34142664074897766\n",
      "Epoch 4839, Loss: 1.6842670291662216, Final Batch Loss: 0.16730673611164093\n",
      "Epoch 4840, Loss: 1.72698512673378, Final Batch Loss: 0.1626090109348297\n",
      "Epoch 4841, Loss: 1.8107957541942596, Final Batch Loss: 0.2583636939525604\n",
      "Epoch 4842, Loss: 1.8773136734962463, Final Batch Loss: 0.40579938888549805\n",
      "Epoch 4843, Loss: 1.6960634738206863, Final Batch Loss: 0.191606804728508\n",
      "Epoch 4844, Loss: 1.6650406271219254, Final Batch Loss: 0.2023230344057083\n",
      "Epoch 4845, Loss: 1.7583619803190231, Final Batch Loss: 0.15353889763355255\n",
      "Epoch 4846, Loss: 1.7220638990402222, Final Batch Loss: 0.1692448854446411\n",
      "Epoch 4847, Loss: 2.1463979184627533, Final Batch Loss: 0.5113561153411865\n",
      "Epoch 4848, Loss: 1.963700920343399, Final Batch Loss: 0.41812410950660706\n",
      "Epoch 4849, Loss: 1.713659182190895, Final Batch Loss: 0.2332695573568344\n",
      "Epoch 4850, Loss: 2.471121460199356, Final Batch Loss: 0.9673261642456055\n",
      "Epoch 4851, Loss: 2.3394680321216583, Final Batch Loss: 0.7664775848388672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4852, Loss: 1.9675841331481934, Final Batch Loss: 0.3860481083393097\n",
      "Epoch 4853, Loss: 2.3048817813396454, Final Batch Loss: 0.3671393394470215\n",
      "Epoch 4854, Loss: 2.3552302420139313, Final Batch Loss: 0.5636218786239624\n",
      "Epoch 4855, Loss: 1.952877789735794, Final Batch Loss: 0.25508221983909607\n",
      "Epoch 4856, Loss: 2.148837089538574, Final Batch Loss: 0.33328312635421753\n",
      "Epoch 4857, Loss: 2.061245083808899, Final Batch Loss: 0.44748738408088684\n",
      "Epoch 4858, Loss: 2.4120372235774994, Final Batch Loss: 0.8278090357780457\n",
      "Epoch 4859, Loss: 1.8641757369041443, Final Batch Loss: 0.36893147230148315\n",
      "Epoch 4860, Loss: 1.8949389457702637, Final Batch Loss: 0.4287625849246979\n",
      "Epoch 4861, Loss: 1.8254368603229523, Final Batch Loss: 0.33065319061279297\n",
      "Epoch 4862, Loss: 2.298447549343109, Final Batch Loss: 0.6067169308662415\n",
      "Epoch 4863, Loss: 2.03266105055809, Final Batch Loss: 0.2513699233531952\n",
      "Epoch 4864, Loss: 1.9070889055728912, Final Batch Loss: 0.4025777280330658\n",
      "Epoch 4865, Loss: 2.5410573482513428, Final Batch Loss: 0.8032010197639465\n",
      "Epoch 4866, Loss: 2.005428910255432, Final Batch Loss: 0.5772048234939575\n",
      "Epoch 4867, Loss: 2.0216944813728333, Final Batch Loss: 0.33332565426826477\n",
      "Epoch 4868, Loss: 2.073712795972824, Final Batch Loss: 0.36036697030067444\n",
      "Epoch 4869, Loss: 1.9903192520141602, Final Batch Loss: 0.4371621012687683\n",
      "Epoch 4870, Loss: 2.5097831189632416, Final Batch Loss: 0.7174707055091858\n",
      "Epoch 4871, Loss: 2.181375205516815, Final Batch Loss: 0.49064186215400696\n",
      "Epoch 4872, Loss: 2.0357568860054016, Final Batch Loss: 0.4365226924419403\n",
      "Epoch 4873, Loss: 1.8706962168216705, Final Batch Loss: 0.3160322606563568\n",
      "Epoch 4874, Loss: 1.8728336691856384, Final Batch Loss: 0.3228670656681061\n",
      "Epoch 4875, Loss: 2.100923627614975, Final Batch Loss: 0.5617946982383728\n",
      "Epoch 4876, Loss: 2.1660461127758026, Final Batch Loss: 0.43863800168037415\n",
      "Epoch 4877, Loss: 1.840326726436615, Final Batch Loss: 0.2500855028629303\n",
      "Epoch 4878, Loss: 2.118320792913437, Final Batch Loss: 0.6142565608024597\n",
      "Epoch 4879, Loss: 1.8581926226615906, Final Batch Loss: 0.2739216387271881\n",
      "Epoch 4880, Loss: 1.8791466653347015, Final Batch Loss: 0.31380537152290344\n",
      "Epoch 4881, Loss: 2.289423644542694, Final Batch Loss: 0.5795594453811646\n",
      "Epoch 4882, Loss: 1.9772753715515137, Final Batch Loss: 0.3314783573150635\n",
      "Epoch 4883, Loss: 2.046432912349701, Final Batch Loss: 0.4450710117816925\n",
      "Epoch 4884, Loss: 2.1287923455238342, Final Batch Loss: 0.5497663617134094\n",
      "Epoch 4885, Loss: 2.1772029399871826, Final Batch Loss: 0.6309316754341125\n",
      "Epoch 4886, Loss: 1.9458563327789307, Final Batch Loss: 0.4086948037147522\n",
      "Epoch 4887, Loss: 1.879697024822235, Final Batch Loss: 0.1684800386428833\n",
      "Epoch 4888, Loss: 2.340157628059387, Final Batch Loss: 0.7676502466201782\n",
      "Epoch 4889, Loss: 1.8989648073911667, Final Batch Loss: 0.21186797320842743\n",
      "Epoch 4890, Loss: 2.243668019771576, Final Batch Loss: 0.6580050587654114\n",
      "Epoch 4891, Loss: 2.316609501838684, Final Batch Loss: 0.8301348090171814\n",
      "Epoch 4892, Loss: 1.954033225774765, Final Batch Loss: 0.5274578928947449\n",
      "Epoch 4893, Loss: 2.089180737733841, Final Batch Loss: 0.5746639966964722\n",
      "Epoch 4894, Loss: 2.3452490270137787, Final Batch Loss: 0.7401889562606812\n",
      "Epoch 4895, Loss: 1.971433937549591, Final Batch Loss: 0.38689476251602173\n",
      "Epoch 4896, Loss: 1.74990676343441, Final Batch Loss: 0.21177415549755096\n",
      "Epoch 4897, Loss: 2.1545777916908264, Final Batch Loss: 0.5866561532020569\n",
      "Epoch 4898, Loss: 1.9548121690750122, Final Batch Loss: 0.22832825779914856\n",
      "Epoch 4899, Loss: 1.829029768705368, Final Batch Loss: 0.24522927403450012\n",
      "Epoch 4900, Loss: 1.902724415063858, Final Batch Loss: 0.2925000786781311\n",
      "Epoch 4901, Loss: 1.9382580816745758, Final Batch Loss: 0.29459914565086365\n",
      "Epoch 4902, Loss: 2.165538936853409, Final Batch Loss: 0.7501093149185181\n",
      "Epoch 4903, Loss: 1.8140449821949005, Final Batch Loss: 0.3093286156654358\n",
      "Epoch 4904, Loss: 1.817105621099472, Final Batch Loss: 0.16020670533180237\n",
      "Epoch 4905, Loss: 1.8712280988693237, Final Batch Loss: 0.29139092564582825\n",
      "Epoch 4906, Loss: 1.771666780114174, Final Batch Loss: 0.23130305111408234\n",
      "Epoch 4907, Loss: 1.827774554491043, Final Batch Loss: 0.29315200448036194\n",
      "Epoch 4908, Loss: 2.011923670768738, Final Batch Loss: 0.31584760546684265\n",
      "Epoch 4909, Loss: 1.8660743832588196, Final Batch Loss: 0.28410667181015015\n",
      "Epoch 4910, Loss: 1.824188843369484, Final Batch Loss: 0.15511934459209442\n",
      "Epoch 4911, Loss: 1.8098402172327042, Final Batch Loss: 0.17802448570728302\n",
      "Epoch 4912, Loss: 1.8407767117023468, Final Batch Loss: 0.4028712213039398\n",
      "Epoch 4913, Loss: 1.9368363916873932, Final Batch Loss: 0.2516040802001953\n",
      "Epoch 4914, Loss: 2.179681748151779, Final Batch Loss: 0.6359295845031738\n",
      "Epoch 4915, Loss: 1.8742032200098038, Final Batch Loss: 0.2463175505399704\n",
      "Epoch 4916, Loss: 2.1582891941070557, Final Batch Loss: 0.5318090915679932\n",
      "Epoch 4917, Loss: 2.1559199392795563, Final Batch Loss: 0.48245784640312195\n",
      "Epoch 4918, Loss: 2.1460262537002563, Final Batch Loss: 0.5337858200073242\n",
      "Epoch 4919, Loss: 2.103949248790741, Final Batch Loss: 0.511566162109375\n",
      "Epoch 4920, Loss: 1.970067322254181, Final Batch Loss: 0.40497714281082153\n",
      "Epoch 4921, Loss: 2.1067076325416565, Final Batch Loss: 0.4986504912376404\n",
      "Epoch 4922, Loss: 1.81249038875103, Final Batch Loss: 0.22492878139019012\n",
      "Epoch 4923, Loss: 1.9036279320716858, Final Batch Loss: 0.37259015440940857\n",
      "Epoch 4924, Loss: 2.0072283297777176, Final Batch Loss: 0.24546416103839874\n",
      "Epoch 4925, Loss: 2.2813876271247864, Final Batch Loss: 0.5547072887420654\n",
      "Epoch 4926, Loss: 2.043053388595581, Final Batch Loss: 0.2858312129974365\n",
      "Epoch 4927, Loss: 1.8653669506311417, Final Batch Loss: 0.228068009018898\n",
      "Epoch 4928, Loss: 1.6861299127340317, Final Batch Loss: 0.23800741136074066\n",
      "Epoch 4929, Loss: 2.415725499391556, Final Batch Loss: 0.8493375778198242\n",
      "Epoch 4930, Loss: 2.033932536840439, Final Batch Loss: 0.5036509037017822\n",
      "Epoch 4931, Loss: 1.9961247444152832, Final Batch Loss: 0.5165500640869141\n",
      "Epoch 4932, Loss: 3.5830778777599335, Final Batch Loss: 1.8579987287521362\n",
      "Epoch 4933, Loss: 2.1915964782238007, Final Batch Loss: 0.32798463106155396\n",
      "Epoch 4934, Loss: 2.276365250349045, Final Batch Loss: 0.47399991750717163\n",
      "Epoch 4935, Loss: 2.3577381372451782, Final Batch Loss: 0.825550377368927\n",
      "Epoch 4936, Loss: 2.5520194470882416, Final Batch Loss: 0.9014541506767273\n",
      "Epoch 4937, Loss: 2.229425936937332, Final Batch Loss: 0.3772273063659668\n",
      "Epoch 4938, Loss: 1.9780200868844986, Final Batch Loss: 0.1048322468996048\n",
      "Epoch 4939, Loss: 1.9442902952432632, Final Batch Loss: 0.16899259388446808\n",
      "Epoch 4940, Loss: 2.29209902882576, Final Batch Loss: 0.5949963331222534\n",
      "Epoch 4941, Loss: 2.4427548944950104, Final Batch Loss: 0.7227115035057068\n",
      "Epoch 4942, Loss: 1.8755267709493637, Final Batch Loss: 0.20276646316051483\n",
      "Epoch 4943, Loss: 2.1267279535531998, Final Batch Loss: 0.23072998225688934\n",
      "Epoch 4944, Loss: 2.537049502134323, Final Batch Loss: 0.8751999735832214\n",
      "Epoch 4945, Loss: 2.195254474878311, Final Batch Loss: 0.4424769878387451\n",
      "Epoch 4946, Loss: 2.0154826045036316, Final Batch Loss: 0.4847252070903778\n",
      "Epoch 4947, Loss: 2.0001902133226395, Final Batch Loss: 0.2331434041261673\n",
      "Epoch 4948, Loss: 1.9250179529190063, Final Batch Loss: 0.29120299220085144\n",
      "Epoch 4949, Loss: 2.0381439328193665, Final Batch Loss: 0.38146069645881653\n",
      "Epoch 4950, Loss: 1.9423643052577972, Final Batch Loss: 0.39678654074668884\n",
      "Epoch 4951, Loss: 1.8510045409202576, Final Batch Loss: 0.2536940276622772\n",
      "Epoch 4952, Loss: 1.621090091764927, Final Batch Loss: 0.044460661709308624\n",
      "Epoch 4953, Loss: 1.771909922361374, Final Batch Loss: 0.24107769131660461\n",
      "Epoch 4954, Loss: 1.8223737925291061, Final Batch Loss: 0.15823854506015778\n",
      "Epoch 4955, Loss: 2.066923290491104, Final Batch Loss: 0.41449174284935\n",
      "Epoch 4956, Loss: 1.7560314908623695, Final Batch Loss: 0.0712314322590828\n",
      "Epoch 4957, Loss: 2.352313816547394, Final Batch Loss: 0.7219036817550659\n",
      "Epoch 4958, Loss: 1.8604649305343628, Final Batch Loss: 0.25802502036094666\n",
      "Epoch 4959, Loss: 1.8908296823501587, Final Batch Loss: 0.3149583339691162\n",
      "Epoch 4960, Loss: 1.7317734062671661, Final Batch Loss: 0.26964372396469116\n",
      "Epoch 4961, Loss: 1.7777499705553055, Final Batch Loss: 0.1862308830022812\n",
      "Epoch 4962, Loss: 2.0371627509593964, Final Batch Loss: 0.39227294921875\n",
      "Epoch 4963, Loss: 1.8184816613793373, Final Batch Loss: 0.12060428410768509\n",
      "Epoch 4964, Loss: 1.9635767042636871, Final Batch Loss: 0.4193664491176605\n",
      "Epoch 4965, Loss: 2.085933029651642, Final Batch Loss: 0.480819970369339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4966, Loss: 1.8408014327287674, Final Batch Loss: 0.22723738849163055\n",
      "Epoch 4967, Loss: 2.137038916349411, Final Batch Loss: 0.3034273684024811\n",
      "Epoch 4968, Loss: 1.8120130747556686, Final Batch Loss: 0.11289118230342865\n",
      "Epoch 4969, Loss: 1.859479621052742, Final Batch Loss: 0.20716558396816254\n",
      "Epoch 4970, Loss: 2.5615617632865906, Final Batch Loss: 0.8328565359115601\n",
      "Epoch 4971, Loss: 1.9149732887744904, Final Batch Loss: 0.23252293467521667\n",
      "Epoch 4972, Loss: 2.010981649160385, Final Batch Loss: 0.4358613193035126\n",
      "Epoch 4973, Loss: 2.228259265422821, Final Batch Loss: 0.5419691801071167\n",
      "Epoch 4974, Loss: 1.929139494895935, Final Batch Loss: 0.3113035559654236\n",
      "Epoch 4975, Loss: 1.988097220659256, Final Batch Loss: 0.448893278837204\n",
      "Epoch 4976, Loss: 2.0370469987392426, Final Batch Loss: 0.3298480808734894\n",
      "Epoch 4977, Loss: 2.056732654571533, Final Batch Loss: 0.4686501622200012\n",
      "Epoch 4978, Loss: 1.9446569681167603, Final Batch Loss: 0.3653326630592346\n",
      "Epoch 4979, Loss: 1.7593269497156143, Final Batch Loss: 0.2466483861207962\n",
      "Epoch 4980, Loss: 2.2317008674144745, Final Batch Loss: 0.5575081706047058\n",
      "Epoch 4981, Loss: 1.8935455083847046, Final Batch Loss: 0.38416749238967896\n",
      "Epoch 4982, Loss: 1.9262801557779312, Final Batch Loss: 0.1902320235967636\n",
      "Epoch 4983, Loss: 1.7884152233600616, Final Batch Loss: 0.3359573781490326\n",
      "Epoch 4984, Loss: 1.9581847488880157, Final Batch Loss: 0.3543841540813446\n",
      "Epoch 4985, Loss: 1.894180417060852, Final Batch Loss: 0.37777701020240784\n",
      "Epoch 4986, Loss: 1.8953121602535248, Final Batch Loss: 0.34178489446640015\n",
      "Epoch 4987, Loss: 2.049516797065735, Final Batch Loss: 0.4507119655609131\n",
      "Epoch 4988, Loss: 1.7726482450962067, Final Batch Loss: 0.16614416241645813\n",
      "Epoch 4989, Loss: 2.001358449459076, Final Batch Loss: 0.44631505012512207\n",
      "Epoch 4990, Loss: 1.8692228496074677, Final Batch Loss: 0.41869717836380005\n",
      "Epoch 4991, Loss: 1.8097167611122131, Final Batch Loss: 0.2718253433704376\n",
      "Epoch 4992, Loss: 2.071899563074112, Final Batch Loss: 0.4807508885860443\n",
      "Epoch 4993, Loss: 2.034460663795471, Final Batch Loss: 0.4717889428138733\n",
      "Epoch 4994, Loss: 1.7867047935724258, Final Batch Loss: 0.2213352769613266\n",
      "Epoch 4995, Loss: 1.8495587408542633, Final Batch Loss: 0.32438644766807556\n",
      "Epoch 4996, Loss: 2.183953195810318, Final Batch Loss: 0.5669590830802917\n",
      "Epoch 4997, Loss: 1.9794138073921204, Final Batch Loss: 0.3589692711830139\n",
      "Epoch 4998, Loss: 1.8385501205921173, Final Batch Loss: 0.2716909945011139\n",
      "Epoch 4999, Loss: 2.108929008245468, Final Batch Loss: 0.5509548187255859\n",
      "Epoch 5000, Loss: 1.9664057344198227, Final Batch Loss: 0.20806001126766205\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  0  0  0  0  0  0  0]\n",
      " [ 0 23  1  0  0  3  0  2]\n",
      " [ 0  0 25  2  0  0  0  0]\n",
      " [ 0  0  2 26  0  0  2  3]\n",
      " [ 5  4  0  0 17  3  0  0]\n",
      " [ 1  0  0  0  0 30  0  0]\n",
      " [ 0  3  0  2  0  0 28  0]\n",
      " [ 0  0  0  0  0  0  0 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85714   1.00000   0.92308        36\n",
      "           1    0.76667   0.79310   0.77966        29\n",
      "           2    0.89286   0.92593   0.90909        27\n",
      "           3    0.86667   0.78788   0.82540        33\n",
      "           4    1.00000   0.58621   0.73913        29\n",
      "           5    0.83333   0.96774   0.89552        31\n",
      "           6    0.93333   0.84848   0.88889        33\n",
      "           7    0.87805   1.00000   0.93506        36\n",
      "\n",
      "    accuracy                        0.87008       254\n",
      "   macro avg    0.87851   0.86367   0.86198       254\n",
      "weighted avg    0.87811   0.87008   0.86542       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples + [7] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples  + [7] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples + [7] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  2  0  0  0  4  2  0]\n",
      " [ 2 22  1  1  0  3  0  1]\n",
      " [ 0  1 20  3  0  2  0  4]\n",
      " [ 2  7  1 17  0  3  0  0]\n",
      " [ 7  1  1  0 18  1  1  1]\n",
      " [ 0  2  3  0  0 25  0  0]\n",
      " [ 0  1  2  0  0  1 25  1]\n",
      " [ 2  4  1  0  0  3  2 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.62857   0.73333   0.67692        30\n",
      "           1    0.55000   0.73333   0.62857        30\n",
      "           2    0.68966   0.66667   0.67797        30\n",
      "           3    0.80952   0.56667   0.66667        30\n",
      "           4    1.00000   0.60000   0.75000        30\n",
      "           5    0.59524   0.83333   0.69444        30\n",
      "           6    0.83333   0.83333   0.83333        30\n",
      "           7    0.72000   0.60000   0.65455        30\n",
      "\n",
      "    accuracy                        0.69583       240\n",
      "   macro avg    0.72829   0.69583   0.69781       240\n",
      "weighted avg    0.72829   0.69583   0.69781       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
