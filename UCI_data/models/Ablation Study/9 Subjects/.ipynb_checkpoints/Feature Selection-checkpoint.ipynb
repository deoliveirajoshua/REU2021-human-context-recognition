{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14, 17, 19]\n",
    "n_iters = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance - Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25    409\n",
      "21    408\n",
      "26    392\n",
      "30    383\n",
      "28    382\n",
      "27    376\n",
      "23    372\n",
      "17    368\n",
      "16    366\n",
      "19    360\n",
      "1     347\n",
      "29    344\n",
      "3     341\n",
      "15    328\n",
      "6     325\n",
      "14    323\n",
      "22    321\n",
      "11    316\n",
      "7     308\n",
      "5     302\n",
      "8     281\n",
      "Name: Subject, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "names = name_dataframe.values.tolist()\n",
    "names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "data.columns = names #Setting column names\n",
    "\n",
    "X_train = data\n",
    "\n",
    "y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train_activity.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "print(GAN_data['Subject'].value_counts())\n",
    "GAN_data = GAN_data[GAN_data['Activity'].isin(activities)]\n",
    "GAN_data = GAN_data[GAN_data['Subject'].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = GAN_data.iloc[:,:-2].values\n",
    "y_train = GAN_data.iloc[:,-1].values #Subject Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    elif y_train[k] == 5:\n",
    "        y_train[k] = 2\n",
    "    elif y_train[k] == 7:\n",
    "        y_train[k] = 3\n",
    "    elif y_train[k] == 8:\n",
    "        y_train[k] = 4\n",
    "    elif y_train[k] == 11:\n",
    "        y_train[k] = 5\n",
    "    elif y_train[k] == 14:\n",
    "        y_train[k] = 6\n",
    "    elif y_train[k] == 17:\n",
    "        y_train[k] = 7\n",
    "    else:\n",
    "        y_train[k] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "total_sum = np.zeros(561,)\n",
    "\n",
    "for k in range(n_iters):\n",
    "    model = RandomForestClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    importance = model.feature_importances_\n",
    "    total_sum = total_sum + importance\n",
    "\n",
    "averaged_importance = total_sum / n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_importance = list(averaged_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 42, 50, 51, 53, 54, 55, 57, 58, 474, 558, 559, 560]\n"
     ]
    }
   ],
   "source": [
    "def importance_filter(averaged_importance):\n",
    "    return averaged_importance > 0.01\n",
    "\n",
    "output = [idx for idx, element in enumerate(averaged_importance) if importance_filter(element)]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = []\n",
    "\n",
    "for index in range(len(output)):\n",
    "    sub_features.append(GAN_data.columns[output[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['42 tGravityAcc-mean()-Y',\n",
       " '43 tGravityAcc-mean()-Z',\n",
       " '51 tGravityAcc-max()-Y',\n",
       " '52 tGravityAcc-max()-Z',\n",
       " '54 tGravityAcc-min()-Y',\n",
       " '55 tGravityAcc-min()-Z',\n",
       " '56 tGravityAcc-sma()',\n",
       " '58 tGravityAcc-energy()-Y',\n",
       " '59 tGravityAcc-energy()-Z',\n",
       " '475 fBodyGyro-bandsEnergy()-1,8',\n",
       " '559 angle(X,gravityMean)',\n",
       " '560 angle(Y,gravityMean)',\n",
       " '561 angle(Z,gravityMean)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance - Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "names = name_dataframe.values.tolist()\n",
    "names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "data.columns = names #Setting column names\n",
    "\n",
    "#X_train = data.loc[:,'1 tBodyAcc-mean()-X':'40 tBodyAcc-correlation()-Y,Z'] #Selecting only acceleration columns\n",
    "\n",
    "X_train = data\n",
    "\n",
    "y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train_activity.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "GAN_data = GAN_data[GAN_data['Activity'].isin(activities)]\n",
    "GAN_data = GAN_data[GAN_data['Subject'].isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = GAN_data.iloc[:,:-2].values\n",
    "y_train = GAN_data.iloc[:,-2].values #Activity Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "total_sum = np.zeros(561,)\n",
    "\n",
    "for k in range(n_iters):\n",
    "    model = RandomForestClassifier()\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    importance = model.feature_importances_\n",
    "    total_sum = total_sum + importance\n",
    "    \n",
    "# summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "#     print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()\n",
    "\n",
    "averaged_importance = total_sum / n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_importance = list(averaged_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 16, 201, 202, 214, 215, 265, 268, 271, 281, 310, 314, 381, 503, 504, 508]\n"
     ]
    }
   ],
   "source": [
    "output_act = [idx for idx, element in enumerate(averaged_importance) if importance_filter(element)]\n",
    "print(output_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_features = []\n",
    "\n",
    "for index in range(len(output_act)):\n",
    "    act_features.append(GAN_data.columns[output_act[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 tBodyAcc-std()-X',\n",
       " '10 tBodyAcc-max()-X',\n",
       " '17 tBodyAcc-energy()-X',\n",
       " '202 tBodyAccMag-std()',\n",
       " '203 tBodyAccMag-mad()',\n",
       " '215 tGravityAccMag-std()',\n",
       " '216 tGravityAccMag-mad()',\n",
       " '266 fBodyAcc-mean()-X',\n",
       " '269 fBodyAcc-std()-X',\n",
       " '272 fBodyAcc-mad()-X',\n",
       " '282 fBodyAcc-energy()-X',\n",
       " '311 fBodyAcc-bandsEnergy()-1,16',\n",
       " '315 fBodyAcc-bandsEnergy()-1,24',\n",
       " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
       " '504 fBodyAccMag-std()',\n",
       " '505 fBodyAccMag-mad()',\n",
       " '509 fBodyAccMag-energy()']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_data(list1, list2):\n",
    "    result = False\n",
    "  \n",
    "    # traverse in the 1st list\n",
    "    for x in list1:\n",
    "  \n",
    "        # traverse in the 2nd list\n",
    "        for y in list2:\n",
    "    \n",
    "            # if one common\n",
    "            if x == y:\n",
    "                result = True\n",
    "                return result \n",
    "                  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common indices for activity/subject classification.\n"
     ]
    }
   ],
   "source": [
    "result = common_data(output_act, output)\n",
    "\n",
    "if result == False:\n",
    "    print(\"No common indices for activity/subject classification.\")\n",
    "else:\n",
    "    print(\"At least one index is shared between the two lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
