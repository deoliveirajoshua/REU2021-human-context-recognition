{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 6)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.292161643505096, Final Batch Loss: 0.9976381659507751\n",
      "Epoch 2, Loss: 4.375752091407776, Final Batch Loss: 1.0886656045913696\n",
      "Epoch 3, Loss: 4.346004009246826, Final Batch Loss: 1.0643161535263062\n",
      "Epoch 4, Loss: 4.315779328346252, Final Batch Loss: 1.0391725301742554\n",
      "Epoch 5, Loss: 4.278451085090637, Final Batch Loss: 1.0078141689300537\n",
      "Epoch 6, Loss: 4.545019745826721, Final Batch Loss: 1.2809569835662842\n",
      "Epoch 7, Loss: 4.48827052116394, Final Batch Loss: 1.2276256084442139\n",
      "Epoch 8, Loss: 4.518041253089905, Final Batch Loss: 1.2628705501556396\n",
      "Epoch 9, Loss: 4.263685464859009, Final Batch Loss: 1.0135387182235718\n",
      "Epoch 10, Loss: 4.252756237983704, Final Batch Loss: 1.0044337511062622\n",
      "Epoch 11, Loss: 4.2537665367126465, Final Batch Loss: 1.01286780834198\n",
      "Epoch 12, Loss: 4.233704447746277, Final Batch Loss: 1.0008234977722168\n",
      "Epoch 13, Loss: 4.487145781517029, Final Batch Loss: 1.2670018672943115\n",
      "Epoch 14, Loss: 4.177056431770325, Final Batch Loss: 0.9624365568161011\n",
      "Epoch 15, Loss: 4.4176318645477295, Final Batch Loss: 1.2193583250045776\n",
      "Epoch 16, Loss: 4.17990106344223, Final Batch Loss: 0.9915151000022888\n",
      "Epoch 17, Loss: 4.132579922676086, Final Batch Loss: 0.965347170829773\n",
      "Epoch 18, Loss: 4.026601254940033, Final Batch Loss: 0.8896641135215759\n",
      "Epoch 19, Loss: 4.0024829506874084, Final Batch Loss: 0.8986483216285706\n",
      "Epoch 20, Loss: 4.0080496072769165, Final Batch Loss: 0.9345250129699707\n",
      "Epoch 21, Loss: 4.257270574569702, Final Batch Loss: 1.2285969257354736\n",
      "Epoch 22, Loss: 3.848346531391144, Final Batch Loss: 0.8380680084228516\n",
      "Epoch 23, Loss: 4.590375661849976, Final Batch Loss: 1.6140496730804443\n",
      "Epoch 24, Loss: 3.7921942472457886, Final Batch Loss: 0.855921745300293\n",
      "Epoch 25, Loss: 3.8010717034339905, Final Batch Loss: 0.9271245002746582\n",
      "Epoch 26, Loss: 4.01520711183548, Final Batch Loss: 1.169819951057434\n",
      "Epoch 27, Loss: 3.9691070318222046, Final Batch Loss: 1.1580121517181396\n",
      "Epoch 28, Loss: 4.134808242321014, Final Batch Loss: 1.373976230621338\n",
      "Epoch 29, Loss: 3.8774126172065735, Final Batch Loss: 1.1523305177688599\n",
      "Epoch 30, Loss: 3.386716306209564, Final Batch Loss: 0.7265016436576843\n",
      "Epoch 31, Loss: 3.6862775683403015, Final Batch Loss: 1.0942914485931396\n",
      "Epoch 32, Loss: 3.091306746006012, Final Batch Loss: 0.5822827219963074\n",
      "Epoch 33, Loss: 3.543664872646332, Final Batch Loss: 1.1476848125457764\n",
      "Epoch 34, Loss: 3.444972574710846, Final Batch Loss: 1.1063166856765747\n",
      "Epoch 35, Loss: 3.0640360713005066, Final Batch Loss: 0.7981861233711243\n",
      "Epoch 36, Loss: 2.792031407356262, Final Batch Loss: 0.6099057197570801\n",
      "Epoch 37, Loss: 2.3550166487693787, Final Batch Loss: 0.24866807460784912\n",
      "Epoch 38, Loss: 2.3334850072860718, Final Batch Loss: 0.2838175296783447\n",
      "Epoch 39, Loss: 2.0644979625940323, Final Batch Loss: 0.18865229189395905\n",
      "Epoch 40, Loss: 2.023542493581772, Final Batch Loss: 0.23031571507453918\n",
      "Epoch 41, Loss: 2.6548105478286743, Final Batch Loss: 0.9060444831848145\n",
      "Epoch 42, Loss: 2.4042983055114746, Final Batch Loss: 0.7930755019187927\n",
      "Epoch 43, Loss: 2.6307820975780487, Final Batch Loss: 1.0708656311035156\n",
      "Epoch 44, Loss: 2.21610689163208, Final Batch Loss: 0.6942110061645508\n",
      "Epoch 45, Loss: 1.8905980587005615, Final Batch Loss: 0.4301950931549072\n",
      "Epoch 46, Loss: 1.9131110310554504, Final Batch Loss: 0.5202330946922302\n",
      "Epoch 47, Loss: 1.8578137755393982, Final Batch Loss: 0.5309033989906311\n",
      "Epoch 48, Loss: 1.9030984342098236, Final Batch Loss: 0.6400215029716492\n",
      "Epoch 49, Loss: 1.2359593659639359, Final Batch Loss: 0.029590949416160583\n",
      "Epoch 50, Loss: 1.8087915778160095, Final Batch Loss: 0.7228063344955444\n",
      "Epoch 51, Loss: 1.1529943943023682, Final Batch Loss: 0.0917980968952179\n",
      "Epoch 52, Loss: 1.4091294407844543, Final Batch Loss: 0.2859611511230469\n",
      "Epoch 53, Loss: 1.3195800483226776, Final Batch Loss: 0.1645365059375763\n",
      "Epoch 54, Loss: 1.3668619096279144, Final Batch Loss: 0.2833915650844574\n",
      "Epoch 55, Loss: 1.1469444036483765, Final Batch Loss: 0.1541348099708557\n",
      "Epoch 56, Loss: 1.0337837412953377, Final Batch Loss: 0.1000443771481514\n",
      "Epoch 57, Loss: 0.9753464311361313, Final Batch Loss: 0.19247843325138092\n",
      "Epoch 58, Loss: 1.545788750052452, Final Batch Loss: 0.7586466670036316\n",
      "Epoch 59, Loss: 0.9355800598859787, Final Batch Loss: 0.17461369931697845\n",
      "Epoch 60, Loss: 0.7974516525864601, Final Batch Loss: 0.09889208525419235\n",
      "Epoch 61, Loss: 0.7239738660282455, Final Batch Loss: 0.00043275527423247695\n",
      "Epoch 62, Loss: 0.7817940004169941, Final Batch Loss: 0.055279094725847244\n",
      "Epoch 63, Loss: 1.2203476130962372, Final Batch Loss: 0.5526634454727173\n",
      "Epoch 64, Loss: 0.7306335531175137, Final Batch Loss: 0.054734017699956894\n",
      "Epoch 65, Loss: 0.6682079583406448, Final Batch Loss: 0.003218710422515869\n",
      "Epoch 66, Loss: 0.8116836324334145, Final Batch Loss: 0.05130227655172348\n",
      "Epoch 67, Loss: 0.7524389000609517, Final Batch Loss: 0.007458341307938099\n",
      "Epoch 68, Loss: 0.6826413948074332, Final Batch Loss: 0.00011896379146492109\n",
      "Epoch 69, Loss: 0.7052539233118296, Final Batch Loss: 0.02438969351351261\n",
      "Epoch 70, Loss: 2.445983663201332, Final Batch Loss: 1.864641547203064\n",
      "Epoch 71, Loss: 0.5804554098285735, Final Batch Loss: 0.003475817386060953\n",
      "Epoch 72, Loss: 1.2998145371675491, Final Batch Loss: 0.5822771787643433\n",
      "Epoch 73, Loss: 0.8275851830840111, Final Batch Loss: 0.10218784958124161\n",
      "Epoch 74, Loss: 0.613580133067444, Final Batch Loss: 0.0009809688199311495\n",
      "Epoch 75, Loss: 0.547298718651291, Final Batch Loss: 0.000565249880310148\n",
      "Epoch 76, Loss: 0.5721113719046116, Final Batch Loss: 0.06198767200112343\n",
      "Epoch 77, Loss: 0.536869483999908, Final Batch Loss: 0.009891423396766186\n",
      "Epoch 78, Loss: 0.8690231740474701, Final Batch Loss: 0.30323314666748047\n",
      "Epoch 79, Loss: 0.585221603512764, Final Batch Loss: 0.07232658565044403\n",
      "Epoch 80, Loss: 0.75205397605896, Final Batch Loss: 0.21751661598682404\n",
      "Epoch 81, Loss: 0.5583184859715402, Final Batch Loss: 0.004640405531972647\n",
      "Epoch 82, Loss: 1.42828568816185, Final Batch Loss: 0.9521171450614929\n",
      "Epoch 83, Loss: 0.5500065125524998, Final Batch Loss: 0.046499017626047134\n",
      "Epoch 84, Loss: 0.6396046625450253, Final Batch Loss: 0.015594561584293842\n",
      "Epoch 85, Loss: 0.5803471496328712, Final Batch Loss: 0.004695816896855831\n",
      "Epoch 86, Loss: 0.7042790874838829, Final Batch Loss: 0.016155876219272614\n",
      "Epoch 87, Loss: 0.5959228468127549, Final Batch Loss: 0.0065861535258591175\n",
      "Epoch 88, Loss: 0.4952147207222879, Final Batch Loss: 0.0019268295727670193\n",
      "Epoch 89, Loss: 0.5091849165037274, Final Batch Loss: 0.004110340960323811\n",
      "Epoch 90, Loss: 0.502753559499979, Final Batch Loss: 0.022495213896036148\n",
      "Epoch 91, Loss: 0.6296960338950157, Final Batch Loss: 0.15975792706012726\n",
      "Epoch 92, Loss: 0.5345445424318314, Final Batch Loss: 0.10021661221981049\n",
      "Epoch 93, Loss: 0.4522061495899834, Final Batch Loss: 1.4662635294371285e-05\n",
      "Epoch 94, Loss: 0.6149077415466309, Final Batch Loss: 0.183433398604393\n",
      "Epoch 95, Loss: 0.4438673637341708, Final Batch Loss: 0.001878284616395831\n",
      "Epoch 96, Loss: 0.4349616961553693, Final Batch Loss: 0.0037529291585087776\n",
      "Epoch 97, Loss: 0.4005483428481966, Final Batch Loss: 0.0014617482665926218\n",
      "Epoch 98, Loss: 0.4277465105988085, Final Batch Loss: 0.002082324121147394\n",
      "Epoch 99, Loss: 0.4372100845212117, Final Batch Loss: 0.0018975600833073258\n",
      "Epoch 100, Loss: 0.4457198306918144, Final Batch Loss: 0.02298230677843094\n",
      "Epoch 101, Loss: 0.40615832741968916, Final Batch Loss: 3.564294092939235e-05\n",
      "Epoch 102, Loss: 0.382171391218435, Final Batch Loss: 0.0005746620590798557\n",
      "Epoch 103, Loss: 0.5106588527560234, Final Batch Loss: 0.07971609383821487\n",
      "Epoch 104, Loss: 0.441431500017643, Final Batch Loss: 0.06918908655643463\n",
      "Epoch 105, Loss: 0.47956278175115585, Final Batch Loss: 0.08856093138456345\n",
      "Epoch 106, Loss: 0.3947831727564335, Final Batch Loss: 0.03468192741274834\n",
      "Epoch 107, Loss: 0.623337484896183, Final Batch Loss: 0.19765983521938324\n",
      "Epoch 108, Loss: 0.37817421203362755, Final Batch Loss: 0.000285584683297202\n",
      "Epoch 109, Loss: 0.8839364722371101, Final Batch Loss: 0.5346497893333435\n",
      "Epoch 110, Loss: 0.35007099783979356, Final Batch Loss: 0.00027378625236451626\n",
      "Epoch 111, Loss: 0.4177304853219539, Final Batch Loss: 0.002187480451539159\n",
      "Epoch 112, Loss: 0.4068798921070993, Final Batch Loss: 0.0008216104470193386\n",
      "Epoch 113, Loss: 1.0024059414863586, Final Batch Loss: 0.5788093209266663\n",
      "Epoch 114, Loss: 0.38798519037663937, Final Batch Loss: 0.0018192660063505173\n",
      "Epoch 115, Loss: 0.3388487022584741, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 116, Loss: 0.3133302692840516, Final Batch Loss: 4.6132929128361866e-05\n",
      "Epoch 117, Loss: 0.3554991023847833, Final Batch Loss: 0.0004909025738015771\n",
      "Epoch 118, Loss: 0.30668926471844316, Final Batch Loss: 0.0011749514378607273\n",
      "Epoch 119, Loss: 0.3653143551564426, Final Batch Loss: 6.0437283536884934e-05\n",
      "Epoch 120, Loss: 0.3472974020987749, Final Batch Loss: 0.007688099518418312\n",
      "Epoch 121, Loss: 0.3421680140309036, Final Batch Loss: 0.0057725864462554455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 0.34008054714649916, Final Batch Loss: 0.011211256496608257\n",
      "Epoch 123, Loss: 0.47290199995040894, Final Batch Loss: 0.12013901025056839\n",
      "Epoch 124, Loss: 0.354988022314501, Final Batch Loss: 0.00018010901112575084\n",
      "Epoch 125, Loss: 0.28894636617042124, Final Batch Loss: 0.0011332763824611902\n",
      "Epoch 126, Loss: 0.5158228352665901, Final Batch Loss: 0.13879461586475372\n",
      "Epoch 127, Loss: 0.3154701800085604, Final Batch Loss: 0.00412446865811944\n",
      "Epoch 128, Loss: 0.32403409451762855, Final Batch Loss: 2.4199192921514623e-05\n",
      "Epoch 129, Loss: 0.3140542294131592, Final Batch Loss: 0.0003632839070633054\n",
      "Epoch 130, Loss: 0.3250706180697307, Final Batch Loss: 0.0008985534077510238\n",
      "Epoch 131, Loss: 0.37655945055303164, Final Batch Loss: 3.659658250398934e-05\n",
      "Epoch 132, Loss: 0.3299112804234028, Final Batch Loss: 0.0015070997178554535\n",
      "Epoch 133, Loss: 0.3276618532836437, Final Batch Loss: 0.061815109103918076\n",
      "Epoch 134, Loss: 0.3473965502344072, Final Batch Loss: 0.002554608043283224\n",
      "Epoch 135, Loss: 0.918626144528389, Final Batch Loss: 0.6240864396095276\n",
      "Epoch 136, Loss: 0.4862504228949547, Final Batch Loss: 0.09905685484409332\n",
      "Epoch 137, Loss: 0.43107836227864027, Final Batch Loss: 0.012091080658137798\n",
      "Epoch 138, Loss: 1.0023711323738098, Final Batch Loss: 0.5261675119400024\n",
      "Epoch 139, Loss: 0.6299863308668137, Final Batch Loss: 0.2815437614917755\n",
      "Epoch 140, Loss: 0.4214628078043461, Final Batch Loss: 0.04190272465348244\n",
      "Epoch 141, Loss: 0.31037441319494974, Final Batch Loss: 0.00014602071314584464\n",
      "Epoch 142, Loss: 0.29421131405979395, Final Batch Loss: 0.0019212374463677406\n",
      "Epoch 143, Loss: 0.318278344348073, Final Batch Loss: 0.015042560175061226\n",
      "Epoch 144, Loss: 0.2604631083086133, Final Batch Loss: 0.00039319414645433426\n",
      "Epoch 145, Loss: 0.3067144453525543, Final Batch Loss: 0.01075955480337143\n",
      "Epoch 146, Loss: 0.4704451933503151, Final Batch Loss: 0.17732709646224976\n",
      "Epoch 147, Loss: 0.30395697057235793, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 148, Loss: 1.6532969176769257, Final Batch Loss: 1.3429625034332275\n",
      "Epoch 149, Loss: 0.3556482270359993, Final Batch Loss: 0.032444678246974945\n",
      "Epoch 150, Loss: 0.43667296320199966, Final Batch Loss: 0.057531170547008514\n",
      "Epoch 151, Loss: 0.39388006925582886, Final Batch Loss: 0.07982594519853592\n",
      "Epoch 152, Loss: 0.31867538020014763, Final Batch Loss: 0.0030146650969982147\n",
      "Epoch 153, Loss: 0.3074004732334288, Final Batch Loss: 7.688703772146255e-05\n",
      "Epoch 154, Loss: 0.3319576083449647, Final Batch Loss: 0.0011959074763581157\n",
      "Epoch 155, Loss: 0.2881779636518331, Final Batch Loss: 0.00014745102089364082\n",
      "Epoch 156, Loss: 0.2756580540590221, Final Batch Loss: 0.0001380348257953301\n",
      "Epoch 157, Loss: 0.2426322444662219, Final Batch Loss: 0.00018940561858471483\n",
      "Epoch 158, Loss: 0.2986453994690237, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 159, Loss: 0.48900581896305084, Final Batch Loss: 0.1635456085205078\n",
      "Epoch 160, Loss: 0.36290623992681503, Final Batch Loss: 0.07465215772390366\n",
      "Epoch 161, Loss: 0.25192706084635574, Final Batch Loss: 6.365573790390044e-05\n",
      "Epoch 162, Loss: 0.45126113295555115, Final Batch Loss: 0.19035710394382477\n",
      "Epoch 163, Loss: 0.32037062011659145, Final Batch Loss: 0.005560407415032387\n",
      "Epoch 164, Loss: 0.31822628527879715, Final Batch Loss: 0.03941093385219574\n",
      "Epoch 165, Loss: 0.28767476679058746, Final Batch Loss: 0.00018904806347563863\n",
      "Epoch 166, Loss: 0.27448390417430346, Final Batch Loss: 1.168244216387393e-05\n",
      "Epoch 167, Loss: 0.2713716310681775, Final Batch Loss: 0.00140865717548877\n",
      "Epoch 168, Loss: 0.28309595279279165, Final Batch Loss: 0.0002563863235991448\n",
      "Epoch 169, Loss: 0.29550203401595354, Final Batch Loss: 0.006485012359917164\n",
      "Epoch 170, Loss: 0.3254531994462013, Final Batch Loss: 0.07136546820402145\n",
      "Epoch 171, Loss: 0.34173331782221794, Final Batch Loss: 0.04282655194401741\n",
      "Epoch 172, Loss: 0.9448696933686733, Final Batch Loss: 0.7450242042541504\n",
      "Epoch 173, Loss: 0.34135005343705416, Final Batch Loss: 0.004026283510029316\n",
      "Epoch 174, Loss: 0.48870870674727485, Final Batch Loss: 0.0007088055717758834\n",
      "Epoch 175, Loss: 0.8090162873252211, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 176, Loss: 0.753743126988411, Final Batch Loss: 0.02645719051361084\n",
      "Epoch 177, Loss: 0.6681484635919333, Final Batch Loss: 0.0087501909583807\n",
      "Epoch 178, Loss: 0.5200438015162945, Final Batch Loss: 0.026190828531980515\n",
      "Epoch 179, Loss: 0.37416480109095573, Final Batch Loss: 0.00970514491200447\n",
      "Epoch 180, Loss: 0.3279578438960016, Final Batch Loss: 0.0032834685407578945\n",
      "Epoch 181, Loss: 0.25664457120001316, Final Batch Loss: 0.006464758887887001\n",
      "Epoch 182, Loss: 0.39441144838929176, Final Batch Loss: 0.1012931540608406\n",
      "Epoch 183, Loss: 0.28248368948698044, Final Batch Loss: 0.029842868447303772\n",
      "Epoch 184, Loss: 0.30633274087449536, Final Batch Loss: 0.0005250982358120382\n",
      "Epoch 185, Loss: 0.903765507042408, Final Batch Loss: 0.6337299942970276\n",
      "Epoch 186, Loss: 0.3000650890171528, Final Batch Loss: 0.03349683806300163\n",
      "Epoch 187, Loss: 0.5720764771103859, Final Batch Loss: 0.1799783706665039\n",
      "Epoch 188, Loss: 0.42680350539740175, Final Batch Loss: 0.0007241725688800216\n",
      "Epoch 189, Loss: 1.0183737874031067, Final Batch Loss: 0.5247736573219299\n",
      "Epoch 190, Loss: 0.5713976994156837, Final Batch Loss: 0.09755239635705948\n",
      "Epoch 191, Loss: 0.3135616679210216, Final Batch Loss: 0.0023952622432261705\n",
      "Epoch 192, Loss: 0.36170194775331765, Final Batch Loss: 0.0007559779332950711\n",
      "Epoch 193, Loss: 0.2964729303494096, Final Batch Loss: 0.010589362122118473\n",
      "Epoch 194, Loss: 0.26253098991037405, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 195, Loss: 0.2615261673927307, Final Batch Loss: 0.01598706841468811\n",
      "Epoch 196, Loss: 0.2638652673631441, Final Batch Loss: 0.00014006110723130405\n",
      "Epoch 197, Loss: 0.2573113263351843, Final Batch Loss: 0.0014094904763624072\n",
      "Epoch 198, Loss: 0.24520253983791918, Final Batch Loss: 0.0018149822717532516\n",
      "Epoch 199, Loss: 0.28351590503007174, Final Batch Loss: 0.0009245174005627632\n",
      "Epoch 200, Loss: 0.30662575364112854, Final Batch Loss: 0.06392919272184372\n",
      "Epoch 201, Loss: 0.23425104143097997, Final Batch Loss: 0.005652159918099642\n",
      "Epoch 202, Loss: 0.2940799817442894, Final Batch Loss: 0.01375529170036316\n",
      "Epoch 203, Loss: 0.29257558658719063, Final Batch Loss: 0.05033433064818382\n",
      "Epoch 204, Loss: 0.22572159057017416, Final Batch Loss: 8.21318244561553e-05\n",
      "Epoch 205, Loss: 0.272268526244261, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 206, Loss: 0.23032823950018155, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 207, Loss: 0.25758660212159157, Final Batch Loss: 0.005817979574203491\n",
      "Epoch 208, Loss: 0.55656798183918, Final Batch Loss: 0.2880042791366577\n",
      "Epoch 209, Loss: 0.2623721733689308, Final Batch Loss: 0.008009813725948334\n",
      "Epoch 210, Loss: 0.28200974567153025, Final Batch Loss: 0.00017951308109331876\n",
      "Epoch 211, Loss: 0.3318367525935102, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 212, Loss: 0.32747640705201775, Final Batch Loss: 0.0010040724882856011\n",
      "Epoch 213, Loss: 0.5770063623785973, Final Batch Loss: 0.29875123500823975\n",
      "Epoch 214, Loss: 0.9519482925534248, Final Batch Loss: 0.6430419683456421\n",
      "Epoch 215, Loss: 0.29792644642293453, Final Batch Loss: 0.007574765011668205\n",
      "Epoch 216, Loss: 0.31227483972907066, Final Batch Loss: 0.047375183552503586\n",
      "Epoch 217, Loss: 0.23674462281633168, Final Batch Loss: 0.0006115949945524335\n",
      "Epoch 218, Loss: 0.20273721346165985, Final Batch Loss: 0.0011503038695082068\n",
      "Epoch 219, Loss: 0.3410640358924866, Final Batch Loss: 0.11225171387195587\n",
      "Epoch 220, Loss: 0.23098620026121353, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 221, Loss: 0.22957630455493927, Final Batch Loss: 0.0038345158100128174\n",
      "Epoch 222, Loss: 0.21669423880666727, Final Batch Loss: 9.42901024245657e-05\n",
      "Epoch 223, Loss: 0.2376233241520822, Final Batch Loss: 0.004560427274554968\n",
      "Epoch 224, Loss: 0.23235822081915103, Final Batch Loss: 0.00025948495022021234\n",
      "Epoch 225, Loss: 0.2501369061355945, Final Batch Loss: 0.0003911683743353933\n",
      "Epoch 226, Loss: 0.22131515201181173, Final Batch Loss: 0.007460116408765316\n",
      "Epoch 227, Loss: 0.2649428900331259, Final Batch Loss: 0.01942562498152256\n",
      "Epoch 228, Loss: 0.2408743080450222, Final Batch Loss: 0.0006973695708438754\n",
      "Epoch 229, Loss: 0.21424952691450017, Final Batch Loss: 0.0001072826053132303\n",
      "Epoch 230, Loss: 0.20369963720440865, Final Batch Loss: 0.015710510313510895\n",
      "Epoch 231, Loss: 0.2159096384420991, Final Batch Loss: 0.007431955076754093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232, Loss: 0.2228777555283159, Final Batch Loss: 0.001536618685349822\n",
      "Epoch 233, Loss: 0.27114530478138477, Final Batch Loss: 0.0010725465836003423\n",
      "Epoch 234, Loss: 0.23272936744615436, Final Batch Loss: 0.0020638848654925823\n",
      "Epoch 235, Loss: 0.22659371771442238, Final Batch Loss: 0.00012385078298393637\n",
      "Epoch 236, Loss: 0.26498235389590263, Final Batch Loss: 0.03692613169550896\n",
      "Epoch 237, Loss: 0.23677814668917563, Final Batch Loss: 4.076874756719917e-05\n",
      "Epoch 238, Loss: 0.39121851697564125, Final Batch Loss: 0.1548784077167511\n",
      "Epoch 239, Loss: 0.242490667828406, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 240, Loss: 6.645429119467735, Final Batch Loss: 6.4308624267578125\n",
      "Epoch 241, Loss: 0.24962211237289011, Final Batch Loss: 0.001426989445462823\n",
      "Epoch 242, Loss: 0.2960498091124464, Final Batch Loss: 6.05564855504781e-05\n",
      "Epoch 243, Loss: 0.4010977072903188, Final Batch Loss: 0.00012337400403339416\n",
      "Epoch 244, Loss: 0.4137201368030219, Final Batch Loss: 5.602679812000133e-05\n",
      "Epoch 245, Loss: 0.5752856433391571, Final Batch Loss: 0.12579593062400818\n",
      "Epoch 246, Loss: 0.3569169354159385, Final Batch Loss: 0.0036022078711539507\n",
      "Epoch 247, Loss: 0.29528163094073534, Final Batch Loss: 0.007967357523739338\n",
      "Epoch 248, Loss: 0.27615629881620407, Final Batch Loss: 0.042826440185308456\n",
      "Epoch 249, Loss: 0.25190170069436135, Final Batch Loss: 2.825220326485578e-05\n",
      "Epoch 250, Loss: 0.2400849325058516, Final Batch Loss: 7.033100700937212e-05\n",
      "Epoch 251, Loss: 0.25855937972664833, Final Batch Loss: 0.03862915560603142\n",
      "Epoch 252, Loss: 0.27127438597381115, Final Batch Loss: 0.030966883525252342\n",
      "Epoch 253, Loss: 0.22401994050960639, Final Batch Loss: 2.9444261599564925e-05\n",
      "Epoch 254, Loss: 0.26377607719041407, Final Batch Loss: 0.0012666305992752314\n",
      "Epoch 255, Loss: 0.22793513140641153, Final Batch Loss: 0.002996124094352126\n",
      "Epoch 256, Loss: 0.3301413729786873, Final Batch Loss: 0.07601335644721985\n",
      "Epoch 257, Loss: 0.2534911585971713, Final Batch Loss: 0.007855120114982128\n",
      "Epoch 258, Loss: 0.23275655508041382, Final Batch Loss: 0.026542633771896362\n",
      "Epoch 259, Loss: 0.22380378408706747, Final Batch Loss: 3.4927710657939315e-05\n",
      "Epoch 260, Loss: 0.24222541600465775, Final Batch Loss: 0.030779171735048294\n",
      "Epoch 261, Loss: 0.22432036656209675, Final Batch Loss: 2.884823152271565e-05\n",
      "Epoch 262, Loss: 0.24907361366786063, Final Batch Loss: 0.001049682730808854\n",
      "Epoch 263, Loss: 0.21113073453307152, Final Batch Loss: 0.01132158562541008\n",
      "Epoch 264, Loss: 0.22389217652380466, Final Batch Loss: 0.006102500483393669\n",
      "Epoch 265, Loss: 0.21856704534729943, Final Batch Loss: 0.0009195152088068426\n",
      "Epoch 266, Loss: 0.22397245901811402, Final Batch Loss: 0.0002256377338198945\n",
      "Epoch 267, Loss: 0.21178743050404591, Final Batch Loss: 6.210611172718927e-05\n",
      "Epoch 268, Loss: 0.20753448069990554, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 269, Loss: 0.20910340326372534, Final Batch Loss: 0.001757030957378447\n",
      "Epoch 270, Loss: 0.2564596120500937, Final Batch Loss: 0.0011741180205717683\n",
      "Epoch 271, Loss: 0.18776786589296535, Final Batch Loss: 0.0008155357209034264\n",
      "Epoch 272, Loss: 0.22877736389636993, Final Batch Loss: 0.010196853429079056\n",
      "Epoch 273, Loss: 0.2167700408026576, Final Batch Loss: 0.004215284250676632\n",
      "Epoch 274, Loss: 0.36524731293320656, Final Batch Loss: 0.17852802574634552\n",
      "Epoch 275, Loss: 0.22449882701039314, Final Batch Loss: 0.022615376859903336\n",
      "Epoch 276, Loss: 0.21941901254467666, Final Batch Loss: 0.0037791754584759474\n",
      "Epoch 277, Loss: 0.20799625663221377, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 278, Loss: 0.2378337550908327, Final Batch Loss: 0.004941986873745918\n",
      "Epoch 279, Loss: 0.22679094970192182, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 280, Loss: 0.20854372903704643, Final Batch Loss: 0.008304115384817123\n",
      "Epoch 281, Loss: 0.18867417785077123, Final Batch Loss: 8.77341881277971e-05\n",
      "Epoch 282, Loss: 0.2222294439561665, Final Batch Loss: 0.0020123724825680256\n",
      "Epoch 283, Loss: 0.18734123784815893, Final Batch Loss: 0.000954768096562475\n",
      "Epoch 284, Loss: 0.2336397013423266, Final Batch Loss: 0.00019739109848160297\n",
      "Epoch 285, Loss: 0.2412374271079898, Final Batch Loss: 0.011486704461276531\n",
      "Epoch 286, Loss: 0.23764090426266193, Final Batch Loss: 0.010954951867461205\n",
      "Epoch 287, Loss: 0.3019883930683136, Final Batch Loss: 0.09363195300102234\n",
      "Epoch 288, Loss: 1.7265386320650578, Final Batch Loss: 1.4980647563934326\n",
      "Epoch 289, Loss: 0.46363459900021553, Final Batch Loss: 0.21714280545711517\n",
      "Epoch 290, Loss: 0.28968904353678226, Final Batch Loss: 0.025784531608223915\n",
      "Epoch 291, Loss: 0.32307588402181864, Final Batch Loss: 0.009942413307726383\n",
      "Epoch 292, Loss: 0.3645799160003662, Final Batch Loss: 0.008510157465934753\n",
      "Epoch 293, Loss: 0.32072922494262457, Final Batch Loss: 0.011264300905168056\n",
      "Epoch 294, Loss: 1.777407318353653, Final Batch Loss: 1.4825177192687988\n",
      "Epoch 295, Loss: 0.2967611141502857, Final Batch Loss: 0.03644658997654915\n",
      "Epoch 296, Loss: 0.35043006390333176, Final Batch Loss: 0.1081506684422493\n",
      "Epoch 297, Loss: 0.1921287141740322, Final Batch Loss: 0.01398419588804245\n",
      "Epoch 298, Loss: 0.20759190076205414, Final Batch Loss: 0.00010418349120300263\n",
      "Epoch 299, Loss: 0.29723962396383286, Final Batch Loss: 0.05127736181020737\n",
      "Epoch 300, Loss: 0.24473376967944205, Final Batch Loss: 0.003615867579355836\n",
      "Epoch 301, Loss: 0.2753669274970889, Final Batch Loss: 0.011734860949218273\n",
      "Epoch 302, Loss: 0.2158758764853701, Final Batch Loss: 0.0009401192655786872\n",
      "Epoch 303, Loss: 0.24245351032004692, Final Batch Loss: 0.0004758894501719624\n",
      "Epoch 304, Loss: 0.22662102337926626, Final Batch Loss: 0.011310270987451077\n",
      "Epoch 305, Loss: 0.271702378988266, Final Batch Loss: 0.036555320024490356\n",
      "Epoch 306, Loss: 0.2109191375238879, Final Batch Loss: 3.2305197237292305e-05\n",
      "Epoch 307, Loss: 0.24149061739433364, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 308, Loss: 0.2211083334768773, Final Batch Loss: 0.00011181206355104223\n",
      "Epoch 309, Loss: 0.21408198529388756, Final Batch Loss: 0.0011339908232912421\n",
      "Epoch 310, Loss: 0.22921077627688646, Final Batch Loss: 0.0029820995405316353\n",
      "Epoch 311, Loss: 0.22049286536639556, Final Batch Loss: 0.0007869484252296388\n",
      "Epoch 312, Loss: 0.17368507755645624, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 313, Loss: 0.21102384943515062, Final Batch Loss: 0.010628876276314259\n",
      "Epoch 314, Loss: 0.22342314012348652, Final Batch Loss: 0.01644122414290905\n",
      "Epoch 315, Loss: 3.547175247222185, Final Batch Loss: 3.368558168411255\n",
      "Epoch 316, Loss: 0.20319747366011143, Final Batch Loss: 0.005250474438071251\n",
      "Epoch 317, Loss: 0.3439520834945142, Final Batch Loss: 0.0075939311645925045\n",
      "Epoch 318, Loss: 0.5802120364969596, Final Batch Loss: 0.0011232740944251418\n",
      "Epoch 319, Loss: 0.7312013283371925, Final Batch Loss: 0.18868911266326904\n",
      "Epoch 320, Loss: 0.523155004309956, Final Batch Loss: 0.00024196557933464646\n",
      "Epoch 321, Loss: 0.4493882099632174, Final Batch Loss: 0.00375708588398993\n",
      "Epoch 322, Loss: 0.3570872046839213, Final Batch Loss: 0.00010132275929208845\n",
      "Epoch 323, Loss: 0.28443739749491215, Final Batch Loss: 0.022917063906788826\n",
      "Epoch 324, Loss: 0.21923422731924802, Final Batch Loss: 4.0411134250462055e-05\n",
      "Epoch 325, Loss: 0.22742279758676887, Final Batch Loss: 0.00502857705578208\n",
      "Epoch 326, Loss: 3.728909023106098, Final Batch Loss: 3.5000195503234863\n",
      "Epoch 327, Loss: 0.1927116269362159, Final Batch Loss: 0.0006490031373687088\n",
      "Epoch 328, Loss: 0.26863696053624153, Final Batch Loss: 0.025577835738658905\n",
      "Epoch 329, Loss: 0.30970598733983934, Final Batch Loss: 0.001057184999808669\n",
      "Epoch 330, Loss: 0.26897251117043197, Final Batch Loss: 0.0011998366098850965\n",
      "Epoch 331, Loss: 0.3313748858345207, Final Batch Loss: 0.00010263393050990999\n",
      "Epoch 332, Loss: 0.322069788351655, Final Batch Loss: 0.016347171738743782\n",
      "Epoch 333, Loss: 0.3037478367332369, Final Batch Loss: 0.0012293646577745676\n",
      "Epoch 334, Loss: 0.2834393046796322, Final Batch Loss: 0.021709073334932327\n",
      "Epoch 335, Loss: 0.30589859560132027, Final Batch Loss: 0.04116007313132286\n",
      "Epoch 336, Loss: 0.21162780828308314, Final Batch Loss: 0.0005016260547563434\n",
      "Epoch 337, Loss: 0.22551499743713066, Final Batch Loss: 0.00044705410255119205\n",
      "Epoch 338, Loss: 0.22749365237541497, Final Batch Loss: 0.0011438739020377398\n",
      "Epoch 339, Loss: 0.2924865633249283, Final Batch Loss: 0.0575975701212883\n",
      "Epoch 340, Loss: 0.2552774436751406, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 341, Loss: 0.21384970372309908, Final Batch Loss: 0.0008244690834544599\n",
      "Epoch 342, Loss: 0.22678966843523085, Final Batch Loss: 0.0007008241955190897\n",
      "Epoch 343, Loss: 0.6960116662085056, Final Batch Loss: 0.5105164647102356\n",
      "Epoch 344, Loss: 0.23840680671855807, Final Batch Loss: 0.004041362088173628\n",
      "Epoch 345, Loss: 0.23728717491030693, Final Batch Loss: 0.008704457432031631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346, Loss: 0.2542355256155133, Final Batch Loss: 0.014263582415878773\n",
      "Epoch 347, Loss: 0.29134029150009155, Final Batch Loss: 0.02758176624774933\n",
      "Epoch 348, Loss: 0.25830355379730463, Final Batch Loss: 0.007691056467592716\n",
      "Epoch 349, Loss: 0.3097275085747242, Final Batch Loss: 0.07992686331272125\n",
      "Epoch 350, Loss: 0.24874367413576692, Final Batch Loss: 0.0012869894271716475\n",
      "Epoch 351, Loss: 0.20964172668755054, Final Batch Loss: 0.015586698427796364\n",
      "Epoch 352, Loss: 0.20473307464271784, Final Batch Loss: 0.000940476544201374\n",
      "Epoch 353, Loss: 0.2241666023619473, Final Batch Loss: 0.005592652130872011\n",
      "Epoch 354, Loss: 0.1932224774354836, Final Batch Loss: 3.45700973412022e-05\n",
      "Epoch 355, Loss: 0.24622373457532376, Final Batch Loss: 0.0013328249333426356\n",
      "Epoch 356, Loss: 0.2099092788857888, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 357, Loss: 0.2032376837960328, Final Batch Loss: 7.080780778778717e-05\n",
      "Epoch 358, Loss: 0.21132015599869192, Final Batch Loss: 0.001934444298967719\n",
      "Epoch 359, Loss: 0.2303441185504198, Final Batch Loss: 0.016188016161322594\n",
      "Epoch 360, Loss: 0.21923793479800224, Final Batch Loss: 0.014866400510072708\n",
      "Epoch 361, Loss: 0.2854761555790901, Final Batch Loss: 0.08835819363594055\n",
      "Epoch 362, Loss: 0.17492595361545682, Final Batch Loss: 0.005593955982476473\n",
      "Epoch 363, Loss: 0.17633983120288121, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 364, Loss: 0.19648376803161227, Final Batch Loss: 3.135155202471651e-05\n",
      "Epoch 365, Loss: 0.23261651999200694, Final Batch Loss: 5.340433563105762e-05\n",
      "Epoch 366, Loss: 0.20772032695822418, Final Batch Loss: 0.0032063524704426527\n",
      "Epoch 367, Loss: 0.19540875917300582, Final Batch Loss: 0.0007097586058080196\n",
      "Epoch 368, Loss: 0.1752701592631638, Final Batch Loss: 0.006942909676581621\n",
      "Epoch 369, Loss: 0.18294521009374876, Final Batch Loss: 0.000125281119835563\n",
      "Epoch 370, Loss: 0.2378640058086603, Final Batch Loss: 3.1709168979432434e-05\n",
      "Epoch 371, Loss: 0.33540043607354164, Final Batch Loss: 0.11649644374847412\n",
      "Epoch 372, Loss: 0.21536669501074357, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 373, Loss: 0.24858234077692032, Final Batch Loss: 0.03643452376127243\n",
      "Epoch 374, Loss: 1.1047564707696438, Final Batch Loss: 0.8779020309448242\n",
      "Epoch 375, Loss: 0.18824607878922706, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 376, Loss: 0.27430860698223114, Final Batch Loss: 0.0959467962384224\n",
      "Epoch 377, Loss: 0.19207609631121159, Final Batch Loss: 0.00838923268020153\n",
      "Epoch 378, Loss: 0.18798424914712086, Final Batch Loss: 0.00041714549297466874\n",
      "Epoch 379, Loss: 0.18992660916410387, Final Batch Loss: 0.001935396110638976\n",
      "Epoch 380, Loss: 2.18174509704113, Final Batch Loss: 2.008254289627075\n",
      "Epoch 381, Loss: 0.26227899082005024, Final Batch Loss: 0.017542442306876183\n",
      "Epoch 382, Loss: 0.32522789016366005, Final Batch Loss: 0.039168063551187515\n",
      "Epoch 383, Loss: 0.37569460179656744, Final Batch Loss: 0.004710054956376553\n",
      "Epoch 384, Loss: 0.43598156049847603, Final Batch Loss: 0.04507126286625862\n",
      "Epoch 385, Loss: 0.41032139206072316, Final Batch Loss: 0.0007221474661491811\n",
      "Epoch 386, Loss: 0.36517201783135533, Final Batch Loss: 8.070142939686775e-05\n",
      "Epoch 387, Loss: 0.28450169536517933, Final Batch Loss: 0.00033063191222026944\n",
      "Epoch 388, Loss: 0.3165878765285015, Final Batch Loss: 0.032534342259168625\n",
      "Epoch 389, Loss: 0.21759909810498357, Final Batch Loss: 0.0061112684197723866\n",
      "Epoch 390, Loss: 0.20909718982875347, Final Batch Loss: 0.010167235508561134\n",
      "Epoch 391, Loss: 0.27845602110028267, Final Batch Loss: 0.05045459792017937\n",
      "Epoch 392, Loss: 0.4923930987715721, Final Batch Loss: 0.3077367842197418\n",
      "Epoch 393, Loss: 0.2152134752832353, Final Batch Loss: 0.005025611724704504\n",
      "Epoch 394, Loss: 0.1930628903210092, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 395, Loss: 0.1778628716710955, Final Batch Loss: 0.00036554806865751743\n",
      "Epoch 396, Loss: 0.18616049317643046, Final Batch Loss: 0.00019536493346095085\n",
      "Epoch 397, Loss: 0.20588904224678117, Final Batch Loss: 2.098061486321967e-05\n",
      "Epoch 398, Loss: 0.20388926507439464, Final Batch Loss: 0.000300958170555532\n",
      "Epoch 399, Loss: 0.2185749989002943, Final Batch Loss: 0.030610157176852226\n",
      "Epoch 400, Loss: 0.15710339392535388, Final Batch Loss: 0.003415823681280017\n",
      "Epoch 401, Loss: 0.19609518349068367, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 402, Loss: 0.19411329552531242, Final Batch Loss: 0.0\n",
      "Epoch 403, Loss: 0.19736705558898393, Final Batch Loss: 5.686121585313231e-05\n",
      "Epoch 404, Loss: 0.1698786504566101, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 405, Loss: 0.19240818917751312, Final Batch Loss: 0.0008543655276298523\n",
      "Epoch 406, Loss: 0.23789830040186644, Final Batch Loss: 0.009864392690360546\n",
      "Epoch 407, Loss: 0.20461898122448474, Final Batch Loss: 0.0006766413571313024\n",
      "Epoch 408, Loss: 0.16602103345212527, Final Batch Loss: 3.659658250398934e-05\n",
      "Epoch 409, Loss: 0.27126310020685196, Final Batch Loss: 0.0655096173286438\n",
      "Epoch 410, Loss: 0.18623135983941097, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 411, Loss: 0.18227646499871497, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 412, Loss: 0.22373075177893043, Final Batch Loss: 0.005315931048244238\n",
      "Epoch 413, Loss: 0.20193432457745075, Final Batch Loss: 0.0010409895330667496\n",
      "Epoch 414, Loss: 0.21350005618296564, Final Batch Loss: 0.0007326302584260702\n",
      "Epoch 415, Loss: 0.2558955177664757, Final Batch Loss: 0.07714418321847916\n",
      "Epoch 416, Loss: 0.2248171716928482, Final Batch Loss: 0.04862752556800842\n",
      "Epoch 417, Loss: 0.17205220786854625, Final Batch Loss: 3.0517112463712692e-05\n",
      "Epoch 418, Loss: 0.1812030404835241, Final Batch Loss: 0.00021491125517059118\n",
      "Epoch 419, Loss: 0.20511301977649055, Final Batch Loss: 5.960446742392378e-06\n",
      "Epoch 420, Loss: 0.7240342013537884, Final Batch Loss: 0.5043497681617737\n",
      "Epoch 421, Loss: 0.16077119509282056, Final Batch Loss: 0.00021026308240834624\n",
      "Epoch 422, Loss: 0.19118547346442938, Final Batch Loss: 0.012175641022622585\n",
      "Epoch 423, Loss: 0.947333000600338, Final Batch Loss: 0.7776011824607849\n",
      "Epoch 424, Loss: 0.21465155109763145, Final Batch Loss: 0.009968969970941544\n",
      "Epoch 425, Loss: 0.1883303483191412, Final Batch Loss: 2.288792165927589e-05\n",
      "Epoch 426, Loss: 0.188906607683748, Final Batch Loss: 0.0020284331403672695\n",
      "Epoch 427, Loss: 0.21968402108177543, Final Batch Loss: 0.0026207170449197292\n",
      "Epoch 428, Loss: 0.2118423804606664, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 429, Loss: 0.2642853409051895, Final Batch Loss: 0.08669237792491913\n",
      "Epoch 430, Loss: 0.16904986022564117, Final Batch Loss: 7.1403817855753e-05\n",
      "Epoch 431, Loss: 0.16896711383014917, Final Batch Loss: 0.006013159640133381\n",
      "Epoch 432, Loss: 0.20652614906430244, Final Batch Loss: 0.0075234174728393555\n",
      "Epoch 433, Loss: 0.17004840821027756, Final Batch Loss: 0.0\n",
      "Epoch 434, Loss: 0.20263160625472665, Final Batch Loss: 0.0015967250801622868\n",
      "Epoch 435, Loss: 0.1582549549639225, Final Batch Loss: 0.01685906946659088\n",
      "Epoch 436, Loss: 0.20901993510778993, Final Batch Loss: 0.0004085659747943282\n",
      "Epoch 437, Loss: 0.23092515766620636, Final Batch Loss: 0.05054175481200218\n",
      "Epoch 438, Loss: 0.1903893267735839, Final Batch Loss: 0.007938737981021404\n",
      "Epoch 439, Loss: 0.1815991030598525, Final Batch Loss: 8.463501580990851e-05\n",
      "Epoch 440, Loss: 0.1663131257519126, Final Batch Loss: 0.0038877157494425774\n",
      "Epoch 441, Loss: 0.1895135622471571, Final Batch Loss: 0.026252025738358498\n",
      "Epoch 442, Loss: 0.26083577424287796, Final Batch Loss: 0.09790364652872086\n",
      "Epoch 443, Loss: 0.1591398787786602, Final Batch Loss: 6.532455881824717e-05\n",
      "Epoch 444, Loss: 0.14591120528893953, Final Batch Loss: 2.3245540432981215e-05\n",
      "Epoch 445, Loss: 0.18376065045592327, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 446, Loss: 0.22360986464173038, Final Batch Loss: 1.1801649634435307e-05\n",
      "Epoch 447, Loss: 0.23354202881455421, Final Batch Loss: 0.02646229788661003\n",
      "Epoch 448, Loss: 0.2317892238497734, Final Batch Loss: 0.047208379954099655\n",
      "Epoch 449, Loss: 0.1818203962247935, Final Batch Loss: 1.4781842764932662e-05\n",
      "Epoch 450, Loss: 0.1748842045199126, Final Batch Loss: 0.0019748962949961424\n",
      "Epoch 451, Loss: 0.21513117849826813, Final Batch Loss: 0.04117448627948761\n",
      "Epoch 452, Loss: 0.16539148613560428, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 453, Loss: 0.21381118893532403, Final Batch Loss: 1.311301275563892e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454, Loss: 0.21715691311646879, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 455, Loss: 0.17294065561145544, Final Batch Loss: 0.010337735526263714\n",
      "Epoch 456, Loss: 0.22945553064346313, Final Batch Loss: 0.04769040644168854\n",
      "Epoch 457, Loss: 0.19028684866862022, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 458, Loss: 0.16223356127738953, Final Batch Loss: 0.0\n",
      "Epoch 459, Loss: 0.2045821025967598, Final Batch Loss: 0.04851340129971504\n",
      "Epoch 460, Loss: 0.16371751809856505, Final Batch Loss: 5.280832192511298e-05\n",
      "Epoch 461, Loss: 0.1731158960610628, Final Batch Loss: 0.011093368753790855\n",
      "Epoch 462, Loss: 0.15304374363040552, Final Batch Loss: 0.0006451908848248422\n",
      "Epoch 463, Loss: 0.1656690089730546, Final Batch Loss: 0.00114827963989228\n",
      "Epoch 464, Loss: 0.19482092617545277, Final Batch Loss: 0.0017254954436793923\n",
      "Epoch 465, Loss: 0.17942953096644487, Final Batch Loss: 0.00012313561455812305\n",
      "Epoch 466, Loss: 0.18462165689561516, Final Batch Loss: 0.001865434111095965\n",
      "Epoch 467, Loss: 0.21423178614350036, Final Batch Loss: 0.00027021096320822835\n",
      "Epoch 468, Loss: 0.42499302327632904, Final Batch Loss: 0.24388377368450165\n",
      "Epoch 469, Loss: 0.16975923102290835, Final Batch Loss: 0.00018130090029444546\n",
      "Epoch 470, Loss: 0.17414108756929636, Final Batch Loss: 0.013722133822739124\n",
      "Epoch 471, Loss: 0.26474686712026596, Final Batch Loss: 0.08566170930862427\n",
      "Epoch 472, Loss: 0.5433423221111298, Final Batch Loss: 0.3772887885570526\n",
      "Epoch 473, Loss: 0.21939669549462337, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 474, Loss: 0.16416363627649844, Final Batch Loss: 0.0034419598523527384\n",
      "Epoch 475, Loss: 0.2235668587964028, Final Batch Loss: 0.0020461592357605696\n",
      "Epoch 476, Loss: 0.21971656382083893, Final Batch Loss: 0.02110406383872032\n",
      "Epoch 477, Loss: 0.16820882067258935, Final Batch Loss: 1.2040065485052764e-05\n",
      "Epoch 478, Loss: 0.18344343843637034, Final Batch Loss: 0.0008841419476084411\n",
      "Epoch 479, Loss: 0.16841502856095758, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 480, Loss: 0.15734145464375615, Final Batch Loss: 0.006676864344626665\n",
      "Epoch 481, Loss: 0.14784989663166925, Final Batch Loss: 0.0002213471452705562\n",
      "Epoch 482, Loss: 0.44200659170746803, Final Batch Loss: 0.26975223422050476\n",
      "Epoch 483, Loss: 0.17848157137245835, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 484, Loss: 0.1874005272974273, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 485, Loss: 0.17884918639902025, Final Batch Loss: 0.0012023370945826173\n",
      "Epoch 486, Loss: 0.2106382609345019, Final Batch Loss: 0.005220590624958277\n",
      "Epoch 487, Loss: 0.21094933015410788, Final Batch Loss: 5.23315102327615e-05\n",
      "Epoch 488, Loss: 0.18204937502400753, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 489, Loss: 0.13205380994986626, Final Batch Loss: 4.8040190449682996e-05\n",
      "Epoch 490, Loss: 0.1704075480811298, Final Batch Loss: 0.004773411434143782\n",
      "Epoch 491, Loss: 0.1801753891631961, Final Batch Loss: 0.013475175015628338\n",
      "Epoch 492, Loss: 0.1565708105044905, Final Batch Loss: 0.00016342257731594145\n",
      "Epoch 493, Loss: 0.17339639496640302, Final Batch Loss: 0.0004538459761533886\n",
      "Epoch 494, Loss: 0.3428734056651592, Final Batch Loss: 0.15958863496780396\n",
      "Epoch 495, Loss: 0.1745085194654621, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 496, Loss: 0.16319162138097454, Final Batch Loss: 3.85038583772257e-05\n",
      "Epoch 497, Loss: 0.20569056576641742, Final Batch Loss: 3.6954195820726454e-05\n",
      "Epoch 498, Loss: 0.1959256947011454, Final Batch Loss: 0.00014447122521232814\n",
      "Epoch 499, Loss: 0.14909631758803243, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 500, Loss: 0.1938381771378772, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 501, Loss: 0.16730536140585173, Final Batch Loss: 1.2159273865108844e-05\n",
      "Epoch 502, Loss: 0.15829292628041003, Final Batch Loss: 3.373566141817719e-05\n",
      "Epoch 503, Loss: 0.16805270593613386, Final Batch Loss: 0.00448115449398756\n",
      "Epoch 504, Loss: 0.13596632331604042, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 505, Loss: 0.19738690866506658, Final Batch Loss: 0.0003305127320345491\n",
      "Epoch 506, Loss: 0.16793776396661997, Final Batch Loss: 0.006416789256036282\n",
      "Epoch 507, Loss: 0.16816668510000454, Final Batch Loss: 3.8742269680369645e-05\n",
      "Epoch 508, Loss: 0.1539862141944468, Final Batch Loss: 0.0008317348547279835\n",
      "Epoch 509, Loss: 0.17816318420227617, Final Batch Loss: 0.0005062728887423873\n",
      "Epoch 510, Loss: 0.4692234769463539, Final Batch Loss: 0.28022798895835876\n",
      "Epoch 511, Loss: 0.18236084654927254, Final Batch Loss: 0.054136473685503006\n",
      "Epoch 512, Loss: 0.1895161427091807, Final Batch Loss: 0.002639383776113391\n",
      "Epoch 513, Loss: 0.1742675375426188, Final Batch Loss: 0.0016511153662577271\n",
      "Epoch 514, Loss: 0.17936676308818278, Final Batch Loss: 3.4450891689630225e-05\n",
      "Epoch 515, Loss: 0.1637427159876097, Final Batch Loss: 5.23315102327615e-05\n",
      "Epoch 516, Loss: 0.17385479994118214, Final Batch Loss: 0.0\n",
      "Epoch 517, Loss: 0.1724703662475804, Final Batch Loss: 6.627816765103489e-05\n",
      "Epoch 518, Loss: 0.20755182579159737, Final Batch Loss: 0.023910271003842354\n",
      "Epoch 519, Loss: 0.129057514219312, Final Batch Loss: 0.0003150205302517861\n",
      "Epoch 520, Loss: 0.16949561206274666, Final Batch Loss: 2.52720492426306e-05\n",
      "Epoch 521, Loss: 0.16210726911231177, Final Batch Loss: 4.684815212385729e-05\n",
      "Epoch 522, Loss: 0.1507814470678568, Final Batch Loss: 0.0\n",
      "Epoch 523, Loss: 0.16588303656317294, Final Batch Loss: 0.0012459142599254847\n",
      "Epoch 524, Loss: 0.22652041167020798, Final Batch Loss: 0.04876060038805008\n",
      "Epoch 525, Loss: 0.17494564317166805, Final Batch Loss: 0.005712967365980148\n",
      "Epoch 526, Loss: 0.15489838798930577, Final Batch Loss: 2.539125671319198e-05\n",
      "Epoch 527, Loss: 0.12242730424623005, Final Batch Loss: 0.00044228785554878414\n",
      "Epoch 528, Loss: 0.17048994824290276, Final Batch Loss: 0.005402132868766785\n",
      "Epoch 529, Loss: 0.14352571964258232, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 530, Loss: 0.15236606448883094, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 531, Loss: 2.8579334877431393, Final Batch Loss: 2.7093565464019775\n",
      "Epoch 532, Loss: 0.23439207673072815, Final Batch Loss: 0.00853840634226799\n",
      "Epoch 533, Loss: 0.4001352488955945, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 534, Loss: 0.5694669857311965, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 535, Loss: 0.6098637862014584, Final Batch Loss: 0.0005754960584454238\n",
      "Epoch 536, Loss: 2.6490294486284256, Final Batch Loss: 2.0032570362091064\n",
      "Epoch 537, Loss: 0.3916408307850361, Final Batch Loss: 0.004994060844182968\n",
      "Epoch 538, Loss: 0.21665183827280998, Final Batch Loss: 0.0\n",
      "Epoch 539, Loss: 0.15708483383059502, Final Batch Loss: 0.0\n",
      "Epoch 540, Loss: 0.19821636914275587, Final Batch Loss: 0.0038928219582885504\n",
      "Epoch 541, Loss: 0.18051091767847538, Final Batch Loss: 0.0005492847412824631\n",
      "Epoch 542, Loss: 0.2159271240234375, Final Batch Loss: 0.019103821367025375\n",
      "Epoch 543, Loss: 0.21172570437190075, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 544, Loss: 0.2524338401854038, Final Batch Loss: 0.055815983563661575\n",
      "Epoch 545, Loss: 0.2268393262979771, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 546, Loss: 0.19013896479737014, Final Batch Loss: 0.00026294111739844084\n",
      "Epoch 547, Loss: 0.22068233415484428, Final Batch Loss: 0.004615012556314468\n",
      "Epoch 548, Loss: 0.20582324033603072, Final Batch Loss: 0.004496344830840826\n",
      "Epoch 549, Loss: 0.1951487474143505, Final Batch Loss: 0.025142576545476913\n",
      "Epoch 550, Loss: 0.19119512103497982, Final Batch Loss: 0.021837962791323662\n",
      "Epoch 551, Loss: 0.1987372301518917, Final Batch Loss: 0.045305412262678146\n",
      "Epoch 552, Loss: 0.21027371287345886, Final Batch Loss: 0.04494168609380722\n",
      "Epoch 553, Loss: 0.15876371412196022, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 554, Loss: 0.18602976418333128, Final Batch Loss: 0.0008648469229228795\n",
      "Epoch 555, Loss: 0.18057077750563622, Final Batch Loss: 0.03632279112935066\n",
      "Epoch 556, Loss: 0.16813020016888913, Final Batch Loss: 1.9311717551317997e-05\n",
      "Epoch 557, Loss: 0.30557818338274956, Final Batch Loss: 0.1500246226787567\n",
      "Epoch 558, Loss: 0.190912252292037, Final Batch Loss: 0.008239207789301872\n",
      "Epoch 559, Loss: 0.16016215458330407, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 560, Loss: 0.16701395366544602, Final Batch Loss: 3.755022044060752e-05\n",
      "Epoch 561, Loss: 0.18464102409780025, Final Batch Loss: 0.02990083582699299\n",
      "Epoch 562, Loss: 0.188385083922185, Final Batch Loss: 0.0019315887475386262\n",
      "Epoch 563, Loss: 0.15683054504916072, Final Batch Loss: 0.00452399579808116\n",
      "Epoch 564, Loss: 0.16417385265225448, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 565, Loss: 0.15784928877837956, Final Batch Loss: 0.0017814256716519594\n",
      "Epoch 566, Loss: 0.15387971210293472, Final Batch Loss: 0.0038791659753769636\n",
      "Epoch 567, Loss: 0.15090268323547207, Final Batch Loss: 0.0002008474839385599\n",
      "Epoch 568, Loss: 0.2238354217261076, Final Batch Loss: 0.05445216968655586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569, Loss: 0.19440345093607903, Final Batch Loss: 0.014868631958961487\n",
      "Epoch 570, Loss: 0.16421703249170605, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 571, Loss: 0.15584706468507648, Final Batch Loss: 0.0031634545885026455\n",
      "Epoch 572, Loss: 0.13205179940086964, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 573, Loss: 0.1594256758667143, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 574, Loss: 0.14396268874389762, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 575, Loss: 0.14842586033046246, Final Batch Loss: 0.004721326753497124\n",
      "Epoch 576, Loss: 0.13892904296517372, Final Batch Loss: 0.006701376289129257\n",
      "Epoch 577, Loss: 0.14060966484248638, Final Batch Loss: 0.0\n",
      "Epoch 578, Loss: 0.1720850876008626, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 579, Loss: 0.15956444945186377, Final Batch Loss: 0.003994344733655453\n",
      "Epoch 580, Loss: 0.14879782125353813, Final Batch Loss: 0.0\n",
      "Epoch 581, Loss: 0.1709517170675099, Final Batch Loss: 0.003348816651850939\n",
      "Epoch 582, Loss: 0.13331397622823715, Final Batch Loss: 0.008799467235803604\n",
      "Epoch 583, Loss: 0.2019227035343647, Final Batch Loss: 0.03213881328701973\n",
      "Epoch 584, Loss: 0.1818551905453205, Final Batch Loss: 0.029229331761598587\n",
      "Epoch 585, Loss: 0.1402831575833261, Final Batch Loss: 0.001191501971334219\n",
      "Epoch 586, Loss: 0.17469963058829308, Final Batch Loss: 0.0\n",
      "Epoch 587, Loss: 0.1582222424003703, Final Batch Loss: 3.969590397900902e-05\n",
      "Epoch 588, Loss: 0.16546833887696266, Final Batch Loss: 0.0\n",
      "Epoch 589, Loss: 0.1648778838571161, Final Batch Loss: 0.0020584126468747854\n",
      "Epoch 590, Loss: 0.15698249230445072, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 591, Loss: 0.1649660764487635, Final Batch Loss: 1.811964830267243e-05\n",
      "Epoch 592, Loss: 0.16297985267010517, Final Batch Loss: 0.00032217081752605736\n",
      "Epoch 593, Loss: 0.1347357928511883, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 594, Loss: 0.1676014082331676, Final Batch Loss: 6.425174069590867e-05\n",
      "Epoch 595, Loss: 0.15219360194350884, Final Batch Loss: 2.1457441107486375e-05\n",
      "Epoch 596, Loss: 0.1717968666634988, Final Batch Loss: 0.0002696150622796267\n",
      "Epoch 597, Loss: 0.1524613689398393, Final Batch Loss: 0.00038509105797857046\n",
      "Epoch 598, Loss: 0.1832868866622448, Final Batch Loss: 0.012087076902389526\n",
      "Epoch 599, Loss: 0.13832351937890053, Final Batch Loss: 0.0\n",
      "Epoch 600, Loss: 0.2196552325040102, Final Batch Loss: 0.09194555133581161\n",
      "Epoch 601, Loss: 0.13913700347166014, Final Batch Loss: 1.4066597032069694e-05\n",
      "Epoch 602, Loss: 0.1594537645537457, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 603, Loss: 0.15419508144134397, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 604, Loss: 0.17033446207642555, Final Batch Loss: 0.04516720771789551\n",
      "Epoch 605, Loss: 0.17183733350339025, Final Batch Loss: 1.3112935448589269e-05\n",
      "Epoch 606, Loss: 0.13892432673810617, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 607, Loss: 0.16131375619443133, Final Batch Loss: 0.0008110094931907952\n",
      "Epoch 608, Loss: 0.16495738548564987, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 609, Loss: 0.9415004812180996, Final Batch Loss: 0.8045700788497925\n",
      "Epoch 610, Loss: 0.16730087995529175, Final Batch Loss: 0.03383029252290726\n",
      "Epoch 611, Loss: 0.1889278291946539, Final Batch Loss: 1.1920858014491387e-05\n",
      "Epoch 612, Loss: 0.23464006697759032, Final Batch Loss: 0.004093007650226355\n",
      "Epoch 613, Loss: 0.25642113279900514, Final Batch Loss: 0.00043406602344475687\n",
      "Epoch 614, Loss: 0.2030098251995014, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 615, Loss: 0.20407964661717415, Final Batch Loss: 0.0\n",
      "Epoch 616, Loss: 0.17078804963875882, Final Batch Loss: 1.0847986231965479e-05\n",
      "Epoch 617, Loss: 0.17928965997998603, Final Batch Loss: 5.23315102327615e-05\n",
      "Epoch 618, Loss: 0.14848786219951648, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 619, Loss: 0.15349409822374582, Final Batch Loss: 0.004086121916770935\n",
      "Epoch 620, Loss: 0.16587661625817418, Final Batch Loss: 0.007424027193337679\n",
      "Epoch 621, Loss: 0.14328658115118742, Final Batch Loss: 0.012858572416007519\n",
      "Epoch 622, Loss: 0.19378709606826305, Final Batch Loss: 0.003698771819472313\n",
      "Epoch 623, Loss: 0.15779653189929377, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 624, Loss: 0.266229297965765, Final Batch Loss: 0.11180708557367325\n",
      "Epoch 625, Loss: 0.14478045747819124, Final Batch Loss: 8.082063141046092e-05\n",
      "Epoch 626, Loss: 0.13801671564260687, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 627, Loss: 0.14228897914289718, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 628, Loss: 0.1487058475104277, Final Batch Loss: 1.0132738680113107e-05\n",
      "Epoch 629, Loss: 0.1712408251933084, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 630, Loss: 0.14624845604612347, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 631, Loss: 0.39048299193382263, Final Batch Loss: 0.24299225211143494\n",
      "Epoch 632, Loss: 0.16465090704150498, Final Batch Loss: 0.0016365956980735064\n",
      "Epoch 633, Loss: 0.19247104553505778, Final Batch Loss: 0.004991095047444105\n",
      "Epoch 634, Loss: 0.19499480724329032, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 635, Loss: 0.16868892682168735, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 636, Loss: 0.285282950848341, Final Batch Loss: 0.10494419932365417\n",
      "Epoch 637, Loss: 0.13684177001778153, Final Batch Loss: 2.2053474822314456e-05\n",
      "Epoch 638, Loss: 0.23693327978253365, Final Batch Loss: 0.020679347217082977\n",
      "Epoch 639, Loss: 0.18590072402730584, Final Batch Loss: 0.0028266259469091892\n",
      "Epoch 640, Loss: 0.15939940698444843, Final Batch Loss: 0.0058081429451704025\n",
      "Epoch 641, Loss: 0.1455262675880249, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 642, Loss: 0.14671574340900406, Final Batch Loss: 0.00031728477915748954\n",
      "Epoch 643, Loss: 0.17573200751212426, Final Batch Loss: 0.00038044367101974785\n",
      "Epoch 644, Loss: 0.15704092366104305, Final Batch Loss: 1.8596476365928538e-05\n",
      "Epoch 645, Loss: 0.12719163551810198, Final Batch Loss: 0.0002335037279408425\n",
      "Epoch 646, Loss: 0.14861983433365822, Final Batch Loss: 0.0\n",
      "Epoch 647, Loss: 0.1114313992757161, Final Batch Loss: 1.2993727978027891e-05\n",
      "Epoch 648, Loss: 1.138888418674469, Final Batch Loss: 0.9756991267204285\n",
      "Epoch 649, Loss: 0.16488459705965397, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 650, Loss: 0.2235997579409741, Final Batch Loss: 0.0007272697403095663\n",
      "Epoch 651, Loss: 0.21947941422695294, Final Batch Loss: 0.00029094755882397294\n",
      "Epoch 652, Loss: 0.2577062919731361, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 653, Loss: 0.23710029805806698, Final Batch Loss: 5.2689116273541003e-05\n",
      "Epoch 654, Loss: 0.2083928784923046, Final Batch Loss: 0.00011038171214750037\n",
      "Epoch 655, Loss: 0.19448039787675953, Final Batch Loss: 7.283422019099817e-05\n",
      "Epoch 656, Loss: 0.15099236906826263, Final Batch Loss: 6.437094270950183e-05\n",
      "Epoch 657, Loss: 0.17726555839180236, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 658, Loss: 0.15381883083819048, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 659, Loss: 0.14122259912619484, Final Batch Loss: 3.9219088648678735e-05\n",
      "Epoch 660, Loss: 0.11779924854636192, Final Batch Loss: 0.0\n",
      "Epoch 661, Loss: 0.2116442546248436, Final Batch Loss: 0.0686894953250885\n",
      "Epoch 662, Loss: 0.1620684526860714, Final Batch Loss: 0.0\n",
      "Epoch 663, Loss: 0.18923748284577613, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 664, Loss: 0.14121581091967528, Final Batch Loss: 5.471556869451888e-05\n",
      "Epoch 665, Loss: 0.1356446711724857, Final Batch Loss: 0.00011705666838679463\n",
      "Epoch 666, Loss: 0.16076243668794632, Final Batch Loss: 0.0\n",
      "Epoch 667, Loss: 0.11761211599787202, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 668, Loss: 0.12976266257464175, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 669, Loss: 0.1157586592817097, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 670, Loss: 0.19510780274868011, Final Batch Loss: 0.059902820736169815\n",
      "Epoch 671, Loss: 0.1849399683997035, Final Batch Loss: 0.014456062577664852\n",
      "Epoch 672, Loss: 0.15157430991529708, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 673, Loss: 0.12570628148660035, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 674, Loss: 0.13573513622395694, Final Batch Loss: 0.0015907741617411375\n",
      "Epoch 675, Loss: 0.1245572374900803, Final Batch Loss: 0.0012421043356880546\n",
      "Epoch 676, Loss: 0.15391324495431036, Final Batch Loss: 0.0015265013789758086\n",
      "Epoch 677, Loss: 0.1280643369536847, Final Batch Loss: 0.0007877822499722242\n",
      "Epoch 678, Loss: 0.14987706020474434, Final Batch Loss: 0.0\n",
      "Epoch 679, Loss: 0.13801558315753226, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 680, Loss: 0.145266592502594, Final Batch Loss: 0.0\n",
      "Epoch 681, Loss: 0.15128450095653534, Final Batch Loss: 0.008706821128726006\n",
      "Epoch 682, Loss: 0.1799292266368866, Final Batch Loss: 0.0\n",
      "Epoch 683, Loss: 0.13827415555329026, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 684, Loss: 0.15951296279672533, Final Batch Loss: 0.0015487592900171876\n",
      "Epoch 685, Loss: 0.14090917623980204, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 686, Loss: 0.14056915789842606, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687, Loss: 0.13043850262329215, Final Batch Loss: 2.253030106658116e-05\n",
      "Epoch 688, Loss: 0.15268883388489485, Final Batch Loss: 0.013748942874372005\n",
      "Epoch 689, Loss: 0.13132709718775004, Final Batch Loss: 0.0014094904763624072\n",
      "Epoch 690, Loss: 0.1209226604196374, Final Batch Loss: 8.4638240878121e-06\n",
      "Epoch 691, Loss: 0.14858474794891663, Final Batch Loss: 0.00034445550409145653\n",
      "Epoch 692, Loss: 0.41502247750759125, Final Batch Loss: 0.2593498229980469\n",
      "Epoch 693, Loss: 0.15675318660214543, Final Batch Loss: 0.004005624447017908\n",
      "Epoch 694, Loss: 0.1883206149796024, Final Batch Loss: 0.0008180370787158608\n",
      "Epoch 695, Loss: 0.13261832669376616, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 696, Loss: 0.18488964100833982, Final Batch Loss: 0.0017105009173974395\n",
      "Epoch 697, Loss: 0.1831124225864187, Final Batch Loss: 0.0011263700434938073\n",
      "Epoch 698, Loss: 0.18194236313865986, Final Batch Loss: 0.0001679517881711945\n",
      "Epoch 699, Loss: 0.17786988988450503, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 700, Loss: 0.13322624191641808, Final Batch Loss: 0.0\n",
      "Epoch 701, Loss: 0.15403500013053417, Final Batch Loss: 0.0\n",
      "Epoch 702, Loss: 0.13634672015780325, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 703, Loss: 0.13207587122451514, Final Batch Loss: 0.0009226117981597781\n",
      "Epoch 704, Loss: 0.13771699328208342, Final Batch Loss: 0.0008008848526515067\n",
      "Epoch 705, Loss: 0.176025164546445, Final Batch Loss: 0.003630002262070775\n",
      "Epoch 706, Loss: 0.16589540615677834, Final Batch Loss: 0.0155893974006176\n",
      "Epoch 707, Loss: 0.1293648770697473, Final Batch Loss: 4.172238186583854e-05\n",
      "Epoch 708, Loss: 0.13153711054474115, Final Batch Loss: 0.0\n",
      "Epoch 709, Loss: 0.1495988906826824, Final Batch Loss: 0.0022509971167892218\n",
      "Epoch 710, Loss: 0.26759888231754303, Final Batch Loss: 0.14454011619091034\n",
      "Epoch 711, Loss: 0.14292218163541293, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 712, Loss: 0.1509953229688108, Final Batch Loss: 0.0027114315889775753\n",
      "Epoch 713, Loss: 0.14277733862400055, Final Batch Loss: 0.0\n",
      "Epoch 714, Loss: 0.14234123751384686, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 715, Loss: 0.1247363667935133, Final Batch Loss: 0.0\n",
      "Epoch 716, Loss: 0.14705140786827542, Final Batch Loss: 0.00040737437666393816\n",
      "Epoch 717, Loss: 0.1420582663267851, Final Batch Loss: 0.0\n",
      "Epoch 718, Loss: 0.11138597200624645, Final Batch Loss: 0.0004906642716377974\n",
      "Epoch 719, Loss: 0.14389135315997237, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 720, Loss: 0.12504507973789458, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 721, Loss: 0.1588967079296708, Final Batch Loss: 0.011362721212208271\n",
      "Epoch 722, Loss: 0.12370964996807743, Final Batch Loss: 3.85038583772257e-05\n",
      "Epoch 723, Loss: 0.13052507885731757, Final Batch Loss: 0.0030623229686170816\n",
      "Epoch 724, Loss: 0.11516358144564265, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 725, Loss: 0.14963813365466194, Final Batch Loss: 5.1616290875244886e-05\n",
      "Epoch 726, Loss: 0.22504550963640213, Final Batch Loss: 0.09405956417322159\n",
      "Epoch 727, Loss: 0.13536831363262536, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 728, Loss: 0.1403471641242504, Final Batch Loss: 0.01336037740111351\n",
      "Epoch 729, Loss: 0.12624860927461867, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 730, Loss: 0.8251513093709946, Final Batch Loss: 0.6867564916610718\n",
      "Epoch 731, Loss: 0.14115153206512332, Final Batch Loss: 0.0053177098743617535\n",
      "Epoch 732, Loss: 0.15643117250874639, Final Batch Loss: 0.003886409569531679\n",
      "Epoch 733, Loss: 0.10956044588238001, Final Batch Loss: 0.004653695039451122\n",
      "Epoch 734, Loss: 0.15630241288090474, Final Batch Loss: 1.3470558769768104e-05\n",
      "Epoch 735, Loss: 0.1384899786207825, Final Batch Loss: 0.0009837078396230936\n",
      "Epoch 736, Loss: 0.14479739568196237, Final Batch Loss: 0.0038311907555907965\n",
      "Epoch 737, Loss: 0.13220198825001717, Final Batch Loss: 0.0\n",
      "Epoch 738, Loss: 0.15758039194406592, Final Batch Loss: 3.135155202471651e-05\n",
      "Epoch 739, Loss: 0.20781687274575233, Final Batch Loss: 0.02605808526277542\n",
      "Epoch 740, Loss: 0.12174185644835234, Final Batch Loss: 0.002838275395333767\n",
      "Epoch 741, Loss: 0.1228441409766674, Final Batch Loss: 0.0\n",
      "Epoch 742, Loss: 0.12738262070342898, Final Batch Loss: 0.0017999890260398388\n",
      "Epoch 743, Loss: 0.13690794774447568, Final Batch Loss: 0.0004576589271891862\n",
      "Epoch 744, Loss: 0.19611288234591484, Final Batch Loss: 0.03656405583024025\n",
      "Epoch 745, Loss: 0.14357133021576374, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 746, Loss: 0.17744694650173187, Final Batch Loss: 0.035032257437705994\n",
      "Epoch 747, Loss: 0.12725445014075376, Final Batch Loss: 0.00038258862332440913\n",
      "Epoch 748, Loss: 0.11434695310889964, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 749, Loss: 0.12860887663555332, Final Batch Loss: 0.00047708096099086106\n",
      "Epoch 750, Loss: 0.14144697785377502, Final Batch Loss: 0.0\n",
      "Epoch 751, Loss: 0.16207896918058395, Final Batch Loss: 0.0\n",
      "Epoch 752, Loss: 0.14404671063675778, Final Batch Loss: 0.0001072826053132303\n",
      "Epoch 753, Loss: 0.12323785078478977, Final Batch Loss: 0.0005548844928853214\n",
      "Epoch 754, Loss: 0.1536509693833068, Final Batch Loss: 0.0012711548479273915\n",
      "Epoch 755, Loss: 0.12978491215471877, Final Batch Loss: 8.296622399939224e-05\n",
      "Epoch 756, Loss: 0.13252157531678677, Final Batch Loss: 0.0027789566665887833\n",
      "Epoch 757, Loss: 0.15952930206913152, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 758, Loss: 0.1328058170620352, Final Batch Loss: 0.0022341071162372828\n",
      "Epoch 759, Loss: 0.14804597943930276, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 760, Loss: 0.11249522114849242, Final Batch Loss: 9.894321920000948e-06\n",
      "Epoch 761, Loss: 0.12823490621667588, Final Batch Loss: 5.94836674281396e-05\n",
      "Epoch 762, Loss: 0.11523034796118736, Final Batch Loss: 0.0\n",
      "Epoch 763, Loss: 0.14184688031673431, Final Batch Loss: 0.002516200765967369\n",
      "Epoch 764, Loss: 0.13823894782217394, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 765, Loss: 0.1358117014169693, Final Batch Loss: 0.0\n",
      "Epoch 766, Loss: 0.09148218110203743, Final Batch Loss: 0.0\n",
      "Epoch 767, Loss: 0.1197469811886549, Final Batch Loss: 0.0\n",
      "Epoch 768, Loss: 0.12714051638613455, Final Batch Loss: 0.00022849810193292797\n",
      "Epoch 769, Loss: 0.14939986541861572, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 770, Loss: 0.14354893006384373, Final Batch Loss: 0.037296462804079056\n",
      "Epoch 771, Loss: 0.13769661623518914, Final Batch Loss: 0.0006797387031838298\n",
      "Epoch 772, Loss: 0.15645676955318777, Final Batch Loss: 7.331102824537084e-05\n",
      "Epoch 773, Loss: 0.12943840585057842, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 774, Loss: 0.13372411066666245, Final Batch Loss: 0.0045918733812868595\n",
      "Epoch 775, Loss: 0.12811531592160463, Final Batch Loss: 0.0\n",
      "Epoch 776, Loss: 0.101852310821414, Final Batch Loss: 0.0\n",
      "Epoch 777, Loss: 0.12974190711969413, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 778, Loss: 0.13542433083057404, Final Batch Loss: 0.013367906212806702\n",
      "Epoch 779, Loss: 0.12643583700992167, Final Batch Loss: 0.0002580548170953989\n",
      "Epoch 780, Loss: 0.14127476479916368, Final Batch Loss: 0.0002040654799202457\n",
      "Epoch 781, Loss: 0.1473203374644072, Final Batch Loss: 1.6093124941107817e-05\n",
      "Epoch 782, Loss: 0.11290614865720272, Final Batch Loss: 0.0\n",
      "Epoch 783, Loss: 0.14086827634037036, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 784, Loss: 0.13285639323294163, Final Batch Loss: 0.0\n",
      "Epoch 785, Loss: 0.12157731681509176, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 786, Loss: 0.10993985203822376, Final Batch Loss: 3.71926071238704e-05\n",
      "Epoch 787, Loss: 0.15480174481672293, Final Batch Loss: 1.7404405298293568e-05\n",
      "Epoch 788, Loss: 0.11736339703199405, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 789, Loss: 0.1262017502449453, Final Batch Loss: 0.002784544136375189\n",
      "Epoch 790, Loss: 0.12510514166149278, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 791, Loss: 0.13790262304246426, Final Batch Loss: 0.0\n",
      "Epoch 792, Loss: 0.1420705148484558, Final Batch Loss: 0.0009814451914280653\n",
      "Epoch 793, Loss: 0.12681549217086285, Final Batch Loss: 0.0006986799417063594\n",
      "Epoch 794, Loss: 0.13826944289030507, Final Batch Loss: 0.00019393471302464604\n",
      "Epoch 795, Loss: 0.10853080824006156, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 796, Loss: 0.15220539644354858, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 797, Loss: 0.13444383814930916, Final Batch Loss: 0.0\n",
      "Epoch 798, Loss: 0.12232373509323224, Final Batch Loss: 0.0005365362740121782\n",
      "Epoch 799, Loss: 0.12643562214725534, Final Batch Loss: 2.9205850296420977e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800, Loss: 0.1329316046085296, Final Batch Loss: 2.729855441430118e-05\n",
      "Epoch 801, Loss: 0.11878992081619799, Final Batch Loss: 0.0029032959137111902\n",
      "Epoch 802, Loss: 0.11712137050517413, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 803, Loss: 0.12441314384329871, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 804, Loss: 0.13267740231458447, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 805, Loss: 0.11688387859612703, Final Batch Loss: 0.010471520014107227\n",
      "Epoch 806, Loss: 0.1468013245612383, Final Batch Loss: 0.021137328818440437\n",
      "Epoch 807, Loss: 0.126309372484684, Final Batch Loss: 0.0\n",
      "Epoch 808, Loss: 0.1270706002251245, Final Batch Loss: 0.00035041390219703317\n",
      "Epoch 809, Loss: 0.13224966113921255, Final Batch Loss: 0.00027164106722921133\n",
      "Epoch 810, Loss: 0.11986174434332497, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 811, Loss: 0.12218832317739725, Final Batch Loss: 0.0016705142334103584\n",
      "Epoch 812, Loss: 0.17415757291018963, Final Batch Loss: 0.06394171714782715\n",
      "Epoch 813, Loss: 0.1608306411653757, Final Batch Loss: 0.042752426117658615\n",
      "Epoch 814, Loss: 0.09885020552064816, Final Batch Loss: 6.318072337307967e-06\n",
      "Epoch 815, Loss: 0.12551420383897494, Final Batch Loss: 5.8410845667822286e-05\n",
      "Epoch 816, Loss: 0.24780744314193726, Final Batch Loss: 0.12981408834457397\n",
      "Epoch 817, Loss: 0.13298717138741267, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 818, Loss: 0.19766793380767922, Final Batch Loss: 1.966933996300213e-05\n",
      "Epoch 819, Loss: 0.1513077281367714, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 820, Loss: 0.18575937300920486, Final Batch Loss: 0.0\n",
      "Epoch 821, Loss: 0.18135343491894673, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 822, Loss: 0.19799646347019006, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 823, Loss: 0.15206982379322653, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 824, Loss: 0.12549392500204704, Final Batch Loss: 1.1205610462639015e-05\n",
      "Epoch 825, Loss: 0.21060390770435333, Final Batch Loss: 0.05559352785348892\n",
      "Epoch 826, Loss: 0.10944603104144335, Final Batch Loss: 0.0022897711023688316\n",
      "Epoch 827, Loss: 0.15083482488972777, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 828, Loss: 0.12218082696165311, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 829, Loss: 0.1312738060951233, Final Batch Loss: 0.0\n",
      "Epoch 830, Loss: 0.12037071740815009, Final Batch Loss: 2.4914430468925275e-05\n",
      "Epoch 831, Loss: 0.15573729571224249, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 832, Loss: 0.13517055986449122, Final Batch Loss: 0.006655549164861441\n",
      "Epoch 833, Loss: 0.11722191236913204, Final Batch Loss: 0.0\n",
      "Epoch 834, Loss: 0.09770263405516744, Final Batch Loss: 0.0010512308217585087\n",
      "Epoch 835, Loss: 0.13831038771422755, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 836, Loss: 0.1237782808020711, Final Batch Loss: 0.0020478246733546257\n",
      "Epoch 837, Loss: 0.15328530967235565, Final Batch Loss: 0.0\n",
      "Epoch 838, Loss: 0.12468851823359728, Final Batch Loss: 0.0010202685371041298\n",
      "Epoch 839, Loss: 0.12996755726635456, Final Batch Loss: 0.02493237517774105\n",
      "Epoch 840, Loss: 0.21145876497030258, Final Batch Loss: 0.07125967741012573\n",
      "Epoch 841, Loss: 0.11199105717241764, Final Batch Loss: 0.000771939754486084\n",
      "Epoch 842, Loss: 0.1222201409691479, Final Batch Loss: 0.0003530356043484062\n",
      "Epoch 843, Loss: 0.12734742648899555, Final Batch Loss: 0.0005821678787469864\n",
      "Epoch 844, Loss: 0.2325523905456066, Final Batch Loss: 0.07838065177202225\n",
      "Epoch 845, Loss: 0.21565956622362137, Final Batch Loss: 0.07654519379138947\n",
      "Epoch 846, Loss: 0.12466521002349396, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 847, Loss: 0.11065144649137437, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 848, Loss: 0.10379231814295053, Final Batch Loss: 0.0\n",
      "Epoch 849, Loss: 0.1344799349353707, Final Batch Loss: 5.054346183896996e-05\n",
      "Epoch 850, Loss: 0.13696316559799016, Final Batch Loss: 0.0019182630348950624\n",
      "Epoch 851, Loss: 0.1332169789238833, Final Batch Loss: 0.0002928543253801763\n",
      "Epoch 852, Loss: 0.09491319954395294, Final Batch Loss: 0.0\n",
      "Epoch 853, Loss: 0.1065451953545562, Final Batch Loss: 8.189342770492658e-05\n",
      "Epoch 854, Loss: 0.27112193405628204, Final Batch Loss: 0.16218210756778717\n",
      "Epoch 855, Loss: 0.12270927056351866, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 856, Loss: 0.13086532294983044, Final Batch Loss: 0.0004985281848348677\n",
      "Epoch 857, Loss: 0.11300267829938093, Final Batch Loss: 8.725739462533966e-05\n",
      "Epoch 858, Loss: 0.08694081820431165, Final Batch Loss: 0.00014494798961095512\n",
      "Epoch 859, Loss: 0.13025252995430492, Final Batch Loss: 7.354942499659956e-05\n",
      "Epoch 860, Loss: 0.1358474754015333, Final Batch Loss: 4.2676016164477915e-05\n",
      "Epoch 861, Loss: 0.1324486043304205, Final Batch Loss: 0.005235888063907623\n",
      "Epoch 862, Loss: 0.11944900625167065, Final Batch Loss: 1.680836794548668e-05\n",
      "Epoch 863, Loss: 0.11975499731488526, Final Batch Loss: 0.0038215715903788805\n",
      "Epoch 864, Loss: 0.12871902342885733, Final Batch Loss: 0.007802722044289112\n",
      "Epoch 865, Loss: 0.22725876979529858, Final Batch Loss: 0.12527377903461456\n",
      "Epoch 866, Loss: 0.1331190960481763, Final Batch Loss: 0.015508529730141163\n",
      "Epoch 867, Loss: 0.1280999913578853, Final Batch Loss: 0.0006005152827128768\n",
      "Epoch 868, Loss: 0.13586504384875298, Final Batch Loss: 0.0\n",
      "Epoch 869, Loss: 0.0983661463833414, Final Batch Loss: 0.00016473367577418685\n",
      "Epoch 870, Loss: 0.19586155749857426, Final Batch Loss: 0.06714741885662079\n",
      "Epoch 871, Loss: 0.10028939140829607, Final Batch Loss: 4.184158387943171e-05\n",
      "Epoch 872, Loss: 0.12092056870454826, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 873, Loss: 0.2134566493332386, Final Batch Loss: 0.06034700945019722\n",
      "Epoch 874, Loss: 0.1311949910596013, Final Batch Loss: 0.011953861452639103\n",
      "Epoch 875, Loss: 0.12313053383650185, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 876, Loss: 0.09547007083892822, Final Batch Loss: 0.0\n",
      "Epoch 877, Loss: 0.13267209415789694, Final Batch Loss: 0.001207933179102838\n",
      "Epoch 878, Loss: 0.09260532251209952, Final Batch Loss: 0.00015007323236204684\n",
      "Epoch 879, Loss: 0.11627537943422084, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 880, Loss: 0.11219308339059353, Final Batch Loss: 0.010431881994009018\n",
      "Epoch 881, Loss: 0.09853465161722852, Final Batch Loss: 5.185469490243122e-05\n",
      "Epoch 882, Loss: 0.11233720369637012, Final Batch Loss: 0.0\n",
      "Epoch 883, Loss: 0.11609132718513138, Final Batch Loss: 3.3378044463461265e-05\n",
      "Epoch 884, Loss: 0.10756704770028591, Final Batch Loss: 0.0\n",
      "Epoch 885, Loss: 0.1369871720661422, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 886, Loss: 0.11044864174618851, Final Batch Loss: 0.00018285033002030104\n",
      "Epoch 887, Loss: 0.12296024151146412, Final Batch Loss: 0.0\n",
      "Epoch 888, Loss: 0.11021932943913271, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 889, Loss: 0.1392902258085087, Final Batch Loss: 0.001816648175008595\n",
      "Epoch 890, Loss: 0.10759425721653315, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 891, Loss: 0.09985890933239716, Final Batch Loss: 3.2066785934148356e-05\n",
      "Epoch 892, Loss: 0.1362794075976126, Final Batch Loss: 0.0009217780898325145\n",
      "Epoch 893, Loss: 0.11141136749847647, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 894, Loss: 0.12730393999663647, Final Batch Loss: 0.0002169373765354976\n",
      "Epoch 895, Loss: 0.11817056033760309, Final Batch Loss: 0.005507533438503742\n",
      "Epoch 896, Loss: 0.14484896458452567, Final Batch Loss: 0.0008528171456418931\n",
      "Epoch 897, Loss: 0.11737930169329047, Final Batch Loss: 0.007136331405490637\n",
      "Epoch 898, Loss: 0.13360219819696795, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 899, Loss: 0.11736734211444855, Final Batch Loss: 0.016567394137382507\n",
      "Epoch 900, Loss: 0.0968580571924349, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 901, Loss: 0.09304355550557375, Final Batch Loss: 0.0\n",
      "Epoch 902, Loss: 0.13250893717486179, Final Batch Loss: 7.60526381782256e-05\n",
      "Epoch 903, Loss: 0.14424781687557697, Final Batch Loss: 0.04612024500966072\n",
      "Epoch 904, Loss: 0.1367776757106185, Final Batch Loss: 0.0\n",
      "Epoch 905, Loss: 0.10983379074605182, Final Batch Loss: 0.0003983181086368859\n",
      "Epoch 906, Loss: 0.11436739150667563, Final Batch Loss: 0.00015221867943182588\n",
      "Epoch 907, Loss: 0.09864947013420533, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 908, Loss: 0.11146119664044818, Final Batch Loss: 2.777537883957848e-05\n",
      "Epoch 909, Loss: 0.09771803207513585, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 910, Loss: 0.11125765182077885, Final Batch Loss: 0.00715680792927742\n",
      "Epoch 911, Loss: 0.10753235407173634, Final Batch Loss: 0.0\n",
      "Epoch 912, Loss: 0.09092745091766119, Final Batch Loss: 0.0\n",
      "Epoch 913, Loss: 0.12523959204554558, Final Batch Loss: 0.0\n",
      "Epoch 914, Loss: 0.10101351328188457, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 915, Loss: 0.11114182415076357, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 916, Loss: 0.08608125708996539, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 917, Loss: 0.08063347860297654, Final Batch Loss: 0.00013374387344811112\n",
      "Epoch 918, Loss: 0.15716754365712404, Final Batch Loss: 0.03704710304737091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 919, Loss: 0.15147856609837618, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 920, Loss: 0.10075417591724545, Final Batch Loss: 0.0012663925299420953\n",
      "Epoch 921, Loss: 0.08518098687636666, Final Batch Loss: 0.0003045333724003285\n",
      "Epoch 922, Loss: 0.1220695711672306, Final Batch Loss: 0.0\n",
      "Epoch 923, Loss: 0.11418021842837334, Final Batch Loss: 0.0\n",
      "Epoch 924, Loss: 0.11614369915332645, Final Batch Loss: 0.0019249258330091834\n",
      "Epoch 925, Loss: 2.5527673941105604, Final Batch Loss: 2.4479010105133057\n",
      "Epoch 926, Loss: 0.21806594356894493, Final Batch Loss: 0.051098182797431946\n",
      "Epoch 927, Loss: 0.25214244902599603, Final Batch Loss: 0.0016925308154895902\n",
      "Epoch 928, Loss: 0.3007650424260646, Final Batch Loss: 0.002809864701703191\n",
      "Epoch 929, Loss: 0.2967841846984811, Final Batch Loss: 1.8715683836489916e-05\n",
      "Epoch 930, Loss: 0.2861135941930115, Final Batch Loss: 0.004459199029952288\n",
      "Epoch 931, Loss: 0.2310635149478344, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 932, Loss: 0.18997145231696777, Final Batch Loss: 0.0002037079248111695\n",
      "Epoch 933, Loss: 0.1852033562026918, Final Batch Loss: 0.002618576865643263\n",
      "Epoch 934, Loss: 0.13916556676849723, Final Batch Loss: 0.0015584002248942852\n",
      "Epoch 935, Loss: 0.3898955099284649, Final Batch Loss: 0.2589058578014374\n",
      "Epoch 936, Loss: 0.20316263288259506, Final Batch Loss: 0.06894166022539139\n",
      "Epoch 937, Loss: 0.19235286058392376, Final Batch Loss: 0.0005469018360599875\n",
      "Epoch 938, Loss: 0.20160625083371997, Final Batch Loss: 0.004865947645157576\n",
      "Epoch 939, Loss: 0.17649517208337784, Final Batch Loss: 0.004220388829708099\n",
      "Epoch 940, Loss: 0.11065699718892574, Final Batch Loss: 0.0\n",
      "Epoch 941, Loss: 0.16225040703966442, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 942, Loss: 0.11341056402307004, Final Batch Loss: 0.001412823679856956\n",
      "Epoch 943, Loss: 0.09885029308497906, Final Batch Loss: 0.004435937851667404\n",
      "Epoch 944, Loss: 0.10278860222751973, Final Batch Loss: 0.00011216964776394889\n",
      "Epoch 945, Loss: 0.11910660316061694, Final Batch Loss: 0.00012706902634818107\n",
      "Epoch 946, Loss: 0.13554364535957575, Final Batch Loss: 0.040826763957738876\n",
      "Epoch 947, Loss: 0.1299407877959311, Final Batch Loss: 0.005878895986825228\n",
      "Epoch 948, Loss: 0.11349819600445699, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 949, Loss: 0.13502877578139305, Final Batch Loss: 0.0\n",
      "Epoch 950, Loss: 0.11399434320628643, Final Batch Loss: 0.007098454982042313\n",
      "Epoch 951, Loss: 0.6428151689469814, Final Batch Loss: 0.539515495300293\n",
      "Epoch 952, Loss: 0.14858436025679111, Final Batch Loss: 0.04704473540186882\n",
      "Epoch 953, Loss: 0.11705258768051863, Final Batch Loss: 0.009602193720638752\n",
      "Epoch 954, Loss: 0.11379678780212998, Final Batch Loss: 0.002352448645979166\n",
      "Epoch 955, Loss: 0.13358286023139954, Final Batch Loss: 0.0\n",
      "Epoch 956, Loss: 0.13363105803728104, Final Batch Loss: 0.016822967678308487\n",
      "Epoch 957, Loss: 0.1161484754702542, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 958, Loss: 0.10155802031022176, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 959, Loss: 0.13696852611610666, Final Batch Loss: 0.0008198237628675997\n",
      "Epoch 960, Loss: 0.10891152173223873, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 961, Loss: 0.09643308625891223, Final Batch Loss: 1.1086402082582936e-05\n",
      "Epoch 962, Loss: 0.13923654705286026, Final Batch Loss: 0.013589136302471161\n",
      "Epoch 963, Loss: 0.09330272467741452, Final Batch Loss: 2.0265373677830212e-05\n",
      "Epoch 964, Loss: 0.11244244212866761, Final Batch Loss: 0.0002961912250611931\n",
      "Epoch 965, Loss: 0.11361844348721206, Final Batch Loss: 0.001716808183118701\n",
      "Epoch 966, Loss: 0.10094820702306606, Final Batch Loss: 1.07287787614041e-05\n",
      "Epoch 967, Loss: 0.0921515467680365, Final Batch Loss: 1.2874520507466514e-05\n",
      "Epoch 968, Loss: 0.1122499133925885, Final Batch Loss: 0.0004077318590134382\n",
      "Epoch 969, Loss: 0.10299349061097018, Final Batch Loss: 0.0004262015863787383\n",
      "Epoch 970, Loss: 0.11652450449764729, Final Batch Loss: 0.0\n",
      "Epoch 971, Loss: 0.10961847193539143, Final Batch Loss: 0.004476407542824745\n",
      "Epoch 972, Loss: 0.12364489585161209, Final Batch Loss: 0.0\n",
      "Epoch 973, Loss: 0.09001245070248842, Final Batch Loss: 0.0\n",
      "Epoch 974, Loss: 0.10438342485576158, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 975, Loss: 0.11598696932195907, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 976, Loss: 0.12347543612065692, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 977, Loss: 0.09800751788861817, Final Batch Loss: 7.450303382938728e-05\n",
      "Epoch 978, Loss: 0.11833838932216167, Final Batch Loss: 0.0\n",
      "Epoch 979, Loss: 0.10271970154281007, Final Batch Loss: 6.55629628454335e-05\n",
      "Epoch 980, Loss: 0.1165533661842062, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 981, Loss: 0.11394704226404428, Final Batch Loss: 0.000533795915544033\n",
      "Epoch 982, Loss: 0.09761099237948656, Final Batch Loss: 0.0\n",
      "Epoch 983, Loss: 0.15623702481389046, Final Batch Loss: 0.0604122094810009\n",
      "Epoch 984, Loss: 0.12787229102104902, Final Batch Loss: 0.014202234335243702\n",
      "Epoch 985, Loss: 0.09110404830425978, Final Batch Loss: 0.0\n",
      "Epoch 986, Loss: 0.22260276600718498, Final Batch Loss: 0.13311755657196045\n",
      "Epoch 987, Loss: 0.090886334888296, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 988, Loss: 0.10607983730733395, Final Batch Loss: 0.0\n",
      "Epoch 989, Loss: 0.11925498576601967, Final Batch Loss: 0.0004568248405121267\n",
      "Epoch 990, Loss: 0.11328286863863468, Final Batch Loss: 0.0\n",
      "Epoch 991, Loss: 0.10614082298343419, Final Batch Loss: 4.589452510117553e-05\n",
      "Epoch 992, Loss: 0.10018724203109741, Final Batch Loss: 0.00931311585009098\n",
      "Epoch 993, Loss: 0.09865002741571516, Final Batch Loss: 0.0008775911992415786\n",
      "Epoch 994, Loss: 0.0968590248376131, Final Batch Loss: 0.0\n",
      "Epoch 995, Loss: 0.10333860130049288, Final Batch Loss: 0.000639710808172822\n",
      "Epoch 996, Loss: 0.10439907911677437, Final Batch Loss: 2.610649426060263e-05\n",
      "Epoch 997, Loss: 0.3782460941001773, Final Batch Loss: 0.2816624045372009\n",
      "Epoch 998, Loss: 0.09830085840076208, Final Batch Loss: 0.0\n",
      "Epoch 999, Loss: 0.08614844735711813, Final Batch Loss: 0.0\n",
      "Epoch 1000, Loss: 0.10888493405218469, Final Batch Loss: 2.3841574147809297e-05\n",
      "Epoch 1001, Loss: 0.08858460932970047, Final Batch Loss: 0.0\n",
      "Epoch 1002, Loss: 0.11126953360508196, Final Batch Loss: 0.00024423000286333263\n",
      "Epoch 1003, Loss: 0.10955184372141957, Final Batch Loss: 0.004408997017890215\n",
      "Epoch 1004, Loss: 0.13685838726814836, Final Batch Loss: 0.0001811817055568099\n",
      "Epoch 1005, Loss: 0.14515813440084457, Final Batch Loss: 0.017321381717920303\n",
      "Epoch 1006, Loss: 0.12154677882790565, Final Batch Loss: 0.021722372621297836\n",
      "Epoch 1007, Loss: 0.10008436627686024, Final Batch Loss: 0.0\n",
      "Epoch 1008, Loss: 0.14841731812339276, Final Batch Loss: 0.0015034097013995051\n",
      "Epoch 1009, Loss: 0.12637209333479404, Final Batch Loss: 0.030336573719978333\n",
      "Epoch 1010, Loss: 0.09914975240826607, Final Batch Loss: 0.0\n",
      "Epoch 1011, Loss: 0.10165871119488656, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 1012, Loss: 0.10860936711651448, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 1013, Loss: 0.1083524599653174, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1014, Loss: 0.10777782904915512, Final Batch Loss: 0.0001685477327555418\n",
      "Epoch 1015, Loss: 0.11040470562875271, Final Batch Loss: 0.0\n",
      "Epoch 1016, Loss: 0.09980424679815769, Final Batch Loss: 0.0\n",
      "Epoch 1017, Loss: 0.10488440468895988, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1018, Loss: 0.08413206971840737, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 1019, Loss: 0.11164711035416985, Final Batch Loss: 1.2516897186287679e-05\n",
      "Epoch 1020, Loss: 5.664648934267461, Final Batch Loss: 5.562932014465332\n",
      "Epoch 1021, Loss: 0.1393374651669319, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1022, Loss: 0.18907564779510722, Final Batch Loss: 4.446407547220588e-05\n",
      "Epoch 1023, Loss: 0.27154143154621124, Final Batch Loss: 0.0\n",
      "Epoch 1024, Loss: 0.3128475842131593, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 1025, Loss: 0.22972805425507659, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1026, Loss: 0.24601413868367672, Final Batch Loss: 0.014010762795805931\n",
      "Epoch 1027, Loss: 0.21432623645523563, Final Batch Loss: 0.0005104430601932108\n",
      "Epoch 1028, Loss: 0.15626673400083746, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 1029, Loss: 0.15368752243375638, Final Batch Loss: 7.879423355916515e-05\n",
      "Epoch 1030, Loss: 0.14852209016680717, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1031, Loss: 0.1257581114768982, Final Batch Loss: 0.0\n",
      "Epoch 1032, Loss: 0.12631806782155763, Final Batch Loss: 0.00014602071314584464\n",
      "Epoch 1033, Loss: 0.11330771073630785, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1034, Loss: 0.11562404402593529, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 1035, Loss: 0.11904119876999175, Final Batch Loss: 6.258291978156194e-05\n",
      "Epoch 1036, Loss: 0.13241010054480284, Final Batch Loss: 0.0010203876299783587\n",
      "Epoch 1037, Loss: 0.09525590389966965, Final Batch Loss: 0.0\n",
      "Epoch 1038, Loss: 0.25556599721312523, Final Batch Loss: 0.1340482532978058\n",
      "Epoch 1039, Loss: 0.10933302698322223, Final Batch Loss: 1.847726889536716e-05\n",
      "Epoch 1040, Loss: 0.10933347803074867, Final Batch Loss: 0.0009801351698115468\n",
      "Epoch 1041, Loss: 0.1744276061654091, Final Batch Loss: 0.04584506154060364\n",
      "Epoch 1042, Loss: 0.1276242403910146, Final Batch Loss: 7.879423355916515e-05\n",
      "Epoch 1043, Loss: 0.11988154798621053, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1044, Loss: 0.11559538543224335, Final Batch Loss: 0.0\n",
      "Epoch 1045, Loss: 0.09291347471662448, Final Batch Loss: 1.847726889536716e-05\n",
      "Epoch 1046, Loss: 0.12538992799818516, Final Batch Loss: 0.0\n",
      "Epoch 1047, Loss: 0.1100678127259016, Final Batch Loss: 0.0\n",
      "Epoch 1048, Loss: 0.1067480817437172, Final Batch Loss: 0.0\n",
      "Epoch 1049, Loss: 0.12740981951355934, Final Batch Loss: 0.03261188417673111\n",
      "Epoch 1050, Loss: 0.11659263633191586, Final Batch Loss: 0.0\n",
      "Epoch 1051, Loss: 0.09148832224309444, Final Batch Loss: 0.0\n",
      "Epoch 1052, Loss: 0.24652791395783424, Final Batch Loss: 0.12786157429218292\n",
      "Epoch 1053, Loss: 0.29181963577866554, Final Batch Loss: 0.1859118938446045\n",
      "Epoch 1054, Loss: 0.12280499748885632, Final Batch Loss: 0.0\n",
      "Epoch 1055, Loss: 0.5067732036113739, Final Batch Loss: 0.3819562494754791\n",
      "Epoch 1056, Loss: 0.11074941791594028, Final Batch Loss: 0.0\n",
      "Epoch 1057, Loss: 0.12864379468373954, Final Batch Loss: 0.002405608771368861\n",
      "Epoch 1058, Loss: 0.10538834840554046, Final Batch Loss: 3.218599158572033e-05\n",
      "Epoch 1059, Loss: 0.12751736119389534, Final Batch Loss: 0.013253919780254364\n",
      "Epoch 1060, Loss: 0.1213487625354901, Final Batch Loss: 0.001259725191630423\n",
      "Epoch 1061, Loss: 0.33180010318756104, Final Batch Loss: 0.21965733170509338\n",
      "Epoch 1062, Loss: 0.1208713091909317, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1063, Loss: 0.11458984325872734, Final Batch Loss: 9.345571743324399e-05\n",
      "Epoch 1064, Loss: 0.10970645025372505, Final Batch Loss: 0.0\n",
      "Epoch 1065, Loss: 0.14207808673381805, Final Batch Loss: 0.05212264508008957\n",
      "Epoch 1066, Loss: 0.10170217812992632, Final Batch Loss: 0.0012474621180444956\n",
      "Epoch 1067, Loss: 0.18453963845968246, Final Batch Loss: 0.06116066873073578\n",
      "Epoch 1068, Loss: 0.10330271732527763, Final Batch Loss: 0.0012310316087678075\n",
      "Epoch 1069, Loss: 0.14651074702851474, Final Batch Loss: 0.0025780319701880217\n",
      "Epoch 1070, Loss: 0.18074606731534004, Final Batch Loss: 0.0636182650923729\n",
      "Epoch 1071, Loss: 0.11677143722772598, Final Batch Loss: 0.0\n",
      "Epoch 1072, Loss: 0.11304428521543741, Final Batch Loss: 0.010915215127170086\n",
      "Epoch 1073, Loss: 0.08309132792055607, Final Batch Loss: 0.0\n",
      "Epoch 1074, Loss: 0.09838911041151732, Final Batch Loss: 0.0010112178279086947\n",
      "Epoch 1075, Loss: 0.1020758212544024, Final Batch Loss: 0.003237603697925806\n",
      "Epoch 1076, Loss: 0.18546950072050095, Final Batch Loss: 0.0918952077627182\n",
      "Epoch 1077, Loss: 0.07772429194300656, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1078, Loss: 0.08687457349151373, Final Batch Loss: 0.0\n",
      "Epoch 1079, Loss: 0.08975864943568013, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 1080, Loss: 0.09696117104067525, Final Batch Loss: 2.5510462364763953e-05\n",
      "Epoch 1081, Loss: 0.10023108404129744, Final Batch Loss: 0.0008937893435359001\n",
      "Epoch 1082, Loss: 0.17810996435582638, Final Batch Loss: 0.08585832267999649\n",
      "Epoch 1083, Loss: 0.08826393884373829, Final Batch Loss: 0.0006744970451109111\n",
      "Epoch 1084, Loss: 0.13120291009545326, Final Batch Loss: 0.0\n",
      "Epoch 1085, Loss: 0.2556733060628176, Final Batch Loss: 0.169748455286026\n",
      "Epoch 1086, Loss: 0.11505498796759639, Final Batch Loss: 5.030505417380482e-05\n",
      "Epoch 1087, Loss: 0.07805160785756016, Final Batch Loss: 1.9907753085135482e-05\n",
      "Epoch 1088, Loss: 0.08086213283240795, Final Batch Loss: 0.0\n",
      "Epoch 1089, Loss: 0.10750358318546205, Final Batch Loss: 3.0636318115284666e-05\n",
      "Epoch 1090, Loss: 0.09259825755725615, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 1091, Loss: 0.11329184100031853, Final Batch Loss: 0.0\n",
      "Epoch 1092, Loss: 0.08315424977627117, Final Batch Loss: 1.7881233361549675e-05\n",
      "Epoch 1093, Loss: 0.10608240216970444, Final Batch Loss: 0.00977727584540844\n",
      "Epoch 1094, Loss: 0.0930365351960063, Final Batch Loss: 0.0\n",
      "Epoch 1095, Loss: 0.08523006943869404, Final Batch Loss: 0.0001919085334520787\n",
      "Epoch 1096, Loss: 0.08095430367393419, Final Batch Loss: 0.00012444675667211413\n",
      "Epoch 1097, Loss: 0.08126621844712645, Final Batch Loss: 0.0011664974736049771\n",
      "Epoch 1098, Loss: 0.08972004843963077, Final Batch Loss: 5.352353764465079e-05\n",
      "Epoch 1099, Loss: 0.10099624641588889, Final Batch Loss: 0.0002802217786666006\n",
      "Epoch 1100, Loss: 0.11658038524910808, Final Batch Loss: 0.002678974997252226\n",
      "Epoch 1101, Loss: 0.11567112617194653, Final Batch Loss: 0.0\n",
      "Epoch 1102, Loss: 0.09201489854604006, Final Batch Loss: 0.017313415184617043\n",
      "Epoch 1103, Loss: 0.10332876630124588, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1104, Loss: 0.10481348626490217, Final Batch Loss: 1.2040065485052764e-05\n",
      "Epoch 1105, Loss: 0.08601931855081801, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1106, Loss: 0.09968560934066772, Final Batch Loss: 0.0028464775532484055\n",
      "Epoch 1107, Loss: 0.08936165642899141, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 1108, Loss: 0.07477467693388462, Final Batch Loss: 0.003958605229854584\n",
      "Epoch 1109, Loss: 0.10326872476071003, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 1110, Loss: 0.06830286653712392, Final Batch Loss: 0.00332065811380744\n",
      "Epoch 1111, Loss: 0.09655098627263214, Final Batch Loss: 0.00010477947944309562\n",
      "Epoch 1112, Loss: 0.06353587051853538, Final Batch Loss: 0.0012822272256016731\n",
      "Epoch 1113, Loss: 0.09391588903963566, Final Batch Loss: 0.010937146842479706\n",
      "Epoch 1114, Loss: 0.08983875066019209, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1115, Loss: 0.08410590109269833, Final Batch Loss: 6.615896563744172e-05\n",
      "Epoch 1116, Loss: 0.10381080101433326, Final Batch Loss: 3.528532761265524e-05\n",
      "Epoch 1117, Loss: 0.12292820401489735, Final Batch Loss: 0.021044302731752396\n",
      "Epoch 1118, Loss: 0.11503603588789701, Final Batch Loss: 0.0019202856346964836\n",
      "Epoch 1119, Loss: 0.09538557380437851, Final Batch Loss: 0.0\n",
      "Epoch 1120, Loss: 0.09477493166922812, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1121, Loss: 0.07292094547284478, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1122, Loss: 0.08113090693949943, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1123, Loss: 0.09806674160063267, Final Batch Loss: 0.0\n",
      "Epoch 1124, Loss: 0.07454984821379185, Final Batch Loss: 0.0\n",
      "Epoch 1125, Loss: 0.06662191520445049, Final Batch Loss: 0.0006212450098246336\n",
      "Epoch 1126, Loss: 0.08468491584062576, Final Batch Loss: 0.0\n",
      "Epoch 1127, Loss: 0.072603717396305, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 1128, Loss: 0.18399354256689548, Final Batch Loss: 0.09336856752634048\n",
      "Epoch 1129, Loss: 0.0938693571370095, Final Batch Loss: 2.1576648578047752e-05\n",
      "Epoch 1130, Loss: 0.08550941105931997, Final Batch Loss: 0.0\n",
      "Epoch 1131, Loss: 0.1217472655698657, Final Batch Loss: 0.02730538137257099\n",
      "Epoch 1132, Loss: 0.1120730489460584, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 1133, Loss: 0.09848516526244566, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 1134, Loss: 0.09160037979017943, Final Batch Loss: 0.0009659630013629794\n",
      "Epoch 1135, Loss: 0.097306651908184, Final Batch Loss: 1.3112935448589269e-05\n",
      "Epoch 1136, Loss: 0.10262244141631527, Final Batch Loss: 6.913899414939806e-05\n",
      "Epoch 1137, Loss: 0.0961558036506176, Final Batch Loss: 0.0\n",
      "Epoch 1138, Loss: 0.08386777010309743, Final Batch Loss: 6.90197994117625e-05\n",
      "Epoch 1139, Loss: 0.09780564007814974, Final Batch Loss: 0.0015470929211005569\n",
      "Epoch 1140, Loss: 0.09085828806473728, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 1141, Loss: 0.08649190142728003, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1142, Loss: 0.11027851451581228, Final Batch Loss: 3.5523738915799186e-05\n",
      "Epoch 1143, Loss: 0.11775024207963725, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 1144, Loss: 0.08697224000752612, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 1145, Loss: 0.07685967769066337, Final Batch Loss: 0.00010108436981681734\n",
      "Epoch 1146, Loss: 0.0689613847041528, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1147, Loss: 0.08074849191928024, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1148, Loss: 0.07961992513082805, Final Batch Loss: 5.0424259825376794e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1149, Loss: 0.10238984040097421, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 1150, Loss: 0.09342535389805562, Final Batch Loss: 1.3470558769768104e-05\n",
      "Epoch 1151, Loss: 0.07166977785527706, Final Batch Loss: 0.0\n",
      "Epoch 1152, Loss: 0.26289516128599644, Final Batch Loss: 0.18013589084148407\n",
      "Epoch 1153, Loss: 0.06987143820151687, Final Batch Loss: 0.006913313176482916\n",
      "Epoch 1154, Loss: 0.07958589480585943, Final Batch Loss: 1.6569954823353328e-05\n",
      "Epoch 1155, Loss: 0.09047472476959229, Final Batch Loss: 0.007507326081395149\n",
      "Epoch 1156, Loss: 0.08687070663893337, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1157, Loss: 0.046346353366971016, Final Batch Loss: 0.0\n",
      "Epoch 1158, Loss: 0.10666063986718655, Final Batch Loss: 0.010718867182731628\n",
      "Epoch 1159, Loss: 0.07976200571283698, Final Batch Loss: 0.00033563701435923576\n",
      "Epoch 1160, Loss: 0.08609640225768089, Final Batch Loss: 0.0\n",
      "Epoch 1161, Loss: 0.0868371929609566, Final Batch Loss: 6.16293036728166e-05\n",
      "Epoch 1162, Loss: 0.6917586531490088, Final Batch Loss: 0.6031783223152161\n",
      "Epoch 1163, Loss: 0.1556316070491448, Final Batch Loss: 0.0015232876176014543\n",
      "Epoch 1164, Loss: 0.40581585466861725, Final Batch Loss: 0.0\n",
      "Epoch 1165, Loss: 0.5336923301218803, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1166, Loss: 0.49095331924036145, Final Batch Loss: 0.007508509326726198\n",
      "Epoch 1167, Loss: 0.35158088777097873, Final Batch Loss: 0.00017414960893802345\n",
      "Epoch 1168, Loss: 0.2466832878999412, Final Batch Loss: 0.005414582323282957\n",
      "Epoch 1169, Loss: 0.24680515192449093, Final Batch Loss: 0.08466043323278427\n",
      "Epoch 1170, Loss: 0.1364378035068512, Final Batch Loss: 0.0\n",
      "Epoch 1171, Loss: 0.09339705028105527, Final Batch Loss: 0.0010621865512803197\n",
      "Epoch 1172, Loss: 0.10045723580515187, Final Batch Loss: 2.706014311115723e-05\n",
      "Epoch 1173, Loss: 0.15785411256365478, Final Batch Loss: 0.0028080816846340895\n",
      "Epoch 1174, Loss: 0.18186894431710243, Final Batch Loss: 0.0\n",
      "Epoch 1175, Loss: 0.1425699330329735, Final Batch Loss: 1.0371154530730564e-05\n",
      "Epoch 1176, Loss: 0.12843325757421553, Final Batch Loss: 0.0011381583753973246\n",
      "Epoch 1177, Loss: 0.10842061787832336, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1178, Loss: 0.07008100673522222, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1179, Loss: 0.09629623852379154, Final Batch Loss: 7.724463648628443e-05\n",
      "Epoch 1180, Loss: 0.10287018911913037, Final Batch Loss: 0.0058717853389680386\n",
      "Epoch 1181, Loss: 0.10821317695081234, Final Batch Loss: 0.0\n",
      "Epoch 1182, Loss: 0.08253533393144608, Final Batch Loss: 0.0\n",
      "Epoch 1183, Loss: 0.084885637725165, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1184, Loss: 0.0936879999935627, Final Batch Loss: 0.0\n",
      "Epoch 1185, Loss: 0.08861078275367618, Final Batch Loss: 0.0006201728247106075\n",
      "Epoch 1186, Loss: 0.09070696468370443, Final Batch Loss: 2.3245540432981215e-05\n",
      "Epoch 1187, Loss: 0.08911115861951657, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1188, Loss: 0.09056767169386148, Final Batch Loss: 0.008081830106675625\n",
      "Epoch 1189, Loss: 0.08456718147499487, Final Batch Loss: 0.0008314966107718647\n",
      "Epoch 1190, Loss: 0.09377298876643181, Final Batch Loss: 8.630380034446716e-05\n",
      "Epoch 1191, Loss: 0.08639709651469474, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1192, Loss: 0.2531223017722368, Final Batch Loss: 0.1527663767337799\n",
      "Epoch 1193, Loss: 0.07179853582056239, Final Batch Loss: 0.0003641180810518563\n",
      "Epoch 1194, Loss: 0.0995379444207174, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1195, Loss: 0.10297216475009918, Final Batch Loss: 0.0\n",
      "Epoch 1196, Loss: 0.11062710359692574, Final Batch Loss: 0.01796521618962288\n",
      "Epoch 1197, Loss: 0.10613955368944517, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 1198, Loss: 0.08438569599820767, Final Batch Loss: 0.00011300401820335537\n",
      "Epoch 1199, Loss: 0.09037047620040539, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 1200, Loss: 0.09513016510754824, Final Batch Loss: 0.0015550674870610237\n",
      "Epoch 1201, Loss: 0.1046388754475629, Final Batch Loss: 0.00012218205665703863\n",
      "Epoch 1202, Loss: 0.06717513951298315, Final Batch Loss: 4.672895011026412e-05\n",
      "Epoch 1203, Loss: 0.09299351461231709, Final Batch Loss: 0.0\n",
      "Epoch 1204, Loss: 0.09632172156125307, Final Batch Loss: 0.004269413650035858\n",
      "Epoch 1205, Loss: 1.6926731131970882, Final Batch Loss: 1.6193962097167969\n",
      "Epoch 1206, Loss: 0.14264079387066886, Final Batch Loss: 0.0002653246629051864\n",
      "Epoch 1207, Loss: 0.32080207765102386, Final Batch Loss: 0.0\n",
      "Epoch 1208, Loss: 0.4431101738009602, Final Batch Loss: 0.0022573007736355066\n",
      "Epoch 1209, Loss: 0.455412488168804, Final Batch Loss: 0.0003120412293355912\n",
      "Epoch 1210, Loss: 0.6870737001299858, Final Batch Loss: 0.2570876181125641\n",
      "Epoch 1211, Loss: 0.3474076110869646, Final Batch Loss: 0.00748058594763279\n",
      "Epoch 1212, Loss: 0.17857643216848373, Final Batch Loss: 0.0\n",
      "Epoch 1213, Loss: 0.12791849210043438, Final Batch Loss: 0.0001879753835964948\n",
      "Epoch 1214, Loss: 0.0975388101360295, Final Batch Loss: 6.246371776796877e-05\n",
      "Epoch 1215, Loss: 0.08974044770002365, Final Batch Loss: 0.0\n",
      "Epoch 1216, Loss: 0.3898321418091655, Final Batch Loss: 0.28850027918815613\n",
      "Epoch 1217, Loss: 0.092342922464006, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1218, Loss: 0.12002052366733551, Final Batch Loss: 0.0\n",
      "Epoch 1219, Loss: 0.101241028343793, Final Batch Loss: 0.0009005781612358987\n",
      "Epoch 1220, Loss: 0.10731733962893486, Final Batch Loss: 0.0\n",
      "Epoch 1221, Loss: 0.12934590317308903, Final Batch Loss: 0.01730954833328724\n",
      "Epoch 1222, Loss: 0.14048033580183983, Final Batch Loss: 0.0\n",
      "Epoch 1223, Loss: 0.08719921857118607, Final Batch Loss: 0.0\n",
      "Epoch 1224, Loss: 0.09645852976973401, Final Batch Loss: 6.55629628454335e-05\n",
      "Epoch 1225, Loss: 0.10165580455213785, Final Batch Loss: 0.0001431601122021675\n",
      "Epoch 1226, Loss: 0.099038945420034, Final Batch Loss: 4.51792984677013e-05\n",
      "Epoch 1227, Loss: 0.0873673661481007, Final Batch Loss: 4.124556289752945e-05\n",
      "Epoch 1228, Loss: 0.1052836300805211, Final Batch Loss: 0.02452765963971615\n",
      "Epoch 1229, Loss: 0.08564859814941883, Final Batch Loss: 0.002241719514131546\n",
      "Epoch 1230, Loss: 0.08941985480487347, Final Batch Loss: 0.0\n",
      "Epoch 1231, Loss: 0.0909209473466035, Final Batch Loss: 0.00016234986833296716\n",
      "Epoch 1232, Loss: 0.2606938797980547, Final Batch Loss: 0.16908973455429077\n",
      "Epoch 1233, Loss: 0.08958210441778647, Final Batch Loss: 0.00010394509445177391\n",
      "Epoch 1234, Loss: 0.079042155295582, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1235, Loss: 0.0944942307069141, Final Batch Loss: 2.5987286790041253e-05\n",
      "Epoch 1236, Loss: 0.08748345263279589, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1237, Loss: 0.06437104009091854, Final Batch Loss: 0.0\n",
      "Epoch 1238, Loss: 0.07703033648431301, Final Batch Loss: 0.010242754593491554\n",
      "Epoch 1239, Loss: 0.08482515625655651, Final Batch Loss: 0.0\n",
      "Epoch 1240, Loss: 0.08047072030512936, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1241, Loss: 0.0953307710401532, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 1242, Loss: 0.08858603366388706, Final Batch Loss: 3.433168603805825e-05\n",
      "Epoch 1243, Loss: 0.08158454857760944, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1244, Loss: 0.08250671846690238, Final Batch Loss: 5.495397272170521e-05\n",
      "Epoch 1245, Loss: 0.06841603107750416, Final Batch Loss: 0.0\n",
      "Epoch 1246, Loss: 0.1606100657954812, Final Batch Loss: 0.08458255231380463\n",
      "Epoch 1247, Loss: 0.08681116437082892, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 1248, Loss: 0.08181091118376571, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1249, Loss: 0.07028228044191565, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 1250, Loss: 0.07657891139388084, Final Batch Loss: 0.0\n",
      "Epoch 1251, Loss: 0.08646020293235779, Final Batch Loss: 0.0\n",
      "Epoch 1252, Loss: 0.06890965249021974, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 1253, Loss: 0.35456936713308096, Final Batch Loss: 0.28516876697540283\n",
      "Epoch 1254, Loss: 0.10018053671956295, Final Batch Loss: 5.745722592109814e-05\n",
      "Epoch 1255, Loss: 0.19294359162449837, Final Batch Loss: 0.0\n",
      "Epoch 1256, Loss: 0.2909784620278515, Final Batch Loss: 0.00040356122190132737\n",
      "Epoch 1257, Loss: 0.3210782780979571, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 1258, Loss: 0.2720057275146246, Final Batch Loss: 0.026834897696971893\n",
      "Epoch 1259, Loss: 0.24571513762930408, Final Batch Loss: 0.00025876989820972085\n",
      "Epoch 1260, Loss: 0.26481612044153735, Final Batch Loss: 0.00012063252506777644\n",
      "Epoch 1261, Loss: 0.2161617949604988, Final Batch Loss: 0.0\n",
      "Epoch 1262, Loss: 0.10798042639885352, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1263, Loss: 0.13538150605745614, Final Batch Loss: 0.003850191133096814\n",
      "Epoch 1264, Loss: 0.0902321582325385, Final Batch Loss: 8.451581379631534e-05\n",
      "Epoch 1265, Loss: 0.16499123629182577, Final Batch Loss: 0.05730706825852394\n",
      "Epoch 1266, Loss: 0.10162796590157086, Final Batch Loss: 3.123234637314454e-05\n",
      "Epoch 1267, Loss: 0.08464909231406637, Final Batch Loss: 0.0002411313180346042\n",
      "Epoch 1268, Loss: 0.07557240780442953, Final Batch Loss: 0.0\n",
      "Epoch 1269, Loss: 0.10790643165819347, Final Batch Loss: 0.0031477685552090406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1270, Loss: 0.08950226940214634, Final Batch Loss: 0.0\n",
      "Epoch 1271, Loss: 0.07189360586926341, Final Batch Loss: 0.0011379201896488667\n",
      "Epoch 1272, Loss: 0.09361060708761215, Final Batch Loss: 0.0\n",
      "Epoch 1273, Loss: 0.07151586131658405, Final Batch Loss: 0.0010362261673435569\n",
      "Epoch 1274, Loss: 0.09573468379675631, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1275, Loss: 0.09817607165314257, Final Batch Loss: 0.003181992331519723\n",
      "Epoch 1276, Loss: 0.0924584809672524, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1277, Loss: 0.07992783188183239, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 1278, Loss: 0.07646848447620869, Final Batch Loss: 0.0\n",
      "Epoch 1279, Loss: 0.10383965611254098, Final Batch Loss: 6.460934673668817e-05\n",
      "Epoch 1280, Loss: 0.10202946420758963, Final Batch Loss: 0.011002232320606709\n",
      "Epoch 1281, Loss: 0.07747052237391472, Final Batch Loss: 0.0\n",
      "Epoch 1282, Loss: 0.07502773557280307, Final Batch Loss: 2.5748875486897305e-05\n",
      "Epoch 1283, Loss: 0.0781739130616188, Final Batch Loss: 0.0\n",
      "Epoch 1284, Loss: 0.07523378357291222, Final Batch Loss: 0.0\n",
      "Epoch 1285, Loss: 0.08406375907361507, Final Batch Loss: 0.0\n",
      "Epoch 1286, Loss: 0.07692458735982655, Final Batch Loss: 4.8397800128441304e-05\n",
      "Epoch 1287, Loss: 0.08655326068401337, Final Batch Loss: 0.0\n",
      "Epoch 1288, Loss: 0.08083043061094486, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1289, Loss: 0.08795139379799366, Final Batch Loss: 0.0\n",
      "Epoch 1290, Loss: 0.08670091163367033, Final Batch Loss: 0.000952267087996006\n",
      "Epoch 1291, Loss: 0.10147691797465086, Final Batch Loss: 0.011932894587516785\n",
      "Epoch 1292, Loss: 0.08500331904906488, Final Batch Loss: 1.7165990357170813e-05\n",
      "Epoch 1293, Loss: 0.09041612036526203, Final Batch Loss: 0.0\n",
      "Epoch 1294, Loss: 0.08557981788180768, Final Batch Loss: 0.002188075101003051\n",
      "Epoch 1295, Loss: 0.07926394161768258, Final Batch Loss: 0.0005704921204596758\n",
      "Epoch 1296, Loss: 0.08430327288806438, Final Batch Loss: 0.0\n",
      "Epoch 1297, Loss: 0.08729992713779211, Final Batch Loss: 0.0\n",
      "Epoch 1298, Loss: 0.06606533657759428, Final Batch Loss: 0.0\n",
      "Epoch 1299, Loss: 0.07657727127752878, Final Batch Loss: 1.07287787614041e-05\n",
      "Epoch 1300, Loss: 0.09124089032394522, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1301, Loss: 0.06295253650750965, Final Batch Loss: 0.0018308082362636924\n",
      "Epoch 1302, Loss: 0.09097367798676714, Final Batch Loss: 0.0007104733376763761\n",
      "Epoch 1303, Loss: 0.05834516649588295, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1304, Loss: 1.7283335784450173, Final Batch Loss: 1.6545997858047485\n",
      "Epoch 1305, Loss: 0.10524472407996655, Final Batch Loss: 0.0\n",
      "Epoch 1306, Loss: 0.08712734654545073, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1307, Loss: 0.07701828815697809, Final Batch Loss: 5.781483559985645e-05\n",
      "Epoch 1308, Loss: 0.10162466578185558, Final Batch Loss: 0.0\n",
      "Epoch 1309, Loss: 0.08817995186836924, Final Batch Loss: 0.00017069313616957515\n",
      "Epoch 1310, Loss: 0.10214793088380247, Final Batch Loss: 0.0012715120101347566\n",
      "Epoch 1311, Loss: 0.0844245823093388, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1312, Loss: 0.09923620149492507, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1313, Loss: 0.08147642947733402, Final Batch Loss: 0.0\n",
      "Epoch 1314, Loss: 0.08785010688006167, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1315, Loss: 0.08359048515558243, Final Batch Loss: 0.0\n",
      "Epoch 1316, Loss: 0.08735465293284506, Final Batch Loss: 0.0013778250431641936\n",
      "Epoch 1317, Loss: 0.0731092672667728, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 1318, Loss: 0.08947074972093105, Final Batch Loss: 0.0\n",
      "Epoch 1319, Loss: 0.07302027195691352, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1320, Loss: 0.08402255550026894, Final Batch Loss: 0.0\n",
      "Epoch 1321, Loss: 0.07773373671807349, Final Batch Loss: 0.000869253883138299\n",
      "Epoch 1322, Loss: 0.07794325985014439, Final Batch Loss: 0.0\n",
      "Epoch 1323, Loss: 0.07408411609594623, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 1324, Loss: 0.08523191884160042, Final Batch Loss: 0.0\n",
      "Epoch 1325, Loss: 0.09221160784363747, Final Batch Loss: 0.005022765137255192\n",
      "Epoch 1326, Loss: 0.533162659034133, Final Batch Loss: 0.45817214250564575\n",
      "Epoch 1327, Loss: 0.09422621675184928, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 1328, Loss: 0.12200359255075455, Final Batch Loss: 0.014301188290119171\n",
      "Epoch 1329, Loss: 0.0973780881613493, Final Batch Loss: 0.0020905323326587677\n",
      "Epoch 1330, Loss: 0.11053430661559105, Final Batch Loss: 0.0\n",
      "Epoch 1331, Loss: 0.12799373152665794, Final Batch Loss: 0.0007489498239010572\n",
      "Epoch 1332, Loss: 0.09119435012689792, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 1333, Loss: 0.0813508927822113, Final Batch Loss: 0.0\n",
      "Epoch 1334, Loss: 0.08746465985313989, Final Batch Loss: 0.00014041867689229548\n",
      "Epoch 1335, Loss: 0.08043664880096912, Final Batch Loss: 0.0\n",
      "Epoch 1336, Loss: 0.09714527614414692, Final Batch Loss: 0.018918784335255623\n",
      "Epoch 1337, Loss: 0.08738266490399127, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1338, Loss: 0.07591728493571281, Final Batch Loss: 0.0\n",
      "Epoch 1339, Loss: 0.08043722854926472, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1340, Loss: 0.0974496640264988, Final Batch Loss: 0.0\n",
      "Epoch 1341, Loss: 0.08407862531021237, Final Batch Loss: 0.004991925787180662\n",
      "Epoch 1342, Loss: 0.07771749133826233, Final Batch Loss: 7.593343616463244e-05\n",
      "Epoch 1343, Loss: 0.06538112659472972, Final Batch Loss: 0.0006697318749502301\n",
      "Epoch 1344, Loss: 0.061608996853465214, Final Batch Loss: 0.00013195598148740828\n",
      "Epoch 1345, Loss: 0.0772071170322306, Final Batch Loss: 4.9828242481453344e-05\n",
      "Epoch 1346, Loss: 0.1005194954414037, Final Batch Loss: 0.00010227633902104571\n",
      "Epoch 1347, Loss: 0.08365956507623196, Final Batch Loss: 0.0184574443846941\n",
      "Epoch 1348, Loss: 0.07338757719116984, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 1349, Loss: 0.08626862708479166, Final Batch Loss: 0.0\n",
      "Epoch 1350, Loss: 0.07340069743804634, Final Batch Loss: 0.0032109867315739393\n",
      "Epoch 1351, Loss: 0.06437424570322037, Final Batch Loss: 0.004335528239607811\n",
      "Epoch 1352, Loss: 0.08156059589236975, Final Batch Loss: 0.0\n",
      "Epoch 1353, Loss: 0.08719201944768429, Final Batch Loss: 0.0\n",
      "Epoch 1354, Loss: 0.07808665139600635, Final Batch Loss: 0.0\n",
      "Epoch 1355, Loss: 0.0717204492538599, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1356, Loss: 0.07620126008987427, Final Batch Loss: 0.0\n",
      "Epoch 1357, Loss: 0.29306059796363115, Final Batch Loss: 0.21449880301952362\n",
      "Epoch 1358, Loss: 0.07487132586538792, Final Batch Loss: 0.0\n",
      "Epoch 1359, Loss: 0.09205421246554124, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1360, Loss: 0.11094040817260975, Final Batch Loss: 5.745722592109814e-05\n",
      "Epoch 1361, Loss: 0.09443170763552189, Final Batch Loss: 0.0\n",
      "Epoch 1362, Loss: 0.07195893209268434, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 1363, Loss: 0.08475026485302806, Final Batch Loss: 7.748573807475623e-06\n",
      "Epoch 1364, Loss: 0.07125172555606696, Final Batch Loss: 2.109982233378105e-05\n",
      "Epoch 1365, Loss: 0.08700734376816399, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1366, Loss: 0.08123282343149185, Final Batch Loss: 0.0\n",
      "Epoch 1367, Loss: 0.10595111269503832, Final Batch Loss: 0.015534586273133755\n",
      "Epoch 1368, Loss: 0.05758342699846253, Final Batch Loss: 0.0005179494037292898\n",
      "Epoch 1369, Loss: 0.06751922890543938, Final Batch Loss: 0.0\n",
      "Epoch 1370, Loss: 0.07156869350001216, Final Batch Loss: 0.003657320514321327\n",
      "Epoch 1371, Loss: 0.09307296760380268, Final Batch Loss: 0.0192757286131382\n",
      "Epoch 1372, Loss: 0.06863244157283788, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1373, Loss: 0.06600017906202993, Final Batch Loss: 2.5510462364763953e-05\n",
      "Epoch 1374, Loss: 0.1841030428186059, Final Batch Loss: 0.11120525747537613\n",
      "Epoch 1375, Loss: 0.07140232283745718, Final Batch Loss: 1.6093124941107817e-05\n",
      "Epoch 1376, Loss: 0.082991654984653, Final Batch Loss: 0.0\n",
      "Epoch 1377, Loss: 0.06709157302907442, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1378, Loss: 0.0817649676464498, Final Batch Loss: 0.002947393339127302\n",
      "Epoch 1379, Loss: 0.0696219831079361, Final Batch Loss: 4.017272294731811e-05\n",
      "Epoch 1380, Loss: 0.09403838406433351, Final Batch Loss: 0.00022825974156148732\n",
      "Epoch 1381, Loss: 0.07921514101326466, Final Batch Loss: 0.0\n",
      "Epoch 1382, Loss: 0.07517800198638724, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 1383, Loss: 0.08261842373758554, Final Batch Loss: 0.0008554374799132347\n",
      "Epoch 1384, Loss: 0.06682471279020774, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1385, Loss: 0.056040896102786064, Final Batch Loss: 0.0\n",
      "Epoch 1386, Loss: 0.07526138858520426, Final Batch Loss: 0.000486970558995381\n",
      "Epoch 1387, Loss: 0.08890272118150477, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1388, Loss: 0.054796941571112256, Final Batch Loss: 3.814689989667386e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1389, Loss: 0.06017064303159714, Final Batch Loss: 0.0\n",
      "Epoch 1390, Loss: 0.07629081513732672, Final Batch Loss: 0.0\n",
      "Epoch 1391, Loss: 0.06207730620997154, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1392, Loss: 0.056752366945147514, Final Batch Loss: 0.0\n",
      "Epoch 1393, Loss: 0.10393457103782566, Final Batch Loss: 1.4781842764932662e-05\n",
      "Epoch 1394, Loss: 0.07625040432321839, Final Batch Loss: 5.757642793469131e-05\n",
      "Epoch 1395, Loss: 0.0703216066758614, Final Batch Loss: 0.00037067217635922134\n",
      "Epoch 1396, Loss: 0.07278860447695479, Final Batch Loss: 0.0005790702416561544\n",
      "Epoch 1397, Loss: 0.05522899136849446, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 1398, Loss: 0.047257671005354496, Final Batch Loss: 1.597391747054644e-05\n",
      "Epoch 1399, Loss: 0.05754624307132872, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1400, Loss: 0.06789774820207839, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1401, Loss: 0.07190771403111285, Final Batch Loss: 8.606540359323844e-05\n",
      "Epoch 1402, Loss: 0.0679880240932107, Final Batch Loss: 0.0\n",
      "Epoch 1403, Loss: 0.06173811386452144, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 1404, Loss: 0.08802743349224329, Final Batch Loss: 0.0017804736271500587\n",
      "Epoch 1405, Loss: 0.06317782588303089, Final Batch Loss: 0.00011419598013162613\n",
      "Epoch 1406, Loss: 0.06405644997721538, Final Batch Loss: 3.242440288886428e-05\n",
      "Epoch 1407, Loss: 0.059879157692193985, Final Batch Loss: 0.0\n",
      "Epoch 1408, Loss: 0.07358316145837307, Final Batch Loss: 0.004996432922780514\n",
      "Epoch 1409, Loss: 0.06974442861951502, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1410, Loss: 0.07602110953303054, Final Batch Loss: 0.00013076403411105275\n",
      "Epoch 1411, Loss: 0.06768966931792875, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1412, Loss: 0.07562410767786787, Final Batch Loss: 3.564294092939235e-05\n",
      "Epoch 1413, Loss: 0.05310786422342062, Final Batch Loss: 0.0\n",
      "Epoch 1414, Loss: 0.061532273852208164, Final Batch Loss: 0.00010609064338495955\n",
      "Epoch 1415, Loss: 0.07112383469848282, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1416, Loss: 0.062466127797961235, Final Batch Loss: 0.00655986275523901\n",
      "Epoch 1417, Loss: 0.07098113372921944, Final Batch Loss: 0.0\n",
      "Epoch 1418, Loss: 0.0528860669582798, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1419, Loss: 0.07189155649393797, Final Batch Loss: 0.0\n",
      "Epoch 1420, Loss: 0.0868207439774551, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1421, Loss: 0.0794672798317606, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1422, Loss: 0.08018804668972734, Final Batch Loss: 0.00010108436981681734\n",
      "Epoch 1423, Loss: 0.05270839414515649, Final Batch Loss: 2.074220174108632e-05\n",
      "Epoch 1424, Loss: 0.05325770052149892, Final Batch Loss: 0.0\n",
      "Epoch 1425, Loss: 0.05508607148658484, Final Batch Loss: 0.0002898749662563205\n",
      "Epoch 1426, Loss: 0.050951056182377386, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1427, Loss: 0.07995477365329862, Final Batch Loss: 0.0\n",
      "Epoch 1428, Loss: 0.21784692257642746, Final Batch Loss: 0.1714211106300354\n",
      "Epoch 1429, Loss: 0.07137581706001583, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1430, Loss: 0.08147310744971037, Final Batch Loss: 0.012012520805001259\n",
      "Epoch 1431, Loss: 0.05407700812793337, Final Batch Loss: 3.4927710657939315e-05\n",
      "Epoch 1432, Loss: 0.05928181577348823, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1433, Loss: 0.07829658687114716, Final Batch Loss: 0.0\n",
      "Epoch 1434, Loss: 0.08166543953120708, Final Batch Loss: 0.0\n",
      "Epoch 1435, Loss: 0.0646638972684741, Final Batch Loss: 0.004444364458322525\n",
      "Epoch 1436, Loss: 0.07558874878930055, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1437, Loss: 0.05691655818372965, Final Batch Loss: 0.0\n",
      "Epoch 1438, Loss: 0.0566695099696517, Final Batch Loss: 0.0\n",
      "Epoch 1439, Loss: 0.09115722763817757, Final Batch Loss: 0.0002520958660170436\n",
      "Epoch 1440, Loss: 0.06529376562684774, Final Batch Loss: 0.0\n",
      "Epoch 1441, Loss: 0.07214569113898506, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1442, Loss: 0.06778849847614765, Final Batch Loss: 0.0024748193100094795\n",
      "Epoch 1443, Loss: 0.06484454544261098, Final Batch Loss: 0.0\n",
      "Epoch 1444, Loss: 0.07215361576527357, Final Batch Loss: 0.005300634540617466\n",
      "Epoch 1445, Loss: 0.06412922032177448, Final Batch Loss: 0.0\n",
      "Epoch 1446, Loss: 0.06152256485074048, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1447, Loss: 0.06837051280672313, Final Batch Loss: 5.900685573578812e-05\n",
      "Epoch 1448, Loss: 0.06694892607629299, Final Batch Loss: 0.0\n",
      "Epoch 1449, Loss: 0.08040319755673409, Final Batch Loss: 0.0\n",
      "Epoch 1450, Loss: 0.07308702822774649, Final Batch Loss: 0.0\n",
      "Epoch 1451, Loss: 0.08296068757636021, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 1452, Loss: 0.058056081626546074, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 1453, Loss: 0.08222485438454896, Final Batch Loss: 0.00012861855793744326\n",
      "Epoch 1454, Loss: 0.08806369826197624, Final Batch Loss: 0.003929988946765661\n",
      "Epoch 1455, Loss: 0.07305470659957791, Final Batch Loss: 1.2516897186287679e-05\n",
      "Epoch 1456, Loss: 0.06484407878451748, Final Batch Loss: 3.2543604902457446e-05\n",
      "Epoch 1457, Loss: 0.07363281026482582, Final Batch Loss: 0.0\n",
      "Epoch 1458, Loss: 0.052128781790088397, Final Batch Loss: 5.721882189391181e-05\n",
      "Epoch 1459, Loss: 0.1542459251359105, Final Batch Loss: 0.07285717129707336\n",
      "Epoch 1460, Loss: 0.058610183814380434, Final Batch Loss: 2.4676019165781327e-05\n",
      "Epoch 1461, Loss: 0.05642576888203621, Final Batch Loss: 0.0\n",
      "Epoch 1462, Loss: 0.05295899789774694, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1463, Loss: 0.059832854191654405, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1464, Loss: 0.0728021776303649, Final Batch Loss: 0.004834866151213646\n",
      "Epoch 1465, Loss: 0.05857773217826434, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1466, Loss: 0.07028766348958015, Final Batch Loss: 0.0\n",
      "Epoch 1467, Loss: 0.07647486589843311, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1468, Loss: 0.06786567473318428, Final Batch Loss: 3.40932747349143e-05\n",
      "Epoch 1469, Loss: 0.06745345883973641, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 1470, Loss: 0.06337400013580918, Final Batch Loss: 0.0013141338713467121\n",
      "Epoch 1471, Loss: 0.07067360659129918, Final Batch Loss: 0.002095290692523122\n",
      "Epoch 1472, Loss: 0.07214141014264897, Final Batch Loss: 0.00017629499780014157\n",
      "Epoch 1473, Loss: 0.057931382209062576, Final Batch Loss: 0.0\n",
      "Epoch 1474, Loss: 0.06932946294489284, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1475, Loss: 0.05853689741342549, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1476, Loss: 0.04949342738814266, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1477, Loss: 0.07778269750997424, Final Batch Loss: 0.007625637110322714\n",
      "Epoch 1478, Loss: 0.09541008342057467, Final Batch Loss: 0.0\n",
      "Epoch 1479, Loss: 0.055139005882665515, Final Batch Loss: 0.002635103417560458\n",
      "Epoch 1480, Loss: 0.8701595608144999, Final Batch Loss: 0.807264506816864\n",
      "Epoch 1481, Loss: 0.08085401263087988, Final Batch Loss: 0.0\n",
      "Epoch 1482, Loss: 0.16742002964019775, Final Batch Loss: 0.0\n",
      "Epoch 1483, Loss: 0.24487048014998436, Final Batch Loss: 0.0\n",
      "Epoch 1484, Loss: 0.2937737815082002, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1485, Loss: 0.27756899819360115, Final Batch Loss: 0.0002914242504630238\n",
      "Epoch 1486, Loss: 0.19024336581787793, Final Batch Loss: 5.07818695041351e-05\n",
      "Epoch 1487, Loss: 0.13332645594937276, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 1488, Loss: 0.21903297863900661, Final Batch Loss: 0.11730121076107025\n",
      "Epoch 1489, Loss: 0.2178064063191414, Final Batch Loss: 0.09012145549058914\n",
      "Epoch 1490, Loss: 0.07326105516401071, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1491, Loss: 0.09197719302028418, Final Batch Loss: 0.0011966219171881676\n",
      "Epoch 1492, Loss: 0.09537045571778435, Final Batch Loss: 5.98412734689191e-05\n",
      "Epoch 1493, Loss: 0.11932987380714621, Final Batch Loss: 7.009260298218578e-05\n",
      "Epoch 1494, Loss: 0.12104473263025284, Final Batch Loss: 0.0\n",
      "Epoch 1495, Loss: 0.10937262512743473, Final Batch Loss: 0.0\n",
      "Epoch 1496, Loss: 0.09452375303953886, Final Batch Loss: 0.0\n",
      "Epoch 1497, Loss: 0.08426272309793603, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1498, Loss: 0.12198306247591972, Final Batch Loss: 0.011975770816206932\n",
      "Epoch 1499, Loss: 0.10238903373829089, Final Batch Loss: 7.664863369427621e-05\n",
      "Epoch 1500, Loss: 0.1017624996602251, Final Batch Loss: 2.3841855067985307e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1501, Loss: 0.08771002665162086, Final Batch Loss: 0.0\n",
      "Epoch 1502, Loss: 0.09034626214997843, Final Batch Loss: 0.0005687049706466496\n",
      "Epoch 1503, Loss: 0.0780231892131269, Final Batch Loss: 0.005654293578118086\n",
      "Epoch 1504, Loss: 0.07596347271464765, Final Batch Loss: 0.00013124081306159496\n",
      "Epoch 1505, Loss: 0.06865527993068099, Final Batch Loss: 0.0006884350441396236\n",
      "Epoch 1506, Loss: 0.08095724228769541, Final Batch Loss: 0.0\n",
      "Epoch 1507, Loss: 0.0751673509948887, Final Batch Loss: 0.0005113962688483298\n",
      "Epoch 1508, Loss: 0.11776586016640067, Final Batch Loss: 8.070142939686775e-05\n",
      "Epoch 1509, Loss: 0.08387977731763385, Final Batch Loss: 4.1126360883936286e-05\n",
      "Epoch 1510, Loss: 0.07442825394173269, Final Batch Loss: 3.9934315282152966e-05\n",
      "Epoch 1511, Loss: 0.06681258749449626, Final Batch Loss: 0.0004755319678224623\n",
      "Epoch 1512, Loss: 0.07824269216507673, Final Batch Loss: 0.0\n",
      "Epoch 1513, Loss: 0.0862509177532047, Final Batch Loss: 2.1576648578047752e-05\n",
      "Epoch 1514, Loss: 0.09497881960112409, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1515, Loss: 0.07085254043340683, Final Batch Loss: 0.004102861508727074\n",
      "Epoch 1516, Loss: 0.11292407726068632, Final Batch Loss: 4.935142715112306e-05\n",
      "Epoch 1517, Loss: 0.06287939846514945, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1518, Loss: 0.07207114248558355, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 1519, Loss: 0.08465420920401812, Final Batch Loss: 0.012600335292518139\n",
      "Epoch 1520, Loss: 0.09033120039384812, Final Batch Loss: 1.5258672647178173e-05\n",
      "Epoch 1521, Loss: 0.08564970828592777, Final Batch Loss: 0.00718083418905735\n",
      "Epoch 1522, Loss: 0.09282472828635946, Final Batch Loss: 0.0005194983095861971\n",
      "Epoch 1523, Loss: 0.10454058460891247, Final Batch Loss: 0.0\n",
      "Epoch 1524, Loss: 0.09919049773998267, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 1525, Loss: 0.11509528290480375, Final Batch Loss: 0.014711824245750904\n",
      "Epoch 1526, Loss: 0.09359466056230303, Final Batch Loss: 2.8967437174287625e-05\n",
      "Epoch 1527, Loss: 0.12319833906803979, Final Batch Loss: 7.080780778778717e-05\n",
      "Epoch 1528, Loss: 0.06240014638751745, Final Batch Loss: 0.0\n",
      "Epoch 1529, Loss: 0.08562866039505934, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1530, Loss: 0.200914529930742, Final Batch Loss: 1.7523612768854946e-05\n",
      "Epoch 1531, Loss: 0.06675439666469174, Final Batch Loss: 2.610649426060263e-05\n",
      "Epoch 1532, Loss: 0.08001167775364593, Final Batch Loss: 0.0002631794777698815\n",
      "Epoch 1533, Loss: 0.07883482240140438, Final Batch Loss: 0.012560546398162842\n",
      "Epoch 1534, Loss: 0.07039222300136316, Final Batch Loss: 1.2159273865108844e-05\n",
      "Epoch 1535, Loss: 0.0987255061045289, Final Batch Loss: 0.028192836791276932\n",
      "Epoch 1536, Loss: 1.8697948772460222, Final Batch Loss: 1.7993590831756592\n",
      "Epoch 1537, Loss: 0.07895579375326633, Final Batch Loss: 0.0\n",
      "Epoch 1538, Loss: 0.20005392655730247, Final Batch Loss: 0.03589759021997452\n",
      "Epoch 1539, Loss: 0.12507629952642674, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 1540, Loss: 0.10742293298244476, Final Batch Loss: 0.0\n",
      "Epoch 1541, Loss: 0.10973628415831627, Final Batch Loss: 1.2874520507466514e-05\n",
      "Epoch 1542, Loss: 0.15307312086224556, Final Batch Loss: 0.0\n",
      "Epoch 1543, Loss: 0.107170729781501, Final Batch Loss: 0.000248401309363544\n",
      "Epoch 1544, Loss: 0.09929442033171654, Final Batch Loss: 0.0\n",
      "Epoch 1545, Loss: 0.0955946072936058, Final Batch Loss: 0.003944000229239464\n",
      "Epoch 1546, Loss: 0.08854381926357746, Final Batch Loss: 0.0\n",
      "Epoch 1547, Loss: 0.08063953163218684, Final Batch Loss: 0.00012373158824630082\n",
      "Epoch 1548, Loss: 0.10118456743657589, Final Batch Loss: 0.006405062973499298\n",
      "Epoch 1549, Loss: 0.08362706191837788, Final Batch Loss: 0.0\n",
      "Epoch 1550, Loss: 0.08590457028958554, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 1551, Loss: 0.08281560800514853, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 1552, Loss: 0.08781712501377115, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 1553, Loss: 0.06572778095141985, Final Batch Loss: 6.949660019017756e-05\n",
      "Epoch 1554, Loss: 0.058612035541955265, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 1555, Loss: 0.0770309281651862, Final Batch Loss: 9.345571743324399e-05\n",
      "Epoch 1556, Loss: 0.07219299487769604, Final Batch Loss: 0.0\n",
      "Epoch 1557, Loss: 0.07481069548521191, Final Batch Loss: 0.0011717366287484765\n",
      "Epoch 1558, Loss: 0.06621868908405304, Final Batch Loss: 0.0\n",
      "Epoch 1559, Loss: 0.07222770806401968, Final Batch Loss: 0.0\n",
      "Epoch 1560, Loss: 0.07374200690537691, Final Batch Loss: 0.0\n",
      "Epoch 1561, Loss: 0.052921952679753304, Final Batch Loss: 0.0\n",
      "Epoch 1562, Loss: 0.06571395602077246, Final Batch Loss: 0.0\n",
      "Epoch 1563, Loss: 0.07196262517391006, Final Batch Loss: 0.00011073929636040702\n",
      "Epoch 1564, Loss: 0.06423239037326312, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1565, Loss: 0.07059486769139767, Final Batch Loss: 0.007025420665740967\n",
      "Epoch 1566, Loss: 0.09276354499161243, Final Batch Loss: 0.02974301017820835\n",
      "Epoch 1567, Loss: 0.10043186042457819, Final Batch Loss: 0.0015430459752678871\n",
      "Epoch 1568, Loss: 0.0811798982322216, Final Batch Loss: 0.01162351667881012\n",
      "Epoch 1569, Loss: 0.07300026156008244, Final Batch Loss: 0.0\n",
      "Epoch 1570, Loss: 0.05862793597771088, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 1571, Loss: 0.08951821178186492, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1572, Loss: 0.04984780587255955, Final Batch Loss: 0.0\n",
      "Epoch 1573, Loss: 0.07432249326666351, Final Batch Loss: 3.099393507000059e-05\n",
      "Epoch 1574, Loss: 0.05409654602408409, Final Batch Loss: 0.00022003613412380219\n",
      "Epoch 1575, Loss: 0.07186686480417848, Final Batch Loss: 0.0023843212984502316\n",
      "Epoch 1576, Loss: 0.07115631921624299, Final Batch Loss: 0.00012218205665703863\n",
      "Epoch 1577, Loss: 0.08932841836940497, Final Batch Loss: 0.0014107999159023166\n",
      "Epoch 1578, Loss: 0.06673803925514221, Final Batch Loss: 0.0\n",
      "Epoch 1579, Loss: 0.08953123618448444, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 1580, Loss: 0.06833666749116674, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1581, Loss: 0.10034010373055935, Final Batch Loss: 0.04096396639943123\n",
      "Epoch 1582, Loss: 0.06258461996912956, Final Batch Loss: 0.0\n",
      "Epoch 1583, Loss: 0.07418752632111136, Final Batch Loss: 1.7762025890988298e-05\n",
      "Epoch 1584, Loss: 0.06611383240669966, Final Batch Loss: 0.0\n",
      "Epoch 1585, Loss: 0.057087237015366554, Final Batch Loss: 0.0\n",
      "Epoch 1586, Loss: 0.2735707573592663, Final Batch Loss: 0.21012738347053528\n",
      "Epoch 1587, Loss: 0.06712429597973113, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1588, Loss: 0.05274397643734119, Final Batch Loss: 3.158996332786046e-05\n",
      "Epoch 1589, Loss: 0.07373474445194006, Final Batch Loss: 0.0\n",
      "Epoch 1590, Loss: 0.05777900354951271, Final Batch Loss: 3.957670196541585e-05\n",
      "Epoch 1591, Loss: 0.07598917989525944, Final Batch Loss: 0.0012693690368905663\n",
      "Epoch 1592, Loss: 0.0630805604159832, Final Batch Loss: 0.0\n",
      "Epoch 1593, Loss: 0.05331779638254375, Final Batch Loss: 1.0609570381348021e-05\n",
      "Epoch 1594, Loss: 0.058307736180722713, Final Batch Loss: 0.0\n",
      "Epoch 1595, Loss: 0.07006510705105029, Final Batch Loss: 0.00047302976599894464\n",
      "Epoch 1596, Loss: 0.07263811090524541, Final Batch Loss: 2.3841574147809297e-05\n",
      "Epoch 1597, Loss: 0.057437192648649216, Final Batch Loss: 0.0\n",
      "Epoch 1598, Loss: 0.14192002452909946, Final Batch Loss: 0.054914917796850204\n",
      "Epoch 1599, Loss: 0.04957098513841629, Final Batch Loss: 0.0\n",
      "Epoch 1600, Loss: 0.06572069134494996, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1601, Loss: 0.06308110273675993, Final Batch Loss: 0.0006791430641897023\n",
      "Epoch 1602, Loss: 0.051526322029531, Final Batch Loss: 0.0\n",
      "Epoch 1603, Loss: 0.05340839736163616, Final Batch Loss: 0.0003343261778354645\n",
      "Epoch 1604, Loss: 0.0664048083126545, Final Batch Loss: 0.0\n",
      "Epoch 1605, Loss: 0.06625782512128353, Final Batch Loss: 0.0\n",
      "Epoch 1606, Loss: 0.0695031797511092, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1607, Loss: 0.0569750936691662, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1608, Loss: 0.04328791797161102, Final Batch Loss: 0.0\n",
      "Epoch 1609, Loss: 0.0580958491191268, Final Batch Loss: 0.0\n",
      "Epoch 1610, Loss: 0.24380884878337383, Final Batch Loss: 0.16856171190738678\n",
      "Epoch 1611, Loss: 0.059290997683547175, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1612, Loss: 0.04729437548666482, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1613, Loss: 0.09281250089406967, Final Batch Loss: 0.0\n",
      "Epoch 1614, Loss: 0.08251203035570143, Final Batch Loss: 6.6756979322235566e-06\n",
      "Epoch 1615, Loss: 0.07478212378919125, Final Batch Loss: 0.005664369091391563\n",
      "Epoch 1616, Loss: 0.08290984947234392, Final Batch Loss: 0.009862503968179226\n",
      "Epoch 1617, Loss: 0.07022154983133078, Final Batch Loss: 0.0\n",
      "Epoch 1618, Loss: 0.06192269176227683, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1619, Loss: 0.07861451990901713, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1620, Loss: 0.07066253200173378, Final Batch Loss: 0.0\n",
      "Epoch 1621, Loss: 0.06416065711005103, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1622, Loss: 0.06513046193867922, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1623, Loss: 0.07120451517403126, Final Batch Loss: 0.0\n",
      "Epoch 1624, Loss: 0.06962090451270342, Final Batch Loss: 0.0\n",
      "Epoch 1625, Loss: 0.05274585634469986, Final Batch Loss: 0.0\n",
      "Epoch 1626, Loss: 0.08044365048408508, Final Batch Loss: 0.0\n",
      "Epoch 1627, Loss: 0.05178813450038433, Final Batch Loss: 0.0\n",
      "Epoch 1628, Loss: 0.06499332612656872, Final Batch Loss: 2.9205850296420977e-05\n",
      "Epoch 1629, Loss: 0.05628034099936485, Final Batch Loss: 0.0\n",
      "Epoch 1630, Loss: 0.11100962944328785, Final Batch Loss: 0.05242246389389038\n",
      "Epoch 1631, Loss: 0.06238951627165079, Final Batch Loss: 0.0\n",
      "Epoch 1632, Loss: 0.047532317228615284, Final Batch Loss: 0.0\n",
      "Epoch 1633, Loss: 0.06530960090458393, Final Batch Loss: 0.0\n",
      "Epoch 1634, Loss: 0.07133414223790169, Final Batch Loss: 0.018228743225336075\n",
      "Epoch 1635, Loss: 0.07307768612849941, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1636, Loss: 0.0914026964455843, Final Batch Loss: 0.0\n",
      "Epoch 1637, Loss: 0.07165352441370487, Final Batch Loss: 0.0\n",
      "Epoch 1638, Loss: 0.0736326705664112, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1639, Loss: 0.07602822494663997, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 1640, Loss: 0.08690922684036195, Final Batch Loss: 0.0012236495967954397\n",
      "Epoch 1641, Loss: 0.048952301032841206, Final Batch Loss: 0.0\n",
      "Epoch 1642, Loss: 0.05696056084707379, Final Batch Loss: 0.0\n",
      "Epoch 1643, Loss: 0.054773084819146334, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1644, Loss: 0.07110781165101798, Final Batch Loss: 6.985420623095706e-05\n",
      "Epoch 1645, Loss: 0.06383388233371079, Final Batch Loss: 0.0036676537711173296\n",
      "Epoch 1646, Loss: 0.04894256126135588, Final Batch Loss: 0.0\n",
      "Epoch 1647, Loss: 0.05687945429235697, Final Batch Loss: 0.0\n",
      "Epoch 1648, Loss: 0.07604199228808284, Final Batch Loss: 0.0\n",
      "Epoch 1649, Loss: 0.04892912524519488, Final Batch Loss: 0.0003195490571670234\n",
      "Epoch 1650, Loss: 0.049193549901247025, Final Batch Loss: 0.0\n",
      "Epoch 1651, Loss: 0.05953599140048027, Final Batch Loss: 0.0\n",
      "Epoch 1652, Loss: 0.04709780868142843, Final Batch Loss: 0.0\n",
      "Epoch 1653, Loss: 0.04777663387199027, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 1654, Loss: 0.05187801271677017, Final Batch Loss: 0.0\n",
      "Epoch 1655, Loss: 0.07887254992965609, Final Batch Loss: 0.0012997282901778817\n",
      "Epoch 1656, Loss: 0.06115479860454087, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1657, Loss: 0.047963413409888744, Final Batch Loss: 0.0\n",
      "Epoch 1658, Loss: 0.060034033841361634, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1659, Loss: 0.048038471490087886, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1660, Loss: 0.06393274758011103, Final Batch Loss: 0.0073389457538723946\n",
      "Epoch 1661, Loss: 0.07043674308806658, Final Batch Loss: 0.014282620511949062\n",
      "Epoch 1662, Loss: 0.05708283092826605, Final Batch Loss: 0.0\n",
      "Epoch 1663, Loss: 0.4634180795401335, Final Batch Loss: 0.38571977615356445\n",
      "Epoch 1664, Loss: 0.10559171997010708, Final Batch Loss: 0.0\n",
      "Epoch 1665, Loss: 0.05668043391779065, Final Batch Loss: 0.005423000548034906\n",
      "Epoch 1666, Loss: 0.06419170531444252, Final Batch Loss: 0.0018753099720925093\n",
      "Epoch 1667, Loss: 0.07024130877107382, Final Batch Loss: 0.0\n",
      "Epoch 1668, Loss: 0.05626774858683348, Final Batch Loss: 0.0\n",
      "Epoch 1669, Loss: 0.05489960499107838, Final Batch Loss: 0.0\n",
      "Epoch 1670, Loss: 0.07036009244563957, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1671, Loss: 0.038173896726220846, Final Batch Loss: 0.0\n",
      "Epoch 1672, Loss: 0.053898766579550283, Final Batch Loss: 1.07287787614041e-05\n",
      "Epoch 1673, Loss: 0.07791539467871189, Final Batch Loss: 0.0\n",
      "Epoch 1674, Loss: 0.04286825470626354, Final Batch Loss: 0.0\n",
      "Epoch 1675, Loss: 0.08139686164213344, Final Batch Loss: 0.00024911639047786593\n",
      "Epoch 1676, Loss: 0.06045454507375325, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 1677, Loss: 0.06389996875076775, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1678, Loss: 0.06352376926770376, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 1679, Loss: 0.07210209034377613, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1680, Loss: 0.05052246060222387, Final Batch Loss: 0.0\n",
      "Epoch 1681, Loss: 0.05561893020058051, Final Batch Loss: 0.00031764229061082006\n",
      "Epoch 1682, Loss: 0.06364510767159004, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1683, Loss: 0.052766893059015274, Final Batch Loss: 0.0\n",
      "Epoch 1684, Loss: 0.04713872540742159, Final Batch Loss: 0.0\n",
      "Epoch 1685, Loss: 0.05353110322903376, Final Batch Loss: 5.4238757002167404e-05\n",
      "Epoch 1686, Loss: 0.055485837743617594, Final Batch Loss: 0.0011605439940467477\n",
      "Epoch 1687, Loss: 0.03932246007025242, Final Batch Loss: 0.0\n",
      "Epoch 1688, Loss: 0.06510610576515319, Final Batch Loss: 9.881961887003854e-05\n",
      "Epoch 1689, Loss: 0.05661269323900342, Final Batch Loss: 0.0\n",
      "Epoch 1690, Loss: 0.07100824732333422, Final Batch Loss: 0.0\n",
      "Epoch 1691, Loss: 0.06896543502807617, Final Batch Loss: 0.0\n",
      "Epoch 1692, Loss: 0.051625258289277554, Final Batch Loss: 0.0\n",
      "Epoch 1693, Loss: 0.04445853735774108, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1694, Loss: 0.06358237091626506, Final Batch Loss: 0.0001530530134914443\n",
      "Epoch 1695, Loss: 0.041823448613229175, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1696, Loss: 0.04750596825033426, Final Batch Loss: 0.0\n",
      "Epoch 1697, Loss: 0.05173267817008309, Final Batch Loss: 0.00014172980445437133\n",
      "Epoch 1698, Loss: 0.06623279256746173, Final Batch Loss: 0.0\n",
      "Epoch 1699, Loss: 0.0448097363114357, Final Batch Loss: 0.0\n",
      "Epoch 1700, Loss: 0.03462760569072998, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 1701, Loss: 0.040791505482047796, Final Batch Loss: 0.0\n",
      "Epoch 1702, Loss: 0.11485248245298862, Final Batch Loss: 0.029427172616124153\n",
      "Epoch 1703, Loss: 0.06169719167519361, Final Batch Loss: 0.001719426247291267\n",
      "Epoch 1704, Loss: 0.04546832104870191, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 1705, Loss: 0.04923431198767503, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 1706, Loss: 1.203813404776156, Final Batch Loss: 1.1677485704421997\n",
      "Epoch 1707, Loss: 0.057119751694699517, Final Batch Loss: 3.421248038648628e-05\n",
      "Epoch 1708, Loss: 0.12137727437675494, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 1709, Loss: 0.17527191009139642, Final Batch Loss: 0.0006952252588234842\n",
      "Epoch 1710, Loss: 7.7810403034091, Final Batch Loss: 7.606985092163086\n",
      "Epoch 1711, Loss: 0.12697330614901148, Final Batch Loss: 0.0003190723655279726\n",
      "Epoch 1712, Loss: 0.18162563629448414, Final Batch Loss: 0.06146776303648949\n",
      "Epoch 1713, Loss: 0.6253541447222233, Final Batch Loss: 0.465869277715683\n",
      "Epoch 1714, Loss: 0.19275779253803194, Final Batch Loss: 0.002550802892073989\n",
      "Epoch 1715, Loss: 0.1517123243011156, Final Batch Loss: 1.8358061424805783e-05\n",
      "Epoch 1716, Loss: 0.16095795109850997, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1717, Loss: 0.10177385993051757, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1718, Loss: 0.11049339175224304, Final Batch Loss: 0.0\n",
      "Epoch 1719, Loss: 0.12050453014671803, Final Batch Loss: 0.01896451972424984\n",
      "Epoch 1720, Loss: 0.0994568318127449, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1721, Loss: 0.08025764301416416, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1722, Loss: 0.10696398094296455, Final Batch Loss: 0.0\n",
      "Epoch 1723, Loss: 0.09047667810227722, Final Batch Loss: 0.0001705739414319396\n",
      "Epoch 1724, Loss: 0.06495927457308426, Final Batch Loss: 7.986990567587782e-06\n",
      "Epoch 1725, Loss: 0.18941486813127995, Final Batch Loss: 0.10899018496274948\n",
      "Epoch 1726, Loss: 0.07411887310445309, Final Batch Loss: 0.0\n",
      "Epoch 1727, Loss: 0.07996981147880433, Final Batch Loss: 0.00011216964776394889\n",
      "Epoch 1728, Loss: 0.08527778461370872, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1729, Loss: 0.10645312257111073, Final Batch Loss: 0.024177588522434235\n",
      "Epoch 1730, Loss: 0.08389940820779884, Final Batch Loss: 9.047575440490618e-05\n",
      "Epoch 1731, Loss: 0.07325220290931611, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 1732, Loss: 0.05919993110001087, Final Batch Loss: 0.0\n",
      "Epoch 1733, Loss: 0.0628350842744112, Final Batch Loss: 0.0014100857079029083\n",
      "Epoch 1734, Loss: 0.07368692383170128, Final Batch Loss: 0.0\n",
      "Epoch 1735, Loss: 0.08071203716099262, Final Batch Loss: 0.005304666236042976\n",
      "Epoch 1736, Loss: 0.06865716164884361, Final Batch Loss: 6.198863957251888e-06\n",
      "Epoch 1737, Loss: 0.0714558232541549, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 1738, Loss: 0.08995342068374157, Final Batch Loss: 0.022186055779457092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1739, Loss: 0.061082430157512135, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 1740, Loss: 0.05773727391715511, Final Batch Loss: 1.883488948806189e-05\n",
      "Epoch 1741, Loss: 0.07078081928176516, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1742, Loss: 0.0789671503007412, Final Batch Loss: 0.019150016829371452\n",
      "Epoch 1743, Loss: 0.06188952550292015, Final Batch Loss: 0.0\n",
      "Epoch 1744, Loss: 0.05882830611699319, Final Batch Loss: 2.312633478140924e-05\n",
      "Epoch 1745, Loss: 0.06990846990447608, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 1746, Loss: 0.06242735777016151, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1747, Loss: 0.0667759608477354, Final Batch Loss: 0.007487685419619083\n",
      "Epoch 1748, Loss: 0.07337347145949025, Final Batch Loss: 0.00012885693286079913\n",
      "Epoch 1749, Loss: 0.06973070651292801, Final Batch Loss: 0.007245573215186596\n",
      "Epoch 1750, Loss: 0.06114329397678375, Final Batch Loss: 0.0\n",
      "Epoch 1751, Loss: 0.0706095090135932, Final Batch Loss: 0.0\n",
      "Epoch 1752, Loss: 0.055564270820468664, Final Batch Loss: 0.0013428251259028912\n",
      "Epoch 1753, Loss: 0.0611739382147789, Final Batch Loss: 0.0\n",
      "Epoch 1754, Loss: 0.07402222882956266, Final Batch Loss: 0.0\n",
      "Epoch 1755, Loss: 0.0753337386995554, Final Batch Loss: 0.014962587505578995\n",
      "Epoch 1756, Loss: 0.07779385149478912, Final Batch Loss: 0.0\n",
      "Epoch 1757, Loss: 0.06230288371438064, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1758, Loss: 0.08000391907989979, Final Batch Loss: 0.005393358878791332\n",
      "Epoch 1759, Loss: 0.05159520171582699, Final Batch Loss: 0.0\n",
      "Epoch 1760, Loss: 0.08122278656810522, Final Batch Loss: 0.0\n",
      "Epoch 1761, Loss: 0.04886672832071781, Final Batch Loss: 0.0\n",
      "Epoch 1762, Loss: 0.04107239469885826, Final Batch Loss: 0.0\n",
      "Epoch 1763, Loss: 0.05166459263273282, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 1764, Loss: 0.052947330033930484, Final Batch Loss: 2.253030106658116e-05\n",
      "Epoch 1765, Loss: 0.060013406196958385, Final Batch Loss: 0.00022742546570952982\n",
      "Epoch 1766, Loss: 0.04731323011213817, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1767, Loss: 0.07273661345243454, Final Batch Loss: 0.0\n",
      "Epoch 1768, Loss: 0.08869874369702302, Final Batch Loss: 0.0001565095444675535\n",
      "Epoch 1769, Loss: 0.058740949251387065, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 1770, Loss: 0.06089825644448865, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 1771, Loss: 0.06992811802774668, Final Batch Loss: 0.0\n",
      "Epoch 1772, Loss: 0.07871486898511648, Final Batch Loss: 0.009434637613594532\n",
      "Epoch 1773, Loss: 0.04463748075067997, Final Batch Loss: 0.0\n",
      "Epoch 1774, Loss: 0.04743934981524944, Final Batch Loss: 0.0\n",
      "Epoch 1775, Loss: 0.04970052186399698, Final Batch Loss: 0.0\n",
      "Epoch 1776, Loss: 0.04866537915631852, Final Batch Loss: 5.960446742392378e-06\n",
      "Epoch 1777, Loss: 0.0530780609606154, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 1778, Loss: 0.057854371079884004, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 1779, Loss: 0.06049197353422642, Final Batch Loss: 0.0\n",
      "Epoch 1780, Loss: 0.05883933138102293, Final Batch Loss: 0.0\n",
      "Epoch 1781, Loss: 0.046243948861956596, Final Batch Loss: 0.0\n",
      "Epoch 1782, Loss: 0.0553785664960742, Final Batch Loss: 0.0\n",
      "Epoch 1783, Loss: 0.04643869455321692, Final Batch Loss: 0.00043883229955099523\n",
      "Epoch 1784, Loss: 0.06518276967040038, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1785, Loss: 0.0665966323686007, Final Batch Loss: 3.015949550899677e-05\n",
      "Epoch 1786, Loss: 0.04881137580377981, Final Batch Loss: 0.00011669908417388797\n",
      "Epoch 1787, Loss: 0.05724385555731715, Final Batch Loss: 1.5020257706055418e-05\n",
      "Epoch 1788, Loss: 0.06345321389198944, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 1789, Loss: 0.0415160886477679, Final Batch Loss: 0.0016883655916899443\n",
      "Epoch 1790, Loss: 0.056588899344205856, Final Batch Loss: 0.0\n",
      "Epoch 1791, Loss: 0.03695928119122982, Final Batch Loss: 0.0\n",
      "Epoch 1792, Loss: 0.08285713009536266, Final Batch Loss: 0.02855795808136463\n",
      "Epoch 1793, Loss: 0.06729497690685093, Final Batch Loss: 0.003616105066612363\n",
      "Epoch 1794, Loss: 0.08035082212882116, Final Batch Loss: 0.0008755664457567036\n",
      "Epoch 1795, Loss: 0.045678007416427135, Final Batch Loss: 0.0\n",
      "Epoch 1796, Loss: 0.05855207936838269, Final Batch Loss: 0.0\n",
      "Epoch 1797, Loss: 0.054490847978733825, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1798, Loss: 0.07774798385798931, Final Batch Loss: 0.005830423906445503\n",
      "Epoch 1799, Loss: 0.04763070307671313, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1800, Loss: 0.062475026556057855, Final Batch Loss: 9.679325739853084e-05\n",
      "Epoch 1801, Loss: 0.08763098670169711, Final Batch Loss: 0.048541564494371414\n",
      "Epoch 1802, Loss: 0.04875317891128361, Final Batch Loss: 0.0004972175229340792\n",
      "Epoch 1803, Loss: 0.06180576048268449, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1804, Loss: 0.03979967022314668, Final Batch Loss: 0.0\n",
      "Epoch 1805, Loss: 0.1101915140170604, Final Batch Loss: 0.0036707420367747545\n",
      "Epoch 1806, Loss: 0.04595379065722227, Final Batch Loss: 0.0\n",
      "Epoch 1807, Loss: 0.041534136049449444, Final Batch Loss: 0.0\n",
      "Epoch 1808, Loss: 0.04523946391282152, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 1809, Loss: 0.06885665562003851, Final Batch Loss: 0.0\n",
      "Epoch 1810, Loss: 0.0570535035803843, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1811, Loss: 0.04785222071222961, Final Batch Loss: 0.0\n",
      "Epoch 1812, Loss: 0.0583696007670369, Final Batch Loss: 2.753696753643453e-05\n",
      "Epoch 1813, Loss: 0.050228320993312536, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1814, Loss: 0.06090631941333413, Final Batch Loss: 0.0\n",
      "Epoch 1815, Loss: 0.0653429847498046, Final Batch Loss: 2.6225699912174605e-05\n",
      "Epoch 1816, Loss: 0.040699576959006833, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1817, Loss: 0.04532825853674893, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1818, Loss: 0.039772262796731184, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1819, Loss: 0.04436275920625121, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 1820, Loss: 0.07721661869436502, Final Batch Loss: 0.0\n",
      "Epoch 1821, Loss: 0.057349975919343876, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1822, Loss: 0.03400184400379658, Final Batch Loss: 0.0\n",
      "Epoch 1823, Loss: 0.057114767376333475, Final Batch Loss: 0.0\n",
      "Epoch 1824, Loss: 0.042049023788422346, Final Batch Loss: 0.0\n",
      "Epoch 1825, Loss: 0.04479391127824783, Final Batch Loss: 0.0\n",
      "Epoch 1826, Loss: 0.05716004455462098, Final Batch Loss: 0.0\n",
      "Epoch 1827, Loss: 0.039532838854910324, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1828, Loss: 0.038899587090782006, Final Batch Loss: 2.7417760065873154e-05\n",
      "Epoch 1829, Loss: 0.0429011273663491, Final Batch Loss: 0.0016532575245946646\n",
      "Epoch 1830, Loss: 0.04566986200734391, Final Batch Loss: 1.1086402082582936e-05\n",
      "Epoch 1831, Loss: 0.03909016028043766, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1832, Loss: 0.03364105848368126, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1833, Loss: 0.05225919187068229, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1834, Loss: 0.034766111228236696, Final Batch Loss: 3.8980677345534787e-05\n",
      "Epoch 1835, Loss: 0.04099909287833725, Final Batch Loss: 2.074220174108632e-05\n",
      "Epoch 1836, Loss: 0.04918336123228073, Final Batch Loss: 0.0\n",
      "Epoch 1837, Loss: 0.0364246005192399, Final Batch Loss: 0.0\n",
      "Epoch 1838, Loss: 0.032358394004404545, Final Batch Loss: 0.0\n",
      "Epoch 1839, Loss: 1.2022396847605705, Final Batch Loss: 1.1673933267593384\n",
      "Epoch 1840, Loss: 0.0873993681743741, Final Batch Loss: 0.0\n",
      "Epoch 1841, Loss: 0.2330191247165203, Final Batch Loss: 0.0\n",
      "Epoch 1842, Loss: 0.3331163749096504, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1843, Loss: 0.30250924453139305, Final Batch Loss: 0.0\n",
      "Epoch 1844, Loss: 0.21562227979302406, Final Batch Loss: 0.0\n",
      "Epoch 1845, Loss: 0.13652994111180305, Final Batch Loss: 0.02146921493113041\n",
      "Epoch 1846, Loss: 0.09040642902255058, Final Batch Loss: 0.0\n",
      "Epoch 1847, Loss: 0.06795710325241089, Final Batch Loss: 0.0\n",
      "Epoch 1848, Loss: 0.07501905737441916, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1849, Loss: 0.11142385704442859, Final Batch Loss: 0.0069090514443814754\n",
      "Epoch 1850, Loss: 0.10036033405049238, Final Batch Loss: 7.295342220459133e-05\n",
      "Epoch 1851, Loss: 0.13660841900855303, Final Batch Loss: 0.048712119460105896\n",
      "Epoch 1852, Loss: 0.12775310687720776, Final Batch Loss: 0.0014413930475711823\n",
      "Epoch 1853, Loss: 0.06326229125261307, Final Batch Loss: 0.0\n",
      "Epoch 1854, Loss: 0.07481017589452676, Final Batch Loss: 0.00035398892941884696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1855, Loss: 0.08516427874565125, Final Batch Loss: 0.0\n",
      "Epoch 1856, Loss: 0.08495984785076871, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1857, Loss: 0.09486520290374756, Final Batch Loss: 0.0\n",
      "Epoch 1858, Loss: 0.08821064978837967, Final Batch Loss: 0.0\n",
      "Epoch 1859, Loss: 0.07878146320581436, Final Batch Loss: 0.0\n",
      "Epoch 1860, Loss: 0.05867153890358168, Final Batch Loss: 3.862306402879767e-05\n",
      "Epoch 1861, Loss: 0.05996443424373865, Final Batch Loss: 0.0\n",
      "Epoch 1862, Loss: 0.07798089738923863, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1863, Loss: 0.06272169657677296, Final Batch Loss: 4.5536911784438416e-05\n",
      "Epoch 1864, Loss: 0.054825460305437446, Final Batch Loss: 0.0022747849579900503\n",
      "Epoch 1865, Loss: 0.06310878973454237, Final Batch Loss: 0.0\n",
      "Epoch 1866, Loss: 0.06859797984358806, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1867, Loss: 0.054945885203778744, Final Batch Loss: 0.0\n",
      "Epoch 1868, Loss: 0.0543643860144698, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1869, Loss: 0.07005611744170892, Final Batch Loss: 3.5523738915799186e-05\n",
      "Epoch 1870, Loss: 0.06513039022681255, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1871, Loss: 0.045685680357564706, Final Batch Loss: 9.881961887003854e-05\n",
      "Epoch 1872, Loss: 0.05128811951726675, Final Batch Loss: 0.0\n",
      "Epoch 1873, Loss: 0.05162712128367275, Final Batch Loss: 0.0004950728034600616\n",
      "Epoch 1874, Loss: 0.05026968382287578, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1875, Loss: 0.054834509267948306, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1876, Loss: 0.06204901635373972, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 1877, Loss: 0.03922464232528, Final Batch Loss: 4.327203714638017e-05\n",
      "Epoch 1878, Loss: 0.05110556445765724, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1879, Loss: 0.04959913296625018, Final Batch Loss: 0.0019791792146861553\n",
      "Epoch 1880, Loss: 0.04979869199451059, Final Batch Loss: 0.0015455455286428332\n",
      "Epoch 1881, Loss: 0.04617002233862877, Final Batch Loss: 0.0\n",
      "Epoch 1882, Loss: 0.04606294259428978, Final Batch Loss: 0.0\n",
      "Epoch 1883, Loss: 0.049424671567635414, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1884, Loss: 0.037779185513500124, Final Batch Loss: 0.0002675890573300421\n",
      "Epoch 1885, Loss: 0.05196283431723714, Final Batch Loss: 0.0023807534016668797\n",
      "Epoch 1886, Loss: 0.04307551309454993, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1887, Loss: 0.036362105049192905, Final Batch Loss: 0.0\n",
      "Epoch 1888, Loss: 0.047963398508159116, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1889, Loss: 0.05515472311526537, Final Batch Loss: 0.0\n",
      "Epoch 1890, Loss: 0.05947098124306649, Final Batch Loss: 0.0014324652729555964\n",
      "Epoch 1891, Loss: 0.05563466064631939, Final Batch Loss: 0.0\n",
      "Epoch 1892, Loss: 0.04706353010078601, Final Batch Loss: 2.539125671319198e-05\n",
      "Epoch 1893, Loss: 0.03224318186403252, Final Batch Loss: 0.0002833203470800072\n",
      "Epoch 1894, Loss: 0.039397550746770094, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1895, Loss: 0.043543764390051365, Final Batch Loss: 0.0\n",
      "Epoch 1896, Loss: 0.06132484972476959, Final Batch Loss: 0.0\n",
      "Epoch 1897, Loss: 0.03990664938464761, Final Batch Loss: 0.002481597475707531\n",
      "Epoch 1898, Loss: 0.06561345925729256, Final Batch Loss: 0.00017033556650858372\n",
      "Epoch 1899, Loss: 0.08357460610568523, Final Batch Loss: 0.039427436888217926\n",
      "Epoch 1900, Loss: 0.04094489284034353, Final Batch Loss: 9.727005090098828e-05\n",
      "Epoch 1901, Loss: 0.0428340844810009, Final Batch Loss: 0.0\n",
      "Epoch 1902, Loss: 0.09833070449531078, Final Batch Loss: 0.048343949019908905\n",
      "Epoch 1903, Loss: 0.03770913343032589, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 1904, Loss: 0.04269746784120798, Final Batch Loss: 0.0\n",
      "Epoch 1905, Loss: 0.053606921806931496, Final Batch Loss: 0.0\n",
      "Epoch 1906, Loss: 0.14655264420434833, Final Batch Loss: 0.12005718797445297\n",
      "Epoch 1907, Loss: 0.03162652160972357, Final Batch Loss: 0.0\n",
      "Epoch 1908, Loss: 0.03316870192065835, Final Batch Loss: 0.0\n",
      "Epoch 1909, Loss: 0.03736570896563762, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1910, Loss: 0.06638946010934887, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 1911, Loss: 0.044618502724802056, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1912, Loss: 0.06801718659698963, Final Batch Loss: 0.0\n",
      "Epoch 1913, Loss: 0.0658719940111041, Final Batch Loss: 0.0\n",
      "Epoch 1914, Loss: 0.042388205183669925, Final Batch Loss: 0.0014842457603663206\n",
      "Epoch 1915, Loss: 0.03759459359571338, Final Batch Loss: 0.0\n",
      "Epoch 1916, Loss: 0.06494399709481513, Final Batch Loss: 8.737658936297521e-05\n",
      "Epoch 1917, Loss: 0.047565281094648526, Final Batch Loss: 2.4318398573086597e-05\n",
      "Epoch 1918, Loss: 0.0862819477897574, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1919, Loss: 0.030318910721689463, Final Batch Loss: 0.0\n",
      "Epoch 1920, Loss: 0.05136206932365894, Final Batch Loss: 0.004621301311999559\n",
      "Epoch 1921, Loss: 0.05846994183957577, Final Batch Loss: 0.0\n",
      "Epoch 1922, Loss: 0.036510287784039974, Final Batch Loss: 0.0\n",
      "Epoch 1923, Loss: 0.04353762891696533, Final Batch Loss: 2.777537883957848e-05\n",
      "Epoch 1924, Loss: 0.03973381221294403, Final Batch Loss: 0.0\n",
      "Epoch 1925, Loss: 0.028859139783889987, Final Batch Loss: 9.262132516596466e-05\n",
      "Epoch 1926, Loss: 0.03274119831620936, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1927, Loss: 0.04423224925994873, Final Batch Loss: 0.0\n",
      "Epoch 1928, Loss: 0.02944800860404939, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 1929, Loss: 0.1588689498603344, Final Batch Loss: 0.10185672342777252\n",
      "Epoch 1930, Loss: 0.08233983675017953, Final Batch Loss: 0.03327800706028938\n",
      "Epoch 1931, Loss: 0.025156760122619914, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1932, Loss: 0.04150238167176212, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 1933, Loss: 0.036157498066131666, Final Batch Loss: 1.1801649634435307e-05\n",
      "Epoch 1934, Loss: 0.04196744365617633, Final Batch Loss: 0.0026075192727148533\n",
      "Epoch 1935, Loss: 0.04130297480151057, Final Batch Loss: 0.0\n",
      "Epoch 1936, Loss: 0.04713703226298094, Final Batch Loss: 0.009614000096917152\n",
      "Epoch 1937, Loss: 0.03236963227391243, Final Batch Loss: 0.0\n",
      "Epoch 1938, Loss: 0.03731601277831942, Final Batch Loss: 0.0006868863711133599\n",
      "Epoch 1939, Loss: 0.029104240238666534, Final Batch Loss: 0.0\n",
      "Epoch 1940, Loss: 0.03060293496673694, Final Batch Loss: 4.3987260141875595e-05\n",
      "Epoch 1941, Loss: 0.03477745968848467, Final Batch Loss: 0.0\n",
      "Epoch 1942, Loss: 0.025766295846551657, Final Batch Loss: 0.0\n",
      "Epoch 1943, Loss: 0.025144645711407065, Final Batch Loss: 0.004391550086438656\n",
      "Epoch 1944, Loss: 0.024868064600013895, Final Batch Loss: 4.2199197196168825e-05\n",
      "Epoch 1945, Loss: 0.027462454570923, Final Batch Loss: 0.00013255194062367082\n",
      "Epoch 1946, Loss: 0.04329268494620919, Final Batch Loss: 0.005355298053473234\n",
      "Epoch 1947, Loss: 0.028166512958705425, Final Batch Loss: 0.0\n",
      "Epoch 1948, Loss: 0.026826693927432643, Final Batch Loss: 2.992108420585282e-05\n",
      "Epoch 1949, Loss: 0.026468558702617884, Final Batch Loss: 0.0\n",
      "Epoch 1950, Loss: 0.04541498561275148, Final Batch Loss: 4.529942543740617e-06\n",
      "Epoch 1951, Loss: 0.024880324956029654, Final Batch Loss: 0.0\n",
      "Epoch 1952, Loss: 0.028697793604806066, Final Batch Loss: 0.0\n",
      "Epoch 1953, Loss: 0.022641703952103853, Final Batch Loss: 0.0\n",
      "Epoch 1954, Loss: 0.04402817226946354, Final Batch Loss: 0.0\n",
      "Epoch 1955, Loss: 0.027809814320789883, Final Batch Loss: 4.815939246327616e-05\n",
      "Epoch 1956, Loss: 0.026696396991610527, Final Batch Loss: 0.0\n",
      "Epoch 1957, Loss: 0.040376916993409395, Final Batch Loss: 0.0\n",
      "Epoch 1958, Loss: 0.028318789787590504, Final Batch Loss: 0.0\n",
      "Epoch 1959, Loss: 0.028117504669353366, Final Batch Loss: 0.0\n",
      "Epoch 1960, Loss: 0.04522853843809571, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 1961, Loss: 0.023442722391337156, Final Batch Loss: 0.0\n",
      "Epoch 1962, Loss: 0.023622472828719765, Final Batch Loss: 0.00024005869636312127\n",
      "Epoch 1963, Loss: 0.03093718457967043, Final Batch Loss: 0.0\n",
      "Epoch 1964, Loss: 0.055266341194453616, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1965, Loss: 0.048028537072241306, Final Batch Loss: 0.0\n",
      "Epoch 1966, Loss: 0.038213768041600815, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1967, Loss: 0.029092983342707157, Final Batch Loss: 0.0\n",
      "Epoch 1968, Loss: 0.03491571871563792, Final Batch Loss: 0.0\n",
      "Epoch 1969, Loss: 0.037082916125655174, Final Batch Loss: 0.0\n",
      "Epoch 1970, Loss: 0.03155384585261345, Final Batch Loss: 0.0\n",
      "Epoch 1971, Loss: 0.027122531550617168, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1972, Loss: 0.04440528340637684, Final Batch Loss: 0.0\n",
      "Epoch 1973, Loss: 0.028937363531440496, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1974, Loss: 0.03398542245849967, Final Batch Loss: 0.00260740052908659\n",
      "Epoch 1975, Loss: 0.024021561488780208, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 1976, Loss: 0.03867892129346728, Final Batch Loss: 0.0\n",
      "Epoch 1977, Loss: 0.022475706675322726, Final Batch Loss: 0.00027366707217879593\n",
      "Epoch 1978, Loss: 0.028306229937697935, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 1979, Loss: 0.03389583953321562, Final Batch Loss: 4.172238186583854e-05\n",
      "Epoch 1980, Loss: 0.0317895351909101, Final Batch Loss: 0.0\n",
      "Epoch 1981, Loss: 0.02353651402484047, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1982, Loss: 0.0341164952442341, Final Batch Loss: 3.528532761265524e-05\n",
      "Epoch 1983, Loss: 0.02746835770085454, Final Batch Loss: 0.0\n",
      "Epoch 1984, Loss: 0.20992952212691307, Final Batch Loss: 0.1823979914188385\n",
      "Epoch 1985, Loss: 0.024869559797934926, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1986, Loss: 0.03448839951079208, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1987, Loss: 0.03831882355734706, Final Batch Loss: 0.0\n",
      "Epoch 1988, Loss: 0.024317290168255568, Final Batch Loss: 0.0\n",
      "Epoch 1989, Loss: 0.05343497032299638, Final Batch Loss: 0.0\n",
      "Epoch 1990, Loss: 0.031962952571802816, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1991, Loss: 1.6170797259546816, Final Batch Loss: 1.592856526374817\n",
      "Epoch 1992, Loss: 0.049472284503281116, Final Batch Loss: 0.0\n",
      "Epoch 1993, Loss: 0.08450017124414444, Final Batch Loss: 0.0\n",
      "Epoch 1994, Loss: 0.1436929665505886, Final Batch Loss: 0.04608415812253952\n",
      "Epoch 1995, Loss: 0.10733979754149203, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1996, Loss: 0.09801268205046654, Final Batch Loss: 0.0\n",
      "Epoch 1997, Loss: 0.046738770324736834, Final Batch Loss: 0.0005187834613025188\n",
      "Epoch 1998, Loss: 0.06845238385722041, Final Batch Loss: 0.0\n",
      "Epoch 1999, Loss: 0.0750142028555274, Final Batch Loss: 0.002263604663312435\n",
      "Epoch 2000, Loss: 0.06667619399377145, Final Batch Loss: 0.00018737945356406271\n",
      "Epoch 2001, Loss: 0.16269564162939787, Final Batch Loss: 0.09221833944320679\n",
      "Epoch 2002, Loss: 0.17999340780078654, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2003, Loss: 0.05170869268476963, Final Batch Loss: 0.0\n",
      "Epoch 2004, Loss: 0.10070894099754923, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2005, Loss: 0.06946930196136236, Final Batch Loss: 0.0\n",
      "Epoch 2006, Loss: 0.0650118961930275, Final Batch Loss: 0.0\n",
      "Epoch 2007, Loss: 0.07636521942913532, Final Batch Loss: 0.0\n",
      "Epoch 2008, Loss: 0.03760084166060551, Final Batch Loss: 3.58813522325363e-05\n",
      "Epoch 2009, Loss: 0.03498620865866542, Final Batch Loss: 0.0\n",
      "Epoch 2010, Loss: 0.039421367575357635, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2011, Loss: 0.07186170285513072, Final Batch Loss: 1.3708974620385561e-05\n",
      "Epoch 2012, Loss: 0.047071563079953194, Final Batch Loss: 0.0\n",
      "Epoch 2013, Loss: 0.03152028004979002, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 2014, Loss: 0.0504346638917923, Final Batch Loss: 0.0\n",
      "Epoch 2015, Loss: 0.035372238140553236, Final Batch Loss: 0.0\n",
      "Epoch 2016, Loss: 0.041922032833099365, Final Batch Loss: 0.0\n",
      "Epoch 2017, Loss: 0.06930075027048588, Final Batch Loss: 0.0\n",
      "Epoch 2018, Loss: 0.04420173447576303, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2019, Loss: 0.04447259148582816, Final Batch Loss: 0.0\n",
      "Epoch 2020, Loss: 0.07978060841560364, Final Batch Loss: 0.04480399936437607\n",
      "Epoch 2021, Loss: 0.04595824971329421, Final Batch Loss: 0.0\n",
      "Epoch 2022, Loss: 0.10552966035800182, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2023, Loss: 0.0458619634155184, Final Batch Loss: 0.0\n",
      "Epoch 2024, Loss: 0.06087756149372581, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 2025, Loss: 0.0391104232694488, Final Batch Loss: 0.00015424491721205413\n",
      "Epoch 2026, Loss: 0.08170617744326591, Final Batch Loss: 0.0\n",
      "Epoch 2027, Loss: 0.05056893830624176, Final Batch Loss: 5.185469490243122e-05\n",
      "Epoch 2028, Loss: 0.0360177094116807, Final Batch Loss: 0.0\n",
      "Epoch 2029, Loss: 0.05715349689126015, Final Batch Loss: 0.0\n",
      "Epoch 2030, Loss: 0.028657967690378428, Final Batch Loss: 0.0\n",
      "Epoch 2031, Loss: 0.07496929711851408, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 2032, Loss: 0.034030133130727336, Final Batch Loss: 3.814624506048858e-05\n",
      "Epoch 2033, Loss: 0.0512799436255591, Final Batch Loss: 0.00020716428116429597\n",
      "Epoch 2034, Loss: 0.04470581980422139, Final Batch Loss: 0.0\n",
      "Epoch 2035, Loss: 0.056991439014382195, Final Batch Loss: 2.4437606043647975e-05\n",
      "Epoch 2036, Loss: 0.04559519721442484, Final Batch Loss: 3.802703940891661e-05\n",
      "Epoch 2037, Loss: 0.0507265015039593, Final Batch Loss: 0.007802840322256088\n",
      "Epoch 2038, Loss: 0.029803387107676826, Final Batch Loss: 5.7338023907504976e-05\n",
      "Epoch 2039, Loss: 0.04551631090362207, Final Batch Loss: 4.935142715112306e-05\n",
      "Epoch 2040, Loss: 0.027360466308209652, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2041, Loss: 0.03594358894042671, Final Batch Loss: 0.0\n",
      "Epoch 2042, Loss: 0.022443135268986225, Final Batch Loss: 0.0\n",
      "Epoch 2043, Loss: 0.038810902275145054, Final Batch Loss: 0.0027393694035708904\n",
      "Epoch 2044, Loss: 0.03323843842372298, Final Batch Loss: 0.0\n",
      "Epoch 2045, Loss: 0.041817872785031796, Final Batch Loss: 0.0\n",
      "Epoch 2046, Loss: 0.06698779063299298, Final Batch Loss: 0.0\n",
      "Epoch 2047, Loss: 0.03238699329085648, Final Batch Loss: 0.0\n",
      "Epoch 2048, Loss: 0.03733565146103501, Final Batch Loss: 0.0\n",
      "Epoch 2049, Loss: 0.03481040825136006, Final Batch Loss: 0.0\n",
      "Epoch 2050, Loss: 0.027644363464787602, Final Batch Loss: 0.0\n",
      "Epoch 2051, Loss: 0.0345580200664628, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2052, Loss: 0.026551863877102733, Final Batch Loss: 0.0\n",
      "Epoch 2053, Loss: 0.19288322050124407, Final Batch Loss: 0.16495859622955322\n",
      "Epoch 2054, Loss: 0.036672760355941136, Final Batch Loss: 2.7417760065873154e-05\n",
      "Epoch 2055, Loss: 0.03971992153674364, Final Batch Loss: 0.0\n",
      "Epoch 2056, Loss: 0.0743837256450206, Final Batch Loss: 0.0\n",
      "Epoch 2057, Loss: 0.06675152946263552, Final Batch Loss: 0.0\n",
      "Epoch 2058, Loss: 0.0784913208335638, Final Batch Loss: 0.0\n",
      "Epoch 2059, Loss: 0.06395978014916182, Final Batch Loss: 0.0\n",
      "Epoch 2060, Loss: 0.04373644093720941, Final Batch Loss: 1.5735502529423684e-05\n",
      "Epoch 2061, Loss: 0.034440524876089285, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2062, Loss: 0.06677484232932329, Final Batch Loss: 0.0\n",
      "Epoch 2063, Loss: 0.09488643240183592, Final Batch Loss: 0.051982663571834564\n",
      "Epoch 2064, Loss: 0.03413180913776159, Final Batch Loss: 0.0\n",
      "Epoch 2065, Loss: 0.045811882708051144, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2066, Loss: 0.05136043857783079, Final Batch Loss: 0.0\n",
      "Epoch 2067, Loss: 0.026460909333763993, Final Batch Loss: 2.884823152271565e-05\n",
      "Epoch 2068, Loss: 0.02789448108524084, Final Batch Loss: 0.0\n",
      "Epoch 2069, Loss: 0.02603480580728501, Final Batch Loss: 0.0\n",
      "Epoch 2070, Loss: 0.05114997364580631, Final Batch Loss: 0.0\n",
      "Epoch 2071, Loss: 0.036129057640209794, Final Batch Loss: 0.0\n",
      "Epoch 2072, Loss: 0.026506749447321454, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2073, Loss: 0.04002882167696953, Final Batch Loss: 0.0\n",
      "Epoch 2074, Loss: 0.026370385196059942, Final Batch Loss: 0.0\n",
      "Epoch 2075, Loss: 0.03955324913840741, Final Batch Loss: 0.0017377528129145503\n",
      "Epoch 2076, Loss: 0.02764914697036147, Final Batch Loss: 0.0\n",
      "Epoch 2077, Loss: 0.02510572969912772, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2078, Loss: 0.030155654061445603, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 2079, Loss: 0.024694253457141713, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2080, Loss: 0.03534034080803394, Final Batch Loss: 0.0\n",
      "Epoch 2081, Loss: 0.018218867713358122, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2082, Loss: 0.023922395041154232, Final Batch Loss: 8.535020606359467e-05\n",
      "Epoch 2083, Loss: 0.024820411577820778, Final Batch Loss: 0.0\n",
      "Epoch 2084, Loss: 0.024779825129371602, Final Batch Loss: 0.00010227633902104571\n",
      "Epoch 2085, Loss: 0.02299657673574984, Final Batch Loss: 0.0\n",
      "Epoch 2086, Loss: 0.03934011235833168, Final Batch Loss: 0.0\n",
      "Epoch 2087, Loss: 0.02941862866282463, Final Batch Loss: 0.0\n",
      "Epoch 2088, Loss: 0.024014341821384733, Final Batch Loss: 2.407998726994265e-05\n",
      "Epoch 2089, Loss: 0.024540015816455707, Final Batch Loss: 0.00048565989709459245\n",
      "Epoch 2090, Loss: 0.03393314406275749, Final Batch Loss: 0.0\n",
      "Epoch 2091, Loss: 0.03364928578957915, Final Batch Loss: 0.006552401464432478\n",
      "Epoch 2092, Loss: 0.02657979167997837, Final Batch Loss: 0.0\n",
      "Epoch 2093, Loss: 0.04125514905899763, Final Batch Loss: 0.010827718302607536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2094, Loss: 0.04373305919523318, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2095, Loss: 0.019514156733748678, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 2096, Loss: 0.032477954402565956, Final Batch Loss: 0.0\n",
      "Epoch 2097, Loss: 0.03066402208060026, Final Batch Loss: 0.0\n",
      "Epoch 2098, Loss: 0.0337762637391279, Final Batch Loss: 2.9444261599564925e-05\n",
      "Epoch 2099, Loss: 0.047300024423748255, Final Batch Loss: 0.0\n",
      "Epoch 2100, Loss: 0.025544503248966066, Final Batch Loss: 2.109982233378105e-05\n",
      "Epoch 2101, Loss: 0.02920229870824187, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 2102, Loss: 0.055314130941042094, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 2103, Loss: 0.02962875599041581, Final Batch Loss: 0.0\n",
      "Epoch 2104, Loss: 0.02415563352406025, Final Batch Loss: 0.0\n",
      "Epoch 2105, Loss: 0.031065012328319597, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2106, Loss: 0.023161489516489553, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2107, Loss: 0.028047672487446107, Final Batch Loss: 5.2569914259947836e-05\n",
      "Epoch 2108, Loss: 0.03034982504323125, Final Batch Loss: 0.0\n",
      "Epoch 2109, Loss: 0.02264413144439459, Final Batch Loss: 0.0\n",
      "Epoch 2110, Loss: 0.027767658233642578, Final Batch Loss: 0.0\n",
      "Epoch 2111, Loss: 0.024138653185218573, Final Batch Loss: 0.0\n",
      "Epoch 2112, Loss: 0.04248113092035055, Final Batch Loss: 0.0\n",
      "Epoch 2113, Loss: 0.02245712885633111, Final Batch Loss: 0.0\n",
      "Epoch 2114, Loss: 0.04263836098834872, Final Batch Loss: 0.0\n",
      "Epoch 2115, Loss: 0.01715728221461177, Final Batch Loss: 0.0\n",
      "Epoch 2116, Loss: 0.02081316674593836, Final Batch Loss: 0.0\n",
      "Epoch 2117, Loss: 0.017997885121985746, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2118, Loss: 0.023096646451449487, Final Batch Loss: 6.592056161025539e-05\n",
      "Epoch 2119, Loss: 0.03089504223316908, Final Batch Loss: 0.0\n",
      "Epoch 2120, Loss: 0.030991356587037444, Final Batch Loss: 0.0\n",
      "Epoch 2121, Loss: 0.01991062704473734, Final Batch Loss: 0.0\n",
      "Epoch 2122, Loss: 0.09212127514183521, Final Batch Loss: 0.06957601755857468\n",
      "Epoch 2123, Loss: 0.020711144665256143, Final Batch Loss: 0.0\n",
      "Epoch 2124, Loss: 0.017404391408490483, Final Batch Loss: 6.139089964563027e-05\n",
      "Epoch 2125, Loss: 0.025112155824899673, Final Batch Loss: 0.0\n",
      "Epoch 2126, Loss: 0.026292412541806698, Final Batch Loss: 0.0\n",
      "Epoch 2127, Loss: 0.029542932500589814, Final Batch Loss: 6.198863957251888e-06\n",
      "Epoch 2128, Loss: 0.04087948566302657, Final Batch Loss: 0.0\n",
      "Epoch 2129, Loss: 0.024511263705790043, Final Batch Loss: 0.0\n",
      "Epoch 2130, Loss: 0.06658541643992066, Final Batch Loss: 0.03270753473043442\n",
      "Epoch 2131, Loss: 0.035012486374853324, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 2132, Loss: 0.01810241723433137, Final Batch Loss: 0.0017216873820871115\n",
      "Epoch 2133, Loss: 0.024156134049917455, Final Batch Loss: 2.4199192921514623e-05\n",
      "Epoch 2134, Loss: 0.029415478464215994, Final Batch Loss: 0.0\n",
      "Epoch 2135, Loss: 0.0234421633635975, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 2136, Loss: 0.04764746502041817, Final Batch Loss: 0.0\n",
      "Epoch 2137, Loss: 0.030452383682131767, Final Batch Loss: 0.0\n",
      "Epoch 2138, Loss: 0.024558553704991937, Final Batch Loss: 0.0\n",
      "Epoch 2139, Loss: 0.024128471958647424, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 2140, Loss: 0.04816560307517648, Final Batch Loss: 0.0\n",
      "Epoch 2141, Loss: 0.03226441816332226, Final Batch Loss: 8.702239938429557e-06\n",
      "Epoch 2142, Loss: 0.07146378234028816, Final Batch Loss: 0.037623945623636246\n",
      "Epoch 2143, Loss: 0.032997751608490944, Final Batch Loss: 0.0\n",
      "Epoch 2144, Loss: 0.025746219005668536, Final Batch Loss: 6.05564855504781e-05\n",
      "Epoch 2145, Loss: 0.059485635021701455, Final Batch Loss: 0.0\n",
      "Epoch 2146, Loss: 0.029341175802983344, Final Batch Loss: 0.0\n",
      "Epoch 2147, Loss: 0.044315642677247524, Final Batch Loss: 0.0\n",
      "Epoch 2148, Loss: 0.022266297601163387, Final Batch Loss: 0.0\n",
      "Epoch 2149, Loss: 0.027017414569684206, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2150, Loss: 0.02867852384224534, Final Batch Loss: 0.0\n",
      "Epoch 2151, Loss: 0.024105021730008502, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2152, Loss: 0.021106782369315624, Final Batch Loss: 0.0\n",
      "Epoch 2153, Loss: 0.024793994981337164, Final Batch Loss: 1.3947389561508317e-05\n",
      "Epoch 2154, Loss: 0.02646899747196585, Final Batch Loss: 0.001105888863094151\n",
      "Epoch 2155, Loss: 0.028623945079743862, Final Batch Loss: 0.0\n",
      "Epoch 2156, Loss: 0.020746510941535234, Final Batch Loss: 0.0\n",
      "Epoch 2157, Loss: 0.02864370308816433, Final Batch Loss: 0.0\n",
      "Epoch 2158, Loss: 0.07644187659025192, Final Batch Loss: 0.05622265860438347\n",
      "Epoch 2159, Loss: 0.01883253501625859, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2160, Loss: 0.02298929006792605, Final Batch Loss: 0.0\n",
      "Epoch 2161, Loss: 0.023569619515910745, Final Batch Loss: 0.0\n",
      "Epoch 2162, Loss: 0.021797806955873966, Final Batch Loss: 0.0\n",
      "Epoch 2163, Loss: 0.03566568777659995, Final Batch Loss: 1.3828182090946939e-05\n",
      "Epoch 2164, Loss: 0.025059695355594158, Final Batch Loss: 0.0\n",
      "Epoch 2165, Loss: 0.02331708464771509, Final Batch Loss: 0.0\n",
      "Epoch 2166, Loss: 0.024940392933785915, Final Batch Loss: 0.0\n",
      "Epoch 2167, Loss: 0.023638739250600338, Final Batch Loss: 0.0\n",
      "Epoch 2168, Loss: 0.027334742248051214, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2169, Loss: 0.026006487661788924, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 2170, Loss: 0.018665263894945383, Final Batch Loss: 0.0\n",
      "Epoch 2171, Loss: 0.026015163864940405, Final Batch Loss: 0.001211266964673996\n",
      "Epoch 2172, Loss: 0.024300987330207136, Final Batch Loss: 5.352353764465079e-05\n",
      "Epoch 2173, Loss: 0.015347901731722402, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2174, Loss: 0.02160739327905503, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2175, Loss: 0.03132141521199827, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2176, Loss: 0.08968896232545376, Final Batch Loss: 0.0\n",
      "Epoch 2177, Loss: 0.029685128480196, Final Batch Loss: 0.007072769105434418\n",
      "Epoch 2178, Loss: 0.03386687370942809, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2179, Loss: 0.05550278365262784, Final Batch Loss: 0.0004664763400796801\n",
      "Epoch 2180, Loss: 0.01112949789967388, Final Batch Loss: 0.0\n",
      "Epoch 2181, Loss: 0.024259939789743612, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2182, Loss: 0.023551680613309145, Final Batch Loss: 0.0\n",
      "Epoch 2183, Loss: 0.032319059519068105, Final Batch Loss: 1.2397689715726301e-05\n",
      "Epoch 2184, Loss: 0.035403115456574596, Final Batch Loss: 0.00020346954988781363\n",
      "Epoch 2185, Loss: 0.01976297143843908, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2186, Loss: 0.019410145934671164, Final Batch Loss: 0.0\n",
      "Epoch 2187, Loss: 0.030751450918614864, Final Batch Loss: 0.0\n",
      "Epoch 2188, Loss: 0.04002145444974303, Final Batch Loss: 0.0\n",
      "Epoch 2189, Loss: 0.018606489989679176, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2190, Loss: 0.01866675168275833, Final Batch Loss: 0.0\n",
      "Epoch 2191, Loss: 0.021260333945967602, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2192, Loss: 0.01891495123891218, Final Batch Loss: 2.1815061700181104e-05\n",
      "Epoch 2193, Loss: 0.02545388787984848, Final Batch Loss: 0.0\n",
      "Epoch 2194, Loss: 0.029592077247798443, Final Batch Loss: 0.0\n",
      "Epoch 2195, Loss: 0.03428805817384273, Final Batch Loss: 0.0007525234250351787\n",
      "Epoch 2196, Loss: 0.02740129455924034, Final Batch Loss: 0.005163903348147869\n",
      "Epoch 2197, Loss: 0.023298191372305155, Final Batch Loss: 0.0\n",
      "Epoch 2198, Loss: 0.021236244589083242, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2199, Loss: 0.026217906037317107, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2200, Loss: 0.028045432176440954, Final Batch Loss: 0.0\n",
      "Epoch 2201, Loss: 0.013143385061994195, Final Batch Loss: 0.0\n",
      "Epoch 2202, Loss: 0.7821845842991024, Final Batch Loss: 0.7581639885902405\n",
      "Epoch 2203, Loss: 0.03393658390109522, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2204, Loss: 0.07043869886547327, Final Batch Loss: 0.0\n",
      "Epoch 2205, Loss: 0.12117113731784457, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2206, Loss: 0.17964046820992507, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2207, Loss: 0.11060694046318531, Final Batch Loss: 0.0\n",
      "Epoch 2208, Loss: 0.1264993920921711, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2209, Loss: 0.11163298320025206, Final Batch Loss: 0.00869204942137003\n",
      "Epoch 2210, Loss: 0.09652708971407264, Final Batch Loss: 0.0009078433504328132\n",
      "Epoch 2211, Loss: 0.09114639461037655, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2212, Loss: 0.08281589637044817, Final Batch Loss: 0.001749057904817164\n",
      "Epoch 2213, Loss: 0.0688164086350298, Final Batch Loss: 4.029192859889008e-05\n",
      "Epoch 2214, Loss: 0.0676045510917902, Final Batch Loss: 0.0\n",
      "Epoch 2215, Loss: 0.05086217162806861, Final Batch Loss: 1.0847986231965479e-05\n",
      "Epoch 2216, Loss: 0.056295302696518945, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2217, Loss: 0.05766411451622844, Final Batch Loss: 0.0\n",
      "Epoch 2218, Loss: 0.05249935109168291, Final Batch Loss: 0.0\n",
      "Epoch 2219, Loss: 0.05737822502851486, Final Batch Loss: 0.0\n",
      "Epoch 2220, Loss: 0.05961990119249094, Final Batch Loss: 9.298280929215252e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2221, Loss: 0.04232076392509043, Final Batch Loss: 0.002294528530910611\n",
      "Epoch 2222, Loss: 0.04799773730336909, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2223, Loss: 0.0488818164812983, Final Batch Loss: 1.9788545614574105e-05\n",
      "Epoch 2224, Loss: 0.034886804870893684, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 2225, Loss: 0.056757543185085524, Final Batch Loss: 1.0132738680113107e-05\n",
      "Epoch 2226, Loss: 0.03254696074873209, Final Batch Loss: 0.0\n",
      "Epoch 2227, Loss: 0.041000571101903915, Final Batch Loss: 0.0\n",
      "Epoch 2228, Loss: 0.05174824119239929, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 2229, Loss: 0.041559139266610146, Final Batch Loss: 0.0\n",
      "Epoch 2230, Loss: 0.6760400673374534, Final Batch Loss: 0.6344424486160278\n",
      "Epoch 2231, Loss: 0.0549547728151083, Final Batch Loss: 0.0\n",
      "Epoch 2232, Loss: 0.1590743909473531, Final Batch Loss: 0.000416907190810889\n",
      "Epoch 2233, Loss: 0.16717911511659622, Final Batch Loss: 0.0\n",
      "Epoch 2234, Loss: 0.15473149341414683, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 2235, Loss: 0.12687042372999713, Final Batch Loss: 0.0006038511055521667\n",
      "Epoch 2236, Loss: 0.1149103119969368, Final Batch Loss: 0.0\n",
      "Epoch 2237, Loss: 0.08780190534889698, Final Batch Loss: 0.0\n",
      "Epoch 2238, Loss: 0.07844200171530247, Final Batch Loss: 0.0\n",
      "Epoch 2239, Loss: 0.06448525004086036, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2240, Loss: 0.06839951127767563, Final Batch Loss: 0.0\n",
      "Epoch 2241, Loss: 0.06277562255854718, Final Batch Loss: 0.0001102625101339072\n",
      "Epoch 2242, Loss: 0.06370574980974197, Final Batch Loss: 0.0\n",
      "Epoch 2243, Loss: 0.06553533672013145, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 2244, Loss: 0.04526450019329786, Final Batch Loss: 0.0\n",
      "Epoch 2245, Loss: 0.062026628978856024, Final Batch Loss: 2.2172682292875834e-05\n",
      "Epoch 2246, Loss: 0.05092292930930853, Final Batch Loss: 0.0\n",
      "Epoch 2247, Loss: 0.07267743535339832, Final Batch Loss: 0.0\n",
      "Epoch 2248, Loss: 0.03539354959502816, Final Batch Loss: 0.0\n",
      "Epoch 2249, Loss: 0.06228330545127392, Final Batch Loss: 0.022770602256059647\n",
      "Epoch 2250, Loss: 0.038282252273347694, Final Batch Loss: 3.3854863431770355e-05\n",
      "Epoch 2251, Loss: 0.057713151909410954, Final Batch Loss: 0.0\n",
      "Epoch 2252, Loss: 0.03522809218702605, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 2253, Loss: 0.04585405949183041, Final Batch Loss: 9.178694017464295e-05\n",
      "Epoch 2254, Loss: 0.03317530918866396, Final Batch Loss: 0.0\n",
      "Epoch 2255, Loss: 0.04525006466428749, Final Batch Loss: 0.00027807659353129566\n",
      "Epoch 2256, Loss: 0.03962610661881172, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2257, Loss: 0.02879258943721652, Final Batch Loss: 0.0\n",
      "Epoch 2258, Loss: 0.05823182873427868, Final Batch Loss: 0.0\n",
      "Epoch 2259, Loss: 0.042189070489257574, Final Batch Loss: 0.0\n",
      "Epoch 2260, Loss: 0.03185222530737519, Final Batch Loss: 0.0\n",
      "Epoch 2261, Loss: 0.057525583542883396, Final Batch Loss: 0.0\n",
      "Epoch 2262, Loss: 0.035925703356042504, Final Batch Loss: 2.1576648578047752e-05\n",
      "Epoch 2263, Loss: 0.047475902363650846, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2264, Loss: 0.04587065731175244, Final Batch Loss: 0.0031836561392992735\n",
      "Epoch 2265, Loss: 0.5528769427910447, Final Batch Loss: 0.521211564540863\n",
      "Epoch 2266, Loss: 0.02899247081933254, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2267, Loss: 0.0593086015433002, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2268, Loss: 0.08225452061742544, Final Batch Loss: 0.003050200641155243\n",
      "Epoch 2269, Loss: 0.060324860736727715, Final Batch Loss: 0.0\n",
      "Epoch 2270, Loss: 0.11600153334438801, Final Batch Loss: 0.0\n",
      "Epoch 2271, Loss: 0.12731492705586334, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2272, Loss: 1.6808553151786327, Final Batch Loss: 1.59238862991333\n",
      "Epoch 2273, Loss: 0.049353849142782735, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2274, Loss: 0.14526944421231747, Final Batch Loss: 0.0\n",
      "Epoch 2275, Loss: 0.31530148535784974, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 2276, Loss: 0.22186801210045104, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2277, Loss: 0.18499817482370418, Final Batch Loss: 6.580135959666222e-05\n",
      "Epoch 2278, Loss: 0.11946877460741234, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 2279, Loss: 0.09864425449632108, Final Batch Loss: 0.0038669349160045385\n",
      "Epoch 2280, Loss: 0.07867354340851307, Final Batch Loss: 0.014466872438788414\n",
      "Epoch 2281, Loss: 0.06883606314659119, Final Batch Loss: 0.0\n",
      "Epoch 2282, Loss: 0.06029083484327202, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 2283, Loss: 0.05821934621781111, Final Batch Loss: 0.0012521054595708847\n",
      "Epoch 2284, Loss: 1.4010398220270872, Final Batch Loss: 1.349499225616455\n",
      "Epoch 2285, Loss: 0.06887883599847555, Final Batch Loss: 0.0\n",
      "Epoch 2286, Loss: 0.09716851293342188, Final Batch Loss: 0.00035506143467500806\n",
      "Epoch 2287, Loss: 0.1280310512520373, Final Batch Loss: 0.006845711264759302\n",
      "Epoch 2288, Loss: 0.4552411660552025, Final Batch Loss: 0.3180830180644989\n",
      "Epoch 2289, Loss: 0.11160808801651001, Final Batch Loss: 0.0\n",
      "Epoch 2290, Loss: 0.08186703659157502, Final Batch Loss: 7.223821739898995e-05\n",
      "Epoch 2291, Loss: 0.07636841014027596, Final Batch Loss: 0.0\n",
      "Epoch 2292, Loss: 0.07694275490939617, Final Batch Loss: 0.0\n",
      "Epoch 2293, Loss: 0.07620722125284374, Final Batch Loss: 0.0006301801186054945\n",
      "Epoch 2294, Loss: 0.0592688787728477, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2295, Loss: 0.0626581720989634, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 2296, Loss: 0.0533667076333586, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 2297, Loss: 0.05132132116705179, Final Batch Loss: 0.0\n",
      "Epoch 2298, Loss: 0.0511058708652854, Final Batch Loss: 0.007314686663448811\n",
      "Epoch 2299, Loss: 0.04963473093812354, Final Batch Loss: 0.00015841660206206143\n",
      "Epoch 2300, Loss: 0.05984809434539784, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 2301, Loss: 0.043896021319824285, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2302, Loss: 0.05323292454704642, Final Batch Loss: 0.0010582567192614079\n",
      "Epoch 2303, Loss: 0.035762617364525795, Final Batch Loss: 0.007360364776104689\n",
      "Epoch 2304, Loss: 0.06189393065869808, Final Batch Loss: 0.0\n",
      "Epoch 2305, Loss: 0.06701115146279335, Final Batch Loss: 0.010230954736471176\n",
      "Epoch 2306, Loss: 0.04134772066026926, Final Batch Loss: 0.0\n",
      "Epoch 2307, Loss: 0.04808753295219503, Final Batch Loss: 0.0001864259538706392\n",
      "Epoch 2308, Loss: 0.17629434168338776, Final Batch Loss: 0.12917523086071014\n",
      "Epoch 2309, Loss: 0.04439133405685425, Final Batch Loss: 0.0\n",
      "Epoch 2310, Loss: 0.031865194439888, Final Batch Loss: 0.0\n",
      "Epoch 2311, Loss: 0.03637279476970434, Final Batch Loss: 0.0\n",
      "Epoch 2312, Loss: 0.03763782139867544, Final Batch Loss: 0.0\n",
      "Epoch 2313, Loss: 0.035518911667161035, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2314, Loss: 0.04702877850650111, Final Batch Loss: 3.302042750874534e-05\n",
      "Epoch 2315, Loss: 0.06273766504364175, Final Batch Loss: 1.3828182090946939e-05\n",
      "Epoch 2316, Loss: 0.031086514703929424, Final Batch Loss: 0.0\n",
      "Epoch 2317, Loss: 0.03815321817819495, Final Batch Loss: 5.98412734689191e-05\n",
      "Epoch 2318, Loss: 0.038823275826871395, Final Batch Loss: 0.0034815194085240364\n",
      "Epoch 2319, Loss: 0.036317733116447926, Final Batch Loss: 0.0\n",
      "Epoch 2320, Loss: 0.03610681486316025, Final Batch Loss: 0.0\n",
      "Epoch 2321, Loss: 0.027314565144479275, Final Batch Loss: 0.0\n",
      "Epoch 2322, Loss: 0.04396275570616126, Final Batch Loss: 0.0\n",
      "Epoch 2323, Loss: 0.04213862866163254, Final Batch Loss: 0.000824230897706002\n",
      "Epoch 2324, Loss: 0.03391643054783344, Final Batch Loss: 0.00013302871957421303\n",
      "Epoch 2325, Loss: 0.03235351201146841, Final Batch Loss: 0.0\n",
      "Epoch 2326, Loss: 0.02712309483649733, Final Batch Loss: 1.823885577323381e-05\n",
      "Epoch 2327, Loss: 0.033412620425224304, Final Batch Loss: 0.0\n",
      "Epoch 2328, Loss: 0.028920214157551527, Final Batch Loss: 0.0\n",
      "Epoch 2329, Loss: 0.03573622275143862, Final Batch Loss: 0.0\n",
      "Epoch 2330, Loss: 0.036782896146178246, Final Batch Loss: 0.0\n",
      "Epoch 2331, Loss: 0.041097749955895324, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2332, Loss: 0.03710446739546569, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2333, Loss: 0.03735448561201338, Final Batch Loss: 0.00019047829846385866\n",
      "Epoch 2334, Loss: 0.03622143063694239, Final Batch Loss: 0.0\n",
      "Epoch 2335, Loss: 0.04385858029127121, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2336, Loss: 0.03666687624718179, Final Batch Loss: 2.7894584491150454e-05\n",
      "Epoch 2337, Loss: 0.03016159124672413, Final Batch Loss: 0.0\n",
      "Epoch 2338, Loss: 0.0598230198957026, Final Batch Loss: 0.0\n",
      "Epoch 2339, Loss: 0.03387702157488093, Final Batch Loss: 0.0007677706307731569\n",
      "Epoch 2340, Loss: 0.03703034669160843, Final Batch Loss: 0.0\n",
      "Epoch 2341, Loss: 0.031167582143098116, Final Batch Loss: 0.0\n",
      "Epoch 2342, Loss: 0.034800960682332516, Final Batch Loss: 0.0\n",
      "Epoch 2343, Loss: 0.03871162422001362, Final Batch Loss: 0.0\n",
      "Epoch 2344, Loss: 0.06741364020854235, Final Batch Loss: 0.0328989215195179\n",
      "Epoch 2345, Loss: 0.035187323577702045, Final Batch Loss: 0.0\n",
      "Epoch 2346, Loss: 0.04208357725292444, Final Batch Loss: 0.0\n",
      "Epoch 2347, Loss: 0.032199757697526366, Final Batch Loss: 0.0007070187130011618\n",
      "Epoch 2348, Loss: 0.033650770291387744, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 2349, Loss: 0.026990704238414764, Final Batch Loss: 0.0\n",
      "Epoch 2350, Loss: 0.1365280468016863, Final Batch Loss: 0.10527923703193665\n",
      "Epoch 2351, Loss: 0.028970596380531788, Final Batch Loss: 0.0\n",
      "Epoch 2352, Loss: 0.05227375030517578, Final Batch Loss: 0.0\n",
      "Epoch 2353, Loss: 0.06936522200703621, Final Batch Loss: 0.0\n",
      "Epoch 2354, Loss: 0.06092673330567777, Final Batch Loss: 0.0\n",
      "Epoch 2355, Loss: 0.061066538211889565, Final Batch Loss: 0.001116010476835072\n",
      "Epoch 2356, Loss: 0.06578748999163508, Final Batch Loss: 0.007790775038301945\n",
      "Epoch 2357, Loss: 0.04927131882868707, Final Batch Loss: 0.0\n",
      "Epoch 2358, Loss: 0.038397233467549086, Final Batch Loss: 0.0\n",
      "Epoch 2359, Loss: 0.050725595094263554, Final Batch Loss: 0.0\n",
      "Epoch 2360, Loss: 0.035953693557416955, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2361, Loss: 0.030736071057617664, Final Batch Loss: 0.0\n",
      "Epoch 2362, Loss: 0.0343840294463007, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 2363, Loss: 0.03106711618602276, Final Batch Loss: 0.0\n",
      "Epoch 2364, Loss: 0.03839738178066909, Final Batch Loss: 0.0\n",
      "Epoch 2365, Loss: 0.032584104454144835, Final Batch Loss: 0.0\n",
      "Epoch 2366, Loss: 0.034180302754975855, Final Batch Loss: 0.0\n",
      "Epoch 2367, Loss: 0.031317753717303276, Final Batch Loss: 0.0\n",
      "Epoch 2368, Loss: 0.0449357866309299, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2369, Loss: 0.1710773785598576, Final Batch Loss: 0.1374920904636383\n",
      "Epoch 2370, Loss: 0.04247518815100193, Final Batch Loss: 0.0\n",
      "Epoch 2371, Loss: 0.02595590567216277, Final Batch Loss: 0.0\n",
      "Epoch 2372, Loss: 0.04887757170945406, Final Batch Loss: 0.0\n",
      "Epoch 2373, Loss: 0.04123334167525172, Final Batch Loss: 0.0\n",
      "Epoch 2374, Loss: 0.03956222906708717, Final Batch Loss: 0.0\n",
      "Epoch 2375, Loss: 0.04225317342206836, Final Batch Loss: 0.0\n",
      "Epoch 2376, Loss: 0.03143072547356951, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2377, Loss: 0.039981761455237574, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 2378, Loss: 0.3879239880479872, Final Batch Loss: 0.3580951392650604\n",
      "Epoch 2379, Loss: 0.03018510201945901, Final Batch Loss: 0.0\n",
      "Epoch 2380, Loss: 0.028687179903499782, Final Batch Loss: 0.0\n",
      "Epoch 2381, Loss: 0.059267072938382626, Final Batch Loss: 0.0\n",
      "Epoch 2382, Loss: 0.03137857769615948, Final Batch Loss: 0.0\n",
      "Epoch 2383, Loss: 0.04386968817561865, Final Batch Loss: 0.0\n",
      "Epoch 2384, Loss: 0.03829977195709944, Final Batch Loss: 0.0\n",
      "Epoch 2385, Loss: 0.039426131173968315, Final Batch Loss: 0.0\n",
      "Epoch 2386, Loss: 0.036436992697417736, Final Batch Loss: 0.0\n",
      "Epoch 2387, Loss: 0.08471215516328812, Final Batch Loss: 0.0\n",
      "Epoch 2388, Loss: 0.021227778401225805, Final Batch Loss: 0.0\n",
      "Epoch 2389, Loss: 0.022143250796943903, Final Batch Loss: 0.0\n",
      "Epoch 2390, Loss: 0.03964922402519733, Final Batch Loss: 0.0\n",
      "Epoch 2391, Loss: 0.026683412492275238, Final Batch Loss: 0.0\n",
      "Epoch 2392, Loss: 0.042496645750361495, Final Batch Loss: 3.2782016205601394e-05\n",
      "Epoch 2393, Loss: 0.03785672792582773, Final Batch Loss: 0.000485183292767033\n",
      "Epoch 2394, Loss: 0.020891796797513962, Final Batch Loss: 0.0\n",
      "Epoch 2395, Loss: 0.0310700223690219, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 2396, Loss: 0.025397052289918065, Final Batch Loss: 0.0\n",
      "Epoch 2397, Loss: 0.029077432118356228, Final Batch Loss: 0.0\n",
      "Epoch 2398, Loss: 0.020392959471791983, Final Batch Loss: 0.0\n",
      "Epoch 2399, Loss: 0.027739114593714476, Final Batch Loss: 0.0\n",
      "Epoch 2400, Loss: 0.029279700931510888, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 2401, Loss: 0.03979774261824787, Final Batch Loss: 0.0\n",
      "Epoch 2402, Loss: 0.033867490477859974, Final Batch Loss: 0.0\n",
      "Epoch 2403, Loss: 0.026032425696001837, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2404, Loss: 0.028155147098004818, Final Batch Loss: 0.0\n",
      "Epoch 2405, Loss: 0.031431682175025344, Final Batch Loss: 0.0\n",
      "Epoch 2406, Loss: 0.026740743312984705, Final Batch Loss: 0.0\n",
      "Epoch 2407, Loss: 0.0356891555711627, Final Batch Loss: 0.0\n",
      "Epoch 2408, Loss: 0.031107579823583364, Final Batch Loss: 0.00283447140827775\n",
      "Epoch 2409, Loss: 0.040478289127349854, Final Batch Loss: 0.0\n",
      "Epoch 2410, Loss: 0.0678095449693501, Final Batch Loss: 0.0\n",
      "Epoch 2411, Loss: 0.029216959974291967, Final Batch Loss: 5.471556869451888e-05\n",
      "Epoch 2412, Loss: 0.02118584467098117, Final Batch Loss: 0.0\n",
      "Epoch 2413, Loss: 0.024227034213254228, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 2414, Loss: 0.030016421107575297, Final Batch Loss: 0.0\n",
      "Epoch 2415, Loss: 0.050823175348341465, Final Batch Loss: 0.0\n",
      "Epoch 2416, Loss: 0.03318955158465542, Final Batch Loss: 9.500529267825186e-05\n",
      "Epoch 2417, Loss: 0.0371957449222009, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 2418, Loss: 0.024577415413659764, Final Batch Loss: 3.4689302992774174e-05\n",
      "Epoch 2419, Loss: 0.01463754117503413, Final Batch Loss: 3.313963316031732e-05\n",
      "Epoch 2420, Loss: 0.02392747113481164, Final Batch Loss: 0.0\n",
      "Epoch 2421, Loss: 0.03644561255350709, Final Batch Loss: 0.0\n",
      "Epoch 2422, Loss: 0.026621476048603654, Final Batch Loss: 0.0023491187021136284\n",
      "Epoch 2423, Loss: 0.0536446503829211, Final Batch Loss: 0.0033875482622534037\n",
      "Epoch 2424, Loss: 0.025533830048516393, Final Batch Loss: 0.0\n",
      "Epoch 2425, Loss: 0.028526121750473976, Final Batch Loss: 0.0\n",
      "Epoch 2426, Loss: 0.8620860138908029, Final Batch Loss: 0.8334956169128418\n",
      "Epoch 2427, Loss: 0.04263826832175255, Final Batch Loss: 0.0\n",
      "Epoch 2428, Loss: 0.08142194151878357, Final Batch Loss: 0.0\n",
      "Epoch 2429, Loss: 0.16381020843982697, Final Batch Loss: 0.0\n",
      "Epoch 2430, Loss: 0.15824861271539703, Final Batch Loss: 0.0005625095800496638\n",
      "Epoch 2431, Loss: 0.12690065894275904, Final Batch Loss: 0.0\n",
      "Epoch 2432, Loss: 0.10477875731885433, Final Batch Loss: 0.0\n",
      "Epoch 2433, Loss: 0.12321186065673828, Final Batch Loss: 0.0\n",
      "Epoch 2434, Loss: 0.08015746995806694, Final Batch Loss: 0.0\n",
      "Epoch 2435, Loss: 0.058421033434569836, Final Batch Loss: 0.0\n",
      "Epoch 2436, Loss: 0.054147227201610804, Final Batch Loss: 0.0\n",
      "Epoch 2437, Loss: 0.07183919381350279, Final Batch Loss: 0.0\n",
      "Epoch 2438, Loss: 0.03623403329401498, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2439, Loss: 0.06657749926671386, Final Batch Loss: 0.0\n",
      "Epoch 2440, Loss: 0.050260990392416716, Final Batch Loss: 0.0\n",
      "Epoch 2441, Loss: 0.06438287906348705, Final Batch Loss: 0.0\n",
      "Epoch 2442, Loss: 0.055685088969767094, Final Batch Loss: 0.0\n",
      "Epoch 2443, Loss: 0.0434404443949461, Final Batch Loss: 0.0\n",
      "Epoch 2444, Loss: 0.04412629958096659, Final Batch Loss: 5.4596363042946905e-05\n",
      "Epoch 2445, Loss: 0.027682180516421795, Final Batch Loss: 0.0\n",
      "Epoch 2446, Loss: 0.04187895169479816, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 2447, Loss: 0.031159923411877344, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2448, Loss: 0.042295451276004314, Final Batch Loss: 0.0\n",
      "Epoch 2449, Loss: 0.04134517814964056, Final Batch Loss: 0.0\n",
      "Epoch 2450, Loss: 0.05949878226965666, Final Batch Loss: 0.0\n",
      "Epoch 2451, Loss: 0.03146811388432269, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2452, Loss: 0.04921811167150736, Final Batch Loss: 0.0\n",
      "Epoch 2453, Loss: 0.03648171946405654, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2454, Loss: 0.036649105604681154, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2455, Loss: 0.0298890583217144, Final Batch Loss: 0.0\n",
      "Epoch 2456, Loss: 0.032519527710974216, Final Batch Loss: 0.0\n",
      "Epoch 2457, Loss: 0.03625435847789049, Final Batch Loss: 0.0\n",
      "Epoch 2458, Loss: 0.03807397373020649, Final Batch Loss: 0.0\n",
      "Epoch 2459, Loss: 0.02468427736312151, Final Batch Loss: 0.0\n",
      "Epoch 2460, Loss: 0.03766810987053759, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2461, Loss: 0.031167723675025627, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 2462, Loss: 0.018105272494722158, Final Batch Loss: 0.0\n",
      "Epoch 2463, Loss: 0.029179814271628857, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2464, Loss: 0.02872388340165344, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 2465, Loss: 0.02216755156155159, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 2466, Loss: 0.03831308940425515, Final Batch Loss: 0.0\n",
      "Epoch 2467, Loss: 0.023175542009994388, Final Batch Loss: 0.002902345033362508\n",
      "Epoch 2468, Loss: 0.019364353733180906, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 2469, Loss: 0.02555651735747233, Final Batch Loss: 9.095255518332124e-05\n",
      "Epoch 2470, Loss: 0.02439227793365717, Final Batch Loss: 0.0\n",
      "Epoch 2471, Loss: 0.02961820995551534, Final Batch Loss: 0.00036161558819003403\n",
      "Epoch 2472, Loss: 0.029033051723672543, Final Batch Loss: 8.856858039507642e-05\n",
      "Epoch 2473, Loss: 0.03431717772036791, Final Batch Loss: 0.0\n",
      "Epoch 2474, Loss: 0.028232647106051445, Final Batch Loss: 0.0025518732145428658\n",
      "Epoch 2475, Loss: 0.019905667286366224, Final Batch Loss: 0.0\n",
      "Epoch 2476, Loss: 0.025388927198946476, Final Batch Loss: 0.0\n",
      "Epoch 2477, Loss: 0.023693820150583633, Final Batch Loss: 1.2516897186287679e-05\n",
      "Epoch 2478, Loss: 0.02314627543091774, Final Batch Loss: 0.0\n",
      "Epoch 2479, Loss: 0.02550896315366913, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2480, Loss: 0.02649799780920148, Final Batch Loss: 0.0\n",
      "Epoch 2481, Loss: 0.029121749567821098, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2482, Loss: 0.024142850656062365, Final Batch Loss: 0.0\n",
      "Epoch 2483, Loss: 0.019075679476372898, Final Batch Loss: 0.0\n",
      "Epoch 2484, Loss: 0.026387177406718365, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2485, Loss: 0.02556375134735589, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2486, Loss: 0.02598366979509592, Final Batch Loss: 0.0\n",
      "Epoch 2487, Loss: 0.03565275626897346, Final Batch Loss: 0.00015233787416946143\n",
      "Epoch 2488, Loss: 0.029535147710703313, Final Batch Loss: 0.0\n",
      "Epoch 2489, Loss: 0.032339063473017404, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2490, Loss: 0.048810322768986225, Final Batch Loss: 0.022443577647209167\n",
      "Epoch 2491, Loss: 0.03279294911772013, Final Batch Loss: 0.0\n",
      "Epoch 2492, Loss: 0.03200985910370946, Final Batch Loss: 0.0\n",
      "Epoch 2493, Loss: 0.024111577774419857, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2494, Loss: 0.023184443125501275, Final Batch Loss: 0.0\n",
      "Epoch 2495, Loss: 0.0541480160318315, Final Batch Loss: 0.0337870754301548\n",
      "Epoch 2496, Loss: 0.029701432213187218, Final Batch Loss: 0.0\n",
      "Epoch 2497, Loss: 0.04268342349678278, Final Batch Loss: 0.0\n",
      "Epoch 2498, Loss: 0.024860972262104042, Final Batch Loss: 9.929640509653836e-05\n",
      "Epoch 2499, Loss: 0.02482012426480651, Final Batch Loss: 0.0\n",
      "Epoch 2500, Loss: 0.03076396230608225, Final Batch Loss: 0.0\n",
      "Epoch 2501, Loss: 0.04552545305341482, Final Batch Loss: 0.0\n",
      "Epoch 2502, Loss: 0.035889719147235155, Final Batch Loss: 0.0\n",
      "Epoch 2503, Loss: 0.023227595491334796, Final Batch Loss: 0.0\n",
      "Epoch 2504, Loss: 0.02665554013901783, Final Batch Loss: 6.6756979322235566e-06\n",
      "Epoch 2505, Loss: 0.030622330494225025, Final Batch Loss: 0.0\n",
      "Epoch 2506, Loss: 0.013021327229580493, Final Batch Loss: 2.5510462364763953e-05\n",
      "Epoch 2507, Loss: 0.021309863892383873, Final Batch Loss: 0.0\n",
      "Epoch 2508, Loss: 0.021038143895566463, Final Batch Loss: 0.0\n",
      "Epoch 2509, Loss: 0.024160791654111335, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2510, Loss: 0.02605655835941434, Final Batch Loss: 0.0\n",
      "Epoch 2511, Loss: 0.01962335011921823, Final Batch Loss: 0.0\n",
      "Epoch 2512, Loss: 0.016734834760427475, Final Batch Loss: 0.0\n",
      "Epoch 2513, Loss: 0.02164176897690595, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 2514, Loss: 0.026715348474681377, Final Batch Loss: 0.0\n",
      "Epoch 2515, Loss: 0.013313301606103778, Final Batch Loss: 0.0\n",
      "Epoch 2516, Loss: 0.026529901893802332, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2517, Loss: 0.03238013316871502, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2518, Loss: 0.04121431009843235, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2519, Loss: 0.030122146708890796, Final Batch Loss: 0.0\n",
      "Epoch 2520, Loss: 0.026088668033480644, Final Batch Loss: 0.0\n",
      "Epoch 2521, Loss: 0.017421873746116034, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 2522, Loss: 0.04484169953298078, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 2523, Loss: 0.02945218374952674, Final Batch Loss: 0.010871939361095428\n",
      "Epoch 2524, Loss: 0.03195856461752555, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 2525, Loss: 0.026240254956064746, Final Batch Loss: 0.00013493580627255142\n",
      "Epoch 2526, Loss: 0.028818692080676556, Final Batch Loss: 0.0\n",
      "Epoch 2527, Loss: 0.034945932681239356, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 2528, Loss: 0.021244692150503397, Final Batch Loss: 0.0\n",
      "Epoch 2529, Loss: 0.041149829514324665, Final Batch Loss: 0.0\n",
      "Epoch 2530, Loss: 0.024840506725013256, Final Batch Loss: 0.003267427906394005\n",
      "Epoch 2531, Loss: 0.028444636041967897, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 2532, Loss: 0.02207408449612558, Final Batch Loss: 0.0\n",
      "Epoch 2533, Loss: 0.02147156417959195, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 2534, Loss: 0.016893288353458047, Final Batch Loss: 0.0\n",
      "Epoch 2535, Loss: 0.033172858413081485, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2536, Loss: 0.030039059463888407, Final Batch Loss: 0.0\n",
      "Epoch 2537, Loss: 0.02206073561680455, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2538, Loss: 0.027269559912383556, Final Batch Loss: 0.0\n",
      "Epoch 2539, Loss: 0.02198214188683778, Final Batch Loss: 0.0\n",
      "Epoch 2540, Loss: 0.030718525473275804, Final Batch Loss: 2.825220326485578e-05\n",
      "Epoch 2541, Loss: 0.03373155227382085, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 2542, Loss: 0.01971937483176589, Final Batch Loss: 0.0\n",
      "Epoch 2543, Loss: 0.02175694005563855, Final Batch Loss: 0.0\n",
      "Epoch 2544, Loss: 0.019085878739133477, Final Batch Loss: 0.003651144215837121\n",
      "Epoch 2545, Loss: 0.031329651828855276, Final Batch Loss: 0.0\n",
      "Epoch 2546, Loss: 0.016703716217307374, Final Batch Loss: 0.0\n",
      "Epoch 2547, Loss: 0.016187117202207446, Final Batch Loss: 0.0\n",
      "Epoch 2548, Loss: 0.02459102449938655, Final Batch Loss: 0.0\n",
      "Epoch 2549, Loss: 0.018843357405785355, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 2550, Loss: 0.045510273426771164, Final Batch Loss: 0.0\n",
      "Epoch 2551, Loss: 0.015658088261261582, Final Batch Loss: 0.0\n",
      "Epoch 2552, Loss: 0.01728356978856027, Final Batch Loss: 0.0\n",
      "Epoch 2553, Loss: 0.03420004900544882, Final Batch Loss: 0.0\n",
      "Epoch 2554, Loss: 0.02641840685828356, Final Batch Loss: 1.5735502529423684e-05\n",
      "Epoch 2555, Loss: 0.017289632465690374, Final Batch Loss: 0.0\n",
      "Epoch 2556, Loss: 0.02523916878271848, Final Batch Loss: 0.0\n",
      "Epoch 2557, Loss: 0.0383925207570428, Final Batch Loss: 0.00012003655137959868\n",
      "Epoch 2558, Loss: 0.020395867992192507, Final Batch Loss: 0.0\n",
      "Epoch 2559, Loss: 0.017496956046670675, Final Batch Loss: 0.0\n",
      "Epoch 2560, Loss: 0.027331385721481638, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 2561, Loss: 0.026104248478077352, Final Batch Loss: 0.0\n",
      "Epoch 2562, Loss: 0.02312279655598104, Final Batch Loss: 0.0\n",
      "Epoch 2563, Loss: 0.024313265457720945, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2564, Loss: 0.01470185280777514, Final Batch Loss: 0.0\n",
      "Epoch 2565, Loss: 0.02398658589072511, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 2566, Loss: 0.021709484746679664, Final Batch Loss: 0.0\n",
      "Epoch 2567, Loss: 0.029729054542144695, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2568, Loss: 0.018090952187776566, Final Batch Loss: 0.0\n",
      "Epoch 2569, Loss: 0.03550573391839862, Final Batch Loss: 0.0\n",
      "Epoch 2570, Loss: 0.019975961418822408, Final Batch Loss: 0.0\n",
      "Epoch 2571, Loss: 0.03131976583972573, Final Batch Loss: 0.00875716283917427\n",
      "Epoch 2572, Loss: 0.02929648756980896, Final Batch Loss: 0.0\n",
      "Epoch 2573, Loss: 0.018917609471827745, Final Batch Loss: 0.0\n",
      "Epoch 2574, Loss: 0.01733942236751318, Final Batch Loss: 0.0\n",
      "Epoch 2575, Loss: 0.015437094843946397, Final Batch Loss: 0.0\n",
      "Epoch 2576, Loss: 0.019967110361903906, Final Batch Loss: 0.0\n",
      "Epoch 2577, Loss: 0.02563887508586049, Final Batch Loss: 0.0\n",
      "Epoch 2578, Loss: 0.018397437874227762, Final Batch Loss: 0.0\n",
      "Epoch 2579, Loss: 0.028073502704501152, Final Batch Loss: 0.0\n",
      "Epoch 2580, Loss: 0.016857130227435846, Final Batch Loss: 3.3854863431770355e-05\n",
      "Epoch 2581, Loss: 0.018191229784861207, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2582, Loss: 0.022555953820528885, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 2583, Loss: 0.018453129141562385, Final Batch Loss: 5.209310256759636e-05\n",
      "Epoch 2584, Loss: 0.03175374601778458, Final Batch Loss: 1.2397689715726301e-05\n",
      "Epoch 2585, Loss: 0.022063486161641777, Final Batch Loss: 0.0015670888824388385\n",
      "Epoch 2586, Loss: 0.017487571574747562, Final Batch Loss: 0.0\n",
      "Epoch 2587, Loss: 0.025605633156374097, Final Batch Loss: 0.0\n",
      "Epoch 2588, Loss: 0.030680944095365703, Final Batch Loss: 0.0\n",
      "Epoch 2589, Loss: 0.01706223381916061, Final Batch Loss: 0.0\n",
      "Epoch 2590, Loss: 0.03003399632871151, Final Batch Loss: 0.0\n",
      "Epoch 2591, Loss: 0.012647275812923908, Final Batch Loss: 0.0\n",
      "Epoch 2592, Loss: 0.016116347862407565, Final Batch Loss: 0.0\n",
      "Epoch 2593, Loss: 0.02540828427197539, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2594, Loss: 0.02019312605261092, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2595, Loss: 0.023260860703885555, Final Batch Loss: 0.0\n",
      "Epoch 2596, Loss: 0.018308082595467567, Final Batch Loss: 0.0\n",
      "Epoch 2597, Loss: 0.018457754515111446, Final Batch Loss: 0.0\n",
      "Epoch 2598, Loss: 0.01479803494294174, Final Batch Loss: 0.00019167017308063805\n",
      "Epoch 2599, Loss: 0.01837349310517311, Final Batch Loss: 0.0\n",
      "Epoch 2600, Loss: 0.021552185993641615, Final Batch Loss: 0.0\n",
      "Epoch 2601, Loss: 0.018931424245238304, Final Batch Loss: 0.0\n",
      "Epoch 2602, Loss: 0.23478795518167317, Final Batch Loss: 0.21834556758403778\n",
      "Epoch 2603, Loss: 0.01069424138404429, Final Batch Loss: 0.0\n",
      "Epoch 2604, Loss: 0.09591556200757623, Final Batch Loss: 0.0\n",
      "Epoch 2605, Loss: 0.08038912899792194, Final Batch Loss: 0.0\n",
      "Epoch 2606, Loss: 0.07778660207986832, Final Batch Loss: 0.0\n",
      "Epoch 2607, Loss: 0.05797874739164399, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 2608, Loss: 0.06032715842593461, Final Batch Loss: 0.00047839165199548006\n",
      "Epoch 2609, Loss: 0.06414815736934543, Final Batch Loss: 0.0\n",
      "Epoch 2610, Loss: 0.10548074636551519, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2611, Loss: 0.09302284335717559, Final Batch Loss: 0.0\n",
      "Epoch 2612, Loss: 0.06331354193389416, Final Batch Loss: 0.0\n",
      "Epoch 2613, Loss: 0.045390550047159195, Final Batch Loss: 0.0\n",
      "Epoch 2614, Loss: 0.04859745968133211, Final Batch Loss: 0.0\n",
      "Epoch 2615, Loss: 0.0555950622074306, Final Batch Loss: 0.0\n",
      "Epoch 2616, Loss: 0.05434731114655733, Final Batch Loss: 0.0\n",
      "Epoch 2617, Loss: 0.053753314539790154, Final Batch Loss: 0.0\n",
      "Epoch 2618, Loss: 0.03197335216100328, Final Batch Loss: 0.00017414960893802345\n",
      "Epoch 2619, Loss: 0.029110028641298413, Final Batch Loss: 0.0\n",
      "Epoch 2620, Loss: 0.02772021060809493, Final Batch Loss: 0.0\n",
      "Epoch 2621, Loss: 0.02087315684184432, Final Batch Loss: 0.0\n",
      "Epoch 2622, Loss: 0.029351403936743736, Final Batch Loss: 0.0\n",
      "Epoch 2623, Loss: 0.01878886274062097, Final Batch Loss: 0.0\n",
      "Epoch 2624, Loss: 0.02216943311941577, Final Batch Loss: 0.00010299152199877426\n",
      "Epoch 2625, Loss: 0.012972393073027888, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2626, Loss: 0.021951281931251287, Final Batch Loss: 0.0\n",
      "Epoch 2627, Loss: 0.03766511753201485, Final Batch Loss: 0.0\n",
      "Epoch 2628, Loss: 0.033779585268348455, Final Batch Loss: 0.0\n",
      "Epoch 2629, Loss: 0.025331012438954303, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2630, Loss: 0.018015459412701773, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2631, Loss: 0.08836240449454635, Final Batch Loss: 0.0016719423001632094\n",
      "Epoch 2632, Loss: 0.41508257598616183, Final Batch Loss: 0.40081363916397095\n",
      "Epoch 2633, Loss: 0.01903586310800165, Final Batch Loss: 0.0\n",
      "Epoch 2634, Loss: 0.0350586399435997, Final Batch Loss: 0.0\n",
      "Epoch 2635, Loss: 0.02396367443679992, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2636, Loss: 0.02806908159982413, Final Batch Loss: 0.0\n",
      "Epoch 2637, Loss: 0.028583179228007793, Final Batch Loss: 0.0\n",
      "Epoch 2638, Loss: 0.02552563336212188, Final Batch Loss: 0.0\n",
      "Epoch 2639, Loss: 0.028429246274299658, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2640, Loss: 0.0196745740249753, Final Batch Loss: 0.0\n",
      "Epoch 2641, Loss: 0.023550384677946568, Final Batch Loss: 0.0015491163358092308\n",
      "Epoch 2642, Loss: 0.019306824176965165, Final Batch Loss: 1.6331539882230572e-05\n",
      "Epoch 2643, Loss: 0.023484122939407825, Final Batch Loss: 0.0\n",
      "Epoch 2644, Loss: 0.027452132664620876, Final Batch Loss: 0.0\n",
      "Epoch 2645, Loss: 0.023338976283412194, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 2646, Loss: 0.03151765023357456, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2647, Loss: 0.016047516837716103, Final Batch Loss: 0.0\n",
      "Epoch 2648, Loss: 0.01726964797853725, Final Batch Loss: 4.160317621426657e-05\n",
      "Epoch 2649, Loss: 0.03284981899196282, Final Batch Loss: 0.0007014198345132172\n",
      "Epoch 2650, Loss: 0.05183665588265285, Final Batch Loss: 0.0003252692404203117\n",
      "Epoch 2651, Loss: 0.02004604460671544, Final Batch Loss: 0.0\n",
      "Epoch 2652, Loss: 0.02846471220254898, Final Batch Loss: 0.0\n",
      "Epoch 2653, Loss: 0.03600079333409667, Final Batch Loss: 0.0\n",
      "Epoch 2654, Loss: 0.0188374319113791, Final Batch Loss: 0.0\n",
      "Epoch 2655, Loss: 0.01832462934180512, Final Batch Loss: 5.400034933700226e-05\n",
      "Epoch 2656, Loss: 0.030870356480591, Final Batch Loss: 0.0\n",
      "Epoch 2657, Loss: 0.021969876252114773, Final Batch Loss: 0.0\n",
      "Epoch 2658, Loss: 0.013682871358469129, Final Batch Loss: 0.0\n",
      "Epoch 2659, Loss: 0.02876628586091101, Final Batch Loss: 0.0\n",
      "Epoch 2660, Loss: 0.014364145157742314, Final Batch Loss: 0.00013958434283267707\n",
      "Epoch 2661, Loss: 0.016475292737595737, Final Batch Loss: 0.0\n",
      "Epoch 2662, Loss: 0.016055464278906584, Final Batch Loss: 0.0\n",
      "Epoch 2663, Loss: 0.011628697393462062, Final Batch Loss: 0.0\n",
      "Epoch 2664, Loss: 0.013489365461282432, Final Batch Loss: 0.0\n",
      "Epoch 2665, Loss: 0.02409935195464641, Final Batch Loss: 0.0\n",
      "Epoch 2666, Loss: 0.032767225522540855, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2667, Loss: 0.010524032229994873, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2668, Loss: 0.02568730292841792, Final Batch Loss: 0.0\n",
      "Epoch 2669, Loss: 0.014753172217751853, Final Batch Loss: 6.031808152329177e-05\n",
      "Epoch 2670, Loss: 0.025949019472875534, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2671, Loss: 0.027210229309275746, Final Batch Loss: 0.0\n",
      "Epoch 2672, Loss: 0.061103130457922816, Final Batch Loss: 0.0\n",
      "Epoch 2673, Loss: 0.015290491748601198, Final Batch Loss: 0.0\n",
      "Epoch 2674, Loss: 0.020967537304386497, Final Batch Loss: 0.0\n",
      "Epoch 2675, Loss: 0.016652556048939005, Final Batch Loss: 0.0\n",
      "Epoch 2676, Loss: 0.020836986019276083, Final Batch Loss: 0.0\n",
      "Epoch 2677, Loss: 0.027478967793285847, Final Batch Loss: 0.0\n",
      "Epoch 2678, Loss: 0.017175581538879214, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2679, Loss: 0.016745479311794043, Final Batch Loss: 0.0\n",
      "Epoch 2680, Loss: 0.017894013784825802, Final Batch Loss: 0.0\n",
      "Epoch 2681, Loss: 0.01371337310411036, Final Batch Loss: 0.0\n",
      "Epoch 2682, Loss: 0.0152003881521523, Final Batch Loss: 0.0\n",
      "Epoch 2683, Loss: 0.019605200504884124, Final Batch Loss: 0.0\n",
      "Epoch 2684, Loss: 0.03213928686182044, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 2685, Loss: 0.02886930084787309, Final Batch Loss: 0.0\n",
      "Epoch 2686, Loss: 0.025539617985486984, Final Batch Loss: 0.0\n",
      "Epoch 2687, Loss: 0.00950477592414245, Final Batch Loss: 0.0\n",
      "Epoch 2688, Loss: 0.019687240826897323, Final Batch Loss: 0.0\n",
      "Epoch 2689, Loss: 0.021817087661474943, Final Batch Loss: 0.0\n",
      "Epoch 2690, Loss: 0.022983528207987547, Final Batch Loss: 0.0\n",
      "Epoch 2691, Loss: 0.023942097323015332, Final Batch Loss: 0.0\n",
      "Epoch 2692, Loss: 0.025781438685953617, Final Batch Loss: 0.0\n",
      "Epoch 2693, Loss: 0.03611329517661943, Final Batch Loss: 1.1086402082582936e-05\n",
      "Epoch 2694, Loss: 0.03355975728479166, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2695, Loss: 0.017009825445711613, Final Batch Loss: 0.0\n",
      "Epoch 2696, Loss: 0.02836603531613946, Final Batch Loss: 0.0\n",
      "Epoch 2697, Loss: 0.013008621288463473, Final Batch Loss: 0.0\n",
      "Epoch 2698, Loss: 0.017767584882669496, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2699, Loss: 0.019684480503201485, Final Batch Loss: 0.0\n",
      "Epoch 2700, Loss: 0.01854491117398993, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2701, Loss: 0.018300340743735433, Final Batch Loss: 0.0\n",
      "Epoch 2702, Loss: 0.013245014008134604, Final Batch Loss: 0.0\n",
      "Epoch 2703, Loss: 0.02961113612400368, Final Batch Loss: 0.0\n",
      "Epoch 2704, Loss: 0.020358549198135734, Final Batch Loss: 0.0\n",
      "Epoch 2705, Loss: 0.02220020687673241, Final Batch Loss: 0.0\n",
      "Epoch 2706, Loss: 0.030204638751456514, Final Batch Loss: 0.00026639728457666934\n",
      "Epoch 2707, Loss: 0.017070881323888898, Final Batch Loss: 0.0\n",
      "Epoch 2708, Loss: 0.01715017179952838, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2709, Loss: 0.015047248220071197, Final Batch Loss: 0.0\n",
      "Epoch 2710, Loss: 0.019218657398596406, Final Batch Loss: 0.0\n",
      "Epoch 2711, Loss: 0.012535465648397803, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2712, Loss: 0.014612482103984803, Final Batch Loss: 0.0\n",
      "Epoch 2713, Loss: 0.016077668289653957, Final Batch Loss: 0.0\n",
      "Epoch 2714, Loss: 0.014368070289492607, Final Batch Loss: 0.0\n",
      "Epoch 2715, Loss: 0.016763920662924647, Final Batch Loss: 0.0\n",
      "Epoch 2716, Loss: 0.018186818808317184, Final Batch Loss: 0.002956307725980878\n",
      "Epoch 2717, Loss: 0.012513964786194265, Final Batch Loss: 0.0\n",
      "Epoch 2718, Loss: 0.030522304587066174, Final Batch Loss: 0.0\n",
      "Epoch 2719, Loss: 0.014544098870828748, Final Batch Loss: 0.0\n",
      "Epoch 2720, Loss: 0.08775711432099342, Final Batch Loss: 0.07205130904912949\n",
      "Epoch 2721, Loss: 0.016523692989721894, Final Batch Loss: 0.0\n",
      "Epoch 2722, Loss: 0.019756474997848272, Final Batch Loss: 0.0\n",
      "Epoch 2723, Loss: 0.01002461020834744, Final Batch Loss: 0.0\n",
      "Epoch 2724, Loss: 0.012490318389609456, Final Batch Loss: 0.0\n",
      "Epoch 2725, Loss: 0.015283250249922276, Final Batch Loss: 0.0\n",
      "Epoch 2726, Loss: 0.019254293481935747, Final Batch Loss: 0.00015436411194968969\n",
      "Epoch 2727, Loss: 0.011639959644526243, Final Batch Loss: 0.0\n",
      "Epoch 2728, Loss: 0.01573455845937133, Final Batch Loss: 0.0\n",
      "Epoch 2729, Loss: 0.016184950713068247, Final Batch Loss: 0.0\n",
      "Epoch 2730, Loss: 0.01062392741914664, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 2731, Loss: 0.026067910248457338, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 2732, Loss: 0.009740366134792566, Final Batch Loss: 0.0\n",
      "Epoch 2733, Loss: 0.01655887395463651, Final Batch Loss: 6.258291978156194e-05\n",
      "Epoch 2734, Loss: 0.019594918412622064, Final Batch Loss: 0.0\n",
      "Epoch 2735, Loss: 0.020967687014490366, Final Batch Loss: 0.0\n",
      "Epoch 2736, Loss: 0.011419482761994004, Final Batch Loss: 0.0\n",
      "Epoch 2737, Loss: 0.011846312553984717, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2738, Loss: 0.008531571831554174, Final Batch Loss: 0.0\n",
      "Epoch 2739, Loss: 0.011249251663684845, Final Batch Loss: 0.0\n",
      "Epoch 2740, Loss: 0.12649731803685427, Final Batch Loss: 0.11511002480983734\n",
      "Epoch 2741, Loss: 0.018694674559810665, Final Batch Loss: 7.521823135903105e-05\n",
      "Epoch 2742, Loss: 0.020644255680963397, Final Batch Loss: 0.0\n",
      "Epoch 2743, Loss: 0.03844618407310918, Final Batch Loss: 0.0\n",
      "Epoch 2744, Loss: 0.035777858457777256, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2745, Loss: 0.023827838245779276, Final Batch Loss: 0.0\n",
      "Epoch 2746, Loss: 0.03295137174427509, Final Batch Loss: 0.0\n",
      "Epoch 2747, Loss: 0.03009861335158348, Final Batch Loss: 0.0\n",
      "Epoch 2748, Loss: 0.0306730386801064, Final Batch Loss: 0.0\n",
      "Epoch 2749, Loss: 0.009323203237727284, Final Batch Loss: 0.0\n",
      "Epoch 2750, Loss: 0.013226355193182826, Final Batch Loss: 0.0\n",
      "Epoch 2751, Loss: 0.08597174880560488, Final Batch Loss: 0.0\n",
      "Epoch 2752, Loss: 0.012409839313477278, Final Batch Loss: 0.0\n",
      "Epoch 2753, Loss: 0.011160621492308564, Final Batch Loss: 0.00022289653134066612\n",
      "Epoch 2754, Loss: 0.017280694097280502, Final Batch Loss: 0.0\n",
      "Epoch 2755, Loss: 0.012431243900209665, Final Batch Loss: 0.0014761515194550157\n",
      "Epoch 2756, Loss: 0.016358766238226963, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2757, Loss: 0.0283956415951252, Final Batch Loss: 0.0\n",
      "Epoch 2758, Loss: 0.01923809666186571, Final Batch Loss: 0.0\n",
      "Epoch 2759, Loss: 0.014572343090549111, Final Batch Loss: 0.0\n",
      "Epoch 2760, Loss: 0.015556098485831171, Final Batch Loss: 0.0\n",
      "Epoch 2761, Loss: 0.02369672665372491, Final Batch Loss: 0.0\n",
      "Epoch 2762, Loss: 0.015572223521303385, Final Batch Loss: 0.0\n",
      "Epoch 2763, Loss: 0.011134330765344203, Final Batch Loss: 0.0\n",
      "Epoch 2764, Loss: 0.008677298639668152, Final Batch Loss: 0.0\n",
      "Epoch 2765, Loss: 0.015020279679447412, Final Batch Loss: 0.0\n",
      "Epoch 2766, Loss: 0.017731201834976673, Final Batch Loss: 0.0\n",
      "Epoch 2767, Loss: 0.021241336129548927, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2768, Loss: 0.01443357765674591, Final Batch Loss: 0.0\n",
      "Epoch 2769, Loss: 0.008043990470468998, Final Batch Loss: 0.0\n",
      "Epoch 2770, Loss: 0.021457900060340762, Final Batch Loss: 0.0\n",
      "Epoch 2771, Loss: 0.013262952179502463, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 2772, Loss: 0.015705343568697572, Final Batch Loss: 0.0\n",
      "Epoch 2773, Loss: 0.013443918665871024, Final Batch Loss: 0.0\n",
      "Epoch 2774, Loss: 0.009803500528505538, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 2775, Loss: 0.012848300277255476, Final Batch Loss: 0.0\n",
      "Epoch 2776, Loss: 0.007040850061457604, Final Batch Loss: 0.0\n",
      "Epoch 2777, Loss: 0.025419090874493122, Final Batch Loss: 0.0\n",
      "Epoch 2778, Loss: 0.01254135905764997, Final Batch Loss: 0.0\n",
      "Epoch 2779, Loss: 0.0147941829636693, Final Batch Loss: 0.0\n",
      "Epoch 2780, Loss: 0.021251074154854166, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2781, Loss: 0.01117873261679847, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2782, Loss: 0.013702419832952728, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 2783, Loss: 0.011913779424503446, Final Batch Loss: 0.0\n",
      "Epoch 2784, Loss: 0.011858995072543621, Final Batch Loss: 0.0\n",
      "Epoch 2785, Loss: 0.014059557695873082, Final Batch Loss: 0.0\n",
      "Epoch 2786, Loss: 0.015555080023659684, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 2787, Loss: 0.007608882733620703, Final Batch Loss: 0.0\n",
      "Epoch 2788, Loss: 0.009738097433000803, Final Batch Loss: 0.0\n",
      "Epoch 2789, Loss: 0.01645692065358162, Final Batch Loss: 0.0\n",
      "Epoch 2790, Loss: 0.008634602585516404, Final Batch Loss: 2.4437606043647975e-05\n",
      "Epoch 2791, Loss: 0.011188441421836615, Final Batch Loss: 0.0\n",
      "Epoch 2792, Loss: 0.01903997198678553, Final Batch Loss: 0.0\n",
      "Epoch 2793, Loss: 0.007005169696640223, Final Batch Loss: 0.0\n",
      "Epoch 2794, Loss: 0.024562867358319806, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2795, Loss: 0.016738583333790302, Final Batch Loss: 0.0\n",
      "Epoch 2796, Loss: 0.013142114854417741, Final Batch Loss: 0.0\n",
      "Epoch 2797, Loss: 0.010171470406930894, Final Batch Loss: 0.0\n",
      "Epoch 2798, Loss: 0.01978821388911456, Final Batch Loss: 0.0031945884693413973\n",
      "Epoch 2799, Loss: 0.034315588731260505, Final Batch Loss: 7.974783511599526e-05\n",
      "Epoch 2800, Loss: 0.01218246022472158, Final Batch Loss: 0.0\n",
      "Epoch 2801, Loss: 0.010143821011297405, Final Batch Loss: 0.0\n",
      "Epoch 2802, Loss: 0.009309421584475785, Final Batch Loss: 0.0\n",
      "Epoch 2803, Loss: 0.010150222922675312, Final Batch Loss: 0.00034588552080094814\n",
      "Epoch 2804, Loss: 0.02313712239265442, Final Batch Loss: 0.0\n",
      "Epoch 2805, Loss: 0.014131821459159255, Final Batch Loss: 0.0\n",
      "Epoch 2806, Loss: 0.011546332854663888, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2807, Loss: 0.012278063455596566, Final Batch Loss: 0.0\n",
      "Epoch 2808, Loss: 0.009799687381018884, Final Batch Loss: 9.572047565598041e-05\n",
      "Epoch 2809, Loss: 0.010580308036878705, Final Batch Loss: 0.0\n",
      "Epoch 2810, Loss: 0.006587350275367498, Final Batch Loss: 0.0\n",
      "Epoch 2811, Loss: 0.013506877236068249, Final Batch Loss: 0.0\n",
      "Epoch 2812, Loss: 0.01193523476831615, Final Batch Loss: 0.0\n",
      "Epoch 2813, Loss: 0.019436080241575837, Final Batch Loss: 0.0\n",
      "Epoch 2814, Loss: 0.009158298838883638, Final Batch Loss: 0.0\n",
      "Epoch 2815, Loss: 0.0077197495847940445, Final Batch Loss: 0.0\n",
      "Epoch 2816, Loss: 0.006711768277455121, Final Batch Loss: 0.0\n",
      "Epoch 2817, Loss: 0.03043262753635645, Final Batch Loss: 0.0\n",
      "Epoch 2818, Loss: 0.02847133530303836, Final Batch Loss: 0.0\n",
      "Epoch 2819, Loss: 0.01163723721401766, Final Batch Loss: 0.0\n",
      "Epoch 2820, Loss: 0.012627662334125489, Final Batch Loss: 0.0\n",
      "Epoch 2821, Loss: 0.01097864136681892, Final Batch Loss: 0.0\n",
      "Epoch 2822, Loss: 0.008721368096303195, Final Batch Loss: 0.0\n",
      "Epoch 2823, Loss: 0.016267777187749743, Final Batch Loss: 0.005100452806800604\n",
      "Epoch 2824, Loss: 0.017671296838642547, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2825, Loss: 0.005172055738512427, Final Batch Loss: 0.0\n",
      "Epoch 2826, Loss: 0.02475110394721014, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2827, Loss: 0.008616488164818747, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2828, Loss: 0.019060487626120448, Final Batch Loss: 0.0006167178507894278\n",
      "Epoch 2829, Loss: 0.013671578490175307, Final Batch Loss: 0.0\n",
      "Epoch 2830, Loss: 0.025005132891237736, Final Batch Loss: 0.014877676032483578\n",
      "Epoch 2831, Loss: 0.005548864486627281, Final Batch Loss: 0.0\n",
      "Epoch 2832, Loss: 0.045882909558713436, Final Batch Loss: 0.0\n",
      "Epoch 2833, Loss: 0.00650906162627507, Final Batch Loss: 0.0\n",
      "Epoch 2834, Loss: 0.022913380002137274, Final Batch Loss: 0.0\n",
      "Epoch 2835, Loss: 0.012769208988174796, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2836, Loss: 0.007829744659829885, Final Batch Loss: 0.0\n",
      "Epoch 2837, Loss: 0.020457189342778292, Final Batch Loss: 1.1920858014491387e-05\n",
      "Epoch 2838, Loss: 0.009335633600130677, Final Batch Loss: 0.0\n",
      "Epoch 2839, Loss: 0.030237478902563453, Final Batch Loss: 0.0\n",
      "Epoch 2840, Loss: 0.0583556949859485, Final Batch Loss: 0.031396497040987015\n",
      "Epoch 2841, Loss: 0.015282781181667815, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 2842, Loss: 0.010350213618949056, Final Batch Loss: 0.0\n",
      "Epoch 2843, Loss: 0.02367665828205645, Final Batch Loss: 0.0\n",
      "Epoch 2844, Loss: 0.03518646773591172, Final Batch Loss: 0.0\n",
      "Epoch 2845, Loss: 0.026340370764955878, Final Batch Loss: 0.01510679256170988\n",
      "Epoch 2846, Loss: 0.008349691750368038, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2847, Loss: 0.018596914131194353, Final Batch Loss: 0.0\n",
      "Epoch 2848, Loss: 0.01737853373742837, Final Batch Loss: 2.098061486321967e-05\n",
      "Epoch 2849, Loss: 0.03738920309115201, Final Batch Loss: 0.001501148217357695\n",
      "Epoch 2850, Loss: 0.010737871052697301, Final Batch Loss: 0.0\n",
      "Epoch 2851, Loss: 0.010727380751632154, Final Batch Loss: 0.0\n",
      "Epoch 2852, Loss: 0.023794077278580517, Final Batch Loss: 0.0\n",
      "Epoch 2853, Loss: 0.021277551189996302, Final Batch Loss: 0.0\n",
      "Epoch 2854, Loss: 0.013329090375918895, Final Batch Loss: 0.0\n",
      "Epoch 2855, Loss: 0.008457771502435207, Final Batch Loss: 0.0\n",
      "Epoch 2856, Loss: 0.017113834619522095, Final Batch Loss: 0.0\n",
      "Epoch 2857, Loss: 0.031173267867416143, Final Batch Loss: 0.0\n",
      "Epoch 2858, Loss: 0.018215743912151083, Final Batch Loss: 0.0003666205739136785\n",
      "Epoch 2859, Loss: 0.02165867387770959, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 2860, Loss: 0.0193065864732489, Final Batch Loss: 0.0012643685331568122\n",
      "Epoch 2861, Loss: 0.01917270803824067, Final Batch Loss: 0.0\n",
      "Epoch 2862, Loss: 0.009392557962200954, Final Batch Loss: 1.0251946150674485e-05\n",
      "Epoch 2863, Loss: 0.010328243137330162, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2864, Loss: 0.0055069345980882645, Final Batch Loss: 0.0\n",
      "Epoch 2865, Loss: 0.014772883267141879, Final Batch Loss: 0.0\n",
      "Epoch 2866, Loss: 0.020306068588979542, Final Batch Loss: 0.012284215539693832\n",
      "Epoch 2867, Loss: 0.013114322704495862, Final Batch Loss: 0.0\n",
      "Epoch 2868, Loss: 0.008706262917257845, Final Batch Loss: 0.0\n",
      "Epoch 2869, Loss: 0.012183036014903337, Final Batch Loss: 0.0\n",
      "Epoch 2870, Loss: 0.006430680557969026, Final Batch Loss: 1.2040065485052764e-05\n",
      "Epoch 2871, Loss: 0.010102775588165969, Final Batch Loss: 0.0\n",
      "Epoch 2872, Loss: 0.014669014140963554, Final Batch Loss: 0.0\n",
      "Epoch 2873, Loss: 0.01367134164320305, Final Batch Loss: 0.0\n",
      "Epoch 2874, Loss: 0.010297915549017489, Final Batch Loss: 0.0\n",
      "Epoch 2875, Loss: 0.013034198665991426, Final Batch Loss: 0.0\n",
      "Epoch 2876, Loss: 0.010906558483839035, Final Batch Loss: 0.0\n",
      "Epoch 2877, Loss: 0.008124389627482742, Final Batch Loss: 0.0\n",
      "Epoch 2878, Loss: 0.004825570227694698, Final Batch Loss: 0.0\n",
      "Epoch 2879, Loss: 0.012389805808197707, Final Batch Loss: 0.0\n",
      "Epoch 2880, Loss: 0.007172759534995521, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2881, Loss: 0.012281999399412769, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2882, Loss: 0.008361474494449794, Final Batch Loss: 0.0\n",
      "Epoch 2883, Loss: 0.0265920358360745, Final Batch Loss: 0.0\n",
      "Epoch 2884, Loss: 0.009163559647276998, Final Batch Loss: 0.0\n",
      "Epoch 2885, Loss: 0.009379616705700755, Final Batch Loss: 0.0\n",
      "Epoch 2886, Loss: 0.012160918966401368, Final Batch Loss: 0.0\n",
      "Epoch 2887, Loss: 0.0066794204412872205, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 2888, Loss: 0.10537839953758521, Final Batch Loss: 0.08074697107076645\n",
      "Epoch 2889, Loss: 0.0061665744869969785, Final Batch Loss: 0.0\n",
      "Epoch 2890, Loss: 0.007529182592406869, Final Batch Loss: 0.0\n",
      "Epoch 2891, Loss: 0.006649686372838914, Final Batch Loss: 0.0\n",
      "Epoch 2892, Loss: 0.011032977898139507, Final Batch Loss: 0.006561639253050089\n",
      "Epoch 2893, Loss: 0.004143957979977131, Final Batch Loss: 0.0\n",
      "Epoch 2894, Loss: 0.01134513021676753, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2895, Loss: 0.03426322527229786, Final Batch Loss: 0.0\n",
      "Epoch 2896, Loss: 0.010870585858356208, Final Batch Loss: 0.0030250048730522394\n",
      "Epoch 2897, Loss: 0.004987238149624318, Final Batch Loss: 0.0\n",
      "Epoch 2898, Loss: 0.01460268686037125, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2899, Loss: 0.0068731787032447755, Final Batch Loss: 0.0\n",
      "Epoch 2900, Loss: 0.022674910258494663, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2901, Loss: 0.011900077457539737, Final Batch Loss: 0.0\n",
      "Epoch 2902, Loss: 0.009605287108570337, Final Batch Loss: 0.0\n",
      "Epoch 2903, Loss: 0.009764476679265499, Final Batch Loss: 0.0\n",
      "Epoch 2904, Loss: 0.0036537589596719044, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 2905, Loss: 0.013125363766448572, Final Batch Loss: 0.0\n",
      "Epoch 2906, Loss: 0.021644300315529108, Final Batch Loss: 0.0\n",
      "Epoch 2907, Loss: 0.0037817717529833317, Final Batch Loss: 0.0\n",
      "Epoch 2908, Loss: 0.01486519817262888, Final Batch Loss: 0.0\n",
      "Epoch 2909, Loss: 0.009909076732583344, Final Batch Loss: 0.0\n",
      "Epoch 2910, Loss: 0.004236584645695984, Final Batch Loss: 0.0\n",
      "Epoch 2911, Loss: 0.0031057228334248066, Final Batch Loss: 0.0\n",
      "Epoch 2912, Loss: 0.0065027723321691155, Final Batch Loss: 0.0\n",
      "Epoch 2913, Loss: 0.005196710466378818, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2914, Loss: 0.00828282511793077, Final Batch Loss: 0.0\n",
      "Epoch 2915, Loss: 0.016510175773873925, Final Batch Loss: 0.0\n",
      "Epoch 2916, Loss: 0.008569058234570548, Final Batch Loss: 0.0\n",
      "Epoch 2917, Loss: 0.006891689001122359, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2918, Loss: 0.04660103132482618, Final Batch Loss: 0.0\n",
      "Epoch 2919, Loss: 0.008325295930262655, Final Batch Loss: 0.0005703729693777859\n",
      "Epoch 2920, Loss: 0.0067107369541190565, Final Batch Loss: 0.0\n",
      "Epoch 2921, Loss: 0.0059796808563987724, Final Batch Loss: 0.0\n",
      "Epoch 2922, Loss: 0.011533948010765016, Final Batch Loss: 0.0\n",
      "Epoch 2923, Loss: 0.00851772353053093, Final Batch Loss: 0.0\n",
      "Epoch 2924, Loss: 0.007665354438358918, Final Batch Loss: 0.0\n",
      "Epoch 2925, Loss: 0.006812513805925846, Final Batch Loss: 0.0\n",
      "Epoch 2926, Loss: 0.008172558387400386, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2927, Loss: 0.0031391921802423894, Final Batch Loss: 0.0\n",
      "Epoch 2928, Loss: 0.006717653886880726, Final Batch Loss: 0.0\n",
      "Epoch 2929, Loss: 0.007695968309235468, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 2930, Loss: 0.016084852861240506, Final Batch Loss: 0.0\n",
      "Epoch 2931, Loss: 0.008895499515347183, Final Batch Loss: 0.0\n",
      "Epoch 2932, Loss: 0.07011521444655955, Final Batch Loss: 0.06191136687994003\n",
      "Epoch 2933, Loss: 0.004129112581722438, Final Batch Loss: 0.0\n",
      "Epoch 2934, Loss: 0.0036073069204576313, Final Batch Loss: 0.0\n",
      "Epoch 2935, Loss: 0.01595412494498305, Final Batch Loss: 0.0\n",
      "Epoch 2936, Loss: 0.025499618495814502, Final Batch Loss: 0.0\n",
      "Epoch 2937, Loss: 0.0068683375138789415, Final Batch Loss: 0.0\n",
      "Epoch 2938, Loss: 0.016141981453984044, Final Batch Loss: 0.0\n",
      "Epoch 2939, Loss: 0.01013459195382893, Final Batch Loss: 0.0\n",
      "Epoch 2940, Loss: 0.01808206900022924, Final Batch Loss: 0.0\n",
      "Epoch 2941, Loss: 0.010489635984413326, Final Batch Loss: 0.0\n",
      "Epoch 2942, Loss: 0.003617561189457774, Final Batch Loss: 0.0\n",
      "Epoch 2943, Loss: 0.006043552275485808, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2944, Loss: 0.006443407502956688, Final Batch Loss: 0.0\n",
      "Epoch 2945, Loss: 0.012524810386821628, Final Batch Loss: 0.0\n",
      "Epoch 2946, Loss: 0.00322688277810812, Final Batch Loss: 0.0\n",
      "Epoch 2947, Loss: 0.009624821366742253, Final Batch Loss: 0.0\n",
      "Epoch 2948, Loss: 0.006510007428005338, Final Batch Loss: 0.0\n",
      "Epoch 2949, Loss: 0.010114226119185332, Final Batch Loss: 0.0\n",
      "Epoch 2950, Loss: 0.007714021950960159, Final Batch Loss: 0.0\n",
      "Epoch 2951, Loss: 0.013395613146713004, Final Batch Loss: 0.0\n",
      "Epoch 2952, Loss: 0.0119375369977206, Final Batch Loss: 0.0\n",
      "Epoch 2953, Loss: 0.009712687751743942, Final Batch Loss: 0.0\n",
      "Epoch 2954, Loss: 0.05705155187752098, Final Batch Loss: 0.0\n",
      "Epoch 2955, Loss: 0.006059910956537351, Final Batch Loss: 0.0\n",
      "Epoch 2956, Loss: 0.009470281333051389, Final Batch Loss: 5.864924969500862e-05\n",
      "Epoch 2957, Loss: 0.013035536539973691, Final Batch Loss: 0.0\n",
      "Epoch 2958, Loss: 0.06045298266599275, Final Batch Loss: 1.311301275563892e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2959, Loss: 0.014443577034398913, Final Batch Loss: 0.0\n",
      "Epoch 2960, Loss: 0.008812459534965456, Final Batch Loss: 0.0\n",
      "Epoch 2961, Loss: 0.015510979108512402, Final Batch Loss: 0.0\n",
      "Epoch 2962, Loss: 0.018299648421816528, Final Batch Loss: 0.0\n",
      "Epoch 2963, Loss: 0.00568752223622937, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2964, Loss: 0.011170807178132236, Final Batch Loss: 0.0\n",
      "Epoch 2965, Loss: 0.00646863880683668, Final Batch Loss: 0.0\n",
      "Epoch 2966, Loss: 0.012502694031581996, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 2967, Loss: 0.006315171252879281, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2968, Loss: 0.007788281480316073, Final Batch Loss: 0.0\n",
      "Epoch 2969, Loss: 0.0064632735073928416, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2970, Loss: 0.02096801227889955, Final Batch Loss: 0.0\n",
      "Epoch 2971, Loss: 0.007447406649582433, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2972, Loss: 0.007808346505044028, Final Batch Loss: 0.0\n",
      "Epoch 2973, Loss: 0.00979637871205341, Final Batch Loss: 8.630380034446716e-05\n",
      "Epoch 2974, Loss: 0.00721789279486984, Final Batch Loss: 0.0\n",
      "Epoch 2975, Loss: 0.009468729724176228, Final Batch Loss: 0.0\n",
      "Epoch 2976, Loss: 0.016354741441318765, Final Batch Loss: 0.0\n",
      "Epoch 2977, Loss: 0.009737207263242453, Final Batch Loss: 0.0\n",
      "Epoch 2978, Loss: 0.0024806486908346415, Final Batch Loss: 0.0\n",
      "Epoch 2979, Loss: 0.005618345399682312, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2980, Loss: 0.003863501827595428, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2981, Loss: 0.010617291671223938, Final Batch Loss: 0.0\n",
      "Epoch 2982, Loss: 0.010709447778026515, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 2983, Loss: 0.005897431634366512, Final Batch Loss: 0.0\n",
      "Epoch 2984, Loss: 0.006191421038124645, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2985, Loss: 0.007629281841211366, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2986, Loss: 0.015575662313494831, Final Batch Loss: 0.0\n",
      "Epoch 2987, Loss: 0.008719486417248845, Final Batch Loss: 0.0\n",
      "Epoch 2988, Loss: 0.006868678636237746, Final Batch Loss: 0.0\n",
      "Epoch 2989, Loss: 0.015680500771850348, Final Batch Loss: 0.0\n",
      "Epoch 2990, Loss: 0.005508294212631881, Final Batch Loss: 0.0\n",
      "Epoch 2991, Loss: 0.02324243343900889, Final Batch Loss: 0.0\n",
      "Epoch 2992, Loss: 0.008012362290173769, Final Batch Loss: 0.0\n",
      "Epoch 2993, Loss: 0.010157493525184691, Final Batch Loss: 0.0\n",
      "Epoch 2994, Loss: 0.009266331268008798, Final Batch Loss: 0.0\n",
      "Epoch 2995, Loss: 0.0022066941819431918, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2996, Loss: 0.00469750118736556, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 2997, Loss: 0.0038084277184680104, Final Batch Loss: 0.0\n",
      "Epoch 2998, Loss: 0.0027576067950576544, Final Batch Loss: 0.0\n",
      "Epoch 2999, Loss: 0.008697178331203759, Final Batch Loss: 0.0\n",
      "Epoch 3000, Loss: 0.0012493309768046856, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3001, Loss: 0.008301009831484407, Final Batch Loss: 0.0\n",
      "Epoch 3002, Loss: 0.016634533065371215, Final Batch Loss: 0.0\n",
      "Epoch 3003, Loss: 0.01657011921628282, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3004, Loss: 0.019100381759869833, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3005, Loss: 0.003799901402089745, Final Batch Loss: 0.0\n",
      "Epoch 3006, Loss: 0.01875580144678679, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 3007, Loss: 0.012793697867891751, Final Batch Loss: 0.0\n",
      "Epoch 3008, Loss: 0.005796196111532481, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3009, Loss: 0.0024203541106544435, Final Batch Loss: 0.0\n",
      "Epoch 3010, Loss: 0.014026710618054494, Final Batch Loss: 0.01130755990743637\n",
      "Epoch 3011, Loss: 0.008655274345073849, Final Batch Loss: 0.0\n",
      "Epoch 3012, Loss: 0.00945501250680536, Final Batch Loss: 0.0\n",
      "Epoch 3013, Loss: 0.0038514353218488395, Final Batch Loss: 0.0\n",
      "Epoch 3014, Loss: 0.007002247963100672, Final Batch Loss: 0.0\n",
      "Epoch 3015, Loss: 0.016279094372293912, Final Batch Loss: 0.0\n",
      "Epoch 3016, Loss: 0.0172246074071154, Final Batch Loss: 0.0\n",
      "Epoch 3017, Loss: 0.00664415251230821, Final Batch Loss: 0.0\n",
      "Epoch 3018, Loss: 0.0024810520990286022, Final Batch Loss: 0.0\n",
      "Epoch 3019, Loss: 0.02048696042766096, Final Batch Loss: 0.0\n",
      "Epoch 3020, Loss: 0.006498617512988858, Final Batch Loss: 0.0\n",
      "Epoch 3021, Loss: 0.0013200140238041058, Final Batch Loss: 0.0\n",
      "Epoch 3022, Loss: 0.002855722443200648, Final Batch Loss: 0.0\n",
      "Epoch 3023, Loss: 0.006947151952772401, Final Batch Loss: 0.0\n",
      "Epoch 3024, Loss: 0.0011764061616759136, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3025, Loss: 0.021656942088149833, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3026, Loss: 0.0201762465255797, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 3027, Loss: 0.003856231214285799, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 3028, Loss: 0.012829223764128983, Final Batch Loss: 0.0\n",
      "Epoch 3029, Loss: 0.004001916095148772, Final Batch Loss: 0.0\n",
      "Epoch 3030, Loss: 0.009012955852085724, Final Batch Loss: 0.0004312062228564173\n",
      "Epoch 3031, Loss: 0.014238271629437804, Final Batch Loss: 0.0\n",
      "Epoch 3032, Loss: 0.00809940047111013, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 3033, Loss: 0.006546737859025598, Final Batch Loss: 0.0\n",
      "Epoch 3034, Loss: 0.0042180647142231464, Final Batch Loss: 0.0\n",
      "Epoch 3035, Loss: 0.004572697027469985, Final Batch Loss: 0.0\n",
      "Epoch 3036, Loss: 0.0036569520452758297, Final Batch Loss: 0.0\n",
      "Epoch 3037, Loss: 0.0032262519525829703, Final Batch Loss: 0.0\n",
      "Epoch 3038, Loss: 0.0052446005283570685, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3039, Loss: 0.006321259366814047, Final Batch Loss: 0.0\n",
      "Epoch 3040, Loss: 0.006046482419378663, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3041, Loss: 0.006031866476405412, Final Batch Loss: 0.0016551617300137877\n",
      "Epoch 3042, Loss: 0.004657193803723203, Final Batch Loss: 4.410646579344757e-05\n",
      "Epoch 3043, Loss: 0.007856935320887715, Final Batch Loss: 0.0\n",
      "Epoch 3044, Loss: 0.005642659089062363, Final Batch Loss: 0.0\n",
      "Epoch 3045, Loss: 0.008533760206773877, Final Batch Loss: 0.0\n",
      "Epoch 3046, Loss: 0.009126441058469936, Final Batch Loss: 0.0\n",
      "Epoch 3047, Loss: 0.012834414752433077, Final Batch Loss: 0.0\n",
      "Epoch 3048, Loss: 0.002543757000239566, Final Batch Loss: 0.0\n",
      "Epoch 3049, Loss: 0.0020795027726308035, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 3050, Loss: 0.0056866770319174975, Final Batch Loss: 0.0\n",
      "Epoch 3051, Loss: 0.0015966550417942926, Final Batch Loss: 0.0\n",
      "Epoch 3052, Loss: 0.008205697169614723, Final Batch Loss: 0.0\n",
      "Epoch 3053, Loss: 0.011922742589376867, Final Batch Loss: 0.0\n",
      "Epoch 3054, Loss: 0.003556799129000865, Final Batch Loss: 0.0\n",
      "Epoch 3055, Loss: 0.0024257656550616957, Final Batch Loss: 0.0\n",
      "Epoch 3056, Loss: 0.04025153967086226, Final Batch Loss: 0.0\n",
      "Epoch 3057, Loss: 0.015402214310597628, Final Batch Loss: 0.009303785860538483\n",
      "Epoch 3058, Loss: 0.005507373309228569, Final Batch Loss: 0.0\n",
      "Epoch 3059, Loss: 0.0014323616051115096, Final Batch Loss: 0.0\n",
      "Epoch 3060, Loss: 0.0013269479385371596, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3061, Loss: 0.0034172761952504516, Final Batch Loss: 0.0\n",
      "Epoch 3062, Loss: 0.0031965295784175396, Final Batch Loss: 0.0\n",
      "Epoch 3063, Loss: 0.003467770657152869, Final Batch Loss: 0.0\n",
      "Epoch 3064, Loss: 0.007291299814824015, Final Batch Loss: 0.0\n",
      "Epoch 3065, Loss: 0.00318324044928886, Final Batch Loss: 0.0\n",
      "Epoch 3066, Loss: 0.003193011798430234, Final Batch Loss: 0.0\n",
      "Epoch 3067, Loss: 0.0047082321252673864, Final Batch Loss: 0.0\n",
      "Epoch 3068, Loss: 0.014490326619124971, Final Batch Loss: 0.0\n",
      "Epoch 3069, Loss: 0.01927190495186437, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3070, Loss: 0.021973935654386878, Final Batch Loss: 0.0\n",
      "Epoch 3071, Loss: 0.010408725654997397, Final Batch Loss: 0.0\n",
      "Epoch 3072, Loss: 0.004139393684454262, Final Batch Loss: 0.0\n",
      "Epoch 3073, Loss: 0.01115500650482204, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3074, Loss: 0.001526061852928251, Final Batch Loss: 0.0\n",
      "Epoch 3075, Loss: 0.021724873513448983, Final Batch Loss: 0.0\n",
      "Epoch 3076, Loss: 0.023492470500059426, Final Batch Loss: 0.0\n",
      "Epoch 3077, Loss: 0.006550019927090034, Final Batch Loss: 0.0\n",
      "Epoch 3078, Loss: 0.0039960850845091045, Final Batch Loss: 0.0011551857460290194\n",
      "Epoch 3079, Loss: 0.010910290904575959, Final Batch Loss: 0.005007463973015547\n",
      "Epoch 3080, Loss: 0.004251233011018485, Final Batch Loss: 0.0\n",
      "Epoch 3081, Loss: 0.01777891348956473, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3082, Loss: 0.012232427077833563, Final Batch Loss: 0.0\n",
      "Epoch 3083, Loss: 0.0017248577714781277, Final Batch Loss: 0.0\n",
      "Epoch 3084, Loss: 0.010129986334504792, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 3085, Loss: 0.00747890817001462, Final Batch Loss: 0.0\n",
      "Epoch 3086, Loss: 0.0013859706959920004, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3087, Loss: 0.006123960338129564, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3088, Loss: 0.0032283577602356672, Final Batch Loss: 0.0\n",
      "Epoch 3089, Loss: 0.0016103306334116496, Final Batch Loss: 0.0\n",
      "Epoch 3090, Loss: 0.0028104684834033833, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 3091, Loss: 0.011816602462204173, Final Batch Loss: 0.0\n",
      "Epoch 3092, Loss: 0.0027855167281742865, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3093, Loss: 0.0034049112437060103, Final Batch Loss: 0.0\n",
      "Epoch 3094, Loss: 0.004438671428943053, Final Batch Loss: 0.0\n",
      "Epoch 3095, Loss: 0.007722892521996982, Final Batch Loss: 0.0\n",
      "Epoch 3096, Loss: 0.002258117907331325, Final Batch Loss: 0.0\n",
      "Epoch 3097, Loss: 0.012083530818927102, Final Batch Loss: 0.00010680581908673048\n",
      "Epoch 3098, Loss: 0.0032842827822605614, Final Batch Loss: 4.303362584323622e-05\n",
      "Epoch 3099, Loss: 0.01837536704260856, Final Batch Loss: 0.0\n",
      "Epoch 3100, Loss: 0.004268885793862864, Final Batch Loss: 0.0\n",
      "Epoch 3101, Loss: 0.0037622838863171637, Final Batch Loss: 0.0\n",
      "Epoch 3102, Loss: 0.003254433802794665, Final Batch Loss: 0.0\n",
      "Epoch 3103, Loss: 0.005160104396054521, Final Batch Loss: 0.0\n",
      "Epoch 3104, Loss: 0.0037735934602096677, Final Batch Loss: 0.0\n",
      "Epoch 3105, Loss: 0.0009835218625084963, Final Batch Loss: 0.0\n",
      "Epoch 3106, Loss: 0.017199974245158955, Final Batch Loss: 0.0\n",
      "Epoch 3107, Loss: 0.006007016883813776, Final Batch Loss: 0.0\n",
      "Epoch 3108, Loss: 0.0019981751102022827, Final Batch Loss: 0.0\n",
      "Epoch 3109, Loss: 0.007629742147400975, Final Batch Loss: 0.0\n",
      "Epoch 3110, Loss: 0.01759771685465239, Final Batch Loss: 0.0\n",
      "Epoch 3111, Loss: 0.003594724490540102, Final Batch Loss: 0.0\n",
      "Epoch 3112, Loss: 0.0024831885239109397, Final Batch Loss: 0.0\n",
      "Epoch 3113, Loss: 0.0022072529973229393, Final Batch Loss: 0.0\n",
      "Epoch 3114, Loss: 0.008568702229240444, Final Batch Loss: 0.0\n",
      "Epoch 3115, Loss: 0.009365406876895577, Final Batch Loss: 0.0\n",
      "Epoch 3116, Loss: 0.003960364039812703, Final Batch Loss: 0.0\n",
      "Epoch 3117, Loss: 0.002957648160190729, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3118, Loss: 0.0029370474512688816, Final Batch Loss: 0.0\n",
      "Epoch 3119, Loss: 0.004378226993132728, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3120, Loss: 0.0011718550376826897, Final Batch Loss: 0.0\n",
      "Epoch 3121, Loss: 0.008198683790396899, Final Batch Loss: 0.0\n",
      "Epoch 3122, Loss: 0.004534352509836026, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 3123, Loss: 0.002836426720023155, Final Batch Loss: 0.0\n",
      "Epoch 3124, Loss: 0.004330059862695634, Final Batch Loss: 0.0\n",
      "Epoch 3125, Loss: 0.004338916565757245, Final Batch Loss: 0.0\n",
      "Epoch 3126, Loss: 0.008760072630138893, Final Batch Loss: 1.3947389561508317e-05\n",
      "Epoch 3127, Loss: 0.01743819132389035, Final Batch Loss: 0.0\n",
      "Epoch 3128, Loss: 0.029703814965614583, Final Batch Loss: 0.0\n",
      "Epoch 3129, Loss: 0.005475196725456044, Final Batch Loss: 0.0\n",
      "Epoch 3130, Loss: 0.003034448192920536, Final Batch Loss: 0.0\n",
      "Epoch 3131, Loss: 0.002658051234902814, Final Batch Loss: 0.0\n",
      "Epoch 3132, Loss: 0.01143330117338337, Final Batch Loss: 0.0\n",
      "Epoch 3133, Loss: 0.008657418773509562, Final Batch Loss: 0.0\n",
      "Epoch 3134, Loss: 0.008960459163063206, Final Batch Loss: 0.0\n",
      "Epoch 3135, Loss: 0.004352616488176864, Final Batch Loss: 0.00236874190159142\n",
      "Epoch 3136, Loss: 0.008409973001107574, Final Batch Loss: 0.0\n",
      "Epoch 3137, Loss: 0.0012051813828293234, Final Batch Loss: 0.0\n",
      "Epoch 3138, Loss: 0.0035512100876076147, Final Batch Loss: 0.0\n",
      "Epoch 3139, Loss: 0.008574729959946126, Final Batch Loss: 0.006870810873806477\n",
      "Epoch 3140, Loss: 0.004190586420008913, Final Batch Loss: 0.0\n",
      "Epoch 3141, Loss: 0.02350835781544447, Final Batch Loss: 0.010254907421767712\n",
      "Epoch 3142, Loss: 0.026264132204232737, Final Batch Loss: 0.0\n",
      "Epoch 3143, Loss: 0.002745113219127404, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3144, Loss: 0.00615538825513795, Final Batch Loss: 0.0\n",
      "Epoch 3145, Loss: 0.011364827398210764, Final Batch Loss: 0.0\n",
      "Epoch 3146, Loss: 0.005029374558944255, Final Batch Loss: 0.0\n",
      "Epoch 3147, Loss: 0.004101401660591364, Final Batch Loss: 0.0\n",
      "Epoch 3148, Loss: 0.02823281183373183, Final Batch Loss: 0.0\n",
      "Epoch 3149, Loss: 0.000881655651028268, Final Batch Loss: 0.0\n",
      "Epoch 3150, Loss: 0.016404800320742652, Final Batch Loss: 0.0\n",
      "Epoch 3151, Loss: 0.00482030602870509, Final Batch Loss: 0.0\n",
      "Epoch 3152, Loss: 0.0029140103433746845, Final Batch Loss: 0.0\n",
      "Epoch 3153, Loss: 0.0270579494535923, Final Batch Loss: 0.0\n",
      "Epoch 3154, Loss: 0.002438623989291955, Final Batch Loss: 0.0\n",
      "Epoch 3155, Loss: 0.00491041227360256, Final Batch Loss: 0.0\n",
      "Epoch 3156, Loss: 0.013870054041035473, Final Batch Loss: 0.0\n",
      "Epoch 3157, Loss: 0.002568586845882237, Final Batch Loss: 0.0\n",
      "Epoch 3158, Loss: 0.003436228769714944, Final Batch Loss: 0.0\n",
      "Epoch 3159, Loss: 0.0054515513038495556, Final Batch Loss: 0.0004058252670802176\n",
      "Epoch 3160, Loss: 0.00274479847575293, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3161, Loss: 0.017525822622701526, Final Batch Loss: 0.0\n",
      "Epoch 3162, Loss: 0.010107742781997331, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3163, Loss: 0.00789844489190017, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3164, Loss: 0.007241726270876825, Final Batch Loss: 0.00035637227119877934\n",
      "Epoch 3165, Loss: 0.002691020941711031, Final Batch Loss: 0.0\n",
      "Epoch 3166, Loss: 0.008719615693962623, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3167, Loss: 0.002841585548594594, Final Batch Loss: 0.0\n",
      "Epoch 3168, Loss: 0.002731515414780006, Final Batch Loss: 0.0\n",
      "Epoch 3169, Loss: 0.0020375587919261307, Final Batch Loss: 0.0\n",
      "Epoch 3170, Loss: 0.005917689501067969, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3171, Loss: 0.0017286528018303216, Final Batch Loss: 0.0\n",
      "Epoch 3172, Loss: 0.007503345055738464, Final Batch Loss: 0.0\n",
      "Epoch 3173, Loss: 0.0032644414459355175, Final Batch Loss: 0.0\n",
      "Epoch 3174, Loss: 0.010237466034595855, Final Batch Loss: 0.0\n",
      "Epoch 3175, Loss: 0.0019757462723646313, Final Batch Loss: 0.0\n",
      "Epoch 3176, Loss: 0.0034228335716690594, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3177, Loss: 0.004397798365971539, Final Batch Loss: 0.0\n",
      "Epoch 3178, Loss: 0.002942072052974254, Final Batch Loss: 0.0008624648326076567\n",
      "Epoch 3179, Loss: 0.016153891221620142, Final Batch Loss: 0.0\n",
      "Epoch 3180, Loss: 0.002394056944467593, Final Batch Loss: 5.6980417866725475e-05\n",
      "Epoch 3181, Loss: 0.0011106458987342194, Final Batch Loss: 0.0\n",
      "Epoch 3182, Loss: 0.002435155736748129, Final Batch Loss: 0.0\n",
      "Epoch 3183, Loss: 0.006214325490873307, Final Batch Loss: 0.0\n",
      "Epoch 3184, Loss: 0.0034167994272138458, Final Batch Loss: 0.0\n",
      "Epoch 3185, Loss: 0.003943591028473747, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3186, Loss: 0.0012564036005642265, Final Batch Loss: 0.0\n",
      "Epoch 3187, Loss: 0.00781625387389795, Final Batch Loss: 0.0\n",
      "Epoch 3188, Loss: 0.0016339865906047635, Final Batch Loss: 0.0\n",
      "Epoch 3189, Loss: 0.002557483850978315, Final Batch Loss: 0.0\n",
      "Epoch 3190, Loss: 0.0055610496492590755, Final Batch Loss: 0.0\n",
      "Epoch 3191, Loss: 0.006555992731591687, Final Batch Loss: 0.0\n",
      "Epoch 3192, Loss: 0.0033505878964206204, Final Batch Loss: 0.0\n",
      "Epoch 3193, Loss: 0.006158370815683156, Final Batch Loss: 0.0\n",
      "Epoch 3194, Loss: 0.003577710420358926, Final Batch Loss: 0.0\n",
      "Epoch 3195, Loss: 0.0006436855619540438, Final Batch Loss: 0.0\n",
      "Epoch 3196, Loss: 0.002493415551725775, Final Batch Loss: 0.0\n",
      "Epoch 3197, Loss: 0.014625827607233077, Final Batch Loss: 0.0\n",
      "Epoch 3198, Loss: 0.0010638517851475626, Final Batch Loss: 0.0\n",
      "Epoch 3199, Loss: 0.001984927133889869, Final Batch Loss: 0.0\n",
      "Epoch 3200, Loss: 0.004101566562894732, Final Batch Loss: 0.0\n",
      "Epoch 3201, Loss: 0.0016475754669045273, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3202, Loss: 0.0009896733354253229, Final Batch Loss: 0.0\n",
      "Epoch 3203, Loss: 0.00871773122344166, Final Batch Loss: 0.0\n",
      "Epoch 3204, Loss: 0.0028224081615917385, Final Batch Loss: 0.0\n",
      "Epoch 3205, Loss: 0.0050608884848770685, Final Batch Loss: 0.0\n",
      "Epoch 3206, Loss: 0.004053357697557658, Final Batch Loss: 0.0\n",
      "Epoch 3207, Loss: 0.0007788351067574695, Final Batch Loss: 0.0\n",
      "Epoch 3208, Loss: 0.0013646546467427356, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3209, Loss: 0.0021598238236038014, Final Batch Loss: 0.0004256058018654585\n",
      "Epoch 3210, Loss: 0.020800253303605132, Final Batch Loss: 0.017746824771165848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3211, Loss: 0.010308721801266074, Final Batch Loss: 0.0\n",
      "Epoch 3212, Loss: 0.03323908356833272, Final Batch Loss: 9.262132516596466e-05\n",
      "Epoch 3213, Loss: 0.0019314260462124366, Final Batch Loss: 0.0\n",
      "Epoch 3214, Loss: 0.018489889042939467, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3215, Loss: 0.002205102704458284, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3216, Loss: 0.009293660783441737, Final Batch Loss: 0.0\n",
      "Epoch 3217, Loss: 0.0010020312747656135, Final Batch Loss: 0.0\n",
      "Epoch 3218, Loss: 0.04271509806858376, Final Batch Loss: 0.0\n",
      "Epoch 3219, Loss: 0.0044019371844115085, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3220, Loss: 0.0030733565072296187, Final Batch Loss: 0.0\n",
      "Epoch 3221, Loss: 0.002002623881708132, Final Batch Loss: 0.0\n",
      "Epoch 3222, Loss: 0.002325942914467305, Final Batch Loss: 0.0\n",
      "Epoch 3223, Loss: 0.004820751812076196, Final Batch Loss: 0.0\n",
      "Epoch 3224, Loss: 0.001960172172402963, Final Batch Loss: 0.0\n",
      "Epoch 3225, Loss: 0.0046748212380407494, Final Batch Loss: 1.3947389561508317e-05\n",
      "Epoch 3226, Loss: 0.0021624961516408803, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3227, Loss: 0.0012537235161289573, Final Batch Loss: 0.0\n",
      "Epoch 3228, Loss: 0.0014254548145800072, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3229, Loss: 0.0015289351576939225, Final Batch Loss: 0.0\n",
      "Epoch 3230, Loss: 0.004564421615214087, Final Batch Loss: 0.0\n",
      "Epoch 3231, Loss: 0.0011900558165507391, Final Batch Loss: 0.0\n",
      "Epoch 3232, Loss: 0.0010481457425157714, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3233, Loss: 0.0013384565972955897, Final Batch Loss: 0.0\n",
      "Epoch 3234, Loss: 0.0017018588255268696, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3235, Loss: 0.009249815600924194, Final Batch Loss: 0.00182819040492177\n",
      "Epoch 3236, Loss: 0.0015782341652013088, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3237, Loss: 0.0008571605430915952, Final Batch Loss: 0.0\n",
      "Epoch 3238, Loss: 0.0009144918876700103, Final Batch Loss: 3.194758028257638e-05\n",
      "Epoch 3239, Loss: 0.004849552526138723, Final Batch Loss: 0.0\n",
      "Epoch 3240, Loss: 0.0010697926845750771, Final Batch Loss: 0.0\n",
      "Epoch 3241, Loss: 0.000873092234513706, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3242, Loss: 0.004341034044045955, Final Batch Loss: 0.0\n",
      "Epoch 3243, Loss: 0.01094662316609174, Final Batch Loss: 0.0\n",
      "Epoch 3244, Loss: 0.0006977968660066836, Final Batch Loss: 0.0\n",
      "Epoch 3245, Loss: 0.007951935927849263, Final Batch Loss: 0.0\n",
      "Epoch 3246, Loss: 0.0014435175398830324, Final Batch Loss: 0.0\n",
      "Epoch 3247, Loss: 0.0058640211063902825, Final Batch Loss: 0.0\n",
      "Epoch 3248, Loss: 0.00186061357089784, Final Batch Loss: 0.0\n",
      "Epoch 3249, Loss: 0.0014803678495809436, Final Batch Loss: 0.0\n",
      "Epoch 3250, Loss: 0.0038134084243210964, Final Batch Loss: 0.0\n",
      "Epoch 3251, Loss: 0.0009505938796792179, Final Batch Loss: 0.0\n",
      "Epoch 3252, Loss: 0.00777639914304018, Final Batch Loss: 0.0\n",
      "Epoch 3253, Loss: 0.08288823913426313, Final Batch Loss: 0.00033861625706776977\n",
      "Epoch 3254, Loss: 0.0015871085633989424, Final Batch Loss: 0.0\n",
      "Epoch 3255, Loss: 0.0016776623742771335, Final Batch Loss: 0.0\n",
      "Epoch 3256, Loss: 0.00029997802630532533, Final Batch Loss: 4.5298504119273275e-05\n",
      "Epoch 3257, Loss: 0.004783361713634804, Final Batch Loss: 0.0\n",
      "Epoch 3258, Loss: 0.003980657740612514, Final Batch Loss: 0.0\n",
      "Epoch 3259, Loss: 0.0029632446176037774, Final Batch Loss: 8.4638240878121e-06\n",
      "Epoch 3260, Loss: 0.00648000834917184, Final Batch Loss: 0.0\n",
      "Epoch 3261, Loss: 0.0030907295586075634, Final Batch Loss: 0.0\n",
      "Epoch 3262, Loss: 0.002775882720015943, Final Batch Loss: 0.0\n",
      "Epoch 3263, Loss: 0.0022746779723092914, Final Batch Loss: 0.0\n",
      "Epoch 3264, Loss: 0.008722970029339194, Final Batch Loss: 0.0\n",
      "Epoch 3265, Loss: 0.0016755499527789652, Final Batch Loss: 0.0\n",
      "Epoch 3266, Loss: 0.007354926957646057, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3267, Loss: 0.005716700862876678, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3268, Loss: 0.0013296701945364475, Final Batch Loss: 0.0\n",
      "Epoch 3269, Loss: 0.002026619768003002, Final Batch Loss: 0.0\n",
      "Epoch 3270, Loss: 0.0017837196282926016, Final Batch Loss: 0.0\n",
      "Epoch 3271, Loss: 0.001991924364119768, Final Batch Loss: 0.0009787060553207994\n",
      "Epoch 3272, Loss: 0.021547181650930725, Final Batch Loss: 1.1205610462639015e-05\n",
      "Epoch 3273, Loss: 0.002240759167733586, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3274, Loss: 0.0015312636096496135, Final Batch Loss: 0.0\n",
      "Epoch 3275, Loss: 0.004086117201950401, Final Batch Loss: 0.003177952254191041\n",
      "Epoch 3276, Loss: 0.0034250413737026975, Final Batch Loss: 0.0\n",
      "Epoch 3277, Loss: 0.026315625305869617, Final Batch Loss: 0.0\n",
      "Epoch 3278, Loss: 0.004249721736414358, Final Batch Loss: 0.0\n",
      "Epoch 3279, Loss: 0.005303384212311357, Final Batch Loss: 0.0\n",
      "Epoch 3280, Loss: 0.0052156332531012595, Final Batch Loss: 0.0\n",
      "Epoch 3281, Loss: 0.015404646983199655, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3282, Loss: 0.014296361361630261, Final Batch Loss: 0.0\n",
      "Epoch 3283, Loss: 0.0016082542133517563, Final Batch Loss: 0.0\n",
      "Epoch 3284, Loss: 0.01583204796769877, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3285, Loss: 0.0016961585206445307, Final Batch Loss: 0.0\n",
      "Epoch 3286, Loss: 0.006343042536173016, Final Batch Loss: 0.0\n",
      "Epoch 3287, Loss: 0.0018494112882763147, Final Batch Loss: 0.0\n",
      "Epoch 3288, Loss: 0.0029182779253460467, Final Batch Loss: 0.0\n",
      "Epoch 3289, Loss: 0.0020604489545803517, Final Batch Loss: 0.0\n",
      "Epoch 3290, Loss: 0.010274785512592643, Final Batch Loss: 0.0\n",
      "Epoch 3291, Loss: 0.008103179759928025, Final Batch Loss: 0.0\n",
      "Epoch 3292, Loss: 0.0020535088094675302, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3293, Loss: 0.0036902731226291507, Final Batch Loss: 0.0\n",
      "Epoch 3294, Loss: 0.0015970313470461406, Final Batch Loss: 0.0\n",
      "Epoch 3295, Loss: 0.004173727589659393, Final Batch Loss: 0.0\n",
      "Epoch 3296, Loss: 0.0022011802211636677, Final Batch Loss: 0.0\n",
      "Epoch 3297, Loss: 0.0025870594690786675, Final Batch Loss: 8.582700684200972e-05\n",
      "Epoch 3298, Loss: 0.003275487913924735, Final Batch Loss: 0.0\n",
      "Epoch 3299, Loss: 0.00378977309082984, Final Batch Loss: 4.51792984677013e-05\n",
      "Epoch 3300, Loss: 0.0030822045810054988, Final Batch Loss: 0.0\n",
      "Epoch 3301, Loss: 0.012427550727352354, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 3302, Loss: 0.0008922635388444178, Final Batch Loss: 0.0\n",
      "Epoch 3303, Loss: 0.004999213284463622, Final Batch Loss: 0.0\n",
      "Epoch 3304, Loss: 0.004531700906227343, Final Batch Loss: 0.0\n",
      "Epoch 3305, Loss: 0.004075523349456489, Final Batch Loss: 0.0\n",
      "Epoch 3306, Loss: 0.00425960952998139, Final Batch Loss: 0.0\n",
      "Epoch 3307, Loss: 0.004539715693681501, Final Batch Loss: 0.0\n",
      "Epoch 3308, Loss: 0.0010695455857785419, Final Batch Loss: 0.00013815402053296566\n",
      "Epoch 3309, Loss: 0.0026594762894092128, Final Batch Loss: 0.0\n",
      "Epoch 3310, Loss: 0.026210001902654767, Final Batch Loss: 0.0\n",
      "Epoch 3311, Loss: 0.0009812000789679587, Final Batch Loss: 0.0\n",
      "Epoch 3312, Loss: 0.0016810400120448321, Final Batch Loss: 0.0\n",
      "Epoch 3313, Loss: 0.0016926531752687879, Final Batch Loss: 2.253030106658116e-05\n",
      "Epoch 3314, Loss: 0.0059988864086335525, Final Batch Loss: 0.0\n",
      "Epoch 3315, Loss: 0.001535602415970061, Final Batch Loss: 0.0\n",
      "Epoch 3316, Loss: 0.0038367238303180784, Final Batch Loss: 0.0\n",
      "Epoch 3317, Loss: 0.0031394029210787266, Final Batch Loss: 0.0\n",
      "Epoch 3318, Loss: 0.008866753123584203, Final Batch Loss: 0.0\n",
      "Epoch 3319, Loss: 0.0031900550675345585, Final Batch Loss: 0.0\n",
      "Epoch 3320, Loss: 0.0024335260823136196, Final Batch Loss: 0.0\n",
      "Epoch 3321, Loss: 0.003985454372013919, Final Batch Loss: 0.0\n",
      "Epoch 3322, Loss: 0.002744536119280383, Final Batch Loss: 0.0\n",
      "Epoch 3323, Loss: 0.0009675999463070184, Final Batch Loss: 0.0\n",
      "Epoch 3324, Loss: 0.00855123240029343, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3325, Loss: 0.010230904270429164, Final Batch Loss: 0.0055229454301297665\n",
      "Epoch 3326, Loss: 0.006686707914923318, Final Batch Loss: 0.0\n",
      "Epoch 3327, Loss: 0.002165437035728246, Final Batch Loss: 0.0\n",
      "Epoch 3328, Loss: 0.014818820665823296, Final Batch Loss: 0.0\n",
      "Epoch 3329, Loss: 0.0013946674334874842, Final Batch Loss: 0.0\n",
      "Epoch 3330, Loss: 0.21299874724354595, Final Batch Loss: 0.20722515881061554\n",
      "Epoch 3331, Loss: 0.034249842778081074, Final Batch Loss: 8.916457591112703e-05\n",
      "Epoch 3332, Loss: 0.07554799318313599, Final Batch Loss: 0.0\n",
      "Epoch 3333, Loss: 0.08015431785315741, Final Batch Loss: 0.0\n",
      "Epoch 3334, Loss: 0.05902078108192654, Final Batch Loss: 0.0\n",
      "Epoch 3335, Loss: 0.07093314526719041, Final Batch Loss: 0.0\n",
      "Epoch 3336, Loss: 0.025945840276108356, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3337, Loss: 0.01796744577586651, Final Batch Loss: 0.0\n",
      "Epoch 3338, Loss: 0.03520812140777707, Final Batch Loss: 0.0\n",
      "Epoch 3339, Loss: 0.04341672034934163, Final Batch Loss: 0.0\n",
      "Epoch 3340, Loss: 0.0006085261702537537, Final Batch Loss: 0.0\n",
      "Epoch 3341, Loss: 0.0130638932751026, Final Batch Loss: 0.0\n",
      "Epoch 3342, Loss: 0.014819916803389788, Final Batch Loss: 0.0\n",
      "Epoch 3343, Loss: 0.03932262324451585, Final Batch Loss: 2.7894584491150454e-05\n",
      "Epoch 3344, Loss: 0.005677424880559556, Final Batch Loss: 0.0\n",
      "Epoch 3345, Loss: 0.022011909731190826, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 3346, Loss: 0.002942226521554403, Final Batch Loss: 0.0\n",
      "Epoch 3347, Loss: 0.0030251500866143033, Final Batch Loss: 0.0\n",
      "Epoch 3348, Loss: 0.001065074946382083, Final Batch Loss: 0.0\n",
      "Epoch 3349, Loss: 0.0014370569115271792, Final Batch Loss: 0.0\n",
      "Epoch 3350, Loss: 0.020185460394714028, Final Batch Loss: 0.0\n",
      "Epoch 3351, Loss: 0.0007280658282979857, Final Batch Loss: 0.0\n",
      "Epoch 3352, Loss: 0.0018741627573035657, Final Batch Loss: 0.0\n",
      "Epoch 3353, Loss: 0.029427902161842212, Final Batch Loss: 0.0\n",
      "Epoch 3354, Loss: 0.0013054404553258792, Final Batch Loss: 0.0\n",
      "Epoch 3355, Loss: 0.07743749755900353, Final Batch Loss: 0.0\n",
      "Epoch 3356, Loss: 0.001462323525629472, Final Batch Loss: 0.0\n",
      "Epoch 3357, Loss: 0.06078408231041976, Final Batch Loss: 0.05983927100896835\n",
      "Epoch 3358, Loss: 2.7690486645078636, Final Batch Loss: 2.7677628993988037\n",
      "Epoch 3359, Loss: 0.027593899983912706, Final Batch Loss: 0.0\n",
      "Epoch 3360, Loss: 0.1600032849235049, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3361, Loss: 0.1577630378305912, Final Batch Loss: 0.0\n",
      "Epoch 3362, Loss: 0.06653425871627405, Final Batch Loss: 0.0\n",
      "Epoch 3363, Loss: 0.03929822600912303, Final Batch Loss: 0.0\n",
      "Epoch 3364, Loss: 0.03777719708159566, Final Batch Loss: 0.0\n",
      "Epoch 3365, Loss: 0.046198390424251556, Final Batch Loss: 0.0\n",
      "Epoch 3366, Loss: 0.058776542544357824, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3367, Loss: 0.02435193315614015, Final Batch Loss: 0.001116844010539353\n",
      "Epoch 3368, Loss: 0.016825033468194306, Final Batch Loss: 0.0\n",
      "Epoch 3369, Loss: 0.012022683628742925, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3370, Loss: 0.010531782463658601, Final Batch Loss: 0.0\n",
      "Epoch 3371, Loss: 0.006864579278044403, Final Batch Loss: 0.0\n",
      "Epoch 3372, Loss: 0.023570887016830966, Final Batch Loss: 5.757642793469131e-05\n",
      "Epoch 3373, Loss: 0.01322757313027978, Final Batch Loss: 0.0\n",
      "Epoch 3374, Loss: 0.00844898249488324, Final Batch Loss: 0.0\n",
      "Epoch 3375, Loss: 0.1532760518603027, Final Batch Loss: 0.1497138887643814\n",
      "Epoch 3376, Loss: 0.008055919548496604, Final Batch Loss: 0.0\n",
      "Epoch 3377, Loss: 0.1286831030374742, Final Batch Loss: 8.868777513271198e-05\n",
      "Epoch 3378, Loss: 0.16708065569309838, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3379, Loss: 0.03925782651640475, Final Batch Loss: 0.0\n",
      "Epoch 3380, Loss: 0.04045282071456313, Final Batch Loss: 0.0\n",
      "Epoch 3381, Loss: 0.035854844260029495, Final Batch Loss: 0.0\n",
      "Epoch 3382, Loss: 0.04443567153066397, Final Batch Loss: 0.0\n",
      "Epoch 3383, Loss: 0.01331909082364291, Final Batch Loss: 0.0\n",
      "Epoch 3384, Loss: 0.01759955915622413, Final Batch Loss: 0.0\n",
      "Epoch 3385, Loss: 0.0396758858114481, Final Batch Loss: 0.0\n",
      "Epoch 3386, Loss: 0.024282530415803194, Final Batch Loss: 0.0\n",
      "Epoch 3387, Loss: 0.014771857880987227, Final Batch Loss: 0.0\n",
      "Epoch 3388, Loss: 0.005267158965580165, Final Batch Loss: 0.0\n",
      "Epoch 3389, Loss: 0.010152827948331833, Final Batch Loss: 0.0\n",
      "Epoch 3390, Loss: 0.012167115812189877, Final Batch Loss: 0.0\n",
      "Epoch 3391, Loss: 0.004459357471205294, Final Batch Loss: 0.0\n",
      "Epoch 3392, Loss: 0.006117850774899125, Final Batch Loss: 0.0\n",
      "Epoch 3393, Loss: 0.006939236734979204, Final Batch Loss: 2.062299427052494e-05\n",
      "Epoch 3394, Loss: 0.018488135188810872, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3395, Loss: 0.005172159697394818, Final Batch Loss: 0.0\n",
      "Epoch 3396, Loss: 0.007203740417025983, Final Batch Loss: 0.0\n",
      "Epoch 3397, Loss: 0.005648342426866293, Final Batch Loss: 0.0\n",
      "Epoch 3398, Loss: 0.019018009887076914, Final Batch Loss: 0.0\n",
      "Epoch 3399, Loss: 0.003742134606000036, Final Batch Loss: 0.0\n",
      "Epoch 3400, Loss: 0.016994362231343985, Final Batch Loss: 0.0\n",
      "Epoch 3401, Loss: 0.0178970646811365, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3402, Loss: 0.0044671862706309184, Final Batch Loss: 0.0\n",
      "Epoch 3403, Loss: 0.013108241487543637, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3404, Loss: 0.01498295390047133, Final Batch Loss: 0.0\n",
      "Epoch 3405, Loss: 0.004451896180398762, Final Batch Loss: 0.0\n",
      "Epoch 3406, Loss: 0.0033953488018596545, Final Batch Loss: 0.0\n",
      "Epoch 3407, Loss: 0.0027542275784071535, Final Batch Loss: 0.0\n",
      "Epoch 3408, Loss: 0.005183528061024845, Final Batch Loss: 0.0\n",
      "Epoch 3409, Loss: 0.007287250191438943, Final Batch Loss: 0.0\n",
      "Epoch 3410, Loss: 0.005013923859223723, Final Batch Loss: 0.0\n",
      "Epoch 3411, Loss: 0.007801637751981616, Final Batch Loss: 0.0\n",
      "Epoch 3412, Loss: 0.004519944777712226, Final Batch Loss: 0.0\n",
      "Epoch 3413, Loss: 0.007323218003875809, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 3414, Loss: 0.007945516670588404, Final Batch Loss: 0.0\n",
      "Epoch 3415, Loss: 0.005802589701488614, Final Batch Loss: 0.0\n",
      "Epoch 3416, Loss: 0.004301136956200935, Final Batch Loss: 2.288792165927589e-05\n",
      "Epoch 3417, Loss: 0.008658623296469159, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 3418, Loss: 0.004545906209386885, Final Batch Loss: 0.0\n",
      "Epoch 3419, Loss: 0.006902688939590007, Final Batch Loss: 0.0\n",
      "Epoch 3420, Loss: 0.005344262521248311, Final Batch Loss: 0.00014029949670657516\n",
      "Epoch 3421, Loss: 0.023262389993760735, Final Batch Loss: 0.0\n",
      "Epoch 3422, Loss: 0.006751544540748, Final Batch Loss: 0.0\n",
      "Epoch 3423, Loss: 0.008578248045523651, Final Batch Loss: 0.0\n",
      "Epoch 3424, Loss: 0.010392571333795786, Final Batch Loss: 0.0\n",
      "Epoch 3425, Loss: 0.004396195006847847, Final Batch Loss: 7.843663479434326e-05\n",
      "Epoch 3426, Loss: 0.010897940723225474, Final Batch Loss: 0.0\n",
      "Epoch 3427, Loss: 0.015528812538832426, Final Batch Loss: 0.0\n",
      "Epoch 3428, Loss: 0.011109982151538134, Final Batch Loss: 0.0\n",
      "Epoch 3429, Loss: 0.007808308611828352, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3430, Loss: 0.017686355626203465, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3431, Loss: 0.008900868648197502, Final Batch Loss: 0.0\n",
      "Epoch 3432, Loss: 0.005138549895491451, Final Batch Loss: 0.0\n",
      "Epoch 3433, Loss: 0.004449931759154424, Final Batch Loss: 0.0\n",
      "Epoch 3434, Loss: 0.0031280111870728433, Final Batch Loss: 0.0\n",
      "Epoch 3435, Loss: 0.012744544685119763, Final Batch Loss: 0.0\n",
      "Epoch 3436, Loss: 0.003959638706874102, Final Batch Loss: 0.0\n",
      "Epoch 3437, Loss: 0.0035245625185780227, Final Batch Loss: 0.0\n",
      "Epoch 3438, Loss: 0.009221757762134075, Final Batch Loss: 0.0\n",
      "Epoch 3439, Loss: 0.003987314994446933, Final Batch Loss: 0.0\n",
      "Epoch 3440, Loss: 0.010038411244750023, Final Batch Loss: 0.0\n",
      "Epoch 3441, Loss: 0.003464953406364657, Final Batch Loss: 0.0\n",
      "Epoch 3442, Loss: 0.01226082377252169, Final Batch Loss: 0.0002615109842736274\n",
      "Epoch 3443, Loss: 0.0032856104080565274, Final Batch Loss: 0.0\n",
      "Epoch 3444, Loss: 0.003989716060459614, Final Batch Loss: 0.0\n",
      "Epoch 3445, Loss: 0.0034309871844016016, Final Batch Loss: 0.0\n",
      "Epoch 3446, Loss: 0.005453090823266393, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3447, Loss: 0.015695828013122082, Final Batch Loss: 0.0\n",
      "Epoch 3448, Loss: 0.0031535993330180645, Final Batch Loss: 0.0\n",
      "Epoch 3449, Loss: 0.001190119088278152, Final Batch Loss: 0.0\n",
      "Epoch 3450, Loss: 0.0029510559397749603, Final Batch Loss: 0.0\n",
      "Epoch 3451, Loss: 0.009095916582737118, Final Batch Loss: 0.0\n",
      "Epoch 3452, Loss: 0.003447385912295431, Final Batch Loss: 0.0\n",
      "Epoch 3453, Loss: 0.009192991070449352, Final Batch Loss: 0.0\n",
      "Epoch 3454, Loss: 0.004105156403966248, Final Batch Loss: 0.0\n",
      "Epoch 3455, Loss: 0.004003623616881669, Final Batch Loss: 0.0\n",
      "Epoch 3456, Loss: 0.00511152227409184, Final Batch Loss: 0.0\n",
      "Epoch 3457, Loss: 0.007486974122002721, Final Batch Loss: 0.0\n",
      "Epoch 3458, Loss: 0.009858404519036412, Final Batch Loss: 0.0\n",
      "Epoch 3459, Loss: 0.00519879418425262, Final Batch Loss: 0.0\n",
      "Epoch 3460, Loss: 0.009745378454681486, Final Batch Loss: 0.0\n",
      "Epoch 3461, Loss: 0.024549405381542044, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3462, Loss: 0.005964120355201885, Final Batch Loss: 0.0\n",
      "Epoch 3463, Loss: 0.003915540408343077, Final Batch Loss: 0.0\n",
      "Epoch 3464, Loss: 0.002790621714666486, Final Batch Loss: 0.0\n",
      "Epoch 3465, Loss: 0.002213870990090072, Final Batch Loss: 0.0\n",
      "Epoch 3466, Loss: 0.004796535532705093, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3467, Loss: 0.002664311963599175, Final Batch Loss: 0.0\n",
      "Epoch 3468, Loss: 0.009602832462405786, Final Batch Loss: 0.0\n",
      "Epoch 3469, Loss: 0.010442904254887253, Final Batch Loss: 0.0\n",
      "Epoch 3470, Loss: 0.003331465064547956, Final Batch Loss: 0.0\n",
      "Epoch 3471, Loss: 0.0023224664903409575, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3472, Loss: 0.01639377785556917, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3473, Loss: 0.0028749829798471183, Final Batch Loss: 0.0\n",
      "Epoch 3474, Loss: 0.0042953912052325904, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3475, Loss: 0.006014788144966587, Final Batch Loss: 0.0\n",
      "Epoch 3476, Loss: 0.0029959578823763877, Final Batch Loss: 0.0\n",
      "Epoch 3477, Loss: 0.004594655940309167, Final Batch Loss: 0.0\n",
      "Epoch 3478, Loss: 0.018891781714046374, Final Batch Loss: 0.0\n",
      "Epoch 3479, Loss: 0.0047237821272574365, Final Batch Loss: 0.0010116941994056106\n",
      "Epoch 3480, Loss: 0.0021266364200300814, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3481, Loss: 0.0012264821853023022, Final Batch Loss: 0.0\n",
      "Epoch 3482, Loss: 0.0073103264321616734, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 3483, Loss: 0.0028970932471565902, Final Batch Loss: 9.095255518332124e-05\n",
      "Epoch 3484, Loss: 0.004888375871814787, Final Batch Loss: 0.0\n",
      "Epoch 3485, Loss: 0.00358209217665717, Final Batch Loss: 0.0\n",
      "Epoch 3486, Loss: 0.017027018155204132, Final Batch Loss: 0.0\n",
      "Epoch 3487, Loss: 0.0013126438113886252, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3488, Loss: 0.006283948780037463, Final Batch Loss: 0.0\n",
      "Epoch 3489, Loss: 0.00669190613552928, Final Batch Loss: 0.0\n",
      "Epoch 3490, Loss: 0.003983620612416416, Final Batch Loss: 0.0\n",
      "Epoch 3491, Loss: 0.008554426312912256, Final Batch Loss: 0.0\n",
      "Epoch 3492, Loss: 0.0036110683855667958, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3493, Loss: 0.003153589670546353, Final Batch Loss: 0.0\n",
      "Epoch 3494, Loss: 0.00481758828391321, Final Batch Loss: 0.0\n",
      "Epoch 3495, Loss: 0.0039357400382868946, Final Batch Loss: 0.0\n",
      "Epoch 3496, Loss: 0.02032710425555706, Final Batch Loss: 0.0\n",
      "Epoch 3497, Loss: 0.0028340973949525505, Final Batch Loss: 0.0\n",
      "Epoch 3498, Loss: 0.0027867502562912705, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 3499, Loss: 0.003131308709271252, Final Batch Loss: 0.0\n",
      "Epoch 3500, Loss: 0.002632686519064009, Final Batch Loss: 0.0\n",
      "Epoch 3501, Loss: 0.011213399411644787, Final Batch Loss: 0.0\n",
      "Epoch 3502, Loss: 0.023917524085845798, Final Batch Loss: 0.0\n",
      "Epoch 3503, Loss: 0.0071417674189433455, Final Batch Loss: 0.0\n",
      "Epoch 3504, Loss: 0.015306973131373525, Final Batch Loss: 0.0\n",
      "Epoch 3505, Loss: 0.0019935450691264123, Final Batch Loss: 0.0\n",
      "Epoch 3506, Loss: 0.011999097769148648, Final Batch Loss: 0.009458609856665134\n",
      "Epoch 3507, Loss: 0.004156461247475818, Final Batch Loss: 0.0\n",
      "Epoch 3508, Loss: 0.004708926877349029, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3509, Loss: 0.0022231118637137115, Final Batch Loss: 0.0\n",
      "Epoch 3510, Loss: 0.004881869710516185, Final Batch Loss: 0.0\n",
      "Epoch 3511, Loss: 0.003525167849140587, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3512, Loss: 0.005564542661886662, Final Batch Loss: 0.0\n",
      "Epoch 3513, Loss: 0.001218884004629217, Final Batch Loss: 0.0\n",
      "Epoch 3514, Loss: 0.007665436249226332, Final Batch Loss: 0.0\n",
      "Epoch 3515, Loss: 0.0036548144635162316, Final Batch Loss: 0.0\n",
      "Epoch 3516, Loss: 0.0027137274155393243, Final Batch Loss: 0.00021550717065110803\n",
      "Epoch 3517, Loss: 0.0048377970815352, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3518, Loss: 0.003487575711886848, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3519, Loss: 0.0013875557342544198, Final Batch Loss: 0.0\n",
      "Epoch 3520, Loss: 0.004208516445942223, Final Batch Loss: 0.0\n",
      "Epoch 3521, Loss: 0.00271849989076145, Final Batch Loss: 0.0\n",
      "Epoch 3522, Loss: 0.005641392315737903, Final Batch Loss: 0.0\n",
      "Epoch 3523, Loss: 0.0021403814616860473, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 3524, Loss: 0.005324838013621047, Final Batch Loss: 0.0\n",
      "Epoch 3525, Loss: 0.0021092339302413166, Final Batch Loss: 0.0\n",
      "Epoch 3526, Loss: 0.006045057496521622, Final Batch Loss: 0.0\n",
      "Epoch 3527, Loss: 0.0016380816523451358, Final Batch Loss: 0.0\n",
      "Epoch 3528, Loss: 0.0017486940846538346, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 3529, Loss: 0.0068136597401462495, Final Batch Loss: 0.0\n",
      "Epoch 3530, Loss: 0.008657820046209963, Final Batch Loss: 3.0874729418428615e-05\n",
      "Epoch 3531, Loss: 0.013377959839999676, Final Batch Loss: 0.0\n",
      "Epoch 3532, Loss: 0.002675468703273509, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 3533, Loss: 0.003440644999500364, Final Batch Loss: 0.0\n",
      "Epoch 3534, Loss: 0.0030880858685122803, Final Batch Loss: 0.0\n",
      "Epoch 3535, Loss: 0.0033151257666759193, Final Batch Loss: 0.0\n",
      "Epoch 3536, Loss: 0.008970516755539393, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3537, Loss: 0.002966730622574687, Final Batch Loss: 0.0\n",
      "Epoch 3538, Loss: 0.02159924643638078, Final Batch Loss: 0.0\n",
      "Epoch 3539, Loss: 0.0036036881210748106, Final Batch Loss: 0.0\n",
      "Epoch 3540, Loss: 0.0024518369464203715, Final Batch Loss: 0.0\n",
      "Epoch 3541, Loss: 0.0027342966059222817, Final Batch Loss: 0.0\n",
      "Epoch 3542, Loss: 0.002882781220250763, Final Batch Loss: 0.0\n",
      "Epoch 3543, Loss: 0.0019157917122356594, Final Batch Loss: 0.0\n",
      "Epoch 3544, Loss: 0.0020066187862539664, Final Batch Loss: 9.63164638960734e-05\n",
      "Epoch 3545, Loss: 0.005530663300305605, Final Batch Loss: 0.0\n",
      "Epoch 3546, Loss: 0.00601448886959588, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3547, Loss: 0.0021740866359323263, Final Batch Loss: 0.0\n",
      "Epoch 3548, Loss: 0.008809135586488992, Final Batch Loss: 0.0\n",
      "Epoch 3549, Loss: 0.003687619770062156, Final Batch Loss: 0.0\n",
      "Epoch 3550, Loss: 0.0030421410920098424, Final Batch Loss: 0.0\n",
      "Epoch 3551, Loss: 0.0010956272672046907, Final Batch Loss: 0.0\n",
      "Epoch 3552, Loss: 0.012327263655606657, Final Batch Loss: 0.0\n",
      "Epoch 3553, Loss: 0.03920139017282054, Final Batch Loss: 0.0\n",
      "Epoch 3554, Loss: 0.003958440478982084, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 3555, Loss: 0.0038664270541630685, Final Batch Loss: 0.0\n",
      "Epoch 3556, Loss: 0.004731896915473044, Final Batch Loss: 0.0\n",
      "Epoch 3557, Loss: 0.0021346539142541587, Final Batch Loss: 0.0\n",
      "Epoch 3558, Loss: 0.05132038611917977, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3559, Loss: 0.007857809105189517, Final Batch Loss: 0.0\n",
      "Epoch 3560, Loss: 0.004625621120794676, Final Batch Loss: 9.572047565598041e-05\n",
      "Epoch 3561, Loss: 0.011063472483897385, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3562, Loss: 0.027035557432100177, Final Batch Loss: 0.0\n",
      "Epoch 3563, Loss: 0.0016237329909927212, Final Batch Loss: 0.0\n",
      "Epoch 3564, Loss: 0.0031649306911276653, Final Batch Loss: 0.0\n",
      "Epoch 3565, Loss: 0.002399861958110705, Final Batch Loss: 0.0004109491710551083\n",
      "Epoch 3566, Loss: 0.004109148925635964, Final Batch Loss: 0.0\n",
      "Epoch 3567, Loss: 0.012406353329424746, Final Batch Loss: 0.0\n",
      "Epoch 3568, Loss: 0.0008383670210605487, Final Batch Loss: 0.0\n",
      "Epoch 3569, Loss: 0.0038127300249470863, Final Batch Loss: 0.0\n",
      "Epoch 3570, Loss: 0.010739303004811518, Final Batch Loss: 0.008983196690678596\n",
      "Epoch 3571, Loss: 0.0030315246112877503, Final Batch Loss: 0.00023135847004596144\n",
      "Epoch 3572, Loss: 0.004452949680853635, Final Batch Loss: 0.0011749514378607273\n",
      "Epoch 3573, Loss: 0.01015815741266124, Final Batch Loss: 0.0\n",
      "Epoch 3574, Loss: 0.0027582613479353313, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 3575, Loss: 0.0025436830101170926, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3576, Loss: 0.01189653982874006, Final Batch Loss: 0.0\n",
      "Epoch 3577, Loss: 0.002717419061809778, Final Batch Loss: 0.0\n",
      "Epoch 3578, Loss: 0.016949037642916664, Final Batch Loss: 0.0\n",
      "Epoch 3579, Loss: 0.0014142856380132685, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3580, Loss: 0.0009751517500262707, Final Batch Loss: 0.0\n",
      "Epoch 3581, Loss: 0.01021739091083873, Final Batch Loss: 0.0\n",
      "Epoch 3582, Loss: 0.003778119120397605, Final Batch Loss: 4.076874756719917e-05\n",
      "Epoch 3583, Loss: 0.0014606948243454099, Final Batch Loss: 0.0\n",
      "Epoch 3584, Loss: 0.0010232942586299032, Final Batch Loss: 0.0\n",
      "Epoch 3585, Loss: 0.003560589044354856, Final Batch Loss: 0.0\n",
      "Epoch 3586, Loss: 0.0016353143146261573, Final Batch Loss: 0.0\n",
      "Epoch 3587, Loss: 0.009032884845510125, Final Batch Loss: 0.0\n",
      "Epoch 3588, Loss: 0.0020427019626367837, Final Batch Loss: 0.0\n",
      "Epoch 3589, Loss: 0.0036027200694661587, Final Batch Loss: 0.0\n",
      "Epoch 3590, Loss: 0.0019787363562500104, Final Batch Loss: 0.0\n",
      "Epoch 3591, Loss: 0.006840710120741278, Final Batch Loss: 0.0\n",
      "Epoch 3592, Loss: 0.004134600079822803, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3593, Loss: 0.005408725934103131, Final Batch Loss: 0.0\n",
      "Epoch 3594, Loss: 0.010464242426678538, Final Batch Loss: 0.0\n",
      "Epoch 3595, Loss: 0.0014460556267295033, Final Batch Loss: 0.0\n",
      "Epoch 3596, Loss: 0.006886450106776465, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 3597, Loss: 0.0025009631062857807, Final Batch Loss: 0.0\n",
      "Epoch 3598, Loss: 0.0008057790255406871, Final Batch Loss: 0.0\n",
      "Epoch 3599, Loss: 0.0082920876739081, Final Batch Loss: 6.05564855504781e-05\n",
      "Epoch 3600, Loss: 0.0023846178664825857, Final Batch Loss: 0.0\n",
      "Epoch 3601, Loss: 0.0031270890322048217, Final Batch Loss: 0.0\n",
      "Epoch 3602, Loss: 0.001715723701636307, Final Batch Loss: 0.0\n",
      "Epoch 3603, Loss: 0.002735988557105884, Final Batch Loss: 0.0\n",
      "Epoch 3604, Loss: 0.0067865189630538225, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3605, Loss: 0.004342563450336456, Final Batch Loss: 0.0\n",
      "Epoch 3606, Loss: 0.0024367434962186962, Final Batch Loss: 0.0\n",
      "Epoch 3607, Loss: 0.001538918077130802, Final Batch Loss: 0.0\n",
      "Epoch 3608, Loss: 0.011357148177921772, Final Batch Loss: 0.0\n",
      "Epoch 3609, Loss: 0.004472004831768572, Final Batch Loss: 0.0\n",
      "Epoch 3610, Loss: 0.001991070283111185, Final Batch Loss: 0.0\n",
      "Epoch 3611, Loss: 0.09875713103974704, Final Batch Loss: 0.08598675578832626\n",
      "Epoch 3612, Loss: 0.0039295757305808365, Final Batch Loss: 0.0\n",
      "Epoch 3613, Loss: 0.0032453907188028097, Final Batch Loss: 0.0\n",
      "Epoch 3614, Loss: 0.0004583235458710533, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3615, Loss: 0.016121379128890112, Final Batch Loss: 0.0\n",
      "Epoch 3616, Loss: 0.0018402190180495381, Final Batch Loss: 0.0\n",
      "Epoch 3617, Loss: 0.004440982535015792, Final Batch Loss: 0.0\n",
      "Epoch 3618, Loss: 0.0012778651434928179, Final Batch Loss: 0.0\n",
      "Epoch 3619, Loss: 0.0016579138464294374, Final Batch Loss: 0.0\n",
      "Epoch 3620, Loss: 0.06213098842999898, Final Batch Loss: 0.06001733988523483\n",
      "Epoch 3621, Loss: 0.0007916453250800259, Final Batch Loss: 0.0\n",
      "Epoch 3622, Loss: 0.05701589175259869, Final Batch Loss: 1.6331539882230572e-05\n",
      "Epoch 3623, Loss: 0.010423875181004405, Final Batch Loss: 0.0\n",
      "Epoch 3624, Loss: 0.004592329321894795, Final Batch Loss: 0.0\n",
      "Epoch 3625, Loss: 0.004074826407304499, Final Batch Loss: 0.0\n",
      "Epoch 3626, Loss: 0.0037123503861948848, Final Batch Loss: 0.0\n",
      "Epoch 3627, Loss: 0.0091422347468324, Final Batch Loss: 0.0\n",
      "Epoch 3628, Loss: 0.005086810153443366, Final Batch Loss: 0.0\n",
      "Epoch 3629, Loss: 0.03087073448114097, Final Batch Loss: 0.0\n",
      "Epoch 3630, Loss: 0.014697483275085688, Final Batch Loss: 0.0\n",
      "Epoch 3631, Loss: 0.002068741392577067, Final Batch Loss: 0.0\n",
      "Epoch 3632, Loss: 0.0024903203593567014, Final Batch Loss: 0.0\n",
      "Epoch 3633, Loss: 0.024375010863870727, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3634, Loss: 0.0013953876186860725, Final Batch Loss: 0.0\n",
      "Epoch 3635, Loss: 0.0045241253392305225, Final Batch Loss: 0.0\n",
      "Epoch 3636, Loss: 0.0024061455033006496, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3637, Loss: 0.0026223826134810224, Final Batch Loss: 3.0278701160568744e-05\n",
      "Epoch 3638, Loss: 0.007705276751948986, Final Batch Loss: 0.0003351603518240154\n",
      "Epoch 3639, Loss: 0.006238711910555139, Final Batch Loss: 0.0\n",
      "Epoch 3640, Loss: 0.0010082401995532564, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 3641, Loss: 0.0011744745424948633, Final Batch Loss: 0.0\n",
      "Epoch 3642, Loss: 0.0016579098446527496, Final Batch Loss: 0.0\n",
      "Epoch 3643, Loss: 0.006361623469274491, Final Batch Loss: 0.0\n",
      "Epoch 3644, Loss: 0.028695035667624325, Final Batch Loss: 0.0\n",
      "Epoch 3645, Loss: 0.0019402948346396443, Final Batch Loss: 0.0\n",
      "Epoch 3646, Loss: 0.01307258929591626, Final Batch Loss: 0.0\n",
      "Epoch 3647, Loss: 0.0008151553192874417, Final Batch Loss: 0.0\n",
      "Epoch 3648, Loss: 0.0010364715053583495, Final Batch Loss: 0.0\n",
      "Epoch 3649, Loss: 0.01465927511060272, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3650, Loss: 0.0015011852665338665, Final Batch Loss: 0.0\n",
      "Epoch 3651, Loss: 0.0014889900121488608, Final Batch Loss: 0.0\n",
      "Epoch 3652, Loss: 0.008043345820624381, Final Batch Loss: 0.0\n",
      "Epoch 3653, Loss: 0.0014510033070109785, Final Batch Loss: 0.0\n",
      "Epoch 3654, Loss: 0.002055184362689033, Final Batch Loss: 0.0\n",
      "Epoch 3655, Loss: 0.0012130467475799378, Final Batch Loss: 0.0\n",
      "Epoch 3656, Loss: 0.013215678540291265, Final Batch Loss: 0.0\n",
      "Epoch 3657, Loss: 0.002199486072640866, Final Batch Loss: 0.0\n",
      "Epoch 3658, Loss: 0.0017965081497095525, Final Batch Loss: 0.0\n",
      "Epoch 3659, Loss: 0.002614357443235349, Final Batch Loss: 0.0\n",
      "Epoch 3660, Loss: 0.003926906203446379, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3661, Loss: 0.0024761120184564334, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3662, Loss: 0.0004599875828716904, Final Batch Loss: 0.0\n",
      "Epoch 3663, Loss: 0.0018989264208357781, Final Batch Loss: 0.0\n",
      "Epoch 3664, Loss: 0.042119694451685064, Final Batch Loss: 0.0\n",
      "Epoch 3665, Loss: 0.002872197612305172, Final Batch Loss: 0.0\n",
      "Epoch 3666, Loss: 0.0014385636313818395, Final Batch Loss: 0.0\n",
      "Epoch 3667, Loss: 0.00837796874839114, Final Batch Loss: 0.0\n",
      "Epoch 3668, Loss: 0.0017797211767174304, Final Batch Loss: 0.0\n",
      "Epoch 3669, Loss: 0.01502261561108753, Final Batch Loss: 0.0\n",
      "Epoch 3670, Loss: 0.0013078853771730792, Final Batch Loss: 0.0\n",
      "Epoch 3671, Loss: 0.001678105545551034, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3672, Loss: 0.004450497799552977, Final Batch Loss: 0.0\n",
      "Epoch 3673, Loss: 0.0019710180204128847, Final Batch Loss: 0.0\n",
      "Epoch 3674, Loss: 0.0019870001706294715, Final Batch Loss: 0.0\n",
      "Epoch 3675, Loss: 0.0029036352643743157, Final Batch Loss: 0.0\n",
      "Epoch 3676, Loss: 0.0011591900837402136, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3677, Loss: 0.004913701850455254, Final Batch Loss: 0.0\n",
      "Epoch 3678, Loss: 0.01183810381917283, Final Batch Loss: 0.007593575865030289\n",
      "Epoch 3679, Loss: 0.002460558091115672, Final Batch Loss: 0.0\n",
      "Epoch 3680, Loss: 0.020167455746559426, Final Batch Loss: 0.0\n",
      "Epoch 3681, Loss: 0.026027032814454287, Final Batch Loss: 0.0\n",
      "Epoch 3682, Loss: 0.0016420672473032027, Final Batch Loss: 0.0\n",
      "Epoch 3683, Loss: 0.004915551049634814, Final Batch Loss: 0.0\n",
      "Epoch 3684, Loss: 0.008718043252883945, Final Batch Loss: 0.0\n",
      "Epoch 3685, Loss: 0.0038498471258208156, Final Batch Loss: 0.0\n",
      "Epoch 3686, Loss: 0.0049088864761870354, Final Batch Loss: 0.0\n",
      "Epoch 3687, Loss: 0.0009789344476303086, Final Batch Loss: 0.0\n",
      "Epoch 3688, Loss: 0.0018827380263246596, Final Batch Loss: 0.0\n",
      "Epoch 3689, Loss: 0.0013805856724502519, Final Batch Loss: 0.0\n",
      "Epoch 3690, Loss: 0.01543364260578528, Final Batch Loss: 0.0\n",
      "Epoch 3691, Loss: 0.0024099542788462713, Final Batch Loss: 0.0\n",
      "Epoch 3692, Loss: 0.0036162495960070373, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3693, Loss: 0.0011593168892432004, Final Batch Loss: 0.00014900050882715732\n",
      "Epoch 3694, Loss: 0.003108881530351937, Final Batch Loss: 0.0\n",
      "Epoch 3695, Loss: 0.004126174419070594, Final Batch Loss: 0.0\n",
      "Epoch 3696, Loss: 0.01837027381407097, Final Batch Loss: 0.0\n",
      "Epoch 3697, Loss: 0.002396168216364458, Final Batch Loss: 0.0\n",
      "Epoch 3698, Loss: 0.002364533487366316, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3699, Loss: 0.011974399181781337, Final Batch Loss: 0.0\n",
      "Epoch 3700, Loss: 0.004136786796152592, Final Batch Loss: 0.0\n",
      "Epoch 3701, Loss: 0.0023119762625469775, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3702, Loss: 0.019739651223062538, Final Batch Loss: 0.0\n",
      "Epoch 3703, Loss: 0.004798639623913914, Final Batch Loss: 0.0\n",
      "Epoch 3704, Loss: 0.004848554963245988, Final Batch Loss: 0.0\n",
      "Epoch 3705, Loss: 0.009005874965623661, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 3706, Loss: 0.0022589410073123872, Final Batch Loss: 0.0\n",
      "Epoch 3707, Loss: 0.006873187609016895, Final Batch Loss: 0.0\n",
      "Epoch 3708, Loss: 0.0023925522691570222, Final Batch Loss: 0.0\n",
      "Epoch 3709, Loss: 0.0031659849864809075, Final Batch Loss: 9.894321920000948e-06\n",
      "Epoch 3710, Loss: 0.011122121162770782, Final Batch Loss: 4.1960789531003684e-05\n",
      "Epoch 3711, Loss: 0.0023278359658434056, Final Batch Loss: 0.001110175740905106\n",
      "Epoch 3712, Loss: 0.0017350252164760605, Final Batch Loss: 0.0\n",
      "Epoch 3713, Loss: 0.0039682697533862665, Final Batch Loss: 0.0\n",
      "Epoch 3714, Loss: 0.001420909378794022, Final Batch Loss: 0.0\n",
      "Epoch 3715, Loss: 0.0038626362147624604, Final Batch Loss: 0.0\n",
      "Epoch 3716, Loss: 0.005971048027276993, Final Batch Loss: 0.0\n",
      "Epoch 3717, Loss: 0.0010246521778469742, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3718, Loss: 0.014441714651177051, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3719, Loss: 0.014321139082312584, Final Batch Loss: 0.0\n",
      "Epoch 3720, Loss: 0.02087531832512468, Final Batch Loss: 0.0\n",
      "Epoch 3721, Loss: 0.0037305996083887294, Final Batch Loss: 0.0\n",
      "Epoch 3722, Loss: 0.0022519951526192017, Final Batch Loss: 0.00010215714428341016\n",
      "Epoch 3723, Loss: 0.0022256074953475036, Final Batch Loss: 0.0004319211875554174\n",
      "Epoch 3724, Loss: 0.0033963745227083564, Final Batch Loss: 0.0\n",
      "Epoch 3725, Loss: 0.036708413681481034, Final Batch Loss: 0.0\n",
      "Epoch 3726, Loss: 0.006950568873435259, Final Batch Loss: 0.0\n",
      "Epoch 3727, Loss: 0.004004142478720496, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3728, Loss: 0.006305715462076478, Final Batch Loss: 0.0\n",
      "Epoch 3729, Loss: 0.026187293617113028, Final Batch Loss: 0.0\n",
      "Epoch 3730, Loss: 0.0006621432148676831, Final Batch Loss: 0.0\n",
      "Epoch 3731, Loss: 0.003217624694116239, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 3732, Loss: 0.018844283476937562, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3733, Loss: 0.017065471620298922, Final Batch Loss: 0.0\n",
      "Epoch 3734, Loss: 0.0036956704570911825, Final Batch Loss: 0.0\n",
      "Epoch 3735, Loss: 0.00353742134575441, Final Batch Loss: 1.3351351299206726e-05\n",
      "Epoch 3736, Loss: 0.0016225031283738645, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3737, Loss: 0.002281183347804472, Final Batch Loss: 0.0\n",
      "Epoch 3738, Loss: 0.0015254175814334303, Final Batch Loss: 0.0\n",
      "Epoch 3739, Loss: 0.010268307087244466, Final Batch Loss: 0.0\n",
      "Epoch 3740, Loss: 0.004260295710992068, Final Batch Loss: 0.0\n",
      "Epoch 3741, Loss: 0.0007062344520818442, Final Batch Loss: 0.0\n",
      "Epoch 3742, Loss: 0.0008557988912798464, Final Batch Loss: 0.0\n",
      "Epoch 3743, Loss: 0.007197742786956951, Final Batch Loss: 0.0\n",
      "Epoch 3744, Loss: 0.003406207047987664, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3745, Loss: 0.003515429620165378, Final Batch Loss: 0.0\n",
      "Epoch 3746, Loss: 0.005488667025929317, Final Batch Loss: 0.0\n",
      "Epoch 3747, Loss: 0.0016889343678485602, Final Batch Loss: 0.0\n",
      "Epoch 3748, Loss: 0.0006070649542380124, Final Batch Loss: 0.0\n",
      "Epoch 3749, Loss: 0.002071760653052479, Final Batch Loss: 0.0\n",
      "Epoch 3750, Loss: 0.002756856905762106, Final Batch Loss: 0.0\n",
      "Epoch 3751, Loss: 0.0066655827686190605, Final Batch Loss: 0.0\n",
      "Epoch 3752, Loss: 0.0025817338173510507, Final Batch Loss: 0.001061591086909175\n",
      "Epoch 3753, Loss: 0.024387251294683665, Final Batch Loss: 0.0\n",
      "Epoch 3754, Loss: 0.003172968337594284, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3755, Loss: 0.0009742738329805434, Final Batch Loss: 0.0\n",
      "Epoch 3756, Loss: 0.002605888031212089, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3757, Loss: 0.002568026538938284, Final Batch Loss: 0.0\n",
      "Epoch 3758, Loss: 0.02416629297658801, Final Batch Loss: 0.0\n",
      "Epoch 3759, Loss: 0.006835528445662931, Final Batch Loss: 0.0\n",
      "Epoch 3760, Loss: 0.00854086602339521, Final Batch Loss: 0.0\n",
      "Epoch 3761, Loss: 0.001337124063866213, Final Batch Loss: 0.0\n",
      "Epoch 3762, Loss: 0.0011796676699304953, Final Batch Loss: 0.0\n",
      "Epoch 3763, Loss: 0.0019877907470799983, Final Batch Loss: 0.0\n",
      "Epoch 3764, Loss: 0.0011815497418865561, Final Batch Loss: 0.0\n",
      "Epoch 3765, Loss: 0.0012598869943758473, Final Batch Loss: 0.0\n",
      "Epoch 3766, Loss: 0.0018321194220334291, Final Batch Loss: 0.0\n",
      "Epoch 3767, Loss: 0.0008414468101989314, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3768, Loss: 0.015600871469359845, Final Batch Loss: 0.0\n",
      "Epoch 3769, Loss: 0.0061450988869182765, Final Batch Loss: 0.0\n",
      "Epoch 3770, Loss: 0.01906991825671156, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3771, Loss: 0.005357344460207969, Final Batch Loss: 0.0006386386230587959\n",
      "Epoch 3772, Loss: 0.0029212066147010773, Final Batch Loss: 0.0\n",
      "Epoch 3773, Loss: 0.0031922298803692684, Final Batch Loss: 0.0\n",
      "Epoch 3774, Loss: 0.014559528179233894, Final Batch Loss: 0.0\n",
      "Epoch 3775, Loss: 0.0013133557513356209, Final Batch Loss: 0.0\n",
      "Epoch 3776, Loss: 0.000906478293472901, Final Batch Loss: 0.0\n",
      "Epoch 3777, Loss: 0.003879079973444277, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3778, Loss: 0.002729275613091886, Final Batch Loss: 0.0\n",
      "Epoch 3779, Loss: 0.0004454411900951527, Final Batch Loss: 0.0\n",
      "Epoch 3780, Loss: 0.0010477868818270508, Final Batch Loss: 0.0\n",
      "Epoch 3781, Loss: 0.01213266716513317, Final Batch Loss: 0.0\n",
      "Epoch 3782, Loss: 0.003212888492271304, Final Batch Loss: 0.0\n",
      "Epoch 3783, Loss: 0.010467865813552635, Final Batch Loss: 0.0\n",
      "Epoch 3784, Loss: 0.026923917932379027, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3785, Loss: 0.0011120925919385627, Final Batch Loss: 0.0\n",
      "Epoch 3786, Loss: 0.001726600545225665, Final Batch Loss: 0.0\n",
      "Epoch 3787, Loss: 0.002249166165711358, Final Batch Loss: 0.00035494225448928773\n",
      "Epoch 3788, Loss: 0.00250192781095393, Final Batch Loss: 0.0\n",
      "Epoch 3789, Loss: 0.0012536102076410316, Final Batch Loss: 0.0\n",
      "Epoch 3790, Loss: 0.0034911624679807574, Final Batch Loss: 0.0\n",
      "Epoch 3791, Loss: 0.00517916158423759, Final Batch Loss: 0.0\n",
      "Epoch 3792, Loss: 0.018389610217127483, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 3793, Loss: 0.007250502589158714, Final Batch Loss: 0.0\n",
      "Epoch 3794, Loss: 0.0019136070179683884, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3795, Loss: 0.001976794470465393, Final Batch Loss: 0.0\n",
      "Epoch 3796, Loss: 0.009613873553462327, Final Batch Loss: 0.0\n",
      "Epoch 3797, Loss: 0.0016425114881712943, Final Batch Loss: 0.0\n",
      "Epoch 3798, Loss: 0.0022320801799651235, Final Batch Loss: 0.0\n",
      "Epoch 3799, Loss: 0.002566747833043337, Final Batch Loss: 0.0\n",
      "Epoch 3800, Loss: 0.00840457555023022, Final Batch Loss: 0.0\n",
      "Epoch 3801, Loss: 0.004021539061788815, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3802, Loss: 0.002744037890806794, Final Batch Loss: 0.0\n",
      "Epoch 3803, Loss: 0.00222845897951629, Final Batch Loss: 0.0\n",
      "Epoch 3804, Loss: 0.0019468359678285196, Final Batch Loss: 0.0\n",
      "Epoch 3805, Loss: 0.0005437758190964814, Final Batch Loss: 0.0\n",
      "Epoch 3806, Loss: 0.0016754910398049105, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 3807, Loss: 0.004164363170275465, Final Batch Loss: 0.0\n",
      "Epoch 3808, Loss: 0.0006973851850489154, Final Batch Loss: 0.0\n",
      "Epoch 3809, Loss: 0.0022705992741975933, Final Batch Loss: 0.0\n",
      "Epoch 3810, Loss: 0.0017148432089015841, Final Batch Loss: 0.0002553137019276619\n",
      "Epoch 3811, Loss: 0.002258348817122169, Final Batch Loss: 0.0\n",
      "Epoch 3812, Loss: 0.002921174862308362, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3813, Loss: 0.0018268682397319935, Final Batch Loss: 0.0\n",
      "Epoch 3814, Loss: 0.001124274160247296, Final Batch Loss: 0.0\n",
      "Epoch 3815, Loss: 0.0016882199836345535, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3816, Loss: 0.002072519506327808, Final Batch Loss: 0.0\n",
      "Epoch 3817, Loss: 0.0011781180437537841, Final Batch Loss: 0.0\n",
      "Epoch 3818, Loss: 0.000526059688127134, Final Batch Loss: 0.0\n",
      "Epoch 3819, Loss: 0.001800611222279258, Final Batch Loss: 0.0\n",
      "Epoch 3820, Loss: 0.0006433246962842532, Final Batch Loss: 0.0\n",
      "Epoch 3821, Loss: 0.010429167145048268, Final Batch Loss: 0.009648829698562622\n",
      "Epoch 3822, Loss: 0.0008160549284639274, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 3823, Loss: 0.016475765587529168, Final Batch Loss: 0.0\n",
      "Epoch 3824, Loss: 0.008606928544395487, Final Batch Loss: 2.539125671319198e-05\n",
      "Epoch 3825, Loss: 0.001089136072096153, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 3826, Loss: 0.012364815964239995, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3827, Loss: 0.0010847290977835655, Final Batch Loss: 0.0\n",
      "Epoch 3828, Loss: 0.002086883567244513, Final Batch Loss: 3.015949550899677e-05\n",
      "Epoch 3829, Loss: 0.011420953736660522, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3830, Loss: 0.017316268879312702, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 3831, Loss: 0.00969871913548559, Final Batch Loss: 0.002444852376356721\n",
      "Epoch 3832, Loss: 0.0008770933636697009, Final Batch Loss: 0.0\n",
      "Epoch 3833, Loss: 0.0027151907852100976, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3834, Loss: 0.007245393819175661, Final Batch Loss: 0.0\n",
      "Epoch 3835, Loss: 0.006075191413401626, Final Batch Loss: 0.0\n",
      "Epoch 3836, Loss: 0.021985262457747012, Final Batch Loss: 0.0\n",
      "Epoch 3837, Loss: 0.0023999438853934407, Final Batch Loss: 0.0\n",
      "Epoch 3838, Loss: 0.0014943442511139438, Final Batch Loss: 0.0\n",
      "Epoch 3839, Loss: 0.00047490753058809787, Final Batch Loss: 0.0\n",
      "Epoch 3840, Loss: 0.00982348340036765, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3841, Loss: 0.010628759919200093, Final Batch Loss: 0.0\n",
      "Epoch 3842, Loss: 0.004592596276779659, Final Batch Loss: 0.0\n",
      "Epoch 3843, Loss: 0.002564655449532438, Final Batch Loss: 0.0\n",
      "Epoch 3844, Loss: 0.0008326180395670235, Final Batch Loss: 0.0\n",
      "Epoch 3845, Loss: 0.006609992778976448, Final Batch Loss: 0.0\n",
      "Epoch 3846, Loss: 0.001967427713680081, Final Batch Loss: 0.0\n",
      "Epoch 3847, Loss: 0.019574385602027178, Final Batch Loss: 0.0\n",
      "Epoch 3848, Loss: 0.001629636826692149, Final Batch Loss: 0.0\n",
      "Epoch 3849, Loss: 0.0021653688738751953, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3850, Loss: 0.0012374062459912238, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 3851, Loss: 0.008028450638448703, Final Batch Loss: 0.0\n",
      "Epoch 3852, Loss: 0.0032305759232258424, Final Batch Loss: 0.0\n",
      "Epoch 3853, Loss: 0.002955831034341827, Final Batch Loss: 0.0\n",
      "Epoch 3854, Loss: 0.0013988398422952741, Final Batch Loss: 0.0\n",
      "Epoch 3855, Loss: 0.02037175081204623, Final Batch Loss: 0.0\n",
      "Epoch 3856, Loss: 0.0016189416346534813, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3857, Loss: 0.02980705427751218, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3858, Loss: 0.0017388925480190665, Final Batch Loss: 0.0\n",
      "Epoch 3859, Loss: 0.0015531998942606151, Final Batch Loss: 0.0\n",
      "Epoch 3860, Loss: 0.0006019854718033457, Final Batch Loss: 0.0\n",
      "Epoch 3861, Loss: 0.005314155205269344, Final Batch Loss: 0.0\n",
      "Epoch 3862, Loss: 0.0008803032542346045, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3863, Loss: 0.002532346043153666, Final Batch Loss: 0.000878544058650732\n",
      "Epoch 3864, Loss: 0.003657306413515471, Final Batch Loss: 0.0\n",
      "Epoch 3865, Loss: 0.0020508661175426823, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3866, Loss: 0.0004488707345444709, Final Batch Loss: 0.0\n",
      "Epoch 3867, Loss: 0.016017905036278535, Final Batch Loss: 0.0\n",
      "Epoch 3868, Loss: 0.006144359125755727, Final Batch Loss: 0.0\n",
      "Epoch 3869, Loss: 0.00561144621940457, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3870, Loss: 0.004649049515109027, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3871, Loss: 0.00668163807114297, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3872, Loss: 0.027069642208516598, Final Batch Loss: 0.0\n",
      "Epoch 3873, Loss: 0.0021609478135360405, Final Batch Loss: 0.0\n",
      "Epoch 3874, Loss: 0.0029392451106105, Final Batch Loss: 0.0\n",
      "Epoch 3875, Loss: 0.0020100788824493065, Final Batch Loss: 0.0\n",
      "Epoch 3876, Loss: 0.006521061703097075, Final Batch Loss: 0.0\n",
      "Epoch 3877, Loss: 0.02660694452788448, Final Batch Loss: 0.0\n",
      "Epoch 3878, Loss: 0.0047345197199319955, Final Batch Loss: 0.0\n",
      "Epoch 3879, Loss: 0.0022009338717836613, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3880, Loss: 0.0014168164198054, Final Batch Loss: 0.0\n",
      "Epoch 3881, Loss: 0.015448646852746606, Final Batch Loss: 0.0\n",
      "Epoch 3882, Loss: 0.0007165174574765842, Final Batch Loss: 3.480850500636734e-05\n",
      "Epoch 3883, Loss: 0.0019783947564064874, Final Batch Loss: 0.0\n",
      "Epoch 3884, Loss: 0.011215582606382668, Final Batch Loss: 0.0\n",
      "Epoch 3885, Loss: 0.0025408160872189, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3886, Loss: 0.0011714960128301755, Final Batch Loss: 0.0\n",
      "Epoch 3887, Loss: 0.018773756455630064, Final Batch Loss: 0.0\n",
      "Epoch 3888, Loss: 0.0024246074608527124, Final Batch Loss: 0.0\n",
      "Epoch 3889, Loss: 0.0009971550316549838, Final Batch Loss: 0.0\n",
      "Epoch 3890, Loss: 0.0010166348620259669, Final Batch Loss: 0.0\n",
      "Epoch 3891, Loss: 0.02448444810579531, Final Batch Loss: 0.0\n",
      "Epoch 3892, Loss: 0.0008683434643899091, Final Batch Loss: 8.976056415122002e-05\n",
      "Epoch 3893, Loss: 0.0015876094985287637, Final Batch Loss: 0.0\n",
      "Epoch 3894, Loss: 0.005743536399677396, Final Batch Loss: 0.0\n",
      "Epoch 3895, Loss: 0.005538812154554762, Final Batch Loss: 0.0\n",
      "Epoch 3896, Loss: 0.0019055047305300832, Final Batch Loss: 0.0\n",
      "Epoch 3897, Loss: 0.001290148175030481, Final Batch Loss: 0.0\n",
      "Epoch 3898, Loss: 0.0027092254313174635, Final Batch Loss: 0.0\n",
      "Epoch 3899, Loss: 0.0010934909514617175, Final Batch Loss: 0.0\n",
      "Epoch 3900, Loss: 0.004983992410409144, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3901, Loss: 0.0014721809711772949, Final Batch Loss: 0.0\n",
      "Epoch 3902, Loss: 0.0041125261268462054, Final Batch Loss: 0.0029273061081767082\n",
      "Epoch 3903, Loss: 0.0007256496755871922, Final Batch Loss: 0.0\n",
      "Epoch 3904, Loss: 0.003418932144967357, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3905, Loss: 0.0006243766765692271, Final Batch Loss: 0.0\n",
      "Epoch 3906, Loss: 0.0031013702391646802, Final Batch Loss: 0.0\n",
      "Epoch 3907, Loss: 0.0011413978718337603, Final Batch Loss: 0.0\n",
      "Epoch 3908, Loss: 0.002626220855745487, Final Batch Loss: 0.0\n",
      "Epoch 3909, Loss: 0.0021100890880916268, Final Batch Loss: 0.0\n",
      "Epoch 3910, Loss: 0.0013621009711357601, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3911, Loss: 0.0004583538575388957, Final Batch Loss: 0.0\n",
      "Epoch 3912, Loss: 0.0005515793745871633, Final Batch Loss: 0.0\n",
      "Epoch 3913, Loss: 0.002212760387919843, Final Batch Loss: 0.0\n",
      "Epoch 3914, Loss: 0.0009696224005892873, Final Batch Loss: 0.0\n",
      "Epoch 3915, Loss: 0.0007482678120140918, Final Batch Loss: 0.0\n",
      "Epoch 3916, Loss: 0.005964964861050248, Final Batch Loss: 0.0\n",
      "Epoch 3917, Loss: 0.006520698341773823, Final Batch Loss: 0.0\n",
      "Epoch 3918, Loss: 0.0014776915377225919, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3919, Loss: 0.0010444138970342465, Final Batch Loss: 0.0\n",
      "Epoch 3920, Loss: 0.02437839936465025, Final Batch Loss: 0.0\n",
      "Epoch 3921, Loss: 0.0007404419884551316, Final Batch Loss: 0.0\n",
      "Epoch 3922, Loss: 0.002397399744950235, Final Batch Loss: 0.0\n",
      "Epoch 3923, Loss: 0.007641886665965103, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3924, Loss: 0.0023823320225346833, Final Batch Loss: 0.0\n",
      "Epoch 3925, Loss: 0.0005805402179248631, Final Batch Loss: 0.0\n",
      "Epoch 3926, Loss: 0.00539614402805455, Final Batch Loss: 0.0\n",
      "Epoch 3927, Loss: 0.0013351951238291804, Final Batch Loss: 0.0\n",
      "Epoch 3928, Loss: 0.001232485533819272, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3929, Loss: 0.0007087160265655257, Final Batch Loss: 0.0\n",
      "Epoch 3930, Loss: 0.0009558735837345012, Final Batch Loss: 0.0\n",
      "Epoch 3931, Loss: 0.0064860736347327475, Final Batch Loss: 0.0\n",
      "Epoch 3932, Loss: 0.002099772304063663, Final Batch Loss: 0.0\n",
      "Epoch 3933, Loss: 0.002031706702837255, Final Batch Loss: 6.544376083184034e-05\n",
      "Epoch 3934, Loss: 0.0023874688777141273, Final Batch Loss: 0.0\n",
      "Epoch 3935, Loss: 0.0030449625410255976, Final Batch Loss: 0.0001037067049765028\n",
      "Epoch 3936, Loss: 0.01589382902602665, Final Batch Loss: 0.0\n",
      "Epoch 3937, Loss: 0.0010851391270989552, Final Batch Loss: 0.0\n",
      "Epoch 3938, Loss: 0.030234760080929846, Final Batch Loss: 0.0\n",
      "Epoch 3939, Loss: 0.0009613058937247843, Final Batch Loss: 0.0\n",
      "Epoch 3940, Loss: 0.0012588331301230937, Final Batch Loss: 0.0\n",
      "Epoch 3941, Loss: 0.002211326667747926, Final Batch Loss: 0.0\n",
      "Epoch 3942, Loss: 0.003012974775629118, Final Batch Loss: 0.00052998325554654\n",
      "Epoch 3943, Loss: 0.00127894664183259, Final Batch Loss: 0.0\n",
      "Epoch 3944, Loss: 0.0005198437138460577, Final Batch Loss: 0.0\n",
      "Epoch 3945, Loss: 0.0036467029767663917, Final Batch Loss: 0.0\n",
      "Epoch 3946, Loss: 0.0011456533247837797, Final Batch Loss: 0.0\n",
      "Epoch 3947, Loss: 0.0016408136289101094, Final Batch Loss: 0.0\n",
      "Epoch 3948, Loss: 0.0021988215448800474, Final Batch Loss: 0.0\n",
      "Epoch 3949, Loss: 0.0021366358196246438, Final Batch Loss: 0.0\n",
      "Epoch 3950, Loss: 0.004046366244438104, Final Batch Loss: 0.0024565064813941717\n",
      "Epoch 3951, Loss: 0.004463896155357361, Final Batch Loss: 0.0\n",
      "Epoch 3952, Loss: 0.005209453869611025, Final Batch Loss: 0.0\n",
      "Epoch 3953, Loss: 0.001124609021616152, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3954, Loss: 0.001105442778680299, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 3955, Loss: 0.011265421562711708, Final Batch Loss: 0.0\n",
      "Epoch 3956, Loss: 0.025705322812427767, Final Batch Loss: 0.0\n",
      "Epoch 3957, Loss: 0.0026655785623006523, Final Batch Loss: 0.0\n",
      "Epoch 3958, Loss: 0.014794672491916572, Final Batch Loss: 0.0\n",
      "Epoch 3959, Loss: 0.005113566286809146, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3960, Loss: 0.0030931836226955056, Final Batch Loss: 0.0\n",
      "Epoch 3961, Loss: 0.0004326960406615399, Final Batch Loss: 0.0\n",
      "Epoch 3962, Loss: 0.006434771006752271, Final Batch Loss: 0.0\n",
      "Epoch 3963, Loss: 0.0019127663399558514, Final Batch Loss: 0.0\n",
      "Epoch 3964, Loss: 0.0013821919783367775, Final Batch Loss: 6.55629628454335e-05\n",
      "Epoch 3965, Loss: 0.0012307206634432077, Final Batch Loss: 0.0\n",
      "Epoch 3966, Loss: 0.015563070308417082, Final Batch Loss: 0.0\n",
      "Epoch 3967, Loss: 0.006307670584618563, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3968, Loss: 0.0034083359423675574, Final Batch Loss: 0.0\n",
      "Epoch 3969, Loss: 0.0009487650822848082, Final Batch Loss: 0.0\n",
      "Epoch 3970, Loss: 0.0007894475202192552, Final Batch Loss: 0.0\n",
      "Epoch 3971, Loss: 0.002117020107107237, Final Batch Loss: 0.0\n",
      "Epoch 3972, Loss: 0.01996048670844175, Final Batch Loss: 0.018392842262983322\n",
      "Epoch 3973, Loss: 0.0026594724331516773, Final Batch Loss: 0.0\n",
      "Epoch 3974, Loss: 0.0029405592558759963, Final Batch Loss: 0.0\n",
      "Epoch 3975, Loss: 0.001771889888914302, Final Batch Loss: 0.0\n",
      "Epoch 3976, Loss: 0.002195506553107407, Final Batch Loss: 0.0\n",
      "Epoch 3977, Loss: 0.004874405582086183, Final Batch Loss: 6.544376083184034e-05\n",
      "Epoch 3978, Loss: 0.0021221553906798363, Final Batch Loss: 0.0\n",
      "Epoch 3979, Loss: 0.0021716510455007665, Final Batch Loss: 0.0\n",
      "Epoch 3980, Loss: 0.000998612587864045, Final Batch Loss: 0.0\n",
      "Epoch 3981, Loss: 0.001426046175765805, Final Batch Loss: 0.0\n",
      "Epoch 3982, Loss: 0.002936148601293098, Final Batch Loss: 0.0\n",
      "Epoch 3983, Loss: 0.001045719487592578, Final Batch Loss: 0.0\n",
      "Epoch 3984, Loss: 0.001570767919474747, Final Batch Loss: 0.0\n",
      "Epoch 3985, Loss: 0.0016857550654094666, Final Batch Loss: 0.0\n",
      "Epoch 3986, Loss: 0.0012691969313891605, Final Batch Loss: 0.0\n",
      "Epoch 3987, Loss: 0.0022994930077402387, Final Batch Loss: 0.0\n",
      "Epoch 3988, Loss: 0.02538773504056735, Final Batch Loss: 0.0\n",
      "Epoch 3989, Loss: 0.0011534055083686212, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3990, Loss: 0.0028595558542292565, Final Batch Loss: 0.0\n",
      "Epoch 3991, Loss: 0.005581503122812137, Final Batch Loss: 0.0\n",
      "Epoch 3992, Loss: 0.003264811326516792, Final Batch Loss: 0.0\n",
      "Epoch 3993, Loss: 0.0007007617823546752, Final Batch Loss: 0.0\n",
      "Epoch 3994, Loss: 0.000869546718604397, Final Batch Loss: 0.0\n",
      "Epoch 3995, Loss: 0.001465260429540649, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3996, Loss: 0.002075393626000732, Final Batch Loss: 0.0\n",
      "Epoch 3997, Loss: 0.008401320548728108, Final Batch Loss: 0.0\n",
      "Epoch 3998, Loss: 0.018536958581535146, Final Batch Loss: 0.0\n",
      "Epoch 3999, Loss: 0.0022331219697662164, Final Batch Loss: 0.0\n",
      "Epoch 4000, Loss: 0.0005462774133775383, Final Batch Loss: 0.0\n",
      "Epoch 4001, Loss: 0.0004597942024702206, Final Batch Loss: 0.0\n",
      "Epoch 4002, Loss: 0.0004049014205520507, Final Batch Loss: 0.0\n",
      "Epoch 4003, Loss: 0.001137503961189168, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4004, Loss: 0.0005020117096137255, Final Batch Loss: 0.0\n",
      "Epoch 4005, Loss: 0.010821710369782522, Final Batch Loss: 0.0\n",
      "Epoch 4006, Loss: 0.0007691382124903612, Final Batch Loss: 0.0\n",
      "Epoch 4007, Loss: 0.0008824942779028788, Final Batch Loss: 0.0\n",
      "Epoch 4008, Loss: 0.00041908900038833963, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 4009, Loss: 0.0009272803436033428, Final Batch Loss: 0.0\n",
      "Epoch 4010, Loss: 0.0020577659888658673, Final Batch Loss: 0.0\n",
      "Epoch 4011, Loss: 0.00089714874047786, Final Batch Loss: 0.0\n",
      "Epoch 4012, Loss: 0.00046164462401065975, Final Batch Loss: 0.0\n",
      "Epoch 4013, Loss: 0.0007775535377732012, Final Batch Loss: 0.0\n",
      "Epoch 4014, Loss: 0.0009613378424546681, Final Batch Loss: 0.0\n",
      "Epoch 4015, Loss: 0.021563915244769305, Final Batch Loss: 0.0\n",
      "Epoch 4016, Loss: 0.000777857298089657, Final Batch Loss: 0.0\n",
      "Epoch 4017, Loss: 0.0007085248980729375, Final Batch Loss: 0.0\n",
      "Epoch 4018, Loss: 0.0018535163108026609, Final Batch Loss: 0.0\n",
      "Epoch 4019, Loss: 0.0004322156746638939, Final Batch Loss: 0.0\n",
      "Epoch 4020, Loss: 0.0005571971123572439, Final Batch Loss: 0.0\n",
      "Epoch 4021, Loss: 0.00045811889867763966, Final Batch Loss: 0.0\n",
      "Epoch 4022, Loss: 0.0011703405907610431, Final Batch Loss: 0.0\n",
      "Epoch 4023, Loss: 0.00042369341099401936, Final Batch Loss: 0.0\n",
      "Epoch 4024, Loss: 0.009041376164361736, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4025, Loss: 0.013365298319058638, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4026, Loss: 0.002286716684466228, Final Batch Loss: 0.0\n",
      "Epoch 4027, Loss: 0.00040013080433709547, Final Batch Loss: 0.0\n",
      "Epoch 4028, Loss: 0.0006742680561728776, Final Batch Loss: 0.0\n",
      "Epoch 4029, Loss: 0.002476433350238949, Final Batch Loss: 0.0\n",
      "Epoch 4030, Loss: 0.0011528546456247568, Final Batch Loss: 0.0\n",
      "Epoch 4031, Loss: 0.0016213818362302845, Final Batch Loss: 0.0\n",
      "Epoch 4032, Loss: 0.002698739233892411, Final Batch Loss: 0.0\n",
      "Epoch 4033, Loss: 0.002206220058724284, Final Batch Loss: 0.0\n",
      "Epoch 4034, Loss: 0.0019052950956393033, Final Batch Loss: 0.0\n",
      "Epoch 4035, Loss: 0.0010600415407679975, Final Batch Loss: 0.0\n",
      "Epoch 4036, Loss: 0.006403050385408449, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4037, Loss: 0.0012215716851642355, Final Batch Loss: 0.0\n",
      "Epoch 4038, Loss: 0.005369736434658989, Final Batch Loss: 0.0\n",
      "Epoch 4039, Loss: 0.004628424121612795, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4040, Loss: 0.0025463390848017298, Final Batch Loss: 0.0\n",
      "Epoch 4041, Loss: 0.0020855024340562522, Final Batch Loss: 0.0\n",
      "Epoch 4042, Loss: 0.0029095350691932254, Final Batch Loss: 0.0\n",
      "Epoch 4043, Loss: 0.001059765651007183, Final Batch Loss: 0.0\n",
      "Epoch 4044, Loss: 0.003954003899707459, Final Batch Loss: 0.0\n",
      "Epoch 4045, Loss: 0.004424303362441151, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4046, Loss: 0.0011992435320280492, Final Batch Loss: 0.0\n",
      "Epoch 4047, Loss: 0.004178794697509147, Final Batch Loss: 0.0\n",
      "Epoch 4048, Loss: 0.0017814397579059005, Final Batch Loss: 0.0\n",
      "Epoch 4049, Loss: 0.0038577463128603995, Final Batch Loss: 0.0\n",
      "Epoch 4050, Loss: 0.015681629214327586, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4051, Loss: 0.0024797669029794633, Final Batch Loss: 0.0\n",
      "Epoch 4052, Loss: 0.0008758817202760838, Final Batch Loss: 0.0\n",
      "Epoch 4053, Loss: 0.003497079838780337, Final Batch Loss: 0.0\n",
      "Epoch 4054, Loss: 0.0008559450707252836, Final Batch Loss: 0.0\n",
      "Epoch 4055, Loss: 0.0020624600185783493, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4056, Loss: 0.0006857896660221741, Final Batch Loss: 0.0\n",
      "Epoch 4057, Loss: 0.014753809431567788, Final Batch Loss: 0.0\n",
      "Epoch 4058, Loss: 0.002738930455961963, Final Batch Loss: 0.0\n",
      "Epoch 4059, Loss: 0.0017566037677170243, Final Batch Loss: 0.0\n",
      "Epoch 4060, Loss: 0.001257536022876593, Final Batch Loss: 0.0\n",
      "Epoch 4061, Loss: 0.0004352363685029559, Final Batch Loss: 0.0\n",
      "Epoch 4062, Loss: 0.000933636401896365, Final Batch Loss: 0.0\n",
      "Epoch 4063, Loss: 0.0018062482340610586, Final Batch Loss: 6.615896563744172e-05\n",
      "Epoch 4064, Loss: 0.0011526038579177111, Final Batch Loss: 0.0\n",
      "Epoch 4065, Loss: 0.0012334351972640434, Final Batch Loss: 6.079655122448457e-06\n",
      "Epoch 4066, Loss: 0.0005242727202130482, Final Batch Loss: 0.0\n",
      "Epoch 4067, Loss: 0.008914159348933026, Final Batch Loss: 0.0\n",
      "Epoch 4068, Loss: 0.00037264736556608113, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 4069, Loss: 0.0007827348968021397, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4070, Loss: 0.0010002215058193542, Final Batch Loss: 0.0\n",
      "Epoch 4071, Loss: 0.0017497124790679663, Final Batch Loss: 0.0\n",
      "Epoch 4072, Loss: 0.000609767492278479, Final Batch Loss: 0.0\n",
      "Epoch 4073, Loss: 0.0035518698568921536, Final Batch Loss: 0.0\n",
      "Epoch 4074, Loss: 0.0014111429481999949, Final Batch Loss: 0.0\n",
      "Epoch 4075, Loss: 0.00034807902920874767, Final Batch Loss: 0.0\n",
      "Epoch 4076, Loss: 0.0008306972595164552, Final Batch Loss: 0.0\n",
      "Epoch 4077, Loss: 0.001620567578356713, Final Batch Loss: 0.0\n",
      "Epoch 4078, Loss: 0.001194560682051815, Final Batch Loss: 0.0\n",
      "Epoch 4079, Loss: 0.0015088533473317511, Final Batch Loss: 0.0\n",
      "Epoch 4080, Loss: 0.0056645678414497524, Final Batch Loss: 0.0\n",
      "Epoch 4081, Loss: 0.0014536781163769774, Final Batch Loss: 0.0\n",
      "Epoch 4082, Loss: 0.0007632326087332331, Final Batch Loss: 0.0\n",
      "Epoch 4083, Loss: 0.0036203628551447764, Final Batch Loss: 0.0\n",
      "Epoch 4084, Loss: 0.0006625876849284396, Final Batch Loss: 0.0\n",
      "Epoch 4085, Loss: 0.0020045943065269967, Final Batch Loss: 0.0\n",
      "Epoch 4086, Loss: 0.001156345329945907, Final Batch Loss: 0.0\n",
      "Epoch 4087, Loss: 0.004591876677750406, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4088, Loss: 0.0017855809855973348, Final Batch Loss: 0.0\n",
      "Epoch 4089, Loss: 0.0026311874778457423, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4090, Loss: 0.0021239057241473347, Final Batch Loss: 0.0\n",
      "Epoch 4091, Loss: 0.01769317073194543, Final Batch Loss: 0.0\n",
      "Epoch 4092, Loss: 0.03447782204602845, Final Batch Loss: 0.0\n",
      "Epoch 4093, Loss: 0.0008429421577531571, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4094, Loss: 0.0014755399315617979, Final Batch Loss: 0.0\n",
      "Epoch 4095, Loss: 0.0012183088547317311, Final Batch Loss: 0.0\n",
      "Epoch 4096, Loss: 0.0003757525046239607, Final Batch Loss: 0.0\n",
      "Epoch 4097, Loss: 0.0007296772382687777, Final Batch Loss: 0.0\n",
      "Epoch 4098, Loss: 0.0004367235378595069, Final Batch Loss: 0.0\n",
      "Epoch 4099, Loss: 0.0010698279656935483, Final Batch Loss: 0.0\n",
      "Epoch 4100, Loss: 0.0021495805704034865, Final Batch Loss: 0.0\n",
      "Epoch 4101, Loss: 0.00025509339138807263, Final Batch Loss: 1.9311717551317997e-05\n",
      "Epoch 4102, Loss: 0.018019473500316963, Final Batch Loss: 0.0\n",
      "Epoch 4103, Loss: 0.0028178970678709447, Final Batch Loss: 0.0\n",
      "Epoch 4104, Loss: 0.0008710596594028175, Final Batch Loss: 0.0\n",
      "Epoch 4105, Loss: 0.0020183634842396714, Final Batch Loss: 0.0\n",
      "Epoch 4106, Loss: 0.000844037473143544, Final Batch Loss: 0.0\n",
      "Epoch 4107, Loss: 0.00047290419752243906, Final Batch Loss: 0.0\n",
      "Epoch 4108, Loss: 0.0014075160397624131, Final Batch Loss: 0.0\n",
      "Epoch 4109, Loss: 0.005635218461975455, Final Batch Loss: 0.0\n",
      "Epoch 4110, Loss: 0.0009147992595899268, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4111, Loss: 0.004071068276061851, Final Batch Loss: 0.0\n",
      "Epoch 4112, Loss: 0.014103284847806208, Final Batch Loss: 0.0\n",
      "Epoch 4113, Loss: 0.0018439770428813063, Final Batch Loss: 0.0\n",
      "Epoch 4114, Loss: 0.0058733629921334796, Final Batch Loss: 0.004069263115525246\n",
      "Epoch 4115, Loss: 0.015711024752818048, Final Batch Loss: 0.0\n",
      "Epoch 4116, Loss: 0.0011189620781806298, Final Batch Loss: 0.0\n",
      "Epoch 4117, Loss: 0.005875521987036336, Final Batch Loss: 0.0\n",
      "Epoch 4118, Loss: 0.017640547994233202, Final Batch Loss: 0.0\n",
      "Epoch 4119, Loss: 0.0008390431394218467, Final Batch Loss: 0.0\n",
      "Epoch 4120, Loss: 0.001218729328684276, Final Batch Loss: 0.0\n",
      "Epoch 4121, Loss: 0.0019273661309853196, Final Batch Loss: 0.0\n",
      "Epoch 4122, Loss: 0.0007386984652839601, Final Batch Loss: 0.0\n",
      "Epoch 4123, Loss: 0.0010880492045544088, Final Batch Loss: 0.0\n",
      "Epoch 4124, Loss: 0.0025913598074112087, Final Batch Loss: 0.0\n",
      "Epoch 4125, Loss: 0.0009778542735148221, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4126, Loss: 0.0003063142648898065, Final Batch Loss: 0.0\n",
      "Epoch 4127, Loss: 0.0014379574859049171, Final Batch Loss: 0.0\n",
      "Epoch 4128, Loss: 0.0010880620102327043, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4129, Loss: 0.01249075393207022, Final Batch Loss: 0.0\n",
      "Epoch 4130, Loss: 0.0010692243376979604, Final Batch Loss: 0.0\n",
      "Epoch 4131, Loss: 0.0021708103886339813, Final Batch Loss: 0.0\n",
      "Epoch 4132, Loss: 0.009616637536964845, Final Batch Loss: 0.0\n",
      "Epoch 4133, Loss: 0.007106167806341546, Final Batch Loss: 0.0\n",
      "Epoch 4134, Loss: 0.002376827054831665, Final Batch Loss: 0.0\n",
      "Epoch 4135, Loss: 0.0006389879890775774, Final Batch Loss: 0.0\n",
      "Epoch 4136, Loss: 0.016370059980545193, Final Batch Loss: 0.0\n",
      "Epoch 4137, Loss: 0.014454305244726129, Final Batch Loss: 0.0\n",
      "Epoch 4138, Loss: 0.022335174318868667, Final Batch Loss: 0.0\n",
      "Epoch 4139, Loss: 0.01468662466504611, Final Batch Loss: 0.0\n",
      "Epoch 4140, Loss: 0.0006518246154882945, Final Batch Loss: 0.0\n",
      "Epoch 4141, Loss: 0.002084318839479238, Final Batch Loss: 0.0\n",
      "Epoch 4142, Loss: 0.0021370372851379216, Final Batch Loss: 0.0\n",
      "Epoch 4143, Loss: 0.0013059253833489493, Final Batch Loss: 0.0\n",
      "Epoch 4144, Loss: 0.0007560292397101875, Final Batch Loss: 0.0\n",
      "Epoch 4145, Loss: 0.0009878870368993375, Final Batch Loss: 0.0\n",
      "Epoch 4146, Loss: 0.00120517353933991, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4147, Loss: 0.00048494310613023117, Final Batch Loss: 0.0\n",
      "Epoch 4148, Loss: 0.0009906615086947568, Final Batch Loss: 0.0\n",
      "Epoch 4149, Loss: 0.0009020183424581774, Final Batch Loss: 0.0\n",
      "Epoch 4150, Loss: 0.001288453466258943, Final Batch Loss: 0.0\n",
      "Epoch 4151, Loss: 0.002291500408318825, Final Batch Loss: 0.0\n",
      "Epoch 4152, Loss: 0.0023793327345629223, Final Batch Loss: 0.0\n",
      "Epoch 4153, Loss: 0.0021834047365700826, Final Batch Loss: 0.0\n",
      "Epoch 4154, Loss: 0.012922474648803473, Final Batch Loss: 0.0\n",
      "Epoch 4155, Loss: 0.0005287769236019813, Final Batch Loss: 0.0\n",
      "Epoch 4156, Loss: 0.003920494740668801, Final Batch Loss: 0.0\n",
      "Epoch 4157, Loss: 0.007812588469278126, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 4158, Loss: 0.0006318764462776016, Final Batch Loss: 0.0\n",
      "Epoch 4159, Loss: 0.007166736759245396, Final Batch Loss: 0.0037762064021080732\n",
      "Epoch 4160, Loss: 0.0012275232002139091, Final Batch Loss: 0.0\n",
      "Epoch 4161, Loss: 0.019470583560178056, Final Batch Loss: 0.0\n",
      "Epoch 4162, Loss: 0.015411064814543352, Final Batch Loss: 0.0\n",
      "Epoch 4163, Loss: 0.0005225790464464808, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 4164, Loss: 0.00141651581361657, Final Batch Loss: 0.0\n",
      "Epoch 4165, Loss: 0.0006063195251044817, Final Batch Loss: 0.0\n",
      "Epoch 4166, Loss: 0.004887526636593975, Final Batch Loss: 0.0\n",
      "Epoch 4167, Loss: 0.001059383896063082, Final Batch Loss: 0.0\n",
      "Epoch 4168, Loss: 0.001264630351215601, Final Batch Loss: 0.0\n",
      "Epoch 4169, Loss: 0.007435272331349552, Final Batch Loss: 0.0\n",
      "Epoch 4170, Loss: 0.004497774178162217, Final Batch Loss: 0.0\n",
      "Epoch 4171, Loss: 0.001006518959911773, Final Batch Loss: 0.0\n",
      "Epoch 4172, Loss: 0.002028817340033129, Final Batch Loss: 0.0\n",
      "Epoch 4173, Loss: 0.0007428832977893762, Final Batch Loss: 0.0\n",
      "Epoch 4174, Loss: 0.0019916144956368953, Final Batch Loss: 0.0\n",
      "Epoch 4175, Loss: 0.001920312934089452, Final Batch Loss: 0.0\n",
      "Epoch 4176, Loss: 0.0005076778834336437, Final Batch Loss: 0.0\n",
      "Epoch 4177, Loss: 0.0005064438628323842, Final Batch Loss: 0.0\n",
      "Epoch 4178, Loss: 0.0018279609212186188, Final Batch Loss: 0.0\n",
      "Epoch 4179, Loss: 0.0012023639137623832, Final Batch Loss: 0.0\n",
      "Epoch 4180, Loss: 0.0002236701138826902, Final Batch Loss: 0.0\n",
      "Epoch 4181, Loss: 0.0011498334242787678, Final Batch Loss: 0.0\n",
      "Epoch 4182, Loss: 0.024685654736458673, Final Batch Loss: 0.024439368396997452\n",
      "Epoch 4183, Loss: 0.014112489030594588, Final Batch Loss: 0.0\n",
      "Epoch 4184, Loss: 0.0011006678105331957, Final Batch Loss: 0.0\n",
      "Epoch 4185, Loss: 0.0009782064053069917, Final Batch Loss: 0.0\n",
      "Epoch 4186, Loss: 0.00027221954428569006, Final Batch Loss: 0.0\n",
      "Epoch 4187, Loss: 0.0011343032529111952, Final Batch Loss: 0.0\n",
      "Epoch 4188, Loss: 0.0018582497941679321, Final Batch Loss: 0.0\n",
      "Epoch 4189, Loss: 0.0006686210836051032, Final Batch Loss: 0.0\n",
      "Epoch 4190, Loss: 0.001121178749599494, Final Batch Loss: 0.0\n",
      "Epoch 4191, Loss: 0.00045249128959312657, Final Batch Loss: 0.0\n",
      "Epoch 4192, Loss: 0.00010084892892336939, Final Batch Loss: 0.0\n",
      "Epoch 4193, Loss: 0.0011271020416643296, Final Batch Loss: 0.0\n",
      "Epoch 4194, Loss: 0.0005813875377498334, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 4195, Loss: 0.012489572276990657, Final Batch Loss: 0.0\n",
      "Epoch 4196, Loss: 0.004929314745822921, Final Batch Loss: 0.0\n",
      "Epoch 4197, Loss: 0.0038888026610948145, Final Batch Loss: 0.0\n",
      "Epoch 4198, Loss: 0.003964468360209139, Final Batch Loss: 0.0\n",
      "Epoch 4199, Loss: 0.00045186024726717733, Final Batch Loss: 0.0\n",
      "Epoch 4200, Loss: 0.0010367852883064188, Final Batch Loss: 0.0\n",
      "Epoch 4201, Loss: 0.000964955470408313, Final Batch Loss: 0.0\n",
      "Epoch 4202, Loss: 0.002237094391603023, Final Batch Loss: 0.0\n",
      "Epoch 4203, Loss: 0.0039434744394384325, Final Batch Loss: 0.0\n",
      "Epoch 4204, Loss: 0.0014069730823393911, Final Batch Loss: 0.0\n",
      "Epoch 4205, Loss: 0.001161530992249027, Final Batch Loss: 0.0\n",
      "Epoch 4206, Loss: 0.0071201162645593286, Final Batch Loss: 0.0\n",
      "Epoch 4207, Loss: 0.0011434003681642935, Final Batch Loss: 0.0\n",
      "Epoch 4208, Loss: 0.0013393797271419317, Final Batch Loss: 0.0\n",
      "Epoch 4209, Loss: 0.005962517170701176, Final Batch Loss: 0.0\n",
      "Epoch 4210, Loss: 0.0003573584253899753, Final Batch Loss: 0.0\n",
      "Epoch 4211, Loss: 0.001055302047461737, Final Batch Loss: 0.0\n",
      "Epoch 4212, Loss: 0.000964213912084233, Final Batch Loss: 0.0\n",
      "Epoch 4213, Loss: 0.0005231558716332074, Final Batch Loss: 0.0\n",
      "Epoch 4214, Loss: 0.0010643040877766907, Final Batch Loss: 0.0\n",
      "Epoch 4215, Loss: 0.0010438995304866694, Final Batch Loss: 0.0\n",
      "Epoch 4216, Loss: 0.0006434075694414787, Final Batch Loss: 0.0\n",
      "Epoch 4217, Loss: 0.0003123740489172633, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 4218, Loss: 0.001158635423053056, Final Batch Loss: 0.0\n",
      "Epoch 4219, Loss: 0.0009321710094809532, Final Batch Loss: 0.0\n",
      "Epoch 4220, Loss: 0.01571884419536218, Final Batch Loss: 0.0\n",
      "Epoch 4221, Loss: 0.026578675939163077, Final Batch Loss: 0.0\n",
      "Epoch 4222, Loss: 0.013416697882348672, Final Batch Loss: 0.0\n",
      "Epoch 4223, Loss: 0.0011133987354696728, Final Batch Loss: 0.0\n",
      "Epoch 4224, Loss: 0.0007233782998810057, Final Batch Loss: 0.0\n",
      "Epoch 4225, Loss: 0.0026886361883953214, Final Batch Loss: 0.0\n",
      "Epoch 4226, Loss: 0.0018865841557271779, Final Batch Loss: 0.0\n",
      "Epoch 4227, Loss: 0.007721391655650223, Final Batch Loss: 0.0\n",
      "Epoch 4228, Loss: 0.003556725656380877, Final Batch Loss: 0.0\n",
      "Epoch 4229, Loss: 0.0015136106148929684, Final Batch Loss: 0.0\n",
      "Epoch 4230, Loss: 0.0023451110610039905, Final Batch Loss: 0.0\n",
      "Epoch 4231, Loss: 0.0031036552391014993, Final Batch Loss: 0.0012185298837721348\n",
      "Epoch 4232, Loss: 0.018521967150263663, Final Batch Loss: 0.0\n",
      "Epoch 4233, Loss: 0.04950221984836389, Final Batch Loss: 0.0\n",
      "Epoch 4234, Loss: 0.0010586851713014767, Final Batch Loss: 0.0\n",
      "Epoch 4235, Loss: 0.03217962650523987, Final Batch Loss: 0.0\n",
      "Epoch 4236, Loss: 0.0010707274268497713, Final Batch Loss: 0.0\n",
      "Epoch 4237, Loss: 0.02991538638525526, Final Batch Loss: 1.2397689715726301e-05\n",
      "Epoch 4238, Loss: 0.002617873760755174, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 4239, Loss: 0.0018640163107193075, Final Batch Loss: 0.0\n",
      "Epoch 4240, Loss: 0.0057008128023881, Final Batch Loss: 0.0\n",
      "Epoch 4241, Loss: 0.002521695932955481, Final Batch Loss: 0.0\n",
      "Epoch 4242, Loss: 0.006224234704859555, Final Batch Loss: 0.0\n",
      "Epoch 4243, Loss: 0.0007398333436867688, Final Batch Loss: 0.0\n",
      "Epoch 4244, Loss: 0.014363726833835244, Final Batch Loss: 0.0\n",
      "Epoch 4245, Loss: 0.002493866406439338, Final Batch Loss: 0.0\n",
      "Epoch 4246, Loss: 0.02402051787248638, Final Batch Loss: 0.0\n",
      "Epoch 4247, Loss: 0.0018284014522578218, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 4248, Loss: 0.0010580022790236399, Final Batch Loss: 0.0\n",
      "Epoch 4249, Loss: 0.0020508204615907744, Final Batch Loss: 0.0\n",
      "Epoch 4250, Loss: 0.0007888105537858792, Final Batch Loss: 0.0\n",
      "Epoch 4251, Loss: 0.0007686810749873985, Final Batch Loss: 0.0\n",
      "Epoch 4252, Loss: 0.001989128824789077, Final Batch Loss: 0.0\n",
      "Epoch 4253, Loss: 0.0012905488038086332, Final Batch Loss: 0.0\n",
      "Epoch 4254, Loss: 0.0022719487315043807, Final Batch Loss: 0.0\n",
      "Epoch 4255, Loss: 0.0008886639043339528, Final Batch Loss: 0.0\n",
      "Epoch 4256, Loss: 0.0002804017549351556, Final Batch Loss: 0.0\n",
      "Epoch 4257, Loss: 0.0010225077494396828, Final Batch Loss: 0.0\n",
      "Epoch 4258, Loss: 0.0032402143369836267, Final Batch Loss: 2.1576648578047752e-05\n",
      "Epoch 4259, Loss: 0.002512959952582605, Final Batch Loss: 0.0\n",
      "Epoch 4260, Loss: 0.0021872004290344194, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4261, Loss: 0.010787364208454164, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4262, Loss: 0.021296081802574918, Final Batch Loss: 0.0\n",
      "Epoch 4263, Loss: 0.0009614404698368162, Final Batch Loss: 0.0\n",
      "Epoch 4264, Loss: 0.001606762494020586, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 4265, Loss: 0.0005487910530064255, Final Batch Loss: 0.0\n",
      "Epoch 4266, Loss: 0.022790783343225485, Final Batch Loss: 0.0\n",
      "Epoch 4267, Loss: 0.0006956076103961095, Final Batch Loss: 0.0\n",
      "Epoch 4268, Loss: 0.0019212873357901117, Final Batch Loss: 0.0\n",
      "Epoch 4269, Loss: 0.0010096623445861042, Final Batch Loss: 0.0\n",
      "Epoch 4270, Loss: 0.00746088835876435, Final Batch Loss: 0.0\n",
      "Epoch 4271, Loss: 0.0015678623040003004, Final Batch Loss: 0.0\n",
      "Epoch 4272, Loss: 0.004799537651706487, Final Batch Loss: 0.0\n",
      "Epoch 4273, Loss: 0.009991624221584061, Final Batch Loss: 0.0\n",
      "Epoch 4274, Loss: 0.0003301889810245484, Final Batch Loss: 0.0\n",
      "Epoch 4275, Loss: 0.0012850001803599298, Final Batch Loss: 0.0\n",
      "Epoch 4276, Loss: 0.006416293530492112, Final Batch Loss: 0.0\n",
      "Epoch 4277, Loss: 0.0026528609450906515, Final Batch Loss: 0.0\n",
      "Epoch 4278, Loss: 0.0006417819313355722, Final Batch Loss: 0.0\n",
      "Epoch 4279, Loss: 0.0013057028409093618, Final Batch Loss: 0.0\n",
      "Epoch 4280, Loss: 0.012698703867499717, Final Batch Loss: 0.0\n",
      "Epoch 4281, Loss: 0.0030775962804909796, Final Batch Loss: 0.0\n",
      "Epoch 4282, Loss: 0.002506809774786234, Final Batch Loss: 0.0\n",
      "Epoch 4283, Loss: 0.0006134668874437921, Final Batch Loss: 0.0\n",
      "Epoch 4284, Loss: 0.0005735202503274195, Final Batch Loss: 0.0\n",
      "Epoch 4285, Loss: 0.0008297343961203296, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4286, Loss: 0.0006695065967505798, Final Batch Loss: 0.0\n",
      "Epoch 4287, Loss: 0.0059743872661783826, Final Batch Loss: 0.0\n",
      "Epoch 4288, Loss: 0.0018665187960777985, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4289, Loss: 0.0003899350995197892, Final Batch Loss: 0.0\n",
      "Epoch 4290, Loss: 0.0021805898286402225, Final Batch Loss: 0.0\n",
      "Epoch 4291, Loss: 0.00594351276231464, Final Batch Loss: 0.0\n",
      "Epoch 4292, Loss: 0.0012144825959410355, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4293, Loss: 0.0006262688330025412, Final Batch Loss: 2.109982233378105e-05\n",
      "Epoch 4294, Loss: 0.0021762552787549794, Final Batch Loss: 0.0\n",
      "Epoch 4295, Loss: 0.0012590339078997204, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 4296, Loss: 0.01763042057336861, Final Batch Loss: 0.0\n",
      "Epoch 4297, Loss: 0.0016182711260626093, Final Batch Loss: 0.0\n",
      "Epoch 4298, Loss: 0.0011481909605208784, Final Batch Loss: 0.0\n",
      "Epoch 4299, Loss: 0.00059884322945436, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 4300, Loss: 0.001924420750583522, Final Batch Loss: 0.0\n",
      "Epoch 4301, Loss: 0.05507965435390361, Final Batch Loss: 0.0\n",
      "Epoch 4302, Loss: 0.004603537031016458, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4303, Loss: 0.011900650302777649, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 4304, Loss: 0.002195475878806974, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 4305, Loss: 0.0036848631973498414, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4306, Loss: 0.014027393714059144, Final Batch Loss: 0.0\n",
      "Epoch 4307, Loss: 0.0015299194983526831, Final Batch Loss: 1.156323378381785e-05\n",
      "Epoch 4308, Loss: 0.001949058409081772, Final Batch Loss: 0.00010871296399272978\n",
      "Epoch 4309, Loss: 0.0012844834855059162, Final Batch Loss: 0.0\n",
      "Epoch 4310, Loss: 0.01906260931673387, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 4311, Loss: 0.0017549892654642463, Final Batch Loss: 0.0\n",
      "Epoch 4312, Loss: 0.0007514779936172999, Final Batch Loss: 0.0\n",
      "Epoch 4313, Loss: 0.0010332942911190912, Final Batch Loss: 0.0\n",
      "Epoch 4314, Loss: 0.0010581024398561567, Final Batch Loss: 0.0\n",
      "Epoch 4315, Loss: 0.0019843354675685987, Final Batch Loss: 0.0\n",
      "Epoch 4316, Loss: 0.0010288009798387066, Final Batch Loss: 0.0\n",
      "Epoch 4317, Loss: 0.033977730563492514, Final Batch Loss: 0.0\n",
      "Epoch 4318, Loss: 0.022123477712682416, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4319, Loss: 0.028665812817052938, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 4320, Loss: 0.0014031519822310656, Final Batch Loss: 0.0\n",
      "Epoch 4321, Loss: 0.002697614414501004, Final Batch Loss: 0.0\n",
      "Epoch 4322, Loss: 0.004840079924179008, Final Batch Loss: 0.0\n",
      "Epoch 4323, Loss: 0.0008174603644874878, Final Batch Loss: 7.331102824537084e-05\n",
      "Epoch 4324, Loss: 0.0007656488342036027, Final Batch Loss: 0.0\n",
      "Epoch 4325, Loss: 0.0007030209817457944, Final Batch Loss: 0.0\n",
      "Epoch 4326, Loss: 0.0010494610562545859, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 4327, Loss: 0.0038642244981019758, Final Batch Loss: 0.0\n",
      "Epoch 4328, Loss: 0.0008354860910344541, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4329, Loss: 0.0022719887201674283, Final Batch Loss: 0.00013910756388213485\n",
      "Epoch 4330, Loss: 0.001677159161090458, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 4331, Loss: 0.005843271443154663, Final Batch Loss: 0.0\n",
      "Epoch 4332, Loss: 0.0015161114715738222, Final Batch Loss: 0.0\n",
      "Epoch 4333, Loss: 0.02640763801173307, Final Batch Loss: 0.0\n",
      "Epoch 4334, Loss: 0.0011402050367905758, Final Batch Loss: 0.0\n",
      "Epoch 4335, Loss: 0.0011057202937081456, Final Batch Loss: 0.0\n",
      "Epoch 4336, Loss: 0.0024080894036160316, Final Batch Loss: 0.0\n",
      "Epoch 4337, Loss: 0.004260522546246648, Final Batch Loss: 0.0\n",
      "Epoch 4338, Loss: 0.0012043446040479466, Final Batch Loss: 0.0\n",
      "Epoch 4339, Loss: 0.013939270815171767, Final Batch Loss: 0.0\n",
      "Epoch 4340, Loss: 0.0009951908141374588, Final Batch Loss: 0.0\n",
      "Epoch 4341, Loss: 0.004013761456008069, Final Batch Loss: 0.0\n",
      "Epoch 4342, Loss: 0.000597212252614554, Final Batch Loss: 0.0\n",
      "Epoch 4343, Loss: 0.0004598775994963944, Final Batch Loss: 0.0\n",
      "Epoch 4344, Loss: 0.0011114580083813053, Final Batch Loss: 0.0\n",
      "Epoch 4345, Loss: 0.0016781412850832567, Final Batch Loss: 0.0\n",
      "Epoch 4346, Loss: 0.000701068540365668, Final Batch Loss: 0.0\n",
      "Epoch 4347, Loss: 0.0008382896994589828, Final Batch Loss: 0.0\n",
      "Epoch 4348, Loss: 0.002584513094916474, Final Batch Loss: 0.0\n",
      "Epoch 4349, Loss: 0.0007219092294690199, Final Batch Loss: 0.0\n",
      "Epoch 4350, Loss: 0.0032900120454542048, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 4351, Loss: 0.0011108292383141816, Final Batch Loss: 0.0\n",
      "Epoch 4352, Loss: 0.00676510515040718, Final Batch Loss: 0.0\n",
      "Epoch 4353, Loss: 0.011805353002273478, Final Batch Loss: 0.00016211149340961128\n",
      "Epoch 4354, Loss: 0.00022136202824185602, Final Batch Loss: 0.0\n",
      "Epoch 4355, Loss: 0.0011844675027532503, Final Batch Loss: 0.0\n",
      "Epoch 4356, Loss: 0.0008715896256035194, Final Batch Loss: 0.0\n",
      "Epoch 4357, Loss: 0.0004319803701946512, Final Batch Loss: 0.0\n",
      "Epoch 4358, Loss: 0.0005568140259128995, Final Batch Loss: 0.0\n",
      "Epoch 4359, Loss: 0.000771412109315861, Final Batch Loss: 0.0\n",
      "Epoch 4360, Loss: 0.0002376572520006448, Final Batch Loss: 0.0\n",
      "Epoch 4361, Loss: 0.002097231721506887, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4362, Loss: 0.00038379615580197424, Final Batch Loss: 0.0\n",
      "Epoch 4363, Loss: 0.0006116633739949862, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4364, Loss: 0.0007192446864792146, Final Batch Loss: 0.0\n",
      "Epoch 4365, Loss: 0.000188172532034514, Final Batch Loss: 0.0\n",
      "Epoch 4366, Loss: 0.0013867884808860254, Final Batch Loss: 0.0\n",
      "Epoch 4367, Loss: 0.0011136220127809793, Final Batch Loss: 0.0\n",
      "Epoch 4368, Loss: 0.0007817743507985142, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 4369, Loss: 0.021827307600688073, Final Batch Loss: 0.0\n",
      "Epoch 4370, Loss: 0.0005883496996830218, Final Batch Loss: 0.0\n",
      "Epoch 4371, Loss: 0.000286427530227229, Final Batch Loss: 0.0\n",
      "Epoch 4372, Loss: 0.0026711155078089632, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4373, Loss: 0.005216146710154135, Final Batch Loss: 0.0\n",
      "Epoch 4374, Loss: 0.0019811084493994713, Final Batch Loss: 0.0\n",
      "Epoch 4375, Loss: 0.0008182376259355806, Final Batch Loss: 0.0\n",
      "Epoch 4376, Loss: 0.0003735287391464226, Final Batch Loss: 0.0\n",
      "Epoch 4377, Loss: 0.0010013319551944733, Final Batch Loss: 0.0\n",
      "Epoch 4378, Loss: 0.001821038720663637, Final Batch Loss: 0.0\n",
      "Epoch 4379, Loss: 0.0014668710573459975, Final Batch Loss: 0.0\n",
      "Epoch 4380, Loss: 0.002021400723606348, Final Batch Loss: 0.0\n",
      "Epoch 4381, Loss: 0.05009570957918186, Final Batch Loss: 0.0\n",
      "Epoch 4382, Loss: 0.0012634939921554178, Final Batch Loss: 0.0\n",
      "Epoch 4383, Loss: 0.002179214818170294, Final Batch Loss: 0.0\n",
      "Epoch 4384, Loss: 0.0004833589482586831, Final Batch Loss: 0.0\n",
      "Epoch 4385, Loss: 0.0007099299800685799, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4386, Loss: 0.0020223838509991765, Final Batch Loss: 0.0\n",
      "Epoch 4387, Loss: 0.0005867906729690731, Final Batch Loss: 0.0\n",
      "Epoch 4388, Loss: 0.002687307871383382, Final Batch Loss: 0.0\n",
      "Epoch 4389, Loss: 0.004537580098258331, Final Batch Loss: 0.0019431296968832612\n",
      "Epoch 4390, Loss: 0.0006732160691171885, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4391, Loss: 0.011083220335422084, Final Batch Loss: 0.0\n",
      "Epoch 4392, Loss: 0.001102122121665161, Final Batch Loss: 0.0\n",
      "Epoch 4393, Loss: 0.0019239691464463249, Final Batch Loss: 0.0\n",
      "Epoch 4394, Loss: 0.0022137706982903183, Final Batch Loss: 0.0\n",
      "Epoch 4395, Loss: 0.0013571754352526, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4396, Loss: 0.0022606249840464443, Final Batch Loss: 0.0\n",
      "Epoch 4397, Loss: 0.0010883200409352867, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 4398, Loss: 0.008266296455985866, Final Batch Loss: 0.001903866184875369\n",
      "Epoch 4399, Loss: 0.0008005550116578775, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4400, Loss: 0.0010189636113864253, Final Batch Loss: 0.0\n",
      "Epoch 4401, Loss: 0.011306953354505822, Final Batch Loss: 0.0\n",
      "Epoch 4402, Loss: 0.00024496040350641124, Final Batch Loss: 0.0\n",
      "Epoch 4403, Loss: 0.0006115712021710351, Final Batch Loss: 0.0\n",
      "Epoch 4404, Loss: 0.0037169392744544894, Final Batch Loss: 0.0\n",
      "Epoch 4405, Loss: 0.0016432074480690062, Final Batch Loss: 0.0\n",
      "Epoch 4406, Loss: 0.05851173470728099, Final Batch Loss: 0.05788540095090866\n",
      "Epoch 4407, Loss: 0.0006800561204727273, Final Batch Loss: 0.0\n",
      "Epoch 4408, Loss: 0.0004012975041405298, Final Batch Loss: 0.0\n",
      "Epoch 4409, Loss: 0.004830470657907426, Final Batch Loss: 0.0\n",
      "Epoch 4410, Loss: 0.005267726302918163, Final Batch Loss: 0.0\n",
      "Epoch 4411, Loss: 0.0015734993503428996, Final Batch Loss: 0.0\n",
      "Epoch 4412, Loss: 0.002386831820331281, Final Batch Loss: 0.0\n",
      "Epoch 4413, Loss: 0.0009701643102744129, Final Batch Loss: 4.51792984677013e-05\n",
      "Epoch 4414, Loss: 0.0022300106429611333, Final Batch Loss: 0.0\n",
      "Epoch 4415, Loss: 0.004887748582397933, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4416, Loss: 0.005481918509758543, Final Batch Loss: 0.0\n",
      "Epoch 4417, Loss: 0.017786223237635568, Final Batch Loss: 0.0\n",
      "Epoch 4418, Loss: 0.0008912103512486169, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4419, Loss: 0.0019378286524442956, Final Batch Loss: 0.0\n",
      "Epoch 4420, Loss: 0.0025808871432673186, Final Batch Loss: 0.0\n",
      "Epoch 4421, Loss: 0.0008700973630766384, Final Batch Loss: 0.0\n",
      "Epoch 4422, Loss: 0.0014360431378008798, Final Batch Loss: 0.0\n",
      "Epoch 4423, Loss: 0.003933850755856838, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 4424, Loss: 0.0002907313460127625, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 4425, Loss: 0.001446576529815502, Final Batch Loss: 0.0\n",
      "Epoch 4426, Loss: 0.003344404452946037, Final Batch Loss: 0.0\n",
      "Epoch 4427, Loss: 0.0003967986904171994, Final Batch Loss: 7.462222856702283e-05\n",
      "Epoch 4428, Loss: 0.05164185352259665, Final Batch Loss: 0.05129151791334152\n",
      "Epoch 4429, Loss: 0.0001494158686909941, Final Batch Loss: 0.0\n",
      "Epoch 4430, Loss: 0.0012844589509768412, Final Batch Loss: 0.0\n",
      "Epoch 4431, Loss: 0.006234808408407844, Final Batch Loss: 0.0\n",
      "Epoch 4432, Loss: 0.0001910102855617879, Final Batch Loss: 0.0\n",
      "Epoch 4433, Loss: 0.00022836964853922836, Final Batch Loss: 0.0\n",
      "Epoch 4434, Loss: 0.0003596748765630764, Final Batch Loss: 0.0\n",
      "Epoch 4435, Loss: 0.0018799642712110654, Final Batch Loss: 0.0\n",
      "Epoch 4436, Loss: 0.0007686282915528864, Final Batch Loss: 0.0\n",
      "Epoch 4437, Loss: 0.0005372670311771799, Final Batch Loss: 0.0\n",
      "Epoch 4438, Loss: 0.0003352952771820128, Final Batch Loss: 0.0\n",
      "Epoch 4439, Loss: 0.00015268970037141116, Final Batch Loss: 0.0\n",
      "Epoch 4440, Loss: 0.00040111122507369146, Final Batch Loss: 0.0\n",
      "Epoch 4441, Loss: 0.0019564713948057033, Final Batch Loss: 0.0\n",
      "Epoch 4442, Loss: 0.0006560478723258711, Final Batch Loss: 0.0\n",
      "Epoch 4443, Loss: 0.00043339173862477764, Final Batch Loss: 0.0\n",
      "Epoch 4444, Loss: 0.0005910737891099416, Final Batch Loss: 0.0\n",
      "Epoch 4445, Loss: 0.000500060110425693, Final Batch Loss: 1.2516897186287679e-05\n",
      "Epoch 4446, Loss: 0.017909662066813326, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 4447, Loss: 0.007343412842601538, Final Batch Loss: 0.0006176709430292249\n",
      "Epoch 4448, Loss: 0.007899992939201184, Final Batch Loss: 0.0\n",
      "Epoch 4449, Loss: 0.00027337318533682264, Final Batch Loss: 0.0\n",
      "Epoch 4450, Loss: 0.016789178509498015, Final Batch Loss: 0.0\n",
      "Epoch 4451, Loss: 0.008408708265051246, Final Batch Loss: 0.0\n",
      "Epoch 4452, Loss: 0.005017228162614629, Final Batch Loss: 0.0\n",
      "Epoch 4453, Loss: 0.00019650664034998044, Final Batch Loss: 0.0\n",
      "Epoch 4454, Loss: 0.002595852674858179, Final Batch Loss: 0.0\n",
      "Epoch 4455, Loss: 0.0010245314188068733, Final Batch Loss: 0.0\n",
      "Epoch 4456, Loss: 0.0003385953932593111, Final Batch Loss: 0.0\n",
      "Epoch 4457, Loss: 0.0002199749360443093, Final Batch Loss: 0.0\n",
      "Epoch 4458, Loss: 0.001152632092271233, Final Batch Loss: 0.0\n",
      "Epoch 4459, Loss: 0.052632777093094774, Final Batch Loss: 0.0\n",
      "Epoch 4460, Loss: 0.004550313504296355, Final Batch Loss: 0.0\n",
      "Epoch 4461, Loss: 0.0009316232171840966, Final Batch Loss: 0.0\n",
      "Epoch 4462, Loss: 0.0007147947544581257, Final Batch Loss: 0.0\n",
      "Epoch 4463, Loss: 0.01606036203156691, Final Batch Loss: 0.0\n",
      "Epoch 4464, Loss: 0.0010278150148224086, Final Batch Loss: 0.0\n",
      "Epoch 4465, Loss: 0.0006260983282118104, Final Batch Loss: 0.0\n",
      "Epoch 4466, Loss: 0.0010825201170518994, Final Batch Loss: 0.0\n",
      "Epoch 4467, Loss: 0.0006832710860180669, Final Batch Loss: 0.0\n",
      "Epoch 4468, Loss: 0.014031353013706394, Final Batch Loss: 0.0\n",
      "Epoch 4469, Loss: 0.031078940257430077, Final Batch Loss: 0.0\n",
      "Epoch 4470, Loss: 0.0011338495532982051, Final Batch Loss: 0.0\n",
      "Epoch 4471, Loss: 0.011592595728870947, Final Batch Loss: 0.0\n",
      "Epoch 4472, Loss: 0.0006197552023650132, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4473, Loss: 0.0013084879610687494, Final Batch Loss: 0.0\n",
      "Epoch 4474, Loss: 0.002319014020031318, Final Batch Loss: 0.0\n",
      "Epoch 4475, Loss: 0.0024510612419135214, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4476, Loss: 0.0005320925229170825, Final Batch Loss: 0.0\n",
      "Epoch 4477, Loss: 0.002458760660374537, Final Batch Loss: 0.0\n",
      "Epoch 4478, Loss: 0.001166941481642425, Final Batch Loss: 0.0\n",
      "Epoch 4479, Loss: 0.0032991469124681316, Final Batch Loss: 0.0\n",
      "Epoch 4480, Loss: 0.014503141093882732, Final Batch Loss: 0.0\n",
      "Epoch 4481, Loss: 0.039720063876274025, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4482, Loss: 0.0006715959571010899, Final Batch Loss: 0.0\n",
      "Epoch 4483, Loss: 0.0008025352763070259, Final Batch Loss: 0.0\n",
      "Epoch 4484, Loss: 0.010391180418082513, Final Batch Loss: 0.0\n",
      "Epoch 4485, Loss: 0.014743479907338042, Final Batch Loss: 0.0\n",
      "Epoch 4486, Loss: 0.0007550110058218706, Final Batch Loss: 0.0\n",
      "Epoch 4487, Loss: 0.004550012614345178, Final Batch Loss: 0.0\n",
      "Epoch 4488, Loss: 0.0021015046950196847, Final Batch Loss: 0.0\n",
      "Epoch 4489, Loss: 0.001035099229284242, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 4490, Loss: 0.0003337199304951355, Final Batch Loss: 0.0\n",
      "Epoch 4491, Loss: 0.00029181959322954754, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4492, Loss: 0.00461878761780099, Final Batch Loss: 0.002179629635065794\n",
      "Epoch 4493, Loss: 0.003812813578406349, Final Batch Loss: 0.0\n",
      "Epoch 4494, Loss: 0.0006674580290564336, Final Batch Loss: 0.0\n",
      "Epoch 4495, Loss: 0.0011836335543193854, Final Batch Loss: 0.0\n",
      "Epoch 4496, Loss: 0.0012758076991303824, Final Batch Loss: 0.0\n",
      "Epoch 4497, Loss: 0.002553377104050014, Final Batch Loss: 0.0\n",
      "Epoch 4498, Loss: 0.0012835534289479256, Final Batch Loss: 0.0\n",
      "Epoch 4499, Loss: 0.0010813006665557623, Final Batch Loss: 0.0\n",
      "Epoch 4500, Loss: 0.0008092337229754776, Final Batch Loss: 0.0\n",
      "Epoch 4501, Loss: 0.0008861315145622939, Final Batch Loss: 0.0\n",
      "Epoch 4502, Loss: 0.002535449340939522, Final Batch Loss: 0.0\n",
      "Epoch 4503, Loss: 0.0012973754928680137, Final Batch Loss: 0.0\n",
      "Epoch 4504, Loss: 0.0004745694459415972, Final Batch Loss: 0.0\n",
      "Epoch 4505, Loss: 0.0013376379642977554, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4506, Loss: 0.00036065148742636666, Final Batch Loss: 0.0\n",
      "Epoch 4507, Loss: 0.004022631008410826, Final Batch Loss: 0.0\n",
      "Epoch 4508, Loss: 0.00137375654776406, Final Batch Loss: 0.0\n",
      "Epoch 4509, Loss: 0.000919946742214961, Final Batch Loss: 0.0\n",
      "Epoch 4510, Loss: 0.003172731143422425, Final Batch Loss: 0.0\n",
      "Epoch 4511, Loss: 0.00048506528219149914, Final Batch Loss: 0.0\n",
      "Epoch 4512, Loss: 0.0005045515245001297, Final Batch Loss: 0.0\n",
      "Epoch 4513, Loss: 0.0015309485461330041, Final Batch Loss: 0.0\n",
      "Epoch 4514, Loss: 0.0008888772572390735, Final Batch Loss: 0.0\n",
      "Epoch 4515, Loss: 0.0007361047028027201, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4516, Loss: 0.0005227306683082134, Final Batch Loss: 0.0\n",
      "Epoch 4517, Loss: 0.0007505031244363636, Final Batch Loss: 0.0\n",
      "Epoch 4518, Loss: 0.00024497779668308794, Final Batch Loss: 0.0\n",
      "Epoch 4519, Loss: 0.0001469513063057093, Final Batch Loss: 0.0\n",
      "Epoch 4520, Loss: 0.00882636169262696, Final Batch Loss: 1.1444026313256472e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4521, Loss: 0.002966661430008344, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4522, Loss: 0.012900881449240842, Final Batch Loss: 0.0\n",
      "Epoch 4523, Loss: 0.04407589584297966, Final Batch Loss: 0.02378642000257969\n",
      "Epoch 4524, Loss: 0.0051391213621627685, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4525, Loss: 0.00044538391375681385, Final Batch Loss: 0.0\n",
      "Epoch 4526, Loss: 0.0024790119241444586, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4527, Loss: 0.0005230806473193184, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4528, Loss: 0.0011390264116926119, Final Batch Loss: 0.0\n",
      "Epoch 4529, Loss: 0.0014438374346354976, Final Batch Loss: 0.0\n",
      "Epoch 4530, Loss: 0.0026718045919551514, Final Batch Loss: 0.0\n",
      "Epoch 4531, Loss: 0.0009750939652803936, Final Batch Loss: 0.0\n",
      "Epoch 4532, Loss: 0.00029063966758258175, Final Batch Loss: 0.0\n",
      "Epoch 4533, Loss: 0.0016207859407586511, Final Batch Loss: 0.0\n",
      "Epoch 4534, Loss: 0.0011189623292011674, Final Batch Loss: 0.0\n",
      "Epoch 4535, Loss: 0.00035874961758963764, Final Batch Loss: 0.0\n",
      "Epoch 4536, Loss: 0.00025979167367040645, Final Batch Loss: 0.0\n",
      "Epoch 4537, Loss: 0.0007417743618134409, Final Batch Loss: 0.0\n",
      "Epoch 4538, Loss: 0.0014160837527015246, Final Batch Loss: 0.0\n",
      "Epoch 4539, Loss: 0.00021498825390153797, Final Batch Loss: 2.7417760065873154e-05\n",
      "Epoch 4540, Loss: 0.0006104528993091662, Final Batch Loss: 0.0\n",
      "Epoch 4541, Loss: 0.0010014232284447644, Final Batch Loss: 0.0\n",
      "Epoch 4542, Loss: 0.0005509523980435915, Final Batch Loss: 0.0\n",
      "Epoch 4543, Loss: 0.007016483890765812, Final Batch Loss: 0.0\n",
      "Epoch 4544, Loss: 0.0014137587895675097, Final Batch Loss: 0.0\n",
      "Epoch 4545, Loss: 7.359819755947683e-05, Final Batch Loss: 0.0\n",
      "Epoch 4546, Loss: 0.0013274850562083884, Final Batch Loss: 0.0\n",
      "Epoch 4547, Loss: 0.003418330449676432, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 4548, Loss: 0.00035517381911631674, Final Batch Loss: 4.851700214203447e-05\n",
      "Epoch 4549, Loss: 0.0006223354284884408, Final Batch Loss: 0.0\n",
      "Epoch 4550, Loss: 0.0004274475068086758, Final Batch Loss: 0.0\n",
      "Epoch 4551, Loss: 0.024998585649882443, Final Batch Loss: 0.0\n",
      "Epoch 4552, Loss: 0.0003643744703367702, Final Batch Loss: 0.0\n",
      "Epoch 4553, Loss: 0.0007710421159572434, Final Batch Loss: 0.0\n",
      "Epoch 4554, Loss: 0.00023587206669617444, Final Batch Loss: 0.0\n",
      "Epoch 4555, Loss: 0.007264016603585333, Final Batch Loss: 0.0\n",
      "Epoch 4556, Loss: 0.014315185479063075, Final Batch Loss: 0.0\n",
      "Epoch 4557, Loss: 0.0018392278179817367, Final Batch Loss: 0.0\n",
      "Epoch 4558, Loss: 0.022783552689361386, Final Batch Loss: 0.0\n",
      "Epoch 4559, Loss: 0.0023590131459059194, Final Batch Loss: 0.0\n",
      "Epoch 4560, Loss: 0.002560723340138793, Final Batch Loss: 0.0\n",
      "Epoch 4561, Loss: 0.0006761260701750871, Final Batch Loss: 0.0\n",
      "Epoch 4562, Loss: 0.00042301231951569207, Final Batch Loss: 0.0\n",
      "Epoch 4563, Loss: 0.0002412489575362997, Final Batch Loss: 0.0\n",
      "Epoch 4564, Loss: 0.0014115506783127785, Final Batch Loss: 0.0\n",
      "Epoch 4565, Loss: 0.0013146780784154544, Final Batch Loss: 0.0\n",
      "Epoch 4566, Loss: 0.00011037638614652678, Final Batch Loss: 0.0\n",
      "Epoch 4567, Loss: 0.0008354411584150512, Final Batch Loss: 0.0\n",
      "Epoch 4568, Loss: 0.0005982720358588267, Final Batch Loss: 0.0\n",
      "Epoch 4569, Loss: 0.00041688299825182185, Final Batch Loss: 0.0\n",
      "Epoch 4570, Loss: 0.0001389006788485858, Final Batch Loss: 0.0\n",
      "Epoch 4571, Loss: 0.0012063383660461113, Final Batch Loss: 0.0\n",
      "Epoch 4572, Loss: 0.0004298907879203284, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4573, Loss: 0.00022264148537942674, Final Batch Loss: 0.0\n",
      "Epoch 4574, Loss: 0.0001354326509499515, Final Batch Loss: 0.0\n",
      "Epoch 4575, Loss: 0.00045369081635726616, Final Batch Loss: 0.0\n",
      "Epoch 4576, Loss: 0.0006473812136391643, Final Batch Loss: 0.0\n",
      "Epoch 4577, Loss: 0.0005001775853088475, Final Batch Loss: 0.0\n",
      "Epoch 4578, Loss: 0.005958881956757978, Final Batch Loss: 0.0\n",
      "Epoch 4579, Loss: 0.002004070054681506, Final Batch Loss: 0.0\n",
      "Epoch 4580, Loss: 0.0002621014973556157, Final Batch Loss: 0.0\n",
      "Epoch 4581, Loss: 0.0005705424191546626, Final Batch Loss: 0.0\n",
      "Epoch 4582, Loss: 0.004855178238358349, Final Batch Loss: 0.0\n",
      "Epoch 4583, Loss: 0.0006371382187353447, Final Batch Loss: 0.0\n",
      "Epoch 4584, Loss: 0.00036069803491045604, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4585, Loss: 0.006628716640989296, Final Batch Loss: 0.0\n",
      "Epoch 4586, Loss: 0.0009208754345308989, Final Batch Loss: 0.0\n",
      "Epoch 4587, Loss: 0.00042196048161713406, Final Batch Loss: 0.0\n",
      "Epoch 4588, Loss: 0.005204250379392761, Final Batch Loss: 0.0\n",
      "Epoch 4589, Loss: 0.026782308457768522, Final Batch Loss: 0.0\n",
      "Epoch 4590, Loss: 0.00042550954822218046, Final Batch Loss: 0.0\n",
      "Epoch 4591, Loss: 0.0005113958213769365, Final Batch Loss: 0.0\n",
      "Epoch 4592, Loss: 0.0009835552500589984, Final Batch Loss: 0.0\n",
      "Epoch 4593, Loss: 0.0003723693334904965, Final Batch Loss: 0.0\n",
      "Epoch 4594, Loss: 0.0005384241267165635, Final Batch Loss: 0.0\n",
      "Epoch 4595, Loss: 0.000824599715997465, Final Batch Loss: 0.0\n",
      "Epoch 4596, Loss: 0.00036310420682639233, Final Batch Loss: 6.6756979322235566e-06\n",
      "Epoch 4597, Loss: 0.00016581602903897874, Final Batch Loss: 0.0\n",
      "Epoch 4598, Loss: 0.010607912895466143, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 4599, Loss: 0.0008353654575330438, Final Batch Loss: 0.0\n",
      "Epoch 4600, Loss: 0.0012570458347909153, Final Batch Loss: 0.0\n",
      "Epoch 4601, Loss: 0.0008656916907057166, Final Batch Loss: 0.0\n",
      "Epoch 4602, Loss: 0.0007649547487744712, Final Batch Loss: 0.0\n",
      "Epoch 4603, Loss: 0.0003241195390728535, Final Batch Loss: 0.0\n",
      "Epoch 4604, Loss: 0.011706106801284477, Final Batch Loss: 0.0\n",
      "Epoch 4605, Loss: 0.0034586597794259433, Final Batch Loss: 0.0\n",
      "Epoch 4606, Loss: 0.0004002636051083641, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4607, Loss: 0.000991100807368639, Final Batch Loss: 0.0\n",
      "Epoch 4608, Loss: 0.0006566506308445241, Final Batch Loss: 0.00014733182615600526\n",
      "Epoch 4609, Loss: 0.0010303912276867777, Final Batch Loss: 0.0\n",
      "Epoch 4610, Loss: 0.0012570209237310337, Final Batch Loss: 0.0\n",
      "Epoch 4611, Loss: 0.003065083466935903, Final Batch Loss: 0.0\n",
      "Epoch 4612, Loss: 0.0007459375920007005, Final Batch Loss: 0.0\n",
      "Epoch 4613, Loss: 0.00029660718428203836, Final Batch Loss: 0.0\n",
      "Epoch 4614, Loss: 0.0003847611556011543, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4615, Loss: 0.000684697661199607, Final Batch Loss: 0.0\n",
      "Epoch 4616, Loss: 0.0028064454800187377, Final Batch Loss: 0.0\n",
      "Epoch 4617, Loss: 0.0001347966763205477, Final Batch Loss: 0.0\n",
      "Epoch 4618, Loss: 0.0001868267008831026, Final Batch Loss: 0.0\n",
      "Epoch 4619, Loss: 9.205799869960174e-05, Final Batch Loss: 0.0\n",
      "Epoch 4620, Loss: 0.0003667145501822233, Final Batch Loss: 0.0\n",
      "Epoch 4621, Loss: 0.005855527600942878, Final Batch Loss: 0.0\n",
      "Epoch 4622, Loss: 0.0005310404667397961, Final Batch Loss: 0.0\n",
      "Epoch 4623, Loss: 0.003204336873750435, Final Batch Loss: 0.0\n",
      "Epoch 4624, Loss: 0.0008205387493944727, Final Batch Loss: 0.0\n",
      "Epoch 4625, Loss: 0.004502108145970851, Final Batch Loss: 0.0\n",
      "Epoch 4626, Loss: 0.00033996832826233003, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 4627, Loss: 0.0009094769920920953, Final Batch Loss: 0.0\n",
      "Epoch 4628, Loss: 0.0005810220318380743, Final Batch Loss: 0.0\n",
      "Epoch 4629, Loss: 0.00040075048309518024, Final Batch Loss: 0.0\n",
      "Epoch 4630, Loss: 0.0007567434895463521, Final Batch Loss: 0.0\n",
      "Epoch 4631, Loss: 0.0012399349893712497, Final Batch Loss: 0.0\n",
      "Epoch 4632, Loss: 0.000279284149655723, Final Batch Loss: 0.0\n",
      "Epoch 4633, Loss: 0.0002730078495005728, Final Batch Loss: 0.0\n",
      "Epoch 4634, Loss: 0.0010742363592726178, Final Batch Loss: 0.0\n",
      "Epoch 4635, Loss: 0.0182077931529534, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4636, Loss: 0.001315298955887556, Final Batch Loss: 0.0\n",
      "Epoch 4637, Loss: 0.00038128990308905486, Final Batch Loss: 0.0\n",
      "Epoch 4638, Loss: 0.0007424585201079026, Final Batch Loss: 0.0\n",
      "Epoch 4639, Loss: 0.0002472746346029453, Final Batch Loss: 0.0\n",
      "Epoch 4640, Loss: 0.0007201727712526917, Final Batch Loss: 0.0\n",
      "Epoch 4641, Loss: 0.0003154033565806458, Final Batch Loss: 0.0\n",
      "Epoch 4642, Loss: 0.0004582645124102669, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4643, Loss: 0.0008660805688123219, Final Batch Loss: 0.0\n",
      "Epoch 4644, Loss: 0.0004940193321090192, Final Batch Loss: 0.0\n",
      "Epoch 4645, Loss: 0.00027422223683970515, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4646, Loss: 0.00467312684531862, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4647, Loss: 0.00022174032528710086, Final Batch Loss: 0.0\n",
      "Epoch 4648, Loss: 0.0004935438319080276, Final Batch Loss: 0.0\n",
      "Epoch 4649, Loss: 0.00110530924575869, Final Batch Loss: 0.0\n",
      "Epoch 4650, Loss: 0.00020890381529170554, Final Batch Loss: 0.0\n",
      "Epoch 4651, Loss: 0.0008146919608407188, Final Batch Loss: 0.0\n",
      "Epoch 4652, Loss: 0.007569413851797435, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 4653, Loss: 0.0009668748571129981, Final Batch Loss: 0.0\n",
      "Epoch 4654, Loss: 0.040337168552923686, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4655, Loss: 0.011347623800247675, Final Batch Loss: 0.0\n",
      "Epoch 4656, Loss: 0.0005846582569120073, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4657, Loss: 0.028813331678975374, Final Batch Loss: 0.0\n",
      "Epoch 4658, Loss: 0.0006091361319704447, Final Batch Loss: 0.0\n",
      "Epoch 4659, Loss: 0.0011097287488155416, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4660, Loss: 0.002672705792065244, Final Batch Loss: 0.0\n",
      "Epoch 4661, Loss: 0.007741840301605407, Final Batch Loss: 0.0\n",
      "Epoch 4662, Loss: 0.007924964298581472, Final Batch Loss: 0.0\n",
      "Epoch 4663, Loss: 0.044430757841837476, Final Batch Loss: 2.47952248173533e-05\n",
      "Epoch 4664, Loss: 0.008146362607476476, Final Batch Loss: 0.0\n",
      "Epoch 4665, Loss: 0.007242926309089626, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4666, Loss: 0.01902006879390683, Final Batch Loss: 0.0\n",
      "Epoch 4667, Loss: 0.0009478788997512311, Final Batch Loss: 0.0\n",
      "Epoch 4668, Loss: 0.0020304950812715106, Final Batch Loss: 0.0\n",
      "Epoch 4669, Loss: 0.0011811690346803516, Final Batch Loss: 0.0\n",
      "Epoch 4670, Loss: 0.0021255287791746014, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4671, Loss: 0.02505734481383115, Final Batch Loss: 0.0\n",
      "Epoch 4672, Loss: 0.0008691743605595548, Final Batch Loss: 0.0\n",
      "Epoch 4673, Loss: 0.000729788145662269, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4674, Loss: 0.012406598278175807, Final Batch Loss: 0.0\n",
      "Epoch 4675, Loss: 0.0020452488388400525, Final Batch Loss: 0.0\n",
      "Epoch 4676, Loss: 0.0021098293069599094, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4677, Loss: 0.0007807061265339144, Final Batch Loss: 0.0\n",
      "Epoch 4678, Loss: 0.0061239623464643955, Final Batch Loss: 0.003971666097640991\n",
      "Epoch 4679, Loss: 0.007162238005548716, Final Batch Loss: 0.0\n",
      "Epoch 4680, Loss: 0.0004329695657361299, Final Batch Loss: 5.030505417380482e-05\n",
      "Epoch 4681, Loss: 0.0012074630794813856, Final Batch Loss: 0.0\n",
      "Epoch 4682, Loss: 0.002960151730803773, Final Batch Loss: 0.0\n",
      "Epoch 4683, Loss: 0.0007657453243155032, Final Batch Loss: 0.0\n",
      "Epoch 4684, Loss: 0.001278812123928219, Final Batch Loss: 0.0\n",
      "Epoch 4685, Loss: 0.003040843512280844, Final Batch Loss: 0.0\n",
      "Epoch 4686, Loss: 0.0010654648867785, Final Batch Loss: 0.0\n",
      "Epoch 4687, Loss: 0.0014452338182309177, Final Batch Loss: 5.817244164063595e-05\n",
      "Epoch 4688, Loss: 0.0024815225042402744, Final Batch Loss: 0.0\n",
      "Epoch 4689, Loss: 0.0007562815299024805, Final Batch Loss: 0.0\n",
      "Epoch 4690, Loss: 0.005846516360179521, Final Batch Loss: 0.0\n",
      "Epoch 4691, Loss: 0.0011810274445451796, Final Batch Loss: 0.0\n",
      "Epoch 4692, Loss: 0.0059177375078434125, Final Batch Loss: 0.0\n",
      "Epoch 4693, Loss: 0.02110155875561759, Final Batch Loss: 0.0\n",
      "Epoch 4694, Loss: 0.0015482218841498252, Final Batch Loss: 0.0\n",
      "Epoch 4695, Loss: 0.0023198300659714732, Final Batch Loss: 0.0\n",
      "Epoch 4696, Loss: 0.0013287983747432008, Final Batch Loss: 0.0\n",
      "Epoch 4697, Loss: 0.0014271231266036466, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4698, Loss: 0.001464687375118956, Final Batch Loss: 0.0\n",
      "Epoch 4699, Loss: 0.005912009364692494, Final Batch Loss: 0.0\n",
      "Epoch 4700, Loss: 0.0020289893582230434, Final Batch Loss: 0.0\n",
      "Epoch 4701, Loss: 0.00036473057480179705, Final Batch Loss: 0.0\n",
      "Epoch 4702, Loss: 0.0009226356633007526, Final Batch Loss: 0.0\n",
      "Epoch 4703, Loss: 0.030273213216332806, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4704, Loss: 0.0006493157416116446, Final Batch Loss: 0.0\n",
      "Epoch 4705, Loss: 0.00121009844042419, Final Batch Loss: 0.0\n",
      "Epoch 4706, Loss: 0.0040340124687645584, Final Batch Loss: 0.0\n",
      "Epoch 4707, Loss: 0.0006994116520147031, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4708, Loss: 0.000824515416752547, Final Batch Loss: 0.0\n",
      "Epoch 4709, Loss: 0.001119240107072983, Final Batch Loss: 0.0\n",
      "Epoch 4710, Loss: 0.0006838390982011333, Final Batch Loss: 0.0\n",
      "Epoch 4711, Loss: 0.0003199734528607223, Final Batch Loss: 0.0\n",
      "Epoch 4712, Loss: 0.001417755258444231, Final Batch Loss: 0.0\n",
      "Epoch 4713, Loss: 0.0016211950496654026, Final Batch Loss: 0.0\n",
      "Epoch 4714, Loss: 0.0004630434777936898, Final Batch Loss: 0.0\n",
      "Epoch 4715, Loss: 0.0003032067761523649, Final Batch Loss: 0.0\n",
      "Epoch 4716, Loss: 0.0008974377124104649, Final Batch Loss: 0.0002628219372127205\n",
      "Epoch 4717, Loss: 0.0012445520533219678, Final Batch Loss: 0.0\n",
      "Epoch 4718, Loss: 0.00040296624501934275, Final Batch Loss: 0.0\n",
      "Epoch 4719, Loss: 0.0011100519768660888, Final Batch Loss: 0.0\n",
      "Epoch 4720, Loss: 0.000979426564292396, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4721, Loss: 0.001165757275884971, Final Batch Loss: 0.0\n",
      "Epoch 4722, Loss: 0.0016431889871455496, Final Batch Loss: 4.279521817807108e-05\n",
      "Epoch 4723, Loss: 0.0009307534928666428, Final Batch Loss: 0.0\n",
      "Epoch 4724, Loss: 0.0005920586045249365, Final Batch Loss: 0.0\n",
      "Epoch 4725, Loss: 0.0005835500924149528, Final Batch Loss: 0.0\n",
      "Epoch 4726, Loss: 0.00043295693467371166, Final Batch Loss: 0.0\n",
      "Epoch 4727, Loss: 0.0021338122824090533, Final Batch Loss: 0.0\n",
      "Epoch 4728, Loss: 0.0008995698344733682, Final Batch Loss: 1.168244216387393e-05\n",
      "Epoch 4729, Loss: 0.0011831618176074699, Final Batch Loss: 0.0\n",
      "Epoch 4730, Loss: 0.0008412139977735933, Final Batch Loss: 0.0\n",
      "Epoch 4731, Loss: 0.00013950732136436272, Final Batch Loss: 0.0\n",
      "Epoch 4732, Loss: 0.0019581336819101125, Final Batch Loss: 0.0\n",
      "Epoch 4733, Loss: 0.0005560425870498875, Final Batch Loss: 0.0\n",
      "Epoch 4734, Loss: 0.00039794396013803635, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4735, Loss: 0.0012603142567968462, Final Batch Loss: 0.0\n",
      "Epoch 4736, Loss: 0.0005319323681760579, Final Batch Loss: 0.0\n",
      "Epoch 4737, Loss: 0.0004201494448281551, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4738, Loss: 0.011671288892102893, Final Batch Loss: 0.0\n",
      "Epoch 4739, Loss: 0.0137148260109754, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4740, Loss: 0.00022616038586420473, Final Batch Loss: 0.0\n",
      "Epoch 4741, Loss: 0.000749831713619642, Final Batch Loss: 0.0\n",
      "Epoch 4742, Loss: 0.00021743876865798484, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4743, Loss: 0.00038995142313069664, Final Batch Loss: 0.0\n",
      "Epoch 4744, Loss: 0.0007401257407764206, Final Batch Loss: 0.0\n",
      "Epoch 4745, Loss: 0.0004308300995035097, Final Batch Loss: 0.0\n",
      "Epoch 4746, Loss: 0.005662126597599126, Final Batch Loss: 0.0\n",
      "Epoch 4747, Loss: 0.0003113665916316677, Final Batch Loss: 0.0\n",
      "Epoch 4748, Loss: 0.002087705444864696, Final Batch Loss: 0.0\n",
      "Epoch 4749, Loss: 0.0007459046573785599, Final Batch Loss: 0.0\n",
      "Epoch 4750, Loss: 0.002168259263271466, Final Batch Loss: 0.0\n",
      "Epoch 4751, Loss: 0.0014722332780365832, Final Batch Loss: 0.0\n",
      "Epoch 4752, Loss: 0.0013634986680699512, Final Batch Loss: 0.0\n",
      "Epoch 4753, Loss: 0.0007682184086661437, Final Batch Loss: 0.0\n",
      "Epoch 4754, Loss: 0.0012331936304690316, Final Batch Loss: 0.0\n",
      "Epoch 4755, Loss: 0.013452319100906607, Final Batch Loss: 0.013036380521953106\n",
      "Epoch 4756, Loss: 0.000979422897216864, Final Batch Loss: 0.0005725175142288208\n",
      "Epoch 4757, Loss: 0.0011744628063752316, Final Batch Loss: 0.0\n",
      "Epoch 4758, Loss: 0.008404838321439456, Final Batch Loss: 0.0\n",
      "Epoch 4759, Loss: 0.0141822696023155, Final Batch Loss: 0.0\n",
      "Epoch 4760, Loss: 0.0002028963717748411, Final Batch Loss: 0.0\n",
      "Epoch 4761, Loss: 0.0005722384012187831, Final Batch Loss: 0.0\n",
      "Epoch 4762, Loss: 0.031937497697072104, Final Batch Loss: 0.0\n",
      "Epoch 4763, Loss: 0.0009793617791729048, Final Batch Loss: 0.0\n",
      "Epoch 4764, Loss: 0.0018797611410263926, Final Batch Loss: 0.0\n",
      "Epoch 4765, Loss: 0.00509686448276625, Final Batch Loss: 0.0\n",
      "Epoch 4766, Loss: 0.01920692434941884, Final Batch Loss: 0.0026190525386482477\n",
      "Epoch 4767, Loss: 0.008107191184535623, Final Batch Loss: 0.0\n",
      "Epoch 4768, Loss: 0.0005025931750424206, Final Batch Loss: 0.0\n",
      "Epoch 4769, Loss: 0.0008338135085068643, Final Batch Loss: 0.0\n",
      "Epoch 4770, Loss: 0.0003763325948966667, Final Batch Loss: 0.0\n",
      "Epoch 4771, Loss: 0.006596315623028204, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4772, Loss: 0.004933653564876295, Final Batch Loss: 3.313963316031732e-05\n",
      "Epoch 4773, Loss: 0.002027220429219767, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4774, Loss: 0.02712808556680102, Final Batch Loss: 0.0\n",
      "Epoch 4775, Loss: 0.015458411537110806, Final Batch Loss: 0.0\n",
      "Epoch 4776, Loss: 0.0019495626329444349, Final Batch Loss: 0.0\n",
      "Epoch 4777, Loss: 0.0012297615357965697, Final Batch Loss: 0.0\n",
      "Epoch 4778, Loss: 0.017673556176305283, Final Batch Loss: 0.0\n",
      "Epoch 4779, Loss: 0.014589401987905148, Final Batch Loss: 0.0\n",
      "Epoch 4780, Loss: 0.0005838256711285794, Final Batch Loss: 1.6569954823353328e-05\n",
      "Epoch 4781, Loss: 0.0047508478310192, Final Batch Loss: 0.0\n",
      "Epoch 4782, Loss: 0.000755012544686906, Final Batch Loss: 0.0\n",
      "Epoch 4783, Loss: 0.0010859325157070998, Final Batch Loss: 0.0\n",
      "Epoch 4784, Loss: 0.0026287969667464495, Final Batch Loss: 0.0\n",
      "Epoch 4785, Loss: 0.015639138728147373, Final Batch Loss: 0.0\n",
      "Epoch 4786, Loss: 0.0009770094256964512, Final Batch Loss: 0.0\n",
      "Epoch 4787, Loss: 0.007452029756677803, Final Batch Loss: 0.0\n",
      "Epoch 4788, Loss: 0.0007170254320953973, Final Batch Loss: 0.0\n",
      "Epoch 4789, Loss: 0.001185193978017196, Final Batch Loss: 0.0\n",
      "Epoch 4790, Loss: 0.003401673187909182, Final Batch Loss: 5.4596363042946905e-05\n",
      "Epoch 4791, Loss: 0.005669494872563519, Final Batch Loss: 0.0\n",
      "Epoch 4792, Loss: 0.002439216448692605, Final Batch Loss: 0.0\n",
      "Epoch 4793, Loss: 0.0008960754676081706, Final Batch Loss: 0.0\n",
      "Epoch 4794, Loss: 0.017451480692216137, Final Batch Loss: 0.0\n",
      "Epoch 4795, Loss: 0.0011123259573651012, Final Batch Loss: 0.0\n",
      "Epoch 4796, Loss: 0.0015393695211969316, Final Batch Loss: 0.0\n",
      "Epoch 4797, Loss: 0.0005616356047539739, Final Batch Loss: 0.0\n",
      "Epoch 4798, Loss: 0.0037979542539687827, Final Batch Loss: 0.0032706360798329115\n",
      "Epoch 4799, Loss: 0.000687111496063153, Final Batch Loss: 0.0\n",
      "Epoch 4800, Loss: 0.0005813246507386793, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 4801, Loss: 0.00033608376543270424, Final Batch Loss: 0.0\n",
      "Epoch 4802, Loss: 0.0002754957049546647, Final Batch Loss: 0.0\n",
      "Epoch 4803, Loss: 0.0008544378069856862, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4804, Loss: 0.022457573370047612, Final Batch Loss: 0.0\n",
      "Epoch 4805, Loss: 0.0016873021177161718, Final Batch Loss: 0.0\n",
      "Epoch 4806, Loss: 0.0053265305468812585, Final Batch Loss: 0.0\n",
      "Epoch 4807, Loss: 0.0004077806261193473, Final Batch Loss: 0.0\n",
      "Epoch 4808, Loss: 0.0003615110654209275, Final Batch Loss: 0.0\n",
      "Epoch 4809, Loss: 0.0017522584312175127, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4810, Loss: 0.0004972995629941579, Final Batch Loss: 0.0\n",
      "Epoch 4811, Loss: 0.0012667059963860083, Final Batch Loss: 0.0\n",
      "Epoch 4812, Loss: 0.00021360315440688282, Final Batch Loss: 0.0\n",
      "Epoch 4813, Loss: 0.0020011409869766794, Final Batch Loss: 0.0\n",
      "Epoch 4814, Loss: 0.0011009230656782165, Final Batch Loss: 0.0\n",
      "Epoch 4815, Loss: 0.0001486734163336223, Final Batch Loss: 0.0\n",
      "Epoch 4816, Loss: 0.0007684550655540079, Final Batch Loss: 0.0\n",
      "Epoch 4817, Loss: 0.004875522194197401, Final Batch Loss: 0.003879759693518281\n",
      "Epoch 4818, Loss: 0.0003835254301520763, Final Batch Loss: 0.0\n",
      "Epoch 4819, Loss: 0.002420328790321946, Final Batch Loss: 0.0\n",
      "Epoch 4820, Loss: 0.00537616585642553, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4821, Loss: 0.0020613635424524546, Final Batch Loss: 0.0\n",
      "Epoch 4822, Loss: 0.00024297804247908061, Final Batch Loss: 0.0\n",
      "Epoch 4823, Loss: 0.0014864066761219874, Final Batch Loss: 1.0490362910786644e-05\n",
      "Epoch 4824, Loss: 0.001200268643515301, Final Batch Loss: 0.0\n",
      "Epoch 4825, Loss: 0.00047337916294054594, Final Batch Loss: 0.0\n",
      "Epoch 4826, Loss: 0.00038615876109560077, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4827, Loss: 0.025946747278766225, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4828, Loss: 0.0004319918543842505, Final Batch Loss: 0.0\n",
      "Epoch 4829, Loss: 0.0004420451432451955, Final Batch Loss: 0.0\n",
      "Epoch 4830, Loss: 0.0008589575299993157, Final Batch Loss: 0.0\n",
      "Epoch 4831, Loss: 0.0031763232541379693, Final Batch Loss: 0.0\n",
      "Epoch 4832, Loss: 0.0007281468424480408, Final Batch Loss: 0.0\n",
      "Epoch 4833, Loss: 0.00292051727535636, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4834, Loss: 0.009946516401157623, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4835, Loss: 0.003295482834801078, Final Batch Loss: 0.0\n",
      "Epoch 4836, Loss: 0.0008837223867885768, Final Batch Loss: 0.0\n",
      "Epoch 4837, Loss: 0.0021995476236043032, Final Batch Loss: 0.0\n",
      "Epoch 4838, Loss: 0.0007546386696049012, Final Batch Loss: 0.0\n",
      "Epoch 4839, Loss: 0.015151247867827067, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4840, Loss: 0.0011077034214395098, Final Batch Loss: 0.0\n",
      "Epoch 4841, Loss: 0.041386472966223664, Final Batch Loss: 0.0\n",
      "Epoch 4842, Loss: 0.0005858213571627857, Final Batch Loss: 0.0\n",
      "Epoch 4843, Loss: 0.0007080377381498693, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 4844, Loss: 0.009796655212994665, Final Batch Loss: 0.0\n",
      "Epoch 4845, Loss: 0.0003816747775999829, Final Batch Loss: 0.0\n",
      "Epoch 4846, Loss: 0.0005957647372270003, Final Batch Loss: 0.0\n",
      "Epoch 4847, Loss: 0.0022612667669932307, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4848, Loss: 0.0017943353886948898, Final Batch Loss: 0.0\n",
      "Epoch 4849, Loss: 0.008566836331738159, Final Batch Loss: 0.0\n",
      "Epoch 4850, Loss: 0.005393513638409786, Final Batch Loss: 0.00016485285595990717\n",
      "Epoch 4851, Loss: 0.0014792382426094264, Final Batch Loss: 0.0\n",
      "Epoch 4852, Loss: 0.0002829824516084045, Final Batch Loss: 0.0\n",
      "Epoch 4853, Loss: 0.000568003017178853, Final Batch Loss: 0.0\n",
      "Epoch 4854, Loss: 0.003604099663789384, Final Batch Loss: 0.0\n",
      "Epoch 4855, Loss: 0.0002315276324225124, Final Batch Loss: 0.0\n",
      "Epoch 4856, Loss: 0.00038624088415417646, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 4857, Loss: 0.0006911541806857713, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 4858, Loss: 0.0025425016061717542, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4859, Loss: 0.0012009146303171292, Final Batch Loss: 0.0\n",
      "Epoch 4860, Loss: 0.0009377083606523229, Final Batch Loss: 0.0\n",
      "Epoch 4861, Loss: 0.0024937276102647843, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4862, Loss: 0.0014461970276897773, Final Batch Loss: 0.0\n",
      "Epoch 4863, Loss: 0.005524324566067662, Final Batch Loss: 0.0\n",
      "Epoch 4864, Loss: 0.00027336087805451825, Final Batch Loss: 0.0\n",
      "Epoch 4865, Loss: 0.0008088172689895146, Final Batch Loss: 0.0\n",
      "Epoch 4866, Loss: 0.0019668331788125215, Final Batch Loss: 0.0\n",
      "Epoch 4867, Loss: 0.00033079797503887676, Final Batch Loss: 0.0\n",
      "Epoch 4868, Loss: 0.0009679266026978439, Final Batch Loss: 0.0\n",
      "Epoch 4869, Loss: 0.0003100356989307329, Final Batch Loss: 0.0\n",
      "Epoch 4870, Loss: 0.0011609386201598682, Final Batch Loss: 0.0\n",
      "Epoch 4871, Loss: 0.00041825462176348083, Final Batch Loss: 0.0\n",
      "Epoch 4872, Loss: 0.002225502210421837, Final Batch Loss: 0.0\n",
      "Epoch 4873, Loss: 0.0011349683700245805, Final Batch Loss: 0.0\n",
      "Epoch 4874, Loss: 0.001068588433554396, Final Batch Loss: 0.0\n",
      "Epoch 4875, Loss: 0.0015473432722501457, Final Batch Loss: 0.0\n",
      "Epoch 4876, Loss: 0.002862558327251463, Final Batch Loss: 0.0015286438865587115\n",
      "Epoch 4877, Loss: 0.02071762244668207, Final Batch Loss: 0.0\n",
      "Epoch 4878, Loss: 0.0003356070646987064, Final Batch Loss: 0.0\n",
      "Epoch 4879, Loss: 0.00028868895969935693, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 4880, Loss: 0.0004734498047582747, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 4881, Loss: 0.004536325655863038, Final Batch Loss: 0.0\n",
      "Epoch 4882, Loss: 0.0011180993114976445, Final Batch Loss: 0.0\n",
      "Epoch 4883, Loss: 0.002417903880996164, Final Batch Loss: 0.0\n",
      "Epoch 4884, Loss: 0.0003058380025322549, Final Batch Loss: 0.0\n",
      "Epoch 4885, Loss: 0.0024781080574030057, Final Batch Loss: 0.0\n",
      "Epoch 4886, Loss: 0.0013877455385227222, Final Batch Loss: 0.0\n",
      "Epoch 4887, Loss: 0.0003522482147673145, Final Batch Loss: 0.0\n",
      "Epoch 4888, Loss: 0.0007794827070028987, Final Batch Loss: 0.0\n",
      "Epoch 4889, Loss: 0.004143712721997872, Final Batch Loss: 0.0\n",
      "Epoch 4890, Loss: 0.00044614939361053985, Final Batch Loss: 0.0\n",
      "Epoch 4891, Loss: 0.00023017394050839357, Final Batch Loss: 0.0\n",
      "Epoch 4892, Loss: 0.0015383911077151424, Final Batch Loss: 1.2755313036905136e-05\n",
      "Epoch 4893, Loss: 0.0025561332447523455, Final Batch Loss: 0.0\n",
      "Epoch 4894, Loss: 0.009855028794845566, Final Batch Loss: 0.0\n",
      "Epoch 4895, Loss: 0.0007377682204605662, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4896, Loss: 0.0004647314563044347, Final Batch Loss: 0.0\n",
      "Epoch 4897, Loss: 0.013401321492892748, Final Batch Loss: 0.0\n",
      "Epoch 4898, Loss: 0.01546031278121518, Final Batch Loss: 0.0\n",
      "Epoch 4899, Loss: 0.0009261374216293916, Final Batch Loss: 0.0\n",
      "Epoch 4900, Loss: 0.019774473355937516, Final Batch Loss: 0.0\n",
      "Epoch 4901, Loss: 0.0004501014045672491, Final Batch Loss: 0.0\n",
      "Epoch 4902, Loss: 0.004121653033962502, Final Batch Loss: 0.0\n",
      "Epoch 4903, Loss: 0.003971497681050096, Final Batch Loss: 0.0\n",
      "Epoch 4904, Loss: 0.013304282780154608, Final Batch Loss: 0.0\n",
      "Epoch 4905, Loss: 0.025950864364858717, Final Batch Loss: 0.0\n",
      "Epoch 4906, Loss: 0.00024973707513709087, Final Batch Loss: 0.0\n",
      "Epoch 4907, Loss: 0.0008577953522035386, Final Batch Loss: 0.0\n",
      "Epoch 4908, Loss: 0.00047120937961153686, Final Batch Loss: 0.0\n",
      "Epoch 4909, Loss: 0.008896992425434291, Final Batch Loss: 0.0\n",
      "Epoch 4910, Loss: 0.009535302735457662, Final Batch Loss: 0.0\n",
      "Epoch 4911, Loss: 0.0002581466324045323, Final Batch Loss: 0.0\n",
      "Epoch 4912, Loss: 0.0015970401000231504, Final Batch Loss: 0.0\n",
      "Epoch 4913, Loss: 0.0006583303838851862, Final Batch Loss: 0.0\n",
      "Epoch 4914, Loss: 0.011942540906602517, Final Batch Loss: 0.0\n",
      "Epoch 4915, Loss: 0.021340053328458453, Final Batch Loss: 0.0\n",
      "Epoch 4916, Loss: 0.0035520084456948098, Final Batch Loss: 0.0\n",
      "Epoch 4917, Loss: 0.0003048582293558866, Final Batch Loss: 0.0\n",
      "Epoch 4918, Loss: 0.004945268337905873, Final Batch Loss: 0.0\n",
      "Epoch 4919, Loss: 0.015302855288602757, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4920, Loss: 0.003541773185133934, Final Batch Loss: 0.0\n",
      "Epoch 4921, Loss: 0.002360673422117543, Final Batch Loss: 1.168244216387393e-05\n",
      "Epoch 4922, Loss: 0.002562238675182016, Final Batch Loss: 0.0\n",
      "Epoch 4923, Loss: 0.0005880816534045152, Final Batch Loss: 0.0\n",
      "Epoch 4924, Loss: 0.0005531420902116224, Final Batch Loss: 0.0\n",
      "Epoch 4925, Loss: 0.011052864814644181, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4926, Loss: 0.0012498719152063131, Final Batch Loss: 0.0\n",
      "Epoch 4927, Loss: 0.0010054589438368566, Final Batch Loss: 0.0\n",
      "Epoch 4928, Loss: 0.0003604723606258631, Final Batch Loss: 0.0\n",
      "Epoch 4929, Loss: 0.000723057374216296, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 4930, Loss: 0.0005338365299394354, Final Batch Loss: 0.0\n",
      "Epoch 4931, Loss: 0.0003762627238756977, Final Batch Loss: 0.0\n",
      "Epoch 4932, Loss: 0.003992023477621842, Final Batch Loss: 0.0\n",
      "Epoch 4933, Loss: 0.001888083657831885, Final Batch Loss: 0.0\n",
      "Epoch 4934, Loss: 0.000907669797015842, Final Batch Loss: 0.0\n",
      "Epoch 4935, Loss: 0.0004238444525981322, Final Batch Loss: 0.0\n",
      "Epoch 4936, Loss: 0.0007441452835337259, Final Batch Loss: 0.0\n",
      "Epoch 4937, Loss: 0.005689487130439375, Final Batch Loss: 0.0\n",
      "Epoch 4938, Loss: 0.0017392745539837051, Final Batch Loss: 0.0\n",
      "Epoch 4939, Loss: 0.0009049366562976502, Final Batch Loss: 8.880697714630514e-05\n",
      "Epoch 4940, Loss: 0.002598237872007303, Final Batch Loss: 0.0001532914029667154\n",
      "Epoch 4941, Loss: 0.002790848651784472, Final Batch Loss: 0.0\n",
      "Epoch 4942, Loss: 0.0010922017972916365, Final Batch Loss: 0.0\n",
      "Epoch 4943, Loss: 0.0006171565182739869, Final Batch Loss: 0.0\n",
      "Epoch 4944, Loss: 0.008619501603789104, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 4945, Loss: 0.009687486162874848, Final Batch Loss: 0.0\n",
      "Epoch 4946, Loss: 0.0011130702769150957, Final Batch Loss: 0.0\n",
      "Epoch 4947, Loss: 0.000520886984304525, Final Batch Loss: 0.0\n",
      "Epoch 4948, Loss: 0.0008362977778233471, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 4949, Loss: 0.0013527175760827959, Final Batch Loss: 0.0\n",
      "Epoch 4950, Loss: 0.0035890013750758953, Final Batch Loss: 0.0\n",
      "Epoch 4951, Loss: 0.0005092555511438945, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4952, Loss: 0.0003453898098086938, Final Batch Loss: 0.0\n",
      "Epoch 4953, Loss: 0.0004874944170296658, Final Batch Loss: 0.0\n",
      "Epoch 4954, Loss: 0.0002357071716687642, Final Batch Loss: 0.0\n",
      "Epoch 4955, Loss: 0.0011998650079476647, Final Batch Loss: 0.0\n",
      "Epoch 4956, Loss: 0.00042707559987320565, Final Batch Loss: 0.0\n",
      "Epoch 4957, Loss: 0.0012406490423018113, Final Batch Loss: 0.0\n",
      "Epoch 4958, Loss: 0.001038736809277907, Final Batch Loss: 0.0\n",
      "Epoch 4959, Loss: 0.00538280101318378, Final Batch Loss: 0.0\n",
      "Epoch 4960, Loss: 0.0006418821649276651, Final Batch Loss: 0.0\n",
      "Epoch 4961, Loss: 0.0030777716892487206, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4962, Loss: 0.0009340488177258521, Final Batch Loss: 0.0\n",
      "Epoch 4963, Loss: 0.008101018545858096, Final Batch Loss: 0.0\n",
      "Epoch 4964, Loss: 0.0011707488010870293, Final Batch Loss: 0.0\n",
      "Epoch 4965, Loss: 0.0008070022595347837, Final Batch Loss: 0.0\n",
      "Epoch 4966, Loss: 0.0011453593033365905, Final Batch Loss: 0.0\n",
      "Epoch 4967, Loss: 0.0008092969364952296, Final Batch Loss: 0.0\n",
      "Epoch 4968, Loss: 0.001458832688513212, Final Batch Loss: 0.0\n",
      "Epoch 4969, Loss: 0.0017393447196809575, Final Batch Loss: 0.0\n",
      "Epoch 4970, Loss: 0.0008317984902532771, Final Batch Loss: 0.0\n",
      "Epoch 4971, Loss: 0.0002683726488612592, Final Batch Loss: 0.0\n",
      "Epoch 4972, Loss: 0.001095946885129706, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4973, Loss: 0.0009809329349081963, Final Batch Loss: 0.0\n",
      "Epoch 4974, Loss: 0.002547895950556267, Final Batch Loss: 0.0\n",
      "Epoch 4975, Loss: 0.002245950025098864, Final Batch Loss: 0.0\n",
      "Epoch 4976, Loss: 0.007918633891677018, Final Batch Loss: 0.0\n",
      "Epoch 4977, Loss: 0.0015820344005703646, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4978, Loss: 0.0003662483268271899, Final Batch Loss: 0.0\n",
      "Epoch 4979, Loss: 0.0542880814172122, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4980, Loss: 0.03387158192344941, Final Batch Loss: 0.0\n",
      "Epoch 4981, Loss: 0.04030336922733113, Final Batch Loss: 0.00012635385792236775\n",
      "Epoch 4982, Loss: 0.000593685355852358, Final Batch Loss: 0.0\n",
      "Epoch 4983, Loss: 0.0020675483565355535, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 4984, Loss: 0.0005221826431807131, Final Batch Loss: 0.0\n",
      "Epoch 4985, Loss: 0.00039878451207187027, Final Batch Loss: 0.0\n",
      "Epoch 4986, Loss: 0.016648669341513767, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4987, Loss: 0.0032275301053346084, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4988, Loss: 0.0014852606109272415, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4989, Loss: 0.0015868666669121012, Final Batch Loss: 0.0\n",
      "Epoch 4990, Loss: 0.0014339185872813687, Final Batch Loss: 0.0\n",
      "Epoch 4991, Loss: 0.0009067878490895964, Final Batch Loss: 0.0\n",
      "Epoch 4992, Loss: 0.0007702150614932179, Final Batch Loss: 0.00032050241134129465\n",
      "Epoch 4993, Loss: 0.011340578086674213, Final Batch Loss: 0.0\n",
      "Epoch 4994, Loss: 0.0009430147547391243, Final Batch Loss: 0.0\n",
      "Epoch 4995, Loss: 0.0005808572750538588, Final Batch Loss: 0.0\n",
      "Epoch 4996, Loss: 0.011025629049981944, Final Batch Loss: 0.008696657605469227\n",
      "Epoch 4997, Loss: 0.0015611648341291584, Final Batch Loss: 0.0\n",
      "Epoch 4998, Loss: 0.02542413500850671, Final Batch Loss: 9.500529267825186e-05\n",
      "Epoch 4999, Loss: 0.008094405636711599, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 5000, Loss: 0.017588599148439243, Final Batch Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  0  0]\n",
      " [ 1 60  0]\n",
      " [ 0  0 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98592   1.00000   0.99291        70\n",
      "           1    1.00000   0.98361   0.99174        61\n",
      "           2    1.00000   1.00000   1.00000        57\n",
      "\n",
      "    accuracy                        0.99468       188\n",
      "   macro avg    0.99531   0.99454   0.99488       188\n",
      "weighted avg    0.99476   0.99468   0.99468       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 6)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 6)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_13 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_14 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_15 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_16 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_17 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_18 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 6) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12,\n",
    "                               fake_features_13, fake_features_14, fake_features_15, fake_features_16, fake_features_17, fake_features_18))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  0  1]\n",
      " [ 0 60  0]\n",
      " [ 0  0 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   0.98333   0.99160        60\n",
      "         1.0    1.00000   1.00000   1.00000        60\n",
      "         2.0    0.98361   1.00000   0.99174        60\n",
      "\n",
      "    accuracy                        0.99444       180\n",
      "   macro avg    0.99454   0.99444   0.99444       180\n",
      "weighted avg    0.99454   0.99444   0.99444       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 4\n",
    "    else:\n",
    "        y[k] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.324767351150513, Final Batch Loss: 1.9476697444915771\n",
      "Epoch 2, Loss: 7.087306380271912, Final Batch Loss: 1.713757038116455\n",
      "Epoch 3, Loss: 7.0897133350372314, Final Batch Loss: 1.7141481637954712\n",
      "Epoch 4, Loss: 7.303276181221008, Final Batch Loss: 1.9305531978607178\n",
      "Epoch 5, Loss: 7.312042713165283, Final Batch Loss: 1.94318425655365\n",
      "Epoch 6, Loss: 7.326673269271851, Final Batch Loss: 1.9543445110321045\n",
      "Epoch 7, Loss: 7.180524110794067, Final Batch Loss: 1.8120821714401245\n",
      "Epoch 8, Loss: 6.924331784248352, Final Batch Loss: 1.5617165565490723\n",
      "Epoch 9, Loss: 7.269026041030884, Final Batch Loss: 1.9064658880233765\n",
      "Epoch 10, Loss: 6.917933225631714, Final Batch Loss: 1.5517066717147827\n",
      "Epoch 11, Loss: 7.081150650978088, Final Batch Loss: 1.7208610773086548\n",
      "Epoch 12, Loss: 7.050141453742981, Final Batch Loss: 1.6901044845581055\n",
      "Epoch 13, Loss: 7.259033679962158, Final Batch Loss: 1.8995311260223389\n",
      "Epoch 14, Loss: 7.040647983551025, Final Batch Loss: 1.6815738677978516\n",
      "Epoch 15, Loss: 7.24428915977478, Final Batch Loss: 1.891603946685791\n",
      "Epoch 16, Loss: 7.273561716079712, Final Batch Loss: 1.924148678779602\n",
      "Epoch 17, Loss: 7.2374314069747925, Final Batch Loss: 1.8910350799560547\n",
      "Epoch 18, Loss: 7.2631306648254395, Final Batch Loss: 1.9191440343856812\n",
      "Epoch 19, Loss: 7.21928083896637, Final Batch Loss: 1.873575210571289\n",
      "Epoch 20, Loss: 7.269079923629761, Final Batch Loss: 1.9318084716796875\n",
      "Epoch 21, Loss: 6.8564475774765015, Final Batch Loss: 1.5218229293823242\n",
      "Epoch 22, Loss: 7.270611047744751, Final Batch Loss: 1.9380285739898682\n",
      "Epoch 23, Loss: 7.223168611526489, Final Batch Loss: 1.8988813161849976\n",
      "Epoch 24, Loss: 7.176686644554138, Final Batch Loss: 1.8610769510269165\n",
      "Epoch 25, Loss: 6.918306112289429, Final Batch Loss: 1.6057686805725098\n",
      "Epoch 26, Loss: 7.154094457626343, Final Batch Loss: 1.8397951126098633\n",
      "Epoch 27, Loss: 7.206422686576843, Final Batch Loss: 1.8984493017196655\n",
      "Epoch 28, Loss: 7.1492695808410645, Final Batch Loss: 1.8518308401107788\n",
      "Epoch 29, Loss: 7.146547913551331, Final Batch Loss: 1.851109266281128\n",
      "Epoch 30, Loss: 7.116140127182007, Final Batch Loss: 1.8247421979904175\n",
      "Epoch 31, Loss: 6.680318355560303, Final Batch Loss: 1.4011696577072144\n",
      "Epoch 32, Loss: 7.145454049110413, Final Batch Loss: 1.8727781772613525\n",
      "Epoch 33, Loss: 6.950493931770325, Final Batch Loss: 1.6921590566635132\n",
      "Epoch 34, Loss: 7.055868148803711, Final Batch Loss: 1.8125710487365723\n",
      "Epoch 35, Loss: 7.143265962600708, Final Batch Loss: 1.9195305109024048\n",
      "Epoch 36, Loss: 7.144820332527161, Final Batch Loss: 1.9350740909576416\n",
      "Epoch 37, Loss: 7.071839690208435, Final Batch Loss: 1.8648476600646973\n",
      "Epoch 38, Loss: 6.860782027244568, Final Batch Loss: 1.6658399105072021\n",
      "Epoch 39, Loss: 6.903914213180542, Final Batch Loss: 1.7357081174850464\n",
      "Epoch 40, Loss: 6.984727501869202, Final Batch Loss: 1.8175907135009766\n",
      "Epoch 41, Loss: 6.907312750816345, Final Batch Loss: 1.7659008502960205\n",
      "Epoch 42, Loss: 6.996804118156433, Final Batch Loss: 1.8600059747695923\n",
      "Epoch 43, Loss: 7.058257341384888, Final Batch Loss: 1.9272727966308594\n",
      "Epoch 44, Loss: 6.782754063606262, Final Batch Loss: 1.6920244693756104\n",
      "Epoch 45, Loss: 7.01769495010376, Final Batch Loss: 1.9219063520431519\n",
      "Epoch 46, Loss: 6.7424010038375854, Final Batch Loss: 1.6692365407943726\n",
      "Epoch 47, Loss: 6.347222566604614, Final Batch Loss: 1.2752262353897095\n",
      "Epoch 48, Loss: 7.075542688369751, Final Batch Loss: 2.021923303604126\n",
      "Epoch 49, Loss: 6.740305066108704, Final Batch Loss: 1.7108052968978882\n",
      "Epoch 50, Loss: 5.909101843833923, Final Batch Loss: 0.8731786012649536\n",
      "Epoch 51, Loss: 6.657775640487671, Final Batch Loss: 1.6667308807373047\n",
      "Epoch 52, Loss: 5.808682560920715, Final Batch Loss: 0.8368816375732422\n",
      "Epoch 53, Loss: 6.592584133148193, Final Batch Loss: 1.6310359239578247\n",
      "Epoch 54, Loss: 6.633023738861084, Final Batch Loss: 1.694477915763855\n",
      "Epoch 55, Loss: 6.626422882080078, Final Batch Loss: 1.7215512990951538\n",
      "Epoch 56, Loss: 6.930888652801514, Final Batch Loss: 2.051661968231201\n",
      "Epoch 57, Loss: 6.888143301010132, Final Batch Loss: 2.0194954872131348\n",
      "Epoch 58, Loss: 6.78558611869812, Final Batch Loss: 1.9078996181488037\n",
      "Epoch 59, Loss: 6.460700631141663, Final Batch Loss: 1.5949079990386963\n",
      "Epoch 60, Loss: 6.569836497306824, Final Batch Loss: 1.712855339050293\n",
      "Epoch 61, Loss: 7.3007248640060425, Final Batch Loss: 2.453242540359497\n",
      "Epoch 62, Loss: 6.743452191352844, Final Batch Loss: 1.9371094703674316\n",
      "Epoch 63, Loss: 6.5537004470825195, Final Batch Loss: 1.7825039625167847\n",
      "Epoch 64, Loss: 6.532252550125122, Final Batch Loss: 1.7440659999847412\n",
      "Epoch 65, Loss: 6.418605923652649, Final Batch Loss: 1.6529784202575684\n",
      "Epoch 66, Loss: 6.911213636398315, Final Batch Loss: 2.1710288524627686\n",
      "Epoch 67, Loss: 6.509283185005188, Final Batch Loss: 1.7859996557235718\n",
      "Epoch 68, Loss: 6.093917608261108, Final Batch Loss: 1.3431252241134644\n",
      "Epoch 69, Loss: 6.346878170967102, Final Batch Loss: 1.652061939239502\n",
      "Epoch 70, Loss: 6.449883937835693, Final Batch Loss: 1.7367067337036133\n",
      "Epoch 71, Loss: 7.057691931724548, Final Batch Loss: 2.3221898078918457\n",
      "Epoch 72, Loss: 5.92318594455719, Final Batch Loss: 1.1934682130813599\n",
      "Epoch 73, Loss: 6.454254508018494, Final Batch Loss: 1.7270293235778809\n",
      "Epoch 74, Loss: 6.569253444671631, Final Batch Loss: 1.8693236112594604\n",
      "Epoch 75, Loss: 6.743374943733215, Final Batch Loss: 2.0493037700653076\n",
      "Epoch 76, Loss: 5.6944568157196045, Final Batch Loss: 1.0214987993240356\n",
      "Epoch 77, Loss: 5.770780086517334, Final Batch Loss: 1.0963189601898193\n",
      "Epoch 78, Loss: 6.366158604621887, Final Batch Loss: 1.6883502006530762\n",
      "Epoch 79, Loss: 6.155851721763611, Final Batch Loss: 1.5101960897445679\n",
      "Epoch 80, Loss: 6.225294828414917, Final Batch Loss: 1.6068006753921509\n",
      "Epoch 81, Loss: 6.342650771141052, Final Batch Loss: 1.731188178062439\n",
      "Epoch 82, Loss: 6.258383274078369, Final Batch Loss: 1.6603240966796875\n",
      "Epoch 83, Loss: 6.361520051956177, Final Batch Loss: 1.7884122133255005\n",
      "Epoch 84, Loss: 6.628085136413574, Final Batch Loss: 2.0694851875305176\n",
      "Epoch 85, Loss: 6.651193737983704, Final Batch Loss: 2.0978598594665527\n",
      "Epoch 86, Loss: 5.957771420478821, Final Batch Loss: 1.4069862365722656\n",
      "Epoch 87, Loss: 5.7319207191467285, Final Batch Loss: 1.1904654502868652\n",
      "Epoch 88, Loss: 5.361800909042358, Final Batch Loss: 0.8507134914398193\n",
      "Epoch 89, Loss: 5.372538208961487, Final Batch Loss: 0.8696095943450928\n",
      "Epoch 90, Loss: 6.040664911270142, Final Batch Loss: 1.5578458309173584\n",
      "Epoch 91, Loss: 5.807547569274902, Final Batch Loss: 1.358824610710144\n",
      "Epoch 92, Loss: 5.168317258358002, Final Batch Loss: 0.7015121579170227\n",
      "Epoch 93, Loss: 6.114567041397095, Final Batch Loss: 1.7016350030899048\n",
      "Epoch 94, Loss: 6.428815245628357, Final Batch Loss: 2.051693916320801\n",
      "Epoch 95, Loss: 5.675426125526428, Final Batch Loss: 1.2432137727737427\n",
      "Epoch 96, Loss: 5.999590992927551, Final Batch Loss: 1.6197444200515747\n",
      "Epoch 97, Loss: 6.247727870941162, Final Batch Loss: 1.9485933780670166\n",
      "Epoch 98, Loss: 5.788029432296753, Final Batch Loss: 1.449939250946045\n",
      "Epoch 99, Loss: 5.04855614900589, Final Batch Loss: 0.6318729519844055\n",
      "Epoch 100, Loss: 5.096400082111359, Final Batch Loss: 0.7577361464500427\n",
      "Epoch 101, Loss: 5.918750524520874, Final Batch Loss: 1.6269694566726685\n",
      "Epoch 102, Loss: 5.470397591590881, Final Batch Loss: 1.2139887809753418\n",
      "Epoch 103, Loss: 5.779969692230225, Final Batch Loss: 1.4872374534606934\n",
      "Epoch 104, Loss: 4.944740355014801, Final Batch Loss: 0.7319368720054626\n",
      "Epoch 105, Loss: 4.683328360319138, Final Batch Loss: 0.4593246877193451\n",
      "Epoch 106, Loss: 5.8504650592803955, Final Batch Loss: 1.6197706460952759\n",
      "Epoch 107, Loss: 5.4288330078125, Final Batch Loss: 1.2069017887115479\n",
      "Epoch 108, Loss: 6.3600382804870605, Final Batch Loss: 2.151646137237549\n",
      "Epoch 109, Loss: 5.682794094085693, Final Batch Loss: 1.5224575996398926\n",
      "Epoch 110, Loss: 5.461206912994385, Final Batch Loss: 1.3039582967758179\n",
      "Epoch 111, Loss: 4.97559666633606, Final Batch Loss: 0.8421032428741455\n",
      "Epoch 112, Loss: 5.937435984611511, Final Batch Loss: 1.8506684303283691\n",
      "Epoch 113, Loss: 5.480564475059509, Final Batch Loss: 1.3182862997055054\n",
      "Epoch 114, Loss: 5.837946653366089, Final Batch Loss: 1.684735655784607\n",
      "Epoch 115, Loss: 5.7912516593933105, Final Batch Loss: 1.4690194129943848\n",
      "Epoch 116, Loss: 5.814871430397034, Final Batch Loss: 1.6547796726226807\n",
      "Epoch 117, Loss: 5.887229323387146, Final Batch Loss: 1.792870283126831\n",
      "Epoch 118, Loss: 5.327261209487915, Final Batch Loss: 1.1499269008636475\n",
      "Epoch 119, Loss: 5.531791925430298, Final Batch Loss: 1.3848718404769897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss: 4.9789615869522095, Final Batch Loss: 0.8175690174102783\n",
      "Epoch 121, Loss: 5.128903746604919, Final Batch Loss: 1.0258671045303345\n",
      "Epoch 122, Loss: 5.493600368499756, Final Batch Loss: 1.2993334531784058\n",
      "Epoch 123, Loss: 7.355509877204895, Final Batch Loss: 3.118911027908325\n",
      "Epoch 124, Loss: 6.32703173160553, Final Batch Loss: 2.1168880462646484\n",
      "Epoch 125, Loss: 5.717969536781311, Final Batch Loss: 1.6001087427139282\n",
      "Epoch 126, Loss: 5.9138407707214355, Final Batch Loss: 1.7884864807128906\n",
      "Epoch 127, Loss: 5.617858052253723, Final Batch Loss: 1.486894965171814\n",
      "Epoch 128, Loss: 5.483014345169067, Final Batch Loss: 1.33988356590271\n",
      "Epoch 129, Loss: 6.0257333517074585, Final Batch Loss: 1.9047983884811401\n",
      "Epoch 130, Loss: 4.613044112920761, Final Batch Loss: 0.47653111815452576\n",
      "Epoch 131, Loss: 5.55274510383606, Final Batch Loss: 1.4567670822143555\n",
      "Epoch 132, Loss: 5.189761400222778, Final Batch Loss: 1.1275300979614258\n",
      "Epoch 133, Loss: 4.804865479469299, Final Batch Loss: 0.7811795473098755\n",
      "Epoch 134, Loss: 5.922738075256348, Final Batch Loss: 1.8879437446594238\n",
      "Epoch 135, Loss: 5.419355630874634, Final Batch Loss: 1.4401836395263672\n",
      "Epoch 136, Loss: 5.922075152397156, Final Batch Loss: 1.872054100036621\n",
      "Epoch 137, Loss: 5.702354550361633, Final Batch Loss: 1.6613537073135376\n",
      "Epoch 138, Loss: 5.6036494970321655, Final Batch Loss: 1.6237338781356812\n",
      "Epoch 139, Loss: 4.921407222747803, Final Batch Loss: 0.9047161340713501\n",
      "Epoch 140, Loss: 5.822677969932556, Final Batch Loss: 1.8571025133132935\n",
      "Epoch 141, Loss: 5.916566967964172, Final Batch Loss: 1.8914811611175537\n",
      "Epoch 142, Loss: 6.218949317932129, Final Batch Loss: 1.915590524673462\n",
      "Epoch 143, Loss: 5.644025564193726, Final Batch Loss: 1.253685474395752\n",
      "Epoch 144, Loss: 5.451529860496521, Final Batch Loss: 1.1944522857666016\n",
      "Epoch 145, Loss: 5.069593966007233, Final Batch Loss: 0.9476848244667053\n",
      "Epoch 146, Loss: 6.133806586265564, Final Batch Loss: 2.0844626426696777\n",
      "Epoch 147, Loss: 5.8578736782073975, Final Batch Loss: 1.8704220056533813\n",
      "Epoch 148, Loss: 5.823385119438171, Final Batch Loss: 1.8349169492721558\n",
      "Epoch 149, Loss: 5.709543466567993, Final Batch Loss: 1.7619706392288208\n",
      "Epoch 150, Loss: 5.539089679718018, Final Batch Loss: 1.6351125240325928\n",
      "Epoch 151, Loss: 5.0940446853637695, Final Batch Loss: 1.0990514755249023\n",
      "Epoch 152, Loss: 5.756761431694031, Final Batch Loss: 1.7962528467178345\n",
      "Epoch 153, Loss: 5.2743775844573975, Final Batch Loss: 1.3740172386169434\n",
      "Epoch 154, Loss: 4.832120776176453, Final Batch Loss: 0.9180546998977661\n",
      "Epoch 155, Loss: 5.438738226890564, Final Batch Loss: 1.4979815483093262\n",
      "Epoch 156, Loss: 5.322033524513245, Final Batch Loss: 1.4285187721252441\n",
      "Epoch 157, Loss: 5.8019737005233765, Final Batch Loss: 1.969437599182129\n",
      "Epoch 158, Loss: 4.377723664045334, Final Batch Loss: 0.4456789195537567\n",
      "Epoch 159, Loss: 5.269147872924805, Final Batch Loss: 1.4402025938034058\n",
      "Epoch 160, Loss: 4.701027750968933, Final Batch Loss: 0.8030872344970703\n",
      "Epoch 161, Loss: 4.483819365501404, Final Batch Loss: 0.6294838190078735\n",
      "Epoch 162, Loss: 4.864864706993103, Final Batch Loss: 1.102867603302002\n",
      "Epoch 163, Loss: 5.567118048667908, Final Batch Loss: 1.7547580003738403\n",
      "Epoch 164, Loss: 5.3575040102005005, Final Batch Loss: 1.4489442110061646\n",
      "Epoch 165, Loss: 5.3540085554122925, Final Batch Loss: 1.3827961683273315\n",
      "Epoch 166, Loss: 4.731176257133484, Final Batch Loss: 0.8758374452590942\n",
      "Epoch 167, Loss: 4.519412100315094, Final Batch Loss: 0.6693745255470276\n",
      "Epoch 168, Loss: 4.382303237915039, Final Batch Loss: 0.48726117610931396\n",
      "Epoch 169, Loss: 4.712565302848816, Final Batch Loss: 0.927495002746582\n",
      "Epoch 170, Loss: 5.057176470756531, Final Batch Loss: 1.2245688438415527\n",
      "Epoch 171, Loss: 5.647381067276001, Final Batch Loss: 1.8232719898223877\n",
      "Epoch 172, Loss: 6.013675093650818, Final Batch Loss: 2.1563563346862793\n",
      "Epoch 173, Loss: 4.294622600078583, Final Batch Loss: 0.34769076108932495\n",
      "Epoch 174, Loss: 5.02738082408905, Final Batch Loss: 1.104137897491455\n",
      "Epoch 175, Loss: 4.528082013130188, Final Batch Loss: 0.6214056015014648\n",
      "Epoch 176, Loss: 5.431551575660706, Final Batch Loss: 1.593407154083252\n",
      "Epoch 177, Loss: 4.325931996107101, Final Batch Loss: 0.45922955870628357\n",
      "Epoch 178, Loss: 5.235726594924927, Final Batch Loss: 1.3746490478515625\n",
      "Epoch 179, Loss: 4.268047958612442, Final Batch Loss: 0.46695879101753235\n",
      "Epoch 180, Loss: 4.347556889057159, Final Batch Loss: 0.5375346541404724\n",
      "Epoch 181, Loss: 5.773209571838379, Final Batch Loss: 1.9463646411895752\n",
      "Epoch 182, Loss: 4.670446693897247, Final Batch Loss: 0.9097784161567688\n",
      "Epoch 183, Loss: 4.972576379776001, Final Batch Loss: 1.2201851606369019\n",
      "Epoch 184, Loss: 4.764278054237366, Final Batch Loss: 1.0288708209991455\n",
      "Epoch 185, Loss: 4.410246968269348, Final Batch Loss: 0.665749192237854\n",
      "Epoch 186, Loss: 5.3283164501190186, Final Batch Loss: 1.598205327987671\n",
      "Epoch 187, Loss: 5.888632535934448, Final Batch Loss: 2.137707471847534\n",
      "Epoch 188, Loss: 5.384395956993103, Final Batch Loss: 1.608182430267334\n",
      "Epoch 189, Loss: 4.14114436507225, Final Batch Loss: 0.3242048919200897\n",
      "Epoch 190, Loss: 5.339431524276733, Final Batch Loss: 1.5639055967330933\n",
      "Epoch 191, Loss: 4.168921560049057, Final Batch Loss: 0.4752219617366791\n",
      "Epoch 192, Loss: 5.6442631483078, Final Batch Loss: 1.957114577293396\n",
      "Epoch 193, Loss: 4.414181172847748, Final Batch Loss: 0.61025470495224\n",
      "Epoch 194, Loss: 4.401492953300476, Final Batch Loss: 0.7284281253814697\n",
      "Epoch 195, Loss: 4.337059319019318, Final Batch Loss: 0.6481534838676453\n",
      "Epoch 196, Loss: 5.322800159454346, Final Batch Loss: 1.5800073146820068\n",
      "Epoch 197, Loss: 5.489855885505676, Final Batch Loss: 1.7844665050506592\n",
      "Epoch 198, Loss: 5.1936503648757935, Final Batch Loss: 1.489335298538208\n",
      "Epoch 199, Loss: 4.601989507675171, Final Batch Loss: 0.8270657062530518\n",
      "Epoch 200, Loss: 4.57740181684494, Final Batch Loss: 0.7682501673698425\n",
      "Epoch 201, Loss: 4.627176284790039, Final Batch Loss: 0.7664713859558105\n",
      "Epoch 202, Loss: 5.500940680503845, Final Batch Loss: 1.788552165031433\n",
      "Epoch 203, Loss: 5.188141942024231, Final Batch Loss: 1.5263035297393799\n",
      "Epoch 204, Loss: 4.469244182109833, Final Batch Loss: 0.6882633566856384\n",
      "Epoch 205, Loss: 4.8413132429122925, Final Batch Loss: 1.1279711723327637\n",
      "Epoch 206, Loss: 4.80001962184906, Final Batch Loss: 1.167972207069397\n",
      "Epoch 207, Loss: 4.681098103523254, Final Batch Loss: 1.0357478857040405\n",
      "Epoch 208, Loss: 4.178658187389374, Final Batch Loss: 0.5323637127876282\n",
      "Epoch 209, Loss: 4.8713778257369995, Final Batch Loss: 1.1463888883590698\n",
      "Epoch 210, Loss: 4.753366589546204, Final Batch Loss: 1.031904697418213\n",
      "Epoch 211, Loss: 4.122210890054703, Final Batch Loss: 0.45284953713417053\n",
      "Epoch 212, Loss: 4.398641884326935, Final Batch Loss: 0.7607045769691467\n",
      "Epoch 213, Loss: 4.059206575155258, Final Batch Loss: 0.4812191426753998\n",
      "Epoch 214, Loss: 3.926871657371521, Final Batch Loss: 0.3214837312698364\n",
      "Epoch 215, Loss: 4.402000844478607, Final Batch Loss: 0.8089085221290588\n",
      "Epoch 216, Loss: 5.0914386510849, Final Batch Loss: 1.4636435508728027\n",
      "Epoch 217, Loss: 3.828979343175888, Final Batch Loss: 0.25153848528862\n",
      "Epoch 218, Loss: 4.050747394561768, Final Batch Loss: 0.4581482410430908\n",
      "Epoch 219, Loss: 4.3616233468055725, Final Batch Loss: 0.8068738579750061\n",
      "Epoch 220, Loss: 3.835290476679802, Final Batch Loss: 0.21971790492534637\n",
      "Epoch 221, Loss: 4.4447978138923645, Final Batch Loss: 0.8629721999168396\n",
      "Epoch 222, Loss: 4.087282240390778, Final Batch Loss: 0.57016521692276\n",
      "Epoch 223, Loss: 4.979861259460449, Final Batch Loss: 1.469059705734253\n",
      "Epoch 224, Loss: 4.175148129463196, Final Batch Loss: 0.6381622552871704\n",
      "Epoch 225, Loss: 5.001536965370178, Final Batch Loss: 1.4214266538619995\n",
      "Epoch 226, Loss: 3.9490838050842285, Final Batch Loss: 0.3305431604385376\n",
      "Epoch 227, Loss: 5.248876690864563, Final Batch Loss: 1.699411153793335\n",
      "Epoch 228, Loss: 4.17225307226181, Final Batch Loss: 0.6819139122962952\n",
      "Epoch 229, Loss: 5.544348835945129, Final Batch Loss: 2.0414843559265137\n",
      "Epoch 230, Loss: 4.055385053157806, Final Batch Loss: 0.6545185446739197\n",
      "Epoch 231, Loss: 4.352771997451782, Final Batch Loss: 0.8356671333312988\n",
      "Epoch 232, Loss: 5.656800985336304, Final Batch Loss: 2.1271395683288574\n",
      "Epoch 233, Loss: 4.285136580467224, Final Batch Loss: 0.7558354139328003\n",
      "Epoch 234, Loss: 4.242897063493729, Final Batch Loss: 0.4446294605731964\n",
      "Epoch 235, Loss: 4.325015753507614, Final Batch Loss: 0.3532392680644989\n",
      "Epoch 236, Loss: 4.217688739299774, Final Batch Loss: 0.4595544934272766\n",
      "Epoch 237, Loss: 4.764333009719849, Final Batch Loss: 1.2020941972732544\n",
      "Epoch 238, Loss: 4.9406620264053345, Final Batch Loss: 1.4020063877105713\n",
      "Epoch 239, Loss: 5.201913118362427, Final Batch Loss: 1.6292266845703125\n",
      "Epoch 240, Loss: 5.896865010261536, Final Batch Loss: 2.381899356842041\n",
      "Epoch 241, Loss: 4.210958421230316, Final Batch Loss: 0.6619957089424133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242, Loss: 3.999774068593979, Final Batch Loss: 0.4275122582912445\n",
      "Epoch 243, Loss: 5.22041392326355, Final Batch Loss: 1.651489496231079\n",
      "Epoch 244, Loss: 3.7167284190654755, Final Batch Loss: 0.22315213084220886\n",
      "Epoch 245, Loss: 4.587936878204346, Final Batch Loss: 1.1303898096084595\n",
      "Epoch 246, Loss: 5.303292274475098, Final Batch Loss: 1.7779109477996826\n",
      "Epoch 247, Loss: 5.470344662666321, Final Batch Loss: 1.9378678798675537\n",
      "Epoch 248, Loss: 5.16180944442749, Final Batch Loss: 1.6224594116210938\n",
      "Epoch 249, Loss: 5.15681529045105, Final Batch Loss: 1.7483646869659424\n",
      "Epoch 250, Loss: 4.952137112617493, Final Batch Loss: 1.5259270668029785\n",
      "Epoch 251, Loss: 4.8489216566085815, Final Batch Loss: 1.4981955289840698\n",
      "Epoch 252, Loss: 5.152587056159973, Final Batch Loss: 1.716200828552246\n",
      "Epoch 253, Loss: 4.379698693752289, Final Batch Loss: 0.8585501313209534\n",
      "Epoch 254, Loss: 5.444775223731995, Final Batch Loss: 1.9153568744659424\n",
      "Epoch 255, Loss: 4.91340959072113, Final Batch Loss: 1.4166958332061768\n",
      "Epoch 256, Loss: 3.7045666873455048, Final Batch Loss: 0.24798855185508728\n",
      "Epoch 257, Loss: 5.188300728797913, Final Batch Loss: 1.8397668600082397\n",
      "Epoch 258, Loss: 5.239184021949768, Final Batch Loss: 1.8782575130462646\n",
      "Epoch 259, Loss: 4.948434472084045, Final Batch Loss: 1.4668487310409546\n",
      "Epoch 260, Loss: 4.527175545692444, Final Batch Loss: 0.7691053152084351\n",
      "Epoch 261, Loss: 5.497915506362915, Final Batch Loss: 1.7760744094848633\n",
      "Epoch 262, Loss: 5.202061891555786, Final Batch Loss: 1.6343765258789062\n",
      "Epoch 263, Loss: 4.004999995231628, Final Batch Loss: 0.580001711845398\n",
      "Epoch 264, Loss: 4.388808727264404, Final Batch Loss: 0.9594758749008179\n",
      "Epoch 265, Loss: 3.9739920496940613, Final Batch Loss: 0.5758302807807922\n",
      "Epoch 266, Loss: 4.538827657699585, Final Batch Loss: 1.1729743480682373\n",
      "Epoch 267, Loss: 3.7810659408569336, Final Batch Loss: 0.39217209815979004\n",
      "Epoch 268, Loss: 4.142759084701538, Final Batch Loss: 0.8349913358688354\n",
      "Epoch 269, Loss: 3.9654513001441956, Final Batch Loss: 0.6644555926322937\n",
      "Epoch 270, Loss: 4.383972764015198, Final Batch Loss: 1.0932400226593018\n",
      "Epoch 271, Loss: 5.357502579689026, Final Batch Loss: 2.0107593536376953\n",
      "Epoch 272, Loss: 4.344656944274902, Final Batch Loss: 1.001183032989502\n",
      "Epoch 273, Loss: 4.596651792526245, Final Batch Loss: 1.2589550018310547\n",
      "Epoch 274, Loss: 3.7027023434638977, Final Batch Loss: 0.40145570039749146\n",
      "Epoch 275, Loss: 3.8185094594955444, Final Batch Loss: 0.5374999046325684\n",
      "Epoch 276, Loss: 5.111883640289307, Final Batch Loss: 1.816478967666626\n",
      "Epoch 277, Loss: 3.5869401395320892, Final Batch Loss: 0.2845596969127655\n",
      "Epoch 278, Loss: 4.988842129707336, Final Batch Loss: 1.6540488004684448\n",
      "Epoch 279, Loss: 3.946845054626465, Final Batch Loss: 0.659797191619873\n",
      "Epoch 280, Loss: 3.7680907547473907, Final Batch Loss: 0.4950273334980011\n",
      "Epoch 281, Loss: 5.005078911781311, Final Batch Loss: 1.8163352012634277\n",
      "Epoch 282, Loss: 4.736358284950256, Final Batch Loss: 1.514898657798767\n",
      "Epoch 283, Loss: 4.321463465690613, Final Batch Loss: 1.1567835807800293\n",
      "Epoch 284, Loss: 3.9008058309555054, Final Batch Loss: 0.6690012216567993\n",
      "Epoch 285, Loss: 3.4331290274858475, Final Batch Loss: 0.2423299103975296\n",
      "Epoch 286, Loss: 4.276881694793701, Final Batch Loss: 1.0774725675582886\n",
      "Epoch 287, Loss: 4.166991114616394, Final Batch Loss: 1.014251708984375\n",
      "Epoch 288, Loss: 5.162679493427277, Final Batch Loss: 2.018059730529785\n",
      "Epoch 289, Loss: 5.730565309524536, Final Batch Loss: 2.5311262607574463\n",
      "Epoch 290, Loss: 4.010218858718872, Final Batch Loss: 0.7530002593994141\n",
      "Epoch 291, Loss: 4.985867142677307, Final Batch Loss: 1.7408581972122192\n",
      "Epoch 292, Loss: 4.064486920833588, Final Batch Loss: 0.8901289105415344\n",
      "Epoch 293, Loss: 3.3416252732276917, Final Batch Loss: 0.20921868085861206\n",
      "Epoch 294, Loss: 4.658621430397034, Final Batch Loss: 1.4177166223526\n",
      "Epoch 295, Loss: 3.2485818564891815, Final Batch Loss: 0.11904796957969666\n",
      "Epoch 296, Loss: 5.149984121322632, Final Batch Loss: 1.953890085220337\n",
      "Epoch 297, Loss: 3.316236734390259, Final Batch Loss: 0.12329351902008057\n",
      "Epoch 298, Loss: 3.66487056016922, Final Batch Loss: 0.5632644295692444\n",
      "Epoch 299, Loss: 3.2141106128692627, Final Batch Loss: 0.1282557249069214\n",
      "Epoch 300, Loss: 4.355537474155426, Final Batch Loss: 1.2411034107208252\n",
      "Epoch 301, Loss: 4.289776086807251, Final Batch Loss: 1.2171108722686768\n",
      "Epoch 302, Loss: 5.10552304983139, Final Batch Loss: 1.9795136451721191\n",
      "Epoch 303, Loss: 3.3637336045503616, Final Batch Loss: 0.23038692772388458\n",
      "Epoch 304, Loss: 3.484899491071701, Final Batch Loss: 0.37674495577812195\n",
      "Epoch 305, Loss: 3.826157510280609, Final Batch Loss: 0.7236077189445496\n",
      "Epoch 306, Loss: 4.812261343002319, Final Batch Loss: 1.6945509910583496\n",
      "Epoch 307, Loss: 3.9661983847618103, Final Batch Loss: 0.915109395980835\n",
      "Epoch 308, Loss: 3.4085763692855835, Final Batch Loss: 0.31976962089538574\n",
      "Epoch 309, Loss: 3.544334053993225, Final Batch Loss: 0.4471951127052307\n",
      "Epoch 310, Loss: 3.8490885496139526, Final Batch Loss: 0.7149198055267334\n",
      "Epoch 311, Loss: 4.6937255859375, Final Batch Loss: 1.5651123523712158\n",
      "Epoch 312, Loss: 4.118527770042419, Final Batch Loss: 0.9830752611160278\n",
      "Epoch 313, Loss: 3.5100632309913635, Final Batch Loss: 0.43507111072540283\n",
      "Epoch 314, Loss: 3.8514389395713806, Final Batch Loss: 0.7970330715179443\n",
      "Epoch 315, Loss: 4.558497250080109, Final Batch Loss: 1.5021570920944214\n",
      "Epoch 316, Loss: 4.2047120332717896, Final Batch Loss: 1.0772759914398193\n",
      "Epoch 317, Loss: 3.349263474345207, Final Batch Loss: 0.18833379447460175\n",
      "Epoch 318, Loss: 4.713928580284119, Final Batch Loss: 1.61469304561615\n",
      "Epoch 319, Loss: 3.9227587580680847, Final Batch Loss: 0.7806029915809631\n",
      "Epoch 320, Loss: 5.292019963264465, Final Batch Loss: 2.255342721939087\n",
      "Epoch 321, Loss: 4.622705340385437, Final Batch Loss: 1.556508183479309\n",
      "Epoch 322, Loss: 3.2868094444274902, Final Batch Loss: 0.22941958904266357\n",
      "Epoch 323, Loss: 3.8613497018814087, Final Batch Loss: 0.7318240404129028\n",
      "Epoch 324, Loss: 4.825415253639221, Final Batch Loss: 1.8262403011322021\n",
      "Epoch 325, Loss: 4.560606777667999, Final Batch Loss: 1.5269439220428467\n",
      "Epoch 326, Loss: 3.414724677801132, Final Batch Loss: 0.36121150851249695\n",
      "Epoch 327, Loss: 3.0558444783091545, Final Batch Loss: 0.07211553305387497\n",
      "Epoch 328, Loss: 3.3376927375793457, Final Batch Loss: 0.3317198157310486\n",
      "Epoch 329, Loss: 3.0248225685209036, Final Batch Loss: 0.028043901547789574\n",
      "Epoch 330, Loss: 4.1122559905052185, Final Batch Loss: 1.1320438385009766\n",
      "Epoch 331, Loss: 3.5948253870010376, Final Batch Loss: 0.5637293457984924\n",
      "Epoch 332, Loss: 3.0311232432723045, Final Batch Loss: 0.030558012425899506\n",
      "Epoch 333, Loss: 3.1469021290540695, Final Batch Loss: 0.16349773108959198\n",
      "Epoch 334, Loss: 3.227063626050949, Final Batch Loss: 0.2959948480129242\n",
      "Epoch 335, Loss: 4.460397124290466, Final Batch Loss: 1.5285073518753052\n",
      "Epoch 336, Loss: 4.3547602891922, Final Batch Loss: 1.330251693725586\n",
      "Epoch 337, Loss: 4.895576179027557, Final Batch Loss: 2.0668723583221436\n",
      "Epoch 338, Loss: 3.9085792899131775, Final Batch Loss: 0.8412585854530334\n",
      "Epoch 339, Loss: 5.174639701843262, Final Batch Loss: 2.090151309967041\n",
      "Epoch 340, Loss: 4.842637479305267, Final Batch Loss: 1.7758634090423584\n",
      "Epoch 341, Loss: 4.66396290063858, Final Batch Loss: 1.7400816679000854\n",
      "Epoch 342, Loss: 3.036895677447319, Final Batch Loss: 0.09623710811138153\n",
      "Epoch 343, Loss: 3.2624832689762115, Final Batch Loss: 0.2919633090496063\n",
      "Epoch 344, Loss: 4.9289862513542175, Final Batch Loss: 1.9702930450439453\n",
      "Epoch 345, Loss: 3.9207111597061157, Final Batch Loss: 0.962660014629364\n",
      "Epoch 346, Loss: 3.274116411805153, Final Batch Loss: 0.19034262001514435\n",
      "Epoch 347, Loss: 4.430362224578857, Final Batch Loss: 1.3952574729919434\n",
      "Epoch 348, Loss: 4.0706751346588135, Final Batch Loss: 1.135693907737732\n",
      "Epoch 349, Loss: 5.448401987552643, Final Batch Loss: 2.507312297821045\n",
      "Epoch 350, Loss: 3.4790053367614746, Final Batch Loss: 0.47408854961395264\n",
      "Epoch 351, Loss: 4.80149120092392, Final Batch Loss: 1.6843451261520386\n",
      "Epoch 352, Loss: 5.838352739810944, Final Batch Loss: 2.8212218284606934\n",
      "Epoch 353, Loss: 3.1540115028619766, Final Batch Loss: 0.18091721832752228\n",
      "Epoch 354, Loss: 4.7523781061172485, Final Batch Loss: 1.7911845445632935\n",
      "Epoch 355, Loss: 4.47373765707016, Final Batch Loss: 1.4800419807434082\n",
      "Epoch 356, Loss: 4.438237369060516, Final Batch Loss: 1.4741166830062866\n",
      "Epoch 357, Loss: 3.6342591047286987, Final Batch Loss: 0.6510875225067139\n",
      "Epoch 358, Loss: 3.5167683959007263, Final Batch Loss: 0.5096678733825684\n",
      "Epoch 359, Loss: 3.6616119146347046, Final Batch Loss: 0.6094552278518677\n",
      "Epoch 360, Loss: 4.299264848232269, Final Batch Loss: 1.3301297426223755\n",
      "Epoch 361, Loss: 3.3800905644893646, Final Batch Loss: 0.450188547372818\n",
      "Epoch 362, Loss: 3.858161747455597, Final Batch Loss: 0.904178261756897\n",
      "Epoch 363, Loss: 5.157428681850433, Final Batch Loss: 2.23854923248291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364, Loss: 3.9531408548355103, Final Batch Loss: 1.098373532295227\n",
      "Epoch 365, Loss: 3.4954793453216553, Final Batch Loss: 0.5587245225906372\n",
      "Epoch 366, Loss: 4.165323615074158, Final Batch Loss: 1.2437822818756104\n",
      "Epoch 367, Loss: 3.855770766735077, Final Batch Loss: 0.9599010944366455\n",
      "Epoch 368, Loss: 3.5415871143341064, Final Batch Loss: 0.6778891682624817\n",
      "Epoch 369, Loss: 4.723100185394287, Final Batch Loss: 1.8740044832229614\n",
      "Epoch 370, Loss: 3.878543257713318, Final Batch Loss: 1.0803393125534058\n",
      "Epoch 371, Loss: 3.195245146751404, Final Batch Loss: 0.28364914655685425\n",
      "Epoch 372, Loss: 3.7890482544898987, Final Batch Loss: 0.9882201552391052\n",
      "Epoch 373, Loss: 4.673769116401672, Final Batch Loss: 1.7210179567337036\n",
      "Epoch 374, Loss: 3.114308178424835, Final Batch Loss: 0.3466287851333618\n",
      "Epoch 375, Loss: 4.445478856563568, Final Batch Loss: 1.5914852619171143\n",
      "Epoch 376, Loss: 4.530440151691437, Final Batch Loss: 1.7089293003082275\n",
      "Epoch 377, Loss: 5.457998752593994, Final Batch Loss: 2.496861219406128\n",
      "Epoch 378, Loss: 4.433063983917236, Final Batch Loss: 1.4838628768920898\n",
      "Epoch 379, Loss: 3.922865927219391, Final Batch Loss: 0.9022116661071777\n",
      "Epoch 380, Loss: 3.319708287715912, Final Batch Loss: 0.29090726375579834\n",
      "Epoch 381, Loss: 3.6386083364486694, Final Batch Loss: 0.5118128061294556\n",
      "Epoch 382, Loss: 3.279601067304611, Final Batch Loss: 0.3307459056377411\n",
      "Epoch 383, Loss: 6.955244421958923, Final Batch Loss: 4.053407192230225\n",
      "Epoch 384, Loss: 4.383067429065704, Final Batch Loss: 1.398459792137146\n",
      "Epoch 385, Loss: 4.30592268705368, Final Batch Loss: 1.2079601287841797\n",
      "Epoch 386, Loss: 3.361955404281616, Final Batch Loss: 0.2675131559371948\n",
      "Epoch 387, Loss: 3.143951117992401, Final Batch Loss: 0.13616186380386353\n",
      "Epoch 388, Loss: 5.037357568740845, Final Batch Loss: 1.8905259370803833\n",
      "Epoch 389, Loss: 5.385216057300568, Final Batch Loss: 2.3386499881744385\n",
      "Epoch 390, Loss: 2.9767704382538795, Final Batch Loss: 0.0984605923295021\n",
      "Epoch 391, Loss: 4.2647780776023865, Final Batch Loss: 1.3439010381698608\n",
      "Epoch 392, Loss: 3.4112237989902496, Final Batch Loss: 0.39935240149497986\n",
      "Epoch 393, Loss: 3.860197901725769, Final Batch Loss: 0.8622492551803589\n",
      "Epoch 394, Loss: 3.108135551214218, Final Batch Loss: 0.18854567408561707\n",
      "Epoch 395, Loss: 3.7976596355438232, Final Batch Loss: 0.8850966095924377\n",
      "Epoch 396, Loss: 3.7140477299690247, Final Batch Loss: 0.8512320518493652\n",
      "Epoch 397, Loss: 4.6880316734313965, Final Batch Loss: 1.8639419078826904\n",
      "Epoch 398, Loss: 4.427083194255829, Final Batch Loss: 1.5722196102142334\n",
      "Epoch 399, Loss: 4.650097370147705, Final Batch Loss: 1.7932559251785278\n",
      "Epoch 400, Loss: 3.4868152737617493, Final Batch Loss: 0.6198732256889343\n",
      "Epoch 401, Loss: 3.0442837327718735, Final Batch Loss: 0.14930348098278046\n",
      "Epoch 402, Loss: 3.133664309978485, Final Batch Loss: 0.27443230152130127\n",
      "Epoch 403, Loss: 4.5577332973480225, Final Batch Loss: 1.7122665643692017\n",
      "Epoch 404, Loss: 5.09661728143692, Final Batch Loss: 2.249999761581421\n",
      "Epoch 405, Loss: 3.1731131970882416, Final Batch Loss: 0.35047683119773865\n",
      "Epoch 406, Loss: 4.713736116886139, Final Batch Loss: 1.6735713481903076\n",
      "Epoch 407, Loss: 6.943720459938049, Final Batch Loss: 3.8451220989227295\n",
      "Epoch 408, Loss: 4.992437779903412, Final Batch Loss: 1.9545490741729736\n",
      "Epoch 409, Loss: 3.086852118372917, Final Batch Loss: 0.10870151221752167\n",
      "Epoch 410, Loss: 3.822411596775055, Final Batch Loss: 1.015528917312622\n",
      "Epoch 411, Loss: 3.341726303100586, Final Batch Loss: 0.4717346429824829\n",
      "Epoch 412, Loss: 3.2365100979804993, Final Batch Loss: 0.3870406150817871\n",
      "Epoch 413, Loss: 2.8517144322395325, Final Batch Loss: 0.07804882526397705\n",
      "Epoch 414, Loss: 4.444097578525543, Final Batch Loss: 1.6308908462524414\n",
      "Epoch 415, Loss: 3.1474876701831818, Final Batch Loss: 0.31926247477531433\n",
      "Epoch 416, Loss: 3.0093384832143784, Final Batch Loss: 0.23459647595882416\n",
      "Epoch 417, Loss: 4.027891993522644, Final Batch Loss: 1.2968909740447998\n",
      "Epoch 418, Loss: 3.395576059818268, Final Batch Loss: 0.5492212772369385\n",
      "Epoch 419, Loss: 5.981110990047455, Final Batch Loss: 3.155690908432007\n",
      "Epoch 420, Loss: 4.417535483837128, Final Batch Loss: 1.616743803024292\n",
      "Epoch 421, Loss: 3.0565739572048187, Final Batch Loss: 0.2495150864124298\n",
      "Epoch 422, Loss: 3.183459162712097, Final Batch Loss: 0.21536630392074585\n",
      "Epoch 423, Loss: 3.785530745983124, Final Batch Loss: 0.7261182069778442\n",
      "Epoch 424, Loss: 5.3668259382247925, Final Batch Loss: 2.461414098739624\n",
      "Epoch 425, Loss: 5.188731372356415, Final Batch Loss: 2.23121976852417\n",
      "Epoch 426, Loss: 4.501548111438751, Final Batch Loss: 1.547358751296997\n",
      "Epoch 427, Loss: 3.2264861166477203, Final Batch Loss: 0.3241482675075531\n",
      "Epoch 428, Loss: 3.332124948501587, Final Batch Loss: 0.46921080350875854\n",
      "Epoch 429, Loss: 2.8773378506302834, Final Batch Loss: 0.08894065767526627\n",
      "Epoch 430, Loss: 4.908435821533203, Final Batch Loss: 2.0681204795837402\n",
      "Epoch 431, Loss: 2.8654337227344513, Final Batch Loss: 0.09649887681007385\n",
      "Epoch 432, Loss: 3.3417121171951294, Final Batch Loss: 0.49237215518951416\n",
      "Epoch 433, Loss: 4.553146123886108, Final Batch Loss: 1.813957691192627\n",
      "Epoch 434, Loss: 5.2331936955451965, Final Batch Loss: 2.423391342163086\n",
      "Epoch 435, Loss: 3.9274592995643616, Final Batch Loss: 1.1444412469863892\n",
      "Epoch 436, Loss: 4.364018082618713, Final Batch Loss: 1.5912851095199585\n",
      "Epoch 437, Loss: 2.888219490647316, Final Batch Loss: 0.18637670576572418\n",
      "Epoch 438, Loss: 3.084001749753952, Final Batch Loss: 0.35160937905311584\n",
      "Epoch 439, Loss: 3.8912145495414734, Final Batch Loss: 1.0660011768341064\n",
      "Epoch 440, Loss: 3.6139445304870605, Final Batch Loss: 0.8944470882415771\n",
      "Epoch 441, Loss: 3.7542762756347656, Final Batch Loss: 1.0171819925308228\n",
      "Epoch 442, Loss: 3.1230345964431763, Final Batch Loss: 0.4002358913421631\n",
      "Epoch 443, Loss: 3.0986063480377197, Final Batch Loss: 0.2964579463005066\n",
      "Epoch 444, Loss: 4.995078027248383, Final Batch Loss: 2.163769483566284\n",
      "Epoch 445, Loss: 4.823624551296234, Final Batch Loss: 2.006314516067505\n",
      "Epoch 446, Loss: 3.257745146751404, Final Batch Loss: 0.4770253896713257\n",
      "Epoch 447, Loss: 4.157372891902924, Final Batch Loss: 1.4856855869293213\n",
      "Epoch 448, Loss: 4.573010563850403, Final Batch Loss: 1.8688747882843018\n",
      "Epoch 449, Loss: 3.647925615310669, Final Batch Loss: 0.8193413019180298\n",
      "Epoch 450, Loss: 3.0490653663873672, Final Batch Loss: 0.24707050621509552\n",
      "Epoch 451, Loss: 3.0396795123815536, Final Batch Loss: 0.23667971789836884\n",
      "Epoch 452, Loss: 2.8965392261743546, Final Batch Loss: 0.13305462896823883\n",
      "Epoch 453, Loss: 3.231827825307846, Final Batch Loss: 0.46349266171455383\n",
      "Epoch 454, Loss: 3.1827316880226135, Final Batch Loss: 0.43962371349334717\n",
      "Epoch 455, Loss: 3.0744616389274597, Final Batch Loss: 0.36355626583099365\n",
      "Epoch 456, Loss: 3.249081462621689, Final Batch Loss: 0.47161540389060974\n",
      "Epoch 457, Loss: 4.08046293258667, Final Batch Loss: 1.420121431350708\n",
      "Epoch 458, Loss: 4.212351322174072, Final Batch Loss: 1.5006186962127686\n",
      "Epoch 459, Loss: 2.860211655497551, Final Batch Loss: 0.16518853604793549\n",
      "Epoch 460, Loss: 3.283236563205719, Final Batch Loss: 0.5707030296325684\n",
      "Epoch 461, Loss: 4.342209756374359, Final Batch Loss: 1.6644185781478882\n",
      "Epoch 462, Loss: 3.40824156999588, Final Batch Loss: 0.7011054754257202\n",
      "Epoch 463, Loss: 4.320541322231293, Final Batch Loss: 1.547283411026001\n",
      "Epoch 464, Loss: 2.787849709391594, Final Batch Loss: 0.08146201074123383\n",
      "Epoch 465, Loss: 4.419776141643524, Final Batch Loss: 1.7571651935577393\n",
      "Epoch 466, Loss: 4.067203164100647, Final Batch Loss: 1.419466495513916\n",
      "Epoch 467, Loss: 4.156196892261505, Final Batch Loss: 1.4573321342468262\n",
      "Epoch 468, Loss: 3.0796403288841248, Final Batch Loss: 0.34253746271133423\n",
      "Epoch 469, Loss: 3.2418151199817657, Final Batch Loss: 0.47823187708854675\n",
      "Epoch 470, Loss: 2.7753685116767883, Final Batch Loss: 0.08831584453582764\n",
      "Epoch 471, Loss: 4.460373520851135, Final Batch Loss: 1.8125624656677246\n",
      "Epoch 472, Loss: 4.364462673664093, Final Batch Loss: 1.76968252658844\n",
      "Epoch 473, Loss: 3.938362419605255, Final Batch Loss: 1.2586045265197754\n",
      "Epoch 474, Loss: 3.0286950767040253, Final Batch Loss: 0.39160946011543274\n",
      "Epoch 475, Loss: 2.952788308262825, Final Batch Loss: 0.2248772531747818\n",
      "Epoch 476, Loss: 4.67376184463501, Final Batch Loss: 1.9241384267807007\n",
      "Epoch 477, Loss: 3.8523706197738647, Final Batch Loss: 1.137200117111206\n",
      "Epoch 478, Loss: 4.1435845494270325, Final Batch Loss: 1.4694346189498901\n",
      "Epoch 479, Loss: 2.9350744634866714, Final Batch Loss: 0.20850057899951935\n",
      "Epoch 480, Loss: 6.059469521045685, Final Batch Loss: 3.425248622894287\n",
      "Epoch 481, Loss: 3.0205136239528656, Final Batch Loss: 0.26087722182273865\n",
      "Epoch 482, Loss: 2.6870045848190784, Final Batch Loss: 0.032918531447649\n",
      "Epoch 483, Loss: 2.9965085089206696, Final Batch Loss: 0.29544922709465027\n",
      "Epoch 484, Loss: 2.818825274705887, Final Batch Loss: 0.13142773509025574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485, Loss: 3.034577190876007, Final Batch Loss: 0.299923837184906\n",
      "Epoch 486, Loss: 2.7171144410967827, Final Batch Loss: 0.06235813349485397\n",
      "Epoch 487, Loss: 2.7776255756616592, Final Batch Loss: 0.08908297121524811\n",
      "Epoch 488, Loss: 2.951182872056961, Final Batch Loss: 0.33158883452415466\n",
      "Epoch 489, Loss: 4.5480599999427795, Final Batch Loss: 1.807560682296753\n",
      "Epoch 490, Loss: 4.118229150772095, Final Batch Loss: 1.403193473815918\n",
      "Epoch 491, Loss: 4.6420938372612, Final Batch Loss: 2.005972146987915\n",
      "Epoch 492, Loss: 4.128359019756317, Final Batch Loss: 1.5051510334014893\n",
      "Epoch 493, Loss: 7.209329724311829, Final Batch Loss: 4.594730854034424\n",
      "Epoch 494, Loss: 4.290566086769104, Final Batch Loss: 1.4914677143096924\n",
      "Epoch 495, Loss: 3.2669522166252136, Final Batch Loss: 0.567240834236145\n",
      "Epoch 496, Loss: 4.043312191963196, Final Batch Loss: 1.305344820022583\n",
      "Epoch 497, Loss: 4.519927680492401, Final Batch Loss: 1.7692625522613525\n",
      "Epoch 498, Loss: 4.562558174133301, Final Batch Loss: 1.804521918296814\n",
      "Epoch 499, Loss: 3.1229275166988373, Final Batch Loss: 0.46150556206703186\n",
      "Epoch 500, Loss: 3.4071739315986633, Final Batch Loss: 0.6033459901809692\n",
      "Epoch 501, Loss: 4.25415712594986, Final Batch Loss: 1.256531000137329\n",
      "Epoch 502, Loss: 4.19381183385849, Final Batch Loss: 1.0686968564987183\n",
      "Epoch 503, Loss: 3.3797520995140076, Final Batch Loss: 0.44076162576675415\n",
      "Epoch 504, Loss: 3.2317187786102295, Final Batch Loss: 0.3317481279373169\n",
      "Epoch 505, Loss: 3.0557138919830322, Final Batch Loss: 0.20378947257995605\n",
      "Epoch 506, Loss: 3.515921890735626, Final Batch Loss: 0.8027359247207642\n",
      "Epoch 507, Loss: 3.6632487177848816, Final Batch Loss: 0.9011139869689941\n",
      "Epoch 508, Loss: 2.75037095323205, Final Batch Loss: 0.04318705573678017\n",
      "Epoch 509, Loss: 3.0586155354976654, Final Batch Loss: 0.35121479630470276\n",
      "Epoch 510, Loss: 4.104699194431305, Final Batch Loss: 1.4661684036254883\n",
      "Epoch 511, Loss: 2.9809563755989075, Final Batch Loss: 0.29496675729751587\n",
      "Epoch 512, Loss: 5.058341860771179, Final Batch Loss: 2.3735904693603516\n",
      "Epoch 513, Loss: 3.8077340126037598, Final Batch Loss: 1.136462926864624\n",
      "Epoch 514, Loss: 3.878260612487793, Final Batch Loss: 1.197834849357605\n",
      "Epoch 515, Loss: 3.2133495807647705, Final Batch Loss: 0.5518911480903625\n",
      "Epoch 516, Loss: 4.014310657978058, Final Batch Loss: 1.4225971698760986\n",
      "Epoch 517, Loss: 3.1648911833763123, Final Batch Loss: 0.5880987644195557\n",
      "Epoch 518, Loss: 2.835058629512787, Final Batch Loss: 0.13094061613082886\n",
      "Epoch 519, Loss: 2.8503766991198063, Final Batch Loss: 0.04320863261818886\n",
      "Epoch 520, Loss: 4.175843715667725, Final Batch Loss: 1.4105393886566162\n",
      "Epoch 521, Loss: 2.8047585040330887, Final Batch Loss: 0.07284153997898102\n",
      "Epoch 522, Loss: 2.930429130792618, Final Batch Loss: 0.26622292399406433\n",
      "Epoch 523, Loss: 3.68535453081131, Final Batch Loss: 0.9789659976959229\n",
      "Epoch 524, Loss: 3.1283977031707764, Final Batch Loss: 0.5594731569290161\n",
      "Epoch 525, Loss: 3.0915396213531494, Final Batch Loss: 0.4830890893936157\n",
      "Epoch 526, Loss: 3.2017120718955994, Final Batch Loss: 0.5735920071601868\n",
      "Epoch 527, Loss: 2.8445079624652863, Final Batch Loss: 0.20959749817848206\n",
      "Epoch 528, Loss: 4.650139153003693, Final Batch Loss: 1.9939873218536377\n",
      "Epoch 529, Loss: 2.9216251969337463, Final Batch Loss: 0.3183431029319763\n",
      "Epoch 530, Loss: 4.7461400628089905, Final Batch Loss: 2.063934803009033\n",
      "Epoch 531, Loss: 3.7962244153022766, Final Batch Loss: 1.1382012367248535\n",
      "Epoch 532, Loss: 3.983055353164673, Final Batch Loss: 1.4275087118148804\n",
      "Epoch 533, Loss: 3.2201085090637207, Final Batch Loss: 0.5548201203346252\n",
      "Epoch 534, Loss: 3.398883581161499, Final Batch Loss: 0.6379413604736328\n",
      "Epoch 535, Loss: 3.204829752445221, Final Batch Loss: 0.4410768747329712\n",
      "Epoch 536, Loss: 2.988515466451645, Final Batch Loss: 0.12840387225151062\n",
      "Epoch 537, Loss: 5.098185658454895, Final Batch Loss: 2.308483123779297\n",
      "Epoch 538, Loss: 2.8611312806606293, Final Batch Loss: 0.14872422814369202\n",
      "Epoch 539, Loss: 3.9697126150131226, Final Batch Loss: 1.2455668449401855\n",
      "Epoch 540, Loss: 2.6662584766745567, Final Batch Loss: 0.04651244729757309\n",
      "Epoch 541, Loss: 2.766453817486763, Final Batch Loss: 0.16932202875614166\n",
      "Epoch 542, Loss: 4.676048934459686, Final Batch Loss: 2.1013998985290527\n",
      "Epoch 543, Loss: 2.8175867795944214, Final Batch Loss: 0.28237730264663696\n",
      "Epoch 544, Loss: 5.083024501800537, Final Batch Loss: 2.5401721000671387\n",
      "Epoch 545, Loss: 2.6680464036762714, Final Batch Loss: 0.04278634861111641\n",
      "Epoch 546, Loss: 2.8037548661231995, Final Batch Loss: 0.20787560939788818\n",
      "Epoch 547, Loss: 3.2291810512542725, Final Batch Loss: 0.6439173817634583\n",
      "Epoch 548, Loss: 3.099320650100708, Final Batch Loss: 0.571739912033081\n",
      "Epoch 549, Loss: 2.9957641065120697, Final Batch Loss: 0.37055703997612\n",
      "Epoch 550, Loss: 4.363275110721588, Final Batch Loss: 1.7728495597839355\n",
      "Epoch 551, Loss: 3.606453776359558, Final Batch Loss: 1.042063593864441\n",
      "Epoch 552, Loss: 3.9049222469329834, Final Batch Loss: 1.2663389444351196\n",
      "Epoch 553, Loss: 3.6100290417671204, Final Batch Loss: 0.9600604176521301\n",
      "Epoch 554, Loss: 4.180957794189453, Final Batch Loss: 1.5045723915100098\n",
      "Epoch 555, Loss: 2.9182637482881546, Final Batch Loss: 0.23553772270679474\n",
      "Epoch 556, Loss: 2.722406305372715, Final Batch Loss: 0.07423398643732071\n",
      "Epoch 557, Loss: 3.8861470222473145, Final Batch Loss: 1.2661364078521729\n",
      "Epoch 558, Loss: 3.545943856239319, Final Batch Loss: 0.9615637063980103\n",
      "Epoch 559, Loss: 3.6297460794448853, Final Batch Loss: 1.0785821676254272\n",
      "Epoch 560, Loss: 8.441669404506683, Final Batch Loss: 5.854351997375488\n",
      "Epoch 561, Loss: 2.8597016632556915, Final Batch Loss: 0.28934958577156067\n",
      "Epoch 562, Loss: 2.789941295981407, Final Batch Loss: 0.11388806998729706\n",
      "Epoch 563, Loss: 3.3573095202445984, Final Batch Loss: 0.6133487224578857\n",
      "Epoch 564, Loss: 3.4436172246932983, Final Batch Loss: 0.5193007588386536\n",
      "Epoch 565, Loss: 3.391491949558258, Final Batch Loss: 0.5582680702209473\n",
      "Epoch 566, Loss: 4.204001724720001, Final Batch Loss: 1.4004442691802979\n",
      "Epoch 567, Loss: 2.7388041019439697, Final Batch Loss: 0.08161133527755737\n",
      "Epoch 568, Loss: 4.491332113742828, Final Batch Loss: 1.774285078048706\n",
      "Epoch 569, Loss: 2.7017483934760094, Final Batch Loss: 0.10639139264822006\n",
      "Epoch 570, Loss: 2.608049441128969, Final Batch Loss: 0.0352737195789814\n",
      "Epoch 571, Loss: 2.9396064281463623, Final Batch Loss: 0.27558833360671997\n",
      "Epoch 572, Loss: 3.3631768822669983, Final Batch Loss: 0.821744978427887\n",
      "Epoch 573, Loss: 4.067984700202942, Final Batch Loss: 1.51695716381073\n",
      "Epoch 574, Loss: 4.122212469577789, Final Batch Loss: 1.494781255722046\n",
      "Epoch 575, Loss: 2.5984946861863136, Final Batch Loss: 0.09275618940591812\n",
      "Epoch 576, Loss: 2.640317887067795, Final Batch Loss: 0.0772460401058197\n",
      "Epoch 577, Loss: 3.338095247745514, Final Batch Loss: 0.8332908153533936\n",
      "Epoch 578, Loss: 3.2793890833854675, Final Batch Loss: 0.7463948726654053\n",
      "Epoch 579, Loss: 3.3880255222320557, Final Batch Loss: 0.7771586179733276\n",
      "Epoch 580, Loss: 2.9679741263389587, Final Batch Loss: 0.205497145652771\n",
      "Epoch 581, Loss: 2.926268994808197, Final Batch Loss: 0.25725406408309937\n",
      "Epoch 582, Loss: 3.601060926914215, Final Batch Loss: 1.022277593612671\n",
      "Epoch 583, Loss: 3.4991820454597473, Final Batch Loss: 0.8500539660453796\n",
      "Epoch 584, Loss: 2.6313379420898855, Final Batch Loss: 0.005993844475597143\n",
      "Epoch 585, Loss: 3.0274128317832947, Final Batch Loss: 0.3880424499511719\n",
      "Epoch 586, Loss: 3.179378032684326, Final Batch Loss: 0.6376729607582092\n",
      "Epoch 587, Loss: 2.9618991017341614, Final Batch Loss: 0.34409040212631226\n",
      "Epoch 588, Loss: 2.661672830581665, Final Batch Loss: 0.09747302532196045\n",
      "Epoch 589, Loss: 4.294432103633881, Final Batch Loss: 1.7522265911102295\n",
      "Epoch 590, Loss: 3.811220407485962, Final Batch Loss: 1.203709363937378\n",
      "Epoch 591, Loss: 2.6346171125769615, Final Batch Loss: 0.08836790174245834\n",
      "Epoch 592, Loss: 2.65288248565048, Final Batch Loss: 0.006503014825284481\n",
      "Epoch 593, Loss: 4.1409905552864075, Final Batch Loss: 1.4825688600540161\n",
      "Epoch 594, Loss: 3.6474239230155945, Final Batch Loss: 1.09284508228302\n",
      "Epoch 595, Loss: 3.0166652500629425, Final Batch Loss: 0.4406421482563019\n",
      "Epoch 596, Loss: 5.545978426933289, Final Batch Loss: 2.9388351440429688\n",
      "Epoch 597, Loss: 2.652123935520649, Final Batch Loss: 0.10482151061296463\n",
      "Epoch 598, Loss: 4.09383350610733, Final Batch Loss: 1.5523784160614014\n",
      "Epoch 599, Loss: 2.5328281112015247, Final Batch Loss: 0.023911435157060623\n",
      "Epoch 600, Loss: 4.900841236114502, Final Batch Loss: 2.356759548187256\n",
      "Epoch 601, Loss: 2.7017598897218704, Final Batch Loss: 0.17341746389865875\n",
      "Epoch 602, Loss: 4.34206086397171, Final Batch Loss: 1.813773274421692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603, Loss: 3.596990406513214, Final Batch Loss: 1.00657320022583\n",
      "Epoch 604, Loss: 3.605166018009186, Final Batch Loss: 0.9858553409576416\n",
      "Epoch 605, Loss: 3.0496919453144073, Final Batch Loss: 0.23368766903877258\n",
      "Epoch 606, Loss: 5.022021770477295, Final Batch Loss: 2.1365175247192383\n",
      "Epoch 607, Loss: 4.861983835697174, Final Batch Loss: 1.807862401008606\n",
      "Epoch 608, Loss: 5.670019209384918, Final Batch Loss: 2.6614747047424316\n",
      "Epoch 609, Loss: 3.0751258805394173, Final Batch Loss: 0.12039227038621902\n",
      "Epoch 610, Loss: 3.276331901550293, Final Batch Loss: 0.5313432812690735\n",
      "Epoch 611, Loss: 3.1487407088279724, Final Batch Loss: 0.4901661276817322\n",
      "Epoch 612, Loss: 4.836306273937225, Final Batch Loss: 2.143688917160034\n",
      "Epoch 613, Loss: 3.9214791655540466, Final Batch Loss: 1.3508692979812622\n",
      "Epoch 614, Loss: 3.414778769016266, Final Batch Loss: 0.8203797936439514\n",
      "Epoch 615, Loss: 4.197933316230774, Final Batch Loss: 1.614111304283142\n",
      "Epoch 616, Loss: 2.560422540642321, Final Batch Loss: 0.01104962918907404\n",
      "Epoch 617, Loss: 4.135329961776733, Final Batch Loss: 1.5727860927581787\n",
      "Epoch 618, Loss: 3.733572542667389, Final Batch Loss: 1.180789589881897\n",
      "Epoch 619, Loss: 3.109062671661377, Final Batch Loss: 0.4884236454963684\n",
      "Epoch 620, Loss: 2.9950791895389557, Final Batch Loss: 0.2965845763683319\n",
      "Epoch 621, Loss: 3.027716189622879, Final Batch Loss: 0.2698036730289459\n",
      "Epoch 622, Loss: 2.8292028307914734, Final Batch Loss: 0.1763228178024292\n",
      "Epoch 623, Loss: 4.585998713970184, Final Batch Loss: 1.9169690608978271\n",
      "Epoch 624, Loss: 4.337403833866119, Final Batch Loss: 1.7257359027862549\n",
      "Epoch 625, Loss: 2.692793995141983, Final Batch Loss: 0.13928601145744324\n",
      "Epoch 626, Loss: 2.941216915845871, Final Batch Loss: 0.3118908107280731\n",
      "Epoch 627, Loss: 2.9923606365919113, Final Batch Loss: 0.20190928876399994\n",
      "Epoch 628, Loss: 4.5823915004730225, Final Batch Loss: 1.9488744735717773\n",
      "Epoch 629, Loss: 2.772251471877098, Final Batch Loss: 0.13273410499095917\n",
      "Epoch 630, Loss: 2.7316817864775658, Final Batch Loss: 0.123299740254879\n",
      "Epoch 631, Loss: 2.7908665537834167, Final Batch Loss: 0.22195160388946533\n",
      "Epoch 632, Loss: 3.0654666423797607, Final Batch Loss: 0.5577916502952576\n",
      "Epoch 633, Loss: 2.749096602201462, Final Batch Loss: 0.16926607489585876\n",
      "Epoch 634, Loss: 2.571640055626631, Final Batch Loss: 0.03401939198374748\n",
      "Epoch 635, Loss: 2.753884255886078, Final Batch Loss: 0.23437339067459106\n",
      "Epoch 636, Loss: 2.8557622134685516, Final Batch Loss: 0.38589945435523987\n",
      "Epoch 637, Loss: 2.558507487177849, Final Batch Loss: 0.09651695191860199\n",
      "Epoch 638, Loss: 3.821959972381592, Final Batch Loss: 1.3738176822662354\n",
      "Epoch 639, Loss: 2.5975630804896355, Final Batch Loss: 0.09254049509763718\n",
      "Epoch 640, Loss: 3.195386826992035, Final Batch Loss: 0.7356241941452026\n",
      "Epoch 641, Loss: 4.078375816345215, Final Batch Loss: 1.6486570835113525\n",
      "Epoch 642, Loss: 2.668014332652092, Final Batch Loss: 0.22339509427547455\n",
      "Epoch 643, Loss: 2.699133351445198, Final Batch Loss: 0.12194742262363434\n",
      "Epoch 644, Loss: 3.1718268990516663, Final Batch Loss: 0.6062703728675842\n",
      "Epoch 645, Loss: 2.6831998080015182, Final Batch Loss: 0.1364329308271408\n",
      "Epoch 646, Loss: 5.131368339061737, Final Batch Loss: 2.45932674407959\n",
      "Epoch 647, Loss: 3.465395510196686, Final Batch Loss: 0.8956385254859924\n",
      "Epoch 648, Loss: 3.113430082798004, Final Batch Loss: 0.5433792471885681\n",
      "Epoch 649, Loss: 3.0524548292160034, Final Batch Loss: 0.566133439540863\n",
      "Epoch 650, Loss: 2.8054767847061157, Final Batch Loss: 0.2880479693412781\n",
      "Epoch 651, Loss: 2.7211253345012665, Final Batch Loss: 0.2747080624103546\n",
      "Epoch 652, Loss: 3.98042494058609, Final Batch Loss: 1.4384671449661255\n",
      "Epoch 653, Loss: 4.284588694572449, Final Batch Loss: 1.7701456546783447\n",
      "Epoch 654, Loss: 3.0389044284820557, Final Batch Loss: 0.5948452353477478\n",
      "Epoch 655, Loss: 3.607652425765991, Final Batch Loss: 1.1054363250732422\n",
      "Epoch 656, Loss: 2.4384104888886213, Final Batch Loss: 0.025144783779978752\n",
      "Epoch 657, Loss: 3.05797415971756, Final Batch Loss: 0.507402777671814\n",
      "Epoch 658, Loss: 2.77352312207222, Final Batch Loss: 0.26246169209480286\n",
      "Epoch 659, Loss: 4.3416770696640015, Final Batch Loss: 1.9376188516616821\n",
      "Epoch 660, Loss: 4.302160263061523, Final Batch Loss: 1.7714425325393677\n",
      "Epoch 661, Loss: 4.471173644065857, Final Batch Loss: 1.9376161098480225\n",
      "Epoch 662, Loss: 2.665262535214424, Final Batch Loss: 0.23111768066883087\n",
      "Epoch 663, Loss: 2.56458293646574, Final Batch Loss: 0.10923784226179123\n",
      "Epoch 664, Loss: 2.5348302107304335, Final Batch Loss: 0.01803523115813732\n",
      "Epoch 665, Loss: 2.6052989065647125, Final Batch Loss: 0.11647161841392517\n",
      "Epoch 666, Loss: 2.538131892681122, Final Batch Loss: 0.16771763563156128\n",
      "Epoch 667, Loss: 4.054451882839203, Final Batch Loss: 1.5896615982055664\n",
      "Epoch 668, Loss: 4.204225063323975, Final Batch Loss: 1.7430760860443115\n",
      "Epoch 669, Loss: 4.0050923228263855, Final Batch Loss: 1.5590728521347046\n",
      "Epoch 670, Loss: 2.735842376947403, Final Batch Loss: 0.2790648639202118\n",
      "Epoch 671, Loss: 4.625339210033417, Final Batch Loss: 2.165351390838623\n",
      "Epoch 672, Loss: 2.781588077545166, Final Batch Loss: 0.2992492914199829\n",
      "Epoch 673, Loss: 2.5741823315620422, Final Batch Loss: 0.1764235496520996\n",
      "Epoch 674, Loss: 3.2816807627677917, Final Batch Loss: 0.8519680500030518\n",
      "Epoch 675, Loss: 2.8065455555915833, Final Batch Loss: 0.3266982436180115\n",
      "Epoch 676, Loss: 4.258930921554565, Final Batch Loss: 1.8960405588150024\n",
      "Epoch 677, Loss: 3.184041380882263, Final Batch Loss: 0.8042386174201965\n",
      "Epoch 678, Loss: 2.5015174224972725, Final Batch Loss: 0.077671118080616\n",
      "Epoch 679, Loss: 3.732706129550934, Final Batch Loss: 1.282130241394043\n",
      "Epoch 680, Loss: 3.1588633060455322, Final Batch Loss: 0.7290513515472412\n",
      "Epoch 681, Loss: 2.6377990394830704, Final Batch Loss: 0.15153296291828156\n",
      "Epoch 682, Loss: 2.910415768623352, Final Batch Loss: 0.38344669342041016\n",
      "Epoch 683, Loss: 5.407950341701508, Final Batch Loss: 2.938058614730835\n",
      "Epoch 684, Loss: 3.6112566590309143, Final Batch Loss: 1.0670452117919922\n",
      "Epoch 685, Loss: 2.6108838617801666, Final Batch Loss: 0.14256861805915833\n",
      "Epoch 686, Loss: 4.344725489616394, Final Batch Loss: 1.815298080444336\n",
      "Epoch 687, Loss: 2.582991488277912, Final Batch Loss: 0.09141433984041214\n",
      "Epoch 688, Loss: 4.742103219032288, Final Batch Loss: 2.311819076538086\n",
      "Epoch 689, Loss: 4.217050671577454, Final Batch Loss: 1.744217872619629\n",
      "Epoch 690, Loss: 2.7382781505584717, Final Batch Loss: 0.2840225100517273\n",
      "Epoch 691, Loss: 5.322876691818237, Final Batch Loss: 2.8717548847198486\n",
      "Epoch 692, Loss: 4.295786559581757, Final Batch Loss: 1.7579917907714844\n",
      "Epoch 693, Loss: 2.7865139096975327, Final Batch Loss: 0.1948898881673813\n",
      "Epoch 694, Loss: 2.837796524167061, Final Batch Loss: 0.11851836740970612\n",
      "Epoch 695, Loss: 4.947565317153931, Final Batch Loss: 2.2729711532592773\n",
      "Epoch 696, Loss: 4.812281489372253, Final Batch Loss: 2.343092203140259\n",
      "Epoch 697, Loss: 2.485840454697609, Final Batch Loss: 0.02200998365879059\n",
      "Epoch 698, Loss: 2.7012202590703964, Final Batch Loss: 0.2405855506658554\n",
      "Epoch 699, Loss: 3.787401556968689, Final Batch Loss: 1.318286418914795\n",
      "Epoch 700, Loss: 4.413945734500885, Final Batch Loss: 1.9515254497528076\n",
      "Epoch 701, Loss: 2.4345216369256377, Final Batch Loss: 0.0029412126168608665\n",
      "Epoch 702, Loss: 2.748942404985428, Final Batch Loss: 0.37934717535972595\n",
      "Epoch 703, Loss: 4.218654155731201, Final Batch Loss: 1.6988930702209473\n",
      "Epoch 704, Loss: 2.6825971454381943, Final Batch Loss: 0.24261091649532318\n",
      "Epoch 705, Loss: 2.6934128254652023, Final Batch Loss: 0.20236293971538544\n",
      "Epoch 706, Loss: 2.5065551325678825, Final Batch Loss: 0.0748782679438591\n",
      "Epoch 707, Loss: 2.446161950007081, Final Batch Loss: 0.004661882296204567\n",
      "Epoch 708, Loss: 2.394114582100883, Final Batch Loss: 0.0037247820291668177\n",
      "Epoch 709, Loss: 2.611550211906433, Final Batch Loss: 0.23583513498306274\n",
      "Epoch 710, Loss: 2.6226836889982224, Final Batch Loss: 0.19016019999980927\n",
      "Epoch 711, Loss: 2.5101837664842606, Final Batch Loss: 0.05661340057849884\n",
      "Epoch 712, Loss: 3.9276298880577087, Final Batch Loss: 1.5217070579528809\n",
      "Epoch 713, Loss: 2.6893516182899475, Final Batch Loss: 0.2864376902580261\n",
      "Epoch 714, Loss: 4.117891013622284, Final Batch Loss: 1.7516322135925293\n",
      "Epoch 715, Loss: 3.1592426896095276, Final Batch Loss: 0.660224974155426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716, Loss: 2.7200027406215668, Final Batch Loss: 0.33480265736579895\n",
      "Epoch 717, Loss: 2.5787629783153534, Final Batch Loss: 0.149478942155838\n",
      "Epoch 718, Loss: 2.4423952801153064, Final Batch Loss: 0.015222798101603985\n",
      "Epoch 719, Loss: 2.4791233595460653, Final Batch Loss: 0.024445300921797752\n",
      "Epoch 720, Loss: 4.431916952133179, Final Batch Loss: 1.9515467882156372\n",
      "Epoch 721, Loss: 2.6536464393138885, Final Batch Loss: 0.27894464135169983\n",
      "Epoch 722, Loss: 3.644989252090454, Final Batch Loss: 1.2786486148834229\n",
      "Epoch 723, Loss: 5.054108798503876, Final Batch Loss: 2.670119524002075\n",
      "Epoch 724, Loss: 2.569729745388031, Final Batch Loss: 0.09965676069259644\n",
      "Epoch 725, Loss: 4.4865453243255615, Final Batch Loss: 2.0708365440368652\n",
      "Epoch 726, Loss: 4.390288949012756, Final Batch Loss: 1.96024751663208\n",
      "Epoch 727, Loss: 2.546670973300934, Final Batch Loss: 0.228038489818573\n",
      "Epoch 728, Loss: 3.579202353954315, Final Batch Loss: 1.1690902709960938\n",
      "Epoch 729, Loss: 2.4688259474933147, Final Batch Loss: 0.04654271528124809\n",
      "Epoch 730, Loss: 3.718707501888275, Final Batch Loss: 1.3460334539413452\n",
      "Epoch 731, Loss: 3.7330257892608643, Final Batch Loss: 1.3838139772415161\n",
      "Epoch 732, Loss: 3.476117193698883, Final Batch Loss: 1.0451475381851196\n",
      "Epoch 733, Loss: 3.8140957951545715, Final Batch Loss: 1.4714877605438232\n",
      "Epoch 734, Loss: 2.363425923511386, Final Batch Loss: 0.010159565135836601\n",
      "Epoch 735, Loss: 2.312223218381405, Final Batch Loss: 0.024011991918087006\n",
      "Epoch 736, Loss: 2.6876458823680878, Final Batch Loss: 0.25152429938316345\n",
      "Epoch 737, Loss: 2.6669137328863144, Final Batch Loss: 0.18367092311382294\n",
      "Epoch 738, Loss: 2.679312765598297, Final Batch Loss: 0.2659885883331299\n",
      "Epoch 739, Loss: 3.859914183616638, Final Batch Loss: 1.3717666864395142\n",
      "Epoch 740, Loss: 2.5546155273914337, Final Batch Loss: 0.21195408701896667\n",
      "Epoch 741, Loss: 2.6536307334899902, Final Batch Loss: 0.1974925398826599\n",
      "Epoch 742, Loss: 4.775887906551361, Final Batch Loss: 2.3742382526397705\n",
      "Epoch 743, Loss: 3.7259382009506226, Final Batch Loss: 1.299957036972046\n",
      "Epoch 744, Loss: 2.687087520956993, Final Batch Loss: 0.23909835517406464\n",
      "Epoch 745, Loss: 2.596783861517906, Final Batch Loss: 0.2208412140607834\n",
      "Epoch 746, Loss: 2.462652910500765, Final Batch Loss: 0.04877762869000435\n",
      "Epoch 747, Loss: 3.6380502581596375, Final Batch Loss: 1.2510061264038086\n",
      "Epoch 748, Loss: 2.8287550806999207, Final Batch Loss: 0.4577890634536743\n",
      "Epoch 749, Loss: 4.504334807395935, Final Batch Loss: 2.0422565937042236\n",
      "Epoch 750, Loss: 3.6078838109970093, Final Batch Loss: 1.257509469985962\n",
      "Epoch 751, Loss: 2.5681584179401398, Final Batch Loss: 0.17523017525672913\n",
      "Epoch 752, Loss: 2.4178668074309826, Final Batch Loss: 0.044516485184431076\n",
      "Epoch 753, Loss: 3.5852246284484863, Final Batch Loss: 1.2092995643615723\n",
      "Epoch 754, Loss: 4.1989858746528625, Final Batch Loss: 1.887397050857544\n",
      "Epoch 755, Loss: 4.048430800437927, Final Batch Loss: 1.5997155904769897\n",
      "Epoch 756, Loss: 2.449070304632187, Final Batch Loss: 0.10543051362037659\n",
      "Epoch 757, Loss: 3.523898959159851, Final Batch Loss: 1.087830901145935\n",
      "Epoch 758, Loss: 2.75492000579834, Final Batch Loss: 0.41230857372283936\n",
      "Epoch 759, Loss: 2.6199674904346466, Final Batch Loss: 0.2150959074497223\n",
      "Epoch 760, Loss: 4.213132739067078, Final Batch Loss: 1.867065191268921\n",
      "Epoch 761, Loss: 4.261743187904358, Final Batch Loss: 1.8907123804092407\n",
      "Epoch 762, Loss: 2.4422582238912582, Final Batch Loss: 0.12061397731304169\n",
      "Epoch 763, Loss: 2.4892909228801727, Final Batch Loss: 0.19870087504386902\n",
      "Epoch 764, Loss: 4.867433488368988, Final Batch Loss: 2.549597978591919\n",
      "Epoch 765, Loss: 2.4054457396268845, Final Batch Loss: 0.09417544305324554\n",
      "Epoch 766, Loss: 2.580107167363167, Final Batch Loss: 0.21622921526432037\n",
      "Epoch 767, Loss: 2.5416760221123695, Final Batch Loss: 0.046017445623874664\n",
      "Epoch 768, Loss: 3.9299638867378235, Final Batch Loss: 1.5343077182769775\n",
      "Epoch 769, Loss: 2.4354665130376816, Final Batch Loss: 0.0849941223859787\n",
      "Epoch 770, Loss: 3.762839615345001, Final Batch Loss: 1.4560496807098389\n",
      "Epoch 771, Loss: 3.592806398868561, Final Batch Loss: 1.2402589321136475\n",
      "Epoch 772, Loss: 4.08769953250885, Final Batch Loss: 1.7117340564727783\n",
      "Epoch 773, Loss: 3.9986888766288757, Final Batch Loss: 1.7190160751342773\n",
      "Epoch 774, Loss: 2.4902663975954056, Final Batch Loss: 0.1502995640039444\n",
      "Epoch 775, Loss: 2.975248098373413, Final Batch Loss: 0.6556870341300964\n",
      "Epoch 776, Loss: 3.8266300559043884, Final Batch Loss: 1.4638123512268066\n",
      "Epoch 777, Loss: 2.504388853907585, Final Batch Loss: 0.13276635110378265\n",
      "Epoch 778, Loss: 2.6363751590251923, Final Batch Loss: 0.2688874900341034\n",
      "Epoch 779, Loss: 4.472282290458679, Final Batch Loss: 2.1180307865142822\n",
      "Epoch 780, Loss: 2.6969412565231323, Final Batch Loss: 0.39732086658477783\n",
      "Epoch 781, Loss: 2.4123490750789642, Final Batch Loss: 0.10377863049507141\n",
      "Epoch 782, Loss: 2.4567252695560455, Final Batch Loss: 0.12458750605583191\n",
      "Epoch 783, Loss: 2.558521568775177, Final Batch Loss: 0.25126582384109497\n",
      "Epoch 784, Loss: 2.556096538901329, Final Batch Loss: 0.19460438191890717\n",
      "Epoch 785, Loss: 4.318280816078186, Final Batch Loss: 2.0024380683898926\n",
      "Epoch 786, Loss: 3.081364095211029, Final Batch Loss: 0.7098353505134583\n",
      "Epoch 787, Loss: 3.5708791613578796, Final Batch Loss: 1.1389681100845337\n",
      "Epoch 788, Loss: 2.6332560777664185, Final Batch Loss: 0.3081551194190979\n",
      "Epoch 789, Loss: 2.584489181637764, Final Batch Loss: 0.08136750757694244\n",
      "Epoch 790, Loss: 2.5273512452840805, Final Batch Loss: 0.06482742726802826\n",
      "Epoch 791, Loss: 2.6634795367717743, Final Batch Loss: 0.30098477005958557\n",
      "Epoch 792, Loss: 2.458951860666275, Final Batch Loss: 0.14158561825752258\n",
      "Epoch 793, Loss: 2.41043609008193, Final Batch Loss: 0.06124734506011009\n",
      "Epoch 794, Loss: 3.7350553274154663, Final Batch Loss: 1.3515173196792603\n",
      "Epoch 795, Loss: 2.385288180783391, Final Batch Loss: 0.01724112220108509\n",
      "Epoch 796, Loss: 3.215740442276001, Final Batch Loss: 0.8921945691108704\n",
      "Epoch 797, Loss: 3.7504060864448547, Final Batch Loss: 1.4318040609359741\n",
      "Epoch 798, Loss: 5.285047352313995, Final Batch Loss: 3.0579071044921875\n",
      "Epoch 799, Loss: 3.8743406534194946, Final Batch Loss: 1.4702001810073853\n",
      "Epoch 800, Loss: 3.172583222389221, Final Batch Loss: 0.7713521122932434\n",
      "Epoch 801, Loss: 2.6037904769182205, Final Batch Loss: 0.1316012293100357\n",
      "Epoch 802, Loss: 3.525125205516815, Final Batch Loss: 1.0602636337280273\n",
      "Epoch 803, Loss: 4.281000435352325, Final Batch Loss: 1.847092628479004\n",
      "Epoch 804, Loss: 3.5440775752067566, Final Batch Loss: 1.1908968687057495\n",
      "Epoch 805, Loss: 4.355338275432587, Final Batch Loss: 1.9969518184661865\n",
      "Epoch 806, Loss: 2.365075725130737, Final Batch Loss: 0.008948343805968761\n",
      "Epoch 807, Loss: 2.6406708359718323, Final Batch Loss: 0.3898078203201294\n",
      "Epoch 808, Loss: 2.6160410046577454, Final Batch Loss: 0.31672799587249756\n",
      "Epoch 809, Loss: 2.461504966020584, Final Batch Loss: 0.11521562933921814\n",
      "Epoch 810, Loss: 3.6506656408309937, Final Batch Loss: 1.4023641347885132\n",
      "Epoch 811, Loss: 2.4526797495782375, Final Batch Loss: 0.05891406163573265\n",
      "Epoch 812, Loss: 5.2315675020217896, Final Batch Loss: 2.169255018234253\n",
      "Epoch 813, Loss: 3.9910820722579956, Final Batch Loss: 1.1335753202438354\n",
      "Epoch 814, Loss: 2.551037395372987, Final Batch Loss: 0.02268739975988865\n",
      "Epoch 815, Loss: 2.501899379771203, Final Batch Loss: 0.004373628180474043\n",
      "Epoch 816, Loss: 2.37137498985976, Final Batch Loss: 0.012971426360309124\n",
      "Epoch 817, Loss: 3.3738039135932922, Final Batch Loss: 1.0002055168151855\n",
      "Epoch 818, Loss: 2.433838746510446, Final Batch Loss: 0.015345952473580837\n",
      "Epoch 819, Loss: 4.9013911485672, Final Batch Loss: 2.5288846492767334\n",
      "Epoch 820, Loss: 2.4466742128133774, Final Batch Loss: 0.07328544557094574\n",
      "Epoch 821, Loss: 3.833245277404785, Final Batch Loss: 1.471415400505066\n",
      "Epoch 822, Loss: 2.904380202293396, Final Batch Loss: 0.648544192314148\n",
      "Epoch 823, Loss: 3.66087806224823, Final Batch Loss: 1.3484268188476562\n",
      "Epoch 824, Loss: 3.986878275871277, Final Batch Loss: 1.6411418914794922\n",
      "Epoch 825, Loss: 4.1077388525009155, Final Batch Loss: 1.6918420791625977\n",
      "Epoch 826, Loss: 3.0060139894485474, Final Batch Loss: 0.667534589767456\n",
      "Epoch 827, Loss: 3.7248308658599854, Final Batch Loss: 1.3094853162765503\n",
      "Epoch 828, Loss: 2.8100167214870453, Final Batch Loss: 0.4560728967189789\n",
      "Epoch 829, Loss: 2.543237581849098, Final Batch Loss: 0.24573148787021637\n",
      "Epoch 830, Loss: 2.6156644225120544, Final Batch Loss: 0.3844025135040283\n",
      "Epoch 831, Loss: 3.302392601966858, Final Batch Loss: 0.9693635702133179\n",
      "Epoch 832, Loss: 2.466698631644249, Final Batch Loss: 0.06001262366771698\n",
      "Epoch 833, Loss: 2.7193685173988342, Final Batch Loss: 0.26627224683761597\n",
      "Epoch 834, Loss: 2.4466488137841225, Final Batch Loss: 0.05802647024393082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 835, Loss: 2.3117238730192184, Final Batch Loss: 0.04147051274776459\n",
      "Epoch 836, Loss: 3.4223809242248535, Final Batch Loss: 1.1391741037368774\n",
      "Epoch 837, Loss: 2.392402723431587, Final Batch Loss: 0.13656271994113922\n",
      "Epoch 838, Loss: 4.111514031887054, Final Batch Loss: 1.8014731407165527\n",
      "Epoch 839, Loss: 2.30510588362813, Final Batch Loss: 0.016664940863847733\n",
      "Epoch 840, Loss: 2.954369306564331, Final Batch Loss: 0.6289623379707336\n",
      "Epoch 841, Loss: 2.467073492705822, Final Batch Loss: 0.09979551285505295\n",
      "Epoch 842, Loss: 3.835933744907379, Final Batch Loss: 1.5585451126098633\n",
      "Epoch 843, Loss: 2.4013992100954056, Final Batch Loss: 0.13776405155658722\n",
      "Epoch 844, Loss: 2.2890843972563744, Final Batch Loss: 0.013327442109584808\n",
      "Epoch 845, Loss: 3.657839834690094, Final Batch Loss: 1.473740816116333\n",
      "Epoch 846, Loss: 2.8805803656578064, Final Batch Loss: 0.6195504665374756\n",
      "Epoch 847, Loss: 2.346396178007126, Final Batch Loss: 0.06668850779533386\n",
      "Epoch 848, Loss: 2.7859624922275543, Final Batch Loss: 0.4987544119358063\n",
      "Epoch 849, Loss: 3.5397709608078003, Final Batch Loss: 1.1866002082824707\n",
      "Epoch 850, Loss: 2.427497699856758, Final Batch Loss: 0.15960092842578888\n",
      "Epoch 851, Loss: 2.5498175621032715, Final Batch Loss: 0.2968170642852783\n",
      "Epoch 852, Loss: 2.49818417429924, Final Batch Loss: 0.2442956268787384\n",
      "Epoch 853, Loss: 2.2887312173843384, Final Batch Loss: 0.08165758848190308\n",
      "Epoch 854, Loss: 8.594629347324371, Final Batch Loss: 6.341686725616455\n",
      "Epoch 855, Loss: 2.3152780327945948, Final Batch Loss: 0.0202737245708704\n",
      "Epoch 856, Loss: 2.3993529230356216, Final Batch Loss: 0.06866790354251862\n",
      "Epoch 857, Loss: 2.5059643536806107, Final Batch Loss: 0.11704589426517487\n",
      "Epoch 858, Loss: 2.5214542895555496, Final Batch Loss: 0.12667758762836456\n",
      "Epoch 859, Loss: 4.854399800300598, Final Batch Loss: 2.4580209255218506\n",
      "Epoch 860, Loss: 3.3958235383033752, Final Batch Loss: 1.025132656097412\n",
      "Epoch 861, Loss: 2.5569935739040375, Final Batch Loss: 0.09428176283836365\n",
      "Epoch 862, Loss: 4.62810879945755, Final Batch Loss: 2.1745147705078125\n",
      "Epoch 863, Loss: 3.5868908762931824, Final Batch Loss: 0.9979169368743896\n",
      "Epoch 864, Loss: 5.007607460021973, Final Batch Loss: 2.5248217582702637\n",
      "Epoch 865, Loss: 2.820596754550934, Final Batch Loss: 0.28462910652160645\n",
      "Epoch 866, Loss: 3.582850933074951, Final Batch Loss: 1.024153232574463\n",
      "Epoch 867, Loss: 2.6059426739811897, Final Batch Loss: 0.07622469216585159\n",
      "Epoch 868, Loss: 3.6386646032333374, Final Batch Loss: 1.0359714031219482\n",
      "Epoch 869, Loss: 4.616589665412903, Final Batch Loss: 1.9695358276367188\n",
      "Epoch 870, Loss: 2.677706453949213, Final Batch Loss: 0.0350024439394474\n",
      "Epoch 871, Loss: 2.9139821231365204, Final Batch Loss: 0.3110392391681671\n",
      "Epoch 872, Loss: 4.297762513160706, Final Batch Loss: 1.7956581115722656\n",
      "Epoch 873, Loss: 2.664232924580574, Final Batch Loss: 0.21632350981235504\n",
      "Epoch 874, Loss: 4.840286076068878, Final Batch Loss: 2.377807378768921\n",
      "Epoch 875, Loss: 4.805744886398315, Final Batch Loss: 2.427412748336792\n",
      "Epoch 876, Loss: 4.192271828651428, Final Batch Loss: 1.642115831375122\n",
      "Epoch 877, Loss: 4.1977426409721375, Final Batch Loss: 1.6918591260910034\n",
      "Epoch 878, Loss: 2.6397791653871536, Final Batch Loss: 0.2276170402765274\n",
      "Epoch 879, Loss: 3.925751507282257, Final Batch Loss: 1.4890002012252808\n",
      "Epoch 880, Loss: 2.581620365381241, Final Batch Loss: 0.07974383234977722\n",
      "Epoch 881, Loss: 3.432611405849457, Final Batch Loss: 1.038429856300354\n",
      "Epoch 882, Loss: 2.865044444799423, Final Batch Loss: 0.4447397291660309\n",
      "Epoch 883, Loss: 3.089774429798126, Final Batch Loss: 0.7407031059265137\n",
      "Epoch 884, Loss: 3.16964328289032, Final Batch Loss: 0.9073763489723206\n",
      "Epoch 885, Loss: 2.8810014128684998, Final Batch Loss: 0.5708796977996826\n",
      "Epoch 886, Loss: 2.613899350166321, Final Batch Loss: 0.3064553141593933\n",
      "Epoch 887, Loss: 2.356771796941757, Final Batch Loss: 0.10604879260063171\n",
      "Epoch 888, Loss: 3.6238436102867126, Final Batch Loss: 1.3635064363479614\n",
      "Epoch 889, Loss: 4.234751522541046, Final Batch Loss: 1.941192626953125\n",
      "Epoch 890, Loss: 3.449747681617737, Final Batch Loss: 1.2065696716308594\n",
      "Epoch 891, Loss: 3.358250319957733, Final Batch Loss: 1.0286097526550293\n",
      "Epoch 892, Loss: 2.8789239525794983, Final Batch Loss: 0.5213568806648254\n",
      "Epoch 893, Loss: 2.892418533563614, Final Batch Loss: 0.42789939045906067\n",
      "Epoch 894, Loss: 3.0574673414230347, Final Batch Loss: 0.6127615571022034\n",
      "Epoch 895, Loss: 3.7017998099327087, Final Batch Loss: 1.240659236907959\n",
      "Epoch 896, Loss: 3.2936707735061646, Final Batch Loss: 0.8765512704849243\n",
      "Epoch 897, Loss: 3.0695791244506836, Final Batch Loss: 0.6700904369354248\n",
      "Epoch 898, Loss: 3.7970250844955444, Final Batch Loss: 1.4475493431091309\n",
      "Epoch 899, Loss: 2.599488079547882, Final Batch Loss: 0.3425189256668091\n",
      "Epoch 900, Loss: 2.790156066417694, Final Batch Loss: 0.47758352756500244\n",
      "Epoch 901, Loss: 3.1523075103759766, Final Batch Loss: 0.8502187728881836\n",
      "Epoch 902, Loss: 3.0155245065689087, Final Batch Loss: 0.6673617959022522\n",
      "Epoch 903, Loss: 4.415881156921387, Final Batch Loss: 2.0706069469451904\n",
      "Epoch 904, Loss: 4.039593458175659, Final Batch Loss: 1.7292206287384033\n",
      "Epoch 905, Loss: 2.4506385400891304, Final Batch Loss: 0.0733572319149971\n",
      "Epoch 906, Loss: 2.7267524898052216, Final Batch Loss: 0.4143761694431305\n",
      "Epoch 907, Loss: 4.345221102237701, Final Batch Loss: 2.064540386199951\n",
      "Epoch 908, Loss: 4.020049870014191, Final Batch Loss: 1.7312310934066772\n",
      "Epoch 909, Loss: 2.514192759990692, Final Batch Loss: 0.19730299711227417\n",
      "Epoch 910, Loss: 4.406695663928986, Final Batch Loss: 1.8968634605407715\n",
      "Epoch 911, Loss: 2.585628941655159, Final Batch Loss: 0.1429307609796524\n",
      "Epoch 912, Loss: 3.1558695435523987, Final Batch Loss: 0.8192609548568726\n",
      "Epoch 913, Loss: 2.5935729146003723, Final Batch Loss: 0.2944750189781189\n",
      "Epoch 914, Loss: 2.398879922926426, Final Batch Loss: 0.09336552768945694\n",
      "Epoch 915, Loss: 3.410406529903412, Final Batch Loss: 1.1442784070968628\n",
      "Epoch 916, Loss: 2.804202079772949, Final Batch Loss: 0.5181106328964233\n",
      "Epoch 917, Loss: 2.382887586951256, Final Batch Loss: 0.24352745711803436\n",
      "Epoch 918, Loss: 2.429522767663002, Final Batch Loss: 0.1490279585123062\n",
      "Epoch 919, Loss: 2.2739115208387375, Final Batch Loss: 0.019867703318595886\n",
      "Epoch 920, Loss: 3.8782527446746826, Final Batch Loss: 1.6553101539611816\n",
      "Epoch 921, Loss: 2.416633203625679, Final Batch Loss: 0.09158219397068024\n",
      "Epoch 922, Loss: 2.442786931991577, Final Batch Loss: 0.13578736782073975\n",
      "Epoch 923, Loss: 2.253684811294079, Final Batch Loss: 0.06516634672880173\n",
      "Epoch 924, Loss: 4.937346935272217, Final Batch Loss: 2.6363203525543213\n",
      "Epoch 925, Loss: 2.489461898803711, Final Batch Loss: 0.2695249319076538\n",
      "Epoch 926, Loss: 3.8666701912879944, Final Batch Loss: 1.558518648147583\n",
      "Epoch 927, Loss: 2.3265308244153857, Final Batch Loss: 0.007224033586680889\n",
      "Epoch 928, Loss: 3.668447196483612, Final Batch Loss: 1.3754842281341553\n",
      "Epoch 929, Loss: 3.777194619178772, Final Batch Loss: 1.491084098815918\n",
      "Epoch 930, Loss: 2.4578193575143814, Final Batch Loss: 0.09820009768009186\n",
      "Epoch 931, Loss: 2.776660203933716, Final Batch Loss: 0.24531733989715576\n",
      "Epoch 932, Loss: 2.572095051407814, Final Batch Loss: 0.09855122864246368\n",
      "Epoch 933, Loss: 2.498009204864502, Final Batch Loss: 0.06988954544067383\n",
      "Epoch 934, Loss: 2.810475319623947, Final Batch Loss: 0.46104761958122253\n",
      "Epoch 935, Loss: 2.262735993601382, Final Batch Loss: 0.005382687784731388\n",
      "Epoch 936, Loss: 2.2754154708236456, Final Batch Loss: 0.027718713507056236\n",
      "Epoch 937, Loss: 4.119956612586975, Final Batch Loss: 1.8098551034927368\n",
      "Epoch 938, Loss: 2.456995375454426, Final Batch Loss: 0.11397136002779007\n",
      "Epoch 939, Loss: 3.6691450476646423, Final Batch Loss: 1.4205584526062012\n",
      "Epoch 940, Loss: 3.504290521144867, Final Batch Loss: 1.2855418920516968\n",
      "Epoch 941, Loss: 2.3579464815557003, Final Batch Loss: 0.03504606708884239\n",
      "Epoch 942, Loss: 4.964410245418549, Final Batch Loss: 2.6882619857788086\n",
      "Epoch 943, Loss: 2.509524330496788, Final Batch Loss: 0.22504489123821259\n",
      "Epoch 944, Loss: 2.4656931310892105, Final Batch Loss: 0.20878060162067413\n",
      "Epoch 945, Loss: 2.3678704872727394, Final Batch Loss: 0.10113058239221573\n",
      "Epoch 946, Loss: 2.312840025871992, Final Batch Loss: 0.008051794022321701\n",
      "Epoch 947, Loss: 2.3516169413924217, Final Batch Loss: 0.08380790799856186\n",
      "Epoch 948, Loss: 2.676417350769043, Final Batch Loss: 0.4661988615989685\n",
      "Epoch 949, Loss: 2.349238708615303, Final Batch Loss: 0.16039694845676422\n",
      "Epoch 950, Loss: 2.9569408893585205, Final Batch Loss: 0.7393185496330261\n",
      "Epoch 951, Loss: 4.750707983970642, Final Batch Loss: 2.5485289096832275\n",
      "Epoch 952, Loss: 2.5267924666404724, Final Batch Loss: 0.32217609882354736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953, Loss: 2.5430544018745422, Final Batch Loss: 0.3697361350059509\n",
      "Epoch 954, Loss: 2.175514968112111, Final Batch Loss: 0.008539469912648201\n",
      "Epoch 955, Loss: 2.5683290362358093, Final Batch Loss: 0.2581220269203186\n",
      "Epoch 956, Loss: 2.4635989144444466, Final Batch Loss: 0.1113012507557869\n",
      "Epoch 957, Loss: 2.276914842426777, Final Batch Loss: 0.10254145413637161\n",
      "Epoch 958, Loss: 4.221657574176788, Final Batch Loss: 1.942514181137085\n",
      "Epoch 959, Loss: 3.8112533688545227, Final Batch Loss: 1.6287862062454224\n",
      "Epoch 960, Loss: 2.1827911336440593, Final Batch Loss: 0.003462155582383275\n",
      "Epoch 961, Loss: 2.452026382088661, Final Batch Loss: 0.16797424852848053\n",
      "Epoch 962, Loss: 3.357035458087921, Final Batch Loss: 1.2425774335861206\n",
      "Epoch 963, Loss: 3.390726864337921, Final Batch Loss: 1.2111239433288574\n",
      "Epoch 964, Loss: 3.8006991147994995, Final Batch Loss: 1.501869797706604\n",
      "Epoch 965, Loss: 3.3647481203079224, Final Batch Loss: 1.0548096895217896\n",
      "Epoch 966, Loss: 2.8524784445762634, Final Batch Loss: 0.6079137325286865\n",
      "Epoch 967, Loss: 2.657131463289261, Final Batch Loss: 0.38747385144233704\n",
      "Epoch 968, Loss: 3.7589131593704224, Final Batch Loss: 1.472415804862976\n",
      "Epoch 969, Loss: 2.3312489688396454, Final Batch Loss: 0.11959591507911682\n",
      "Epoch 970, Loss: 4.430601060390472, Final Batch Loss: 2.196544885635376\n",
      "Epoch 971, Loss: 2.2956598699092865, Final Batch Loss: 0.03584066033363342\n",
      "Epoch 972, Loss: 2.17252874141559, Final Batch Loss: 0.003716943319886923\n",
      "Epoch 973, Loss: 2.3011845499277115, Final Batch Loss: 0.09933407604694366\n",
      "Epoch 974, Loss: 2.5003204345703125, Final Batch Loss: 0.25169771909713745\n",
      "Epoch 975, Loss: 4.760613918304443, Final Batch Loss: 2.602316379547119\n",
      "Epoch 976, Loss: 3.0669447779655457, Final Batch Loss: 0.8861754536628723\n",
      "Epoch 977, Loss: 3.826859772205353, Final Batch Loss: 1.6019906997680664\n",
      "Epoch 978, Loss: 2.5406855940818787, Final Batch Loss: 0.22709053754806519\n",
      "Epoch 979, Loss: 3.6413798928260803, Final Batch Loss: 1.4150115251541138\n",
      "Epoch 980, Loss: 2.5565622746944427, Final Batch Loss: 0.29061517119407654\n",
      "Epoch 981, Loss: 3.734999716281891, Final Batch Loss: 1.536736249923706\n",
      "Epoch 982, Loss: 2.248887011781335, Final Batch Loss: 0.03044874407351017\n",
      "Epoch 983, Loss: 2.6329149901866913, Final Batch Loss: 0.39567235112190247\n",
      "Epoch 984, Loss: 2.8796942234039307, Final Batch Loss: 0.6265044808387756\n",
      "Epoch 985, Loss: 2.4128481298685074, Final Batch Loss: 0.1971506029367447\n",
      "Epoch 986, Loss: 3.3653936982154846, Final Batch Loss: 1.1448816061019897\n",
      "Epoch 987, Loss: 2.228780746459961, Final Batch Loss: 0.11528372764587402\n",
      "Epoch 988, Loss: 3.5385181307792664, Final Batch Loss: 1.3104010820388794\n",
      "Epoch 989, Loss: 4.137829661369324, Final Batch Loss: 1.9362728595733643\n",
      "Epoch 990, Loss: 3.237872302532196, Final Batch Loss: 1.0154509544372559\n",
      "Epoch 991, Loss: 4.206351697444916, Final Batch Loss: 2.026189088821411\n",
      "Epoch 992, Loss: 4.615644335746765, Final Batch Loss: 2.416285991668701\n",
      "Epoch 993, Loss: 3.043120563030243, Final Batch Loss: 0.8376485109329224\n",
      "Epoch 994, Loss: 2.3865096122026443, Final Batch Loss: 0.1790781170129776\n",
      "Epoch 995, Loss: 3.4661099314689636, Final Batch Loss: 1.3032891750335693\n",
      "Epoch 996, Loss: 2.649726688861847, Final Batch Loss: 0.45976799726486206\n",
      "Epoch 997, Loss: 2.570790857076645, Final Batch Loss: 0.3740624487400055\n",
      "Epoch 998, Loss: 2.475954085588455, Final Batch Loss: 0.31239572167396545\n",
      "Epoch 999, Loss: 4.063259124755859, Final Batch Loss: 1.8136937618255615\n",
      "Epoch 1000, Loss: 2.417720854282379, Final Batch Loss: 0.17430901527404785\n",
      "Epoch 1001, Loss: 2.360275026410818, Final Batch Loss: 0.0164484940469265\n",
      "Epoch 1002, Loss: 3.0978763103485107, Final Batch Loss: 0.8896600008010864\n",
      "Epoch 1003, Loss: 2.3644567728042603, Final Batch Loss: 0.22080421447753906\n",
      "Epoch 1004, Loss: 2.372512847185135, Final Batch Loss: 0.2614559829235077\n",
      "Epoch 1005, Loss: 2.2329745069146156, Final Batch Loss: 0.07177052646875381\n",
      "Epoch 1006, Loss: 2.247973557561636, Final Batch Loss: 0.02385067567229271\n",
      "Epoch 1007, Loss: 2.516835242509842, Final Batch Loss: 0.2813970148563385\n",
      "Epoch 1008, Loss: 5.385212957859039, Final Batch Loss: 3.179136276245117\n",
      "Epoch 1009, Loss: 3.903066098690033, Final Batch Loss: 1.6720590591430664\n",
      "Epoch 1010, Loss: 4.548105955123901, Final Batch Loss: 2.3677988052368164\n",
      "Epoch 1011, Loss: 2.314825937151909, Final Batch Loss: 0.11411122977733612\n",
      "Epoch 1012, Loss: 2.352720979601145, Final Batch Loss: 0.022282008081674576\n",
      "Epoch 1013, Loss: 2.6202639043331146, Final Batch Loss: 0.3739790618419647\n",
      "Epoch 1014, Loss: 3.6779054403305054, Final Batch Loss: 1.3661472797393799\n",
      "Epoch 1015, Loss: 2.2751167938113213, Final Batch Loss: 0.06984185427427292\n",
      "Epoch 1016, Loss: 2.3480543941259384, Final Batch Loss: 0.04849909245967865\n",
      "Epoch 1017, Loss: 2.3157590478658676, Final Batch Loss: 0.058905407786369324\n",
      "Epoch 1018, Loss: 2.3769683241844177, Final Batch Loss: 0.22157686948776245\n",
      "Epoch 1019, Loss: 2.782580256462097, Final Batch Loss: 0.5219734311103821\n",
      "Epoch 1020, Loss: 2.2407290935516357, Final Batch Loss: 0.06540477275848389\n",
      "Epoch 1021, Loss: 2.3396797627210617, Final Batch Loss: 0.16496406495571136\n",
      "Epoch 1022, Loss: 3.3620824217796326, Final Batch Loss: 1.2054463624954224\n",
      "Epoch 1023, Loss: 2.2021990052890033, Final Batch Loss: 0.0026645890902727842\n",
      "Epoch 1024, Loss: 2.5336493849754333, Final Batch Loss: 0.3911059498786926\n",
      "Epoch 1025, Loss: 3.464759349822998, Final Batch Loss: 1.3374438285827637\n",
      "Epoch 1026, Loss: 2.3790868669748306, Final Batch Loss: 0.1663786917924881\n",
      "Epoch 1027, Loss: 2.176001075655222, Final Batch Loss: 0.060372594743967056\n",
      "Epoch 1028, Loss: 2.650404781103134, Final Batch Loss: 0.44875505566596985\n",
      "Epoch 1029, Loss: 2.2657658383250237, Final Batch Loss: 0.1012345477938652\n",
      "Epoch 1030, Loss: 2.5132342278957367, Final Batch Loss: 0.2531200349330902\n",
      "Epoch 1031, Loss: 2.4236813485622406, Final Batch Loss: 0.2591734230518341\n",
      "Epoch 1032, Loss: 4.052692532539368, Final Batch Loss: 1.8515255451202393\n",
      "Epoch 1033, Loss: 2.228338360786438, Final Batch Loss: 0.010533332824707031\n",
      "Epoch 1034, Loss: 2.2265703678131104, Final Batch Loss: 0.03605318069458008\n",
      "Epoch 1035, Loss: 3.24749219417572, Final Batch Loss: 1.0722562074661255\n",
      "Epoch 1036, Loss: 2.850040018558502, Final Batch Loss: 0.7092748880386353\n",
      "Epoch 1037, Loss: 3.461533486843109, Final Batch Loss: 1.2466140985488892\n",
      "Epoch 1038, Loss: 4.722117006778717, Final Batch Loss: 2.4522953033447266\n",
      "Epoch 1039, Loss: 4.240347981452942, Final Batch Loss: 2.074558734893799\n",
      "Epoch 1040, Loss: 2.4297319650650024, Final Batch Loss: 0.19655591249465942\n",
      "Epoch 1041, Loss: 2.2432494834065437, Final Batch Loss: 0.03583640605211258\n",
      "Epoch 1042, Loss: 4.418701946735382, Final Batch Loss: 2.112109422683716\n",
      "Epoch 1043, Loss: 3.669275224208832, Final Batch Loss: 1.350348711013794\n",
      "Epoch 1044, Loss: 2.350693367421627, Final Batch Loss: 0.08265211433172226\n",
      "Epoch 1045, Loss: 2.391436602920294, Final Batch Loss: 0.06071796640753746\n",
      "Epoch 1046, Loss: 3.6151227355003357, Final Batch Loss: 1.3987222909927368\n",
      "Epoch 1047, Loss: 2.270363189280033, Final Batch Loss: 0.07051108032464981\n",
      "Epoch 1048, Loss: 3.475082218647003, Final Batch Loss: 0.9573190212249756\n",
      "Epoch 1049, Loss: 2.725289915688336, Final Batch Loss: 0.004944478161633015\n",
      "Epoch 1050, Loss: 2.6816900204867125, Final Batch Loss: 0.02472875826060772\n",
      "Epoch 1051, Loss: 2.5193230509757996, Final Batch Loss: 0.10505324602127075\n",
      "Epoch 1052, Loss: 3.581175446510315, Final Batch Loss: 1.25516676902771\n",
      "Epoch 1053, Loss: 3.739052474498749, Final Batch Loss: 1.4839717149734497\n",
      "Epoch 1054, Loss: 4.145230054855347, Final Batch Loss: 1.8023184537887573\n",
      "Epoch 1055, Loss: 2.4891678765416145, Final Batch Loss: 0.12007082253694534\n",
      "Epoch 1056, Loss: 2.4423120245337486, Final Batch Loss: 0.09797271341085434\n",
      "Epoch 1057, Loss: 4.128854930400848, Final Batch Loss: 1.7893624305725098\n",
      "Epoch 1058, Loss: 2.322759971022606, Final Batch Loss: 0.034375593066215515\n",
      "Epoch 1059, Loss: 3.987189292907715, Final Batch Loss: 1.6964911222457886\n",
      "Epoch 1060, Loss: 3.86393141746521, Final Batch Loss: 1.6079243421554565\n",
      "Epoch 1061, Loss: 2.32289057970047, Final Batch Loss: 0.12842243909835815\n",
      "Epoch 1062, Loss: 3.133681893348694, Final Batch Loss: 0.9145870804786682\n",
      "Epoch 1063, Loss: 3.786969780921936, Final Batch Loss: 1.668271780014038\n",
      "Epoch 1064, Loss: 2.326147437095642, Final Batch Loss: 0.1350504755973816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1065, Loss: 3.7297523617744446, Final Batch Loss: 1.618461012840271\n",
      "Epoch 1066, Loss: 2.233649715781212, Final Batch Loss: 0.1508842557668686\n",
      "Epoch 1067, Loss: 2.257083460688591, Final Batch Loss: 0.04109714925289154\n",
      "Epoch 1068, Loss: 3.7052130103111267, Final Batch Loss: 1.6213173866271973\n",
      "Epoch 1069, Loss: 2.300766199827194, Final Batch Loss: 0.1489143669605255\n",
      "Epoch 1070, Loss: 4.431168437004089, Final Batch Loss: 2.2686028480529785\n",
      "Epoch 1071, Loss: 2.704614758491516, Final Batch Loss: 0.585064709186554\n",
      "Epoch 1072, Loss: 2.434096083045006, Final Batch Loss: 0.21208958327770233\n",
      "Epoch 1073, Loss: 2.2046411763876677, Final Batch Loss: 0.012083543464541435\n",
      "Epoch 1074, Loss: 3.3195111751556396, Final Batch Loss: 1.1330058574676514\n",
      "Epoch 1075, Loss: 2.4038047790527344, Final Batch Loss: 0.2547723054885864\n",
      "Epoch 1076, Loss: 3.0071361660957336, Final Batch Loss: 0.8153653144836426\n",
      "Epoch 1077, Loss: 3.813523769378662, Final Batch Loss: 1.6795237064361572\n",
      "Epoch 1078, Loss: 3.7493492364883423, Final Batch Loss: 1.5817580223083496\n",
      "Epoch 1079, Loss: 2.1896974481642246, Final Batch Loss: 0.02742183580994606\n",
      "Epoch 1080, Loss: 2.166823636740446, Final Batch Loss: 0.024142097681760788\n",
      "Epoch 1081, Loss: 3.9522138833999634, Final Batch Loss: 1.8232288360595703\n",
      "Epoch 1082, Loss: 2.2125615775585175, Final Batch Loss: 0.05042251944541931\n",
      "Epoch 1083, Loss: 2.0856537111103535, Final Batch Loss: 0.006398666650056839\n",
      "Epoch 1084, Loss: 2.160083189373836, Final Batch Loss: 0.003899946575984359\n",
      "Epoch 1085, Loss: 2.838483691215515, Final Batch Loss: 0.6474387645721436\n",
      "Epoch 1086, Loss: 3.1467284560203552, Final Batch Loss: 1.0610895156860352\n",
      "Epoch 1087, Loss: 3.5712886452674866, Final Batch Loss: 1.3818093538284302\n",
      "Epoch 1088, Loss: 2.2042520381510258, Final Batch Loss: 0.05027470365166664\n",
      "Epoch 1089, Loss: 3.271363317966461, Final Batch Loss: 1.1752617359161377\n",
      "Epoch 1090, Loss: 2.0741477685514838, Final Batch Loss: 0.0033610539976507425\n",
      "Epoch 1091, Loss: 2.669812887907028, Final Batch Loss: 0.42884334921836853\n",
      "Epoch 1092, Loss: 2.4537854492664337, Final Batch Loss: 0.25118330121040344\n",
      "Epoch 1093, Loss: 2.640984058380127, Final Batch Loss: 0.5277055501937866\n",
      "Epoch 1094, Loss: 2.1664768159389496, Final Batch Loss: 0.03666725754737854\n",
      "Epoch 1095, Loss: 2.1570292934775352, Final Batch Loss: 0.059618495404720306\n",
      "Epoch 1096, Loss: 2.396985203027725, Final Batch Loss: 0.2601449191570282\n",
      "Epoch 1097, Loss: 2.183811455965042, Final Batch Loss: 0.01889386773109436\n",
      "Epoch 1098, Loss: 2.26164548099041, Final Batch Loss: 0.1499640792608261\n",
      "Epoch 1099, Loss: 2.092219904065132, Final Batch Loss: 0.03623254597187042\n",
      "Epoch 1100, Loss: 2.1981450617313385, Final Batch Loss: 0.15192362666130066\n",
      "Epoch 1101, Loss: 2.887168526649475, Final Batch Loss: 0.8659242987632751\n",
      "Epoch 1102, Loss: 4.120165705680847, Final Batch Loss: 2.0058975219726562\n",
      "Epoch 1103, Loss: 4.0144122838974, Final Batch Loss: 1.9380449056625366\n",
      "Epoch 1104, Loss: 4.143020272254944, Final Batch Loss: 2.0803356170654297\n",
      "Epoch 1105, Loss: 2.1517359875142574, Final Batch Loss: 0.02268984541296959\n",
      "Epoch 1106, Loss: 2.235371582210064, Final Batch Loss: 0.07969044893980026\n",
      "Epoch 1107, Loss: 6.611046195030212, Final Batch Loss: 4.511064529418945\n",
      "Epoch 1108, Loss: 3.7934977412223816, Final Batch Loss: 1.475850224494934\n",
      "Epoch 1109, Loss: 6.394161641597748, Final Batch Loss: 3.693807601928711\n",
      "Epoch 1110, Loss: 3.0119804590940475, Final Batch Loss: 0.09178929030895233\n",
      "Epoch 1111, Loss: 2.78795903082937, Final Batch Loss: 0.010712734423577785\n",
      "Epoch 1112, Loss: 4.30512797832489, Final Batch Loss: 1.7673546075820923\n",
      "Epoch 1113, Loss: 4.027982473373413, Final Batch Loss: 1.6710783243179321\n",
      "Epoch 1114, Loss: 4.141220271587372, Final Batch Loss: 1.7169690132141113\n",
      "Epoch 1115, Loss: 2.786380112171173, Final Batch Loss: 0.4782191514968872\n",
      "Epoch 1116, Loss: 4.473787307739258, Final Batch Loss: 2.1613430976867676\n",
      "Epoch 1117, Loss: 3.863878905773163, Final Batch Loss: 1.6211683750152588\n",
      "Epoch 1118, Loss: 3.3654003143310547, Final Batch Loss: 1.0949674844741821\n",
      "Epoch 1119, Loss: 2.3799362182617188, Final Batch Loss: 0.1393100619316101\n",
      "Epoch 1120, Loss: 2.382096268236637, Final Batch Loss: 0.04233703762292862\n",
      "Epoch 1121, Loss: 4.132293879985809, Final Batch Loss: 1.7995654344558716\n",
      "Epoch 1122, Loss: 2.792996346950531, Final Batch Loss: 0.6270914673805237\n",
      "Epoch 1123, Loss: 2.34529647603631, Final Batch Loss: 0.027892623096704483\n",
      "Epoch 1124, Loss: 2.257919754832983, Final Batch Loss: 0.06172623857855797\n",
      "Epoch 1125, Loss: 3.6679333448410034, Final Batch Loss: 1.4496084451675415\n",
      "Epoch 1126, Loss: 3.445519804954529, Final Batch Loss: 1.0996506214141846\n",
      "Epoch 1127, Loss: 2.8059640526771545, Final Batch Loss: 0.6437324285507202\n",
      "Epoch 1128, Loss: 2.440181866288185, Final Batch Loss: 0.22650142014026642\n",
      "Epoch 1129, Loss: 3.7840861082077026, Final Batch Loss: 1.6361560821533203\n",
      "Epoch 1130, Loss: 2.258790411055088, Final Batch Loss: 0.09003768116235733\n",
      "Epoch 1131, Loss: 2.2310976088047028, Final Batch Loss: 0.07200494408607483\n",
      "Epoch 1132, Loss: 2.3285714983940125, Final Batch Loss: 0.1377682089805603\n",
      "Epoch 1133, Loss: 2.193536128848791, Final Batch Loss: 0.025780465453863144\n",
      "Epoch 1134, Loss: 2.240601547062397, Final Batch Loss: 0.09827239066362381\n",
      "Epoch 1135, Loss: 4.767442226409912, Final Batch Loss: 2.568690776824951\n",
      "Epoch 1136, Loss: 2.8314509987831116, Final Batch Loss: 0.7019962668418884\n",
      "Epoch 1137, Loss: 3.6513745188713074, Final Batch Loss: 1.3919683694839478\n",
      "Epoch 1138, Loss: 2.569274455308914, Final Batch Loss: 0.38412848114967346\n",
      "Epoch 1139, Loss: 2.224103830754757, Final Batch Loss: 0.07014640420675278\n",
      "Epoch 1140, Loss: 3.4119235277175903, Final Batch Loss: 1.2972989082336426\n",
      "Epoch 1141, Loss: 3.629621386528015, Final Batch Loss: 1.492624044418335\n",
      "Epoch 1142, Loss: 3.0470027923583984, Final Batch Loss: 0.982538104057312\n",
      "Epoch 1143, Loss: 2.292833887040615, Final Batch Loss: 0.059854768216609955\n",
      "Epoch 1144, Loss: 4.153126239776611, Final Batch Loss: 2.048311233520508\n",
      "Epoch 1145, Loss: 2.2629710137844086, Final Batch Loss: 0.11871889233589172\n",
      "Epoch 1146, Loss: 4.554631531238556, Final Batch Loss: 2.4167838096618652\n",
      "Epoch 1147, Loss: 3.6749624609947205, Final Batch Loss: 1.5202538967132568\n",
      "Epoch 1148, Loss: 2.26420496404171, Final Batch Loss: 0.17216752469539642\n",
      "Epoch 1149, Loss: 3.7326736450195312, Final Batch Loss: 1.5381544828414917\n",
      "Epoch 1150, Loss: 4.279235780239105, Final Batch Loss: 2.139340877532959\n",
      "Epoch 1151, Loss: 2.542168527841568, Final Batch Loss: 0.3816840350627899\n",
      "Epoch 1152, Loss: 2.7147125899791718, Final Batch Loss: 0.45037922263145447\n",
      "Epoch 1153, Loss: 2.4210716234520078, Final Batch Loss: 0.0056091295555233955\n",
      "Epoch 1154, Loss: 2.492623671889305, Final Batch Loss: 0.1363053172826767\n",
      "Epoch 1155, Loss: 2.571119949221611, Final Batch Loss: 0.15763013064861298\n",
      "Epoch 1156, Loss: 4.286799311637878, Final Batch Loss: 1.9315972328186035\n",
      "Epoch 1157, Loss: 2.4180339723825455, Final Batch Loss: 0.06795467436313629\n",
      "Epoch 1158, Loss: 2.651102066040039, Final Batch Loss: 0.39491695165634155\n",
      "Epoch 1159, Loss: 2.338676691055298, Final Batch Loss: 0.16344386339187622\n",
      "Epoch 1160, Loss: 2.1460783006623387, Final Batch Loss: 0.007914138026535511\n",
      "Epoch 1161, Loss: 2.307909980416298, Final Batch Loss: 0.08783085644245148\n",
      "Epoch 1162, Loss: 3.1353732347488403, Final Batch Loss: 0.9987804889678955\n",
      "Epoch 1163, Loss: 3.3991953134536743, Final Batch Loss: 1.1993712186813354\n",
      "Epoch 1164, Loss: 3.741306722164154, Final Batch Loss: 1.6231756210327148\n",
      "Epoch 1165, Loss: 2.394297331571579, Final Batch Loss: 0.25804170966148376\n",
      "Epoch 1166, Loss: 3.8853541016578674, Final Batch Loss: 1.6791532039642334\n",
      "Epoch 1167, Loss: 2.421418860554695, Final Batch Loss: 0.19800110161304474\n",
      "Epoch 1168, Loss: 2.218240611255169, Final Batch Loss: 0.0785815641283989\n",
      "Epoch 1169, Loss: 2.137614645063877, Final Batch Loss: 0.08678660541772842\n",
      "Epoch 1170, Loss: 2.2198670133948326, Final Batch Loss: 0.07790227979421616\n",
      "Epoch 1171, Loss: 2.902374267578125, Final Batch Loss: 0.7757131457328796\n",
      "Epoch 1172, Loss: 2.196943446993828, Final Batch Loss: 0.015661105513572693\n",
      "Epoch 1173, Loss: 4.530855238437653, Final Batch Loss: 2.4453351497650146\n",
      "Epoch 1174, Loss: 2.486193537712097, Final Batch Loss: 0.3876681923866272\n",
      "Epoch 1175, Loss: 2.7864387035369873, Final Batch Loss: 0.6693878769874573\n",
      "Epoch 1176, Loss: 2.0485863527283072, Final Batch Loss: 0.006315275095403194\n",
      "Epoch 1177, Loss: 2.143774083815515, Final Batch Loss: 0.010150006972253323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1178, Loss: 2.382145494222641, Final Batch Loss: 0.29061588644981384\n",
      "Epoch 1179, Loss: 2.08411780372262, Final Batch Loss: 0.01827404275536537\n",
      "Epoch 1180, Loss: 2.173050656914711, Final Batch Loss: 0.06178911030292511\n",
      "Epoch 1181, Loss: 3.5570902228355408, Final Batch Loss: 1.4833145141601562\n",
      "Epoch 1182, Loss: 2.1322775781154633, Final Batch Loss: 0.07446882128715515\n",
      "Epoch 1183, Loss: 3.8764522671699524, Final Batch Loss: 1.8139487504959106\n",
      "Epoch 1184, Loss: 2.330953359603882, Final Batch Loss: 0.18317675590515137\n",
      "Epoch 1185, Loss: 2.2022553980350494, Final Batch Loss: 0.11166998744010925\n",
      "Epoch 1186, Loss: 3.944154143333435, Final Batch Loss: 1.8065663576126099\n",
      "Epoch 1187, Loss: 2.198795720934868, Final Batch Loss: 0.10862986743450165\n",
      "Epoch 1188, Loss: 2.210335820913315, Final Batch Loss: 0.1747661530971527\n",
      "Epoch 1189, Loss: 2.168221391737461, Final Batch Loss: 0.06025508791208267\n",
      "Epoch 1190, Loss: 2.683794140815735, Final Batch Loss: 0.6434846520423889\n",
      "Epoch 1191, Loss: 2.067630904726684, Final Batch Loss: 0.011525946669280529\n",
      "Epoch 1192, Loss: 2.2617893368005753, Final Batch Loss: 0.1411723643541336\n",
      "Epoch 1193, Loss: 2.306412249803543, Final Batch Loss: 0.20279857516288757\n",
      "Epoch 1194, Loss: 3.28256893157959, Final Batch Loss: 1.2243993282318115\n",
      "Epoch 1195, Loss: 2.1465300023555756, Final Batch Loss: 0.07903185486793518\n",
      "Epoch 1196, Loss: 2.030973933171481, Final Batch Loss: 0.005373321007937193\n",
      "Epoch 1197, Loss: 4.56425803899765, Final Batch Loss: 2.487621307373047\n",
      "Epoch 1198, Loss: 2.742548704147339, Final Batch Loss: 0.6911863088607788\n",
      "Epoch 1199, Loss: 3.2757166028022766, Final Batch Loss: 1.1762408018112183\n",
      "Epoch 1200, Loss: 2.87543386220932, Final Batch Loss: 0.7431538105010986\n",
      "Epoch 1201, Loss: 2.3320303559303284, Final Batch Loss: 0.1600014567375183\n",
      "Epoch 1202, Loss: 2.3751208931207657, Final Batch Loss: 0.22749246656894684\n",
      "Epoch 1203, Loss: 2.141840197145939, Final Batch Loss: 0.056725479662418365\n",
      "Epoch 1204, Loss: 3.41767817735672, Final Batch Loss: 1.27531099319458\n",
      "Epoch 1205, Loss: 2.2323628813028336, Final Batch Loss: 0.043236032128334045\n",
      "Epoch 1206, Loss: 2.1822418739902787, Final Batch Loss: 0.00029213930247351527\n",
      "Epoch 1207, Loss: 2.224311091005802, Final Batch Loss: 0.03056333214044571\n",
      "Epoch 1208, Loss: 4.13625293970108, Final Batch Loss: 2.0104494094848633\n",
      "Epoch 1209, Loss: 2.2275798209011555, Final Batch Loss: 0.03155117109417915\n",
      "Epoch 1210, Loss: 2.3532243072986603, Final Batch Loss: 0.28488782048225403\n",
      "Epoch 1211, Loss: 2.638731598854065, Final Batch Loss: 0.5216981768608093\n",
      "Epoch 1212, Loss: 2.293071746826172, Final Batch Loss: 0.1290034055709839\n",
      "Epoch 1213, Loss: 3.1171826124191284, Final Batch Loss: 1.0807806253433228\n",
      "Epoch 1214, Loss: 2.5409166514873505, Final Batch Loss: 0.4283159077167511\n",
      "Epoch 1215, Loss: 2.169617050611123, Final Batch Loss: 0.00011169286881340668\n",
      "Epoch 1216, Loss: 2.3058669418096542, Final Batch Loss: 0.13186560571193695\n",
      "Epoch 1217, Loss: 2.1994131403043866, Final Batch Loss: 0.008365352638065815\n",
      "Epoch 1218, Loss: 2.488398492336273, Final Batch Loss: 0.2964632511138916\n",
      "Epoch 1219, Loss: 2.566981792449951, Final Batch Loss: 0.41904914379119873\n",
      "Epoch 1220, Loss: 2.1799600571393967, Final Batch Loss: 0.20145903527736664\n",
      "Epoch 1221, Loss: 2.1120163090527058, Final Batch Loss: 0.03472476080060005\n",
      "Epoch 1222, Loss: 2.1229471201077104, Final Batch Loss: 0.00860282126814127\n",
      "Epoch 1223, Loss: 2.0430166439618915, Final Batch Loss: 0.0008783058729022741\n",
      "Epoch 1224, Loss: 3.6679300665855408, Final Batch Loss: 1.6920528411865234\n",
      "Epoch 1225, Loss: 2.1608975678682327, Final Batch Loss: 0.10022707283496857\n",
      "Epoch 1226, Loss: 2.118499204516411, Final Batch Loss: 0.14335857331752777\n",
      "Epoch 1227, Loss: 2.191708482801914, Final Batch Loss: 0.08885983377695084\n",
      "Epoch 1228, Loss: 4.308402121067047, Final Batch Loss: 2.1489577293395996\n",
      "Epoch 1229, Loss: 3.9278000593185425, Final Batch Loss: 1.8062994480133057\n",
      "Epoch 1230, Loss: 3.2521328926086426, Final Batch Loss: 1.2577323913574219\n",
      "Epoch 1231, Loss: 2.614603817462921, Final Batch Loss: 0.5357773303985596\n",
      "Epoch 1232, Loss: 2.3992180228233337, Final Batch Loss: 0.2788480520248413\n",
      "Epoch 1233, Loss: 2.7345064878463745, Final Batch Loss: 0.683156430721283\n",
      "Epoch 1234, Loss: 2.2138632982969284, Final Batch Loss: 0.035288676619529724\n",
      "Epoch 1235, Loss: 2.2625921964645386, Final Batch Loss: 0.16318053007125854\n",
      "Epoch 1236, Loss: 2.136360816657543, Final Batch Loss: 0.07584231346845627\n",
      "Epoch 1237, Loss: 2.2500231713056564, Final Batch Loss: 0.2310820072889328\n",
      "Epoch 1238, Loss: 2.668396532535553, Final Batch Loss: 0.6067081689834595\n",
      "Epoch 1239, Loss: 2.680353283882141, Final Batch Loss: 0.665637195110321\n",
      "Epoch 1240, Loss: 2.0371772311627865, Final Batch Loss: 0.028507675975561142\n",
      "Epoch 1241, Loss: 3.494547486305237, Final Batch Loss: 1.5699440240859985\n",
      "Epoch 1242, Loss: 2.2564035654067993, Final Batch Loss: 0.2463424801826477\n",
      "Epoch 1243, Loss: 2.1077260226011276, Final Batch Loss: 0.04592601954936981\n",
      "Epoch 1244, Loss: 2.0315424129366875, Final Batch Loss: 0.033496491611003876\n",
      "Epoch 1245, Loss: 2.545913189649582, Final Batch Loss: 0.49069371819496155\n",
      "Epoch 1246, Loss: 2.1500589475035667, Final Batch Loss: 0.10562338680028915\n",
      "Epoch 1247, Loss: 2.0356149589642882, Final Batch Loss: 0.0007024919614195824\n",
      "Epoch 1248, Loss: 2.107974633574486, Final Batch Loss: 0.15908871591091156\n",
      "Epoch 1249, Loss: 2.0699582025408745, Final Batch Loss: 0.09671848267316818\n",
      "Epoch 1250, Loss: 3.2082905769348145, Final Batch Loss: 1.1178739070892334\n",
      "Epoch 1251, Loss: 1.9989220760762691, Final Batch Loss: 0.024284984916448593\n",
      "Epoch 1252, Loss: 2.1101488291751593, Final Batch Loss: 0.002107900334522128\n",
      "Epoch 1253, Loss: 2.387977421283722, Final Batch Loss: 0.270465612411499\n",
      "Epoch 1254, Loss: 2.3236721605062485, Final Batch Loss: 0.22525666654109955\n",
      "Epoch 1255, Loss: 3.4802350401878357, Final Batch Loss: 1.4022575616836548\n",
      "Epoch 1256, Loss: 3.5854328870773315, Final Batch Loss: 1.4995310306549072\n",
      "Epoch 1257, Loss: 2.0711301770061255, Final Batch Loss: 0.024627109989523888\n",
      "Epoch 1258, Loss: 2.3032890260219574, Final Batch Loss: 0.2293054759502411\n",
      "Epoch 1259, Loss: 2.3616595566272736, Final Batch Loss: 0.3510442078113556\n",
      "Epoch 1260, Loss: 3.691671073436737, Final Batch Loss: 1.665789246559143\n",
      "Epoch 1261, Loss: 5.451480329036713, Final Batch Loss: 3.432861328125\n",
      "Epoch 1262, Loss: 2.449326902627945, Final Batch Loss: 0.2732750475406647\n",
      "Epoch 1263, Loss: 4.244465410709381, Final Batch Loss: 1.6872347593307495\n",
      "Epoch 1264, Loss: 3.0788021236658096, Final Batch Loss: 0.1683313399553299\n",
      "Epoch 1265, Loss: 4.701283097267151, Final Batch Loss: 1.5383048057556152\n",
      "Epoch 1266, Loss: 3.301720380783081, Final Batch Loss: 0.23767352104187012\n",
      "Epoch 1267, Loss: 2.961675703525543, Final Batch Loss: 0.18863481283187866\n",
      "Epoch 1268, Loss: 2.5695425560697913, Final Batch Loss: 0.007180242799222469\n",
      "Epoch 1269, Loss: 3.6319980025291443, Final Batch Loss: 1.2958736419677734\n",
      "Epoch 1270, Loss: 3.278070092201233, Final Batch Loss: 1.0495436191558838\n",
      "Epoch 1271, Loss: 4.098340272903442, Final Batch Loss: 1.808556079864502\n",
      "Epoch 1272, Loss: 2.53532075881958, Final Batch Loss: 0.26793766021728516\n",
      "Epoch 1273, Loss: 3.2106271982192993, Final Batch Loss: 0.8200966715812683\n",
      "Epoch 1274, Loss: 8.217434346675873, Final Batch Loss: 5.884244918823242\n",
      "Epoch 1275, Loss: 2.7046287059783936, Final Batch Loss: 0.48367083072662354\n",
      "Epoch 1276, Loss: 3.068247973918915, Final Batch Loss: 0.9982655048370361\n",
      "Epoch 1277, Loss: 2.2025971934199333, Final Batch Loss: 0.11803000420331955\n",
      "Epoch 1278, Loss: 4.2255706787109375, Final Batch Loss: 2.1291604042053223\n",
      "Epoch 1279, Loss: 4.701903343200684, Final Batch Loss: 2.565885305404663\n",
      "Epoch 1280, Loss: 2.5785924792289734, Final Batch Loss: 0.38626521825790405\n",
      "Epoch 1281, Loss: 2.3392526656389236, Final Batch Loss: 0.12876982986927032\n",
      "Epoch 1282, Loss: 2.251594200730324, Final Batch Loss: 0.22056205570697784\n",
      "Epoch 1283, Loss: 2.408433675765991, Final Batch Loss: 0.3408079147338867\n",
      "Epoch 1284, Loss: 3.642725348472595, Final Batch Loss: 1.5323363542556763\n",
      "Epoch 1285, Loss: 3.589891791343689, Final Batch Loss: 1.482619047164917\n",
      "Epoch 1286, Loss: 2.597557485103607, Final Batch Loss: 0.512599766254425\n",
      "Epoch 1287, Loss: 2.4567317068576813, Final Batch Loss: 0.43088969588279724\n",
      "Epoch 1288, Loss: 3.699631154537201, Final Batch Loss: 1.7201738357543945\n",
      "Epoch 1289, Loss: 4.871546268463135, Final Batch Loss: 2.769037961959839\n",
      "Epoch 1290, Loss: 2.0765763875097036, Final Batch Loss: 0.016370510682463646\n",
      "Epoch 1291, Loss: 2.1091410145163536, Final Batch Loss: 0.03249349445104599\n",
      "Epoch 1292, Loss: 4.351875305175781, Final Batch Loss: 2.1731719970703125\n",
      "Epoch 1293, Loss: 2.190155852586031, Final Batch Loss: 0.05613904073834419\n",
      "Epoch 1294, Loss: 2.366022676229477, Final Batch Loss: 0.30794277787208557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1295, Loss: 2.1323700943030417, Final Batch Loss: 0.006390730384737253\n",
      "Epoch 1296, Loss: 3.390362858772278, Final Batch Loss: 1.326382040977478\n",
      "Epoch 1297, Loss: 2.2041085101664066, Final Batch Loss: 0.0321446992456913\n",
      "Epoch 1298, Loss: 3.3518396615982056, Final Batch Loss: 1.229576587677002\n",
      "Epoch 1299, Loss: 3.8647841811180115, Final Batch Loss: 1.7716608047485352\n",
      "Epoch 1300, Loss: 2.8694140911102295, Final Batch Loss: 0.7814688086509705\n",
      "Epoch 1301, Loss: 2.4793606102466583, Final Batch Loss: 0.3936499059200287\n",
      "Epoch 1302, Loss: 2.181369364261627, Final Batch Loss: 0.055854201316833496\n",
      "Epoch 1303, Loss: 2.3738517463207245, Final Batch Loss: 0.2800699770450592\n",
      "Epoch 1304, Loss: 2.320504665374756, Final Batch Loss: 0.2985458970069885\n",
      "Epoch 1305, Loss: 3.391565978527069, Final Batch Loss: 1.3178801536560059\n",
      "Epoch 1306, Loss: 2.6014397740364075, Final Batch Loss: 0.5275452733039856\n",
      "Epoch 1307, Loss: 2.785789906978607, Final Batch Loss: 0.6947843432426453\n",
      "Epoch 1308, Loss: 2.043868713924894, Final Batch Loss: 0.0003638797497842461\n",
      "Epoch 1309, Loss: 2.141269562765956, Final Batch Loss: 0.022649524733424187\n",
      "Epoch 1310, Loss: 3.0439090728759766, Final Batch Loss: 1.0162776708602905\n",
      "Epoch 1311, Loss: 2.2568273097276688, Final Batch Loss: 0.07413668930530548\n",
      "Epoch 1312, Loss: 3.1212167739868164, Final Batch Loss: 0.9164150953292847\n",
      "Epoch 1313, Loss: 2.4775034189224243, Final Batch Loss: 0.4011377692222595\n",
      "Epoch 1314, Loss: 3.642825424671173, Final Batch Loss: 1.5990928411483765\n",
      "Epoch 1315, Loss: 2.1280418559908867, Final Batch Loss: 0.06614314764738083\n",
      "Epoch 1316, Loss: 3.803037643432617, Final Batch Loss: 1.7222992181777954\n",
      "Epoch 1317, Loss: 3.418097734451294, Final Batch Loss: 1.3325090408325195\n",
      "Epoch 1318, Loss: 2.1676535308361053, Final Batch Loss: 0.07407847046852112\n",
      "Epoch 1319, Loss: 2.209235370159149, Final Batch Loss: 0.1819480061531067\n",
      "Epoch 1320, Loss: 3.519441306591034, Final Batch Loss: 1.5411075353622437\n",
      "Epoch 1321, Loss: 3.818809390068054, Final Batch Loss: 1.764672040939331\n",
      "Epoch 1322, Loss: 3.90741765499115, Final Batch Loss: 1.8086224794387817\n",
      "Epoch 1323, Loss: 3.4395869970321655, Final Batch Loss: 1.3988237380981445\n",
      "Epoch 1324, Loss: 2.060213550925255, Final Batch Loss: 0.027608439326286316\n",
      "Epoch 1325, Loss: 2.6204274892807007, Final Batch Loss: 0.5372627377510071\n",
      "Epoch 1326, Loss: 2.107465826906264, Final Batch Loss: 0.004519605077803135\n",
      "Epoch 1327, Loss: 2.176842827349901, Final Batch Loss: 0.06097270920872688\n",
      "Epoch 1328, Loss: 2.071748469956219, Final Batch Loss: 0.008118723519146442\n",
      "Epoch 1329, Loss: 3.2799347043037415, Final Batch Loss: 1.2478610277175903\n",
      "Epoch 1330, Loss: 2.456571251153946, Final Batch Loss: 0.413045197725296\n",
      "Epoch 1331, Loss: 2.226047620177269, Final Batch Loss: 0.23000501096248627\n",
      "Epoch 1332, Loss: 2.752686321735382, Final Batch Loss: 0.7197317481040955\n",
      "Epoch 1333, Loss: 3.3826292157173157, Final Batch Loss: 1.3603177070617676\n",
      "Epoch 1334, Loss: 3.7429251670837402, Final Batch Loss: 1.7451913356781006\n",
      "Epoch 1335, Loss: 2.453055262565613, Final Batch Loss: 0.5418304800987244\n",
      "Epoch 1336, Loss: 4.335519075393677, Final Batch Loss: 2.231949806213379\n",
      "Epoch 1337, Loss: 2.1373181995004416, Final Batch Loss: 0.0034143980592489243\n",
      "Epoch 1338, Loss: 2.4672804921865463, Final Batch Loss: 0.19498680531978607\n",
      "Epoch 1339, Loss: 4.9921374917030334, Final Batch Loss: 2.685148000717163\n",
      "Epoch 1340, Loss: 3.7276241779327393, Final Batch Loss: 1.4020850658416748\n",
      "Epoch 1341, Loss: 2.492227904498577, Final Batch Loss: 0.023031584918498993\n",
      "Epoch 1342, Loss: 4.122110664844513, Final Batch Loss: 1.534900426864624\n",
      "Epoch 1343, Loss: 5.185957729816437, Final Batch Loss: 2.597308874130249\n",
      "Epoch 1344, Loss: 2.77602356672287, Final Batch Loss: 0.26006001234054565\n",
      "Epoch 1345, Loss: 2.4835175424814224, Final Batch Loss: 0.1392701417207718\n",
      "Epoch 1346, Loss: 3.852589190006256, Final Batch Loss: 1.5558850765228271\n",
      "Epoch 1347, Loss: 3.700172543525696, Final Batch Loss: 1.3389891386032104\n",
      "Epoch 1348, Loss: 3.434519588947296, Final Batch Loss: 1.1350749731063843\n",
      "Epoch 1349, Loss: 3.969526171684265, Final Batch Loss: 1.6641921997070312\n",
      "Epoch 1350, Loss: 2.31675336509943, Final Batch Loss: 0.01669929176568985\n",
      "Epoch 1351, Loss: 5.907821357250214, Final Batch Loss: 3.6200714111328125\n",
      "Epoch 1352, Loss: 2.4877053648233414, Final Batch Loss: 0.145476832985878\n",
      "Epoch 1353, Loss: 2.4107598662376404, Final Batch Loss: 0.13311296701431274\n",
      "Epoch 1354, Loss: 3.3293139338493347, Final Batch Loss: 0.9793965816497803\n",
      "Epoch 1355, Loss: 3.7632669806480408, Final Batch Loss: 1.465802550315857\n",
      "Epoch 1356, Loss: 2.3773016333580017, Final Batch Loss: 0.17751896381378174\n",
      "Epoch 1357, Loss: 2.4450604766607285, Final Batch Loss: 0.23400883376598358\n",
      "Epoch 1358, Loss: 3.2361145615577698, Final Batch Loss: 1.1057329177856445\n",
      "Epoch 1359, Loss: 2.117105297744274, Final Batch Loss: 0.028202109038829803\n",
      "Epoch 1360, Loss: 2.1303771948441863, Final Batch Loss: 0.015361330471932888\n",
      "Epoch 1361, Loss: 2.156542018055916, Final Batch Loss: 0.07300545275211334\n",
      "Epoch 1362, Loss: 2.215682417154312, Final Batch Loss: 0.13480600714683533\n",
      "Epoch 1363, Loss: 3.8425443172454834, Final Batch Loss: 1.7880635261535645\n",
      "Epoch 1364, Loss: 3.59116393327713, Final Batch Loss: 1.5543334484100342\n",
      "Epoch 1365, Loss: 2.763473331928253, Final Batch Loss: 0.6770474314689636\n",
      "Epoch 1366, Loss: 2.3196984380483627, Final Batch Loss: 0.21880178153514862\n",
      "Epoch 1367, Loss: 2.1728455051779747, Final Batch Loss: 0.09866508096456528\n",
      "Epoch 1368, Loss: 2.199258029460907, Final Batch Loss: 0.12700659036636353\n",
      "Epoch 1369, Loss: 3.8036563396453857, Final Batch Loss: 1.757880687713623\n",
      "Epoch 1370, Loss: 2.2605623602867126, Final Batch Loss: 0.1668328046798706\n",
      "Epoch 1371, Loss: 2.0391527286265045, Final Batch Loss: 0.0031289926264435053\n",
      "Epoch 1372, Loss: 2.6414952278137207, Final Batch Loss: 0.5845985412597656\n",
      "Epoch 1373, Loss: 2.1471783965826035, Final Batch Loss: 0.11279593408107758\n",
      "Epoch 1374, Loss: 2.853260815143585, Final Batch Loss: 0.8402664065361023\n",
      "Epoch 1375, Loss: 4.052659511566162, Final Batch Loss: 1.9797917604446411\n",
      "Epoch 1376, Loss: 3.317533493041992, Final Batch Loss: 1.3176628351211548\n",
      "Epoch 1377, Loss: 3.2204436659812927, Final Batch Loss: 1.2298002243041992\n",
      "Epoch 1378, Loss: 3.5136579275131226, Final Batch Loss: 1.5149033069610596\n",
      "Epoch 1379, Loss: 2.910080909729004, Final Batch Loss: 0.8260480761528015\n",
      "Epoch 1380, Loss: 2.1076632030308247, Final Batch Loss: 0.05217062309384346\n",
      "Epoch 1381, Loss: 2.069381386972964, Final Batch Loss: 0.012387127615511417\n",
      "Epoch 1382, Loss: 2.1104194447398186, Final Batch Loss: 0.06677805632352829\n",
      "Epoch 1383, Loss: 2.8049156069755554, Final Batch Loss: 0.741159200668335\n",
      "Epoch 1384, Loss: 2.15004163980484, Final Batch Loss: 0.16919320821762085\n",
      "Epoch 1385, Loss: 2.150389850139618, Final Batch Loss: 0.16578662395477295\n",
      "Epoch 1386, Loss: 2.082619733409956, Final Batch Loss: 0.002714879112318158\n",
      "Epoch 1387, Loss: 2.251044809818268, Final Batch Loss: 0.22804361581802368\n",
      "Epoch 1388, Loss: 3.171733319759369, Final Batch Loss: 1.1639666557312012\n",
      "Epoch 1389, Loss: 2.639188587665558, Final Batch Loss: 0.6542240381240845\n",
      "Epoch 1390, Loss: 2.367057979106903, Final Batch Loss: 0.3638193607330322\n",
      "Epoch 1391, Loss: 2.67301607131958, Final Batch Loss: 0.5385522842407227\n",
      "Epoch 1392, Loss: 2.172541730105877, Final Batch Loss: 0.09804480522871017\n",
      "Epoch 1393, Loss: 2.1859828159213066, Final Batch Loss: 0.05018877238035202\n",
      "Epoch 1394, Loss: 2.2280775979161263, Final Batch Loss: 0.03328365832567215\n",
      "Epoch 1395, Loss: 2.4015551805496216, Final Batch Loss: 0.33702170848846436\n",
      "Epoch 1396, Loss: 3.021361291408539, Final Batch Loss: 0.9826544523239136\n",
      "Epoch 1397, Loss: 2.121232245117426, Final Batch Loss: 0.04052356258034706\n",
      "Epoch 1398, Loss: 3.7899189591407776, Final Batch Loss: 1.8028761148452759\n",
      "Epoch 1399, Loss: 3.9533380270004272, Final Batch Loss: 1.8612076044082642\n",
      "Epoch 1400, Loss: 2.011638137511909, Final Batch Loss: 0.01311615388840437\n",
      "Epoch 1401, Loss: 2.0449483157135546, Final Batch Loss: 0.0014398456551134586\n",
      "Epoch 1402, Loss: 2.1056510135531425, Final Batch Loss: 0.12164293974637985\n",
      "Epoch 1403, Loss: 2.21395480632782, Final Batch Loss: 0.27101367712020874\n",
      "Epoch 1404, Loss: 2.786405384540558, Final Batch Loss: 0.8422985672950745\n",
      "Epoch 1405, Loss: 1.8941562015679665, Final Batch Loss: 0.0009307105210609734\n",
      "Epoch 1406, Loss: 2.04716132581234, Final Batch Loss: 0.08489523828029633\n",
      "Epoch 1407, Loss: 3.690290093421936, Final Batch Loss: 1.773234486579895\n",
      "Epoch 1408, Loss: 2.344983994960785, Final Batch Loss: 0.2997390627861023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1409, Loss: 4.0956942439079285, Final Batch Loss: 2.0955898761749268\n",
      "Epoch 1410, Loss: 3.443281829357147, Final Batch Loss: 1.3993948698043823\n",
      "Epoch 1411, Loss: 4.386301338672638, Final Batch Loss: 2.4047389030456543\n",
      "Epoch 1412, Loss: 3.932737350463867, Final Batch Loss: 1.928838849067688\n",
      "Epoch 1413, Loss: 2.76138174533844, Final Batch Loss: 0.7715548276901245\n",
      "Epoch 1414, Loss: 2.070677552372217, Final Batch Loss: 0.059802327305078506\n",
      "Epoch 1415, Loss: 2.168314889073372, Final Batch Loss: 0.201443150639534\n",
      "Epoch 1416, Loss: 2.0846126209944487, Final Batch Loss: 0.02175678126513958\n",
      "Epoch 1417, Loss: 3.8564606308937073, Final Batch Loss: 1.811380386352539\n",
      "Epoch 1418, Loss: 1.9750669039785862, Final Batch Loss: 0.03798598423600197\n",
      "Epoch 1419, Loss: 2.112809121608734, Final Batch Loss: 0.1670864224433899\n",
      "Epoch 1420, Loss: 2.0384151190519333, Final Batch Loss: 0.11995558440685272\n",
      "Epoch 1421, Loss: 2.099024884402752, Final Batch Loss: 0.10371028631925583\n",
      "Epoch 1422, Loss: 2.075833961367607, Final Batch Loss: 0.10810337960720062\n",
      "Epoch 1423, Loss: 4.0503129959106445, Final Batch Loss: 2.075050115585327\n",
      "Epoch 1424, Loss: 2.0862971525639296, Final Batch Loss: 0.007176218554377556\n",
      "Epoch 1425, Loss: 2.1170397251844406, Final Batch Loss: 0.14568428695201874\n",
      "Epoch 1426, Loss: 1.9716653153300285, Final Batch Loss: 0.025561682879924774\n",
      "Epoch 1427, Loss: 3.707757353782654, Final Batch Loss: 1.7541699409484863\n",
      "Epoch 1428, Loss: 3.811608076095581, Final Batch Loss: 1.836484432220459\n",
      "Epoch 1429, Loss: 2.3263627886772156, Final Batch Loss: 0.23905348777770996\n",
      "Epoch 1430, Loss: 3.654226064682007, Final Batch Loss: 1.66592276096344\n",
      "Epoch 1431, Loss: 3.7383204102516174, Final Batch Loss: 1.678095817565918\n",
      "Epoch 1432, Loss: 4.119838297367096, Final Batch Loss: 2.1606833934783936\n",
      "Epoch 1433, Loss: 2.412151277065277, Final Batch Loss: 0.42197275161743164\n",
      "Epoch 1434, Loss: 2.144171664491296, Final Batch Loss: 0.008352348580956459\n",
      "Epoch 1435, Loss: 3.5646637082099915, Final Batch Loss: 1.5188989639282227\n",
      "Epoch 1436, Loss: 3.3900179862976074, Final Batch Loss: 1.4462605714797974\n",
      "Epoch 1437, Loss: 2.089576669037342, Final Batch Loss: 0.015538342297077179\n",
      "Epoch 1438, Loss: 2.8616105914115906, Final Batch Loss: 0.783822774887085\n",
      "Epoch 1439, Loss: 2.9721257090568542, Final Batch Loss: 0.9135312438011169\n",
      "Epoch 1440, Loss: 2.114373628050089, Final Batch Loss: 0.05471641197800636\n",
      "Epoch 1441, Loss: 2.369512915611267, Final Batch Loss: 0.32472747564315796\n",
      "Epoch 1442, Loss: 2.0347341685555875, Final Batch Loss: 0.00390909006819129\n",
      "Epoch 1443, Loss: 3.4982742071151733, Final Batch Loss: 1.5099360942840576\n",
      "Epoch 1444, Loss: 2.0023400794889312, Final Batch Loss: 0.0004858981992583722\n",
      "Epoch 1445, Loss: 3.4153116941452026, Final Batch Loss: 1.3945000171661377\n",
      "Epoch 1446, Loss: 2.632124602794647, Final Batch Loss: 0.525804877281189\n",
      "Epoch 1447, Loss: 2.6521944403648376, Final Batch Loss: 0.695647120475769\n",
      "Epoch 1448, Loss: 3.4891006350517273, Final Batch Loss: 1.4317736625671387\n",
      "Epoch 1449, Loss: 3.5850293040275574, Final Batch Loss: 1.6574167013168335\n",
      "Epoch 1450, Loss: 1.969555303454399, Final Batch Loss: 0.036811813712120056\n",
      "Epoch 1451, Loss: 2.603657305240631, Final Batch Loss: 0.5904799103736877\n",
      "Epoch 1452, Loss: 2.965781033039093, Final Batch Loss: 1.0264432430267334\n",
      "Epoch 1453, Loss: 2.1491828188300133, Final Batch Loss: 0.08854194730520248\n",
      "Epoch 1454, Loss: 2.0779985561966896, Final Batch Loss: 0.048739708960056305\n",
      "Epoch 1455, Loss: 2.0735013000667095, Final Batch Loss: 0.023234497755765915\n",
      "Epoch 1456, Loss: 2.3129122108221054, Final Batch Loss: 0.2192922681570053\n",
      "Epoch 1457, Loss: 2.102038387209177, Final Batch Loss: 0.016339901834726334\n",
      "Epoch 1458, Loss: 2.1079012900590897, Final Batch Loss: 0.014764800667762756\n",
      "Epoch 1459, Loss: 3.9460856318473816, Final Batch Loss: 1.8499045372009277\n",
      "Epoch 1460, Loss: 2.0531948059797287, Final Batch Loss: 0.07522706687450409\n",
      "Epoch 1461, Loss: 2.0282282046973705, Final Batch Loss: 0.022962849587202072\n",
      "Epoch 1462, Loss: 2.452536851167679, Final Batch Loss: 0.4477490484714508\n",
      "Epoch 1463, Loss: 2.734963059425354, Final Batch Loss: 0.7310037016868591\n",
      "Epoch 1464, Loss: 1.9822039431892335, Final Batch Loss: 0.00018559163436293602\n",
      "Epoch 1465, Loss: 2.530352771282196, Final Batch Loss: 0.5851222276687622\n",
      "Epoch 1466, Loss: 1.929517498880159, Final Batch Loss: 0.00013171759201213717\n",
      "Epoch 1467, Loss: 2.3287015855312347, Final Batch Loss: 0.31788310408592224\n",
      "Epoch 1468, Loss: 1.9272300694137812, Final Batch Loss: 0.00784672237932682\n",
      "Epoch 1469, Loss: 2.180314213037491, Final Batch Loss: 0.22566112875938416\n",
      "Epoch 1470, Loss: 4.071593880653381, Final Batch Loss: 2.062567710876465\n",
      "Epoch 1471, Loss: 2.055996760725975, Final Batch Loss: 0.0700254887342453\n",
      "Epoch 1472, Loss: 3.5932236909866333, Final Batch Loss: 1.6605792045593262\n",
      "Epoch 1473, Loss: 3.5907427072525024, Final Batch Loss: 1.5065864324569702\n",
      "Epoch 1474, Loss: 3.7340638041496277, Final Batch Loss: 1.6981761455535889\n",
      "Epoch 1475, Loss: 2.4099785685539246, Final Batch Loss: 0.468017578125\n",
      "Epoch 1476, Loss: 4.099487781524658, Final Batch Loss: 2.062869071960449\n",
      "Epoch 1477, Loss: 1.9960894571850076, Final Batch Loss: 0.001760719926096499\n",
      "Epoch 1478, Loss: 3.2443917989730835, Final Batch Loss: 1.3179160356521606\n",
      "Epoch 1479, Loss: 2.6483696699142456, Final Batch Loss: 0.6295964121818542\n",
      "Epoch 1480, Loss: 3.7364811301231384, Final Batch Loss: 1.7799999713897705\n",
      "Epoch 1481, Loss: 2.5795631408691406, Final Batch Loss: 0.5583924055099487\n",
      "Epoch 1482, Loss: 3.299249053001404, Final Batch Loss: 1.3029146194458008\n",
      "Epoch 1483, Loss: 1.9832338765263557, Final Batch Loss: 0.016960926353931427\n",
      "Epoch 1484, Loss: 2.590280592441559, Final Batch Loss: 0.7374680042266846\n",
      "Epoch 1485, Loss: 2.2359331250190735, Final Batch Loss: 0.3167821764945984\n",
      "Epoch 1486, Loss: 1.9159999061375856, Final Batch Loss: 0.013569967821240425\n",
      "Epoch 1487, Loss: 3.2357813119888306, Final Batch Loss: 1.2506201267242432\n",
      "Epoch 1488, Loss: 2.058806598186493, Final Batch Loss: 0.05921870470046997\n",
      "Epoch 1489, Loss: 2.34654238820076, Final Batch Loss: 0.48750612139701843\n",
      "Epoch 1490, Loss: 2.225416913628578, Final Batch Loss: 0.23166437447071075\n",
      "Epoch 1491, Loss: 4.80818510055542, Final Batch Loss: 2.5496013164520264\n",
      "Epoch 1492, Loss: 2.8657360579818487, Final Batch Loss: 0.007218470796942711\n",
      "Epoch 1493, Loss: 2.892002820968628, Final Batch Loss: 0.08929789066314697\n",
      "Epoch 1494, Loss: 4.520563066005707, Final Batch Loss: 2.2045862674713135\n",
      "Epoch 1495, Loss: 3.5577898025512695, Final Batch Loss: 1.512516975402832\n",
      "Epoch 1496, Loss: 3.8718857169151306, Final Batch Loss: 1.9070382118225098\n",
      "Epoch 1497, Loss: 3.1701303720474243, Final Batch Loss: 1.2840118408203125\n",
      "Epoch 1498, Loss: 2.4468382000923157, Final Batch Loss: 0.45706355571746826\n",
      "Epoch 1499, Loss: 3.335368037223816, Final Batch Loss: 1.3873200416564941\n",
      "Epoch 1500, Loss: 2.766297936439514, Final Batch Loss: 0.8164893984794617\n",
      "Epoch 1501, Loss: 2.9795865416526794, Final Batch Loss: 1.0025734901428223\n",
      "Epoch 1502, Loss: 3.8162439465522766, Final Batch Loss: 1.8315832614898682\n",
      "Epoch 1503, Loss: 2.133428707718849, Final Batch Loss: 0.19899441301822662\n",
      "Epoch 1504, Loss: 3.2617087364196777, Final Batch Loss: 1.2777515649795532\n",
      "Epoch 1505, Loss: 2.2522884011268616, Final Batch Loss: 0.2800478935241699\n",
      "Epoch 1506, Loss: 2.4730035066604614, Final Batch Loss: 0.5201144814491272\n",
      "Epoch 1507, Loss: 1.991420608945191, Final Batch Loss: 0.0076431455090641975\n",
      "Epoch 1508, Loss: 1.9609208218753338, Final Batch Loss: 0.04994691535830498\n",
      "Epoch 1509, Loss: 3.187699019908905, Final Batch Loss: 1.232588529586792\n",
      "Epoch 1510, Loss: 2.2123653292655945, Final Batch Loss: 0.23309117555618286\n",
      "Epoch 1511, Loss: 2.076350636780262, Final Batch Loss: 0.08121979981660843\n",
      "Epoch 1512, Loss: 2.2552165389060974, Final Batch Loss: 0.30796247720718384\n",
      "Epoch 1513, Loss: 3.353142201900482, Final Batch Loss: 1.365221381187439\n",
      "Epoch 1514, Loss: 1.940645769238472, Final Batch Loss: 0.0030232220888137817\n",
      "Epoch 1515, Loss: 2.015811201184988, Final Batch Loss: 0.03532492741942406\n",
      "Epoch 1516, Loss: 2.142393968999386, Final Batch Loss: 0.09350015968084335\n",
      "Epoch 1517, Loss: 2.173958456143737, Final Batch Loss: 0.005190705880522728\n",
      "Epoch 1518, Loss: 3.02903014421463, Final Batch Loss: 1.0279470682144165\n",
      "Epoch 1519, Loss: 1.997495288029313, Final Batch Loss: 0.02761017717421055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1520, Loss: 1.9135369057767093, Final Batch Loss: 0.005421459209173918\n",
      "Epoch 1521, Loss: 2.0163587257266045, Final Batch Loss: 0.07422678917646408\n",
      "Epoch 1522, Loss: 3.684833347797394, Final Batch Loss: 1.726459264755249\n",
      "Epoch 1523, Loss: 2.4163248538970947, Final Batch Loss: 0.5011162161827087\n",
      "Epoch 1524, Loss: 1.9765290841460228, Final Batch Loss: 0.0631774291396141\n",
      "Epoch 1525, Loss: 2.07589852809906, Final Batch Loss: 0.1526433825492859\n",
      "Epoch 1526, Loss: 2.257785350084305, Final Batch Loss: 0.36574068665504456\n",
      "Epoch 1527, Loss: 2.0019092932343483, Final Batch Loss: 0.06600198894739151\n",
      "Epoch 1528, Loss: 1.9381868038326502, Final Batch Loss: 0.012419858947396278\n",
      "Epoch 1529, Loss: 3.272901475429535, Final Batch Loss: 1.3470065593719482\n",
      "Epoch 1530, Loss: 2.2633711099624634, Final Batch Loss: 0.31685417890548706\n",
      "Epoch 1531, Loss: 2.22691111266613, Final Batch Loss: 0.22622792422771454\n",
      "Epoch 1532, Loss: 2.010729059576988, Final Batch Loss: 0.021270260214805603\n",
      "Epoch 1533, Loss: 2.086973324418068, Final Batch Loss: 0.14271147549152374\n",
      "Epoch 1534, Loss: 2.810996890068054, Final Batch Loss: 0.8245707154273987\n",
      "Epoch 1535, Loss: 3.6512823700904846, Final Batch Loss: 1.6863634586334229\n",
      "Epoch 1536, Loss: 2.1510982513427734, Final Batch Loss: 0.20930367708206177\n",
      "Epoch 1537, Loss: 1.994378238916397, Final Batch Loss: 0.14164748787879944\n",
      "Epoch 1538, Loss: 1.9801803082227707, Final Batch Loss: 0.15209196507930756\n",
      "Epoch 1539, Loss: 1.8522501047700644, Final Batch Loss: 0.02046937309205532\n",
      "Epoch 1540, Loss: 2.0740981847047806, Final Batch Loss: 0.16555429995059967\n",
      "Epoch 1541, Loss: 3.5366291403770447, Final Batch Loss: 1.638554573059082\n",
      "Epoch 1542, Loss: 2.976042866706848, Final Batch Loss: 1.0381345748901367\n",
      "Epoch 1543, Loss: 3.317484676837921, Final Batch Loss: 1.4469389915466309\n",
      "Epoch 1544, Loss: 2.211722582578659, Final Batch Loss: 0.28555455803871155\n",
      "Epoch 1545, Loss: 3.8108522295951843, Final Batch Loss: 1.9431662559509277\n",
      "Epoch 1546, Loss: 2.043238304555416, Final Batch Loss: 0.11853107064962387\n",
      "Epoch 1547, Loss: 2.4989866614341736, Final Batch Loss: 0.6344123482704163\n",
      "Epoch 1548, Loss: 1.9292897023260593, Final Batch Loss: 0.005398694425821304\n",
      "Epoch 1549, Loss: 3.341114640235901, Final Batch Loss: 1.3251252174377441\n",
      "Epoch 1550, Loss: 2.25968074798584, Final Batch Loss: 0.2770717740058899\n",
      "Epoch 1551, Loss: 3.7693257331848145, Final Batch Loss: 1.770887851715088\n",
      "Epoch 1552, Loss: 1.9734827056527138, Final Batch Loss: 0.051779843866825104\n",
      "Epoch 1553, Loss: 2.6093702912330627, Final Batch Loss: 0.6024041175842285\n",
      "Epoch 1554, Loss: 1.9671696834266186, Final Batch Loss: 0.04058824107050896\n",
      "Epoch 1555, Loss: 2.5035025477409363, Final Batch Loss: 0.35415220260620117\n",
      "Epoch 1556, Loss: 3.6906769275665283, Final Batch Loss: 1.5215429067611694\n",
      "Epoch 1557, Loss: 2.5276174545288086, Final Batch Loss: 0.5021135210990906\n",
      "Epoch 1558, Loss: 2.3535328805446625, Final Batch Loss: 0.4579116404056549\n",
      "Epoch 1559, Loss: 2.889216899871826, Final Batch Loss: 0.8898321390151978\n",
      "Epoch 1560, Loss: 2.051082819700241, Final Batch Loss: 0.06548193097114563\n",
      "Epoch 1561, Loss: 2.0018177318852395, Final Batch Loss: 0.0004256058018654585\n",
      "Epoch 1562, Loss: 4.766517519950867, Final Batch Loss: 2.6953344345092773\n",
      "Epoch 1563, Loss: 1.911838511005044, Final Batch Loss: 0.005120733752846718\n",
      "Epoch 1564, Loss: 2.850351333618164, Final Batch Loss: 0.8916769027709961\n",
      "Epoch 1565, Loss: 2.144920215010643, Final Batch Loss: 0.18089930713176727\n",
      "Epoch 1566, Loss: 2.137211173772812, Final Batch Loss: 0.22601094841957092\n",
      "Epoch 1567, Loss: 1.9951336863159668, Final Batch Loss: 0.0001528146385680884\n",
      "Epoch 1568, Loss: 2.1287726014852524, Final Batch Loss: 0.12185339629650116\n",
      "Epoch 1569, Loss: 1.901087096426636, Final Batch Loss: 0.0075166733004152775\n",
      "Epoch 1570, Loss: 2.007615551352501, Final Batch Loss: 0.1650291532278061\n",
      "Epoch 1571, Loss: 2.490991711616516, Final Batch Loss: 0.5928561687469482\n",
      "Epoch 1572, Loss: 2.660460352897644, Final Batch Loss: 0.876727819442749\n",
      "Epoch 1573, Loss: 3.848351240158081, Final Batch Loss: 1.8953815698623657\n",
      "Epoch 1574, Loss: 2.5991892218589783, Final Batch Loss: 0.7232477068901062\n",
      "Epoch 1575, Loss: 1.9915713723748922, Final Batch Loss: 0.028044944629073143\n",
      "Epoch 1576, Loss: 3.350406527519226, Final Batch Loss: 1.4702361822128296\n",
      "Epoch 1577, Loss: 1.9287100154906511, Final Batch Loss: 0.01029113121330738\n",
      "Epoch 1578, Loss: 3.8473495841026306, Final Batch Loss: 1.917153000831604\n",
      "Epoch 1579, Loss: 4.1266061663627625, Final Batch Loss: 2.130436420440674\n",
      "Epoch 1580, Loss: 2.0143541768193245, Final Batch Loss: 0.01018340140581131\n",
      "Epoch 1581, Loss: 1.9345991676673293, Final Batch Loss: 0.013109094463288784\n",
      "Epoch 1582, Loss: 1.9494131281971931, Final Batch Loss: 0.010973699390888214\n",
      "Epoch 1583, Loss: 4.04637598991394, Final Batch Loss: 2.0787177085876465\n",
      "Epoch 1584, Loss: 2.787661373615265, Final Batch Loss: 0.83449387550354\n",
      "Epoch 1585, Loss: 1.9253767598420382, Final Batch Loss: 0.015309559181332588\n",
      "Epoch 1586, Loss: 2.069680169224739, Final Batch Loss: 0.1957736760377884\n",
      "Epoch 1587, Loss: 3.8541215658187866, Final Batch Loss: 1.849412202835083\n",
      "Epoch 1588, Loss: 2.9657448530197144, Final Batch Loss: 1.117866039276123\n",
      "Epoch 1589, Loss: 3.723673939704895, Final Batch Loss: 1.7494759559631348\n",
      "Epoch 1590, Loss: 1.8629395487951115, Final Batch Loss: 0.0016837242292240262\n",
      "Epoch 1591, Loss: 2.4056769609451294, Final Batch Loss: 0.4591977000236511\n",
      "Epoch 1592, Loss: 1.8875189516693354, Final Batch Loss: 0.009911725297570229\n",
      "Epoch 1593, Loss: 3.6615394353866577, Final Batch Loss: 1.7151243686676025\n",
      "Epoch 1594, Loss: 8.761139333248138, Final Batch Loss: 6.886621952056885\n",
      "Epoch 1595, Loss: 1.9806421846151352, Final Batch Loss: 0.12747053802013397\n",
      "Epoch 1596, Loss: 2.0870410576462746, Final Batch Loss: 0.08493707329034805\n",
      "Epoch 1597, Loss: 7.422892451286316, Final Batch Loss: 5.085899829864502\n",
      "Epoch 1598, Loss: 3.490254759788513, Final Batch Loss: 1.361340880393982\n",
      "Epoch 1599, Loss: 2.1720721144229174, Final Batch Loss: 0.02578139491379261\n",
      "Epoch 1600, Loss: 2.3245169892907143, Final Batch Loss: 0.09577880054712296\n",
      "Epoch 1601, Loss: 2.2828612439334393, Final Batch Loss: 0.03873718902468681\n",
      "Epoch 1602, Loss: 2.2387391105294228, Final Batch Loss: 0.006037332117557526\n",
      "Epoch 1603, Loss: 2.2366201711120084, Final Batch Loss: 0.00018249277491122484\n",
      "Epoch 1604, Loss: 2.9360060691833496, Final Batch Loss: 0.7677760124206543\n",
      "Epoch 1605, Loss: 2.99960196018219, Final Batch Loss: 0.8864730000495911\n",
      "Epoch 1606, Loss: 2.453313499689102, Final Batch Loss: 0.41800031065940857\n",
      "Epoch 1607, Loss: 2.1665869802236557, Final Batch Loss: 0.10884468257427216\n",
      "Epoch 1608, Loss: 2.354504257440567, Final Batch Loss: 0.37543514370918274\n",
      "Epoch 1609, Loss: 2.405353367328644, Final Batch Loss: 0.47026675939559937\n",
      "Epoch 1610, Loss: 2.502203106880188, Final Batch Loss: 0.5878393650054932\n",
      "Epoch 1611, Loss: 2.64135605096817, Final Batch Loss: 0.6914294958114624\n",
      "Epoch 1612, Loss: 1.963777294382453, Final Batch Loss: 0.014269223436713219\n",
      "Epoch 1613, Loss: 2.478310465812683, Final Batch Loss: 0.5494289994239807\n",
      "Epoch 1614, Loss: 3.4485430121421814, Final Batch Loss: 1.6125609874725342\n",
      "Epoch 1615, Loss: 2.0061598047614098, Final Batch Loss: 0.09880062192678452\n",
      "Epoch 1616, Loss: 1.942243106663227, Final Batch Loss: 0.03876597434282303\n",
      "Epoch 1617, Loss: 3.5222896933555603, Final Batch Loss: 1.51926589012146\n",
      "Epoch 1618, Loss: 2.1686963737010956, Final Batch Loss: 0.2102576196193695\n",
      "Epoch 1619, Loss: 2.011928878724575, Final Batch Loss: 0.09782960265874863\n",
      "Epoch 1620, Loss: 2.0019941609352827, Final Batch Loss: 0.02319571189582348\n",
      "Epoch 1621, Loss: 3.269706130027771, Final Batch Loss: 1.2579936981201172\n",
      "Epoch 1622, Loss: 1.9302332343067974, Final Batch Loss: 0.0029705704655498266\n",
      "Epoch 1623, Loss: 2.1322353929281235, Final Batch Loss: 0.19822220504283905\n",
      "Epoch 1624, Loss: 3.54038405418396, Final Batch Loss: 1.631557822227478\n",
      "Epoch 1625, Loss: 4.445969641208649, Final Batch Loss: 2.4850807189941406\n",
      "Epoch 1626, Loss: 2.3095561265945435, Final Batch Loss: 0.4131695628166199\n",
      "Epoch 1627, Loss: 3.043105959892273, Final Batch Loss: 1.127317190170288\n",
      "Epoch 1628, Loss: 1.9454453065991402, Final Batch Loss: 0.03415615111589432\n",
      "Epoch 1629, Loss: 2.144031897187233, Final Batch Loss: 0.13388122618198395\n",
      "Epoch 1630, Loss: 1.8958457875996828, Final Batch Loss: 0.0060897041112184525\n",
      "Epoch 1631, Loss: 1.9446013295091689, Final Batch Loss: 0.003925951663404703\n",
      "Epoch 1632, Loss: 2.131678193807602, Final Batch Loss: 0.14387086033821106\n",
      "Epoch 1633, Loss: 2.8883188366889954, Final Batch Loss: 1.0093231201171875\n",
      "Epoch 1634, Loss: 1.9028380289673805, Final Batch Loss: 0.08186564594507217\n",
      "Epoch 1635, Loss: 3.3653765320777893, Final Batch Loss: 1.4087034463882446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1636, Loss: 2.2764010429382324, Final Batch Loss: 0.3742527961730957\n",
      "Epoch 1637, Loss: 3.6579824686050415, Final Batch Loss: 1.650551199913025\n",
      "Epoch 1638, Loss: 3.0906506776809692, Final Batch Loss: 1.1613727807998657\n",
      "Epoch 1639, Loss: 2.6692755222320557, Final Batch Loss: 0.703647255897522\n",
      "Epoch 1640, Loss: 3.054203689098358, Final Batch Loss: 0.9999029040336609\n",
      "Epoch 1641, Loss: 1.9603273496031761, Final Batch Loss: 0.049073003232479095\n",
      "Epoch 1642, Loss: 2.5566888451576233, Final Batch Loss: 0.6318621635437012\n",
      "Epoch 1643, Loss: 2.256906121969223, Final Batch Loss: 0.25849178433418274\n",
      "Epoch 1644, Loss: 2.1691245436668396, Final Batch Loss: 0.3386465311050415\n",
      "Epoch 1645, Loss: 2.2422555685043335, Final Batch Loss: 0.3072790503501892\n",
      "Epoch 1646, Loss: 4.130914807319641, Final Batch Loss: 2.229358196258545\n",
      "Epoch 1647, Loss: 2.7022672295570374, Final Batch Loss: 0.7547828555107117\n",
      "Epoch 1648, Loss: 1.9864878542721272, Final Batch Loss: 0.057990361005067825\n",
      "Epoch 1649, Loss: 1.9886567518115044, Final Batch Loss: 0.10718762129545212\n",
      "Epoch 1650, Loss: 2.10757514834404, Final Batch Loss: 0.2662869393825531\n",
      "Epoch 1651, Loss: 1.8849119772203267, Final Batch Loss: 0.0014893640764057636\n",
      "Epoch 1652, Loss: 2.0262088626623154, Final Batch Loss: 0.14245645701885223\n",
      "Epoch 1653, Loss: 2.204019248485565, Final Batch Loss: 0.3890641927719116\n",
      "Epoch 1654, Loss: 1.9136074857087806, Final Batch Loss: 0.0008366183610633016\n",
      "Epoch 1655, Loss: 2.237864673137665, Final Batch Loss: 0.36594367027282715\n",
      "Epoch 1656, Loss: 1.9795668753795326, Final Batch Loss: 0.0018887552432715893\n",
      "Epoch 1657, Loss: 1.9153826313558966, Final Batch Loss: 0.003431149059906602\n",
      "Epoch 1658, Loss: 1.943078950047493, Final Batch Loss: 0.0907498151063919\n",
      "Epoch 1659, Loss: 1.961561352480203, Final Batch Loss: 0.006727308500558138\n",
      "Epoch 1660, Loss: 4.383573770523071, Final Batch Loss: 2.4745547771453857\n",
      "Epoch 1661, Loss: 3.0752137899398804, Final Batch Loss: 1.1059538125991821\n",
      "Epoch 1662, Loss: 1.9044522726908326, Final Batch Loss: 0.008597620762884617\n",
      "Epoch 1663, Loss: 1.9670906364917755, Final Batch Loss: 0.1525079905986786\n",
      "Epoch 1664, Loss: 1.8717783689498901, Final Batch Loss: 0.0785253643989563\n",
      "Epoch 1665, Loss: 2.0422115176916122, Final Batch Loss: 0.17188559472560883\n",
      "Epoch 1666, Loss: 1.9106550216674805, Final Batch Loss: 0.05474722385406494\n",
      "Epoch 1667, Loss: 1.8337274759542197, Final Batch Loss: 0.0032011240255087614\n",
      "Epoch 1668, Loss: 1.8319361098110676, Final Batch Loss: 0.019935715943574905\n",
      "Epoch 1669, Loss: 1.8190245123114437, Final Batch Loss: 0.0027140469755977392\n",
      "Epoch 1670, Loss: 1.833363339304924, Final Batch Loss: 0.04444305598735809\n",
      "Epoch 1671, Loss: 2.1523582339286804, Final Batch Loss: 0.41071391105651855\n",
      "Epoch 1672, Loss: 1.8730538878589869, Final Batch Loss: 0.01435265876352787\n",
      "Epoch 1673, Loss: 1.8178805555216968, Final Batch Loss: 0.0018669809214770794\n",
      "Epoch 1674, Loss: 2.8232319951057434, Final Batch Loss: 0.9926655888557434\n",
      "Epoch 1675, Loss: 1.9584457725286484, Final Batch Loss: 0.08249251544475555\n",
      "Epoch 1676, Loss: 1.8922662157565355, Final Batch Loss: 0.01834672875702381\n",
      "Epoch 1677, Loss: 1.9659511372447014, Final Batch Loss: 0.11231159418821335\n",
      "Epoch 1678, Loss: 1.945200216025114, Final Batch Loss: 0.05026937648653984\n",
      "Epoch 1679, Loss: 1.8463683606387349, Final Batch Loss: 0.00015364897262770683\n",
      "Epoch 1680, Loss: 1.8472232855856419, Final Batch Loss: 0.02925897017121315\n",
      "Epoch 1681, Loss: 2.1473205536603928, Final Batch Loss: 0.23068861663341522\n",
      "Epoch 1682, Loss: 2.134132355451584, Final Batch Loss: 0.3147192895412445\n",
      "Epoch 1683, Loss: 2.300425797700882, Final Batch Loss: 0.42391374707221985\n",
      "Epoch 1684, Loss: 2.0748617947101593, Final Batch Loss: 0.1737428605556488\n",
      "Epoch 1685, Loss: 1.7940995930694044, Final Batch Loss: 0.0025733946822583675\n",
      "Epoch 1686, Loss: 3.7001960277557373, Final Batch Loss: 1.8714817762374878\n",
      "Epoch 1687, Loss: 3.5937499403953552, Final Batch Loss: 1.768591284751892\n",
      "Epoch 1688, Loss: 2.1526216864585876, Final Batch Loss: 0.2601470351219177\n",
      "Epoch 1689, Loss: 1.8950125873088837, Final Batch Loss: 0.018151015043258667\n",
      "Epoch 1690, Loss: 2.722579300403595, Final Batch Loss: 0.8193877935409546\n",
      "Epoch 1691, Loss: 2.2248990535736084, Final Batch Loss: 0.3448261618614197\n",
      "Epoch 1692, Loss: 2.1181449592113495, Final Batch Loss: 0.27514997124671936\n",
      "Epoch 1693, Loss: 3.523718297481537, Final Batch Loss: 1.6665019989013672\n",
      "Epoch 1694, Loss: 3.6433423161506653, Final Batch Loss: 1.6177804470062256\n",
      "Epoch 1695, Loss: 2.718142867088318, Final Batch Loss: 0.8985172510147095\n",
      "Epoch 1696, Loss: 2.20959734916687, Final Batch Loss: 0.26831138134002686\n",
      "Epoch 1697, Loss: 2.1395005136728287, Final Batch Loss: 0.16465581953525543\n",
      "Epoch 1698, Loss: 1.9459065049886703, Final Batch Loss: 0.06566379964351654\n",
      "Epoch 1699, Loss: 2.0547427237033844, Final Batch Loss: 0.19783952832221985\n",
      "Epoch 1700, Loss: 2.23906147480011, Final Batch Loss: 0.39972198009490967\n",
      "Epoch 1701, Loss: 1.8479848725255579, Final Batch Loss: 0.002597056096419692\n",
      "Epoch 1702, Loss: 1.8640873674303293, Final Batch Loss: 0.007122719660401344\n",
      "Epoch 1703, Loss: 1.9189199581742287, Final Batch Loss: 0.08593479543924332\n",
      "Epoch 1704, Loss: 1.9547544717788696, Final Batch Loss: 0.1303722858428955\n",
      "Epoch 1705, Loss: 2.1353655457496643, Final Batch Loss: 0.32142382860183716\n",
      "Epoch 1706, Loss: 3.737673044204712, Final Batch Loss: 1.943048119544983\n",
      "Epoch 1707, Loss: 1.8814671747386456, Final Batch Loss: 0.044687043875455856\n",
      "Epoch 1708, Loss: 1.876466833986342, Final Batch Loss: 0.006088637746870518\n",
      "Epoch 1709, Loss: 2.227003514766693, Final Batch Loss: 0.39692652225494385\n",
      "Epoch 1710, Loss: 3.299928843975067, Final Batch Loss: 1.4742412567138672\n",
      "Epoch 1711, Loss: 2.1730426251888275, Final Batch Loss: 0.37447765469551086\n",
      "Epoch 1712, Loss: 1.9512265175580978, Final Batch Loss: 0.1250429004430771\n",
      "Epoch 1713, Loss: 2.7114705443382263, Final Batch Loss: 0.8284351825714111\n",
      "Epoch 1714, Loss: 2.1599133908748627, Final Batch Loss: 0.2493526041507721\n",
      "Epoch 1715, Loss: 1.952152542769909, Final Batch Loss: 0.040057770907878876\n",
      "Epoch 1716, Loss: 3.12181693315506, Final Batch Loss: 1.2526476383209229\n",
      "Epoch 1717, Loss: 2.354309618473053, Final Batch Loss: 0.4559965133666992\n",
      "Epoch 1718, Loss: 3.0813823342323303, Final Batch Loss: 1.248206377029419\n",
      "Epoch 1719, Loss: 5.797966003417969, Final Batch Loss: 3.921125888824463\n",
      "Epoch 1720, Loss: 3.0190029740333557, Final Batch Loss: 1.185010552406311\n",
      "Epoch 1721, Loss: 1.919154676841572, Final Batch Loss: 0.002875956939533353\n",
      "Epoch 1722, Loss: 1.9263847395777702, Final Batch Loss: 0.03374408930540085\n",
      "Epoch 1723, Loss: 4.069011390209198, Final Batch Loss: 2.0944483280181885\n",
      "Epoch 1724, Loss: 1.9621070474386215, Final Batch Loss: 0.041925475001335144\n",
      "Epoch 1725, Loss: 1.9461939595639706, Final Batch Loss: 0.03479119762778282\n",
      "Epoch 1726, Loss: 3.5150421857833862, Final Batch Loss: 1.713669776916504\n",
      "Epoch 1727, Loss: 1.929166778922081, Final Batch Loss: 0.11706869304180145\n",
      "Epoch 1728, Loss: 2.9319987893104553, Final Batch Loss: 1.1480218172073364\n",
      "Epoch 1729, Loss: 2.040619745850563, Final Batch Loss: 0.13182736933231354\n",
      "Epoch 1730, Loss: 1.8149971552193165, Final Batch Loss: 0.00429113581776619\n",
      "Epoch 1731, Loss: 3.6370989084243774, Final Batch Loss: 1.765434741973877\n",
      "Epoch 1732, Loss: 1.990101009607315, Final Batch Loss: 0.14184001088142395\n",
      "Epoch 1733, Loss: 1.795272040180862, Final Batch Loss: 0.010523187927901745\n",
      "Epoch 1734, Loss: 2.0634686052799225, Final Batch Loss: 0.19112882018089294\n",
      "Epoch 1735, Loss: 3.5555902123451233, Final Batch Loss: 1.7278995513916016\n",
      "Epoch 1736, Loss: 2.2018328309059143, Final Batch Loss: 0.33934247493743896\n",
      "Epoch 1737, Loss: 1.8405062162782997, Final Batch Loss: 0.0013660395052284002\n",
      "Epoch 1738, Loss: 2.0236821183934808, Final Batch Loss: 0.013549269177019596\n",
      "Epoch 1739, Loss: 2.353891283273697, Final Batch Loss: 0.278510183095932\n",
      "Epoch 1740, Loss: 2.3161484003067017, Final Batch Loss: 0.4204387068748474\n",
      "Epoch 1741, Loss: 2.0071605816483498, Final Batch Loss: 0.10645977407693863\n",
      "Epoch 1742, Loss: 3.9744454622268677, Final Batch Loss: 2.195458173751831\n",
      "Epoch 1743, Loss: 3.606478750705719, Final Batch Loss: 1.7235846519470215\n",
      "Epoch 1744, Loss: 1.8898387141525745, Final Batch Loss: 0.017349500209093094\n",
      "Epoch 1745, Loss: 2.10202918946743, Final Batch Loss: 0.22606991231441498\n",
      "Epoch 1746, Loss: 2.195467710494995, Final Batch Loss: 0.40235400199890137\n",
      "Epoch 1747, Loss: 1.8676513992249966, Final Batch Loss: 0.03183227404952049\n",
      "Epoch 1748, Loss: 2.012380301952362, Final Batch Loss: 0.14893531799316406\n",
      "Epoch 1749, Loss: 2.397164762020111, Final Batch Loss: 0.5847837924957275\n",
      "Epoch 1750, Loss: 2.2079604268074036, Final Batch Loss: 0.37605345249176025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751, Loss: 1.895822829566896, Final Batch Loss: 0.015381521545350552\n",
      "Epoch 1752, Loss: 1.8757124319672585, Final Batch Loss: 0.0844602957367897\n",
      "Epoch 1753, Loss: 3.9194419980049133, Final Batch Loss: 2.1157970428466797\n",
      "Epoch 1754, Loss: 2.099150523543358, Final Batch Loss: 0.23754708468914032\n",
      "Epoch 1755, Loss: 2.0084615610539913, Final Batch Loss: 0.019160892814397812\n",
      "Epoch 1756, Loss: 2.3657037913799286, Final Batch Loss: 0.4078654944896698\n",
      "Epoch 1757, Loss: 2.1738302409648895, Final Batch Loss: 0.2566245496273041\n",
      "Epoch 1758, Loss: 1.946838989853859, Final Batch Loss: 0.03656531870365143\n",
      "Epoch 1759, Loss: 3.1113832592964172, Final Batch Loss: 1.327286720275879\n",
      "Epoch 1760, Loss: 1.818265525624156, Final Batch Loss: 0.01538786105811596\n",
      "Epoch 1761, Loss: 3.3190208673477173, Final Batch Loss: 1.4715640544891357\n",
      "Epoch 1762, Loss: 1.8702065823599696, Final Batch Loss: 0.0006179092451930046\n",
      "Epoch 1763, Loss: 1.815807323437184, Final Batch Loss: 0.00655583618208766\n",
      "Epoch 1764, Loss: 3.6220139861106873, Final Batch Loss: 1.8446044921875\n",
      "Epoch 1765, Loss: 1.8629644811153412, Final Batch Loss: 0.04011949896812439\n",
      "Epoch 1766, Loss: 3.493616998195648, Final Batch Loss: 1.7078490257263184\n",
      "Epoch 1767, Loss: 3.630045235157013, Final Batch Loss: 1.7060270309448242\n",
      "Epoch 1768, Loss: 3.0471009612083435, Final Batch Loss: 1.1550641059875488\n",
      "Epoch 1769, Loss: 2.7820934057235718, Final Batch Loss: 0.8273608684539795\n",
      "Epoch 1770, Loss: 1.8525452818721533, Final Batch Loss: 0.011744758114218712\n",
      "Epoch 1771, Loss: 1.9806999564170837, Final Batch Loss: 0.19069939851760864\n",
      "Epoch 1772, Loss: 3.819310486316681, Final Batch Loss: 2.032738208770752\n",
      "Epoch 1773, Loss: 1.8791699595749378, Final Batch Loss: 0.017116326838731766\n",
      "Epoch 1774, Loss: 1.9200679641216993, Final Batch Loss: 0.02699202112853527\n",
      "Epoch 1775, Loss: 3.8312777280807495, Final Batch Loss: 1.9844037294387817\n",
      "Epoch 1776, Loss: 2.0051462948322296, Final Batch Loss: 0.16239574551582336\n",
      "Epoch 1777, Loss: 1.976689025759697, Final Batch Loss: 0.08548848330974579\n",
      "Epoch 1778, Loss: 1.740016575960908, Final Batch Loss: 0.0006040894077159464\n",
      "Epoch 1779, Loss: 3.8734230995178223, Final Batch Loss: 1.9563584327697754\n",
      "Epoch 1780, Loss: 1.9932646974921227, Final Batch Loss: 0.10147067159414291\n",
      "Epoch 1781, Loss: 2.3476330637931824, Final Batch Loss: 0.5436679720878601\n",
      "Epoch 1782, Loss: 1.9442188888788223, Final Batch Loss: 0.14658494293689728\n",
      "Epoch 1783, Loss: 2.8147432804107666, Final Batch Loss: 1.0417165756225586\n",
      "Epoch 1784, Loss: 1.8748239129781723, Final Batch Loss: 0.044109925627708435\n",
      "Epoch 1785, Loss: 1.8876299504190683, Final Batch Loss: 0.005361819639801979\n",
      "Epoch 1786, Loss: 1.8492113155080006, Final Batch Loss: 0.0007183355046436191\n",
      "Epoch 1787, Loss: 1.819314669817686, Final Batch Loss: 0.05554391071200371\n",
      "Epoch 1788, Loss: 1.8214299529790878, Final Batch Loss: 0.028457507491111755\n",
      "Epoch 1789, Loss: 2.3626378774642944, Final Batch Loss: 0.5727227330207825\n",
      "Epoch 1790, Loss: 2.2001753747463226, Final Batch Loss: 0.37312057614326477\n",
      "Epoch 1791, Loss: 1.9431042857468128, Final Batch Loss: 0.01700546219944954\n",
      "Epoch 1792, Loss: 4.815693736076355, Final Batch Loss: 2.8084752559661865\n",
      "Epoch 1793, Loss: 2.042553387582302, Final Batch Loss: 0.0206122025847435\n",
      "Epoch 1794, Loss: 3.0452283024787903, Final Batch Loss: 1.1368993520736694\n",
      "Epoch 1795, Loss: 3.7592297792434692, Final Batch Loss: 1.8901574611663818\n",
      "Epoch 1796, Loss: 1.948853437206708, Final Batch Loss: 0.0015410225605592132\n",
      "Epoch 1797, Loss: 2.022888347506523, Final Batch Loss: 0.14906565845012665\n",
      "Epoch 1798, Loss: 2.0227047204971313, Final Batch Loss: 0.12980163097381592\n",
      "Epoch 1799, Loss: 1.9502517580986023, Final Batch Loss: 0.1314203143119812\n",
      "Epoch 1800, Loss: 2.094097077846527, Final Batch Loss: 0.17107939720153809\n",
      "Epoch 1801, Loss: 2.1238012611865997, Final Batch Loss: 0.22479471564292908\n",
      "Epoch 1802, Loss: 2.008875660598278, Final Batch Loss: 0.08575373142957687\n",
      "Epoch 1803, Loss: 2.148253232240677, Final Batch Loss: 0.257422536611557\n",
      "Epoch 1804, Loss: 2.359038680791855, Final Batch Loss: 0.44152167439460754\n",
      "Epoch 1805, Loss: 1.9044329104945064, Final Batch Loss: 0.004092651419341564\n",
      "Epoch 1806, Loss: 2.585596203804016, Final Batch Loss: 0.6003813743591309\n",
      "Epoch 1807, Loss: 2.0863152742385864, Final Batch Loss: 0.27322089672088623\n",
      "Epoch 1808, Loss: 3.5341427326202393, Final Batch Loss: 1.6315675973892212\n",
      "Epoch 1809, Loss: 2.4888691902160645, Final Batch Loss: 0.7159295678138733\n",
      "Epoch 1810, Loss: 2.127695247530937, Final Batch Loss: 0.18941949307918549\n",
      "Epoch 1811, Loss: 2.1714420914649963, Final Batch Loss: 0.2616822123527527\n",
      "Epoch 1812, Loss: 2.6772449612617493, Final Batch Loss: 0.6553080677986145\n",
      "Epoch 1813, Loss: 2.6533547043800354, Final Batch Loss: 0.717621922492981\n",
      "Epoch 1814, Loss: 4.613828718662262, Final Batch Loss: 2.6807260513305664\n",
      "Epoch 1815, Loss: 1.9893423058092594, Final Batch Loss: 0.009703610092401505\n",
      "Epoch 1816, Loss: 1.8246318169403821, Final Batch Loss: 0.0003251500893384218\n",
      "Epoch 1817, Loss: 3.177605092525482, Final Batch Loss: 1.3899266719818115\n",
      "Epoch 1818, Loss: 1.904088331386447, Final Batch Loss: 0.009139133617281914\n",
      "Epoch 1819, Loss: 1.9724707566201687, Final Batch Loss: 0.02762502059340477\n",
      "Epoch 1820, Loss: 2.416456460952759, Final Batch Loss: 0.5421954393386841\n",
      "Epoch 1821, Loss: 1.9326855912804604, Final Batch Loss: 0.019371725618839264\n",
      "Epoch 1822, Loss: 4.46544349193573, Final Batch Loss: 2.5687217712402344\n",
      "Epoch 1823, Loss: 3.108003556728363, Final Batch Loss: 1.2741056680679321\n",
      "Epoch 1824, Loss: 2.1084382385015488, Final Batch Loss: 0.2415236085653305\n",
      "Epoch 1825, Loss: 1.990501955151558, Final Batch Loss: 0.1820479780435562\n",
      "Epoch 1826, Loss: 2.8353907465934753, Final Batch Loss: 0.9869850873947144\n",
      "Epoch 1827, Loss: 4.6801846623420715, Final Batch Loss: 2.8587191104888916\n",
      "Epoch 1828, Loss: 2.0107277184724808, Final Batch Loss: 0.19539429247379303\n",
      "Epoch 1829, Loss: 2.1971003115177155, Final Batch Loss: 0.36378538608551025\n",
      "Epoch 1830, Loss: 3.0481634736061096, Final Batch Loss: 1.2789714336395264\n",
      "Epoch 1831, Loss: 3.1977524161338806, Final Batch Loss: 1.36971116065979\n",
      "Epoch 1832, Loss: 1.8362198476679623, Final Batch Loss: 0.004805088508874178\n",
      "Epoch 1833, Loss: 2.2709344923496246, Final Batch Loss: 0.4076854884624481\n",
      "Epoch 1834, Loss: 1.9726225584745407, Final Batch Loss: 0.10908029973506927\n",
      "Epoch 1835, Loss: 1.7885624952614307, Final Batch Loss: 0.006290990859270096\n",
      "Epoch 1836, Loss: 2.043039843440056, Final Batch Loss: 0.10493002831935883\n",
      "Epoch 1837, Loss: 2.949208378791809, Final Batch Loss: 1.1423554420471191\n",
      "Epoch 1838, Loss: 1.9060712307691574, Final Batch Loss: 0.12553320825099945\n",
      "Epoch 1839, Loss: 7.124098896980286, Final Batch Loss: 5.219687461853027\n",
      "Epoch 1840, Loss: 1.866980497725308, Final Batch Loss: 0.01197094190865755\n",
      "Epoch 1841, Loss: 2.024551944807172, Final Batch Loss: 0.029240446165204048\n",
      "Epoch 1842, Loss: 2.2002715431153774, Final Batch Loss: 0.026020105928182602\n",
      "Epoch 1843, Loss: 2.0777815070468932, Final Batch Loss: 0.0033072319347411394\n",
      "Epoch 1844, Loss: 4.699550747871399, Final Batch Loss: 2.787639617919922\n",
      "Epoch 1845, Loss: 1.990996040403843, Final Batch Loss: 0.09357843548059464\n",
      "Epoch 1846, Loss: 2.096324384212494, Final Batch Loss: 0.2790812849998474\n",
      "Epoch 1847, Loss: 2.6412322521209717, Final Batch Loss: 0.7650312781333923\n",
      "Epoch 1848, Loss: 1.880789989605546, Final Batch Loss: 0.00468098558485508\n",
      "Epoch 1849, Loss: 1.9121325239539146, Final Batch Loss: 0.03779568523168564\n",
      "Epoch 1850, Loss: 1.9630677290260792, Final Batch Loss: 0.046784598380327225\n",
      "Epoch 1851, Loss: 1.9450565427541733, Final Batch Loss: 0.1127115935087204\n",
      "Epoch 1852, Loss: 4.069204926490784, Final Batch Loss: 2.225449562072754\n",
      "Epoch 1853, Loss: 2.2861518263816833, Final Batch Loss: 0.4561777710914612\n",
      "Epoch 1854, Loss: 3.2660516500473022, Final Batch Loss: 1.4692792892456055\n",
      "Epoch 1855, Loss: 3.854159116744995, Final Batch Loss: 1.9992923736572266\n",
      "Epoch 1856, Loss: 2.020986244082451, Final Batch Loss: 0.23544935882091522\n",
      "Epoch 1857, Loss: 1.9229687247425318, Final Batch Loss: 0.020171621814370155\n",
      "Epoch 1858, Loss: 1.792195340822218, Final Batch Loss: 0.00044383687782101333\n",
      "Epoch 1859, Loss: 1.8651250153779984, Final Batch Loss: 0.09213365614414215\n",
      "Epoch 1860, Loss: 1.930665023624897, Final Batch Loss: 0.10810477286577225\n",
      "Epoch 1861, Loss: 3.4694878458976746, Final Batch Loss: 1.7045611143112183\n",
      "Epoch 1862, Loss: 2.9352978467941284, Final Batch Loss: 1.1669189929962158\n",
      "Epoch 1863, Loss: 1.9601661413908005, Final Batch Loss: 0.10848794877529144\n",
      "Epoch 1864, Loss: 2.000554636120796, Final Batch Loss: 0.15683354437351227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1865, Loss: 1.8421402883250266, Final Batch Loss: 0.0005436849314719439\n",
      "Epoch 1866, Loss: 2.58365136384964, Final Batch Loss: 0.6452358365058899\n",
      "Epoch 1867, Loss: 2.4876479506492615, Final Batch Loss: 0.6388497352600098\n",
      "Epoch 1868, Loss: 1.9527976512908936, Final Batch Loss: 0.027675926685333252\n",
      "Epoch 1869, Loss: 1.964051604270935, Final Batch Loss: 0.14974355697631836\n",
      "Epoch 1870, Loss: 3.3567687273025513, Final Batch Loss: 1.4264709949493408\n",
      "Epoch 1871, Loss: 3.90496027469635, Final Batch Loss: 2.0442028045654297\n",
      "Epoch 1872, Loss: 1.8465920984745026, Final Batch Loss: 0.03120020031929016\n",
      "Epoch 1873, Loss: 1.8302857428789139, Final Batch Loss: 0.023173466324806213\n",
      "Epoch 1874, Loss: 1.840662496164441, Final Batch Loss: 0.02578081376850605\n",
      "Epoch 1875, Loss: 3.616907298564911, Final Batch Loss: 1.8138617277145386\n",
      "Epoch 1876, Loss: 1.7923331577330828, Final Batch Loss: 0.001841636374592781\n",
      "Epoch 1877, Loss: 1.7896564677357674, Final Batch Loss: 0.03923649340867996\n",
      "Epoch 1878, Loss: 1.8429320491850376, Final Batch Loss: 0.03870118036866188\n",
      "Epoch 1879, Loss: 1.7959747544955462, Final Batch Loss: 0.0011245838832110167\n",
      "Epoch 1880, Loss: 1.7789303646422923, Final Batch Loss: 0.0020425901748239994\n",
      "Epoch 1881, Loss: 1.8409858923405409, Final Batch Loss: 0.02403259091079235\n",
      "Epoch 1882, Loss: 2.4006203413009644, Final Batch Loss: 0.6150738596916199\n",
      "Epoch 1883, Loss: 2.5755547285079956, Final Batch Loss: 0.748712956905365\n",
      "Epoch 1884, Loss: 3.543895900249481, Final Batch Loss: 1.7309561967849731\n",
      "Epoch 1885, Loss: 3.764559745788574, Final Batch Loss: 2.0047032833099365\n",
      "Epoch 1886, Loss: 1.788882466033101, Final Batch Loss: 0.0010045487433671951\n",
      "Epoch 1887, Loss: 3.766753613948822, Final Batch Loss: 2.0178611278533936\n",
      "Epoch 1888, Loss: 3.876098394393921, Final Batch Loss: 2.0479462146759033\n",
      "Epoch 1889, Loss: 2.9908589124679565, Final Batch Loss: 1.0693355798721313\n",
      "Epoch 1890, Loss: 1.9383947160094976, Final Batch Loss: 0.004500379785895348\n",
      "Epoch 1891, Loss: 1.9400909021496773, Final Batch Loss: 0.03296685963869095\n",
      "Epoch 1892, Loss: 2.860792636871338, Final Batch Loss: 1.0603816509246826\n",
      "Epoch 1893, Loss: 2.4953532218933105, Final Batch Loss: 0.6128374338150024\n",
      "Epoch 1894, Loss: 3.6345880031585693, Final Batch Loss: 1.6882123947143555\n",
      "Epoch 1895, Loss: 4.040377974510193, Final Batch Loss: 2.088632106781006\n",
      "Epoch 1896, Loss: 2.1208309531211853, Final Batch Loss: 0.20401346683502197\n",
      "Epoch 1897, Loss: 2.082098864018917, Final Batch Loss: 0.09254636615514755\n",
      "Epoch 1898, Loss: 1.9717731103301048, Final Batch Loss: 0.026993297040462494\n",
      "Epoch 1899, Loss: 1.876739501592965, Final Batch Loss: 2.682172998902388e-05\n",
      "Epoch 1900, Loss: 2.512558400630951, Final Batch Loss: 0.6842494010925293\n",
      "Epoch 1901, Loss: 1.8614940918050706, Final Batch Loss: 0.005736080463975668\n",
      "Epoch 1902, Loss: 3.3164348006248474, Final Batch Loss: 1.4880008697509766\n",
      "Epoch 1903, Loss: 1.7783211283385754, Final Batch Loss: 0.021882515400648117\n",
      "Epoch 1904, Loss: 1.8358733609202318, Final Batch Loss: 9.464769391342998e-05\n",
      "Epoch 1905, Loss: 1.9100105557590723, Final Batch Loss: 0.03011820651590824\n",
      "Epoch 1906, Loss: 3.1151286959648132, Final Batch Loss: 1.351694107055664\n",
      "Epoch 1907, Loss: 2.332506388425827, Final Batch Loss: 0.4567025601863861\n",
      "Epoch 1908, Loss: 3.83340984582901, Final Batch Loss: 2.0155234336853027\n",
      "Epoch 1909, Loss: 2.966025650501251, Final Batch Loss: 1.114161491394043\n",
      "Epoch 1910, Loss: 1.792242193594575, Final Batch Loss: 0.02436014451086521\n",
      "Epoch 1911, Loss: 1.8558845296502113, Final Batch Loss: 0.04115549474954605\n",
      "Epoch 1912, Loss: 2.0039209127426147, Final Batch Loss: 0.1653394103050232\n",
      "Epoch 1913, Loss: 1.8164276741445065, Final Batch Loss: 0.007480349391698837\n",
      "Epoch 1914, Loss: 2.8742157220840454, Final Batch Loss: 1.088180661201477\n",
      "Epoch 1915, Loss: 1.9247671961784363, Final Batch Loss: 0.18321436643600464\n",
      "Epoch 1916, Loss: 3.0110278129577637, Final Batch Loss: 1.2538541555404663\n",
      "Epoch 1917, Loss: 1.855858557857573, Final Batch Loss: 0.006562941707670689\n",
      "Epoch 1918, Loss: 2.225724369287491, Final Batch Loss: 0.37714114785194397\n",
      "Epoch 1919, Loss: 1.910009078681469, Final Batch Loss: 0.11336296051740646\n",
      "Epoch 1920, Loss: 1.8567462409846485, Final Batch Loss: 0.006663128267973661\n",
      "Epoch 1921, Loss: 1.8173548690974712, Final Batch Loss: 0.045870911329984665\n",
      "Epoch 1922, Loss: 1.9416365921497345, Final Batch Loss: 0.15596452355384827\n",
      "Epoch 1923, Loss: 1.7921806453814497, Final Batch Loss: 0.00015496007108595222\n",
      "Epoch 1924, Loss: 2.289204955101013, Final Batch Loss: 0.532526433467865\n",
      "Epoch 1925, Loss: 3.774947464466095, Final Batch Loss: 2.018392562866211\n",
      "Epoch 1926, Loss: 1.7757285684347153, Final Batch Loss: 0.010916158556938171\n",
      "Epoch 1927, Loss: 1.783945757895708, Final Batch Loss: 0.018499691039323807\n",
      "Epoch 1928, Loss: 2.02741876244545, Final Batch Loss: 0.1857503354549408\n",
      "Epoch 1929, Loss: 3.499850571155548, Final Batch Loss: 1.6320915222167969\n",
      "Epoch 1930, Loss: 1.7898636609315872, Final Batch Loss: 0.04439254105091095\n",
      "Epoch 1931, Loss: 1.7703530918806791, Final Batch Loss: 0.027438653632998466\n",
      "Epoch 1932, Loss: 2.3248290419578552, Final Batch Loss: 0.5695846676826477\n",
      "Epoch 1933, Loss: 3.37980717420578, Final Batch Loss: 1.581703782081604\n",
      "Epoch 1934, Loss: 2.9780850410461426, Final Batch Loss: 1.1970932483673096\n",
      "Epoch 1935, Loss: 1.7911416189745069, Final Batch Loss: 0.01248567271977663\n",
      "Epoch 1936, Loss: 3.2647594809532166, Final Batch Loss: 1.4543912410736084\n",
      "Epoch 1937, Loss: 1.8624796569347382, Final Batch Loss: 0.10035917162895203\n",
      "Epoch 1938, Loss: 2.1241959929466248, Final Batch Loss: 0.37979477643966675\n",
      "Epoch 1939, Loss: 3.336081087589264, Final Batch Loss: 1.5417335033416748\n",
      "Epoch 1940, Loss: 1.8083582147955894, Final Batch Loss: 0.07268901914358139\n",
      "Epoch 1941, Loss: 1.9106497317552567, Final Batch Loss: 0.15715928375720978\n",
      "Epoch 1942, Loss: 2.236344635486603, Final Batch Loss: 0.4321393370628357\n",
      "Epoch 1943, Loss: 1.7336525451391935, Final Batch Loss: 0.01967228762805462\n",
      "Epoch 1944, Loss: 2.7550770044326782, Final Batch Loss: 0.9847894906997681\n",
      "Epoch 1945, Loss: 1.7946182526648045, Final Batch Loss: 0.015674952417612076\n",
      "Epoch 1946, Loss: 1.8019298762083054, Final Batch Loss: 0.06537853181362152\n",
      "Epoch 1947, Loss: 3.3854541778564453, Final Batch Loss: 1.6425631046295166\n",
      "Epoch 1948, Loss: 1.8041087165474892, Final Batch Loss: 0.04441431909799576\n",
      "Epoch 1949, Loss: 1.8833306804299355, Final Batch Loss: 0.11902955919504166\n",
      "Epoch 1950, Loss: 1.9318862408399582, Final Batch Loss: 0.14685402810573578\n",
      "Epoch 1951, Loss: 1.86361625790596, Final Batch Loss: 0.11196419596672058\n",
      "Epoch 1952, Loss: 2.2787631154060364, Final Batch Loss: 0.414972186088562\n",
      "Epoch 1953, Loss: 1.8009922951459885, Final Batch Loss: 0.0676560252904892\n",
      "Epoch 1954, Loss: 1.866267628967762, Final Batch Loss: 0.11604148894548416\n",
      "Epoch 1955, Loss: 1.9352558851242065, Final Batch Loss: 0.07495325803756714\n",
      "Epoch 1956, Loss: 1.7837256231578067, Final Batch Loss: 0.001420561340637505\n",
      "Epoch 1957, Loss: 1.9069093614816666, Final Batch Loss: 0.12960006296634674\n",
      "Epoch 1958, Loss: 1.864733531489037, Final Batch Loss: 0.0008285188814625144\n",
      "Epoch 1959, Loss: 1.7557136560499202, Final Batch Loss: 0.0004577780782710761\n",
      "Epoch 1960, Loss: 2.0067699551582336, Final Batch Loss: 0.2878801226615906\n",
      "Epoch 1961, Loss: 1.8547140546143055, Final Batch Loss: 0.053596872836351395\n",
      "Epoch 1962, Loss: 1.7845520512200892, Final Batch Loss: 0.0035987631417810917\n",
      "Epoch 1963, Loss: 4.255525529384613, Final Batch Loss: 2.4621798992156982\n",
      "Epoch 1964, Loss: 1.7846833802759647, Final Batch Loss: 0.05117848888039589\n",
      "Epoch 1965, Loss: 1.8213150948286057, Final Batch Loss: 0.1594281643629074\n",
      "Epoch 1966, Loss: 3.5531551241874695, Final Batch Loss: 1.8520221710205078\n",
      "Epoch 1967, Loss: 1.7705887857009657, Final Batch Loss: 0.00042215018766000867\n",
      "Epoch 1968, Loss: 1.8625298738479614, Final Batch Loss: 0.028826236724853516\n",
      "Epoch 1969, Loss: 1.9175004251301289, Final Batch Loss: 0.043988097459077835\n",
      "Epoch 1970, Loss: 3.7471814155578613, Final Batch Loss: 1.9652032852172852\n",
      "Epoch 1971, Loss: 2.148611456155777, Final Batch Loss: 0.31988027691841125\n",
      "Epoch 1972, Loss: 3.433313548564911, Final Batch Loss: 1.6271367073059082\n",
      "Epoch 1973, Loss: 2.891983985900879, Final Batch Loss: 1.1635843515396118\n",
      "Epoch 1974, Loss: 2.7257325053215027, Final Batch Loss: 0.8286094665527344\n",
      "Epoch 1975, Loss: 3.998487412929535, Final Batch Loss: 1.8963510990142822\n",
      "Epoch 1976, Loss: 4.391250431537628, Final Batch Loss: 2.223675489425659\n",
      "Epoch 1977, Loss: 2.4186010360717773, Final Batch Loss: 0.2347368597984314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1978, Loss: 2.5826477706432343, Final Batch Loss: 0.23093941807746887\n",
      "Epoch 1979, Loss: 3.252385914325714, Final Batch Loss: 1.1264772415161133\n",
      "Epoch 1980, Loss: 2.1845047175884247, Final Batch Loss: 0.06520745158195496\n",
      "Epoch 1981, Loss: 3.516054391860962, Final Batch Loss: 1.4017550945281982\n",
      "Epoch 1982, Loss: 2.0589374974370003, Final Batch Loss: 0.025627799332141876\n",
      "Epoch 1983, Loss: 3.137660503387451, Final Batch Loss: 1.2425905466079712\n",
      "Epoch 1984, Loss: 2.6662092804908752, Final Batch Loss: 0.7523065209388733\n",
      "Epoch 1985, Loss: 2.0911161303520203, Final Batch Loss: 0.19143009185791016\n",
      "Epoch 1986, Loss: 2.07183775305748, Final Batch Loss: 0.15450003743171692\n",
      "Epoch 1987, Loss: 1.7848823815293144, Final Batch Loss: 0.00029905137489549816\n",
      "Epoch 1988, Loss: 2.0371237695217133, Final Batch Loss: 0.16147717833518982\n",
      "Epoch 1989, Loss: 2.874236583709717, Final Batch Loss: 1.0705454349517822\n",
      "Epoch 1990, Loss: 1.8334000781178474, Final Batch Loss: 0.09769565612077713\n",
      "Epoch 1991, Loss: 2.4001097679138184, Final Batch Loss: 0.5761460661888123\n",
      "Epoch 1992, Loss: 1.8747189044952393, Final Batch Loss: 0.003873109817504883\n",
      "Epoch 1993, Loss: 2.476075232028961, Final Batch Loss: 0.6351933479309082\n",
      "Epoch 1994, Loss: 1.7973222031723708, Final Batch Loss: 0.0027646913658827543\n",
      "Epoch 1995, Loss: 1.8193778498098254, Final Batch Loss: 0.012677083723247051\n",
      "Epoch 1996, Loss: 3.0229786038398743, Final Batch Loss: 1.2280468940734863\n",
      "Epoch 1997, Loss: 1.87858728133142, Final Batch Loss: 0.020819460973143578\n",
      "Epoch 1998, Loss: 1.87324208766222, Final Batch Loss: 0.11392147094011307\n",
      "Epoch 1999, Loss: 2.2696459889411926, Final Batch Loss: 0.48906177282333374\n",
      "Epoch 2000, Loss: 2.9667640924453735, Final Batch Loss: 1.195068120956421\n",
      "Epoch 2001, Loss: 1.9295743256807327, Final Batch Loss: 0.16775120794773102\n",
      "Epoch 2002, Loss: 2.9081801772117615, Final Batch Loss: 0.9602962732315063\n",
      "Epoch 2003, Loss: 3.5604058504104614, Final Batch Loss: 1.6162141561508179\n",
      "Epoch 2004, Loss: 1.894686993706273, Final Batch Loss: 0.00035446559195406735\n",
      "Epoch 2005, Loss: 2.6195988059043884, Final Batch Loss: 0.7347764372825623\n",
      "Epoch 2006, Loss: 3.5814200043678284, Final Batch Loss: 1.729610800743103\n",
      "Epoch 2007, Loss: 1.930686742067337, Final Batch Loss: 0.03074541687965393\n",
      "Epoch 2008, Loss: 1.8754888400435448, Final Batch Loss: 0.11287697404623032\n",
      "Epoch 2009, Loss: 1.7683508979134785, Final Batch Loss: 5.113947918289341e-05\n",
      "Epoch 2010, Loss: 1.7812582226470113, Final Batch Loss: 0.006732163019478321\n",
      "Epoch 2011, Loss: 1.8480460201390088, Final Batch Loss: 0.006613746751099825\n",
      "Epoch 2012, Loss: 1.8361739926040173, Final Batch Loss: 0.057338815182447433\n",
      "Epoch 2013, Loss: 2.0112600922584534, Final Batch Loss: 0.227749764919281\n",
      "Epoch 2014, Loss: 1.7937894091010094, Final Batch Loss: 0.05959030240774155\n",
      "Epoch 2015, Loss: 3.0962148308753967, Final Batch Loss: 1.3618860244750977\n",
      "Epoch 2016, Loss: 3.1723247170448303, Final Batch Loss: 1.4401066303253174\n",
      "Epoch 2017, Loss: 1.915506437420845, Final Batch Loss: 0.08955831825733185\n",
      "Epoch 2018, Loss: 1.9393914751708508, Final Batch Loss: 0.023294012993574142\n",
      "Epoch 2019, Loss: 5.042500376701355, Final Batch Loss: 3.2320990562438965\n",
      "Epoch 2020, Loss: 3.0196688175201416, Final Batch Loss: 1.2213335037231445\n",
      "Epoch 2021, Loss: 1.8456800282001495, Final Batch Loss: 0.15534523129463196\n",
      "Epoch 2022, Loss: 1.7866767086088657, Final Batch Loss: 0.015227142721414566\n",
      "Epoch 2023, Loss: 1.857799917459488, Final Batch Loss: 0.08744928240776062\n",
      "Epoch 2024, Loss: 1.8487127653206699, Final Batch Loss: 0.00027056847466155887\n",
      "Epoch 2025, Loss: 1.9164631813764572, Final Batch Loss: 0.15316085517406464\n",
      "Epoch 2026, Loss: 1.810001790523529, Final Batch Loss: 0.07649374008178711\n",
      "Epoch 2027, Loss: 1.9877173602581024, Final Batch Loss: 0.26751908659935\n",
      "Epoch 2028, Loss: 1.7968054227530956, Final Batch Loss: 0.008355777710676193\n",
      "Epoch 2029, Loss: 2.8681508898735046, Final Batch Loss: 1.1751008033752441\n",
      "Epoch 2030, Loss: 1.720537172834156, Final Batch Loss: 0.00016020445036701858\n",
      "Epoch 2031, Loss: 4.218274116516113, Final Batch Loss: 2.490983009338379\n",
      "Epoch 2032, Loss: 1.748171728104353, Final Batch Loss: 0.01745353266596794\n",
      "Epoch 2033, Loss: 2.073862001299858, Final Batch Loss: 0.19739292562007904\n",
      "Epoch 2034, Loss: 4.180624306201935, Final Batch Loss: 2.3390321731567383\n",
      "Epoch 2035, Loss: 1.864512120373547, Final Batch Loss: 0.007423435337841511\n",
      "Epoch 2036, Loss: 4.0601338148117065, Final Batch Loss: 2.2043838500976562\n",
      "Epoch 2037, Loss: 1.7487029605545104, Final Batch Loss: 0.00700600678101182\n",
      "Epoch 2038, Loss: 2.4911133646965027, Final Batch Loss: 0.6842882633209229\n",
      "Epoch 2039, Loss: 1.796894394326955, Final Batch Loss: 0.002172373700886965\n",
      "Epoch 2040, Loss: 2.359007179737091, Final Batch Loss: 0.6107190251350403\n",
      "Epoch 2041, Loss: 1.786869503557682, Final Batch Loss: 0.05915645509958267\n",
      "Epoch 2042, Loss: 2.5747668147087097, Final Batch Loss: 0.8434448838233948\n",
      "Epoch 2043, Loss: 1.832481300458312, Final Batch Loss: 0.010081207379698753\n",
      "Epoch 2044, Loss: 3.7358880639076233, Final Batch Loss: 2.0102500915527344\n",
      "Epoch 2045, Loss: 3.505159556865692, Final Batch Loss: 1.7839546203613281\n",
      "Epoch 2046, Loss: 1.734876375645399, Final Batch Loss: 0.0348999910056591\n",
      "Epoch 2047, Loss: 2.8230689764022827, Final Batch Loss: 1.0523464679718018\n",
      "Epoch 2048, Loss: 1.78415137526963, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 2049, Loss: 2.0175265669822693, Final Batch Loss: 0.20097768306732178\n",
      "Epoch 2050, Loss: 3.433000087738037, Final Batch Loss: 1.4764610528945923\n",
      "Epoch 2051, Loss: 2.0631901621818542, Final Batch Loss: 0.06982606649398804\n",
      "Epoch 2052, Loss: 2.558776557445526, Final Batch Loss: 0.6625899076461792\n",
      "Epoch 2053, Loss: 2.395104944705963, Final Batch Loss: 0.591217577457428\n",
      "Epoch 2054, Loss: 3.4486365914344788, Final Batch Loss: 1.5334177017211914\n",
      "Epoch 2055, Loss: 9.903279900550842, Final Batch Loss: 8.087932586669922\n",
      "Epoch 2056, Loss: 1.8596605393686332, Final Batch Loss: 0.00023016665363684297\n",
      "Epoch 2057, Loss: 1.9625868664006703, Final Batch Loss: 0.000514851592015475\n",
      "Epoch 2058, Loss: 2.1495764702558517, Final Batch Loss: 0.14222155511379242\n",
      "Epoch 2059, Loss: 3.3681966066360474, Final Batch Loss: 1.3174642324447632\n",
      "Epoch 2060, Loss: 3.344054639339447, Final Batch Loss: 1.4117083549499512\n",
      "Epoch 2061, Loss: 2.11314844340086, Final Batch Loss: 0.08824556320905685\n",
      "Epoch 2062, Loss: 2.2962407171726227, Final Batch Loss: 0.37875983119010925\n",
      "Epoch 2063, Loss: 2.4337376952171326, Final Batch Loss: 0.4434976577758789\n",
      "Epoch 2064, Loss: 2.0644355714321136, Final Batch Loss: 0.18036535382270813\n",
      "Epoch 2065, Loss: 1.9171571396291256, Final Batch Loss: 0.022113647311925888\n",
      "Epoch 2066, Loss: 2.4862003326416016, Final Batch Loss: 0.5956764817237854\n",
      "Epoch 2067, Loss: 3.351350784301758, Final Batch Loss: 1.4944312572479248\n",
      "Epoch 2068, Loss: 1.7949816267937422, Final Batch Loss: 0.016802219673991203\n",
      "Epoch 2069, Loss: 3.4338038563728333, Final Batch Loss: 1.6382811069488525\n",
      "Epoch 2070, Loss: 2.3029677271842957, Final Batch Loss: 0.5083664059638977\n",
      "Epoch 2071, Loss: 2.8237037658691406, Final Batch Loss: 1.040909767150879\n",
      "Epoch 2072, Loss: 2.3423407077789307, Final Batch Loss: 0.5979518294334412\n",
      "Epoch 2073, Loss: 4.017439603805542, Final Batch Loss: 2.1835546493530273\n",
      "Epoch 2074, Loss: 1.946295976638794, Final Batch Loss: 0.06545859575271606\n",
      "Epoch 2075, Loss: 1.8590813875198364, Final Batch Loss: 0.04139971733093262\n",
      "Epoch 2076, Loss: 2.7946595549583435, Final Batch Loss: 1.011223554611206\n",
      "Epoch 2077, Loss: 3.939201593399048, Final Batch Loss: 2.0829100608825684\n",
      "Epoch 2078, Loss: 2.360154449939728, Final Batch Loss: 0.5053001046180725\n",
      "Epoch 2079, Loss: 1.9247771371155977, Final Batch Loss: 0.007276343181729317\n",
      "Epoch 2080, Loss: 2.304997533559799, Final Batch Loss: 0.24967166781425476\n",
      "Epoch 2081, Loss: 2.202147616073489, Final Batch Loss: 0.014391554519534111\n",
      "Epoch 2082, Loss: 2.0397770926938392, Final Batch Loss: 0.00012158608296886086\n",
      "Epoch 2083, Loss: 3.6151406168937683, Final Batch Loss: 1.5864589214324951\n",
      "Epoch 2084, Loss: 2.8862740993499756, Final Batch Loss: 1.0058906078338623\n",
      "Epoch 2085, Loss: 2.104521870613098, Final Batch Loss: 0.2816516160964966\n",
      "Epoch 2086, Loss: 2.571855843067169, Final Batch Loss: 0.7999151349067688\n",
      "Epoch 2087, Loss: 1.841293528676033, Final Batch Loss: 0.026331797242164612\n",
      "Epoch 2088, Loss: 2.0150010101497173, Final Batch Loss: 0.03145171329379082\n",
      "Epoch 2089, Loss: 1.952699389308691, Final Batch Loss: 0.03839423879981041\n",
      "Epoch 2090, Loss: 1.9980688905343413, Final Batch Loss: 0.011499903164803982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2091, Loss: 1.9292776584625244, Final Batch Loss: 0.13729476928710938\n",
      "Epoch 2092, Loss: 3.9388078451156616, Final Batch Loss: 2.0849287509918213\n",
      "Epoch 2093, Loss: 1.786829048767686, Final Batch Loss: 0.019119376316666603\n",
      "Epoch 2094, Loss: 1.9732818901538849, Final Batch Loss: 0.2291572391986847\n",
      "Epoch 2095, Loss: 1.8174297084042337, Final Batch Loss: 0.00016091958968900144\n",
      "Epoch 2096, Loss: 1.935812659561634, Final Batch Loss: 0.04431910067796707\n",
      "Epoch 2097, Loss: 2.1215444803237915, Final Batch Loss: 0.3155500888824463\n",
      "Epoch 2098, Loss: 3.3304765224456787, Final Batch Loss: 1.5901437997817993\n",
      "Epoch 2099, Loss: 2.1401721239089966, Final Batch Loss: 0.29665589332580566\n",
      "Epoch 2100, Loss: 1.80472756549716, Final Batch Loss: 0.017144333571195602\n",
      "Epoch 2101, Loss: 3.6245598196983337, Final Batch Loss: 1.8313275575637817\n",
      "Epoch 2102, Loss: 2.25165718793869, Final Batch Loss: 0.3980224132537842\n",
      "Epoch 2103, Loss: 2.2039476335048676, Final Batch Loss: 0.48071256279945374\n",
      "Epoch 2104, Loss: 1.8872581273317337, Final Batch Loss: 0.17022879421710968\n",
      "Epoch 2105, Loss: 1.907022550702095, Final Batch Loss: 0.13747359812259674\n",
      "Epoch 2106, Loss: 1.7999444678425789, Final Batch Loss: 0.06038404256105423\n",
      "Epoch 2107, Loss: 3.7068870067596436, Final Batch Loss: 1.9110853672027588\n",
      "Epoch 2108, Loss: 2.67990243434906, Final Batch Loss: 1.0033082962036133\n",
      "Epoch 2109, Loss: 2.2412169277668, Final Batch Loss: 0.4610896408557892\n",
      "Epoch 2110, Loss: 2.3299837708473206, Final Batch Loss: 0.6606963872909546\n",
      "Epoch 2111, Loss: 2.2693803310394287, Final Batch Loss: 0.5308687686920166\n",
      "Epoch 2112, Loss: 1.9396836012601852, Final Batch Loss: 0.2060895413160324\n",
      "Epoch 2113, Loss: 2.7766138911247253, Final Batch Loss: 1.0476850271224976\n",
      "Epoch 2114, Loss: 2.3656797409057617, Final Batch Loss: 0.628330647945404\n",
      "Epoch 2115, Loss: 2.6453417539596558, Final Batch Loss: 0.8641572594642639\n",
      "Epoch 2116, Loss: 1.7416784289525822, Final Batch Loss: 0.0011342290090397\n",
      "Epoch 2117, Loss: 1.69564613327384, Final Batch Loss: 0.034086909145116806\n",
      "Epoch 2118, Loss: 3.0243287086486816, Final Batch Loss: 1.2812799215316772\n",
      "Epoch 2119, Loss: 1.6938673071563244, Final Batch Loss: 0.03495029732584953\n",
      "Epoch 2120, Loss: 2.3864059448242188, Final Batch Loss: 0.6163442730903625\n",
      "Epoch 2121, Loss: 1.7624669969081879, Final Batch Loss: 0.0414300262928009\n",
      "Epoch 2122, Loss: 2.058177202939987, Final Batch Loss: 0.3289788067340851\n",
      "Epoch 2123, Loss: 3.4800831079483032, Final Batch Loss: 1.7237025499343872\n",
      "Epoch 2124, Loss: 3.483625590801239, Final Batch Loss: 1.8155980110168457\n",
      "Epoch 2125, Loss: 2.0372455716133118, Final Batch Loss: 0.3112073540687561\n",
      "Epoch 2126, Loss: 1.7624128125607967, Final Batch Loss: 0.030703570693731308\n",
      "Epoch 2127, Loss: 1.790851429104805, Final Batch Loss: 0.03667403757572174\n",
      "Epoch 2128, Loss: 1.7414044700562954, Final Batch Loss: 0.011665817350149155\n",
      "Epoch 2129, Loss: 1.8157642388250679, Final Batch Loss: 0.0020172500517219305\n",
      "Epoch 2130, Loss: 2.147742062807083, Final Batch Loss: 0.3976888954639435\n",
      "Epoch 2131, Loss: 2.087900459766388, Final Batch Loss: 0.3506978154182434\n",
      "Epoch 2132, Loss: 3.7760415077209473, Final Batch Loss: 1.999800205230713\n",
      "Epoch 2133, Loss: 1.8276198729872704, Final Batch Loss: 0.10177382081747055\n",
      "Epoch 2134, Loss: 2.5866532921791077, Final Batch Loss: 0.8812704086303711\n",
      "Epoch 2135, Loss: 2.1062515676021576, Final Batch Loss: 0.32433202862739563\n",
      "Epoch 2136, Loss: 1.8070649090223014, Final Batch Loss: 0.0022286358289420605\n",
      "Epoch 2137, Loss: 1.7515887431800365, Final Batch Loss: 0.03147689625620842\n",
      "Epoch 2138, Loss: 1.787229523062706, Final Batch Loss: 0.05753128230571747\n",
      "Epoch 2139, Loss: 1.664597349241376, Final Batch Loss: 0.013054030016064644\n",
      "Epoch 2140, Loss: 1.7834166476968676, Final Batch Loss: 0.0018160531762987375\n",
      "Epoch 2141, Loss: 3.684690535068512, Final Batch Loss: 1.9786930084228516\n",
      "Epoch 2142, Loss: 1.7100079376250505, Final Batch Loss: 0.012515457347035408\n",
      "Epoch 2143, Loss: 3.5322256088256836, Final Batch Loss: 1.7950716018676758\n",
      "Epoch 2144, Loss: 1.8847039937973022, Final Batch Loss: 0.2750862240791321\n",
      "Epoch 2145, Loss: 3.1348817944526672, Final Batch Loss: 1.4025952816009521\n",
      "Epoch 2146, Loss: 1.6859613059932599, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 2147, Loss: 1.943735733628273, Final Batch Loss: 0.15728773176670074\n",
      "Epoch 2148, Loss: 1.775153011083603, Final Batch Loss: 0.028096407651901245\n",
      "Epoch 2149, Loss: 1.6579426832031459, Final Batch Loss: 0.0014842457603663206\n",
      "Epoch 2150, Loss: 2.931518852710724, Final Batch Loss: 1.2958645820617676\n",
      "Epoch 2151, Loss: 1.7173289712518454, Final Batch Loss: 0.011397724971175194\n",
      "Epoch 2152, Loss: 2.0700261890888214, Final Batch Loss: 0.46310368180274963\n",
      "Epoch 2153, Loss: 1.7578368782997131, Final Batch Loss: 0.06498807668685913\n",
      "Epoch 2154, Loss: 1.6717634424567223, Final Batch Loss: 0.02157130092382431\n",
      "Epoch 2155, Loss: 2.8009387254714966, Final Batch Loss: 1.1555137634277344\n",
      "Epoch 2156, Loss: 1.663614097982645, Final Batch Loss: 0.05984971299767494\n",
      "Epoch 2157, Loss: 1.7797981351613998, Final Batch Loss: 0.09378890693187714\n",
      "Epoch 2158, Loss: 1.6575690917670727, Final Batch Loss: 0.004187624901533127\n",
      "Epoch 2159, Loss: 5.51274710893631, Final Batch Loss: 3.7754974365234375\n",
      "Epoch 2160, Loss: 3.539540946483612, Final Batch Loss: 1.8529036045074463\n",
      "Epoch 2161, Loss: 2.12429715692997, Final Batch Loss: 0.19872482120990753\n",
      "Epoch 2162, Loss: 3.2303269505500793, Final Batch Loss: 1.0889159440994263\n",
      "Epoch 2163, Loss: 2.2860770523548126, Final Batch Loss: 0.1393381655216217\n",
      "Epoch 2164, Loss: 2.2408504113554955, Final Batch Loss: 0.10104503482580185\n",
      "Epoch 2165, Loss: 3.386984169483185, Final Batch Loss: 1.2319345474243164\n",
      "Epoch 2166, Loss: 2.543504774570465, Final Batch Loss: 0.5929359197616577\n",
      "Epoch 2167, Loss: 1.9539274536073208, Final Batch Loss: 0.02846747264266014\n",
      "Epoch 2168, Loss: 4.079393088817596, Final Batch Loss: 2.118746042251587\n",
      "Epoch 2169, Loss: 2.4709604382514954, Final Batch Loss: 0.5485845804214478\n",
      "Epoch 2170, Loss: 2.003771100193262, Final Batch Loss: 0.03157207742333412\n",
      "Epoch 2171, Loss: 2.1936245902907103, Final Batch Loss: 0.0037549480330199003\n",
      "Epoch 2172, Loss: 3.3230347633361816, Final Batch Loss: 1.0740129947662354\n",
      "Epoch 2173, Loss: 2.2537190914154053, Final Batch Loss: 0.05321037769317627\n",
      "Epoch 2174, Loss: 4.25484573841095, Final Batch Loss: 2.1898255348205566\n",
      "Epoch 2175, Loss: 2.3746883869171143, Final Batch Loss: 0.39304715394973755\n",
      "Epoch 2176, Loss: 3.3341128826141357, Final Batch Loss: 1.4015637636184692\n",
      "Epoch 2177, Loss: 2.0835519582033157, Final Batch Loss: 0.2211577445268631\n",
      "Epoch 2178, Loss: 1.8669915709178895, Final Batch Loss: 0.0034874591510742903\n",
      "Epoch 2179, Loss: 1.973733738064766, Final Batch Loss: 0.11749519407749176\n",
      "Epoch 2180, Loss: 3.3954739570617676, Final Batch Loss: 1.5816420316696167\n",
      "Epoch 2181, Loss: 1.9377601044252515, Final Batch Loss: 0.007397403009235859\n",
      "Epoch 2182, Loss: 1.9596536457538605, Final Batch Loss: 0.11934319138526917\n",
      "Epoch 2183, Loss: 1.95658390969038, Final Batch Loss: 0.0711628720164299\n",
      "Epoch 2184, Loss: 2.0651341676712036, Final Batch Loss: 0.27517086267471313\n",
      "Epoch 2185, Loss: 1.8543528858572245, Final Batch Loss: 0.0180582944303751\n",
      "Epoch 2186, Loss: 1.8756515718996525, Final Batch Loss: 0.04107895866036415\n",
      "Epoch 2187, Loss: 1.8498638737946749, Final Batch Loss: 0.005835520103573799\n",
      "Epoch 2188, Loss: 1.8472705836757086, Final Batch Loss: 0.00040951924165710807\n",
      "Epoch 2189, Loss: 1.9771857857704163, Final Batch Loss: 0.16591346263885498\n",
      "Epoch 2190, Loss: 4.248004794120789, Final Batch Loss: 2.4914474487304688\n",
      "Epoch 2191, Loss: 1.7426093398826197, Final Batch Loss: 0.001715499092824757\n",
      "Epoch 2192, Loss: 2.400662899017334, Final Batch Loss: 0.5270293354988098\n",
      "Epoch 2193, Loss: 1.8494921838864684, Final Batch Loss: 0.0024920618161559105\n",
      "Epoch 2194, Loss: 2.317747473716736, Final Batch Loss: 0.6091783046722412\n",
      "Epoch 2195, Loss: 1.9339269697666168, Final Batch Loss: 0.16364338994026184\n",
      "Epoch 2196, Loss: 1.7997242771089077, Final Batch Loss: 0.038199540227651596\n",
      "Epoch 2197, Loss: 2.630267381668091, Final Batch Loss: 0.7612812519073486\n",
      "Epoch 2198, Loss: 1.820421151816845, Final Batch Loss: 0.04232286661863327\n",
      "Epoch 2199, Loss: 1.8709387555718422, Final Batch Loss: 0.07359138876199722\n",
      "Epoch 2200, Loss: 1.9356987476348877, Final Batch Loss: 0.1862260103225708\n",
      "Epoch 2201, Loss: 2.6568753123283386, Final Batch Loss: 0.841561496257782\n",
      "Epoch 2202, Loss: 2.6449407935142517, Final Batch Loss: 0.7789055109024048\n",
      "Epoch 2203, Loss: 1.761579839658225, Final Batch Loss: 0.00025102324434556067\n",
      "Epoch 2204, Loss: 1.9232033491134644, Final Batch Loss: 0.03544723987579346\n",
      "Epoch 2205, Loss: 4.797195553779602, Final Batch Loss: 3.024885416030884\n",
      "Epoch 2206, Loss: 3.252824693918228, Final Batch Loss: 1.5115774869918823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2207, Loss: 2.868096947669983, Final Batch Loss: 1.1363630294799805\n",
      "Epoch 2208, Loss: 4.084513306617737, Final Batch Loss: 2.3341801166534424\n",
      "Epoch 2209, Loss: 3.2724315524101257, Final Batch Loss: 1.4773054122924805\n",
      "Epoch 2210, Loss: 2.5409117341041565, Final Batch Loss: 0.809422492980957\n",
      "Epoch 2211, Loss: 3.922592043876648, Final Batch Loss: 2.1734871864318848\n",
      "Epoch 2212, Loss: 2.918604850769043, Final Batch Loss: 1.215698480606079\n",
      "Epoch 2213, Loss: 1.6933408119803062, Final Batch Loss: 0.00022790218645241112\n",
      "Epoch 2214, Loss: 2.1430028080940247, Final Batch Loss: 0.3986963629722595\n",
      "Epoch 2215, Loss: 1.89078950881958, Final Batch Loss: 0.15414553880691528\n",
      "Epoch 2216, Loss: 4.413163363933563, Final Batch Loss: 2.6036972999572754\n",
      "Epoch 2217, Loss: 2.771661639213562, Final Batch Loss: 1.0489397048950195\n",
      "Epoch 2218, Loss: 1.7360275825485587, Final Batch Loss: 0.013908370397984982\n",
      "Epoch 2219, Loss: 1.9765137881040573, Final Batch Loss: 0.13908033072948456\n",
      "Epoch 2220, Loss: 3.2214470505714417, Final Batch Loss: 1.2672687768936157\n",
      "Epoch 2221, Loss: 3.086730659008026, Final Batch Loss: 1.232011079788208\n",
      "Epoch 2222, Loss: 1.8139915186911821, Final Batch Loss: 0.01848939247429371\n",
      "Epoch 2223, Loss: 2.173418402671814, Final Batch Loss: 0.45642906427383423\n",
      "Epoch 2224, Loss: 1.7871130146086216, Final Batch Loss: 0.03857100382447243\n",
      "Epoch 2225, Loss: 3.000678837299347, Final Batch Loss: 1.242933750152588\n",
      "Epoch 2226, Loss: 1.7678224090486765, Final Batch Loss: 0.03025677241384983\n",
      "Epoch 2227, Loss: 2.8972184658050537, Final Batch Loss: 1.0837197303771973\n",
      "Epoch 2228, Loss: 2.1219895780086517, Final Batch Loss: 0.2712797224521637\n",
      "Epoch 2229, Loss: 3.280268967151642, Final Batch Loss: 1.4656561613082886\n",
      "Epoch 2230, Loss: 2.102100908756256, Final Batch Loss: 0.23735493421554565\n",
      "Epoch 2231, Loss: 3.342607796192169, Final Batch Loss: 1.4983224868774414\n",
      "Epoch 2232, Loss: 1.8780387621372938, Final Batch Loss: 0.014009116217494011\n",
      "Epoch 2233, Loss: 1.8481222093105316, Final Batch Loss: 0.07106372714042664\n",
      "Epoch 2234, Loss: 3.0876764059066772, Final Batch Loss: 1.2181416749954224\n",
      "Epoch 2235, Loss: 3.0197739005088806, Final Batch Loss: 1.247300624847412\n",
      "Epoch 2236, Loss: 1.8149348865263164, Final Batch Loss: 0.0024978886358439922\n",
      "Epoch 2237, Loss: 3.853363871574402, Final Batch Loss: 2.0188052654266357\n",
      "Epoch 2238, Loss: 1.9475956708192825, Final Batch Loss: 0.17375709116458893\n",
      "Epoch 2239, Loss: 1.9195158928632736, Final Batch Loss: 0.023500367999076843\n",
      "Epoch 2240, Loss: 1.8276573866605759, Final Batch Loss: 0.037602707743644714\n",
      "Epoch 2241, Loss: 1.9598649442195892, Final Batch Loss: 0.15221461653709412\n",
      "Epoch 2242, Loss: 1.7940511703200173, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 2243, Loss: 2.465684413909912, Final Batch Loss: 0.6874946355819702\n",
      "Epoch 2244, Loss: 1.8135414607822895, Final Batch Loss: 0.03705250099301338\n",
      "Epoch 2245, Loss: 3.4928298592567444, Final Batch Loss: 1.7220330238342285\n",
      "Epoch 2246, Loss: 2.707696795463562, Final Batch Loss: 1.006384015083313\n",
      "Epoch 2247, Loss: 1.702471051365137, Final Batch Loss: 0.01899341121315956\n",
      "Epoch 2248, Loss: 1.8046248145401478, Final Batch Loss: 0.03195120766758919\n",
      "Epoch 2249, Loss: 1.8117239754647017, Final Batch Loss: 0.024192599579691887\n",
      "Epoch 2250, Loss: 3.482469618320465, Final Batch Loss: 1.776766300201416\n",
      "Epoch 2251, Loss: 1.73902322165668, Final Batch Loss: 0.028664303943514824\n",
      "Epoch 2252, Loss: 1.682971091940999, Final Batch Loss: 0.016794951632618904\n",
      "Epoch 2253, Loss: 2.4382594227790833, Final Batch Loss: 0.7760985493659973\n",
      "Epoch 2254, Loss: 1.8545876368880272, Final Batch Loss: 0.05956896394491196\n",
      "Epoch 2255, Loss: 1.850280687212944, Final Batch Loss: 0.15289591252803802\n",
      "Epoch 2256, Loss: 1.7512692511081696, Final Batch Loss: 0.017931610345840454\n",
      "Epoch 2257, Loss: 1.7473653682973236, Final Batch Loss: 0.0006716379430145025\n",
      "Epoch 2258, Loss: 4.004453897476196, Final Batch Loss: 2.3164942264556885\n",
      "Epoch 2259, Loss: 2.293988823890686, Final Batch Loss: 0.6074599027633667\n",
      "Epoch 2260, Loss: 1.7147883283905685, Final Batch Loss: 0.007755171041935682\n",
      "Epoch 2261, Loss: 1.6702680531234364, Final Batch Loss: 0.00010632903286023065\n",
      "Epoch 2262, Loss: 1.7042499212548137, Final Batch Loss: 0.014968576841056347\n",
      "Epoch 2263, Loss: 1.6596461739391088, Final Batch Loss: 0.009086212143301964\n",
      "Epoch 2264, Loss: 3.5994539856910706, Final Batch Loss: 1.9385018348693848\n",
      "Epoch 2265, Loss: 3.7569578289985657, Final Batch Loss: 2.0963335037231445\n",
      "Epoch 2266, Loss: 3.590397536754608, Final Batch Loss: 1.814333438873291\n",
      "Epoch 2267, Loss: 1.7161744348704815, Final Batch Loss: 0.018737923353910446\n",
      "Epoch 2268, Loss: 2.6386823058128357, Final Batch Loss: 0.8755931258201599\n",
      "Epoch 2269, Loss: 1.7882431723264745, Final Batch Loss: 6.675497570540756e-05\n",
      "Epoch 2270, Loss: 1.7074410845307284, Final Batch Loss: 0.00011836781777674332\n",
      "Epoch 2271, Loss: 1.8094379007816315, Final Batch Loss: 0.01625123620033264\n",
      "Epoch 2272, Loss: 2.1227957606315613, Final Batch Loss: 0.438568115234375\n",
      "Epoch 2273, Loss: 1.799122042953968, Final Batch Loss: 0.10914260894060135\n",
      "Epoch 2274, Loss: 1.730624494710355, Final Batch Loss: 6.675497570540756e-05\n",
      "Epoch 2275, Loss: 1.706349627696909, Final Batch Loss: 0.000666277133859694\n",
      "Epoch 2276, Loss: 1.7309912219643593, Final Batch Loss: 0.004594840109348297\n",
      "Epoch 2277, Loss: 1.7198709249360036, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 2278, Loss: 2.7086483240127563, Final Batch Loss: 1.0063669681549072\n",
      "Epoch 2279, Loss: 1.9474023878574371, Final Batch Loss: 0.21188503503799438\n",
      "Epoch 2280, Loss: 2.793881416320801, Final Batch Loss: 1.1846349239349365\n",
      "Epoch 2281, Loss: 1.8582266047596931, Final Batch Loss: 0.116181381046772\n",
      "Epoch 2282, Loss: 1.796240142037277, Final Batch Loss: 0.0001333863037871197\n",
      "Epoch 2283, Loss: 1.8392503317445517, Final Batch Loss: 0.02249777875840664\n",
      "Epoch 2284, Loss: 3.9692590832710266, Final Batch Loss: 2.043748378753662\n",
      "Epoch 2285, Loss: 3.134262263774872, Final Batch Loss: 1.4432920217514038\n",
      "Epoch 2286, Loss: 2.507629245519638, Final Batch Loss: 0.48163995146751404\n",
      "Epoch 2287, Loss: 5.39729380607605, Final Batch Loss: 3.100776195526123\n",
      "Epoch 2288, Loss: 2.4860729947686195, Final Batch Loss: 0.049028851091861725\n",
      "Epoch 2289, Loss: 6.087537467479706, Final Batch Loss: 3.925586462020874\n",
      "Epoch 2290, Loss: 2.13591355830431, Final Batch Loss: 0.06781644374132156\n",
      "Epoch 2291, Loss: 2.2578765638172626, Final Batch Loss: 0.052285123616456985\n",
      "Epoch 2292, Loss: 2.5602491050958633, Final Batch Loss: 0.17770560085773468\n",
      "Epoch 2293, Loss: 3.3126651644706726, Final Batch Loss: 1.1051417589187622\n",
      "Epoch 2294, Loss: 2.2806982793845236, Final Batch Loss: 0.00772074842825532\n",
      "Epoch 2295, Loss: 2.1492258720099926, Final Batch Loss: 0.01506064459681511\n",
      "Epoch 2296, Loss: 2.0733758313581347, Final Batch Loss: 0.0043481094762682915\n",
      "Epoch 2297, Loss: 2.0418771356344223, Final Batch Loss: 0.04790644347667694\n",
      "Epoch 2298, Loss: 2.1924623027443886, Final Batch Loss: 0.10954014211893082\n",
      "Epoch 2299, Loss: 1.971390314400196, Final Batch Loss: 0.06811726838350296\n",
      "Epoch 2300, Loss: 1.9070062313985545, Final Batch Loss: 0.000254241080256179\n",
      "Epoch 2301, Loss: 1.9765498265624046, Final Batch Loss: 0.10907837003469467\n",
      "Epoch 2302, Loss: 1.9504144042730331, Final Batch Loss: 0.09156326949596405\n",
      "Epoch 2303, Loss: 2.279441863298416, Final Batch Loss: 0.4622214138507843\n",
      "Epoch 2304, Loss: 2.6535587310791016, Final Batch Loss: 0.8492311239242554\n",
      "Epoch 2305, Loss: 1.9765727669000626, Final Batch Loss: 0.08927150070667267\n",
      "Epoch 2306, Loss: 1.9518018662929535, Final Batch Loss: 0.07620933651924133\n",
      "Epoch 2307, Loss: 5.305082440376282, Final Batch Loss: 3.524827241897583\n",
      "Epoch 2308, Loss: 3.2407266497612, Final Batch Loss: 1.3933169841766357\n",
      "Epoch 2309, Loss: 2.0429590344429016, Final Batch Loss: 0.25839918851852417\n",
      "Epoch 2310, Loss: 1.8491513691842556, Final Batch Loss: 0.011568840593099594\n",
      "Epoch 2311, Loss: 1.953484047204256, Final Batch Loss: 0.012095320969820023\n",
      "Epoch 2312, Loss: 3.643353044986725, Final Batch Loss: 1.6402140855789185\n",
      "Epoch 2313, Loss: 4.060675740242004, Final Batch Loss: 2.116183042526245\n",
      "Epoch 2314, Loss: 1.8318349048495293, Final Batch Loss: 0.01787763088941574\n",
      "Epoch 2315, Loss: 3.586906611919403, Final Batch Loss: 1.8240785598754883\n",
      "Epoch 2316, Loss: 1.8010139731923118, Final Batch Loss: 0.0005515484372153878\n",
      "Epoch 2317, Loss: 2.7395750284194946, Final Batch Loss: 0.9534863829612732\n",
      "Epoch 2318, Loss: 2.1560590863227844, Final Batch Loss: 0.38097500801086426\n",
      "Epoch 2319, Loss: 3.1803672909736633, Final Batch Loss: 1.4561516046524048\n",
      "Epoch 2320, Loss: 3.34994238615036, Final Batch Loss: 1.6408520936965942\n",
      "Epoch 2321, Loss: 3.763125002384186, Final Batch Loss: 1.9296817779541016\n",
      "Epoch 2322, Loss: 1.766260134827462, Final Batch Loss: 0.00015662873920518905\n",
      "Epoch 2323, Loss: 1.9138830825686455, Final Batch Loss: 0.10432147234678268\n",
      "Epoch 2324, Loss: 1.6633770153857768, Final Batch Loss: 0.006261019501835108\n",
      "Epoch 2325, Loss: 1.7812192887067795, Final Batch Loss: 0.0671156495809555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2326, Loss: 3.315820097923279, Final Batch Loss: 1.6431450843811035\n",
      "Epoch 2327, Loss: 1.8798437602818012, Final Batch Loss: 0.061700571328401566\n",
      "Epoch 2328, Loss: 2.481522262096405, Final Batch Loss: 0.72587651014328\n",
      "Epoch 2329, Loss: 1.695239633321762, Final Batch Loss: 0.0344526469707489\n",
      "Epoch 2330, Loss: 1.7839721143245697, Final Batch Loss: 0.10513469576835632\n",
      "Epoch 2331, Loss: 2.7852760553359985, Final Batch Loss: 1.0320545434951782\n",
      "Epoch 2332, Loss: 2.019907981157303, Final Batch Loss: 0.28898587822914124\n",
      "Epoch 2333, Loss: 2.4921913743019104, Final Batch Loss: 0.7267268896102905\n",
      "Epoch 2334, Loss: 2.21740061044693, Final Batch Loss: 0.40201258659362793\n",
      "Epoch 2335, Loss: 1.871376084163785, Final Batch Loss: 0.01909809000790119\n",
      "Epoch 2336, Loss: 3.685988485813141, Final Batch Loss: 1.9390255212783813\n",
      "Epoch 2337, Loss: 2.6335152983665466, Final Batch Loss: 0.8126617670059204\n",
      "Epoch 2338, Loss: 2.3105431497097015, Final Batch Loss: 0.48738500475883484\n",
      "Epoch 2339, Loss: 3.359186589717865, Final Batch Loss: 1.5499074459075928\n",
      "Epoch 2340, Loss: 1.7498201057314873, Final Batch Loss: 0.028930239379405975\n",
      "Epoch 2341, Loss: 1.751959337212611, Final Batch Loss: 0.0004601611872203648\n",
      "Epoch 2342, Loss: 3.6216410994529724, Final Batch Loss: 1.9343905448913574\n",
      "Epoch 2343, Loss: 2.0055848509073257, Final Batch Loss: 0.22121240198612213\n",
      "Epoch 2344, Loss: 1.8677856549620628, Final Batch Loss: 0.08614393323659897\n",
      "Epoch 2345, Loss: 1.710573785007, Final Batch Loss: 0.037451259791851044\n",
      "Epoch 2346, Loss: 1.839982345700264, Final Batch Loss: 0.14579980075359344\n",
      "Epoch 2347, Loss: 1.7784457113593817, Final Batch Loss: 0.01200663112103939\n",
      "Epoch 2348, Loss: 1.7392076179385185, Final Batch Loss: 0.02054481953382492\n",
      "Epoch 2349, Loss: 1.7802624125033617, Final Batch Loss: 0.0176509041339159\n",
      "Epoch 2350, Loss: 1.681692068465054, Final Batch Loss: 0.00496250856667757\n",
      "Epoch 2351, Loss: 1.8506420217454433, Final Batch Loss: 0.011931952089071274\n",
      "Epoch 2352, Loss: 3.5667964220046997, Final Batch Loss: 1.8536641597747803\n",
      "Epoch 2353, Loss: 1.6726688593626022, Final Batch Loss: 0.0019601434469223022\n",
      "Epoch 2354, Loss: 3.3682278394699097, Final Batch Loss: 1.6444894075393677\n",
      "Epoch 2355, Loss: 2.7658058404922485, Final Batch Loss: 1.0637407302856445\n",
      "Epoch 2356, Loss: 2.537927567958832, Final Batch Loss: 0.7956359386444092\n",
      "Epoch 2357, Loss: 1.7890720337163657, Final Batch Loss: 0.00365256960503757\n",
      "Epoch 2358, Loss: 3.4613202810287476, Final Batch Loss: 1.6925212144851685\n",
      "Epoch 2359, Loss: 2.114934504032135, Final Batch Loss: 0.34020084142684937\n",
      "Epoch 2360, Loss: 3.873029887676239, Final Batch Loss: 2.1101419925689697\n",
      "Epoch 2361, Loss: 1.708576250821352, Final Batch Loss: 0.01429002359509468\n",
      "Epoch 2362, Loss: 2.1293297708034515, Final Batch Loss: 0.41990289092063904\n",
      "Epoch 2363, Loss: 2.335385322570801, Final Batch Loss: 0.5448498129844666\n",
      "Epoch 2364, Loss: 1.7656209701672196, Final Batch Loss: 0.007185094989836216\n",
      "Epoch 2365, Loss: 3.0107182264328003, Final Batch Loss: 1.3148856163024902\n",
      "Epoch 2366, Loss: 1.7222947077825665, Final Batch Loss: 0.0011276798322796822\n",
      "Epoch 2367, Loss: 1.7349774492904544, Final Batch Loss: 0.009006942622363567\n",
      "Epoch 2368, Loss: 1.6129312646226026, Final Batch Loss: 0.00030501006403937936\n",
      "Epoch 2369, Loss: 1.7871687673032284, Final Batch Loss: 0.03783264383673668\n",
      "Epoch 2370, Loss: 2.5721169114112854, Final Batch Loss: 0.9040676355361938\n",
      "Epoch 2371, Loss: 1.6672624764905777, Final Batch Loss: 0.00019012074335478246\n",
      "Epoch 2372, Loss: 1.6463626026352358, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 2373, Loss: 1.6831308263354003, Final Batch Loss: 0.0046743410639464855\n",
      "Epoch 2374, Loss: 1.888440117239952, Final Batch Loss: 0.1865902990102768\n",
      "Epoch 2375, Loss: 1.757582187652588, Final Batch Loss: 0.07112324237823486\n",
      "Epoch 2376, Loss: 1.7585712671279907, Final Batch Loss: 0.09929943084716797\n",
      "Epoch 2377, Loss: 3.4090795516967773, Final Batch Loss: 1.7750728130340576\n",
      "Epoch 2378, Loss: 1.7897632792592049, Final Batch Loss: 0.07382483035326004\n",
      "Epoch 2379, Loss: 3.5741196274757385, Final Batch Loss: 1.8653215169906616\n",
      "Epoch 2380, Loss: 1.6291047284030356, Final Batch Loss: 0.0006977269076742232\n",
      "Epoch 2381, Loss: 1.7177184992469847, Final Batch Loss: 0.006532149855047464\n",
      "Epoch 2382, Loss: 2.9225433468818665, Final Batch Loss: 1.2071318626403809\n",
      "Epoch 2383, Loss: 1.654615268111229, Final Batch Loss: 0.056985631585121155\n",
      "Epoch 2384, Loss: 1.6538654118776321, Final Batch Loss: 0.034703806042671204\n",
      "Epoch 2385, Loss: 3.1173466444015503, Final Batch Loss: 1.4524850845336914\n",
      "Epoch 2386, Loss: 1.6544911264936673, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 2387, Loss: 1.670078981667757, Final Batch Loss: 0.02401338890194893\n",
      "Epoch 2388, Loss: 2.8526571393013, Final Batch Loss: 1.119798183441162\n",
      "Epoch 2389, Loss: 1.7281731739640236, Final Batch Loss: 0.05412755161523819\n",
      "Epoch 2390, Loss: 1.6369051281362772, Final Batch Loss: 0.017811352387070656\n",
      "Epoch 2391, Loss: 2.2632029056549072, Final Batch Loss: 0.6098781824111938\n",
      "Epoch 2392, Loss: 1.6685470342172266, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 2393, Loss: 2.389414370059967, Final Batch Loss: 0.6787429451942444\n",
      "Epoch 2394, Loss: 3.5813058018684387, Final Batch Loss: 1.8778061866760254\n",
      "Epoch 2395, Loss: 1.705702729523182, Final Batch Loss: 0.022170431911945343\n",
      "Epoch 2396, Loss: 2.195289045572281, Final Batch Loss: 0.46182891726493835\n",
      "Epoch 2397, Loss: 2.120179235935211, Final Batch Loss: 0.2800147533416748\n",
      "Epoch 2398, Loss: 1.9683543741703033, Final Batch Loss: 0.16613510251045227\n",
      "Epoch 2399, Loss: 1.9184616059064865, Final Batch Loss: 0.10629825294017792\n",
      "Epoch 2400, Loss: 3.5315844416618347, Final Batch Loss: 1.7538354396820068\n",
      "Epoch 2401, Loss: 1.619850624119863, Final Batch Loss: 0.002241838490590453\n",
      "Epoch 2402, Loss: 2.194939970970154, Final Batch Loss: 0.5371292233467102\n",
      "Epoch 2403, Loss: 1.7267349604517221, Final Batch Loss: 0.011617625132203102\n",
      "Epoch 2404, Loss: 3.7261351943016052, Final Batch Loss: 2.0299458503723145\n",
      "Epoch 2405, Loss: 1.7320139408111572, Final Batch Loss: 0.08099555969238281\n",
      "Epoch 2406, Loss: 3.373834013938904, Final Batch Loss: 1.3862192630767822\n",
      "Epoch 2407, Loss: 2.5495885014533997, Final Batch Loss: 0.10684829950332642\n",
      "Epoch 2408, Loss: 2.625131279230118, Final Batch Loss: 0.33031341433525085\n",
      "Epoch 2409, Loss: 2.091939594130963, Final Batch Loss: 0.0032107490114867687\n",
      "Epoch 2410, Loss: 1.8876688502496108, Final Batch Loss: 0.0018252156442031264\n",
      "Epoch 2411, Loss: 1.9115940853953362, Final Batch Loss: 0.011767260730266571\n",
      "Epoch 2412, Loss: 1.9091788225632627, Final Batch Loss: 0.00024685196694917977\n",
      "Epoch 2413, Loss: 2.9367571473121643, Final Batch Loss: 1.2723528146743774\n",
      "Epoch 2414, Loss: 1.7379192970693111, Final Batch Loss: 0.014361824840307236\n",
      "Epoch 2415, Loss: 1.6571004927391186, Final Batch Loss: 0.00010895135346800089\n",
      "Epoch 2416, Loss: 4.86585795879364, Final Batch Loss: 3.1896698474884033\n",
      "Epoch 2417, Loss: 2.708201289176941, Final Batch Loss: 0.9670369029045105\n",
      "Epoch 2418, Loss: 1.690560769988224, Final Batch Loss: 0.00342996115796268\n",
      "Epoch 2419, Loss: 1.7218641191720963, Final Batch Loss: 0.05710138380527496\n",
      "Epoch 2420, Loss: 1.6906509036198258, Final Batch Loss: 0.0032847756519913673\n",
      "Epoch 2421, Loss: 2.3388975858688354, Final Batch Loss: 0.5205146670341492\n",
      "Epoch 2422, Loss: 1.7382276225835085, Final Batch Loss: 0.00948907621204853\n",
      "Epoch 2423, Loss: 1.72486456297338, Final Batch Loss: 0.012699564918875694\n",
      "Epoch 2424, Loss: 1.7082980163395405, Final Batch Loss: 0.013971734791994095\n",
      "Epoch 2425, Loss: 1.800167143182989, Final Batch Loss: 1.8000440832111053e-05\n",
      "Epoch 2426, Loss: 2.9231855869293213, Final Batch Loss: 1.2242578268051147\n",
      "Epoch 2427, Loss: 2.392102062702179, Final Batch Loss: 0.6427564024925232\n",
      "Epoch 2428, Loss: 1.6833411785773933, Final Batch Loss: 0.00527063338086009\n",
      "Epoch 2429, Loss: 2.422206401824951, Final Batch Loss: 0.6967448592185974\n",
      "Epoch 2430, Loss: 2.0370298326015472, Final Batch Loss: 0.2970915734767914\n",
      "Epoch 2431, Loss: 1.9839674830436707, Final Batch Loss: 0.24042874574661255\n",
      "Epoch 2432, Loss: 1.7343015940859914, Final Batch Loss: 0.013089445419609547\n",
      "Epoch 2433, Loss: 3.208893835544586, Final Batch Loss: 1.507580280303955\n",
      "Epoch 2434, Loss: 1.7483576703816652, Final Batch Loss: 0.01501108892261982\n",
      "Epoch 2435, Loss: 1.9862890839576721, Final Batch Loss: 0.28835976123809814\n",
      "Epoch 2436, Loss: 1.654998540873521, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 2437, Loss: 1.8373688161373138, Final Batch Loss: 0.14281347393989563\n",
      "Epoch 2438, Loss: 2.1160672903060913, Final Batch Loss: 0.4125106930732727\n",
      "Epoch 2439, Loss: 1.7759369686245918, Final Batch Loss: 0.10021866112947464\n",
      "Epoch 2440, Loss: 4.310054183006287, Final Batch Loss: 2.6440019607543945\n",
      "Epoch 2441, Loss: 1.7411374151706696, Final Batch Loss: 0.041920214891433716\n",
      "Epoch 2442, Loss: 2.198971837759018, Final Batch Loss: 0.29529157280921936\n",
      "Epoch 2443, Loss: 2.3063510358333588, Final Batch Loss: 0.2040899693965912\n",
      "Epoch 2444, Loss: 2.1416234970092773, Final Batch Loss: 0.06771796941757202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2445, Loss: 2.2870084643363953, Final Batch Loss: 0.05065655708312988\n",
      "Epoch 2446, Loss: 1.9249600172042847, Final Batch Loss: 0.06771796941757202\n",
      "Epoch 2447, Loss: 2.20886692404747, Final Batch Loss: 0.4178756773471832\n",
      "Epoch 2448, Loss: 1.760850477963686, Final Batch Loss: 0.028106261044740677\n",
      "Epoch 2449, Loss: 1.8755765855312347, Final Batch Loss: 0.1321166455745697\n",
      "Epoch 2450, Loss: 1.7736189179122448, Final Batch Loss: 0.03012595698237419\n",
      "Epoch 2451, Loss: 1.8141878843307495, Final Batch Loss: 0.14232361316680908\n",
      "Epoch 2452, Loss: 2.702501952648163, Final Batch Loss: 1.1179105043411255\n",
      "Epoch 2453, Loss: 1.7577246567234397, Final Batch Loss: 0.0027122637256979942\n",
      "Epoch 2454, Loss: 3.338626742362976, Final Batch Loss: 1.689720869064331\n",
      "Epoch 2455, Loss: 4.363408744335175, Final Batch Loss: 2.7213475704193115\n",
      "Epoch 2456, Loss: 1.677904921816662, Final Batch Loss: 0.0036140859592705965\n",
      "Epoch 2457, Loss: 2.1380870938301086, Final Batch Loss: 0.3949350118637085\n",
      "Epoch 2458, Loss: 1.9542920589447021, Final Batch Loss: 0.11497008800506592\n",
      "Epoch 2459, Loss: 1.8437076266855001, Final Batch Loss: 0.013670748099684715\n",
      "Epoch 2460, Loss: 2.047062188386917, Final Batch Loss: 0.20670613646507263\n",
      "Epoch 2461, Loss: 1.8448504209518433, Final Batch Loss: 0.11906522512435913\n",
      "Epoch 2462, Loss: 4.391630470752716, Final Batch Loss: 2.648399829864502\n",
      "Epoch 2463, Loss: 1.7248824429116212, Final Batch Loss: 0.000565249880310148\n",
      "Epoch 2464, Loss: 3.7667474150657654, Final Batch Loss: 1.9795747995376587\n",
      "Epoch 2465, Loss: 1.874467894434929, Final Batch Loss: 0.13469712436199188\n",
      "Epoch 2466, Loss: 1.7749618329107761, Final Batch Loss: 0.02168399468064308\n",
      "Epoch 2467, Loss: 3.153938889503479, Final Batch Loss: 1.343278169631958\n",
      "Epoch 2468, Loss: 3.523324489593506, Final Batch Loss: 1.7457971572875977\n",
      "Epoch 2469, Loss: 1.7770954456645995, Final Batch Loss: 0.00031931069679558277\n",
      "Epoch 2470, Loss: 1.9358869194984436, Final Batch Loss: 0.21002322435379028\n",
      "Epoch 2471, Loss: 2.7843013405799866, Final Batch Loss: 1.0286740064620972\n",
      "Epoch 2472, Loss: 3.7021071910858154, Final Batch Loss: 1.973535180091858\n",
      "Epoch 2473, Loss: 3.4473296999931335, Final Batch Loss: 1.7494806051254272\n",
      "Epoch 2474, Loss: 2.2555297315120697, Final Batch Loss: 0.6382266283035278\n",
      "Epoch 2475, Loss: 2.1107691526412964, Final Batch Loss: 0.39068639278411865\n",
      "Epoch 2476, Loss: 1.7495806436054409, Final Batch Loss: 0.0054283360950648785\n",
      "Epoch 2477, Loss: 3.114802837371826, Final Batch Loss: 1.2889618873596191\n",
      "Epoch 2478, Loss: 1.863579049706459, Final Batch Loss: 0.14095164835453033\n",
      "Epoch 2479, Loss: 3.4392028152942657, Final Batch Loss: 1.7057297229766846\n",
      "Epoch 2480, Loss: 3.0284637808799744, Final Batch Loss: 1.36417818069458\n",
      "Epoch 2481, Loss: 2.7948049902915955, Final Batch Loss: 1.0928428173065186\n",
      "Epoch 2482, Loss: 3.182784378528595, Final Batch Loss: 1.5404998064041138\n",
      "Epoch 2483, Loss: 1.7371041686274111, Final Batch Loss: 0.0028279335238039494\n",
      "Epoch 2484, Loss: 2.121084064245224, Final Batch Loss: 0.45701804757118225\n",
      "Epoch 2485, Loss: 1.7376666888594627, Final Batch Loss: 0.039309047162532806\n",
      "Epoch 2486, Loss: 1.9145874977111816, Final Batch Loss: 0.2660871744155884\n",
      "Epoch 2487, Loss: 2.7124688029289246, Final Batch Loss: 1.017652988433838\n",
      "Epoch 2488, Loss: 2.59512460231781, Final Batch Loss: 0.9521964192390442\n",
      "Epoch 2489, Loss: 2.9293578267097473, Final Batch Loss: 1.234283685684204\n",
      "Epoch 2490, Loss: 1.6823231503512943, Final Batch Loss: 0.00012194366718176752\n",
      "Epoch 2491, Loss: 1.697133406996727, Final Batch Loss: 0.02733449637889862\n",
      "Epoch 2492, Loss: 2.059329032897949, Final Batch Loss: 0.4026562571525574\n",
      "Epoch 2493, Loss: 3.294123351573944, Final Batch Loss: 1.7273368835449219\n",
      "Epoch 2494, Loss: 1.629070567083545, Final Batch Loss: 0.001301514101214707\n",
      "Epoch 2495, Loss: 1.725957090035081, Final Batch Loss: 0.011140996590256691\n",
      "Epoch 2496, Loss: 1.6760353408753872, Final Batch Loss: 0.0610659085214138\n",
      "Epoch 2497, Loss: 1.620551039930433, Final Batch Loss: 0.006881584879010916\n",
      "Epoch 2498, Loss: 1.5686101336032152, Final Batch Loss: 0.01350104995071888\n",
      "Epoch 2499, Loss: 1.7454691343009472, Final Batch Loss: 0.054025571793317795\n",
      "Epoch 2500, Loss: 1.9811213314533234, Final Batch Loss: 0.27933600544929504\n",
      "Epoch 2501, Loss: 1.585775815648958, Final Batch Loss: 0.0002703301142901182\n",
      "Epoch 2502, Loss: 1.7080798521637917, Final Batch Loss: 0.007179059088230133\n",
      "Epoch 2503, Loss: 1.6296708204317838, Final Batch Loss: 0.0019259967375546694\n",
      "Epoch 2504, Loss: 2.807254731655121, Final Batch Loss: 1.2401660680770874\n",
      "Epoch 2505, Loss: 2.29816210269928, Final Batch Loss: 0.7105107307434082\n",
      "Epoch 2506, Loss: 1.8182444721460342, Final Batch Loss: 0.1605544239282608\n",
      "Epoch 2507, Loss: 1.755066990852356, Final Batch Loss: 0.07412451505661011\n",
      "Epoch 2508, Loss: 1.6550214416347444, Final Batch Loss: 0.003043664153665304\n",
      "Epoch 2509, Loss: 2.8444358706474304, Final Batch Loss: 1.1704421043395996\n",
      "Epoch 2510, Loss: 1.6028509642928839, Final Batch Loss: 0.017059138044714928\n",
      "Epoch 2511, Loss: 4.582287520170212, Final Batch Loss: 2.920804977416992\n",
      "Epoch 2512, Loss: 3.9166343212127686, Final Batch Loss: 2.3176705837249756\n",
      "Epoch 2513, Loss: 1.8013429641723633, Final Batch Loss: 0.19359314441680908\n",
      "Epoch 2514, Loss: 3.1984686851501465, Final Batch Loss: 1.566389799118042\n",
      "Epoch 2515, Loss: 2.7686580419540405, Final Batch Loss: 1.0881654024124146\n",
      "Epoch 2516, Loss: 1.7717552706599236, Final Batch Loss: 0.05534034222364426\n",
      "Epoch 2517, Loss: 2.629844307899475, Final Batch Loss: 0.8583681583404541\n",
      "Epoch 2518, Loss: 3.511439085006714, Final Batch Loss: 1.7511677742004395\n",
      "Epoch 2519, Loss: 1.8516391217708588, Final Batch Loss: 0.14529851078987122\n",
      "Epoch 2520, Loss: 3.290872812271118, Final Batch Loss: 1.5347169637680054\n",
      "Epoch 2521, Loss: 1.719310567714274, Final Batch Loss: 0.0012557962909340858\n",
      "Epoch 2522, Loss: 1.6641521784476936, Final Batch Loss: 0.002638432662934065\n",
      "Epoch 2523, Loss: 3.513241767883301, Final Batch Loss: 1.85239577293396\n",
      "Epoch 2524, Loss: 1.7198788784444332, Final Batch Loss: 0.024989929050207138\n",
      "Epoch 2525, Loss: 1.7006297763437033, Final Batch Loss: 0.026649659499526024\n",
      "Epoch 2526, Loss: 1.6326113961986266, Final Batch Loss: 0.00033861625706776977\n",
      "Epoch 2527, Loss: 1.776457466185093, Final Batch Loss: 0.11511597782373428\n",
      "Epoch 2528, Loss: 1.8284332752227783, Final Batch Loss: 0.19756200909614563\n",
      "Epoch 2529, Loss: 1.6805843780748546, Final Batch Loss: 0.0050921509973704815\n",
      "Epoch 2530, Loss: 1.715593472123146, Final Batch Loss: 0.05431409180164337\n",
      "Epoch 2531, Loss: 2.2345006465911865, Final Batch Loss: 0.5230196118354797\n",
      "Epoch 2532, Loss: 1.8613004684448242, Final Batch Loss: 0.2691645920276642\n",
      "Epoch 2533, Loss: 2.3379536271095276, Final Batch Loss: 0.7151155471801758\n",
      "Epoch 2534, Loss: 2.757653772830963, Final Batch Loss: 1.1511293649673462\n",
      "Epoch 2535, Loss: 1.8996464014053345, Final Batch Loss: 0.1881086230278015\n",
      "Epoch 2536, Loss: 3.712131828069687, Final Batch Loss: 2.0851454734802246\n",
      "Epoch 2537, Loss: 3.055000126361847, Final Batch Loss: 1.354180932044983\n",
      "Epoch 2538, Loss: 3.3476098775863647, Final Batch Loss: 1.642960786819458\n",
      "Epoch 2539, Loss: 1.8595310151576996, Final Batch Loss: 0.13401666283607483\n",
      "Epoch 2540, Loss: 2.4907801151275635, Final Batch Loss: 0.7304202318191528\n",
      "Epoch 2541, Loss: 2.947646975517273, Final Batch Loss: 1.1821324825286865\n",
      "Epoch 2542, Loss: 3.094843626022339, Final Batch Loss: 1.3002949953079224\n",
      "Epoch 2543, Loss: 1.7786750849336386, Final Batch Loss: 0.01732981763780117\n",
      "Epoch 2544, Loss: 1.8344444334506989, Final Batch Loss: 0.12802919745445251\n",
      "Epoch 2545, Loss: 1.732086930423975, Final Batch Loss: 0.014504823833703995\n",
      "Epoch 2546, Loss: 3.151894509792328, Final Batch Loss: 1.3771119117736816\n",
      "Epoch 2547, Loss: 3.87136310338974, Final Batch Loss: 2.2450075149536133\n",
      "Epoch 2548, Loss: 1.6479035094380379, Final Batch Loss: 0.027558572590351105\n",
      "Epoch 2549, Loss: 3.7883363366127014, Final Batch Loss: 2.1173362731933594\n",
      "Epoch 2550, Loss: 1.7499603852629662, Final Batch Loss: 0.10066642612218857\n",
      "Epoch 2551, Loss: 1.862380888313055, Final Batch Loss: 0.04582991823554039\n",
      "Epoch 2552, Loss: 3.0363752841949463, Final Batch Loss: 1.2531870603561401\n",
      "Epoch 2553, Loss: 1.700174389858148, Final Batch Loss: 5.3165931603871286e-05\n",
      "Epoch 2554, Loss: 1.690527830272913, Final Batch Loss: 0.0177825428545475\n",
      "Epoch 2555, Loss: 1.6330858282744884, Final Batch Loss: 0.0457272045314312\n",
      "Epoch 2556, Loss: 2.2637339532375336, Final Batch Loss: 0.6485723853111267\n",
      "Epoch 2557, Loss: 3.5642500519752502, Final Batch Loss: 1.9107098579406738\n",
      "Epoch 2558, Loss: 2.1905992329120636, Final Batch Loss: 0.4597224295139313\n",
      "Epoch 2559, Loss: 1.7883048094809055, Final Batch Loss: 0.03180444613099098\n",
      "Epoch 2560, Loss: 3.4014744758605957, Final Batch Loss: 1.2696564197540283\n",
      "Epoch 2561, Loss: 3.6322274208068848, Final Batch Loss: 1.5589150190353394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2562, Loss: 2.9725136756896973, Final Batch Loss: 0.8188944458961487\n",
      "Epoch 2563, Loss: 2.3598167300224304, Final Batch Loss: 0.42941391468048096\n",
      "Epoch 2564, Loss: 1.8112810803577304, Final Batch Loss: 0.007656986825168133\n",
      "Epoch 2565, Loss: 4.502892315387726, Final Batch Loss: 2.597512722015381\n",
      "Epoch 2566, Loss: 1.8740851134061813, Final Batch Loss: 0.18292878568172455\n",
      "Epoch 2567, Loss: 1.736636444926262, Final Batch Loss: 0.07130829989910126\n",
      "Epoch 2568, Loss: 1.777847109362483, Final Batch Loss: 0.025995133444666862\n",
      "Epoch 2569, Loss: 1.773748591542244, Final Batch Loss: 0.11020798981189728\n",
      "Epoch 2570, Loss: 1.6734471693634987, Final Batch Loss: 0.01846996694803238\n",
      "Epoch 2571, Loss: 3.7949123680591583, Final Batch Loss: 2.171163558959961\n",
      "Epoch 2572, Loss: 1.6334875538013875, Final Batch Loss: 0.0005433275364339352\n",
      "Epoch 2573, Loss: 1.6222145759966224, Final Batch Loss: 0.003156324615702033\n",
      "Epoch 2574, Loss: 3.6155861616134644, Final Batch Loss: 1.987231969833374\n",
      "Epoch 2575, Loss: 7.995449662208557, Final Batch Loss: 6.370492458343506\n",
      "Epoch 2576, Loss: 4.002273142337799, Final Batch Loss: 2.3170077800750732\n",
      "Epoch 2577, Loss: 3.2307228446006775, Final Batch Loss: 1.5159331560134888\n",
      "Epoch 2578, Loss: 1.710623145036152, Final Batch Loss: 1.156323378381785e-05\n",
      "Epoch 2579, Loss: 3.2950958013534546, Final Batch Loss: 1.5773258209228516\n",
      "Epoch 2580, Loss: 1.6640102872624993, Final Batch Loss: 0.006633878685534\n",
      "Epoch 2581, Loss: 3.6089670658111572, Final Batch Loss: 1.7341296672821045\n",
      "Epoch 2582, Loss: 1.9268903285264969, Final Batch Loss: 0.18347735702991486\n",
      "Epoch 2583, Loss: 1.8877554535865784, Final Batch Loss: 0.18482810258865356\n",
      "Epoch 2584, Loss: 3.241959571838379, Final Batch Loss: 1.5747005939483643\n",
      "Epoch 2585, Loss: 1.8995383903384209, Final Batch Loss: 0.12148427218198776\n",
      "Epoch 2586, Loss: 2.6782789826393127, Final Batch Loss: 1.0029003620147705\n",
      "Epoch 2587, Loss: 1.72197175770998, Final Batch Loss: 0.0329330638051033\n",
      "Epoch 2588, Loss: 2.337901771068573, Final Batch Loss: 0.6998935341835022\n",
      "Epoch 2589, Loss: 1.6610412448644638, Final Batch Loss: 0.046023592352867126\n",
      "Epoch 2590, Loss: 1.9608613848686218, Final Batch Loss: 0.2585618495941162\n",
      "Epoch 2591, Loss: 2.94456684589386, Final Batch Loss: 1.2695693969726562\n",
      "Epoch 2592, Loss: 1.7072247005999088, Final Batch Loss: 0.05279150977730751\n",
      "Epoch 2593, Loss: 1.7262816168367863, Final Batch Loss: 0.02413627877831459\n",
      "Epoch 2594, Loss: 1.6948972344398499, Final Batch Loss: 0.042904555797576904\n",
      "Epoch 2595, Loss: 1.9161338955163956, Final Batch Loss: 0.24178452789783478\n",
      "Epoch 2596, Loss: 1.6872294172644615, Final Batch Loss: 0.034580133855342865\n",
      "Epoch 2597, Loss: 3.0677465200424194, Final Batch Loss: 1.4264485836029053\n",
      "Epoch 2598, Loss: 2.4450342059135437, Final Batch Loss: 0.7146039009094238\n",
      "Epoch 2599, Loss: 3.298108607530594, Final Batch Loss: 1.65675687789917\n",
      "Epoch 2600, Loss: 1.7183643765747547, Final Batch Loss: 0.030364442616701126\n",
      "Epoch 2601, Loss: 1.7149915974587202, Final Batch Loss: 0.02519860677421093\n",
      "Epoch 2602, Loss: 2.865015983581543, Final Batch Loss: 1.2618224620819092\n",
      "Epoch 2603, Loss: 1.7300774827599525, Final Batch Loss: 0.02086184173822403\n",
      "Epoch 2604, Loss: 1.6546552442014217, Final Batch Loss: 0.05869757756590843\n",
      "Epoch 2605, Loss: 1.616595536405839, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 2606, Loss: 1.7205210775136948, Final Batch Loss: 0.07116298377513885\n",
      "Epoch 2607, Loss: 3.0039687156677246, Final Batch Loss: 1.346717119216919\n",
      "Epoch 2608, Loss: 3.160592496395111, Final Batch Loss: 1.5737279653549194\n",
      "Epoch 2609, Loss: 2.361535459756851, Final Batch Loss: 0.7949320673942566\n",
      "Epoch 2610, Loss: 1.748573325574398, Final Batch Loss: 0.10063149780035019\n",
      "Epoch 2611, Loss: 1.880814254283905, Final Batch Loss: 0.29507309198379517\n",
      "Epoch 2612, Loss: 1.8473681509494781, Final Batch Loss: 0.25782012939453125\n",
      "Epoch 2613, Loss: 3.066194176673889, Final Batch Loss: 1.4155806303024292\n",
      "Epoch 2614, Loss: 1.6550056636333466, Final Batch Loss: 0.031585246324539185\n",
      "Epoch 2615, Loss: 1.6486871607776266, Final Batch Loss: 0.00040665941196493804\n",
      "Epoch 2616, Loss: 2.9324687123298645, Final Batch Loss: 1.3027801513671875\n",
      "Epoch 2617, Loss: 1.6453616398503073, Final Batch Loss: 0.00021002470748499036\n",
      "Epoch 2618, Loss: 2.1141134798526764, Final Batch Loss: 0.49191683530807495\n",
      "Epoch 2619, Loss: 2.491186559200287, Final Batch Loss: 0.8654628396034241\n",
      "Epoch 2620, Loss: 1.676470322534442, Final Batch Loss: 0.00871710292994976\n",
      "Epoch 2621, Loss: 1.683457588776946, Final Batch Loss: 0.010376786813139915\n",
      "Epoch 2622, Loss: 1.677563723642379, Final Batch Loss: 0.0051636663265526295\n",
      "Epoch 2623, Loss: 1.696694484911859, Final Batch Loss: 0.013869456015527248\n",
      "Epoch 2624, Loss: 1.582675045618089, Final Batch Loss: 0.00021884430316276848\n",
      "Epoch 2625, Loss: 1.9660668969154358, Final Batch Loss: 0.3275686502456665\n",
      "Epoch 2626, Loss: 1.5936230218503624, Final Batch Loss: 0.0016314780805259943\n",
      "Epoch 2627, Loss: 2.567456603050232, Final Batch Loss: 0.9102824926376343\n",
      "Epoch 2628, Loss: 1.5787174310535192, Final Batch Loss: 0.024418195709586143\n",
      "Epoch 2629, Loss: 1.6200140472501516, Final Batch Loss: 0.018700366839766502\n",
      "Epoch 2630, Loss: 3.2882019877433777, Final Batch Loss: 1.6302196979522705\n",
      "Epoch 2631, Loss: 2.339673101902008, Final Batch Loss: 0.674731433391571\n",
      "Epoch 2632, Loss: 1.5863949032500386, Final Batch Loss: 0.004958000965416431\n",
      "Epoch 2633, Loss: 1.6206673430278897, Final Batch Loss: 0.0033971713855862617\n",
      "Epoch 2634, Loss: 1.9851548373699188, Final Batch Loss: 0.32661888003349304\n",
      "Epoch 2635, Loss: 1.6555682197213173, Final Batch Loss: 0.04126954823732376\n",
      "Epoch 2636, Loss: 2.58771288394928, Final Batch Loss: 0.945231556892395\n",
      "Epoch 2637, Loss: 1.6566143035888672, Final Batch Loss: 0.021704524755477905\n",
      "Epoch 2638, Loss: 1.614412423223257, Final Batch Loss: 0.0475446842610836\n",
      "Epoch 2639, Loss: 1.7192151919007301, Final Batch Loss: 0.0904800072312355\n",
      "Epoch 2640, Loss: 1.741051998542389, Final Batch Loss: 0.00025674383505247533\n",
      "Epoch 2641, Loss: 2.7316323816776276, Final Batch Loss: 1.105951189994812\n",
      "Epoch 2642, Loss: 1.93931046128273, Final Batch Loss: 0.30874350666999817\n",
      "Epoch 2643, Loss: 1.6617117673158646, Final Batch Loss: 0.009350672364234924\n",
      "Epoch 2644, Loss: 1.854283332824707, Final Batch Loss: 0.1992741823196411\n",
      "Epoch 2645, Loss: 1.6432511322200298, Final Batch Loss: 0.05351145192980766\n",
      "Epoch 2646, Loss: 1.7219656258821487, Final Batch Loss: 0.0871286541223526\n",
      "Epoch 2647, Loss: 1.6118517713621259, Final Batch Loss: 0.01043247152119875\n",
      "Epoch 2648, Loss: 2.837022751569748, Final Batch Loss: 1.2774138450622559\n",
      "Epoch 2649, Loss: 1.5519052445888448, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2650, Loss: 3.28872549533844, Final Batch Loss: 1.7058393955230713\n",
      "Epoch 2651, Loss: 3.1100699305534363, Final Batch Loss: 1.5200705528259277\n",
      "Epoch 2652, Loss: 1.6002670880407095, Final Batch Loss: 0.014610325917601585\n",
      "Epoch 2653, Loss: 3.4289026260375977, Final Batch Loss: 1.817260980606079\n",
      "Epoch 2654, Loss: 1.6486630546860397, Final Batch Loss: 0.0024114358238875866\n",
      "Epoch 2655, Loss: 1.7678429698571563, Final Batch Loss: 0.014582953415811062\n",
      "Epoch 2656, Loss: 1.757270603615325, Final Batch Loss: 0.0009461931767873466\n",
      "Epoch 2657, Loss: 3.9263839721679688, Final Batch Loss: 2.2027437686920166\n",
      "Epoch 2658, Loss: 1.6913343109190464, Final Batch Loss: 0.05994919314980507\n",
      "Epoch 2659, Loss: 1.5655947141349316, Final Batch Loss: 0.035209041088819504\n",
      "Epoch 2660, Loss: 3.373615115880966, Final Batch Loss: 1.7988368272781372\n",
      "Epoch 2661, Loss: 5.304628074169159, Final Batch Loss: 3.684523105621338\n",
      "Epoch 2662, Loss: 3.9820180237293243, Final Batch Loss: 2.3900489807128906\n",
      "Epoch 2663, Loss: 3.016418367624283, Final Batch Loss: 1.3856899738311768\n",
      "Epoch 2664, Loss: 1.909693542867899, Final Batch Loss: 0.0396735705435276\n",
      "Epoch 2665, Loss: 1.9252185672521591, Final Batch Loss: 0.04919444024562836\n",
      "Epoch 2666, Loss: 2.0460903644561768, Final Batch Loss: 0.17607063055038452\n",
      "Epoch 2667, Loss: 1.9499440342187881, Final Batch Loss: 0.08035619556903839\n",
      "Epoch 2668, Loss: 2.529727578163147, Final Batch Loss: 0.7764625549316406\n",
      "Epoch 2669, Loss: 3.259262651205063, Final Batch Loss: 1.5806541442871094\n",
      "Epoch 2670, Loss: 2.7593865990638733, Final Batch Loss: 1.068658471107483\n",
      "Epoch 2671, Loss: 1.6734102610498667, Final Batch Loss: 0.02082284726202488\n",
      "Epoch 2672, Loss: 4.86759489774704, Final Batch Loss: 3.1446433067321777\n",
      "Epoch 2673, Loss: 1.7335831075906754, Final Batch Loss: 0.1455504149198532\n",
      "Epoch 2674, Loss: 1.8139993324875832, Final Batch Loss: 0.11931917816400528\n",
      "Epoch 2675, Loss: 1.664109870151151, Final Batch Loss: 0.00017629499780014157\n",
      "Epoch 2676, Loss: 1.7488409439101815, Final Batch Loss: 0.013713196851313114\n",
      "Epoch 2677, Loss: 1.797173149883747, Final Batch Loss: 0.09880245476961136\n",
      "Epoch 2678, Loss: 1.7033974342048168, Final Batch Loss: 0.04070533439517021\n",
      "Epoch 2679, Loss: 1.8349545300006866, Final Batch Loss: 0.13636907935142517\n",
      "Epoch 2680, Loss: 1.713874138891697, Final Batch Loss: 0.04604146629571915\n",
      "Epoch 2681, Loss: 1.9198309183120728, Final Batch Loss: 0.291658878326416\n",
      "Epoch 2682, Loss: 1.7165056641679257, Final Batch Loss: 0.001881259260699153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2683, Loss: 2.886770188808441, Final Batch Loss: 1.3749700784683228\n",
      "Epoch 2684, Loss: 1.6812380328774452, Final Batch Loss: 0.04952622205018997\n",
      "Epoch 2685, Loss: 1.8568074703216553, Final Batch Loss: 0.24885621666908264\n",
      "Epoch 2686, Loss: 1.9476641118526459, Final Batch Loss: 0.3251473009586334\n",
      "Epoch 2687, Loss: 1.8720249980688095, Final Batch Loss: 0.23036496341228485\n",
      "Epoch 2688, Loss: 1.5874078953638673, Final Batch Loss: 0.013350614346563816\n",
      "Epoch 2689, Loss: 3.3977907299995422, Final Batch Loss: 1.719240665435791\n",
      "Epoch 2690, Loss: 1.7038307506591082, Final Batch Loss: 0.018316062167286873\n",
      "Epoch 2691, Loss: 1.6667068898677826, Final Batch Loss: 0.015695959329605103\n",
      "Epoch 2692, Loss: 3.5949719548225403, Final Batch Loss: 2.045450448989868\n",
      "Epoch 2693, Loss: 1.6587558761239052, Final Batch Loss: 0.06757301837205887\n",
      "Epoch 2694, Loss: 1.5902301266323775, Final Batch Loss: 0.000144709600135684\n",
      "Epoch 2695, Loss: 2.019129067659378, Final Batch Loss: 0.31761476397514343\n",
      "Epoch 2696, Loss: 1.999231219291687, Final Batch Loss: 0.33300453424453735\n",
      "Epoch 2697, Loss: 1.6401473766891286, Final Batch Loss: 0.0011547094909474254\n",
      "Epoch 2698, Loss: 1.6558215618132408, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2699, Loss: 2.065487802028656, Final Batch Loss: 0.48747989535331726\n",
      "Epoch 2700, Loss: 1.6883257701992989, Final Batch Loss: 0.0351717546582222\n",
      "Epoch 2701, Loss: 2.3733562529087067, Final Batch Loss: 0.8121891021728516\n",
      "Epoch 2702, Loss: 1.839802771806717, Final Batch Loss: 0.22870078682899475\n",
      "Epoch 2703, Loss: 3.1660017669200897, Final Batch Loss: 1.6129060983657837\n",
      "Epoch 2704, Loss: 1.937679409980774, Final Batch Loss: 0.3184335231781006\n",
      "Epoch 2705, Loss: 2.098539173603058, Final Batch Loss: 0.5420737862586975\n",
      "Epoch 2706, Loss: 1.6692498717457056, Final Batch Loss: 0.024628737941384315\n",
      "Epoch 2707, Loss: 1.7208188157528639, Final Batch Loss: 0.00919252447783947\n",
      "Epoch 2708, Loss: 2.1870442032814026, Final Batch Loss: 0.5417681932449341\n",
      "Epoch 2709, Loss: 3.5307830572128296, Final Batch Loss: 1.8581128120422363\n",
      "Epoch 2710, Loss: 1.6033348646014929, Final Batch Loss: 0.02508770488202572\n",
      "Epoch 2711, Loss: 1.6047203476118739, Final Batch Loss: 0.0001137191939051263\n",
      "Epoch 2712, Loss: 1.8746894598007202, Final Batch Loss: 0.2677697539329529\n",
      "Epoch 2713, Loss: 3.2938926815986633, Final Batch Loss: 1.6798393726348877\n",
      "Epoch 2714, Loss: 2.0036148726940155, Final Batch Loss: 0.29811784625053406\n",
      "Epoch 2715, Loss: 3.4995360374450684, Final Batch Loss: 1.5412064790725708\n",
      "Epoch 2716, Loss: 2.3890029825270176, Final Batch Loss: 0.02740037813782692\n",
      "Epoch 2717, Loss: 2.6320900319551583, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 2718, Loss: 3.926889181137085, Final Batch Loss: 1.6524897813796997\n",
      "Epoch 2719, Loss: 2.0143248655367643, Final Batch Loss: 0.0033033110667020082\n",
      "Epoch 2720, Loss: 2.213388219475746, Final Batch Loss: 0.18548031151294708\n",
      "Epoch 2721, Loss: 1.8245479706674814, Final Batch Loss: 0.01564725674688816\n",
      "Epoch 2722, Loss: 1.8154377862811089, Final Batch Loss: 0.048182420432567596\n",
      "Epoch 2723, Loss: 1.899504542350769, Final Batch Loss: 0.04832577705383301\n",
      "Epoch 2724, Loss: 1.9541558772325516, Final Batch Loss: 0.19021184742450714\n",
      "Epoch 2725, Loss: 2.096962094306946, Final Batch Loss: 0.23139190673828125\n",
      "Epoch 2726, Loss: 1.938189510256052, Final Batch Loss: 0.01560312882065773\n",
      "Epoch 2727, Loss: 1.8865132331848145, Final Batch Loss: 0.009192287921905518\n",
      "Epoch 2728, Loss: 2.416648507118225, Final Batch Loss: 0.793643593788147\n",
      "Epoch 2729, Loss: 2.714689612388611, Final Batch Loss: 0.9701629281044006\n",
      "Epoch 2730, Loss: 1.6666278117336333, Final Batch Loss: 0.00015853578224778175\n",
      "Epoch 2731, Loss: 2.196069449186325, Final Batch Loss: 0.42559871077537537\n",
      "Epoch 2732, Loss: 1.7362242685630918, Final Batch Loss: 0.011405621655285358\n",
      "Epoch 2733, Loss: 1.8119020015001297, Final Batch Loss: 0.1274672895669937\n",
      "Epoch 2734, Loss: 1.6304244324564934, Final Batch Loss: 0.015634112060070038\n",
      "Epoch 2735, Loss: 1.6726119788363576, Final Batch Loss: 0.006754186935722828\n",
      "Epoch 2736, Loss: 1.6689277030527592, Final Batch Loss: 0.02103099599480629\n",
      "Epoch 2737, Loss: 1.7223992459475994, Final Batch Loss: 0.03593818470835686\n",
      "Epoch 2738, Loss: 2.263732761144638, Final Batch Loss: 0.6356974244117737\n",
      "Epoch 2739, Loss: 1.656054456718266, Final Batch Loss: 0.003929157741367817\n",
      "Epoch 2740, Loss: 1.668747190386057, Final Batch Loss: 0.02727672830224037\n",
      "Epoch 2741, Loss: 1.7609289418905973, Final Batch Loss: 0.020131899043917656\n",
      "Epoch 2742, Loss: 2.2173343300819397, Final Batch Loss: 0.5164915919303894\n",
      "Epoch 2743, Loss: 3.871004283428192, Final Batch Loss: 2.277132749557495\n",
      "Epoch 2744, Loss: 1.7610962614417076, Final Batch Loss: 0.10662823170423508\n",
      "Epoch 2745, Loss: 2.5520634055137634, Final Batch Loss: 0.8900390863418579\n",
      "Epoch 2746, Loss: 1.6593180112540722, Final Batch Loss: 0.05736808106303215\n",
      "Epoch 2747, Loss: 1.6388144409283996, Final Batch Loss: 0.013740829192101955\n",
      "Epoch 2748, Loss: 1.7048719972372055, Final Batch Loss: 0.09187258780002594\n",
      "Epoch 2749, Loss: 1.6954791247844696, Final Batch Loss: 0.050659388303756714\n",
      "Epoch 2750, Loss: 3.0115219950675964, Final Batch Loss: 1.3826673030853271\n",
      "Epoch 2751, Loss: 1.7175785526633263, Final Batch Loss: 0.11654015630483627\n",
      "Epoch 2752, Loss: 2.793862998485565, Final Batch Loss: 1.1635968685150146\n",
      "Epoch 2753, Loss: 1.7567338719964027, Final Batch Loss: 0.03468964248895645\n",
      "Epoch 2754, Loss: 1.9666418731212616, Final Batch Loss: 0.2621047794818878\n",
      "Epoch 2755, Loss: 1.700014054775238, Final Batch Loss: 0.06473904848098755\n",
      "Epoch 2756, Loss: 2.5223475098609924, Final Batch Loss: 0.8737318515777588\n",
      "Epoch 2757, Loss: 3.0718986690044403, Final Batch Loss: 1.4497640132904053\n",
      "Epoch 2758, Loss: 1.7583549544215202, Final Batch Loss: 0.05961894243955612\n",
      "Epoch 2759, Loss: 3.5199832916259766, Final Batch Loss: 1.9200655221939087\n",
      "Epoch 2760, Loss: 1.559146416373551, Final Batch Loss: 0.010886442847549915\n",
      "Epoch 2761, Loss: 1.6753089800477028, Final Batch Loss: 0.06588301807641983\n",
      "Epoch 2762, Loss: 1.9248951971530914, Final Batch Loss: 0.3722682297229767\n",
      "Epoch 2763, Loss: 1.5990499220788479, Final Batch Loss: 0.05769243463873863\n",
      "Epoch 2764, Loss: 1.688721388578415, Final Batch Loss: 0.08353358507156372\n",
      "Epoch 2765, Loss: 1.8791177570819855, Final Batch Loss: 0.2589793801307678\n",
      "Epoch 2766, Loss: 1.5676913405768573, Final Batch Loss: 0.005505755078047514\n",
      "Epoch 2767, Loss: 3.3996790647506714, Final Batch Loss: 1.8304400444030762\n",
      "Epoch 2768, Loss: 1.734268682077527, Final Batch Loss: 0.015760736539959908\n",
      "Epoch 2769, Loss: 1.5945948418229818, Final Batch Loss: 0.011573201045393944\n",
      "Epoch 2770, Loss: 1.6303835958242416, Final Batch Loss: 0.020451620221138\n",
      "Epoch 2771, Loss: 2.3639849424362183, Final Batch Loss: 0.7055405378341675\n",
      "Epoch 2772, Loss: 1.6429065242409706, Final Batch Loss: 0.0915142074227333\n",
      "Epoch 2773, Loss: 3.7983403503894806, Final Batch Loss: 2.2927374839782715\n",
      "Epoch 2774, Loss: 1.9758004248142242, Final Batch Loss: 0.30593571066856384\n",
      "Epoch 2775, Loss: 2.876962661743164, Final Batch Loss: 1.2303730249404907\n",
      "Epoch 2776, Loss: 2.4178141355514526, Final Batch Loss: 0.6656568646430969\n",
      "Epoch 2777, Loss: 1.6335542723536491, Final Batch Loss: 0.03171517699956894\n",
      "Epoch 2778, Loss: 3.1909975111484528, Final Batch Loss: 1.5895190238952637\n",
      "Epoch 2779, Loss: 2.0949215590953827, Final Batch Loss: 0.4543440043926239\n",
      "Epoch 2780, Loss: 2.2231603264808655, Final Batch Loss: 0.47807496786117554\n",
      "Epoch 2781, Loss: 1.6437278669327497, Final Batch Loss: 0.01527210883796215\n",
      "Epoch 2782, Loss: 3.3442123234272003, Final Batch Loss: 1.7982230186462402\n",
      "Epoch 2783, Loss: 1.645170258358121, Final Batch Loss: 0.010724173858761787\n",
      "Epoch 2784, Loss: 1.7886318415403366, Final Batch Loss: 0.0677521675825119\n",
      "Epoch 2785, Loss: 2.7095564007759094, Final Batch Loss: 1.044354796409607\n",
      "Epoch 2786, Loss: 1.5230657474603504, Final Batch Loss: 0.003300340613350272\n",
      "Epoch 2787, Loss: 2.4651175439357758, Final Batch Loss: 0.9115071296691895\n",
      "Epoch 2788, Loss: 1.6076890528202057, Final Batch Loss: 0.017903625965118408\n",
      "Epoch 2789, Loss: 1.599423629231751, Final Batch Loss: 0.013153803534805775\n",
      "Epoch 2790, Loss: 1.5694629810750484, Final Batch Loss: 0.031339194625616074\n",
      "Epoch 2791, Loss: 2.8748141825199127, Final Batch Loss: 1.2825357913970947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2792, Loss: 1.5312412414932624, Final Batch Loss: 0.0006406639004126191\n",
      "Epoch 2793, Loss: 1.5576916672289371, Final Batch Loss: 0.02197161689400673\n",
      "Epoch 2794, Loss: 1.5958061192650348, Final Batch Loss: 0.0027725372929126024\n",
      "Epoch 2795, Loss: 3.9805458188056946, Final Batch Loss: 2.4529199600219727\n",
      "Epoch 2796, Loss: 3.1769351959228516, Final Batch Loss: 1.6260005235671997\n",
      "Epoch 2797, Loss: 2.014836013317108, Final Batch Loss: 0.35475969314575195\n",
      "Epoch 2798, Loss: 1.7129557782318443, Final Batch Loss: 0.0019189768936485052\n",
      "Epoch 2799, Loss: 1.6590757919475436, Final Batch Loss: 0.007093365304172039\n",
      "Epoch 2800, Loss: 1.8151678889989853, Final Batch Loss: 0.17433224618434906\n",
      "Epoch 2801, Loss: 1.8811967074871063, Final Batch Loss: 0.14199206233024597\n",
      "Epoch 2802, Loss: 2.4892354607582092, Final Batch Loss: 0.8207519054412842\n",
      "Epoch 2803, Loss: 2.279348611831665, Final Batch Loss: 0.6070418357849121\n",
      "Epoch 2804, Loss: 3.133146047592163, Final Batch Loss: 1.5409411191940308\n",
      "Epoch 2805, Loss: 2.1484104990959167, Final Batch Loss: 0.46520763635635376\n",
      "Epoch 2806, Loss: 1.8145704083144665, Final Batch Loss: 0.008852403610944748\n",
      "Epoch 2807, Loss: 1.8163113748305477, Final Batch Loss: 0.0006677066558040679\n",
      "Epoch 2808, Loss: 2.3359557390213013, Final Batch Loss: 0.6323025822639465\n",
      "Epoch 2809, Loss: 2.5770740807056427, Final Batch Loss: 1.0251877307891846\n",
      "Epoch 2810, Loss: 4.608596324920654, Final Batch Loss: 2.9358768463134766\n",
      "Epoch 2811, Loss: 2.6610515117645264, Final Batch Loss: 1.1519582271575928\n",
      "Epoch 2812, Loss: 1.523158929310739, Final Batch Loss: 0.00988056417554617\n",
      "Epoch 2813, Loss: 2.3294187784194946, Final Batch Loss: 0.7061820030212402\n",
      "Epoch 2814, Loss: 1.9806981682777405, Final Batch Loss: 0.39651957154273987\n",
      "Epoch 2815, Loss: 1.8619590997695923, Final Batch Loss: 0.25469180941581726\n",
      "Epoch 2816, Loss: 1.6687717434779188, Final Batch Loss: 2.4318398573086597e-05\n",
      "Epoch 2817, Loss: 3.2421493530273438, Final Batch Loss: 1.6529812812805176\n",
      "Epoch 2818, Loss: 1.6174700511619449, Final Batch Loss: 0.009750242345035076\n",
      "Epoch 2819, Loss: 3.941698580980301, Final Batch Loss: 2.2847559452056885\n",
      "Epoch 2820, Loss: 1.7016658075153828, Final Batch Loss: 0.0389934666454792\n",
      "Epoch 2821, Loss: 4.050810605287552, Final Batch Loss: 2.4004597663879395\n",
      "Epoch 2822, Loss: 1.6179538359865546, Final Batch Loss: 0.01483186986297369\n",
      "Epoch 2823, Loss: 1.873167859390378, Final Batch Loss: 0.013903902843594551\n",
      "Epoch 2824, Loss: 5.3112804889678955, Final Batch Loss: 3.081566333770752\n",
      "Epoch 2825, Loss: 3.309959828853607, Final Batch Loss: 1.2858190536499023\n",
      "Epoch 2826, Loss: 1.7501857802271843, Final Batch Loss: 0.07942479103803635\n",
      "Epoch 2827, Loss: 2.1980522871017456, Final Batch Loss: 0.6016201972961426\n",
      "Epoch 2828, Loss: 2.710270345211029, Final Batch Loss: 0.9345834851264954\n",
      "Epoch 2829, Loss: 3.5316370725631714, Final Batch Loss: 1.85183846950531\n",
      "Epoch 2830, Loss: 2.354117691516876, Final Batch Loss: 0.7180898785591125\n",
      "Epoch 2831, Loss: 2.6759350299835205, Final Batch Loss: 0.9956456422805786\n",
      "Epoch 2832, Loss: 2.291086196899414, Final Batch Loss: 0.5692296028137207\n",
      "Epoch 2833, Loss: 1.8055690936744213, Final Batch Loss: 0.025249402970075607\n",
      "Epoch 2834, Loss: 3.1957274079322815, Final Batch Loss: 1.2696646451950073\n",
      "Epoch 2835, Loss: 1.8193030543625355, Final Batch Loss: 0.03213419392704964\n",
      "Epoch 2836, Loss: 1.7561188339168439, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 2837, Loss: 2.166507840156555, Final Batch Loss: 0.4587901830673218\n",
      "Epoch 2838, Loss: 1.6816607294604182, Final Batch Loss: 0.0031571565195918083\n",
      "Epoch 2839, Loss: 2.8070815205574036, Final Batch Loss: 1.1590425968170166\n",
      "Epoch 2840, Loss: 1.8230291455984116, Final Batch Loss: 0.17504827678203583\n",
      "Epoch 2841, Loss: 1.7308048689737916, Final Batch Loss: 0.002095409668982029\n",
      "Epoch 2842, Loss: 1.8118553906679153, Final Batch Loss: 0.13040335476398468\n",
      "Epoch 2843, Loss: 2.1976596415042877, Final Batch Loss: 0.47369328141212463\n",
      "Epoch 2844, Loss: 1.5906676263548434, Final Batch Loss: 0.000985375139862299\n",
      "Epoch 2845, Loss: 3.047928214073181, Final Batch Loss: 1.3990296125411987\n",
      "Epoch 2846, Loss: 3.4482852816581726, Final Batch Loss: 1.808188557624817\n",
      "Epoch 2847, Loss: 1.72512698918581, Final Batch Loss: 0.0695849135518074\n",
      "Epoch 2848, Loss: 3.9761080741882324, Final Batch Loss: 2.291562080383301\n",
      "Epoch 2849, Loss: 3.1743715405464172, Final Batch Loss: 1.5608494281768799\n",
      "Epoch 2850, Loss: 2.0896176993846893, Final Batch Loss: 0.3803040087223053\n",
      "Epoch 2851, Loss: 1.7494259690865874, Final Batch Loss: 0.01107992883771658\n",
      "Epoch 2852, Loss: 1.8792854504063143, Final Batch Loss: 9.321732068201527e-05\n",
      "Epoch 2853, Loss: 1.917095273733139, Final Batch Loss: 0.02259078621864319\n",
      "Epoch 2854, Loss: 2.9936651587486267, Final Batch Loss: 1.1795519590377808\n",
      "Epoch 2855, Loss: 1.7687812596559525, Final Batch Loss: 0.020335987210273743\n",
      "Epoch 2856, Loss: 5.018034517765045, Final Batch Loss: 3.344238519668579\n",
      "Epoch 2857, Loss: 3.097715198993683, Final Batch Loss: 1.4223194122314453\n",
      "Epoch 2858, Loss: 2.0042748749256134, Final Batch Loss: 0.2670431435108185\n",
      "Epoch 2859, Loss: 1.7934119328856468, Final Batch Loss: 0.07343610376119614\n",
      "Epoch 2860, Loss: 2.9975967705249786, Final Batch Loss: 1.3106579780578613\n",
      "Epoch 2861, Loss: 1.7125083208084106, Final Batch Loss: 0.10388436913490295\n",
      "Epoch 2862, Loss: 1.6718494268134236, Final Batch Loss: 0.007340011186897755\n",
      "Epoch 2863, Loss: 1.7784365564584732, Final Batch Loss: 0.1602933555841446\n",
      "Epoch 2864, Loss: 1.6926674544811249, Final Batch Loss: 0.08160749077796936\n",
      "Epoch 2865, Loss: 1.6087608151137829, Final Batch Loss: 0.004395585507154465\n",
      "Epoch 2866, Loss: 2.753847986459732, Final Batch Loss: 1.1609013080596924\n",
      "Epoch 2867, Loss: 2.210010528564453, Final Batch Loss: 0.591156005859375\n",
      "Epoch 2868, Loss: 2.349320113658905, Final Batch Loss: 0.7653202414512634\n",
      "Epoch 2869, Loss: 1.594989014789462, Final Batch Loss: 0.0079811941832304\n",
      "Epoch 2870, Loss: 1.6323135793209076, Final Batch Loss: 0.042975932359695435\n",
      "Epoch 2871, Loss: 1.7310894131660461, Final Batch Loss: 0.08161342144012451\n",
      "Epoch 2872, Loss: 1.9003732800483704, Final Batch Loss: 0.3142702281475067\n",
      "Epoch 2873, Loss: 1.876383513212204, Final Batch Loss: 0.23694631457328796\n",
      "Epoch 2874, Loss: 3.154580771923065, Final Batch Loss: 1.467109203338623\n",
      "Epoch 2875, Loss: 1.8310072422027588, Final Batch Loss: 0.20085793733596802\n",
      "Epoch 2876, Loss: 3.294966071844101, Final Batch Loss: 1.6975802183151245\n",
      "Epoch 2877, Loss: 1.7272601015865803, Final Batch Loss: 0.05703585222363472\n",
      "Epoch 2878, Loss: 3.150192677974701, Final Batch Loss: 1.4189027547836304\n",
      "Epoch 2879, Loss: 1.6651668902486563, Final Batch Loss: 0.018868600949645042\n",
      "Epoch 2880, Loss: 1.7269628420472145, Final Batch Loss: 0.026863910257816315\n",
      "Epoch 2881, Loss: 1.613163589965552, Final Batch Loss: 0.002341031562536955\n",
      "Epoch 2882, Loss: 1.6969808069989085, Final Batch Loss: 0.0024023978039622307\n",
      "Epoch 2883, Loss: 2.5095736980438232, Final Batch Loss: 0.9217353463172913\n",
      "Epoch 2884, Loss: 2.584643542766571, Final Batch Loss: 0.9895212054252625\n",
      "Epoch 2885, Loss: 1.7027216008864343, Final Batch Loss: 0.005822246428579092\n",
      "Epoch 2886, Loss: 3.7129937410354614, Final Batch Loss: 2.035046100616455\n",
      "Epoch 2887, Loss: 2.051488608121872, Final Batch Loss: 0.36375531554222107\n",
      "Epoch 2888, Loss: 3.273829221725464, Final Batch Loss: 1.6425902843475342\n",
      "Epoch 2889, Loss: 1.6439724350348115, Final Batch Loss: 0.008597620762884617\n",
      "Epoch 2890, Loss: 5.0215535163879395, Final Batch Loss: 3.3535561561584473\n",
      "Epoch 2891, Loss: 2.3918651938438416, Final Batch Loss: 0.7164008021354675\n",
      "Epoch 2892, Loss: 2.523490309715271, Final Batch Loss: 0.6672009825706482\n",
      "Epoch 2893, Loss: 2.0250539761036634, Final Batch Loss: 0.0010933857411146164\n",
      "Epoch 2894, Loss: 9.840726733207703, Final Batch Loss: 7.889403820037842\n",
      "Epoch 2895, Loss: 1.8906794339418411, Final Batch Loss: 0.1832045465707779\n",
      "Epoch 2896, Loss: 2.107688933610916, Final Batch Loss: 0.5013086795806885\n",
      "Epoch 2897, Loss: 2.3512982726097107, Final Batch Loss: 0.6697160005569458\n",
      "Epoch 2898, Loss: 1.737203000113368, Final Batch Loss: 0.005604980513453484\n",
      "Epoch 2899, Loss: 1.7931833360344172, Final Batch Loss: 0.031063267961144447\n",
      "Epoch 2900, Loss: 3.4030284583568573, Final Batch Loss: 1.7712030410766602\n",
      "Epoch 2901, Loss: 1.7610023077577353, Final Batch Loss: 0.015757685527205467\n",
      "Epoch 2902, Loss: 1.7377117034047842, Final Batch Loss: 0.020479535683989525\n",
      "Epoch 2903, Loss: 3.0123096704483032, Final Batch Loss: 1.2695235013961792\n",
      "Epoch 2904, Loss: 3.0264646410942078, Final Batch Loss: 1.2437844276428223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2905, Loss: 2.9571824073791504, Final Batch Loss: 1.2481008768081665\n",
      "Epoch 2906, Loss: 2.559226840734482, Final Batch Loss: 0.8195732831954956\n",
      "Epoch 2907, Loss: 1.9433328062295914, Final Batch Loss: 0.16614307463169098\n",
      "Epoch 2908, Loss: 3.251643478870392, Final Batch Loss: 1.484005331993103\n",
      "Epoch 2909, Loss: 1.8516247123479843, Final Batch Loss: 0.19028161466121674\n",
      "Epoch 2910, Loss: 1.7428936939686537, Final Batch Loss: 0.01691955141723156\n",
      "Epoch 2911, Loss: 1.7341130374825298, Final Batch Loss: 1.4424220353248529e-05\n",
      "Epoch 2912, Loss: 2.5336660742759705, Final Batch Loss: 0.883042573928833\n",
      "Epoch 2913, Loss: 1.7227879879064858, Final Batch Loss: 0.006921481806784868\n",
      "Epoch 2914, Loss: 2.8513281047344208, Final Batch Loss: 1.262812614440918\n",
      "Epoch 2915, Loss: 7.87310516834259, Final Batch Loss: 6.259061813354492\n",
      "Epoch 2916, Loss: 4.670542120933533, Final Batch Loss: 3.0129899978637695\n",
      "Epoch 2917, Loss: 1.8292850442230701, Final Batch Loss: 0.06131865456700325\n",
      "Epoch 2918, Loss: 1.766466535627842, Final Batch Loss: 0.02120397239923477\n",
      "Epoch 2919, Loss: 2.294441521167755, Final Batch Loss: 0.3612253665924072\n",
      "Epoch 2920, Loss: 2.013427935540676, Final Batch Loss: 0.0792526826262474\n",
      "Epoch 2921, Loss: 2.3109030723571777, Final Batch Loss: 0.5315316915512085\n",
      "Epoch 2922, Loss: 1.9434088133275509, Final Batch Loss: 0.03206273540854454\n",
      "Epoch 2923, Loss: 1.815547034071642, Final Batch Loss: 0.00017307691450696439\n",
      "Epoch 2924, Loss: 3.176082134246826, Final Batch Loss: 1.278548002243042\n",
      "Epoch 2925, Loss: 1.8353362083428237, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2926, Loss: 2.515578269958496, Final Batch Loss: 0.7349801659584045\n",
      "Epoch 2927, Loss: 1.9911488741636276, Final Batch Loss: 0.22738991677761078\n",
      "Epoch 2928, Loss: 3.5723955631256104, Final Batch Loss: 1.9600151777267456\n",
      "Epoch 2929, Loss: 2.9132646918296814, Final Batch Loss: 1.2064878940582275\n",
      "Epoch 2930, Loss: 1.7492633229121566, Final Batch Loss: 0.0022734766826033592\n",
      "Epoch 2931, Loss: 1.914233237504959, Final Batch Loss: 0.21883541345596313\n",
      "Epoch 2932, Loss: 2.7027814984321594, Final Batch Loss: 1.033414363861084\n",
      "Epoch 2933, Loss: 4.2879891991615295, Final Batch Loss: 2.533824920654297\n",
      "Epoch 2934, Loss: 3.115514039993286, Final Batch Loss: 1.4441139698028564\n",
      "Epoch 2935, Loss: 1.8437031731009483, Final Batch Loss: 0.08361264318227768\n",
      "Epoch 2936, Loss: 3.1750450134277344, Final Batch Loss: 1.1155376434326172\n",
      "Epoch 2937, Loss: 2.3236559629440308, Final Batch Loss: 0.39573198556900024\n",
      "Epoch 2938, Loss: 6.058921635150909, Final Batch Loss: 4.143779277801514\n",
      "Epoch 2939, Loss: 4.262163937091827, Final Batch Loss: 2.3554162979125977\n",
      "Epoch 2940, Loss: 1.8542004143819213, Final Batch Loss: 0.010789862833917141\n",
      "Epoch 2941, Loss: 3.32333242893219, Final Batch Loss: 1.534354567527771\n",
      "Epoch 2942, Loss: 1.986176922917366, Final Batch Loss: 0.08190365135669708\n",
      "Epoch 2943, Loss: 1.8384133540093899, Final Batch Loss: 0.0420030914247036\n",
      "Epoch 2944, Loss: 1.9165148064494133, Final Batch Loss: 0.0999901220202446\n",
      "Epoch 2945, Loss: 1.7937862519174814, Final Batch Loss: 0.02100052870810032\n",
      "Epoch 2946, Loss: 1.7574998335912824, Final Batch Loss: 0.012797256000339985\n",
      "Epoch 2947, Loss: 1.952672928571701, Final Batch Loss: 0.2715355455875397\n",
      "Epoch 2948, Loss: 1.7494343500584364, Final Batch Loss: 0.015464512631297112\n",
      "Epoch 2949, Loss: 1.995260238647461, Final Batch Loss: 0.3070828318595886\n",
      "Epoch 2950, Loss: 2.507293403148651, Final Batch Loss: 0.8972793817520142\n",
      "Epoch 2951, Loss: 1.718513301864732, Final Batch Loss: 0.00036793138133361936\n",
      "Epoch 2952, Loss: 1.8584005907177925, Final Batch Loss: 0.07174289971590042\n",
      "Epoch 2953, Loss: 1.8235603123903275, Final Batch Loss: 0.19556303322315216\n",
      "Epoch 2954, Loss: 2.119546055793762, Final Batch Loss: 0.5078611373901367\n",
      "Epoch 2955, Loss: 1.6587519189342856, Final Batch Loss: 0.013475998304784298\n",
      "Epoch 2956, Loss: 1.90773107111454, Final Batch Loss: 0.18074460327625275\n",
      "Epoch 2957, Loss: 1.6275857340660878, Final Batch Loss: 0.0005546461907215416\n",
      "Epoch 2958, Loss: 1.7536948025226593, Final Batch Loss: 0.17129948735237122\n",
      "Epoch 2959, Loss: 3.3412802517414093, Final Batch Loss: 1.713760495185852\n",
      "Epoch 2960, Loss: 3.6283284723758698, Final Batch Loss: 1.9869285821914673\n",
      "Epoch 2961, Loss: 3.538145363330841, Final Batch Loss: 1.8822129964828491\n",
      "Epoch 2962, Loss: 2.0627274215221405, Final Batch Loss: 0.3951866924762726\n",
      "Epoch 2963, Loss: 3.0532172322273254, Final Batch Loss: 1.3477749824523926\n",
      "Epoch 2964, Loss: 1.8428247775882483, Final Batch Loss: 0.013582786545157433\n",
      "Epoch 2965, Loss: 1.7988256495445967, Final Batch Loss: 0.011401025578379631\n",
      "Epoch 2966, Loss: 2.099420428276062, Final Batch Loss: 0.35080206394195557\n",
      "Epoch 2967, Loss: 2.4742658734321594, Final Batch Loss: 0.7597789168357849\n",
      "Epoch 2968, Loss: 2.6272623538970947, Final Batch Loss: 0.9292939305305481\n",
      "Epoch 2969, Loss: 3.1245182156562805, Final Batch Loss: 1.3785312175750732\n",
      "Epoch 2970, Loss: 1.6659592762589455, Final Batch Loss: 0.09544912725687027\n",
      "Epoch 2971, Loss: 2.737066149711609, Final Batch Loss: 1.07749342918396\n",
      "Epoch 2972, Loss: 1.8042407549219206, Final Batch Loss: 0.0013867533998563886\n",
      "Epoch 2973, Loss: 2.0906597673892975, Final Batch Loss: 0.21134468913078308\n",
      "Epoch 2974, Loss: 2.7250084280967712, Final Batch Loss: 0.843075156211853\n",
      "Epoch 2975, Loss: 3.6800697445869446, Final Batch Loss: 1.7894346714019775\n",
      "Epoch 2976, Loss: 2.83555668592453, Final Batch Loss: 1.106182336807251\n",
      "Epoch 2977, Loss: 1.7881237417459488, Final Batch Loss: 0.10994316637516022\n",
      "Epoch 2978, Loss: 3.351738005876541, Final Batch Loss: 1.7745238542556763\n",
      "Epoch 2979, Loss: 1.626694053400115, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 2980, Loss: 2.997096538543701, Final Batch Loss: 1.3252804279327393\n",
      "Epoch 2981, Loss: 1.7293036319315434, Final Batch Loss: 0.054863009601831436\n",
      "Epoch 2982, Loss: 1.7933998852968216, Final Batch Loss: 0.005861237645149231\n",
      "Epoch 2983, Loss: 1.8136153891682625, Final Batch Loss: 0.041251130402088165\n",
      "Epoch 2984, Loss: 1.6651379223912954, Final Batch Loss: 0.012135481461882591\n",
      "Epoch 2985, Loss: 1.6731465961784124, Final Batch Loss: 0.019968202337622643\n",
      "Epoch 2986, Loss: 1.6982225067913532, Final Batch Loss: 0.02596156671643257\n",
      "Epoch 2987, Loss: 1.672285320237279, Final Batch Loss: 0.023334892466664314\n",
      "Epoch 2988, Loss: 1.7344126254320145, Final Batch Loss: 0.14211203157901764\n",
      "Epoch 2989, Loss: 2.2593802511692047, Final Batch Loss: 0.6973201036453247\n",
      "Epoch 2990, Loss: 1.6695561185479164, Final Batch Loss: 0.07652542740106583\n",
      "Epoch 2991, Loss: 1.6154473926872015, Final Batch Loss: 0.010975232347846031\n",
      "Epoch 2992, Loss: 2.3691931068897247, Final Batch Loss: 0.718264639377594\n",
      "Epoch 2993, Loss: 1.697940825484693, Final Batch Loss: 0.010078846476972103\n",
      "Epoch 2994, Loss: 3.808144062757492, Final Batch Loss: 2.2554116249084473\n",
      "Epoch 2995, Loss: 1.8033569753170013, Final Batch Loss: 0.2347640097141266\n",
      "Epoch 2996, Loss: 3.733562469482422, Final Batch Loss: 2.1109368801116943\n",
      "Epoch 2997, Loss: 1.5473021706566215, Final Batch Loss: 0.013484819792211056\n",
      "Epoch 2998, Loss: 1.5846652869367972, Final Batch Loss: 0.00015186110977083445\n",
      "Epoch 2999, Loss: 1.5590260326821408, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 3000, Loss: 1.532098748954013, Final Batch Loss: 0.0029456105548888445\n",
      "Epoch 3001, Loss: 1.692502148449421, Final Batch Loss: 0.04494328051805496\n",
      "Epoch 3002, Loss: 2.9708787500858307, Final Batch Loss: 1.4019557237625122\n",
      "Epoch 3003, Loss: 1.6090906048193574, Final Batch Loss: 0.010946580208837986\n",
      "Epoch 3004, Loss: 1.613534890115261, Final Batch Loss: 0.04588206857442856\n",
      "Epoch 3005, Loss: 1.6334035694599152, Final Batch Loss: 0.04231509566307068\n",
      "Epoch 3006, Loss: 1.750774621963501, Final Batch Loss: 0.15561604499816895\n",
      "Epoch 3007, Loss: 1.7028257623314857, Final Batch Loss: 0.11166135221719742\n",
      "Epoch 3008, Loss: 3.67962509393692, Final Batch Loss: 2.0629725456237793\n",
      "Epoch 3009, Loss: 1.656738594174385, Final Batch Loss: 0.07183532416820526\n",
      "Epoch 3010, Loss: 1.6687912829220295, Final Batch Loss: 0.03680538013577461\n",
      "Epoch 3011, Loss: 1.6108437501825392, Final Batch Loss: 0.006428989116102457\n",
      "Epoch 3012, Loss: 3.197215735912323, Final Batch Loss: 1.627516746520996\n",
      "Epoch 3013, Loss: 1.8681438118219376, Final Batch Loss: 0.21454931795597076\n",
      "Epoch 3014, Loss: 2.015313744544983, Final Batch Loss: 0.4150943458080292\n",
      "Epoch 3015, Loss: 2.7195452451705933, Final Batch Loss: 1.224045753479004\n",
      "Epoch 3016, Loss: 1.5548745896667242, Final Batch Loss: 0.01800607703626156\n",
      "Epoch 3017, Loss: 1.5468004876747727, Final Batch Loss: 0.014264875091612339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3018, Loss: 1.6480500400066376, Final Batch Loss: 0.13554099202156067\n",
      "Epoch 3019, Loss: 2.2710858583450317, Final Batch Loss: 0.7430738210678101\n",
      "Epoch 3020, Loss: 4.316587924957275, Final Batch Loss: 2.7926506996154785\n",
      "Epoch 3021, Loss: 2.230962812900543, Final Batch Loss: 0.7481117248535156\n",
      "Epoch 3022, Loss: 1.6036331709474325, Final Batch Loss: 0.018736636266112328\n",
      "Epoch 3023, Loss: 1.6601765491068363, Final Batch Loss: 0.04086944833397865\n",
      "Epoch 3024, Loss: 3.1211202144622803, Final Batch Loss: 1.4832454919815063\n",
      "Epoch 3025, Loss: 2.4297727942466736, Final Batch Loss: 0.8061462044715881\n",
      "Epoch 3026, Loss: 3.010327398777008, Final Batch Loss: 1.3629369735717773\n",
      "Epoch 3027, Loss: 1.6035364731797017, Final Batch Loss: 0.0007096394547261298\n",
      "Epoch 3028, Loss: 2.6546047925949097, Final Batch Loss: 1.0309752225875854\n",
      "Epoch 3029, Loss: 1.6746873930096626, Final Batch Loss: 0.08672703057527542\n",
      "Epoch 3030, Loss: 1.6683420985937119, Final Batch Loss: 0.07257838547229767\n",
      "Epoch 3031, Loss: 3.831569254398346, Final Batch Loss: 2.2402565479278564\n",
      "Epoch 3032, Loss: 1.9908832013607025, Final Batch Loss: 0.39305922389030457\n",
      "Epoch 3033, Loss: 1.5950171761214733, Final Batch Loss: 0.019682925194501877\n",
      "Epoch 3034, Loss: 1.6712665483355522, Final Batch Loss: 0.09884046763181686\n",
      "Epoch 3035, Loss: 1.9504000842571259, Final Batch Loss: 0.3386349678039551\n",
      "Epoch 3036, Loss: 3.4053074717521667, Final Batch Loss: 1.8091614246368408\n",
      "Epoch 3037, Loss: 3.15710586309433, Final Batch Loss: 1.623197078704834\n",
      "Epoch 3038, Loss: 1.5601394111290574, Final Batch Loss: 0.00011419598013162613\n",
      "Epoch 3039, Loss: 1.6884925663471222, Final Batch Loss: 0.1582445502281189\n",
      "Epoch 3040, Loss: 1.9504383206367493, Final Batch Loss: 0.40077245235443115\n",
      "Epoch 3041, Loss: 1.9726340174674988, Final Batch Loss: 0.4429767429828644\n",
      "Epoch 3042, Loss: 1.5724226236343384, Final Batch Loss: 0.0241071879863739\n",
      "Epoch 3043, Loss: 1.8146285712718964, Final Batch Loss: 0.25790348649024963\n",
      "Epoch 3044, Loss: 1.938855767250061, Final Batch Loss: 0.374624639749527\n",
      "Epoch 3045, Loss: 1.562184530775994, Final Batch Loss: 0.005418020766228437\n",
      "Epoch 3046, Loss: 3.2538070380687714, Final Batch Loss: 1.7707666158676147\n",
      "Epoch 3047, Loss: 2.341099888086319, Final Batch Loss: 0.7846964001655579\n",
      "Epoch 3048, Loss: 2.4053725004196167, Final Batch Loss: 0.7745431661605835\n",
      "Epoch 3049, Loss: 1.5804508179426193, Final Batch Loss: 0.05852894484996796\n",
      "Epoch 3050, Loss: 4.375104486942291, Final Batch Loss: 2.8407232761383057\n",
      "Epoch 3051, Loss: 1.6887502036988735, Final Batch Loss: 0.05337437614798546\n",
      "Epoch 3052, Loss: 1.7136032953858376, Final Batch Loss: 0.09075743705034256\n",
      "Epoch 3053, Loss: 1.7655226290225983, Final Batch Loss: 0.243098646402359\n",
      "Epoch 3054, Loss: 1.5618369178846478, Final Batch Loss: 0.002609540708363056\n",
      "Epoch 3055, Loss: 2.1777215600013733, Final Batch Loss: 0.6632117033004761\n",
      "Epoch 3056, Loss: 2.8990436494350433, Final Batch Loss: 1.3186482191085815\n",
      "Epoch 3057, Loss: 1.6838672459125519, Final Batch Loss: 0.1281801164150238\n",
      "Epoch 3058, Loss: 1.7329459488391876, Final Batch Loss: 0.20862463116645813\n",
      "Epoch 3059, Loss: 2.3127333521842957, Final Batch Loss: 0.8342552781105042\n",
      "Epoch 3060, Loss: 1.545602886006236, Final Batch Loss: 0.017065702006220818\n",
      "Epoch 3061, Loss: 2.782267242670059, Final Batch Loss: 1.1917674541473389\n",
      "Epoch 3062, Loss: 1.640585407614708, Final Batch Loss: 0.06928341090679169\n",
      "Epoch 3063, Loss: 1.7815923765301704, Final Batch Loss: 0.11262691766023636\n",
      "Epoch 3064, Loss: 3.1545439958572388, Final Batch Loss: 1.5104913711547852\n",
      "Epoch 3065, Loss: 1.7657515167957172, Final Batch Loss: 0.0011132716899737716\n",
      "Epoch 3066, Loss: 1.860736422240734, Final Batch Loss: 0.04824637621641159\n",
      "Epoch 3067, Loss: 1.568220973012103, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 3068, Loss: 1.6155405696481466, Final Batch Loss: 0.0023637469857931137\n",
      "Epoch 3069, Loss: 1.6222211718559265, Final Batch Loss: 0.07781901955604553\n",
      "Epoch 3070, Loss: 1.5946986369126535, Final Batch Loss: 4.029192859889008e-05\n",
      "Epoch 3071, Loss: 1.699761539697647, Final Batch Loss: 0.11066475510597229\n",
      "Epoch 3072, Loss: 1.5358737936476246, Final Batch Loss: 0.0017297795275226235\n",
      "Epoch 3073, Loss: 1.6696296408772469, Final Batch Loss: 0.08588064461946487\n",
      "Epoch 3074, Loss: 1.5306996870785952, Final Batch Loss: 0.0010193157941102982\n",
      "Epoch 3075, Loss: 1.5502973198890402, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3076, Loss: 1.5131922167784069, Final Batch Loss: 0.00046695294440723956\n",
      "Epoch 3077, Loss: 1.5585969612002373, Final Batch Loss: 0.059188030660152435\n",
      "Epoch 3078, Loss: 1.5987948030233383, Final Batch Loss: 0.12791560590267181\n",
      "Epoch 3079, Loss: 2.2431922256946564, Final Batch Loss: 0.703758955001831\n",
      "Epoch 3080, Loss: 1.4942035488784313, Final Batch Loss: 0.021075468510389328\n",
      "Epoch 3081, Loss: 3.372705399990082, Final Batch Loss: 1.870804786682129\n",
      "Epoch 3082, Loss: 1.5103313401341438, Final Batch Loss: 0.0697150006890297\n",
      "Epoch 3083, Loss: 1.5598316262476146, Final Batch Loss: 0.00261429650709033\n",
      "Epoch 3084, Loss: 1.5419852477498353, Final Batch Loss: 0.003940556664019823\n",
      "Epoch 3085, Loss: 3.0914549231529236, Final Batch Loss: 1.5804736614227295\n",
      "Epoch 3086, Loss: 1.7960239052772522, Final Batch Loss: 0.2966894805431366\n",
      "Epoch 3087, Loss: 3.3975290656089783, Final Batch Loss: 1.8605453968048096\n",
      "Epoch 3088, Loss: 1.918404906988144, Final Batch Loss: 0.29019075632095337\n",
      "Epoch 3089, Loss: 1.980416551232338, Final Batch Loss: 0.19375844299793243\n",
      "Epoch 3090, Loss: 1.8133428543806076, Final Batch Loss: 0.1279701441526413\n",
      "Epoch 3091, Loss: 2.3009112179279327, Final Batch Loss: 0.6534633040428162\n",
      "Epoch 3092, Loss: 1.6012031720019877, Final Batch Loss: 0.0021421597339212894\n",
      "Epoch 3093, Loss: 3.8949644565582275, Final Batch Loss: 2.3171565532684326\n",
      "Epoch 3094, Loss: 3.6235105097293854, Final Batch Loss: 2.136481285095215\n",
      "Epoch 3095, Loss: 2.8453211188316345, Final Batch Loss: 1.2956814765930176\n",
      "Epoch 3096, Loss: 1.6777089200913906, Final Batch Loss: 0.0410456620156765\n",
      "Epoch 3097, Loss: 1.7111735790967941, Final Batch Loss: 0.14079777896404266\n",
      "Epoch 3098, Loss: 1.650456887728069, Final Batch Loss: 0.0006725909770466387\n",
      "Epoch 3099, Loss: 1.6255409605801105, Final Batch Loss: 0.03180675581097603\n",
      "Epoch 3100, Loss: 3.3636958599090576, Final Batch Loss: 1.7627193927764893\n",
      "Epoch 3101, Loss: 3.6034805178642273, Final Batch Loss: 2.033304214477539\n",
      "Epoch 3102, Loss: 3.214422285556793, Final Batch Loss: 1.6010510921478271\n",
      "Epoch 3103, Loss: 3.3307478427886963, Final Batch Loss: 1.7049996852874756\n",
      "Epoch 3104, Loss: 1.6015382707118988, Final Batch Loss: 0.03545472025871277\n",
      "Epoch 3105, Loss: 2.2828450202941895, Final Batch Loss: 0.5799453854560852\n",
      "Epoch 3106, Loss: 1.7877705246210098, Final Batch Loss: 0.1439266949892044\n",
      "Epoch 3107, Loss: 1.7565647214651108, Final Batch Loss: 0.1733093112707138\n",
      "Epoch 3108, Loss: 2.981204330921173, Final Batch Loss: 1.4551221132278442\n",
      "Epoch 3109, Loss: 2.5255183577537537, Final Batch Loss: 0.9726060628890991\n",
      "Epoch 3110, Loss: 2.91366970539093, Final Batch Loss: 1.3336148262023926\n",
      "Epoch 3111, Loss: 1.6797139532864094, Final Batch Loss: 0.043719518929719925\n",
      "Epoch 3112, Loss: 2.0004513263702393, Final Batch Loss: 0.351312518119812\n",
      "Epoch 3113, Loss: 1.6223755944520235, Final Batch Loss: 0.02221648581326008\n",
      "Epoch 3114, Loss: 1.6950451476004673, Final Batch Loss: 0.0002261144545627758\n",
      "Epoch 3115, Loss: 1.6884573679417372, Final Batch Loss: 0.013154862448573112\n",
      "Epoch 3116, Loss: 2.458119034767151, Final Batch Loss: 0.9003156423568726\n",
      "Epoch 3117, Loss: 2.4181841015815735, Final Batch Loss: 0.8562681674957275\n",
      "Epoch 3118, Loss: 1.6625546542927623, Final Batch Loss: 0.006057712249457836\n",
      "Epoch 3119, Loss: 3.934045672416687, Final Batch Loss: 2.2051520347595215\n",
      "Epoch 3120, Loss: 2.1818588376045227, Final Batch Loss: 0.5140442848205566\n",
      "Epoch 3121, Loss: 1.8450572490692139, Final Batch Loss: 0.17043852806091309\n",
      "Epoch 3122, Loss: 2.0120444297790527, Final Batch Loss: 0.4770797789096832\n",
      "Epoch 3123, Loss: 2.2463622093200684, Final Batch Loss: 0.6444154977798462\n",
      "Epoch 3124, Loss: 1.7421628087759018, Final Batch Loss: 0.12472926080226898\n",
      "Epoch 3125, Loss: 1.8225407302379608, Final Batch Loss: 0.2349262237548828\n",
      "Epoch 3126, Loss: 1.5837242100387812, Final Batch Loss: 0.02651790715754032\n",
      "Epoch 3127, Loss: 1.6389967016875744, Final Batch Loss: 0.019630324095487595\n",
      "Epoch 3128, Loss: 1.6750059351325035, Final Batch Loss: 0.09322576969861984\n",
      "Epoch 3129, Loss: 1.7968235611915588, Final Batch Loss: 0.2687453627586365\n",
      "Epoch 3130, Loss: 3.8998143672943115, Final Batch Loss: 2.3754537105560303\n",
      "Epoch 3131, Loss: 2.908111870288849, Final Batch Loss: 1.3588929176330566\n",
      "Epoch 3132, Loss: 1.5047575049102306, Final Batch Loss: 0.010763328522443771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3133, Loss: 1.5663215536624193, Final Batch Loss: 0.0254309494048357\n",
      "Epoch 3134, Loss: 2.209234207868576, Final Batch Loss: 0.7088322043418884\n",
      "Epoch 3135, Loss: 2.905051827430725, Final Batch Loss: 1.4222865104675293\n",
      "Epoch 3136, Loss: 1.4028165287163574, Final Batch Loss: 0.00010322991875000298\n",
      "Epoch 3137, Loss: 1.578842056915164, Final Batch Loss: 0.022476447746157646\n",
      "Epoch 3138, Loss: 2.7852123975753784, Final Batch Loss: 1.2542617321014404\n",
      "Epoch 3139, Loss: 4.00297424197197, Final Batch Loss: 2.423832654953003\n",
      "Epoch 3140, Loss: 1.5478678308427334, Final Batch Loss: 0.03273880109190941\n",
      "Epoch 3141, Loss: 3.1572803258895874, Final Batch Loss: 1.5852833986282349\n",
      "Epoch 3142, Loss: 2.0071381330490112, Final Batch Loss: 0.4667019844055176\n",
      "Epoch 3143, Loss: 1.5314975222572684, Final Batch Loss: 0.004960610531270504\n",
      "Epoch 3144, Loss: 1.585311470553279, Final Batch Loss: 0.008367953822016716\n",
      "Epoch 3145, Loss: 1.789801374077797, Final Batch Loss: 0.23020361363887787\n",
      "Epoch 3146, Loss: 1.5160253392532468, Final Batch Loss: 0.0038333283737301826\n",
      "Epoch 3147, Loss: 1.5101472267415375, Final Batch Loss: 0.002020938089117408\n",
      "Epoch 3148, Loss: 1.5282514849677682, Final Batch Loss: 0.003176526166498661\n",
      "Epoch 3149, Loss: 1.660040721297264, Final Batch Loss: 0.11163778603076935\n",
      "Epoch 3150, Loss: 1.508184105156829, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3151, Loss: 2.5242960155010223, Final Batch Loss: 0.951321542263031\n",
      "Epoch 3152, Loss: 1.7854517698287964, Final Batch Loss: 0.32945629954338074\n",
      "Epoch 3153, Loss: 3.30601903796196, Final Batch Loss: 1.756511926651001\n",
      "Epoch 3154, Loss: 1.4698300769669004, Final Batch Loss: 0.0006743779522366822\n",
      "Epoch 3155, Loss: 1.5205157827585936, Final Batch Loss: 0.026500029489398003\n",
      "Epoch 3156, Loss: 2.810835987329483, Final Batch Loss: 1.2647393941879272\n",
      "Epoch 3157, Loss: 1.593158459290862, Final Batch Loss: 0.030246710404753685\n",
      "Epoch 3158, Loss: 1.5679833143949509, Final Batch Loss: 0.13105230033397675\n",
      "Epoch 3159, Loss: 1.592492911964655, Final Batch Loss: 0.04108181968331337\n",
      "Epoch 3160, Loss: 1.5109970578923821, Final Batch Loss: 0.0063267657533288\n",
      "Epoch 3161, Loss: 1.6521537452936172, Final Batch Loss: 0.15675027668476105\n",
      "Epoch 3162, Loss: 2.702176570892334, Final Batch Loss: 1.2193150520324707\n",
      "Epoch 3163, Loss: 1.511321670099278, Final Batch Loss: 0.00021705655672121793\n",
      "Epoch 3164, Loss: 1.654748260974884, Final Batch Loss: 0.07142174243927002\n",
      "Epoch 3165, Loss: 2.5590862035751343, Final Batch Loss: 1.023331880569458\n",
      "Epoch 3166, Loss: 1.5804107240401208, Final Batch Loss: 0.004131948109716177\n",
      "Epoch 3167, Loss: 2.223759412765503, Final Batch Loss: 0.6487054228782654\n",
      "Epoch 3168, Loss: 1.6088148970156908, Final Batch Loss: 0.018689485266804695\n",
      "Epoch 3169, Loss: 1.602333065122366, Final Batch Loss: 0.05123591050505638\n",
      "Epoch 3170, Loss: 1.7795465886592865, Final Batch Loss: 0.2537572383880615\n",
      "Epoch 3171, Loss: 2.6824323534965515, Final Batch Loss: 1.1974338293075562\n",
      "Epoch 3172, Loss: 1.6626490205526352, Final Batch Loss: 0.19280122220516205\n",
      "Epoch 3173, Loss: 1.496220713481307, Final Batch Loss: 0.013757055625319481\n",
      "Epoch 3174, Loss: 1.7668711841106415, Final Batch Loss: 0.22244912385940552\n",
      "Epoch 3175, Loss: 1.49213281799166, Final Batch Loss: 0.0002215855201939121\n",
      "Epoch 3176, Loss: 1.5522336959838796, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3177, Loss: 1.5461541414259727, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3178, Loss: 2.683488607406616, Final Batch Loss: 1.1134788990020752\n",
      "Epoch 3179, Loss: 1.7845796793699265, Final Batch Loss: 0.24294157326221466\n",
      "Epoch 3180, Loss: 1.5077974125742912, Final Batch Loss: 0.06457366794347763\n",
      "Epoch 3181, Loss: 1.5236973017454147, Final Batch Loss: 0.01696397364139557\n",
      "Epoch 3182, Loss: 2.1759020686149597, Final Batch Loss: 0.6428793668746948\n",
      "Epoch 3183, Loss: 1.5799208730459213, Final Batch Loss: 0.09205178916454315\n",
      "Epoch 3184, Loss: 1.5827233586460352, Final Batch Loss: 0.024312326684594154\n",
      "Epoch 3185, Loss: 1.548487100750208, Final Batch Loss: 0.060375962406396866\n",
      "Epoch 3186, Loss: 2.556617021560669, Final Batch Loss: 1.0193374156951904\n",
      "Epoch 3187, Loss: 1.5015192702412605, Final Batch Loss: 0.04895881563425064\n",
      "Epoch 3188, Loss: 1.4981044651940465, Final Batch Loss: 0.015501839108765125\n",
      "Epoch 3189, Loss: 1.4409658079966903, Final Batch Loss: 0.013553268276154995\n",
      "Epoch 3190, Loss: 1.5359330996870995, Final Batch Loss: 0.01822289079427719\n",
      "Epoch 3191, Loss: 1.4985537701286376, Final Batch Loss: 0.007735180202871561\n",
      "Epoch 3192, Loss: 1.4411226278170943, Final Batch Loss: 0.011534667573869228\n",
      "Epoch 3193, Loss: 2.230835646390915, Final Batch Loss: 0.7920939326286316\n",
      "Epoch 3194, Loss: 2.793977051973343, Final Batch Loss: 1.328352928161621\n",
      "Epoch 3195, Loss: 3.5891358852386475, Final Batch Loss: 2.092578649520874\n",
      "Epoch 3196, Loss: 3.2368550896644592, Final Batch Loss: 1.6818280220031738\n",
      "Epoch 3197, Loss: 1.5494476035237312, Final Batch Loss: 0.025718308985233307\n",
      "Epoch 3198, Loss: 1.5271201772848144, Final Batch Loss: 0.0017059786478057504\n",
      "Epoch 3199, Loss: 1.5532766738906503, Final Batch Loss: 0.005357787944376469\n",
      "Epoch 3200, Loss: 1.515024144668132, Final Batch Loss: 0.006243486423045397\n",
      "Epoch 3201, Loss: 2.599084049463272, Final Batch Loss: 1.095691204071045\n",
      "Epoch 3202, Loss: 1.9922261834144592, Final Batch Loss: 0.5614922046661377\n",
      "Epoch 3203, Loss: 1.5098951044492424, Final Batch Loss: 0.004605400841683149\n",
      "Epoch 3204, Loss: 1.548534419387579, Final Batch Loss: 0.03953137621283531\n",
      "Epoch 3205, Loss: 1.5131890177726746, Final Batch Loss: 0.059856563806533813\n",
      "Epoch 3206, Loss: 1.4655446093529463, Final Batch Loss: 0.026339111849665642\n",
      "Epoch 3207, Loss: 1.4736337563954294, Final Batch Loss: 0.006074537988752127\n",
      "Epoch 3208, Loss: 3.6099809408187866, Final Batch Loss: 2.015226364135742\n",
      "Epoch 3209, Loss: 1.5194758709258167, Final Batch Loss: 0.00011276562872808427\n",
      "Epoch 3210, Loss: 1.5359647572040558, Final Batch Loss: 0.02577349543571472\n",
      "Epoch 3211, Loss: 1.5714571019634604, Final Batch Loss: 0.014393552206456661\n",
      "Epoch 3212, Loss: 1.8901951909065247, Final Batch Loss: 0.4714857339859009\n",
      "Epoch 3213, Loss: 1.4634176958352327, Final Batch Loss: 0.004676239565014839\n",
      "Epoch 3214, Loss: 1.6167576722800732, Final Batch Loss: 0.010616373270750046\n",
      "Epoch 3215, Loss: 1.4492029542125238, Final Batch Loss: 3.3378044463461265e-05\n",
      "Epoch 3216, Loss: 1.8321778178215027, Final Batch Loss: 0.3488824963569641\n",
      "Epoch 3217, Loss: 1.5733990725129843, Final Batch Loss: 0.018044596537947655\n",
      "Epoch 3218, Loss: 2.7389214634895325, Final Batch Loss: 1.2923781871795654\n",
      "Epoch 3219, Loss: 3.448491007089615, Final Batch Loss: 1.998304843902588\n",
      "Epoch 3220, Loss: 1.7117869257888287, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 3221, Loss: 2.327603593468666, Final Batch Loss: 0.014250889420509338\n",
      "Epoch 3222, Loss: 2.441728513687849, Final Batch Loss: 0.010785382241010666\n",
      "Epoch 3223, Loss: 2.311311487108469, Final Batch Loss: 0.04758674278855324\n",
      "Epoch 3224, Loss: 2.3166610915213823, Final Batch Loss: 0.001936228945851326\n",
      "Epoch 3225, Loss: 2.1178285628557205, Final Batch Loss: 0.07896389067173004\n",
      "Epoch 3226, Loss: 3.8454235196113586, Final Batch Loss: 1.9629133939743042\n",
      "Epoch 3227, Loss: 1.7097178911790252, Final Batch Loss: 0.011754772625863552\n",
      "Epoch 3228, Loss: 1.813968114554882, Final Batch Loss: 0.09712433069944382\n",
      "Epoch 3229, Loss: 2.097105383872986, Final Batch Loss: 0.3124415874481201\n",
      "Epoch 3230, Loss: 1.756981585174799, Final Batch Loss: 0.038256678730249405\n",
      "Epoch 3231, Loss: 1.7899337206035852, Final Batch Loss: 0.017356881871819496\n",
      "Epoch 3232, Loss: 5.556091785430908, Final Batch Loss: 3.8053789138793945\n",
      "Epoch 3233, Loss: 1.7409112448258384, Final Batch Loss: 3.2305197237292305e-05\n",
      "Epoch 3234, Loss: 2.58750057220459, Final Batch Loss: 0.8576456308364868\n",
      "Epoch 3235, Loss: 2.1181150376796722, Final Batch Loss: 0.38272711634635925\n",
      "Epoch 3236, Loss: 1.7332648634908878, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3237, Loss: 3.2816162109375, Final Batch Loss: 1.6334148645401\n",
      "Epoch 3238, Loss: 1.62356926582288, Final Batch Loss: 0.0013250865740701556\n",
      "Epoch 3239, Loss: 3.069858431816101, Final Batch Loss: 1.5222585201263428\n",
      "Epoch 3240, Loss: 2.850166916847229, Final Batch Loss: 1.192203402519226\n",
      "Epoch 3241, Loss: 1.7180611193180084, Final Batch Loss: 0.06398990750312805\n",
      "Epoch 3242, Loss: 1.6314091011881828, Final Batch Loss: 0.04328843206167221\n",
      "Epoch 3243, Loss: 1.5813042223453522, Final Batch Loss: 0.0\n",
      "Epoch 3244, Loss: 1.7121620029211044, Final Batch Loss: 0.18474258482456207\n",
      "Epoch 3245, Loss: 1.7439642697572708, Final Batch Loss: 0.18345235288143158\n",
      "Epoch 3246, Loss: 1.519809409044683, Final Batch Loss: 0.010790570639073849\n",
      "Epoch 3247, Loss: 2.6431795358657837, Final Batch Loss: 1.1308389902114868\n",
      "Epoch 3248, Loss: 1.9787666201591492, Final Batch Loss: 0.33588263392448425\n",
      "Epoch 3249, Loss: 2.694502830505371, Final Batch Loss: 0.960157036781311\n",
      "Epoch 3250, Loss: 2.5985612869262695, Final Batch Loss: 0.8681490421295166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251, Loss: 1.7120207119733095, Final Batch Loss: 0.006224768236279488\n",
      "Epoch 3252, Loss: 1.6222193837165833, Final Batch Loss: 0.0\n",
      "Epoch 3253, Loss: 1.8520243167877197, Final Batch Loss: 0.2625740170478821\n",
      "Epoch 3254, Loss: 1.6007242240011692, Final Batch Loss: 0.01999858394265175\n",
      "Epoch 3255, Loss: 1.5761652402579784, Final Batch Loss: 0.03380424901843071\n",
      "Epoch 3256, Loss: 1.5854378992808051, Final Batch Loss: 0.000724887300748378\n",
      "Epoch 3257, Loss: 1.6118843629956245, Final Batch Loss: 0.10406572371721268\n",
      "Epoch 3258, Loss: 4.043030887842178, Final Batch Loss: 2.536860942840576\n",
      "Epoch 3259, Loss: 1.7709746658802032, Final Batch Loss: 0.1727006733417511\n",
      "Epoch 3260, Loss: 1.6031890446320176, Final Batch Loss: 0.0055792564526200294\n",
      "Epoch 3261, Loss: 1.5882747611030936, Final Batch Loss: 0.004012866877019405\n",
      "Epoch 3262, Loss: 2.6150774359703064, Final Batch Loss: 1.021378755569458\n",
      "Epoch 3263, Loss: 2.02817639708519, Final Batch Loss: 0.4197642207145691\n",
      "Epoch 3264, Loss: 1.7596268057823181, Final Batch Loss: 0.1526256799697876\n",
      "Epoch 3265, Loss: 1.7848759293556213, Final Batch Loss: 0.1562032699584961\n",
      "Epoch 3266, Loss: 1.5993950067077094, Final Batch Loss: 1.9311717551317997e-05\n",
      "Epoch 3267, Loss: 2.755654811859131, Final Batch Loss: 1.154634952545166\n",
      "Epoch 3268, Loss: 1.5617113531479845, Final Batch Loss: 0.00018869050836656243\n",
      "Epoch 3269, Loss: 1.621195886284113, Final Batch Loss: 0.02955159917473793\n",
      "Epoch 3270, Loss: 1.9778028428554535, Final Batch Loss: 0.43979865312576294\n",
      "Epoch 3271, Loss: 1.9893833994865417, Final Batch Loss: 0.4619917571544647\n",
      "Epoch 3272, Loss: 1.7853582501411438, Final Batch Loss: 0.2660156190395355\n",
      "Epoch 3273, Loss: 1.5663628596812487, Final Batch Loss: 0.010207237675786018\n",
      "Epoch 3274, Loss: 1.5919302627444267, Final Batch Loss: 0.12207826226949692\n",
      "Epoch 3275, Loss: 3.6950530409812927, Final Batch Loss: 2.1653892993927\n",
      "Epoch 3276, Loss: 1.605304542928934, Final Batch Loss: 0.025947395712137222\n",
      "Epoch 3277, Loss: 1.5668450146913528, Final Batch Loss: 0.05335991084575653\n",
      "Epoch 3278, Loss: 1.6529954746365547, Final Batch Loss: 0.003234870731830597\n",
      "Epoch 3279, Loss: 1.5628694071783684, Final Batch Loss: 0.0005855038180015981\n",
      "Epoch 3280, Loss: 1.5551241366192698, Final Batch Loss: 0.0030272630974650383\n",
      "Epoch 3281, Loss: 1.562841665756423, Final Batch Loss: 0.0006270825979299843\n",
      "Epoch 3282, Loss: 3.912945181131363, Final Batch Loss: 2.3601057529449463\n",
      "Epoch 3283, Loss: 1.4870693227276206, Final Batch Loss: 0.004676832817494869\n",
      "Epoch 3284, Loss: 1.5741334483027458, Final Batch Loss: 0.08632787317037582\n",
      "Epoch 3285, Loss: 3.046269714832306, Final Batch Loss: 1.4743762016296387\n",
      "Epoch 3286, Loss: 1.7669993191957474, Final Batch Loss: 0.1453530341386795\n",
      "Epoch 3287, Loss: 2.0808674097061157, Final Batch Loss: 0.5570080280303955\n",
      "Epoch 3288, Loss: 1.6397002190351486, Final Batch Loss: 0.06326986849308014\n",
      "Epoch 3289, Loss: 1.9354296326637268, Final Batch Loss: 0.37371721863746643\n",
      "Epoch 3290, Loss: 1.5175031721579444, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3291, Loss: 3.121425688266754, Final Batch Loss: 1.5870296955108643\n",
      "Epoch 3292, Loss: 1.5369024500250816, Final Batch Loss: 0.012406907975673676\n",
      "Epoch 3293, Loss: 1.73098024725914, Final Batch Loss: 0.18861833214759827\n",
      "Epoch 3294, Loss: 1.6502974480390549, Final Batch Loss: 0.14542870223522186\n",
      "Epoch 3295, Loss: 1.8500554859638214, Final Batch Loss: 0.3150320053100586\n",
      "Epoch 3296, Loss: 3.3074800074100494, Final Batch Loss: 1.781463384628296\n",
      "Epoch 3297, Loss: 3.342721849679947, Final Batch Loss: 1.8780940771102905\n",
      "Epoch 3298, Loss: 1.6168740276189055, Final Batch Loss: 0.00028761065914295614\n",
      "Epoch 3299, Loss: 3.5417401790618896, Final Batch Loss: 1.9613591432571411\n",
      "Epoch 3300, Loss: 1.5466797393746674, Final Batch Loss: 0.0024509173817932606\n",
      "Epoch 3301, Loss: 2.3828933238983154, Final Batch Loss: 0.7887877821922302\n",
      "Epoch 3302, Loss: 2.87167552113533, Final Batch Loss: 1.3635249137878418\n",
      "Epoch 3303, Loss: 3.5986319184303284, Final Batch Loss: 2.0539212226867676\n",
      "Epoch 3304, Loss: 2.825865238904953, Final Batch Loss: 1.3265537023544312\n",
      "Epoch 3305, Loss: 1.9002835750579834, Final Batch Loss: 0.32694679498672485\n",
      "Epoch 3306, Loss: 2.141359031200409, Final Batch Loss: 0.624066948890686\n",
      "Epoch 3307, Loss: 2.3387701213359833, Final Batch Loss: 0.7534455060958862\n",
      "Epoch 3308, Loss: 1.625531129539013, Final Batch Loss: 0.053874336183071136\n",
      "Epoch 3309, Loss: 2.044534921646118, Final Batch Loss: 0.48285093903541565\n",
      "Epoch 3310, Loss: 1.8745959848165512, Final Batch Loss: 0.24500621855258942\n",
      "Epoch 3311, Loss: 3.49422287940979, Final Batch Loss: 1.9433016777038574\n",
      "Epoch 3312, Loss: 1.6140695735812187, Final Batch Loss: 0.07518848031759262\n",
      "Epoch 3313, Loss: 1.5685679912567139, Final Batch Loss: 0.0\n",
      "Epoch 3314, Loss: 1.5439595617353916, Final Batch Loss: 0.0282423235476017\n",
      "Epoch 3315, Loss: 1.5214960277080536, Final Batch Loss: 0.033734291791915894\n",
      "Epoch 3316, Loss: 1.4953404068842246, Final Batch Loss: 4.529942543740617e-06\n",
      "Epoch 3317, Loss: 1.6859190464019775, Final Batch Loss: 0.18121173977851868\n",
      "Epoch 3318, Loss: 1.558306373655796, Final Batch Loss: 0.08956725150346756\n",
      "Epoch 3319, Loss: 1.8447090685367584, Final Batch Loss: 0.34978967905044556\n",
      "Epoch 3320, Loss: 3.158650517463684, Final Batch Loss: 1.6839773654937744\n",
      "Epoch 3321, Loss: 1.6174360886216164, Final Batch Loss: 0.10253209620714188\n",
      "Epoch 3322, Loss: 2.0472492277622223, Final Batch Loss: 0.5658481121063232\n",
      "Epoch 3323, Loss: 1.5002825444098562, Final Batch Loss: 0.0005110388156026602\n",
      "Epoch 3324, Loss: 1.7063255533576012, Final Batch Loss: 0.1141170784831047\n",
      "Epoch 3325, Loss: 4.626056283712387, Final Batch Loss: 3.2154910564422607\n",
      "Epoch 3326, Loss: 2.6376761496067047, Final Batch Loss: 1.0548689365386963\n",
      "Epoch 3327, Loss: 1.6593148037791252, Final Batch Loss: 0.10791965574026108\n",
      "Epoch 3328, Loss: 2.0662636160850525, Final Batch Loss: 0.5761412978172302\n",
      "Epoch 3329, Loss: 4.522985547780991, Final Batch Loss: 2.9868268966674805\n",
      "Epoch 3330, Loss: 2.7469554245471954, Final Batch Loss: 1.1349025964736938\n",
      "Epoch 3331, Loss: 2.3561826944351196, Final Batch Loss: 0.31079334020614624\n",
      "Epoch 3332, Loss: 2.802810251712799, Final Batch Loss: 0.39199739694595337\n",
      "Epoch 3333, Loss: 3.6555463075637817, Final Batch Loss: 1.4792288541793823\n",
      "Epoch 3334, Loss: 1.9087341278791428, Final Batch Loss: 0.14426420629024506\n",
      "Epoch 3335, Loss: 5.010478734970093, Final Batch Loss: 3.3231496810913086\n",
      "Epoch 3336, Loss: 2.113040030002594, Final Batch Loss: 0.5033812522888184\n",
      "Epoch 3337, Loss: 1.7001234889030457, Final Batch Loss: 0.0\n",
      "Epoch 3338, Loss: 1.7629215716870021, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 3339, Loss: 1.8218168009261717, Final Batch Loss: 4.684815212385729e-05\n",
      "Epoch 3340, Loss: 1.8671672344207764, Final Batch Loss: 0.13523614406585693\n",
      "Epoch 3341, Loss: 1.645848570857197, Final Batch Loss: 0.0026513920165598392\n",
      "Epoch 3342, Loss: 3.473450630903244, Final Batch Loss: 1.862661361694336\n",
      "Epoch 3343, Loss: 1.6886406876146793, Final Batch Loss: 0.03137916699051857\n",
      "Epoch 3344, Loss: 1.5500995153561234, Final Batch Loss: 0.015093171037733555\n",
      "Epoch 3345, Loss: 3.7288655638694763, Final Batch Loss: 2.197509765625\n",
      "Epoch 3346, Loss: 1.6053581051528454, Final Batch Loss: 0.027966003865003586\n",
      "Epoch 3347, Loss: 1.5705085322260857, Final Batch Loss: 0.042887769639492035\n",
      "Epoch 3348, Loss: 1.580957238242263, Final Batch Loss: 0.00033241944038309157\n",
      "Epoch 3349, Loss: 2.994462788105011, Final Batch Loss: 1.528868556022644\n",
      "Epoch 3350, Loss: 1.7461570650339127, Final Batch Loss: 0.1283256560564041\n",
      "Epoch 3351, Loss: 2.215767413377762, Final Batch Loss: 0.7204370498657227\n",
      "Epoch 3352, Loss: 1.5397128239274025, Final Batch Loss: 0.03169438987970352\n",
      "Epoch 3353, Loss: 4.412014842033386, Final Batch Loss: 2.8864598274230957\n",
      "Epoch 3354, Loss: 2.5566373467445374, Final Batch Loss: 1.041677474975586\n",
      "Epoch 3355, Loss: 1.783104472051491, Final Batch Loss: 0.00012051333033014089\n",
      "Epoch 3356, Loss: 1.8283901484683156, Final Batch Loss: 0.008623030968010426\n",
      "Epoch 3357, Loss: 1.7955369092524052, Final Batch Loss: 0.009900275617837906\n",
      "Epoch 3358, Loss: 5.020835638046265, Final Batch Loss: 3.3207156658172607\n",
      "Epoch 3359, Loss: 3.3106413185596466, Final Batch Loss: 1.769336462020874\n",
      "Epoch 3360, Loss: 1.8641932308673859, Final Batch Loss: 0.35821545124053955\n",
      "Epoch 3361, Loss: 4.061432927846909, Final Batch Loss: 2.4832615852355957\n",
      "Epoch 3362, Loss: 1.6490568369627, Final Batch Loss: 0.11508972942829132\n",
      "Epoch 3363, Loss: 1.717055782675743, Final Batch Loss: 0.1950349658727646\n",
      "Epoch 3364, Loss: 1.9484876096248627, Final Batch Loss: 0.4331936240196228\n",
      "Epoch 3365, Loss: 1.4735062126419507, Final Batch Loss: 0.00024244230007752776\n",
      "Epoch 3366, Loss: 1.53999899700284, Final Batch Loss: 0.030551422387361526\n",
      "Epoch 3367, Loss: 2.602515310049057, Final Batch Loss: 1.0598129034042358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3368, Loss: 1.5695366323925555, Final Batch Loss: 0.005496507976204157\n",
      "Epoch 3369, Loss: 1.456456482410431, Final Batch Loss: 0.0\n",
      "Epoch 3370, Loss: 1.5848957425914705, Final Batch Loss: 0.004108441527932882\n",
      "Epoch 3371, Loss: 1.5826835501939058, Final Batch Loss: 0.01731388457119465\n",
      "Epoch 3372, Loss: 1.4666284429840744, Final Batch Loss: 0.0025553214363753796\n",
      "Epoch 3373, Loss: 1.420360863208657, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3374, Loss: 3.3729340732097626, Final Batch Loss: 1.8430272340774536\n",
      "Epoch 3375, Loss: 1.4770759858656675, Final Batch Loss: 0.003400973277166486\n",
      "Epoch 3376, Loss: 2.0973949432373047, Final Batch Loss: 0.6302173733711243\n",
      "Epoch 3377, Loss: 1.6669000387191772, Final Batch Loss: 0.15420541167259216\n",
      "Epoch 3378, Loss: 1.5351429581639877, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3379, Loss: 1.7063132375478745, Final Batch Loss: 0.15273649990558624\n",
      "Epoch 3380, Loss: 2.4924338459968567, Final Batch Loss: 0.9295362234115601\n",
      "Epoch 3381, Loss: 1.653790969401598, Final Batch Loss: 0.04155125096440315\n",
      "Epoch 3382, Loss: 1.532952956855297, Final Batch Loss: 0.03338523954153061\n",
      "Epoch 3383, Loss: 1.620948188006878, Final Batch Loss: 0.06356512755155563\n",
      "Epoch 3384, Loss: 3.348378837108612, Final Batch Loss: 1.9009819030761719\n",
      "Epoch 3385, Loss: 1.7241867035627365, Final Batch Loss: 0.16792960464954376\n",
      "Epoch 3386, Loss: 1.4954563416540623, Final Batch Loss: 0.016383294016122818\n",
      "Epoch 3387, Loss: 1.8166362047195435, Final Batch Loss: 0.34835284948349\n",
      "Epoch 3388, Loss: 1.5210490711033344, Final Batch Loss: 0.02793319895863533\n",
      "Epoch 3389, Loss: 1.4736756663769484, Final Batch Loss: 0.003957180306315422\n",
      "Epoch 3390, Loss: 1.5981209948658943, Final Batch Loss: 0.07168398052453995\n",
      "Epoch 3391, Loss: 2.403523802757263, Final Batch Loss: 0.9177610874176025\n",
      "Epoch 3392, Loss: 2.4914920330047607, Final Batch Loss: 1.1217105388641357\n",
      "Epoch 3393, Loss: 1.432404617778957, Final Batch Loss: 0.015519092790782452\n",
      "Epoch 3394, Loss: 1.6132743656635284, Final Batch Loss: 0.0706155002117157\n",
      "Epoch 3395, Loss: 2.175103724002838, Final Batch Loss: 0.6367085576057434\n",
      "Epoch 3396, Loss: 1.7823119461536407, Final Batch Loss: 0.3306664228439331\n",
      "Epoch 3397, Loss: 1.446894061518833, Final Batch Loss: 0.0011344670783728361\n",
      "Epoch 3398, Loss: 1.4996880667749792, Final Batch Loss: 0.001375206047669053\n",
      "Epoch 3399, Loss: 1.595785729587078, Final Batch Loss: 0.0707780048251152\n",
      "Epoch 3400, Loss: 1.5356287434697151, Final Batch Loss: 0.035327114164829254\n",
      "Epoch 3401, Loss: 2.693621575832367, Final Batch Loss: 1.1975451707839966\n",
      "Epoch 3402, Loss: 1.8414882123470306, Final Batch Loss: 0.273605614900589\n",
      "Epoch 3403, Loss: 6.131491124629974, Final Batch Loss: 3.9943957328796387\n",
      "Epoch 3404, Loss: 3.9005738496780396, Final Batch Loss: 1.5985735654830933\n",
      "Epoch 3405, Loss: 2.3162941634655, Final Batch Loss: 0.2284872829914093\n",
      "Epoch 3406, Loss: 1.9685531556606293, Final Batch Loss: 0.19975343346595764\n",
      "Epoch 3407, Loss: 1.609275757915384, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 3408, Loss: 1.75345778465271, Final Batch Loss: 0.23537993431091309\n",
      "Epoch 3409, Loss: 1.5614900263026357, Final Batch Loss: 0.009921875782310963\n",
      "Epoch 3410, Loss: 1.5646878480911255, Final Batch Loss: 0.060223549604415894\n",
      "Epoch 3411, Loss: 1.4954185353417415, Final Batch Loss: 0.0001627074379939586\n",
      "Epoch 3412, Loss: 1.5688110813498497, Final Batch Loss: 0.07265343517065048\n",
      "Epoch 3413, Loss: 3.0881204903125763, Final Batch Loss: 1.59140145778656\n",
      "Epoch 3414, Loss: 2.5382480323314667, Final Batch Loss: 1.0205061435699463\n",
      "Epoch 3415, Loss: 1.5548435446380608, Final Batch Loss: 2.539125671319198e-05\n",
      "Epoch 3416, Loss: 1.417214094195515, Final Batch Loss: 0.002428798470646143\n",
      "Epoch 3417, Loss: 1.495106989517808, Final Batch Loss: 0.013937408104538918\n",
      "Epoch 3418, Loss: 1.4931008621642832, Final Batch Loss: 0.00019703354337252676\n",
      "Epoch 3419, Loss: 1.4518275214359164, Final Batch Loss: 0.007547671906650066\n",
      "Epoch 3420, Loss: 2.622280180454254, Final Batch Loss: 1.1495428085327148\n",
      "Epoch 3421, Loss: 1.4641275266185403, Final Batch Loss: 0.014623836614191532\n",
      "Epoch 3422, Loss: 3.150182843208313, Final Batch Loss: 1.6886858940124512\n",
      "Epoch 3423, Loss: 1.7079018950462341, Final Batch Loss: 0.22603633999824524\n",
      "Epoch 3424, Loss: 1.5175022180192173, Final Batch Loss: 0.004570632707327604\n",
      "Epoch 3425, Loss: 1.5410688370466232, Final Batch Loss: 0.08339135348796844\n",
      "Epoch 3426, Loss: 1.9947992265224457, Final Batch Loss: 0.5890299081802368\n",
      "Epoch 3427, Loss: 1.4949052324518561, Final Batch Loss: 0.015364735387265682\n",
      "Epoch 3428, Loss: 2.646949917078018, Final Batch Loss: 1.1773227453231812\n",
      "Epoch 3429, Loss: 1.475476254709065, Final Batch Loss: 0.01364805269986391\n",
      "Epoch 3430, Loss: 3.2525332272052765, Final Batch Loss: 1.776780366897583\n",
      "Epoch 3431, Loss: 1.4287372748367488, Final Batch Loss: 0.0045198420993983746\n",
      "Epoch 3432, Loss: 6.718676537275314, Final Batch Loss: 5.247575283050537\n",
      "Epoch 3433, Loss: 1.5537291467189789, Final Batch Loss: 0.0\n",
      "Epoch 3434, Loss: 1.9234811067581177, Final Batch Loss: 0.3837495744228363\n",
      "Epoch 3435, Loss: 1.7853009700775146, Final Batch Loss: 0.17006570100784302\n",
      "Epoch 3436, Loss: 1.660179140046239, Final Batch Loss: 0.0048047322779893875\n",
      "Epoch 3437, Loss: 1.604682918637991, Final Batch Loss: 0.006885018199682236\n",
      "Epoch 3438, Loss: 3.2541959285736084, Final Batch Loss: 1.62265944480896\n",
      "Epoch 3439, Loss: 1.5781653225212722, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 3440, Loss: 1.6461435034871101, Final Batch Loss: 0.12060848623514175\n",
      "Epoch 3441, Loss: 1.6122990474104881, Final Batch Loss: 0.03929048031568527\n",
      "Epoch 3442, Loss: 1.8044173866510391, Final Batch Loss: 0.20407868921756744\n",
      "Epoch 3443, Loss: 1.6685728505253792, Final Batch Loss: 0.07907480746507645\n",
      "Epoch 3444, Loss: 2.82517209649086, Final Batch Loss: 1.3448426723480225\n",
      "Epoch 3445, Loss: 1.600431814789772, Final Batch Loss: 0.15690110623836517\n",
      "Epoch 3446, Loss: 1.6288339048624039, Final Batch Loss: 0.1494169384241104\n",
      "Epoch 3447, Loss: 2.661993980407715, Final Batch Loss: 1.1447944641113281\n",
      "Epoch 3448, Loss: 2.9996319115161896, Final Batch Loss: 1.521862506866455\n",
      "Epoch 3449, Loss: 1.7209756076335907, Final Batch Loss: 0.1616629958152771\n",
      "Epoch 3450, Loss: 1.8097706735134125, Final Batch Loss: 0.41739094257354736\n",
      "Epoch 3451, Loss: 1.489880608394742, Final Batch Loss: 0.02179049141705036\n",
      "Epoch 3452, Loss: 1.555873541161418, Final Batch Loss: 0.024759111925959587\n",
      "Epoch 3453, Loss: 1.6452177185565233, Final Batch Loss: 0.025096656754612923\n",
      "Epoch 3454, Loss: 1.7013059854507446, Final Batch Loss: 0.24275025725364685\n",
      "Epoch 3455, Loss: 3.263158679008484, Final Batch Loss: 1.7880852222442627\n",
      "Epoch 3456, Loss: 1.646084439009428, Final Batch Loss: 0.03980417177081108\n",
      "Epoch 3457, Loss: 2.6763272285461426, Final Batch Loss: 1.22701096534729\n",
      "Epoch 3458, Loss: 1.4958295626565814, Final Batch Loss: 0.011626462452113628\n",
      "Epoch 3459, Loss: 2.8461175560951233, Final Batch Loss: 1.3699499368667603\n",
      "Epoch 3460, Loss: 2.3309224247932434, Final Batch Loss: 0.7788384556770325\n",
      "Epoch 3461, Loss: 1.6218372508883476, Final Batch Loss: 0.04062681645154953\n",
      "Epoch 3462, Loss: 2.7006156742572784, Final Batch Loss: 1.1969724893569946\n",
      "Epoch 3463, Loss: 2.7084078788757324, Final Batch Loss: 1.2592782974243164\n",
      "Epoch 3464, Loss: 1.7737641632556915, Final Batch Loss: 0.2505589425563812\n",
      "Epoch 3465, Loss: 1.5333334524184465, Final Batch Loss: 0.028859825804829597\n",
      "Epoch 3466, Loss: 1.5116626669187099, Final Batch Loss: 0.0015210260171443224\n",
      "Epoch 3467, Loss: 1.511946676298976, Final Batch Loss: 0.022536007687449455\n",
      "Epoch 3468, Loss: 1.490550810471177, Final Batch Loss: 0.019725704565644264\n",
      "Epoch 3469, Loss: 1.53367443010211, Final Batch Loss: 0.03330729529261589\n",
      "Epoch 3470, Loss: 1.929845929145813, Final Batch Loss: 0.4466031491756439\n",
      "Epoch 3471, Loss: 1.5527070630341768, Final Batch Loss: 0.015941666439175606\n",
      "Epoch 3472, Loss: 1.4929933557286859, Final Batch Loss: 0.004823477007448673\n",
      "Epoch 3473, Loss: 1.5504008724819869, Final Batch Loss: 0.003844965947791934\n",
      "Epoch 3474, Loss: 1.7108090668916702, Final Batch Loss: 0.04183836281299591\n",
      "Epoch 3475, Loss: 1.5427927714772522, Final Batch Loss: 0.006642286200076342\n",
      "Epoch 3476, Loss: 2.3984606862068176, Final Batch Loss: 0.9387984871864319\n",
      "Epoch 3477, Loss: 1.577332935295999, Final Batch Loss: 0.009000799618661404\n",
      "Epoch 3478, Loss: 1.625060811638832, Final Batch Loss: 0.15794767439365387\n",
      "Epoch 3479, Loss: 1.4074132815003395, Final Batch Loss: 0.027644850313663483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3480, Loss: 1.6099835485219955, Final Batch Loss: 0.10880865156650543\n",
      "Epoch 3481, Loss: 2.9137080907821655, Final Batch Loss: 1.4261696338653564\n",
      "Epoch 3482, Loss: 1.514085564762354, Final Batch Loss: 0.04790792241692543\n",
      "Epoch 3483, Loss: 1.5070401802659035, Final Batch Loss: 0.04607618600130081\n",
      "Epoch 3484, Loss: 1.4410474514588714, Final Batch Loss: 0.00601529236882925\n",
      "Epoch 3485, Loss: 2.7210792005062103, Final Batch Loss: 1.273966670036316\n",
      "Epoch 3486, Loss: 2.1195075809955597, Final Batch Loss: 0.7120705246925354\n",
      "Epoch 3487, Loss: 1.4207469820976257, Final Batch Loss: 0.0\n",
      "Epoch 3488, Loss: 2.9336116313934326, Final Batch Loss: 1.5463597774505615\n",
      "Epoch 3489, Loss: 1.9196932911872864, Final Batch Loss: 0.5311926603317261\n",
      "Epoch 3490, Loss: 2.6249673664569855, Final Batch Loss: 1.0737066268920898\n",
      "Epoch 3491, Loss: 1.5921760271303356, Final Batch Loss: 0.0053092907182872295\n",
      "Epoch 3492, Loss: 1.6575357338879257, Final Batch Loss: 0.0023902675602585077\n",
      "Epoch 3493, Loss: 1.5960580836981535, Final Batch Loss: 0.016120804473757744\n",
      "Epoch 3494, Loss: 1.4966519009321928, Final Batch Loss: 0.00711597315967083\n",
      "Epoch 3495, Loss: 4.666697800159454, Final Batch Loss: 3.1837592124938965\n",
      "Epoch 3496, Loss: 1.4825973933329806, Final Batch Loss: 0.0008996253600344062\n",
      "Epoch 3497, Loss: 1.5490299686789513, Final Batch Loss: 0.08193560689687729\n",
      "Epoch 3498, Loss: 1.4554964764975011, Final Batch Loss: 0.005815254058688879\n",
      "Epoch 3499, Loss: 1.5117249861359596, Final Batch Loss: 0.07427570968866348\n",
      "Epoch 3500, Loss: 1.4499773494899273, Final Batch Loss: 0.030103515833616257\n",
      "Epoch 3501, Loss: 3.9298591911792755, Final Batch Loss: 2.531797170639038\n",
      "Epoch 3502, Loss: 1.4289123620837927, Final Batch Loss: 0.01981394551694393\n",
      "Epoch 3503, Loss: 2.5136102437973022, Final Batch Loss: 1.0270408391952515\n",
      "Epoch 3504, Loss: 1.4752891869284213, Final Batch Loss: 0.002319029066711664\n",
      "Epoch 3505, Loss: 3.0703226029872894, Final Batch Loss: 1.6871402263641357\n",
      "Epoch 3506, Loss: 1.7201078236103058, Final Batch Loss: 0.13572940230369568\n",
      "Epoch 3507, Loss: 1.5429659588262439, Final Batch Loss: 0.009347955696284771\n",
      "Epoch 3508, Loss: 1.5135050639510155, Final Batch Loss: 0.014370284974575043\n",
      "Epoch 3509, Loss: 1.5214671994908713, Final Batch Loss: 0.0005627478822134435\n",
      "Epoch 3510, Loss: 2.089748203754425, Final Batch Loss: 0.5634663701057434\n",
      "Epoch 3511, Loss: 4.501281350851059, Final Batch Loss: 3.027683973312378\n",
      "Epoch 3512, Loss: 1.4655601971317083, Final Batch Loss: 0.0027394883800297976\n",
      "Epoch 3513, Loss: 1.5650006840005517, Final Batch Loss: 0.004397840239107609\n",
      "Epoch 3514, Loss: 1.5186739536002278, Final Batch Loss: 0.014816013164818287\n",
      "Epoch 3515, Loss: 2.2259727120399475, Final Batch Loss: 0.6733379364013672\n",
      "Epoch 3516, Loss: 2.2629145979881287, Final Batch Loss: 0.7332044839859009\n",
      "Epoch 3517, Loss: 1.5952028632164001, Final Batch Loss: 0.11132887005805969\n",
      "Epoch 3518, Loss: 1.6172723174095154, Final Batch Loss: 0.10598382353782654\n",
      "Epoch 3519, Loss: 1.5457546589896083, Final Batch Loss: 0.004764157347381115\n",
      "Epoch 3520, Loss: 1.5149541068822145, Final Batch Loss: 0.020166831091046333\n",
      "Epoch 3521, Loss: 1.5398150703404099, Final Batch Loss: 0.002055438468232751\n",
      "Epoch 3522, Loss: 2.9625117480754852, Final Batch Loss: 1.510382890701294\n",
      "Epoch 3523, Loss: 1.5646965578198433, Final Batch Loss: 0.07195857912302017\n",
      "Epoch 3524, Loss: 1.4980742707848549, Final Batch Loss: 0.07328356057405472\n",
      "Epoch 3525, Loss: 1.5176717787981033, Final Batch Loss: 0.019116804003715515\n",
      "Epoch 3526, Loss: 1.5171715319149826, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3527, Loss: 5.183938592672348, Final Batch Loss: 3.6884055137634277\n",
      "Epoch 3528, Loss: 1.6344551295042038, Final Batch Loss: 0.1629510372877121\n",
      "Epoch 3529, Loss: 2.4422551691532135, Final Batch Loss: 0.9367120265960693\n",
      "Epoch 3530, Loss: 1.418123232666403, Final Batch Loss: 0.004739242140203714\n",
      "Epoch 3531, Loss: 3.5175936222076416, Final Batch Loss: 2.0495123863220215\n",
      "Epoch 3532, Loss: 1.4015644872561097, Final Batch Loss: 0.004029133357107639\n",
      "Epoch 3533, Loss: 2.5404399633407593, Final Batch Loss: 1.0228102207183838\n",
      "Epoch 3534, Loss: 1.677513748407364, Final Batch Loss: 0.24582481384277344\n",
      "Epoch 3535, Loss: 1.4992616474551141, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 3536, Loss: 1.678796425461769, Final Batch Loss: 0.2084008902311325\n",
      "Epoch 3537, Loss: 2.5994435846805573, Final Batch Loss: 1.1121737957000732\n",
      "Epoch 3538, Loss: 1.441693663597107, Final Batch Loss: 0.04618683457374573\n",
      "Epoch 3539, Loss: 3.2424671947956085, Final Batch Loss: 1.6925609111785889\n",
      "Epoch 3540, Loss: 1.5482785186031833, Final Batch Loss: 0.0010842165211215615\n",
      "Epoch 3541, Loss: 1.6708048731088638, Final Batch Loss: 0.06256116926670074\n",
      "Epoch 3542, Loss: 1.6624485328793526, Final Batch Loss: 0.10815901309251785\n",
      "Epoch 3543, Loss: 1.5573019119910896, Final Batch Loss: 0.005293163936585188\n",
      "Epoch 3544, Loss: 1.5877566551789641, Final Batch Loss: 0.012063167057931423\n",
      "Epoch 3545, Loss: 2.350048780441284, Final Batch Loss: 0.8453299403190613\n",
      "Epoch 3546, Loss: 1.5234389081597328, Final Batch Loss: 0.05602193623781204\n",
      "Epoch 3547, Loss: 1.4994949726387858, Final Batch Loss: 0.009045573882758617\n",
      "Epoch 3548, Loss: 1.509771584886039, Final Batch Loss: 3.397406908334233e-05\n",
      "Epoch 3549, Loss: 1.3890148096106714, Final Batch Loss: 3.7788631743751466e-05\n",
      "Epoch 3550, Loss: 3.150903880596161, Final Batch Loss: 1.6694914102554321\n",
      "Epoch 3551, Loss: 3.8917811810970306, Final Batch Loss: 2.4833903312683105\n",
      "Epoch 3552, Loss: 2.6065041720867157, Final Batch Loss: 1.1237680912017822\n",
      "Epoch 3553, Loss: 1.5299398973584175, Final Batch Loss: 0.02954847365617752\n",
      "Epoch 3554, Loss: 2.7765076756477356, Final Batch Loss: 1.2142407894134521\n",
      "Epoch 3555, Loss: 1.6672798842191696, Final Batch Loss: 0.12720657885074615\n",
      "Epoch 3556, Loss: 1.4975565991480835, Final Batch Loss: 0.0003389737685211003\n",
      "Epoch 3557, Loss: 1.573701984481886, Final Batch Loss: 0.0005865760613232851\n",
      "Epoch 3558, Loss: 1.4893077611907302, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3559, Loss: 3.971092700958252, Final Batch Loss: 2.5010454654693604\n",
      "Epoch 3560, Loss: 1.5087307742796838, Final Batch Loss: 0.0013552061282098293\n",
      "Epoch 3561, Loss: 1.5205795979127288, Final Batch Loss: 0.011656037531793118\n",
      "Epoch 3562, Loss: 1.6104796268045902, Final Batch Loss: 0.02437422052025795\n",
      "Epoch 3563, Loss: 2.9357829093933105, Final Batch Loss: 1.4538613557815552\n",
      "Epoch 3564, Loss: 1.5083799021085724, Final Batch Loss: 0.0019239740213379264\n",
      "Epoch 3565, Loss: 1.4685986127587967, Final Batch Loss: 0.0008354272576980293\n",
      "Epoch 3566, Loss: 1.6506079609243898, Final Batch Loss: 0.00015758226800244302\n",
      "Epoch 3567, Loss: 1.5910947993397713, Final Batch Loss: 0.11857924610376358\n",
      "Epoch 3568, Loss: 3.47219255566597, Final Batch Loss: 1.9595768451690674\n",
      "Epoch 3569, Loss: 1.4883199464529753, Final Batch Loss: 0.016140861436724663\n",
      "Epoch 3570, Loss: 1.6863413006067276, Final Batch Loss: 0.1954135149717331\n",
      "Epoch 3571, Loss: 1.4672664701924987, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 3572, Loss: 1.4884635638445616, Final Batch Loss: 0.0009629856795072556\n",
      "Epoch 3573, Loss: 1.433906902326271, Final Batch Loss: 0.0035387768875807524\n",
      "Epoch 3574, Loss: 1.455964864231646, Final Batch Loss: 0.01524862740188837\n",
      "Epoch 3575, Loss: 1.4884386835619807, Final Batch Loss: 0.008881705813109875\n",
      "Epoch 3576, Loss: 1.5269172210246325, Final Batch Loss: 0.02765992470085621\n",
      "Epoch 3577, Loss: 2.013011634349823, Final Batch Loss: 0.5570475459098816\n",
      "Epoch 3578, Loss: 3.970791816711426, Final Batch Loss: 2.5036871433258057\n",
      "Epoch 3579, Loss: 1.5085607953369617, Final Batch Loss: 0.03996958211064339\n",
      "Epoch 3580, Loss: 1.519100420671748, Final Batch Loss: 0.00036483307485468686\n",
      "Epoch 3581, Loss: 2.6516191363334656, Final Batch Loss: 1.1101572513580322\n",
      "Epoch 3582, Loss: 1.6636907905340195, Final Batch Loss: 0.06505130231380463\n",
      "Epoch 3583, Loss: 2.257295608520508, Final Batch Loss: 0.6281932592391968\n",
      "Epoch 3584, Loss: 2.865143597126007, Final Batch Loss: 1.0743122100830078\n",
      "Epoch 3585, Loss: 3.8384286165237427, Final Batch Loss: 1.9992307424545288\n",
      "Epoch 3586, Loss: 1.8263747445307672, Final Batch Loss: 0.005491291638463736\n",
      "Epoch 3587, Loss: 1.9069832153618336, Final Batch Loss: 0.03497769311070442\n",
      "Epoch 3588, Loss: 2.018357217311859, Final Batch Loss: 0.07664501667022705\n",
      "Epoch 3589, Loss: 1.934484913945198, Final Batch Loss: 0.12594003975391388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3590, Loss: 2.257609784603119, Final Batch Loss: 0.472281813621521\n",
      "Epoch 3591, Loss: 4.458761364221573, Final Batch Loss: 2.7831783294677734\n",
      "Epoch 3592, Loss: 1.7794995531439781, Final Batch Loss: 0.11517908424139023\n",
      "Epoch 3593, Loss: 1.738162517547039, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3594, Loss: 1.5863777605409268, Final Batch Loss: 0.0004439560289029032\n",
      "Epoch 3595, Loss: 2.3156757950782776, Final Batch Loss: 0.76469886302948\n",
      "Epoch 3596, Loss: 1.6449284702539444, Final Batch Loss: 0.1314142495393753\n",
      "Epoch 3597, Loss: 1.9185202717781067, Final Batch Loss: 0.4132555425167084\n",
      "Epoch 3598, Loss: 4.048346042633057, Final Batch Loss: 2.574942111968994\n",
      "Epoch 3599, Loss: 1.9003970623016357, Final Batch Loss: 0.34199193120002747\n",
      "Epoch 3600, Loss: 2.819533050060272, Final Batch Loss: 1.155707597732544\n",
      "Epoch 3601, Loss: 1.9220415279269218, Final Batch Loss: 0.07151519507169724\n",
      "Epoch 3602, Loss: 1.9206537902355194, Final Batch Loss: 0.11126360297203064\n",
      "Epoch 3603, Loss: 1.7492103166878223, Final Batch Loss: 0.05282916501164436\n",
      "Epoch 3604, Loss: 3.241533041000366, Final Batch Loss: 1.5818812847137451\n",
      "Epoch 3605, Loss: 1.6156722083687782, Final Batch Loss: 0.06451354175806046\n",
      "Epoch 3606, Loss: 3.677422285079956, Final Batch Loss: 2.1158366203308105\n",
      "Epoch 3607, Loss: 2.2446205019950867, Final Batch Loss: 0.6942213773727417\n",
      "Epoch 3608, Loss: 1.6000117841176689, Final Batch Loss: 0.004207212012261152\n",
      "Epoch 3609, Loss: 1.6095329374074936, Final Batch Loss: 0.032279178500175476\n",
      "Epoch 3610, Loss: 1.8900560140609741, Final Batch Loss: 0.3944591283798218\n",
      "Epoch 3611, Loss: 1.7228695452213287, Final Batch Loss: 0.10852816700935364\n",
      "Epoch 3612, Loss: 2.1368198096752167, Final Batch Loss: 0.5972394943237305\n",
      "Epoch 3613, Loss: 2.4398264288902283, Final Batch Loss: 0.9285022616386414\n",
      "Epoch 3614, Loss: 1.8158581405878067, Final Batch Loss: 0.23263944685459137\n",
      "Epoch 3615, Loss: 1.8794683068990707, Final Batch Loss: 0.14693234860897064\n",
      "Epoch 3616, Loss: 3.595212757587433, Final Batch Loss: 1.9652330875396729\n",
      "Epoch 3617, Loss: 3.232628643512726, Final Batch Loss: 1.6836483478546143\n",
      "Epoch 3618, Loss: 2.32115837931633, Final Batch Loss: 0.681054413318634\n",
      "Epoch 3619, Loss: 1.9264174550771713, Final Batch Loss: 0.11019293963909149\n",
      "Epoch 3620, Loss: 1.8363134884275496, Final Batch Loss: 0.002760055009275675\n",
      "Epoch 3621, Loss: 3.8551632165908813, Final Batch Loss: 2.010037899017334\n",
      "Epoch 3622, Loss: 4.655009925365448, Final Batch Loss: 2.717599391937256\n",
      "Epoch 3623, Loss: 2.555267333984375, Final Batch Loss: 0.7708010077476501\n",
      "Epoch 3624, Loss: 3.457670509815216, Final Batch Loss: 1.7725262641906738\n",
      "Epoch 3625, Loss: 1.7110314518213272, Final Batch Loss: 0.07937370240688324\n",
      "Epoch 3626, Loss: 3.670849323272705, Final Batch Loss: 1.9969253540039062\n",
      "Epoch 3627, Loss: 1.567977043800056, Final Batch Loss: 0.01030257623642683\n",
      "Epoch 3628, Loss: 1.569192258757539, Final Batch Loss: 0.0008476955117657781\n",
      "Epoch 3629, Loss: 2.797976404428482, Final Batch Loss: 1.2721681594848633\n",
      "Epoch 3630, Loss: 1.540416896343224, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3631, Loss: 1.5453119872818206, Final Batch Loss: 1.537788011773955e-05\n",
      "Epoch 3632, Loss: 2.505117118358612, Final Batch Loss: 0.8877466320991516\n",
      "Epoch 3633, Loss: 1.7928878664970398, Final Batch Loss: 0.16183984279632568\n",
      "Epoch 3634, Loss: 1.997757464647293, Final Batch Loss: 0.3276166617870331\n",
      "Epoch 3635, Loss: 1.9845501482486725, Final Batch Loss: 0.30226877331733704\n",
      "Epoch 3636, Loss: 1.654589177109301, Final Batch Loss: 0.004524470306932926\n",
      "Epoch 3637, Loss: 1.8101810812950134, Final Batch Loss: 0.16862988471984863\n",
      "Epoch 3638, Loss: 2.430685132741928, Final Batch Loss: 0.8716272115707397\n",
      "Epoch 3639, Loss: 3.9974843561649323, Final Batch Loss: 2.3735108375549316\n",
      "Epoch 3640, Loss: 3.4282736480236053, Final Batch Loss: 1.8994091749191284\n",
      "Epoch 3641, Loss: 2.0117166340351105, Final Batch Loss: 0.410853773355484\n",
      "Epoch 3642, Loss: 2.0067346394062042, Final Batch Loss: 0.4475420415401459\n",
      "Epoch 3643, Loss: 1.6555034331977367, Final Batch Loss: 0.017399292439222336\n",
      "Epoch 3644, Loss: 1.572551669087261, Final Batch Loss: 0.006488920655101538\n",
      "Epoch 3645, Loss: 1.5678246605675668, Final Batch Loss: 0.0010367024224251509\n",
      "Epoch 3646, Loss: 3.7721256613731384, Final Batch Loss: 2.181102752685547\n",
      "Epoch 3647, Loss: 1.6104010976850986, Final Batch Loss: 0.037797633558511734\n",
      "Epoch 3648, Loss: 1.5158896042848937, Final Batch Loss: 0.0005093707586638629\n",
      "Epoch 3649, Loss: 3.2990832924842834, Final Batch Loss: 1.736903429031372\n",
      "Epoch 3650, Loss: 1.5860857502557337, Final Batch Loss: 0.004292322788387537\n",
      "Epoch 3651, Loss: 2.820846676826477, Final Batch Loss: 1.29827880859375\n",
      "Epoch 3652, Loss: 1.4953315798193216, Final Batch Loss: 0.01622789539396763\n",
      "Epoch 3653, Loss: 1.5581419803202152, Final Batch Loss: 0.009565118700265884\n",
      "Epoch 3654, Loss: 1.500337302657499, Final Batch Loss: 7.390948667307384e-06\n",
      "Epoch 3655, Loss: 1.6408163234591484, Final Batch Loss: 0.10147347301244736\n",
      "Epoch 3656, Loss: 2.6486776769161224, Final Batch Loss: 1.190072774887085\n",
      "Epoch 3657, Loss: 1.5107560455799103, Final Batch Loss: 0.010357320308685303\n",
      "Epoch 3658, Loss: 1.5371294347569346, Final Batch Loss: 0.0069185225293040276\n",
      "Epoch 3659, Loss: 3.3841356337070465, Final Batch Loss: 1.9052505493164062\n",
      "Epoch 3660, Loss: 1.7529141008853912, Final Batch Loss: 0.2857016623020172\n",
      "Epoch 3661, Loss: 1.5185102373361588, Final Batch Loss: 0.04403851926326752\n",
      "Epoch 3662, Loss: 1.4990869766043033, Final Batch Loss: 0.0004215544031467289\n",
      "Epoch 3663, Loss: 1.527394413948059, Final Batch Loss: 0.06240427494049072\n",
      "Epoch 3664, Loss: 3.2087422609329224, Final Batch Loss: 1.6744194030761719\n",
      "Epoch 3665, Loss: 1.5630981419235468, Final Batch Loss: 0.020833471789956093\n",
      "Epoch 3666, Loss: 2.5386438369750977, Final Batch Loss: 0.6262757778167725\n",
      "Epoch 3667, Loss: 2.3862356077879667, Final Batch Loss: 0.02165902964770794\n",
      "Epoch 3668, Loss: 2.4346955716609955, Final Batch Loss: 0.22514817118644714\n",
      "Epoch 3669, Loss: 4.071264207363129, Final Batch Loss: 2.1831445693969727\n",
      "Epoch 3670, Loss: 1.6852413434535265, Final Batch Loss: 0.02873230166733265\n",
      "Epoch 3671, Loss: 1.702677162596956, Final Batch Loss: 0.0038028082344681025\n",
      "Epoch 3672, Loss: 1.7184032648801804, Final Batch Loss: 0.09033374488353729\n",
      "Epoch 3673, Loss: 1.6549096405506134, Final Batch Loss: 0.11188596487045288\n",
      "Epoch 3674, Loss: 1.6279302360489964, Final Batch Loss: 0.012540650554001331\n",
      "Epoch 3675, Loss: 2.212372213602066, Final Batch Loss: 0.6525996923446655\n",
      "Epoch 3676, Loss: 1.8074607253074646, Final Batch Loss: 0.28463035821914673\n",
      "Epoch 3677, Loss: 1.5159551274846308, Final Batch Loss: 0.0007225048611871898\n",
      "Epoch 3678, Loss: 2.5949502885341644, Final Batch Loss: 1.1197316646575928\n",
      "Epoch 3679, Loss: 1.4465250200591981, Final Batch Loss: 0.0011338717304170132\n",
      "Epoch 3680, Loss: 1.7795445919036865, Final Batch Loss: 0.2996060252189636\n",
      "Epoch 3681, Loss: 1.5332427872344851, Final Batch Loss: 0.010058666579425335\n",
      "Epoch 3682, Loss: 3.5685707926750183, Final Batch Loss: 2.0416040420532227\n",
      "Epoch 3683, Loss: 1.5210690200328827, Final Batch Loss: 0.02584981918334961\n",
      "Epoch 3684, Loss: 2.2081662714481354, Final Batch Loss: 0.7020074725151062\n",
      "Epoch 3685, Loss: 1.932405173778534, Final Batch Loss: 0.44452905654907227\n",
      "Epoch 3686, Loss: 3.007525771856308, Final Batch Loss: 1.577736735343933\n",
      "Epoch 3687, Loss: 1.492767897732847, Final Batch Loss: 7.068861305015162e-05\n",
      "Epoch 3688, Loss: 3.3753156065940857, Final Batch Loss: 1.8185333013534546\n",
      "Epoch 3689, Loss: 1.9358627498149872, Final Batch Loss: 0.25519391894340515\n",
      "Epoch 3690, Loss: 2.9933390617370605, Final Batch Loss: 1.3330340385437012\n",
      "Epoch 3691, Loss: 2.0583687722682953, Final Batch Loss: 0.43614867329597473\n",
      "Epoch 3692, Loss: 4.475691974163055, Final Batch Loss: 2.5249102115631104\n",
      "Epoch 3693, Loss: 1.9680108845350333, Final Batch Loss: 0.000715833914000541\n",
      "Epoch 3694, Loss: 3.3288668990135193, Final Batch Loss: 1.4379422664642334\n",
      "Epoch 3695, Loss: 2.816022515296936, Final Batch Loss: 1.1109906435012817\n",
      "Epoch 3696, Loss: 2.721839427947998, Final Batch Loss: 1.066419243812561\n",
      "Epoch 3697, Loss: 1.80003622174263, Final Batch Loss: 0.22351646423339844\n",
      "Epoch 3698, Loss: 1.8135866522789001, Final Batch Loss: 0.229661226272583\n",
      "Epoch 3699, Loss: 1.6078947782515343, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3700, Loss: 1.5922435360989766, Final Batch Loss: 0.00017951308109331876\n",
      "Epoch 3701, Loss: 1.611490473151207, Final Batch Loss: 0.06867547333240509\n",
      "Epoch 3702, Loss: 3.888020783662796, Final Batch Loss: 2.2936301231384277\n",
      "Epoch 3703, Loss: 2.2394235730171204, Final Batch Loss: 0.6785030961036682\n",
      "Epoch 3704, Loss: 1.6317283883690834, Final Batch Loss: 0.024082399904727936\n",
      "Epoch 3705, Loss: 1.6006215885281563, Final Batch Loss: 0.04891658574342728\n",
      "Epoch 3706, Loss: 1.600016176700592, Final Batch Loss: 0.11280083656311035\n",
      "Epoch 3707, Loss: 3.524284839630127, Final Batch Loss: 2.0134477615356445\n",
      "Epoch 3708, Loss: 1.5701321866363287, Final Batch Loss: 0.014353951439261436\n",
      "Epoch 3709, Loss: 1.796763837337494, Final Batch Loss: 0.3067239224910736\n",
      "Epoch 3710, Loss: 2.150336056947708, Final Batch Loss: 0.6819732785224915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3711, Loss: 1.5303700044751167, Final Batch Loss: 0.03372449427843094\n",
      "Epoch 3712, Loss: 1.5000020914012566, Final Batch Loss: 0.0007651500636711717\n",
      "Epoch 3713, Loss: 1.8444295823574066, Final Batch Loss: 0.26325780153274536\n",
      "Epoch 3714, Loss: 2.839670717716217, Final Batch Loss: 1.3762109279632568\n",
      "Epoch 3715, Loss: 4.6678138971328735, Final Batch Loss: 3.081658124923706\n",
      "Epoch 3716, Loss: 1.5092966575175524, Final Batch Loss: 0.013152273371815681\n",
      "Epoch 3717, Loss: 1.8824227452278137, Final Batch Loss: 0.3393978476524353\n",
      "Epoch 3718, Loss: 1.729956939816475, Final Batch Loss: 0.16125501692295074\n",
      "Epoch 3719, Loss: 1.5123664140701294, Final Batch Loss: 0.0\n",
      "Epoch 3720, Loss: 2.8384949862957, Final Batch Loss: 1.2856850624084473\n",
      "Epoch 3721, Loss: 4.892724543809891, Final Batch Loss: 3.4292094707489014\n",
      "Epoch 3722, Loss: 1.5051109790802002, Final Batch Loss: 0.0\n",
      "Epoch 3723, Loss: 1.6595924496650696, Final Batch Loss: 0.06668293476104736\n",
      "Epoch 3724, Loss: 1.7219838798046112, Final Batch Loss: 0.20791879296302795\n",
      "Epoch 3725, Loss: 1.594402670794807, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 3726, Loss: 1.6567973643541336, Final Batch Loss: 0.06277324259281158\n",
      "Epoch 3727, Loss: 2.6981457471847534, Final Batch Loss: 1.160521388053894\n",
      "Epoch 3728, Loss: 1.6064538061618805, Final Batch Loss: 0.07010862231254578\n",
      "Epoch 3729, Loss: 1.5513328313824104, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3730, Loss: 1.496626168488433, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3731, Loss: 1.5586164655978791, Final Batch Loss: 0.0004752936656586826\n",
      "Epoch 3732, Loss: 1.5731888115406036, Final Batch Loss: 0.06479513645172119\n",
      "Epoch 3733, Loss: 1.6118667647242546, Final Batch Loss: 0.03830739110708237\n",
      "Epoch 3734, Loss: 1.5594317466020584, Final Batch Loss: 0.08234651386737823\n",
      "Epoch 3735, Loss: 1.4615667965263128, Final Batch Loss: 0.026402970775961876\n",
      "Epoch 3736, Loss: 1.7003380954265594, Final Batch Loss: 0.26063841581344604\n",
      "Epoch 3737, Loss: 1.428330548107624, Final Batch Loss: 0.04878205806016922\n",
      "Epoch 3738, Loss: 3.0288475453853607, Final Batch Loss: 1.6249737739562988\n",
      "Epoch 3739, Loss: 1.4451118415454403, Final Batch Loss: 0.0010350352386012673\n",
      "Epoch 3740, Loss: 1.9344627857208252, Final Batch Loss: 0.5331630706787109\n",
      "Epoch 3741, Loss: 1.41404582047835, Final Batch Loss: 0.004223356489092112\n",
      "Epoch 3742, Loss: 2.197394013404846, Final Batch Loss: 0.7495819926261902\n",
      "Epoch 3743, Loss: 1.4258679040940478, Final Batch Loss: 0.0015315004857257009\n",
      "Epoch 3744, Loss: 1.519830465316744, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3745, Loss: 3.8721536099910736, Final Batch Loss: 2.4052391052246094\n",
      "Epoch 3746, Loss: 1.6812375038862228, Final Batch Loss: 0.24311219155788422\n",
      "Epoch 3747, Loss: 1.6146911531686783, Final Batch Loss: 0.1381363421678543\n",
      "Epoch 3748, Loss: 3.224869281053543, Final Batch Loss: 1.734529733657837\n",
      "Epoch 3749, Loss: 1.4638537280261517, Final Batch Loss: 0.04741690680384636\n",
      "Epoch 3750, Loss: 2.5615871250629425, Final Batch Loss: 1.1882213354110718\n",
      "Epoch 3751, Loss: 1.4317173063755035, Final Batch Loss: 0.02040618658065796\n",
      "Epoch 3752, Loss: 1.4112121739890426, Final Batch Loss: 0.002536890795454383\n",
      "Epoch 3753, Loss: 1.3662364985211752, Final Batch Loss: 0.0003713871701620519\n",
      "Epoch 3754, Loss: 1.689917877316475, Final Batch Loss: 0.24886439740657806\n",
      "Epoch 3755, Loss: 1.4584825038909912, Final Batch Loss: 0.0\n",
      "Epoch 3756, Loss: 1.7945892214775085, Final Batch Loss: 0.3898976743221283\n",
      "Epoch 3757, Loss: 1.6368045955896378, Final Batch Loss: 0.1834026426076889\n",
      "Epoch 3758, Loss: 1.5620508566498756, Final Batch Loss: 0.09785933047533035\n",
      "Epoch 3759, Loss: 1.4125394821166992, Final Batch Loss: 0.0\n",
      "Epoch 3760, Loss: 2.44613453745842, Final Batch Loss: 1.0147956609725952\n",
      "Epoch 3761, Loss: 2.5577272474765778, Final Batch Loss: 1.084592580795288\n",
      "Epoch 3762, Loss: 1.4668906478909776, Final Batch Loss: 0.0014947204617783427\n",
      "Epoch 3763, Loss: 2.5160123109817505, Final Batch Loss: 1.067442536354065\n",
      "Epoch 3764, Loss: 2.9203367233276367, Final Batch Loss: 1.4875366687774658\n",
      "Epoch 3765, Loss: 3.08294078707695, Final Batch Loss: 1.6756049394607544\n",
      "Epoch 3766, Loss: 1.40893186442554, Final Batch Loss: 0.011575086042284966\n",
      "Epoch 3767, Loss: 1.4282845351845026, Final Batch Loss: 0.024484852328896523\n",
      "Epoch 3768, Loss: 1.7830849289894104, Final Batch Loss: 0.38354799151420593\n",
      "Epoch 3769, Loss: 1.4975883290171623, Final Batch Loss: 0.033454529941082\n",
      "Epoch 3770, Loss: 1.374155447119847, Final Batch Loss: 0.0029332491103559732\n",
      "Epoch 3771, Loss: 1.3606876209378242, Final Batch Loss: 0.0006796196103096008\n",
      "Epoch 3772, Loss: 4.056836783885956, Final Batch Loss: 2.651350975036621\n",
      "Epoch 3773, Loss: 1.4171246844925918, Final Batch Loss: 0.000553335587028414\n",
      "Epoch 3774, Loss: 1.9574337601661682, Final Batch Loss: 0.5251946449279785\n",
      "Epoch 3775, Loss: 1.3835142329335213, Final Batch Loss: 0.0035756006836891174\n",
      "Epoch 3776, Loss: 1.9998416900634766, Final Batch Loss: 0.536748468875885\n",
      "Epoch 3777, Loss: 1.4540263309900183, Final Batch Loss: 0.00037424711626954377\n",
      "Epoch 3778, Loss: 1.8780733942985535, Final Batch Loss: 0.44398602843284607\n",
      "Epoch 3779, Loss: 2.475550413131714, Final Batch Loss: 1.0834777355194092\n",
      "Epoch 3780, Loss: 2.322593033313751, Final Batch Loss: 0.9193764328956604\n",
      "Epoch 3781, Loss: 3.1333601474761963, Final Batch Loss: 1.6877241134643555\n",
      "Epoch 3782, Loss: 1.501480046659708, Final Batch Loss: 0.047307077795267105\n",
      "Epoch 3783, Loss: 3.0646560192108154, Final Batch Loss: 1.2473034858703613\n",
      "Epoch 3784, Loss: 2.1227488490985706, Final Batch Loss: 0.0008487674640491605\n",
      "Epoch 3785, Loss: 2.35267473035492, Final Batch Loss: 0.0028846340719610453\n",
      "Epoch 3786, Loss: 2.2261731885373592, Final Batch Loss: 0.060209181159734726\n",
      "Epoch 3787, Loss: 9.406635105609894, Final Batch Loss: 7.111412525177002\n",
      "Epoch 3788, Loss: 2.1533497273921967, Final Batch Loss: 0.18123719096183777\n",
      "Epoch 3789, Loss: 1.7601886391614698, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3790, Loss: 2.0263476967811584, Final Batch Loss: 0.3718087077140808\n",
      "Epoch 3791, Loss: 2.694723427295685, Final Batch Loss: 1.0640822649002075\n",
      "Epoch 3792, Loss: 3.074235677719116, Final Batch Loss: 1.4113285541534424\n",
      "Epoch 3793, Loss: 1.6444604378193617, Final Batch Loss: 0.010374663397669792\n",
      "Epoch 3794, Loss: 1.6526550892740488, Final Batch Loss: 0.03097381629049778\n",
      "Epoch 3795, Loss: 2.3115060329437256, Final Batch Loss: 0.6568350791931152\n",
      "Epoch 3796, Loss: 2.509511798620224, Final Batch Loss: 0.979130744934082\n",
      "Epoch 3797, Loss: 2.5768278539180756, Final Batch Loss: 0.994337260723114\n",
      "Epoch 3798, Loss: 1.7366714626550674, Final Batch Loss: 0.19251392781734467\n",
      "Epoch 3799, Loss: 1.7014418095350266, Final Batch Loss: 0.1096033900976181\n",
      "Epoch 3800, Loss: 1.6486200969666243, Final Batch Loss: 0.018948612734675407\n",
      "Epoch 3801, Loss: 1.6146563664078712, Final Batch Loss: 0.035418130457401276\n",
      "Epoch 3802, Loss: 2.454675257205963, Final Batch Loss: 0.8327625393867493\n",
      "Epoch 3803, Loss: 2.954859495162964, Final Batch Loss: 1.4234908819198608\n",
      "Epoch 3804, Loss: 1.6664841920137405, Final Batch Loss: 0.11908014118671417\n",
      "Epoch 3805, Loss: 1.5194019098998979, Final Batch Loss: 0.0016720612766221166\n",
      "Epoch 3806, Loss: 2.690718173980713, Final Batch Loss: 1.086378574371338\n",
      "Epoch 3807, Loss: 1.657111532986164, Final Batch Loss: 0.09351427108049393\n",
      "Epoch 3808, Loss: 3.17317795753479, Final Batch Loss: 1.7814210653305054\n",
      "Epoch 3809, Loss: 2.8480247855186462, Final Batch Loss: 1.3583248853683472\n",
      "Epoch 3810, Loss: 2.2089555859565735, Final Batch Loss: 0.7433700561523438\n",
      "Epoch 3811, Loss: 1.685779757797718, Final Batch Loss: 0.12314144521951675\n",
      "Epoch 3812, Loss: 1.7927969098091125, Final Batch Loss: 0.3072504699230194\n",
      "Epoch 3813, Loss: 1.7297417670488358, Final Batch Loss: 0.1875968724489212\n",
      "Epoch 3814, Loss: 2.0385521054267883, Final Batch Loss: 0.569511353969574\n",
      "Epoch 3815, Loss: 1.5428132861852646, Final Batch Loss: 0.049080267548561096\n",
      "Epoch 3816, Loss: 1.4788705888204277, Final Batch Loss: 0.0016077938489615917\n",
      "Epoch 3817, Loss: 1.529571384191513, Final Batch Loss: 0.03737443685531616\n",
      "Epoch 3818, Loss: 1.5728262141346931, Final Batch Loss: 0.01145724207162857\n",
      "Epoch 3819, Loss: 2.680040180683136, Final Batch Loss: 1.1640466451644897\n",
      "Epoch 3820, Loss: 1.5097917495295405, Final Batch Loss: 0.010809439234435558\n",
      "Epoch 3821, Loss: 1.6466846764087677, Final Batch Loss: 0.19258511066436768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3822, Loss: 1.473581112921238, Final Batch Loss: 0.03288231045007706\n",
      "Epoch 3823, Loss: 1.7373388409614563, Final Batch Loss: 0.3203129768371582\n",
      "Epoch 3824, Loss: 1.7272779494524002, Final Batch Loss: 0.2248292714357376\n",
      "Epoch 3825, Loss: 2.997418850660324, Final Batch Loss: 1.5236551761627197\n",
      "Epoch 3826, Loss: 1.4190581045113504, Final Batch Loss: 0.001409133430570364\n",
      "Epoch 3827, Loss: 1.4499086968135089, Final Batch Loss: 0.002030574483796954\n",
      "Epoch 3828, Loss: 1.5701252482831478, Final Batch Loss: 0.0607769750058651\n",
      "Epoch 3829, Loss: 2.074778288602829, Final Batch Loss: 0.5098406076431274\n",
      "Epoch 3830, Loss: 2.79719677567482, Final Batch Loss: 1.296736240386963\n",
      "Epoch 3831, Loss: 1.6854858398342003, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 3832, Loss: 3.3864599466323853, Final Batch Loss: 1.557084083557129\n",
      "Epoch 3833, Loss: 3.2859233021736145, Final Batch Loss: 1.4550316333770752\n",
      "Epoch 3834, Loss: 1.8238843828439713, Final Batch Loss: 0.0626000314950943\n",
      "Epoch 3835, Loss: 1.8082225397229195, Final Batch Loss: 0.052147991955280304\n",
      "Epoch 3836, Loss: 1.6820260202512145, Final Batch Loss: 0.00914787407964468\n",
      "Epoch 3837, Loss: 3.493795782327652, Final Batch Loss: 1.9264209270477295\n",
      "Epoch 3838, Loss: 1.6466372162103653, Final Batch Loss: 0.144600972533226\n",
      "Epoch 3839, Loss: 1.5477101423311979, Final Batch Loss: 0.0036457993555814028\n",
      "Epoch 3840, Loss: 1.575559067656286, Final Batch Loss: 0.0011807858245447278\n",
      "Epoch 3841, Loss: 2.7456261813640594, Final Batch Loss: 1.121788501739502\n",
      "Epoch 3842, Loss: 1.5142618753015995, Final Batch Loss: 0.022350672632455826\n",
      "Epoch 3843, Loss: 1.567385494709015, Final Batch Loss: 0.0\n",
      "Epoch 3844, Loss: 1.5668666083365679, Final Batch Loss: 0.02557400055229664\n",
      "Epoch 3845, Loss: 1.4917643696535379, Final Batch Loss: 0.003353568958118558\n",
      "Epoch 3846, Loss: 1.503143539535813, Final Batch Loss: 0.001408895361237228\n",
      "Epoch 3847, Loss: 3.3183617889881134, Final Batch Loss: 1.760589838027954\n",
      "Epoch 3848, Loss: 3.375097692012787, Final Batch Loss: 1.948418140411377\n",
      "Epoch 3849, Loss: 2.510388493537903, Final Batch Loss: 1.0866765975952148\n",
      "Epoch 3850, Loss: 1.59101240336895, Final Batch Loss: 0.0907839983701706\n",
      "Epoch 3851, Loss: 1.9117807149887085, Final Batch Loss: 0.37472429871559143\n",
      "Epoch 3852, Loss: 1.5746363699433914, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3853, Loss: 1.7130107134580612, Final Batch Loss: 0.17373935878276825\n",
      "Epoch 3854, Loss: 3.342803657054901, Final Batch Loss: 1.7726364135742188\n",
      "Epoch 3855, Loss: 1.6048170325811952, Final Batch Loss: 0.0014848408754915\n",
      "Epoch 3856, Loss: 2.452356278896332, Final Batch Loss: 0.8287217020988464\n",
      "Epoch 3857, Loss: 1.5778078138828278, Final Batch Loss: 0.003544241189956665\n",
      "Epoch 3858, Loss: 2.777590364217758, Final Batch Loss: 1.2083935737609863\n",
      "Epoch 3859, Loss: 2.5899951457977295, Final Batch Loss: 1.0823230743408203\n",
      "Epoch 3860, Loss: 1.6307578384876251, Final Batch Loss: 0.12678954005241394\n",
      "Epoch 3861, Loss: 2.3503405451774597, Final Batch Loss: 0.8535728454589844\n",
      "Epoch 3862, Loss: 2.4617408514022827, Final Batch Loss: 1.0035842657089233\n",
      "Epoch 3863, Loss: 1.4931277967989445, Final Batch Loss: 0.020353857427835464\n",
      "Epoch 3864, Loss: 1.6550074964761734, Final Batch Loss: 0.17127878963947296\n",
      "Epoch 3865, Loss: 2.117848962545395, Final Batch Loss: 0.6407682299613953\n",
      "Epoch 3866, Loss: 2.5872595012187958, Final Batch Loss: 1.0967814922332764\n",
      "Epoch 3867, Loss: 3.9608628153800964, Final Batch Loss: 2.55778431892395\n",
      "Epoch 3868, Loss: 2.4014832377433777, Final Batch Loss: 0.9948283433914185\n",
      "Epoch 3869, Loss: 1.683868631720543, Final Batch Loss: 0.2412506490945816\n",
      "Epoch 3870, Loss: 2.0495265126228333, Final Batch Loss: 0.623748779296875\n",
      "Epoch 3871, Loss: 1.6599827408790588, Final Batch Loss: 0.1689312756061554\n",
      "Epoch 3872, Loss: 2.149551182985306, Final Batch Loss: 0.6682699918746948\n",
      "Epoch 3873, Loss: 1.5386789143071837, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 3874, Loss: 1.4213954210280804, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3875, Loss: 3.0674385130405426, Final Batch Loss: 1.6501848697662354\n",
      "Epoch 3876, Loss: 2.7315857112407684, Final Batch Loss: 1.309797763824463\n",
      "Epoch 3877, Loss: 2.976590096950531, Final Batch Loss: 1.4674530029296875\n",
      "Epoch 3878, Loss: 2.356043040752411, Final Batch Loss: 0.8282442688941956\n",
      "Epoch 3879, Loss: 2.313722103834152, Final Batch Loss: 0.824110746383667\n",
      "Epoch 3880, Loss: 1.8974149823129665, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 3881, Loss: 2.615745022892952, Final Batch Loss: 0.10223175585269928\n",
      "Epoch 3882, Loss: 2.249294400215142, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3883, Loss: 1.9079501628780235, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 3884, Loss: 1.8851088285446167, Final Batch Loss: 0.20482230186462402\n",
      "Epoch 3885, Loss: 2.534028112888336, Final Batch Loss: 0.8791964650154114\n",
      "Epoch 3886, Loss: 1.61660367064178, Final Batch Loss: 0.016459165140986443\n",
      "Epoch 3887, Loss: 2.2829933762550354, Final Batch Loss: 0.7938808798789978\n",
      "Epoch 3888, Loss: 1.6393961235880852, Final Batch Loss: 0.11916374415159225\n",
      "Epoch 3889, Loss: 2.185029238462448, Final Batch Loss: 0.6486265659332275\n",
      "Epoch 3890, Loss: 1.7773680090904236, Final Batch Loss: 0.33922675251960754\n",
      "Epoch 3891, Loss: 1.4351981338113546, Final Batch Loss: 0.028497016057372093\n",
      "Epoch 3892, Loss: 1.5157581914681941, Final Batch Loss: 0.0038564850110560656\n",
      "Epoch 3893, Loss: 2.0107652246952057, Final Batch Loss: 0.5941269993782043\n",
      "Epoch 3894, Loss: 1.4517296999692917, Final Batch Loss: 0.04821400344371796\n",
      "Epoch 3895, Loss: 1.4101618770509958, Final Batch Loss: 0.022274428978562355\n",
      "Epoch 3896, Loss: 2.660601556301117, Final Batch Loss: 1.1891469955444336\n",
      "Epoch 3897, Loss: 1.779470443725586, Final Batch Loss: 0.3059696853160858\n",
      "Epoch 3898, Loss: 2.400160074234009, Final Batch Loss: 0.9826147556304932\n",
      "Epoch 3899, Loss: 2.063866049051285, Final Batch Loss: 0.5763088464736938\n",
      "Epoch 3900, Loss: 1.4167518764734268, Final Batch Loss: 0.016459986567497253\n",
      "Epoch 3901, Loss: 2.8813887536525726, Final Batch Loss: 1.4453245401382446\n",
      "Epoch 3902, Loss: 1.4313086504116654, Final Batch Loss: 0.00605925265699625\n",
      "Epoch 3903, Loss: 3.2873435616493225, Final Batch Loss: 1.822655200958252\n",
      "Epoch 3904, Loss: 1.4644175162538886, Final Batch Loss: 0.011665581725537777\n",
      "Epoch 3905, Loss: 1.5482647120952606, Final Batch Loss: 0.051768749952316284\n",
      "Epoch 3906, Loss: 3.2335681915283203, Final Batch Loss: 1.7530903816223145\n",
      "Epoch 3907, Loss: 2.9817352294921875, Final Batch Loss: 1.4309096336364746\n",
      "Epoch 3908, Loss: 2.6823366284370422, Final Batch Loss: 1.253448486328125\n",
      "Epoch 3909, Loss: 3.0619733929634094, Final Batch Loss: 1.5784447193145752\n",
      "Epoch 3910, Loss: 1.7005269825458527, Final Batch Loss: 0.2215108573436737\n",
      "Epoch 3911, Loss: 1.8892219066619873, Final Batch Loss: 0.3525097370147705\n",
      "Epoch 3912, Loss: 2.009859561920166, Final Batch Loss: 0.482166588306427\n",
      "Epoch 3913, Loss: 2.5539656579494476, Final Batch Loss: 1.1097781658172607\n",
      "Epoch 3914, Loss: 1.5683361254632473, Final Batch Loss: 0.060512419790029526\n",
      "Epoch 3915, Loss: 1.6433787271380424, Final Batch Loss: 0.06868492811918259\n",
      "Epoch 3916, Loss: 2.202297955751419, Final Batch Loss: 0.7258788347244263\n",
      "Epoch 3917, Loss: 1.5280716009438038, Final Batch Loss: 0.033112067729234695\n",
      "Epoch 3918, Loss: 2.3996562063694, Final Batch Loss: 1.0117789506912231\n",
      "Epoch 3919, Loss: 3.805662602186203, Final Batch Loss: 2.3871407508850098\n",
      "Epoch 3920, Loss: 1.5288086645305157, Final Batch Loss: 0.03659830614924431\n",
      "Epoch 3921, Loss: 1.648567020893097, Final Batch Loss: 0.23297560214996338\n",
      "Epoch 3922, Loss: 1.3888410302752163, Final Batch Loss: 0.0002549561613705009\n",
      "Epoch 3923, Loss: 1.4036774691194296, Final Batch Loss: 0.005190705880522728\n",
      "Epoch 3924, Loss: 1.3381531536515467, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 3925, Loss: 2.7843153178691864, Final Batch Loss: 1.456050157546997\n",
      "Epoch 3926, Loss: 2.5836316347122192, Final Batch Loss: 1.140763282775879\n",
      "Epoch 3927, Loss: 1.7926924526691437, Final Batch Loss: 0.16017159819602966\n",
      "Epoch 3928, Loss: 1.761711984872818, Final Batch Loss: 0.007934361696243286\n",
      "Epoch 3929, Loss: 4.325990259647369, Final Batch Loss: 2.539487361907959\n",
      "Epoch 3930, Loss: 1.5551586216315627, Final Batch Loss: 0.006779170595109463\n",
      "Epoch 3931, Loss: 1.6920391768217087, Final Batch Loss: 0.2257705181837082\n",
      "Epoch 3932, Loss: 2.8859091997146606, Final Batch Loss: 1.3012796640396118\n",
      "Epoch 3933, Loss: 1.6571920849382877, Final Batch Loss: 0.054328206926584244\n",
      "Epoch 3934, Loss: 2.325334072113037, Final Batch Loss: 0.5509527921676636\n",
      "Epoch 3935, Loss: 1.808503121137619, Final Batch Loss: 0.07655999064445496\n",
      "Epoch 3936, Loss: 3.096816658973694, Final Batch Loss: 1.4479957818984985\n",
      "Epoch 3937, Loss: 1.6025989847257733, Final Batch Loss: 0.014706303365528584\n",
      "Epoch 3938, Loss: 1.7263971343636513, Final Batch Loss: 0.059102632105350494\n",
      "Epoch 3939, Loss: 1.6161783188581467, Final Batch Loss: 0.04403851926326752\n",
      "Epoch 3940, Loss: 1.6293131411075592, Final Batch Loss: 0.08260217308998108\n",
      "Epoch 3941, Loss: 1.7864522486925125, Final Batch Loss: 0.1899464875459671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3942, Loss: 3.5058484077453613, Final Batch Loss: 1.9506826400756836\n",
      "Epoch 3943, Loss: 1.537416473031044, Final Batch Loss: 0.025892451405525208\n",
      "Epoch 3944, Loss: 2.6795522570610046, Final Batch Loss: 1.1894419193267822\n",
      "Epoch 3945, Loss: 1.6881777420639992, Final Batch Loss: 0.06579328328371048\n",
      "Epoch 3946, Loss: 2.8350606858730316, Final Batch Loss: 1.3496599197387695\n",
      "Epoch 3947, Loss: 1.7862781286239624, Final Batch Loss: 0.3277705907821655\n",
      "Epoch 3948, Loss: 1.5306794606149197, Final Batch Loss: 0.011849727481603622\n",
      "Epoch 3949, Loss: 1.4789719870314002, Final Batch Loss: 0.01444172766059637\n",
      "Epoch 3950, Loss: 1.4117346787825227, Final Batch Loss: 0.012585737742483616\n",
      "Epoch 3951, Loss: 1.4227800108492374, Final Batch Loss: 0.009249810129404068\n",
      "Epoch 3952, Loss: 1.4612619581166655, Final Batch Loss: 0.0022762122098356485\n",
      "Epoch 3953, Loss: 1.4471543617546558, Final Batch Loss: 0.01246907189488411\n",
      "Epoch 3954, Loss: 1.4619161635637283, Final Batch Loss: 0.004291966557502747\n",
      "Epoch 3955, Loss: 1.6350538432598114, Final Batch Loss: 0.20072004199028015\n",
      "Epoch 3956, Loss: 1.4237309971867944, Final Batch Loss: 6.389413465512916e-05\n",
      "Epoch 3957, Loss: 1.52772780880332, Final Batch Loss: 0.05533977970480919\n",
      "Epoch 3958, Loss: 2.833533227443695, Final Batch Loss: 1.4527913331985474\n",
      "Epoch 3959, Loss: 1.5719040464609861, Final Batch Loss: 0.015132976695895195\n",
      "Epoch 3960, Loss: 2.728099226951599, Final Batch Loss: 1.3433763980865479\n",
      "Epoch 3961, Loss: 1.4549816874787211, Final Batch Loss: 0.014638873748481274\n",
      "Epoch 3962, Loss: 3.0729822516441345, Final Batch Loss: 1.6846387386322021\n",
      "Epoch 3963, Loss: 2.509265214204788, Final Batch Loss: 1.1264359951019287\n",
      "Epoch 3964, Loss: 1.4461436970159411, Final Batch Loss: 0.006943146698176861\n",
      "Epoch 3965, Loss: 1.8736464381217957, Final Batch Loss: 0.3764970302581787\n",
      "Epoch 3966, Loss: 1.4874456226825714, Final Batch Loss: 0.09874424338340759\n",
      "Epoch 3967, Loss: 2.9231459498405457, Final Batch Loss: 1.585168480873108\n",
      "Epoch 3968, Loss: 1.4678412452340126, Final Batch Loss: 0.06359488517045975\n",
      "Epoch 3969, Loss: 2.45646271109581, Final Batch Loss: 0.8090560436248779\n",
      "Epoch 3970, Loss: 2.2366048395633698, Final Batch Loss: 0.4625210464000702\n",
      "Epoch 3971, Loss: 1.7444492289505433, Final Batch Loss: 0.0004207202873658389\n",
      "Epoch 3972, Loss: 1.9569913893938065, Final Batch Loss: 0.17114700376987457\n",
      "Epoch 3973, Loss: 1.6976556438021362, Final Batch Loss: 0.0006523388437926769\n",
      "Epoch 3974, Loss: 1.6391011774539948, Final Batch Loss: 0.03769788146018982\n",
      "Epoch 3975, Loss: 1.6945335492491722, Final Batch Loss: 0.09638413041830063\n",
      "Epoch 3976, Loss: 3.704839050769806, Final Batch Loss: 2.17121958732605\n",
      "Epoch 3977, Loss: 2.037737339735031, Final Batch Loss: 0.5792967677116394\n",
      "Epoch 3978, Loss: 1.4678949397057295, Final Batch Loss: 0.004590330645442009\n",
      "Epoch 3979, Loss: 1.7083715572953224, Final Batch Loss: 0.10906586796045303\n",
      "Epoch 3980, Loss: 1.753409519791603, Final Batch Loss: 0.2305934876203537\n",
      "Epoch 3981, Loss: 2.878984212875366, Final Batch Loss: 1.3538250923156738\n",
      "Epoch 3982, Loss: 2.5617207288742065, Final Batch Loss: 1.0146385431289673\n",
      "Epoch 3983, Loss: 1.7660219967365265, Final Batch Loss: 0.25068196654319763\n",
      "Epoch 3984, Loss: 1.7310638278722763, Final Batch Loss: 0.13658498227596283\n",
      "Epoch 3985, Loss: 1.524868007749319, Final Batch Loss: 0.018282469362020493\n",
      "Epoch 3986, Loss: 1.4635131508111954, Final Batch Loss: 0.030938103795051575\n",
      "Epoch 3987, Loss: 1.4140566056594253, Final Batch Loss: 0.004728919826447964\n",
      "Epoch 3988, Loss: 1.463161701336503, Final Batch Loss: 0.026248658075928688\n",
      "Epoch 3989, Loss: 1.5758798159658909, Final Batch Loss: 0.03194520249962807\n",
      "Epoch 3990, Loss: 2.73544642329216, Final Batch Loss: 1.2018468379974365\n",
      "Epoch 3991, Loss: 1.718925803899765, Final Batch Loss: 0.20171630382537842\n",
      "Epoch 3992, Loss: 3.1317977905273438, Final Batch Loss: 1.7272412776947021\n",
      "Epoch 3993, Loss: 1.4820474460721016, Final Batch Loss: 0.07147390395402908\n",
      "Epoch 3994, Loss: 1.5648524183779955, Final Batch Loss: 0.011369438841938972\n",
      "Epoch 3995, Loss: 1.587089091539383, Final Batch Loss: 0.12867403030395508\n",
      "Epoch 3996, Loss: 1.8201914429664612, Final Batch Loss: 0.3537278175354004\n",
      "Epoch 3997, Loss: 1.4881004493799992, Final Batch Loss: 0.000527123745996505\n",
      "Epoch 3998, Loss: 2.9065252244472504, Final Batch Loss: 1.470940113067627\n",
      "Epoch 3999, Loss: 1.8327932059764862, Final Batch Loss: 0.36846116185188293\n",
      "Epoch 4000, Loss: 2.7738786041736603, Final Batch Loss: 1.2768150568008423\n",
      "Epoch 4001, Loss: 2.444471687078476, Final Batch Loss: 1.0628929138183594\n",
      "Epoch 4002, Loss: 1.9854419231414795, Final Batch Loss: 0.5606268048286438\n",
      "Epoch 4003, Loss: 1.4270184123888612, Final Batch Loss: 0.00597784761339426\n",
      "Epoch 4004, Loss: 3.1927250921726227, Final Batch Loss: 1.755231499671936\n",
      "Epoch 4005, Loss: 1.502504512667656, Final Batch Loss: 0.0877612978219986\n",
      "Epoch 4006, Loss: 3.3859002590179443, Final Batch Loss: 1.9825489521026611\n",
      "Epoch 4007, Loss: 1.9931612312793732, Final Batch Loss: 0.5612898468971252\n",
      "Epoch 4008, Loss: 2.4305833876132965, Final Batch Loss: 1.0244193077087402\n",
      "Epoch 4009, Loss: 1.5152497584967932, Final Batch Loss: 3.0397906812140718e-05\n",
      "Epoch 4010, Loss: 1.4144360619975487, Final Batch Loss: 0.00014220656885299832\n",
      "Epoch 4011, Loss: 2.3060061633586884, Final Batch Loss: 0.8882821202278137\n",
      "Epoch 4012, Loss: 1.4623822080902755, Final Batch Loss: 0.0065194773487746716\n",
      "Epoch 4013, Loss: 2.2457282543182373, Final Batch Loss: 0.8430869579315186\n",
      "Epoch 4014, Loss: 1.4376014740555547, Final Batch Loss: 0.00035339308669790626\n",
      "Epoch 4015, Loss: 1.434610740689095, Final Batch Loss: 0.0008615119731985033\n",
      "Epoch 4016, Loss: 2.7626005113124847, Final Batch Loss: 1.3395607471466064\n",
      "Epoch 4017, Loss: 1.8427838385105133, Final Batch Loss: 0.4139467775821686\n",
      "Epoch 4018, Loss: 2.280853182077408, Final Batch Loss: 0.8773195743560791\n",
      "Epoch 4019, Loss: 3.2643294036388397, Final Batch Loss: 1.8738491535186768\n",
      "Epoch 4020, Loss: 2.244444102048874, Final Batch Loss: 0.8648507595062256\n",
      "Epoch 4021, Loss: 1.4611102128401399, Final Batch Loss: 0.0073748016729950905\n",
      "Epoch 4022, Loss: 1.526262916624546, Final Batch Loss: 0.12166056782007217\n",
      "Epoch 4023, Loss: 2.4505256712436676, Final Batch Loss: 1.0344840288162231\n",
      "Epoch 4024, Loss: 1.3636943335295655, Final Batch Loss: 0.0005012686015106738\n",
      "Epoch 4025, Loss: 3.851663589477539, Final Batch Loss: 2.4062752723693848\n",
      "Epoch 4026, Loss: 1.5673744156956673, Final Batch Loss: 0.06759396940469742\n",
      "Epoch 4027, Loss: 1.534936651471071, Final Batch Loss: 0.00045694399159401655\n",
      "Epoch 4028, Loss: 1.4009654429974034, Final Batch Loss: 0.00160624657291919\n",
      "Epoch 4029, Loss: 3.3967284560203552, Final Batch Loss: 1.929347276687622\n",
      "Epoch 4030, Loss: 3.734121263027191, Final Batch Loss: 2.362377405166626\n",
      "Epoch 4031, Loss: 2.3897968232631683, Final Batch Loss: 0.8880398273468018\n",
      "Epoch 4032, Loss: 1.5396349523216486, Final Batch Loss: 0.004272500053048134\n",
      "Epoch 4033, Loss: 1.5665471954271197, Final Batch Loss: 0.0038704974576830864\n",
      "Epoch 4034, Loss: 2.4218044877052307, Final Batch Loss: 0.7190930843353271\n",
      "Epoch 4035, Loss: 1.7780537009066393, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 4036, Loss: 1.7066222131252289, Final Batch Loss: 0.029966086149215698\n",
      "Epoch 4037, Loss: 3.254437804222107, Final Batch Loss: 1.7231388092041016\n",
      "Epoch 4038, Loss: 1.4050984112545848, Final Batch Loss: 0.007733169011771679\n",
      "Epoch 4039, Loss: 1.6520624607801437, Final Batch Loss: 0.1589941531419754\n",
      "Epoch 4040, Loss: 2.1800247728824615, Final Batch Loss: 0.6870002746582031\n",
      "Epoch 4041, Loss: 1.5261768326163292, Final Batch Loss: 0.052810393273830414\n",
      "Epoch 4042, Loss: 1.4901776853948832, Final Batch Loss: 0.0009513143450021744\n",
      "Epoch 4043, Loss: 1.4736847968306392, Final Batch Loss: 0.0014785320963710546\n",
      "Epoch 4044, Loss: 1.4912663102149963, Final Batch Loss: 0.1305743157863617\n",
      "Epoch 4045, Loss: 3.8127375841140747, Final Batch Loss: 2.283376693725586\n",
      "Epoch 4046, Loss: 3.07016584277153, Final Batch Loss: 1.637366533279419\n",
      "Epoch 4047, Loss: 1.7267320901155472, Final Batch Loss: 0.2181643396615982\n",
      "Epoch 4048, Loss: 3.5186601877212524, Final Batch Loss: 2.0409159660339355\n",
      "Epoch 4049, Loss: 1.9836368262767792, Final Batch Loss: 0.5560817718505859\n",
      "Epoch 4050, Loss: 2.356361150741577, Final Batch Loss: 0.9002072811126709\n",
      "Epoch 4051, Loss: 1.587824072841613, Final Batch Loss: 8.451581379631534e-05\n",
      "Epoch 4052, Loss: 2.631180465221405, Final Batch Loss: 1.131301999092102\n",
      "Epoch 4053, Loss: 1.441991093219258, Final Batch Loss: 0.0013572300085797906\n",
      "Epoch 4054, Loss: 1.5437102243304253, Final Batch Loss: 0.03766470402479172\n",
      "Epoch 4055, Loss: 1.9769521057605743, Final Batch Loss: 0.5569438338279724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4056, Loss: 1.482205955984682, Final Batch Loss: 4.875540980719961e-05\n",
      "Epoch 4057, Loss: 1.5561443269252777, Final Batch Loss: 0.07311061024665833\n",
      "Epoch 4058, Loss: 1.663024976849556, Final Batch Loss: 0.1986764520406723\n",
      "Epoch 4059, Loss: 2.6108563244342804, Final Batch Loss: 1.1802901029586792\n",
      "Epoch 4060, Loss: 1.4123356863856316, Final Batch Loss: 0.00531759113073349\n",
      "Epoch 4061, Loss: 2.5004220008850098, Final Batch Loss: 1.0793205499649048\n",
      "Epoch 4062, Loss: 1.4100585505366325, Final Batch Loss: 0.005844764411449432\n",
      "Epoch 4063, Loss: 1.5171507321647368, Final Batch Loss: 0.0008068405441008508\n",
      "Epoch 4064, Loss: 2.6082096695899963, Final Batch Loss: 1.2452348470687866\n",
      "Epoch 4065, Loss: 2.67278453707695, Final Batch Loss: 1.3205275535583496\n",
      "Epoch 4066, Loss: 1.4653069525957108, Final Batch Loss: 0.09938685595989227\n",
      "Epoch 4067, Loss: 2.6164364218711853, Final Batch Loss: 1.1128116846084595\n",
      "Epoch 4068, Loss: 1.4733514189720154, Final Batch Loss: 0.03151640295982361\n",
      "Epoch 4069, Loss: 1.4561012395424768, Final Batch Loss: 0.0007312007946893573\n",
      "Epoch 4070, Loss: 2.913249433040619, Final Batch Loss: 1.4961241483688354\n",
      "Epoch 4071, Loss: 2.746775895357132, Final Batch Loss: 1.3047564029693604\n",
      "Epoch 4072, Loss: 1.6795808672904968, Final Batch Loss: 0.28173506259918213\n",
      "Epoch 4073, Loss: 2.696747452020645, Final Batch Loss: 1.2849410772323608\n",
      "Epoch 4074, Loss: 1.4473605658859015, Final Batch Loss: 0.01706956885755062\n",
      "Epoch 4075, Loss: 1.5298357009887695, Final Batch Loss: 0.1501164436340332\n",
      "Epoch 4076, Loss: 2.477393627166748, Final Batch Loss: 1.010968804359436\n",
      "Epoch 4077, Loss: 1.6259467601776123, Final Batch Loss: 0.14557144045829773\n",
      "Epoch 4078, Loss: 1.4251019298098981, Final Batch Loss: 0.0010124086402356625\n",
      "Epoch 4079, Loss: 1.5679808259010315, Final Batch Loss: 0.09777036309242249\n",
      "Epoch 4080, Loss: 1.4306477105710655, Final Batch Loss: 0.0021921193692833185\n",
      "Epoch 4081, Loss: 1.4818768198601902, Final Batch Loss: 0.003018468152731657\n",
      "Epoch 4082, Loss: 1.413634717464447, Final Batch Loss: 0.04399847984313965\n",
      "Epoch 4083, Loss: 2.2913873493671417, Final Batch Loss: 0.897863507270813\n",
      "Epoch 4084, Loss: 1.47790939360857, Final Batch Loss: 0.040167368948459625\n",
      "Epoch 4085, Loss: 1.4666713404585607, Final Batch Loss: 0.0006568658282049\n",
      "Epoch 4086, Loss: 1.483370172791183, Final Batch Loss: 0.01503856759518385\n",
      "Epoch 4087, Loss: 1.9791655540466309, Final Batch Loss: 0.45363104343414307\n",
      "Epoch 4088, Loss: 1.3613984361290932, Final Batch Loss: 0.020389951765537262\n",
      "Epoch 4089, Loss: 1.4580746782012284, Final Batch Loss: 0.006108779925853014\n",
      "Epoch 4090, Loss: 1.4381349353061523, Final Batch Loss: 0.00025674383505247533\n",
      "Epoch 4091, Loss: 1.4200926476623863, Final Batch Loss: 0.0036339217331260443\n",
      "Epoch 4092, Loss: 2.781565696001053, Final Batch Loss: 1.355673909187317\n",
      "Epoch 4093, Loss: 1.4205967062152922, Final Batch Loss: 0.00045158201828598976\n",
      "Epoch 4094, Loss: 1.5340941287577152, Final Batch Loss: 0.014222566038370132\n",
      "Epoch 4095, Loss: 1.8430697619915009, Final Batch Loss: 0.44007545709609985\n",
      "Epoch 4096, Loss: 1.3807915686629713, Final Batch Loss: 0.004800224211066961\n",
      "Epoch 4097, Loss: 1.5300641991198063, Final Batch Loss: 0.043768469244241714\n",
      "Epoch 4098, Loss: 1.4604639024473727, Final Batch Loss: 0.0035801143385469913\n",
      "Epoch 4099, Loss: 2.2873364686965942, Final Batch Loss: 0.7989125847816467\n",
      "Epoch 4100, Loss: 1.8980557024478912, Final Batch Loss: 0.4725939929485321\n",
      "Epoch 4101, Loss: 2.901699483394623, Final Batch Loss: 1.4487168788909912\n",
      "Epoch 4102, Loss: 1.500602155116212, Final Batch Loss: 4.017272294731811e-05\n",
      "Epoch 4103, Loss: 1.5408817832358181, Final Batch Loss: 0.001618743408471346\n",
      "Epoch 4104, Loss: 1.4467729637399316, Final Batch Loss: 0.0024154791608452797\n",
      "Epoch 4105, Loss: 1.5968052595853806, Final Batch Loss: 0.22900430858135223\n",
      "Epoch 4106, Loss: 1.4406980631465558, Final Batch Loss: 0.00032824851223267615\n",
      "Epoch 4107, Loss: 1.4510428961366415, Final Batch Loss: 0.005791431292891502\n",
      "Epoch 4108, Loss: 2.4677672684192657, Final Batch Loss: 1.0768964290618896\n",
      "Epoch 4109, Loss: 1.374403577297926, Final Batch Loss: 0.05768163129687309\n",
      "Epoch 4110, Loss: 1.5820116251707077, Final Batch Loss: 0.18518616259098053\n",
      "Epoch 4111, Loss: 1.4141053308267146, Final Batch Loss: 0.003344183089211583\n",
      "Epoch 4112, Loss: 1.4140880899503827, Final Batch Loss: 0.0034708278253674507\n",
      "Epoch 4113, Loss: 1.4194136671721935, Final Batch Loss: 0.027765672653913498\n",
      "Epoch 4114, Loss: 2.7839319109916687, Final Batch Loss: 1.3731263875961304\n",
      "Epoch 4115, Loss: 1.7920943796634674, Final Batch Loss: 0.3618510961532593\n",
      "Epoch 4116, Loss: 1.958234280347824, Final Batch Loss: 0.5091222524642944\n",
      "Epoch 4117, Loss: 1.342944728443399, Final Batch Loss: 0.003322677919641137\n",
      "Epoch 4118, Loss: 1.4424704313278198, Final Batch Loss: 0.08297571539878845\n",
      "Epoch 4119, Loss: 1.4264648891985416, Final Batch Loss: 0.027946297079324722\n",
      "Epoch 4120, Loss: 1.7489619255065918, Final Batch Loss: 0.3980446755886078\n",
      "Epoch 4121, Loss: 2.4519118070602417, Final Batch Loss: 1.0588915348052979\n",
      "Epoch 4122, Loss: 3.766708582639694, Final Batch Loss: 2.436675786972046\n",
      "Epoch 4123, Loss: 1.5000332333147526, Final Batch Loss: 0.0319865383207798\n",
      "Epoch 4124, Loss: 1.3268350111320615, Final Batch Loss: 0.009930138476192951\n",
      "Epoch 4125, Loss: 2.040062338113785, Final Batch Loss: 0.619484007358551\n",
      "Epoch 4126, Loss: 1.2981521785257542, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4127, Loss: 1.3955309987067608, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4128, Loss: 1.3987325942143798, Final Batch Loss: 0.00897433515638113\n",
      "Epoch 4129, Loss: 1.3135632807388902, Final Batch Loss: 0.009046637453138828\n",
      "Epoch 4130, Loss: 1.4518831595778465, Final Batch Loss: 0.11000030487775803\n",
      "Epoch 4131, Loss: 1.5773543119430542, Final Batch Loss: 0.1426171064376831\n",
      "Epoch 4132, Loss: 1.3271089550107718, Final Batch Loss: 0.0232702549546957\n",
      "Epoch 4133, Loss: 1.6737298965454102, Final Batch Loss: 0.2966262996196747\n",
      "Epoch 4134, Loss: 1.3898557509528473, Final Batch Loss: 0.001111009274609387\n",
      "Epoch 4135, Loss: 1.4247897872992326, Final Batch Loss: 0.0003424296446610242\n",
      "Epoch 4136, Loss: 1.3456193036399782, Final Batch Loss: 0.0023354417644441128\n",
      "Epoch 4137, Loss: 1.6112972050905228, Final Batch Loss: 0.22095389664173126\n",
      "Epoch 4138, Loss: 1.4590598195791245, Final Batch Loss: 0.09974469244480133\n",
      "Epoch 4139, Loss: 1.4973531365394592, Final Batch Loss: 0.11372944712638855\n",
      "Epoch 4140, Loss: 3.281154125928879, Final Batch Loss: 1.9527055025100708\n",
      "Epoch 4141, Loss: 1.4124297108501196, Final Batch Loss: 0.01628091000020504\n",
      "Epoch 4142, Loss: 3.744533061981201, Final Batch Loss: 2.458310127258301\n",
      "Epoch 4143, Loss: 1.441063486970961, Final Batch Loss: 0.003669791854918003\n",
      "Epoch 4144, Loss: 1.4961629868485034, Final Batch Loss: 0.0031608403660357\n",
      "Epoch 4145, Loss: 1.4248123951256275, Final Batch Loss: 0.05685477331280708\n",
      "Epoch 4146, Loss: 1.4866415932774544, Final Batch Loss: 0.09553743153810501\n",
      "Epoch 4147, Loss: 4.120216071605682, Final Batch Loss: 2.755830764770508\n",
      "Epoch 4148, Loss: 2.064662665128708, Final Batch Loss: 0.5710841417312622\n",
      "Epoch 4149, Loss: 3.121943950653076, Final Batch Loss: 1.737511396408081\n",
      "Epoch 4150, Loss: 1.5122334882616997, Final Batch Loss: 0.1103643998503685\n",
      "Epoch 4151, Loss: 1.4791419953107834, Final Batch Loss: 0.0376485139131546\n",
      "Epoch 4152, Loss: 1.4116365880472586, Final Batch Loss: 0.0013828248484060168\n",
      "Epoch 4153, Loss: 1.6361072212457657, Final Batch Loss: 0.22970055043697357\n",
      "Epoch 4154, Loss: 1.5962066501379013, Final Batch Loss: 0.19201712310314178\n",
      "Epoch 4155, Loss: 1.3904964294051751, Final Batch Loss: 0.0016930069541558623\n",
      "Epoch 4156, Loss: 1.3287093807011843, Final Batch Loss: 0.006698297336697578\n",
      "Epoch 4157, Loss: 1.4006357223843224, Final Batch Loss: 0.00033623288618400693\n",
      "Epoch 4158, Loss: 1.377365660853684, Final Batch Loss: 0.015595030970871449\n",
      "Epoch 4159, Loss: 2.4106665551662445, Final Batch Loss: 1.047135591506958\n",
      "Epoch 4160, Loss: 1.5018849074840546, Final Batch Loss: 0.09342676401138306\n",
      "Epoch 4161, Loss: 1.3192347027361393, Final Batch Loss: 0.023688051849603653\n",
      "Epoch 4162, Loss: 3.391794115304947, Final Batch Loss: 2.0185019969940186\n",
      "Epoch 4163, Loss: 2.343246281147003, Final Batch Loss: 1.0364681482315063\n",
      "Epoch 4164, Loss: 1.6893936693668365, Final Batch Loss: 0.2588833272457123\n",
      "Epoch 4165, Loss: 1.7073230147361755, Final Batch Loss: 0.35712963342666626\n",
      "Epoch 4166, Loss: 1.4823690578341484, Final Batch Loss: 0.0667741522192955\n",
      "Epoch 4167, Loss: 1.4599591717123985, Final Batch Loss: 0.015138261020183563\n",
      "Epoch 4168, Loss: 1.915111780166626, Final Batch Loss: 0.44918617606163025\n",
      "Epoch 4169, Loss: 2.224364995956421, Final Batch Loss: 0.8286647796630859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4170, Loss: 1.456633950372634, Final Batch Loss: 9.870042413240299e-05\n",
      "Epoch 4171, Loss: 1.5478520467877388, Final Batch Loss: 0.0766235962510109\n",
      "Epoch 4172, Loss: 2.4251053035259247, Final Batch Loss: 0.9917351603507996\n",
      "Epoch 4173, Loss: 1.6484473422169685, Final Batch Loss: 0.12410283833742142\n",
      "Epoch 4174, Loss: 3.655554324388504, Final Batch Loss: 2.315530776977539\n",
      "Epoch 4175, Loss: 1.8957292139530182, Final Batch Loss: 0.43727821111679077\n",
      "Epoch 4176, Loss: 1.7935027182102203, Final Batch Loss: 0.17817625403404236\n",
      "Epoch 4177, Loss: 2.130003958940506, Final Batch Loss: 0.4778057634830475\n",
      "Epoch 4178, Loss: 1.6783731722243829, Final Batch Loss: 0.00017641419253777713\n",
      "Epoch 4179, Loss: 1.8099362839275273, Final Batch Loss: 4.672895011026412e-05\n",
      "Epoch 4180, Loss: 2.8247263431549072, Final Batch Loss: 1.0318264961242676\n",
      "Epoch 4181, Loss: 1.872492205351591, Final Batch Loss: 0.05726654455065727\n",
      "Epoch 4182, Loss: 1.8042258396744728, Final Batch Loss: 0.10545454174280167\n",
      "Epoch 4183, Loss: 2.8188587427139282, Final Batch Loss: 0.9829996228218079\n",
      "Epoch 4184, Loss: 1.9945241510868073, Final Batch Loss: 0.2670386731624603\n",
      "Epoch 4185, Loss: 3.3943076133728027, Final Batch Loss: 1.7823840379714966\n",
      "Epoch 4186, Loss: 1.6159496903419495, Final Batch Loss: 0.07176908850669861\n",
      "Epoch 4187, Loss: 1.5625184772998182, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 4188, Loss: 2.051948219537735, Final Batch Loss: 0.4471268951892853\n",
      "Epoch 4189, Loss: 1.5118816529866308, Final Batch Loss: 0.0016351675149053335\n",
      "Epoch 4190, Loss: 1.5315336622297764, Final Batch Loss: 0.017705950886011124\n",
      "Epoch 4191, Loss: 1.5840802788733868, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4192, Loss: 5.005023777484894, Final Batch Loss: 3.539722204208374\n",
      "Epoch 4193, Loss: 1.9324931800365448, Final Batch Loss: 0.383431077003479\n",
      "Epoch 4194, Loss: 2.731085419654846, Final Batch Loss: 0.9330231547355652\n",
      "Epoch 4195, Loss: 2.0159791484475136, Final Batch Loss: 0.08889386802911758\n",
      "Epoch 4196, Loss: 1.8924835732905194, Final Batch Loss: 0.0018039158312603831\n",
      "Epoch 4197, Loss: 3.3359391689300537, Final Batch Loss: 1.640083909034729\n",
      "Epoch 4198, Loss: 1.758477471768856, Final Batch Loss: 0.09704156965017319\n",
      "Epoch 4199, Loss: 1.7380869537591934, Final Batch Loss: 0.11157925426959991\n",
      "Epoch 4200, Loss: 1.7296486645936966, Final Batch Loss: 0.14180587232112885\n",
      "Epoch 4201, Loss: 1.6364333238452673, Final Batch Loss: 0.01815476082265377\n",
      "Epoch 4202, Loss: 1.6582283079624176, Final Batch Loss: 0.020201295614242554\n",
      "Epoch 4203, Loss: 2.3469698429107666, Final Batch Loss: 0.8375830054283142\n",
      "Epoch 4204, Loss: 3.1858034431934357, Final Batch Loss: 1.8023635149002075\n",
      "Epoch 4205, Loss: 1.508291321573779, Final Batch Loss: 0.0012060280423611403\n",
      "Epoch 4206, Loss: 1.6204751133918762, Final Batch Loss: 0.131125807762146\n",
      "Epoch 4207, Loss: 2.226947546005249, Final Batch Loss: 0.8174349069595337\n",
      "Epoch 4208, Loss: 1.5138259083032608, Final Batch Loss: 0.16522733867168427\n",
      "Epoch 4209, Loss: 3.1384971737861633, Final Batch Loss: 1.7436518669128418\n",
      "Epoch 4210, Loss: 1.5311839552596211, Final Batch Loss: 0.009871003217995167\n",
      "Epoch 4211, Loss: 1.3947983644902706, Final Batch Loss: 0.06016933545470238\n",
      "Epoch 4212, Loss: 1.3501436184160411, Final Batch Loss: 0.0024375985376536846\n",
      "Epoch 4213, Loss: 1.4367884993553162, Final Batch Loss: 0.05485939979553223\n",
      "Epoch 4214, Loss: 1.3498622849583626, Final Batch Loss: 0.0019639506936073303\n",
      "Epoch 4215, Loss: 1.4986687256023288, Final Batch Loss: 0.013680155389010906\n",
      "Epoch 4216, Loss: 3.070050925016403, Final Batch Loss: 1.657278299331665\n",
      "Epoch 4217, Loss: 1.448576144874096, Final Batch Loss: 0.08594825118780136\n",
      "Epoch 4218, Loss: 1.5078923217952251, Final Batch Loss: 0.051275890320539474\n",
      "Epoch 4219, Loss: 1.3893385529518127, Final Batch Loss: 0.0\n",
      "Epoch 4220, Loss: 1.3873915342555847, Final Batch Loss: 7.962863310240209e-05\n",
      "Epoch 4221, Loss: 1.3790999984485097, Final Batch Loss: 0.0006403064471669495\n",
      "Epoch 4222, Loss: 2.08373561501503, Final Batch Loss: 0.7107869982719421\n",
      "Epoch 4223, Loss: 2.210379660129547, Final Batch Loss: 0.7651494741439819\n",
      "Epoch 4224, Loss: 1.4090964505448937, Final Batch Loss: 0.015412629581987858\n",
      "Epoch 4225, Loss: 3.157503664493561, Final Batch Loss: 1.7110813856124878\n",
      "Epoch 4226, Loss: 1.4623669255524874, Final Batch Loss: 0.024241702631115913\n",
      "Epoch 4227, Loss: 1.6031147241592407, Final Batch Loss: 0.06711319088935852\n",
      "Epoch 4228, Loss: 1.5283485259860754, Final Batch Loss: 0.01086934469640255\n",
      "Epoch 4229, Loss: 1.5867591798305511, Final Batch Loss: 0.09637731313705444\n",
      "Epoch 4230, Loss: 1.5205969339003786, Final Batch Loss: 0.0017865424742922187\n",
      "Epoch 4231, Loss: 1.6487500667572021, Final Batch Loss: 0.17489036917686462\n",
      "Epoch 4232, Loss: 1.3870637395375525, Final Batch Loss: 6.55629628454335e-05\n",
      "Epoch 4233, Loss: 1.6012642979621887, Final Batch Loss: 0.12593668699264526\n",
      "Epoch 4234, Loss: 5.553713142871857, Final Batch Loss: 4.143747806549072\n",
      "Epoch 4235, Loss: 1.4262112602591515, Final Batch Loss: 0.064023457467556\n",
      "Epoch 4236, Loss: 1.4485297873616219, Final Batch Loss: 0.07230518013238907\n",
      "Epoch 4237, Loss: 1.6086238287389278, Final Batch Loss: 0.0418604277074337\n",
      "Epoch 4238, Loss: 2.230411648750305, Final Batch Loss: 0.7044737339019775\n",
      "Epoch 4239, Loss: 4.2436569929122925, Final Batch Loss: 2.7731189727783203\n",
      "Epoch 4240, Loss: 1.6202597916126251, Final Batch Loss: 0.15119585394859314\n",
      "Epoch 4241, Loss: 1.7389931380748749, Final Batch Loss: 0.27630695700645447\n",
      "Epoch 4242, Loss: 1.510423898696672, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4243, Loss: 3.691156655550003, Final Batch Loss: 2.1673755645751953\n",
      "Epoch 4244, Loss: 1.4572355290874839, Final Batch Loss: 0.015240057371556759\n",
      "Epoch 4245, Loss: 1.5152984634041786, Final Batch Loss: 0.033184029161930084\n",
      "Epoch 4246, Loss: 1.4541117250917637, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4247, Loss: 1.84074667096138, Final Batch Loss: 0.42683351039886475\n",
      "Epoch 4248, Loss: 1.8595545589923859, Final Batch Loss: 0.4503498077392578\n",
      "Epoch 4249, Loss: 2.4835425913333893, Final Batch Loss: 1.0988118648529053\n",
      "Epoch 4250, Loss: 1.3351548220962286, Final Batch Loss: 0.028845926746726036\n",
      "Epoch 4251, Loss: 1.4720317162573338, Final Batch Loss: 0.03478163853287697\n",
      "Epoch 4252, Loss: 1.3267541890963912, Final Batch Loss: 0.004633641801774502\n",
      "Epoch 4253, Loss: 2.4915404319763184, Final Batch Loss: 1.122864007949829\n",
      "Epoch 4254, Loss: 1.3247266504913568, Final Batch Loss: 0.0016315970569849014\n",
      "Epoch 4255, Loss: 1.394281210959889, Final Batch Loss: 0.0017921352991834283\n",
      "Epoch 4256, Loss: 1.4405414666980505, Final Batch Loss: 0.007757773622870445\n",
      "Epoch 4257, Loss: 3.1660456359386444, Final Batch Loss: 1.702101469039917\n",
      "Epoch 4258, Loss: 1.421704474836588, Final Batch Loss: 0.044742558151483536\n",
      "Epoch 4259, Loss: 1.469678545370698, Final Batch Loss: 0.019317472353577614\n",
      "Epoch 4260, Loss: 1.363044822588563, Final Batch Loss: 0.023713314905762672\n",
      "Epoch 4261, Loss: 1.6369849294424057, Final Batch Loss: 0.232842817902565\n",
      "Epoch 4262, Loss: 1.4221432693302631, Final Batch Loss: 0.05065961554646492\n",
      "Epoch 4263, Loss: 1.350054895505309, Final Batch Loss: 0.02763000689446926\n",
      "Epoch 4264, Loss: 1.3633806407115117, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 4265, Loss: 2.443832039833069, Final Batch Loss: 1.0272657871246338\n",
      "Epoch 4266, Loss: 1.3213551342487335, Final Batch Loss: 0.0\n",
      "Epoch 4267, Loss: 2.059145510196686, Final Batch Loss: 0.7037613391876221\n",
      "Epoch 4268, Loss: 1.408632151549682, Final Batch Loss: 0.0008887869771569967\n",
      "Epoch 4269, Loss: 1.9270648062229156, Final Batch Loss: 0.5692371726036072\n",
      "Epoch 4270, Loss: 1.387375713326037, Final Batch Loss: 0.005388260819017887\n",
      "Epoch 4271, Loss: 1.386578632518649, Final Batch Loss: 0.024599893018603325\n",
      "Epoch 4272, Loss: 1.4630447458475828, Final Batch Loss: 0.015193445608019829\n",
      "Epoch 4273, Loss: 1.4743708008900285, Final Batch Loss: 0.015216105617582798\n",
      "Epoch 4274, Loss: 3.5571029484272003, Final Batch Loss: 2.1217293739318848\n",
      "Epoch 4275, Loss: 2.8294190764427185, Final Batch Loss: 1.240410327911377\n",
      "Epoch 4276, Loss: 1.5691753715509549, Final Batch Loss: 0.0015949398512020707\n",
      "Epoch 4277, Loss: 1.6337389033287764, Final Batch Loss: 0.014492956921458244\n",
      "Epoch 4278, Loss: 1.658980437205173, Final Batch Loss: 0.0013309201458469033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4279, Loss: 3.315939486026764, Final Batch Loss: 1.6733490228652954\n",
      "Epoch 4280, Loss: 5.159363359212875, Final Batch Loss: 3.6021978855133057\n",
      "Epoch 4281, Loss: 1.6104569612070918, Final Batch Loss: 0.009802537970244884\n",
      "Epoch 4282, Loss: 1.9076431393623352, Final Batch Loss: 0.4156605899333954\n",
      "Epoch 4283, Loss: 2.7819021344184875, Final Batch Loss: 1.3123356103897095\n",
      "Epoch 4284, Loss: 3.1956471502780914, Final Batch Loss: 1.6663790941238403\n",
      "Epoch 4285, Loss: 1.5831448733688376, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 4286, Loss: 1.7895497977733612, Final Batch Loss: 0.2674909234046936\n",
      "Epoch 4287, Loss: 1.55212110177672, Final Batch Loss: 4.541770613286644e-05\n",
      "Epoch 4288, Loss: 1.550760269165039, Final Batch Loss: 0.07927492260932922\n",
      "Epoch 4289, Loss: 1.4378518906305544, Final Batch Loss: 0.0007527616689912975\n",
      "Epoch 4290, Loss: 2.1897610127925873, Final Batch Loss: 0.7146309614181519\n",
      "Epoch 4291, Loss: 1.4456765875220299, Final Batch Loss: 0.023583851754665375\n",
      "Epoch 4292, Loss: 2.282907783985138, Final Batch Loss: 0.7604413628578186\n",
      "Epoch 4293, Loss: 1.4407214084640145, Final Batch Loss: 0.0122537175193429\n",
      "Epoch 4294, Loss: 2.6428748071193695, Final Batch Loss: 1.1023024320602417\n",
      "Epoch 4295, Loss: 1.6234869956970215, Final Batch Loss: 0.0\n",
      "Epoch 4296, Loss: 1.51350586861372, Final Batch Loss: 0.03508128970861435\n",
      "Epoch 4297, Loss: 2.9282203912734985, Final Batch Loss: 1.4086546897888184\n",
      "Epoch 4298, Loss: 1.4914458552375436, Final Batch Loss: 0.012636826373636723\n",
      "Epoch 4299, Loss: 1.4831284049432725, Final Batch Loss: 0.0037465158384293318\n",
      "Epoch 4300, Loss: 1.4692217782139778, Final Batch Loss: 0.05754254013299942\n",
      "Epoch 4301, Loss: 2.3711738884449005, Final Batch Loss: 0.9392622709274292\n",
      "Epoch 4302, Loss: 1.707414984703064, Final Batch Loss: 0.33682382106781006\n",
      "Epoch 4303, Loss: 1.7933827340602875, Final Batch Loss: 0.377542644739151\n",
      "Epoch 4304, Loss: 1.4374598804861307, Final Batch Loss: 0.02083837427198887\n",
      "Epoch 4305, Loss: 3.4358397126197815, Final Batch Loss: 1.970003366470337\n",
      "Epoch 4306, Loss: 1.3561021387868095, Final Batch Loss: 0.00034517052699811757\n",
      "Epoch 4307, Loss: 1.4394351793453097, Final Batch Loss: 0.0014265133067965508\n",
      "Epoch 4308, Loss: 3.0642901360988617, Final Batch Loss: 1.62150239944458\n",
      "Epoch 4309, Loss: 1.4707851158455014, Final Batch Loss: 0.005242173559963703\n",
      "Epoch 4310, Loss: 2.954681485891342, Final Batch Loss: 1.4875271320343018\n",
      "Epoch 4311, Loss: 1.566325955092907, Final Batch Loss: 0.077340267598629\n",
      "Epoch 4312, Loss: 1.4746474002604373, Final Batch Loss: 0.0004932855372317135\n",
      "Epoch 4313, Loss: 1.540580257307738, Final Batch Loss: 0.006509765516966581\n",
      "Epoch 4314, Loss: 1.6281548142433167, Final Batch Loss: 0.1752707064151764\n",
      "Epoch 4315, Loss: 1.6825618147850037, Final Batch Loss: 0.29598820209503174\n",
      "Epoch 4316, Loss: 1.915337234735489, Final Batch Loss: 0.524709939956665\n",
      "Epoch 4317, Loss: 1.5309567339718342, Final Batch Loss: 0.016431022435426712\n",
      "Epoch 4318, Loss: 1.3819265244528651, Final Batch Loss: 0.011531132273375988\n",
      "Epoch 4319, Loss: 1.5229990972438827, Final Batch Loss: 0.001880307332612574\n",
      "Epoch 4320, Loss: 1.412445207242854, Final Batch Loss: 0.001471390132792294\n",
      "Epoch 4321, Loss: 2.0788131952285767, Final Batch Loss: 0.5623430013656616\n",
      "Epoch 4322, Loss: 1.9620898365974426, Final Batch Loss: 0.43583494424819946\n",
      "Epoch 4323, Loss: 1.7789707304909825, Final Batch Loss: 0.0012348415330052376\n",
      "Epoch 4324, Loss: 2.5362238585948944, Final Batch Loss: 0.4658997356891632\n",
      "Epoch 4325, Loss: 2.8454798460006714, Final Batch Loss: 1.025813102722168\n",
      "Epoch 4326, Loss: 5.363247931003571, Final Batch Loss: 3.632254123687744\n",
      "Epoch 4327, Loss: 3.703526586294174, Final Batch Loss: 2.1609947681427\n",
      "Epoch 4328, Loss: 1.631334364414215, Final Batch Loss: 0.06569650769233704\n",
      "Epoch 4329, Loss: 1.6147268959321082, Final Batch Loss: 0.0033293315209448338\n",
      "Epoch 4330, Loss: 3.9066568315029144, Final Batch Loss: 2.2930097579956055\n",
      "Epoch 4331, Loss: 1.5902629373595119, Final Batch Loss: 0.007803904823958874\n",
      "Epoch 4332, Loss: 3.0758811235427856, Final Batch Loss: 1.1211514472961426\n",
      "Epoch 4333, Loss: 1.8948826054111123, Final Batch Loss: 0.014902339316904545\n",
      "Epoch 4334, Loss: 1.912803006125614, Final Batch Loss: 0.0010240792762488127\n",
      "Epoch 4335, Loss: 4.581855475902557, Final Batch Loss: 2.6430435180664062\n",
      "Epoch 4336, Loss: 3.078646332025528, Final Batch Loss: 1.375298261642456\n",
      "Epoch 4337, Loss: 1.947475090622902, Final Batch Loss: 0.1933029443025589\n",
      "Epoch 4338, Loss: 2.966215431690216, Final Batch Loss: 1.2255158424377441\n",
      "Epoch 4339, Loss: 1.6769353356212378, Final Batch Loss: 0.021470030769705772\n",
      "Epoch 4340, Loss: 1.6880659461021423, Final Batch Loss: 0.11161848902702332\n",
      "Epoch 4341, Loss: 1.7066099718213081, Final Batch Loss: 0.10597149282693863\n",
      "Epoch 4342, Loss: 2.035804659128189, Final Batch Loss: 0.4820287227630615\n",
      "Epoch 4343, Loss: 3.114337980747223, Final Batch Loss: 1.693208932876587\n",
      "Epoch 4344, Loss: 2.155421018600464, Final Batch Loss: 0.604738712310791\n",
      "Epoch 4345, Loss: 1.6505297683179379, Final Batch Loss: 0.059471245855093\n",
      "Epoch 4346, Loss: 2.610532194375992, Final Batch Loss: 1.1302623748779297\n",
      "Epoch 4347, Loss: 3.0947369933128357, Final Batch Loss: 1.5801206827163696\n",
      "Epoch 4348, Loss: 1.4530062198755331, Final Batch Loss: 0.00018904806347563863\n",
      "Epoch 4349, Loss: 1.6119099855421268, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4350, Loss: 2.4565243124961853, Final Batch Loss: 0.9067161083221436\n",
      "Epoch 4351, Loss: 1.6280044317245483, Final Batch Loss: 0.19245865941047668\n",
      "Epoch 4352, Loss: 1.59496508538723, Final Batch Loss: 0.1508455127477646\n",
      "Epoch 4353, Loss: 3.2874534130096436, Final Batch Loss: 1.8618264198303223\n",
      "Epoch 4354, Loss: 1.5603483244776726, Final Batch Loss: 0.02038773149251938\n",
      "Epoch 4355, Loss: 1.471531837247312, Final Batch Loss: 0.01054182555526495\n",
      "Epoch 4356, Loss: 1.5468691871392366, Final Batch Loss: 5.304672595229931e-05\n",
      "Epoch 4357, Loss: 4.275853604078293, Final Batch Loss: 2.8572633266448975\n",
      "Epoch 4358, Loss: 3.179811269044876, Final Batch Loss: 1.695131540298462\n",
      "Epoch 4359, Loss: 3.8151273131370544, Final Batch Loss: 1.8954048156738281\n",
      "Epoch 4360, Loss: 2.4891332238912582, Final Batch Loss: 0.044135019183158875\n",
      "Epoch 4361, Loss: 2.650082189589739, Final Batch Loss: 0.048228997737169266\n",
      "Epoch 4362, Loss: 3.5528895258903503, Final Batch Loss: 1.0318149328231812\n",
      "Epoch 4363, Loss: 3.1165151596069336, Final Batch Loss: 0.8393688201904297\n",
      "Epoch 4364, Loss: 2.330634504556656, Final Batch Loss: 0.28277847170829773\n",
      "Epoch 4365, Loss: 2.25926510989666, Final Batch Loss: 0.0029333680868148804\n",
      "Epoch 4366, Loss: 3.0962328910827637, Final Batch Loss: 1.103629231452942\n",
      "Epoch 4367, Loss: 1.7885732613503933, Final Batch Loss: 0.05073338374495506\n",
      "Epoch 4368, Loss: 1.5478541562333703, Final Batch Loss: 0.0012197205796837807\n",
      "Epoch 4369, Loss: 1.7602548897266388, Final Batch Loss: 0.10253188014030457\n",
      "Epoch 4370, Loss: 1.5071406923234463, Final Batch Loss: 0.010561760514974594\n",
      "Epoch 4371, Loss: 1.6698568155406974, Final Batch Loss: 0.00024816294899210334\n",
      "Epoch 4372, Loss: 1.6695328056812286, Final Batch Loss: 0.1470303237438202\n",
      "Epoch 4373, Loss: 1.451349082402885, Final Batch Loss: 0.007858905009925365\n",
      "Epoch 4374, Loss: 3.334413915872574, Final Batch Loss: 1.7696510553359985\n",
      "Epoch 4375, Loss: 1.6726496368646622, Final Batch Loss: 0.1914253681898117\n",
      "Epoch 4376, Loss: 1.8524144440889359, Final Batch Loss: 0.24900157749652863\n",
      "Epoch 4377, Loss: 2.9529301822185516, Final Batch Loss: 1.290781855583191\n",
      "Epoch 4378, Loss: 2.443143308162689, Final Batch Loss: 0.7907965779304504\n",
      "Epoch 4379, Loss: 2.471358895301819, Final Batch Loss: 0.8751730918884277\n",
      "Epoch 4380, Loss: 3.3263450860977173, Final Batch Loss: 1.7085752487182617\n",
      "Epoch 4381, Loss: 2.654555767774582, Final Batch Loss: 1.1852561235427856\n",
      "Epoch 4382, Loss: 1.4393057823128856, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 4383, Loss: 2.4407477974891663, Final Batch Loss: 1.015779733657837\n",
      "Epoch 4384, Loss: 1.7604827880859375, Final Batch Loss: 0.3664790391921997\n",
      "Epoch 4385, Loss: 1.4375424286117777, Final Batch Loss: 0.001073261140845716\n",
      "Epoch 4386, Loss: 1.456136204302311, Final Batch Loss: 0.03260565549135208\n",
      "Epoch 4387, Loss: 1.4463494922965765, Final Batch Loss: 0.021229764446616173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4388, Loss: 1.4573050364851952, Final Batch Loss: 0.05898284167051315\n",
      "Epoch 4389, Loss: 1.4804410599172115, Final Batch Loss: 0.05235379561781883\n",
      "Epoch 4390, Loss: 1.6605899631977081, Final Batch Loss: 0.27191129326820374\n",
      "Epoch 4391, Loss: 1.4085357375442982, Final Batch Loss: 0.008193451911211014\n",
      "Epoch 4392, Loss: 1.4676860272884298, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4393, Loss: 1.4443778228014708, Final Batch Loss: 0.020985586568713188\n",
      "Epoch 4394, Loss: 1.6075669676065445, Final Batch Loss: 0.14953817427158356\n",
      "Epoch 4395, Loss: 1.359423064859584, Final Batch Loss: 0.0002686616498976946\n",
      "Epoch 4396, Loss: 1.5019717048853636, Final Batch Loss: 0.024089498445391655\n",
      "Epoch 4397, Loss: 1.280141383409493, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4398, Loss: 1.4523389865644276, Final Batch Loss: 0.007622324395924807\n",
      "Epoch 4399, Loss: 2.9533028304576874, Final Batch Loss: 1.5467098951339722\n",
      "Epoch 4400, Loss: 2.723211109638214, Final Batch Loss: 1.430988073348999\n",
      "Epoch 4401, Loss: 2.4284007251262665, Final Batch Loss: 1.1131649017333984\n",
      "Epoch 4402, Loss: 1.4288166761398315, Final Batch Loss: 0.07965829968452454\n",
      "Epoch 4403, Loss: 1.364645461551845, Final Batch Loss: 0.00019774865359067917\n",
      "Epoch 4404, Loss: 1.5636304914951324, Final Batch Loss: 0.09448590874671936\n",
      "Epoch 4405, Loss: 1.6567855775356293, Final Batch Loss: 0.13157206773757935\n",
      "Epoch 4406, Loss: 1.4370972961187363, Final Batch Loss: 0.018223240971565247\n",
      "Epoch 4407, Loss: 2.6524237990379333, Final Batch Loss: 1.323892593383789\n",
      "Epoch 4408, Loss: 3.4388777017593384, Final Batch Loss: 1.9190365076065063\n",
      "Epoch 4409, Loss: 1.6881065964698792, Final Batch Loss: 0.21770170331001282\n",
      "Epoch 4410, Loss: 2.5593121945858, Final Batch Loss: 1.130462408065796\n",
      "Epoch 4411, Loss: 1.5023791268467903, Final Batch Loss: 0.07522950321435928\n",
      "Epoch 4412, Loss: 1.3413673066534102, Final Batch Loss: 0.00604799622669816\n",
      "Epoch 4413, Loss: 1.4157647024840117, Final Batch Loss: 0.018099738284945488\n",
      "Epoch 4414, Loss: 1.394433306530118, Final Batch Loss: 0.0040638018399477005\n",
      "Epoch 4415, Loss: 1.5633690059185028, Final Batch Loss: 0.2574583888053894\n",
      "Epoch 4416, Loss: 1.413913513533771, Final Batch Loss: 0.01277595292776823\n",
      "Epoch 4417, Loss: 1.5038032680749893, Final Batch Loss: 0.13257144391536713\n",
      "Epoch 4418, Loss: 1.4218321107327938, Final Batch Loss: 0.03458600863814354\n",
      "Epoch 4419, Loss: 1.3745077392086387, Final Batch Loss: 0.012795372866094112\n",
      "Epoch 4420, Loss: 1.4891068786382675, Final Batch Loss: 0.14874641597270966\n",
      "Epoch 4421, Loss: 2.1801114976406097, Final Batch Loss: 0.8372480273246765\n",
      "Epoch 4422, Loss: 1.3070920179598033, Final Batch Loss: 0.003886647056788206\n",
      "Epoch 4423, Loss: 1.3552462990628555, Final Batch Loss: 0.0010418231831863523\n",
      "Epoch 4424, Loss: 1.7774651050567627, Final Batch Loss: 0.4285648465156555\n",
      "Epoch 4425, Loss: 1.3817262649535849, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4426, Loss: 2.1501838862895966, Final Batch Loss: 0.7917231321334839\n",
      "Epoch 4427, Loss: 3.1404506266117096, Final Batch Loss: 1.8144972324371338\n",
      "Epoch 4428, Loss: 2.45701202750206, Final Batch Loss: 1.0376708507537842\n",
      "Epoch 4429, Loss: 1.5081931352615356, Final Batch Loss: 0.07958608865737915\n",
      "Epoch 4430, Loss: 1.3759862107690424, Final Batch Loss: 0.0022665781434625387\n",
      "Epoch 4431, Loss: 1.3916268345728895, Final Batch Loss: 2.4318398573086597e-05\n",
      "Epoch 4432, Loss: 2.3664214611053467, Final Batch Loss: 1.0282105207443237\n",
      "Epoch 4433, Loss: 1.4437715392559767, Final Batch Loss: 0.019688067957758904\n",
      "Epoch 4434, Loss: 1.3383641839027405, Final Batch Loss: 0.0\n",
      "Epoch 4435, Loss: 1.3474473075475544, Final Batch Loss: 0.0008436457719653845\n",
      "Epoch 4436, Loss: 1.447419710457325, Final Batch Loss: 0.07213682681322098\n",
      "Epoch 4437, Loss: 1.5043183267116547, Final Batch Loss: 0.08382073044776917\n",
      "Epoch 4438, Loss: 1.580597072839737, Final Batch Loss: 0.2770736813545227\n",
      "Epoch 4439, Loss: 1.429074540734291, Final Batch Loss: 0.11428020894527435\n",
      "Epoch 4440, Loss: 2.1858884692192078, Final Batch Loss: 0.8079316020011902\n",
      "Epoch 4441, Loss: 1.4721870850771666, Final Batch Loss: 0.029194368049502373\n",
      "Epoch 4442, Loss: 1.3769586458802223, Final Batch Loss: 0.020428963005542755\n",
      "Epoch 4443, Loss: 1.5006677359342575, Final Batch Loss: 0.12757159769535065\n",
      "Epoch 4444, Loss: 2.719104081392288, Final Batch Loss: 1.3385082483291626\n",
      "Epoch 4445, Loss: 1.477093867957592, Final Batch Loss: 0.09458427876234055\n",
      "Epoch 4446, Loss: 1.3746394293848425, Final Batch Loss: 0.0021655934397131205\n",
      "Epoch 4447, Loss: 3.7557003796100616, Final Batch Loss: 2.440325975418091\n",
      "Epoch 4448, Loss: 1.4722044691443443, Final Batch Loss: 0.051055364310741425\n",
      "Epoch 4449, Loss: 1.3397344008553773, Final Batch Loss: 0.002442236291244626\n",
      "Epoch 4450, Loss: 1.7423807680606842, Final Batch Loss: 0.15419518947601318\n",
      "Epoch 4451, Loss: 4.272156357765198, Final Batch Loss: 2.835207462310791\n",
      "Epoch 4452, Loss: 1.5400040447711945, Final Batch Loss: 0.1180858314037323\n",
      "Epoch 4453, Loss: 3.857638716697693, Final Batch Loss: 2.397061824798584\n",
      "Epoch 4454, Loss: 1.6615455597639084, Final Batch Loss: 0.08029206097126007\n",
      "Epoch 4455, Loss: 1.5493305921409046, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 4456, Loss: 1.5038322219625115, Final Batch Loss: 0.009339452721178532\n",
      "Epoch 4457, Loss: 1.83776493370533, Final Batch Loss: 0.24181045591831207\n",
      "Epoch 4458, Loss: 2.7352552115917206, Final Batch Loss: 1.1910643577575684\n",
      "Epoch 4459, Loss: 1.4498743989970535, Final Batch Loss: 0.0024044194724410772\n",
      "Epoch 4460, Loss: 1.4694178700447083, Final Batch Loss: 0.08357974886894226\n",
      "Epoch 4461, Loss: 1.5237920992076397, Final Batch Loss: 0.059215109795331955\n",
      "Epoch 4462, Loss: 1.3793949782848287, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4463, Loss: 3.11466646194458, Final Batch Loss: 1.6626816987991333\n",
      "Epoch 4464, Loss: 2.293109178543091, Final Batch Loss: 0.9296828508377075\n",
      "Epoch 4465, Loss: 1.6958147883415222, Final Batch Loss: 0.2650463283061981\n",
      "Epoch 4466, Loss: 1.430105141364038, Final Batch Loss: 0.011777392588555813\n",
      "Epoch 4467, Loss: 1.7900739908218384, Final Batch Loss: 0.4222758412361145\n",
      "Epoch 4468, Loss: 1.4246461316943169, Final Batch Loss: 0.055333010852336884\n",
      "Epoch 4469, Loss: 1.8256092369556427, Final Batch Loss: 0.4626309275627136\n",
      "Epoch 4470, Loss: 1.937278300523758, Final Batch Loss: 0.5193631052970886\n",
      "Epoch 4471, Loss: 1.3840964436530996, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4472, Loss: 3.1334829330444336, Final Batch Loss: 1.7189420461654663\n",
      "Epoch 4473, Loss: 1.3830172521993518, Final Batch Loss: 0.008362988941371441\n",
      "Epoch 4474, Loss: 1.3798359241336584, Final Batch Loss: 0.016463270410895348\n",
      "Epoch 4475, Loss: 2.300665259361267, Final Batch Loss: 1.021132230758667\n",
      "Epoch 4476, Loss: 1.5252701798453927, Final Batch Loss: 0.001453653909265995\n",
      "Epoch 4477, Loss: 1.6175573145010276, Final Batch Loss: 7.092700980138034e-05\n",
      "Epoch 4478, Loss: 3.146300256252289, Final Batch Loss: 1.488963007926941\n",
      "Epoch 4479, Loss: 1.6093700230073864, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4480, Loss: 3.652051627635956, Final Batch Loss: 1.9735609292984009\n",
      "Epoch 4481, Loss: 2.783775359392166, Final Batch Loss: 1.249544620513916\n",
      "Epoch 4482, Loss: 1.467504482716322, Final Batch Loss: 0.012431632727384567\n",
      "Epoch 4483, Loss: 1.611842729151249, Final Batch Loss: 0.12402660399675369\n",
      "Epoch 4484, Loss: 2.572721302509308, Final Batch Loss: 1.1193124055862427\n",
      "Epoch 4485, Loss: 1.459749961271882, Final Batch Loss: 0.010417843237519264\n",
      "Epoch 4486, Loss: 1.4191281362436712, Final Batch Loss: 0.003735946025699377\n",
      "Epoch 4487, Loss: 1.740422248840332, Final Batch Loss: 0.335428923368454\n",
      "Epoch 4488, Loss: 1.4532855302095413, Final Batch Loss: 0.10882554948329926\n",
      "Epoch 4489, Loss: 2.9219300150871277, Final Batch Loss: 1.5446325540542603\n",
      "Epoch 4490, Loss: 1.4436180843040347, Final Batch Loss: 0.014495189301669598\n",
      "Epoch 4491, Loss: 1.451870070421137, Final Batch Loss: 0.0007503792876377702\n",
      "Epoch 4492, Loss: 1.7384647130966187, Final Batch Loss: 0.3551226556301117\n",
      "Epoch 4493, Loss: 1.382852059789002, Final Batch Loss: 0.0037529291585087776\n",
      "Epoch 4494, Loss: 1.6381997764110565, Final Batch Loss: 0.30869823694229126\n",
      "Epoch 4495, Loss: 1.4440159630030394, Final Batch Loss: 0.026079339906573296\n",
      "Epoch 4496, Loss: 2.6742142736911774, Final Batch Loss: 1.2731029987335205\n",
      "Epoch 4497, Loss: 2.661027818918228, Final Batch Loss: 1.2390400171279907\n",
      "Epoch 4498, Loss: 1.4011562876403332, Final Batch Loss: 0.056352924555540085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4499, Loss: 1.4956259345635772, Final Batch Loss: 0.012197545729577541\n",
      "Epoch 4500, Loss: 1.3970561623573303, Final Batch Loss: 0.0\n",
      "Epoch 4501, Loss: 1.4145292527973652, Final Batch Loss: 0.03935890272259712\n",
      "Epoch 4502, Loss: 2.2314994037151337, Final Batch Loss: 0.9034202694892883\n",
      "Epoch 4503, Loss: 1.4015132738422835, Final Batch Loss: 9.63164638960734e-05\n",
      "Epoch 4504, Loss: 1.9269347190856934, Final Batch Loss: 0.5023369193077087\n",
      "Epoch 4505, Loss: 2.493835359811783, Final Batch Loss: 0.9892603158950806\n",
      "Epoch 4506, Loss: 2.7837541699409485, Final Batch Loss: 1.4230319261550903\n",
      "Epoch 4507, Loss: 1.479354154318571, Final Batch Loss: 0.022569458931684494\n",
      "Epoch 4508, Loss: 1.569135569036007, Final Batch Loss: 0.07348185032606125\n",
      "Epoch 4509, Loss: 4.072472870349884, Final Batch Loss: 2.444058418273926\n",
      "Epoch 4510, Loss: 1.6980252638459206, Final Batch Loss: 0.07445643097162247\n",
      "Epoch 4511, Loss: 3.233040750026703, Final Batch Loss: 1.649332046508789\n",
      "Epoch 4512, Loss: 2.9787800312042236, Final Batch Loss: 1.3729519844055176\n",
      "Epoch 4513, Loss: 2.3419253826141357, Final Batch Loss: 0.6925610303878784\n",
      "Epoch 4514, Loss: 1.9276067614555359, Final Batch Loss: 0.21384871006011963\n",
      "Epoch 4515, Loss: 1.7406270280480385, Final Batch Loss: 0.06862515956163406\n",
      "Epoch 4516, Loss: 1.9323660582304, Final Batch Loss: 0.17604903876781464\n",
      "Epoch 4517, Loss: 1.7693678000941873, Final Batch Loss: 0.011669234372675419\n",
      "Epoch 4518, Loss: 3.371427357196808, Final Batch Loss: 1.6342711448669434\n",
      "Epoch 4519, Loss: 2.3897374868392944, Final Batch Loss: 0.6007975339889526\n",
      "Epoch 4520, Loss: 2.6638686656951904, Final Batch Loss: 1.041243553161621\n",
      "Epoch 4521, Loss: 3.1381008625030518, Final Batch Loss: 1.5664716958999634\n",
      "Epoch 4522, Loss: 1.6787454448640347, Final Batch Loss: 0.033681388944387436\n",
      "Epoch 4523, Loss: 1.6709945444017649, Final Batch Loss: 0.017356062307953835\n",
      "Epoch 4524, Loss: 1.8826024532318115, Final Batch Loss: 0.275945246219635\n",
      "Epoch 4525, Loss: 3.00642591714859, Final Batch Loss: 1.470476746559143\n",
      "Epoch 4526, Loss: 1.5444822608969844, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 4527, Loss: 1.5166253289207816, Final Batch Loss: 0.008124872110784054\n",
      "Epoch 4528, Loss: 1.7341631054878235, Final Batch Loss: 0.050170063972473145\n",
      "Epoch 4529, Loss: 1.7760505080223083, Final Batch Loss: 0.19627264142036438\n",
      "Epoch 4530, Loss: 1.4479633867322264, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 4531, Loss: 2.7029224932193756, Final Batch Loss: 1.2389851808547974\n",
      "Epoch 4532, Loss: 1.472088159993291, Final Batch Loss: 0.0008434075862169266\n",
      "Epoch 4533, Loss: 2.528196483850479, Final Batch Loss: 1.0544171333312988\n",
      "Epoch 4534, Loss: 1.6242405949160457, Final Batch Loss: 0.012294578365981579\n",
      "Epoch 4535, Loss: 2.6962942481040955, Final Batch Loss: 1.2556979656219482\n",
      "Epoch 4536, Loss: 1.543751067481935, Final Batch Loss: 0.014090693555772305\n",
      "Epoch 4537, Loss: 1.4736057519874066, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 4538, Loss: 1.5553153343498707, Final Batch Loss: 0.05255650356411934\n",
      "Epoch 4539, Loss: 1.4988077990710735, Final Batch Loss: 0.03685317561030388\n",
      "Epoch 4540, Loss: 1.5719153434038162, Final Batch Loss: 0.17393441498279572\n",
      "Epoch 4541, Loss: 2.6182596385478973, Final Batch Loss: 1.205467939376831\n",
      "Epoch 4542, Loss: 1.4587105512619019, Final Batch Loss: 0.06305387616157532\n",
      "Epoch 4543, Loss: 3.1935980319976807, Final Batch Loss: 1.7824770212173462\n",
      "Epoch 4544, Loss: 1.3954215706326067, Final Batch Loss: 0.0030261934734880924\n",
      "Epoch 4545, Loss: 1.8106207847595215, Final Batch Loss: 0.3541911840438843\n",
      "Epoch 4546, Loss: 3.023527294397354, Final Batch Loss: 1.5091221332550049\n",
      "Epoch 4547, Loss: 1.3964070812799037, Final Batch Loss: 0.004374696407467127\n",
      "Epoch 4548, Loss: 1.5146751105785086, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4549, Loss: 2.1727283596992493, Final Batch Loss: 0.6631653904914856\n",
      "Epoch 4550, Loss: 1.5049863454478327, Final Batch Loss: 2.52720492426306e-05\n",
      "Epoch 4551, Loss: 1.5540563083486632, Final Batch Loss: 0.0018309272127225995\n",
      "Epoch 4552, Loss: 2.9299752712249756, Final Batch Loss: 1.3714029788970947\n",
      "Epoch 4553, Loss: 1.4317116532474756, Final Batch Loss: 0.005882451310753822\n",
      "Epoch 4554, Loss: 1.4583266321569681, Final Batch Loss: 0.020329678431153297\n",
      "Epoch 4555, Loss: 1.4003569222986698, Final Batch Loss: 0.005287472158670425\n",
      "Epoch 4556, Loss: 1.581638976931572, Final Batch Loss: 0.17178158462047577\n",
      "Epoch 4557, Loss: 4.803367853164673, Final Batch Loss: 3.378810167312622\n",
      "Epoch 4558, Loss: 2.583861470222473, Final Batch Loss: 1.203017234802246\n",
      "Epoch 4559, Loss: 2.4546872675418854, Final Batch Loss: 1.0566600561141968\n",
      "Epoch 4560, Loss: 1.4279390933224931, Final Batch Loss: 0.0015779199311509728\n",
      "Epoch 4561, Loss: 1.4195715487003326, Final Batch Loss: 0.0\n",
      "Epoch 4562, Loss: 1.560485616326332, Final Batch Loss: 0.1667412966489792\n",
      "Epoch 4563, Loss: 1.4502826370298862, Final Batch Loss: 0.025108281522989273\n",
      "Epoch 4564, Loss: 1.4764537289738655, Final Batch Loss: 0.11240843683481216\n",
      "Epoch 4565, Loss: 1.551315262913704, Final Batch Loss: 0.17581979930400848\n",
      "Epoch 4566, Loss: 1.3029200532473624, Final Batch Loss: 0.005347827915102243\n",
      "Epoch 4567, Loss: 1.3715472519397736, Final Batch Loss: 0.0\n",
      "Epoch 4568, Loss: 1.2940759923658334, Final Batch Loss: 0.0004306104383431375\n",
      "Epoch 4569, Loss: 1.3913303930312395, Final Batch Loss: 0.02811622805893421\n",
      "Epoch 4570, Loss: 1.2644755542278219, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4571, Loss: 3.442191243171692, Final Batch Loss: 2.149982452392578\n",
      "Epoch 4572, Loss: 1.705793410539627, Final Batch Loss: 0.23626801371574402\n",
      "Epoch 4573, Loss: 2.7295252084732056, Final Batch Loss: 1.3214337825775146\n",
      "Epoch 4574, Loss: 1.4803256103768945, Final Batch Loss: 0.009882570244371891\n",
      "Epoch 4575, Loss: 1.610528364777565, Final Batch Loss: 0.21355487406253815\n",
      "Epoch 4576, Loss: 2.7334542870521545, Final Batch Loss: 1.3266838788986206\n",
      "Epoch 4577, Loss: 1.4254203774034977, Final Batch Loss: 0.03586745634675026\n",
      "Epoch 4578, Loss: 1.5817099660634995, Final Batch Loss: 0.1504475623369217\n",
      "Epoch 4579, Loss: 2.113814353942871, Final Batch Loss: 0.6594071388244629\n",
      "Epoch 4580, Loss: 1.4584226385923102, Final Batch Loss: 0.0009373800130560994\n",
      "Epoch 4581, Loss: 1.32902738917619, Final Batch Loss: 0.013406251557171345\n",
      "Epoch 4582, Loss: 1.3290533437393606, Final Batch Loss: 0.0035855784080922604\n",
      "Epoch 4583, Loss: 1.6657583713531494, Final Batch Loss: 0.3010413348674774\n",
      "Epoch 4584, Loss: 1.6756781041622162, Final Batch Loss: 0.30542272329330444\n",
      "Epoch 4585, Loss: 2.286287784576416, Final Batch Loss: 0.8984724879264832\n",
      "Epoch 4586, Loss: 1.496093213558197, Final Batch Loss: 0.12709036469459534\n",
      "Epoch 4587, Loss: 1.422968119242796, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 4588, Loss: 1.353275639936328, Final Batch Loss: 0.02103753201663494\n",
      "Epoch 4589, Loss: 1.3297935656737536, Final Batch Loss: 0.0012736550997942686\n",
      "Epoch 4590, Loss: 1.496949601743836, Final Batch Loss: 0.0005663221818394959\n",
      "Epoch 4591, Loss: 1.3504747562110424, Final Batch Loss: 0.004943173378705978\n",
      "Epoch 4592, Loss: 1.3287378851964604, Final Batch Loss: 0.00024232311989180744\n",
      "Epoch 4593, Loss: 1.397725715301931, Final Batch Loss: 0.007560922764241695\n",
      "Epoch 4594, Loss: 1.355394753627479, Final Batch Loss: 0.010719927959144115\n",
      "Epoch 4595, Loss: 1.3442682223394513, Final Batch Loss: 0.0017658369615674019\n",
      "Epoch 4596, Loss: 1.2313597649335861, Final Batch Loss: 0.0025653094053268433\n",
      "Epoch 4597, Loss: 1.3653288884088397, Final Batch Loss: 0.008063028566539288\n",
      "Epoch 4598, Loss: 1.2918002605438161, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4599, Loss: 1.3362120076817519, Final Batch Loss: 5.495397272170521e-05\n",
      "Epoch 4600, Loss: 1.33170747756958, Final Batch Loss: 0.0866323709487915\n",
      "Epoch 4601, Loss: 1.4057832919061184, Final Batch Loss: 0.022486355155706406\n",
      "Epoch 4602, Loss: 1.3426306657493114, Final Batch Loss: 0.01438755914568901\n",
      "Epoch 4603, Loss: 1.2853185695130378, Final Batch Loss: 0.0013248485047370195\n",
      "Epoch 4604, Loss: 1.551148533821106, Final Batch Loss: 0.2792655825614929\n",
      "Epoch 4605, Loss: 1.3372048381716013, Final Batch Loss: 0.0018776897341012955\n",
      "Epoch 4606, Loss: 1.6261427402496338, Final Batch Loss: 0.32409051060676575\n",
      "Epoch 4607, Loss: 1.3501116205006838, Final Batch Loss: 0.028485314920544624\n",
      "Epoch 4608, Loss: 2.235157698392868, Final Batch Loss: 0.8909794092178345\n",
      "Epoch 4609, Loss: 1.3508558273309745, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4610, Loss: 1.2740582836268004, Final Batch Loss: 0.0003415954706724733\n",
      "Epoch 4611, Loss: 1.3208308517932892, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4612, Loss: 1.3255667071789503, Final Batch Loss: 0.011426953598856926\n",
      "Epoch 4613, Loss: 1.3093066215514568, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4614, Loss: 1.3621832567732781, Final Batch Loss: 0.0012809175532311201\n",
      "Epoch 4615, Loss: 2.515632599592209, Final Batch Loss: 1.2441163063049316\n",
      "Epoch 4616, Loss: 1.2646222419571131, Final Batch Loss: 0.00024125049822032452\n",
      "Epoch 4617, Loss: 2.9124240279197693, Final Batch Loss: 1.5435022115707397\n",
      "Epoch 4618, Loss: 1.3853197139687836, Final Batch Loss: 0.001167092937976122\n",
      "Epoch 4619, Loss: 1.5934962865503621, Final Batch Loss: 0.00011205045302631333\n",
      "Epoch 4620, Loss: 1.850068163126707, Final Batch Loss: 0.02047206088900566\n",
      "Epoch 4621, Loss: 2.17423614859581, Final Batch Loss: 0.3171752393245697\n",
      "Epoch 4622, Loss: 1.712124544661492, Final Batch Loss: 0.0023834886960685253\n",
      "Epoch 4623, Loss: 1.416985738556832, Final Batch Loss: 0.00271071819588542\n",
      "Epoch 4624, Loss: 1.424583401530981, Final Batch Loss: 0.01356055960059166\n",
      "Epoch 4625, Loss: 4.358758628368378, Final Batch Loss: 2.917454719543457\n",
      "Epoch 4626, Loss: 1.524553069844842, Final Batch Loss: 0.014031568542122841\n",
      "Epoch 4627, Loss: 3.14340877532959, Final Batch Loss: 1.8331520557403564\n",
      "Epoch 4628, Loss: 6.0357182919979095, Final Batch Loss: 4.711306571960449\n",
      "Epoch 4629, Loss: 1.6396080926060677, Final Batch Loss: 0.10170016437768936\n",
      "Epoch 4630, Loss: 1.9152450934780063, Final Batch Loss: 0.00021109737281221896\n",
      "Epoch 4631, Loss: 2.37483624368906, Final Batch Loss: 0.024369217455387115\n",
      "Epoch 4632, Loss: 3.819967567920685, Final Batch Loss: 1.1229668855667114\n",
      "Epoch 4633, Loss: 3.659694254398346, Final Batch Loss: 1.0731815099716187\n",
      "Epoch 4634, Loss: 4.959309458732605, Final Batch Loss: 2.5883965492248535\n",
      "Epoch 4635, Loss: 2.9158153533935547, Final Batch Loss: 0.6954177021980286\n",
      "Epoch 4636, Loss: 4.08497542142868, Final Batch Loss: 2.0204508304595947\n",
      "Epoch 4637, Loss: 3.628566324710846, Final Batch Loss: 1.731674313545227\n",
      "Epoch 4638, Loss: 3.9869697093963623, Final Batch Loss: 2.221644639968872\n",
      "Epoch 4639, Loss: 2.0687076151371, Final Batch Loss: 0.4134199321269989\n",
      "Epoch 4640, Loss: 3.2616397738456726, Final Batch Loss: 1.5461719036102295\n",
      "Epoch 4641, Loss: 1.8330124914646149, Final Batch Loss: 0.144954651594162\n",
      "Epoch 4642, Loss: 2.411150574684143, Final Batch Loss: 0.8289042711257935\n",
      "Epoch 4643, Loss: 1.6982607040554285, Final Batch Loss: 0.010785499587655067\n",
      "Epoch 4644, Loss: 2.973273992538452, Final Batch Loss: 1.3085532188415527\n",
      "Epoch 4645, Loss: 1.6891305968165398, Final Batch Loss: 0.09180407971143723\n",
      "Epoch 4646, Loss: 1.8449870944023132, Final Batch Loss: 0.25114351511001587\n",
      "Epoch 4647, Loss: 1.8449014127254486, Final Batch Loss: 0.2700565755367279\n",
      "Epoch 4648, Loss: 1.7085906937718391, Final Batch Loss: 0.06005416065454483\n",
      "Epoch 4649, Loss: 2.4391312301158905, Final Batch Loss: 0.9254754781723022\n",
      "Epoch 4650, Loss: 1.3965510725961394, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4651, Loss: 1.4093475341728663, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4652, Loss: 1.4674594076350331, Final Batch Loss: 0.013710257597267628\n",
      "Epoch 4653, Loss: 1.863690733909607, Final Batch Loss: 0.44755223393440247\n",
      "Epoch 4654, Loss: 2.9011404514312744, Final Batch Loss: 1.5099025964736938\n",
      "Epoch 4655, Loss: 1.3364550047554076, Final Batch Loss: 0.003042119089514017\n",
      "Epoch 4656, Loss: 1.48153215815546, Final Batch Loss: 0.0004188137245364487\n",
      "Epoch 4657, Loss: 2.637462615966797, Final Batch Loss: 1.243886947631836\n",
      "Epoch 4658, Loss: 2.3194933235645294, Final Batch Loss: 0.8910990953445435\n",
      "Epoch 4659, Loss: 1.8394811749458313, Final Batch Loss: 0.45952776074409485\n",
      "Epoch 4660, Loss: 1.572137326002121, Final Batch Loss: 0.2087952196598053\n",
      "Epoch 4661, Loss: 2.7809138894081116, Final Batch Loss: 1.480940818786621\n",
      "Epoch 4662, Loss: 1.5751506835222244, Final Batch Loss: 0.16494031250476837\n",
      "Epoch 4663, Loss: 1.4099154910072684, Final Batch Loss: 0.007988526485860348\n",
      "Epoch 4664, Loss: 1.3584994729608297, Final Batch Loss: 0.008755272254347801\n",
      "Epoch 4665, Loss: 1.4131771996617317, Final Batch Loss: 0.035083360970020294\n",
      "Epoch 4666, Loss: 1.3196919718757272, Final Batch Loss: 0.0039149085059762\n",
      "Epoch 4667, Loss: 1.3337863683700562, Final Batch Loss: 0.0\n",
      "Epoch 4668, Loss: 1.3554427027679594, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4669, Loss: 1.3084047138690948, Final Batch Loss: 0.022821754217147827\n",
      "Epoch 4670, Loss: 1.4619732270948589, Final Batch Loss: 0.005671955179423094\n",
      "Epoch 4671, Loss: 1.3598328134976327, Final Batch Loss: 0.003750791307538748\n",
      "Epoch 4672, Loss: 1.4336843281053007, Final Batch Loss: 0.004265615250915289\n",
      "Epoch 4673, Loss: 1.3032919324468821, Final Batch Loss: 0.0013252056669443846\n",
      "Epoch 4674, Loss: 1.3596227811649442, Final Batch Loss: 0.012343679554760456\n",
      "Epoch 4675, Loss: 3.028865307569504, Final Batch Loss: 1.722172737121582\n",
      "Epoch 4676, Loss: 1.4778587743639946, Final Batch Loss: 0.11231958121061325\n",
      "Epoch 4677, Loss: 1.3062418393965345, Final Batch Loss: 3.814624506048858e-05\n",
      "Epoch 4678, Loss: 1.386656390503049, Final Batch Loss: 0.01907961256802082\n",
      "Epoch 4679, Loss: 2.3987960815429688, Final Batch Loss: 1.0409070253372192\n",
      "Epoch 4680, Loss: 1.3497242546873167, Final Batch Loss: 0.0019414640264585614\n",
      "Epoch 4681, Loss: 1.419840669259429, Final Batch Loss: 0.017117148265242577\n",
      "Epoch 4682, Loss: 1.3266167077235878, Final Batch Loss: 0.0021261009387671947\n",
      "Epoch 4683, Loss: 1.298817986389622, Final Batch Loss: 0.0020302177872508764\n",
      "Epoch 4684, Loss: 2.221630573272705, Final Batch Loss: 0.8909597396850586\n",
      "Epoch 4685, Loss: 1.5945482552051544, Final Batch Loss: 0.18408215045928955\n",
      "Epoch 4686, Loss: 1.36289475671947, Final Batch Loss: 0.02923153154551983\n",
      "Epoch 4687, Loss: 2.0308533310890198, Final Batch Loss: 0.7337065935134888\n",
      "Epoch 4688, Loss: 2.8991017639636993, Final Batch Loss: 1.5843559503555298\n",
      "Epoch 4689, Loss: 1.6257483959197998, Final Batch Loss: 0.2597591280937195\n",
      "Epoch 4690, Loss: 2.417591392993927, Final Batch Loss: 0.9655309915542603\n",
      "Epoch 4691, Loss: 1.4306253157556057, Final Batch Loss: 0.06208973750472069\n",
      "Epoch 4692, Loss: 1.430982530117035, Final Batch Loss: 0.0381297767162323\n",
      "Epoch 4693, Loss: 2.3775559663772583, Final Batch Loss: 0.9776070713996887\n",
      "Epoch 4694, Loss: 2.4861316084861755, Final Batch Loss: 1.093200922012329\n",
      "Epoch 4695, Loss: 2.7159033119678497, Final Batch Loss: 1.3108402490615845\n",
      "Epoch 4696, Loss: 1.4925179481506348, Final Batch Loss: 0.1851336658000946\n",
      "Epoch 4697, Loss: 1.298484057188034, Final Batch Loss: 0.0\n",
      "Epoch 4698, Loss: 2.383503645658493, Final Batch Loss: 1.0321166515350342\n",
      "Epoch 4699, Loss: 1.6754406988620758, Final Batch Loss: 0.4174933433532715\n",
      "Epoch 4700, Loss: 1.8592830896377563, Final Batch Loss: 0.45689064264297485\n",
      "Epoch 4701, Loss: 1.876428872346878, Final Batch Loss: 0.548974335193634\n",
      "Epoch 4702, Loss: 1.4459446971304715, Final Batch Loss: 0.0028246049769222736\n",
      "Epoch 4703, Loss: 3.891371041536331, Final Batch Loss: 2.5389485359191895\n",
      "Epoch 4704, Loss: 3.9999080896377563, Final Batch Loss: 2.5772547721862793\n",
      "Epoch 4705, Loss: 1.7361554801463512, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4706, Loss: 3.1235378980636597, Final Batch Loss: 1.3549569845199585\n",
      "Epoch 4707, Loss: 5.1633260846138, Final Batch Loss: 3.349961757659912\n",
      "Epoch 4708, Loss: 1.7092707459814847, Final Batch Loss: 0.0028456454165279865\n",
      "Epoch 4709, Loss: 1.8303975593298674, Final Batch Loss: 0.02117164246737957\n",
      "Epoch 4710, Loss: 1.7805340290059348, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 4711, Loss: 2.5629180669784546, Final Batch Loss: 0.8269542455673218\n",
      "Epoch 4712, Loss: 2.855332911014557, Final Batch Loss: 1.1487631797790527\n",
      "Epoch 4713, Loss: 1.7186688184736454, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4714, Loss: 1.650508583523333, Final Batch Loss: 0.011006594635546207\n",
      "Epoch 4715, Loss: 1.5968709765002131, Final Batch Loss: 0.013693678192794323\n",
      "Epoch 4716, Loss: 2.217873215675354, Final Batch Loss: 0.5598081350326538\n",
      "Epoch 4717, Loss: 3.113009989261627, Final Batch Loss: 1.4823756217956543\n",
      "Epoch 4718, Loss: 1.8449885100126266, Final Batch Loss: 0.12742824852466583\n",
      "Epoch 4719, Loss: 1.5736851274850778, Final Batch Loss: 0.000617551791947335\n",
      "Epoch 4720, Loss: 1.5577134196646512, Final Batch Loss: 0.0030960743315517902\n",
      "Epoch 4721, Loss: 2.9644452929496765, Final Batch Loss: 1.474523663520813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4722, Loss: 1.5628516469150782, Final Batch Loss: 0.026273855939507484\n",
      "Epoch 4723, Loss: 1.5986979380249977, Final Batch Loss: 0.08789024502038956\n",
      "Epoch 4724, Loss: 1.4937454746104777, Final Batch Loss: 0.0007737264968454838\n",
      "Epoch 4725, Loss: 1.4394169971346855, Final Batch Loss: 0.007965229451656342\n",
      "Epoch 4726, Loss: 1.559566006064415, Final Batch Loss: 0.07059817016124725\n",
      "Epoch 4727, Loss: 2.8800743520259857, Final Batch Loss: 1.359267234802246\n",
      "Epoch 4728, Loss: 1.5443990221247077, Final Batch Loss: 0.004915415309369564\n",
      "Epoch 4729, Loss: 3.0639306902885437, Final Batch Loss: 1.5543444156646729\n",
      "Epoch 4730, Loss: 1.5692817606031895, Final Batch Loss: 0.030841592699289322\n",
      "Epoch 4731, Loss: 1.4965881591197103, Final Batch Loss: 0.0018807833548635244\n",
      "Epoch 4732, Loss: 1.9793227910995483, Final Batch Loss: 0.508560061454773\n",
      "Epoch 4733, Loss: 1.5254370141774416, Final Batch Loss: 0.011141704395413399\n",
      "Epoch 4734, Loss: 1.545297022908926, Final Batch Loss: 0.020097550004720688\n",
      "Epoch 4735, Loss: 3.4446139335632324, Final Batch Loss: 2.009476900100708\n",
      "Epoch 4736, Loss: 1.603176575154066, Final Batch Loss: 0.01275618001818657\n",
      "Epoch 4737, Loss: 1.6260333416284993, Final Batch Loss: 0.0015592334093526006\n",
      "Epoch 4738, Loss: 1.4971093154890696, Final Batch Loss: 0.0001284993631998077\n",
      "Epoch 4739, Loss: 1.7401724010705948, Final Batch Loss: 0.21381933987140656\n",
      "Epoch 4740, Loss: 1.480550855398178, Final Batch Loss: 0.0\n",
      "Epoch 4741, Loss: 1.4782743826508522, Final Batch Loss: 0.01822207123041153\n",
      "Epoch 4742, Loss: 1.5580779165029526, Final Batch Loss: 0.05190117657184601\n",
      "Epoch 4743, Loss: 1.5834490358829498, Final Batch Loss: 0.11033108830451965\n",
      "Epoch 4744, Loss: 1.5002680718898773, Final Batch Loss: 0.08325117826461792\n",
      "Epoch 4745, Loss: 1.4943409617990255, Final Batch Loss: 0.009165829047560692\n",
      "Epoch 4746, Loss: 3.2097156941890717, Final Batch Loss: 1.7580444812774658\n",
      "Epoch 4747, Loss: 1.6545471996068954, Final Batch Loss: 0.22205348312854767\n",
      "Epoch 4748, Loss: 1.4650987582281232, Final Batch Loss: 0.012100149877369404\n",
      "Epoch 4749, Loss: 1.4169677514582872, Final Batch Loss: 0.013150038197636604\n",
      "Epoch 4750, Loss: 2.6602537631988525, Final Batch Loss: 1.148394227027893\n",
      "Epoch 4751, Loss: 1.5966980904340744, Final Batch Loss: 0.14006467163562775\n",
      "Epoch 4752, Loss: 1.4943206571915653, Final Batch Loss: 0.00043132537393830717\n",
      "Epoch 4753, Loss: 1.4200700129149482, Final Batch Loss: 0.0012988949893042445\n",
      "Epoch 4754, Loss: 2.8185433447360992, Final Batch Loss: 1.4065037965774536\n",
      "Epoch 4755, Loss: 1.4252467420883477, Final Batch Loss: 0.0009488132782280445\n",
      "Epoch 4756, Loss: 1.3597327787429094, Final Batch Loss: 0.004315705969929695\n",
      "Epoch 4757, Loss: 1.4439076371490955, Final Batch Loss: 0.04058663919568062\n",
      "Epoch 4758, Loss: 1.5938562601804733, Final Batch Loss: 0.21754662692546844\n",
      "Epoch 4759, Loss: 1.49254759401083, Final Batch Loss: 0.02030070871114731\n",
      "Epoch 4760, Loss: 1.5684691369533539, Final Batch Loss: 0.19435039162635803\n",
      "Epoch 4761, Loss: 1.6699170470237732, Final Batch Loss: 0.27238228917121887\n",
      "Epoch 4762, Loss: 1.420238614082109, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4763, Loss: 1.405386745929718, Final Batch Loss: 0.0\n",
      "Epoch 4764, Loss: 1.5689827799797058, Final Batch Loss: 0.24872198700904846\n",
      "Epoch 4765, Loss: 1.4183684289455414, Final Batch Loss: 0.00786292552947998\n",
      "Epoch 4766, Loss: 1.3267375603318214, Final Batch Loss: 0.01870504766702652\n",
      "Epoch 4767, Loss: 2.8678804337978363, Final Batch Loss: 1.5399690866470337\n",
      "Epoch 4768, Loss: 1.3901497051119804, Final Batch Loss: 0.08340495079755783\n",
      "Epoch 4769, Loss: 1.3698454789773677, Final Batch Loss: 3.8742269680369645e-05\n",
      "Epoch 4770, Loss: 1.3220897018909454, Final Batch Loss: 0.0\n",
      "Epoch 4771, Loss: 1.4981784373521805, Final Batch Loss: 0.1045854240655899\n",
      "Epoch 4772, Loss: 1.31068751309067, Final Batch Loss: 0.013729424215853214\n",
      "Epoch 4773, Loss: 1.3019048577407375, Final Batch Loss: 0.0010634964564815164\n",
      "Epoch 4774, Loss: 1.3829610012471676, Final Batch Loss: 0.018512096256017685\n",
      "Epoch 4775, Loss: 2.1541811525821686, Final Batch Loss: 0.9440328478813171\n",
      "Epoch 4776, Loss: 2.83385369181633, Final Batch Loss: 1.4994356632232666\n",
      "Epoch 4777, Loss: 1.3158519566059113, Final Batch Loss: 0.0\n",
      "Epoch 4778, Loss: 1.8730565905570984, Final Batch Loss: 0.4853096604347229\n",
      "Epoch 4779, Loss: 2.371489644050598, Final Batch Loss: 0.8572329878807068\n",
      "Epoch 4780, Loss: 2.970678150653839, Final Batch Loss: 1.4255870580673218\n",
      "Epoch 4781, Loss: 1.9120824038982391, Final Batch Loss: 0.44020596146583557\n",
      "Epoch 4782, Loss: 1.5548983514286192, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4783, Loss: 2.1388390362262726, Final Batch Loss: 0.5929792523384094\n",
      "Epoch 4784, Loss: 1.5999309518083464, Final Batch Loss: 0.0002002515539061278\n",
      "Epoch 4785, Loss: 1.5078587979078293, Final Batch Loss: 0.03667323291301727\n",
      "Epoch 4786, Loss: 2.6924608945846558, Final Batch Loss: 1.2367353439331055\n",
      "Epoch 4787, Loss: 1.9265183210372925, Final Batch Loss: 0.5111125111579895\n",
      "Epoch 4788, Loss: 1.3126445636153221, Final Batch Loss: 0.033835940062999725\n",
      "Epoch 4789, Loss: 2.2479661405086517, Final Batch Loss: 0.7711307406425476\n",
      "Epoch 4790, Loss: 1.3668499328196049, Final Batch Loss: 0.04362503066658974\n",
      "Epoch 4791, Loss: 1.59015791118145, Final Batch Loss: 0.24055810272693634\n",
      "Epoch 4792, Loss: 2.614382356405258, Final Batch Loss: 1.2983381748199463\n",
      "Epoch 4793, Loss: 8.286960780620575, Final Batch Loss: 6.391627311706543\n",
      "Epoch 4794, Loss: 1.6007841359823942, Final Batch Loss: 0.02430371753871441\n",
      "Epoch 4795, Loss: 1.714666062798642, Final Batch Loss: 0.0001072826053132303\n",
      "Epoch 4796, Loss: 1.7103392919525504, Final Batch Loss: 0.013559265993535519\n",
      "Epoch 4797, Loss: 2.3906786143779755, Final Batch Loss: 0.3711571991443634\n",
      "Epoch 4798, Loss: 1.8903973251581192, Final Batch Loss: 0.08945836126804352\n",
      "Epoch 4799, Loss: 3.945718616247177, Final Batch Loss: 2.259944438934326\n",
      "Epoch 4800, Loss: 2.2317057251930237, Final Batch Loss: 0.6740640997886658\n",
      "Epoch 4801, Loss: 2.058952182531357, Final Batch Loss: 0.4620089530944824\n",
      "Epoch 4802, Loss: 1.7068013588432223, Final Batch Loss: 0.0014617482665926218\n",
      "Epoch 4803, Loss: 2.3727810457348824, Final Batch Loss: 0.03509003669023514\n",
      "Epoch 4804, Loss: 3.3260322213172913, Final Batch Loss: 0.8967986702919006\n",
      "Epoch 4805, Loss: 2.999190390110016, Final Batch Loss: 1.2570366859436035\n",
      "Epoch 4806, Loss: 1.8408415615558624, Final Batch Loss: 0.35315752029418945\n",
      "Epoch 4807, Loss: 1.494269196409732, Final Batch Loss: 0.00549686374142766\n",
      "Epoch 4808, Loss: 2.556907892227173, Final Batch Loss: 1.1449214220046997\n",
      "Epoch 4809, Loss: 1.4966157488524914, Final Batch Loss: 0.017575006932020187\n",
      "Epoch 4810, Loss: 1.955768346786499, Final Batch Loss: 0.4787476062774658\n",
      "Epoch 4811, Loss: 2.274242341518402, Final Batch Loss: 0.8576834797859192\n",
      "Epoch 4812, Loss: 3.7435335218906403, Final Batch Loss: 2.3204708099365234\n",
      "Epoch 4813, Loss: 2.8288576900959015, Final Batch Loss: 1.3270611763000488\n",
      "Epoch 4814, Loss: 3.508315622806549, Final Batch Loss: 1.9137709140777588\n",
      "Epoch 4815, Loss: 2.438988983631134, Final Batch Loss: 1.0034902095794678\n",
      "Epoch 4816, Loss: 1.4277802938595414, Final Batch Loss: 0.0006087357178330421\n",
      "Epoch 4817, Loss: 1.5441419379785657, Final Batch Loss: 0.00876047182828188\n",
      "Epoch 4818, Loss: 1.371686249933191, Final Batch Loss: 8.702239938429557e-06\n",
      "Epoch 4819, Loss: 1.5482331379316747, Final Batch Loss: 0.004844950046390295\n",
      "Epoch 4820, Loss: 1.358297943341313, Final Batch Loss: 0.00034731553751043975\n",
      "Epoch 4821, Loss: 2.7465606927871704, Final Batch Loss: 1.3118313550949097\n",
      "Epoch 4822, Loss: 1.9284407794475555, Final Batch Loss: 0.6058820486068726\n",
      "Epoch 4823, Loss: 1.3337142691016197, Final Batch Loss: 0.0168604776263237\n",
      "Epoch 4824, Loss: 1.7507447600364685, Final Batch Loss: 0.39261671900749207\n",
      "Epoch 4825, Loss: 2.4460384845733643, Final Batch Loss: 1.0871185064315796\n",
      "Epoch 4826, Loss: 2.05279079079628, Final Batch Loss: 0.7372332811355591\n",
      "Epoch 4827, Loss: 1.5245235487818718, Final Batch Loss: 0.09781014174222946\n",
      "Epoch 4828, Loss: 1.4420710504055023, Final Batch Loss: 0.0\n",
      "Epoch 4829, Loss: 1.992130070924759, Final Batch Loss: 0.5727353096008301\n",
      "Epoch 4830, Loss: 2.9672194719314575, Final Batch Loss: 1.5726730823516846\n",
      "Epoch 4831, Loss: 1.4502732157707214, Final Batch Loss: 0.009764999151229858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4832, Loss: 1.4903898340417072, Final Batch Loss: 0.0005270045949146152\n",
      "Epoch 4833, Loss: 1.461052279919386, Final Batch Loss: 0.04411197826266289\n",
      "Epoch 4834, Loss: 2.4161621630191803, Final Batch Loss: 1.0057334899902344\n",
      "Epoch 4835, Loss: 2.628078430891037, Final Batch Loss: 1.238690733909607\n",
      "Epoch 4836, Loss: 2.4497110545635223, Final Batch Loss: 1.0872387886047363\n",
      "Epoch 4837, Loss: 2.266256332397461, Final Batch Loss: 0.9472771286964417\n",
      "Epoch 4838, Loss: 1.4398313760757446, Final Batch Loss: 0.0\n",
      "Epoch 4839, Loss: 3.2321803867816925, Final Batch Loss: 1.8004493713378906\n",
      "Epoch 4840, Loss: 1.9194468557834625, Final Batch Loss: 0.5288419127464294\n",
      "Epoch 4841, Loss: 1.4355807833489962, Final Batch Loss: 0.0006090931710787117\n",
      "Epoch 4842, Loss: 2.330797702074051, Final Batch Loss: 0.9796951413154602\n",
      "Epoch 4843, Loss: 3.9526856541633606, Final Batch Loss: 2.5467028617858887\n",
      "Epoch 4844, Loss: 1.5983734279870987, Final Batch Loss: 0.13526864349842072\n",
      "Epoch 4845, Loss: 1.3780344645492733, Final Batch Loss: 0.006522319745272398\n",
      "Epoch 4846, Loss: 1.3508779564872384, Final Batch Loss: 0.004387752152979374\n",
      "Epoch 4847, Loss: 1.6468960046768188, Final Batch Loss: 0.1789541244506836\n",
      "Epoch 4848, Loss: 3.232163816690445, Final Batch Loss: 1.8210504055023193\n",
      "Epoch 4849, Loss: 2.8796859979629517, Final Batch Loss: 1.5071682929992676\n",
      "Epoch 4850, Loss: 4.4537985026836395, Final Batch Loss: 3.036391258239746\n",
      "Epoch 4851, Loss: 1.5056970873847604, Final Batch Loss: 0.010367230512201786\n",
      "Epoch 4852, Loss: 1.5895980298191716, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 4853, Loss: 1.558109562844038, Final Batch Loss: 0.020466219633817673\n",
      "Epoch 4854, Loss: 3.4609881937503815, Final Batch Loss: 1.9737327098846436\n",
      "Epoch 4855, Loss: 1.5645313765853643, Final Batch Loss: 0.030037811025977135\n",
      "Epoch 4856, Loss: 1.6320181488645176, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 4857, Loss: 2.78282368183136, Final Batch Loss: 1.2364462614059448\n",
      "Epoch 4858, Loss: 2.7074432373046875, Final Batch Loss: 1.1749118566513062\n",
      "Epoch 4859, Loss: 1.4809661358594894, Final Batch Loss: 0.00929976999759674\n",
      "Epoch 4860, Loss: 3.458645284175873, Final Batch Loss: 1.9556069374084473\n",
      "Epoch 4861, Loss: 1.5021599978208542, Final Batch Loss: 0.0294426828622818\n",
      "Epoch 4862, Loss: 1.6644512936472893, Final Batch Loss: 0.07194959372282028\n",
      "Epoch 4863, Loss: 1.6613194340316113, Final Batch Loss: 0.0002466136065777391\n",
      "Epoch 4864, Loss: 2.158825308084488, Final Batch Loss: 0.4040359556674957\n",
      "Epoch 4865, Loss: 2.5863404273986816, Final Batch Loss: 0.8890042901039124\n",
      "Epoch 4866, Loss: 3.0629241466522217, Final Batch Loss: 1.5045998096466064\n",
      "Epoch 4867, Loss: 1.6875787675380707, Final Batch Loss: 0.18611735105514526\n",
      "Epoch 4868, Loss: 1.5832155272364616, Final Batch Loss: 0.09255277365446091\n",
      "Epoch 4869, Loss: 2.790345549583435, Final Batch Loss: 1.3075203895568848\n",
      "Epoch 4870, Loss: 2.258336305618286, Final Batch Loss: 0.7586180567741394\n",
      "Epoch 4871, Loss: 1.546187572646886, Final Batch Loss: 0.0028377999551594257\n",
      "Epoch 4872, Loss: 1.4376618296373636, Final Batch Loss: 0.0018410414922982454\n",
      "Epoch 4873, Loss: 1.459632174402941, Final Batch Loss: 0.00029488030122593045\n",
      "Epoch 4874, Loss: 1.593886986374855, Final Batch Loss: 0.14571623504161835\n",
      "Epoch 4875, Loss: 3.0747372210025787, Final Batch Loss: 1.6560286283493042\n",
      "Epoch 4876, Loss: 2.094969719648361, Final Batch Loss: 0.6657048463821411\n",
      "Epoch 4877, Loss: 1.457655556499958, Final Batch Loss: 0.022668637335300446\n",
      "Epoch 4878, Loss: 2.0061933398246765, Final Batch Loss: 0.6071245074272156\n",
      "Epoch 4879, Loss: 1.471874049399048, Final Batch Loss: 0.007043531630188227\n",
      "Epoch 4880, Loss: 1.5211724266409874, Final Batch Loss: 0.03500520437955856\n",
      "Epoch 4881, Loss: 1.48215374693973, Final Batch Loss: 0.0006405447493307292\n",
      "Epoch 4882, Loss: 3.937454491853714, Final Batch Loss: 2.5444724559783936\n",
      "Epoch 4883, Loss: 1.7336598634719849, Final Batch Loss: 0.2857649028301239\n",
      "Epoch 4884, Loss: 1.4982403218746185, Final Batch Loss: 0.08545991778373718\n",
      "Epoch 4885, Loss: 1.4915645919390954, Final Batch Loss: 0.0007454953738488257\n",
      "Epoch 4886, Loss: 1.4990844428539276, Final Batch Loss: 0.0560871958732605\n",
      "Epoch 4887, Loss: 1.4623200255446136, Final Batch Loss: 0.004247691016644239\n",
      "Epoch 4888, Loss: 1.3961298363137757, Final Batch Loss: 0.00014327930693980306\n",
      "Epoch 4889, Loss: 1.3584580644965172, Final Batch Loss: 0.03490977734327316\n",
      "Epoch 4890, Loss: 1.6203078031539917, Final Batch Loss: 0.27684667706489563\n",
      "Epoch 4891, Loss: 1.3841090653731953, Final Batch Loss: 0.0002975021197926253\n",
      "Epoch 4892, Loss: 1.4052202887833118, Final Batch Loss: 0.010412652045488358\n",
      "Epoch 4893, Loss: 2.3262682259082794, Final Batch Loss: 0.9812482595443726\n",
      "Epoch 4894, Loss: 1.4374278856557794, Final Batch Loss: 0.0003234816831536591\n",
      "Epoch 4895, Loss: 2.3896965980529785, Final Batch Loss: 0.9451826810836792\n",
      "Epoch 4896, Loss: 1.4501520600169897, Final Batch Loss: 0.02824174426496029\n",
      "Epoch 4897, Loss: 1.3911910582100973, Final Batch Loss: 0.0006567466771230102\n",
      "Epoch 4898, Loss: 1.4921444394276477, Final Batch Loss: 0.00033408781746402383\n",
      "Epoch 4899, Loss: 1.3871978803326783, Final Batch Loss: 5.6622808187967166e-05\n",
      "Epoch 4900, Loss: 1.378144621848378, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 4901, Loss: 1.4176858915016055, Final Batch Loss: 0.008920933119952679\n",
      "Epoch 4902, Loss: 1.7720953822135925, Final Batch Loss: 0.43602150678634644\n",
      "Epoch 4903, Loss: 1.3914515990763903, Final Batch Loss: 0.0073272306472063065\n",
      "Epoch 4904, Loss: 1.4220255457330495, Final Batch Loss: 0.003720506327226758\n",
      "Epoch 4905, Loss: 1.4158597886562347, Final Batch Loss: 0.0\n",
      "Epoch 4906, Loss: 2.44241401553154, Final Batch Loss: 1.1044771671295166\n",
      "Epoch 4907, Loss: 2.3951118290424347, Final Batch Loss: 1.0445114374160767\n",
      "Epoch 4908, Loss: 1.418798596598208, Final Batch Loss: 0.005399287678301334\n",
      "Epoch 4909, Loss: 2.8585242927074432, Final Batch Loss: 1.558316946029663\n",
      "Epoch 4910, Loss: 2.022677570581436, Final Batch Loss: 0.6950553059577942\n",
      "Epoch 4911, Loss: 1.3231014655902982, Final Batch Loss: 0.0017573880031704903\n",
      "Epoch 4912, Loss: 3.409472644329071, Final Batch Loss: 2.1337785720825195\n",
      "Epoch 4913, Loss: 1.7499179542064667, Final Batch Loss: 0.452282577753067\n",
      "Epoch 4914, Loss: 1.4135080315172672, Final Batch Loss: 0.05373719707131386\n",
      "Epoch 4915, Loss: 1.3007407729819533, Final Batch Loss: 0.0001045410826918669\n",
      "Epoch 4916, Loss: 1.4246557913720608, Final Batch Loss: 0.02835368737578392\n",
      "Epoch 4917, Loss: 3.0045654475688934, Final Batch Loss: 1.6794378757476807\n",
      "Epoch 4918, Loss: 1.5140630453824997, Final Batch Loss: 0.13982732594013214\n",
      "Epoch 4919, Loss: 1.3844220442697406, Final Batch Loss: 0.009663115255534649\n",
      "Epoch 4920, Loss: 2.9717637300491333, Final Batch Loss: 1.6483187675476074\n",
      "Epoch 4921, Loss: 1.4560349799576215, Final Batch Loss: 0.0007022537174634635\n",
      "Epoch 4922, Loss: 1.881565272808075, Final Batch Loss: 0.5317161083221436\n",
      "Epoch 4923, Loss: 1.2711220683995634, Final Batch Loss: 0.003659814829006791\n",
      "Epoch 4924, Loss: 2.8267899453639984, Final Batch Loss: 1.5406925678253174\n",
      "Epoch 4925, Loss: 2.9976285696029663, Final Batch Loss: 1.6682571172714233\n",
      "Epoch 4926, Loss: 1.3541010469198227, Final Batch Loss: 0.10298667848110199\n",
      "Epoch 4927, Loss: 2.0391238033771515, Final Batch Loss: 0.6802236437797546\n",
      "Epoch 4928, Loss: 2.1701681911945343, Final Batch Loss: 0.7457590699195862\n",
      "Epoch 4929, Loss: 1.4747655764222145, Final Batch Loss: 0.04063791781663895\n",
      "Epoch 4930, Loss: 2.593298554420471, Final Batch Loss: 1.1285531520843506\n",
      "Epoch 4931, Loss: 2.1814208030700684, Final Batch Loss: 0.7209780216217041\n",
      "Epoch 4932, Loss: 1.8906544744968414, Final Batch Loss: 0.4859963357448578\n",
      "Epoch 4933, Loss: 2.0572929680347443, Final Batch Loss: 0.6604185104370117\n",
      "Epoch 4934, Loss: 2.953504741191864, Final Batch Loss: 1.6299281120300293\n",
      "Epoch 4935, Loss: 2.2078120708465576, Final Batch Loss: 0.7937653064727783\n",
      "Epoch 4936, Loss: 1.3746738876216114, Final Batch Loss: 0.0017686928622424603\n",
      "Epoch 4937, Loss: 1.3307290896773338, Final Batch Loss: 0.007417045533657074\n",
      "Epoch 4938, Loss: 1.586115449666977, Final Batch Loss: 0.21448659896850586\n",
      "Epoch 4939, Loss: 1.4174209702759981, Final Batch Loss: 0.026579665020108223\n",
      "Epoch 4940, Loss: 1.428433489825693, Final Batch Loss: 0.00018892886873800308\n",
      "Epoch 4941, Loss: 2.03606316447258, Final Batch Loss: 0.683460533618927\n",
      "Epoch 4942, Loss: 1.403110608458519, Final Batch Loss: 0.033852651715278625\n",
      "Epoch 4943, Loss: 1.3877154309302568, Final Batch Loss: 0.0038879532366991043\n",
      "Epoch 4944, Loss: 1.414299806987401, Final Batch Loss: 0.00013350549852475524\n",
      "Epoch 4945, Loss: 1.371425747871399, Final Batch Loss: 0.111124187707901\n",
      "Epoch 4946, Loss: 3.1377347111701965, Final Batch Loss: 1.7789790630340576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4947, Loss: 1.36879447940737, Final Batch Loss: 0.011174359358847141\n",
      "Epoch 4948, Loss: 1.3057560920715332, Final Batch Loss: 0.016651928424835205\n",
      "Epoch 4949, Loss: 1.4001265991755645, Final Batch Loss: 0.00011872540198964998\n",
      "Epoch 4950, Loss: 2.891960710287094, Final Batch Loss: 1.6043767929077148\n",
      "Epoch 4951, Loss: 2.0106993913650513, Final Batch Loss: 0.7250180244445801\n",
      "Epoch 4952, Loss: 1.5788757801055908, Final Batch Loss: 0.2701202630996704\n",
      "Epoch 4953, Loss: 1.4421348869800568, Final Batch Loss: 0.13398820161819458\n",
      "Epoch 4954, Loss: 1.3194102048873901, Final Batch Loss: 0.007787108421325684\n",
      "Epoch 4955, Loss: 2.144783675670624, Final Batch Loss: 0.8424031138420105\n",
      "Epoch 4956, Loss: 1.353608574718237, Final Batch Loss: 0.04604613408446312\n",
      "Epoch 4957, Loss: 1.3056495431810617, Final Batch Loss: 0.009898269549012184\n",
      "Epoch 4958, Loss: 2.1386231780052185, Final Batch Loss: 0.6993080973625183\n",
      "Epoch 4959, Loss: 3.119908422231674, Final Batch Loss: 1.7431716918945312\n",
      "Epoch 4960, Loss: 1.9932112991809845, Final Batch Loss: 0.5653042793273926\n",
      "Epoch 4961, Loss: 3.3365637362003326, Final Batch Loss: 2.010207176208496\n",
      "Epoch 4962, Loss: 3.611003965139389, Final Batch Loss: 2.196497917175293\n",
      "Epoch 4963, Loss: 2.1883870661258698, Final Batch Loss: 0.7075566053390503\n",
      "Epoch 4964, Loss: 1.5690926611423492, Final Batch Loss: 0.0\n",
      "Epoch 4965, Loss: 1.6566450744867325, Final Batch Loss: 0.13269464671611786\n",
      "Epoch 4966, Loss: 1.4235877324827015, Final Batch Loss: 0.0070516993291676044\n",
      "Epoch 4967, Loss: 1.3832602072507143, Final Batch Loss: 0.02738274820148945\n",
      "Epoch 4968, Loss: 1.3137434762902558, Final Batch Loss: 0.005426083225756884\n",
      "Epoch 4969, Loss: 1.5064250081777573, Final Batch Loss: 0.0735986977815628\n",
      "Epoch 4970, Loss: 3.8866283893585205, Final Batch Loss: 2.6051180362701416\n",
      "Epoch 4971, Loss: 1.9358094036579132, Final Batch Loss: 0.6041988730430603\n",
      "Epoch 4972, Loss: 1.4565356676466763, Final Batch Loss: 0.004183114040642977\n",
      "Epoch 4973, Loss: 1.4214763268828392, Final Batch Loss: 0.03844987601041794\n",
      "Epoch 4974, Loss: 1.6092945039272308, Final Batch Loss: 0.17727866768836975\n",
      "Epoch 4975, Loss: 1.440717060584575, Final Batch Loss: 0.004150111693888903\n",
      "Epoch 4976, Loss: 1.3818834874546155, Final Batch Loss: 0.0012323412811383605\n",
      "Epoch 4977, Loss: 1.417030332610011, Final Batch Loss: 0.009049354121088982\n",
      "Epoch 4978, Loss: 1.5274830162525177, Final Batch Loss: 0.1803918182849884\n",
      "Epoch 4979, Loss: 2.2209458351135254, Final Batch Loss: 0.8607551455497742\n",
      "Epoch 4980, Loss: 1.3973690867424011, Final Batch Loss: 0.0\n",
      "Epoch 4981, Loss: 3.275046467781067, Final Batch Loss: 1.9224563837051392\n",
      "Epoch 4982, Loss: 1.3492801571264863, Final Batch Loss: 0.006783314980566502\n",
      "Epoch 4983, Loss: 1.2774493899196386, Final Batch Loss: 0.010363927111029625\n",
      "Epoch 4984, Loss: 1.360045962035656, Final Batch Loss: 0.04860913008451462\n",
      "Epoch 4985, Loss: 1.252614713885123, Final Batch Loss: 0.00047338721924461424\n",
      "Epoch 4986, Loss: 1.3017773497849703, Final Batch Loss: 0.01632102020084858\n",
      "Epoch 4987, Loss: 3.045039802789688, Final Batch Loss: 1.6864025592803955\n",
      "Epoch 4988, Loss: 1.277748435462854, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 4989, Loss: 1.7078115046024323, Final Batch Loss: 0.3915288746356964\n",
      "Epoch 4990, Loss: 2.2678290009498596, Final Batch Loss: 0.9026648998260498\n",
      "Epoch 4991, Loss: 1.7874774038791656, Final Batch Loss: 0.4975234568119049\n",
      "Epoch 4992, Loss: 1.3408354697749019, Final Batch Loss: 0.0027759848162531853\n",
      "Epoch 4993, Loss: 1.3153196908533573, Final Batch Loss: 0.00041392818093299866\n",
      "Epoch 4994, Loss: 1.3197235914412886, Final Batch Loss: 0.00141258561052382\n",
      "Epoch 4995, Loss: 3.260916829109192, Final Batch Loss: 1.994582176208496\n",
      "Epoch 4996, Loss: 1.2983852273318917, Final Batch Loss: 0.0026863461825996637\n",
      "Epoch 4997, Loss: 1.3307872377336025, Final Batch Loss: 0.025287296622991562\n",
      "Epoch 4998, Loss: 1.6543689370155334, Final Batch Loss: 0.2665368318557739\n",
      "Epoch 4999, Loss: 2.781306654214859, Final Batch Loss: 1.429361343383789\n",
      "Epoch 5000, Loss: 1.5002296641469002, Final Batch Loss: 0.10524962097406387\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  0  0  0  0  0]\n",
      " [ 1 21  1  3  1  1]\n",
      " [ 0  0 25  2  0  1]\n",
      " [ 0  0  2 33  0  0]\n",
      " [14  0  4  1 13  0]\n",
      " [ 0  0  0  0  1 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.68085   1.00000   0.81013        32\n",
      "           1    1.00000   0.75000   0.85714        28\n",
      "           2    0.78125   0.89286   0.83333        28\n",
      "           3    0.84615   0.94286   0.89189        35\n",
      "           4    0.86667   0.40625   0.55319        32\n",
      "           5    0.94118   0.96970   0.95522        33\n",
      "\n",
      "    accuracy                        0.82979       188\n",
      "   macro avg    0.85268   0.82694   0.81682       188\n",
      "weighted avg    0.85143   0.82979   0.81754       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  1  2  4  0]\n",
      " [ 3 17  0  3  5  2]\n",
      " [ 0  0 17  7  2  4]\n",
      " [ 0  2  1 24  3  0]\n",
      " [ 2  0  0  0 24  4]\n",
      " [ 1  0  3  0  4 22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79310   0.76667   0.77966        30\n",
      "           1    0.89474   0.56667   0.69388        30\n",
      "           2    0.77273   0.56667   0.65385        30\n",
      "           3    0.66667   0.80000   0.72727        30\n",
      "           4    0.57143   0.80000   0.66667        30\n",
      "           5    0.68750   0.73333   0.70968        30\n",
      "\n",
      "    accuracy                        0.70556       180\n",
      "   macro avg    0.73103   0.70556   0.70517       180\n",
      "weighted avg    0.73103   0.70556   0.70517       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
