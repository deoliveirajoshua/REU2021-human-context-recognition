{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '90 tBodyAccJerk-max()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 6)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.332762122154236, Final Batch Loss: 1.037563681602478\n",
      "Epoch 2, Loss: 4.338975429534912, Final Batch Loss: 1.0544679164886475\n",
      "Epoch 3, Loss: 4.314476132392883, Final Batch Loss: 1.0376667976379395\n",
      "Epoch 4, Loss: 4.2819541692733765, Final Batch Loss: 1.0079344511032104\n",
      "Epoch 5, Loss: 4.5537601709365845, Final Batch Loss: 1.292805552482605\n",
      "Epoch 6, Loss: 4.26775050163269, Final Batch Loss: 1.0072368383407593\n",
      "Epoch 7, Loss: 4.269147276878357, Final Batch Loss: 1.0190597772598267\n",
      "Epoch 8, Loss: 4.480282664299011, Final Batch Loss: 1.2444655895233154\n",
      "Epoch 9, Loss: 4.221273958683014, Final Batch Loss: 0.9904813170433044\n",
      "Epoch 10, Loss: 4.4857810735702515, Final Batch Loss: 1.2732107639312744\n",
      "Epoch 11, Loss: 4.167403876781464, Final Batch Loss: 0.9695670008659363\n",
      "Epoch 12, Loss: 4.197650194168091, Final Batch Loss: 1.0093309879302979\n",
      "Epoch 13, Loss: 4.229457378387451, Final Batch Loss: 1.0511400699615479\n",
      "Epoch 14, Loss: 4.34416663646698, Final Batch Loss: 1.1905593872070312\n",
      "Epoch 15, Loss: 4.380338668823242, Final Batch Loss: 1.2460942268371582\n",
      "Epoch 16, Loss: 4.2638325691223145, Final Batch Loss: 1.1530723571777344\n",
      "Epoch 17, Loss: 4.191773295402527, Final Batch Loss: 1.114359736442566\n",
      "Epoch 18, Loss: 4.045801043510437, Final Batch Loss: 1.003504991531372\n",
      "Epoch 19, Loss: 3.9065979719161987, Final Batch Loss: 0.9067613482475281\n",
      "Epoch 20, Loss: 3.9646982550621033, Final Batch Loss: 1.0122697353363037\n",
      "Epoch 21, Loss: 3.8394070863723755, Final Batch Loss: 0.9564302563667297\n",
      "Epoch 22, Loss: 3.808476150035858, Final Batch Loss: 0.9873706102371216\n",
      "Epoch 23, Loss: 3.6702720522880554, Final Batch Loss: 0.9289901852607727\n",
      "Epoch 24, Loss: 3.5423858165740967, Final Batch Loss: 0.8787733316421509\n",
      "Epoch 25, Loss: 3.3304284811019897, Final Batch Loss: 0.7477657198905945\n",
      "Epoch 26, Loss: 3.22288054227829, Final Batch Loss: 0.7564430236816406\n",
      "Epoch 27, Loss: 3.1298860907554626, Final Batch Loss: 0.7537116408348083\n",
      "Epoch 28, Loss: 2.9645808935165405, Final Batch Loss: 0.6899830102920532\n",
      "Epoch 29, Loss: 2.657778114080429, Final Batch Loss: 0.4945538341999054\n",
      "Epoch 30, Loss: 2.5224465131759644, Final Batch Loss: 0.49371087551116943\n",
      "Epoch 31, Loss: 2.5370309948921204, Final Batch Loss: 0.6615102291107178\n",
      "Epoch 32, Loss: 2.721934735774994, Final Batch Loss: 0.9751513004302979\n",
      "Epoch 33, Loss: 1.9872523248195648, Final Batch Loss: 0.3322429358959198\n",
      "Epoch 34, Loss: 1.906578004360199, Final Batch Loss: 0.3892221450805664\n",
      "Epoch 35, Loss: 1.8605793118476868, Final Batch Loss: 0.386045902967453\n",
      "Epoch 36, Loss: 1.823830485343933, Final Batch Loss: 0.4558849036693573\n",
      "Epoch 37, Loss: 2.114208608865738, Final Batch Loss: 0.8593958616256714\n",
      "Epoch 38, Loss: 1.2990645319223404, Final Batch Loss: 0.11818297207355499\n",
      "Epoch 39, Loss: 1.380422681570053, Final Batch Loss: 0.2549900412559509\n",
      "Epoch 40, Loss: 1.5455312132835388, Final Batch Loss: 0.42011716961860657\n",
      "Epoch 41, Loss: 1.0865376256406307, Final Batch Loss: 0.02672823891043663\n",
      "Epoch 42, Loss: 1.08787901699543, Final Batch Loss: 0.10996805131435394\n",
      "Epoch 43, Loss: 1.2076670229434967, Final Batch Loss: 0.17564129829406738\n",
      "Epoch 44, Loss: 0.9853523075580597, Final Batch Loss: 0.04983702301979065\n",
      "Epoch 45, Loss: 2.2084636986255646, Final Batch Loss: 1.320770502090454\n",
      "Epoch 46, Loss: 0.9020579494535923, Final Batch Loss: 0.031125668436288834\n",
      "Epoch 47, Loss: 1.1583257764577866, Final Batch Loss: 0.23671264946460724\n",
      "Epoch 48, Loss: 1.3671591877937317, Final Batch Loss: 0.4402005076408386\n",
      "Epoch 49, Loss: 0.9950415352359414, Final Batch Loss: 0.014688448049128056\n",
      "Epoch 50, Loss: 1.9345803558826447, Final Batch Loss: 0.7879235148429871\n",
      "Epoch 51, Loss: 1.2166849672794342, Final Batch Loss: 0.2081153392791748\n",
      "Epoch 52, Loss: 1.1589403003454208, Final Batch Loss: 0.17632271349430084\n",
      "Epoch 53, Loss: 1.0477197915315628, Final Batch Loss: 0.20864562690258026\n",
      "Epoch 54, Loss: 1.6821768432855606, Final Batch Loss: 0.8763840794563293\n",
      "Epoch 55, Loss: 0.8115223795175552, Final Batch Loss: 0.09634667634963989\n",
      "Epoch 56, Loss: 0.758148830384016, Final Batch Loss: 0.053441163152456284\n",
      "Epoch 57, Loss: 1.5744519531726837, Final Batch Loss: 0.7866856455802917\n",
      "Epoch 58, Loss: 1.0304472893476486, Final Batch Loss: 0.28217649459838867\n",
      "Epoch 59, Loss: 1.0723610073328018, Final Batch Loss: 0.31232428550720215\n",
      "Epoch 60, Loss: 0.8188353441655636, Final Batch Loss: 0.04054393991827965\n",
      "Epoch 61, Loss: 0.7624327689409256, Final Batch Loss: 0.042171791195869446\n",
      "Epoch 62, Loss: 0.8134467005729675, Final Batch Loss: 0.18583250045776367\n",
      "Epoch 63, Loss: 1.091349869966507, Final Batch Loss: 0.4138685166835785\n",
      "Epoch 64, Loss: 0.9548596292734146, Final Batch Loss: 0.26546379923820496\n",
      "Epoch 65, Loss: 0.9266065955162048, Final Batch Loss: 0.1808343529701233\n",
      "Epoch 66, Loss: 0.8017298802733421, Final Batch Loss: 0.04348031431436539\n",
      "Epoch 67, Loss: 0.928462415933609, Final Batch Loss: 0.25334668159484863\n",
      "Epoch 68, Loss: 0.970965638756752, Final Batch Loss: 0.35194289684295654\n",
      "Epoch 69, Loss: 0.8487277179956436, Final Batch Loss: 0.20397818088531494\n",
      "Epoch 70, Loss: 0.6251168609596789, Final Batch Loss: 0.006842514965683222\n",
      "Epoch 71, Loss: 1.469066396355629, Final Batch Loss: 0.7884678244590759\n",
      "Epoch 72, Loss: 0.6473153736442327, Final Batch Loss: 0.008654704317450523\n",
      "Epoch 73, Loss: 0.6470938492566347, Final Batch Loss: 0.026729168370366096\n",
      "Epoch 74, Loss: 0.8234733045101166, Final Batch Loss: 0.2516430616378784\n",
      "Epoch 75, Loss: 0.5855871690437198, Final Batch Loss: 0.011485408060252666\n",
      "Epoch 76, Loss: 0.5827398964902386, Final Batch Loss: 0.0017476299544796348\n",
      "Epoch 77, Loss: 0.7193155623972416, Final Batch Loss: 0.030763451009988785\n",
      "Epoch 78, Loss: 3.109185293316841, Final Batch Loss: 2.4909157752990723\n",
      "Epoch 79, Loss: 1.1736080795526505, Final Batch Loss: 0.5485945343971252\n",
      "Epoch 80, Loss: 0.5610480103641748, Final Batch Loss: 0.008129129186272621\n",
      "Epoch 81, Loss: 0.9147666245698929, Final Batch Loss: 0.3766867220401764\n",
      "Epoch 82, Loss: 0.5977881737053394, Final Batch Loss: 0.057846132665872574\n",
      "Epoch 83, Loss: 0.5889326350297779, Final Batch Loss: 0.0032913105096668005\n",
      "Epoch 84, Loss: 0.6953906333073974, Final Batch Loss: 0.007703832350671291\n",
      "Epoch 85, Loss: 0.5501013826578856, Final Batch Loss: 0.011442510411143303\n",
      "Epoch 86, Loss: 0.6359743028879166, Final Batch Loss: 0.10840409994125366\n",
      "Epoch 87, Loss: 0.5313649894669652, Final Batch Loss: 0.006048825569450855\n",
      "Epoch 88, Loss: 0.5677798101678491, Final Batch Loss: 0.012857512570917606\n",
      "Epoch 89, Loss: 0.619903608225286, Final Batch Loss: 0.003986864350736141\n",
      "Epoch 90, Loss: 0.8289396017789841, Final Batch Loss: 0.23110830783843994\n",
      "Epoch 91, Loss: 0.5092826958280057, Final Batch Loss: 0.0009267802815884352\n",
      "Epoch 92, Loss: 0.5267596300691366, Final Batch Loss: 0.00999552570283413\n",
      "Epoch 93, Loss: 0.6042174581671134, Final Batch Loss: 0.0014416311169043183\n",
      "Epoch 94, Loss: 0.5978039319161326, Final Batch Loss: 0.0010811204556375742\n",
      "Epoch 95, Loss: 0.6354468986392021, Final Batch Loss: 0.08639807254076004\n",
      "Epoch 96, Loss: 0.5591410947963595, Final Batch Loss: 0.013659576885402203\n",
      "Epoch 97, Loss: 0.5497129443101585, Final Batch Loss: 0.007377523463219404\n",
      "Epoch 98, Loss: 0.5175690522883087, Final Batch Loss: 0.0011815002653747797\n",
      "Epoch 99, Loss: 2.514571897685528, Final Batch Loss: 2.050504684448242\n",
      "Epoch 100, Loss: 0.5940442979335785, Final Batch Loss: 0.05467724800109863\n",
      "Epoch 101, Loss: 0.5985107254236937, Final Batch Loss: 0.01032310537993908\n",
      "Epoch 102, Loss: 0.6897041127085686, Final Batch Loss: 0.015261776745319366\n",
      "Epoch 103, Loss: 0.7382217049598694, Final Batch Loss: 0.1260022670030594\n",
      "Epoch 104, Loss: 2.25585974752903, Final Batch Loss: 1.723526120185852\n",
      "Epoch 105, Loss: 0.5191546938149258, Final Batch Loss: 0.000259365770034492\n",
      "Epoch 106, Loss: 0.6816833764314651, Final Batch Loss: 0.09558607637882233\n",
      "Epoch 107, Loss: 3.161839112639427, Final Batch Loss: 2.5118765830993652\n",
      "Epoch 108, Loss: 1.6877615749835968, Final Batch Loss: 1.0902879238128662\n",
      "Epoch 109, Loss: 0.5204982897266746, Final Batch Loss: 0.0027986904606223106\n",
      "Epoch 110, Loss: 0.692945584654808, Final Batch Loss: 0.14027740061283112\n",
      "Epoch 111, Loss: 4.285718947649002, Final Batch Loss: 3.754882574081421\n",
      "Epoch 112, Loss: 0.5445929057896137, Final Batch Loss: 0.010906253010034561\n",
      "Epoch 113, Loss: 0.5397313998546451, Final Batch Loss: 0.0019208805169910192\n",
      "Epoch 114, Loss: 0.6062273904681206, Final Batch Loss: 0.03994060307741165\n",
      "Epoch 115, Loss: 0.5972168911248446, Final Batch Loss: 0.02191995270550251\n",
      "Epoch 116, Loss: 0.58397058211267, Final Batch Loss: 0.015919139608740807\n",
      "Epoch 117, Loss: 0.8490192592144012, Final Batch Loss: 0.3002101182937622\n",
      "Epoch 118, Loss: 0.5262456751661375, Final Batch Loss: 0.0015586382942274213\n",
      "Epoch 119, Loss: 0.541601873934269, Final Batch Loss: 0.07207749038934708\n",
      "Epoch 120, Loss: 0.6539379805326462, Final Batch Loss: 0.014232203364372253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Loss: 1.4132584035396576, Final Batch Loss: 0.9430651068687439\n",
      "Epoch 122, Loss: 0.5500411875545979, Final Batch Loss: 0.01973341777920723\n",
      "Epoch 123, Loss: 0.6075681820511818, Final Batch Loss: 0.06171760708093643\n",
      "Epoch 124, Loss: 0.478874983265996, Final Batch Loss: 0.009172679856419563\n",
      "Epoch 125, Loss: 0.49207987543195486, Final Batch Loss: 0.006574547849595547\n",
      "Epoch 126, Loss: 0.8608949780464172, Final Batch Loss: 0.3669470250606537\n",
      "Epoch 127, Loss: 0.4847510326653719, Final Batch Loss: 0.023003624752163887\n",
      "Epoch 128, Loss: 0.48078217916190624, Final Batch Loss: 0.016887200996279716\n",
      "Epoch 129, Loss: 0.484311081469059, Final Batch Loss: 0.029603563249111176\n",
      "Epoch 130, Loss: 0.4143781578168273, Final Batch Loss: 0.010253137908875942\n",
      "Epoch 131, Loss: 0.5212156176567078, Final Batch Loss: 0.0078497976064682\n",
      "Epoch 132, Loss: 0.4936432056128979, Final Batch Loss: 0.031728919595479965\n",
      "Epoch 133, Loss: 0.37698125350289047, Final Batch Loss: 0.0029627259355038404\n",
      "Epoch 134, Loss: 0.41132660512812436, Final Batch Loss: 0.0035181075800210238\n",
      "Epoch 135, Loss: 0.4228178206831217, Final Batch Loss: 0.01082807220518589\n",
      "Epoch 136, Loss: 0.4546325863339007, Final Batch Loss: 0.0013763965107500553\n",
      "Epoch 137, Loss: 0.4125604247674346, Final Batch Loss: 0.005700758658349514\n",
      "Epoch 138, Loss: 0.4084290536120534, Final Batch Loss: 0.012408320792019367\n",
      "Epoch 139, Loss: 0.4115194045007229, Final Batch Loss: 0.013768460601568222\n",
      "Epoch 140, Loss: 0.591813862323761, Final Batch Loss: 0.14689838886260986\n",
      "Epoch 141, Loss: 0.4371231603436172, Final Batch Loss: 0.007601502817124128\n",
      "Epoch 142, Loss: 0.39741906709969044, Final Batch Loss: 0.013929413631558418\n",
      "Epoch 143, Loss: 0.4052047077566385, Final Batch Loss: 0.028424369171261787\n",
      "Epoch 144, Loss: 0.4366520196199417, Final Batch Loss: 0.014667302370071411\n",
      "Epoch 145, Loss: 0.6489342674612999, Final Batch Loss: 0.2692549526691437\n",
      "Epoch 146, Loss: 0.40702007873915136, Final Batch Loss: 0.0020005942787975073\n",
      "Epoch 147, Loss: 0.4383849413716234, Final Batch Loss: 0.0003034608089365065\n",
      "Epoch 148, Loss: 0.6604523658752441, Final Batch Loss: 0.29771342873573303\n",
      "Epoch 149, Loss: 0.43007590994238853, Final Batch Loss: 0.0514494888484478\n",
      "Epoch 150, Loss: 0.48163579031825066, Final Batch Loss: 0.016332630068063736\n",
      "Epoch 151, Loss: 0.3752447073929943, Final Batch Loss: 0.0002972637885250151\n",
      "Epoch 152, Loss: 0.5520901829004288, Final Batch Loss: 0.1461077332496643\n",
      "Epoch 153, Loss: 0.3905817084014416, Final Batch Loss: 0.008220527321100235\n",
      "Epoch 154, Loss: 0.34287184476852417, Final Batch Loss: 0.016226135194301605\n",
      "Epoch 155, Loss: 0.41528038308024406, Final Batch Loss: 0.01357855275273323\n",
      "Epoch 156, Loss: 2.6354978680610657, Final Batch Loss: 2.265655517578125\n",
      "Epoch 157, Loss: 2.97512748837471, Final Batch Loss: 2.516230344772339\n",
      "Epoch 158, Loss: 2.26299612224102, Final Batch Loss: 1.4731850624084473\n",
      "Epoch 159, Loss: 4.581272482872009, Final Batch Loss: 3.531229257583618\n",
      "Epoch 160, Loss: 1.0563625823706388, Final Batch Loss: 0.017087263986468315\n",
      "Epoch 161, Loss: 1.1313404589891434, Final Batch Loss: 0.3433827757835388\n",
      "Epoch 162, Loss: 0.5965936848660931, Final Batch Loss: 0.0001267114421352744\n",
      "Epoch 163, Loss: 0.5289397835731506, Final Batch Loss: 0.01848869025707245\n",
      "Epoch 164, Loss: 0.6345219314098358, Final Batch Loss: 0.18487387895584106\n",
      "Epoch 165, Loss: 0.522975817322731, Final Batch Loss: 0.07440043240785599\n",
      "Epoch 166, Loss: 0.9634566828608513, Final Batch Loss: 0.5517102479934692\n",
      "Epoch 167, Loss: 0.3758650121744722, Final Batch Loss: 0.0009993088897317648\n",
      "Epoch 168, Loss: 0.4237349983304739, Final Batch Loss: 0.0022508781403303146\n",
      "Epoch 169, Loss: 2.2014952152967453, Final Batch Loss: 1.8027650117874146\n",
      "Epoch 170, Loss: 0.8585278987884521, Final Batch Loss: 0.43839678168296814\n",
      "Epoch 171, Loss: 0.3685583633487113, Final Batch Loss: 0.0004372832481749356\n",
      "Epoch 172, Loss: 1.095166638493538, Final Batch Loss: 0.6602004170417786\n",
      "Epoch 173, Loss: 0.41527891252189875, Final Batch Loss: 0.0028663286939263344\n",
      "Epoch 174, Loss: 0.529869444668293, Final Batch Loss: 0.13307811319828033\n",
      "Epoch 175, Loss: 0.5146013423800468, Final Batch Loss: 0.07049085944890976\n",
      "Epoch 176, Loss: 0.40043973247520626, Final Batch Loss: 0.0029101900290697813\n",
      "Epoch 177, Loss: 0.4176032217219472, Final Batch Loss: 0.004793343134224415\n",
      "Epoch 178, Loss: 0.5714314728975296, Final Batch Loss: 0.19101695716381073\n",
      "Epoch 179, Loss: 0.39503253530710936, Final Batch Loss: 0.0021227700635790825\n",
      "Epoch 180, Loss: 0.38216074177762493, Final Batch Loss: 0.0005918181850574911\n",
      "Epoch 181, Loss: 0.3818652769550681, Final Batch Loss: 0.010493225418031216\n",
      "Epoch 182, Loss: 0.43100133538246155, Final Batch Loss: 0.08835982531309128\n",
      "Epoch 183, Loss: 0.3668682835996151, Final Batch Loss: 0.019571293145418167\n",
      "Epoch 184, Loss: 0.4081335458904505, Final Batch Loss: 0.007822947576642036\n",
      "Epoch 185, Loss: 0.6647246554493904, Final Batch Loss: 0.2996467351913452\n",
      "Epoch 186, Loss: 0.3721929434686899, Final Batch Loss: 0.02770584262907505\n",
      "Epoch 187, Loss: 0.6962919533252716, Final Batch Loss: 0.3487292528152466\n",
      "Epoch 188, Loss: 0.4219730272889137, Final Batch Loss: 0.1115763783454895\n",
      "Epoch 189, Loss: 0.645181268453598, Final Batch Loss: 0.2868022322654724\n",
      "Epoch 190, Loss: 0.374004615470767, Final Batch Loss: 0.01747707836329937\n",
      "Epoch 191, Loss: 0.36070405691862106, Final Batch Loss: 0.07490293681621552\n",
      "Epoch 192, Loss: 0.35538671165704727, Final Batch Loss: 0.013870984315872192\n",
      "Epoch 193, Loss: 0.4010777436196804, Final Batch Loss: 0.020492147654294968\n",
      "Epoch 194, Loss: 0.34725906618405133, Final Batch Loss: 0.0014801985817030072\n",
      "Epoch 195, Loss: 0.4916239455342293, Final Batch Loss: 0.18476587533950806\n",
      "Epoch 196, Loss: 0.3497622774448246, Final Batch Loss: 0.003539608558639884\n",
      "Epoch 197, Loss: 0.342908741440624, Final Batch Loss: 0.0022526620887219906\n",
      "Epoch 198, Loss: 0.34415258676745, Final Batch Loss: 0.0030471107456833124\n",
      "Epoch 199, Loss: 0.5389352291822433, Final Batch Loss: 0.2279880940914154\n",
      "Epoch 200, Loss: 0.32104134709516075, Final Batch Loss: 0.0002379134384682402\n",
      "Epoch 201, Loss: 0.34682429023087025, Final Batch Loss: 0.022166000679135323\n",
      "Epoch 202, Loss: 0.3617040391545743, Final Batch Loss: 0.0021228890400379896\n",
      "Epoch 203, Loss: 0.3765548225492239, Final Batch Loss: 0.02751891128718853\n",
      "Epoch 204, Loss: 0.3586899288929999, Final Batch Loss: 0.001384491566568613\n",
      "Epoch 205, Loss: 0.3155359505908564, Final Batch Loss: 0.0011025547282770276\n",
      "Epoch 206, Loss: 0.4370006248354912, Final Batch Loss: 0.0896356999874115\n",
      "Epoch 207, Loss: 0.29277239194198046, Final Batch Loss: 0.00020180096908006817\n",
      "Epoch 208, Loss: 1.3796495199203491, Final Batch Loss: 1.0533872842788696\n",
      "Epoch 209, Loss: 0.3835180914029479, Final Batch Loss: 0.002302735112607479\n",
      "Epoch 210, Loss: 0.5187546592205763, Final Batch Loss: 0.019554225727915764\n",
      "Epoch 211, Loss: 0.5913411693763919, Final Batch Loss: 0.0003816353273577988\n",
      "Epoch 212, Loss: 4.212615609169006, Final Batch Loss: 3.7049102783203125\n",
      "Epoch 213, Loss: 0.4311838308349252, Final Batch Loss: 0.010927596129477024\n",
      "Epoch 214, Loss: 0.36969015188515186, Final Batch Loss: 0.008826525881886482\n",
      "Epoch 215, Loss: 0.3324566094670445, Final Batch Loss: 0.0014807938132435083\n",
      "Epoch 216, Loss: 0.3424394859466702, Final Batch Loss: 0.0029490573797374964\n",
      "Epoch 217, Loss: 0.4612050727009773, Final Batch Loss: 0.08659038692712784\n",
      "Epoch 218, Loss: 0.35947771556675434, Final Batch Loss: 0.005781831219792366\n",
      "Epoch 219, Loss: 0.41612400487065315, Final Batch Loss: 0.04672703519463539\n",
      "Epoch 220, Loss: 0.3934963163919747, Final Batch Loss: 0.002221499104052782\n",
      "Epoch 221, Loss: 0.3808976486325264, Final Batch Loss: 0.04135030508041382\n",
      "Epoch 222, Loss: 0.4081764593720436, Final Batch Loss: 0.10432963818311691\n",
      "Epoch 223, Loss: 0.3495337497442961, Final Batch Loss: 0.012721104547381401\n",
      "Epoch 224, Loss: 0.856037013232708, Final Batch Loss: 0.5457127094268799\n",
      "Epoch 225, Loss: 0.3047543738503009, Final Batch Loss: 0.0030994017142802477\n",
      "Epoch 226, Loss: 0.4817982017993927, Final Batch Loss: 0.16665057837963104\n",
      "Epoch 227, Loss: 0.33785116294166073, Final Batch Loss: 0.0007475204183720052\n",
      "Epoch 228, Loss: 0.30739658512175083, Final Batch Loss: 0.005887547507882118\n",
      "Epoch 229, Loss: 0.4597090035676956, Final Batch Loss: 0.06866879016160965\n",
      "Epoch 230, Loss: 0.38600718043744564, Final Batch Loss: 0.027611104771494865\n",
      "Epoch 231, Loss: 0.3448332482948899, Final Batch Loss: 0.01107910368591547\n",
      "Epoch 232, Loss: 0.3556177467107773, Final Batch Loss: 0.06393858790397644\n",
      "Epoch 233, Loss: 0.3469748683273792, Final Batch Loss: 0.008465949445962906\n",
      "Epoch 234, Loss: 0.4525180533528328, Final Batch Loss: 0.11636795103549957\n",
      "Epoch 235, Loss: 0.29153712396509945, Final Batch Loss: 0.0015751824248582125\n",
      "Epoch 236, Loss: 0.4447159096598625, Final Batch Loss: 0.1306118667125702\n",
      "Epoch 237, Loss: 0.3435220312967431, Final Batch Loss: 0.0002847504511009902\n",
      "Epoch 238, Loss: 0.30327785201370716, Final Batch Loss: 0.008058534935116768\n",
      "Epoch 239, Loss: 0.2956599108874798, Final Batch Loss: 0.012593742460012436\n",
      "Epoch 240, Loss: 0.3214378015836701, Final Batch Loss: 0.001527096494100988\n",
      "Epoch 241, Loss: 0.2920206186536234, Final Batch Loss: 0.0002451834443490952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242, Loss: 0.3219840005040169, Final Batch Loss: 0.02616121619939804\n",
      "Epoch 243, Loss: 0.3664289303123951, Final Batch Loss: 0.05270138010382652\n",
      "Epoch 244, Loss: 0.2888956156093627, Final Batch Loss: 0.0007508557755500078\n",
      "Epoch 245, Loss: 0.30688963062129915, Final Batch Loss: 0.0016374287661165\n",
      "Epoch 246, Loss: 0.3440200686454773, Final Batch Loss: 0.06379096210002899\n",
      "Epoch 247, Loss: 0.29563168389722705, Final Batch Loss: 0.00453467620536685\n",
      "Epoch 248, Loss: 0.30642257793806493, Final Batch Loss: 0.003742834320291877\n",
      "Epoch 249, Loss: 0.3025062996894121, Final Batch Loss: 0.017730897292494774\n",
      "Epoch 250, Loss: 0.328701376914978, Final Batch Loss: 0.008133858442306519\n",
      "Epoch 251, Loss: 0.4488726481795311, Final Batch Loss: 0.1483456790447235\n",
      "Epoch 252, Loss: 0.31199186434969306, Final Batch Loss: 0.002075543161481619\n",
      "Epoch 253, Loss: 0.2609716388396919, Final Batch Loss: 0.0030122878961265087\n",
      "Epoch 254, Loss: 0.24791712185833603, Final Batch Loss: 0.0014855550834909081\n",
      "Epoch 255, Loss: 0.28352304454892874, Final Batch Loss: 0.004824663512408733\n",
      "Epoch 256, Loss: 0.27046129608061165, Final Batch Loss: 0.0017185931792482734\n",
      "Epoch 257, Loss: 0.43800409883260727, Final Batch Loss: 0.16681787371635437\n",
      "Epoch 258, Loss: 0.25776780024170876, Final Batch Loss: 0.015455592423677444\n",
      "Epoch 259, Loss: 0.285907041747123, Final Batch Loss: 0.005305614788085222\n",
      "Epoch 260, Loss: 0.2934399680234492, Final Batch Loss: 0.0002498314715921879\n",
      "Epoch 261, Loss: 0.3280049776658416, Final Batch Loss: 0.013846530579030514\n",
      "Epoch 262, Loss: 0.2837556264712475, Final Batch Loss: 0.00039569655200466514\n",
      "Epoch 263, Loss: 0.3011966706253588, Final Batch Loss: 0.001465438399463892\n",
      "Epoch 264, Loss: 0.28610455617308617, Final Batch Loss: 0.016710545867681503\n",
      "Epoch 265, Loss: 0.4193960055708885, Final Batch Loss: 0.11149437725543976\n",
      "Epoch 266, Loss: 0.8635673373937607, Final Batch Loss: 0.5773483514785767\n",
      "Epoch 267, Loss: 0.27470970898866653, Final Batch Loss: 0.05315781757235527\n",
      "Epoch 268, Loss: 0.30553785589290783, Final Batch Loss: 0.00038914260221645236\n",
      "Epoch 269, Loss: 0.3259991981467465, Final Batch Loss: 0.00013886917440686375\n",
      "Epoch 270, Loss: 0.32933733332902193, Final Batch Loss: 0.015051250346004963\n",
      "Epoch 271, Loss: 0.37509649293497205, Final Batch Loss: 0.0052655343897640705\n",
      "Epoch 272, Loss: 0.39633112912997603, Final Batch Loss: 0.0017271614633500576\n",
      "Epoch 273, Loss: 0.3975868336856365, Final Batch Loss: 0.05336827412247658\n",
      "Epoch 274, Loss: 0.29526797076687217, Final Batch Loss: 0.007753515150398016\n",
      "Epoch 275, Loss: 0.40733762830495834, Final Batch Loss: 0.08081921190023422\n",
      "Epoch 276, Loss: 0.2988592928741127, Final Batch Loss: 0.00108624086715281\n",
      "Epoch 277, Loss: 0.2554281624034047, Final Batch Loss: 0.0007462101057171822\n",
      "Epoch 278, Loss: 0.30990247428417206, Final Batch Loss: 0.0501471608877182\n",
      "Epoch 279, Loss: 0.3283550441265106, Final Batch Loss: 0.07978940010070801\n",
      "Epoch 280, Loss: 2.304449677467346, Final Batch Loss: 2.066694736480713\n",
      "Epoch 281, Loss: 0.3419565036892891, Final Batch Loss: 0.038830533623695374\n",
      "Epoch 282, Loss: 0.29289107176009566, Final Batch Loss: 0.0006773561472073197\n",
      "Epoch 283, Loss: 0.4266542661935091, Final Batch Loss: 0.022105136886239052\n",
      "Epoch 284, Loss: 0.3746380646189209, Final Batch Loss: 0.00021646064124070108\n",
      "Epoch 285, Loss: 0.39342377078719437, Final Batch Loss: 0.00266304356046021\n",
      "Epoch 286, Loss: 0.34776693338062614, Final Batch Loss: 0.0018399705877527595\n",
      "Epoch 287, Loss: 0.32898311177268624, Final Batch Loss: 0.007764397654682398\n",
      "Epoch 288, Loss: 0.36190151050686836, Final Batch Loss: 0.060927171260118484\n",
      "Epoch 289, Loss: 0.4924752712249756, Final Batch Loss: 0.204112708568573\n",
      "Epoch 290, Loss: 0.318277939921245, Final Batch Loss: 0.0029130426701158285\n",
      "Epoch 291, Loss: 0.310327596096613, Final Batch Loss: 4.160317621426657e-05\n",
      "Epoch 292, Loss: 0.7034015133976936, Final Batch Loss: 0.44551584124565125\n",
      "Epoch 293, Loss: 0.2554348222911358, Final Batch Loss: 0.011889073997735977\n",
      "Epoch 294, Loss: 0.7415973246097565, Final Batch Loss: 0.4325290322303772\n",
      "Epoch 295, Loss: 0.2934337480292015, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 296, Loss: 0.27797103207558393, Final Batch Loss: 0.011879178695380688\n",
      "Epoch 297, Loss: 1.0319621339440346, Final Batch Loss: 0.736105740070343\n",
      "Epoch 298, Loss: 0.2167494412715314, Final Batch Loss: 0.00017033556650858372\n",
      "Epoch 299, Loss: 0.2649175067199394, Final Batch Loss: 0.000898077036254108\n",
      "Epoch 300, Loss: 0.27180871267046314, Final Batch Loss: 4.482168878894299e-05\n",
      "Epoch 301, Loss: 0.30994061566889286, Final Batch Loss: 0.016332747414708138\n",
      "Epoch 302, Loss: 0.30843296903185546, Final Batch Loss: 0.0025056179147213697\n",
      "Epoch 303, Loss: 0.22674893845396582, Final Batch Loss: 0.00017915551143232733\n",
      "Epoch 304, Loss: 0.26501321786145127, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 305, Loss: 0.2717544068582356, Final Batch Loss: 0.00670409994199872\n",
      "Epoch 306, Loss: 1.6572461687028408, Final Batch Loss: 1.4227373600006104\n",
      "Epoch 307, Loss: 0.6677724868059158, Final Batch Loss: 0.41324764490127563\n",
      "Epoch 308, Loss: 0.31837671514222166, Final Batch Loss: 9.810443589231e-05\n",
      "Epoch 309, Loss: 0.27660157589707524, Final Batch Loss: 0.0008794969180598855\n",
      "Epoch 310, Loss: 0.26750382827594876, Final Batch Loss: 0.0010351543314754963\n",
      "Epoch 311, Loss: 0.25712819304317236, Final Batch Loss: 0.003534025512635708\n",
      "Epoch 312, Loss: 0.43924520909786224, Final Batch Loss: 0.23129940032958984\n",
      "Epoch 313, Loss: 0.3008228912949562, Final Batch Loss: 0.004271194338798523\n",
      "Epoch 314, Loss: 0.32201709927176125, Final Batch Loss: 0.0002302858338225633\n",
      "Epoch 315, Loss: 0.23496205944684334, Final Batch Loss: 0.00023529145983047783\n",
      "Epoch 316, Loss: 2.079665943980217, Final Batch Loss: 1.7954604625701904\n",
      "Epoch 317, Loss: 0.21609206170978723, Final Batch Loss: 0.00011824862303910777\n",
      "Epoch 318, Loss: 0.35714179277420044, Final Batch Loss: 0.009457901120185852\n",
      "Epoch 319, Loss: 0.4861244559288025, Final Batch Loss: 0.011863157153129578\n",
      "Epoch 320, Loss: 0.5216043265536427, Final Batch Loss: 0.0006148116663098335\n",
      "Epoch 321, Loss: 0.5378849767148495, Final Batch Loss: 0.01646197959780693\n",
      "Epoch 322, Loss: 0.751785159111023, Final Batch Loss: 0.27591848373413086\n",
      "Epoch 323, Loss: 0.44527161959558725, Final Batch Loss: 0.009952091611921787\n",
      "Epoch 324, Loss: 0.7066950350999832, Final Batch Loss: 0.37487319111824036\n",
      "Epoch 325, Loss: 0.3317422792315483, Final Batch Loss: 0.04870780557394028\n",
      "Epoch 326, Loss: 0.35412128269672394, Final Batch Loss: 0.06799443066120148\n",
      "Epoch 327, Loss: 0.2423313269391656, Final Batch Loss: 0.005121682770550251\n",
      "Epoch 328, Loss: 0.23363395583146485, Final Batch Loss: 6.282132380874828e-05\n",
      "Epoch 329, Loss: 0.2279407803725917, Final Batch Loss: 0.00045408427831716835\n",
      "Epoch 330, Loss: 0.26277766842395067, Final Batch Loss: 0.011547629721462727\n",
      "Epoch 331, Loss: 0.27946820482611656, Final Batch Loss: 0.03295336291193962\n",
      "Epoch 332, Loss: 0.42946650832891464, Final Batch Loss: 0.14385391771793365\n",
      "Epoch 333, Loss: 0.45210495963692665, Final Batch Loss: 0.1696687787771225\n",
      "Epoch 334, Loss: 0.2734486721456051, Final Batch Loss: 0.0277712382376194\n",
      "Epoch 335, Loss: 0.276873528258875, Final Batch Loss: 0.0004897110629826784\n",
      "Epoch 336, Loss: 0.27041293820366263, Final Batch Loss: 0.0010869554243981838\n",
      "Epoch 337, Loss: 0.294555701315403, Final Batch Loss: 0.0015291199088096619\n",
      "Epoch 338, Loss: 0.20932737295879633, Final Batch Loss: 3.731181277544238e-05\n",
      "Epoch 339, Loss: 0.23607708257623017, Final Batch Loss: 7.152301259338856e-05\n",
      "Epoch 340, Loss: 0.2552062227623537, Final Batch Loss: 0.0004974558250978589\n",
      "Epoch 341, Loss: 0.30321262031793594, Final Batch Loss: 0.03753266856074333\n",
      "Epoch 342, Loss: 0.24149362437310629, Final Batch Loss: 0.00018952481332235038\n",
      "Epoch 343, Loss: 0.28082970902323723, Final Batch Loss: 0.07993126660585403\n",
      "Epoch 344, Loss: 0.5564431250095367, Final Batch Loss: 0.28775620460510254\n",
      "Epoch 345, Loss: 0.2078889813274145, Final Batch Loss: 0.0007499027997255325\n",
      "Epoch 346, Loss: 0.279784235637635, Final Batch Loss: 0.0020146328024566174\n",
      "Epoch 347, Loss: 0.2610235168831423, Final Batch Loss: 0.00015484087634831667\n",
      "Epoch 348, Loss: 0.2592254764167592, Final Batch Loss: 0.001536499592475593\n",
      "Epoch 349, Loss: 0.2789228782057762, Final Batch Loss: 0.052343275398015976\n",
      "Epoch 350, Loss: 0.24194367774180137, Final Batch Loss: 0.00016234986833296716\n",
      "Epoch 351, Loss: 0.21861996897496283, Final Batch Loss: 0.0010389650706201792\n",
      "Epoch 352, Loss: 0.320943396538496, Final Batch Loss: 0.10630007833242416\n",
      "Epoch 353, Loss: 0.2826866649556905, Final Batch Loss: 0.0038210966158658266\n",
      "Epoch 354, Loss: 0.2241516333670006, Final Batch Loss: 2.5033637939486653e-05\n",
      "Epoch 355, Loss: 0.2588820453020162, Final Batch Loss: 2.9801878554280847e-05\n",
      "Epoch 356, Loss: 0.2459917962551117, Final Batch Loss: 0.018747635185718536\n",
      "Epoch 357, Loss: 0.2786455322057009, Final Batch Loss: 0.022704878821969032\n",
      "Epoch 358, Loss: 0.2993767559528351, Final Batch Loss: 0.03345925360918045\n",
      "Epoch 359, Loss: 0.2591807518620044, Final Batch Loss: 0.00018690270371735096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360, Loss: 0.37831997126340866, Final Batch Loss: 0.18254320323467255\n",
      "Epoch 361, Loss: 0.2559818085283041, Final Batch Loss: 0.027572372928261757\n",
      "Epoch 362, Loss: 0.25205791737698746, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 363, Loss: 0.270680001238361, Final Batch Loss: 0.00279357866384089\n",
      "Epoch 364, Loss: 0.19401853493764065, Final Batch Loss: 0.00035696811391972005\n",
      "Epoch 365, Loss: 0.237162932656247, Final Batch Loss: 1.3947389561508317e-05\n",
      "Epoch 366, Loss: 0.22415489983541192, Final Batch Loss: 9.643566590966657e-05\n",
      "Epoch 367, Loss: 0.21526717639062554, Final Batch Loss: 0.0005274811992421746\n",
      "Epoch 368, Loss: 0.22458127047866583, Final Batch Loss: 0.010489686392247677\n",
      "Epoch 369, Loss: 0.26798414811491966, Final Batch Loss: 0.03520386293530464\n",
      "Epoch 370, Loss: 0.9511478170752525, Final Batch Loss: 0.7250995635986328\n",
      "Epoch 371, Loss: 0.2147818819139502, Final Batch Loss: 6.615896563744172e-05\n",
      "Epoch 372, Loss: 0.3960597049444914, Final Batch Loss: 0.018527893349528313\n",
      "Epoch 373, Loss: 0.4732676985731814, Final Batch Loss: 0.00016199229867197573\n",
      "Epoch 374, Loss: 0.5029581627568405, Final Batch Loss: 4.1483970562694594e-05\n",
      "Epoch 375, Loss: 0.4749224622210022, Final Batch Loss: 0.0002485204895492643\n",
      "Epoch 376, Loss: 0.5453997850418091, Final Batch Loss: 0.22373884916305542\n",
      "Epoch 377, Loss: 0.2993908905191347, Final Batch Loss: 0.0018096276326104999\n",
      "Epoch 378, Loss: 0.2841522261442151, Final Batch Loss: 0.0003620922507252544\n",
      "Epoch 379, Loss: 0.3894069269299507, Final Batch Loss: 0.17955021560192108\n",
      "Epoch 380, Loss: 0.24740380747243762, Final Batch Loss: 0.002612869720906019\n",
      "Epoch 381, Loss: 0.22012307029217482, Final Batch Loss: 0.002198542468249798\n",
      "Epoch 382, Loss: 0.2922825254499912, Final Batch Loss: 0.021101612597703934\n",
      "Epoch 383, Loss: 0.2388696987181902, Final Batch Loss: 0.028153663501143456\n",
      "Epoch 384, Loss: 0.23404843779280782, Final Batch Loss: 0.005319606978446245\n",
      "Epoch 385, Loss: 0.22130800968716358, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 386, Loss: 0.2736665363772772, Final Batch Loss: 0.000418575422372669\n",
      "Epoch 387, Loss: 0.23550922144204378, Final Batch Loss: 0.0012287693098187447\n",
      "Epoch 388, Loss: 0.2521329037845135, Final Batch Loss: 0.05149443820118904\n",
      "Epoch 389, Loss: 0.2797455827239901, Final Batch Loss: 0.0017428698483854532\n",
      "Epoch 390, Loss: 0.22816949858679436, Final Batch Loss: 0.0002674698771443218\n",
      "Epoch 391, Loss: 0.2644786275923252, Final Batch Loss: 0.06514222174882889\n",
      "Epoch 392, Loss: 0.4996168129146099, Final Batch Loss: 0.27763113379478455\n",
      "Epoch 393, Loss: 0.24940391637937864, Final Batch Loss: 8.535020606359467e-05\n",
      "Epoch 394, Loss: 0.18112608906812966, Final Batch Loss: 0.00219164346344769\n",
      "Epoch 395, Loss: 0.2501397464329784, Final Batch Loss: 2.7656173188006505e-05\n",
      "Epoch 396, Loss: 0.24816139455651864, Final Batch Loss: 0.0004949536523781717\n",
      "Epoch 397, Loss: 0.19958005473017693, Final Batch Loss: 0.003936875611543655\n",
      "Epoch 398, Loss: 0.24097418071323773, Final Batch Loss: 8.260862523457035e-05\n",
      "Epoch 399, Loss: 0.23866367246955633, Final Batch Loss: 0.014844554476439953\n",
      "Epoch 400, Loss: 0.2551444359123707, Final Batch Loss: 0.05956289917230606\n",
      "Epoch 401, Loss: 0.2184999557211995, Final Batch Loss: 0.013104152865707874\n",
      "Epoch 402, Loss: 0.2254914043005556, Final Batch Loss: 0.0026198846753686666\n",
      "Epoch 403, Loss: 0.29188840091228485, Final Batch Loss: 0.053615741431713104\n",
      "Epoch 404, Loss: 0.21563753113150597, Final Batch Loss: 0.01032688096165657\n",
      "Epoch 405, Loss: 0.2320598093792796, Final Batch Loss: 0.008438053540885448\n",
      "Epoch 406, Loss: 0.2337609026581049, Final Batch Loss: 0.014979733154177666\n",
      "Epoch 407, Loss: 0.2448402550071478, Final Batch Loss: 0.01311168260872364\n",
      "Epoch 408, Loss: 0.2529370168922469, Final Batch Loss: 0.0011595914838835597\n",
      "Epoch 409, Loss: 0.2440458599012345, Final Batch Loss: 0.002101714489981532\n",
      "Epoch 410, Loss: 0.2384229712188244, Final Batch Loss: 0.031911835074424744\n",
      "Epoch 411, Loss: 0.23923370981901826, Final Batch Loss: 1.0251946150674485e-05\n",
      "Epoch 412, Loss: 0.23960257694125175, Final Batch Loss: 0.008547980338335037\n",
      "Epoch 413, Loss: 0.2395944558084011, Final Batch Loss: 0.026391245424747467\n",
      "Epoch 414, Loss: 0.3434120714664459, Final Batch Loss: 0.13989314436912537\n",
      "Epoch 415, Loss: 0.2586434985496453, Final Batch Loss: 6.258291978156194e-05\n",
      "Epoch 416, Loss: 0.2322100987403246, Final Batch Loss: 4.3748852476710454e-05\n",
      "Epoch 417, Loss: 0.38899271935224533, Final Batch Loss: 0.09921879321336746\n",
      "Epoch 418, Loss: 0.2039125425799284, Final Batch Loss: 3.325883881188929e-05\n",
      "Epoch 419, Loss: 0.20420578117136756, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 420, Loss: 0.22177365960669704, Final Batch Loss: 0.0003912875254172832\n",
      "Epoch 421, Loss: 0.23568707425147295, Final Batch Loss: 0.0017867805436253548\n",
      "Epoch 422, Loss: 0.23089834675192833, Final Batch Loss: 0.008836451917886734\n",
      "Epoch 423, Loss: 0.20883622486144304, Final Batch Loss: 0.006016832776367664\n",
      "Epoch 424, Loss: 0.21196318354122923, Final Batch Loss: 3.564294092939235e-05\n",
      "Epoch 425, Loss: 0.2439524269066169, Final Batch Loss: 8.809178689261898e-05\n",
      "Epoch 426, Loss: 0.2084710246126633, Final Batch Loss: 0.00020144341397099197\n",
      "Epoch 427, Loss: 0.21793657168745995, Final Batch Loss: 0.038990139961242676\n",
      "Epoch 428, Loss: 0.472150519490242, Final Batch Loss: 0.21934960782527924\n",
      "Epoch 429, Loss: 0.23301025829277933, Final Batch Loss: 0.002895094221457839\n",
      "Epoch 430, Loss: 0.1862393593764864, Final Batch Loss: 0.0007456144667230546\n",
      "Epoch 431, Loss: 0.21644258627202362, Final Batch Loss: 0.0010698077967390418\n",
      "Epoch 432, Loss: 0.17416066970326938, Final Batch Loss: 0.0004158347437623888\n",
      "Epoch 433, Loss: 0.19671532651409507, Final Batch Loss: 0.001019792165607214\n",
      "Epoch 434, Loss: 0.2876654155552387, Final Batch Loss: 0.04054142162203789\n",
      "Epoch 435, Loss: 0.2034407127648592, Final Batch Loss: 0.003691764548420906\n",
      "Epoch 436, Loss: 0.39123065769672394, Final Batch Loss: 0.1394030898809433\n",
      "Epoch 437, Loss: 0.5964873507618904, Final Batch Loss: 0.3447079360485077\n",
      "Epoch 438, Loss: 0.263379470910877, Final Batch Loss: 0.006021691020578146\n",
      "Epoch 439, Loss: 0.21235401088779327, Final Batch Loss: 4.351044481154531e-05\n",
      "Epoch 440, Loss: 0.22964052762836218, Final Batch Loss: 0.004499430768191814\n",
      "Epoch 441, Loss: 0.2508865397030604, Final Batch Loss: 9.881961887003854e-05\n",
      "Epoch 442, Loss: 0.20999632187886164, Final Batch Loss: 0.0005220004240982234\n",
      "Epoch 443, Loss: 0.18417942215455696, Final Batch Loss: 0.0007365613128058612\n",
      "Epoch 444, Loss: 0.2142777431399736, Final Batch Loss: 4.8040190449682996e-05\n",
      "Epoch 445, Loss: 0.6427279114723206, Final Batch Loss: 0.392039030790329\n",
      "Epoch 446, Loss: 0.28867487609386444, Final Batch Loss: 0.0855943039059639\n",
      "Epoch 447, Loss: 0.961245022714138, Final Batch Loss: 0.7696459889411926\n",
      "Epoch 448, Loss: 0.2213663742877543, Final Batch Loss: 0.0020553194917738438\n",
      "Epoch 449, Loss: 0.23302549810614437, Final Batch Loss: 0.0011518517276272178\n",
      "Epoch 450, Loss: 0.2530701442155987, Final Batch Loss: 5.709961988031864e-05\n",
      "Epoch 451, Loss: 0.2766440584855445, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 452, Loss: 0.27960230968892574, Final Batch Loss: 0.02569553814828396\n",
      "Epoch 453, Loss: 0.3152551595121622, Final Batch Loss: 0.0041237566620111465\n",
      "Epoch 454, Loss: 0.24400597671046853, Final Batch Loss: 0.006821321789175272\n",
      "Epoch 455, Loss: 0.2375301904976368, Final Batch Loss: 8.630380034446716e-05\n",
      "Epoch 456, Loss: 0.23017184613854624, Final Batch Loss: 0.00031740395934320986\n",
      "Epoch 457, Loss: 0.2653791749035008, Final Batch Loss: 0.0005402297829277813\n",
      "Epoch 458, Loss: 0.25136711448340066, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 459, Loss: 0.34206850826740265, Final Batch Loss: 0.05859280377626419\n",
      "Epoch 460, Loss: 0.23527063569054008, Final Batch Loss: 0.0047418526373803616\n",
      "Epoch 461, Loss: 0.231733896809601, Final Batch Loss: 4.2199197196168825e-05\n",
      "Epoch 462, Loss: 0.2062340847805899, Final Batch Loss: 5.519237674889155e-05\n",
      "Epoch 463, Loss: 0.22306320630013943, Final Batch Loss: 0.010368293151259422\n",
      "Epoch 464, Loss: 0.21891498006880283, Final Batch Loss: 0.0020060669630765915\n",
      "Epoch 465, Loss: 0.30381380021572113, Final Batch Loss: 0.05804120749235153\n",
      "Epoch 466, Loss: 0.20310459728352726, Final Batch Loss: 0.0004632591735571623\n",
      "Epoch 467, Loss: 0.20963748164922436, Final Batch Loss: 1.1801649634435307e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468, Loss: 0.2523161011922639, Final Batch Loss: 0.00032658010604791343\n",
      "Epoch 469, Loss: 0.2188583230599761, Final Batch Loss: 0.007259420119225979\n",
      "Epoch 470, Loss: 0.18027514548157342, Final Batch Loss: 0.0002134810492862016\n",
      "Epoch 471, Loss: 0.26044802367687225, Final Batch Loss: 0.023387879133224487\n",
      "Epoch 472, Loss: 0.23685843497514725, Final Batch Loss: 0.03975147381424904\n",
      "Epoch 473, Loss: 0.2333893571048975, Final Batch Loss: 0.022410938516259193\n",
      "Epoch 474, Loss: 0.21932229015146731, Final Batch Loss: 1.549708758830093e-05\n",
      "Epoch 475, Loss: 0.22372510211425833, Final Batch Loss: 0.00034731553751043975\n",
      "Epoch 476, Loss: 0.3844621889293194, Final Batch Loss: 0.15058661997318268\n",
      "Epoch 477, Loss: 3.790855549275875, Final Batch Loss: 3.601966381072998\n",
      "Epoch 478, Loss: 0.2257873160415329, Final Batch Loss: 0.0007366804056800902\n",
      "Epoch 479, Loss: 0.4747392609715462, Final Batch Loss: 0.04000142216682434\n",
      "Epoch 480, Loss: 0.47004711779300123, Final Batch Loss: 0.0006435230607166886\n",
      "Epoch 481, Loss: 0.5973234064877033, Final Batch Loss: 0.051421407610177994\n",
      "Epoch 482, Loss: 0.5197434285655618, Final Batch Loss: 0.002782047726213932\n",
      "Epoch 483, Loss: 0.5940712317824364, Final Batch Loss: 0.2087063044309616\n",
      "Epoch 484, Loss: 0.2651311536319554, Final Batch Loss: 0.001632430125027895\n",
      "Epoch 485, Loss: 0.2420700069051236, Final Batch Loss: 0.002593132434412837\n",
      "Epoch 486, Loss: 0.20341429952532053, Final Batch Loss: 0.0017951102927327156\n",
      "Epoch 487, Loss: 0.2543143033981323, Final Batch Loss: 0.03195836395025253\n",
      "Epoch 488, Loss: 0.21157846704591066, Final Batch Loss: 0.0015669699059799314\n",
      "Epoch 489, Loss: 0.26266443729400635, Final Batch Loss: 0.06899439543485641\n",
      "Epoch 490, Loss: 0.23017339734360576, Final Batch Loss: 0.002900324296206236\n",
      "Epoch 491, Loss: 0.21623289995477535, Final Batch Loss: 0.00040391870425082743\n",
      "Epoch 492, Loss: 0.24138069991022348, Final Batch Loss: 0.006477550603449345\n",
      "Epoch 493, Loss: 0.22295179925276898, Final Batch Loss: 0.0003672163875307888\n",
      "Epoch 494, Loss: 0.21343995147617534, Final Batch Loss: 0.0005478549865074456\n",
      "Epoch 495, Loss: 0.20628338365349919, Final Batch Loss: 0.0003844952443614602\n",
      "Epoch 496, Loss: 0.20356182067189366, Final Batch Loss: 0.001364015624858439\n",
      "Epoch 497, Loss: 0.204564843676053, Final Batch Loss: 0.0010244365548714995\n",
      "Epoch 498, Loss: 0.22148659185040742, Final Batch Loss: 0.001876142923720181\n",
      "Epoch 499, Loss: 0.18329152278602123, Final Batch Loss: 0.005177067592740059\n",
      "Epoch 500, Loss: 0.23318246565759182, Final Batch Loss: 0.015755103901028633\n",
      "Epoch 501, Loss: 0.23097370564937592, Final Batch Loss: 0.01462489366531372\n",
      "Epoch 502, Loss: 0.18192353031190578, Final Batch Loss: 0.0001656871900195256\n",
      "Epoch 503, Loss: 0.28455835953354836, Final Batch Loss: 0.05764078348875046\n",
      "Epoch 504, Loss: 0.17620691430056468, Final Batch Loss: 0.0006017066189087927\n",
      "Epoch 505, Loss: 0.1969846859574318, Final Batch Loss: 0.005337867885828018\n",
      "Epoch 506, Loss: 0.3780503533780575, Final Batch Loss: 0.1440749317407608\n",
      "Epoch 507, Loss: 0.19817424318171106, Final Batch Loss: 0.0002683041093405336\n",
      "Epoch 508, Loss: 0.23492975812405348, Final Batch Loss: 0.0040525225922465324\n",
      "Epoch 509, Loss: 0.1992840130114928, Final Batch Loss: 0.0007771808886900544\n",
      "Epoch 510, Loss: 0.22870535124093294, Final Batch Loss: 0.00986191350966692\n",
      "Epoch 511, Loss: 0.1747578306531068, Final Batch Loss: 8.797258487902582e-05\n",
      "Epoch 512, Loss: 0.17402121680788696, Final Batch Loss: 0.002060672966763377\n",
      "Epoch 513, Loss: 0.22846202752407407, Final Batch Loss: 0.00010442188795423135\n",
      "Epoch 514, Loss: 1.9869257919490337, Final Batch Loss: 1.7530821561813354\n",
      "Epoch 515, Loss: 0.30581436678767204, Final Batch Loss: 0.0973031297326088\n",
      "Epoch 516, Loss: 0.49302589893341064, Final Batch Loss: 0.21163317561149597\n",
      "Epoch 517, Loss: 0.8089995682239532, Final Batch Loss: 0.4332832992076874\n",
      "Epoch 518, Loss: 0.28840384259819984, Final Batch Loss: 0.025768034160137177\n",
      "Epoch 519, Loss: 0.3291207104921341, Final Batch Loss: 0.1086929589509964\n",
      "Epoch 520, Loss: 0.21652394637931138, Final Batch Loss: 0.00014232576359063387\n",
      "Epoch 521, Loss: 0.1512061561952578, Final Batch Loss: 6.174850568640977e-05\n",
      "Epoch 522, Loss: 0.1900143643724732, Final Batch Loss: 0.0004683827864937484\n",
      "Epoch 523, Loss: 0.191197257488966, Final Batch Loss: 0.016568448394536972\n",
      "Epoch 524, Loss: 0.19032908158260398, Final Batch Loss: 0.00020597243565134704\n",
      "Epoch 525, Loss: 0.17271430371329188, Final Batch Loss: 0.006086386274546385\n",
      "Epoch 526, Loss: 0.16040763584169326, Final Batch Loss: 3.075552376685664e-05\n",
      "Epoch 527, Loss: 0.1747245576698333, Final Batch Loss: 0.0003073934931308031\n",
      "Epoch 528, Loss: 0.18482333421707153, Final Batch Loss: 0.016684051603078842\n",
      "Epoch 529, Loss: 0.2135735813062638, Final Batch Loss: 0.001416156766936183\n",
      "Epoch 530, Loss: 0.1932039000093937, Final Batch Loss: 0.009573973715305328\n",
      "Epoch 531, Loss: 0.22941916435956955, Final Batch Loss: 0.011439800262451172\n",
      "Epoch 532, Loss: 0.1997200419427827, Final Batch Loss: 0.0011593532981351018\n",
      "Epoch 533, Loss: 0.1976835102395853, Final Batch Loss: 7.652943895664066e-05\n",
      "Epoch 534, Loss: 0.1937255623342935, Final Batch Loss: 0.0002774807217065245\n",
      "Epoch 535, Loss: 0.21924152318388224, Final Batch Loss: 0.0037893885746598244\n",
      "Epoch 536, Loss: 0.20573720592074096, Final Batch Loss: 0.003475698409602046\n",
      "Epoch 537, Loss: 0.18361903330696805, Final Batch Loss: 2.1815061700181104e-05\n",
      "Epoch 538, Loss: 0.20250930823385715, Final Batch Loss: 0.011719780042767525\n",
      "Epoch 539, Loss: 0.23325640335679054, Final Batch Loss: 0.03964698687195778\n",
      "Epoch 540, Loss: 0.2109916415065527, Final Batch Loss: 0.009504662826657295\n",
      "Epoch 541, Loss: 0.22602476764586754, Final Batch Loss: 0.0004761277523357421\n",
      "Epoch 542, Loss: 0.21329964883625507, Final Batch Loss: 0.01714984141290188\n",
      "Epoch 543, Loss: 0.1845205894933315, Final Batch Loss: 5.578839045483619e-05\n",
      "Epoch 544, Loss: 0.23750951327383518, Final Batch Loss: 0.02118331380188465\n",
      "Epoch 545, Loss: 0.18773660622537136, Final Batch Loss: 0.004787767305970192\n",
      "Epoch 546, Loss: 0.1584876483248081, Final Batch Loss: 0.0004555141495075077\n",
      "Epoch 547, Loss: 0.20985681749880314, Final Batch Loss: 0.028704268857836723\n",
      "Epoch 548, Loss: 0.1667778958217241, Final Batch Loss: 0.0008344743982888758\n",
      "Epoch 549, Loss: 0.234588123857975, Final Batch Loss: 0.06087624654173851\n",
      "Epoch 550, Loss: 0.2066925149410963, Final Batch Loss: 0.009494507685303688\n",
      "Epoch 551, Loss: 0.2541622966527939, Final Batch Loss: 0.0850159078836441\n",
      "Epoch 552, Loss: 0.14832014124840498, Final Batch Loss: 0.0029513156041502953\n",
      "Epoch 553, Loss: 0.17748897802084684, Final Batch Loss: 0.009424245916306973\n",
      "Epoch 554, Loss: 0.18147770036011934, Final Batch Loss: 0.006787103600800037\n",
      "Epoch 555, Loss: 0.19641654891893268, Final Batch Loss: 0.0011189873330295086\n",
      "Epoch 556, Loss: 0.205388691771077, Final Batch Loss: 8.034383063204587e-05\n",
      "Epoch 557, Loss: 0.20555751389474608, Final Batch Loss: 0.0001227780303452164\n",
      "Epoch 558, Loss: 0.21696997061269485, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 559, Loss: 0.23800464533269405, Final Batch Loss: 0.02363414876163006\n",
      "Epoch 560, Loss: 0.3927994333207607, Final Batch Loss: 0.2126677930355072\n",
      "Epoch 561, Loss: 0.19043076314846985, Final Batch Loss: 0.000129691296024248\n",
      "Epoch 562, Loss: 0.17834692136966623, Final Batch Loss: 0.000284154579276219\n",
      "Epoch 563, Loss: 6.26299386844039, Final Batch Loss: 6.107217311859131\n",
      "Epoch 564, Loss: 0.32321985624730587, Final Batch Loss: 0.1264706701040268\n",
      "Epoch 565, Loss: 0.26107944920659065, Final Batch Loss: 0.058896753937006\n",
      "Epoch 566, Loss: 0.5564044006168842, Final Batch Loss: 0.3103317618370056\n",
      "Epoch 567, Loss: 0.24043415486812592, Final Batch Loss: 0.0011832863092422485\n",
      "Epoch 568, Loss: 0.18990048849082086, Final Batch Loss: 0.0001677133986959234\n",
      "Epoch 569, Loss: 0.20192203612532467, Final Batch Loss: 0.00022265815641731024\n",
      "Epoch 570, Loss: 0.20500782248564065, Final Batch Loss: 0.0012406755704432726\n",
      "Epoch 571, Loss: 0.19744927203282714, Final Batch Loss: 0.005590518470853567\n",
      "Epoch 572, Loss: 0.21368829882703722, Final Batch Loss: 0.0011254174169152975\n",
      "Epoch 573, Loss: 0.19330225135399814, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 574, Loss: 0.222206087782979, Final Batch Loss: 0.022200046107172966\n",
      "Epoch 575, Loss: 0.1653001494705677, Final Batch Loss: 0.016436181962490082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576, Loss: 0.20115364219236653, Final Batch Loss: 4.970903682988137e-05\n",
      "Epoch 577, Loss: 0.19170911278342828, Final Batch Loss: 8.141662692651153e-05\n",
      "Epoch 578, Loss: 0.2051302008330822, Final Batch Loss: 0.004003843292593956\n",
      "Epoch 579, Loss: 0.18035677113221027, Final Batch Loss: 8.177422569133341e-05\n",
      "Epoch 580, Loss: 0.17171957341588495, Final Batch Loss: 6.6756979322235566e-06\n",
      "Epoch 581, Loss: 0.4247330017387867, Final Batch Loss: 0.22003383934497833\n",
      "Epoch 582, Loss: 0.19823509640991688, Final Batch Loss: 0.0348881334066391\n",
      "Epoch 583, Loss: 0.18244521971791983, Final Batch Loss: 0.002747691236436367\n",
      "Epoch 584, Loss: 0.15248009085917147, Final Batch Loss: 4.565611743601039e-05\n",
      "Epoch 585, Loss: 0.2123223878443241, Final Batch Loss: 0.013827484101057053\n",
      "Epoch 586, Loss: 0.17360659246332943, Final Batch Loss: 0.003842472331598401\n",
      "Epoch 587, Loss: 0.1850625589140691, Final Batch Loss: 0.0007479969062842429\n",
      "Epoch 588, Loss: 0.19344172152341343, Final Batch Loss: 0.0004119024670217186\n",
      "Epoch 589, Loss: 0.1619883167441003, Final Batch Loss: 0.0009388091857545078\n",
      "Epoch 590, Loss: 0.18472968880087137, Final Batch Loss: 0.00491731334477663\n",
      "Epoch 591, Loss: 0.17788802925497293, Final Batch Loss: 0.014586360193789005\n",
      "Epoch 592, Loss: 0.1939354229325545, Final Batch Loss: 9.881961887003854e-05\n",
      "Epoch 593, Loss: 0.19607406249269843, Final Batch Loss: 0.002257657703012228\n",
      "Epoch 594, Loss: 0.17534882645122707, Final Batch Loss: 0.003682975424453616\n",
      "Epoch 595, Loss: 0.16061081271618605, Final Batch Loss: 0.00435748603194952\n",
      "Epoch 596, Loss: 0.20521900709718466, Final Batch Loss: 0.01401910837739706\n",
      "Epoch 597, Loss: 0.15720887477800716, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 598, Loss: 0.20953735672628682, Final Batch Loss: 2.706014311115723e-05\n",
      "Epoch 599, Loss: 0.20942808528707246, Final Batch Loss: 5.638440416078083e-05\n",
      "Epoch 600, Loss: 0.13092310819774866, Final Batch Loss: 0.0011375630274415016\n",
      "Epoch 601, Loss: 0.1619173858780414, Final Batch Loss: 0.003100590081885457\n",
      "Epoch 602, Loss: 0.25480082258582115, Final Batch Loss: 0.08715476840734482\n",
      "Epoch 603, Loss: 0.1659739586757496, Final Batch Loss: 0.0012497241841629148\n",
      "Epoch 604, Loss: 0.15919568762058134, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 605, Loss: 0.1848936784081161, Final Batch Loss: 0.0006170752458274364\n",
      "Epoch 606, Loss: 0.2337261427892372, Final Batch Loss: 0.0007923085941001773\n",
      "Epoch 607, Loss: 0.14468677807599306, Final Batch Loss: 0.00839963462203741\n",
      "Epoch 608, Loss: 0.17091278522275388, Final Batch Loss: 0.0023289003875106573\n",
      "Epoch 609, Loss: 0.1655851377563522, Final Batch Loss: 1.7165990357170813e-05\n",
      "Epoch 610, Loss: 0.18095697765238583, Final Batch Loss: 0.0027812153566628695\n",
      "Epoch 611, Loss: 0.21026052720844746, Final Batch Loss: 0.030664263293147087\n",
      "Epoch 612, Loss: 0.21328896237537265, Final Batch Loss: 0.004189524333924055\n",
      "Epoch 613, Loss: 0.19698641439845233, Final Batch Loss: 1.3708974620385561e-05\n",
      "Epoch 614, Loss: 0.1990939825773239, Final Batch Loss: 0.05225763097405434\n",
      "Epoch 615, Loss: 0.1936603523784015, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 616, Loss: 0.22639797627925873, Final Batch Loss: 0.030233178287744522\n",
      "Epoch 617, Loss: 0.2443285621702671, Final Batch Loss: 0.05632159858942032\n",
      "Epoch 618, Loss: 0.19018556736409664, Final Batch Loss: 0.023671520873904228\n",
      "Epoch 619, Loss: 0.1806983724109159, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 620, Loss: 0.21548604778945446, Final Batch Loss: 0.01643829233944416\n",
      "Epoch 621, Loss: 0.28561292588710785, Final Batch Loss: 0.11514583230018616\n",
      "Epoch 622, Loss: 0.19621910626301542, Final Batch Loss: 0.0005086558521725237\n",
      "Epoch 623, Loss: 0.18557079415768385, Final Batch Loss: 0.002568519674241543\n",
      "Epoch 624, Loss: 0.4808562956750393, Final Batch Loss: 0.2833799719810486\n",
      "Epoch 625, Loss: 0.16407274268567562, Final Batch Loss: 0.011562006548047066\n",
      "Epoch 626, Loss: 0.1893240493227495, Final Batch Loss: 6.031808152329177e-05\n",
      "Epoch 627, Loss: 0.1646622166445013, Final Batch Loss: 0.00028355870745144784\n",
      "Epoch 628, Loss: 0.16908019388574758, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 629, Loss: 0.14448329363949597, Final Batch Loss: 0.0011406589765101671\n",
      "Epoch 630, Loss: 0.18975579530524556, Final Batch Loss: 0.00020346954988781363\n",
      "Epoch 631, Loss: 0.2098056972026825, Final Batch Loss: 0.01979910209774971\n",
      "Epoch 632, Loss: 0.16343009378761053, Final Batch Loss: 0.0022078203037381172\n",
      "Epoch 633, Loss: 0.2287092893384397, Final Batch Loss: 0.005913381930440664\n",
      "Epoch 634, Loss: 0.26528025418519974, Final Batch Loss: 0.0746445283293724\n",
      "Epoch 635, Loss: 0.1760549907303357, Final Batch Loss: 4.589452510117553e-05\n",
      "Epoch 636, Loss: 0.21196550875902176, Final Batch Loss: 0.03122677654027939\n",
      "Epoch 637, Loss: 0.19463229086250067, Final Batch Loss: 0.012307177297770977\n",
      "Epoch 638, Loss: 0.17051418288610876, Final Batch Loss: 0.0026481819804757833\n",
      "Epoch 639, Loss: 0.18537690304219723, Final Batch Loss: 0.010424567386507988\n",
      "Epoch 640, Loss: 0.17318478925153613, Final Batch Loss: 0.006333991419523954\n",
      "Epoch 641, Loss: 0.20048645790666342, Final Batch Loss: 0.005812409333884716\n",
      "Epoch 642, Loss: 0.18357592687243596, Final Batch Loss: 0.0007784912013448775\n",
      "Epoch 643, Loss: 0.20897427685122238, Final Batch Loss: 7.223821739898995e-05\n",
      "Epoch 644, Loss: 0.16712951519002672, Final Batch Loss: 0.0001586549769854173\n",
      "Epoch 645, Loss: 0.18187639117240906, Final Batch Loss: 0.013321325182914734\n",
      "Epoch 646, Loss: 0.18380677679670043, Final Batch Loss: 0.0004233417857903987\n",
      "Epoch 647, Loss: 0.1871396868446027, Final Batch Loss: 7.843663479434326e-05\n",
      "Epoch 648, Loss: 0.14135045539842395, Final Batch Loss: 1.9192511899746023e-05\n",
      "Epoch 649, Loss: 0.2552676349878311, Final Batch Loss: 0.09063604474067688\n",
      "Epoch 650, Loss: 0.1489050568197854, Final Batch Loss: 0.0008104139124043286\n",
      "Epoch 651, Loss: 0.18206302437465638, Final Batch Loss: 0.00038628268521279097\n",
      "Epoch 652, Loss: 0.5654636174440384, Final Batch Loss: 0.41297516226768494\n",
      "Epoch 653, Loss: 0.3236512877047062, Final Batch Loss: 0.13127949833869934\n",
      "Epoch 654, Loss: 0.1812688557238289, Final Batch Loss: 2.0265373677830212e-05\n",
      "Epoch 655, Loss: 0.1837539839616511, Final Batch Loss: 0.0003054867556784302\n",
      "Epoch 656, Loss: 0.15949830029603618, Final Batch Loss: 1.4662635294371285e-05\n",
      "Epoch 657, Loss: 0.1752529783625505, Final Batch Loss: 5.018585216021165e-05\n",
      "Epoch 658, Loss: 0.13802242651581764, Final Batch Loss: 0.0015267394483089447\n",
      "Epoch 659, Loss: 0.1811494082212448, Final Batch Loss: 0.009731825441122055\n",
      "Epoch 660, Loss: 0.20019544506794773, Final Batch Loss: 0.00015948931104503572\n",
      "Epoch 661, Loss: 0.931719396263361, Final Batch Loss: 0.7691031694412231\n",
      "Epoch 662, Loss: 0.16334035304316785, Final Batch Loss: 7.950943836476654e-05\n",
      "Epoch 663, Loss: 0.4653577896533534, Final Batch Loss: 0.00023684080224484205\n",
      "Epoch 664, Loss: 0.6303689852356911, Final Batch Loss: 0.09504053741693497\n",
      "Epoch 665, Loss: 0.5458643090678379, Final Batch Loss: 0.0011094611836597323\n",
      "Epoch 666, Loss: 0.2156355744227767, Final Batch Loss: 0.014840326271951199\n",
      "Epoch 667, Loss: 0.17683095764368773, Final Batch Loss: 0.003338123671710491\n",
      "Epoch 668, Loss: 0.1578620239160955, Final Batch Loss: 0.002464830409735441\n",
      "Epoch 669, Loss: 0.2454880252480507, Final Batch Loss: 0.11145374923944473\n",
      "Epoch 670, Loss: 0.19268206635024399, Final Batch Loss: 0.0015380469849333167\n",
      "Epoch 671, Loss: 0.19240028969943523, Final Batch Loss: 0.02826503850519657\n",
      "Epoch 672, Loss: 0.1697677168995142, Final Batch Loss: 0.017562823370099068\n",
      "Epoch 673, Loss: 0.17393787950277328, Final Batch Loss: 0.00906553864479065\n",
      "Epoch 674, Loss: 0.14863406425138237, Final Batch Loss: 3.71926071238704e-05\n",
      "Epoch 675, Loss: 1.1149504948407412, Final Batch Loss: 0.9521838426589966\n",
      "Epoch 676, Loss: 0.1828023111447692, Final Batch Loss: 0.007173496298491955\n",
      "Epoch 677, Loss: 0.22213034250307828, Final Batch Loss: 0.001434250851161778\n",
      "Epoch 678, Loss: 0.2568517848767442, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 679, Loss: 0.28301802632631734, Final Batch Loss: 0.0008588915807195008\n",
      "Epoch 680, Loss: 0.2564913667711153, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 681, Loss: 0.23186270846053958, Final Batch Loss: 0.007275159936398268\n",
      "Epoch 682, Loss: 0.29837558045983315, Final Batch Loss: 0.02198432758450508\n",
      "Epoch 683, Loss: 0.22648344683693722, Final Batch Loss: 0.0006554362480528653\n",
      "Epoch 684, Loss: 0.19698091433383524, Final Batch Loss: 0.00026520551182329655\n",
      "Epoch 685, Loss: 0.2123234262689948, Final Batch Loss: 0.00352559145539999\n",
      "Epoch 686, Loss: 0.18383015293511562, Final Batch Loss: 0.000386640167562291\n",
      "Epoch 687, Loss: 0.2932443358004093, Final Batch Loss: 0.10977312922477722\n",
      "Epoch 688, Loss: 0.20730504393577576, Final Batch Loss: 0.00843970850110054\n",
      "Epoch 689, Loss: 0.17436663786429563, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 690, Loss: 0.3488019220530987, Final Batch Loss: 0.20060142874717712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691, Loss: 0.22133101522922516, Final Batch Loss: 0.06576191633939743\n",
      "Epoch 692, Loss: 0.18999607511796057, Final Batch Loss: 0.0038257280830293894\n",
      "Epoch 693, Loss: 0.2170133872423321, Final Batch Loss: 0.003242237726226449\n",
      "Epoch 694, Loss: 0.23577862977981567, Final Batch Loss: 0.009899213910102844\n",
      "Epoch 695, Loss: 0.21449288073927164, Final Batch Loss: 0.004734852351248264\n",
      "Epoch 696, Loss: 0.21956085111014545, Final Batch Loss: 0.0009485750924795866\n",
      "Epoch 697, Loss: 0.22628946416079998, Final Batch Loss: 0.03098352439701557\n",
      "Epoch 698, Loss: 0.17332619801163673, Final Batch Loss: 0.011610908433794975\n",
      "Epoch 699, Loss: 0.15612206983496435, Final Batch Loss: 8.594620157964528e-05\n",
      "Epoch 700, Loss: 0.18124566800543107, Final Batch Loss: 0.00010430268594063818\n",
      "Epoch 701, Loss: 0.19131772195578378, Final Batch Loss: 2.2172682292875834e-05\n",
      "Epoch 702, Loss: 0.16844584979116917, Final Batch Loss: 0.004758106544613838\n",
      "Epoch 703, Loss: 0.19322544615715742, Final Batch Loss: 0.011554229073226452\n",
      "Epoch 704, Loss: 0.1588537972420454, Final Batch Loss: 0.0017322786152362823\n",
      "Epoch 705, Loss: 0.16458218542811665, Final Batch Loss: 6.198863957251888e-06\n",
      "Epoch 706, Loss: 0.18688109144477494, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 707, Loss: 0.1647511906849104, Final Batch Loss: 8.642300235806033e-05\n",
      "Epoch 708, Loss: 0.14329594373521104, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 709, Loss: 0.13743659285228205, Final Batch Loss: 1.4066597032069694e-05\n",
      "Epoch 710, Loss: 0.1282767122605719, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 711, Loss: 0.138274158234708, Final Batch Loss: 0.0011523280991241336\n",
      "Epoch 712, Loss: 0.1650154665111927, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 713, Loss: 0.15385478181997314, Final Batch Loss: 0.00034505134681239724\n",
      "Epoch 714, Loss: 0.14283844572491944, Final Batch Loss: 0.002041400643065572\n",
      "Epoch 715, Loss: 0.16639448725618422, Final Batch Loss: 0.00017128908075392246\n",
      "Epoch 716, Loss: 0.14917209084524075, Final Batch Loss: 4.494089080253616e-05\n",
      "Epoch 717, Loss: 0.17989359400235116, Final Batch Loss: 0.00259420252405107\n",
      "Epoch 718, Loss: 0.12857253722904716, Final Batch Loss: 0.00011705666838679463\n",
      "Epoch 719, Loss: 0.16660235222661868, Final Batch Loss: 0.0007303669699467719\n",
      "Epoch 720, Loss: 0.17511019157245755, Final Batch Loss: 0.00235958443954587\n",
      "Epoch 721, Loss: 0.12694406855734996, Final Batch Loss: 0.00013839241000823677\n",
      "Epoch 722, Loss: 0.14894057721903664, Final Batch Loss: 4.207999518257566e-05\n",
      "Epoch 723, Loss: 0.17507372290128842, Final Batch Loss: 0.0006977269076742232\n",
      "Epoch 724, Loss: 0.15111447498202324, Final Batch Loss: 0.0018647201359272003\n",
      "Epoch 725, Loss: 0.15229398483643308, Final Batch Loss: 0.00054058717796579\n",
      "Epoch 726, Loss: 0.12878106790594757, Final Batch Loss: 0.0010456338059157133\n",
      "Epoch 727, Loss: 0.20473626255989075, Final Batch Loss: 0.024181894958019257\n",
      "Epoch 728, Loss: 0.18447407335042953, Final Batch Loss: 0.025883043184876442\n",
      "Epoch 729, Loss: 0.10948201463907026, Final Batch Loss: 0.0002586507180240005\n",
      "Epoch 730, Loss: 0.14684997079893947, Final Batch Loss: 0.00026067672297358513\n",
      "Epoch 731, Loss: 0.1612132077698334, Final Batch Loss: 2.098061486321967e-05\n",
      "Epoch 732, Loss: 0.12867941660806537, Final Batch Loss: 0.0023694555275142193\n",
      "Epoch 733, Loss: 0.15462860651314259, Final Batch Loss: 0.014608094468712807\n",
      "Epoch 734, Loss: 0.18648447282612324, Final Batch Loss: 0.02179492451250553\n",
      "Epoch 735, Loss: 0.1754886938506388, Final Batch Loss: 5.745722592109814e-05\n",
      "Epoch 736, Loss: 0.17845498491078615, Final Batch Loss: 0.006055579520761967\n",
      "Epoch 737, Loss: 0.14858279237523675, Final Batch Loss: 0.0021115881390869617\n",
      "Epoch 738, Loss: 0.15903049474582076, Final Batch Loss: 0.0065300180576741695\n",
      "Epoch 739, Loss: 0.15399855840951204, Final Batch Loss: 0.008330714888870716\n",
      "Epoch 740, Loss: 0.17199440859258175, Final Batch Loss: 0.003417130559682846\n",
      "Epoch 741, Loss: 0.16082444041967392, Final Batch Loss: 0.0021415650844573975\n",
      "Epoch 742, Loss: 0.15958890586625785, Final Batch Loss: 0.0010112178279086947\n",
      "Epoch 743, Loss: 0.14577183220535517, Final Batch Loss: 0.013803381472826004\n",
      "Epoch 744, Loss: 0.20509194349870086, Final Batch Loss: 0.004225374665111303\n",
      "Epoch 745, Loss: 0.1814507208764553, Final Batch Loss: 0.05309191346168518\n",
      "Epoch 746, Loss: 0.1292372420407446, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 747, Loss: 0.1877976490650326, Final Batch Loss: 0.0017018134240061045\n",
      "Epoch 748, Loss: 0.1636798456311226, Final Batch Loss: 0.013804204761981964\n",
      "Epoch 749, Loss: 0.22511421144008636, Final Batch Loss: 0.07928890734910965\n",
      "Epoch 750, Loss: 0.14883260638453066, Final Batch Loss: 0.0038984029088169336\n",
      "Epoch 751, Loss: 0.15096321328655904, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 752, Loss: 0.16429745173081756, Final Batch Loss: 0.006399021949619055\n",
      "Epoch 753, Loss: 0.15950491186231375, Final Batch Loss: 0.011309563182294369\n",
      "Epoch 754, Loss: 0.16924062528232753, Final Batch Loss: 2.4199192921514623e-05\n",
      "Epoch 755, Loss: 0.16154344747064897, Final Batch Loss: 1.0371154530730564e-05\n",
      "Epoch 756, Loss: 0.17686669086106122, Final Batch Loss: 0.00248754327185452\n",
      "Epoch 757, Loss: 0.1586800439399667, Final Batch Loss: 0.0009611992281861603\n",
      "Epoch 758, Loss: 0.17973519128281623, Final Batch Loss: 0.001940988120622933\n",
      "Epoch 759, Loss: 0.17574451649852563, Final Batch Loss: 0.00023755589791107923\n",
      "Epoch 760, Loss: 0.1675256527959732, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 761, Loss: 0.16380584298167378, Final Batch Loss: 0.0013558013597503304\n",
      "Epoch 762, Loss: 0.17810730962082744, Final Batch Loss: 0.0017813066951930523\n",
      "Epoch 763, Loss: 0.16803558543321628, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 764, Loss: 0.17067803291138262, Final Batch Loss: 0.001760838902555406\n",
      "Epoch 765, Loss: 0.1650857685599476, Final Batch Loss: 0.003126021707430482\n",
      "Epoch 766, Loss: 0.16391693614423275, Final Batch Loss: 0.011335847899317741\n",
      "Epoch 767, Loss: 0.17205799743533134, Final Batch Loss: 0.017540685832500458\n",
      "Epoch 768, Loss: 0.15720719937235117, Final Batch Loss: 0.0022096047177910805\n",
      "Epoch 769, Loss: 0.1275712966453284, Final Batch Loss: 0.000797192333266139\n",
      "Epoch 770, Loss: 0.1618535495363176, Final Batch Loss: 0.0006719953380525112\n",
      "Epoch 771, Loss: 0.1392637137323618, Final Batch Loss: 0.009563583880662918\n",
      "Epoch 772, Loss: 0.15869836136698012, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 773, Loss: 0.11681868927553296, Final Batch Loss: 0.00037496211007237434\n",
      "Epoch 774, Loss: 0.19287950173020363, Final Batch Loss: 0.02681191824376583\n",
      "Epoch 775, Loss: 0.17503132997080684, Final Batch Loss: 0.004373153205960989\n",
      "Epoch 776, Loss: 0.1841093814728083, Final Batch Loss: 0.00019739109848160297\n",
      "Epoch 777, Loss: 0.14424591604620218, Final Batch Loss: 0.01440377440303564\n",
      "Epoch 778, Loss: 0.15622564756995416, Final Batch Loss: 2.038458114839159e-05\n",
      "Epoch 779, Loss: 0.12809128127992153, Final Batch Loss: 0.01893574558198452\n",
      "Epoch 780, Loss: 0.13975882029626518, Final Batch Loss: 0.0005779979983344674\n",
      "Epoch 781, Loss: 0.25349803641438484, Final Batch Loss: 0.09490209817886353\n",
      "Epoch 782, Loss: 0.14415347133763134, Final Batch Loss: 0.0027611248660832644\n",
      "Epoch 783, Loss: 0.14358881043153815, Final Batch Loss: 0.00033087024348787963\n",
      "Epoch 784, Loss: 0.17687593307346106, Final Batch Loss: 0.00231879111379385\n",
      "Epoch 785, Loss: 0.16999978535750415, Final Batch Loss: 0.00017474555352237076\n",
      "Epoch 786, Loss: 0.11529305577221294, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 787, Loss: 0.1408840510121081, Final Batch Loss: 0.00023672162205912173\n",
      "Epoch 788, Loss: 0.15242507541188388, Final Batch Loss: 5.2927523938706145e-05\n",
      "Epoch 789, Loss: 0.15875344663800206, Final Batch Loss: 7.009260298218578e-05\n",
      "Epoch 790, Loss: 0.18619654513895512, Final Batch Loss: 0.0063628945499658585\n",
      "Epoch 791, Loss: 0.15722805680707097, Final Batch Loss: 0.006601667497307062\n",
      "Epoch 792, Loss: 0.16394535079597716, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 793, Loss: 0.13361202059604693, Final Batch Loss: 6.544376083184034e-05\n",
      "Epoch 794, Loss: 0.13181295432150364, Final Batch Loss: 0.008038194850087166\n",
      "Epoch 795, Loss: 0.1693235262810049, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 796, Loss: 0.13808702770620584, Final Batch Loss: 0.0006958208978176117\n",
      "Epoch 797, Loss: 0.1548909466364421, Final Batch Loss: 0.000518664310220629\n",
      "Epoch 798, Loss: 0.139803237747401, Final Batch Loss: 0.0012847273610532284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799, Loss: 3.0300488360226154, Final Batch Loss: 2.838724374771118\n",
      "Epoch 800, Loss: 0.1747806966304779, Final Batch Loss: 0.023203516378998756\n",
      "Epoch 801, Loss: 0.29658615522566834, Final Batch Loss: 3.6477376852417365e-05\n",
      "Epoch 802, Loss: 0.33050944947171956, Final Batch Loss: 0.0004502712981775403\n",
      "Epoch 803, Loss: 0.31962015814497136, Final Batch Loss: 9.059495641849935e-05\n",
      "Epoch 804, Loss: 0.36326267663389444, Final Batch Loss: 0.007707499898970127\n",
      "Epoch 805, Loss: 0.29851839496404864, Final Batch Loss: 6.246371776796877e-05\n",
      "Epoch 806, Loss: 0.27616204880177975, Final Batch Loss: 0.013213803991675377\n",
      "Epoch 807, Loss: 0.19374073832295835, Final Batch Loss: 0.0007250064518302679\n",
      "Epoch 808, Loss: 0.23934025689959526, Final Batch Loss: 0.032971933484077454\n",
      "Epoch 809, Loss: 0.20852990448474884, Final Batch Loss: 0.03092828020453453\n",
      "Epoch 810, Loss: 0.12903149323756224, Final Batch Loss: 4.51792984677013e-05\n",
      "Epoch 811, Loss: 0.13367424334865063, Final Batch Loss: 0.0010266992030665278\n",
      "Epoch 812, Loss: 0.19036354700801894, Final Batch Loss: 0.0006598440813831985\n",
      "Epoch 813, Loss: 0.1616555592045188, Final Batch Loss: 0.017115037888288498\n",
      "Epoch 814, Loss: 0.12004434304071765, Final Batch Loss: 1.6331539882230572e-05\n",
      "Epoch 815, Loss: 0.15994563971253228, Final Batch Loss: 4.470248313737102e-05\n",
      "Epoch 816, Loss: 0.14435523306019604, Final Batch Loss: 0.0032408118713647127\n",
      "Epoch 817, Loss: 0.16675678081810474, Final Batch Loss: 0.01906662993133068\n",
      "Epoch 818, Loss: 0.14070358918979764, Final Batch Loss: 0.004276654217392206\n",
      "Epoch 819, Loss: 0.14493187534390017, Final Batch Loss: 0.0001821352052502334\n",
      "Epoch 820, Loss: 0.13180127867963165, Final Batch Loss: 0.0009958551963791251\n",
      "Epoch 821, Loss: 0.1571384161070455, Final Batch Loss: 0.0001641377166379243\n",
      "Epoch 822, Loss: 0.1549008820875315, Final Batch Loss: 0.0001515035255579278\n",
      "Epoch 823, Loss: 0.14782069786451757, Final Batch Loss: 0.003178665181621909\n",
      "Epoch 824, Loss: 0.14940382732311264, Final Batch Loss: 0.00020215852418914437\n",
      "Epoch 825, Loss: 0.15800726489396766, Final Batch Loss: 0.0001567479339428246\n",
      "Epoch 826, Loss: 0.15007317287381738, Final Batch Loss: 0.0011703077470883727\n",
      "Epoch 827, Loss: 0.13602300372440368, Final Batch Loss: 0.0013072286965325475\n",
      "Epoch 828, Loss: 0.13578559644520283, Final Batch Loss: 0.011172119528055191\n",
      "Epoch 829, Loss: 0.13601574720814824, Final Batch Loss: 0.005749237257987261\n",
      "Epoch 830, Loss: 0.20197219215333462, Final Batch Loss: 0.06167759746313095\n",
      "Epoch 831, Loss: 0.13466985034756362, Final Batch Loss: 0.0038202654104679823\n",
      "Epoch 832, Loss: 0.12838101893430576, Final Batch Loss: 0.0007774191326461732\n",
      "Epoch 833, Loss: 0.2350366935133934, Final Batch Loss: 0.07770674675703049\n",
      "Epoch 834, Loss: 0.1632914608308056, Final Batch Loss: 4.327203714638017e-05\n",
      "Epoch 835, Loss: 0.12695953622460365, Final Batch Loss: 0.02247038669884205\n",
      "Epoch 836, Loss: 0.15013888850808144, Final Batch Loss: 0.049324940890073776\n",
      "Epoch 837, Loss: 0.15742610332381446, Final Batch Loss: 3.540453326422721e-05\n",
      "Epoch 838, Loss: 0.210328359156847, Final Batch Loss: 0.0476556234061718\n",
      "Epoch 839, Loss: 0.17633214084344218, Final Batch Loss: 0.00010084597306558862\n",
      "Epoch 840, Loss: 0.14128700050059706, Final Batch Loss: 0.0007503792876377702\n",
      "Epoch 841, Loss: 0.10190529513783986, Final Batch Loss: 3.123234637314454e-05\n",
      "Epoch 842, Loss: 0.1517680361866951, Final Batch Loss: 0.032972048968076706\n",
      "Epoch 843, Loss: 0.14253866844774166, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 844, Loss: 0.12546955045399955, Final Batch Loss: 4.3987260141875595e-05\n",
      "Epoch 845, Loss: 0.132211179821752, Final Batch Loss: 0.0001110968878492713\n",
      "Epoch 846, Loss: 0.15504977072123438, Final Batch Loss: 0.001035987981595099\n",
      "Epoch 847, Loss: 0.15451304177986458, Final Batch Loss: 0.0008594871615059674\n",
      "Epoch 848, Loss: 0.14197900984436274, Final Batch Loss: 0.0016771787777543068\n",
      "Epoch 849, Loss: 0.15378054208122194, Final Batch Loss: 0.0011787617113441229\n",
      "Epoch 850, Loss: 0.14384918471569108, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 851, Loss: 0.12643354572355747, Final Batch Loss: 0.00946439616382122\n",
      "Epoch 852, Loss: 0.13271591253578663, Final Batch Loss: 0.001578276976943016\n",
      "Epoch 853, Loss: 6.055658692494035, Final Batch Loss: 5.948925495147705\n",
      "Epoch 854, Loss: 0.16925223224097863, Final Batch Loss: 0.0003748429589904845\n",
      "Epoch 855, Loss: 0.18856829963624477, Final Batch Loss: 0.01815967820584774\n",
      "Epoch 856, Loss: 0.22701259143650532, Final Batch Loss: 0.026030907407402992\n",
      "Epoch 857, Loss: 0.21967507526278496, Final Batch Loss: 0.03930503502488136\n",
      "Epoch 858, Loss: 0.1924045216292143, Final Batch Loss: 0.01736004464328289\n",
      "Epoch 859, Loss: 0.18096648203209043, Final Batch Loss: 0.002576724160462618\n",
      "Epoch 860, Loss: 0.25109188072383404, Final Batch Loss: 0.08584289997816086\n",
      "Epoch 861, Loss: 0.1697364579886198, Final Batch Loss: 0.02700188383460045\n",
      "Epoch 862, Loss: 0.14817330241203308, Final Batch Loss: 0.012595508247613907\n",
      "Epoch 863, Loss: 0.12608468090184033, Final Batch Loss: 0.0015368566382676363\n",
      "Epoch 864, Loss: 0.20156461000442505, Final Batch Loss: 0.04878194257616997\n",
      "Epoch 865, Loss: 0.12048242505989037, Final Batch Loss: 0.00032050241134129465\n",
      "Epoch 866, Loss: 0.14548504375852644, Final Batch Loss: 0.0020198675338178873\n",
      "Epoch 867, Loss: 0.10222319327294827, Final Batch Loss: 0.003630833700299263\n",
      "Epoch 868, Loss: 0.19501904770731926, Final Batch Loss: 0.0576372966170311\n",
      "Epoch 869, Loss: 0.1350737139582634, Final Batch Loss: 0.024860166013240814\n",
      "Epoch 870, Loss: 0.13208746351028822, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 871, Loss: 0.15695558849256486, Final Batch Loss: 0.0013942531077191234\n",
      "Epoch 872, Loss: 0.12398381260572933, Final Batch Loss: 0.00034231049357913435\n",
      "Epoch 873, Loss: 0.19828123971819878, Final Batch Loss: 0.057674992829561234\n",
      "Epoch 874, Loss: 0.14422130957200352, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 875, Loss: 0.1422551292926073, Final Batch Loss: 0.009212249889969826\n",
      "Epoch 876, Loss: 0.12321113632060587, Final Batch Loss: 0.001536261523142457\n",
      "Epoch 877, Loss: 0.11409002319851425, Final Batch Loss: 0.00010907054820563644\n",
      "Epoch 878, Loss: 0.14009822672232985, Final Batch Loss: 0.0067458986304700375\n",
      "Epoch 879, Loss: 0.15049781173001975, Final Batch Loss: 0.000276765669696033\n",
      "Epoch 880, Loss: 0.1379846604540944, Final Batch Loss: 0.008211896754801273\n",
      "Epoch 881, Loss: 0.10971000316203572, Final Batch Loss: 0.00037889453233219683\n",
      "Epoch 882, Loss: 0.13741795657551847, Final Batch Loss: 0.0004661188868340105\n",
      "Epoch 883, Loss: 0.15459866309538484, Final Batch Loss: 0.00751075753942132\n",
      "Epoch 884, Loss: 0.12181530333930368, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 885, Loss: 0.13330135121941566, Final Batch Loss: 0.018524616956710815\n",
      "Epoch 886, Loss: 0.1383462529629469, Final Batch Loss: 0.009313942864537239\n",
      "Epoch 887, Loss: 0.13075114268576726, Final Batch Loss: 0.00010179955279454589\n",
      "Epoch 888, Loss: 0.14292487362399697, Final Batch Loss: 0.0023963325656950474\n",
      "Epoch 889, Loss: 0.13717443286441267, Final Batch Loss: 0.00275827175937593\n",
      "Epoch 890, Loss: 0.18804766424000263, Final Batch Loss: 0.05881908908486366\n",
      "Epoch 891, Loss: 0.15513996640220284, Final Batch Loss: 0.006251542363315821\n",
      "Epoch 892, Loss: 0.11908970569493249, Final Batch Loss: 0.0003457663697190583\n",
      "Epoch 893, Loss: 0.14780188852455467, Final Batch Loss: 0.001110771088860929\n",
      "Epoch 894, Loss: 0.40150849148631096, Final Batch Loss: 0.2715413570404053\n",
      "Epoch 895, Loss: 0.11693820706568658, Final Batch Loss: 0.0003768687602132559\n",
      "Epoch 896, Loss: 0.14739418772023782, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 897, Loss: 0.19869743788149208, Final Batch Loss: 0.0009078433504328132\n",
      "Epoch 898, Loss: 0.17118235537782311, Final Batch Loss: 0.006790774408727884\n",
      "Epoch 899, Loss: 0.12059974853218591, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 900, Loss: 0.11991759190823359, Final Batch Loss: 1.585470999998506e-05\n",
      "Epoch 901, Loss: 0.16585146472789347, Final Batch Loss: 0.003688676515594125\n",
      "Epoch 902, Loss: 0.15683775953948498, Final Batch Loss: 0.022670501843094826\n",
      "Epoch 903, Loss: 0.1781107559800148, Final Batch Loss: 0.06086839735507965\n",
      "Epoch 904, Loss: 0.14549980318406597, Final Batch Loss: 0.0006162413046695292\n",
      "Epoch 905, Loss: 0.12849731591995806, Final Batch Loss: 0.0007085673278197646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 906, Loss: 0.13048758590593934, Final Batch Loss: 0.00378606328740716\n",
      "Epoch 907, Loss: 0.1277298070190227, Final Batch Loss: 7.748573807475623e-06\n",
      "Epoch 908, Loss: 0.15120144514366984, Final Batch Loss: 0.005132119636982679\n",
      "Epoch 909, Loss: 0.123823140776949, Final Batch Loss: 0.0003081085451412946\n",
      "Epoch 910, Loss: 1.6401919983327389, Final Batch Loss: 1.5232115983963013\n",
      "Epoch 911, Loss: 0.15787139408348594, Final Batch Loss: 0.00018988236843142658\n",
      "Epoch 912, Loss: 0.35275596007704735, Final Batch Loss: 0.12225771695375443\n",
      "Epoch 913, Loss: 0.32412714484598837, Final Batch Loss: 2.3007127310847864e-05\n",
      "Epoch 914, Loss: 0.33241759867814835, Final Batch Loss: 4.851700214203447e-05\n",
      "Epoch 915, Loss: 0.3024104237555889, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 916, Loss: 0.282586274901405, Final Batch Loss: 0.000506511190906167\n",
      "Epoch 917, Loss: 0.18924605380743742, Final Batch Loss: 0.005558273755013943\n",
      "Epoch 918, Loss: 0.2060698950663209, Final Batch Loss: 0.012573142535984516\n",
      "Epoch 919, Loss: 0.18140460085123777, Final Batch Loss: 0.006897567771375179\n",
      "Epoch 920, Loss: 0.1298469558241777, Final Batch Loss: 3.886147169396281e-05\n",
      "Epoch 921, Loss: 0.14520139182786806, Final Batch Loss: 3.58813522325363e-05\n",
      "Epoch 922, Loss: 0.13259011966874823, Final Batch Loss: 0.0005088941543363035\n",
      "Epoch 923, Loss: 0.15968769532628357, Final Batch Loss: 0.003859334858134389\n",
      "Epoch 924, Loss: 0.1372773158363998, Final Batch Loss: 0.0041770595125854015\n",
      "Epoch 925, Loss: 0.11996413082670188, Final Batch Loss: 5.018585216021165e-05\n",
      "Epoch 926, Loss: 0.16638394072651863, Final Batch Loss: 0.04320806264877319\n",
      "Epoch 927, Loss: 0.1448882073036657, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 928, Loss: 0.15002101473507423, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 929, Loss: 0.15112017025239766, Final Batch Loss: 0.0024559118319302797\n",
      "Epoch 930, Loss: 0.13407226651906967, Final Batch Loss: 0.0\n",
      "Epoch 931, Loss: 0.12522419821470976, Final Batch Loss: 0.00213585514575243\n",
      "Epoch 932, Loss: 0.14520211284980178, Final Batch Loss: 0.005402251612395048\n",
      "Epoch 933, Loss: 0.1338857263326645, Final Batch Loss: 0.010614132508635521\n",
      "Epoch 934, Loss: 0.2820914462208748, Final Batch Loss: 0.14655889570713043\n",
      "Epoch 935, Loss: 0.14277047850180224, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 936, Loss: 0.1167294200276956, Final Batch Loss: 0.0011861439561471343\n",
      "Epoch 937, Loss: 0.11101297641835117, Final Batch Loss: 1.9907753085135482e-05\n",
      "Epoch 938, Loss: 0.11827943523530848, Final Batch Loss: 5.23315102327615e-05\n",
      "Epoch 939, Loss: 0.14763010723982006, Final Batch Loss: 0.0011984078446403146\n",
      "Epoch 940, Loss: 0.1159909525886178, Final Batch Loss: 0.009163112379610538\n",
      "Epoch 941, Loss: 0.12242667470127344, Final Batch Loss: 0.010861915536224842\n",
      "Epoch 942, Loss: 0.11398201248812256, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 943, Loss: 0.1278664938727161, Final Batch Loss: 0.00023493390472140163\n",
      "Epoch 944, Loss: 0.09983552247285843, Final Batch Loss: 0.004585465416312218\n",
      "Epoch 945, Loss: 0.12981509976089, Final Batch Loss: 0.0036415234208106995\n",
      "Epoch 946, Loss: 0.2277118619531393, Final Batch Loss: 0.10449104011058807\n",
      "Epoch 947, Loss: 0.11270167119801044, Final Batch Loss: 0.0075768944807350636\n",
      "Epoch 948, Loss: 0.12512690706716967, Final Batch Loss: 3.266281055402942e-05\n",
      "Epoch 949, Loss: 0.10236132510908647, Final Batch Loss: 0.00010632903286023065\n",
      "Epoch 950, Loss: 0.12799495621584356, Final Batch Loss: 0.002288700779899955\n",
      "Epoch 951, Loss: 0.10348366553444066, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 952, Loss: 0.20182601176202297, Final Batch Loss: 0.06904935836791992\n",
      "Epoch 953, Loss: 0.13070856570266187, Final Batch Loss: 0.0026600712444633245\n",
      "Epoch 954, Loss: 0.12075105659278051, Final Batch Loss: 2.13382354559144e-05\n",
      "Epoch 955, Loss: 0.11962286400375888, Final Batch Loss: 0.0004223884898237884\n",
      "Epoch 956, Loss: 0.11844803392887115, Final Batch Loss: 0.005399761721491814\n",
      "Epoch 957, Loss: 0.13794206455349922, Final Batch Loss: 0.0\n",
      "Epoch 958, Loss: 0.11320457234978676, Final Batch Loss: 0.0005355831235647202\n",
      "Epoch 959, Loss: 0.1246187087654107, Final Batch Loss: 2.539125671319198e-05\n",
      "Epoch 960, Loss: 0.15420415811240673, Final Batch Loss: 0.0065094102174043655\n",
      "Epoch 961, Loss: 0.12208981858566403, Final Batch Loss: 0.005147062707692385\n",
      "Epoch 962, Loss: 0.10776026666280814, Final Batch Loss: 0.00021455370006151497\n",
      "Epoch 963, Loss: 0.15527880564332008, Final Batch Loss: 0.026183629408478737\n",
      "Epoch 964, Loss: 0.10909370891749859, Final Batch Loss: 0.0020650746300816536\n",
      "Epoch 965, Loss: 0.11320059858553577, Final Batch Loss: 0.00016604475968051702\n",
      "Epoch 966, Loss: 0.11768938216846436, Final Batch Loss: 0.001259606215171516\n",
      "Epoch 967, Loss: 0.103207575155011, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 968, Loss: 0.15662188734859228, Final Batch Loss: 0.011046799831092358\n",
      "Epoch 969, Loss: 0.1128446354996413, Final Batch Loss: 0.0033515493851155043\n",
      "Epoch 970, Loss: 0.1088924184514326, Final Batch Loss: 0.00010561384988250211\n",
      "Epoch 971, Loss: 0.1427347063936395, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 972, Loss: 0.12587829038966447, Final Batch Loss: 0.00047052756417542696\n",
      "Epoch 973, Loss: 0.08607559103984386, Final Batch Loss: 0.00026556302327662706\n",
      "Epoch 974, Loss: 0.2793774865567684, Final Batch Loss: 0.14047567546367645\n",
      "Epoch 975, Loss: 0.219215489923954, Final Batch Loss: 0.10129304975271225\n",
      "Epoch 976, Loss: 0.453206330537796, Final Batch Loss: 0.3168293535709381\n",
      "Epoch 977, Loss: 0.14996262826025486, Final Batch Loss: 0.027805903926491737\n",
      "Epoch 978, Loss: 0.15966038033366203, Final Batch Loss: 0.0266454815864563\n",
      "Epoch 979, Loss: 0.11743148183450103, Final Batch Loss: 0.0029067429713904858\n",
      "Epoch 980, Loss: 0.13623215771804098, Final Batch Loss: 0.00020466140995267779\n",
      "Epoch 981, Loss: 0.16474025510251522, Final Batch Loss: 0.005564438179135323\n",
      "Epoch 982, Loss: 0.13856788724660163, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 983, Loss: 0.1373044434003532, Final Batch Loss: 0.0074889869429171085\n",
      "Epoch 984, Loss: 0.135258418507874, Final Batch Loss: 0.00793731864541769\n",
      "Epoch 985, Loss: 0.10886527132242918, Final Batch Loss: 0.010078846476972103\n",
      "Epoch 986, Loss: 0.25639479979872704, Final Batch Loss: 0.1341482251882553\n",
      "Epoch 987, Loss: 0.13090916009969078, Final Batch Loss: 0.000426439888542518\n",
      "Epoch 988, Loss: 0.13134764132337295, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 989, Loss: 0.18052602279931307, Final Batch Loss: 0.07532757520675659\n",
      "Epoch 990, Loss: 0.09743914660066366, Final Batch Loss: 0.006701494567096233\n",
      "Epoch 991, Loss: 0.2055996311828494, Final Batch Loss: 0.07511494308710098\n",
      "Epoch 992, Loss: 0.12700658745598048, Final Batch Loss: 0.0002029928145930171\n",
      "Epoch 993, Loss: 0.1477481471374631, Final Batch Loss: 0.010875594802200794\n",
      "Epoch 994, Loss: 0.12643570551881567, Final Batch Loss: 0.0008344743982888758\n",
      "Epoch 995, Loss: 0.13014323462266475, Final Batch Loss: 0.0006485265912488103\n",
      "Epoch 996, Loss: 0.13322108890861273, Final Batch Loss: 0.012490028515458107\n",
      "Epoch 997, Loss: 0.13301472576858941, Final Batch Loss: 0.00012003655137959868\n",
      "Epoch 998, Loss: 0.12927247108018491, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 999, Loss: 0.1405020132658592, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1000, Loss: 0.16089072078466415, Final Batch Loss: 0.03427595645189285\n",
      "Epoch 1001, Loss: 0.15601563267409801, Final Batch Loss: 0.03258788585662842\n",
      "Epoch 1002, Loss: 0.11787425447252531, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1003, Loss: 0.11640015314333141, Final Batch Loss: 0.0004077318590134382\n",
      "Epoch 1004, Loss: 0.14005785225890577, Final Batch Loss: 0.0019073167350143194\n",
      "Epoch 1005, Loss: 0.11397542516351677, Final Batch Loss: 0.0003638797497842461\n",
      "Epoch 1006, Loss: 0.12575252167879825, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1007, Loss: 0.1117623234167624, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1008, Loss: 0.1553704386242316, Final Batch Loss: 8.451581379631534e-05\n",
      "Epoch 1009, Loss: 0.11140106117090909, Final Batch Loss: 0.00011729506513802335\n",
      "Epoch 1010, Loss: 0.10776313208043575, Final Batch Loss: 0.0054565537720918655\n",
      "Epoch 1011, Loss: 0.10951036155165639, Final Batch Loss: 0.0002227773511549458\n",
      "Epoch 1012, Loss: 0.12344297510571778, Final Batch Loss: 0.000694153131917119\n",
      "Epoch 1013, Loss: 0.1050023389927901, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1014, Loss: 0.08438857644795661, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1015, Loss: 0.21907068230211735, Final Batch Loss: 0.07320424169301987\n",
      "Epoch 1016, Loss: 0.11229988071136177, Final Batch Loss: 0.0005514293443411589\n",
      "Epoch 1017, Loss: 0.11898605152964592, Final Batch Loss: 0.0004228651523590088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1018, Loss: 0.10799492569640279, Final Batch Loss: 0.0018694796599447727\n",
      "Epoch 1019, Loss: 0.11151282081846148, Final Batch Loss: 0.0001746263587847352\n",
      "Epoch 1020, Loss: 0.1313202055171132, Final Batch Loss: 0.015240292064845562\n",
      "Epoch 1021, Loss: 0.1346409568868694, Final Batch Loss: 6.639736966462806e-05\n",
      "Epoch 1022, Loss: 0.1957784704864025, Final Batch Loss: 0.045632220804691315\n",
      "Epoch 1023, Loss: 0.1144625882152468, Final Batch Loss: 0.00229904823936522\n",
      "Epoch 1024, Loss: 0.1241169031706022, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1025, Loss: 0.11116898921318352, Final Batch Loss: 0.0019356340635567904\n",
      "Epoch 1026, Loss: 0.11045800556894392, Final Batch Loss: 0.0018114125123247504\n",
      "Epoch 1027, Loss: 0.11873385682702065, Final Batch Loss: 0.00023636408150196075\n",
      "Epoch 1028, Loss: 0.12253273132955655, Final Batch Loss: 0.0008839037618599832\n",
      "Epoch 1029, Loss: 0.10761250928038635, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1030, Loss: 0.09531113857519813, Final Batch Loss: 2.0146166207268834e-05\n",
      "Epoch 1031, Loss: 0.12846100982278585, Final Batch Loss: 0.01194149348884821\n",
      "Epoch 1032, Loss: 0.1164327235892344, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1033, Loss: 0.12392684258520603, Final Batch Loss: 0.008240745402872562\n",
      "Epoch 1034, Loss: 0.12008596677333117, Final Batch Loss: 0.0015526870265603065\n",
      "Epoch 1035, Loss: 0.09918121201917529, Final Batch Loss: 0.004852186422795057\n",
      "Epoch 1036, Loss: 0.10751979984343052, Final Batch Loss: 0.0\n",
      "Epoch 1037, Loss: 0.11627723387937294, Final Batch Loss: 7.223821739898995e-05\n",
      "Epoch 1038, Loss: 0.09248923644190654, Final Batch Loss: 0.0008148210472427309\n",
      "Epoch 1039, Loss: 0.12676947488216683, Final Batch Loss: 0.00022349244682118297\n",
      "Epoch 1040, Loss: 0.09158540140015248, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 1041, Loss: 0.21698674745857716, Final Batch Loss: 0.08630447089672089\n",
      "Epoch 1042, Loss: 0.10059547239507083, Final Batch Loss: 0.00016139635408762842\n",
      "Epoch 1043, Loss: 0.10090075425705436, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 1044, Loss: 0.1243427733425051, Final Batch Loss: 0.0024915861431509256\n",
      "Epoch 1045, Loss: 0.12597742583602667, Final Batch Loss: 0.011531485244631767\n",
      "Epoch 1046, Loss: 0.12413089536130428, Final Batch Loss: 0.0\n",
      "Epoch 1047, Loss: 0.11387780867514152, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1048, Loss: 4.514575190842152, Final Batch Loss: 4.42647647857666\n",
      "Epoch 1049, Loss: 0.1631835582666099, Final Batch Loss: 0.00439356779679656\n",
      "Epoch 1050, Loss: 0.14029973896685988, Final Batch Loss: 0.0002809368306770921\n",
      "Epoch 1051, Loss: 0.15938851605460513, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 1052, Loss: 0.17475549329537898, Final Batch Loss: 0.001209600013680756\n",
      "Epoch 1053, Loss: 0.4379470907151699, Final Batch Loss: 0.2592712938785553\n",
      "Epoch 1054, Loss: 0.147448159288615, Final Batch Loss: 0.004842577036470175\n",
      "Epoch 1055, Loss: 0.15365326140454272, Final Batch Loss: 3.9457496313843876e-05\n",
      "Epoch 1056, Loss: 0.34529393538832664, Final Batch Loss: 0.21286965906620026\n",
      "Epoch 1057, Loss: 0.13335961042321287, Final Batch Loss: 0.00015352977789007127\n",
      "Epoch 1058, Loss: 0.1266340179136023, Final Batch Loss: 0.0004328744253143668\n",
      "Epoch 1059, Loss: 0.1320358645170927, Final Batch Loss: 0.012976368889212608\n",
      "Epoch 1060, Loss: 0.12973450776189566, Final Batch Loss: 0.01453948300331831\n",
      "Epoch 1061, Loss: 0.14629272185266018, Final Batch Loss: 0.020376168191432953\n",
      "Epoch 1062, Loss: 0.11386698193382472, Final Batch Loss: 0.0012349606258794665\n",
      "Epoch 1063, Loss: 0.1285927388817072, Final Batch Loss: 0.01882578432559967\n",
      "Epoch 1064, Loss: 0.10266073979420298, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1065, Loss: 0.41446124389767647, Final Batch Loss: 0.30569568276405334\n",
      "Epoch 1066, Loss: 0.129933612071909, Final Batch Loss: 0.0018387805903330445\n",
      "Epoch 1067, Loss: 0.1334775013383478, Final Batch Loss: 0.0032806170638650656\n",
      "Epoch 1068, Loss: 0.1926428857295832, Final Batch Loss: 3.0397906812140718e-05\n",
      "Epoch 1069, Loss: 0.17396067432127893, Final Batch Loss: 0.0015889888163655996\n",
      "Epoch 1070, Loss: 0.11261706682853401, Final Batch Loss: 0.0022735956590622663\n",
      "Epoch 1071, Loss: 0.16711872816085815, Final Batch Loss: 0.0\n",
      "Epoch 1072, Loss: 0.1370090696727857, Final Batch Loss: 0.001214005402289331\n",
      "Epoch 1073, Loss: 0.11301808524876833, Final Batch Loss: 0.0020971940830349922\n",
      "Epoch 1074, Loss: 0.1126203655730933, Final Batch Loss: 0.0028605039697140455\n",
      "Epoch 1075, Loss: 0.11556676644249819, Final Batch Loss: 0.0003381395654287189\n",
      "Epoch 1076, Loss: 0.09722027357929619, Final Batch Loss: 1.4781842764932662e-05\n",
      "Epoch 1077, Loss: 0.10245495273920824, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 1078, Loss: 0.11391416715923697, Final Batch Loss: 0.0004010588163509965\n",
      "Epoch 1079, Loss: 0.0996250956577569, Final Batch Loss: 1.156323378381785e-05\n",
      "Epoch 1080, Loss: 0.11676992490538396, Final Batch Loss: 0.00024351492174901068\n",
      "Epoch 1081, Loss: 0.11265625418127456, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 1082, Loss: 0.10430119163356721, Final Batch Loss: 0.0029743739869445562\n",
      "Epoch 1083, Loss: 0.09985393844533519, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1084, Loss: 0.09112440509488806, Final Batch Loss: 0.00014351768186315894\n",
      "Epoch 1085, Loss: 0.11922516151389573, Final Batch Loss: 3.373566141817719e-05\n",
      "Epoch 1086, Loss: 0.11657118171569891, Final Batch Loss: 3.659658250398934e-05\n",
      "Epoch 1087, Loss: 0.11354605690576136, Final Batch Loss: 0.0013450870756059885\n",
      "Epoch 1088, Loss: 0.09905698709189892, Final Batch Loss: 0.0010507544502615929\n",
      "Epoch 1089, Loss: 0.13754206872545183, Final Batch Loss: 0.002733900910243392\n",
      "Epoch 1090, Loss: 0.11202088627032936, Final Batch Loss: 0.0027362785767763853\n",
      "Epoch 1091, Loss: 0.10598728805780411, Final Batch Loss: 0.0\n",
      "Epoch 1092, Loss: 0.1182243399816798, Final Batch Loss: 9.202533692587167e-05\n",
      "Epoch 1093, Loss: 0.10680408833286492, Final Batch Loss: 0.00011729506513802335\n",
      "Epoch 1094, Loss: 0.08465962111358749, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 1095, Loss: 0.12742683850228786, Final Batch Loss: 0.0\n",
      "Epoch 1096, Loss: 0.09532094025053084, Final Batch Loss: 0.000834236154332757\n",
      "Epoch 1097, Loss: 0.09815055574290454, Final Batch Loss: 0.0005236684810370207\n",
      "Epoch 1098, Loss: 0.084685136040207, Final Batch Loss: 0.0005799042410217226\n",
      "Epoch 1099, Loss: 0.10550959222018719, Final Batch Loss: 0.0\n",
      "Epoch 1100, Loss: 0.12182630272582173, Final Batch Loss: 0.003341569099575281\n",
      "Epoch 1101, Loss: 0.12449337169528008, Final Batch Loss: 0.007032286375761032\n",
      "Epoch 1102, Loss: 0.10895672021433711, Final Batch Loss: 0.007400124799460173\n",
      "Epoch 1103, Loss: 0.1782135795801878, Final Batch Loss: 0.08537684381008148\n",
      "Epoch 1104, Loss: 0.13855830766260624, Final Batch Loss: 0.020017746835947037\n",
      "Epoch 1105, Loss: 0.12519247017189628, Final Batch Loss: 0.00011193125828867778\n",
      "Epoch 1106, Loss: 0.09764022444142029, Final Batch Loss: 0.0006391151691786945\n",
      "Epoch 1107, Loss: 0.11453038043691777, Final Batch Loss: 0.0004103533865418285\n",
      "Epoch 1108, Loss: 0.1074695996940136, Final Batch Loss: 0.010746345855295658\n",
      "Epoch 1109, Loss: 0.1092618447728455, Final Batch Loss: 0.003956586588174105\n",
      "Epoch 1110, Loss: 0.09706366428781621, Final Batch Loss: 1.0847986231965479e-05\n",
      "Epoch 1111, Loss: 0.09929513052338734, Final Batch Loss: 0.0006815256201662123\n",
      "Epoch 1112, Loss: 0.09844706719741225, Final Batch Loss: 0.004239856731146574\n",
      "Epoch 1113, Loss: 0.08413899692823179, Final Batch Loss: 0.0002989322238136083\n",
      "Epoch 1114, Loss: 0.11975152185186744, Final Batch Loss: 0.0007150000892579556\n",
      "Epoch 1115, Loss: 0.11650400422513485, Final Batch Loss: 0.004758106544613838\n",
      "Epoch 1116, Loss: 0.09559548640390858, Final Batch Loss: 0.0005594118847511709\n",
      "Epoch 1117, Loss: 0.1013001072278712, Final Batch Loss: 0.00033456450910307467\n",
      "Epoch 1118, Loss: 0.10539450123633287, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 1119, Loss: 0.08876799978293093, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1120, Loss: 0.09973378949871403, Final Batch Loss: 4.207999518257566e-05\n",
      "Epoch 1121, Loss: 0.10860013402964341, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1122, Loss: 0.2994611244648695, Final Batch Loss: 0.1799873411655426\n",
      "Epoch 1123, Loss: 0.10880132578296298, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1124, Loss: 0.11119029285509896, Final Batch Loss: 1.6093124941107817e-05\n",
      "Epoch 1125, Loss: 0.17222273864899762, Final Batch Loss: 0.0003518439189065248\n",
      "Epoch 1126, Loss: 0.1503816395998001, Final Batch Loss: 0.019214335829019547\n",
      "Epoch 1127, Loss: 0.1450957148335874, Final Batch Loss: 0.00011002412065863609\n",
      "Epoch 1128, Loss: 0.134311856701963, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1129, Loss: 0.1239366689696908, Final Batch Loss: 0.003922508098185062\n",
      "Epoch 1130, Loss: 0.14225515443831682, Final Batch Loss: 0.03583605960011482\n",
      "Epoch 1131, Loss: 0.09428222104907036, Final Batch Loss: 0.01142294704914093\n",
      "Epoch 1132, Loss: 0.0851942300786277, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1133, Loss: 0.10992912636720575, Final Batch Loss: 0.00045944625162519515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1134, Loss: 0.10780377546325326, Final Batch Loss: 0.0062004816718399525\n",
      "Epoch 1135, Loss: 0.10049634979804978, Final Batch Loss: 0.0006057572900317609\n",
      "Epoch 1136, Loss: 0.09016906190663576, Final Batch Loss: 0.0\n",
      "Epoch 1137, Loss: 0.10253003216348588, Final Batch Loss: 0.00029345019720494747\n",
      "Epoch 1138, Loss: 0.13539184955880046, Final Batch Loss: 0.04092391952872276\n",
      "Epoch 1139, Loss: 0.11993636790430173, Final Batch Loss: 0.0004129749140702188\n",
      "Epoch 1140, Loss: 0.13276642560958862, Final Batch Loss: 0.0\n",
      "Epoch 1141, Loss: 0.13622090400986053, Final Batch Loss: 1.07287787614041e-05\n",
      "Epoch 1142, Loss: 0.09552138112484698, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1143, Loss: 0.12327835988253355, Final Batch Loss: 0.009703374467790127\n",
      "Epoch 1144, Loss: 0.12027353188022971, Final Batch Loss: 0.028584834188222885\n",
      "Epoch 1145, Loss: 0.14137594401836395, Final Batch Loss: 0.023225298151373863\n",
      "Epoch 1146, Loss: 0.12029630155302584, Final Batch Loss: 0.0025535377208143473\n",
      "Epoch 1147, Loss: 0.09785623429343104, Final Batch Loss: 0.008470441214740276\n",
      "Epoch 1148, Loss: 0.10005072868716525, Final Batch Loss: 1.2755313036905136e-05\n",
      "Epoch 1149, Loss: 0.08540741911701843, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 1150, Loss: 0.09739916899707168, Final Batch Loss: 0.0012070996453985572\n",
      "Epoch 1151, Loss: 0.11683122499380261, Final Batch Loss: 0.0010278901318088174\n",
      "Epoch 1152, Loss: 0.11411365307731103, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 1153, Loss: 0.10901495142752538, Final Batch Loss: 7.73638384998776e-05\n",
      "Epoch 1154, Loss: 0.08114916831254959, Final Batch Loss: 0.0068967388942837715\n",
      "Epoch 1155, Loss: 0.1667382102459669, Final Batch Loss: 0.08016157895326614\n",
      "Epoch 1156, Loss: 0.103997375437757, Final Batch Loss: 0.000459565402707085\n",
      "Epoch 1157, Loss: 0.09754099207930267, Final Batch Loss: 0.0012290074955672026\n",
      "Epoch 1158, Loss: 0.12317566643469036, Final Batch Loss: 0.00311211752705276\n",
      "Epoch 1159, Loss: 0.1165376917924732, Final Batch Loss: 0.0024836191441863775\n",
      "Epoch 1160, Loss: 0.11966824997216463, Final Batch Loss: 0.004021652974188328\n",
      "Epoch 1161, Loss: 0.1120055795472581, Final Batch Loss: 0.0002615109842736274\n",
      "Epoch 1162, Loss: 0.10038310289155561, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1163, Loss: 0.3180709546431899, Final Batch Loss: 0.22185947000980377\n",
      "Epoch 1164, Loss: 0.09179962426424026, Final Batch Loss: 0.010450638830661774\n",
      "Epoch 1165, Loss: 0.1393307372545678, Final Batch Loss: 8.702239938429557e-06\n",
      "Epoch 1166, Loss: 0.15400435030119297, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 1167, Loss: 0.15811853150080424, Final Batch Loss: 0.00019095504831057042\n",
      "Epoch 1168, Loss: 0.12570065258205432, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 1169, Loss: 0.12281350139528513, Final Batch Loss: 0.02105690911412239\n",
      "Epoch 1170, Loss: 0.1032636440359056, Final Batch Loss: 0.005648366641253233\n",
      "Epoch 1171, Loss: 0.09032774623472051, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1172, Loss: 0.11695210614561802, Final Batch Loss: 2.0503786799963564e-05\n",
      "Epoch 1173, Loss: 0.07406442333012819, Final Batch Loss: 0.010463261976838112\n",
      "Epoch 1174, Loss: 0.1150103835389018, Final Batch Loss: 0.015385161153972149\n",
      "Epoch 1175, Loss: 0.0885465897154063, Final Batch Loss: 0.002169756917282939\n",
      "Epoch 1176, Loss: 0.1019159479837981, Final Batch Loss: 4.565611743601039e-05\n",
      "Epoch 1177, Loss: 0.0966708597188699, Final Batch Loss: 3.755022044060752e-05\n",
      "Epoch 1178, Loss: 0.1000317428257631, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1179, Loss: 0.11898984014987946, Final Batch Loss: 0.024570465087890625\n",
      "Epoch 1180, Loss: 0.08009618892856452, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 1181, Loss: 0.09248244389641513, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1182, Loss: 0.11338991153752431, Final Batch Loss: 0.0004912600270472467\n",
      "Epoch 1183, Loss: 2.335700207389891, Final Batch Loss: 2.243016004562378\n",
      "Epoch 1184, Loss: 0.10073308448772877, Final Batch Loss: 0.001392586505971849\n",
      "Epoch 1185, Loss: 0.17530841179541312, Final Batch Loss: 0.0004362108593340963\n",
      "Epoch 1186, Loss: 0.21142159402370453, Final Batch Loss: 0.01456662267446518\n",
      "Epoch 1187, Loss: 0.3042532639228739, Final Batch Loss: 0.0006001578294672072\n",
      "Epoch 1188, Loss: 0.26961592941370327, Final Batch Loss: 1.7881233361549675e-05\n",
      "Epoch 1189, Loss: 0.209872018545866, Final Batch Loss: 0.0\n",
      "Epoch 1190, Loss: 0.12974706850940265, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1191, Loss: 0.15851860492648484, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 1192, Loss: 0.1391901597380354, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1193, Loss: 0.26465906761586666, Final Batch Loss: 0.1486303210258484\n",
      "Epoch 1194, Loss: 0.31074132584035397, Final Batch Loss: 0.20284821093082428\n",
      "Epoch 1195, Loss: 0.09185873156502566, Final Batch Loss: 5.960446742392378e-06\n",
      "Epoch 1196, Loss: 0.11251616037043277, Final Batch Loss: 0.00015400654228869826\n",
      "Epoch 1197, Loss: 0.09338746964931488, Final Batch Loss: 0.0\n",
      "Epoch 1198, Loss: 0.1127861548011424, Final Batch Loss: 9.07141511561349e-05\n",
      "Epoch 1199, Loss: 0.11084836313966662, Final Batch Loss: 0.0001389883691444993\n",
      "Epoch 1200, Loss: 0.12265332276001573, Final Batch Loss: 0.0032922611571848392\n",
      "Epoch 1201, Loss: 0.11185209709219635, Final Batch Loss: 0.0016971721779555082\n",
      "Epoch 1202, Loss: 0.08484726399149167, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1203, Loss: 0.1664469577372074, Final Batch Loss: 0.07511074095964432\n",
      "Epoch 1204, Loss: 0.08994456779328175, Final Batch Loss: 0.0002917817619163543\n",
      "Epoch 1205, Loss: 0.07906845666730078, Final Batch Loss: 6.282132380874828e-05\n",
      "Epoch 1206, Loss: 0.09871434979140759, Final Batch Loss: 0.027390172705054283\n",
      "Epoch 1207, Loss: 0.10221063903941285, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1208, Loss: 0.09083376765192952, Final Batch Loss: 0.0001760566228767857\n",
      "Epoch 1209, Loss: 0.12832989916205406, Final Batch Loss: 0.01631585881114006\n",
      "Epoch 1210, Loss: 1.490840269252658, Final Batch Loss: 1.3971880674362183\n",
      "Epoch 1211, Loss: 0.22311300403089263, Final Batch Loss: 0.00047291061491705477\n",
      "Epoch 1212, Loss: 0.8614885108545423, Final Batch Loss: 0.013148744590580463\n",
      "Epoch 1213, Loss: 2.521505117416382, Final Batch Loss: 0.8911167979240417\n",
      "Epoch 1214, Loss: 2.103037327528, Final Batch Loss: 1.0402384996414185\n",
      "Epoch 1215, Loss: 0.3329128362238407, Final Batch Loss: 0.024823885411024094\n",
      "Epoch 1216, Loss: 0.1829926585778594, Final Batch Loss: 0.0021437061950564384\n",
      "Epoch 1217, Loss: 0.1934243011928629, Final Batch Loss: 0.00035065223346464336\n",
      "Epoch 1218, Loss: 0.19802962616085296, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1219, Loss: 0.3841011971235275, Final Batch Loss: 0.0764409527182579\n",
      "Epoch 1220, Loss: 0.26722008199431, Final Batch Loss: 0.0006189814303070307\n",
      "Epoch 1221, Loss: 0.27039859085925855, Final Batch Loss: 0.00019226610311307013\n",
      "Epoch 1222, Loss: 0.267421942204237, Final Batch Loss: 0.01664184406399727\n",
      "Epoch 1223, Loss: 0.8678882420063019, Final Batch Loss: 0.6423770785331726\n",
      "Epoch 1224, Loss: 0.16953567042946815, Final Batch Loss: 0.0026543643325567245\n",
      "Epoch 1225, Loss: 0.13413952430710196, Final Batch Loss: 0.007497505750507116\n",
      "Epoch 1226, Loss: 0.16126380860771405, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1227, Loss: 0.15756292231708358, Final Batch Loss: 2.7179348762729205e-05\n",
      "Epoch 1228, Loss: 0.7568848133087158, Final Batch Loss: 0.6027419567108154\n",
      "Epoch 1229, Loss: 0.15358378482051194, Final Batch Loss: 0.0038206216413527727\n",
      "Epoch 1230, Loss: 0.2052235459559597, Final Batch Loss: 0.0006032554083503783\n",
      "Epoch 1231, Loss: 0.19950581120792776, Final Batch Loss: 0.0006138585740700364\n",
      "Epoch 1232, Loss: 0.1918578539043665, Final Batch Loss: 0.011620806530117989\n",
      "Epoch 1233, Loss: 0.190877738466952, Final Batch Loss: 0.0005994430393911898\n",
      "Epoch 1234, Loss: 0.14901065977755934, Final Batch Loss: 0.000993711524643004\n",
      "Epoch 1235, Loss: 0.16883244551718235, Final Batch Loss: 0.00722876749932766\n",
      "Epoch 1236, Loss: 0.15681587156177557, Final Batch Loss: 8.34461570775602e-06\n",
      "Epoch 1237, Loss: 0.14904231682885438, Final Batch Loss: 0.0008310201810672879\n",
      "Epoch 1238, Loss: 0.1610813996521756, Final Batch Loss: 0.001921832445077598\n",
      "Epoch 1239, Loss: 0.11799212917684798, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1240, Loss: 0.1536762522009667, Final Batch Loss: 9.30981186684221e-05\n",
      "Epoch 1241, Loss: 0.13090863428078592, Final Batch Loss: 0.0024374795611947775\n",
      "Epoch 1242, Loss: 0.598938561975956, Final Batch Loss: 0.5005024075508118\n",
      "Epoch 1243, Loss: 0.13581027288455516, Final Batch Loss: 0.0006192197324708104\n",
      "Epoch 1244, Loss: 0.13416559784673154, Final Batch Loss: 0.003625726094469428\n",
      "Epoch 1245, Loss: 0.1671384479268454, Final Batch Loss: 0.00025185750564560294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1246, Loss: 0.17129452526552313, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1247, Loss: 0.1729942038655281, Final Batch Loss: 0.0\n",
      "Epoch 1248, Loss: 0.1924210856668651, Final Batch Loss: 0.0053684595040977\n",
      "Epoch 1249, Loss: 0.15632903953519417, Final Batch Loss: 8.570780482841656e-05\n",
      "Epoch 1250, Loss: 0.14914238161873072, Final Batch Loss: 0.0016023189527913928\n",
      "Epoch 1251, Loss: 0.145506443164777, Final Batch Loss: 0.0005395148764364421\n",
      "Epoch 1252, Loss: 0.1478288434436763, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1253, Loss: 0.12089039344573393, Final Batch Loss: 0.0009458358981646597\n",
      "Epoch 1254, Loss: 0.17619062587618828, Final Batch Loss: 0.05392177402973175\n",
      "Epoch 1255, Loss: 0.28850081749260426, Final Batch Loss: 0.17116136848926544\n",
      "Epoch 1256, Loss: 0.11997033654733968, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 1257, Loss: 0.09218094124571508, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 1258, Loss: 0.13544449183973484, Final Batch Loss: 0.00048494499060325325\n",
      "Epoch 1259, Loss: 0.15714735583605943, Final Batch Loss: 0.00011824862303910777\n",
      "Epoch 1260, Loss: 0.09896710320299462, Final Batch Loss: 1.2993727978027891e-05\n",
      "Epoch 1261, Loss: 0.11148198787122965, Final Batch Loss: 0.004971879534423351\n",
      "Epoch 1262, Loss: 0.10170148496672482, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 1263, Loss: 0.11306937411427498, Final Batch Loss: 0.0043445490300655365\n",
      "Epoch 1264, Loss: 0.11016744701191783, Final Batch Loss: 0.005842631217092276\n",
      "Epoch 1265, Loss: 0.10181629555700056, Final Batch Loss: 1.3351351299206726e-05\n",
      "Epoch 1266, Loss: 0.10613760945852846, Final Batch Loss: 0.0014781750505790114\n",
      "Epoch 1267, Loss: 0.09411625983193517, Final Batch Loss: 0.003377568442374468\n",
      "Epoch 1268, Loss: 0.10500735625100788, Final Batch Loss: 0.00021038226259406656\n",
      "Epoch 1269, Loss: 0.09956316882744431, Final Batch Loss: 0.004344786051660776\n",
      "Epoch 1270, Loss: 0.1174983088276349, Final Batch Loss: 0.0006898645660839975\n",
      "Epoch 1271, Loss: 0.12414557643387525, Final Batch Loss: 2.4318398573086597e-05\n",
      "Epoch 1272, Loss: 0.11080195102840662, Final Batch Loss: 0.0\n",
      "Epoch 1273, Loss: 0.0955244954675436, Final Batch Loss: 0.004994060844182968\n",
      "Epoch 1274, Loss: 0.11746904801111668, Final Batch Loss: 0.0013152052415534854\n",
      "Epoch 1275, Loss: 0.13549311505630612, Final Batch Loss: 0.0029841200448572636\n",
      "Epoch 1276, Loss: 2.1364932898432016, Final Batch Loss: 2.0369272232055664\n",
      "Epoch 1277, Loss: 0.15134527027839795, Final Batch Loss: 0.0002640137099660933\n",
      "Epoch 1278, Loss: 0.236950145335868, Final Batch Loss: 0.0030166853684931993\n",
      "Epoch 1279, Loss: 0.31378401815891266, Final Batch Loss: 0.00986994057893753\n",
      "Epoch 1280, Loss: 0.4460638649761677, Final Batch Loss: 0.004044923931360245\n",
      "Epoch 1281, Loss: 0.3387274369597435, Final Batch Loss: 0.0\n",
      "Epoch 1282, Loss: 0.40001125633716583, Final Batch Loss: 0.016620390117168427\n",
      "Epoch 1283, Loss: 0.3425924424082041, Final Batch Loss: 0.015918904915452003\n",
      "Epoch 1284, Loss: 0.30399712897633435, Final Batch Loss: 2.1219027985353023e-05\n",
      "Epoch 1285, Loss: 0.2570722318487242, Final Batch Loss: 0.0007232195930555463\n",
      "Epoch 1286, Loss: 0.21070406520084362, Final Batch Loss: 5.638440416078083e-05\n",
      "Epoch 1287, Loss: 0.17393647311837412, Final Batch Loss: 0.0003054867556784302\n",
      "Epoch 1288, Loss: 0.16957177965196024, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1289, Loss: 0.14578055642778054, Final Batch Loss: 0.0005516675882972777\n",
      "Epoch 1290, Loss: 0.12667400622740388, Final Batch Loss: 0.0045242332853376865\n",
      "Epoch 1291, Loss: 0.1338614672422409, Final Batch Loss: 0.0\n",
      "Epoch 1292, Loss: 0.11410105787217617, Final Batch Loss: 0.009193941950798035\n",
      "Epoch 1293, Loss: 0.11209084652363543, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1294, Loss: 0.08953034505247359, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1295, Loss: 0.12144049443304539, Final Batch Loss: 0.01943100430071354\n",
      "Epoch 1296, Loss: 0.126156410202384, Final Batch Loss: 0.0023479294031858444\n",
      "Epoch 1297, Loss: 0.08934076005243696, Final Batch Loss: 0.00016902448260225356\n",
      "Epoch 1298, Loss: 0.0985668902285397, Final Batch Loss: 0.002224829513579607\n",
      "Epoch 1299, Loss: 0.10715516103664413, Final Batch Loss: 0.0005723983631469309\n",
      "Epoch 1300, Loss: 0.09318608231842518, Final Batch Loss: 0.0\n",
      "Epoch 1301, Loss: 0.09083650819945888, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1302, Loss: 0.10559281333735271, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 1303, Loss: 0.08745475858438567, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1304, Loss: 0.0981800276786089, Final Batch Loss: 0.004738174378871918\n",
      "Epoch 1305, Loss: 0.11569540097843856, Final Batch Loss: 0.0012469858629629016\n",
      "Epoch 1306, Loss: 0.1140480525791645, Final Batch Loss: 0.010694099590182304\n",
      "Epoch 1307, Loss: 0.10886762305744924, Final Batch Loss: 0.00034481301554478705\n",
      "Epoch 1308, Loss: 0.10206266678869724, Final Batch Loss: 0.002153698354959488\n",
      "Epoch 1309, Loss: 0.0860325526446033, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1310, Loss: 0.11442616116255522, Final Batch Loss: 0.004478069022297859\n",
      "Epoch 1311, Loss: 0.14168341923505068, Final Batch Loss: 0.022159704938530922\n",
      "Epoch 1312, Loss: 0.1057557724416256, Final Batch Loss: 0.0\n",
      "Epoch 1313, Loss: 0.10447107022628188, Final Batch Loss: 0.004865947645157576\n",
      "Epoch 1314, Loss: 0.14728898741304874, Final Batch Loss: 0.0267935823649168\n",
      "Epoch 1315, Loss: 0.09257236309349537, Final Batch Loss: 0.0026315366849303246\n",
      "Epoch 1316, Loss: 0.09277334229955159, Final Batch Loss: 2.0265373677830212e-05\n",
      "Epoch 1317, Loss: 0.09313365072011948, Final Batch Loss: 0.006804035045206547\n",
      "Epoch 1318, Loss: 0.09099855576641858, Final Batch Loss: 0.0033435889054089785\n",
      "Epoch 1319, Loss: 0.10312534077093005, Final Batch Loss: 0.001611840445548296\n",
      "Epoch 1320, Loss: 0.10235345573164523, Final Batch Loss: 0.001096481690183282\n",
      "Epoch 1321, Loss: 0.13861460611224174, Final Batch Loss: 0.0215164665132761\n",
      "Epoch 1322, Loss: 0.11427848064340651, Final Batch Loss: 0.003075633430853486\n",
      "Epoch 1323, Loss: 0.10931717031235166, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 1324, Loss: 0.10452960012480617, Final Batch Loss: 0.005946444813162088\n",
      "Epoch 1325, Loss: 0.09953558052075095, Final Batch Loss: 0.00036161558819003403\n",
      "Epoch 1326, Loss: 0.09789238643134013, Final Batch Loss: 0.0006493605324067175\n",
      "Epoch 1327, Loss: 0.14099763706326485, Final Batch Loss: 0.07080510258674622\n",
      "Epoch 1328, Loss: 0.0981164462864399, Final Batch Loss: 0.005805891007184982\n",
      "Epoch 1329, Loss: 0.10256841339287348, Final Batch Loss: 0.00012742661056108773\n",
      "Epoch 1330, Loss: 0.08488906675484031, Final Batch Loss: 0.001892800792120397\n",
      "Epoch 1331, Loss: 0.13912302069365268, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1332, Loss: 0.10480443569667841, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 1333, Loss: 0.12244520708918571, Final Batch Loss: 0.019269999116659164\n",
      "Epoch 1334, Loss: 0.08420341141754761, Final Batch Loss: 0.00027783826226368546\n",
      "Epoch 1335, Loss: 0.10004226630553603, Final Batch Loss: 0.006633759941905737\n",
      "Epoch 1336, Loss: 0.08265803282756679, Final Batch Loss: 1.0847986231965479e-05\n",
      "Epoch 1337, Loss: 0.09130308532257914, Final Batch Loss: 3.421248038648628e-05\n",
      "Epoch 1338, Loss: 0.16392884124070406, Final Batch Loss: 0.07460369914770126\n",
      "Epoch 1339, Loss: 0.08600433729498036, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1340, Loss: 0.10036776214837317, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1341, Loss: 0.07199180820225592, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 1342, Loss: 0.08074431476416066, Final Batch Loss: 0.00026663561584427953\n",
      "Epoch 1343, Loss: 0.09541004670609254, Final Batch Loss: 0.00015209948469419032\n",
      "Epoch 1344, Loss: 0.18785885348916054, Final Batch Loss: 0.08881871402263641\n",
      "Epoch 1345, Loss: 0.08800501108635217, Final Batch Loss: 0.001473889802582562\n",
      "Epoch 1346, Loss: 0.09864144725725055, Final Batch Loss: 0.00759499566629529\n",
      "Epoch 1347, Loss: 0.07831387966689363, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 1348, Loss: 0.10474616955616511, Final Batch Loss: 0.0003682888636831194\n",
      "Epoch 1349, Loss: 0.11010443419218063, Final Batch Loss: 0.027133457362651825\n",
      "Epoch 1350, Loss: 0.10679211001843214, Final Batch Loss: 0.009141613729298115\n",
      "Epoch 1351, Loss: 0.09100143593968824, Final Batch Loss: 0.0005760917556472123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1352, Loss: 0.06367856325232424, Final Batch Loss: 0.00016902448260225356\n",
      "Epoch 1353, Loss: 0.08982327161356807, Final Batch Loss: 0.0\n",
      "Epoch 1354, Loss: 0.28541991487145424, Final Batch Loss: 0.17219020426273346\n",
      "Epoch 1355, Loss: 0.09148191066924483, Final Batch Loss: 9.023735765367746e-05\n",
      "Epoch 1356, Loss: 0.11577996425330639, Final Batch Loss: 0.006691666319966316\n",
      "Epoch 1357, Loss: 0.08883143006823957, Final Batch Loss: 0.0030509138014167547\n",
      "Epoch 1358, Loss: 0.11832388304173946, Final Batch Loss: 0.0\n",
      "Epoch 1359, Loss: 0.09046237636356835, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1360, Loss: 0.12305350694805384, Final Batch Loss: 0.010424449108541012\n",
      "Epoch 1361, Loss: 0.08275054674595594, Final Batch Loss: 0.0\n",
      "Epoch 1362, Loss: 0.09407097101194495, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1363, Loss: 0.10905497858766466, Final Batch Loss: 7.92710343375802e-05\n",
      "Epoch 1364, Loss: 0.0891115940103191, Final Batch Loss: 3.075552376685664e-05\n",
      "Epoch 1365, Loss: 0.10340187605470419, Final Batch Loss: 0.030410122126340866\n",
      "Epoch 1366, Loss: 0.13340514339503784, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1367, Loss: 0.07950817043456482, Final Batch Loss: 0.0001062098381225951\n",
      "Epoch 1368, Loss: 0.07376490934984758, Final Batch Loss: 0.0005849081207998097\n",
      "Epoch 1369, Loss: 0.08837923124974623, Final Batch Loss: 7.986990567587782e-06\n",
      "Epoch 1370, Loss: 0.10438866773620248, Final Batch Loss: 0.006930242758244276\n",
      "Epoch 1371, Loss: 0.09297068079467863, Final Batch Loss: 0.0006510283565148711\n",
      "Epoch 1372, Loss: 0.09681611694395542, Final Batch Loss: 0.0\n",
      "Epoch 1373, Loss: 0.07399143953807652, Final Batch Loss: 7.152301259338856e-05\n",
      "Epoch 1374, Loss: 0.0992828207090497, Final Batch Loss: 0.010926063172519207\n",
      "Epoch 1375, Loss: 0.06959166610613465, Final Batch Loss: 0.0038628973998129368\n",
      "Epoch 1376, Loss: 0.09638436511158943, Final Batch Loss: 0.0\n",
      "Epoch 1377, Loss: 0.09962516650170983, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 1378, Loss: 0.10884755290840076, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1379, Loss: 0.09567624278133735, Final Batch Loss: 0.0002224197960458696\n",
      "Epoch 1380, Loss: 0.07888947240235211, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 1381, Loss: 0.07220296529703774, Final Batch Loss: 0.0004397855664137751\n",
      "Epoch 1382, Loss: 0.06583814119949238, Final Batch Loss: 0.0001072826053132303\n",
      "Epoch 1383, Loss: 0.083882762119174, Final Batch Loss: 0.0\n",
      "Epoch 1384, Loss: 0.08425945969065651, Final Batch Loss: 0.0007400158210657537\n",
      "Epoch 1385, Loss: 0.09106363728642464, Final Batch Loss: 0.0\n",
      "Epoch 1386, Loss: 0.10229975020047277, Final Batch Loss: 0.00011920218821614981\n",
      "Epoch 1387, Loss: 0.09010802680859342, Final Batch Loss: 0.0008422164828516543\n",
      "Epoch 1388, Loss: 0.07338782394890586, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 1389, Loss: 0.0655540936277248, Final Batch Loss: 0.0005915798828937113\n",
      "Epoch 1390, Loss: 0.9174774121493101, Final Batch Loss: 0.8403680920600891\n",
      "Epoch 1391, Loss: 0.08121501235291362, Final Batch Loss: 0.005099741276353598\n",
      "Epoch 1392, Loss: 0.15306767472065985, Final Batch Loss: 0.0022827538195997477\n",
      "Epoch 1393, Loss: 0.1590589570114389, Final Batch Loss: 0.00149555376265198\n",
      "Epoch 1394, Loss: 0.18543715425767004, Final Batch Loss: 0.0004991239402443171\n",
      "Epoch 1395, Loss: 0.18493757396936417, Final Batch Loss: 0.0\n",
      "Epoch 1396, Loss: 0.17720646404450235, Final Batch Loss: 1.156323378381785e-05\n",
      "Epoch 1397, Loss: 0.19318044977262616, Final Batch Loss: 0.004921939689666033\n",
      "Epoch 1398, Loss: 0.15611158311367035, Final Batch Loss: 0.0\n",
      "Epoch 1399, Loss: 0.11746264644898474, Final Batch Loss: 0.0014477020595222712\n",
      "Epoch 1400, Loss: 0.08110108830442186, Final Batch Loss: 0.0001399419124936685\n",
      "Epoch 1401, Loss: 0.1409475514665246, Final Batch Loss: 0.007239419035613537\n",
      "Epoch 1402, Loss: 0.11542418057797477, Final Batch Loss: 0.0007558587822131813\n",
      "Epoch 1403, Loss: 0.146948566660285, Final Batch Loss: 0.05720575153827667\n",
      "Epoch 1404, Loss: 0.09974221325683175, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 1405, Loss: 0.10301404539494996, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1406, Loss: 0.0926587370922789, Final Batch Loss: 0.00083078199531883\n",
      "Epoch 1407, Loss: 0.11328395642340183, Final Batch Loss: 0.008677158504724503\n",
      "Epoch 1408, Loss: 0.08495705109089613, Final Batch Loss: 0.006705638952553272\n",
      "Epoch 1409, Loss: 0.0643827486783266, Final Batch Loss: 0.0\n",
      "Epoch 1410, Loss: 0.0812041675162618, Final Batch Loss: 1.0132738680113107e-05\n",
      "Epoch 1411, Loss: 0.07661114065831498, Final Batch Loss: 1.2993727978027891e-05\n",
      "Epoch 1412, Loss: 0.07035252050263807, Final Batch Loss: 0.00020382710499688983\n",
      "Epoch 1413, Loss: 0.08566835086094216, Final Batch Loss: 0.00020096666412428021\n",
      "Epoch 1414, Loss: 0.08472572453319316, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1415, Loss: 0.08545076660720952, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1416, Loss: 0.08060373551620614, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 1417, Loss: 0.09148710223234957, Final Batch Loss: 8.606540359323844e-05\n",
      "Epoch 1418, Loss: 0.1154013006016612, Final Batch Loss: 0.03873569890856743\n",
      "Epoch 1419, Loss: 0.0810017199255526, Final Batch Loss: 0.0\n",
      "Epoch 1420, Loss: 0.08069525802784483, Final Batch Loss: 2.9205850296420977e-05\n",
      "Epoch 1421, Loss: 0.09883134617211908, Final Batch Loss: 1.3112935448589269e-05\n",
      "Epoch 1422, Loss: 0.09157568588852882, Final Batch Loss: 0.0\n",
      "Epoch 1423, Loss: 0.09230032563209534, Final Batch Loss: 0.0\n",
      "Epoch 1424, Loss: 0.1177436773723457, Final Batch Loss: 0.0003535122668836266\n",
      "Epoch 1425, Loss: 0.07175864133387222, Final Batch Loss: 5.400034933700226e-05\n",
      "Epoch 1426, Loss: 0.08704796190431807, Final Batch Loss: 0.00014709345123264939\n",
      "Epoch 1427, Loss: 0.08172313297109213, Final Batch Loss: 0.00010692501382436603\n",
      "Epoch 1428, Loss: 0.08867227286100388, Final Batch Loss: 0.009720610454678535\n",
      "Epoch 1429, Loss: 0.0979302861742326, Final Batch Loss: 5.94836674281396e-05\n",
      "Epoch 1430, Loss: 0.08637929381802678, Final Batch Loss: 0.000806721393018961\n",
      "Epoch 1431, Loss: 0.0764528177678585, Final Batch Loss: 0.0\n",
      "Epoch 1432, Loss: 0.08153721131373004, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1433, Loss: 0.07280601840466261, Final Batch Loss: 0.0\n",
      "Epoch 1434, Loss: 0.07092431746406191, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1435, Loss: 0.0651053765323013, Final Batch Loss: 0.0007120219524949789\n",
      "Epoch 1436, Loss: 0.07179900794290006, Final Batch Loss: 0.0007697956170886755\n",
      "Epoch 1437, Loss: 0.08141400758177042, Final Batch Loss: 0.0045609017834067345\n",
      "Epoch 1438, Loss: 0.10325735376682132, Final Batch Loss: 0.0004913791781291366\n",
      "Epoch 1439, Loss: 0.17890973202884197, Final Batch Loss: 0.08418242633342743\n",
      "Epoch 1440, Loss: 0.07700987718999386, Final Batch Loss: 0.0\n",
      "Epoch 1441, Loss: 0.08480810932815075, Final Batch Loss: 0.0\n",
      "Epoch 1442, Loss: 0.09619021847902332, Final Batch Loss: 0.00011705666838679463\n",
      "Epoch 1443, Loss: 0.06427026214078069, Final Batch Loss: 0.003475817386060953\n",
      "Epoch 1444, Loss: 0.09749168807184105, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 1445, Loss: 0.09943759348243475, Final Batch Loss: 0.01120878104120493\n",
      "Epoch 1446, Loss: 0.07810174860060215, Final Batch Loss: 0.0035068225115537643\n",
      "Epoch 1447, Loss: 0.07131068035960197, Final Batch Loss: 0.0\n",
      "Epoch 1448, Loss: 0.08478205091523705, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 1449, Loss: 0.07422745041546364, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1450, Loss: 0.08648920711129904, Final Batch Loss: 0.007363323122262955\n",
      "Epoch 1451, Loss: 0.07682236074469984, Final Batch Loss: 0.0035508933942764997\n",
      "Epoch 1452, Loss: 0.08283841283957827, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1453, Loss: 0.08729731659241224, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 1454, Loss: 0.0774436173912818, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1455, Loss: 0.08336862036958337, Final Batch Loss: 0.007322970312088728\n",
      "Epoch 1456, Loss: 0.0890209693458246, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1457, Loss: 0.07741917221574113, Final Batch Loss: 0.0005429700831882656\n",
      "Epoch 1458, Loss: 0.10463290102779865, Final Batch Loss: 0.02211259864270687\n",
      "Epoch 1459, Loss: 0.079872474540025, Final Batch Loss: 0.0\n",
      "Epoch 1460, Loss: 0.0546426429937128, Final Batch Loss: 0.0004644507134798914\n",
      "Epoch 1461, Loss: 0.07160174434829969, Final Batch Loss: 0.00023803261865396053\n",
      "Epoch 1462, Loss: 2.5078219221904874, Final Batch Loss: 2.4527571201324463\n",
      "Epoch 1463, Loss: 0.06871963571756368, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1464, Loss: 0.09828854724730718, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1465, Loss: 0.10151730064535514, Final Batch Loss: 0.0005732323625124991\n",
      "Epoch 1466, Loss: 0.10017351992428303, Final Batch Loss: 0.00868874043226242\n",
      "Epoch 1467, Loss: 0.08750927635992412, Final Batch Loss: 6.0794889577664435e-05\n",
      "Epoch 1468, Loss: 0.12365134712308645, Final Batch Loss: 0.009544101543724537\n",
      "Epoch 1469, Loss: 0.20726464316248894, Final Batch Loss: 0.11622966825962067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1470, Loss: 0.11659062572289258, Final Batch Loss: 0.00046456989366561174\n",
      "Epoch 1471, Loss: 0.17505287006497383, Final Batch Loss: 0.08636286854743958\n",
      "Epoch 1472, Loss: 0.06689583047409542, Final Batch Loss: 0.00019762947340495884\n",
      "Epoch 1473, Loss: 0.06884189388074446, Final Batch Loss: 0.00013159839727450162\n",
      "Epoch 1474, Loss: 0.15123231353936717, Final Batch Loss: 0.0006161222117953002\n",
      "Epoch 1475, Loss: 0.13305700570344925, Final Batch Loss: 0.003927495330572128\n",
      "Epoch 1476, Loss: 0.09392191201914102, Final Batch Loss: 0.0018929197685793042\n",
      "Epoch 1477, Loss: 0.09044388076290488, Final Batch Loss: 0.020095447078347206\n",
      "Epoch 1478, Loss: 0.07121767848730087, Final Batch Loss: 0.0\n",
      "Epoch 1479, Loss: 0.1158257694914937, Final Batch Loss: 0.05667343735694885\n",
      "Epoch 1480, Loss: 0.08788317628204823, Final Batch Loss: 0.0\n",
      "Epoch 1481, Loss: 0.09009066596399862, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1482, Loss: 0.12598613882437348, Final Batch Loss: 0.0030900132842361927\n",
      "Epoch 1483, Loss: 0.1200455091893673, Final Batch Loss: 0.0\n",
      "Epoch 1484, Loss: 0.0894004859146662, Final Batch Loss: 0.0008578196284361184\n",
      "Epoch 1485, Loss: 0.10593512747436762, Final Batch Loss: 0.0\n",
      "Epoch 1486, Loss: 0.07189689856022596, Final Batch Loss: 0.0\n",
      "Epoch 1487, Loss: 0.09485732342363917, Final Batch Loss: 3.135155202471651e-05\n",
      "Epoch 1488, Loss: 0.08749670162796974, Final Batch Loss: 0.0\n",
      "Epoch 1489, Loss: 0.10881531340419315, Final Batch Loss: 0.00030489088385365903\n",
      "Epoch 1490, Loss: 0.09068746748380363, Final Batch Loss: 0.0005614373367279768\n",
      "Epoch 1491, Loss: 0.1027268678881228, Final Batch Loss: 0.007365808356553316\n",
      "Epoch 1492, Loss: 0.14948280341923237, Final Batch Loss: 0.06688141822814941\n",
      "Epoch 1493, Loss: 0.08332823842647485, Final Batch Loss: 0.00013147920253686607\n",
      "Epoch 1494, Loss: 0.11335586942732334, Final Batch Loss: 0.017749400809407234\n",
      "Epoch 1495, Loss: 0.06905162800103426, Final Batch Loss: 0.0\n",
      "Epoch 1496, Loss: 0.09402321183824824, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 1497, Loss: 0.059268062585033476, Final Batch Loss: 0.0016628975281491876\n",
      "Epoch 1498, Loss: 0.089642733335495, Final Batch Loss: 0.0\n",
      "Epoch 1499, Loss: 0.06650099670412146, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1500, Loss: 0.07395268222899176, Final Batch Loss: 0.0002698534226510674\n",
      "Epoch 1501, Loss: 0.07633456061012112, Final Batch Loss: 0.0004351384413894266\n",
      "Epoch 1502, Loss: 0.10987754537836736, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 1503, Loss: 0.05958272214047611, Final Batch Loss: 0.00020811776630580425\n",
      "Epoch 1504, Loss: 0.07488915052090306, Final Batch Loss: 0.00019739109848160297\n",
      "Epoch 1505, Loss: 0.12363211414776742, Final Batch Loss: 0.003137429943308234\n",
      "Epoch 1506, Loss: 0.07010025528506958, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 1507, Loss: 0.06960348191205412, Final Batch Loss: 0.00032550760079175234\n",
      "Epoch 1508, Loss: 0.0761984453201876, Final Batch Loss: 6.592056161025539e-05\n",
      "Epoch 1509, Loss: 0.0698321929667145, Final Batch Loss: 0.002240411238744855\n",
      "Epoch 1510, Loss: 0.09040453768102452, Final Batch Loss: 9.464769391342998e-05\n",
      "Epoch 1511, Loss: 0.0824946885695681, Final Batch Loss: 0.000406301929615438\n",
      "Epoch 1512, Loss: 0.08850904850987718, Final Batch Loss: 0.0006915323319844902\n",
      "Epoch 1513, Loss: 0.05359591683372855, Final Batch Loss: 0.0028139064088463783\n",
      "Epoch 1514, Loss: 0.21011718921363354, Final Batch Loss: 0.13109757006168365\n",
      "Epoch 1515, Loss: 0.08516347853583284, Final Batch Loss: 0.00037925204378552735\n",
      "Epoch 1516, Loss: 0.07866880047367886, Final Batch Loss: 0.0006597249885089695\n",
      "Epoch 1517, Loss: 0.07466478674905375, Final Batch Loss: 0.00024673278676345944\n",
      "Epoch 1518, Loss: 0.07760847639291768, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1519, Loss: 0.2505878247320652, Final Batch Loss: 0.1761762946844101\n",
      "Epoch 1520, Loss: 0.10481707549843122, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 1521, Loss: 0.08977537602186203, Final Batch Loss: 0.0\n",
      "Epoch 1522, Loss: 0.07995113390643382, Final Batch Loss: 5.543078441405669e-05\n",
      "Epoch 1523, Loss: 0.09998227329924703, Final Batch Loss: 0.00914740189909935\n",
      "Epoch 1524, Loss: 0.08731088577769697, Final Batch Loss: 2.1576648578047752e-05\n",
      "Epoch 1525, Loss: 0.05756479559931904, Final Batch Loss: 7.92710343375802e-05\n",
      "Epoch 1526, Loss: 0.04655403585638851, Final Batch Loss: 0.0010938619961962104\n",
      "Epoch 1527, Loss: 0.0766131365661522, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1528, Loss: 0.08863339782692492, Final Batch Loss: 0.0033233908470720053\n",
      "Epoch 1529, Loss: 0.07505960988783045, Final Batch Loss: 6.913899414939806e-05\n",
      "Epoch 1530, Loss: 0.07976162047998514, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 1531, Loss: 0.12188764847815037, Final Batch Loss: 0.04954777657985687\n",
      "Epoch 1532, Loss: 0.05920327827334404, Final Batch Loss: 0.0\n",
      "Epoch 1533, Loss: 0.06868189747910947, Final Batch Loss: 0.0016498061595484614\n",
      "Epoch 1534, Loss: 0.07210209959885105, Final Batch Loss: 0.0006672301678918302\n",
      "Epoch 1535, Loss: 0.08016719945680961, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 1536, Loss: 0.07505740612759837, Final Batch Loss: 2.5152843591058627e-05\n",
      "Epoch 1537, Loss: 0.08223682641971664, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1538, Loss: 0.11186741478741169, Final Batch Loss: 0.04706179350614548\n",
      "Epoch 1539, Loss: 0.0896670489164535, Final Batch Loss: 0.000359351426595822\n",
      "Epoch 1540, Loss: 0.19400356151163578, Final Batch Loss: 0.13127772510051727\n",
      "Epoch 1541, Loss: 0.07942959107458591, Final Batch Loss: 0.0\n",
      "Epoch 1542, Loss: 0.09277979098260403, Final Batch Loss: 0.0\n",
      "Epoch 1543, Loss: 0.10459712240844965, Final Batch Loss: 0.044225580990314484\n",
      "Epoch 1544, Loss: 0.06149089243263006, Final Batch Loss: 0.0\n",
      "Epoch 1545, Loss: 0.07132471863405954, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1546, Loss: 0.09388687834120901, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1547, Loss: 0.05688776180613786, Final Batch Loss: 0.000243634101934731\n",
      "Epoch 1548, Loss: 0.07424205914139748, Final Batch Loss: 0.0\n",
      "Epoch 1549, Loss: 0.07737462501427217, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 1550, Loss: 0.04609064199030399, Final Batch Loss: 0.0\n",
      "Epoch 1551, Loss: 0.08357527572661638, Final Batch Loss: 0.0\n",
      "Epoch 1552, Loss: 0.07099759712764353, Final Batch Loss: 1.0609570381348021e-05\n",
      "Epoch 1553, Loss: 0.057204035493668925, Final Batch Loss: 1.2874520507466514e-05\n",
      "Epoch 1554, Loss: 0.07265588136579026, Final Batch Loss: 5.1377883210079744e-05\n",
      "Epoch 1555, Loss: 0.09067769721150398, Final Batch Loss: 0.03005562722682953\n",
      "Epoch 1556, Loss: 0.1550767095759511, Final Batch Loss: 0.07980756461620331\n",
      "Epoch 1557, Loss: 0.06784537434577942, Final Batch Loss: 0.0\n",
      "Epoch 1558, Loss: 0.07985296520928387, Final Batch Loss: 0.00012194366718176752\n",
      "Epoch 1559, Loss: 0.07279718853533268, Final Batch Loss: 0.0\n",
      "Epoch 1560, Loss: 0.08682040125131607, Final Batch Loss: 0.0\n",
      "Epoch 1561, Loss: 0.0765137792996029, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 1562, Loss: 0.07553337319222919, Final Batch Loss: 1.3351351299206726e-05\n",
      "Epoch 1563, Loss: 0.09211942180990462, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1564, Loss: 0.1360804894939065, Final Batch Loss: 0.06885408610105515\n",
      "Epoch 1565, Loss: 0.07349339430220425, Final Batch Loss: 0.0011175584513694048\n",
      "Epoch 1566, Loss: 0.0989456344395876, Final Batch Loss: 0.0012868703342974186\n",
      "Epoch 1567, Loss: 0.04860062664374709, Final Batch Loss: 0.005632007960230112\n",
      "Epoch 1568, Loss: 0.04462529794545844, Final Batch Loss: 0.0006702084210701287\n",
      "Epoch 1569, Loss: 0.06811859272420406, Final Batch Loss: 0.0\n",
      "Epoch 1570, Loss: 0.06465550162829459, Final Batch Loss: 0.001985484967008233\n",
      "Epoch 1571, Loss: 0.06185722694499418, Final Batch Loss: 0.00017426878912374377\n",
      "Epoch 1572, Loss: 0.0680418302945327, Final Batch Loss: 8.666139910928905e-05\n",
      "Epoch 1573, Loss: 0.06301822966815962, Final Batch Loss: 1.5616295058862306e-05\n",
      "Epoch 1574, Loss: 0.07100112664920744, Final Batch Loss: 3.7788631743751466e-05\n",
      "Epoch 1575, Loss: 0.06329574622088785, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1576, Loss: 0.06081823476415593, Final Batch Loss: 0.00013767725613433868\n",
      "Epoch 1577, Loss: 0.061616704100742936, Final Batch Loss: 0.0013402060139924288\n",
      "Epoch 1578, Loss: 0.0737446928396821, Final Batch Loss: 0.004687985870987177\n",
      "Epoch 1579, Loss: 0.053876257385127246, Final Batch Loss: 0.00083078199531883\n",
      "Epoch 1580, Loss: 0.08117956409114413, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 1581, Loss: 0.11184151004999876, Final Batch Loss: 0.0\n",
      "Epoch 1582, Loss: 0.058790583628933746, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1583, Loss: 0.06665633059787979, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1584, Loss: 0.06886159966234118, Final Batch Loss: 0.0013830630341544747\n",
      "Epoch 1585, Loss: 0.07438507756160107, Final Batch Loss: 0.00018880968855228275\n",
      "Epoch 1586, Loss: 0.07857730425803311, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1587, Loss: 0.06841235398314893, Final Batch Loss: 0.0\n",
      "Epoch 1588, Loss: 0.07216430734843016, Final Batch Loss: 0.0\n",
      "Epoch 1589, Loss: 0.06018013639277342, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 1590, Loss: 0.06509947218000889, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591, Loss: 0.08456443156842397, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1592, Loss: 0.05107803920009246, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 1593, Loss: 0.060241399332880974, Final Batch Loss: 0.0\n",
      "Epoch 1594, Loss: 0.05152685090251907, Final Batch Loss: 1.537788011773955e-05\n",
      "Epoch 1595, Loss: 0.07983553933263465, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 1596, Loss: 0.059569005854427814, Final Batch Loss: 0.0\n",
      "Epoch 1597, Loss: 0.07159612979717167, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1598, Loss: 0.05419383681146428, Final Batch Loss: 0.0008174415561370552\n",
      "Epoch 1599, Loss: 0.049758159555494785, Final Batch Loss: 0.001215077005326748\n",
      "Epoch 1600, Loss: 0.7469481658190489, Final Batch Loss: 0.6699728965759277\n",
      "Epoch 1601, Loss: 0.08395798987476155, Final Batch Loss: 0.0009704885887913406\n",
      "Epoch 1602, Loss: 0.11156835033216339, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 1603, Loss: 0.09895122476154938, Final Batch Loss: 0.0005683475756086409\n",
      "Epoch 1604, Loss: 0.16092099400702864, Final Batch Loss: 0.0011693552369251847\n",
      "Epoch 1605, Loss: 0.16296085715293174, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1606, Loss: 0.10131941363215446, Final Batch Loss: 0.001729065552353859\n",
      "Epoch 1607, Loss: 0.15344198764069006, Final Batch Loss: 0.0007601470570079982\n",
      "Epoch 1608, Loss: 0.09840954336686991, Final Batch Loss: 0.00019012074335478246\n",
      "Epoch 1609, Loss: 0.09921835083513741, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1610, Loss: 0.11184405721721191, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1611, Loss: 0.07514771644491702, Final Batch Loss: 0.0005946775199845433\n",
      "Epoch 1612, Loss: 0.09267482534050941, Final Batch Loss: 0.0005995621904730797\n",
      "Epoch 1613, Loss: 0.10463279951363802, Final Batch Loss: 0.019408905878663063\n",
      "Epoch 1614, Loss: 0.08613595133647323, Final Batch Loss: 0.005021341610699892\n",
      "Epoch 1615, Loss: 0.06054252665489912, Final Batch Loss: 0.0\n",
      "Epoch 1616, Loss: 0.07212544459616765, Final Batch Loss: 0.0006246999255381525\n",
      "Epoch 1617, Loss: 0.0711635947227478, Final Batch Loss: 0.0\n",
      "Epoch 1618, Loss: 0.05071221571415663, Final Batch Loss: 0.0\n",
      "Epoch 1619, Loss: 0.08389660192187876, Final Batch Loss: 0.0002308817347511649\n",
      "Epoch 1620, Loss: 0.09734648000448942, Final Batch Loss: 0.024324659258127213\n",
      "Epoch 1621, Loss: 0.13184657879173756, Final Batch Loss: 0.036031678318977356\n",
      "Epoch 1622, Loss: 0.07853849604725838, Final Batch Loss: 0.0\n",
      "Epoch 1623, Loss: 0.060432673897594213, Final Batch Loss: 0.009143149480223656\n",
      "Epoch 1624, Loss: 0.048335577826946974, Final Batch Loss: 0.0\n",
      "Epoch 1625, Loss: 0.0739029641263187, Final Batch Loss: 0.0\n",
      "Epoch 1626, Loss: 0.07432524043542799, Final Batch Loss: 0.0001658063702052459\n",
      "Epoch 1627, Loss: 0.07473541051149368, Final Batch Loss: 0.0024725599214434624\n",
      "Epoch 1628, Loss: 0.07509010285139084, Final Batch Loss: 0.0\n",
      "Epoch 1629, Loss: 0.058858166448771954, Final Batch Loss: 0.0\n",
      "Epoch 1630, Loss: 0.0655286093824543, Final Batch Loss: 0.00012540031457319856\n",
      "Epoch 1631, Loss: 0.08366836025379598, Final Batch Loss: 0.0005841932725161314\n",
      "Epoch 1632, Loss: 0.07987525494991132, Final Batch Loss: 1.0371154530730564e-05\n",
      "Epoch 1633, Loss: 0.05960483127273619, Final Batch Loss: 0.0\n",
      "Epoch 1634, Loss: 0.06944022048247689, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1635, Loss: 0.08222283446229994, Final Batch Loss: 0.0016797969583421946\n",
      "Epoch 1636, Loss: 0.08554031420496244, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1637, Loss: 0.09220975171768941, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1638, Loss: 0.04917248387937434, Final Batch Loss: 0.00034648136352188885\n",
      "Epoch 1639, Loss: 0.06529453629627824, Final Batch Loss: 0.003977127838879824\n",
      "Epoch 1640, Loss: 0.06351494509726763, Final Batch Loss: 0.0\n",
      "Epoch 1641, Loss: 0.1804473279044032, Final Batch Loss: 0.11745937168598175\n",
      "Epoch 1642, Loss: 0.056507528643123806, Final Batch Loss: 0.001035749795846641\n",
      "Epoch 1643, Loss: 0.05460003034386318, Final Batch Loss: 0.0002150304353563115\n",
      "Epoch 1644, Loss: 0.07215827794971119, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1645, Loss: 0.06829146447125822, Final Batch Loss: 0.0002775999018922448\n",
      "Epoch 1646, Loss: 0.06732582394016617, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 1647, Loss: 0.046092934790067375, Final Batch Loss: 0.0005322470096871257\n",
      "Epoch 1648, Loss: 0.06620405908688554, Final Batch Loss: 5.8530047681415454e-05\n",
      "Epoch 1649, Loss: 0.07220991421490908, Final Batch Loss: 0.0\n",
      "Epoch 1650, Loss: 0.11313995905220509, Final Batch Loss: 0.05912499502301216\n",
      "Epoch 1651, Loss: 0.07083498127758503, Final Batch Loss: 0.0\n",
      "Epoch 1652, Loss: 0.0894239102276515, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 1653, Loss: 0.05784476210101275, Final Batch Loss: 3.433168603805825e-05\n",
      "Epoch 1654, Loss: 0.06481603624524723, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1655, Loss: 0.07327684387564659, Final Batch Loss: 0.0033456087112426758\n",
      "Epoch 1656, Loss: 0.06482681652414612, Final Batch Loss: 0.00029202012228779495\n",
      "Epoch 1657, Loss: 0.06927490001544356, Final Batch Loss: 0.0\n",
      "Epoch 1658, Loss: 0.08701535686839179, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1659, Loss: 0.053573840286389895, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 1660, Loss: 0.08060027379542589, Final Batch Loss: 0.002845288719981909\n",
      "Epoch 1661, Loss: 0.0835392955050338, Final Batch Loss: 2.95634672511369e-05\n",
      "Epoch 1662, Loss: 0.05993034830316901, Final Batch Loss: 0.0\n",
      "Epoch 1663, Loss: 0.08158014621585608, Final Batch Loss: 0.009016276337206364\n",
      "Epoch 1664, Loss: 0.08797947422135621, Final Batch Loss: 0.0010471820132806897\n",
      "Epoch 1665, Loss: 0.07437376303869314, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 1666, Loss: 0.07032063926453702, Final Batch Loss: 0.000226472009671852\n",
      "Epoch 1667, Loss: 0.06989531634826562, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 1668, Loss: 0.05268284032354131, Final Batch Loss: 0.0005788319394923747\n",
      "Epoch 1669, Loss: 0.06814729608584003, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1670, Loss: 0.08971499186006326, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1671, Loss: 0.051330993805095204, Final Batch Loss: 1.2516897186287679e-05\n",
      "Epoch 1672, Loss: 0.05699452944099903, Final Batch Loss: 0.0\n",
      "Epoch 1673, Loss: 0.06830129958621001, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 1674, Loss: 0.07026846893131022, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1675, Loss: 0.06809593171055894, Final Batch Loss: 0.00019810620869975537\n",
      "Epoch 1676, Loss: 0.08860096506032278, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 1677, Loss: 0.07471878622891381, Final Batch Loss: 0.0005199749139137566\n",
      "Epoch 1678, Loss: 0.056862736819311976, Final Batch Loss: 0.0010010951664298773\n",
      "Epoch 1679, Loss: 0.049469605553895235, Final Batch Loss: 0.0010468247346580029\n",
      "Epoch 1680, Loss: 0.07238311261244235, Final Batch Loss: 3.4450891689630225e-05\n",
      "Epoch 1681, Loss: 0.06477133836494886, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 1682, Loss: 0.09162788093090057, Final Batch Loss: 0.010386933572590351\n",
      "Epoch 1683, Loss: 0.0724288085475564, Final Batch Loss: 0.0\n",
      "Epoch 1684, Loss: 0.05991666566114873, Final Batch Loss: 0.0002520958660170436\n",
      "Epoch 1685, Loss: 0.07099420542363077, Final Batch Loss: 0.0015843469882383943\n",
      "Epoch 1686, Loss: 0.062425313517451286, Final Batch Loss: 0.0\n",
      "Epoch 1687, Loss: 0.052678310486953706, Final Batch Loss: 3.886147169396281e-05\n",
      "Epoch 1688, Loss: 0.06891494360752404, Final Batch Loss: 0.0006205302197486162\n",
      "Epoch 1689, Loss: 0.06940099166240543, Final Batch Loss: 8.761498611420393e-05\n",
      "Epoch 1690, Loss: 0.048462885431945324, Final Batch Loss: 0.0\n",
      "Epoch 1691, Loss: 0.07207580760587007, Final Batch Loss: 0.00033945043105632067\n",
      "Epoch 1692, Loss: 0.0759656373411417, Final Batch Loss: 0.0\n",
      "Epoch 1693, Loss: 0.06626064900774509, Final Batch Loss: 0.001353420433588326\n",
      "Epoch 1694, Loss: 0.09091063030064106, Final Batch Loss: 0.0012081712484359741\n",
      "Epoch 1695, Loss: 0.05932430271059275, Final Batch Loss: 0.0\n",
      "Epoch 1696, Loss: 0.5185397602617741, Final Batch Loss: 0.445587158203125\n",
      "Epoch 1697, Loss: 0.12464437168091536, Final Batch Loss: 0.031202396377921104\n",
      "Epoch 1698, Loss: 0.20416580513119698, Final Batch Loss: 0.01991947367787361\n",
      "Epoch 1699, Loss: 0.28394985292106867, Final Batch Loss: 0.004005030728876591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1700, Loss: 0.19571017573980498, Final Batch Loss: 4.1483970562694594e-05\n",
      "Epoch 1701, Loss: 0.17738965526223183, Final Batch Loss: 0.0\n",
      "Epoch 1702, Loss: 0.0958054248476401, Final Batch Loss: 0.0005859803641214967\n",
      "Epoch 1703, Loss: 0.09108026696594607, Final Batch Loss: 5.722029527532868e-06\n",
      "Epoch 1704, Loss: 0.08604075433685665, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1705, Loss: 0.06860753896762617, Final Batch Loss: 0.00047755756531842053\n",
      "Epoch 1706, Loss: 0.07940674502606271, Final Batch Loss: 7.164221460698172e-05\n",
      "Epoch 1707, Loss: 0.08120394684374332, Final Batch Loss: 0.0\n",
      "Epoch 1708, Loss: 0.09018982565612532, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 1709, Loss: 0.07370669200463453, Final Batch Loss: 7.581423415103927e-05\n",
      "Epoch 1710, Loss: 0.09833692526444793, Final Batch Loss: 0.0\n",
      "Epoch 1711, Loss: 0.0791142611997202, Final Batch Loss: 0.0018161722691729665\n",
      "Epoch 1712, Loss: 0.06982828956096654, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1713, Loss: 0.0844392791041173, Final Batch Loss: 0.0003299168893136084\n",
      "Epoch 1714, Loss: 0.05162035736429971, Final Batch Loss: 6.580135959666222e-05\n",
      "Epoch 1715, Loss: 0.06786073022522032, Final Batch Loss: 0.0034091707784682512\n",
      "Epoch 1716, Loss: 0.06782895333890337, Final Batch Loss: 0.00010501786891836673\n",
      "Epoch 1717, Loss: 0.07435042038559914, Final Batch Loss: 0.0\n",
      "Epoch 1718, Loss: 0.14350756537169218, Final Batch Loss: 0.0868287906050682\n",
      "Epoch 1719, Loss: 0.09545527212321758, Final Batch Loss: 0.0\n",
      "Epoch 1720, Loss: 0.07437210786156356, Final Batch Loss: 0.000797192333266139\n",
      "Epoch 1721, Loss: 0.06147515040356666, Final Batch Loss: 0.00167598866391927\n",
      "Epoch 1722, Loss: 0.06217345199547708, Final Batch Loss: 0.003821927821263671\n",
      "Epoch 1723, Loss: 0.08065522185643204, Final Batch Loss: 6.05564855504781e-05\n",
      "Epoch 1724, Loss: 0.07551353611006562, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1725, Loss: 0.07673608665936626, Final Batch Loss: 2.52720492426306e-05\n",
      "Epoch 1726, Loss: 1.0156319849193096, Final Batch Loss: 0.9724597930908203\n",
      "Epoch 1727, Loss: 0.12428744591306895, Final Batch Loss: 0.00047100416850298643\n",
      "Epoch 1728, Loss: 0.30663651158101857, Final Batch Loss: 0.003008722560480237\n",
      "Epoch 1729, Loss: 0.5020132130885031, Final Batch Loss: 0.00030179237364791334\n",
      "Epoch 1730, Loss: 0.47511536185629666, Final Batch Loss: 0.0016891986597329378\n",
      "Epoch 1731, Loss: 0.46659788489250786, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 1732, Loss: 0.29214268550276756, Final Batch Loss: 0.0\n",
      "Epoch 1733, Loss: 0.2158651766658295, Final Batch Loss: 0.0004303721070755273\n",
      "Epoch 1734, Loss: 0.16256125643849373, Final Batch Loss: 0.0\n",
      "Epoch 1735, Loss: 0.15651237429119647, Final Batch Loss: 0.0018374717328697443\n",
      "Epoch 1736, Loss: 0.12041154340840876, Final Batch Loss: 0.001263773301616311\n",
      "Epoch 1737, Loss: 0.10970168700441718, Final Batch Loss: 0.002592181321233511\n",
      "Epoch 1738, Loss: 0.12439936771511384, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 1739, Loss: 0.11656692654651124, Final Batch Loss: 0.00011955977242905647\n",
      "Epoch 1740, Loss: 0.08659557439386845, Final Batch Loss: 0.0\n",
      "Epoch 1741, Loss: 0.09565146826207638, Final Batch Loss: 0.0\n",
      "Epoch 1742, Loss: 0.09946180763654411, Final Batch Loss: 0.0008469808381050825\n",
      "Epoch 1743, Loss: 0.6399036254733801, Final Batch Loss: 0.5440608859062195\n",
      "Epoch 1744, Loss: 0.07378159509971738, Final Batch Loss: 0.0007493072189390659\n",
      "Epoch 1745, Loss: 0.17676305398344994, Final Batch Loss: 0.04955696314573288\n",
      "Epoch 1746, Loss: 0.16877687330816116, Final Batch Loss: 1.9550132492440753e-05\n",
      "Epoch 1747, Loss: 0.10684207263420831, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 1748, Loss: 0.13402344658970833, Final Batch Loss: 0.007077503949403763\n",
      "Epoch 1749, Loss: 0.12019947078078985, Final Batch Loss: 0.005847134627401829\n",
      "Epoch 1750, Loss: 0.09634288139932323, Final Batch Loss: 0.00011252723925281316\n",
      "Epoch 1751, Loss: 0.0879022520093713, Final Batch Loss: 0.00040391870425082743\n",
      "Epoch 1752, Loss: 0.0783923912094906, Final Batch Loss: 0.001716570113785565\n",
      "Epoch 1753, Loss: 0.09852444846183062, Final Batch Loss: 0.0018436592072248459\n",
      "Epoch 1754, Loss: 0.14019659343739477, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 1755, Loss: 0.08932605618610978, Final Batch Loss: 0.0015135272406041622\n",
      "Epoch 1756, Loss: 0.07121841527987272, Final Batch Loss: 0.0015969631494954228\n",
      "Epoch 1757, Loss: 0.07151170072029345, Final Batch Loss: 0.00046885941992513835\n",
      "Epoch 1758, Loss: 0.0722953854123034, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 1759, Loss: 0.10567245970014483, Final Batch Loss: 0.0003182381624355912\n",
      "Epoch 1760, Loss: 0.06432820484042168, Final Batch Loss: 0.0\n",
      "Epoch 1761, Loss: 0.09011882357298617, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1762, Loss: 0.07105035148561001, Final Batch Loss: 0.0\n",
      "Epoch 1763, Loss: 0.08640395665861433, Final Batch Loss: 0.00010549465514486656\n",
      "Epoch 1764, Loss: 0.08265236392617226, Final Batch Loss: 0.0\n",
      "Epoch 1765, Loss: 0.7580940062180161, Final Batch Loss: 0.6611770987510681\n",
      "Epoch 1766, Loss: 0.09933867491781712, Final Batch Loss: 0.020045438781380653\n",
      "Epoch 1767, Loss: 0.12233391543850303, Final Batch Loss: 0.002482192125171423\n",
      "Epoch 1768, Loss: 0.12363335318514146, Final Batch Loss: 0.00014852374442853034\n",
      "Epoch 1769, Loss: 0.1205831696279347, Final Batch Loss: 0.004659390542656183\n",
      "Epoch 1770, Loss: 0.1192278265953064, Final Batch Loss: 0.0\n",
      "Epoch 1771, Loss: 0.10700341314077377, Final Batch Loss: 0.0\n",
      "Epoch 1772, Loss: 0.08688209019595661, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1773, Loss: 0.10550978220999241, Final Batch Loss: 0.0\n",
      "Epoch 1774, Loss: 0.09834607969969511, Final Batch Loss: 0.0\n",
      "Epoch 1775, Loss: 0.12598690763070408, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 1776, Loss: 0.07938981897314079, Final Batch Loss: 6.05564855504781e-05\n",
      "Epoch 1777, Loss: 0.05655753239989281, Final Batch Loss: 0.0\n",
      "Epoch 1778, Loss: 0.08051633263676194, Final Batch Loss: 1.5735502529423684e-05\n",
      "Epoch 1779, Loss: 0.10177276630383858, Final Batch Loss: 2.2649508537142538e-05\n",
      "Epoch 1780, Loss: 0.07526545412838459, Final Batch Loss: 0.0\n",
      "Epoch 1781, Loss: 0.08406471272337512, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 1782, Loss: 0.08344820328056812, Final Batch Loss: 0.002419760450720787\n",
      "Epoch 1783, Loss: 0.07027001492679119, Final Batch Loss: 0.0\n",
      "Epoch 1784, Loss: 0.06987416464835405, Final Batch Loss: 0.006816585548222065\n",
      "Epoch 1785, Loss: 0.07572537733722129, Final Batch Loss: 4.756337511935271e-05\n",
      "Epoch 1786, Loss: 0.08145539090037346, Final Batch Loss: 0.0007980260998010635\n",
      "Epoch 1787, Loss: 0.08850741712376475, Final Batch Loss: 0.0032624374143779278\n",
      "Epoch 1788, Loss: 0.0792678942088969, Final Batch Loss: 0.00017093151109293103\n",
      "Epoch 1789, Loss: 0.060543247032910585, Final Batch Loss: 0.0005311747081577778\n",
      "Epoch 1790, Loss: 0.08253288366358902, Final Batch Loss: 2.90866428258596e-05\n",
      "Epoch 1791, Loss: 0.05635869762045331, Final Batch Loss: 0.000433112756581977\n",
      "Epoch 1792, Loss: 0.056091280523105524, Final Batch Loss: 5.531158240046352e-05\n",
      "Epoch 1793, Loss: 0.06290029268711805, Final Batch Loss: 0.0\n",
      "Epoch 1794, Loss: 0.06605585478245501, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1795, Loss: 0.09231842309236526, Final Batch Loss: 0.011500492691993713\n",
      "Epoch 1796, Loss: 0.0776172988844337, Final Batch Loss: 8.546940807718784e-05\n",
      "Epoch 1797, Loss: 0.06972944224252586, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1798, Loss: 0.1033283848373685, Final Batch Loss: 0.000102037942269817\n",
      "Epoch 1799, Loss: 0.0821484001353383, Final Batch Loss: 0.0\n",
      "Epoch 1800, Loss: 0.08720289915549984, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 1801, Loss: 0.06544847487020888, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 1802, Loss: 0.06804324965912656, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 1803, Loss: 0.06946550123393536, Final Batch Loss: 0.0002862997353076935\n",
      "Epoch 1804, Loss: 0.07251446694135666, Final Batch Loss: 0.0\n",
      "Epoch 1805, Loss: 0.0824520904570818, Final Batch Loss: 0.002338058315217495\n",
      "Epoch 1806, Loss: 0.08577261515893042, Final Batch Loss: 0.0006541258189827204\n",
      "Epoch 1807, Loss: 0.06183403357863426, Final Batch Loss: 0.0\n",
      "Epoch 1808, Loss: 0.08247803372796625, Final Batch Loss: 0.0014869834994897246\n",
      "Epoch 1809, Loss: 0.06864248687634245, Final Batch Loss: 0.0005650115781463683\n",
      "Epoch 1810, Loss: 0.08725385553361775, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 1811, Loss: 0.05626014608424157, Final Batch Loss: 0.0006074252305552363\n",
      "Epoch 1812, Loss: 0.05317505821585655, Final Batch Loss: 0.0\n",
      "Epoch 1813, Loss: 0.06447052594739944, Final Batch Loss: 0.0010319390567019582\n",
      "Epoch 1814, Loss: 0.10579745285212994, Final Batch Loss: 0.019658612087368965\n",
      "Epoch 1815, Loss: 0.05774081265553832, Final Batch Loss: 0.0\n",
      "Epoch 1816, Loss: 0.059757267124950886, Final Batch Loss: 0.0038347532972693443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1817, Loss: 0.05667022743728012, Final Batch Loss: 0.001508409040980041\n",
      "Epoch 1818, Loss: 0.06045562215143718, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1819, Loss: 0.07132923137396574, Final Batch Loss: 0.0\n",
      "Epoch 1820, Loss: 0.055397446267306805, Final Batch Loss: 0.0\n",
      "Epoch 1821, Loss: 0.05320235155522823, Final Batch Loss: 0.0\n",
      "Epoch 1822, Loss: 0.07337164877708346, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 1823, Loss: 0.05239748512394726, Final Batch Loss: 0.0011049362365156412\n",
      "Epoch 1824, Loss: 0.0572058348916471, Final Batch Loss: 0.0\n",
      "Epoch 1825, Loss: 0.14875589637085795, Final Batch Loss: 0.088243268430233\n",
      "Epoch 1826, Loss: 0.07392424205318093, Final Batch Loss: 0.0058683487586677074\n",
      "Epoch 1827, Loss: 0.07309849186640349, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 1828, Loss: 0.075336510737543, Final Batch Loss: 6.890059739816934e-05\n",
      "Epoch 1829, Loss: 0.09669015754479915, Final Batch Loss: 0.0013993718894198537\n",
      "Epoch 1830, Loss: 0.0915699404431507, Final Batch Loss: 1.5258672647178173e-05\n",
      "Epoch 1831, Loss: 0.06166909582680091, Final Batch Loss: 0.0005701346672140062\n",
      "Epoch 1832, Loss: 0.04376015951856971, Final Batch Loss: 0.0\n",
      "Epoch 1833, Loss: 0.04666952742263675, Final Batch Loss: 0.0\n",
      "Epoch 1834, Loss: 0.05531942658126354, Final Batch Loss: 0.0\n",
      "Epoch 1835, Loss: 0.05282839573101228, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 1836, Loss: 0.05188600346446037, Final Batch Loss: 0.0\n",
      "Epoch 1837, Loss: 0.05889949668198824, Final Batch Loss: 0.006262322422116995\n",
      "Epoch 1838, Loss: 0.04789971373975277, Final Batch Loss: 0.0\n",
      "Epoch 1839, Loss: 0.061257146298885345, Final Batch Loss: 0.008425640873610973\n",
      "Epoch 1840, Loss: 0.06134944502264261, Final Batch Loss: 0.0\n",
      "Epoch 1841, Loss: 0.06491193120018579, Final Batch Loss: 5.447716102935374e-05\n",
      "Epoch 1842, Loss: 0.05687489965930581, Final Batch Loss: 0.0\n",
      "Epoch 1843, Loss: 0.058161208406090736, Final Batch Loss: 0.0\n",
      "Epoch 1844, Loss: 0.08181402238551527, Final Batch Loss: 0.0007200032705441117\n",
      "Epoch 1845, Loss: 0.05415572097990662, Final Batch Loss: 0.0009447640040889382\n",
      "Epoch 1846, Loss: 0.0734757287427783, Final Batch Loss: 0.0\n",
      "Epoch 1847, Loss: 0.03805294097401202, Final Batch Loss: 0.0002450642641633749\n",
      "Epoch 1848, Loss: 0.08949550427496433, Final Batch Loss: 0.019512606784701347\n",
      "Epoch 1849, Loss: 0.05757911409978078, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 1850, Loss: 0.03950148168951273, Final Batch Loss: 0.0\n",
      "Epoch 1851, Loss: 0.04532620124518871, Final Batch Loss: 0.0\n",
      "Epoch 1852, Loss: 0.04298608563840389, Final Batch Loss: 0.002913280390202999\n",
      "Epoch 1853, Loss: 0.07163607142859973, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1854, Loss: 0.09362026117742062, Final Batch Loss: 0.025388993322849274\n",
      "Epoch 1855, Loss: 0.06280677858194395, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 1856, Loss: 0.046588623896212766, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1857, Loss: 0.06971692387014627, Final Batch Loss: 0.0\n",
      "Epoch 1858, Loss: 0.07486644531309139, Final Batch Loss: 0.00013267113536130637\n",
      "Epoch 1859, Loss: 0.0524603787343878, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1860, Loss: 0.05486545851454139, Final Batch Loss: 0.0043060919269919395\n",
      "Epoch 1861, Loss: 0.03328764680918539, Final Batch Loss: 0.00010918975021922961\n",
      "Epoch 1862, Loss: 0.055967979133072276, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1863, Loss: 3.4763145544566214, Final Batch Loss: 3.4349892139434814\n",
      "Epoch 1864, Loss: 0.07808139162807493, Final Batch Loss: 8.77341881277971e-05\n",
      "Epoch 1865, Loss: 0.44087598379701376, Final Batch Loss: 0.004604688845574856\n",
      "Epoch 1866, Loss: 0.6559868156909943, Final Batch Loss: 0.0\n",
      "Epoch 1867, Loss: 1.0667206645011902, Final Batch Loss: 0.4268885850906372\n",
      "Epoch 1868, Loss: 0.2871534153819084, Final Batch Loss: 0.026227407157421112\n",
      "Epoch 1869, Loss: 0.13069531376822852, Final Batch Loss: 0.00038938093348406255\n",
      "Epoch 1870, Loss: 0.10507615603273734, Final Batch Loss: 0.0005766874528490007\n",
      "Epoch 1871, Loss: 0.10907871089875698, Final Batch Loss: 0.016970420256257057\n",
      "Epoch 1872, Loss: 0.143609625287354, Final Batch Loss: 0.00566448736935854\n",
      "Epoch 1873, Loss: 0.10251330863684416, Final Batch Loss: 0.0\n",
      "Epoch 1874, Loss: 0.10268656335574633, Final Batch Loss: 1.7404405298293568e-05\n",
      "Epoch 1875, Loss: 0.12279751776077319, Final Batch Loss: 9.929640509653836e-05\n",
      "Epoch 1876, Loss: 0.08841215865686536, Final Batch Loss: 0.0012635351158678532\n",
      "Epoch 1877, Loss: 0.10184563510119915, Final Batch Loss: 0.014687743037939072\n",
      "Epoch 1878, Loss: 0.1054582605138421, Final Batch Loss: 0.005543217994272709\n",
      "Epoch 1879, Loss: 0.1129578649997427, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1880, Loss: 0.07375690329899953, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 1881, Loss: 0.07300870120519676, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1882, Loss: 0.08610190683975816, Final Batch Loss: 0.006413946393877268\n",
      "Epoch 1883, Loss: 0.10630261222831905, Final Batch Loss: 0.0019092203583568335\n",
      "Epoch 1884, Loss: 0.0775386456225533, Final Batch Loss: 0.0004612335760612041\n",
      "Epoch 1885, Loss: 0.07882103013253072, Final Batch Loss: 2.5033637939486653e-05\n",
      "Epoch 1886, Loss: 0.06529807904735208, Final Batch Loss: 0.002182603348046541\n",
      "Epoch 1887, Loss: 0.07456625410122797, Final Batch Loss: 8.964136941358447e-05\n",
      "Epoch 1888, Loss: 0.08074955641995984, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 1889, Loss: 0.061192884342744946, Final Batch Loss: 0.0027411526534706354\n",
      "Epoch 1890, Loss: 0.10442070569843054, Final Batch Loss: 0.012322955764830112\n",
      "Epoch 1891, Loss: 0.08575532399117947, Final Batch Loss: 0.0\n",
      "Epoch 1892, Loss: 0.10201485082506423, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1893, Loss: 0.06990018568467349, Final Batch Loss: 0.000947503256611526\n",
      "Epoch 1894, Loss: 0.07871591858562965, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1895, Loss: 0.0812216419581091, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 1896, Loss: 0.0795448999851871, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1897, Loss: 0.04870216659037396, Final Batch Loss: 0.0002857038634829223\n",
      "Epoch 1898, Loss: 0.08243513655543211, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 1899, Loss: 0.09579253196716309, Final Batch Loss: 0.0\n",
      "Epoch 1900, Loss: 0.07652771472930908, Final Batch Loss: 0.0\n",
      "Epoch 1901, Loss: 0.12109101471651229, Final Batch Loss: 4.2914423829643056e-05\n",
      "Epoch 1902, Loss: 0.059892892379139084, Final Batch Loss: 5.2689116273541003e-05\n",
      "Epoch 1903, Loss: 0.0908637922257185, Final Batch Loss: 0.008342655375599861\n",
      "Epoch 1904, Loss: 0.05616376840043813, Final Batch Loss: 0.0008151783840730786\n",
      "Epoch 1905, Loss: 0.09217178309336305, Final Batch Loss: 0.001039679627865553\n",
      "Epoch 1906, Loss: 0.13191872742027044, Final Batch Loss: 0.030331136658787727\n",
      "Epoch 1907, Loss: 0.0961497582757147, Final Batch Loss: 0.00016807096835691482\n",
      "Epoch 1908, Loss: 0.07926845570909791, Final Batch Loss: 0.00036566724884323776\n",
      "Epoch 1909, Loss: 0.0816656457609497, Final Batch Loss: 0.0004107108688913286\n",
      "Epoch 1910, Loss: 1.0119170090183616, Final Batch Loss: 0.9403141736984253\n",
      "Epoch 1911, Loss: 0.07481089380962658, Final Batch Loss: 2.8132995794294402e-05\n",
      "Epoch 1912, Loss: 0.11178427189582862, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1913, Loss: 0.12710601091384177, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1914, Loss: 0.16535452379503113, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 1915, Loss: 0.1572149923449615, Final Batch Loss: 0.0001691436773398891\n",
      "Epoch 1916, Loss: 0.08571964036672597, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1917, Loss: 0.15579678863286972, Final Batch Loss: 0.0843532532453537\n",
      "Epoch 1918, Loss: 0.06749229039996862, Final Batch Loss: 0.0\n",
      "Epoch 1919, Loss: 0.08940768148750067, Final Batch Loss: 0.02460605651140213\n",
      "Epoch 1920, Loss: 0.05415314761580703, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 1921, Loss: 0.08834193646907806, Final Batch Loss: 0.0\n",
      "Epoch 1922, Loss: 0.09879312850534916, Final Batch Loss: 0.0\n",
      "Epoch 1923, Loss: 0.08139596025102946, Final Batch Loss: 1.8000440832111053e-05\n",
      "Epoch 1924, Loss: 0.09983801495400257, Final Batch Loss: 0.00021884430316276848\n",
      "Epoch 1925, Loss: 0.05500774446409196, Final Batch Loss: 0.0012454380048438907\n",
      "Epoch 1926, Loss: 0.062359629198908806, Final Batch Loss: 0.0\n",
      "Epoch 1927, Loss: 0.07063591480255127, Final Batch Loss: 0.0\n",
      "Epoch 1928, Loss: 0.08259044773876667, Final Batch Loss: 0.015903417021036148\n",
      "Epoch 1929, Loss: 0.08584961807354574, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1930, Loss: 0.07986967332544737, Final Batch Loss: 0.0002489972102921456\n",
      "Epoch 1931, Loss: 0.08601006492972374, Final Batch Loss: 0.0\n",
      "Epoch 1932, Loss: 0.08262465859297663, Final Batch Loss: 0.001915883389301598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1933, Loss: 0.0871785981580615, Final Batch Loss: 0.0\n",
      "Epoch 1934, Loss: 0.07835281919687986, Final Batch Loss: 0.0\n",
      "Epoch 1935, Loss: 0.10028617922216654, Final Batch Loss: 0.022519458085298538\n",
      "Epoch 1936, Loss: 0.07211558753624558, Final Batch Loss: 0.004626641049981117\n",
      "Epoch 1937, Loss: 0.10638858936727047, Final Batch Loss: 0.0005105622112751007\n",
      "Epoch 1938, Loss: 0.05090006161481142, Final Batch Loss: 0.0\n",
      "Epoch 1939, Loss: 0.09077193727716804, Final Batch Loss: 0.0001012035645544529\n",
      "Epoch 1940, Loss: 0.09745130932424217, Final Batch Loss: 0.001734658726491034\n",
      "Epoch 1941, Loss: 0.08546447660773993, Final Batch Loss: 0.02473585307598114\n",
      "Epoch 1942, Loss: 0.06151247723028064, Final Batch Loss: 0.004816833417862654\n",
      "Epoch 1943, Loss: 0.05376039445400238, Final Batch Loss: 0.0\n",
      "Epoch 1944, Loss: 0.08348941430449486, Final Batch Loss: 0.016085846349596977\n",
      "Epoch 1945, Loss: 0.08291578757643947, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 1946, Loss: 0.06239926256205308, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 1947, Loss: 0.050764190491008776, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 1948, Loss: 0.06398000195622444, Final Batch Loss: 0.0\n",
      "Epoch 1949, Loss: 0.07973119417147245, Final Batch Loss: 0.0002369599969824776\n",
      "Epoch 1950, Loss: 0.07044475246220827, Final Batch Loss: 0.004758344031870365\n",
      "Epoch 1951, Loss: 0.06221380986971781, Final Batch Loss: 0.0002671123365871608\n",
      "Epoch 1952, Loss: 0.08352381172790047, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 1953, Loss: 0.058454412965716074, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 1954, Loss: 0.05667166784405708, Final Batch Loss: 0.0\n",
      "Epoch 1955, Loss: 0.06643045949749649, Final Batch Loss: 0.0033548760693520308\n",
      "Epoch 1956, Loss: 0.0752923022955656, Final Batch Loss: 0.0\n",
      "Epoch 1957, Loss: 0.08645255398005247, Final Batch Loss: 0.0\n",
      "Epoch 1958, Loss: 0.08062034139584284, Final Batch Loss: 6.925819616299123e-05\n",
      "Epoch 1959, Loss: 0.06770703627262264, Final Batch Loss: 0.0010764762992039323\n",
      "Epoch 1960, Loss: 0.07624202780425549, Final Batch Loss: 0.0\n",
      "Epoch 1961, Loss: 0.06272427132353187, Final Batch Loss: 0.0\n",
      "Epoch 1962, Loss: 0.20528624206781387, Final Batch Loss: 0.14103654026985168\n",
      "Epoch 1963, Loss: 0.05536603322249789, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 1964, Loss: 0.07763804960995913, Final Batch Loss: 0.0\n",
      "Epoch 1965, Loss: 0.08003143765381537, Final Batch Loss: 8.248942322097719e-05\n",
      "Epoch 1966, Loss: 0.07242436613887548, Final Batch Loss: 0.0\n",
      "Epoch 1967, Loss: 0.06895409384742379, Final Batch Loss: 0.007349004503339529\n",
      "Epoch 1968, Loss: 0.06429742166073993, Final Batch Loss: 0.0005936052766628563\n",
      "Epoch 1969, Loss: 0.0513852636795491, Final Batch Loss: 0.0\n",
      "Epoch 1970, Loss: 0.053760793822220876, Final Batch Loss: 1.8358061424805783e-05\n",
      "Epoch 1971, Loss: 0.04659871617332101, Final Batch Loss: 0.003775256220251322\n",
      "Epoch 1972, Loss: 0.11340555921196938, Final Batch Loss: 0.0\n",
      "Epoch 1973, Loss: 3.961441154126078, Final Batch Loss: 3.9208006858825684\n",
      "Epoch 1974, Loss: 0.09111883759032935, Final Batch Loss: 0.0016987192211672664\n",
      "Epoch 1975, Loss: 0.11963568441569805, Final Batch Loss: 0.0\n",
      "Epoch 1976, Loss: 0.16813777014613152, Final Batch Loss: 0.0\n",
      "Epoch 1977, Loss: 0.22254461457487196, Final Batch Loss: 0.000621840707026422\n",
      "Epoch 1978, Loss: 0.19493902091380733, Final Batch Loss: 1.4662635294371285e-05\n",
      "Epoch 1979, Loss: 0.1793177425806789, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 1980, Loss: 0.34646788239479065, Final Batch Loss: 0.16469596326351166\n",
      "Epoch 1981, Loss: 0.10002557304687798, Final Batch Loss: 0.0010255083907395601\n",
      "Epoch 1982, Loss: 0.10392500832676888, Final Batch Loss: 0.0\n",
      "Epoch 1983, Loss: 0.0922715188935399, Final Batch Loss: 0.0022204285487532616\n",
      "Epoch 1984, Loss: 0.1446564756333828, Final Batch Loss: 0.02333163097500801\n",
      "Epoch 1985, Loss: 0.13614910375326872, Final Batch Loss: 0.06032029539346695\n",
      "Epoch 1986, Loss: 0.07804676066734828, Final Batch Loss: 0.000325388420606032\n",
      "Epoch 1987, Loss: 0.0794046325609088, Final Batch Loss: 0.017261158674955368\n",
      "Epoch 1988, Loss: 0.08492982108145952, Final Batch Loss: 0.0\n",
      "Epoch 1989, Loss: 0.07417227601399645, Final Batch Loss: 0.0007285801111720502\n",
      "Epoch 1990, Loss: 0.11024147336138412, Final Batch Loss: 0.0005308172549121082\n",
      "Epoch 1991, Loss: 0.09534591436386108, Final Batch Loss: 0.01967579498887062\n",
      "Epoch 1992, Loss: 0.08589999284595251, Final Batch Loss: 0.0\n",
      "Epoch 1993, Loss: 0.06895253621041064, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 1994, Loss: 0.09397613172768615, Final Batch Loss: 0.00014256415306590497\n",
      "Epoch 1995, Loss: 0.07929616724140942, Final Batch Loss: 0.0027285509277135134\n",
      "Epoch 1996, Loss: 0.10713836736954363, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 1997, Loss: 0.08436578325921573, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 1998, Loss: 0.064920592107228, Final Batch Loss: 9.667406266089529e-05\n",
      "Epoch 1999, Loss: 0.10708221793174744, Final Batch Loss: 0.03514493629336357\n",
      "Epoch 2000, Loss: 0.08392191817983985, Final Batch Loss: 0.006965757813304663\n",
      "Epoch 2001, Loss: 0.06425523012785561, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2002, Loss: 0.060102715506218374, Final Batch Loss: 0.0008797351038083434\n",
      "Epoch 2003, Loss: 0.06693928991444409, Final Batch Loss: 0.0011032691691070795\n",
      "Epoch 2004, Loss: 0.07030251994729042, Final Batch Loss: 0.007101887371391058\n",
      "Epoch 2005, Loss: 0.07391113665653393, Final Batch Loss: 0.00033790123416110873\n",
      "Epoch 2006, Loss: 0.08491029962897301, Final Batch Loss: 0.00043585337698459625\n",
      "Epoch 2007, Loss: 0.06478313144179992, Final Batch Loss: 0.0003592322755139321\n",
      "Epoch 2008, Loss: 0.09062142018228769, Final Batch Loss: 0.010485085658729076\n",
      "Epoch 2009, Loss: 0.06888923252699897, Final Batch Loss: 0.0008574623498134315\n",
      "Epoch 2010, Loss: 0.07554274983453979, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 2011, Loss: 0.07004253636114299, Final Batch Loss: 0.0033755486365407705\n",
      "Epoch 2012, Loss: 0.0869868751614149, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2013, Loss: 0.04907750163692981, Final Batch Loss: 0.0011118428083136678\n",
      "Epoch 2014, Loss: 0.07391433138400316, Final Batch Loss: 0.015000284649431705\n",
      "Epoch 2015, Loss: 0.05853159446235168, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2016, Loss: 0.06650466145947576, Final Batch Loss: 0.019867587834596634\n",
      "Epoch 2017, Loss: 0.07170556345954537, Final Batch Loss: 0.00036995718255639076\n",
      "Epoch 2018, Loss: 0.08019207511097193, Final Batch Loss: 0.026085611432790756\n",
      "Epoch 2019, Loss: 0.07002922520041466, Final Batch Loss: 0.0\n",
      "Epoch 2020, Loss: 0.13603083416819572, Final Batch Loss: 0.06957568228244781\n",
      "Epoch 2021, Loss: 0.11434635438490659, Final Batch Loss: 0.0009413101943209767\n",
      "Epoch 2022, Loss: 0.06207843683642977, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2023, Loss: 0.047028400003910065, Final Batch Loss: 0.006596219725906849\n",
      "Epoch 2024, Loss: 0.07558169006370008, Final Batch Loss: 0.00024125049822032452\n",
      "Epoch 2025, Loss: 0.07080835662782192, Final Batch Loss: 0.0\n",
      "Epoch 2026, Loss: 0.04787167254835367, Final Batch Loss: 0.0\n",
      "Epoch 2027, Loss: 0.08224566466242322, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 2028, Loss: 0.06338394712656736, Final Batch Loss: 0.0\n",
      "Epoch 2029, Loss: 0.05814176597959886, Final Batch Loss: 1.6569954823353328e-05\n",
      "Epoch 2030, Loss: 0.14955475367605686, Final Batch Loss: 0.08730345964431763\n",
      "Epoch 2031, Loss: 0.05275008361786604, Final Batch Loss: 0.0\n",
      "Epoch 2032, Loss: 0.06442322698421776, Final Batch Loss: 0.00286846817471087\n",
      "Epoch 2033, Loss: 0.06374467909233772, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2034, Loss: 0.04992869414854795, Final Batch Loss: 0.0014355602907016873\n",
      "Epoch 2035, Loss: 0.061481384793296456, Final Batch Loss: 0.0010389650706201792\n",
      "Epoch 2036, Loss: 0.07676980830729008, Final Batch Loss: 0.0\n",
      "Epoch 2037, Loss: 0.062208533287041234, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2038, Loss: 0.06568880844861269, Final Batch Loss: 0.008499992080032825\n",
      "Epoch 2039, Loss: 0.06974231079220772, Final Batch Loss: 0.0011251792311668396\n",
      "Epoch 2040, Loss: 0.05826464481651783, Final Batch Loss: 0.0\n",
      "Epoch 2041, Loss: 0.06677066122938413, Final Batch Loss: 2.8013790142722428e-05\n",
      "Epoch 2042, Loss: 0.07689278107136488, Final Batch Loss: 0.00592475850135088\n",
      "Epoch 2043, Loss: 0.062225410249084234, Final Batch Loss: 0.004329237621277571\n",
      "Epoch 2044, Loss: 0.3757387390360236, Final Batch Loss: 0.2843055725097656\n",
      "Epoch 2045, Loss: 0.06965580023822326, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2046, Loss: 0.10124059952794795, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2047, Loss: 0.08760826270008693, Final Batch Loss: 0.00011586471373448148\n",
      "Epoch 2048, Loss: 0.12722331995610148, Final Batch Loss: 0.001213052892126143\n",
      "Epoch 2049, Loss: 0.0987943084910512, Final Batch Loss: 0.009790024720132351\n",
      "Epoch 2050, Loss: 0.10673381667581339, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2051, Loss: 0.10476223193103351, Final Batch Loss: 3.576278118089249e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2052, Loss: 0.09521099366247654, Final Batch Loss: 0.0\n",
      "Epoch 2053, Loss: 0.09664439105836209, Final Batch Loss: 4.851700214203447e-05\n",
      "Epoch 2054, Loss: 0.11178859695792198, Final Batch Loss: 0.017206907272338867\n",
      "Epoch 2055, Loss: 0.059868700336664915, Final Batch Loss: 0.0\n",
      "Epoch 2056, Loss: 0.06343087393179303, Final Batch Loss: 8.332382276421413e-05\n",
      "Epoch 2057, Loss: 0.0678937491029501, Final Batch Loss: 0.0\n",
      "Epoch 2058, Loss: 0.06624562852084637, Final Batch Loss: 0.0\n",
      "Epoch 2059, Loss: 0.06592354457825422, Final Batch Loss: 0.003907071426510811\n",
      "Epoch 2060, Loss: 0.07892585732039947, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2061, Loss: 0.07730716187506914, Final Batch Loss: 0.0013455632142722607\n",
      "Epoch 2062, Loss: 0.06287866743514314, Final Batch Loss: 0.00039772229501977563\n",
      "Epoch 2063, Loss: 0.05678944834289723, Final Batch Loss: 1.680836794548668e-05\n",
      "Epoch 2064, Loss: 0.04406789084896445, Final Batch Loss: 0.0\n",
      "Epoch 2065, Loss: 0.17016620095819235, Final Batch Loss: 0.09262286871671677\n",
      "Epoch 2066, Loss: 0.06799178197843503, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 2067, Loss: 0.04740027383741108, Final Batch Loss: 3.0874729418428615e-05\n",
      "Epoch 2068, Loss: 0.05795831419527531, Final Batch Loss: 0.0\n",
      "Epoch 2069, Loss: 0.06546884588897228, Final Batch Loss: 0.0\n",
      "Epoch 2070, Loss: 0.0422798381055145, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 2071, Loss: 0.05950578284137009, Final Batch Loss: 1.8954096958623268e-05\n",
      "Epoch 2072, Loss: 0.05602305382490158, Final Batch Loss: 0.0\n",
      "Epoch 2073, Loss: 0.05413204419892281, Final Batch Loss: 0.001095171901397407\n",
      "Epoch 2074, Loss: 0.0671786934544798, Final Batch Loss: 0.0004435985756572336\n",
      "Epoch 2075, Loss: 0.07372137991478667, Final Batch Loss: 0.00040725519647821784\n",
      "Epoch 2076, Loss: 0.06224602600559592, Final Batch Loss: 0.0\n",
      "Epoch 2077, Loss: 0.06390720610215794, Final Batch Loss: 8.582700684200972e-05\n",
      "Epoch 2078, Loss: 0.06511661614058539, Final Batch Loss: 0.000596107158344239\n",
      "Epoch 2079, Loss: 0.06813419330862303, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2080, Loss: 0.07771773915737867, Final Batch Loss: 0.004444957710802555\n",
      "Epoch 2081, Loss: 0.04931160807609558, Final Batch Loss: 0.0\n",
      "Epoch 2082, Loss: 0.05458123981952667, Final Batch Loss: 0.0\n",
      "Epoch 2083, Loss: 0.06738137546926737, Final Batch Loss: 0.005751726217567921\n",
      "Epoch 2084, Loss: 0.10298367869108915, Final Batch Loss: 0.06156226247549057\n",
      "Epoch 2085, Loss: 0.05883922195062041, Final Batch Loss: 0.00438668392598629\n",
      "Epoch 2086, Loss: 0.06280645355582237, Final Batch Loss: 0.0\n",
      "Epoch 2087, Loss: 0.07427486422238871, Final Batch Loss: 0.0009303532424382865\n",
      "Epoch 2088, Loss: 0.03483489388599992, Final Batch Loss: 0.0\n",
      "Epoch 2089, Loss: 0.04166885558515787, Final Batch Loss: 0.0\n",
      "Epoch 2090, Loss: 0.050352965015918016, Final Batch Loss: 0.008286026306450367\n",
      "Epoch 2091, Loss: 0.04195472318679094, Final Batch Loss: 0.0\n",
      "Epoch 2092, Loss: 0.0587655371055007, Final Batch Loss: 0.0\n",
      "Epoch 2093, Loss: 0.05511162616312504, Final Batch Loss: 0.0\n",
      "Epoch 2094, Loss: 0.04607984120956843, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2095, Loss: 0.6737306108698249, Final Batch Loss: 0.630012571811676\n",
      "Epoch 2096, Loss: 0.07582114264369011, Final Batch Loss: 0.0\n",
      "Epoch 2097, Loss: 0.2583782970905304, Final Batch Loss: 0.0\n",
      "Epoch 2098, Loss: 0.41770811879541725, Final Batch Loss: 0.0005080600967630744\n",
      "Epoch 2099, Loss: 0.49915842912741937, Final Batch Loss: 0.00010430268594063818\n",
      "Epoch 2100, Loss: 0.5483682490885258, Final Batch Loss: 0.057760510593652725\n",
      "Epoch 2101, Loss: 0.485797056928277, Final Batch Loss: 0.02323240227997303\n",
      "Epoch 2102, Loss: 0.42130009084939957, Final Batch Loss: 0.0\n",
      "Epoch 2103, Loss: 0.2933010030828882, Final Batch Loss: 0.00023624490131624043\n",
      "Epoch 2104, Loss: 0.266434647142205, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2105, Loss: 0.18932535144267604, Final Batch Loss: 0.0006426891195587814\n",
      "Epoch 2106, Loss: 0.14807642350206152, Final Batch Loss: 0.00037853704998269677\n",
      "Epoch 2107, Loss: 0.16014745831489563, Final Batch Loss: 0.0\n",
      "Epoch 2108, Loss: 0.11960503086447716, Final Batch Loss: 0.0\n",
      "Epoch 2109, Loss: 1.8499065674841404, Final Batch Loss: 1.7662885189056396\n",
      "Epoch 2110, Loss: 0.07977482920978218, Final Batch Loss: 0.0018980359891429543\n",
      "Epoch 2111, Loss: 0.17738244496285915, Final Batch Loss: 0.007657105103135109\n",
      "Epoch 2112, Loss: 0.34507854966796003, Final Batch Loss: 0.00032479254878126085\n",
      "Epoch 2113, Loss: 0.5351592153309639, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2114, Loss: 0.4781124070286751, Final Batch Loss: 0.0\n",
      "Epoch 2115, Loss: 0.3168755136357504, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 2116, Loss: 1.863852635025978, Final Batch Loss: 1.55270516872406\n",
      "Epoch 2117, Loss: 0.16117062978446484, Final Batch Loss: 0.023988133296370506\n",
      "Epoch 2118, Loss: 0.08510911156190559, Final Batch Loss: 0.00047922570956870914\n",
      "Epoch 2119, Loss: 0.09590588984428905, Final Batch Loss: 0.00015507926582358778\n",
      "Epoch 2120, Loss: 0.11023391410708427, Final Batch Loss: 0.0\n",
      "Epoch 2121, Loss: 0.11145065166056156, Final Batch Loss: 0.0\n",
      "Epoch 2122, Loss: 0.12991797900758684, Final Batch Loss: 0.002983050188049674\n",
      "Epoch 2123, Loss: 0.08878175728023052, Final Batch Loss: 0.0\n",
      "Epoch 2124, Loss: 0.10458539240062237, Final Batch Loss: 0.0\n",
      "Epoch 2125, Loss: 0.0858775433152914, Final Batch Loss: 0.0\n",
      "Epoch 2126, Loss: 0.09727947227656841, Final Batch Loss: 0.0\n",
      "Epoch 2127, Loss: 0.08669948400347494, Final Batch Loss: 0.0002512616047170013\n",
      "Epoch 2128, Loss: 0.09428031789138913, Final Batch Loss: 0.006892476696521044\n",
      "Epoch 2129, Loss: 0.07985218428075314, Final Batch Loss: 0.0\n",
      "Epoch 2130, Loss: 0.0711707565933466, Final Batch Loss: 0.00664560217410326\n",
      "Epoch 2131, Loss: 0.09671210963279009, Final Batch Loss: 0.006537715904414654\n",
      "Epoch 2132, Loss: 0.05211897380308983, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2133, Loss: 0.09956861473619938, Final Batch Loss: 0.01812092959880829\n",
      "Epoch 2134, Loss: 0.07223574516683584, Final Batch Loss: 4.7801782784517854e-05\n",
      "Epoch 2135, Loss: 0.07249787919863593, Final Batch Loss: 9.60780744208023e-05\n",
      "Epoch 2136, Loss: 0.05702513467986137, Final Batch Loss: 0.0017089537577703595\n",
      "Epoch 2137, Loss: 0.06825038813985884, Final Batch Loss: 0.003403111593797803\n",
      "Epoch 2138, Loss: 0.06107599727693014, Final Batch Loss: 0.0004633783537428826\n",
      "Epoch 2139, Loss: 0.07710786349684895, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 2140, Loss: 0.7054435592144728, Final Batch Loss: 0.6465484499931335\n",
      "Epoch 2141, Loss: 0.08107822295278311, Final Batch Loss: 0.008029680699110031\n",
      "Epoch 2142, Loss: 0.10876525659114122, Final Batch Loss: 0.02697693556547165\n",
      "Epoch 2143, Loss: 0.07955849543213134, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2144, Loss: 0.09012009855359793, Final Batch Loss: 0.019644001498818398\n",
      "Epoch 2145, Loss: 0.06234021671116352, Final Batch Loss: 0.0\n",
      "Epoch 2146, Loss: 0.06752449553459883, Final Batch Loss: 0.0\n",
      "Epoch 2147, Loss: 0.05239650793373585, Final Batch Loss: 0.0\n",
      "Epoch 2148, Loss: 0.062165326438844204, Final Batch Loss: 0.0\n",
      "Epoch 2149, Loss: 0.06412079813890159, Final Batch Loss: 0.0009247555863112211\n",
      "Epoch 2150, Loss: 0.05094723678394075, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 2151, Loss: 0.061396422795951366, Final Batch Loss: 0.006524096243083477\n",
      "Epoch 2152, Loss: 0.04924052845672122, Final Batch Loss: 1.728519782773219e-05\n",
      "Epoch 2153, Loss: 0.04894695617258549, Final Batch Loss: 0.004096688237041235\n",
      "Epoch 2154, Loss: 0.05693872401388944, Final Batch Loss: 3.397406908334233e-05\n",
      "Epoch 2155, Loss: 0.05238896422088146, Final Batch Loss: 0.0\n",
      "Epoch 2156, Loss: 0.06255694851279259, Final Batch Loss: 0.017603585496544838\n",
      "Epoch 2157, Loss: 0.05084770801477134, Final Batch Loss: 0.00127948890440166\n",
      "Epoch 2158, Loss: 0.06251625437289476, Final Batch Loss: 0.0\n",
      "Epoch 2159, Loss: 0.060507988557219505, Final Batch Loss: 0.002163214609026909\n",
      "Epoch 2160, Loss: 0.056156008504324006, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2161, Loss: 0.056960307992994785, Final Batch Loss: 0.0\n",
      "Epoch 2162, Loss: 0.06931129656732082, Final Batch Loss: 0.0\n",
      "Epoch 2163, Loss: 0.058464037592784734, Final Batch Loss: 5.519237674889155e-05\n",
      "Epoch 2164, Loss: 0.04905154200969264, Final Batch Loss: 0.00015448330668732524\n",
      "Epoch 2165, Loss: 0.08455389301525429, Final Batch Loss: 0.0007229813490994275\n",
      "Epoch 2166, Loss: 0.03877876282786019, Final Batch Loss: 0.0001854724541772157\n",
      "Epoch 2167, Loss: 0.0431585805490613, Final Batch Loss: 0.0\n",
      "Epoch 2168, Loss: 0.0517704719629819, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 2169, Loss: 0.05607353150844574, Final Batch Loss: 0.0\n",
      "Epoch 2170, Loss: 0.061455534771084785, Final Batch Loss: 0.0\n",
      "Epoch 2171, Loss: 0.050863120617577806, Final Batch Loss: 0.00027497802511788905\n",
      "Epoch 2172, Loss: 0.06813693791627884, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2173, Loss: 0.036465952871367335, Final Batch Loss: 0.0007185738068073988\n",
      "Epoch 2174, Loss: 0.061819560825796316, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2175, Loss: 0.06337113888002932, Final Batch Loss: 0.0029651031363755465\n",
      "Epoch 2176, Loss: 0.03042508428916335, Final Batch Loss: 0.0\n",
      "Epoch 2177, Loss: 0.06095485872356221, Final Batch Loss: 0.0007153574260883033\n",
      "Epoch 2178, Loss: 0.07270491681993008, Final Batch Loss: 0.020544001832604408\n",
      "Epoch 2179, Loss: 0.05693235592843848, Final Batch Loss: 4.9232225137529895e-05\n",
      "Epoch 2180, Loss: 0.0631957805599086, Final Batch Loss: 0.0005129451747052372\n",
      "Epoch 2181, Loss: 0.05675825531943701, Final Batch Loss: 0.00028761065914295614\n",
      "Epoch 2182, Loss: 0.05091695523879025, Final Batch Loss: 0.0001532914029667154\n",
      "Epoch 2183, Loss: 0.05342279374588088, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2184, Loss: 0.048543970100581646, Final Batch Loss: 0.0\n",
      "Epoch 2185, Loss: 0.04358994495123625, Final Batch Loss: 0.0\n",
      "Epoch 2186, Loss: 0.03571263700723648, Final Batch Loss: 0.006379477679729462\n",
      "Epoch 2187, Loss: 0.07741446234149407, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 2188, Loss: 0.05703320633620024, Final Batch Loss: 0.001695387065410614\n",
      "Epoch 2189, Loss: 0.05323102883994579, Final Batch Loss: 0.0\n",
      "Epoch 2190, Loss: 0.05337936244904995, Final Batch Loss: 0.0\n",
      "Epoch 2191, Loss: 0.07910576089693677, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 2192, Loss: 0.04457253497093916, Final Batch Loss: 0.0\n",
      "Epoch 2193, Loss: 0.06204632902517915, Final Batch Loss: 0.003318400587886572\n",
      "Epoch 2194, Loss: 0.05022551211504833, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 2195, Loss: 1.2024827231653035, Final Batch Loss: 1.160314679145813\n",
      "Epoch 2196, Loss: 0.055860091000795364, Final Batch Loss: 0.0\n",
      "Epoch 2197, Loss: 0.08818397484719753, Final Batch Loss: 0.025384927168488503\n",
      "Epoch 2198, Loss: 0.07784741230716463, Final Batch Loss: 3.099393507000059e-05\n",
      "Epoch 2199, Loss: 0.08560315519571304, Final Batch Loss: 0.0\n",
      "Epoch 2200, Loss: 0.08687738422304392, Final Batch Loss: 0.0\n",
      "Epoch 2201, Loss: 0.07457220833731526, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2202, Loss: 0.10557544231414795, Final Batch Loss: 0.0\n",
      "Epoch 2203, Loss: 0.08532876213575946, Final Batch Loss: 7.843663479434326e-05\n",
      "Epoch 2204, Loss: 0.07928531349170953, Final Batch Loss: 0.0006528153317049146\n",
      "Epoch 2205, Loss: 0.05735721439123154, Final Batch Loss: 0.0\n",
      "Epoch 2206, Loss: 0.09206704632379115, Final Batch Loss: 0.002925642067566514\n",
      "Epoch 2207, Loss: 0.07008759491145611, Final Batch Loss: 0.018033239990472794\n",
      "Epoch 2208, Loss: 0.05998432636260986, Final Batch Loss: 0.0\n",
      "Epoch 2209, Loss: 0.05330435575888259, Final Batch Loss: 8.439661905867979e-05\n",
      "Epoch 2210, Loss: 0.05436117108911276, Final Batch Loss: 0.0\n",
      "Epoch 2211, Loss: 0.0701633021235466, Final Batch Loss: 0.0\n",
      "Epoch 2212, Loss: 0.054818461649119854, Final Batch Loss: 0.00113589596003294\n",
      "Epoch 2213, Loss: 0.05232633970445022, Final Batch Loss: 6.19869097135961e-05\n",
      "Epoch 2214, Loss: 0.04147518771424075, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 2215, Loss: 0.06276835780499823, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2216, Loss: 0.05043675657361746, Final Batch Loss: 0.0\n",
      "Epoch 2217, Loss: 0.054400268010795116, Final Batch Loss: 0.002926355227828026\n",
      "Epoch 2218, Loss: 0.04485116383239074, Final Batch Loss: 8.4638240878121e-06\n",
      "Epoch 2219, Loss: 0.05345085496082902, Final Batch Loss: 0.00649507949128747\n",
      "Epoch 2220, Loss: 0.04941185610368848, Final Batch Loss: 0.0\n",
      "Epoch 2221, Loss: 0.05614619608968496, Final Batch Loss: 0.0\n",
      "Epoch 2222, Loss: 0.15949233900755644, Final Batch Loss: 0.1096050962805748\n",
      "Epoch 2223, Loss: 0.059855357743799686, Final Batch Loss: 0.0\n",
      "Epoch 2224, Loss: 0.03768359590321779, Final Batch Loss: 0.0\n",
      "Epoch 2225, Loss: 0.05449956655502319, Final Batch Loss: 0.0005509527400135994\n",
      "Epoch 2226, Loss: 0.042778752162121236, Final Batch Loss: 0.0006445952458307147\n",
      "Epoch 2227, Loss: 0.07629892241675407, Final Batch Loss: 0.0002585315378382802\n",
      "Epoch 2228, Loss: 0.043626428887364455, Final Batch Loss: 0.00012337400403339416\n",
      "Epoch 2229, Loss: 0.039703418267883706, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2230, Loss: 0.03425930790217535, Final Batch Loss: 2.13382354559144e-05\n",
      "Epoch 2231, Loss: 0.04507723683491349, Final Batch Loss: 0.0\n",
      "Epoch 2232, Loss: 0.06141952448524535, Final Batch Loss: 0.001061114715412259\n",
      "Epoch 2233, Loss: 0.040597277926281095, Final Batch Loss: 0.00465808529406786\n",
      "Epoch 2234, Loss: 0.04711919673718512, Final Batch Loss: 0.0\n",
      "Epoch 2235, Loss: 0.04066332313232124, Final Batch Loss: 0.0021228890400379896\n",
      "Epoch 2236, Loss: 0.05093070538714528, Final Batch Loss: 0.0\n",
      "Epoch 2237, Loss: 0.06431533116847277, Final Batch Loss: 0.0018919678404927254\n",
      "Epoch 2238, Loss: 0.05177145637566127, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2239, Loss: 0.10849268455058336, Final Batch Loss: 0.048118915408849716\n",
      "Epoch 2240, Loss: 0.05214905925094371, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2241, Loss: 0.02977028866916953, Final Batch Loss: 2.8729025871143676e-05\n",
      "Epoch 2242, Loss: 0.049076822586357594, Final Batch Loss: 0.0\n",
      "Epoch 2243, Loss: 0.07061424199491739, Final Batch Loss: 0.006843935698270798\n",
      "Epoch 2244, Loss: 0.04567600507289171, Final Batch Loss: 0.0010156240314245224\n",
      "Epoch 2245, Loss: 0.0397087256424129, Final Batch Loss: 0.0010236029047518969\n",
      "Epoch 2246, Loss: 0.2434592330828309, Final Batch Loss: 0.16975077986717224\n",
      "Epoch 2247, Loss: 0.06230616420361912, Final Batch Loss: 6.961580220377073e-05\n",
      "Epoch 2248, Loss: 0.04410493055183906, Final Batch Loss: 0.0001722425949992612\n",
      "Epoch 2249, Loss: 0.0370216090204849, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 2250, Loss: 0.061078394937794656, Final Batch Loss: 0.00010406429646536708\n",
      "Epoch 2251, Loss: 0.030957913491874933, Final Batch Loss: 0.0\n",
      "Epoch 2252, Loss: 0.04501375229961013, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2253, Loss: 0.05987231817562133, Final Batch Loss: 0.0010150285670533776\n",
      "Epoch 2254, Loss: 0.043716020649299026, Final Batch Loss: 0.0027101237792521715\n",
      "Epoch 2255, Loss: 0.0566085793543607, Final Batch Loss: 0.018301548436284065\n",
      "Epoch 2256, Loss: 0.039801467675715685, Final Batch Loss: 0.0\n",
      "Epoch 2257, Loss: 0.041695591222378425, Final Batch Loss: 0.0002150304353563115\n",
      "Epoch 2258, Loss: 0.047393944347277284, Final Batch Loss: 0.0005484507419168949\n",
      "Epoch 2259, Loss: 0.07203390718495939, Final Batch Loss: 0.0001731960946926847\n",
      "Epoch 2260, Loss: 0.07266508601605892, Final Batch Loss: 0.0\n",
      "Epoch 2261, Loss: 0.050601865514181554, Final Batch Loss: 0.000723576988093555\n",
      "Epoch 2262, Loss: 0.0548946989219985, Final Batch Loss: 3.981510963058099e-05\n",
      "Epoch 2263, Loss: 0.05432217288762331, Final Batch Loss: 0.0\n",
      "Epoch 2264, Loss: 0.039347192679997534, Final Batch Loss: 0.0003897384158335626\n",
      "Epoch 2265, Loss: 0.03406716987956315, Final Batch Loss: 0.0012972281547263265\n",
      "Epoch 2266, Loss: 0.1373650054447353, Final Batch Loss: 0.08476557582616806\n",
      "Epoch 2267, Loss: 0.062399359885034755, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2268, Loss: 0.1421029600314796, Final Batch Loss: 0.09564545005559921\n",
      "Epoch 2269, Loss: 0.04014712710204549, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 2270, Loss: 0.05081659404095262, Final Batch Loss: 0.0010544460965320468\n",
      "Epoch 2271, Loss: 0.05227219872176647, Final Batch Loss: 0.007529096212238073\n",
      "Epoch 2272, Loss: 1.5969755863770843, Final Batch Loss: 1.551191806793213\n",
      "Epoch 2273, Loss: 0.09966080449521542, Final Batch Loss: 0.010493343695998192\n",
      "Epoch 2274, Loss: 0.30359853059007946, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2275, Loss: 0.4305837268475443, Final Batch Loss: 0.003058638656511903\n",
      "Epoch 2276, Loss: 0.3956510125535715, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 2277, Loss: 0.34899120032696374, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2278, Loss: 0.23787950724346274, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2279, Loss: 0.2178809791769254, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2280, Loss: 0.14707460978024756, Final Batch Loss: 2.074220174108632e-05\n",
      "Epoch 2281, Loss: 0.1024183388799429, Final Batch Loss: 0.0\n",
      "Epoch 2282, Loss: 0.14436580054461956, Final Batch Loss: 0.025391317903995514\n",
      "Epoch 2283, Loss: 0.08516812638845295, Final Batch Loss: 0.0001267114421352744\n",
      "Epoch 2284, Loss: 0.07976957922801375, Final Batch Loss: 0.0041594901122152805\n",
      "Epoch 2285, Loss: 0.07584481593221426, Final Batch Loss: 0.0\n",
      "Epoch 2286, Loss: 0.07352550052019069, Final Batch Loss: 0.00011383838864276186\n",
      "Epoch 2287, Loss: 0.06036374997347593, Final Batch Loss: 0.0022421954199671745\n",
      "Epoch 2288, Loss: 0.05880396626889706, Final Batch Loss: 0.0\n",
      "Epoch 2289, Loss: 0.06519511435180902, Final Batch Loss: 0.0\n",
      "Epoch 2290, Loss: 0.04999791923864905, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2291, Loss: 0.06500318711914588, Final Batch Loss: 7.83174327807501e-05\n",
      "Epoch 2292, Loss: 0.06696901051327586, Final Batch Loss: 0.004817070905119181\n",
      "Epoch 2293, Loss: 0.08248547278344631, Final Batch Loss: 0.018802035599946976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2294, Loss: 0.1289384162519127, Final Batch Loss: 0.000390215078368783\n",
      "Epoch 2295, Loss: 0.07128495443612337, Final Batch Loss: 0.00466164480894804\n",
      "Epoch 2296, Loss: 0.06047767773270607, Final Batch Loss: 0.014996644109487534\n",
      "Epoch 2297, Loss: 0.07458319887518883, Final Batch Loss: 0.0\n",
      "Epoch 2298, Loss: 0.06182144582203364, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2299, Loss: 0.11766409082338214, Final Batch Loss: 0.006977714132517576\n",
      "Epoch 2300, Loss: 0.05868344637565315, Final Batch Loss: 0.0020122535061091185\n",
      "Epoch 2301, Loss: 0.05867227911949158, Final Batch Loss: 0.0010027624666690826\n",
      "Epoch 2302, Loss: 0.0582554611901287, Final Batch Loss: 0.0003831844369415194\n",
      "Epoch 2303, Loss: 0.05406659562140703, Final Batch Loss: 0.0008367374539375305\n",
      "Epoch 2304, Loss: 0.1402677157893777, Final Batch Loss: 0.06595321744680405\n",
      "Epoch 2305, Loss: 0.059984487481408166, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2306, Loss: 0.0703656654804945, Final Batch Loss: 0.0\n",
      "Epoch 2307, Loss: 0.0647956719622016, Final Batch Loss: 0.0\n",
      "Epoch 2308, Loss: 0.044270627200603485, Final Batch Loss: 0.0\n",
      "Epoch 2309, Loss: 0.05196001706644893, Final Batch Loss: 0.0\n",
      "Epoch 2310, Loss: 0.05780394282191992, Final Batch Loss: 0.001830213237553835\n",
      "Epoch 2311, Loss: 0.06555085345644329, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 2312, Loss: 0.1110915937460959, Final Batch Loss: 0.04719951003789902\n",
      "Epoch 2313, Loss: 0.06990639958530664, Final Batch Loss: 0.016892241314053535\n",
      "Epoch 2314, Loss: 0.05619383654993726, Final Batch Loss: 6.747018051100895e-05\n",
      "Epoch 2315, Loss: 0.04742385260757942, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2316, Loss: 0.04844784224394516, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2317, Loss: 0.039086102397050126, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 2318, Loss: 0.047641993034631014, Final Batch Loss: 0.0\n",
      "Epoch 2319, Loss: 0.050861707888543606, Final Batch Loss: 0.0\n",
      "Epoch 2320, Loss: 0.0849592536687851, Final Batch Loss: 0.0\n",
      "Epoch 2321, Loss: 0.06495965097565204, Final Batch Loss: 0.0006983225466683507\n",
      "Epoch 2322, Loss: 0.05013041337952018, Final Batch Loss: 0.0055153584107756615\n",
      "Epoch 2323, Loss: 0.48859633691608906, Final Batch Loss: 0.42415979504585266\n",
      "Epoch 2324, Loss: 0.06253654533065856, Final Batch Loss: 0.0030317793134599924\n",
      "Epoch 2325, Loss: 0.11127102002501488, Final Batch Loss: 0.06193310394883156\n",
      "Epoch 2326, Loss: 0.03810976096428931, Final Batch Loss: 0.0008600826840847731\n",
      "Epoch 2327, Loss: 0.08602310717105865, Final Batch Loss: 0.0\n",
      "Epoch 2328, Loss: 0.0756997856660746, Final Batch Loss: 0.0006104036583565176\n",
      "Epoch 2329, Loss: 0.07591230794787407, Final Batch Loss: 0.0\n",
      "Epoch 2330, Loss: 0.04092014057096094, Final Batch Loss: 0.0011331572895869613\n",
      "Epoch 2331, Loss: 0.06024083119518764, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 2332, Loss: 0.06697996985167265, Final Batch Loss: 0.0\n",
      "Epoch 2333, Loss: 0.05631610396085307, Final Batch Loss: 3.886147169396281e-05\n",
      "Epoch 2334, Loss: 0.065045568626374, Final Batch Loss: 0.0009276139317080379\n",
      "Epoch 2335, Loss: 0.046187329571694136, Final Batch Loss: 0.0\n",
      "Epoch 2336, Loss: 0.045118306297808886, Final Batch Loss: 0.0002812943421304226\n",
      "Epoch 2337, Loss: 0.06628065835684538, Final Batch Loss: 0.0\n",
      "Epoch 2338, Loss: 0.0676928780740127, Final Batch Loss: 0.00026472879108041525\n",
      "Epoch 2339, Loss: 0.04947625100601272, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2340, Loss: 0.06357361190021038, Final Batch Loss: 0.009422356262803078\n",
      "Epoch 2341, Loss: 0.059674307762179524, Final Batch Loss: 5.173549288883805e-05\n",
      "Epoch 2342, Loss: 0.05709810368716717, Final Batch Loss: 0.0022701462730765343\n",
      "Epoch 2343, Loss: 0.05437637529030326, Final Batch Loss: 5.4834770708112046e-05\n",
      "Epoch 2344, Loss: 0.05053348280262071, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 2345, Loss: 0.05376850313041359, Final Batch Loss: 0.0001389883691444993\n",
      "Epoch 2346, Loss: 0.06844758003717288, Final Batch Loss: 0.00058466981863603\n",
      "Epoch 2347, Loss: 0.050557068549096584, Final Batch Loss: 0.0\n",
      "Epoch 2348, Loss: 0.07357726176269352, Final Batch Loss: 0.0\n",
      "Epoch 2349, Loss: 0.048060919623821974, Final Batch Loss: 0.0\n",
      "Epoch 2350, Loss: 0.058424604125207225, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2351, Loss: 0.058814010117203, Final Batch Loss: 0.009698297828435898\n",
      "Epoch 2352, Loss: 0.06871510135533754, Final Batch Loss: 3.6954195820726454e-05\n",
      "Epoch 2353, Loss: 0.05424071196466684, Final Batch Loss: 0.0\n",
      "Epoch 2354, Loss: 0.0587815148755908, Final Batch Loss: 0.0\n",
      "Epoch 2355, Loss: 0.05099026513926219, Final Batch Loss: 0.00014768941036891192\n",
      "Epoch 2356, Loss: 0.0593607333721593, Final Batch Loss: 0.0015594713622704148\n",
      "Epoch 2357, Loss: 0.06794349348638207, Final Batch Loss: 0.00016926287207752466\n",
      "Epoch 2358, Loss: 0.0501422043889761, Final Batch Loss: 0.0\n",
      "Epoch 2359, Loss: 0.06420632916342583, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 2360, Loss: 0.049477864522486925, Final Batch Loss: 0.0\n",
      "Epoch 2361, Loss: 0.042389083653681325, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2362, Loss: 0.054998761537717655, Final Batch Loss: 0.0002796259068418294\n",
      "Epoch 2363, Loss: 0.03623290156247094, Final Batch Loss: 0.00032634177478030324\n",
      "Epoch 2364, Loss: 0.03283481109974673, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 2365, Loss: 0.0624845037234536, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2366, Loss: 0.05763870687223971, Final Batch Loss: 0.0\n",
      "Epoch 2367, Loss: 0.06334539037197828, Final Batch Loss: 0.0049908580258488655\n",
      "Epoch 2368, Loss: 0.04789943597279489, Final Batch Loss: 0.003658389439806342\n",
      "Epoch 2369, Loss: 0.052685344591736794, Final Batch Loss: 0.0\n",
      "Epoch 2370, Loss: 0.042236431618221104, Final Batch Loss: 0.00019000156316906214\n",
      "Epoch 2371, Loss: 0.035265389818505355, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 2372, Loss: 0.03590617838108301, Final Batch Loss: 7.748573807475623e-06\n",
      "Epoch 2373, Loss: 0.060436360698076896, Final Batch Loss: 7.259582343976945e-05\n",
      "Epoch 2374, Loss: 0.03190592164173722, Final Batch Loss: 0.0\n",
      "Epoch 2375, Loss: 0.05915122479197521, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2376, Loss: 0.0793166235089231, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2377, Loss: 0.05301680928096175, Final Batch Loss: 0.0\n",
      "Epoch 2378, Loss: 0.05007477104663849, Final Batch Loss: 0.0\n",
      "Epoch 2379, Loss: 0.05527979135513306, Final Batch Loss: 0.0\n",
      "Epoch 2380, Loss: 0.035454172634217684, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 2381, Loss: 0.0390184773132205, Final Batch Loss: 0.0\n",
      "Epoch 2382, Loss: 0.037053437903523445, Final Batch Loss: 0.0\n",
      "Epoch 2383, Loss: 0.07271772180683911, Final Batch Loss: 0.002775865839794278\n",
      "Epoch 2384, Loss: 0.032427155412733555, Final Batch Loss: 0.0\n",
      "Epoch 2385, Loss: 0.04026882222206041, Final Batch Loss: 2.6464111215318553e-05\n",
      "Epoch 2386, Loss: 0.05708479322493076, Final Batch Loss: 0.0\n",
      "Epoch 2387, Loss: 0.05683364439755678, Final Batch Loss: 0.0\n",
      "Epoch 2388, Loss: 0.06032700927471524, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 2389, Loss: 0.049894722644239664, Final Batch Loss: 0.001984414178878069\n",
      "Epoch 2390, Loss: 0.10217952448874712, Final Batch Loss: 0.050967007875442505\n",
      "Epoch 2391, Loss: 0.04188970380255341, Final Batch Loss: 7.748573807475623e-06\n",
      "Epoch 2392, Loss: 0.043453847989439964, Final Batch Loss: 0.0\n",
      "Epoch 2393, Loss: 0.056741692358627915, Final Batch Loss: 0.0005975367967039347\n",
      "Epoch 2394, Loss: 0.04740844201296568, Final Batch Loss: 0.0\n",
      "Epoch 2395, Loss: 0.038645385298877954, Final Batch Loss: 0.0\n",
      "Epoch 2396, Loss: 0.03594698122469708, Final Batch Loss: 0.00045277358731254935\n",
      "Epoch 2397, Loss: 0.051821100525557995, Final Batch Loss: 0.0\n",
      "Epoch 2398, Loss: 0.025521782226860523, Final Batch Loss: 0.0\n",
      "Epoch 2399, Loss: 0.06476639956235175, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2400, Loss: 0.05930541723500937, Final Batch Loss: 0.0012894895626232028\n",
      "Epoch 2401, Loss: 0.06802946142852306, Final Batch Loss: 0.01725119911134243\n",
      "Epoch 2402, Loss: 0.0295720505528152, Final Batch Loss: 0.0\n",
      "Epoch 2403, Loss: 0.03853100840933621, Final Batch Loss: 0.0012692499440163374\n",
      "Epoch 2404, Loss: 0.05524900322780013, Final Batch Loss: 0.0\n",
      "Epoch 2405, Loss: 0.05619598226621747, Final Batch Loss: 0.0\n",
      "Epoch 2406, Loss: 0.032076666480861604, Final Batch Loss: 0.00013386306818574667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2407, Loss: 0.04980472950410331, Final Batch Loss: 0.00011336160969221964\n",
      "Epoch 2408, Loss: 0.030670578837089124, Final Batch Loss: 2.098061486321967e-05\n",
      "Epoch 2409, Loss: 0.062359664821997285, Final Batch Loss: 0.0023317548912018538\n",
      "Epoch 2410, Loss: 0.05414939683396369, Final Batch Loss: 0.0014257990987971425\n",
      "Epoch 2411, Loss: 0.046291500329971313, Final Batch Loss: 0.0001431601122021675\n",
      "Epoch 2412, Loss: 0.0458086677826941, Final Batch Loss: 0.0\n",
      "Epoch 2413, Loss: 0.05034251572214998, Final Batch Loss: 0.0003843760641757399\n",
      "Epoch 2414, Loss: 0.06105453230338753, Final Batch Loss: 1.5020257706055418e-05\n",
      "Epoch 2415, Loss: 0.06612861203029752, Final Batch Loss: 0.0\n",
      "Epoch 2416, Loss: 0.057103258557617664, Final Batch Loss: 0.021914588287472725\n",
      "Epoch 2417, Loss: 0.058511619092314504, Final Batch Loss: 6.675497570540756e-05\n",
      "Epoch 2418, Loss: 0.03972978983063058, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2419, Loss: 0.05024089792277664, Final Batch Loss: 0.0010555178159847856\n",
      "Epoch 2420, Loss: 0.03115727030672133, Final Batch Loss: 0.0\n",
      "Epoch 2421, Loss: 0.04130695073399693, Final Batch Loss: 0.0016812250250950456\n",
      "Epoch 2422, Loss: 0.030634947412181646, Final Batch Loss: 9.345571743324399e-05\n",
      "Epoch 2423, Loss: 0.04586902668233961, Final Batch Loss: 0.0008775911992415786\n",
      "Epoch 2424, Loss: 0.055851300896392786, Final Batch Loss: 9.894321920000948e-06\n",
      "Epoch 2425, Loss: 0.04189477814361453, Final Batch Loss: 0.0\n",
      "Epoch 2426, Loss: 0.04092328995466232, Final Batch Loss: 0.0\n",
      "Epoch 2427, Loss: 0.0502600222826004, Final Batch Loss: 0.0\n",
      "Epoch 2428, Loss: 0.0729698995128274, Final Batch Loss: 0.0\n",
      "Epoch 2429, Loss: 0.034593223594129086, Final Batch Loss: 0.0\n",
      "Epoch 2430, Loss: 0.06982414610683918, Final Batch Loss: 0.02563267946243286\n",
      "Epoch 2431, Loss: 0.038428614381700754, Final Batch Loss: 0.0\n",
      "Epoch 2432, Loss: 0.042467890772961425, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2433, Loss: 0.04602115736634005, Final Batch Loss: 8.129743218887597e-05\n",
      "Epoch 2434, Loss: 0.030349930795637192, Final Batch Loss: 3.611976353568025e-05\n",
      "Epoch 2435, Loss: 0.05863872915506363, Final Batch Loss: 0.0\n",
      "Epoch 2436, Loss: 0.03838379587977414, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2437, Loss: 0.04085301700979471, Final Batch Loss: 0.0\n",
      "Epoch 2438, Loss: 0.03666358892223798, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 2439, Loss: 0.07296744175255299, Final Batch Loss: 0.0\n",
      "Epoch 2440, Loss: 0.04020869246960501, Final Batch Loss: 4.2199197196168825e-05\n",
      "Epoch 2441, Loss: 0.05232361424714327, Final Batch Loss: 0.0\n",
      "Epoch 2442, Loss: 0.032230512239038944, Final Batch Loss: 0.0\n",
      "Epoch 2443, Loss: 0.040711448023103, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 2444, Loss: 0.048451754031702876, Final Batch Loss: 0.0024706574622541666\n",
      "Epoch 2445, Loss: 0.030785240145632997, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 2446, Loss: 0.03588345204479282, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2447, Loss: 0.033689291682094336, Final Batch Loss: 0.0\n",
      "Epoch 2448, Loss: 0.04026770987547934, Final Batch Loss: 0.0016419512685388327\n",
      "Epoch 2449, Loss: 0.05042484821751714, Final Batch Loss: 0.0007227431051433086\n",
      "Epoch 2450, Loss: 0.04509824791330175, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 2451, Loss: 0.03821030375547707, Final Batch Loss: 0.0\n",
      "Epoch 2452, Loss: 0.05810060724616051, Final Batch Loss: 0.0\n",
      "Epoch 2453, Loss: 0.024216844263719395, Final Batch Loss: 6.782778655178845e-05\n",
      "Epoch 2454, Loss: 0.05694474512461056, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 2455, Loss: 0.04051062091866697, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 2456, Loss: 0.03668687000754289, Final Batch Loss: 0.0004633783537428826\n",
      "Epoch 2457, Loss: 0.04735030140659546, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2458, Loss: 0.049976919777691364, Final Batch Loss: 0.0\n",
      "Epoch 2459, Loss: 0.03221084708638955, Final Batch Loss: 0.00014184899919200689\n",
      "Epoch 2460, Loss: 0.04171254299581051, Final Batch Loss: 0.005583405494689941\n",
      "Epoch 2461, Loss: 0.037354418889663066, Final Batch Loss: 1.537788011773955e-05\n",
      "Epoch 2462, Loss: 0.056998951360583305, Final Batch Loss: 0.0\n",
      "Epoch 2463, Loss: 0.03141363151371479, Final Batch Loss: 0.0\n",
      "Epoch 2464, Loss: 0.07667209208011627, Final Batch Loss: 0.0\n",
      "Epoch 2465, Loss: 0.02662306791170721, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2466, Loss: 0.039949129335582256, Final Batch Loss: 0.0\n",
      "Epoch 2467, Loss: 0.073015371337533, Final Batch Loss: 0.0\n",
      "Epoch 2468, Loss: 0.03221334143881904, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 2469, Loss: 0.03402368930983357, Final Batch Loss: 3.814624506048858e-05\n",
      "Epoch 2470, Loss: 0.0414416043786332, Final Batch Loss: 0.0\n",
      "Epoch 2471, Loss: 0.05774668711819686, Final Batch Loss: 0.00035279724397696555\n",
      "Epoch 2472, Loss: 0.025661850144388154, Final Batch Loss: 2.0146166207268834e-05\n",
      "Epoch 2473, Loss: 0.027780873700976372, Final Batch Loss: 0.0\n",
      "Epoch 2474, Loss: 0.032140052411705256, Final Batch Loss: 0.0\n",
      "Epoch 2475, Loss: 0.04863257706165314, Final Batch Loss: 0.0\n",
      "Epoch 2476, Loss: 0.05556426080875099, Final Batch Loss: 0.02541235461831093\n",
      "Epoch 2477, Loss: 0.04185211373260245, Final Batch Loss: 0.0006224363460205495\n",
      "Epoch 2478, Loss: 0.7542726774699986, Final Batch Loss: 0.7150165438652039\n",
      "Epoch 2479, Loss: 0.0514128815557342, Final Batch Loss: 0.00023552982020191848\n",
      "Epoch 2480, Loss: 0.05074214708292857, Final Batch Loss: 0.00033408781746402383\n",
      "Epoch 2481, Loss: 0.07783102197572589, Final Batch Loss: 0.0\n",
      "Epoch 2482, Loss: 0.10891526751220226, Final Batch Loss: 0.0\n",
      "Epoch 2483, Loss: 0.1095841582855428, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2484, Loss: 0.06271571821889665, Final Batch Loss: 2.4676019165781327e-05\n",
      "Epoch 2485, Loss: 0.06616790448060783, Final Batch Loss: 9.894321920000948e-06\n",
      "Epoch 2486, Loss: 0.106110791064566, Final Batch Loss: 0.00026127262390218675\n",
      "Epoch 2487, Loss: 0.04533454842021456, Final Batch Loss: 6.532455881824717e-05\n",
      "Epoch 2488, Loss: 0.04769848450087011, Final Batch Loss: 0.0\n",
      "Epoch 2489, Loss: 0.04564499179832637, Final Batch Loss: 0.0\n",
      "Epoch 2490, Loss: 0.06501958705484867, Final Batch Loss: 0.013868280686438084\n",
      "Epoch 2491, Loss: 0.04972363915135247, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2492, Loss: 0.0834886240772903, Final Batch Loss: 0.02912350744009018\n",
      "Epoch 2493, Loss: 4.924813241697848, Final Batch Loss: 4.894449710845947\n",
      "Epoch 2494, Loss: 1.1680774334818125, Final Batch Loss: 1.14414381980896\n",
      "Epoch 2495, Loss: 0.05642069346868084, Final Batch Loss: 5.602679812000133e-05\n",
      "Epoch 2496, Loss: 0.06251964904367924, Final Batch Loss: 0.0\n",
      "Epoch 2497, Loss: 0.05502826733572874, Final Batch Loss: 0.00011300401820335537\n",
      "Epoch 2498, Loss: 0.04811482224613428, Final Batch Loss: 0.0\n",
      "Epoch 2499, Loss: 0.06554866605438292, Final Batch Loss: 0.003152046585455537\n",
      "Epoch 2500, Loss: 0.12737233098596334, Final Batch Loss: 0.04963058978319168\n",
      "Epoch 2501, Loss: 0.051254347315989435, Final Batch Loss: 0.0014302035560831428\n",
      "Epoch 2502, Loss: 0.05383039855223615, Final Batch Loss: 0.0001787979417713359\n",
      "Epoch 2503, Loss: 0.06308557162992656, Final Batch Loss: 0.003903033910319209\n",
      "Epoch 2504, Loss: 0.0427008718252182, Final Batch Loss: 0.0\n",
      "Epoch 2505, Loss: 0.04619803559035063, Final Batch Loss: 0.0028708456084132195\n",
      "Epoch 2506, Loss: 0.051785548217594624, Final Batch Loss: 0.0\n",
      "Epoch 2507, Loss: 0.055731532596837496, Final Batch Loss: 3.158996332786046e-05\n",
      "Epoch 2508, Loss: 0.053740351446322165, Final Batch Loss: 0.00010132275929208845\n",
      "Epoch 2509, Loss: 0.06031819060444832, Final Batch Loss: 0.0\n",
      "Epoch 2510, Loss: 0.2623907965607941, Final Batch Loss: 0.21337230503559113\n",
      "Epoch 2511, Loss: 0.0823937525274232, Final Batch Loss: 0.0018053437815979123\n",
      "Epoch 2512, Loss: 0.04720543697476387, Final Batch Loss: 0.0\n",
      "Epoch 2513, Loss: 0.0534740649163723, Final Batch Loss: 0.0\n",
      "Epoch 2514, Loss: 0.06367501150816679, Final Batch Loss: 0.0\n",
      "Epoch 2515, Loss: 0.034295592486159876, Final Batch Loss: 0.00019762947340495884\n",
      "Epoch 2516, Loss: 0.048362401289523405, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 2517, Loss: 0.050572685890074354, Final Batch Loss: 8.082063141046092e-05\n",
      "Epoch 2518, Loss: 0.035275389440357685, Final Batch Loss: 0.0\n",
      "Epoch 2519, Loss: 0.03534178633708507, Final Batch Loss: 0.00098204065579921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2520, Loss: 0.10164197813719511, Final Batch Loss: 0.061057720333337784\n",
      "Epoch 2521, Loss: 0.05707761738449335, Final Batch Loss: 0.0\n",
      "Epoch 2522, Loss: 0.04192411340772395, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2523, Loss: 0.06303573213517666, Final Batch Loss: 0.0\n",
      "Epoch 2524, Loss: 0.08024628832936287, Final Batch Loss: 0.04389329254627228\n",
      "Epoch 2525, Loss: 0.03251285897567868, Final Batch Loss: 0.0\n",
      "Epoch 2526, Loss: 0.05862048175185919, Final Batch Loss: 0.013813492842018604\n",
      "Epoch 2527, Loss: 0.11093731597065926, Final Batch Loss: 0.0\n",
      "Epoch 2528, Loss: 0.04549585608765483, Final Batch Loss: 0.0\n",
      "Epoch 2529, Loss: 0.058185763333312934, Final Batch Loss: 5.006664650863968e-05\n",
      "Epoch 2530, Loss: 0.03959095990182959, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2531, Loss: 0.04226408980321139, Final Batch Loss: 0.0010658780811354518\n",
      "Epoch 2532, Loss: 0.044819615779715605, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2533, Loss: 0.04320415062829852, Final Batch Loss: 0.004833086393773556\n",
      "Epoch 2534, Loss: 0.041797229408985004, Final Batch Loss: 9.30981186684221e-05\n",
      "Epoch 2535, Loss: 0.05073487378831487, Final Batch Loss: 8.165503095369786e-05\n",
      "Epoch 2536, Loss: 0.02998494915664196, Final Batch Loss: 0.0024379552341997623\n",
      "Epoch 2537, Loss: 0.036418254468117084, Final Batch Loss: 6.198863957251888e-06\n",
      "Epoch 2538, Loss: 0.044409338384866714, Final Batch Loss: 0.0\n",
      "Epoch 2539, Loss: 0.031249484898580704, Final Batch Loss: 3.302042750874534e-05\n",
      "Epoch 2540, Loss: 0.03618033463129677, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2541, Loss: 0.04355791141279042, Final Batch Loss: 0.006133661139756441\n",
      "Epoch 2542, Loss: 0.08178760949181196, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2543, Loss: 0.03891170735005289, Final Batch Loss: 0.0011649496154859662\n",
      "Epoch 2544, Loss: 0.07641349453479052, Final Batch Loss: 0.02748759835958481\n",
      "Epoch 2545, Loss: 0.03785136387932653, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 2546, Loss: 0.047289072535932064, Final Batch Loss: 0.0\n",
      "Epoch 2547, Loss: 0.0316246142598402, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 2548, Loss: 0.038476280868053436, Final Batch Loss: 0.0\n",
      "Epoch 2549, Loss: 0.042466687969863415, Final Batch Loss: 0.0\n",
      "Epoch 2550, Loss: 0.08933244552463293, Final Batch Loss: 0.0\n",
      "Epoch 2551, Loss: 0.0395449138013646, Final Batch Loss: 0.0014699617167934775\n",
      "Epoch 2552, Loss: 0.03802337356910357, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 2553, Loss: 0.027038830681703985, Final Batch Loss: 0.0006652049487456679\n",
      "Epoch 2554, Loss: 0.03977780696004629, Final Batch Loss: 0.0025725625455379486\n",
      "Epoch 2555, Loss: 0.04285927163437009, Final Batch Loss: 0.0\n",
      "Epoch 2556, Loss: 0.04494971642270684, Final Batch Loss: 0.0\n",
      "Epoch 2557, Loss: 0.03804492875224241, Final Batch Loss: 1.0371154530730564e-05\n",
      "Epoch 2558, Loss: 0.08989704214036465, Final Batch Loss: 0.05189189687371254\n",
      "Epoch 2559, Loss: 0.029158615738424487, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 2560, Loss: 0.039687942480668426, Final Batch Loss: 0.003652807092294097\n",
      "Epoch 2561, Loss: 0.03427872580505209, Final Batch Loss: 5.9960475482512265e-05\n",
      "Epoch 2562, Loss: 0.04272370086982846, Final Batch Loss: 0.0\n",
      "Epoch 2563, Loss: 0.03019429720006883, Final Batch Loss: 0.0\n",
      "Epoch 2564, Loss: 0.0421921145170856, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2565, Loss: 0.02854795567691326, Final Batch Loss: 0.0038628973998129368\n",
      "Epoch 2566, Loss: 0.029746566893209092, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 2567, Loss: 0.0328681506216526, Final Batch Loss: 0.0\n",
      "Epoch 2568, Loss: 0.03992610331624746, Final Batch Loss: 0.0\n",
      "Epoch 2569, Loss: 0.04036046503460966, Final Batch Loss: 0.00035232058144174516\n",
      "Epoch 2570, Loss: 0.043828025460243225, Final Batch Loss: 0.0\n",
      "Epoch 2571, Loss: 0.025342153618112206, Final Batch Loss: 0.0\n",
      "Epoch 2572, Loss: 0.0474796649068594, Final Batch Loss: 0.0\n",
      "Epoch 2573, Loss: 0.03935824939981103, Final Batch Loss: 0.0\n",
      "Epoch 2574, Loss: 0.026109523656487, Final Batch Loss: 9.595887240720913e-05\n",
      "Epoch 2575, Loss: 0.03155821096152067, Final Batch Loss: 0.0\n",
      "Epoch 2576, Loss: 0.05745370686042861, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2577, Loss: 0.04130664931062711, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 2578, Loss: 0.048471925780177116, Final Batch Loss: 0.0\n",
      "Epoch 2579, Loss: 0.05190905201015994, Final Batch Loss: 0.000910106289666146\n",
      "Epoch 2580, Loss: 0.04830274172127247, Final Batch Loss: 0.0\n",
      "Epoch 2581, Loss: 0.02484145830385387, Final Batch Loss: 0.0\n",
      "Epoch 2582, Loss: 0.026127792429178953, Final Batch Loss: 0.0\n",
      "Epoch 2583, Loss: 0.042047355789684104, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2584, Loss: 0.05168213415890932, Final Batch Loss: 0.0\n",
      "Epoch 2585, Loss: 0.03146710686451115, Final Batch Loss: 2.276871418871451e-05\n",
      "Epoch 2586, Loss: 0.023864359129163404, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2587, Loss: 0.03459470903771944, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 2588, Loss: 0.04553331200304456, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 2589, Loss: 0.06130894040688872, Final Batch Loss: 0.0037473472766578197\n",
      "Epoch 2590, Loss: 0.028008937886625063, Final Batch Loss: 3.6000557884108275e-05\n",
      "Epoch 2591, Loss: 0.046444450272247195, Final Batch Loss: 0.0015291199088096619\n",
      "Epoch 2592, Loss: 0.04275648014390754, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 2593, Loss: 0.04144645729684271, Final Batch Loss: 0.00016056202002801\n",
      "Epoch 2594, Loss: 0.04516100650653243, Final Batch Loss: 0.01339072547852993\n",
      "Epoch 2595, Loss: 0.04349449100118363, Final Batch Loss: 7.343022298300639e-05\n",
      "Epoch 2596, Loss: 0.18342211097478867, Final Batch Loss: 0.13962145149707794\n",
      "Epoch 2597, Loss: 0.05005544942468987, Final Batch Loss: 1.847726889536716e-05\n",
      "Epoch 2598, Loss: 0.0478920831810683, Final Batch Loss: 0.0032069466542452574\n",
      "Epoch 2599, Loss: 0.0307233672356233, Final Batch Loss: 0.00012766500003635883\n",
      "Epoch 2600, Loss: 0.03832092731954617, Final Batch Loss: 1.3828182090946939e-05\n",
      "Epoch 2601, Loss: 0.029805008431139868, Final Batch Loss: 0.00010013079008786008\n",
      "Epoch 2602, Loss: 0.03520268737337773, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2603, Loss: 0.02541667828336358, Final Batch Loss: 0.0\n",
      "Epoch 2604, Loss: 0.036387862637639046, Final Batch Loss: 0.001644093543291092\n",
      "Epoch 2605, Loss: 0.028667018465966976, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 2606, Loss: 0.027901719324290752, Final Batch Loss: 0.0\n",
      "Epoch 2607, Loss: 0.02957035880535841, Final Batch Loss: 0.0\n",
      "Epoch 2608, Loss: 0.03491727774962783, Final Batch Loss: 0.0\n",
      "Epoch 2609, Loss: 0.0553275691311228, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2610, Loss: 0.04178523039445281, Final Batch Loss: 0.0\n",
      "Epoch 2611, Loss: 0.05140549689531326, Final Batch Loss: 0.01053097378462553\n",
      "Epoch 2612, Loss: 0.02770451526157558, Final Batch Loss: 0.001795467222109437\n",
      "Epoch 2613, Loss: 0.04918448720127344, Final Batch Loss: 0.0\n",
      "Epoch 2614, Loss: 0.028892563190311193, Final Batch Loss: 0.0\n",
      "Epoch 2615, Loss: 0.05183625500649214, Final Batch Loss: 0.0\n",
      "Epoch 2616, Loss: 0.03044931753538549, Final Batch Loss: 0.0\n",
      "Epoch 2617, Loss: 0.03562846500426531, Final Batch Loss: 0.0\n",
      "Epoch 2618, Loss: 0.02309076365781948, Final Batch Loss: 0.0005075835506431758\n",
      "Epoch 2619, Loss: 0.03270698292180896, Final Batch Loss: 0.0\n",
      "Epoch 2620, Loss: 0.04352395370369777, Final Batch Loss: 0.0005408254801295698\n",
      "Epoch 2621, Loss: 0.05797769216587767, Final Batch Loss: 0.0007815881981514394\n",
      "Epoch 2622, Loss: 0.02484730747494268, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2623, Loss: 0.02918242403666227, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 2624, Loss: 0.039192251628264785, Final Batch Loss: 0.0\n",
      "Epoch 2625, Loss: 0.05523539241403341, Final Batch Loss: 0.0\n",
      "Epoch 2626, Loss: 0.03797310777736129, Final Batch Loss: 0.00011812942830147222\n",
      "Epoch 2627, Loss: 0.0581125244497116, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 2628, Loss: 0.03948543919250369, Final Batch Loss: 0.005956517532467842\n",
      "Epoch 2629, Loss: 0.029895571991801262, Final Batch Loss: 0.0005055579822510481\n",
      "Epoch 2630, Loss: 0.0314613840491802, Final Batch Loss: 2.5748875486897305e-05\n",
      "Epoch 2631, Loss: 0.02237476850859821, Final Batch Loss: 0.0\n",
      "Epoch 2632, Loss: 0.034142917837016284, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2633, Loss: 0.05348353506997228, Final Batch Loss: 0.0\n",
      "Epoch 2634, Loss: 0.03317352803424001, Final Batch Loss: 0.0\n",
      "Epoch 2635, Loss: 0.046224757097661495, Final Batch Loss: 0.006028563715517521\n",
      "Epoch 2636, Loss: 0.052693605015520006, Final Batch Loss: 0.0006185048841871321\n",
      "Epoch 2637, Loss: 0.04563689464703202, Final Batch Loss: 0.0\n",
      "Epoch 2638, Loss: 0.02613108431069122, Final Batch Loss: 2.6225699912174605e-05\n",
      "Epoch 2639, Loss: 0.03723841346783274, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2640, Loss: 0.025962016195990145, Final Batch Loss: 0.001757030957378447\n",
      "Epoch 2641, Loss: 0.027578843059018254, Final Batch Loss: 0.0\n",
      "Epoch 2642, Loss: 0.0694812424480844, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2643, Loss: 0.041448110016062856, Final Batch Loss: 0.0003438596613705158\n",
      "Epoch 2644, Loss: 0.044075881072785705, Final Batch Loss: 0.00010179955279454589\n",
      "Epoch 2645, Loss: 0.03210139536531642, Final Batch Loss: 0.0009465504554100335\n",
      "Epoch 2646, Loss: 0.028018166995934735, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 2647, Loss: 0.026900009717785167, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2648, Loss: 0.022153425437863916, Final Batch Loss: 0.0003849719068966806\n",
      "Epoch 2649, Loss: 0.03587517630785442, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 2650, Loss: 0.02561187231913209, Final Batch Loss: 0.0\n",
      "Epoch 2651, Loss: 0.049302357248961926, Final Batch Loss: 0.0\n",
      "Epoch 2652, Loss: 0.0368706164881587, Final Batch Loss: 0.0\n",
      "Epoch 2653, Loss: 0.03463630750775337, Final Batch Loss: 0.0\n",
      "Epoch 2654, Loss: 0.035964497830718756, Final Batch Loss: 0.0\n",
      "Epoch 2655, Loss: 0.043304226361215115, Final Batch Loss: 0.0\n",
      "Epoch 2656, Loss: 0.051571622490882874, Final Batch Loss: 0.0\n",
      "Epoch 2657, Loss: 0.03994230879470706, Final Batch Loss: 0.0\n",
      "Epoch 2658, Loss: 0.04926203680224717, Final Batch Loss: 0.0206285510212183\n",
      "Epoch 2659, Loss: 0.03837351160655089, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 2660, Loss: 0.04457243391902921, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 2661, Loss: 0.02133343683090061, Final Batch Loss: 0.0\n",
      "Epoch 2662, Loss: 0.025699189369333908, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 2663, Loss: 0.04633380239829421, Final Batch Loss: 0.0\n",
      "Epoch 2664, Loss: 0.0396468862890913, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2665, Loss: 0.030534395948052406, Final Batch Loss: 0.0\n",
      "Epoch 2666, Loss: 0.031123131953791017, Final Batch Loss: 4.875540980719961e-05\n",
      "Epoch 2667, Loss: 0.029880162262998056, Final Batch Loss: 2.4437606043647975e-05\n",
      "Epoch 2668, Loss: 0.048744601197533655, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2669, Loss: 0.017428197388653643, Final Batch Loss: 0.00020716428116429597\n",
      "Epoch 2670, Loss: 0.031153192743431646, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2671, Loss: 0.03841989528154954, Final Batch Loss: 0.0009731086320243776\n",
      "Epoch 2672, Loss: 0.02322014770469849, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2673, Loss: 0.02766624495779979, Final Batch Loss: 4.1483970562694594e-05\n",
      "Epoch 2674, Loss: 0.03511518891900778, Final Batch Loss: 0.0\n",
      "Epoch 2675, Loss: 0.03316259291023016, Final Batch Loss: 0.0\n",
      "Epoch 2676, Loss: 0.028883386170491576, Final Batch Loss: 0.0\n",
      "Epoch 2677, Loss: 0.03369204606860876, Final Batch Loss: 0.0\n",
      "Epoch 2678, Loss: 0.03192813927307725, Final Batch Loss: 0.0008764001540839672\n",
      "Epoch 2679, Loss: 0.06327970931306481, Final Batch Loss: 0.03682640567421913\n",
      "Epoch 2680, Loss: 0.03204867406748235, Final Batch Loss: 0.0\n",
      "Epoch 2681, Loss: 0.03767233504913747, Final Batch Loss: 0.003579520620405674\n",
      "Epoch 2682, Loss: 0.03504173457622528, Final Batch Loss: 0.0\n",
      "Epoch 2683, Loss: 0.030834945570859418, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 2684, Loss: 0.030389650106371846, Final Batch Loss: 8.260862523457035e-05\n",
      "Epoch 2685, Loss: 0.040219196933321655, Final Batch Loss: 0.0\n",
      "Epoch 2686, Loss: 0.03308784193353631, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2687, Loss: 0.0459490236826241, Final Batch Loss: 0.0006636562757194042\n",
      "Epoch 2688, Loss: 0.038160119438543916, Final Batch Loss: 0.0005110388156026602\n",
      "Epoch 2689, Loss: 0.025658996775746346, Final Batch Loss: 0.0\n",
      "Epoch 2690, Loss: 0.041981362219303264, Final Batch Loss: 1.0251946150674485e-05\n",
      "Epoch 2691, Loss: 0.03779624658636749, Final Batch Loss: 0.0\n",
      "Epoch 2692, Loss: 0.03304222924634814, Final Batch Loss: 0.005903427489101887\n",
      "Epoch 2693, Loss: 0.04001567035447806, Final Batch Loss: 0.0012336509535089135\n",
      "Epoch 2694, Loss: 0.02377832400088664, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 2695, Loss: 0.038410114124417305, Final Batch Loss: 0.0\n",
      "Epoch 2696, Loss: 0.03457982082545641, Final Batch Loss: 2.5987286790041253e-05\n",
      "Epoch 2697, Loss: 0.03126700973371044, Final Batch Loss: 0.0003147821989841759\n",
      "Epoch 2698, Loss: 0.035127465380355716, Final Batch Loss: 0.0\n",
      "Epoch 2699, Loss: 0.03013545040448662, Final Batch Loss: 0.00013314791431184858\n",
      "Epoch 2700, Loss: 0.05329484485264402, Final Batch Loss: 0.00014995403762441128\n",
      "Epoch 2701, Loss: 0.0235358530189842, Final Batch Loss: 0.0\n",
      "Epoch 2702, Loss: 0.030046292842598632, Final Batch Loss: 0.00029023250681348145\n",
      "Epoch 2703, Loss: 0.034477230394259095, Final Batch Loss: 0.002212697174400091\n",
      "Epoch 2704, Loss: 0.24619671888649464, Final Batch Loss: 0.20464308559894562\n",
      "Epoch 2705, Loss: 0.03625386441126466, Final Batch Loss: 0.0\n",
      "Epoch 2706, Loss: 0.045492099597822744, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2707, Loss: 0.04791497765074837, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2708, Loss: 0.07168436874599138, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 2709, Loss: 0.04480561683882911, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2710, Loss: 0.07757401093840599, Final Batch Loss: 0.0\n",
      "Epoch 2711, Loss: 0.05224822135642171, Final Batch Loss: 0.0\n",
      "Epoch 2712, Loss: 0.0318656601011682, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2713, Loss: 0.04302025234210305, Final Batch Loss: 0.00046135272714309394\n",
      "Epoch 2714, Loss: 0.02496188040765901, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 2715, Loss: 0.03777267376420923, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2716, Loss: 0.04879456479102373, Final Batch Loss: 0.0\n",
      "Epoch 2717, Loss: 0.04055422660894692, Final Batch Loss: 0.0015044810716062784\n",
      "Epoch 2718, Loss: 0.050007887184619904, Final Batch Loss: 0.0\n",
      "Epoch 2719, Loss: 0.0536557137966156, Final Batch Loss: 0.0\n",
      "Epoch 2720, Loss: 0.025504354138320195, Final Batch Loss: 2.2291887944447808e-05\n",
      "Epoch 2721, Loss: 0.03269500887108734, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 2722, Loss: 0.03226075649581617, Final Batch Loss: 5.245071224635467e-05\n",
      "Epoch 2723, Loss: 0.026089070830266792, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2724, Loss: 0.03308029333129525, Final Batch Loss: 0.0\n",
      "Epoch 2725, Loss: 0.04631837923079729, Final Batch Loss: 0.0\n",
      "Epoch 2726, Loss: 0.0349723695881039, Final Batch Loss: 1.2874520507466514e-05\n",
      "Epoch 2727, Loss: 0.029015100895776413, Final Batch Loss: 0.0002299282787134871\n",
      "Epoch 2728, Loss: 0.041165989357978106, Final Batch Loss: 0.0\n",
      "Epoch 2729, Loss: 0.026812516385689378, Final Batch Loss: 0.0005813338793814182\n",
      "Epoch 2730, Loss: 0.03452367022327962, Final Batch Loss: 2.5987286790041253e-05\n",
      "Epoch 2731, Loss: 0.03830318106338382, Final Batch Loss: 0.0\n",
      "Epoch 2732, Loss: 0.02775115007534623, Final Batch Loss: 0.0\n",
      "Epoch 2733, Loss: 0.027074609184637666, Final Batch Loss: 0.0\n",
      "Epoch 2734, Loss: 0.03342236625030637, Final Batch Loss: 0.0\n",
      "Epoch 2735, Loss: 0.035338517278432846, Final Batch Loss: 0.0\n",
      "Epoch 2736, Loss: 0.04778383835218847, Final Batch Loss: 0.020353039726614952\n",
      "Epoch 2737, Loss: 0.0313322667243483, Final Batch Loss: 3.802703940891661e-05\n",
      "Epoch 2738, Loss: 0.028350072680041194, Final Batch Loss: 0.0\n",
      "Epoch 2739, Loss: 0.03397888398831128, Final Batch Loss: 1.549708758830093e-05\n",
      "Epoch 2740, Loss: 0.06378305424004793, Final Batch Loss: 0.0\n",
      "Epoch 2741, Loss: 0.03503260047364165, Final Batch Loss: 4.660974445869215e-05\n",
      "Epoch 2742, Loss: 0.05372412735596299, Final Batch Loss: 0.02263495698571205\n",
      "Epoch 2743, Loss: 0.027359661646187305, Final Batch Loss: 0.0\n",
      "Epoch 2744, Loss: 0.023704475257538604, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2745, Loss: 0.025298641994595528, Final Batch Loss: 0.0\n",
      "Epoch 2746, Loss: 0.021159039810299873, Final Batch Loss: 0.0\n",
      "Epoch 2747, Loss: 0.12132732919417322, Final Batch Loss: 0.08882667869329453\n",
      "Epoch 2748, Loss: 0.025485333047072345, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 2749, Loss: 0.03170761000365019, Final Batch Loss: 0.0\n",
      "Epoch 2750, Loss: 0.051415658788755536, Final Batch Loss: 0.0008798541966825724\n",
      "Epoch 2751, Loss: 0.02223728799071978, Final Batch Loss: 1.2397689715726301e-05\n",
      "Epoch 2752, Loss: 0.01957487832987681, Final Batch Loss: 0.000626367807853967\n",
      "Epoch 2753, Loss: 0.04074563761241734, Final Batch Loss: 0.002086249878630042\n",
      "Epoch 2754, Loss: 0.047652441542595625, Final Batch Loss: 0.0\n",
      "Epoch 2755, Loss: 0.025197717825790278, Final Batch Loss: 1.4305104514278355e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2756, Loss: 0.036729729390572174, Final Batch Loss: 2.13382354559144e-05\n",
      "Epoch 2757, Loss: 0.05122860614210367, Final Batch Loss: 0.0\n",
      "Epoch 2758, Loss: 0.03862127550019068, Final Batch Loss: 5.6265202147187665e-05\n",
      "Epoch 2759, Loss: 0.0439411822007969, Final Batch Loss: 0.001456748810596764\n",
      "Epoch 2760, Loss: 0.013937580806668848, Final Batch Loss: 0.0006254147156141698\n",
      "Epoch 2761, Loss: 0.024286965839557695, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2762, Loss: 0.06331209827840212, Final Batch Loss: 1.4543427823809907e-05\n",
      "Epoch 2763, Loss: 0.05061347922310233, Final Batch Loss: 0.0\n",
      "Epoch 2764, Loss: 0.02767183735704748, Final Batch Loss: 2.6702524337451905e-05\n",
      "Epoch 2765, Loss: 0.03273542037641164, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 2766, Loss: 0.02633887913543731, Final Batch Loss: 0.0010714748641476035\n",
      "Epoch 2767, Loss: 0.02179290121421218, Final Batch Loss: 0.0\n",
      "Epoch 2768, Loss: 0.015702401637099683, Final Batch Loss: 0.0\n",
      "Epoch 2769, Loss: 0.034797811746102525, Final Batch Loss: 1.645074735279195e-05\n",
      "Epoch 2770, Loss: 0.04981769481673837, Final Batch Loss: 0.0\n",
      "Epoch 2771, Loss: 0.026319704484194517, Final Batch Loss: 0.0\n",
      "Epoch 2772, Loss: 0.048903323244303465, Final Batch Loss: 0.0\n",
      "Epoch 2773, Loss: 0.044032379635609686, Final Batch Loss: 0.0\n",
      "Epoch 2774, Loss: 0.02172386832535267, Final Batch Loss: 0.0\n",
      "Epoch 2775, Loss: 0.01814673061016947, Final Batch Loss: 0.0\n",
      "Epoch 2776, Loss: 0.03625384019687772, Final Batch Loss: 0.0008516260422766209\n",
      "Epoch 2777, Loss: 0.022011074237184403, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2778, Loss: 0.03921696310862899, Final Batch Loss: 0.0\n",
      "Epoch 2779, Loss: 0.026685122749768198, Final Batch Loss: 0.00019476900342851877\n",
      "Epoch 2780, Loss: 0.03875071322420354, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 2781, Loss: 0.03529966023052111, Final Batch Loss: 0.0005168771021999419\n",
      "Epoch 2782, Loss: 0.025829432299360633, Final Batch Loss: 0.0\n",
      "Epoch 2783, Loss: 0.027298460247493495, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 2784, Loss: 0.03391638338143821, Final Batch Loss: 1.645074735279195e-05\n",
      "Epoch 2785, Loss: 0.0162544974591583, Final Batch Loss: 0.0\n",
      "Epoch 2786, Loss: 0.03687763214111328, Final Batch Loss: 0.0\n",
      "Epoch 2787, Loss: 0.06450649859834812, Final Batch Loss: 3.158996332786046e-05\n",
      "Epoch 2788, Loss: 0.022952564293518662, Final Batch Loss: 0.0\n",
      "Epoch 2789, Loss: 0.024514442193321884, Final Batch Loss: 0.0\n",
      "Epoch 2790, Loss: 0.025162014229863416, Final Batch Loss: 8.010543388081715e-05\n",
      "Epoch 2791, Loss: 0.02511924458667636, Final Batch Loss: 0.0\n",
      "Epoch 2792, Loss: 0.02951537538319826, Final Batch Loss: 0.0\n",
      "Epoch 2793, Loss: 0.02768696565181017, Final Batch Loss: 0.0\n",
      "Epoch 2794, Loss: 0.02900953049902455, Final Batch Loss: 3.2305197237292305e-05\n",
      "Epoch 2795, Loss: 0.035217993790865876, Final Batch Loss: 3.373566141817719e-05\n",
      "Epoch 2796, Loss: 0.017456120112910867, Final Batch Loss: 0.0\n",
      "Epoch 2797, Loss: 0.03748268820345402, Final Batch Loss: 0.0007269124034792185\n",
      "Epoch 2798, Loss: 0.06645750799361849, Final Batch Loss: 7.343022298300639e-05\n",
      "Epoch 2799, Loss: 0.02895265386902679, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2800, Loss: 0.021454265573936482, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2801, Loss: 0.04264836851507425, Final Batch Loss: 0.0040197535417973995\n",
      "Epoch 2802, Loss: 0.045019705314189196, Final Batch Loss: 0.0\n",
      "Epoch 2803, Loss: 0.02748631569556892, Final Batch Loss: 0.0\n",
      "Epoch 2804, Loss: 0.02530217485036701, Final Batch Loss: 0.0024909917265176773\n",
      "Epoch 2805, Loss: 0.03129131993591727, Final Batch Loss: 2.6225699912174605e-05\n",
      "Epoch 2806, Loss: 0.019098143558949232, Final Batch Loss: 0.0\n",
      "Epoch 2807, Loss: 0.04417817851935979, Final Batch Loss: 0.00012957210128661245\n",
      "Epoch 2808, Loss: 0.014107714354395284, Final Batch Loss: 1.0251946150674485e-05\n",
      "Epoch 2809, Loss: 0.027685331646353006, Final Batch Loss: 0.0\n",
      "Epoch 2810, Loss: 0.04030693573440658, Final Batch Loss: 9.703165414975956e-05\n",
      "Epoch 2811, Loss: 0.023803998122275516, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 2812, Loss: 0.024646075908094645, Final Batch Loss: 0.0\n",
      "Epoch 2813, Loss: 0.02510233689096708, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2814, Loss: 0.020605006487983246, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 2815, Loss: 0.023185490630567074, Final Batch Loss: 0.0\n",
      "Epoch 2816, Loss: 0.026822171537787654, Final Batch Loss: 8.201262971851975e-05\n",
      "Epoch 2817, Loss: 0.05110206292010844, Final Batch Loss: 0.0\n",
      "Epoch 2818, Loss: 0.03419037123239832, Final Batch Loss: 9.083335316972807e-05\n",
      "Epoch 2819, Loss: 0.03278947458602488, Final Batch Loss: 0.0\n",
      "Epoch 2820, Loss: 0.03446446103026801, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2821, Loss: 0.025614895625039935, Final Batch Loss: 0.0\n",
      "Epoch 2822, Loss: 0.035630928352475166, Final Batch Loss: 0.006940305233001709\n",
      "Epoch 2823, Loss: 0.03766213036578847, Final Batch Loss: 6.747018051100895e-05\n",
      "Epoch 2824, Loss: 0.03002960537560284, Final Batch Loss: 0.0016592082101851702\n",
      "Epoch 2825, Loss: 0.031087294686585665, Final Batch Loss: 0.0\n",
      "Epoch 2826, Loss: 0.04021321702748537, Final Batch Loss: 0.0043144007213413715\n",
      "Epoch 2827, Loss: 0.016203030169435806, Final Batch Loss: 5.960446742392378e-06\n",
      "Epoch 2828, Loss: 0.03222453605849296, Final Batch Loss: 0.0\n",
      "Epoch 2829, Loss: 0.021014795871451497, Final Batch Loss: 0.0\n",
      "Epoch 2830, Loss: 0.026838075136765838, Final Batch Loss: 0.0\n",
      "Epoch 2831, Loss: 0.03128031035885215, Final Batch Loss: 0.0\n",
      "Epoch 2832, Loss: 0.028982796993659576, Final Batch Loss: 1.883488948806189e-05\n",
      "Epoch 2833, Loss: 0.02745266212127717, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2834, Loss: 0.017795542487874627, Final Batch Loss: 0.0008044582791626453\n",
      "Epoch 2835, Loss: 0.03608239465376073, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2836, Loss: 0.03589193895459175, Final Batch Loss: 0.0005818104837089777\n",
      "Epoch 2837, Loss: 0.024146463023498654, Final Batch Loss: 0.0\n",
      "Epoch 2838, Loss: 0.022266389954893384, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 2839, Loss: 0.03425411084390362, Final Batch Loss: 5.364274329622276e-05\n",
      "Epoch 2840, Loss: 0.025756250601261854, Final Batch Loss: 0.0\n",
      "Epoch 2841, Loss: 0.019706159255292732, Final Batch Loss: 2.1219027985353023e-05\n",
      "Epoch 2842, Loss: 0.030399875598959625, Final Batch Loss: 0.0014611531514674425\n",
      "Epoch 2843, Loss: 0.030166973784616857, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 2844, Loss: 0.024469237658195198, Final Batch Loss: 0.002618101192638278\n",
      "Epoch 2845, Loss: 0.03927309555001557, Final Batch Loss: 0.0\n",
      "Epoch 2846, Loss: 0.02250395967712393, Final Batch Loss: 1.7523612768854946e-05\n",
      "Epoch 2847, Loss: 0.02003571530804038, Final Batch Loss: 0.0\n",
      "Epoch 2848, Loss: 0.03286549774907144, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2849, Loss: 0.04317519860342145, Final Batch Loss: 0.0\n",
      "Epoch 2850, Loss: 0.019432432833127677, Final Batch Loss: 0.0\n",
      "Epoch 2851, Loss: 0.01837413478642702, Final Batch Loss: 0.0\n",
      "Epoch 2852, Loss: 0.02297150914091617, Final Batch Loss: 0.0\n",
      "Epoch 2853, Loss: 0.023230153165059164, Final Batch Loss: 5.23315102327615e-05\n",
      "Epoch 2854, Loss: 0.026319858618080616, Final Batch Loss: 0.0012702024541795254\n",
      "Epoch 2855, Loss: 0.027809133136543096, Final Batch Loss: 1.7404405298293568e-05\n",
      "Epoch 2856, Loss: 0.039141297805599606, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2857, Loss: 0.02469234983433921, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2858, Loss: 0.025420273188501596, Final Batch Loss: 0.0\n",
      "Epoch 2859, Loss: 0.028779556563677033, Final Batch Loss: 1.883488948806189e-05\n",
      "Epoch 2860, Loss: 0.028832317794581286, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 2861, Loss: 0.04005629430321278, Final Batch Loss: 1.4781842764932662e-05\n",
      "Epoch 2862, Loss: 0.02055915235541761, Final Batch Loss: 6.294052582234144e-05\n",
      "Epoch 2863, Loss: 0.03160364058567211, Final Batch Loss: 0.0035331938415765762\n",
      "Epoch 2864, Loss: 0.03540540020912886, Final Batch Loss: 0.004052403848618269\n",
      "Epoch 2865, Loss: 0.051664531230926514, Final Batch Loss: 0.0\n",
      "Epoch 2866, Loss: 0.029013709228820517, Final Batch Loss: 2.8371408916427754e-05\n",
      "Epoch 2867, Loss: 0.04044115263968706, Final Batch Loss: 0.0\n",
      "Epoch 2868, Loss: 0.024571697256760672, Final Batch Loss: 2.95634672511369e-05\n",
      "Epoch 2869, Loss: 0.026352920380304568, Final Batch Loss: 0.00011979816190432757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2870, Loss: 0.028818082180805504, Final Batch Loss: 0.0005640584276989102\n",
      "Epoch 2871, Loss: 0.02317465585656464, Final Batch Loss: 0.0\n",
      "Epoch 2872, Loss: 0.02145035541613538, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2873, Loss: 0.023150468477979302, Final Batch Loss: 0.0\n",
      "Epoch 2874, Loss: 0.026352246291935444, Final Batch Loss: 0.0\n",
      "Epoch 2875, Loss: 0.019733948167413473, Final Batch Loss: 0.0\n",
      "Epoch 2876, Loss: 0.03268873621709645, Final Batch Loss: 0.0\n",
      "Epoch 2877, Loss: 0.025357240345329046, Final Batch Loss: 0.0\n",
      "Epoch 2878, Loss: 0.030785084702074528, Final Batch Loss: 0.0004931663861498237\n",
      "Epoch 2879, Loss: 0.034184450283646584, Final Batch Loss: 0.005714626982808113\n",
      "Epoch 2880, Loss: 0.021705262362957, Final Batch Loss: 0.0\n",
      "Epoch 2881, Loss: 0.09779310692101717, Final Batch Loss: 0.037566885352134705\n",
      "Epoch 2882, Loss: 0.019369294866919518, Final Batch Loss: 0.0016971721779555082\n",
      "Epoch 2883, Loss: 0.03395844670012593, Final Batch Loss: 0.0\n",
      "Epoch 2884, Loss: 0.07212137675355734, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2885, Loss: 0.024990228353999555, Final Batch Loss: 0.003037959337234497\n",
      "Epoch 2886, Loss: 0.023118205135347125, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2887, Loss: 0.040148449363186955, Final Batch Loss: 0.0036149173974990845\n",
      "Epoch 2888, Loss: 0.036013612985243526, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 2889, Loss: 0.017772163497284055, Final Batch Loss: 0.0\n",
      "Epoch 2890, Loss: 0.030570684919439373, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 2891, Loss: 0.03012130130082369, Final Batch Loss: 0.0\n",
      "Epoch 2892, Loss: 0.04323386726900935, Final Batch Loss: 0.0\n",
      "Epoch 2893, Loss: 0.03560587204992771, Final Batch Loss: 0.013672159053385258\n",
      "Epoch 2894, Loss: 0.027478610165417194, Final Batch Loss: 0.0\n",
      "Epoch 2895, Loss: 0.03771774863707833, Final Batch Loss: 4.637133679352701e-05\n",
      "Epoch 2896, Loss: 0.030562914442270994, Final Batch Loss: 0.001708239782601595\n",
      "Epoch 2897, Loss: 0.01999774668365717, Final Batch Loss: 0.0\n",
      "Epoch 2898, Loss: 0.031123422217206098, Final Batch Loss: 6.627816765103489e-05\n",
      "Epoch 2899, Loss: 0.05529719495689278, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 2900, Loss: 0.024669989477843046, Final Batch Loss: 0.0\n",
      "Epoch 2901, Loss: 0.02580813644453883, Final Batch Loss: 0.0\n",
      "Epoch 2902, Loss: 0.037611221894394475, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 2903, Loss: 0.02897159825079143, Final Batch Loss: 0.005732880439609289\n",
      "Epoch 2904, Loss: 0.035329046309925616, Final Batch Loss: 0.001278298324905336\n",
      "Epoch 2905, Loss: 0.012641902780153202, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2906, Loss: 0.02521932938179816, Final Batch Loss: 2.2411095415009186e-05\n",
      "Epoch 2907, Loss: 0.027745710311137373, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 2908, Loss: 0.03169668943155557, Final Batch Loss: 0.0\n",
      "Epoch 2909, Loss: 0.04149718303216332, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 2910, Loss: 0.01917287684045732, Final Batch Loss: 0.0\n",
      "Epoch 2911, Loss: 0.02211034600622952, Final Batch Loss: 0.0\n",
      "Epoch 2912, Loss: 0.030176992993801832, Final Batch Loss: 0.0\n",
      "Epoch 2913, Loss: 0.030482284259051085, Final Batch Loss: 0.0020918408408761024\n",
      "Epoch 2914, Loss: 0.034488865261664614, Final Batch Loss: 0.00018261195509694517\n",
      "Epoch 2915, Loss: 0.01895822730693908, Final Batch Loss: 1.8358061424805783e-05\n",
      "Epoch 2916, Loss: 0.032356871757656336, Final Batch Loss: 0.0\n",
      "Epoch 2917, Loss: 0.013595047552371398, Final Batch Loss: 0.0\n",
      "Epoch 2918, Loss: 0.02146737219300121, Final Batch Loss: 0.0\n",
      "Epoch 2919, Loss: 0.02148132398656344, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 2920, Loss: 0.01655346274492331, Final Batch Loss: 0.00039188333903439343\n",
      "Epoch 2921, Loss: 0.03307785326614976, Final Batch Loss: 0.0\n",
      "Epoch 2922, Loss: 0.017855926882475615, Final Batch Loss: 0.001770953880622983\n",
      "Epoch 2923, Loss: 0.017169209895655513, Final Batch Loss: 0.0\n",
      "Epoch 2924, Loss: 0.04003348061814904, Final Batch Loss: 0.0008164886385202408\n",
      "Epoch 2925, Loss: 0.052596432622522116, Final Batch Loss: 0.0\n",
      "Epoch 2926, Loss: 0.03829382918047486, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 2927, Loss: 0.03739936414785916, Final Batch Loss: 3.123234637314454e-05\n",
      "Epoch 2928, Loss: 0.021090929865749786, Final Batch Loss: 4.815939246327616e-05\n",
      "Epoch 2929, Loss: 0.025978729827329516, Final Batch Loss: 0.0\n",
      "Epoch 2930, Loss: 0.03604329423978925, Final Batch Loss: 0.0\n",
      "Epoch 2931, Loss: 0.02710467716678977, Final Batch Loss: 0.0\n",
      "Epoch 2932, Loss: 0.02433852618560195, Final Batch Loss: 0.0\n",
      "Epoch 2933, Loss: 0.03275346759619424, Final Batch Loss: 9.119095193454996e-05\n",
      "Epoch 2934, Loss: 0.026586373336613178, Final Batch Loss: 0.0\n",
      "Epoch 2935, Loss: 0.03647943795658648, Final Batch Loss: 0.0\n",
      "Epoch 2936, Loss: 0.019364735548151657, Final Batch Loss: 0.00044907975825481117\n",
      "Epoch 2937, Loss: 0.031568375416100025, Final Batch Loss: 0.0\n",
      "Epoch 2938, Loss: 0.029647130286321044, Final Batch Loss: 0.002130740089341998\n",
      "Epoch 2939, Loss: 0.019538909662514925, Final Batch Loss: 0.0\n",
      "Epoch 2940, Loss: 0.04272218811092898, Final Batch Loss: 0.00022551853908225894\n",
      "Epoch 2941, Loss: 0.024814626667648554, Final Batch Loss: 0.0\n",
      "Epoch 2942, Loss: 0.03352641314268112, Final Batch Loss: 0.0\n",
      "Epoch 2943, Loss: 0.03520504722473561, Final Batch Loss: 1.549708758830093e-05\n",
      "Epoch 2944, Loss: 0.021760489558801055, Final Batch Loss: 0.00543758412823081\n",
      "Epoch 2945, Loss: 0.022595085836655926, Final Batch Loss: 4.95898348162882e-05\n",
      "Epoch 2946, Loss: 0.02299841785861645, Final Batch Loss: 0.00013374387344811112\n",
      "Epoch 2947, Loss: 0.020020098250824958, Final Batch Loss: 0.0\n",
      "Epoch 2948, Loss: 0.02727584633976221, Final Batch Loss: 0.0\n",
      "Epoch 2949, Loss: 0.029030780075117946, Final Batch Loss: 0.016125613823533058\n",
      "Epoch 2950, Loss: 0.0219166666502133, Final Batch Loss: 0.0011922164121642709\n",
      "Epoch 2951, Loss: 0.04324639693368226, Final Batch Loss: 0.0\n",
      "Epoch 2952, Loss: 0.03563257725818403, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2953, Loss: 0.03726311472382804, Final Batch Loss: 2.062299427052494e-05\n",
      "Epoch 2954, Loss: 0.026201679022051394, Final Batch Loss: 0.0\n",
      "Epoch 2955, Loss: 0.03660539351017178, Final Batch Loss: 2.7418097943154862e-06\n",
      "Epoch 2956, Loss: 0.01784606301180247, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2957, Loss: 0.039706956595154, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 2958, Loss: 0.031172670715022832, Final Batch Loss: 0.0005787128466181457\n",
      "Epoch 2959, Loss: 0.018977215822815197, Final Batch Loss: 5.1377883210079744e-05\n",
      "Epoch 2960, Loss: 0.02260650062817149, Final Batch Loss: 0.0002643712505232543\n",
      "Epoch 2961, Loss: 0.016699279276508605, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 2962, Loss: 0.009768442883796524, Final Batch Loss: 0.00011062010162277147\n",
      "Epoch 2963, Loss: 0.022538655786775053, Final Batch Loss: 0.0005322470096871257\n",
      "Epoch 2964, Loss: 0.03364715399220586, Final Batch Loss: 0.0\n",
      "Epoch 2965, Loss: 0.025396507888217457, Final Batch Loss: 0.00017951308109331876\n",
      "Epoch 2966, Loss: 0.07164920959621668, Final Batch Loss: 0.04556114971637726\n",
      "Epoch 2967, Loss: 0.03074408076281543, Final Batch Loss: 3.4689302992774174e-05\n",
      "Epoch 2968, Loss: 0.03019782993942499, Final Batch Loss: 0.0\n",
      "Epoch 2969, Loss: 0.013688665610963824, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2970, Loss: 0.04085972567554563, Final Batch Loss: 0.0\n",
      "Epoch 2971, Loss: 0.023987567517906427, Final Batch Loss: 0.0\n",
      "Epoch 2972, Loss: 0.022261799313127995, Final Batch Loss: 0.0\n",
      "Epoch 2973, Loss: 0.017460137138186838, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 2974, Loss: 0.02829458168673682, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 2975, Loss: 0.03375839116051793, Final Batch Loss: 0.0\n",
      "Epoch 2976, Loss: 0.03257412114179914, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2977, Loss: 0.024110619095154107, Final Batch Loss: 0.0\n",
      "Epoch 2978, Loss: 0.023527426274085883, Final Batch Loss: 4.362964682513848e-05\n",
      "Epoch 2979, Loss: 0.014841902084299363, Final Batch Loss: 4.541770613286644e-05\n",
      "Epoch 2980, Loss: 0.022315259790040898, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 2981, Loss: 0.0218099633930251, Final Batch Loss: 0.0\n",
      "Epoch 2982, Loss: 0.025589413695342955, Final Batch Loss: 2.2172682292875834e-05\n",
      "Epoch 2983, Loss: 0.014551426283105684, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 2984, Loss: 0.023734270129352808, Final Batch Loss: 0.0\n",
      "Epoch 2985, Loss: 0.02842044640055974, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 2986, Loss: 0.025184220797200396, Final Batch Loss: 1.1801649634435307e-05\n",
      "Epoch 2987, Loss: 0.012858194764703512, Final Batch Loss: 0.0\n",
      "Epoch 2988, Loss: 0.0182472369633615, Final Batch Loss: 0.0\n",
      "Epoch 2989, Loss: 0.020221686456352472, Final Batch Loss: 0.0\n",
      "Epoch 2990, Loss: 0.017011024057865143, Final Batch Loss: 0.0\n",
      "Epoch 2991, Loss: 0.020436667487956583, Final Batch Loss: 0.0\n",
      "Epoch 2992, Loss: 0.015410801395773888, Final Batch Loss: 0.002172611653804779\n",
      "Epoch 2993, Loss: 0.04884598683565855, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2994, Loss: 0.02084813521923934, Final Batch Loss: 4.887569048150908e-06\n",
      "Epoch 2995, Loss: 0.014041975140571594, Final Batch Loss: 0.0\n",
      "Epoch 2996, Loss: 0.04488950641825795, Final Batch Loss: 0.008140480145812035\n",
      "Epoch 2997, Loss: 0.035767718218266964, Final Batch Loss: 0.006590890698134899\n",
      "Epoch 2998, Loss: 0.01763297105935635, Final Batch Loss: 0.00011812942830147222\n",
      "Epoch 2999, Loss: 0.03875541681190953, Final Batch Loss: 0.00025185750564560294\n",
      "Epoch 3000, Loss: 0.045790148886226234, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 3001, Loss: 0.02080577425658703, Final Batch Loss: 0.0\n",
      "Epoch 3002, Loss: 0.026184041751548648, Final Batch Loss: 0.00014149141497910023\n",
      "Epoch 3003, Loss: 0.017785457892159684, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3004, Loss: 0.03123052336741239, Final Batch Loss: 0.0005926521262153983\n",
      "Epoch 3005, Loss: 0.01760929054580629, Final Batch Loss: 0.0\n",
      "Epoch 3006, Loss: 0.025166176488710335, Final Batch Loss: 3.421248038648628e-05\n",
      "Epoch 3007, Loss: 0.029867829056456685, Final Batch Loss: 0.0\n",
      "Epoch 3008, Loss: 0.016221884870901704, Final Batch Loss: 0.0\n",
      "Epoch 3009, Loss: 0.02740651003387029, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 3010, Loss: 0.016429176551582714, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3011, Loss: 0.01759735653467942, Final Batch Loss: 0.00016878610767889768\n",
      "Epoch 3012, Loss: 0.03373702933004097, Final Batch Loss: 1.2993727978027891e-05\n",
      "Epoch 3013, Loss: 0.013674722868017852, Final Batch Loss: 0.0\n",
      "Epoch 3014, Loss: 0.046317361178807914, Final Batch Loss: 0.0\n",
      "Epoch 3015, Loss: 0.016063330229371786, Final Batch Loss: 0.0\n",
      "Epoch 3016, Loss: 0.06033281562793036, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3017, Loss: 0.01422456291038543, Final Batch Loss: 0.0\n",
      "Epoch 3018, Loss: 0.01776474341750145, Final Batch Loss: 0.0\n",
      "Epoch 3019, Loss: 0.03491194441448897, Final Batch Loss: 0.0019156454363837838\n",
      "Epoch 3020, Loss: 0.029678095364943147, Final Batch Loss: 0.0\n",
      "Epoch 3021, Loss: 0.029081955581204966, Final Batch Loss: 2.95634672511369e-05\n",
      "Epoch 3022, Loss: 0.03138329461057765, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3023, Loss: 0.023962115636066983, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3024, Loss: 0.02937295543961227, Final Batch Loss: 0.0\n",
      "Epoch 3025, Loss: 0.04502477259666193, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 3026, Loss: 0.019412783804000355, Final Batch Loss: 6.270212179515511e-05\n",
      "Epoch 3027, Loss: 0.03462768280587625, Final Batch Loss: 6.401333666872233e-05\n",
      "Epoch 3028, Loss: 0.03492238058242947, Final Batch Loss: 0.0008871195605024695\n",
      "Epoch 3029, Loss: 0.019414489155678893, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 3030, Loss: 0.031051999307237566, Final Batch Loss: 0.0\n",
      "Epoch 3031, Loss: 0.030438448069617152, Final Batch Loss: 0.0\n",
      "Epoch 3032, Loss: 0.023550688288992205, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3033, Loss: 0.014808721454755869, Final Batch Loss: 2.777537883957848e-05\n",
      "Epoch 3034, Loss: 0.021963087609037757, Final Batch Loss: 0.0\n",
      "Epoch 3035, Loss: 0.023675926262512803, Final Batch Loss: 0.0\n",
      "Epoch 3036, Loss: 0.05348181480076164, Final Batch Loss: 0.0\n",
      "Epoch 3037, Loss: 0.03913882956840098, Final Batch Loss: 0.0032669526990503073\n",
      "Epoch 3038, Loss: 0.019458216847851872, Final Batch Loss: 0.00371029251255095\n",
      "Epoch 3039, Loss: 0.0564256333746016, Final Batch Loss: 0.030575355514883995\n",
      "Epoch 3040, Loss: 0.014154335134662688, Final Batch Loss: 0.0\n",
      "Epoch 3041, Loss: 0.013967980281449854, Final Batch Loss: 0.0\n",
      "Epoch 3042, Loss: 0.013909474248066545, Final Batch Loss: 0.0\n",
      "Epoch 3043, Loss: 0.05813807080994593, Final Batch Loss: 6.90197994117625e-05\n",
      "Epoch 3044, Loss: 0.01983966544503346, Final Batch Loss: 0.0\n",
      "Epoch 3045, Loss: 0.026941132265960732, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3046, Loss: 0.03169682971167731, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3047, Loss: 0.022710727876983583, Final Batch Loss: 0.0\n",
      "Epoch 3048, Loss: 0.019425431732081222, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3049, Loss: 0.021723727229812084, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3050, Loss: 0.02914190763840452, Final Batch Loss: 0.00027104519540444016\n",
      "Epoch 3051, Loss: 0.04272295592818409, Final Batch Loss: 0.0\n",
      "Epoch 3052, Loss: 0.016275785280981836, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3053, Loss: 0.02297932794317603, Final Batch Loss: 0.0\n",
      "Epoch 3054, Loss: 0.012147325901423756, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 3055, Loss: 0.018434290715958923, Final Batch Loss: 0.0007234578370116651\n",
      "Epoch 3056, Loss: 0.03533615334890783, Final Batch Loss: 0.00027211778797209263\n",
      "Epoch 3057, Loss: 0.02934943069703877, Final Batch Loss: 0.0\n",
      "Epoch 3058, Loss: 0.020201900973916054, Final Batch Loss: 0.0\n",
      "Epoch 3059, Loss: 0.012363933259621263, Final Batch Loss: 0.0\n",
      "Epoch 3060, Loss: 0.029344595037393617, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3061, Loss: 0.021296578925095844, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3062, Loss: 0.024905304017011076, Final Batch Loss: 7.70062324590981e-05\n",
      "Epoch 3063, Loss: 0.03583683993201703, Final Batch Loss: 0.0003303935518488288\n",
      "Epoch 3064, Loss: 0.022725851391385277, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3065, Loss: 0.020528435823450764, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3066, Loss: 0.0350672706262003, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3067, Loss: 0.01262407866124704, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 3068, Loss: 0.028566566586960107, Final Batch Loss: 0.00037293630884960294\n",
      "Epoch 3069, Loss: 0.01546810462602366, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3070, Loss: 0.01413448597304523, Final Batch Loss: 0.0019574069883674383\n",
      "Epoch 3071, Loss: 0.02607331203762442, Final Batch Loss: 0.0\n",
      "Epoch 3072, Loss: 0.02082528264145367, Final Batch Loss: 0.0\n",
      "Epoch 3073, Loss: 0.044537462759763, Final Batch Loss: 0.007862807251513004\n",
      "Epoch 3074, Loss: 0.015513443649979308, Final Batch Loss: 0.00045563330058939755\n",
      "Epoch 3075, Loss: 0.017387205618433654, Final Batch Loss: 0.0\n",
      "Epoch 3076, Loss: 0.02551119777490385, Final Batch Loss: 0.00034683887497521937\n",
      "Epoch 3077, Loss: 0.038705078419297934, Final Batch Loss: 0.0\n",
      "Epoch 3078, Loss: 0.02144864620277076, Final Batch Loss: 3.0636318115284666e-05\n",
      "Epoch 3079, Loss: 0.02487246109944863, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3080, Loss: 0.02397971367457785, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3081, Loss: 0.026399030990432948, Final Batch Loss: 0.000303818320389837\n",
      "Epoch 3082, Loss: 0.0198779811616987, Final Batch Loss: 0.0\n",
      "Epoch 3083, Loss: 0.026823231717571616, Final Batch Loss: 0.0\n",
      "Epoch 3084, Loss: 0.015433310501975939, Final Batch Loss: 4.386805812828243e-05\n",
      "Epoch 3085, Loss: 0.015049710171069819, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3086, Loss: 0.026712318416684866, Final Batch Loss: 0.0\n",
      "Epoch 3087, Loss: 0.02512421677238308, Final Batch Loss: 0.0\n",
      "Epoch 3088, Loss: 0.015096507064299658, Final Batch Loss: 0.0002619877050165087\n",
      "Epoch 3089, Loss: 0.027088123111752793, Final Batch Loss: 0.00040665941196493804\n",
      "Epoch 3090, Loss: 0.03273951215669513, Final Batch Loss: 0.0\n",
      "Epoch 3091, Loss: 0.025551446280587697, Final Batch Loss: 3.802703940891661e-05\n",
      "Epoch 3092, Loss: 0.019737390335649252, Final Batch Loss: 0.0\n",
      "Epoch 3093, Loss: 0.02288954542018473, Final Batch Loss: 0.0\n",
      "Epoch 3094, Loss: 0.037048194790259004, Final Batch Loss: 0.0\n",
      "Epoch 3095, Loss: 0.01589702870887777, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 3096, Loss: 0.011602464190218598, Final Batch Loss: 0.0009897815762087703\n",
      "Epoch 3097, Loss: 0.008072382770478725, Final Batch Loss: 0.0\n",
      "Epoch 3098, Loss: 0.029324186354642734, Final Batch Loss: 0.00020311199477873743\n",
      "Epoch 3099, Loss: 0.010547437355853617, Final Batch Loss: 0.0\n",
      "Epoch 3100, Loss: 0.019794853636994958, Final Batch Loss: 0.0\n",
      "Epoch 3101, Loss: 0.014829872292409618, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3102, Loss: 0.02769550448283553, Final Batch Loss: 0.0\n",
      "Epoch 3103, Loss: 0.011324847406058325, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3104, Loss: 0.025140858546365052, Final Batch Loss: 0.0\n",
      "Epoch 3105, Loss: 0.02024271525237964, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3106, Loss: 0.012907950207591057, Final Batch Loss: 0.0\n",
      "Epoch 3107, Loss: 0.006861914065666497, Final Batch Loss: 0.0\n",
      "Epoch 3108, Loss: 0.04645956004969776, Final Batch Loss: 0.0037764438893646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3109, Loss: 0.013331650756299496, Final Batch Loss: 0.0\n",
      "Epoch 3110, Loss: 0.014496047515422106, Final Batch Loss: 0.0\n",
      "Epoch 3111, Loss: 0.01391810351924505, Final Batch Loss: 5.7338023907504976e-05\n",
      "Epoch 3112, Loss: 0.025878889369778335, Final Batch Loss: 0.0\n",
      "Epoch 3113, Loss: 0.01641852271677635, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 3114, Loss: 0.021494938525961516, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3115, Loss: 0.028941801516339183, Final Batch Loss: 0.0\n",
      "Epoch 3116, Loss: 0.031243307050317526, Final Batch Loss: 0.0\n",
      "Epoch 3117, Loss: 0.025912443292327225, Final Batch Loss: 0.0\n",
      "Epoch 3118, Loss: 0.010054673739432474, Final Batch Loss: 7.390948667307384e-06\n",
      "Epoch 3119, Loss: 0.015724653494544327, Final Batch Loss: 0.001100054127164185\n",
      "Epoch 3120, Loss: 0.01853801030665636, Final Batch Loss: 0.0\n",
      "Epoch 3121, Loss: 0.011104893404933591, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3122, Loss: 0.031365471892051744, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3123, Loss: 0.016987101232871282, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3124, Loss: 0.012876963470262126, Final Batch Loss: 1.5616295058862306e-05\n",
      "Epoch 3125, Loss: 0.010291393788065761, Final Batch Loss: 0.0\n",
      "Epoch 3126, Loss: 0.0222263207715514, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 3127, Loss: 0.021715320646762848, Final Batch Loss: 0.0\n",
      "Epoch 3128, Loss: 0.024391282891883748, Final Batch Loss: 3.9934315282152966e-05\n",
      "Epoch 3129, Loss: 0.0332758747972548, Final Batch Loss: 0.0\n",
      "Epoch 3130, Loss: 0.010689305141568184, Final Batch Loss: 0.0\n",
      "Epoch 3131, Loss: 0.04174556606449187, Final Batch Loss: 0.0\n",
      "Epoch 3132, Loss: 0.012039145884045865, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 3133, Loss: 0.015903196638646477, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 3134, Loss: 0.02859906409867108, Final Batch Loss: 0.0\n",
      "Epoch 3135, Loss: 0.01868594461120665, Final Batch Loss: 0.0\n",
      "Epoch 3136, Loss: 0.021079992991872132, Final Batch Loss: 0.0\n",
      "Epoch 3137, Loss: 0.017401070064806845, Final Batch Loss: 3.1709168979432434e-05\n",
      "Epoch 3138, Loss: 0.024705084273591638, Final Batch Loss: 0.0\n",
      "Epoch 3139, Loss: 0.014497129479394744, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3140, Loss: 0.01707177038770169, Final Batch Loss: 0.0\n",
      "Epoch 3141, Loss: 0.013202484115026891, Final Batch Loss: 0.0\n",
      "Epoch 3142, Loss: 0.009335841983556747, Final Batch Loss: 0.0\n",
      "Epoch 3143, Loss: 0.02044634032063186, Final Batch Loss: 0.0\n",
      "Epoch 3144, Loss: 0.014396639169717673, Final Batch Loss: 0.00011538793478393927\n",
      "Epoch 3145, Loss: 0.0400344543158937, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3146, Loss: 0.027429248206317425, Final Batch Loss: 0.0\n",
      "Epoch 3147, Loss: 0.024423492490313947, Final Batch Loss: 0.0\n",
      "Epoch 3148, Loss: 0.015871081860495906, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 3149, Loss: 0.03136761114001274, Final Batch Loss: 0.0\n",
      "Epoch 3150, Loss: 0.015925649786360907, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3151, Loss: 0.02359278395306319, Final Batch Loss: 0.0\n",
      "Epoch 3152, Loss: 0.019907772191800177, Final Batch Loss: 0.0016319541027769446\n",
      "Epoch 3153, Loss: 0.01412268914282322, Final Batch Loss: 0.0\n",
      "Epoch 3154, Loss: 0.02335377337749378, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 3155, Loss: 0.03144590137526393, Final Batch Loss: 0.0\n",
      "Epoch 3156, Loss: 0.027111499337479472, Final Batch Loss: 0.0019704941660165787\n",
      "Epoch 3157, Loss: 0.03209795127622783, Final Batch Loss: 0.0009826361201703548\n",
      "Epoch 3158, Loss: 0.009043205296620727, Final Batch Loss: 0.0\n",
      "Epoch 3159, Loss: 0.013109288175883194, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3160, Loss: 0.021188236685702577, Final Batch Loss: 0.0002961912250611931\n",
      "Epoch 3161, Loss: 0.012746338965371251, Final Batch Loss: 0.0\n",
      "Epoch 3162, Loss: 0.018118080753083632, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 3163, Loss: 0.008680932456570645, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3164, Loss: 0.008637697203084826, Final Batch Loss: 0.0\n",
      "Epoch 3165, Loss: 0.01717688632197678, Final Batch Loss: 0.0\n",
      "Epoch 3166, Loss: 0.019050943024922162, Final Batch Loss: 0.001741322805173695\n",
      "Epoch 3167, Loss: 0.004108906025010128, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3168, Loss: 0.01701191463507712, Final Batch Loss: 0.0\n",
      "Epoch 3169, Loss: 0.029034455539658666, Final Batch Loss: 0.0\n",
      "Epoch 3170, Loss: 0.01399732869822401, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3171, Loss: 0.020281080622226, Final Batch Loss: 0.0\n",
      "Epoch 3172, Loss: 0.009076031623408198, Final Batch Loss: 0.0\n",
      "Epoch 3173, Loss: 0.017224790295578885, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3174, Loss: 0.010711547685787082, Final Batch Loss: 0.0\n",
      "Epoch 3175, Loss: 0.019610698794167547, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 3176, Loss: 0.009341980679892004, Final Batch Loss: 0.0024125061463564634\n",
      "Epoch 3177, Loss: 0.06855702170287259, Final Batch Loss: 0.0003250309091527015\n",
      "Epoch 3178, Loss: 0.012737532786559314, Final Batch Loss: 0.0\n",
      "Epoch 3179, Loss: 0.02414776897057891, Final Batch Loss: 0.0\n",
      "Epoch 3180, Loss: 0.012637574684049468, Final Batch Loss: 8.082063141046092e-05\n",
      "Epoch 3181, Loss: 0.005960020120255649, Final Batch Loss: 0.0\n",
      "Epoch 3182, Loss: 0.008429065050222562, Final Batch Loss: 2.8729025871143676e-05\n",
      "Epoch 3183, Loss: 0.010835446417218009, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3184, Loss: 0.021662595216184855, Final Batch Loss: 0.000562271336093545\n",
      "Epoch 3185, Loss: 0.022752138320356607, Final Batch Loss: 0.0\n",
      "Epoch 3186, Loss: 0.007563561375718564, Final Batch Loss: 0.000750736624468118\n",
      "Epoch 3187, Loss: 0.02487443841255299, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 3188, Loss: 0.036246529547490525, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3189, Loss: 0.01064968528226018, Final Batch Loss: 0.0\n",
      "Epoch 3190, Loss: 0.05364536010893062, Final Batch Loss: 0.026522202417254448\n",
      "Epoch 3191, Loss: 0.033794801973272115, Final Batch Loss: 0.0\n",
      "Epoch 3192, Loss: 0.010529241582844406, Final Batch Loss: 0.0016986002447083592\n",
      "Epoch 3193, Loss: 0.04389527812600136, Final Batch Loss: 0.0014541300479322672\n",
      "Epoch 3194, Loss: 0.017164976918138564, Final Batch Loss: 0.0\n",
      "Epoch 3195, Loss: 0.03524917736649513, Final Batch Loss: 0.0\n",
      "Epoch 3196, Loss: 0.03248877078294754, Final Batch Loss: 0.0\n",
      "Epoch 3197, Loss: 0.015203600982147236, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3198, Loss: 0.010959996288875118, Final Batch Loss: 0.0\n",
      "Epoch 3199, Loss: 0.0058902951423078775, Final Batch Loss: 0.0\n",
      "Epoch 3200, Loss: 0.015947238483924764, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3201, Loss: 0.0066196230764035136, Final Batch Loss: 0.0\n",
      "Epoch 3202, Loss: 0.005152892379555851, Final Batch Loss: 0.0\n",
      "Epoch 3203, Loss: 0.019293786957859993, Final Batch Loss: 0.0\n",
      "Epoch 3204, Loss: 0.016152684071130352, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 3205, Loss: 0.012130234041251242, Final Batch Loss: 0.0\n",
      "Epoch 3206, Loss: 0.026962009724229574, Final Batch Loss: 0.0\n",
      "Epoch 3207, Loss: 0.026584456558339298, Final Batch Loss: 0.0\n",
      "Epoch 3208, Loss: 0.022602803161134943, Final Batch Loss: 0.0003262225945945829\n",
      "Epoch 3209, Loss: 0.014090857467294882, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3210, Loss: 0.02768116840161383, Final Batch Loss: 0.0\n",
      "Epoch 3211, Loss: 0.008521974319592118, Final Batch Loss: 0.0\n",
      "Epoch 3212, Loss: 0.007995666936039925, Final Batch Loss: 0.0\n",
      "Epoch 3213, Loss: 0.011815729201771319, Final Batch Loss: 0.0\n",
      "Epoch 3214, Loss: 0.013751869119005278, Final Batch Loss: 0.0003906917118001729\n",
      "Epoch 3215, Loss: 0.014491090376395732, Final Batch Loss: 0.0\n",
      "Epoch 3216, Loss: 0.03472479688934982, Final Batch Loss: 0.0\n",
      "Epoch 3217, Loss: 0.016430569114163518, Final Batch Loss: 0.0\n",
      "Epoch 3218, Loss: 0.009959488538925143, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3219, Loss: 0.027249189792087236, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3220, Loss: 0.6703007682226598, Final Batch Loss: 0.6389834880828857\n",
      "Epoch 3221, Loss: 0.05915390548761934, Final Batch Loss: 0.0\n",
      "Epoch 3222, Loss: 0.12161178549285978, Final Batch Loss: 0.0015142414486035705\n",
      "Epoch 3223, Loss: 2.9304604902863503, Final Batch Loss: 2.7446000576019287\n",
      "Epoch 3224, Loss: 0.04899473837571122, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3225, Loss: 0.1782156303524971, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3226, Loss: 0.44982826709747314, Final Batch Loss: 0.0\n",
      "Epoch 3227, Loss: 0.4062996953725815, Final Batch Loss: 0.0\n",
      "Epoch 3228, Loss: 2.227653294801712, Final Batch Loss: 1.8228495121002197\n",
      "Epoch 3229, Loss: 0.3179265856742859, Final Batch Loss: 0.0\n",
      "Epoch 3230, Loss: 0.24667287804186344, Final Batch Loss: 0.0\n",
      "Epoch 3231, Loss: 0.12557208957150578, Final Batch Loss: 0.008677276782691479\n",
      "Epoch 3232, Loss: 0.13486307743005455, Final Batch Loss: 0.0008611546363681555\n",
      "Epoch 3233, Loss: 0.11806327709928155, Final Batch Loss: 0.0031688022427260876\n",
      "Epoch 3234, Loss: 0.12211090326286467, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3235, Loss: 0.11022289913671557, Final Batch Loss: 7.760223525110632e-05\n",
      "Epoch 3236, Loss: 0.09005421260371804, Final Batch Loss: 0.0\n",
      "Epoch 3237, Loss: 0.12122897058725357, Final Batch Loss: 0.010524721816182137\n",
      "Epoch 3238, Loss: 0.07718746358295903, Final Batch Loss: 0.0003688847064040601\n",
      "Epoch 3239, Loss: 0.14101091399786014, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3240, Loss: 0.09679154632613063, Final Batch Loss: 0.00488386070355773\n",
      "Epoch 3241, Loss: 0.07905549742281437, Final Batch Loss: 0.0\n",
      "Epoch 3242, Loss: 0.08674903586506844, Final Batch Loss: 0.0\n",
      "Epoch 3243, Loss: 0.10088445455767214, Final Batch Loss: 0.0\n",
      "Epoch 3244, Loss: 0.06926422752439976, Final Batch Loss: 0.0\n",
      "Epoch 3245, Loss: 0.0881823431700468, Final Batch Loss: 0.0\n",
      "Epoch 3246, Loss: 0.0511931519722566, Final Batch Loss: 0.0004285847535356879\n",
      "Epoch 3247, Loss: 0.09963104501366615, Final Batch Loss: 0.0\n",
      "Epoch 3248, Loss: 0.09184676688164473, Final Batch Loss: 0.0\n",
      "Epoch 3249, Loss: 0.0865124617703259, Final Batch Loss: 0.009483997710049152\n",
      "Epoch 3250, Loss: 0.06813335977494717, Final Batch Loss: 0.0038004331290721893\n",
      "Epoch 3251, Loss: 0.08330781757831573, Final Batch Loss: 0.0\n",
      "Epoch 3252, Loss: 0.27387527748942375, Final Batch Loss: 0.184380903840065\n",
      "Epoch 3253, Loss: 0.04721889737993479, Final Batch Loss: 0.0\n",
      "Epoch 3254, Loss: 0.06678260862827301, Final Batch Loss: 0.0\n",
      "Epoch 3255, Loss: 0.1312399646267295, Final Batch Loss: 0.057181548327207565\n",
      "Epoch 3256, Loss: 0.07972831156803295, Final Batch Loss: 0.0004101150552742183\n",
      "Epoch 3257, Loss: 0.06352438870817423, Final Batch Loss: 0.0\n",
      "Epoch 3258, Loss: 0.04952244227751379, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3259, Loss: 0.0808665375225246, Final Batch Loss: 0.0\n",
      "Epoch 3260, Loss: 0.07997618428498754, Final Batch Loss: 4.172316494077677e-06\n",
      "Epoch 3261, Loss: 0.10432556772138923, Final Batch Loss: 0.00020525732543319464\n",
      "Epoch 3262, Loss: 0.08664576054434292, Final Batch Loss: 9.679325739853084e-05\n",
      "Epoch 3263, Loss: 0.07440033957391279, Final Batch Loss: 9.333651541965082e-05\n",
      "Epoch 3264, Loss: 0.11687115393579006, Final Batch Loss: 0.017823413014411926\n",
      "Epoch 3265, Loss: 0.090230347646866, Final Batch Loss: 0.0002972637885250151\n",
      "Epoch 3266, Loss: 0.0521741554766777, Final Batch Loss: 0.00011324241495458409\n",
      "Epoch 3267, Loss: 0.051719770301133394, Final Batch Loss: 0.0\n",
      "Epoch 3268, Loss: 0.07919099618447945, Final Batch Loss: 0.0005535738891921937\n",
      "Epoch 3269, Loss: 0.057004014030098915, Final Batch Loss: 0.0\n",
      "Epoch 3270, Loss: 0.06858279556035995, Final Batch Loss: 0.0\n",
      "Epoch 3271, Loss: 0.07997388206421618, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3272, Loss: 0.07667125016450882, Final Batch Loss: 0.0\n",
      "Epoch 3273, Loss: 0.0653407818172127, Final Batch Loss: 0.0\n",
      "Epoch 3274, Loss: 0.0555288465693593, Final Batch Loss: 0.0\n",
      "Epoch 3275, Loss: 0.052705855341628194, Final Batch Loss: 0.003743428038433194\n",
      "Epoch 3276, Loss: 0.15555571671575308, Final Batch Loss: 0.10893651843070984\n",
      "Epoch 3277, Loss: 0.06498096663563047, Final Batch Loss: 2.586808113846928e-05\n",
      "Epoch 3278, Loss: 0.05959283886471667, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3279, Loss: 0.05689189394479399, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 3280, Loss: 0.06328298826701939, Final Batch Loss: 0.0\n",
      "Epoch 3281, Loss: 0.06340824672952294, Final Batch Loss: 0.0\n",
      "Epoch 3282, Loss: 0.0708570908755064, Final Batch Loss: 0.0\n",
      "Epoch 3283, Loss: 0.07889929856173694, Final Batch Loss: 0.02553216740489006\n",
      "Epoch 3284, Loss: 0.11225411528721452, Final Batch Loss: 0.04452024772763252\n",
      "Epoch 3285, Loss: 0.05632057340699248, Final Batch Loss: 0.0003526780928950757\n",
      "Epoch 3286, Loss: 0.05423774989321828, Final Batch Loss: 0.0\n",
      "Epoch 3287, Loss: 0.05325303931022063, Final Batch Loss: 0.0006550788530148566\n",
      "Epoch 3288, Loss: 0.06952089979313314, Final Batch Loss: 0.0032320187892764807\n",
      "Epoch 3289, Loss: 0.058711723424494267, Final Batch Loss: 0.0\n",
      "Epoch 3290, Loss: 0.04367192971039913, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 3291, Loss: 0.0648807492107153, Final Batch Loss: 0.0\n",
      "Epoch 3292, Loss: 0.04321346298820572, Final Batch Loss: 8.5588610090781e-05\n",
      "Epoch 3293, Loss: 0.05758011946454644, Final Batch Loss: 0.006051314063370228\n",
      "Epoch 3294, Loss: 0.06880894603818888, Final Batch Loss: 3.790783375734463e-05\n",
      "Epoch 3295, Loss: 0.06806275900453329, Final Batch Loss: 0.002720348071306944\n",
      "Epoch 3296, Loss: 0.07243814785033464, Final Batch Loss: 0.0\n",
      "Epoch 3297, Loss: 0.04205104149878025, Final Batch Loss: 0.0\n",
      "Epoch 3298, Loss: 0.052895413246005774, Final Batch Loss: 0.0\n",
      "Epoch 3299, Loss: 0.04787885257974267, Final Batch Loss: 0.0\n",
      "Epoch 3300, Loss: 0.0422488562471699, Final Batch Loss: 0.00017009719158522785\n",
      "Epoch 3301, Loss: 0.08636040682904422, Final Batch Loss: 0.04020790755748749\n",
      "Epoch 3302, Loss: 0.031700583174824715, Final Batch Loss: 0.0\n",
      "Epoch 3303, Loss: 0.044471021274375744, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3304, Loss: 0.054597366601228714, Final Batch Loss: 0.011598181910812855\n",
      "Epoch 3305, Loss: 0.027639422565698624, Final Batch Loss: 0.0\n",
      "Epoch 3306, Loss: 0.049487664829939604, Final Batch Loss: 0.0\n",
      "Epoch 3307, Loss: 0.07831903756596148, Final Batch Loss: 0.020365538075566292\n",
      "Epoch 3308, Loss: 0.04502602692809887, Final Batch Loss: 4.768258077092469e-05\n",
      "Epoch 3309, Loss: 0.03873614780604839, Final Batch Loss: 0.0\n",
      "Epoch 3310, Loss: 0.0686731506138969, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3311, Loss: 0.03709967085160315, Final Batch Loss: 0.0\n",
      "Epoch 3312, Loss: 0.06970214554166887, Final Batch Loss: 8.749579137656838e-05\n",
      "Epoch 3313, Loss: 0.06057317042723298, Final Batch Loss: 0.0\n",
      "Epoch 3314, Loss: 0.04534586425870657, Final Batch Loss: 0.0\n",
      "Epoch 3315, Loss: 0.0384778615552932, Final Batch Loss: 0.002698948374018073\n",
      "Epoch 3316, Loss: 0.050263626420019136, Final Batch Loss: 1.2755313036905136e-05\n",
      "Epoch 3317, Loss: 0.17644918547011912, Final Batch Loss: 0.14665113389492035\n",
      "Epoch 3318, Loss: 0.04347188852261752, Final Batch Loss: 0.0005628670332953334\n",
      "Epoch 3319, Loss: 0.07471002545207739, Final Batch Loss: 0.0\n",
      "Epoch 3320, Loss: 0.04551100428216159, Final Batch Loss: 0.0041276742704212666\n",
      "Epoch 3321, Loss: 0.04589585237772553, Final Batch Loss: 3.7431014789035544e-05\n",
      "Epoch 3322, Loss: 0.04553284193389118, Final Batch Loss: 0.0\n",
      "Epoch 3323, Loss: 5.14269183925353, Final Batch Loss: 5.11647367477417\n",
      "Epoch 3324, Loss: 0.03630027428152971, Final Batch Loss: 0.00014494798961095512\n",
      "Epoch 3325, Loss: 0.04254598543047905, Final Batch Loss: 0.0\n",
      "Epoch 3326, Loss: 0.04895566217601299, Final Batch Loss: 0.0\n",
      "Epoch 3327, Loss: 0.13000585324971325, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3328, Loss: 0.06526247877627611, Final Batch Loss: 0.01600431464612484\n",
      "Epoch 3329, Loss: 0.045063316822052, Final Batch Loss: 0.0\n",
      "Epoch 3330, Loss: 0.05638308264315128, Final Batch Loss: 0.0\n",
      "Epoch 3331, Loss: 0.06151963770389557, Final Batch Loss: 0.003808746114373207\n",
      "Epoch 3332, Loss: 0.0793332969769267, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3333, Loss: 0.04311166889965534, Final Batch Loss: 0.0\n",
      "Epoch 3334, Loss: 0.05576778686372563, Final Batch Loss: 0.0003135904553346336\n",
      "Epoch 3335, Loss: 0.06100084260106087, Final Batch Loss: 0.0\n",
      "Epoch 3336, Loss: 0.045669110491871834, Final Batch Loss: 0.011899086646735668\n",
      "Epoch 3337, Loss: 0.04318956338101998, Final Batch Loss: 0.00031549722189083695\n",
      "Epoch 3338, Loss: 0.025853042956384797, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3339, Loss: 0.04289866707404144, Final Batch Loss: 0.0004881620698142797\n",
      "Epoch 3340, Loss: 0.03302276524482295, Final Batch Loss: 8.964136941358447e-05\n",
      "Epoch 3341, Loss: 0.029111044481396675, Final Batch Loss: 0.0\n",
      "Epoch 3342, Loss: 0.027613364160060883, Final Batch Loss: 0.0\n",
      "Epoch 3343, Loss: 0.03199712419882417, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3344, Loss: 0.046065547969192266, Final Batch Loss: 0.0\n",
      "Epoch 3345, Loss: 0.043763598426835415, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3346, Loss: 0.026922156946966425, Final Batch Loss: 0.00037150635034777224\n",
      "Epoch 3347, Loss: 0.03043857729062438, Final Batch Loss: 0.0\n",
      "Epoch 3348, Loss: 0.026817192789167166, Final Batch Loss: 0.0\n",
      "Epoch 3349, Loss: 0.03518241969868541, Final Batch Loss: 0.0\n",
      "Epoch 3350, Loss: 0.03073801054051728, Final Batch Loss: 3.0397906812140718e-05\n",
      "Epoch 3351, Loss: 0.024896629620343447, Final Batch Loss: 0.0\n",
      "Epoch 3352, Loss: 0.06599239725619555, Final Batch Loss: 0.03251218795776367\n",
      "Epoch 3353, Loss: 0.03857185551896691, Final Batch Loss: 0.0\n",
      "Epoch 3354, Loss: 0.02788015501573682, Final Batch Loss: 0.0\n",
      "Epoch 3355, Loss: 0.030951471999287605, Final Batch Loss: 0.0\n",
      "Epoch 3356, Loss: 0.019990248139947653, Final Batch Loss: 0.0\n",
      "Epoch 3357, Loss: 0.02644062042236328, Final Batch Loss: 0.0026043090038001537\n",
      "Epoch 3358, Loss: 0.02021353480813559, Final Batch Loss: 0.00013314791431184858\n",
      "Epoch 3359, Loss: 0.029577043838799, Final Batch Loss: 0.0035426970571279526\n",
      "Epoch 3360, Loss: 0.02597792701999424, Final Batch Loss: 4.8397800128441304e-05\n",
      "Epoch 3361, Loss: 0.03298457432538271, Final Batch Loss: 0.0\n",
      "Epoch 3362, Loss: 0.019463867851300165, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 3363, Loss: 0.03164895885856822, Final Batch Loss: 0.0009366653976030648\n",
      "Epoch 3364, Loss: 0.034000216983258724, Final Batch Loss: 0.0\n",
      "Epoch 3365, Loss: 0.031015663174912333, Final Batch Loss: 0.010212075896561146\n",
      "Epoch 3366, Loss: 0.04044861299916391, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3367, Loss: 0.029189986176788807, Final Batch Loss: 0.0\n",
      "Epoch 3368, Loss: 0.035474080126164154, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3369, Loss: 0.025598245963919908, Final Batch Loss: 0.0007300095749087632\n",
      "Epoch 3370, Loss: 0.026815285440534353, Final Batch Loss: 0.0\n",
      "Epoch 3371, Loss: 0.02564866724424064, Final Batch Loss: 0.0\n",
      "Epoch 3372, Loss: 0.04088195159238239, Final Batch Loss: 2.062299427052494e-05\n",
      "Epoch 3373, Loss: 0.018010972067713737, Final Batch Loss: 0.0\n",
      "Epoch 3374, Loss: 0.04095751326531172, Final Batch Loss: 0.0\n",
      "Epoch 3375, Loss: 0.043194565281737596, Final Batch Loss: 0.0004086851258762181\n",
      "Epoch 3376, Loss: 0.028243626933544874, Final Batch Loss: 0.0\n",
      "Epoch 3377, Loss: 0.0294568482786417, Final Batch Loss: 0.012956246733665466\n",
      "Epoch 3378, Loss: 0.03926674055401236, Final Batch Loss: 0.0011816193582490087\n",
      "Epoch 3379, Loss: 0.05706663243472576, Final Batch Loss: 0.0\n",
      "Epoch 3380, Loss: 0.03162808148590557, Final Batch Loss: 1.3351351299206726e-05\n",
      "Epoch 3381, Loss: 0.02620537648908794, Final Batch Loss: 0.003724663285538554\n",
      "Epoch 3382, Loss: 0.04019951447844505, Final Batch Loss: 0.0\n",
      "Epoch 3383, Loss: 0.027952651027590036, Final Batch Loss: 0.0\n",
      "Epoch 3384, Loss: 0.025061459745643333, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3385, Loss: 0.022218758349481504, Final Batch Loss: 4.053033626405522e-05\n",
      "Epoch 3386, Loss: 0.029921589157311246, Final Batch Loss: 0.00013839241000823677\n",
      "Epoch 3387, Loss: 0.02405740038739168, Final Batch Loss: 3.135155202471651e-05\n",
      "Epoch 3388, Loss: 0.02908420143648982, Final Batch Loss: 0.0\n",
      "Epoch 3389, Loss: 0.03740737494081259, Final Batch Loss: 0.0\n",
      "Epoch 3390, Loss: 0.02367224730551243, Final Batch Loss: 0.0\n",
      "Epoch 3391, Loss: 0.06121302954852581, Final Batch Loss: 0.040718838572502136\n",
      "Epoch 3392, Loss: 0.04225726472213864, Final Batch Loss: 0.0\n",
      "Epoch 3393, Loss: 0.034285851288586855, Final Batch Loss: 0.0\n",
      "Epoch 3394, Loss: 0.020936789456747817, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3395, Loss: 0.03205388691276312, Final Batch Loss: 0.0018668619450181723\n",
      "Epoch 3396, Loss: 0.01473393360265618, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 3397, Loss: 0.01878584874793887, Final Batch Loss: 0.0\n",
      "Epoch 3398, Loss: 0.04587213194463402, Final Batch Loss: 9.023735765367746e-05\n",
      "Epoch 3399, Loss: 0.024126423057168722, Final Batch Loss: 0.0\n",
      "Epoch 3400, Loss: 0.01913774060085416, Final Batch Loss: 0.0\n",
      "Epoch 3401, Loss: 0.019894415279395616, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3402, Loss: 0.024540039245039225, Final Batch Loss: 0.0\n",
      "Epoch 3403, Loss: 0.015032161958515644, Final Batch Loss: 0.0\n",
      "Epoch 3404, Loss: 0.03605527244505424, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3405, Loss: 0.040313909063115716, Final Batch Loss: 0.008813410066068172\n",
      "Epoch 3406, Loss: 0.02134564472362399, Final Batch Loss: 0.0032423564698547125\n",
      "Epoch 3407, Loss: 0.026753908197861165, Final Batch Loss: 0.000558220490347594\n",
      "Epoch 3408, Loss: 0.01447121542878449, Final Batch Loss: 0.0\n",
      "Epoch 3409, Loss: 0.020550267305225134, Final Batch Loss: 0.006156290881335735\n",
      "Epoch 3410, Loss: 0.05963033903026371, Final Batch Loss: 4.327203714638017e-05\n",
      "Epoch 3411, Loss: 0.03116321548441192, Final Batch Loss: 7.366862701019272e-05\n",
      "Epoch 3412, Loss: 0.02068601083010435, Final Batch Loss: 0.0\n",
      "Epoch 3413, Loss: 0.01180872693657875, Final Batch Loss: 0.0\n",
      "Epoch 3414, Loss: 0.03556579758878797, Final Batch Loss: 0.0005925330333411694\n",
      "Epoch 3415, Loss: 0.019566846545785666, Final Batch Loss: 0.0\n",
      "Epoch 3416, Loss: 0.0157702285795267, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3417, Loss: 0.0378141505025269, Final Batch Loss: 3.8980677345534787e-05\n",
      "Epoch 3418, Loss: 0.022663029056275263, Final Batch Loss: 0.0003567297535482794\n",
      "Epoch 3419, Loss: 0.013599561993025588, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3420, Loss: 0.02702820545528084, Final Batch Loss: 0.0017703588819131255\n",
      "Epoch 3421, Loss: 0.01727554271928966, Final Batch Loss: 0.0\n",
      "Epoch 3422, Loss: 0.01733779930509627, Final Batch Loss: 0.0013002045452594757\n",
      "Epoch 3423, Loss: 0.023255074112967122, Final Batch Loss: 2.3841574147809297e-05\n",
      "Epoch 3424, Loss: 0.021503198193386197, Final Batch Loss: 0.003690576646476984\n",
      "Epoch 3425, Loss: 0.028231293450517114, Final Batch Loss: 2.9801878554280847e-05\n",
      "Epoch 3426, Loss: 0.01604092493647613, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3427, Loss: 0.02503738821542356, Final Batch Loss: 0.0001691436773398891\n",
      "Epoch 3428, Loss: 0.015073304530233145, Final Batch Loss: 0.0\n",
      "Epoch 3429, Loss: 0.026769677535412484, Final Batch Loss: 2.610649426060263e-05\n",
      "Epoch 3430, Loss: 0.02014530502492562, Final Batch Loss: 0.00024005869636312127\n",
      "Epoch 3431, Loss: 0.021538093220435428, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3432, Loss: 0.031243201810866594, Final Batch Loss: 0.0\n",
      "Epoch 3433, Loss: 0.02564502220502618, Final Batch Loss: 1.2278481335670222e-05\n",
      "Epoch 3434, Loss: 0.02041607410137658, Final Batch Loss: 5.471556869451888e-05\n",
      "Epoch 3435, Loss: 0.025110909482464194, Final Batch Loss: 0.0\n",
      "Epoch 3436, Loss: 0.01912942831336295, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3437, Loss: 0.022042668104404584, Final Batch Loss: 0.00011693747364915907\n",
      "Epoch 3438, Loss: 0.02783391997218132, Final Batch Loss: 0.0\n",
      "Epoch 3439, Loss: 0.023377426397928502, Final Batch Loss: 3.1709168979432434e-05\n",
      "Epoch 3440, Loss: 0.022506837267428637, Final Batch Loss: 0.0\n",
      "Epoch 3441, Loss: 0.034487916502257576, Final Batch Loss: 2.658331868587993e-05\n",
      "Epoch 3442, Loss: 0.026596782903652638, Final Batch Loss: 8.964136941358447e-05\n",
      "Epoch 3443, Loss: 0.026204387766483705, Final Batch Loss: 2.6702524337451905e-05\n",
      "Epoch 3444, Loss: 0.019940665224567056, Final Batch Loss: 0.0\n",
      "Epoch 3445, Loss: 0.01786370319314301, Final Batch Loss: 0.0\n",
      "Epoch 3446, Loss: 0.032165466530386766, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 3447, Loss: 0.01639070058922698, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3448, Loss: 0.026787085735122673, Final Batch Loss: 0.000179036331246607\n",
      "Epoch 3449, Loss: 0.021314511657692492, Final Batch Loss: 0.0011399445356801152\n",
      "Epoch 3450, Loss: 0.024991712998428284, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3451, Loss: 0.02068834356032312, Final Batch Loss: 0.0\n",
      "Epoch 3452, Loss: 0.008843574672937393, Final Batch Loss: 0.0\n",
      "Epoch 3453, Loss: 0.03503423323854804, Final Batch Loss: 0.0\n",
      "Epoch 3454, Loss: 0.02150130225339808, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3455, Loss: 0.027403216809034348, Final Batch Loss: 0.0\n",
      "Epoch 3456, Loss: 0.015281154424855004, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3457, Loss: 0.013911899295635521, Final Batch Loss: 0.0\n",
      "Epoch 3458, Loss: 0.013665674107869563, Final Batch Loss: 7.748573807475623e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3459, Loss: 0.024052383843809366, Final Batch Loss: 0.0\n",
      "Epoch 3460, Loss: 0.05165657866746187, Final Batch Loss: 0.0\n",
      "Epoch 3461, Loss: 0.022586217841762846, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 3462, Loss: 0.01518285961174115, Final Batch Loss: 1.537788011773955e-05\n",
      "Epoch 3463, Loss: 0.0210209172219038, Final Batch Loss: 0.0\n",
      "Epoch 3464, Loss: 0.011538868770003319, Final Batch Loss: 0.0\n",
      "Epoch 3465, Loss: 0.02025328017771244, Final Batch Loss: 0.0\n",
      "Epoch 3466, Loss: 0.023454157169908285, Final Batch Loss: 0.004748496692627668\n",
      "Epoch 3467, Loss: 0.010170524823479354, Final Batch Loss: 0.0\n",
      "Epoch 3468, Loss: 0.013234535930678248, Final Batch Loss: 0.0\n",
      "Epoch 3469, Loss: 0.021497403969988227, Final Batch Loss: 0.0019850090611726046\n",
      "Epoch 3470, Loss: 0.03452578508586157, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 3471, Loss: 0.012450226815417409, Final Batch Loss: 0.0\n",
      "Epoch 3472, Loss: 0.018061148854030762, Final Batch Loss: 3.302042750874534e-05\n",
      "Epoch 3473, Loss: 0.012365181930356073, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3474, Loss: 0.0123449542443268, Final Batch Loss: 0.0001776060671545565\n",
      "Epoch 3475, Loss: 0.015218936832297913, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 3476, Loss: 0.014032527571544051, Final Batch Loss: 0.0022852513939142227\n",
      "Epoch 3477, Loss: 0.0277720709782443, Final Batch Loss: 0.00011085849109804258\n",
      "Epoch 3478, Loss: 0.029203113523180946, Final Batch Loss: 1.490105023549404e-05\n",
      "Epoch 3479, Loss: 0.020939833018928766, Final Batch Loss: 0.0\n",
      "Epoch 3480, Loss: 0.015224884962663054, Final Batch Loss: 0.0013450870756059885\n",
      "Epoch 3481, Loss: 0.05599564011208713, Final Batch Loss: 0.04189712181687355\n",
      "Epoch 3482, Loss: 0.0238884111167863, Final Batch Loss: 0.0004528927383944392\n",
      "Epoch 3483, Loss: 0.0298074539750246, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3484, Loss: 0.03456972085405141, Final Batch Loss: 0.007605170365422964\n",
      "Epoch 3485, Loss: 0.03986769774928689, Final Batch Loss: 0.0\n",
      "Epoch 3486, Loss: 0.01967432651827039, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 3487, Loss: 0.014323396608233452, Final Batch Loss: 0.0\n",
      "Epoch 3488, Loss: 0.014261574717238545, Final Batch Loss: 0.0\n",
      "Epoch 3489, Loss: 0.03427828149870038, Final Batch Loss: 0.0\n",
      "Epoch 3490, Loss: 0.01215226016483939, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 3491, Loss: 0.02718061802079319, Final Batch Loss: 1.549708758830093e-05\n",
      "Epoch 3492, Loss: 0.01049045062973164, Final Batch Loss: 0.00012039413559250534\n",
      "Epoch 3493, Loss: 0.017928807064834018, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3494, Loss: 0.022536539589054883, Final Batch Loss: 0.015802744776010513\n",
      "Epoch 3495, Loss: 0.017558910438310704, Final Batch Loss: 2.062299427052494e-05\n",
      "Epoch 3496, Loss: 0.05824686726555228, Final Batch Loss: 0.0010880271438509226\n",
      "Epoch 3497, Loss: 0.013822301989414143, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3498, Loss: 0.014923852868378162, Final Batch Loss: 0.0\n",
      "Epoch 3499, Loss: 0.022032533772289753, Final Batch Loss: 0.0\n",
      "Epoch 3500, Loss: 0.02000184589996934, Final Batch Loss: 0.0\n",
      "Epoch 3501, Loss: 0.020699516053923617, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3502, Loss: 1.256380507024005, Final Batch Loss: 1.240180253982544\n",
      "Epoch 3503, Loss: 0.03594777872785926, Final Batch Loss: 0.0\n",
      "Epoch 3504, Loss: 0.14297359436750412, Final Batch Loss: 0.0\n",
      "Epoch 3505, Loss: 0.26404916506726295, Final Batch Loss: 0.0002108589978888631\n",
      "Epoch 3506, Loss: 1.4009996205568314, Final Batch Loss: 1.087348461151123\n",
      "Epoch 3507, Loss: 0.10729976184665446, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3508, Loss: 1.8588234279304743, Final Batch Loss: 1.8184794187545776\n",
      "Epoch 3509, Loss: 0.029813711997121572, Final Batch Loss: 0.0\n",
      "Epoch 3510, Loss: 0.05588100291788578, Final Batch Loss: 0.0\n",
      "Epoch 3511, Loss: 0.06808034227924509, Final Batch Loss: 1.3828182090946939e-05\n",
      "Epoch 3512, Loss: 0.07504942081868649, Final Batch Loss: 0.0\n",
      "Epoch 3513, Loss: 0.11496668681468236, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3514, Loss: 0.09701124206185341, Final Batch Loss: 0.0\n",
      "Epoch 3515, Loss: 0.11454483680427074, Final Batch Loss: 0.0\n",
      "Epoch 3516, Loss: 0.07548188697535352, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3517, Loss: 0.07783119101077318, Final Batch Loss: 0.0\n",
      "Epoch 3518, Loss: 0.07248398661612754, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3519, Loss: 0.0666015618480742, Final Batch Loss: 0.005160938482731581\n",
      "Epoch 3520, Loss: 0.049620509123087686, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 3521, Loss: 0.06414170167408884, Final Batch Loss: 0.0\n",
      "Epoch 3522, Loss: 0.04288410529261455, Final Batch Loss: 0.000782183778937906\n",
      "Epoch 3523, Loss: 0.04787135020887945, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 3524, Loss: 0.05736720506774873, Final Batch Loss: 1.3112935448589269e-05\n",
      "Epoch 3525, Loss: 0.06234137248247862, Final Batch Loss: 0.0\n",
      "Epoch 3526, Loss: 0.047199155104863166, Final Batch Loss: 1.4066597032069694e-05\n",
      "Epoch 3527, Loss: 0.04549720790237188, Final Batch Loss: 0.0\n",
      "Epoch 3528, Loss: 0.038944093509485356, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3529, Loss: 0.0413847779527714, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 3530, Loss: 0.06179394555147155, Final Batch Loss: 1.883488948806189e-05\n",
      "Epoch 3531, Loss: 0.04452250144822756, Final Batch Loss: 0.00010644822759786621\n",
      "Epoch 3532, Loss: 0.03457618923857808, Final Batch Loss: 0.0\n",
      "Epoch 3533, Loss: 0.031215365044772625, Final Batch Loss: 0.0\n",
      "Epoch 3534, Loss: 0.06244152411818504, Final Batch Loss: 0.0\n",
      "Epoch 3535, Loss: 0.33727900870144367, Final Batch Loss: 0.28984931111335754\n",
      "Epoch 3536, Loss: 0.05141119658946991, Final Batch Loss: 0.0\n",
      "Epoch 3537, Loss: 0.036194350046571344, Final Batch Loss: 0.0005544078885577619\n",
      "Epoch 3538, Loss: 0.042475843205465935, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 3539, Loss: 0.08542988076806068, Final Batch Loss: 0.0\n",
      "Epoch 3540, Loss: 0.060645941644907, Final Batch Loss: 0.0\n",
      "Epoch 3541, Loss: 0.056725245900423715, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3542, Loss: 0.0726786395534873, Final Batch Loss: 0.030588189139962196\n",
      "Epoch 3543, Loss: 0.054727165361327934, Final Batch Loss: 1.6331539882230572e-05\n",
      "Epoch 3544, Loss: 0.10412146151065826, Final Batch Loss: 0.030624261125922203\n",
      "Epoch 3545, Loss: 0.04202739428728819, Final Batch Loss: 0.0\n",
      "Epoch 3546, Loss: 0.03559211362153292, Final Batch Loss: 0.002952028764411807\n",
      "Epoch 3547, Loss: 0.027976338517873955, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3548, Loss: 0.05518382322040338, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3549, Loss: 0.03931333823129535, Final Batch Loss: 0.0\n",
      "Epoch 3550, Loss: 0.0353099200874567, Final Batch Loss: 0.0\n",
      "Epoch 3551, Loss: 0.03667856151878368, Final Batch Loss: 9.107174992095679e-05\n",
      "Epoch 3552, Loss: 0.031633983831852674, Final Batch Loss: 0.0\n",
      "Epoch 3553, Loss: 0.031496959733203767, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 3554, Loss: 0.024178815539919185, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3555, Loss: 0.029971991665661335, Final Batch Loss: 0.0\n",
      "Epoch 3556, Loss: 0.05975322099402547, Final Batch Loss: 0.0\n",
      "Epoch 3557, Loss: 0.020001237513497472, Final Batch Loss: 0.0\n",
      "Epoch 3558, Loss: 0.030441782437257814, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3559, Loss: 0.025491238106042147, Final Batch Loss: 0.0\n",
      "Epoch 3560, Loss: 0.027780972857726738, Final Batch Loss: 0.0002325502864550799\n",
      "Epoch 3561, Loss: 0.04504561121575534, Final Batch Loss: 0.0\n",
      "Epoch 3562, Loss: 0.038237374828895554, Final Batch Loss: 5.9602869441732764e-05\n",
      "Epoch 3563, Loss: 0.030808123759925365, Final Batch Loss: 0.0\n",
      "Epoch 3564, Loss: 0.03200402716174722, Final Batch Loss: 0.011524532921612263\n",
      "Epoch 3565, Loss: 0.028274641835650982, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3566, Loss: 0.03183600411284715, Final Batch Loss: 0.00029392691794782877\n",
      "Epoch 3567, Loss: 0.02519939374178648, Final Batch Loss: 0.0\n",
      "Epoch 3568, Loss: 0.03137657814659178, Final Batch Loss: 0.0017482249531894922\n",
      "Epoch 3569, Loss: 0.03230570978485048, Final Batch Loss: 0.0026342712808400393\n",
      "Epoch 3570, Loss: 0.03838483197489495, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3571, Loss: 0.0668171551078558, Final Batch Loss: 0.029662007465958595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3572, Loss: 0.06535542360506952, Final Batch Loss: 0.002571730175986886\n",
      "Epoch 3573, Loss: 0.03525017714127898, Final Batch Loss: 0.0\n",
      "Epoch 3574, Loss: 0.03853791952133179, Final Batch Loss: 0.0\n",
      "Epoch 3575, Loss: 0.052713312208652496, Final Batch Loss: 0.022557569667696953\n",
      "Epoch 3576, Loss: 0.03816438466310501, Final Batch Loss: 0.0\n",
      "Epoch 3577, Loss: 0.019643384686787613, Final Batch Loss: 0.00012051333033014089\n",
      "Epoch 3578, Loss: 0.03256749268621206, Final Batch Loss: 0.0\n",
      "Epoch 3579, Loss: 0.03014687483664602, Final Batch Loss: 0.0\n",
      "Epoch 3580, Loss: 0.022637812988250516, Final Batch Loss: 4.076874756719917e-05\n",
      "Epoch 3581, Loss: 0.06061436608342774, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3582, Loss: 0.035333991050720215, Final Batch Loss: 0.0\n",
      "Epoch 3583, Loss: 0.03671570726692153, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 3584, Loss: 0.02774578332901001, Final Batch Loss: 0.0\n",
      "Epoch 3585, Loss: 0.0742149231955409, Final Batch Loss: 0.014556166715919971\n",
      "Epoch 3586, Loss: 0.026023103564511985, Final Batch Loss: 0.00022349244682118297\n",
      "Epoch 3587, Loss: 0.0265119601654078, Final Batch Loss: 7.986990567587782e-06\n",
      "Epoch 3588, Loss: 0.0318274786695838, Final Batch Loss: 0.0\n",
      "Epoch 3589, Loss: 0.04799204133450985, Final Batch Loss: 0.0\n",
      "Epoch 3590, Loss: 0.030521096428856254, Final Batch Loss: 0.0\n",
      "Epoch 3591, Loss: 0.030879137106239796, Final Batch Loss: 0.00705749960616231\n",
      "Epoch 3592, Loss: 0.01656988635659218, Final Batch Loss: 0.0\n",
      "Epoch 3593, Loss: 0.023950014816364273, Final Batch Loss: 0.0003741279651876539\n",
      "Epoch 3594, Loss: 0.04880235041491687, Final Batch Loss: 0.022466422989964485\n",
      "Epoch 3595, Loss: 0.023857289855186536, Final Batch Loss: 1.1801649634435307e-05\n",
      "Epoch 3596, Loss: 0.03693490680598188, Final Batch Loss: 0.00014983485743869096\n",
      "Epoch 3597, Loss: 0.05322972498834133, Final Batch Loss: 0.0009999042376875877\n",
      "Epoch 3598, Loss: 0.025043191941222176, Final Batch Loss: 0.00013410145766101778\n",
      "Epoch 3599, Loss: 0.019653458148241043, Final Batch Loss: 0.0\n",
      "Epoch 3600, Loss: 0.02626548753505631, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 3601, Loss: 0.035349343903355646, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3602, Loss: 0.030077263712541935, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3603, Loss: 0.02123905372718582, Final Batch Loss: 1.9788545614574105e-05\n",
      "Epoch 3604, Loss: 0.02113934839144349, Final Batch Loss: 0.0\n",
      "Epoch 3605, Loss: 0.02262528031127431, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3606, Loss: 0.025807415593135374, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 3607, Loss: 0.022236483404412866, Final Batch Loss: 0.0\n",
      "Epoch 3608, Loss: 0.017095953691750765, Final Batch Loss: 0.0\n",
      "Epoch 3609, Loss: 0.02721815649420023, Final Batch Loss: 0.0\n",
      "Epoch 3610, Loss: 0.07069396879523993, Final Batch Loss: 0.05019081011414528\n",
      "Epoch 3611, Loss: 0.032491417514393106, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 3612, Loss: 0.03970403596756, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3613, Loss: 0.03261555708013475, Final Batch Loss: 0.0\n",
      "Epoch 3614, Loss: 0.014645180199295282, Final Batch Loss: 0.00011717586312443018\n",
      "Epoch 3615, Loss: 0.026301676404273167, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 3616, Loss: 0.016703987028449774, Final Batch Loss: 0.0\n",
      "Epoch 3617, Loss: 0.039555967203341424, Final Batch Loss: 0.006149419117718935\n",
      "Epoch 3618, Loss: 0.022106494288777867, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3619, Loss: 0.020330377481514006, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 3620, Loss: 0.021941515180515125, Final Batch Loss: 0.00013457823661156\n",
      "Epoch 3621, Loss: 0.026571891270577908, Final Batch Loss: 0.0\n",
      "Epoch 3622, Loss: 0.08791830390691757, Final Batch Loss: 0.062303923070430756\n",
      "Epoch 3623, Loss: 0.03120756101588995, Final Batch Loss: 4.768360213347478e-06\n",
      "Epoch 3624, Loss: 0.11666008923202753, Final Batch Loss: 0.0\n",
      "Epoch 3625, Loss: 0.058670509373769164, Final Batch Loss: 0.017350204288959503\n",
      "Epoch 3626, Loss: 0.03413491274886837, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 3627, Loss: 0.050206213258206844, Final Batch Loss: 0.0\n",
      "Epoch 3628, Loss: 0.046143947169184685, Final Batch Loss: 0.0\n",
      "Epoch 3629, Loss: 0.0866591647209134, Final Batch Loss: 0.00014256415306590497\n",
      "Epoch 3630, Loss: 0.03672691248175397, Final Batch Loss: 2.169585604860913e-05\n",
      "Epoch 3631, Loss: 0.03492663288488984, Final Batch Loss: 0.0\n",
      "Epoch 3632, Loss: 0.02816065587103367, Final Batch Loss: 0.0\n",
      "Epoch 3633, Loss: 0.04845734376976907, Final Batch Loss: 2.8609820219571702e-05\n",
      "Epoch 3634, Loss: 0.017261606407942054, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3635, Loss: 0.01968732640671078, Final Batch Loss: 8.34430247778073e-05\n",
      "Epoch 3636, Loss: 0.020232940107234754, Final Batch Loss: 0.00012194366718176752\n",
      "Epoch 3637, Loss: 0.04777917638421059, Final Batch Loss: 0.0060484702698886395\n",
      "Epoch 3638, Loss: 0.03124915598834832, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3639, Loss: 0.019069597823317963, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3640, Loss: 0.02662460715509951, Final Batch Loss: 0.0\n",
      "Epoch 3641, Loss: 0.021136470139026642, Final Batch Loss: 0.0\n",
      "Epoch 3642, Loss: 0.023920646868646145, Final Batch Loss: 0.0\n",
      "Epoch 3643, Loss: 0.021864084352273494, Final Batch Loss: 0.0007010624394752085\n",
      "Epoch 3644, Loss: 0.017986551392823458, Final Batch Loss: 0.0\n",
      "Epoch 3645, Loss: 0.024693829473108053, Final Batch Loss: 0.0\n",
      "Epoch 3646, Loss: 0.0372206433675899, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3647, Loss: 0.04519925708882511, Final Batch Loss: 0.019102418795228004\n",
      "Epoch 3648, Loss: 0.016397951869294047, Final Batch Loss: 0.0\n",
      "Epoch 3649, Loss: 0.018910677637904882, Final Batch Loss: 0.0\n",
      "Epoch 3650, Loss: 0.029113227385096252, Final Batch Loss: 0.0018797124503180385\n",
      "Epoch 3651, Loss: 0.017400442739017308, Final Batch Loss: 0.0017213303362950683\n",
      "Epoch 3652, Loss: 0.03994504455476999, Final Batch Loss: 0.0\n",
      "Epoch 3653, Loss: 0.011877366850967519, Final Batch Loss: 0.00012730741582345217\n",
      "Epoch 3654, Loss: 0.017482792725786567, Final Batch Loss: 0.0\n",
      "Epoch 3655, Loss: 0.01449523528572172, Final Batch Loss: 0.0\n",
      "Epoch 3656, Loss: 0.049843182088807225, Final Batch Loss: 0.0034458802547305822\n",
      "Epoch 3657, Loss: 0.029000751208513975, Final Batch Loss: 0.0\n",
      "Epoch 3658, Loss: 0.024078097951132804, Final Batch Loss: 0.0\n",
      "Epoch 3659, Loss: 0.029310780577333162, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3660, Loss: 0.02502757403999567, Final Batch Loss: 0.0\n",
      "Epoch 3661, Loss: 0.02102951281267451, Final Batch Loss: 6.90197994117625e-05\n",
      "Epoch 3662, Loss: 0.013974077999591827, Final Batch Loss: 0.0\n",
      "Epoch 3663, Loss: 0.015521854300459381, Final Batch Loss: 6.437094270950183e-05\n",
      "Epoch 3664, Loss: 0.02935509174113804, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3665, Loss: 0.014781375648453832, Final Batch Loss: 0.0\n",
      "Epoch 3666, Loss: 0.03555739955845638, Final Batch Loss: 4.184158387943171e-05\n",
      "Epoch 3667, Loss: 0.02752968919230625, Final Batch Loss: 0.0\n",
      "Epoch 3668, Loss: 0.0158575497334823, Final Batch Loss: 0.0\n",
      "Epoch 3669, Loss: 0.015000308398157358, Final Batch Loss: 0.0\n",
      "Epoch 3670, Loss: 0.0241660273168236, Final Batch Loss: 0.0\n",
      "Epoch 3671, Loss: 0.013963603996671736, Final Batch Loss: 0.0\n",
      "Epoch 3672, Loss: 0.019743159863992332, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 3673, Loss: 0.03582229744642973, Final Batch Loss: 0.0015267394483089447\n",
      "Epoch 3674, Loss: 0.016053992439992726, Final Batch Loss: 0.0\n",
      "Epoch 3675, Loss: 0.017294386168941855, Final Batch Loss: 0.0\n",
      "Epoch 3676, Loss: 0.04486614908091724, Final Batch Loss: 0.020131781697273254\n",
      "Epoch 3677, Loss: 0.011949819279266194, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3678, Loss: 0.02537287853192538, Final Batch Loss: 0.0\n",
      "Epoch 3679, Loss: 0.024153929203748703, Final Batch Loss: 0.0\n",
      "Epoch 3680, Loss: 0.015070923371233391, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3681, Loss: 0.014344093855413576, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3682, Loss: 0.025447186770179542, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 3683, Loss: 0.02034358462515229, Final Batch Loss: 1.9907753085135482e-05\n",
      "Epoch 3684, Loss: 0.022166638867929578, Final Batch Loss: 0.0\n",
      "Epoch 3685, Loss: 0.012046657153405249, Final Batch Loss: 0.0\n",
      "Epoch 3686, Loss: 0.01746797643136233, Final Batch Loss: 0.0\n",
      "Epoch 3687, Loss: 0.02272106328746304, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3688, Loss: 0.026284011779353023, Final Batch Loss: 0.0\n",
      "Epoch 3689, Loss: 0.04325639524267899, Final Batch Loss: 6.437280717364047e-06\n",
      "Epoch 3690, Loss: 0.015050014946609735, Final Batch Loss: 0.0\n",
      "Epoch 3691, Loss: 0.009411554783582687, Final Batch Loss: 0.0\n",
      "Epoch 3692, Loss: 0.021825925912708044, Final Batch Loss: 0.0\n",
      "Epoch 3693, Loss: 0.03276609699241817, Final Batch Loss: 0.0\n",
      "Epoch 3694, Loss: 0.02958833123545901, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3695, Loss: 0.0248489279763362, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3696, Loss: 0.012172361195553094, Final Batch Loss: 0.0\n",
      "Epoch 3697, Loss: 0.013082076795399189, Final Batch Loss: 0.0\n",
      "Epoch 3698, Loss: 0.03479454802527471, Final Batch Loss: 8.4638240878121e-06\n",
      "Epoch 3699, Loss: 0.02715592680027612, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3700, Loss: 0.014606408774852753, Final Batch Loss: 0.0\n",
      "Epoch 3701, Loss: 0.03257312468485907, Final Batch Loss: 0.0\n",
      "Epoch 3702, Loss: 0.011029685358607821, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 3703, Loss: 0.028749575139897843, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3704, Loss: 0.0073626404628157616, Final Batch Loss: 0.0\n",
      "Epoch 3705, Loss: 0.010797549621202052, Final Batch Loss: 0.0\n",
      "Epoch 3706, Loss: 0.017226148396730423, Final Batch Loss: 0.0\n",
      "Epoch 3707, Loss: 0.022521358681842685, Final Batch Loss: 0.0\n",
      "Epoch 3708, Loss: 0.028235608595309714, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3709, Loss: 0.03319161589752184, Final Batch Loss: 6.55629628454335e-05\n",
      "Epoch 3710, Loss: 0.020765264285728335, Final Batch Loss: 0.0\n",
      "Epoch 3711, Loss: 0.01920547289773822, Final Batch Loss: 0.0\n",
      "Epoch 3712, Loss: 0.015450140279426705, Final Batch Loss: 0.00011574551899684593\n",
      "Epoch 3713, Loss: 0.006431206476918305, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 3714, Loss: 0.027822688687592745, Final Batch Loss: 0.0\n",
      "Epoch 3715, Loss: 0.02303098700258488, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 3716, Loss: 0.012853656776997013, Final Batch Loss: 2.0265558760002023e-06\n",
      "Epoch 3717, Loss: 0.020504537504166365, Final Batch Loss: 0.0\n",
      "Epoch 3718, Loss: 0.01658935332670808, Final Batch Loss: 0.0\n",
      "Epoch 3719, Loss: 0.044389192829839885, Final Batch Loss: 0.0006005152827128768\n",
      "Epoch 3720, Loss: 0.015089325839653611, Final Batch Loss: 0.0\n",
      "Epoch 3721, Loss: 0.014064405927342705, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3722, Loss: 0.014752196031622589, Final Batch Loss: 4.577531944960356e-05\n",
      "Epoch 3723, Loss: 0.04944003000855446, Final Batch Loss: 0.0\n",
      "Epoch 3724, Loss: 0.021059804130345583, Final Batch Loss: 0.0\n",
      "Epoch 3725, Loss: 0.021654645446687937, Final Batch Loss: 0.0\n",
      "Epoch 3726, Loss: 0.012909910350572318, Final Batch Loss: 0.0\n",
      "Epoch 3727, Loss: 0.022811834450294555, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 3728, Loss: 0.04154474101943606, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3729, Loss: 0.021015152102336287, Final Batch Loss: 0.0\n",
      "Epoch 3730, Loss: 0.017768264573533088, Final Batch Loss: 0.0007238152320496738\n",
      "Epoch 3731, Loss: 0.03119831252502081, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 3732, Loss: 0.02867840243561659, Final Batch Loss: 0.00013886917440686375\n",
      "Epoch 3733, Loss: 0.013374092993217346, Final Batch Loss: 1.0371154530730564e-05\n",
      "Epoch 3734, Loss: 0.016368471180612687, Final Batch Loss: 3.790783375734463e-05\n",
      "Epoch 3735, Loss: 0.013756188504771671, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3736, Loss: 0.016131136333569884, Final Batch Loss: 0.0027838307432830334\n",
      "Epoch 3737, Loss: 0.010421745013445616, Final Batch Loss: 0.0\n",
      "Epoch 3738, Loss: 0.026873885188251734, Final Batch Loss: 0.0\n",
      "Epoch 3739, Loss: 0.013598943303804845, Final Batch Loss: 0.00033790123416110873\n",
      "Epoch 3740, Loss: 0.020697661209851503, Final Batch Loss: 0.0\n",
      "Epoch 3741, Loss: 0.0194575572386384, Final Batch Loss: 0.0\n",
      "Epoch 3742, Loss: 0.02862715534865856, Final Batch Loss: 0.0\n",
      "Epoch 3743, Loss: 0.014586730161681771, Final Batch Loss: 0.0\n",
      "Epoch 3744, Loss: 0.012896158266812563, Final Batch Loss: 0.0\n",
      "Epoch 3745, Loss: 0.010554576059632836, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3746, Loss: 0.015607556939357892, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 3747, Loss: 0.03177280630916357, Final Batch Loss: 0.0\n",
      "Epoch 3748, Loss: 0.015433346037752926, Final Batch Loss: 0.0\n",
      "Epoch 3749, Loss: 0.019668306398664015, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3750, Loss: 0.011202597292140126, Final Batch Loss: 0.0\n",
      "Epoch 3751, Loss: 0.047828991067945026, Final Batch Loss: 8.785339014139026e-05\n",
      "Epoch 3752, Loss: 0.018850720487535, Final Batch Loss: 0.0\n",
      "Epoch 3753, Loss: 0.02936377818696201, Final Batch Loss: 0.0\n",
      "Epoch 3754, Loss: 0.030327449319770494, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3755, Loss: 0.023389894515275955, Final Batch Loss: 0.0\n",
      "Epoch 3756, Loss: 0.022162048378959298, Final Batch Loss: 0.0\n",
      "Epoch 3757, Loss: 0.013884805841371417, Final Batch Loss: 0.0\n",
      "Epoch 3758, Loss: 0.013914173002831376, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3759, Loss: 0.010810734471306205, Final Batch Loss: 0.0\n",
      "Epoch 3760, Loss: 0.022627696162089705, Final Batch Loss: 0.0\n",
      "Epoch 3761, Loss: 0.025700814789161086, Final Batch Loss: 0.0\n",
      "Epoch 3762, Loss: 0.01094114623265341, Final Batch Loss: 0.0\n",
      "Epoch 3763, Loss: 0.01716279494576156, Final Batch Loss: 0.0\n",
      "Epoch 3764, Loss: 0.01510475727263838, Final Batch Loss: 0.0\n",
      "Epoch 3765, Loss: 0.02276194654405117, Final Batch Loss: 0.0\n",
      "Epoch 3766, Loss: 0.017895342966767203, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 3767, Loss: 0.028427574696252123, Final Batch Loss: 0.00048387263086624444\n",
      "Epoch 3768, Loss: 0.021390192908143035, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3769, Loss: 0.023400958627462387, Final Batch Loss: 0.0\n",
      "Epoch 3770, Loss: 0.022364991600625217, Final Batch Loss: 0.0\n",
      "Epoch 3771, Loss: 0.010287248762324452, Final Batch Loss: 0.0\n",
      "Epoch 3772, Loss: 0.03159029223024845, Final Batch Loss: 0.0\n",
      "Epoch 3773, Loss: 0.015605101478286088, Final Batch Loss: 0.00027783826226368546\n",
      "Epoch 3774, Loss: 0.023541459097941697, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 3775, Loss: 0.019824996589363764, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3776, Loss: 0.016968818265013397, Final Batch Loss: 0.0\n",
      "Epoch 3777, Loss: 0.013484491730423542, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 3778, Loss: 0.00787867431029099, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3779, Loss: 0.007399694703053683, Final Batch Loss: 0.0\n",
      "Epoch 3780, Loss: 0.03696697938721627, Final Batch Loss: 0.0004931663861498237\n",
      "Epoch 3781, Loss: 0.03071073586716011, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 3782, Loss: 0.014190885005490372, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3783, Loss: 0.026096188012161292, Final Batch Loss: 8.05822346592322e-05\n",
      "Epoch 3784, Loss: 0.024749399395659566, Final Batch Loss: 0.0\n",
      "Epoch 3785, Loss: 0.011603744933381677, Final Batch Loss: 0.0\n",
      "Epoch 3786, Loss: 0.008288166543934494, Final Batch Loss: 0.0\n",
      "Epoch 3787, Loss: 0.010881917783990502, Final Batch Loss: 0.0\n",
      "Epoch 3788, Loss: 0.02881836472079158, Final Batch Loss: 0.0\n",
      "Epoch 3789, Loss: 0.03998330887406354, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3790, Loss: 0.013460373040288687, Final Batch Loss: 0.0\n",
      "Epoch 3791, Loss: 0.01733253401471302, Final Batch Loss: 0.0005505952867679298\n",
      "Epoch 3792, Loss: 0.01354732210165821, Final Batch Loss: 0.00015352977789007127\n",
      "Epoch 3793, Loss: 0.011840278515592217, Final Batch Loss: 0.0\n",
      "Epoch 3794, Loss: 0.008662172476419983, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3795, Loss: 0.023575081955641508, Final Batch Loss: 0.00846985075622797\n",
      "Epoch 3796, Loss: 0.005442487308755517, Final Batch Loss: 0.0\n",
      "Epoch 3797, Loss: 0.011214725906029344, Final Batch Loss: 0.0\n",
      "Epoch 3798, Loss: 0.0054478420643135905, Final Batch Loss: 0.0\n",
      "Epoch 3799, Loss: 0.011458923225177386, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3800, Loss: 0.023314027057494968, Final Batch Loss: 0.0005489272880367935\n",
      "Epoch 3801, Loss: 0.023882959503680468, Final Batch Loss: 0.0\n",
      "Epoch 3802, Loss: 0.012419515519923152, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3803, Loss: 0.012386506965412991, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 3804, Loss: 0.014324593108995032, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 3805, Loss: 0.011779408087022603, Final Batch Loss: 0.0\n",
      "Epoch 3806, Loss: 0.008724626386538148, Final Batch Loss: 0.0\n",
      "Epoch 3807, Loss: 0.008484682242851704, Final Batch Loss: 0.0\n",
      "Epoch 3808, Loss: 0.024295123483170755, Final Batch Loss: 0.0\n",
      "Epoch 3809, Loss: 0.015868342015892267, Final Batch Loss: 0.0\n",
      "Epoch 3810, Loss: 0.01325254631228745, Final Batch Loss: 0.0\n",
      "Epoch 3811, Loss: 0.0127653565723449, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3812, Loss: 0.028001474915072322, Final Batch Loss: 0.0\n",
      "Epoch 3813, Loss: 0.017327366755125695, Final Batch Loss: 2.610649426060263e-05\n",
      "Epoch 3814, Loss: 0.01934783603064716, Final Batch Loss: 0.0\n",
      "Epoch 3815, Loss: 0.008185134269297123, Final Batch Loss: 0.0\n",
      "Epoch 3816, Loss: 0.00918848872242961, Final Batch Loss: 0.0\n",
      "Epoch 3817, Loss: 0.027813649736344814, Final Batch Loss: 0.0\n",
      "Epoch 3818, Loss: 0.01661218679510057, Final Batch Loss: 0.0\n",
      "Epoch 3819, Loss: 0.00923667369352188, Final Batch Loss: 0.00018940561858471483\n",
      "Epoch 3820, Loss: 0.021277037914842367, Final Batch Loss: 0.0\n",
      "Epoch 3821, Loss: 0.014660815816569084, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 3822, Loss: 0.011127331759780645, Final Batch Loss: 0.0\n",
      "Epoch 3823, Loss: 0.015523640974606678, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 3824, Loss: 0.021063129883259535, Final Batch Loss: 0.0\n",
      "Epoch 3825, Loss: 0.010020080080721527, Final Batch Loss: 0.0\n",
      "Epoch 3826, Loss: 0.010526617639527558, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3827, Loss: 0.04120740800863132, Final Batch Loss: 0.0007905219099484384\n",
      "Epoch 3828, Loss: 0.017290826770476997, Final Batch Loss: 0.0\n",
      "Epoch 3829, Loss: 0.04726101830601692, Final Batch Loss: 0.0\n",
      "Epoch 3830, Loss: 0.010206602048128843, Final Batch Loss: 0.0\n",
      "Epoch 3831, Loss: 0.02816847211215645, Final Batch Loss: 0.0\n",
      "Epoch 3832, Loss: 0.021996180992566394, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3833, Loss: 0.01870542927463248, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 3834, Loss: 0.012596296132869611, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 3835, Loss: 0.009999331423387048, Final Batch Loss: 1.6093124941107817e-05\n",
      "Epoch 3836, Loss: 0.011898717377334833, Final Batch Loss: 0.0\n",
      "Epoch 3837, Loss: 0.00899335379654076, Final Batch Loss: 2.6940935640595853e-05\n",
      "Epoch 3838, Loss: 0.01661659777892055, Final Batch Loss: 2.1219027985353023e-05\n",
      "Epoch 3839, Loss: 0.01037243241341912, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3840, Loss: 0.014936631079763174, Final Batch Loss: 0.0\n",
      "Epoch 3841, Loss: 0.018547188454249408, Final Batch Loss: 0.00010609064338495955\n",
      "Epoch 3842, Loss: 0.011670114356093109, Final Batch Loss: 0.00010680581908673048\n",
      "Epoch 3843, Loss: 0.015894291806034744, Final Batch Loss: 0.0\n",
      "Epoch 3844, Loss: 0.010966203408308672, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3845, Loss: 0.02124157384969294, Final Batch Loss: 5.709961988031864e-05\n",
      "Epoch 3846, Loss: 0.0337461840827018, Final Batch Loss: 0.0\n",
      "Epoch 3847, Loss: 0.007079037604853511, Final Batch Loss: 0.0\n",
      "Epoch 3848, Loss: 0.007009467954048887, Final Batch Loss: 0.00024077377747744322\n",
      "Epoch 3849, Loss: 0.0121058450313285, Final Batch Loss: 0.0\n",
      "Epoch 3850, Loss: 0.010785122867673635, Final Batch Loss: 0.0\n",
      "Epoch 3851, Loss: 0.009153553401120007, Final Batch Loss: 0.0005159238935448229\n",
      "Epoch 3852, Loss: 0.013717238616663963, Final Batch Loss: 0.0004017737810499966\n",
      "Epoch 3853, Loss: 0.011376017122529447, Final Batch Loss: 0.0\n",
      "Epoch 3854, Loss: 0.009404837968759239, Final Batch Loss: 0.0004122599493712187\n",
      "Epoch 3855, Loss: 0.008812916610622779, Final Batch Loss: 0.0\n",
      "Epoch 3856, Loss: 0.007344253914197907, Final Batch Loss: 0.0\n",
      "Epoch 3857, Loss: 0.011879964033141732, Final Batch Loss: 0.0\n",
      "Epoch 3858, Loss: 0.004061299987370148, Final Batch Loss: 0.0\n",
      "Epoch 3859, Loss: 0.005457697785459459, Final Batch Loss: 0.0\n",
      "Epoch 3860, Loss: 0.010522140190005302, Final Batch Loss: 0.0\n",
      "Epoch 3861, Loss: 0.009253190032723069, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 3862, Loss: 0.013405740717189474, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 3863, Loss: 0.020384941599331796, Final Batch Loss: 0.0\n",
      "Epoch 3864, Loss: 0.01503713522106409, Final Batch Loss: 0.0\n",
      "Epoch 3865, Loss: 0.01005661569070071, Final Batch Loss: 0.0\n",
      "Epoch 3866, Loss: 0.026896941242739558, Final Batch Loss: 0.0\n",
      "Epoch 3867, Loss: 0.007070606487104669, Final Batch Loss: 0.00045372682507149875\n",
      "Epoch 3868, Loss: 0.018209952544566477, Final Batch Loss: 4.994744449504651e-05\n",
      "Epoch 3869, Loss: 0.016232250956811356, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3870, Loss: 0.011540667619556189, Final Batch Loss: 0.0\n",
      "Epoch 3871, Loss: 0.0072558931351522915, Final Batch Loss: 6.913899414939806e-05\n",
      "Epoch 3872, Loss: 0.015118577517569065, Final Batch Loss: 0.0\n",
      "Epoch 3873, Loss: 0.03509691655199276, Final Batch Loss: 3.8742269680369645e-05\n",
      "Epoch 3874, Loss: 0.02583324143779464, Final Batch Loss: 0.021011851727962494\n",
      "Epoch 3875, Loss: 0.007081372401444241, Final Batch Loss: 0.000446696620201692\n",
      "Epoch 3876, Loss: 0.008990493253804743, Final Batch Loss: 0.0\n",
      "Epoch 3877, Loss: 0.019806744181543934, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3878, Loss: 0.014696289552375674, Final Batch Loss: 0.0\n",
      "Epoch 3879, Loss: 0.009742041933350265, Final Batch Loss: 0.0\n",
      "Epoch 3880, Loss: 0.00851697544567287, Final Batch Loss: 0.0\n",
      "Epoch 3881, Loss: 0.024585888777664877, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 3882, Loss: 0.0136618961696513, Final Batch Loss: 0.0\n",
      "Epoch 3883, Loss: 0.04546471871435642, Final Batch Loss: 0.0\n",
      "Epoch 3884, Loss: 0.010940115957055241, Final Batch Loss: 0.0\n",
      "Epoch 3885, Loss: 0.029897465341491625, Final Batch Loss: 0.0001481661747675389\n",
      "Epoch 3886, Loss: 0.015034412237582728, Final Batch Loss: 1.7046782886609435e-05\n",
      "Epoch 3887, Loss: 0.019147188097122125, Final Batch Loss: 0.0\n",
      "Epoch 3888, Loss: 0.005597866955213249, Final Batch Loss: 0.0\n",
      "Epoch 3889, Loss: 0.02294946205802262, Final Batch Loss: 0.0\n",
      "Epoch 3890, Loss: 0.014614642481319606, Final Batch Loss: 0.0\n",
      "Epoch 3891, Loss: 0.013036863216257188, Final Batch Loss: 9.369411418447271e-05\n",
      "Epoch 3892, Loss: 0.014918837929144502, Final Batch Loss: 0.0\n",
      "Epoch 3893, Loss: 0.03796158288605511, Final Batch Loss: 0.00020680672605521977\n",
      "Epoch 3894, Loss: 0.022557064658030868, Final Batch Loss: 0.0\n",
      "Epoch 3895, Loss: 0.027646681002806872, Final Batch Loss: 0.00025376438861712813\n",
      "Epoch 3896, Loss: 0.008535440894775093, Final Batch Loss: 0.0\n",
      "Epoch 3897, Loss: 0.011537749785929918, Final Batch Loss: 0.0\n",
      "Epoch 3898, Loss: 0.03919659904204309, Final Batch Loss: 0.0\n",
      "Epoch 3899, Loss: 0.015844808192923665, Final Batch Loss: 0.0\n",
      "Epoch 3900, Loss: 0.015531859826296568, Final Batch Loss: 0.0\n",
      "Epoch 3901, Loss: 0.010217752424068749, Final Batch Loss: 0.0013624681159853935\n",
      "Epoch 3902, Loss: 0.024336648173630238, Final Batch Loss: 0.0\n",
      "Epoch 3903, Loss: 0.010805441648699343, Final Batch Loss: 0.00015639036428183317\n",
      "Epoch 3904, Loss: 0.00848728057462722, Final Batch Loss: 0.0\n",
      "Epoch 3905, Loss: 0.02414186403620988, Final Batch Loss: 5.173549288883805e-05\n",
      "Epoch 3906, Loss: 0.014399190666154027, Final Batch Loss: 0.0\n",
      "Epoch 3907, Loss: 0.008030431830320595, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3908, Loss: 0.02813176898052916, Final Batch Loss: 0.0\n",
      "Epoch 3909, Loss: 0.004336015495937318, Final Batch Loss: 0.0\n",
      "Epoch 3910, Loss: 0.021649691449056263, Final Batch Loss: 1.537788011773955e-05\n",
      "Epoch 3911, Loss: 0.03698368649520489, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 3912, Loss: 0.008763965335504054, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3913, Loss: 0.013055879855528474, Final Batch Loss: 0.0\n",
      "Epoch 3914, Loss: 0.005421355715952814, Final Batch Loss: 0.0\n",
      "Epoch 3915, Loss: 0.022399559849873185, Final Batch Loss: 0.0\n",
      "Epoch 3916, Loss: 0.006544782081618905, Final Batch Loss: 0.0\n",
      "Epoch 3917, Loss: 0.007561882957816124, Final Batch Loss: 0.0\n",
      "Epoch 3918, Loss: 0.02889110369142145, Final Batch Loss: 0.0034791436046361923\n",
      "Epoch 3919, Loss: 0.015343575454608072, Final Batch Loss: 9.941560711013153e-05\n",
      "Epoch 3920, Loss: 0.012522527715191245, Final Batch Loss: 0.0030797929503023624\n",
      "Epoch 3921, Loss: 0.0059059448539073855, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3922, Loss: 0.0215066633945753, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 3923, Loss: 0.007524846587330103, Final Batch Loss: 0.0\n",
      "Epoch 3924, Loss: 0.00668093713466078, Final Batch Loss: 0.0\n",
      "Epoch 3925, Loss: 0.02569788281101637, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3926, Loss: 0.008214193425374106, Final Batch Loss: 0.00027891082572750747\n",
      "Epoch 3927, Loss: 0.011317406198941171, Final Batch Loss: 0.0\n",
      "Epoch 3928, Loss: 0.012014439154881984, Final Batch Loss: 0.0\n",
      "Epoch 3929, Loss: 0.01033703563734889, Final Batch Loss: 0.0\n",
      "Epoch 3930, Loss: 0.006981082551639872, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3931, Loss: 0.02634408178164449, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 3932, Loss: 0.01448775635799393, Final Batch Loss: 0.0\n",
      "Epoch 3933, Loss: 0.014383466448634863, Final Batch Loss: 0.0\n",
      "Epoch 3934, Loss: 0.022827961714938283, Final Batch Loss: 0.0\n",
      "Epoch 3935, Loss: 0.023415476083755493, Final Batch Loss: 0.0033286185935139656\n",
      "Epoch 3936, Loss: 0.00953837251290679, Final Batch Loss: 0.0\n",
      "Epoch 3937, Loss: 0.01203842553513823, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 3938, Loss: 0.033487553235318046, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 3939, Loss: 0.006306533003225923, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3940, Loss: 0.01144312135875225, Final Batch Loss: 0.0\n",
      "Epoch 3941, Loss: 0.008018647149583558, Final Batch Loss: 1.0490362910786644e-05\n",
      "Epoch 3942, Loss: 0.01426491723395884, Final Batch Loss: 0.0\n",
      "Epoch 3943, Loss: 0.007808148511685431, Final Batch Loss: 0.0020353333093225956\n",
      "Epoch 3944, Loss: 0.011706777498943666, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 3945, Loss: 0.05455654487013817, Final Batch Loss: 0.0\n",
      "Epoch 3946, Loss: 0.012681984109796929, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3947, Loss: 0.00534236547537148, Final Batch Loss: 0.0\n",
      "Epoch 3948, Loss: 0.03299026714876163, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 3949, Loss: 0.01476571208331734, Final Batch Loss: 0.0\n",
      "Epoch 3950, Loss: 0.05450266599586939, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 3951, Loss: 0.009219743486028165, Final Batch Loss: 0.0\n",
      "Epoch 3952, Loss: 0.011664197081699967, Final Batch Loss: 0.0\n",
      "Epoch 3953, Loss: 0.005411210818976997, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3954, Loss: 0.01620867836754769, Final Batch Loss: 0.00034290633630007505\n",
      "Epoch 3955, Loss: 0.0038736633432563394, Final Batch Loss: 0.0\n",
      "Epoch 3956, Loss: 0.044523549266159534, Final Batch Loss: 0.0\n",
      "Epoch 3957, Loss: 0.02243588317650591, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3958, Loss: 0.004839618923142552, Final Batch Loss: 0.0\n",
      "Epoch 3959, Loss: 0.0071332225343212485, Final Batch Loss: 0.0\n",
      "Epoch 3960, Loss: 0.03167217012378387, Final Batch Loss: 0.023140734061598778\n",
      "Epoch 3961, Loss: 0.008844929281394798, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 3962, Loss: 0.010386656736955047, Final Batch Loss: 0.0\n",
      "Epoch 3963, Loss: 0.0061070690280757844, Final Batch Loss: 0.00030191155383363366\n",
      "Epoch 3964, Loss: 0.01548716373491743, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3965, Loss: 0.012167987722932594, Final Batch Loss: 4.136476854910143e-05\n",
      "Epoch 3966, Loss: 0.010150773217901587, Final Batch Loss: 0.0\n",
      "Epoch 3967, Loss: 0.009560831123962998, Final Batch Loss: 0.0\n",
      "Epoch 3968, Loss: 0.004892105935141444, Final Batch Loss: 0.0\n",
      "Epoch 3969, Loss: 0.025014318525791168, Final Batch Loss: 0.0\n",
      "Epoch 3970, Loss: 0.0033009407306963112, Final Batch Loss: 1.883488948806189e-05\n",
      "Epoch 3971, Loss: 0.011884834729016802, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 3972, Loss: 0.01451513228857948, Final Batch Loss: 1.5616295058862306e-05\n",
      "Epoch 3973, Loss: 0.011923544625460636, Final Batch Loss: 4.1960789531003684e-05\n",
      "Epoch 3974, Loss: 0.005555497598834336, Final Batch Loss: 0.0\n",
      "Epoch 3975, Loss: 0.009270357608329505, Final Batch Loss: 0.00012587709352374077\n",
      "Epoch 3976, Loss: 0.01555442262903739, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3977, Loss: 0.012618419946534232, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3978, Loss: 0.009702005074359477, Final Batch Loss: 0.0\n",
      "Epoch 3979, Loss: 0.005826447129948065, Final Batch Loss: 0.0\n",
      "Epoch 3980, Loss: 0.009486706927361865, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3981, Loss: 0.007286666834261268, Final Batch Loss: 0.00022110878489911556\n",
      "Epoch 3982, Loss: 0.005340828480711934, Final Batch Loss: 6.556489552167477e-06\n",
      "Epoch 3983, Loss: 0.004431101435329765, Final Batch Loss: 0.0\n",
      "Epoch 3984, Loss: 0.011615919996984303, Final Batch Loss: 0.0\n",
      "Epoch 3985, Loss: 0.005630048748571426, Final Batch Loss: 0.0\n",
      "Epoch 3986, Loss: 0.004397747979965061, Final Batch Loss: 0.0\n",
      "Epoch 3987, Loss: 0.009945880941813812, Final Batch Loss: 0.0\n",
      "Epoch 3988, Loss: 0.024075094231761796, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 3989, Loss: 0.02490030595782855, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3990, Loss: 0.008198828203603625, Final Batch Loss: 0.0\n",
      "Epoch 3991, Loss: 0.011556349531019805, Final Batch Loss: 5.793403761344962e-05\n",
      "Epoch 3992, Loss: 0.008638480445370078, Final Batch Loss: 0.0\n",
      "Epoch 3993, Loss: 0.0051003327826038, Final Batch Loss: 0.0\n",
      "Epoch 3994, Loss: 0.026060900883720706, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 3995, Loss: 0.024215882876887918, Final Batch Loss: 0.013567850925028324\n",
      "Epoch 3996, Loss: 0.008345870999619365, Final Batch Loss: 0.0\n",
      "Epoch 3997, Loss: 0.00671224961115513, Final Batch Loss: 0.0\n",
      "Epoch 3998, Loss: 0.0026274162219124264, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 3999, Loss: 0.02472835930529982, Final Batch Loss: 0.0\n",
      "Epoch 4000, Loss: 0.035314207314513624, Final Batch Loss: 0.0\n",
      "Epoch 4001, Loss: 0.010378810809925199, Final Batch Loss: 0.0\n",
      "Epoch 4002, Loss: 0.003895850393746514, Final Batch Loss: 7.915183232398704e-05\n",
      "Epoch 4003, Loss: 0.0047019016346894205, Final Batch Loss: 0.0\n",
      "Epoch 4004, Loss: 0.009828252485021949, Final Batch Loss: 0.0\n",
      "Epoch 4005, Loss: 0.0044411343405883486, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4006, Loss: 0.010261427944442403, Final Batch Loss: 5.602820692729438e-06\n",
      "Epoch 4007, Loss: 0.008989319903768944, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4008, Loss: 0.009676571644376963, Final Batch Loss: 0.0\n",
      "Epoch 4009, Loss: 0.009987781168092624, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 4010, Loss: 0.018467605346813798, Final Batch Loss: 0.0\n",
      "Epoch 4011, Loss: 0.015083183418028057, Final Batch Loss: 0.0\n",
      "Epoch 4012, Loss: 0.015287232352413582, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4013, Loss: 0.0031826490303501487, Final Batch Loss: 0.0\n",
      "Epoch 4014, Loss: 0.01223108501653769, Final Batch Loss: 3.802703940891661e-05\n",
      "Epoch 4015, Loss: 0.012013574480079114, Final Batch Loss: 0.0005006728461012244\n",
      "Epoch 4016, Loss: 0.004153600777499378, Final Batch Loss: 0.0\n",
      "Epoch 4017, Loss: 0.005256233911495656, Final Batch Loss: 0.0\n",
      "Epoch 4018, Loss: 0.005195160742459848, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4019, Loss: 0.014050538287847303, Final Batch Loss: 0.00011932138295378536\n",
      "Epoch 4020, Loss: 0.009974818443879485, Final Batch Loss: 0.0\n",
      "Epoch 4021, Loss: 0.02720118116121739, Final Batch Loss: 0.0\n",
      "Epoch 4022, Loss: 0.01484320143936202, Final Batch Loss: 0.0\n",
      "Epoch 4023, Loss: 0.01060172452707775, Final Batch Loss: 0.00014375607133843005\n",
      "Epoch 4024, Loss: 0.006056814076146111, Final Batch Loss: 0.0\n",
      "Epoch 4025, Loss: 0.032893545459948825, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4026, Loss: 0.010874197876546532, Final Batch Loss: 0.0\n",
      "Epoch 4027, Loss: 0.006455160895711742, Final Batch Loss: 0.00010334911348763853\n",
      "Epoch 4028, Loss: 0.005441677960334346, Final Batch Loss: 0.0\n",
      "Epoch 4029, Loss: 0.024391274491790682, Final Batch Loss: 0.0003748429589904845\n",
      "Epoch 4030, Loss: 0.004122648858810862, Final Batch Loss: 6.9141146923357155e-06\n",
      "Epoch 4031, Loss: 0.02859758900012821, Final Batch Loss: 0.0\n",
      "Epoch 4032, Loss: 0.03478139592300522, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4033, Loss: 0.00865413285100658, Final Batch Loss: 9.179073458653875e-06\n",
      "Epoch 4034, Loss: 0.0126036434571688, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 4035, Loss: 0.00641611369792372, Final Batch Loss: 0.0\n",
      "Epoch 4036, Loss: 0.0029311146863619797, Final Batch Loss: 0.0\n",
      "Epoch 4037, Loss: 0.014562862681486877, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 4038, Loss: 0.013893304800149053, Final Batch Loss: 0.0\n",
      "Epoch 4039, Loss: 0.005427099531516433, Final Batch Loss: 0.0006070678355172276\n",
      "Epoch 4040, Loss: 0.005845264531672001, Final Batch Loss: 0.0\n",
      "Epoch 4041, Loss: 0.012124304892495275, Final Batch Loss: 0.0005374894244596362\n",
      "Epoch 4042, Loss: 0.005434108668850968, Final Batch Loss: 4.6967357775429264e-05\n",
      "Epoch 4043, Loss: 0.007883322541601956, Final Batch Loss: 0.0\n",
      "Epoch 4044, Loss: 0.024276862619444728, Final Batch Loss: 0.007835840806365013\n",
      "Epoch 4045, Loss: 0.008148832595907152, Final Batch Loss: 0.0\n",
      "Epoch 4046, Loss: 0.005823024781420827, Final Batch Loss: 0.0\n",
      "Epoch 4047, Loss: 0.027111219133985287, Final Batch Loss: 1.0013530300057027e-05\n",
      "Epoch 4048, Loss: 0.011164449446368963, Final Batch Loss: 0.006157593801617622\n",
      "Epoch 4049, Loss: 0.012798483716323972, Final Batch Loss: 0.0\n",
      "Epoch 4050, Loss: 0.0312958178064946, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 4051, Loss: 0.024633457127492875, Final Batch Loss: 0.0\n",
      "Epoch 4052, Loss: 0.02781105734175071, Final Batch Loss: 0.02056257054209709\n",
      "Epoch 4053, Loss: 0.003518367186188698, Final Batch Loss: 0.0\n",
      "Epoch 4054, Loss: 0.027099853032268584, Final Batch Loss: 0.0\n",
      "Epoch 4055, Loss: 0.023404182167723775, Final Batch Loss: 0.0\n",
      "Epoch 4056, Loss: 0.01951126183848828, Final Batch Loss: 0.0\n",
      "Epoch 4057, Loss: 0.006784231110941619, Final Batch Loss: 0.0\n",
      "Epoch 4058, Loss: 0.00452831294387579, Final Batch Loss: 0.0\n",
      "Epoch 4059, Loss: 0.003949083504267037, Final Batch Loss: 0.0\n",
      "Epoch 4060, Loss: 0.019712012552190572, Final Batch Loss: 0.0\n",
      "Epoch 4061, Loss: 0.0029077475192025304, Final Batch Loss: 0.0\n",
      "Epoch 4062, Loss: 0.009889726289429746, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4063, Loss: 0.011690235580317676, Final Batch Loss: 0.0017629809444770217\n",
      "Epoch 4064, Loss: 0.004644620406907052, Final Batch Loss: 0.0\n",
      "Epoch 4065, Loss: 0.004355010518338531, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4066, Loss: 0.015057529788464308, Final Batch Loss: 0.0\n",
      "Epoch 4067, Loss: 0.020656809443607926, Final Batch Loss: 0.0\n",
      "Epoch 4068, Loss: 0.012025308795273304, Final Batch Loss: 0.0\n",
      "Epoch 4069, Loss: 0.004874833393841982, Final Batch Loss: 0.0014348459662869573\n",
      "Epoch 4070, Loss: 0.009127066121379812, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4071, Loss: 0.02513525052926724, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4072, Loss: 0.004994803457520902, Final Batch Loss: 0.0\n",
      "Epoch 4073, Loss: 0.0068110276479274035, Final Batch Loss: 0.0\n",
      "Epoch 4074, Loss: 0.017232923884876072, Final Batch Loss: 0.0\n",
      "Epoch 4075, Loss: 0.014552795580129896, Final Batch Loss: 1.3947389561508317e-05\n",
      "Epoch 4076, Loss: 0.015688198494899552, Final Batch Loss: 7.86750388215296e-05\n",
      "Epoch 4077, Loss: 0.008155778690706939, Final Batch Loss: 0.0\n",
      "Epoch 4078, Loss: 0.013421984040178359, Final Batch Loss: 0.0\n",
      "Epoch 4079, Loss: 0.018882147531257942, Final Batch Loss: 0.0\n",
      "Epoch 4080, Loss: 0.007405459997187336, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4081, Loss: 0.008176836825441569, Final Batch Loss: 0.0\n",
      "Epoch 4082, Loss: 0.006305594695724892, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4083, Loss: 0.011802105189417489, Final Batch Loss: 0.00019143179815728217\n",
      "Epoch 4084, Loss: 0.003280249133233326, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4085, Loss: 0.0053721797885373235, Final Batch Loss: 0.0\n",
      "Epoch 4086, Loss: 0.0050807257648557425, Final Batch Loss: 0.0\n",
      "Epoch 4087, Loss: 0.014616769971325994, Final Batch Loss: 0.0\n",
      "Epoch 4088, Loss: 0.006887775045470335, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 4089, Loss: 0.0055588994873687625, Final Batch Loss: 0.0\n",
      "Epoch 4090, Loss: 0.00390760216396302, Final Batch Loss: 0.00010322991875000298\n",
      "Epoch 4091, Loss: 0.028415371023584157, Final Batch Loss: 0.0\n",
      "Epoch 4092, Loss: 0.008365661837132166, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4093, Loss: 0.010105391032993793, Final Batch Loss: 0.0\n",
      "Epoch 4094, Loss: 0.009529353119432926, Final Batch Loss: 0.0\n",
      "Epoch 4095, Loss: 0.006408593850210309, Final Batch Loss: 0.0\n",
      "Epoch 4096, Loss: 0.018609730032039806, Final Batch Loss: 0.00013362467871047556\n",
      "Epoch 4097, Loss: 0.00863538212433923, Final Batch Loss: 0.0001646144810365513\n",
      "Epoch 4098, Loss: 0.004777204769197851, Final Batch Loss: 0.0\n",
      "Epoch 4099, Loss: 0.007314463262446225, Final Batch Loss: 0.004149517975747585\n",
      "Epoch 4100, Loss: 0.018663727836610633, Final Batch Loss: 2.47952248173533e-05\n",
      "Epoch 4101, Loss: 0.007322537479922175, Final Batch Loss: 0.0010080024367198348\n",
      "Epoch 4102, Loss: 0.010451110894791782, Final Batch Loss: 0.0\n",
      "Epoch 4103, Loss: 0.008458968251943588, Final Batch Loss: 0.0\n",
      "Epoch 4104, Loss: 0.011421300586789584, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4105, Loss: 0.004580365875881398, Final Batch Loss: 4.172238186583854e-05\n",
      "Epoch 4106, Loss: 0.02182007006194908, Final Batch Loss: 0.0\n",
      "Epoch 4107, Loss: 0.005490170500706881, Final Batch Loss: 0.0\n",
      "Epoch 4108, Loss: 0.00483037330195657, Final Batch Loss: 1.3470558769768104e-05\n",
      "Epoch 4109, Loss: 0.014544265945005463, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 4110, Loss: 0.00324103538844156, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4111, Loss: 0.03582103468943387, Final Batch Loss: 0.0\n",
      "Epoch 4112, Loss: 0.012499052958446555, Final Batch Loss: 1.9430925021879375e-05\n",
      "Epoch 4113, Loss: 0.005062858817836968, Final Batch Loss: 4.8040190449682996e-05\n",
      "Epoch 4114, Loss: 0.009228385926689953, Final Batch Loss: 0.0\n",
      "Epoch 4115, Loss: 0.008766145561764915, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4116, Loss: 0.004293641191907227, Final Batch Loss: 0.0\n",
      "Epoch 4117, Loss: 0.018754126969717788, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4118, Loss: 0.003502058010781184, Final Batch Loss: 0.0\n",
      "Epoch 4119, Loss: 0.006074310745134426, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4120, Loss: 0.005063709802925587, Final Batch Loss: 0.0\n",
      "Epoch 4121, Loss: 0.026031025394331664, Final Batch Loss: 0.0\n",
      "Epoch 4122, Loss: 0.024879847071133554, Final Batch Loss: 0.0\n",
      "Epoch 4123, Loss: 0.006046633352468689, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4124, Loss: 0.025158361764454185, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4125, Loss: 0.00540872139390558, Final Batch Loss: 0.0\n",
      "Epoch 4126, Loss: 0.01401358557632193, Final Batch Loss: 0.0\n",
      "Epoch 4127, Loss: 0.0062051765853468055, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4128, Loss: 0.003268373286118731, Final Batch Loss: 0.0\n",
      "Epoch 4129, Loss: 0.022810400230810046, Final Batch Loss: 0.0\n",
      "Epoch 4130, Loss: 0.0045061939490551595, Final Batch Loss: 5.221230458118953e-05\n",
      "Epoch 4131, Loss: 0.004908510542009026, Final Batch Loss: 0.0\n",
      "Epoch 4132, Loss: 0.014708000164318946, Final Batch Loss: 2.2172682292875834e-05\n",
      "Epoch 4133, Loss: 0.004381027305498719, Final Batch Loss: 0.00021526881027966738\n",
      "Epoch 4134, Loss: 0.008519086131855147, Final Batch Loss: 2.074220174108632e-05\n",
      "Epoch 4135, Loss: 0.006306137074716389, Final Batch Loss: 0.0\n",
      "Epoch 4136, Loss: 0.03203939460127003, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4137, Loss: 0.005798840196803212, Final Batch Loss: 0.0\n",
      "Epoch 4138, Loss: 0.009128284873440862, Final Batch Loss: 0.0\n",
      "Epoch 4139, Loss: 0.008290976460557431, Final Batch Loss: 0.0\n",
      "Epoch 4140, Loss: 0.012787493411451578, Final Batch Loss: 0.0\n",
      "Epoch 4141, Loss: 0.0038164849975146353, Final Batch Loss: 0.0\n",
      "Epoch 4142, Loss: 0.02824749716091901, Final Batch Loss: 0.0\n",
      "Epoch 4143, Loss: 0.011836320511065423, Final Batch Loss: 0.0\n",
      "Epoch 4144, Loss: 0.0015913379611447453, Final Batch Loss: 0.0\n",
      "Epoch 4145, Loss: 0.0048679247265681624, Final Batch Loss: 0.0\n",
      "Epoch 4146, Loss: 0.003277815310866572, Final Batch Loss: 0.00018320789968129247\n",
      "Epoch 4147, Loss: 0.019326329813338816, Final Batch Loss: 0.0055410838685929775\n",
      "Epoch 4148, Loss: 0.017116347327828407, Final Batch Loss: 0.0\n",
      "Epoch 4149, Loss: 0.0021469903585895622, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4150, Loss: 0.003920603659935296, Final Batch Loss: 0.0\n",
      "Epoch 4151, Loss: 0.004588212730595842, Final Batch Loss: 0.0\n",
      "Epoch 4152, Loss: 0.004250233079801546, Final Batch Loss: 1.764281842042692e-05\n",
      "Epoch 4153, Loss: 0.003987589734606445, Final Batch Loss: 0.0\n",
      "Epoch 4154, Loss: 0.012909574317745864, Final Batch Loss: 0.0\n",
      "Epoch 4155, Loss: 0.0041397715685889125, Final Batch Loss: 0.0\n",
      "Epoch 4156, Loss: 0.0031853919062996283, Final Batch Loss: 0.0\n",
      "Epoch 4157, Loss: 0.0025623671826906502, Final Batch Loss: 0.0\n",
      "Epoch 4158, Loss: 0.011775303981266916, Final Batch Loss: 0.0\n",
      "Epoch 4159, Loss: 0.02486987819429487, Final Batch Loss: 0.0\n",
      "Epoch 4160, Loss: 0.0022649601596640423, Final Batch Loss: 0.0\n",
      "Epoch 4161, Loss: 0.0035214981762692332, Final Batch Loss: 0.0\n",
      "Epoch 4162, Loss: 0.016834532842040062, Final Batch Loss: 0.0\n",
      "Epoch 4163, Loss: 0.01390556653495878, Final Batch Loss: 0.0\n",
      "Epoch 4164, Loss: 0.006648717797354209, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4165, Loss: 0.002445739286031312, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4166, Loss: 0.0200069120619375, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4167, Loss: 0.006454937974922359, Final Batch Loss: 0.0\n",
      "Epoch 4168, Loss: 0.004265583644155413, Final Batch Loss: 0.0008630603551864624\n",
      "Epoch 4169, Loss: 0.024583027057815343, Final Batch Loss: 0.0\n",
      "Epoch 4170, Loss: 0.004908009199425578, Final Batch Loss: 0.0\n",
      "Epoch 4171, Loss: 0.0019067510147579014, Final Batch Loss: 0.0\n",
      "Epoch 4172, Loss: 0.019565319385947078, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 4173, Loss: 0.004581051296554506, Final Batch Loss: 0.0\n",
      "Epoch 4174, Loss: 0.011031221132725477, Final Batch Loss: 0.0\n",
      "Epoch 4175, Loss: 0.002920667888247408, Final Batch Loss: 0.0\n",
      "Epoch 4176, Loss: 0.01744086088729091, Final Batch Loss: 6.174850568640977e-05\n",
      "Epoch 4177, Loss: 0.009406385303009301, Final Batch Loss: 0.0\n",
      "Epoch 4178, Loss: 0.0024448392208569203, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4179, Loss: 0.004261815105564892, Final Batch Loss: 0.0\n",
      "Epoch 4180, Loss: 0.004056068486534059, Final Batch Loss: 0.0\n",
      "Epoch 4181, Loss: 0.023792633437551558, Final Batch Loss: 0.0\n",
      "Epoch 4182, Loss: 0.0035888866914319806, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 4183, Loss: 0.0030360386299363995, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4184, Loss: 0.0046429774520220235, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4185, Loss: 0.0073980705928988755, Final Batch Loss: 0.0\n",
      "Epoch 4186, Loss: 0.0035778795718215406, Final Batch Loss: 0.0\n",
      "Epoch 4187, Loss: 0.008394149277592078, Final Batch Loss: 0.000922849983908236\n",
      "Epoch 4188, Loss: 0.00325338589027524, Final Batch Loss: 0.0\n",
      "Epoch 4189, Loss: 0.0040586949326097965, Final Batch Loss: 0.0\n",
      "Epoch 4190, Loss: 0.023898644212749787, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 4191, Loss: 0.0020058944646734744, Final Batch Loss: 0.0\n",
      "Epoch 4192, Loss: 0.031353928527096286, Final Batch Loss: 0.0\n",
      "Epoch 4193, Loss: 0.03290102928622218, Final Batch Loss: 9.894321920000948e-06\n",
      "Epoch 4194, Loss: 0.0034971930144820362, Final Batch Loss: 0.0\n",
      "Epoch 4195, Loss: 0.025582884962204844, Final Batch Loss: 0.0\n",
      "Epoch 4196, Loss: 0.006724115693941712, Final Batch Loss: 0.0\n",
      "Epoch 4197, Loss: 0.0022779725986765698, Final Batch Loss: 4.076874756719917e-05\n",
      "Epoch 4198, Loss: 0.0034537126193754375, Final Batch Loss: 0.0\n",
      "Epoch 4199, Loss: 0.018365593525231816, Final Batch Loss: 0.0\n",
      "Epoch 4200, Loss: 0.003451529220910743, Final Batch Loss: 0.0\n",
      "Epoch 4201, Loss: 0.0027741693193092942, Final Batch Loss: 0.0\n",
      "Epoch 4202, Loss: 0.005083381314534563, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4203, Loss: 0.01002534746658057, Final Batch Loss: 0.0\n",
      "Epoch 4204, Loss: 0.005343184948287671, Final Batch Loss: 8.106198947643861e-06\n",
      "Epoch 4205, Loss: 0.02733070048270747, Final Batch Loss: 0.0\n",
      "Epoch 4206, Loss: 0.008145960833473964, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4207, Loss: 0.020174580975435674, Final Batch Loss: 0.0\n",
      "Epoch 4208, Loss: 0.013976430229377002, Final Batch Loss: 0.0\n",
      "Epoch 4209, Loss: 0.003057689784327522, Final Batch Loss: 0.0\n",
      "Epoch 4210, Loss: 0.0016889279067413554, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4211, Loss: 0.010243229160437295, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4212, Loss: 0.016531008179299533, Final Batch Loss: 0.0\n",
      "Epoch 4213, Loss: 0.016109608463011682, Final Batch Loss: 0.0\n",
      "Epoch 4214, Loss: 0.00867217790801078, Final Batch Loss: 0.0\n",
      "Epoch 4215, Loss: 0.04188566352240741, Final Batch Loss: 0.0002783149539027363\n",
      "Epoch 4216, Loss: 0.006584365386515856, Final Batch Loss: 0.001178285456262529\n",
      "Epoch 4217, Loss: 0.0030738977948203683, Final Batch Loss: 0.0\n",
      "Epoch 4218, Loss: 0.0018746178539004177, Final Batch Loss: 0.0\n",
      "Epoch 4219, Loss: 0.013734263950027525, Final Batch Loss: 0.0\n",
      "Epoch 4220, Loss: 0.007874339469708502, Final Batch Loss: 0.0\n",
      "Epoch 4221, Loss: 0.03660832121386193, Final Batch Loss: 0.0\n",
      "Epoch 4222, Loss: 0.011721700022462755, Final Batch Loss: 0.0\n",
      "Epoch 4223, Loss: 0.005207203881582245, Final Batch Loss: 0.0\n",
      "Epoch 4224, Loss: 0.011204531183466315, Final Batch Loss: 0.0\n",
      "Epoch 4225, Loss: 0.0033502787409815937, Final Batch Loss: 0.0\n",
      "Epoch 4226, Loss: 0.008316309249494225, Final Batch Loss: 0.0\n",
      "Epoch 4227, Loss: 0.0025674753705970943, Final Batch Loss: 0.0\n",
      "Epoch 4228, Loss: 0.013304038206115365, Final Batch Loss: 0.0\n",
      "Epoch 4229, Loss: 0.025866791082080454, Final Batch Loss: 0.0\n",
      "Epoch 4230, Loss: 0.010736012482084334, Final Batch Loss: 0.0\n",
      "Epoch 4231, Loss: 0.04933569999411702, Final Batch Loss: 0.024251358583569527\n",
      "Epoch 4232, Loss: 0.004271067271474749, Final Batch Loss: 0.0\n",
      "Epoch 4233, Loss: 0.021186680649407208, Final Batch Loss: 0.0\n",
      "Epoch 4234, Loss: 0.009100497118197381, Final Batch Loss: 0.0\n",
      "Epoch 4235, Loss: 0.005023453559260815, Final Batch Loss: 0.0\n",
      "Epoch 4236, Loss: 0.013901528902351856, Final Batch Loss: 0.0\n",
      "Epoch 4237, Loss: 0.00662935507716611, Final Batch Loss: 0.0\n",
      "Epoch 4238, Loss: 0.00755336999282008, Final Batch Loss: 6.913899414939806e-05\n",
      "Epoch 4239, Loss: 0.0034520150802563876, Final Batch Loss: 0.0\n",
      "Epoch 4240, Loss: 0.01511424477212131, Final Batch Loss: 0.0\n",
      "Epoch 4241, Loss: 0.01228535411064513, Final Batch Loss: 0.0\n",
      "Epoch 4242, Loss: 0.0033902412815223215, Final Batch Loss: 1.4424220353248529e-05\n",
      "Epoch 4243, Loss: 0.019889052071448532, Final Batch Loss: 2.407998726994265e-05\n",
      "Epoch 4244, Loss: 0.011028450448065996, Final Batch Loss: 0.0\n",
      "Epoch 4245, Loss: 0.002477382542565465, Final Batch Loss: 0.00020525732543319464\n",
      "Epoch 4246, Loss: 0.02086809627871844, Final Batch Loss: 3.290122185717337e-05\n",
      "Epoch 4247, Loss: 0.007459550630301237, Final Batch Loss: 0.0\n",
      "Epoch 4248, Loss: 0.03537620486167725, Final Batch Loss: 1.2040065485052764e-05\n",
      "Epoch 4249, Loss: 0.012162256287410855, Final Batch Loss: 0.0\n",
      "Epoch 4250, Loss: 0.007301320787512111, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4251, Loss: 0.0043048404331784695, Final Batch Loss: 0.0\n",
      "Epoch 4252, Loss: 0.002329232753254473, Final Batch Loss: 0.0\n",
      "Epoch 4253, Loss: 0.007642125245183706, Final Batch Loss: 0.0\n",
      "Epoch 4254, Loss: 0.002666143893293338, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 4255, Loss: 0.004502467575548508, Final Batch Loss: 5.8412379075889476e-06\n",
      "Epoch 4256, Loss: 0.008514626417309046, Final Batch Loss: 0.0\n",
      "Epoch 4257, Loss: 0.012828022358007729, Final Batch Loss: 0.0\n",
      "Epoch 4258, Loss: 0.015486732809222303, Final Batch Loss: 0.0001472126314183697\n",
      "Epoch 4259, Loss: 0.025271595281083137, Final Batch Loss: 0.0\n",
      "Epoch 4260, Loss: 0.004719035991001874, Final Batch Loss: 0.0\n",
      "Epoch 4261, Loss: 0.011526417270033562, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 4262, Loss: 0.009238282451406121, Final Batch Loss: 0.0015024575404822826\n",
      "Epoch 4263, Loss: 0.007076152614899911, Final Batch Loss: 0.0\n",
      "Epoch 4264, Loss: 0.017434411282010842, Final Batch Loss: 0.0\n",
      "Epoch 4265, Loss: 0.00168614217542995, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4266, Loss: 0.003599056290113367, Final Batch Loss: 0.0\n",
      "Epoch 4267, Loss: 0.011010804897523485, Final Batch Loss: 0.0\n",
      "Epoch 4268, Loss: 0.20118944101704983, Final Batch Loss: 0.17850179970264435\n",
      "Epoch 4269, Loss: 0.017454928063671105, Final Batch Loss: 0.0\n",
      "Epoch 4270, Loss: 0.006498835049562501, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4271, Loss: 0.06877064472064376, Final Batch Loss: 0.01282232441008091\n",
      "Epoch 4272, Loss: 0.014440406986921062, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4273, Loss: 0.012723600884783082, Final Batch Loss: 0.0007641970878466964\n",
      "Epoch 4274, Loss: 0.035530092820408754, Final Batch Loss: 0.03109019249677658\n",
      "Epoch 4275, Loss: 0.010076327016577125, Final Batch Loss: 0.0\n",
      "Epoch 4276, Loss: 0.009878389071673155, Final Batch Loss: 0.0\n",
      "Epoch 4277, Loss: 0.005510632414370775, Final Batch Loss: 0.0\n",
      "Epoch 4278, Loss: 0.019123442834825255, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 4279, Loss: 0.031292839033994824, Final Batch Loss: 0.00011669908417388797\n",
      "Epoch 4280, Loss: 0.009348767809569836, Final Batch Loss: 0.0\n",
      "Epoch 4281, Loss: 0.01352145679993555, Final Batch Loss: 0.00023040501400828362\n",
      "Epoch 4282, Loss: 0.005593706388026476, Final Batch Loss: 0.0\n",
      "Epoch 4283, Loss: 0.0045100259194441605, Final Batch Loss: 2.3364747903542593e-05\n",
      "Epoch 4284, Loss: 0.014667549752630293, Final Batch Loss: 0.0\n",
      "Epoch 4285, Loss: 0.004147459084379079, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 4286, Loss: 0.011069430271163583, Final Batch Loss: 0.0\n",
      "Epoch 4287, Loss: 0.0037322015850804746, Final Batch Loss: 0.0\n",
      "Epoch 4288, Loss: 0.021091050467020978, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4289, Loss: 0.024469868512824178, Final Batch Loss: 0.0\n",
      "Epoch 4290, Loss: 0.0018259071730426513, Final Batch Loss: 0.0\n",
      "Epoch 4291, Loss: 0.01096060621785, Final Batch Loss: 0.0\n",
      "Epoch 4292, Loss: 0.02378412924008444, Final Batch Loss: 0.0\n",
      "Epoch 4293, Loss: 0.0010656759914127178, Final Batch Loss: 5.352353764465079e-05\n",
      "Epoch 4294, Loss: 0.009369215884362347, Final Batch Loss: 0.0002244459028588608\n",
      "Epoch 4295, Loss: 0.0037185325636528432, Final Batch Loss: 0.0\n",
      "Epoch 4296, Loss: 0.025423593193409033, Final Batch Loss: 0.0\n",
      "Epoch 4297, Loss: 0.007839651108895396, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4298, Loss: 0.060426713433116674, Final Batch Loss: 0.0\n",
      "Epoch 4299, Loss: 0.004457352799363434, Final Batch Loss: 0.0\n",
      "Epoch 4300, Loss: 0.004168198385741562, Final Batch Loss: 0.0008512687054462731\n",
      "Epoch 4301, Loss: 0.00642647553650022, Final Batch Loss: 1.6093124941107817e-05\n",
      "Epoch 4302, Loss: 0.027416782337240875, Final Batch Loss: 0.0\n",
      "Epoch 4303, Loss: 0.0025299743720097467, Final Batch Loss: 0.00026043839170597494\n",
      "Epoch 4304, Loss: 0.04846107680350542, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4305, Loss: 0.0031516118901890877, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4306, Loss: 0.014853395114187151, Final Batch Loss: 0.0\n",
      "Epoch 4307, Loss: 0.008541515344404615, Final Batch Loss: 0.005877355579286814\n",
      "Epoch 4308, Loss: 0.0019061533530475572, Final Batch Loss: 0.0\n",
      "Epoch 4309, Loss: 0.005673585634212941, Final Batch Loss: 0.0\n",
      "Epoch 4310, Loss: 0.004050522577017546, Final Batch Loss: 0.0\n",
      "Epoch 4311, Loss: 0.008612023899218002, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4312, Loss: 0.0031904697534628212, Final Batch Loss: 0.0\n",
      "Epoch 4313, Loss: 0.018093121237711784, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4314, Loss: 0.003285363665781915, Final Batch Loss: 0.0\n",
      "Epoch 4315, Loss: 0.021710397122660652, Final Batch Loss: 0.0\n",
      "Epoch 4316, Loss: 0.011107439800980501, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 4317, Loss: 0.0032419425842817873, Final Batch Loss: 0.0\n",
      "Epoch 4318, Loss: 0.00818458385674603, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4319, Loss: 0.0023372107528984998, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4320, Loss: 0.019354444403234083, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4321, Loss: 0.0046916471619624645, Final Batch Loss: 0.0\n",
      "Epoch 4322, Loss: 0.01767364307306707, Final Batch Loss: 0.0\n",
      "Epoch 4323, Loss: 0.0017643899482138181, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4324, Loss: 0.0034327782632317394, Final Batch Loss: 0.0\n",
      "Epoch 4325, Loss: 0.02152087504504152, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4326, Loss: 0.012439846963388845, Final Batch Loss: 0.0\n",
      "Epoch 4327, Loss: 0.00288981175981462, Final Batch Loss: 0.0\n",
      "Epoch 4328, Loss: 0.011361559387296438, Final Batch Loss: 0.0\n",
      "Epoch 4329, Loss: 0.0033574986139228713, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4330, Loss: 0.001498290861491114, Final Batch Loss: 0.0\n",
      "Epoch 4331, Loss: 0.004721130579120825, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4332, Loss: 0.017283598152971535, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 4333, Loss: 0.014065375900827348, Final Batch Loss: 0.0\n",
      "Epoch 4334, Loss: 0.01050547615159303, Final Batch Loss: 0.0\n",
      "Epoch 4335, Loss: 0.00816803582705461, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4336, Loss: 0.017346302047371864, Final Batch Loss: 0.0\n",
      "Epoch 4337, Loss: 0.008094532793620601, Final Batch Loss: 0.0\n",
      "Epoch 4338, Loss: 0.012180540967165143, Final Batch Loss: 1.3589766240329482e-05\n",
      "Epoch 4339, Loss: 0.03862686452339403, Final Batch Loss: 0.0\n",
      "Epoch 4340, Loss: 0.00346648006234318, Final Batch Loss: 0.0\n",
      "Epoch 4341, Loss: 0.0024256682954728603, Final Batch Loss: 0.0\n",
      "Epoch 4342, Loss: 0.026182400179095566, Final Batch Loss: 0.0\n",
      "Epoch 4343, Loss: 0.03879544720962258, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4344, Loss: 0.011525865376825095, Final Batch Loss: 1.3589766240329482e-05\n",
      "Epoch 4345, Loss: 0.0022571054869047202, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4346, Loss: 0.011058093718020245, Final Batch Loss: 0.0\n",
      "Epoch 4347, Loss: 0.010093193734064698, Final Batch Loss: 0.0\n",
      "Epoch 4348, Loss: 0.08761012024478987, Final Batch Loss: 0.0\n",
      "Epoch 4349, Loss: 0.004003831825684756, Final Batch Loss: 0.0\n",
      "Epoch 4350, Loss: 0.025684889871627092, Final Batch Loss: 0.0\n",
      "Epoch 4351, Loss: 0.004661001556087285, Final Batch Loss: 0.0\n",
      "Epoch 4352, Loss: 0.0038103264523670077, Final Batch Loss: 0.0\n",
      "Epoch 4353, Loss: 0.027692513511283323, Final Batch Loss: 0.00015424491721205413\n",
      "Epoch 4354, Loss: 0.014052754268050194, Final Batch Loss: 0.0\n",
      "Epoch 4355, Loss: 0.003197078753146343, Final Batch Loss: 4.482168878894299e-05\n",
      "Epoch 4356, Loss: 0.0056293612433364615, Final Batch Loss: 0.00017105070583056659\n",
      "Epoch 4357, Loss: 0.0024419802939519286, Final Batch Loss: 0.0\n",
      "Epoch 4358, Loss: 0.012242339056513174, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4359, Loss: 0.0247203284347961, Final Batch Loss: 5.960446742392378e-06\n",
      "Epoch 4360, Loss: 0.005587239807880451, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4361, Loss: 0.012879721251010778, Final Batch Loss: 9.536697689327411e-06\n",
      "Epoch 4362, Loss: 0.011387493053916842, Final Batch Loss: 0.00043704494601115584\n",
      "Epoch 4363, Loss: 0.01343092753083397, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4364, Loss: 0.020250629517249763, Final Batch Loss: 0.0\n",
      "Epoch 4365, Loss: 0.009092724085348891, Final Batch Loss: 4.0649541915627196e-05\n",
      "Epoch 4366, Loss: 0.029850141261704266, Final Batch Loss: 0.0\n",
      "Epoch 4367, Loss: 0.021182076598051935, Final Batch Loss: 0.0\n",
      "Epoch 4368, Loss: 0.0053720281284768134, Final Batch Loss: 0.0\n",
      "Epoch 4369, Loss: 0.0046370403142645955, Final Batch Loss: 0.0\n",
      "Epoch 4370, Loss: 0.0017092712660087273, Final Batch Loss: 0.0\n",
      "Epoch 4371, Loss: 0.007918831826827955, Final Batch Loss: 1.9073304429184645e-05\n",
      "Epoch 4372, Loss: 0.010318747430574149, Final Batch Loss: 0.0011126763420179486\n",
      "Epoch 4373, Loss: 0.04277364275185391, Final Batch Loss: 0.0\n",
      "Epoch 4374, Loss: 0.02820957778018851, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4375, Loss: 0.005008467560401186, Final Batch Loss: 0.0030149028170853853\n",
      "Epoch 4376, Loss: 0.005542426602914929, Final Batch Loss: 0.0\n",
      "Epoch 4377, Loss: 0.006297793937847018, Final Batch Loss: 0.0\n",
      "Epoch 4378, Loss: 0.0020539338001981378, Final Batch Loss: 0.0\n",
      "Epoch 4379, Loss: 0.016270556196104735, Final Batch Loss: 0.0\n",
      "Epoch 4380, Loss: 0.007376360590001241, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4381, Loss: 0.004351758892880753, Final Batch Loss: 0.0\n",
      "Epoch 4382, Loss: 0.010521611286094412, Final Batch Loss: 0.0\n",
      "Epoch 4383, Loss: 0.004791815459611826, Final Batch Loss: 5.7338023907504976e-05\n",
      "Epoch 4384, Loss: 0.029864530341001227, Final Batch Loss: 0.0\n",
      "Epoch 4385, Loss: 0.0027267411060165614, Final Batch Loss: 0.0\n",
      "Epoch 4386, Loss: 0.003551424728357233, Final Batch Loss: 0.0\n",
      "Epoch 4387, Loss: 0.020206833389238454, Final Batch Loss: 0.0\n",
      "Epoch 4388, Loss: 0.009772295772563666, Final Batch Loss: 0.0\n",
      "Epoch 4389, Loss: 0.004409652232425287, Final Batch Loss: 0.0\n",
      "Epoch 4390, Loss: 0.04726587357436074, Final Batch Loss: 0.0002325502864550799\n",
      "Epoch 4391, Loss: 0.010356039900209169, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4392, Loss: 0.01804566156351939, Final Batch Loss: 0.0\n",
      "Epoch 4393, Loss: 0.0065972967131529, Final Batch Loss: 0.0\n",
      "Epoch 4394, Loss: 0.020117285836022347, Final Batch Loss: 0.0\n",
      "Epoch 4395, Loss: 0.005965591728454456, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 4396, Loss: 0.0031152568990080454, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4397, Loss: 0.03008945366306648, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4398, Loss: 0.006056497601093724, Final Batch Loss: 0.0\n",
      "Epoch 4399, Loss: 0.01882873396971263, Final Batch Loss: 0.001870788517408073\n",
      "Epoch 4400, Loss: 0.004505094315391034, Final Batch Loss: 0.0\n",
      "Epoch 4401, Loss: 0.005894303438253701, Final Batch Loss: 0.0\n",
      "Epoch 4402, Loss: 0.021700347308069468, Final Batch Loss: 0.0\n",
      "Epoch 4403, Loss: 0.0030763646182094817, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 4404, Loss: 0.020006927665235708, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 4405, Loss: 0.0073500818107277155, Final Batch Loss: 0.0\n",
      "Epoch 4406, Loss: 0.002581824184744619, Final Batch Loss: 0.0\n",
      "Epoch 4407, Loss: 0.0035991382901485736, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4408, Loss: 0.008050797157864054, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4409, Loss: 0.0023610691423527896, Final Batch Loss: 0.0\n",
      "Epoch 4410, Loss: 0.0032071048917714506, Final Batch Loss: 0.0\n",
      "Epoch 4411, Loss: 0.012076323851943016, Final Batch Loss: 0.0\n",
      "Epoch 4412, Loss: 0.002120503892228953, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4413, Loss: 0.030262479675002396, Final Batch Loss: 0.0\n",
      "Epoch 4414, Loss: 0.007832249393686652, Final Batch Loss: 0.0\n",
      "Epoch 4415, Loss: 0.009354355395771563, Final Batch Loss: 0.0\n",
      "Epoch 4416, Loss: 0.021619218051341704, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 4417, Loss: 0.0032160057437522482, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4418, Loss: 0.01464480580352756, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 4419, Loss: 0.003839626609988045, Final Batch Loss: 2.6702524337451905e-05\n",
      "Epoch 4420, Loss: 0.017818368622101843, Final Batch Loss: 0.0\n",
      "Epoch 4421, Loss: 0.020185544854030013, Final Batch Loss: 0.004107017070055008\n",
      "Epoch 4422, Loss: 0.00757882313337177, Final Batch Loss: 0.0\n",
      "Epoch 4423, Loss: 0.006609470675357443, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 4424, Loss: 0.00519329821690917, Final Batch Loss: 0.0\n",
      "Epoch 4425, Loss: 0.0048640060700790855, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4426, Loss: 0.013843709893990308, Final Batch Loss: 0.0\n",
      "Epoch 4427, Loss: 0.0030425879667745903, Final Batch Loss: 1.7523612768854946e-05\n",
      "Epoch 4428, Loss: 0.001899232302037035, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4429, Loss: 0.03195343405241147, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4430, Loss: 0.0010310084326192737, Final Batch Loss: 0.0\n",
      "Epoch 4431, Loss: 0.002224717682111077, Final Batch Loss: 0.0\n",
      "Epoch 4432, Loss: 0.006646316469407054, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4433, Loss: 0.004758162423968315, Final Batch Loss: 0.0\n",
      "Epoch 4434, Loss: 0.010447588651459228, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4435, Loss: 0.01070954039460048, Final Batch Loss: 0.0\n",
      "Epoch 4436, Loss: 0.0012317724176611478, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4437, Loss: 0.015396953443996608, Final Batch Loss: 0.0\n",
      "Epoch 4438, Loss: 0.003018230908764963, Final Batch Loss: 2.861018856492592e-06\n",
      "Epoch 4439, Loss: 0.01866868195065763, Final Batch Loss: 0.0\n",
      "Epoch 4440, Loss: 0.006338434759527445, Final Batch Loss: 0.0\n",
      "Epoch 4441, Loss: 0.02152958540500549, Final Batch Loss: 1.9192511899746023e-05\n",
      "Epoch 4442, Loss: 0.0020098059903546073, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4443, Loss: 0.018555945251137018, Final Batch Loss: 0.0\n",
      "Epoch 4444, Loss: 0.01276881736703217, Final Batch Loss: 0.0\n",
      "Epoch 4445, Loss: 0.006193513894686475, Final Batch Loss: 0.0\n",
      "Epoch 4446, Loss: 0.01819101069122553, Final Batch Loss: 0.0\n",
      "Epoch 4447, Loss: 0.024387042736634612, Final Batch Loss: 0.0\n",
      "Epoch 4448, Loss: 0.0023927667934842134, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4449, Loss: 0.004541157220955938, Final Batch Loss: 0.0019539566710591316\n",
      "Epoch 4450, Loss: 0.007838124642148614, Final Batch Loss: 0.0004967409186065197\n",
      "Epoch 4451, Loss: 0.01024547783890739, Final Batch Loss: 0.0\n",
      "Epoch 4452, Loss: 0.005975179316010326, Final Batch Loss: 0.0\n",
      "Epoch 4453, Loss: 0.007068308972520754, Final Batch Loss: 0.0\n",
      "Epoch 4454, Loss: 0.004709352986537851, Final Batch Loss: 0.0\n",
      "Epoch 4455, Loss: 0.010357877763453871, Final Batch Loss: 0.0\n",
      "Epoch 4456, Loss: 0.0028610101144295186, Final Batch Loss: 0.0\n",
      "Epoch 4457, Loss: 0.010662599568604492, Final Batch Loss: 0.00010799778101500124\n",
      "Epoch 4458, Loss: 0.023326805065153167, Final Batch Loss: 0.0\n",
      "Epoch 4459, Loss: 0.004169373772811014, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4460, Loss: 0.0018117205618182197, Final Batch Loss: 0.0\n",
      "Epoch 4461, Loss: 0.0032257106504403055, Final Batch Loss: 0.0\n",
      "Epoch 4462, Loss: 0.004757272021379322, Final Batch Loss: 0.0\n",
      "Epoch 4463, Loss: 0.00200757198035717, Final Batch Loss: 0.0\n",
      "Epoch 4464, Loss: 0.009947541635483503, Final Batch Loss: 0.0\n",
      "Epoch 4465, Loss: 0.005100608235807158, Final Batch Loss: 6.925819616299123e-05\n",
      "Epoch 4466, Loss: 0.001756022626068443, Final Batch Loss: 0.0\n",
      "Epoch 4467, Loss: 0.0026601842837408185, Final Batch Loss: 0.0\n",
      "Epoch 4468, Loss: 0.006649465474765748, Final Batch Loss: 0.0\n",
      "Epoch 4469, Loss: 0.004831321013625711, Final Batch Loss: 0.0\n",
      "Epoch 4470, Loss: 0.005940385203302867, Final Batch Loss: 4.529942543740617e-06\n",
      "Epoch 4471, Loss: 0.0017167734331451356, Final Batch Loss: 0.0\n",
      "Epoch 4472, Loss: 0.007298537588212639, Final Batch Loss: 0.0\n",
      "Epoch 4473, Loss: 0.018667033797100885, Final Batch Loss: 5.4834770708112046e-05\n",
      "Epoch 4474, Loss: 0.012555641471408308, Final Batch Loss: 0.0\n",
      "Epoch 4475, Loss: 0.004691394940891769, Final Batch Loss: 0.0\n",
      "Epoch 4476, Loss: 0.0023047366266837344, Final Batch Loss: 0.0\n",
      "Epoch 4477, Loss: 0.013987805810756981, Final Batch Loss: 0.0\n",
      "Epoch 4478, Loss: 0.00870960287284106, Final Batch Loss: 0.0\n",
      "Epoch 4479, Loss: 0.00485011340060737, Final Batch Loss: 0.0\n",
      "Epoch 4480, Loss: 0.004121746074360999, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 4481, Loss: 0.0017144591208761994, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4482, Loss: 0.017152731044916436, Final Batch Loss: 2.753696753643453e-05\n",
      "Epoch 4483, Loss: 0.0033643145579844713, Final Batch Loss: 0.0\n",
      "Epoch 4484, Loss: 0.003126023570075631, Final Batch Loss: 0.0\n",
      "Epoch 4485, Loss: 0.0020460076666495297, Final Batch Loss: 7.152531907195225e-06\n",
      "Epoch 4486, Loss: 0.0034796620602719486, Final Batch Loss: 0.0\n",
      "Epoch 4487, Loss: 0.0017057533550541848, Final Batch Loss: 0.0\n",
      "Epoch 4488, Loss: 0.005906716920435429, Final Batch Loss: 0.0\n",
      "Epoch 4489, Loss: 0.05547585629392415, Final Batch Loss: 0.04681474342942238\n",
      "Epoch 4490, Loss: 0.005191555304911333, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4491, Loss: 0.005408323166186335, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4492, Loss: 0.00273416044365149, Final Batch Loss: 0.0011277989251539111\n",
      "Epoch 4493, Loss: 0.00831050165288616, Final Batch Loss: 0.0\n",
      "Epoch 4494, Loss: 0.009252051822812746, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4495, Loss: 0.0011979431001236662, Final Batch Loss: 0.0\n",
      "Epoch 4496, Loss: 0.0068337409959440265, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4497, Loss: 0.004946971021070112, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4498, Loss: 0.011476387531729415, Final Batch Loss: 4.637133679352701e-05\n",
      "Epoch 4499, Loss: 0.011374576046364382, Final Batch Loss: 0.0\n",
      "Epoch 4500, Loss: 0.014182553306454793, Final Batch Loss: 0.0\n",
      "Epoch 4501, Loss: 0.00361835393414367, Final Batch Loss: 0.0\n",
      "Epoch 4502, Loss: 0.001468136761104688, Final Batch Loss: 0.0\n",
      "Epoch 4503, Loss: 0.016508590342539264, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4504, Loss: 0.005013667800085386, Final Batch Loss: 4.51792984677013e-05\n",
      "Epoch 4505, Loss: 0.009735412138972777, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4506, Loss: 0.02265348569926573, Final Batch Loss: 0.0\n",
      "Epoch 4507, Loss: 0.012875556712970138, Final Batch Loss: 0.0\n",
      "Epoch 4508, Loss: 0.0014811594737693667, Final Batch Loss: 0.0\n",
      "Epoch 4509, Loss: 0.006047735863830894, Final Batch Loss: 0.0\n",
      "Epoch 4510, Loss: 0.0025029390526469797, Final Batch Loss: 0.00010752100206445903\n",
      "Epoch 4511, Loss: 0.0035654412931762636, Final Batch Loss: 0.0\n",
      "Epoch 4512, Loss: 0.011249210219830275, Final Batch Loss: 0.0\n",
      "Epoch 4513, Loss: 0.004405238316394389, Final Batch Loss: 0.0001299296854995191\n",
      "Epoch 4514, Loss: 0.00494831899413839, Final Batch Loss: 0.0\n",
      "Epoch 4515, Loss: 0.008734647039091215, Final Batch Loss: 0.0002671123365871608\n",
      "Epoch 4516, Loss: 0.003833261347608641, Final Batch Loss: 0.0\n",
      "Epoch 4517, Loss: 0.011194799706565561, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4518, Loss: 0.003932885592803359, Final Batch Loss: 0.0\n",
      "Epoch 4519, Loss: 0.005978707820759155, Final Batch Loss: 0.0\n",
      "Epoch 4520, Loss: 0.00393221975537017, Final Batch Loss: 0.0\n",
      "Epoch 4521, Loss: 0.018450590418069623, Final Batch Loss: 0.0\n",
      "Epoch 4522, Loss: 0.011500940716359764, Final Batch Loss: 0.0\n",
      "Epoch 4523, Loss: 0.001801903621526435, Final Batch Loss: 0.0\n",
      "Epoch 4524, Loss: 0.003031142696272582, Final Batch Loss: 0.0\n",
      "Epoch 4525, Loss: 0.000985310776741244, Final Batch Loss: 0.0\n",
      "Epoch 4526, Loss: 0.0017538676038313383, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4527, Loss: 0.0013571077506639995, Final Batch Loss: 8.082063141046092e-05\n",
      "Epoch 4528, Loss: 0.0013207167503423989, Final Batch Loss: 0.0\n",
      "Epoch 4529, Loss: 0.001970808720216155, Final Batch Loss: 0.0\n",
      "Epoch 4530, Loss: 0.0031572116131357575, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4531, Loss: 0.013208284508408497, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4532, Loss: 0.0036845795111730695, Final Batch Loss: 0.0\n",
      "Epoch 4533, Loss: 0.022647057132417103, Final Batch Loss: 0.0\n",
      "Epoch 4534, Loss: 0.003462680266238749, Final Batch Loss: 0.0\n",
      "Epoch 4535, Loss: 0.0018694049504119903, Final Batch Loss: 0.0\n",
      "Epoch 4536, Loss: 0.006838236469775438, Final Batch Loss: 0.0040955008007586\n",
      "Epoch 4537, Loss: 0.0038948125147726387, Final Batch Loss: 0.0\n",
      "Epoch 4538, Loss: 0.0020991590063204058, Final Batch Loss: 0.0\n",
      "Epoch 4539, Loss: 0.030708167381817475, Final Batch Loss: 0.0\n",
      "Epoch 4540, Loss: 0.043704656940008135, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4541, Loss: 0.0015011747018434107, Final Batch Loss: 0.0\n",
      "Epoch 4542, Loss: 0.005042491859057918, Final Batch Loss: 0.00018904806347563863\n",
      "Epoch 4543, Loss: 0.021138389756288234, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 4544, Loss: 0.012281478353543207, Final Batch Loss: 0.0\n",
      "Epoch 4545, Loss: 0.001923620220622979, Final Batch Loss: 0.0\n",
      "Epoch 4546, Loss: 0.004497432295465842, Final Batch Loss: 0.0\n",
      "Epoch 4547, Loss: 0.001509054328835191, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4548, Loss: 0.005258156452271123, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4549, Loss: 0.0072078973753377795, Final Batch Loss: 0.0\n",
      "Epoch 4550, Loss: 0.02993782242992893, Final Batch Loss: 0.0\n",
      "Epoch 4551, Loss: 0.03708690730854869, Final Batch Loss: 0.0\n",
      "Epoch 4552, Loss: 0.004597472041496076, Final Batch Loss: 0.0\n",
      "Epoch 4553, Loss: 0.006447015592129901, Final Batch Loss: 0.001150065683759749\n",
      "Epoch 4554, Loss: 0.024955115750344703, Final Batch Loss: 3.313963316031732e-05\n",
      "Epoch 4555, Loss: 0.002940507663538483, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4556, Loss: 0.0027894224040210247, Final Batch Loss: 0.0\n",
      "Epoch 4557, Loss: 0.004319865969591774, Final Batch Loss: 0.00013469743134919554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4558, Loss: 0.011647865292616189, Final Batch Loss: 0.0\n",
      "Epoch 4559, Loss: 0.005111587990541011, Final Batch Loss: 0.0\n",
      "Epoch 4560, Loss: 0.006079699611291289, Final Batch Loss: 0.0\n",
      "Epoch 4561, Loss: 0.001984546950545507, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4562, Loss: 0.026944729557726532, Final Batch Loss: 0.0\n",
      "Epoch 4563, Loss: 0.00688391097355634, Final Batch Loss: 0.0\n",
      "Epoch 4564, Loss: 0.0031684309942647815, Final Batch Loss: 0.0\n",
      "Epoch 4565, Loss: 0.028359495423501357, Final Batch Loss: 3.659658250398934e-05\n",
      "Epoch 4566, Loss: 0.03401258162193699, Final Batch Loss: 0.0001081169830285944\n",
      "Epoch 4567, Loss: 0.017562348861240196, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4568, Loss: 0.003840008925180882, Final Batch Loss: 0.0\n",
      "Epoch 4569, Loss: 0.0197920220089145, Final Batch Loss: 0.0\n",
      "Epoch 4570, Loss: 0.03842209675349295, Final Batch Loss: 0.0\n",
      "Epoch 4571, Loss: 0.022072176449000835, Final Batch Loss: 0.0\n",
      "Epoch 4572, Loss: 0.013265793444560359, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4573, Loss: 0.006822652994969758, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4574, Loss: 0.0054118240950629115, Final Batch Loss: 0.0\n",
      "Epoch 4575, Loss: 0.00161179804092626, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4576, Loss: 0.011013645867762989, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4577, Loss: 0.025135953968856484, Final Batch Loss: 0.0\n",
      "Epoch 4578, Loss: 0.004186119214864448, Final Batch Loss: 0.0\n",
      "Epoch 4579, Loss: 0.018673479731660336, Final Batch Loss: 0.0\n",
      "Epoch 4580, Loss: 0.017442738258978352, Final Batch Loss: 0.0\n",
      "Epoch 4581, Loss: 0.0015170212282100692, Final Batch Loss: 0.0\n",
      "Epoch 4582, Loss: 0.014516555165755562, Final Batch Loss: 4.482168878894299e-05\n",
      "Epoch 4583, Loss: 0.007736395811662078, Final Batch Loss: 0.0\n",
      "Epoch 4584, Loss: 0.011862322549859527, Final Batch Loss: 0.0\n",
      "Epoch 4585, Loss: 0.026255645003402606, Final Batch Loss: 0.0\n",
      "Epoch 4586, Loss: 0.00188479435746558, Final Batch Loss: 0.0\n",
      "Epoch 4587, Loss: 0.0009877695565592148, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 4588, Loss: 0.009436627849936485, Final Batch Loss: 0.0\n",
      "Epoch 4589, Loss: 0.003051833075005561, Final Batch Loss: 0.0\n",
      "Epoch 4590, Loss: 0.0017468920777901076, Final Batch Loss: 0.0\n",
      "Epoch 4591, Loss: 0.010925808383035474, Final Batch Loss: 0.0\n",
      "Epoch 4592, Loss: 0.0031643363181501627, Final Batch Loss: 0.0\n",
      "Epoch 4593, Loss: 0.015043716179206967, Final Batch Loss: 0.0\n",
      "Epoch 4594, Loss: 0.010472440160810947, Final Batch Loss: 0.0\n",
      "Epoch 4595, Loss: 0.0029374424484558403, Final Batch Loss: 0.0\n",
      "Epoch 4596, Loss: 0.01838788390159607, Final Batch Loss: 0.0\n",
      "Epoch 4597, Loss: 0.0025074077129829675, Final Batch Loss: 0.0\n",
      "Epoch 4598, Loss: 0.003569115055142902, Final Batch Loss: 0.0\n",
      "Epoch 4599, Loss: 0.013981713389512151, Final Batch Loss: 0.0\n",
      "Epoch 4600, Loss: 0.03914324380457401, Final Batch Loss: 0.03538130968809128\n",
      "Epoch 4601, Loss: 0.006287570431595668, Final Batch Loss: 0.0\n",
      "Epoch 4602, Loss: 0.004499878385104239, Final Batch Loss: 0.0\n",
      "Epoch 4603, Loss: 0.013535495963651556, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4604, Loss: 0.019618517486371445, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4605, Loss: 0.0028807682101614773, Final Batch Loss: 0.0\n",
      "Epoch 4606, Loss: 0.0014071479090489447, Final Batch Loss: 0.0\n",
      "Epoch 4607, Loss: 0.009230844093849555, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4608, Loss: 0.0048145166074391454, Final Batch Loss: 0.0\n",
      "Epoch 4609, Loss: 0.0028718560351990163, Final Batch Loss: 0.0\n",
      "Epoch 4610, Loss: 0.012537987393443473, Final Batch Loss: 0.0\n",
      "Epoch 4611, Loss: 0.0068907594249765225, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4612, Loss: 0.010124241351149976, Final Batch Loss: 0.0\n",
      "Epoch 4613, Loss: 0.0020921681425463134, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4614, Loss: 0.005173790006665513, Final Batch Loss: 0.0\n",
      "Epoch 4615, Loss: 0.0027338620857335627, Final Batch Loss: 0.0\n",
      "Epoch 4616, Loss: 0.002960386890663358, Final Batch Loss: 0.0\n",
      "Epoch 4617, Loss: 0.002270290278829634, Final Batch Loss: 0.0\n",
      "Epoch 4618, Loss: 0.005936114604992326, Final Batch Loss: 0.0\n",
      "Epoch 4619, Loss: 0.02327460388187319, Final Batch Loss: 0.0\n",
      "Epoch 4620, Loss: 0.0018853798683267087, Final Batch Loss: 0.0\n",
      "Epoch 4621, Loss: 0.002843095629941672, Final Batch Loss: 0.0\n",
      "Epoch 4622, Loss: 0.002808896329952404, Final Batch Loss: 0.0\n",
      "Epoch 4623, Loss: 0.0018799981911570285, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4624, Loss: 0.01296605611923951, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4625, Loss: 0.008273894316516817, Final Batch Loss: 0.0\n",
      "Epoch 4626, Loss: 0.0017376126779709011, Final Batch Loss: 0.0\n",
      "Epoch 4627, Loss: 0.0033242086501559243, Final Batch Loss: 0.0\n",
      "Epoch 4628, Loss: 0.01664076597080566, Final Batch Loss: 0.0\n",
      "Epoch 4629, Loss: 0.005245392670531146, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 4630, Loss: 0.002851363329682499, Final Batch Loss: 0.0\n",
      "Epoch 4631, Loss: 0.007393781003202093, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 4632, Loss: 0.003916025525541045, Final Batch Loss: 0.0\n",
      "Epoch 4633, Loss: 0.003491917856308646, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4634, Loss: 0.004349377173184621, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 4635, Loss: 0.022071321029208946, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4636, Loss: 0.0012013001542072743, Final Batch Loss: 0.0\n",
      "Epoch 4637, Loss: 0.002992017864016816, Final Batch Loss: 0.0\n",
      "Epoch 4638, Loss: 0.0010532094456721097, Final Batch Loss: 0.0\n",
      "Epoch 4639, Loss: 0.002546857838751748, Final Batch Loss: 0.0\n",
      "Epoch 4640, Loss: 0.0067750493601579365, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4641, Loss: 0.0018734298937488347, Final Batch Loss: 0.0\n",
      "Epoch 4642, Loss: 0.0017061556645785458, Final Batch Loss: 4.684815212385729e-05\n",
      "Epoch 4643, Loss: 0.0025675178039819, Final Batch Loss: 0.0005616756388917565\n",
      "Epoch 4644, Loss: 0.004170425483607687, Final Batch Loss: 0.0\n",
      "Epoch 4645, Loss: 0.001546801920994767, Final Batch Loss: 1.6927575416048057e-05\n",
      "Epoch 4646, Loss: 0.004282793583115563, Final Batch Loss: 0.0\n",
      "Epoch 4647, Loss: 0.0022886885562840575, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4648, Loss: 0.02771102874245912, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4649, Loss: 0.004327956528868526, Final Batch Loss: 0.0010209829779341817\n",
      "Epoch 4650, Loss: 0.0016325341421179473, Final Batch Loss: 0.0\n",
      "Epoch 4651, Loss: 0.002892121090553701, Final Batch Loss: 0.0\n",
      "Epoch 4652, Loss: 0.005424610862633017, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4653, Loss: 0.00748998043127358, Final Batch Loss: 0.0\n",
      "Epoch 4654, Loss: 0.002413891705145943, Final Batch Loss: 0.0\n",
      "Epoch 4655, Loss: 0.0011809360572669902, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 4656, Loss: 0.037620064947986975, Final Batch Loss: 0.0\n",
      "Epoch 4657, Loss: 0.023671914037549868, Final Batch Loss: 0.0\n",
      "Epoch 4658, Loss: 0.004923549569866736, Final Batch Loss: 1.0609570381348021e-05\n",
      "Epoch 4659, Loss: 0.011780718137742952, Final Batch Loss: 7.438383181579411e-05\n",
      "Epoch 4660, Loss: 0.011238196486374363, Final Batch Loss: 0.0\n",
      "Epoch 4661, Loss: 0.006810887542087585, Final Batch Loss: 0.0\n",
      "Epoch 4662, Loss: 0.009721766306029167, Final Batch Loss: 1.1444026313256472e-05\n",
      "Epoch 4663, Loss: 0.007944596331526554, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4664, Loss: 0.021403690928764263, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4665, Loss: 0.007607496518147627, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4666, Loss: 0.009836608049226925, Final Batch Loss: 0.0\n",
      "Epoch 4667, Loss: 0.006217169342562556, Final Batch Loss: 0.0\n",
      "Epoch 4668, Loss: 0.0053607528388965875, Final Batch Loss: 0.0\n",
      "Epoch 4669, Loss: 0.004155680791882332, Final Batch Loss: 0.0\n",
      "Epoch 4670, Loss: 0.002288075804244727, Final Batch Loss: 0.0\n",
      "Epoch 4671, Loss: 0.001139389234566579, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4672, Loss: 0.0029253862740006298, Final Batch Loss: 0.00018189683032687753\n",
      "Epoch 4673, Loss: 0.001846652608946897, Final Batch Loss: 0.0\n",
      "Epoch 4674, Loss: 0.049971697430009954, Final Batch Loss: 0.0\n",
      "Epoch 4675, Loss: 0.004994011833332479, Final Batch Loss: 0.0\n",
      "Epoch 4676, Loss: 0.002156041213311255, Final Batch Loss: 0.0\n",
      "Epoch 4677, Loss: 0.006664236847427674, Final Batch Loss: 0.0\n",
      "Epoch 4678, Loss: 0.006172766345116543, Final Batch Loss: 3.838465272565372e-05\n",
      "Epoch 4679, Loss: 0.003309260297100991, Final Batch Loss: 0.0\n",
      "Epoch 4680, Loss: 0.02001192275928787, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4681, Loss: 0.0018955472332891077, Final Batch Loss: 0.0\n",
      "Epoch 4682, Loss: 0.005956212284218054, Final Batch Loss: 0.00010716341057559475\n",
      "Epoch 4683, Loss: 0.006743227189872414, Final Batch Loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4684, Loss: 0.004442470446520019, Final Batch Loss: 0.0\n",
      "Epoch 4685, Loss: 0.05168070080981124, Final Batch Loss: 0.0001333863037871197\n",
      "Epoch 4686, Loss: 0.02289834665134549, Final Batch Loss: 0.0\n",
      "Epoch 4687, Loss: 0.003939905378501862, Final Batch Loss: 0.0\n",
      "Epoch 4688, Loss: 0.012402359105180949, Final Batch Loss: 0.0\n",
      "Epoch 4689, Loss: 0.002088884566546767, Final Batch Loss: 8.702239938429557e-06\n",
      "Epoch 4690, Loss: 0.03127234138082713, Final Batch Loss: 0.0\n",
      "Epoch 4691, Loss: 0.0037003081815782934, Final Batch Loss: 0.0\n",
      "Epoch 4692, Loss: 0.0010637784871505573, Final Batch Loss: 0.0\n",
      "Epoch 4693, Loss: 0.0020083064864593325, Final Batch Loss: 1.585470999998506e-05\n",
      "Epoch 4694, Loss: 0.011584402425796725, Final Batch Loss: 0.0\n",
      "Epoch 4695, Loss: 0.0021281463559148506, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4696, Loss: 0.001652619219377982, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4697, Loss: 0.013095693226205185, Final Batch Loss: 0.01091910619288683\n",
      "Epoch 4698, Loss: 0.003972293721744791, Final Batch Loss: 0.0\n",
      "Epoch 4699, Loss: 0.011462923517683521, Final Batch Loss: 0.0\n",
      "Epoch 4700, Loss: 0.007209790957858786, Final Batch Loss: 0.0\n",
      "Epoch 4701, Loss: 0.0035843211371684447, Final Batch Loss: 0.0\n",
      "Epoch 4702, Loss: 0.0023344054934568703, Final Batch Loss: 0.0\n",
      "Epoch 4703, Loss: 0.004218295740429312, Final Batch Loss: 0.0\n",
      "Epoch 4704, Loss: 0.005317736147389951, Final Batch Loss: 3.933898824470816e-06\n",
      "Epoch 4705, Loss: 0.0034145290264859796, Final Batch Loss: 0.0\n",
      "Epoch 4706, Loss: 0.0066852825111709535, Final Batch Loss: 0.0\n",
      "Epoch 4707, Loss: 0.0035902693634852767, Final Batch Loss: 0.0\n",
      "Epoch 4708, Loss: 0.02364165153903741, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4709, Loss: 0.0026139837864320725, Final Batch Loss: 0.0\n",
      "Epoch 4710, Loss: 0.008553195730200969, Final Batch Loss: 0.0\n",
      "Epoch 4711, Loss: 0.026095184657606296, Final Batch Loss: 0.0001662831346038729\n",
      "Epoch 4712, Loss: 0.0016015774453990161, Final Batch Loss: 0.0\n",
      "Epoch 4713, Loss: 0.0032367638777941465, Final Batch Loss: 0.0\n",
      "Epoch 4714, Loss: 0.0030021204438526183, Final Batch Loss: 0.0\n",
      "Epoch 4715, Loss: 0.007938395254313946, Final Batch Loss: 0.0\n",
      "Epoch 4716, Loss: 0.005353237211238593, Final Batch Loss: 0.0\n",
      "Epoch 4717, Loss: 0.0024459058768115938, Final Batch Loss: 0.0\n",
      "Epoch 4718, Loss: 0.002999872565851547, Final Batch Loss: 0.0\n",
      "Epoch 4719, Loss: 0.009832226118298593, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4720, Loss: 0.0021868899348191917, Final Batch Loss: 0.0\n",
      "Epoch 4721, Loss: 0.011081211734563112, Final Batch Loss: 0.0\n",
      "Epoch 4722, Loss: 0.003928215286578052, Final Batch Loss: 0.0\n",
      "Epoch 4723, Loss: 0.022235108830500394, Final Batch Loss: 0.0\n",
      "Epoch 4724, Loss: 0.0021728481660829857, Final Batch Loss: 0.0\n",
      "Epoch 4725, Loss: 0.019134491332806647, Final Batch Loss: 0.0\n",
      "Epoch 4726, Loss: 0.015527435331016193, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4727, Loss: 0.00742557909666175, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4728, Loss: 0.02257652749517547, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4729, Loss: 0.02970233839005232, Final Batch Loss: 0.0\n",
      "Epoch 4730, Loss: 0.0046915736747621395, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4731, Loss: 0.0032771513797342777, Final Batch Loss: 0.0\n",
      "Epoch 4732, Loss: 0.00470031367149204, Final Batch Loss: 0.0\n",
      "Epoch 4733, Loss: 0.002565150265581906, Final Batch Loss: 0.0\n",
      "Epoch 4734, Loss: 0.010578683926723897, Final Batch Loss: 0.0\n",
      "Epoch 4735, Loss: 0.01047187794392812, Final Batch Loss: 0.0\n",
      "Epoch 4736, Loss: 0.0028929989312018733, Final Batch Loss: 4.9232225137529895e-05\n",
      "Epoch 4737, Loss: 0.009634725574869663, Final Batch Loss: 0.0\n",
      "Epoch 4738, Loss: 0.0038793925086793024, Final Batch Loss: 0.0\n",
      "Epoch 4739, Loss: 0.005178115301532671, Final Batch Loss: 0.0\n",
      "Epoch 4740, Loss: 0.0012827413229388185, Final Batch Loss: 0.0\n",
      "Epoch 4741, Loss: 0.005417125765234232, Final Batch Loss: 0.0\n",
      "Epoch 4742, Loss: 0.005159633612493053, Final Batch Loss: 0.0029526231810450554\n",
      "Epoch 4743, Loss: 0.0020061518780494225, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 4744, Loss: 0.13435008116357494, Final Batch Loss: 0.13357701897621155\n",
      "Epoch 4745, Loss: 0.013222846040662262, Final Batch Loss: 1.9073468138230965e-06\n",
      "Epoch 4746, Loss: 0.08238524571061134, Final Batch Loss: 0.0\n",
      "Epoch 4747, Loss: 0.07662412044009415, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4748, Loss: 0.043198198080062866, Final Batch Loss: 0.0\n",
      "Epoch 4749, Loss: 0.03810012942994945, Final Batch Loss: 0.0\n",
      "Epoch 4750, Loss: 0.01507964706979692, Final Batch Loss: 0.0\n",
      "Epoch 4751, Loss: 0.03671937766193878, Final Batch Loss: 0.0\n",
      "Epoch 4752, Loss: 0.009635141934268177, Final Batch Loss: 0.0\n",
      "Epoch 4753, Loss: 0.01102661360221191, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 4754, Loss: 0.011217374070831454, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4755, Loss: 0.007941810035845265, Final Batch Loss: 0.0\n",
      "Epoch 4756, Loss: 0.014089595788391307, Final Batch Loss: 0.0001267114421352744\n",
      "Epoch 4757, Loss: 0.017877799766210956, Final Batch Loss: 1.7762025890988298e-05\n",
      "Epoch 4758, Loss: 0.0016732264775782824, Final Batch Loss: 0.0\n",
      "Epoch 4759, Loss: 0.021429857557905052, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4760, Loss: 0.005662596333422698, Final Batch Loss: 0.0\n",
      "Epoch 4761, Loss: 0.002720399264887874, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4762, Loss: 0.024585078353993595, Final Batch Loss: 0.0\n",
      "Epoch 4763, Loss: 0.0009945184574462473, Final Batch Loss: 0.0\n",
      "Epoch 4764, Loss: 0.002965243096696213, Final Batch Loss: 0.0\n",
      "Epoch 4765, Loss: 0.013142605799657758, Final Batch Loss: 4.124556289752945e-05\n",
      "Epoch 4766, Loss: 0.002499400288797915, Final Batch Loss: 0.0\n",
      "Epoch 4767, Loss: 0.023897312115877867, Final Batch Loss: 0.0\n",
      "Epoch 4768, Loss: 0.026745293754515842, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4769, Loss: 0.07444995033438317, Final Batch Loss: 0.0\n",
      "Epoch 4770, Loss: 0.014023171359440312, Final Batch Loss: 0.0\n",
      "Epoch 4771, Loss: 0.04950298252515495, Final Batch Loss: 0.0005952732171863317\n",
      "Epoch 4772, Loss: 0.02403221497661434, Final Batch Loss: 0.001335205975919962\n",
      "Epoch 4773, Loss: 0.012439277168596163, Final Batch Loss: 0.0\n",
      "Epoch 4774, Loss: 0.003525194486428518, Final Batch Loss: 0.0\n",
      "Epoch 4775, Loss: 0.005145337374415249, Final Batch Loss: 0.0\n",
      "Epoch 4776, Loss: 0.03719050975632854, Final Batch Loss: 0.0022870355751365423\n",
      "Epoch 4777, Loss: 0.01316973625216633, Final Batch Loss: 0.0\n",
      "Epoch 4778, Loss: 0.00533837055809272, Final Batch Loss: 1.156323378381785e-05\n",
      "Epoch 4779, Loss: 0.018919322421425022, Final Batch Loss: 6.4490144723095e-05\n",
      "Epoch 4780, Loss: 0.01693632884413887, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4781, Loss: 0.025371082330821082, Final Batch Loss: 0.0\n",
      "Epoch 4782, Loss: 0.01600855987635441, Final Batch Loss: 0.0\n",
      "Epoch 4783, Loss: 0.006503169395728037, Final Batch Loss: 0.004724055528640747\n",
      "Epoch 4784, Loss: 0.006237404260900803, Final Batch Loss: 0.00016616393986623734\n",
      "Epoch 4785, Loss: 0.027971766015980393, Final Batch Loss: 0.0\n",
      "Epoch 4786, Loss: 0.019670569591653475, Final Batch Loss: 4.0531076592742465e-06\n",
      "Epoch 4787, Loss: 0.01661214421619661, Final Batch Loss: 0.0\n",
      "Epoch 4788, Loss: 0.0020448976138141006, Final Batch Loss: 0.00017987063620239496\n",
      "Epoch 4789, Loss: 0.006651170551776886, Final Batch Loss: 0.0\n",
      "Epoch 4790, Loss: 0.006294204169535078, Final Batch Loss: 0.004289830103516579\n",
      "Epoch 4791, Loss: 0.004654977092286572, Final Batch Loss: 0.00010430268594063818\n",
      "Epoch 4792, Loss: 0.00295741853187792, Final Batch Loss: 0.0\n",
      "Epoch 4793, Loss: 0.03436069097369909, Final Batch Loss: 0.0\n",
      "Epoch 4794, Loss: 0.007003688398754093, Final Batch Loss: 7.152555099310121e-07\n",
      "Epoch 4795, Loss: 0.005225192151556257, Final Batch Loss: 3.9457496313843876e-05\n",
      "Epoch 4796, Loss: 0.013120141782565042, Final Batch Loss: 1.3232143828645349e-05\n",
      "Epoch 4797, Loss: 0.0012401728599797934, Final Batch Loss: 0.0\n",
      "Epoch 4798, Loss: 0.0009709944715723395, Final Batch Loss: 0.0\n",
      "Epoch 4799, Loss: 0.0031588756246492267, Final Batch Loss: 0.0\n",
      "Epoch 4800, Loss: 0.009225362300639972, Final Batch Loss: 0.00035565727739594877\n",
      "Epoch 4801, Loss: 0.029699852093131085, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4802, Loss: 0.000982797224423848, Final Batch Loss: 0.0\n",
      "Epoch 4803, Loss: 0.015227589930873364, Final Batch Loss: 0.0\n",
      "Epoch 4804, Loss: 0.001165044232038781, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 4805, Loss: 0.0013591646638815291, Final Batch Loss: 0.0\n",
      "Epoch 4806, Loss: 0.0020244592633389402, Final Batch Loss: 8.940656698541716e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4807, Loss: 0.0010435455696438112, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4808, Loss: 0.03386653258348815, Final Batch Loss: 0.0\n",
      "Epoch 4809, Loss: 0.011721412971269274, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4810, Loss: 0.01697569907992147, Final Batch Loss: 0.015853434801101685\n",
      "Epoch 4811, Loss: 0.004520756367128342, Final Batch Loss: 0.0\n",
      "Epoch 4812, Loss: 0.005328663683023649, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4813, Loss: 0.0009560380131006241, Final Batch Loss: 0.0\n",
      "Epoch 4814, Loss: 0.002774125852738507, Final Batch Loss: 0.0\n",
      "Epoch 4815, Loss: 0.028571601695148274, Final Batch Loss: 0.0\n",
      "Epoch 4816, Loss: 0.001128818679710264, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4817, Loss: 0.010721199389074343, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4818, Loss: 0.0008227453417930519, Final Batch Loss: 8.702239938429557e-06\n",
      "Epoch 4819, Loss: 0.001888651677290909, Final Batch Loss: 0.0\n",
      "Epoch 4820, Loss: 0.0010522570373723283, Final Batch Loss: 0.0\n",
      "Epoch 4821, Loss: 0.016973961843177676, Final Batch Loss: 0.0\n",
      "Epoch 4822, Loss: 0.010708678672926908, Final Batch Loss: 1.2159273865108844e-05\n",
      "Epoch 4823, Loss: 0.005527604254893959, Final Batch Loss: 0.0003177614707965404\n",
      "Epoch 4824, Loss: 0.003658763445855584, Final Batch Loss: 0.0\n",
      "Epoch 4825, Loss: 0.002818062668637822, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4826, Loss: 0.024094034917652607, Final Batch Loss: 0.0\n",
      "Epoch 4827, Loss: 0.006725972722051665, Final Batch Loss: 0.0\n",
      "Epoch 4828, Loss: 0.0015608748162776465, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 4829, Loss: 0.01431946577213239, Final Batch Loss: 0.0\n",
      "Epoch 4830, Loss: 0.006397702374670189, Final Batch Loss: 0.0\n",
      "Epoch 4831, Loss: 0.004026123307824037, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4832, Loss: 0.0021793180640088394, Final Batch Loss: 0.0\n",
      "Epoch 4833, Loss: 0.0019531802099663764, Final Batch Loss: 0.0\n",
      "Epoch 4834, Loss: 0.004721885894923616, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4835, Loss: 0.004051466705277562, Final Batch Loss: 0.0\n",
      "Epoch 4836, Loss: 0.02053754177177325, Final Batch Loss: 0.0\n",
      "Epoch 4837, Loss: 0.001452366093872115, Final Batch Loss: 0.0\n",
      "Epoch 4838, Loss: 0.0033133748511318117, Final Batch Loss: 0.0\n",
      "Epoch 4839, Loss: 0.006485304271336645, Final Batch Loss: 0.0\n",
      "Epoch 4840, Loss: 0.001858533014456043, Final Batch Loss: 5.495397272170521e-05\n",
      "Epoch 4841, Loss: 0.023918921826407313, Final Batch Loss: 0.0\n",
      "Epoch 4842, Loss: 0.00841088828519787, Final Batch Loss: 2.145764938177308e-06\n",
      "Epoch 4843, Loss: 0.001565749800647609, Final Batch Loss: 0.0\n",
      "Epoch 4844, Loss: 0.00408427236834541, Final Batch Loss: 0.0\n",
      "Epoch 4845, Loss: 0.002120947859111766, Final Batch Loss: 1.4185804502631072e-05\n",
      "Epoch 4846, Loss: 0.0018564094498287886, Final Batch Loss: 0.0\n",
      "Epoch 4847, Loss: 0.00740465585840866, Final Batch Loss: 0.0\n",
      "Epoch 4848, Loss: 0.0031754832598096527, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4849, Loss: 0.0021601673745408334, Final Batch Loss: 3.2186455882765586e-06\n",
      "Epoch 4850, Loss: 0.0023234677501022816, Final Batch Loss: 0.0\n",
      "Epoch 4851, Loss: 0.0015532812249148265, Final Batch Loss: 0.0\n",
      "Epoch 4852, Loss: 0.0046102244523353875, Final Batch Loss: 0.0\n",
      "Epoch 4853, Loss: 0.0221791717922315, Final Batch Loss: 0.0\n",
      "Epoch 4854, Loss: 0.014899712841717871, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4855, Loss: 0.0018387309100944549, Final Batch Loss: 0.0\n",
      "Epoch 4856, Loss: 0.018896628433139995, Final Batch Loss: 0.0\n",
      "Epoch 4857, Loss: 0.03820620046462864, Final Batch Loss: 0.0\n",
      "Epoch 4858, Loss: 0.010274928645173986, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4859, Loss: 0.0014101201086305082, Final Batch Loss: 0.0\n",
      "Epoch 4860, Loss: 0.009200391214108095, Final Batch Loss: 0.0\n",
      "Epoch 4861, Loss: 0.0031952334102243185, Final Batch Loss: 0.0\n",
      "Epoch 4862, Loss: 0.002298430335940793, Final Batch Loss: 0.0\n",
      "Epoch 4863, Loss: 0.0030236365273594856, Final Batch Loss: 0.0001935771433636546\n",
      "Epoch 4864, Loss: 0.0014707647787872702, Final Batch Loss: 0.0\n",
      "Epoch 4865, Loss: 0.011003722072928213, Final Batch Loss: 0.0012325793504714966\n",
      "Epoch 4866, Loss: 0.0036268700641812757, Final Batch Loss: 0.0\n",
      "Epoch 4867, Loss: 0.023376879224088043, Final Batch Loss: 0.0\n",
      "Epoch 4868, Loss: 0.014648768410552293, Final Batch Loss: 0.0\n",
      "Epoch 4869, Loss: 0.0073832606576615945, Final Batch Loss: 0.0\n",
      "Epoch 4870, Loss: 0.008116530137613154, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4871, Loss: 0.010344280579374754, Final Batch Loss: 2.7179348762729205e-05\n",
      "Epoch 4872, Loss: 0.0014644891052739695, Final Batch Loss: 0.0\n",
      "Epoch 4873, Loss: 0.025466472215725844, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4874, Loss: 0.0032093314802921213, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4875, Loss: 0.004922279171296395, Final Batch Loss: 5.352353764465079e-05\n",
      "Epoch 4876, Loss: 0.01675305723620113, Final Batch Loss: 0.0\n",
      "Epoch 4877, Loss: 0.0010482964789844118, Final Batch Loss: 0.0\n",
      "Epoch 4878, Loss: 0.009495384234469384, Final Batch Loss: 0.0\n",
      "Epoch 4879, Loss: 0.001218856697960291, Final Batch Loss: 0.0\n",
      "Epoch 4880, Loss: 0.016712707292754203, Final Batch Loss: 0.0\n",
      "Epoch 4881, Loss: 0.02403808054646106, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4882, Loss: 0.001375881838605153, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4883, Loss: 0.006161905417656044, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4884, Loss: 0.012395904046798023, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4885, Loss: 0.0022864915008540265, Final Batch Loss: 0.0\n",
      "Epoch 4886, Loss: 0.004594330799591262, Final Batch Loss: 2.1219027985353023e-05\n",
      "Epoch 4887, Loss: 0.002798445158987306, Final Batch Loss: 0.0012660353677347302\n",
      "Epoch 4888, Loss: 0.042565197582007386, Final Batch Loss: 0.03618345409631729\n",
      "Epoch 4889, Loss: 0.0024330157320946455, Final Batch Loss: 0.0\n",
      "Epoch 4890, Loss: 0.005074453758425079, Final Batch Loss: 0.0\n",
      "Epoch 4891, Loss: 0.038641286664642394, Final Batch Loss: 0.0\n",
      "Epoch 4892, Loss: 0.002422540041152388, Final Batch Loss: 0.0\n",
      "Epoch 4893, Loss: 0.006998082535574213, Final Batch Loss: 0.0\n",
      "Epoch 4894, Loss: 0.0023857397318352014, Final Batch Loss: 0.0\n",
      "Epoch 4895, Loss: 0.012057381507474929, Final Batch Loss: 0.0\n",
      "Epoch 4896, Loss: 0.0017587158508831635, Final Batch Loss: 0.0\n",
      "Epoch 4897, Loss: 0.0021691451693186536, Final Batch Loss: 0.0\n",
      "Epoch 4898, Loss: 0.00110782083356753, Final Batch Loss: 0.0\n",
      "Epoch 4899, Loss: 0.0041748235817067325, Final Batch Loss: 0.0\n",
      "Epoch 4900, Loss: 0.002417239649957992, Final Batch Loss: 1.7881377516459906e-06\n",
      "Epoch 4901, Loss: 0.021724256813286047, Final Batch Loss: 6.198863957251888e-06\n",
      "Epoch 4902, Loss: 0.009229945688161934, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4903, Loss: 0.002368658344494179, Final Batch Loss: 7.664863369427621e-05\n",
      "Epoch 4904, Loss: 0.017610120950848795, Final Batch Loss: 0.0\n",
      "Epoch 4905, Loss: 0.022119635777926305, Final Batch Loss: 0.0\n",
      "Epoch 4906, Loss: 0.0119245854438077, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4907, Loss: 0.0005259652025415562, Final Batch Loss: 0.0\n",
      "Epoch 4908, Loss: 0.000743919750675559, Final Batch Loss: 0.0\n",
      "Epoch 4909, Loss: 0.010441536360303871, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 4910, Loss: 0.012170447007520124, Final Batch Loss: 0.0\n",
      "Epoch 4911, Loss: 0.0033157285361085087, Final Batch Loss: 0.0\n",
      "Epoch 4912, Loss: 0.0026648150087567046, Final Batch Loss: 0.0010763572063297033\n",
      "Epoch 4913, Loss: 0.0023181067081168294, Final Batch Loss: 0.0\n",
      "Epoch 4914, Loss: 0.0016339819703716785, Final Batch Loss: 0.0\n",
      "Epoch 4915, Loss: 0.004703668376350834, Final Batch Loss: 8.4638240878121e-06\n",
      "Epoch 4916, Loss: 0.0013513597950520762, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4917, Loss: 0.0018752111353705914, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4918, Loss: 0.00483725854428485, Final Batch Loss: 0.0\n",
      "Epoch 4919, Loss: 0.005531115457301894, Final Batch Loss: 4.768370445162873e-07\n",
      "Epoch 4920, Loss: 0.001936857937835157, Final Batch Loss: 0.0\n",
      "Epoch 4921, Loss: 0.016185846703592688, Final Batch Loss: 0.0\n",
      "Epoch 4922, Loss: 0.04180845245718956, Final Batch Loss: 0.0\n",
      "Epoch 4923, Loss: 0.004445252881851047, Final Batch Loss: 0.0\n",
      "Epoch 4924, Loss: 0.023283679229280096, Final Batch Loss: 1.7762025890988298e-05\n",
      "Epoch 4925, Loss: 0.027817897964268923, Final Batch Loss: 0.0\n",
      "Epoch 4926, Loss: 0.014485249192603078, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4927, Loss: 0.006299963279161602, Final Batch Loss: 0.0\n",
      "Epoch 4928, Loss: 0.009360665164422244, Final Batch Loss: 0.0\n",
      "Epoch 4929, Loss: 0.004065724263114134, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 4930, Loss: 0.005048652354162186, Final Batch Loss: 0.0\n",
      "Epoch 4931, Loss: 0.0033099456577474484, Final Batch Loss: 3.3378546504536644e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4932, Loss: 0.012045142677322929, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4933, Loss: 0.0011450903111835942, Final Batch Loss: 0.0\n",
      "Epoch 4934, Loss: 0.00234323728363961, Final Batch Loss: 0.0\n",
      "Epoch 4935, Loss: 0.003701043300679885, Final Batch Loss: 0.0\n",
      "Epoch 4936, Loss: 0.003967753727920353, Final Batch Loss: 0.0\n",
      "Epoch 4937, Loss: 0.006522424744616728, Final Batch Loss: 0.0\n",
      "Epoch 4938, Loss: 0.01355735256220214, Final Batch Loss: 0.0\n",
      "Epoch 4939, Loss: 0.00114951743353231, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4940, Loss: 0.007845774642191827, Final Batch Loss: 0.0\n",
      "Epoch 4941, Loss: 0.002390411180385854, Final Batch Loss: 0.0\n",
      "Epoch 4942, Loss: 0.012381578708300367, Final Batch Loss: 0.0\n",
      "Epoch 4943, Loss: 0.011653181194560602, Final Batch Loss: 0.0\n",
      "Epoch 4944, Loss: 0.004269608747563325, Final Batch Loss: 0.0\n",
      "Epoch 4945, Loss: 0.003844088285404723, Final Batch Loss: 0.0\n",
      "Epoch 4946, Loss: 0.013235429825726897, Final Batch Loss: 0.0\n",
      "Epoch 4947, Loss: 0.0014014719636179507, Final Batch Loss: 0.0\n",
      "Epoch 4948, Loss: 0.0022512760187964886, Final Batch Loss: 0.0\n",
      "Epoch 4949, Loss: 0.04000259219901636, Final Batch Loss: 0.0\n",
      "Epoch 4950, Loss: 0.0037251790922709915, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4951, Loss: 0.002371207403484732, Final Batch Loss: 0.0005740663618780673\n",
      "Epoch 4952, Loss: 0.003994067752500996, Final Batch Loss: 0.0\n",
      "Epoch 4953, Loss: 0.004052779098856263, Final Batch Loss: 0.0009388091857545078\n",
      "Epoch 4954, Loss: 0.005873444955796003, Final Batch Loss: 0.0\n",
      "Epoch 4955, Loss: 0.007217307724204147, Final Batch Loss: 0.0\n",
      "Epoch 4956, Loss: 0.003088392761128489, Final Batch Loss: 0.0\n",
      "Epoch 4957, Loss: 0.0023842517839511856, Final Batch Loss: 0.0\n",
      "Epoch 4958, Loss: 0.007572891596737463, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4959, Loss: 0.0018698573985602707, Final Batch Loss: 0.0\n",
      "Epoch 4960, Loss: 0.0021181743213674054, Final Batch Loss: 0.0\n",
      "Epoch 4961, Loss: 0.0004901154661638429, Final Batch Loss: 0.0\n",
      "Epoch 4962, Loss: 0.0024150924291461706, Final Batch Loss: 0.0\n",
      "Epoch 4963, Loss: 0.0007495661757275229, Final Batch Loss: 0.0\n",
      "Epoch 4964, Loss: 0.052434793207766006, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4965, Loss: 0.003940983279335342, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4966, Loss: 0.01686684346623224, Final Batch Loss: 1.4066597032069694e-05\n",
      "Epoch 4967, Loss: 0.03827940998598933, Final Batch Loss: 0.0\n",
      "Epoch 4968, Loss: 0.016406508453655988, Final Batch Loss: 0.0\n",
      "Epoch 4969, Loss: 0.006216332949406933, Final Batch Loss: 0.0\n",
      "Epoch 4970, Loss: 0.03137626699754037, Final Batch Loss: 0.0\n",
      "Epoch 4971, Loss: 0.005517506607702671, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4972, Loss: 0.0025025545473909006, Final Batch Loss: 0.0\n",
      "Epoch 4973, Loss: 0.003092585611739196, Final Batch Loss: 0.0\n",
      "Epoch 4974, Loss: 0.01207421428989619, Final Batch Loss: 0.0\n",
      "Epoch 4975, Loss: 0.0018354442581767216, Final Batch Loss: 0.0\n",
      "Epoch 4976, Loss: 0.005829452638863586, Final Batch Loss: 0.0\n",
      "Epoch 4977, Loss: 0.0022586851991945878, Final Batch Loss: 0.0\n",
      "Epoch 4978, Loss: 0.0016100505308713764, Final Batch Loss: 0.0\n",
      "Epoch 4979, Loss: 0.003440416817284131, Final Batch Loss: 1.3828182090946939e-05\n",
      "Epoch 4980, Loss: 0.004391565889818594, Final Batch Loss: 0.0\n",
      "Epoch 4981, Loss: 0.002299760904861614, Final Batch Loss: 0.0\n",
      "Epoch 4982, Loss: 0.004812569844943937, Final Batch Loss: 3.814689989667386e-06\n",
      "Epoch 4983, Loss: 0.002545696246670559, Final Batch Loss: 0.0\n",
      "Epoch 4984, Loss: 0.05087763085612096, Final Batch Loss: 0.04995904862880707\n",
      "Epoch 4985, Loss: 0.004370294918771833, Final Batch Loss: 0.0\n",
      "Epoch 4986, Loss: 0.03281671009972342, Final Batch Loss: 0.0\n",
      "Epoch 4987, Loss: 0.037201565923169255, Final Batch Loss: 0.0\n",
      "Epoch 4988, Loss: 0.005621515243547037, Final Batch Loss: 0.0\n",
      "Epoch 4989, Loss: 0.012312786187976599, Final Batch Loss: 0.0\n",
      "Epoch 4990, Loss: 0.0008715058465895709, Final Batch Loss: 0.0\n",
      "Epoch 4991, Loss: 0.0015523599280413691, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4992, Loss: 0.0021244878298603, Final Batch Loss: 0.0\n",
      "Epoch 4993, Loss: 0.0008485230828227941, Final Batch Loss: 0.0\n",
      "Epoch 4994, Loss: 0.0008444478808087297, Final Batch Loss: 0.00045158201828598976\n",
      "Epoch 4995, Loss: 0.004405991028754386, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4996, Loss: 0.007774604855057987, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 4997, Loss: 0.0007291483780136332, Final Batch Loss: 0.0\n",
      "Epoch 4998, Loss: 0.002943372877780348, Final Batch Loss: 0.0\n",
      "Epoch 4999, Loss: 0.001387329859426245, Final Batch Loss: 0.0\n",
      "Epoch 5000, Loss: 0.002178735099732876, Final Batch Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79  0  0]\n",
      " [ 0 51  0]\n",
      " [ 0  0 58]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        79\n",
      "           1    1.00000   1.00000   1.00000        51\n",
      "           2    1.00000   1.00000   1.00000        58\n",
      "\n",
      "    accuracy                        1.00000       188\n",
      "   macro avg    1.00000   1.00000   1.00000       188\n",
      "weighted avg    1.00000   1.00000   1.00000       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=109, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=33, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 109)\n",
    "load_model(gen, \"3 Label 6 Subject GAN Ablation_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 6)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  0  0]\n",
      " [ 0 66  0]\n",
      " [ 0  0 66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        56\n",
      "           1    1.00000   1.00000   1.00000        66\n",
      "           2    1.00000   1.00000   1.00000        66\n",
      "\n",
      "    accuracy                        1.00000       188\n",
      "   macro avg    1.00000   1.00000   1.00000       188\n",
      "weighted avg    1.00000   1.00000   1.00000       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 4\n",
    "    else:\n",
    "        y[k] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.404765486717224, Final Batch Loss: 1.9325590133666992\n",
      "Epoch 2, Loss: 7.557250142097473, Final Batch Loss: 2.090374708175659\n",
      "Epoch 3, Loss: 7.312644720077515, Final Batch Loss: 1.848496675491333\n",
      "Epoch 4, Loss: 7.331683874130249, Final Batch Loss: 1.872426986694336\n",
      "Epoch 5, Loss: 7.413126349449158, Final Batch Loss: 1.9549418687820435\n",
      "Epoch 6, Loss: 7.526399254798889, Final Batch Loss: 2.072183847427368\n",
      "Epoch 7, Loss: 7.174553155899048, Final Batch Loss: 1.7197792530059814\n",
      "Epoch 8, Loss: 7.491686820983887, Final Batch Loss: 2.0428950786590576\n",
      "Epoch 9, Loss: 7.0883495807647705, Final Batch Loss: 1.6400468349456787\n",
      "Epoch 10, Loss: 7.317397832870483, Final Batch Loss: 1.8740417957305908\n",
      "Epoch 11, Loss: 7.121568202972412, Final Batch Loss: 1.6763677597045898\n",
      "Epoch 12, Loss: 7.06843626499176, Final Batch Loss: 1.6258912086486816\n",
      "Epoch 13, Loss: 7.374050736427307, Final Batch Loss: 1.9352648258209229\n",
      "Epoch 14, Loss: 7.104016542434692, Final Batch Loss: 1.6648855209350586\n",
      "Epoch 15, Loss: 7.369668006896973, Final Batch Loss: 1.9348814487457275\n",
      "Epoch 16, Loss: 7.374510288238525, Final Batch Loss: 1.9418232440948486\n",
      "Epoch 17, Loss: 7.447884798049927, Final Batch Loss: 2.015843391418457\n",
      "Epoch 18, Loss: 7.4312673807144165, Final Batch Loss: 2.002110242843628\n",
      "Epoch 19, Loss: 7.1396297216415405, Final Batch Loss: 1.7100549936294556\n",
      "Epoch 20, Loss: 7.2800703048706055, Final Batch Loss: 1.8516125679016113\n",
      "Epoch 21, Loss: 7.3889384269714355, Final Batch Loss: 1.9657924175262451\n",
      "Epoch 22, Loss: 7.270371913909912, Final Batch Loss: 1.8496686220169067\n",
      "Epoch 23, Loss: 7.36212432384491, Final Batch Loss: 1.9446606636047363\n",
      "Epoch 24, Loss: 7.172060608863831, Final Batch Loss: 1.7557950019836426\n",
      "Epoch 25, Loss: 7.308170199394226, Final Batch Loss: 1.8908158540725708\n",
      "Epoch 26, Loss: 7.2510740756988525, Final Batch Loss: 1.8376398086547852\n",
      "Epoch 27, Loss: 7.093919515609741, Final Batch Loss: 1.6816645860671997\n",
      "Epoch 28, Loss: 7.175225734710693, Final Batch Loss: 1.7648444175720215\n",
      "Epoch 29, Loss: 7.165306568145752, Final Batch Loss: 1.7522125244140625\n",
      "Epoch 30, Loss: 7.256675601005554, Final Batch Loss: 1.845289945602417\n",
      "Epoch 31, Loss: 7.386947751045227, Final Batch Loss: 1.981386423110962\n",
      "Epoch 32, Loss: 7.149593114852905, Final Batch Loss: 1.7386888265609741\n",
      "Epoch 33, Loss: 7.032316088676453, Final Batch Loss: 1.628827452659607\n",
      "Epoch 34, Loss: 7.35724139213562, Final Batch Loss: 1.9528725147247314\n",
      "Epoch 35, Loss: 7.283608317375183, Final Batch Loss: 1.8811025619506836\n",
      "Epoch 36, Loss: 7.300079703330994, Final Batch Loss: 1.8996343612670898\n",
      "Epoch 37, Loss: 7.299076199531555, Final Batch Loss: 1.8966082334518433\n",
      "Epoch 38, Loss: 7.164830684661865, Final Batch Loss: 1.7647472620010376\n",
      "Epoch 39, Loss: 7.12088143825531, Final Batch Loss: 1.7216137647628784\n",
      "Epoch 40, Loss: 7.249144434928894, Final Batch Loss: 1.8569471836090088\n",
      "Epoch 41, Loss: 7.301009654998779, Final Batch Loss: 1.9097447395324707\n",
      "Epoch 42, Loss: 7.0701985359191895, Final Batch Loss: 1.6802654266357422\n",
      "Epoch 43, Loss: 7.049275517463684, Final Batch Loss: 1.6625934839248657\n",
      "Epoch 44, Loss: 7.298967599868774, Final Batch Loss: 1.9129791259765625\n",
      "Epoch 45, Loss: 7.32598090171814, Final Batch Loss: 1.9498915672302246\n",
      "Epoch 46, Loss: 6.9193302392959595, Final Batch Loss: 1.5445892810821533\n",
      "Epoch 47, Loss: 7.144909739494324, Final Batch Loss: 1.773000955581665\n",
      "Epoch 48, Loss: 7.287232160568237, Final Batch Loss: 1.9068511724472046\n",
      "Epoch 49, Loss: 6.984186053276062, Final Batch Loss: 1.6135185956954956\n",
      "Epoch 50, Loss: 7.2731428146362305, Final Batch Loss: 1.9125920534133911\n",
      "Epoch 51, Loss: 7.192246675491333, Final Batch Loss: 1.8305742740631104\n",
      "Epoch 52, Loss: 7.189465165138245, Final Batch Loss: 1.8325614929199219\n",
      "Epoch 53, Loss: 7.261553645133972, Final Batch Loss: 1.9221086502075195\n",
      "Epoch 54, Loss: 7.144094705581665, Final Batch Loss: 1.8014529943466187\n",
      "Epoch 55, Loss: 7.2110055685043335, Final Batch Loss: 1.8679014444351196\n",
      "Epoch 56, Loss: 7.219349384307861, Final Batch Loss: 1.8776031732559204\n",
      "Epoch 57, Loss: 6.981356143951416, Final Batch Loss: 1.6482282876968384\n",
      "Epoch 58, Loss: 6.958079814910889, Final Batch Loss: 1.6378973722457886\n",
      "Epoch 59, Loss: 7.082945227622986, Final Batch Loss: 1.7642107009887695\n",
      "Epoch 60, Loss: 7.1155864000320435, Final Batch Loss: 1.7860618829727173\n",
      "Epoch 61, Loss: 7.12616753578186, Final Batch Loss: 1.8108289241790771\n",
      "Epoch 62, Loss: 7.052964925765991, Final Batch Loss: 1.7484681606292725\n",
      "Epoch 63, Loss: 7.106873393058777, Final Batch Loss: 1.8056060075759888\n",
      "Epoch 64, Loss: 6.845946192741394, Final Batch Loss: 1.543542504310608\n",
      "Epoch 65, Loss: 7.044410705566406, Final Batch Loss: 1.7789841890335083\n",
      "Epoch 66, Loss: 6.924735069274902, Final Batch Loss: 1.661220669746399\n",
      "Epoch 67, Loss: 7.13681948184967, Final Batch Loss: 1.8951807022094727\n",
      "Epoch 68, Loss: 6.876068472862244, Final Batch Loss: 1.6344050168991089\n",
      "Epoch 69, Loss: 7.06801962852478, Final Batch Loss: 1.8497779369354248\n",
      "Epoch 70, Loss: 7.116674900054932, Final Batch Loss: 1.9092903137207031\n",
      "Epoch 71, Loss: 6.875690937042236, Final Batch Loss: 1.7119418382644653\n",
      "Epoch 72, Loss: 6.541867733001709, Final Batch Loss: 1.3829364776611328\n",
      "Epoch 73, Loss: 6.986158728599548, Final Batch Loss: 1.8367979526519775\n",
      "Epoch 74, Loss: 6.953620433807373, Final Batch Loss: 1.8255834579467773\n",
      "Epoch 75, Loss: 6.186593055725098, Final Batch Loss: 1.0676239728927612\n",
      "Epoch 76, Loss: 6.696778416633606, Final Batch Loss: 1.6254518032073975\n",
      "Epoch 77, Loss: 6.936155200004578, Final Batch Loss: 1.806786298751831\n",
      "Epoch 78, Loss: 6.456079602241516, Final Batch Loss: 1.3626655340194702\n",
      "Epoch 79, Loss: 6.799397110939026, Final Batch Loss: 1.799798607826233\n",
      "Epoch 80, Loss: 6.107550859451294, Final Batch Loss: 1.1326556205749512\n",
      "Epoch 81, Loss: 6.028335094451904, Final Batch Loss: 1.0680427551269531\n",
      "Epoch 82, Loss: 6.97588837146759, Final Batch Loss: 1.985901117324829\n",
      "Epoch 83, Loss: 6.764029145240784, Final Batch Loss: 1.8642526865005493\n",
      "Epoch 84, Loss: 6.94388210773468, Final Batch Loss: 2.0573034286499023\n",
      "Epoch 85, Loss: 6.691429495811462, Final Batch Loss: 1.8351731300354004\n",
      "Epoch 86, Loss: 6.67502748966217, Final Batch Loss: 1.802337884902954\n",
      "Epoch 87, Loss: 6.306556582450867, Final Batch Loss: 1.4382777214050293\n",
      "Epoch 88, Loss: 6.80756688117981, Final Batch Loss: 1.9980347156524658\n",
      "Epoch 89, Loss: 5.478851497173309, Final Batch Loss: 0.7313478589057922\n",
      "Epoch 90, Loss: 6.599559426307678, Final Batch Loss: 1.8165191411972046\n",
      "Epoch 91, Loss: 5.700305640697479, Final Batch Loss: 0.9036441445350647\n",
      "Epoch 92, Loss: 6.670401215553284, Final Batch Loss: 1.8831580877304077\n",
      "Epoch 93, Loss: 6.843852162361145, Final Batch Loss: 2.144381523132324\n",
      "Epoch 94, Loss: 6.3936179876327515, Final Batch Loss: 1.7305810451507568\n",
      "Epoch 95, Loss: 6.260912775993347, Final Batch Loss: 1.5617694854736328\n",
      "Epoch 96, Loss: 5.345387697219849, Final Batch Loss: 0.6709215641021729\n",
      "Epoch 97, Loss: 6.38637387752533, Final Batch Loss: 1.7557382583618164\n",
      "Epoch 98, Loss: 5.2691842913627625, Final Batch Loss: 0.6364423632621765\n",
      "Epoch 99, Loss: 5.9633448123931885, Final Batch Loss: 1.3148326873779297\n",
      "Epoch 100, Loss: 6.4473384618759155, Final Batch Loss: 1.8474410772323608\n",
      "Epoch 101, Loss: 6.168887734413147, Final Batch Loss: 1.5440624952316284\n",
      "Epoch 102, Loss: 7.102726340293884, Final Batch Loss: 2.4891819953918457\n",
      "Epoch 103, Loss: 6.365528106689453, Final Batch Loss: 1.7482283115386963\n",
      "Epoch 104, Loss: 5.748042047023773, Final Batch Loss: 0.9245030283927917\n",
      "Epoch 105, Loss: 6.605156779289246, Final Batch Loss: 1.8480117321014404\n",
      "Epoch 106, Loss: 5.936581969261169, Final Batch Loss: 1.2483441829681396\n",
      "Epoch 107, Loss: 6.1546934843063354, Final Batch Loss: 1.38029146194458\n",
      "Epoch 108, Loss: 7.517616271972656, Final Batch Loss: 2.704244613647461\n",
      "Epoch 109, Loss: 5.665127635002136, Final Batch Loss: 0.955440878868103\n",
      "Epoch 110, Loss: 6.02168607711792, Final Batch Loss: 1.4574891328811646\n",
      "Epoch 111, Loss: 5.2239830493927, Final Batch Loss: 0.6656440496444702\n",
      "Epoch 112, Loss: 6.359729528427124, Final Batch Loss: 1.7842541933059692\n",
      "Epoch 113, Loss: 6.796993732452393, Final Batch Loss: 2.1990838050842285\n",
      "Epoch 114, Loss: 6.311280250549316, Final Batch Loss: 1.7941598892211914\n",
      "Epoch 115, Loss: 5.5139806270599365, Final Batch Loss: 1.0010464191436768\n",
      "Epoch 116, Loss: 6.167018890380859, Final Batch Loss: 1.7155455350875854\n",
      "Epoch 117, Loss: 5.37493622303009, Final Batch Loss: 0.9062342643737793\n",
      "Epoch 118, Loss: 5.68402886390686, Final Batch Loss: 1.263037919998169\n",
      "Epoch 119, Loss: 5.382019996643066, Final Batch Loss: 0.8891587257385254\n",
      "Epoch 120, Loss: 5.7687904834747314, Final Batch Loss: 1.3372875452041626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Loss: 6.947214365005493, Final Batch Loss: 2.4900126457214355\n",
      "Epoch 122, Loss: 6.141047716140747, Final Batch Loss: 1.697652816772461\n",
      "Epoch 123, Loss: 5.0949559807777405, Final Batch Loss: 0.6629793047904968\n",
      "Epoch 124, Loss: 5.471714615821838, Final Batch Loss: 1.0293619632720947\n",
      "Epoch 125, Loss: 5.705200552940369, Final Batch Loss: 1.2358460426330566\n",
      "Epoch 126, Loss: 5.6658406257629395, Final Batch Loss: 1.199222207069397\n",
      "Epoch 127, Loss: 5.9078956842422485, Final Batch Loss: 1.5511351823806763\n",
      "Epoch 128, Loss: 6.417731523513794, Final Batch Loss: 2.0361499786376953\n",
      "Epoch 129, Loss: 5.400048673152924, Final Batch Loss: 0.9706173539161682\n",
      "Epoch 130, Loss: 6.203579306602478, Final Batch Loss: 1.7060704231262207\n",
      "Epoch 131, Loss: 5.72327446937561, Final Batch Loss: 1.1769216060638428\n",
      "Epoch 132, Loss: 6.024537801742554, Final Batch Loss: 1.6313540935516357\n",
      "Epoch 133, Loss: 5.973628044128418, Final Batch Loss: 1.6137535572052002\n",
      "Epoch 134, Loss: 5.733196258544922, Final Batch Loss: 1.4045543670654297\n",
      "Epoch 135, Loss: 5.50341272354126, Final Batch Loss: 1.1576944589614868\n",
      "Epoch 136, Loss: 5.986342549324036, Final Batch Loss: 1.6610937118530273\n",
      "Epoch 137, Loss: 5.709000587463379, Final Batch Loss: 1.3197928667068481\n",
      "Epoch 138, Loss: 5.530319809913635, Final Batch Loss: 1.2261731624603271\n",
      "Epoch 139, Loss: 5.299428582191467, Final Batch Loss: 0.9839307069778442\n",
      "Epoch 140, Loss: 5.809056878089905, Final Batch Loss: 1.4909279346466064\n",
      "Epoch 141, Loss: 5.036371827125549, Final Batch Loss: 0.7642538547515869\n",
      "Epoch 142, Loss: 5.097841382026672, Final Batch Loss: 0.8236351013183594\n",
      "Epoch 143, Loss: 5.57434606552124, Final Batch Loss: 1.318751573562622\n",
      "Epoch 144, Loss: 5.836004972457886, Final Batch Loss: 1.5864942073822021\n",
      "Epoch 145, Loss: 5.343216180801392, Final Batch Loss: 1.022586703300476\n",
      "Epoch 146, Loss: 5.131991028785706, Final Batch Loss: 0.8152544498443604\n",
      "Epoch 147, Loss: 5.482402086257935, Final Batch Loss: 1.2032521963119507\n",
      "Epoch 148, Loss: 4.992764890193939, Final Batch Loss: 0.7961978316307068\n",
      "Epoch 149, Loss: 5.618771433830261, Final Batch Loss: 1.315515160560608\n",
      "Epoch 150, Loss: 5.230120360851288, Final Batch Loss: 0.9413190484046936\n",
      "Epoch 151, Loss: 6.0720871686935425, Final Batch Loss: 1.791752576828003\n",
      "Epoch 152, Loss: 5.12909072637558, Final Batch Loss: 0.8637520670890808\n",
      "Epoch 153, Loss: 5.752994060516357, Final Batch Loss: 1.3984806537628174\n",
      "Epoch 154, Loss: 6.5599143505096436, Final Batch Loss: 2.207218885421753\n",
      "Epoch 155, Loss: 5.50886344909668, Final Batch Loss: 1.1725075244903564\n",
      "Epoch 156, Loss: 5.920167803764343, Final Batch Loss: 1.5416250228881836\n",
      "Epoch 157, Loss: 5.796158194541931, Final Batch Loss: 1.5106574296951294\n",
      "Epoch 158, Loss: 4.925894796848297, Final Batch Loss: 0.619204580783844\n",
      "Epoch 159, Loss: 5.973811149597168, Final Batch Loss: 1.69754159450531\n",
      "Epoch 160, Loss: 6.065480709075928, Final Batch Loss: 1.753423810005188\n",
      "Epoch 161, Loss: 5.948788285255432, Final Batch Loss: 1.6131997108459473\n",
      "Epoch 162, Loss: 5.844757080078125, Final Batch Loss: 1.604696273803711\n",
      "Epoch 163, Loss: 5.238235712051392, Final Batch Loss: 0.9930711984634399\n",
      "Epoch 164, Loss: 5.925853610038757, Final Batch Loss: 1.6072666645050049\n",
      "Epoch 165, Loss: 5.257835507392883, Final Batch Loss: 0.8975141048431396\n",
      "Epoch 166, Loss: 5.7595003843307495, Final Batch Loss: 1.518909215927124\n",
      "Epoch 167, Loss: 5.5054391622543335, Final Batch Loss: 1.2602801322937012\n",
      "Epoch 168, Loss: 5.015440464019775, Final Batch Loss: 0.8147678375244141\n",
      "Epoch 169, Loss: 4.860128998756409, Final Batch Loss: 0.6670404672622681\n",
      "Epoch 170, Loss: 5.869864463806152, Final Batch Loss: 1.676259994506836\n",
      "Epoch 171, Loss: 5.417423129081726, Final Batch Loss: 1.269862174987793\n",
      "Epoch 172, Loss: 6.222810387611389, Final Batch Loss: 1.9976063966751099\n",
      "Epoch 173, Loss: 5.210302829742432, Final Batch Loss: 1.0247862339019775\n",
      "Epoch 174, Loss: 5.783323526382446, Final Batch Loss: 1.5230087041854858\n",
      "Epoch 175, Loss: 4.9253745675086975, Final Batch Loss: 0.7677921652793884\n",
      "Epoch 176, Loss: 6.259456515312195, Final Batch Loss: 2.0911731719970703\n",
      "Epoch 177, Loss: 6.092797636985779, Final Batch Loss: 1.9056801795959473\n",
      "Epoch 178, Loss: 6.2496795654296875, Final Batch Loss: 2.0312511920928955\n",
      "Epoch 179, Loss: 5.673314690589905, Final Batch Loss: 1.4459093809127808\n",
      "Epoch 180, Loss: 5.196337342262268, Final Batch Loss: 1.0376826524734497\n",
      "Epoch 181, Loss: 6.02497136592865, Final Batch Loss: 1.8994394540786743\n",
      "Epoch 182, Loss: 5.301482558250427, Final Batch Loss: 1.1294078826904297\n",
      "Epoch 183, Loss: 4.738820910453796, Final Batch Loss: 0.6261765956878662\n",
      "Epoch 184, Loss: 6.024490118026733, Final Batch Loss: 1.830349087715149\n",
      "Epoch 185, Loss: 5.047803461551666, Final Batch Loss: 0.8954669833183289\n",
      "Epoch 186, Loss: 5.03256368637085, Final Batch Loss: 0.8509577512741089\n",
      "Epoch 187, Loss: 5.45999801158905, Final Batch Loss: 1.3005821704864502\n",
      "Epoch 188, Loss: 5.22172999382019, Final Batch Loss: 1.085623860359192\n",
      "Epoch 189, Loss: 5.3819659948349, Final Batch Loss: 1.2303030490875244\n",
      "Epoch 190, Loss: 5.962700009346008, Final Batch Loss: 1.7171586751937866\n",
      "Epoch 191, Loss: 5.917008638381958, Final Batch Loss: 1.750584602355957\n",
      "Epoch 192, Loss: 5.4522998332977295, Final Batch Loss: 1.2715599536895752\n",
      "Epoch 193, Loss: 5.100625574588776, Final Batch Loss: 0.9806423783302307\n",
      "Epoch 194, Loss: 5.961860775947571, Final Batch Loss: 1.8613195419311523\n",
      "Epoch 195, Loss: 5.561248540878296, Final Batch Loss: 1.4525620937347412\n",
      "Epoch 196, Loss: 5.479895234107971, Final Batch Loss: 1.3496439456939697\n",
      "Epoch 197, Loss: 5.616047620773315, Final Batch Loss: 1.442920207977295\n",
      "Epoch 198, Loss: 5.582811713218689, Final Batch Loss: 1.3750289678573608\n",
      "Epoch 199, Loss: 5.521206617355347, Final Batch Loss: 1.3974850177764893\n",
      "Epoch 200, Loss: 5.659180283546448, Final Batch Loss: 1.5717886686325073\n",
      "Epoch 201, Loss: 5.95232617855072, Final Batch Loss: 1.868618130683899\n",
      "Epoch 202, Loss: 5.964736104011536, Final Batch Loss: 1.9235292673110962\n",
      "Epoch 203, Loss: 5.041376113891602, Final Batch Loss: 0.9408260583877563\n",
      "Epoch 204, Loss: 5.168301820755005, Final Batch Loss: 1.0861456394195557\n",
      "Epoch 205, Loss: 4.822661519050598, Final Batch Loss: 0.7381564378738403\n",
      "Epoch 206, Loss: 5.130170464515686, Final Batch Loss: 1.0451247692108154\n",
      "Epoch 207, Loss: 5.681943655014038, Final Batch Loss: 1.5648785829544067\n",
      "Epoch 208, Loss: 5.383997559547424, Final Batch Loss: 1.3192487955093384\n",
      "Epoch 209, Loss: 5.191559553146362, Final Batch Loss: 1.1278928518295288\n",
      "Epoch 210, Loss: 4.993730187416077, Final Batch Loss: 0.9885871410369873\n",
      "Epoch 211, Loss: 5.1120840311050415, Final Batch Loss: 1.049931287765503\n",
      "Epoch 212, Loss: 4.6029199957847595, Final Batch Loss: 0.48214155435562134\n",
      "Epoch 213, Loss: 5.239590644836426, Final Batch Loss: 1.0964066982269287\n",
      "Epoch 214, Loss: 6.063568472862244, Final Batch Loss: 1.9784294366836548\n",
      "Epoch 215, Loss: 5.4523162841796875, Final Batch Loss: 1.4100738763809204\n",
      "Epoch 216, Loss: 5.1947972774505615, Final Batch Loss: 1.117014765739441\n",
      "Epoch 217, Loss: 4.809960186481476, Final Batch Loss: 0.688948929309845\n",
      "Epoch 218, Loss: 5.280080676078796, Final Batch Loss: 1.1784186363220215\n",
      "Epoch 219, Loss: 5.804652094841003, Final Batch Loss: 1.793972373008728\n",
      "Epoch 220, Loss: 5.300985097885132, Final Batch Loss: 1.245165467262268\n",
      "Epoch 221, Loss: 6.205027937889099, Final Batch Loss: 2.0626542568206787\n",
      "Epoch 222, Loss: 4.9958285093307495, Final Batch Loss: 0.8601808547973633\n",
      "Epoch 223, Loss: 4.94059419631958, Final Batch Loss: 0.8252981901168823\n",
      "Epoch 224, Loss: 5.0812113881111145, Final Batch Loss: 0.9713216423988342\n",
      "Epoch 225, Loss: 5.454449415206909, Final Batch Loss: 1.495735764503479\n",
      "Epoch 226, Loss: 5.900224447250366, Final Batch Loss: 1.8816386461257935\n",
      "Epoch 227, Loss: 5.3116655349731445, Final Batch Loss: 1.1884814500808716\n",
      "Epoch 228, Loss: 4.9381473660469055, Final Batch Loss: 0.8778397440910339\n",
      "Epoch 229, Loss: 5.360254526138306, Final Batch Loss: 1.2628345489501953\n",
      "Epoch 230, Loss: 4.625804007053375, Final Batch Loss: 0.4929240345954895\n",
      "Epoch 231, Loss: 5.10946524143219, Final Batch Loss: 1.1028352975845337\n",
      "Epoch 232, Loss: 5.445173740386963, Final Batch Loss: 1.4520081281661987\n",
      "Epoch 233, Loss: 5.346836805343628, Final Batch Loss: 1.32257080078125\n",
      "Epoch 234, Loss: 5.369404196739197, Final Batch Loss: 1.322021722793579\n",
      "Epoch 235, Loss: 5.268915057182312, Final Batch Loss: 1.2704899311065674\n",
      "Epoch 236, Loss: 6.1276034116744995, Final Batch Loss: 2.0779614448547363\n",
      "Epoch 237, Loss: 4.910150766372681, Final Batch Loss: 0.77988600730896\n",
      "Epoch 238, Loss: 4.66639518737793, Final Batch Loss: 0.5952017307281494\n",
      "Epoch 239, Loss: 4.436061352491379, Final Batch Loss: 0.48203107714653015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss: 4.807971239089966, Final Batch Loss: 0.7923368215560913\n",
      "Epoch 241, Loss: 6.722527384757996, Final Batch Loss: 2.722194194793701\n",
      "Epoch 242, Loss: 5.089017629623413, Final Batch Loss: 1.0971534252166748\n",
      "Epoch 243, Loss: 6.961426019668579, Final Batch Loss: 2.9538958072662354\n",
      "Epoch 244, Loss: 5.4144017696380615, Final Batch Loss: 1.3670140504837036\n",
      "Epoch 245, Loss: 5.162849187850952, Final Batch Loss: 1.0527048110961914\n",
      "Epoch 246, Loss: 5.723467707633972, Final Batch Loss: 1.557281732559204\n",
      "Epoch 247, Loss: 5.371070623397827, Final Batch Loss: 1.246679425239563\n",
      "Epoch 248, Loss: 6.009191513061523, Final Batch Loss: 1.990105390548706\n",
      "Epoch 249, Loss: 5.6194223165512085, Final Batch Loss: 1.4666857719421387\n",
      "Epoch 250, Loss: 5.903215408325195, Final Batch Loss: 1.7328695058822632\n",
      "Epoch 251, Loss: 5.053424775600433, Final Batch Loss: 0.8859243988990784\n",
      "Epoch 252, Loss: 4.578644752502441, Final Batch Loss: 0.5144016742706299\n",
      "Epoch 253, Loss: 5.858137726783752, Final Batch Loss: 1.8347597122192383\n",
      "Epoch 254, Loss: 5.0278013944625854, Final Batch Loss: 1.0665050745010376\n",
      "Epoch 255, Loss: 4.470330536365509, Final Batch Loss: 0.4446396231651306\n",
      "Epoch 256, Loss: 4.7113922238349915, Final Batch Loss: 0.7371280789375305\n",
      "Epoch 257, Loss: 5.223794341087341, Final Batch Loss: 1.2647426128387451\n",
      "Epoch 258, Loss: 4.951018273830414, Final Batch Loss: 0.9853188395500183\n",
      "Epoch 259, Loss: 5.62327778339386, Final Batch Loss: 1.6856657266616821\n",
      "Epoch 260, Loss: 5.605276823043823, Final Batch Loss: 1.6968841552734375\n",
      "Epoch 261, Loss: 5.173084378242493, Final Batch Loss: 1.2253185510635376\n",
      "Epoch 262, Loss: 5.190702557563782, Final Batch Loss: 1.273720383644104\n",
      "Epoch 263, Loss: 4.664493381977081, Final Batch Loss: 0.7354821562767029\n",
      "Epoch 264, Loss: 5.091171979904175, Final Batch Loss: 1.1175625324249268\n",
      "Epoch 265, Loss: 5.644363522529602, Final Batch Loss: 1.6671384572982788\n",
      "Epoch 266, Loss: 4.674647152423859, Final Batch Loss: 0.7089747786521912\n",
      "Epoch 267, Loss: 5.469544768333435, Final Batch Loss: 1.547242283821106\n",
      "Epoch 268, Loss: 4.5763238072395325, Final Batch Loss: 0.5320355296134949\n",
      "Epoch 269, Loss: 6.929768800735474, Final Batch Loss: 2.96205735206604\n",
      "Epoch 270, Loss: 6.140808701515198, Final Batch Loss: 2.067110300064087\n",
      "Epoch 271, Loss: 5.461288571357727, Final Batch Loss: 1.5219333171844482\n",
      "Epoch 272, Loss: 5.292343616485596, Final Batch Loss: 1.3091838359832764\n",
      "Epoch 273, Loss: 5.064108490943909, Final Batch Loss: 0.968156099319458\n",
      "Epoch 274, Loss: 5.98885715007782, Final Batch Loss: 1.9713118076324463\n",
      "Epoch 275, Loss: 5.6312936544418335, Final Batch Loss: 1.5840187072753906\n",
      "Epoch 276, Loss: 5.782747745513916, Final Batch Loss: 1.825226068496704\n",
      "Epoch 277, Loss: 5.399620413780212, Final Batch Loss: 1.405248761177063\n",
      "Epoch 278, Loss: 5.249660611152649, Final Batch Loss: 1.2576696872711182\n",
      "Epoch 279, Loss: 4.994630575180054, Final Batch Loss: 1.0854135751724243\n",
      "Epoch 280, Loss: 5.025880694389343, Final Batch Loss: 1.1330598592758179\n",
      "Epoch 281, Loss: 4.465862989425659, Final Batch Loss: 0.5116206407546997\n",
      "Epoch 282, Loss: 5.421054840087891, Final Batch Loss: 1.526734709739685\n",
      "Epoch 283, Loss: 4.66181868314743, Final Batch Loss: 0.7077253460884094\n",
      "Epoch 284, Loss: 4.851795434951782, Final Batch Loss: 0.9728851318359375\n",
      "Epoch 285, Loss: 4.9544126987457275, Final Batch Loss: 1.0709415674209595\n",
      "Epoch 286, Loss: 4.927759885787964, Final Batch Loss: 1.0668554306030273\n",
      "Epoch 287, Loss: 4.8873730301856995, Final Batch Loss: 0.9754130244255066\n",
      "Epoch 288, Loss: 5.1258385181427, Final Batch Loss: 1.226010799407959\n",
      "Epoch 289, Loss: 4.84025239944458, Final Batch Loss: 0.9958209991455078\n",
      "Epoch 290, Loss: 4.8653475642204285, Final Batch Loss: 0.992216169834137\n",
      "Epoch 291, Loss: 5.104924440383911, Final Batch Loss: 1.1815811395645142\n",
      "Epoch 292, Loss: 4.9573798179626465, Final Batch Loss: 1.0656324625015259\n",
      "Epoch 293, Loss: 5.377792119979858, Final Batch Loss: 1.3742942810058594\n",
      "Epoch 294, Loss: 5.121605277061462, Final Batch Loss: 1.2156472206115723\n",
      "Epoch 295, Loss: 5.497126460075378, Final Batch Loss: 1.5852761268615723\n",
      "Epoch 296, Loss: 5.825857877731323, Final Batch Loss: 1.9184081554412842\n",
      "Epoch 297, Loss: 4.3877981305122375, Final Batch Loss: 0.4934132695198059\n",
      "Epoch 298, Loss: 5.293158411979675, Final Batch Loss: 1.4259228706359863\n",
      "Epoch 299, Loss: 5.534573078155518, Final Batch Loss: 1.6150410175323486\n",
      "Epoch 300, Loss: 4.688457667827606, Final Batch Loss: 0.8220584988594055\n",
      "Epoch 301, Loss: 5.716681957244873, Final Batch Loss: 1.9183810949325562\n",
      "Epoch 302, Loss: 4.918717861175537, Final Batch Loss: 1.0339515209197998\n",
      "Epoch 303, Loss: 4.833621501922607, Final Batch Loss: 0.9529778957366943\n",
      "Epoch 304, Loss: 5.234432697296143, Final Batch Loss: 1.2840195894241333\n",
      "Epoch 305, Loss: 4.818487644195557, Final Batch Loss: 0.9027851819992065\n",
      "Epoch 306, Loss: 5.48495090007782, Final Batch Loss: 1.5844975709915161\n",
      "Epoch 307, Loss: 6.760125160217285, Final Batch Loss: 2.839017629623413\n",
      "Epoch 308, Loss: 4.610274136066437, Final Batch Loss: 0.6045209765434265\n",
      "Epoch 309, Loss: 5.506271243095398, Final Batch Loss: 1.4455785751342773\n",
      "Epoch 310, Loss: 6.375227570533752, Final Batch Loss: 2.272686004638672\n",
      "Epoch 311, Loss: 4.840064525604248, Final Batch Loss: 0.8656759262084961\n",
      "Epoch 312, Loss: 5.092928647994995, Final Batch Loss: 1.2092630863189697\n",
      "Epoch 313, Loss: 4.955260872840881, Final Batch Loss: 1.0995761156082153\n",
      "Epoch 314, Loss: 6.064120888710022, Final Batch Loss: 2.233469247817993\n",
      "Epoch 315, Loss: 4.68361896276474, Final Batch Loss: 0.8155160546302795\n",
      "Epoch 316, Loss: 5.139726400375366, Final Batch Loss: 1.226572036743164\n",
      "Epoch 317, Loss: 4.620077729225159, Final Batch Loss: 0.7711988687515259\n",
      "Epoch 318, Loss: 5.06741726398468, Final Batch Loss: 1.1854854822158813\n",
      "Epoch 319, Loss: 5.185019493103027, Final Batch Loss: 1.3351072072982788\n",
      "Epoch 320, Loss: 4.373938024044037, Final Batch Loss: 0.5629542469978333\n",
      "Epoch 321, Loss: 4.68110191822052, Final Batch Loss: 0.8384312391281128\n",
      "Epoch 322, Loss: 7.549281477928162, Final Batch Loss: 3.7239413261413574\n",
      "Epoch 323, Loss: 4.943285346031189, Final Batch Loss: 1.1537206172943115\n",
      "Epoch 324, Loss: 5.562505483627319, Final Batch Loss: 1.7099968194961548\n",
      "Epoch 325, Loss: 4.632672727108002, Final Batch Loss: 0.810906708240509\n",
      "Epoch 326, Loss: 5.007734179496765, Final Batch Loss: 1.156327486038208\n",
      "Epoch 327, Loss: 5.622105956077576, Final Batch Loss: 1.8209266662597656\n",
      "Epoch 328, Loss: 4.4291622042655945, Final Batch Loss: 0.5905995965003967\n",
      "Epoch 329, Loss: 4.562564313411713, Final Batch Loss: 0.7226290106773376\n",
      "Epoch 330, Loss: 5.436086177825928, Final Batch Loss: 1.54006028175354\n",
      "Epoch 331, Loss: 4.5018510222435, Final Batch Loss: 0.5927354693412781\n",
      "Epoch 332, Loss: 4.961243748664856, Final Batch Loss: 1.1041654348373413\n",
      "Epoch 333, Loss: 4.505732417106628, Final Batch Loss: 0.7241111993789673\n",
      "Epoch 334, Loss: 5.653116703033447, Final Batch Loss: 1.8257040977478027\n",
      "Epoch 335, Loss: 5.182756543159485, Final Batch Loss: 1.357974648475647\n",
      "Epoch 336, Loss: 4.662787735462189, Final Batch Loss: 0.8548957705497742\n",
      "Epoch 337, Loss: 5.474716782569885, Final Batch Loss: 1.6530096530914307\n",
      "Epoch 338, Loss: 4.982815384864807, Final Batch Loss: 1.1809561252593994\n",
      "Epoch 339, Loss: 4.814849436283112, Final Batch Loss: 0.9726158976554871\n",
      "Epoch 340, Loss: 5.238649129867554, Final Batch Loss: 1.4350579977035522\n",
      "Epoch 341, Loss: 5.093175053596497, Final Batch Loss: 1.2741739749908447\n",
      "Epoch 342, Loss: 5.062954902648926, Final Batch Loss: 1.2347733974456787\n",
      "Epoch 343, Loss: 5.205033540725708, Final Batch Loss: 1.3787389993667603\n",
      "Epoch 344, Loss: 6.470232129096985, Final Batch Loss: 2.6547322273254395\n",
      "Epoch 345, Loss: 6.749980807304382, Final Batch Loss: 2.9461848735809326\n",
      "Epoch 346, Loss: 5.084390044212341, Final Batch Loss: 1.2381596565246582\n",
      "Epoch 347, Loss: 5.263332962989807, Final Batch Loss: 1.4470731019973755\n",
      "Epoch 348, Loss: 5.250097632408142, Final Batch Loss: 1.388985276222229\n",
      "Epoch 349, Loss: 4.611275494098663, Final Batch Loss: 0.8347248435020447\n",
      "Epoch 350, Loss: 5.114968180656433, Final Batch Loss: 1.261479139328003\n",
      "Epoch 351, Loss: 6.031903028488159, Final Batch Loss: 2.2312421798706055\n",
      "Epoch 352, Loss: 4.942016005516052, Final Batch Loss: 1.1577163934707642\n",
      "Epoch 353, Loss: 4.650404512882233, Final Batch Loss: 0.8768002390861511\n",
      "Epoch 354, Loss: 6.324096202850342, Final Batch Loss: 2.487391471862793\n",
      "Epoch 355, Loss: 5.886599183082581, Final Batch Loss: 2.065279722213745\n",
      "Epoch 356, Loss: 6.331973910331726, Final Batch Loss: 2.531907796859741\n",
      "Epoch 357, Loss: 5.662115812301636, Final Batch Loss: 1.9827651977539062\n",
      "Epoch 358, Loss: 4.918708086013794, Final Batch Loss: 1.0804197788238525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359, Loss: 4.970702052116394, Final Batch Loss: 1.0682365894317627\n",
      "Epoch 360, Loss: 5.453144311904907, Final Batch Loss: 1.5506433248519897\n",
      "Epoch 361, Loss: 4.83413553237915, Final Batch Loss: 1.026991605758667\n",
      "Epoch 362, Loss: 6.461446762084961, Final Batch Loss: 2.641084671020508\n",
      "Epoch 363, Loss: 4.958101868629456, Final Batch Loss: 1.1345170736312866\n",
      "Epoch 364, Loss: 5.04952347278595, Final Batch Loss: 1.2324848175048828\n",
      "Epoch 365, Loss: 5.182866454124451, Final Batch Loss: 1.3571943044662476\n",
      "Epoch 366, Loss: 4.762534499168396, Final Batch Loss: 0.9867322444915771\n",
      "Epoch 367, Loss: 5.216724753379822, Final Batch Loss: 1.441164493560791\n",
      "Epoch 368, Loss: 5.35165536403656, Final Batch Loss: 1.4987585544586182\n",
      "Epoch 369, Loss: 4.720380663871765, Final Batch Loss: 0.8880308866500854\n",
      "Epoch 370, Loss: 4.853997349739075, Final Batch Loss: 0.9951685667037964\n",
      "Epoch 371, Loss: 4.43034040927887, Final Batch Loss: 0.6410348415374756\n",
      "Epoch 372, Loss: 5.039961218833923, Final Batch Loss: 1.284787654876709\n",
      "Epoch 373, Loss: 4.855787754058838, Final Batch Loss: 1.1646860837936401\n",
      "Epoch 374, Loss: 4.721248269081116, Final Batch Loss: 1.0202577114105225\n",
      "Epoch 375, Loss: 4.7213146686553955, Final Batch Loss: 1.011676549911499\n",
      "Epoch 376, Loss: 6.442913889884949, Final Batch Loss: 2.7666404247283936\n",
      "Epoch 377, Loss: 4.592063724994659, Final Batch Loss: 0.8890276551246643\n",
      "Epoch 378, Loss: 5.256906867027283, Final Batch Loss: 1.5536489486694336\n",
      "Epoch 379, Loss: 4.729542434215546, Final Batch Loss: 0.9761177897453308\n",
      "Epoch 380, Loss: 5.389461159706116, Final Batch Loss: 1.677741527557373\n",
      "Epoch 381, Loss: 4.718593180179596, Final Batch Loss: 0.9206381440162659\n",
      "Epoch 382, Loss: 5.754810094833374, Final Batch Loss: 1.9630205631256104\n",
      "Epoch 383, Loss: 4.46622908115387, Final Batch Loss: 0.7781124114990234\n",
      "Epoch 384, Loss: 4.570688545703888, Final Batch Loss: 0.8072579503059387\n",
      "Epoch 385, Loss: 4.58494246006012, Final Batch Loss: 0.8078842163085938\n",
      "Epoch 386, Loss: 4.803857684135437, Final Batch Loss: 1.0632598400115967\n",
      "Epoch 387, Loss: 5.713001608848572, Final Batch Loss: 2.044712781906128\n",
      "Epoch 388, Loss: 4.804141163825989, Final Batch Loss: 1.1115140914916992\n",
      "Epoch 389, Loss: 4.553221106529236, Final Batch Loss: 0.7732846736907959\n",
      "Epoch 390, Loss: 4.787391006946564, Final Batch Loss: 0.9892788529396057\n",
      "Epoch 391, Loss: 5.565261960029602, Final Batch Loss: 1.7549114227294922\n",
      "Epoch 392, Loss: 4.99198317527771, Final Batch Loss: 1.1663357019424438\n",
      "Epoch 393, Loss: 5.0939401388168335, Final Batch Loss: 1.3120402097702026\n",
      "Epoch 394, Loss: 4.855171084403992, Final Batch Loss: 1.0902810096740723\n",
      "Epoch 395, Loss: 5.528070092201233, Final Batch Loss: 1.7404249906539917\n",
      "Epoch 396, Loss: 5.656758546829224, Final Batch Loss: 1.9580743312835693\n",
      "Epoch 397, Loss: 4.959937930107117, Final Batch Loss: 1.2909281253814697\n",
      "Epoch 398, Loss: 5.020628452301025, Final Batch Loss: 1.3447883129119873\n",
      "Epoch 399, Loss: 4.532074153423309, Final Batch Loss: 0.7457645535469055\n",
      "Epoch 400, Loss: 4.403995156288147, Final Batch Loss: 0.739044189453125\n",
      "Epoch 401, Loss: 5.67891263961792, Final Batch Loss: 2.011197090148926\n",
      "Epoch 402, Loss: 5.238851428031921, Final Batch Loss: 1.568535566329956\n",
      "Epoch 403, Loss: 5.40202522277832, Final Batch Loss: 1.5201364755630493\n",
      "Epoch 404, Loss: 5.575642466545105, Final Batch Loss: 1.5890864133834839\n",
      "Epoch 405, Loss: 5.492859125137329, Final Batch Loss: 1.665500283241272\n",
      "Epoch 406, Loss: 5.309481143951416, Final Batch Loss: 1.508376955986023\n",
      "Epoch 407, Loss: 5.011916875839233, Final Batch Loss: 1.1198875904083252\n",
      "Epoch 408, Loss: 4.462168216705322, Final Batch Loss: 0.5997624397277832\n",
      "Epoch 409, Loss: 4.856831073760986, Final Batch Loss: 1.0153889656066895\n",
      "Epoch 410, Loss: 4.471874713897705, Final Batch Loss: 0.7998285293579102\n",
      "Epoch 411, Loss: 5.255656003952026, Final Batch Loss: 1.5862184762954712\n",
      "Epoch 412, Loss: 5.432927370071411, Final Batch Loss: 1.7526023387908936\n",
      "Epoch 413, Loss: 4.802769780158997, Final Batch Loss: 1.130969524383545\n",
      "Epoch 414, Loss: 5.580546259880066, Final Batch Loss: 1.7954065799713135\n",
      "Epoch 415, Loss: 4.935006380081177, Final Batch Loss: 1.0767014026641846\n",
      "Epoch 416, Loss: 5.990009546279907, Final Batch Loss: 2.302574634552002\n",
      "Epoch 417, Loss: 4.55406779050827, Final Batch Loss: 0.8952000737190247\n",
      "Epoch 418, Loss: 5.7639641761779785, Final Batch Loss: 1.9691472053527832\n",
      "Epoch 419, Loss: 4.751383423805237, Final Batch Loss: 0.9915182590484619\n",
      "Epoch 420, Loss: 5.0086976289749146, Final Batch Loss: 1.4304498434066772\n",
      "Epoch 421, Loss: 5.285600662231445, Final Batch Loss: 1.649949073791504\n",
      "Epoch 422, Loss: 4.730145454406738, Final Batch Loss: 1.005933403968811\n",
      "Epoch 423, Loss: 4.916228175163269, Final Batch Loss: 1.2935773134231567\n",
      "Epoch 424, Loss: 4.905248641967773, Final Batch Loss: 1.3417909145355225\n",
      "Epoch 425, Loss: 5.020651936531067, Final Batch Loss: 1.4439723491668701\n",
      "Epoch 426, Loss: 5.328313112258911, Final Batch Loss: 1.7652184963226318\n",
      "Epoch 427, Loss: 4.558554291725159, Final Batch Loss: 0.9877861738204956\n",
      "Epoch 428, Loss: 5.580152153968811, Final Batch Loss: 1.910999059677124\n",
      "Epoch 429, Loss: 4.350623190402985, Final Batch Loss: 0.7282904982566833\n",
      "Epoch 430, Loss: 4.420156538486481, Final Batch Loss: 0.7666725516319275\n",
      "Epoch 431, Loss: 6.657310962677002, Final Batch Loss: 3.0344505310058594\n",
      "Epoch 432, Loss: 5.370673179626465, Final Batch Loss: 1.6412670612335205\n",
      "Epoch 433, Loss: 4.874378085136414, Final Batch Loss: 1.045182466506958\n",
      "Epoch 434, Loss: 4.338770270347595, Final Batch Loss: 0.5668599605560303\n",
      "Epoch 435, Loss: 4.539061069488525, Final Batch Loss: 0.7783955335617065\n",
      "Epoch 436, Loss: 4.754353761672974, Final Batch Loss: 1.069568395614624\n",
      "Epoch 437, Loss: 4.412882149219513, Final Batch Loss: 0.7378407120704651\n",
      "Epoch 438, Loss: 4.432414293289185, Final Batch Loss: 0.8661538362503052\n",
      "Epoch 439, Loss: 4.311699628829956, Final Batch Loss: 0.6998133659362793\n",
      "Epoch 440, Loss: 4.123579204082489, Final Batch Loss: 0.5179556012153625\n",
      "Epoch 441, Loss: 5.123335003852844, Final Batch Loss: 1.5657074451446533\n",
      "Epoch 442, Loss: 4.322734296321869, Final Batch Loss: 0.7669830918312073\n",
      "Epoch 443, Loss: 4.848415017127991, Final Batch Loss: 1.3072450160980225\n",
      "Epoch 444, Loss: 5.3985984325408936, Final Batch Loss: 1.8301951885223389\n",
      "Epoch 445, Loss: 4.212431371212006, Final Batch Loss: 0.6324544548988342\n",
      "Epoch 446, Loss: 4.256183743476868, Final Batch Loss: 0.5710453987121582\n",
      "Epoch 447, Loss: 4.851868391036987, Final Batch Loss: 1.1637362241744995\n",
      "Epoch 448, Loss: 4.962897777557373, Final Batch Loss: 1.3227381706237793\n",
      "Epoch 449, Loss: 4.296301782131195, Final Batch Loss: 0.6643159985542297\n",
      "Epoch 450, Loss: 4.863235950469971, Final Batch Loss: 1.2772072553634644\n",
      "Epoch 451, Loss: 4.507698953151703, Final Batch Loss: 0.9733917117118835\n",
      "Epoch 452, Loss: 3.9289772510528564, Final Batch Loss: 0.3269919157028198\n",
      "Epoch 453, Loss: 3.996296375989914, Final Batch Loss: 0.406714528799057\n",
      "Epoch 454, Loss: 4.15248030424118, Final Batch Loss: 0.5511096119880676\n",
      "Epoch 455, Loss: 3.835028350353241, Final Batch Loss: 0.26809340715408325\n",
      "Epoch 456, Loss: 5.9803794622421265, Final Batch Loss: 2.403317928314209\n",
      "Epoch 457, Loss: 4.698443293571472, Final Batch Loss: 1.1753689050674438\n",
      "Epoch 458, Loss: 5.172939658164978, Final Batch Loss: 1.6046785116195679\n",
      "Epoch 459, Loss: 4.097735047340393, Final Batch Loss: 0.5960512161254883\n",
      "Epoch 460, Loss: 5.571907877922058, Final Batch Loss: 2.059286117553711\n",
      "Epoch 461, Loss: 4.588380932807922, Final Batch Loss: 1.107588768005371\n",
      "Epoch 462, Loss: 3.8613266050815582, Final Batch Loss: 0.35106149315834045\n",
      "Epoch 463, Loss: 4.931564092636108, Final Batch Loss: 1.4087536334991455\n",
      "Epoch 464, Loss: 4.469659209251404, Final Batch Loss: 0.9502242803573608\n",
      "Epoch 465, Loss: 4.133124589920044, Final Batch Loss: 0.6986922025680542\n",
      "Epoch 466, Loss: 5.407934784889221, Final Batch Loss: 1.944981575012207\n",
      "Epoch 467, Loss: 4.407092452049255, Final Batch Loss: 0.9186639785766602\n",
      "Epoch 468, Loss: 4.504897892475128, Final Batch Loss: 0.9698552489280701\n",
      "Epoch 469, Loss: 4.16972678899765, Final Batch Loss: 0.7351669669151306\n",
      "Epoch 470, Loss: 4.386106431484222, Final Batch Loss: 0.9359874129295349\n",
      "Epoch 471, Loss: 3.9561631083488464, Final Batch Loss: 0.4264386296272278\n",
      "Epoch 472, Loss: 4.905678391456604, Final Batch Loss: 1.4166691303253174\n",
      "Epoch 473, Loss: 3.9819758534431458, Final Batch Loss: 0.5191143155097961\n",
      "Epoch 474, Loss: 4.803313493728638, Final Batch Loss: 1.336039662361145\n",
      "Epoch 475, Loss: 4.097981691360474, Final Batch Loss: 0.5892418622970581\n",
      "Epoch 476, Loss: 6.070304870605469, Final Batch Loss: 2.4885973930358887\n",
      "Epoch 477, Loss: 4.752071976661682, Final Batch Loss: 1.1646239757537842\n",
      "Epoch 478, Loss: 4.243461072444916, Final Batch Loss: 0.7226447463035583\n",
      "Epoch 479, Loss: 4.241419613361359, Final Batch Loss: 0.7190132737159729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480, Loss: 4.64704704284668, Final Batch Loss: 1.1283979415893555\n",
      "Epoch 481, Loss: 4.523630142211914, Final Batch Loss: 1.0623546838760376\n",
      "Epoch 482, Loss: 3.996812105178833, Final Batch Loss: 0.5653464794158936\n",
      "Epoch 483, Loss: 4.032197117805481, Final Batch Loss: 0.5587352514266968\n",
      "Epoch 484, Loss: 5.650731325149536, Final Batch Loss: 2.1918740272521973\n",
      "Epoch 485, Loss: 5.079882740974426, Final Batch Loss: 1.713343858718872\n",
      "Epoch 486, Loss: 4.147972643375397, Final Batch Loss: 0.7941895127296448\n",
      "Epoch 487, Loss: 6.485862135887146, Final Batch Loss: 3.084554672241211\n",
      "Epoch 488, Loss: 4.574575185775757, Final Batch Loss: 1.0706889629364014\n",
      "Epoch 489, Loss: 6.256928443908691, Final Batch Loss: 2.864274024963379\n",
      "Epoch 490, Loss: 4.048253774642944, Final Batch Loss: 0.6201677322387695\n",
      "Epoch 491, Loss: 4.654390215873718, Final Batch Loss: 1.216693639755249\n",
      "Epoch 492, Loss: 4.500250339508057, Final Batch Loss: 1.0224665403366089\n",
      "Epoch 493, Loss: 3.844268500804901, Final Batch Loss: 0.42432552576065063\n",
      "Epoch 494, Loss: 4.285182952880859, Final Batch Loss: 0.9179579019546509\n",
      "Epoch 495, Loss: 5.021313428878784, Final Batch Loss: 1.6079237461090088\n",
      "Epoch 496, Loss: 4.156137824058533, Final Batch Loss: 0.7150826454162598\n",
      "Epoch 497, Loss: 3.737760901451111, Final Batch Loss: 0.2614448070526123\n",
      "Epoch 498, Loss: 4.50139057636261, Final Batch Loss: 1.0275936126708984\n",
      "Epoch 499, Loss: 4.228428065776825, Final Batch Loss: 0.848744809627533\n",
      "Epoch 500, Loss: 4.166610360145569, Final Batch Loss: 0.708716630935669\n",
      "Epoch 501, Loss: 4.499922871589661, Final Batch Loss: 1.094330072402954\n",
      "Epoch 502, Loss: 5.821131587028503, Final Batch Loss: 2.405369281768799\n",
      "Epoch 503, Loss: 4.5474607944488525, Final Batch Loss: 1.0536279678344727\n",
      "Epoch 504, Loss: 6.75705349445343, Final Batch Loss: 2.979269027709961\n",
      "Epoch 505, Loss: 4.912637114524841, Final Batch Loss: 1.3516722917556763\n",
      "Epoch 506, Loss: 5.587157368659973, Final Batch Loss: 1.8186051845550537\n",
      "Epoch 507, Loss: 4.7593525648117065, Final Batch Loss: 0.5787348747253418\n",
      "Epoch 508, Loss: 5.546536803245544, Final Batch Loss: 1.3854161500930786\n",
      "Epoch 509, Loss: 4.930779933929443, Final Batch Loss: 1.0063881874084473\n",
      "Epoch 510, Loss: 5.454800605773926, Final Batch Loss: 1.8250370025634766\n",
      "Epoch 511, Loss: 5.377933621406555, Final Batch Loss: 1.8224080801010132\n",
      "Epoch 512, Loss: 5.218084335327148, Final Batch Loss: 1.622782588005066\n",
      "Epoch 513, Loss: 4.561764597892761, Final Batch Loss: 1.0173429250717163\n",
      "Epoch 514, Loss: 4.828334093093872, Final Batch Loss: 1.352186679840088\n",
      "Epoch 515, Loss: 4.256066560745239, Final Batch Loss: 0.716213583946228\n",
      "Epoch 516, Loss: 4.054357469081879, Final Batch Loss: 0.5671581625938416\n",
      "Epoch 517, Loss: 4.853007674217224, Final Batch Loss: 1.387845516204834\n",
      "Epoch 518, Loss: 3.731539785861969, Final Batch Loss: 0.37442201375961304\n",
      "Epoch 519, Loss: 4.475918650627136, Final Batch Loss: 1.0648661851882935\n",
      "Epoch 520, Loss: 4.555465817451477, Final Batch Loss: 1.1434136629104614\n",
      "Epoch 521, Loss: 4.227990627288818, Final Batch Loss: 0.818510890007019\n",
      "Epoch 522, Loss: 4.1281872391700745, Final Batch Loss: 0.7200290560722351\n",
      "Epoch 523, Loss: 5.08848249912262, Final Batch Loss: 1.7848780155181885\n",
      "Epoch 524, Loss: 3.8296379446983337, Final Batch Loss: 0.4353482127189636\n",
      "Epoch 525, Loss: 4.6319321393966675, Final Batch Loss: 1.1869041919708252\n",
      "Epoch 526, Loss: 4.338051497936249, Final Batch Loss: 0.8397474884986877\n",
      "Epoch 527, Loss: 3.9311139285564423, Final Batch Loss: 0.4226592481136322\n",
      "Epoch 528, Loss: 3.7538666129112244, Final Batch Loss: 0.3515360951423645\n",
      "Epoch 529, Loss: 3.7189582884311676, Final Batch Loss: 0.32137325406074524\n",
      "Epoch 530, Loss: 5.228605031967163, Final Batch Loss: 1.9178837537765503\n",
      "Epoch 531, Loss: 4.15843278169632, Final Batch Loss: 0.7504099011421204\n",
      "Epoch 532, Loss: 4.144524276256561, Final Batch Loss: 0.6683208346366882\n",
      "Epoch 533, Loss: 3.9945940375328064, Final Batch Loss: 0.5026819109916687\n",
      "Epoch 534, Loss: 4.814373135566711, Final Batch Loss: 1.3568625450134277\n",
      "Epoch 535, Loss: 4.008782267570496, Final Batch Loss: 0.6207900047302246\n",
      "Epoch 536, Loss: 6.540807485580444, Final Batch Loss: 2.9833364486694336\n",
      "Epoch 537, Loss: 4.594294548034668, Final Batch Loss: 1.0046842098236084\n",
      "Epoch 538, Loss: 4.0358399748802185, Final Batch Loss: 0.5604808926582336\n",
      "Epoch 539, Loss: 4.3085020780563354, Final Batch Loss: 0.8208739757537842\n",
      "Epoch 540, Loss: 5.124809980392456, Final Batch Loss: 1.5667781829833984\n",
      "Epoch 541, Loss: 4.126520454883575, Final Batch Loss: 0.5915288329124451\n",
      "Epoch 542, Loss: 4.394806444644928, Final Batch Loss: 0.8104963898658752\n",
      "Epoch 543, Loss: 5.029313921928406, Final Batch Loss: 1.5019102096557617\n",
      "Epoch 544, Loss: 4.209938883781433, Final Batch Loss: 0.683966875076294\n",
      "Epoch 545, Loss: 4.765234470367432, Final Batch Loss: 1.2898595333099365\n",
      "Epoch 546, Loss: 5.294993042945862, Final Batch Loss: 1.7601187229156494\n",
      "Epoch 547, Loss: 3.8922199606895447, Final Batch Loss: 0.5164080262184143\n",
      "Epoch 548, Loss: 4.694804072380066, Final Batch Loss: 1.2690855264663696\n",
      "Epoch 549, Loss: 4.0982865691185, Final Batch Loss: 0.7231257557868958\n",
      "Epoch 550, Loss: 6.012656211853027, Final Batch Loss: 2.640061855316162\n",
      "Epoch 551, Loss: 5.121755361557007, Final Batch Loss: 1.6850062608718872\n",
      "Epoch 552, Loss: 4.109662294387817, Final Batch Loss: 0.6110212802886963\n",
      "Epoch 553, Loss: 5.168629169464111, Final Batch Loss: 1.6546895503997803\n",
      "Epoch 554, Loss: 4.423843801021576, Final Batch Loss: 0.9417662024497986\n",
      "Epoch 555, Loss: 4.589111924171448, Final Batch Loss: 1.1659176349639893\n",
      "Epoch 556, Loss: 4.486639142036438, Final Batch Loss: 1.0629689693450928\n",
      "Epoch 557, Loss: 4.412110865116119, Final Batch Loss: 0.9991922974586487\n",
      "Epoch 558, Loss: 4.09481543302536, Final Batch Loss: 0.7225674986839294\n",
      "Epoch 559, Loss: 4.372656881809235, Final Batch Loss: 0.9922171235084534\n",
      "Epoch 560, Loss: 5.376804232597351, Final Batch Loss: 2.1429738998413086\n",
      "Epoch 561, Loss: 4.177114427089691, Final Batch Loss: 0.825315535068512\n",
      "Epoch 562, Loss: 4.366246342658997, Final Batch Loss: 1.0403581857681274\n",
      "Epoch 563, Loss: 4.401866436004639, Final Batch Loss: 1.093153715133667\n",
      "Epoch 564, Loss: 4.1495261788368225, Final Batch Loss: 0.8276557326316833\n",
      "Epoch 565, Loss: 4.136721312999725, Final Batch Loss: 0.8302591443061829\n",
      "Epoch 566, Loss: 4.169919073581696, Final Batch Loss: 0.8368321061134338\n",
      "Epoch 567, Loss: 4.3850860595703125, Final Batch Loss: 1.1014444828033447\n",
      "Epoch 568, Loss: 4.391106963157654, Final Batch Loss: 1.0762224197387695\n",
      "Epoch 569, Loss: 4.605265855789185, Final Batch Loss: 1.2888598442077637\n",
      "Epoch 570, Loss: 4.31099671125412, Final Batch Loss: 0.9534458518028259\n",
      "Epoch 571, Loss: 4.133418500423431, Final Batch Loss: 0.7863287329673767\n",
      "Epoch 572, Loss: 4.1326428055763245, Final Batch Loss: 0.7246381640434265\n",
      "Epoch 573, Loss: 4.81306254863739, Final Batch Loss: 1.4634156227111816\n",
      "Epoch 574, Loss: 5.297797799110413, Final Batch Loss: 1.8378678560256958\n",
      "Epoch 575, Loss: 6.469202876091003, Final Batch Loss: 2.9743709564208984\n",
      "Epoch 576, Loss: 4.328930616378784, Final Batch Loss: 0.7836869955062866\n",
      "Epoch 577, Loss: 3.9674571752548218, Final Batch Loss: 0.6583026647567749\n",
      "Epoch 578, Loss: 4.688273668289185, Final Batch Loss: 1.3440457582473755\n",
      "Epoch 579, Loss: 4.244584143161774, Final Batch Loss: 0.8804619908332825\n",
      "Epoch 580, Loss: 3.877291202545166, Final Batch Loss: 0.5543975830078125\n",
      "Epoch 581, Loss: 4.11722856760025, Final Batch Loss: 0.7991098761558533\n",
      "Epoch 582, Loss: 3.8624724745750427, Final Batch Loss: 0.6859282851219177\n",
      "Epoch 583, Loss: 3.8455276489257812, Final Batch Loss: 0.6007838249206543\n",
      "Epoch 584, Loss: 3.968748450279236, Final Batch Loss: 0.692306399345398\n",
      "Epoch 585, Loss: 4.442995190620422, Final Batch Loss: 1.2163962125778198\n",
      "Epoch 586, Loss: 3.961823582649231, Final Batch Loss: 0.7358487844467163\n",
      "Epoch 587, Loss: 4.678859710693359, Final Batch Loss: 1.4115703105926514\n",
      "Epoch 588, Loss: 3.6502762734889984, Final Batch Loss: 0.40706321597099304\n",
      "Epoch 589, Loss: 5.236610174179077, Final Batch Loss: 1.9750001430511475\n",
      "Epoch 590, Loss: 5.953029274940491, Final Batch Loss: 2.7194604873657227\n",
      "Epoch 591, Loss: 4.862489461898804, Final Batch Loss: 1.6198707818984985\n",
      "Epoch 592, Loss: 5.053725361824036, Final Batch Loss: 1.7978274822235107\n",
      "Epoch 593, Loss: 4.155849397182465, Final Batch Loss: 0.9103912711143494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594, Loss: 5.457664489746094, Final Batch Loss: 2.1534042358398438\n",
      "Epoch 595, Loss: 4.505599617958069, Final Batch Loss: 1.1049623489379883\n",
      "Epoch 596, Loss: 4.129182457923889, Final Batch Loss: 0.6829909086227417\n",
      "Epoch 597, Loss: 4.053564071655273, Final Batch Loss: 0.5019100904464722\n",
      "Epoch 598, Loss: 5.343993544578552, Final Batch Loss: 1.7051887512207031\n",
      "Epoch 599, Loss: 4.579797863960266, Final Batch Loss: 1.0224549770355225\n",
      "Epoch 600, Loss: 4.157976806163788, Final Batch Loss: 0.728884756565094\n",
      "Epoch 601, Loss: 5.170319557189941, Final Batch Loss: 1.8759424686431885\n",
      "Epoch 602, Loss: 5.860568165779114, Final Batch Loss: 2.5035552978515625\n",
      "Epoch 603, Loss: 4.651925444602966, Final Batch Loss: 1.3774609565734863\n",
      "Epoch 604, Loss: 3.6739117205142975, Final Batch Loss: 0.4684962332248688\n",
      "Epoch 605, Loss: 5.015873432159424, Final Batch Loss: 1.779222846031189\n",
      "Epoch 606, Loss: 4.108307421207428, Final Batch Loss: 0.8496715426445007\n",
      "Epoch 607, Loss: 3.42587473988533, Final Batch Loss: 0.14501002430915833\n",
      "Epoch 608, Loss: 4.326127767562866, Final Batch Loss: 1.145527720451355\n",
      "Epoch 609, Loss: 4.14205139875412, Final Batch Loss: 0.9390680193901062\n",
      "Epoch 610, Loss: 4.845714688301086, Final Batch Loss: 1.5377644300460815\n",
      "Epoch 611, Loss: 4.580649495124817, Final Batch Loss: 1.316145420074463\n",
      "Epoch 612, Loss: 4.3314372301101685, Final Batch Loss: 1.0649635791778564\n",
      "Epoch 613, Loss: 3.7996073961257935, Final Batch Loss: 0.5542465448379517\n",
      "Epoch 614, Loss: 3.461506336927414, Final Batch Loss: 0.24108728766441345\n",
      "Epoch 615, Loss: 4.175705075263977, Final Batch Loss: 1.001678228378296\n",
      "Epoch 616, Loss: 4.104125797748566, Final Batch Loss: 0.9356548190116882\n",
      "Epoch 617, Loss: 5.5349200963974, Final Batch Loss: 2.2801434993743896\n",
      "Epoch 618, Loss: 4.109351575374603, Final Batch Loss: 0.7970542311668396\n",
      "Epoch 619, Loss: 4.342933416366577, Final Batch Loss: 1.0737491846084595\n",
      "Epoch 620, Loss: 4.144106984138489, Final Batch Loss: 0.8238980770111084\n",
      "Epoch 621, Loss: 3.380756303668022, Final Batch Loss: 0.2062874287366867\n",
      "Epoch 622, Loss: 4.309031248092651, Final Batch Loss: 1.065646767616272\n",
      "Epoch 623, Loss: 4.373600661754608, Final Batch Loss: 1.168089509010315\n",
      "Epoch 624, Loss: 3.847586691379547, Final Batch Loss: 0.5996134877204895\n",
      "Epoch 625, Loss: 4.366142153739929, Final Batch Loss: 1.230419397354126\n",
      "Epoch 626, Loss: 3.8935959935188293, Final Batch Loss: 0.7483786940574646\n",
      "Epoch 627, Loss: 4.376413464546204, Final Batch Loss: 1.2697702646255493\n",
      "Epoch 628, Loss: 3.833748698234558, Final Batch Loss: 0.7011483907699585\n",
      "Epoch 629, Loss: 6.513327717781067, Final Batch Loss: 3.3047358989715576\n",
      "Epoch 630, Loss: 4.949041962623596, Final Batch Loss: 1.6649067401885986\n",
      "Epoch 631, Loss: 4.3621092438697815, Final Batch Loss: 0.9189209342002869\n",
      "Epoch 632, Loss: 5.0028733015060425, Final Batch Loss: 1.5254637002944946\n",
      "Epoch 633, Loss: 5.237335801124573, Final Batch Loss: 1.8155096769332886\n",
      "Epoch 634, Loss: 3.658140480518341, Final Batch Loss: 0.41800540685653687\n",
      "Epoch 635, Loss: 5.8129318952560425, Final Batch Loss: 2.611786365509033\n",
      "Epoch 636, Loss: 3.5747376680374146, Final Batch Loss: 0.3370847702026367\n",
      "Epoch 637, Loss: 4.3601309061050415, Final Batch Loss: 1.1124553680419922\n",
      "Epoch 638, Loss: 4.302249908447266, Final Batch Loss: 1.0582237243652344\n",
      "Epoch 639, Loss: 4.25281548500061, Final Batch Loss: 1.0787203311920166\n",
      "Epoch 640, Loss: 3.818422853946686, Final Batch Loss: 0.5705515742301941\n",
      "Epoch 641, Loss: 4.056838810443878, Final Batch Loss: 0.8141128420829773\n",
      "Epoch 642, Loss: 3.700591266155243, Final Batch Loss: 0.505322277545929\n",
      "Epoch 643, Loss: 3.3506945371627808, Final Batch Loss: 0.22161221504211426\n",
      "Epoch 644, Loss: 4.427557110786438, Final Batch Loss: 1.308091402053833\n",
      "Epoch 645, Loss: 4.413064122200012, Final Batch Loss: 1.3044577836990356\n",
      "Epoch 646, Loss: 5.316110968589783, Final Batch Loss: 2.2120726108551025\n",
      "Epoch 647, Loss: 3.2865100651979446, Final Batch Loss: 0.10388179123401642\n",
      "Epoch 648, Loss: 4.363309860229492, Final Batch Loss: 1.1909589767456055\n",
      "Epoch 649, Loss: 3.9133054614067078, Final Batch Loss: 0.7670897841453552\n",
      "Epoch 650, Loss: 3.944548189640045, Final Batch Loss: 0.8203702569007874\n",
      "Epoch 651, Loss: 4.153384804725647, Final Batch Loss: 1.0272679328918457\n",
      "Epoch 652, Loss: 4.158961772918701, Final Batch Loss: 1.0726065635681152\n",
      "Epoch 653, Loss: 3.2929427474737167, Final Batch Loss: 0.22440503537654877\n",
      "Epoch 654, Loss: 4.853446066379547, Final Batch Loss: 1.8153941631317139\n",
      "Epoch 655, Loss: 3.7573657035827637, Final Batch Loss: 0.6521748304367065\n",
      "Epoch 656, Loss: 4.940722167491913, Final Batch Loss: 1.771719217300415\n",
      "Epoch 657, Loss: 4.209680914878845, Final Batch Loss: 1.1012847423553467\n",
      "Epoch 658, Loss: 4.69755345582962, Final Batch Loss: 1.579061508178711\n",
      "Epoch 659, Loss: 3.8385422825813293, Final Batch Loss: 0.787750780582428\n",
      "Epoch 660, Loss: 4.071491956710815, Final Batch Loss: 0.9712215662002563\n",
      "Epoch 661, Loss: 3.2921365574002266, Final Batch Loss: 0.11155153065919876\n",
      "Epoch 662, Loss: 3.998208224773407, Final Batch Loss: 0.757598340511322\n",
      "Epoch 663, Loss: 3.351035088300705, Final Batch Loss: 0.19435206055641174\n",
      "Epoch 664, Loss: 4.080305397510529, Final Batch Loss: 0.9932129383087158\n",
      "Epoch 665, Loss: 4.241052627563477, Final Batch Loss: 1.1112568378448486\n",
      "Epoch 666, Loss: 3.377622961997986, Final Batch Loss: 0.32213956117630005\n",
      "Epoch 667, Loss: 4.683906257152557, Final Batch Loss: 1.5991573333740234\n",
      "Epoch 668, Loss: 4.16584837436676, Final Batch Loss: 1.1011159420013428\n",
      "Epoch 669, Loss: 3.404229015111923, Final Batch Loss: 0.3549032509326935\n",
      "Epoch 670, Loss: 3.2280158698558807, Final Batch Loss: 0.13959667086601257\n",
      "Epoch 671, Loss: 3.6306747794151306, Final Batch Loss: 0.6213571429252625\n",
      "Epoch 672, Loss: 4.258500635623932, Final Batch Loss: 1.176849365234375\n",
      "Epoch 673, Loss: 3.423099637031555, Final Batch Loss: 0.2733203172683716\n",
      "Epoch 674, Loss: 4.001013696193695, Final Batch Loss: 0.8862562775611877\n",
      "Epoch 675, Loss: 4.446185529232025, Final Batch Loss: 1.426243543624878\n",
      "Epoch 676, Loss: 4.227849006652832, Final Batch Loss: 1.327386498451233\n",
      "Epoch 677, Loss: 4.475073575973511, Final Batch Loss: 1.4832435846328735\n",
      "Epoch 678, Loss: 3.8324477076530457, Final Batch Loss: 0.73446124792099\n",
      "Epoch 679, Loss: 5.000942945480347, Final Batch Loss: 1.9044657945632935\n",
      "Epoch 680, Loss: 9.516227781772614, Final Batch Loss: 6.473010063171387\n",
      "Epoch 681, Loss: 4.48170280456543, Final Batch Loss: 1.4557111263275146\n",
      "Epoch 682, Loss: 3.994011402130127, Final Batch Loss: 0.9647883772850037\n",
      "Epoch 683, Loss: 5.544278860092163, Final Batch Loss: 2.4999234676361084\n",
      "Epoch 684, Loss: 3.924491822719574, Final Batch Loss: 0.6719077229499817\n",
      "Epoch 685, Loss: 4.782376408576965, Final Batch Loss: 1.3443942070007324\n",
      "Epoch 686, Loss: 4.251332342624664, Final Batch Loss: 0.8816953301429749\n",
      "Epoch 687, Loss: 3.9540783762931824, Final Batch Loss: 0.7525549530982971\n",
      "Epoch 688, Loss: 4.674300909042358, Final Batch Loss: 1.479335069656372\n",
      "Epoch 689, Loss: 4.398194670677185, Final Batch Loss: 1.2804386615753174\n",
      "Epoch 690, Loss: 4.019347727298737, Final Batch Loss: 0.8964113593101501\n",
      "Epoch 691, Loss: 3.460880011320114, Final Batch Loss: 0.37557312846183777\n",
      "Epoch 692, Loss: 4.356752812862396, Final Batch Loss: 1.2645883560180664\n",
      "Epoch 693, Loss: 3.450603276491165, Final Batch Loss: 0.424051970243454\n",
      "Epoch 694, Loss: 3.210718661546707, Final Batch Loss: 0.1501655876636505\n",
      "Epoch 695, Loss: 3.966194748878479, Final Batch Loss: 0.9592831134796143\n",
      "Epoch 696, Loss: 4.719300627708435, Final Batch Loss: 1.6121995449066162\n",
      "Epoch 697, Loss: 3.52639377117157, Final Batch Loss: 0.45874112844467163\n",
      "Epoch 698, Loss: 3.4649211168289185, Final Batch Loss: 0.3619424104690552\n",
      "Epoch 699, Loss: 3.677716612815857, Final Batch Loss: 0.6206546425819397\n",
      "Epoch 700, Loss: 4.34845095872879, Final Batch Loss: 1.347778558731079\n",
      "Epoch 701, Loss: 4.293165445327759, Final Batch Loss: 1.2617653608322144\n",
      "Epoch 702, Loss: 5.7658257484436035, Final Batch Loss: 2.6584577560424805\n",
      "Epoch 703, Loss: 3.5319803059101105, Final Batch Loss: 0.4904669225215912\n",
      "Epoch 704, Loss: 4.565803170204163, Final Batch Loss: 1.3989980220794678\n",
      "Epoch 705, Loss: 3.27835550904274, Final Batch Loss: 0.2805156409740448\n",
      "Epoch 706, Loss: 3.171928644180298, Final Batch Loss: 0.11177712678909302\n",
      "Epoch 707, Loss: 4.63849663734436, Final Batch Loss: 1.58455491065979\n",
      "Epoch 708, Loss: 4.564083099365234, Final Batch Loss: 1.5380384922027588\n",
      "Epoch 709, Loss: 4.012747585773468, Final Batch Loss: 1.079272985458374\n",
      "Epoch 710, Loss: 3.2920619547367096, Final Batch Loss: 0.2822347581386566\n",
      "Epoch 711, Loss: 4.635842978954315, Final Batch Loss: 1.6291544437408447\n",
      "Epoch 712, Loss: 4.072715759277344, Final Batch Loss: 1.1326825618743896\n",
      "Epoch 713, Loss: 3.6182780861854553, Final Batch Loss: 0.6193100810050964\n",
      "Epoch 714, Loss: 3.379646062850952, Final Batch Loss: 0.33135485649108887\n",
      "Epoch 715, Loss: 3.891516387462616, Final Batch Loss: 0.9735180735588074\n",
      "Epoch 716, Loss: 2.9181960448622704, Final Batch Loss: 0.03413333743810654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717, Loss: 3.517979919910431, Final Batch Loss: 0.5372036099433899\n",
      "Epoch 718, Loss: 3.1579278260469437, Final Batch Loss: 0.1542809158563614\n",
      "Epoch 719, Loss: 3.3706526160240173, Final Batch Loss: 0.44492828845977783\n",
      "Epoch 720, Loss: 4.623551845550537, Final Batch Loss: 1.6459099054336548\n",
      "Epoch 721, Loss: 3.0749761015176773, Final Batch Loss: 0.15016569197177887\n",
      "Epoch 722, Loss: 5.351389229297638, Final Batch Loss: 2.382589340209961\n",
      "Epoch 723, Loss: 3.288039118051529, Final Batch Loss: 0.34984245896339417\n",
      "Epoch 724, Loss: 4.3503143191337585, Final Batch Loss: 1.313122272491455\n",
      "Epoch 725, Loss: 3.5873868465423584, Final Batch Loss: 0.6680775880813599\n",
      "Epoch 726, Loss: 3.082110673189163, Final Batch Loss: 0.09976616501808167\n",
      "Epoch 727, Loss: 4.085102379322052, Final Batch Loss: 1.1886897087097168\n",
      "Epoch 728, Loss: 3.5062740445137024, Final Batch Loss: 0.6314089894294739\n",
      "Epoch 729, Loss: 3.319166362285614, Final Batch Loss: 0.337605357170105\n",
      "Epoch 730, Loss: 3.0417338833212852, Final Batch Loss: 0.11319180577993393\n",
      "Epoch 731, Loss: 4.502436637878418, Final Batch Loss: 1.581912875175476\n",
      "Epoch 732, Loss: 4.5836488008499146, Final Batch Loss: 1.7317222356796265\n",
      "Epoch 733, Loss: 3.5179024934768677, Final Batch Loss: 0.6324624419212341\n",
      "Epoch 734, Loss: 3.849053919315338, Final Batch Loss: 0.9217162132263184\n",
      "Epoch 735, Loss: 3.461412727832794, Final Batch Loss: 0.5377843379974365\n",
      "Epoch 736, Loss: 3.761556625366211, Final Batch Loss: 0.8139619827270508\n",
      "Epoch 737, Loss: 3.511990249156952, Final Batch Loss: 0.5998876094818115\n",
      "Epoch 738, Loss: 3.9032009840011597, Final Batch Loss: 1.0986757278442383\n",
      "Epoch 739, Loss: 3.038121998310089, Final Batch Loss: 0.24963796138763428\n",
      "Epoch 740, Loss: 4.435047745704651, Final Batch Loss: 1.5545648336410522\n",
      "Epoch 741, Loss: 4.413351118564606, Final Batch Loss: 1.5549951791763306\n",
      "Epoch 742, Loss: 3.2652956545352936, Final Batch Loss: 0.3620992600917816\n",
      "Epoch 743, Loss: 3.2647712230682373, Final Batch Loss: 0.39981895685195923\n",
      "Epoch 744, Loss: 3.400842547416687, Final Batch Loss: 0.5894871950149536\n",
      "Epoch 745, Loss: 3.9885213375091553, Final Batch Loss: 1.160817265510559\n",
      "Epoch 746, Loss: 4.577409863471985, Final Batch Loss: 1.69024658203125\n",
      "Epoch 747, Loss: 4.469522476196289, Final Batch Loss: 1.6504313945770264\n",
      "Epoch 748, Loss: 3.4397983253002167, Final Batch Loss: 0.45608195662498474\n",
      "Epoch 749, Loss: 4.779368996620178, Final Batch Loss: 1.7564210891723633\n",
      "Epoch 750, Loss: 3.9858930110931396, Final Batch Loss: 1.0470845699310303\n",
      "Epoch 751, Loss: 4.106864154338837, Final Batch Loss: 1.154590368270874\n",
      "Epoch 752, Loss: 3.020112916827202, Final Batch Loss: 0.15613697469234467\n",
      "Epoch 753, Loss: 3.2441761195659637, Final Batch Loss: 0.37385866045951843\n",
      "Epoch 754, Loss: 2.928806394338608, Final Batch Loss: 0.12793007493019104\n",
      "Epoch 755, Loss: 2.9999370127916336, Final Batch Loss: 0.15134955942630768\n",
      "Epoch 756, Loss: 3.3656002283096313, Final Batch Loss: 0.47401130199432373\n",
      "Epoch 757, Loss: 5.063391029834747, Final Batch Loss: 2.1883201599121094\n",
      "Epoch 758, Loss: 3.505699098110199, Final Batch Loss: 0.7031899094581604\n",
      "Epoch 759, Loss: 3.49471914768219, Final Batch Loss: 0.562873125076294\n",
      "Epoch 760, Loss: 3.1928772032260895, Final Batch Loss: 0.27459707856178284\n",
      "Epoch 761, Loss: 3.2285526990890503, Final Batch Loss: 0.47116369009017944\n",
      "Epoch 762, Loss: 3.0845091193914413, Final Batch Loss: 0.23242603242397308\n",
      "Epoch 763, Loss: 3.45550799369812, Final Batch Loss: 0.6401170492172241\n",
      "Epoch 764, Loss: 4.210308790206909, Final Batch Loss: 1.4079428911209106\n",
      "Epoch 765, Loss: 4.823174953460693, Final Batch Loss: 1.8749847412109375\n",
      "Epoch 766, Loss: 3.4683690071105957, Final Batch Loss: 0.6346946358680725\n",
      "Epoch 767, Loss: 3.137248083949089, Final Batch Loss: 0.23848555982112885\n",
      "Epoch 768, Loss: 3.3326510787010193, Final Batch Loss: 0.43313008546829224\n",
      "Epoch 769, Loss: 3.453283429145813, Final Batch Loss: 0.6528865694999695\n",
      "Epoch 770, Loss: 3.2333321571350098, Final Batch Loss: 0.4371573328971863\n",
      "Epoch 771, Loss: 4.300356447696686, Final Batch Loss: 1.4401419162750244\n",
      "Epoch 772, Loss: 3.0741795897483826, Final Batch Loss: 0.2585689425468445\n",
      "Epoch 773, Loss: 3.133106768131256, Final Batch Loss: 0.34327536821365356\n",
      "Epoch 774, Loss: 3.0227270871400833, Final Batch Loss: 0.19870586693286896\n",
      "Epoch 775, Loss: 4.2008137702941895, Final Batch Loss: 1.4832885265350342\n",
      "Epoch 776, Loss: 3.2175897359848022, Final Batch Loss: 0.40984445810317993\n",
      "Epoch 777, Loss: 4.929454207420349, Final Batch Loss: 2.118913173675537\n",
      "Epoch 778, Loss: 4.064512550830841, Final Batch Loss: 1.3217713832855225\n",
      "Epoch 779, Loss: 2.9201793372631073, Final Batch Loss: 0.10751184821128845\n",
      "Epoch 780, Loss: 3.2916574478149414, Final Batch Loss: 0.4249672293663025\n",
      "Epoch 781, Loss: 4.991034507751465, Final Batch Loss: 2.1277501583099365\n",
      "Epoch 782, Loss: 3.778601884841919, Final Batch Loss: 0.9353740811347961\n",
      "Epoch 783, Loss: 3.1556566953659058, Final Batch Loss: 0.3776546120643616\n",
      "Epoch 784, Loss: 4.405521750450134, Final Batch Loss: 1.4944148063659668\n",
      "Epoch 785, Loss: 3.6241645216941833, Final Batch Loss: 0.8099927306175232\n",
      "Epoch 786, Loss: 3.5171552896499634, Final Batch Loss: 0.6843674778938293\n",
      "Epoch 787, Loss: 4.9352312088012695, Final Batch Loss: 2.170825481414795\n",
      "Epoch 788, Loss: 3.6768057346343994, Final Batch Loss: 0.9001545906066895\n",
      "Epoch 789, Loss: 4.175808310508728, Final Batch Loss: 1.3415946960449219\n",
      "Epoch 790, Loss: 3.9460291266441345, Final Batch Loss: 1.1136819124221802\n",
      "Epoch 791, Loss: 3.8183804750442505, Final Batch Loss: 0.9758641123771667\n",
      "Epoch 792, Loss: 4.054154694080353, Final Batch Loss: 1.260511040687561\n",
      "Epoch 793, Loss: 3.7938451170921326, Final Batch Loss: 1.0065573453903198\n",
      "Epoch 794, Loss: 3.575847566127777, Final Batch Loss: 0.8338099122047424\n",
      "Epoch 795, Loss: 2.8499923180788755, Final Batch Loss: 0.02409927360713482\n",
      "Epoch 796, Loss: 4.967784345149994, Final Batch Loss: 2.195894956588745\n",
      "Epoch 797, Loss: 3.3941717743873596, Final Batch Loss: 0.571410059928894\n",
      "Epoch 798, Loss: 3.0311382114887238, Final Batch Loss: 0.2772795855998993\n",
      "Epoch 799, Loss: 4.88867324590683, Final Batch Loss: 2.0849223136901855\n",
      "Epoch 800, Loss: 3.4361284971237183, Final Batch Loss: 0.5782803297042847\n",
      "Epoch 801, Loss: 3.388264536857605, Final Batch Loss: 0.5966538786888123\n",
      "Epoch 802, Loss: 4.052843272686005, Final Batch Loss: 1.2728519439697266\n",
      "Epoch 803, Loss: 2.800913155078888, Final Batch Loss: 0.06219291687011719\n",
      "Epoch 804, Loss: 3.2512185275554657, Final Batch Loss: 0.45536836981773376\n",
      "Epoch 805, Loss: 3.126840978860855, Final Batch Loss: 0.3024502694606781\n",
      "Epoch 806, Loss: 4.204220354557037, Final Batch Loss: 1.4044691324234009\n",
      "Epoch 807, Loss: 2.9819626808166504, Final Batch Loss: 0.24920135736465454\n",
      "Epoch 808, Loss: 3.557166814804077, Final Batch Loss: 0.758388340473175\n",
      "Epoch 809, Loss: 3.9164374470710754, Final Batch Loss: 1.1400418281555176\n",
      "Epoch 810, Loss: 3.778401732444763, Final Batch Loss: 1.0706753730773926\n",
      "Epoch 811, Loss: 4.5140169858932495, Final Batch Loss: 1.8077552318572998\n",
      "Epoch 812, Loss: 2.7864187620580196, Final Batch Loss: 0.02499225363135338\n",
      "Epoch 813, Loss: 4.759329736232758, Final Batch Loss: 2.0589218139648438\n",
      "Epoch 814, Loss: 4.231857061386108, Final Batch Loss: 1.4861042499542236\n",
      "Epoch 815, Loss: 3.0533784925937653, Final Batch Loss: 0.2228393852710724\n",
      "Epoch 816, Loss: 3.1783227622509003, Final Batch Loss: 0.4967154562473297\n",
      "Epoch 817, Loss: 3.175269216299057, Final Batch Loss: 0.429899662733078\n",
      "Epoch 818, Loss: 4.505364120006561, Final Batch Loss: 1.7355602979660034\n",
      "Epoch 819, Loss: 2.9205043613910675, Final Batch Loss: 0.25927266478538513\n",
      "Epoch 820, Loss: 4.371883273124695, Final Batch Loss: 1.6770002841949463\n",
      "Epoch 821, Loss: 4.018195331096649, Final Batch Loss: 1.3148623704910278\n",
      "Epoch 822, Loss: 3.636577308177948, Final Batch Loss: 0.8841820359230042\n",
      "Epoch 823, Loss: 3.998020827770233, Final Batch Loss: 1.2158575057983398\n",
      "Epoch 824, Loss: 4.331777930259705, Final Batch Loss: 1.539542317390442\n",
      "Epoch 825, Loss: 3.1194745898246765, Final Batch Loss: 0.3703462481498718\n",
      "Epoch 826, Loss: 3.168300449848175, Final Batch Loss: 0.4652478098869324\n",
      "Epoch 827, Loss: 4.49711138010025, Final Batch Loss: 1.759110689163208\n",
      "Epoch 828, Loss: 3.2884755730628967, Final Batch Loss: 0.607090950012207\n",
      "Epoch 829, Loss: 4.587973773479462, Final Batch Loss: 1.911455512046814\n",
      "Epoch 830, Loss: 3.205850303173065, Final Batch Loss: 0.3986697793006897\n",
      "Epoch 831, Loss: 3.6471760272979736, Final Batch Loss: 1.0015971660614014\n",
      "Epoch 832, Loss: 2.736485429108143, Final Batch Loss: 0.04219544678926468\n",
      "Epoch 833, Loss: 2.94643971323967, Final Batch Loss: 0.27189192175865173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 834, Loss: 3.629215180873871, Final Batch Loss: 0.9998396039009094\n",
      "Epoch 835, Loss: 3.440423905849457, Final Batch Loss: 0.7365843653678894\n",
      "Epoch 836, Loss: 3.196057438850403, Final Batch Loss: 0.5544372200965881\n",
      "Epoch 837, Loss: 3.1193418204784393, Final Batch Loss: 0.43328723311424255\n",
      "Epoch 838, Loss: 3.387991189956665, Final Batch Loss: 0.7301779985427856\n",
      "Epoch 839, Loss: 3.5601871013641357, Final Batch Loss: 0.8937350511550903\n",
      "Epoch 840, Loss: 3.0620683431625366, Final Batch Loss: 0.41722434759140015\n",
      "Epoch 841, Loss: 2.971424788236618, Final Batch Loss: 0.2758035957813263\n",
      "Epoch 842, Loss: 4.476258099079132, Final Batch Loss: 1.782512903213501\n",
      "Epoch 843, Loss: 4.0623539090156555, Final Batch Loss: 1.4487404823303223\n",
      "Epoch 844, Loss: 3.8767098784446716, Final Batch Loss: 1.2785346508026123\n",
      "Epoch 845, Loss: 4.6022573709487915, Final Batch Loss: 1.9857531785964966\n",
      "Epoch 846, Loss: 3.762815237045288, Final Batch Loss: 1.0113723278045654\n",
      "Epoch 847, Loss: 2.775933787226677, Final Batch Loss: 0.03984449803829193\n",
      "Epoch 848, Loss: 3.4626272320747375, Final Batch Loss: 0.7193281650543213\n",
      "Epoch 849, Loss: 4.094436883926392, Final Batch Loss: 1.378638744354248\n",
      "Epoch 850, Loss: 3.2307628393173218, Final Batch Loss: 0.4166930913925171\n",
      "Epoch 851, Loss: 4.898792862892151, Final Batch Loss: 2.1596505641937256\n",
      "Epoch 852, Loss: 4.272907495498657, Final Batch Loss: 1.4360473155975342\n",
      "Epoch 853, Loss: 5.947561502456665, Final Batch Loss: 3.261324644088745\n",
      "Epoch 854, Loss: 2.837427496910095, Final Batch Loss: 0.13252341747283936\n",
      "Epoch 855, Loss: 3.433715522289276, Final Batch Loss: 0.6961959600448608\n",
      "Epoch 856, Loss: 3.0049276649951935, Final Batch Loss: 0.2959584891796112\n",
      "Epoch 857, Loss: 4.567416191101074, Final Batch Loss: 1.8810882568359375\n",
      "Epoch 858, Loss: 2.7371088415384293, Final Batch Loss: 0.06719578802585602\n",
      "Epoch 859, Loss: 2.906498223543167, Final Batch Loss: 0.2514934241771698\n",
      "Epoch 860, Loss: 2.850655123591423, Final Batch Loss: 0.1872604340314865\n",
      "Epoch 861, Loss: 3.0840179324150085, Final Batch Loss: 0.41311365365982056\n",
      "Epoch 862, Loss: 2.9624721705913544, Final Batch Loss: 0.3127972185611725\n",
      "Epoch 863, Loss: 4.217853426933289, Final Batch Loss: 1.5984623432159424\n",
      "Epoch 864, Loss: 4.157061278820038, Final Batch Loss: 1.5395803451538086\n",
      "Epoch 865, Loss: 3.623254895210266, Final Batch Loss: 0.9734922647476196\n",
      "Epoch 866, Loss: 4.098828017711639, Final Batch Loss: 1.482161283493042\n",
      "Epoch 867, Loss: 2.9402916431427, Final Batch Loss: 0.256492555141449\n",
      "Epoch 868, Loss: 5.049932301044464, Final Batch Loss: 2.374699831008911\n",
      "Epoch 869, Loss: 2.8452018350362778, Final Batch Loss: 0.2400423139333725\n",
      "Epoch 870, Loss: 2.849693715572357, Final Batch Loss: 0.03604018688201904\n",
      "Epoch 871, Loss: 4.34026300907135, Final Batch Loss: 1.565777063369751\n",
      "Epoch 872, Loss: 2.7567472346127033, Final Batch Loss: 0.04719280079007149\n",
      "Epoch 873, Loss: 3.7062389850616455, Final Batch Loss: 1.0519529581069946\n",
      "Epoch 874, Loss: 2.772773824632168, Final Batch Loss: 0.04118993133306503\n",
      "Epoch 875, Loss: 5.0869041085243225, Final Batch Loss: 2.4210903644561768\n",
      "Epoch 876, Loss: 2.7331836596131325, Final Batch Loss: 0.07094458490610123\n",
      "Epoch 877, Loss: 3.6794521808624268, Final Batch Loss: 0.8926129937171936\n",
      "Epoch 878, Loss: 4.10276198387146, Final Batch Loss: 1.1846356391906738\n",
      "Epoch 879, Loss: 3.232639878988266, Final Batch Loss: 0.2912231385707855\n",
      "Epoch 880, Loss: 4.111942768096924, Final Batch Loss: 1.1547417640686035\n",
      "Epoch 881, Loss: 3.3035190999507904, Final Batch Loss: 0.2974373996257782\n",
      "Epoch 882, Loss: 3.183657079935074, Final Batch Loss: 0.3088279068470001\n",
      "Epoch 883, Loss: 2.881488863378763, Final Batch Loss: 0.043969158083200455\n",
      "Epoch 884, Loss: 3.629161059856415, Final Batch Loss: 0.8632099628448486\n",
      "Epoch 885, Loss: 4.96989643573761, Final Batch Loss: 2.219668388366699\n",
      "Epoch 886, Loss: 3.781529724597931, Final Batch Loss: 1.087080478668213\n",
      "Epoch 887, Loss: 3.738892376422882, Final Batch Loss: 1.1677545309066772\n",
      "Epoch 888, Loss: 3.232656240463257, Final Batch Loss: 0.4883934259414673\n",
      "Epoch 889, Loss: 2.934266537427902, Final Batch Loss: 0.2726159393787384\n",
      "Epoch 890, Loss: 3.151068687438965, Final Batch Loss: 0.22678709030151367\n",
      "Epoch 891, Loss: 3.7590953707695007, Final Batch Loss: 0.9349058866500854\n",
      "Epoch 892, Loss: 3.823874533176422, Final Batch Loss: 1.061042308807373\n",
      "Epoch 893, Loss: 3.799627184867859, Final Batch Loss: 1.1570603847503662\n",
      "Epoch 894, Loss: 3.0181727409362793, Final Batch Loss: 0.3127860426902771\n",
      "Epoch 895, Loss: 2.684658944606781, Final Batch Loss: 0.06343859434127808\n",
      "Epoch 896, Loss: 3.4396835565567017, Final Batch Loss: 0.8145118951797485\n",
      "Epoch 897, Loss: 3.082307457923889, Final Batch Loss: 0.5283344388008118\n",
      "Epoch 898, Loss: 5.146388053894043, Final Batch Loss: 2.532646417617798\n",
      "Epoch 899, Loss: 2.8952538669109344, Final Batch Loss: 0.2807972729206085\n",
      "Epoch 900, Loss: 3.967783272266388, Final Batch Loss: 1.339351773262024\n",
      "Epoch 901, Loss: 2.929150491952896, Final Batch Loss: 0.2960474193096161\n",
      "Epoch 902, Loss: 2.8307854682207108, Final Batch Loss: 0.11652572453022003\n",
      "Epoch 903, Loss: 3.9661853909492493, Final Batch Loss: 1.1948319673538208\n",
      "Epoch 904, Loss: 2.8501512706279755, Final Batch Loss: 0.2599922716617584\n",
      "Epoch 905, Loss: 3.0904721915721893, Final Batch Loss: 0.49522170424461365\n",
      "Epoch 906, Loss: 3.225310266017914, Final Batch Loss: 0.6853612661361694\n",
      "Epoch 907, Loss: 3.0321250557899475, Final Batch Loss: 0.32461512088775635\n",
      "Epoch 908, Loss: 3.1018075346946716, Final Batch Loss: 0.45336949825286865\n",
      "Epoch 909, Loss: 3.6774824261665344, Final Batch Loss: 1.0802642107009888\n",
      "Epoch 910, Loss: 2.9350927770137787, Final Batch Loss: 0.3327387869358063\n",
      "Epoch 911, Loss: 4.681589722633362, Final Batch Loss: 1.9661250114440918\n",
      "Epoch 912, Loss: 2.7524024844169617, Final Batch Loss: 0.16253650188446045\n",
      "Epoch 913, Loss: 4.239564299583435, Final Batch Loss: 1.6015260219573975\n",
      "Epoch 914, Loss: 3.6570557355880737, Final Batch Loss: 1.0371832847595215\n",
      "Epoch 915, Loss: 3.7894336581230164, Final Batch Loss: 1.2218493223190308\n",
      "Epoch 916, Loss: 3.704179048538208, Final Batch Loss: 0.9054603576660156\n",
      "Epoch 917, Loss: 4.878694593906403, Final Batch Loss: 1.8597358465194702\n",
      "Epoch 918, Loss: 3.125005204230547, Final Batch Loss: 0.05762525275349617\n",
      "Epoch 919, Loss: 3.519688308238983, Final Batch Loss: 0.7772095203399658\n",
      "Epoch 920, Loss: 4.025974750518799, Final Batch Loss: 1.3115525245666504\n",
      "Epoch 921, Loss: 3.0150955617427826, Final Batch Loss: 0.42030230164527893\n",
      "Epoch 922, Loss: 3.0524500906467438, Final Batch Loss: 0.4936569035053253\n",
      "Epoch 923, Loss: 2.7198980897665024, Final Batch Loss: 0.20770816504955292\n",
      "Epoch 924, Loss: 4.279025495052338, Final Batch Loss: 1.7580512762069702\n",
      "Epoch 925, Loss: 3.8858977556228638, Final Batch Loss: 1.2652779817581177\n",
      "Epoch 926, Loss: 2.7732782810926437, Final Batch Loss: 0.15624628961086273\n",
      "Epoch 927, Loss: 2.8435311019420624, Final Batch Loss: 0.35590896010398865\n",
      "Epoch 928, Loss: 4.113484621047974, Final Batch Loss: 1.7052500247955322\n",
      "Epoch 929, Loss: 2.7178941518068314, Final Batch Loss: 0.2060115486383438\n",
      "Epoch 930, Loss: 3.016089290380478, Final Batch Loss: 0.4933291971683502\n",
      "Epoch 931, Loss: 3.1325895190238953, Final Batch Loss: 0.5816164612770081\n",
      "Epoch 932, Loss: 3.695496380329132, Final Batch Loss: 1.0874453783035278\n",
      "Epoch 933, Loss: 3.041171759366989, Final Batch Loss: 0.4423583447933197\n",
      "Epoch 934, Loss: 3.0637190490961075, Final Batch Loss: 0.23944969475269318\n",
      "Epoch 935, Loss: 3.697844624519348, Final Batch Loss: 0.9863743185997009\n",
      "Epoch 936, Loss: 2.930468410253525, Final Batch Loss: 0.31528547406196594\n",
      "Epoch 937, Loss: 3.744110345840454, Final Batch Loss: 1.2554168701171875\n",
      "Epoch 938, Loss: 2.6160606145858765, Final Batch Loss: 0.10449361801147461\n",
      "Epoch 939, Loss: 2.6544610112905502, Final Batch Loss: 0.1686156839132309\n",
      "Epoch 940, Loss: 3.4804510474205017, Final Batch Loss: 0.9635265469551086\n",
      "Epoch 941, Loss: 2.9129100143909454, Final Batch Loss: 0.38970932364463806\n",
      "Epoch 942, Loss: 2.6924661844968796, Final Batch Loss: 0.1919495314359665\n",
      "Epoch 943, Loss: 2.9962505102157593, Final Batch Loss: 0.4118182063102722\n",
      "Epoch 944, Loss: 2.7143432646989822, Final Batch Loss: 0.2121375948190689\n",
      "Epoch 945, Loss: 3.548929989337921, Final Batch Loss: 1.1361583471298218\n",
      "Epoch 946, Loss: 2.81439408659935, Final Batch Loss: 0.27687135338783264\n",
      "Epoch 947, Loss: 2.9767168760299683, Final Batch Loss: 0.564875066280365\n",
      "Epoch 948, Loss: 2.704595297574997, Final Batch Loss: 0.07746019959449768\n",
      "Epoch 949, Loss: 4.540913760662079, Final Batch Loss: 1.8455700874328613\n",
      "Epoch 950, Loss: 3.16790634393692, Final Batch Loss: 0.44234800338745117\n",
      "Epoch 951, Loss: 3.124054789543152, Final Batch Loss: 0.4741218090057373\n",
      "Epoch 952, Loss: 3.33697909116745, Final Batch Loss: 0.8320527076721191\n",
      "Epoch 953, Loss: 2.9752219915390015, Final Batch Loss: 0.5291140675544739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954, Loss: 3.611264169216156, Final Batch Loss: 1.050209403038025\n",
      "Epoch 955, Loss: 3.51791250705719, Final Batch Loss: 1.0129578113555908\n",
      "Epoch 956, Loss: 2.8872789442539215, Final Batch Loss: 0.42702409625053406\n",
      "Epoch 957, Loss: 3.6223517656326294, Final Batch Loss: 1.048985242843628\n",
      "Epoch 958, Loss: 2.818591818213463, Final Batch Loss: 0.24411635100841522\n",
      "Epoch 959, Loss: 4.502300500869751, Final Batch Loss: 2.0334389209747314\n",
      "Epoch 960, Loss: 2.674694739282131, Final Batch Loss: 0.07999839633703232\n",
      "Epoch 961, Loss: 2.8152090162038803, Final Batch Loss: 0.127237007021904\n",
      "Epoch 962, Loss: 3.4127336740493774, Final Batch Loss: 0.7321314811706543\n",
      "Epoch 963, Loss: 2.7348642796278, Final Batch Loss: 0.12062053382396698\n",
      "Epoch 964, Loss: 2.8719788193702698, Final Batch Loss: 0.2837092876434326\n",
      "Epoch 965, Loss: 3.486292064189911, Final Batch Loss: 0.912057101726532\n",
      "Epoch 966, Loss: 3.09354430437088, Final Batch Loss: 0.5374994277954102\n",
      "Epoch 967, Loss: 4.020536482334137, Final Batch Loss: 1.5016851425170898\n",
      "Epoch 968, Loss: 2.572809174656868, Final Batch Loss: 0.11409963667392731\n",
      "Epoch 969, Loss: 2.6019543260335922, Final Batch Loss: 0.1285659521818161\n",
      "Epoch 970, Loss: 2.6365888118743896, Final Batch Loss: 0.2202979326248169\n",
      "Epoch 971, Loss: 3.1396199464797974, Final Batch Loss: 0.6753278374671936\n",
      "Epoch 972, Loss: 2.682604655623436, Final Batch Loss: 0.23010455071926117\n",
      "Epoch 973, Loss: 2.8170299232006073, Final Batch Loss: 0.33706972002983093\n",
      "Epoch 974, Loss: 2.7330377995967865, Final Batch Loss: 0.17086568474769592\n",
      "Epoch 975, Loss: 3.218051254749298, Final Batch Loss: 0.6570696234703064\n",
      "Epoch 976, Loss: 3.1627217531204224, Final Batch Loss: 0.7145583033561707\n",
      "Epoch 977, Loss: 2.555531769990921, Final Batch Loss: 0.1336517035961151\n",
      "Epoch 978, Loss: 6.328157901763916, Final Batch Loss: 3.8426647186279297\n",
      "Epoch 979, Loss: 3.515161395072937, Final Batch Loss: 1.010542631149292\n",
      "Epoch 980, Loss: 3.939965546131134, Final Batch Loss: 1.548105239868164\n",
      "Epoch 981, Loss: 4.881446957588196, Final Batch Loss: 2.434206247329712\n",
      "Epoch 982, Loss: 3.66978257894516, Final Batch Loss: 1.2089143991470337\n",
      "Epoch 983, Loss: 2.5242593362927437, Final Batch Loss: 0.06642384082078934\n",
      "Epoch 984, Loss: 2.6102830469608307, Final Batch Loss: 0.14642873406410217\n",
      "Epoch 985, Loss: 2.896058678627014, Final Batch Loss: 0.4435022473335266\n",
      "Epoch 986, Loss: 2.813461184501648, Final Batch Loss: 0.3441276550292969\n",
      "Epoch 987, Loss: 3.772003710269928, Final Batch Loss: 1.3069751262664795\n",
      "Epoch 988, Loss: 4.551095426082611, Final Batch Loss: 2.117265224456787\n",
      "Epoch 989, Loss: 3.141269326210022, Final Batch Loss: 0.6704068183898926\n",
      "Epoch 990, Loss: 3.685689687728882, Final Batch Loss: 1.2226638793945312\n",
      "Epoch 991, Loss: 3.6987898349761963, Final Batch Loss: 1.1566028594970703\n",
      "Epoch 992, Loss: 2.5006634667515755, Final Batch Loss: 0.07642162591218948\n",
      "Epoch 993, Loss: 3.4703750610351562, Final Batch Loss: 1.0764051675796509\n",
      "Epoch 994, Loss: 2.6178296357393265, Final Batch Loss: 0.1892886906862259\n",
      "Epoch 995, Loss: 3.5712098479270935, Final Batch Loss: 1.2065709829330444\n",
      "Epoch 996, Loss: 4.026153802871704, Final Batch Loss: 1.617468237876892\n",
      "Epoch 997, Loss: 3.7129213213920593, Final Batch Loss: 1.29978346824646\n",
      "Epoch 998, Loss: 2.898026317358017, Final Batch Loss: 0.4403892457485199\n",
      "Epoch 999, Loss: 2.892543762922287, Final Batch Loss: 0.4215979278087616\n",
      "Epoch 1000, Loss: 2.6511925756931305, Final Batch Loss: 0.1786029040813446\n",
      "Epoch 1001, Loss: 3.6297802329063416, Final Batch Loss: 1.1782608032226562\n",
      "Epoch 1002, Loss: 2.614179965108633, Final Batch Loss: 0.052516575902700424\n",
      "Epoch 1003, Loss: 2.646202504634857, Final Batch Loss: 0.17628192901611328\n",
      "Epoch 1004, Loss: 2.47938921302557, Final Batch Loss: 0.04624750465154648\n",
      "Epoch 1005, Loss: 3.8628531098365784, Final Batch Loss: 1.4370126724243164\n",
      "Epoch 1006, Loss: 3.738592505455017, Final Batch Loss: 1.32939612865448\n",
      "Epoch 1007, Loss: 2.466881789267063, Final Batch Loss: 0.05442247539758682\n",
      "Epoch 1008, Loss: 2.8820179402828217, Final Batch Loss: 0.4056570827960968\n",
      "Epoch 1009, Loss: 2.382494330406189, Final Batch Loss: 0.027607858180999756\n",
      "Epoch 1010, Loss: 3.0517120957374573, Final Batch Loss: 0.662523627281189\n",
      "Epoch 1011, Loss: 3.6375367045402527, Final Batch Loss: 1.1813279390335083\n",
      "Epoch 1012, Loss: 2.7542048394680023, Final Batch Loss: 0.38375112414360046\n",
      "Epoch 1013, Loss: 2.820741981267929, Final Batch Loss: 0.49008098244667053\n",
      "Epoch 1014, Loss: 4.26021546125412, Final Batch Loss: 1.8909001350402832\n",
      "Epoch 1015, Loss: 2.8493934273719788, Final Batch Loss: 0.5110999345779419\n",
      "Epoch 1016, Loss: 2.4802008979022503, Final Batch Loss: 0.05475975200533867\n",
      "Epoch 1017, Loss: 3.3358888030052185, Final Batch Loss: 0.8845512866973877\n",
      "Epoch 1018, Loss: 4.977862238883972, Final Batch Loss: 2.4780263900756836\n",
      "Epoch 1019, Loss: 3.3212903141975403, Final Batch Loss: 0.8787278532981873\n",
      "Epoch 1020, Loss: 2.6255572885274887, Final Batch Loss: 0.1571563333272934\n",
      "Epoch 1021, Loss: 3.3190194964408875, Final Batch Loss: 0.9196571707725525\n",
      "Epoch 1022, Loss: 3.4905800223350525, Final Batch Loss: 0.964163064956665\n",
      "Epoch 1023, Loss: 3.1550204753875732, Final Batch Loss: 0.7249016165733337\n",
      "Epoch 1024, Loss: 2.4370421431958675, Final Batch Loss: 0.06125631555914879\n",
      "Epoch 1025, Loss: 3.405497133731842, Final Batch Loss: 1.0498762130737305\n",
      "Epoch 1026, Loss: 2.7641618847846985, Final Batch Loss: 0.3241317868232727\n",
      "Epoch 1027, Loss: 2.5582429692149162, Final Batch Loss: 0.108741395175457\n",
      "Epoch 1028, Loss: 5.299599707126617, Final Batch Loss: 2.9707140922546387\n",
      "Epoch 1029, Loss: 4.512409448623657, Final Batch Loss: 2.0874428749084473\n",
      "Epoch 1030, Loss: 3.160966217517853, Final Batch Loss: 0.8019970059394836\n",
      "Epoch 1031, Loss: 3.673542618751526, Final Batch Loss: 1.277602195739746\n",
      "Epoch 1032, Loss: 2.7568430304527283, Final Batch Loss: 0.357013463973999\n",
      "Epoch 1033, Loss: 3.2563244700431824, Final Batch Loss: 0.808148205280304\n",
      "Epoch 1034, Loss: 2.773515909910202, Final Batch Loss: 0.3585197627544403\n",
      "Epoch 1035, Loss: 3.0490375757217407, Final Batch Loss: 0.6121357083320618\n",
      "Epoch 1036, Loss: 3.949007034301758, Final Batch Loss: 1.4834014177322388\n",
      "Epoch 1037, Loss: 4.965322494506836, Final Batch Loss: 2.462745189666748\n",
      "Epoch 1038, Loss: 2.6826390624046326, Final Batch Loss: 0.22747641801834106\n",
      "Epoch 1039, Loss: 3.8912466764450073, Final Batch Loss: 1.4507099390029907\n",
      "Epoch 1040, Loss: 4.311172842979431, Final Batch Loss: 1.7945215702056885\n",
      "Epoch 1041, Loss: 4.300735414028168, Final Batch Loss: 1.8042595386505127\n",
      "Epoch 1042, Loss: 2.5953557416796684, Final Batch Loss: 0.11512266844511032\n",
      "Epoch 1043, Loss: 2.6290902122855186, Final Batch Loss: 0.08902855962514877\n",
      "Epoch 1044, Loss: 2.7559421062469482, Final Batch Loss: 0.344407320022583\n",
      "Epoch 1045, Loss: 3.1218296885490417, Final Batch Loss: 0.7354336977005005\n",
      "Epoch 1046, Loss: 3.5376181602478027, Final Batch Loss: 1.086925745010376\n",
      "Epoch 1047, Loss: 2.3602252788841724, Final Batch Loss: 0.012713689357042313\n",
      "Epoch 1048, Loss: 2.9987226724624634, Final Batch Loss: 0.4957835078239441\n",
      "Epoch 1049, Loss: 2.6592190116643906, Final Batch Loss: 0.10265861451625824\n",
      "Epoch 1050, Loss: 2.810096263885498, Final Batch Loss: 0.3688696026802063\n",
      "Epoch 1051, Loss: 2.4073899360373616, Final Batch Loss: 0.014085051603615284\n",
      "Epoch 1052, Loss: 2.507860094308853, Final Batch Loss: 0.14185687899589539\n",
      "Epoch 1053, Loss: 2.7582505345344543, Final Batch Loss: 0.40078938007354736\n",
      "Epoch 1054, Loss: 2.5942853689193726, Final Batch Loss: 0.29587382078170776\n",
      "Epoch 1055, Loss: 2.4390320405364037, Final Batch Loss: 0.04609110206365585\n",
      "Epoch 1056, Loss: 2.5758946985006332, Final Batch Loss: 0.18639551103115082\n",
      "Epoch 1057, Loss: 4.721038401126862, Final Batch Loss: 2.2946982383728027\n",
      "Epoch 1058, Loss: 2.9358014464378357, Final Batch Loss: 0.5935366749763489\n",
      "Epoch 1059, Loss: 2.9958220720291138, Final Batch Loss: 0.5041919350624084\n",
      "Epoch 1060, Loss: 2.9086883068084717, Final Batch Loss: 0.3235326409339905\n",
      "Epoch 1061, Loss: 3.650482416152954, Final Batch Loss: 1.2408391237258911\n",
      "Epoch 1062, Loss: 2.6639948338270187, Final Batch Loss: 0.1826717108488083\n",
      "Epoch 1063, Loss: 3.88508677482605, Final Batch Loss: 1.4841561317443848\n",
      "Epoch 1064, Loss: 2.4549309611320496, Final Batch Loss: 0.10855180025100708\n",
      "Epoch 1065, Loss: 2.933136522769928, Final Batch Loss: 0.553713321685791\n",
      "Epoch 1066, Loss: 4.392976880073547, Final Batch Loss: 1.9368261098861694\n",
      "Epoch 1067, Loss: 3.3568501472473145, Final Batch Loss: 0.9558220505714417\n",
      "Epoch 1068, Loss: 2.341249536490068, Final Batch Loss: 0.000832568621262908\n",
      "Epoch 1069, Loss: 2.890020966529846, Final Batch Loss: 0.4938671588897705\n",
      "Epoch 1070, Loss: 2.5835708528757095, Final Batch Loss: 0.15683670341968536\n",
      "Epoch 1071, Loss: 4.5082409381866455, Final Batch Loss: 2.068726062774658\n",
      "Epoch 1072, Loss: 3.2580379247665405, Final Batch Loss: 0.7774404883384705\n",
      "Epoch 1073, Loss: 3.670308470726013, Final Batch Loss: 1.2756092548370361\n",
      "Epoch 1074, Loss: 2.4970842897892, Final Batch Loss: 0.13368579745292664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1075, Loss: 2.941318929195404, Final Batch Loss: 0.5345057845115662\n",
      "Epoch 1076, Loss: 4.193578720092773, Final Batch Loss: 1.7802469730377197\n",
      "Epoch 1077, Loss: 4.677170038223267, Final Batch Loss: 2.256727695465088\n",
      "Epoch 1078, Loss: 4.0644989013671875, Final Batch Loss: 1.7730664014816284\n",
      "Epoch 1079, Loss: 2.365680642426014, Final Batch Loss: 0.03651750832796097\n",
      "Epoch 1080, Loss: 4.093279480934143, Final Batch Loss: 1.7294881343841553\n",
      "Epoch 1081, Loss: 2.5365237295627594, Final Batch Loss: 0.1726801097393036\n",
      "Epoch 1082, Loss: 2.339376036077738, Final Batch Loss: 0.023196760565042496\n",
      "Epoch 1083, Loss: 3.23993843793869, Final Batch Loss: 0.8189569711685181\n",
      "Epoch 1084, Loss: 2.641372337937355, Final Batch Loss: 0.22009803354740143\n",
      "Epoch 1085, Loss: 4.4773754477500916, Final Batch Loss: 2.0517592430114746\n",
      "Epoch 1086, Loss: 2.6855815052986145, Final Batch Loss: 0.33041244745254517\n",
      "Epoch 1087, Loss: 2.450980145484209, Final Batch Loss: 0.05795987322926521\n",
      "Epoch 1088, Loss: 2.41759030893445, Final Batch Loss: 0.021325457841157913\n",
      "Epoch 1089, Loss: 2.4794308617711067, Final Batch Loss: 0.09685320407152176\n",
      "Epoch 1090, Loss: 5.800054669380188, Final Batch Loss: 3.3309545516967773\n",
      "Epoch 1091, Loss: 2.4378651082515717, Final Batch Loss: 0.0900326669216156\n",
      "Epoch 1092, Loss: 2.74376580119133, Final Batch Loss: 0.37424203753471375\n",
      "Epoch 1093, Loss: 3.3311997056007385, Final Batch Loss: 0.9479477405548096\n",
      "Epoch 1094, Loss: 3.671444356441498, Final Batch Loss: 1.3049113750457764\n",
      "Epoch 1095, Loss: 3.318120777606964, Final Batch Loss: 0.9984252452850342\n",
      "Epoch 1096, Loss: 2.5444592237472534, Final Batch Loss: 0.23483526706695557\n",
      "Epoch 1097, Loss: 2.467522121965885, Final Batch Loss: 0.07558945566415787\n",
      "Epoch 1098, Loss: 2.51783487200737, Final Batch Loss: 0.167714923620224\n",
      "Epoch 1099, Loss: 2.4136220179498196, Final Batch Loss: 0.061153825372457504\n",
      "Epoch 1100, Loss: 2.4026728355675004, Final Batch Loss: 0.0006783091812394559\n",
      "Epoch 1101, Loss: 2.3872377797961235, Final Batch Loss: 0.05765687674283981\n",
      "Epoch 1102, Loss: 2.718850553035736, Final Batch Loss: 0.39862608909606934\n",
      "Epoch 1103, Loss: 2.6922928988933563, Final Batch Loss: 0.3391543924808502\n",
      "Epoch 1104, Loss: 2.3040394075214863, Final Batch Loss: 0.02284424379467964\n",
      "Epoch 1105, Loss: 3.5608978271484375, Final Batch Loss: 1.234494686126709\n",
      "Epoch 1106, Loss: 2.360582150518894, Final Batch Loss: 0.05122152715921402\n",
      "Epoch 1107, Loss: 3.328605353832245, Final Batch Loss: 0.9720966815948486\n",
      "Epoch 1108, Loss: 2.505462110042572, Final Batch Loss: 0.10793238878250122\n",
      "Epoch 1109, Loss: 2.6813915967941284, Final Batch Loss: 0.30673032999038696\n",
      "Epoch 1110, Loss: 3.30727219581604, Final Batch Loss: 1.0037680864334106\n",
      "Epoch 1111, Loss: 2.492426797747612, Final Batch Loss: 0.15532349050045013\n",
      "Epoch 1112, Loss: 3.780203342437744, Final Batch Loss: 1.3367990255355835\n",
      "Epoch 1113, Loss: 2.8253444135189056, Final Batch Loss: 0.49012473225593567\n",
      "Epoch 1114, Loss: 2.606107383966446, Final Batch Loss: 0.2372010052204132\n",
      "Epoch 1115, Loss: 2.4281646460294724, Final Batch Loss: 0.13535402715206146\n",
      "Epoch 1116, Loss: 2.4691817089915276, Final Batch Loss: 0.05693315714597702\n",
      "Epoch 1117, Loss: 2.7592742443084717, Final Batch Loss: 0.41434913873672485\n",
      "Epoch 1118, Loss: 2.406761273741722, Final Batch Loss: 0.028358206152915955\n",
      "Epoch 1119, Loss: 2.8186608254909515, Final Batch Loss: 0.4762187898159027\n",
      "Epoch 1120, Loss: 3.729633867740631, Final Batch Loss: 1.4202135801315308\n",
      "Epoch 1121, Loss: 2.782669186592102, Final Batch Loss: 0.3938611149787903\n",
      "Epoch 1122, Loss: 4.112211108207703, Final Batch Loss: 1.7983996868133545\n",
      "Epoch 1123, Loss: 2.6710763722658157, Final Batch Loss: 0.24911876022815704\n",
      "Epoch 1124, Loss: 2.5514460057020187, Final Batch Loss: 0.18888907134532928\n",
      "Epoch 1125, Loss: 2.4808967858552933, Final Batch Loss: 0.07276506721973419\n",
      "Epoch 1126, Loss: 2.5759942829608917, Final Batch Loss: 0.2755105793476105\n",
      "Epoch 1127, Loss: 2.692853033542633, Final Batch Loss: 0.30338454246520996\n",
      "Epoch 1128, Loss: 2.4634651839733124, Final Batch Loss: 0.17284980416297913\n",
      "Epoch 1129, Loss: 3.2596457600593567, Final Batch Loss: 0.8960977792739868\n",
      "Epoch 1130, Loss: 4.403314888477325, Final Batch Loss: 2.0344576835632324\n",
      "Epoch 1131, Loss: 2.311771873384714, Final Batch Loss: 0.034864071756601334\n",
      "Epoch 1132, Loss: 3.526378631591797, Final Batch Loss: 1.2216113805770874\n",
      "Epoch 1133, Loss: 3.1983203291893005, Final Batch Loss: 0.8376311659812927\n",
      "Epoch 1134, Loss: 2.491837667301297, Final Batch Loss: 0.01688532717525959\n",
      "Epoch 1135, Loss: 3.0317219495773315, Final Batch Loss: 0.598922073841095\n",
      "Epoch 1136, Loss: 2.414772294461727, Final Batch Loss: 0.09543677419424057\n",
      "Epoch 1137, Loss: 3.290923058986664, Final Batch Loss: 1.0062240362167358\n",
      "Epoch 1138, Loss: 4.257684230804443, Final Batch Loss: 1.9273428916931152\n",
      "Epoch 1139, Loss: 2.331381056457758, Final Batch Loss: 0.06178877130150795\n",
      "Epoch 1140, Loss: 3.657171308994293, Final Batch Loss: 1.4067643880844116\n",
      "Epoch 1141, Loss: 2.8060141801834106, Final Batch Loss: 0.4569810628890991\n",
      "Epoch 1142, Loss: 2.9916862845420837, Final Batch Loss: 0.6422210335731506\n",
      "Epoch 1143, Loss: 2.980052947998047, Final Batch Loss: 0.5743321776390076\n",
      "Epoch 1144, Loss: 2.494270145893097, Final Batch Loss: 0.21274662017822266\n",
      "Epoch 1145, Loss: 2.339442193508148, Final Batch Loss: 0.09435075521469116\n",
      "Epoch 1146, Loss: 2.4184954166412354, Final Batch Loss: 0.16136914491653442\n",
      "Epoch 1147, Loss: 4.226726472377777, Final Batch Loss: 1.9178298711776733\n",
      "Epoch 1148, Loss: 3.305050790309906, Final Batch Loss: 1.0338900089263916\n",
      "Epoch 1149, Loss: 4.461956024169922, Final Batch Loss: 2.1381356716156006\n",
      "Epoch 1150, Loss: 2.5833462923765182, Final Batch Loss: 0.17064307630062103\n",
      "Epoch 1151, Loss: 3.2246976494789124, Final Batch Loss: 0.7862116694450378\n",
      "Epoch 1152, Loss: 4.185847282409668, Final Batch Loss: 1.7416441440582275\n",
      "Epoch 1153, Loss: 2.6371876895427704, Final Batch Loss: 0.30679383873939514\n",
      "Epoch 1154, Loss: 4.20206356048584, Final Batch Loss: 1.7940665483474731\n",
      "Epoch 1155, Loss: 3.033441960811615, Final Batch Loss: 0.6579577326774597\n",
      "Epoch 1156, Loss: 2.6561244130134583, Final Batch Loss: 0.28848010301589966\n",
      "Epoch 1157, Loss: 3.1869054436683655, Final Batch Loss: 0.8866413235664368\n",
      "Epoch 1158, Loss: 3.012111246585846, Final Batch Loss: 0.6340363025665283\n",
      "Epoch 1159, Loss: 2.5553584322333336, Final Batch Loss: 0.05078323930501938\n",
      "Epoch 1160, Loss: 4.1558877825737, Final Batch Loss: 1.6229000091552734\n",
      "Epoch 1161, Loss: 2.652088224887848, Final Batch Loss: 0.016992688179016113\n",
      "Epoch 1162, Loss: 2.8099603354930878, Final Batch Loss: 0.2903824746608734\n",
      "Epoch 1163, Loss: 2.6023646742105484, Final Batch Loss: 0.15790756046772003\n",
      "Epoch 1164, Loss: 3.4115939140319824, Final Batch Loss: 1.0582187175750732\n",
      "Epoch 1165, Loss: 3.492023766040802, Final Batch Loss: 1.2080657482147217\n",
      "Epoch 1166, Loss: 2.5938974916934967, Final Batch Loss: 0.26728835701942444\n",
      "Epoch 1167, Loss: 3.9722328782081604, Final Batch Loss: 1.737037181854248\n",
      "Epoch 1168, Loss: 3.4069440364837646, Final Batch Loss: 1.1337186098098755\n",
      "Epoch 1169, Loss: 4.466226279735565, Final Batch Loss: 2.1831297874450684\n",
      "Epoch 1170, Loss: 2.3066731709986925, Final Batch Loss: 0.025906624272465706\n",
      "Epoch 1171, Loss: 3.0573389530181885, Final Batch Loss: 0.75514155626297\n",
      "Epoch 1172, Loss: 2.3300857059657574, Final Batch Loss: 0.019173990935087204\n",
      "Epoch 1173, Loss: 3.397461175918579, Final Batch Loss: 1.1145853996276855\n",
      "Epoch 1174, Loss: 2.5198662132024765, Final Batch Loss: 0.1614692658185959\n",
      "Epoch 1175, Loss: 3.1957250833511353, Final Batch Loss: 0.8152068853378296\n",
      "Epoch 1176, Loss: 3.85749089717865, Final Batch Loss: 1.6583569049835205\n",
      "Epoch 1177, Loss: 3.2913854122161865, Final Batch Loss: 1.012756109237671\n",
      "Epoch 1178, Loss: 3.8372244834899902, Final Batch Loss: 1.598313808441162\n",
      "Epoch 1179, Loss: 3.4386593103408813, Final Batch Loss: 1.2272288799285889\n",
      "Epoch 1180, Loss: 2.303607415407896, Final Batch Loss: 0.05458153411746025\n",
      "Epoch 1181, Loss: 3.789344906806946, Final Batch Loss: 1.575797200202942\n",
      "Epoch 1182, Loss: 4.053089439868927, Final Batch Loss: 1.7329843044281006\n",
      "Epoch 1183, Loss: 3.254958987236023, Final Batch Loss: 0.9776052832603455\n",
      "Epoch 1184, Loss: 2.8416357934474945, Final Batch Loss: 0.26840224862098694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1185, Loss: 3.7271509170532227, Final Batch Loss: 0.9836517572402954\n",
      "Epoch 1186, Loss: 2.5644237918313593, Final Batch Loss: 0.0030109805520623922\n",
      "Epoch 1187, Loss: 2.564254719763994, Final Batch Loss: 0.027371961623430252\n",
      "Epoch 1188, Loss: 2.6198489665985107, Final Batch Loss: 0.32901012897491455\n",
      "Epoch 1189, Loss: 2.4093806073069572, Final Batch Loss: 0.11645644158124924\n",
      "Epoch 1190, Loss: 2.51530185341835, Final Batch Loss: 0.2860663831233978\n",
      "Epoch 1191, Loss: 2.8110861778259277, Final Batch Loss: 0.5652331113815308\n",
      "Epoch 1192, Loss: 2.7286779582500458, Final Batch Loss: 0.4731541574001312\n",
      "Epoch 1193, Loss: 2.357368990778923, Final Batch Loss: 0.099199578166008\n",
      "Epoch 1194, Loss: 3.5832542181015015, Final Batch Loss: 1.4379462003707886\n",
      "Epoch 1195, Loss: 3.883566975593567, Final Batch Loss: 1.7069435119628906\n",
      "Epoch 1196, Loss: 3.2894323468208313, Final Batch Loss: 1.0438158512115479\n",
      "Epoch 1197, Loss: 2.3981731235980988, Final Batch Loss: 0.1392333209514618\n",
      "Epoch 1198, Loss: 3.500662863254547, Final Batch Loss: 1.2688652276992798\n",
      "Epoch 1199, Loss: 2.609849840402603, Final Batch Loss: 0.2504216134548187\n",
      "Epoch 1200, Loss: 3.1105188727378845, Final Batch Loss: 0.9061793088912964\n",
      "Epoch 1201, Loss: 2.5761417150497437, Final Batch Loss: 0.3068331480026245\n",
      "Epoch 1202, Loss: 2.443118989467621, Final Batch Loss: 0.17305296659469604\n",
      "Epoch 1203, Loss: 2.4782180935144424, Final Batch Loss: 0.17868836224079132\n",
      "Epoch 1204, Loss: 3.694406032562256, Final Batch Loss: 1.4035837650299072\n",
      "Epoch 1205, Loss: 2.21949552744627, Final Batch Loss: 0.010352365672588348\n",
      "Epoch 1206, Loss: 2.4515077024698257, Final Batch Loss: 0.18717868626117706\n",
      "Epoch 1207, Loss: 3.3791903853416443, Final Batch Loss: 1.1047728061676025\n",
      "Epoch 1208, Loss: 2.258904593065381, Final Batch Loss: 0.02051784284412861\n",
      "Epoch 1209, Loss: 2.711493134498596, Final Batch Loss: 0.41569292545318604\n",
      "Epoch 1210, Loss: 2.2076255274005234, Final Batch Loss: 0.006675798911601305\n",
      "Epoch 1211, Loss: 3.7155069708824158, Final Batch Loss: 1.5132794380187988\n",
      "Epoch 1212, Loss: 3.281919300556183, Final Batch Loss: 1.0768136978149414\n",
      "Epoch 1213, Loss: 5.504260241985321, Final Batch Loss: 3.2728185653686523\n",
      "Epoch 1214, Loss: 2.2452385876677, Final Batch Loss: 0.00017021637177094817\n",
      "Epoch 1215, Loss: 3.484036922454834, Final Batch Loss: 1.1696447134017944\n",
      "Epoch 1216, Loss: 2.365390256047249, Final Batch Loss: 0.0769919902086258\n",
      "Epoch 1217, Loss: 6.025934994220734, Final Batch Loss: 3.672771453857422\n",
      "Epoch 1218, Loss: 4.60705840587616, Final Batch Loss: 2.180675506591797\n",
      "Epoch 1219, Loss: 3.690305173397064, Final Batch Loss: 1.2757601737976074\n",
      "Epoch 1220, Loss: 3.658012866973877, Final Batch Loss: 1.2647349834442139\n",
      "Epoch 1221, Loss: 3.6596725583076477, Final Batch Loss: 1.2607288360595703\n",
      "Epoch 1222, Loss: 2.2830375656485558, Final Batch Loss: 0.03645613044500351\n",
      "Epoch 1223, Loss: 2.705453872680664, Final Batch Loss: 0.4757230877876282\n",
      "Epoch 1224, Loss: 4.101783037185669, Final Batch Loss: 1.776777982711792\n",
      "Epoch 1225, Loss: 2.766759932041168, Final Batch Loss: 0.47680747509002686\n",
      "Epoch 1226, Loss: 2.5326952189207077, Final Batch Loss: 0.18197552859783173\n",
      "Epoch 1227, Loss: 3.1685569286346436, Final Batch Loss: 0.7823343873023987\n",
      "Epoch 1228, Loss: 2.553494080901146, Final Batch Loss: 0.17222623527050018\n",
      "Epoch 1229, Loss: 3.140384256839752, Final Batch Loss: 0.8650197982788086\n",
      "Epoch 1230, Loss: 3.034444212913513, Final Batch Loss: 0.7403872609138489\n",
      "Epoch 1231, Loss: 3.086791157722473, Final Batch Loss: 0.7450311779975891\n",
      "Epoch 1232, Loss: 3.915966808795929, Final Batch Loss: 1.2853091955184937\n",
      "Epoch 1233, Loss: 2.872700348496437, Final Batch Loss: 0.1747995764017105\n",
      "Epoch 1234, Loss: 2.994921565055847, Final Batch Loss: 0.5669048428535461\n",
      "Epoch 1235, Loss: 3.9149674773216248, Final Batch Loss: 1.539870023727417\n",
      "Epoch 1236, Loss: 2.8572856783866882, Final Batch Loss: 0.5063762068748474\n",
      "Epoch 1237, Loss: 4.0123207569122314, Final Batch Loss: 1.6847240924835205\n",
      "Epoch 1238, Loss: 3.030444920063019, Final Batch Loss: 0.6392702460289001\n",
      "Epoch 1239, Loss: 3.5705552101135254, Final Batch Loss: 1.16788649559021\n",
      "Epoch 1240, Loss: 3.47059565782547, Final Batch Loss: 1.076954960823059\n",
      "Epoch 1241, Loss: 3.897454023361206, Final Batch Loss: 1.565859317779541\n",
      "Epoch 1242, Loss: 3.487838327884674, Final Batch Loss: 1.2001453638076782\n",
      "Epoch 1243, Loss: 2.929418206214905, Final Batch Loss: 0.6432991623878479\n",
      "Epoch 1244, Loss: 3.3015920519828796, Final Batch Loss: 1.037992238998413\n",
      "Epoch 1245, Loss: 3.18776673078537, Final Batch Loss: 0.9517580270767212\n",
      "Epoch 1246, Loss: 4.309130668640137, Final Batch Loss: 2.125321865081787\n",
      "Epoch 1247, Loss: 3.3734625577926636, Final Batch Loss: 1.076650857925415\n",
      "Epoch 1248, Loss: 2.5221096575260162, Final Batch Loss: 0.30870428681373596\n",
      "Epoch 1249, Loss: 3.1127155423164368, Final Batch Loss: 0.8463860750198364\n",
      "Epoch 1250, Loss: 3.348907232284546, Final Batch Loss: 1.15419340133667\n",
      "Epoch 1251, Loss: 2.4847082793712616, Final Batch Loss: 0.16629794239997864\n",
      "Epoch 1252, Loss: 2.2181633189320564, Final Batch Loss: 0.02488679438829422\n",
      "Epoch 1253, Loss: 2.8222904801368713, Final Batch Loss: 0.5525035262107849\n",
      "Epoch 1254, Loss: 2.2149697199929506, Final Batch Loss: 0.002919580088928342\n",
      "Epoch 1255, Loss: 2.286074801813811, Final Batch Loss: 0.0024949158541858196\n",
      "Epoch 1256, Loss: 2.372814416885376, Final Batch Loss: 0.1069750189781189\n",
      "Epoch 1257, Loss: 6.7725828886032104, Final Batch Loss: 4.5167083740234375\n",
      "Epoch 1258, Loss: 3.075728952884674, Final Batch Loss: 0.7011826634407043\n",
      "Epoch 1259, Loss: 2.650442659854889, Final Batch Loss: 0.031364262104034424\n",
      "Epoch 1260, Loss: 3.733012080192566, Final Batch Loss: 1.0394083261489868\n",
      "Epoch 1261, Loss: 3.7054420709609985, Final Batch Loss: 1.0698933601379395\n",
      "Epoch 1262, Loss: 4.333815276622772, Final Batch Loss: 1.6316554546356201\n",
      "Epoch 1263, Loss: 2.6980173885822296, Final Batch Loss: 0.23756137490272522\n",
      "Epoch 1264, Loss: 3.6239500045776367, Final Batch Loss: 1.1562249660491943\n",
      "Epoch 1265, Loss: 2.6864626705646515, Final Batch Loss: 0.25459107756614685\n",
      "Epoch 1266, Loss: 3.1092997789382935, Final Batch Loss: 0.6803686022758484\n",
      "Epoch 1267, Loss: 3.6089678406715393, Final Batch Loss: 1.307793378829956\n",
      "Epoch 1268, Loss: 4.115044295787811, Final Batch Loss: 1.7465393543243408\n",
      "Epoch 1269, Loss: 3.797184109687805, Final Batch Loss: 1.1968331336975098\n",
      "Epoch 1270, Loss: 2.974066913127899, Final Batch Loss: 0.5537809729576111\n",
      "Epoch 1271, Loss: 3.747165620326996, Final Batch Loss: 1.2258983850479126\n",
      "Epoch 1272, Loss: 3.8209710717201233, Final Batch Loss: 1.2963206768035889\n",
      "Epoch 1273, Loss: 2.450372487306595, Final Batch Loss: 0.07696869969367981\n",
      "Epoch 1274, Loss: 2.5581762939691544, Final Batch Loss: 0.18837298452854156\n",
      "Epoch 1275, Loss: 2.3624549508094788, Final Batch Loss: 0.05042082071304321\n",
      "Epoch 1276, Loss: 2.682089239358902, Final Batch Loss: 0.3115765154361725\n",
      "Epoch 1277, Loss: 3.3511447310447693, Final Batch Loss: 1.0320484638214111\n",
      "Epoch 1278, Loss: 4.106473445892334, Final Batch Loss: 1.8336564302444458\n",
      "Epoch 1279, Loss: 4.42443311214447, Final Batch Loss: 2.0828163623809814\n",
      "Epoch 1280, Loss: 3.5333091020584106, Final Batch Loss: 1.2754555940628052\n",
      "Epoch 1281, Loss: 2.322972074151039, Final Batch Loss: 0.07194603979587555\n",
      "Epoch 1282, Loss: 2.5923978686332703, Final Batch Loss: 0.3045409917831421\n",
      "Epoch 1283, Loss: 2.32162667211378, Final Batch Loss: 0.0006774752982892096\n",
      "Epoch 1284, Loss: 2.3621519804000854, Final Batch Loss: 0.08951646089553833\n",
      "Epoch 1285, Loss: 2.5998547673225403, Final Batch Loss: 0.3016148805618286\n",
      "Epoch 1286, Loss: 3.7480252981185913, Final Batch Loss: 1.5334324836730957\n",
      "Epoch 1287, Loss: 2.3894302397966385, Final Batch Loss: 0.13950999081134796\n",
      "Epoch 1288, Loss: 2.2766240248456597, Final Batch Loss: 0.008374691940844059\n",
      "Epoch 1289, Loss: 2.428734213113785, Final Batch Loss: 0.13414457440376282\n",
      "Epoch 1290, Loss: 3.254661440849304, Final Batch Loss: 0.9447054862976074\n",
      "Epoch 1291, Loss: 3.0992603302001953, Final Batch Loss: 0.9076589941978455\n",
      "Epoch 1292, Loss: 2.97047621011734, Final Batch Loss: 0.7116701602935791\n",
      "Epoch 1293, Loss: 2.1875404734164476, Final Batch Loss: 0.008775951340794563\n",
      "Epoch 1294, Loss: 2.2781011760234833, Final Batch Loss: 0.07486709952354431\n",
      "Epoch 1295, Loss: 2.201491133775562, Final Batch Loss: 0.004249946679919958\n",
      "Epoch 1296, Loss: 2.521921932697296, Final Batch Loss: 0.27794700860977173\n",
      "Epoch 1297, Loss: 2.627378612756729, Final Batch Loss: 0.3569570481777191\n",
      "Epoch 1298, Loss: 3.2478228211402893, Final Batch Loss: 0.9846034646034241\n",
      "Epoch 1299, Loss: 2.234298514900729, Final Batch Loss: 0.0037036414723843336\n",
      "Epoch 1300, Loss: 3.7239354252815247, Final Batch Loss: 1.5534026622772217\n",
      "Epoch 1301, Loss: 3.7617969512939453, Final Batch Loss: 1.538263201713562\n",
      "Epoch 1302, Loss: 2.2713464088737965, Final Batch Loss: 0.053151149302721024\n",
      "Epoch 1303, Loss: 2.271969825029373, Final Batch Loss: 0.12201938033103943\n",
      "Epoch 1304, Loss: 3.713962137699127, Final Batch Loss: 1.4504547119140625\n",
      "Epoch 1305, Loss: 3.5094186663627625, Final Batch Loss: 1.2507952451705933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1306, Loss: 3.8636481165885925, Final Batch Loss: 1.6655027866363525\n",
      "Epoch 1307, Loss: 3.2287718057632446, Final Batch Loss: 1.03972327709198\n",
      "Epoch 1308, Loss: 2.150631571188569, Final Batch Loss: 0.009463215246796608\n",
      "Epoch 1309, Loss: 2.914404571056366, Final Batch Loss: 0.7438737750053406\n",
      "Epoch 1310, Loss: 2.5419525504112244, Final Batch Loss: 0.30639326572418213\n",
      "Epoch 1311, Loss: 2.2102434150874615, Final Batch Loss: 0.05426396057009697\n",
      "Epoch 1312, Loss: 3.177529990673065, Final Batch Loss: 0.9249829053878784\n",
      "Epoch 1313, Loss: 3.1199722290039062, Final Batch Loss: 1.0022315979003906\n",
      "Epoch 1314, Loss: 3.680271804332733, Final Batch Loss: 1.4001154899597168\n",
      "Epoch 1315, Loss: 2.2777314335107803, Final Batch Loss: 0.05415906012058258\n",
      "Epoch 1316, Loss: 2.271290898323059, Final Batch Loss: 0.08274704217910767\n",
      "Epoch 1317, Loss: 2.3844994008541107, Final Batch Loss: 0.2127210795879364\n",
      "Epoch 1318, Loss: 4.649940252304077, Final Batch Loss: 2.4714889526367188\n",
      "Epoch 1319, Loss: 3.48081773519516, Final Batch Loss: 1.3133714199066162\n",
      "Epoch 1320, Loss: 3.4272650480270386, Final Batch Loss: 1.2728548049926758\n",
      "Epoch 1321, Loss: 3.3562334775924683, Final Batch Loss: 1.1302932500839233\n",
      "Epoch 1322, Loss: 3.254945933818817, Final Batch Loss: 1.0409276485443115\n",
      "Epoch 1323, Loss: 3.2935505509376526, Final Batch Loss: 1.0386815071105957\n",
      "Epoch 1324, Loss: 2.0933407340198755, Final Batch Loss: 0.017738977447152138\n",
      "Epoch 1325, Loss: 3.443508207798004, Final Batch Loss: 1.2362806797027588\n",
      "Epoch 1326, Loss: 2.32535557448864, Final Batch Loss: 0.14749382436275482\n",
      "Epoch 1327, Loss: 3.176105499267578, Final Batch Loss: 0.9787201881408691\n",
      "Epoch 1328, Loss: 2.304099813103676, Final Batch Loss: 0.06079234182834625\n",
      "Epoch 1329, Loss: 2.2792992554605007, Final Batch Loss: 0.054650839418172836\n",
      "Epoch 1330, Loss: 3.6123074889183044, Final Batch Loss: 1.515887975692749\n",
      "Epoch 1331, Loss: 2.5266159176826477, Final Batch Loss: 0.3390929102897644\n",
      "Epoch 1332, Loss: 3.87746798992157, Final Batch Loss: 1.7543044090270996\n",
      "Epoch 1333, Loss: 2.4553427696228027, Final Batch Loss: 0.35786688327789307\n",
      "Epoch 1334, Loss: 2.188544437289238, Final Batch Loss: 0.05223296582698822\n",
      "Epoch 1335, Loss: 2.1539766266942024, Final Batch Loss: 0.0161137655377388\n",
      "Epoch 1336, Loss: 2.527886390686035, Final Batch Loss: 0.3211522698402405\n",
      "Epoch 1337, Loss: 3.5229694843292236, Final Batch Loss: 1.4116449356079102\n",
      "Epoch 1338, Loss: 2.331147998571396, Final Batch Loss: 0.212442547082901\n",
      "Epoch 1339, Loss: 2.411336213350296, Final Batch Loss: 0.26198533177375793\n",
      "Epoch 1340, Loss: 4.105165123939514, Final Batch Loss: 1.913588285446167\n",
      "Epoch 1341, Loss: 3.873171806335449, Final Batch Loss: 1.8085540533065796\n",
      "Epoch 1342, Loss: 3.2739237546920776, Final Batch Loss: 1.0945813655853271\n",
      "Epoch 1343, Loss: 3.759196937084198, Final Batch Loss: 1.6160753965377808\n",
      "Epoch 1344, Loss: 2.8553993105888367, Final Batch Loss: 0.7461873292922974\n",
      "Epoch 1345, Loss: 2.290675088763237, Final Batch Loss: 0.11218170821666718\n",
      "Epoch 1346, Loss: 2.9664860367774963, Final Batch Loss: 0.8597413301467896\n",
      "Epoch 1347, Loss: 2.3515860736370087, Final Batch Loss: 0.14957645535469055\n",
      "Epoch 1348, Loss: 2.362506151199341, Final Batch Loss: 0.28177428245544434\n",
      "Epoch 1349, Loss: 2.130598144023679, Final Batch Loss: 0.000570253818295896\n",
      "Epoch 1350, Loss: 2.4106657952070236, Final Batch Loss: 0.19655846059322357\n",
      "Epoch 1351, Loss: 2.3028065115213394, Final Batch Loss: 0.13408328592777252\n",
      "Epoch 1352, Loss: 2.608282059431076, Final Batch Loss: 0.47153201699256897\n",
      "Epoch 1353, Loss: 3.590324640274048, Final Batch Loss: 1.407662272453308\n",
      "Epoch 1354, Loss: 2.2016001231968403, Final Batch Loss: 0.04197268560528755\n",
      "Epoch 1355, Loss: 2.105889707629103, Final Batch Loss: 0.000809818331617862\n",
      "Epoch 1356, Loss: 3.1554835438728333, Final Batch Loss: 1.0226054191589355\n",
      "Epoch 1357, Loss: 2.653385877609253, Final Batch Loss: 0.46285510063171387\n",
      "Epoch 1358, Loss: 2.84524667263031, Final Batch Loss: 0.7250250577926636\n",
      "Epoch 1359, Loss: 2.3402996510267258, Final Batch Loss: 0.17246173322200775\n",
      "Epoch 1360, Loss: 3.3725043535232544, Final Batch Loss: 1.2587666511535645\n",
      "Epoch 1361, Loss: 3.921436369419098, Final Batch Loss: 1.7624977827072144\n",
      "Epoch 1362, Loss: 2.2722271531820297, Final Batch Loss: 0.13113395869731903\n",
      "Epoch 1363, Loss: 2.165805112454109, Final Batch Loss: 0.0017536989180371165\n",
      "Epoch 1364, Loss: 2.6734135150909424, Final Batch Loss: 0.5036706328392029\n",
      "Epoch 1365, Loss: 2.4290928840637207, Final Batch Loss: 0.26449114084243774\n",
      "Epoch 1366, Loss: 2.301106408238411, Final Batch Loss: 0.1429222971200943\n",
      "Epoch 1367, Loss: 2.666193038225174, Final Batch Loss: 0.4686639606952667\n",
      "Epoch 1368, Loss: 2.2452030181884766, Final Batch Loss: 0.14978408813476562\n",
      "Epoch 1369, Loss: 2.191212013363838, Final Batch Loss: 0.17405612766742706\n",
      "Epoch 1370, Loss: 2.1399535685777664, Final Batch Loss: 0.11460979282855988\n",
      "Epoch 1371, Loss: 2.324062079191208, Final Batch Loss: 0.19408121705055237\n",
      "Epoch 1372, Loss: 3.25003445148468, Final Batch Loss: 1.0841999053955078\n",
      "Epoch 1373, Loss: 2.7666951417922974, Final Batch Loss: 0.732182502746582\n",
      "Epoch 1374, Loss: 2.2453135550022125, Final Batch Loss: 0.05301538109779358\n",
      "Epoch 1375, Loss: 2.95978707075119, Final Batch Loss: 0.8786411881446838\n",
      "Epoch 1376, Loss: 2.2761915765004233, Final Batch Loss: 0.001434250851161778\n",
      "Epoch 1377, Loss: 3.4487223625183105, Final Batch Loss: 1.2819585800170898\n",
      "Epoch 1378, Loss: 2.270482949912548, Final Batch Loss: 0.08774536103010178\n",
      "Epoch 1379, Loss: 3.2542641162872314, Final Batch Loss: 1.0708900690078735\n",
      "Epoch 1380, Loss: 3.5265382528305054, Final Batch Loss: 1.3606585264205933\n",
      "Epoch 1381, Loss: 3.3184126019477844, Final Batch Loss: 1.1800343990325928\n",
      "Epoch 1382, Loss: 2.1576858684420586, Final Batch Loss: 0.03352450579404831\n",
      "Epoch 1383, Loss: 2.1544446796178818, Final Batch Loss: 0.019592568278312683\n",
      "Epoch 1384, Loss: 3.534152626991272, Final Batch Loss: 1.450515866279602\n",
      "Epoch 1385, Loss: 3.398361921310425, Final Batch Loss: 1.1184568405151367\n",
      "Epoch 1386, Loss: 3.3954548239707947, Final Batch Loss: 1.1821439266204834\n",
      "Epoch 1387, Loss: 2.6572899222373962, Final Batch Loss: 0.5002827048301697\n",
      "Epoch 1388, Loss: 2.3577540516853333, Final Batch Loss: 0.11239224672317505\n",
      "Epoch 1389, Loss: 4.849991202354431, Final Batch Loss: 2.6544384956359863\n",
      "Epoch 1390, Loss: 2.1137943053618073, Final Batch Loss: 0.010905900038778782\n",
      "Epoch 1391, Loss: 4.4982399344444275, Final Batch Loss: 2.235081195831299\n",
      "Epoch 1392, Loss: 3.628905177116394, Final Batch Loss: 1.1456351280212402\n",
      "Epoch 1393, Loss: 2.7651195749640465, Final Batch Loss: 0.02661146968603134\n",
      "Epoch 1394, Loss: 3.6234790682792664, Final Batch Loss: 0.9723904132843018\n",
      "Epoch 1395, Loss: 3.674163520336151, Final Batch Loss: 1.0838571786880493\n",
      "Epoch 1396, Loss: 2.679557979106903, Final Batch Loss: 0.20399004220962524\n",
      "Epoch 1397, Loss: 3.8990450501441956, Final Batch Loss: 1.3832606077194214\n",
      "Epoch 1398, Loss: 2.589610442519188, Final Batch Loss: 0.1848519891500473\n",
      "Epoch 1399, Loss: 2.5424821376800537, Final Batch Loss: 0.12194383144378662\n",
      "Epoch 1400, Loss: 2.9845399260520935, Final Batch Loss: 0.5632615089416504\n",
      "Epoch 1401, Loss: 2.4118882664479315, Final Batch Loss: 0.0012246021069586277\n",
      "Epoch 1402, Loss: 3.249593734741211, Final Batch Loss: 0.9191012382507324\n",
      "Epoch 1403, Loss: 2.3455169051885605, Final Batch Loss: 0.08319984376430511\n",
      "Epoch 1404, Loss: 2.8254343271255493, Final Batch Loss: 0.6127977967262268\n",
      "Epoch 1405, Loss: 3.1837334036827087, Final Batch Loss: 1.005488634109497\n",
      "Epoch 1406, Loss: 4.535261929035187, Final Batch Loss: 2.3468339443206787\n",
      "Epoch 1407, Loss: 2.4041338860988617, Final Batch Loss: 0.1961728036403656\n",
      "Epoch 1408, Loss: 2.929591953754425, Final Batch Loss: 0.69407719373703\n",
      "Epoch 1409, Loss: 2.1505482071079314, Final Batch Loss: 0.007202493492513895\n",
      "Epoch 1410, Loss: 3.232494831085205, Final Batch Loss: 1.0359950065612793\n",
      "Epoch 1411, Loss: 2.485968768596649, Final Batch Loss: 0.29700905084609985\n",
      "Epoch 1412, Loss: 2.222041368484497, Final Batch Loss: 0.08720403909683228\n",
      "Epoch 1413, Loss: 3.4430057406425476, Final Batch Loss: 1.2226536273956299\n",
      "Epoch 1414, Loss: 2.546516329050064, Final Batch Loss: 0.33542630076408386\n",
      "Epoch 1415, Loss: 2.142656896263361, Final Batch Loss: 0.01966831460595131\n",
      "Epoch 1416, Loss: 3.9406407475471497, Final Batch Loss: 1.7701977491378784\n",
      "Epoch 1417, Loss: 2.1887630706187338, Final Batch Loss: 0.0001510267611593008\n",
      "Epoch 1418, Loss: 3.214165210723877, Final Batch Loss: 1.1214896440505981\n",
      "Epoch 1419, Loss: 2.307968407869339, Final Batch Loss: 0.2489502727985382\n",
      "Epoch 1420, Loss: 2.9243932366371155, Final Batch Loss: 0.8428820967674255\n",
      "Epoch 1421, Loss: 2.2382365986704826, Final Batch Loss: 0.0644407793879509\n",
      "Epoch 1422, Loss: 3.2195428609848022, Final Batch Loss: 0.9983036518096924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1423, Loss: 2.286452829837799, Final Batch Loss: 0.1944444179534912\n",
      "Epoch 1424, Loss: 4.006744027137756, Final Batch Loss: 1.860388994216919\n",
      "Epoch 1425, Loss: 4.001247525215149, Final Batch Loss: 1.9479682445526123\n",
      "Epoch 1426, Loss: 2.535139560699463, Final Batch Loss: 0.34394359588623047\n",
      "Epoch 1427, Loss: 2.3350978046655655, Final Batch Loss: 0.24473382532596588\n",
      "Epoch 1428, Loss: 2.163126703351736, Final Batch Loss: 0.0452226959168911\n",
      "Epoch 1429, Loss: 3.2027575969696045, Final Batch Loss: 1.069414734840393\n",
      "Epoch 1430, Loss: 2.2477993592619896, Final Batch Loss: 0.11517175287008286\n",
      "Epoch 1431, Loss: 3.9143656492233276, Final Batch Loss: 1.8704147338867188\n",
      "Epoch 1432, Loss: 2.8114548325538635, Final Batch Loss: 0.6916236281394958\n",
      "Epoch 1433, Loss: 2.8108434677124023, Final Batch Loss: 0.6006718277931213\n",
      "Epoch 1434, Loss: 2.1705558449029922, Final Batch Loss: 0.10141660273075104\n",
      "Epoch 1435, Loss: 3.58701890707016, Final Batch Loss: 1.484128475189209\n",
      "Epoch 1436, Loss: 2.5047831684350967, Final Batch Loss: 0.23503167927265167\n",
      "Epoch 1437, Loss: 3.0139235854148865, Final Batch Loss: 0.7685253620147705\n",
      "Epoch 1438, Loss: 2.1921956464648247, Final Batch Loss: 0.012139014899730682\n",
      "Epoch 1439, Loss: 3.909880042076111, Final Batch Loss: 1.7438559532165527\n",
      "Epoch 1440, Loss: 2.120178684592247, Final Batch Loss: 0.06596605479717255\n",
      "Epoch 1441, Loss: 2.297407329082489, Final Batch Loss: 0.19861721992492676\n",
      "Epoch 1442, Loss: 2.245907187461853, Final Batch Loss: 0.19661927223205566\n",
      "Epoch 1443, Loss: 2.3410177677869797, Final Batch Loss: 0.14073388278484344\n",
      "Epoch 1444, Loss: 2.139260644093156, Final Batch Loss: 0.00439261831343174\n",
      "Epoch 1445, Loss: 2.176749810576439, Final Batch Loss: 0.11859862506389618\n",
      "Epoch 1446, Loss: 2.0973440473899245, Final Batch Loss: 0.013050264678895473\n",
      "Epoch 1447, Loss: 2.0094261686317623, Final Batch Loss: 0.005803994368761778\n",
      "Epoch 1448, Loss: 4.099671304225922, Final Batch Loss: 1.9570746421813965\n",
      "Epoch 1449, Loss: 2.282938450574875, Final Batch Loss: 0.2202412188053131\n",
      "Epoch 1450, Loss: 3.286454677581787, Final Batch Loss: 1.2679977416992188\n",
      "Epoch 1451, Loss: 2.242435038089752, Final Batch Loss: 0.10887515544891357\n",
      "Epoch 1452, Loss: 3.2607548236846924, Final Batch Loss: 1.172809362411499\n",
      "Epoch 1453, Loss: 2.2492485493421555, Final Batch Loss: 0.10666798055171967\n",
      "Epoch 1454, Loss: 2.244660183787346, Final Batch Loss: 0.14546982944011688\n",
      "Epoch 1455, Loss: 3.471509277820587, Final Batch Loss: 1.4170804023742676\n",
      "Epoch 1456, Loss: 2.165186382830143, Final Batch Loss: 0.08101842552423477\n",
      "Epoch 1457, Loss: 2.1053017280064523, Final Batch Loss: 0.0042977831326425076\n",
      "Epoch 1458, Loss: 2.231324166059494, Final Batch Loss: 0.24052885174751282\n",
      "Epoch 1459, Loss: 2.080529186874628, Final Batch Loss: 0.0204910971224308\n",
      "Epoch 1460, Loss: 4.234984755516052, Final Batch Loss: 2.1597840785980225\n",
      "Epoch 1461, Loss: 3.753969967365265, Final Batch Loss: 1.6621114015579224\n",
      "Epoch 1462, Loss: 3.5064035654067993, Final Batch Loss: 1.420400857925415\n",
      "Epoch 1463, Loss: 2.1081222926732153, Final Batch Loss: 0.003161672269925475\n",
      "Epoch 1464, Loss: 2.08345590159297, Final Batch Loss: 0.01757160946726799\n",
      "Epoch 1465, Loss: 2.2192183285951614, Final Batch Loss: 0.18552102148532867\n",
      "Epoch 1466, Loss: 2.0512813106179237, Final Batch Loss: 0.08456305414438248\n",
      "Epoch 1467, Loss: 2.304871439933777, Final Batch Loss: 0.22782009840011597\n",
      "Epoch 1468, Loss: 3.232263505458832, Final Batch Loss: 1.2168365716934204\n",
      "Epoch 1469, Loss: 3.1704512238502502, Final Batch Loss: 1.0676488876342773\n",
      "Epoch 1470, Loss: 2.003914624452591, Final Batch Loss: 0.06093648076057434\n",
      "Epoch 1471, Loss: 2.432819217443466, Final Batch Loss: 0.431691437959671\n",
      "Epoch 1472, Loss: 3.729984760284424, Final Batch Loss: 1.7390908002853394\n",
      "Epoch 1473, Loss: 1.970055179670453, Final Batch Loss: 0.004235820844769478\n",
      "Epoch 1474, Loss: 2.34343558549881, Final Batch Loss: 0.2698291540145874\n",
      "Epoch 1475, Loss: 2.2425210624933243, Final Batch Loss: 0.11983038485050201\n",
      "Epoch 1476, Loss: 2.498093366622925, Final Batch Loss: 0.5061842203140259\n",
      "Epoch 1477, Loss: 2.214333403855562, Final Batch Loss: 0.05791543796658516\n",
      "Epoch 1478, Loss: 2.147632248699665, Final Batch Loss: 0.08185971528291702\n",
      "Epoch 1479, Loss: 2.8109337091445923, Final Batch Loss: 0.8289221525192261\n",
      "Epoch 1480, Loss: 3.4565452337265015, Final Batch Loss: 1.3495179414749146\n",
      "Epoch 1481, Loss: 2.0504001115914434, Final Batch Loss: 0.0022218560334295034\n",
      "Epoch 1482, Loss: 2.7275500297546387, Final Batch Loss: 0.7088618278503418\n",
      "Epoch 1483, Loss: 2.155448853969574, Final Batch Loss: 0.06832927465438843\n",
      "Epoch 1484, Loss: 4.630968451499939, Final Batch Loss: 2.4814915657043457\n",
      "Epoch 1485, Loss: 2.1338617764413357, Final Batch Loss: 0.04773711785674095\n",
      "Epoch 1486, Loss: 2.774166464805603, Final Batch Loss: 0.7709789872169495\n",
      "Epoch 1487, Loss: 3.6880788803100586, Final Batch Loss: 1.631467342376709\n",
      "Epoch 1488, Loss: 2.2956027388572693, Final Batch Loss: 0.27487504482269287\n",
      "Epoch 1489, Loss: 2.831201910972595, Final Batch Loss: 0.8283363580703735\n",
      "Epoch 1490, Loss: 2.465359926223755, Final Batch Loss: 0.3915882110595703\n",
      "Epoch 1491, Loss: 2.1092972569167614, Final Batch Loss: 0.020642798393964767\n",
      "Epoch 1492, Loss: 2.7776771187782288, Final Batch Loss: 0.6039480566978455\n",
      "Epoch 1493, Loss: 2.9660730957984924, Final Batch Loss: 0.723108172416687\n",
      "Epoch 1494, Loss: 5.134254455566406, Final Batch Loss: 2.9629034996032715\n",
      "Epoch 1495, Loss: 3.748467266559601, Final Batch Loss: 1.567160725593567\n",
      "Epoch 1496, Loss: 2.421564817428589, Final Batch Loss: 0.2247004508972168\n",
      "Epoch 1497, Loss: 2.4218631675466895, Final Batch Loss: 0.014002769254148006\n",
      "Epoch 1498, Loss: 4.514078795909882, Final Batch Loss: 2.1825993061065674\n",
      "Epoch 1499, Loss: 2.6432246565818787, Final Batch Loss: 0.3256610631942749\n",
      "Epoch 1500, Loss: 2.4384878873825073, Final Batch Loss: 0.2628028988838196\n",
      "Epoch 1501, Loss: 3.2710745334625244, Final Batch Loss: 1.2251614332199097\n",
      "Epoch 1502, Loss: 3.470535159111023, Final Batch Loss: 1.3904612064361572\n",
      "Epoch 1503, Loss: 3.168419659137726, Final Batch Loss: 1.0207898616790771\n",
      "Epoch 1504, Loss: 2.084175370633602, Final Batch Loss: 0.016171477735042572\n",
      "Epoch 1505, Loss: 4.994879722595215, Final Batch Loss: 2.8645060062408447\n",
      "Epoch 1506, Loss: 3.0281874537467957, Final Batch Loss: 0.9191285967826843\n",
      "Epoch 1507, Loss: 3.1934854984283447, Final Batch Loss: 0.968331515789032\n",
      "Epoch 1508, Loss: 2.414208322763443, Final Batch Loss: 0.26147517561912537\n",
      "Epoch 1509, Loss: 3.577792763710022, Final Batch Loss: 1.4048715829849243\n",
      "Epoch 1510, Loss: 2.24084060639143, Final Batch Loss: 0.07123314589262009\n",
      "Epoch 1511, Loss: 2.269212082028389, Final Batch Loss: 0.2067282348871231\n",
      "Epoch 1512, Loss: 5.3946157693862915, Final Batch Loss: 3.191032886505127\n",
      "Epoch 1513, Loss: 2.100116103887558, Final Batch Loss: 0.04686024785041809\n",
      "Epoch 1514, Loss: 2.1767436331138015, Final Batch Loss: 0.004470354877412319\n",
      "Epoch 1515, Loss: 2.744696408510208, Final Batch Loss: 0.30787453055381775\n",
      "Epoch 1516, Loss: 4.029294788837433, Final Batch Loss: 1.664555549621582\n",
      "Epoch 1517, Loss: 4.256049454212189, Final Batch Loss: 2.017277717590332\n",
      "Epoch 1518, Loss: 2.2760034631937742, Final Batch Loss: 0.01611892692744732\n",
      "Epoch 1519, Loss: 2.195277649909258, Final Batch Loss: 0.006281513720750809\n",
      "Epoch 1520, Loss: 2.6892425417900085, Final Batch Loss: 0.64951491355896\n",
      "Epoch 1521, Loss: 2.218870297074318, Final Batch Loss: 0.11794610321521759\n",
      "Epoch 1522, Loss: 2.33475986123085, Final Batch Loss: 0.2501535713672638\n",
      "Epoch 1523, Loss: 2.9781845211982727, Final Batch Loss: 0.8052288293838501\n",
      "Epoch 1524, Loss: 2.2576064467430115, Final Batch Loss: 0.13030415773391724\n",
      "Epoch 1525, Loss: 2.26505845785141, Final Batch Loss: 0.2488890290260315\n",
      "Epoch 1526, Loss: 2.1671891510486603, Final Batch Loss: 0.10175928473472595\n",
      "Epoch 1527, Loss: 2.1231134608387947, Final Batch Loss: 0.10922373086214066\n",
      "Epoch 1528, Loss: 3.6444701552391052, Final Batch Loss: 1.5579789876937866\n",
      "Epoch 1529, Loss: 2.1654430478811264, Final Batch Loss: 0.14069764316082\n",
      "Epoch 1530, Loss: 1.9848622609861195, Final Batch Loss: 0.006199889350682497\n",
      "Epoch 1531, Loss: 2.1863429993391037, Final Batch Loss: 0.10637103021144867\n",
      "Epoch 1532, Loss: 3.2734195590019226, Final Batch Loss: 1.2340973615646362\n",
      "Epoch 1533, Loss: 2.5368260741233826, Final Batch Loss: 0.5016952157020569\n",
      "Epoch 1534, Loss: 2.399613320827484, Final Batch Loss: 0.28063350915908813\n",
      "Epoch 1535, Loss: 3.810890018939972, Final Batch Loss: 1.816957712173462\n",
      "Epoch 1536, Loss: 2.057626576075563, Final Batch Loss: 0.00042083943844772875\n",
      "Epoch 1537, Loss: 2.3240718245506287, Final Batch Loss: 0.24973398447036743\n",
      "Epoch 1538, Loss: 3.6886945962905884, Final Batch Loss: 1.7195419073104858\n",
      "Epoch 1539, Loss: 2.8218093514442444, Final Batch Loss: 0.7525590062141418\n",
      "Epoch 1540, Loss: 2.018398172687739, Final Batch Loss: 0.005431063007563353\n",
      "Epoch 1541, Loss: 2.1683198511600494, Final Batch Loss: 0.14222869277000427\n",
      "Epoch 1542, Loss: 3.036671817302704, Final Batch Loss: 0.9604459404945374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1543, Loss: 2.0911343321204185, Final Batch Loss: 0.04248454421758652\n",
      "Epoch 1544, Loss: 2.027574419043958, Final Batch Loss: 0.01102298405021429\n",
      "Epoch 1545, Loss: 2.9935637712478638, Final Batch Loss: 0.9272883534431458\n",
      "Epoch 1546, Loss: 2.108913578093052, Final Batch Loss: 0.11693952232599258\n",
      "Epoch 1547, Loss: 4.163589119911194, Final Batch Loss: 2.1781015396118164\n",
      "Epoch 1548, Loss: 2.1539153084158897, Final Batch Loss: 0.08932121843099594\n",
      "Epoch 1549, Loss: 2.3149081766605377, Final Batch Loss: 0.27733948826789856\n",
      "Epoch 1550, Loss: 3.5102344751358032, Final Batch Loss: 1.490468144416809\n",
      "Epoch 1551, Loss: 1.9977677180431783, Final Batch Loss: 0.006901474203914404\n",
      "Epoch 1552, Loss: 2.2043930739164352, Final Batch Loss: 0.1665963977575302\n",
      "Epoch 1553, Loss: 2.0784108489751816, Final Batch Loss: 0.05129842460155487\n",
      "Epoch 1554, Loss: 2.0616687301080674, Final Batch Loss: 0.002545333234593272\n",
      "Epoch 1555, Loss: 2.0464463643729687, Final Batch Loss: 0.0154215507209301\n",
      "Epoch 1556, Loss: 3.059697687625885, Final Batch Loss: 0.9211256504058838\n",
      "Epoch 1557, Loss: 3.281000316143036, Final Batch Loss: 1.2576940059661865\n",
      "Epoch 1558, Loss: 3.533904731273651, Final Batch Loss: 1.5144402980804443\n",
      "Epoch 1559, Loss: 2.744262218475342, Final Batch Loss: 0.6814209818840027\n",
      "Epoch 1560, Loss: 2.0296237021684647, Final Batch Loss: 0.014296486973762512\n",
      "Epoch 1561, Loss: 2.0673284083604813, Final Batch Loss: 0.02258099615573883\n",
      "Epoch 1562, Loss: 2.332399696111679, Final Batch Loss: 0.2864982783794403\n",
      "Epoch 1563, Loss: 2.9076087474823, Final Batch Loss: 0.8025875091552734\n",
      "Epoch 1564, Loss: 3.2403236031532288, Final Batch Loss: 1.269464135169983\n",
      "Epoch 1565, Loss: 2.705032706260681, Final Batch Loss: 0.6762745976448059\n",
      "Epoch 1566, Loss: 3.2117443084716797, Final Batch Loss: 1.028288722038269\n",
      "Epoch 1567, Loss: 2.961690664291382, Final Batch Loss: 0.7028929591178894\n",
      "Epoch 1568, Loss: 2.293131798505783, Final Batch Loss: 0.1285252869129181\n",
      "Epoch 1569, Loss: 2.1022591311484575, Final Batch Loss: 0.009162994101643562\n",
      "Epoch 1570, Loss: 2.451423764228821, Final Batch Loss: 0.34382688999176025\n",
      "Epoch 1571, Loss: 5.028919816017151, Final Batch Loss: 2.8958797454833984\n",
      "Epoch 1572, Loss: 2.04999247379601, Final Batch Loss: 0.023782463744282722\n",
      "Epoch 1573, Loss: 4.05975204706192, Final Batch Loss: 1.8774582147598267\n",
      "Epoch 1574, Loss: 2.4951098412275314, Final Batch Loss: 0.21370767056941986\n",
      "Epoch 1575, Loss: 2.1901321311015636, Final Batch Loss: 0.002293695928528905\n",
      "Epoch 1576, Loss: 3.122013568878174, Final Batch Loss: 0.8621791005134583\n",
      "Epoch 1577, Loss: 3.38029408454895, Final Batch Loss: 1.2212623357772827\n",
      "Epoch 1578, Loss: 3.4600600004196167, Final Batch Loss: 1.4413094520568848\n",
      "Epoch 1579, Loss: 2.927303969860077, Final Batch Loss: 0.9132239818572998\n",
      "Epoch 1580, Loss: 2.29387329518795, Final Batch Loss: 0.2058020681142807\n",
      "Epoch 1581, Loss: 3.889987051486969, Final Batch Loss: 1.728327751159668\n",
      "Epoch 1582, Loss: 2.2447277158498764, Final Batch Loss: 0.15249274671077728\n",
      "Epoch 1583, Loss: 2.1130224987864494, Final Batch Loss: 0.04415201395750046\n",
      "Epoch 1584, Loss: 6.045376718044281, Final Batch Loss: 3.982149600982666\n",
      "Epoch 1585, Loss: 2.0908214040100574, Final Batch Loss: 0.01026352122426033\n",
      "Epoch 1586, Loss: 3.576961398124695, Final Batch Loss: 1.4565809965133667\n",
      "Epoch 1587, Loss: 4.876315355300903, Final Batch Loss: 2.549269676208496\n",
      "Epoch 1588, Loss: 2.2715208753943443, Final Batch Loss: 0.10379668325185776\n",
      "Epoch 1589, Loss: 3.104181170463562, Final Batch Loss: 1.0418541431427002\n",
      "Epoch 1590, Loss: 2.4616393744945526, Final Batch Loss: 0.3181760013103485\n",
      "Epoch 1591, Loss: 2.299955874681473, Final Batch Loss: 0.162740558385849\n",
      "Epoch 1592, Loss: 2.0719067864120007, Final Batch Loss: 0.03810028359293938\n",
      "Epoch 1593, Loss: 3.3399091958999634, Final Batch Loss: 1.2216187715530396\n",
      "Epoch 1594, Loss: 3.6169368028640747, Final Batch Loss: 1.6126501560211182\n",
      "Epoch 1595, Loss: 2.4237755239009857, Final Batch Loss: 0.3981209695339203\n",
      "Epoch 1596, Loss: 2.142545831389725, Final Batch Loss: 0.013274741359055042\n",
      "Epoch 1597, Loss: 2.980135202407837, Final Batch Loss: 0.9589272141456604\n",
      "Epoch 1598, Loss: 2.021248006261885, Final Batch Loss: 0.009814106859266758\n",
      "Epoch 1599, Loss: 2.4731687009334564, Final Batch Loss: 0.4354260265827179\n",
      "Epoch 1600, Loss: 3.689848840236664, Final Batch Loss: 1.6770427227020264\n",
      "Epoch 1601, Loss: 2.537157267332077, Final Batch Loss: 0.4887982904911041\n",
      "Epoch 1602, Loss: 3.859514892101288, Final Batch Loss: 1.801350712776184\n",
      "Epoch 1603, Loss: 3.12771475315094, Final Batch Loss: 1.1093072891235352\n",
      "Epoch 1604, Loss: 2.1634681969881058, Final Batch Loss: 0.12197728455066681\n",
      "Epoch 1605, Loss: 3.5145561695098877, Final Batch Loss: 1.527320384979248\n",
      "Epoch 1606, Loss: 2.8726112246513367, Final Batch Loss: 0.9160095453262329\n",
      "Epoch 1607, Loss: 3.103730857372284, Final Batch Loss: 1.1371212005615234\n",
      "Epoch 1608, Loss: 3.583151698112488, Final Batch Loss: 1.645827293395996\n",
      "Epoch 1609, Loss: 2.2669202983379364, Final Batch Loss: 0.26014915108680725\n",
      "Epoch 1610, Loss: 2.5007839500904083, Final Batch Loss: 0.4986114203929901\n",
      "Epoch 1611, Loss: 4.415829002857208, Final Batch Loss: 2.4243907928466797\n",
      "Epoch 1612, Loss: 2.8732075095176697, Final Batch Loss: 0.7356395125389099\n",
      "Epoch 1613, Loss: 3.6518803238868713, Final Batch Loss: 1.5700874328613281\n",
      "Epoch 1614, Loss: 2.200680933892727, Final Batch Loss: 0.10846634954214096\n",
      "Epoch 1615, Loss: 3.824322283267975, Final Batch Loss: 1.7952454090118408\n",
      "Epoch 1616, Loss: 2.005161978304386, Final Batch Loss: 0.06439260393381119\n",
      "Epoch 1617, Loss: 2.5237414836883545, Final Batch Loss: 0.5262975692749023\n",
      "Epoch 1618, Loss: 2.0424460619688034, Final Batch Loss: 0.023329302668571472\n",
      "Epoch 1619, Loss: 2.1082602217793465, Final Batch Loss: 0.08196229487657547\n",
      "Epoch 1620, Loss: 2.3199518024921417, Final Batch Loss: 0.27639666199684143\n",
      "Epoch 1621, Loss: 2.000183939933777, Final Batch Loss: 0.05458706617355347\n",
      "Epoch 1622, Loss: 2.3183381259441376, Final Batch Loss: 0.23802563548088074\n",
      "Epoch 1623, Loss: 3.415465772151947, Final Batch Loss: 1.4294159412384033\n",
      "Epoch 1624, Loss: 1.9842197578400373, Final Batch Loss: 0.0048852842301130295\n",
      "Epoch 1625, Loss: 1.9429598664864898, Final Batch Loss: 0.00309892650693655\n",
      "Epoch 1626, Loss: 3.2704936861991882, Final Batch Loss: 1.276306390762329\n",
      "Epoch 1627, Loss: 2.2190831154584885, Final Batch Loss: 0.21350769698619843\n",
      "Epoch 1628, Loss: 3.9049962759017944, Final Batch Loss: 1.8718922138214111\n",
      "Epoch 1629, Loss: 2.202998697757721, Final Batch Loss: 0.2909266948699951\n",
      "Epoch 1630, Loss: 3.4591503739356995, Final Batch Loss: 1.4760801792144775\n",
      "Epoch 1631, Loss: 2.184265375137329, Final Batch Loss: 0.20589900016784668\n",
      "Epoch 1632, Loss: 3.283958315849304, Final Batch Loss: 1.3229880332946777\n",
      "Epoch 1633, Loss: 3.0946948528289795, Final Batch Loss: 0.9974893927574158\n",
      "Epoch 1634, Loss: 3.2336394786834717, Final Batch Loss: 1.256130576133728\n",
      "Epoch 1635, Loss: 2.0528534557670355, Final Batch Loss: 0.02169274352490902\n",
      "Epoch 1636, Loss: 2.109789937734604, Final Batch Loss: 0.13861581683158875\n",
      "Epoch 1637, Loss: 2.056166909635067, Final Batch Loss: 0.11401274055242538\n",
      "Epoch 1638, Loss: 2.0957491770386696, Final Batch Loss: 0.09212104231119156\n",
      "Epoch 1639, Loss: 1.9739283074159175, Final Batch Loss: 0.003423308255150914\n",
      "Epoch 1640, Loss: 2.14872258156538, Final Batch Loss: 0.10896997898817062\n",
      "Epoch 1641, Loss: 4.639646768569946, Final Batch Loss: 2.6925127506256104\n",
      "Epoch 1642, Loss: 2.7764384746551514, Final Batch Loss: 0.7206906676292419\n",
      "Epoch 1643, Loss: 2.9091816544532776, Final Batch Loss: 0.9551063776016235\n",
      "Epoch 1644, Loss: 2.9058974385261536, Final Batch Loss: 0.8889588117599487\n",
      "Epoch 1645, Loss: 2.1389338076114655, Final Batch Loss: 0.08560273051261902\n",
      "Epoch 1646, Loss: 3.819527804851532, Final Batch Loss: 1.8426049947738647\n",
      "Epoch 1647, Loss: 2.6578924655914307, Final Batch Loss: 0.6525244116783142\n",
      "Epoch 1648, Loss: 2.0791096836328506, Final Batch Loss: 0.0115518718957901\n",
      "Epoch 1649, Loss: 2.0281888375466224, Final Batch Loss: 0.00030560590676032007\n",
      "Epoch 1650, Loss: 1.9618205815786496, Final Batch Loss: 0.000529149197973311\n",
      "Epoch 1651, Loss: 3.3973146080970764, Final Batch Loss: 1.393903136253357\n",
      "Epoch 1652, Loss: 3.9914427399635315, Final Batch Loss: 1.9220263957977295\n",
      "Epoch 1653, Loss: 2.0475907251238823, Final Batch Loss: 0.04023527354001999\n",
      "Epoch 1654, Loss: 2.36443167924881, Final Batch Loss: 0.3785938620567322\n",
      "Epoch 1655, Loss: 2.2755084186792374, Final Batch Loss: 0.2250228077173233\n",
      "Epoch 1656, Loss: 2.7218539118766785, Final Batch Loss: 0.7027498483657837\n",
      "Epoch 1657, Loss: 2.357097953557968, Final Batch Loss: 0.3371463716030121\n",
      "Epoch 1658, Loss: 2.725466728210449, Final Batch Loss: 0.7818804979324341\n",
      "Epoch 1659, Loss: 2.0145986191928387, Final Batch Loss: 0.001328539103269577\n",
      "Epoch 1660, Loss: 1.9426568150520325, Final Batch Loss: 0.061196327209472656\n",
      "Epoch 1661, Loss: 2.2135463058948517, Final Batch Loss: 0.17143335938453674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1662, Loss: 2.9421169757843018, Final Batch Loss: 1.0415608882904053\n",
      "Epoch 1663, Loss: 4.52668821811676, Final Batch Loss: 2.5826871395111084\n",
      "Epoch 1664, Loss: 3.327959418296814, Final Batch Loss: 1.3224462270736694\n",
      "Epoch 1665, Loss: 2.039718486368656, Final Batch Loss: 0.020121969282627106\n",
      "Epoch 1666, Loss: 2.108914129436016, Final Batch Loss: 0.053079478442668915\n",
      "Epoch 1667, Loss: 2.192032665014267, Final Batch Loss: 0.15009018778800964\n",
      "Epoch 1668, Loss: 2.728851079940796, Final Batch Loss: 0.7579586505889893\n",
      "Epoch 1669, Loss: 2.39284747838974, Final Batch Loss: 0.3506176471710205\n",
      "Epoch 1670, Loss: 1.9670176059007645, Final Batch Loss: 0.14454682171344757\n",
      "Epoch 1671, Loss: 2.9528735280036926, Final Batch Loss: 1.0374191999435425\n",
      "Epoch 1672, Loss: 2.1051866710186005, Final Batch Loss: 0.13870641589164734\n",
      "Epoch 1673, Loss: 2.3347353041172028, Final Batch Loss: 0.38853976130485535\n",
      "Epoch 1674, Loss: 3.402245879173279, Final Batch Loss: 1.5048081874847412\n",
      "Epoch 1675, Loss: 3.0238744616508484, Final Batch Loss: 1.0352838039398193\n",
      "Epoch 1676, Loss: 2.8487245440483093, Final Batch Loss: 0.8652148246765137\n",
      "Epoch 1677, Loss: 2.641964077949524, Final Batch Loss: 0.7220350503921509\n",
      "Epoch 1678, Loss: 2.4238636195659637, Final Batch Loss: 0.45998767018318176\n",
      "Epoch 1679, Loss: 2.7815287113189697, Final Batch Loss: 0.862259566783905\n",
      "Epoch 1680, Loss: 4.562329947948456, Final Batch Loss: 2.584200382232666\n",
      "Epoch 1681, Loss: 1.999095469713211, Final Batch Loss: 0.06848970055580139\n",
      "Epoch 1682, Loss: 1.86774138873443, Final Batch Loss: 0.002244455274194479\n",
      "Epoch 1683, Loss: 2.1993353068828583, Final Batch Loss: 0.251583069562912\n",
      "Epoch 1684, Loss: 4.313840866088867, Final Batch Loss: 2.3824009895324707\n",
      "Epoch 1685, Loss: 4.57056599855423, Final Batch Loss: 2.4612581729888916\n",
      "Epoch 1686, Loss: 2.13716350402683, Final Batch Loss: 0.009950085543096066\n",
      "Epoch 1687, Loss: 5.098295629024506, Final Batch Loss: 3.057209014892578\n",
      "Epoch 1688, Loss: 2.62289622426033, Final Batch Loss: 0.3496600091457367\n",
      "Epoch 1689, Loss: 8.274738609790802, Final Batch Loss: 5.912317752838135\n",
      "Epoch 1690, Loss: 2.6023517549037933, Final Batch Loss: 0.3896489441394806\n",
      "Epoch 1691, Loss: 2.409951090812683, Final Batch Loss: 0.3017258644104004\n",
      "Epoch 1692, Loss: 3.3404459953308105, Final Batch Loss: 1.2024050951004028\n",
      "Epoch 1693, Loss: 3.316437542438507, Final Batch Loss: 1.1179872751235962\n",
      "Epoch 1694, Loss: 2.401954099535942, Final Batch Loss: 0.05668650567531586\n",
      "Epoch 1695, Loss: 3.741813600063324, Final Batch Loss: 1.514190435409546\n",
      "Epoch 1696, Loss: 2.374610126018524, Final Batch Loss: 0.16574126482009888\n",
      "Epoch 1697, Loss: 2.707789719104767, Final Batch Loss: 0.4973214268684387\n",
      "Epoch 1698, Loss: 3.910079002380371, Final Batch Loss: 1.7091518640518188\n",
      "Epoch 1699, Loss: 3.6977438926696777, Final Batch Loss: 1.5615565776824951\n",
      "Epoch 1700, Loss: 2.2629660964012146, Final Batch Loss: 0.08292579650878906\n",
      "Epoch 1701, Loss: 3.01561963558197, Final Batch Loss: 0.7618964314460754\n",
      "Epoch 1702, Loss: 3.5364689230918884, Final Batch Loss: 1.3149937391281128\n",
      "Epoch 1703, Loss: 3.019942581653595, Final Batch Loss: 0.791233479976654\n",
      "Epoch 1704, Loss: 3.5478397607803345, Final Batch Loss: 1.4151599407196045\n",
      "Epoch 1705, Loss: 3.779072105884552, Final Batch Loss: 1.626145362854004\n",
      "Epoch 1706, Loss: 3.520612120628357, Final Batch Loss: 1.3464770317077637\n",
      "Epoch 1707, Loss: 3.215531349182129, Final Batch Loss: 1.1618380546569824\n",
      "Epoch 1708, Loss: 3.7486740350723267, Final Batch Loss: 1.6550863981246948\n",
      "Epoch 1709, Loss: 2.5421568155288696, Final Batch Loss: 0.4705374836921692\n",
      "Epoch 1710, Loss: 2.689614713191986, Final Batch Loss: 0.6029974222183228\n",
      "Epoch 1711, Loss: 2.066918211057782, Final Batch Loss: 0.022114114835858345\n",
      "Epoch 1712, Loss: 2.1510550677776337, Final Batch Loss: 0.08934029936790466\n",
      "Epoch 1713, Loss: 2.322085604071617, Final Batch Loss: 0.19183795154094696\n",
      "Epoch 1714, Loss: 3.102030873298645, Final Batch Loss: 0.9494106769561768\n",
      "Epoch 1715, Loss: 2.2221360728144646, Final Batch Loss: 0.06972145289182663\n",
      "Epoch 1716, Loss: 3.811029314994812, Final Batch Loss: 1.7089433670043945\n",
      "Epoch 1717, Loss: 3.354662299156189, Final Batch Loss: 1.2720699310302734\n",
      "Epoch 1718, Loss: 3.736291229724884, Final Batch Loss: 1.5714623928070068\n",
      "Epoch 1719, Loss: 2.047423799347598, Final Batch Loss: 0.000746448349673301\n",
      "Epoch 1720, Loss: 3.3091041445732117, Final Batch Loss: 1.1632792949676514\n",
      "Epoch 1721, Loss: 2.082522179931402, Final Batch Loss: 0.0204482339322567\n",
      "Epoch 1722, Loss: 2.2372472286224365, Final Batch Loss: 0.1641044020652771\n",
      "Epoch 1723, Loss: 2.077877275645733, Final Batch Loss: 0.043831340968608856\n",
      "Epoch 1724, Loss: 2.028430731035769, Final Batch Loss: 0.01364722941070795\n",
      "Epoch 1725, Loss: 4.310701012611389, Final Batch Loss: 2.268094539642334\n",
      "Epoch 1726, Loss: 1.9963377639651299, Final Batch Loss: 0.09549473971128464\n",
      "Epoch 1727, Loss: 3.125741720199585, Final Batch Loss: 1.1026403903961182\n",
      "Epoch 1728, Loss: 2.23623189330101, Final Batch Loss: 0.30321475863456726\n",
      "Epoch 1729, Loss: 2.171624183654785, Final Batch Loss: 0.16255342960357666\n",
      "Epoch 1730, Loss: 3.3025115728378296, Final Batch Loss: 1.240502119064331\n",
      "Epoch 1731, Loss: 4.360531270503998, Final Batch Loss: 2.2348294258117676\n",
      "Epoch 1732, Loss: 4.873544931411743, Final Batch Loss: 2.7281227111816406\n",
      "Epoch 1733, Loss: 3.301936984062195, Final Batch Loss: 0.8134831190109253\n",
      "Epoch 1734, Loss: 3.3233470916748047, Final Batch Loss: 0.7605929374694824\n",
      "Epoch 1735, Loss: 4.449171841144562, Final Batch Loss: 1.987982988357544\n",
      "Epoch 1736, Loss: 2.6721126437187195, Final Batch Loss: 0.2672635316848755\n",
      "Epoch 1737, Loss: 2.4676419347524643, Final Batch Loss: 0.21000592410564423\n",
      "Epoch 1738, Loss: 2.661256641149521, Final Batch Loss: 0.3508196175098419\n",
      "Epoch 1739, Loss: 2.462427034974098, Final Batch Loss: 0.22630532085895538\n",
      "Epoch 1740, Loss: 2.027743806131184, Final Batch Loss: 0.009997059591114521\n",
      "Epoch 1741, Loss: 1.998676432762295, Final Batch Loss: 0.0011844770051538944\n",
      "Epoch 1742, Loss: 2.9358227849006653, Final Batch Loss: 0.9034838080406189\n",
      "Epoch 1743, Loss: 2.8908276557922363, Final Batch Loss: 0.8978767991065979\n",
      "Epoch 1744, Loss: 3.6046206951141357, Final Batch Loss: 1.583675742149353\n",
      "Epoch 1745, Loss: 2.101954612880945, Final Batch Loss: 0.05551222339272499\n",
      "Epoch 1746, Loss: 1.9666384011507034, Final Batch Loss: 0.039219990372657776\n",
      "Epoch 1747, Loss: 1.9581484943628311, Final Batch Loss: 0.015354052186012268\n",
      "Epoch 1748, Loss: 4.230794072151184, Final Batch Loss: 2.2794418334960938\n",
      "Epoch 1749, Loss: 2.125530082732439, Final Batch Loss: 0.052955348044633865\n",
      "Epoch 1750, Loss: 2.1607651859521866, Final Batch Loss: 0.08760328590869904\n",
      "Epoch 1751, Loss: 3.6821570992469788, Final Batch Loss: 1.7750661373138428\n",
      "Epoch 1752, Loss: 2.808312237262726, Final Batch Loss: 0.8641723990440369\n",
      "Epoch 1753, Loss: 1.9630780718289316, Final Batch Loss: 0.007035245653241873\n",
      "Epoch 1754, Loss: 1.959946517541539, Final Batch Loss: 0.0005906267906539142\n",
      "Epoch 1755, Loss: 1.849984937114641, Final Batch Loss: 0.002515249652788043\n",
      "Epoch 1756, Loss: 3.0372760891914368, Final Batch Loss: 1.0662370920181274\n",
      "Epoch 1757, Loss: 2.10447183996439, Final Batch Loss: 0.06987909227609634\n",
      "Epoch 1758, Loss: 3.299571931362152, Final Batch Loss: 1.3888986110687256\n",
      "Epoch 1759, Loss: 4.655906438827515, Final Batch Loss: 2.7505035400390625\n",
      "Epoch 1760, Loss: 2.0869934260845184, Final Batch Loss: 0.09420093894004822\n",
      "Epoch 1761, Loss: 2.49996754527092, Final Batch Loss: 0.49725624918937683\n",
      "Epoch 1762, Loss: 2.882816791534424, Final Batch Loss: 0.7948123216629028\n",
      "Epoch 1763, Loss: 2.0176717727445066, Final Batch Loss: 0.000760385300964117\n",
      "Epoch 1764, Loss: 3.7380537390708923, Final Batch Loss: 1.7111884355545044\n",
      "Epoch 1765, Loss: 4.920170307159424, Final Batch Loss: 2.8347678184509277\n",
      "Epoch 1766, Loss: 2.929888963699341, Final Batch Loss: 0.7733049392700195\n",
      "Epoch 1767, Loss: 2.3038979284465313, Final Batch Loss: 0.02950657531619072\n",
      "Epoch 1768, Loss: 2.3012593388557434, Final Batch Loss: 0.01735055446624756\n",
      "Epoch 1769, Loss: 2.463713774457574, Final Batch Loss: 0.027163157239556313\n",
      "Epoch 1770, Loss: 3.1091650128364563, Final Batch Loss: 0.831739604473114\n",
      "Epoch 1771, Loss: 2.762949228286743, Final Batch Loss: 0.6321790814399719\n",
      "Epoch 1772, Loss: 2.631139099597931, Final Batch Loss: 0.5949248671531677\n",
      "Epoch 1773, Loss: 2.178279787302017, Final Batch Loss: 0.1814853847026825\n",
      "Epoch 1774, Loss: 3.695724070072174, Final Batch Loss: 1.7844467163085938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1775, Loss: 3.0200620889663696, Final Batch Loss: 1.1048953533172607\n",
      "Epoch 1776, Loss: 3.2437840700149536, Final Batch Loss: 1.2117910385131836\n",
      "Epoch 1777, Loss: 2.303142875432968, Final Batch Loss: 0.325368195772171\n",
      "Epoch 1778, Loss: 4.044885635375977, Final Batch Loss: 2.0818827152252197\n",
      "Epoch 1779, Loss: 2.037343129515648, Final Batch Loss: 0.019474729895591736\n",
      "Epoch 1780, Loss: 2.773726165294647, Final Batch Loss: 0.7666611671447754\n",
      "Epoch 1781, Loss: 3.3560945987701416, Final Batch Loss: 1.4348182678222656\n",
      "Epoch 1782, Loss: 3.5341917872428894, Final Batch Loss: 1.5337412357330322\n",
      "Epoch 1783, Loss: 2.8720940351486206, Final Batch Loss: 0.9633699655532837\n",
      "Epoch 1784, Loss: 3.569638252258301, Final Batch Loss: 1.6008895635604858\n",
      "Epoch 1785, Loss: 2.9969266653060913, Final Batch Loss: 1.056138277053833\n",
      "Epoch 1786, Loss: 2.499895691871643, Final Batch Loss: 0.5793833136558533\n",
      "Epoch 1787, Loss: 2.0968080163002014, Final Batch Loss: 0.22540444135665894\n",
      "Epoch 1788, Loss: 4.150237679481506, Final Batch Loss: 2.2551779747009277\n",
      "Epoch 1789, Loss: 3.917890727519989, Final Batch Loss: 2.004939079284668\n",
      "Epoch 1790, Loss: 2.102256014943123, Final Batch Loss: 0.14950235188007355\n",
      "Epoch 1791, Loss: 3.827615201473236, Final Batch Loss: 1.765312671661377\n",
      "Epoch 1792, Loss: 3.073338031768799, Final Batch Loss: 1.0970637798309326\n",
      "Epoch 1793, Loss: 2.1065646708011627, Final Batch Loss: 0.13822844624519348\n",
      "Epoch 1794, Loss: 2.002601455664262, Final Batch Loss: 0.0026467551942914724\n",
      "Epoch 1795, Loss: 4.078947126865387, Final Batch Loss: 2.0053255558013916\n",
      "Epoch 1796, Loss: 4.251766920089722, Final Batch Loss: 2.1626694202423096\n",
      "Epoch 1797, Loss: 3.3494643568992615, Final Batch Loss: 1.2980351448059082\n",
      "Epoch 1798, Loss: 2.085440667986404, Final Batch Loss: 0.000416907190810889\n",
      "Epoch 1799, Loss: 2.06793275102973, Final Batch Loss: 0.05624046549201012\n",
      "Epoch 1800, Loss: 3.0856143832206726, Final Batch Loss: 1.018791675567627\n",
      "Epoch 1801, Loss: 3.2998767495155334, Final Batch Loss: 1.224181056022644\n",
      "Epoch 1802, Loss: 2.9058115482330322, Final Batch Loss: 0.8750194311141968\n",
      "Epoch 1803, Loss: 2.182992711663246, Final Batch Loss: 0.08501459658145905\n",
      "Epoch 1804, Loss: 3.612468123435974, Final Batch Loss: 1.617931842803955\n",
      "Epoch 1805, Loss: 2.2560698091983795, Final Batch Loss: 0.3004980981349945\n",
      "Epoch 1806, Loss: 3.632132053375244, Final Batch Loss: 1.6307599544525146\n",
      "Epoch 1807, Loss: 3.3824456334114075, Final Batch Loss: 1.432011365890503\n",
      "Epoch 1808, Loss: 2.0334859592840075, Final Batch Loss: 0.009008596651256084\n",
      "Epoch 1809, Loss: 1.9335062229074538, Final Batch Loss: 0.0006422125734388828\n",
      "Epoch 1810, Loss: 3.5134376287460327, Final Batch Loss: 1.517837405204773\n",
      "Epoch 1811, Loss: 2.7465990781784058, Final Batch Loss: 0.7394189238548279\n",
      "Epoch 1812, Loss: 2.011381385847926, Final Batch Loss: 0.01940727047622204\n",
      "Epoch 1813, Loss: 2.06562814489007, Final Batch Loss: 0.021298501640558243\n",
      "Epoch 1814, Loss: 1.9829024031132576, Final Batch Loss: 9.524368942948058e-05\n",
      "Epoch 1815, Loss: 2.311921179294586, Final Batch Loss: 0.38502317667007446\n",
      "Epoch 1816, Loss: 2.601522207260132, Final Batch Loss: 0.6906673908233643\n",
      "Epoch 1817, Loss: 2.328569322824478, Final Batch Loss: 0.4284614622592926\n",
      "Epoch 1818, Loss: 2.4525307416915894, Final Batch Loss: 0.5302696228027344\n",
      "Epoch 1819, Loss: 2.00565929710865, Final Batch Loss: 0.1626616269350052\n",
      "Epoch 1820, Loss: 2.0894143134355545, Final Batch Loss: 0.12582768499851227\n",
      "Epoch 1821, Loss: 2.4926977157592773, Final Batch Loss: 0.4885435104370117\n",
      "Epoch 1822, Loss: 3.4610921144485474, Final Batch Loss: 1.5155534744262695\n",
      "Epoch 1823, Loss: 1.9706139713525772, Final Batch Loss: 0.07759423553943634\n",
      "Epoch 1824, Loss: 3.380473554134369, Final Batch Loss: 1.4352765083312988\n",
      "Epoch 1825, Loss: 2.9174287915229797, Final Batch Loss: 0.8868704438209534\n",
      "Epoch 1826, Loss: 3.745226800441742, Final Batch Loss: 1.7931588888168335\n",
      "Epoch 1827, Loss: 1.834730769507587, Final Batch Loss: 0.010825241915881634\n",
      "Epoch 1828, Loss: 1.9443589113652706, Final Batch Loss: 0.0444958470761776\n",
      "Epoch 1829, Loss: 1.869316777214408, Final Batch Loss: 0.024357816204428673\n",
      "Epoch 1830, Loss: 2.535588264465332, Final Batch Loss: 0.6410987973213196\n",
      "Epoch 1831, Loss: 2.620642304420471, Final Batch Loss: 0.6724371314048767\n",
      "Epoch 1832, Loss: 2.4954264760017395, Final Batch Loss: 0.526268720626831\n",
      "Epoch 1833, Loss: 2.6454862356185913, Final Batch Loss: 0.8253695368766785\n",
      "Epoch 1834, Loss: 2.8931814432144165, Final Batch Loss: 0.9774664044380188\n",
      "Epoch 1835, Loss: 2.2707513868808746, Final Batch Loss: 0.3251315653324127\n",
      "Epoch 1836, Loss: 2.6880182027816772, Final Batch Loss: 0.7955950498580933\n",
      "Epoch 1837, Loss: 2.4173914790153503, Final Batch Loss: 0.5001322031021118\n",
      "Epoch 1838, Loss: 2.6565454602241516, Final Batch Loss: 0.7944034934043884\n",
      "Epoch 1839, Loss: 2.1364974677562714, Final Batch Loss: 0.1945161521434784\n",
      "Epoch 1840, Loss: 1.9154466930776834, Final Batch Loss: 0.02637499012053013\n",
      "Epoch 1841, Loss: 1.8376114340499043, Final Batch Loss: 0.008152422495186329\n",
      "Epoch 1842, Loss: 3.7016014456748962, Final Batch Loss: 1.8234949111938477\n",
      "Epoch 1843, Loss: 2.7764472365379333, Final Batch Loss: 0.8777374625205994\n",
      "Epoch 1844, Loss: 2.414674073457718, Final Batch Loss: 0.41778799891471863\n",
      "Epoch 1845, Loss: 1.9604018609970808, Final Batch Loss: 0.015760032460093498\n",
      "Epoch 1846, Loss: 2.001403830945492, Final Batch Loss: 0.07256486266851425\n",
      "Epoch 1847, Loss: 3.0016244649887085, Final Batch Loss: 1.0387635231018066\n",
      "Epoch 1848, Loss: 2.773164987564087, Final Batch Loss: 0.87510746717453\n",
      "Epoch 1849, Loss: 4.019051671028137, Final Batch Loss: 2.077960729598999\n",
      "Epoch 1850, Loss: 2.5012585520744324, Final Batch Loss: 0.641119658946991\n",
      "Epoch 1851, Loss: 3.5601797103881836, Final Batch Loss: 1.5664454698562622\n",
      "Epoch 1852, Loss: 2.8680192828178406, Final Batch Loss: 0.9190161824226379\n",
      "Epoch 1853, Loss: 5.148665249347687, Final Batch Loss: 3.2588396072387695\n",
      "Epoch 1854, Loss: 2.302920550107956, Final Batch Loss: 0.41942211985588074\n",
      "Epoch 1855, Loss: 3.0171427130699158, Final Batch Loss: 1.0063178539276123\n",
      "Epoch 1856, Loss: 7.447660803794861, Final Batch Loss: 5.417591094970703\n",
      "Epoch 1857, Loss: 2.0037901912728557, Final Batch Loss: 0.00013028726971242577\n",
      "Epoch 1858, Loss: 2.071991838514805, Final Batch Loss: 0.07218185812234879\n",
      "Epoch 1859, Loss: 3.4651042222976685, Final Batch Loss: 1.3726561069488525\n",
      "Epoch 1860, Loss: 2.2324950620532036, Final Batch Loss: 0.0796055719256401\n",
      "Epoch 1861, Loss: 2.144952625967562, Final Batch Loss: 0.0074797580018639565\n",
      "Epoch 1862, Loss: 3.0811866521835327, Final Batch Loss: 1.0535483360290527\n",
      "Epoch 1863, Loss: 3.133551597595215, Final Batch Loss: 1.1810965538024902\n",
      "Epoch 1864, Loss: 2.0727572843898088, Final Batch Loss: 0.002831618534401059\n",
      "Epoch 1865, Loss: 2.0787902995944023, Final Batch Loss: 0.09065716713666916\n",
      "Epoch 1866, Loss: 1.9354190789163113, Final Batch Loss: 0.04838120564818382\n",
      "Epoch 1867, Loss: 1.9406782127916813, Final Batch Loss: 0.004175160080194473\n",
      "Epoch 1868, Loss: 2.0729278549551964, Final Batch Loss: 0.09447278827428818\n",
      "Epoch 1869, Loss: 2.9911404848098755, Final Batch Loss: 1.0372081995010376\n",
      "Epoch 1870, Loss: 3.498344123363495, Final Batch Loss: 1.6235404014587402\n",
      "Epoch 1871, Loss: 1.9048723275773227, Final Batch Loss: 0.003911464940756559\n",
      "Epoch 1872, Loss: 3.759440302848816, Final Batch Loss: 1.7057907581329346\n",
      "Epoch 1873, Loss: 2.0554349422454834, Final Batch Loss: 0.1400884985923767\n",
      "Epoch 1874, Loss: 2.0615529492497444, Final Batch Loss: 0.09249366074800491\n",
      "Epoch 1875, Loss: 2.403272867202759, Final Batch Loss: 0.3880632519721985\n",
      "Epoch 1876, Loss: 2.151493579149246, Final Batch Loss: 0.12025877833366394\n",
      "Epoch 1877, Loss: 1.9832508768886328, Final Batch Loss: 0.010094424709677696\n",
      "Epoch 1878, Loss: 4.33126300573349, Final Batch Loss: 2.356182336807251\n",
      "Epoch 1879, Loss: 3.4087958931922913, Final Batch Loss: 1.4218708276748657\n",
      "Epoch 1880, Loss: 2.3211648762226105, Final Batch Loss: 0.4003200829029083\n",
      "Epoch 1881, Loss: 1.9220278594875708, Final Batch Loss: 0.0008054111385717988\n",
      "Epoch 1882, Loss: 3.8181630969047546, Final Batch Loss: 1.802879810333252\n",
      "Epoch 1883, Loss: 3.224452316761017, Final Batch Loss: 1.2986167669296265\n",
      "Epoch 1884, Loss: 3.3816677927970886, Final Batch Loss: 1.451446771621704\n",
      "Epoch 1885, Loss: 2.0944744050502777, Final Batch Loss: 0.08301368355751038\n",
      "Epoch 1886, Loss: 3.1022220849990845, Final Batch Loss: 1.1660045385360718\n",
      "Epoch 1887, Loss: 4.254632413387299, Final Batch Loss: 2.309204339981079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888, Loss: 4.180751442909241, Final Batch Loss: 2.197031021118164\n",
      "Epoch 1889, Loss: 2.6054535508155823, Final Batch Loss: 0.6281539797782898\n",
      "Epoch 1890, Loss: 2.385814666748047, Final Batch Loss: 0.32857149839401245\n",
      "Epoch 1891, Loss: 2.107770211994648, Final Batch Loss: 0.04459310322999954\n",
      "Epoch 1892, Loss: 3.358408212661743, Final Batch Loss: 1.396224021911621\n",
      "Epoch 1893, Loss: 2.315685957670212, Final Batch Loss: 0.31307801604270935\n",
      "Epoch 1894, Loss: 3.296084761619568, Final Batch Loss: 1.2398725748062134\n",
      "Epoch 1895, Loss: 2.053317990154028, Final Batch Loss: 0.02033248171210289\n",
      "Epoch 1896, Loss: 2.0207848362624645, Final Batch Loss: 0.017385702580213547\n",
      "Epoch 1897, Loss: 2.655081868171692, Final Batch Loss: 0.6489207148551941\n",
      "Epoch 1898, Loss: 3.9049667716026306, Final Batch Loss: 1.943164348602295\n",
      "Epoch 1899, Loss: 2.0216580517590046, Final Batch Loss: 0.048139024525880814\n",
      "Epoch 1900, Loss: 2.6363445520401, Final Batch Loss: 0.6761001348495483\n",
      "Epoch 1901, Loss: 3.6358569860458374, Final Batch Loss: 1.703078269958496\n",
      "Epoch 1902, Loss: 2.2036917954683304, Final Batch Loss: 0.21943892538547516\n",
      "Epoch 1903, Loss: 1.9516756534576416, Final Batch Loss: 0.004854440689086914\n",
      "Epoch 1904, Loss: 3.2697070837020874, Final Batch Loss: 1.2758305072784424\n",
      "Epoch 1905, Loss: 2.6080355048179626, Final Batch Loss: 0.6982446908950806\n",
      "Epoch 1906, Loss: 3.405663847923279, Final Batch Loss: 1.4704864025115967\n",
      "Epoch 1907, Loss: 3.141837954521179, Final Batch Loss: 1.2805778980255127\n",
      "Epoch 1908, Loss: 2.0857984870672226, Final Batch Loss: 0.14743642508983612\n",
      "Epoch 1909, Loss: 1.9535594191402197, Final Batch Loss: 0.030559977516531944\n",
      "Epoch 1910, Loss: 3.2975624799728394, Final Batch Loss: 1.3499428033828735\n",
      "Epoch 1911, Loss: 3.171491026878357, Final Batch Loss: 1.3343546390533447\n",
      "Epoch 1912, Loss: 2.0543709993362427, Final Batch Loss: 0.19467473030090332\n",
      "Epoch 1913, Loss: 3.542120099067688, Final Batch Loss: 1.6179916858673096\n",
      "Epoch 1914, Loss: 2.0118777453899384, Final Batch Loss: 0.08080634474754333\n",
      "Epoch 1915, Loss: 1.9632966462522745, Final Batch Loss: 0.024370962753891945\n",
      "Epoch 1916, Loss: 3.2073997259140015, Final Batch Loss: 1.144132137298584\n",
      "Epoch 1917, Loss: 2.9350258708000183, Final Batch Loss: 0.9617801308631897\n",
      "Epoch 1918, Loss: 2.0287862718105316, Final Batch Loss: 0.14463523030281067\n",
      "Epoch 1919, Loss: 2.0643520802259445, Final Batch Loss: 0.1161220520734787\n",
      "Epoch 1920, Loss: 2.4011551439762115, Final Batch Loss: 0.4820050895214081\n",
      "Epoch 1921, Loss: 1.917706660926342, Final Batch Loss: 0.09612786024808884\n",
      "Epoch 1922, Loss: 4.0346702337265015, Final Batch Loss: 2.119736671447754\n",
      "Epoch 1923, Loss: 1.9688527658581734, Final Batch Loss: 0.09084714204072952\n",
      "Epoch 1924, Loss: 2.1958824396133423, Final Batch Loss: 0.3509445786476135\n",
      "Epoch 1925, Loss: 3.0537278056144714, Final Batch Loss: 1.2028969526290894\n",
      "Epoch 1926, Loss: 1.8847275232255924, Final Batch Loss: 0.00016973962192423642\n",
      "Epoch 1927, Loss: 1.9057125896215439, Final Batch Loss: 0.05160324275493622\n",
      "Epoch 1928, Loss: 2.014976292848587, Final Batch Loss: 0.13441339135169983\n",
      "Epoch 1929, Loss: 3.6559518575668335, Final Batch Loss: 1.8586002588272095\n",
      "Epoch 1930, Loss: 1.98801539093256, Final Batch Loss: 0.1130010262131691\n",
      "Epoch 1931, Loss: 2.903836488723755, Final Batch Loss: 1.0389668941497803\n",
      "Epoch 1932, Loss: 2.436734914779663, Final Batch Loss: 0.541081428527832\n",
      "Epoch 1933, Loss: 3.182643234729767, Final Batch Loss: 1.2949376106262207\n",
      "Epoch 1934, Loss: 3.6270253658294678, Final Batch Loss: 1.8004220724105835\n",
      "Epoch 1935, Loss: 1.8800450935959816, Final Batch Loss: 0.009648121893405914\n",
      "Epoch 1936, Loss: 3.070454776287079, Final Batch Loss: 1.2010676860809326\n",
      "Epoch 1937, Loss: 1.9911319198727142, Final Batch Loss: 0.00028796817059628665\n",
      "Epoch 1938, Loss: 2.0363748595118523, Final Batch Loss: 0.06346064060926437\n",
      "Epoch 1939, Loss: 2.0791456773877144, Final Batch Loss: 0.10665876418352127\n",
      "Epoch 1940, Loss: 2.022842299193144, Final Batch Loss: 0.056472014635801315\n",
      "Epoch 1941, Loss: 3.065570116043091, Final Batch Loss: 1.1668232679367065\n",
      "Epoch 1942, Loss: 2.0650204718112946, Final Batch Loss: 0.15921255946159363\n",
      "Epoch 1943, Loss: 1.8710197247564793, Final Batch Loss: 0.035030070692300797\n",
      "Epoch 1944, Loss: 2.182390049099922, Final Batch Loss: 0.24418796598911285\n",
      "Epoch 1945, Loss: 2.8022043704986572, Final Batch Loss: 0.90500807762146\n",
      "Epoch 1946, Loss: 1.945154865970835, Final Batch Loss: 0.002961775055155158\n",
      "Epoch 1947, Loss: 1.9167995676398277, Final Batch Loss: 0.02764751762151718\n",
      "Epoch 1948, Loss: 1.8156452290713787, Final Batch Loss: 0.039476942270994186\n",
      "Epoch 1949, Loss: 2.301778018474579, Final Batch Loss: 0.4980772137641907\n",
      "Epoch 1950, Loss: 2.57618248462677, Final Batch Loss: 0.775361180305481\n",
      "Epoch 1951, Loss: 3.06695294380188, Final Batch Loss: 1.2394828796386719\n",
      "Epoch 1952, Loss: 3.734765410423279, Final Batch Loss: 1.8915128707885742\n",
      "Epoch 1953, Loss: 3.4833750128746033, Final Batch Loss: 1.6819361448287964\n",
      "Epoch 1954, Loss: 1.8803106993436813, Final Batch Loss: 0.03694818913936615\n",
      "Epoch 1955, Loss: 1.9787617325782776, Final Batch Loss: 0.14577239751815796\n",
      "Epoch 1956, Loss: 3.378254234790802, Final Batch Loss: 1.5011465549468994\n",
      "Epoch 1957, Loss: 2.7649712562561035, Final Batch Loss: 0.8764476180076599\n",
      "Epoch 1958, Loss: 1.8626435361802578, Final Batch Loss: 0.04051154479384422\n",
      "Epoch 1959, Loss: 3.560985743999481, Final Batch Loss: 1.7303314208984375\n",
      "Epoch 1960, Loss: 1.90834391862154, Final Batch Loss: 0.03650946170091629\n",
      "Epoch 1961, Loss: 1.9020185538684018, Final Batch Loss: 0.0004741021548397839\n",
      "Epoch 1962, Loss: 2.4578131437301636, Final Batch Loss: 0.498531699180603\n",
      "Epoch 1963, Loss: 1.9430476408451796, Final Batch Loss: 0.0021002870053052902\n",
      "Epoch 1964, Loss: 3.269365131855011, Final Batch Loss: 1.4170151948928833\n",
      "Epoch 1965, Loss: 1.9680899027734995, Final Batch Loss: 0.024741435423493385\n",
      "Epoch 1966, Loss: 2.53525048494339, Final Batch Loss: 0.7317479848861694\n",
      "Epoch 1967, Loss: 2.737785220146179, Final Batch Loss: 0.9179496765136719\n",
      "Epoch 1968, Loss: 1.8327607495011762, Final Batch Loss: 0.0012460333527997136\n",
      "Epoch 1969, Loss: 3.0575125217437744, Final Batch Loss: 1.1139850616455078\n",
      "Epoch 1970, Loss: 2.672565996646881, Final Batch Loss: 0.7941713929176331\n",
      "Epoch 1971, Loss: 1.9515047371387482, Final Batch Loss: 0.12987837195396423\n",
      "Epoch 1972, Loss: 1.8788634641095996, Final Batch Loss: 0.008273730985820293\n",
      "Epoch 1973, Loss: 1.9717208743095398, Final Batch Loss: 0.10866248607635498\n",
      "Epoch 1974, Loss: 3.2290419340133667, Final Batch Loss: 1.394855260848999\n",
      "Epoch 1975, Loss: 3.530313193798065, Final Batch Loss: 1.7431917190551758\n",
      "Epoch 1976, Loss: 1.9030383708886802, Final Batch Loss: 0.007587778847664595\n",
      "Epoch 1977, Loss: 1.885875005275011, Final Batch Loss: 0.028222043067216873\n",
      "Epoch 1978, Loss: 1.8663900028914213, Final Batch Loss: 0.017315758392214775\n",
      "Epoch 1979, Loss: 2.0142904818058014, Final Batch Loss: 0.15842577815055847\n",
      "Epoch 1980, Loss: 2.415179193019867, Final Batch Loss: 0.5435268878936768\n",
      "Epoch 1981, Loss: 3.344348728656769, Final Batch Loss: 1.4114845991134644\n",
      "Epoch 1982, Loss: 2.7604721784591675, Final Batch Loss: 0.8568386435508728\n",
      "Epoch 1983, Loss: 3.136551320552826, Final Batch Loss: 1.2568674087524414\n",
      "Epoch 1984, Loss: 2.2652924060821533, Final Batch Loss: 0.4210829734802246\n",
      "Epoch 1985, Loss: 2.648914873600006, Final Batch Loss: 0.7301367521286011\n",
      "Epoch 1986, Loss: 2.5945562720298767, Final Batch Loss: 0.7054933309555054\n",
      "Epoch 1987, Loss: 1.8875235840678215, Final Batch Loss: 0.03945379704236984\n",
      "Epoch 1988, Loss: 2.314431756734848, Final Batch Loss: 0.4205292761325836\n",
      "Epoch 1989, Loss: 2.1081255972385406, Final Batch Loss: 0.18729612231254578\n",
      "Epoch 1990, Loss: 1.9946015402674675, Final Batch Loss: 0.008797340095043182\n",
      "Epoch 1991, Loss: 2.015699210896855, Final Batch Loss: 0.0004818470624741167\n",
      "Epoch 1992, Loss: 2.8120816946029663, Final Batch Loss: 0.9172049164772034\n",
      "Epoch 1993, Loss: 3.4354814887046814, Final Batch Loss: 1.6259701251983643\n",
      "Epoch 1994, Loss: 1.956611655652523, Final Batch Loss: 0.10573729127645493\n",
      "Epoch 1995, Loss: 2.9599703550338745, Final Batch Loss: 1.0657484531402588\n",
      "Epoch 1996, Loss: 2.643193483352661, Final Batch Loss: 0.7026252746582031\n",
      "Epoch 1997, Loss: 4.724418461322784, Final Batch Loss: 2.9540774822235107\n",
      "Epoch 1998, Loss: 3.014727473258972, Final Batch Loss: 1.1133053302764893\n",
      "Epoch 1999, Loss: 1.8945919014513493, Final Batch Loss: 0.01912662759423256\n",
      "Epoch 2000, Loss: 2.677493989467621, Final Batch Loss: 0.7786962985992432\n",
      "Epoch 2001, Loss: 3.516111373901367, Final Batch Loss: 1.532062292098999\n",
      "Epoch 2002, Loss: 2.079267457127571, Final Batch Loss: 0.025259748101234436\n",
      "Epoch 2003, Loss: 2.671121120452881, Final Batch Loss: 0.7343605756759644\n",
      "Epoch 2004, Loss: 2.0748187601566315, Final Batch Loss: 0.1651478111743927\n",
      "Epoch 2005, Loss: 4.732268750667572, Final Batch Loss: 2.776909828186035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2006, Loss: 2.0482292473316193, Final Batch Loss: 0.16373488306999207\n",
      "Epoch 2007, Loss: 2.3722533583641052, Final Batch Loss: 0.3189166784286499\n",
      "Epoch 2008, Loss: 2.319922409951687, Final Batch Loss: 0.11422916501760483\n",
      "Epoch 2009, Loss: 3.100479483604431, Final Batch Loss: 0.9387730956077576\n",
      "Epoch 2010, Loss: 2.058483181404881, Final Batch Loss: 0.00035089056473225355\n",
      "Epoch 2011, Loss: 2.6028648018836975, Final Batch Loss: 0.6297672986984253\n",
      "Epoch 2012, Loss: 3.256958484649658, Final Batch Loss: 1.3339546918869019\n",
      "Epoch 2013, Loss: 1.8919578503118828, Final Batch Loss: 0.0015998195158317685\n",
      "Epoch 2014, Loss: 4.066338300704956, Final Batch Loss: 2.1234958171844482\n",
      "Epoch 2015, Loss: 1.9623276069760323, Final Batch Loss: 0.12294770032167435\n",
      "Epoch 2016, Loss: 2.3992239832878113, Final Batch Loss: 0.5038133263587952\n",
      "Epoch 2017, Loss: 2.9873088598251343, Final Batch Loss: 1.0602912902832031\n",
      "Epoch 2018, Loss: 2.5313960909843445, Final Batch Loss: 0.6494694948196411\n",
      "Epoch 2019, Loss: 2.587265431880951, Final Batch Loss: 0.601923406124115\n",
      "Epoch 2020, Loss: 1.9534707111306489, Final Batch Loss: 0.0013777059502899647\n",
      "Epoch 2021, Loss: 1.9182399772107601, Final Batch Loss: 0.060675110667943954\n",
      "Epoch 2022, Loss: 3.058708071708679, Final Batch Loss: 1.1489555835723877\n",
      "Epoch 2023, Loss: 1.874722980428487, Final Batch Loss: 0.004453383851796389\n",
      "Epoch 2024, Loss: 1.8648452752968296, Final Batch Loss: 0.0011454218765720725\n",
      "Epoch 2025, Loss: 2.7523237466812134, Final Batch Loss: 0.8627398014068604\n",
      "Epoch 2026, Loss: 2.08070969581604, Final Batch Loss: 0.19745975732803345\n",
      "Epoch 2027, Loss: 2.7693801522254944, Final Batch Loss: 0.9526982307434082\n",
      "Epoch 2028, Loss: 2.814319670200348, Final Batch Loss: 1.0191770792007446\n",
      "Epoch 2029, Loss: 2.902582287788391, Final Batch Loss: 1.0941805839538574\n",
      "Epoch 2030, Loss: 1.8907956678594928, Final Batch Loss: 0.00028224775451235473\n",
      "Epoch 2031, Loss: 2.3816911578178406, Final Batch Loss: 0.4886842966079712\n",
      "Epoch 2032, Loss: 4.167645335197449, Final Batch Loss: 2.2474365234375\n",
      "Epoch 2033, Loss: 3.2817238569259644, Final Batch Loss: 1.3752734661102295\n",
      "Epoch 2034, Loss: 3.609307050704956, Final Batch Loss: 1.8348236083984375\n",
      "Epoch 2035, Loss: 2.49393492937088, Final Batch Loss: 0.5650604367256165\n",
      "Epoch 2036, Loss: 1.9395690187811852, Final Batch Loss: 0.09284397214651108\n",
      "Epoch 2037, Loss: 2.8078407049179077, Final Batch Loss: 0.9039874076843262\n",
      "Epoch 2038, Loss: 2.2460951805114746, Final Batch Loss: 0.45098429918289185\n",
      "Epoch 2039, Loss: 1.9187935516238213, Final Batch Loss: 0.019001714885234833\n",
      "Epoch 2040, Loss: 3.091636538505554, Final Batch Loss: 1.1681385040283203\n",
      "Epoch 2041, Loss: 1.9766997061669827, Final Batch Loss: 0.02300327643752098\n",
      "Epoch 2042, Loss: 2.075028821825981, Final Batch Loss: 0.11469100415706635\n",
      "Epoch 2043, Loss: 2.119715541601181, Final Batch Loss: 0.14630022644996643\n",
      "Epoch 2044, Loss: 1.9458234459161758, Final Batch Loss: 0.06459154188632965\n",
      "Epoch 2045, Loss: 1.9509958699345589, Final Batch Loss: 0.11190802603960037\n",
      "Epoch 2046, Loss: 1.8953460901975632, Final Batch Loss: 0.06329034268856049\n",
      "Epoch 2047, Loss: 2.709897756576538, Final Batch Loss: 0.9236725568771362\n",
      "Epoch 2048, Loss: 1.8483262895606458, Final Batch Loss: 0.005438887979835272\n",
      "Epoch 2049, Loss: 3.8320323824882507, Final Batch Loss: 1.9532742500305176\n",
      "Epoch 2050, Loss: 2.715062975883484, Final Batch Loss: 0.8924625515937805\n",
      "Epoch 2051, Loss: 1.9638707730919123, Final Batch Loss: 0.018766352906823158\n",
      "Epoch 2052, Loss: 1.935448333621025, Final Batch Loss: 0.1265343278646469\n",
      "Epoch 2053, Loss: 2.929252564907074, Final Batch Loss: 1.0126558542251587\n",
      "Epoch 2054, Loss: 2.2084383964538574, Final Batch Loss: 0.330294668674469\n",
      "Epoch 2055, Loss: 1.8775436819996685, Final Batch Loss: 0.0023935975041240454\n",
      "Epoch 2056, Loss: 1.9009230006486177, Final Batch Loss: 0.029831992462277412\n",
      "Epoch 2057, Loss: 3.7366912364959717, Final Batch Loss: 1.8870911598205566\n",
      "Epoch 2058, Loss: 2.956522285938263, Final Batch Loss: 1.1304975748062134\n",
      "Epoch 2059, Loss: 3.1122854948043823, Final Batch Loss: 1.2725193500518799\n",
      "Epoch 2060, Loss: 1.8179262513294816, Final Batch Loss: 0.005204462446272373\n",
      "Epoch 2061, Loss: 2.286459058523178, Final Batch Loss: 0.40824761986732483\n",
      "Epoch 2062, Loss: 2.217013269662857, Final Batch Loss: 0.35879477858543396\n",
      "Epoch 2063, Loss: 4.34125280380249, Final Batch Loss: 2.5545401573181152\n",
      "Epoch 2064, Loss: 2.8947237730026245, Final Batch Loss: 1.0769619941711426\n",
      "Epoch 2065, Loss: 5.496016502380371, Final Batch Loss: 3.633090019226074\n",
      "Epoch 2066, Loss: 3.5986298322677612, Final Batch Loss: 1.6654407978057861\n",
      "Epoch 2067, Loss: 3.9392098784446716, Final Batch Loss: 1.6126734018325806\n",
      "Epoch 2068, Loss: 3.60431170463562, Final Batch Loss: 1.1644445657730103\n",
      "Epoch 2069, Loss: 4.177893698215485, Final Batch Loss: 1.6602474451065063\n",
      "Epoch 2070, Loss: 2.430219709640369, Final Batch Loss: 0.0024159548338502645\n",
      "Epoch 2071, Loss: 2.410541519522667, Final Batch Loss: 0.1970032900571823\n",
      "Epoch 2072, Loss: 2.4880049526691437, Final Batch Loss: 0.14193227887153625\n",
      "Epoch 2073, Loss: 5.892054200172424, Final Batch Loss: 3.795424461364746\n",
      "Epoch 2074, Loss: 2.820918619632721, Final Batch Loss: 0.6846575736999512\n",
      "Epoch 2075, Loss: 3.462840735912323, Final Batch Loss: 1.3553855419158936\n",
      "Epoch 2076, Loss: 2.1952525675296783, Final Batch Loss: 0.15942928194999695\n",
      "Epoch 2077, Loss: 1.9683274030685425, Final Batch Loss: 0.05875074863433838\n",
      "Epoch 2078, Loss: 3.8372806310653687, Final Batch Loss: 1.8714793920516968\n",
      "Epoch 2079, Loss: 1.9966074973344803, Final Batch Loss: 0.17996592819690704\n",
      "Epoch 2080, Loss: 3.9235552549362183, Final Batch Loss: 2.01355242729187\n",
      "Epoch 2081, Loss: 1.9761170148849487, Final Batch Loss: 0.1802951693534851\n",
      "Epoch 2082, Loss: 2.6724676489830017, Final Batch Loss: 0.7426955103874207\n",
      "Epoch 2083, Loss: 2.1458030939102173, Final Batch Loss: 0.2699834108352661\n",
      "Epoch 2084, Loss: 2.895537793636322, Final Batch Loss: 1.0699329376220703\n",
      "Epoch 2085, Loss: 3.2866820693016052, Final Batch Loss: 1.3643853664398193\n",
      "Epoch 2086, Loss: 2.0276730940677226, Final Batch Loss: 0.003372578416019678\n",
      "Epoch 2087, Loss: 4.211066782474518, Final Batch Loss: 2.3259341716766357\n",
      "Epoch 2088, Loss: 2.217654138803482, Final Batch Loss: 0.28421810269355774\n",
      "Epoch 2089, Loss: 3.268272042274475, Final Batch Loss: 1.3415839672088623\n",
      "Epoch 2090, Loss: 2.967579662799835, Final Batch Loss: 0.9762032628059387\n",
      "Epoch 2091, Loss: 2.833970844745636, Final Batch Loss: 0.9157452583312988\n",
      "Epoch 2092, Loss: 2.950541079044342, Final Batch Loss: 1.0431835651397705\n",
      "Epoch 2093, Loss: 2.246809095144272, Final Batch Loss: 0.3146776854991913\n",
      "Epoch 2094, Loss: 2.541911005973816, Final Batch Loss: 0.5591826438903809\n",
      "Epoch 2095, Loss: 2.6691353917121887, Final Batch Loss: 0.7614144682884216\n",
      "Epoch 2096, Loss: 2.343482106924057, Final Batch Loss: 0.49744632840156555\n",
      "Epoch 2097, Loss: 2.9226233959198, Final Batch Loss: 0.9804590940475464\n",
      "Epoch 2098, Loss: 1.9325162786990404, Final Batch Loss: 0.02584064193069935\n",
      "Epoch 2099, Loss: 1.9066613297909498, Final Batch Loss: 0.025936244055628777\n",
      "Epoch 2100, Loss: 2.141672730445862, Final Batch Loss: 0.2807684540748596\n",
      "Epoch 2101, Loss: 3.469670593738556, Final Batch Loss: 1.5968183279037476\n",
      "Epoch 2102, Loss: 3.112112522125244, Final Batch Loss: 1.2777369022369385\n",
      "Epoch 2103, Loss: 2.146979570388794, Final Batch Loss: 0.28930914402008057\n",
      "Epoch 2104, Loss: 3.5817984342575073, Final Batch Loss: 1.7292481660842896\n",
      "Epoch 2105, Loss: 3.9800471663475037, Final Batch Loss: 2.1245110034942627\n",
      "Epoch 2106, Loss: 1.8607608899474144, Final Batch Loss: 0.06116100400686264\n",
      "Epoch 2107, Loss: 1.8826684542000294, Final Batch Loss: 0.034799832850694656\n",
      "Epoch 2108, Loss: 2.086040437221527, Final Batch Loss: 0.13505536317825317\n",
      "Epoch 2109, Loss: 2.859381914138794, Final Batch Loss: 1.0192115306854248\n",
      "Epoch 2110, Loss: 3.481509804725647, Final Batch Loss: 1.5980931520462036\n",
      "Epoch 2111, Loss: 2.1840992867946625, Final Batch Loss: 0.32534536719322205\n",
      "Epoch 2112, Loss: 5.223143458366394, Final Batch Loss: 3.3582069873809814\n",
      "Epoch 2113, Loss: 1.954066626727581, Final Batch Loss: 0.0761217400431633\n",
      "Epoch 2114, Loss: 2.502884030342102, Final Batch Loss: 0.6032964587211609\n",
      "Epoch 2115, Loss: 5.759373128414154, Final Batch Loss: 3.7880170345306396\n",
      "Epoch 2116, Loss: 3.1065425872802734, Final Batch Loss: 1.0455963611602783\n",
      "Epoch 2117, Loss: 2.274462103843689, Final Batch Loss: 0.09889715909957886\n",
      "Epoch 2118, Loss: 5.805717825889587, Final Batch Loss: 3.592968225479126\n",
      "Epoch 2119, Loss: 2.561247982084751, Final Batch Loss: 0.11364177614450455\n",
      "Epoch 2120, Loss: 2.6166848111897707, Final Batch Loss: 0.013144390657544136\n",
      "Epoch 2121, Loss: 2.6895152975339442, Final Batch Loss: 0.0008398343343287706\n",
      "Epoch 2122, Loss: 3.328793942928314, Final Batch Loss: 0.84005206823349\n",
      "Epoch 2123, Loss: 2.4931120797991753, Final Batch Loss: 0.12042777985334396\n",
      "Epoch 2124, Loss: 3.8241576552391052, Final Batch Loss: 1.5567816495895386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2125, Loss: 2.617955595254898, Final Batch Loss: 0.4751370847225189\n",
      "Epoch 2126, Loss: 2.658328413963318, Final Batch Loss: 0.42152488231658936\n",
      "Epoch 2127, Loss: 3.164253354072571, Final Batch Loss: 0.9674227237701416\n",
      "Epoch 2128, Loss: 2.1589511279016733, Final Batch Loss: 0.015745246782898903\n",
      "Epoch 2129, Loss: 2.2079661106690764, Final Batch Loss: 0.010525665245950222\n",
      "Epoch 2130, Loss: 2.248706690967083, Final Batch Loss: 0.10939674824476242\n",
      "Epoch 2131, Loss: 5.099120616912842, Final Batch Loss: 3.010509490966797\n",
      "Epoch 2132, Loss: 2.1208984218537807, Final Batch Loss: 0.050953980535268784\n",
      "Epoch 2133, Loss: 2.7502530813217163, Final Batch Loss: 0.8137174248695374\n",
      "Epoch 2134, Loss: 1.9416232481598854, Final Batch Loss: 0.1055370345711708\n",
      "Epoch 2135, Loss: 4.197250723838806, Final Batch Loss: 2.246427059173584\n",
      "Epoch 2136, Loss: 2.146346792578697, Final Batch Loss: 0.24626784026622772\n",
      "Epoch 2137, Loss: 1.9274125173687935, Final Batch Loss: 0.03673482686281204\n",
      "Epoch 2138, Loss: 2.872221827507019, Final Batch Loss: 0.9636406302452087\n",
      "Epoch 2139, Loss: 2.0577034428715706, Final Batch Loss: 0.065566785633564\n",
      "Epoch 2140, Loss: 1.9665284976363182, Final Batch Loss: 0.07701637595891953\n",
      "Epoch 2141, Loss: 2.6395809650421143, Final Batch Loss: 0.803734540939331\n",
      "Epoch 2142, Loss: 2.674417495727539, Final Batch Loss: 0.818614661693573\n",
      "Epoch 2143, Loss: 2.322532683610916, Final Batch Loss: 0.4319550693035126\n",
      "Epoch 2144, Loss: 1.9513976834714413, Final Batch Loss: 0.036899592727422714\n",
      "Epoch 2145, Loss: 1.931220706552267, Final Batch Loss: 0.025416072458028793\n",
      "Epoch 2146, Loss: 2.773977756500244, Final Batch Loss: 0.9884971976280212\n",
      "Epoch 2147, Loss: 2.8217859268188477, Final Batch Loss: 0.9823336005210876\n",
      "Epoch 2148, Loss: 3.26273113489151, Final Batch Loss: 1.3970175981521606\n",
      "Epoch 2149, Loss: 2.469111680984497, Final Batch Loss: 0.6084107160568237\n",
      "Epoch 2150, Loss: 2.5752081274986267, Final Batch Loss: 0.7397926449775696\n",
      "Epoch 2151, Loss: 3.0747217535972595, Final Batch Loss: 1.2412962913513184\n",
      "Epoch 2152, Loss: 1.9064780473709106, Final Batch Loss: 0.03817039728164673\n",
      "Epoch 2153, Loss: 1.8845284457784146, Final Batch Loss: 0.0015128131490200758\n",
      "Epoch 2154, Loss: 1.835110042244196, Final Batch Loss: 0.011311803013086319\n",
      "Epoch 2155, Loss: 2.0736263394355774, Final Batch Loss: 0.2134723663330078\n",
      "Epoch 2156, Loss: 1.9102783128619194, Final Batch Loss: 0.11018877476453781\n",
      "Epoch 2157, Loss: 3.953232228755951, Final Batch Loss: 2.1911847591400146\n",
      "Epoch 2158, Loss: 1.8030020501464605, Final Batch Loss: 0.026592781767249107\n",
      "Epoch 2159, Loss: 2.7371506094932556, Final Batch Loss: 0.8524267077445984\n",
      "Epoch 2160, Loss: 1.8348281159996986, Final Batch Loss: 0.07300911098718643\n",
      "Epoch 2161, Loss: 2.3667136430740356, Final Batch Loss: 0.5119512677192688\n",
      "Epoch 2162, Loss: 1.8212024290114641, Final Batch Loss: 0.023042650893330574\n",
      "Epoch 2163, Loss: 2.2862164080142975, Final Batch Loss: 0.4149647057056427\n",
      "Epoch 2164, Loss: 2.924582779407501, Final Batch Loss: 1.1068713665008545\n",
      "Epoch 2165, Loss: 1.8732269927859306, Final Batch Loss: 0.08677392452955246\n",
      "Epoch 2166, Loss: 2.584802269935608, Final Batch Loss: 0.770263671875\n",
      "Epoch 2167, Loss: 4.0131853222846985, Final Batch Loss: 2.1815359592437744\n",
      "Epoch 2168, Loss: 1.8470316706225276, Final Batch Loss: 0.0038531599566340446\n",
      "Epoch 2169, Loss: 2.2931682765483856, Final Batch Loss: 0.35294464230537415\n",
      "Epoch 2170, Loss: 3.0120924711227417, Final Batch Loss: 1.1670238971710205\n",
      "Epoch 2171, Loss: 3.1813372373580933, Final Batch Loss: 1.3721542358398438\n",
      "Epoch 2172, Loss: 2.567412257194519, Final Batch Loss: 0.7222365140914917\n",
      "Epoch 2173, Loss: 6.8124149441719055, Final Batch Loss: 5.042452812194824\n",
      "Epoch 2174, Loss: 1.8359091226011515, Final Batch Loss: 0.018973642960190773\n",
      "Epoch 2175, Loss: 1.956745995907113, Final Batch Loss: 0.0023853916209191084\n",
      "Epoch 2176, Loss: 4.085031270980835, Final Batch Loss: 1.956897497177124\n",
      "Epoch 2177, Loss: 2.0387503150850534, Final Batch Loss: 0.00609823502600193\n",
      "Epoch 2178, Loss: 2.8842434883117676, Final Batch Loss: 0.876228928565979\n",
      "Epoch 2179, Loss: 3.1375197172164917, Final Batch Loss: 1.1298729181289673\n",
      "Epoch 2180, Loss: 1.9312690682709217, Final Batch Loss: 0.011112231761217117\n",
      "Epoch 2181, Loss: 2.4489974975585938, Final Batch Loss: 0.5724821090698242\n",
      "Epoch 2182, Loss: 2.047310035675764, Final Batch Loss: 0.05862484499812126\n",
      "Epoch 2183, Loss: 1.9409954184666276, Final Batch Loss: 0.011010014452040195\n",
      "Epoch 2184, Loss: 1.9805640149861574, Final Batch Loss: 0.015790658071637154\n",
      "Epoch 2185, Loss: 2.019023686647415, Final Batch Loss: 0.10913780331611633\n",
      "Epoch 2186, Loss: 1.9076649770140648, Final Batch Loss: 0.04510214179754257\n",
      "Epoch 2187, Loss: 1.9677834678441286, Final Batch Loss: 0.015693025663495064\n",
      "Epoch 2188, Loss: 2.2296858429908752, Final Batch Loss: 0.32764267921447754\n",
      "Epoch 2189, Loss: 2.964370369911194, Final Batch Loss: 1.1062300205230713\n",
      "Epoch 2190, Loss: 2.258652836084366, Final Batch Loss: 0.37139496207237244\n",
      "Epoch 2191, Loss: 3.1947168111801147, Final Batch Loss: 1.275876760482788\n",
      "Epoch 2192, Loss: 1.9642362892627716, Final Batch Loss: 0.08805301785469055\n",
      "Epoch 2193, Loss: 3.032472789287567, Final Batch Loss: 1.2244138717651367\n",
      "Epoch 2194, Loss: 1.8553711995482445, Final Batch Loss: 0.04373206943273544\n",
      "Epoch 2195, Loss: 1.9511601328849792, Final Batch Loss: 0.11142069101333618\n",
      "Epoch 2196, Loss: 1.7585165277123451, Final Batch Loss: 0.026142634451389313\n",
      "Epoch 2197, Loss: 1.8217629892751575, Final Batch Loss: 0.014071534387767315\n",
      "Epoch 2198, Loss: 1.8502326495945454, Final Batch Loss: 0.018634844571352005\n",
      "Epoch 2199, Loss: 2.0148923099040985, Final Batch Loss: 0.13591048121452332\n",
      "Epoch 2200, Loss: 1.852000979008153, Final Batch Loss: 0.0035949621815234423\n",
      "Epoch 2201, Loss: 1.793276690877974, Final Batch Loss: 0.0002694958820939064\n",
      "Epoch 2202, Loss: 1.7902949443086982, Final Batch Loss: 0.0029488196596503258\n",
      "Epoch 2203, Loss: 1.8789072632789612, Final Batch Loss: 0.0987393856048584\n",
      "Epoch 2204, Loss: 1.8263419214636087, Final Batch Loss: 0.019245559349656105\n",
      "Epoch 2205, Loss: 1.9045906960964203, Final Batch Loss: 0.055450648069381714\n",
      "Epoch 2206, Loss: 2.290365219116211, Final Batch Loss: 0.5068666338920593\n",
      "Epoch 2207, Loss: 4.313365459442139, Final Batch Loss: 2.548675298690796\n",
      "Epoch 2208, Loss: 2.822255551815033, Final Batch Loss: 1.0333893299102783\n",
      "Epoch 2209, Loss: 1.9424618035554886, Final Batch Loss: 0.10894443094730377\n",
      "Epoch 2210, Loss: 3.041360855102539, Final Batch Loss: 1.1772916316986084\n",
      "Epoch 2211, Loss: 2.168555647134781, Final Batch Loss: 0.3518294394016266\n",
      "Epoch 2212, Loss: 1.9183120280504227, Final Batch Loss: 0.11450763046741486\n",
      "Epoch 2213, Loss: 3.100894331932068, Final Batch Loss: 1.2805991172790527\n",
      "Epoch 2214, Loss: 2.7661589086055756, Final Batch Loss: 0.9927300214767456\n",
      "Epoch 2215, Loss: 2.509831666946411, Final Batch Loss: 0.6403522491455078\n",
      "Epoch 2216, Loss: 1.8530247807502747, Final Batch Loss: 0.0587921142578125\n",
      "Epoch 2217, Loss: 2.047510176897049, Final Batch Loss: 0.25599047541618347\n",
      "Epoch 2218, Loss: 1.7998429825529456, Final Batch Loss: 0.006222872994840145\n",
      "Epoch 2219, Loss: 1.786092790775001, Final Batch Loss: 0.003423902206122875\n",
      "Epoch 2220, Loss: 1.8307125344872475, Final Batch Loss: 0.07616714388132095\n",
      "Epoch 2221, Loss: 1.7326652770861983, Final Batch Loss: 0.009920931421220303\n",
      "Epoch 2222, Loss: 1.8830372616648674, Final Batch Loss: 0.04853134602308273\n",
      "Epoch 2223, Loss: 1.8563334718346596, Final Batch Loss: 0.05003241449594498\n",
      "Epoch 2224, Loss: 3.3712069988250732, Final Batch Loss: 1.5454347133636475\n",
      "Epoch 2225, Loss: 1.96904556453228, Final Batch Loss: 0.20706187188625336\n",
      "Epoch 2226, Loss: 1.868002738803625, Final Batch Loss: 0.049653615802526474\n",
      "Epoch 2227, Loss: 2.223045289516449, Final Batch Loss: 0.3998687267303467\n",
      "Epoch 2228, Loss: 3.3963392972946167, Final Batch Loss: 1.6040821075439453\n",
      "Epoch 2229, Loss: 2.1446678042411804, Final Batch Loss: 0.39226841926574707\n",
      "Epoch 2230, Loss: 1.7624941556714475, Final Batch Loss: 0.0030448525212705135\n",
      "Epoch 2231, Loss: 2.289259612560272, Final Batch Loss: 0.48624342679977417\n",
      "Epoch 2232, Loss: 1.805934451520443, Final Batch Loss: 0.0039132460951805115\n",
      "Epoch 2233, Loss: 1.750632181763649, Final Batch Loss: 0.02210618555545807\n",
      "Epoch 2234, Loss: 2.6483325958251953, Final Batch Loss: 0.8953368067741394\n",
      "Epoch 2235, Loss: 1.9140377044677734, Final Batch Loss: 0.07112479209899902\n",
      "Epoch 2236, Loss: 3.37624853849411, Final Batch Loss: 1.5757708549499512\n",
      "Epoch 2237, Loss: 1.9761236757040024, Final Batch Loss: 0.08869217336177826\n",
      "Epoch 2238, Loss: 3.985908627510071, Final Batch Loss: 1.9780291318893433\n",
      "Epoch 2239, Loss: 2.112634539604187, Final Batch Loss: 0.18691015243530273\n",
      "Epoch 2240, Loss: 1.8374362289323471, Final Batch Loss: 0.000809699238743633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2241, Loss: 1.825669270081562, Final Batch Loss: 0.00019262365822214633\n",
      "Epoch 2242, Loss: 1.8475354750989936, Final Batch Loss: 0.0007130940794013441\n",
      "Epoch 2243, Loss: 3.1056853532791138, Final Batch Loss: 1.2772023677825928\n",
      "Epoch 2244, Loss: 2.1351707875728607, Final Batch Loss: 0.2694447934627533\n",
      "Epoch 2245, Loss: 1.8530252166092396, Final Batch Loss: 0.044029850512742996\n",
      "Epoch 2246, Loss: 1.8238288004067726, Final Batch Loss: 0.0007924277451820672\n",
      "Epoch 2247, Loss: 1.7658142447471619, Final Batch Loss: 0.05392855405807495\n",
      "Epoch 2248, Loss: 3.2693474292755127, Final Batch Loss: 1.4951621294021606\n",
      "Epoch 2249, Loss: 1.7895209807902575, Final Batch Loss: 0.012079538777470589\n",
      "Epoch 2250, Loss: 2.7906349897384644, Final Batch Loss: 1.0354403257369995\n",
      "Epoch 2251, Loss: 1.9738366603851318, Final Batch Loss: 0.15771484375\n",
      "Epoch 2252, Loss: 2.423591375350952, Final Batch Loss: 0.6174236536026001\n",
      "Epoch 2253, Loss: 1.938888430595398, Final Batch Loss: 0.055347561836242676\n",
      "Epoch 2254, Loss: 1.7711487524211407, Final Batch Loss: 0.03376264497637749\n",
      "Epoch 2255, Loss: 1.9922139346599579, Final Batch Loss: 0.1398129165172577\n",
      "Epoch 2256, Loss: 1.9050639122724533, Final Batch Loss: 0.042262300848960876\n",
      "Epoch 2257, Loss: 1.857616201043129, Final Batch Loss: 0.00603117048740387\n",
      "Epoch 2258, Loss: 1.826364582637325, Final Batch Loss: 0.0006820021662861109\n",
      "Epoch 2259, Loss: 1.9015312045812607, Final Batch Loss: 0.04060976207256317\n",
      "Epoch 2260, Loss: 3.130885601043701, Final Batch Loss: 1.348734974861145\n",
      "Epoch 2261, Loss: 3.6553778052330017, Final Batch Loss: 1.8380781412124634\n",
      "Epoch 2262, Loss: 2.8228933811187744, Final Batch Loss: 1.0917549133300781\n",
      "Epoch 2263, Loss: 1.9764328300952911, Final Batch Loss: 0.14787855744361877\n",
      "Epoch 2264, Loss: 1.7862960199126974, Final Batch Loss: 0.00046754872892051935\n",
      "Epoch 2265, Loss: 1.907105565071106, Final Batch Loss: 0.12646132707595825\n",
      "Epoch 2266, Loss: 1.9202246740460396, Final Batch Loss: 0.12323028594255447\n",
      "Epoch 2267, Loss: 2.377033054828644, Final Batch Loss: 0.5613976120948792\n",
      "Epoch 2268, Loss: 1.852059770390042, Final Batch Loss: 0.00014935807848814875\n",
      "Epoch 2269, Loss: 1.8119167247787118, Final Batch Loss: 0.014108912087976933\n",
      "Epoch 2270, Loss: 4.138031840324402, Final Batch Loss: 2.3203964233398438\n",
      "Epoch 2271, Loss: 1.8445055074989796, Final Batch Loss: 0.039392370730638504\n",
      "Epoch 2272, Loss: 2.4079248309135437, Final Batch Loss: 0.5495485067367554\n",
      "Epoch 2273, Loss: 1.8789896499365568, Final Batch Loss: 0.008099330589175224\n",
      "Epoch 2274, Loss: 1.8683688342571259, Final Batch Loss: 0.0790456235408783\n",
      "Epoch 2275, Loss: 1.8986231870949268, Final Batch Loss: 0.06111188605427742\n",
      "Epoch 2276, Loss: 1.837886761437403, Final Batch Loss: 0.00031263710116036236\n",
      "Epoch 2277, Loss: 1.7351208855616278, Final Batch Loss: 0.00011801023356383666\n",
      "Epoch 2278, Loss: 2.0959086418151855, Final Batch Loss: 0.3118724822998047\n",
      "Epoch 2279, Loss: 1.7230890895007178, Final Batch Loss: 0.0017987991450354457\n",
      "Epoch 2280, Loss: 2.245372772216797, Final Batch Loss: 0.45583587884902954\n",
      "Epoch 2281, Loss: 1.7798156887292862, Final Batch Loss: 0.010503724217414856\n",
      "Epoch 2282, Loss: 2.090649753808975, Final Batch Loss: 0.2993791997432709\n",
      "Epoch 2283, Loss: 1.7998786333482713, Final Batch Loss: 0.00256863865070045\n",
      "Epoch 2284, Loss: 2.144842952489853, Final Batch Loss: 0.2509744465351105\n",
      "Epoch 2285, Loss: 3.380429446697235, Final Batch Loss: 1.5742900371551514\n",
      "Epoch 2286, Loss: 2.053541734814644, Final Batch Loss: 0.18520517647266388\n",
      "Epoch 2287, Loss: 3.8136878609657288, Final Batch Loss: 2.001976490020752\n",
      "Epoch 2288, Loss: 1.9316364116966724, Final Batch Loss: 0.011689264327287674\n",
      "Epoch 2289, Loss: 2.679953157901764, Final Batch Loss: 0.9195473790168762\n",
      "Epoch 2290, Loss: 1.7698364071547985, Final Batch Loss: 0.037978868931531906\n",
      "Epoch 2291, Loss: 3.2221723794937134, Final Batch Loss: 1.4038673639297485\n",
      "Epoch 2292, Loss: 2.7905181646347046, Final Batch Loss: 1.0973080396652222\n",
      "Epoch 2293, Loss: 2.8137624859809875, Final Batch Loss: 1.054295301437378\n",
      "Epoch 2294, Loss: 1.7441730611026287, Final Batch Loss: 0.016379188746213913\n",
      "Epoch 2295, Loss: 2.238716959953308, Final Batch Loss: 0.4211087226867676\n",
      "Epoch 2296, Loss: 2.856706738471985, Final Batch Loss: 1.1063787937164307\n",
      "Epoch 2297, Loss: 2.0230946987867355, Final Batch Loss: 0.22425244748592377\n",
      "Epoch 2298, Loss: 2.105560213327408, Final Batch Loss: 0.27759024500846863\n",
      "Epoch 2299, Loss: 2.2199330627918243, Final Batch Loss: 0.4852190315723419\n",
      "Epoch 2300, Loss: 2.6189185976982117, Final Batch Loss: 0.7714406251907349\n",
      "Epoch 2301, Loss: 2.037623777985573, Final Batch Loss: 0.15843971073627472\n",
      "Epoch 2302, Loss: 2.6257354617118835, Final Batch Loss: 0.5550112128257751\n",
      "Epoch 2303, Loss: 2.01989608630538, Final Batch Loss: 0.035445746034383774\n",
      "Epoch 2304, Loss: 2.427581936120987, Final Batch Loss: 0.4300245940685272\n",
      "Epoch 2305, Loss: 3.4393619894981384, Final Batch Loss: 1.5289990901947021\n",
      "Epoch 2306, Loss: 1.8881089314818382, Final Batch Loss: 0.07216056436300278\n",
      "Epoch 2307, Loss: 3.0306840538978577, Final Batch Loss: 1.144157886505127\n",
      "Epoch 2308, Loss: 1.9919294118881226, Final Batch Loss: 0.11815500259399414\n",
      "Epoch 2309, Loss: 2.677908182144165, Final Batch Loss: 0.8368991017341614\n",
      "Epoch 2310, Loss: 1.8365522623062134, Final Batch Loss: 0.056226491928100586\n",
      "Epoch 2311, Loss: 3.198221743106842, Final Batch Loss: 1.4850130081176758\n",
      "Epoch 2312, Loss: 1.8243641704320908, Final Batch Loss: 0.05109761655330658\n",
      "Epoch 2313, Loss: 1.7949893958866596, Final Batch Loss: 0.020100820809602737\n",
      "Epoch 2314, Loss: 1.9421799927949905, Final Batch Loss: 0.12870599329471588\n",
      "Epoch 2315, Loss: 3.8855682611465454, Final Batch Loss: 2.0803680419921875\n",
      "Epoch 2316, Loss: 1.7665615640580654, Final Batch Loss: 0.041518088430166245\n",
      "Epoch 2317, Loss: 3.4440433979034424, Final Batch Loss: 1.6894161701202393\n",
      "Epoch 2318, Loss: 3.497375786304474, Final Batch Loss: 1.6576197147369385\n",
      "Epoch 2319, Loss: 1.9193263798952103, Final Batch Loss: 0.12513042986392975\n",
      "Epoch 2320, Loss: 3.5138692259788513, Final Batch Loss: 1.67725670337677\n",
      "Epoch 2321, Loss: 4.578809142112732, Final Batch Loss: 2.7174625396728516\n",
      "Epoch 2322, Loss: 2.7363852858543396, Final Batch Loss: 0.9328665137290955\n",
      "Epoch 2323, Loss: 1.8861798588186502, Final Batch Loss: 0.009670907631516457\n",
      "Epoch 2324, Loss: 2.0284904539585114, Final Batch Loss: 0.20677515864372253\n",
      "Epoch 2325, Loss: 3.4054080843925476, Final Batch Loss: 1.4541414976119995\n",
      "Epoch 2326, Loss: 2.9449768662452698, Final Batch Loss: 1.0986711978912354\n",
      "Epoch 2327, Loss: 1.9213657435029745, Final Batch Loss: 0.0037783440202474594\n",
      "Epoch 2328, Loss: 1.893586036945635, Final Batch Loss: 7.211902266135439e-05\n",
      "Epoch 2329, Loss: 3.7000728845596313, Final Batch Loss: 1.9188292026519775\n",
      "Epoch 2330, Loss: 1.824048724025488, Final Batch Loss: 0.007271017879247665\n",
      "Epoch 2331, Loss: 2.5335909128189087, Final Batch Loss: 0.7285725474357605\n",
      "Epoch 2332, Loss: 2.528093457221985, Final Batch Loss: 0.7685510516166687\n",
      "Epoch 2333, Loss: 2.5959514379501343, Final Batch Loss: 0.8250433802604675\n",
      "Epoch 2334, Loss: 1.8486787560395896, Final Batch Loss: 0.006361472886055708\n",
      "Epoch 2335, Loss: 3.364468216896057, Final Batch Loss: 1.5227680206298828\n",
      "Epoch 2336, Loss: 1.7880556813906878, Final Batch Loss: 0.0002703301142901182\n",
      "Epoch 2337, Loss: 2.4661785364151, Final Batch Loss: 0.6977300643920898\n",
      "Epoch 2338, Loss: 2.207723468542099, Final Batch Loss: 0.4408678710460663\n",
      "Epoch 2339, Loss: 2.6538257598876953, Final Batch Loss: 0.841422438621521\n",
      "Epoch 2340, Loss: 2.2674956619739532, Final Batch Loss: 0.4633561074733734\n",
      "Epoch 2341, Loss: 3.54972904920578, Final Batch Loss: 1.7986987829208374\n",
      "Epoch 2342, Loss: 2.3934465646743774, Final Batch Loss: 0.5658757090568542\n",
      "Epoch 2343, Loss: 1.8679870590567589, Final Batch Loss: 0.12068202346563339\n",
      "Epoch 2344, Loss: 1.8643479570746422, Final Batch Loss: 0.11209496110677719\n",
      "Epoch 2345, Loss: 1.8397819809615612, Final Batch Loss: 0.06243978068232536\n",
      "Epoch 2346, Loss: 2.341324806213379, Final Batch Loss: 0.5756573677062988\n",
      "Epoch 2347, Loss: 3.527653455734253, Final Batch Loss: 1.8363182544708252\n",
      "Epoch 2348, Loss: 3.2549842596054077, Final Batch Loss: 1.5529637336730957\n",
      "Epoch 2349, Loss: 1.728899921523407, Final Batch Loss: 0.001405324088409543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2350, Loss: 2.7528567910194397, Final Batch Loss: 0.9757412672042847\n",
      "Epoch 2351, Loss: 3.087992012500763, Final Batch Loss: 1.3313448429107666\n",
      "Epoch 2352, Loss: 1.8955258503556252, Final Batch Loss: 0.112601138651371\n",
      "Epoch 2353, Loss: 1.7911647537257522, Final Batch Loss: 0.0026291587855666876\n",
      "Epoch 2354, Loss: 1.9660488665103912, Final Batch Loss: 0.1859612762928009\n",
      "Epoch 2355, Loss: 2.57246732711792, Final Batch Loss: 0.7085118889808655\n",
      "Epoch 2356, Loss: 3.5765398740768433, Final Batch Loss: 1.74253511428833\n",
      "Epoch 2357, Loss: 3.038259446620941, Final Batch Loss: 1.2826886177062988\n",
      "Epoch 2358, Loss: 2.3935552835464478, Final Batch Loss: 0.5567010641098022\n",
      "Epoch 2359, Loss: 1.9876541085541248, Final Batch Loss: 0.03231437876820564\n",
      "Epoch 2360, Loss: 2.875851094722748, Final Batch Loss: 1.0127360820770264\n",
      "Epoch 2361, Loss: 2.5910383462905884, Final Batch Loss: 0.6052045822143555\n",
      "Epoch 2362, Loss: 2.017888069152832, Final Batch Loss: 0.10034191608428955\n",
      "Epoch 2363, Loss: 2.0157326506450772, Final Batch Loss: 0.015400891192257404\n",
      "Epoch 2364, Loss: 1.8312343423021957, Final Batch Loss: 0.0018553201807662845\n",
      "Epoch 2365, Loss: 2.516236186027527, Final Batch Loss: 0.5052974224090576\n",
      "Epoch 2366, Loss: 2.0674129277467728, Final Batch Loss: 0.19271381199359894\n",
      "Epoch 2367, Loss: 3.4593154788017273, Final Batch Loss: 1.613520860671997\n",
      "Epoch 2368, Loss: 1.8349864217452705, Final Batch Loss: 0.007204386871308088\n",
      "Epoch 2369, Loss: 1.7665163837373257, Final Batch Loss: 0.041216012090444565\n",
      "Epoch 2370, Loss: 1.833826556801796, Final Batch Loss: 0.09704048931598663\n",
      "Epoch 2371, Loss: 1.785078617860563, Final Batch Loss: 0.0015610187547281384\n",
      "Epoch 2372, Loss: 1.9469329118728638, Final Batch Loss: 0.16678649187088013\n",
      "Epoch 2373, Loss: 1.84529597312212, Final Batch Loss: 0.08698583394289017\n",
      "Epoch 2374, Loss: 2.367732584476471, Final Batch Loss: 0.5679146647453308\n",
      "Epoch 2375, Loss: 2.096050500869751, Final Batch Loss: 0.2969321608543396\n",
      "Epoch 2376, Loss: 1.87093485891819, Final Batch Loss: 0.023130133748054504\n",
      "Epoch 2377, Loss: 3.376473307609558, Final Batch Loss: 1.4926440715789795\n",
      "Epoch 2378, Loss: 3.1036351323127747, Final Batch Loss: 1.2578492164611816\n",
      "Epoch 2379, Loss: 1.8150502628996037, Final Batch Loss: 0.0005660838796757162\n",
      "Epoch 2380, Loss: 1.914819898083806, Final Batch Loss: 0.007885398343205452\n",
      "Epoch 2381, Loss: 2.1420405507087708, Final Batch Loss: 0.26142799854278564\n",
      "Epoch 2382, Loss: 2.2608624696731567, Final Batch Loss: 0.2967042922973633\n",
      "Epoch 2383, Loss: 2.548884928226471, Final Batch Loss: 0.7134809494018555\n",
      "Epoch 2384, Loss: 3.391076445579529, Final Batch Loss: 1.6679338216781616\n",
      "Epoch 2385, Loss: 3.004507005214691, Final Batch Loss: 1.2003328800201416\n",
      "Epoch 2386, Loss: 1.8736696392297745, Final Batch Loss: 0.09001894295215607\n",
      "Epoch 2387, Loss: 1.8248607032001019, Final Batch Loss: 0.03829086944460869\n",
      "Epoch 2388, Loss: 1.9223733991384506, Final Batch Loss: 0.13175390660762787\n",
      "Epoch 2389, Loss: 3.5119622349739075, Final Batch Loss: 1.7355585098266602\n",
      "Epoch 2390, Loss: 2.4806472659111023, Final Batch Loss: 0.7932235598564148\n",
      "Epoch 2391, Loss: 2.0255695283412933, Final Batch Loss: 0.28434309363365173\n",
      "Epoch 2392, Loss: 1.7836725190281868, Final Batch Loss: 0.10191185027360916\n",
      "Epoch 2393, Loss: 2.5918174982070923, Final Batch Loss: 0.8006627559661865\n",
      "Epoch 2394, Loss: 2.080886960029602, Final Batch Loss: 0.39132368564605713\n",
      "Epoch 2395, Loss: 1.7659198865294456, Final Batch Loss: 0.06851073354482651\n",
      "Epoch 2396, Loss: 1.8823764324188232, Final Batch Loss: 0.12307935953140259\n",
      "Epoch 2397, Loss: 2.9654282927513123, Final Batch Loss: 1.1824288368225098\n",
      "Epoch 2398, Loss: 3.621339976787567, Final Batch Loss: 1.8474664688110352\n",
      "Epoch 2399, Loss: 2.1026166677474976, Final Batch Loss: 0.2884029150009155\n",
      "Epoch 2400, Loss: 1.8246219454449601, Final Batch Loss: 0.0004232226056046784\n",
      "Epoch 2401, Loss: 3.6161877512931824, Final Batch Loss: 1.7936792373657227\n",
      "Epoch 2402, Loss: 2.0359302684664726, Final Batch Loss: 0.1191929504275322\n",
      "Epoch 2403, Loss: 1.8611778360791504, Final Batch Loss: 0.005371068138629198\n",
      "Epoch 2404, Loss: 2.5750638246536255, Final Batch Loss: 0.7701424956321716\n",
      "Epoch 2405, Loss: 1.8001803867518902, Final Batch Loss: 0.01867802068591118\n",
      "Epoch 2406, Loss: 2.6947937607765198, Final Batch Loss: 0.9307770133018494\n",
      "Epoch 2407, Loss: 1.7249901053874055, Final Batch Loss: 0.00021944021864328533\n",
      "Epoch 2408, Loss: 2.7578999400138855, Final Batch Loss: 1.0977766513824463\n",
      "Epoch 2409, Loss: 1.7078981043305248, Final Batch Loss: 0.0026642323937267065\n",
      "Epoch 2410, Loss: 2.8898155093193054, Final Batch Loss: 1.2058632373809814\n",
      "Epoch 2411, Loss: 1.793108226149343, Final Batch Loss: 0.0018898261478170753\n",
      "Epoch 2412, Loss: 3.1436702609062195, Final Batch Loss: 1.4028571844100952\n",
      "Epoch 2413, Loss: 1.782222155481577, Final Batch Loss: 0.0004805363714694977\n",
      "Epoch 2414, Loss: 1.8752106819301844, Final Batch Loss: 0.013546446338295937\n",
      "Epoch 2415, Loss: 1.8458598291035742, Final Batch Loss: 0.00048101297579705715\n",
      "Epoch 2416, Loss: 3.6330260634422302, Final Batch Loss: 1.8057146072387695\n",
      "Epoch 2417, Loss: 1.9765883088111877, Final Batch Loss: 0.14413273334503174\n",
      "Epoch 2418, Loss: 1.8051254227757454, Final Batch Loss: 0.04881305247545242\n",
      "Epoch 2419, Loss: 1.8078563654999016, Final Batch Loss: 0.00017569905321579427\n",
      "Epoch 2420, Loss: 1.734880312345922, Final Batch Loss: 0.0038618287071585655\n",
      "Epoch 2421, Loss: 5.146103620529175, Final Batch Loss: 3.335355520248413\n",
      "Epoch 2422, Loss: 1.7840396741376026, Final Batch Loss: 6.401333666872233e-05\n",
      "Epoch 2423, Loss: 3.6360581517219543, Final Batch Loss: 1.8131179809570312\n",
      "Epoch 2424, Loss: 3.1841455698013306, Final Batch Loss: 1.3561416864395142\n",
      "Epoch 2425, Loss: 2.043293339200318, Final Batch Loss: 0.007036310620605946\n",
      "Epoch 2426, Loss: 1.9791184579953551, Final Batch Loss: 0.0037025725468993187\n",
      "Epoch 2427, Loss: 2.053738284157589, Final Batch Loss: 0.002829003380611539\n",
      "Epoch 2428, Loss: 2.0752857273400878, Final Batch Loss: 0.00010394509445177391\n",
      "Epoch 2429, Loss: 2.7963412404060364, Final Batch Loss: 0.814716100692749\n",
      "Epoch 2430, Loss: 1.9006988042965531, Final Batch Loss: 0.004812681116163731\n",
      "Epoch 2431, Loss: 1.8557951394468546, Final Batch Loss: 0.004127318039536476\n",
      "Epoch 2432, Loss: 2.0764144957065582, Final Batch Loss: 0.16109886765480042\n",
      "Epoch 2433, Loss: 3.0060201287269592, Final Batch Loss: 1.1691627502441406\n",
      "Epoch 2434, Loss: 2.063874363899231, Final Batch Loss: 0.21953779458999634\n",
      "Epoch 2435, Loss: 2.4902120232582092, Final Batch Loss: 0.7327350378036499\n",
      "Epoch 2436, Loss: 1.7223480772227049, Final Batch Loss: 0.01964680664241314\n",
      "Epoch 2437, Loss: 1.7766053174855188, Final Batch Loss: 0.0012842511059716344\n",
      "Epoch 2438, Loss: 1.8982573226094246, Final Batch Loss: 0.07438350468873978\n",
      "Epoch 2439, Loss: 3.3030120134353638, Final Batch Loss: 1.4797966480255127\n",
      "Epoch 2440, Loss: 1.8359055519104004, Final Batch Loss: 0.07955151796340942\n",
      "Epoch 2441, Loss: 1.8455539122223854, Final Batch Loss: 0.09564826637506485\n",
      "Epoch 2442, Loss: 1.701529516838491, Final Batch Loss: 0.010705067776143551\n",
      "Epoch 2443, Loss: 1.7935637219416094, Final Batch Loss: 5.6980417866725475e-05\n",
      "Epoch 2444, Loss: 1.8650291934609413, Final Batch Loss: 0.05673358589410782\n",
      "Epoch 2445, Loss: 2.829392194747925, Final Batch Loss: 1.0839327573776245\n",
      "Epoch 2446, Loss: 1.7950133830308914, Final Batch Loss: 0.0030034929513931274\n",
      "Epoch 2447, Loss: 1.749329388141632, Final Batch Loss: 0.016321957111358643\n",
      "Epoch 2448, Loss: 1.7535177238751203, Final Batch Loss: 0.0005333193112164736\n",
      "Epoch 2449, Loss: 3.83890563249588, Final Batch Loss: 2.063603162765503\n",
      "Epoch 2450, Loss: 1.7759280236205086, Final Batch Loss: 0.0010325344046577811\n",
      "Epoch 2451, Loss: 1.8174482211470604, Final Batch Loss: 0.0037896260619163513\n",
      "Epoch 2452, Loss: 3.3750112652778625, Final Batch Loss: 1.605872392654419\n",
      "Epoch 2453, Loss: 2.7314584851264954, Final Batch Loss: 1.0197503566741943\n",
      "Epoch 2454, Loss: 1.810873169451952, Final Batch Loss: 0.0008232779800891876\n",
      "Epoch 2455, Loss: 2.8150988817214966, Final Batch Loss: 1.0781633853912354\n",
      "Epoch 2456, Loss: 2.325497567653656, Final Batch Loss: 0.6176281571388245\n",
      "Epoch 2457, Loss: 3.0231098532676697, Final Batch Loss: 0.9502065181732178\n",
      "Epoch 2458, Loss: 3.6267213821411133, Final Batch Loss: 1.498568058013916\n",
      "Epoch 2459, Loss: 2.3169613778591156, Final Batch Loss: 0.1951996386051178\n",
      "Epoch 2460, Loss: 3.0459156036376953, Final Batch Loss: 0.9757919311523438\n",
      "Epoch 2461, Loss: 2.0169575288891792, Final Batch Loss: 0.09215963631868362\n",
      "Epoch 2462, Loss: 1.9061420075595379, Final Batch Loss: 0.018436145037412643\n",
      "Epoch 2463, Loss: 2.531319558620453, Final Batch Loss: 0.5464844107627869\n",
      "Epoch 2464, Loss: 2.4036706686019897, Final Batch Loss: 0.5830707550048828\n",
      "Epoch 2465, Loss: 1.9987127184867859, Final Batch Loss: 0.1375521421432495\n",
      "Epoch 2466, Loss: 2.2993335723876953, Final Batch Loss: 0.5106402635574341\n",
      "Epoch 2467, Loss: 1.986655741930008, Final Batch Loss: 0.15532991290092468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2468, Loss: 1.9171313121914864, Final Batch Loss: 0.07360745221376419\n",
      "Epoch 2469, Loss: 1.8002616129815578, Final Batch Loss: 0.004112359136343002\n",
      "Epoch 2470, Loss: 1.751404770766385, Final Batch Loss: 0.000904032145626843\n",
      "Epoch 2471, Loss: 1.8190358156571165, Final Batch Loss: 0.000513064325787127\n",
      "Epoch 2472, Loss: 2.4805116653442383, Final Batch Loss: 0.7580800652503967\n",
      "Epoch 2473, Loss: 3.0019466280937195, Final Batch Loss: 1.229020357131958\n",
      "Epoch 2474, Loss: 2.9458764791488647, Final Batch Loss: 1.163835048675537\n",
      "Epoch 2475, Loss: 2.8535374999046326, Final Batch Loss: 1.1005375385284424\n",
      "Epoch 2476, Loss: 1.8124773167073727, Final Batch Loss: 0.06224074587225914\n",
      "Epoch 2477, Loss: 1.9373915567994118, Final Batch Loss: 0.11080113798379898\n",
      "Epoch 2478, Loss: 2.434258818626404, Final Batch Loss: 0.6977195739746094\n",
      "Epoch 2479, Loss: 2.9524277448654175, Final Batch Loss: 1.1811249256134033\n",
      "Epoch 2480, Loss: 2.2137612998485565, Final Batch Loss: 0.4942374527454376\n",
      "Epoch 2481, Loss: 1.6877570084179752, Final Batch Loss: 0.00011669908417388797\n",
      "Epoch 2482, Loss: 1.7792356261052191, Final Batch Loss: 0.007205570582300425\n",
      "Epoch 2483, Loss: 4.554802417755127, Final Batch Loss: 2.8668935298919678\n",
      "Epoch 2484, Loss: 3.33462792634964, Final Batch Loss: 1.6088778972625732\n",
      "Epoch 2485, Loss: 1.9402513056993484, Final Batch Loss: 0.1349731832742691\n",
      "Epoch 2486, Loss: 2.9607073068618774, Final Batch Loss: 1.285597324371338\n",
      "Epoch 2487, Loss: 1.7440215883107157, Final Batch Loss: 0.00011145447206217796\n",
      "Epoch 2488, Loss: 1.959475114941597, Final Batch Loss: 0.2341463714838028\n",
      "Epoch 2489, Loss: 1.738936354406178, Final Batch Loss: 0.005036761052906513\n",
      "Epoch 2490, Loss: 2.8082152605056763, Final Batch Loss: 1.0985747575759888\n",
      "Epoch 2491, Loss: 1.9280446767807007, Final Batch Loss: 0.16213202476501465\n",
      "Epoch 2492, Loss: 1.6737209763377905, Final Batch Loss: 0.02989771030843258\n",
      "Epoch 2493, Loss: 2.36137992143631, Final Batch Loss: 0.6584998369216919\n",
      "Epoch 2494, Loss: 1.7741733491420746, Final Batch Loss: 0.05010691285133362\n",
      "Epoch 2495, Loss: 2.0075269639492035, Final Batch Loss: 0.3084408938884735\n",
      "Epoch 2496, Loss: 1.9743166863918304, Final Batch Loss: 0.25049862265586853\n",
      "Epoch 2497, Loss: 1.769952753558755, Final Batch Loss: 0.02856490947306156\n",
      "Epoch 2498, Loss: 3.3852856755256653, Final Batch Loss: 1.647904872894287\n",
      "Epoch 2499, Loss: 1.82332618907094, Final Batch Loss: 0.01719554141163826\n",
      "Epoch 2500, Loss: 1.8530170693993568, Final Batch Loss: 0.10186932235956192\n",
      "Epoch 2501, Loss: 4.486128568649292, Final Batch Loss: 2.7267346382141113\n",
      "Epoch 2502, Loss: 2.138869285583496, Final Batch Loss: 0.4191167950630188\n",
      "Epoch 2503, Loss: 4.749513626098633, Final Batch Loss: 2.9556961059570312\n",
      "Epoch 2504, Loss: 1.7537004813784733, Final Batch Loss: 0.0010484919184818864\n",
      "Epoch 2505, Loss: 3.1557440757751465, Final Batch Loss: 1.338037371635437\n",
      "Epoch 2506, Loss: 1.84119076654315, Final Batch Loss: 0.008982133120298386\n",
      "Epoch 2507, Loss: 2.951002776622772, Final Batch Loss: 1.1381938457489014\n",
      "Epoch 2508, Loss: 2.2565461099147797, Final Batch Loss: 0.49135950207710266\n",
      "Epoch 2509, Loss: 2.3347216844558716, Final Batch Loss: 0.5052148103713989\n",
      "Epoch 2510, Loss: 2.292934775352478, Final Batch Loss: 0.5140588283538818\n",
      "Epoch 2511, Loss: 1.705399326980114, Final Batch Loss: 0.010020546615123749\n",
      "Epoch 2512, Loss: 2.3519728779792786, Final Batch Loss: 0.6688783168792725\n",
      "Epoch 2513, Loss: 2.1750574707984924, Final Batch Loss: 0.48842209577560425\n",
      "Epoch 2514, Loss: 1.742445118026808, Final Batch Loss: 0.0031606026459485292\n",
      "Epoch 2515, Loss: 1.817710405215621, Final Batch Loss: 0.02951074205338955\n",
      "Epoch 2516, Loss: 1.7503965124487877, Final Batch Loss: 0.062073491513729095\n",
      "Epoch 2517, Loss: 2.5521289706230164, Final Batch Loss: 0.8178063035011292\n",
      "Epoch 2518, Loss: 3.759394645690918, Final Batch Loss: 2.0728836059570312\n",
      "Epoch 2519, Loss: 2.28891783952713, Final Batch Loss: 0.5599697828292847\n",
      "Epoch 2520, Loss: 1.9009067714214325, Final Batch Loss: 0.07751128077507019\n",
      "Epoch 2521, Loss: 3.8959255814552307, Final Batch Loss: 2.0289156436920166\n",
      "Epoch 2522, Loss: 1.7577228997834027, Final Batch Loss: 0.0022695516236126423\n",
      "Epoch 2523, Loss: 2.3608840703964233, Final Batch Loss: 0.6354126334190369\n",
      "Epoch 2524, Loss: 1.9539959728717804, Final Batch Loss: 0.19066807627677917\n",
      "Epoch 2525, Loss: 1.826302409172058, Final Batch Loss: 0.10193520784378052\n",
      "Epoch 2526, Loss: 1.7950335759669542, Final Batch Loss: 0.013324500992894173\n",
      "Epoch 2527, Loss: 2.7571370005607605, Final Batch Loss: 1.0609325170516968\n",
      "Epoch 2528, Loss: 1.6839407297084108, Final Batch Loss: 0.0002775999018922448\n",
      "Epoch 2529, Loss: 1.7251568865031004, Final Batch Loss: 0.015001459047198296\n",
      "Epoch 2530, Loss: 1.915099985897541, Final Batch Loss: 0.12178415805101395\n",
      "Epoch 2531, Loss: 1.772864990918606, Final Batch Loss: 0.0001137191939051263\n",
      "Epoch 2532, Loss: 2.7288798391819, Final Batch Loss: 1.0439828634262085\n",
      "Epoch 2533, Loss: 3.178941547870636, Final Batch Loss: 1.4138668775558472\n",
      "Epoch 2534, Loss: 2.7576418817043304, Final Batch Loss: 1.001003384590149\n",
      "Epoch 2535, Loss: 2.3278051614761353, Final Batch Loss: 0.5219653248786926\n",
      "Epoch 2536, Loss: 1.9691536352038383, Final Batch Loss: 0.11006694287061691\n",
      "Epoch 2537, Loss: 1.9750232994556427, Final Batch Loss: 0.13482984900474548\n",
      "Epoch 2538, Loss: 1.8295257240533829, Final Batch Loss: 0.06685109436511993\n",
      "Epoch 2539, Loss: 3.097659707069397, Final Batch Loss: 1.4109063148498535\n",
      "Epoch 2540, Loss: 1.8682509064674377, Final Batch Loss: 0.2513964772224426\n",
      "Epoch 2541, Loss: 3.2258378863334656, Final Batch Loss: 1.4966235160827637\n",
      "Epoch 2542, Loss: 2.7518675327301025, Final Batch Loss: 1.0233042240142822\n",
      "Epoch 2543, Loss: 1.6961625668482156, Final Batch Loss: 0.00017081231635529548\n",
      "Epoch 2544, Loss: 3.1410478353500366, Final Batch Loss: 1.4885588884353638\n",
      "Epoch 2545, Loss: 2.756358027458191, Final Batch Loss: 1.031845211982727\n",
      "Epoch 2546, Loss: 2.155135363340378, Final Batch Loss: 0.4063110649585724\n",
      "Epoch 2547, Loss: 1.7013546942034736, Final Batch Loss: 0.0003093002596870065\n",
      "Epoch 2548, Loss: 1.9291937500238419, Final Batch Loss: 0.17732159793376923\n",
      "Epoch 2549, Loss: 3.41495144367218, Final Batch Loss: 1.6956868171691895\n",
      "Epoch 2550, Loss: 2.018303334712982, Final Batch Loss: 0.3208455443382263\n",
      "Epoch 2551, Loss: 1.718082029838115, Final Batch Loss: 0.007123429793864489\n",
      "Epoch 2552, Loss: 1.716808264143765, Final Batch Loss: 0.007506971247494221\n",
      "Epoch 2553, Loss: 2.698420524597168, Final Batch Loss: 0.9910340905189514\n",
      "Epoch 2554, Loss: 1.64507579873316, Final Batch Loss: 0.0014435357879847288\n",
      "Epoch 2555, Loss: 1.7312966675963253, Final Batch Loss: 0.001374134561046958\n",
      "Epoch 2556, Loss: 2.554763674736023, Final Batch Loss: 0.8025522232055664\n",
      "Epoch 2557, Loss: 1.7755653411149979, Final Batch Loss: 0.023097053170204163\n",
      "Epoch 2558, Loss: 3.1065635681152344, Final Batch Loss: 1.4395241737365723\n",
      "Epoch 2559, Loss: 3.110096573829651, Final Batch Loss: 1.3465522527694702\n",
      "Epoch 2560, Loss: 1.7105885748169385, Final Batch Loss: 0.0009759668610058725\n",
      "Epoch 2561, Loss: 1.8198822354897857, Final Batch Loss: 0.0005609607324004173\n",
      "Epoch 2562, Loss: 3.859222888946533, Final Batch Loss: 1.991633415222168\n",
      "Epoch 2563, Loss: 1.797851525247097, Final Batch Loss: 0.006902776658535004\n",
      "Epoch 2564, Loss: 1.8026291131973267, Final Batch Loss: 0.03967219591140747\n",
      "Epoch 2565, Loss: 1.8260659584775567, Final Batch Loss: 0.012835622765123844\n",
      "Epoch 2566, Loss: 3.476087212562561, Final Batch Loss: 1.7433905601501465\n",
      "Epoch 2567, Loss: 3.111983299255371, Final Batch Loss: 1.3440015316009521\n",
      "Epoch 2568, Loss: 3.5239741802215576, Final Batch Loss: 1.673736810684204\n",
      "Epoch 2569, Loss: 1.8893522629514337, Final Batch Loss: 0.015207887627184391\n",
      "Epoch 2570, Loss: 2.451079875230789, Final Batch Loss: 0.3491581380367279\n",
      "Epoch 2571, Loss: 2.368558257818222, Final Batch Loss: 0.1351560652256012\n",
      "Epoch 2572, Loss: 2.617937445640564, Final Batch Loss: 0.5317912697792053\n",
      "Epoch 2573, Loss: 4.058516442775726, Final Batch Loss: 1.9618664979934692\n",
      "Epoch 2574, Loss: 2.7090779542922974, Final Batch Loss: 0.6560657620429993\n",
      "Epoch 2575, Loss: 3.5693212151527405, Final Batch Loss: 1.4109551906585693\n",
      "Epoch 2576, Loss: 2.2649456057697535, Final Batch Loss: 0.001869717612862587\n",
      "Epoch 2577, Loss: 2.3042104093619855, Final Batch Loss: 0.00017355366435367614\n",
      "Epoch 2578, Loss: 5.299285411834717, Final Batch Loss: 2.889772891998291\n",
      "Epoch 2579, Loss: 2.3048206428065896, Final Batch Loss: 0.008517012931406498\n",
      "Epoch 2580, Loss: 3.872378706932068, Final Batch Loss: 1.7302463054656982\n",
      "Epoch 2581, Loss: 2.000632946845144, Final Batch Loss: 0.005127375479787588\n",
      "Epoch 2582, Loss: 1.972610204713419, Final Batch Loss: 0.0011712603736668825\n",
      "Epoch 2583, Loss: 2.8575480580329895, Final Batch Loss: 0.9054355621337891\n",
      "Epoch 2584, Loss: 2.7689672112464905, Final Batch Loss: 0.8434354662895203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2585, Loss: 2.36364284157753, Final Batch Loss: 0.4296291172504425\n",
      "Epoch 2586, Loss: 1.9030566290020943, Final Batch Loss: 0.11186421662569046\n",
      "Epoch 2587, Loss: 2.3660581707954407, Final Batch Loss: 0.49069952964782715\n",
      "Epoch 2588, Loss: 2.1018756926059723, Final Batch Loss: 0.268633097410202\n",
      "Epoch 2589, Loss: 2.566353142261505, Final Batch Loss: 0.7110580801963806\n",
      "Epoch 2590, Loss: 3.092725932598114, Final Batch Loss: 1.3004651069641113\n",
      "Epoch 2591, Loss: 1.905510283075273, Final Batch Loss: 0.014767385087907314\n",
      "Epoch 2592, Loss: 2.811427056789398, Final Batch Loss: 0.9995232820510864\n",
      "Epoch 2593, Loss: 2.283339411020279, Final Batch Loss: 0.426776260137558\n",
      "Epoch 2594, Loss: 1.7593625186455029, Final Batch Loss: 1.680836794548668e-05\n",
      "Epoch 2595, Loss: 1.924909234046936, Final Batch Loss: 0.17102694511413574\n",
      "Epoch 2596, Loss: 2.4716063141822815, Final Batch Loss: 0.7853789329528809\n",
      "Epoch 2597, Loss: 2.7418593764305115, Final Batch Loss: 0.9646722078323364\n",
      "Epoch 2598, Loss: 2.8159103095531464, Final Batch Loss: 1.0842596292495728\n",
      "Epoch 2599, Loss: 3.1164034008979797, Final Batch Loss: 1.3653802871704102\n",
      "Epoch 2600, Loss: 1.9529152065515518, Final Batch Loss: 0.1329462081193924\n",
      "Epoch 2601, Loss: 4.797486484050751, Final Batch Loss: 3.0844264030456543\n",
      "Epoch 2602, Loss: 3.43520724773407, Final Batch Loss: 1.6678259372711182\n",
      "Epoch 2603, Loss: 1.7799769038756494, Final Batch Loss: 3.218599158572033e-05\n",
      "Epoch 2604, Loss: 1.8986054584383965, Final Batch Loss: 0.023512594401836395\n",
      "Epoch 2605, Loss: 2.370911717414856, Final Batch Loss: 0.4246842861175537\n",
      "Epoch 2606, Loss: 1.9181994451209903, Final Batch Loss: 0.004426087252795696\n",
      "Epoch 2607, Loss: 2.580709218978882, Final Batch Loss: 0.6129835247993469\n",
      "Epoch 2608, Loss: 1.799717728048563, Final Batch Loss: 0.034352902323007584\n",
      "Epoch 2609, Loss: 2.1782853603363037, Final Batch Loss: 0.3799676299095154\n",
      "Epoch 2610, Loss: 1.862671717070043, Final Batch Loss: 0.006239577196538448\n",
      "Epoch 2611, Loss: 1.8659103140234947, Final Batch Loss: 0.09871389716863632\n",
      "Epoch 2612, Loss: 2.07420951128006, Final Batch Loss: 0.22763991355895996\n",
      "Epoch 2613, Loss: 1.737105664331466, Final Batch Loss: 0.0023166504688560963\n",
      "Epoch 2614, Loss: 4.023498952388763, Final Batch Loss: 2.2139129638671875\n",
      "Epoch 2615, Loss: 1.9205247461795807, Final Batch Loss: 0.19121882319450378\n",
      "Epoch 2616, Loss: 1.7933768406510353, Final Batch Loss: 0.04179457575082779\n",
      "Epoch 2617, Loss: 1.862356010824442, Final Batch Loss: 0.04808551445603371\n",
      "Epoch 2618, Loss: 2.275097072124481, Final Batch Loss: 0.44761478900909424\n",
      "Epoch 2619, Loss: 3.5150339603424072, Final Batch Loss: 1.7367565631866455\n",
      "Epoch 2620, Loss: 2.9618844985961914, Final Batch Loss: 1.053013563156128\n",
      "Epoch 2621, Loss: 3.444440722465515, Final Batch Loss: 1.490139126777649\n",
      "Epoch 2622, Loss: 1.968953214585781, Final Batch Loss: 0.01786275953054428\n",
      "Epoch 2623, Loss: 2.037779854843393, Final Batch Loss: 0.003295706817880273\n",
      "Epoch 2624, Loss: 3.017099618911743, Final Batch Loss: 1.1047728061676025\n",
      "Epoch 2625, Loss: 1.845929965376854, Final Batch Loss: 0.019858822226524353\n",
      "Epoch 2626, Loss: 1.7479658918455243, Final Batch Loss: 0.002732117660343647\n",
      "Epoch 2627, Loss: 2.425243556499481, Final Batch Loss: 0.5763177871704102\n",
      "Epoch 2628, Loss: 1.7908486698943307, Final Batch Loss: 7.068861305015162e-05\n",
      "Epoch 2629, Loss: 1.754099577665329, Final Batch Loss: 0.08588370680809021\n",
      "Epoch 2630, Loss: 1.727525083348155, Final Batch Loss: 0.01703616790473461\n",
      "Epoch 2631, Loss: 2.449255645275116, Final Batch Loss: 0.7624989151954651\n",
      "Epoch 2632, Loss: 1.734063882380724, Final Batch Loss: 0.01603211835026741\n",
      "Epoch 2633, Loss: 3.1447930335998535, Final Batch Loss: 1.4362564086914062\n",
      "Epoch 2634, Loss: 1.7070799500215799, Final Batch Loss: 0.003095242427662015\n",
      "Epoch 2635, Loss: 1.7929040119051933, Final Batch Loss: 0.07246773689985275\n",
      "Epoch 2636, Loss: 3.0854328274726868, Final Batch Loss: 1.3503608703613281\n",
      "Epoch 2637, Loss: 1.9861444979906082, Final Batch Loss: 0.24279870092868805\n",
      "Epoch 2638, Loss: 3.050049066543579, Final Batch Loss: 1.2676758766174316\n",
      "Epoch 2639, Loss: 3.762776553630829, Final Batch Loss: 1.9533522129058838\n",
      "Epoch 2640, Loss: 3.18708735704422, Final Batch Loss: 1.3393526077270508\n",
      "Epoch 2641, Loss: 1.834055884508416, Final Batch Loss: 0.0014754373114556074\n",
      "Epoch 2642, Loss: 3.0978047847747803, Final Batch Loss: 1.3488562107086182\n",
      "Epoch 2643, Loss: 3.989788055419922, Final Batch Loss: 2.201669692993164\n",
      "Epoch 2644, Loss: 2.766498625278473, Final Batch Loss: 0.938960075378418\n",
      "Epoch 2645, Loss: 2.0439282655715942, Final Batch Loss: 0.14534592628479004\n",
      "Epoch 2646, Loss: 2.140442579984665, Final Batch Loss: 0.27623894810676575\n",
      "Epoch 2647, Loss: 3.1869946122169495, Final Batch Loss: 1.3751496076583862\n",
      "Epoch 2648, Loss: 2.1797205209732056, Final Batch Loss: 0.3958958387374878\n",
      "Epoch 2649, Loss: 1.7997752116061747, Final Batch Loss: 0.005909471306949854\n",
      "Epoch 2650, Loss: 1.684111289359862, Final Batch Loss: 0.00012468514614738524\n",
      "Epoch 2651, Loss: 2.2277002930641174, Final Batch Loss: 0.5232972502708435\n",
      "Epoch 2652, Loss: 1.9998721480369568, Final Batch Loss: 0.17593348026275635\n",
      "Epoch 2653, Loss: 3.4407918751239777, Final Batch Loss: 1.778998851776123\n",
      "Epoch 2654, Loss: 2.911884754896164, Final Batch Loss: 1.1573388576507568\n",
      "Epoch 2655, Loss: 1.696145583409816, Final Batch Loss: 0.007734943646937609\n",
      "Epoch 2656, Loss: 1.8366559073328972, Final Batch Loss: 0.03816591948270798\n",
      "Epoch 2657, Loss: 3.2461790442466736, Final Batch Loss: 1.4576549530029297\n",
      "Epoch 2658, Loss: 2.88081431388855, Final Batch Loss: 1.2078717947006226\n",
      "Epoch 2659, Loss: 1.6935318151954561, Final Batch Loss: 0.002234939718618989\n",
      "Epoch 2660, Loss: 2.689177989959717, Final Batch Loss: 0.9955083727836609\n",
      "Epoch 2661, Loss: 2.5616455674171448, Final Batch Loss: 0.8692030906677246\n",
      "Epoch 2662, Loss: 3.389691412448883, Final Batch Loss: 1.6389975547790527\n",
      "Epoch 2663, Loss: 2.9451246857643127, Final Batch Loss: 1.20076322555542\n",
      "Epoch 2664, Loss: 3.017683684825897, Final Batch Loss: 1.3452703952789307\n",
      "Epoch 2665, Loss: 2.700845718383789, Final Batch Loss: 0.9594064950942993\n",
      "Epoch 2666, Loss: 1.701437289826572, Final Batch Loss: 0.0035033775493502617\n",
      "Epoch 2667, Loss: 2.702998638153076, Final Batch Loss: 1.042884111404419\n",
      "Epoch 2668, Loss: 2.238674521446228, Final Batch Loss: 0.5523437857627869\n",
      "Epoch 2669, Loss: 1.7542780003277585, Final Batch Loss: 0.0012477001873776317\n",
      "Epoch 2670, Loss: 1.6771938558667898, Final Batch Loss: 0.017898356541991234\n",
      "Epoch 2671, Loss: 1.709099067375064, Final Batch Loss: 0.013732833787798882\n",
      "Epoch 2672, Loss: 2.5411733388900757, Final Batch Loss: 0.882207989692688\n",
      "Epoch 2673, Loss: 2.1150896549224854, Final Batch Loss: 0.3598371744155884\n",
      "Epoch 2674, Loss: 2.9279794692993164, Final Batch Loss: 1.2301959991455078\n",
      "Epoch 2675, Loss: 2.864898145198822, Final Batch Loss: 1.1184314489364624\n",
      "Epoch 2676, Loss: 1.6425975239471882, Final Batch Loss: 6.878139538457617e-05\n",
      "Epoch 2677, Loss: 3.464358389377594, Final Batch Loss: 1.7969717979431152\n",
      "Epoch 2678, Loss: 2.823798179626465, Final Batch Loss: 1.0475361347198486\n",
      "Epoch 2679, Loss: 1.6926932083297288, Final Batch Loss: 0.00022432672267314047\n",
      "Epoch 2680, Loss: 1.6853878132242244, Final Batch Loss: 0.0004385939973872155\n",
      "Epoch 2681, Loss: 1.8235326368376263, Final Batch Loss: 9.047575440490618e-05\n",
      "Epoch 2682, Loss: 1.7957951873540878, Final Batch Loss: 0.08738069236278534\n",
      "Epoch 2683, Loss: 3.170743465423584, Final Batch Loss: 1.5210707187652588\n",
      "Epoch 2684, Loss: 3.456978678703308, Final Batch Loss: 1.8161728382110596\n",
      "Epoch 2685, Loss: 1.7501603737473488, Final Batch Loss: 0.05115798860788345\n",
      "Epoch 2686, Loss: 2.337810754776001, Final Batch Loss: 0.7137388586997986\n",
      "Epoch 2687, Loss: 3.7211325764656067, Final Batch Loss: 2.039720296859741\n",
      "Epoch 2688, Loss: 3.2866989374160767, Final Batch Loss: 1.5997164249420166\n",
      "Epoch 2689, Loss: 1.7417447329498827, Final Batch Loss: 0.000802075956016779\n",
      "Epoch 2690, Loss: 1.6562308254651725, Final Batch Loss: 0.007777172606438398\n",
      "Epoch 2691, Loss: 1.6626735300960718, Final Batch Loss: 7.56950321374461e-05\n",
      "Epoch 2692, Loss: 2.917858362197876, Final Batch Loss: 1.2056111097335815\n",
      "Epoch 2693, Loss: 1.6781528980936855, Final Batch Loss: 0.003360697766765952\n",
      "Epoch 2694, Loss: 1.6727800242952071, Final Batch Loss: 0.0006187431863509119\n",
      "Epoch 2695, Loss: 1.8227447271347046, Final Batch Loss: 0.19189876317977905\n",
      "Epoch 2696, Loss: 2.162366807460785, Final Batch Loss: 0.5349321365356445\n",
      "Epoch 2697, Loss: 1.740517561789602, Final Batch Loss: 0.0022871545515954494\n",
      "Epoch 2698, Loss: 1.763054772556643, Final Batch Loss: 0.00017641419253777713\n",
      "Epoch 2699, Loss: 1.9133580923080444, Final Batch Loss: 0.2121918797492981\n",
      "Epoch 2700, Loss: 1.9322090148925781, Final Batch Loss: 0.28592514991760254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2701, Loss: 4.354922592639923, Final Batch Loss: 2.6543240547180176\n",
      "Epoch 2702, Loss: 3.2542126774787903, Final Batch Loss: 1.5181338787078857\n",
      "Epoch 2703, Loss: 3.7322678565979004, Final Batch Loss: 1.9712423086166382\n",
      "Epoch 2704, Loss: 1.6755887865001569, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 2705, Loss: 1.8361447006464005, Final Batch Loss: 0.15645785629749298\n",
      "Epoch 2706, Loss: 1.7056922242045403, Final Batch Loss: 0.07421361654996872\n",
      "Epoch 2707, Loss: 1.724806634709239, Final Batch Loss: 0.026844529435038567\n",
      "Epoch 2708, Loss: 1.8817811757326126, Final Batch Loss: 0.21734090149402618\n",
      "Epoch 2709, Loss: 2.7045353651046753, Final Batch Loss: 1.0558034181594849\n",
      "Epoch 2710, Loss: 1.7012382373213768, Final Batch Loss: 0.020952783524990082\n",
      "Epoch 2711, Loss: 1.8759279400110245, Final Batch Loss: 0.21086139976978302\n",
      "Epoch 2712, Loss: 1.7352960564894602, Final Batch Loss: 0.0014330603880807757\n",
      "Epoch 2713, Loss: 2.8838687539100647, Final Batch Loss: 1.256448745727539\n",
      "Epoch 2714, Loss: 1.6106173612060957, Final Batch Loss: 0.00027569307712838054\n",
      "Epoch 2715, Loss: 1.6643384373746812, Final Batch Loss: 0.0010087168775498867\n",
      "Epoch 2716, Loss: 3.4241049885749817, Final Batch Loss: 1.8011956214904785\n",
      "Epoch 2717, Loss: 2.3357266187667847, Final Batch Loss: 0.6466206312179565\n",
      "Epoch 2718, Loss: 2.495195508003235, Final Batch Loss: 0.8366638422012329\n",
      "Epoch 2719, Loss: 3.0414193272590637, Final Batch Loss: 1.4040247201919556\n",
      "Epoch 2720, Loss: 1.9849776029586792, Final Batch Loss: 0.25931626558303833\n",
      "Epoch 2721, Loss: 3.9997254014015198, Final Batch Loss: 2.139747142791748\n",
      "Epoch 2722, Loss: 2.0177827775478363, Final Batch Loss: 0.08781185746192932\n",
      "Epoch 2723, Loss: 2.0320362895727158, Final Batch Loss: 0.23042450845241547\n",
      "Epoch 2724, Loss: 1.9733690470457077, Final Batch Loss: 0.19191263616085052\n",
      "Epoch 2725, Loss: 1.7958520133979619, Final Batch Loss: 0.0005845506675541401\n",
      "Epoch 2726, Loss: 2.0093308240175247, Final Batch Loss: 0.18203814327716827\n",
      "Epoch 2727, Loss: 2.9367228150367737, Final Batch Loss: 1.2392195463180542\n",
      "Epoch 2728, Loss: 1.8898520767688751, Final Batch Loss: 0.10553929209709167\n",
      "Epoch 2729, Loss: 1.8855811208486557, Final Batch Loss: 0.2425169199705124\n",
      "Epoch 2730, Loss: 2.5851296186447144, Final Batch Loss: 0.912971019744873\n",
      "Epoch 2731, Loss: 2.2203329205513, Final Batch Loss: 0.5882920026779175\n",
      "Epoch 2732, Loss: 2.7124555706977844, Final Batch Loss: 0.955816924571991\n",
      "Epoch 2733, Loss: 2.8695910573005676, Final Batch Loss: 1.0746002197265625\n",
      "Epoch 2734, Loss: 2.0562578588724136, Final Batch Loss: 0.15845294296741486\n",
      "Epoch 2735, Loss: 1.7474608197808266, Final Batch Loss: 0.022272564470767975\n",
      "Epoch 2736, Loss: 3.184406816959381, Final Batch Loss: 1.521736979484558\n",
      "Epoch 2737, Loss: 1.9604541957378387, Final Batch Loss: 0.1941101849079132\n",
      "Epoch 2738, Loss: 1.6899968320067273, Final Batch Loss: 0.00011455356434453279\n",
      "Epoch 2739, Loss: 1.7036629704525694, Final Batch Loss: 0.0007987407734617591\n",
      "Epoch 2740, Loss: 1.689828522503376, Final Batch Loss: 0.030755706131458282\n",
      "Epoch 2741, Loss: 1.807249590754509, Final Batch Loss: 0.03795407712459564\n",
      "Epoch 2742, Loss: 1.9564147889614105, Final Batch Loss: 0.348495215177536\n",
      "Epoch 2743, Loss: 1.6473619210300967, Final Batch Loss: 0.001733468729071319\n",
      "Epoch 2744, Loss: 1.624629676096447, Final Batch Loss: 2.2172682292875834e-05\n",
      "Epoch 2745, Loss: 4.117897987365723, Final Batch Loss: 2.4610791206359863\n",
      "Epoch 2746, Loss: 2.5190271139144897, Final Batch Loss: 0.8428623080253601\n",
      "Epoch 2747, Loss: 2.3334057927131653, Final Batch Loss: 0.6603568196296692\n",
      "Epoch 2748, Loss: 2.204105943441391, Final Batch Loss: 0.48171675205230713\n",
      "Epoch 2749, Loss: 2.842540144920349, Final Batch Loss: 1.081390142440796\n",
      "Epoch 2750, Loss: 1.7465512752528412, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 2751, Loss: 1.809792399406433, Final Batch Loss: 0.08241403102874756\n",
      "Epoch 2752, Loss: 1.7388122184202075, Final Batch Loss: 0.01192087959498167\n",
      "Epoch 2753, Loss: 1.7143316566944122, Final Batch Loss: 0.08639883995056152\n",
      "Epoch 2754, Loss: 2.895971119403839, Final Batch Loss: 1.2865021228790283\n",
      "Epoch 2755, Loss: 1.6343333409167826, Final Batch Loss: 0.0002498314715921879\n",
      "Epoch 2756, Loss: 2.8437888622283936, Final Batch Loss: 1.1652213335037231\n",
      "Epoch 2757, Loss: 2.355530560016632, Final Batch Loss: 0.7782676219940186\n",
      "Epoch 2758, Loss: 1.6302604875527322, Final Batch Loss: 0.004373153205960989\n",
      "Epoch 2759, Loss: 3.6967324912548065, Final Batch Loss: 1.9897834062576294\n",
      "Epoch 2760, Loss: 1.7540826946496964, Final Batch Loss: 0.0030034929513931274\n",
      "Epoch 2761, Loss: 2.134012265247293, Final Batch Loss: 0.0010515881003811955\n",
      "Epoch 2762, Loss: 2.9170252680778503, Final Batch Loss: 0.6392778158187866\n",
      "Epoch 2763, Loss: 2.301574435085058, Final Batch Loss: 0.0409252904355526\n",
      "Epoch 2764, Loss: 2.2003704141825438, Final Batch Loss: 0.013445300981402397\n",
      "Epoch 2765, Loss: 1.8620700780302286, Final Batch Loss: 0.015855664387345314\n",
      "Epoch 2766, Loss: 2.0732531547546387, Final Batch Loss: 0.2683377265930176\n",
      "Epoch 2767, Loss: 1.7289687348529696, Final Batch Loss: 0.0031829429790377617\n",
      "Epoch 2768, Loss: 1.969023883342743, Final Batch Loss: 0.26676344871520996\n",
      "Epoch 2769, Loss: 1.7057612890785094, Final Batch Loss: 0.00040975757292471826\n",
      "Epoch 2770, Loss: 1.8011052012443542, Final Batch Loss: 0.06756120920181274\n",
      "Epoch 2771, Loss: 1.7107649818062782, Final Batch Loss: 0.008183874189853668\n",
      "Epoch 2772, Loss: 1.9746076464653015, Final Batch Loss: 0.30325549840927124\n",
      "Epoch 2773, Loss: 1.6439351584995165, Final Batch Loss: 0.001534238108433783\n",
      "Epoch 2774, Loss: 1.6487168945604935, Final Batch Loss: 0.0014861501986160874\n",
      "Epoch 2775, Loss: 3.159219980239868, Final Batch Loss: 1.52907133102417\n",
      "Epoch 2776, Loss: 1.7072128650615923, Final Batch Loss: 0.0009136793087236583\n",
      "Epoch 2777, Loss: 2.510749101638794, Final Batch Loss: 0.8121666312217712\n",
      "Epoch 2778, Loss: 1.6618398753926158, Final Batch Loss: 0.008263918571174145\n",
      "Epoch 2779, Loss: 4.985456824302673, Final Batch Loss: 3.298356056213379\n",
      "Epoch 2780, Loss: 1.803770512342453, Final Batch Loss: 0.13124510645866394\n",
      "Epoch 2781, Loss: 2.855248212814331, Final Batch Loss: 1.1706687211990356\n",
      "Epoch 2782, Loss: 3.543556272983551, Final Batch Loss: 1.7513148784637451\n",
      "Epoch 2783, Loss: 2.922700524330139, Final Batch Loss: 1.153374195098877\n",
      "Epoch 2784, Loss: 3.2821656465530396, Final Batch Loss: 1.3171710968017578\n",
      "Epoch 2785, Loss: 1.9514943130634492, Final Batch Loss: 0.00021479207498487085\n",
      "Epoch 2786, Loss: 3.180075466632843, Final Batch Loss: 1.394616961479187\n",
      "Epoch 2787, Loss: 1.844119243323803, Final Batch Loss: 0.09959989041090012\n",
      "Epoch 2788, Loss: 3.3198344707489014, Final Batch Loss: 1.5933141708374023\n",
      "Epoch 2789, Loss: 1.7560595723916776, Final Batch Loss: 0.00017093151109293103\n",
      "Epoch 2790, Loss: 1.6987728744279593, Final Batch Loss: 0.0014867454301565886\n",
      "Epoch 2791, Loss: 1.7255332430358976, Final Batch Loss: 0.001148398732766509\n",
      "Epoch 2792, Loss: 1.8309935176512226, Final Batch Loss: 0.00038747431244701147\n",
      "Epoch 2793, Loss: 1.671515634690877, Final Batch Loss: 0.00013350549852475524\n",
      "Epoch 2794, Loss: 2.212372601032257, Final Batch Loss: 0.5190281867980957\n",
      "Epoch 2795, Loss: 1.7747560068964958, Final Batch Loss: 0.06931745260953903\n",
      "Epoch 2796, Loss: 2.427334249019623, Final Batch Loss: 0.7625961899757385\n",
      "Epoch 2797, Loss: 1.6896185011137277, Final Batch Loss: 0.003095242427662015\n",
      "Epoch 2798, Loss: 3.4648460745811462, Final Batch Loss: 1.8148810863494873\n",
      "Epoch 2799, Loss: 3.216199964284897, Final Batch Loss: 1.53165864944458\n",
      "Epoch 2800, Loss: 1.653435752785299, Final Batch Loss: 0.0009284476400353014\n",
      "Epoch 2801, Loss: 1.6753042218042538, Final Batch Loss: 0.0011555430246517062\n",
      "Epoch 2802, Loss: 1.7260423489497043, Final Batch Loss: 0.00028606137493625283\n",
      "Epoch 2803, Loss: 1.7214535405873903, Final Batch Loss: 0.0001174142598756589\n",
      "Epoch 2804, Loss: 1.7915542609989643, Final Batch Loss: 0.044586945325136185\n",
      "Epoch 2805, Loss: 4.184328258037567, Final Batch Loss: 2.4561750888824463\n",
      "Epoch 2806, Loss: 1.7745301946997643, Final Batch Loss: 0.08357711881399155\n",
      "Epoch 2807, Loss: 1.622518544900231, Final Batch Loss: 0.0017904693959280849\n",
      "Epoch 2808, Loss: 1.8560385555028915, Final Batch Loss: 0.16445235908031464\n",
      "Epoch 2809, Loss: 1.7227286603301764, Final Batch Loss: 0.015987655147910118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2810, Loss: 1.7182213917840272, Final Batch Loss: 0.002899135695770383\n",
      "Epoch 2811, Loss: 3.2775793075561523, Final Batch Loss: 1.5391590595245361\n",
      "Epoch 2812, Loss: 1.6620524218305945, Final Batch Loss: 0.012677907012403011\n",
      "Epoch 2813, Loss: 1.7598657412454486, Final Batch Loss: 0.005392055027186871\n",
      "Epoch 2814, Loss: 2.4008793234825134, Final Batch Loss: 0.67439204454422\n",
      "Epoch 2815, Loss: 1.8156396746635437, Final Batch Loss: 0.01920229196548462\n",
      "Epoch 2816, Loss: 1.831800612155348, Final Batch Loss: 0.0028761946596205235\n",
      "Epoch 2817, Loss: 2.2764716744422913, Final Batch Loss: 0.6048623323440552\n",
      "Epoch 2818, Loss: 1.8150779008865356, Final Batch Loss: 0.14529582858085632\n",
      "Epoch 2819, Loss: 2.576653778553009, Final Batch Loss: 0.884164035320282\n",
      "Epoch 2820, Loss: 1.7249986827373505, Final Batch Loss: 0.06665527820587158\n",
      "Epoch 2821, Loss: 3.1708890199661255, Final Batch Loss: 1.5074899196624756\n",
      "Epoch 2822, Loss: 2.526581048965454, Final Batch Loss: 0.8598660826683044\n",
      "Epoch 2823, Loss: 1.8543013781309128, Final Batch Loss: 0.14042584598064423\n",
      "Epoch 2824, Loss: 1.7183914743363857, Final Batch Loss: 0.009134408086538315\n",
      "Epoch 2825, Loss: 3.017262816429138, Final Batch Loss: 1.1844983100891113\n",
      "Epoch 2826, Loss: 2.543774962425232, Final Batch Loss: 0.7686025500297546\n",
      "Epoch 2827, Loss: 3.0265416502952576, Final Batch Loss: 1.3304932117462158\n",
      "Epoch 2828, Loss: 4.488427102565765, Final Batch Loss: 2.6587274074554443\n",
      "Epoch 2829, Loss: 3.223815470933914, Final Batch Loss: 1.5746666193008423\n",
      "Epoch 2830, Loss: 1.7053121256176382, Final Batch Loss: 0.0023438858333975077\n",
      "Epoch 2831, Loss: 1.9554006680846214, Final Batch Loss: 0.06878175586462021\n",
      "Epoch 2832, Loss: 3.9654277563095093, Final Batch Loss: 2.005357265472412\n",
      "Epoch 2833, Loss: 1.9401978232417605, Final Batch Loss: 6.615896563744172e-05\n",
      "Epoch 2834, Loss: 1.9789056777954102, Final Batch Loss: 0.053861796855926514\n",
      "Epoch 2835, Loss: 2.722563326358795, Final Batch Loss: 0.8747572302818298\n",
      "Epoch 2836, Loss: 7.223829805850983, Final Batch Loss: 5.439496040344238\n",
      "Epoch 2837, Loss: 3.008389174938202, Final Batch Loss: 1.1503571271896362\n",
      "Epoch 2838, Loss: 2.70331209897995, Final Batch Loss: 0.6946799755096436\n",
      "Epoch 2839, Loss: 2.233043134212494, Final Batch Loss: 0.0681309700012207\n",
      "Epoch 2840, Loss: 3.8751192688941956, Final Batch Loss: 1.8319966793060303\n",
      "Epoch 2841, Loss: 3.0057188272476196, Final Batch Loss: 0.9753885865211487\n",
      "Epoch 2842, Loss: 1.9721050299704075, Final Batch Loss: 0.05526262894272804\n",
      "Epoch 2843, Loss: 1.8276906584651442, Final Batch Loss: 7.056941103655845e-05\n",
      "Epoch 2844, Loss: 2.0313170552253723, Final Batch Loss: 0.18007755279541016\n",
      "Epoch 2845, Loss: 1.864932654891163, Final Batch Loss: 0.0009778724052011967\n",
      "Epoch 2846, Loss: 1.8336977697908878, Final Batch Loss: 0.02452591434121132\n",
      "Epoch 2847, Loss: 1.885313168168068, Final Batch Loss: 0.09669531881809235\n",
      "Epoch 2848, Loss: 1.6897647379173577, Final Batch Loss: 1.823885577323381e-05\n",
      "Epoch 2849, Loss: 4.645148158073425, Final Batch Loss: 2.915818214416504\n",
      "Epoch 2850, Loss: 1.748633861541748, Final Batch Loss: 0.04384845495223999\n",
      "Epoch 2851, Loss: 2.252757489681244, Final Batch Loss: 0.5086304545402527\n",
      "Epoch 2852, Loss: 1.6932366653345525, Final Batch Loss: 0.0014937683008611202\n",
      "Epoch 2853, Loss: 1.7714555859565735, Final Batch Loss: 0.07230484485626221\n",
      "Epoch 2854, Loss: 1.965589426457882, Final Batch Loss: 0.07514955848455429\n",
      "Epoch 2855, Loss: 1.917327180504799, Final Batch Loss: 0.18250764906406403\n",
      "Epoch 2856, Loss: 1.7063083462417126, Final Batch Loss: 0.014207523316144943\n",
      "Epoch 2857, Loss: 3.8585546016693115, Final Batch Loss: 2.1419050693511963\n",
      "Epoch 2858, Loss: 1.739019166037906, Final Batch Loss: 0.0008330450509674847\n",
      "Epoch 2859, Loss: 1.6283988356253758, Final Batch Loss: 8.22540732769994e-06\n",
      "Epoch 2860, Loss: 1.7804401455214247, Final Batch Loss: 0.0006553170969709754\n",
      "Epoch 2861, Loss: 1.82639186270535, Final Batch Loss: 0.029497431591153145\n",
      "Epoch 2862, Loss: 3.045658051967621, Final Batch Loss: 1.4156219959259033\n",
      "Epoch 2863, Loss: 3.1881614327430725, Final Batch Loss: 1.471247673034668\n",
      "Epoch 2864, Loss: 2.971156507730484, Final Batch Loss: 1.3290599584579468\n",
      "Epoch 2865, Loss: 3.039113402366638, Final Batch Loss: 1.30715012550354\n",
      "Epoch 2866, Loss: 1.7740452587604523, Final Batch Loss: 0.05598011612892151\n",
      "Epoch 2867, Loss: 2.098014861345291, Final Batch Loss: 0.40029022097587585\n",
      "Epoch 2868, Loss: 1.7494688853621483, Final Batch Loss: 0.021511100232601166\n",
      "Epoch 2869, Loss: 3.1588972210884094, Final Batch Loss: 1.4080830812454224\n",
      "Epoch 2870, Loss: 1.828826904296875, Final Batch Loss: 0.029176652431488037\n",
      "Epoch 2871, Loss: 2.989289402961731, Final Batch Loss: 1.3290343284606934\n",
      "Epoch 2872, Loss: 1.9171854108572006, Final Batch Loss: 0.1805795282125473\n",
      "Epoch 2873, Loss: 3.1469953060150146, Final Batch Loss: 1.446362018585205\n",
      "Epoch 2874, Loss: 1.7219502739608288, Final Batch Loss: 0.029179316014051437\n",
      "Epoch 2875, Loss: 3.249393343925476, Final Batch Loss: 1.5758475065231323\n",
      "Epoch 2876, Loss: 4.557251691818237, Final Batch Loss: 2.8287136554718018\n",
      "Epoch 2877, Loss: 1.9259764552116394, Final Batch Loss: 0.18473118543624878\n",
      "Epoch 2878, Loss: 2.8678974509239197, Final Batch Loss: 1.1209349632263184\n",
      "Epoch 2879, Loss: 3.353878915309906, Final Batch Loss: 1.6570215225219727\n",
      "Epoch 2880, Loss: 3.0295052528381348, Final Batch Loss: 1.292318344116211\n",
      "Epoch 2881, Loss: 2.518714666366577, Final Batch Loss: 0.8340286016464233\n",
      "Epoch 2882, Loss: 1.7793767526745796, Final Batch Loss: 0.021079786121845245\n",
      "Epoch 2883, Loss: 2.987271785736084, Final Batch Loss: 1.2495911121368408\n",
      "Epoch 2884, Loss: 1.9517218172550201, Final Batch Loss: 0.09388962388038635\n",
      "Epoch 2885, Loss: 2.471636474132538, Final Batch Loss: 0.6036210656166077\n",
      "Epoch 2886, Loss: 2.0653866678476334, Final Batch Loss: 0.21587951481342316\n",
      "Epoch 2887, Loss: 3.2789642810821533, Final Batch Loss: 1.5153205394744873\n",
      "Epoch 2888, Loss: 1.6656410740688443, Final Batch Loss: 0.014913027174770832\n",
      "Epoch 2889, Loss: 3.2990387082099915, Final Batch Loss: 1.6450555324554443\n",
      "Epoch 2890, Loss: 3.128577768802643, Final Batch Loss: 1.4418580532073975\n",
      "Epoch 2891, Loss: 2.437216877937317, Final Batch Loss: 0.7592387795448303\n",
      "Epoch 2892, Loss: 1.7497956607112428, Final Batch Loss: 0.00017069313616957515\n",
      "Epoch 2893, Loss: 2.4157615900039673, Final Batch Loss: 0.7379704713821411\n",
      "Epoch 2894, Loss: 3.0622828602790833, Final Batch Loss: 1.2469207048416138\n",
      "Epoch 2895, Loss: 3.221077561378479, Final Batch Loss: 1.4884331226348877\n",
      "Epoch 2896, Loss: 2.171414017677307, Final Batch Loss: 0.5134904980659485\n",
      "Epoch 2897, Loss: 1.6452503420878202, Final Batch Loss: 0.0023442425299435854\n",
      "Epoch 2898, Loss: 1.8513742163777351, Final Batch Loss: 0.09795088320970535\n",
      "Epoch 2899, Loss: 1.9422424286603928, Final Batch Loss: 0.19233839213848114\n",
      "Epoch 2900, Loss: 3.5342958569526672, Final Batch Loss: 1.8002955913543701\n",
      "Epoch 2901, Loss: 2.576193869113922, Final Batch Loss: 0.9410762190818787\n",
      "Epoch 2902, Loss: 1.9322711080312729, Final Batch Loss: 0.19805215299129486\n",
      "Epoch 2903, Loss: 1.7975607365369797, Final Batch Loss: 0.14592282474040985\n",
      "Epoch 2904, Loss: 1.6744133829806742, Final Batch Loss: 7.271740287251305e-06\n",
      "Epoch 2905, Loss: 1.8197606950998306, Final Batch Loss: 0.06041647493839264\n",
      "Epoch 2906, Loss: 4.082344233989716, Final Batch Loss: 2.4809200763702393\n",
      "Epoch 2907, Loss: 2.209232121706009, Final Batch Loss: 0.48260554671287537\n",
      "Epoch 2908, Loss: 1.9895516633987427, Final Batch Loss: 0.3254789113998413\n",
      "Epoch 2909, Loss: 2.623499810695648, Final Batch Loss: 0.8692281246185303\n",
      "Epoch 2910, Loss: 1.8607059847563505, Final Batch Loss: 0.028417302295565605\n",
      "Epoch 2911, Loss: 2.2922085523605347, Final Batch Loss: 0.4504377841949463\n",
      "Epoch 2912, Loss: 1.822049617767334, Final Batch Loss: 0.09835028648376465\n",
      "Epoch 2913, Loss: 1.7902597768697888, Final Batch Loss: 0.0015827997121959925\n",
      "Epoch 2914, Loss: 3.59169864654541, Final Batch Loss: 1.8987257480621338\n",
      "Epoch 2915, Loss: 1.7620563581585884, Final Batch Loss: 0.036185868084430695\n",
      "Epoch 2916, Loss: 2.0964960753917694, Final Batch Loss: 0.43360641598701477\n",
      "Epoch 2917, Loss: 1.7927687652409077, Final Batch Loss: 0.041889119893312454\n",
      "Epoch 2918, Loss: 1.861932098865509, Final Batch Loss: 0.20606839656829834\n",
      "Epoch 2919, Loss: 1.7157838344573975, Final Batch Loss: 0.019407153129577637\n",
      "Epoch 2920, Loss: 1.619617447257042, Final Batch Loss: 0.0007116645574569702\n",
      "Epoch 2921, Loss: 1.6318353242531884, Final Batch Loss: 0.00039188333903439343\n",
      "Epoch 2922, Loss: 2.3597846031188965, Final Batch Loss: 0.7288228869438171\n",
      "Epoch 2923, Loss: 1.6766437031328678, Final Batch Loss: 0.01908639445900917\n",
      "Epoch 2924, Loss: 1.7924455553293228, Final Batch Loss: 0.13678617775440216\n",
      "Epoch 2925, Loss: 1.64883459568955, Final Batch Loss: 0.000528076896443963\n",
      "Epoch 2926, Loss: 3.174732208251953, Final Batch Loss: 1.5125081539154053\n",
      "Epoch 2927, Loss: 1.6533500105142593, Final Batch Loss: 0.001682177186012268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2928, Loss: 1.5922617400065064, Final Batch Loss: 0.012566902674734592\n",
      "Epoch 2929, Loss: 1.71287202835083, Final Batch Loss: 0.04971963167190552\n",
      "Epoch 2930, Loss: 2.38018661737442, Final Batch Loss: 0.7151866555213928\n",
      "Epoch 2931, Loss: 1.7259695399552584, Final Batch Loss: 0.02353029139339924\n",
      "Epoch 2932, Loss: 1.845573976635933, Final Batch Loss: 0.22549892961978912\n",
      "Epoch 2933, Loss: 2.037621319293976, Final Batch Loss: 0.4735431671142578\n",
      "Epoch 2934, Loss: 1.6381904094014317, Final Batch Loss: 0.002227446297183633\n",
      "Epoch 2935, Loss: 1.6409997704904526, Final Batch Loss: 0.0022205475252121687\n",
      "Epoch 2936, Loss: 2.821710556745529, Final Batch Loss: 1.232487678527832\n",
      "Epoch 2937, Loss: 1.6342070079917903, Final Batch Loss: 6.747018051100895e-05\n",
      "Epoch 2938, Loss: 1.673931488301605, Final Batch Loss: 0.006663957145065069\n",
      "Epoch 2939, Loss: 1.654992494979524, Final Batch Loss: 0.0002273062855238095\n",
      "Epoch 2940, Loss: 2.2655851542949677, Final Batch Loss: 0.678398072719574\n",
      "Epoch 2941, Loss: 2.688739597797394, Final Batch Loss: 1.0614509582519531\n",
      "Epoch 2942, Loss: 1.7553428560495377, Final Batch Loss: 0.14189060032367706\n",
      "Epoch 2943, Loss: 2.8856714367866516, Final Batch Loss: 1.240807294845581\n",
      "Epoch 2944, Loss: 3.2373037338256836, Final Batch Loss: 1.6712392568588257\n",
      "Epoch 2945, Loss: 3.349921405315399, Final Batch Loss: 1.648545265197754\n",
      "Epoch 2946, Loss: 1.9526867270469666, Final Batch Loss: 0.283342182636261\n",
      "Epoch 2947, Loss: 1.8393595665693283, Final Batch Loss: 0.139912948012352\n",
      "Epoch 2948, Loss: 2.795723021030426, Final Batch Loss: 1.2596807479858398\n",
      "Epoch 2949, Loss: 3.613805055618286, Final Batch Loss: 1.9683078527450562\n",
      "Epoch 2950, Loss: 2.0303152203559875, Final Batch Loss: 0.3959074020385742\n",
      "Epoch 2951, Loss: 1.5285190159920603, Final Batch Loss: 0.0013505632523447275\n",
      "Epoch 2952, Loss: 2.1706299781799316, Final Batch Loss: 0.5667280554771423\n",
      "Epoch 2953, Loss: 3.3270007967948914, Final Batch Loss: 1.7087746858596802\n",
      "Epoch 2954, Loss: 1.7288748882710934, Final Batch Loss: 0.04235657677054405\n",
      "Epoch 2955, Loss: 3.8429405093193054, Final Batch Loss: 2.2740087509155273\n",
      "Epoch 2956, Loss: 3.354414999485016, Final Batch Loss: 1.6808570623397827\n",
      "Epoch 2957, Loss: 2.0425898730754852, Final Batch Loss: 0.3634224236011505\n",
      "Epoch 2958, Loss: 2.313932478427887, Final Batch Loss: 0.6556901335716248\n",
      "Epoch 2959, Loss: 3.4237128496170044, Final Batch Loss: 1.7525328397750854\n",
      "Epoch 2960, Loss: 1.6969183419714682, Final Batch Loss: 0.000727627135347575\n",
      "Epoch 2961, Loss: 2.5132700204849243, Final Batch Loss: 0.7735157012939453\n",
      "Epoch 2962, Loss: 1.6932984510203823, Final Batch Loss: 0.0009845414897426963\n",
      "Epoch 2963, Loss: 3.367116153240204, Final Batch Loss: 1.698633074760437\n",
      "Epoch 2964, Loss: 1.662979893386364, Final Batch Loss: 0.02438073605298996\n",
      "Epoch 2965, Loss: 1.6588365212082863, Final Batch Loss: 0.03721354156732559\n",
      "Epoch 2966, Loss: 2.6770817041397095, Final Batch Loss: 1.0546869039535522\n",
      "Epoch 2967, Loss: 1.699989441782236, Final Batch Loss: 0.042183104902505875\n",
      "Epoch 2968, Loss: 2.329443097114563, Final Batch Loss: 0.670401394367218\n",
      "Epoch 2969, Loss: 1.7294597253203392, Final Batch Loss: 0.06771930307149887\n",
      "Epoch 2970, Loss: 1.6160600476141553, Final Batch Loss: 3.814624506048858e-05\n",
      "Epoch 2971, Loss: 1.6393385722767562, Final Batch Loss: 0.002174039138481021\n",
      "Epoch 2972, Loss: 1.8296507447957993, Final Batch Loss: 0.1754484623670578\n",
      "Epoch 2973, Loss: 1.9829866886138916, Final Batch Loss: 0.4070512354373932\n",
      "Epoch 2974, Loss: 1.710720993578434, Final Batch Loss: 0.09621686488389969\n",
      "Epoch 2975, Loss: 1.6830749455839396, Final Batch Loss: 0.030796164646744728\n",
      "Epoch 2976, Loss: 1.68104574654717, Final Batch Loss: 0.0010007378878071904\n",
      "Epoch 2977, Loss: 1.5950875668786466, Final Batch Loss: 0.007257053162902594\n",
      "Epoch 2978, Loss: 1.5937202803906985, Final Batch Loss: 0.0008877150830812752\n",
      "Epoch 2979, Loss: 2.7670191526412964, Final Batch Loss: 1.2121105194091797\n",
      "Epoch 2980, Loss: 2.445851892232895, Final Batch Loss: 0.8234633803367615\n",
      "Epoch 2981, Loss: 2.6751241087913513, Final Batch Loss: 0.9963339567184448\n",
      "Epoch 2982, Loss: 1.9397679381072521, Final Batch Loss: 0.050507526844739914\n",
      "Epoch 2983, Loss: 1.754914201097563, Final Batch Loss: 0.0024498470593243837\n",
      "Epoch 2984, Loss: 2.0023953318595886, Final Batch Loss: 0.3240063488483429\n",
      "Epoch 2985, Loss: 4.578479886054993, Final Batch Loss: 2.950188636779785\n",
      "Epoch 2986, Loss: 1.5602681338377806, Final Batch Loss: 9.059865078597795e-06\n",
      "Epoch 2987, Loss: 2.4379587918519974, Final Batch Loss: 0.10756601393222809\n",
      "Epoch 2988, Loss: 2.720020364620723, Final Batch Loss: 0.001328777172602713\n",
      "Epoch 2989, Loss: 2.972823053598404, Final Batch Loss: 0.22956231236457825\n",
      "Epoch 2990, Loss: 2.159166081575677, Final Batch Loss: 0.0029740172903984785\n",
      "Epoch 2991, Loss: 2.081208548974246, Final Batch Loss: 0.00372644467279315\n",
      "Epoch 2992, Loss: 3.8620254397392273, Final Batch Loss: 1.9620311260223389\n",
      "Epoch 2993, Loss: 2.0439419597387314, Final Batch Loss: 0.07247893512248993\n",
      "Epoch 2994, Loss: 1.9912213245988823, Final Batch Loss: 0.0008958140970207751\n",
      "Epoch 2995, Loss: 2.1165744364261627, Final Batch Loss: 0.24499818682670593\n",
      "Epoch 2996, Loss: 1.9060813374817371, Final Batch Loss: 0.05761422589421272\n",
      "Epoch 2997, Loss: 2.6353295147418976, Final Batch Loss: 0.8263585567474365\n",
      "Epoch 2998, Loss: 1.7912887097336352, Final Batch Loss: 0.0011131525970995426\n",
      "Epoch 2999, Loss: 1.9170114248991013, Final Batch Loss: 0.09353457391262054\n",
      "Epoch 3000, Loss: 1.7812315820801814, Final Batch Loss: 1.2993727978027891e-05\n",
      "Epoch 3001, Loss: 3.6358962655067444, Final Batch Loss: 1.7370401620864868\n",
      "Epoch 3002, Loss: 5.5559545159339905, Final Batch Loss: 3.780317783355713\n",
      "Epoch 3003, Loss: 1.7214174568653107, Final Batch Loss: 0.015399247407913208\n",
      "Epoch 3004, Loss: 1.8323837900534272, Final Batch Loss: 0.012970485724508762\n",
      "Epoch 3005, Loss: 1.8599434113129973, Final Batch Loss: 0.011815092526376247\n",
      "Epoch 3006, Loss: 2.545347034931183, Final Batch Loss: 0.7951054573059082\n",
      "Epoch 3007, Loss: 1.796921187764383, Final Batch Loss: 0.00010799778101500124\n",
      "Epoch 3008, Loss: 1.7155177508830093, Final Batch Loss: 0.0005052005290053785\n",
      "Epoch 3009, Loss: 2.0352770686149597, Final Batch Loss: 0.2920575737953186\n",
      "Epoch 3010, Loss: 2.3066099286079407, Final Batch Loss: 0.6361383199691772\n",
      "Epoch 3011, Loss: 4.390955626964569, Final Batch Loss: 2.7158854007720947\n",
      "Epoch 3012, Loss: 1.744958377443254, Final Batch Loss: 0.010954833589494228\n",
      "Epoch 3013, Loss: 3.3869054913520813, Final Batch Loss: 1.6169326305389404\n",
      "Epoch 3014, Loss: 1.723725447722245, Final Batch Loss: 0.0007594323833473027\n",
      "Epoch 3015, Loss: 2.8808735013008118, Final Batch Loss: 1.1835846900939941\n",
      "Epoch 3016, Loss: 2.523846924304962, Final Batch Loss: 0.8241880536079407\n",
      "Epoch 3017, Loss: 2.79398313164711, Final Batch Loss: 1.1192424297332764\n",
      "Epoch 3018, Loss: 2.1484488546848297, Final Batch Loss: 0.4606551229953766\n",
      "Epoch 3019, Loss: 1.7382698096334934, Final Batch Loss: 0.009954098612070084\n",
      "Epoch 3020, Loss: 3.410123825073242, Final Batch Loss: 1.6350849866867065\n",
      "Epoch 3021, Loss: 1.707720455386152, Final Batch Loss: 7.903263758635148e-05\n",
      "Epoch 3022, Loss: 1.8397557735443115, Final Batch Loss: 0.199662446975708\n",
      "Epoch 3023, Loss: 2.1837618947029114, Final Batch Loss: 0.5039125084877014\n",
      "Epoch 3024, Loss: 2.1621589064598083, Final Batch Loss: 0.5010992288589478\n",
      "Epoch 3025, Loss: 1.7011554688215256, Final Batch Loss: 0.02620081603527069\n",
      "Epoch 3026, Loss: 1.7673687562346458, Final Batch Loss: 0.06640543788671494\n",
      "Epoch 3027, Loss: 2.459621250629425, Final Batch Loss: 0.825038492679596\n",
      "Epoch 3028, Loss: 1.9400942921638489, Final Batch Loss: 0.19955211877822876\n",
      "Epoch 3029, Loss: 2.4302926659584045, Final Batch Loss: 0.656602144241333\n",
      "Epoch 3030, Loss: 1.7865732078207657, Final Batch Loss: 0.0018065337790176272\n",
      "Epoch 3031, Loss: 1.9020949602127075, Final Batch Loss: 0.2509543299674988\n",
      "Epoch 3032, Loss: 2.1232940554618835, Final Batch Loss: 0.5001188516616821\n",
      "Epoch 3033, Loss: 1.685341315343976, Final Batch Loss: 0.02577395923435688\n",
      "Epoch 3034, Loss: 2.994211792945862, Final Batch Loss: 1.2288845777511597\n",
      "Epoch 3035, Loss: 4.162343442440033, Final Batch Loss: 2.4200785160064697\n",
      "Epoch 3036, Loss: 1.7865669280290604, Final Batch Loss: 0.130753293633461\n",
      "Epoch 3037, Loss: 2.903921127319336, Final Batch Loss: 1.222546100616455\n",
      "Epoch 3038, Loss: 2.884038805961609, Final Batch Loss: 1.2361257076263428\n",
      "Epoch 3039, Loss: 1.5943837645463645, Final Batch Loss: 0.005896079819649458\n",
      "Epoch 3040, Loss: 1.637994010001421, Final Batch Loss: 0.005611974745988846\n",
      "Epoch 3041, Loss: 1.7441973986569792, Final Batch Loss: 0.0007320346776396036\n",
      "Epoch 3042, Loss: 1.6991228577680886, Final Batch Loss: 0.002944540698081255\n",
      "Epoch 3043, Loss: 2.4915178418159485, Final Batch Loss: 0.8871174454689026\n",
      "Epoch 3044, Loss: 2.3832030296325684, Final Batch Loss: 0.7365116477012634\n",
      "Epoch 3045, Loss: 1.6196670676581562, Final Batch Loss: 0.0032510305754840374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3046, Loss: 1.7036913633346558, Final Batch Loss: 0.018823444843292236\n",
      "Epoch 3047, Loss: 1.6460672412067652, Final Batch Loss: 0.020963290706276894\n",
      "Epoch 3048, Loss: 4.0614864230155945, Final Batch Loss: 2.491433620452881\n",
      "Epoch 3049, Loss: 1.7245356552302837, Final Batch Loss: 0.056729983538389206\n",
      "Epoch 3050, Loss: 2.2789483070373535, Final Batch Loss: 0.692769467830658\n",
      "Epoch 3051, Loss: 2.4006054401397705, Final Batch Loss: 0.722761869430542\n",
      "Epoch 3052, Loss: 1.8120660185813904, Final Batch Loss: 0.25613516569137573\n",
      "Epoch 3053, Loss: 1.7693203687667847, Final Batch Loss: 0.13674437999725342\n",
      "Epoch 3054, Loss: 2.9467511773109436, Final Batch Loss: 1.2629871368408203\n",
      "Epoch 3055, Loss: 1.749408297240734, Final Batch Loss: 0.05962669104337692\n",
      "Epoch 3056, Loss: 4.219675421714783, Final Batch Loss: 2.524686098098755\n",
      "Epoch 3057, Loss: 1.8166012614965439, Final Batch Loss: 0.21785424649715424\n",
      "Epoch 3058, Loss: 1.6498007773188874, Final Batch Loss: 0.0005460678366944194\n",
      "Epoch 3059, Loss: 1.7771299043670297, Final Batch Loss: 0.0024339118972420692\n",
      "Epoch 3060, Loss: 2.241211175918579, Final Batch Loss: 0.48080551624298096\n",
      "Epoch 3061, Loss: 2.0605952441692352, Final Batch Loss: 0.2476067841053009\n",
      "Epoch 3062, Loss: 2.2368963062763214, Final Batch Loss: 0.3916034996509552\n",
      "Epoch 3063, Loss: 1.8575884625315666, Final Batch Loss: 0.01148175448179245\n",
      "Epoch 3064, Loss: 3.0617105960845947, Final Batch Loss: 1.250873327255249\n",
      "Epoch 3065, Loss: 1.8306552013382316, Final Batch Loss: 0.004632099531590939\n",
      "Epoch 3066, Loss: 1.930867925286293, Final Batch Loss: 0.2252548485994339\n",
      "Epoch 3067, Loss: 3.4277124404907227, Final Batch Loss: 1.6635979413986206\n",
      "Epoch 3068, Loss: 2.0312255024909973, Final Batch Loss: 0.3104541301727295\n",
      "Epoch 3069, Loss: 2.8308196663856506, Final Batch Loss: 1.1424239873886108\n",
      "Epoch 3070, Loss: 2.412903308868408, Final Batch Loss: 0.4787692427635193\n",
      "Epoch 3071, Loss: 3.132295608520508, Final Batch Loss: 1.2708747386932373\n",
      "Epoch 3072, Loss: 1.8057710104621947, Final Batch Loss: 0.00763084227219224\n",
      "Epoch 3073, Loss: 2.1895621716976166, Final Batch Loss: 0.4290001094341278\n",
      "Epoch 3074, Loss: 1.7137533137574792, Final Batch Loss: 0.01009336207062006\n",
      "Epoch 3075, Loss: 1.8252248615026474, Final Batch Loss: 0.1508284956216812\n",
      "Epoch 3076, Loss: 2.175657629966736, Final Batch Loss: 0.46202218532562256\n",
      "Epoch 3077, Loss: 1.6727983951122951, Final Batch Loss: 9.417489309271332e-06\n",
      "Epoch 3078, Loss: 2.347779393196106, Final Batch Loss: 0.6954646706581116\n",
      "Epoch 3079, Loss: 1.7015873052441748, Final Batch Loss: 0.00016807096835691482\n",
      "Epoch 3080, Loss: 3.4584780037403107, Final Batch Loss: 1.795365333557129\n",
      "Epoch 3081, Loss: 1.6465183920226991, Final Batch Loss: 0.00018559163436293602\n",
      "Epoch 3082, Loss: 2.7877233922481537, Final Batch Loss: 1.119728684425354\n",
      "Epoch 3083, Loss: 1.7459370866417885, Final Batch Loss: 0.04388747364282608\n",
      "Epoch 3084, Loss: 1.6231812611222267, Final Batch Loss: 0.019148029386997223\n",
      "Epoch 3085, Loss: 2.884292483329773, Final Batch Loss: 1.247997760772705\n",
      "Epoch 3086, Loss: 1.754029169678688, Final Batch Loss: 0.14055927097797394\n",
      "Epoch 3087, Loss: 1.626414592101355, Final Batch Loss: 9.929640509653836e-05\n",
      "Epoch 3088, Loss: 1.7669002935290337, Final Batch Loss: 0.11180644482374191\n",
      "Epoch 3089, Loss: 1.6915243691764772, Final Batch Loss: 0.006813270505517721\n",
      "Epoch 3090, Loss: 1.9185124933719635, Final Batch Loss: 0.2965073883533478\n",
      "Epoch 3091, Loss: 2.9811619222164154, Final Batch Loss: 1.2655205726623535\n",
      "Epoch 3092, Loss: 1.7839203998446465, Final Batch Loss: 0.11961590498685837\n",
      "Epoch 3093, Loss: 1.6339483130723238, Final Batch Loss: 0.009112672880291939\n",
      "Epoch 3094, Loss: 2.357881247997284, Final Batch Loss: 0.7176291346549988\n",
      "Epoch 3095, Loss: 5.676189124584198, Final Batch Loss: 4.105372905731201\n",
      "Epoch 3096, Loss: 3.2609145641326904, Final Batch Loss: 1.5949161052703857\n",
      "Epoch 3097, Loss: 1.7889395589008927, Final Batch Loss: 0.008350693620741367\n",
      "Epoch 3098, Loss: 1.8168642409145832, Final Batch Loss: 0.06154118850827217\n",
      "Epoch 3099, Loss: 3.69586980342865, Final Batch Loss: 1.9621100425720215\n",
      "Epoch 3100, Loss: 1.9064777195453644, Final Batch Loss: 0.15605732798576355\n",
      "Epoch 3101, Loss: 1.722146589832846, Final Batch Loss: 0.0002843929105438292\n",
      "Epoch 3102, Loss: 1.7078689988702536, Final Batch Loss: 0.018162136897444725\n",
      "Epoch 3103, Loss: 1.841493397951126, Final Batch Loss: 0.09054359793663025\n",
      "Epoch 3104, Loss: 3.619164526462555, Final Batch Loss: 1.9067349433898926\n",
      "Epoch 3105, Loss: 1.690676974831149, Final Batch Loss: 0.002765285549685359\n",
      "Epoch 3106, Loss: 1.6524671897423104, Final Batch Loss: 5.435795901576057e-05\n",
      "Epoch 3107, Loss: 1.7182443924248219, Final Batch Loss: 0.03220357373356819\n",
      "Epoch 3108, Loss: 1.644287930597784, Final Batch Loss: 0.0001627074379939586\n",
      "Epoch 3109, Loss: 1.5877430913969874, Final Batch Loss: 0.0043464479967951775\n",
      "Epoch 3110, Loss: 1.7444973438978195, Final Batch Loss: 0.15335865318775177\n",
      "Epoch 3111, Loss: 1.6356807517586276, Final Batch Loss: 0.0011302995262667537\n",
      "Epoch 3112, Loss: 2.3784243166446686, Final Batch Loss: 0.7239825129508972\n",
      "Epoch 3113, Loss: 1.6481740921735764, Final Batch Loss: 0.03704790771007538\n",
      "Epoch 3114, Loss: 1.678888320682745, Final Batch Loss: 2.1934269170742482e-05\n",
      "Epoch 3115, Loss: 1.7258757650852203, Final Batch Loss: 0.04120388627052307\n",
      "Epoch 3116, Loss: 2.0756170451641083, Final Batch Loss: 0.38562890887260437\n",
      "Epoch 3117, Loss: 1.759801909327507, Final Batch Loss: 0.09183017909526825\n",
      "Epoch 3118, Loss: 2.276822030544281, Final Batch Loss: 0.5678822994232178\n",
      "Epoch 3119, Loss: 3.051209330558777, Final Batch Loss: 1.30740225315094\n",
      "Epoch 3120, Loss: 1.8080970644950867, Final Batch Loss: 0.11069762706756592\n",
      "Epoch 3121, Loss: 1.7370864590629935, Final Batch Loss: 0.006591483019292355\n",
      "Epoch 3122, Loss: 2.4129799604415894, Final Batch Loss: 0.7817835211753845\n",
      "Epoch 3123, Loss: 2.21444970369339, Final Batch Loss: 0.5263665914535522\n",
      "Epoch 3124, Loss: 4.365394979715347, Final Batch Loss: 2.729858875274658\n",
      "Epoch 3125, Loss: 1.7553451623462024, Final Batch Loss: 8.225102646974847e-05\n",
      "Epoch 3126, Loss: 1.9565589725971222, Final Batch Loss: 0.2529362142086029\n",
      "Epoch 3127, Loss: 1.632755191065371, Final Batch Loss: 0.0034761736169457436\n",
      "Epoch 3128, Loss: 2.201994001865387, Final Batch Loss: 0.5981307029724121\n",
      "Epoch 3129, Loss: 1.6861692515667528, Final Batch Loss: 0.001208409434184432\n",
      "Epoch 3130, Loss: 3.107209324836731, Final Batch Loss: 1.5070044994354248\n",
      "Epoch 3131, Loss: 1.6401357594731962, Final Batch Loss: 0.00010585224663373083\n",
      "Epoch 3132, Loss: 3.053936719894409, Final Batch Loss: 1.4838683605194092\n",
      "Epoch 3133, Loss: 3.1105427742004395, Final Batch Loss: 1.491721510887146\n",
      "Epoch 3134, Loss: 1.617896769195795, Final Batch Loss: 0.01357525959610939\n",
      "Epoch 3135, Loss: 3.1123831272125244, Final Batch Loss: 1.5479240417480469\n",
      "Epoch 3136, Loss: 1.6858774423599243, Final Batch Loss: 0.0738987922668457\n",
      "Epoch 3137, Loss: 1.7112416699528694, Final Batch Loss: 0.08715290576219559\n",
      "Epoch 3138, Loss: 1.7002598084509373, Final Batch Loss: 0.04749000445008278\n",
      "Epoch 3139, Loss: 1.6701363772153854, Final Batch Loss: 0.05869285762310028\n",
      "Epoch 3140, Loss: 1.6390506410971284, Final Batch Loss: 0.00959251169115305\n",
      "Epoch 3141, Loss: 2.1230606138706207, Final Batch Loss: 0.4829320013523102\n",
      "Epoch 3142, Loss: 2.121001362800598, Final Batch Loss: 0.5373523831367493\n",
      "Epoch 3143, Loss: 1.5548062083980767, Final Batch Loss: 0.000219321038457565\n",
      "Epoch 3144, Loss: 1.6787756512640044, Final Batch Loss: 0.0010518262861296535\n",
      "Epoch 3145, Loss: 2.8538848161697388, Final Batch Loss: 1.1790707111358643\n",
      "Epoch 3146, Loss: 1.6499384045555416, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 3147, Loss: 2.5037750005722046, Final Batch Loss: 0.867131769657135\n",
      "Epoch 3148, Loss: 2.6158483624458313, Final Batch Loss: 0.8687692880630493\n",
      "Epoch 3149, Loss: 1.8908838480710983, Final Batch Loss: 0.24329279363155365\n",
      "Epoch 3150, Loss: 2.5518605709075928, Final Batch Loss: 0.8618475794792175\n",
      "Epoch 3151, Loss: 1.7941114753484726, Final Batch Loss: 0.15504972636699677\n",
      "Epoch 3152, Loss: 2.878337323665619, Final Batch Loss: 1.2194929122924805\n",
      "Epoch 3153, Loss: 2.3496503233909607, Final Batch Loss: 0.5847641825675964\n",
      "Epoch 3154, Loss: 1.6762357277330011, Final Batch Loss: 0.0017302555497735739\n",
      "Epoch 3155, Loss: 2.8694533109664917, Final Batch Loss: 1.1756508350372314\n",
      "Epoch 3156, Loss: 3.4015656113624573, Final Batch Loss: 1.8241335153579712\n",
      "Epoch 3157, Loss: 1.8169774413108826, Final Batch Loss: 0.13932281732559204\n",
      "Epoch 3158, Loss: 1.6197449039318599, Final Batch Loss: 0.00021336186910048127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3159, Loss: 1.6447893244767329, Final Batch Loss: 0.00016509123088326305\n",
      "Epoch 3160, Loss: 1.7173468763940036, Final Batch Loss: 0.006203680764883757\n",
      "Epoch 3161, Loss: 1.5859243239974603, Final Batch Loss: 0.000849601230584085\n",
      "Epoch 3162, Loss: 1.668280377984047, Final Batch Loss: 0.06307144463062286\n",
      "Epoch 3163, Loss: 2.6893251836299896, Final Batch Loss: 1.0434632301330566\n",
      "Epoch 3164, Loss: 1.6480681896155147, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 3165, Loss: 1.6441834721481428, Final Batch Loss: 0.0011314902221783996\n",
      "Epoch 3166, Loss: 1.9981218874454498, Final Batch Loss: 0.3936810791492462\n",
      "Epoch 3167, Loss: 2.4520264267921448, Final Batch Loss: 0.7783876657485962\n",
      "Epoch 3168, Loss: 1.514605193704483, Final Batch Loss: 3.540453326422721e-05\n",
      "Epoch 3169, Loss: 2.956092357635498, Final Batch Loss: 1.285854697227478\n",
      "Epoch 3170, Loss: 2.162814199924469, Final Batch Loss: 0.5542258620262146\n",
      "Epoch 3171, Loss: 3.126080572605133, Final Batch Loss: 1.380280613899231\n",
      "Epoch 3172, Loss: 2.061088353395462, Final Batch Loss: 0.3204546272754669\n",
      "Epoch 3173, Loss: 2.3891788125038147, Final Batch Loss: 0.6999331116676331\n",
      "Epoch 3174, Loss: 1.618649184703827, Final Batch Loss: 0.006274998188018799\n",
      "Epoch 3175, Loss: 1.6392188959289342, Final Batch Loss: 0.001524715917184949\n",
      "Epoch 3176, Loss: 2.163494259119034, Final Batch Loss: 0.42964968085289\n",
      "Epoch 3177, Loss: 1.8926340118050575, Final Batch Loss: 0.1242549791932106\n",
      "Epoch 3178, Loss: 2.4149139523506165, Final Batch Loss: 0.7481306195259094\n",
      "Epoch 3179, Loss: 2.715196043252945, Final Batch Loss: 1.1011971235275269\n",
      "Epoch 3180, Loss: 2.044532686471939, Final Batch Loss: 0.38930466771125793\n",
      "Epoch 3181, Loss: 1.641789922490716, Final Batch Loss: 0.021994123235344887\n",
      "Epoch 3182, Loss: 1.8947904855012894, Final Batch Loss: 0.17505468428134918\n",
      "Epoch 3183, Loss: 2.5765814185142517, Final Batch Loss: 1.0358624458312988\n",
      "Epoch 3184, Loss: 3.0402767062187195, Final Batch Loss: 1.4097439050674438\n",
      "Epoch 3185, Loss: 1.6902893632650375, Final Batch Loss: 0.042185619473457336\n",
      "Epoch 3186, Loss: 1.610172250730102, Final Batch Loss: 0.00020489977032411844\n",
      "Epoch 3187, Loss: 2.720952123403549, Final Batch Loss: 1.1429718732833862\n",
      "Epoch 3188, Loss: 2.6587037444114685, Final Batch Loss: 1.0229412317276\n",
      "Epoch 3189, Loss: 1.6020481687737629, Final Batch Loss: 0.0014575821114704013\n",
      "Epoch 3190, Loss: 3.152480363845825, Final Batch Loss: 1.4542597532272339\n",
      "Epoch 3191, Loss: 1.545848535373807, Final Batch Loss: 0.018421398475766182\n",
      "Epoch 3192, Loss: 1.6336135268079488, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 3193, Loss: 1.9182245433330536, Final Batch Loss: 0.32413360476493835\n",
      "Epoch 3194, Loss: 1.687448039650917, Final Batch Loss: 0.0850696712732315\n",
      "Epoch 3195, Loss: 1.7200603187084198, Final Batch Loss: 0.07355639338493347\n",
      "Epoch 3196, Loss: 1.669634897261858, Final Batch Loss: 0.016291815787553787\n",
      "Epoch 3197, Loss: 2.9381447434425354, Final Batch Loss: 1.3695318698883057\n",
      "Epoch 3198, Loss: 1.5854364335245918, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 3199, Loss: 1.5999830226646736, Final Batch Loss: 0.0017678599106147885\n",
      "Epoch 3200, Loss: 1.5755727135110646, Final Batch Loss: 0.001348539488390088\n",
      "Epoch 3201, Loss: 1.5556037294736598, Final Batch Loss: 0.00016199229867197573\n",
      "Epoch 3202, Loss: 1.5480695813894272, Final Batch Loss: 0.02255360782146454\n",
      "Epoch 3203, Loss: 1.6460631486061175, Final Batch Loss: 2.7179348762729205e-05\n",
      "Epoch 3204, Loss: 1.558768080896698, Final Batch Loss: 0.0009893052047118545\n",
      "Epoch 3205, Loss: 2.4375127851963043, Final Batch Loss: 0.8424579501152039\n",
      "Epoch 3206, Loss: 3.095641642808914, Final Batch Loss: 1.5656458139419556\n",
      "Epoch 3207, Loss: 3.0392603874206543, Final Batch Loss: 1.4675487279891968\n",
      "Epoch 3208, Loss: 1.5962577199097723, Final Batch Loss: 0.0017748808022588491\n",
      "Epoch 3209, Loss: 2.1208653151988983, Final Batch Loss: 0.542984664440155\n",
      "Epoch 3210, Loss: 1.6370595982189116, Final Batch Loss: 4.339123915997334e-05\n",
      "Epoch 3211, Loss: 2.1166864931583405, Final Batch Loss: 0.5250769853591919\n",
      "Epoch 3212, Loss: 1.619038313627243, Final Batch Loss: 0.08276152610778809\n",
      "Epoch 3213, Loss: 2.3388313949108124, Final Batch Loss: 0.7869288325309753\n",
      "Epoch 3214, Loss: 1.6035213861614466, Final Batch Loss: 0.02159241773188114\n",
      "Epoch 3215, Loss: 2.061105579137802, Final Batch Loss: 0.44852739572525024\n",
      "Epoch 3216, Loss: 1.6526459604501724, Final Batch Loss: 0.09359656274318695\n",
      "Epoch 3217, Loss: 1.5600382490083575, Final Batch Loss: 0.013810436241328716\n",
      "Epoch 3218, Loss: 1.6232310691848397, Final Batch Loss: 0.004752055741846561\n",
      "Epoch 3219, Loss: 1.7190639078617096, Final Batch Loss: 0.18384739756584167\n",
      "Epoch 3220, Loss: 1.753505878150463, Final Batch Loss: 0.12228693813085556\n",
      "Epoch 3221, Loss: 1.5871385319551337, Final Batch Loss: 5.721882189391181e-05\n",
      "Epoch 3222, Loss: 2.5040649473667145, Final Batch Loss: 0.9618139863014221\n",
      "Epoch 3223, Loss: 2.6664510667324066, Final Batch Loss: 1.0725524425506592\n",
      "Epoch 3224, Loss: 2.3801781833171844, Final Batch Loss: 0.8258649706840515\n",
      "Epoch 3225, Loss: 3.7251296937465668, Final Batch Loss: 2.0530714988708496\n",
      "Epoch 3226, Loss: 2.4936466217041016, Final Batch Loss: 0.7872499227523804\n",
      "Epoch 3227, Loss: 3.6602869629859924, Final Batch Loss: 1.8667771816253662\n",
      "Epoch 3228, Loss: 1.8669932186603546, Final Batch Loss: 0.27814432978630066\n",
      "Epoch 3229, Loss: 1.810820147395134, Final Batch Loss: 0.21912126243114471\n",
      "Epoch 3230, Loss: 2.4195444583892822, Final Batch Loss: 0.7391361594200134\n",
      "Epoch 3231, Loss: 1.5987665919819847, Final Batch Loss: 0.0007759897271171212\n",
      "Epoch 3232, Loss: 1.648860423185397, Final Batch Loss: 0.00042655906872823834\n",
      "Epoch 3233, Loss: 1.6612504529766738, Final Batch Loss: 0.0066099571995437145\n",
      "Epoch 3234, Loss: 1.592896387912333, Final Batch Loss: 0.002610967494547367\n",
      "Epoch 3235, Loss: 2.160785675048828, Final Batch Loss: 0.5770232081413269\n",
      "Epoch 3236, Loss: 4.656614720821381, Final Batch Loss: 3.10463809967041\n",
      "Epoch 3237, Loss: 1.8632395267486572, Final Batch Loss: 0.3338033854961395\n",
      "Epoch 3238, Loss: 1.7387914210557938, Final Batch Loss: 0.1385890394449234\n",
      "Epoch 3239, Loss: 3.4123826026916504, Final Batch Loss: 1.779943585395813\n",
      "Epoch 3240, Loss: 2.9535924196243286, Final Batch Loss: 1.2599798440933228\n",
      "Epoch 3241, Loss: 1.7235218881487526, Final Batch Loss: 1.4662635294371285e-05\n",
      "Epoch 3242, Loss: 3.4470471143722534, Final Batch Loss: 1.7845044136047363\n",
      "Epoch 3243, Loss: 1.7529034093022346, Final Batch Loss: 0.1187262013554573\n",
      "Epoch 3244, Loss: 1.7340240776538849, Final Batch Loss: 0.1617882251739502\n",
      "Epoch 3245, Loss: 1.5867334900285641, Final Batch Loss: 2.002696055569686e-05\n",
      "Epoch 3246, Loss: 1.6824585497379303, Final Batch Loss: 0.07698315382003784\n",
      "Epoch 3247, Loss: 1.6467472920194268, Final Batch Loss: 0.015291244722902775\n",
      "Epoch 3248, Loss: 1.6377761320327409, Final Batch Loss: 9.345571743324399e-05\n",
      "Epoch 3249, Loss: 1.50185082652024, Final Batch Loss: 0.00030560590676032007\n",
      "Epoch 3250, Loss: 1.5402306289615808, Final Batch Loss: 7.56950321374461e-05\n",
      "Epoch 3251, Loss: 3.2709425389766693, Final Batch Loss: 1.7199466228485107\n",
      "Epoch 3252, Loss: 2.7468860149383545, Final Batch Loss: 1.1740140914916992\n",
      "Epoch 3253, Loss: 1.640177413704805, Final Batch Loss: 0.00017331528943032026\n",
      "Epoch 3254, Loss: 1.748969927430153, Final Batch Loss: 0.11727459728717804\n",
      "Epoch 3255, Loss: 2.4892624020576477, Final Batch Loss: 0.9522312879562378\n",
      "Epoch 3256, Loss: 2.1263965368270874, Final Batch Loss: 0.41438764333724976\n",
      "Epoch 3257, Loss: 1.9644323289394379, Final Batch Loss: 0.3206999599933624\n",
      "Epoch 3258, Loss: 2.664331704378128, Final Batch Loss: 1.1275660991668701\n",
      "Epoch 3259, Loss: 1.8810576051473618, Final Batch Loss: 0.24314753711223602\n",
      "Epoch 3260, Loss: 1.6691191727295518, Final Batch Loss: 0.009738200344145298\n",
      "Epoch 3261, Loss: 1.7014439459890127, Final Batch Loss: 0.0005355831235647202\n",
      "Epoch 3262, Loss: 1.6689594462513924, Final Batch Loss: 0.025607116520404816\n",
      "Epoch 3263, Loss: 2.0040288865566254, Final Batch Loss: 0.35173729062080383\n",
      "Epoch 3264, Loss: 1.6131680523976684, Final Batch Loss: 0.004338732920587063\n",
      "Epoch 3265, Loss: 1.5334285795624965, Final Batch Loss: 3.576272320060525e-06\n",
      "Epoch 3266, Loss: 1.6290142852813005, Final Batch Loss: 0.010388584807515144\n",
      "Epoch 3267, Loss: 1.6837557256221771, Final Batch Loss: 0.07772758603096008\n",
      "Epoch 3268, Loss: 1.7657744735479355, Final Batch Loss: 0.18100665509700775\n",
      "Epoch 3269, Loss: 1.5894362175604329, Final Batch Loss: 0.0017347777029499412\n",
      "Epoch 3270, Loss: 2.6861567199230194, Final Batch Loss: 1.1449525356292725\n",
      "Epoch 3271, Loss: 2.0233748853206635, Final Batch Loss: 0.4383585751056671\n",
      "Epoch 3272, Loss: 1.6042169885477051, Final Batch Loss: 0.0002611534437164664\n",
      "Epoch 3273, Loss: 1.5309656256031303, Final Batch Loss: 3.564294092939235e-05\n",
      "Epoch 3274, Loss: 2.788630723953247, Final Batch Loss: 1.1823252439498901\n",
      "Epoch 3275, Loss: 1.643315924826311, Final Batch Loss: 0.00030357998912222683\n",
      "Epoch 3276, Loss: 1.6732358005829155, Final Batch Loss: 0.0011734035797417164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3277, Loss: 1.636007621884346, Final Batch Loss: 0.032148972153663635\n",
      "Epoch 3278, Loss: 2.3075106143951416, Final Batch Loss: 0.7447184324264526\n",
      "Epoch 3279, Loss: 1.9141543805599213, Final Batch Loss: 0.27924683690071106\n",
      "Epoch 3280, Loss: 1.6608362570405006, Final Batch Loss: 0.09625671058893204\n",
      "Epoch 3281, Loss: 3.4308468103408813, Final Batch Loss: 1.8988494873046875\n",
      "Epoch 3282, Loss: 1.6544233113527298, Final Batch Loss: 0.12762700021266937\n",
      "Epoch 3283, Loss: 1.7795421034097672, Final Batch Loss: 0.16260559856891632\n",
      "Epoch 3284, Loss: 3.1836578845977783, Final Batch Loss: 1.5627976655960083\n",
      "Epoch 3285, Loss: 3.3722841441631317, Final Batch Loss: 1.8205931186676025\n",
      "Epoch 3286, Loss: 1.9234668910503387, Final Batch Loss: 0.2928529679775238\n",
      "Epoch 3287, Loss: 1.9738734066486359, Final Batch Loss: 0.4270387887954712\n",
      "Epoch 3288, Loss: 1.7091726120561361, Final Batch Loss: 0.00921744666993618\n",
      "Epoch 3289, Loss: 1.6109399311244488, Final Batch Loss: 0.03310514613986015\n",
      "Epoch 3290, Loss: 1.7285475507378578, Final Batch Loss: 0.005132712423801422\n",
      "Epoch 3291, Loss: 2.2219740748405457, Final Batch Loss: 0.6464641094207764\n",
      "Epoch 3292, Loss: 2.0367705821990967, Final Batch Loss: 0.4471353590488434\n",
      "Epoch 3293, Loss: 1.7277685403823853, Final Batch Loss: 0.04913973808288574\n",
      "Epoch 3294, Loss: 1.6144177690148354, Final Batch Loss: 0.012424804270267487\n",
      "Epoch 3295, Loss: 2.671506941318512, Final Batch Loss: 1.0250580310821533\n",
      "Epoch 3296, Loss: 4.1528748869895935, Final Batch Loss: 2.610118865966797\n",
      "Epoch 3297, Loss: 1.8700828030705452, Final Batch Loss: 0.1015065386891365\n",
      "Epoch 3298, Loss: 1.8151396214962006, Final Batch Loss: 0.055411964654922485\n",
      "Epoch 3299, Loss: 1.8009723271243274, Final Batch Loss: 0.006085201632231474\n",
      "Epoch 3300, Loss: 3.491141438484192, Final Batch Loss: 1.7048563957214355\n",
      "Epoch 3301, Loss: 2.269537091255188, Final Batch Loss: 0.5505154728889465\n",
      "Epoch 3302, Loss: 1.8500775396823883, Final Batch Loss: 0.1602034866809845\n",
      "Epoch 3303, Loss: 1.6719012279063463, Final Batch Loss: 0.026528121903538704\n",
      "Epoch 3304, Loss: 4.768952310085297, Final Batch Loss: 3.0838446617126465\n",
      "Epoch 3305, Loss: 1.8872937560081482, Final Batch Loss: 0.2909562587738037\n",
      "Epoch 3306, Loss: 1.6788100567646325, Final Batch Loss: 0.0010387268848717213\n",
      "Epoch 3307, Loss: 2.039875239133835, Final Batch Loss: 0.20793506503105164\n",
      "Epoch 3308, Loss: 2.2440364956855774, Final Batch Loss: 0.4594898223876953\n",
      "Epoch 3309, Loss: 1.8814204558730125, Final Batch Loss: 0.035826168954372406\n",
      "Epoch 3310, Loss: 3.1498706936836243, Final Batch Loss: 1.3421828746795654\n",
      "Epoch 3311, Loss: 4.076802134513855, Final Batch Loss: 2.277125358581543\n",
      "Epoch 3312, Loss: 4.054967641830444, Final Batch Loss: 2.2614665031433105\n",
      "Epoch 3313, Loss: 1.7605830682441592, Final Batch Loss: 0.005361582152545452\n",
      "Epoch 3314, Loss: 1.7649109449703246, Final Batch Loss: 0.003730007680132985\n",
      "Epoch 3315, Loss: 2.8011218309402466, Final Batch Loss: 1.0590448379516602\n",
      "Epoch 3316, Loss: 3.343882977962494, Final Batch Loss: 1.7185148000717163\n",
      "Epoch 3317, Loss: 3.8008298873901367, Final Batch Loss: 2.0557544231414795\n",
      "Epoch 3318, Loss: 2.619713246822357, Final Batch Loss: 0.8835207223892212\n",
      "Epoch 3319, Loss: 1.996591955423355, Final Batch Loss: 0.18615129590034485\n",
      "Epoch 3320, Loss: 2.58696049451828, Final Batch Loss: 0.7774263620376587\n",
      "Epoch 3321, Loss: 3.5878420174121857, Final Batch Loss: 1.9895612001419067\n",
      "Epoch 3322, Loss: 3.5812808573246, Final Batch Loss: 1.9209538698196411\n",
      "Epoch 3323, Loss: 1.7776512503005506, Final Batch Loss: 1.1086402082582936e-05\n",
      "Epoch 3324, Loss: 3.3806220293045044, Final Batch Loss: 1.7167738676071167\n",
      "Epoch 3325, Loss: 3.2066465616226196, Final Batch Loss: 1.5328679084777832\n",
      "Epoch 3326, Loss: 3.742356061935425, Final Batch Loss: 2.0500824451446533\n",
      "Epoch 3327, Loss: 2.1676143407821655, Final Batch Loss: 0.5049464702606201\n",
      "Epoch 3328, Loss: 1.667739157215692, Final Batch Loss: 0.0003325386205688119\n",
      "Epoch 3329, Loss: 3.2825942039489746, Final Batch Loss: 1.5399152040481567\n",
      "Epoch 3330, Loss: 1.6059420797973871, Final Batch Loss: 0.004864761605858803\n",
      "Epoch 3331, Loss: 1.7922095656394958, Final Batch Loss: 0.19595694541931152\n",
      "Epoch 3332, Loss: 1.6488088071346283, Final Batch Loss: 0.10764041543006897\n",
      "Epoch 3333, Loss: 2.1167746782302856, Final Batch Loss: 0.5310463309288025\n",
      "Epoch 3334, Loss: 3.4771276116371155, Final Batch Loss: 1.8025990724563599\n",
      "Epoch 3335, Loss: 1.7710340917110443, Final Batch Loss: 0.18023982644081116\n",
      "Epoch 3336, Loss: 1.6373531972058117, Final Batch Loss: 0.005580679047852755\n",
      "Epoch 3337, Loss: 1.64194649271667, Final Batch Loss: 0.013426600024104118\n",
      "Epoch 3338, Loss: 1.5865316005656496, Final Batch Loss: 0.0008203001925721765\n",
      "Epoch 3339, Loss: 1.6260594800114632, Final Batch Loss: 0.04314366728067398\n",
      "Epoch 3340, Loss: 2.2616808712482452, Final Batch Loss: 0.6744116544723511\n",
      "Epoch 3341, Loss: 2.467683345079422, Final Batch Loss: 0.8048751354217529\n",
      "Epoch 3342, Loss: 1.6988662481307983, Final Batch Loss: 0.06613075733184814\n",
      "Epoch 3343, Loss: 1.8344361037015915, Final Batch Loss: 0.21636642515659332\n",
      "Epoch 3344, Loss: 1.6298658251757843, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 3345, Loss: 1.7367718666791916, Final Batch Loss: 0.14550094306468964\n",
      "Epoch 3346, Loss: 1.8947210013866425, Final Batch Loss: 0.31500163674354553\n",
      "Epoch 3347, Loss: 3.2246479392051697, Final Batch Loss: 1.498150110244751\n",
      "Epoch 3348, Loss: 1.7684733718633652, Final Batch Loss: 0.08413563668727875\n",
      "Epoch 3349, Loss: 1.6324385347543284, Final Batch Loss: 0.001763218897394836\n",
      "Epoch 3350, Loss: 1.6192320017144084, Final Batch Loss: 0.0118716387078166\n",
      "Epoch 3351, Loss: 3.1183935403823853, Final Batch Loss: 1.506181240081787\n",
      "Epoch 3352, Loss: 1.8704539239406586, Final Batch Loss: 0.2582692801952362\n",
      "Epoch 3353, Loss: 3.457141548395157, Final Batch Loss: 1.8530515432357788\n",
      "Epoch 3354, Loss: 2.276370882987976, Final Batch Loss: 0.6748701333999634\n",
      "Epoch 3355, Loss: 2.151911675930023, Final Batch Loss: 0.5515019297599792\n",
      "Epoch 3356, Loss: 2.472796231508255, Final Batch Loss: 0.951896607875824\n",
      "Epoch 3357, Loss: 1.6139450469054282, Final Batch Loss: 0.0056714811362326145\n",
      "Epoch 3358, Loss: 2.846890926361084, Final Batch Loss: 1.1098952293395996\n",
      "Epoch 3359, Loss: 1.7099801165022654, Final Batch Loss: 0.00016544880054425448\n",
      "Epoch 3360, Loss: 1.8460444211959839, Final Batch Loss: 0.18519151210784912\n",
      "Epoch 3361, Loss: 3.174208492040634, Final Batch Loss: 1.587178349494934\n",
      "Epoch 3362, Loss: 1.9558363854885101, Final Batch Loss: 0.2864152193069458\n",
      "Epoch 3363, Loss: 1.8632416725031362, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 3364, Loss: 1.9192628087475896, Final Batch Loss: 0.002471846528351307\n",
      "Epoch 3365, Loss: 2.1644681692123413, Final Batch Loss: 0.12606710195541382\n",
      "Epoch 3366, Loss: 1.8879339673076174, Final Batch Loss: 6.615896563744172e-05\n",
      "Epoch 3367, Loss: 1.8843975737690926, Final Batch Loss: 0.07043231278657913\n",
      "Epoch 3368, Loss: 2.604843318462372, Final Batch Loss: 0.9164944887161255\n",
      "Epoch 3369, Loss: 2.0211005806922913, Final Batch Loss: 0.4294776916503906\n",
      "Epoch 3370, Loss: 1.6533165539149195, Final Batch Loss: 0.0010948146227747202\n",
      "Epoch 3371, Loss: 1.6482798643410206, Final Batch Loss: 0.04025714471936226\n",
      "Epoch 3372, Loss: 2.4316576421260834, Final Batch Loss: 0.8192692399024963\n",
      "Epoch 3373, Loss: 2.6910971999168396, Final Batch Loss: 1.074716567993164\n",
      "Epoch 3374, Loss: 1.607315808534615, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3375, Loss: 2.3269569277763367, Final Batch Loss: 0.4327200651168823\n",
      "Epoch 3376, Loss: 3.678153872489929, Final Batch Loss: 1.546372890472412\n",
      "Epoch 3377, Loss: 1.9171420836355537, Final Batch Loss: 0.0027209424879401922\n",
      "Epoch 3378, Loss: 1.8485454721958376, Final Batch Loss: 0.00039772229501977563\n",
      "Epoch 3379, Loss: 1.6712648868015094, Final Batch Loss: 1.0490362910786644e-05\n",
      "Epoch 3380, Loss: 1.6801710280415136, Final Batch Loss: 0.0002980979916173965\n",
      "Epoch 3381, Loss: 1.940056473016739, Final Batch Loss: 0.3014884293079376\n",
      "Epoch 3382, Loss: 2.2869608402252197, Final Batch Loss: 0.6246203780174255\n",
      "Epoch 3383, Loss: 1.8908932954072952, Final Batch Loss: 0.2233840376138687\n",
      "Epoch 3384, Loss: 2.307772219181061, Final Batch Loss: 0.5529246926307678\n",
      "Epoch 3385, Loss: 1.6027289219200611, Final Batch Loss: 0.04468749836087227\n",
      "Epoch 3386, Loss: 2.9673536121845245, Final Batch Loss: 1.3891513347625732\n",
      "Epoch 3387, Loss: 1.64836192317307, Final Batch Loss: 0.02058744616806507\n",
      "Epoch 3388, Loss: 4.043929398059845, Final Batch Loss: 2.384611129760742\n",
      "Epoch 3389, Loss: 1.872000940144062, Final Batch Loss: 0.08950109034776688\n",
      "Epoch 3390, Loss: 2.350939452648163, Final Batch Loss: 0.4602659344673157\n",
      "Epoch 3391, Loss: 1.8701931089162827, Final Batch Loss: 0.10992906987667084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3392, Loss: 1.9769920408725739, Final Batch Loss: 0.16241297125816345\n",
      "Epoch 3393, Loss: 2.6470484733581543, Final Batch Loss: 0.9673916101455688\n",
      "Epoch 3394, Loss: 2.009955793619156, Final Batch Loss: 0.2966814339160919\n",
      "Epoch 3395, Loss: 1.5761688821949065, Final Batch Loss: 0.0062295072712004185\n",
      "Epoch 3396, Loss: 1.6503885090351105, Final Batch Loss: 0.03147077560424805\n",
      "Epoch 3397, Loss: 1.6444940813817084, Final Batch Loss: 0.005715812090784311\n",
      "Epoch 3398, Loss: 1.7477833479642868, Final Batch Loss: 0.0866614431142807\n",
      "Epoch 3399, Loss: 2.657263398170471, Final Batch Loss: 1.0308951139450073\n",
      "Epoch 3400, Loss: 1.6608469635248184, Final Batch Loss: 0.03830452263355255\n",
      "Epoch 3401, Loss: 1.767502948641777, Final Batch Loss: 0.13991408050060272\n",
      "Epoch 3402, Loss: 1.6389316646382213, Final Batch Loss: 0.011238249950110912\n",
      "Epoch 3403, Loss: 2.097317188978195, Final Batch Loss: 0.45166948437690735\n",
      "Epoch 3404, Loss: 3.1643951535224915, Final Batch Loss: 1.5402331352233887\n",
      "Epoch 3405, Loss: 1.6299958974123, Final Batch Loss: 0.042216017842292786\n",
      "Epoch 3406, Loss: 3.2812203764915466, Final Batch Loss: 1.6271264553070068\n",
      "Epoch 3407, Loss: 1.6112762838602066, Final Batch Loss: 0.024348393082618713\n",
      "Epoch 3408, Loss: 2.8627732694149017, Final Batch Loss: 1.2598519325256348\n",
      "Epoch 3409, Loss: 1.7256207577884197, Final Batch Loss: 0.02859259769320488\n",
      "Epoch 3410, Loss: 1.7564775943756104, Final Batch Loss: 0.08106756210327148\n",
      "Epoch 3411, Loss: 1.6349213665962452, Final Batch Loss: 0.00010334911348763853\n",
      "Epoch 3412, Loss: 4.3003034591674805, Final Batch Loss: 2.6701042652130127\n",
      "Epoch 3413, Loss: 1.610784750431776, Final Batch Loss: 0.048868339508771896\n",
      "Epoch 3414, Loss: 2.6259148716926575, Final Batch Loss: 1.0202497243881226\n",
      "Epoch 3415, Loss: 2.2467487156391144, Final Batch Loss: 0.6374238133430481\n",
      "Epoch 3416, Loss: 2.240931987762451, Final Batch Loss: 0.6041883826255798\n",
      "Epoch 3417, Loss: 1.7118758745491505, Final Batch Loss: 0.002528805285692215\n",
      "Epoch 3418, Loss: 1.70323993335478, Final Batch Loss: 0.00029666791670024395\n",
      "Epoch 3419, Loss: 4.860841989517212, Final Batch Loss: 3.231477975845337\n",
      "Epoch 3420, Loss: 3.365534543991089, Final Batch Loss: 1.6745643615722656\n",
      "Epoch 3421, Loss: 4.413409888744354, Final Batch Loss: 2.4361772537231445\n",
      "Epoch 3422, Loss: 2.0238184928894043, Final Batch Loss: 0.32440459728240967\n",
      "Epoch 3423, Loss: 1.7965761972227483, Final Batch Loss: 9.691245941212401e-05\n",
      "Epoch 3424, Loss: 2.068253628909588, Final Batch Loss: 0.03560899943113327\n",
      "Epoch 3425, Loss: 3.5166026949882507, Final Batch Loss: 1.3878593444824219\n",
      "Epoch 3426, Loss: 2.028544969856739, Final Batch Loss: 0.01716870814561844\n",
      "Epoch 3427, Loss: 4.086125433444977, Final Batch Loss: 2.1247997283935547\n",
      "Epoch 3428, Loss: 3.221316695213318, Final Batch Loss: 1.3717635869979858\n",
      "Epoch 3429, Loss: 1.810656249326712, Final Batch Loss: 1.9788545614574105e-05\n",
      "Epoch 3430, Loss: 2.1942880749702454, Final Batch Loss: 0.3538856506347656\n",
      "Epoch 3431, Loss: 3.515635907649994, Final Batch Loss: 1.7743148803710938\n",
      "Epoch 3432, Loss: 2.882961392402649, Final Batch Loss: 1.2222564220428467\n",
      "Epoch 3433, Loss: 2.917266547679901, Final Batch Loss: 1.200034499168396\n",
      "Epoch 3434, Loss: 1.8336420580744743, Final Batch Loss: 0.0810094103217125\n",
      "Epoch 3435, Loss: 3.124844193458557, Final Batch Loss: 1.4596220254898071\n",
      "Epoch 3436, Loss: 1.7816968556617212, Final Batch Loss: 2.682172998902388e-05\n",
      "Epoch 3437, Loss: 1.9279318898916245, Final Batch Loss: 0.2470957487821579\n",
      "Epoch 3438, Loss: 1.583530968055129, Final Batch Loss: 0.0038870032876729965\n",
      "Epoch 3439, Loss: 1.6959659587591887, Final Batch Loss: 0.02956421487033367\n",
      "Epoch 3440, Loss: 4.592071831226349, Final Batch Loss: 3.0110723972320557\n",
      "Epoch 3441, Loss: 3.702059745788574, Final Batch Loss: 2.016528844833374\n",
      "Epoch 3442, Loss: 2.2673676908016205, Final Batch Loss: 0.45674416422843933\n",
      "Epoch 3443, Loss: 1.8308060519048013, Final Batch Loss: 0.0005362979718483984\n",
      "Epoch 3444, Loss: 1.7893962122034281, Final Batch Loss: 0.0024704195093363523\n",
      "Epoch 3445, Loss: 2.488531708717346, Final Batch Loss: 0.7029924392700195\n",
      "Epoch 3446, Loss: 1.6754145479790168, Final Batch Loss: 0.00016878610767889768\n",
      "Epoch 3447, Loss: 1.698721222113818, Final Batch Loss: 0.0065450589172542095\n",
      "Epoch 3448, Loss: 3.122468054294586, Final Batch Loss: 1.42666494846344\n",
      "Epoch 3449, Loss: 1.7022534674033523, Final Batch Loss: 0.006245500408113003\n",
      "Epoch 3450, Loss: 1.7318338304758072, Final Batch Loss: 0.1266546994447708\n",
      "Epoch 3451, Loss: 1.669258057638217, Final Batch Loss: 2.9444261599564925e-05\n",
      "Epoch 3452, Loss: 3.1175254583358765, Final Batch Loss: 1.4222328662872314\n",
      "Epoch 3453, Loss: 1.6280517121776938, Final Batch Loss: 0.014221861027181149\n",
      "Epoch 3454, Loss: 4.010067522525787, Final Batch Loss: 2.3615195751190186\n",
      "Epoch 3455, Loss: 3.189689129590988, Final Batch Loss: 1.4423739910125732\n",
      "Epoch 3456, Loss: 3.035680592060089, Final Batch Loss: 1.3421375751495361\n",
      "Epoch 3457, Loss: 1.6568102911114693, Final Batch Loss: 0.002625472843647003\n",
      "Epoch 3458, Loss: 1.9492897689342499, Final Batch Loss: 0.24517592787742615\n",
      "Epoch 3459, Loss: 1.8850199729204178, Final Batch Loss: 0.21753425896167755\n",
      "Epoch 3460, Loss: 2.770728826522827, Final Batch Loss: 1.1361610889434814\n",
      "Epoch 3461, Loss: 1.6710006585344672, Final Batch Loss: 0.005741058848798275\n",
      "Epoch 3462, Loss: 1.5953204715624452, Final Batch Loss: 0.00380114559084177\n",
      "Epoch 3463, Loss: 1.6623017452657223, Final Batch Loss: 0.05534711107611656\n",
      "Epoch 3464, Loss: 2.1757476329803467, Final Batch Loss: 0.5688994526863098\n",
      "Epoch 3465, Loss: 1.8130163252353668, Final Batch Loss: 0.2242639660835266\n",
      "Epoch 3466, Loss: 1.6340197585523129, Final Batch Loss: 0.002836611121892929\n",
      "Epoch 3467, Loss: 1.7967106699943542, Final Batch Loss: 0.2540604770183563\n",
      "Epoch 3468, Loss: 1.7399830594658852, Final Batch Loss: 0.12366650253534317\n",
      "Epoch 3469, Loss: 1.6477011516690254, Final Batch Loss: 0.11841744929552078\n",
      "Epoch 3470, Loss: 1.6339528956450522, Final Batch Loss: 0.0054030814208090305\n",
      "Epoch 3471, Loss: 3.1630305647850037, Final Batch Loss: 1.6030534505844116\n",
      "Epoch 3472, Loss: 1.7482401877641678, Final Batch Loss: 0.1416526585817337\n",
      "Epoch 3473, Loss: 3.591449558734894, Final Batch Loss: 2.096933364868164\n",
      "Epoch 3474, Loss: 1.6929055154323578, Final Batch Loss: 0.03721216320991516\n",
      "Epoch 3475, Loss: 2.5141748189926147, Final Batch Loss: 0.9135525226593018\n",
      "Epoch 3476, Loss: 1.601106223606621, Final Batch Loss: 7.533743337262422e-05\n",
      "Epoch 3477, Loss: 1.6275630593067945, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 3478, Loss: 2.6784252524375916, Final Batch Loss: 1.0495145320892334\n",
      "Epoch 3479, Loss: 2.407107949256897, Final Batch Loss: 0.831811785697937\n",
      "Epoch 3480, Loss: 1.6840007565915585, Final Batch Loss: 0.036406245082616806\n",
      "Epoch 3481, Loss: 2.4611849784851074, Final Batch Loss: 0.783332347869873\n",
      "Epoch 3482, Loss: 1.6307536959623121, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3483, Loss: 1.6880974471569061, Final Batch Loss: 0.04452595114707947\n",
      "Epoch 3484, Loss: 1.8452465683221817, Final Batch Loss: 0.19376827776432037\n",
      "Epoch 3485, Loss: 1.591011596028693, Final Batch Loss: 0.0013499680208042264\n",
      "Epoch 3486, Loss: 1.534324944484979, Final Batch Loss: 0.0077794198878109455\n",
      "Epoch 3487, Loss: 4.506558686494827, Final Batch Loss: 2.961796760559082\n",
      "Epoch 3488, Loss: 1.9576091468334198, Final Batch Loss: 0.3380887508392334\n",
      "Epoch 3489, Loss: 3.860660672187805, Final Batch Loss: 2.21799898147583\n",
      "Epoch 3490, Loss: 2.969040334224701, Final Batch Loss: 1.3068406581878662\n",
      "Epoch 3491, Loss: 1.9757784828543663, Final Batch Loss: 0.12025042623281479\n",
      "Epoch 3492, Loss: 2.380249470472336, Final Batch Loss: 0.45119622349739075\n",
      "Epoch 3493, Loss: 1.7472628951072124, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 3494, Loss: 2.1692957282066345, Final Batch Loss: 0.2988993525505066\n",
      "Epoch 3495, Loss: 1.8919624164700508, Final Batch Loss: 0.1123620942234993\n",
      "Epoch 3496, Loss: 1.7803457048721611, Final Batch Loss: 0.006039109546691179\n",
      "Epoch 3497, Loss: 2.1507008373737335, Final Batch Loss: 0.38081666827201843\n",
      "Epoch 3498, Loss: 2.2894168496131897, Final Batch Loss: 0.617660403251648\n",
      "Epoch 3499, Loss: 1.6854401854798198, Final Batch Loss: 0.004998686723411083\n",
      "Epoch 3500, Loss: 1.8247082811722066, Final Batch Loss: 5.9602869441732764e-05\n",
      "Epoch 3501, Loss: 3.228679060935974, Final Batch Loss: 1.2081049680709839\n",
      "Epoch 3502, Loss: 2.1501060128211975, Final Batch Loss: 0.33345407247543335\n",
      "Epoch 3503, Loss: 2.2368801534175873, Final Batch Loss: 0.46095356345176697\n",
      "Epoch 3504, Loss: 1.6552264988317802, Final Batch Loss: 4.529942543740617e-06\n",
      "Epoch 3505, Loss: 1.7529451623558998, Final Batch Loss: 0.013642407953739166\n",
      "Epoch 3506, Loss: 3.225854218006134, Final Batch Loss: 1.4477953910827637\n",
      "Epoch 3507, Loss: 1.679287664592266, Final Batch Loss: 0.08719857782125473\n",
      "Epoch 3508, Loss: 2.3472048938274384, Final Batch Loss: 0.6788668632507324\n",
      "Epoch 3509, Loss: 1.8948579728603363, Final Batch Loss: 0.3025224208831787\n",
      "Epoch 3510, Loss: 1.679466187953949, Final Batch Loss: 0.0024647116661071777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3511, Loss: 1.61524598300457, Final Batch Loss: 0.06620775163173676\n",
      "Epoch 3512, Loss: 2.6289965510368347, Final Batch Loss: 1.0202126502990723\n",
      "Epoch 3513, Loss: 3.49214306473732, Final Batch Loss: 1.9216275215148926\n",
      "Epoch 3514, Loss: 2.3241810500621796, Final Batch Loss: 0.7296810150146484\n",
      "Epoch 3515, Loss: 1.5652396861260058, Final Batch Loss: 0.00015209948469419032\n",
      "Epoch 3516, Loss: 2.0262024998664856, Final Batch Loss: 0.45117419958114624\n",
      "Epoch 3517, Loss: 1.6372594023123384, Final Batch Loss: 0.012037255801260471\n",
      "Epoch 3518, Loss: 1.6093386518768966, Final Batch Loss: 0.0009957361035048962\n",
      "Epoch 3519, Loss: 1.5918661458417773, Final Batch Loss: 0.015025298111140728\n",
      "Epoch 3520, Loss: 2.804914712905884, Final Batch Loss: 1.196616291999817\n",
      "Epoch 3521, Loss: 3.0253745913505554, Final Batch Loss: 1.448896050453186\n",
      "Epoch 3522, Loss: 3.163754940032959, Final Batch Loss: 1.5223734378814697\n",
      "Epoch 3523, Loss: 1.8714324533939362, Final Batch Loss: 0.2056964933872223\n",
      "Epoch 3524, Loss: 1.7171141714788973, Final Batch Loss: 0.0010440857149660587\n",
      "Epoch 3525, Loss: 3.3919175267219543, Final Batch Loss: 1.6828482151031494\n",
      "Epoch 3526, Loss: 1.655499568209052, Final Batch Loss: 0.014766445383429527\n",
      "Epoch 3527, Loss: 1.6879680920392275, Final Batch Loss: 0.012792782858014107\n",
      "Epoch 3528, Loss: 1.629950262606144, Final Batch Loss: 0.02783975750207901\n",
      "Epoch 3529, Loss: 2.677434742450714, Final Batch Loss: 1.126906156539917\n",
      "Epoch 3530, Loss: 2.538168251514435, Final Batch Loss: 0.91130530834198\n",
      "Epoch 3531, Loss: 2.5344288051128387, Final Batch Loss: 0.9834722280502319\n",
      "Epoch 3532, Loss: 1.6789055541157722, Final Batch Loss: 0.0777183249592781\n",
      "Epoch 3533, Loss: 1.6743386982379889, Final Batch Loss: 1.728519782773219e-05\n",
      "Epoch 3534, Loss: 1.654137164239728, Final Batch Loss: 1.5139465176616795e-05\n",
      "Epoch 3535, Loss: 1.687399625731814, Final Batch Loss: 9.65590606938349e-06\n",
      "Epoch 3536, Loss: 1.8613775074481964, Final Batch Loss: 0.20632311701774597\n",
      "Epoch 3537, Loss: 1.7093327790498734, Final Batch Loss: 0.09119607508182526\n",
      "Epoch 3538, Loss: 3.0110979676246643, Final Batch Loss: 1.437804937362671\n",
      "Epoch 3539, Loss: 1.629897115039057, Final Batch Loss: 7.176141662057489e-05\n",
      "Epoch 3540, Loss: 2.243251234292984, Final Batch Loss: 0.49661126732826233\n",
      "Epoch 3541, Loss: 2.8404455184936523, Final Batch Loss: 1.1389771699905396\n",
      "Epoch 3542, Loss: 2.828069508075714, Final Batch Loss: 1.1593729257583618\n",
      "Epoch 3543, Loss: 1.988374799489975, Final Batch Loss: 0.2951122224330902\n",
      "Epoch 3544, Loss: 1.673303515650332, Final Batch Loss: 0.012140781618654728\n",
      "Epoch 3545, Loss: 1.7076055631041527, Final Batch Loss: 0.04183539003133774\n",
      "Epoch 3546, Loss: 2.3321006298065186, Final Batch Loss: 0.7584995031356812\n",
      "Epoch 3547, Loss: 2.047103464603424, Final Batch Loss: 0.5312966704368591\n",
      "Epoch 3548, Loss: 3.385879397392273, Final Batch Loss: 1.7528373003005981\n",
      "Epoch 3549, Loss: 2.9874632358551025, Final Batch Loss: 1.4021799564361572\n",
      "Epoch 3550, Loss: 2.2304293513298035, Final Batch Loss: 0.6482675671577454\n",
      "Epoch 3551, Loss: 1.5922560989574777, Final Batch Loss: 7.510157047363464e-06\n",
      "Epoch 3552, Loss: 1.6052175164113578, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 3553, Loss: 2.0785831212997437, Final Batch Loss: 0.4987792372703552\n",
      "Epoch 3554, Loss: 3.1593337655067444, Final Batch Loss: 1.5009205341339111\n",
      "Epoch 3555, Loss: 1.6143047474324703, Final Batch Loss: 0.02291601523756981\n",
      "Epoch 3556, Loss: 2.969282865524292, Final Batch Loss: 1.3614275455474854\n",
      "Epoch 3557, Loss: 1.5124076791107655, Final Batch Loss: 0.018337715417146683\n",
      "Epoch 3558, Loss: 1.9480215311050415, Final Batch Loss: 0.38070082664489746\n",
      "Epoch 3559, Loss: 2.03843292593956, Final Batch Loss: 0.46770069003105164\n",
      "Epoch 3560, Loss: 3.0062995851039886, Final Batch Loss: 1.448614478111267\n",
      "Epoch 3561, Loss: 2.23515522480011, Final Batch Loss: 0.6024873852729797\n",
      "Epoch 3562, Loss: 3.5408161878585815, Final Batch Loss: 1.8442531824111938\n",
      "Epoch 3563, Loss: 1.928007185459137, Final Batch Loss: 0.29733237624168396\n",
      "Epoch 3564, Loss: 2.667829304933548, Final Batch Loss: 1.1023507118225098\n",
      "Epoch 3565, Loss: 1.5367852691560984, Final Batch Loss: 0.006992274895310402\n",
      "Epoch 3566, Loss: 1.5918618431569485, Final Batch Loss: 4.255681051290594e-05\n",
      "Epoch 3567, Loss: 1.7775182723999023, Final Batch Loss: 0.2568402588367462\n",
      "Epoch 3568, Loss: 2.7526935040950775, Final Batch Loss: 1.1644067764282227\n",
      "Epoch 3569, Loss: 3.4179155230522156, Final Batch Loss: 1.7712589502334595\n",
      "Epoch 3570, Loss: 3.0211355090141296, Final Batch Loss: 1.485917329788208\n",
      "Epoch 3571, Loss: 1.59393170471958, Final Batch Loss: 8.940656698541716e-06\n",
      "Epoch 3572, Loss: 1.5996320843601097, Final Batch Loss: 4.410734163684538e-06\n",
      "Epoch 3573, Loss: 2.3743869066238403, Final Batch Loss: 0.8618320822715759\n",
      "Epoch 3574, Loss: 3.4511104226112366, Final Batch Loss: 1.8710600137710571\n",
      "Epoch 3575, Loss: 3.672995448112488, Final Batch Loss: 2.1679623126983643\n",
      "Epoch 3576, Loss: 4.599268764257431, Final Batch Loss: 2.989044427871704\n",
      "Epoch 3577, Loss: 2.0243190228939056, Final Batch Loss: 0.3246815502643585\n",
      "Epoch 3578, Loss: 1.7682879865169525, Final Batch Loss: 0.12169793248176575\n",
      "Epoch 3579, Loss: 2.7325401306152344, Final Batch Loss: 1.1008262634277344\n",
      "Epoch 3580, Loss: 1.7289640922099352, Final Batch Loss: 0.02385661192238331\n",
      "Epoch 3581, Loss: 3.4338681399822235, Final Batch Loss: 1.8946681022644043\n",
      "Epoch 3582, Loss: 1.9432028532028198, Final Batch Loss: 0.3484523296356201\n",
      "Epoch 3583, Loss: 1.5762558877436277, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 3584, Loss: 1.5987652975600213, Final Batch Loss: 0.00017927470616996288\n",
      "Epoch 3585, Loss: 2.875397741794586, Final Batch Loss: 1.3181257247924805\n",
      "Epoch 3586, Loss: 1.6138861207291484, Final Batch Loss: 0.015551957301795483\n",
      "Epoch 3587, Loss: 1.6426384560763836, Final Batch Loss: 0.023037176579236984\n",
      "Epoch 3588, Loss: 1.9557901620864868, Final Batch Loss: 0.37003085017204285\n",
      "Epoch 3589, Loss: 3.8039430379867554, Final Batch Loss: 2.22735595703125\n",
      "Epoch 3590, Loss: 1.7006278722546995, Final Batch Loss: 0.0020375936292111874\n",
      "Epoch 3591, Loss: 1.8247684985399246, Final Batch Loss: 0.08754463493824005\n",
      "Epoch 3592, Loss: 1.9823697917163372, Final Batch Loss: 0.03634233400225639\n",
      "Epoch 3593, Loss: 1.7817914612824097, Final Batch Loss: 0.0011337526375427842\n",
      "Epoch 3594, Loss: 1.771442557044793, Final Batch Loss: 0.0006540066679008305\n",
      "Epoch 3595, Loss: 2.576689302921295, Final Batch Loss: 0.8513648509979248\n",
      "Epoch 3596, Loss: 1.648240415728651, Final Batch Loss: 0.0012457951670512557\n",
      "Epoch 3597, Loss: 1.7712420746684074, Final Batch Loss: 0.09193413704633713\n",
      "Epoch 3598, Loss: 1.6132817259058356, Final Batch Loss: 0.009009896777570248\n",
      "Epoch 3599, Loss: 1.5165394822106464, Final Batch Loss: 6.401333666872233e-05\n",
      "Epoch 3600, Loss: 1.9373440146446228, Final Batch Loss: 0.42381909489631653\n",
      "Epoch 3601, Loss: 2.224426954984665, Final Batch Loss: 0.6701295375823975\n",
      "Epoch 3602, Loss: 1.817908138036728, Final Batch Loss: 0.23305341601371765\n",
      "Epoch 3603, Loss: 1.671034038066864, Final Batch Loss: 0.08873897790908813\n",
      "Epoch 3604, Loss: 1.6825962513685226, Final Batch Loss: 0.1470865160226822\n",
      "Epoch 3605, Loss: 2.0063088834285736, Final Batch Loss: 0.39786508679389954\n",
      "Epoch 3606, Loss: 1.4937334135174751, Final Batch Loss: 0.008566655218601227\n",
      "Epoch 3607, Loss: 1.8253315091133118, Final Batch Loss: 0.3069997727870941\n",
      "Epoch 3608, Loss: 1.6633442416787148, Final Batch Loss: 0.09772474318742752\n",
      "Epoch 3609, Loss: 1.590565737336874, Final Batch Loss: 0.03626691922545433\n",
      "Epoch 3610, Loss: 1.929946482181549, Final Batch Loss: 0.3526057004928589\n",
      "Epoch 3611, Loss: 3.374646842479706, Final Batch Loss: 1.8188672065734863\n",
      "Epoch 3612, Loss: 2.614766627550125, Final Batch Loss: 1.0593419075012207\n",
      "Epoch 3613, Loss: 1.5933177657425404, Final Batch Loss: 0.059010375291109085\n",
      "Epoch 3614, Loss: 2.596924841403961, Final Batch Loss: 1.0535856485366821\n",
      "Epoch 3615, Loss: 2.4307738840579987, Final Batch Loss: 0.875263512134552\n",
      "Epoch 3616, Loss: 1.61494598723948, Final Batch Loss: 0.007557610049843788\n",
      "Epoch 3617, Loss: 3.2303479313850403, Final Batch Loss: 1.6104846000671387\n",
      "Epoch 3618, Loss: 3.2832019329071045, Final Batch Loss: 1.5267705917358398\n",
      "Epoch 3619, Loss: 1.883363749831915, Final Batch Loss: 0.05484619364142418\n",
      "Epoch 3620, Loss: 2.094764143228531, Final Batch Loss: 0.2842070758342743\n",
      "Epoch 3621, Loss: 1.8322612521005794, Final Batch Loss: 0.00015639036428183317\n",
      "Epoch 3622, Loss: 2.8240044116973877, Final Batch Loss: 0.9264063239097595\n",
      "Epoch 3623, Loss: 1.8289703580376226, Final Batch Loss: 0.00038532938924618065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3624, Loss: 1.7564925821498036, Final Batch Loss: 0.002979603596031666\n",
      "Epoch 3625, Loss: 2.3025989532470703, Final Batch Loss: 0.5181182026863098\n",
      "Epoch 3626, Loss: 2.207437038421631, Final Batch Loss: 0.5153433084487915\n",
      "Epoch 3627, Loss: 1.5756038109539077, Final Batch Loss: 0.0008120815036818385\n",
      "Epoch 3628, Loss: 1.6736435107304715, Final Batch Loss: 0.000717025191988796\n",
      "Epoch 3629, Loss: 3.1080867052078247, Final Batch Loss: 1.4996473789215088\n",
      "Epoch 3630, Loss: 1.6212785631068982, Final Batch Loss: 0.0008699684985913336\n",
      "Epoch 3631, Loss: 2.027092605829239, Final Batch Loss: 0.4473462700843811\n",
      "Epoch 3632, Loss: 1.5727636797601008, Final Batch Loss: 5.745722592109814e-05\n",
      "Epoch 3633, Loss: 1.6041524782776833, Final Batch Loss: 0.05427525192499161\n",
      "Epoch 3634, Loss: 1.5494492696598172, Final Batch Loss: 0.0037469910457730293\n",
      "Epoch 3635, Loss: 2.9069629907608032, Final Batch Loss: 1.366384744644165\n",
      "Epoch 3636, Loss: 1.6415221095085144, Final Batch Loss: 0.07498809695243835\n",
      "Epoch 3637, Loss: 2.6112943291664124, Final Batch Loss: 0.9003711938858032\n",
      "Epoch 3638, Loss: 2.0558777451515198, Final Batch Loss: 0.5062877535820007\n",
      "Epoch 3639, Loss: 3.3714491426944733, Final Batch Loss: 1.724396824836731\n",
      "Epoch 3640, Loss: 1.5888520478074497, Final Batch Loss: 1.5020257706055418e-05\n",
      "Epoch 3641, Loss: 3.186974048614502, Final Batch Loss: 1.579986572265625\n",
      "Epoch 3642, Loss: 3.5828760862350464, Final Batch Loss: 1.9885385036468506\n",
      "Epoch 3643, Loss: 1.6097791194914066, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 3644, Loss: 2.5175313353538513, Final Batch Loss: 0.9693748950958252\n",
      "Epoch 3645, Loss: 2.9605036973953247, Final Batch Loss: 1.30023992061615\n",
      "Epoch 3646, Loss: 1.6840002164244652, Final Batch Loss: 0.06649043411016464\n",
      "Epoch 3647, Loss: 1.6733852438628674, Final Batch Loss: 0.057085733860731125\n",
      "Epoch 3648, Loss: 1.8550292551517487, Final Batch Loss: 0.3131050169467926\n",
      "Epoch 3649, Loss: 1.5868228077863478, Final Batch Loss: 2.264974000354414e-06\n",
      "Epoch 3650, Loss: 1.7177176028490067, Final Batch Loss: 0.18684567511081696\n",
      "Epoch 3651, Loss: 2.965686619281769, Final Batch Loss: 1.359037160873413\n",
      "Epoch 3652, Loss: 1.543742494424805, Final Batch Loss: 0.0008950994815677404\n",
      "Epoch 3653, Loss: 1.6680283397436142, Final Batch Loss: 0.15970651805400848\n",
      "Epoch 3654, Loss: 1.6519133895635605, Final Batch Loss: 0.09020696580410004\n",
      "Epoch 3655, Loss: 1.6336765725864097, Final Batch Loss: 0.001434369827620685\n",
      "Epoch 3656, Loss: 2.960165560245514, Final Batch Loss: 1.44390869140625\n",
      "Epoch 3657, Loss: 3.0816966891288757, Final Batch Loss: 1.5168594121932983\n",
      "Epoch 3658, Loss: 2.4669689536094666, Final Batch Loss: 0.8375202417373657\n",
      "Epoch 3659, Loss: 1.7469565570354462, Final Batch Loss: 0.06696882843971252\n",
      "Epoch 3660, Loss: 2.074005663394928, Final Batch Loss: 0.4466347098350525\n",
      "Epoch 3661, Loss: 1.9430602192878723, Final Batch Loss: 0.34823715686798096\n",
      "Epoch 3662, Loss: 1.9810420870780945, Final Batch Loss: 0.361877977848053\n",
      "Epoch 3663, Loss: 1.6296461038291454, Final Batch Loss: 0.042111676186323166\n",
      "Epoch 3664, Loss: 1.659246721304953, Final Batch Loss: 0.015009679831564426\n",
      "Epoch 3665, Loss: 3.164844572544098, Final Batch Loss: 1.5502439737319946\n",
      "Epoch 3666, Loss: 2.71108141541481, Final Batch Loss: 1.1782602071762085\n",
      "Epoch 3667, Loss: 2.2218785285949707, Final Batch Loss: 0.6666421890258789\n",
      "Epoch 3668, Loss: 1.6129199203569442, Final Batch Loss: 0.0012010273057967424\n",
      "Epoch 3669, Loss: 1.8904094696044922, Final Batch Loss: 0.3390016257762909\n",
      "Epoch 3670, Loss: 2.289035677909851, Final Batch Loss: 0.7253737449645996\n",
      "Epoch 3671, Loss: 1.7596638202667236, Final Batch Loss: 0.28240111470222473\n",
      "Epoch 3672, Loss: 1.6697183847427368, Final Batch Loss: 0.14100050926208496\n",
      "Epoch 3673, Loss: 1.556558916272479, Final Batch Loss: 0.00020275443966966122\n",
      "Epoch 3674, Loss: 1.6454496008518618, Final Batch Loss: 0.00012420836719684303\n",
      "Epoch 3675, Loss: 2.604264497756958, Final Batch Loss: 1.0745660066604614\n",
      "Epoch 3676, Loss: 1.736057534813881, Final Batch Loss: 0.17291449010372162\n",
      "Epoch 3677, Loss: 3.5343975126743317, Final Batch Loss: 1.9910039901733398\n",
      "Epoch 3678, Loss: 3.168275237083435, Final Batch Loss: 1.6893740892410278\n",
      "Epoch 3679, Loss: 1.964365839958191, Final Batch Loss: 0.344887375831604\n",
      "Epoch 3680, Loss: 1.6347404904663563, Final Batch Loss: 0.05753679946064949\n",
      "Epoch 3681, Loss: 2.3689626455307007, Final Batch Loss: 0.7425116300582886\n",
      "Epoch 3682, Loss: 1.6821089462027885, Final Batch Loss: 0.000634111522231251\n",
      "Epoch 3683, Loss: 3.2613744139671326, Final Batch Loss: 1.5722483396530151\n",
      "Epoch 3684, Loss: 2.0014304518699646, Final Batch Loss: 0.4046162962913513\n",
      "Epoch 3685, Loss: 1.586669735610485, Final Batch Loss: 0.016680650413036346\n",
      "Epoch 3686, Loss: 1.6098698489367962, Final Batch Loss: 0.03208143636584282\n",
      "Epoch 3687, Loss: 1.6953023821115494, Final Batch Loss: 0.09938944876194\n",
      "Epoch 3688, Loss: 1.641355987638235, Final Batch Loss: 0.0461648665368557\n",
      "Epoch 3689, Loss: 2.3753045201301575, Final Batch Loss: 0.7874293923377991\n",
      "Epoch 3690, Loss: 1.5583089589781594, Final Batch Loss: 7.629365427419543e-06\n",
      "Epoch 3691, Loss: 1.6682014986872673, Final Batch Loss: 0.1223137304186821\n",
      "Epoch 3692, Loss: 1.5534926048312627, Final Batch Loss: 4.136476854910143e-05\n",
      "Epoch 3693, Loss: 1.71567253023386, Final Batch Loss: 0.10119221359491348\n",
      "Epoch 3694, Loss: 1.757610872387886, Final Batch Loss: 0.13355647027492523\n",
      "Epoch 3695, Loss: 1.7456746846437454, Final Batch Loss: 0.2097550481557846\n",
      "Epoch 3696, Loss: 2.4147179424762726, Final Batch Loss: 0.9028295278549194\n",
      "Epoch 3697, Loss: 1.7337331622838974, Final Batch Loss: 0.1691533476114273\n",
      "Epoch 3698, Loss: 3.4888743460178375, Final Batch Loss: 1.9530607461929321\n",
      "Epoch 3699, Loss: 2.1093478202819824, Final Batch Loss: 0.5666072964668274\n",
      "Epoch 3700, Loss: 3.1114994883537292, Final Batch Loss: 1.581930160522461\n",
      "Epoch 3701, Loss: 1.5469117327593267, Final Batch Loss: 0.002091722097247839\n",
      "Epoch 3702, Loss: 2.1899285316467285, Final Batch Loss: 0.6374362707138062\n",
      "Epoch 3703, Loss: 2.1231069564819336, Final Batch Loss: 0.5468866229057312\n",
      "Epoch 3704, Loss: 1.5524189802818, Final Batch Loss: 0.00571960536763072\n",
      "Epoch 3705, Loss: 2.5505043268203735, Final Batch Loss: 1.0269017219543457\n",
      "Epoch 3706, Loss: 1.5089100247714669, Final Batch Loss: 0.0004991239402443171\n",
      "Epoch 3707, Loss: 3.356112003326416, Final Batch Loss: 1.7735161781311035\n",
      "Epoch 3708, Loss: 2.487796902656555, Final Batch Loss: 0.9502292275428772\n",
      "Epoch 3709, Loss: 2.3607142865657806, Final Batch Loss: 0.8279567956924438\n",
      "Epoch 3710, Loss: 1.673417367041111, Final Batch Loss: 0.06482396274805069\n",
      "Epoch 3711, Loss: 2.7263593077659607, Final Batch Loss: 1.1529589891433716\n",
      "Epoch 3712, Loss: 1.5327819838712458, Final Batch Loss: 0.0003580405900720507\n",
      "Epoch 3713, Loss: 1.823638916015625, Final Batch Loss: 0.26312869787216187\n",
      "Epoch 3714, Loss: 1.555401623234502, Final Batch Loss: 5.364403477869928e-06\n",
      "Epoch 3715, Loss: 1.6479920595884323, Final Batch Loss: 0.0859343558549881\n",
      "Epoch 3716, Loss: 1.5204847184941173, Final Batch Loss: 0.008508029393851757\n",
      "Epoch 3717, Loss: 1.4717651861719787, Final Batch Loss: 0.0004326361231505871\n",
      "Epoch 3718, Loss: 1.9165824353694916, Final Batch Loss: 0.28631457686424255\n",
      "Epoch 3719, Loss: 1.9916505813598633, Final Batch Loss: 0.4987838566303253\n",
      "Epoch 3720, Loss: 1.6007754620804917, Final Batch Loss: 0.0003943857445847243\n",
      "Epoch 3721, Loss: 2.534216046333313, Final Batch Loss: 0.9814845323562622\n",
      "Epoch 3722, Loss: 1.6604169756174088, Final Batch Loss: 0.14582957327365875\n",
      "Epoch 3723, Loss: 2.043994277715683, Final Batch Loss: 0.5105952620506287\n",
      "Epoch 3724, Loss: 3.6808422207832336, Final Batch Loss: 2.137373685836792\n",
      "Epoch 3725, Loss: 3.0121268033981323, Final Batch Loss: 1.5211451053619385\n",
      "Epoch 3726, Loss: 2.1277068853378296, Final Batch Loss: 0.5590984225273132\n",
      "Epoch 3727, Loss: 1.5700487117865123, Final Batch Loss: 0.0002743821241892874\n",
      "Epoch 3728, Loss: 1.6314010471105576, Final Batch Loss: 0.0795750766992569\n",
      "Epoch 3729, Loss: 1.5558695872314274, Final Batch Loss: 0.005161531735211611\n",
      "Epoch 3730, Loss: 1.6003711014054716, Final Batch Loss: 0.007442840840667486\n",
      "Epoch 3731, Loss: 3.8273088932037354, Final Batch Loss: 2.2884345054626465\n",
      "Epoch 3732, Loss: 1.759878009557724, Final Batch Loss: 0.19099873304367065\n",
      "Epoch 3733, Loss: 1.633362103253603, Final Batch Loss: 0.03638233616948128\n",
      "Epoch 3734, Loss: 2.214225709438324, Final Batch Loss: 0.6028616428375244\n",
      "Epoch 3735, Loss: 3.2896323800086975, Final Batch Loss: 1.599130392074585\n",
      "Epoch 3736, Loss: 1.6377667049964657, Final Batch Loss: 0.00016652150952722877\n",
      "Epoch 3737, Loss: 1.95932137966156, Final Batch Loss: 0.37929725646972656\n",
      "Epoch 3738, Loss: 3.0423290133476257, Final Batch Loss: 1.5433025360107422\n",
      "Epoch 3739, Loss: 1.485912386327982, Final Batch Loss: 0.03177395835518837\n",
      "Epoch 3740, Loss: 3.400433599948883, Final Batch Loss: 1.8409925699234009\n",
      "Epoch 3741, Loss: 1.6085359177086502, Final Batch Loss: 0.002154411980882287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3742, Loss: 2.690449833869934, Final Batch Loss: 1.1289759874343872\n",
      "Epoch 3743, Loss: 1.5333713768050075, Final Batch Loss: 0.00843628030270338\n",
      "Epoch 3744, Loss: 1.611278310418129, Final Batch Loss: 0.11681066453456879\n",
      "Epoch 3745, Loss: 2.132321774959564, Final Batch Loss: 0.550300121307373\n",
      "Epoch 3746, Loss: 1.6238144040107727, Final Batch Loss: 0.08550730347633362\n",
      "Epoch 3747, Loss: 1.6374559924006462, Final Batch Loss: 0.1031499132514\n",
      "Epoch 3748, Loss: 2.1939632892608643, Final Batch Loss: 0.6320708990097046\n",
      "Epoch 3749, Loss: 2.6711813509464264, Final Batch Loss: 1.147111177444458\n",
      "Epoch 3750, Loss: 3.096198946237564, Final Batch Loss: 1.5159976482391357\n",
      "Epoch 3751, Loss: 1.5874372702091932, Final Batch Loss: 0.01802867464721203\n",
      "Epoch 3752, Loss: 2.416556656360626, Final Batch Loss: 0.8499581217765808\n",
      "Epoch 3753, Loss: 1.662364237010479, Final Batch Loss: 0.1002069041132927\n",
      "Epoch 3754, Loss: 3.2431657314300537, Final Batch Loss: 1.6119357347488403\n",
      "Epoch 3755, Loss: 1.7361709773540497, Final Batch Loss: 0.1718505620956421\n",
      "Epoch 3756, Loss: 1.5985847860574722, Final Batch Loss: 0.05333922803401947\n",
      "Epoch 3757, Loss: 2.821127861738205, Final Batch Loss: 1.336323857307434\n",
      "Epoch 3758, Loss: 1.7698479294776917, Final Batch Loss: 0.18706074357032776\n",
      "Epoch 3759, Loss: 2.891745001077652, Final Batch Loss: 1.3260356187820435\n",
      "Epoch 3760, Loss: 1.5643708449788392, Final Batch Loss: 0.0020252210088074207\n",
      "Epoch 3761, Loss: 2.3258067965507507, Final Batch Loss: 0.7935621738433838\n",
      "Epoch 3762, Loss: 1.6734080091118813, Final Batch Loss: 0.06599674373865128\n",
      "Epoch 3763, Loss: 1.5574279427473812, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 3764, Loss: 2.9044584035873413, Final Batch Loss: 1.2418473958969116\n",
      "Epoch 3765, Loss: 2.412530481815338, Final Batch Loss: 0.7794479131698608\n",
      "Epoch 3766, Loss: 1.7664936296641827, Final Batch Loss: 0.045093368738889694\n",
      "Epoch 3767, Loss: 1.7459108084440231, Final Batch Loss: 0.06910042464733124\n",
      "Epoch 3768, Loss: 1.5684737358242273, Final Batch Loss: 0.02936396934092045\n",
      "Epoch 3769, Loss: 1.9869873225688934, Final Batch Loss: 0.4474688768386841\n",
      "Epoch 3770, Loss: 3.5736368894577026, Final Batch Loss: 1.9815536737442017\n",
      "Epoch 3771, Loss: 2.7579965591430664, Final Batch Loss: 1.167887806892395\n",
      "Epoch 3772, Loss: 1.5582266587298363, Final Batch Loss: 0.002360298065468669\n",
      "Epoch 3773, Loss: 1.6102735393687908, Final Batch Loss: 3.611976353568025e-05\n",
      "Epoch 3774, Loss: 2.4555389881134033, Final Batch Loss: 0.8034240007400513\n",
      "Epoch 3775, Loss: 2.8627209961414337, Final Batch Loss: 1.2823420763015747\n",
      "Epoch 3776, Loss: 1.5800980846979655, Final Batch Loss: 0.0008192281820811331\n",
      "Epoch 3777, Loss: 1.6752629280090332, Final Batch Loss: 0.15622609853744507\n",
      "Epoch 3778, Loss: 1.5444219112337123, Final Batch Loss: 3.4570634852570947e-06\n",
      "Epoch 3779, Loss: 1.9366191029548645, Final Batch Loss: 0.39406442642211914\n",
      "Epoch 3780, Loss: 2.910902053117752, Final Batch Loss: 1.3680542707443237\n",
      "Epoch 3781, Loss: 1.523933820426464, Final Batch Loss: 0.009340398013591766\n",
      "Epoch 3782, Loss: 1.5781604424118996, Final Batch Loss: 0.07109881192445755\n",
      "Epoch 3783, Loss: 1.6299317047232762, Final Batch Loss: 0.00029392691794782877\n",
      "Epoch 3784, Loss: 1.8409575819969177, Final Batch Loss: 0.29707202315330505\n",
      "Epoch 3785, Loss: 1.7005597949028015, Final Batch Loss: 0.16530120372772217\n",
      "Epoch 3786, Loss: 2.1697232127189636, Final Batch Loss: 0.6813190579414368\n",
      "Epoch 3787, Loss: 1.7534832954406738, Final Batch Loss: 0.262281596660614\n",
      "Epoch 3788, Loss: 1.6341735776513815, Final Batch Loss: 0.0180478747934103\n",
      "Epoch 3789, Loss: 1.915107399225235, Final Batch Loss: 0.35325273871421814\n",
      "Epoch 3790, Loss: 1.590664088504127, Final Batch Loss: 2.109982233378105e-05\n",
      "Epoch 3791, Loss: 1.8852979242801666, Final Batch Loss: 0.29243937134742737\n",
      "Epoch 3792, Loss: 3.123227536678314, Final Batch Loss: 1.414022445678711\n",
      "Epoch 3793, Loss: 1.6331632882356644, Final Batch Loss: 0.07696516811847687\n",
      "Epoch 3794, Loss: 2.369813084602356, Final Batch Loss: 0.7016001343727112\n",
      "Epoch 3795, Loss: 2.0768330693244934, Final Batch Loss: 0.5151605010032654\n",
      "Epoch 3796, Loss: 1.7931090295314789, Final Batch Loss: 0.1724737584590912\n",
      "Epoch 3797, Loss: 3.4894875288009644, Final Batch Loss: 1.9512548446655273\n",
      "Epoch 3798, Loss: 2.031433403491974, Final Batch Loss: 0.5000843405723572\n",
      "Epoch 3799, Loss: 1.5032068453729153, Final Batch Loss: 0.017330404371023178\n",
      "Epoch 3800, Loss: 1.6469106971289875, Final Batch Loss: 1.3589766240329482e-05\n",
      "Epoch 3801, Loss: 1.6092005868122214, Final Batch Loss: 0.00014137222024146467\n",
      "Epoch 3802, Loss: 1.9587005078792572, Final Batch Loss: 0.33175018429756165\n",
      "Epoch 3803, Loss: 1.5366477192292223, Final Batch Loss: 0.00018869050836656243\n",
      "Epoch 3804, Loss: 1.541286617503829, Final Batch Loss: 5.245195097813848e-06\n",
      "Epoch 3805, Loss: 1.6952818483114243, Final Batch Loss: 0.22407428920269012\n",
      "Epoch 3806, Loss: 2.8460609912872314, Final Batch Loss: 1.343734860420227\n",
      "Epoch 3807, Loss: 1.4837970742373727, Final Batch Loss: 0.0003426679759286344\n",
      "Epoch 3808, Loss: 1.56210046261549, Final Batch Loss: 0.03180571645498276\n",
      "Epoch 3809, Loss: 1.50106081366539, Final Batch Loss: 0.08807244896888733\n",
      "Epoch 3810, Loss: 1.9296098351478577, Final Batch Loss: 0.3687766194343567\n",
      "Epoch 3811, Loss: 1.4360385742038488, Final Batch Loss: 0.01341613195836544\n",
      "Epoch 3812, Loss: 2.0088354647159576, Final Batch Loss: 0.39476314187049866\n",
      "Epoch 3813, Loss: 1.485389411356664, Final Batch Loss: 1.3589766240329482e-05\n",
      "Epoch 3814, Loss: 1.6906535141170025, Final Batch Loss: 0.05069417878985405\n",
      "Epoch 3815, Loss: 2.1045882999897003, Final Batch Loss: 0.5661452412605286\n",
      "Epoch 3816, Loss: 1.5973655171692371, Final Batch Loss: 0.03453706577420235\n",
      "Epoch 3817, Loss: 1.57711417414248, Final Batch Loss: 0.00838426686823368\n",
      "Epoch 3818, Loss: 1.5563204720965587, Final Batch Loss: 0.0008647278300486505\n",
      "Epoch 3819, Loss: 2.7100245654582977, Final Batch Loss: 1.1691373586654663\n",
      "Epoch 3820, Loss: 7.626192688941956, Final Batch Loss: 6.054973125457764\n",
      "Epoch 3821, Loss: 1.6195627637207508, Final Batch Loss: 0.05367155745625496\n",
      "Epoch 3822, Loss: 4.012942373752594, Final Batch Loss: 2.1607391834259033\n",
      "Epoch 3823, Loss: 1.9149784203618765, Final Batch Loss: 0.012348389253020287\n",
      "Epoch 3824, Loss: 1.9013195079751313, Final Batch Loss: 0.005550686735659838\n",
      "Epoch 3825, Loss: 1.8404420684091747, Final Batch Loss: 0.004678256344050169\n",
      "Epoch 3826, Loss: 2.686515748500824, Final Batch Loss: 0.8592046499252319\n",
      "Epoch 3827, Loss: 1.694166138768196, Final Batch Loss: 0.10055582225322723\n",
      "Epoch 3828, Loss: 3.2720828652381897, Final Batch Loss: 1.579209327697754\n",
      "Epoch 3829, Loss: 2.363483250141144, Final Batch Loss: 0.7443652153015137\n",
      "Epoch 3830, Loss: 1.5892632043687627, Final Batch Loss: 0.0006852186052128673\n",
      "Epoch 3831, Loss: 1.7697532996535301, Final Batch Loss: 0.00398852676153183\n",
      "Epoch 3832, Loss: 2.3435391783714294, Final Batch Loss: 0.6696901917457581\n",
      "Epoch 3833, Loss: 1.6715285135724116, Final Batch Loss: 9.619726915843785e-05\n",
      "Epoch 3834, Loss: 1.5834497797040967, Final Batch Loss: 4.970903682988137e-05\n",
      "Epoch 3835, Loss: 2.2822728753089905, Final Batch Loss: 0.6107488870620728\n",
      "Epoch 3836, Loss: 3.7860767245292664, Final Batch Loss: 2.1238255500793457\n",
      "Epoch 3837, Loss: 1.5853426455196313, Final Batch Loss: 1.585470999998506e-05\n",
      "Epoch 3838, Loss: 1.5094041818338155, Final Batch Loss: 3.4689302992774174e-05\n",
      "Epoch 3839, Loss: 1.5436040498316288, Final Batch Loss: 0.018312785774469376\n",
      "Epoch 3840, Loss: 1.564883922226727, Final Batch Loss: 0.009512101300060749\n",
      "Epoch 3841, Loss: 1.8242322504520416, Final Batch Loss: 0.2979815900325775\n",
      "Epoch 3842, Loss: 1.6803054958581924, Final Batch Loss: 0.1460629254579544\n",
      "Epoch 3843, Loss: 2.851459324359894, Final Batch Loss: 1.3216888904571533\n",
      "Epoch 3844, Loss: 1.642043766565621, Final Batch Loss: 0.01538985688239336\n",
      "Epoch 3845, Loss: 2.4364424347877502, Final Batch Loss: 0.9625763297080994\n",
      "Epoch 3846, Loss: 1.5683735087513924, Final Batch Loss: 0.058009035885334015\n",
      "Epoch 3847, Loss: 1.572546899318695, Final Batch Loss: 0.08936166763305664\n",
      "Epoch 3848, Loss: 2.6913196444511414, Final Batch Loss: 1.209865927696228\n",
      "Epoch 3849, Loss: 1.4618633994250558, Final Batch Loss: 0.0005964645533822477\n",
      "Epoch 3850, Loss: 2.6103246808052063, Final Batch Loss: 1.0263617038726807\n",
      "Epoch 3851, Loss: 2.7242277562618256, Final Batch Loss: 1.2473137378692627\n",
      "Epoch 3852, Loss: 3.2386973798274994, Final Batch Loss: 1.7626376152038574\n",
      "Epoch 3853, Loss: 2.4149033427238464, Final Batch Loss: 0.8117161393165588\n",
      "Epoch 3854, Loss: 1.6494053304195404, Final Batch Loss: 0.13628420233726501\n",
      "Epoch 3855, Loss: 1.4986962333350675, Final Batch Loss: 9.452849917579442e-05\n",
      "Epoch 3856, Loss: 3.992502808570862, Final Batch Loss: 2.5032191276550293\n",
      "Epoch 3857, Loss: 1.516567355953157, Final Batch Loss: 0.004044330678880215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3858, Loss: 2.067768633365631, Final Batch Loss: 0.21303999423980713\n",
      "Epoch 3859, Loss: 2.0981577411293983, Final Batch Loss: 0.0393962636590004\n",
      "Epoch 3860, Loss: 2.050154447524619, Final Batch Loss: 7.867782187531702e-06\n",
      "Epoch 3861, Loss: 3.0914740562438965, Final Batch Loss: 0.9824506044387817\n",
      "Epoch 3862, Loss: 2.9333027601242065, Final Batch Loss: 0.935332715511322\n",
      "Epoch 3863, Loss: 6.653828263282776, Final Batch Loss: 4.7265777587890625\n",
      "Epoch 3864, Loss: 1.7917033212725073, Final Batch Loss: 0.0029154198709875345\n",
      "Epoch 3865, Loss: 3.049192249774933, Final Batch Loss: 1.3342318534851074\n",
      "Epoch 3866, Loss: 1.7694376385770738, Final Batch Loss: 0.005449203308671713\n",
      "Epoch 3867, Loss: 2.008193664252758, Final Batch Loss: 0.07856040447950363\n",
      "Epoch 3868, Loss: 1.9335236996412277, Final Batch Loss: 0.03670518100261688\n",
      "Epoch 3869, Loss: 2.4660028219223022, Final Batch Loss: 0.6655380725860596\n",
      "Epoch 3870, Loss: 1.9544636607170105, Final Batch Loss: 0.23588693141937256\n",
      "Epoch 3871, Loss: 1.7850377913564444, Final Batch Loss: 0.023585831746459007\n",
      "Epoch 3872, Loss: 1.8408248270861804, Final Batch Loss: 0.004644795786589384\n",
      "Epoch 3873, Loss: 2.7261879444122314, Final Batch Loss: 0.973531186580658\n",
      "Epoch 3874, Loss: 1.6846522502601147, Final Batch Loss: 0.04274968430399895\n",
      "Epoch 3875, Loss: 1.6224777422030456, Final Batch Loss: 0.0008777103503234684\n",
      "Epoch 3876, Loss: 1.746468871831894, Final Batch Loss: 0.09313258528709412\n",
      "Epoch 3877, Loss: 2.6757373809814453, Final Batch Loss: 1.0474894046783447\n",
      "Epoch 3878, Loss: 2.3028129637241364, Final Batch Loss: 0.6706740260124207\n",
      "Epoch 3879, Loss: 1.5953666805289686, Final Batch Loss: 0.003248178865760565\n",
      "Epoch 3880, Loss: 2.5392238795757294, Final Batch Loss: 0.9088576436042786\n",
      "Epoch 3881, Loss: 2.9786660075187683, Final Batch Loss: 1.410353422164917\n",
      "Epoch 3882, Loss: 2.6272700428962708, Final Batch Loss: 1.0210518836975098\n",
      "Epoch 3883, Loss: 2.191571891307831, Final Batch Loss: 0.5994678735733032\n",
      "Epoch 3884, Loss: 1.7143369242548943, Final Batch Loss: 0.11198615282773972\n",
      "Epoch 3885, Loss: 1.7725360244512558, Final Batch Loss: 0.15981321036815643\n",
      "Epoch 3886, Loss: 1.6467412030760897, Final Batch Loss: 0.00012909532233607024\n",
      "Epoch 3887, Loss: 1.6849661941523664, Final Batch Loss: 0.00037949037505313754\n",
      "Epoch 3888, Loss: 3.0195043087005615, Final Batch Loss: 1.4519009590148926\n",
      "Epoch 3889, Loss: 2.7309041619300842, Final Batch Loss: 1.2005096673965454\n",
      "Epoch 3890, Loss: 2.6043977439403534, Final Batch Loss: 1.016755223274231\n",
      "Epoch 3891, Loss: 1.6368085909634829, Final Batch Loss: 0.022765474393963814\n",
      "Epoch 3892, Loss: 1.5189644682614016, Final Batch Loss: 4.8397800128441304e-05\n",
      "Epoch 3893, Loss: 1.475131713959854, Final Batch Loss: 0.0003631647559814155\n",
      "Epoch 3894, Loss: 1.551407962664598, Final Batch Loss: 2.729855441430118e-05\n",
      "Epoch 3895, Loss: 2.6752430200576782, Final Batch Loss: 1.1928248405456543\n",
      "Epoch 3896, Loss: 1.6801561266183853, Final Batch Loss: 0.1599024087190628\n",
      "Epoch 3897, Loss: 2.6637445986270905, Final Batch Loss: 1.0730417966842651\n",
      "Epoch 3898, Loss: 1.7804270386695862, Final Batch Loss: 0.28949862718582153\n",
      "Epoch 3899, Loss: 1.557690177578479, Final Batch Loss: 0.006506804842501879\n",
      "Epoch 3900, Loss: 1.5661053656222066, Final Batch Loss: 1.6212332411669195e-05\n",
      "Epoch 3901, Loss: 1.8857218325138092, Final Batch Loss: 0.31668221950531006\n",
      "Epoch 3902, Loss: 1.6514306738972664, Final Batch Loss: 0.0814814642071724\n",
      "Epoch 3903, Loss: 1.5780844297260046, Final Batch Loss: 0.026856830343604088\n",
      "Epoch 3904, Loss: 1.5203459728509188, Final Batch Loss: 0.0248213279992342\n",
      "Epoch 3905, Loss: 1.9944558441638947, Final Batch Loss: 0.5336194038391113\n",
      "Epoch 3906, Loss: 1.7097747325884711, Final Batch Loss: 1.5497195136049413e-06\n",
      "Epoch 3907, Loss: 3.019021451473236, Final Batch Loss: 0.9769666790962219\n",
      "Epoch 3908, Loss: 2.292082557163667, Final Batch Loss: 0.0006772369961254299\n",
      "Epoch 3909, Loss: 2.1630600632779533, Final Batch Loss: 0.00010775939153973013\n",
      "Epoch 3910, Loss: 1.9881537184119225, Final Batch Loss: 0.08261128515005112\n",
      "Epoch 3911, Loss: 2.280195951461792, Final Batch Loss: 0.32713228464126587\n",
      "Epoch 3912, Loss: 3.119316518306732, Final Batch Loss: 1.362352967262268\n",
      "Epoch 3913, Loss: 11.065422236919403, Final Batch Loss: 9.339789390563965\n",
      "Epoch 3914, Loss: 5.3555102944374084, Final Batch Loss: 3.673259735107422\n",
      "Epoch 3915, Loss: 1.9816720295348205, Final Batch Loss: 0.0006289887824095786\n",
      "Epoch 3916, Loss: 3.044278085231781, Final Batch Loss: 0.38056111335754395\n",
      "Epoch 3917, Loss: 3.1727453023195267, Final Batch Loss: 0.13417543470859528\n",
      "Epoch 3918, Loss: 2.936527344863862, Final Batch Loss: 0.0016352864913642406\n",
      "Epoch 3919, Loss: 2.7422484459821135, Final Batch Loss: 0.0028769078198820353\n",
      "Epoch 3920, Loss: 4.338677525520325, Final Batch Loss: 1.8561241626739502\n",
      "Epoch 3921, Loss: 2.3792481417585805, Final Batch Loss: 3.111314072157256e-05\n",
      "Epoch 3922, Loss: 2.638957843184471, Final Batch Loss: 0.24333970248699188\n",
      "Epoch 3923, Loss: 4.426233291625977, Final Batch Loss: 2.21505069732666\n",
      "Epoch 3924, Loss: 2.027445614337921, Final Batch Loss: 0.07733762264251709\n",
      "Epoch 3925, Loss: 1.9903887584805489, Final Batch Loss: 0.048552580177783966\n",
      "Epoch 3926, Loss: 2.181094527244568, Final Batch Loss: 0.3101372718811035\n",
      "Epoch 3927, Loss: 1.885248027741909, Final Batch Loss: 0.08100029081106186\n",
      "Epoch 3928, Loss: 2.1254360526800156, Final Batch Loss: 0.22209911048412323\n",
      "Epoch 3929, Loss: 1.8124936874955893, Final Batch Loss: 0.011730855330824852\n",
      "Epoch 3930, Loss: 3.18730765581131, Final Batch Loss: 1.387024998664856\n",
      "Epoch 3931, Loss: 2.015082061290741, Final Batch Loss: 0.3053464889526367\n",
      "Epoch 3932, Loss: 2.5017159581184387, Final Batch Loss: 0.7112307548522949\n",
      "Epoch 3933, Loss: 1.9959126114845276, Final Batch Loss: 0.2619755268096924\n",
      "Epoch 3934, Loss: 1.7450854079215787, Final Batch Loss: 0.0005088941543363035\n",
      "Epoch 3935, Loss: 1.8030455708503723, Final Batch Loss: 0.14788132905960083\n",
      "Epoch 3936, Loss: 2.8324528336524963, Final Batch Loss: 1.1760748624801636\n",
      "Epoch 3937, Loss: 1.8246267065405846, Final Batch Loss: 0.06788840144872665\n",
      "Epoch 3938, Loss: 1.7108951807022095, Final Batch Loss: 0.0\n",
      "Epoch 3939, Loss: 1.8780179768800735, Final Batch Loss: 0.1471933275461197\n",
      "Epoch 3940, Loss: 1.7757147550582815, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 3941, Loss: 1.6812866628170013, Final Batch Loss: 0.0818282961845398\n",
      "Epoch 3942, Loss: 1.7139236291259294, Final Batch Loss: 8.916457591112703e-05\n",
      "Epoch 3943, Loss: 3.0296595692634583, Final Batch Loss: 1.443000316619873\n",
      "Epoch 3944, Loss: 1.6819826958435442, Final Batch Loss: 2.062299427052494e-05\n",
      "Epoch 3945, Loss: 1.7871682927943766, Final Batch Loss: 0.005909471306949854\n",
      "Epoch 3946, Loss: 2.604537457227707, Final Batch Loss: 0.949654221534729\n",
      "Epoch 3947, Loss: 1.699398297816515, Final Batch Loss: 0.01603211835026741\n",
      "Epoch 3948, Loss: 2.5226689279079437, Final Batch Loss: 0.7920310497283936\n",
      "Epoch 3949, Loss: 1.7438494563097038, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 3950, Loss: 2.175669699907303, Final Batch Loss: 0.4716205298900604\n",
      "Epoch 3951, Loss: 2.2619041204452515, Final Batch Loss: 0.5790107250213623\n",
      "Epoch 3952, Loss: 2.6806529760360718, Final Batch Loss: 0.8628513813018799\n",
      "Epoch 3953, Loss: 4.026565968990326, Final Batch Loss: 1.9351626634597778\n",
      "Epoch 3954, Loss: 2.0408244635909796, Final Batch Loss: 0.011399021372199059\n",
      "Epoch 3955, Loss: 2.01348819443956, Final Batch Loss: 0.0027532787062227726\n",
      "Epoch 3956, Loss: 2.7713812589645386, Final Batch Loss: 1.0004199743270874\n",
      "Epoch 3957, Loss: 1.9021719694127341, Final Batch Loss: 1.4305104514278355e-06\n",
      "Epoch 3958, Loss: 2.8596468567848206, Final Batch Loss: 1.0419632196426392\n",
      "Epoch 3959, Loss: 4.222050845623016, Final Batch Loss: 2.421727418899536\n",
      "Epoch 3960, Loss: 1.8020884168799967, Final Batch Loss: 0.0023756397422403097\n",
      "Epoch 3961, Loss: 2.5533106923103333, Final Batch Loss: 0.708251416683197\n",
      "Epoch 3962, Loss: 4.4490065574646, Final Batch Loss: 2.667083978652954\n",
      "Epoch 3963, Loss: 5.348789095878601, Final Batch Loss: 3.544832229614258\n",
      "Epoch 3964, Loss: 2.0086292400956154, Final Batch Loss: 0.1191190853714943\n",
      "Epoch 3965, Loss: 2.5514637231826782, Final Batch Loss: 0.6103379726409912\n",
      "Epoch 3966, Loss: 1.9299085289239883, Final Batch Loss: 0.012316480278968811\n",
      "Epoch 3967, Loss: 1.8515028730034828, Final Batch Loss: 0.05433080345392227\n",
      "Epoch 3968, Loss: 1.8493006527423859, Final Batch Loss: 0.11313995718955994\n",
      "Epoch 3969, Loss: 2.1668286621570587, Final Batch Loss: 0.32868632674217224\n",
      "Epoch 3970, Loss: 1.7971453294157982, Final Batch Loss: 0.05715902894735336\n",
      "Epoch 3971, Loss: 1.8038499397225678, Final Batch Loss: 0.00047958316281437874\n",
      "Epoch 3972, Loss: 1.788785606622696, Final Batch Loss: 0.06375953555107117\n",
      "Epoch 3973, Loss: 2.1120491325855255, Final Batch Loss: 0.47138455510139465\n",
      "Epoch 3974, Loss: 1.6684038983657956, Final Batch Loss: 0.013892029412090778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3975, Loss: 1.7715061385242734, Final Batch Loss: 0.00032181330607272685\n",
      "Epoch 3976, Loss: 1.7910854369401932, Final Batch Loss: 0.05992056429386139\n",
      "Epoch 3977, Loss: 1.6822003852576017, Final Batch Loss: 0.01696760766208172\n",
      "Epoch 3978, Loss: 1.9489687085151672, Final Batch Loss: 0.172413170337677\n",
      "Epoch 3979, Loss: 1.6962895282340469, Final Batch Loss: 0.00014900050882715732\n",
      "Epoch 3980, Loss: 1.7269485965371132, Final Batch Loss: 0.08064425736665726\n",
      "Epoch 3981, Loss: 1.968852460384369, Final Batch Loss: 0.3377687931060791\n",
      "Epoch 3982, Loss: 1.7280764108290896, Final Batch Loss: 0.0012346034636721015\n",
      "Epoch 3983, Loss: 3.1254562735557556, Final Batch Loss: 1.470993995666504\n",
      "Epoch 3984, Loss: 1.8497376292943954, Final Batch Loss: 0.15157465636730194\n",
      "Epoch 3985, Loss: 1.8303335160017014, Final Batch Loss: 0.18403713405132294\n",
      "Epoch 3986, Loss: 1.65519514773041, Final Batch Loss: 0.0007310817018151283\n",
      "Epoch 3987, Loss: 1.6577391621140123, Final Batch Loss: 2.5748875486897305e-05\n",
      "Epoch 3988, Loss: 1.7140326276421547, Final Batch Loss: 0.09420961886644363\n",
      "Epoch 3989, Loss: 1.972058117389679, Final Batch Loss: 0.3310202360153198\n",
      "Epoch 3990, Loss: 1.8756394386291504, Final Batch Loss: 0.12897133827209473\n",
      "Epoch 3991, Loss: 1.7208352349698544, Final Batch Loss: 0.003741290420293808\n",
      "Epoch 3992, Loss: 1.6390327736735344, Final Batch Loss: 0.03127553313970566\n",
      "Epoch 3993, Loss: 2.6660817563533783, Final Batch Loss: 1.0734987258911133\n",
      "Epoch 3994, Loss: 1.591846733692364, Final Batch Loss: 3.4450891689630225e-05\n",
      "Epoch 3995, Loss: 2.5635202527046204, Final Batch Loss: 0.9705497026443481\n",
      "Epoch 3996, Loss: 1.6366794481873512, Final Batch Loss: 0.06364790350198746\n",
      "Epoch 3997, Loss: 3.9581339359283447, Final Batch Loss: 2.3344907760620117\n",
      "Epoch 3998, Loss: 3.210421144962311, Final Batch Loss: 1.6062425374984741\n",
      "Epoch 3999, Loss: 2.006638266146183, Final Batch Loss: 0.03153292089700699\n",
      "Epoch 4000, Loss: 2.1323382556438446, Final Batch Loss: 0.05309519171714783\n",
      "Epoch 4001, Loss: 2.743436098098755, Final Batch Loss: 0.6984953880310059\n",
      "Epoch 4002, Loss: 3.1140125393867493, Final Batch Loss: 1.03836190700531\n",
      "Epoch 4003, Loss: 1.9523859024047852, Final Batch Loss: 0.0\n",
      "Epoch 4004, Loss: 2.8625487685203552, Final Batch Loss: 1.055058479309082\n",
      "Epoch 4005, Loss: 2.4573894739151, Final Batch Loss: 0.6733851432800293\n",
      "Epoch 4006, Loss: 1.7103716395795345, Final Batch Loss: 0.04102220758795738\n",
      "Epoch 4007, Loss: 2.2462035417556763, Final Batch Loss: 0.5362289547920227\n",
      "Epoch 4008, Loss: 1.6884149312822956, Final Batch Loss: 5.483612312673358e-06\n",
      "Epoch 4009, Loss: 2.244450569152832, Final Batch Loss: 0.6011155247688293\n",
      "Epoch 4010, Loss: 1.6495391724674846, Final Batch Loss: 1.9073304429184645e-05\n",
      "Epoch 4011, Loss: 1.819505736231804, Final Batch Loss: 0.21148894727230072\n",
      "Epoch 4012, Loss: 1.6390106873586774, Final Batch Loss: 0.0009561972692608833\n",
      "Epoch 4013, Loss: 2.465320438146591, Final Batch Loss: 0.807213306427002\n",
      "Epoch 4014, Loss: 1.6230939514935017, Final Batch Loss: 0.019867587834596634\n",
      "Epoch 4015, Loss: 1.566696465015383, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4016, Loss: 1.6935179212596267, Final Batch Loss: 6.472854875028133e-05\n",
      "Epoch 4017, Loss: 2.7555235624313354, Final Batch Loss: 1.1230127811431885\n",
      "Epoch 4018, Loss: 1.5933296944131143, Final Batch Loss: 0.00043084874050691724\n",
      "Epoch 4019, Loss: 1.9776867032051086, Final Batch Loss: 0.3666732907295227\n",
      "Epoch 4020, Loss: 1.9274570643901825, Final Batch Loss: 0.2964129149913788\n",
      "Epoch 4021, Loss: 1.6391106992959976, Final Batch Loss: 0.05097980797290802\n",
      "Epoch 4022, Loss: 2.0719620883464813, Final Batch Loss: 0.5105787515640259\n",
      "Epoch 4023, Loss: 1.629344992339611, Final Batch Loss: 0.01997988671064377\n",
      "Epoch 4024, Loss: 2.655315786600113, Final Batch Loss: 1.1626121997833252\n",
      "Epoch 4025, Loss: 1.4955529072030913, Final Batch Loss: 0.00031573555315844715\n",
      "Epoch 4026, Loss: 1.5718609914183617, Final Batch Loss: 0.015579186379909515\n",
      "Epoch 4027, Loss: 1.5688390401483048, Final Batch Loss: 8.034383063204587e-05\n",
      "Epoch 4028, Loss: 1.585439793765545, Final Batch Loss: 0.015264712274074554\n",
      "Epoch 4029, Loss: 1.5081490487791598, Final Batch Loss: 0.005985668394714594\n",
      "Epoch 4030, Loss: 1.5716746682301164, Final Batch Loss: 0.002305113710463047\n",
      "Epoch 4031, Loss: 2.457203984260559, Final Batch Loss: 0.8898628354072571\n",
      "Epoch 4032, Loss: 2.116423010826111, Final Batch Loss: 0.6302765607833862\n",
      "Epoch 4033, Loss: 2.7550955414772034, Final Batch Loss: 1.220969557762146\n",
      "Epoch 4034, Loss: 2.729475885629654, Final Batch Loss: 1.1938989162445068\n",
      "Epoch 4035, Loss: 1.5774425400886685, Final Batch Loss: 0.0006709231529384851\n",
      "Epoch 4036, Loss: 2.8300523161888123, Final Batch Loss: 1.2297170162200928\n",
      "Epoch 4037, Loss: 1.6278362846933305, Final Batch Loss: 0.003328499849885702\n",
      "Epoch 4038, Loss: 2.0744493305683136, Final Batch Loss: 0.524440586566925\n",
      "Epoch 4039, Loss: 1.6373637906035583, Final Batch Loss: 4.1483970562694594e-05\n",
      "Epoch 4040, Loss: 2.521868407726288, Final Batch Loss: 0.9116031527519226\n",
      "Epoch 4041, Loss: 2.376426637172699, Final Batch Loss: 0.6962109208106995\n",
      "Epoch 4042, Loss: 1.9555552303791046, Final Batch Loss: 0.3544716536998749\n",
      "Epoch 4043, Loss: 2.704109787940979, Final Batch Loss: 1.056799292564392\n",
      "Epoch 4044, Loss: 1.6523378163692541, Final Batch Loss: 0.0008132726070471108\n",
      "Epoch 4045, Loss: 1.7630341798067093, Final Batch Loss: 0.1215648204088211\n",
      "Epoch 4046, Loss: 3.4911832213401794, Final Batch Loss: 1.835227608680725\n",
      "Epoch 4047, Loss: 1.62983638048172, Final Batch Loss: 0.038202524185180664\n",
      "Epoch 4048, Loss: 1.996099591255188, Final Batch Loss: 0.31482580304145813\n",
      "Epoch 4049, Loss: 1.8911001980304718, Final Batch Loss: 0.3441028296947479\n",
      "Epoch 4050, Loss: 2.0117803514003754, Final Batch Loss: 0.47111761569976807\n",
      "Epoch 4051, Loss: 2.3517390191555023, Final Batch Loss: 0.8492186069488525\n",
      "Epoch 4052, Loss: 2.288194239139557, Final Batch Loss: 0.7370170950889587\n",
      "Epoch 4053, Loss: 2.4300270676612854, Final Batch Loss: 0.8742467164993286\n",
      "Epoch 4054, Loss: 1.5853027710691094, Final Batch Loss: 0.014392376877367496\n",
      "Epoch 4055, Loss: 1.5607880376046523, Final Batch Loss: 0.0016896746819838881\n",
      "Epoch 4056, Loss: 1.5012094425037503, Final Batch Loss: 0.011467848904430866\n",
      "Epoch 4057, Loss: 3.4805135130882263, Final Batch Loss: 1.8886539936065674\n",
      "Epoch 4058, Loss: 1.5025099813890392, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4059, Loss: 2.276084542274475, Final Batch Loss: 0.822320818901062\n",
      "Epoch 4060, Loss: 2.963509351015091, Final Batch Loss: 1.4723823070526123\n",
      "Epoch 4061, Loss: 2.6971004009246826, Final Batch Loss: 1.1465246677398682\n",
      "Epoch 4062, Loss: 1.5793527364367037, Final Batch Loss: 8.583032467868179e-06\n",
      "Epoch 4063, Loss: 1.6440038083383115, Final Batch Loss: 1.7881233361549675e-05\n",
      "Epoch 4064, Loss: 1.966097742319107, Final Batch Loss: 0.31879517436027527\n",
      "Epoch 4065, Loss: 3.335285484790802, Final Batch Loss: 1.6957387924194336\n",
      "Epoch 4066, Loss: 1.706356454611523, Final Batch Loss: 0.0001497156627010554\n",
      "Epoch 4067, Loss: 1.6192644536481566, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4068, Loss: 1.6377436742186546, Final Batch Loss: 0.0632232055068016\n",
      "Epoch 4069, Loss: 3.4710819125175476, Final Batch Loss: 1.8230112791061401\n",
      "Epoch 4070, Loss: 1.522374683074304, Final Batch Loss: 0.00011407678539399058\n",
      "Epoch 4071, Loss: 1.6278400644659996, Final Batch Loss: 0.02844279259443283\n",
      "Epoch 4072, Loss: 1.6088275089568924, Final Batch Loss: 0.0004048719711136073\n",
      "Epoch 4073, Loss: 2.081573575735092, Final Batch Loss: 0.5447916388511658\n",
      "Epoch 4074, Loss: 3.331783890724182, Final Batch Loss: 1.9301860332489014\n",
      "Epoch 4075, Loss: 1.6090726850161445, Final Batch Loss: 2.1219027985353023e-05\n",
      "Epoch 4076, Loss: 1.5381912626326084, Final Batch Loss: 0.02297985926270485\n",
      "Epoch 4077, Loss: 1.5804345728829503, Final Batch Loss: 0.009060931392014027\n",
      "Epoch 4078, Loss: 3.024313122034073, Final Batch Loss: 1.563175082206726\n",
      "Epoch 4079, Loss: 1.5855836123228073, Final Batch Loss: 0.01666693389415741\n",
      "Epoch 4080, Loss: 2.1412609219551086, Final Batch Loss: 0.4917828440666199\n",
      "Epoch 4081, Loss: 1.5069371713325381, Final Batch Loss: 0.005041624419391155\n",
      "Epoch 4082, Loss: 1.6095292559584777, Final Batch Loss: 4.1483970562694594e-05\n",
      "Epoch 4083, Loss: 1.588383376524689, Final Batch Loss: 1.2159273865108844e-05\n",
      "Epoch 4084, Loss: 1.7754920348525047, Final Batch Loss: 0.04981672018766403\n",
      "Epoch 4085, Loss: 2.8161906003952026, Final Batch Loss: 1.1320871114730835\n",
      "Epoch 4086, Loss: 1.606887698173523, Final Batch Loss: 0.0\n",
      "Epoch 4087, Loss: 1.5736479200422764, Final Batch Loss: 0.05993998423218727\n",
      "Epoch 4088, Loss: 1.592431810175185, Final Batch Loss: 8.129743218887597e-05\n",
      "Epoch 4089, Loss: 1.5797551869909512, Final Batch Loss: 9.298280929215252e-06\n",
      "Epoch 4090, Loss: 1.8902300894260406, Final Batch Loss: 0.33052852749824524\n",
      "Epoch 4091, Loss: 3.161445200443268, Final Batch Loss: 1.558733344078064\n",
      "Epoch 4092, Loss: 2.7758096754550934, Final Batch Loss: 1.2487378120422363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4093, Loss: 1.512425706954673, Final Batch Loss: 0.0010200303513556719\n",
      "Epoch 4094, Loss: 2.018433928489685, Final Batch Loss: 0.42944464087486267\n",
      "Epoch 4095, Loss: 1.6119872331614715, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4096, Loss: 1.5876575857400894, Final Batch Loss: 0.07899792492389679\n",
      "Epoch 4097, Loss: 1.5529278730973601, Final Batch Loss: 0.011344215832650661\n",
      "Epoch 4098, Loss: 1.5955778919160366, Final Batch Loss: 0.010317560285329819\n",
      "Epoch 4099, Loss: 2.193546801805496, Final Batch Loss: 0.6758653521537781\n",
      "Epoch 4100, Loss: 2.684787839651108, Final Batch Loss: 1.1938449144363403\n",
      "Epoch 4101, Loss: 1.8758969008922577, Final Batch Loss: 0.30897292494773865\n",
      "Epoch 4102, Loss: 2.2218419313430786, Final Batch Loss: 0.6256610155105591\n",
      "Epoch 4103, Loss: 3.0873185098171234, Final Batch Loss: 1.615692138671875\n",
      "Epoch 4104, Loss: 1.5016113785095513, Final Batch Loss: 0.007234093267470598\n",
      "Epoch 4105, Loss: 1.6032903604209423, Final Batch Loss: 0.020461898297071457\n",
      "Epoch 4106, Loss: 3.6672329902648926, Final Batch Loss: 2.1249747276306152\n",
      "Epoch 4107, Loss: 1.5643921153678093, Final Batch Loss: 9.250213042832911e-05\n",
      "Epoch 4108, Loss: 1.5427146820147755, Final Batch Loss: 7.986703712958843e-05\n",
      "Epoch 4109, Loss: 1.6548859030008316, Final Batch Loss: 0.0880153626203537\n",
      "Epoch 4110, Loss: 1.5948968507436803, Final Batch Loss: 6.675497570540756e-05\n",
      "Epoch 4111, Loss: 3.2495522499084473, Final Batch Loss: 1.6683638095855713\n",
      "Epoch 4112, Loss: 1.606701433653825, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4113, Loss: 1.5624470680049853, Final Batch Loss: 7.83174327807501e-05\n",
      "Epoch 4114, Loss: 1.5168992727994919, Final Batch Loss: 0.02216075360774994\n",
      "Epoch 4115, Loss: 1.7918604612350464, Final Batch Loss: 0.24299225211143494\n",
      "Epoch 4116, Loss: 1.6647071242332458, Final Batch Loss: 0.1833878457546234\n",
      "Epoch 4117, Loss: 4.6079577803611755, Final Batch Loss: 3.042940139770508\n",
      "Epoch 4118, Loss: 1.6921440213918686, Final Batch Loss: 0.1869635432958603\n",
      "Epoch 4119, Loss: 1.510321719571948, Final Batch Loss: 0.006519122049212456\n",
      "Epoch 4120, Loss: 2.7381250858306885, Final Batch Loss: 1.231039047241211\n",
      "Epoch 4121, Loss: 1.557262822985649, Final Batch Loss: 0.06488575041294098\n",
      "Epoch 4122, Loss: 1.8025534898042679, Final Batch Loss: 0.15223868191242218\n",
      "Epoch 4123, Loss: 1.6871304214000702, Final Batch Loss: 0.14469876885414124\n",
      "Epoch 4124, Loss: 2.9547115862369537, Final Batch Loss: 1.380066156387329\n",
      "Epoch 4125, Loss: 1.6236379444599152, Final Batch Loss: 0.08408445119857788\n",
      "Epoch 4126, Loss: 1.626547222607769, Final Batch Loss: 0.001790588372386992\n",
      "Epoch 4127, Loss: 1.8482298851013184, Final Batch Loss: 0.2672077715396881\n",
      "Epoch 4128, Loss: 3.9240283966064453, Final Batch Loss: 2.38153076171875\n",
      "Epoch 4129, Loss: 1.6058531031012535, Final Batch Loss: 0.10805448144674301\n",
      "Epoch 4130, Loss: 2.4095773100852966, Final Batch Loss: 0.9058845639228821\n",
      "Epoch 4131, Loss: 1.7787557393312454, Final Batch Loss: 0.211759552359581\n",
      "Epoch 4132, Loss: 1.7186148748805863, Final Batch Loss: 5.2689116273541003e-05\n",
      "Epoch 4133, Loss: 5.3492904007434845, Final Batch Loss: 3.7527313232421875\n",
      "Epoch 4134, Loss: 2.1446051597595215, Final Batch Loss: 0.6077136397361755\n",
      "Epoch 4135, Loss: 2.4371084570884705, Final Batch Loss: 0.8156523704528809\n",
      "Epoch 4136, Loss: 3.1023457646369934, Final Batch Loss: 1.3377125263214111\n",
      "Epoch 4137, Loss: 1.71618294570726, Final Batch Loss: 5.3881147323409095e-05\n",
      "Epoch 4138, Loss: 4.69531923532486, Final Batch Loss: 2.998223304748535\n",
      "Epoch 4139, Loss: 1.9249858558177948, Final Batch Loss: 0.10440674424171448\n",
      "Epoch 4140, Loss: 1.8778615519404411, Final Batch Loss: 0.11232566088438034\n",
      "Epoch 4141, Loss: 1.9860983788967133, Final Batch Loss: 0.16598960757255554\n",
      "Epoch 4142, Loss: 1.8635939061641693, Final Batch Loss: 0.0970754325389862\n",
      "Epoch 4143, Loss: 1.8847721772035584, Final Batch Loss: 0.0018287854036316276\n",
      "Epoch 4144, Loss: 1.7569392109871842, Final Batch Loss: 0.00020668754586949944\n",
      "Epoch 4145, Loss: 1.7740872353315353, Final Batch Loss: 0.12461970746517181\n",
      "Epoch 4146, Loss: 3.8090028166770935, Final Batch Loss: 2.12442684173584\n",
      "Epoch 4147, Loss: 1.6187445726245642, Final Batch Loss: 0.017294785007834435\n",
      "Epoch 4148, Loss: 1.6060460582375526, Final Batch Loss: 0.021426625549793243\n",
      "Epoch 4149, Loss: 1.6590751033945708, Final Batch Loss: 0.0001245659514097497\n",
      "Epoch 4150, Loss: 3.0636360943317413, Final Batch Loss: 1.531034231185913\n",
      "Epoch 4151, Loss: 1.8014740496873856, Final Batch Loss: 0.15267173945903778\n",
      "Epoch 4152, Loss: 1.6156974993646145, Final Batch Loss: 0.056890811771154404\n",
      "Epoch 4153, Loss: 2.681051254272461, Final Batch Loss: 1.0829977989196777\n",
      "Epoch 4154, Loss: 1.6324877738952566, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4155, Loss: 2.3871189057826996, Final Batch Loss: 0.8850171566009521\n",
      "Epoch 4156, Loss: 1.664877988398075, Final Batch Loss: 0.06268445402383804\n",
      "Epoch 4157, Loss: 2.741517573595047, Final Batch Loss: 1.1746861934661865\n",
      "Epoch 4158, Loss: 1.5446645015690592, Final Batch Loss: 3.3854863431770355e-05\n",
      "Epoch 4159, Loss: 1.8097983598709106, Final Batch Loss: 0.2562706172466278\n",
      "Epoch 4160, Loss: 1.5580957870697603, Final Batch Loss: 0.0011149387573823333\n",
      "Epoch 4161, Loss: 1.831215351819992, Final Batch Loss: 0.3246784508228302\n",
      "Epoch 4162, Loss: 1.5205182730132947, Final Batch Loss: 1.4305012882687151e-05\n",
      "Epoch 4163, Loss: 1.9557629227638245, Final Batch Loss: 0.38751357793807983\n",
      "Epoch 4164, Loss: 1.7504754811525345, Final Batch Loss: 0.1367942839860916\n",
      "Epoch 4165, Loss: 1.6453896537423134, Final Batch Loss: 0.010433651506900787\n",
      "Epoch 4166, Loss: 1.7435694932937622, Final Batch Loss: 0.11364209651947021\n",
      "Epoch 4167, Loss: 3.9427060186862946, Final Batch Loss: 2.30950665473938\n",
      "Epoch 4168, Loss: 1.6141757363584475, Final Batch Loss: 3.302042750874534e-05\n",
      "Epoch 4169, Loss: 1.6167848550976487, Final Batch Loss: 0.00017617580306250602\n",
      "Epoch 4170, Loss: 1.743502365425229, Final Batch Loss: 0.02813767082989216\n",
      "Epoch 4171, Loss: 2.3031885027885437, Final Batch Loss: 0.615261971950531\n",
      "Epoch 4172, Loss: 1.854544997215271, Final Batch Loss: 0.1772364377975464\n",
      "Epoch 4173, Loss: 2.4957845211029053, Final Batch Loss: 0.8014682531356812\n",
      "Epoch 4174, Loss: 2.7924813330173492, Final Batch Loss: 1.1749624013900757\n",
      "Epoch 4175, Loss: 2.042998254299164, Final Batch Loss: 0.42006391286849976\n",
      "Epoch 4176, Loss: 1.7396267130970955, Final Batch Loss: 0.11208654195070267\n",
      "Epoch 4177, Loss: 1.8956103026866913, Final Batch Loss: 0.2703731954097748\n",
      "Epoch 4178, Loss: 1.6494008293375373, Final Batch Loss: 0.0019832244142889977\n",
      "Epoch 4179, Loss: 4.5972936153411865, Final Batch Loss: 2.9745993614196777\n",
      "Epoch 4180, Loss: 1.6216817274689674, Final Batch Loss: 0.024249382317066193\n",
      "Epoch 4181, Loss: 1.567020974936895, Final Batch Loss: 0.0010711177019402385\n",
      "Epoch 4182, Loss: 1.7540801465511322, Final Batch Loss: 0.10067537426948547\n",
      "Epoch 4183, Loss: 1.6904768645763397, Final Batch Loss: 0.08191463351249695\n",
      "Epoch 4184, Loss: 1.6033285963349044, Final Batch Loss: 0.004715512972325087\n",
      "Epoch 4185, Loss: 1.6335682459175587, Final Batch Loss: 0.025509972125291824\n",
      "Epoch 4186, Loss: 3.1293195486068726, Final Batch Loss: 1.510911226272583\n",
      "Epoch 4187, Loss: 2.0170470476150513, Final Batch Loss: 0.4955080449581146\n",
      "Epoch 4188, Loss: 3.3439217805862427, Final Batch Loss: 1.6964302062988281\n",
      "Epoch 4189, Loss: 3.5057772994041443, Final Batch Loss: 1.866663932800293\n",
      "Epoch 4190, Loss: 1.6184779939430882, Final Batch Loss: 0.00011157367407577112\n",
      "Epoch 4191, Loss: 1.7973590083420277, Final Batch Loss: 0.03363366797566414\n",
      "Epoch 4192, Loss: 2.5444889664649963, Final Batch Loss: 0.7960966229438782\n",
      "Epoch 4193, Loss: 1.9299601539969444, Final Batch Loss: 0.08650096505880356\n",
      "Epoch 4194, Loss: 4.089018285274506, Final Batch Loss: 2.308689594268799\n",
      "Epoch 4195, Loss: 2.291467249393463, Final Batch Loss: 0.5366491675376892\n",
      "Epoch 4196, Loss: 1.5798256671987474, Final Batch Loss: 0.005838838871568441\n",
      "Epoch 4197, Loss: 3.458484649658203, Final Batch Loss: 1.8464667797088623\n",
      "Epoch 4198, Loss: 1.9228460490703583, Final Batch Loss: 0.3310866057872772\n",
      "Epoch 4199, Loss: 1.5769263893453171, Final Batch Loss: 0.00020418466010596603\n",
      "Epoch 4200, Loss: 1.6361622158437967, Final Batch Loss: 0.016645127907395363\n",
      "Epoch 4201, Loss: 1.629315038677305, Final Batch Loss: 0.006504317279905081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4202, Loss: 1.6899859607219696, Final Batch Loss: 0.14504972100257874\n",
      "Epoch 4203, Loss: 3.029696822166443, Final Batch Loss: 1.4563766717910767\n",
      "Epoch 4204, Loss: 1.5940826432779431, Final Batch Loss: 0.009024073369801044\n",
      "Epoch 4205, Loss: 2.989914745092392, Final Batch Loss: 1.4496678113937378\n",
      "Epoch 4206, Loss: 2.292133241891861, Final Batch Loss: 0.7238849401473999\n",
      "Epoch 4207, Loss: 1.6102298074401915, Final Batch Loss: 0.004701512400060892\n",
      "Epoch 4208, Loss: 1.8760550618171692, Final Batch Loss: 0.2852279245853424\n",
      "Epoch 4209, Loss: 1.6437188610434532, Final Batch Loss: 0.08006640523672104\n",
      "Epoch 4210, Loss: 1.5342650731327012, Final Batch Loss: 0.0012430568458512425\n",
      "Epoch 4211, Loss: 1.6721736751496792, Final Batch Loss: 0.04932936653494835\n",
      "Epoch 4212, Loss: 3.8880125284194946, Final Batch Loss: 2.289252996444702\n",
      "Epoch 4213, Loss: 2.884111762046814, Final Batch Loss: 1.3084830045700073\n",
      "Epoch 4214, Loss: 1.793327659368515, Final Batch Loss: 0.32590314745903015\n",
      "Epoch 4215, Loss: 1.4967394550330937, Final Batch Loss: 0.00020919041708111763\n",
      "Epoch 4216, Loss: 1.5176953971385956, Final Batch Loss: 0.004031151533126831\n",
      "Epoch 4217, Loss: 2.50802019238472, Final Batch Loss: 1.0140970945358276\n",
      "Epoch 4218, Loss: 1.5170295285061002, Final Batch Loss: 0.00953394640237093\n",
      "Epoch 4219, Loss: 3.9554744958877563, Final Batch Loss: 2.498915910720825\n",
      "Epoch 4220, Loss: 1.9156768023967743, Final Batch Loss: 0.2816248834133148\n",
      "Epoch 4221, Loss: 1.675377642735839, Final Batch Loss: 0.004203176125884056\n",
      "Epoch 4222, Loss: 1.6033891210245201, Final Batch Loss: 0.00021407696476671845\n",
      "Epoch 4223, Loss: 1.6831578984856606, Final Batch Loss: 0.06469882279634476\n",
      "Epoch 4224, Loss: 3.425860583782196, Final Batch Loss: 1.7754740715026855\n",
      "Epoch 4225, Loss: 2.050993472337723, Final Batch Loss: 0.45191529393196106\n",
      "Epoch 4226, Loss: 2.8803004026412964, Final Batch Loss: 1.3434221744537354\n",
      "Epoch 4227, Loss: 3.1150699257850647, Final Batch Loss: 1.6270973682403564\n",
      "Epoch 4228, Loss: 2.051461786031723, Final Batch Loss: 0.44750621914863586\n",
      "Epoch 4229, Loss: 1.5561160147185547, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4230, Loss: 1.7273471057415009, Final Batch Loss: 0.0713174045085907\n",
      "Epoch 4231, Loss: 2.201909989118576, Final Batch Loss: 0.6628929376602173\n",
      "Epoch 4232, Loss: 2.29128497838974, Final Batch Loss: 0.6758332252502441\n",
      "Epoch 4233, Loss: 1.5391782522201467, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4234, Loss: 1.859941840171814, Final Batch Loss: 0.2521939277648926\n",
      "Epoch 4235, Loss: 2.539400339126587, Final Batch Loss: 0.9108816981315613\n",
      "Epoch 4236, Loss: 4.703895390033722, Final Batch Loss: 3.1997523307800293\n",
      "Epoch 4237, Loss: 1.4644707888364792, Final Batch Loss: 0.027251556515693665\n",
      "Epoch 4238, Loss: 1.6077285736828344, Final Batch Loss: 0.0002315968304174021\n",
      "Epoch 4239, Loss: 1.5535757071338594, Final Batch Loss: 0.003990901168435812\n",
      "Epoch 4240, Loss: 1.5540231093764305, Final Batch Loss: 0.043498121201992035\n",
      "Epoch 4241, Loss: 1.6090011969208717, Final Batch Loss: 0.04508505016565323\n",
      "Epoch 4242, Loss: 2.175377279520035, Final Batch Loss: 0.6546977758407593\n",
      "Epoch 4243, Loss: 1.8400074392557144, Final Batch Loss: 0.18264420330524445\n",
      "Epoch 4244, Loss: 2.872052550315857, Final Batch Loss: 1.3560528755187988\n",
      "Epoch 4245, Loss: 2.375053822994232, Final Batch Loss: 0.8157342672348022\n",
      "Epoch 4246, Loss: 1.5712883099913597, Final Batch Loss: 0.038113825023174286\n",
      "Epoch 4247, Loss: 2.8394826352596283, Final Batch Loss: 1.2984973192214966\n",
      "Epoch 4248, Loss: 1.6493238285183907, Final Batch Loss: 0.12128166109323502\n",
      "Epoch 4249, Loss: 1.6370534151792526, Final Batch Loss: 0.05798642337322235\n",
      "Epoch 4250, Loss: 1.5838536154478788, Final Batch Loss: 0.02213825099170208\n",
      "Epoch 4251, Loss: 2.8487406373023987, Final Batch Loss: 1.2305855751037598\n",
      "Epoch 4252, Loss: 1.661748319515027, Final Batch Loss: 0.0010068115079775453\n",
      "Epoch 4253, Loss: 3.372913211584091, Final Batch Loss: 1.7394949197769165\n",
      "Epoch 4254, Loss: 1.6595683544874191, Final Batch Loss: 0.06280772387981415\n",
      "Epoch 4255, Loss: 2.553430199623108, Final Batch Loss: 0.9391680359840393\n",
      "Epoch 4256, Loss: 2.3372215628623962, Final Batch Loss: 0.7204535007476807\n",
      "Epoch 4257, Loss: 2.841447949409485, Final Batch Loss: 1.2079952955245972\n",
      "Epoch 4258, Loss: 1.6510769724798138, Final Batch Loss: 3.099436753473128e-06\n",
      "Epoch 4259, Loss: 1.87565578520298, Final Batch Loss: 0.2127154916524887\n",
      "Epoch 4260, Loss: 3.882448375225067, Final Batch Loss: 2.264646530151367\n",
      "Epoch 4261, Loss: 1.6184767407830805, Final Batch Loss: 0.0003668589051812887\n",
      "Epoch 4262, Loss: 1.696230124682188, Final Batch Loss: 0.01440812274813652\n",
      "Epoch 4263, Loss: 1.7160433363169432, Final Batch Loss: 0.020932121202349663\n",
      "Epoch 4264, Loss: 1.6617117307032458, Final Batch Loss: 0.0007211944903247058\n",
      "Epoch 4265, Loss: 1.7230824854923412, Final Batch Loss: 0.00033742457162588835\n",
      "Epoch 4266, Loss: 1.8564123958349228, Final Batch Loss: 0.18736927211284637\n",
      "Epoch 4267, Loss: 1.615880947560072, Final Batch Loss: 0.025089215487241745\n",
      "Epoch 4268, Loss: 1.5822900350904092, Final Batch Loss: 0.0006277974462136626\n",
      "Epoch 4269, Loss: 2.10491743683815, Final Batch Loss: 0.5787599682807922\n",
      "Epoch 4270, Loss: 1.667117789387703, Final Batch Loss: 0.023905381560325623\n",
      "Epoch 4271, Loss: 2.6432405710220337, Final Batch Loss: 0.8939864039421082\n",
      "Epoch 4272, Loss: 2.8563680350780487, Final Batch Loss: 1.3336622714996338\n",
      "Epoch 4273, Loss: 2.433139681816101, Final Batch Loss: 0.9164847135543823\n",
      "Epoch 4274, Loss: 1.7868964970111847, Final Batch Loss: 0.12957671284675598\n",
      "Epoch 4275, Loss: 1.5768647982913535, Final Batch Loss: 0.00028391621890477836\n",
      "Epoch 4276, Loss: 1.5709555931971408, Final Batch Loss: 0.00014911970356479287\n",
      "Epoch 4277, Loss: 1.7782302647829056, Final Batch Loss: 0.22390048205852509\n",
      "Epoch 4278, Loss: 1.8420050144195557, Final Batch Loss: 0.2384207546710968\n",
      "Epoch 4279, Loss: 1.5368625223568415, Final Batch Loss: 3.6954811548639555e-06\n",
      "Epoch 4280, Loss: 1.6365951974876225, Final Batch Loss: 0.00497377710416913\n",
      "Epoch 4281, Loss: 1.604966415092349, Final Batch Loss: 0.0266007911413908\n",
      "Epoch 4282, Loss: 1.5399610330350697, Final Batch Loss: 0.0015481640584766865\n",
      "Epoch 4283, Loss: 2.6379849016666412, Final Batch Loss: 1.0728882551193237\n",
      "Epoch 4284, Loss: 1.6526022106409073, Final Batch Loss: 0.17932306230068207\n",
      "Epoch 4285, Loss: 1.5744247849070234, Final Batch Loss: 0.0001915509783430025\n",
      "Epoch 4286, Loss: 2.0651703476905823, Final Batch Loss: 0.4494057893753052\n",
      "Epoch 4287, Loss: 1.555825598537922, Final Batch Loss: 0.07833016663789749\n",
      "Epoch 4288, Loss: 1.6361385583877563, Final Batch Loss: 0.055417150259017944\n",
      "Epoch 4289, Loss: 2.8723706901073456, Final Batch Loss: 1.287489652633667\n",
      "Epoch 4290, Loss: 2.945618689060211, Final Batch Loss: 1.4237735271453857\n",
      "Epoch 4291, Loss: 1.6852560639381409, Final Batch Loss: 0.13776996731758118\n",
      "Epoch 4292, Loss: 2.8814148902893066, Final Batch Loss: 1.381894588470459\n",
      "Epoch 4293, Loss: 2.2724364697933197, Final Batch Loss: 0.7968088388442993\n",
      "Epoch 4294, Loss: 1.542616158243618, Final Batch Loss: 3.099393507000059e-05\n",
      "Epoch 4295, Loss: 3.9575799107551575, Final Batch Loss: 2.461775302886963\n",
      "Epoch 4296, Loss: 2.4740743339061737, Final Batch Loss: 0.8979780673980713\n",
      "Epoch 4297, Loss: 3.2300681471824646, Final Batch Loss: 1.7020869255065918\n",
      "Epoch 4298, Loss: 1.5541481140535325, Final Batch Loss: 0.0020678106229752302\n",
      "Epoch 4299, Loss: 1.9834183156490326, Final Batch Loss: 0.41251078248023987\n",
      "Epoch 4300, Loss: 1.6174625325365923, Final Batch Loss: 0.000569300667848438\n",
      "Epoch 4301, Loss: 1.8403638750314713, Final Batch Loss: 0.20753808319568634\n",
      "Epoch 4302, Loss: 1.6114935725927353, Final Batch Loss: 0.054409608244895935\n",
      "Epoch 4303, Loss: 1.5866645493078977, Final Batch Loss: 0.0010145523119717836\n",
      "Epoch 4304, Loss: 1.5205306997522712, Final Batch Loss: 0.010190009139478207\n",
      "Epoch 4305, Loss: 1.7968908995389938, Final Batch Loss: 0.24302683770656586\n",
      "Epoch 4306, Loss: 3.2752194106578827, Final Batch Loss: 1.830986499786377\n",
      "Epoch 4307, Loss: 1.6923711746931076, Final Batch Loss: 0.14079539477825165\n",
      "Epoch 4308, Loss: 1.8262527137994766, Final Batch Loss: 0.21902360022068024\n",
      "Epoch 4309, Loss: 1.8721135165542364, Final Batch Loss: 0.018513968214392662\n",
      "Epoch 4310, Loss: 2.1749615520238876, Final Batch Loss: 0.21020226180553436\n",
      "Epoch 4311, Loss: 3.921311378479004, Final Batch Loss: 2.1756179332733154\n",
      "Epoch 4312, Loss: 1.6473477738909423, Final Batch Loss: 0.0022518294863402843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4313, Loss: 1.5460061424637388, Final Batch Loss: 3.5523738915799186e-05\n",
      "Epoch 4314, Loss: 3.836273044347763, Final Batch Loss: 2.315399408340454\n",
      "Epoch 4315, Loss: 2.4698131680488586, Final Batch Loss: 0.8668384552001953\n",
      "Epoch 4316, Loss: 2.9724228978157043, Final Batch Loss: 1.33286714553833\n",
      "Epoch 4317, Loss: 1.6096872687335235, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4318, Loss: 1.7649674796266481, Final Batch Loss: 0.00020752183627337217\n",
      "Epoch 4319, Loss: 2.8876705169677734, Final Batch Loss: 1.2327600717544556\n",
      "Epoch 4320, Loss: 1.6273943663109094, Final Batch Loss: 0.003012406872585416\n",
      "Epoch 4321, Loss: 2.2037006318569183, Final Batch Loss: 0.5822167992591858\n",
      "Epoch 4322, Loss: 1.663515716791153, Final Batch Loss: 0.09077790379524231\n",
      "Epoch 4323, Loss: 1.6954119056463242, Final Batch Loss: 0.12577901780605316\n",
      "Epoch 4324, Loss: 2.641246199607849, Final Batch Loss: 1.1383161544799805\n",
      "Epoch 4325, Loss: 3.3978940546512604, Final Batch Loss: 1.863377571105957\n",
      "Epoch 4326, Loss: 2.6509175300598145, Final Batch Loss: 1.1846152544021606\n",
      "Epoch 4327, Loss: 3.078087568283081, Final Batch Loss: 1.5437301397323608\n",
      "Epoch 4328, Loss: 1.7912654429674149, Final Batch Loss: 0.16243942081928253\n",
      "Epoch 4329, Loss: 2.7805928587913513, Final Batch Loss: 1.188934564590454\n",
      "Epoch 4330, Loss: 3.2043930292129517, Final Batch Loss: 1.665379285812378\n",
      "Epoch 4331, Loss: 2.213294744491577, Final Batch Loss: 0.7090553045272827\n",
      "Epoch 4332, Loss: 1.5910388678312302, Final Batch Loss: 0.09765003621578217\n",
      "Epoch 4333, Loss: 1.5436045108363032, Final Batch Loss: 0.0009581027552485466\n",
      "Epoch 4334, Loss: 3.2746609449386597, Final Batch Loss: 1.7800819873809814\n",
      "Epoch 4335, Loss: 2.3825815618038177, Final Batch Loss: 0.7704280614852905\n",
      "Epoch 4336, Loss: 1.614935889840126, Final Batch Loss: 0.11007772386074066\n",
      "Epoch 4337, Loss: 2.001449316740036, Final Batch Loss: 0.48977547883987427\n",
      "Epoch 4338, Loss: 3.3445869088172913, Final Batch Loss: 1.8435786962509155\n",
      "Epoch 4339, Loss: 2.5093607306480408, Final Batch Loss: 0.8518309593200684\n",
      "Epoch 4340, Loss: 2.015844225883484, Final Batch Loss: 0.4940755069255829\n",
      "Epoch 4341, Loss: 1.5833318415097892, Final Batch Loss: 0.005840379279106855\n",
      "Epoch 4342, Loss: 1.544609094504267, Final Batch Loss: 0.002130026463419199\n",
      "Epoch 4343, Loss: 2.631753981113434, Final Batch Loss: 1.0822830200195312\n",
      "Epoch 4344, Loss: 2.2744393944740295, Final Batch Loss: 0.7283324003219604\n",
      "Epoch 4345, Loss: 2.454207479953766, Final Batch Loss: 0.9978085160255432\n",
      "Epoch 4346, Loss: 1.541086191427894, Final Batch Loss: 0.0006542449118569493\n",
      "Epoch 4347, Loss: 1.6950793638825417, Final Batch Loss: 0.09037796407938004\n",
      "Epoch 4348, Loss: 1.75029057264328, Final Batch Loss: 0.14846518635749817\n",
      "Epoch 4349, Loss: 2.145454913377762, Final Batch Loss: 0.5456987023353577\n",
      "Epoch 4350, Loss: 1.7789258062839508, Final Batch Loss: 0.25222551822662354\n",
      "Epoch 4351, Loss: 1.6138980835676193, Final Batch Loss: 0.09566538035869598\n",
      "Epoch 4352, Loss: 2.558822900056839, Final Batch Loss: 1.0840073823928833\n",
      "Epoch 4353, Loss: 1.7877914905548096, Final Batch Loss: 0.26654139161109924\n",
      "Epoch 4354, Loss: 2.0862148702144623, Final Batch Loss: 0.5832315683364868\n",
      "Epoch 4355, Loss: 1.5164572432840941, Final Batch Loss: 0.00018094333063345402\n",
      "Epoch 4356, Loss: 1.5915788561105728, Final Batch Loss: 0.06978093087673187\n",
      "Epoch 4357, Loss: 1.547989359125495, Final Batch Loss: 0.022779574617743492\n",
      "Epoch 4358, Loss: 1.6913045197725296, Final Batch Loss: 0.20505841076374054\n",
      "Epoch 4359, Loss: 3.079677492380142, Final Batch Loss: 1.582167148590088\n",
      "Epoch 4360, Loss: 2.841544508934021, Final Batch Loss: 1.3096784353256226\n",
      "Epoch 4361, Loss: 1.7578597366809845, Final Batch Loss: 0.2515156865119934\n",
      "Epoch 4362, Loss: 2.011082887649536, Final Batch Loss: 0.40429234504699707\n",
      "Epoch 4363, Loss: 1.7248356193304062, Final Batch Loss: 0.05112718045711517\n",
      "Epoch 4364, Loss: 1.557347863911673, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4365, Loss: 1.5887932884506881, Final Batch Loss: 0.0015172171406447887\n",
      "Epoch 4366, Loss: 1.6373182237148285, Final Batch Loss: 0.10655739903450012\n",
      "Epoch 4367, Loss: 1.67922592908144, Final Batch Loss: 0.09568477421998978\n",
      "Epoch 4368, Loss: 1.6790023744106293, Final Batch Loss: 0.22161468863487244\n",
      "Epoch 4369, Loss: 1.5776366516947746, Final Batch Loss: 0.03352969139814377\n",
      "Epoch 4370, Loss: 1.454516665020492, Final Batch Loss: 0.0005161621957086027\n",
      "Epoch 4371, Loss: 1.5416723784292117, Final Batch Loss: 0.0006909366929903626\n",
      "Epoch 4372, Loss: 1.6165257289540023, Final Batch Loss: 0.0031566813122481108\n",
      "Epoch 4373, Loss: 1.8408347368240356, Final Batch Loss: 0.3151337802410126\n",
      "Epoch 4374, Loss: 1.5504710748791695, Final Batch Loss: 0.08832675963640213\n",
      "Epoch 4375, Loss: 1.5186405181884766, Final Batch Loss: 0.06623965501785278\n",
      "Epoch 4376, Loss: 2.512775182723999, Final Batch Loss: 1.0500776767730713\n",
      "Epoch 4377, Loss: 1.536827325811828, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 4378, Loss: 1.4909785464406013, Final Batch Loss: 0.014040149748325348\n",
      "Epoch 4379, Loss: 3.35771381855011, Final Batch Loss: 1.879465103149414\n",
      "Epoch 4380, Loss: 1.47305928170681, Final Batch Loss: 0.06310950219631195\n",
      "Epoch 4381, Loss: 2.3046275675296783, Final Batch Loss: 0.7867453694343567\n",
      "Epoch 4382, Loss: 2.653689295053482, Final Batch Loss: 1.172987937927246\n",
      "Epoch 4383, Loss: 1.8184912204742432, Final Batch Loss: 0.3186032772064209\n",
      "Epoch 4384, Loss: 3.6248112320899963, Final Batch Loss: 2.1559929847717285\n",
      "Epoch 4385, Loss: 1.7311786115169525, Final Batch Loss: 0.26578718423843384\n",
      "Epoch 4386, Loss: 1.6431280970573425, Final Batch Loss: 0.1840696632862091\n",
      "Epoch 4387, Loss: 2.3643932044506073, Final Batch Loss: 0.8850175738334656\n",
      "Epoch 4388, Loss: 3.818534940481186, Final Batch Loss: 2.198270797729492\n",
      "Epoch 4389, Loss: 1.7518453150987625, Final Batch Loss: 0.19319160282611847\n",
      "Epoch 4390, Loss: 1.84547820687294, Final Batch Loss: 0.36361536383628845\n",
      "Epoch 4391, Loss: 1.7804075181484222, Final Batch Loss: 0.2371290624141693\n",
      "Epoch 4392, Loss: 1.5415576975792646, Final Batch Loss: 0.01752018742263317\n",
      "Epoch 4393, Loss: 1.589165249839425, Final Batch Loss: 0.0166956577450037\n",
      "Epoch 4394, Loss: 2.081899493932724, Final Batch Loss: 0.6230716109275818\n",
      "Epoch 4395, Loss: 3.50865238904953, Final Batch Loss: 2.0254223346710205\n",
      "Epoch 4396, Loss: 3.1066017150878906, Final Batch Loss: 1.566751480102539\n",
      "Epoch 4397, Loss: 2.2435640394687653, Final Batch Loss: 0.7883068919181824\n",
      "Epoch 4398, Loss: 2.327245533466339, Final Batch Loss: 0.7146101593971252\n",
      "Epoch 4399, Loss: 1.9798782169818878, Final Batch Loss: 0.4782736897468567\n",
      "Epoch 4400, Loss: 1.9630969166755676, Final Batch Loss: 0.38868531584739685\n",
      "Epoch 4401, Loss: 1.5607807526830584, Final Batch Loss: 0.0013450870756059885\n",
      "Epoch 4402, Loss: 1.9409414678812027, Final Batch Loss: 0.18582002818584442\n",
      "Epoch 4403, Loss: 2.1688366532325745, Final Batch Loss: 0.44617241621017456\n",
      "Epoch 4404, Loss: 2.0305031836032867, Final Batch Loss: 0.37097230553627014\n",
      "Epoch 4405, Loss: 4.609249234199524, Final Batch Loss: 3.081676959991455\n",
      "Epoch 4406, Loss: 1.605229496955701, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4407, Loss: 2.4745665788650513, Final Batch Loss: 0.6584442257881165\n",
      "Epoch 4408, Loss: 1.763444906566292, Final Batch Loss: 0.0063773454166948795\n",
      "Epoch 4409, Loss: 1.874914065003395, Final Batch Loss: 0.19730837643146515\n",
      "Epoch 4410, Loss: 2.0046358704566956, Final Batch Loss: 0.457398384809494\n",
      "Epoch 4411, Loss: 2.9598114788532257, Final Batch Loss: 1.4373890161514282\n",
      "Epoch 4412, Loss: 1.6225134545675246, Final Batch Loss: 0.00019214690837543458\n",
      "Epoch 4413, Loss: 1.8740266859531403, Final Batch Loss: 0.2855980098247528\n",
      "Epoch 4414, Loss: 1.5197338695215876, Final Batch Loss: 0.0001137191939051263\n",
      "Epoch 4415, Loss: 1.618304044008255, Final Batch Loss: 0.09058389067649841\n",
      "Epoch 4416, Loss: 2.018828719854355, Final Batch Loss: 0.5348279476165771\n",
      "Epoch 4417, Loss: 3.27247354388237, Final Batch Loss: 1.842468023300171\n",
      "Epoch 4418, Loss: 3.6983117163181305, Final Batch Loss: 2.2714076042175293\n",
      "Epoch 4419, Loss: 1.9513747990131378, Final Batch Loss: 0.2469232976436615\n",
      "Epoch 4420, Loss: 1.9050446539185941, Final Batch Loss: 0.0026587634347379208\n",
      "Epoch 4421, Loss: 1.94275495223701, Final Batch Loss: 0.02324649505317211\n",
      "Epoch 4422, Loss: 3.4083080291748047, Final Batch Loss: 1.383516788482666\n",
      "Epoch 4423, Loss: 2.1005098149180412, Final Batch Loss: 0.11673694103956223\n",
      "Epoch 4424, Loss: 2.214415192604065, Final Batch Loss: 0.29200148582458496\n",
      "Epoch 4425, Loss: 3.1596150994300842, Final Batch Loss: 1.3029013872146606\n",
      "Epoch 4426, Loss: 3.1069474816322327, Final Batch Loss: 1.3021537065505981\n",
      "Epoch 4427, Loss: 1.839239090681076, Final Batch Loss: 0.05291453003883362\n",
      "Epoch 4428, Loss: 1.768810510626281, Final Batch Loss: 4.291525328881107e-06\n",
      "Epoch 4429, Loss: 1.7101845915894955, Final Batch Loss: 0.0008247073274105787\n",
      "Epoch 4430, Loss: 1.8780818581581116, Final Batch Loss: 0.1645016074180603\n",
      "Epoch 4431, Loss: 1.711630273523042, Final Batch Loss: 0.00015007323236204684\n",
      "Epoch 4432, Loss: 1.6935337018221617, Final Batch Loss: 0.004042668268084526\n",
      "Epoch 4433, Loss: 1.6480862999742385, Final Batch Loss: 0.00013755806139670312\n",
      "Epoch 4434, Loss: 1.6824978540244047, Final Batch Loss: 0.0002637753786984831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4435, Loss: 1.8690557181835175, Final Batch Loss: 0.25371119379997253\n",
      "Epoch 4436, Loss: 3.6288733780384064, Final Batch Loss: 2.056915283203125\n",
      "Epoch 4437, Loss: 1.6027365885674953, Final Batch Loss: 0.02169787511229515\n",
      "Epoch 4438, Loss: 1.6056824922555961, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4439, Loss: 2.654489517211914, Final Batch Loss: 0.9713022112846375\n",
      "Epoch 4440, Loss: 1.5718214093067218, Final Batch Loss: 0.0001554368354845792\n",
      "Epoch 4441, Loss: 3.51875638961792, Final Batch Loss: 2.016861915588379\n",
      "Epoch 4442, Loss: 1.6012707650661469, Final Batch Loss: 0.06629890203475952\n",
      "Epoch 4443, Loss: 1.562618268537335, Final Batch Loss: 0.0016110072610899806\n",
      "Epoch 4444, Loss: 1.5231858626939356, Final Batch Loss: 0.001717998180538416\n",
      "Epoch 4445, Loss: 3.1167512238025665, Final Batch Loss: 1.6131900548934937\n",
      "Epoch 4446, Loss: 2.2878766655921936, Final Batch Loss: 0.7909042239189148\n",
      "Epoch 4447, Loss: 1.5289289305219427, Final Batch Loss: 0.0004345426568761468\n",
      "Epoch 4448, Loss: 1.681669257581234, Final Batch Loss: 0.10283675044775009\n",
      "Epoch 4449, Loss: 1.4933815726544708, Final Batch Loss: 0.002163333585485816\n",
      "Epoch 4450, Loss: 1.4903435679152608, Final Batch Loss: 0.012694385834038258\n",
      "Epoch 4451, Loss: 2.1691114008426666, Final Batch Loss: 0.6619253158569336\n",
      "Epoch 4452, Loss: 2.3125503063201904, Final Batch Loss: 0.8511898517608643\n",
      "Epoch 4453, Loss: 3.5305705666542053, Final Batch Loss: 1.9031585454940796\n",
      "Epoch 4454, Loss: 2.0583175122737885, Final Batch Loss: 0.49133288860321045\n",
      "Epoch 4455, Loss: 1.6569520458579063, Final Batch Loss: 0.0461479052901268\n",
      "Epoch 4456, Loss: 2.020374359562993, Final Batch Loss: 0.011751355603337288\n",
      "Epoch 4457, Loss: 2.570556327700615, Final Batch Loss: 0.18580220639705658\n",
      "Epoch 4458, Loss: 3.7335705757141113, Final Batch Loss: 1.3186239004135132\n",
      "Epoch 4459, Loss: 2.2711386792361736, Final Batch Loss: 0.023803066462278366\n",
      "Epoch 4460, Loss: 2.5848113894462585, Final Batch Loss: 0.3032683730125427\n",
      "Epoch 4461, Loss: 1.9971494674682617, Final Batch Loss: 0.008388996124267578\n",
      "Epoch 4462, Loss: 2.264522433280945, Final Batch Loss: 0.40807223320007324\n",
      "Epoch 4463, Loss: 2.428757071495056, Final Batch Loss: 0.774989664554596\n",
      "Epoch 4464, Loss: 2.342712789773941, Final Batch Loss: 0.7680703997612\n",
      "Epoch 4465, Loss: 1.7039126977324486, Final Batch Loss: 0.10775109380483627\n",
      "Epoch 4466, Loss: 1.6500604157336056, Final Batch Loss: 0.005904138553887606\n",
      "Epoch 4467, Loss: 1.6811472848057747, Final Batch Loss: 0.12134174257516861\n",
      "Epoch 4468, Loss: 1.4742217861203244, Final Batch Loss: 0.00013910756388213485\n",
      "Epoch 4469, Loss: 1.4218561911256984, Final Batch Loss: 0.0018446111353114247\n",
      "Epoch 4470, Loss: 3.2138529121875763, Final Batch Loss: 1.7939727306365967\n",
      "Epoch 4471, Loss: 1.479409086983651, Final Batch Loss: 0.004869032185524702\n",
      "Epoch 4472, Loss: 2.2692799866199493, Final Batch Loss: 0.7833099365234375\n",
      "Epoch 4473, Loss: 2.740649402141571, Final Batch Loss: 1.2241567373275757\n",
      "Epoch 4474, Loss: 1.923393964767456, Final Batch Loss: 0.41808757185935974\n",
      "Epoch 4475, Loss: 1.527103053405881, Final Batch Loss: 0.027026133611798286\n",
      "Epoch 4476, Loss: 1.7303495109081268, Final Batch Loss: 0.2699912488460541\n",
      "Epoch 4477, Loss: 1.531202586600557, Final Batch Loss: 0.001312824198976159\n",
      "Epoch 4478, Loss: 1.8383581340312958, Final Batch Loss: 0.31301167607307434\n",
      "Epoch 4479, Loss: 1.5243464494124055, Final Batch Loss: 0.015371778048574924\n",
      "Epoch 4480, Loss: 1.5732209458947182, Final Batch Loss: 0.06311599165201187\n",
      "Epoch 4481, Loss: 1.6585270911455154, Final Batch Loss: 0.18907539546489716\n",
      "Epoch 4482, Loss: 1.5153882382437587, Final Batch Loss: 0.0029017506167292595\n",
      "Epoch 4483, Loss: 2.505465477705002, Final Batch Loss: 1.0504961013793945\n",
      "Epoch 4484, Loss: 1.5251848548650742, Final Batch Loss: 0.009008124470710754\n",
      "Epoch 4485, Loss: 1.4472942342508759, Final Batch Loss: 4.4225667807040736e-05\n",
      "Epoch 4486, Loss: 1.7987513542175293, Final Batch Loss: 0.25712069869041443\n",
      "Epoch 4487, Loss: 1.4770159125218925, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 4488, Loss: 3.573646306991577, Final Batch Loss: 2.113809108734131\n",
      "Epoch 4489, Loss: 2.1488592624664307, Final Batch Loss: 0.6819403767585754\n",
      "Epoch 4490, Loss: 1.4798722882114816, Final Batch Loss: 0.00023624490131624043\n",
      "Epoch 4491, Loss: 2.4248542189598083, Final Batch Loss: 0.9136126637458801\n",
      "Epoch 4492, Loss: 2.5264495611190796, Final Batch Loss: 1.0181547403335571\n",
      "Epoch 4493, Loss: 2.422036349773407, Final Batch Loss: 1.0100196599960327\n",
      "Epoch 4494, Loss: 2.523962616920471, Final Batch Loss: 1.0825566053390503\n",
      "Epoch 4495, Loss: 2.448783040046692, Final Batch Loss: 0.9451335072517395\n",
      "Epoch 4496, Loss: 1.4987680884078145, Final Batch Loss: 0.007652846165001392\n",
      "Epoch 4497, Loss: 3.5547522008419037, Final Batch Loss: 2.0505127906799316\n",
      "Epoch 4498, Loss: 1.6851372122764587, Final Batch Loss: 0.23744753003120422\n",
      "Epoch 4499, Loss: 2.086849480867386, Final Batch Loss: 0.5806596875190735\n",
      "Epoch 4500, Loss: 1.4706414060201496, Final Batch Loss: 0.0012903229799121618\n",
      "Epoch 4501, Loss: 3.0147126615047455, Final Batch Loss: 1.5157601833343506\n",
      "Epoch 4502, Loss: 2.6110700070858, Final Batch Loss: 1.0873534679412842\n",
      "Epoch 4503, Loss: 2.021703988313675, Final Batch Loss: 0.4786588251590729\n",
      "Epoch 4504, Loss: 2.2903577387332916, Final Batch Loss: 0.7057525515556335\n",
      "Epoch 4505, Loss: 1.8343683779239655, Final Batch Loss: 0.1388052999973297\n",
      "Epoch 4506, Loss: 1.9983515739440918, Final Batch Loss: 0.15586751699447632\n",
      "Epoch 4507, Loss: 3.4156121611595154, Final Batch Loss: 1.6681160926818848\n",
      "Epoch 4508, Loss: 2.0668784081935883, Final Batch Loss: 0.3118745982646942\n",
      "Epoch 4509, Loss: 1.718434453010559, Final Batch Loss: 0.0\n",
      "Epoch 4510, Loss: 1.6816425174474716, Final Batch Loss: 0.09265176951885223\n",
      "Epoch 4511, Loss: 1.5992751973681152, Final Batch Loss: 0.001675750594586134\n",
      "Epoch 4512, Loss: 1.5606086254119873, Final Batch Loss: 0.0\n",
      "Epoch 4513, Loss: 2.1014976501464844, Final Batch Loss: 0.5170957446098328\n",
      "Epoch 4514, Loss: 2.891340672969818, Final Batch Loss: 1.392163872718811\n",
      "Epoch 4515, Loss: 2.829090893268585, Final Batch Loss: 1.2832081317901611\n",
      "Epoch 4516, Loss: 1.5438852193765342, Final Batch Loss: 0.006305206101387739\n",
      "Epoch 4517, Loss: 1.4824292194098234, Final Batch Loss: 0.007891429588198662\n",
      "Epoch 4518, Loss: 1.5074720680709106, Final Batch Loss: 9.536738616588991e-07\n",
      "Epoch 4519, Loss: 1.7485255002975464, Final Batch Loss: 0.12352269887924194\n",
      "Epoch 4520, Loss: 3.257035493850708, Final Batch Loss: 1.7635397911071777\n",
      "Epoch 4521, Loss: 1.6235685497522354, Final Batch Loss: 0.2012200504541397\n",
      "Epoch 4522, Loss: 1.4664703272283077, Final Batch Loss: 0.010134901851415634\n",
      "Epoch 4523, Loss: 2.70758917927742, Final Batch Loss: 1.3226256370544434\n",
      "Epoch 4524, Loss: 1.4697040318915242, Final Batch Loss: 1.0251946150674485e-05\n",
      "Epoch 4525, Loss: 2.281568318605423, Final Batch Loss: 0.8021162152290344\n",
      "Epoch 4526, Loss: 1.8229478299617767, Final Batch Loss: 0.324669748544693\n",
      "Epoch 4527, Loss: 1.5860336680998444, Final Batch Loss: 8.940297266235575e-05\n",
      "Epoch 4528, Loss: 2.1128019094467163, Final Batch Loss: 0.5296119451522827\n",
      "Epoch 4529, Loss: 1.474034666787702, Final Batch Loss: 2.13382354559144e-05\n",
      "Epoch 4530, Loss: 1.7179473787546158, Final Batch Loss: 0.21250779926776886\n",
      "Epoch 4531, Loss: 1.505969613790512, Final Batch Loss: 0.08595940470695496\n",
      "Epoch 4532, Loss: 1.538735929876566, Final Batch Loss: 0.021724704653024673\n",
      "Epoch 4533, Loss: 2.581736236810684, Final Batch Loss: 1.144071340560913\n",
      "Epoch 4534, Loss: 1.5275162755078782, Final Batch Loss: 1.6569954823353328e-05\n",
      "Epoch 4535, Loss: 1.4567612208193168, Final Batch Loss: 0.0007593132322654128\n",
      "Epoch 4536, Loss: 2.5819534063339233, Final Batch Loss: 1.0742216110229492\n",
      "Epoch 4537, Loss: 1.5011651143431664, Final Batch Loss: 0.026008956134319305\n",
      "Epoch 4538, Loss: 1.5182708203792572, Final Batch Loss: 0.06884351372718811\n",
      "Epoch 4539, Loss: 2.0648171305656433, Final Batch Loss: 0.6395987868309021\n",
      "Epoch 4540, Loss: 2.2072568237781525, Final Batch Loss: 0.8044191002845764\n",
      "Epoch 4541, Loss: 1.4599564059171826, Final Batch Loss: 0.0010371787939220667\n",
      "Epoch 4542, Loss: 1.5285981621127576, Final Batch Loss: 0.002570065436884761\n",
      "Epoch 4543, Loss: 2.3125248551368713, Final Batch Loss: 0.8343293070793152\n",
      "Epoch 4544, Loss: 1.7112174332141876, Final Batch Loss: 0.2664662301540375\n",
      "Epoch 4545, Loss: 1.5038905441761017, Final Batch Loss: 0.032430022954940796\n",
      "Epoch 4546, Loss: 1.5319977700710297, Final Batch Loss: 0.0\n",
      "Epoch 4547, Loss: 1.55469960719347, Final Batch Loss: 0.08468759804964066\n",
      "Epoch 4548, Loss: 2.578156441450119, Final Batch Loss: 1.1711339950561523\n",
      "Epoch 4549, Loss: 1.9865985810756683, Final Batch Loss: 0.5610712170600891\n",
      "Epoch 4550, Loss: 1.565453551709652, Final Batch Loss: 0.11927484720945358\n",
      "Epoch 4551, Loss: 1.5291241593658924, Final Batch Loss: 0.05333210900425911\n",
      "Epoch 4552, Loss: 1.5899758264422417, Final Batch Loss: 0.07827725261449814\n",
      "Epoch 4553, Loss: 3.8820404410362244, Final Batch Loss: 2.4346983432769775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4554, Loss: 1.4945603661471978, Final Batch Loss: 0.0004102342063561082\n",
      "Epoch 4555, Loss: 1.5282880887389183, Final Batch Loss: 0.030756168067455292\n",
      "Epoch 4556, Loss: 1.5100734233856201, Final Batch Loss: 0.06579864025115967\n",
      "Epoch 4557, Loss: 1.5273335622623563, Final Batch Loss: 0.015019779093563557\n",
      "Epoch 4558, Loss: 1.761379063129425, Final Batch Loss: 0.33174848556518555\n",
      "Epoch 4559, Loss: 2.3946887254714966, Final Batch Loss: 0.8848375678062439\n",
      "Epoch 4560, Loss: 2.1114483177661896, Final Batch Loss: 0.6250478029251099\n",
      "Epoch 4561, Loss: 1.618147850036621, Final Batch Loss: 0.17479407787322998\n",
      "Epoch 4562, Loss: 1.3655972480773926, Final Batch Loss: 0.0\n",
      "Epoch 4563, Loss: 1.4013914071256295, Final Batch Loss: 0.00158791767898947\n",
      "Epoch 4564, Loss: 1.6079275906085968, Final Batch Loss: 0.2594066858291626\n",
      "Epoch 4565, Loss: 1.8634423613548279, Final Batch Loss: 0.4667836129665375\n",
      "Epoch 4566, Loss: 1.977048397064209, Final Batch Loss: 0.49567413330078125\n",
      "Epoch 4567, Loss: 3.500139355659485, Final Batch Loss: 2.0847439765930176\n",
      "Epoch 4568, Loss: 1.4641158491140231, Final Batch Loss: 0.0005062728887423873\n",
      "Epoch 4569, Loss: 1.5509587055421434, Final Batch Loss: 0.0003069168305955827\n",
      "Epoch 4570, Loss: 2.451072722673416, Final Batch Loss: 0.8632224798202515\n",
      "Epoch 4571, Loss: 2.0542661547660828, Final Batch Loss: 0.5974394083023071\n",
      "Epoch 4572, Loss: 1.427741752937436, Final Batch Loss: 0.01250721700489521\n",
      "Epoch 4573, Loss: 1.4627388503868133, Final Batch Loss: 0.0026475873310118914\n",
      "Epoch 4574, Loss: 1.4760689176619053, Final Batch Loss: 0.006726834923028946\n",
      "Epoch 4575, Loss: 1.395171396434307, Final Batch Loss: 0.016779594123363495\n",
      "Epoch 4576, Loss: 2.9104276299476624, Final Batch Loss: 1.5109984874725342\n",
      "Epoch 4577, Loss: 1.4708027525484795, Final Batch Loss: 5.686121585313231e-05\n",
      "Epoch 4578, Loss: 3.607625335454941, Final Batch Loss: 2.1411709785461426\n",
      "Epoch 4579, Loss: 1.462797412648797, Final Batch Loss: 0.02198747731745243\n",
      "Epoch 4580, Loss: 1.4743344793096185, Final Batch Loss: 0.011713535524904728\n",
      "Epoch 4581, Loss: 2.433466464281082, Final Batch Loss: 1.0288265943527222\n",
      "Epoch 4582, Loss: 1.9235230088233948, Final Batch Loss: 0.3729614019393921\n",
      "Epoch 4583, Loss: 2.44833567738533, Final Batch Loss: 0.9648198485374451\n",
      "Epoch 4584, Loss: 1.6227500438690186, Final Batch Loss: 0.16146156191825867\n",
      "Epoch 4585, Loss: 1.8595647513866425, Final Batch Loss: 0.31963133811950684\n",
      "Epoch 4586, Loss: 1.7796281427145004, Final Batch Loss: 0.19959644973278046\n",
      "Epoch 4587, Loss: 1.5426387182669714, Final Batch Loss: 0.0014650813536718488\n",
      "Epoch 4588, Loss: 3.1806704699993134, Final Batch Loss: 1.6744203567504883\n",
      "Epoch 4589, Loss: 1.5733621417994073, Final Batch Loss: 9.775113539944869e-06\n",
      "Epoch 4590, Loss: 2.6659320890903473, Final Batch Loss: 1.1289026737213135\n",
      "Epoch 4591, Loss: 1.4522593019501073, Final Batch Loss: 1.9430925021879375e-05\n",
      "Epoch 4592, Loss: 1.4895818678342039, Final Batch Loss: 0.00017391123401466757\n",
      "Epoch 4593, Loss: 1.9691572487354279, Final Batch Loss: 0.491655558347702\n",
      "Epoch 4594, Loss: 2.6518636643886566, Final Batch Loss: 1.1787633895874023\n",
      "Epoch 4595, Loss: 1.5339362025260925, Final Batch Loss: 0.07082498073577881\n",
      "Epoch 4596, Loss: 1.5509039387106895, Final Batch Loss: 0.07883598655462265\n",
      "Epoch 4597, Loss: 2.756536841392517, Final Batch Loss: 1.3296011686325073\n",
      "Epoch 4598, Loss: 1.7091601341962814, Final Batch Loss: 0.21582360565662384\n",
      "Epoch 4599, Loss: 2.2090939581394196, Final Batch Loss: 0.764113187789917\n",
      "Epoch 4600, Loss: 1.469561640638858, Final Batch Loss: 0.004595552105456591\n",
      "Epoch 4601, Loss: 1.6559964567422867, Final Batch Loss: 0.09795109927654266\n",
      "Epoch 4602, Loss: 1.6782695651054382, Final Batch Loss: 0.06849971413612366\n",
      "Epoch 4603, Loss: 1.5088495910167694, Final Batch Loss: 0.0\n",
      "Epoch 4604, Loss: 1.537559658285545, Final Batch Loss: 2.622600959512056e-06\n",
      "Epoch 4605, Loss: 1.4925330802798271, Final Batch Loss: 0.07111480087041855\n",
      "Epoch 4606, Loss: 2.2499738335609436, Final Batch Loss: 0.8964388370513916\n",
      "Epoch 4607, Loss: 3.7727703750133514, Final Batch Loss: 2.408740282058716\n",
      "Epoch 4608, Loss: 1.498334638774395, Final Batch Loss: 0.061403416097164154\n",
      "Epoch 4609, Loss: 1.596870169043541, Final Batch Loss: 0.15318213403224945\n",
      "Epoch 4610, Loss: 1.489746242761612, Final Batch Loss: 0.03859531879425049\n",
      "Epoch 4611, Loss: 2.2233179211616516, Final Batch Loss: 0.7651791572570801\n",
      "Epoch 4612, Loss: 1.4381969133391976, Final Batch Loss: 0.00945152435451746\n",
      "Epoch 4613, Loss: 1.3822354945586994, Final Batch Loss: 0.001620647613890469\n",
      "Epoch 4614, Loss: 1.4871596843004227, Final Batch Loss: 0.013810083270072937\n",
      "Epoch 4615, Loss: 1.5305112598816777, Final Batch Loss: 1.7404405298293568e-05\n",
      "Epoch 4616, Loss: 1.887678474187851, Final Batch Loss: 0.4253438413143158\n",
      "Epoch 4617, Loss: 1.5828096270561218, Final Batch Loss: 0.0326310396194458\n",
      "Epoch 4618, Loss: 1.83246994018009, Final Batch Loss: 3.3378546504536644e-06\n",
      "Epoch 4619, Loss: 1.9745107162743807, Final Batch Loss: 0.02211807854473591\n",
      "Epoch 4620, Loss: 2.035927228629589, Final Batch Loss: 0.04575430601835251\n",
      "Epoch 4621, Loss: 1.8225424264892354, Final Batch Loss: 7.045020902296528e-05\n",
      "Epoch 4622, Loss: 1.6555514633655548, Final Batch Loss: 0.0730603039264679\n",
      "Epoch 4623, Loss: 1.568892091512339, Final Batch Loss: 8.344646857949556e-07\n",
      "Epoch 4624, Loss: 1.5190761219710112, Final Batch Loss: 0.016547812148928642\n",
      "Epoch 4625, Loss: 1.488235131255351, Final Batch Loss: 0.0010495636379346251\n",
      "Epoch 4626, Loss: 1.9918249249458313, Final Batch Loss: 0.44434499740600586\n",
      "Epoch 4627, Loss: 1.4052333775616717, Final Batch Loss: 0.00010597144137136638\n",
      "Epoch 4628, Loss: 2.4178945124149323, Final Batch Loss: 0.8841146230697632\n",
      "Epoch 4629, Loss: 1.4654646515845684, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4630, Loss: 1.6906742751598358, Final Batch Loss: 0.25510653853416443\n",
      "Epoch 4631, Loss: 1.419249743095861, Final Batch Loss: 1.597391747054644e-05\n",
      "Epoch 4632, Loss: 1.4964358210518185, Final Batch Loss: 2.9802276912960224e-06\n",
      "Epoch 4633, Loss: 1.4706410057842731, Final Batch Loss: 0.033596206456422806\n",
      "Epoch 4634, Loss: 2.002109110355377, Final Batch Loss: 0.5303804874420166\n",
      "Epoch 4635, Loss: 1.5055047813802958, Final Batch Loss: 0.023944372311234474\n",
      "Epoch 4636, Loss: 3.506920725107193, Final Batch Loss: 1.9582359790802002\n",
      "Epoch 4637, Loss: 2.3450870513916016, Final Batch Loss: 0.8040955662727356\n",
      "Epoch 4638, Loss: 1.6310442462563515, Final Batch Loss: 0.017030425369739532\n",
      "Epoch 4639, Loss: 1.7609554678201675, Final Batch Loss: 0.12931205332279205\n",
      "Epoch 4640, Loss: 1.6227286447756342, Final Batch Loss: 4.5298504119273275e-05\n",
      "Epoch 4641, Loss: 1.7494548112154007, Final Batch Loss: 0.12564434111118317\n",
      "Epoch 4642, Loss: 1.6501593608409166, Final Batch Loss: 0.027372540906071663\n",
      "Epoch 4643, Loss: 3.623265564441681, Final Batch Loss: 2.0147385597229004\n",
      "Epoch 4644, Loss: 1.5036691426585094, Final Batch Loss: 1.1324817933200393e-05\n",
      "Epoch 4645, Loss: 1.4741689595393836, Final Batch Loss: 0.002886179368942976\n",
      "Epoch 4646, Loss: 1.8953129351139069, Final Batch Loss: 0.29340660572052\n",
      "Epoch 4647, Loss: 2.5775625109672546, Final Batch Loss: 0.9674475789070129\n",
      "Epoch 4648, Loss: 3.077797055244446, Final Batch Loss: 1.333936095237732\n",
      "Epoch 4649, Loss: 2.943033456802368, Final Batch Loss: 1.2972757816314697\n",
      "Epoch 4650, Loss: 2.6271029710769653, Final Batch Loss: 1.1100164651870728\n",
      "Epoch 4651, Loss: 3.5615053474903107, Final Batch Loss: 2.0474259853363037\n",
      "Epoch 4652, Loss: 2.906537175178528, Final Batch Loss: 1.2801581621170044\n",
      "Epoch 4653, Loss: 1.6878748899325728, Final Batch Loss: 0.0036743050441145897\n",
      "Epoch 4654, Loss: 1.7752325823530555, Final Batch Loss: 0.00042500998824834824\n",
      "Epoch 4655, Loss: 1.7894771099090576, Final Batch Loss: 0.0\n",
      "Epoch 4656, Loss: 2.2875524163246155, Final Batch Loss: 0.5806301832199097\n",
      "Epoch 4657, Loss: 3.441422760486603, Final Batch Loss: 1.6158053874969482\n",
      "Epoch 4658, Loss: 2.4222812056541443, Final Batch Loss: 0.6435894966125488\n",
      "Epoch 4659, Loss: 1.8540000319480896, Final Batch Loss: 0.2068798542022705\n",
      "Epoch 4660, Loss: 1.8389445322973188, Final Batch Loss: 0.0004040378553327173\n",
      "Epoch 4661, Loss: 3.2714935541152954, Final Batch Loss: 1.3181324005126953\n",
      "Epoch 4662, Loss: 1.7713567113969475, Final Batch Loss: 0.002362082013860345\n",
      "Epoch 4663, Loss: 2.5157126784324646, Final Batch Loss: 0.6714098453521729\n",
      "Epoch 4664, Loss: 3.5079845190048218, Final Batch Loss: 1.8086899518966675\n",
      "Epoch 4665, Loss: 1.8140425253659487, Final Batch Loss: 0.018601613119244576\n",
      "Epoch 4666, Loss: 1.9511866122484207, Final Batch Loss: 0.24461640417575836\n",
      "Epoch 4667, Loss: 3.265174150466919, Final Batch Loss: 1.694000244140625\n",
      "Epoch 4668, Loss: 2.992340564727783, Final Batch Loss: 1.4298216104507446\n",
      "Epoch 4669, Loss: 2.6566471457481384, Final Batch Loss: 1.0541417598724365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4670, Loss: 1.7023706957697868, Final Batch Loss: 0.03719734400510788\n",
      "Epoch 4671, Loss: 3.308130979537964, Final Batch Loss: 1.707349419593811\n",
      "Epoch 4672, Loss: 1.716741930693388, Final Batch Loss: 0.026943515986204147\n",
      "Epoch 4673, Loss: 1.6325099989771843, Final Batch Loss: 0.009257368743419647\n",
      "Epoch 4674, Loss: 1.9009304344654083, Final Batch Loss: 0.26632383465766907\n",
      "Epoch 4675, Loss: 1.6519737225025892, Final Batch Loss: 0.005459992215037346\n",
      "Epoch 4676, Loss: 1.5626790383830667, Final Batch Loss: 0.011061654426157475\n",
      "Epoch 4677, Loss: 5.068981885910034, Final Batch Loss: 3.5851430892944336\n",
      "Epoch 4678, Loss: 1.8717913925647736, Final Batch Loss: 0.3354591131210327\n",
      "Epoch 4679, Loss: 1.6220767344348133, Final Batch Loss: 0.006959601771086454\n",
      "Epoch 4680, Loss: 2.4459195733070374, Final Batch Loss: 0.9089332222938538\n",
      "Epoch 4681, Loss: 1.5191039741032455, Final Batch Loss: 1.1920922133867862e-06\n",
      "Epoch 4682, Loss: 1.515822820365429, Final Batch Loss: 0.011957041919231415\n",
      "Epoch 4683, Loss: 2.3519917130470276, Final Batch Loss: 0.8665516972541809\n",
      "Epoch 4684, Loss: 1.4837352335453033, Final Batch Loss: 0.0\n",
      "Epoch 4685, Loss: 4.597703337669373, Final Batch Loss: 3.0226714611053467\n",
      "Epoch 4686, Loss: 1.502962619041682, Final Batch Loss: 7.033323527139146e-06\n",
      "Epoch 4687, Loss: 2.217723309993744, Final Batch Loss: 0.6267176270484924\n",
      "Epoch 4688, Loss: 3.9940101504325867, Final Batch Loss: 2.3523519039154053\n",
      "Epoch 4689, Loss: 1.572205156087307, Final Batch Loss: 1.0728830375228426e-06\n",
      "Epoch 4690, Loss: 1.6082726791501045, Final Batch Loss: 0.056873805820941925\n",
      "Epoch 4691, Loss: 1.4403326475294307, Final Batch Loss: 0.0015266203554347157\n",
      "Epoch 4692, Loss: 2.4679672718048096, Final Batch Loss: 0.8605058789253235\n",
      "Epoch 4693, Loss: 1.5889154076576233, Final Batch Loss: 0.03430613875389099\n",
      "Epoch 4694, Loss: 1.5468467473951932, Final Batch Loss: 2.50339189733495e-06\n",
      "Epoch 4695, Loss: 1.5622591152787209, Final Batch Loss: 0.07664413005113602\n",
      "Epoch 4696, Loss: 3.3528073728084564, Final Batch Loss: 1.815861463546753\n",
      "Epoch 4697, Loss: 1.5370436601297115, Final Batch Loss: 3.8742269680369645e-05\n",
      "Epoch 4698, Loss: 3.51324000954628, Final Batch Loss: 1.9913787841796875\n",
      "Epoch 4699, Loss: 3.8200680911540985, Final Batch Loss: 2.3034517765045166\n",
      "Epoch 4700, Loss: 1.5807765125136939, Final Batch Loss: 1.4781842764932662e-05\n",
      "Epoch 4701, Loss: 2.909599155187607, Final Batch Loss: 1.3646081686019897\n",
      "Epoch 4702, Loss: 1.7335422188043594, Final Batch Loss: 0.21007202565670013\n",
      "Epoch 4703, Loss: 1.5769090123358183, Final Batch Loss: 0.0005334384622983634\n",
      "Epoch 4704, Loss: 1.7220162190496922, Final Batch Loss: 0.0323566235601902\n",
      "Epoch 4705, Loss: 1.8516280949115753, Final Batch Loss: 0.32591572403907776\n",
      "Epoch 4706, Loss: 3.303709864616394, Final Batch Loss: 1.7958027124404907\n",
      "Epoch 4707, Loss: 2.0309221148490906, Final Batch Loss: 0.5140181183815002\n",
      "Epoch 4708, Loss: 1.4799004477681592, Final Batch Loss: 0.0003502947511151433\n",
      "Epoch 4709, Loss: 2.2206010222434998, Final Batch Loss: 0.7468030452728271\n",
      "Epoch 4710, Loss: 2.6348482072353363, Final Batch Loss: 1.137071132659912\n",
      "Epoch 4711, Loss: 2.463282734155655, Final Batch Loss: 0.9745094776153564\n",
      "Epoch 4712, Loss: 1.5496284440159798, Final Batch Loss: 0.021747566759586334\n",
      "Epoch 4713, Loss: 1.4440434572807135, Final Batch Loss: 2.13382354559144e-05\n",
      "Epoch 4714, Loss: 2.4545507729053497, Final Batch Loss: 1.013477087020874\n",
      "Epoch 4715, Loss: 3.1097577810287476, Final Batch Loss: 1.5602023601531982\n",
      "Epoch 4716, Loss: 3.9094086587429047, Final Batch Loss: 2.435986042022705\n",
      "Epoch 4717, Loss: 2.891858994960785, Final Batch Loss: 1.4021244049072266\n",
      "Epoch 4718, Loss: 1.8198918849229813, Final Batch Loss: 0.19935543835163116\n",
      "Epoch 4719, Loss: 1.6649147821735824, Final Batch Loss: 9.63164638960734e-05\n",
      "Epoch 4720, Loss: 3.2366883456707, Final Batch Loss: 1.5256264209747314\n",
      "Epoch 4721, Loss: 1.616885781115343, Final Batch Loss: 1.8596476365928538e-05\n",
      "Epoch 4722, Loss: 1.6178559269756079, Final Batch Loss: 0.019421299919486046\n",
      "Epoch 4723, Loss: 1.70660862326622, Final Batch Loss: 0.02969244122505188\n",
      "Epoch 4724, Loss: 1.6184582570567727, Final Batch Loss: 0.008572564460337162\n",
      "Epoch 4725, Loss: 1.5504513680934338, Final Batch Loss: 3.576278118089249e-07\n",
      "Epoch 4726, Loss: 1.5401803852291778, Final Batch Loss: 0.0011448265286162496\n",
      "Epoch 4727, Loss: 1.505187445320189, Final Batch Loss: 0.0009831124916672707\n",
      "Epoch 4728, Loss: 2.196696102619171, Final Batch Loss: 0.7082796692848206\n",
      "Epoch 4729, Loss: 1.525117690616753, Final Batch Loss: 0.0008854520856402814\n",
      "Epoch 4730, Loss: 1.7022901773452759, Final Batch Loss: 0.2664625644683838\n",
      "Epoch 4731, Loss: 4.84435510635376, Final Batch Loss: 3.390134811401367\n",
      "Epoch 4732, Loss: 3.0567104518413544, Final Batch Loss: 1.564660906791687\n",
      "Epoch 4733, Loss: 2.0791081488132477, Final Batch Loss: 0.5961105823516846\n",
      "Epoch 4734, Loss: 1.6237304206642875, Final Batch Loss: 2.8371408916427754e-05\n",
      "Epoch 4735, Loss: 1.596954977430869, Final Batch Loss: 0.00021872512297704816\n",
      "Epoch 4736, Loss: 2.0697548389434814, Final Batch Loss: 0.5199329853057861\n",
      "Epoch 4737, Loss: 4.297759860754013, Final Batch Loss: 2.7478418350219727\n",
      "Epoch 4738, Loss: 2.4956915378570557, Final Batch Loss: 1.016262173652649\n",
      "Epoch 4739, Loss: 3.108938992023468, Final Batch Loss: 1.495802402496338\n",
      "Epoch 4740, Loss: 1.9069527089595795, Final Batch Loss: 0.11556455492973328\n",
      "Epoch 4741, Loss: 1.9373458474874496, Final Batch Loss: 0.22790513932704926\n",
      "Epoch 4742, Loss: 1.9357383400201797, Final Batch Loss: 0.1288287192583084\n",
      "Epoch 4743, Loss: 1.8237852966412902, Final Batch Loss: 0.008247247897088528\n",
      "Epoch 4744, Loss: 1.7734209892350918, Final Batch Loss: 2.3603161025675945e-05\n",
      "Epoch 4745, Loss: 1.7175010181963444, Final Batch Loss: 0.01954183354973793\n",
      "Epoch 4746, Loss: 1.8701504915952682, Final Batch Loss: 0.11206363141536713\n",
      "Epoch 4747, Loss: 1.6054358129913453, Final Batch Loss: 0.00026544384309090674\n",
      "Epoch 4748, Loss: 2.9980749785900116, Final Batch Loss: 1.4057650566101074\n",
      "Epoch 4749, Loss: 1.6982384994626045, Final Batch Loss: 0.11486775428056717\n",
      "Epoch 4750, Loss: 1.6213023662558044, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4751, Loss: 1.7820831537246704, Final Batch Loss: 0.017261862754821777\n",
      "Epoch 4752, Loss: 3.1777126789093018, Final Batch Loss: 1.4968113899230957\n",
      "Epoch 4753, Loss: 1.6730996184051037, Final Batch Loss: 0.04180977866053581\n",
      "Epoch 4754, Loss: 1.5886955810710788, Final Batch Loss: 0.0068375421687960625\n",
      "Epoch 4755, Loss: 2.3205787539482117, Final Batch Loss: 0.7140453457832336\n",
      "Epoch 4756, Loss: 2.8799220621585846, Final Batch Loss: 1.386624813079834\n",
      "Epoch 4757, Loss: 1.5347736176790931, Final Batch Loss: 2.4676019165781327e-05\n",
      "Epoch 4758, Loss: 2.7540280520915985, Final Batch Loss: 1.197828769683838\n",
      "Epoch 4759, Loss: 1.6608023717999458, Final Batch Loss: 0.10914421826601028\n",
      "Epoch 4760, Loss: 1.7016897276043892, Final Batch Loss: 0.1093909814953804\n",
      "Epoch 4761, Loss: 1.7062595933675766, Final Batch Loss: 0.2494065910577774\n",
      "Epoch 4762, Loss: 1.4450767636171804, Final Batch Loss: 5.006777428206988e-06\n",
      "Epoch 4763, Loss: 1.4682246837764978, Final Batch Loss: 0.0013740155845880508\n",
      "Epoch 4764, Loss: 1.7777611315250397, Final Batch Loss: 0.31283149123191833\n",
      "Epoch 4765, Loss: 1.4883515946567059, Final Batch Loss: 0.06096620485186577\n",
      "Epoch 4766, Loss: 1.9201633632183075, Final Batch Loss: 0.4203130304813385\n",
      "Epoch 4767, Loss: 1.4768002219498158, Final Batch Loss: 0.028416026383638382\n",
      "Epoch 4768, Loss: 1.5263993213884532, Final Batch Loss: 0.007191486191004515\n",
      "Epoch 4769, Loss: 1.53134732414037, Final Batch Loss: 0.011362721212208271\n",
      "Epoch 4770, Loss: 1.5615341626107693, Final Batch Loss: 0.02779686078429222\n",
      "Epoch 4771, Loss: 1.4771399833261967, Final Batch Loss: 0.029884520918130875\n",
      "Epoch 4772, Loss: 1.4670412667910568, Final Batch Loss: 0.0005762108485214412\n",
      "Epoch 4773, Loss: 1.8475661277770996, Final Batch Loss: 0.3775131404399872\n",
      "Epoch 4774, Loss: 1.389526842162013, Final Batch Loss: 0.010052410885691643\n",
      "Epoch 4775, Loss: 1.4635763531550765, Final Batch Loss: 0.011371678672730923\n",
      "Epoch 4776, Loss: 1.4605387448873444, Final Batch Loss: 8.821448318485636e-06\n",
      "Epoch 4777, Loss: 1.5440029052551836, Final Batch Loss: 0.001105412608012557\n",
      "Epoch 4778, Loss: 1.5160270929336477, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4779, Loss: 2.0124029219150543, Final Batch Loss: 0.514548122882843\n",
      "Epoch 4780, Loss: 1.7468863427639008, Final Batch Loss: 0.3504585325717926\n",
      "Epoch 4781, Loss: 2.7836318910121918, Final Batch Loss: 1.2836573123931885\n",
      "Epoch 4782, Loss: 1.5359604954719543, Final Batch Loss: 0.09764376282691956\n",
      "Epoch 4783, Loss: 2.8017985820770264, Final Batch Loss: 1.4341298341751099\n",
      "Epoch 4784, Loss: 1.4210869263624772, Final Batch Loss: 0.000925112864933908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4785, Loss: 1.5706231407821178, Final Batch Loss: 0.023399990051984787\n",
      "Epoch 4786, Loss: 2.8826266527175903, Final Batch Loss: 1.4083406925201416\n",
      "Epoch 4787, Loss: 1.4979877099394798, Final Batch Loss: 0.06618934124708176\n",
      "Epoch 4788, Loss: 1.5336046479642391, Final Batch Loss: 0.016662713140249252\n",
      "Epoch 4789, Loss: 2.198865056037903, Final Batch Loss: 0.7098842263221741\n",
      "Epoch 4790, Loss: 1.407034957781434, Final Batch Loss: 0.007017726078629494\n",
      "Epoch 4791, Loss: 1.842935860157013, Final Batch Loss: 0.3108447194099426\n",
      "Epoch 4792, Loss: 3.1018348336219788, Final Batch Loss: 1.6335625648498535\n",
      "Epoch 4793, Loss: 2.571726471185684, Final Batch Loss: 1.0466399192810059\n",
      "Epoch 4794, Loss: 1.5894757211208344, Final Batch Loss: 0.03108811378479004\n",
      "Epoch 4795, Loss: 1.8128736019134521, Final Batch Loss: 0.14642935991287231\n",
      "Epoch 4796, Loss: 2.4750254154205322, Final Batch Loss: 0.835788369178772\n",
      "Epoch 4797, Loss: 2.786014139652252, Final Batch Loss: 1.2395128011703491\n",
      "Epoch 4798, Loss: 1.4666076443972997, Final Batch Loss: 0.00030155404238030314\n",
      "Epoch 4799, Loss: 1.9021320343017578, Final Batch Loss: 0.4677838981151581\n",
      "Epoch 4800, Loss: 1.726443737745285, Final Batch Loss: 0.3039904236793518\n",
      "Epoch 4801, Loss: 1.5600605607032776, Final Batch Loss: 0.12486636638641357\n",
      "Epoch 4802, Loss: 1.451608985661096, Final Batch Loss: 1.6689286894688848e-06\n",
      "Epoch 4803, Loss: 1.5093607306480408, Final Batch Loss: 0.08080250024795532\n",
      "Epoch 4804, Loss: 1.8100617229938507, Final Batch Loss: 0.3094213008880615\n",
      "Epoch 4805, Loss: 2.0872869789600372, Final Batch Loss: 0.5952084064483643\n",
      "Epoch 4806, Loss: 3.100891590118408, Final Batch Loss: 1.6638879776000977\n",
      "Epoch 4807, Loss: 2.242292046546936, Final Batch Loss: 0.8386244177818298\n",
      "Epoch 4808, Loss: 2.691035509109497, Final Batch Loss: 1.2920234203338623\n",
      "Epoch 4809, Loss: 2.5855491757392883, Final Batch Loss: 1.1976615190505981\n",
      "Epoch 4810, Loss: 1.5296319583430886, Final Batch Loss: 0.01271392498165369\n",
      "Epoch 4811, Loss: 1.451724972575903, Final Batch Loss: 0.03140931949019432\n",
      "Epoch 4812, Loss: 1.344799585203873, Final Batch Loss: 0.00032431588624604046\n",
      "Epoch 4813, Loss: 1.6320616453886032, Final Batch Loss: 0.09884057939052582\n",
      "Epoch 4814, Loss: 1.3938627219758928, Final Batch Loss: 0.0013824678026139736\n",
      "Epoch 4815, Loss: 1.3960356356110424, Final Batch Loss: 0.0006987990345805883\n",
      "Epoch 4816, Loss: 1.8730265498161316, Final Batch Loss: 0.4688890874385834\n",
      "Epoch 4817, Loss: 1.3812831507530063, Final Batch Loss: 0.0024336741771548986\n",
      "Epoch 4818, Loss: 3.2843947410583496, Final Batch Loss: 1.886591911315918\n",
      "Epoch 4819, Loss: 2.267146050930023, Final Batch Loss: 0.8693458437919617\n",
      "Epoch 4820, Loss: 2.230693966150284, Final Batch Loss: 0.773690938949585\n",
      "Epoch 4821, Loss: 1.3993444992229342, Final Batch Loss: 0.0022652698680758476\n",
      "Epoch 4822, Loss: 1.410153299556896, Final Batch Loss: 5.125986263010418e-06\n",
      "Epoch 4823, Loss: 1.4813061519525945, Final Batch Loss: 0.006468312349170446\n",
      "Epoch 4824, Loss: 1.67134490609169, Final Batch Loss: 0.2873039245605469\n",
      "Epoch 4825, Loss: 1.3973700050264597, Final Batch Loss: 0.0016039852052927017\n",
      "Epoch 4826, Loss: 2.1568515300750732, Final Batch Loss: 0.665503740310669\n",
      "Epoch 4827, Loss: 1.8089928030967712, Final Batch Loss: 0.41016194224357605\n",
      "Epoch 4828, Loss: 1.7718855440616608, Final Batch Loss: 0.38691627979278564\n",
      "Epoch 4829, Loss: 2.8407327830791473, Final Batch Loss: 1.3820395469665527\n",
      "Epoch 4830, Loss: 3.0532360672950745, Final Batch Loss: 1.6528258323669434\n",
      "Epoch 4831, Loss: 1.5841293781995773, Final Batch Loss: 0.09742836654186249\n",
      "Epoch 4832, Loss: 1.4085347749642096, Final Batch Loss: 0.00020037073409184813\n",
      "Epoch 4833, Loss: 4.342285931110382, Final Batch Loss: 2.8982954025268555\n",
      "Epoch 4834, Loss: 1.3872604069874797, Final Batch Loss: 2.109982233378105e-05\n",
      "Epoch 4835, Loss: 1.567069910466671, Final Batch Loss: 0.10006626695394516\n",
      "Epoch 4836, Loss: 2.7799880504608154, Final Batch Loss: 1.2346371412277222\n",
      "Epoch 4837, Loss: 1.4729339150799206, Final Batch Loss: 7.950943836476654e-05\n",
      "Epoch 4838, Loss: 1.4770482699386775, Final Batch Loss: 0.003951124381273985\n",
      "Epoch 4839, Loss: 1.5488398547749966, Final Batch Loss: 0.0010474200826138258\n",
      "Epoch 4840, Loss: 2.95625838637352, Final Batch Loss: 1.4789739847183228\n",
      "Epoch 4841, Loss: 1.6005261540412619, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4842, Loss: 1.5172249467577785, Final Batch Loss: 0.003215858479961753\n",
      "Epoch 4843, Loss: 1.764726310968399, Final Batch Loss: 0.26872724294662476\n",
      "Epoch 4844, Loss: 2.5571479201316833, Final Batch Loss: 1.0301120281219482\n",
      "Epoch 4845, Loss: 1.4203725531697273, Final Batch Loss: 0.009370513260364532\n",
      "Epoch 4846, Loss: 1.7036892175674438, Final Batch Loss: 0.19867566227912903\n",
      "Epoch 4847, Loss: 1.530398263130337, Final Batch Loss: 0.006182237062603235\n",
      "Epoch 4848, Loss: 1.5137801794335246, Final Batch Loss: 0.008704575709998608\n",
      "Epoch 4849, Loss: 3.101623237133026, Final Batch Loss: 1.6588456630706787\n",
      "Epoch 4850, Loss: 1.4604303315281868, Final Batch Loss: 0.08108273893594742\n",
      "Epoch 4851, Loss: 3.640974670648575, Final Batch Loss: 2.1952593326568604\n",
      "Epoch 4852, Loss: 1.5673034824430943, Final Batch Loss: 0.04098433628678322\n",
      "Epoch 4853, Loss: 1.4482993874698877, Final Batch Loss: 0.004529217258095741\n",
      "Epoch 4854, Loss: 1.5436247363686562, Final Batch Loss: 0.11063487082719803\n",
      "Epoch 4855, Loss: 1.8564298748970032, Final Batch Loss: 0.4088766276836395\n",
      "Epoch 4856, Loss: 1.4718963420018554, Final Batch Loss: 0.006617299281060696\n",
      "Epoch 4857, Loss: 1.6499577164649963, Final Batch Loss: 0.12194931507110596\n",
      "Epoch 4858, Loss: 1.363910213811323, Final Batch Loss: 0.002973423106595874\n",
      "Epoch 4859, Loss: 1.4225575232994743, Final Batch Loss: 0.0005073452484793961\n",
      "Epoch 4860, Loss: 1.3867124842945486, Final Batch Loss: 0.003504090243950486\n",
      "Epoch 4861, Loss: 2.1142009794712067, Final Batch Loss: 0.6718154549598694\n",
      "Epoch 4862, Loss: 2.101369947195053, Final Batch Loss: 0.7115030288696289\n",
      "Epoch 4863, Loss: 1.3975668782368302, Final Batch Loss: 0.011721783317625523\n",
      "Epoch 4864, Loss: 1.333222764893435, Final Batch Loss: 0.0015512587269768119\n",
      "Epoch 4865, Loss: 1.4618385657668114, Final Batch Loss: 0.12136285752058029\n",
      "Epoch 4866, Loss: 2.3665399849414825, Final Batch Loss: 0.9396345615386963\n",
      "Epoch 4867, Loss: 1.4499248564243317, Final Batch Loss: 0.1368948221206665\n",
      "Epoch 4868, Loss: 2.028910666704178, Final Batch Loss: 0.6462461352348328\n",
      "Epoch 4869, Loss: 2.056867867708206, Final Batch Loss: 0.6660991311073303\n",
      "Epoch 4870, Loss: 1.3767668007731118, Final Batch Loss: 1.4662635294371285e-05\n",
      "Epoch 4871, Loss: 1.4525209069020093, Final Batch Loss: 6.794906312279636e-06\n",
      "Epoch 4872, Loss: 1.3910356146698177, Final Batch Loss: 5.876845170860179e-05\n",
      "Epoch 4873, Loss: 1.5258890241384506, Final Batch Loss: 0.046086207032203674\n",
      "Epoch 4874, Loss: 1.4339885171502829, Final Batch Loss: 0.02128869853913784\n",
      "Epoch 4875, Loss: 1.4179002045784728, Final Batch Loss: 1.2636104656849056e-05\n",
      "Epoch 4876, Loss: 2.2877717912197113, Final Batch Loss: 0.9244034290313721\n",
      "Epoch 4877, Loss: 1.4918333366513252, Final Batch Loss: 0.10867873579263687\n",
      "Epoch 4878, Loss: 2.04098778963089, Final Batch Loss: 0.6269386410713196\n",
      "Epoch 4879, Loss: 1.4944211235269904, Final Batch Loss: 0.008705048821866512\n",
      "Epoch 4880, Loss: 1.4334154680836946, Final Batch Loss: 0.0008150592911988497\n",
      "Epoch 4881, Loss: 1.4654553905129433, Final Batch Loss: 0.09968794137239456\n",
      "Epoch 4882, Loss: 1.4816313460469246, Final Batch Loss: 0.055083371698856354\n",
      "Epoch 4883, Loss: 1.445302665233612, Final Batch Loss: 0.0\n",
      "Epoch 4884, Loss: 1.4999196417629719, Final Batch Loss: 0.03985755518078804\n",
      "Epoch 4885, Loss: 2.2450603246688843, Final Batch Loss: 0.7906861901283264\n",
      "Epoch 4886, Loss: 1.9440898895263672, Final Batch Loss: 0.5553961396217346\n",
      "Epoch 4887, Loss: 1.4197151808766648, Final Batch Loss: 0.0010212211636826396\n",
      "Epoch 4888, Loss: 1.4092217460274696, Final Batch Loss: 0.043153829872608185\n",
      "Epoch 4889, Loss: 2.332704484462738, Final Batch Loss: 0.9618387818336487\n",
      "Epoch 4890, Loss: 2.061005711555481, Final Batch Loss: 0.7319475412368774\n",
      "Epoch 4891, Loss: 2.19089338183403, Final Batch Loss: 0.75264972448349\n",
      "Epoch 4892, Loss: 1.4429992139339376, Final Batch Loss: 1.1920928244535389e-07\n",
      "Epoch 4893, Loss: 1.4239155948161795, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4894, Loss: 3.374319553375244, Final Batch Loss: 1.9480946063995361\n",
      "Epoch 4895, Loss: 2.912700653076172, Final Batch Loss: 1.451730489730835\n",
      "Epoch 4896, Loss: 1.4085517227647983, Final Batch Loss: 5.960462772236497e-07\n",
      "Epoch 4897, Loss: 1.7913967669010162, Final Batch Loss: 0.31604939699172974\n",
      "Epoch 4898, Loss: 1.5422063991427422, Final Batch Loss: 0.08044760674238205\n",
      "Epoch 4899, Loss: 3.171647757291794, Final Batch Loss: 1.7200911045074463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4900, Loss: 1.5246775671839714, Final Batch Loss: 0.07367666810750961\n",
      "Epoch 4901, Loss: 1.4847206268459558, Final Batch Loss: 0.011229762807488441\n",
      "Epoch 4902, Loss: 1.5214804112911224, Final Batch Loss: 0.1637032926082611\n",
      "Epoch 4903, Loss: 2.907282531261444, Final Batch Loss: 1.4947311878204346\n",
      "Epoch 4904, Loss: 2.8861744105815887, Final Batch Loss: 1.3833611011505127\n",
      "Epoch 4905, Loss: 3.5488114058971405, Final Batch Loss: 2.0766184329986572\n",
      "Epoch 4906, Loss: 1.4905315963551402, Final Batch Loss: 0.004504295997321606\n",
      "Epoch 4907, Loss: 1.5096422149799764, Final Batch Loss: 0.0033004595898091793\n",
      "Epoch 4908, Loss: 1.456504476169357, Final Batch Loss: 0.0003084660565946251\n",
      "Epoch 4909, Loss: 1.4409967957526533, Final Batch Loss: 1.6689160474925302e-05\n",
      "Epoch 4910, Loss: 2.8047457337379456, Final Batch Loss: 1.4399470090866089\n",
      "Epoch 4911, Loss: 1.3971064604411367, Final Batch Loss: 0.00027581225731410086\n",
      "Epoch 4912, Loss: 1.4564647375946151, Final Batch Loss: 1.0847986231965479e-05\n",
      "Epoch 4913, Loss: 1.8107092082500458, Final Batch Loss: 0.35608792304992676\n",
      "Epoch 4914, Loss: 1.6312347948551178, Final Batch Loss: 0.22999146580696106\n",
      "Epoch 4915, Loss: 1.3769461512565329, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4916, Loss: 2.28757706284523, Final Batch Loss: 0.9261472225189209\n",
      "Epoch 4917, Loss: 2.69500195980072, Final Batch Loss: 1.276397943496704\n",
      "Epoch 4918, Loss: 3.5215263664722443, Final Batch Loss: 2.0972959995269775\n",
      "Epoch 4919, Loss: 2.135719448328018, Final Batch Loss: 0.7336221933364868\n",
      "Epoch 4920, Loss: 3.2889475226402283, Final Batch Loss: 1.8489785194396973\n",
      "Epoch 4921, Loss: 1.9387816488742828, Final Batch Loss: 0.4867458641529083\n",
      "Epoch 4922, Loss: 1.9504783153533936, Final Batch Loss: 0.530901312828064\n",
      "Epoch 4923, Loss: 2.4447880387306213, Final Batch Loss: 1.00063955783844\n",
      "Epoch 4924, Loss: 1.666906751692295, Final Batch Loss: 0.10957977920770645\n",
      "Epoch 4925, Loss: 2.068542182445526, Final Batch Loss: 0.462955504655838\n",
      "Epoch 4926, Loss: 1.9562144577503204, Final Batch Loss: 0.46824249625205994\n",
      "Epoch 4927, Loss: 1.546796619892092, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4928, Loss: 1.8155760169029236, Final Batch Loss: 0.3436208665370941\n",
      "Epoch 4929, Loss: 1.4203171795234084, Final Batch Loss: 0.006646431051194668\n",
      "Epoch 4930, Loss: 1.7425671219825745, Final Batch Loss: 0.28701159358024597\n",
      "Epoch 4931, Loss: 3.309704214334488, Final Batch Loss: 1.9326057434082031\n",
      "Epoch 4932, Loss: 1.6376477517187595, Final Batch Loss: 0.03983304277062416\n",
      "Epoch 4933, Loss: 2.6897255182266235, Final Batch Loss: 1.0565104484558105\n",
      "Epoch 4934, Loss: 1.6368743032217026, Final Batch Loss: 0.030440881848335266\n",
      "Epoch 4935, Loss: 2.2764572203159332, Final Batch Loss: 0.7340468168258667\n",
      "Epoch 4936, Loss: 1.4952677427427261, Final Batch Loss: 0.00011038171214750037\n",
      "Epoch 4937, Loss: 1.8450253307819366, Final Batch Loss: 0.44829079508781433\n",
      "Epoch 4938, Loss: 1.463218979537487, Final Batch Loss: 0.019349627196788788\n",
      "Epoch 4939, Loss: 1.4439741941168904, Final Batch Loss: 0.003627982921898365\n",
      "Epoch 4940, Loss: 1.4814196228981018, Final Batch Loss: 0.04407787322998047\n",
      "Epoch 4941, Loss: 3.088410198688507, Final Batch Loss: 1.6490702629089355\n",
      "Epoch 4942, Loss: 1.4625931867049076, Final Batch Loss: 0.00028606137493625283\n",
      "Epoch 4943, Loss: 1.502350926399231, Final Batch Loss: 0.0\n",
      "Epoch 4944, Loss: 1.4320748635218479, Final Batch Loss: 0.00028606137493625283\n",
      "Epoch 4945, Loss: 1.3474032476369757, Final Batch Loss: 0.0001445904199499637\n",
      "Epoch 4946, Loss: 2.018087089061737, Final Batch Loss: 0.5654794573783875\n",
      "Epoch 4947, Loss: 1.4010772552137496, Final Batch Loss: 0.00017486473370809108\n",
      "Epoch 4948, Loss: 1.729655683040619, Final Batch Loss: 0.3612174689769745\n",
      "Epoch 4949, Loss: 1.4637386351823807, Final Batch Loss: 0.09313888847827911\n",
      "Epoch 4950, Loss: 1.4073882149532437, Final Batch Loss: 0.0012409137561917305\n",
      "Epoch 4951, Loss: 1.9543842375278473, Final Batch Loss: 0.5054992437362671\n",
      "Epoch 4952, Loss: 1.4274875917471945, Final Batch Loss: 0.0003156163729727268\n",
      "Epoch 4953, Loss: 2.5843614041805267, Final Batch Loss: 1.0993108749389648\n",
      "Epoch 4954, Loss: 1.6687244474887848, Final Batch Loss: 0.2609473764896393\n",
      "Epoch 4955, Loss: 1.5389819405972958, Final Batch Loss: 0.02063065394759178\n",
      "Epoch 4956, Loss: 2.726832389831543, Final Batch Loss: 1.367043137550354\n",
      "Epoch 4957, Loss: 1.529433161020279, Final Batch Loss: 0.11523517966270447\n",
      "Epoch 4958, Loss: 2.567250043153763, Final Batch Loss: 1.174630045890808\n",
      "Epoch 4959, Loss: 1.4843830280005932, Final Batch Loss: 0.05431894585490227\n",
      "Epoch 4960, Loss: 1.4118224329431541, Final Batch Loss: 0.0009191579301841557\n",
      "Epoch 4961, Loss: 1.4247608132427558, Final Batch Loss: 0.00036006642039865255\n",
      "Epoch 4962, Loss: 2.703440248966217, Final Batch Loss: 1.2418261766433716\n",
      "Epoch 4963, Loss: 2.4690402448177338, Final Batch Loss: 1.0210022926330566\n",
      "Epoch 4964, Loss: 1.5138867311179638, Final Batch Loss: 0.014020871371030807\n",
      "Epoch 4965, Loss: 2.8906567692756653, Final Batch Loss: 1.3600125312805176\n",
      "Epoch 4966, Loss: 1.4755865900078788, Final Batch Loss: 0.0007759897271171212\n",
      "Epoch 4967, Loss: 2.199275881052017, Final Batch Loss: 0.808222234249115\n",
      "Epoch 4968, Loss: 1.7900018393993378, Final Batch Loss: 0.27469536662101746\n",
      "Epoch 4969, Loss: 2.8524048030376434, Final Batch Loss: 1.4403762817382812\n",
      "Epoch 4970, Loss: 1.5070506609481527, Final Batch Loss: 6.758938252460212e-05\n",
      "Epoch 4971, Loss: 1.9551686644554138, Final Batch Loss: 0.5948099493980408\n",
      "Epoch 4972, Loss: 2.996942460536957, Final Batch Loss: 1.5960211753845215\n",
      "Epoch 4973, Loss: 1.9493172764778137, Final Batch Loss: 0.548088550567627\n",
      "Epoch 4974, Loss: 1.5126581601798534, Final Batch Loss: 0.009216856211423874\n",
      "Epoch 4975, Loss: 1.4595086360350251, Final Batch Loss: 0.0027686143293976784\n",
      "Epoch 4976, Loss: 1.5275022005662322, Final Batch Loss: 0.003563365899026394\n",
      "Epoch 4977, Loss: 4.266447603702545, Final Batch Loss: 2.689082622528076\n",
      "Epoch 4978, Loss: 2.0096200704574585, Final Batch Loss: 0.5888333320617676\n",
      "Epoch 4979, Loss: 1.5913964509936704, Final Batch Loss: 2.3841830625315197e-06\n",
      "Epoch 4980, Loss: 1.415000787237659, Final Batch Loss: 0.002394905546680093\n",
      "Epoch 4981, Loss: 1.3983322083940948, Final Batch Loss: 1.311301275563892e-06\n",
      "Epoch 4982, Loss: 1.4572870392003097, Final Batch Loss: 0.00026055757189169526\n",
      "Epoch 4983, Loss: 2.892445743083954, Final Batch Loss: 1.4262986183166504\n",
      "Epoch 4984, Loss: 2.7785021662712097, Final Batch Loss: 1.3217211961746216\n",
      "Epoch 4985, Loss: 1.3461044512223452, Final Batch Loss: 0.0009043894242495298\n",
      "Epoch 4986, Loss: 1.510930873453617, Final Batch Loss: 0.09018496423959732\n",
      "Epoch 4987, Loss: 1.5750518403947353, Final Batch Loss: 0.05968823656439781\n",
      "Epoch 4988, Loss: 1.8700641095638275, Final Batch Loss: 0.27986517548561096\n",
      "Epoch 4989, Loss: 2.769713521003723, Final Batch Loss: 1.3712043762207031\n",
      "Epoch 4990, Loss: 1.4441881477723655, Final Batch Loss: 4.6491513785440475e-06\n",
      "Epoch 4991, Loss: 4.035254746675491, Final Batch Loss: 2.553323268890381\n",
      "Epoch 4992, Loss: 1.4535856200673152, Final Batch Loss: 0.0002623452164698392\n",
      "Epoch 4993, Loss: 1.4918187664588913, Final Batch Loss: 0.00019596086349338293\n",
      "Epoch 4994, Loss: 1.5678163435659371, Final Batch Loss: 0.00025733973598107696\n",
      "Epoch 4995, Loss: 1.911670207977295, Final Batch Loss: 0.40492478013038635\n",
      "Epoch 4996, Loss: 1.6437573730945587, Final Batch Loss: 0.07345947623252869\n",
      "Epoch 4997, Loss: 1.4656139600556344, Final Batch Loss: 0.003724663285538554\n",
      "Epoch 4998, Loss: 1.5601336658000662, Final Batch Loss: 2.3841855067985307e-07\n",
      "Epoch 4999, Loss: 1.5604493017344794, Final Batch Loss: 3.0397906812140718e-05\n",
      "Epoch 5000, Loss: 1.6589578986167908, Final Batch Loss: 0.15194430947303772\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  1  3]\n",
      " [ 0 33  0  6  0  0]\n",
      " [ 0  0 21  5  0  1]\n",
      " [ 0  0  0 32  0  0]\n",
      " [ 5  5  0  0 10  2]\n",
      " [ 0  0  0  1  0 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84375   0.87097   0.85714        31\n",
      "           1    0.86842   0.84615   0.85714        39\n",
      "           2    1.00000   0.77778   0.87500        27\n",
      "           3    0.72727   1.00000   0.84211        32\n",
      "           4    0.90909   0.45455   0.60606        22\n",
      "           5    0.85714   0.97297   0.91139        37\n",
      "\n",
      "    accuracy                        0.84574       188\n",
      "   macro avg    0.86761   0.82040   0.82481       188\n",
      "weighted avg    0.86176   0.84574   0.83844       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0]\n",
      " [ 0 32  0  0  0  0]\n",
      " [ 0  0 30  0  0  8]\n",
      " [ 0  0  0 30  0  0]\n",
      " [17  0  0  0  0  7]\n",
      " [ 0  0  0  0  0 37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.61364   1.00000   0.76056        27\n",
      "           1    1.00000   1.00000   1.00000        32\n",
      "           2    1.00000   0.78947   0.88235        38\n",
      "           3    1.00000   1.00000   1.00000        30\n",
      "           4    0.00000   0.00000   0.00000        24\n",
      "           5    0.71154   1.00000   0.83146        37\n",
      "\n",
      "    accuracy                        0.82979       188\n",
      "   macro avg    0.72086   0.79825   0.74573       188\n",
      "weighted avg    0.76008   0.82979   0.78100       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkimr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hkimr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hkimr\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
