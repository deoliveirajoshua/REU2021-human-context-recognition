{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.333291292190552, Final Batch Loss: 2.167613983154297\n",
      "Epoch 2, Loss: 4.308588266372681, Final Batch Loss: 2.1522305011749268\n",
      "Epoch 3, Loss: 4.277683973312378, Final Batch Loss: 2.1284339427948\n",
      "Epoch 4, Loss: 4.264641284942627, Final Batch Loss: 2.1299753189086914\n",
      "Epoch 5, Loss: 4.255535840988159, Final Batch Loss: 2.125379800796509\n",
      "Epoch 6, Loss: 4.226950645446777, Final Batch Loss: 2.109034538269043\n",
      "Epoch 7, Loss: 4.222549676895142, Final Batch Loss: 2.113011598587036\n",
      "Epoch 8, Loss: 4.182394027709961, Final Batch Loss: 2.076690912246704\n",
      "Epoch 9, Loss: 4.165081739425659, Final Batch Loss: 2.074948787689209\n",
      "Epoch 10, Loss: 4.13722562789917, Final Batch Loss: 2.058183193206787\n",
      "Epoch 11, Loss: 4.116027593612671, Final Batch Loss: 2.0543360710144043\n",
      "Epoch 12, Loss: 4.081467866897583, Final Batch Loss: 2.0333056449890137\n",
      "Epoch 13, Loss: 4.04861855506897, Final Batch Loss: 2.009908437728882\n",
      "Epoch 14, Loss: 4.001461148262024, Final Batch Loss: 1.9894887208938599\n",
      "Epoch 15, Loss: 3.9619065523147583, Final Batch Loss: 1.967530369758606\n",
      "Epoch 16, Loss: 3.9034067392349243, Final Batch Loss: 1.9316121339797974\n",
      "Epoch 17, Loss: 3.843980550765991, Final Batch Loss: 1.921707272529602\n",
      "Epoch 18, Loss: 3.78391695022583, Final Batch Loss: 1.8830244541168213\n",
      "Epoch 19, Loss: 3.703835129737854, Final Batch Loss: 1.8402091264724731\n",
      "Epoch 20, Loss: 3.610477328300476, Final Batch Loss: 1.7785283327102661\n",
      "Epoch 21, Loss: 3.508025050163269, Final Batch Loss: 1.7146128416061401\n",
      "Epoch 22, Loss: 3.397933602333069, Final Batch Loss: 1.7074497938156128\n",
      "Epoch 23, Loss: 3.2212746143341064, Final Batch Loss: 1.5344758033752441\n",
      "Epoch 24, Loss: 3.1607080698013306, Final Batch Loss: 1.5786106586456299\n",
      "Epoch 25, Loss: 3.058659076690674, Final Batch Loss: 1.5335227251052856\n",
      "Epoch 26, Loss: 2.8510974645614624, Final Batch Loss: 1.4396270513534546\n",
      "Epoch 27, Loss: 2.7235779762268066, Final Batch Loss: 1.3432121276855469\n",
      "Epoch 28, Loss: 2.638468623161316, Final Batch Loss: 1.2968790531158447\n",
      "Epoch 29, Loss: 2.557869076728821, Final Batch Loss: 1.3366600275039673\n",
      "Epoch 30, Loss: 2.4041653871536255, Final Batch Loss: 1.2568939924240112\n",
      "Epoch 31, Loss: 2.26059091091156, Final Batch Loss: 1.1167711019515991\n",
      "Epoch 32, Loss: 2.1151888370513916, Final Batch Loss: 1.0223674774169922\n",
      "Epoch 33, Loss: 2.131159245967865, Final Batch Loss: 1.1464414596557617\n",
      "Epoch 34, Loss: 1.9546125531196594, Final Batch Loss: 0.9515231251716614\n",
      "Epoch 35, Loss: 1.821945607662201, Final Batch Loss: 0.860985517501831\n",
      "Epoch 36, Loss: 1.8456535935401917, Final Batch Loss: 0.9259085059165955\n",
      "Epoch 37, Loss: 1.790485441684723, Final Batch Loss: 0.9142468571662903\n",
      "Epoch 38, Loss: 1.6886669397354126, Final Batch Loss: 0.8978316783905029\n",
      "Epoch 39, Loss: 1.6208234429359436, Final Batch Loss: 0.8314666748046875\n",
      "Epoch 40, Loss: 1.5037168860435486, Final Batch Loss: 0.7340986132621765\n",
      "Epoch 41, Loss: 1.4794291853904724, Final Batch Loss: 0.7423427700996399\n",
      "Epoch 42, Loss: 1.407785952091217, Final Batch Loss: 0.6934435963630676\n",
      "Epoch 43, Loss: 1.3442233204841614, Final Batch Loss: 0.671187698841095\n",
      "Epoch 44, Loss: 1.3149626851081848, Final Batch Loss: 0.6378365159034729\n",
      "Epoch 45, Loss: 1.2971895337104797, Final Batch Loss: 0.6664841175079346\n",
      "Epoch 46, Loss: 1.255741536617279, Final Batch Loss: 0.6441880464553833\n",
      "Epoch 47, Loss: 1.2266876101493835, Final Batch Loss: 0.6258572340011597\n",
      "Epoch 48, Loss: 1.2313709259033203, Final Batch Loss: 0.6123354434967041\n",
      "Epoch 49, Loss: 1.2090062499046326, Final Batch Loss: 0.5940001010894775\n",
      "Epoch 50, Loss: 1.1605289578437805, Final Batch Loss: 0.564123809337616\n",
      "Epoch 51, Loss: 1.186700463294983, Final Batch Loss: 0.6170146465301514\n",
      "Epoch 52, Loss: 1.1349058747291565, Final Batch Loss: 0.537783145904541\n",
      "Epoch 53, Loss: 1.0528225302696228, Final Batch Loss: 0.5017443299293518\n",
      "Epoch 54, Loss: 1.1427525877952576, Final Batch Loss: 0.5586978197097778\n",
      "Epoch 55, Loss: 1.0890962481498718, Final Batch Loss: 0.5780647993087769\n",
      "Epoch 56, Loss: 1.0473685264587402, Final Batch Loss: 0.5051622986793518\n",
      "Epoch 57, Loss: 0.9469306170940399, Final Batch Loss: 0.41645631194114685\n",
      "Epoch 58, Loss: 1.0146157145500183, Final Batch Loss: 0.47545456886291504\n",
      "Epoch 59, Loss: 1.02213054895401, Final Batch Loss: 0.5172328948974609\n",
      "Epoch 60, Loss: 1.0294561982154846, Final Batch Loss: 0.5024974942207336\n",
      "Epoch 61, Loss: 0.998457133769989, Final Batch Loss: 0.5126911997795105\n",
      "Epoch 62, Loss: 0.9492694437503815, Final Batch Loss: 0.4292236864566803\n",
      "Epoch 63, Loss: 1.0097868144512177, Final Batch Loss: 0.49576815962791443\n",
      "Epoch 64, Loss: 0.9142885208129883, Final Batch Loss: 0.4417688250541687\n",
      "Epoch 65, Loss: 0.9100776016712189, Final Batch Loss: 0.4455432593822479\n",
      "Epoch 66, Loss: 0.8927052915096283, Final Batch Loss: 0.45090532302856445\n",
      "Epoch 67, Loss: 0.9097634255886078, Final Batch Loss: 0.4782693684101105\n",
      "Epoch 68, Loss: 0.8593706786632538, Final Batch Loss: 0.3607572019100189\n",
      "Epoch 69, Loss: 0.8268321454524994, Final Batch Loss: 0.407776802778244\n",
      "Epoch 70, Loss: 0.8260948657989502, Final Batch Loss: 0.37563344836235046\n",
      "Epoch 71, Loss: 0.7945398986339569, Final Batch Loss: 0.4173716902732849\n",
      "Epoch 72, Loss: 0.7858661115169525, Final Batch Loss: 0.4402599036693573\n",
      "Epoch 73, Loss: 0.8029208481311798, Final Batch Loss: 0.4316498935222626\n",
      "Epoch 74, Loss: 0.7436177134513855, Final Batch Loss: 0.3440488874912262\n",
      "Epoch 75, Loss: 0.6885376870632172, Final Batch Loss: 0.3280099630355835\n",
      "Epoch 76, Loss: 0.6423447728157043, Final Batch Loss: 0.35176023840904236\n",
      "Epoch 77, Loss: 0.7634475827217102, Final Batch Loss: 0.4108019471168518\n",
      "Epoch 78, Loss: 0.5855879485607147, Final Batch Loss: 0.2681163549423218\n",
      "Epoch 79, Loss: 0.7459149658679962, Final Batch Loss: 0.4069192707538605\n",
      "Epoch 80, Loss: 0.6357867419719696, Final Batch Loss: 0.3285561800003052\n",
      "Epoch 81, Loss: 0.6617195010185242, Final Batch Loss: 0.37150484323501587\n",
      "Epoch 82, Loss: 0.5434244871139526, Final Batch Loss: 0.26528751850128174\n",
      "Epoch 83, Loss: 0.5333625972270966, Final Batch Loss: 0.23358261585235596\n",
      "Epoch 84, Loss: 0.5848215222358704, Final Batch Loss: 0.3186122179031372\n",
      "Epoch 85, Loss: 0.45272424817085266, Final Batch Loss: 0.25115710496902466\n",
      "Epoch 86, Loss: 0.4958978146314621, Final Batch Loss: 0.22925947606563568\n",
      "Epoch 87, Loss: 0.4732026904821396, Final Batch Loss: 0.25797638297080994\n",
      "Epoch 88, Loss: 0.44409145414829254, Final Batch Loss: 0.2393101453781128\n",
      "Epoch 89, Loss: 0.4955936521291733, Final Batch Loss: 0.26414573192596436\n",
      "Epoch 90, Loss: 0.4217284172773361, Final Batch Loss: 0.20496489107608795\n",
      "Epoch 91, Loss: 0.4050731211900711, Final Batch Loss: 0.21492518484592438\n",
      "Epoch 92, Loss: 0.539596438407898, Final Batch Loss: 0.3072103261947632\n",
      "Epoch 93, Loss: 0.39992648363113403, Final Batch Loss: 0.1911926567554474\n",
      "Epoch 94, Loss: 0.4613973796367645, Final Batch Loss: 0.21657712757587433\n",
      "Epoch 95, Loss: 0.5515665709972382, Final Batch Loss: 0.2833757996559143\n",
      "Epoch 96, Loss: 0.3649165779352188, Final Batch Loss: 0.19379958510398865\n",
      "Epoch 97, Loss: 0.38417625427246094, Final Batch Loss: 0.1760246306657791\n",
      "Epoch 98, Loss: 0.44012320041656494, Final Batch Loss: 0.2389461249113083\n",
      "Epoch 99, Loss: 0.3595229983329773, Final Batch Loss: 0.1846943497657776\n",
      "Epoch 100, Loss: 0.4451707899570465, Final Batch Loss: 0.20629683136940002\n",
      "Epoch 101, Loss: 0.3677549511194229, Final Batch Loss: 0.17089414596557617\n",
      "Epoch 102, Loss: 0.35087481141090393, Final Batch Loss: 0.16331316530704498\n",
      "Epoch 103, Loss: 0.3663247376680374, Final Batch Loss: 0.1742430180311203\n",
      "Epoch 104, Loss: 0.27504434436559677, Final Batch Loss: 0.1076774075627327\n",
      "Epoch 105, Loss: 0.374907523393631, Final Batch Loss: 0.18971313536167145\n",
      "Epoch 106, Loss: 0.31326763331890106, Final Batch Loss: 0.11595313251018524\n",
      "Epoch 107, Loss: 0.35094054043293, Final Batch Loss: 0.16236625611782074\n",
      "Epoch 108, Loss: 0.3681428134441376, Final Batch Loss: 0.18675833940505981\n",
      "Epoch 109, Loss: 0.3564661741256714, Final Batch Loss: 0.17603179812431335\n",
      "Epoch 110, Loss: 0.2952515631914139, Final Batch Loss: 0.1344747245311737\n",
      "Epoch 111, Loss: 0.33331260085105896, Final Batch Loss: 0.16462068259716034\n",
      "Epoch 112, Loss: 0.3034975230693817, Final Batch Loss: 0.14718760550022125\n",
      "Epoch 113, Loss: 0.45569901168346405, Final Batch Loss: 0.27670568227767944\n",
      "Epoch 114, Loss: 0.2920107915997505, Final Batch Loss: 0.12214767187833786\n",
      "Epoch 115, Loss: 0.2371201440691948, Final Batch Loss: 0.1094878539443016\n",
      "Epoch 116, Loss: 0.3500588536262512, Final Batch Loss: 0.18490204215049744\n",
      "Epoch 117, Loss: 0.33025307953357697, Final Batch Loss: 0.14466868340969086\n",
      "Epoch 118, Loss: 0.31904593110084534, Final Batch Loss: 0.18070009350776672\n",
      "Epoch 119, Loss: 0.32223308086395264, Final Batch Loss: 0.15794523060321808\n",
      "Epoch 120, Loss: 0.264546737074852, Final Batch Loss: 0.13010092079639435\n",
      "Epoch 121, Loss: 0.2865886390209198, Final Batch Loss: 0.1256868988275528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Loss: 0.2406589686870575, Final Batch Loss: 0.07569363713264465\n",
      "Epoch 123, Loss: 0.26931925117969513, Final Batch Loss: 0.13471201062202454\n",
      "Epoch 124, Loss: 0.28491320461034775, Final Batch Loss: 0.09531185775995255\n",
      "Epoch 125, Loss: 0.3103422671556473, Final Batch Loss: 0.1642555296421051\n",
      "Epoch 126, Loss: 0.2627699449658394, Final Batch Loss: 0.14287297427654266\n",
      "Epoch 127, Loss: 0.33081451058387756, Final Batch Loss: 0.20125417411327362\n",
      "Epoch 128, Loss: 0.2860408425331116, Final Batch Loss: 0.15226686000823975\n",
      "Epoch 129, Loss: 0.19398894906044006, Final Batch Loss: 0.10760249197483063\n",
      "Epoch 130, Loss: 0.23417022079229355, Final Batch Loss: 0.12244955450296402\n",
      "Epoch 131, Loss: 0.3242689073085785, Final Batch Loss: 0.19092242419719696\n",
      "Epoch 132, Loss: 0.280525840818882, Final Batch Loss: 0.10154589265584946\n",
      "Epoch 133, Loss: 0.22671276330947876, Final Batch Loss: 0.08551380038261414\n",
      "Epoch 134, Loss: 0.3120070546865463, Final Batch Loss: 0.15089145302772522\n",
      "Epoch 135, Loss: 0.21119440346956253, Final Batch Loss: 0.08669852465391159\n",
      "Epoch 136, Loss: 0.23477178812026978, Final Batch Loss: 0.1322498917579651\n",
      "Epoch 137, Loss: 0.1558559164404869, Final Batch Loss: 0.06442820280790329\n",
      "Epoch 138, Loss: 0.19499840587377548, Final Batch Loss: 0.10048939287662506\n",
      "Epoch 139, Loss: 0.2886236384510994, Final Batch Loss: 0.17366114258766174\n",
      "Epoch 140, Loss: 0.20109139382839203, Final Batch Loss: 0.11538363248109818\n",
      "Epoch 141, Loss: 0.276508592069149, Final Batch Loss: 0.08705473691225052\n",
      "Epoch 142, Loss: 0.3018079251050949, Final Batch Loss: 0.17227907478809357\n",
      "Epoch 143, Loss: 0.27700579166412354, Final Batch Loss: 0.13983431458473206\n",
      "Epoch 144, Loss: 0.22732242941856384, Final Batch Loss: 0.14712294936180115\n",
      "Epoch 145, Loss: 0.19480955600738525, Final Batch Loss: 0.08781600743532181\n",
      "Epoch 146, Loss: 0.13803938776254654, Final Batch Loss: 0.06259802728891373\n",
      "Epoch 147, Loss: 0.14745444804430008, Final Batch Loss: 0.05422539263963699\n",
      "Epoch 148, Loss: 0.23947583884000778, Final Batch Loss: 0.13239577412605286\n",
      "Epoch 149, Loss: 0.19513419270515442, Final Batch Loss: 0.0669633150100708\n",
      "Epoch 150, Loss: 0.1541467159986496, Final Batch Loss: 0.08194417506456375\n",
      "Epoch 151, Loss: 0.14089884236454964, Final Batch Loss: 0.034860264509916306\n",
      "Epoch 152, Loss: 0.2159973606467247, Final Batch Loss: 0.14007268846035004\n",
      "Epoch 153, Loss: 0.24431000649929047, Final Batch Loss: 0.15174026787281036\n",
      "Epoch 154, Loss: 0.1653236821293831, Final Batch Loss: 0.07000353932380676\n",
      "Epoch 155, Loss: 0.21558807790279388, Final Batch Loss: 0.13468565046787262\n",
      "Epoch 156, Loss: 0.18347540497779846, Final Batch Loss: 0.09019748121500015\n",
      "Epoch 157, Loss: 0.24285870790481567, Final Batch Loss: 0.09350883960723877\n",
      "Epoch 158, Loss: 0.20430873334407806, Final Batch Loss: 0.12943021953105927\n",
      "Epoch 159, Loss: 0.22908587753772736, Final Batch Loss: 0.11683472245931625\n",
      "Epoch 160, Loss: 0.17812661454081535, Final Batch Loss: 0.05991977080702782\n",
      "Epoch 161, Loss: 0.12336475402116776, Final Batch Loss: 0.04364464432001114\n",
      "Epoch 162, Loss: 0.18665450811386108, Final Batch Loss: 0.11084209382534027\n",
      "Epoch 163, Loss: 0.17857667803764343, Final Batch Loss: 0.11973687261343002\n",
      "Epoch 164, Loss: 0.15873756259679794, Final Batch Loss: 0.07556255906820297\n",
      "Epoch 165, Loss: 0.14552093297243118, Final Batch Loss: 0.04558631777763367\n",
      "Epoch 166, Loss: 0.13127508386969566, Final Batch Loss: 0.049869563430547714\n",
      "Epoch 167, Loss: 0.14544806629419327, Final Batch Loss: 0.09255391359329224\n",
      "Epoch 168, Loss: 0.21166780591011047, Final Batch Loss: 0.08568000793457031\n",
      "Epoch 169, Loss: 0.20410267263650894, Final Batch Loss: 0.11227497458457947\n",
      "Epoch 170, Loss: 0.13457700610160828, Final Batch Loss: 0.04673086106777191\n",
      "Epoch 171, Loss: 0.1514793410897255, Final Batch Loss: 0.06374791264533997\n",
      "Epoch 172, Loss: 0.17053882777690887, Final Batch Loss: 0.10479152947664261\n",
      "Epoch 173, Loss: 0.20217694342136383, Final Batch Loss: 0.11360970139503479\n",
      "Epoch 174, Loss: 0.0931758601218462, Final Batch Loss: 0.025437453761696815\n",
      "Epoch 175, Loss: 0.18709442764520645, Final Batch Loss: 0.11626819521188736\n",
      "Epoch 176, Loss: 0.11073504015803337, Final Batch Loss: 0.04538251832127571\n",
      "Epoch 177, Loss: 0.17826274037361145, Final Batch Loss: 0.102590411901474\n",
      "Epoch 178, Loss: 0.1333962008357048, Final Batch Loss: 0.04910539090633392\n",
      "Epoch 179, Loss: 0.12467187270522118, Final Batch Loss: 0.03716829791665077\n",
      "Epoch 180, Loss: 0.17537565529346466, Final Batch Loss: 0.06812403351068497\n",
      "Epoch 181, Loss: 0.12085024267435074, Final Batch Loss: 0.0678333267569542\n",
      "Epoch 182, Loss: 0.1334000825881958, Final Batch Loss: 0.07943124324083328\n",
      "Epoch 183, Loss: 0.15068551152944565, Final Batch Loss: 0.06874077767133713\n",
      "Epoch 184, Loss: 0.17270567268133163, Final Batch Loss: 0.09079515933990479\n",
      "Epoch 185, Loss: 0.13097622990608215, Final Batch Loss: 0.07005877047777176\n",
      "Epoch 186, Loss: 0.12379501014947891, Final Batch Loss: 0.08302898705005646\n",
      "Epoch 187, Loss: 0.15235675126314163, Final Batch Loss: 0.08664289861917496\n",
      "Epoch 188, Loss: 0.10244352743029594, Final Batch Loss: 0.045053936541080475\n",
      "Epoch 189, Loss: 0.0975070558488369, Final Batch Loss: 0.05015619099140167\n",
      "Epoch 190, Loss: 0.19645314663648605, Final Batch Loss: 0.11905115842819214\n",
      "Epoch 191, Loss: 0.2740336284041405, Final Batch Loss: 0.2020563781261444\n",
      "Epoch 192, Loss: 0.15574583411216736, Final Batch Loss: 0.06792809069156647\n",
      "Epoch 193, Loss: 0.21086379140615463, Final Batch Loss: 0.11485008895397186\n",
      "Epoch 194, Loss: 0.12583619356155396, Final Batch Loss: 0.04659843444824219\n",
      "Epoch 195, Loss: 0.07904761657118797, Final Batch Loss: 0.0233650840818882\n",
      "Epoch 196, Loss: 0.14585936814546585, Final Batch Loss: 0.07264727354049683\n",
      "Epoch 197, Loss: 0.16401535272598267, Final Batch Loss: 0.08220416307449341\n",
      "Epoch 198, Loss: 0.18114206194877625, Final Batch Loss: 0.10027097165584564\n",
      "Epoch 199, Loss: 0.11565859615802765, Final Batch Loss: 0.061713166534900665\n",
      "Epoch 200, Loss: 0.11357124336063862, Final Batch Loss: 0.02734527923166752\n",
      "Epoch 201, Loss: 0.13929706066846848, Final Batch Loss: 0.0759265273809433\n",
      "Epoch 202, Loss: 0.1292729191482067, Final Batch Loss: 0.08909309655427933\n",
      "Epoch 203, Loss: 0.1309216059744358, Final Batch Loss: 0.04046090319752693\n",
      "Epoch 204, Loss: 0.08314018696546555, Final Batch Loss: 0.03204650804400444\n",
      "Epoch 205, Loss: 0.1566740907728672, Final Batch Loss: 0.10542549937963486\n",
      "Epoch 206, Loss: 0.06945336796343327, Final Batch Loss: 0.04178498685359955\n",
      "Epoch 207, Loss: 0.1969912350177765, Final Batch Loss: 0.14192266762256622\n",
      "Epoch 208, Loss: 0.12490133196115494, Final Batch Loss: 0.04392506927251816\n",
      "Epoch 209, Loss: 0.16093023121356964, Final Batch Loss: 0.06792807579040527\n",
      "Epoch 210, Loss: 0.10628417134284973, Final Batch Loss: 0.05611497908830643\n",
      "Epoch 211, Loss: 0.1566261164844036, Final Batch Loss: 0.1102302148938179\n",
      "Epoch 212, Loss: 0.10172531753778458, Final Batch Loss: 0.05857580900192261\n",
      "Epoch 213, Loss: 0.11075865104794502, Final Batch Loss: 0.05386287346482277\n",
      "Epoch 214, Loss: 0.12165771424770355, Final Batch Loss: 0.05856496840715408\n",
      "Epoch 215, Loss: 0.06965170986950397, Final Batch Loss: 0.045128386467695236\n",
      "Epoch 216, Loss: 0.10328774154186249, Final Batch Loss: 0.027916014194488525\n",
      "Epoch 217, Loss: 0.060664234682917595, Final Batch Loss: 0.022223738953471184\n",
      "Epoch 218, Loss: 0.12908532842993736, Final Batch Loss: 0.04894671216607094\n",
      "Epoch 219, Loss: 0.08836728148162365, Final Batch Loss: 0.029663747176527977\n",
      "Epoch 220, Loss: 0.11205381155014038, Final Batch Loss: 0.05274469777941704\n",
      "Epoch 221, Loss: 0.1355961114168167, Final Batch Loss: 0.08955956995487213\n",
      "Epoch 222, Loss: 0.11754729971289635, Final Batch Loss: 0.04704863950610161\n",
      "Epoch 223, Loss: 0.0986424945294857, Final Batch Loss: 0.023987319320440292\n",
      "Epoch 224, Loss: 0.10240648686885834, Final Batch Loss: 0.04758001118898392\n",
      "Epoch 225, Loss: 0.11163410544395447, Final Batch Loss: 0.06549031287431717\n",
      "Epoch 226, Loss: 0.08349729515612125, Final Batch Loss: 0.022752298042178154\n",
      "Epoch 227, Loss: 0.10947256162762642, Final Batch Loss: 0.050916045904159546\n",
      "Epoch 228, Loss: 0.1181723140180111, Final Batch Loss: 0.07516239583492279\n",
      "Epoch 229, Loss: 0.11882245726883411, Final Batch Loss: 0.09260693937540054\n",
      "Epoch 230, Loss: 0.07300257869064808, Final Batch Loss: 0.04352714866399765\n",
      "Epoch 231, Loss: 0.11060123518109322, Final Batch Loss: 0.04029516503214836\n",
      "Epoch 232, Loss: 0.07969343103468418, Final Batch Loss: 0.0298768337816\n",
      "Epoch 233, Loss: 0.11455396562814713, Final Batch Loss: 0.0564231276512146\n",
      "Epoch 234, Loss: 0.07672335207462311, Final Batch Loss: 0.03177863731980324\n",
      "Epoch 235, Loss: 0.09177419915795326, Final Batch Loss: 0.02694881334900856\n",
      "Epoch 236, Loss: 0.1233505979180336, Final Batch Loss: 0.07438620924949646\n",
      "Epoch 237, Loss: 0.07440375350415707, Final Batch Loss: 0.043196674436330795\n",
      "Epoch 238, Loss: 0.14551769942045212, Final Batch Loss: 0.08027096837759018\n",
      "Epoch 239, Loss: 0.12450835481286049, Final Batch Loss: 0.07353831082582474\n",
      "Epoch 240, Loss: 0.11660847812891006, Final Batch Loss: 0.04217516630887985\n",
      "Epoch 241, Loss: 0.11354542896151543, Final Batch Loss: 0.025507163256406784\n",
      "Epoch 242, Loss: 0.07970930356532335, Final Batch Loss: 0.014556501992046833\n",
      "Epoch 243, Loss: 0.06794454623013735, Final Batch Loss: 0.015326925553381443\n",
      "Epoch 244, Loss: 0.05885990336537361, Final Batch Loss: 0.016073841601610184\n",
      "Epoch 245, Loss: 0.06956913694739342, Final Batch Loss: 0.03607618063688278\n",
      "Epoch 246, Loss: 0.08029844984412193, Final Batch Loss: 0.03367891162633896\n",
      "Epoch 247, Loss: 0.0612504743039608, Final Batch Loss: 0.027215871959924698\n",
      "Epoch 248, Loss: 0.10502418130636215, Final Batch Loss: 0.057828061282634735\n",
      "Epoch 249, Loss: 0.07348494604229927, Final Batch Loss: 0.02809111773967743\n",
      "Epoch 250, Loss: 0.10636323690414429, Final Batch Loss: 0.04391747713088989\n",
      "Epoch 251, Loss: 0.08410155028104782, Final Batch Loss: 0.04211084544658661\n",
      "Epoch 252, Loss: 0.08884723484516144, Final Batch Loss: 0.045122962445020676\n",
      "Epoch 253, Loss: 0.07526024244725704, Final Batch Loss: 0.020356109365820885\n",
      "Epoch 254, Loss: 0.1449623629450798, Final Batch Loss: 0.1195245236158371\n",
      "Epoch 255, Loss: 0.1006544753909111, Final Batch Loss: 0.06471141427755356\n",
      "Epoch 256, Loss: 0.09740817546844482, Final Batch Loss: 0.045108478516340256\n",
      "Epoch 257, Loss: 0.060054974630475044, Final Batch Loss: 0.04051809757947922\n",
      "Epoch 258, Loss: 0.06256213784217834, Final Batch Loss: 0.018371619284152985\n",
      "Epoch 259, Loss: 0.09409506246447563, Final Batch Loss: 0.05508427321910858\n",
      "Epoch 260, Loss: 0.03539586719125509, Final Batch Loss: 0.012185574509203434\n",
      "Epoch 261, Loss: 0.05407143384218216, Final Batch Loss: 0.026240075007081032\n",
      "Epoch 262, Loss: 0.0488301906734705, Final Batch Loss: 0.017268510535359383\n",
      "Epoch 263, Loss: 0.11060351505875587, Final Batch Loss: 0.07100331038236618\n",
      "Epoch 264, Loss: 0.10372604057192802, Final Batch Loss: 0.04082503542304039\n",
      "Epoch 265, Loss: 0.07677056640386581, Final Batch Loss: 0.04157675430178642\n",
      "Epoch 266, Loss: 0.06251547113060951, Final Batch Loss: 0.026989039033651352\n",
      "Epoch 267, Loss: 0.052328672260046005, Final Batch Loss: 0.021783122792840004\n",
      "Epoch 268, Loss: 0.05532575957477093, Final Batch Loss: 0.02306983806192875\n",
      "Epoch 269, Loss: 0.056423963978886604, Final Batch Loss: 0.02303754724562168\n",
      "Epoch 270, Loss: 0.06937975995242596, Final Batch Loss: 0.028508605435490608\n",
      "Epoch 271, Loss: 0.05670973099768162, Final Batch Loss: 0.03316064551472664\n",
      "Epoch 272, Loss: 0.04769158270210028, Final Batch Loss: 0.013351655565202236\n",
      "Epoch 273, Loss: 0.09290284849703312, Final Batch Loss: 0.06638917326927185\n",
      "Epoch 274, Loss: 0.06580589525401592, Final Batch Loss: 0.015758713707327843\n",
      "Epoch 275, Loss: 0.0906413234770298, Final Batch Loss: 0.05485895648598671\n",
      "Epoch 276, Loss: 0.0751476101577282, Final Batch Loss: 0.034216396510601044\n",
      "Epoch 277, Loss: 0.07412130013108253, Final Batch Loss: 0.03852909058332443\n",
      "Epoch 278, Loss: 0.05877091363072395, Final Batch Loss: 0.027653705328702927\n",
      "Epoch 279, Loss: 0.05849310848861933, Final Batch Loss: 0.014462781138718128\n",
      "Epoch 280, Loss: 0.05159419775009155, Final Batch Loss: 0.026171734556555748\n",
      "Epoch 281, Loss: 0.031423269771039486, Final Batch Loss: 0.014591635204851627\n",
      "Epoch 282, Loss: 0.05077645741403103, Final Batch Loss: 0.023959780111908913\n",
      "Epoch 283, Loss: 0.0580481942743063, Final Batch Loss: 0.04239249974489212\n",
      "Epoch 284, Loss: 0.06460889801383018, Final Batch Loss: 0.02810008078813553\n",
      "Epoch 285, Loss: 0.13152460753917694, Final Batch Loss: 0.09277311712503433\n",
      "Epoch 286, Loss: 0.05851311795413494, Final Batch Loss: 0.029078371822834015\n",
      "Epoch 287, Loss: 0.04563853330910206, Final Batch Loss: 0.014030450955033302\n",
      "Epoch 288, Loss: 0.06662927009165287, Final Batch Loss: 0.045360714197158813\n",
      "Epoch 289, Loss: 0.12146372720599174, Final Batch Loss: 0.0851675420999527\n",
      "Epoch 290, Loss: 0.06639762409031391, Final Batch Loss: 0.04401592165231705\n",
      "Epoch 291, Loss: 0.08901154529303312, Final Batch Loss: 0.011311116628348827\n",
      "Epoch 292, Loss: 0.06744222342967987, Final Batch Loss: 0.034078989177942276\n",
      "Epoch 293, Loss: 0.06728617288172245, Final Batch Loss: 0.04951570928096771\n",
      "Epoch 294, Loss: 0.07166549004614353, Final Batch Loss: 0.05033523589372635\n",
      "Epoch 295, Loss: 0.053798346780240536, Final Batch Loss: 0.04000430926680565\n",
      "Epoch 296, Loss: 0.04427690990269184, Final Batch Loss: 0.013034747913479805\n",
      "Epoch 297, Loss: 0.05653104931116104, Final Batch Loss: 0.02237183228135109\n",
      "Epoch 298, Loss: 0.05742847919464111, Final Batch Loss: 0.014031335711479187\n",
      "Epoch 299, Loss: 0.04840581864118576, Final Batch Loss: 0.02417580969631672\n",
      "Epoch 300, Loss: 0.034951671957969666, Final Batch Loss: 0.01791047304868698\n",
      "Epoch 301, Loss: 0.04905165731906891, Final Batch Loss: 0.03434043005108833\n",
      "Epoch 302, Loss: 0.05284009128808975, Final Batch Loss: 0.02335689589381218\n",
      "Epoch 303, Loss: 0.06156940571963787, Final Batch Loss: 0.009795362129807472\n",
      "Epoch 304, Loss: 0.04588352143764496, Final Batch Loss: 0.018639571964740753\n",
      "Epoch 305, Loss: 0.06777114607393742, Final Batch Loss: 0.02314644120633602\n",
      "Epoch 306, Loss: 0.03519630990922451, Final Batch Loss: 0.02064785175025463\n",
      "Epoch 307, Loss: 0.06644412875175476, Final Batch Loss: 0.014920700341463089\n",
      "Epoch 308, Loss: 0.056232694536447525, Final Batch Loss: 0.01853349804878235\n",
      "Epoch 309, Loss: 0.03194108884781599, Final Batch Loss: 0.011826873756945133\n",
      "Epoch 310, Loss: 0.12487606704235077, Final Batch Loss: 0.08888169378042221\n",
      "Epoch 311, Loss: 0.04752717446535826, Final Batch Loss: 0.03763651102781296\n",
      "Epoch 312, Loss: 0.07278134115040302, Final Batch Loss: 0.04265870526432991\n",
      "Epoch 313, Loss: 0.07041629776358604, Final Batch Loss: 0.038410380482673645\n",
      "Epoch 314, Loss: 0.04361244849860668, Final Batch Loss: 0.016199853271245956\n",
      "Epoch 315, Loss: 0.06735324300825596, Final Batch Loss: 0.028362644836306572\n",
      "Epoch 316, Loss: 0.10452060773968697, Final Batch Loss: 0.0727110356092453\n",
      "Epoch 317, Loss: 0.04991118237376213, Final Batch Loss: 0.025625230744481087\n",
      "Epoch 318, Loss: 0.029896540567278862, Final Batch Loss: 0.011479075998067856\n",
      "Epoch 319, Loss: 0.06523365341126919, Final Batch Loss: 0.017057674005627632\n",
      "Epoch 320, Loss: 0.05852873995900154, Final Batch Loss: 0.02698254957795143\n",
      "Epoch 321, Loss: 0.05482007376849651, Final Batch Loss: 0.04298654571175575\n",
      "Epoch 322, Loss: 0.05446801707148552, Final Batch Loss: 0.034478992223739624\n",
      "Epoch 323, Loss: 0.08543619140982628, Final Batch Loss: 0.03786221146583557\n",
      "Epoch 324, Loss: 0.06959421560168266, Final Batch Loss: 0.01771721988916397\n",
      "Epoch 325, Loss: 0.06607040576636791, Final Batch Loss: 0.04589107260107994\n",
      "Epoch 326, Loss: 0.07511815242469311, Final Batch Loss: 0.050866469740867615\n",
      "Epoch 327, Loss: 0.05628037266433239, Final Batch Loss: 0.02179979346692562\n",
      "Epoch 328, Loss: 0.033270735293626785, Final Batch Loss: 0.022164564579725266\n",
      "Epoch 329, Loss: 0.08218069933354855, Final Batch Loss: 0.029696760699152946\n",
      "Epoch 330, Loss: 0.05689673684537411, Final Batch Loss: 0.01961696334183216\n",
      "Epoch 331, Loss: 0.035782162100076675, Final Batch Loss: 0.01646740920841694\n",
      "Epoch 332, Loss: 0.04205275513231754, Final Batch Loss: 0.02281246893107891\n",
      "Epoch 333, Loss: 0.09502464719116688, Final Batch Loss: 0.06583447009325027\n",
      "Epoch 334, Loss: 0.04831714369356632, Final Batch Loss: 0.02398412488400936\n",
      "Epoch 335, Loss: 0.06181147135794163, Final Batch Loss: 0.03472040966153145\n",
      "Epoch 336, Loss: 0.039651453495025635, Final Batch Loss: 0.02092079445719719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337, Loss: 0.04832051042467356, Final Batch Loss: 0.03589189052581787\n",
      "Epoch 338, Loss: 0.04030638560652733, Final Batch Loss: 0.030927009880542755\n",
      "Epoch 339, Loss: 0.035489261616021395, Final Batch Loss: 0.007008607033640146\n",
      "Epoch 340, Loss: 0.11890073399990797, Final Batch Loss: 0.10429489612579346\n",
      "Epoch 341, Loss: 0.06621458381414413, Final Batch Loss: 0.04466941952705383\n",
      "Epoch 342, Loss: 0.03475209977477789, Final Batch Loss: 0.014380685053765774\n",
      "Epoch 343, Loss: 0.042700973339378834, Final Batch Loss: 0.027369877323508263\n",
      "Epoch 344, Loss: 0.024778655730187893, Final Batch Loss: 0.013189023360610008\n",
      "Epoch 345, Loss: 0.07104440033435822, Final Batch Loss: 0.0317331925034523\n",
      "Epoch 346, Loss: 0.047229353338479996, Final Batch Loss: 0.037513215094804764\n",
      "Epoch 347, Loss: 0.07200734131038189, Final Batch Loss: 0.06311008334159851\n",
      "Epoch 348, Loss: 0.04247724637389183, Final Batch Loss: 0.008465040475130081\n",
      "Epoch 349, Loss: 0.048225236125290394, Final Batch Loss: 0.036333680152893066\n",
      "Epoch 350, Loss: 0.03616255987435579, Final Batch Loss: 0.01122788991779089\n",
      "Epoch 351, Loss: 0.028803981840610504, Final Batch Loss: 0.007911494001746178\n",
      "Epoch 352, Loss: 0.04017614107578993, Final Batch Loss: 0.014060554094612598\n",
      "Epoch 353, Loss: 0.09056498482823372, Final Batch Loss: 0.07895203679800034\n",
      "Epoch 354, Loss: 0.041613541543483734, Final Batch Loss: 0.022217238321900368\n",
      "Epoch 355, Loss: 0.035108812153339386, Final Batch Loss: 0.014071697369217873\n",
      "Epoch 356, Loss: 0.03561428189277649, Final Batch Loss: 0.01683201640844345\n",
      "Epoch 357, Loss: 0.04691499099135399, Final Batch Loss: 0.028325699269771576\n",
      "Epoch 358, Loss: 0.052111951634287834, Final Batch Loss: 0.032802704721689224\n",
      "Epoch 359, Loss: 0.08678879030048847, Final Batch Loss: 0.05616866424679756\n",
      "Epoch 360, Loss: 0.07821640186011791, Final Batch Loss: 0.050166115164756775\n",
      "Epoch 361, Loss: 0.07316496409475803, Final Batch Loss: 0.0567714124917984\n",
      "Epoch 362, Loss: 0.05997779965400696, Final Batch Loss: 0.04337566718459129\n",
      "Epoch 363, Loss: 0.014263528399169445, Final Batch Loss: 0.004880192689597607\n",
      "Epoch 364, Loss: 0.05249445512890816, Final Batch Loss: 0.03028864786028862\n",
      "Epoch 365, Loss: 0.026790257543325424, Final Batch Loss: 0.013086455874145031\n",
      "Epoch 366, Loss: 0.04604225605726242, Final Batch Loss: 0.010382000356912613\n",
      "Epoch 367, Loss: 0.030781909823417664, Final Batch Loss: 0.014497192576527596\n",
      "Epoch 368, Loss: 0.04128886014223099, Final Batch Loss: 0.023608552291989326\n",
      "Epoch 369, Loss: 0.0452855359762907, Final Batch Loss: 0.0233197882771492\n",
      "Epoch 370, Loss: 0.047061700373888016, Final Batch Loss: 0.014225710183382034\n",
      "Epoch 371, Loss: 0.058078939095139503, Final Batch Loss: 0.0045615676790475845\n",
      "Epoch 372, Loss: 0.03203234728425741, Final Batch Loss: 0.015502928756177425\n",
      "Epoch 373, Loss: 0.04236598405987024, Final Batch Loss: 0.012996134348213673\n",
      "Epoch 374, Loss: 0.037931240163743496, Final Batch Loss: 0.0117184454575181\n",
      "Epoch 375, Loss: 0.05664507672190666, Final Batch Loss: 0.02454552799463272\n",
      "Epoch 376, Loss: 0.024298865348100662, Final Batch Loss: 0.009732667356729507\n",
      "Epoch 377, Loss: 0.0758266169577837, Final Batch Loss: 0.06028539314866066\n",
      "Epoch 378, Loss: 0.05737217143177986, Final Batch Loss: 0.04743139445781708\n",
      "Epoch 379, Loss: 0.06123292073607445, Final Batch Loss: 0.04543657228350639\n",
      "Epoch 380, Loss: 0.036476410925388336, Final Batch Loss: 0.023535702377557755\n",
      "Epoch 381, Loss: 0.033406865783035755, Final Batch Loss: 0.020139658823609352\n",
      "Epoch 382, Loss: 0.023148635169491172, Final Batch Loss: 0.0033418217208236456\n",
      "Epoch 383, Loss: 0.06121576391160488, Final Batch Loss: 0.022476518526673317\n",
      "Epoch 384, Loss: 0.03686163015663624, Final Batch Loss: 0.014071265235543251\n",
      "Epoch 385, Loss: 0.089829221367836, Final Batch Loss: 0.04590003937482834\n",
      "Epoch 386, Loss: 0.022196953184902668, Final Batch Loss: 0.007715897634625435\n",
      "Epoch 387, Loss: 0.030258110025897622, Final Batch Loss: 0.0032889212016016245\n",
      "Epoch 388, Loss: 0.03855003137141466, Final Batch Loss: 0.014198088087141514\n",
      "Epoch 389, Loss: 0.03646768070757389, Final Batch Loss: 0.01591655984520912\n",
      "Epoch 390, Loss: 0.04250677116215229, Final Batch Loss: 0.011792033910751343\n",
      "Epoch 391, Loss: 0.026307327672839165, Final Batch Loss: 0.012483850121498108\n",
      "Epoch 392, Loss: 0.030961685813963413, Final Batch Loss: 0.00696899089962244\n",
      "Epoch 393, Loss: 0.047373094130307436, Final Batch Loss: 0.007571358699351549\n",
      "Epoch 394, Loss: 0.022073812782764435, Final Batch Loss: 0.009508411400020123\n",
      "Epoch 395, Loss: 0.02266781497746706, Final Batch Loss: 0.00824219174683094\n",
      "Epoch 396, Loss: 0.015349060762673616, Final Batch Loss: 0.004989696200937033\n",
      "Epoch 397, Loss: 0.04413014743477106, Final Batch Loss: 0.009463769383728504\n",
      "Epoch 398, Loss: 0.027123162988573313, Final Batch Loss: 0.0049676415510475636\n",
      "Epoch 399, Loss: 0.05533652380108833, Final Batch Loss: 0.022453267127275467\n",
      "Epoch 400, Loss: 0.022800684440881014, Final Batch Loss: 0.004297275561839342\n",
      "Epoch 401, Loss: 0.025036273524165154, Final Batch Loss: 0.016499927267432213\n",
      "Epoch 402, Loss: 0.0376621438190341, Final Batch Loss: 0.012644697912037373\n",
      "Epoch 403, Loss: 0.032004572451114655, Final Batch Loss: 0.00367044098675251\n",
      "Epoch 404, Loss: 0.021866774186491966, Final Batch Loss: 0.010214095935225487\n",
      "Epoch 405, Loss: 0.039295436814427376, Final Batch Loss: 0.017758339643478394\n",
      "Epoch 406, Loss: 0.06781886145472527, Final Batch Loss: 0.04424385353922844\n",
      "Epoch 407, Loss: 0.04065797198563814, Final Batch Loss: 0.00658851582556963\n",
      "Epoch 408, Loss: 0.020352832041680813, Final Batch Loss: 0.010512963868677616\n",
      "Epoch 409, Loss: 0.043699514120817184, Final Batch Loss: 0.028549520298838615\n",
      "Epoch 410, Loss: 0.023163907695561647, Final Batch Loss: 0.007460445631295443\n",
      "Epoch 411, Loss: 0.033245581202208996, Final Batch Loss: 0.012493294663727283\n",
      "Epoch 412, Loss: 0.06051153317093849, Final Batch Loss: 0.03439808264374733\n",
      "Epoch 413, Loss: 0.031182321719825268, Final Batch Loss: 0.01568259857594967\n",
      "Epoch 414, Loss: 0.04177853651344776, Final Batch Loss: 0.020641090348362923\n",
      "Epoch 415, Loss: 0.029675502330064774, Final Batch Loss: 0.011697797104716301\n",
      "Epoch 416, Loss: 0.03885850962251425, Final Batch Loss: 0.028624095022678375\n",
      "Epoch 417, Loss: 0.03401029855012894, Final Batch Loss: 0.013666801154613495\n",
      "Epoch 418, Loss: 0.036125482991337776, Final Batch Loss: 0.017723524942994118\n",
      "Epoch 419, Loss: 0.02054042648524046, Final Batch Loss: 0.013863610103726387\n",
      "Epoch 420, Loss: 0.03188353683799505, Final Batch Loss: 0.01267742644995451\n",
      "Epoch 421, Loss: 0.03689737431704998, Final Batch Loss: 0.008801424875855446\n",
      "Epoch 422, Loss: 0.012248679297044873, Final Batch Loss: 0.0033952260855585337\n",
      "Epoch 423, Loss: 0.04605577699840069, Final Batch Loss: 0.028695926070213318\n",
      "Epoch 424, Loss: 0.04360814020037651, Final Batch Loss: 0.009065166115760803\n",
      "Epoch 425, Loss: 0.016647498589009047, Final Batch Loss: 0.0035015190951526165\n",
      "Epoch 426, Loss: 0.014934366568922997, Final Batch Loss: 0.00980237778276205\n",
      "Epoch 427, Loss: 0.12012425810098648, Final Batch Loss: 0.08293434232473373\n",
      "Epoch 428, Loss: 0.07862047106027603, Final Batch Loss: 0.042269788682460785\n",
      "Epoch 429, Loss: 0.033418217208236456, Final Batch Loss: 0.0034320964477956295\n",
      "Epoch 430, Loss: 0.04372485540807247, Final Batch Loss: 0.027647048234939575\n",
      "Epoch 431, Loss: 0.017519603949040174, Final Batch Loss: 0.006669912952929735\n",
      "Epoch 432, Loss: 0.01687939651310444, Final Batch Loss: 0.0074682943522930145\n",
      "Epoch 433, Loss: 0.09016066789627075, Final Batch Loss: 0.07941631972789764\n",
      "Epoch 434, Loss: 0.03979411441832781, Final Batch Loss: 0.012677100487053394\n",
      "Epoch 435, Loss: 0.031965214759111404, Final Batch Loss: 0.006365055218338966\n",
      "Epoch 436, Loss: 0.016947508789598942, Final Batch Loss: 0.010112467221915722\n",
      "Epoch 437, Loss: 0.06506990781053901, Final Batch Loss: 0.06025594100356102\n",
      "Epoch 438, Loss: 0.022074764128774405, Final Batch Loss: 0.01641434244811535\n",
      "Epoch 439, Loss: 0.028279664926230907, Final Batch Loss: 0.01764269545674324\n",
      "Epoch 440, Loss: 0.04753601737320423, Final Batch Loss: 0.022823961451649666\n",
      "Epoch 441, Loss: 0.06333864480257034, Final Batch Loss: 0.04214486852288246\n",
      "Epoch 442, Loss: 0.018408472649753094, Final Batch Loss: 0.007630839012563229\n",
      "Epoch 443, Loss: 0.06160115450620651, Final Batch Loss: 0.028558187186717987\n",
      "Epoch 444, Loss: 0.039922676514834166, Final Batch Loss: 0.0027689109556376934\n",
      "Epoch 445, Loss: 0.033862858079373837, Final Batch Loss: 0.007344362325966358\n",
      "Epoch 446, Loss: 0.04800300765782595, Final Batch Loss: 0.013007731176912785\n",
      "Epoch 447, Loss: 0.028441203758120537, Final Batch Loss: 0.016145918518304825\n",
      "Epoch 448, Loss: 0.03385561425238848, Final Batch Loss: 0.01857607811689377\n",
      "Epoch 449, Loss: 0.019507617689669132, Final Batch Loss: 0.008312782272696495\n",
      "Epoch 450, Loss: 0.022635923698544502, Final Batch Loss: 0.0049207862466573715\n",
      "Epoch 451, Loss: 0.026009222492575645, Final Batch Loss: 0.012486981227993965\n",
      "Epoch 452, Loss: 0.036722817458212376, Final Batch Loss: 0.026581967249512672\n",
      "Epoch 453, Loss: 0.02267957478761673, Final Batch Loss: 0.012095888145267963\n",
      "Epoch 454, Loss: 0.03190366644412279, Final Batch Loss: 0.008320613764226437\n",
      "Epoch 455, Loss: 0.012048284523189068, Final Batch Loss: 0.006086769979447126\n",
      "Epoch 456, Loss: 0.023916613310575485, Final Batch Loss: 0.01780541241168976\n",
      "Epoch 457, Loss: 0.04647303558886051, Final Batch Loss: 0.03175767511129379\n",
      "Epoch 458, Loss: 0.022823886945843697, Final Batch Loss: 0.011412725783884525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459, Loss: 0.028125274926424026, Final Batch Loss: 0.01613292284309864\n",
      "Epoch 460, Loss: 0.04479090077802539, Final Batch Loss: 0.004983055870980024\n",
      "Epoch 461, Loss: 0.021457900293171406, Final Batch Loss: 0.009994057938456535\n",
      "Epoch 462, Loss: 0.041076477617025375, Final Batch Loss: 0.007944270968437195\n",
      "Epoch 463, Loss: 0.032219399232417345, Final Batch Loss: 0.007107865530997515\n",
      "Epoch 464, Loss: 0.025598183274269104, Final Batch Loss: 0.013415031135082245\n",
      "Epoch 465, Loss: 0.035136753693223, Final Batch Loss: 0.028441349044442177\n",
      "Epoch 466, Loss: 0.02886302920524031, Final Batch Loss: 0.0011399459326639771\n",
      "Epoch 467, Loss: 0.05177238862961531, Final Batch Loss: 0.04305552691221237\n",
      "Epoch 468, Loss: 0.02914080210030079, Final Batch Loss: 0.01451877225190401\n",
      "Epoch 469, Loss: 0.06385358422994614, Final Batch Loss: 0.02158432826399803\n",
      "Epoch 470, Loss: 0.015608992194756866, Final Batch Loss: 0.002555006882175803\n",
      "Epoch 471, Loss: 0.015188344288617373, Final Batch Loss: 0.004622821230441332\n",
      "Epoch 472, Loss: 0.017816860228776932, Final Batch Loss: 0.004542183130979538\n",
      "Epoch 473, Loss: 0.021896471735090017, Final Batch Loss: 0.014738303609192371\n",
      "Epoch 474, Loss: 0.03636325616389513, Final Batch Loss: 0.0306557584553957\n",
      "Epoch 475, Loss: 0.028041153214871883, Final Batch Loss: 0.010691781528294086\n",
      "Epoch 476, Loss: 0.04187281522899866, Final Batch Loss: 0.032415520399808884\n",
      "Epoch 477, Loss: 0.01082788105122745, Final Batch Loss: 0.0035247786436229944\n",
      "Epoch 478, Loss: 0.011717010289430618, Final Batch Loss: 0.005521409213542938\n",
      "Epoch 479, Loss: 0.010831770719960332, Final Batch Loss: 0.0028032187838107347\n",
      "Epoch 480, Loss: 0.01700178300961852, Final Batch Loss: 0.0103401904925704\n",
      "Epoch 481, Loss: 0.016336807515472174, Final Batch Loss: 0.002332999836653471\n",
      "Epoch 482, Loss: 0.02690199576318264, Final Batch Loss: 0.01820613443851471\n",
      "Epoch 483, Loss: 0.020770944887772202, Final Batch Loss: 0.0034023860935121775\n",
      "Epoch 484, Loss: 0.016002680640667677, Final Batch Loss: 0.010671635158360004\n",
      "Epoch 485, Loss: 0.017575536854565144, Final Batch Loss: 0.005571527406573296\n",
      "Epoch 486, Loss: 0.03323394572362304, Final Batch Loss: 0.029219716787338257\n",
      "Epoch 487, Loss: 0.01848756894469261, Final Batch Loss: 0.009759023785591125\n",
      "Epoch 488, Loss: 0.04101173020899296, Final Batch Loss: 0.023284005001187325\n",
      "Epoch 489, Loss: 0.008296094834804535, Final Batch Loss: 0.006064696703106165\n",
      "Epoch 490, Loss: 0.008664429653435946, Final Batch Loss: 0.004839474800974131\n",
      "Epoch 491, Loss: 0.038562631234526634, Final Batch Loss: 0.016381965950131416\n",
      "Epoch 492, Loss: 0.016780965495854616, Final Batch Loss: 0.00540779298171401\n",
      "Epoch 493, Loss: 0.034267013892531395, Final Batch Loss: 0.02746914140880108\n",
      "Epoch 494, Loss: 0.016525324434041977, Final Batch Loss: 0.009995688684284687\n",
      "Epoch 495, Loss: 0.026999300345778465, Final Batch Loss: 0.011178556829690933\n",
      "Epoch 496, Loss: 0.016107035567983985, Final Batch Loss: 0.0025651955511420965\n",
      "Epoch 497, Loss: 0.013755684718489647, Final Batch Loss: 0.0057778675109148026\n",
      "Epoch 498, Loss: 0.0443810960277915, Final Batch Loss: 0.03692932426929474\n",
      "Epoch 499, Loss: 0.05123085156083107, Final Batch Loss: 0.029628979042172432\n",
      "Epoch 500, Loss: 0.021909113973379135, Final Batch Loss: 0.011299435049295425\n",
      "Epoch 501, Loss: 0.022168796509504318, Final Batch Loss: 0.008397619239985943\n",
      "Epoch 502, Loss: 0.027543365256860852, Final Batch Loss: 0.002736122580245137\n",
      "Epoch 503, Loss: 0.015463748946785927, Final Batch Loss: 0.011262437328696251\n",
      "Epoch 504, Loss: 0.023130297660827637, Final Batch Loss: 0.00990909244865179\n",
      "Epoch 505, Loss: 0.01932897185906768, Final Batch Loss: 0.007620709482580423\n",
      "Epoch 506, Loss: 0.033313839696347713, Final Batch Loss: 0.015509461052715778\n",
      "Epoch 507, Loss: 0.08204774558544159, Final Batch Loss: 0.03927904739975929\n",
      "Epoch 508, Loss: 0.006115370546467602, Final Batch Loss: 0.0016866588266566396\n",
      "Epoch 509, Loss: 0.012622940819710493, Final Batch Loss: 0.004041309002786875\n",
      "Epoch 510, Loss: 0.01651435298845172, Final Batch Loss: 0.009868351742625237\n",
      "Epoch 511, Loss: 0.04769062530249357, Final Batch Loss: 0.03728269040584564\n",
      "Epoch 512, Loss: 0.011262435466051102, Final Batch Loss: 0.005301442462950945\n",
      "Epoch 513, Loss: 0.027505760779604316, Final Batch Loss: 0.0034597383346408606\n",
      "Epoch 514, Loss: 0.011066383216530085, Final Batch Loss: 0.004126251209527254\n",
      "Epoch 515, Loss: 0.08980037271976471, Final Batch Loss: 0.06499934196472168\n",
      "Epoch 516, Loss: 0.030334884766489267, Final Batch Loss: 0.007738696876913309\n",
      "Epoch 517, Loss: 0.008922685170546174, Final Batch Loss: 0.0024075729306787252\n",
      "Epoch 518, Loss: 0.022478321567177773, Final Batch Loss: 0.01448072586208582\n",
      "Epoch 519, Loss: 0.01856372645124793, Final Batch Loss: 0.014064289629459381\n",
      "Epoch 520, Loss: 0.046607473865151405, Final Batch Loss: 0.038374632596969604\n",
      "Epoch 521, Loss: 0.05500434339046478, Final Batch Loss: 0.0328744538128376\n",
      "Epoch 522, Loss: 0.04893758334219456, Final Batch Loss: 0.030908724293112755\n",
      "Epoch 523, Loss: 0.026656678412109613, Final Batch Loss: 0.020721925422549248\n",
      "Epoch 524, Loss: 0.026083990931510925, Final Batch Loss: 0.018725352361798286\n",
      "Epoch 525, Loss: 0.025333177763968706, Final Batch Loss: 0.020656537264585495\n",
      "Epoch 526, Loss: 0.01615359354764223, Final Batch Loss: 0.004229534417390823\n",
      "Epoch 527, Loss: 0.02264788094907999, Final Batch Loss: 0.005253857932984829\n",
      "Epoch 528, Loss: 0.0406710309907794, Final Batch Loss: 0.006466544233262539\n",
      "Epoch 529, Loss: 0.042581355199217796, Final Batch Loss: 0.007613839581608772\n",
      "Epoch 530, Loss: 0.02796495519578457, Final Batch Loss: 0.006261749193072319\n",
      "Epoch 531, Loss: 0.0103861796669662, Final Batch Loss: 0.0020657344721257687\n",
      "Epoch 532, Loss: 0.016645371448248625, Final Batch Loss: 0.009076331742107868\n",
      "Epoch 533, Loss: 0.024373685009777546, Final Batch Loss: 0.01803010143339634\n",
      "Epoch 534, Loss: 0.01120188320055604, Final Batch Loss: 0.003143980633467436\n",
      "Epoch 535, Loss: 0.04859744757413864, Final Batch Loss: 0.014253940433263779\n",
      "Epoch 536, Loss: 0.03248722373973578, Final Batch Loss: 0.0018431403441354632\n",
      "Epoch 537, Loss: 0.04182187654078007, Final Batch Loss: 0.035317178815603256\n",
      "Epoch 538, Loss: 0.013047647196799517, Final Batch Loss: 0.005609674844890833\n",
      "Epoch 539, Loss: 0.02129348274320364, Final Batch Loss: 0.008618406020104885\n",
      "Epoch 540, Loss: 0.013820126187056303, Final Batch Loss: 0.0067031001672148705\n",
      "Epoch 541, Loss: 0.04363152198493481, Final Batch Loss: 0.0187264084815979\n",
      "Epoch 542, Loss: 0.025394373573362827, Final Batch Loss: 0.020859643816947937\n",
      "Epoch 543, Loss: 0.011499851010739803, Final Batch Loss: 0.007617304567247629\n",
      "Epoch 544, Loss: 0.03323635086417198, Final Batch Loss: 0.016218598932027817\n",
      "Epoch 545, Loss: 0.01696140319108963, Final Batch Loss: 0.0053157443180680275\n",
      "Epoch 546, Loss: 0.015684325015172362, Final Batch Loss: 0.0037724196445196867\n",
      "Epoch 547, Loss: 0.012093860656023026, Final Batch Loss: 0.006538067478686571\n",
      "Epoch 548, Loss: 0.013607105938717723, Final Batch Loss: 0.0038534177001565695\n",
      "Epoch 549, Loss: 0.01265457971021533, Final Batch Loss: 0.004813164006918669\n",
      "Epoch 550, Loss: 0.03194179851561785, Final Batch Loss: 0.01513370219618082\n",
      "Epoch 551, Loss: 0.020935670472681522, Final Batch Loss: 0.004640032537281513\n",
      "Epoch 552, Loss: 0.016669939504936337, Final Batch Loss: 0.003793506184592843\n",
      "Epoch 553, Loss: 0.019868044648319483, Final Batch Loss: 0.012581054121255875\n",
      "Epoch 554, Loss: 0.02028442919254303, Final Batch Loss: 0.004344485700130463\n",
      "Epoch 555, Loss: 0.03772252704948187, Final Batch Loss: 0.01488663163036108\n",
      "Epoch 556, Loss: 0.0076725727412849665, Final Batch Loss: 0.002779067726805806\n",
      "Epoch 557, Loss: 0.011073356959968805, Final Batch Loss: 0.005768290255218744\n",
      "Epoch 558, Loss: 0.060061629861593246, Final Batch Loss: 0.011327851563692093\n",
      "Epoch 559, Loss: 0.01363409124314785, Final Batch Loss: 0.003078736364841461\n",
      "Epoch 560, Loss: 0.008219465613365173, Final Batch Loss: 0.003965496551245451\n",
      "Epoch 561, Loss: 0.026700353249907494, Final Batch Loss: 0.009280124679207802\n",
      "Epoch 562, Loss: 0.015880851075053215, Final Batch Loss: 0.009334813803434372\n",
      "Epoch 563, Loss: 0.01651783613488078, Final Batch Loss: 0.009430731646716595\n",
      "Epoch 564, Loss: 0.021597441285848618, Final Batch Loss: 0.006498527713119984\n",
      "Epoch 565, Loss: 0.027450404595583677, Final Batch Loss: 0.024254731833934784\n",
      "Epoch 566, Loss: 0.036790041252970695, Final Batch Loss: 0.02770129404962063\n",
      "Epoch 567, Loss: 0.01255010161548853, Final Batch Loss: 0.005312691442668438\n",
      "Epoch 568, Loss: 0.05463764537125826, Final Batch Loss: 0.012875732965767384\n",
      "Epoch 569, Loss: 0.01503242552280426, Final Batch Loss: 0.004183230921626091\n",
      "Epoch 570, Loss: 0.016954859253019094, Final Batch Loss: 0.00474553694948554\n",
      "Epoch 571, Loss: 0.010044408263638616, Final Batch Loss: 0.0033449677284806967\n",
      "Epoch 572, Loss: 0.02314885426312685, Final Batch Loss: 0.007134410552680492\n",
      "Epoch 573, Loss: 0.013863727916032076, Final Batch Loss: 0.007242698688060045\n",
      "Epoch 574, Loss: 0.037920225877314806, Final Batch Loss: 0.03226710855960846\n",
      "Epoch 575, Loss: 0.03180751856416464, Final Batch Loss: 0.01934477686882019\n",
      "Epoch 576, Loss: 0.014536474365741014, Final Batch Loss: 0.004513391759246588\n",
      "Epoch 577, Loss: 0.010256043868139386, Final Batch Loss: 0.0029197700787335634\n",
      "Epoch 578, Loss: 0.00870573241263628, Final Batch Loss: 0.003075417596846819\n",
      "Epoch 579, Loss: 0.015743227442726493, Final Batch Loss: 0.0015402247663587332\n",
      "Epoch 580, Loss: 0.06261097500100732, Final Batch Loss: 0.055982209742069244\n",
      "Epoch 581, Loss: 0.009450678247958422, Final Batch Loss: 0.004164243116974831\n",
      "Epoch 582, Loss: 0.040554346051067114, Final Batch Loss: 0.007647512014955282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583, Loss: 0.008756852243095636, Final Batch Loss: 0.0026766336522996426\n",
      "Epoch 584, Loss: 0.01319103641435504, Final Batch Loss: 0.007552645169198513\n",
      "Epoch 585, Loss: 0.024945922661572695, Final Batch Loss: 0.020133597776293755\n",
      "Epoch 586, Loss: 0.0048147624474950135, Final Batch Loss: 0.0008774276939220726\n",
      "Epoch 587, Loss: 0.014387509785592556, Final Batch Loss: 0.005390887148678303\n",
      "Epoch 588, Loss: 0.026106600649654865, Final Batch Loss: 0.00881206151098013\n",
      "Epoch 589, Loss: 0.016852517146617174, Final Batch Loss: 0.01228091586381197\n",
      "Epoch 590, Loss: 0.013652091845870018, Final Batch Loss: 0.007794352248311043\n",
      "Epoch 591, Loss: 0.026942161843180656, Final Batch Loss: 0.010615857318043709\n",
      "Epoch 592, Loss: 0.013156778644770384, Final Batch Loss: 0.005308240186423063\n",
      "Epoch 593, Loss: 0.014248276129364967, Final Batch Loss: 0.005709292367100716\n",
      "Epoch 594, Loss: 0.021878685161937028, Final Batch Loss: 0.0009328921441920102\n",
      "Epoch 595, Loss: 0.012994440272450447, Final Batch Loss: 0.010598535649478436\n",
      "Epoch 596, Loss: 0.0359173147007823, Final Batch Loss: 0.03136422485113144\n",
      "Epoch 597, Loss: 0.012345633003860712, Final Batch Loss: 0.006107361987233162\n",
      "Epoch 598, Loss: 0.008144615218043327, Final Batch Loss: 0.004811693914234638\n",
      "Epoch 599, Loss: 0.008433996699750423, Final Batch Loss: 0.003950044512748718\n",
      "Epoch 600, Loss: 0.0299967466853559, Final Batch Loss: 0.0046114507131278515\n",
      "Epoch 601, Loss: 0.00936675793491304, Final Batch Loss: 0.002689040033146739\n",
      "Epoch 602, Loss: 0.027244103606790304, Final Batch Loss: 0.007042046170681715\n",
      "Epoch 603, Loss: 0.024152198806405067, Final Batch Loss: 0.005493879318237305\n",
      "Epoch 604, Loss: 0.010615539271384478, Final Batch Loss: 0.0062675694935023785\n",
      "Epoch 605, Loss: 0.01032709120772779, Final Batch Loss: 0.0033945252653211355\n",
      "Epoch 606, Loss: 0.015714949928224087, Final Batch Loss: 0.008782483637332916\n",
      "Epoch 607, Loss: 0.020521455444395542, Final Batch Loss: 0.0012525347992777824\n",
      "Epoch 608, Loss: 0.04263876471668482, Final Batch Loss: 0.009870697744190693\n",
      "Epoch 609, Loss: 0.0291671734303236, Final Batch Loss: 0.015392135828733444\n",
      "Epoch 610, Loss: 0.011973762535490096, Final Batch Loss: 0.01006404310464859\n",
      "Epoch 611, Loss: 0.015060836914926767, Final Batch Loss: 0.0048338077031075954\n",
      "Epoch 612, Loss: 0.020580529235303402, Final Batch Loss: 0.0091909384354949\n",
      "Epoch 613, Loss: 0.015145029406994581, Final Batch Loss: 0.009507713839411736\n",
      "Epoch 614, Loss: 0.0076139945012982935, Final Batch Loss: 0.00041237924597226083\n",
      "Epoch 615, Loss: 0.02740156790241599, Final Batch Loss: 0.02196020446717739\n",
      "Epoch 616, Loss: 0.016286206431686878, Final Batch Loss: 0.011906785890460014\n",
      "Epoch 617, Loss: 0.03481905360240489, Final Batch Loss: 0.033692505210638046\n",
      "Epoch 618, Loss: 0.007500340696424246, Final Batch Loss: 0.003257960081100464\n",
      "Epoch 619, Loss: 0.018690631724894047, Final Batch Loss: 0.01238572970032692\n",
      "Epoch 620, Loss: 0.031060466077178717, Final Batch Loss: 0.025598738342523575\n",
      "Epoch 621, Loss: 0.019975988194346428, Final Batch Loss: 0.014850873500108719\n",
      "Epoch 622, Loss: 0.028847006149590015, Final Batch Loss: 0.022992145270109177\n",
      "Epoch 623, Loss: 0.008727625594474375, Final Batch Loss: 0.001066358876414597\n",
      "Epoch 624, Loss: 0.013170423451811075, Final Batch Loss: 0.005392519757151604\n",
      "Epoch 625, Loss: 0.017587782349437475, Final Batch Loss: 0.0022272723726928234\n",
      "Epoch 626, Loss: 0.01903473772108555, Final Batch Loss: 0.010473976843059063\n",
      "Epoch 627, Loss: 0.01081212516874075, Final Batch Loss: 0.0031724334694445133\n",
      "Epoch 628, Loss: 0.00787970656529069, Final Batch Loss: 0.0020022313110530376\n",
      "Epoch 629, Loss: 0.019643363542854786, Final Batch Loss: 0.00974536594003439\n",
      "Epoch 630, Loss: 0.05377632938325405, Final Batch Loss: 0.03778610751032829\n",
      "Epoch 631, Loss: 0.015750597463920712, Final Batch Loss: 0.012032699771225452\n",
      "Epoch 632, Loss: 0.016093660145998, Final Batch Loss: 0.010688988491892815\n",
      "Epoch 633, Loss: 0.01707018818706274, Final Batch Loss: 0.009653329849243164\n",
      "Epoch 634, Loss: 0.013512105098925531, Final Batch Loss: 0.0014651477104052901\n",
      "Epoch 635, Loss: 0.010323657072149217, Final Batch Loss: 0.0015036932891234756\n",
      "Epoch 636, Loss: 0.0272061824798584, Final Batch Loss: 0.015315264463424683\n",
      "Epoch 637, Loss: 0.011407350189983845, Final Batch Loss: 0.005930857267230749\n",
      "Epoch 638, Loss: 0.008683100109919906, Final Batch Loss: 0.006693759001791477\n",
      "Epoch 639, Loss: 0.01874556951224804, Final Batch Loss: 0.003075169399380684\n",
      "Epoch 640, Loss: 0.03361603058874607, Final Batch Loss: 0.014015229418873787\n",
      "Epoch 641, Loss: 0.017227808944880962, Final Batch Loss: 0.002938254736363888\n",
      "Epoch 642, Loss: 0.019176820875145495, Final Batch Loss: 0.0006981889018788934\n",
      "Epoch 643, Loss: 0.023300948552787304, Final Batch Loss: 0.014451646246016026\n",
      "Epoch 644, Loss: 0.008833585307002068, Final Batch Loss: 0.0042587523348629475\n",
      "Epoch 645, Loss: 0.03157028462737799, Final Batch Loss: 0.015454192645847797\n",
      "Epoch 646, Loss: 0.009725958574563265, Final Batch Loss: 0.004882906097918749\n",
      "Epoch 647, Loss: 0.008712985785678029, Final Batch Loss: 0.0051172953099012375\n",
      "Epoch 648, Loss: 0.005587516003288329, Final Batch Loss: 0.0004969044821336865\n",
      "Epoch 649, Loss: 0.013224737718701363, Final Batch Loss: 0.00583398574963212\n",
      "Epoch 650, Loss: 0.013124318327754736, Final Batch Loss: 0.007634346839040518\n",
      "Epoch 651, Loss: 0.01619131024926901, Final Batch Loss: 0.0015548262745141983\n",
      "Epoch 652, Loss: 0.01257399283349514, Final Batch Loss: 0.0042555322870612144\n",
      "Epoch 653, Loss: 0.009221651125699282, Final Batch Loss: 0.004601898603141308\n",
      "Epoch 654, Loss: 0.03436925262212753, Final Batch Loss: 0.024747798219323158\n",
      "Epoch 655, Loss: 0.015908729285001755, Final Batch Loss: 0.004910397343337536\n",
      "Epoch 656, Loss: 0.0063977171666920185, Final Batch Loss: 0.0035330415703356266\n",
      "Epoch 657, Loss: 0.028445784002542496, Final Batch Loss: 0.012076374143362045\n",
      "Epoch 658, Loss: 0.00796013930812478, Final Batch Loss: 0.004726659506559372\n",
      "Epoch 659, Loss: 0.015417605638504028, Final Batch Loss: 0.008299504406750202\n",
      "Epoch 660, Loss: 0.017908753361552954, Final Batch Loss: 0.012600461021065712\n",
      "Epoch 661, Loss: 0.004215608933009207, Final Batch Loss: 0.0013900037156417966\n",
      "Epoch 662, Loss: 0.016202181577682495, Final Batch Loss: 0.010209479369223118\n",
      "Epoch 663, Loss: 0.009527029818855226, Final Batch Loss: 0.008737102150917053\n",
      "Epoch 664, Loss: 0.024868651758879423, Final Batch Loss: 0.02240874618291855\n",
      "Epoch 665, Loss: 0.0115090012550354, Final Batch Loss: 0.006136426702141762\n",
      "Epoch 666, Loss: 0.011242232983931899, Final Batch Loss: 0.007741499692201614\n",
      "Epoch 667, Loss: 0.007269907859154046, Final Batch Loss: 0.0007541408995166421\n",
      "Epoch 668, Loss: 0.015121847856789827, Final Batch Loss: 0.011492039076983929\n",
      "Epoch 669, Loss: 0.00396250793710351, Final Batch Loss: 0.0027051889337599277\n",
      "Epoch 670, Loss: 0.012858080677688122, Final Batch Loss: 0.000902252271771431\n",
      "Epoch 671, Loss: 0.01844712282763794, Final Batch Loss: 0.0006623354856856167\n",
      "Epoch 672, Loss: 0.028939741663634777, Final Batch Loss: 0.009260893799364567\n",
      "Epoch 673, Loss: 0.006820084527134895, Final Batch Loss: 0.0016569769941270351\n",
      "Epoch 674, Loss: 0.005808469606563449, Final Batch Loss: 0.0016935502644628286\n",
      "Epoch 675, Loss: 0.014494515489786863, Final Batch Loss: 0.005816000048071146\n",
      "Epoch 676, Loss: 0.0076585153583437204, Final Batch Loss: 0.005009012762457132\n",
      "Epoch 677, Loss: 0.02393239177763462, Final Batch Loss: 0.016754118725657463\n",
      "Epoch 678, Loss: 0.012274848530068994, Final Batch Loss: 0.0025344102177768946\n",
      "Epoch 679, Loss: 0.01233965263236314, Final Batch Loss: 0.001759601873345673\n",
      "Epoch 680, Loss: 0.0128198794554919, Final Batch Loss: 0.002935949480161071\n",
      "Epoch 681, Loss: 0.012285452801734209, Final Batch Loss: 0.0034233550541102886\n",
      "Epoch 682, Loss: 0.003359577036462724, Final Batch Loss: 0.0015359621029347181\n",
      "Epoch 683, Loss: 0.01076358649879694, Final Batch Loss: 0.0023162420839071274\n",
      "Epoch 684, Loss: 0.006917607970535755, Final Batch Loss: 0.0050040362402796745\n",
      "Epoch 685, Loss: 0.014720012433826923, Final Batch Loss: 0.007279911078512669\n",
      "Epoch 686, Loss: 0.015786551870405674, Final Batch Loss: 0.00988154485821724\n",
      "Epoch 687, Loss: 0.028578167781233788, Final Batch Loss: 0.019904877990484238\n",
      "Epoch 688, Loss: 0.01571743027307093, Final Batch Loss: 0.012215734459459782\n",
      "Epoch 689, Loss: 0.025946922600269318, Final Batch Loss: 0.015032844617962837\n",
      "Epoch 690, Loss: 0.027621742337942123, Final Batch Loss: 0.013141660951077938\n",
      "Epoch 691, Loss: 0.014853027882054448, Final Batch Loss: 0.0005458064842969179\n",
      "Epoch 692, Loss: 0.00823052111081779, Final Batch Loss: 0.0020554710645228624\n",
      "Epoch 693, Loss: 0.01795449503697455, Final Batch Loss: 0.0029185388702899218\n",
      "Epoch 694, Loss: 0.021301566623151302, Final Batch Loss: 0.012660328298807144\n",
      "Epoch 695, Loss: 0.01168672414496541, Final Batch Loss: 0.007300111930817366\n",
      "Epoch 696, Loss: 0.009663900826126337, Final Batch Loss: 0.005903364159166813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697, Loss: 0.05945759825408459, Final Batch Loss: 0.055424779653549194\n",
      "Epoch 698, Loss: 0.01785818813368678, Final Batch Loss: 0.011729288846254349\n",
      "Epoch 699, Loss: 0.005156965693458915, Final Batch Loss: 0.002466487465426326\n",
      "Epoch 700, Loss: 0.014758589211851358, Final Batch Loss: 0.005618479568511248\n",
      "Epoch 701, Loss: 0.006187740480527282, Final Batch Loss: 0.002084379317238927\n",
      "Epoch 702, Loss: 0.007123345043510199, Final Batch Loss: 0.0025329040363430977\n",
      "Epoch 703, Loss: 0.005918121663853526, Final Batch Loss: 0.002009616931900382\n",
      "Epoch 704, Loss: 0.005097846093121916, Final Batch Loss: 0.00039664568612352014\n",
      "Epoch 705, Loss: 0.031058596912771463, Final Batch Loss: 0.023924415931105614\n",
      "Epoch 706, Loss: 0.0076885398011654615, Final Batch Loss: 0.004374416545033455\n",
      "Epoch 707, Loss: 0.010535524692386389, Final Batch Loss: 0.00764952227473259\n",
      "Epoch 708, Loss: 0.03312556631863117, Final Batch Loss: 0.025391483679413795\n",
      "Epoch 709, Loss: 0.010722811566665769, Final Batch Loss: 0.002583109075203538\n",
      "Epoch 710, Loss: 0.013299035374075174, Final Batch Loss: 0.004113178234547377\n",
      "Epoch 711, Loss: 0.02061004750430584, Final Batch Loss: 0.010622067376971245\n",
      "Epoch 712, Loss: 0.007619895390234888, Final Batch Loss: 0.0013273580698296428\n",
      "Epoch 713, Loss: 0.006292212987318635, Final Batch Loss: 0.003360607661306858\n",
      "Epoch 714, Loss: 0.03144098911434412, Final Batch Loss: 0.019279424101114273\n",
      "Epoch 715, Loss: 0.008635230362415314, Final Batch Loss: 0.0013199043460190296\n",
      "Epoch 716, Loss: 0.03040015883743763, Final Batch Loss: 0.01562244538217783\n",
      "Epoch 717, Loss: 0.010457797208800912, Final Batch Loss: 0.0038112758193165064\n",
      "Epoch 718, Loss: 0.015172204934060574, Final Batch Loss: 0.007873945869505405\n",
      "Epoch 719, Loss: 0.008386925677768886, Final Batch Loss: 0.0019408621592447162\n",
      "Epoch 720, Loss: 0.03918728698045015, Final Batch Loss: 0.026681052520871162\n",
      "Epoch 721, Loss: 0.010780701937619597, Final Batch Loss: 0.0007988936849869788\n",
      "Epoch 722, Loss: 0.005206892965361476, Final Batch Loss: 0.0016229201573878527\n",
      "Epoch 723, Loss: 0.004546663869405165, Final Batch Loss: 0.00047940356307663023\n",
      "Epoch 724, Loss: 0.0036825147399213165, Final Batch Loss: 0.0002723905199673027\n",
      "Epoch 725, Loss: 0.01890107849612832, Final Batch Loss: 0.004191781859844923\n",
      "Epoch 726, Loss: 0.008414794690907001, Final Batch Loss: 0.0035362388007342815\n",
      "Epoch 727, Loss: 0.01970542361959815, Final Batch Loss: 0.006045397836714983\n",
      "Epoch 728, Loss: 0.018556700320914388, Final Batch Loss: 0.0010004539508372545\n",
      "Epoch 729, Loss: 0.027576268650591373, Final Batch Loss: 0.016328908503055573\n",
      "Epoch 730, Loss: 0.031995423370972276, Final Batch Loss: 0.0033389630261808634\n",
      "Epoch 731, Loss: 0.018819102086126804, Final Batch Loss: 0.0056703463196754456\n",
      "Epoch 732, Loss: 0.014647010248154402, Final Batch Loss: 0.0025467216037213802\n",
      "Epoch 733, Loss: 0.010866469237953424, Final Batch Loss: 0.005349519196897745\n",
      "Epoch 734, Loss: 0.01933770626783371, Final Batch Loss: 0.001405090093612671\n",
      "Epoch 735, Loss: 0.009242826607078314, Final Batch Loss: 0.004196234978735447\n",
      "Epoch 736, Loss: 0.022363074123859406, Final Batch Loss: 0.015314478427171707\n",
      "Epoch 737, Loss: 0.01760582299903035, Final Batch Loss: 0.012421506457030773\n",
      "Epoch 738, Loss: 0.015334140975028276, Final Batch Loss: 0.013268179260194302\n",
      "Epoch 739, Loss: 0.0030719953356310725, Final Batch Loss: 0.001053710118867457\n",
      "Epoch 740, Loss: 0.010649912990629673, Final Batch Loss: 0.0051825931295752525\n",
      "Epoch 741, Loss: 0.01073200348764658, Final Batch Loss: 0.007234008051455021\n",
      "Epoch 742, Loss: 0.009612055378966033, Final Batch Loss: 0.00169562257360667\n",
      "Epoch 743, Loss: 0.013477315427735448, Final Batch Loss: 0.001995580503717065\n",
      "Epoch 744, Loss: 0.005015507980715483, Final Batch Loss: 0.0007989007863216102\n",
      "Epoch 745, Loss: 0.014511021319776773, Final Batch Loss: 0.008146973326802254\n",
      "Epoch 746, Loss: 0.004445711616426706, Final Batch Loss: 0.0006577512249350548\n",
      "Epoch 747, Loss: 0.030404032208025455, Final Batch Loss: 0.021245794370770454\n",
      "Epoch 748, Loss: 0.008415694581344724, Final Batch Loss: 0.0031986043322831392\n",
      "Epoch 749, Loss: 0.02332523837685585, Final Batch Loss: 0.006102869287133217\n",
      "Epoch 750, Loss: 0.013047069311141968, Final Batch Loss: 0.006029758136719465\n",
      "Epoch 751, Loss: 0.009236081503331661, Final Batch Loss: 0.005449931602925062\n",
      "Epoch 752, Loss: 0.018128301482647657, Final Batch Loss: 0.003835985902696848\n",
      "Epoch 753, Loss: 0.008978000609204173, Final Batch Loss: 0.003773076692596078\n",
      "Epoch 754, Loss: 0.012936092214658856, Final Batch Loss: 0.009617804549634457\n",
      "Epoch 755, Loss: 0.013275026809424162, Final Batch Loss: 0.010623477399349213\n",
      "Epoch 756, Loss: 0.03821184590924531, Final Batch Loss: 0.036586251109838486\n",
      "Epoch 757, Loss: 0.014453487936407328, Final Batch Loss: 0.009126107208430767\n",
      "Epoch 758, Loss: 0.0028032177360728383, Final Batch Loss: 0.0008446554420515895\n",
      "Epoch 759, Loss: 0.020012373279314488, Final Batch Loss: 0.0004194157081656158\n",
      "Epoch 760, Loss: 0.006466961232945323, Final Batch Loss: 0.0029123451095074415\n",
      "Epoch 761, Loss: 0.010110151953995228, Final Batch Loss: 0.005731639917939901\n",
      "Epoch 762, Loss: 0.007037564180791378, Final Batch Loss: 0.00494567072018981\n",
      "Epoch 763, Loss: 0.015748882375191897, Final Batch Loss: 0.0008537850226275623\n",
      "Epoch 764, Loss: 0.011960277333855629, Final Batch Loss: 0.002779817208647728\n",
      "Epoch 765, Loss: 0.00556815043091774, Final Batch Loss: 0.001463018823415041\n",
      "Epoch 766, Loss: 0.006459724449086934, Final Batch Loss: 0.0009566427324898541\n",
      "Epoch 767, Loss: 0.0064490074291825294, Final Batch Loss: 0.003531381022185087\n",
      "Epoch 768, Loss: 0.006323031964711845, Final Batch Loss: 0.005139037035405636\n",
      "Epoch 769, Loss: 0.033166862558573484, Final Batch Loss: 0.0311327762901783\n",
      "Epoch 770, Loss: 0.004197625210508704, Final Batch Loss: 0.0032644965685904026\n",
      "Epoch 771, Loss: 0.003337428322993219, Final Batch Loss: 0.000856569386087358\n",
      "Epoch 772, Loss: 0.009877996635623276, Final Batch Loss: 0.0006646170513704419\n",
      "Epoch 773, Loss: 0.014495558105409145, Final Batch Loss: 0.007227353285998106\n",
      "Epoch 774, Loss: 0.008194437657948583, Final Batch Loss: 0.0006954101263545454\n",
      "Epoch 775, Loss: 0.013400009367614985, Final Batch Loss: 0.0019098860211670399\n",
      "Epoch 776, Loss: 0.00803689332678914, Final Batch Loss: 0.0019748532213270664\n",
      "Epoch 777, Loss: 0.024241797858849168, Final Batch Loss: 0.0021762216929346323\n",
      "Epoch 778, Loss: 0.014897165820002556, Final Batch Loss: 0.011282230727374554\n",
      "Epoch 779, Loss: 0.009145973715931177, Final Batch Loss: 0.006710901856422424\n",
      "Epoch 780, Loss: 0.01642226241528988, Final Batch Loss: 0.012770135886967182\n",
      "Epoch 781, Loss: 0.012577517656609416, Final Batch Loss: 0.011132221668958664\n",
      "Epoch 782, Loss: 0.01553779374808073, Final Batch Loss: 0.010482911951839924\n",
      "Epoch 783, Loss: 0.00971306674182415, Final Batch Loss: 0.004514499567449093\n",
      "Epoch 784, Loss: 0.005915413610637188, Final Batch Loss: 0.0012115035206079483\n",
      "Epoch 785, Loss: 0.010135718621313572, Final Batch Loss: 0.0007502976804971695\n",
      "Epoch 786, Loss: 0.02888751169666648, Final Batch Loss: 0.026504676789045334\n",
      "Epoch 787, Loss: 0.005233584204688668, Final Batch Loss: 0.00202566129155457\n",
      "Epoch 788, Loss: 0.012882486451417208, Final Batch Loss: 0.005576849915087223\n",
      "Epoch 789, Loss: 0.007759357104077935, Final Batch Loss: 0.005681570153683424\n",
      "Epoch 790, Loss: 0.0075438732746988535, Final Batch Loss: 0.004599215928465128\n",
      "Epoch 791, Loss: 0.012259617680683732, Final Batch Loss: 0.009132826700806618\n",
      "Epoch 792, Loss: 0.010589003330096602, Final Batch Loss: 0.003699568333104253\n",
      "Epoch 793, Loss: 0.0016379650041926652, Final Batch Loss: 0.0013224906288087368\n",
      "Epoch 794, Loss: 0.003959050984121859, Final Batch Loss: 0.0012055464321747422\n",
      "Epoch 795, Loss: 0.00692138122394681, Final Batch Loss: 0.004149976186454296\n",
      "Epoch 796, Loss: 0.00474877655506134, Final Batch Loss: 0.002224189229309559\n",
      "Epoch 797, Loss: 0.001872197724878788, Final Batch Loss: 0.001021596952341497\n",
      "Epoch 798, Loss: 0.008737450931221247, Final Batch Loss: 0.004848681855946779\n",
      "Epoch 799, Loss: 0.0038506530690938234, Final Batch Loss: 0.0023061607498675585\n",
      "Epoch 800, Loss: 0.005902884237002581, Final Batch Loss: 0.0009258577483706176\n",
      "Epoch 801, Loss: 0.007925475714728236, Final Batch Loss: 0.005489644128829241\n",
      "Epoch 802, Loss: 0.005105302669107914, Final Batch Loss: 0.0020527373999357224\n",
      "Epoch 803, Loss: 0.010258249938488007, Final Batch Loss: 0.0042031933553516865\n",
      "Epoch 804, Loss: 0.003363619791343808, Final Batch Loss: 0.0014459158992394805\n",
      "Epoch 805, Loss: 0.00686435610987246, Final Batch Loss: 0.004276944790035486\n",
      "Epoch 806, Loss: 0.0136208301410079, Final Batch Loss: 0.008953488431870937\n",
      "Epoch 807, Loss: 0.011624305276200175, Final Batch Loss: 0.00828434620052576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808, Loss: 0.010203456738963723, Final Batch Loss: 0.007984830066561699\n",
      "Epoch 809, Loss: 0.015103467274457216, Final Batch Loss: 0.010947445407509804\n",
      "Epoch 810, Loss: 0.01495668338611722, Final Batch Loss: 0.012476807460188866\n",
      "Epoch 811, Loss: 0.007583882659673691, Final Batch Loss: 0.0030714026652276516\n",
      "Epoch 812, Loss: 0.005577400326728821, Final Batch Loss: 0.003135132836177945\n",
      "Epoch 813, Loss: 0.014015351422131062, Final Batch Loss: 0.011341175995767117\n",
      "Epoch 814, Loss: 0.005567315500229597, Final Batch Loss: 0.0021370407193899155\n",
      "Epoch 815, Loss: 0.005058936076238751, Final Batch Loss: 0.002540941582992673\n",
      "Epoch 816, Loss: 0.014762269798666239, Final Batch Loss: 0.003094757441431284\n",
      "Epoch 817, Loss: 0.04330685082823038, Final Batch Loss: 0.008231119252741337\n",
      "Epoch 818, Loss: 0.006471172207966447, Final Batch Loss: 0.004123617894947529\n",
      "Epoch 819, Loss: 0.004788128775544465, Final Batch Loss: 0.0019091736758127809\n",
      "Epoch 820, Loss: 0.011304829735308886, Final Batch Loss: 0.007054291665554047\n",
      "Epoch 821, Loss: 0.009820318315178156, Final Batch Loss: 0.008306463249027729\n",
      "Epoch 822, Loss: 0.012252442073076963, Final Batch Loss: 0.008274057880043983\n",
      "Epoch 823, Loss: 0.008388677379116416, Final Batch Loss: 0.003823094768449664\n",
      "Epoch 824, Loss: 0.034712718799710274, Final Batch Loss: 0.03033076971769333\n",
      "Epoch 825, Loss: 0.010142725193873048, Final Batch Loss: 0.0022245238069444895\n",
      "Epoch 826, Loss: 0.01145046460442245, Final Batch Loss: 0.0035808614920824766\n",
      "Epoch 827, Loss: 0.019270075485110283, Final Batch Loss: 0.011529045179486275\n",
      "Epoch 828, Loss: 0.0075550835754256696, Final Batch Loss: 0.0070696561597287655\n",
      "Epoch 829, Loss: 0.0049881808226928115, Final Batch Loss: 0.003371412632986903\n",
      "Epoch 830, Loss: 0.023525089723989367, Final Batch Loss: 0.020435351878404617\n",
      "Epoch 831, Loss: 0.007264229003340006, Final Batch Loss: 0.0026192720979452133\n",
      "Epoch 832, Loss: 0.002518284774851054, Final Batch Loss: 0.0006365408771671355\n",
      "Epoch 833, Loss: 0.0027948980568908155, Final Batch Loss: 0.0005308230756781995\n",
      "Epoch 834, Loss: 0.006891904165968299, Final Batch Loss: 0.0018510574009269476\n",
      "Epoch 835, Loss: 0.011356638744473457, Final Batch Loss: 0.0052201226353645325\n",
      "Epoch 836, Loss: 0.01289026951417327, Final Batch Loss: 0.008926521986722946\n",
      "Epoch 837, Loss: 0.0055476101115345955, Final Batch Loss: 0.0033768184948712587\n",
      "Epoch 838, Loss: 0.029256911017000675, Final Batch Loss: 0.018535763025283813\n",
      "Epoch 839, Loss: 0.02191925561055541, Final Batch Loss: 0.01801072247326374\n",
      "Epoch 840, Loss: 0.002600582200102508, Final Batch Loss: 0.0010103631066158414\n",
      "Epoch 841, Loss: 0.005842637037858367, Final Batch Loss: 0.00348816835321486\n",
      "Epoch 842, Loss: 0.014588217716664076, Final Batch Loss: 0.00755802309140563\n",
      "Epoch 843, Loss: 0.00894908094778657, Final Batch Loss: 0.0033637629821896553\n",
      "Epoch 844, Loss: 0.01511082798242569, Final Batch Loss: 0.00749314296990633\n",
      "Epoch 845, Loss: 0.0043628832791000605, Final Batch Loss: 0.0023555858060717583\n",
      "Epoch 846, Loss: 0.003214408061467111, Final Batch Loss: 0.0009303925326094031\n",
      "Epoch 847, Loss: 0.015531564713455737, Final Batch Loss: 0.01485525444149971\n",
      "Epoch 848, Loss: 0.00498072209302336, Final Batch Loss: 0.0004979331279173493\n",
      "Epoch 849, Loss: 0.007191691547632217, Final Batch Loss: 0.0036284103989601135\n",
      "Epoch 850, Loss: 0.010001502931118011, Final Batch Loss: 0.0040070293471217155\n",
      "Epoch 851, Loss: 0.0034000405576080084, Final Batch Loss: 0.0003211603034287691\n",
      "Epoch 852, Loss: 0.05312777031213045, Final Batch Loss: 0.046205371618270874\n",
      "Epoch 853, Loss: 0.01895935647189617, Final Batch Loss: 0.014498273842036724\n",
      "Epoch 854, Loss: 0.008373258053325117, Final Batch Loss: 0.007305551320314407\n",
      "Epoch 855, Loss: 0.012608557008206844, Final Batch Loss: 0.006288615055382252\n",
      "Epoch 856, Loss: 0.004460861557163298, Final Batch Loss: 0.001260533812455833\n",
      "Epoch 857, Loss: 0.023818554589524865, Final Batch Loss: 0.0007190520409494638\n",
      "Epoch 858, Loss: 0.0013893595605622977, Final Batch Loss: 0.00037004819023422897\n",
      "Epoch 859, Loss: 0.012186782550998032, Final Batch Loss: 0.01080932468175888\n",
      "Epoch 860, Loss: 0.0037570365238934755, Final Batch Loss: 0.0013662739656865597\n",
      "Epoch 861, Loss: 0.004866043746005744, Final Batch Loss: 0.0006977884913794696\n",
      "Epoch 862, Loss: 0.0037303201388567686, Final Batch Loss: 0.0010692381765693426\n",
      "Epoch 863, Loss: 0.0045865969732403755, Final Batch Loss: 0.0020155846141278744\n",
      "Epoch 864, Loss: 0.006169585045427084, Final Batch Loss: 0.0027118781581521034\n",
      "Epoch 865, Loss: 0.08213201514445245, Final Batch Loss: 0.08107085525989532\n",
      "Epoch 866, Loss: 0.003387812292203307, Final Batch Loss: 0.001051911385729909\n",
      "Epoch 867, Loss: 0.008635524660348892, Final Batch Loss: 0.0007567116990685463\n",
      "Epoch 868, Loss: 0.018403294612653553, Final Batch Loss: 0.0018452844815328717\n",
      "Epoch 869, Loss: 0.009118440328165889, Final Batch Loss: 0.003566320287063718\n",
      "Epoch 870, Loss: 0.006586417672224343, Final Batch Loss: 0.0005427181022241712\n",
      "Epoch 871, Loss: 0.003274446935392916, Final Batch Loss: 0.002280630636960268\n",
      "Epoch 872, Loss: 0.012735769618302584, Final Batch Loss: 0.003102939110249281\n",
      "Epoch 873, Loss: 0.029612798243761063, Final Batch Loss: 0.002172045409679413\n",
      "Epoch 874, Loss: 0.031248782644979656, Final Batch Loss: 0.0007899970514699817\n",
      "Epoch 875, Loss: 0.019031100906431675, Final Batch Loss: 0.013115506619215012\n",
      "Epoch 876, Loss: 0.01035997539293021, Final Batch Loss: 0.0010079442290589213\n",
      "Epoch 877, Loss: 0.01130753755569458, Final Batch Loss: 0.003654161933809519\n",
      "Epoch 878, Loss: 0.014995351200923324, Final Batch Loss: 0.0025024458300322294\n",
      "Epoch 879, Loss: 0.006035051541402936, Final Batch Loss: 0.0039800615049898624\n",
      "Epoch 880, Loss: 0.007747744210064411, Final Batch Loss: 0.002982392441481352\n",
      "Epoch 881, Loss: 0.004105986095964909, Final Batch Loss: 0.0014329133555293083\n",
      "Epoch 882, Loss: 0.009785139467567205, Final Batch Loss: 0.003988649696111679\n",
      "Epoch 883, Loss: 0.013194671832025051, Final Batch Loss: 0.005157174542546272\n",
      "Epoch 884, Loss: 0.003877778071910143, Final Batch Loss: 0.0017125529702752829\n",
      "Epoch 885, Loss: 0.015680106356739998, Final Batch Loss: 0.008818455040454865\n",
      "Epoch 886, Loss: 0.0054782658407930285, Final Batch Loss: 0.0004508017154876143\n",
      "Epoch 887, Loss: 0.004780280636623502, Final Batch Loss: 0.0017743112985044718\n",
      "Epoch 888, Loss: 0.020159804495051503, Final Batch Loss: 0.017978720366954803\n",
      "Epoch 889, Loss: 0.007088084472343326, Final Batch Loss: 0.002603505039587617\n",
      "Epoch 890, Loss: 0.005265787011012435, Final Batch Loss: 0.002098682802170515\n",
      "Epoch 891, Loss: 0.008383358363062143, Final Batch Loss: 0.0012719915248453617\n",
      "Epoch 892, Loss: 0.012634527869522572, Final Batch Loss: 0.005263057537376881\n",
      "Epoch 893, Loss: 0.004405750427395105, Final Batch Loss: 0.0013127524871379137\n",
      "Epoch 894, Loss: 0.003201806452125311, Final Batch Loss: 0.0006381634157150984\n",
      "Epoch 895, Loss: 0.0028954591252841055, Final Batch Loss: 0.0019244831055402756\n",
      "Epoch 896, Loss: 0.008027950185351074, Final Batch Loss: 0.0006467903731390834\n",
      "Epoch 897, Loss: 0.008798115595709532, Final Batch Loss: 0.000804683833848685\n",
      "Epoch 898, Loss: 0.007027259096503258, Final Batch Loss: 0.004006114788353443\n",
      "Epoch 899, Loss: 0.017090838635340333, Final Batch Loss: 0.015455888584256172\n",
      "Epoch 900, Loss: 0.0041203126311302185, Final Batch Loss: 0.0023568840697407722\n",
      "Epoch 901, Loss: 0.0038345219363691285, Final Batch Loss: 9.287062857765704e-05\n",
      "Epoch 902, Loss: 0.006971836439333856, Final Batch Loss: 0.0057027023285627365\n",
      "Epoch 903, Loss: 0.009106978570343927, Final Batch Loss: 0.000373297167243436\n",
      "Epoch 904, Loss: 0.0030453663785010576, Final Batch Loss: 0.0016172647010535002\n",
      "Epoch 905, Loss: 0.009466074872761965, Final Batch Loss: 0.005455339327454567\n",
      "Epoch 906, Loss: 0.004698102478869259, Final Batch Loss: 0.003780279541388154\n",
      "Epoch 907, Loss: 0.0344930796418339, Final Batch Loss: 0.031643375754356384\n",
      "Epoch 908, Loss: 0.003779000020585954, Final Batch Loss: 0.0016779761062934995\n",
      "Epoch 909, Loss: 0.006549131823703647, Final Batch Loss: 0.0010666453745216131\n",
      "Epoch 910, Loss: 0.00306627934332937, Final Batch Loss: 0.0014430731534957886\n",
      "Epoch 911, Loss: 0.002687666390556842, Final Batch Loss: 0.0007727034972049296\n",
      "Epoch 912, Loss: 0.0062496185710188, Final Batch Loss: 0.00031032119295559824\n",
      "Epoch 913, Loss: 0.022682941984385252, Final Batch Loss: 0.015689421445131302\n",
      "Epoch 914, Loss: 0.009502659318968654, Final Batch Loss: 0.003747327486053109\n",
      "Epoch 915, Loss: 0.0020902041578665376, Final Batch Loss: 0.0014305211370810866\n",
      "Epoch 916, Loss: 0.001992437639273703, Final Batch Loss: 0.0005608927458524704\n",
      "Epoch 917, Loss: 0.003697769599966705, Final Batch Loss: 0.0022969606798142195\n",
      "Epoch 918, Loss: 0.002060506376437843, Final Batch Loss: 0.000991179491393268\n",
      "Epoch 919, Loss: 0.0021673900773748755, Final Batch Loss: 0.0013889450347051024\n",
      "Epoch 920, Loss: 0.0016760891303420067, Final Batch Loss: 0.0005712650017812848\n",
      "Epoch 921, Loss: 0.023434496950358152, Final Batch Loss: 0.020432231947779655\n",
      "Epoch 922, Loss: 0.002700708108022809, Final Batch Loss: 0.0020824673119932413\n",
      "Epoch 923, Loss: 0.016135364770889282, Final Batch Loss: 0.00519935879856348\n",
      "Epoch 924, Loss: 0.002931276452727616, Final Batch Loss: 0.00238475832156837\n",
      "Epoch 925, Loss: 0.008784880163148046, Final Batch Loss: 0.003318322589620948\n",
      "Epoch 926, Loss: 0.012401862069964409, Final Batch Loss: 0.006410617381334305\n",
      "Epoch 927, Loss: 0.037733654491603374, Final Batch Loss: 0.012981909327208996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928, Loss: 0.0016007316880859435, Final Batch Loss: 0.00035456480691209435\n",
      "Epoch 929, Loss: 0.0035424220841377974, Final Batch Loss: 0.0012513117399066687\n",
      "Epoch 930, Loss: 0.007830634771380574, Final Batch Loss: 0.0006695762858726084\n",
      "Epoch 931, Loss: 0.017181540839374065, Final Batch Loss: 0.010785010643303394\n",
      "Epoch 932, Loss: 0.007445732597261667, Final Batch Loss: 0.003181717824190855\n",
      "Epoch 933, Loss: 0.005280762183247134, Final Batch Loss: 0.0002480589027982205\n",
      "Epoch 934, Loss: 0.04303439520299435, Final Batch Loss: 0.033263228833675385\n",
      "Epoch 935, Loss: 0.025800376432016492, Final Batch Loss: 0.0014255114365369081\n",
      "Epoch 936, Loss: 0.0068930803099647164, Final Batch Loss: 0.0005161386216059327\n",
      "Epoch 937, Loss: 0.004052022937685251, Final Batch Loss: 0.0028356232214719057\n",
      "Epoch 938, Loss: 0.0038402781647164375, Final Batch Loss: 0.00033778490615077317\n",
      "Epoch 939, Loss: 0.010846907272934914, Final Batch Loss: 0.0020225029438734055\n",
      "Epoch 940, Loss: 0.013135341461747885, Final Batch Loss: 0.006989543791860342\n",
      "Epoch 941, Loss: 0.0015047219349071383, Final Batch Loss: 0.00028976856265217066\n",
      "Epoch 942, Loss: 0.0038061224622651935, Final Batch Loss: 0.0026502644177526236\n",
      "Epoch 943, Loss: 0.005753393517807126, Final Batch Loss: 0.003315830370411277\n",
      "Epoch 944, Loss: 0.004939591512084007, Final Batch Loss: 0.0018242967780679464\n",
      "Epoch 945, Loss: 0.004410335037391633, Final Batch Loss: 0.0005250865942798555\n",
      "Epoch 946, Loss: 0.0534444497898221, Final Batch Loss: 0.05100555717945099\n",
      "Epoch 947, Loss: 0.014075680170208216, Final Batch Loss: 0.006763773038983345\n",
      "Epoch 948, Loss: 0.004022636712761596, Final Batch Loss: 0.003627740079537034\n",
      "Epoch 949, Loss: 0.007058248855173588, Final Batch Loss: 0.0014261244796216488\n",
      "Epoch 950, Loss: 0.0026138596003875136, Final Batch Loss: 0.0005007005529478192\n",
      "Epoch 951, Loss: 0.005455755395814776, Final Batch Loss: 0.0010253300424665213\n",
      "Epoch 952, Loss: 0.004313393495976925, Final Batch Loss: 0.002539685694500804\n",
      "Epoch 953, Loss: 0.005064533208496869, Final Batch Loss: 0.003182976506650448\n",
      "Epoch 954, Loss: 0.012864894233644009, Final Batch Loss: 0.007986173965036869\n",
      "Epoch 955, Loss: 0.025926407892256975, Final Batch Loss: 0.005624006036669016\n",
      "Epoch 956, Loss: 0.0011459675442893058, Final Batch Loss: 0.0003975611471105367\n",
      "Epoch 957, Loss: 0.004747268510982394, Final Batch Loss: 0.0016163629479706287\n",
      "Epoch 958, Loss: 0.01109322946285829, Final Batch Loss: 0.010390878655016422\n",
      "Epoch 959, Loss: 0.010700063081458211, Final Batch Loss: 0.006913132965564728\n",
      "Epoch 960, Loss: 0.006581607041880488, Final Batch Loss: 0.0021549544762820005\n",
      "Epoch 961, Loss: 0.005320231895893812, Final Batch Loss: 0.002318208571523428\n",
      "Epoch 962, Loss: 0.004155608272412792, Final Batch Loss: 0.0003890119551215321\n",
      "Epoch 963, Loss: 0.023080453858710825, Final Batch Loss: 0.02160344086587429\n",
      "Epoch 964, Loss: 0.0032016028417274356, Final Batch Loss: 0.001957057975232601\n",
      "Epoch 965, Loss: 0.0033949442440643907, Final Batch Loss: 0.0022062216885387897\n",
      "Epoch 966, Loss: 0.017471979837864637, Final Batch Loss: 0.006384306121617556\n",
      "Epoch 967, Loss: 0.012401642743498087, Final Batch Loss: 0.007831419818103313\n",
      "Epoch 968, Loss: 0.009681587805971503, Final Batch Loss: 0.0029572935309261084\n",
      "Epoch 969, Loss: 0.0007248808396980166, Final Batch Loss: 0.0002998320269398391\n",
      "Epoch 970, Loss: 0.031559758353978395, Final Batch Loss: 0.029756180942058563\n",
      "Epoch 971, Loss: 0.004745454294607043, Final Batch Loss: 0.0009578890167176723\n",
      "Epoch 972, Loss: 0.008381932973861694, Final Batch Loss: 0.0030481992289423943\n",
      "Epoch 973, Loss: 0.009144185110926628, Final Batch Loss: 0.003644851502031088\n",
      "Epoch 974, Loss: 0.001737183250952512, Final Batch Loss: 0.001242209691554308\n",
      "Epoch 975, Loss: 0.003558964701369405, Final Batch Loss: 0.000572526128962636\n",
      "Epoch 976, Loss: 0.0010334151156712323, Final Batch Loss: 0.00032021969673223794\n",
      "Epoch 977, Loss: 0.006655054516158998, Final Batch Loss: 0.005332635249942541\n",
      "Epoch 978, Loss: 0.018498631950933486, Final Batch Loss: 0.0008624073234386742\n",
      "Epoch 979, Loss: 0.0015879189886618406, Final Batch Loss: 0.0012432652292773128\n",
      "Epoch 980, Loss: 0.010466039646416903, Final Batch Loss: 0.005498108919709921\n",
      "Epoch 981, Loss: 0.022596926777623594, Final Batch Loss: 0.02066962607204914\n",
      "Epoch 982, Loss: 0.00719149992801249, Final Batch Loss: 0.003903336590155959\n",
      "Epoch 983, Loss: 0.0068384017795324326, Final Batch Loss: 0.0033999404404312372\n",
      "Epoch 984, Loss: 0.00414755690144375, Final Batch Loss: 0.0032751045655459166\n",
      "Epoch 985, Loss: 0.003092654049396515, Final Batch Loss: 0.0012698847567662597\n",
      "Epoch 986, Loss: 0.0013495689490810037, Final Batch Loss: 0.0009120094473473728\n",
      "Epoch 987, Loss: 0.009538423735648394, Final Batch Loss: 0.000702007208019495\n",
      "Epoch 988, Loss: 0.006579835084266961, Final Batch Loss: 0.004866652190685272\n",
      "Epoch 989, Loss: 0.0012989063980057836, Final Batch Loss: 0.0007308390340767801\n",
      "Epoch 990, Loss: 0.026644840370863676, Final Batch Loss: 0.004634795244783163\n",
      "Epoch 991, Loss: 0.013043413404375315, Final Batch Loss: 0.005370166152715683\n",
      "Epoch 992, Loss: 0.01620473712682724, Final Batch Loss: 0.0010650316253304482\n",
      "Epoch 993, Loss: 0.0025193821638822556, Final Batch Loss: 0.0011943505378440022\n",
      "Epoch 994, Loss: 0.01654207077808678, Final Batch Loss: 0.002847744384780526\n",
      "Epoch 995, Loss: 0.012566477234940976, Final Batch Loss: 0.011734958738088608\n",
      "Epoch 996, Loss: 0.005142522510141134, Final Batch Loss: 0.0022794376127421856\n",
      "Epoch 997, Loss: 0.0027507442282512784, Final Batch Loss: 0.0012778333621099591\n",
      "Epoch 998, Loss: 0.005687848431989551, Final Batch Loss: 0.0029970123432576656\n",
      "Epoch 999, Loss: 0.009414086933247745, Final Batch Loss: 0.0016499770572409034\n",
      "Epoch 1000, Loss: 0.004352363350335509, Final Batch Loss: 0.0037910453975200653\n",
      "Epoch 1001, Loss: 0.005560200312174857, Final Batch Loss: 0.0013888158136978745\n",
      "Epoch 1002, Loss: 0.004251372418366373, Final Batch Loss: 0.0016297627007588744\n",
      "Epoch 1003, Loss: 0.004701583660789765, Final Batch Loss: 0.00017506630683783442\n",
      "Epoch 1004, Loss: 0.00203987950226292, Final Batch Loss: 0.00047869276022538543\n",
      "Epoch 1005, Loss: 0.0016632998012937605, Final Batch Loss: 0.000543744012247771\n",
      "Epoch 1006, Loss: 0.00418047490529716, Final Batch Loss: 0.0016908198595046997\n",
      "Epoch 1007, Loss: 0.0043509131646715105, Final Batch Loss: 0.0036361252423375845\n",
      "Epoch 1008, Loss: 0.0013999936054460704, Final Batch Loss: 0.000640922284219414\n",
      "Epoch 1009, Loss: 0.009268559282645583, Final Batch Loss: 0.002261697081848979\n",
      "Epoch 1010, Loss: 0.0019953096634708345, Final Batch Loss: 0.0005882668192498386\n",
      "Epoch 1011, Loss: 0.002266571973450482, Final Batch Loss: 0.0010071102296933532\n",
      "Epoch 1012, Loss: 0.021430726628750563, Final Batch Loss: 0.0022998019121587276\n",
      "Epoch 1013, Loss: 0.011302057653665543, Final Batch Loss: 0.0031317146494984627\n",
      "Epoch 1014, Loss: 0.00899216951802373, Final Batch Loss: 0.007570330984890461\n",
      "Epoch 1015, Loss: 0.0014887388097122312, Final Batch Loss: 0.00031943758949637413\n",
      "Epoch 1016, Loss: 0.006731265690177679, Final Batch Loss: 0.0030501424334943295\n",
      "Epoch 1017, Loss: 0.0012803138233721256, Final Batch Loss: 0.00041600881377235055\n",
      "Epoch 1018, Loss: 0.003335410889121704, Final Batch Loss: 0.0002430718595860526\n",
      "Epoch 1019, Loss: 0.002737499075010419, Final Batch Loss: 0.0012199115008115768\n",
      "Epoch 1020, Loss: 0.0014974166988395154, Final Batch Loss: 0.0007718080887570977\n",
      "Epoch 1021, Loss: 0.003025769954547286, Final Batch Loss: 0.0018979394808411598\n",
      "Epoch 1022, Loss: 0.004866483395744581, Final Batch Loss: 6.709923763992265e-05\n",
      "Epoch 1023, Loss: 0.0014829369611106813, Final Batch Loss: 0.0003475830308161676\n",
      "Epoch 1024, Loss: 0.004643152584321797, Final Batch Loss: 0.0008701839251443744\n",
      "Epoch 1025, Loss: 0.019728546030819416, Final Batch Loss: 0.01364905945956707\n",
      "Epoch 1026, Loss: 0.009055278453161009, Final Batch Loss: 0.00018979721062351018\n",
      "Epoch 1027, Loss: 0.002512274484615773, Final Batch Loss: 0.0007013008580543101\n",
      "Epoch 1028, Loss: 0.005460711661726236, Final Batch Loss: 0.0034055064897984266\n",
      "Epoch 1029, Loss: 0.010075792961288244, Final Batch Loss: 0.009549817070364952\n",
      "Epoch 1030, Loss: 0.008109004236757755, Final Batch Loss: 0.0023990264162421227\n",
      "Epoch 1031, Loss: 0.0036379413213580847, Final Batch Loss: 0.0026054857298731804\n",
      "Epoch 1032, Loss: 0.0060895191272720695, Final Batch Loss: 0.004479576367884874\n",
      "Epoch 1033, Loss: 0.0034458081354387105, Final Batch Loss: 0.002924662549048662\n",
      "Epoch 1034, Loss: 0.006460154254455119, Final Batch Loss: 0.0006214439054019749\n",
      "Epoch 1035, Loss: 0.004064725246280432, Final Batch Loss: 0.0030740078072994947\n",
      "Epoch 1036, Loss: 0.001976812956854701, Final Batch Loss: 0.0014160656137391925\n",
      "Epoch 1037, Loss: 0.0028016290452796966, Final Batch Loss: 0.00046112763811834157\n",
      "Epoch 1038, Loss: 0.0034433293039910495, Final Batch Loss: 0.00255883252248168\n",
      "Epoch 1039, Loss: 0.016607481069513597, Final Batch Loss: 0.00016806555504444987\n",
      "Epoch 1040, Loss: 0.004500445211306214, Final Batch Loss: 0.0010136053897440434\n",
      "Epoch 1041, Loss: 0.01609501289203763, Final Batch Loss: 0.007482562679797411\n",
      "Epoch 1042, Loss: 0.0034039641031995416, Final Batch Loss: 0.0021738149225711823\n",
      "Epoch 1043, Loss: 0.0012341384281171486, Final Batch Loss: 6.27494155196473e-05\n",
      "Epoch 1044, Loss: 0.008752131136134267, Final Batch Loss: 0.006694382056593895\n",
      "Epoch 1045, Loss: 0.0018223000224679708, Final Batch Loss: 0.0007455702871084213\n",
      "Epoch 1046, Loss: 0.0019124916871078312, Final Batch Loss: 0.0011541559360921383\n",
      "Epoch 1047, Loss: 0.0021305858390405774, Final Batch Loss: 0.0006614552112296224\n",
      "Epoch 1048, Loss: 0.00688656693091616, Final Batch Loss: 0.006382654421031475\n",
      "Epoch 1049, Loss: 0.029925274662673473, Final Batch Loss: 0.008332447148859501\n",
      "Epoch 1050, Loss: 0.009898916352540255, Final Batch Loss: 0.0012325323186814785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051, Loss: 0.005885439924895763, Final Batch Loss: 0.0005716299638152122\n",
      "Epoch 1052, Loss: 0.002217402041424066, Final Batch Loss: 0.0005240201135165989\n",
      "Epoch 1053, Loss: 0.0030691290739923716, Final Batch Loss: 0.0017717631999403238\n",
      "Epoch 1054, Loss: 0.0013556783669628203, Final Batch Loss: 0.0007777675637044013\n",
      "Epoch 1055, Loss: 0.021402370533905923, Final Batch Loss: 0.0012386183952912688\n",
      "Epoch 1056, Loss: 0.004125807055970654, Final Batch Loss: 0.00012343339039944112\n",
      "Epoch 1057, Loss: 0.007189076306531206, Final Batch Loss: 0.0067633697763085365\n",
      "Epoch 1058, Loss: 0.003314509231131524, Final Batch Loss: 0.0003656325279735029\n",
      "Epoch 1059, Loss: 0.009689424856333062, Final Batch Loss: 0.00013373486581258476\n",
      "Epoch 1060, Loss: 0.003468202514341101, Final Batch Loss: 0.00041354759014211595\n",
      "Epoch 1061, Loss: 0.003917735535651445, Final Batch Loss: 0.0017533821519464254\n",
      "Epoch 1062, Loss: 0.007750387652777135, Final Batch Loss: 0.00664657074958086\n",
      "Epoch 1063, Loss: 0.000996000977465883, Final Batch Loss: 0.000278135557891801\n",
      "Epoch 1064, Loss: 0.002256576786749065, Final Batch Loss: 0.00107661634683609\n",
      "Epoch 1065, Loss: 0.004228860372677445, Final Batch Loss: 0.0020359563641250134\n",
      "Epoch 1066, Loss: 0.002922500716522336, Final Batch Loss: 0.00032920436933636665\n",
      "Epoch 1067, Loss: 0.011586186068598181, Final Batch Loss: 0.0002894770004786551\n",
      "Epoch 1068, Loss: 0.011990462895482779, Final Batch Loss: 0.0033645709045231342\n",
      "Epoch 1069, Loss: 0.0018902222509495914, Final Batch Loss: 0.000993648893199861\n",
      "Epoch 1070, Loss: 0.01140900980681181, Final Batch Loss: 0.010009048506617546\n",
      "Epoch 1071, Loss: 0.0066678370494628325, Final Batch Loss: 0.00021800353715661913\n",
      "Epoch 1072, Loss: 0.009225916350260377, Final Batch Loss: 0.002551642945036292\n",
      "Epoch 1073, Loss: 0.0036712890723720193, Final Batch Loss: 0.0019222523551434278\n",
      "Epoch 1074, Loss: 0.01362203003372997, Final Batch Loss: 0.0017718629678711295\n",
      "Epoch 1075, Loss: 0.0023206370533443987, Final Batch Loss: 0.001602842123247683\n",
      "Epoch 1076, Loss: 0.0011264344793744385, Final Batch Loss: 0.0004920442006550729\n",
      "Epoch 1077, Loss: 0.0022091291612014174, Final Batch Loss: 0.0005300856428220868\n",
      "Epoch 1078, Loss: 0.003525989828631282, Final Batch Loss: 0.0004979828372597694\n",
      "Epoch 1079, Loss: 0.0010651886404957622, Final Batch Loss: 0.00024699021014384925\n",
      "Epoch 1080, Loss: 0.008910445030778646, Final Batch Loss: 0.004629221279174089\n",
      "Epoch 1081, Loss: 0.0035816209856420755, Final Batch Loss: 0.0015757845249027014\n",
      "Epoch 1082, Loss: 0.0041905828402377665, Final Batch Loss: 0.0002822629758156836\n",
      "Epoch 1083, Loss: 0.0008311044075526297, Final Batch Loss: 0.0004353153635747731\n",
      "Epoch 1084, Loss: 0.003881293348968029, Final Batch Loss: 0.0023372822906821966\n",
      "Epoch 1085, Loss: 0.02992080827243626, Final Batch Loss: 0.0009462342131882906\n",
      "Epoch 1086, Loss: 0.0014505606959573925, Final Batch Loss: 0.0006945391651242971\n",
      "Epoch 1087, Loss: 0.052787921857088804, Final Batch Loss: 0.04865582659840584\n",
      "Epoch 1088, Loss: 0.00300993345445022, Final Batch Loss: 0.002131473505869508\n",
      "Epoch 1089, Loss: 0.005366362631320953, Final Batch Loss: 0.005121717695146799\n",
      "Epoch 1090, Loss: 0.013854268356226385, Final Batch Loss: 0.0017110867192968726\n",
      "Epoch 1091, Loss: 0.01140500402834732, Final Batch Loss: 0.00016762113955337554\n",
      "Epoch 1092, Loss: 0.00979815237224102, Final Batch Loss: 0.002146706450730562\n",
      "Epoch 1093, Loss: 0.0046443367609754205, Final Batch Loss: 0.000635479693301022\n",
      "Epoch 1094, Loss: 0.012844397686421871, Final Batch Loss: 0.006188997533172369\n",
      "Epoch 1095, Loss: 0.0017201238661073148, Final Batch Loss: 0.0006244268151931465\n",
      "Epoch 1096, Loss: 0.010125529253855348, Final Batch Loss: 0.009308811277151108\n",
      "Epoch 1097, Loss: 0.0026277213473804295, Final Batch Loss: 0.001977191772311926\n",
      "Epoch 1098, Loss: 0.003842896141577512, Final Batch Loss: 0.00019937200704589486\n",
      "Epoch 1099, Loss: 0.020773530937731266, Final Batch Loss: 0.018420424312353134\n",
      "Epoch 1100, Loss: 0.0017786854295991361, Final Batch Loss: 0.0009020924335345626\n",
      "Epoch 1101, Loss: 0.0026231732917949557, Final Batch Loss: 0.0002223061164841056\n",
      "Epoch 1102, Loss: 0.0014216593699529767, Final Batch Loss: 0.0011688786325976253\n",
      "Epoch 1103, Loss: 0.0014647412463091314, Final Batch Loss: 0.0008082151180133224\n",
      "Epoch 1104, Loss: 0.0030988777361926623, Final Batch Loss: 8.867646829457954e-05\n",
      "Epoch 1105, Loss: 0.005400691967224702, Final Batch Loss: 0.0003297425282653421\n",
      "Epoch 1106, Loss: 0.004996095201931894, Final Batch Loss: 0.0018391205230727792\n",
      "Epoch 1107, Loss: 0.003286137944087386, Final Batch Loss: 0.0026594260707497597\n",
      "Epoch 1108, Loss: 0.0031457318691536784, Final Batch Loss: 0.001292061759158969\n",
      "Epoch 1109, Loss: 0.00427954520273488, Final Batch Loss: 9.468400094192475e-05\n",
      "Epoch 1110, Loss: 0.0026797596365213394, Final Batch Loss: 0.00017895200289785862\n",
      "Epoch 1111, Loss: 0.007083716453053057, Final Batch Loss: 0.0007253625662997365\n",
      "Epoch 1112, Loss: 0.008043168345466256, Final Batch Loss: 0.0016903758514672518\n",
      "Epoch 1113, Loss: 0.012186962820123881, Final Batch Loss: 0.011618567630648613\n",
      "Epoch 1114, Loss: 0.004335955498390831, Final Batch Loss: 0.0001656573876971379\n",
      "Epoch 1115, Loss: 0.001867409737315029, Final Batch Loss: 0.0012328801676630974\n",
      "Epoch 1116, Loss: 0.0010604795825202018, Final Batch Loss: 0.00045229363604448736\n",
      "Epoch 1117, Loss: 0.0018214726587757468, Final Batch Loss: 0.000781892566010356\n",
      "Epoch 1118, Loss: 0.009655475267209113, Final Batch Loss: 0.008907919749617577\n",
      "Epoch 1119, Loss: 0.001128749194322154, Final Batch Loss: 0.0001153059711214155\n",
      "Epoch 1120, Loss: 0.012238731607794762, Final Batch Loss: 0.004182427190244198\n",
      "Epoch 1121, Loss: 0.004324629902839661, Final Batch Loss: 0.0012055544648319483\n",
      "Epoch 1122, Loss: 0.01141860568895936, Final Batch Loss: 0.005392644088715315\n",
      "Epoch 1123, Loss: 0.0070890437345951796, Final Batch Loss: 0.004853487480431795\n",
      "Epoch 1124, Loss: 0.0018362149130553007, Final Batch Loss: 0.0006777736125513911\n",
      "Epoch 1125, Loss: 0.005935146240517497, Final Batch Loss: 0.001988397678360343\n",
      "Epoch 1126, Loss: 0.0012245714897289872, Final Batch Loss: 0.0005178563296794891\n",
      "Epoch 1127, Loss: 0.003958221626817249, Final Batch Loss: 0.00024400731490459293\n",
      "Epoch 1128, Loss: 0.003965926298405975, Final Batch Loss: 0.0031361745204776525\n",
      "Epoch 1129, Loss: 0.010043294751085341, Final Batch Loss: 0.0005433425540104508\n",
      "Epoch 1130, Loss: 0.0057850879384204745, Final Batch Loss: 0.0008227656362578273\n",
      "Epoch 1131, Loss: 0.0006248141289688647, Final Batch Loss: 0.0003654477186501026\n",
      "Epoch 1132, Loss: 0.005533755989745259, Final Batch Loss: 0.00433342857286334\n",
      "Epoch 1133, Loss: 0.0017514145583845675, Final Batch Loss: 0.00044167664600536227\n",
      "Epoch 1134, Loss: 0.008943293476477265, Final Batch Loss: 0.005073848180472851\n",
      "Epoch 1135, Loss: 0.01220954186283052, Final Batch Loss: 0.010028066113591194\n",
      "Epoch 1136, Loss: 0.0003906619385816157, Final Batch Loss: 0.00012746232096105814\n",
      "Epoch 1137, Loss: 0.00386753462953493, Final Batch Loss: 0.0006033873069100082\n",
      "Epoch 1138, Loss: 0.01944744703359902, Final Batch Loss: 0.015544638969004154\n",
      "Epoch 1139, Loss: 0.009073856985196471, Final Batch Loss: 0.0067667714320123196\n",
      "Epoch 1140, Loss: 0.0013901967904530466, Final Batch Loss: 0.00025617884239181876\n",
      "Epoch 1141, Loss: 0.009218031540513039, Final Batch Loss: 0.006592705845832825\n",
      "Epoch 1142, Loss: 0.0012871072685811669, Final Batch Loss: 0.0001419280015397817\n",
      "Epoch 1143, Loss: 0.0005392366438172758, Final Batch Loss: 8.204090408980846e-05\n",
      "Epoch 1144, Loss: 0.0024575438583269715, Final Batch Loss: 0.00014713627751916647\n",
      "Epoch 1145, Loss: 0.003548389533534646, Final Batch Loss: 0.0004954936448484659\n",
      "Epoch 1146, Loss: 0.0026831788709387183, Final Batch Loss: 0.0008752786088734865\n",
      "Epoch 1147, Loss: 0.005807217792607844, Final Batch Loss: 0.001480901730246842\n",
      "Epoch 1148, Loss: 0.00614116876386106, Final Batch Loss: 0.003945450764149427\n",
      "Epoch 1149, Loss: 0.006830902770161629, Final Batch Loss: 0.002543959766626358\n",
      "Epoch 1150, Loss: 0.001124715810874477, Final Batch Loss: 0.0008410564623773098\n",
      "Epoch 1151, Loss: 0.01222203322686255, Final Batch Loss: 0.003373889485374093\n",
      "Epoch 1152, Loss: 0.004949995956849307, Final Batch Loss: 0.00422812020406127\n",
      "Epoch 1153, Loss: 0.006870284792967141, Final Batch Loss: 0.005873929709196091\n",
      "Epoch 1154, Loss: 0.003165649017319083, Final Batch Loss: 0.0021678342018276453\n",
      "Epoch 1155, Loss: 0.0044857802568003535, Final Batch Loss: 0.002649928443133831\n",
      "Epoch 1156, Loss: 0.0007926132093416527, Final Batch Loss: 0.00020035869965795428\n",
      "Epoch 1157, Loss: 0.002273993392009288, Final Batch Loss: 0.0006648264243267477\n",
      "Epoch 1158, Loss: 0.006026591174304485, Final Batch Loss: 0.00035189418122172356\n",
      "Epoch 1159, Loss: 0.0024013825168367475, Final Batch Loss: 0.00027621895424090326\n",
      "Epoch 1160, Loss: 0.002448109386023134, Final Batch Loss: 0.0006746453582309186\n",
      "Epoch 1161, Loss: 0.006448909407481551, Final Batch Loss: 0.005838336423039436\n",
      "Epoch 1162, Loss: 0.0017323278007097542, Final Batch Loss: 0.0007067564292810857\n",
      "Epoch 1163, Loss: 0.01694057509303093, Final Batch Loss: 0.0039059296250343323\n",
      "Epoch 1164, Loss: 0.0035157093370798975, Final Batch Loss: 0.00019340278231538832\n",
      "Epoch 1165, Loss: 0.0004590970347635448, Final Batch Loss: 0.00010882655624300241\n",
      "Epoch 1166, Loss: 0.005275642266497016, Final Batch Loss: 0.002887028269469738\n",
      "Epoch 1167, Loss: 0.0013946117251180112, Final Batch Loss: 0.0007586510037072003\n",
      "Epoch 1168, Loss: 0.0007586038045701571, Final Batch Loss: 7.486303366022184e-05\n",
      "Epoch 1169, Loss: 0.001912656705826521, Final Batch Loss: 0.0009501700988039374\n",
      "Epoch 1170, Loss: 0.0016643093549646437, Final Batch Loss: 0.0011391189182177186\n",
      "Epoch 1171, Loss: 0.0026378484726592433, Final Batch Loss: 5.822300954605453e-05\n",
      "Epoch 1172, Loss: 0.0023648287751711905, Final Batch Loss: 0.00026656483532860875\n",
      "Epoch 1173, Loss: 0.0010221865959465504, Final Batch Loss: 0.0005187052884139121\n",
      "Epoch 1174, Loss: 0.002665856358362362, Final Batch Loss: 0.0023856668267399073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1175, Loss: 0.0039358403300866485, Final Batch Loss: 0.0007169524906203151\n",
      "Epoch 1176, Loss: 0.0036339997895993292, Final Batch Loss: 0.0027058585546910763\n",
      "Epoch 1177, Loss: 0.0014339684857986867, Final Batch Loss: 0.00022255658404901624\n",
      "Epoch 1178, Loss: 0.003945603035390377, Final Batch Loss: 0.002608210314065218\n",
      "Epoch 1179, Loss: 0.0014205725165084004, Final Batch Loss: 0.0008072120253928006\n",
      "Epoch 1180, Loss: 0.002101598831359297, Final Batch Loss: 0.0008539391565136611\n",
      "Epoch 1181, Loss: 0.000707111248630099, Final Batch Loss: 0.00020789225527551025\n",
      "Epoch 1182, Loss: 0.015064794104546309, Final Batch Loss: 0.008017824962735176\n",
      "Epoch 1183, Loss: 0.005841014150064439, Final Batch Loss: 0.0006232719752006233\n",
      "Epoch 1184, Loss: 0.0023762185592204332, Final Batch Loss: 0.0011222087778151035\n",
      "Epoch 1185, Loss: 0.0022430947283282876, Final Batch Loss: 0.0010045850649476051\n",
      "Epoch 1186, Loss: 0.0031001222814666107, Final Batch Loss: 0.00024195802689064294\n",
      "Epoch 1187, Loss: 0.011266612680628896, Final Batch Loss: 0.010156374424695969\n",
      "Epoch 1188, Loss: 0.002221332222688943, Final Batch Loss: 0.0009522595792077482\n",
      "Epoch 1189, Loss: 0.005059123854152858, Final Batch Loss: 0.00455873366445303\n",
      "Epoch 1190, Loss: 0.0014813224770477973, Final Batch Loss: 7.716347317909822e-05\n",
      "Epoch 1191, Loss: 0.0011035171191906556, Final Batch Loss: 0.0001922597730299458\n",
      "Epoch 1192, Loss: 0.004111762100365013, Final Batch Loss: 0.00045347673585638404\n",
      "Epoch 1193, Loss: 0.0058996714651584625, Final Batch Loss: 0.0025093171279877424\n",
      "Epoch 1194, Loss: 0.03739265908370726, Final Batch Loss: 0.00023585368762724102\n",
      "Epoch 1195, Loss: 0.012346324045211077, Final Batch Loss: 0.009246614761650562\n",
      "Epoch 1196, Loss: 0.0009626752871554345, Final Batch Loss: 0.0005524661391973495\n",
      "Epoch 1197, Loss: 0.0017107478925026953, Final Batch Loss: 0.0009510627132840455\n",
      "Epoch 1198, Loss: 0.03906033013481647, Final Batch Loss: 0.0018211324932053685\n",
      "Epoch 1199, Loss: 0.0003391842619748786, Final Batch Loss: 9.491034143138677e-05\n",
      "Epoch 1200, Loss: 0.0028700563707388937, Final Batch Loss: 0.0023293776903301477\n",
      "Epoch 1201, Loss: 0.017150032857898623, Final Batch Loss: 0.0003891713568009436\n",
      "Epoch 1202, Loss: 0.0029024351679254323, Final Batch Loss: 0.00022279194672591984\n",
      "Epoch 1203, Loss: 0.001131443161284551, Final Batch Loss: 0.0002208066580351442\n",
      "Epoch 1204, Loss: 0.0010689465561881661, Final Batch Loss: 0.0006386700551956892\n",
      "Epoch 1205, Loss: 0.0018051409278996289, Final Batch Loss: 0.0007554108160547912\n",
      "Epoch 1206, Loss: 0.002823364397045225, Final Batch Loss: 0.0003256694762967527\n",
      "Epoch 1207, Loss: 0.0035199556732550263, Final Batch Loss: 0.0023912284523248672\n",
      "Epoch 1208, Loss: 0.0031974322628229856, Final Batch Loss: 0.001113485312089324\n",
      "Epoch 1209, Loss: 0.0130637944675982, Final Batch Loss: 0.006296963430941105\n",
      "Epoch 1210, Loss: 0.011104735531262122, Final Batch Loss: 0.0001899842027341947\n",
      "Epoch 1211, Loss: 0.0030059925047680736, Final Batch Loss: 0.0005052118794992566\n",
      "Epoch 1212, Loss: 0.0013509247364709154, Final Batch Loss: 0.00017357351316604763\n",
      "Epoch 1213, Loss: 0.00442733388626948, Final Batch Loss: 0.003873802488669753\n",
      "Epoch 1214, Loss: 0.021954664029181004, Final Batch Loss: 0.0006392942741513252\n",
      "Epoch 1215, Loss: 0.0037812708760611713, Final Batch Loss: 0.003026641206815839\n",
      "Epoch 1216, Loss: 0.0019381909514777362, Final Batch Loss: 0.001025778823532164\n",
      "Epoch 1217, Loss: 0.0009722073446027935, Final Batch Loss: 0.0007220678962767124\n",
      "Epoch 1218, Loss: 0.0016456005105283111, Final Batch Loss: 0.00012941911700181663\n",
      "Epoch 1219, Loss: 0.011287575354799628, Final Batch Loss: 0.007545440923422575\n",
      "Epoch 1220, Loss: 0.002087764529278502, Final Batch Loss: 0.00014376462786458433\n",
      "Epoch 1221, Loss: 0.004545417497865856, Final Batch Loss: 0.0033619331661611795\n",
      "Epoch 1222, Loss: 0.0038064997643232346, Final Batch Loss: 0.002762372139841318\n",
      "Epoch 1223, Loss: 0.021968612709315494, Final Batch Loss: 0.00043458331492729485\n",
      "Epoch 1224, Loss: 0.00960913859307766, Final Batch Loss: 0.004176220390945673\n",
      "Epoch 1225, Loss: 0.017907408881001174, Final Batch Loss: 0.0006380545673891902\n",
      "Epoch 1226, Loss: 0.0019303099834360182, Final Batch Loss: 0.0009607383981347084\n",
      "Epoch 1227, Loss: 0.0054594220709986985, Final Batch Loss: 0.0008725824882276356\n",
      "Epoch 1228, Loss: 0.00048723175132181495, Final Batch Loss: 0.00018786692817229778\n",
      "Epoch 1229, Loss: 0.007676288951188326, Final Batch Loss: 0.003139176405966282\n",
      "Epoch 1230, Loss: 0.006649674731306732, Final Batch Loss: 0.0010795051930472255\n",
      "Epoch 1231, Loss: 0.016247653402388096, Final Batch Loss: 0.015707504004240036\n",
      "Epoch 1232, Loss: 0.04117441922426224, Final Batch Loss: 0.017978142946958542\n",
      "Epoch 1233, Loss: 0.027730868896469474, Final Batch Loss: 0.003371139755472541\n",
      "Epoch 1234, Loss: 0.0018930606747744605, Final Batch Loss: 0.00024337104696314782\n",
      "Epoch 1235, Loss: 0.0016792040842119604, Final Batch Loss: 0.0004557549546007067\n",
      "Epoch 1236, Loss: 0.0024221459752880037, Final Batch Loss: 0.0004842945490963757\n",
      "Epoch 1237, Loss: 0.005177864921279252, Final Batch Loss: 0.0005640374729409814\n",
      "Epoch 1238, Loss: 0.0005490750045282766, Final Batch Loss: 0.00032609954359941185\n",
      "Epoch 1239, Loss: 0.011104341130703688, Final Batch Loss: 0.00026895711198449135\n",
      "Epoch 1240, Loss: 0.004340417915955186, Final Batch Loss: 0.001971332123503089\n",
      "Epoch 1241, Loss: 0.011525168200023472, Final Batch Loss: 0.009990801103413105\n",
      "Epoch 1242, Loss: 0.002770265913568437, Final Batch Loss: 0.002282225526869297\n",
      "Epoch 1243, Loss: 0.0009575701988069341, Final Batch Loss: 0.0007484695524908602\n",
      "Epoch 1244, Loss: 0.0016604967531748116, Final Batch Loss: 0.0007724235183559358\n",
      "Epoch 1245, Loss: 0.003986957832239568, Final Batch Loss: 0.0018304168479517102\n",
      "Epoch 1246, Loss: 0.003677292261272669, Final Batch Loss: 0.0009915116243064404\n",
      "Epoch 1247, Loss: 0.00435382837895304, Final Batch Loss: 0.0029392566066235304\n",
      "Epoch 1248, Loss: 0.008010324323549867, Final Batch Loss: 0.003302378812804818\n",
      "Epoch 1249, Loss: 0.004148549400269985, Final Batch Loss: 0.001965308329090476\n",
      "Epoch 1250, Loss: 0.0011320719495415688, Final Batch Loss: 0.0005257456796243787\n",
      "Epoch 1251, Loss: 0.0013065017119515687, Final Batch Loss: 0.0003410639183130115\n",
      "Epoch 1252, Loss: 0.010064668487757444, Final Batch Loss: 0.009179995395243168\n",
      "Epoch 1253, Loss: 0.01309055408637505, Final Batch Loss: 0.00016571527521591634\n",
      "Epoch 1254, Loss: 0.013797865714877844, Final Batch Loss: 0.003025457728654146\n",
      "Epoch 1255, Loss: 0.004691928159445524, Final Batch Loss: 0.001539865043014288\n",
      "Epoch 1256, Loss: 0.008072330325376242, Final Batch Loss: 0.0005763379740528762\n",
      "Epoch 1257, Loss: 0.004908745351713151, Final Batch Loss: 0.00014541455311700702\n",
      "Epoch 1258, Loss: 0.0016424023197032511, Final Batch Loss: 0.00041036290349438787\n",
      "Epoch 1259, Loss: 0.00177726786932908, Final Batch Loss: 0.00017569700139574707\n",
      "Epoch 1260, Loss: 0.0018542460747994483, Final Batch Loss: 0.000554017664398998\n",
      "Epoch 1261, Loss: 0.0010278283752995776, Final Batch Loss: 2.456380934745539e-05\n",
      "Epoch 1262, Loss: 0.015324705746024847, Final Batch Loss: 0.009974983520805836\n",
      "Epoch 1263, Loss: 0.0027229675324633718, Final Batch Loss: 0.0016328433994203806\n",
      "Epoch 1264, Loss: 0.006631294236285612, Final Batch Loss: 0.00015712526510469615\n",
      "Epoch 1265, Loss: 0.00481206615222618, Final Batch Loss: 0.0005865750717930496\n",
      "Epoch 1266, Loss: 0.002611853531561792, Final Batch Loss: 0.001881314441561699\n",
      "Epoch 1267, Loss: 0.0009064886253327131, Final Batch Loss: 0.00012975954450666904\n",
      "Epoch 1268, Loss: 0.003054001717828214, Final Batch Loss: 0.0024667158722877502\n",
      "Epoch 1269, Loss: 0.002109354711137712, Final Batch Loss: 0.0011327053653076291\n",
      "Epoch 1270, Loss: 0.004839048866415396, Final Batch Loss: 0.0002612109819892794\n",
      "Epoch 1271, Loss: 0.002040888153715059, Final Batch Loss: 0.0003969728422816843\n",
      "Epoch 1272, Loss: 0.0004570793971652165, Final Batch Loss: 0.0002515320375096053\n",
      "Epoch 1273, Loss: 0.0012006441538687795, Final Batch Loss: 0.0003960805188398808\n",
      "Epoch 1274, Loss: 0.00613027362851426, Final Batch Loss: 0.00021404045401141047\n",
      "Epoch 1275, Loss: 0.008453709073364735, Final Batch Loss: 0.0007207905873656273\n",
      "Epoch 1276, Loss: 0.0034039897145703435, Final Batch Loss: 0.002175169298425317\n",
      "Epoch 1277, Loss: 0.005066127050668001, Final Batch Loss: 0.0009047803469002247\n",
      "Epoch 1278, Loss: 0.002000194101128727, Final Batch Loss: 0.0011347595136612654\n",
      "Epoch 1279, Loss: 0.002001049775572028, Final Batch Loss: 6.791608029743657e-05\n",
      "Epoch 1280, Loss: 0.0004001068737125024, Final Batch Loss: 0.000214726896956563\n",
      "Epoch 1281, Loss: 0.0005342971708159894, Final Batch Loss: 0.00014752740389667451\n",
      "Epoch 1282, Loss: 0.004136320945690386, Final Batch Loss: 0.00018858238763641566\n",
      "Epoch 1283, Loss: 0.005194294120883569, Final Batch Loss: 0.00016720438725315034\n",
      "Epoch 1284, Loss: 0.005135479848831892, Final Batch Loss: 0.000598592683672905\n",
      "Epoch 1285, Loss: 0.0020533967326628044, Final Batch Loss: 0.00019982685626018792\n",
      "Epoch 1286, Loss: 0.003697675361763686, Final Batch Loss: 0.002899022540077567\n",
      "Epoch 1287, Loss: 0.011680080177029595, Final Batch Loss: 0.00030574723496101797\n",
      "Epoch 1288, Loss: 0.007094039276125841, Final Batch Loss: 0.00021401156845968217\n",
      "Epoch 1289, Loss: 0.0017850142321549356, Final Batch Loss: 0.0006307000876404345\n",
      "Epoch 1290, Loss: 0.00041045137913897634, Final Batch Loss: 0.00021127476065885276\n",
      "Epoch 1291, Loss: 0.0023559536784887314, Final Batch Loss: 0.0013045285595580935\n",
      "Epoch 1292, Loss: 0.005856632604263723, Final Batch Loss: 0.004708323627710342\n",
      "Epoch 1293, Loss: 0.0039636221481487155, Final Batch Loss: 0.002799905138090253\n",
      "Epoch 1294, Loss: 0.0010383259505033493, Final Batch Loss: 0.0005066244048066437\n",
      "Epoch 1295, Loss: 0.004745985381305218, Final Batch Loss: 0.0033649993129074574\n",
      "Epoch 1296, Loss: 0.005615265225060284, Final Batch Loss: 0.001381712150759995\n",
      "Epoch 1297, Loss: 0.0015021467115730047, Final Batch Loss: 0.0011677468428388238\n",
      "Epoch 1298, Loss: 0.0015416965907206759, Final Batch Loss: 0.0013193620834499598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1299, Loss: 0.006292391917668283, Final Batch Loss: 0.005446207709610462\n",
      "Epoch 1300, Loss: 0.0010849200480151922, Final Batch Loss: 0.0007015764713287354\n",
      "Epoch 1301, Loss: 0.010959791019558907, Final Batch Loss: 0.006251445040106773\n",
      "Epoch 1302, Loss: 0.019643001403892413, Final Batch Loss: 0.00025502234348095953\n",
      "Epoch 1303, Loss: 0.0011878788936883211, Final Batch Loss: 0.000392434885725379\n",
      "Epoch 1304, Loss: 0.0010534220054978505, Final Batch Loss: 8.054527279455215e-05\n",
      "Epoch 1305, Loss: 0.037452653516083956, Final Batch Loss: 0.03313291072845459\n",
      "Epoch 1306, Loss: 0.032470909878611565, Final Batch Loss: 0.0236275102943182\n",
      "Epoch 1307, Loss: 0.0018022701842710376, Final Batch Loss: 0.0010486026294529438\n",
      "Epoch 1308, Loss: 0.0009635891037760302, Final Batch Loss: 0.00022411356621887535\n",
      "Epoch 1309, Loss: 0.0020803570660063997, Final Batch Loss: 0.00017082459817174822\n",
      "Epoch 1310, Loss: 0.003626283592893742, Final Batch Loss: 0.0001479369675507769\n",
      "Epoch 1311, Loss: 0.016712977085262537, Final Batch Loss: 0.012730931863188744\n",
      "Epoch 1312, Loss: 0.001501881779404357, Final Batch Loss: 0.0003661683585960418\n",
      "Epoch 1313, Loss: 0.008022990776225924, Final Batch Loss: 0.0009876273106783628\n",
      "Epoch 1314, Loss: 0.003072113380767405, Final Batch Loss: 0.0016484211664646864\n",
      "Epoch 1315, Loss: 0.0022363175230566412, Final Batch Loss: 0.0004624070425052196\n",
      "Epoch 1316, Loss: 0.002964672719826922, Final Batch Loss: 0.0001703792659100145\n",
      "Epoch 1317, Loss: 0.0070662659127265215, Final Batch Loss: 0.00346636981703341\n",
      "Epoch 1318, Loss: 0.001607019396033138, Final Batch Loss: 0.0004405530053190887\n",
      "Epoch 1319, Loss: 0.005539533158298582, Final Batch Loss: 0.0006529194652102888\n",
      "Epoch 1320, Loss: 0.0024129492230713367, Final Batch Loss: 0.0011572919320315123\n",
      "Epoch 1321, Loss: 0.005471749464049935, Final Batch Loss: 0.000986636383458972\n",
      "Epoch 1322, Loss: 0.0015891043585725129, Final Batch Loss: 0.000749875558540225\n",
      "Epoch 1323, Loss: 0.0038784892531111836, Final Batch Loss: 0.0005137455882504582\n",
      "Epoch 1324, Loss: 0.001302862525335513, Final Batch Loss: 0.00014898610243108124\n",
      "Epoch 1325, Loss: 0.003373310319148004, Final Batch Loss: 0.002753743203356862\n",
      "Epoch 1326, Loss: 0.007969198748469353, Final Batch Loss: 0.004791576415300369\n",
      "Epoch 1327, Loss: 0.0011035166098736227, Final Batch Loss: 0.0004122453392483294\n",
      "Epoch 1328, Loss: 0.021364753134548664, Final Batch Loss: 0.006235121749341488\n",
      "Epoch 1329, Loss: 0.00897068646736443, Final Batch Loss: 0.007916802540421486\n",
      "Epoch 1330, Loss: 0.0073126350762322545, Final Batch Loss: 0.0010389938252046704\n",
      "Epoch 1331, Loss: 0.001330292274360545, Final Batch Loss: 0.0001788303052308038\n",
      "Epoch 1332, Loss: 0.002105346415191889, Final Batch Loss: 0.0007143671391531825\n",
      "Epoch 1333, Loss: 0.002741521690040827, Final Batch Loss: 0.0011190759250894189\n",
      "Epoch 1334, Loss: 0.0019211331382393837, Final Batch Loss: 0.001341888215392828\n",
      "Epoch 1335, Loss: 0.004214382148347795, Final Batch Loss: 0.003940653521567583\n",
      "Epoch 1336, Loss: 0.019691905938088894, Final Batch Loss: 0.006762191653251648\n",
      "Epoch 1337, Loss: 0.00359862222103402, Final Batch Loss: 0.0006356343510560691\n",
      "Epoch 1338, Loss: 0.0031166455009952188, Final Batch Loss: 0.0001219090772792697\n",
      "Epoch 1339, Loss: 0.007342084776610136, Final Batch Loss: 0.004201811272650957\n",
      "Epoch 1340, Loss: 0.000926507287658751, Final Batch Loss: 0.0004765786579810083\n",
      "Epoch 1341, Loss: 0.0010039769113063812, Final Batch Loss: 0.0005100431153550744\n",
      "Epoch 1342, Loss: 0.004067572299391031, Final Batch Loss: 0.0006369540933519602\n",
      "Epoch 1343, Loss: 0.0035794464929495007, Final Batch Loss: 5.829325527884066e-05\n",
      "Epoch 1344, Loss: 0.017366930842399597, Final Batch Loss: 0.0026096161454916\n",
      "Epoch 1345, Loss: 0.0017503592534922063, Final Batch Loss: 0.001180377439595759\n",
      "Epoch 1346, Loss: 0.0010039248445536941, Final Batch Loss: 0.0002883040870074183\n",
      "Epoch 1347, Loss: 0.0007820625614840537, Final Batch Loss: 0.00040021163295023143\n",
      "Epoch 1348, Loss: 0.0014918667438905686, Final Batch Loss: 0.0004638464597519487\n",
      "Epoch 1349, Loss: 0.005123488488607109, Final Batch Loss: 0.004611227661371231\n",
      "Epoch 1350, Loss: 0.0031671469332650304, Final Batch Loss: 0.0011676616268232465\n",
      "Epoch 1351, Loss: 0.0038894928875379264, Final Batch Loss: 0.0009193757432512939\n",
      "Epoch 1352, Loss: 0.002432969748042524, Final Batch Loss: 0.0008646580390632153\n",
      "Epoch 1353, Loss: 0.006917120364960283, Final Batch Loss: 0.006218445487320423\n",
      "Epoch 1354, Loss: 0.016289888182654977, Final Batch Loss: 0.00021720887161791325\n",
      "Epoch 1355, Loss: 0.0023162919096648693, Final Batch Loss: 0.0007969537982717156\n",
      "Epoch 1356, Loss: 0.0005707413365598768, Final Batch Loss: 0.00029959878884255886\n",
      "Epoch 1357, Loss: 0.0019522359943948686, Final Batch Loss: 0.0015583912609145045\n",
      "Epoch 1358, Loss: 0.005714380356948823, Final Batch Loss: 0.00021467654732987285\n",
      "Epoch 1359, Loss: 0.009943060344085097, Final Batch Loss: 0.007659242022782564\n",
      "Epoch 1360, Loss: 0.0010934379533864558, Final Batch Loss: 0.00027360679814592004\n",
      "Epoch 1361, Loss: 0.006048142386134714, Final Batch Loss: 0.00549963628873229\n",
      "Epoch 1362, Loss: 0.0017130193882621825, Final Batch Loss: 0.0005647575599141419\n",
      "Epoch 1363, Loss: 0.012747826986014843, Final Batch Loss: 0.0012000435963273048\n",
      "Epoch 1364, Loss: 0.004917241574730724, Final Batch Loss: 0.0006015397957526147\n",
      "Epoch 1365, Loss: 0.0010846061049960554, Final Batch Loss: 0.0003077419241890311\n",
      "Epoch 1366, Loss: 0.0017367697437293828, Final Batch Loss: 7.185543654486537e-05\n",
      "Epoch 1367, Loss: 0.006486287631560117, Final Batch Loss: 0.005766382906585932\n",
      "Epoch 1368, Loss: 0.002914231037721038, Final Batch Loss: 0.0018607802921906114\n",
      "Epoch 1369, Loss: 0.0035149090690538287, Final Batch Loss: 0.001270587439648807\n",
      "Epoch 1370, Loss: 0.002374637871980667, Final Batch Loss: 0.0012252199230715632\n",
      "Epoch 1371, Loss: 0.0035140393883921206, Final Batch Loss: 0.0029483221005648375\n",
      "Epoch 1372, Loss: 0.00337387400213629, Final Batch Loss: 0.0011207001516595483\n",
      "Epoch 1373, Loss: 0.0014814066380495206, Final Batch Loss: 0.0001939581852639094\n",
      "Epoch 1374, Loss: 0.0008056966180447489, Final Batch Loss: 0.00031636658241041005\n",
      "Epoch 1375, Loss: 0.0033866394660435617, Final Batch Loss: 0.0004375858115963638\n",
      "Epoch 1376, Loss: 0.0032287978392560035, Final Batch Loss: 0.00026318177697248757\n",
      "Epoch 1377, Loss: 0.008347662864252925, Final Batch Loss: 0.003284529550001025\n",
      "Epoch 1378, Loss: 0.008301879395730793, Final Batch Loss: 0.007748179137706757\n",
      "Epoch 1379, Loss: 0.00177052165963687, Final Batch Loss: 0.000383118080208078\n",
      "Epoch 1380, Loss: 0.0012898324057459831, Final Batch Loss: 0.0009156254236586392\n",
      "Epoch 1381, Loss: 0.0017951454210560769, Final Batch Loss: 0.0003333826025482267\n",
      "Epoch 1382, Loss: 0.0014415897603612393, Final Batch Loss: 0.001005786471068859\n",
      "Epoch 1383, Loss: 0.014839772331470158, Final Batch Loss: 9.425656025996432e-05\n",
      "Epoch 1384, Loss: 0.0045020617471891455, Final Batch Loss: 5.658668669639155e-05\n",
      "Epoch 1385, Loss: 0.0005939709371887147, Final Batch Loss: 0.00015729592996649444\n",
      "Epoch 1386, Loss: 0.0008939840627135709, Final Batch Loss: 0.00018845884187612683\n",
      "Epoch 1387, Loss: 0.0051902353297919035, Final Batch Loss: 0.0024538240395486355\n",
      "Epoch 1388, Loss: 0.0005498910031747073, Final Batch Loss: 0.0001192501513287425\n",
      "Epoch 1389, Loss: 0.0008937742386478931, Final Batch Loss: 0.0005090396152809262\n",
      "Epoch 1390, Loss: 0.001283891120692715, Final Batch Loss: 0.0002539978304412216\n",
      "Epoch 1391, Loss: 0.004007124429335818, Final Batch Loss: 0.0003323604760225862\n",
      "Epoch 1392, Loss: 0.006770480016712099, Final Batch Loss: 0.005870175547897816\n",
      "Epoch 1393, Loss: 0.0013338287826627493, Final Batch Loss: 0.0006162996287457645\n",
      "Epoch 1394, Loss: 0.011268342539551668, Final Batch Loss: 0.00023909441370051354\n",
      "Epoch 1395, Loss: 0.0060126330208731815, Final Batch Loss: 0.0001915665779961273\n",
      "Epoch 1396, Loss: 0.003241624537622556, Final Batch Loss: 0.00025331121287308633\n",
      "Epoch 1397, Loss: 0.0012274996552150697, Final Batch Loss: 0.0009350112522952259\n",
      "Epoch 1398, Loss: 0.0007015614173724316, Final Batch Loss: 0.000610346207395196\n",
      "Epoch 1399, Loss: 0.0033780711237341166, Final Batch Loss: 0.000649566063657403\n",
      "Epoch 1400, Loss: 0.001688184420345351, Final Batch Loss: 0.0012569647515192628\n",
      "Epoch 1401, Loss: 0.007649726343515795, Final Batch Loss: 0.007555603515356779\n",
      "Epoch 1402, Loss: 0.010056645551230758, Final Batch Loss: 0.00935880932956934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1403, Loss: 0.0009531346731819212, Final Batch Loss: 0.00035687547642737627\n",
      "Epoch 1404, Loss: 0.004166052327491343, Final Batch Loss: 0.0005455295322462916\n",
      "Epoch 1405, Loss: 0.002132594418071676, Final Batch Loss: 6.28382622380741e-05\n",
      "Epoch 1406, Loss: 0.0006629290292039514, Final Batch Loss: 0.0002917893580161035\n",
      "Epoch 1407, Loss: 0.0010308563796570525, Final Batch Loss: 0.00012000328570138663\n",
      "Epoch 1408, Loss: 0.02538858275511302, Final Batch Loss: 0.0004312853852752596\n",
      "Epoch 1409, Loss: 0.001266971870791167, Final Batch Loss: 0.0005114356754347682\n",
      "Epoch 1410, Loss: 0.0018548560183262452, Final Batch Loss: 0.0016975681064650416\n",
      "Epoch 1411, Loss: 0.0018239007331430912, Final Batch Loss: 0.0006722387624904513\n",
      "Epoch 1412, Loss: 0.0033592189429327846, Final Batch Loss: 0.0021925526671111584\n",
      "Epoch 1413, Loss: 0.0027530633378773928, Final Batch Loss: 0.0014126076130196452\n",
      "Epoch 1414, Loss: 0.001423013411113061, Final Batch Loss: 0.00010111603478435427\n",
      "Epoch 1415, Loss: 0.01205029257107526, Final Batch Loss: 0.011634549126029015\n",
      "Epoch 1416, Loss: 0.001229493587743491, Final Batch Loss: 0.0007217679522000253\n",
      "Epoch 1417, Loss: 0.0023258269648067653, Final Batch Loss: 0.0020234144758433104\n",
      "Epoch 1418, Loss: 0.0033101029112003744, Final Batch Loss: 0.002479230985045433\n",
      "Epoch 1419, Loss: 0.001400920154992491, Final Batch Loss: 0.0006075174314901233\n",
      "Epoch 1420, Loss: 0.004757627670187503, Final Batch Loss: 0.00033971230732277036\n",
      "Epoch 1421, Loss: 0.0005604406032944098, Final Batch Loss: 8.616775448899716e-05\n",
      "Epoch 1422, Loss: 0.002874948986573145, Final Batch Loss: 0.0026238777209073305\n",
      "Epoch 1423, Loss: 0.009638769886805676, Final Batch Loss: 0.009419414214789867\n",
      "Epoch 1424, Loss: 0.0009986770746763796, Final Batch Loss: 0.0005642044707201421\n",
      "Epoch 1425, Loss: 0.004527881334070116, Final Batch Loss: 0.0038338552694767714\n",
      "Epoch 1426, Loss: 0.01439213182311505, Final Batch Loss: 0.0005700037581846118\n",
      "Epoch 1427, Loss: 0.009076474932953715, Final Batch Loss: 0.006185343023389578\n",
      "Epoch 1428, Loss: 0.01836860051844269, Final Batch Loss: 0.0178571417927742\n",
      "Epoch 1429, Loss: 0.0027718351338990033, Final Batch Loss: 0.00034291791962459683\n",
      "Epoch 1430, Loss: 0.004229803802445531, Final Batch Loss: 0.00226520374417305\n",
      "Epoch 1431, Loss: 0.0011100900592282414, Final Batch Loss: 0.0004263320588506758\n",
      "Epoch 1432, Loss: 0.006573121179826558, Final Batch Loss: 0.005490833893418312\n",
      "Epoch 1433, Loss: 0.03762220445787534, Final Batch Loss: 0.03740917518734932\n",
      "Epoch 1434, Loss: 0.0031521705677732825, Final Batch Loss: 0.0022898223251104355\n",
      "Epoch 1435, Loss: 0.0032231366203632206, Final Batch Loss: 0.0003545324725564569\n",
      "Epoch 1436, Loss: 0.0005297407042235136, Final Batch Loss: 0.00032651747460477054\n",
      "Epoch 1437, Loss: 0.009130892110988498, Final Batch Loss: 0.0025754293892532587\n",
      "Epoch 1438, Loss: 0.0024712878512218595, Final Batch Loss: 0.0004568550502881408\n",
      "Epoch 1439, Loss: 0.00047722049203002825, Final Batch Loss: 8.229973173001781e-05\n",
      "Epoch 1440, Loss: 0.016316226305207238, Final Batch Loss: 0.00024672652943991125\n",
      "Epoch 1441, Loss: 0.001937814406119287, Final Batch Loss: 0.000753815402276814\n",
      "Epoch 1442, Loss: 0.00353065732633695, Final Batch Loss: 0.0030923259910196066\n",
      "Epoch 1443, Loss: 0.0006386267377820332, Final Batch Loss: 5.6861656048567966e-05\n",
      "Epoch 1444, Loss: 0.00012306139251450077, Final Batch Loss: 3.5805416700895876e-05\n",
      "Epoch 1445, Loss: 0.00250572498771362, Final Batch Loss: 0.0002676245931070298\n",
      "Epoch 1446, Loss: 0.001717702834866941, Final Batch Loss: 0.0015567047521471977\n",
      "Epoch 1447, Loss: 0.004489012993872166, Final Batch Loss: 0.002517570508643985\n",
      "Epoch 1448, Loss: 0.006580077635589987, Final Batch Loss: 0.005744540598243475\n",
      "Epoch 1449, Loss: 0.005873601126950234, Final Batch Loss: 0.005356203764677048\n",
      "Epoch 1450, Loss: 0.0009494138066656888, Final Batch Loss: 0.0008268890669569373\n",
      "Epoch 1451, Loss: 0.004290704280720092, Final Batch Loss: 0.00012177567987237126\n",
      "Epoch 1452, Loss: 0.007859797915443778, Final Batch Loss: 0.0004843787755817175\n",
      "Epoch 1453, Loss: 0.00047043485392350703, Final Batch Loss: 0.00013727186887990683\n",
      "Epoch 1454, Loss: 0.0009069536463357508, Final Batch Loss: 0.0004661938874050975\n",
      "Epoch 1455, Loss: 0.009624517522752285, Final Batch Loss: 0.007502192631363869\n",
      "Epoch 1456, Loss: 0.0021996995783410966, Final Batch Loss: 0.001862277858890593\n",
      "Epoch 1457, Loss: 0.0008939352410379797, Final Batch Loss: 0.0006057772552594543\n",
      "Epoch 1458, Loss: 0.0019476298475638032, Final Batch Loss: 0.0007470432901754975\n",
      "Epoch 1459, Loss: 0.006534044863656163, Final Batch Loss: 0.005356726702302694\n",
      "Epoch 1460, Loss: 0.001230534873684519, Final Batch Loss: 2.9423516025417484e-05\n",
      "Epoch 1461, Loss: 0.001744692213833332, Final Batch Loss: 0.00045017863158136606\n",
      "Epoch 1462, Loss: 0.00242154038278386, Final Batch Loss: 0.0018509882502257824\n",
      "Epoch 1463, Loss: 0.0014203870086930692, Final Batch Loss: 0.000912790244910866\n",
      "Epoch 1464, Loss: 0.003131164819933474, Final Batch Loss: 0.0008367985719814897\n",
      "Epoch 1465, Loss: 0.0041922463569790125, Final Batch Loss: 0.0010742659214884043\n",
      "Epoch 1466, Loss: 0.04531383910216391, Final Batch Loss: 0.041602883487939835\n",
      "Epoch 1467, Loss: 0.02118402163614519, Final Batch Loss: 0.00028641524841077626\n",
      "Epoch 1468, Loss: 0.0012765111168846488, Final Batch Loss: 0.00028789660427719355\n",
      "Epoch 1469, Loss: 0.0014891943137627095, Final Batch Loss: 0.0002525313466321677\n",
      "Epoch 1470, Loss: 0.0065972162410616875, Final Batch Loss: 0.0022382126189768314\n",
      "Epoch 1471, Loss: 0.008048093295656145, Final Batch Loss: 0.007052128668874502\n",
      "Epoch 1472, Loss: 0.005236397555563599, Final Batch Loss: 0.004713224712759256\n",
      "Epoch 1473, Loss: 0.0017539545078761876, Final Batch Loss: 0.0008322992362082005\n",
      "Epoch 1474, Loss: 0.004876499064266682, Final Batch Loss: 0.004300914704799652\n",
      "Epoch 1475, Loss: 0.0007670338964089751, Final Batch Loss: 0.00010516052134335041\n",
      "Epoch 1476, Loss: 0.0008563228766433895, Final Batch Loss: 0.00047055009054020047\n",
      "Epoch 1477, Loss: 0.0025693073112051934, Final Batch Loss: 0.00042492078500799835\n",
      "Epoch 1478, Loss: 0.002955536008812487, Final Batch Loss: 0.0006394387455657125\n",
      "Epoch 1479, Loss: 0.0016205955762416124, Final Batch Loss: 0.0007532681920565665\n",
      "Epoch 1480, Loss: 0.0017608979251235723, Final Batch Loss: 0.0009465033654123545\n",
      "Epoch 1481, Loss: 0.002687405329197645, Final Batch Loss: 0.0013356681447476149\n",
      "Epoch 1482, Loss: 0.0015170571859925985, Final Batch Loss: 0.00014283251948654652\n",
      "Epoch 1483, Loss: 0.0036965534673072398, Final Batch Loss: 0.0006279606022872031\n",
      "Epoch 1484, Loss: 0.0008200248557841405, Final Batch Loss: 7.631861080881208e-05\n",
      "Epoch 1485, Loss: 0.0006212171574588865, Final Batch Loss: 0.0004630534676834941\n",
      "Epoch 1486, Loss: 0.0017746955272741616, Final Batch Loss: 0.0012141232145950198\n",
      "Epoch 1487, Loss: 0.0009065307967830449, Final Batch Loss: 0.0003399499983061105\n",
      "Epoch 1488, Loss: 0.0012247657869011164, Final Batch Loss: 0.0004853615537285805\n",
      "Epoch 1489, Loss: 0.0004122808313695714, Final Batch Loss: 0.00010887433018069714\n",
      "Epoch 1490, Loss: 0.0032818274339661, Final Batch Loss: 0.001042148913256824\n",
      "Epoch 1491, Loss: 0.0039835008210502565, Final Batch Loss: 0.00026324059581384063\n",
      "Epoch 1492, Loss: 0.0021449299238156527, Final Batch Loss: 0.00015360579709522426\n",
      "Epoch 1493, Loss: 0.00432436607661657, Final Batch Loss: 0.003899178234860301\n",
      "Epoch 1494, Loss: 0.003383267787285149, Final Batch Loss: 0.0012167327804490924\n",
      "Epoch 1495, Loss: 0.004368981346487999, Final Batch Loss: 0.0011722072958946228\n",
      "Epoch 1496, Loss: 0.0007980424561537802, Final Batch Loss: 0.0002164990291930735\n",
      "Epoch 1497, Loss: 0.0024052121152635664, Final Batch Loss: 0.00017609083442948759\n",
      "Epoch 1498, Loss: 0.016712858436221723, Final Batch Loss: 7.125651609385386e-05\n",
      "Epoch 1499, Loss: 0.004948310801410116, Final Batch Loss: 0.00021018578263465315\n",
      "Epoch 1500, Loss: 0.0034577437909319997, Final Batch Loss: 0.0006926405476406217\n",
      "Epoch 1501, Loss: 0.0022112620645202696, Final Batch Loss: 0.0005672122933901846\n",
      "Epoch 1502, Loss: 0.0007735224062344059, Final Batch Loss: 0.00019559501379262656\n",
      "Epoch 1503, Loss: 0.000522354144777637, Final Batch Loss: 6.282730464590713e-05\n",
      "Epoch 1504, Loss: 0.03219333221204579, Final Batch Loss: 0.03017492964863777\n",
      "Epoch 1505, Loss: 0.0041623859433457255, Final Batch Loss: 0.00019068724941462278\n",
      "Epoch 1506, Loss: 0.0014655509876320139, Final Batch Loss: 9.211713040713221e-05\n",
      "Epoch 1507, Loss: 0.003998289466835558, Final Batch Loss: 0.0006855762330815196\n",
      "Epoch 1508, Loss: 0.005292970687150955, Final Batch Loss: 0.003931733779609203\n",
      "Epoch 1509, Loss: 0.002052214491413906, Final Batch Loss: 0.0016486060339957476\n",
      "Epoch 1510, Loss: 0.005981181398965418, Final Batch Loss: 0.005236407276242971\n",
      "Epoch 1511, Loss: 0.0015325068088714033, Final Batch Loss: 0.00018921474111266434\n",
      "Epoch 1512, Loss: 0.0005591627705143765, Final Batch Loss: 0.00012760232493747026\n",
      "Epoch 1513, Loss: 0.006453606649301946, Final Batch Loss: 0.00571546982973814\n",
      "Epoch 1514, Loss: 0.0019258683896623552, Final Batch Loss: 0.00088187848450616\n",
      "Epoch 1515, Loss: 0.009457305772230029, Final Batch Loss: 0.0008419833611696959\n",
      "Epoch 1516, Loss: 0.0088036993984133, Final Batch Loss: 0.005987233482301235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1517, Loss: 0.0013488258991856128, Final Batch Loss: 0.0009455304825678468\n",
      "Epoch 1518, Loss: 0.01320685283280909, Final Batch Loss: 0.01156159583479166\n",
      "Epoch 1519, Loss: 0.0007709983183303848, Final Batch Loss: 0.00012210420391056687\n",
      "Epoch 1520, Loss: 0.002669234585482627, Final Batch Loss: 0.0007361331372521818\n",
      "Epoch 1521, Loss: 0.0030367157887667418, Final Batch Loss: 0.0024494470562785864\n",
      "Epoch 1522, Loss: 0.0015258408966474235, Final Batch Loss: 0.0008158382843248546\n",
      "Epoch 1523, Loss: 0.0074163530371151865, Final Batch Loss: 0.00727299228310585\n",
      "Epoch 1524, Loss: 0.002193995111156255, Final Batch Loss: 0.0014220040757209063\n",
      "Epoch 1525, Loss: 0.0018253355519846082, Final Batch Loss: 0.001555265742354095\n",
      "Epoch 1526, Loss: 0.018302029697224498, Final Batch Loss: 0.01699204556643963\n",
      "Epoch 1527, Loss: 0.0018075049738399684, Final Batch Loss: 0.001127592520788312\n",
      "Epoch 1528, Loss: 0.0009348858147859573, Final Batch Loss: 0.0004289421485736966\n",
      "Epoch 1529, Loss: 0.000861729116877541, Final Batch Loss: 0.0002076989330817014\n",
      "Epoch 1530, Loss: 0.008565131487557665, Final Batch Loss: 0.008094115182757378\n",
      "Epoch 1531, Loss: 0.005966316821286455, Final Batch Loss: 0.005543623585253954\n",
      "Epoch 1532, Loss: 0.0005759782725363038, Final Batch Loss: 8.064522262429819e-05\n",
      "Epoch 1533, Loss: 0.018406916788080707, Final Batch Loss: 0.01825317181646824\n",
      "Epoch 1534, Loss: 0.0005378937421482988, Final Batch Loss: 6.30725480732508e-05\n",
      "Epoch 1535, Loss: 0.004949937458150089, Final Batch Loss: 0.0019199944799765944\n",
      "Epoch 1536, Loss: 0.005336397862265585, Final Batch Loss: 4.72726060252171e-05\n",
      "Epoch 1537, Loss: 0.001166246205684729, Final Batch Loss: 0.00011894312046933919\n",
      "Epoch 1538, Loss: 0.06340388883836567, Final Batch Loss: 0.061457302421331406\n",
      "Epoch 1539, Loss: 0.0022495444791275077, Final Batch Loss: 0.0021444440353661776\n",
      "Epoch 1540, Loss: 0.013296024349983782, Final Batch Loss: 0.012485647574067116\n",
      "Epoch 1541, Loss: 0.0008144658931996673, Final Batch Loss: 0.00029593807994388044\n",
      "Epoch 1542, Loss: 0.010765029830508865, Final Batch Loss: 0.010612145997583866\n",
      "Epoch 1543, Loss: 0.0011576635151868686, Final Batch Loss: 9.573505667503923e-05\n",
      "Epoch 1544, Loss: 0.00031788687920197845, Final Batch Loss: 4.706447361968458e-05\n",
      "Epoch 1545, Loss: 0.0019977139309048653, Final Batch Loss: 0.0013169918674975634\n",
      "Epoch 1546, Loss: 0.0009912255918607116, Final Batch Loss: 0.0007183345733210444\n",
      "Epoch 1547, Loss: 0.009995703585445881, Final Batch Loss: 0.0050950124859809875\n",
      "Epoch 1548, Loss: 0.0142057864140952, Final Batch Loss: 0.014011600986123085\n",
      "Epoch 1549, Loss: 0.0020420660584932193, Final Batch Loss: 0.00021752702014055103\n",
      "Epoch 1550, Loss: 0.0024372590705752373, Final Batch Loss: 0.0016207298031076789\n",
      "Epoch 1551, Loss: 0.002947917324490845, Final Batch Loss: 0.0015798849053680897\n",
      "Epoch 1552, Loss: 0.011255122226430103, Final Batch Loss: 0.00023745044018141925\n",
      "Epoch 1553, Loss: 0.029973357915878296, Final Batch Loss: 0.009881887584924698\n",
      "Epoch 1554, Loss: 0.001727326714899391, Final Batch Loss: 0.00038902024971321225\n",
      "Epoch 1555, Loss: 0.01172551978379488, Final Batch Loss: 0.00289074145257473\n",
      "Epoch 1556, Loss: 0.0006593061261810362, Final Batch Loss: 0.0003252754977438599\n",
      "Epoch 1557, Loss: 0.00021728551655542105, Final Batch Loss: 7.200171239674091e-05\n",
      "Epoch 1558, Loss: 0.001266421575564891, Final Batch Loss: 0.00048228492960333824\n",
      "Epoch 1559, Loss: 0.0023406960535794497, Final Batch Loss: 0.0016565086552873254\n",
      "Epoch 1560, Loss: 0.002513559680664912, Final Batch Loss: 0.00031669731833972037\n",
      "Epoch 1561, Loss: 0.00033946067924262024, Final Batch Loss: 4.331031595938839e-05\n",
      "Epoch 1562, Loss: 0.0008842611496220343, Final Batch Loss: 0.0008033687481656671\n",
      "Epoch 1563, Loss: 0.006270607700571418, Final Batch Loss: 0.0004886405076831579\n",
      "Epoch 1564, Loss: 0.0011195578190381639, Final Batch Loss: 0.00010741693404270336\n",
      "Epoch 1565, Loss: 0.009277972392737865, Final Batch Loss: 0.00480775348842144\n",
      "Epoch 1566, Loss: 0.0010923745066975243, Final Batch Loss: 4.5313914597500116e-05\n",
      "Epoch 1567, Loss: 0.0015224923263303936, Final Batch Loss: 0.0006466158083640039\n",
      "Epoch 1568, Loss: 0.0038921136292628944, Final Batch Loss: 0.0006443061283789575\n",
      "Epoch 1569, Loss: 0.0027188541716895998, Final Batch Loss: 0.0001674109953455627\n",
      "Epoch 1570, Loss: 0.003349092905409634, Final Batch Loss: 0.0008949300972744823\n",
      "Epoch 1571, Loss: 0.0011983956210315228, Final Batch Loss: 0.0004564631381072104\n",
      "Epoch 1572, Loss: 0.0019088719855062664, Final Batch Loss: 0.0009532392141409218\n",
      "Epoch 1573, Loss: 0.008310460019856691, Final Batch Loss: 0.006232286337763071\n",
      "Epoch 1574, Loss: 0.003524969913996756, Final Batch Loss: 0.001377958687953651\n",
      "Epoch 1575, Loss: 0.0024554428528063, Final Batch Loss: 0.0023832209408283234\n",
      "Epoch 1576, Loss: 0.004447743995115161, Final Batch Loss: 0.0022144089452922344\n",
      "Epoch 1577, Loss: 0.003079345333389938, Final Batch Loss: 0.0019808425568044186\n",
      "Epoch 1578, Loss: 0.007649781531654298, Final Batch Loss: 0.006403783801943064\n",
      "Epoch 1579, Loss: 0.001414307436789386, Final Batch Loss: 0.0012674253666773438\n",
      "Epoch 1580, Loss: 0.0014464656705968082, Final Batch Loss: 0.00031221291283145547\n",
      "Epoch 1581, Loss: 0.0026986593729816377, Final Batch Loss: 0.001745055546052754\n",
      "Epoch 1582, Loss: 0.001544227881822735, Final Batch Loss: 0.00028383085737004876\n",
      "Epoch 1583, Loss: 0.006645620567724109, Final Batch Loss: 0.00310342526063323\n",
      "Epoch 1584, Loss: 0.004312265198677778, Final Batch Loss: 0.0011735367588698864\n",
      "Epoch 1585, Loss: 0.03824815611005761, Final Batch Loss: 0.037841737270355225\n",
      "Epoch 1586, Loss: 0.0005697176675312221, Final Batch Loss: 0.0001089790603145957\n",
      "Epoch 1587, Loss: 0.003228098343242891, Final Batch Loss: 0.00015108515799511224\n",
      "Epoch 1588, Loss: 0.05761339142918587, Final Batch Loss: 0.032667841762304306\n",
      "Epoch 1589, Loss: 0.03140794858336449, Final Batch Loss: 0.0026526059955358505\n",
      "Epoch 1590, Loss: 0.0017150109051726758, Final Batch Loss: 0.0010458565084263682\n",
      "Epoch 1591, Loss: 0.0017415294278180227, Final Batch Loss: 0.00013189121091272682\n",
      "Epoch 1592, Loss: 0.00587235065177083, Final Batch Loss: 0.0019004233181476593\n",
      "Epoch 1593, Loss: 0.0012570885301101953, Final Batch Loss: 0.0002095189702231437\n",
      "Epoch 1594, Loss: 0.004750423482619226, Final Batch Loss: 0.001359428628347814\n",
      "Epoch 1595, Loss: 0.023974386975169182, Final Batch Loss: 0.0021607037633657455\n",
      "Epoch 1596, Loss: 0.010205553742707707, Final Batch Loss: 0.0001398919994244352\n",
      "Epoch 1597, Loss: 0.0022671356855425984, Final Batch Loss: 0.0019944212399423122\n",
      "Epoch 1598, Loss: 0.003344634227687493, Final Batch Loss: 0.00032960964017547667\n",
      "Epoch 1599, Loss: 0.0013948464184068143, Final Batch Loss: 0.0004897096077911556\n",
      "Epoch 1600, Loss: 0.0006290796882240102, Final Batch Loss: 0.00045612355461344123\n",
      "Epoch 1601, Loss: 0.0023398143239319324, Final Batch Loss: 0.0012344749411568046\n",
      "Epoch 1602, Loss: 0.004620985826477408, Final Batch Loss: 0.000981612829491496\n",
      "Epoch 1603, Loss: 0.0034570630596135743, Final Batch Loss: 0.0001200488259200938\n",
      "Epoch 1604, Loss: 0.0075800002086907625, Final Batch Loss: 0.006202674005180597\n",
      "Epoch 1605, Loss: 0.0016137142083607614, Final Batch Loss: 0.0012035268591716886\n",
      "Epoch 1606, Loss: 0.0021798915695399046, Final Batch Loss: 0.0005242747720330954\n",
      "Epoch 1607, Loss: 0.000698927429766627, Final Batch Loss: 5.131900616106577e-05\n",
      "Epoch 1608, Loss: 0.0025440716999582946, Final Batch Loss: 0.0005138213164173067\n",
      "Epoch 1609, Loss: 0.0005672658880939707, Final Batch Loss: 0.00023316087026614696\n",
      "Epoch 1610, Loss: 0.020792610477656126, Final Batch Loss: 0.017204919829964638\n",
      "Epoch 1611, Loss: 0.0024646570382174104, Final Batch Loss: 0.0003731489123310894\n",
      "Epoch 1612, Loss: 0.000452656764537096, Final Batch Loss: 0.00013442148338072002\n",
      "Epoch 1613, Loss: 0.0031864707125350833, Final Batch Loss: 0.00273399637080729\n",
      "Epoch 1614, Loss: 0.0007600333192385733, Final Batch Loss: 0.0004165575955994427\n",
      "Epoch 1615, Loss: 0.013411672902293503, Final Batch Loss: 0.0012064446927979589\n",
      "Epoch 1616, Loss: 0.0017922786355484277, Final Batch Loss: 0.0015830802731215954\n",
      "Epoch 1617, Loss: 0.000521662223036401, Final Batch Loss: 0.00037206991692073643\n",
      "Epoch 1618, Loss: 0.0062677040114067495, Final Batch Loss: 0.005334983114153147\n",
      "Epoch 1619, Loss: 0.0019491841085255146, Final Batch Loss: 0.0009952777763828635\n",
      "Epoch 1620, Loss: 0.0025213020780938677, Final Batch Loss: 7.408647070406005e-05\n",
      "Epoch 1621, Loss: 0.004443567944690585, Final Batch Loss: 0.003867202904075384\n",
      "Epoch 1622, Loss: 0.004659864469431341, Final Batch Loss: 0.0016495216405019164\n",
      "Epoch 1623, Loss: 0.00048731455171946436, Final Batch Loss: 3.496506542433053e-05\n",
      "Epoch 1624, Loss: 0.000464586351881735, Final Batch Loss: 0.0001526554551674053\n",
      "Epoch 1625, Loss: 0.0030633944625151344, Final Batch Loss: 4.910445568384603e-05\n",
      "Epoch 1626, Loss: 0.0025989668210968375, Final Batch Loss: 0.00205211085267365\n",
      "Epoch 1627, Loss: 0.019001478096470237, Final Batch Loss: 6.537488661706448e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1628, Loss: 0.008967557587311603, Final Batch Loss: 0.00012841321586165577\n",
      "Epoch 1629, Loss: 0.0017818814376369119, Final Batch Loss: 0.0011981864226981997\n",
      "Epoch 1630, Loss: 0.0019349764625076205, Final Batch Loss: 0.000309298891806975\n",
      "Epoch 1631, Loss: 0.0018390346667729318, Final Batch Loss: 0.0008251943509094417\n",
      "Epoch 1632, Loss: 0.002041860017925501, Final Batch Loss: 0.0013246682938188314\n",
      "Epoch 1633, Loss: 0.003366469405591488, Final Batch Loss: 0.0003697096835821867\n",
      "Epoch 1634, Loss: 0.0029435663600452244, Final Batch Loss: 0.0006221493822522461\n",
      "Epoch 1635, Loss: 0.0010253015789203346, Final Batch Loss: 0.00014896155335009098\n",
      "Epoch 1636, Loss: 0.001395471699652262, Final Batch Loss: 0.0011916724033653736\n",
      "Epoch 1637, Loss: 0.0017262558685615659, Final Batch Loss: 0.0011651425156742334\n",
      "Epoch 1638, Loss: 0.004655416822060943, Final Batch Loss: 0.0024972669780254364\n",
      "Epoch 1639, Loss: 0.0029949492309242487, Final Batch Loss: 0.001576035749167204\n",
      "Epoch 1640, Loss: 0.0016102209483506158, Final Batch Loss: 0.00014548162289429456\n",
      "Epoch 1641, Loss: 0.05521527997916564, Final Batch Loss: 0.054434508085250854\n",
      "Epoch 1642, Loss: 0.0033820385579019785, Final Batch Loss: 0.00239788880571723\n",
      "Epoch 1643, Loss: 0.002137786999810487, Final Batch Loss: 0.00030953873647376895\n",
      "Epoch 1644, Loss: 0.021895465906709433, Final Batch Loss: 0.0010091564618051052\n",
      "Epoch 1645, Loss: 0.002474361113854684, Final Batch Loss: 0.00023610309290234\n",
      "Epoch 1646, Loss: 0.004379736608825624, Final Batch Loss: 0.0037023734766989946\n",
      "Epoch 1647, Loss: 0.0013493378646671772, Final Batch Loss: 0.0008715877193026245\n",
      "Epoch 1648, Loss: 0.0036512453807517886, Final Batch Loss: 0.0010102681117132306\n",
      "Epoch 1649, Loss: 0.0009360492404084653, Final Batch Loss: 0.00028444730560295284\n",
      "Epoch 1650, Loss: 0.0013576493947766721, Final Batch Loss: 0.0006346473237499595\n",
      "Epoch 1651, Loss: 0.001461250096326694, Final Batch Loss: 0.00043473110417835414\n",
      "Epoch 1652, Loss: 0.00047654124500695616, Final Batch Loss: 0.00029932541656307876\n",
      "Epoch 1653, Loss: 0.0010694721422623843, Final Batch Loss: 0.0002031322510447353\n",
      "Epoch 1654, Loss: 0.0008577882836107165, Final Batch Loss: 0.0003712886245921254\n",
      "Epoch 1655, Loss: 0.005711024394258857, Final Batch Loss: 0.0022578358184546232\n",
      "Epoch 1656, Loss: 0.0018827148014679551, Final Batch Loss: 0.00020892976317554712\n",
      "Epoch 1657, Loss: 0.0029272191459313035, Final Batch Loss: 0.0005588923813775182\n",
      "Epoch 1658, Loss: 0.0021794539934489876, Final Batch Loss: 0.00017837705672718585\n",
      "Epoch 1659, Loss: 0.0008161943987943232, Final Batch Loss: 0.00028992968145757914\n",
      "Epoch 1660, Loss: 0.000992939036223106, Final Batch Loss: 0.000825536553747952\n",
      "Epoch 1661, Loss: 0.0013819689920637757, Final Batch Loss: 0.0009005313040688634\n",
      "Epoch 1662, Loss: 0.009782309818547219, Final Batch Loss: 0.008821500465273857\n",
      "Epoch 1663, Loss: 0.0007316117989830673, Final Batch Loss: 9.421911090612411e-05\n",
      "Epoch 1664, Loss: 0.0004672773357015103, Final Batch Loss: 0.00011717778397724032\n",
      "Epoch 1665, Loss: 0.01916344463825226, Final Batch Loss: 0.014416798017919064\n",
      "Epoch 1666, Loss: 0.0004941167862853035, Final Batch Loss: 5.347818660084158e-05\n",
      "Epoch 1667, Loss: 0.0022707831230945885, Final Batch Loss: 0.00033025891752913594\n",
      "Epoch 1668, Loss: 0.0006296808714978397, Final Batch Loss: 0.0002890298783313483\n",
      "Epoch 1669, Loss: 0.004430738394148648, Final Batch Loss: 0.0016044870717450976\n",
      "Epoch 1670, Loss: 0.0009085478195629548, Final Batch Loss: 3.4259905078215525e-05\n",
      "Epoch 1671, Loss: 0.0007399937967420556, Final Batch Loss: 8.298122702399269e-05\n",
      "Epoch 1672, Loss: 0.000633722884231247, Final Batch Loss: 7.656765228603035e-05\n",
      "Epoch 1673, Loss: 0.0038437938201241195, Final Batch Loss: 0.0007806417415849864\n",
      "Epoch 1674, Loss: 0.0022086125682108104, Final Batch Loss: 0.0018395924707874656\n",
      "Epoch 1675, Loss: 0.0003400483910809271, Final Batch Loss: 0.00022763197193853557\n",
      "Epoch 1676, Loss: 0.002325521993043367, Final Batch Loss: 0.0022616577334702015\n",
      "Epoch 1677, Loss: 0.0011466569849289954, Final Batch Loss: 0.00026931409956887364\n",
      "Epoch 1678, Loss: 0.005647717887768522, Final Batch Loss: 0.0004348437360022217\n",
      "Epoch 1679, Loss: 0.0007309137145057321, Final Batch Loss: 0.0005358738708309829\n",
      "Epoch 1680, Loss: 0.0032955086207948625, Final Batch Loss: 0.002842115005478263\n",
      "Epoch 1681, Loss: 0.006451169610954821, Final Batch Loss: 0.005762944929301739\n",
      "Epoch 1682, Loss: 0.0032487075641256524, Final Batch Loss: 1.2567905287141912e-05\n",
      "Epoch 1683, Loss: 0.0041077131099882536, Final Batch Loss: 0.004027531482279301\n",
      "Epoch 1684, Loss: 0.0003642887559180963, Final Batch Loss: 1.0164086233999114e-05\n",
      "Epoch 1685, Loss: 0.008221047348342836, Final Batch Loss: 0.00796549953520298\n",
      "Epoch 1686, Loss: 0.0005692750128218904, Final Batch Loss: 0.0004299395077396184\n",
      "Epoch 1687, Loss: 0.002775948800262995, Final Batch Loss: 0.00019601041276473552\n",
      "Epoch 1688, Loss: 0.0004946569533785805, Final Batch Loss: 0.00014623616880271584\n",
      "Epoch 1689, Loss: 0.0020589672349160537, Final Batch Loss: 0.00012978141603525728\n",
      "Epoch 1690, Loss: 0.004310766700655222, Final Batch Loss: 0.0017277044244110584\n",
      "Epoch 1691, Loss: 0.004616571823135018, Final Batch Loss: 0.0010053073056042194\n",
      "Epoch 1692, Loss: 0.0020566968305502087, Final Batch Loss: 0.0003986296069342643\n",
      "Epoch 1693, Loss: 0.013723350490181474, Final Batch Loss: 0.013688134029507637\n",
      "Epoch 1694, Loss: 0.001000895063043572, Final Batch Loss: 0.0007895783637650311\n",
      "Epoch 1695, Loss: 0.0017095210423576646, Final Batch Loss: 9.983684140024707e-05\n",
      "Epoch 1696, Loss: 0.005522218809346668, Final Batch Loss: 0.00016381153545808047\n",
      "Epoch 1697, Loss: 0.0011228527582716197, Final Batch Loss: 0.00037711902405135334\n",
      "Epoch 1698, Loss: 0.0030931459041312337, Final Batch Loss: 0.0017815814353525639\n",
      "Epoch 1699, Loss: 0.0012592573184520006, Final Batch Loss: 0.0007295167306438088\n",
      "Epoch 1700, Loss: 0.0019908056419808418, Final Batch Loss: 0.0015191680286079645\n",
      "Epoch 1701, Loss: 0.0015871653449721634, Final Batch Loss: 0.0008781854412518442\n",
      "Epoch 1702, Loss: 0.0013937046460341662, Final Batch Loss: 0.0010417927987873554\n",
      "Epoch 1703, Loss: 0.0007146367233872297, Final Batch Loss: 1.0270824532199185e-05\n",
      "Epoch 1704, Loss: 0.006113318115239963, Final Batch Loss: 0.0003396201354917139\n",
      "Epoch 1705, Loss: 0.0005254511634120718, Final Batch Loss: 0.00044416735181584954\n",
      "Epoch 1706, Loss: 0.0021099674413562752, Final Batch Loss: 8.893202902982011e-05\n",
      "Epoch 1707, Loss: 0.0016276266978820786, Final Batch Loss: 0.0015129190869629383\n",
      "Epoch 1708, Loss: 8.607839481555857e-05, Final Batch Loss: 4.9345817387802526e-05\n",
      "Epoch 1709, Loss: 0.004091120325028896, Final Batch Loss: 0.0021180349867790937\n",
      "Epoch 1710, Loss: 0.0039051745552569628, Final Batch Loss: 0.000392501475289464\n",
      "Epoch 1711, Loss: 0.0004749507934320718, Final Batch Loss: 0.00030720920767635107\n",
      "Epoch 1712, Loss: 0.0006654573371633887, Final Batch Loss: 0.0002321431238669902\n",
      "Epoch 1713, Loss: 0.0010060089698527008, Final Batch Loss: 0.00047810535761527717\n",
      "Epoch 1714, Loss: 0.002488936937879771, Final Batch Loss: 0.001653576036915183\n",
      "Epoch 1715, Loss: 0.0009563303028699011, Final Batch Loss: 0.0005305719096213579\n",
      "Epoch 1716, Loss: 0.0002985395913128741, Final Batch Loss: 7.866419764468446e-05\n",
      "Epoch 1717, Loss: 0.0003783505999308545, Final Batch Loss: 3.134024518658407e-05\n",
      "Epoch 1718, Loss: 0.0031766773317940533, Final Batch Loss: 0.0004977691569365561\n",
      "Epoch 1719, Loss: 0.0015275399273377843, Final Batch Loss: 7.583539263578132e-05\n",
      "Epoch 1720, Loss: 0.002632635754707735, Final Batch Loss: 0.00011519842519192025\n",
      "Epoch 1721, Loss: 0.0016194033669307828, Final Batch Loss: 0.0009318683296442032\n",
      "Epoch 1722, Loss: 0.002214761567302048, Final Batch Loss: 0.0012302054092288017\n",
      "Epoch 1723, Loss: 0.0005906062497160747, Final Batch Loss: 1.4982309039623942e-05\n",
      "Epoch 1724, Loss: 0.013868595706298947, Final Batch Loss: 0.0016658951062709093\n",
      "Epoch 1725, Loss: 0.0005556523683480918, Final Batch Loss: 0.0003257759381085634\n",
      "Epoch 1726, Loss: 0.00024765678244875744, Final Batch Loss: 0.00020343763753771782\n",
      "Epoch 1727, Loss: 0.00021388475943240337, Final Batch Loss: 1.435432568541728e-05\n",
      "Epoch 1728, Loss: 0.0002846627976396121, Final Batch Loss: 0.00020123360445722938\n",
      "Epoch 1729, Loss: 0.000598256679950282, Final Batch Loss: 0.0002745731908362359\n",
      "Epoch 1730, Loss: 0.0006078130390960723, Final Batch Loss: 0.00025136704789474607\n",
      "Epoch 1731, Loss: 0.0008637769205961376, Final Batch Loss: 0.00041311801760457456\n",
      "Epoch 1732, Loss: 0.004547818651190028, Final Batch Loss: 0.0001773551048245281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1733, Loss: 0.0040636800986249, Final Batch Loss: 0.0035872531589120626\n",
      "Epoch 1734, Loss: 0.0017750539118424058, Final Batch Loss: 0.00024591642431914806\n",
      "Epoch 1735, Loss: 0.0002505604279576801, Final Batch Loss: 7.92701102909632e-05\n",
      "Epoch 1736, Loss: 0.0031441317551070824, Final Batch Loss: 0.00017303765343967825\n",
      "Epoch 1737, Loss: 0.0005429132143035531, Final Batch Loss: 8.546150638721883e-05\n",
      "Epoch 1738, Loss: 0.00043828402704093605, Final Batch Loss: 9.515915007796139e-05\n",
      "Epoch 1739, Loss: 0.001089048688299954, Final Batch Loss: 0.00040058791637420654\n",
      "Epoch 1740, Loss: 0.0005016328450437868, Final Batch Loss: 2.0443849280127324e-05\n",
      "Epoch 1741, Loss: 0.003553573740646243, Final Batch Loss: 0.0021489185746759176\n",
      "Epoch 1742, Loss: 0.0025492534550721757, Final Batch Loss: 9.393836808158085e-05\n",
      "Epoch 1743, Loss: 0.016555697307921946, Final Batch Loss: 0.015001293271780014\n",
      "Epoch 1744, Loss: 0.0005027720544603653, Final Batch Loss: 9.818960825214162e-05\n",
      "Epoch 1745, Loss: 0.0038927155328565277, Final Batch Loss: 5.527909524971619e-05\n",
      "Epoch 1746, Loss: 0.0012911199082736857, Final Batch Loss: 0.00010393135744379833\n",
      "Epoch 1747, Loss: 0.0005928148457314819, Final Batch Loss: 0.0002983525046147406\n",
      "Epoch 1748, Loss: 0.00040465572965331376, Final Batch Loss: 3.5735953133553267e-05\n",
      "Epoch 1749, Loss: 0.0007963966345414519, Final Batch Loss: 0.0002199744340032339\n",
      "Epoch 1750, Loss: 0.027665009605698287, Final Batch Loss: 0.0011140777496621013\n",
      "Epoch 1751, Loss: 0.0006866297917440534, Final Batch Loss: 0.00032978164381347597\n",
      "Epoch 1752, Loss: 0.0015349751920439303, Final Batch Loss: 0.0008766156970523298\n",
      "Epoch 1753, Loss: 0.0030806279173702933, Final Batch Loss: 8.59557549119927e-05\n",
      "Epoch 1754, Loss: 0.0027455492090666667, Final Batch Loss: 0.00017928263696376234\n",
      "Epoch 1755, Loss: 0.0028366020633256994, Final Batch Loss: 4.790329694515094e-05\n",
      "Epoch 1756, Loss: 0.0033726197143550962, Final Batch Loss: 0.0002792799787130207\n",
      "Epoch 1757, Loss: 0.0023046246205922216, Final Batch Loss: 0.00048147080815397203\n",
      "Epoch 1758, Loss: 0.0013571714516729116, Final Batch Loss: 0.0010681288549676538\n",
      "Epoch 1759, Loss: 0.001960231689736247, Final Batch Loss: 0.0016667051240801811\n",
      "Epoch 1760, Loss: 0.0006673153839074075, Final Batch Loss: 0.0003021073353011161\n",
      "Epoch 1761, Loss: 0.0013103906530886889, Final Batch Loss: 0.0007661869167350233\n",
      "Epoch 1762, Loss: 0.0018167856615036726, Final Batch Loss: 0.0014695943100377917\n",
      "Epoch 1763, Loss: 0.0007675485976506025, Final Batch Loss: 0.00031510950066149235\n",
      "Epoch 1764, Loss: 0.0015117126749828458, Final Batch Loss: 0.0005652028485201299\n",
      "Epoch 1765, Loss: 0.0012333509730524383, Final Batch Loss: 3.8463993405457586e-05\n",
      "Epoch 1766, Loss: 0.0006609014089917764, Final Batch Loss: 0.0001571028697071597\n",
      "Epoch 1767, Loss: 0.0005475861980812624, Final Batch Loss: 6.90301094437018e-05\n",
      "Epoch 1768, Loss: 0.00026439637440489605, Final Batch Loss: 7.683685544179752e-05\n",
      "Epoch 1769, Loss: 0.004081505350768566, Final Batch Loss: 0.003586903912946582\n",
      "Epoch 1770, Loss: 0.0005959261179668829, Final Batch Loss: 0.0004343895707279444\n",
      "Epoch 1771, Loss: 0.002841244713636115, Final Batch Loss: 0.0003447605122346431\n",
      "Epoch 1772, Loss: 0.0019165321136824787, Final Batch Loss: 0.0011797469342127442\n",
      "Epoch 1773, Loss: 0.0008187256462406367, Final Batch Loss: 0.0002929504553321749\n",
      "Epoch 1774, Loss: 0.0007231668059830554, Final Batch Loss: 0.000640487705823034\n",
      "Epoch 1775, Loss: 0.00017488267985754646, Final Batch Loss: 3.5306544305058196e-05\n",
      "Epoch 1776, Loss: 0.0010454053990542889, Final Batch Loss: 0.000352485163602978\n",
      "Epoch 1777, Loss: 0.009071444626897573, Final Batch Loss: 0.006466505117714405\n",
      "Epoch 1778, Loss: 0.0028086315578548238, Final Batch Loss: 0.00012747237633448094\n",
      "Epoch 1779, Loss: 0.0013443755160551518, Final Batch Loss: 7.228317554108799e-05\n",
      "Epoch 1780, Loss: 0.0011296466109342873, Final Batch Loss: 0.0008046607254073024\n",
      "Epoch 1781, Loss: 0.001377581458655186, Final Batch Loss: 0.0002421492972644046\n",
      "Epoch 1782, Loss: 0.0073341584065929055, Final Batch Loss: 0.0009793402859941125\n",
      "Epoch 1783, Loss: 0.007368891267105937, Final Batch Loss: 0.006602993234992027\n",
      "Epoch 1784, Loss: 0.0008773014997132123, Final Batch Loss: 0.0002752862637862563\n",
      "Epoch 1785, Loss: 0.00806924583230284, Final Batch Loss: 0.008016658946871758\n",
      "Epoch 1786, Loss: 0.0030148018850013614, Final Batch Loss: 0.0006190011044964194\n",
      "Epoch 1787, Loss: 0.0037002591998316348, Final Batch Loss: 0.0004834845312871039\n",
      "Epoch 1788, Loss: 0.006616022088564932, Final Batch Loss: 0.006184013560414314\n",
      "Epoch 1789, Loss: 0.0008654161647427827, Final Batch Loss: 0.000521442387253046\n",
      "Epoch 1790, Loss: 0.0003342793497722596, Final Batch Loss: 0.0001234594965353608\n",
      "Epoch 1791, Loss: 0.003741449036169797, Final Batch Loss: 0.00048780423821881413\n",
      "Epoch 1792, Loss: 0.0009247091948054731, Final Batch Loss: 0.0005713034770451486\n",
      "Epoch 1793, Loss: 0.0030258702754508704, Final Batch Loss: 0.002604100853204727\n",
      "Epoch 1794, Loss: 0.0009419795242138207, Final Batch Loss: 0.0005362734664231539\n",
      "Epoch 1795, Loss: 0.0030925875762477517, Final Batch Loss: 0.0002810597652569413\n",
      "Epoch 1796, Loss: 0.002182190481107682, Final Batch Loss: 0.0003895502886734903\n",
      "Epoch 1797, Loss: 0.0014257801813073456, Final Batch Loss: 0.0005185304908081889\n",
      "Epoch 1798, Loss: 0.0012848137394030346, Final Batch Loss: 2.955272611870896e-05\n",
      "Epoch 1799, Loss: 0.00047498057392658666, Final Batch Loss: 6.193106673890725e-05\n",
      "Epoch 1800, Loss: 0.003566709958249703, Final Batch Loss: 0.00038347337977029383\n",
      "Epoch 1801, Loss: 0.0034304503933526576, Final Batch Loss: 0.00023904169211164117\n",
      "Epoch 1802, Loss: 0.0015884943131823093, Final Batch Loss: 0.00043070598621852696\n",
      "Epoch 1803, Loss: 0.0011251622927375138, Final Batch Loss: 0.00048563245218247175\n",
      "Epoch 1804, Loss: 0.007047786406474188, Final Batch Loss: 0.0002961485006380826\n",
      "Epoch 1805, Loss: 0.004869642143603414, Final Batch Loss: 0.0006435308023355901\n",
      "Epoch 1806, Loss: 0.001229017332661897, Final Batch Loss: 0.0008001411333680153\n",
      "Epoch 1807, Loss: 0.0016706422611605376, Final Batch Loss: 0.0015050291549414396\n",
      "Epoch 1808, Loss: 0.0002912927157012746, Final Batch Loss: 0.0002475542132742703\n",
      "Epoch 1809, Loss: 0.0008769423584453762, Final Batch Loss: 0.0007573720067739487\n",
      "Epoch 1810, Loss: 0.006069119306630455, Final Batch Loss: 0.005973562598228455\n",
      "Epoch 1811, Loss: 0.00014100152839091606, Final Batch Loss: 4.993781840312295e-05\n",
      "Epoch 1812, Loss: 0.00031263991513696965, Final Batch Loss: 1.7525793737149797e-05\n",
      "Epoch 1813, Loss: 0.0008085523440968245, Final Batch Loss: 0.0006653272430412471\n",
      "Epoch 1814, Loss: 0.002143509977031499, Final Batch Loss: 0.000668292457703501\n",
      "Epoch 1815, Loss: 0.001640373440750409, Final Batch Loss: 9.560486796544865e-05\n",
      "Epoch 1816, Loss: 0.001562345540151, Final Batch Loss: 0.0010599339148029685\n",
      "Epoch 1817, Loss: 0.0006532398692797869, Final Batch Loss: 0.00031390890944749117\n",
      "Epoch 1818, Loss: 0.003395626146811992, Final Batch Loss: 0.0009060309384949505\n",
      "Epoch 1819, Loss: 0.0030386125508812256, Final Batch Loss: 2.985576429637149e-05\n",
      "Epoch 1820, Loss: 0.00030824948044028133, Final Batch Loss: 7.114269828889519e-05\n",
      "Epoch 1821, Loss: 0.00016998150385916233, Final Batch Loss: 5.836106720380485e-05\n",
      "Epoch 1822, Loss: 0.0001436962265870534, Final Batch Loss: 3.264979750383645e-05\n",
      "Epoch 1823, Loss: 0.002850501419743523, Final Batch Loss: 0.002520627109333873\n",
      "Epoch 1824, Loss: 0.0002326139474462252, Final Batch Loss: 5.0451064453227445e-05\n",
      "Epoch 1825, Loss: 0.0005050374456914142, Final Batch Loss: 0.00019241082191001624\n",
      "Epoch 1826, Loss: 0.0003207074187230319, Final Batch Loss: 0.00020489191228989512\n",
      "Epoch 1827, Loss: 0.0034091364359483123, Final Batch Loss: 0.00047702889423817396\n",
      "Epoch 1828, Loss: 0.004180583804554772, Final Batch Loss: 8.416146010858938e-05\n",
      "Epoch 1829, Loss: 0.00018928008921648143, Final Batch Loss: 6.6243619585293345e-06\n",
      "Epoch 1830, Loss: 0.008643867098726332, Final Batch Loss: 0.006828493904322386\n",
      "Epoch 1831, Loss: 0.0005189115108805709, Final Batch Loss: 2.5962413928937167e-05\n",
      "Epoch 1832, Loss: 0.002716421033255756, Final Batch Loss: 0.00028876925352960825\n",
      "Epoch 1833, Loss: 0.003615196095779538, Final Batch Loss: 0.0014068675227463245\n",
      "Epoch 1834, Loss: 0.004491466621402651, Final Batch Loss: 0.0038559644017368555\n",
      "Epoch 1835, Loss: 0.002861532149836421, Final Batch Loss: 0.0003779553808271885\n",
      "Epoch 1836, Loss: 0.0011835107579827309, Final Batch Loss: 0.0008404228719882667\n",
      "Epoch 1837, Loss: 0.0008192661916837096, Final Batch Loss: 0.000170390703715384\n",
      "Epoch 1838, Loss: 0.0005550390342250466, Final Batch Loss: 0.00026168060139752924\n",
      "Epoch 1839, Loss: 0.00044850812264485285, Final Batch Loss: 0.00032700333395041525\n",
      "Epoch 1840, Loss: 0.002211705199442804, Final Batch Loss: 0.001136027742177248\n",
      "Epoch 1841, Loss: 0.0002921029517892748, Final Batch Loss: 0.00024705094983801246\n",
      "Epoch 1842, Loss: 0.0031145979883149266, Final Batch Loss: 0.0017145745223388076\n",
      "Epoch 1843, Loss: 0.00016671443881932646, Final Batch Loss: 6.331392069114372e-05\n",
      "Epoch 1844, Loss: 0.00012071682613168377, Final Batch Loss: 9.446930562262423e-06\n",
      "Epoch 1845, Loss: 0.0012521717872004956, Final Batch Loss: 0.00048249648534692824\n",
      "Epoch 1846, Loss: 0.004143428755924106, Final Batch Loss: 0.0011557114776223898\n",
      "Epoch 1847, Loss: 0.002981658595672343, Final Batch Loss: 0.0029302628245204687\n",
      "Epoch 1848, Loss: 0.0011374407331459224, Final Batch Loss: 0.0006245997501537204\n",
      "Epoch 1849, Loss: 0.0001406921655870974, Final Batch Loss: 5.7709890825208277e-05\n",
      "Epoch 1850, Loss: 0.00024836496595526114, Final Batch Loss: 9.409800259163603e-05\n",
      "Epoch 1851, Loss: 0.0005730934499297291, Final Batch Loss: 0.000188927398994565\n",
      "Epoch 1852, Loss: 0.004280904511688277, Final Batch Loss: 0.004102495964616537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1853, Loss: 0.0008896708313841373, Final Batch Loss: 0.0005659886519424617\n",
      "Epoch 1854, Loss: 0.0001246577267011162, Final Batch Loss: 7.18673545634374e-05\n",
      "Epoch 1855, Loss: 0.0008575474785175174, Final Batch Loss: 0.00012447763583622873\n",
      "Epoch 1856, Loss: 0.00034779908310156316, Final Batch Loss: 0.00022610097948927432\n",
      "Epoch 1857, Loss: 0.00820233253762126, Final Batch Loss: 0.0024305330589413643\n",
      "Epoch 1858, Loss: 0.00017634023970458657, Final Batch Loss: 6.837059481767938e-05\n",
      "Epoch 1859, Loss: 0.005867875952390023, Final Batch Loss: 0.005704920738935471\n",
      "Epoch 1860, Loss: 0.0005100492417113855, Final Batch Loss: 0.00013634619244839996\n",
      "Epoch 1861, Loss: 0.001115173006837722, Final Batch Loss: 6.13548545516096e-05\n",
      "Epoch 1862, Loss: 0.0013189436576794833, Final Batch Loss: 0.0009176540770567954\n",
      "Epoch 1863, Loss: 0.004093609284609556, Final Batch Loss: 0.0016320385038852692\n",
      "Epoch 1864, Loss: 0.0027204850339330733, Final Batch Loss: 0.0005075098597444594\n",
      "Epoch 1865, Loss: 0.00038388013490475714, Final Batch Loss: 2.1141080651432276e-05\n",
      "Epoch 1866, Loss: 0.006842475529992953, Final Batch Loss: 0.006699059158563614\n",
      "Epoch 1867, Loss: 0.0017667655483819544, Final Batch Loss: 0.0003062239266000688\n",
      "Epoch 1868, Loss: 0.0008550658967578784, Final Batch Loss: 0.0001288891799049452\n",
      "Epoch 1869, Loss: 0.004547597156488337, Final Batch Loss: 0.00021011546778026968\n",
      "Epoch 1870, Loss: 0.0009366342274006456, Final Batch Loss: 0.0006346451700665057\n",
      "Epoch 1871, Loss: 0.0053165286662988365, Final Batch Loss: 0.004882499575614929\n",
      "Epoch 1872, Loss: 0.00023668006906518713, Final Batch Loss: 0.00011883246770594269\n",
      "Epoch 1873, Loss: 0.021773478332761442, Final Batch Loss: 9.877923730527982e-06\n",
      "Epoch 1874, Loss: 0.0025059415493160486, Final Batch Loss: 0.002079470083117485\n",
      "Epoch 1875, Loss: 0.0007350402938754996, Final Batch Loss: 2.8195156119181775e-05\n",
      "Epoch 1876, Loss: 0.0002308795801582164, Final Batch Loss: 9.146518095803913e-06\n",
      "Epoch 1877, Loss: 0.027552238476346247, Final Batch Loss: 0.00011921934492420405\n",
      "Epoch 1878, Loss: 0.015621584141626954, Final Batch Loss: 0.013242436572909355\n",
      "Epoch 1879, Loss: 0.00149011656321818, Final Batch Loss: 5.638969741994515e-05\n",
      "Epoch 1880, Loss: 8.850453559716698e-05, Final Batch Loss: 2.1697835109080188e-05\n",
      "Epoch 1881, Loss: 0.0007948872807901353, Final Batch Loss: 0.0002829461882356554\n",
      "Epoch 1882, Loss: 0.0004506256664171815, Final Batch Loss: 0.00015656001050956547\n",
      "Epoch 1883, Loss: 0.019227392738685012, Final Batch Loss: 0.016242392361164093\n",
      "Epoch 1884, Loss: 0.005425915587693453, Final Batch Loss: 0.0017117029055953026\n",
      "Epoch 1885, Loss: 0.0031751852948218584, Final Batch Loss: 0.002279862994328141\n",
      "Epoch 1886, Loss: 0.0021026278845965862, Final Batch Loss: 0.0008874919731169939\n",
      "Epoch 1887, Loss: 0.0005624208133667707, Final Batch Loss: 0.00041422282811254263\n",
      "Epoch 1888, Loss: 0.0012525297934189439, Final Batch Loss: 0.0009125503711402416\n",
      "Epoch 1889, Loss: 0.0007349192601395771, Final Batch Loss: 0.00014436447236221284\n",
      "Epoch 1890, Loss: 0.010688181966543198, Final Batch Loss: 0.007643106859177351\n",
      "Epoch 1891, Loss: 0.0006656714540440589, Final Batch Loss: 0.00012599365436472\n",
      "Epoch 1892, Loss: 0.0046410065770032816, Final Batch Loss: 6.268719880608842e-05\n",
      "Epoch 1893, Loss: 0.00028537936123029795, Final Batch Loss: 2.4281622245325707e-05\n",
      "Epoch 1894, Loss: 0.0032067774154711515, Final Batch Loss: 0.00034958499600179493\n",
      "Epoch 1895, Loss: 0.0021987278014421463, Final Batch Loss: 0.0019540973007678986\n",
      "Epoch 1896, Loss: 0.0006556729786098003, Final Batch Loss: 0.00041335748392157257\n",
      "Epoch 1897, Loss: 0.0007924450328573585, Final Batch Loss: 0.00040492910193279386\n",
      "Epoch 1898, Loss: 0.0003676854867080692, Final Batch Loss: 0.0003513573610689491\n",
      "Epoch 1899, Loss: 0.005309226384270005, Final Batch Loss: 0.00019041627820115536\n",
      "Epoch 1900, Loss: 0.0005362675001379102, Final Batch Loss: 0.00021013157675042748\n",
      "Epoch 1901, Loss: 0.0015700586081948131, Final Batch Loss: 0.0011579171987250447\n",
      "Epoch 1902, Loss: 0.0017630385118536651, Final Batch Loss: 0.0008956875535659492\n",
      "Epoch 1903, Loss: 0.00048501414130441844, Final Batch Loss: 0.0002893198688980192\n",
      "Epoch 1904, Loss: 0.0038276052509900182, Final Batch Loss: 0.0037543675862252712\n",
      "Epoch 1905, Loss: 7.60259572416544e-05, Final Batch Loss: 2.0310457330197096e-05\n",
      "Epoch 1906, Loss: 0.002521676491596736, Final Batch Loss: 9.057439456228167e-05\n",
      "Epoch 1907, Loss: 0.0020270588429411873, Final Batch Loss: 0.0001975967170437798\n",
      "Epoch 1908, Loss: 0.0003697337378980592, Final Batch Loss: 0.00010389911767560989\n",
      "Epoch 1909, Loss: 0.00044129867455922067, Final Batch Loss: 0.00019589217845350504\n",
      "Epoch 1910, Loss: 0.0053452635984285735, Final Batch Loss: 0.00012184640945633873\n",
      "Epoch 1911, Loss: 0.0009266139932151418, Final Batch Loss: 1.1220119631616399e-05\n",
      "Epoch 1912, Loss: 0.00020403648522915319, Final Batch Loss: 0.0001418354077031836\n",
      "Epoch 1913, Loss: 0.00023156484530773014, Final Batch Loss: 8.4791419794783e-05\n",
      "Epoch 1914, Loss: 0.00044811618863604963, Final Batch Loss: 0.0001265320461243391\n",
      "Epoch 1915, Loss: 0.0129381435981486, Final Batch Loss: 0.01272963173687458\n",
      "Epoch 1916, Loss: 0.00019352759136381792, Final Batch Loss: 3.210426257282961e-06\n",
      "Epoch 1917, Loss: 0.00030740048532607034, Final Batch Loss: 0.00019951640570070595\n",
      "Epoch 1918, Loss: 0.000760071343393065, Final Batch Loss: 0.0001287543709622696\n",
      "Epoch 1919, Loss: 0.004545677569694817, Final Batch Loss: 0.0036755900364369154\n",
      "Epoch 1920, Loss: 0.005071807565400377, Final Batch Loss: 0.004598160274326801\n",
      "Epoch 1921, Loss: 0.004308591393055394, Final Batch Loss: 0.00021067706984467804\n",
      "Epoch 1922, Loss: 0.00028331222711130977, Final Batch Loss: 3.7386169424280524e-05\n",
      "Epoch 1923, Loss: 0.0030762319802306592, Final Batch Loss: 0.0022933809086680412\n",
      "Epoch 1924, Loss: 0.0017284299246966839, Final Batch Loss: 0.0011369804851710796\n",
      "Epoch 1925, Loss: 0.000314029268338345, Final Batch Loss: 0.00014410691801458597\n",
      "Epoch 1926, Loss: 0.0004245700838509947, Final Batch Loss: 0.00026519165839999914\n",
      "Epoch 1927, Loss: 0.008841271075652912, Final Batch Loss: 0.00010315843974240124\n",
      "Epoch 1928, Loss: 0.00110169718391262, Final Batch Loss: 0.0009203405352309346\n",
      "Epoch 1929, Loss: 0.017694903537631035, Final Batch Loss: 0.00623466819524765\n",
      "Epoch 1930, Loss: 0.0027446370804682374, Final Batch Loss: 0.0007594608468934894\n",
      "Epoch 1931, Loss: 0.0006976304575800896, Final Batch Loss: 0.0004131188034079969\n",
      "Epoch 1932, Loss: 0.0008577220723964274, Final Batch Loss: 0.0005652690306305885\n",
      "Epoch 1933, Loss: 0.00017749040125636384, Final Batch Loss: 0.0001243078149855137\n",
      "Epoch 1934, Loss: 0.00030487267940770835, Final Batch Loss: 0.00010345080227125436\n",
      "Epoch 1935, Loss: 0.00013281820611155126, Final Batch Loss: 1.6390638847951777e-05\n",
      "Epoch 1936, Loss: 0.0007499232015106827, Final Batch Loss: 0.0004125246487092227\n",
      "Epoch 1937, Loss: 0.000449836123152636, Final Batch Loss: 0.00023157343093771487\n",
      "Epoch 1938, Loss: 0.0003160658015985973, Final Batch Loss: 6.200164352776483e-05\n",
      "Epoch 1939, Loss: 0.0008370555005967617, Final Batch Loss: 0.0003047249629162252\n",
      "Epoch 1940, Loss: 0.00033385687856934965, Final Batch Loss: 1.563623663969338e-05\n",
      "Epoch 1941, Loss: 0.003956922912038863, Final Batch Loss: 0.002017035847529769\n",
      "Epoch 1942, Loss: 0.0008931573429435957, Final Batch Loss: 0.0008611908997409046\n",
      "Epoch 1943, Loss: 0.0007661640775040723, Final Batch Loss: 1.2682961823884398e-05\n",
      "Epoch 1944, Loss: 0.0009024923201650381, Final Batch Loss: 0.0007442609639838338\n",
      "Epoch 1945, Loss: 0.0007309994543902576, Final Batch Loss: 0.000527924217749387\n",
      "Epoch 1946, Loss: 0.01565158523590071, Final Batch Loss: 9.66355946729891e-05\n",
      "Epoch 1947, Loss: 0.018027933321718592, Final Batch Loss: 9.22679973882623e-05\n",
      "Epoch 1948, Loss: 0.0011492407866171561, Final Batch Loss: 0.001043395372107625\n",
      "Epoch 1949, Loss: 0.00014371882662089774, Final Batch Loss: 9.086587851925287e-06\n",
      "Epoch 1950, Loss: 0.0007011143898125738, Final Batch Loss: 0.0006061040912754834\n",
      "Epoch 1951, Loss: 0.0018794465577229857, Final Batch Loss: 0.00036219332832843065\n",
      "Epoch 1952, Loss: 0.0003931416285922751, Final Batch Loss: 0.00020622400916181505\n",
      "Epoch 1953, Loss: 0.00879813835490495, Final Batch Loss: 0.007982691749930382\n",
      "Epoch 1954, Loss: 7.659782659175107e-05, Final Batch Loss: 1.3399906492850278e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1955, Loss: 0.001215961339767091, Final Batch Loss: 5.6755307014100254e-05\n",
      "Epoch 1956, Loss: 0.0001566445680509787, Final Batch Loss: 3.341410410939716e-05\n",
      "Epoch 1957, Loss: 0.007444266579113901, Final Batch Loss: 0.005734553094953299\n",
      "Epoch 1958, Loss: 0.0005224149208515882, Final Batch Loss: 0.00034736329689621925\n",
      "Epoch 1959, Loss: 0.0011430811646278016, Final Batch Loss: 5.323631194187328e-05\n",
      "Epoch 1960, Loss: 0.0025785275211092085, Final Batch Loss: 0.00017164027667604387\n",
      "Epoch 1961, Loss: 0.00015500754670938477, Final Batch Loss: 0.00012873391096945852\n",
      "Epoch 1962, Loss: 0.0003173058503307402, Final Batch Loss: 6.462095188908279e-05\n",
      "Epoch 1963, Loss: 0.001641231996472925, Final Batch Loss: 0.0014900118112564087\n",
      "Epoch 1964, Loss: 0.0013784637267235667, Final Batch Loss: 0.00015457873814739287\n",
      "Epoch 1965, Loss: 0.0004730097862193361, Final Batch Loss: 0.00012600758054759353\n",
      "Epoch 1966, Loss: 0.000778506335336715, Final Batch Loss: 0.00017746648518368602\n",
      "Epoch 1967, Loss: 0.0074359053978696465, Final Batch Loss: 0.005951534025371075\n",
      "Epoch 1968, Loss: 0.003936998778954148, Final Batch Loss: 0.0003521800972521305\n",
      "Epoch 1969, Loss: 0.009239295963197947, Final Batch Loss: 0.008327523246407509\n",
      "Epoch 1970, Loss: 0.00039286829996854067, Final Batch Loss: 7.653035572730005e-05\n",
      "Epoch 1971, Loss: 0.0005103599050926277, Final Batch Loss: 2.335791396035347e-05\n",
      "Epoch 1972, Loss: 0.0004161431425018236, Final Batch Loss: 4.076752520631999e-05\n",
      "Epoch 1973, Loss: 0.0006125086792962975, Final Batch Loss: 1.226365475304192e-05\n",
      "Epoch 1974, Loss: 0.0006672015297226608, Final Batch Loss: 0.00023926212452352047\n",
      "Epoch 1975, Loss: 0.00222579027285974, Final Batch Loss: 2.1447061953949742e-05\n",
      "Epoch 1976, Loss: 0.00328993919538334, Final Batch Loss: 0.0003048508078791201\n",
      "Epoch 1977, Loss: 0.0029378392500802875, Final Batch Loss: 0.0005694552091881633\n",
      "Epoch 1978, Loss: 0.005094170744996518, Final Batch Loss: 0.00013350247172638774\n",
      "Epoch 1979, Loss: 0.0025143814855255187, Final Batch Loss: 0.00019852683180943131\n",
      "Epoch 1980, Loss: 0.0007727077754680067, Final Batch Loss: 0.0004368565569166094\n",
      "Epoch 1981, Loss: 0.0005709337710868567, Final Batch Loss: 0.0005385065451264381\n",
      "Epoch 1982, Loss: 0.00033487767723272555, Final Batch Loss: 3.956169166485779e-05\n",
      "Epoch 1983, Loss: 0.0002127560946973972, Final Batch Loss: 9.348784806206822e-05\n",
      "Epoch 1984, Loss: 0.0002594082252471708, Final Batch Loss: 0.00019266769231762737\n",
      "Epoch 1985, Loss: 0.002367708511883393, Final Batch Loss: 0.0003990583645645529\n",
      "Epoch 1986, Loss: 0.0032426492543891072, Final Batch Loss: 0.0016558325150981545\n",
      "Epoch 1987, Loss: 0.0011109329643659294, Final Batch Loss: 0.00036609696689993143\n",
      "Epoch 1988, Loss: 0.00425837910734117, Final Batch Loss: 0.00395799707621336\n",
      "Epoch 1989, Loss: 0.000376795964257326, Final Batch Loss: 0.00026892361347563565\n",
      "Epoch 1990, Loss: 0.0037931085098534822, Final Batch Loss: 0.0014218895230442286\n",
      "Epoch 1991, Loss: 0.0002917711872214568, Final Batch Loss: 1.1132350664411206e-05\n",
      "Epoch 1992, Loss: 0.0046668473951285705, Final Batch Loss: 0.0044687669724226\n",
      "Epoch 1993, Loss: 0.0005538914119824767, Final Batch Loss: 0.00041857812902890146\n",
      "Epoch 1994, Loss: 0.008336780592799187, Final Batch Loss: 0.0019696936942636967\n",
      "Epoch 1995, Loss: 0.0005369659265852533, Final Batch Loss: 7.094136526575312e-05\n",
      "Epoch 1996, Loss: 0.0012207299669171334, Final Batch Loss: 3.3933401937247254e-06\n",
      "Epoch 1997, Loss: 0.0005073084939795081, Final Batch Loss: 3.0453204090008512e-05\n",
      "Epoch 1998, Loss: 0.0033211834088433534, Final Batch Loss: 0.00012802754645235837\n",
      "Epoch 1999, Loss: 0.0017394394672010094, Final Batch Loss: 0.0002122860460076481\n",
      "Epoch 2000, Loss: 0.005107425517053343, Final Batch Loss: 0.00017946901789400727\n",
      "Epoch 2001, Loss: 0.0002616798192320857, Final Batch Loss: 3.786936940741725e-05\n",
      "Epoch 2002, Loss: 0.00018859829833672848, Final Batch Loss: 2.5589781216694973e-05\n",
      "Epoch 2003, Loss: 0.0015059488359838724, Final Batch Loss: 0.00020173087250441313\n",
      "Epoch 2004, Loss: 0.017430997220799327, Final Batch Loss: 0.014936093240976334\n",
      "Epoch 2005, Loss: 0.00032767775701358914, Final Batch Loss: 0.00018569758685771376\n",
      "Epoch 2006, Loss: 7.092675332387444e-05, Final Batch Loss: 8.953347787610255e-06\n",
      "Epoch 2007, Loss: 0.002064614167466061, Final Batch Loss: 5.2340637921588495e-05\n",
      "Epoch 2008, Loss: 0.0003843439480988309, Final Batch Loss: 0.00030457391403615475\n",
      "Epoch 2009, Loss: 0.0013664267753483728, Final Batch Loss: 0.00024131541431415826\n",
      "Epoch 2010, Loss: 0.0010446554515510798, Final Batch Loss: 0.00014161330182105303\n",
      "Epoch 2011, Loss: 0.003281582548879669, Final Batch Loss: 1.643824543862138e-05\n",
      "Epoch 2012, Loss: 0.000407896517572226, Final Batch Loss: 3.6216824810253456e-05\n",
      "Epoch 2013, Loss: 0.0003481430612737313, Final Batch Loss: 1.3507946277968585e-05\n",
      "Epoch 2014, Loss: 0.001114680682803737, Final Batch Loss: 2.6252837415086105e-05\n",
      "Epoch 2015, Loss: 0.0014264777128119022, Final Batch Loss: 0.001148091396316886\n",
      "Epoch 2016, Loss: 0.00015188715406111442, Final Batch Loss: 2.8968872356927022e-05\n",
      "Epoch 2017, Loss: 0.00033202310441993177, Final Batch Loss: 0.00010721852595452219\n",
      "Epoch 2018, Loss: 0.0013316450640559196, Final Batch Loss: 0.0005994307575747371\n",
      "Epoch 2019, Loss: 0.00023006751871434972, Final Batch Loss: 6.226065306691453e-05\n",
      "Epoch 2020, Loss: 0.0006343508648569696, Final Batch Loss: 0.000578968960326165\n",
      "Epoch 2021, Loss: 0.0002750329367700033, Final Batch Loss: 0.000210006779525429\n",
      "Epoch 2022, Loss: 0.00040997477481141686, Final Batch Loss: 0.00010737607954069972\n",
      "Epoch 2023, Loss: 0.012007056036964059, Final Batch Loss: 0.0019272894132882357\n",
      "Epoch 2024, Loss: 0.006582676025573164, Final Batch Loss: 0.0005479897954501212\n",
      "Epoch 2025, Loss: 0.0003450307995080948, Final Batch Loss: 0.00012479985889513046\n",
      "Epoch 2026, Loss: 0.0006436692201532423, Final Batch Loss: 0.0002875054196920246\n",
      "Epoch 2027, Loss: 0.001612437321455218, Final Batch Loss: 8.701837214175612e-05\n",
      "Epoch 2028, Loss: 0.005279292294289917, Final Batch Loss: 0.004745223093777895\n",
      "Epoch 2029, Loss: 0.0019443856763246004, Final Batch Loss: 5.8467940107220784e-05\n",
      "Epoch 2030, Loss: 0.0020224840627633967, Final Batch Loss: 0.0019254244398325682\n",
      "Epoch 2031, Loss: 0.0012794387293979526, Final Batch Loss: 3.574730362743139e-05\n",
      "Epoch 2032, Loss: 0.0007179160020314157, Final Batch Loss: 8.693721611052752e-05\n",
      "Epoch 2033, Loss: 0.0006113150157034397, Final Batch Loss: 0.00034375188988633454\n",
      "Epoch 2034, Loss: 0.0011539787628862541, Final Batch Loss: 5.237305231275968e-05\n",
      "Epoch 2035, Loss: 0.0014742486971499602, Final Batch Loss: 3.5796408610622166e-06\n",
      "Epoch 2036, Loss: 0.0001917831050377572, Final Batch Loss: 1.7318825484835543e-05\n",
      "Epoch 2037, Loss: 0.00010794692934723571, Final Batch Loss: 5.0190563342766836e-05\n",
      "Epoch 2038, Loss: 0.00030887559478287585, Final Batch Loss: 2.275324732181616e-05\n",
      "Epoch 2039, Loss: 0.00026584972329146694, Final Batch Loss: 2.0555538867483847e-05\n",
      "Epoch 2040, Loss: 0.0003624538949225098, Final Batch Loss: 0.00016521984071005136\n",
      "Epoch 2041, Loss: 0.00036502251350611914, Final Batch Loss: 1.1762751455535181e-05\n",
      "Epoch 2042, Loss: 0.00028108789410907775, Final Batch Loss: 0.00014234943955671042\n",
      "Epoch 2043, Loss: 0.00012959884497831808, Final Batch Loss: 0.00012146640801802278\n",
      "Epoch 2044, Loss: 0.00033284653909504414, Final Batch Loss: 0.00020942041010130197\n",
      "Epoch 2045, Loss: 0.003163608576869592, Final Batch Loss: 0.00015845554298721254\n",
      "Epoch 2046, Loss: 0.00042597996070981026, Final Batch Loss: 0.00020358129404485226\n",
      "Epoch 2047, Loss: 0.0011568724148673937, Final Batch Loss: 0.0009984831558540463\n",
      "Epoch 2048, Loss: 0.0003731878550752299, Final Batch Loss: 2.181230411224533e-05\n",
      "Epoch 2049, Loss: 0.00032731435203459114, Final Batch Loss: 0.0002599489816930145\n",
      "Epoch 2050, Loss: 0.00019931717906729318, Final Batch Loss: 0.0001573529007146135\n",
      "Epoch 2051, Loss: 0.0011016177013516426, Final Batch Loss: 0.00024541548918932676\n",
      "Epoch 2052, Loss: 0.0024851280759321526, Final Batch Loss: 0.00022790343791712075\n",
      "Epoch 2053, Loss: 0.002144244674127549, Final Batch Loss: 0.0006539080641232431\n",
      "Epoch 2054, Loss: 0.0005418434084276669, Final Batch Loss: 0.00043955931323580444\n",
      "Epoch 2055, Loss: 0.00017090391338570043, Final Batch Loss: 7.141383684938774e-05\n",
      "Epoch 2056, Loss: 0.00011676911526592448, Final Batch Loss: 3.4009084629360586e-05\n",
      "Epoch 2057, Loss: 0.007365507015492767, Final Batch Loss: 0.006892738398164511\n",
      "Epoch 2058, Loss: 0.010933689423836768, Final Batch Loss: 0.010448681190609932\n",
      "Epoch 2059, Loss: 0.00151082084630616, Final Batch Loss: 0.00021979937446303666\n",
      "Epoch 2060, Loss: 0.0005033616471337155, Final Batch Loss: 0.0003407281474210322\n",
      "Epoch 2061, Loss: 0.00038359272184607107, Final Batch Loss: 0.00035547453444451094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2062, Loss: 0.00016291483552777208, Final Batch Loss: 0.00011091485794167966\n",
      "Epoch 2063, Loss: 0.00031820272488403134, Final Batch Loss: 0.00026120003894902766\n",
      "Epoch 2064, Loss: 0.0007247676076076459, Final Batch Loss: 4.730662840302102e-05\n",
      "Epoch 2065, Loss: 0.0004888722323812544, Final Batch Loss: 5.078912363387644e-05\n",
      "Epoch 2066, Loss: 0.0003897118494933238, Final Batch Loss: 2.422946818114724e-05\n",
      "Epoch 2067, Loss: 0.00011541464846231975, Final Batch Loss: 5.886573489988223e-05\n",
      "Epoch 2068, Loss: 0.0011378529015928507, Final Batch Loss: 0.0008449640590697527\n",
      "Epoch 2069, Loss: 0.0029021077207289636, Final Batch Loss: 0.0002846591523848474\n",
      "Epoch 2070, Loss: 0.00046523211494786665, Final Batch Loss: 9.756377403391525e-05\n",
      "Epoch 2071, Loss: 0.0052719276609423105, Final Batch Loss: 5.411703386926092e-05\n",
      "Epoch 2072, Loss: 0.0019449608807917684, Final Batch Loss: 0.0001226756430696696\n",
      "Epoch 2073, Loss: 0.0007274656054505613, Final Batch Loss: 1.8134418496629223e-05\n",
      "Epoch 2074, Loss: 0.0016132623832163517, Final Batch Loss: 1.4277099580795038e-05\n",
      "Epoch 2075, Loss: 0.0007043038931442425, Final Batch Loss: 0.00024055437825154513\n",
      "Epoch 2076, Loss: 0.0002860994354705326, Final Batch Loss: 0.0001908814738271758\n",
      "Epoch 2077, Loss: 0.001213008064951282, Final Batch Loss: 4.3040367017965764e-05\n",
      "Epoch 2078, Loss: 0.0008923535060603172, Final Batch Loss: 0.00046055426355451345\n",
      "Epoch 2079, Loss: 5.208349875829299e-05, Final Batch Loss: 5.824266281706514e-06\n",
      "Epoch 2080, Loss: 0.00021527402714127675, Final Batch Loss: 2.6044879632536322e-05\n",
      "Epoch 2081, Loss: 0.001672895466981572, Final Batch Loss: 2.5483155695837922e-05\n",
      "Epoch 2082, Loss: 0.0013853496056981385, Final Batch Loss: 0.0005209592636674643\n",
      "Epoch 2083, Loss: 0.00048002889434428653, Final Batch Loss: 1.3055257113592234e-05\n",
      "Epoch 2084, Loss: 0.0002634949705679901, Final Batch Loss: 0.00019264660659246147\n",
      "Epoch 2085, Loss: 0.002931967901531607, Final Batch Loss: 0.0027386308647692204\n",
      "Epoch 2086, Loss: 0.00472312933561625, Final Batch Loss: 0.004658251069486141\n",
      "Epoch 2087, Loss: 0.0003056774439755827, Final Batch Loss: 6.465692422352731e-05\n",
      "Epoch 2088, Loss: 1.7639280031289672e-05, Final Batch Loss: 5.0028806981572416e-06\n",
      "Epoch 2089, Loss: 6.019810462021269e-05, Final Batch Loss: 3.536218355293386e-05\n",
      "Epoch 2090, Loss: 0.001586654550919775, Final Batch Loss: 0.0015035764081403613\n",
      "Epoch 2091, Loss: 0.012883384188171476, Final Batch Loss: 0.0006208544946275651\n",
      "Epoch 2092, Loss: 0.0026866571861319244, Final Batch Loss: 0.0024242722429335117\n",
      "Epoch 2093, Loss: 0.0009677376001491211, Final Batch Loss: 0.00011459233792265877\n",
      "Epoch 2094, Loss: 0.004371412218461046, Final Batch Loss: 2.2078518668422475e-05\n",
      "Epoch 2095, Loss: 0.006692470051348209, Final Batch Loss: 0.0048142727464437485\n",
      "Epoch 2096, Loss: 0.00019348253408679739, Final Batch Loss: 0.00017276576545555145\n",
      "Epoch 2097, Loss: 6.36673566987156e-05, Final Batch Loss: 4.870397970080376e-05\n",
      "Epoch 2098, Loss: 0.00034166847763117403, Final Batch Loss: 0.0002776538021862507\n",
      "Epoch 2099, Loss: 0.004726221042801626, Final Batch Loss: 0.004681052174419165\n",
      "Epoch 2100, Loss: 0.0006198426999617368, Final Batch Loss: 0.00026829124544747174\n",
      "Epoch 2101, Loss: 0.0023412724840454757, Final Batch Loss: 0.00212311209179461\n",
      "Epoch 2102, Loss: 0.0002950187408714555, Final Batch Loss: 4.4868495024275035e-05\n",
      "Epoch 2103, Loss: 2.7911673896596767e-05, Final Batch Loss: 1.4084645954426378e-05\n",
      "Epoch 2104, Loss: 0.00049802397552412, Final Batch Loss: 6.797148671466857e-05\n",
      "Epoch 2105, Loss: 0.01408800552599132, Final Batch Loss: 0.013945584185421467\n",
      "Epoch 2106, Loss: 4.868350197284599e-05, Final Batch Loss: 2.060071437881561e-06\n",
      "Epoch 2107, Loss: 0.0002964638733828906, Final Batch Loss: 5.28931304870639e-05\n",
      "Epoch 2108, Loss: 0.0009200914146276773, Final Batch Loss: 0.0009078327566385269\n",
      "Epoch 2109, Loss: 0.00029572605376415595, Final Batch Loss: 2.6549339509074343e-06\n",
      "Epoch 2110, Loss: 3.2768561140983365e-05, Final Batch Loss: 1.5826055459911004e-05\n",
      "Epoch 2111, Loss: 0.0007320637232623994, Final Batch Loss: 0.00038519283407367766\n",
      "Epoch 2112, Loss: 0.001740659929055255, Final Batch Loss: 3.6782810639124364e-05\n",
      "Epoch 2113, Loss: 0.00037044523924123496, Final Batch Loss: 0.00012644397793337703\n",
      "Epoch 2114, Loss: 0.0003422877398406854, Final Batch Loss: 3.0426372177316807e-05\n",
      "Epoch 2115, Loss: 5.9002337820857065e-05, Final Batch Loss: 3.1189342735160608e-06\n",
      "Epoch 2116, Loss: 0.003643357544206083, Final Batch Loss: 0.0021174673456698656\n",
      "Epoch 2117, Loss: 0.0002856883256754372, Final Batch Loss: 4.217184687149711e-05\n",
      "Epoch 2118, Loss: 0.0006413684895960614, Final Batch Loss: 0.00020428722200449556\n",
      "Epoch 2119, Loss: 0.0004571823133119324, Final Batch Loss: 7.084182925609639e-06\n",
      "Epoch 2120, Loss: 0.00024993861734401435, Final Batch Loss: 0.00018940756854135543\n",
      "Epoch 2121, Loss: 0.0008584860479459167, Final Batch Loss: 9.311939356848598e-05\n",
      "Epoch 2122, Loss: 0.0002232254046248272, Final Batch Loss: 4.9257694627158344e-05\n",
      "Epoch 2123, Loss: 0.006399678904472239, Final Batch Loss: 1.0080634638143238e-06\n",
      "Epoch 2124, Loss: 0.0001606087507752818, Final Batch Loss: 4.999475095246453e-06\n",
      "Epoch 2125, Loss: 5.991961825202452e-05, Final Batch Loss: 8.970896487880964e-06\n",
      "Epoch 2126, Loss: 0.0001660062289374764, Final Batch Loss: 6.119592399045359e-06\n",
      "Epoch 2127, Loss: 0.0004414304348756559, Final Batch Loss: 9.046830382430926e-05\n",
      "Epoch 2128, Loss: 0.001317099668085575, Final Batch Loss: 0.000801446964032948\n",
      "Epoch 2129, Loss: 0.010371466167271137, Final Batch Loss: 0.004699445329606533\n",
      "Epoch 2130, Loss: 0.005129002071043942, Final Batch Loss: 0.005049081519246101\n",
      "Epoch 2131, Loss: 0.000327048051985912, Final Batch Loss: 1.1980024282820523e-05\n",
      "Epoch 2132, Loss: 0.004769863459841872, Final Batch Loss: 4.971764610672835e-06\n",
      "Epoch 2133, Loss: 0.002981368690598174, Final Batch Loss: 2.056598532362841e-06\n",
      "Epoch 2134, Loss: 0.0012824595614802092, Final Batch Loss: 0.00026407543919049203\n",
      "Epoch 2135, Loss: 0.0015422708675032482, Final Batch Loss: 0.0002426449063932523\n",
      "Epoch 2136, Loss: 0.0002018445302383043, Final Batch Loss: 7.236206874949858e-05\n",
      "Epoch 2137, Loss: 0.0007880752036726335, Final Batch Loss: 0.0007585107232443988\n",
      "Epoch 2138, Loss: 0.0014535068185068667, Final Batch Loss: 5.595892434939742e-05\n",
      "Epoch 2139, Loss: 0.0030621024779975414, Final Batch Loss: 0.0015458862762898207\n",
      "Epoch 2140, Loss: 0.00021482789270521607, Final Batch Loss: 8.980414349935018e-06\n",
      "Epoch 2141, Loss: 6.097109326219652e-05, Final Batch Loss: 2.5405968699487858e-05\n",
      "Epoch 2142, Loss: 0.00034930460969917476, Final Batch Loss: 0.00013565682456828654\n",
      "Epoch 2143, Loss: 0.0009005751853692345, Final Batch Loss: 4.838778841076419e-05\n",
      "Epoch 2144, Loss: 7.479403348042979e-05, Final Batch Loss: 5.982042694085976e-06\n",
      "Epoch 2145, Loss: 0.0007268968329299241, Final Batch Loss: 0.00045895809307694435\n",
      "Epoch 2146, Loss: 0.0032568060414632782, Final Batch Loss: 0.0031535145826637745\n",
      "Epoch 2147, Loss: 0.0001893390726763755, Final Batch Loss: 0.00011319824261590838\n",
      "Epoch 2148, Loss: 0.0013371850945986807, Final Batch Loss: 0.0012717912904918194\n",
      "Epoch 2149, Loss: 0.00033413364144507796, Final Batch Loss: 6.583695358131081e-05\n",
      "Epoch 2150, Loss: 0.0008249367820098996, Final Batch Loss: 0.000543303438462317\n",
      "Epoch 2151, Loss: 1.0519246643525548e-05, Final Batch Loss: 4.708856977231335e-06\n",
      "Epoch 2152, Loss: 0.00022684161149300053, Final Batch Loss: 6.757368737453362e-06\n",
      "Epoch 2153, Loss: 0.013570989078743878, Final Batch Loss: 0.013563758693635464\n",
      "Epoch 2154, Loss: 0.002868952877179254, Final Batch Loss: 0.0028344038873910904\n",
      "Epoch 2155, Loss: 0.00016946561663644388, Final Batch Loss: 0.00012927937495987862\n",
      "Epoch 2156, Loss: 0.0002766273173619993, Final Batch Loss: 0.00015887695190031081\n",
      "Epoch 2157, Loss: 0.00010894662773353048, Final Batch Loss: 9.303171100327745e-05\n",
      "Epoch 2158, Loss: 0.00036710566200781614, Final Batch Loss: 0.00027575890999287367\n",
      "Epoch 2159, Loss: 0.0011467476288089529, Final Batch Loss: 7.467438990715891e-05\n",
      "Epoch 2160, Loss: 0.0006933852437214227, Final Batch Loss: 0.000663742539472878\n",
      "Epoch 2161, Loss: 0.0015832017452339642, Final Batch Loss: 1.5191784768830985e-05\n",
      "Epoch 2162, Loss: 9.760219472809695e-05, Final Batch Loss: 3.023304816451855e-05\n",
      "Epoch 2163, Loss: 0.0007541794184362516, Final Batch Loss: 0.0002095002419082448\n",
      "Epoch 2164, Loss: 9.594089874553902e-05, Final Batch Loss: 1.3587321063823765e-06\n",
      "Epoch 2165, Loss: 7.893380916357273e-05, Final Batch Loss: 1.0580058187770192e-05\n",
      "Epoch 2166, Loss: 8.233513653976843e-05, Final Batch Loss: 3.070454840781167e-05\n",
      "Epoch 2167, Loss: 9.131089359470934e-05, Final Batch Loss: 1.3413784927251982e-06\n",
      "Epoch 2168, Loss: 0.0031789010854481603, Final Batch Loss: 1.5208776858344208e-05\n",
      "Epoch 2169, Loss: 0.00033832451481430326, Final Batch Loss: 1.838462230807636e-05\n",
      "Epoch 2170, Loss: 0.0006957068981137127, Final Batch Loss: 0.0003705529379658401\n",
      "Epoch 2171, Loss: 0.00021342217223718762, Final Batch Loss: 6.512079562526196e-05\n",
      "Epoch 2172, Loss: 0.0032196416759688873, Final Batch Loss: 0.0031822456512600183\n",
      "Epoch 2173, Loss: 0.00027186294028069824, Final Batch Loss: 0.00012714545300696045\n",
      "Epoch 2174, Loss: 0.002279523484503443, Final Batch Loss: 1.1994460692221764e-05\n",
      "Epoch 2175, Loss: 0.0037192929521552287, Final Batch Loss: 0.0036883950233459473\n",
      "Epoch 2176, Loss: 0.0008141793205140857, Final Batch Loss: 1.8877106413128786e-05\n",
      "Epoch 2177, Loss: 0.00015919662109808996, Final Batch Loss: 7.715434912825003e-05\n",
      "Epoch 2178, Loss: 0.0019589833973441273, Final Batch Loss: 0.0015080560697242618\n",
      "Epoch 2179, Loss: 0.009925921738613397, Final Batch Loss: 0.009608577005565166\n",
      "Epoch 2180, Loss: 0.0011666766076814383, Final Batch Loss: 3.318508970551193e-05\n",
      "Epoch 2181, Loss: 0.0007288735250767786, Final Batch Loss: 1.822375998017378e-05\n",
      "Epoch 2182, Loss: 0.00022068341786507517, Final Batch Loss: 7.505725079681724e-05\n",
      "Epoch 2183, Loss: 0.0011672594391711755, Final Batch Loss: 1.3088252671877854e-05\n",
      "Epoch 2184, Loss: 0.00043768556497525424, Final Batch Loss: 0.0002773607266135514\n",
      "Epoch 2185, Loss: 4.219081347400788e-05, Final Batch Loss: 2.338965168746654e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2186, Loss: 0.0004003939393442124, Final Batch Loss: 0.00018016158719547093\n",
      "Epoch 2187, Loss: 0.004613765573594719, Final Batch Loss: 0.0039585852064192295\n",
      "Epoch 2188, Loss: 0.00277369178365916, Final Batch Loss: 0.0025778391864150763\n",
      "Epoch 2189, Loss: 0.00020721269902423956, Final Batch Loss: 0.0001633412466617301\n",
      "Epoch 2190, Loss: 0.00016662773850839585, Final Batch Loss: 0.00011070627806475386\n",
      "Epoch 2191, Loss: 0.0008308500509883743, Final Batch Loss: 0.0007958763162605464\n",
      "Epoch 2192, Loss: 0.005001743862521835, Final Batch Loss: 0.00013446768571157008\n",
      "Epoch 2193, Loss: 0.0007495491299778223, Final Batch Loss: 0.0004976913915015757\n",
      "Epoch 2194, Loss: 0.0018052943355542084, Final Batch Loss: 5.848270575370407e-06\n",
      "Epoch 2195, Loss: 0.0022313870085781673, Final Batch Loss: 0.0022152962628751993\n",
      "Epoch 2196, Loss: 0.0004774394619744271, Final Batch Loss: 0.00013472509454004467\n",
      "Epoch 2197, Loss: 0.00024679865600774065, Final Batch Loss: 0.0001551084133097902\n",
      "Epoch 2198, Loss: 0.003707880612637382, Final Batch Loss: 0.00010338168794987723\n",
      "Epoch 2199, Loss: 0.01043338654562831, Final Batch Loss: 0.007468263152986765\n",
      "Epoch 2200, Loss: 0.00010724087042035535, Final Batch Loss: 8.834379696054384e-05\n",
      "Epoch 2201, Loss: 0.005174073041416705, Final Batch Loss: 0.003778833895921707\n",
      "Epoch 2202, Loss: 0.00015833790530450642, Final Batch Loss: 8.552573854103684e-05\n",
      "Epoch 2203, Loss: 0.0006933020849828608, Final Batch Loss: 0.000621490238700062\n",
      "Epoch 2204, Loss: 0.0007937821069390338, Final Batch Loss: 7.310402452276321e-06\n",
      "Epoch 2205, Loss: 0.00017926794816958136, Final Batch Loss: 5.682429673470324e-06\n",
      "Epoch 2206, Loss: 0.0019318225167808123, Final Batch Loss: 0.0018955968553200364\n",
      "Epoch 2207, Loss: 0.000950383189774584, Final Batch Loss: 0.00012199702177895233\n",
      "Epoch 2208, Loss: 0.04022350051673129, Final Batch Loss: 0.04017259553074837\n",
      "Epoch 2209, Loss: 5.366141704143956e-05, Final Batch Loss: 1.7630638467380777e-05\n",
      "Epoch 2210, Loss: 0.0034514660401328, Final Batch Loss: 0.003432278521358967\n",
      "Epoch 2211, Loss: 0.0008088914037216455, Final Batch Loss: 0.00015065059415064752\n",
      "Epoch 2212, Loss: 0.00031924277755024377, Final Batch Loss: 2.8680495233857073e-05\n",
      "Epoch 2213, Loss: 8.888714592103497e-05, Final Batch Loss: 5.744399913965026e-06\n",
      "Epoch 2214, Loss: 0.0019004593195859343, Final Batch Loss: 0.00020645910990424454\n",
      "Epoch 2215, Loss: 0.009461420471780002, Final Batch Loss: 0.0003888373030349612\n",
      "Epoch 2216, Loss: 0.0003187808470102027, Final Batch Loss: 0.0002862715919036418\n",
      "Epoch 2217, Loss: 0.00031645836133975536, Final Batch Loss: 8.304409857373685e-05\n",
      "Epoch 2218, Loss: 5.8606356105883606e-05, Final Batch Loss: 1.4444567568716593e-05\n",
      "Epoch 2219, Loss: 0.00014946407463867217, Final Batch Loss: 7.762353925500065e-05\n",
      "Epoch 2220, Loss: 0.0005387892342696432, Final Batch Loss: 4.0963383071357384e-05\n",
      "Epoch 2221, Loss: 0.0005072032727184705, Final Batch Loss: 0.00042094264063052833\n",
      "Epoch 2222, Loss: 0.0010356123275414575, Final Batch Loss: 0.000994569854810834\n",
      "Epoch 2223, Loss: 0.00048440368846058846, Final Batch Loss: 0.00014551612548530102\n",
      "Epoch 2224, Loss: 0.00012495858936745208, Final Batch Loss: 1.3869064787286334e-05\n",
      "Epoch 2225, Loss: 5.586149291048059e-05, Final Batch Loss: 1.4352925973071251e-05\n",
      "Epoch 2226, Loss: 0.0017380426288582385, Final Batch Loss: 0.0008296981104649603\n",
      "Epoch 2227, Loss: 0.00020598973060259596, Final Batch Loss: 6.79306176607497e-05\n",
      "Epoch 2228, Loss: 0.00012163168503320776, Final Batch Loss: 3.349221151438542e-05\n",
      "Epoch 2229, Loss: 5.0306359298701864e-05, Final Batch Loss: 1.4950749573472422e-05\n",
      "Epoch 2230, Loss: 0.0007510247232858092, Final Batch Loss: 0.00010720119462348521\n",
      "Epoch 2231, Loss: 0.0004213059364701621, Final Batch Loss: 0.00034855620469897985\n",
      "Epoch 2232, Loss: 0.0023909984156489372, Final Batch Loss: 0.0014416907215490937\n",
      "Epoch 2233, Loss: 0.0006776934169465676, Final Batch Loss: 0.00045225699432194233\n",
      "Epoch 2234, Loss: 0.005073199397884309, Final Batch Loss: 0.0010033984435722232\n",
      "Epoch 2235, Loss: 0.00018360540707362816, Final Batch Loss: 0.00012549213715828955\n",
      "Epoch 2236, Loss: 0.00016191956092370674, Final Batch Loss: 1.8090802768711e-05\n",
      "Epoch 2237, Loss: 0.0006970207541598938, Final Batch Loss: 0.0006362602580338717\n",
      "Epoch 2238, Loss: 0.0007714501407463104, Final Batch Loss: 0.0005927077727392316\n",
      "Epoch 2239, Loss: 0.00039595850103069097, Final Batch Loss: 0.00015663012163713574\n",
      "Epoch 2240, Loss: 0.00021802264382131398, Final Batch Loss: 0.00015043960593175143\n",
      "Epoch 2241, Loss: 0.0023700762540102005, Final Batch Loss: 0.001254971488378942\n",
      "Epoch 2242, Loss: 0.004405285573739093, Final Batch Loss: 0.00430062972009182\n",
      "Epoch 2243, Loss: 8.322834537466406e-05, Final Batch Loss: 7.784255285514519e-05\n",
      "Epoch 2244, Loss: 0.0003920131712220609, Final Batch Loss: 0.00029606567113660276\n",
      "Epoch 2245, Loss: 0.00013486175521393307, Final Batch Loss: 2.5514458684483543e-05\n",
      "Epoch 2246, Loss: 0.0009019778808578849, Final Batch Loss: 0.00039514113450422883\n",
      "Epoch 2247, Loss: 0.00026491434982744977, Final Batch Loss: 0.0001451924763387069\n",
      "Epoch 2248, Loss: 0.004268543228135968, Final Batch Loss: 0.004256377927958965\n",
      "Epoch 2249, Loss: 0.005033153807744384, Final Batch Loss: 0.003861664794385433\n",
      "Epoch 2250, Loss: 0.04980039270594716, Final Batch Loss: 0.0002493453212082386\n",
      "Epoch 2251, Loss: 0.0003257356947869994, Final Batch Loss: 0.00022084540978539735\n",
      "Epoch 2252, Loss: 0.009418017958523706, Final Batch Loss: 4.229581099934876e-05\n",
      "Epoch 2253, Loss: 0.00798084694542922, Final Batch Loss: 0.007823469117283821\n",
      "Epoch 2254, Loss: 0.005691456142812967, Final Batch Loss: 0.004389356821775436\n",
      "Epoch 2255, Loss: 0.000632385301287286, Final Batch Loss: 4.6087647206149995e-05\n",
      "Epoch 2256, Loss: 0.009031915105879307, Final Batch Loss: 0.0021980335004627705\n",
      "Epoch 2257, Loss: 0.0024796832003630698, Final Batch Loss: 0.0003949055098928511\n",
      "Epoch 2258, Loss: 0.014943143352866173, Final Batch Loss: 0.012973140925168991\n",
      "Epoch 2259, Loss: 0.0026376329187769443, Final Batch Loss: 0.00044656082172878087\n",
      "Epoch 2260, Loss: 0.00011276694021944422, Final Batch Loss: 1.3408165614237078e-05\n",
      "Epoch 2261, Loss: 0.0005043702549301088, Final Batch Loss: 4.545817500911653e-05\n",
      "Epoch 2262, Loss: 0.00042807233694475144, Final Batch Loss: 0.0002492872881703079\n",
      "Epoch 2263, Loss: 0.00047377684677485377, Final Batch Loss: 0.00012427767796907574\n",
      "Epoch 2264, Loss: 0.006816387991420925, Final Batch Loss: 0.0011987759498879313\n",
      "Epoch 2265, Loss: 0.0822121798992157, Final Batch Loss: 0.07407553493976593\n",
      "Epoch 2266, Loss: 0.0008706044754944742, Final Batch Loss: 0.0005821652594022453\n",
      "Epoch 2267, Loss: 0.0028986348188482225, Final Batch Loss: 0.002716523827984929\n",
      "Epoch 2268, Loss: 0.000295074496534653, Final Batch Loss: 6.123633647803217e-05\n",
      "Epoch 2269, Loss: 0.0038841605783090927, Final Batch Loss: 0.003762239357456565\n",
      "Epoch 2270, Loss: 7.658796130272094e-05, Final Batch Loss: 2.148868406948168e-05\n",
      "Epoch 2271, Loss: 0.0002522826034692116, Final Batch Loss: 0.00010003035276895389\n",
      "Epoch 2272, Loss: 0.002318852180906106, Final Batch Loss: 6.297889194684103e-05\n",
      "Epoch 2273, Loss: 0.028244721150258556, Final Batch Loss: 0.00032938868389464915\n",
      "Epoch 2274, Loss: 0.001237512806255836, Final Batch Loss: 0.00011053961497964337\n",
      "Epoch 2275, Loss: 0.006413815397536382, Final Batch Loss: 0.0004118609649594873\n",
      "Epoch 2276, Loss: 0.00029702208121307194, Final Batch Loss: 7.558548531960696e-05\n",
      "Epoch 2277, Loss: 0.00015323122079280438, Final Batch Loss: 1.2602530659933109e-05\n",
      "Epoch 2278, Loss: 0.011996543413260952, Final Batch Loss: 0.00014901105896569788\n",
      "Epoch 2279, Loss: 0.00016463667270727456, Final Batch Loss: 7.911097054602578e-05\n",
      "Epoch 2280, Loss: 0.00040609666757518426, Final Batch Loss: 5.758379847975448e-05\n",
      "Epoch 2281, Loss: 0.00014707342415931635, Final Batch Loss: 5.086110832053237e-05\n",
      "Epoch 2282, Loss: 0.0005144603637745604, Final Batch Loss: 3.5258897696621716e-05\n",
      "Epoch 2283, Loss: 0.0033650242839939892, Final Batch Loss: 0.00322464806959033\n",
      "Epoch 2284, Loss: 0.0007633239256392699, Final Batch Loss: 1.0557832865742967e-05\n",
      "Epoch 2285, Loss: 0.004156673690886237, Final Batch Loss: 0.004006561823189259\n",
      "Epoch 2286, Loss: 0.00012453142517188098, Final Batch Loss: 1.8824493963620625e-05\n",
      "Epoch 2287, Loss: 0.0005659196649503428, Final Batch Loss: 1.903051816043444e-05\n",
      "Epoch 2288, Loss: 0.0004122429236304015, Final Batch Loss: 0.00019497635366860777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2289, Loss: 0.0007666029559914023, Final Batch Loss: 0.0006840607384219766\n",
      "Epoch 2290, Loss: 0.00014506563456961885, Final Batch Loss: 6.23159867245704e-05\n",
      "Epoch 2291, Loss: 0.00027024954033549875, Final Batch Loss: 9.413197403773665e-05\n",
      "Epoch 2292, Loss: 0.0010931692740996368, Final Batch Loss: 2.892578049795702e-05\n",
      "Epoch 2293, Loss: 0.001629117912671063, Final Batch Loss: 0.0015157508896663785\n",
      "Epoch 2294, Loss: 0.0004891321332252119, Final Batch Loss: 0.0004674067022278905\n",
      "Epoch 2295, Loss: 0.0004534392719506286, Final Batch Loss: 9.640570351621136e-05\n",
      "Epoch 2296, Loss: 0.0008994253221317194, Final Batch Loss: 9.129233512794599e-05\n",
      "Epoch 2297, Loss: 0.00034567765760584734, Final Batch Loss: 4.737189374282025e-05\n",
      "Epoch 2298, Loss: 0.0037444265908561647, Final Batch Loss: 0.0035029412247240543\n",
      "Epoch 2299, Loss: 0.00429880568117369, Final Batch Loss: 0.0001867203536676243\n",
      "Epoch 2300, Loss: 0.0004353024924057536, Final Batch Loss: 0.00038033275632187724\n",
      "Epoch 2301, Loss: 0.00019832487851090264, Final Batch Loss: 2.4643448341521434e-05\n",
      "Epoch 2302, Loss: 0.0020429854630492628, Final Batch Loss: 0.0016308866906911135\n",
      "Epoch 2303, Loss: 0.0021366319633671083, Final Batch Loss: 6.151278648758307e-05\n",
      "Epoch 2304, Loss: 0.0009024581522680819, Final Batch Loss: 0.00040524365613237023\n",
      "Epoch 2305, Loss: 0.0018916071858257055, Final Batch Loss: 0.00047005992382764816\n",
      "Epoch 2306, Loss: 0.00019838460866594687, Final Batch Loss: 6.825279706390575e-05\n",
      "Epoch 2307, Loss: 0.0027539546135812998, Final Batch Loss: 0.000875579658895731\n",
      "Epoch 2308, Loss: 0.0002952562499558553, Final Batch Loss: 0.00015226821415126324\n",
      "Epoch 2309, Loss: 0.001863516925368458, Final Batch Loss: 0.0002859524101950228\n",
      "Epoch 2310, Loss: 0.0004715002069133334, Final Batch Loss: 0.0004300300497561693\n",
      "Epoch 2311, Loss: 7.395675584120909e-05, Final Batch Loss: 1.3538739040086512e-05\n",
      "Epoch 2312, Loss: 0.0010906170355156064, Final Batch Loss: 0.0002668118104338646\n",
      "Epoch 2313, Loss: 0.004803642441402189, Final Batch Loss: 0.0046128458343446255\n",
      "Epoch 2314, Loss: 0.0021099813038745197, Final Batch Loss: 2.0455265257623978e-05\n",
      "Epoch 2315, Loss: 0.0005723894432776433, Final Batch Loss: 2.5831836865108926e-06\n",
      "Epoch 2316, Loss: 0.0009949395898729563, Final Batch Loss: 0.000153834349475801\n",
      "Epoch 2317, Loss: 0.0011911188885278534, Final Batch Loss: 2.2436764993472025e-05\n",
      "Epoch 2318, Loss: 0.0006304738280960009, Final Batch Loss: 1.0511133041291032e-05\n",
      "Epoch 2319, Loss: 0.00026250549854012206, Final Batch Loss: 0.00019631221948657185\n",
      "Epoch 2320, Loss: 0.00026651049847714603, Final Batch Loss: 0.00010051748540718108\n",
      "Epoch 2321, Loss: 0.0003387628894415684, Final Batch Loss: 0.00022555085888598114\n",
      "Epoch 2322, Loss: 0.0033364557602908462, Final Batch Loss: 0.00025548911071382463\n",
      "Epoch 2323, Loss: 0.0004729635184048675, Final Batch Loss: 6.046308408258483e-05\n",
      "Epoch 2324, Loss: 0.0010303747840225697, Final Batch Loss: 0.00053687539184466\n",
      "Epoch 2325, Loss: 0.0015667350889998488, Final Batch Loss: 3.373237996129319e-05\n",
      "Epoch 2326, Loss: 0.0004396209551487118, Final Batch Loss: 0.00016896033775992692\n",
      "Epoch 2327, Loss: 3.8873964513186365e-05, Final Batch Loss: 2.1326952264644206e-05\n",
      "Epoch 2328, Loss: 0.0004409550747368485, Final Batch Loss: 7.949117571115494e-05\n",
      "Epoch 2329, Loss: 0.0001407284835295286, Final Batch Loss: 2.044201028184034e-05\n",
      "Epoch 2330, Loss: 0.0004923792076851896, Final Batch Loss: 1.628381255613931e-06\n",
      "Epoch 2331, Loss: 0.0014973416546126828, Final Batch Loss: 0.0014088823227211833\n",
      "Epoch 2332, Loss: 0.0007976908818818629, Final Batch Loss: 0.0004631148767657578\n",
      "Epoch 2333, Loss: 0.00011218548752367496, Final Batch Loss: 3.657353954622522e-05\n",
      "Epoch 2334, Loss: 0.0005757050676038489, Final Batch Loss: 0.0002377150085521862\n",
      "Epoch 2335, Loss: 0.00010278492845827714, Final Batch Loss: 3.116310836048797e-05\n",
      "Epoch 2336, Loss: 0.007940222369143157, Final Batch Loss: 0.0079117426648736\n",
      "Epoch 2337, Loss: 0.0021418598771560937, Final Batch Loss: 0.00046362009015865624\n",
      "Epoch 2338, Loss: 0.0005183685861993581, Final Batch Loss: 0.000267595547484234\n",
      "Epoch 2339, Loss: 0.00047767499199835584, Final Batch Loss: 0.0004332657263148576\n",
      "Epoch 2340, Loss: 0.002478898109984584, Final Batch Loss: 7.416594598907977e-05\n",
      "Epoch 2341, Loss: 0.002478781680110842, Final Batch Loss: 0.0007183886482380331\n",
      "Epoch 2342, Loss: 0.00035214554736739956, Final Batch Loss: 3.56081836798694e-05\n",
      "Epoch 2343, Loss: 0.0022986199765000492, Final Batch Loss: 0.00028537624166347086\n",
      "Epoch 2344, Loss: 0.0002931463786808308, Final Batch Loss: 0.0002598911232780665\n",
      "Epoch 2345, Loss: 0.004491097599384375, Final Batch Loss: 0.00426727207377553\n",
      "Epoch 2346, Loss: 0.00019618993974290788, Final Batch Loss: 2.3247761419042945e-05\n",
      "Epoch 2347, Loss: 0.02090957657492254, Final Batch Loss: 0.020786253735423088\n",
      "Epoch 2348, Loss: 0.00036963800448575057, Final Batch Loss: 3.817910692305304e-05\n",
      "Epoch 2349, Loss: 0.00019961612633778714, Final Batch Loss: 2.0783914806088433e-05\n",
      "Epoch 2350, Loss: 0.0024693280502106063, Final Batch Loss: 5.399440851761028e-05\n",
      "Epoch 2351, Loss: 0.0013265244997455738, Final Batch Loss: 7.921558426460251e-05\n",
      "Epoch 2352, Loss: 0.0017028224410751136, Final Batch Loss: 2.384749132033903e-05\n",
      "Epoch 2353, Loss: 0.0006011571203998756, Final Batch Loss: 1.7839814972830936e-05\n",
      "Epoch 2354, Loss: 0.0007051275897538289, Final Batch Loss: 0.000652677146717906\n",
      "Epoch 2355, Loss: 0.0005402399983722717, Final Batch Loss: 4.544257535599172e-05\n",
      "Epoch 2356, Loss: 0.007469891104847193, Final Batch Loss: 0.0044842977076768875\n",
      "Epoch 2357, Loss: 0.000408342806622386, Final Batch Loss: 0.00027703886735253036\n",
      "Epoch 2358, Loss: 0.0012442132028809283, Final Batch Loss: 3.449502764851786e-05\n",
      "Epoch 2359, Loss: 0.0014550910145771923, Final Batch Loss: 2.538071021263022e-05\n",
      "Epoch 2360, Loss: 0.026178553380304947, Final Batch Loss: 0.026043055579066277\n",
      "Epoch 2361, Loss: 0.0013769668876193464, Final Batch Loss: 2.386100823059678e-05\n",
      "Epoch 2362, Loss: 0.0013161501265130937, Final Batch Loss: 0.0005878802039660513\n",
      "Epoch 2363, Loss: 0.004569404642097652, Final Batch Loss: 0.0005629783263429999\n",
      "Epoch 2364, Loss: 0.00012434914242476225, Final Batch Loss: 6.119527824921533e-05\n",
      "Epoch 2365, Loss: 0.0002588857460068539, Final Batch Loss: 0.00020457044593058527\n",
      "Epoch 2366, Loss: 8.23003920231713e-05, Final Batch Loss: 2.193382715631742e-05\n",
      "Epoch 2367, Loss: 0.00035951151221524924, Final Batch Loss: 0.00013820854655932635\n",
      "Epoch 2368, Loss: 0.00047307322347478475, Final Batch Loss: 2.3541628252132796e-05\n",
      "Epoch 2369, Loss: 0.0012664160021813586, Final Batch Loss: 0.001179199549369514\n",
      "Epoch 2370, Loss: 0.0026429809076944366, Final Batch Loss: 0.00021368767193052918\n",
      "Epoch 2371, Loss: 0.00026018903008662164, Final Batch Loss: 2.8576847398653626e-05\n",
      "Epoch 2372, Loss: 0.00010326833944418468, Final Batch Loss: 5.422771209850907e-05\n",
      "Epoch 2373, Loss: 0.0003944274199056963, Final Batch Loss: 7.320921667997027e-06\n",
      "Epoch 2374, Loss: 0.0002533271472202614, Final Batch Loss: 0.0001599507813807577\n",
      "Epoch 2375, Loss: 0.006376247853040695, Final Batch Loss: 0.0040465244092047215\n",
      "Epoch 2376, Loss: 0.0032390747510362417, Final Batch Loss: 0.0002448933955747634\n",
      "Epoch 2377, Loss: 0.007325364953430835, Final Batch Loss: 0.0072261495515704155\n",
      "Epoch 2378, Loss: 0.0002809464349411428, Final Batch Loss: 7.706032192800194e-05\n",
      "Epoch 2379, Loss: 9.922523167915642e-05, Final Batch Loss: 3.685739648062736e-05\n",
      "Epoch 2380, Loss: 0.00022267622989602387, Final Batch Loss: 0.00011240128515055403\n",
      "Epoch 2381, Loss: 0.00039359358606816386, Final Batch Loss: 5.1260763029858936e-06\n",
      "Epoch 2382, Loss: 0.0009183879010379314, Final Batch Loss: 0.00088517862604931\n",
      "Epoch 2383, Loss: 0.00155820100553683, Final Batch Loss: 2.1144831407582387e-05\n",
      "Epoch 2384, Loss: 0.00015482884373341221, Final Batch Loss: 0.00012700559454970062\n",
      "Epoch 2385, Loss: 0.0009871982620097697, Final Batch Loss: 0.0008344420930370688\n",
      "Epoch 2386, Loss: 0.0017995603557210416, Final Batch Loss: 0.0003002618614118546\n",
      "Epoch 2387, Loss: 0.0004334853874752298, Final Batch Loss: 0.0002675728756003082\n",
      "Epoch 2388, Loss: 0.0015009082271717489, Final Batch Loss: 0.00019393378170207143\n",
      "Epoch 2389, Loss: 0.0005758391052950174, Final Batch Loss: 0.00028959926567040384\n",
      "Epoch 2390, Loss: 0.0004424865182954818, Final Batch Loss: 0.0003935396671295166\n",
      "Epoch 2391, Loss: 0.0027056068647652864, Final Batch Loss: 0.00035837898030877113\n",
      "Epoch 2392, Loss: 0.000443337150500156, Final Batch Loss: 0.0002803030365612358\n",
      "Epoch 2393, Loss: 0.0005951359962637071, Final Batch Loss: 2.19660323637072e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2394, Loss: 0.0016562012606300414, Final Batch Loss: 0.0009704739786684513\n",
      "Epoch 2395, Loss: 0.0030471905192825943, Final Batch Loss: 0.002667834283784032\n",
      "Epoch 2396, Loss: 0.0010688413894968107, Final Batch Loss: 0.0009067573701031506\n",
      "Epoch 2397, Loss: 0.0021770089042547625, Final Batch Loss: 4.670513953897171e-05\n",
      "Epoch 2398, Loss: 0.00037003272882429883, Final Batch Loss: 0.00028923057834617794\n",
      "Epoch 2399, Loss: 0.0018179838079959154, Final Batch Loss: 0.0003222191007807851\n",
      "Epoch 2400, Loss: 9.431984290131368e-05, Final Batch Loss: 5.8469628129387274e-05\n",
      "Epoch 2401, Loss: 0.00015054282039272948, Final Batch Loss: 6.74981629344984e-06\n",
      "Epoch 2402, Loss: 0.00040220897062681615, Final Batch Loss: 0.00022933368745725602\n",
      "Epoch 2403, Loss: 0.0003390489873709157, Final Batch Loss: 0.00014580361312255263\n",
      "Epoch 2404, Loss: 0.002574489190010354, Final Batch Loss: 0.0022640815004706383\n",
      "Epoch 2405, Loss: 5.465024514705874e-05, Final Batch Loss: 2.5052613636944443e-05\n",
      "Epoch 2406, Loss: 0.00023046387468639296, Final Batch Loss: 1.1276510122115724e-05\n",
      "Epoch 2407, Loss: 0.00512661668471992, Final Batch Loss: 0.004235770553350449\n",
      "Epoch 2408, Loss: 0.006087517365813255, Final Batch Loss: 0.005423045251518488\n",
      "Epoch 2409, Loss: 0.0020224252803018317, Final Batch Loss: 9.050079097505659e-05\n",
      "Epoch 2410, Loss: 0.00018599132090457715, Final Batch Loss: 0.0001613932108739391\n",
      "Epoch 2411, Loss: 0.00013692925131181255, Final Batch Loss: 2.3860804503783584e-05\n",
      "Epoch 2412, Loss: 0.0037079195099067874, Final Batch Loss: 0.003659997833892703\n",
      "Epoch 2413, Loss: 0.0005862026591785252, Final Batch Loss: 0.0002755647001322359\n",
      "Epoch 2414, Loss: 3.359595393703785e-05, Final Batch Loss: 8.114566298900172e-06\n",
      "Epoch 2415, Loss: 0.0005727132956963032, Final Batch Loss: 0.00033873130450956523\n",
      "Epoch 2416, Loss: 0.0006101456128817517, Final Batch Loss: 0.0005946847377344966\n",
      "Epoch 2417, Loss: 0.0001379286841256544, Final Batch Loss: 6.58621356706135e-05\n",
      "Epoch 2418, Loss: 0.000196813383809058, Final Batch Loss: 3.794559961534105e-05\n",
      "Epoch 2419, Loss: 0.0003154466685373336, Final Batch Loss: 0.00014205613115336746\n",
      "Epoch 2420, Loss: 0.00041580837250876357, Final Batch Loss: 2.414101345493691e-06\n",
      "Epoch 2421, Loss: 0.0033528099302202463, Final Batch Loss: 0.0019880805630236864\n",
      "Epoch 2422, Loss: 0.008363135319086723, Final Batch Loss: 0.0001547766587464139\n",
      "Epoch 2423, Loss: 0.00012893840448668925, Final Batch Loss: 1.1407671081542503e-05\n",
      "Epoch 2424, Loss: 0.00011705570068443194, Final Batch Loss: 1.2846678146161139e-05\n",
      "Epoch 2425, Loss: 0.00027263628726359457, Final Batch Loss: 0.00017313426360487938\n",
      "Epoch 2426, Loss: 0.00012793692803825252, Final Batch Loss: 4.4688476918963715e-05\n",
      "Epoch 2427, Loss: 7.395950979116606e-05, Final Batch Loss: 9.023036000144202e-06\n",
      "Epoch 2428, Loss: 0.00013153770942153642, Final Batch Loss: 0.00012196168245282024\n",
      "Epoch 2429, Loss: 0.00011729840116458945, Final Batch Loss: 4.8989724746206775e-05\n",
      "Epoch 2430, Loss: 7.976376582519151e-05, Final Batch Loss: 2.7717909688362852e-05\n",
      "Epoch 2431, Loss: 0.00385761978031951, Final Batch Loss: 0.0038338724989444017\n",
      "Epoch 2432, Loss: 0.000583141518291086, Final Batch Loss: 0.00042878935346379876\n",
      "Epoch 2433, Loss: 0.00018209288464277051, Final Batch Loss: 3.585715239751153e-05\n",
      "Epoch 2434, Loss: 0.0006714333285344765, Final Batch Loss: 0.000628860667347908\n",
      "Epoch 2435, Loss: 9.31469548959285e-05, Final Batch Loss: 2.3461987439077348e-05\n",
      "Epoch 2436, Loss: 0.0028174565522931516, Final Batch Loss: 0.002457882510498166\n",
      "Epoch 2437, Loss: 0.00031130875140661374, Final Batch Loss: 0.00011760573397623375\n",
      "Epoch 2438, Loss: 2.759318067546701e-05, Final Batch Loss: 1.111520850827219e-05\n",
      "Epoch 2439, Loss: 0.0021243455121293664, Final Batch Loss: 0.0008102359715849161\n",
      "Epoch 2440, Loss: 9.850119749899022e-05, Final Batch Loss: 8.440381498076022e-05\n",
      "Epoch 2441, Loss: 0.0008354357923963107, Final Batch Loss: 4.536900814855471e-05\n",
      "Epoch 2442, Loss: 0.00011755553168768529, Final Batch Loss: 8.390039511141367e-06\n",
      "Epoch 2443, Loss: 7.140606635402946e-05, Final Batch Loss: 3.136214445476071e-06\n",
      "Epoch 2444, Loss: 0.016257529224731115, Final Batch Loss: 0.016251342371106148\n",
      "Epoch 2445, Loss: 0.0001378244487568736, Final Batch Loss: 6.10442875768058e-05\n",
      "Epoch 2446, Loss: 7.090010512911249e-05, Final Batch Loss: 4.214894215692766e-05\n",
      "Epoch 2447, Loss: 0.00040118165634339675, Final Batch Loss: 3.571749402908608e-05\n",
      "Epoch 2448, Loss: 0.000303183031064691, Final Batch Loss: 0.0002699611650314182\n",
      "Epoch 2449, Loss: 0.00014765760715818033, Final Batch Loss: 7.664619624847546e-05\n",
      "Epoch 2450, Loss: 0.0006235068140085787, Final Batch Loss: 0.0005955123342573643\n",
      "Epoch 2451, Loss: 0.0002497756067896262, Final Batch Loss: 3.64440493285656e-05\n",
      "Epoch 2452, Loss: 0.0006667672569165006, Final Batch Loss: 0.0004782775358762592\n",
      "Epoch 2453, Loss: 0.001346624325378798, Final Batch Loss: 0.001283271238207817\n",
      "Epoch 2454, Loss: 0.0008496143782394938, Final Batch Loss: 0.0007500389474444091\n",
      "Epoch 2455, Loss: 0.0013366542552830651, Final Batch Loss: 0.0012243320234119892\n",
      "Epoch 2456, Loss: 0.00016223232887568884, Final Batch Loss: 3.279286829638295e-05\n",
      "Epoch 2457, Loss: 0.0015628460387233645, Final Batch Loss: 6.0241116443648934e-05\n",
      "Epoch 2458, Loss: 0.0019428543600952253, Final Batch Loss: 0.00013579240476246923\n",
      "Epoch 2459, Loss: 0.0010983427964674775, Final Batch Loss: 0.001054862979799509\n",
      "Epoch 2460, Loss: 0.005719988606870174, Final Batch Loss: 0.0015082824975252151\n",
      "Epoch 2461, Loss: 0.00018256342445965856, Final Batch Loss: 0.0001387143274769187\n",
      "Epoch 2462, Loss: 0.0003983212518505752, Final Batch Loss: 8.536281529814005e-05\n",
      "Epoch 2463, Loss: 0.003671950369607657, Final Batch Loss: 0.0031610133592039347\n",
      "Epoch 2464, Loss: 0.0002857103099813685, Final Batch Loss: 4.071769944857806e-05\n",
      "Epoch 2465, Loss: 0.0015170405094977468, Final Batch Loss: 0.00036826086579822004\n",
      "Epoch 2466, Loss: 0.0021443705045385286, Final Batch Loss: 0.002109355526044965\n",
      "Epoch 2467, Loss: 0.0003283115820522653, Final Batch Loss: 2.4063543605734594e-05\n",
      "Epoch 2468, Loss: 0.002705301681999117, Final Batch Loss: 0.00015579565661028028\n",
      "Epoch 2469, Loss: 2.7630585464066826e-05, Final Batch Loss: 9.851666618487798e-06\n",
      "Epoch 2470, Loss: 0.00030824866553302854, Final Batch Loss: 0.00015017477562651038\n",
      "Epoch 2471, Loss: 0.0005172844394110143, Final Batch Loss: 0.0002570900251157582\n",
      "Epoch 2472, Loss: 0.00016103701636893675, Final Batch Loss: 0.0001146018912550062\n",
      "Epoch 2473, Loss: 0.00022211654140846804, Final Batch Loss: 0.0001230183115694672\n",
      "Epoch 2474, Loss: 0.00029863634654248017, Final Batch Loss: 7.400601589324651e-06\n",
      "Epoch 2475, Loss: 0.00041246794717153534, Final Batch Loss: 3.119327448075637e-05\n",
      "Epoch 2476, Loss: 0.0014027584111317992, Final Batch Loss: 0.0002551166107878089\n",
      "Epoch 2477, Loss: 5.1458177040331066e-05, Final Batch Loss: 1.1090178304584697e-05\n",
      "Epoch 2478, Loss: 0.000946550011576619, Final Batch Loss: 9.963349293684587e-05\n",
      "Epoch 2479, Loss: 0.00011463884220574982, Final Batch Loss: 6.951090472284704e-05\n",
      "Epoch 2480, Loss: 0.0027954430545378273, Final Batch Loss: 0.002791790757328272\n",
      "Epoch 2481, Loss: 9.70456276263576e-05, Final Batch Loss: 1.2502317986218259e-05\n",
      "Epoch 2482, Loss: 0.00026249681832268834, Final Batch Loss: 0.0002237232110928744\n",
      "Epoch 2483, Loss: 0.00010011875201598741, Final Batch Loss: 6.327518349280581e-05\n",
      "Epoch 2484, Loss: 0.00016125932711474888, Final Batch Loss: 3.489383061605622e-06\n",
      "Epoch 2485, Loss: 0.00216568581527099, Final Batch Loss: 0.0006717271753586829\n",
      "Epoch 2486, Loss: 0.00019296866958029568, Final Batch Loss: 9.900224540615454e-05\n",
      "Epoch 2487, Loss: 0.00018125872156815603, Final Batch Loss: 4.881345375906676e-06\n",
      "Epoch 2488, Loss: 0.00031275050514523173, Final Batch Loss: 0.000301370513625443\n",
      "Epoch 2489, Loss: 0.0022802541570854373, Final Batch Loss: 4.7997345973271877e-05\n",
      "Epoch 2490, Loss: 0.0030719820060767233, Final Batch Loss: 0.0006802620482631028\n",
      "Epoch 2491, Loss: 0.000128126872368739, Final Batch Loss: 0.00010599016241030768\n",
      "Epoch 2492, Loss: 0.0004704128368757665, Final Batch Loss: 0.00021420916891656816\n",
      "Epoch 2493, Loss: 0.00011545882443897426, Final Batch Loss: 2.060597762465477e-05\n",
      "Epoch 2494, Loss: 0.0006684581603622064, Final Batch Loss: 0.00048496617819182575\n",
      "Epoch 2495, Loss: 0.0005956335025985027, Final Batch Loss: 0.0005845929263159633\n",
      "Epoch 2496, Loss: 0.00014347664910019375, Final Batch Loss: 1.974031692952849e-05\n",
      "Epoch 2497, Loss: 0.00014093777281232178, Final Batch Loss: 7.259417907334864e-05\n",
      "Epoch 2498, Loss: 0.000112036324935616, Final Batch Loss: 8.402230741921812e-05\n",
      "Epoch 2499, Loss: 0.00022577078925678506, Final Batch Loss: 0.00018728412396740168\n",
      "Epoch 2500, Loss: 0.00201182338378203, Final Batch Loss: 6.932448286534054e-06\n",
      "Epoch 2501, Loss: 4.422670463100076e-05, Final Batch Loss: 2.0469864466576837e-05\n",
      "Epoch 2502, Loss: 0.0006503778349724598, Final Batch Loss: 0.0005635293200612068\n",
      "Epoch 2503, Loss: 0.0027632206911221147, Final Batch Loss: 0.0017518822569400072\n",
      "Epoch 2504, Loss: 8.149624773068354e-05, Final Batch Loss: 4.567974610836245e-05\n",
      "Epoch 2505, Loss: 0.00022964842719375156, Final Batch Loss: 0.00019323972810525447\n",
      "Epoch 2506, Loss: 0.0025517946880881937, Final Batch Loss: 9.224124823958846e-07\n",
      "Epoch 2507, Loss: 0.00017302934520557756, Final Batch Loss: 1.1547367648745421e-05\n",
      "Epoch 2508, Loss: 0.004304808680899441, Final Batch Loss: 0.002761265030130744\n",
      "Epoch 2509, Loss: 0.00023160829005064443, Final Batch Loss: 8.291802805615589e-05\n",
      "Epoch 2510, Loss: 0.00014787738473387435, Final Batch Loss: 0.00012101347965653986\n",
      "Epoch 2511, Loss: 0.00014326764721772633, Final Batch Loss: 0.00011677894508466125\n",
      "Epoch 2512, Loss: 0.00010529379869694822, Final Batch Loss: 7.029584230622277e-05\n",
      "Epoch 2513, Loss: 5.21298136391124e-05, Final Batch Loss: 1.329783344772295e-06\n",
      "Epoch 2514, Loss: 0.0016618070869753865, Final Batch Loss: 1.1249424005654873e-06\n",
      "Epoch 2515, Loss: 0.0035232549373631628, Final Batch Loss: 0.0035201290156692266\n",
      "Epoch 2516, Loss: 0.0013553368007706013, Final Batch Loss: 1.961044836207293e-05\n",
      "Epoch 2517, Loss: 0.004138512013014406, Final Batch Loss: 9.773805504664779e-05\n",
      "Epoch 2518, Loss: 7.574928622489097e-05, Final Batch Loss: 9.945867532223929e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2519, Loss: 0.0005710142868338153, Final Batch Loss: 0.00015458943380508572\n",
      "Epoch 2520, Loss: 0.0007928369668661617, Final Batch Loss: 0.00010431530972709879\n",
      "Epoch 2521, Loss: 0.002805698361044051, Final Batch Loss: 5.383084135246463e-05\n",
      "Epoch 2522, Loss: 0.0003027431230293587, Final Batch Loss: 0.00026339685427956283\n",
      "Epoch 2523, Loss: 0.001241940985664769, Final Batch Loss: 1.0867177024920238e-06\n",
      "Epoch 2524, Loss: 0.0005710742109386047, Final Batch Loss: 1.6549740848859074e-06\n",
      "Epoch 2525, Loss: 0.00046818438568152487, Final Batch Loss: 0.00011422249372117221\n",
      "Epoch 2526, Loss: 9.29818188524223e-05, Final Batch Loss: 1.2927600437251385e-05\n",
      "Epoch 2527, Loss: 8.010467263375176e-05, Final Batch Loss: 7.503817323595285e-05\n",
      "Epoch 2528, Loss: 9.807518108573277e-05, Final Batch Loss: 7.7780077845091e-06\n",
      "Epoch 2529, Loss: 0.001954219264916901, Final Batch Loss: 7.066836587910075e-06\n",
      "Epoch 2530, Loss: 0.012012649887765292, Final Batch Loss: 0.011957336217164993\n",
      "Epoch 2531, Loss: 0.0006091024633860798, Final Batch Loss: 1.153842549683759e-05\n",
      "Epoch 2532, Loss: 0.00013679381663678214, Final Batch Loss: 0.00010186522558797151\n",
      "Epoch 2533, Loss: 0.000944608727877494, Final Batch Loss: 8.899010572349653e-05\n",
      "Epoch 2534, Loss: 0.00042027042218251154, Final Batch Loss: 6.97384457453154e-05\n",
      "Epoch 2535, Loss: 0.0010566319460849627, Final Batch Loss: 9.163667527900543e-06\n",
      "Epoch 2536, Loss: 7.0030875463089615e-06, Final Batch Loss: 7.904765766397759e-07\n",
      "Epoch 2537, Loss: 0.00021327461217879318, Final Batch Loss: 1.9038645405089483e-05\n",
      "Epoch 2538, Loss: 8.990440665002097e-05, Final Batch Loss: 8.28441625344567e-05\n",
      "Epoch 2539, Loss: 9.512827091384679e-05, Final Batch Loss: 5.240850441623479e-06\n",
      "Epoch 2540, Loss: 9.910110020427965e-05, Final Batch Loss: 5.863494880031794e-05\n",
      "Epoch 2541, Loss: 0.00022866087419970427, Final Batch Loss: 0.0002055296499747783\n",
      "Epoch 2542, Loss: 0.0033983709327003453, Final Batch Loss: 0.0033554399851709604\n",
      "Epoch 2543, Loss: 0.00011512327182572335, Final Batch Loss: 5.737530591432005e-05\n",
      "Epoch 2544, Loss: 0.0010262331225021626, Final Batch Loss: 0.0010130155133083463\n",
      "Epoch 2545, Loss: 0.0002655547432368621, Final Batch Loss: 0.00013603897241409868\n",
      "Epoch 2546, Loss: 0.0019212538682040758, Final Batch Loss: 4.29068531957455e-05\n",
      "Epoch 2547, Loss: 0.00017377257609041408, Final Batch Loss: 0.00014671709504909813\n",
      "Epoch 2548, Loss: 0.0012782768499164376, Final Batch Loss: 4.7718120185891166e-05\n",
      "Epoch 2549, Loss: 0.00219986181036802, Final Batch Loss: 0.00010587287397356704\n",
      "Epoch 2550, Loss: 0.041036568058189005, Final Batch Loss: 0.04030358046293259\n",
      "Epoch 2551, Loss: 0.00012648487791011576, Final Batch Loss: 2.7492484150570817e-05\n",
      "Epoch 2552, Loss: 5.451869856187841e-05, Final Batch Loss: 1.2923689610033762e-05\n",
      "Epoch 2553, Loss: 0.0015668213918615947, Final Batch Loss: 4.360600541986059e-06\n",
      "Epoch 2554, Loss: 0.0001263526501134038, Final Batch Loss: 6.88163927407004e-05\n",
      "Epoch 2555, Loss: 0.0007003721984801814, Final Batch Loss: 0.0001613385247765109\n",
      "Epoch 2556, Loss: 0.0004412818145738129, Final Batch Loss: 2.040402478087344e-06\n",
      "Epoch 2557, Loss: 0.014066336640098598, Final Batch Loss: 8.593868551542982e-05\n",
      "Epoch 2558, Loss: 0.0003604534913392854, Final Batch Loss: 9.03117052075686e-06\n",
      "Epoch 2559, Loss: 0.005421661816399137, Final Batch Loss: 0.005413784179836512\n",
      "Epoch 2560, Loss: 0.0005074297077953815, Final Batch Loss: 0.00010113589814864099\n",
      "Epoch 2561, Loss: 9.390029390488053e-06, Final Batch Loss: 3.3654864637355786e-06\n",
      "Epoch 2562, Loss: 0.00021102137543493882, Final Batch Loss: 7.547709537902847e-05\n",
      "Epoch 2563, Loss: 0.0001310772859142162, Final Batch Loss: 6.353876233333722e-05\n",
      "Epoch 2564, Loss: 0.0018199143014498986, Final Batch Loss: 2.93032280751504e-05\n",
      "Epoch 2565, Loss: 0.00017824538736022078, Final Batch Loss: 0.00013104444951750338\n",
      "Epoch 2566, Loss: 0.006236582419660408, Final Batch Loss: 0.00010990713053615764\n",
      "Epoch 2567, Loss: 0.0017784213641789393, Final Batch Loss: 1.1203600479348097e-05\n",
      "Epoch 2568, Loss: 0.00011405087934690528, Final Batch Loss: 7.795650890329853e-05\n",
      "Epoch 2569, Loss: 0.0005741924978792667, Final Batch Loss: 0.0003293349000159651\n",
      "Epoch 2570, Loss: 0.0004606916627380997, Final Batch Loss: 0.0003519390884321183\n",
      "Epoch 2571, Loss: 0.00026166023599216715, Final Batch Loss: 0.00024818224483169615\n",
      "Epoch 2572, Loss: 0.015303670923458412, Final Batch Loss: 1.08029053080827e-05\n",
      "Epoch 2573, Loss: 0.0013337183627299964, Final Batch Loss: 7.595069473609328e-05\n",
      "Epoch 2574, Loss: 7.586992524011293e-05, Final Batch Loss: 3.361995368322823e-06\n",
      "Epoch 2575, Loss: 0.000805006486189086, Final Batch Loss: 6.455713446484879e-05\n",
      "Epoch 2576, Loss: 7.909621308499482e-05, Final Batch Loss: 5.34939972567372e-05\n",
      "Epoch 2577, Loss: 5.80058458581334e-05, Final Batch Loss: 1.8713350073085167e-05\n",
      "Epoch 2578, Loss: 8.840300688461866e-05, Final Batch Loss: 1.7499512978247367e-05\n",
      "Epoch 2579, Loss: 0.0010003850038629025, Final Batch Loss: 0.00034169931313954294\n",
      "Epoch 2580, Loss: 0.014973619247030001, Final Batch Loss: 0.014914564788341522\n",
      "Epoch 2581, Loss: 0.0010465137602295727, Final Batch Loss: 0.0007196677033789456\n",
      "Epoch 2582, Loss: 0.000935482225031592, Final Batch Loss: 1.0087984264828265e-05\n",
      "Epoch 2583, Loss: 0.002959376533908653, Final Batch Loss: 2.823756767611485e-05\n",
      "Epoch 2584, Loss: 0.007201078798971139, Final Batch Loss: 0.00014059430395718664\n",
      "Epoch 2585, Loss: 0.05458134398213588, Final Batch Loss: 0.0003921723400708288\n",
      "Epoch 2586, Loss: 0.01620571024250239, Final Batch Loss: 0.0007778526050969958\n",
      "Epoch 2587, Loss: 0.0013886029646528186, Final Batch Loss: 7.41282019589562e-06\n",
      "Epoch 2588, Loss: 0.0006248598219826818, Final Batch Loss: 0.000375535135390237\n",
      "Epoch 2589, Loss: 0.000424499245127663, Final Batch Loss: 0.00033381456159986556\n",
      "Epoch 2590, Loss: 5.79540337639628e-05, Final Batch Loss: 1.3421724361251108e-05\n",
      "Epoch 2591, Loss: 0.0020754726137965918, Final Batch Loss: 0.0019297546241432428\n",
      "Epoch 2592, Loss: 0.00012809935651603155, Final Batch Loss: 9.36796932364814e-05\n",
      "Epoch 2593, Loss: 0.001120910412282683, Final Batch Loss: 8.336339669767767e-05\n",
      "Epoch 2594, Loss: 0.018692321174057724, Final Batch Loss: 4.121132405998651e-06\n",
      "Epoch 2595, Loss: 0.014935321640223265, Final Batch Loss: 0.007168038282543421\n",
      "Epoch 2596, Loss: 0.0022604247569688596, Final Batch Loss: 1.2702868843916804e-05\n",
      "Epoch 2597, Loss: 0.0013059782058917335, Final Batch Loss: 1.4937525520508643e-05\n",
      "Epoch 2598, Loss: 0.0004125615005250438, Final Batch Loss: 1.3877905985282268e-05\n",
      "Epoch 2599, Loss: 0.0015682238445151597, Final Batch Loss: 0.00013982600648887455\n",
      "Epoch 2600, Loss: 0.0005303498710418353, Final Batch Loss: 0.0005040689138695598\n",
      "Epoch 2601, Loss: 0.003942557901609689, Final Batch Loss: 0.003333667991682887\n",
      "Epoch 2602, Loss: 8.442814032605384e-05, Final Batch Loss: 2.8472628400777467e-05\n",
      "Epoch 2603, Loss: 0.0004452912526176078, Final Batch Loss: 2.936259079433512e-05\n",
      "Epoch 2604, Loss: 0.000673633012411301, Final Batch Loss: 2.5046409064088948e-05\n",
      "Epoch 2605, Loss: 0.00040258200806420064, Final Batch Loss: 5.928813152422663e-06\n",
      "Epoch 2606, Loss: 5.2612819217756623e-05, Final Batch Loss: 3.918625679943943e-06\n",
      "Epoch 2607, Loss: 0.001260404122149339, Final Batch Loss: 0.0012018928537145257\n",
      "Epoch 2608, Loss: 0.0005490760231623426, Final Batch Loss: 0.00022779435676056892\n",
      "Epoch 2609, Loss: 0.00021118564109201543, Final Batch Loss: 3.9524846215499565e-05\n",
      "Epoch 2610, Loss: 0.0004590965477859754, Final Batch Loss: 8.367720170099346e-07\n",
      "Epoch 2611, Loss: 0.001274677239052835, Final Batch Loss: 2.0662917449953966e-05\n",
      "Epoch 2612, Loss: 0.0211927584687146, Final Batch Loss: 0.021180083975195885\n",
      "Epoch 2613, Loss: 0.00022621714015258476, Final Batch Loss: 7.291990186786279e-05\n",
      "Epoch 2614, Loss: 0.00422985406476073, Final Batch Loss: 0.004046950954943895\n",
      "Epoch 2615, Loss: 0.00014492712398350704, Final Batch Loss: 1.0853693311219104e-05\n",
      "Epoch 2616, Loss: 0.0002393402119196253, Final Batch Loss: 0.000215243679122068\n",
      "Epoch 2617, Loss: 0.005410136955106282, Final Batch Loss: 1.6845131540321745e-05\n",
      "Epoch 2618, Loss: 0.0016854981222422794, Final Batch Loss: 0.0015223311493173242\n",
      "Epoch 2619, Loss: 0.00024001607380341738, Final Batch Loss: 0.00021314765035640448\n",
      "Epoch 2620, Loss: 2.0417684368112532e-05, Final Batch Loss: 9.91841602626664e-07\n",
      "Epoch 2621, Loss: 0.00019015399448107928, Final Batch Loss: 2.1755127818323672e-05\n",
      "Epoch 2622, Loss: 0.006344325578538701, Final Batch Loss: 0.006207218859344721\n",
      "Epoch 2623, Loss: 0.00024632178246974945, Final Batch Loss: 0.00018926568736787885\n",
      "Epoch 2624, Loss: 0.0003280618657299783, Final Batch Loss: 5.05266034451779e-05\n",
      "Epoch 2625, Loss: 0.00044122904364485294, Final Batch Loss: 8.467382576782256e-05\n",
      "Epoch 2626, Loss: 0.0037267044244799763, Final Batch Loss: 0.0033616959117352962\n",
      "Epoch 2627, Loss: 0.0003830552741419524, Final Batch Loss: 0.0002878294908441603\n",
      "Epoch 2628, Loss: 0.00022915993758942932, Final Batch Loss: 0.00019848452939186245\n",
      "Epoch 2629, Loss: 0.0004914184537483379, Final Batch Loss: 0.0003057688008993864\n",
      "Epoch 2630, Loss: 0.002367965440498665, Final Batch Loss: 0.0022449383977800608\n",
      "Epoch 2631, Loss: 0.005984799237921834, Final Batch Loss: 0.0011250062379986048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2632, Loss: 0.00013482233771355823, Final Batch Loss: 4.111967427888885e-05\n",
      "Epoch 2633, Loss: 0.0028101439820602536, Final Batch Loss: 0.0007039824267849326\n",
      "Epoch 2634, Loss: 0.000660072299069725, Final Batch Loss: 0.0001472194999223575\n",
      "Epoch 2635, Loss: 0.003069270333298846, Final Batch Loss: 2.6930831609206507e-06\n",
      "Epoch 2636, Loss: 0.0021655771415680647, Final Batch Loss: 0.00070602772757411\n",
      "Epoch 2637, Loss: 0.00213767695822753, Final Batch Loss: 0.000148554245242849\n",
      "Epoch 2638, Loss: 7.568977889604867e-05, Final Batch Loss: 5.092302308185026e-05\n",
      "Epoch 2639, Loss: 0.003129577962681651, Final Batch Loss: 0.001355799031443894\n",
      "Epoch 2640, Loss: 0.0001078592558769742, Final Batch Loss: 2.2942245777812786e-05\n",
      "Epoch 2641, Loss: 0.0014715383877046406, Final Batch Loss: 0.00021256046602502465\n",
      "Epoch 2642, Loss: 0.00032245095280813985, Final Batch Loss: 0.0002860149252228439\n",
      "Epoch 2643, Loss: 0.00013267360191093758, Final Batch Loss: 3.2590491173323244e-05\n",
      "Epoch 2644, Loss: 0.0005543712049984606, Final Batch Loss: 1.567921026435215e-05\n",
      "Epoch 2645, Loss: 7.792514816173934e-05, Final Batch Loss: 1.894563411042327e-06\n",
      "Epoch 2646, Loss: 3.4931059872178594e-05, Final Batch Loss: 3.111273326794617e-05\n",
      "Epoch 2647, Loss: 0.0008075777514022775, Final Batch Loss: 6.575289444299415e-05\n",
      "Epoch 2648, Loss: 0.0002303627843502909, Final Batch Loss: 9.593837603460997e-05\n",
      "Epoch 2649, Loss: 0.00040759499825071543, Final Batch Loss: 0.00012231363507453352\n",
      "Epoch 2650, Loss: 0.0015609894471708685, Final Batch Loss: 0.000129274238133803\n",
      "Epoch 2651, Loss: 8.061946573434398e-05, Final Batch Loss: 3.600978016038425e-05\n",
      "Epoch 2652, Loss: 0.00024998946719279047, Final Batch Loss: 2.895862235163804e-05\n",
      "Epoch 2653, Loss: 0.0013999385519127827, Final Batch Loss: 1.030724888551049e-05\n",
      "Epoch 2654, Loss: 0.0024392266761879, Final Batch Loss: 1.0369815299782204e-06\n",
      "Epoch 2655, Loss: 0.002338881604373455, Final Batch Loss: 0.0014720764011144638\n",
      "Epoch 2656, Loss: 0.00464137827657396, Final Batch Loss: 7.35409339540638e-05\n",
      "Epoch 2657, Loss: 0.00044102627725806087, Final Batch Loss: 0.0002949178160633892\n",
      "Epoch 2658, Loss: 0.002670523535925895, Final Batch Loss: 0.00018303474644199014\n",
      "Epoch 2659, Loss: 0.0022580010918318294, Final Batch Loss: 0.002241776790469885\n",
      "Epoch 2660, Loss: 0.00042747305997181684, Final Batch Loss: 0.00024303664395119995\n",
      "Epoch 2661, Loss: 0.0005075614662928274, Final Batch Loss: 0.0004924196982756257\n",
      "Epoch 2662, Loss: 8.652572796563618e-05, Final Batch Loss: 4.2216335714329034e-05\n",
      "Epoch 2663, Loss: 0.0005281038829707541, Final Batch Loss: 0.0004160196695011109\n",
      "Epoch 2664, Loss: 0.00041839945606625406, Final Batch Loss: 0.00040635166806168854\n",
      "Epoch 2665, Loss: 8.408039502683096e-05, Final Batch Loss: 3.84248596674297e-05\n",
      "Epoch 2666, Loss: 0.00018391113189863972, Final Batch Loss: 0.00014685536734759808\n",
      "Epoch 2667, Loss: 0.002536106636398472, Final Batch Loss: 0.002370281144976616\n",
      "Epoch 2668, Loss: 0.0008993957890197635, Final Batch Loss: 0.0006891029770486057\n",
      "Epoch 2669, Loss: 0.00012637361578526907, Final Batch Loss: 7.962475501699373e-05\n",
      "Epoch 2670, Loss: 0.00022569320753973443, Final Batch Loss: 1.8505090338294394e-05\n",
      "Epoch 2671, Loss: 0.0013637452834700525, Final Batch Loss: 7.32331363906269e-06\n",
      "Epoch 2672, Loss: 0.0005632125612464733, Final Batch Loss: 0.0005322545766830444\n",
      "Epoch 2673, Loss: 0.00016081737339845859, Final Batch Loss: 0.00012466263433452696\n",
      "Epoch 2674, Loss: 0.00010673247743397951, Final Batch Loss: 9.729691373649985e-05\n",
      "Epoch 2675, Loss: 0.00036919035483151674, Final Batch Loss: 0.00014882396499160677\n",
      "Epoch 2676, Loss: 0.003330502042445005, Final Batch Loss: 0.0033170513343065977\n",
      "Epoch 2677, Loss: 0.001133072655647993, Final Batch Loss: 0.0002534923260100186\n",
      "Epoch 2678, Loss: 0.0020969832912669517, Final Batch Loss: 0.00011100099800387397\n",
      "Epoch 2679, Loss: 8.738526116758294e-05, Final Batch Loss: 2.389830797255854e-06\n",
      "Epoch 2680, Loss: 0.0003353927459102124, Final Batch Loss: 0.0002653467236086726\n",
      "Epoch 2681, Loss: 0.00014892756007611752, Final Batch Loss: 3.309120802441612e-05\n",
      "Epoch 2682, Loss: 0.00016156518177012913, Final Batch Loss: 4.347054709796794e-05\n",
      "Epoch 2683, Loss: 0.0003826905303867534, Final Batch Loss: 0.0001629330072319135\n",
      "Epoch 2684, Loss: 0.00019375368356122635, Final Batch Loss: 5.216602221480571e-05\n",
      "Epoch 2685, Loss: 0.00022286532475845888, Final Batch Loss: 6.74357361276634e-05\n",
      "Epoch 2686, Loss: 6.890772419865243e-05, Final Batch Loss: 2.0894542103633285e-05\n",
      "Epoch 2687, Loss: 0.001336783408987685, Final Batch Loss: 1.3245740774436854e-05\n",
      "Epoch 2688, Loss: 0.0006335997823043726, Final Batch Loss: 0.0005468129529617727\n",
      "Epoch 2689, Loss: 0.0026244572072755545, Final Batch Loss: 0.0004441328055690974\n",
      "Epoch 2690, Loss: 0.0024473601952195168, Final Batch Loss: 0.002144288271665573\n",
      "Epoch 2691, Loss: 1.5870502011239296e-05, Final Batch Loss: 4.822446953767212e-06\n",
      "Epoch 2692, Loss: 0.0002554524289735127, Final Batch Loss: 3.0035476811463013e-05\n",
      "Epoch 2693, Loss: 0.000285264482954517, Final Batch Loss: 8.304364746436477e-05\n",
      "Epoch 2694, Loss: 0.0003171284988638945, Final Batch Loss: 7.099874346749857e-05\n",
      "Epoch 2695, Loss: 0.00015310386788769392, Final Batch Loss: 1.254425569641171e-05\n",
      "Epoch 2696, Loss: 4.097610781172989e-05, Final Batch Loss: 1.434538444300415e-05\n",
      "Epoch 2697, Loss: 5.8834753872361034e-05, Final Batch Loss: 4.1898307244991884e-05\n",
      "Epoch 2698, Loss: 0.009754826605785638, Final Batch Loss: 0.009388319216668606\n",
      "Epoch 2699, Loss: 0.0014796468894928694, Final Batch Loss: 0.0007923010271042585\n",
      "Epoch 2700, Loss: 0.00013906857930123806, Final Batch Loss: 6.675063195871189e-05\n",
      "Epoch 2701, Loss: 0.000266977262981527, Final Batch Loss: 4.378057383291889e-06\n",
      "Epoch 2702, Loss: 0.00028525018933578394, Final Batch Loss: 0.00023227320343721658\n",
      "Epoch 2703, Loss: 0.00030120747032924555, Final Batch Loss: 2.2991673176875338e-05\n",
      "Epoch 2704, Loss: 0.00024345581914531067, Final Batch Loss: 6.605726230191067e-05\n",
      "Epoch 2705, Loss: 0.0011699930328177288, Final Batch Loss: 0.00013292553194332868\n",
      "Epoch 2706, Loss: 0.0024808940761431586, Final Batch Loss: 1.100332519854419e-05\n",
      "Epoch 2707, Loss: 0.0050493410672061145, Final Batch Loss: 0.00450401334092021\n",
      "Epoch 2708, Loss: 0.00046402212683460675, Final Batch Loss: 0.0004292785015422851\n",
      "Epoch 2709, Loss: 0.00022867488587507978, Final Batch Loss: 0.0001541322417324409\n",
      "Epoch 2710, Loss: 6.431096562664607e-05, Final Batch Loss: 6.390861472027609e-06\n",
      "Epoch 2711, Loss: 0.0014097760231379652, Final Batch Loss: 1.0844067219295539e-05\n",
      "Epoch 2712, Loss: 0.0003205009379598778, Final Batch Loss: 0.00028463659691624343\n",
      "Epoch 2713, Loss: 0.00015816396989976056, Final Batch Loss: 5.4911153711145744e-05\n",
      "Epoch 2714, Loss: 0.0015314985284931026, Final Batch Loss: 0.0014400267973542213\n",
      "Epoch 2715, Loss: 0.000329241589497542, Final Batch Loss: 1.584368510521017e-05\n",
      "Epoch 2716, Loss: 8.464314123557415e-05, Final Batch Loss: 7.279665442183614e-05\n",
      "Epoch 2717, Loss: 0.001062294322764501, Final Batch Loss: 4.832385457120836e-05\n",
      "Epoch 2718, Loss: 0.000681540430377936, Final Batch Loss: 2.035838770098053e-05\n",
      "Epoch 2719, Loss: 0.0029061157547403127, Final Batch Loss: 0.00034091368434019387\n",
      "Epoch 2720, Loss: 0.001144967885920778, Final Batch Loss: 0.0003491829556878656\n",
      "Epoch 2721, Loss: 0.00013022215898672584, Final Batch Loss: 2.1621193809551187e-05\n",
      "Epoch 2722, Loss: 1.327083418800612e-05, Final Batch Loss: 4.7380613068526145e-06\n",
      "Epoch 2723, Loss: 0.0033889064616232645, Final Batch Loss: 1.0109371942235157e-05\n",
      "Epoch 2724, Loss: 0.00365334223897662, Final Batch Loss: 0.003617999143898487\n",
      "Epoch 2725, Loss: 8.439469638688024e-05, Final Batch Loss: 6.75319170113653e-05\n",
      "Epoch 2726, Loss: 0.0002463389828335494, Final Batch Loss: 0.0001902449002955109\n",
      "Epoch 2727, Loss: 0.0033771510934457183, Final Batch Loss: 0.001789266592822969\n",
      "Epoch 2728, Loss: 0.0013298763224156573, Final Batch Loss: 0.00023760339536238462\n",
      "Epoch 2729, Loss: 0.00013055808631179389, Final Batch Loss: 0.00010679494153009728\n",
      "Epoch 2730, Loss: 0.0004048476730531547, Final Batch Loss: 4.776576315634884e-05\n",
      "Epoch 2731, Loss: 0.00033277637703577057, Final Batch Loss: 3.573249705368653e-05\n",
      "Epoch 2732, Loss: 0.0001458099050068995, Final Batch Loss: 1.3743838280788623e-05\n",
      "Epoch 2733, Loss: 0.0024768859439063817, Final Batch Loss: 0.000212442857446149\n",
      "Epoch 2734, Loss: 0.00012069718104612548, Final Batch Loss: 4.523675670498051e-06\n",
      "Epoch 2735, Loss: 0.0006101074686739594, Final Batch Loss: 0.0004498676862567663\n",
      "Epoch 2736, Loss: 8.830665137793403e-05, Final Batch Loss: 7.209595787571743e-05\n",
      "Epoch 2737, Loss: 0.003080808218783204, Final Batch Loss: 0.003075544023886323\n",
      "Epoch 2738, Loss: 0.0026295170209778007, Final Batch Loss: 4.4726442865794525e-05\n",
      "Epoch 2739, Loss: 0.0002298468789376784, Final Batch Loss: 0.00020384072558954358\n",
      "Epoch 2740, Loss: 6.677013607259141e-05, Final Batch Loss: 9.856024007603992e-06\n",
      "Epoch 2741, Loss: 0.0003178615511387761, Final Batch Loss: 2.694250269996701e-06\n",
      "Epoch 2742, Loss: 0.000724142372746428, Final Batch Loss: 7.021138117124792e-06\n",
      "Epoch 2743, Loss: 6.320613385923934e-05, Final Batch Loss: 1.452484070796345e-06\n",
      "Epoch 2744, Loss: 0.00011974941207881784, Final Batch Loss: 0.00010943497181870043\n",
      "Epoch 2745, Loss: 0.00013977744220028399, Final Batch Loss: 1.122981029766379e-05\n",
      "Epoch 2746, Loss: 0.00031198073338600807, Final Batch Loss: 1.2366897863103077e-05\n",
      "Epoch 2747, Loss: 0.00023748805688228458, Final Batch Loss: 0.00011116893438156694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2748, Loss: 0.00018102372996509075, Final Batch Loss: 7.733242091489956e-05\n",
      "Epoch 2749, Loss: 0.0003806923796219053, Final Batch Loss: 1.590581268828828e-05\n",
      "Epoch 2750, Loss: 8.050643191381823e-05, Final Batch Loss: 6.30020149401389e-05\n",
      "Epoch 2751, Loss: 0.00011204712427570485, Final Batch Loss: 4.8706770030548796e-05\n",
      "Epoch 2752, Loss: 0.004302758716221433, Final Batch Loss: 0.00427815830335021\n",
      "Epoch 2753, Loss: 0.0008618954889243469, Final Batch Loss: 0.00014546581951435655\n",
      "Epoch 2754, Loss: 0.0013704028679057956, Final Batch Loss: 0.0006864272872917354\n",
      "Epoch 2755, Loss: 0.00014901856775395572, Final Batch Loss: 6.612814468098804e-05\n",
      "Epoch 2756, Loss: 0.00015902563609415665, Final Batch Loss: 0.0001107527787098661\n",
      "Epoch 2757, Loss: 0.00010684926257908955, Final Batch Loss: 1.7117187098847353e-06\n",
      "Epoch 2758, Loss: 9.431607077203807e-05, Final Batch Loss: 5.631926342175575e-06\n",
      "Epoch 2759, Loss: 0.0022814429430582095, Final Batch Loss: 2.294285877724178e-05\n",
      "Epoch 2760, Loss: 0.0006110479771450628, Final Batch Loss: 5.791448711534031e-05\n",
      "Epoch 2761, Loss: 8.078824248514138e-05, Final Batch Loss: 5.764820161857642e-05\n",
      "Epoch 2762, Loss: 0.00011392200030968525, Final Batch Loss: 4.748779974761419e-05\n",
      "Epoch 2763, Loss: 0.00017337834651698358, Final Batch Loss: 2.3433985916199163e-05\n",
      "Epoch 2764, Loss: 9.619492675483343e-05, Final Batch Loss: 2.572764515207382e-06\n",
      "Epoch 2765, Loss: 0.0009316059968114132, Final Batch Loss: 1.9821172827505507e-05\n",
      "Epoch 2766, Loss: 0.0006772539636585861, Final Batch Loss: 0.00014221182209439576\n",
      "Epoch 2767, Loss: 0.0006731468383804895, Final Batch Loss: 0.0006068641087040305\n",
      "Epoch 2768, Loss: 0.0001959486435225699, Final Batch Loss: 0.00017228556680493057\n",
      "Epoch 2769, Loss: 7.027607716736384e-05, Final Batch Loss: 5.312263238010928e-05\n",
      "Epoch 2770, Loss: 0.00015872770745772868, Final Batch Loss: 4.311175871407613e-05\n",
      "Epoch 2771, Loss: 0.0001800360405468382, Final Batch Loss: 7.063493831083179e-05\n",
      "Epoch 2772, Loss: 0.00016714058074285276, Final Batch Loss: 4.534519030130468e-05\n",
      "Epoch 2773, Loss: 0.007321830140426755, Final Batch Loss: 0.0005912932101637125\n",
      "Epoch 2774, Loss: 0.003988633052358637, Final Batch Loss: 0.0039395177736878395\n",
      "Epoch 2775, Loss: 0.0004990450979676098, Final Batch Loss: 0.00021663130610249937\n",
      "Epoch 2776, Loss: 0.0006145654333522543, Final Batch Loss: 0.0005831224843859673\n",
      "Epoch 2777, Loss: 0.014993187389336526, Final Batch Loss: 0.013859755359590054\n",
      "Epoch 2778, Loss: 0.00020880302326986566, Final Batch Loss: 0.0001813494454836473\n",
      "Epoch 2779, Loss: 0.0004446704188012518, Final Batch Loss: 0.00033184047788381577\n",
      "Epoch 2780, Loss: 7.870261941889112e-05, Final Batch Loss: 6.504389489236928e-07\n",
      "Epoch 2781, Loss: 0.0014266608832258498, Final Batch Loss: 2.952719478344079e-05\n",
      "Epoch 2782, Loss: 7.70758433645824e-05, Final Batch Loss: 2.3055979909258895e-05\n",
      "Epoch 2783, Loss: 0.0042482540011405945, Final Batch Loss: 0.002179585164412856\n",
      "Epoch 2784, Loss: 7.319016003748402e-05, Final Batch Loss: 4.1398856410523877e-05\n",
      "Epoch 2785, Loss: 0.001451751304557547, Final Batch Loss: 0.001033038948662579\n",
      "Epoch 2786, Loss: 0.0001918115740409121, Final Batch Loss: 0.0001451086427550763\n",
      "Epoch 2787, Loss: 0.005289764863846358, Final Batch Loss: 2.0003200916107744e-05\n",
      "Epoch 2788, Loss: 0.0004683576826209901, Final Batch Loss: 2.213370862591546e-05\n",
      "Epoch 2789, Loss: 0.0033757809983399056, Final Batch Loss: 3.816789558186429e-06\n",
      "Epoch 2790, Loss: 0.001372445250126475, Final Batch Loss: 0.0013609339948743582\n",
      "Epoch 2791, Loss: 6.987444248807151e-05, Final Batch Loss: 5.433686601463705e-05\n",
      "Epoch 2792, Loss: 3.1620586923963856e-05, Final Batch Loss: 1.692181103862822e-05\n",
      "Epoch 2793, Loss: 0.00011096127491327934, Final Batch Loss: 7.684773299843073e-05\n",
      "Epoch 2794, Loss: 0.00022451179756899364, Final Batch Loss: 3.0786428396822885e-05\n",
      "Epoch 2795, Loss: 0.00017769509940990247, Final Batch Loss: 2.2093481675256044e-06\n",
      "Epoch 2796, Loss: 9.16817007237114e-05, Final Batch Loss: 6.753770139766857e-05\n",
      "Epoch 2797, Loss: 0.0009103923221118748, Final Batch Loss: 0.00026863464154303074\n",
      "Epoch 2798, Loss: 0.002160000723961275, Final Batch Loss: 3.009207284776494e-05\n",
      "Epoch 2799, Loss: 0.0003435195054635187, Final Batch Loss: 9.35144839786517e-07\n",
      "Epoch 2800, Loss: 0.0004713025555247441, Final Batch Loss: 0.0003360385890118778\n",
      "Epoch 2801, Loss: 0.0006214901604835177, Final Batch Loss: 1.721326589176897e-05\n",
      "Epoch 2802, Loss: 0.0005166784831089899, Final Batch Loss: 0.00046461093006655574\n",
      "Epoch 2803, Loss: 0.000200276886971551, Final Batch Loss: 0.0001833600690588355\n",
      "Epoch 2804, Loss: 0.0002569130083429627, Final Batch Loss: 0.00014317690511234105\n",
      "Epoch 2805, Loss: 0.0012078675972588826, Final Batch Loss: 0.0011510924668982625\n",
      "Epoch 2806, Loss: 0.00012169766034730856, Final Batch Loss: 1.4952971696402528e-06\n",
      "Epoch 2807, Loss: 0.0029188402404543012, Final Batch Loss: 0.0002551107609178871\n",
      "Epoch 2808, Loss: 0.005027385312132537, Final Batch Loss: 0.0011691508116200566\n",
      "Epoch 2809, Loss: 0.0021230009058399446, Final Batch Loss: 1.2857979072578019e-06\n",
      "Epoch 2810, Loss: 0.001635154170799069, Final Batch Loss: 5.49968535779044e-05\n",
      "Epoch 2811, Loss: 7.887617584856343e-06, Final Batch Loss: 3.1107795166462893e-06\n",
      "Epoch 2812, Loss: 0.003358566742463154, Final Batch Loss: 1.4699371604365297e-05\n",
      "Epoch 2813, Loss: 1.4644220755144488e-05, Final Batch Loss: 6.401683094736654e-06\n",
      "Epoch 2814, Loss: 0.00035389612821745686, Final Batch Loss: 0.0003109473909717053\n",
      "Epoch 2815, Loss: 0.00017549027688801289, Final Batch Loss: 6.97058712830767e-05\n",
      "Epoch 2816, Loss: 8.676374636706896e-05, Final Batch Loss: 6.166694947751239e-05\n",
      "Epoch 2817, Loss: 0.0001842627243604511, Final Batch Loss: 0.00011715260188793764\n",
      "Epoch 2818, Loss: 0.0013413440847216407, Final Batch Loss: 1.1986116078332998e-05\n",
      "Epoch 2819, Loss: 0.0001240450110344682, Final Batch Loss: 0.00010336773993913084\n",
      "Epoch 2820, Loss: 0.00035035884502576664, Final Batch Loss: 8.488706225762144e-05\n",
      "Epoch 2821, Loss: 0.002869569871108979, Final Batch Loss: 0.002193531021475792\n",
      "Epoch 2822, Loss: 0.0017707473271002527, Final Batch Loss: 0.0017172908410429955\n",
      "Epoch 2823, Loss: 0.00014563192962668836, Final Batch Loss: 8.393132156925276e-05\n",
      "Epoch 2824, Loss: 0.005222624400630593, Final Batch Loss: 0.003567288862541318\n",
      "Epoch 2825, Loss: 0.0003913809608491192, Final Batch Loss: 3.055441482047172e-07\n",
      "Epoch 2826, Loss: 0.0008085455338004977, Final Batch Loss: 0.00026293788687326014\n",
      "Epoch 2827, Loss: 0.0010375458077760413, Final Batch Loss: 9.535186109133065e-06\n",
      "Epoch 2828, Loss: 0.0016093071700424844, Final Batch Loss: 1.0983004585796152e-06\n",
      "Epoch 2829, Loss: 0.00035886185651179403, Final Batch Loss: 0.00028104346711188555\n",
      "Epoch 2830, Loss: 0.0011214028527319897, Final Batch Loss: 0.0010796482674777508\n",
      "Epoch 2831, Loss: 0.047834642231464386, Final Batch Loss: 0.04677418991923332\n",
      "Epoch 2832, Loss: 0.005976479107630439, Final Batch Loss: 0.005876923445612192\n",
      "Epoch 2833, Loss: 2.312614469701657e-05, Final Batch Loss: 1.6459456674056128e-05\n",
      "Epoch 2834, Loss: 0.00040219635320681846, Final Batch Loss: 1.1547860594873782e-05\n",
      "Epoch 2835, Loss: 0.00035788061359198764, Final Batch Loss: 6.896831473568454e-05\n",
      "Epoch 2836, Loss: 0.0004977593962394167, Final Batch Loss: 0.0004643767897505313\n",
      "Epoch 2837, Loss: 0.0027698386111296713, Final Batch Loss: 0.00215500732883811\n",
      "Epoch 2838, Loss: 0.0012454935349524021, Final Batch Loss: 0.0009077885770238936\n",
      "Epoch 2839, Loss: 0.004505563229031395, Final Batch Loss: 0.00442346790805459\n",
      "Epoch 2840, Loss: 0.0018684141759877093, Final Batch Loss: 0.00010076066973851994\n",
      "Epoch 2841, Loss: 4.047939592055627e-05, Final Batch Loss: 4.732088655146072e-06\n",
      "Epoch 2842, Loss: 0.00010077378829009831, Final Batch Loss: 3.0060371500439942e-05\n",
      "Epoch 2843, Loss: 0.0011268244998063892, Final Batch Loss: 0.0007928856066428125\n",
      "Epoch 2844, Loss: 7.230446863104589e-05, Final Batch Loss: 1.0324631148250774e-05\n",
      "Epoch 2845, Loss: 0.00033727123809512705, Final Batch Loss: 0.00013317768753040582\n",
      "Epoch 2846, Loss: 0.006723355694703059, Final Batch Loss: 4.323392204241827e-06\n",
      "Epoch 2847, Loss: 0.0005858210515725659, Final Batch Loss: 2.928637150034774e-05\n",
      "Epoch 2848, Loss: 0.0007133628459996544, Final Batch Loss: 9.567711822455749e-05\n",
      "Epoch 2849, Loss: 0.0001230522248079069, Final Batch Loss: 8.509379404131323e-05\n",
      "Epoch 2850, Loss: 0.0013338448479771614, Final Batch Loss: 0.0008412707829847932\n",
      "Epoch 2851, Loss: 5.578740291412032e-05, Final Batch Loss: 9.281959023610398e-07\n",
      "Epoch 2852, Loss: 3.7543832149822265e-05, Final Batch Loss: 2.144774771295488e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2853, Loss: 0.03368265234894352, Final Batch Loss: 0.0336734913289547\n",
      "Epoch 2854, Loss: 5.917441376368515e-05, Final Batch Loss: 4.945068940287456e-05\n",
      "Epoch 2855, Loss: 0.0009043634636327624, Final Batch Loss: 5.3629279136657715e-05\n",
      "Epoch 2856, Loss: 0.002067521612843848, Final Batch Loss: 0.0020425613038241863\n",
      "Epoch 2857, Loss: 0.0003628104750532657, Final Batch Loss: 0.0003143249487038702\n",
      "Epoch 2858, Loss: 0.0015376282972283661, Final Batch Loss: 0.0005154668469913304\n",
      "Epoch 2859, Loss: 0.07177760341437533, Final Batch Loss: 0.0009286318090744317\n",
      "Epoch 2860, Loss: 0.005944443633779883, Final Batch Loss: 0.00011748098768293858\n",
      "Epoch 2861, Loss: 0.0007273435530805727, Final Batch Loss: 7.99383815319743e-06\n",
      "Epoch 2862, Loss: 8.769045598455705e-05, Final Batch Loss: 5.708861499442719e-05\n",
      "Epoch 2863, Loss: 9.564816355123185e-05, Final Batch Loss: 4.007244569947943e-05\n",
      "Epoch 2864, Loss: 0.00021190039115026593, Final Batch Loss: 9.903380123432726e-05\n",
      "Epoch 2865, Loss: 6.023851301506511e-05, Final Batch Loss: 6.8435087996476796e-06\n",
      "Epoch 2866, Loss: 0.006565592017068411, Final Batch Loss: 0.006555380765348673\n",
      "Epoch 2867, Loss: 0.0006906250710017048, Final Batch Loss: 6.701502570649609e-05\n",
      "Epoch 2868, Loss: 0.0014610471844207495, Final Batch Loss: 0.0014261381002143025\n",
      "Epoch 2869, Loss: 0.00019630308815976605, Final Batch Loss: 0.0001110644661821425\n",
      "Epoch 2870, Loss: 0.002078539597277995, Final Batch Loss: 6.205811951076612e-05\n",
      "Epoch 2871, Loss: 0.0005115095500514144, Final Batch Loss: 2.937785211543087e-05\n",
      "Epoch 2872, Loss: 0.0042490849391469965, Final Batch Loss: 0.0042204419150948524\n",
      "Epoch 2873, Loss: 0.0003328232414787635, Final Batch Loss: 0.0002951477072201669\n",
      "Epoch 2874, Loss: 0.00015960792370606214, Final Batch Loss: 7.737356645520777e-05\n",
      "Epoch 2875, Loss: 0.000544840848306194, Final Batch Loss: 0.0003471165837254375\n",
      "Epoch 2876, Loss: 0.0051616032142192125, Final Batch Loss: 0.0035166474990546703\n",
      "Epoch 2877, Loss: 0.000274918602372054, Final Batch Loss: 8.462648111162707e-05\n",
      "Epoch 2878, Loss: 0.0013243446737760678, Final Batch Loss: 8.40766733745113e-05\n",
      "Epoch 2879, Loss: 0.000492783852678258, Final Batch Loss: 6.126618973212317e-05\n",
      "Epoch 2880, Loss: 0.0006767098821001127, Final Batch Loss: 0.000505198200698942\n",
      "Epoch 2881, Loss: 0.00013622397818835452, Final Batch Loss: 7.139898661989719e-05\n",
      "Epoch 2882, Loss: 0.0011423996111261658, Final Batch Loss: 9.301245881943032e-05\n",
      "Epoch 2883, Loss: 0.00039098155320971273, Final Batch Loss: 1.73038242792245e-05\n",
      "Epoch 2884, Loss: 0.0001923363670357503, Final Batch Loss: 0.000130925647681579\n",
      "Epoch 2885, Loss: 0.00021733983885496855, Final Batch Loss: 7.253915828187019e-05\n",
      "Epoch 2886, Loss: 0.00018543554688221775, Final Batch Loss: 0.00012468667409848422\n",
      "Epoch 2887, Loss: 0.0001398480344505515, Final Batch Loss: 3.035851477761753e-05\n",
      "Epoch 2888, Loss: 0.00039125024022723665, Final Batch Loss: 4.704310867964523e-06\n",
      "Epoch 2889, Loss: 0.009130957500019576, Final Batch Loss: 7.739473221590742e-05\n",
      "Epoch 2890, Loss: 0.00026297842850908637, Final Batch Loss: 0.00012746160791721195\n",
      "Epoch 2891, Loss: 0.0004115378833375871, Final Batch Loss: 0.00021545327035710216\n",
      "Epoch 2892, Loss: 0.0003975864456151612, Final Batch Loss: 6.707313150400296e-05\n",
      "Epoch 2893, Loss: 0.00015919344332360197, Final Batch Loss: 0.00013720385322812945\n",
      "Epoch 2894, Loss: 0.00025086871391977184, Final Batch Loss: 1.6188027075259015e-05\n",
      "Epoch 2895, Loss: 0.0009795670412131585, Final Batch Loss: 2.8124057280365378e-05\n",
      "Epoch 2896, Loss: 0.0004034598241560161, Final Batch Loss: 0.0001368260127492249\n",
      "Epoch 2897, Loss: 0.0006813783838879317, Final Batch Loss: 0.0003001195436809212\n",
      "Epoch 2898, Loss: 0.000843016809085384, Final Batch Loss: 0.0006591008277609944\n",
      "Epoch 2899, Loss: 0.0033574494768799923, Final Batch Loss: 2.9985562832735013e-06\n",
      "Epoch 2900, Loss: 0.007743711714283563, Final Batch Loss: 0.00017831534205470234\n",
      "Epoch 2901, Loss: 0.00026782859640661627, Final Batch Loss: 0.0001309281651629135\n",
      "Epoch 2902, Loss: 0.00033987990900641307, Final Batch Loss: 0.0002183538454119116\n",
      "Epoch 2903, Loss: 0.000741030595236225, Final Batch Loss: 5.214863267610781e-05\n",
      "Epoch 2904, Loss: 0.0002318740080227144, Final Batch Loss: 0.00016832337132655084\n",
      "Epoch 2905, Loss: 0.00029613061633426696, Final Batch Loss: 0.00015575512952636927\n",
      "Epoch 2906, Loss: 0.0021048412436357467, Final Batch Loss: 2.2026315491530113e-05\n",
      "Epoch 2907, Loss: 0.000302659158478491, Final Batch Loss: 1.0045914677903056e-06\n",
      "Epoch 2908, Loss: 0.0013282863073982298, Final Batch Loss: 0.00035613018553704023\n",
      "Epoch 2909, Loss: 0.006284662405960262, Final Batch Loss: 0.005171141587197781\n",
      "Epoch 2910, Loss: 0.0007640829426236451, Final Batch Loss: 0.00025711883790791035\n",
      "Epoch 2911, Loss: 0.001357636249395, Final Batch Loss: 2.8586459848156665e-06\n",
      "Epoch 2912, Loss: 0.0018864371231757104, Final Batch Loss: 0.00040839758003130555\n",
      "Epoch 2913, Loss: 0.0005802992091048509, Final Batch Loss: 0.0002819376240950078\n",
      "Epoch 2914, Loss: 0.004948902656906284, Final Batch Loss: 0.004753303248435259\n",
      "Epoch 2915, Loss: 0.0019073636121902382, Final Batch Loss: 3.0122309908620082e-05\n",
      "Epoch 2916, Loss: 0.001396851977915503, Final Batch Loss: 0.00015673811140004545\n",
      "Epoch 2917, Loss: 0.0018406960589345545, Final Batch Loss: 0.0013666785089299083\n",
      "Epoch 2918, Loss: 0.00035992744960822165, Final Batch Loss: 0.00020820384088438004\n",
      "Epoch 2919, Loss: 0.002962082471640315, Final Batch Loss: 1.7819540516939014e-05\n",
      "Epoch 2920, Loss: 0.004862497909925878, Final Batch Loss: 0.0031674476340413094\n",
      "Epoch 2921, Loss: 0.0031213947077048942, Final Batch Loss: 0.002916748868301511\n",
      "Epoch 2922, Loss: 0.0003243667852075305, Final Batch Loss: 6.0739923355868086e-05\n",
      "Epoch 2923, Loss: 0.0002904046359617496, Final Batch Loss: 6.4538999140495434e-06\n",
      "Epoch 2924, Loss: 0.00015741152674308978, Final Batch Loss: 2.6655976398615167e-05\n",
      "Epoch 2925, Loss: 0.00020935356587870046, Final Batch Loss: 0.00010299522546119988\n",
      "Epoch 2926, Loss: 0.00019071505084866658, Final Batch Loss: 0.00015303878171835095\n",
      "Epoch 2927, Loss: 0.00221235762728611, Final Batch Loss: 0.00010257741814712062\n",
      "Epoch 2928, Loss: 0.0019561770604923368, Final Batch Loss: 0.0007149740122258663\n",
      "Epoch 2929, Loss: 0.0037669645971618593, Final Batch Loss: 0.003477239515632391\n",
      "Epoch 2930, Loss: 0.0012713351970887743, Final Batch Loss: 0.00010175644274568185\n",
      "Epoch 2931, Loss: 0.00033108179923146963, Final Batch Loss: 0.0001200987899210304\n",
      "Epoch 2932, Loss: 0.00021384621868492104, Final Batch Loss: 0.0001532488822704181\n",
      "Epoch 2933, Loss: 0.00021116906646057032, Final Batch Loss: 2.9588740289909765e-05\n",
      "Epoch 2934, Loss: 0.0006415173993445933, Final Batch Loss: 0.00019496417371556163\n",
      "Epoch 2935, Loss: 0.0009051208180608228, Final Batch Loss: 0.0001255659881280735\n",
      "Epoch 2936, Loss: 0.0019409661763347685, Final Batch Loss: 0.0011849809670820832\n",
      "Epoch 2937, Loss: 0.0003268786385888234, Final Batch Loss: 3.707826544996351e-05\n",
      "Epoch 2938, Loss: 0.0002602574022603221, Final Batch Loss: 6.33634117548354e-05\n",
      "Epoch 2939, Loss: 0.005346848396584392, Final Batch Loss: 0.0025298045948147774\n",
      "Epoch 2940, Loss: 0.0034209952573291957, Final Batch Loss: 0.0029529393650591373\n",
      "Epoch 2941, Loss: 0.04326089360984042, Final Batch Loss: 0.04268530383706093\n",
      "Epoch 2942, Loss: 0.00035544454294722527, Final Batch Loss: 9.594655421096832e-05\n",
      "Epoch 2943, Loss: 0.00037917658187325287, Final Batch Loss: 0.00037675813655368984\n",
      "Epoch 2944, Loss: 0.00172769567245723, Final Batch Loss: 1.3309555697560427e-06\n",
      "Epoch 2945, Loss: 0.005455420083308127, Final Batch Loss: 2.5954759621527046e-05\n",
      "Epoch 2946, Loss: 0.02156455841031857, Final Batch Loss: 0.02119659259915352\n",
      "Epoch 2947, Loss: 0.00035499957448337227, Final Batch Loss: 0.00014144895249046385\n",
      "Epoch 2948, Loss: 0.002634985256008804, Final Batch Loss: 0.0022550271824002266\n",
      "Epoch 2949, Loss: 5.3071660829573375e-05, Final Batch Loss: 8.275130198853731e-07\n",
      "Epoch 2950, Loss: 0.03482618885573174, Final Batch Loss: 0.03480720520019531\n",
      "Epoch 2951, Loss: 0.001731338765239343, Final Batch Loss: 9.555657743476331e-05\n",
      "Epoch 2952, Loss: 0.00013617339936899953, Final Batch Loss: 8.330486161867157e-05\n",
      "Epoch 2953, Loss: 0.0024718983622733504, Final Batch Loss: 0.00018499759607948363\n",
      "Epoch 2954, Loss: 0.00572360260412097, Final Batch Loss: 0.003594280919060111\n",
      "Epoch 2955, Loss: 0.0012976496363990009, Final Batch Loss: 0.0007693713414482772\n",
      "Epoch 2956, Loss: 0.0001027186040118977, Final Batch Loss: 7.457437732227845e-06\n",
      "Epoch 2957, Loss: 0.0008077783277258277, Final Batch Loss: 0.00037537311436608434\n",
      "Epoch 2958, Loss: 0.003009274834766984, Final Batch Loss: 0.0010922399815171957\n",
      "Epoch 2959, Loss: 0.0015085806517163292, Final Batch Loss: 0.0013226693263277411\n",
      "Epoch 2960, Loss: 0.0009047216080944054, Final Batch Loss: 4.097935016034171e-05\n",
      "Epoch 2961, Loss: 0.030212842510081828, Final Batch Loss: 7.990433368831873e-05\n",
      "Epoch 2962, Loss: 0.0003307990191387944, Final Batch Loss: 0.0002190209925174713\n",
      "Epoch 2963, Loss: 0.002285065427713562, Final Batch Loss: 7.401436596410349e-05\n",
      "Epoch 2964, Loss: 0.0011290482943877578, Final Batch Loss: 0.000384666898753494\n",
      "Epoch 2965, Loss: 0.0029927011783001944, Final Batch Loss: 0.000180646704393439\n",
      "Epoch 2966, Loss: 0.0003847343323286623, Final Batch Loss: 0.0001794859126675874\n",
      "Epoch 2967, Loss: 0.0007763795147184283, Final Batch Loss: 0.00044100405648350716\n",
      "Epoch 2968, Loss: 0.00016834406415000558, Final Batch Loss: 3.374594962224364e-05\n",
      "Epoch 2969, Loss: 0.0002437418734189123, Final Batch Loss: 7.842114428058267e-06\n",
      "Epoch 2970, Loss: 0.0003797036115429364, Final Batch Loss: 0.00034762590075843036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2971, Loss: 0.000768623300245963, Final Batch Loss: 7.291276415344328e-05\n",
      "Epoch 2972, Loss: 8.777261746217846e-05, Final Batch Loss: 7.268373792612692e-06\n",
      "Epoch 2973, Loss: 0.0003387342221685685, Final Batch Loss: 9.607978427084163e-05\n",
      "Epoch 2974, Loss: 0.0030338835595102864, Final Batch Loss: 8.437009455519728e-07\n",
      "Epoch 2975, Loss: 0.003166746253555175, Final Batch Loss: 0.00010111802112078294\n",
      "Epoch 2976, Loss: 7.606164763274137e-05, Final Batch Loss: 4.987178908777423e-05\n",
      "Epoch 2977, Loss: 5.467784922075225e-05, Final Batch Loss: 4.2755746108014137e-05\n",
      "Epoch 2978, Loss: 0.00027910036351386225, Final Batch Loss: 7.998881301318761e-06\n",
      "Epoch 2979, Loss: 0.00017331404160358943, Final Batch Loss: 4.0425820770906284e-05\n",
      "Epoch 2980, Loss: 0.00033842942502815276, Final Batch Loss: 0.00022052896383684129\n",
      "Epoch 2981, Loss: 0.005950475810095668, Final Batch Loss: 0.00439841952174902\n",
      "Epoch 2982, Loss: 0.00011589700079639442, Final Batch Loss: 5.445649367175065e-05\n",
      "Epoch 2983, Loss: 0.00010696192839532159, Final Batch Loss: 6.977418524911627e-05\n",
      "Epoch 2984, Loss: 0.0001879072660813108, Final Batch Loss: 9.214921738021076e-05\n",
      "Epoch 2985, Loss: 0.0001270636021217797, Final Batch Loss: 7.549881411250681e-05\n",
      "Epoch 2986, Loss: 0.00040875651029637083, Final Batch Loss: 0.00031064284848980606\n",
      "Epoch 2987, Loss: 0.00019657926895888522, Final Batch Loss: 7.940869545564055e-05\n",
      "Epoch 2988, Loss: 6.552057311637327e-05, Final Batch Loss: 3.921770985471085e-05\n",
      "Epoch 2989, Loss: 0.0009760741054378741, Final Batch Loss: 7.071965683280723e-06\n",
      "Epoch 2990, Loss: 0.0008778927767707501, Final Batch Loss: 0.0008199056028388441\n",
      "Epoch 2991, Loss: 0.0009272439347114414, Final Batch Loss: 2.8903334168717265e-05\n",
      "Epoch 2992, Loss: 0.0003325512971059652, Final Batch Loss: 2.5506817109999247e-05\n",
      "Epoch 2993, Loss: 0.00026747632728074677, Final Batch Loss: 0.00022763056040275842\n",
      "Epoch 2994, Loss: 0.0004998216390958987, Final Batch Loss: 0.0004573641635943204\n",
      "Epoch 2995, Loss: 5.9582952644632314e-05, Final Batch Loss: 2.2914621240488486e-06\n",
      "Epoch 2996, Loss: 0.0005166783957974985, Final Batch Loss: 0.0003242839593440294\n",
      "Epoch 2997, Loss: 0.00010051223944174126, Final Batch Loss: 6.248646968742833e-05\n",
      "Epoch 2998, Loss: 0.00029888624339946546, Final Batch Loss: 0.0002501444541849196\n",
      "Epoch 2999, Loss: 0.00033337339846184477, Final Batch Loss: 8.910855831345543e-05\n",
      "Epoch 3000, Loss: 7.672530409763567e-05, Final Batch Loss: 4.487916157813743e-06\n",
      "Epoch 3001, Loss: 0.00024050076899584383, Final Batch Loss: 0.00010646476584952325\n",
      "Epoch 3002, Loss: 0.00012406793030095287, Final Batch Loss: 7.588020525872707e-05\n",
      "Epoch 3003, Loss: 0.0032587058667559177, Final Batch Loss: 0.0031747515313327312\n",
      "Epoch 3004, Loss: 0.0027853391875396483, Final Batch Loss: 2.481642150087282e-05\n",
      "Epoch 3005, Loss: 0.0008729338478588033, Final Batch Loss: 0.0008528893231414258\n",
      "Epoch 3006, Loss: 0.00029522097156586824, Final Batch Loss: 7.213481694634538e-06\n",
      "Epoch 3007, Loss: 0.0004062350926687941, Final Batch Loss: 0.0003221248334739357\n",
      "Epoch 3008, Loss: 0.0009219637213391252, Final Batch Loss: 0.0001218394681927748\n",
      "Epoch 3009, Loss: 0.00016393633632105775, Final Batch Loss: 4.34947396570351e-05\n",
      "Epoch 3010, Loss: 0.0032571968622505665, Final Batch Loss: 0.0019381491001695395\n",
      "Epoch 3011, Loss: 0.0003278905860497616, Final Batch Loss: 0.0002897220547311008\n",
      "Epoch 3012, Loss: 0.0015349656314356253, Final Batch Loss: 7.296462717931718e-05\n",
      "Epoch 3013, Loss: 0.00012125635475968011, Final Batch Loss: 7.127761637093499e-05\n",
      "Epoch 3014, Loss: 0.0012663011148106307, Final Batch Loss: 0.0009599425829946995\n",
      "Epoch 3015, Loss: 0.00014477415970759466, Final Batch Loss: 9.283328836318105e-05\n",
      "Epoch 3016, Loss: 0.001291419510380365, Final Batch Loss: 0.0012012182269245386\n",
      "Epoch 3017, Loss: 0.0005600482691079378, Final Batch Loss: 0.00033998891012743115\n",
      "Epoch 3018, Loss: 0.0015975913993315771, Final Batch Loss: 0.0001281570439459756\n",
      "Epoch 3019, Loss: 0.0006856254858575994, Final Batch Loss: 3.024418583663646e-05\n",
      "Epoch 3020, Loss: 6.485496669483837e-05, Final Batch Loss: 4.000617263955064e-05\n",
      "Epoch 3021, Loss: 0.0012198476833873428, Final Batch Loss: 8.49880525493063e-05\n",
      "Epoch 3022, Loss: 0.0006136783777037635, Final Batch Loss: 0.00046760006807744503\n",
      "Epoch 3023, Loss: 0.0032945192069746554, Final Batch Loss: 0.0027879371773451567\n",
      "Epoch 3024, Loss: 0.00013272004798636772, Final Batch Loss: 0.00011079287651227787\n",
      "Epoch 3025, Loss: 0.0011123981093987823, Final Batch Loss: 0.00015011726645752788\n",
      "Epoch 3026, Loss: 0.0007544888503616676, Final Batch Loss: 0.000189822560059838\n",
      "Epoch 3027, Loss: 0.0003922057840100024, Final Batch Loss: 4.498762791627087e-05\n",
      "Epoch 3028, Loss: 0.0017410362925147638, Final Batch Loss: 0.00166739069391042\n",
      "Epoch 3029, Loss: 0.007641607720870525, Final Batch Loss: 0.007240353152155876\n",
      "Epoch 3030, Loss: 0.0002177351307182107, Final Batch Loss: 4.492975494940765e-05\n",
      "Epoch 3031, Loss: 0.001522160014246765, Final Batch Loss: 0.0015104617923498154\n",
      "Epoch 3032, Loss: 0.0003139713589916937, Final Batch Loss: 0.00020892673637717962\n",
      "Epoch 3033, Loss: 0.00023555749794468284, Final Batch Loss: 1.6850652173161507e-05\n",
      "Epoch 3034, Loss: 0.0004426954546943307, Final Batch Loss: 0.00028849663794972\n",
      "Epoch 3035, Loss: 0.0032420977877336554, Final Batch Loss: 0.0031470234971493483\n",
      "Epoch 3036, Loss: 0.00012345289178483654, Final Batch Loss: 8.200864613172598e-06\n",
      "Epoch 3037, Loss: 0.0004058045815327205, Final Batch Loss: 0.00010141949314856902\n",
      "Epoch 3038, Loss: 0.00020129035010540974, Final Batch Loss: 2.3736288312647957e-06\n",
      "Epoch 3039, Loss: 0.0003161934109812137, Final Batch Loss: 9.595645678928122e-06\n",
      "Epoch 3040, Loss: 0.0002358020756219048, Final Batch Loss: 4.5613243855768815e-05\n",
      "Epoch 3041, Loss: 0.0010531679090490798, Final Batch Loss: 7.501972504542209e-06\n",
      "Epoch 3042, Loss: 0.042042370309900434, Final Batch Loss: 0.04202821105718613\n",
      "Epoch 3043, Loss: 0.00024179554122838454, Final Batch Loss: 1.7522116877444205e-06\n",
      "Epoch 3044, Loss: 0.0013289750604599249, Final Batch Loss: 3.412911246414296e-05\n",
      "Epoch 3045, Loss: 0.00040045166497293394, Final Batch Loss: 0.00037721602711826563\n",
      "Epoch 3046, Loss: 0.0005322376600815915, Final Batch Loss: 6.723004480591044e-05\n",
      "Epoch 3047, Loss: 9.605519153410569e-05, Final Batch Loss: 3.5962468245998025e-05\n",
      "Epoch 3048, Loss: 0.0001143952622442157, Final Batch Loss: 0.00010478337208041921\n",
      "Epoch 3049, Loss: 0.0010848010024346877, Final Batch Loss: 4.113461545784958e-05\n",
      "Epoch 3050, Loss: 0.0006067625363357365, Final Batch Loss: 0.00011543900473043323\n",
      "Epoch 3051, Loss: 0.0026476121274754405, Final Batch Loss: 0.002589710056781769\n",
      "Epoch 3052, Loss: 0.002540441113524139, Final Batch Loss: 0.0003030012594535947\n",
      "Epoch 3053, Loss: 2.0568243144225562e-05, Final Batch Loss: 1.4410877156478819e-05\n",
      "Epoch 3054, Loss: 0.002730020205490291, Final Batch Loss: 0.0015343641862273216\n",
      "Epoch 3055, Loss: 0.0003859272919726209, Final Batch Loss: 7.42050997359911e-06\n",
      "Epoch 3056, Loss: 7.927466776891379e-05, Final Batch Loss: 4.446107595867943e-06\n",
      "Epoch 3057, Loss: 0.0006467057310146629, Final Batch Loss: 1.4828102393948939e-05\n",
      "Epoch 3058, Loss: 0.0011523642906468012, Final Batch Loss: 1.0441742233524565e-05\n",
      "Epoch 3059, Loss: 0.00013853803284291644, Final Batch Loss: 0.00012641675129998475\n",
      "Epoch 3060, Loss: 0.00038315096753649414, Final Batch Loss: 0.00014085936709307134\n",
      "Epoch 3061, Loss: 0.02085534718207782, Final Batch Loss: 0.02083960361778736\n",
      "Epoch 3062, Loss: 0.000276944279903546, Final Batch Loss: 3.3140924642793834e-05\n",
      "Epoch 3063, Loss: 0.0021808318997500464, Final Batch Loss: 0.0019869222305715084\n",
      "Epoch 3064, Loss: 0.07058216651785187, Final Batch Loss: 0.00027366747963242233\n",
      "Epoch 3065, Loss: 0.03268770962313283, Final Batch Loss: 0.00017111464694608003\n",
      "Epoch 3066, Loss: 0.00011568222817004425, Final Batch Loss: 0.00010173986811423674\n",
      "Epoch 3067, Loss: 0.0037091467529535294, Final Batch Loss: 0.0035180889535695314\n",
      "Epoch 3068, Loss: 0.0019439349125605077, Final Batch Loss: 0.0017495763022452593\n",
      "Epoch 3069, Loss: 0.0003762247652048245, Final Batch Loss: 0.00013500354543793947\n",
      "Epoch 3070, Loss: 0.0002658672428879072, Final Batch Loss: 9.019070603244472e-06\n",
      "Epoch 3071, Loss: 0.0011611456557147903, Final Batch Loss: 6.455024049500935e-06\n",
      "Epoch 3072, Loss: 0.000832963727589231, Final Batch Loss: 0.0007308658678084612\n",
      "Epoch 3073, Loss: 0.00021904332970734686, Final Batch Loss: 0.00010948906128760427\n",
      "Epoch 3074, Loss: 0.001769241303918534, Final Batch Loss: 1.5159728718572296e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3075, Loss: 0.001957283737283433, Final Batch Loss: 1.891682404675521e-05\n",
      "Epoch 3076, Loss: 0.00017080604266084265, Final Batch Loss: 1.5365088984253816e-05\n",
      "Epoch 3077, Loss: 0.0017355596719426103, Final Batch Loss: 0.00010639581159921363\n",
      "Epoch 3078, Loss: 0.00033162553518195637, Final Batch Loss: 1.7573813238414004e-05\n",
      "Epoch 3079, Loss: 0.0006032766541466117, Final Batch Loss: 0.00017215238767676055\n",
      "Epoch 3080, Loss: 0.0007648319588042796, Final Batch Loss: 0.00034298020182177424\n",
      "Epoch 3081, Loss: 0.0011943259742110968, Final Batch Loss: 0.00036674615694209933\n",
      "Epoch 3082, Loss: 0.00011079041541961487, Final Batch Loss: 1.663098191784229e-05\n",
      "Epoch 3083, Loss: 0.00013009706185584946, Final Batch Loss: 2.5125484626187244e-06\n",
      "Epoch 3084, Loss: 0.003748857110622339, Final Batch Loss: 2.5807108613662422e-05\n",
      "Epoch 3085, Loss: 0.0010897053471126128, Final Batch Loss: 1.5286688721971586e-05\n",
      "Epoch 3086, Loss: 0.0023050318277455517, Final Batch Loss: 1.0405740795249585e-05\n",
      "Epoch 3087, Loss: 8.395566851504555e-06, Final Batch Loss: 1.703627162896737e-06\n",
      "Epoch 3088, Loss: 0.0002101580048474716, Final Batch Loss: 1.7777218090486713e-05\n",
      "Epoch 3089, Loss: 0.0004964409017702565, Final Batch Loss: 0.0004269429773557931\n",
      "Epoch 3090, Loss: 0.006310967430181336, Final Batch Loss: 0.006225118413567543\n",
      "Epoch 3091, Loss: 0.00028635758644668385, Final Batch Loss: 1.2671654985751957e-05\n",
      "Epoch 3092, Loss: 3.3367733522027265e-05, Final Batch Loss: 1.1650548003672156e-05\n",
      "Epoch 3093, Loss: 0.01703473975067027, Final Batch Loss: 0.00017539647524245083\n",
      "Epoch 3094, Loss: 0.00013966763071948662, Final Batch Loss: 6.959156598895788e-05\n",
      "Epoch 3095, Loss: 0.00020364176452858374, Final Batch Loss: 4.280490247765556e-05\n",
      "Epoch 3096, Loss: 0.00020245496125426143, Final Batch Loss: 0.00017371521971654147\n",
      "Epoch 3097, Loss: 0.0003487513640720863, Final Batch Loss: 0.00030353572219610214\n",
      "Epoch 3098, Loss: 0.0003896872658515349, Final Batch Loss: 0.00017531558114569634\n",
      "Epoch 3099, Loss: 0.000213527113373857, Final Batch Loss: 0.00014551162894349545\n",
      "Epoch 3100, Loss: 0.00046937296156102093, Final Batch Loss: 1.4608177480113227e-05\n",
      "Epoch 3101, Loss: 0.0010712885014072526, Final Batch Loss: 1.8806098523782566e-05\n",
      "Epoch 3102, Loss: 0.0014244850215163751, Final Batch Loss: 3.2045834359450964e-06\n",
      "Epoch 3103, Loss: 0.0030930309876566753, Final Batch Loss: 0.0028674574568867683\n",
      "Epoch 3104, Loss: 0.0012433429365046322, Final Batch Loss: 0.0002538161934353411\n",
      "Epoch 3105, Loss: 0.00017748362506608828, Final Batch Loss: 6.3364836933033075e-06\n",
      "Epoch 3106, Loss: 0.000672577996738255, Final Batch Loss: 0.0004006506933365017\n",
      "Epoch 3107, Loss: 0.00019909994443878531, Final Batch Loss: 7.623570854775608e-05\n",
      "Epoch 3108, Loss: 0.0029570260376203805, Final Batch Loss: 0.00017054451745934784\n",
      "Epoch 3109, Loss: 0.002810020523611456, Final Batch Loss: 0.00215919385664165\n",
      "Epoch 3110, Loss: 0.00032243915848084725, Final Batch Loss: 4.315717160352506e-05\n",
      "Epoch 3111, Loss: 0.0005797325284220278, Final Batch Loss: 0.0005238442681729794\n",
      "Epoch 3112, Loss: 0.0005165602269698866, Final Batch Loss: 0.00041714776307344437\n",
      "Epoch 3113, Loss: 0.0029501784447347745, Final Batch Loss: 0.002812919206917286\n",
      "Epoch 3114, Loss: 0.002601071017124923, Final Batch Loss: 0.0025563761591911316\n",
      "Epoch 3115, Loss: 0.00031736234632262494, Final Batch Loss: 1.3124639735906385e-05\n",
      "Epoch 3116, Loss: 0.0003968858545704279, Final Batch Loss: 0.00036542373709380627\n",
      "Epoch 3117, Loss: 0.0005457835795823485, Final Batch Loss: 0.000504311581607908\n",
      "Epoch 3118, Loss: 0.0007288574270205572, Final Batch Loss: 0.00019003859779331833\n",
      "Epoch 3119, Loss: 0.0001902922854242206, Final Batch Loss: 6.769467745471047e-06\n",
      "Epoch 3120, Loss: 3.7819297176611144e-05, Final Batch Loss: 7.632653250766452e-06\n",
      "Epoch 3121, Loss: 0.000454365055730932, Final Batch Loss: 3.553123235633393e-07\n",
      "Epoch 3122, Loss: 0.0024231379065895453, Final Batch Loss: 0.0022806290071457624\n",
      "Epoch 3123, Loss: 3.464260566943267e-05, Final Batch Loss: 2.5982224087783834e-06\n",
      "Epoch 3124, Loss: 0.0038232806691667065, Final Batch Loss: 3.0100680305622518e-05\n",
      "Epoch 3125, Loss: 0.0002447423103149049, Final Batch Loss: 8.703064668225124e-05\n",
      "Epoch 3126, Loss: 0.0011435746578172257, Final Batch Loss: 2.623711679916596e-06\n",
      "Epoch 3127, Loss: 0.00011067195737268776, Final Batch Loss: 7.121252565411851e-05\n",
      "Epoch 3128, Loss: 6.69829723847215e-05, Final Batch Loss: 1.1794990314228926e-05\n",
      "Epoch 3129, Loss: 6.262101851461921e-05, Final Batch Loss: 1.4618673958466388e-05\n",
      "Epoch 3130, Loss: 0.00010622799163684249, Final Batch Loss: 4.5100438001099974e-05\n",
      "Epoch 3131, Loss: 0.00023764019715599716, Final Batch Loss: 0.00012192760914331302\n",
      "Epoch 3132, Loss: 5.2601733841584064e-05, Final Batch Loss: 2.0531459085759707e-05\n",
      "Epoch 3133, Loss: 8.143162449414376e-05, Final Batch Loss: 1.9539498680387624e-05\n",
      "Epoch 3134, Loss: 0.00034126451100746635, Final Batch Loss: 1.8657514374353923e-05\n",
      "Epoch 3135, Loss: 0.002059411257505417, Final Batch Loss: 0.001220285426825285\n",
      "Epoch 3136, Loss: 0.0038994423362055386, Final Batch Loss: 6.457629297074163e-06\n",
      "Epoch 3137, Loss: 0.00022259916659095325, Final Batch Loss: 2.2996919142315164e-05\n",
      "Epoch 3138, Loss: 0.0016714257944840938, Final Batch Loss: 9.842324652709067e-05\n",
      "Epoch 3139, Loss: 0.00011238324077567086, Final Batch Loss: 6.10409551882185e-05\n",
      "Epoch 3140, Loss: 0.0006912082244525664, Final Batch Loss: 0.0006323627312667668\n",
      "Epoch 3141, Loss: 0.00653494890411821, Final Batch Loss: 1.0019592991739046e-05\n",
      "Epoch 3142, Loss: 0.0005184641049709171, Final Batch Loss: 0.0002428334264550358\n",
      "Epoch 3143, Loss: 0.0003786624929489335, Final Batch Loss: 0.0003539231256581843\n",
      "Epoch 3144, Loss: 1.973968574020546e-05, Final Batch Loss: 6.358367500070017e-06\n",
      "Epoch 3145, Loss: 0.0016873250642674975, Final Batch Loss: 0.00010772980022011325\n",
      "Epoch 3146, Loss: 0.00024433906673948513, Final Batch Loss: 6.19477668806212e-06\n",
      "Epoch 3147, Loss: 0.000381651749194134, Final Batch Loss: 0.00033734182943589985\n",
      "Epoch 3148, Loss: 0.00018640659254742786, Final Batch Loss: 3.9054655644576997e-05\n",
      "Epoch 3149, Loss: 2.4160253815352917e-05, Final Batch Loss: 1.0376843420090154e-05\n",
      "Epoch 3150, Loss: 0.00017650632798904553, Final Batch Loss: 9.67271116678603e-05\n",
      "Epoch 3151, Loss: 0.0004009793083241675, Final Batch Loss: 6.098926314734854e-05\n",
      "Epoch 3152, Loss: 0.001664058720052708, Final Batch Loss: 0.0016026557423174381\n",
      "Epoch 3153, Loss: 0.00019659945246530697, Final Batch Loss: 0.00010483585356269032\n",
      "Epoch 3154, Loss: 9.848177614912856e-05, Final Batch Loss: 2.086729546135757e-05\n",
      "Epoch 3155, Loss: 0.00030024044099263847, Final Batch Loss: 0.0002200005983468145\n",
      "Epoch 3156, Loss: 0.0018980557360919192, Final Batch Loss: 1.035381865222007e-05\n",
      "Epoch 3157, Loss: 0.00025349603356517036, Final Batch Loss: 7.245613687700825e-06\n",
      "Epoch 3158, Loss: 0.0002803250554279657, Final Batch Loss: 2.9094329875078984e-05\n",
      "Epoch 3159, Loss: 4.7412576805072604e-05, Final Batch Loss: 6.789071903767763e-06\n",
      "Epoch 3160, Loss: 0.0010123904939973727, Final Batch Loss: 0.0008509769686497748\n",
      "Epoch 3161, Loss: 9.932081593433395e-05, Final Batch Loss: 1.839986362028867e-05\n",
      "Epoch 3162, Loss: 0.0004076692639500834, Final Batch Loss: 0.00011386644473532215\n",
      "Epoch 3163, Loss: 7.345765698119067e-05, Final Batch Loss: 3.7644418625859544e-05\n",
      "Epoch 3164, Loss: 7.236817691591568e-05, Final Batch Loss: 4.091176015208475e-05\n",
      "Epoch 3165, Loss: 0.00030999433420220157, Final Batch Loss: 1.070500638888916e-05\n",
      "Epoch 3166, Loss: 0.003555214401330886, Final Batch Loss: 0.00354824704118073\n",
      "Epoch 3167, Loss: 0.002304138499312103, Final Batch Loss: 0.001084442948922515\n",
      "Epoch 3168, Loss: 0.00011154513049405068, Final Batch Loss: 4.3144391383975744e-06\n",
      "Epoch 3169, Loss: 0.0003108215951215243, Final Batch Loss: 2.1368052330217324e-05\n",
      "Epoch 3170, Loss: 0.0005171825978322886, Final Batch Loss: 7.139174704207107e-05\n",
      "Epoch 3171, Loss: 5.099921281725983e-05, Final Batch Loss: 2.1387781998782884e-06\n",
      "Epoch 3172, Loss: 0.0010907444593613036, Final Batch Loss: 2.40485678659752e-06\n",
      "Epoch 3173, Loss: 2.441441210976336e-05, Final Batch Loss: 8.355025784112513e-06\n",
      "Epoch 3174, Loss: 0.00023388403496937826, Final Batch Loss: 0.00010510600259294733\n",
      "Epoch 3175, Loss: 0.0002551503202994354, Final Batch Loss: 0.0001710363430902362\n",
      "Epoch 3176, Loss: 0.0003662808676381246, Final Batch Loss: 1.100674217013875e-05\n",
      "Epoch 3177, Loss: 0.003546021835063584, Final Batch Loss: 0.003421497531235218\n",
      "Epoch 3178, Loss: 0.002207291872764472, Final Batch Loss: 1.4687982911709696e-05\n",
      "Epoch 3179, Loss: 0.00035406300048634876, Final Batch Loss: 1.024452103592921e-05\n",
      "Epoch 3180, Loss: 9.295182098867372e-05, Final Batch Loss: 1.2637312465813011e-05\n",
      "Epoch 3181, Loss: 0.001202119925437728, Final Batch Loss: 2.63964211626444e-05\n",
      "Epoch 3182, Loss: 6.696174568787683e-05, Final Batch Loss: 2.4077866328298114e-05\n",
      "Epoch 3183, Loss: 0.00023708320441073738, Final Batch Loss: 0.00018575073045212775\n",
      "Epoch 3184, Loss: 0.0009111174585996196, Final Batch Loss: 0.0007229445036500692\n",
      "Epoch 3185, Loss: 0.00027456813768367283, Final Batch Loss: 1.982035973924212e-05\n",
      "Epoch 3186, Loss: 0.0014046669457457028, Final Batch Loss: 0.0013263706350699067\n",
      "Epoch 3187, Loss: 0.0007094607062754221, Final Batch Loss: 3.6960824218112975e-05\n",
      "Epoch 3188, Loss: 0.0005074955988675356, Final Batch Loss: 2.6977824745699763e-05\n",
      "Epoch 3189, Loss: 0.0001685654278844595, Final Batch Loss: 0.00013168157602194697\n",
      "Epoch 3190, Loss: 0.0004917726037092507, Final Batch Loss: 0.00019166097627021372\n",
      "Epoch 3191, Loss: 0.00015688697385485284, Final Batch Loss: 5.513451833394356e-05\n",
      "Epoch 3192, Loss: 0.00025582087982911617, Final Batch Loss: 0.00010751844092737883\n",
      "Epoch 3193, Loss: 6.392419345502276e-05, Final Batch Loss: 1.5562354747089557e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3194, Loss: 0.00013782102178083733, Final Batch Loss: 1.8875827663578093e-05\n",
      "Epoch 3195, Loss: 6.632917097704194e-05, Final Batch Loss: 8.992708444566233e-07\n",
      "Epoch 3196, Loss: 0.00214163210875995, Final Batch Loss: 1.4895775166223757e-05\n",
      "Epoch 3197, Loss: 0.0017368923872709274, Final Batch Loss: 0.00029567163437604904\n",
      "Epoch 3198, Loss: 0.0007792153410264291, Final Batch Loss: 6.523446791106835e-05\n",
      "Epoch 3199, Loss: 0.00012504821415859624, Final Batch Loss: 3.7703480302297976e-06\n",
      "Epoch 3200, Loss: 0.0003431008453844697, Final Batch Loss: 1.2030396646878216e-05\n",
      "Epoch 3201, Loss: 0.0026941354444716126, Final Batch Loss: 0.00025042463676072657\n",
      "Epoch 3202, Loss: 0.0037177379672357347, Final Batch Loss: 4.025152520625852e-05\n",
      "Epoch 3203, Loss: 0.002668237779289484, Final Batch Loss: 0.0023893252946436405\n",
      "Epoch 3204, Loss: 0.0007669063415960409, Final Batch Loss: 3.837465919787064e-05\n",
      "Epoch 3205, Loss: 0.0038399782351916656, Final Batch Loss: 0.0036653412971645594\n",
      "Epoch 3206, Loss: 0.0054050059043220244, Final Batch Loss: 0.005312786437571049\n",
      "Epoch 3207, Loss: 0.0033050416386686265, Final Batch Loss: 0.0025434319395571947\n",
      "Epoch 3208, Loss: 0.0010903740476351231, Final Batch Loss: 0.00010550275328569114\n",
      "Epoch 3209, Loss: 0.0019116807961836457, Final Batch Loss: 0.0011440046364441514\n",
      "Epoch 3210, Loss: 9.233886976289796e-05, Final Batch Loss: 9.963780939870048e-06\n",
      "Epoch 3211, Loss: 0.0006872373924124986, Final Batch Loss: 0.00040754801011644304\n",
      "Epoch 3212, Loss: 0.0006527613295475021, Final Batch Loss: 0.0006439590943045914\n",
      "Epoch 3213, Loss: 0.00024099458642012905, Final Batch Loss: 2.2031001208233647e-05\n",
      "Epoch 3214, Loss: 0.0010131400467798812, Final Batch Loss: 2.0924691852997057e-05\n",
      "Epoch 3215, Loss: 0.0013077979820081964, Final Batch Loss: 0.0011299790348857641\n",
      "Epoch 3216, Loss: 5.914267967455089e-05, Final Batch Loss: 1.0128365829586983e-05\n",
      "Epoch 3217, Loss: 0.00014175500109558925, Final Batch Loss: 7.307437772396952e-05\n",
      "Epoch 3218, Loss: 9.97839706542436e-05, Final Batch Loss: 1.7720678442856297e-05\n",
      "Epoch 3219, Loss: 0.00011012622235284653, Final Batch Loss: 2.5934654331649654e-05\n",
      "Epoch 3220, Loss: 0.0002762492367764935, Final Batch Loss: 0.00011081338743679225\n",
      "Epoch 3221, Loss: 4.7144359996309504e-05, Final Batch Loss: 2.7566107746679336e-05\n",
      "Epoch 3222, Loss: 0.0015305446941056289, Final Batch Loss: 7.844329957151785e-05\n",
      "Epoch 3223, Loss: 0.0003139301534247352, Final Batch Loss: 1.4809162166784517e-05\n",
      "Epoch 3224, Loss: 6.30374079264584e-05, Final Batch Loss: 5.341498035704717e-05\n",
      "Epoch 3225, Loss: 0.00030044418963370845, Final Batch Loss: 8.910163160180673e-05\n",
      "Epoch 3226, Loss: 0.0011212338431505486, Final Batch Loss: 0.0009020533761940897\n",
      "Epoch 3227, Loss: 0.00021566566283581778, Final Batch Loss: 0.00011670988897094503\n",
      "Epoch 3228, Loss: 9.625699021853507e-05, Final Batch Loss: 3.841053330688737e-05\n",
      "Epoch 3229, Loss: 0.00048210553904937115, Final Batch Loss: 2.1261197616695426e-05\n",
      "Epoch 3230, Loss: 0.001043586071318714, Final Batch Loss: 0.0009988993406295776\n",
      "Epoch 3231, Loss: 0.0001178518396045547, Final Batch Loss: 4.54099899798166e-05\n",
      "Epoch 3232, Loss: 8.181764133041725e-05, Final Batch Loss: 2.4595210561528802e-05\n",
      "Epoch 3233, Loss: 0.0014762500004508183, Final Batch Loss: 7.938238013593946e-06\n",
      "Epoch 3234, Loss: 0.0017110340340877883, Final Batch Loss: 1.0944255336653441e-05\n",
      "Epoch 3235, Loss: 5.126389237375406e-05, Final Batch Loss: 3.389735638847924e-06\n",
      "Epoch 3236, Loss: 0.002170631181797944, Final Batch Loss: 0.0001665185991441831\n",
      "Epoch 3237, Loss: 0.0041345150384586304, Final Batch Loss: 0.0038879872299730778\n",
      "Epoch 3238, Loss: 0.00012975523873137718, Final Batch Loss: 2.401431402176968e-06\n",
      "Epoch 3239, Loss: 0.0017226715572178364, Final Batch Loss: 0.0015911568189039826\n",
      "Epoch 3240, Loss: 2.0592638037442157e-05, Final Batch Loss: 4.721996162970754e-07\n",
      "Epoch 3241, Loss: 0.003270980782872357, Final Batch Loss: 7.025778359093238e-06\n",
      "Epoch 3242, Loss: 0.001337314299235004, Final Batch Loss: 6.404980013030581e-06\n",
      "Epoch 3243, Loss: 0.004167776685420677, Final Batch Loss: 2.5577864448678156e-07\n",
      "Epoch 3244, Loss: 8.790492211119272e-05, Final Batch Loss: 1.9475493900245056e-05\n",
      "Epoch 3245, Loss: 0.0004380009340820834, Final Batch Loss: 0.00024487185874022543\n",
      "Epoch 3246, Loss: 0.00013274626871861983, Final Batch Loss: 0.0001120872693718411\n",
      "Epoch 3247, Loss: 7.3850673288689e-05, Final Batch Loss: 5.144682290847413e-05\n",
      "Epoch 3248, Loss: 0.005703483060642611, Final Batch Loss: 0.00562610337510705\n",
      "Epoch 3249, Loss: 0.0003364139556651935, Final Batch Loss: 0.0001290553336730227\n",
      "Epoch 3250, Loss: 0.0001472726507927291, Final Batch Loss: 8.39897693367675e-05\n",
      "Epoch 3251, Loss: 3.736822964128805e-05, Final Batch Loss: 1.1596363947319333e-05\n",
      "Epoch 3252, Loss: 0.00010223338466630594, Final Batch Loss: 8.853778012962721e-07\n",
      "Epoch 3253, Loss: 0.0032101421820698306, Final Batch Loss: 7.10284075466916e-05\n",
      "Epoch 3254, Loss: 3.181567262799945e-05, Final Batch Loss: 1.3211129044066183e-05\n",
      "Epoch 3255, Loss: 0.0002449790945320274, Final Batch Loss: 8.956080819189083e-06\n",
      "Epoch 3256, Loss: 7.15215501259081e-05, Final Batch Loss: 3.783876309171319e-05\n",
      "Epoch 3257, Loss: 0.008101428118379772, Final Batch Loss: 0.008098731748759747\n",
      "Epoch 3258, Loss: 0.002937479435786372, Final Batch Loss: 5.770197822130285e-05\n",
      "Epoch 3259, Loss: 0.0005914572370784299, Final Batch Loss: 6.16092938798829e-06\n",
      "Epoch 3260, Loss: 0.004601612570695579, Final Batch Loss: 0.002812616527080536\n",
      "Epoch 3261, Loss: 0.0010768099018605426, Final Batch Loss: 0.00018764777632895857\n",
      "Epoch 3262, Loss: 0.0002441645738144871, Final Batch Loss: 1.6368005162803456e-05\n",
      "Epoch 3263, Loss: 2.743700133578386e-05, Final Batch Loss: 8.683447958901525e-06\n",
      "Epoch 3264, Loss: 0.0003965337891713716, Final Batch Loss: 0.0003112283593509346\n",
      "Epoch 3265, Loss: 4.555577288556378e-05, Final Batch Loss: 1.1784732123487629e-05\n",
      "Epoch 3266, Loss: 0.00012194948192245647, Final Batch Loss: 4.860934268435813e-07\n",
      "Epoch 3267, Loss: 5.9968908317387104e-05, Final Batch Loss: 4.370838723843917e-05\n",
      "Epoch 3268, Loss: 8.628790465081693e-05, Final Batch Loss: 3.5274374567961786e-06\n",
      "Epoch 3269, Loss: 7.997373359103221e-05, Final Batch Loss: 1.1348749467288144e-05\n",
      "Epoch 3270, Loss: 0.0011282077903160825, Final Batch Loss: 6.963104533497244e-05\n",
      "Epoch 3271, Loss: 0.0011241053466619633, Final Batch Loss: 5.211145889916224e-06\n",
      "Epoch 3272, Loss: 0.0008948557660914958, Final Batch Loss: 2.5533372536301613e-05\n",
      "Epoch 3273, Loss: 1.556478719066945e-05, Final Batch Loss: 3.0724700081918854e-06\n",
      "Epoch 3274, Loss: 0.00027996787684969604, Final Batch Loss: 0.0002295518497703597\n",
      "Epoch 3275, Loss: 3.101537606653437e-05, Final Batch Loss: 1.5427418702529394e-06\n",
      "Epoch 3276, Loss: 0.0001221661923409556, Final Batch Loss: 1.3393208973866422e-05\n",
      "Epoch 3277, Loss: 0.0008102839565253817, Final Batch Loss: 0.0001102158785215579\n",
      "Epoch 3278, Loss: 0.00027608901291387156, Final Batch Loss: 7.369157538050786e-05\n",
      "Epoch 3279, Loss: 6.48200984869618e-05, Final Batch Loss: 5.2698494982905686e-05\n",
      "Epoch 3280, Loss: 0.0005424515547929332, Final Batch Loss: 0.0003959831374231726\n",
      "Epoch 3281, Loss: 0.0024559859302826226, Final Batch Loss: 0.0020480179227888584\n",
      "Epoch 3282, Loss: 0.0002951523183583049, Final Batch Loss: 3.93138725485187e-06\n",
      "Epoch 3283, Loss: 0.00011771842764574103, Final Batch Loss: 8.857909415382892e-05\n",
      "Epoch 3284, Loss: 0.0007730628603894729, Final Batch Loss: 3.255792034906335e-05\n",
      "Epoch 3285, Loss: 0.0018300976371392608, Final Batch Loss: 0.000966092455200851\n",
      "Epoch 3286, Loss: 0.0003854476490232628, Final Batch Loss: 0.00035341206239536405\n",
      "Epoch 3287, Loss: 0.000607945621595718, Final Batch Loss: 2.0833351300098002e-05\n",
      "Epoch 3288, Loss: 2.662587917257042e-05, Final Batch Loss: 2.3519005480920896e-05\n",
      "Epoch 3289, Loss: 0.0006117191333032679, Final Batch Loss: 2.1821044356329367e-05\n",
      "Epoch 3290, Loss: 0.00031845625562709756, Final Batch Loss: 0.0002721128112170845\n",
      "Epoch 3291, Loss: 7.380408760582213e-05, Final Batch Loss: 6.416300038836198e-06\n",
      "Epoch 3292, Loss: 0.0006147281674202532, Final Batch Loss: 0.0003673225874081254\n",
      "Epoch 3293, Loss: 4.264241397322621e-05, Final Batch Loss: 1.4881463357596658e-05\n",
      "Epoch 3294, Loss: 3.6941961241154786e-06, Final Batch Loss: 3.9118808103921765e-07\n",
      "Epoch 3295, Loss: 1.4210483556098552e-05, Final Batch Loss: 4.6525829588972556e-07\n",
      "Epoch 3296, Loss: 3.307755878267926e-05, Final Batch Loss: 3.988063781434903e-06\n",
      "Epoch 3297, Loss: 1.9009292373084463e-05, Final Batch Loss: 1.7185993783641607e-06\n",
      "Epoch 3298, Loss: 4.7250698571588146e-05, Final Batch Loss: 6.277904049056815e-06\n",
      "Epoch 3299, Loss: 0.002177569505874999, Final Batch Loss: 0.0019402545876801014\n",
      "Epoch 3300, Loss: 0.00011995742909221008, Final Batch Loss: 8.379248583878507e-07\n",
      "Epoch 3301, Loss: 0.0015004889137344435, Final Batch Loss: 0.0013433222193270922\n",
      "Epoch 3302, Loss: 7.138707223930396e-05, Final Batch Loss: 3.977019514422864e-05\n",
      "Epoch 3303, Loss: 0.0001284377540287096, Final Batch Loss: 3.2321408070856705e-05\n",
      "Epoch 3304, Loss: 0.007126492333554779, Final Batch Loss: 1.860910742834676e-05\n",
      "Epoch 3305, Loss: 0.0003350511397002265, Final Batch Loss: 0.00013616433716379106\n",
      "Epoch 3306, Loss: 1.4753413324797293e-05, Final Batch Loss: 7.0789333221910056e-06\n",
      "Epoch 3307, Loss: 4.776819082508155e-05, Final Batch Loss: 3.489255732347374e-06\n",
      "Epoch 3308, Loss: 1.044321321330699e-05, Final Batch Loss: 1.9096601988621842e-07\n",
      "Epoch 3309, Loss: 0.003381164952315885, Final Batch Loss: 4.854261078435229e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3310, Loss: 0.00017153122098534368, Final Batch Loss: 0.00013948333798907697\n",
      "Epoch 3311, Loss: 3.49231386280735e-05, Final Batch Loss: 2.1129511878825724e-05\n",
      "Epoch 3312, Loss: 0.0022740993299521506, Final Batch Loss: 0.00019631331088021398\n",
      "Epoch 3313, Loss: 0.0013071356534055667, Final Batch Loss: 9.513187251286581e-07\n",
      "Epoch 3314, Loss: 5.492322088684887e-05, Final Batch Loss: 3.2520729291718453e-06\n",
      "Epoch 3315, Loss: 3.539655699569266e-05, Final Batch Loss: 4.040934072691016e-06\n",
      "Epoch 3316, Loss: 0.0005491590563906357, Final Batch Loss: 0.0001698040432529524\n",
      "Epoch 3317, Loss: 0.00015688292410231952, Final Batch Loss: 2.4765679427218856e-06\n",
      "Epoch 3318, Loss: 0.0002275586007272068, Final Batch Loss: 6.69335668135318e-06\n",
      "Epoch 3319, Loss: 0.00012664668247452937, Final Batch Loss: 8.73393946676515e-05\n",
      "Epoch 3320, Loss: 5.3456575187738054e-05, Final Batch Loss: 1.2322447219048627e-05\n",
      "Epoch 3321, Loss: 0.003089197176450398, Final Batch Loss: 0.002982035046443343\n",
      "Epoch 3322, Loss: 0.00015525976778008044, Final Batch Loss: 8.418493234785274e-05\n",
      "Epoch 3323, Loss: 9.473825912209577e-06, Final Batch Loss: 1.0485562143003335e-06\n",
      "Epoch 3324, Loss: 0.0008221868783948594, Final Batch Loss: 0.0008092043572105467\n",
      "Epoch 3325, Loss: 2.771568688331172e-06, Final Batch Loss: 9.038710686581908e-07\n",
      "Epoch 3326, Loss: 0.00036608087793865707, Final Batch Loss: 2.8528773327707313e-05\n",
      "Epoch 3327, Loss: 6.880927131192038e-06, Final Batch Loss: 2.0022470437197626e-07\n",
      "Epoch 3328, Loss: 0.0010451427324369433, Final Batch Loss: 1.1178980457771104e-05\n",
      "Epoch 3329, Loss: 3.7206597880867776e-05, Final Batch Loss: 1.4306836419564206e-05\n",
      "Epoch 3330, Loss: 0.0003618264709075447, Final Batch Loss: 0.00035231682704761624\n",
      "Epoch 3331, Loss: 0.00019447515114734415, Final Batch Loss: 8.047480150707997e-06\n",
      "Epoch 3332, Loss: 0.001890682313387515, Final Batch Loss: 0.001844110433012247\n",
      "Epoch 3333, Loss: 1.1943567642447306e-05, Final Batch Loss: 2.9777370400552172e-06\n",
      "Epoch 3334, Loss: 0.00010194798346674361, Final Batch Loss: 1.0763044429040747e-06\n",
      "Epoch 3335, Loss: 0.004006003015916804, Final Batch Loss: 1.2152386830166506e-07\n",
      "Epoch 3336, Loss: 0.00017467946599936113, Final Batch Loss: 9.349389438284561e-05\n",
      "Epoch 3337, Loss: 0.042855479228819604, Final Batch Loss: 0.04283907264471054\n",
      "Epoch 3338, Loss: 5.9973090174025856e-05, Final Batch Loss: 2.870385469577741e-05\n",
      "Epoch 3339, Loss: 0.00021461099822772667, Final Batch Loss: 0.0001733180833980441\n",
      "Epoch 3340, Loss: 0.0002577090563136153, Final Batch Loss: 4.03458034270443e-05\n",
      "Epoch 3341, Loss: 0.0017299911414738744, Final Batch Loss: 0.001667147851549089\n",
      "Epoch 3342, Loss: 0.0013816342543577775, Final Batch Loss: 0.0012523450423032045\n",
      "Epoch 3343, Loss: 0.0002525214877096005, Final Batch Loss: 0.0001138200968853198\n",
      "Epoch 3344, Loss: 0.019296814964036457, Final Batch Loss: 5.610966763924807e-05\n",
      "Epoch 3345, Loss: 0.00023929945018608123, Final Batch Loss: 3.4454584238119423e-05\n",
      "Epoch 3346, Loss: 0.00014342524809762836, Final Batch Loss: 0.00010214789654128253\n",
      "Epoch 3347, Loss: 0.0034501677146181464, Final Batch Loss: 0.0005933175561949611\n",
      "Epoch 3348, Loss: 0.0028612121241167188, Final Batch Loss: 0.001999602885916829\n",
      "Epoch 3349, Loss: 0.0041424644623475615, Final Batch Loss: 2.4450800992781296e-05\n",
      "Epoch 3350, Loss: 8.87782243808033e-05, Final Batch Loss: 2.0767709429492243e-05\n",
      "Epoch 3351, Loss: 2.870259413612075e-05, Final Batch Loss: 1.0666235539247282e-05\n",
      "Epoch 3352, Loss: 8.207687096728478e-05, Final Batch Loss: 7.357243885053322e-05\n",
      "Epoch 3353, Loss: 0.0001838601783674676, Final Batch Loss: 2.5372926756972447e-05\n",
      "Epoch 3354, Loss: 0.0006111315015004948, Final Batch Loss: 0.00024065673642326146\n",
      "Epoch 3355, Loss: 0.0039435839134966955, Final Batch Loss: 0.00012256995250936598\n",
      "Epoch 3356, Loss: 0.0001665595918893814, Final Batch Loss: 0.00013542042870540172\n",
      "Epoch 3357, Loss: 0.000349966296198545, Final Batch Loss: 2.2011296096025035e-05\n",
      "Epoch 3358, Loss: 0.00015636664466001093, Final Batch Loss: 9.332214540336281e-05\n",
      "Epoch 3359, Loss: 0.00018350479149376042, Final Batch Loss: 2.852734542102553e-05\n",
      "Epoch 3360, Loss: 0.00016649106601107633, Final Batch Loss: 8.419664482062217e-06\n",
      "Epoch 3361, Loss: 0.0010141163220396265, Final Batch Loss: 0.0009266728302463889\n",
      "Epoch 3362, Loss: 0.000189450234756805, Final Batch Loss: 6.605361704714596e-05\n",
      "Epoch 3363, Loss: 0.0004400101715873461, Final Batch Loss: 5.305930244503543e-06\n",
      "Epoch 3364, Loss: 6.672885592706734e-05, Final Batch Loss: 9.414849955646787e-06\n",
      "Epoch 3365, Loss: 9.039273572852835e-05, Final Batch Loss: 7.250111229950562e-05\n",
      "Epoch 3366, Loss: 0.00014941919243938173, Final Batch Loss: 4.148979769524885e-06\n",
      "Epoch 3367, Loss: 0.0016489794493281806, Final Batch Loss: 5.0088406169379596e-06\n",
      "Epoch 3368, Loss: 0.00026619126583682373, Final Batch Loss: 0.00010822938202181831\n",
      "Epoch 3369, Loss: 8.09053690318251e-05, Final Batch Loss: 6.518141890410334e-05\n",
      "Epoch 3370, Loss: 0.00019724736466741888, Final Batch Loss: 1.0139275218534749e-05\n",
      "Epoch 3371, Loss: 0.0004518763889791444, Final Batch Loss: 0.00022659802925772965\n",
      "Epoch 3372, Loss: 0.0028895307914353907, Final Batch Loss: 0.002291328040882945\n",
      "Epoch 3373, Loss: 0.00800800088836695, Final Batch Loss: 0.00795499887317419\n",
      "Epoch 3374, Loss: 0.002135218237526715, Final Batch Loss: 0.0002293270081281662\n",
      "Epoch 3375, Loss: 7.76765045884531e-05, Final Batch Loss: 2.1423507860163227e-05\n",
      "Epoch 3376, Loss: 6.012471567373723e-05, Final Batch Loss: 2.8731014026561752e-05\n",
      "Epoch 3377, Loss: 0.001708591736132803, Final Batch Loss: 5.962124305369798e-06\n",
      "Epoch 3378, Loss: 0.00034503224742366, Final Batch Loss: 6.556559674208984e-05\n",
      "Epoch 3379, Loss: 0.00039309950079768896, Final Batch Loss: 0.0003014961548615247\n",
      "Epoch 3380, Loss: 3.970477609982481e-05, Final Batch Loss: 1.277793762710644e-05\n",
      "Epoch 3381, Loss: 7.958307833177969e-05, Final Batch Loss: 4.887238901574165e-06\n",
      "Epoch 3382, Loss: 0.0058113256527576596, Final Batch Loss: 0.005339744966477156\n",
      "Epoch 3383, Loss: 4.785561304743169e-05, Final Batch Loss: 1.0724062121880706e-05\n",
      "Epoch 3384, Loss: 0.0008431645983364433, Final Batch Loss: 0.00013529343414120376\n",
      "Epoch 3385, Loss: 0.0027072535594925284, Final Batch Loss: 0.00029913021717220545\n",
      "Epoch 3386, Loss: 8.125567728711758e-05, Final Batch Loss: 5.424518167274073e-05\n",
      "Epoch 3387, Loss: 0.0008812002779450268, Final Batch Loss: 7.544047548435628e-05\n",
      "Epoch 3388, Loss: 2.074493204418104e-05, Final Batch Loss: 8.689064088684972e-06\n",
      "Epoch 3389, Loss: 0.00014606797412852757, Final Batch Loss: 4.914007513434626e-05\n",
      "Epoch 3390, Loss: 0.006184917889186181, Final Batch Loss: 0.00020462741667870432\n",
      "Epoch 3391, Loss: 0.00043063308476121165, Final Batch Loss: 1.7257731087738648e-05\n",
      "Epoch 3392, Loss: 0.0009902176789182704, Final Batch Loss: 2.9087892471579835e-05\n",
      "Epoch 3393, Loss: 0.00019999342475784943, Final Batch Loss: 0.00013543065870180726\n",
      "Epoch 3394, Loss: 9.302464650318143e-05, Final Batch Loss: 8.885462739272043e-05\n",
      "Epoch 3395, Loss: 0.0027278942907287274, Final Batch Loss: 1.851184424594976e-05\n",
      "Epoch 3396, Loss: 0.0002725907397689298, Final Batch Loss: 9.590917034074664e-05\n",
      "Epoch 3397, Loss: 8.096599049167708e-05, Final Batch Loss: 5.445361603051424e-05\n",
      "Epoch 3398, Loss: 0.0013100670912535861, Final Batch Loss: 0.0012062530731782317\n",
      "Epoch 3399, Loss: 0.00014890406509948662, Final Batch Loss: 9.160509762295987e-06\n",
      "Epoch 3400, Loss: 8.10898891359102e-05, Final Batch Loss: 2.3135544324759394e-06\n",
      "Epoch 3401, Loss: 0.001547536885482259, Final Batch Loss: 0.0001658462715568021\n",
      "Epoch 3402, Loss: 0.005507948146259878, Final Batch Loss: 9.244427928933874e-05\n",
      "Epoch 3403, Loss: 0.0001621410438019666, Final Batch Loss: 0.00015546834038104862\n",
      "Epoch 3404, Loss: 9.334515743830707e-05, Final Batch Loss: 1.025661731546279e-05\n",
      "Epoch 3405, Loss: 0.00016365459305234253, Final Batch Loss: 0.00010205784201389179\n",
      "Epoch 3406, Loss: 0.0035697589919436723, Final Batch Loss: 0.0003639464557636529\n",
      "Epoch 3407, Loss: 0.0020085765281692147, Final Batch Loss: 0.0018506479682400823\n",
      "Epoch 3408, Loss: 5.719927469272079e-05, Final Batch Loss: 9.2357333869586e-07\n",
      "Epoch 3409, Loss: 0.00010213199379904836, Final Batch Loss: 1.9466122012090636e-06\n",
      "Epoch 3410, Loss: 0.0003714929425768787, Final Batch Loss: 0.0003536487929522991\n",
      "Epoch 3411, Loss: 6.465714409387147e-05, Final Batch Loss: 3.2821860713738715e-06\n",
      "Epoch 3412, Loss: 0.0008609490359958727, Final Batch Loss: 2.0113762730034068e-05\n",
      "Epoch 3413, Loss: 0.0013248087489046156, Final Batch Loss: 0.001068456331267953\n",
      "Epoch 3414, Loss: 0.003261980185925495, Final Batch Loss: 7.899250340415165e-05\n",
      "Epoch 3415, Loss: 0.0002027365180765628, Final Batch Loss: 8.46530656417599e-06\n",
      "Epoch 3416, Loss: 0.0005646398094540928, Final Batch Loss: 2.649997259140946e-05\n",
      "Epoch 3417, Loss: 0.0001350374786852626, Final Batch Loss: 0.00011342327343299985\n",
      "Epoch 3418, Loss: 0.0012275538756512105, Final Batch Loss: 0.00015014136442914605\n",
      "Epoch 3419, Loss: 0.004320249776355922, Final Batch Loss: 0.004201930947601795\n",
      "Epoch 3420, Loss: 0.00018383681162958965, Final Batch Loss: 9.711590246297419e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3421, Loss: 8.037258521653712e-05, Final Batch Loss: 4.765104313264601e-05\n",
      "Epoch 3422, Loss: 0.0006416571854970243, Final Batch Loss: 4.436617473402293e-06\n",
      "Epoch 3423, Loss: 0.0006410282767319586, Final Batch Loss: 3.432988523854874e-05\n",
      "Epoch 3424, Loss: 0.0003409069322515279, Final Batch Loss: 0.00023139981203712523\n",
      "Epoch 3425, Loss: 0.0003556933145318908, Final Batch Loss: 0.00035293554537929595\n",
      "Epoch 3426, Loss: 0.001644298987230286, Final Batch Loss: 2.194111584685743e-05\n",
      "Epoch 3427, Loss: 0.0012006338947685435, Final Batch Loss: 0.0011447180295363069\n",
      "Epoch 3428, Loss: 0.0003129811302642338, Final Batch Loss: 6.88072104821913e-05\n",
      "Epoch 3429, Loss: 0.0020869260652034427, Final Batch Loss: 1.1710263606801163e-05\n",
      "Epoch 3430, Loss: 7.553606701549143e-05, Final Batch Loss: 5.4560750868404284e-05\n",
      "Epoch 3431, Loss: 0.00029153269133530557, Final Batch Loss: 0.0002757163601927459\n",
      "Epoch 3432, Loss: 0.00043242173546786944, Final Batch Loss: 1.8517880562285427e-07\n",
      "Epoch 3433, Loss: 0.0007859061042836402, Final Batch Loss: 3.227522029192187e-05\n",
      "Epoch 3434, Loss: 0.00011322952559567057, Final Batch Loss: 8.054018690017983e-05\n",
      "Epoch 3435, Loss: 0.0006658934871666133, Final Batch Loss: 0.00034347790642641485\n",
      "Epoch 3436, Loss: 9.45074534683954e-05, Final Batch Loss: 6.263588147703558e-05\n",
      "Epoch 3437, Loss: 0.00012035558756906539, Final Batch Loss: 3.7481499020941556e-05\n",
      "Epoch 3438, Loss: 0.006666429850156419, Final Batch Loss: 0.006601888686418533\n",
      "Epoch 3439, Loss: 0.00010424228821648285, Final Batch Loss: 6.0453494370449334e-05\n",
      "Epoch 3440, Loss: 0.00039938787449500524, Final Batch Loss: 2.8194739570608363e-05\n",
      "Epoch 3441, Loss: 5.6384697927569505e-05, Final Batch Loss: 3.29024169332115e-06\n",
      "Epoch 3442, Loss: 0.0009595197707312764, Final Batch Loss: 1.4693368029838894e-05\n",
      "Epoch 3443, Loss: 0.0022439151944126934, Final Batch Loss: 0.0019530608551576734\n",
      "Epoch 3444, Loss: 0.0020472465257626027, Final Batch Loss: 0.0018764114938676357\n",
      "Epoch 3445, Loss: 0.0012715281554847024, Final Batch Loss: 0.0011961536947637796\n",
      "Epoch 3446, Loss: 0.00018353973905504972, Final Batch Loss: 2.7902399324375438e-06\n",
      "Epoch 3447, Loss: 0.0002954707197204698, Final Batch Loss: 0.0002540046989452094\n",
      "Epoch 3448, Loss: 0.0002709115215111524, Final Batch Loss: 8.092023199424148e-05\n",
      "Epoch 3449, Loss: 0.00010034893421106972, Final Batch Loss: 6.567275704583153e-05\n",
      "Epoch 3450, Loss: 6.685218249913305e-05, Final Batch Loss: 2.2189298761077225e-05\n",
      "Epoch 3451, Loss: 0.00033859660470625386, Final Batch Loss: 8.925058500608429e-05\n",
      "Epoch 3452, Loss: 5.082518509880174e-05, Final Batch Loss: 4.12307090300601e-05\n",
      "Epoch 3453, Loss: 0.0025103710358962417, Final Batch Loss: 0.0011307353852316737\n",
      "Epoch 3454, Loss: 0.013418187232673517, Final Batch Loss: 4.130261004320346e-06\n",
      "Epoch 3455, Loss: 4.6416360419243574e-05, Final Batch Loss: 2.4451835997751914e-05\n",
      "Epoch 3456, Loss: 0.00023683232279836375, Final Batch Loss: 2.870262960641412e-07\n",
      "Epoch 3457, Loss: 0.0001719259078640789, Final Batch Loss: 4.999808993488841e-07\n",
      "Epoch 3458, Loss: 0.00010627248320815852, Final Batch Loss: 1.1529947187227663e-05\n",
      "Epoch 3459, Loss: 8.473240995954257e-05, Final Batch Loss: 2.749702071014326e-05\n",
      "Epoch 3460, Loss: 0.000140396885399241, Final Batch Loss: 3.720190579770133e-05\n",
      "Epoch 3461, Loss: 0.00011865265332744457, Final Batch Loss: 1.6620473616058007e-05\n",
      "Epoch 3462, Loss: 8.992505536298268e-05, Final Batch Loss: 5.3165684221312404e-05\n",
      "Epoch 3463, Loss: 5.042796055931831e-05, Final Batch Loss: 3.592461143853143e-05\n",
      "Epoch 3464, Loss: 3.6551509765558876e-05, Final Batch Loss: 1.5922920283628628e-05\n",
      "Epoch 3465, Loss: 0.0001300335097766947, Final Batch Loss: 4.324119436205365e-05\n",
      "Epoch 3466, Loss: 0.0007632051965629216, Final Batch Loss: 0.0007039800402708352\n",
      "Epoch 3467, Loss: 0.0008113599906209856, Final Batch Loss: 0.0005397943314164877\n",
      "Epoch 3468, Loss: 0.001402390231305617, Final Batch Loss: 0.0013802922330796719\n",
      "Epoch 3469, Loss: 0.00015658143092878163, Final Batch Loss: 8.742855425225571e-05\n",
      "Epoch 3470, Loss: 0.00010656160884536803, Final Batch Loss: 4.713597445515916e-05\n",
      "Epoch 3471, Loss: 0.0002683066559256986, Final Batch Loss: 0.00010939322237391025\n",
      "Epoch 3472, Loss: 0.00021067790657980368, Final Batch Loss: 0.0001015801026369445\n",
      "Epoch 3473, Loss: 0.00015395109039673116, Final Batch Loss: 2.211504579463508e-05\n",
      "Epoch 3474, Loss: 0.0012065734335919842, Final Batch Loss: 8.44783935463056e-05\n",
      "Epoch 3475, Loss: 0.0004270386343705468, Final Batch Loss: 0.0003648799320217222\n",
      "Epoch 3476, Loss: 0.0003644987227744423, Final Batch Loss: 7.455187005689368e-05\n",
      "Epoch 3477, Loss: 0.002607196947792545, Final Batch Loss: 0.00013543912791647017\n",
      "Epoch 3478, Loss: 0.00013760167348664254, Final Batch Loss: 9.183907241094857e-05\n",
      "Epoch 3479, Loss: 6.412590118998196e-05, Final Batch Loss: 4.46155718236696e-05\n",
      "Epoch 3480, Loss: 0.00534530240111053, Final Batch Loss: 0.004922666121274233\n",
      "Epoch 3481, Loss: 0.012685837937169708, Final Batch Loss: 0.012522416189312935\n",
      "Epoch 3482, Loss: 0.001028980335831875, Final Batch Loss: 4.239738700562157e-05\n",
      "Epoch 3483, Loss: 0.0012459975723686512, Final Batch Loss: 1.5220680325001013e-05\n",
      "Epoch 3484, Loss: 0.002982677960972069, Final Batch Loss: 0.002948347246274352\n",
      "Epoch 3485, Loss: 0.0011541667918208987, Final Batch Loss: 0.0009453240199945867\n",
      "Epoch 3486, Loss: 1.500586404290516e-05, Final Batch Loss: 5.416652129497379e-06\n",
      "Epoch 3487, Loss: 0.0014761424135940615, Final Batch Loss: 2.197243520640768e-05\n",
      "Epoch 3488, Loss: 0.0018810698529705405, Final Batch Loss: 0.0007876813178882003\n",
      "Epoch 3489, Loss: 0.0031338519183918834, Final Batch Loss: 0.000559592735953629\n",
      "Epoch 3490, Loss: 9.242737723980099e-05, Final Batch Loss: 3.2551422918913886e-05\n",
      "Epoch 3491, Loss: 0.0022857447620481253, Final Batch Loss: 0.0007757084676995873\n",
      "Epoch 3492, Loss: 0.0002621989624458365, Final Batch Loss: 1.9740524294320494e-05\n",
      "Epoch 3493, Loss: 3.684644616441801e-05, Final Batch Loss: 2.0450333977350965e-05\n",
      "Epoch 3494, Loss: 9.074902663996909e-05, Final Batch Loss: 2.779840178845916e-05\n",
      "Epoch 3495, Loss: 0.001208876872624387, Final Batch Loss: 0.0011921076802536845\n",
      "Epoch 3496, Loss: 0.00020124142520216992, Final Batch Loss: 0.0001955220941454172\n",
      "Epoch 3497, Loss: 0.00015703147073509172, Final Batch Loss: 3.929762897314504e-05\n",
      "Epoch 3498, Loss: 0.00016659338143654168, Final Batch Loss: 4.580836684908718e-05\n",
      "Epoch 3499, Loss: 0.0001550075048726285, Final Batch Loss: 0.00014133953663986176\n",
      "Epoch 3500, Loss: 0.0001724031026242301, Final Batch Loss: 9.479034633841366e-05\n",
      "Epoch 3501, Loss: 0.0014043648152437527, Final Batch Loss: 0.001362546463496983\n",
      "Epoch 3502, Loss: 0.00026200925537978037, Final Batch Loss: 3.599405999921146e-07\n",
      "Epoch 3503, Loss: 2.5939267402463884e-05, Final Batch Loss: 9.085143801712547e-07\n",
      "Epoch 3504, Loss: 0.00013799395674141124, Final Batch Loss: 8.974551019491628e-05\n",
      "Epoch 3505, Loss: 0.00014704699788126163, Final Batch Loss: 0.00012484246690291911\n",
      "Epoch 3506, Loss: 0.00017864205528894672, Final Batch Loss: 0.0001750141236698255\n",
      "Epoch 3507, Loss: 0.0014537491749138098, Final Batch Loss: 1.921231955748226e-07\n",
      "Epoch 3508, Loss: 2.6434568098920863e-05, Final Batch Loss: 3.942951479984913e-06\n",
      "Epoch 3509, Loss: 0.001440612213627901, Final Batch Loss: 1.2341733963694423e-05\n",
      "Epoch 3510, Loss: 6.6658967625699e-05, Final Batch Loss: 1.4291714251157828e-05\n",
      "Epoch 3511, Loss: 0.0003096315485890955, Final Batch Loss: 0.00016585373668931425\n",
      "Epoch 3512, Loss: 0.0004771768949467514, Final Batch Loss: 5.573245744017186e-06\n",
      "Epoch 3513, Loss: 0.0005167806230019778, Final Batch Loss: 0.00031689280876889825\n",
      "Epoch 3514, Loss: 0.00024167810261133127, Final Batch Loss: 3.478978396742605e-05\n",
      "Epoch 3515, Loss: 7.968715635797707e-06, Final Batch Loss: 6.4162054513872135e-06\n",
      "Epoch 3516, Loss: 0.005180390478926711, Final Batch Loss: 0.005027117673307657\n",
      "Epoch 3517, Loss: 0.00030155751733218494, Final Batch Loss: 1.4825607195234625e-06\n",
      "Epoch 3518, Loss: 0.0008752885478315875, Final Batch Loss: 0.00011555488163139671\n",
      "Epoch 3519, Loss: 0.00026134557992918417, Final Batch Loss: 0.0001853517460403964\n",
      "Epoch 3520, Loss: 7.82789870754641e-05, Final Batch Loss: 1.2290988706809003e-06\n",
      "Epoch 3521, Loss: 8.236083886004053e-05, Final Batch Loss: 3.4181146475020796e-05\n",
      "Epoch 3522, Loss: 0.0004537658242043108, Final Batch Loss: 0.0002513886720407754\n",
      "Epoch 3523, Loss: 0.0007202047576697623, Final Batch Loss: 5.601627321993874e-07\n",
      "Epoch 3524, Loss: 0.004961756174452603, Final Batch Loss: 0.004811301827430725\n",
      "Epoch 3525, Loss: 8.273861840280006e-05, Final Batch Loss: 6.881784065626562e-05\n",
      "Epoch 3526, Loss: 7.17707043804694e-05, Final Batch Loss: 4.0180882933782414e-05\n",
      "Epoch 3527, Loss: 0.00028175203215141664, Final Batch Loss: 4.04214688387583e-06\n",
      "Epoch 3528, Loss: 0.002294782587526356, Final Batch Loss: 7.291437498224695e-08\n",
      "Epoch 3529, Loss: 7.601597644679714e-05, Final Batch Loss: 4.84485317429062e-05\n",
      "Epoch 3530, Loss: 0.001356899093480024, Final Batch Loss: 5.632576176139992e-06\n",
      "Epoch 3531, Loss: 0.0028261758270673454, Final Batch Loss: 0.002386367181316018\n",
      "Epoch 3532, Loss: 0.0003203655735433131, Final Batch Loss: 1.5740192793600727e-07\n",
      "Epoch 3533, Loss: 2.0808037305641847e-05, Final Batch Loss: 8.333060463883157e-08\n",
      "Epoch 3534, Loss: 4.718366744782543e-05, Final Batch Loss: 4.285247086954769e-06\n",
      "Epoch 3535, Loss: 2.6923856353278097e-06, Final Batch Loss: 6.712678555231832e-07\n",
      "Epoch 3536, Loss: 0.00025870223362289835, Final Batch Loss: 2.404673614364583e-05\n",
      "Epoch 3537, Loss: 0.00024023472997214412, Final Batch Loss: 0.00022682426788378507\n",
      "Epoch 3538, Loss: 3.8684860555804335e-05, Final Batch Loss: 3.525959618855268e-05\n",
      "Epoch 3539, Loss: 0.0011573851970752003, Final Batch Loss: 1.7352069335174747e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3540, Loss: 3.7267857123879367e-05, Final Batch Loss: 3.375723827048205e-05\n",
      "Epoch 3541, Loss: 0.0056642884883331135, Final Batch Loss: 0.005633602384477854\n",
      "Epoch 3542, Loss: 7.923265548015479e-05, Final Batch Loss: 5.699391840607859e-05\n",
      "Epoch 3543, Loss: 0.0018571301446854704, Final Batch Loss: 9.224135055774241e-07\n",
      "Epoch 3544, Loss: 0.00030895816462361836, Final Batch Loss: 0.0003067033539991826\n",
      "Epoch 3545, Loss: 0.00012299837908358313, Final Batch Loss: 4.460901618585922e-05\n",
      "Epoch 3546, Loss: 0.0024079150871330057, Final Batch Loss: 2.146826773241628e-06\n",
      "Epoch 3547, Loss: 4.8178384531638585e-05, Final Batch Loss: 4.7240664571290836e-06\n",
      "Epoch 3548, Loss: 0.0003708722781539109, Final Batch Loss: 0.00036790614831261337\n",
      "Epoch 3549, Loss: 0.00018386107603873825, Final Batch Loss: 6.408444278349634e-06\n",
      "Epoch 3550, Loss: 8.011343379621394e-05, Final Batch Loss: 1.7962080164579675e-05\n",
      "Epoch 3551, Loss: 7.910417298262473e-05, Final Batch Loss: 5.590006185229868e-05\n",
      "Epoch 3552, Loss: 0.0014658255968242884, Final Batch Loss: 0.0003766894806176424\n",
      "Epoch 3553, Loss: 8.190088948367702e-06, Final Batch Loss: 3.5068117654191155e-07\n",
      "Epoch 3554, Loss: 0.0009859271399932368, Final Batch Loss: 7.580552505714877e-07\n",
      "Epoch 3555, Loss: 8.526731107849628e-05, Final Batch Loss: 3.2104828278534114e-05\n",
      "Epoch 3556, Loss: 0.00048084250011015683, Final Batch Loss: 0.00031873927218839526\n",
      "Epoch 3557, Loss: 8.08993136161007e-05, Final Batch Loss: 1.8835096852853894e-05\n",
      "Epoch 3558, Loss: 1.7961849039238587e-05, Final Batch Loss: 1.6398970501541044e-06\n",
      "Epoch 3559, Loss: 0.0006053264696674887, Final Batch Loss: 4.600597094395198e-05\n",
      "Epoch 3560, Loss: 0.0012508292084021377, Final Batch Loss: 7.124744115571957e-06\n",
      "Epoch 3561, Loss: 0.00022333086235448718, Final Batch Loss: 3.5676988773047924e-05\n",
      "Epoch 3562, Loss: 8.471272781207517e-05, Final Batch Loss: 2.5784804620343493e-06\n",
      "Epoch 3563, Loss: 5.1504730436136015e-05, Final Batch Loss: 4.0945054934127256e-05\n",
      "Epoch 3564, Loss: 4.620024924406607e-05, Final Batch Loss: 4.546593481791206e-05\n",
      "Epoch 3565, Loss: 2.556366825956502e-05, Final Batch Loss: 1.958061875484418e-05\n",
      "Epoch 3566, Loss: 7.537302917626221e-05, Final Batch Loss: 2.6262803658028133e-05\n",
      "Epoch 3567, Loss: 0.00043183461639273446, Final Batch Loss: 0.00042591121746227145\n",
      "Epoch 3568, Loss: 4.3463179281388875e-05, Final Batch Loss: 3.753768760361709e-05\n",
      "Epoch 3569, Loss: 1.2964108634605509e-05, Final Batch Loss: 6.620077215302445e-07\n",
      "Epoch 3570, Loss: 2.4704582983758883e-06, Final Batch Loss: 6.133968781796284e-07\n",
      "Epoch 3571, Loss: 2.235257488791831e-05, Final Batch Loss: 5.745569069404155e-06\n",
      "Epoch 3572, Loss: 0.0008237767376613192, Final Batch Loss: 1.2290890936128562e-06\n",
      "Epoch 3573, Loss: 0.00010566188666416565, Final Batch Loss: 9.42551650950918e-06\n",
      "Epoch 3574, Loss: 7.449601753251045e-06, Final Batch Loss: 1.408460093443864e-06\n",
      "Epoch 3575, Loss: 2.224200434852719e-05, Final Batch Loss: 2.1179803866289149e-07\n",
      "Epoch 3576, Loss: 6.157606225087875e-05, Final Batch Loss: 4.907237212137261e-07\n",
      "Epoch 3577, Loss: 0.00021602885863103438, Final Batch Loss: 0.00018914302927441895\n",
      "Epoch 3578, Loss: 5.5088762564992066e-05, Final Batch Loss: 3.782798557949718e-06\n",
      "Epoch 3579, Loss: 5.632081820294843e-05, Final Batch Loss: 1.0971693882311229e-06\n",
      "Epoch 3580, Loss: 0.0005821927616125322, Final Batch Loss: 2.1050500436103903e-06\n",
      "Epoch 3581, Loss: 4.923026608594228e-06, Final Batch Loss: 2.6988655008608475e-06\n",
      "Epoch 3582, Loss: 1.4654035908279184e-05, Final Batch Loss: 1.0416023314974154e-06\n",
      "Epoch 3583, Loss: 1.0649568935150455e-05, Final Batch Loss: 9.991070328396745e-06\n",
      "Epoch 3584, Loss: 5.1048293244093657e-05, Final Batch Loss: 5.8384503063280135e-06\n",
      "Epoch 3585, Loss: 0.0006897505227243528, Final Batch Loss: 5.50033146282658e-05\n",
      "Epoch 3586, Loss: 0.00119567532237852, Final Batch Loss: 0.0011609694920480251\n",
      "Epoch 3587, Loss: 0.002078780164310956, Final Batch Loss: 6.018256044626469e-07\n",
      "Epoch 3588, Loss: 0.00016614256310276687, Final Batch Loss: 9.946203499566764e-05\n",
      "Epoch 3589, Loss: 1.8344894670008216e-05, Final Batch Loss: 1.0276804459863342e-05\n",
      "Epoch 3590, Loss: 0.0028194346668897197, Final Batch Loss: 0.002699212869629264\n",
      "Epoch 3591, Loss: 0.0321364714691299, Final Batch Loss: 0.03208211436867714\n",
      "Epoch 3592, Loss: 1.5413509572681505e-05, Final Batch Loss: 6.147688509372529e-06\n",
      "Epoch 3593, Loss: 8.632937124275486e-06, Final Batch Loss: 3.0784165119257523e-06\n",
      "Epoch 3594, Loss: 7.740922956145369e-05, Final Batch Loss: 1.9750419596675783e-05\n",
      "Epoch 3595, Loss: 0.05361302256403633, Final Batch Loss: 1.0474008149685687e-06\n",
      "Epoch 3596, Loss: 0.006950307338229322, Final Batch Loss: 1.0136681339645293e-05\n",
      "Epoch 3597, Loss: 0.013091500298287428, Final Batch Loss: 8.244448508776259e-06\n",
      "Epoch 3598, Loss: 0.0008219202172767837, Final Batch Loss: 1.4528330211760476e-05\n",
      "Epoch 3599, Loss: 0.00033302776319033, Final Batch Loss: 2.7069554562331177e-05\n",
      "Epoch 3600, Loss: 0.0019789008099451166, Final Batch Loss: 1.6503643109899713e-06\n",
      "Epoch 3601, Loss: 3.576219046408369e-05, Final Batch Loss: 2.3250470349012176e-06\n",
      "Epoch 3602, Loss: 0.0006266998752835207, Final Batch Loss: 8.3195096522104e-05\n",
      "Epoch 3603, Loss: 6.220702016435098e-05, Final Batch Loss: 8.468874511891045e-06\n",
      "Epoch 3604, Loss: 2.7328742362442426e-05, Final Batch Loss: 1.8282402379554696e-05\n",
      "Epoch 3605, Loss: 0.0001641460426071717, Final Batch Loss: 4.750140305986861e-06\n",
      "Epoch 3606, Loss: 0.009598139207810163, Final Batch Loss: 0.0035813585855066776\n",
      "Epoch 3607, Loss: 0.001379283086862415, Final Batch Loss: 0.0006298431544564664\n",
      "Epoch 3608, Loss: 0.000231313915719511, Final Batch Loss: 0.0002030888426816091\n",
      "Epoch 3609, Loss: 0.0010789107182063162, Final Batch Loss: 0.0006975876167416573\n",
      "Epoch 3610, Loss: 0.00043027529272876563, Final Batch Loss: 3.7172135307628196e-06\n",
      "Epoch 3611, Loss: 5.411185657067108e-05, Final Batch Loss: 4.815151623915881e-05\n",
      "Epoch 3612, Loss: 1.6276069629839185e-05, Final Batch Loss: 7.187152846199751e-07\n",
      "Epoch 3613, Loss: 8.65320498633082e-06, Final Batch Loss: 5.3267513067112304e-06\n",
      "Epoch 3614, Loss: 1.1820450254163006e-05, Final Batch Loss: 7.9892570283846e-06\n",
      "Epoch 3615, Loss: 5.435987645796558e-06, Final Batch Loss: 7.754189255138044e-07\n",
      "Epoch 3616, Loss: 0.0024419898982159793, Final Batch Loss: 0.0019923034124076366\n",
      "Epoch 3617, Loss: 6.639894672844093e-05, Final Batch Loss: 3.7899935705354437e-06\n",
      "Epoch 3618, Loss: 0.00022533614264830248, Final Batch Loss: 8.830201295495499e-06\n",
      "Epoch 3619, Loss: 0.0009784930443856865, Final Batch Loss: 0.0009455844992771745\n",
      "Epoch 3620, Loss: 2.5287052949352073e-05, Final Batch Loss: 1.0288629255228443e-06\n",
      "Epoch 3621, Loss: 8.867185783856257e-06, Final Batch Loss: 2.2105712105258135e-07\n",
      "Epoch 3622, Loss: 7.929699495434761e-05, Final Batch Loss: 7.210946205304936e-05\n",
      "Epoch 3623, Loss: 0.00032891320006456226, Final Batch Loss: 0.000281913933577016\n",
      "Epoch 3624, Loss: 0.002291726166731678, Final Batch Loss: 0.002245124662294984\n",
      "Epoch 3625, Loss: 2.5605075279599987e-05, Final Batch Loss: 7.372265827143565e-06\n",
      "Epoch 3626, Loss: 7.465464477718342e-06, Final Batch Loss: 5.271246664051432e-06\n",
      "Epoch 3627, Loss: 0.0012151012961112428, Final Batch Loss: 2.1456107788253576e-06\n",
      "Epoch 3628, Loss: 7.226254820125178e-05, Final Batch Loss: 2.9128997994121164e-05\n",
      "Epoch 3629, Loss: 8.498714919369377e-06, Final Batch Loss: 1.8158656303057796e-06\n",
      "Epoch 3630, Loss: 0.0017320846673101187, Final Batch Loss: 0.0005702471826225519\n",
      "Epoch 3631, Loss: 0.0036353530595079064, Final Batch Loss: 0.0011296890443190932\n",
      "Epoch 3632, Loss: 0.0047506572809652425, Final Batch Loss: 0.004666474182158709\n",
      "Epoch 3633, Loss: 9.113007627092884e-05, Final Batch Loss: 5.0603653107827995e-06\n",
      "Epoch 3634, Loss: 0.00041398526263947133, Final Batch Loss: 1.0335797924199142e-05\n",
      "Epoch 3635, Loss: 0.00019805854935839307, Final Batch Loss: 2.2486765374196693e-06\n",
      "Epoch 3636, Loss: 2.015319250858738e-05, Final Batch Loss: 1.4604022908315528e-05\n",
      "Epoch 3637, Loss: 0.0017926715681824135, Final Batch Loss: 0.0017673817928880453\n",
      "Epoch 3638, Loss: 5.569807899519219e-05, Final Batch Loss: 4.953465031576343e-05\n",
      "Epoch 3639, Loss: 0.0005975472577119945, Final Batch Loss: 1.4421571904676966e-05\n",
      "Epoch 3640, Loss: 8.284680370707065e-05, Final Batch Loss: 2.1696658222936094e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3641, Loss: 4.446522041234857e-05, Final Batch Loss: 1.0149987019758555e-06\n",
      "Epoch 3642, Loss: 0.0004992244257664424, Final Batch Loss: 1.0728156667028088e-05\n",
      "Epoch 3643, Loss: 0.004318912397138774, Final Batch Loss: 0.0037744573783129454\n",
      "Epoch 3644, Loss: 0.00016841639080666937, Final Batch Loss: 0.00014396572078112513\n",
      "Epoch 3645, Loss: 1.841208518271742e-05, Final Batch Loss: 2.5378628834005212e-06\n",
      "Epoch 3646, Loss: 0.0003514047130011022, Final Batch Loss: 6.291858153417706e-05\n",
      "Epoch 3647, Loss: 2.3781800337019376e-05, Final Batch Loss: 1.1271345101704355e-05\n",
      "Epoch 3648, Loss: 0.0005855449708178639, Final Batch Loss: 7.139932131394744e-05\n",
      "Epoch 3649, Loss: 5.753540335717844e-05, Final Batch Loss: 4.709423228632659e-05\n",
      "Epoch 3650, Loss: 9.709968071547337e-05, Final Batch Loss: 8.142233127728105e-05\n",
      "Epoch 3651, Loss: 0.0006326554721454158, Final Batch Loss: 0.00012768486340064555\n",
      "Epoch 3652, Loss: 7.328026913455687e-05, Final Batch Loss: 2.1857820684090257e-05\n",
      "Epoch 3653, Loss: 1.5735181023046607e-05, Final Batch Loss: 7.1097788350016344e-06\n",
      "Epoch 3654, Loss: 6.539507194247562e-05, Final Batch Loss: 1.7161457435577177e-05\n",
      "Epoch 3655, Loss: 7.855401236156467e-05, Final Batch Loss: 3.0320525183924474e-05\n",
      "Epoch 3656, Loss: 0.0001470459565098281, Final Batch Loss: 0.00013501293142326176\n",
      "Epoch 3657, Loss: 0.00019203775980258797, Final Batch Loss: 1.258047518604144e-06\n",
      "Epoch 3658, Loss: 0.0012610160028998507, Final Batch Loss: 2.7501255317474715e-05\n",
      "Epoch 3659, Loss: 0.00029460755763466295, Final Batch Loss: 0.000291500793537125\n",
      "Epoch 3660, Loss: 0.0005141992005519569, Final Batch Loss: 0.00044292109669186175\n",
      "Epoch 3661, Loss: 7.999533136171522e-05, Final Batch Loss: 9.673208296590019e-06\n",
      "Epoch 3662, Loss: 0.0008946470261435024, Final Batch Loss: 5.608882929664105e-06\n",
      "Epoch 3663, Loss: 1.0635245871526422e-05, Final Batch Loss: 2.2058661670598667e-06\n",
      "Epoch 3664, Loss: 0.0002236888831248507, Final Batch Loss: 0.00014006988203618675\n",
      "Epoch 3665, Loss: 0.00036098959026276134, Final Batch Loss: 7.070044375723228e-06\n",
      "Epoch 3666, Loss: 1.6856819684107904e-05, Final Batch Loss: 5.138674623594852e-07\n",
      "Epoch 3667, Loss: 3.1856276336839073e-06, Final Batch Loss: 1.6179652675418765e-06\n",
      "Epoch 3668, Loss: 0.0011604201044974616, Final Batch Loss: 0.0011470022145658731\n",
      "Epoch 3669, Loss: 1.4006302535563009e-05, Final Batch Loss: 7.055323294480331e-06\n",
      "Epoch 3670, Loss: 7.022748468443751e-05, Final Batch Loss: 5.137668995303102e-05\n",
      "Epoch 3671, Loss: 0.00018510650988901034, Final Batch Loss: 7.176510553108528e-05\n",
      "Epoch 3672, Loss: 3.981625923188403e-05, Final Batch Loss: 2.6270961825503036e-05\n",
      "Epoch 3673, Loss: 0.006462546049988305, Final Batch Loss: 0.006452099420130253\n",
      "Epoch 3674, Loss: 0.0016068222921603592, Final Batch Loss: 0.001585259335115552\n",
      "Epoch 3675, Loss: 0.00018561243450676557, Final Batch Loss: 0.00016179702652152628\n",
      "Epoch 3676, Loss: 0.0008431738006038358, Final Batch Loss: 0.0008377424674108624\n",
      "Epoch 3677, Loss: 0.00018708640493514395, Final Batch Loss: 1.6666092506056884e-07\n",
      "Epoch 3678, Loss: 0.0001059016867657192, Final Batch Loss: 5.941525159869343e-05\n",
      "Epoch 3679, Loss: 2.00631975530996e-05, Final Batch Loss: 1.8342900148127228e-05\n",
      "Epoch 3680, Loss: 0.0017743770531524206, Final Batch Loss: 0.0017573477234691381\n",
      "Epoch 3681, Loss: 0.00022215624630916864, Final Batch Loss: 3.607351391110569e-05\n",
      "Epoch 3682, Loss: 4.211964619571518e-05, Final Batch Loss: 2.1757884951512096e-06\n",
      "Epoch 3683, Loss: 0.000312406486045802, Final Batch Loss: 0.000293832941679284\n",
      "Epoch 3684, Loss: 2.4104469048324972e-05, Final Batch Loss: 1.626634730200749e-05\n",
      "Epoch 3685, Loss: 0.00013213981037552003, Final Batch Loss: 1.2507103747338988e-05\n",
      "Epoch 3686, Loss: 0.0019247784111939836, Final Batch Loss: 0.0018876896938309073\n",
      "Epoch 3687, Loss: 0.00022947502475290094, Final Batch Loss: 0.00020640186266973615\n",
      "Epoch 3688, Loss: 4.573153773890226e-05, Final Batch Loss: 4.148629886913113e-05\n",
      "Epoch 3689, Loss: 0.000828758553325315, Final Batch Loss: 0.0008075042860582471\n",
      "Epoch 3690, Loss: 0.00013751363667324767, Final Batch Loss: 5.736294497182826e-06\n",
      "Epoch 3691, Loss: 0.0012793298810720444, Final Batch Loss: 0.0006840304122306406\n",
      "Epoch 3692, Loss: 0.00014366471805260517, Final Batch Loss: 0.00012301988317631185\n",
      "Epoch 3693, Loss: 2.403997905275901e-05, Final Batch Loss: 3.822492089966545e-06\n",
      "Epoch 3694, Loss: 0.007388140307739377, Final Batch Loss: 0.0023094674106687307\n",
      "Epoch 3695, Loss: 0.00030347371193784056, Final Batch Loss: 1.094913295673905e-05\n",
      "Epoch 3696, Loss: 2.035844346437443e-05, Final Batch Loss: 4.282240411157545e-07\n",
      "Epoch 3697, Loss: 0.00024029852647799999, Final Batch Loss: 0.00016318330017384142\n",
      "Epoch 3698, Loss: 2.8545173336169682e-05, Final Batch Loss: 1.1657875802484341e-05\n",
      "Epoch 3699, Loss: 0.0001273759062314639, Final Batch Loss: 0.00011894427007064223\n",
      "Epoch 3700, Loss: 0.0007877518655732274, Final Batch Loss: 0.0003411965153645724\n",
      "Epoch 3701, Loss: 0.00024461753127980046, Final Batch Loss: 1.6674381186021492e-05\n",
      "Epoch 3702, Loss: 4.0189863085515753e-05, Final Batch Loss: 2.962858900446008e-07\n",
      "Epoch 3703, Loss: 3.7835717648704303e-05, Final Batch Loss: 6.092635430832161e-06\n",
      "Epoch 3704, Loss: 8.36613276078424e-06, Final Batch Loss: 2.1931525679974584e-06\n",
      "Epoch 3705, Loss: 3.64482075383421e-05, Final Batch Loss: 2.7191361368750222e-05\n",
      "Epoch 3706, Loss: 0.0023015332908471464, Final Batch Loss: 1.2866504221165087e-05\n",
      "Epoch 3707, Loss: 0.00017679202574072406, Final Batch Loss: 0.0001614057837286964\n",
      "Epoch 3708, Loss: 4.5079549636284355e-05, Final Batch Loss: 6.337756531138439e-06\n",
      "Epoch 3709, Loss: 0.0030770216510518367, Final Batch Loss: 2.1363050564104924e-06\n",
      "Epoch 3710, Loss: 0.0002094018536809017, Final Batch Loss: 1.1138222362205852e-05\n",
      "Epoch 3711, Loss: 6.155077608127613e-05, Final Batch Loss: 1.4357612599269487e-05\n",
      "Epoch 3712, Loss: 1.0280204946866434e-05, Final Batch Loss: 8.274954552689451e-07\n",
      "Epoch 3713, Loss: 9.319411037722602e-05, Final Batch Loss: 6.808254693169147e-05\n",
      "Epoch 3714, Loss: 7.118644680303987e-05, Final Batch Loss: 1.8562695913715288e-06\n",
      "Epoch 3715, Loss: 1.7506185940874275e-05, Final Batch Loss: 8.526257261110004e-06\n",
      "Epoch 3716, Loss: 0.0018172471827710979, Final Batch Loss: 0.001704114256426692\n",
      "Epoch 3717, Loss: 0.001230639709319803, Final Batch Loss: 2.0860183212789707e-05\n",
      "Epoch 3718, Loss: 2.1917525373282842e-05, Final Batch Loss: 9.098986993194558e-06\n",
      "Epoch 3719, Loss: 0.0011342396292093326, Final Batch Loss: 1.4708403796248604e-05\n",
      "Epoch 3720, Loss: 8.485329817631282e-05, Final Batch Loss: 7.16348658897914e-05\n",
      "Epoch 3721, Loss: 0.0012235732247063424, Final Batch Loss: 3.633740925579332e-05\n",
      "Epoch 3722, Loss: 0.00020631461205766755, Final Batch Loss: 7.962543691064639e-07\n",
      "Epoch 3723, Loss: 0.001504661121089157, Final Batch Loss: 4.852378424402559e-06\n",
      "Epoch 3724, Loss: 0.00010581816150079248, Final Batch Loss: 0.00010186858708038926\n",
      "Epoch 3725, Loss: 0.0004540295703918673, Final Batch Loss: 8.191206870833412e-05\n",
      "Epoch 3726, Loss: 8.947349124355242e-05, Final Batch Loss: 1.1052448826376349e-05\n",
      "Epoch 3727, Loss: 0.0007612316035192634, Final Batch Loss: 0.000757751171477139\n",
      "Epoch 3728, Loss: 4.343529690231662e-05, Final Batch Loss: 9.550474715069868e-06\n",
      "Epoch 3729, Loss: 0.0005599798751063645, Final Batch Loss: 0.00014060930698178709\n",
      "Epoch 3730, Loss: 0.00043964497353954357, Final Batch Loss: 3.507484962028684e-06\n",
      "Epoch 3731, Loss: 0.00023138252799981274, Final Batch Loss: 0.00020872557070106268\n",
      "Epoch 3732, Loss: 0.0004278678907212452, Final Batch Loss: 0.0004187897138763219\n",
      "Epoch 3733, Loss: 2.4223315904237097e-05, Final Batch Loss: 3.838769316644175e-06\n",
      "Epoch 3734, Loss: 0.00035122180270263925, Final Batch Loss: 0.00025852699764072895\n",
      "Epoch 3735, Loss: 0.0009032167960185689, Final Batch Loss: 1.8181978020948009e-06\n",
      "Epoch 3736, Loss: 5.3575973652186804e-05, Final Batch Loss: 2.832286736520473e-05\n",
      "Epoch 3737, Loss: 1.0110111475114536e-05, Final Batch Loss: 1.7579551467861165e-06\n",
      "Epoch 3738, Loss: 5.703206852558651e-06, Final Batch Loss: 7.661585641471902e-07\n",
      "Epoch 3739, Loss: 0.0006908281279720541, Final Batch Loss: 1.5126347534533124e-06\n",
      "Epoch 3740, Loss: 2.3500238967244513e-05, Final Batch Loss: 5.0526268751127645e-06\n",
      "Epoch 3741, Loss: 2.780694785542437e-05, Final Batch Loss: 5.79732704864e-06\n",
      "Epoch 3742, Loss: 0.00015539103878836613, Final Batch Loss: 8.027256626519375e-06\n",
      "Epoch 3743, Loss: 0.00039634567610846716, Final Batch Loss: 6.262874649110017e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3744, Loss: 8.953094220487401e-05, Final Batch Loss: 5.6220531405415386e-05\n",
      "Epoch 3745, Loss: 0.0006528321960104222, Final Batch Loss: 2.947678240161622e-06\n",
      "Epoch 3746, Loss: 0.0006375934029279051, Final Batch Loss: 0.0006367131718434393\n",
      "Epoch 3747, Loss: 0.00017015546563925454, Final Batch Loss: 8.288939170597587e-06\n",
      "Epoch 3748, Loss: 0.0008556724569643848, Final Batch Loss: 2.3825552489142865e-05\n",
      "Epoch 3749, Loss: 0.0002798645946313627, Final Batch Loss: 6.205881800269708e-05\n",
      "Epoch 3750, Loss: 9.523659718979616e-05, Final Batch Loss: 9.853147275862284e-06\n",
      "Epoch 3751, Loss: 0.00022912682106834836, Final Batch Loss: 0.00016847382357809693\n",
      "Epoch 3752, Loss: 8.545867785869632e-06, Final Batch Loss: 4.723784513771534e-06\n",
      "Epoch 3753, Loss: 2.0794394913536962e-05, Final Batch Loss: 5.175140358915087e-06\n",
      "Epoch 3754, Loss: 5.3639556682583134e-05, Final Batch Loss: 2.6850855761040293e-07\n",
      "Epoch 3755, Loss: 3.645370452431962e-05, Final Batch Loss: 1.7250444216188043e-05\n",
      "Epoch 3756, Loss: 0.0011450123158027736, Final Batch Loss: 1.6087430765310273e-07\n",
      "Epoch 3757, Loss: 0.0020073698199780665, Final Batch Loss: 8.795707913122897e-07\n",
      "Epoch 3758, Loss: 0.004998912118026055, Final Batch Loss: 9.751740435604006e-05\n",
      "Epoch 3759, Loss: 0.002504373522242531, Final Batch Loss: 0.002162735676392913\n",
      "Epoch 3760, Loss: 0.00020222675084369257, Final Batch Loss: 0.00010562506940914318\n",
      "Epoch 3761, Loss: 0.0003346655457789893, Final Batch Loss: 1.2671301192312967e-05\n",
      "Epoch 3762, Loss: 0.0002064098111986823, Final Batch Loss: 2.2717899810231756e-06\n",
      "Epoch 3763, Loss: 0.003486487941700034, Final Batch Loss: 2.450069587212056e-05\n",
      "Epoch 3764, Loss: 2.1450955841828545e-05, Final Batch Loss: 1.4108094319453812e-06\n",
      "Epoch 3765, Loss: 5.801989175324707e-06, Final Batch Loss: 1.5508754813708947e-07\n",
      "Epoch 3766, Loss: 4.0359916965826415e-05, Final Batch Loss: 2.5477915187366307e-05\n",
      "Epoch 3767, Loss: 2.4387563826167025e-05, Final Batch Loss: 8.936427548178472e-06\n",
      "Epoch 3768, Loss: 0.00010829458551597781, Final Batch Loss: 8.081599662546068e-05\n",
      "Epoch 3769, Loss: 0.0002687629767024191, Final Batch Loss: 3.004973586939741e-05\n",
      "Epoch 3770, Loss: 0.0033250784035772085, Final Batch Loss: 0.0021595056168735027\n",
      "Epoch 3771, Loss: 7.204482517408906e-05, Final Batch Loss: 9.177437277685385e-06\n",
      "Epoch 3772, Loss: 7.231491508719046e-05, Final Batch Loss: 5.8022855228045955e-05\n",
      "Epoch 3773, Loss: 6.4578771343803965e-06, Final Batch Loss: 4.375245225674007e-06\n",
      "Epoch 3774, Loss: 0.0009460591827519238, Final Batch Loss: 0.00020980136469006538\n",
      "Epoch 3775, Loss: 0.00015103821715456434, Final Batch Loss: 7.752580131636932e-06\n",
      "Epoch 3776, Loss: 0.00025512790111292816, Final Batch Loss: 2.5346329834974313e-07\n",
      "Epoch 3777, Loss: 2.7977633180853445e-05, Final Batch Loss: 1.8826376617653295e-05\n",
      "Epoch 3778, Loss: 0.001219262121594511, Final Batch Loss: 0.0011468363227322698\n",
      "Epoch 3779, Loss: 4.216548293811684e-05, Final Batch Loss: 3.1364359642793715e-07\n",
      "Epoch 3780, Loss: 1.4236817605706165e-05, Final Batch Loss: 3.867691248160554e-06\n",
      "Epoch 3781, Loss: 0.00415847143085557, Final Batch Loss: 0.004101884085685015\n",
      "Epoch 3782, Loss: 7.631359949300531e-05, Final Batch Loss: 2.2584603357245214e-05\n",
      "Epoch 3783, Loss: 6.949289127078373e-05, Final Batch Loss: 1.8169286704505794e-05\n",
      "Epoch 3784, Loss: 2.5988774723373353e-05, Final Batch Loss: 1.3482541362463962e-05\n",
      "Epoch 3785, Loss: 1.2054418220941443e-05, Final Batch Loss: 7.3143301051459275e-06\n",
      "Epoch 3786, Loss: 0.0003527321750880219, Final Batch Loss: 0.000287125090835616\n",
      "Epoch 3787, Loss: 0.0029074967987980926, Final Batch Loss: 8.899174645193852e-06\n",
      "Epoch 3788, Loss: 0.0002184802776810102, Final Batch Loss: 3.0438764042628463e-07\n",
      "Epoch 3789, Loss: 0.0010098108763685332, Final Batch Loss: 5.208168829540227e-08\n",
      "Epoch 3790, Loss: 1.929220479723881e-05, Final Batch Loss: 5.151576715434203e-06\n",
      "Epoch 3791, Loss: 1.3600136597347046e-05, Final Batch Loss: 2.0601085282123677e-07\n",
      "Epoch 3792, Loss: 0.0007798759095294372, Final Batch Loss: 0.0007766893249936402\n",
      "Epoch 3793, Loss: 0.0013629210272938508, Final Batch Loss: 0.0013602494727820158\n",
      "Epoch 3794, Loss: 0.0008741449810258928, Final Batch Loss: 0.0008631142554804683\n",
      "Epoch 3795, Loss: 0.0005432628895505331, Final Batch Loss: 0.00011542764696059749\n",
      "Epoch 3796, Loss: 0.00010339130130887497, Final Batch Loss: 7.676891254959628e-05\n",
      "Epoch 3797, Loss: 4.8161645736399805e-05, Final Batch Loss: 6.594918431801489e-06\n",
      "Epoch 3798, Loss: 1.6823595387904788e-06, Final Batch Loss: 4.884046802544617e-07\n",
      "Epoch 3799, Loss: 6.444888185797026e-05, Final Batch Loss: 4.942738996760454e-06\n",
      "Epoch 3800, Loss: 7.531278129135899e-06, Final Batch Loss: 6.281527930696029e-06\n",
      "Epoch 3801, Loss: 0.0009888025815598667, Final Batch Loss: 0.00012109574163332582\n",
      "Epoch 3802, Loss: 6.94181874791866e-05, Final Batch Loss: 3.634125391727139e-07\n",
      "Epoch 3803, Loss: 0.0029679109720746055, Final Batch Loss: 2.4062013835646212e-05\n",
      "Epoch 3804, Loss: 0.00022452045595855452, Final Batch Loss: 0.00021921707957517356\n",
      "Epoch 3805, Loss: 2.2813045006842003e-05, Final Batch Loss: 9.594298262527445e-07\n",
      "Epoch 3806, Loss: 0.0005831134085383383, Final Batch Loss: 4.184611498203594e-06\n",
      "Epoch 3807, Loss: 0.0015869556290226683, Final Batch Loss: 1.010374830912042e-06\n",
      "Epoch 3808, Loss: 2.0975141410417564e-06, Final Batch Loss: 1.2464158771763323e-06\n",
      "Epoch 3809, Loss: 0.0003261278761783615, Final Batch Loss: 0.0001438078616047278\n",
      "Epoch 3810, Loss: 8.072313357843086e-05, Final Batch Loss: 3.20296676363796e-05\n",
      "Epoch 3811, Loss: 0.00020888560538878664, Final Batch Loss: 4.073787567904219e-05\n",
      "Epoch 3812, Loss: 0.00012283270098123467, Final Batch Loss: 1.4142299733066466e-05\n",
      "Epoch 3813, Loss: 1.3746787772106472e-05, Final Batch Loss: 1.213191444549011e-05\n",
      "Epoch 3814, Loss: 1.6259090216408367e-05, Final Batch Loss: 1.3676623893843498e-05\n",
      "Epoch 3815, Loss: 0.0002509268974790757, Final Batch Loss: 0.0002447939186822623\n",
      "Epoch 3816, Loss: 1.3403874618234113e-05, Final Batch Loss: 4.75388969789492e-06\n",
      "Epoch 3817, Loss: 3.396004558453569e-05, Final Batch Loss: 2.5162995370919816e-05\n",
      "Epoch 3818, Loss: 0.00021462240005121203, Final Batch Loss: 8.367500754502544e-07\n",
      "Epoch 3819, Loss: 2.477971656844602e-05, Final Batch Loss: 1.8538772565079853e-05\n",
      "Epoch 3820, Loss: 5.756893733632751e-05, Final Batch Loss: 4.924432869302109e-05\n",
      "Epoch 3821, Loss: 2.7157504518982023e-05, Final Batch Loss: 8.272567356470972e-06\n",
      "Epoch 3822, Loss: 0.0002459005456785235, Final Batch Loss: 1.7730465060594724e-06\n",
      "Epoch 3823, Loss: 0.08765267256740117, Final Batch Loss: 0.08764868229627609\n",
      "Epoch 3824, Loss: 0.0001261590987269301, Final Batch Loss: 2.2087766410550103e-05\n",
      "Epoch 3825, Loss: 1.8425968562496564e-05, Final Batch Loss: 7.083060040713463e-07\n",
      "Epoch 3826, Loss: 5.033476190874353e-05, Final Batch Loss: 2.774704080366064e-05\n",
      "Epoch 3827, Loss: 1.5011682734211718e-05, Final Batch Loss: 3.2753425216469623e-07\n",
      "Epoch 3828, Loss: 5.348862941900734e-05, Final Batch Loss: 2.2166577764437534e-05\n",
      "Epoch 3829, Loss: 0.0003270711185905384, Final Batch Loss: 0.00029892451129853725\n",
      "Epoch 3830, Loss: 0.0019183555850759149, Final Batch Loss: 0.0001682913862168789\n",
      "Epoch 3831, Loss: 0.0020441888100322103, Final Batch Loss: 2.360922735533677e-06\n",
      "Epoch 3832, Loss: 0.0011323696162435226, Final Batch Loss: 0.0010380649473518133\n",
      "Epoch 3833, Loss: 0.0002542521235682216, Final Batch Loss: 2.0889985989924753e-06\n",
      "Epoch 3834, Loss: 0.0005233256761130178, Final Batch Loss: 2.8887097869301215e-06\n",
      "Epoch 3835, Loss: 0.00018842014105757698, Final Batch Loss: 7.287744665518403e-05\n",
      "Epoch 3836, Loss: 0.0009220666215696838, Final Batch Loss: 0.000910310773178935\n",
      "Epoch 3837, Loss: 0.003974388746428303, Final Batch Loss: 0.0037400100845843554\n",
      "Epoch 3838, Loss: 4.5090173443895765e-05, Final Batch Loss: 1.4169980204314925e-05\n",
      "Epoch 3839, Loss: 0.0022368904392351396, Final Batch Loss: 0.0021591356489807367\n",
      "Epoch 3840, Loss: 0.0001618088899704162, Final Batch Loss: 0.00011105064186267555\n",
      "Epoch 3841, Loss: 0.00019332755618961528, Final Batch Loss: 0.00015732260362710804\n",
      "Epoch 3842, Loss: 0.0001211407252412755, Final Batch Loss: 1.366318974760361e-05\n",
      "Epoch 3843, Loss: 0.0006104524654801935, Final Batch Loss: 0.00028598227072507143\n",
      "Epoch 3844, Loss: 6.602110443054698e-05, Final Batch Loss: 5.620536830974743e-05\n",
      "Epoch 3845, Loss: 0.00010749825469247298, Final Batch Loss: 3.742429726116825e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3846, Loss: 0.0003764600805880036, Final Batch Loss: 2.162044620490633e-05\n",
      "Epoch 3847, Loss: 0.00011166021249664482, Final Batch Loss: 8.61471489770338e-05\n",
      "Epoch 3848, Loss: 0.00015176858505583368, Final Batch Loss: 3.421595829422586e-05\n",
      "Epoch 3849, Loss: 0.00022670001635560766, Final Batch Loss: 6.157017924124375e-05\n",
      "Epoch 3850, Loss: 0.00033030426857294515, Final Batch Loss: 0.0002113815862685442\n",
      "Epoch 3851, Loss: 0.00011716446351783816, Final Batch Loss: 2.621387284307275e-05\n",
      "Epoch 3852, Loss: 0.0002365170785196824, Final Batch Loss: 0.00020851132285315543\n",
      "Epoch 3853, Loss: 0.00026388050173409283, Final Batch Loss: 0.0001917714689625427\n",
      "Epoch 3854, Loss: 9.524886081635486e-05, Final Batch Loss: 1.85652152140392e-05\n",
      "Epoch 3855, Loss: 0.00026715467538451776, Final Batch Loss: 0.00023597324616275728\n",
      "Epoch 3856, Loss: 0.0003742040498764254, Final Batch Loss: 7.065325189614668e-05\n",
      "Epoch 3857, Loss: 0.00019776689714490203, Final Batch Loss: 4.403477760206442e-06\n",
      "Epoch 3858, Loss: 0.0005889858293812722, Final Batch Loss: 0.0002474676293786615\n",
      "Epoch 3859, Loss: 0.0004064760869368911, Final Batch Loss: 0.0002076765667879954\n",
      "Epoch 3860, Loss: 1.0491809916857164e-05, Final Batch Loss: 2.8527865651994944e-06\n",
      "Epoch 3861, Loss: 0.00026802190575381246, Final Batch Loss: 0.00026646899641491473\n",
      "Epoch 3862, Loss: 2.014032543229405e-05, Final Batch Loss: 7.780417035974097e-06\n",
      "Epoch 3863, Loss: 0.00011623203317867592, Final Batch Loss: 2.548964403104037e-05\n",
      "Epoch 3864, Loss: 0.0006569487131855567, Final Batch Loss: 0.0006491816020570695\n",
      "Epoch 3865, Loss: 2.517209850338986e-05, Final Batch Loss: 2.6259685910190456e-06\n",
      "Epoch 3866, Loss: 0.0006963172763789771, Final Batch Loss: 2.6351406631874852e-05\n",
      "Epoch 3867, Loss: 0.0016600419985479675, Final Batch Loss: 0.0016441195039078593\n",
      "Epoch 3868, Loss: 9.164284347207285e-05, Final Batch Loss: 4.8535446694586426e-05\n",
      "Epoch 3869, Loss: 0.0003187801667081658, Final Batch Loss: 2.9055492632323876e-05\n",
      "Epoch 3870, Loss: 5.768740993516985e-05, Final Batch Loss: 5.133517333888449e-05\n",
      "Epoch 3871, Loss: 0.00011601995720411651, Final Batch Loss: 7.50743129174225e-05\n",
      "Epoch 3872, Loss: 0.00015294982222258113, Final Batch Loss: 9.738995140651241e-05\n",
      "Epoch 3873, Loss: 0.00026361114578321576, Final Batch Loss: 0.00018761592218652368\n",
      "Epoch 3874, Loss: 0.003787900488532614, Final Batch Loss: 7.733789243502542e-05\n",
      "Epoch 3875, Loss: 5.3623397207047674e-05, Final Batch Loss: 2.9338195872696815e-06\n",
      "Epoch 3876, Loss: 8.19814658825635e-06, Final Batch Loss: 2.1514797481358983e-06\n",
      "Epoch 3877, Loss: 1.5637928754586028e-05, Final Batch Loss: 5.374388365453342e-06\n",
      "Epoch 3878, Loss: 9.992548802983947e-05, Final Batch Loss: 5.6016673624981195e-05\n",
      "Epoch 3879, Loss: 0.004543336515780538, Final Batch Loss: 0.004259501583874226\n",
      "Epoch 3880, Loss: 0.0021453130757436156, Final Batch Loss: 0.0010538502829149365\n",
      "Epoch 3881, Loss: 8.462960749966442e-06, Final Batch Loss: 5.844647148478543e-07\n",
      "Epoch 3882, Loss: 0.000585081487770367, Final Batch Loss: 2.5922445274773054e-06\n",
      "Epoch 3883, Loss: 0.00019597180653363466, Final Batch Loss: 2.362167288083583e-05\n",
      "Epoch 3884, Loss: 2.6705160507844994e-05, Final Batch Loss: 2.1757807189715095e-05\n",
      "Epoch 3885, Loss: 1.692576506684418e-05, Final Batch Loss: 4.499207079788903e-06\n",
      "Epoch 3886, Loss: 9.17059114726726e-05, Final Batch Loss: 3.4477361623430625e-05\n",
      "Epoch 3887, Loss: 0.00011151388389407657, Final Batch Loss: 8.283176430268213e-05\n",
      "Epoch 3888, Loss: 0.0013515141527022934, Final Batch Loss: 2.1612640921375714e-05\n",
      "Epoch 3889, Loss: 0.0014921867104931152, Final Batch Loss: 7.017194548097905e-06\n",
      "Epoch 3890, Loss: 8.228798287746031e-05, Final Batch Loss: 7.203008135547861e-05\n",
      "Epoch 3891, Loss: 4.7146982524282066e-05, Final Batch Loss: 6.498019047285197e-06\n",
      "Epoch 3892, Loss: 0.001428687850420829, Final Batch Loss: 7.365378405665979e-05\n",
      "Epoch 3893, Loss: 0.00385569037462119, Final Batch Loss: 0.0036304446402937174\n",
      "Epoch 3894, Loss: 4.273251897757291e-05, Final Batch Loss: 5.962688646832248e-06\n",
      "Epoch 3895, Loss: 0.00018835020000551594, Final Batch Loss: 0.00017837049381341785\n",
      "Epoch 3896, Loss: 5.0136714435211616e-05, Final Batch Loss: 5.535840045922669e-06\n",
      "Epoch 3897, Loss: 0.00012164073689291399, Final Batch Loss: 1.1596681588343927e-06\n",
      "Epoch 3898, Loss: 4.998696277880299e-05, Final Batch Loss: 7.997358011380129e-07\n",
      "Epoch 3899, Loss: 0.0010198653471888974, Final Batch Loss: 8.85228073457256e-05\n",
      "Epoch 3900, Loss: 0.0021337681726549818, Final Batch Loss: 5.346999500943639e-07\n",
      "Epoch 3901, Loss: 0.00011585391803237144, Final Batch Loss: 0.00010585124982753769\n",
      "Epoch 3902, Loss: 0.00019556060578906909, Final Batch Loss: 0.00011998879926977679\n",
      "Epoch 3903, Loss: 6.341215521388222e-05, Final Batch Loss: 4.0633694879943505e-05\n",
      "Epoch 3904, Loss: 4.189995053138773e-06, Final Batch Loss: 1.759197232331644e-07\n",
      "Epoch 3905, Loss: 0.0005803715813499366, Final Batch Loss: 9.004053254102473e-07\n",
      "Epoch 3906, Loss: 0.00023551810954813845, Final Batch Loss: 1.5649628039682284e-05\n",
      "Epoch 3907, Loss: 0.000141106345836306, Final Batch Loss: 4.769815859617665e-06\n",
      "Epoch 3908, Loss: 3.820046428515411e-05, Final Batch Loss: 3.124902647755334e-08\n",
      "Epoch 3909, Loss: 1.7813257727539167e-05, Final Batch Loss: 1.5055647963890806e-05\n",
      "Epoch 3910, Loss: 0.002054947366559645, Final Batch Loss: 0.0020016715861856937\n",
      "Epoch 3911, Loss: 0.0015312558989535319, Final Batch Loss: 1.8713066310738213e-05\n",
      "Epoch 3912, Loss: 0.000998686475213617, Final Batch Loss: 0.00034429802326485515\n",
      "Epoch 3913, Loss: 2.7097896236227825e-05, Final Batch Loss: 4.283974703866988e-06\n",
      "Epoch 3914, Loss: 0.00035345311334822327, Final Batch Loss: 0.00013132495223544538\n",
      "Epoch 3915, Loss: 0.0012549959647003561, Final Batch Loss: 0.0003686271084006876\n",
      "Epoch 3916, Loss: 0.0004239744012011215, Final Batch Loss: 0.0003015529946424067\n",
      "Epoch 3917, Loss: 5.9638299489961355e-06, Final Batch Loss: 1.7972687373912777e-06\n",
      "Epoch 3918, Loss: 0.00016047314238676336, Final Batch Loss: 1.9561824956326745e-05\n",
      "Epoch 3919, Loss: 3.264226006649551e-05, Final Batch Loss: 5.7195125009457115e-06\n",
      "Epoch 3920, Loss: 0.002260095123347128, Final Batch Loss: 0.0022183505352586508\n",
      "Epoch 3921, Loss: 2.177359323241035e-05, Final Batch Loss: 2.0844268874498084e-05\n",
      "Epoch 3922, Loss: 0.0024752881004133087, Final Batch Loss: 2.786619461403461e-06\n",
      "Epoch 3923, Loss: 0.00016924663350437186, Final Batch Loss: 6.810210379626369e-06\n",
      "Epoch 3924, Loss: 1.90293944797304e-05, Final Batch Loss: 6.539575679198606e-06\n",
      "Epoch 3925, Loss: 0.0001282087996514747, Final Batch Loss: 1.5208586773951538e-05\n",
      "Epoch 3926, Loss: 8.419702908213367e-06, Final Batch Loss: 5.234641321294475e-06\n",
      "Epoch 3927, Loss: 2.973239088532864e-05, Final Batch Loss: 1.4072988960833754e-06\n",
      "Epoch 3928, Loss: 1.360181818199635e-05, Final Batch Loss: 9.998833775171079e-06\n",
      "Epoch 3929, Loss: 0.0003669466241262853, Final Batch Loss: 0.0002550457138568163\n",
      "Epoch 3930, Loss: 4.28325229222537e-05, Final Batch Loss: 3.311826731078327e-05\n",
      "Epoch 3931, Loss: 0.0031389403593493626, Final Batch Loss: 1.5506098861806095e-05\n",
      "Epoch 3932, Loss: 0.00011759348763007438, Final Batch Loss: 0.00010472114809090272\n",
      "Epoch 3933, Loss: 3.971126801616265e-05, Final Batch Loss: 9.143122383648006e-07\n",
      "Epoch 3934, Loss: 7.46703317417996e-05, Final Batch Loss: 4.798593363375403e-05\n",
      "Epoch 3935, Loss: 0.0008525937573722331, Final Batch Loss: 2.2497970348922536e-06\n",
      "Epoch 3936, Loss: 0.00026285924832336605, Final Batch Loss: 0.00016182377294171602\n",
      "Epoch 3937, Loss: 0.00048295607120962813, Final Batch Loss: 0.0004244302399456501\n",
      "Epoch 3938, Loss: 0.00012900459842057899, Final Batch Loss: 6.748254963895306e-05\n",
      "Epoch 3939, Loss: 6.98558651492931e-05, Final Batch Loss: 3.81132194888778e-05\n",
      "Epoch 3940, Loss: 9.743876262291451e-05, Final Batch Loss: 4.717567662737565e-06\n",
      "Epoch 3941, Loss: 0.00014498141672447673, Final Batch Loss: 6.7254163695906755e-06\n",
      "Epoch 3942, Loss: 0.0018459973798599094, Final Batch Loss: 0.0004864381335210055\n",
      "Epoch 3943, Loss: 0.00010101117186422925, Final Batch Loss: 7.759169966448098e-05\n",
      "Epoch 3944, Loss: 0.002393426198977977, Final Batch Loss: 0.0023271117825061083\n",
      "Epoch 3945, Loss: 0.00013683171709999442, Final Batch Loss: 1.8695733160711825e-05\n",
      "Epoch 3946, Loss: 0.0001355776825846533, Final Batch Loss: 1.6781856970737863e-07\n",
      "Epoch 3947, Loss: 0.002558355176006444, Final Batch Loss: 0.0001033204171108082\n",
      "Epoch 3948, Loss: 0.00019353377865627408, Final Batch Loss: 0.00017094424401875585\n",
      "Epoch 3949, Loss: 5.0314183681621216e-05, Final Batch Loss: 1.057567169482354e-05\n",
      "Epoch 3950, Loss: 0.00011004453028817807, Final Batch Loss: 1.7521966810818412e-06\n",
      "Epoch 3951, Loss: 1.7068347915483173e-05, Final Batch Loss: 1.0986035704263486e-05\n",
      "Epoch 3952, Loss: 0.0008244683373277439, Final Batch Loss: 1.2731072729366133e-07\n",
      "Epoch 3953, Loss: 0.00020441909146029502, Final Batch Loss: 9.536802826914936e-05\n",
      "Epoch 3954, Loss: 0.0028114194137742743, Final Batch Loss: 5.786573456134647e-05\n",
      "Epoch 3955, Loss: 0.00010823177944985218, Final Batch Loss: 9.830597991822287e-05\n",
      "Epoch 3956, Loss: 0.013294344323639962, Final Batch Loss: 2.230073278042255e-06\n",
      "Epoch 3957, Loss: 0.027826747775179683, Final Batch Loss: 0.027808809652924538\n",
      "Epoch 3958, Loss: 2.7220445645070868e-05, Final Batch Loss: 7.354791250691051e-06\n",
      "Epoch 3959, Loss: 0.009319492179201916, Final Batch Loss: 0.009210954420268536\n",
      "Epoch 3960, Loss: 7.957588422868866e-05, Final Batch Loss: 1.0867124728974886e-05\n",
      "Epoch 3961, Loss: 0.0014417846978176385, Final Batch Loss: 0.00015744895790703595\n",
      "Epoch 3962, Loss: 0.00027717152988770977, Final Batch Loss: 0.00025697090313769877\n",
      "Epoch 3963, Loss: 0.00025598117281333543, Final Batch Loss: 1.6947687981883064e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3964, Loss: 0.0003796267119469121, Final Batch Loss: 0.0001686599280219525\n",
      "Epoch 3965, Loss: 0.006033974306774326, Final Batch Loss: 0.00591185363009572\n",
      "Epoch 3966, Loss: 0.000338218203978613, Final Batch Loss: 0.00017288490198552608\n",
      "Epoch 3967, Loss: 6.450033470173366e-05, Final Batch Loss: 2.1305258997017518e-05\n",
      "Epoch 3968, Loss: 0.0017165737590403296, Final Batch Loss: 9.582474740454927e-05\n",
      "Epoch 3969, Loss: 4.4994874770054594e-05, Final Batch Loss: 1.950113073689863e-06\n",
      "Epoch 3970, Loss: 6.080609455239028e-05, Final Batch Loss: 3.341516276123002e-05\n",
      "Epoch 3971, Loss: 0.0036615850731323007, Final Batch Loss: 0.0036072921939194202\n",
      "Epoch 3972, Loss: 0.0010208885360043496, Final Batch Loss: 7.397003355436027e-05\n",
      "Epoch 3973, Loss: 4.734832282338175e-05, Final Batch Loss: 3.1084741749509703e-06\n",
      "Epoch 3974, Loss: 2.665254169187392e-05, Final Batch Loss: 4.9067452891904395e-06\n",
      "Epoch 3975, Loss: 0.002659423726527166, Final Batch Loss: 0.0026520707178860903\n",
      "Epoch 3976, Loss: 0.0009797906163839798, Final Batch Loss: 0.0009739050874486566\n",
      "Epoch 3977, Loss: 0.0002386279847996775, Final Batch Loss: 0.0001913193700602278\n",
      "Epoch 3978, Loss: 8.582883583585499e-05, Final Batch Loss: 7.455101695086341e-06\n",
      "Epoch 3979, Loss: 2.7079560823040083e-05, Final Batch Loss: 9.330975444754586e-06\n",
      "Epoch 3980, Loss: 0.002986988372867927, Final Batch Loss: 0.0027803322300314903\n",
      "Epoch 3981, Loss: 0.0022406159550882876, Final Batch Loss: 0.001519564539194107\n",
      "Epoch 3982, Loss: 0.0002435061587675591, Final Batch Loss: 5.799051905341912e-06\n",
      "Epoch 3983, Loss: 0.0001336856080342841, Final Batch Loss: 5.6888679864641745e-06\n",
      "Epoch 3984, Loss: 0.0007434592153003905, Final Batch Loss: 2.0326584490248933e-05\n",
      "Epoch 3985, Loss: 0.000619943326455541, Final Batch Loss: 0.0005372829036787152\n",
      "Epoch 3986, Loss: 8.867020915204193e-05, Final Batch Loss: 1.129467818827834e-05\n",
      "Epoch 3987, Loss: 0.0001696492718110676, Final Batch Loss: 1.7117154129664414e-06\n",
      "Epoch 3988, Loss: 0.0056249463596032, Final Batch Loss: 9.495917765889317e-06\n",
      "Epoch 3989, Loss: 3.549089046828158e-05, Final Batch Loss: 2.7856719952978892e-06\n",
      "Epoch 3990, Loss: 0.0006028637657209401, Final Batch Loss: 8.460268645649194e-07\n",
      "Epoch 3991, Loss: 0.0010039799817604944, Final Batch Loss: 0.00017714219575282186\n",
      "Epoch 3992, Loss: 4.212526800984051e-05, Final Batch Loss: 1.8238899428979494e-05\n",
      "Epoch 3993, Loss: 0.0007171838951762766, Final Batch Loss: 0.00039559349534101784\n",
      "Epoch 3994, Loss: 5.771449468738865e-05, Final Batch Loss: 3.728046431206167e-05\n",
      "Epoch 3995, Loss: 0.002344751976124826, Final Batch Loss: 0.0023142502177506685\n",
      "Epoch 3996, Loss: 4.913832526654005e-05, Final Batch Loss: 4.198144961264916e-05\n",
      "Epoch 3997, Loss: 5.104904266772792e-05, Final Batch Loss: 1.2522701581474394e-05\n",
      "Epoch 3998, Loss: 0.000690328364726156, Final Batch Loss: 8.351181168109179e-05\n",
      "Epoch 3999, Loss: 0.0007597699568577809, Final Batch Loss: 3.0488792617688887e-05\n",
      "Epoch 4000, Loss: 1.0386661642769468e-05, Final Batch Loss: 7.161678240663605e-06\n",
      "Epoch 4001, Loss: 0.0009117854167470796, Final Batch Loss: 2.585478569017141e-06\n",
      "Epoch 4002, Loss: 0.0003962668270105496, Final Batch Loss: 0.00013567555288318545\n",
      "Epoch 4003, Loss: 7.639287082383817e-05, Final Batch Loss: 2.271882976856432e-06\n",
      "Epoch 4004, Loss: 3.14986200464773e-05, Final Batch Loss: 1.0211636435997207e-05\n",
      "Epoch 4005, Loss: 0.0006825297532486729, Final Batch Loss: 1.7036909412126988e-05\n",
      "Epoch 4006, Loss: 6.140246478025801e-05, Final Batch Loss: 3.9317204937106e-05\n",
      "Epoch 4007, Loss: 0.0038886971306055784, Final Batch Loss: 0.0027974857948720455\n",
      "Epoch 4008, Loss: 0.0002828052110999124, Final Batch Loss: 0.00028064483194611967\n",
      "Epoch 4009, Loss: 2.8186034796817694e-05, Final Batch Loss: 2.261473855469376e-05\n",
      "Epoch 4010, Loss: 0.0009728089062264189, Final Batch Loss: 0.00010098893835674971\n",
      "Epoch 4011, Loss: 8.821835399430711e-05, Final Batch Loss: 1.743917709973175e-05\n",
      "Epoch 4012, Loss: 0.00019850745593430474, Final Batch Loss: 3.0240844353102148e-06\n",
      "Epoch 4013, Loss: 0.000984064744443458, Final Batch Loss: 9.731365025800187e-06\n",
      "Epoch 4014, Loss: 0.00015119918316486292, Final Batch Loss: 0.00011136148532386869\n",
      "Epoch 4015, Loss: 0.0015449528796125378, Final Batch Loss: 0.0015413769287988544\n",
      "Epoch 4016, Loss: 0.001626194774871692, Final Batch Loss: 0.00030850720941089094\n",
      "Epoch 4017, Loss: 0.0006228168494999409, Final Batch Loss: 0.00016392083489336073\n",
      "Epoch 4018, Loss: 8.321084123963374e-05, Final Batch Loss: 7.677105168113485e-05\n",
      "Epoch 4019, Loss: 0.000854364760016324, Final Batch Loss: 2.738494731602259e-05\n",
      "Epoch 4020, Loss: 0.0010253286163788289, Final Batch Loss: 6.300516542978585e-05\n",
      "Epoch 4021, Loss: 0.0005779745770269074, Final Batch Loss: 0.000505765900015831\n",
      "Epoch 4022, Loss: 0.001103043683656324, Final Batch Loss: 1.8528772898207535e-06\n",
      "Epoch 4023, Loss: 6.239331833057804e-05, Final Batch Loss: 1.255560255231103e-05\n",
      "Epoch 4024, Loss: 0.003720169188454747, Final Batch Loss: 0.0017118121031671762\n",
      "Epoch 4025, Loss: 0.00020159618361503817, Final Batch Loss: 0.00017166437464766204\n",
      "Epoch 4026, Loss: 0.005743854641707458, Final Batch Loss: 6.006656008139544e-07\n",
      "Epoch 4027, Loss: 0.0018215278032585047, Final Batch Loss: 8.455450733890757e-05\n",
      "Epoch 4028, Loss: 7.638399074494373e-05, Final Batch Loss: 6.1019913118798286e-05\n",
      "Epoch 4029, Loss: 0.0025403884355910122, Final Batch Loss: 0.002257083309814334\n",
      "Epoch 4030, Loss: 2.9454668947437312e-05, Final Batch Loss: 1.080417223420227e-05\n",
      "Epoch 4031, Loss: 6.107721583248349e-05, Final Batch Loss: 5.727488314732909e-05\n",
      "Epoch 4032, Loss: 0.00047154766480161925, Final Batch Loss: 3.830657533399062e-06\n",
      "Epoch 4033, Loss: 0.001920415103313644, Final Batch Loss: 2.689557959456579e-06\n",
      "Epoch 4034, Loss: 0.0028107495381846093, Final Batch Loss: 0.0027804935816675425\n",
      "Epoch 4035, Loss: 0.000510191050125286, Final Batch Loss: 6.231979932636023e-05\n",
      "Epoch 4036, Loss: 9.153576866083313e-05, Final Batch Loss: 2.7492462322697975e-05\n",
      "Epoch 4037, Loss: 0.003644472802989185, Final Batch Loss: 0.0023528633173555136\n",
      "Epoch 4038, Loss: 0.0012906375923193991, Final Batch Loss: 0.0007599219679832458\n",
      "Epoch 4039, Loss: 6.290954297583085e-05, Final Batch Loss: 8.266930308309384e-06\n",
      "Epoch 4040, Loss: 0.00022554150928044692, Final Batch Loss: 1.885834353743121e-05\n",
      "Epoch 4041, Loss: 0.0007670673876418732, Final Batch Loss: 4.33964523836039e-05\n",
      "Epoch 4042, Loss: 0.00039129458309616894, Final Batch Loss: 0.00019047362729907036\n",
      "Epoch 4043, Loss: 0.0007785922380207921, Final Batch Loss: 8.183345016732346e-06\n",
      "Epoch 4044, Loss: 0.0002581969638413284, Final Batch Loss: 4.7463199734920636e-05\n",
      "Epoch 4045, Loss: 1.5299319230166475e-05, Final Batch Loss: 1.6666071189774812e-07\n",
      "Epoch 4046, Loss: 0.00024309793661814183, Final Batch Loss: 7.851906411815435e-05\n",
      "Epoch 4047, Loss: 0.004307454230001895, Final Batch Loss: 0.004247924778610468\n",
      "Epoch 4048, Loss: 0.0008624452329968335, Final Batch Loss: 1.6079940905910917e-05\n",
      "Epoch 4049, Loss: 0.0010455134288349655, Final Batch Loss: 2.5490528059890494e-05\n",
      "Epoch 4050, Loss: 9.506548656190716e-05, Final Batch Loss: 1.2939125326738576e-06\n",
      "Epoch 4051, Loss: 0.0003278859437614301, Final Batch Loss: 2.964959776363685e-06\n",
      "Epoch 4052, Loss: 3.7180476283538155e-05, Final Batch Loss: 8.768662155489437e-06\n",
      "Epoch 4053, Loss: 0.001467365962525946, Final Batch Loss: 0.0014390188734978437\n",
      "Epoch 4054, Loss: 2.8327374820946716e-05, Final Batch Loss: 9.85896258498542e-06\n",
      "Epoch 4055, Loss: 5.380334914661944e-05, Final Batch Loss: 1.6677669918863103e-05\n",
      "Epoch 4056, Loss: 0.0007450872126355534, Final Batch Loss: 0.0007274400559253991\n",
      "Epoch 4057, Loss: 0.00016781556223577354, Final Batch Loss: 1.0205572834820487e-05\n",
      "Epoch 4058, Loss: 8.878114431354334e-05, Final Batch Loss: 6.667473371635424e-06\n",
      "Epoch 4059, Loss: 0.0001325655580330931, Final Batch Loss: 7.021965302556055e-06\n",
      "Epoch 4060, Loss: 0.00020247447588417344, Final Batch Loss: 6.944225106053636e-08\n",
      "Epoch 4061, Loss: 6.979786667216104e-05, Final Batch Loss: 4.755011104862206e-06\n",
      "Epoch 4062, Loss: 0.0006566298388861469, Final Batch Loss: 0.000647221109829843\n",
      "Epoch 4063, Loss: 3.96525456380914e-06, Final Batch Loss: 1.1145286862301873e-06\n",
      "Epoch 4064, Loss: 0.0001796779797587078, Final Batch Loss: 5.7113411457976326e-05\n",
      "Epoch 4065, Loss: 2.4267307480840827e-05, Final Batch Loss: 1.332062993242289e-06\n",
      "Epoch 4066, Loss: 0.0006825144646427361, Final Batch Loss: 2.1311059754225425e-05\n",
      "Epoch 4067, Loss: 0.0007241964021886815, Final Batch Loss: 0.0007138256332837045\n",
      "Epoch 4068, Loss: 0.00011496217848616652, Final Batch Loss: 1.5726353012723848e-05\n",
      "Epoch 4069, Loss: 3.684681266236112e-05, Final Batch Loss: 1.1805147437371488e-07\n",
      "Epoch 4070, Loss: 0.0006190319454617565, Final Batch Loss: 3.3179439924424514e-06\n",
      "Epoch 4071, Loss: 5.0216345698572695e-05, Final Batch Loss: 1.1241951142437756e-05\n",
      "Epoch 4072, Loss: 5.519775822904194e-05, Final Batch Loss: 4.7245230234693736e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4073, Loss: 4.787704710906837e-05, Final Batch Loss: 2.6215146135655232e-05\n",
      "Epoch 4074, Loss: 0.0017310323673882522, Final Batch Loss: 2.0623534510377795e-05\n",
      "Epoch 4075, Loss: 0.0009307854227245116, Final Batch Loss: 0.0009280505473725498\n",
      "Epoch 4076, Loss: 6.272442624322139e-05, Final Batch Loss: 1.9617986254161224e-05\n",
      "Epoch 4077, Loss: 0.002351385119254701, Final Batch Loss: 0.002317545237019658\n",
      "Epoch 4078, Loss: 0.000753043109398277, Final Batch Loss: 7.3391192927374505e-06\n",
      "Epoch 4079, Loss: 1.7589783965377137e-05, Final Batch Loss: 9.15916734811617e-06\n",
      "Epoch 4080, Loss: 0.001685878423813847, Final Batch Loss: 0.0016634534113109112\n",
      "Epoch 4081, Loss: 9.304881450589164e-05, Final Batch Loss: 4.296559836802771e-06\n",
      "Epoch 4082, Loss: 0.00011092110071331263, Final Batch Loss: 3.0556337151210755e-05\n",
      "Epoch 4083, Loss: 4.72246290428302e-05, Final Batch Loss: 3.526380851326394e-06\n",
      "Epoch 4084, Loss: 0.000826092749775853, Final Batch Loss: 4.0358710975851864e-05\n",
      "Epoch 4085, Loss: 0.00021705137623939663, Final Batch Loss: 0.0001735531259328127\n",
      "Epoch 4086, Loss: 0.0005800916046609927, Final Batch Loss: 1.5404007172037382e-06\n",
      "Epoch 4087, Loss: 6.443668553401949e-05, Final Batch Loss: 5.7285986258648336e-05\n",
      "Epoch 4088, Loss: 0.00011715969230863266, Final Batch Loss: 4.541982707451098e-05\n",
      "Epoch 4089, Loss: 0.00011299822836008389, Final Batch Loss: 1.2652935765800066e-05\n",
      "Epoch 4090, Loss: 8.229365994338877e-05, Final Batch Loss: 4.381097824079916e-06\n",
      "Epoch 4091, Loss: 3.414587081351783e-05, Final Batch Loss: 8.697084922459908e-06\n",
      "Epoch 4092, Loss: 1.7933144135895418e-05, Final Batch Loss: 6.611754997720709e-06\n",
      "Epoch 4093, Loss: 0.0011183987262484152, Final Batch Loss: 1.087585769710131e-05\n",
      "Epoch 4094, Loss: 0.006855427820710247, Final Batch Loss: 0.00685186916962266\n",
      "Epoch 4095, Loss: 0.009718192006403115, Final Batch Loss: 0.00967616867274046\n",
      "Epoch 4096, Loss: 3.629021011875011e-05, Final Batch Loss: 5.444184353109449e-06\n",
      "Epoch 4097, Loss: 0.0031890536192804575, Final Batch Loss: 0.002544532995671034\n",
      "Epoch 4098, Loss: 7.765344435028965e-06, Final Batch Loss: 2.8746717362082563e-06\n",
      "Epoch 4099, Loss: 0.00022105257085058838, Final Batch Loss: 1.803311170078814e-05\n",
      "Epoch 4100, Loss: 1.3596202848020766e-06, Final Batch Loss: 8.599018883614917e-07\n",
      "Epoch 4101, Loss: 3.2154168366105296e-05, Final Batch Loss: 1.4505656508845277e-05\n",
      "Epoch 4102, Loss: 0.0002533125225454569, Final Batch Loss: 0.00019571221491787583\n",
      "Epoch 4103, Loss: 0.0002191201492678374, Final Batch Loss: 1.7400816432200372e-05\n",
      "Epoch 4104, Loss: 6.0502259657368995e-05, Final Batch Loss: 3.2658990676281974e-05\n",
      "Epoch 4105, Loss: 5.407994467532262e-05, Final Batch Loss: 1.0738200217019767e-05\n",
      "Epoch 4106, Loss: 0.0038235075447801137, Final Batch Loss: 1.350618163087347e-06\n",
      "Epoch 4107, Loss: 0.00022868259520691936, Final Batch Loss: 5.147569481778191e-06\n",
      "Epoch 4108, Loss: 0.0017580721578269731, Final Batch Loss: 1.2611253623617813e-05\n",
      "Epoch 4109, Loss: 0.0011972224568808087, Final Batch Loss: 1.1168416449436336e-06\n",
      "Epoch 4110, Loss: 7.763588939724286e-05, Final Batch Loss: 1.7568337398188305e-06\n",
      "Epoch 4111, Loss: 1.3810292983862382e-05, Final Batch Loss: 3.0091516123320616e-07\n",
      "Epoch 4112, Loss: 0.005738665990065783, Final Batch Loss: 0.005191843956708908\n",
      "Epoch 4113, Loss: 1.5110399658624374e-05, Final Batch Loss: 1.8332312947677565e-06\n",
      "Epoch 4114, Loss: 0.0017326102242805064, Final Batch Loss: 0.00020862818928435445\n",
      "Epoch 4115, Loss: 3.1174788091448136e-05, Final Batch Loss: 1.0104648026754148e-05\n",
      "Epoch 4116, Loss: 0.00023021295055514202, Final Batch Loss: 0.0001887225080281496\n",
      "Epoch 4117, Loss: 3.5050488691013015e-05, Final Batch Loss: 3.39643083862029e-05\n",
      "Epoch 4118, Loss: 0.00034845509799197316, Final Batch Loss: 0.00032115611247718334\n",
      "Epoch 4119, Loss: 7.698480294493493e-05, Final Batch Loss: 6.662171654170379e-05\n",
      "Epoch 4120, Loss: 0.0002632425034789776, Final Batch Loss: 5.099007012177026e-06\n",
      "Epoch 4121, Loss: 2.1333528366085375e-05, Final Batch Loss: 7.166823252191534e-06\n",
      "Epoch 4122, Loss: 5.980728747090325e-05, Final Batch Loss: 1.5985482605174184e-05\n",
      "Epoch 4123, Loss: 0.00020999478874728084, Final Batch Loss: 6.434251554310322e-05\n",
      "Epoch 4124, Loss: 0.0005002160735898542, Final Batch Loss: 6.353778303491708e-07\n",
      "Epoch 4125, Loss: 0.03880331840264262, Final Batch Loss: 0.03878457471728325\n",
      "Epoch 4126, Loss: 0.00028300549092818983, Final Batch Loss: 0.0002558162668719888\n",
      "Epoch 4127, Loss: 0.0037550394190475345, Final Batch Loss: 0.002347392262890935\n",
      "Epoch 4128, Loss: 0.027477074399939738, Final Batch Loss: 0.027257759124040604\n",
      "Epoch 4129, Loss: 0.0011523411753842083, Final Batch Loss: 7.332223958655959e-06\n",
      "Epoch 4130, Loss: 0.0012780393299181014, Final Batch Loss: 5.227155634202063e-05\n",
      "Epoch 4131, Loss: 0.0008697598859725986, Final Batch Loss: 3.527134322212078e-05\n",
      "Epoch 4132, Loss: 0.00012675864309130702, Final Batch Loss: 0.00011638194700935856\n",
      "Epoch 4133, Loss: 0.0013815191141475225, Final Batch Loss: 0.0013561664381995797\n",
      "Epoch 4134, Loss: 5.9553058235906065e-05, Final Batch Loss: 8.194110705517232e-07\n",
      "Epoch 4135, Loss: 0.0019890642288373783, Final Batch Loss: 6.161707278806716e-05\n",
      "Epoch 4136, Loss: 1.2810542102670297e-05, Final Batch Loss: 6.441784535127226e-06\n",
      "Epoch 4137, Loss: 9.504492754786042e-05, Final Batch Loss: 1.1907900443475228e-05\n",
      "Epoch 4138, Loss: 0.0005050274384643672, Final Batch Loss: 3.9350283032035804e-07\n",
      "Epoch 4139, Loss: 2.157449853257276e-05, Final Batch Loss: 1.0960175131913275e-06\n",
      "Epoch 4140, Loss: 4.121513666177634e-05, Final Batch Loss: 1.1439506124588661e-05\n",
      "Epoch 4141, Loss: 2.6739311806522892e-05, Final Batch Loss: 2.4532189854653552e-05\n",
      "Epoch 4142, Loss: 0.038822325645014644, Final Batch Loss: 0.038727857172489166\n",
      "Epoch 4143, Loss: 0.0018694631862672395, Final Batch Loss: 6.952263902348932e-06\n",
      "Epoch 4144, Loss: 0.00013407832011580467, Final Batch Loss: 6.458108691731468e-05\n",
      "Epoch 4145, Loss: 0.022578211523068603, Final Batch Loss: 0.02249310538172722\n",
      "Epoch 4146, Loss: 0.003129641780105885, Final Batch Loss: 7.336705311900005e-05\n",
      "Epoch 4147, Loss: 0.00010607290278130677, Final Batch Loss: 2.8985165045014583e-05\n",
      "Epoch 4148, Loss: 6.334305180644151e-05, Final Batch Loss: 2.7948653951170854e-05\n",
      "Epoch 4149, Loss: 0.03353674593381584, Final Batch Loss: 0.0002550769131630659\n",
      "Epoch 4150, Loss: 0.0012335469291429035, Final Batch Loss: 0.0011577242985367775\n",
      "Epoch 4151, Loss: 0.0003645446340669878, Final Batch Loss: 0.000298028695397079\n",
      "Epoch 4152, Loss: 0.00014943209316697903, Final Batch Loss: 3.804912921623327e-05\n",
      "Epoch 4153, Loss: 0.00010554815889918245, Final Batch Loss: 3.861925870296545e-05\n",
      "Epoch 4154, Loss: 0.0013454139116220176, Final Batch Loss: 0.0009255947661586106\n",
      "Epoch 4155, Loss: 0.0017015690900734626, Final Batch Loss: 0.00010514890163904056\n",
      "Epoch 4156, Loss: 0.005453202233184129, Final Batch Loss: 0.0005783320521004498\n",
      "Epoch 4157, Loss: 0.00017984262740355916, Final Batch Loss: 2.0736802980536595e-05\n",
      "Epoch 4158, Loss: 0.00016744359709264245, Final Batch Loss: 2.892096745199524e-06\n",
      "Epoch 4159, Loss: 0.003035653291590279, Final Batch Loss: 2.797451088554226e-05\n",
      "Epoch 4160, Loss: 0.00023965410446180613, Final Batch Loss: 7.353179626079509e-06\n",
      "Epoch 4161, Loss: 6.964785598029266e-05, Final Batch Loss: 7.297868705791188e-06\n",
      "Epoch 4162, Loss: 0.0003320882824482396, Final Batch Loss: 0.0001685373717918992\n",
      "Epoch 4163, Loss: 9.810462142922916e-05, Final Batch Loss: 5.1177961722714826e-05\n",
      "Epoch 4164, Loss: 0.001247106702066958, Final Batch Loss: 0.00037163792876526713\n",
      "Epoch 4165, Loss: 0.00011282939885859378, Final Batch Loss: 4.188241655356251e-05\n",
      "Epoch 4166, Loss: 0.001980745932087302, Final Batch Loss: 6.331840995699167e-05\n",
      "Epoch 4167, Loss: 0.0001079771623153647, Final Batch Loss: 0.00010131546150660142\n",
      "Epoch 4168, Loss: 0.0002138361905963393, Final Batch Loss: 1.997713297896553e-05\n",
      "Epoch 4169, Loss: 0.0006526472861878574, Final Batch Loss: 0.00033255532616749406\n",
      "Epoch 4170, Loss: 0.00020173213124508038, Final Batch Loss: 7.89617988630198e-05\n",
      "Epoch 4171, Loss: 0.0037551348850684008, Final Batch Loss: 0.0037314030341804028\n",
      "Epoch 4172, Loss: 2.8913578717038035e-05, Final Batch Loss: 7.651544365216978e-06\n",
      "Epoch 4173, Loss: 0.00019049335969612002, Final Batch Loss: 0.00010105855471920222\n",
      "Epoch 4174, Loss: 0.0023376158251267043, Final Batch Loss: 1.3968329767521936e-05\n",
      "Epoch 4175, Loss: 0.0007809714952600189, Final Batch Loss: 0.0007064942619763315\n",
      "Epoch 4176, Loss: 0.00020787867680382988, Final Batch Loss: 8.761110734667454e-07\n",
      "Epoch 4177, Loss: 0.001173759956145659, Final Batch Loss: 0.00040544153307564557\n",
      "Epoch 4178, Loss: 8.040509737838875e-05, Final Batch Loss: 7.695749081904069e-05\n",
      "Epoch 4179, Loss: 0.0009347393352072686, Final Batch Loss: 0.0005218875012360513\n",
      "Epoch 4180, Loss: 0.00217183462518733, Final Batch Loss: 0.0020081850234419107\n",
      "Epoch 4181, Loss: 5.81271688133711e-05, Final Batch Loss: 4.273160811862908e-05\n",
      "Epoch 4182, Loss: 0.00011505497423058841, Final Batch Loss: 2.568286618043203e-05\n",
      "Epoch 4183, Loss: 0.0005207829381106421, Final Batch Loss: 0.0001258967531612143\n",
      "Epoch 4184, Loss: 0.0003259878903918434, Final Batch Loss: 2.5092438590945676e-05\n",
      "Epoch 4185, Loss: 0.000620089253061451, Final Batch Loss: 0.00010902418580371886\n",
      "Epoch 4186, Loss: 0.0002246819349238649, Final Batch Loss: 0.00012902116577606648\n",
      "Epoch 4187, Loss: 0.00015016737688711146, Final Batch Loss: 8.662836080475245e-06\n",
      "Epoch 4188, Loss: 0.0012500635639298707, Final Batch Loss: 0.000994655885733664\n",
      "Epoch 4189, Loss: 0.0033121692467830144, Final Batch Loss: 0.0032481439411640167\n",
      "Epoch 4190, Loss: 2.668482125045557e-05, Final Batch Loss: 2.394080365775153e-05\n",
      "Epoch 4191, Loss: 0.0009553289055475034, Final Batch Loss: 5.810199218103662e-05\n",
      "Epoch 4192, Loss: 3.1330124102169066e-05, Final Batch Loss: 2.926811930592521e-06\n",
      "Epoch 4193, Loss: 5.2811555519838294e-05, Final Batch Loss: 1.1561891142264358e-06\n",
      "Epoch 4194, Loss: 0.0004222880443194299, Final Batch Loss: 0.00041326021892018616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4195, Loss: 0.0006627927014051238, Final Batch Loss: 2.8244854547665454e-05\n",
      "Epoch 4196, Loss: 0.00018536492279963568, Final Batch Loss: 0.0001081125155906193\n",
      "Epoch 4197, Loss: 0.000469106700620614, Final Batch Loss: 7.881321653258055e-05\n",
      "Epoch 4198, Loss: 0.0015068799839355052, Final Batch Loss: 5.961180431768298e-05\n",
      "Epoch 4199, Loss: 0.004441193632374052, Final Batch Loss: 0.004408044274896383\n",
      "Epoch 4200, Loss: 0.00010590857709757984, Final Batch Loss: 5.14660932822153e-05\n",
      "Epoch 4201, Loss: 0.00018134941637981683, Final Batch Loss: 0.0001305997429881245\n",
      "Epoch 4202, Loss: 0.00011806162638094975, Final Batch Loss: 1.1286904737062287e-05\n",
      "Epoch 4203, Loss: 0.0001191161572933197, Final Batch Loss: 6.282367394305766e-05\n",
      "Epoch 4204, Loss: 0.0029097165879647946, Final Batch Loss: 1.4657058272860013e-05\n",
      "Epoch 4205, Loss: 0.00011071603512391448, Final Batch Loss: 3.318207018310204e-05\n",
      "Epoch 4206, Loss: 0.00030693912549395463, Final Batch Loss: 0.00030196033185347915\n",
      "Epoch 4207, Loss: 0.0015395033988170326, Final Batch Loss: 0.0012697268975898623\n",
      "Epoch 4208, Loss: 0.0005165594193385914, Final Batch Loss: 0.0001234302035300061\n",
      "Epoch 4209, Loss: 0.0011159324058098719, Final Batch Loss: 0.0010109067661687732\n",
      "Epoch 4210, Loss: 5.890740249014925e-05, Final Batch Loss: 1.3009490430704318e-05\n",
      "Epoch 4211, Loss: 5.16696491104085e-05, Final Batch Loss: 2.918952304753475e-05\n",
      "Epoch 4212, Loss: 3.731596098077716e-05, Final Batch Loss: 1.3802559806208592e-05\n",
      "Epoch 4213, Loss: 0.00032668709127392503, Final Batch Loss: 7.566384283563821e-06\n",
      "Epoch 4214, Loss: 0.00020776838960046007, Final Batch Loss: 2.8990764349146048e-06\n",
      "Epoch 4215, Loss: 6.630645793848089e-05, Final Batch Loss: 6.735515398759162e-06\n",
      "Epoch 4216, Loss: 0.00010941208893200383, Final Batch Loss: 4.325865302234888e-05\n",
      "Epoch 4217, Loss: 0.00019819674344034865, Final Batch Loss: 0.00014553649816662073\n",
      "Epoch 4218, Loss: 0.0020871757660643198, Final Batch Loss: 0.0019961786456406116\n",
      "Epoch 4219, Loss: 0.0009112793995882384, Final Batch Loss: 0.0008288862300105393\n",
      "Epoch 4220, Loss: 0.0008789336807240034, Final Batch Loss: 1.2940357919433154e-05\n",
      "Epoch 4221, Loss: 0.002306817708813469, Final Batch Loss: 0.002285891678184271\n",
      "Epoch 4222, Loss: 0.00011255127174081281, Final Batch Loss: 7.598790398333222e-05\n",
      "Epoch 4223, Loss: 0.00018425470625516027, Final Batch Loss: 0.0001526460109744221\n",
      "Epoch 4224, Loss: 0.00026521470135776326, Final Batch Loss: 0.00016851609689183533\n",
      "Epoch 4225, Loss: 0.0350883225328289, Final Batch Loss: 0.00018387980526313186\n",
      "Epoch 4226, Loss: 0.0012969792260264512, Final Batch Loss: 4.5285294618224725e-05\n",
      "Epoch 4227, Loss: 0.00011646380153251812, Final Batch Loss: 6.900442531332374e-05\n",
      "Epoch 4228, Loss: 0.0006194048328325152, Final Batch Loss: 0.000551458855625242\n",
      "Epoch 4229, Loss: 0.0028435161657398567, Final Batch Loss: 0.002768618753179908\n",
      "Epoch 4230, Loss: 0.00018474659373168834, Final Batch Loss: 5.998915366944857e-05\n",
      "Epoch 4231, Loss: 0.0002550362769397907, Final Batch Loss: 0.00016181854880414903\n",
      "Epoch 4232, Loss: 0.00020610303909052163, Final Batch Loss: 0.00014435974298976362\n",
      "Epoch 4233, Loss: 0.0013277008547447622, Final Batch Loss: 0.00018842279678210616\n",
      "Epoch 4234, Loss: 0.0020024626173835713, Final Batch Loss: 0.0019551506265997887\n",
      "Epoch 4235, Loss: 0.001450581978133414, Final Batch Loss: 5.2923256589565426e-05\n",
      "Epoch 4236, Loss: 0.0006392396171577275, Final Batch Loss: 0.00020163538283668458\n",
      "Epoch 4237, Loss: 0.00020024383411509916, Final Batch Loss: 5.918247188674286e-05\n",
      "Epoch 4238, Loss: 0.00012593930296134204, Final Batch Loss: 3.067206853302196e-05\n",
      "Epoch 4239, Loss: 0.0039322329830611125, Final Batch Loss: 0.003826351137831807\n",
      "Epoch 4240, Loss: 0.002239982830360532, Final Batch Loss: 6.325985305011272e-05\n",
      "Epoch 4241, Loss: 0.0014087275339988992, Final Batch Loss: 0.00012263764801900834\n",
      "Epoch 4242, Loss: 0.002011959149967879, Final Batch Loss: 0.0005255466676317155\n",
      "Epoch 4243, Loss: 0.0001626078737899661, Final Batch Loss: 0.00010817011207109317\n",
      "Epoch 4244, Loss: 0.0005995945102768019, Final Batch Loss: 0.00011928939784411341\n",
      "Epoch 4245, Loss: 0.006321065913653001, Final Batch Loss: 0.006142870523035526\n",
      "Epoch 4246, Loss: 0.000434435140050482, Final Batch Loss: 2.6952933694701642e-05\n",
      "Epoch 4247, Loss: 8.58175803841732e-05, Final Batch Loss: 4.20779133492033e-06\n",
      "Epoch 4248, Loss: 0.0035400803317315876, Final Batch Loss: 0.000527852273080498\n",
      "Epoch 4249, Loss: 0.00026247850473737344, Final Batch Loss: 0.000236366773606278\n",
      "Epoch 4250, Loss: 0.000908403642824851, Final Batch Loss: 0.00012769158638548106\n",
      "Epoch 4251, Loss: 0.00019132589659420773, Final Batch Loss: 3.9137557905633e-05\n",
      "Epoch 4252, Loss: 0.00035317952279001474, Final Batch Loss: 0.00023038493236526847\n",
      "Epoch 4253, Loss: 0.0010589745361357927, Final Batch Loss: 2.5077257305383682e-05\n",
      "Epoch 4254, Loss: 0.00030561717721866444, Final Batch Loss: 7.35264693503268e-05\n",
      "Epoch 4255, Loss: 7.716162508586422e-05, Final Batch Loss: 4.810212703887373e-05\n",
      "Epoch 4256, Loss: 0.0002531419122533407, Final Batch Loss: 0.00021300475054886192\n",
      "Epoch 4257, Loss: 0.023623577202670276, Final Batch Loss: 0.0013597708893939853\n",
      "Epoch 4258, Loss: 0.00010820429793056974, Final Batch Loss: 0.00010483190999366343\n",
      "Epoch 4259, Loss: 9.907310413836967e-05, Final Batch Loss: 1.5561656255158596e-05\n",
      "Epoch 4260, Loss: 0.0011262297116445552, Final Batch Loss: 2.092397608066676e-06\n",
      "Epoch 4261, Loss: 0.0010015484859877688, Final Batch Loss: 1.7626426824790542e-06\n",
      "Epoch 4262, Loss: 0.0002870140742743388, Final Batch Loss: 0.00013311362999957055\n",
      "Epoch 4263, Loss: 0.0010045950330095366, Final Batch Loss: 0.00024222031061071903\n",
      "Epoch 4264, Loss: 8.023862756090239e-05, Final Batch Loss: 4.1174622310791165e-05\n",
      "Epoch 4265, Loss: 0.00017404578466084786, Final Batch Loss: 5.761256397818215e-05\n",
      "Epoch 4266, Loss: 0.0003168080293107778, Final Batch Loss: 0.00017604572349227965\n",
      "Epoch 4267, Loss: 0.0017434830024285475, Final Batch Loss: 0.0017223499016836286\n",
      "Epoch 4268, Loss: 3.4493305065552704e-05, Final Batch Loss: 1.6318284906446934e-05\n",
      "Epoch 4269, Loss: 8.815473108825245e-06, Final Batch Loss: 8.830667752590671e-07\n",
      "Epoch 4270, Loss: 2.87317570837331e-05, Final Batch Loss: 5.9645617511705495e-06\n",
      "Epoch 4271, Loss: 0.00037028687074780464, Final Batch Loss: 0.00026513560442253947\n",
      "Epoch 4272, Loss: 5.4738948165322654e-05, Final Batch Loss: 3.9028949686326087e-05\n",
      "Epoch 4273, Loss: 0.0009119154929067008, Final Batch Loss: 6.503785698441789e-05\n",
      "Epoch 4274, Loss: 0.0011520263615238946, Final Batch Loss: 2.1797732188133523e-05\n",
      "Epoch 4275, Loss: 0.00014898314839228988, Final Batch Loss: 3.450800431892276e-05\n",
      "Epoch 4276, Loss: 0.0013197856897022575, Final Batch Loss: 0.00017416125047020614\n",
      "Epoch 4277, Loss: 0.0014249013474909589, Final Batch Loss: 0.0013431342085823417\n",
      "Epoch 4278, Loss: 0.00021597816157736816, Final Batch Loss: 0.00018791333422996104\n",
      "Epoch 4279, Loss: 0.0007186548318713903, Final Batch Loss: 0.00023195476387627423\n",
      "Epoch 4280, Loss: 0.0001252938382094726, Final Batch Loss: 6.945453060325235e-05\n",
      "Epoch 4281, Loss: 8.203660399885848e-05, Final Batch Loss: 1.8281345546711236e-05\n",
      "Epoch 4282, Loss: 0.00013617500007967465, Final Batch Loss: 9.256257908418775e-05\n",
      "Epoch 4283, Loss: 4.40924657141295e-05, Final Batch Loss: 2.666379032234545e-06\n",
      "Epoch 4284, Loss: 0.000351157046679873, Final Batch Loss: 0.00010239825496682897\n",
      "Epoch 4285, Loss: 0.00020762930944329128, Final Batch Loss: 9.846761531662196e-05\n",
      "Epoch 4286, Loss: 0.0008759097745496547, Final Batch Loss: 2.2323472876450978e-05\n",
      "Epoch 4287, Loss: 0.0005831341222801711, Final Batch Loss: 4.402926060720347e-05\n",
      "Epoch 4288, Loss: 9.92508194030961e-05, Final Batch Loss: 5.123094524606131e-06\n",
      "Epoch 4289, Loss: 0.00020946886616002303, Final Batch Loss: 4.666011591325514e-06\n",
      "Epoch 4290, Loss: 0.0012755987117998302, Final Batch Loss: 0.0004426336381584406\n",
      "Epoch 4291, Loss: 0.0029413241304609983, Final Batch Loss: 7.152434591262136e-07\n",
      "Epoch 4292, Loss: 8.851313305058284e-05, Final Batch Loss: 5.044511453888845e-06\n",
      "Epoch 4293, Loss: 0.00042089053022209555, Final Batch Loss: 0.00040233967592939734\n",
      "Epoch 4294, Loss: 0.0007554208932560869, Final Batch Loss: 0.0007164385169744492\n",
      "Epoch 4295, Loss: 0.000222396818571724, Final Batch Loss: 7.27357401046902e-05\n",
      "Epoch 4296, Loss: 0.00023359886108664796, Final Batch Loss: 0.00014988501789048314\n",
      "Epoch 4297, Loss: 0.00039796511578060745, Final Batch Loss: 7.279816145455698e-07\n",
      "Epoch 4298, Loss: 0.00012301922470214777, Final Batch Loss: 2.087800021399744e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4299, Loss: 0.0006968302841414697, Final Batch Loss: 3.4577220503706485e-05\n",
      "Epoch 4300, Loss: 7.920089774415828e-05, Final Batch Loss: 5.122610673424788e-05\n",
      "Epoch 4301, Loss: 6.402989674825221e-05, Final Batch Loss: 3.706991992658004e-05\n",
      "Epoch 4302, Loss: 0.005562284430197906, Final Batch Loss: 0.0055199796333909035\n",
      "Epoch 4303, Loss: 0.00010739423942141002, Final Batch Loss: 1.5171003724390175e-05\n",
      "Epoch 4304, Loss: 9.09598729776917e-05, Final Batch Loss: 7.261060090968385e-05\n",
      "Epoch 4305, Loss: 0.00039758841739967465, Final Batch Loss: 0.00024476947146467865\n",
      "Epoch 4306, Loss: 0.00021007773466408253, Final Batch Loss: 9.239716018782929e-05\n",
      "Epoch 4307, Loss: 0.0012024405177726294, Final Batch Loss: 1.331353541900171e-05\n",
      "Epoch 4308, Loss: 0.00033076390900532715, Final Batch Loss: 5.452472760225646e-05\n",
      "Epoch 4309, Loss: 0.00012066537328792037, Final Batch Loss: 9.045787919603754e-06\n",
      "Epoch 4310, Loss: 0.0018557477960712276, Final Batch Loss: 0.0017730642575770617\n",
      "Epoch 4311, Loss: 0.001332426574663259, Final Batch Loss: 4.133164475206286e-05\n",
      "Epoch 4312, Loss: 0.0001715828402666375, Final Batch Loss: 2.1484738681465387e-05\n",
      "Epoch 4313, Loss: 0.00017531029152451083, Final Batch Loss: 5.332662112778053e-05\n",
      "Epoch 4314, Loss: 4.7136809371295385e-05, Final Batch Loss: 2.640646016516257e-05\n",
      "Epoch 4315, Loss: 8.707886809133925e-05, Final Batch Loss: 3.669541183626279e-05\n",
      "Epoch 4316, Loss: 0.00016996325575746596, Final Batch Loss: 4.474946763366461e-05\n",
      "Epoch 4317, Loss: 0.00039536091935588047, Final Batch Loss: 2.532867802074179e-05\n",
      "Epoch 4318, Loss: 0.00010994667900376953, Final Batch Loss: 5.583366146311164e-05\n",
      "Epoch 4319, Loss: 8.932294804253615e-05, Final Batch Loss: 1.8685797840589657e-05\n",
      "Epoch 4320, Loss: 0.000552965488168411, Final Batch Loss: 0.0005000584642402828\n",
      "Epoch 4321, Loss: 7.219904728117399e-05, Final Batch Loss: 3.0026414606254548e-05\n",
      "Epoch 4322, Loss: 0.0001043249076246866, Final Batch Loss: 5.166920345800463e-06\n",
      "Epoch 4323, Loss: 0.0006578421307494864, Final Batch Loss: 3.141611523460597e-05\n",
      "Epoch 4324, Loss: 0.0006798409503971925, Final Batch Loss: 1.3136863344698213e-05\n",
      "Epoch 4325, Loss: 7.917044058558531e-05, Final Batch Loss: 5.2823772421106696e-05\n",
      "Epoch 4326, Loss: 5.526949098566547e-05, Final Batch Loss: 7.5532916525844485e-06\n",
      "Epoch 4327, Loss: 0.0004845406865570112, Final Batch Loss: 4.142878424318042e-06\n",
      "Epoch 4328, Loss: 0.00011568338709366799, Final Batch Loss: 1.446690703232889e-06\n",
      "Epoch 4329, Loss: 0.0005435806669993326, Final Batch Loss: 0.0003878208517562598\n",
      "Epoch 4330, Loss: 0.0005112052422191482, Final Batch Loss: 0.0004964243853464723\n",
      "Epoch 4331, Loss: 0.019290829135570675, Final Batch Loss: 0.018499338999390602\n",
      "Epoch 4332, Loss: 0.00016555293404962867, Final Batch Loss: 7.501921209041029e-05\n",
      "Epoch 4333, Loss: 0.0006430461271520471, Final Batch Loss: 3.0282497391453944e-05\n",
      "Epoch 4334, Loss: 0.0018667974595700798, Final Batch Loss: 4.321345386415487e-06\n",
      "Epoch 4335, Loss: 0.03553866595029831, Final Batch Loss: 0.01664537750184536\n",
      "Epoch 4336, Loss: 0.0002533960578148253, Final Batch Loss: 8.298083412228152e-05\n",
      "Epoch 4337, Loss: 0.012040784829878248, Final Batch Loss: 0.011806534603238106\n",
      "Epoch 4338, Loss: 0.00031491467780142557, Final Batch Loss: 0.0002970391360577196\n",
      "Epoch 4339, Loss: 1.560747887197067e-05, Final Batch Loss: 1.03731736089685e-05\n",
      "Epoch 4340, Loss: 0.00015373582391475793, Final Batch Loss: 0.0001357961300527677\n",
      "Epoch 4341, Loss: 0.0003256622085245908, Final Batch Loss: 1.356428492726991e-05\n",
      "Epoch 4342, Loss: 0.0016630756545055192, Final Batch Loss: 0.001626539626158774\n",
      "Epoch 4343, Loss: 0.00013332517482922412, Final Batch Loss: 0.00011576020187931135\n",
      "Epoch 4344, Loss: 0.002586760442227387, Final Batch Loss: 2.976623818540247e-06\n",
      "Epoch 4345, Loss: 0.00059918210899923, Final Batch Loss: 0.0005131537327542901\n",
      "Epoch 4346, Loss: 0.00010419917134640855, Final Batch Loss: 3.8582734305236954e-06\n",
      "Epoch 4347, Loss: 0.020621224877686473, Final Batch Loss: 6.092862531659193e-05\n",
      "Epoch 4348, Loss: 2.6416116270411294e-05, Final Batch Loss: 2.3543263523606583e-05\n",
      "Epoch 4349, Loss: 0.0015648970888832991, Final Batch Loss: 4.451912445802009e-06\n",
      "Epoch 4350, Loss: 0.00012791488188668154, Final Batch Loss: 7.1069989644456655e-06\n",
      "Epoch 4351, Loss: 0.0006944725682842545, Final Batch Loss: 0.0006355034420266747\n",
      "Epoch 4352, Loss: 0.0001994736012420617, Final Batch Loss: 3.413059312151745e-05\n",
      "Epoch 4353, Loss: 6.807026147725992e-05, Final Batch Loss: 2.402692916803062e-05\n",
      "Epoch 4354, Loss: 0.0004739665746456012, Final Batch Loss: 0.00021388848836068064\n",
      "Epoch 4355, Loss: 0.0001064260613929946, Final Batch Loss: 9.328067244496197e-05\n",
      "Epoch 4356, Loss: 0.00014563970307790441, Final Batch Loss: 8.650621566630434e-06\n",
      "Epoch 4357, Loss: 0.007262932838784764, Final Batch Loss: 1.692143632681109e-05\n",
      "Epoch 4358, Loss: 0.00016590601262578275, Final Batch Loss: 0.00015044449537526816\n",
      "Epoch 4359, Loss: 2.4617862550257996e-05, Final Batch Loss: 1.2707479299933766e-06\n",
      "Epoch 4360, Loss: 0.0008579656278016046, Final Batch Loss: 0.00013279142149258405\n",
      "Epoch 4361, Loss: 0.0009594455186743289, Final Batch Loss: 0.00042538196430541575\n",
      "Epoch 4362, Loss: 0.00019249748584115878, Final Batch Loss: 0.0001396940933773294\n",
      "Epoch 4363, Loss: 0.000990917847957462, Final Batch Loss: 0.0008144835010170937\n",
      "Epoch 4364, Loss: 0.00010793239925988019, Final Batch Loss: 3.204785753041506e-05\n",
      "Epoch 4365, Loss: 5.832618808199186e-05, Final Batch Loss: 2.6657738999347202e-05\n",
      "Epoch 4366, Loss: 0.0002720845750445733, Final Batch Loss: 1.2352125850156881e-05\n",
      "Epoch 4367, Loss: 7.050706881273072e-05, Final Batch Loss: 4.6104159991955385e-06\n",
      "Epoch 4368, Loss: 0.00021853012322026188, Final Batch Loss: 7.103367806848837e-06\n",
      "Epoch 4369, Loss: 0.00031073027753336646, Final Batch Loss: 1.4594127151212888e-06\n",
      "Epoch 4370, Loss: 0.00338636536616832, Final Batch Loss: 0.00268172612413764\n",
      "Epoch 4371, Loss: 0.0018843392317648977, Final Batch Loss: 0.0015151698607951403\n",
      "Epoch 4372, Loss: 0.00323861074866727, Final Batch Loss: 7.450516568496823e-05\n",
      "Epoch 4373, Loss: 0.00018084055045619607, Final Batch Loss: 2.4992565158754587e-05\n",
      "Epoch 4374, Loss: 0.00026905175036517903, Final Batch Loss: 0.00023353549477178603\n",
      "Epoch 4375, Loss: 0.0013780364679405466, Final Batch Loss: 0.0012909366050735116\n",
      "Epoch 4376, Loss: 0.004545991013401363, Final Batch Loss: 6.601384484383743e-06\n",
      "Epoch 4377, Loss: 0.0004920245992252603, Final Batch Loss: 0.0002557840780355036\n",
      "Epoch 4378, Loss: 0.013793966147204628, Final Batch Loss: 3.017705967067741e-05\n",
      "Epoch 4379, Loss: 0.00012880631584266666, Final Batch Loss: 2.4495800971635617e-05\n",
      "Epoch 4380, Loss: 0.0008491970947943628, Final Batch Loss: 0.00014595111133530736\n",
      "Epoch 4381, Loss: 0.0175926187512232, Final Batch Loss: 4.661134153138846e-05\n",
      "Epoch 4382, Loss: 0.00023400672307616333, Final Batch Loss: 0.00022190863091964275\n",
      "Epoch 4383, Loss: 0.00041442916608502856, Final Batch Loss: 0.00041013583540916443\n",
      "Epoch 4384, Loss: 0.00036644459032686427, Final Batch Loss: 9.480812877882272e-06\n",
      "Epoch 4385, Loss: 0.00018784086569212377, Final Batch Loss: 1.4099918189458549e-05\n",
      "Epoch 4386, Loss: 0.0056603526518301805, Final Batch Loss: 0.005640674382448196\n",
      "Epoch 4387, Loss: 9.831070838117739e-05, Final Batch Loss: 1.4072217709326651e-05\n",
      "Epoch 4388, Loss: 0.00020391661428220687, Final Batch Loss: 6.415343250409933e-06\n",
      "Epoch 4389, Loss: 0.00010605043257783109, Final Batch Loss: 2.555399760240107e-06\n",
      "Epoch 4390, Loss: 9.199330816045403e-05, Final Batch Loss: 5.195258927415125e-05\n",
      "Epoch 4391, Loss: 8.180513032129966e-05, Final Batch Loss: 3.613436274463311e-05\n",
      "Epoch 4392, Loss: 0.000319134043820668, Final Batch Loss: 8.694137068232521e-05\n",
      "Epoch 4393, Loss: 0.0037144998141229735, Final Batch Loss: 0.0037082089111208916\n",
      "Epoch 4394, Loss: 3.8382904676836915e-05, Final Batch Loss: 8.365934263565578e-06\n",
      "Epoch 4395, Loss: 0.001602824981091544, Final Batch Loss: 0.0014619036810472608\n",
      "Epoch 4396, Loss: 0.0006073701113109564, Final Batch Loss: 1.0485562143003335e-06\n",
      "Epoch 4397, Loss: 0.0006602773937629536, Final Batch Loss: 0.000579724321141839\n",
      "Epoch 4398, Loss: 0.0006922923967067618, Final Batch Loss: 0.0006732465699315071\n",
      "Epoch 4399, Loss: 0.0010414119606139138, Final Batch Loss: 0.001010237610898912\n",
      "Epoch 4400, Loss: 0.0034222297836095095, Final Batch Loss: 0.002175733679905534\n",
      "Epoch 4401, Loss: 0.0010292131792084547, Final Batch Loss: 8.797143891570158e-06\n",
      "Epoch 4402, Loss: 0.00043607586121652275, Final Batch Loss: 0.00023139565018936992\n",
      "Epoch 4403, Loss: 0.0005669718111676048, Final Batch Loss: 2.4767095965216868e-06\n",
      "Epoch 4404, Loss: 0.0014844480770079826, Final Batch Loss: 3.02410762742511e-06\n",
      "Epoch 4405, Loss: 0.0002402208478997636, Final Batch Loss: 3.7473068914550822e-06\n",
      "Epoch 4406, Loss: 0.0044863202929263934, Final Batch Loss: 0.004423364065587521\n",
      "Epoch 4407, Loss: 0.000305824403767474, Final Batch Loss: 7.128856668714434e-05\n",
      "Epoch 4408, Loss: 0.0001116088186563502, Final Batch Loss: 5.381751861932571e-07\n",
      "Epoch 4409, Loss: 3.951879443775397e-05, Final Batch Loss: 2.7258676709607244e-05\n",
      "Epoch 4410, Loss: 0.00032148940499610035, Final Batch Loss: 3.115444087598007e-06\n",
      "Epoch 4411, Loss: 0.0010434998821438057, Final Batch Loss: 2.3134487491915934e-05\n",
      "Epoch 4412, Loss: 0.041784633067436516, Final Batch Loss: 0.0015683920355513692\n",
      "Epoch 4413, Loss: 6.408828357962193e-05, Final Batch Loss: 8.842152965371497e-07\n",
      "Epoch 4414, Loss: 0.00024283949915115954, Final Batch Loss: 1.0657608982000966e-05\n",
      "Epoch 4415, Loss: 0.00013382378165260889, Final Batch Loss: 9.5083647465799e-05\n",
      "Epoch 4416, Loss: 8.565884854760952e-05, Final Batch Loss: 7.069524872349575e-05\n",
      "Epoch 4417, Loss: 0.00014727879170095548, Final Batch Loss: 8.134041854646057e-05\n",
      "Epoch 4418, Loss: 0.0023766947342664935, Final Batch Loss: 0.0023212882224470377\n",
      "Epoch 4419, Loss: 0.0005504747969098389, Final Batch Loss: 0.0004051530850119889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4420, Loss: 0.00011311180151096778, Final Batch Loss: 1.4827576706011314e-05\n",
      "Epoch 4421, Loss: 0.0008554166415706277, Final Batch Loss: 0.0008231351966969669\n",
      "Epoch 4422, Loss: 4.2975649193977006e-05, Final Batch Loss: 1.7927770386449993e-05\n",
      "Epoch 4423, Loss: 0.00010075669956677302, Final Batch Loss: 2.3748459625494434e-06\n",
      "Epoch 4424, Loss: 0.0003177029502694495, Final Batch Loss: 2.6071655156556517e-05\n",
      "Epoch 4425, Loss: 0.00010034109891421394, Final Batch Loss: 9.113299893215299e-05\n",
      "Epoch 4426, Loss: 0.0007578418881166726, Final Batch Loss: 0.0006778696551918983\n",
      "Epoch 4427, Loss: 0.0023925093901198125, Final Batch Loss: 1.2220718417665921e-05\n",
      "Epoch 4428, Loss: 1.1816683581855614e-05, Final Batch Loss: 5.422898084361805e-06\n",
      "Epoch 4429, Loss: 5.9869265896850266e-05, Final Batch Loss: 1.7138265320681967e-05\n",
      "Epoch 4430, Loss: 0.008782267836068058, Final Batch Loss: 3.117442611255683e-05\n",
      "Epoch 4431, Loss: 0.0001947429573192494, Final Batch Loss: 0.000171757405041717\n",
      "Epoch 4432, Loss: 7.357037065958139e-05, Final Batch Loss: 1.990538112295326e-05\n",
      "Epoch 4433, Loss: 5.7665674830786884e-05, Final Batch Loss: 3.642952651716769e-05\n",
      "Epoch 4434, Loss: 0.0015655648130632471, Final Batch Loss: 3.15537145070266e-05\n",
      "Epoch 4435, Loss: 0.00020836451585637406, Final Batch Loss: 0.00010804315388668329\n",
      "Epoch 4436, Loss: 2.6215636808046838e-05, Final Batch Loss: 2.4523828869860154e-06\n",
      "Epoch 4437, Loss: 0.0006684640175080858, Final Batch Loss: 0.0005874973721802235\n",
      "Epoch 4438, Loss: 0.002171031687339564, Final Batch Loss: 3.880377789755585e-06\n",
      "Epoch 4439, Loss: 4.440066550159827e-05, Final Batch Loss: 1.2708911526715383e-05\n",
      "Epoch 4440, Loss: 0.00044038266969437245, Final Batch Loss: 2.902962478401605e-05\n",
      "Epoch 4441, Loss: 0.00041338840765092755, Final Batch Loss: 2.330795723537449e-06\n",
      "Epoch 4442, Loss: 0.0010275795268626098, Final Batch Loss: 2.437262310195365e-06\n",
      "Epoch 4443, Loss: 0.000722801691154018, Final Batch Loss: 1.9903964130207896e-05\n",
      "Epoch 4444, Loss: 6.689166684736847e-05, Final Batch Loss: 4.866471044806531e-06\n",
      "Epoch 4445, Loss: 0.0001304255420109257, Final Batch Loss: 8.234566485043615e-05\n",
      "Epoch 4446, Loss: 0.0006714583814755315, Final Batch Loss: 2.2097965484135784e-05\n",
      "Epoch 4447, Loss: 0.0003787648893194273, Final Batch Loss: 0.0003119512984994799\n",
      "Epoch 4448, Loss: 0.00038764722376072314, Final Batch Loss: 8.840614100336097e-06\n",
      "Epoch 4449, Loss: 9.855220378085505e-05, Final Batch Loss: 8.041630644584075e-05\n",
      "Epoch 4450, Loss: 3.993611426267307e-05, Final Batch Loss: 2.8883054255857132e-05\n",
      "Epoch 4451, Loss: 8.303599133796524e-05, Final Batch Loss: 2.1001227651140653e-05\n",
      "Epoch 4452, Loss: 3.700476918311324e-05, Final Batch Loss: 1.5921576050459407e-05\n",
      "Epoch 4453, Loss: 0.004824007010029163, Final Batch Loss: 0.004736336879432201\n",
      "Epoch 4454, Loss: 0.0005450615790323354, Final Batch Loss: 0.0004600907559506595\n",
      "Epoch 4455, Loss: 0.00016381834575440735, Final Batch Loss: 9.492001845501363e-05\n",
      "Epoch 4456, Loss: 0.00017762530478648841, Final Batch Loss: 9.281887469114736e-05\n",
      "Epoch 4457, Loss: 5.751810022047721e-05, Final Batch Loss: 4.0897710277931765e-05\n",
      "Epoch 4458, Loss: 0.004310728763812222, Final Batch Loss: 0.004195903893560171\n",
      "Epoch 4459, Loss: 0.00127239417815872, Final Batch Loss: 3.837370968540199e-06\n",
      "Epoch 4460, Loss: 4.897890903521329e-05, Final Batch Loss: 5.704951036022976e-06\n",
      "Epoch 4461, Loss: 0.0008773599984124303, Final Batch Loss: 0.0003078058362007141\n",
      "Epoch 4462, Loss: 2.352383944526082e-05, Final Batch Loss: 1.0576896784186829e-05\n",
      "Epoch 4463, Loss: 0.002385197885814705, Final Batch Loss: 7.766977432765998e-06\n",
      "Epoch 4464, Loss: 0.0015780424455442699, Final Batch Loss: 1.6018211681512184e-05\n",
      "Epoch 4465, Loss: 0.00038467178819701076, Final Batch Loss: 0.0002845819399226457\n",
      "Epoch 4466, Loss: 3.4455290006008e-05, Final Batch Loss: 4.180246833129786e-06\n",
      "Epoch 4467, Loss: 0.00021845606534043327, Final Batch Loss: 1.7448583093937486e-05\n",
      "Epoch 4468, Loss: 5.72963290323969e-05, Final Batch Loss: 2.474797292961739e-05\n",
      "Epoch 4469, Loss: 4.8899797548074275e-05, Final Batch Loss: 1.8074835679726675e-05\n",
      "Epoch 4470, Loss: 9.486515773460269e-05, Final Batch Loss: 1.474479358876124e-05\n",
      "Epoch 4471, Loss: 0.00017887475678435294, Final Batch Loss: 4.0586992327007465e-06\n",
      "Epoch 4472, Loss: 0.0004051467312820023, Final Batch Loss: 2.4429891709587537e-05\n",
      "Epoch 4473, Loss: 5.2873479944537394e-05, Final Batch Loss: 1.8000389900407754e-05\n",
      "Epoch 4474, Loss: 2.7536786774362554e-05, Final Batch Loss: 3.7380043522716733e-06\n",
      "Epoch 4475, Loss: 0.0004474067682167515, Final Batch Loss: 0.00038548855809494853\n",
      "Epoch 4476, Loss: 5.6835538998711854e-05, Final Batch Loss: 2.047657108050771e-05\n",
      "Epoch 4477, Loss: 0.0005553129456075112, Final Batch Loss: 1.230263251272845e-06\n",
      "Epoch 4478, Loss: 0.00014130196359474212, Final Batch Loss: 0.0001158201921498403\n",
      "Epoch 4479, Loss: 0.0001535693445475772, Final Batch Loss: 1.7605794710107148e-05\n",
      "Epoch 4480, Loss: 2.9953465400467394e-05, Final Batch Loss: 2.6363936740381178e-06\n",
      "Epoch 4481, Loss: 0.0004940515718772076, Final Batch Loss: 0.00044454296585172415\n",
      "Epoch 4482, Loss: 0.00035943078091804637, Final Batch Loss: 0.00034749420592561364\n",
      "Epoch 4483, Loss: 0.001046803779900074, Final Batch Loss: 0.00015021569561213255\n",
      "Epoch 4484, Loss: 2.3590770979353692e-05, Final Batch Loss: 1.2409946975822095e-05\n",
      "Epoch 4485, Loss: 0.0005000432138331234, Final Batch Loss: 0.00045122296432964504\n",
      "Epoch 4486, Loss: 9.806017260416411e-05, Final Batch Loss: 2.9311104299267754e-05\n",
      "Epoch 4487, Loss: 0.0001667896631261101, Final Batch Loss: 1.2382492059259675e-05\n",
      "Epoch 4488, Loss: 0.0019886127847712487, Final Batch Loss: 3.149217809550464e-05\n",
      "Epoch 4489, Loss: 0.0018435078891343437, Final Batch Loss: 2.7223162760492414e-05\n",
      "Epoch 4490, Loss: 0.0003200478149665287, Final Batch Loss: 3.0597202567150816e-06\n",
      "Epoch 4491, Loss: 5.2525962132676796e-05, Final Batch Loss: 8.448679409411852e-07\n",
      "Epoch 4492, Loss: 2.759482231340371e-05, Final Batch Loss: 1.6655325453029945e-05\n",
      "Epoch 4493, Loss: 0.0007731030927971005, Final Batch Loss: 2.0932231564074755e-05\n",
      "Epoch 4494, Loss: 0.0019134167705487926, Final Batch Loss: 1.7522124835522845e-05\n",
      "Epoch 4495, Loss: 0.0002710778935579583, Final Batch Loss: 7.794465636834502e-05\n",
      "Epoch 4496, Loss: 0.0013615594671136932, Final Batch Loss: 0.0013333148090168834\n",
      "Epoch 4497, Loss: 4.386981026982539e-05, Final Batch Loss: 3.783981446758844e-05\n",
      "Epoch 4498, Loss: 0.00148805117351003, Final Batch Loss: 0.0002903882705140859\n",
      "Epoch 4499, Loss: 0.00014728166297572898, Final Batch Loss: 1.1908426131412853e-05\n",
      "Epoch 4500, Loss: 0.0001461853680666536, Final Batch Loss: 6.760729593224823e-05\n",
      "Epoch 4501, Loss: 0.000205216013455356, Final Batch Loss: 0.00019773551321122795\n",
      "Epoch 4502, Loss: 0.0005684718489646912, Final Batch Loss: 0.00014966930029913783\n",
      "Epoch 4503, Loss: 0.00013165673772164155, Final Batch Loss: 2.956295975309331e-05\n",
      "Epoch 4504, Loss: 0.001931601065734867, Final Batch Loss: 0.00010136733908439055\n",
      "Epoch 4505, Loss: 0.0001270580632990459, Final Batch Loss: 1.9636516299215145e-05\n",
      "Epoch 4506, Loss: 0.0006878549138491508, Final Batch Loss: 0.0006796640227548778\n",
      "Epoch 4507, Loss: 8.344929938175483e-05, Final Batch Loss: 1.218574743688805e-05\n",
      "Epoch 4508, Loss: 1.0444145573274e-05, Final Batch Loss: 6.326051334326621e-06\n",
      "Epoch 4509, Loss: 1.882056130853016e-05, Final Batch Loss: 8.371595868084114e-06\n",
      "Epoch 4510, Loss: 1.8886047655541915e-05, Final Batch Loss: 8.925586371333338e-06\n",
      "Epoch 4511, Loss: 8.724812141736038e-05, Final Batch Loss: 4.803381671081297e-05\n",
      "Epoch 4512, Loss: 0.0014292195046436973, Final Batch Loss: 0.0014060038374736905\n",
      "Epoch 4513, Loss: 4.4854547013528645e-05, Final Batch Loss: 3.6877601814921945e-05\n",
      "Epoch 4514, Loss: 6.518129112009774e-06, Final Batch Loss: 4.227571935189189e-06\n",
      "Epoch 4515, Loss: 0.00027531007981451694, Final Batch Loss: 1.7377789845340885e-05\n",
      "Epoch 4516, Loss: 0.0009491338159932639, Final Batch Loss: 1.0881037269427907e-05\n",
      "Epoch 4517, Loss: 0.0013601756654679775, Final Batch Loss: 7.5106509029865265e-06\n",
      "Epoch 4518, Loss: 0.0003772527925320901, Final Batch Loss: 0.00025964598171412945\n",
      "Epoch 4519, Loss: 2.5685973923827987e-05, Final Batch Loss: 1.2532535947684664e-05\n",
      "Epoch 4520, Loss: 0.0008126092243401217, Final Batch Loss: 0.0008014368358999491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4521, Loss: 0.0019135846614517504, Final Batch Loss: 0.0018953413236886263\n",
      "Epoch 4522, Loss: 0.000280585289146984, Final Batch Loss: 0.000253268372034654\n",
      "Epoch 4523, Loss: 5.4118405387271196e-05, Final Batch Loss: 2.8341795768938027e-05\n",
      "Epoch 4524, Loss: 0.00010081689833896235, Final Batch Loss: 2.3115200747270137e-05\n",
      "Epoch 4525, Loss: 0.0011695863843215193, Final Batch Loss: 1.4072913927520858e-06\n",
      "Epoch 4526, Loss: 5.012272140447749e-05, Final Batch Loss: 9.241945917892735e-06\n",
      "Epoch 4527, Loss: 0.000246946670813486, Final Batch Loss: 0.00017628251225687563\n",
      "Epoch 4528, Loss: 0.00029185807579779066, Final Batch Loss: 4.3849784560734406e-05\n",
      "Epoch 4529, Loss: 2.412325529732584e-05, Final Batch Loss: 5.9025932586109775e-08\n",
      "Epoch 4530, Loss: 1.495408037044399e-05, Final Batch Loss: 2.504323902030592e-06\n",
      "Epoch 4531, Loss: 4.5477876483346336e-05, Final Batch Loss: 1.832006273616571e-05\n",
      "Epoch 4532, Loss: 0.002127207029843703, Final Batch Loss: 0.0019665779545903206\n",
      "Epoch 4533, Loss: 0.003054950800105871, Final Batch Loss: 1.310412244492909e-05\n",
      "Epoch 4534, Loss: 0.024947769597929437, Final Batch Loss: 5.2103430789429694e-05\n",
      "Epoch 4535, Loss: 0.0004121218153159134, Final Batch Loss: 4.867181269219145e-05\n",
      "Epoch 4536, Loss: 0.0002572799858171493, Final Batch Loss: 0.00020217825658619404\n",
      "Epoch 4537, Loss: 9.856318138190545e-05, Final Batch Loss: 4.081167935510166e-05\n",
      "Epoch 4538, Loss: 0.00033272398286499083, Final Batch Loss: 0.00027507563936524093\n",
      "Epoch 4539, Loss: 0.0001449972332920879, Final Batch Loss: 6.358845712384209e-05\n",
      "Epoch 4540, Loss: 9.853158508121851e-05, Final Batch Loss: 3.5030166145588737e-06\n",
      "Epoch 4541, Loss: 3.220694543415448e-05, Final Batch Loss: 1.2548444829008076e-05\n",
      "Epoch 4542, Loss: 0.00016437652811873704, Final Batch Loss: 0.00010573030886007473\n",
      "Epoch 4543, Loss: 9.086404043046059e-05, Final Batch Loss: 7.996217027539387e-05\n",
      "Epoch 4544, Loss: 0.0003203960513928905, Final Batch Loss: 7.716973777860403e-05\n",
      "Epoch 4545, Loss: 5.1032491683145054e-05, Final Batch Loss: 3.19750870403368e-05\n",
      "Epoch 4546, Loss: 0.00010588296572677791, Final Batch Loss: 4.307050403440371e-05\n",
      "Epoch 4547, Loss: 0.00012389900075504556, Final Batch Loss: 1.9313956727273762e-05\n",
      "Epoch 4548, Loss: 5.568381857301574e-05, Final Batch Loss: 2.819757537508849e-05\n",
      "Epoch 4549, Loss: 0.0003268060099799186, Final Batch Loss: 0.00017148042388726026\n",
      "Epoch 4550, Loss: 5.600069198408164e-05, Final Batch Loss: 3.455197293078527e-05\n",
      "Epoch 4551, Loss: 0.00021734383108196198, Final Batch Loss: 7.5259354161971714e-06\n",
      "Epoch 4552, Loss: 0.0013060081187177275, Final Batch Loss: 6.249094894883456e-06\n",
      "Epoch 4553, Loss: 0.00036502539751381846, Final Batch Loss: 1.1939123396587092e-05\n",
      "Epoch 4554, Loss: 0.0007537073179264553, Final Batch Loss: 0.0001033014923450537\n",
      "Epoch 4555, Loss: 0.0004952664821757935, Final Batch Loss: 0.0004622079140972346\n",
      "Epoch 4556, Loss: 9.559616228216328e-05, Final Batch Loss: 5.008260268368758e-05\n",
      "Epoch 4557, Loss: 3.2117730825120816e-05, Final Batch Loss: 6.327435130515369e-06\n",
      "Epoch 4558, Loss: 3.5400636988924816e-05, Final Batch Loss: 1.0885492883971892e-05\n",
      "Epoch 4559, Loss: 4.729504871647805e-05, Final Batch Loss: 2.9449698558892123e-05\n",
      "Epoch 4560, Loss: 0.0001099220935429912, Final Batch Loss: 7.574044866487384e-05\n",
      "Epoch 4561, Loss: 0.00047095303943933686, Final Batch Loss: 1.3083138583169784e-05\n",
      "Epoch 4562, Loss: 0.0002880388346966356, Final Batch Loss: 0.00023121436242945492\n",
      "Epoch 4563, Loss: 0.0006543359086208511, Final Batch Loss: 5.007408981327899e-05\n",
      "Epoch 4564, Loss: 9.158934699371457e-05, Final Batch Loss: 1.632655767025426e-05\n",
      "Epoch 4565, Loss: 0.00013238397559689474, Final Batch Loss: 0.0001265575847355649\n",
      "Epoch 4566, Loss: 9.048148785950616e-05, Final Batch Loss: 3.6146990169072524e-05\n",
      "Epoch 4567, Loss: 0.000405132423111354, Final Batch Loss: 6.786287485738285e-06\n",
      "Epoch 4568, Loss: 0.0007107781305251137, Final Batch Loss: 1.9559527686396905e-07\n",
      "Epoch 4569, Loss: 4.093265806659474e-05, Final Batch Loss: 3.876999016938498e-06\n",
      "Epoch 4570, Loss: 4.128488080823445e-05, Final Batch Loss: 7.227723926916951e-06\n",
      "Epoch 4571, Loss: 5.336190588423051e-05, Final Batch Loss: 9.167004463961348e-06\n",
      "Epoch 4572, Loss: 0.0004038105107611045, Final Batch Loss: 0.00016798177966848016\n",
      "Epoch 4573, Loss: 0.00010715262033045292, Final Batch Loss: 4.77223438792862e-05\n",
      "Epoch 4574, Loss: 0.0003719316082424484, Final Batch Loss: 3.4971155400853604e-05\n",
      "Epoch 4575, Loss: 0.0006267227962553079, Final Batch Loss: 5.590062528426643e-07\n",
      "Epoch 4576, Loss: 0.00018778579760692082, Final Batch Loss: 5.4124797316035256e-05\n",
      "Epoch 4577, Loss: 0.00017699954378258553, Final Batch Loss: 4.773785349243553e-06\n",
      "Epoch 4578, Loss: 0.00024178633520932635, Final Batch Loss: 1.2162846360297408e-05\n",
      "Epoch 4579, Loss: 0.0009918277646647766, Final Batch Loss: 0.0009143092902377248\n",
      "Epoch 4580, Loss: 0.00015569056722597452, Final Batch Loss: 4.349150003690738e-06\n",
      "Epoch 4581, Loss: 2.3563234208268113e-05, Final Batch Loss: 8.240373063017614e-06\n",
      "Epoch 4582, Loss: 0.001572076934735378, Final Batch Loss: 6.820313046773663e-06\n",
      "Epoch 4583, Loss: 0.0023856412262830418, Final Batch Loss: 0.002357564168050885\n",
      "Epoch 4584, Loss: 0.0001872278589871712, Final Batch Loss: 7.386540528386831e-05\n",
      "Epoch 4585, Loss: 4.1200990381184965e-05, Final Batch Loss: 3.3170119422720745e-05\n",
      "Epoch 4586, Loss: 6.261724411160685e-05, Final Batch Loss: 9.917024726746604e-06\n",
      "Epoch 4587, Loss: 4.580820859700907e-05, Final Batch Loss: 2.7477091862238012e-05\n",
      "Epoch 4588, Loss: 3.137674457320827e-05, Final Batch Loss: 5.290941317070974e-06\n",
      "Epoch 4589, Loss: 0.00013418756498140283, Final Batch Loss: 4.5375021727522835e-05\n",
      "Epoch 4590, Loss: 6.023493369866628e-05, Final Batch Loss: 3.6477675166679546e-05\n",
      "Epoch 4591, Loss: 0.0019984994160040515, Final Batch Loss: 2.5828749130596407e-05\n",
      "Epoch 4592, Loss: 6.510108687507454e-05, Final Batch Loss: 3.707560244947672e-05\n",
      "Epoch 4593, Loss: 9.852024049905594e-06, Final Batch Loss: 2.352736373723019e-06\n",
      "Epoch 4594, Loss: 0.00020676690473919734, Final Batch Loss: 8.281108603114262e-05\n",
      "Epoch 4595, Loss: 0.0003862971061607823, Final Batch Loss: 2.3080574464984238e-05\n",
      "Epoch 4596, Loss: 0.001732916854962241, Final Batch Loss: 0.0016422098269686103\n",
      "Epoch 4597, Loss: 0.0015647525506210513, Final Batch Loss: 0.0014597284607589245\n",
      "Epoch 4598, Loss: 0.00012123050328227691, Final Batch Loss: 6.617025064770132e-05\n",
      "Epoch 4599, Loss: 0.0003003345723300299, Final Batch Loss: 2.7474984563014004e-06\n",
      "Epoch 4600, Loss: 1.8399657164991368e-05, Final Batch Loss: 1.0453326467541046e-05\n",
      "Epoch 4601, Loss: 8.972328032541554e-05, Final Batch Loss: 6.265242700465024e-05\n",
      "Epoch 4602, Loss: 0.0007169871387304738, Final Batch Loss: 0.0006416272954083979\n",
      "Epoch 4603, Loss: 6.562360704265302e-05, Final Batch Loss: 5.400536974775605e-05\n",
      "Epoch 4604, Loss: 9.26620157315483e-06, Final Batch Loss: 1.153877178694529e-06\n",
      "Epoch 4605, Loss: 4.20269475398527e-05, Final Batch Loss: 3.577340248739347e-05\n",
      "Epoch 4606, Loss: 0.0004926524707116187, Final Batch Loss: 0.00020259202574379742\n",
      "Epoch 4607, Loss: 5.4377839660446625e-05, Final Batch Loss: 4.35598922194913e-05\n",
      "Epoch 4608, Loss: 0.00034738746762741357, Final Batch Loss: 3.839624696411192e-06\n",
      "Epoch 4609, Loss: 0.0005618941531793098, Final Batch Loss: 7.2326538429479115e-06\n",
      "Epoch 4610, Loss: 4.79417485621525e-05, Final Batch Loss: 2.2301257558865473e-05\n",
      "Epoch 4611, Loss: 2.33042511581516e-05, Final Batch Loss: 1.5126125845199567e-06\n",
      "Epoch 4612, Loss: 4.0137403175322106e-05, Final Batch Loss: 3.266612475272268e-05\n",
      "Epoch 4613, Loss: 0.0013980406511109322, Final Batch Loss: 0.00031369863427244127\n",
      "Epoch 4614, Loss: 0.0010152511240448803, Final Batch Loss: 0.0005911248736083508\n",
      "Epoch 4615, Loss: 0.00204832389135845, Final Batch Loss: 0.0018510569352656603\n",
      "Epoch 4616, Loss: 0.0015044987967485213, Final Batch Loss: 0.001494196243584156\n",
      "Epoch 4617, Loss: 3.910688428732101e-05, Final Batch Loss: 1.1604715837165713e-05\n",
      "Epoch 4618, Loss: 9.65952824572014e-06, Final Batch Loss: 5.358557473300607e-07\n",
      "Epoch 4619, Loss: 5.68403320357902e-05, Final Batch Loss: 2.22041617234936e-05\n",
      "Epoch 4620, Loss: 0.00013992128151585348, Final Batch Loss: 4.075039396411739e-05\n",
      "Epoch 4621, Loss: 0.00024501118605257943, Final Batch Loss: 4.798269219463691e-05\n",
      "Epoch 4622, Loss: 0.0012507321025623241, Final Batch Loss: 0.001228919718414545\n",
      "Epoch 4623, Loss: 2.3938375051102412e-05, Final Batch Loss: 4.2359326357654936e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4624, Loss: 7.922562508611009e-05, Final Batch Loss: 4.1500607039779425e-05\n",
      "Epoch 4625, Loss: 0.00089550778056946, Final Batch Loss: 6.99589281794033e-06\n",
      "Epoch 4626, Loss: 4.651157581747611e-06, Final Batch Loss: 4.3516897108020203e-07\n",
      "Epoch 4627, Loss: 0.0006250360365811503, Final Batch Loss: 2.2383368559530936e-05\n",
      "Epoch 4628, Loss: 0.00030492141377180815, Final Batch Loss: 0.00016048284305725247\n",
      "Epoch 4629, Loss: 9.291043579651159e-05, Final Batch Loss: 3.901165200659307e-06\n",
      "Epoch 4630, Loss: 0.0003227023007639218, Final Batch Loss: 6.349921022774652e-06\n",
      "Epoch 4631, Loss: 0.00018521926540415734, Final Batch Loss: 1.1122087016701698e-05\n",
      "Epoch 4632, Loss: 0.0005807257819014922, Final Batch Loss: 2.1409339296951657e-06\n",
      "Epoch 4633, Loss: 0.001478354290156858, Final Batch Loss: 3.0423125281231478e-05\n",
      "Epoch 4634, Loss: 5.788265207229415e-05, Final Batch Loss: 1.138051175075816e-05\n",
      "Epoch 4635, Loss: 1.7195404069525466e-05, Final Batch Loss: 3.448937775374361e-07\n",
      "Epoch 4636, Loss: 0.001466410463763168, Final Batch Loss: 1.4260989701142535e-05\n",
      "Epoch 4637, Loss: 1.8186190118285595e-05, Final Batch Loss: 5.766300546383718e-06\n",
      "Epoch 4638, Loss: 0.013312142182257958, Final Batch Loss: 0.013086870312690735\n",
      "Epoch 4639, Loss: 1.6220851648540702e-05, Final Batch Loss: 4.545352567220107e-06\n",
      "Epoch 4640, Loss: 2.9144010113668628e-05, Final Batch Loss: 2.1855419618077576e-05\n",
      "Epoch 4641, Loss: 0.0006986833429891703, Final Batch Loss: 1.446712758479407e-07\n",
      "Epoch 4642, Loss: 7.324235912165022e-05, Final Batch Loss: 4.545706815406447e-06\n",
      "Epoch 4643, Loss: 0.0004786731433341629, Final Batch Loss: 1.4075251783651765e-05\n",
      "Epoch 4644, Loss: 3.632436073530698e-05, Final Batch Loss: 2.456079891999252e-05\n",
      "Epoch 4645, Loss: 6.492106422228971e-05, Final Batch Loss: 8.882417205313686e-06\n",
      "Epoch 4646, Loss: 1.812094615161186e-05, Final Batch Loss: 1.6312898878823034e-05\n",
      "Epoch 4647, Loss: 0.0007785304815115524, Final Batch Loss: 9.87398834695341e-06\n",
      "Epoch 4648, Loss: 0.00022455987709690817, Final Batch Loss: 0.00016423167835455388\n",
      "Epoch 4649, Loss: 0.0012533086228359025, Final Batch Loss: 3.0561943276552483e-05\n",
      "Epoch 4650, Loss: 0.00046571760321967304, Final Batch Loss: 8.307106327265501e-05\n",
      "Epoch 4651, Loss: 0.002049854976576171, Final Batch Loss: 1.871611129899975e-05\n",
      "Epoch 4652, Loss: 3.920598464901559e-05, Final Batch Loss: 1.2449094356270507e-05\n",
      "Epoch 4653, Loss: 0.01156980823725462, Final Batch Loss: 0.0009719142690300941\n",
      "Epoch 4654, Loss: 3.3915466474354616e-05, Final Batch Loss: 3.10932045977097e-05\n",
      "Epoch 4655, Loss: 0.00011256690595473628, Final Batch Loss: 2.514620246074628e-05\n",
      "Epoch 4656, Loss: 0.0022062035277485847, Final Batch Loss: 0.0021569225937128067\n",
      "Epoch 4657, Loss: 1.7670836314209737e-05, Final Batch Loss: 4.675315722124651e-06\n",
      "Epoch 4658, Loss: 3.478045528026996e-05, Final Batch Loss: 1.3293664778757375e-05\n",
      "Epoch 4659, Loss: 2.983021704494604e-05, Final Batch Loss: 5.488659098773496e-06\n",
      "Epoch 4660, Loss: 9.480825252694558e-05, Final Batch Loss: 4.154936164013634e-07\n",
      "Epoch 4661, Loss: 3.3639035450505617e-06, Final Batch Loss: 2.6467487259651534e-06\n",
      "Epoch 4662, Loss: 4.770528039443889e-05, Final Batch Loss: 5.191019681660691e-06\n",
      "Epoch 4663, Loss: 0.0012809985928470269, Final Batch Loss: 0.0011824414832517505\n",
      "Epoch 4664, Loss: 0.00019787965720752254, Final Batch Loss: 9.96173475869e-05\n",
      "Epoch 4665, Loss: 6.560537349287188e-05, Final Batch Loss: 6.511722858704161e-06\n",
      "Epoch 4666, Loss: 2.726261982388678e-05, Final Batch Loss: 2.489676080585923e-05\n",
      "Epoch 4667, Loss: 0.00026872926764553995, Final Batch Loss: 5.509102720679948e-06\n",
      "Epoch 4668, Loss: 0.0002128994533450168, Final Batch Loss: 3.887369985022815e-06\n",
      "Epoch 4669, Loss: 8.650133349874523e-05, Final Batch Loss: 8.951485142461024e-06\n",
      "Epoch 4670, Loss: 0.0003451398079050705, Final Batch Loss: 2.5680477847345173e-05\n",
      "Epoch 4671, Loss: 1.2961946140421787e-05, Final Batch Loss: 7.434286999341566e-06\n",
      "Epoch 4672, Loss: 0.0006806161036365665, Final Batch Loss: 0.0005600507720373571\n",
      "Epoch 4673, Loss: 6.481872333097272e-05, Final Batch Loss: 5.3001815103925765e-05\n",
      "Epoch 4674, Loss: 3.4896890610980336e-05, Final Batch Loss: 1.7325264707324095e-06\n",
      "Epoch 4675, Loss: 0.00017613658656046027, Final Batch Loss: 0.0001674830709816888\n",
      "Epoch 4676, Loss: 0.008197682211175561, Final Batch Loss: 0.003110316814854741\n",
      "Epoch 4677, Loss: 7.399014884867938e-05, Final Batch Loss: 8.021187568374444e-06\n",
      "Epoch 4678, Loss: 0.0020749233081005514, Final Batch Loss: 0.0019384428160265088\n",
      "Epoch 4679, Loss: 0.0013618019293062389, Final Batch Loss: 0.001087233773432672\n",
      "Epoch 4680, Loss: 0.0018086568161379546, Final Batch Loss: 6.684564868919551e-05\n",
      "Epoch 4681, Loss: 0.0002263373044115724, Final Batch Loss: 1.923542185977567e-05\n",
      "Epoch 4682, Loss: 0.0002488037698640255, Final Batch Loss: 2.8516615202534012e-05\n",
      "Epoch 4683, Loss: 2.9586703362838307e-06, Final Batch Loss: 4.2012374024125165e-07\n",
      "Epoch 4684, Loss: 0.0003576383169274777, Final Batch Loss: 0.00019427483493927866\n",
      "Epoch 4685, Loss: 0.0005013764202885795, Final Batch Loss: 0.00045579433208331466\n",
      "Epoch 4686, Loss: 3.336029179479283e-05, Final Batch Loss: 2.3725873177227186e-07\n",
      "Epoch 4687, Loss: 0.002464859498104488, Final Batch Loss: 1.0705304703151342e-05\n",
      "Epoch 4688, Loss: 6.0536496675922535e-05, Final Batch Loss: 1.0081230357172899e-05\n",
      "Epoch 4689, Loss: 0.0006237359557417221, Final Batch Loss: 0.00011138391710119322\n",
      "Epoch 4690, Loss: 1.833131864259485e-05, Final Batch Loss: 8.187996172637213e-06\n",
      "Epoch 4691, Loss: 0.0004981114034308121, Final Batch Loss: 3.9043035940267146e-05\n",
      "Epoch 4692, Loss: 0.0013078497504466213, Final Batch Loss: 1.9455190340522677e-05\n",
      "Epoch 4693, Loss: 4.610525184034486e-05, Final Batch Loss: 4.022754364996217e-05\n",
      "Epoch 4694, Loss: 0.0003767616453842493, Final Batch Loss: 0.0003520402533467859\n",
      "Epoch 4695, Loss: 1.3208402833697619e-05, Final Batch Loss: 8.704467290954199e-06\n",
      "Epoch 4696, Loss: 2.2883553356223274e-05, Final Batch Loss: 1.5278343198588118e-05\n",
      "Epoch 4697, Loss: 2.325432433281094e-05, Final Batch Loss: 1.1646397979347967e-05\n",
      "Epoch 4698, Loss: 6.005051182000898e-05, Final Batch Loss: 3.986624869867228e-05\n",
      "Epoch 4699, Loss: 0.00015497352615057025, Final Batch Loss: 0.00014904519775882363\n",
      "Epoch 4700, Loss: 0.0003178828152385904, Final Batch Loss: 1.3633504067911417e-06\n",
      "Epoch 4701, Loss: 1.4404859825845051e-05, Final Batch Loss: 1.6318216466970625e-06\n",
      "Epoch 4702, Loss: 5.6826649597496726e-05, Final Batch Loss: 8.151217116392218e-06\n",
      "Epoch 4703, Loss: 6.47437641561055e-05, Final Batch Loss: 1.5740216952053743e-07\n",
      "Epoch 4704, Loss: 3.967962220485788e-05, Final Batch Loss: 2.016794496739749e-05\n",
      "Epoch 4705, Loss: 7.164087219280191e-05, Final Batch Loss: 3.133322388748638e-05\n",
      "Epoch 4706, Loss: 2.7774528462032322e-05, Final Batch Loss: 2.520523594284896e-06\n",
      "Epoch 4707, Loss: 0.0008543794384650027, Final Batch Loss: 1.617939346942876e-06\n",
      "Epoch 4708, Loss: 1.1170285517891898e-05, Final Batch Loss: 6.527496339003847e-07\n",
      "Epoch 4709, Loss: 7.0424415753223e-05, Final Batch Loss: 1.4418699720408767e-05\n",
      "Epoch 4710, Loss: 5.897034314372718e-05, Final Batch Loss: 5.555373761012561e-08\n",
      "Epoch 4711, Loss: 0.001119090709835291, Final Batch Loss: 0.0008144524763338268\n",
      "Epoch 4712, Loss: 0.0008377357135032071, Final Batch Loss: 2.256105472042691e-05\n",
      "Epoch 4713, Loss: 0.0006162580589261779, Final Batch Loss: 0.0006140675977803767\n",
      "Epoch 4714, Loss: 0.00012480832629080396, Final Batch Loss: 0.0001170048417407088\n",
      "Epoch 4715, Loss: 0.00015425198944285512, Final Batch Loss: 8.904422429623082e-05\n",
      "Epoch 4716, Loss: 8.104584139800863e-05, Final Batch Loss: 7.91082584328251e-06\n",
      "Epoch 4717, Loss: 1.2249420024090796e-05, Final Batch Loss: 3.276067900515045e-06\n",
      "Epoch 4718, Loss: 1.5696391869823856e-05, Final Batch Loss: 1.4457607903750613e-05\n",
      "Epoch 4719, Loss: 2.8682276933977846e-05, Final Batch Loss: 8.30445878818864e-06\n",
      "Epoch 4720, Loss: 2.6931582624456496e-05, Final Batch Loss: 1.0288788416801253e-06\n",
      "Epoch 4721, Loss: 0.0045054616493871436, Final Batch Loss: 0.004425049293786287\n",
      "Epoch 4722, Loss: 6.672355834780319e-05, Final Batch Loss: 6.654811386397341e-07\n",
      "Epoch 4723, Loss: 9.924452342602308e-06, Final Batch Loss: 1.8482667201169534e-06\n",
      "Epoch 4724, Loss: 0.00042140460573136806, Final Batch Loss: 5.257880548015237e-05\n",
      "Epoch 4725, Loss: 0.00013200787998357555, Final Batch Loss: 0.0001246319734491408\n",
      "Epoch 4726, Loss: 5.523552135855425e-05, Final Batch Loss: 1.699129461485427e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4727, Loss: 5.963604780845344e-05, Final Batch Loss: 1.7452115571359172e-05\n",
      "Epoch 4728, Loss: 0.00034309553484490607, Final Batch Loss: 0.0003232230374123901\n",
      "Epoch 4729, Loss: 0.000758601920097135, Final Batch Loss: 8.666007488500327e-05\n",
      "Epoch 4730, Loss: 5.5536478612339124e-05, Final Batch Loss: 4.5759297790937126e-06\n",
      "Epoch 4731, Loss: 0.0027032074522139737, Final Batch Loss: 0.0026832004077732563\n",
      "Epoch 4732, Loss: 0.000337342826242093, Final Batch Loss: 0.00029937434010207653\n",
      "Epoch 4733, Loss: 1.2165026191723882e-05, Final Batch Loss: 3.090001655436936e-06\n",
      "Epoch 4734, Loss: 4.231039611113374e-05, Final Batch Loss: 3.489634764264338e-05\n",
      "Epoch 4735, Loss: 5.9722915466409177e-05, Final Batch Loss: 3.065237615373917e-05\n",
      "Epoch 4736, Loss: 0.0005251427537587006, Final Batch Loss: 0.0004968389985151589\n",
      "Epoch 4737, Loss: 0.0014160016280584387, Final Batch Loss: 9.206049981003162e-06\n",
      "Epoch 4738, Loss: 0.0009407322294237019, Final Batch Loss: 6.585404435099917e-07\n",
      "Epoch 4739, Loss: 4.831671049032593e-05, Final Batch Loss: 3.927858415408991e-05\n",
      "Epoch 4740, Loss: 0.00011121027796434646, Final Batch Loss: 0.00010878671309910715\n",
      "Epoch 4741, Loss: 7.563528122034313e-05, Final Batch Loss: 2.0485383345203445e-07\n",
      "Epoch 4742, Loss: 0.0004494940390031843, Final Batch Loss: 3.817566266661743e-06\n",
      "Epoch 4743, Loss: 6.0862594182253815e-05, Final Batch Loss: 4.082930536242202e-05\n",
      "Epoch 4744, Loss: 0.0004208532482152805, Final Batch Loss: 0.0002581146836746484\n",
      "Epoch 4745, Loss: 0.00023908132152428152, Final Batch Loss: 4.104736035515089e-06\n",
      "Epoch 4746, Loss: 0.00014974262194300536, Final Batch Loss: 0.00013280728308018297\n",
      "Epoch 4747, Loss: 0.00014114442456047982, Final Batch Loss: 1.9381288439035416e-05\n",
      "Epoch 4748, Loss: 0.00027403653075452894, Final Batch Loss: 9.808230970520526e-05\n",
      "Epoch 4749, Loss: 3.67888833352481e-06, Final Batch Loss: 2.8701801966235507e-06\n",
      "Epoch 4750, Loss: 0.0003052598694921471, Final Batch Loss: 8.397477358812466e-05\n",
      "Epoch 4751, Loss: 2.8335431807136047e-05, Final Batch Loss: 2.5743622245499864e-05\n",
      "Epoch 4752, Loss: 3.832435322692618e-05, Final Batch Loss: 4.020101187052205e-06\n",
      "Epoch 4753, Loss: 0.00022778268066758756, Final Batch Loss: 0.00020891717576887459\n",
      "Epoch 4754, Loss: 3.291699340479681e-05, Final Batch Loss: 9.95712343865307e-06\n",
      "Epoch 4755, Loss: 0.00039595034104422666, Final Batch Loss: 1.624817741685547e-05\n",
      "Epoch 4756, Loss: 6.808412581449375e-05, Final Batch Loss: 4.239452755427919e-05\n",
      "Epoch 4757, Loss: 1.3673104774625244e-05, Final Batch Loss: 9.14288364128879e-07\n",
      "Epoch 4758, Loss: 0.00015391065971925855, Final Batch Loss: 9.032159869093448e-05\n",
      "Epoch 4759, Loss: 0.00011163979070261121, Final Batch Loss: 3.647783159976825e-05\n",
      "Epoch 4760, Loss: 0.0001222700229845941, Final Batch Loss: 5.640533345285803e-05\n",
      "Epoch 4761, Loss: 0.0008920474938349798, Final Batch Loss: 0.00013149513688404113\n",
      "Epoch 4762, Loss: 7.713885509019747e-06, Final Batch Loss: 6.631515248045616e-07\n",
      "Epoch 4763, Loss: 2.2781186416409582e-05, Final Batch Loss: 1.5277269937996607e-07\n",
      "Epoch 4764, Loss: 5.098878136777785e-05, Final Batch Loss: 3.6422901757759973e-05\n",
      "Epoch 4765, Loss: 7.607445149915293e-05, Final Batch Loss: 9.289738954976201e-06\n",
      "Epoch 4766, Loss: 0.00043363315671740565, Final Batch Loss: 0.000404220016207546\n",
      "Epoch 4767, Loss: 6.994390423642471e-05, Final Batch Loss: 3.369954356458038e-05\n",
      "Epoch 4768, Loss: 1.1950564726248558e-05, Final Batch Loss: 1.0939260391751304e-05\n",
      "Epoch 4769, Loss: 0.004394884802422894, Final Batch Loss: 3.261141500843223e-06\n",
      "Epoch 4770, Loss: 2.3008367293186893e-05, Final Batch Loss: 1.3355614782994962e-06\n",
      "Epoch 4771, Loss: 4.752819535269737e-05, Final Batch Loss: 4.670138150686398e-05\n",
      "Epoch 4772, Loss: 2.8346633371256758e-05, Final Batch Loss: 1.1091536180174444e-05\n",
      "Epoch 4773, Loss: 0.00017204133473569527, Final Batch Loss: 9.028492058860138e-05\n",
      "Epoch 4774, Loss: 2.8627485562537913e-05, Final Batch Loss: 5.208087259234162e-07\n",
      "Epoch 4775, Loss: 2.9086907034070464e-06, Final Batch Loss: 2.222059265477583e-06\n",
      "Epoch 4776, Loss: 0.0015945113627822138, Final Batch Loss: 0.0015253202291205525\n",
      "Epoch 4777, Loss: 0.0005840164303663187, Final Batch Loss: 0.0005757351755164564\n",
      "Epoch 4778, Loss: 0.001697719704679912, Final Batch Loss: 0.001677798107266426\n",
      "Epoch 4779, Loss: 0.0007555224001407623, Final Batch Loss: 0.00011894002091139555\n",
      "Epoch 4780, Loss: 1.7733811546349898e-05, Final Batch Loss: 1.1517231541802175e-05\n",
      "Epoch 4781, Loss: 0.00022523687584907748, Final Batch Loss: 5.684355346602388e-05\n",
      "Epoch 4782, Loss: 0.00015295697085093707, Final Batch Loss: 7.04167177900672e-05\n",
      "Epoch 4783, Loss: 0.0006320203137875069, Final Batch Loss: 7.009966793702915e-06\n",
      "Epoch 4784, Loss: 2.9387408289949235e-05, Final Batch Loss: 2.8388480131980032e-05\n",
      "Epoch 4785, Loss: 4.107123731955653e-05, Final Batch Loss: 2.1293735699146055e-06\n",
      "Epoch 4786, Loss: 3.062827921951339e-06, Final Batch Loss: 3.8193242346551415e-08\n",
      "Epoch 4787, Loss: 2.6063918085128535e-05, Final Batch Loss: 8.430994967056904e-06\n",
      "Epoch 4788, Loss: 7.298408513634058e-05, Final Batch Loss: 7.020802149781957e-05\n",
      "Epoch 4789, Loss: 0.0002103026199620217, Final Batch Loss: 0.00014608782657887787\n",
      "Epoch 4790, Loss: 0.00015210704623314086, Final Batch Loss: 2.47134539677063e-05\n",
      "Epoch 4791, Loss: 0.00029096169191689114, Final Batch Loss: 0.0002849077864084393\n",
      "Epoch 4792, Loss: 3.127298555227753e-05, Final Batch Loss: 2.8164729883428663e-05\n",
      "Epoch 4793, Loss: 7.951611337375653e-06, Final Batch Loss: 6.555569598276634e-06\n",
      "Epoch 4794, Loss: 0.0017383814411005005, Final Batch Loss: 0.0016663074493408203\n",
      "Epoch 4795, Loss: 5.31729915564938e-06, Final Batch Loss: 2.0912352738378104e-06\n",
      "Epoch 4796, Loss: 6.4378766637673834e-06, Final Batch Loss: 1.654951347518363e-06\n",
      "Epoch 4797, Loss: 0.0011081600678153336, Final Batch Loss: 0.0008781509823165834\n",
      "Epoch 4798, Loss: 6.363780795481944e-05, Final Batch Loss: 6.294355262070894e-05\n",
      "Epoch 4799, Loss: 9.329655040346552e-05, Final Batch Loss: 9.929808584274724e-07\n",
      "Epoch 4800, Loss: 0.0003958330800060139, Final Batch Loss: 1.7880539644465898e-06\n",
      "Epoch 4801, Loss: 2.020013607761939e-05, Final Batch Loss: 1.9246992451371625e-05\n",
      "Epoch 4802, Loss: 1.025811627641815e-06, Final Batch Loss: 7.025181503195199e-07\n",
      "Epoch 4803, Loss: 5.3124738769838586e-05, Final Batch Loss: 2.696065348573029e-05\n",
      "Epoch 4804, Loss: 2.5209680416082847e-05, Final Batch Loss: 2.3284870621864684e-05\n",
      "Epoch 4805, Loss: 1.111157189370715e-05, Final Batch Loss: 2.4603564270364586e-06\n",
      "Epoch 4806, Loss: 9.643225780564535e-06, Final Batch Loss: 1.7001055994114722e-06\n",
      "Epoch 4807, Loss: 5.347465275917784e-06, Final Batch Loss: 1.0982860203512246e-06\n",
      "Epoch 4808, Loss: 0.0013609026091785381, Final Batch Loss: 0.0013602941762655973\n",
      "Epoch 4809, Loss: 7.0356220476242015e-06, Final Batch Loss: 1.976646899493062e-06\n",
      "Epoch 4810, Loss: 0.0001152362547145458, Final Batch Loss: 3.4055792639264837e-06\n",
      "Epoch 4811, Loss: 1.4797841629388131e-05, Final Batch Loss: 1.4043512237549294e-05\n",
      "Epoch 4812, Loss: 9.175621107715415e-05, Final Batch Loss: 4.800979695573915e-06\n",
      "Epoch 4813, Loss: 2.0177174633317918e-05, Final Batch Loss: 1.6862251186466892e-06\n",
      "Epoch 4814, Loss: 0.00010065263995784335, Final Batch Loss: 5.848833097843453e-06\n",
      "Epoch 4815, Loss: 0.0009236880325147467, Final Batch Loss: 6.782103696423292e-07\n",
      "Epoch 4816, Loss: 1.9257687711160543e-06, Final Batch Loss: 1.7591926848581352e-07\n",
      "Epoch 4817, Loss: 5.375969067245023e-06, Final Batch Loss: 1.2557279660541099e-06\n",
      "Epoch 4818, Loss: 6.998194066909491e-06, Final Batch Loss: 4.659690148400841e-06\n",
      "Epoch 4819, Loss: 1.1087888196925633e-05, Final Batch Loss: 2.019444764300715e-06\n",
      "Epoch 4820, Loss: 1.3577156323663075e-05, Final Batch Loss: 2.7450644211057806e-06\n",
      "Epoch 4821, Loss: 7.828589468772407e-05, Final Batch Loss: 7.107898272806779e-05\n",
      "Epoch 4822, Loss: 9.578001431975736e-06, Final Batch Loss: 6.597014845510785e-08\n",
      "Epoch 4823, Loss: 4.643292413675226e-05, Final Batch Loss: 2.7813071937998757e-05\n",
      "Epoch 4824, Loss: 3.112867601728908e-05, Final Batch Loss: 1.9675315598988163e-08\n",
      "Epoch 4825, Loss: 2.91976488142609e-06, Final Batch Loss: 2.6327138584747445e-06\n",
      "Epoch 4826, Loss: 1.895624149028663e-05, Final Batch Loss: 1.8141354303224944e-05\n",
      "Epoch 4827, Loss: 3.5251653571322095e-05, Final Batch Loss: 1.3386966202233452e-05\n",
      "Epoch 4828, Loss: 9.658058274908399e-06, Final Batch Loss: 1.629461053198611e-06\n",
      "Epoch 4829, Loss: 2.7842450606385682e-05, Final Batch Loss: 2.7660843215926434e-07\n",
      "Epoch 4830, Loss: 0.0009489106269029435, Final Batch Loss: 4.917234036838636e-06\n",
      "Epoch 4831, Loss: 9.328892883786466e-05, Final Batch Loss: 1.535791489004623e-05\n",
      "Epoch 4832, Loss: 0.00023326730070039048, Final Batch Loss: 4.987710326531669e-06\n",
      "Epoch 4833, Loss: 0.0007382174251233664, Final Batch Loss: 2.153729610654409e-06\n",
      "Epoch 4834, Loss: 1.6804517940727237e-05, Final Batch Loss: 1.538607648399193e-05\n",
      "Epoch 4835, Loss: 1.8348968751524808e-05, Final Batch Loss: 1.6857062291819602e-05\n",
      "Epoch 4836, Loss: 1.5394484023545374e-05, Final Batch Loss: 5.393268907027959e-07\n",
      "Epoch 4837, Loss: 0.00029633872600243194, Final Batch Loss: 0.0002899712708313018\n",
      "Epoch 4838, Loss: 1.1157579280052232e-05, Final Batch Loss: 4.027607758416707e-07\n",
      "Epoch 4839, Loss: 1.4285586757978308e-06, Final Batch Loss: 6.041426559022511e-07\n",
      "Epoch 4840, Loss: 0.00033873619395308197, Final Batch Loss: 0.000172977612237446\n",
      "Epoch 4841, Loss: 0.0005055512156104669, Final Batch Loss: 5.5643540690653026e-05\n",
      "Epoch 4842, Loss: 0.0013545437350330758, Final Batch Loss: 1.1874462870764546e-06\n",
      "Epoch 4843, Loss: 0.00022626187478635984, Final Batch Loss: 3.2113841825776035e-06\n",
      "Epoch 4844, Loss: 9.631111242924817e-05, Final Batch Loss: 4.723759411717765e-05\n",
      "Epoch 4845, Loss: 5.9429612520034425e-06, Final Batch Loss: 2.9161731163185323e-06\n",
      "Epoch 4846, Loss: 1.4136513073026435e-05, Final Batch Loss: 6.311649940471398e-06\n",
      "Epoch 4847, Loss: 0.0001457198231946677, Final Batch Loss: 1.3668090105056763e-05\n",
      "Epoch 4848, Loss: 9.635979495214997e-06, Final Batch Loss: 5.172251348994905e-06\n",
      "Epoch 4849, Loss: 0.00011979449118371122, Final Batch Loss: 7.97099492046982e-05\n",
      "Epoch 4850, Loss: 5.154597351975099e-05, Final Batch Loss: 3.2797627227409976e-06\n",
      "Epoch 4851, Loss: 5.973028328298824e-05, Final Batch Loss: 1.3336580195755232e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4852, Loss: 0.0013481458299793303, Final Batch Loss: 0.0004651483613997698\n",
      "Epoch 4853, Loss: 6.519692405504429e-06, Final Batch Loss: 1.817062269537928e-07\n",
      "Epoch 4854, Loss: 1.975876875803806e-05, Final Batch Loss: 2.0692805264843628e-06\n",
      "Epoch 4855, Loss: 0.005558316770475358, Final Batch Loss: 0.005413779988884926\n",
      "Epoch 4856, Loss: 4.7283838853218185e-06, Final Batch Loss: 8.124525834318774e-07\n",
      "Epoch 4857, Loss: 2.759882772807032e-05, Final Batch Loss: 1.8806722437147982e-05\n",
      "Epoch 4858, Loss: 0.00015179152478594915, Final Batch Loss: 2.410585238976637e-06\n",
      "Epoch 4859, Loss: 4.7451021600863896e-05, Final Batch Loss: 2.324895831407048e-06\n",
      "Epoch 4860, Loss: 2.9620049645018298e-05, Final Batch Loss: 9.857337317953352e-06\n",
      "Epoch 4861, Loss: 1.5452848572294897e-05, Final Batch Loss: 8.795884127721365e-07\n",
      "Epoch 4862, Loss: 2.493211013643304e-05, Final Batch Loss: 2.3146067178458907e-06\n",
      "Epoch 4863, Loss: 4.822619075639523e-06, Final Batch Loss: 1.3100873275107006e-06\n",
      "Epoch 4864, Loss: 0.0005769128899402176, Final Batch Loss: 2.3841739960062114e-07\n",
      "Epoch 4865, Loss: 0.01580160741286818, Final Batch Loss: 0.015604282729327679\n",
      "Epoch 4866, Loss: 0.0019285348589619389, Final Batch Loss: 0.0019256450468674302\n",
      "Epoch 4867, Loss: 3.6065147241970408e-06, Final Batch Loss: 1.8748739876173204e-06\n",
      "Epoch 4868, Loss: 2.6927233989226806e-06, Final Batch Loss: 7.27967233160598e-07\n",
      "Epoch 4869, Loss: 8.974156662588939e-05, Final Batch Loss: 8.827817509882152e-06\n",
      "Epoch 4870, Loss: 0.0011008825034934944, Final Batch Loss: 4.027619127100479e-07\n",
      "Epoch 4871, Loss: 0.003190952166733041, Final Batch Loss: 0.003186106448993087\n",
      "Epoch 4872, Loss: 3.226373610232258e-05, Final Batch Loss: 1.0611848665575963e-05\n",
      "Epoch 4873, Loss: 7.66101788940432e-06, Final Batch Loss: 2.422297939119744e-06\n",
      "Epoch 4874, Loss: 3.945156640838832e-05, Final Batch Loss: 2.0328086975496262e-05\n",
      "Epoch 4875, Loss: 0.0002213785337517038, Final Batch Loss: 9.772411431185901e-05\n",
      "Epoch 4876, Loss: 4.601523949077091e-05, Final Batch Loss: 1.6838374676808598e-06\n",
      "Epoch 4877, Loss: 7.539571197412442e-05, Final Batch Loss: 4.896166137768887e-05\n",
      "Epoch 4878, Loss: 0.00010207350715063512, Final Batch Loss: 4.309695941628888e-05\n",
      "Epoch 4879, Loss: 0.00020058916561538354, Final Batch Loss: 0.00012782608973793685\n",
      "Epoch 4880, Loss: 2.0413306174305035e-05, Final Batch Loss: 4.336945039540296e-06\n",
      "Epoch 4881, Loss: 0.00324201332841767, Final Batch Loss: 0.003192291595041752\n",
      "Epoch 4882, Loss: 0.0002713496687647421, Final Batch Loss: 0.00023530799080617726\n",
      "Epoch 4883, Loss: 0.0024509342038072646, Final Batch Loss: 0.0004933721502311528\n",
      "Epoch 4884, Loss: 2.1939328235021094e-05, Final Batch Loss: 5.2284726734797005e-06\n",
      "Epoch 4885, Loss: 1.8394513972452842e-05, Final Batch Loss: 1.0346737326472066e-05\n",
      "Epoch 4886, Loss: 0.00031724840732749726, Final Batch Loss: 0.00031438935548067093\n",
      "Epoch 4887, Loss: 4.3519879909581505e-05, Final Batch Loss: 2.625137312861625e-05\n",
      "Epoch 4888, Loss: 5.363571040106763e-05, Final Batch Loss: 2.561114570198697e-06\n",
      "Epoch 4889, Loss: 0.00011179459215782117, Final Batch Loss: 1.1215362974326126e-05\n",
      "Epoch 4890, Loss: 1.2386894468363607e-05, Final Batch Loss: 3.857102910842514e-06\n",
      "Epoch 4891, Loss: 3.085363414356834e-05, Final Batch Loss: 4.44618808614905e-06\n",
      "Epoch 4892, Loss: 3.2136655136127956e-05, Final Batch Loss: 2.81229404208716e-06\n",
      "Epoch 4893, Loss: 9.199886517308187e-05, Final Batch Loss: 8.790503488853574e-05\n",
      "Epoch 4894, Loss: 1.09159911403367e-05, Final Batch Loss: 4.40955943759036e-07\n",
      "Epoch 4895, Loss: 1.811678021113039e-05, Final Batch Loss: 6.0126135394966695e-06\n",
      "Epoch 4896, Loss: 0.0003106875064986525, Final Batch Loss: 0.0002872830955311656\n",
      "Epoch 4897, Loss: 3.175674282829277e-05, Final Batch Loss: 2.255447361676488e-05\n",
      "Epoch 4898, Loss: 2.5955371256713988e-05, Final Batch Loss: 2.507420867914334e-05\n",
      "Epoch 4899, Loss: 4.072776391694788e-06, Final Batch Loss: 3.039023340534186e-06\n",
      "Epoch 4900, Loss: 0.0002334774517294136, Final Batch Loss: 4.8545962272328325e-06\n",
      "Epoch 4901, Loss: 1.3851415928911592e-05, Final Batch Loss: 1.362181933473039e-06\n",
      "Epoch 4902, Loss: 0.0002824008215611684, Final Batch Loss: 7.913807166914921e-06\n",
      "Epoch 4903, Loss: 2.5314992853964213e-05, Final Batch Loss: 1.1438323781476356e-05\n",
      "Epoch 4904, Loss: 0.00017047809888026677, Final Batch Loss: 3.248035136493854e-05\n",
      "Epoch 4905, Loss: 3.86402125513996e-05, Final Batch Loss: 1.4533746252709534e-05\n",
      "Epoch 4906, Loss: 6.733937789249467e-05, Final Batch Loss: 5.968836376268882e-06\n",
      "Epoch 4907, Loss: 4.149548567511374e-05, Final Batch Loss: 1.4831962289463263e-05\n",
      "Epoch 4908, Loss: 0.00026055889611598104, Final Batch Loss: 0.0001546313869766891\n",
      "Epoch 4909, Loss: 2.68558032985311e-05, Final Batch Loss: 1.7873268006951548e-05\n",
      "Epoch 4910, Loss: 0.0014099900363362394, Final Batch Loss: 0.0013016777811571956\n",
      "Epoch 4911, Loss: 8.967251460489933e-06, Final Batch Loss: 7.432480742863845e-06\n",
      "Epoch 4912, Loss: 9.387272802996449e-05, Final Batch Loss: 4.423480640980415e-05\n",
      "Epoch 4913, Loss: 4.3404734242358245e-05, Final Batch Loss: 1.3816474165651016e-05\n",
      "Epoch 4914, Loss: 0.003251714166253805, Final Batch Loss: 0.0021723988465964794\n",
      "Epoch 4915, Loss: 6.251418562897015e-05, Final Batch Loss: 5.872827387065627e-06\n",
      "Epoch 4916, Loss: 7.592659670763169e-05, Final Batch Loss: 5.69416386042576e-07\n",
      "Epoch 4917, Loss: 0.00024508018759661354, Final Batch Loss: 2.979872078867629e-06\n",
      "Epoch 4918, Loss: 2.6388295736978762e-05, Final Batch Loss: 2.2891545086167753e-05\n",
      "Epoch 4919, Loss: 7.015775281615788e-06, Final Batch Loss: 1.4466163520410191e-06\n",
      "Epoch 4920, Loss: 2.791458882711595e-05, Final Batch Loss: 1.0490078238944989e-05\n",
      "Epoch 4921, Loss: 0.0005664575516561854, Final Batch Loss: 3.807733151006687e-07\n",
      "Epoch 4922, Loss: 0.00017903558324405822, Final Batch Loss: 9.28188057969237e-07\n",
      "Epoch 4923, Loss: 5.9128841712663416e-05, Final Batch Loss: 5.70431166124763e-06\n",
      "Epoch 4924, Loss: 0.0009514879549215038, Final Batch Loss: 0.0009510440286248922\n",
      "Epoch 4925, Loss: 1.264577595350147e-05, Final Batch Loss: 4.6294829303406004e-08\n",
      "Epoch 4926, Loss: 8.639561315249011e-06, Final Batch Loss: 5.717330395782483e-07\n",
      "Epoch 4927, Loss: 6.631441192439524e-05, Final Batch Loss: 9.783786481420975e-06\n",
      "Epoch 4928, Loss: 1.5626945696567418e-05, Final Batch Loss: 6.609138381463708e-06\n",
      "Epoch 4929, Loss: 0.00029267155878187623, Final Batch Loss: 2.4497077902196907e-05\n",
      "Epoch 4930, Loss: 0.00015386474115075544, Final Batch Loss: 0.000130548607558012\n",
      "Epoch 4931, Loss: 3.668681893032044e-05, Final Batch Loss: 5.427620635600761e-06\n",
      "Epoch 4932, Loss: 0.00016132747805386316, Final Batch Loss: 2.6906154744210653e-05\n",
      "Epoch 4933, Loss: 2.3139678887673654e-05, Final Batch Loss: 8.312909812957514e-06\n",
      "Epoch 4934, Loss: 3.941719251088216e-05, Final Batch Loss: 2.621288786031073e-06\n",
      "Epoch 4935, Loss: 0.0009734368377394276, Final Batch Loss: 0.0009722390677779913\n",
      "Epoch 4936, Loss: 4.079706832271768e-05, Final Batch Loss: 1.3760399269813206e-05\n",
      "Epoch 4937, Loss: 2.4065028128461563e-05, Final Batch Loss: 3.1662514174968237e-06\n",
      "Epoch 4938, Loss: 0.0001918697016662918, Final Batch Loss: 1.5265373804140836e-05\n",
      "Epoch 4939, Loss: 1.8344310547036002e-05, Final Batch Loss: 2.5218403152393876e-06\n",
      "Epoch 4940, Loss: 1.7840202190200216e-05, Final Batch Loss: 1.8378484583081445e-06\n",
      "Epoch 4941, Loss: 7.313974674616475e-05, Final Batch Loss: 4.681790233007632e-05\n",
      "Epoch 4942, Loss: 1.352715878510935e-05, Final Batch Loss: 1.2244986464793328e-05\n",
      "Epoch 4943, Loss: 3.3828233881649794e-05, Final Batch Loss: 3.241874946979806e-05\n",
      "Epoch 4944, Loss: 8.373062155442312e-05, Final Batch Loss: 2.5100056518567726e-05\n",
      "Epoch 4945, Loss: 1.4695216577820247e-05, Final Batch Loss: 4.152263045398286e-06\n",
      "Epoch 4946, Loss: 2.693069427550654e-05, Final Batch Loss: 4.9645018407318275e-06\n",
      "Epoch 4947, Loss: 4.2755055119414465e-05, Final Batch Loss: 2.9568584523076424e-06\n",
      "Epoch 4948, Loss: 0.00034881132751252153, Final Batch Loss: 0.0003433121892157942\n",
      "Epoch 4949, Loss: 0.00018528417786001228, Final Batch Loss: 0.00016520994540769607\n",
      "Epoch 4950, Loss: 2.1528181150642922e-05, Final Batch Loss: 1.9248127500759438e-05\n",
      "Epoch 4951, Loss: 0.00017465519704273902, Final Batch Loss: 2.3615673853782937e-05\n",
      "Epoch 4952, Loss: 3.165633370372234e-05, Final Batch Loss: 9.918995601765346e-06\n",
      "Epoch 4953, Loss: 0.001761505423928611, Final Batch Loss: 0.0017101031262427568\n",
      "Epoch 4954, Loss: 2.503295399947092e-05, Final Batch Loss: 1.007033006317215e-05\n",
      "Epoch 4955, Loss: 9.87936635965525e-06, Final Batch Loss: 4.0044886873147334e-07\n",
      "Epoch 4956, Loss: 3.819081302935956e-05, Final Batch Loss: 9.917967872752342e-06\n",
      "Epoch 4957, Loss: 1.977000124497863e-05, Final Batch Loss: 1.6351008525816724e-05\n",
      "Epoch 4958, Loss: 4.9230752665607724e-05, Final Batch Loss: 3.926304088963661e-06\n",
      "Epoch 4959, Loss: 0.00012979137045476818, Final Batch Loss: 1.0124263098987285e-05\n",
      "Epoch 4960, Loss: 0.0010174630442634225, Final Batch Loss: 0.0003176304162479937\n",
      "Epoch 4961, Loss: 0.0011893307500940864, Final Batch Loss: 0.0011792677687481046\n",
      "Epoch 4962, Loss: 2.3268585209734738e-05, Final Batch Loss: 1.672346297709737e-05\n",
      "Epoch 4963, Loss: 0.0003514174895826727, Final Batch Loss: 3.366303280927241e-05\n",
      "Epoch 4964, Loss: 0.00011139756861666683, Final Batch Loss: 1.2230508218635805e-05\n",
      "Epoch 4965, Loss: 5.0147629735874943e-05, Final Batch Loss: 2.03950512513984e-05\n",
      "Epoch 4966, Loss: 2.459239840391092e-05, Final Batch Loss: 2.535502062528394e-06\n",
      "Epoch 4967, Loss: 0.0005208105458223145, Final Batch Loss: 8.215490197471809e-06\n",
      "Epoch 4968, Loss: 0.0005524146495190507, Final Batch Loss: 4.818919933313737e-06\n",
      "Epoch 4969, Loss: 1.3579574442701414e-05, Final Batch Loss: 8.99212682270445e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4970, Loss: 4.173235811322229e-05, Final Batch Loss: 6.314520760497544e-06\n",
      "Epoch 4971, Loss: 7.813574939063983e-06, Final Batch Loss: 2.290265456394991e-06\n",
      "Epoch 4972, Loss: 2.0552600062728743e-05, Final Batch Loss: 9.918319392454578e-07\n",
      "Epoch 4973, Loss: 4.379746229687953e-06, Final Batch Loss: 2.835544421486702e-07\n",
      "Epoch 4974, Loss: 0.00014534183719661087, Final Batch Loss: 6.58183271298185e-05\n",
      "Epoch 4975, Loss: 1.6155144294316415e-05, Final Batch Loss: 8.032742698560469e-06\n",
      "Epoch 4976, Loss: 0.00010563291709786427, Final Batch Loss: 0.00010398979793535545\n",
      "Epoch 4977, Loss: 0.001713102768007957, Final Batch Loss: 0.0017050206661224365\n",
      "Epoch 4978, Loss: 3.0863110680456884e-05, Final Batch Loss: 2.777679242171871e-07\n",
      "Epoch 4979, Loss: 0.0013899602379296994, Final Batch Loss: 1.1711997558450093e-06\n",
      "Epoch 4980, Loss: 5.856068071352638e-06, Final Batch Loss: 7.349235033871082e-07\n",
      "Epoch 4981, Loss: 2.533074530219892e-05, Final Batch Loss: 1.7548743926454335e-05\n",
      "Epoch 4982, Loss: 0.00028315792042121757, Final Batch Loss: 1.8799242752720602e-05\n",
      "Epoch 4983, Loss: 3.928217495285935e-06, Final Batch Loss: 3.356028628331842e-06\n",
      "Epoch 4984, Loss: 5.3489150559471454e-05, Final Batch Loss: 1.016199075820623e-05\n",
      "Epoch 4985, Loss: 0.00020800080892513506, Final Batch Loss: 0.00016784769832156599\n",
      "Epoch 4986, Loss: 2.9394620923994808e-06, Final Batch Loss: 7.349156021518866e-07\n",
      "Epoch 4987, Loss: 3.6983316249461495e-06, Final Batch Loss: 2.4557532469771104e-06\n",
      "Epoch 4988, Loss: 5.843356598234095e-05, Final Batch Loss: 3.330636218379368e-06\n",
      "Epoch 4989, Loss: 1.4584307336917846e-05, Final Batch Loss: 1.1866142813232727e-05\n",
      "Epoch 4990, Loss: 1.1706810596479045e-05, Final Batch Loss: 9.924069672706537e-06\n",
      "Epoch 4991, Loss: 4.8060453138987214e-05, Final Batch Loss: 1.2615333844223642e-07\n",
      "Epoch 4992, Loss: 0.0001366232718282845, Final Batch Loss: 8.611347584519535e-05\n",
      "Epoch 4993, Loss: 1.2735030395560898e-05, Final Batch Loss: 5.304387741489336e-06\n",
      "Epoch 4994, Loss: 1.0450472018419532e-05, Final Batch Loss: 3.3074543352995533e-06\n",
      "Epoch 4995, Loss: 4.649738912121393e-05, Final Batch Loss: 4.173757406533696e-05\n",
      "Epoch 4996, Loss: 4.1074547880270984e-05, Final Batch Loss: 3.0330058507388458e-05\n",
      "Epoch 4997, Loss: 0.00011232475299038924, Final Batch Loss: 8.952669304562733e-06\n",
      "Epoch 4998, Loss: 9.13695846520568e-05, Final Batch Loss: 9.02133688214235e-05\n",
      "Epoch 4999, Loss: 1.6838125247886637e-05, Final Batch Loss: 4.263335995347006e-06\n",
      "Epoch 5000, Loss: 0.000871982559914386, Final Batch Loss: 2.650375279245054e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  0  0]\n",
      " [ 0 24  0]\n",
      " [ 0  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        34\n",
      "           1    1.00000   1.00000   1.00000        24\n",
      "           2    1.00000   1.00000   1.00000        31\n",
      "\n",
      "    accuracy                        1.00000        89\n",
      "   macro avg    1.00000   1.00000   1.00000        89\n",
      "weighted avg    1.00000   1.00000   1.00000        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples) + 1\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_4 = np.ones(n_samples) + 2\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_5 = np.ones(n_samples) + 3\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_6 = np.ones(n_samples) + 4\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_7 = np.ones(n_samples) + 5\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_8 = np.ones(n_samples) + 6\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_9 = np.ones(n_samples) + 7\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_10 = np.ones(n_samples) + 8\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_11 = np.ones(n_samples) + 9\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_12 = np.ones(n_samples) + 10\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3, y_4, y_5, y_6, y_7, y_8, y_9, y_10, y_11, y_12))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 0 30  0]\n",
      " [ 0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   1.00000   1.00000        30\n",
      "         1.0    1.00000   1.00000   1.00000        30\n",
      "         2.0    1.00000   1.00000   1.00000        30\n",
      "\n",
      "    accuracy                        1.00000        90\n",
      "   macro avg    1.00000   1.00000   1.00000        90\n",
      "weighted avg    1.00000   1.00000   1.00000        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [7, 8, 11]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 7:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.1934168338775635, Final Batch Loss: 2.082148790359497\n",
      "Epoch 2, Loss: 4.190881967544556, Final Batch Loss: 2.1059324741363525\n",
      "Epoch 3, Loss: 4.166425704956055, Final Batch Loss: 2.0846848487854004\n",
      "Epoch 4, Loss: 4.16010046005249, Final Batch Loss: 2.094223976135254\n",
      "Epoch 5, Loss: 4.137653589248657, Final Batch Loss: 2.0719170570373535\n",
      "Epoch 6, Loss: 4.123960494995117, Final Batch Loss: 2.0641279220581055\n",
      "Epoch 7, Loss: 4.1096351146698, Final Batch Loss: 2.052764415740967\n",
      "Epoch 8, Loss: 4.102541923522949, Final Batch Loss: 2.058190107345581\n",
      "Epoch 9, Loss: 4.084380865097046, Final Batch Loss: 2.037447690963745\n",
      "Epoch 10, Loss: 4.076278448104858, Final Batch Loss: 2.038702964782715\n",
      "Epoch 11, Loss: 4.067895889282227, Final Batch Loss: 2.038447618484497\n",
      "Epoch 12, Loss: 4.047670841217041, Final Batch Loss: 2.0226809978485107\n",
      "Epoch 13, Loss: 4.026986837387085, Final Batch Loss: 2.007044553756714\n",
      "Epoch 14, Loss: 4.016131162643433, Final Batch Loss: 2.002532482147217\n",
      "Epoch 15, Loss: 3.999916672706604, Final Batch Loss: 1.992470145225525\n",
      "Epoch 16, Loss: 3.984263777732849, Final Batch Loss: 1.98480224609375\n",
      "Epoch 17, Loss: 3.97398042678833, Final Batch Loss: 1.9874225854873657\n",
      "Epoch 18, Loss: 3.957501173019409, Final Batch Loss: 1.97836434841156\n",
      "Epoch 19, Loss: 3.9300628900527954, Final Batch Loss: 1.9563086032867432\n",
      "Epoch 20, Loss: 3.907932162284851, Final Batch Loss: 1.9541926383972168\n",
      "Epoch 21, Loss: 3.870391368865967, Final Batch Loss: 1.9280427694320679\n",
      "Epoch 22, Loss: 3.853545069694519, Final Batch Loss: 1.9227354526519775\n",
      "Epoch 23, Loss: 3.7983131408691406, Final Batch Loss: 1.9002571105957031\n",
      "Epoch 24, Loss: 3.7194480895996094, Final Batch Loss: 1.8409113883972168\n",
      "Epoch 25, Loss: 3.7056983709335327, Final Batch Loss: 1.8538732528686523\n",
      "Epoch 26, Loss: 3.6479690074920654, Final Batch Loss: 1.8330159187316895\n",
      "Epoch 27, Loss: 3.546879291534424, Final Batch Loss: 1.759873628616333\n",
      "Epoch 28, Loss: 3.48967444896698, Final Batch Loss: 1.7396161556243896\n",
      "Epoch 29, Loss: 3.3825877904891968, Final Batch Loss: 1.6546529531478882\n",
      "Epoch 30, Loss: 3.320206880569458, Final Batch Loss: 1.6598066091537476\n",
      "Epoch 31, Loss: 3.2692352533340454, Final Batch Loss: 1.6439281702041626\n",
      "Epoch 32, Loss: 3.138361692428589, Final Batch Loss: 1.5423351526260376\n",
      "Epoch 33, Loss: 3.0747365951538086, Final Batch Loss: 1.4768937826156616\n",
      "Epoch 34, Loss: 3.0033522844314575, Final Batch Loss: 1.5103381872177124\n",
      "Epoch 35, Loss: 2.9718434810638428, Final Batch Loss: 1.433946967124939\n",
      "Epoch 36, Loss: 2.867024064064026, Final Batch Loss: 1.3816670179367065\n",
      "Epoch 37, Loss: 2.8755393028259277, Final Batch Loss: 1.385966420173645\n",
      "Epoch 38, Loss: 2.77354896068573, Final Batch Loss: 1.3856940269470215\n",
      "Epoch 39, Loss: 2.863348603248596, Final Batch Loss: 1.4928747415542603\n",
      "Epoch 40, Loss: 2.573965907096863, Final Batch Loss: 1.281798005104065\n",
      "Epoch 41, Loss: 2.731931447982788, Final Batch Loss: 1.2984960079193115\n",
      "Epoch 42, Loss: 2.5062085390090942, Final Batch Loss: 1.2241976261138916\n",
      "Epoch 43, Loss: 2.68564236164093, Final Batch Loss: 1.3891334533691406\n",
      "Epoch 44, Loss: 2.584904909133911, Final Batch Loss: 1.2651041746139526\n",
      "Epoch 45, Loss: 2.519824504852295, Final Batch Loss: 1.263096809387207\n",
      "Epoch 46, Loss: 2.5508512258529663, Final Batch Loss: 1.220702886581421\n",
      "Epoch 47, Loss: 2.5848664045333862, Final Batch Loss: 1.3065136671066284\n",
      "Epoch 48, Loss: 2.5464354753494263, Final Batch Loss: 1.2822121381759644\n",
      "Epoch 49, Loss: 2.5868343114852905, Final Batch Loss: 1.3030755519866943\n",
      "Epoch 50, Loss: 2.448531985282898, Final Batch Loss: 1.246763825416565\n",
      "Epoch 51, Loss: 2.445886015892029, Final Batch Loss: 1.1712909936904907\n",
      "Epoch 52, Loss: 2.5938870906829834, Final Batch Loss: 1.3010951280593872\n",
      "Epoch 53, Loss: 2.454580307006836, Final Batch Loss: 1.2124369144439697\n",
      "Epoch 54, Loss: 2.506717324256897, Final Batch Loss: 1.2382844686508179\n",
      "Epoch 55, Loss: 2.4725853204727173, Final Batch Loss: 1.2348889112472534\n",
      "Epoch 56, Loss: 2.5999869108200073, Final Batch Loss: 1.309130311012268\n",
      "Epoch 57, Loss: 2.463319420814514, Final Batch Loss: 1.2437994480133057\n",
      "Epoch 58, Loss: 2.427358388900757, Final Batch Loss: 1.1637300252914429\n",
      "Epoch 59, Loss: 2.4532934427261353, Final Batch Loss: 1.2062952518463135\n",
      "Epoch 60, Loss: 2.4645419120788574, Final Batch Loss: 1.2312942743301392\n",
      "Epoch 61, Loss: 2.37796151638031, Final Batch Loss: 1.176957368850708\n",
      "Epoch 62, Loss: 2.409699320793152, Final Batch Loss: 1.1967331171035767\n",
      "Epoch 63, Loss: 2.486737608909607, Final Batch Loss: 1.198484182357788\n",
      "Epoch 64, Loss: 2.493780255317688, Final Batch Loss: 1.3046114444732666\n",
      "Epoch 65, Loss: 2.3711074590682983, Final Batch Loss: 1.167129635810852\n",
      "Epoch 66, Loss: 2.529924750328064, Final Batch Loss: 1.2865049839019775\n",
      "Epoch 67, Loss: 2.4349019527435303, Final Batch Loss: 1.2342753410339355\n",
      "Epoch 68, Loss: 2.3416497707366943, Final Batch Loss: 1.1762440204620361\n",
      "Epoch 69, Loss: 2.390681505203247, Final Batch Loss: 1.1692932844161987\n",
      "Epoch 70, Loss: 2.3775702714920044, Final Batch Loss: 1.1341904401779175\n",
      "Epoch 71, Loss: 2.373868942260742, Final Batch Loss: 1.1921969652175903\n",
      "Epoch 72, Loss: 2.391383171081543, Final Batch Loss: 1.2156800031661987\n",
      "Epoch 73, Loss: 2.3534750938415527, Final Batch Loss: 1.154667615890503\n",
      "Epoch 74, Loss: 2.358053207397461, Final Batch Loss: 1.1960747241973877\n",
      "Epoch 75, Loss: 2.3792608976364136, Final Batch Loss: 1.2305084466934204\n",
      "Epoch 76, Loss: 2.3543753623962402, Final Batch Loss: 1.1801813840866089\n",
      "Epoch 77, Loss: 2.408949613571167, Final Batch Loss: 1.2139170169830322\n",
      "Epoch 78, Loss: 2.312563419342041, Final Batch Loss: 1.1441234350204468\n",
      "Epoch 79, Loss: 2.3455780744552612, Final Batch Loss: 1.1651155948638916\n",
      "Epoch 80, Loss: 2.3391308784484863, Final Batch Loss: 1.1535505056381226\n",
      "Epoch 81, Loss: 2.4254069328308105, Final Batch Loss: 1.2380565404891968\n",
      "Epoch 82, Loss: 2.2393639087677, Final Batch Loss: 1.1200209856033325\n",
      "Epoch 83, Loss: 2.2506195306777954, Final Batch Loss: 1.1087396144866943\n",
      "Epoch 84, Loss: 2.2728980779647827, Final Batch Loss: 1.1654229164123535\n",
      "Epoch 85, Loss: 2.312112331390381, Final Batch Loss: 1.1456965208053589\n",
      "Epoch 86, Loss: 2.3024097681045532, Final Batch Loss: 1.1753827333450317\n",
      "Epoch 87, Loss: 2.2981433868408203, Final Batch Loss: 1.1419765949249268\n",
      "Epoch 88, Loss: 2.3023699522018433, Final Batch Loss: 1.1520286798477173\n",
      "Epoch 89, Loss: 2.249072790145874, Final Batch Loss: 1.1100877523422241\n",
      "Epoch 90, Loss: 2.3085821866989136, Final Batch Loss: 1.1561146974563599\n",
      "Epoch 91, Loss: 2.253874897956848, Final Batch Loss: 1.1102062463760376\n",
      "Epoch 92, Loss: 2.2384177446365356, Final Batch Loss: 1.1305744647979736\n",
      "Epoch 93, Loss: 2.2900975942611694, Final Batch Loss: 1.1558810472488403\n",
      "Epoch 94, Loss: 2.2580111026763916, Final Batch Loss: 1.1577292680740356\n",
      "Epoch 95, Loss: 2.2095723152160645, Final Batch Loss: 1.092085599899292\n",
      "Epoch 96, Loss: 2.2676000595092773, Final Batch Loss: 1.124969244003296\n",
      "Epoch 97, Loss: 2.2029709815979004, Final Batch Loss: 1.073432207107544\n",
      "Epoch 98, Loss: 2.1902964115142822, Final Batch Loss: 1.0809264183044434\n",
      "Epoch 99, Loss: 2.23082172870636, Final Batch Loss: 1.1404187679290771\n",
      "Epoch 100, Loss: 2.2117408514022827, Final Batch Loss: 1.0986807346343994\n",
      "Epoch 101, Loss: 2.2430540323257446, Final Batch Loss: 1.140107274055481\n",
      "Epoch 102, Loss: 2.166245698928833, Final Batch Loss: 1.0679819583892822\n",
      "Epoch 103, Loss: 2.1170148849487305, Final Batch Loss: 1.0462473630905151\n",
      "Epoch 104, Loss: 2.121645927429199, Final Batch Loss: 1.0520853996276855\n",
      "Epoch 105, Loss: 2.1410151720046997, Final Batch Loss: 1.0511168241500854\n",
      "Epoch 106, Loss: 2.118120312690735, Final Batch Loss: 1.0306600332260132\n",
      "Epoch 107, Loss: 2.066911458969116, Final Batch Loss: 1.0359376668930054\n",
      "Epoch 108, Loss: 2.1404348611831665, Final Batch Loss: 1.1066603660583496\n",
      "Epoch 109, Loss: 2.1014716625213623, Final Batch Loss: 1.0444743633270264\n",
      "Epoch 110, Loss: 2.10141384601593, Final Batch Loss: 1.0114343166351318\n",
      "Epoch 111, Loss: 1.9849300384521484, Final Batch Loss: 0.9278924465179443\n",
      "Epoch 112, Loss: 2.03364634513855, Final Batch Loss: 1.019264578819275\n",
      "Epoch 113, Loss: 2.012296438217163, Final Batch Loss: 1.0023572444915771\n",
      "Epoch 114, Loss: 1.9306232333183289, Final Batch Loss: 0.9224486947059631\n",
      "Epoch 115, Loss: 1.9569379091262817, Final Batch Loss: 0.9838244915008545\n",
      "Epoch 116, Loss: 1.9303341507911682, Final Batch Loss: 0.95895916223526\n",
      "Epoch 117, Loss: 1.9954921007156372, Final Batch Loss: 1.0338976383209229\n",
      "Epoch 118, Loss: 1.9202464818954468, Final Batch Loss: 0.9166713953018188\n",
      "Epoch 119, Loss: 1.8309434056282043, Final Batch Loss: 0.9060147404670715\n",
      "Epoch 120, Loss: 1.8237183094024658, Final Batch Loss: 0.8812209963798523\n",
      "Epoch 121, Loss: 1.7650951147079468, Final Batch Loss: 0.8510766625404358\n",
      "Epoch 122, Loss: 1.7242255210876465, Final Batch Loss: 0.80483478307724\n",
      "Epoch 123, Loss: 1.7705557346343994, Final Batch Loss: 0.8636819124221802\n",
      "Epoch 124, Loss: 1.6723700165748596, Final Batch Loss: 0.8122569918632507\n",
      "Epoch 125, Loss: 1.6723922491073608, Final Batch Loss: 0.8215156197547913\n",
      "Epoch 126, Loss: 1.7567500472068787, Final Batch Loss: 0.9306213855743408\n",
      "Epoch 127, Loss: 1.7241206765174866, Final Batch Loss: 0.8878531455993652\n",
      "Epoch 128, Loss: 1.7392083406448364, Final Batch Loss: 0.9143528342247009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129, Loss: 1.6520867943763733, Final Batch Loss: 0.8220260739326477\n",
      "Epoch 130, Loss: 1.6051265597343445, Final Batch Loss: 0.7959716320037842\n",
      "Epoch 131, Loss: 1.5965367555618286, Final Batch Loss: 0.7785414457321167\n",
      "Epoch 132, Loss: 1.5125485062599182, Final Batch Loss: 0.7307056784629822\n",
      "Epoch 133, Loss: 1.5041359066963196, Final Batch Loss: 0.7373256683349609\n",
      "Epoch 134, Loss: 1.5417620539665222, Final Batch Loss: 0.7967577576637268\n",
      "Epoch 135, Loss: 1.5447232127189636, Final Batch Loss: 0.7948752045631409\n",
      "Epoch 136, Loss: 1.4600780606269836, Final Batch Loss: 0.7048540115356445\n",
      "Epoch 137, Loss: 1.5438221096992493, Final Batch Loss: 0.7706069350242615\n",
      "Epoch 138, Loss: 1.4097643494606018, Final Batch Loss: 0.6840198040008545\n",
      "Epoch 139, Loss: 1.4237446188926697, Final Batch Loss: 0.6889946460723877\n",
      "Epoch 140, Loss: 1.524436593055725, Final Batch Loss: 0.8277743458747864\n",
      "Epoch 141, Loss: 1.4475210309028625, Final Batch Loss: 0.721274197101593\n",
      "Epoch 142, Loss: 1.3564155101776123, Final Batch Loss: 0.672222375869751\n",
      "Epoch 143, Loss: 1.4071911573410034, Final Batch Loss: 0.6797913312911987\n",
      "Epoch 144, Loss: 1.3463427424430847, Final Batch Loss: 0.651857316493988\n",
      "Epoch 145, Loss: 1.3321661353111267, Final Batch Loss: 0.6569275259971619\n",
      "Epoch 146, Loss: 1.4109161496162415, Final Batch Loss: 0.7196221351623535\n",
      "Epoch 147, Loss: 1.312319815158844, Final Batch Loss: 0.6379061937332153\n",
      "Epoch 148, Loss: 1.4000404477119446, Final Batch Loss: 0.74018394947052\n",
      "Epoch 149, Loss: 1.390760064125061, Final Batch Loss: 0.717381477355957\n",
      "Epoch 150, Loss: 1.3228190541267395, Final Batch Loss: 0.6344377994537354\n",
      "Epoch 151, Loss: 1.3329898118972778, Final Batch Loss: 0.6452232003211975\n",
      "Epoch 152, Loss: 1.3133090138435364, Final Batch Loss: 0.6099361181259155\n",
      "Epoch 153, Loss: 1.40880286693573, Final Batch Loss: 0.6789461970329285\n",
      "Epoch 154, Loss: 1.4301722049713135, Final Batch Loss: 0.7992224097251892\n",
      "Epoch 155, Loss: 1.3533023595809937, Final Batch Loss: 0.6835976243019104\n",
      "Epoch 156, Loss: 1.2970658540725708, Final Batch Loss: 0.6335445642471313\n",
      "Epoch 157, Loss: 1.3304404616355896, Final Batch Loss: 0.6816861033439636\n",
      "Epoch 158, Loss: 1.298090934753418, Final Batch Loss: 0.6499585509300232\n",
      "Epoch 159, Loss: 1.2790635824203491, Final Batch Loss: 0.6011226773262024\n",
      "Epoch 160, Loss: 1.3037874102592468, Final Batch Loss: 0.6611102819442749\n",
      "Epoch 161, Loss: 1.318687379360199, Final Batch Loss: 0.6042976975440979\n",
      "Epoch 162, Loss: 1.225875198841095, Final Batch Loss: 0.580754816532135\n",
      "Epoch 163, Loss: 1.2662373781204224, Final Batch Loss: 0.6159169673919678\n",
      "Epoch 164, Loss: 1.3414716720581055, Final Batch Loss: 0.6628533601760864\n",
      "Epoch 165, Loss: 1.3107697367668152, Final Batch Loss: 0.6578001976013184\n",
      "Epoch 166, Loss: 1.2935810685157776, Final Batch Loss: 0.6398078203201294\n",
      "Epoch 167, Loss: 1.2056745886802673, Final Batch Loss: 0.5626326203346252\n",
      "Epoch 168, Loss: 1.3052369356155396, Final Batch Loss: 0.6779935359954834\n",
      "Epoch 169, Loss: 1.2031386494636536, Final Batch Loss: 0.5467765927314758\n",
      "Epoch 170, Loss: 1.16991126537323, Final Batch Loss: 0.6088847517967224\n",
      "Epoch 171, Loss: 1.2350668907165527, Final Batch Loss: 0.6732220649719238\n",
      "Epoch 172, Loss: 1.2816375494003296, Final Batch Loss: 0.6344649791717529\n",
      "Epoch 173, Loss: 1.3136633038520813, Final Batch Loss: 0.6851792335510254\n",
      "Epoch 174, Loss: 1.3165648579597473, Final Batch Loss: 0.6804871559143066\n",
      "Epoch 175, Loss: 1.2496265172958374, Final Batch Loss: 0.5856815576553345\n",
      "Epoch 176, Loss: 1.210394561290741, Final Batch Loss: 0.5546194911003113\n",
      "Epoch 177, Loss: 1.1761928796768188, Final Batch Loss: 0.6091836094856262\n",
      "Epoch 178, Loss: 1.1004867851734161, Final Batch Loss: 0.4742110073566437\n",
      "Epoch 179, Loss: 1.2361705303192139, Final Batch Loss: 0.6221274137496948\n",
      "Epoch 180, Loss: 1.2417011260986328, Final Batch Loss: 0.6524744629859924\n",
      "Epoch 181, Loss: 1.1209526658058167, Final Batch Loss: 0.5523055195808411\n",
      "Epoch 182, Loss: 1.1871598958969116, Final Batch Loss: 0.6272943615913391\n",
      "Epoch 183, Loss: 1.1974151134490967, Final Batch Loss: 0.5604793429374695\n",
      "Epoch 184, Loss: 1.2652677297592163, Final Batch Loss: 0.6305699944496155\n",
      "Epoch 185, Loss: 1.2936899065971375, Final Batch Loss: 0.6808051466941833\n",
      "Epoch 186, Loss: 1.1310798525810242, Final Batch Loss: 0.5614790320396423\n",
      "Epoch 187, Loss: 1.1138821840286255, Final Batch Loss: 0.5337779521942139\n",
      "Epoch 188, Loss: 1.1515988111495972, Final Batch Loss: 0.6437468528747559\n",
      "Epoch 189, Loss: 1.1877721548080444, Final Batch Loss: 0.6323874592781067\n",
      "Epoch 190, Loss: 1.2047761678695679, Final Batch Loss: 0.6707125902175903\n",
      "Epoch 191, Loss: 1.1610557436943054, Final Batch Loss: 0.6053289175033569\n",
      "Epoch 192, Loss: 1.179889440536499, Final Batch Loss: 0.6001107692718506\n",
      "Epoch 193, Loss: 1.1586899161338806, Final Batch Loss: 0.5899047255516052\n",
      "Epoch 194, Loss: 1.1547645926475525, Final Batch Loss: 0.5970588326454163\n",
      "Epoch 195, Loss: 1.2167632579803467, Final Batch Loss: 0.6103259325027466\n",
      "Epoch 196, Loss: 1.203767716884613, Final Batch Loss: 0.6342222094535828\n",
      "Epoch 197, Loss: 1.1303921937942505, Final Batch Loss: 0.5757477879524231\n",
      "Epoch 198, Loss: 1.103941798210144, Final Batch Loss: 0.5385096073150635\n",
      "Epoch 199, Loss: 1.2863841652870178, Final Batch Loss: 0.6803774833679199\n",
      "Epoch 200, Loss: 1.134375274181366, Final Batch Loss: 0.5399854779243469\n",
      "Epoch 201, Loss: 1.1354933381080627, Final Batch Loss: 0.5679512023925781\n",
      "Epoch 202, Loss: 1.1037782430648804, Final Batch Loss: 0.565934956073761\n",
      "Epoch 203, Loss: 1.1260127425193787, Final Batch Loss: 0.5543309450149536\n",
      "Epoch 204, Loss: 1.1318960189819336, Final Batch Loss: 0.5515310764312744\n",
      "Epoch 205, Loss: 1.0859777927398682, Final Batch Loss: 0.5544344782829285\n",
      "Epoch 206, Loss: 1.1904845833778381, Final Batch Loss: 0.6624183058738708\n",
      "Epoch 207, Loss: 1.1054775714874268, Final Batch Loss: 0.5960178375244141\n",
      "Epoch 208, Loss: 1.0497552156448364, Final Batch Loss: 0.515765905380249\n",
      "Epoch 209, Loss: 1.079373836517334, Final Batch Loss: 0.5360353589057922\n",
      "Epoch 210, Loss: 1.167145848274231, Final Batch Loss: 0.6776593327522278\n",
      "Epoch 211, Loss: 1.0048218965530396, Final Batch Loss: 0.501491129398346\n",
      "Epoch 212, Loss: 1.0518079102039337, Final Batch Loss: 0.4890676438808441\n",
      "Epoch 213, Loss: 1.0640616416931152, Final Batch Loss: 0.5068235397338867\n",
      "Epoch 214, Loss: 1.1272299885749817, Final Batch Loss: 0.5498857498168945\n",
      "Epoch 215, Loss: 0.9533778429031372, Final Batch Loss: 0.4054942727088928\n",
      "Epoch 216, Loss: 1.16488116979599, Final Batch Loss: 0.6469216346740723\n",
      "Epoch 217, Loss: 1.1953778266906738, Final Batch Loss: 0.659429132938385\n",
      "Epoch 218, Loss: 1.100951910018921, Final Batch Loss: 0.5754914283752441\n",
      "Epoch 219, Loss: 1.120356023311615, Final Batch Loss: 0.5080564022064209\n",
      "Epoch 220, Loss: 1.0148481726646423, Final Batch Loss: 0.5515661835670471\n",
      "Epoch 221, Loss: 1.1317448019981384, Final Batch Loss: 0.5530054569244385\n",
      "Epoch 222, Loss: 1.0475136041641235, Final Batch Loss: 0.5209980010986328\n",
      "Epoch 223, Loss: 0.9508776366710663, Final Batch Loss: 0.42882898449897766\n",
      "Epoch 224, Loss: 1.0659285187721252, Final Batch Loss: 0.4975903034210205\n",
      "Epoch 225, Loss: 1.0247949957847595, Final Batch Loss: 0.5153577327728271\n",
      "Epoch 226, Loss: 0.9919739663600922, Final Batch Loss: 0.5358084440231323\n",
      "Epoch 227, Loss: 0.9874271750450134, Final Batch Loss: 0.4931655526161194\n",
      "Epoch 228, Loss: 1.0393367409706116, Final Batch Loss: 0.5074183344841003\n",
      "Epoch 229, Loss: 0.9481161534786224, Final Batch Loss: 0.46816951036453247\n",
      "Epoch 230, Loss: 0.9475921988487244, Final Batch Loss: 0.4419320225715637\n",
      "Epoch 231, Loss: 1.0740504264831543, Final Batch Loss: 0.5752579569816589\n",
      "Epoch 232, Loss: 0.9440777599811554, Final Batch Loss: 0.4833355247974396\n",
      "Epoch 233, Loss: 0.9543075561523438, Final Batch Loss: 0.46612197160720825\n",
      "Epoch 234, Loss: 0.9818307459354401, Final Batch Loss: 0.5152781009674072\n",
      "Epoch 235, Loss: 0.93142169713974, Final Batch Loss: 0.4610385298728943\n",
      "Epoch 236, Loss: 0.9725803136825562, Final Batch Loss: 0.4351309537887573\n",
      "Epoch 237, Loss: 0.9289847612380981, Final Batch Loss: 0.41616714000701904\n",
      "Epoch 238, Loss: 1.0131128430366516, Final Batch Loss: 0.5222657322883606\n",
      "Epoch 239, Loss: 0.9187250733375549, Final Batch Loss: 0.3939553499221802\n",
      "Epoch 240, Loss: 0.9161648452281952, Final Batch Loss: 0.40095457434654236\n",
      "Epoch 241, Loss: 0.9312131106853485, Final Batch Loss: 0.4601713716983795\n",
      "Epoch 242, Loss: 0.9484176337718964, Final Batch Loss: 0.4758216440677643\n",
      "Epoch 243, Loss: 0.9451923072338104, Final Batch Loss: 0.43794140219688416\n",
      "Epoch 244, Loss: 0.9282802939414978, Final Batch Loss: 0.4365265965461731\n",
      "Epoch 245, Loss: 0.9682971835136414, Final Batch Loss: 0.4575842022895813\n",
      "Epoch 246, Loss: 0.9440487027168274, Final Batch Loss: 0.5091210603713989\n",
      "Epoch 247, Loss: 0.9041578769683838, Final Batch Loss: 0.42445752024650574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248, Loss: 0.8654788732528687, Final Batch Loss: 0.4176351726055145\n",
      "Epoch 249, Loss: 0.921276330947876, Final Batch Loss: 0.5195333361625671\n",
      "Epoch 250, Loss: 0.8361555337905884, Final Batch Loss: 0.3761011064052582\n",
      "Epoch 251, Loss: 0.8246051967144012, Final Batch Loss: 0.4044993221759796\n",
      "Epoch 252, Loss: 0.932742565870285, Final Batch Loss: 0.4631202220916748\n",
      "Epoch 253, Loss: 0.9529316425323486, Final Batch Loss: 0.5409291982650757\n",
      "Epoch 254, Loss: 0.8306609392166138, Final Batch Loss: 0.3985813856124878\n",
      "Epoch 255, Loss: 0.8449950218200684, Final Batch Loss: 0.33570295572280884\n",
      "Epoch 256, Loss: 0.8702782094478607, Final Batch Loss: 0.47333356738090515\n",
      "Epoch 257, Loss: 0.9111373126506805, Final Batch Loss: 0.5132513046264648\n",
      "Epoch 258, Loss: 0.8561458885669708, Final Batch Loss: 0.4353562593460083\n",
      "Epoch 259, Loss: 0.8343964219093323, Final Batch Loss: 0.3542938828468323\n",
      "Epoch 260, Loss: 0.8464823961257935, Final Batch Loss: 0.45036759972572327\n",
      "Epoch 261, Loss: 0.9603762626647949, Final Batch Loss: 0.5205007195472717\n",
      "Epoch 262, Loss: 0.8736701905727386, Final Batch Loss: 0.4263596832752228\n",
      "Epoch 263, Loss: 0.8481456637382507, Final Batch Loss: 0.41851651668548584\n",
      "Epoch 264, Loss: 0.8200993835926056, Final Batch Loss: 0.41011154651641846\n",
      "Epoch 265, Loss: 0.8007875382900238, Final Batch Loss: 0.41453367471694946\n",
      "Epoch 266, Loss: 0.7573151588439941, Final Batch Loss: 0.3979986310005188\n",
      "Epoch 267, Loss: 0.6823979020118713, Final Batch Loss: 0.3097223937511444\n",
      "Epoch 268, Loss: 0.9044806957244873, Final Batch Loss: 0.48591840267181396\n",
      "Epoch 269, Loss: 0.8034641742706299, Final Batch Loss: 0.42718732357025146\n",
      "Epoch 270, Loss: 0.875157505273819, Final Batch Loss: 0.442179411649704\n",
      "Epoch 271, Loss: 0.7203787863254547, Final Batch Loss: 0.30769506096839905\n",
      "Epoch 272, Loss: 0.6933161318302155, Final Batch Loss: 0.32169145345687866\n",
      "Epoch 273, Loss: 0.8312575221061707, Final Batch Loss: 0.4252106249332428\n",
      "Epoch 274, Loss: 0.827883243560791, Final Batch Loss: 0.3716225028038025\n",
      "Epoch 275, Loss: 0.6880285739898682, Final Batch Loss: 0.32335561513900757\n",
      "Epoch 276, Loss: 0.7640741169452667, Final Batch Loss: 0.37412551045417786\n",
      "Epoch 277, Loss: 0.7755419015884399, Final Batch Loss: 0.34229329228401184\n",
      "Epoch 278, Loss: 0.7772981226444244, Final Batch Loss: 0.38710489869117737\n",
      "Epoch 279, Loss: 0.6578448414802551, Final Batch Loss: 0.3274562358856201\n",
      "Epoch 280, Loss: 0.7472198903560638, Final Batch Loss: 0.3872627019882202\n",
      "Epoch 281, Loss: 0.7273412644863129, Final Batch Loss: 0.3987356722354889\n",
      "Epoch 282, Loss: 0.7068302929401398, Final Batch Loss: 0.34704074263572693\n",
      "Epoch 283, Loss: 0.7137409448623657, Final Batch Loss: 0.3703944683074951\n",
      "Epoch 284, Loss: 0.7266687750816345, Final Batch Loss: 0.3565806448459625\n",
      "Epoch 285, Loss: 0.6992424726486206, Final Batch Loss: 0.3522571921348572\n",
      "Epoch 286, Loss: 0.7227502763271332, Final Batch Loss: 0.37653881311416626\n",
      "Epoch 287, Loss: 0.7922294437885284, Final Batch Loss: 0.3593962490558624\n",
      "Epoch 288, Loss: 0.712489515542984, Final Batch Loss: 0.34211623668670654\n",
      "Epoch 289, Loss: 0.699372261762619, Final Batch Loss: 0.28558191657066345\n",
      "Epoch 290, Loss: 0.6865909993648529, Final Batch Loss: 0.3209288418292999\n",
      "Epoch 291, Loss: 0.7337178885936737, Final Batch Loss: 0.4243059754371643\n",
      "Epoch 292, Loss: 0.7288488745689392, Final Batch Loss: 0.38573452830314636\n",
      "Epoch 293, Loss: 0.7155462801456451, Final Batch Loss: 0.3753756284713745\n",
      "Epoch 294, Loss: 0.6413277685642242, Final Batch Loss: 0.3398570716381073\n",
      "Epoch 295, Loss: 0.7005203366279602, Final Batch Loss: 0.35946476459503174\n",
      "Epoch 296, Loss: 0.6451732516288757, Final Batch Loss: 0.34470537304878235\n",
      "Epoch 297, Loss: 0.6658405065536499, Final Batch Loss: 0.3574844002723694\n",
      "Epoch 298, Loss: 0.7040504217147827, Final Batch Loss: 0.3433208763599396\n",
      "Epoch 299, Loss: 0.5959345251321793, Final Batch Loss: 0.22875498235225677\n",
      "Epoch 300, Loss: 0.6251136362552643, Final Batch Loss: 0.2678217887878418\n",
      "Epoch 301, Loss: 0.8572010099887848, Final Batch Loss: 0.5013518929481506\n",
      "Epoch 302, Loss: 0.6869107782840729, Final Batch Loss: 0.34584346413612366\n",
      "Epoch 303, Loss: 0.6812776029109955, Final Batch Loss: 0.3437470495700836\n",
      "Epoch 304, Loss: 0.6771034002304077, Final Batch Loss: 0.36315080523490906\n",
      "Epoch 305, Loss: 0.6284066736698151, Final Batch Loss: 0.28980666399002075\n",
      "Epoch 306, Loss: 0.6266436278820038, Final Batch Loss: 0.3181008994579315\n",
      "Epoch 307, Loss: 0.7390532195568085, Final Batch Loss: 0.41701003909111023\n",
      "Epoch 308, Loss: 0.6586394608020782, Final Batch Loss: 0.27528902888298035\n",
      "Epoch 309, Loss: 0.6460687220096588, Final Batch Loss: 0.34319111704826355\n",
      "Epoch 310, Loss: 0.6497796475887299, Final Batch Loss: 0.29618850350379944\n",
      "Epoch 311, Loss: 0.7462830543518066, Final Batch Loss: 0.44469091296195984\n",
      "Epoch 312, Loss: 0.680200457572937, Final Batch Loss: 0.34766101837158203\n",
      "Epoch 313, Loss: 0.6731306612491608, Final Batch Loss: 0.3278706967830658\n",
      "Epoch 314, Loss: 0.7228489816188812, Final Batch Loss: 0.4148777723312378\n",
      "Epoch 315, Loss: 0.6553462743759155, Final Batch Loss: 0.32327577471733093\n",
      "Epoch 316, Loss: 0.653875857591629, Final Batch Loss: 0.2975212335586548\n",
      "Epoch 317, Loss: 0.677757203578949, Final Batch Loss: 0.33267346024513245\n",
      "Epoch 318, Loss: 0.6194781363010406, Final Batch Loss: 0.29476237297058105\n",
      "Epoch 319, Loss: 0.6225434243679047, Final Batch Loss: 0.2983478903770447\n",
      "Epoch 320, Loss: 0.6866672039031982, Final Batch Loss: 0.2585293650627136\n",
      "Epoch 321, Loss: 0.5991778075695038, Final Batch Loss: 0.27645015716552734\n",
      "Epoch 322, Loss: 0.6421344876289368, Final Batch Loss: 0.3138085603713989\n",
      "Epoch 323, Loss: 0.7054921388626099, Final Batch Loss: 0.38267314434051514\n",
      "Epoch 324, Loss: 0.6158322095870972, Final Batch Loss: 0.2573234736919403\n",
      "Epoch 325, Loss: 0.5528978854417801, Final Batch Loss: 0.22241388261318207\n",
      "Epoch 326, Loss: 0.6686245501041412, Final Batch Loss: 0.3972206711769104\n",
      "Epoch 327, Loss: 0.5854755789041519, Final Batch Loss: 0.3418077528476715\n",
      "Epoch 328, Loss: 0.5848066508769989, Final Batch Loss: 0.272275447845459\n",
      "Epoch 329, Loss: 0.5735084414482117, Final Batch Loss: 0.23284101486206055\n",
      "Epoch 330, Loss: 0.575981467962265, Final Batch Loss: 0.26117846369743347\n",
      "Epoch 331, Loss: 0.6605916321277618, Final Batch Loss: 0.39188235998153687\n",
      "Epoch 332, Loss: 0.5785616338253021, Final Batch Loss: 0.2990950345993042\n",
      "Epoch 333, Loss: 0.6023769378662109, Final Batch Loss: 0.29745227098464966\n",
      "Epoch 334, Loss: 0.595570832490921, Final Batch Loss: 0.3012949824333191\n",
      "Epoch 335, Loss: 0.6132184565067291, Final Batch Loss: 0.31845495104789734\n",
      "Epoch 336, Loss: 0.5768405497074127, Final Batch Loss: 0.2739737033843994\n",
      "Epoch 337, Loss: 0.5306707471609116, Final Batch Loss: 0.21566782891750336\n",
      "Epoch 338, Loss: 0.631401538848877, Final Batch Loss: 0.32674792408943176\n",
      "Epoch 339, Loss: 0.6364936530590057, Final Batch Loss: 0.3274064362049103\n",
      "Epoch 340, Loss: 0.5852071940898895, Final Batch Loss: 0.30727624893188477\n",
      "Epoch 341, Loss: 0.6178763210773468, Final Batch Loss: 0.3192687928676605\n",
      "Epoch 342, Loss: 0.5270060449838638, Final Batch Loss: 0.22179649770259857\n",
      "Epoch 343, Loss: 0.5490874648094177, Final Batch Loss: 0.27648136019706726\n",
      "Epoch 344, Loss: 0.545659989118576, Final Batch Loss: 0.26759272813796997\n",
      "Epoch 345, Loss: 0.5657903254032135, Final Batch Loss: 0.2762034833431244\n",
      "Epoch 346, Loss: 0.5314794778823853, Final Batch Loss: 0.2607055902481079\n",
      "Epoch 347, Loss: 0.5399603843688965, Final Batch Loss: 0.23491236567497253\n",
      "Epoch 348, Loss: 0.5993548929691315, Final Batch Loss: 0.31776395440101624\n",
      "Epoch 349, Loss: 0.5358046889305115, Final Batch Loss: 0.27637484669685364\n",
      "Epoch 350, Loss: 0.5334462374448776, Final Batch Loss: 0.30575990676879883\n",
      "Epoch 351, Loss: 0.5979434847831726, Final Batch Loss: 0.2588907480239868\n",
      "Epoch 352, Loss: 0.624869167804718, Final Batch Loss: 0.33888280391693115\n",
      "Epoch 353, Loss: 0.5996175706386566, Final Batch Loss: 0.33308929204940796\n",
      "Epoch 354, Loss: 0.5103788524866104, Final Batch Loss: 0.20316384732723236\n",
      "Epoch 355, Loss: 0.5195325314998627, Final Batch Loss: 0.25624388456344604\n",
      "Epoch 356, Loss: 0.7104544937610626, Final Batch Loss: 0.4321906864643097\n",
      "Epoch 357, Loss: 0.5804843008518219, Final Batch Loss: 0.30310502648353577\n",
      "Epoch 358, Loss: 0.5428505837917328, Final Batch Loss: 0.2619059383869171\n",
      "Epoch 359, Loss: 0.6371409595012665, Final Batch Loss: 0.36032700538635254\n",
      "Epoch 360, Loss: 0.509276270866394, Final Batch Loss: 0.2240288257598877\n",
      "Epoch 361, Loss: 0.6437428593635559, Final Batch Loss: 0.3032473921775818\n",
      "Epoch 362, Loss: 0.5823209881782532, Final Batch Loss: 0.2851361632347107\n",
      "Epoch 363, Loss: 0.622019499540329, Final Batch Loss: 0.3518766760826111\n",
      "Epoch 364, Loss: 0.5053427964448929, Final Batch Loss: 0.29743021726608276\n",
      "Epoch 365, Loss: 0.48600445687770844, Final Batch Loss: 0.19808988273143768\n",
      "Epoch 366, Loss: 0.5226241648197174, Final Batch Loss: 0.24245953559875488\n",
      "Epoch 367, Loss: 0.576220840215683, Final Batch Loss: 0.26882222294807434\n",
      "Epoch 368, Loss: 0.5856941044330597, Final Batch Loss: 0.3085930049419403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369, Loss: 0.6039352715015411, Final Batch Loss: 0.3281840682029724\n",
      "Epoch 370, Loss: 0.5639574527740479, Final Batch Loss: 0.33676549792289734\n",
      "Epoch 371, Loss: 0.4921778440475464, Final Batch Loss: 0.22880244255065918\n",
      "Epoch 372, Loss: 0.5193647742271423, Final Batch Loss: 0.26183778047561646\n",
      "Epoch 373, Loss: 0.5971089005470276, Final Batch Loss: 0.3400273621082306\n",
      "Epoch 374, Loss: 0.5774286389350891, Final Batch Loss: 0.3293133080005646\n",
      "Epoch 375, Loss: 0.5219485461711884, Final Batch Loss: 0.26407569646835327\n",
      "Epoch 376, Loss: 0.5112003237009048, Final Batch Loss: 0.23306380212306976\n",
      "Epoch 377, Loss: 0.5703945010900497, Final Batch Loss: 0.32163143157958984\n",
      "Epoch 378, Loss: 0.614170104265213, Final Batch Loss: 0.3120096027851105\n",
      "Epoch 379, Loss: 0.522768646478653, Final Batch Loss: 0.2697995603084564\n",
      "Epoch 380, Loss: 0.45351825654506683, Final Batch Loss: 0.18552421033382416\n",
      "Epoch 381, Loss: 0.4732213020324707, Final Batch Loss: 0.2318091094493866\n",
      "Epoch 382, Loss: 0.46018795669078827, Final Batch Loss: 0.1701628714799881\n",
      "Epoch 383, Loss: 0.6384092420339584, Final Batch Loss: 0.40307745337486267\n",
      "Epoch 384, Loss: 0.4740467667579651, Final Batch Loss: 0.26178768277168274\n",
      "Epoch 385, Loss: 0.47488290071487427, Final Batch Loss: 0.22099393606185913\n",
      "Epoch 386, Loss: 0.5238888263702393, Final Batch Loss: 0.22926515340805054\n",
      "Epoch 387, Loss: 0.5577750504016876, Final Batch Loss: 0.2734965980052948\n",
      "Epoch 388, Loss: 0.49302229285240173, Final Batch Loss: 0.2948085069656372\n",
      "Epoch 389, Loss: 0.5211691409349442, Final Batch Loss: 0.21590928733348846\n",
      "Epoch 390, Loss: 0.5456128418445587, Final Batch Loss: 0.28614047169685364\n",
      "Epoch 391, Loss: 0.47496503591537476, Final Batch Loss: 0.23295007646083832\n",
      "Epoch 392, Loss: 0.43834391236305237, Final Batch Loss: 0.18219077587127686\n",
      "Epoch 393, Loss: 0.5020096600055695, Final Batch Loss: 0.19887679815292358\n",
      "Epoch 394, Loss: 0.47966596484184265, Final Batch Loss: 0.21564847230911255\n",
      "Epoch 395, Loss: 0.41303421556949615, Final Batch Loss: 0.17538060247898102\n",
      "Epoch 396, Loss: 0.5252007842063904, Final Batch Loss: 0.26719585061073303\n",
      "Epoch 397, Loss: 0.44653336703777313, Final Batch Loss: 0.21206898987293243\n",
      "Epoch 398, Loss: 0.5842995345592499, Final Batch Loss: 0.30697980523109436\n",
      "Epoch 399, Loss: 0.4960041344165802, Final Batch Loss: 0.2631301283836365\n",
      "Epoch 400, Loss: 0.4838460385799408, Final Batch Loss: 0.24319005012512207\n",
      "Epoch 401, Loss: 0.5820602774620056, Final Batch Loss: 0.3150435984134674\n",
      "Epoch 402, Loss: 0.5509992837905884, Final Batch Loss: 0.2936025559902191\n",
      "Epoch 403, Loss: 0.46404123306274414, Final Batch Loss: 0.20296183228492737\n",
      "Epoch 404, Loss: 0.47453299164772034, Final Batch Loss: 0.21152761578559875\n",
      "Epoch 405, Loss: 0.4520104229450226, Final Batch Loss: 0.22836320102214813\n",
      "Epoch 406, Loss: 0.45790864527225494, Final Batch Loss: 0.19767163693904877\n",
      "Epoch 407, Loss: 0.5062604546546936, Final Batch Loss: 0.22838875651359558\n",
      "Epoch 408, Loss: 0.4631550908088684, Final Batch Loss: 0.23716512322425842\n",
      "Epoch 409, Loss: 0.5049506276845932, Final Batch Loss: 0.2562701106071472\n",
      "Epoch 410, Loss: 0.5194728821516037, Final Batch Loss: 0.18634240329265594\n",
      "Epoch 411, Loss: 0.5160069465637207, Final Batch Loss: 0.2923511564731598\n",
      "Epoch 412, Loss: 0.4673231840133667, Final Batch Loss: 0.21898770332336426\n",
      "Epoch 413, Loss: 0.5384508818387985, Final Batch Loss: 0.19693045318126678\n",
      "Epoch 414, Loss: 0.5322327464818954, Final Batch Loss: 0.2837432622909546\n",
      "Epoch 415, Loss: 0.4408637434244156, Final Batch Loss: 0.2071227878332138\n",
      "Epoch 416, Loss: 0.43697863817214966, Final Batch Loss: 0.21201011538505554\n",
      "Epoch 417, Loss: 0.5189151465892792, Final Batch Loss: 0.2871171832084656\n",
      "Epoch 418, Loss: 0.5521091520786285, Final Batch Loss: 0.27980759739875793\n",
      "Epoch 419, Loss: 0.5678884387016296, Final Batch Loss: 0.27441897988319397\n",
      "Epoch 420, Loss: 0.5494267791509628, Final Batch Loss: 0.328740656375885\n",
      "Epoch 421, Loss: 0.4555080235004425, Final Batch Loss: 0.2233593463897705\n",
      "Epoch 422, Loss: 0.5059941709041595, Final Batch Loss: 0.2534013092517853\n",
      "Epoch 423, Loss: 0.45873430371284485, Final Batch Loss: 0.23832261562347412\n",
      "Epoch 424, Loss: 0.4546666592359543, Final Batch Loss: 0.1880001276731491\n",
      "Epoch 425, Loss: 0.5113305896520615, Final Batch Loss: 0.2485446184873581\n",
      "Epoch 426, Loss: 0.5730348229408264, Final Batch Loss: 0.3025643527507782\n",
      "Epoch 427, Loss: 0.49465619027614594, Final Batch Loss: 0.24596136808395386\n",
      "Epoch 428, Loss: 0.45926427841186523, Final Batch Loss: 0.23858016729354858\n",
      "Epoch 429, Loss: 0.5118734687566757, Final Batch Loss: 0.2691466808319092\n",
      "Epoch 430, Loss: 0.5516297817230225, Final Batch Loss: 0.2828871011734009\n",
      "Epoch 431, Loss: 0.39855243265628815, Final Batch Loss: 0.15582551062107086\n",
      "Epoch 432, Loss: 0.4309542328119278, Final Batch Loss: 0.18921616673469543\n",
      "Epoch 433, Loss: 0.5135936588048935, Final Batch Loss: 0.22729681432247162\n",
      "Epoch 434, Loss: 0.46027565002441406, Final Batch Loss: 0.1959247589111328\n",
      "Epoch 435, Loss: 0.5218237936496735, Final Batch Loss: 0.2966017723083496\n",
      "Epoch 436, Loss: 0.39592137932777405, Final Batch Loss: 0.16895826160907745\n",
      "Epoch 437, Loss: 0.423753023147583, Final Batch Loss: 0.213917538523674\n",
      "Epoch 438, Loss: 0.4837314039468765, Final Batch Loss: 0.24216842651367188\n",
      "Epoch 439, Loss: 0.43188588321208954, Final Batch Loss: 0.16643212735652924\n",
      "Epoch 440, Loss: 0.47632962465286255, Final Batch Loss: 0.2620459496974945\n",
      "Epoch 441, Loss: 0.3958329111337662, Final Batch Loss: 0.15425509214401245\n",
      "Epoch 442, Loss: 0.5166324973106384, Final Batch Loss: 0.28140780329704285\n",
      "Epoch 443, Loss: 0.4727141559123993, Final Batch Loss: 0.2661440968513489\n",
      "Epoch 444, Loss: 0.44182543456554413, Final Batch Loss: 0.2071181684732437\n",
      "Epoch 445, Loss: 0.3657122999429703, Final Batch Loss: 0.15431968867778778\n",
      "Epoch 446, Loss: 0.4708492159843445, Final Batch Loss: 0.26936018466949463\n",
      "Epoch 447, Loss: 0.4677320569753647, Final Batch Loss: 0.21638505160808563\n",
      "Epoch 448, Loss: 0.44349077343940735, Final Batch Loss: 0.23728670179843903\n",
      "Epoch 449, Loss: 0.48824751377105713, Final Batch Loss: 0.27111712098121643\n",
      "Epoch 450, Loss: 0.3915338069200516, Final Batch Loss: 0.19523337483406067\n",
      "Epoch 451, Loss: 0.46424540877342224, Final Batch Loss: 0.20665612816810608\n",
      "Epoch 452, Loss: 0.47047995030879974, Final Batch Loss: 0.2667853832244873\n",
      "Epoch 453, Loss: 0.4224500060081482, Final Batch Loss: 0.2278970330953598\n",
      "Epoch 454, Loss: 0.4485725462436676, Final Batch Loss: 0.2274835854768753\n",
      "Epoch 455, Loss: 0.4584694355726242, Final Batch Loss: 0.241756871342659\n",
      "Epoch 456, Loss: 0.4659610539674759, Final Batch Loss: 0.27091479301452637\n",
      "Epoch 457, Loss: 0.4863297790288925, Final Batch Loss: 0.27263274788856506\n",
      "Epoch 458, Loss: 0.46347372233867645, Final Batch Loss: 0.27317380905151367\n",
      "Epoch 459, Loss: 0.4330732375383377, Final Batch Loss: 0.21970391273498535\n",
      "Epoch 460, Loss: 0.4539773166179657, Final Batch Loss: 0.24177946150302887\n",
      "Epoch 461, Loss: 0.4750577360391617, Final Batch Loss: 0.2806450128555298\n",
      "Epoch 462, Loss: 0.47220200300216675, Final Batch Loss: 0.3056308627128601\n",
      "Epoch 463, Loss: 0.40781787037849426, Final Batch Loss: 0.24071243405342102\n",
      "Epoch 464, Loss: 0.49499332904815674, Final Batch Loss: 0.2654113471508026\n",
      "Epoch 465, Loss: 0.38800711929798126, Final Batch Loss: 0.15777398645877838\n",
      "Epoch 466, Loss: 0.4547918140888214, Final Batch Loss: 0.24144668877124786\n",
      "Epoch 467, Loss: 0.46444156765937805, Final Batch Loss: 0.24596872925758362\n",
      "Epoch 468, Loss: 0.37244684994220734, Final Batch Loss: 0.1815003752708435\n",
      "Epoch 469, Loss: 0.3786208927631378, Final Batch Loss: 0.18777237832546234\n",
      "Epoch 470, Loss: 0.47522956132888794, Final Batch Loss: 0.2812434434890747\n",
      "Epoch 471, Loss: 0.4190186560153961, Final Batch Loss: 0.24919164180755615\n",
      "Epoch 472, Loss: 0.3864050507545471, Final Batch Loss: 0.1431448608636856\n",
      "Epoch 473, Loss: 0.443787544965744, Final Batch Loss: 0.2006603479385376\n",
      "Epoch 474, Loss: 0.39722079038619995, Final Batch Loss: 0.17233960330486298\n",
      "Epoch 475, Loss: 0.39825575053691864, Final Batch Loss: 0.1824178397655487\n",
      "Epoch 476, Loss: 0.400997057557106, Final Batch Loss: 0.17065636813640594\n",
      "Epoch 477, Loss: 0.46264055371284485, Final Batch Loss: 0.20963096618652344\n",
      "Epoch 478, Loss: 0.47721295058727264, Final Batch Loss: 0.21997149288654327\n",
      "Epoch 479, Loss: 0.3253069221973419, Final Batch Loss: 0.1522493064403534\n",
      "Epoch 480, Loss: 0.4757496863603592, Final Batch Loss: 0.306045264005661\n",
      "Epoch 481, Loss: 0.424677774310112, Final Batch Loss: 0.22545881569385529\n",
      "Epoch 482, Loss: 0.40104275941848755, Final Batch Loss: 0.18585754930973053\n",
      "Epoch 483, Loss: 0.4593532234430313, Final Batch Loss: 0.21525411307811737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484, Loss: 0.39365769922733307, Final Batch Loss: 0.1702406406402588\n",
      "Epoch 485, Loss: 0.37388022243976593, Final Batch Loss: 0.1815117597579956\n",
      "Epoch 486, Loss: 0.4316241890192032, Final Batch Loss: 0.23539960384368896\n",
      "Epoch 487, Loss: 0.4009027034044266, Final Batch Loss: 0.21039435267448425\n",
      "Epoch 488, Loss: 0.46901847422122955, Final Batch Loss: 0.2768111526966095\n",
      "Epoch 489, Loss: 0.35424868762493134, Final Batch Loss: 0.1321771889925003\n",
      "Epoch 490, Loss: 0.5270193070173264, Final Batch Loss: 0.301810622215271\n",
      "Epoch 491, Loss: 0.3758838474750519, Final Batch Loss: 0.17131760716438293\n",
      "Epoch 492, Loss: 0.4240895211696625, Final Batch Loss: 0.14339637756347656\n",
      "Epoch 493, Loss: 0.43781423568725586, Final Batch Loss: 0.213413268327713\n",
      "Epoch 494, Loss: 0.42466701567173004, Final Batch Loss: 0.2512052357196808\n",
      "Epoch 495, Loss: 0.4152335971593857, Final Batch Loss: 0.16351433098316193\n",
      "Epoch 496, Loss: 0.3572714775800705, Final Batch Loss: 0.15088889002799988\n",
      "Epoch 497, Loss: 0.5263471156358719, Final Batch Loss: 0.21295659244060516\n",
      "Epoch 498, Loss: 0.4022029787302017, Final Batch Loss: 0.17877718806266785\n",
      "Epoch 499, Loss: 0.3429318368434906, Final Batch Loss: 0.12813794612884521\n",
      "Epoch 500, Loss: 0.44751115143299103, Final Batch Loss: 0.23539932072162628\n",
      "Epoch 501, Loss: 0.38721127808094025, Final Batch Loss: 0.2100967913866043\n",
      "Epoch 502, Loss: 0.3564607501029968, Final Batch Loss: 0.16972684860229492\n",
      "Epoch 503, Loss: 0.34433820843696594, Final Batch Loss: 0.16043740510940552\n",
      "Epoch 504, Loss: 0.4126054495573044, Final Batch Loss: 0.21820668876171112\n",
      "Epoch 505, Loss: 0.3562881201505661, Final Batch Loss: 0.16915975511074066\n",
      "Epoch 506, Loss: 0.39502935111522675, Final Batch Loss: 0.21749107539653778\n",
      "Epoch 507, Loss: 0.4819173514842987, Final Batch Loss: 0.2989196181297302\n",
      "Epoch 508, Loss: 0.4229156821966171, Final Batch Loss: 0.24248304963111877\n",
      "Epoch 509, Loss: 0.380517914891243, Final Batch Loss: 0.1870952546596527\n",
      "Epoch 510, Loss: 0.3337602913379669, Final Batch Loss: 0.16978536546230316\n",
      "Epoch 511, Loss: 0.35239799320697784, Final Batch Loss: 0.16573084890842438\n",
      "Epoch 512, Loss: 0.4087201654911041, Final Batch Loss: 0.2006622552871704\n",
      "Epoch 513, Loss: 0.36335524916648865, Final Batch Loss: 0.13961762189865112\n",
      "Epoch 514, Loss: 0.36477838456630707, Final Batch Loss: 0.17603188753128052\n",
      "Epoch 515, Loss: 0.4016841650009155, Final Batch Loss: 0.22694481909275055\n",
      "Epoch 516, Loss: 0.36301325261592865, Final Batch Loss: 0.1819392293691635\n",
      "Epoch 517, Loss: 0.36027079820632935, Final Batch Loss: 0.20346753299236298\n",
      "Epoch 518, Loss: 0.3813392221927643, Final Batch Loss: 0.22531138360500336\n",
      "Epoch 519, Loss: 0.3230437636375427, Final Batch Loss: 0.14356037974357605\n",
      "Epoch 520, Loss: 0.36333218216896057, Final Batch Loss: 0.1879076212644577\n",
      "Epoch 521, Loss: 0.33908508718013763, Final Batch Loss: 0.17044806480407715\n",
      "Epoch 522, Loss: 0.3883514851331711, Final Batch Loss: 0.18187639117240906\n",
      "Epoch 523, Loss: 0.41254493594169617, Final Batch Loss: 0.2067590355873108\n",
      "Epoch 524, Loss: 0.35258282721042633, Final Batch Loss: 0.17379936575889587\n",
      "Epoch 525, Loss: 0.38122333586215973, Final Batch Loss: 0.20116746425628662\n",
      "Epoch 526, Loss: 0.3911076933145523, Final Batch Loss: 0.18583643436431885\n",
      "Epoch 527, Loss: 0.41555359959602356, Final Batch Loss: 0.21988217532634735\n",
      "Epoch 528, Loss: 0.3868824988603592, Final Batch Loss: 0.17471572756767273\n",
      "Epoch 529, Loss: 0.3832121640443802, Final Batch Loss: 0.19717171788215637\n",
      "Epoch 530, Loss: 0.3277778625488281, Final Batch Loss: 0.17930153012275696\n",
      "Epoch 531, Loss: 0.42003877460956573, Final Batch Loss: 0.20883139967918396\n",
      "Epoch 532, Loss: 0.47881487011909485, Final Batch Loss: 0.3075065016746521\n",
      "Epoch 533, Loss: 0.3868672251701355, Final Batch Loss: 0.20608972012996674\n",
      "Epoch 534, Loss: 0.4048886001110077, Final Batch Loss: 0.23495438694953918\n",
      "Epoch 535, Loss: 0.3643769770860672, Final Batch Loss: 0.11771629750728607\n",
      "Epoch 536, Loss: 0.30475524067878723, Final Batch Loss: 0.1395738273859024\n",
      "Epoch 537, Loss: 0.35083286464214325, Final Batch Loss: 0.18333673477172852\n",
      "Epoch 538, Loss: 0.3011530414223671, Final Batch Loss: 0.10112743824720383\n",
      "Epoch 539, Loss: 0.3650181442499161, Final Batch Loss: 0.1607527732849121\n",
      "Epoch 540, Loss: 0.3091925382614136, Final Batch Loss: 0.16905510425567627\n",
      "Epoch 541, Loss: 0.379702165722847, Final Batch Loss: 0.19428220391273499\n",
      "Epoch 542, Loss: 0.37131521105766296, Final Batch Loss: 0.1923404484987259\n",
      "Epoch 543, Loss: 0.2809447720646858, Final Batch Loss: 0.061137907207012177\n",
      "Epoch 544, Loss: 0.3602531999349594, Final Batch Loss: 0.22585533559322357\n",
      "Epoch 545, Loss: 0.321206733584404, Final Batch Loss: 0.14168021082878113\n",
      "Epoch 546, Loss: 0.3524840623140335, Final Batch Loss: 0.1928693950176239\n",
      "Epoch 547, Loss: 0.3554234951734543, Final Batch Loss: 0.17316818237304688\n",
      "Epoch 548, Loss: 0.3378162831068039, Final Batch Loss: 0.12935464084148407\n",
      "Epoch 549, Loss: 0.39509108662605286, Final Batch Loss: 0.1987406462430954\n",
      "Epoch 550, Loss: 0.3149265870451927, Final Batch Loss: 0.11618130654096603\n",
      "Epoch 551, Loss: 0.31401659548282623, Final Batch Loss: 0.1532564014196396\n",
      "Epoch 552, Loss: 0.30874696373939514, Final Batch Loss: 0.16703087091445923\n",
      "Epoch 553, Loss: 0.3413168042898178, Final Batch Loss: 0.1399228423833847\n",
      "Epoch 554, Loss: 0.38384345173835754, Final Batch Loss: 0.202578604221344\n",
      "Epoch 555, Loss: 0.37551623582839966, Final Batch Loss: 0.20136649906635284\n",
      "Epoch 556, Loss: 0.3049050271511078, Final Batch Loss: 0.15952168405056\n",
      "Epoch 557, Loss: 0.3445778042078018, Final Batch Loss: 0.15223148465156555\n",
      "Epoch 558, Loss: 0.2612827271223068, Final Batch Loss: 0.10391712188720703\n",
      "Epoch 559, Loss: 0.30305810272693634, Final Batch Loss: 0.16452421247959137\n",
      "Epoch 560, Loss: 0.2970684841275215, Final Batch Loss: 0.12440551072359085\n",
      "Epoch 561, Loss: 0.3241010904312134, Final Batch Loss: 0.19186612963676453\n",
      "Epoch 562, Loss: 0.3119535893201828, Final Batch Loss: 0.14673353731632233\n",
      "Epoch 563, Loss: 0.2360634282231331, Final Batch Loss: 0.09048844128847122\n",
      "Epoch 564, Loss: 0.3835226744413376, Final Batch Loss: 0.2561247944831848\n",
      "Epoch 565, Loss: 0.30953918397426605, Final Batch Loss: 0.13586990535259247\n",
      "Epoch 566, Loss: 0.3491435796022415, Final Batch Loss: 0.18821017444133759\n",
      "Epoch 567, Loss: 0.36715927720069885, Final Batch Loss: 0.18830841779708862\n",
      "Epoch 568, Loss: 0.4115341901779175, Final Batch Loss: 0.26838427782058716\n",
      "Epoch 569, Loss: 0.26074695587158203, Final Batch Loss: 0.08256056904792786\n",
      "Epoch 570, Loss: 0.27657759189605713, Final Batch Loss: 0.13077358901500702\n",
      "Epoch 571, Loss: 0.3390897661447525, Final Batch Loss: 0.13923047482967377\n",
      "Epoch 572, Loss: 0.32495708763599396, Final Batch Loss: 0.19624872505664825\n",
      "Epoch 573, Loss: 0.2868693321943283, Final Batch Loss: 0.096766397356987\n",
      "Epoch 574, Loss: 0.46447165310382843, Final Batch Loss: 0.2964417636394501\n",
      "Epoch 575, Loss: 0.29767757654190063, Final Batch Loss: 0.14299146831035614\n",
      "Epoch 576, Loss: 0.3166326880455017, Final Batch Loss: 0.1881825029850006\n",
      "Epoch 577, Loss: 0.3921928405761719, Final Batch Loss: 0.2297280877828598\n",
      "Epoch 578, Loss: 0.31658700108528137, Final Batch Loss: 0.16820724308490753\n",
      "Epoch 579, Loss: 0.32276491820812225, Final Batch Loss: 0.18889030814170837\n",
      "Epoch 580, Loss: 0.2704138606786728, Final Batch Loss: 0.12811657786369324\n",
      "Epoch 581, Loss: 0.3293835371732712, Final Batch Loss: 0.1574169248342514\n",
      "Epoch 582, Loss: 0.29396962374448776, Final Batch Loss: 0.11441300064325333\n",
      "Epoch 583, Loss: 0.3389936685562134, Final Batch Loss: 0.16172398626804352\n",
      "Epoch 584, Loss: 0.3585093319416046, Final Batch Loss: 0.17454011738300323\n",
      "Epoch 585, Loss: 0.2854616045951843, Final Batch Loss: 0.1393277496099472\n",
      "Epoch 586, Loss: 0.2703905329108238, Final Batch Loss: 0.11362770944833755\n",
      "Epoch 587, Loss: 0.3165445178747177, Final Batch Loss: 0.17305757105350494\n",
      "Epoch 588, Loss: 0.32796308398246765, Final Batch Loss: 0.17108380794525146\n",
      "Epoch 589, Loss: 0.3828310966491699, Final Batch Loss: 0.22535280883312225\n",
      "Epoch 590, Loss: 0.3552626967430115, Final Batch Loss: 0.16049325466156006\n",
      "Epoch 591, Loss: 0.3025156706571579, Final Batch Loss: 0.15676839649677277\n",
      "Epoch 592, Loss: 0.2978180944919586, Final Batch Loss: 0.15896542370319366\n",
      "Epoch 593, Loss: 0.27674759179353714, Final Batch Loss: 0.11019546538591385\n",
      "Epoch 594, Loss: 0.2804722785949707, Final Batch Loss: 0.1371861696243286\n",
      "Epoch 595, Loss: 0.2725529074668884, Final Batch Loss: 0.11625790596008301\n",
      "Epoch 596, Loss: 0.30100761353969574, Final Batch Loss: 0.13207846879959106\n",
      "Epoch 597, Loss: 0.34286054968833923, Final Batch Loss: 0.19352571666240692\n",
      "Epoch 598, Loss: 0.29479651153087616, Final Batch Loss: 0.13269904255867004\n",
      "Epoch 599, Loss: 0.26045670360326767, Final Batch Loss: 0.10760874301195145\n",
      "Epoch 600, Loss: 0.2940656989812851, Final Batch Loss: 0.14757169783115387\n",
      "Epoch 601, Loss: 0.32670940458774567, Final Batch Loss: 0.15656113624572754\n",
      "Epoch 602, Loss: 0.28929944336414337, Final Batch Loss: 0.13264986872673035\n",
      "Epoch 603, Loss: 0.2974732294678688, Final Batch Loss: 0.11469749361276627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 604, Loss: 0.3373689651489258, Final Batch Loss: 0.1929217278957367\n",
      "Epoch 605, Loss: 0.31488431990146637, Final Batch Loss: 0.14116419851779938\n",
      "Epoch 606, Loss: 0.24583975225687027, Final Batch Loss: 0.1015966460108757\n",
      "Epoch 607, Loss: 0.2533174753189087, Final Batch Loss: 0.11064952611923218\n",
      "Epoch 608, Loss: 0.2911248877644539, Final Batch Loss: 0.1676218956708908\n",
      "Epoch 609, Loss: 0.3436534255743027, Final Batch Loss: 0.18228882551193237\n",
      "Epoch 610, Loss: 0.2689877972006798, Final Batch Loss: 0.1203678622841835\n",
      "Epoch 611, Loss: 0.29819583892822266, Final Batch Loss: 0.15366733074188232\n",
      "Epoch 612, Loss: 0.23351777344942093, Final Batch Loss: 0.09691699594259262\n",
      "Epoch 613, Loss: 0.3476947546005249, Final Batch Loss: 0.1916530579328537\n",
      "Epoch 614, Loss: 0.24517352879047394, Final Batch Loss: 0.09811678528785706\n",
      "Epoch 615, Loss: 0.33804477751255035, Final Batch Loss: 0.15911176800727844\n",
      "Epoch 616, Loss: 0.3576260209083557, Final Batch Loss: 0.19715826213359833\n",
      "Epoch 617, Loss: 0.335584357380867, Final Batch Loss: 0.1571723222732544\n",
      "Epoch 618, Loss: 0.29878973960876465, Final Batch Loss: 0.17223244905471802\n",
      "Epoch 619, Loss: 0.24782094359397888, Final Batch Loss: 0.10670618712902069\n",
      "Epoch 620, Loss: 0.2808123528957367, Final Batch Loss: 0.14657141268253326\n",
      "Epoch 621, Loss: 0.23328839242458344, Final Batch Loss: 0.09260325133800507\n",
      "Epoch 622, Loss: 0.3015449643135071, Final Batch Loss: 0.07742360234260559\n",
      "Epoch 623, Loss: 0.33004361391067505, Final Batch Loss: 0.23259834945201874\n",
      "Epoch 624, Loss: 0.28768880665302277, Final Batch Loss: 0.13935141265392303\n",
      "Epoch 625, Loss: 0.36038896441459656, Final Batch Loss: 0.19529013335704803\n",
      "Epoch 626, Loss: 0.33653873205184937, Final Batch Loss: 0.18977691233158112\n",
      "Epoch 627, Loss: 0.3405470997095108, Final Batch Loss: 0.17664091289043427\n",
      "Epoch 628, Loss: 0.3106693625450134, Final Batch Loss: 0.1521812230348587\n",
      "Epoch 629, Loss: 0.2569837421178818, Final Batch Loss: 0.10377803444862366\n",
      "Epoch 630, Loss: 0.32806918025016785, Final Batch Loss: 0.1700272113084793\n",
      "Epoch 631, Loss: 0.3051671236753464, Final Batch Loss: 0.15337586402893066\n",
      "Epoch 632, Loss: 0.23550468683242798, Final Batch Loss: 0.1145586296916008\n",
      "Epoch 633, Loss: 0.27943454682826996, Final Batch Loss: 0.07581338286399841\n",
      "Epoch 634, Loss: 0.25024936348199844, Final Batch Loss: 0.12284355610609055\n",
      "Epoch 635, Loss: 0.249513678252697, Final Batch Loss: 0.11988653987646103\n",
      "Epoch 636, Loss: 0.4282776117324829, Final Batch Loss: 0.276382178068161\n",
      "Epoch 637, Loss: 0.29521843791007996, Final Batch Loss: 0.15634526312351227\n",
      "Epoch 638, Loss: 0.2729179561138153, Final Batch Loss: 0.12005080282688141\n",
      "Epoch 639, Loss: 0.29457442462444305, Final Batch Loss: 0.12777674198150635\n",
      "Epoch 640, Loss: 0.24360448867082596, Final Batch Loss: 0.0988517478108406\n",
      "Epoch 641, Loss: 0.2598237842321396, Final Batch Loss: 0.0592387318611145\n",
      "Epoch 642, Loss: 0.2809610366821289, Final Batch Loss: 0.14492842555046082\n",
      "Epoch 643, Loss: 0.254582516849041, Final Batch Loss: 0.10431460291147232\n",
      "Epoch 644, Loss: 0.29015538841485977, Final Batch Loss: 0.11787403374910355\n",
      "Epoch 645, Loss: 0.3423100709915161, Final Batch Loss: 0.22367094457149506\n",
      "Epoch 646, Loss: 0.27933308482170105, Final Batch Loss: 0.13004182279109955\n",
      "Epoch 647, Loss: 0.29305434226989746, Final Batch Loss: 0.11478528380393982\n",
      "Epoch 648, Loss: 0.267773762345314, Final Batch Loss: 0.14375577867031097\n",
      "Epoch 649, Loss: 0.29016292095184326, Final Batch Loss: 0.1405203491449356\n",
      "Epoch 650, Loss: 0.31381241977214813, Final Batch Loss: 0.12942849099636078\n",
      "Epoch 651, Loss: 0.2909795641899109, Final Batch Loss: 0.13162899017333984\n",
      "Epoch 652, Loss: 0.27934978902339935, Final Batch Loss: 0.15292006731033325\n",
      "Epoch 653, Loss: 0.3341545909643173, Final Batch Loss: 0.19449788331985474\n",
      "Epoch 654, Loss: 0.31220485270023346, Final Batch Loss: 0.16006650030612946\n",
      "Epoch 655, Loss: 0.23788292706012726, Final Batch Loss: 0.07802295684814453\n",
      "Epoch 656, Loss: 0.2812030017375946, Final Batch Loss: 0.15068963170051575\n",
      "Epoch 657, Loss: 0.26670683175325394, Final Batch Loss: 0.09762396663427353\n",
      "Epoch 658, Loss: 0.2816636562347412, Final Batch Loss: 0.12626154720783234\n",
      "Epoch 659, Loss: 0.24555834382772446, Final Batch Loss: 0.08304499834775925\n",
      "Epoch 660, Loss: 0.23850563168525696, Final Batch Loss: 0.06847831606864929\n",
      "Epoch 661, Loss: 0.3320373445749283, Final Batch Loss: 0.20248514413833618\n",
      "Epoch 662, Loss: 0.23343266546726227, Final Batch Loss: 0.11929023265838623\n",
      "Epoch 663, Loss: 0.28802479803562164, Final Batch Loss: 0.13163450360298157\n",
      "Epoch 664, Loss: 0.3189328610897064, Final Batch Loss: 0.16981855034828186\n",
      "Epoch 665, Loss: 0.22501502186059952, Final Batch Loss: 0.08398660272359848\n",
      "Epoch 666, Loss: 0.2848852723836899, Final Batch Loss: 0.14143213629722595\n",
      "Epoch 667, Loss: 0.2870858609676361, Final Batch Loss: 0.1229022741317749\n",
      "Epoch 668, Loss: 0.2644111290574074, Final Batch Loss: 0.1473015695810318\n",
      "Epoch 669, Loss: 0.2715640366077423, Final Batch Loss: 0.15812571346759796\n",
      "Epoch 670, Loss: 0.30044153332710266, Final Batch Loss: 0.18291610479354858\n",
      "Epoch 671, Loss: 0.22769390791654587, Final Batch Loss: 0.10491520911455154\n",
      "Epoch 672, Loss: 0.2671068608760834, Final Batch Loss: 0.12430939078330994\n",
      "Epoch 673, Loss: 0.276486799120903, Final Batch Loss: 0.14028410613536835\n",
      "Epoch 674, Loss: 0.24809975177049637, Final Batch Loss: 0.10551144927740097\n",
      "Epoch 675, Loss: 0.2887839525938034, Final Batch Loss: 0.13820211589336395\n",
      "Epoch 676, Loss: 0.2682102769613266, Final Batch Loss: 0.12404212355613708\n",
      "Epoch 677, Loss: 0.25997766852378845, Final Batch Loss: 0.13220609724521637\n",
      "Epoch 678, Loss: 0.28989556431770325, Final Batch Loss: 0.13768458366394043\n",
      "Epoch 679, Loss: 0.2261890470981598, Final Batch Loss: 0.09040772914886475\n",
      "Epoch 680, Loss: 0.28679509460926056, Final Batch Loss: 0.18145865201950073\n",
      "Epoch 681, Loss: 0.29817749559879303, Final Batch Loss: 0.21197816729545593\n",
      "Epoch 682, Loss: 0.28186092525720596, Final Batch Loss: 0.176215261220932\n",
      "Epoch 683, Loss: 0.2732974886894226, Final Batch Loss: 0.1627858430147171\n",
      "Epoch 684, Loss: 0.2609640806913376, Final Batch Loss: 0.1337818056344986\n",
      "Epoch 685, Loss: 0.24719897657632828, Final Batch Loss: 0.11278415471315384\n",
      "Epoch 686, Loss: 0.3493199944496155, Final Batch Loss: 0.21270881593227386\n",
      "Epoch 687, Loss: 0.3334439992904663, Final Batch Loss: 0.20626378059387207\n",
      "Epoch 688, Loss: 0.25737352669239044, Final Batch Loss: 0.12813234329223633\n",
      "Epoch 689, Loss: 0.32617081701755524, Final Batch Loss: 0.2041729986667633\n",
      "Epoch 690, Loss: 0.26503634452819824, Final Batch Loss: 0.1233125776052475\n",
      "Epoch 691, Loss: 0.32661469280719757, Final Batch Loss: 0.1600540727376938\n",
      "Epoch 692, Loss: 0.33578841388225555, Final Batch Loss: 0.16807858645915985\n",
      "Epoch 693, Loss: 0.2510169818997383, Final Batch Loss: 0.10631433874368668\n",
      "Epoch 694, Loss: 0.31004559993743896, Final Batch Loss: 0.18850670754909515\n",
      "Epoch 695, Loss: 0.292111799120903, Final Batch Loss: 0.13872703909873962\n",
      "Epoch 696, Loss: 0.24742674827575684, Final Batch Loss: 0.08491542935371399\n",
      "Epoch 697, Loss: 0.37704674899578094, Final Batch Loss: 0.20049619674682617\n",
      "Epoch 698, Loss: 0.3251418024301529, Final Batch Loss: 0.1717865914106369\n",
      "Epoch 699, Loss: 0.2819443494081497, Final Batch Loss: 0.1399163156747818\n",
      "Epoch 700, Loss: 0.3144836872816086, Final Batch Loss: 0.1561731994152069\n",
      "Epoch 701, Loss: 0.2641453519463539, Final Batch Loss: 0.12412133067846298\n",
      "Epoch 702, Loss: 0.2831316813826561, Final Batch Loss: 0.16027258336544037\n",
      "Epoch 703, Loss: 0.2958252653479576, Final Batch Loss: 0.1729305237531662\n",
      "Epoch 704, Loss: 0.2832566946744919, Final Batch Loss: 0.14022687077522278\n",
      "Epoch 705, Loss: 0.2597169950604439, Final Batch Loss: 0.11178768426179886\n",
      "Epoch 706, Loss: 0.2652125507593155, Final Batch Loss: 0.13879792392253876\n",
      "Epoch 707, Loss: 0.2882784307003021, Final Batch Loss: 0.13217231631278992\n",
      "Epoch 708, Loss: 0.2503519803285599, Final Batch Loss: 0.10013447701931\n",
      "Epoch 709, Loss: 0.22753556072711945, Final Batch Loss: 0.10321086645126343\n",
      "Epoch 710, Loss: 0.2713109329342842, Final Batch Loss: 0.1212964877486229\n",
      "Epoch 711, Loss: 0.28902049362659454, Final Batch Loss: 0.1810470074415207\n",
      "Epoch 712, Loss: 0.28733203560113907, Final Batch Loss: 0.16720525920391083\n",
      "Epoch 713, Loss: 0.283061146736145, Final Batch Loss: 0.12914425134658813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714, Loss: 0.2531234994530678, Final Batch Loss: 0.12195233255624771\n",
      "Epoch 715, Loss: 0.256329283118248, Final Batch Loss: 0.15064339339733124\n",
      "Epoch 716, Loss: 0.22911283373832703, Final Batch Loss: 0.09620220959186554\n",
      "Epoch 717, Loss: 0.22339968383312225, Final Batch Loss: 0.1039867028594017\n",
      "Epoch 718, Loss: 0.3324808031320572, Final Batch Loss: 0.18664050102233887\n",
      "Epoch 719, Loss: 0.2942456305027008, Final Batch Loss: 0.1441330909729004\n",
      "Epoch 720, Loss: 0.3063204884529114, Final Batch Loss: 0.1704452782869339\n",
      "Epoch 721, Loss: 0.25819678604602814, Final Batch Loss: 0.1250508427619934\n",
      "Epoch 722, Loss: 0.24521591514348984, Final Batch Loss: 0.0873381569981575\n",
      "Epoch 723, Loss: 0.24486301094293594, Final Batch Loss: 0.13358621299266815\n",
      "Epoch 724, Loss: 0.22666021436452866, Final Batch Loss: 0.10788105428218842\n",
      "Epoch 725, Loss: 0.2615071088075638, Final Batch Loss: 0.13212962448596954\n",
      "Epoch 726, Loss: 0.283208891749382, Final Batch Loss: 0.1525382399559021\n",
      "Epoch 727, Loss: 0.2575170770287514, Final Batch Loss: 0.1340593844652176\n",
      "Epoch 728, Loss: 0.25776372104883194, Final Batch Loss: 0.12346100062131882\n",
      "Epoch 729, Loss: 0.2197786048054695, Final Batch Loss: 0.09441319853067398\n",
      "Epoch 730, Loss: 0.2924512103199959, Final Batch Loss: 0.19247765839099884\n",
      "Epoch 731, Loss: 0.23827184736728668, Final Batch Loss: 0.11507533490657806\n",
      "Epoch 732, Loss: 0.24693743139505386, Final Batch Loss: 0.14541348814964294\n",
      "Epoch 733, Loss: 0.2254631221294403, Final Batch Loss: 0.039749547839164734\n",
      "Epoch 734, Loss: 0.26124459505081177, Final Batch Loss: 0.13501755893230438\n",
      "Epoch 735, Loss: 0.2937067300081253, Final Batch Loss: 0.14551851153373718\n",
      "Epoch 736, Loss: 0.26825592666864395, Final Batch Loss: 0.12144618481397629\n",
      "Epoch 737, Loss: 0.23835573345422745, Final Batch Loss: 0.10403766483068466\n",
      "Epoch 738, Loss: 0.23971036821603775, Final Batch Loss: 0.10679871588945389\n",
      "Epoch 739, Loss: 0.3043903261423111, Final Batch Loss: 0.1319977343082428\n",
      "Epoch 740, Loss: 0.2633877247571945, Final Batch Loss: 0.13785219192504883\n",
      "Epoch 741, Loss: 0.22853676974773407, Final Batch Loss: 0.07965689897537231\n",
      "Epoch 742, Loss: 0.28231360018253326, Final Batch Loss: 0.13623419404029846\n",
      "Epoch 743, Loss: 0.2856863960623741, Final Batch Loss: 0.18628670275211334\n",
      "Epoch 744, Loss: 0.24502761662006378, Final Batch Loss: 0.12444617599248886\n",
      "Epoch 745, Loss: 0.2804507911205292, Final Batch Loss: 0.1560482233762741\n",
      "Epoch 746, Loss: 0.22473999857902527, Final Batch Loss: 0.1037667915225029\n",
      "Epoch 747, Loss: 0.22905907034873962, Final Batch Loss: 0.12287018448114395\n",
      "Epoch 748, Loss: 0.2133055254817009, Final Batch Loss: 0.10397952049970627\n",
      "Epoch 749, Loss: 0.30016572773456573, Final Batch Loss: 0.16780084371566772\n",
      "Epoch 750, Loss: 0.24114938080310822, Final Batch Loss: 0.12075214833021164\n",
      "Epoch 751, Loss: 0.20825716108083725, Final Batch Loss: 0.08004704862833023\n",
      "Epoch 752, Loss: 0.25328584015369415, Final Batch Loss: 0.15473294258117676\n",
      "Epoch 753, Loss: 0.26391588151454926, Final Batch Loss: 0.15000350773334503\n",
      "Epoch 754, Loss: 0.30213047564029694, Final Batch Loss: 0.16885033249855042\n",
      "Epoch 755, Loss: 0.2532469555735588, Final Batch Loss: 0.1228606328368187\n",
      "Epoch 756, Loss: 0.2632250413298607, Final Batch Loss: 0.11648795753717422\n",
      "Epoch 757, Loss: 0.22571202367544174, Final Batch Loss: 0.12378565967082977\n",
      "Epoch 758, Loss: 0.21898242086172104, Final Batch Loss: 0.08570034056901932\n",
      "Epoch 759, Loss: 0.3021358549594879, Final Batch Loss: 0.19585610926151276\n",
      "Epoch 760, Loss: 0.24857356399297714, Final Batch Loss: 0.13981488347053528\n",
      "Epoch 761, Loss: 0.34672071039676666, Final Batch Loss: 0.2032255381345749\n",
      "Epoch 762, Loss: 0.284868024289608, Final Batch Loss: 0.12169360369443893\n",
      "Epoch 763, Loss: 0.329343318939209, Final Batch Loss: 0.24168536067008972\n",
      "Epoch 764, Loss: 0.29890061914920807, Final Batch Loss: 0.1516561359167099\n",
      "Epoch 765, Loss: 0.2696811705827713, Final Batch Loss: 0.11908592283725739\n",
      "Epoch 766, Loss: 0.23312494903802872, Final Batch Loss: 0.09814993292093277\n",
      "Epoch 767, Loss: 0.2583201378583908, Final Batch Loss: 0.13384442031383514\n",
      "Epoch 768, Loss: 0.25082364678382874, Final Batch Loss: 0.14179468154907227\n",
      "Epoch 769, Loss: 0.2313532680273056, Final Batch Loss: 0.09195835888385773\n",
      "Epoch 770, Loss: 0.2772302180528641, Final Batch Loss: 0.19308210909366608\n",
      "Epoch 771, Loss: 0.2938656210899353, Final Batch Loss: 0.16430501639842987\n",
      "Epoch 772, Loss: 0.2367543876171112, Final Batch Loss: 0.11509452015161514\n",
      "Epoch 773, Loss: 0.23284315317869186, Final Batch Loss: 0.12348201125860214\n",
      "Epoch 774, Loss: 0.24889282137155533, Final Batch Loss: 0.1168081983923912\n",
      "Epoch 775, Loss: 0.25288987904787064, Final Batch Loss: 0.14258509874343872\n",
      "Epoch 776, Loss: 0.24245043098926544, Final Batch Loss: 0.09537801146507263\n",
      "Epoch 777, Loss: 0.2624936103820801, Final Batch Loss: 0.14676015079021454\n",
      "Epoch 778, Loss: 0.26019228994846344, Final Batch Loss: 0.1348712146282196\n",
      "Epoch 779, Loss: 0.23311641067266464, Final Batch Loss: 0.09774801880121231\n",
      "Epoch 780, Loss: 0.21830851584672928, Final Batch Loss: 0.10583546757698059\n",
      "Epoch 781, Loss: 0.2372680976986885, Final Batch Loss: 0.08706419914960861\n",
      "Epoch 782, Loss: 0.25492842495441437, Final Batch Loss: 0.09215264022350311\n",
      "Epoch 783, Loss: 0.2521826699376106, Final Batch Loss: 0.09471239894628525\n",
      "Epoch 784, Loss: 0.2978326305747032, Final Batch Loss: 0.1927911639213562\n",
      "Epoch 785, Loss: 0.2924584671854973, Final Batch Loss: 0.1754622608423233\n",
      "Epoch 786, Loss: 0.270692341029644, Final Batch Loss: 0.12350858002901077\n",
      "Epoch 787, Loss: 0.3103952407836914, Final Batch Loss: 0.12900248169898987\n",
      "Epoch 788, Loss: 0.27501849830150604, Final Batch Loss: 0.14445412158966064\n",
      "Epoch 789, Loss: 0.2765056863427162, Final Batch Loss: 0.09794185310602188\n",
      "Epoch 790, Loss: 0.30555586516857147, Final Batch Loss: 0.16965676844120026\n",
      "Epoch 791, Loss: 0.23273862153291702, Final Batch Loss: 0.11140596866607666\n",
      "Epoch 792, Loss: 0.23319590836763382, Final Batch Loss: 0.10856360197067261\n",
      "Epoch 793, Loss: 0.2475418895483017, Final Batch Loss: 0.16361920535564423\n",
      "Epoch 794, Loss: 0.22504767030477524, Final Batch Loss: 0.10219704359769821\n",
      "Epoch 795, Loss: 0.25462234765291214, Final Batch Loss: 0.1333637237548828\n",
      "Epoch 796, Loss: 0.2658372297883034, Final Batch Loss: 0.15446177124977112\n",
      "Epoch 797, Loss: 0.36751122772693634, Final Batch Loss: 0.2194792926311493\n",
      "Epoch 798, Loss: 0.2715974450111389, Final Batch Loss: 0.13598379492759705\n",
      "Epoch 799, Loss: 0.3134559765458107, Final Batch Loss: 0.22211050987243652\n",
      "Epoch 800, Loss: 0.29931024461984634, Final Batch Loss: 0.19579817354679108\n",
      "Epoch 801, Loss: 0.24073585122823715, Final Batch Loss: 0.13242845237255096\n",
      "Epoch 802, Loss: 0.2380170226097107, Final Batch Loss: 0.11346300691366196\n",
      "Epoch 803, Loss: 0.2816231846809387, Final Batch Loss: 0.11208236217498779\n",
      "Epoch 804, Loss: 0.24472244083881378, Final Batch Loss: 0.1475207805633545\n",
      "Epoch 805, Loss: 0.3084307610988617, Final Batch Loss: 0.2031363695859909\n",
      "Epoch 806, Loss: 0.22361642122268677, Final Batch Loss: 0.08755473792552948\n",
      "Epoch 807, Loss: 0.24282661825418472, Final Batch Loss: 0.08718947321176529\n",
      "Epoch 808, Loss: 0.2604702264070511, Final Batch Loss: 0.13418279588222504\n",
      "Epoch 809, Loss: 0.20002040266990662, Final Batch Loss: 0.09832700341939926\n",
      "Epoch 810, Loss: 0.3020719438791275, Final Batch Loss: 0.19910886883735657\n",
      "Epoch 811, Loss: 0.20722148567438126, Final Batch Loss: 0.06573211401700974\n",
      "Epoch 812, Loss: 0.22675176709890366, Final Batch Loss: 0.12255596369504929\n",
      "Epoch 813, Loss: 0.2506488785147667, Final Batch Loss: 0.14649513363838196\n",
      "Epoch 814, Loss: 0.22612600773572922, Final Batch Loss: 0.11652188748121262\n",
      "Epoch 815, Loss: 0.2509877309203148, Final Batch Loss: 0.13714824616909027\n",
      "Epoch 816, Loss: 0.2656400352716446, Final Batch Loss: 0.13271395862102509\n",
      "Epoch 817, Loss: 0.2693033218383789, Final Batch Loss: 0.15637682378292084\n",
      "Epoch 818, Loss: 0.2457566186785698, Final Batch Loss: 0.12736393511295319\n",
      "Epoch 819, Loss: 0.27214568108320236, Final Batch Loss: 0.12418466061353683\n",
      "Epoch 820, Loss: 0.258725181221962, Final Batch Loss: 0.1309823989868164\n",
      "Epoch 821, Loss: 0.23015312105417252, Final Batch Loss: 0.1173676997423172\n",
      "Epoch 822, Loss: 0.21277175843715668, Final Batch Loss: 0.08456912636756897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823, Loss: 0.3049768730998039, Final Batch Loss: 0.19351041316986084\n",
      "Epoch 824, Loss: 0.2385542094707489, Final Batch Loss: 0.14252382516860962\n",
      "Epoch 825, Loss: 0.2922300770878792, Final Batch Loss: 0.1729757934808731\n",
      "Epoch 826, Loss: 0.26630260795354843, Final Batch Loss: 0.15526461601257324\n",
      "Epoch 827, Loss: 0.2845824658870697, Final Batch Loss: 0.15748178958892822\n",
      "Epoch 828, Loss: 0.26185568422079086, Final Batch Loss: 0.14960923790931702\n",
      "Epoch 829, Loss: 0.27795156091451645, Final Batch Loss: 0.15826387703418732\n",
      "Epoch 830, Loss: 0.22696467489004135, Final Batch Loss: 0.09667938202619553\n",
      "Epoch 831, Loss: 0.2332494780421257, Final Batch Loss: 0.09791610389947891\n",
      "Epoch 832, Loss: 0.20281118899583817, Final Batch Loss: 0.09221725165843964\n",
      "Epoch 833, Loss: 0.20722423493862152, Final Batch Loss: 0.09569256007671356\n",
      "Epoch 834, Loss: 0.23013903200626373, Final Batch Loss: 0.10477623343467712\n",
      "Epoch 835, Loss: 0.2037787064909935, Final Batch Loss: 0.07974807918071747\n",
      "Epoch 836, Loss: 0.21307051926851273, Final Batch Loss: 0.08420991152524948\n",
      "Epoch 837, Loss: 0.22698336839675903, Final Batch Loss: 0.12002438306808472\n",
      "Epoch 838, Loss: 0.29223134368658066, Final Batch Loss: 0.1869223266839981\n",
      "Epoch 839, Loss: 0.25615597516298294, Final Batch Loss: 0.13898155093193054\n",
      "Epoch 840, Loss: 0.23846249282360077, Final Batch Loss: 0.09310367703437805\n",
      "Epoch 841, Loss: 0.26116351038217545, Final Batch Loss: 0.11882521957159042\n",
      "Epoch 842, Loss: 0.22431639581918716, Final Batch Loss: 0.09568297117948532\n",
      "Epoch 843, Loss: 0.2561489939689636, Final Batch Loss: 0.13607415556907654\n",
      "Epoch 844, Loss: 0.2727871462702751, Final Batch Loss: 0.1483318954706192\n",
      "Epoch 845, Loss: 0.26908136904239655, Final Batch Loss: 0.13098639249801636\n",
      "Epoch 846, Loss: 0.21937233209609985, Final Batch Loss: 0.08124257624149323\n",
      "Epoch 847, Loss: 0.27520498633384705, Final Batch Loss: 0.17204412817955017\n",
      "Epoch 848, Loss: 0.22545823454856873, Final Batch Loss: 0.14467304944992065\n",
      "Epoch 849, Loss: 0.20123686641454697, Final Batch Loss: 0.09885753691196442\n",
      "Epoch 850, Loss: 0.23460260778665543, Final Batch Loss: 0.09671356528997421\n",
      "Epoch 851, Loss: 0.2289029210805893, Final Batch Loss: 0.1323220282793045\n",
      "Epoch 852, Loss: 0.24597643315792084, Final Batch Loss: 0.09269793331623077\n",
      "Epoch 853, Loss: 0.2313912957906723, Final Batch Loss: 0.07953375577926636\n",
      "Epoch 854, Loss: 0.248381145298481, Final Batch Loss: 0.12184178084135056\n",
      "Epoch 855, Loss: 0.24878034740686417, Final Batch Loss: 0.11336243897676468\n",
      "Epoch 856, Loss: 0.27597978711128235, Final Batch Loss: 0.18150535225868225\n",
      "Epoch 857, Loss: 0.20869804173707962, Final Batch Loss: 0.08051470667123795\n",
      "Epoch 858, Loss: 0.20022506266832352, Final Batch Loss: 0.07292286306619644\n",
      "Epoch 859, Loss: 0.22673805058002472, Final Batch Loss: 0.08251160383224487\n",
      "Epoch 860, Loss: 0.2008603885769844, Final Batch Loss: 0.09328052401542664\n",
      "Epoch 861, Loss: 0.26367026567459106, Final Batch Loss: 0.16592949628829956\n",
      "Epoch 862, Loss: 0.21674375236034393, Final Batch Loss: 0.11675326526165009\n",
      "Epoch 863, Loss: 0.22599633038043976, Final Batch Loss: 0.07818464934825897\n",
      "Epoch 864, Loss: 0.21538365632295609, Final Batch Loss: 0.13457514345645905\n",
      "Epoch 865, Loss: 0.28392475843429565, Final Batch Loss: 0.16097226738929749\n",
      "Epoch 866, Loss: 0.27992577850818634, Final Batch Loss: 0.11869673430919647\n",
      "Epoch 867, Loss: 0.2283424586057663, Final Batch Loss: 0.11669444292783737\n",
      "Epoch 868, Loss: 0.22450466454029083, Final Batch Loss: 0.10637877136468887\n",
      "Epoch 869, Loss: 0.25307677686214447, Final Batch Loss: 0.13106586039066315\n",
      "Epoch 870, Loss: 0.3137599676847458, Final Batch Loss: 0.20069529116153717\n",
      "Epoch 871, Loss: 0.2305164486169815, Final Batch Loss: 0.11570506542921066\n",
      "Epoch 872, Loss: 0.22055523097515106, Final Batch Loss: 0.09754245728254318\n",
      "Epoch 873, Loss: 0.2740829214453697, Final Batch Loss: 0.16276505589485168\n",
      "Epoch 874, Loss: 0.28721538186073303, Final Batch Loss: 0.17746955156326294\n",
      "Epoch 875, Loss: 0.2534056380391121, Final Batch Loss: 0.1018696203827858\n",
      "Epoch 876, Loss: 0.25472644716501236, Final Batch Loss: 0.10813606530427933\n",
      "Epoch 877, Loss: 0.24606891721487045, Final Batch Loss: 0.09300395101308823\n",
      "Epoch 878, Loss: 0.2522587776184082, Final Batch Loss: 0.13994835317134857\n",
      "Epoch 879, Loss: 0.3141716867685318, Final Batch Loss: 0.19040746986865997\n",
      "Epoch 880, Loss: 0.21306870132684708, Final Batch Loss: 0.10708694159984589\n",
      "Epoch 881, Loss: 0.24016862362623215, Final Batch Loss: 0.11893219500780106\n",
      "Epoch 882, Loss: 0.268637977540493, Final Batch Loss: 0.15967048704624176\n",
      "Epoch 883, Loss: 0.25455342233181, Final Batch Loss: 0.1261826902627945\n",
      "Epoch 884, Loss: 0.2107934057712555, Final Batch Loss: 0.09961098432540894\n",
      "Epoch 885, Loss: 0.20129238069057465, Final Batch Loss: 0.07471664249897003\n",
      "Epoch 886, Loss: 0.22082124650478363, Final Batch Loss: 0.10817234963178635\n",
      "Epoch 887, Loss: 0.2566479668021202, Final Batch Loss: 0.12447560578584671\n",
      "Epoch 888, Loss: 0.2862534523010254, Final Batch Loss: 0.18098627030849457\n",
      "Epoch 889, Loss: 0.18930865079164505, Final Batch Loss: 0.07749764621257782\n",
      "Epoch 890, Loss: 0.21052834391593933, Final Batch Loss: 0.08486507833003998\n",
      "Epoch 891, Loss: 0.1985883042216301, Final Batch Loss: 0.10492577403783798\n",
      "Epoch 892, Loss: 0.25253359973430634, Final Batch Loss: 0.12498535215854645\n",
      "Epoch 893, Loss: 0.21125879883766174, Final Batch Loss: 0.08905281871557236\n",
      "Epoch 894, Loss: 0.22756019234657288, Final Batch Loss: 0.08527262508869171\n",
      "Epoch 895, Loss: 0.29525282233953476, Final Batch Loss: 0.20278434455394745\n",
      "Epoch 896, Loss: 0.22101715207099915, Final Batch Loss: 0.07081256806850433\n",
      "Epoch 897, Loss: 0.24962212145328522, Final Batch Loss: 0.14066870510578156\n",
      "Epoch 898, Loss: 0.19892414659261703, Final Batch Loss: 0.10754753649234772\n",
      "Epoch 899, Loss: 0.2113061137497425, Final Batch Loss: 0.05513500049710274\n",
      "Epoch 900, Loss: 0.23294544965028763, Final Batch Loss: 0.12688219547271729\n",
      "Epoch 901, Loss: 0.22222061455249786, Final Batch Loss: 0.11064377427101135\n",
      "Epoch 902, Loss: 0.2792729511857033, Final Batch Loss: 0.10940640419721603\n",
      "Epoch 903, Loss: 0.20647971332073212, Final Batch Loss: 0.07400394976139069\n",
      "Epoch 904, Loss: 0.20629271492362022, Final Batch Loss: 0.04436464235186577\n",
      "Epoch 905, Loss: 0.22877590358257294, Final Batch Loss: 0.1147775948047638\n",
      "Epoch 906, Loss: 0.2518705427646637, Final Batch Loss: 0.13105051219463348\n",
      "Epoch 907, Loss: 0.19777051359415054, Final Batch Loss: 0.07513385266065598\n",
      "Epoch 908, Loss: 0.21607595682144165, Final Batch Loss: 0.09837455302476883\n",
      "Epoch 909, Loss: 0.2689635008573532, Final Batch Loss: 0.14256855845451355\n",
      "Epoch 910, Loss: 0.31271591037511826, Final Batch Loss: 0.21306073665618896\n",
      "Epoch 911, Loss: 0.26865388453006744, Final Batch Loss: 0.10466359555721283\n",
      "Epoch 912, Loss: 0.20718372613191605, Final Batch Loss: 0.10001406818628311\n",
      "Epoch 913, Loss: 0.22658671438694, Final Batch Loss: 0.11033706367015839\n",
      "Epoch 914, Loss: 0.2555946633219719, Final Batch Loss: 0.11523861438035965\n",
      "Epoch 915, Loss: 0.2608456239104271, Final Batch Loss: 0.11911758035421371\n",
      "Epoch 916, Loss: 0.19272323697805405, Final Batch Loss: 0.07257141172885895\n",
      "Epoch 917, Loss: 0.20992816239595413, Final Batch Loss: 0.09633120894432068\n",
      "Epoch 918, Loss: 0.24994153529405594, Final Batch Loss: 0.14171336591243744\n",
      "Epoch 919, Loss: 0.23566316068172455, Final Batch Loss: 0.12779659032821655\n",
      "Epoch 920, Loss: 0.2525680661201477, Final Batch Loss: 0.14954380691051483\n",
      "Epoch 921, Loss: 0.20914217084646225, Final Batch Loss: 0.07545610517263412\n",
      "Epoch 922, Loss: 0.27523674815893173, Final Batch Loss: 0.18417422473430634\n",
      "Epoch 923, Loss: 0.23853790760040283, Final Batch Loss: 0.12309742718935013\n",
      "Epoch 924, Loss: 0.20268014818429947, Final Batch Loss: 0.09571999311447144\n",
      "Epoch 925, Loss: 0.22587569802999496, Final Batch Loss: 0.1019553393125534\n",
      "Epoch 926, Loss: 0.21935328841209412, Final Batch Loss: 0.10004757344722748\n",
      "Epoch 927, Loss: 0.23747681826353073, Final Batch Loss: 0.13767771422863007\n",
      "Epoch 928, Loss: 0.22265976667404175, Final Batch Loss: 0.126702219247818\n",
      "Epoch 929, Loss: 0.19388161599636078, Final Batch Loss: 0.07334762811660767\n",
      "Epoch 930, Loss: 0.20183036476373672, Final Batch Loss: 0.08662593364715576\n",
      "Epoch 931, Loss: 0.318028524518013, Final Batch Loss: 0.21012136340141296\n",
      "Epoch 932, Loss: 0.2134348377585411, Final Batch Loss: 0.0854240134358406\n",
      "Epoch 933, Loss: 0.3595062643289566, Final Batch Loss: 0.24446947872638702\n",
      "Epoch 934, Loss: 0.20715557038784027, Final Batch Loss: 0.10184314101934433\n",
      "Epoch 935, Loss: 0.1889893263578415, Final Batch Loss: 0.0941208004951477\n",
      "Epoch 936, Loss: 0.20032253861427307, Final Batch Loss: 0.06826707720756531\n",
      "Epoch 937, Loss: 0.19522560387849808, Final Batch Loss: 0.0921570286154747\n",
      "Epoch 938, Loss: 0.2753693088889122, Final Batch Loss: 0.18849602341651917\n",
      "Epoch 939, Loss: 0.21955014020204544, Final Batch Loss: 0.11630434542894363\n",
      "Epoch 940, Loss: 0.18809963762760162, Final Batch Loss: 0.06841996312141418\n",
      "Epoch 941, Loss: 0.19100628793239594, Final Batch Loss: 0.07840504497289658\n",
      "Epoch 942, Loss: 0.22431575506925583, Final Batch Loss: 0.12248202413320541\n",
      "Epoch 943, Loss: 0.26621533930301666, Final Batch Loss: 0.15565378963947296\n",
      "Epoch 944, Loss: 0.1798093095421791, Final Batch Loss: 0.07723309844732285\n",
      "Epoch 945, Loss: 0.24287362396717072, Final Batch Loss: 0.12339584529399872\n",
      "Epoch 946, Loss: 0.19555258750915527, Final Batch Loss: 0.10062161833047867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947, Loss: 0.20773082971572876, Final Batch Loss: 0.08689665794372559\n",
      "Epoch 948, Loss: 0.22668521851301193, Final Batch Loss: 0.10196948051452637\n",
      "Epoch 949, Loss: 0.22779271751642227, Final Batch Loss: 0.1362169086933136\n",
      "Epoch 950, Loss: 0.21490024030208588, Final Batch Loss: 0.09456101059913635\n",
      "Epoch 951, Loss: 0.2133941575884819, Final Batch Loss: 0.07160007208585739\n",
      "Epoch 952, Loss: 0.26572491228580475, Final Batch Loss: 0.1371828317642212\n",
      "Epoch 953, Loss: 0.2303498089313507, Final Batch Loss: 0.09563404321670532\n",
      "Epoch 954, Loss: 0.24421219527721405, Final Batch Loss: 0.15363137423992157\n",
      "Epoch 955, Loss: 0.2908841669559479, Final Batch Loss: 0.15974676609039307\n",
      "Epoch 956, Loss: 0.2145145684480667, Final Batch Loss: 0.0635845810174942\n",
      "Epoch 957, Loss: 0.25095731019973755, Final Batch Loss: 0.12865129113197327\n",
      "Epoch 958, Loss: 0.21723558753728867, Final Batch Loss: 0.11460937559604645\n",
      "Epoch 959, Loss: 0.19932381808757782, Final Batch Loss: 0.07669860869646072\n",
      "Epoch 960, Loss: 0.22754698991775513, Final Batch Loss: 0.12729135155677795\n",
      "Epoch 961, Loss: 0.26682984083890915, Final Batch Loss: 0.1626937836408615\n",
      "Epoch 962, Loss: 0.170199453830719, Final Batch Loss: 0.06949946284294128\n",
      "Epoch 963, Loss: 0.21097488701343536, Final Batch Loss: 0.12629856169223785\n",
      "Epoch 964, Loss: 0.19820889830589294, Final Batch Loss: 0.07976657152175903\n",
      "Epoch 965, Loss: 0.2813315913081169, Final Batch Loss: 0.18225853145122528\n",
      "Epoch 966, Loss: 0.20183205604553223, Final Batch Loss: 0.09686915576457977\n",
      "Epoch 967, Loss: 0.22522420436143875, Final Batch Loss: 0.09255114942789078\n",
      "Epoch 968, Loss: 0.23747893422842026, Final Batch Loss: 0.1297370046377182\n",
      "Epoch 969, Loss: 0.21750211715698242, Final Batch Loss: 0.09144732356071472\n",
      "Epoch 970, Loss: 0.259698249399662, Final Batch Loss: 0.12420646101236343\n",
      "Epoch 971, Loss: 0.20631658285856247, Final Batch Loss: 0.10123734176158905\n",
      "Epoch 972, Loss: 0.22437582165002823, Final Batch Loss: 0.11305353790521622\n",
      "Epoch 973, Loss: 0.21731940656900406, Final Batch Loss: 0.09182383865118027\n",
      "Epoch 974, Loss: 0.17441490665078163, Final Batch Loss: 0.054128844290971756\n",
      "Epoch 975, Loss: 0.19699776917696, Final Batch Loss: 0.1148417666554451\n",
      "Epoch 976, Loss: 0.17287766933441162, Final Batch Loss: 0.08564063161611557\n",
      "Epoch 977, Loss: 0.27742423862218857, Final Batch Loss: 0.18337996304035187\n",
      "Epoch 978, Loss: 0.20756813138723373, Final Batch Loss: 0.10400424152612686\n",
      "Epoch 979, Loss: 0.17969228327274323, Final Batch Loss: 0.08339211344718933\n",
      "Epoch 980, Loss: 0.25093089044094086, Final Batch Loss: 0.16854791343212128\n",
      "Epoch 981, Loss: 0.2338649183511734, Final Batch Loss: 0.11067412793636322\n",
      "Epoch 982, Loss: 0.23192189633846283, Final Batch Loss: 0.0808490514755249\n",
      "Epoch 983, Loss: 0.22727426141500473, Final Batch Loss: 0.13011494278907776\n",
      "Epoch 984, Loss: 0.23969463258981705, Final Batch Loss: 0.12588414549827576\n",
      "Epoch 985, Loss: 0.2261732891201973, Final Batch Loss: 0.11763135343790054\n",
      "Epoch 986, Loss: 0.2374565303325653, Final Batch Loss: 0.11549035459756851\n",
      "Epoch 987, Loss: 0.24909571558237076, Final Batch Loss: 0.10322072356939316\n",
      "Epoch 988, Loss: 0.1822962686419487, Final Batch Loss: 0.07865993678569794\n",
      "Epoch 989, Loss: 0.2314441129565239, Final Batch Loss: 0.12421618402004242\n",
      "Epoch 990, Loss: 0.2313229963183403, Final Batch Loss: 0.10960724949836731\n",
      "Epoch 991, Loss: 0.27948151528835297, Final Batch Loss: 0.10836562514305115\n",
      "Epoch 992, Loss: 0.24267494678497314, Final Batch Loss: 0.13179853558540344\n",
      "Epoch 993, Loss: 0.19990409910678864, Final Batch Loss: 0.11110927164554596\n",
      "Epoch 994, Loss: 0.22171448916196823, Final Batch Loss: 0.12467817962169647\n",
      "Epoch 995, Loss: 0.2122335284948349, Final Batch Loss: 0.09867431223392487\n",
      "Epoch 996, Loss: 0.20479365438222885, Final Batch Loss: 0.11361053586006165\n",
      "Epoch 997, Loss: 0.20001410692930222, Final Batch Loss: 0.08573295921087265\n",
      "Epoch 998, Loss: 0.1705627329647541, Final Batch Loss: 0.062465328723192215\n",
      "Epoch 999, Loss: 0.23120960593223572, Final Batch Loss: 0.0975097268819809\n",
      "Epoch 1000, Loss: 0.1910809725522995, Final Batch Loss: 0.10156062245368958\n",
      "Epoch 1001, Loss: 0.24656984210014343, Final Batch Loss: 0.09998363256454468\n",
      "Epoch 1002, Loss: 0.23327983170747757, Final Batch Loss: 0.12931682169437408\n",
      "Epoch 1003, Loss: 0.24545016139745712, Final Batch Loss: 0.15613950788974762\n",
      "Epoch 1004, Loss: 0.2935551479458809, Final Batch Loss: 0.16874907910823822\n",
      "Epoch 1005, Loss: 0.23259437084197998, Final Batch Loss: 0.12740784883499146\n",
      "Epoch 1006, Loss: 0.20887520164251328, Final Batch Loss: 0.09869059175252914\n",
      "Epoch 1007, Loss: 0.24469900876283646, Final Batch Loss: 0.1322643905878067\n",
      "Epoch 1008, Loss: 0.20236637443304062, Final Batch Loss: 0.0915730744600296\n",
      "Epoch 1009, Loss: 0.25068987160921097, Final Batch Loss: 0.10058144479990005\n",
      "Epoch 1010, Loss: 0.2641078159213066, Final Batch Loss: 0.1448618620634079\n",
      "Epoch 1011, Loss: 0.25658704340457916, Final Batch Loss: 0.1561281830072403\n",
      "Epoch 1012, Loss: 0.2001207023859024, Final Batch Loss: 0.10274333506822586\n",
      "Epoch 1013, Loss: 0.20492452383041382, Final Batch Loss: 0.11468449980020523\n",
      "Epoch 1014, Loss: 0.308234304189682, Final Batch Loss: 0.1814386248588562\n",
      "Epoch 1015, Loss: 0.24562936276197433, Final Batch Loss: 0.09763983637094498\n",
      "Epoch 1016, Loss: 0.23967401683330536, Final Batch Loss: 0.06355798244476318\n",
      "Epoch 1017, Loss: 0.2489992082118988, Final Batch Loss: 0.15354010462760925\n",
      "Epoch 1018, Loss: 0.19300366938114166, Final Batch Loss: 0.10192643105983734\n",
      "Epoch 1019, Loss: 0.2195335105061531, Final Batch Loss: 0.12372000515460968\n",
      "Epoch 1020, Loss: 0.2379525601863861, Final Batch Loss: 0.11989962309598923\n",
      "Epoch 1021, Loss: 0.253417931497097, Final Batch Loss: 0.14221878349781036\n",
      "Epoch 1022, Loss: 0.2265598028898239, Final Batch Loss: 0.10119768977165222\n",
      "Epoch 1023, Loss: 0.18142783641815186, Final Batch Loss: 0.06497924029827118\n",
      "Epoch 1024, Loss: 0.275053046643734, Final Batch Loss: 0.17629972100257874\n",
      "Epoch 1025, Loss: 0.22561683878302574, Final Batch Loss: 0.16422636806964874\n",
      "Epoch 1026, Loss: 0.19659218192100525, Final Batch Loss: 0.08875701576471329\n",
      "Epoch 1027, Loss: 0.2489257976412773, Final Batch Loss: 0.1333458572626114\n",
      "Epoch 1028, Loss: 0.20574940741062164, Final Batch Loss: 0.08244822919368744\n",
      "Epoch 1029, Loss: 0.20913349092006683, Final Batch Loss: 0.07488097250461578\n",
      "Epoch 1030, Loss: 0.2032952979207039, Final Batch Loss: 0.07499434798955917\n",
      "Epoch 1031, Loss: 0.21406510472297668, Final Batch Loss: 0.11256164312362671\n",
      "Epoch 1032, Loss: 0.19475191086530685, Final Batch Loss: 0.10875305533409119\n",
      "Epoch 1033, Loss: 0.23008380830287933, Final Batch Loss: 0.09381210803985596\n",
      "Epoch 1034, Loss: 0.18394777178764343, Final Batch Loss: 0.08382495492696762\n",
      "Epoch 1035, Loss: 0.25327810645103455, Final Batch Loss: 0.12064319849014282\n",
      "Epoch 1036, Loss: 0.20381689816713333, Final Batch Loss: 0.13308095932006836\n",
      "Epoch 1037, Loss: 0.20558901131153107, Final Batch Loss: 0.10367798060178757\n",
      "Epoch 1038, Loss: 0.19144468754529953, Final Batch Loss: 0.08087105304002762\n",
      "Epoch 1039, Loss: 0.18731320649385452, Final Batch Loss: 0.08492416143417358\n",
      "Epoch 1040, Loss: 0.26206641644239426, Final Batch Loss: 0.17023566365242004\n",
      "Epoch 1041, Loss: 0.25429440289735794, Final Batch Loss: 0.1413939744234085\n",
      "Epoch 1042, Loss: 0.23402189463377, Final Batch Loss: 0.11252844333648682\n",
      "Epoch 1043, Loss: 0.21057681739330292, Final Batch Loss: 0.08678615093231201\n",
      "Epoch 1044, Loss: 0.30837494134902954, Final Batch Loss: 0.19553864002227783\n",
      "Epoch 1045, Loss: 0.2124943509697914, Final Batch Loss: 0.10886187851428986\n",
      "Epoch 1046, Loss: 0.19365361332893372, Final Batch Loss: 0.09055512398481369\n",
      "Epoch 1047, Loss: 0.222025565803051, Final Batch Loss: 0.11504554748535156\n",
      "Epoch 1048, Loss: 0.3039820045232773, Final Batch Loss: 0.18894071877002716\n",
      "Epoch 1049, Loss: 0.20681662112474442, Final Batch Loss: 0.12565094232559204\n",
      "Epoch 1050, Loss: 0.2104325294494629, Final Batch Loss: 0.09747044742107391\n",
      "Epoch 1051, Loss: 0.22585639357566833, Final Batch Loss: 0.1147640198469162\n",
      "Epoch 1052, Loss: 0.21139158308506012, Final Batch Loss: 0.08727974444627762\n",
      "Epoch 1053, Loss: 0.30129899084568024, Final Batch Loss: 0.14667274057865143\n",
      "Epoch 1054, Loss: 0.3160867914557457, Final Batch Loss: 0.2095222771167755\n",
      "Epoch 1055, Loss: 0.1928873062133789, Final Batch Loss: 0.09154807776212692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1056, Loss: 0.23629138618707657, Final Batch Loss: 0.12030041217803955\n",
      "Epoch 1057, Loss: 0.2325388416647911, Final Batch Loss: 0.1165890023112297\n",
      "Epoch 1058, Loss: 0.21401526033878326, Final Batch Loss: 0.10173004865646362\n",
      "Epoch 1059, Loss: 0.17462851107120514, Final Batch Loss: 0.07894263416528702\n",
      "Epoch 1060, Loss: 0.2229815274477005, Final Batch Loss: 0.1047220230102539\n",
      "Epoch 1061, Loss: 0.18145551159977913, Final Batch Loss: 0.044046033173799515\n",
      "Epoch 1062, Loss: 0.22192727774381638, Final Batch Loss: 0.13191287219524384\n",
      "Epoch 1063, Loss: 0.23529160767793655, Final Batch Loss: 0.09492874890565872\n",
      "Epoch 1064, Loss: 0.1882474347949028, Final Batch Loss: 0.08271212130784988\n",
      "Epoch 1065, Loss: 0.21492323279380798, Final Batch Loss: 0.1120440736413002\n",
      "Epoch 1066, Loss: 0.25065384805202484, Final Batch Loss: 0.14566613733768463\n",
      "Epoch 1067, Loss: 0.19050099700689316, Final Batch Loss: 0.09037411212921143\n",
      "Epoch 1068, Loss: 0.2188286855816841, Final Batch Loss: 0.11140745878219604\n",
      "Epoch 1069, Loss: 0.255825474858284, Final Batch Loss: 0.16689078509807587\n",
      "Epoch 1070, Loss: 0.23016250878572464, Final Batch Loss: 0.1240256056189537\n",
      "Epoch 1071, Loss: 0.18210766464471817, Final Batch Loss: 0.08086345344781876\n",
      "Epoch 1072, Loss: 0.2004092037677765, Final Batch Loss: 0.08664955198764801\n",
      "Epoch 1073, Loss: 0.22385095804929733, Final Batch Loss: 0.09473774582147598\n",
      "Epoch 1074, Loss: 0.21898071467876434, Final Batch Loss: 0.10961936414241791\n",
      "Epoch 1075, Loss: 0.22380049526691437, Final Batch Loss: 0.12124422937631607\n",
      "Epoch 1076, Loss: 0.1985129490494728, Final Batch Loss: 0.08040808886289597\n",
      "Epoch 1077, Loss: 0.2140054702758789, Final Batch Loss: 0.0965554416179657\n",
      "Epoch 1078, Loss: 0.2372102215886116, Final Batch Loss: 0.12211272865533829\n",
      "Epoch 1079, Loss: 0.19815141707658768, Final Batch Loss: 0.11798179894685745\n",
      "Epoch 1080, Loss: 0.23961758613586426, Final Batch Loss: 0.11474967747926712\n",
      "Epoch 1081, Loss: 0.22230495512485504, Final Batch Loss: 0.10935061424970627\n",
      "Epoch 1082, Loss: 0.1791648045182228, Final Batch Loss: 0.0901678204536438\n",
      "Epoch 1083, Loss: 0.22943364828824997, Final Batch Loss: 0.1328732967376709\n",
      "Epoch 1084, Loss: 0.22920601069927216, Final Batch Loss: 0.141870379447937\n",
      "Epoch 1085, Loss: 0.2176642343401909, Final Batch Loss: 0.12196779996156693\n",
      "Epoch 1086, Loss: 0.270073838531971, Final Batch Loss: 0.1772710382938385\n",
      "Epoch 1087, Loss: 0.22977221012115479, Final Batch Loss: 0.14214849472045898\n",
      "Epoch 1088, Loss: 0.26830387860536575, Final Batch Loss: 0.14842568337917328\n",
      "Epoch 1089, Loss: 0.2273665964603424, Final Batch Loss: 0.1300671249628067\n",
      "Epoch 1090, Loss: 0.24548227339982986, Final Batch Loss: 0.1309240609407425\n",
      "Epoch 1091, Loss: 0.20636481046676636, Final Batch Loss: 0.10420192033052444\n",
      "Epoch 1092, Loss: 0.23196131736040115, Final Batch Loss: 0.11298592388629913\n",
      "Epoch 1093, Loss: 0.19685422629117966, Final Batch Loss: 0.07890795171260834\n",
      "Epoch 1094, Loss: 0.2236097976565361, Final Batch Loss: 0.12430806457996368\n",
      "Epoch 1095, Loss: 0.22916341572999954, Final Batch Loss: 0.12047263979911804\n",
      "Epoch 1096, Loss: 0.2547633871436119, Final Batch Loss: 0.1543225198984146\n",
      "Epoch 1097, Loss: 0.17148828506469727, Final Batch Loss: 0.061185114085674286\n",
      "Epoch 1098, Loss: 0.2345474287867546, Final Batch Loss: 0.12825842201709747\n",
      "Epoch 1099, Loss: 0.2102864906191826, Final Batch Loss: 0.09273276478052139\n",
      "Epoch 1100, Loss: 0.25291234999895096, Final Batch Loss: 0.14509020745754242\n",
      "Epoch 1101, Loss: 0.22324492782354355, Final Batch Loss: 0.1332252323627472\n",
      "Epoch 1102, Loss: 0.1643163338303566, Final Batch Loss: 0.05896978825330734\n",
      "Epoch 1103, Loss: 0.21210766583681107, Final Batch Loss: 0.11126136034727097\n",
      "Epoch 1104, Loss: 0.21621856838464737, Final Batch Loss: 0.09675817936658859\n",
      "Epoch 1105, Loss: 0.2466234639286995, Final Batch Loss: 0.13551634550094604\n",
      "Epoch 1106, Loss: 0.19175828248262405, Final Batch Loss: 0.0886177197098732\n",
      "Epoch 1107, Loss: 0.29463084787130356, Final Batch Loss: 0.19479794800281525\n",
      "Epoch 1108, Loss: 0.21033581346273422, Final Batch Loss: 0.11811913549900055\n",
      "Epoch 1109, Loss: 0.19537316262722015, Final Batch Loss: 0.09745648503303528\n",
      "Epoch 1110, Loss: 0.1935129091143608, Final Batch Loss: 0.09361973404884338\n",
      "Epoch 1111, Loss: 0.24700410664081573, Final Batch Loss: 0.1254958063364029\n",
      "Epoch 1112, Loss: 0.18858284503221512, Final Batch Loss: 0.06711707264184952\n",
      "Epoch 1113, Loss: 0.19081710278987885, Final Batch Loss: 0.11045315861701965\n",
      "Epoch 1114, Loss: 0.1834137961268425, Final Batch Loss: 0.07771371304988861\n",
      "Epoch 1115, Loss: 0.17169182002544403, Final Batch Loss: 0.0688057392835617\n",
      "Epoch 1116, Loss: 0.23343131691217422, Final Batch Loss: 0.13621456921100616\n",
      "Epoch 1117, Loss: 0.22182349115610123, Final Batch Loss: 0.07540049403905869\n",
      "Epoch 1118, Loss: 0.211859792470932, Final Batch Loss: 0.11221426725387573\n",
      "Epoch 1119, Loss: 0.21633020788431168, Final Batch Loss: 0.1297580599784851\n",
      "Epoch 1120, Loss: 0.18375102058053017, Final Batch Loss: 0.055523667484521866\n",
      "Epoch 1121, Loss: 0.2517976388335228, Final Batch Loss: 0.13842613995075226\n",
      "Epoch 1122, Loss: 0.1766105219721794, Final Batch Loss: 0.0768059492111206\n",
      "Epoch 1123, Loss: 0.23390448838472366, Final Batch Loss: 0.13389348983764648\n",
      "Epoch 1124, Loss: 0.20468104630708694, Final Batch Loss: 0.10841021686792374\n",
      "Epoch 1125, Loss: 0.18897175043821335, Final Batch Loss: 0.08625433593988419\n",
      "Epoch 1126, Loss: 0.2170870527625084, Final Batch Loss: 0.12177830934524536\n",
      "Epoch 1127, Loss: 0.16636639833450317, Final Batch Loss: 0.0796775370836258\n",
      "Epoch 1128, Loss: 0.20022114366292953, Final Batch Loss: 0.06725247949361801\n",
      "Epoch 1129, Loss: 0.2123047262430191, Final Batch Loss: 0.0905662402510643\n",
      "Epoch 1130, Loss: 0.2222628816962242, Final Batch Loss: 0.10214177519083023\n",
      "Epoch 1131, Loss: 0.22532042115926743, Final Batch Loss: 0.12711168825626373\n",
      "Epoch 1132, Loss: 0.20472391694784164, Final Batch Loss: 0.09609822183847427\n",
      "Epoch 1133, Loss: 0.1635056883096695, Final Batch Loss: 0.06436767429113388\n",
      "Epoch 1134, Loss: 0.19721719622612, Final Batch Loss: 0.09539280086755753\n",
      "Epoch 1135, Loss: 0.1983860358595848, Final Batch Loss: 0.08212167024612427\n",
      "Epoch 1136, Loss: 0.2473311424255371, Final Batch Loss: 0.09954772889614105\n",
      "Epoch 1137, Loss: 0.2590414360165596, Final Batch Loss: 0.1698761284351349\n",
      "Epoch 1138, Loss: 0.20449047535657883, Final Batch Loss: 0.09350289404392242\n",
      "Epoch 1139, Loss: 0.23717714846134186, Final Batch Loss: 0.13832391798496246\n",
      "Epoch 1140, Loss: 0.22558878362178802, Final Batch Loss: 0.12826687097549438\n",
      "Epoch 1141, Loss: 0.16861605644226074, Final Batch Loss: 0.0390763133764267\n",
      "Epoch 1142, Loss: 0.24567364156246185, Final Batch Loss: 0.13036856055259705\n",
      "Epoch 1143, Loss: 0.19467255473136902, Final Batch Loss: 0.1149609237909317\n",
      "Epoch 1144, Loss: 0.21706927567720413, Final Batch Loss: 0.13435813784599304\n",
      "Epoch 1145, Loss: 0.20948726683855057, Final Batch Loss: 0.1116175428032875\n",
      "Epoch 1146, Loss: 0.24057753384113312, Final Batch Loss: 0.155162513256073\n",
      "Epoch 1147, Loss: 0.20494328439235687, Final Batch Loss: 0.11300621926784515\n",
      "Epoch 1148, Loss: 0.3001207336783409, Final Batch Loss: 0.2003328800201416\n",
      "Epoch 1149, Loss: 0.19602849334478378, Final Batch Loss: 0.06579730659723282\n",
      "Epoch 1150, Loss: 0.19881952553987503, Final Batch Loss: 0.07504256814718246\n",
      "Epoch 1151, Loss: 0.22243919223546982, Final Batch Loss: 0.13123606145381927\n",
      "Epoch 1152, Loss: 0.1674864925444126, Final Batch Loss: 0.0556618832051754\n",
      "Epoch 1153, Loss: 0.17287784814834595, Final Batch Loss: 0.06257054954767227\n",
      "Epoch 1154, Loss: 0.22116142511367798, Final Batch Loss: 0.10656725615262985\n",
      "Epoch 1155, Loss: 0.2089349552989006, Final Batch Loss: 0.1278427690267563\n",
      "Epoch 1156, Loss: 0.16252926737070084, Final Batch Loss: 0.05557215213775635\n",
      "Epoch 1157, Loss: 0.21719344705343246, Final Batch Loss: 0.09342220425605774\n",
      "Epoch 1158, Loss: 0.25391092896461487, Final Batch Loss: 0.15815328061580658\n",
      "Epoch 1159, Loss: 0.2191789746284485, Final Batch Loss: 0.08215045928955078\n",
      "Epoch 1160, Loss: 0.209161639213562, Final Batch Loss: 0.07480141520500183\n",
      "Epoch 1161, Loss: 0.20479830354452133, Final Batch Loss: 0.11505082249641418\n",
      "Epoch 1162, Loss: 0.1976044923067093, Final Batch Loss: 0.06566743552684784\n",
      "Epoch 1163, Loss: 0.18054810166358948, Final Batch Loss: 0.07759010791778564\n",
      "Epoch 1164, Loss: 0.21923161298036575, Final Batch Loss: 0.10375045239925385\n",
      "Epoch 1165, Loss: 0.18585169315338135, Final Batch Loss: 0.0865592285990715\n",
      "Epoch 1166, Loss: 0.17544159293174744, Final Batch Loss: 0.0626445859670639\n",
      "Epoch 1167, Loss: 0.2333606705069542, Final Batch Loss: 0.12669724225997925\n",
      "Epoch 1168, Loss: 0.34753039479255676, Final Batch Loss: 0.23573404550552368\n",
      "Epoch 1169, Loss: 0.20083437114953995, Final Batch Loss: 0.09126187115907669\n",
      "Epoch 1170, Loss: 0.17273131757974625, Final Batch Loss: 0.06827202439308167\n",
      "Epoch 1171, Loss: 0.2693776711821556, Final Batch Loss: 0.1606750786304474\n",
      "Epoch 1172, Loss: 0.24026205390691757, Final Batch Loss: 0.11880744248628616\n",
      "Epoch 1173, Loss: 0.23329471796751022, Final Batch Loss: 0.10945034772157669\n",
      "Epoch 1174, Loss: 0.28430473804473877, Final Batch Loss: 0.1835964173078537\n",
      "Epoch 1175, Loss: 0.20717546343803406, Final Batch Loss: 0.10120097547769547\n",
      "Epoch 1176, Loss: 0.21211323887109756, Final Batch Loss: 0.07388351112604141\n",
      "Epoch 1177, Loss: 0.18795397877693176, Final Batch Loss: 0.0854940265417099\n",
      "Epoch 1178, Loss: 0.17222539335489273, Final Batch Loss: 0.06728656589984894\n",
      "Epoch 1179, Loss: 0.219611294567585, Final Batch Loss: 0.08382096141576767\n",
      "Epoch 1180, Loss: 0.2013399600982666, Final Batch Loss: 0.12207295745611191\n",
      "Epoch 1181, Loss: 0.19265828281641006, Final Batch Loss: 0.09431998431682587\n",
      "Epoch 1182, Loss: 0.15714383497834206, Final Batch Loss: 0.060592275112867355\n",
      "Epoch 1183, Loss: 0.21619678288698196, Final Batch Loss: 0.1100897267460823\n",
      "Epoch 1184, Loss: 0.18264078721404076, Final Batch Loss: 0.058024290949106216\n",
      "Epoch 1185, Loss: 0.17063301801681519, Final Batch Loss: 0.07762701064348221\n",
      "Epoch 1186, Loss: 0.20147578418254852, Final Batch Loss: 0.07912489771842957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1187, Loss: 0.21718358248472214, Final Batch Loss: 0.1497744768857956\n",
      "Epoch 1188, Loss: 0.23742835223674774, Final Batch Loss: 0.1322007179260254\n",
      "Epoch 1189, Loss: 0.19660645723342896, Final Batch Loss: 0.10405732691287994\n",
      "Epoch 1190, Loss: 0.20319174230098724, Final Batch Loss: 0.1280919462442398\n",
      "Epoch 1191, Loss: 0.21357719600200653, Final Batch Loss: 0.12738898396492004\n",
      "Epoch 1192, Loss: 0.19719532132148743, Final Batch Loss: 0.10674446076154709\n",
      "Epoch 1193, Loss: 0.24670914560556412, Final Batch Loss: 0.1390228271484375\n",
      "Epoch 1194, Loss: 0.22215229272842407, Final Batch Loss: 0.13021047413349152\n",
      "Epoch 1195, Loss: 0.19065368920564651, Final Batch Loss: 0.1124945729970932\n",
      "Epoch 1196, Loss: 0.18803508579730988, Final Batch Loss: 0.07646378129720688\n",
      "Epoch 1197, Loss: 0.19031719118356705, Final Batch Loss: 0.09041138738393784\n",
      "Epoch 1198, Loss: 0.20045358687639236, Final Batch Loss: 0.11885033547878265\n",
      "Epoch 1199, Loss: 0.1945500373840332, Final Batch Loss: 0.0979095846414566\n",
      "Epoch 1200, Loss: 0.2126215398311615, Final Batch Loss: 0.10543747246265411\n",
      "Epoch 1201, Loss: 0.1923423409461975, Final Batch Loss: 0.06280618906021118\n",
      "Epoch 1202, Loss: 0.19557440280914307, Final Batch Loss: 0.0831378921866417\n",
      "Epoch 1203, Loss: 0.2208370789885521, Final Batch Loss: 0.1255292445421219\n",
      "Epoch 1204, Loss: 0.2327985242009163, Final Batch Loss: 0.12218716740608215\n",
      "Epoch 1205, Loss: 0.1524539366364479, Final Batch Loss: 0.059966981410980225\n",
      "Epoch 1206, Loss: 0.18958886712789536, Final Batch Loss: 0.1035328283905983\n",
      "Epoch 1207, Loss: 0.18855049461126328, Final Batch Loss: 0.08443824201822281\n",
      "Epoch 1208, Loss: 0.1950862929224968, Final Batch Loss: 0.0881071388721466\n",
      "Epoch 1209, Loss: 0.2207949236035347, Final Batch Loss: 0.11700087785720825\n",
      "Epoch 1210, Loss: 0.21119645982980728, Final Batch Loss: 0.08602974563837051\n",
      "Epoch 1211, Loss: 0.19832659512758255, Final Batch Loss: 0.09456932544708252\n",
      "Epoch 1212, Loss: 0.1977579966187477, Final Batch Loss: 0.10819210112094879\n",
      "Epoch 1213, Loss: 0.22443818300962448, Final Batch Loss: 0.14555680751800537\n",
      "Epoch 1214, Loss: 0.19676699489355087, Final Batch Loss: 0.07947304844856262\n",
      "Epoch 1215, Loss: 0.18503987789154053, Final Batch Loss: 0.08972790092229843\n",
      "Epoch 1216, Loss: 0.176674947142601, Final Batch Loss: 0.08041304349899292\n",
      "Epoch 1217, Loss: 0.19150174409151077, Final Batch Loss: 0.06371060758829117\n",
      "Epoch 1218, Loss: 0.24597962945699692, Final Batch Loss: 0.10354157537221909\n",
      "Epoch 1219, Loss: 0.16292930394411087, Final Batch Loss: 0.05619392544031143\n",
      "Epoch 1220, Loss: 0.23318566381931305, Final Batch Loss: 0.1446152627468109\n",
      "Epoch 1221, Loss: 0.23475586622953415, Final Batch Loss: 0.14846143126487732\n",
      "Epoch 1222, Loss: 0.21932081878185272, Final Batch Loss: 0.10269026458263397\n",
      "Epoch 1223, Loss: 0.19075918197631836, Final Batch Loss: 0.07617728412151337\n",
      "Epoch 1224, Loss: 0.21024875342845917, Final Batch Loss: 0.10399207472801208\n",
      "Epoch 1225, Loss: 0.19775980710983276, Final Batch Loss: 0.10366012901067734\n",
      "Epoch 1226, Loss: 0.19719408452510834, Final Batch Loss: 0.08676028251647949\n",
      "Epoch 1227, Loss: 0.18249744921922684, Final Batch Loss: 0.08359874039888382\n",
      "Epoch 1228, Loss: 0.1998031958937645, Final Batch Loss: 0.1220109686255455\n",
      "Epoch 1229, Loss: 0.23092927783727646, Final Batch Loss: 0.16193151473999023\n",
      "Epoch 1230, Loss: 0.19666650891304016, Final Batch Loss: 0.11276977509260178\n",
      "Epoch 1231, Loss: 0.20110367238521576, Final Batch Loss: 0.12101774662733078\n",
      "Epoch 1232, Loss: 0.27417123317718506, Final Batch Loss: 0.1899682879447937\n",
      "Epoch 1233, Loss: 0.22187479585409164, Final Batch Loss: 0.1572548747062683\n",
      "Epoch 1234, Loss: 0.19168943166732788, Final Batch Loss: 0.0902014672756195\n",
      "Epoch 1235, Loss: 0.19456936419010162, Final Batch Loss: 0.09493927657604218\n",
      "Epoch 1236, Loss: 0.20392654091119766, Final Batch Loss: 0.08260119706392288\n",
      "Epoch 1237, Loss: 0.21946129947900772, Final Batch Loss: 0.14161688089370728\n",
      "Epoch 1238, Loss: 0.21199824661016464, Final Batch Loss: 0.1414065808057785\n",
      "Epoch 1239, Loss: 0.16728656738996506, Final Batch Loss: 0.06274791061878204\n",
      "Epoch 1240, Loss: 0.21180762350559235, Final Batch Loss: 0.06791345775127411\n",
      "Epoch 1241, Loss: 0.28672049939632416, Final Batch Loss: 0.15598654747009277\n",
      "Epoch 1242, Loss: 0.20407886058092117, Final Batch Loss: 0.08537571132183075\n",
      "Epoch 1243, Loss: 0.1584451012313366, Final Batch Loss: 0.056246135383844376\n",
      "Epoch 1244, Loss: 0.18719927221536636, Final Batch Loss: 0.08429402858018875\n",
      "Epoch 1245, Loss: 0.20943182706832886, Final Batch Loss: 0.11924460530281067\n",
      "Epoch 1246, Loss: 0.18814387917518616, Final Batch Loss: 0.07761876285076141\n",
      "Epoch 1247, Loss: 0.22963181883096695, Final Batch Loss: 0.12301551550626755\n",
      "Epoch 1248, Loss: 0.2169538289308548, Final Batch Loss: 0.12440185993909836\n",
      "Epoch 1249, Loss: 0.21651718765497208, Final Batch Loss: 0.07456778734922409\n",
      "Epoch 1250, Loss: 0.17332258820533752, Final Batch Loss: 0.07230271399021149\n",
      "Epoch 1251, Loss: 0.217593714594841, Final Batch Loss: 0.1019231379032135\n",
      "Epoch 1252, Loss: 0.1985553875565529, Final Batch Loss: 0.1129644438624382\n",
      "Epoch 1253, Loss: 0.19290637969970703, Final Batch Loss: 0.08128324896097183\n",
      "Epoch 1254, Loss: 0.20076707005500793, Final Batch Loss: 0.08553747832775116\n",
      "Epoch 1255, Loss: 0.2289179340004921, Final Batch Loss: 0.1267707347869873\n",
      "Epoch 1256, Loss: 0.24697283655405045, Final Batch Loss: 0.165484219789505\n",
      "Epoch 1257, Loss: 0.21568921953439713, Final Batch Loss: 0.12174665927886963\n",
      "Epoch 1258, Loss: 0.21448014676570892, Final Batch Loss: 0.10511252284049988\n",
      "Epoch 1259, Loss: 0.18031199276447296, Final Batch Loss: 0.10002502799034119\n",
      "Epoch 1260, Loss: 0.2463199496269226, Final Batch Loss: 0.12817592918872833\n",
      "Epoch 1261, Loss: 0.23680680990219116, Final Batch Loss: 0.14054013788700104\n",
      "Epoch 1262, Loss: 0.1877378225326538, Final Batch Loss: 0.0746280699968338\n",
      "Epoch 1263, Loss: 0.19480066746473312, Final Batch Loss: 0.1057489812374115\n",
      "Epoch 1264, Loss: 0.24264633655548096, Final Batch Loss: 0.17275016009807587\n",
      "Epoch 1265, Loss: 0.20098721235990524, Final Batch Loss: 0.09568112343549728\n",
      "Epoch 1266, Loss: 0.2143651768565178, Final Batch Loss: 0.12243625521659851\n",
      "Epoch 1267, Loss: 0.24889681488275528, Final Batch Loss: 0.1611766219139099\n",
      "Epoch 1268, Loss: 0.20652415603399277, Final Batch Loss: 0.11649749428033829\n",
      "Epoch 1269, Loss: 0.181400828063488, Final Batch Loss: 0.10388751327991486\n",
      "Epoch 1270, Loss: 0.15287739410996437, Final Batch Loss: 0.03195727989077568\n",
      "Epoch 1271, Loss: 0.19471492618322372, Final Batch Loss: 0.09780783951282501\n",
      "Epoch 1272, Loss: 0.19601834565401077, Final Batch Loss: 0.11388802528381348\n",
      "Epoch 1273, Loss: 0.1692046970129013, Final Batch Loss: 0.07462764531373978\n",
      "Epoch 1274, Loss: 0.17354921251535416, Final Batch Loss: 0.06082208454608917\n",
      "Epoch 1275, Loss: 0.22458025068044662, Final Batch Loss: 0.10207811743021011\n",
      "Epoch 1276, Loss: 0.20078414678573608, Final Batch Loss: 0.10154464840888977\n",
      "Epoch 1277, Loss: 0.1710515022277832, Final Batch Loss: 0.06659799069166183\n",
      "Epoch 1278, Loss: 0.18842493742704391, Final Batch Loss: 0.08131713420152664\n",
      "Epoch 1279, Loss: 0.21115798503160477, Final Batch Loss: 0.08923933655023575\n",
      "Epoch 1280, Loss: 0.2282467782497406, Final Batch Loss: 0.11260533332824707\n",
      "Epoch 1281, Loss: 0.23051957041025162, Final Batch Loss: 0.12676234543323517\n",
      "Epoch 1282, Loss: 0.22906477004289627, Final Batch Loss: 0.11244643479585648\n",
      "Epoch 1283, Loss: 0.18199292942881584, Final Batch Loss: 0.05657174810767174\n",
      "Epoch 1284, Loss: 0.1872708424925804, Final Batch Loss: 0.09507977962493896\n",
      "Epoch 1285, Loss: 0.20180638879537582, Final Batch Loss: 0.0876728892326355\n",
      "Epoch 1286, Loss: 0.1897779107093811, Final Batch Loss: 0.07546811550855637\n",
      "Epoch 1287, Loss: 0.17391075193881989, Final Batch Loss: 0.05120278149843216\n",
      "Epoch 1288, Loss: 0.1531040146946907, Final Batch Loss: 0.07593405246734619\n",
      "Epoch 1289, Loss: 0.21750210970640182, Final Batch Loss: 0.06846704334020615\n",
      "Epoch 1290, Loss: 0.194123737514019, Final Batch Loss: 0.09344872832298279\n",
      "Epoch 1291, Loss: 0.19629722088575363, Final Batch Loss: 0.10780724883079529\n",
      "Epoch 1292, Loss: 0.3030354976654053, Final Batch Loss: 0.16663816571235657\n",
      "Epoch 1293, Loss: 0.20320361107587814, Final Batch Loss: 0.0986955314874649\n",
      "Epoch 1294, Loss: 0.20820250362157822, Final Batch Loss: 0.14291276037693024\n",
      "Epoch 1295, Loss: 0.3583332598209381, Final Batch Loss: 0.25637373328208923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1296, Loss: 0.26526082307100296, Final Batch Loss: 0.1917482614517212\n",
      "Epoch 1297, Loss: 0.20862092077732086, Final Batch Loss: 0.1264798790216446\n",
      "Epoch 1298, Loss: 0.2043823078274727, Final Batch Loss: 0.07420103996992111\n",
      "Epoch 1299, Loss: 0.2275286540389061, Final Batch Loss: 0.12309736758470535\n",
      "Epoch 1300, Loss: 0.19738050550222397, Final Batch Loss: 0.09052569419145584\n",
      "Epoch 1301, Loss: 0.1818721815943718, Final Batch Loss: 0.0806385725736618\n",
      "Epoch 1302, Loss: 0.19530555605888367, Final Batch Loss: 0.12131339311599731\n",
      "Epoch 1303, Loss: 0.2640066146850586, Final Batch Loss: 0.1615675836801529\n",
      "Epoch 1304, Loss: 0.23598722368478775, Final Batch Loss: 0.15801598131656647\n",
      "Epoch 1305, Loss: 0.27053647488355637, Final Batch Loss: 0.17981810867786407\n",
      "Epoch 1306, Loss: 0.16667044162750244, Final Batch Loss: 0.07689093053340912\n",
      "Epoch 1307, Loss: 0.21837349236011505, Final Batch Loss: 0.13677562773227692\n",
      "Epoch 1308, Loss: 0.17410649359226227, Final Batch Loss: 0.07565420120954514\n",
      "Epoch 1309, Loss: 0.23302460461854935, Final Batch Loss: 0.14225351810455322\n",
      "Epoch 1310, Loss: 0.18467121571302414, Final Batch Loss: 0.09464391320943832\n",
      "Epoch 1311, Loss: 0.20909161865711212, Final Batch Loss: 0.11582858860492706\n",
      "Epoch 1312, Loss: 0.23707269132137299, Final Batch Loss: 0.11546142399311066\n",
      "Epoch 1313, Loss: 0.22994394600391388, Final Batch Loss: 0.12396416068077087\n",
      "Epoch 1314, Loss: 0.22349755465984344, Final Batch Loss: 0.08592930436134338\n",
      "Epoch 1315, Loss: 0.22143666446208954, Final Batch Loss: 0.13652507960796356\n",
      "Epoch 1316, Loss: 0.1739385426044464, Final Batch Loss: 0.08059947937726974\n",
      "Epoch 1317, Loss: 0.24714282900094986, Final Batch Loss: 0.10771364718675613\n",
      "Epoch 1318, Loss: 0.17292235791683197, Final Batch Loss: 0.07410044968128204\n",
      "Epoch 1319, Loss: 0.1961829960346222, Final Batch Loss: 0.09400807321071625\n",
      "Epoch 1320, Loss: 0.23365084826946259, Final Batch Loss: 0.0986272394657135\n",
      "Epoch 1321, Loss: 0.20993672311306, Final Batch Loss: 0.09679381549358368\n",
      "Epoch 1322, Loss: 0.17604736238718033, Final Batch Loss: 0.0663934275507927\n",
      "Epoch 1323, Loss: 0.20464437454938889, Final Batch Loss: 0.11566267907619476\n",
      "Epoch 1324, Loss: 0.15723977610468864, Final Batch Loss: 0.05066327378153801\n",
      "Epoch 1325, Loss: 0.1717132031917572, Final Batch Loss: 0.058857426047325134\n",
      "Epoch 1326, Loss: 0.21375303715467453, Final Batch Loss: 0.11007732897996902\n",
      "Epoch 1327, Loss: 0.17245400696992874, Final Batch Loss: 0.07923907786607742\n",
      "Epoch 1328, Loss: 0.19953332096338272, Final Batch Loss: 0.09067360311746597\n",
      "Epoch 1329, Loss: 0.21382562071084976, Final Batch Loss: 0.11523917317390442\n",
      "Epoch 1330, Loss: 0.16533977538347244, Final Batch Loss: 0.0829942375421524\n",
      "Epoch 1331, Loss: 0.20203808695077896, Final Batch Loss: 0.102223239839077\n",
      "Epoch 1332, Loss: 0.24290799349546432, Final Batch Loss: 0.12515999376773834\n",
      "Epoch 1333, Loss: 0.2091861069202423, Final Batch Loss: 0.07526017725467682\n",
      "Epoch 1334, Loss: 0.21331912279129028, Final Batch Loss: 0.11015456169843674\n",
      "Epoch 1335, Loss: 0.2132319137454033, Final Batch Loss: 0.139151930809021\n",
      "Epoch 1336, Loss: 0.1789848729968071, Final Batch Loss: 0.0672542080283165\n",
      "Epoch 1337, Loss: 0.1819480136036873, Final Batch Loss: 0.08366332203149796\n",
      "Epoch 1338, Loss: 0.2227584794163704, Final Batch Loss: 0.12621630728244781\n",
      "Epoch 1339, Loss: 0.22728430479764938, Final Batch Loss: 0.12351018190383911\n",
      "Epoch 1340, Loss: 0.20058058202266693, Final Batch Loss: 0.12035413086414337\n",
      "Epoch 1341, Loss: 0.195387601852417, Final Batch Loss: 0.09186778962612152\n",
      "Epoch 1342, Loss: 0.27932896465063095, Final Batch Loss: 0.18429850041866302\n",
      "Epoch 1343, Loss: 0.17567609995603561, Final Batch Loss: 0.08986972272396088\n",
      "Epoch 1344, Loss: 0.2208988219499588, Final Batch Loss: 0.06760649383068085\n",
      "Epoch 1345, Loss: 0.21139489114284515, Final Batch Loss: 0.10313641279935837\n",
      "Epoch 1346, Loss: 0.22607742249965668, Final Batch Loss: 0.1635454297065735\n",
      "Epoch 1347, Loss: 0.2075280174612999, Final Batch Loss: 0.09923314303159714\n",
      "Epoch 1348, Loss: 0.18002746999263763, Final Batch Loss: 0.09348367154598236\n",
      "Epoch 1349, Loss: 0.1995415985584259, Final Batch Loss: 0.11546746641397476\n",
      "Epoch 1350, Loss: 0.19521523267030716, Final Batch Loss: 0.10851014405488968\n",
      "Epoch 1351, Loss: 0.22210361063480377, Final Batch Loss: 0.14624524116516113\n",
      "Epoch 1352, Loss: 0.19293799251317978, Final Batch Loss: 0.08028411865234375\n",
      "Epoch 1353, Loss: 0.16298668086528778, Final Batch Loss: 0.06260611116886139\n",
      "Epoch 1354, Loss: 0.1931617259979248, Final Batch Loss: 0.10653553158044815\n",
      "Epoch 1355, Loss: 0.16755665838718414, Final Batch Loss: 0.09290984272956848\n",
      "Epoch 1356, Loss: 0.22940794378519058, Final Batch Loss: 0.13939331471920013\n",
      "Epoch 1357, Loss: 0.19387230277061462, Final Batch Loss: 0.06933050602674484\n",
      "Epoch 1358, Loss: 0.185468427836895, Final Batch Loss: 0.09006904065608978\n",
      "Epoch 1359, Loss: 0.1592542827129364, Final Batch Loss: 0.06123396009206772\n",
      "Epoch 1360, Loss: 0.25513432919979095, Final Batch Loss: 0.14692801237106323\n",
      "Epoch 1361, Loss: 0.17207204550504684, Final Batch Loss: 0.08418729156255722\n",
      "Epoch 1362, Loss: 0.17973247170448303, Final Batch Loss: 0.10223200917243958\n",
      "Epoch 1363, Loss: 0.1940932422876358, Final Batch Loss: 0.10568978637456894\n",
      "Epoch 1364, Loss: 0.17357775568962097, Final Batch Loss: 0.06814317405223846\n",
      "Epoch 1365, Loss: 0.17740508168935776, Final Batch Loss: 0.09170818328857422\n",
      "Epoch 1366, Loss: 0.18017000705003738, Final Batch Loss: 0.07368756085634232\n",
      "Epoch 1367, Loss: 0.29146958887577057, Final Batch Loss: 0.1366303712129593\n",
      "Epoch 1368, Loss: 0.17536934465169907, Final Batch Loss: 0.05108150839805603\n",
      "Epoch 1369, Loss: 0.19423121958971024, Final Batch Loss: 0.0860518142580986\n",
      "Epoch 1370, Loss: 0.18968071043491364, Final Batch Loss: 0.0765765905380249\n",
      "Epoch 1371, Loss: 0.21086392551660538, Final Batch Loss: 0.11793678253889084\n",
      "Epoch 1372, Loss: 0.16089395433664322, Final Batch Loss: 0.07755111902952194\n",
      "Epoch 1373, Loss: 0.20927750319242477, Final Batch Loss: 0.10563880205154419\n",
      "Epoch 1374, Loss: 0.18791548907756805, Final Batch Loss: 0.08929497003555298\n",
      "Epoch 1375, Loss: 0.15537796542048454, Final Batch Loss: 0.04812345281243324\n",
      "Epoch 1376, Loss: 0.15880845487117767, Final Batch Loss: 0.07942435145378113\n",
      "Epoch 1377, Loss: 0.20933474600315094, Final Batch Loss: 0.10363180935382843\n",
      "Epoch 1378, Loss: 0.19283504784107208, Final Batch Loss: 0.10241886228322983\n",
      "Epoch 1379, Loss: 0.17775661498308182, Final Batch Loss: 0.10628219693899155\n",
      "Epoch 1380, Loss: 0.1599721908569336, Final Batch Loss: 0.08645468950271606\n",
      "Epoch 1381, Loss: 0.1956210508942604, Final Batch Loss: 0.12224070727825165\n",
      "Epoch 1382, Loss: 0.2396395355463028, Final Batch Loss: 0.13635584712028503\n",
      "Epoch 1383, Loss: 0.21807965636253357, Final Batch Loss: 0.11109618842601776\n",
      "Epoch 1384, Loss: 0.2536609619855881, Final Batch Loss: 0.17355866730213165\n",
      "Epoch 1385, Loss: 0.1599501594901085, Final Batch Loss: 0.061453357338905334\n",
      "Epoch 1386, Loss: 0.165301613509655, Final Batch Loss: 0.07520544528961182\n",
      "Epoch 1387, Loss: 0.16443413123488426, Final Batch Loss: 0.04748290404677391\n",
      "Epoch 1388, Loss: 0.15116456896066666, Final Batch Loss: 0.04547366499900818\n",
      "Epoch 1389, Loss: 0.1953422874212265, Final Batch Loss: 0.1166774109005928\n",
      "Epoch 1390, Loss: 0.17056138813495636, Final Batch Loss: 0.07457800954580307\n",
      "Epoch 1391, Loss: 0.2231994867324829, Final Batch Loss: 0.11476103216409683\n",
      "Epoch 1392, Loss: 0.20063970237970352, Final Batch Loss: 0.09678513556718826\n",
      "Epoch 1393, Loss: 0.19046567380428314, Final Batch Loss: 0.06906889379024506\n",
      "Epoch 1394, Loss: 0.19645528495311737, Final Batch Loss: 0.10360997170209885\n",
      "Epoch 1395, Loss: 0.22110379487276077, Final Batch Loss: 0.13103559613227844\n",
      "Epoch 1396, Loss: 0.2215152382850647, Final Batch Loss: 0.12041604518890381\n",
      "Epoch 1397, Loss: 0.18664011731743813, Final Batch Loss: 0.05437963083386421\n",
      "Epoch 1398, Loss: 0.17320245504379272, Final Batch Loss: 0.07676178216934204\n",
      "Epoch 1399, Loss: 0.21779815107584, Final Batch Loss: 0.1278613954782486\n",
      "Epoch 1400, Loss: 0.18116257339715958, Final Batch Loss: 0.09610316902399063\n",
      "Epoch 1401, Loss: 0.20529206842184067, Final Batch Loss: 0.11009281128644943\n",
      "Epoch 1402, Loss: 0.1586323194205761, Final Batch Loss: 0.054286692291498184\n",
      "Epoch 1403, Loss: 0.21307508274912834, Final Batch Loss: 0.1511385291814804\n",
      "Epoch 1404, Loss: 0.22417029738426208, Final Batch Loss: 0.11958259344100952\n",
      "Epoch 1405, Loss: 0.187712199985981, Final Batch Loss: 0.076675646007061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1406, Loss: 0.18998237699270248, Final Batch Loss: 0.09912510216236115\n",
      "Epoch 1407, Loss: 0.2503764480352402, Final Batch Loss: 0.14442148804664612\n",
      "Epoch 1408, Loss: 0.23693370074033737, Final Batch Loss: 0.16048161685466766\n",
      "Epoch 1409, Loss: 0.18973750621080399, Final Batch Loss: 0.07667314261198044\n",
      "Epoch 1410, Loss: 0.16729839891195297, Final Batch Loss: 0.070100799202919\n",
      "Epoch 1411, Loss: 0.187569297850132, Final Batch Loss: 0.10348818451166153\n",
      "Epoch 1412, Loss: 0.1960938274860382, Final Batch Loss: 0.1252361238002777\n",
      "Epoch 1413, Loss: 0.23072549700737, Final Batch Loss: 0.0736483782529831\n",
      "Epoch 1414, Loss: 0.2202504649758339, Final Batch Loss: 0.11540122330188751\n",
      "Epoch 1415, Loss: 0.16586272418498993, Final Batch Loss: 0.08248044550418854\n",
      "Epoch 1416, Loss: 0.15856725722551346, Final Batch Loss: 0.06100250035524368\n",
      "Epoch 1417, Loss: 0.19863251596689224, Final Batch Loss: 0.07455194741487503\n",
      "Epoch 1418, Loss: 0.19366564601659775, Final Batch Loss: 0.08870215713977814\n",
      "Epoch 1419, Loss: 0.1606847196817398, Final Batch Loss: 0.07499372214078903\n",
      "Epoch 1420, Loss: 0.21928999572992325, Final Batch Loss: 0.11695389449596405\n",
      "Epoch 1421, Loss: 0.2236529141664505, Final Batch Loss: 0.07713133096694946\n",
      "Epoch 1422, Loss: 0.1711609736084938, Final Batch Loss: 0.08006253093481064\n",
      "Epoch 1423, Loss: 0.21505532413721085, Final Batch Loss: 0.11900529265403748\n",
      "Epoch 1424, Loss: 0.1660902202129364, Final Batch Loss: 0.08375349640846252\n",
      "Epoch 1425, Loss: 0.18734492361545563, Final Batch Loss: 0.08067382872104645\n",
      "Epoch 1426, Loss: 0.19090168178081512, Final Batch Loss: 0.08660110086202621\n",
      "Epoch 1427, Loss: 0.18761062622070312, Final Batch Loss: 0.1056939959526062\n",
      "Epoch 1428, Loss: 0.19142386317253113, Final Batch Loss: 0.09484989941120148\n",
      "Epoch 1429, Loss: 0.19179246574640274, Final Batch Loss: 0.0872020572423935\n",
      "Epoch 1430, Loss: 0.17264524847269058, Final Batch Loss: 0.08211103826761246\n",
      "Epoch 1431, Loss: 0.23342977464199066, Final Batch Loss: 0.1347266435623169\n",
      "Epoch 1432, Loss: 0.1654176190495491, Final Batch Loss: 0.06980951130390167\n",
      "Epoch 1433, Loss: 0.20078232139348984, Final Batch Loss: 0.12266992032527924\n",
      "Epoch 1434, Loss: 0.19329190254211426, Final Batch Loss: 0.0896398276090622\n",
      "Epoch 1435, Loss: 0.207032211124897, Final Batch Loss: 0.13475213944911957\n",
      "Epoch 1436, Loss: 0.24163473397493362, Final Batch Loss: 0.15012969076633453\n",
      "Epoch 1437, Loss: 0.20234102755784988, Final Batch Loss: 0.09584686905145645\n",
      "Epoch 1438, Loss: 0.21664239466190338, Final Batch Loss: 0.11233536154031754\n",
      "Epoch 1439, Loss: 0.18953046575188637, Final Batch Loss: 0.059891197830438614\n",
      "Epoch 1440, Loss: 0.31787730008363724, Final Batch Loss: 0.19802069664001465\n",
      "Epoch 1441, Loss: 0.19909006357192993, Final Batch Loss: 0.10022038221359253\n",
      "Epoch 1442, Loss: 0.1546575464308262, Final Batch Loss: 0.05422437563538551\n",
      "Epoch 1443, Loss: 0.16038209199905396, Final Batch Loss: 0.07500844448804855\n",
      "Epoch 1444, Loss: 0.170799158513546, Final Batch Loss: 0.07967862486839294\n",
      "Epoch 1445, Loss: 0.19549092650413513, Final Batch Loss: 0.09711060672998428\n",
      "Epoch 1446, Loss: 0.21343642473220825, Final Batch Loss: 0.09232871979475021\n",
      "Epoch 1447, Loss: 0.235739104449749, Final Batch Loss: 0.14311425387859344\n",
      "Epoch 1448, Loss: 0.2072955146431923, Final Batch Loss: 0.1169784888625145\n",
      "Epoch 1449, Loss: 0.16613486409187317, Final Batch Loss: 0.07301094383001328\n",
      "Epoch 1450, Loss: 0.20690491795539856, Final Batch Loss: 0.12439887225627899\n",
      "Epoch 1451, Loss: 0.1984313279390335, Final Batch Loss: 0.08742627501487732\n",
      "Epoch 1452, Loss: 0.2201489731669426, Final Batch Loss: 0.12487107515335083\n",
      "Epoch 1453, Loss: 0.18486852198839188, Final Batch Loss: 0.08073177188634872\n",
      "Epoch 1454, Loss: 0.19362915307283401, Final Batch Loss: 0.09252098947763443\n",
      "Epoch 1455, Loss: 0.1835305318236351, Final Batch Loss: 0.06827320903539658\n",
      "Epoch 1456, Loss: 0.21982184797525406, Final Batch Loss: 0.12854914367198944\n",
      "Epoch 1457, Loss: 0.1433066576719284, Final Batch Loss: 0.0468609556555748\n",
      "Epoch 1458, Loss: 0.18105752766132355, Final Batch Loss: 0.08359049260616302\n",
      "Epoch 1459, Loss: 0.1981566697359085, Final Batch Loss: 0.09119198471307755\n",
      "Epoch 1460, Loss: 0.2271418273448944, Final Batch Loss: 0.15119190514087677\n",
      "Epoch 1461, Loss: 0.16358157992362976, Final Batch Loss: 0.09012382477521896\n",
      "Epoch 1462, Loss: 0.20965508371591568, Final Batch Loss: 0.11458102613687515\n",
      "Epoch 1463, Loss: 0.17750754207372665, Final Batch Loss: 0.06723351031541824\n",
      "Epoch 1464, Loss: 0.21026866137981415, Final Batch Loss: 0.1120670810341835\n",
      "Epoch 1465, Loss: 0.20520130917429924, Final Batch Loss: 0.15333010256290436\n",
      "Epoch 1466, Loss: 0.19042637199163437, Final Batch Loss: 0.11158668994903564\n",
      "Epoch 1467, Loss: 0.20796440541744232, Final Batch Loss: 0.08715049177408218\n",
      "Epoch 1468, Loss: 0.1928565725684166, Final Batch Loss: 0.10479356348514557\n",
      "Epoch 1469, Loss: 0.18562724441289902, Final Batch Loss: 0.10014048963785172\n",
      "Epoch 1470, Loss: 0.180529423058033, Final Batch Loss: 0.06785452365875244\n",
      "Epoch 1471, Loss: 0.15095113962888718, Final Batch Loss: 0.07369712740182877\n",
      "Epoch 1472, Loss: 0.1551273725926876, Final Batch Loss: 0.049397435039281845\n",
      "Epoch 1473, Loss: 0.2964545488357544, Final Batch Loss: 0.08339852094650269\n",
      "Epoch 1474, Loss: 0.16448872536420822, Final Batch Loss: 0.08487247675657272\n",
      "Epoch 1475, Loss: 0.19816020876169205, Final Batch Loss: 0.10619287937879562\n",
      "Epoch 1476, Loss: 0.2423706203699112, Final Batch Loss: 0.15208104252815247\n",
      "Epoch 1477, Loss: 0.15155649185180664, Final Batch Loss: 0.0644397884607315\n",
      "Epoch 1478, Loss: 0.16029374301433563, Final Batch Loss: 0.06570229679346085\n",
      "Epoch 1479, Loss: 0.17123033106327057, Final Batch Loss: 0.06982444226741791\n",
      "Epoch 1480, Loss: 0.15046291425824165, Final Batch Loss: 0.05544418469071388\n",
      "Epoch 1481, Loss: 0.2803323343396187, Final Batch Loss: 0.18642960488796234\n",
      "Epoch 1482, Loss: 0.17975832521915436, Final Batch Loss: 0.07197662442922592\n",
      "Epoch 1483, Loss: 0.21522188186645508, Final Batch Loss: 0.12384890764951706\n",
      "Epoch 1484, Loss: 0.15696635097265244, Final Batch Loss: 0.07326750457286835\n",
      "Epoch 1485, Loss: 0.21310725808143616, Final Batch Loss: 0.09534049779176712\n",
      "Epoch 1486, Loss: 0.20724866539239883, Final Batch Loss: 0.09636837989091873\n",
      "Epoch 1487, Loss: 0.2022966369986534, Final Batch Loss: 0.11274361610412598\n",
      "Epoch 1488, Loss: 0.1667073369026184, Final Batch Loss: 0.07458239048719406\n",
      "Epoch 1489, Loss: 0.20175377279520035, Final Batch Loss: 0.0826122909784317\n",
      "Epoch 1490, Loss: 0.22150330990552902, Final Batch Loss: 0.08226596564054489\n",
      "Epoch 1491, Loss: 0.1993994116783142, Final Batch Loss: 0.11311284452676773\n",
      "Epoch 1492, Loss: 0.17600765451788902, Final Batch Loss: 0.06128547713160515\n",
      "Epoch 1493, Loss: 0.2057497650384903, Final Batch Loss: 0.11035949736833572\n",
      "Epoch 1494, Loss: 0.18842828273773193, Final Batch Loss: 0.08967860043048859\n",
      "Epoch 1495, Loss: 0.1970594897866249, Final Batch Loss: 0.09353326261043549\n",
      "Epoch 1496, Loss: 0.18340996280312538, Final Batch Loss: 0.0497271902859211\n",
      "Epoch 1497, Loss: 0.18547707796096802, Final Batch Loss: 0.07771620899438858\n",
      "Epoch 1498, Loss: 0.15904119610786438, Final Batch Loss: 0.05999545753002167\n",
      "Epoch 1499, Loss: 0.2379569113254547, Final Batch Loss: 0.15696099400520325\n",
      "Epoch 1500, Loss: 0.15797009319067, Final Batch Loss: 0.05695222318172455\n",
      "Epoch 1501, Loss: 0.23598726093769073, Final Batch Loss: 0.13681736588478088\n",
      "Epoch 1502, Loss: 0.17739958316087723, Final Batch Loss: 0.07752272486686707\n",
      "Epoch 1503, Loss: 0.19852299243211746, Final Batch Loss: 0.11298878490924835\n",
      "Epoch 1504, Loss: 0.27689947932958603, Final Batch Loss: 0.1747491955757141\n",
      "Epoch 1505, Loss: 0.25954727828502655, Final Batch Loss: 0.1878771036863327\n",
      "Epoch 1506, Loss: 0.3011022210121155, Final Batch Loss: 0.18675127625465393\n",
      "Epoch 1507, Loss: 0.2521718665957451, Final Batch Loss: 0.11286675184965134\n",
      "Epoch 1508, Loss: 0.20379211008548737, Final Batch Loss: 0.11465366929769516\n",
      "Epoch 1509, Loss: 0.19552451372146606, Final Batch Loss: 0.09278933703899384\n",
      "Epoch 1510, Loss: 0.22413406521081924, Final Batch Loss: 0.09861461073160172\n",
      "Epoch 1511, Loss: 0.26871809363365173, Final Batch Loss: 0.13516879081726074\n",
      "Epoch 1512, Loss: 0.2376938760280609, Final Batch Loss: 0.15135064721107483\n",
      "Epoch 1513, Loss: 0.2006697803735733, Final Batch Loss: 0.11005280166864395\n",
      "Epoch 1514, Loss: 0.20818724483251572, Final Batch Loss: 0.08285755664110184\n",
      "Epoch 1515, Loss: 0.2210739105939865, Final Batch Loss: 0.10005141794681549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1516, Loss: 0.16015919297933578, Final Batch Loss: 0.04202188551425934\n",
      "Epoch 1517, Loss: 0.16815779358148575, Final Batch Loss: 0.08572474867105484\n",
      "Epoch 1518, Loss: 0.22489184141159058, Final Batch Loss: 0.12809300422668457\n",
      "Epoch 1519, Loss: 0.16255580633878708, Final Batch Loss: 0.0733756497502327\n",
      "Epoch 1520, Loss: 0.15967100113630295, Final Batch Loss: 0.07396313548088074\n",
      "Epoch 1521, Loss: 0.14375461637973785, Final Batch Loss: 0.04904118925333023\n",
      "Epoch 1522, Loss: 0.18163394182920456, Final Batch Loss: 0.08241589367389679\n",
      "Epoch 1523, Loss: 0.18239159137010574, Final Batch Loss: 0.08861779421567917\n",
      "Epoch 1524, Loss: 0.16865749284625053, Final Batch Loss: 0.04852476343512535\n",
      "Epoch 1525, Loss: 0.21779820322990417, Final Batch Loss: 0.12881805002689362\n",
      "Epoch 1526, Loss: 0.17252064496278763, Final Batch Loss: 0.08538620173931122\n",
      "Epoch 1527, Loss: 0.17749063670635223, Final Batch Loss: 0.0978066623210907\n",
      "Epoch 1528, Loss: 0.1862952560186386, Final Batch Loss: 0.08949735015630722\n",
      "Epoch 1529, Loss: 0.18741653859615326, Final Batch Loss: 0.11217434704303741\n",
      "Epoch 1530, Loss: 0.17815475910902023, Final Batch Loss: 0.0935034230351448\n",
      "Epoch 1531, Loss: 0.19473358243703842, Final Batch Loss: 0.07983112335205078\n",
      "Epoch 1532, Loss: 0.154893908649683, Final Batch Loss: 0.05194847658276558\n",
      "Epoch 1533, Loss: 0.19815394282341003, Final Batch Loss: 0.08593373000621796\n",
      "Epoch 1534, Loss: 0.1757635772228241, Final Batch Loss: 0.10111090540885925\n",
      "Epoch 1535, Loss: 0.1727888211607933, Final Batch Loss: 0.09633377194404602\n",
      "Epoch 1536, Loss: 0.21117541193962097, Final Batch Loss: 0.12403613328933716\n",
      "Epoch 1537, Loss: 0.23406169563531876, Final Batch Loss: 0.14407549798488617\n",
      "Epoch 1538, Loss: 0.1745322197675705, Final Batch Loss: 0.08120425045490265\n",
      "Epoch 1539, Loss: 0.196834035217762, Final Batch Loss: 0.0852154940366745\n",
      "Epoch 1540, Loss: 0.1839095875620842, Final Batch Loss: 0.08924710750579834\n",
      "Epoch 1541, Loss: 0.219369038939476, Final Batch Loss: 0.11074785888195038\n",
      "Epoch 1542, Loss: 0.18240270018577576, Final Batch Loss: 0.08601279556751251\n",
      "Epoch 1543, Loss: 0.16188502311706543, Final Batch Loss: 0.05853843688964844\n",
      "Epoch 1544, Loss: 0.14358361437916756, Final Batch Loss: 0.04725639149546623\n",
      "Epoch 1545, Loss: 0.20385238528251648, Final Batch Loss: 0.11988331377506256\n",
      "Epoch 1546, Loss: 0.16864486783742905, Final Batch Loss: 0.06627340614795685\n",
      "Epoch 1547, Loss: 0.1486932411789894, Final Batch Loss: 0.07102935016155243\n",
      "Epoch 1548, Loss: 0.19308039546012878, Final Batch Loss: 0.09208697080612183\n",
      "Epoch 1549, Loss: 0.1846877858042717, Final Batch Loss: 0.08835600316524506\n",
      "Epoch 1550, Loss: 0.1867566555738449, Final Batch Loss: 0.11378888040781021\n",
      "Epoch 1551, Loss: 0.16275805979967117, Final Batch Loss: 0.08223216980695724\n",
      "Epoch 1552, Loss: 0.20998450368642807, Final Batch Loss: 0.11848150938749313\n",
      "Epoch 1553, Loss: 0.16854581236839294, Final Batch Loss: 0.08600065857172012\n",
      "Epoch 1554, Loss: 0.14502600952982903, Final Batch Loss: 0.05340929701924324\n",
      "Epoch 1555, Loss: 0.21667031943798065, Final Batch Loss: 0.1287744641304016\n",
      "Epoch 1556, Loss: 0.20200880616903305, Final Batch Loss: 0.1050921380519867\n",
      "Epoch 1557, Loss: 0.1679903343319893, Final Batch Loss: 0.07273545861244202\n",
      "Epoch 1558, Loss: 0.18779122829437256, Final Batch Loss: 0.0855119451880455\n",
      "Epoch 1559, Loss: 0.17314443737268448, Final Batch Loss: 0.07752532511949539\n",
      "Epoch 1560, Loss: 0.18759293854236603, Final Batch Loss: 0.11662504822015762\n",
      "Epoch 1561, Loss: 0.18390873819589615, Final Batch Loss: 0.0992165133357048\n",
      "Epoch 1562, Loss: 0.18979905545711517, Final Batch Loss: 0.09693977981805801\n",
      "Epoch 1563, Loss: 0.1626472920179367, Final Batch Loss: 0.06646941602230072\n",
      "Epoch 1564, Loss: 0.21274977922439575, Final Batch Loss: 0.10957776010036469\n",
      "Epoch 1565, Loss: 0.23272335529327393, Final Batch Loss: 0.09197880327701569\n",
      "Epoch 1566, Loss: 0.16824611276388168, Final Batch Loss: 0.0858088955283165\n",
      "Epoch 1567, Loss: 0.21643595397472382, Final Batch Loss: 0.1328444480895996\n",
      "Epoch 1568, Loss: 0.17802312970161438, Final Batch Loss: 0.07593531906604767\n",
      "Epoch 1569, Loss: 0.1719917505979538, Final Batch Loss: 0.07297035306692123\n",
      "Epoch 1570, Loss: 0.18861228972673416, Final Batch Loss: 0.09270679205656052\n",
      "Epoch 1571, Loss: 0.18232890963554382, Final Batch Loss: 0.08856264501810074\n",
      "Epoch 1572, Loss: 0.16902323812246323, Final Batch Loss: 0.08196152001619339\n",
      "Epoch 1573, Loss: 0.24185099452733994, Final Batch Loss: 0.1686367243528366\n",
      "Epoch 1574, Loss: 0.19238066673278809, Final Batch Loss: 0.10749396681785583\n",
      "Epoch 1575, Loss: 0.18023549765348434, Final Batch Loss: 0.0985662117600441\n",
      "Epoch 1576, Loss: 0.17914139479398727, Final Batch Loss: 0.08594546467065811\n",
      "Epoch 1577, Loss: 0.2139991819858551, Final Batch Loss: 0.1311747431755066\n",
      "Epoch 1578, Loss: 0.1497981995344162, Final Batch Loss: 0.0624847486615181\n",
      "Epoch 1579, Loss: 0.16538438946008682, Final Batch Loss: 0.0869542732834816\n",
      "Epoch 1580, Loss: 0.17522645369172096, Final Batch Loss: 0.11440766602754593\n",
      "Epoch 1581, Loss: 0.2093367949128151, Final Batch Loss: 0.12078587710857391\n",
      "Epoch 1582, Loss: 0.18846717476844788, Final Batch Loss: 0.10820746421813965\n",
      "Epoch 1583, Loss: 0.14206647500395775, Final Batch Loss: 0.04377100244164467\n",
      "Epoch 1584, Loss: 0.18492817878723145, Final Batch Loss: 0.10909980535507202\n",
      "Epoch 1585, Loss: 0.17446670681238174, Final Batch Loss: 0.06920784711837769\n",
      "Epoch 1586, Loss: 0.18512927740812302, Final Batch Loss: 0.10634017735719681\n",
      "Epoch 1587, Loss: 0.17309340834617615, Final Batch Loss: 0.09757264703512192\n",
      "Epoch 1588, Loss: 0.1645825132727623, Final Batch Loss: 0.08450012654066086\n",
      "Epoch 1589, Loss: 0.21658535301685333, Final Batch Loss: 0.1376190036535263\n",
      "Epoch 1590, Loss: 0.1818448007106781, Final Batch Loss: 0.10273829102516174\n",
      "Epoch 1591, Loss: 0.17404008656740189, Final Batch Loss: 0.10101815313100815\n",
      "Epoch 1592, Loss: 0.21881622076034546, Final Batch Loss: 0.1258813887834549\n",
      "Epoch 1593, Loss: 0.23120692372322083, Final Batch Loss: 0.1588466614484787\n",
      "Epoch 1594, Loss: 0.16772325336933136, Final Batch Loss: 0.08047764003276825\n",
      "Epoch 1595, Loss: 0.1827206313610077, Final Batch Loss: 0.08997425436973572\n",
      "Epoch 1596, Loss: 0.16897115856409073, Final Batch Loss: 0.0825929194688797\n",
      "Epoch 1597, Loss: 0.21318548172712326, Final Batch Loss: 0.11392129212617874\n",
      "Epoch 1598, Loss: 0.17818907648324966, Final Batch Loss: 0.12078220397233963\n",
      "Epoch 1599, Loss: 0.16993744298815727, Final Batch Loss: 0.0591411255300045\n",
      "Epoch 1600, Loss: 0.23870161920785904, Final Batch Loss: 0.10549987107515335\n",
      "Epoch 1601, Loss: 0.1978113353252411, Final Batch Loss: 0.09994179010391235\n",
      "Epoch 1602, Loss: 0.16347651183605194, Final Batch Loss: 0.06616965681314468\n",
      "Epoch 1603, Loss: 0.23172516375780106, Final Batch Loss: 0.15315553545951843\n",
      "Epoch 1604, Loss: 0.14063678681850433, Final Batch Loss: 0.05429904907941818\n",
      "Epoch 1605, Loss: 0.15113896876573563, Final Batch Loss: 0.05332178622484207\n",
      "Epoch 1606, Loss: 0.15501950681209564, Final Batch Loss: 0.06254584342241287\n",
      "Epoch 1607, Loss: 0.14603270590305328, Final Batch Loss: 0.07476538419723511\n",
      "Epoch 1608, Loss: 0.17093107849359512, Final Batch Loss: 0.07795868813991547\n",
      "Epoch 1609, Loss: 0.2072337493300438, Final Batch Loss: 0.11394234001636505\n",
      "Epoch 1610, Loss: 0.14808641001582146, Final Batch Loss: 0.03901660814881325\n",
      "Epoch 1611, Loss: 0.13556241244077682, Final Batch Loss: 0.05214589834213257\n",
      "Epoch 1612, Loss: 0.16213668882846832, Final Batch Loss: 0.07477571815252304\n",
      "Epoch 1613, Loss: 0.17078383266925812, Final Batch Loss: 0.07411099970340729\n",
      "Epoch 1614, Loss: 0.156331405043602, Final Batch Loss: 0.07286812365055084\n",
      "Epoch 1615, Loss: 0.14776218682527542, Final Batch Loss: 0.051611512899398804\n",
      "Epoch 1616, Loss: 0.17963171750307083, Final Batch Loss: 0.07886423915624619\n",
      "Epoch 1617, Loss: 0.20474392175674438, Final Batch Loss: 0.09793242812156677\n",
      "Epoch 1618, Loss: 0.17270730435848236, Final Batch Loss: 0.09694232046604156\n",
      "Epoch 1619, Loss: 0.14849333092570305, Final Batch Loss: 0.04645679518580437\n",
      "Epoch 1620, Loss: 0.21135985851287842, Final Batch Loss: 0.1196073591709137\n",
      "Epoch 1621, Loss: 0.17746908962726593, Final Batch Loss: 0.06660091876983643\n",
      "Epoch 1622, Loss: 0.1845710352063179, Final Batch Loss: 0.08483231067657471\n",
      "Epoch 1623, Loss: 0.14319943264126778, Final Batch Loss: 0.03616677597165108\n",
      "Epoch 1624, Loss: 0.1738199070096016, Final Batch Loss: 0.09409485012292862\n",
      "Epoch 1625, Loss: 0.1396223045885563, Final Batch Loss: 0.05951154604554176\n",
      "Epoch 1626, Loss: 0.137399323284626, Final Batch Loss: 0.05515402555465698\n",
      "Epoch 1627, Loss: 0.17397474497556686, Final Batch Loss: 0.08418048173189163\n",
      "Epoch 1628, Loss: 0.17096015065908432, Final Batch Loss: 0.10092853754758835\n",
      "Epoch 1629, Loss: 0.18352660536766052, Final Batch Loss: 0.09355391561985016\n",
      "Epoch 1630, Loss: 0.14758412539958954, Final Batch Loss: 0.07400219142436981\n",
      "Epoch 1631, Loss: 0.20483940839767456, Final Batch Loss: 0.1180286854505539\n",
      "Epoch 1632, Loss: 0.167283795773983, Final Batch Loss: 0.09002556651830673\n",
      "Epoch 1633, Loss: 0.16383032500743866, Final Batch Loss: 0.08750390261411667\n",
      "Epoch 1634, Loss: 0.22199128568172455, Final Batch Loss: 0.1296328604221344\n",
      "Epoch 1635, Loss: 0.27577678859233856, Final Batch Loss: 0.21610987186431885\n",
      "Epoch 1636, Loss: 0.19731681048870087, Final Batch Loss: 0.1139555498957634\n",
      "Epoch 1637, Loss: 0.14513976871967316, Final Batch Loss: 0.05335813760757446\n",
      "Epoch 1638, Loss: 0.1662931591272354, Final Batch Loss: 0.04757598787546158\n",
      "Epoch 1639, Loss: 0.14770785719156265, Final Batch Loss: 0.05562078207731247\n",
      "Epoch 1640, Loss: 0.1834445372223854, Final Batch Loss: 0.10099426656961441\n",
      "Epoch 1641, Loss: 0.15455103665590286, Final Batch Loss: 0.0625845417380333\n",
      "Epoch 1642, Loss: 0.15056360512971878, Final Batch Loss: 0.05285823345184326\n",
      "Epoch 1643, Loss: 0.17463411763310432, Final Batch Loss: 0.05712393298745155\n",
      "Epoch 1644, Loss: 0.22505905479192734, Final Batch Loss: 0.14890553057193756\n",
      "Epoch 1645, Loss: 0.19418535381555557, Final Batch Loss: 0.09124768525362015\n",
      "Epoch 1646, Loss: 0.14804289862513542, Final Batch Loss: 0.0427858866751194\n",
      "Epoch 1647, Loss: 0.14866845682263374, Final Batch Loss: 0.04908909276127815\n",
      "Epoch 1648, Loss: 0.1901937499642372, Final Batch Loss: 0.11703621596097946\n",
      "Epoch 1649, Loss: 0.20481765270233154, Final Batch Loss: 0.09038683772087097\n",
      "Epoch 1650, Loss: 0.152377437800169, Final Batch Loss: 0.06249561533331871\n",
      "Epoch 1651, Loss: 0.18706096708774567, Final Batch Loss: 0.07949801534414291\n",
      "Epoch 1652, Loss: 0.22804002463817596, Final Batch Loss: 0.15764310956001282\n",
      "Epoch 1653, Loss: 0.23377994447946548, Final Batch Loss: 0.09532817453145981\n",
      "Epoch 1654, Loss: 0.17977111786603928, Final Batch Loss: 0.06626787036657333\n",
      "Epoch 1655, Loss: 0.18621961027383804, Final Batch Loss: 0.0929655060172081\n",
      "Epoch 1656, Loss: 0.1824122965335846, Final Batch Loss: 0.07876946032047272\n",
      "Epoch 1657, Loss: 0.1623133271932602, Final Batch Loss: 0.08191440999507904\n",
      "Epoch 1658, Loss: 0.19560469686985016, Final Batch Loss: 0.10918430238962173\n",
      "Epoch 1659, Loss: 0.1537201777100563, Final Batch Loss: 0.050193533301353455\n",
      "Epoch 1660, Loss: 0.17727863043546677, Final Batch Loss: 0.08255179226398468\n",
      "Epoch 1661, Loss: 0.17704759538173676, Final Batch Loss: 0.10242599993944168\n",
      "Epoch 1662, Loss: 0.20381249487400055, Final Batch Loss: 0.07439063489437103\n",
      "Epoch 1663, Loss: 0.16019463539123535, Final Batch Loss: 0.06998985260725021\n",
      "Epoch 1664, Loss: 0.17299149930477142, Final Batch Loss: 0.09959790110588074\n",
      "Epoch 1665, Loss: 0.21126867830753326, Final Batch Loss: 0.08031764626502991\n",
      "Epoch 1666, Loss: 0.15751079842448235, Final Batch Loss: 0.05821323022246361\n",
      "Epoch 1667, Loss: 0.23195842653512955, Final Batch Loss: 0.15394650399684906\n",
      "Epoch 1668, Loss: 0.18667737394571304, Final Batch Loss: 0.07211913913488388\n",
      "Epoch 1669, Loss: 0.21650207042694092, Final Batch Loss: 0.12979108095169067\n",
      "Epoch 1670, Loss: 0.15726720914244652, Final Batch Loss: 0.05630018189549446\n",
      "Epoch 1671, Loss: 0.20671001076698303, Final Batch Loss: 0.08744145184755325\n",
      "Epoch 1672, Loss: 0.22368958592414856, Final Batch Loss: 0.10468960553407669\n",
      "Epoch 1673, Loss: 0.15269315242767334, Final Batch Loss: 0.07399868220090866\n",
      "Epoch 1674, Loss: 0.14778434485197067, Final Batch Loss: 0.055273182690143585\n",
      "Epoch 1675, Loss: 0.21496541798114777, Final Batch Loss: 0.12159942090511322\n",
      "Epoch 1676, Loss: 0.26777784526348114, Final Batch Loss: 0.13230633735656738\n",
      "Epoch 1677, Loss: 0.14652105048298836, Final Batch Loss: 0.047274019569158554\n",
      "Epoch 1678, Loss: 0.18786445260047913, Final Batch Loss: 0.08713524043560028\n",
      "Epoch 1679, Loss: 0.164349015802145, Final Batch Loss: 0.06223451718688011\n",
      "Epoch 1680, Loss: 0.181294746696949, Final Batch Loss: 0.08355286717414856\n",
      "Epoch 1681, Loss: 0.18888278305530548, Final Batch Loss: 0.11028144508600235\n",
      "Epoch 1682, Loss: 0.21799633651971817, Final Batch Loss: 0.09917601197957993\n",
      "Epoch 1683, Loss: 0.1684759184718132, Final Batch Loss: 0.09625095129013062\n",
      "Epoch 1684, Loss: 0.20049726963043213, Final Batch Loss: 0.12071530520915985\n",
      "Epoch 1685, Loss: 0.17820874601602554, Final Batch Loss: 0.08903178572654724\n",
      "Epoch 1686, Loss: 0.1886214166879654, Final Batch Loss: 0.10215412825345993\n",
      "Epoch 1687, Loss: 0.2135356292128563, Final Batch Loss: 0.11623496562242508\n",
      "Epoch 1688, Loss: 0.20431548357009888, Final Batch Loss: 0.10438472777605057\n",
      "Epoch 1689, Loss: 0.18137085437774658, Final Batch Loss: 0.0978734940290451\n",
      "Epoch 1690, Loss: 0.20070252567529678, Final Batch Loss: 0.11518875509500504\n",
      "Epoch 1691, Loss: 0.21852219849824905, Final Batch Loss: 0.14034123718738556\n",
      "Epoch 1692, Loss: 0.1842813640832901, Final Batch Loss: 0.09302496910095215\n",
      "Epoch 1693, Loss: 0.1931699812412262, Final Batch Loss: 0.09640797227621078\n",
      "Epoch 1694, Loss: 0.16790034621953964, Final Batch Loss: 0.05788746476173401\n",
      "Epoch 1695, Loss: 0.19667788594961166, Final Batch Loss: 0.08329199254512787\n",
      "Epoch 1696, Loss: 0.2057415246963501, Final Batch Loss: 0.10507826507091522\n",
      "Epoch 1697, Loss: 0.21090847998857498, Final Batch Loss: 0.09683192521333694\n",
      "Epoch 1698, Loss: 0.16951142996549606, Final Batch Loss: 0.09997665882110596\n",
      "Epoch 1699, Loss: 0.16991879045963287, Final Batch Loss: 0.0784594714641571\n",
      "Epoch 1700, Loss: 0.16464748233556747, Final Batch Loss: 0.07539831846952438\n",
      "Epoch 1701, Loss: 0.16855473816394806, Final Batch Loss: 0.06779655814170837\n",
      "Epoch 1702, Loss: 0.2122189700603485, Final Batch Loss: 0.08044394850730896\n",
      "Epoch 1703, Loss: 0.16249462217092514, Final Batch Loss: 0.07691384106874466\n",
      "Epoch 1704, Loss: 0.16131871566176414, Final Batch Loss: 0.04821902886033058\n",
      "Epoch 1705, Loss: 0.20328618586063385, Final Batch Loss: 0.1106286272406578\n",
      "Epoch 1706, Loss: 0.19843075424432755, Final Batch Loss: 0.10206802189350128\n",
      "Epoch 1707, Loss: 0.18689262866973877, Final Batch Loss: 0.10518582910299301\n",
      "Epoch 1708, Loss: 0.1908247247338295, Final Batch Loss: 0.08436500281095505\n",
      "Epoch 1709, Loss: 0.16350945830345154, Final Batch Loss: 0.09115465730428696\n",
      "Epoch 1710, Loss: 0.18097198009490967, Final Batch Loss: 0.07874824106693268\n",
      "Epoch 1711, Loss: 0.29546409100294113, Final Batch Loss: 0.19530194997787476\n",
      "Epoch 1712, Loss: 0.1715390980243683, Final Batch Loss: 0.08218570798635483\n",
      "Epoch 1713, Loss: 0.17069174349308014, Final Batch Loss: 0.09205783158540726\n",
      "Epoch 1714, Loss: 0.18349283933639526, Final Batch Loss: 0.10394760966300964\n",
      "Epoch 1715, Loss: 0.1927223652601242, Final Batch Loss: 0.08526147156953812\n",
      "Epoch 1716, Loss: 0.18137066811323166, Final Batch Loss: 0.08913607895374298\n",
      "Epoch 1717, Loss: 0.18486085534095764, Final Batch Loss: 0.13327525556087494\n",
      "Epoch 1718, Loss: 0.17007017880678177, Final Batch Loss: 0.09451859444379807\n",
      "Epoch 1719, Loss: 0.17891118675470352, Final Batch Loss: 0.10074272751808167\n",
      "Epoch 1720, Loss: 0.237791508436203, Final Batch Loss: 0.15663114190101624\n",
      "Epoch 1721, Loss: 0.1814042627811432, Final Batch Loss: 0.09726870805025101\n",
      "Epoch 1722, Loss: 0.1552843265235424, Final Batch Loss: 0.04905698075890541\n",
      "Epoch 1723, Loss: 0.19004351645708084, Final Batch Loss: 0.0906825140118599\n",
      "Epoch 1724, Loss: 0.15592286735773087, Final Batch Loss: 0.0700162798166275\n",
      "Epoch 1725, Loss: 0.22601549327373505, Final Batch Loss: 0.15264183282852173\n",
      "Epoch 1726, Loss: 0.20188412442803383, Final Batch Loss: 0.051582220941782\n",
      "Epoch 1727, Loss: 0.19183213263750076, Final Batch Loss: 0.10141779482364655\n",
      "Epoch 1728, Loss: 0.13301843777298927, Final Batch Loss: 0.05523586645722389\n",
      "Epoch 1729, Loss: 0.16386036574840546, Final Batch Loss: 0.07849138975143433\n",
      "Epoch 1730, Loss: 0.15608664602041245, Final Batch Loss: 0.07849211990833282\n",
      "Epoch 1731, Loss: 0.15192239731550217, Final Batch Loss: 0.07472340762615204\n",
      "Epoch 1732, Loss: 0.18156024813652039, Final Batch Loss: 0.09640391916036606\n",
      "Epoch 1733, Loss: 0.1394420526921749, Final Batch Loss: 0.05094822123646736\n",
      "Epoch 1734, Loss: 0.15781740844249725, Final Batch Loss: 0.06827133893966675\n",
      "Epoch 1735, Loss: 0.1389048546552658, Final Batch Loss: 0.07071501761674881\n",
      "Epoch 1736, Loss: 0.17347201704978943, Final Batch Loss: 0.09200377017259598\n",
      "Epoch 1737, Loss: 0.22911277413368225, Final Batch Loss: 0.14561827480793\n",
      "Epoch 1738, Loss: 0.22006017714738846, Final Batch Loss: 0.13353756070137024\n",
      "Epoch 1739, Loss: 0.18530256301164627, Final Batch Loss: 0.07810521125793457\n",
      "Epoch 1740, Loss: 0.17185936868190765, Final Batch Loss: 0.07358235120773315\n",
      "Epoch 1741, Loss: 0.16965685039758682, Final Batch Loss: 0.09856715053319931\n",
      "Epoch 1742, Loss: 0.18466954678297043, Final Batch Loss: 0.10610050708055496\n",
      "Epoch 1743, Loss: 0.18000861257314682, Final Batch Loss: 0.07778026163578033\n",
      "Epoch 1744, Loss: 0.22465748339891434, Final Batch Loss: 0.1406668722629547\n",
      "Epoch 1745, Loss: 0.17817293852567673, Final Batch Loss: 0.08870135247707367\n",
      "Epoch 1746, Loss: 0.1702057123184204, Final Batch Loss: 0.08499424904584885\n",
      "Epoch 1747, Loss: 0.1738995462656021, Final Batch Loss: 0.07969710230827332\n",
      "Epoch 1748, Loss: 0.1537661850452423, Final Batch Loss: 0.08804108947515488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1749, Loss: 0.17046275734901428, Final Batch Loss: 0.08712200075387955\n",
      "Epoch 1750, Loss: 0.22488447278738022, Final Batch Loss: 0.12131097167730331\n",
      "Epoch 1751, Loss: 0.16244429349899292, Final Batch Loss: 0.07419724762439728\n",
      "Epoch 1752, Loss: 0.20636170357465744, Final Batch Loss: 0.11440388858318329\n",
      "Epoch 1753, Loss: 0.1702224388718605, Final Batch Loss: 0.0801464319229126\n",
      "Epoch 1754, Loss: 0.2209119349718094, Final Batch Loss: 0.13888725638389587\n",
      "Epoch 1755, Loss: 0.16755037009716034, Final Batch Loss: 0.06926430761814117\n",
      "Epoch 1756, Loss: 0.16444648057222366, Final Batch Loss: 0.0964355319738388\n",
      "Epoch 1757, Loss: 0.1634315699338913, Final Batch Loss: 0.06183398514986038\n",
      "Epoch 1758, Loss: 0.16625452786684036, Final Batch Loss: 0.08645881712436676\n",
      "Epoch 1759, Loss: 0.17045138776302338, Final Batch Loss: 0.09926222264766693\n",
      "Epoch 1760, Loss: 0.18023600429296494, Final Batch Loss: 0.10340676456689835\n",
      "Epoch 1761, Loss: 0.2045159414410591, Final Batch Loss: 0.11936049163341522\n",
      "Epoch 1762, Loss: 0.1698637679219246, Final Batch Loss: 0.08273997157812119\n",
      "Epoch 1763, Loss: 0.1557328924536705, Final Batch Loss: 0.0790599063038826\n",
      "Epoch 1764, Loss: 0.1815226897597313, Final Batch Loss: 0.09561677277088165\n",
      "Epoch 1765, Loss: 0.16184771806001663, Final Batch Loss: 0.08154869824647903\n",
      "Epoch 1766, Loss: 0.17205975949764252, Final Batch Loss: 0.07290315628051758\n",
      "Epoch 1767, Loss: 0.18337533622980118, Final Batch Loss: 0.09121739119291306\n",
      "Epoch 1768, Loss: 0.18182434141635895, Final Batch Loss: 0.08732334524393082\n",
      "Epoch 1769, Loss: 0.1803954616189003, Final Batch Loss: 0.1114640086889267\n",
      "Epoch 1770, Loss: 0.16077737510204315, Final Batch Loss: 0.07198334485292435\n",
      "Epoch 1771, Loss: 0.16507203876972198, Final Batch Loss: 0.076799176633358\n",
      "Epoch 1772, Loss: 0.15811732411384583, Final Batch Loss: 0.0836799144744873\n",
      "Epoch 1773, Loss: 0.1633220687508583, Final Batch Loss: 0.08241474628448486\n",
      "Epoch 1774, Loss: 0.13741766661405563, Final Batch Loss: 0.04969196021556854\n",
      "Epoch 1775, Loss: 0.2265366166830063, Final Batch Loss: 0.12415427714586258\n",
      "Epoch 1776, Loss: 0.2893291860818863, Final Batch Loss: 0.18346473574638367\n",
      "Epoch 1777, Loss: 0.15605760365724564, Final Batch Loss: 0.07003834843635559\n",
      "Epoch 1778, Loss: 0.16889777034521103, Final Batch Loss: 0.06981564313173294\n",
      "Epoch 1779, Loss: 0.1683610863983631, Final Batch Loss: 0.058598268777132034\n",
      "Epoch 1780, Loss: 0.16363513469696045, Final Batch Loss: 0.07907219976186752\n",
      "Epoch 1781, Loss: 0.18667428940534592, Final Batch Loss: 0.08668898791074753\n",
      "Epoch 1782, Loss: 0.2228628173470497, Final Batch Loss: 0.07012852281332016\n",
      "Epoch 1783, Loss: 0.18136688321828842, Final Batch Loss: 0.10897090286016464\n",
      "Epoch 1784, Loss: 0.18305353075265884, Final Batch Loss: 0.10046898573637009\n",
      "Epoch 1785, Loss: 0.14527368545532227, Final Batch Loss: 0.07095956802368164\n",
      "Epoch 1786, Loss: 0.16361382976174355, Final Batch Loss: 0.061658237129449844\n",
      "Epoch 1787, Loss: 0.15885179489850998, Final Batch Loss: 0.06375418603420258\n",
      "Epoch 1788, Loss: 0.1824776977300644, Final Batch Loss: 0.11164996773004532\n",
      "Epoch 1789, Loss: 0.17501936107873917, Final Batch Loss: 0.07268817722797394\n",
      "Epoch 1790, Loss: 0.16310769319534302, Final Batch Loss: 0.08220415562391281\n",
      "Epoch 1791, Loss: 0.19148853421211243, Final Batch Loss: 0.09919166564941406\n",
      "Epoch 1792, Loss: 0.1363517791032791, Final Batch Loss: 0.05401146411895752\n",
      "Epoch 1793, Loss: 0.1650528833270073, Final Batch Loss: 0.06858579069375992\n",
      "Epoch 1794, Loss: 0.1591101437807083, Final Batch Loss: 0.07838168740272522\n",
      "Epoch 1795, Loss: 0.14251992106437683, Final Batch Loss: 0.07754477858543396\n",
      "Epoch 1796, Loss: 0.13224201276898384, Final Batch Loss: 0.04186813160777092\n",
      "Epoch 1797, Loss: 0.19560381770133972, Final Batch Loss: 0.10752888768911362\n",
      "Epoch 1798, Loss: 0.19181914627552032, Final Batch Loss: 0.1066276878118515\n",
      "Epoch 1799, Loss: 0.19410274922847748, Final Batch Loss: 0.08347660303115845\n",
      "Epoch 1800, Loss: 0.17986083775758743, Final Batch Loss: 0.10422734171152115\n",
      "Epoch 1801, Loss: 0.19812649488449097, Final Batch Loss: 0.09210273623466492\n",
      "Epoch 1802, Loss: 0.13937867805361748, Final Batch Loss: 0.0392155684530735\n",
      "Epoch 1803, Loss: 0.2014515921473503, Final Batch Loss: 0.12223324924707413\n",
      "Epoch 1804, Loss: 0.1452217698097229, Final Batch Loss: 0.07981418073177338\n",
      "Epoch 1805, Loss: 0.15236406028270721, Final Batch Loss: 0.05920809507369995\n",
      "Epoch 1806, Loss: 0.2213253602385521, Final Batch Loss: 0.10543008148670197\n",
      "Epoch 1807, Loss: 0.1824217066168785, Final Batch Loss: 0.08397738635540009\n",
      "Epoch 1808, Loss: 0.3227652385830879, Final Batch Loss: 0.2381351739168167\n",
      "Epoch 1809, Loss: 0.15156909078359604, Final Batch Loss: 0.08128876239061356\n",
      "Epoch 1810, Loss: 0.163898304104805, Final Batch Loss: 0.08186399936676025\n",
      "Epoch 1811, Loss: 0.19839441031217575, Final Batch Loss: 0.1094885915517807\n",
      "Epoch 1812, Loss: 0.1368490643799305, Final Batch Loss: 0.05588735267519951\n",
      "Epoch 1813, Loss: 0.18834467232227325, Final Batch Loss: 0.06494171172380447\n",
      "Epoch 1814, Loss: 0.15823837369680405, Final Batch Loss: 0.06483040750026703\n",
      "Epoch 1815, Loss: 0.1742931790649891, Final Batch Loss: 0.11217574775218964\n",
      "Epoch 1816, Loss: 0.14285539090633392, Final Batch Loss: 0.04467765986919403\n",
      "Epoch 1817, Loss: 0.15126655995845795, Final Batch Loss: 0.09026408940553665\n",
      "Epoch 1818, Loss: 0.20501477271318436, Final Batch Loss: 0.12884657084941864\n",
      "Epoch 1819, Loss: 0.18038666248321533, Final Batch Loss: 0.09462139755487442\n",
      "Epoch 1820, Loss: 0.16962382197380066, Final Batch Loss: 0.07724273204803467\n",
      "Epoch 1821, Loss: 0.25139176845550537, Final Batch Loss: 0.16641058027744293\n",
      "Epoch 1822, Loss: 0.2234521433711052, Final Batch Loss: 0.13638578355312347\n",
      "Epoch 1823, Loss: 0.16272766888141632, Final Batch Loss: 0.09381606429815292\n",
      "Epoch 1824, Loss: 0.1667858138680458, Final Batch Loss: 0.0963728278875351\n",
      "Epoch 1825, Loss: 0.18980339914560318, Final Batch Loss: 0.10457602888345718\n",
      "Epoch 1826, Loss: 0.14882126823067665, Final Batch Loss: 0.04380449280142784\n",
      "Epoch 1827, Loss: 0.19826189428567886, Final Batch Loss: 0.09433910995721817\n",
      "Epoch 1828, Loss: 0.1621224656701088, Final Batch Loss: 0.07957011461257935\n",
      "Epoch 1829, Loss: 0.19139326363801956, Final Batch Loss: 0.0997074544429779\n",
      "Epoch 1830, Loss: 0.14928347989916801, Final Batch Loss: 0.05776074156165123\n",
      "Epoch 1831, Loss: 0.16400206089019775, Final Batch Loss: 0.08872516453266144\n",
      "Epoch 1832, Loss: 0.1620577983558178, Final Batch Loss: 0.052692774683237076\n",
      "Epoch 1833, Loss: 0.16231049597263336, Final Batch Loss: 0.06896600127220154\n",
      "Epoch 1834, Loss: 0.2115188091993332, Final Batch Loss: 0.12842518091201782\n",
      "Epoch 1835, Loss: 0.22439703345298767, Final Batch Loss: 0.1440615952014923\n",
      "Epoch 1836, Loss: 0.19025994837284088, Final Batch Loss: 0.10400541871786118\n",
      "Epoch 1837, Loss: 0.1548120081424713, Final Batch Loss: 0.08761253952980042\n",
      "Epoch 1838, Loss: 0.17028488963842392, Final Batch Loss: 0.06399601697921753\n",
      "Epoch 1839, Loss: 0.20519229024648666, Final Batch Loss: 0.11467449367046356\n",
      "Epoch 1840, Loss: 0.17398406565189362, Final Batch Loss: 0.08402466028928757\n",
      "Epoch 1841, Loss: 0.1628144383430481, Final Batch Loss: 0.06483498215675354\n",
      "Epoch 1842, Loss: 0.1534525603055954, Final Batch Loss: 0.0677642747759819\n",
      "Epoch 1843, Loss: 0.16311419010162354, Final Batch Loss: 0.06724953651428223\n",
      "Epoch 1844, Loss: 0.1496153473854065, Final Batch Loss: 0.057806260883808136\n",
      "Epoch 1845, Loss: 0.16513074934482574, Final Batch Loss: 0.09262233972549438\n",
      "Epoch 1846, Loss: 0.17797596752643585, Final Batch Loss: 0.09058026224374771\n",
      "Epoch 1847, Loss: 0.15244293212890625, Final Batch Loss: 0.058995477855205536\n",
      "Epoch 1848, Loss: 0.161748006939888, Final Batch Loss: 0.09391419589519501\n",
      "Epoch 1849, Loss: 0.18105952441692352, Final Batch Loss: 0.07698807865381241\n",
      "Epoch 1850, Loss: 0.17454659193754196, Final Batch Loss: 0.08157824724912643\n",
      "Epoch 1851, Loss: 0.16153337806463242, Final Batch Loss: 0.09200897812843323\n",
      "Epoch 1852, Loss: 0.16621264815330505, Final Batch Loss: 0.09707193821668625\n",
      "Epoch 1853, Loss: 0.21776273101568222, Final Batch Loss: 0.08579864352941513\n",
      "Epoch 1854, Loss: 0.1765846237540245, Final Batch Loss: 0.07599272578954697\n",
      "Epoch 1855, Loss: 0.14498161152005196, Final Batch Loss: 0.06041908636689186\n",
      "Epoch 1856, Loss: 0.1724025458097458, Final Batch Loss: 0.0990351065993309\n",
      "Epoch 1857, Loss: 0.15663034468889236, Final Batch Loss: 0.050670020282268524\n",
      "Epoch 1858, Loss: 0.16042932868003845, Final Batch Loss: 0.08868812769651413\n",
      "Epoch 1859, Loss: 0.16531267017126083, Final Batch Loss: 0.08512837439775467\n",
      "Epoch 1860, Loss: 0.16286958754062653, Final Batch Loss: 0.06644270569086075\n",
      "Epoch 1861, Loss: 0.2233325093984604, Final Batch Loss: 0.14743590354919434\n",
      "Epoch 1862, Loss: 0.1851974055171013, Final Batch Loss: 0.09962985664606094\n",
      "Epoch 1863, Loss: 0.18916922807693481, Final Batch Loss: 0.1027422770857811\n",
      "Epoch 1864, Loss: 0.15196272358298302, Final Batch Loss: 0.05840429291129112\n",
      "Epoch 1865, Loss: 0.18782062083482742, Final Batch Loss: 0.09098515659570694\n",
      "Epoch 1866, Loss: 0.1569126658141613, Final Batch Loss: 0.05452270433306694\n",
      "Epoch 1867, Loss: 0.1357027143239975, Final Batch Loss: 0.04747221618890762\n",
      "Epoch 1868, Loss: 0.16072365641593933, Final Batch Loss: 0.06463244557380676\n",
      "Epoch 1869, Loss: 0.1291881427168846, Final Batch Loss: 0.06463602185249329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1870, Loss: 0.17000464349985123, Final Batch Loss: 0.09277664870023727\n",
      "Epoch 1871, Loss: 0.15441937744617462, Final Batch Loss: 0.06557749956846237\n",
      "Epoch 1872, Loss: 0.1508663110435009, Final Batch Loss: 0.061662834137678146\n",
      "Epoch 1873, Loss: 0.16268328577280045, Final Batch Loss: 0.0896647498011589\n",
      "Epoch 1874, Loss: 0.18035665154457092, Final Batch Loss: 0.07282853126525879\n",
      "Epoch 1875, Loss: 0.1581188291311264, Final Batch Loss: 0.07587016373872757\n",
      "Epoch 1876, Loss: 0.17250124365091324, Final Batch Loss: 0.11919742077589035\n",
      "Epoch 1877, Loss: 0.13172050565481186, Final Batch Loss: 0.06245890259742737\n",
      "Epoch 1878, Loss: 0.1991853341460228, Final Batch Loss: 0.10281354188919067\n",
      "Epoch 1879, Loss: 0.15483281761407852, Final Batch Loss: 0.062129996716976166\n",
      "Epoch 1880, Loss: 0.18070971965789795, Final Batch Loss: 0.09646939486265182\n",
      "Epoch 1881, Loss: 0.18053249269723892, Final Batch Loss: 0.10901807248592377\n",
      "Epoch 1882, Loss: 0.1585886999964714, Final Batch Loss: 0.054066337645053864\n",
      "Epoch 1883, Loss: 0.1797749474644661, Final Batch Loss: 0.07055501639842987\n",
      "Epoch 1884, Loss: 0.20348302274942398, Final Batch Loss: 0.10889788717031479\n",
      "Epoch 1885, Loss: 0.17664824426174164, Final Batch Loss: 0.1083289235830307\n",
      "Epoch 1886, Loss: 0.14828304946422577, Final Batch Loss: 0.048964016139507294\n",
      "Epoch 1887, Loss: 0.1688687950372696, Final Batch Loss: 0.09302403777837753\n",
      "Epoch 1888, Loss: 0.13238992542028427, Final Batch Loss: 0.04671379178762436\n",
      "Epoch 1889, Loss: 0.17767010629177094, Final Batch Loss: 0.07441886514425278\n",
      "Epoch 1890, Loss: 0.1491716355085373, Final Batch Loss: 0.07039634883403778\n",
      "Epoch 1891, Loss: 0.1843022033572197, Final Batch Loss: 0.11884097754955292\n",
      "Epoch 1892, Loss: 0.1885637268424034, Final Batch Loss: 0.07890991121530533\n",
      "Epoch 1893, Loss: 0.2321297451853752, Final Batch Loss: 0.14140138030052185\n",
      "Epoch 1894, Loss: 0.17672550678253174, Final Batch Loss: 0.07953066378831863\n",
      "Epoch 1895, Loss: 0.15390674769878387, Final Batch Loss: 0.0776074007153511\n",
      "Epoch 1896, Loss: 0.16845019161701202, Final Batch Loss: 0.08489437401294708\n",
      "Epoch 1897, Loss: 0.20371349155902863, Final Batch Loss: 0.09926865994930267\n",
      "Epoch 1898, Loss: 0.16055748611688614, Final Batch Loss: 0.06732111424207687\n",
      "Epoch 1899, Loss: 0.12113991007208824, Final Batch Loss: 0.03655143454670906\n",
      "Epoch 1900, Loss: 0.21578817814588547, Final Batch Loss: 0.10614261776208878\n",
      "Epoch 1901, Loss: 0.20468012243509293, Final Batch Loss: 0.08997650444507599\n",
      "Epoch 1902, Loss: 0.16231071949005127, Final Batch Loss: 0.0729622170329094\n",
      "Epoch 1903, Loss: 0.14750181883573532, Final Batch Loss: 0.06994588673114777\n",
      "Epoch 1904, Loss: 0.1657969057559967, Final Batch Loss: 0.07612016052007675\n",
      "Epoch 1905, Loss: 0.1309477798640728, Final Batch Loss: 0.0561179555952549\n",
      "Epoch 1906, Loss: 0.17148235440254211, Final Batch Loss: 0.07098397612571716\n",
      "Epoch 1907, Loss: 0.17173344641923904, Final Batch Loss: 0.10716398805379868\n",
      "Epoch 1908, Loss: 0.15055648237466812, Final Batch Loss: 0.05927889049053192\n",
      "Epoch 1909, Loss: 0.16220976412296295, Final Batch Loss: 0.06631702929735184\n",
      "Epoch 1910, Loss: 0.22111620008945465, Final Batch Loss: 0.10230018943548203\n",
      "Epoch 1911, Loss: 0.19084323942661285, Final Batch Loss: 0.10337398946285248\n",
      "Epoch 1912, Loss: 0.15021170675754547, Final Batch Loss: 0.07363875955343246\n",
      "Epoch 1913, Loss: 0.18534737825393677, Final Batch Loss: 0.1125120297074318\n",
      "Epoch 1914, Loss: 0.16475531831383705, Final Batch Loss: 0.10265789926052094\n",
      "Epoch 1915, Loss: 0.18702037632465363, Final Batch Loss: 0.11032242327928543\n",
      "Epoch 1916, Loss: 0.22062472999095917, Final Batch Loss: 0.15801690518856049\n",
      "Epoch 1917, Loss: 0.16124436259269714, Final Batch Loss: 0.06375433504581451\n",
      "Epoch 1918, Loss: 0.15343090891838074, Final Batch Loss: 0.07562336325645447\n",
      "Epoch 1919, Loss: 0.21940073370933533, Final Batch Loss: 0.14827179908752441\n",
      "Epoch 1920, Loss: 0.13539575785398483, Final Batch Loss: 0.044051915407180786\n",
      "Epoch 1921, Loss: 0.16602730005979538, Final Batch Loss: 0.10543397068977356\n",
      "Epoch 1922, Loss: 0.16722089797258377, Final Batch Loss: 0.08037672936916351\n",
      "Epoch 1923, Loss: 0.15390881150960922, Final Batch Loss: 0.07205811142921448\n",
      "Epoch 1924, Loss: 0.15719041228294373, Final Batch Loss: 0.0784853994846344\n",
      "Epoch 1925, Loss: 0.20609045773744583, Final Batch Loss: 0.12807781994342804\n",
      "Epoch 1926, Loss: 0.1754869893193245, Final Batch Loss: 0.10432476550340652\n",
      "Epoch 1927, Loss: 0.15370308607816696, Final Batch Loss: 0.09445837885141373\n",
      "Epoch 1928, Loss: 0.16727736592292786, Final Batch Loss: 0.08216380327939987\n",
      "Epoch 1929, Loss: 0.17832861095666885, Final Batch Loss: 0.10994674265384674\n",
      "Epoch 1930, Loss: 0.14463436603546143, Final Batch Loss: 0.057925745844841\n",
      "Epoch 1931, Loss: 0.16178353130817413, Final Batch Loss: 0.06520508229732513\n",
      "Epoch 1932, Loss: 0.2704627811908722, Final Batch Loss: 0.08505874872207642\n",
      "Epoch 1933, Loss: 0.15212856978178024, Final Batch Loss: 0.07917658239603043\n",
      "Epoch 1934, Loss: 0.17803525179624557, Final Batch Loss: 0.1079050675034523\n",
      "Epoch 1935, Loss: 0.1480647586286068, Final Batch Loss: 0.06189022585749626\n",
      "Epoch 1936, Loss: 0.17441944777965546, Final Batch Loss: 0.08970537781715393\n",
      "Epoch 1937, Loss: 0.15741632133722305, Final Batch Loss: 0.06261558830738068\n",
      "Epoch 1938, Loss: 0.1663089469075203, Final Batch Loss: 0.08959728479385376\n",
      "Epoch 1939, Loss: 0.15712282061576843, Final Batch Loss: 0.09331294149160385\n",
      "Epoch 1940, Loss: 0.14421214908361435, Final Batch Loss: 0.06258957833051682\n",
      "Epoch 1941, Loss: 0.13834766671061516, Final Batch Loss: 0.055880215018987656\n",
      "Epoch 1942, Loss: 0.16284319013357162, Final Batch Loss: 0.06979813426733017\n",
      "Epoch 1943, Loss: 0.15148207545280457, Final Batch Loss: 0.07631333917379379\n",
      "Epoch 1944, Loss: 0.1359662227332592, Final Batch Loss: 0.049116235226392746\n",
      "Epoch 1945, Loss: 0.18143901228904724, Final Batch Loss: 0.07337261736392975\n",
      "Epoch 1946, Loss: 0.1595870852470398, Final Batch Loss: 0.0802437961101532\n",
      "Epoch 1947, Loss: 0.15005042776465416, Final Batch Loss: 0.0954221710562706\n",
      "Epoch 1948, Loss: 0.14828558266162872, Final Batch Loss: 0.0738840103149414\n",
      "Epoch 1949, Loss: 0.1460491195321083, Final Batch Loss: 0.045410268008708954\n",
      "Epoch 1950, Loss: 0.15224577113986015, Final Batch Loss: 0.05555086210370064\n",
      "Epoch 1951, Loss: 0.14961755275726318, Final Batch Loss: 0.08343587070703506\n",
      "Epoch 1952, Loss: 0.18905963376164436, Final Batch Loss: 0.12915755808353424\n",
      "Epoch 1953, Loss: 0.20067382603883743, Final Batch Loss: 0.130451038479805\n",
      "Epoch 1954, Loss: 0.1557445079088211, Final Batch Loss: 0.06272312998771667\n",
      "Epoch 1955, Loss: 0.16997041553258896, Final Batch Loss: 0.09707432240247726\n",
      "Epoch 1956, Loss: 0.16361238062381744, Final Batch Loss: 0.09622244536876678\n",
      "Epoch 1957, Loss: 0.14364884048700333, Final Batch Loss: 0.06860587000846863\n",
      "Epoch 1958, Loss: 0.1860327124595642, Final Batch Loss: 0.10128246992826462\n",
      "Epoch 1959, Loss: 0.18033631891012192, Final Batch Loss: 0.10874583572149277\n",
      "Epoch 1960, Loss: 0.15301570668816566, Final Batch Loss: 0.06176002696156502\n",
      "Epoch 1961, Loss: 0.1277734860777855, Final Batch Loss: 0.03967259079217911\n",
      "Epoch 1962, Loss: 0.15254324302077293, Final Batch Loss: 0.050868649035692215\n",
      "Epoch 1963, Loss: 0.14784184098243713, Final Batch Loss: 0.06784158945083618\n",
      "Epoch 1964, Loss: 0.15918922424316406, Final Batch Loss: 0.09249438345432281\n",
      "Epoch 1965, Loss: 0.123162891715765, Final Batch Loss: 0.04319744184613228\n",
      "Epoch 1966, Loss: 0.23660973459482193, Final Batch Loss: 0.12839272618293762\n",
      "Epoch 1967, Loss: 0.15112952515482903, Final Batch Loss: 0.05885698273777962\n",
      "Epoch 1968, Loss: 0.1411137953400612, Final Batch Loss: 0.07312173396348953\n",
      "Epoch 1969, Loss: 0.1809103935956955, Final Batch Loss: 0.1063610166311264\n",
      "Epoch 1970, Loss: 0.1559486910700798, Final Batch Loss: 0.0639532133936882\n",
      "Epoch 1971, Loss: 0.1637600213289261, Final Batch Loss: 0.07001479715108871\n",
      "Epoch 1972, Loss: 0.13948740810155869, Final Batch Loss: 0.04955422878265381\n",
      "Epoch 1973, Loss: 0.1454545296728611, Final Batch Loss: 0.05615442618727684\n",
      "Epoch 1974, Loss: 0.16560013592243195, Final Batch Loss: 0.08741466701030731\n",
      "Epoch 1975, Loss: 0.18140485137701035, Final Batch Loss: 0.10925285518169403\n",
      "Epoch 1976, Loss: 0.17042458802461624, Final Batch Loss: 0.08976580947637558\n",
      "Epoch 1977, Loss: 0.1547161266207695, Final Batch Loss: 0.06972188502550125\n",
      "Epoch 1978, Loss: 0.13078657537698746, Final Batch Loss: 0.043436720967292786\n",
      "Epoch 1979, Loss: 0.15591418370604515, Final Batch Loss: 0.09604998677968979\n",
      "Epoch 1980, Loss: 0.17391437292099, Final Batch Loss: 0.0816858634352684\n",
      "Epoch 1981, Loss: 0.15133218467235565, Final Batch Loss: 0.0853082612156868\n",
      "Epoch 1982, Loss: 0.14612051099538803, Final Batch Loss: 0.07439528405666351\n",
      "Epoch 1983, Loss: 0.14610302448272705, Final Batch Loss: 0.07711011916399002\n",
      "Epoch 1984, Loss: 0.18432150781154633, Final Batch Loss: 0.09142450988292694\n",
      "Epoch 1985, Loss: 0.1705372929573059, Final Batch Loss: 0.09656020253896713\n",
      "Epoch 1986, Loss: 0.14058559760451317, Final Batch Loss: 0.057417113333940506\n",
      "Epoch 1987, Loss: 0.14637713879346848, Final Batch Loss: 0.07352159917354584\n",
      "Epoch 1988, Loss: 0.18954677879810333, Final Batch Loss: 0.09738779813051224\n",
      "Epoch 1989, Loss: 0.15053389966487885, Final Batch Loss: 0.0712164044380188\n",
      "Epoch 1990, Loss: 0.15303773805499077, Final Batch Loss: 0.05503161624073982\n",
      "Epoch 1991, Loss: 0.21475499868392944, Final Batch Loss: 0.12922802567481995\n",
      "Epoch 1992, Loss: 0.17286309599876404, Final Batch Loss: 0.09510626643896103\n",
      "Epoch 1993, Loss: 0.20262183994054794, Final Batch Loss: 0.12277716398239136\n",
      "Epoch 1994, Loss: 0.1777941733598709, Final Batch Loss: 0.0920652374625206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1995, Loss: 0.1828450784087181, Final Batch Loss: 0.09155388176441193\n",
      "Epoch 1996, Loss: 0.14963662438094616, Final Batch Loss: 0.030736884102225304\n",
      "Epoch 1997, Loss: 0.13541262969374657, Final Batch Loss: 0.039651501923799515\n",
      "Epoch 1998, Loss: 0.14348405972123146, Final Batch Loss: 0.05974309518933296\n",
      "Epoch 1999, Loss: 0.16345763951539993, Final Batch Loss: 0.07950910180807114\n",
      "Epoch 2000, Loss: 0.15435830503702164, Final Batch Loss: 0.06703662127256393\n",
      "Epoch 2001, Loss: 0.15417736023664474, Final Batch Loss: 0.08010762184858322\n",
      "Epoch 2002, Loss: 0.1432402804493904, Final Batch Loss: 0.07078743726015091\n",
      "Epoch 2003, Loss: 0.1690811738371849, Final Batch Loss: 0.05253933370113373\n",
      "Epoch 2004, Loss: 0.16023340821266174, Final Batch Loss: 0.0938156470656395\n",
      "Epoch 2005, Loss: 0.1666160672903061, Final Batch Loss: 0.07434328645467758\n",
      "Epoch 2006, Loss: 0.15292811393737793, Final Batch Loss: 0.07225372642278671\n",
      "Epoch 2007, Loss: 0.1942274123430252, Final Batch Loss: 0.10678698122501373\n",
      "Epoch 2008, Loss: 0.13295849412679672, Final Batch Loss: 0.04230290651321411\n",
      "Epoch 2009, Loss: 0.2089778110384941, Final Batch Loss: 0.1359148621559143\n",
      "Epoch 2010, Loss: 0.14714441448450089, Final Batch Loss: 0.06439141184091568\n",
      "Epoch 2011, Loss: 0.16914306581020355, Final Batch Loss: 0.09164830297231674\n",
      "Epoch 2012, Loss: 0.15356678515672684, Final Batch Loss: 0.06732077896595001\n",
      "Epoch 2013, Loss: 0.18957960233092308, Final Batch Loss: 0.12787485122680664\n",
      "Epoch 2014, Loss: 0.15082047134637833, Final Batch Loss: 0.07319009304046631\n",
      "Epoch 2015, Loss: 0.17778653651475906, Final Batch Loss: 0.10292813181877136\n",
      "Epoch 2016, Loss: 0.17575795948505402, Final Batch Loss: 0.0896821990609169\n",
      "Epoch 2017, Loss: 0.20714329928159714, Final Batch Loss: 0.1283743977546692\n",
      "Epoch 2018, Loss: 0.24273256212472916, Final Batch Loss: 0.14799365401268005\n",
      "Epoch 2019, Loss: 0.1535899005830288, Final Batch Loss: 0.09305386990308762\n",
      "Epoch 2020, Loss: 0.1588304117321968, Final Batch Loss: 0.08818462491035461\n",
      "Epoch 2021, Loss: 0.17404569685459137, Final Batch Loss: 0.07600421458482742\n",
      "Epoch 2022, Loss: 0.1825055405497551, Final Batch Loss: 0.11411578953266144\n",
      "Epoch 2023, Loss: 0.155267171561718, Final Batch Loss: 0.08540917932987213\n",
      "Epoch 2024, Loss: 0.16324598342180252, Final Batch Loss: 0.04618433117866516\n",
      "Epoch 2025, Loss: 0.23297277837991714, Final Batch Loss: 0.1644124835729599\n",
      "Epoch 2026, Loss: 0.18093720078468323, Final Batch Loss: 0.09079032391309738\n",
      "Epoch 2027, Loss: 0.1801542416214943, Final Batch Loss: 0.09070055931806564\n",
      "Epoch 2028, Loss: 0.16790884733200073, Final Batch Loss: 0.08058770000934601\n",
      "Epoch 2029, Loss: 0.17157043144106865, Final Batch Loss: 0.054583217948675156\n",
      "Epoch 2030, Loss: 0.17080576717853546, Final Batch Loss: 0.07466258853673935\n",
      "Epoch 2031, Loss: 0.1565857082605362, Final Batch Loss: 0.08052685111761093\n",
      "Epoch 2032, Loss: 0.1788574829697609, Final Batch Loss: 0.11163743585348129\n",
      "Epoch 2033, Loss: 0.138481292873621, Final Batch Loss: 0.046942297369241714\n",
      "Epoch 2034, Loss: 0.14841242879629135, Final Batch Loss: 0.06093597412109375\n",
      "Epoch 2035, Loss: 0.18186084926128387, Final Batch Loss: 0.1002851203083992\n",
      "Epoch 2036, Loss: 0.1885204203426838, Final Batch Loss: 0.05595878139138222\n",
      "Epoch 2037, Loss: 0.16277345269918442, Final Batch Loss: 0.08107241243124008\n",
      "Epoch 2038, Loss: 0.16675136983394623, Final Batch Loss: 0.0978059396147728\n",
      "Epoch 2039, Loss: 0.16120175272226334, Final Batch Loss: 0.07033278048038483\n",
      "Epoch 2040, Loss: 0.12826361879706383, Final Batch Loss: 0.043204616755247116\n",
      "Epoch 2041, Loss: 0.1352025642991066, Final Batch Loss: 0.06429457664489746\n",
      "Epoch 2042, Loss: 0.1829943135380745, Final Batch Loss: 0.11763057857751846\n",
      "Epoch 2043, Loss: 0.14908184111118317, Final Batch Loss: 0.045115694403648376\n",
      "Epoch 2044, Loss: 0.14307071268558502, Final Batch Loss: 0.07962616533041\n",
      "Epoch 2045, Loss: 0.18512780219316483, Final Batch Loss: 0.11138595640659332\n",
      "Epoch 2046, Loss: 0.1732550784945488, Final Batch Loss: 0.10803122073411942\n",
      "Epoch 2047, Loss: 0.15662608295679092, Final Batch Loss: 0.06525109708309174\n",
      "Epoch 2048, Loss: 0.20636990666389465, Final Batch Loss: 0.12231789529323578\n",
      "Epoch 2049, Loss: 0.1383989416062832, Final Batch Loss: 0.06090252473950386\n",
      "Epoch 2050, Loss: 0.17859146744012833, Final Batch Loss: 0.08927983790636063\n",
      "Epoch 2051, Loss: 0.17274967581033707, Final Batch Loss: 0.07278452813625336\n",
      "Epoch 2052, Loss: 0.18867649883031845, Final Batch Loss: 0.10509888082742691\n",
      "Epoch 2053, Loss: 0.15330320596694946, Final Batch Loss: 0.08586272597312927\n",
      "Epoch 2054, Loss: 0.1358242705464363, Final Batch Loss: 0.06284536421298981\n",
      "Epoch 2055, Loss: 0.18053290992975235, Final Batch Loss: 0.0805625170469284\n",
      "Epoch 2056, Loss: 0.15292208641767502, Final Batch Loss: 0.0807993933558464\n",
      "Epoch 2057, Loss: 0.15438205376267433, Final Batch Loss: 0.05691438540816307\n",
      "Epoch 2058, Loss: 0.16154030710458755, Final Batch Loss: 0.08271686732769012\n",
      "Epoch 2059, Loss: 0.14989084005355835, Final Batch Loss: 0.07879746705293655\n",
      "Epoch 2060, Loss: 0.20295245200395584, Final Batch Loss: 0.08407238125801086\n",
      "Epoch 2061, Loss: 0.16512452065944672, Final Batch Loss: 0.05413225293159485\n",
      "Epoch 2062, Loss: 0.15350885689258575, Final Batch Loss: 0.08076294511556625\n",
      "Epoch 2063, Loss: 0.15183737874031067, Final Batch Loss: 0.08113868534564972\n",
      "Epoch 2064, Loss: 0.12323268502950668, Final Batch Loss: 0.03493756055831909\n",
      "Epoch 2065, Loss: 0.14232132583856583, Final Batch Loss: 0.07069751620292664\n",
      "Epoch 2066, Loss: 0.1567811444401741, Final Batch Loss: 0.08852944523096085\n",
      "Epoch 2067, Loss: 0.17823483049869537, Final Batch Loss: 0.07298913598060608\n",
      "Epoch 2068, Loss: 0.20282267779111862, Final Batch Loss: 0.11252368986606598\n",
      "Epoch 2069, Loss: 0.12260482460260391, Final Batch Loss: 0.034807972609996796\n",
      "Epoch 2070, Loss: 0.16110464930534363, Final Batch Loss: 0.08473725616931915\n",
      "Epoch 2071, Loss: 0.13259249180555344, Final Batch Loss: 0.05323696881532669\n",
      "Epoch 2072, Loss: 0.1969945952296257, Final Batch Loss: 0.1344812661409378\n",
      "Epoch 2073, Loss: 0.14260583370923996, Final Batch Loss: 0.0772387757897377\n",
      "Epoch 2074, Loss: 0.1554718241095543, Final Batch Loss: 0.08435641974210739\n",
      "Epoch 2075, Loss: 0.22092723846435547, Final Batch Loss: 0.14775891602039337\n",
      "Epoch 2076, Loss: 0.10590285435318947, Final Batch Loss: 0.01707017794251442\n",
      "Epoch 2077, Loss: 0.19890473783016205, Final Batch Loss: 0.09197361022233963\n",
      "Epoch 2078, Loss: 0.14925947040319443, Final Batch Loss: 0.06988134980201721\n",
      "Epoch 2079, Loss: 0.1545427180826664, Final Batch Loss: 0.09860304743051529\n",
      "Epoch 2080, Loss: 0.13137569651007652, Final Batch Loss: 0.05753769353032112\n",
      "Epoch 2081, Loss: 0.2056211456656456, Final Batch Loss: 0.1243867427110672\n",
      "Epoch 2082, Loss: 0.1787082627415657, Final Batch Loss: 0.09738784283399582\n",
      "Epoch 2083, Loss: 0.14422894641757011, Final Batch Loss: 0.059716369956731796\n",
      "Epoch 2084, Loss: 0.14985712617635727, Final Batch Loss: 0.07956183701753616\n",
      "Epoch 2085, Loss: 0.1746237874031067, Final Batch Loss: 0.1065215989947319\n",
      "Epoch 2086, Loss: 0.15299032628536224, Final Batch Loss: 0.09267224371433258\n",
      "Epoch 2087, Loss: 0.16156576573848724, Final Batch Loss: 0.0666988268494606\n",
      "Epoch 2088, Loss: 0.3392551988363266, Final Batch Loss: 0.2645638585090637\n",
      "Epoch 2089, Loss: 0.12640488147735596, Final Batch Loss: 0.06292324513196945\n",
      "Epoch 2090, Loss: 0.13435796275734901, Final Batch Loss: 0.059608932584524155\n",
      "Epoch 2091, Loss: 0.14964009076356888, Final Batch Loss: 0.06877398490905762\n",
      "Epoch 2092, Loss: 0.14491265267133713, Final Batch Loss: 0.06986340135335922\n",
      "Epoch 2093, Loss: 0.162235789000988, Final Batch Loss: 0.0772072896361351\n",
      "Epoch 2094, Loss: 0.16967499256134033, Final Batch Loss: 0.08049647510051727\n",
      "Epoch 2095, Loss: 0.15970385819673538, Final Batch Loss: 0.09312880039215088\n",
      "Epoch 2096, Loss: 0.16853970289230347, Final Batch Loss: 0.09168105572462082\n",
      "Epoch 2097, Loss: 0.11839905381202698, Final Batch Loss: 0.040422290563583374\n",
      "Epoch 2098, Loss: 0.1514950729906559, Final Batch Loss: 0.06191186234354973\n",
      "Epoch 2099, Loss: 0.129111647605896, Final Batch Loss: 0.06010499596595764\n",
      "Epoch 2100, Loss: 0.18611448630690575, Final Batch Loss: 0.12696968019008636\n",
      "Epoch 2101, Loss: 0.19177477061748505, Final Batch Loss: 0.06300950050354004\n",
      "Epoch 2102, Loss: 0.1456839144229889, Final Batch Loss: 0.07040742039680481\n",
      "Epoch 2103, Loss: 0.1676485911011696, Final Batch Loss: 0.09600652009248734\n",
      "Epoch 2104, Loss: 0.16829589009284973, Final Batch Loss: 0.07763636112213135\n",
      "Epoch 2105, Loss: 0.16311340034008026, Final Batch Loss: 0.09262511134147644\n",
      "Epoch 2106, Loss: 0.17078544199466705, Final Batch Loss: 0.07774104923009872\n",
      "Epoch 2107, Loss: 0.1846563220024109, Final Batch Loss: 0.06455573439598083\n",
      "Epoch 2108, Loss: 0.14381001889705658, Final Batch Loss: 0.05923616141080856\n",
      "Epoch 2109, Loss: 0.12335402891039848, Final Batch Loss: 0.06382189691066742\n",
      "Epoch 2110, Loss: 0.1788128837943077, Final Batch Loss: 0.1057935580611229\n",
      "Epoch 2111, Loss: 0.1406511589884758, Final Batch Loss: 0.06520445644855499\n",
      "Epoch 2112, Loss: 0.1879814863204956, Final Batch Loss: 0.10625855624675751\n",
      "Epoch 2113, Loss: 0.14418278634548187, Final Batch Loss: 0.05689527839422226\n",
      "Epoch 2114, Loss: 0.10755476541817188, Final Batch Loss: 0.030574055388569832\n",
      "Epoch 2115, Loss: 0.16197644174098969, Final Batch Loss: 0.07439860701560974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2116, Loss: 0.18393494188785553, Final Batch Loss: 0.10051959753036499\n",
      "Epoch 2117, Loss: 0.1867138370871544, Final Batch Loss: 0.1225501224398613\n",
      "Epoch 2118, Loss: 0.14403150230646133, Final Batch Loss: 0.062474802136421204\n",
      "Epoch 2119, Loss: 0.19278065860271454, Final Batch Loss: 0.07571659982204437\n",
      "Epoch 2120, Loss: 0.15875349938869476, Final Batch Loss: 0.06770487129688263\n",
      "Epoch 2121, Loss: 0.13424087688326836, Final Batch Loss: 0.05427445098757744\n",
      "Epoch 2122, Loss: 0.19000159949064255, Final Batch Loss: 0.11057980358600616\n",
      "Epoch 2123, Loss: 0.153021402657032, Final Batch Loss: 0.06516927480697632\n",
      "Epoch 2124, Loss: 0.1730094701051712, Final Batch Loss: 0.09394301474094391\n",
      "Epoch 2125, Loss: 0.14646385610103607, Final Batch Loss: 0.06715403497219086\n",
      "Epoch 2126, Loss: 0.14434200525283813, Final Batch Loss: 0.06571350246667862\n",
      "Epoch 2127, Loss: 0.13048119470477104, Final Batch Loss: 0.06963217258453369\n",
      "Epoch 2128, Loss: 0.14310984686017036, Final Batch Loss: 0.05617279186844826\n",
      "Epoch 2129, Loss: 0.1917945146560669, Final Batch Loss: 0.12502510845661163\n",
      "Epoch 2130, Loss: 0.1522417590022087, Final Batch Loss: 0.08248818665742874\n",
      "Epoch 2131, Loss: 0.1795039400458336, Final Batch Loss: 0.07561608403921127\n",
      "Epoch 2132, Loss: 0.1647772714495659, Final Batch Loss: 0.08977881819009781\n",
      "Epoch 2133, Loss: 0.13679896667599678, Final Batch Loss: 0.05181369557976723\n",
      "Epoch 2134, Loss: 0.11850440502166748, Final Batch Loss: 0.040023550391197205\n",
      "Epoch 2135, Loss: 0.15563099831342697, Final Batch Loss: 0.07163935899734497\n",
      "Epoch 2136, Loss: 0.14416180551052094, Final Batch Loss: 0.06873684376478195\n",
      "Epoch 2137, Loss: 0.15412818640470505, Final Batch Loss: 0.0601007416844368\n",
      "Epoch 2138, Loss: 0.1640007421374321, Final Batch Loss: 0.08040317893028259\n",
      "Epoch 2139, Loss: 0.12304642796516418, Final Batch Loss: 0.057088106870651245\n",
      "Epoch 2140, Loss: 0.13470504060387611, Final Batch Loss: 0.05153805390000343\n",
      "Epoch 2141, Loss: 0.10850466787815094, Final Batch Loss: 0.03463301807641983\n",
      "Epoch 2142, Loss: 0.16700822860002518, Final Batch Loss: 0.07768432050943375\n",
      "Epoch 2143, Loss: 0.15220265835523605, Final Batch Loss: 0.08070365339517593\n",
      "Epoch 2144, Loss: 0.11424898728728294, Final Batch Loss: 0.03720923885703087\n",
      "Epoch 2145, Loss: 0.19736798852682114, Final Batch Loss: 0.13222439587116241\n",
      "Epoch 2146, Loss: 0.1490212418138981, Final Batch Loss: 0.058527376502752304\n",
      "Epoch 2147, Loss: 0.13539786636829376, Final Batch Loss: 0.07463723421096802\n",
      "Epoch 2148, Loss: 0.16185975074768066, Final Batch Loss: 0.08146040886640549\n",
      "Epoch 2149, Loss: 0.18669237941503525, Final Batch Loss: 0.11183372884988785\n",
      "Epoch 2150, Loss: 0.15769515186548233, Final Batch Loss: 0.07132215052843094\n",
      "Epoch 2151, Loss: 0.13332202285528183, Final Batch Loss: 0.06701456755399704\n",
      "Epoch 2152, Loss: 0.11433546617627144, Final Batch Loss: 0.0513901449739933\n",
      "Epoch 2153, Loss: 0.14123882353305817, Final Batch Loss: 0.09084151685237885\n",
      "Epoch 2154, Loss: 0.13210216164588928, Final Batch Loss: 0.06055211275815964\n",
      "Epoch 2155, Loss: 0.13606799021363258, Final Batch Loss: 0.05746128782629967\n",
      "Epoch 2156, Loss: 0.1905987188220024, Final Batch Loss: 0.1094023659825325\n",
      "Epoch 2157, Loss: 0.21668418496847153, Final Batch Loss: 0.14450469613075256\n",
      "Epoch 2158, Loss: 0.1743735671043396, Final Batch Loss: 0.08208636194467545\n",
      "Epoch 2159, Loss: 0.13509587943553925, Final Batch Loss: 0.06588119268417358\n",
      "Epoch 2160, Loss: 0.17861739546060562, Final Batch Loss: 0.08031982183456421\n",
      "Epoch 2161, Loss: 0.1413116231560707, Final Batch Loss: 0.06352950632572174\n",
      "Epoch 2162, Loss: 0.27489108592271805, Final Batch Loss: 0.18452957272529602\n",
      "Epoch 2163, Loss: 0.14236429706215858, Final Batch Loss: 0.057590801268815994\n",
      "Epoch 2164, Loss: 0.13880212977528572, Final Batch Loss: 0.056553784757852554\n",
      "Epoch 2165, Loss: 0.23186376690864563, Final Batch Loss: 0.1344475895166397\n",
      "Epoch 2166, Loss: 0.16710403561592102, Final Batch Loss: 0.09633024781942368\n",
      "Epoch 2167, Loss: 0.16984831541776657, Final Batch Loss: 0.0874011218547821\n",
      "Epoch 2168, Loss: 0.18590682744979858, Final Batch Loss: 0.1303827464580536\n",
      "Epoch 2169, Loss: 0.15607108920812607, Final Batch Loss: 0.07348056137561798\n",
      "Epoch 2170, Loss: 0.15944477170705795, Final Batch Loss: 0.0960642620921135\n",
      "Epoch 2171, Loss: 0.14600641280412674, Final Batch Loss: 0.08307890594005585\n",
      "Epoch 2172, Loss: 0.14635762572288513, Final Batch Loss: 0.07411910593509674\n",
      "Epoch 2173, Loss: 0.16936438530683517, Final Batch Loss: 0.09069737792015076\n",
      "Epoch 2174, Loss: 0.13526462018489838, Final Batch Loss: 0.0634404644370079\n",
      "Epoch 2175, Loss: 0.12262076884508133, Final Batch Loss: 0.04100862145423889\n",
      "Epoch 2176, Loss: 0.12244187295436859, Final Batch Loss: 0.046704113483428955\n",
      "Epoch 2177, Loss: 0.1645924225449562, Final Batch Loss: 0.09213577210903168\n",
      "Epoch 2178, Loss: 0.1475241258740425, Final Batch Loss: 0.0901995375752449\n",
      "Epoch 2179, Loss: 0.14744491502642632, Final Batch Loss: 0.08860111236572266\n",
      "Epoch 2180, Loss: 0.15751682966947556, Final Batch Loss: 0.07563017308712006\n",
      "Epoch 2181, Loss: 0.14035970717668533, Final Batch Loss: 0.05089031904935837\n",
      "Epoch 2182, Loss: 0.17335521429777145, Final Batch Loss: 0.10845765471458435\n",
      "Epoch 2183, Loss: 0.10755637660622597, Final Batch Loss: 0.034486111253499985\n",
      "Epoch 2184, Loss: 0.14123724400997162, Final Batch Loss: 0.06824425607919693\n",
      "Epoch 2185, Loss: 0.1421453356742859, Final Batch Loss: 0.06112789362668991\n",
      "Epoch 2186, Loss: 0.14361649751663208, Final Batch Loss: 0.06571869552135468\n",
      "Epoch 2187, Loss: 0.16142185777425766, Final Batch Loss: 0.08856569975614548\n",
      "Epoch 2188, Loss: 0.1386074386537075, Final Batch Loss: 0.0809171050786972\n",
      "Epoch 2189, Loss: 0.15448308736085892, Final Batch Loss: 0.09413692355155945\n",
      "Epoch 2190, Loss: 0.1317652128636837, Final Batch Loss: 0.055066514760255814\n",
      "Epoch 2191, Loss: 0.15048187226057053, Final Batch Loss: 0.06395472586154938\n",
      "Epoch 2192, Loss: 0.18294720351696014, Final Batch Loss: 0.11269331723451614\n",
      "Epoch 2193, Loss: 0.15140850096940994, Final Batch Loss: 0.0711725726723671\n",
      "Epoch 2194, Loss: 0.1438184417784214, Final Batch Loss: 0.08876654505729675\n",
      "Epoch 2195, Loss: 0.1463189646601677, Final Batch Loss: 0.06483279168605804\n",
      "Epoch 2196, Loss: 0.14886858314275742, Final Batch Loss: 0.07614079862833023\n",
      "Epoch 2197, Loss: 0.1606050655245781, Final Batch Loss: 0.07613896578550339\n",
      "Epoch 2198, Loss: 0.1554395779967308, Final Batch Loss: 0.06218818575143814\n",
      "Epoch 2199, Loss: 0.1670144647359848, Final Batch Loss: 0.09444811940193176\n",
      "Epoch 2200, Loss: 0.13284970074892044, Final Batch Loss: 0.05728940665721893\n",
      "Epoch 2201, Loss: 0.12940892949700356, Final Batch Loss: 0.03686666861176491\n",
      "Epoch 2202, Loss: 0.12700622901320457, Final Batch Loss: 0.047619398683309555\n",
      "Epoch 2203, Loss: 0.14741800725460052, Final Batch Loss: 0.0873885303735733\n",
      "Epoch 2204, Loss: 0.15265505015850067, Final Batch Loss: 0.06737280637025833\n",
      "Epoch 2205, Loss: 0.2076135128736496, Final Batch Loss: 0.0904441848397255\n",
      "Epoch 2206, Loss: 0.14190474152565002, Final Batch Loss: 0.0645127221941948\n",
      "Epoch 2207, Loss: 0.15024776756763458, Final Batch Loss: 0.08750937134027481\n",
      "Epoch 2208, Loss: 0.16384949162602425, Final Batch Loss: 0.11850620061159134\n",
      "Epoch 2209, Loss: 0.1648607850074768, Final Batch Loss: 0.09320379793643951\n",
      "Epoch 2210, Loss: 0.11223059520125389, Final Batch Loss: 0.04195331409573555\n",
      "Epoch 2211, Loss: 0.15554696321487427, Final Batch Loss: 0.09382425993680954\n",
      "Epoch 2212, Loss: 0.17968617379665375, Final Batch Loss: 0.0917036384344101\n",
      "Epoch 2213, Loss: 0.1703500896692276, Final Batch Loss: 0.11303206533193588\n",
      "Epoch 2214, Loss: 0.11606467142701149, Final Batch Loss: 0.03401084616780281\n",
      "Epoch 2215, Loss: 0.12674402445554733, Final Batch Loss: 0.051023371517658234\n",
      "Epoch 2216, Loss: 0.167686827480793, Final Batch Loss: 0.09919178485870361\n",
      "Epoch 2217, Loss: 0.17409689724445343, Final Batch Loss: 0.09200958907604218\n",
      "Epoch 2218, Loss: 0.14263903722167015, Final Batch Loss: 0.057677093893289566\n",
      "Epoch 2219, Loss: 0.12934182211756706, Final Batch Loss: 0.04913662001490593\n",
      "Epoch 2220, Loss: 0.1574607565999031, Final Batch Loss: 0.08826972544193268\n",
      "Epoch 2221, Loss: 0.18339087069034576, Final Batch Loss: 0.11717472225427628\n",
      "Epoch 2222, Loss: 0.1651369109749794, Final Batch Loss: 0.09569671005010605\n",
      "Epoch 2223, Loss: 0.13411202281713486, Final Batch Loss: 0.05422256141901016\n",
      "Epoch 2224, Loss: 0.21989567577838898, Final Batch Loss: 0.1500672847032547\n",
      "Epoch 2225, Loss: 0.14478451758623123, Final Batch Loss: 0.09136838465929031\n",
      "Epoch 2226, Loss: 0.1391647346317768, Final Batch Loss: 0.056889262050390244\n",
      "Epoch 2227, Loss: 0.14038056135177612, Final Batch Loss: 0.09229613840579987\n",
      "Epoch 2228, Loss: 0.12552737444639206, Final Batch Loss: 0.03970416635274887\n",
      "Epoch 2229, Loss: 0.14274250715970993, Final Batch Loss: 0.07026537507772446\n",
      "Epoch 2230, Loss: 0.15749456733465195, Final Batch Loss: 0.0767531469464302\n",
      "Epoch 2231, Loss: 0.1549135558307171, Final Batch Loss: 0.05609218403697014\n",
      "Epoch 2232, Loss: 0.1498449370265007, Final Batch Loss: 0.07501765340566635\n",
      "Epoch 2233, Loss: 0.13466890156269073, Final Batch Loss: 0.05869239568710327\n",
      "Epoch 2234, Loss: 0.14476658403873444, Final Batch Loss: 0.0747419223189354\n",
      "Epoch 2235, Loss: 0.13717945665121078, Final Batch Loss: 0.04698339104652405\n",
      "Epoch 2236, Loss: 0.11495783552527428, Final Batch Loss: 0.04759148880839348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2237, Loss: 0.13963859900832176, Final Batch Loss: 0.04477880522608757\n",
      "Epoch 2238, Loss: 0.12167742103338242, Final Batch Loss: 0.053906746208667755\n",
      "Epoch 2239, Loss: 0.15338634699583054, Final Batch Loss: 0.08891928195953369\n",
      "Epoch 2240, Loss: 0.13921382278203964, Final Batch Loss: 0.07551327347755432\n",
      "Epoch 2241, Loss: 0.15445562452077866, Final Batch Loss: 0.088658906519413\n",
      "Epoch 2242, Loss: 0.1481785625219345, Final Batch Loss: 0.04811151325702667\n",
      "Epoch 2243, Loss: 0.15910892933607101, Final Batch Loss: 0.08627641201019287\n",
      "Epoch 2244, Loss: 0.13388608023524284, Final Batch Loss: 0.07768561691045761\n",
      "Epoch 2245, Loss: 0.1376507207751274, Final Batch Loss: 0.08106128126382828\n",
      "Epoch 2246, Loss: 0.15963677316904068, Final Batch Loss: 0.09065048396587372\n",
      "Epoch 2247, Loss: 0.1236584298312664, Final Batch Loss: 0.05183114483952522\n",
      "Epoch 2248, Loss: 0.1327897012233734, Final Batch Loss: 0.061522968113422394\n",
      "Epoch 2249, Loss: 0.1358625292778015, Final Batch Loss: 0.06872778385877609\n",
      "Epoch 2250, Loss: 0.15804729610681534, Final Batch Loss: 0.09972561150789261\n",
      "Epoch 2251, Loss: 0.1824379712343216, Final Batch Loss: 0.11835525184869766\n",
      "Epoch 2252, Loss: 0.23330747336149216, Final Batch Loss: 0.15160632133483887\n",
      "Epoch 2253, Loss: 0.13469209522008896, Final Batch Loss: 0.0721488669514656\n",
      "Epoch 2254, Loss: 0.13666382059454918, Final Batch Loss: 0.06060728803277016\n",
      "Epoch 2255, Loss: 0.1508776918053627, Final Batch Loss: 0.07008296996355057\n",
      "Epoch 2256, Loss: 0.15415405482053757, Final Batch Loss: 0.0750863179564476\n",
      "Epoch 2257, Loss: 0.15882352739572525, Final Batch Loss: 0.09544047713279724\n",
      "Epoch 2258, Loss: 0.1833004653453827, Final Batch Loss: 0.1163116917014122\n",
      "Epoch 2259, Loss: 0.20689523220062256, Final Batch Loss: 0.09874770045280457\n",
      "Epoch 2260, Loss: 0.15959912538528442, Final Batch Loss: 0.08703204244375229\n",
      "Epoch 2261, Loss: 0.15625986456871033, Final Batch Loss: 0.08749787509441376\n",
      "Epoch 2262, Loss: 0.17431654781103134, Final Batch Loss: 0.09987504035234451\n",
      "Epoch 2263, Loss: 0.12970717996358871, Final Batch Loss: 0.06028653681278229\n",
      "Epoch 2264, Loss: 0.17146171629428864, Final Batch Loss: 0.1087852343916893\n",
      "Epoch 2265, Loss: 0.12568075954914093, Final Batch Loss: 0.0529460534453392\n",
      "Epoch 2266, Loss: 0.1383400857448578, Final Batch Loss: 0.06735474616289139\n",
      "Epoch 2267, Loss: 0.1475665420293808, Final Batch Loss: 0.0705224797129631\n",
      "Epoch 2268, Loss: 0.18625302612781525, Final Batch Loss: 0.08818268775939941\n",
      "Epoch 2269, Loss: 0.12726259604096413, Final Batch Loss: 0.03139965608716011\n",
      "Epoch 2270, Loss: 0.16725826263427734, Final Batch Loss: 0.07408822327852249\n",
      "Epoch 2271, Loss: 0.15547281876206398, Final Batch Loss: 0.05595826730132103\n",
      "Epoch 2272, Loss: 0.12014046311378479, Final Batch Loss: 0.04922542721033096\n",
      "Epoch 2273, Loss: 0.136187095195055, Final Batch Loss: 0.05969378724694252\n",
      "Epoch 2274, Loss: 0.1856432929635048, Final Batch Loss: 0.11029238253831863\n",
      "Epoch 2275, Loss: 0.12275558710098267, Final Batch Loss: 0.05548427999019623\n",
      "Epoch 2276, Loss: 0.20174790173768997, Final Batch Loss: 0.13912060856819153\n",
      "Epoch 2277, Loss: 0.13791005313396454, Final Batch Loss: 0.06619955599308014\n",
      "Epoch 2278, Loss: 0.16909412294626236, Final Batch Loss: 0.09105031192302704\n",
      "Epoch 2279, Loss: 0.15388143807649612, Final Batch Loss: 0.07811591029167175\n",
      "Epoch 2280, Loss: 0.15259656310081482, Final Batch Loss: 0.07813700288534164\n",
      "Epoch 2281, Loss: 0.11601635441184044, Final Batch Loss: 0.048969816416502\n",
      "Epoch 2282, Loss: 0.10723943263292313, Final Batch Loss: 0.033361583948135376\n",
      "Epoch 2283, Loss: 0.15635383501648903, Final Batch Loss: 0.09919556975364685\n",
      "Epoch 2284, Loss: 0.14992393553256989, Final Batch Loss: 0.07381850481033325\n",
      "Epoch 2285, Loss: 0.11899423599243164, Final Batch Loss: 0.05222056061029434\n",
      "Epoch 2286, Loss: 0.14020952954888344, Final Batch Loss: 0.06246624514460564\n",
      "Epoch 2287, Loss: 0.150397177785635, Final Batch Loss: 0.09945285320281982\n",
      "Epoch 2288, Loss: 0.1556013822555542, Final Batch Loss: 0.08357487618923187\n",
      "Epoch 2289, Loss: 0.13901477307081223, Final Batch Loss: 0.051121801137924194\n",
      "Epoch 2290, Loss: 0.14482251182198524, Final Batch Loss: 0.08370619267225266\n",
      "Epoch 2291, Loss: 0.1496962308883667, Final Batch Loss: 0.08909893780946732\n",
      "Epoch 2292, Loss: 0.13732459768652916, Final Batch Loss: 0.05782811716198921\n",
      "Epoch 2293, Loss: 0.15191968902945518, Final Batch Loss: 0.09998831897974014\n",
      "Epoch 2294, Loss: 0.1196882389485836, Final Batch Loss: 0.06331442296504974\n",
      "Epoch 2295, Loss: 0.12131332606077194, Final Batch Loss: 0.057941243052482605\n",
      "Epoch 2296, Loss: 0.19075552374124527, Final Batch Loss: 0.10534636676311493\n",
      "Epoch 2297, Loss: 0.239833764731884, Final Batch Loss: 0.15842203795909882\n",
      "Epoch 2298, Loss: 0.15639538317918777, Final Batch Loss: 0.0906604751944542\n",
      "Epoch 2299, Loss: 0.14379431679844856, Final Batch Loss: 0.08137799799442291\n",
      "Epoch 2300, Loss: 0.16167844831943512, Final Batch Loss: 0.08236484974622726\n",
      "Epoch 2301, Loss: 0.14073452726006508, Final Batch Loss: 0.08238592743873596\n",
      "Epoch 2302, Loss: 0.1454625129699707, Final Batch Loss: 0.07244183123111725\n",
      "Epoch 2303, Loss: 0.16487989574670792, Final Batch Loss: 0.09919197857379913\n",
      "Epoch 2304, Loss: 0.1839827299118042, Final Batch Loss: 0.11805804073810577\n",
      "Epoch 2305, Loss: 0.1769452840089798, Final Batch Loss: 0.09878222644329071\n",
      "Epoch 2306, Loss: 0.17973073571920395, Final Batch Loss: 0.10248356312513351\n",
      "Epoch 2307, Loss: 0.1618095561861992, Final Batch Loss: 0.06363850831985474\n",
      "Epoch 2308, Loss: 0.12780850753188133, Final Batch Loss: 0.050211351364851\n",
      "Epoch 2309, Loss: 0.14162609726190567, Final Batch Loss: 0.07261955738067627\n",
      "Epoch 2310, Loss: 0.17310474812984467, Final Batch Loss: 0.09713011980056763\n",
      "Epoch 2311, Loss: 0.14159280806779861, Final Batch Loss: 0.0823366791009903\n",
      "Epoch 2312, Loss: 0.17079616338014603, Final Batch Loss: 0.07990896701812744\n",
      "Epoch 2313, Loss: 0.1601480096578598, Final Batch Loss: 0.07886625826358795\n",
      "Epoch 2314, Loss: 0.1508341208100319, Final Batch Loss: 0.06915680319070816\n",
      "Epoch 2315, Loss: 0.1516823172569275, Final Batch Loss: 0.09009427577257156\n",
      "Epoch 2316, Loss: 0.14226988703012466, Final Batch Loss: 0.06197206676006317\n",
      "Epoch 2317, Loss: 0.1250506043434143, Final Batch Loss: 0.050454944372177124\n",
      "Epoch 2318, Loss: 0.14681978523731232, Final Batch Loss: 0.07738614082336426\n",
      "Epoch 2319, Loss: 0.14766889438033104, Final Batch Loss: 0.05777011439204216\n",
      "Epoch 2320, Loss: 0.14384103938937187, Final Batch Loss: 0.08603641390800476\n",
      "Epoch 2321, Loss: 0.12461769208312035, Final Batch Loss: 0.050124313682317734\n",
      "Epoch 2322, Loss: 0.14620937034487724, Final Batch Loss: 0.04885805770754814\n",
      "Epoch 2323, Loss: 0.10496199503540993, Final Batch Loss: 0.03634997084736824\n",
      "Epoch 2324, Loss: 0.15803764387965202, Final Batch Loss: 0.09626710414886475\n",
      "Epoch 2325, Loss: 0.14256396889686584, Final Batch Loss: 0.07330425083637238\n",
      "Epoch 2326, Loss: 0.14037379994988441, Final Batch Loss: 0.06057463213801384\n",
      "Epoch 2327, Loss: 0.12510256469249725, Final Batch Loss: 0.05496300011873245\n",
      "Epoch 2328, Loss: 0.16550380364060402, Final Batch Loss: 0.10895977169275284\n",
      "Epoch 2329, Loss: 0.13750925660133362, Final Batch Loss: 0.06778645515441895\n",
      "Epoch 2330, Loss: 0.11663957312703133, Final Batch Loss: 0.03302304074168205\n",
      "Epoch 2331, Loss: 0.1392613686621189, Final Batch Loss: 0.07734593749046326\n",
      "Epoch 2332, Loss: 0.13326483964920044, Final Batch Loss: 0.05756682902574539\n",
      "Epoch 2333, Loss: 0.14320194721221924, Final Batch Loss: 0.04052262008190155\n",
      "Epoch 2334, Loss: 0.15431112796068192, Final Batch Loss: 0.090187668800354\n",
      "Epoch 2335, Loss: 0.16247893124818802, Final Batch Loss: 0.07751426100730896\n",
      "Epoch 2336, Loss: 0.13180508837103844, Final Batch Loss: 0.058162715286016464\n",
      "Epoch 2337, Loss: 0.13482453674077988, Final Batch Loss: 0.05874641239643097\n",
      "Epoch 2338, Loss: 0.16840939968824387, Final Batch Loss: 0.09050972014665604\n",
      "Epoch 2339, Loss: 0.11579148471355438, Final Batch Loss: 0.05581638216972351\n",
      "Epoch 2340, Loss: 0.11652376502752304, Final Batch Loss: 0.059709351509809494\n",
      "Epoch 2341, Loss: 0.11809108033776283, Final Batch Loss: 0.04939683899283409\n",
      "Epoch 2342, Loss: 0.13486285135149956, Final Batch Loss: 0.060575563460588455\n",
      "Epoch 2343, Loss: 0.15514014661312103, Final Batch Loss: 0.0680331140756607\n",
      "Epoch 2344, Loss: 0.1309545673429966, Final Batch Loss: 0.07485232502222061\n",
      "Epoch 2345, Loss: 0.13624804466962814, Final Batch Loss: 0.08814381808042526\n",
      "Epoch 2346, Loss: 0.1305030733346939, Final Batch Loss: 0.03871358186006546\n",
      "Epoch 2347, Loss: 0.11623015999794006, Final Batch Loss: 0.04780036211013794\n",
      "Epoch 2348, Loss: 0.13008785992860794, Final Batch Loss: 0.04541250318288803\n",
      "Epoch 2349, Loss: 0.1613999828696251, Final Batch Loss: 0.09559020400047302\n",
      "Epoch 2350, Loss: 0.12753992155194283, Final Batch Loss: 0.06816230714321136\n",
      "Epoch 2351, Loss: 0.14815498888492584, Final Batch Loss: 0.07136161625385284\n",
      "Epoch 2352, Loss: 0.1446767821907997, Final Batch Loss: 0.07643212378025055\n",
      "Epoch 2353, Loss: 0.13063521310687065, Final Batch Loss: 0.05710148438811302\n",
      "Epoch 2354, Loss: 0.19352485984563828, Final Batch Loss: 0.07354514300823212\n",
      "Epoch 2355, Loss: 0.14612986892461777, Final Batch Loss: 0.06501214951276779\n",
      "Epoch 2356, Loss: 0.12975668162107468, Final Batch Loss: 0.06284627318382263\n",
      "Epoch 2357, Loss: 0.11703803390264511, Final Batch Loss: 0.04907508194446564\n",
      "Epoch 2358, Loss: 0.13597343489527702, Final Batch Loss: 0.044034551829099655\n",
      "Epoch 2359, Loss: 0.14616111665964127, Final Batch Loss: 0.06469061225652695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2360, Loss: 0.20028404146432877, Final Batch Loss: 0.11330430209636688\n",
      "Epoch 2361, Loss: 0.15277646854519844, Final Batch Loss: 0.0993998795747757\n",
      "Epoch 2362, Loss: 0.18284115940332413, Final Batch Loss: 0.1202268972992897\n",
      "Epoch 2363, Loss: 0.17523598670959473, Final Batch Loss: 0.08890265226364136\n",
      "Epoch 2364, Loss: 0.12871699035167694, Final Batch Loss: 0.0734061747789383\n",
      "Epoch 2365, Loss: 0.15804008394479752, Final Batch Loss: 0.09036361426115036\n",
      "Epoch 2366, Loss: 0.15642892196774483, Final Batch Loss: 0.04755918309092522\n",
      "Epoch 2367, Loss: 0.13949057459831238, Final Batch Loss: 0.05737566202878952\n",
      "Epoch 2368, Loss: 0.14196238294243813, Final Batch Loss: 0.09045730531215668\n",
      "Epoch 2369, Loss: 0.15136516094207764, Final Batch Loss: 0.08074801415205002\n",
      "Epoch 2370, Loss: 0.17005325853824615, Final Batch Loss: 0.08057484775781631\n",
      "Epoch 2371, Loss: 0.12807891890406609, Final Batch Loss: 0.06670539081096649\n",
      "Epoch 2372, Loss: 0.2972432076931, Final Batch Loss: 0.20903456211090088\n",
      "Epoch 2373, Loss: 0.21079321950674057, Final Batch Loss: 0.06305720657110214\n",
      "Epoch 2374, Loss: 0.10112402215600014, Final Batch Loss: 0.03920523449778557\n",
      "Epoch 2375, Loss: 0.19375739246606827, Final Batch Loss: 0.1175520047545433\n",
      "Epoch 2376, Loss: 0.12460599839687347, Final Batch Loss: 0.0410035103559494\n",
      "Epoch 2377, Loss: 0.18632864579558372, Final Batch Loss: 0.0561048649251461\n",
      "Epoch 2378, Loss: 0.15412355959415436, Final Batch Loss: 0.06311261653900146\n",
      "Epoch 2379, Loss: 0.13588039577007294, Final Batch Loss: 0.06581912189722061\n",
      "Epoch 2380, Loss: 0.1493985280394554, Final Batch Loss: 0.0797140970826149\n",
      "Epoch 2381, Loss: 0.1331327110528946, Final Batch Loss: 0.04972217231988907\n",
      "Epoch 2382, Loss: 0.17665620148181915, Final Batch Loss: 0.10243971645832062\n",
      "Epoch 2383, Loss: 0.12718113884329796, Final Batch Loss: 0.04719546064734459\n",
      "Epoch 2384, Loss: 0.15341095626354218, Final Batch Loss: 0.09959901124238968\n",
      "Epoch 2385, Loss: 0.1463521383702755, Final Batch Loss: 0.06226598843932152\n",
      "Epoch 2386, Loss: 0.173044815659523, Final Batch Loss: 0.08426491171121597\n",
      "Epoch 2387, Loss: 0.14099105447530746, Final Batch Loss: 0.07741837203502655\n",
      "Epoch 2388, Loss: 0.1485021524131298, Final Batch Loss: 0.09643471986055374\n",
      "Epoch 2389, Loss: 0.17518524080514908, Final Batch Loss: 0.07718703150749207\n",
      "Epoch 2390, Loss: 0.15449796244502068, Final Batch Loss: 0.09441737085580826\n",
      "Epoch 2391, Loss: 0.15289926528930664, Final Batch Loss: 0.08691281080245972\n",
      "Epoch 2392, Loss: 0.13115373998880386, Final Batch Loss: 0.06610063463449478\n",
      "Epoch 2393, Loss: 0.17578771710395813, Final Batch Loss: 0.0776936262845993\n",
      "Epoch 2394, Loss: 0.1716286614537239, Final Batch Loss: 0.08921321481466293\n",
      "Epoch 2395, Loss: 0.15618757158517838, Final Batch Loss: 0.07207409292459488\n",
      "Epoch 2396, Loss: 0.15920303761959076, Final Batch Loss: 0.0885167345404625\n",
      "Epoch 2397, Loss: 0.13691341131925583, Final Batch Loss: 0.06892161071300507\n",
      "Epoch 2398, Loss: 0.12401348352432251, Final Batch Loss: 0.03125172108411789\n",
      "Epoch 2399, Loss: 0.12647869810461998, Final Batch Loss: 0.057052236050367355\n",
      "Epoch 2400, Loss: 0.09339240193367004, Final Batch Loss: 0.028993770480155945\n",
      "Epoch 2401, Loss: 0.15671422332525253, Final Batch Loss: 0.08336013555526733\n",
      "Epoch 2402, Loss: 0.15209535136818886, Final Batch Loss: 0.08971381187438965\n",
      "Epoch 2403, Loss: 0.1264415979385376, Final Batch Loss: 0.0553496778011322\n",
      "Epoch 2404, Loss: 0.1765214018523693, Final Batch Loss: 0.13649976253509521\n",
      "Epoch 2405, Loss: 0.13589897379279137, Final Batch Loss: 0.06054520234465599\n",
      "Epoch 2406, Loss: 0.16720081120729446, Final Batch Loss: 0.07665203511714935\n",
      "Epoch 2407, Loss: 0.16925765573978424, Final Batch Loss: 0.09369000792503357\n",
      "Epoch 2408, Loss: 0.12676658108830452, Final Batch Loss: 0.059813689440488815\n",
      "Epoch 2409, Loss: 0.12606073915958405, Final Batch Loss: 0.06960844248533249\n",
      "Epoch 2410, Loss: 0.15798170119524002, Final Batch Loss: 0.07619590312242508\n",
      "Epoch 2411, Loss: 0.15121778473258018, Final Batch Loss: 0.09042967855930328\n",
      "Epoch 2412, Loss: 0.14652202650904655, Final Batch Loss: 0.08618819713592529\n",
      "Epoch 2413, Loss: 0.18116595596075058, Final Batch Loss: 0.06522681564092636\n",
      "Epoch 2414, Loss: 0.1300315111875534, Final Batch Loss: 0.06825537979602814\n",
      "Epoch 2415, Loss: 0.17934627830982208, Final Batch Loss: 0.10621745884418488\n",
      "Epoch 2416, Loss: 0.165109284222126, Final Batch Loss: 0.10904877632856369\n",
      "Epoch 2417, Loss: 0.13866343349218369, Final Batch Loss: 0.06053507328033447\n",
      "Epoch 2418, Loss: 0.11566172912716866, Final Batch Loss: 0.03604656830430031\n",
      "Epoch 2419, Loss: 0.2523088976740837, Final Batch Loss: 0.2010178565979004\n",
      "Epoch 2420, Loss: 0.11917845904827118, Final Batch Loss: 0.05410289019346237\n",
      "Epoch 2421, Loss: 0.11681966111063957, Final Batch Loss: 0.05941637232899666\n",
      "Epoch 2422, Loss: 0.14273008704185486, Final Batch Loss: 0.0817372277379036\n",
      "Epoch 2423, Loss: 0.11787793040275574, Final Batch Loss: 0.057659149169921875\n",
      "Epoch 2424, Loss: 0.12060678377747536, Final Batch Loss: 0.04699413850903511\n",
      "Epoch 2425, Loss: 0.13123877719044685, Final Batch Loss: 0.059430088847875595\n",
      "Epoch 2426, Loss: 0.14708907902240753, Final Batch Loss: 0.07268337905406952\n",
      "Epoch 2427, Loss: 0.14509271085262299, Final Batch Loss: 0.08147221803665161\n",
      "Epoch 2428, Loss: 0.13439105451107025, Final Batch Loss: 0.06956367939710617\n",
      "Epoch 2429, Loss: 0.19808796793222427, Final Batch Loss: 0.12186587601900101\n",
      "Epoch 2430, Loss: 0.14475645124912262, Final Batch Loss: 0.05228722095489502\n",
      "Epoch 2431, Loss: 0.13123350962996483, Final Batch Loss: 0.06064185872673988\n",
      "Epoch 2432, Loss: 0.11823879554867744, Final Batch Loss: 0.06627040356397629\n",
      "Epoch 2433, Loss: 0.1484363079071045, Final Batch Loss: 0.0843210369348526\n",
      "Epoch 2434, Loss: 0.1839362271130085, Final Batch Loss: 0.14292709529399872\n",
      "Epoch 2435, Loss: 0.14727749675512314, Final Batch Loss: 0.07346677035093307\n",
      "Epoch 2436, Loss: 0.1228330209851265, Final Batch Loss: 0.04184038192033768\n",
      "Epoch 2437, Loss: 0.15330567955970764, Final Batch Loss: 0.0828666016459465\n",
      "Epoch 2438, Loss: 0.13116709887981415, Final Batch Loss: 0.06791241466999054\n",
      "Epoch 2439, Loss: 0.13177401572465897, Final Batch Loss: 0.07164279371500015\n",
      "Epoch 2440, Loss: 0.142494797706604, Final Batch Loss: 0.08515175431966782\n",
      "Epoch 2441, Loss: 0.12630244344472885, Final Batch Loss: 0.06791839003562927\n",
      "Epoch 2442, Loss: 0.15711088478565216, Final Batch Loss: 0.10419326275587082\n",
      "Epoch 2443, Loss: 0.1377934254705906, Final Batch Loss: 0.08035603910684586\n",
      "Epoch 2444, Loss: 0.13766653835773468, Final Batch Loss: 0.0605931282043457\n",
      "Epoch 2445, Loss: 0.1511159911751747, Final Batch Loss: 0.08807560801506042\n",
      "Epoch 2446, Loss: 0.1258813999593258, Final Batch Loss: 0.036519791930913925\n",
      "Epoch 2447, Loss: 0.14818517863750458, Final Batch Loss: 0.08225295692682266\n",
      "Epoch 2448, Loss: 0.12054888531565666, Final Batch Loss: 0.05787167325615883\n",
      "Epoch 2449, Loss: 0.10209277272224426, Final Batch Loss: 0.04920559003949165\n",
      "Epoch 2450, Loss: 0.18649426847696304, Final Batch Loss: 0.07673755288124084\n",
      "Epoch 2451, Loss: 0.15539495646953583, Final Batch Loss: 0.0834021344780922\n",
      "Epoch 2452, Loss: 0.1253778152167797, Final Batch Loss: 0.06951586902141571\n",
      "Epoch 2453, Loss: 0.1739005744457245, Final Batch Loss: 0.09502746164798737\n",
      "Epoch 2454, Loss: 0.11178534105420113, Final Batch Loss: 0.05080626159906387\n",
      "Epoch 2455, Loss: 0.11791963130235672, Final Batch Loss: 0.06512404978275299\n",
      "Epoch 2456, Loss: 0.2155623659491539, Final Batch Loss: 0.053765587508678436\n",
      "Epoch 2457, Loss: 0.13430310413241386, Final Batch Loss: 0.059143636375665665\n",
      "Epoch 2458, Loss: 0.12683513015508652, Final Batch Loss: 0.05341252684593201\n",
      "Epoch 2459, Loss: 0.12252170220017433, Final Batch Loss: 0.05830921605229378\n",
      "Epoch 2460, Loss: 0.13186948746442795, Final Batch Loss: 0.06682872027158737\n",
      "Epoch 2461, Loss: 0.1184757724404335, Final Batch Loss: 0.03843808174133301\n",
      "Epoch 2462, Loss: 0.11936356127262115, Final Batch Loss: 0.058675773441791534\n",
      "Epoch 2463, Loss: 0.1509871780872345, Final Batch Loss: 0.07859393954277039\n",
      "Epoch 2464, Loss: 0.11102474853396416, Final Batch Loss: 0.029347393661737442\n",
      "Epoch 2465, Loss: 0.12799197062849998, Final Batch Loss: 0.07763569802045822\n",
      "Epoch 2466, Loss: 0.13203568011522293, Final Batch Loss: 0.05425059795379639\n",
      "Epoch 2467, Loss: 0.1740008443593979, Final Batch Loss: 0.060506902635097504\n",
      "Epoch 2468, Loss: 0.15257124230265617, Final Batch Loss: 0.10028371214866638\n",
      "Epoch 2469, Loss: 0.15550583600997925, Final Batch Loss: 0.07746218144893646\n",
      "Epoch 2470, Loss: 0.13680411130189896, Final Batch Loss: 0.06817872077226639\n",
      "Epoch 2471, Loss: 0.12966232001781464, Final Batch Loss: 0.06780808418989182\n",
      "Epoch 2472, Loss: 0.16775181144475937, Final Batch Loss: 0.08112616837024689\n",
      "Epoch 2473, Loss: 0.14778711646795273, Final Batch Loss: 0.10138432681560516\n",
      "Epoch 2474, Loss: 0.23082195222377777, Final Batch Loss: 0.17277184128761292\n",
      "Epoch 2475, Loss: 0.11066213250160217, Final Batch Loss: 0.03553456813097\n",
      "Epoch 2476, Loss: 0.16771188378334045, Final Batch Loss: 0.11666461825370789\n",
      "Epoch 2477, Loss: 0.1343592219054699, Final Batch Loss: 0.07214856147766113\n",
      "Epoch 2478, Loss: 0.1475660353899002, Final Batch Loss: 0.07297726720571518\n",
      "Epoch 2479, Loss: 0.11066120490431786, Final Batch Loss: 0.05998518690466881\n",
      "Epoch 2480, Loss: 0.133441474288702, Final Batch Loss: 0.0578877218067646\n",
      "Epoch 2481, Loss: 0.12475959956645966, Final Batch Loss: 0.053183287382125854\n",
      "Epoch 2482, Loss: 0.1578172706067562, Final Batch Loss: 0.10283074527978897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2483, Loss: 0.12166678532958031, Final Batch Loss: 0.06721819192171097\n",
      "Epoch 2484, Loss: 0.14255977421998978, Final Batch Loss: 0.09278453886508942\n",
      "Epoch 2485, Loss: 0.14569927006959915, Final Batch Loss: 0.08045512437820435\n",
      "Epoch 2486, Loss: 0.1554940566420555, Final Batch Loss: 0.0969717875123024\n",
      "Epoch 2487, Loss: 0.12964176386594772, Final Batch Loss: 0.05444516986608505\n",
      "Epoch 2488, Loss: 0.16145357489585876, Final Batch Loss: 0.09042252600193024\n",
      "Epoch 2489, Loss: 0.1456243172287941, Final Batch Loss: 0.07538503408432007\n",
      "Epoch 2490, Loss: 0.12276765331625938, Final Batch Loss: 0.044829610735177994\n",
      "Epoch 2491, Loss: 0.10871374793350697, Final Batch Loss: 0.03027539886534214\n",
      "Epoch 2492, Loss: 0.17362374067306519, Final Batch Loss: 0.09196697920560837\n",
      "Epoch 2493, Loss: 0.14426328986883163, Final Batch Loss: 0.0760364979505539\n",
      "Epoch 2494, Loss: 0.18923678249120712, Final Batch Loss: 0.09555381536483765\n",
      "Epoch 2495, Loss: 0.19217002391815186, Final Batch Loss: 0.09898587316274643\n",
      "Epoch 2496, Loss: 0.12144403532147408, Final Batch Loss: 0.05450276657938957\n",
      "Epoch 2497, Loss: 0.12706253305077553, Final Batch Loss: 0.06650098413228989\n",
      "Epoch 2498, Loss: 0.14138109236955643, Final Batch Loss: 0.06933922320604324\n",
      "Epoch 2499, Loss: 0.12616366520524025, Final Batch Loss: 0.0486409030854702\n",
      "Epoch 2500, Loss: 0.16527506709098816, Final Batch Loss: 0.08569376915693283\n",
      "Epoch 2501, Loss: 0.11681115627288818, Final Batch Loss: 0.05016103386878967\n",
      "Epoch 2502, Loss: 0.12264177203178406, Final Batch Loss: 0.05318078398704529\n",
      "Epoch 2503, Loss: 0.14134611189365387, Final Batch Loss: 0.07323410362005234\n",
      "Epoch 2504, Loss: 0.11381438001990318, Final Batch Loss: 0.04154429957270622\n",
      "Epoch 2505, Loss: 0.14155889675021172, Final Batch Loss: 0.08667663484811783\n",
      "Epoch 2506, Loss: 0.12251406535506248, Final Batch Loss: 0.056981999427080154\n",
      "Epoch 2507, Loss: 0.2015475109219551, Final Batch Loss: 0.12058932334184647\n",
      "Epoch 2508, Loss: 0.12631744891405106, Final Batch Loss: 0.06839070469141006\n",
      "Epoch 2509, Loss: 0.11621219292283058, Final Batch Loss: 0.061222873628139496\n",
      "Epoch 2510, Loss: 0.16448074579238892, Final Batch Loss: 0.08520987629890442\n",
      "Epoch 2511, Loss: 0.1590918004512787, Final Batch Loss: 0.08827681094408035\n",
      "Epoch 2512, Loss: 0.19048427790403366, Final Batch Loss: 0.12450563907623291\n",
      "Epoch 2513, Loss: 0.24800359830260277, Final Batch Loss: 0.18975310027599335\n",
      "Epoch 2514, Loss: 0.12819843739271164, Final Batch Loss: 0.04544515162706375\n",
      "Epoch 2515, Loss: 0.20331086963415146, Final Batch Loss: 0.09680432826280594\n",
      "Epoch 2516, Loss: 0.1552218534052372, Final Batch Loss: 0.056360889226198196\n",
      "Epoch 2517, Loss: 0.1488042138516903, Final Batch Loss: 0.03711962327361107\n",
      "Epoch 2518, Loss: 0.18442580103874207, Final Batch Loss: 0.09202397614717484\n",
      "Epoch 2519, Loss: 0.14080260694026947, Final Batch Loss: 0.05388660728931427\n",
      "Epoch 2520, Loss: 0.16757550090551376, Final Batch Loss: 0.10962914675474167\n",
      "Epoch 2521, Loss: 0.15740514546632767, Final Batch Loss: 0.06958524137735367\n",
      "Epoch 2522, Loss: 0.22537528723478317, Final Batch Loss: 0.10558025538921356\n",
      "Epoch 2523, Loss: 0.15630319342017174, Final Batch Loss: 0.09829006344079971\n",
      "Epoch 2524, Loss: 0.13235421478748322, Final Batch Loss: 0.06450514495372772\n",
      "Epoch 2525, Loss: 0.15611395239830017, Final Batch Loss: 0.10191914439201355\n",
      "Epoch 2526, Loss: 0.16966572776436806, Final Batch Loss: 0.11440280079841614\n",
      "Epoch 2527, Loss: 0.1268586963415146, Final Batch Loss: 0.06346217542886734\n",
      "Epoch 2528, Loss: 0.16352003812789917, Final Batch Loss: 0.08941355347633362\n",
      "Epoch 2529, Loss: 0.14019985124468803, Final Batch Loss: 0.05557647719979286\n",
      "Epoch 2530, Loss: 0.13575230538845062, Final Batch Loss: 0.07454875111579895\n",
      "Epoch 2531, Loss: 0.14109943062067032, Final Batch Loss: 0.06987161189317703\n",
      "Epoch 2532, Loss: 0.14323218166828156, Final Batch Loss: 0.07143110036849976\n",
      "Epoch 2533, Loss: 0.1630789451301098, Final Batch Loss: 0.1026555746793747\n",
      "Epoch 2534, Loss: 0.1380590796470642, Final Batch Loss: 0.07175037264823914\n",
      "Epoch 2535, Loss: 0.1272328794002533, Final Batch Loss: 0.06151929497718811\n",
      "Epoch 2536, Loss: 0.1355515420436859, Final Batch Loss: 0.061767272651195526\n",
      "Epoch 2537, Loss: 0.12046398967504501, Final Batch Loss: 0.05486340820789337\n",
      "Epoch 2538, Loss: 0.15987657755613327, Final Batch Loss: 0.08692223578691483\n",
      "Epoch 2539, Loss: 0.1602548286318779, Final Batch Loss: 0.08942484855651855\n",
      "Epoch 2540, Loss: 0.10228169709444046, Final Batch Loss: 0.03275787830352783\n",
      "Epoch 2541, Loss: 0.1664828434586525, Final Batch Loss: 0.08741810917854309\n",
      "Epoch 2542, Loss: 0.12634676694869995, Final Batch Loss: 0.056061699986457825\n",
      "Epoch 2543, Loss: 0.11876320093870163, Final Batch Loss: 0.056452371180057526\n",
      "Epoch 2544, Loss: 0.3554653897881508, Final Batch Loss: 0.2769189774990082\n",
      "Epoch 2545, Loss: 0.1285066269338131, Final Batch Loss: 0.08170248568058014\n",
      "Epoch 2546, Loss: 0.12254799902439117, Final Batch Loss: 0.042921751737594604\n",
      "Epoch 2547, Loss: 0.15460697561502457, Final Batch Loss: 0.076421357691288\n",
      "Epoch 2548, Loss: 0.12161629274487495, Final Batch Loss: 0.04333500191569328\n",
      "Epoch 2549, Loss: 0.1545739397406578, Final Batch Loss: 0.05777745693922043\n",
      "Epoch 2550, Loss: 0.15824954211711884, Final Batch Loss: 0.0854664295911789\n",
      "Epoch 2551, Loss: 0.11550656706094742, Final Batch Loss: 0.04456757754087448\n",
      "Epoch 2552, Loss: 0.1731826812028885, Final Batch Loss: 0.111690454185009\n",
      "Epoch 2553, Loss: 0.15055672824382782, Final Batch Loss: 0.07888482511043549\n",
      "Epoch 2554, Loss: 0.124650489538908, Final Batch Loss: 0.05738448724150658\n",
      "Epoch 2555, Loss: 0.11961707100272179, Final Batch Loss: 0.04681970551609993\n",
      "Epoch 2556, Loss: 0.12649355456233025, Final Batch Loss: 0.06503685563802719\n",
      "Epoch 2557, Loss: 0.1242174543440342, Final Batch Loss: 0.06622801721096039\n",
      "Epoch 2558, Loss: 0.11723022535443306, Final Batch Loss: 0.06145166978240013\n",
      "Epoch 2559, Loss: 0.11432942375540733, Final Batch Loss: 0.04638782516121864\n",
      "Epoch 2560, Loss: 0.16815894842147827, Final Batch Loss: 0.0943455845117569\n",
      "Epoch 2561, Loss: 0.240443404763937, Final Batch Loss: 0.18128539621829987\n",
      "Epoch 2562, Loss: 0.13735578581690788, Final Batch Loss: 0.07632312178611755\n",
      "Epoch 2563, Loss: 0.15462960302829742, Final Batch Loss: 0.061727963387966156\n",
      "Epoch 2564, Loss: 0.17742277681827545, Final Batch Loss: 0.11108061671257019\n",
      "Epoch 2565, Loss: 0.14398257434368134, Final Batch Loss: 0.07441164553165436\n",
      "Epoch 2566, Loss: 0.1498088240623474, Final Batch Loss: 0.06451096385717392\n",
      "Epoch 2567, Loss: 0.18224751204252243, Final Batch Loss: 0.08518936485052109\n",
      "Epoch 2568, Loss: 0.15433897078037262, Final Batch Loss: 0.09357859939336777\n",
      "Epoch 2569, Loss: 0.1219605952501297, Final Batch Loss: 0.052253931760787964\n",
      "Epoch 2570, Loss: 0.1041401382535696, Final Batch Loss: 0.02211627922952175\n",
      "Epoch 2571, Loss: 0.13459257036447525, Final Batch Loss: 0.04564376175403595\n",
      "Epoch 2572, Loss: 0.15090347826480865, Final Batch Loss: 0.08940928429365158\n",
      "Epoch 2573, Loss: 0.10918506979942322, Final Batch Loss: 0.049360718578100204\n",
      "Epoch 2574, Loss: 0.10950809717178345, Final Batch Loss: 0.032406002283096313\n",
      "Epoch 2575, Loss: 0.1540083810687065, Final Batch Loss: 0.04752446711063385\n",
      "Epoch 2576, Loss: 0.14381980895996094, Final Batch Loss: 0.08216401189565659\n",
      "Epoch 2577, Loss: 0.1464436948299408, Final Batch Loss: 0.06631756573915482\n",
      "Epoch 2578, Loss: 0.1140715628862381, Final Batch Loss: 0.048355452716350555\n",
      "Epoch 2579, Loss: 0.11916005611419678, Final Batch Loss: 0.04244912415742874\n",
      "Epoch 2580, Loss: 0.19198545068502426, Final Batch Loss: 0.10353367030620575\n",
      "Epoch 2581, Loss: 0.11805693060159683, Final Batch Loss: 0.055322691798210144\n",
      "Epoch 2582, Loss: 0.130437184125185, Final Batch Loss: 0.0469011627137661\n",
      "Epoch 2583, Loss: 0.10562841035425663, Final Batch Loss: 0.022692473605275154\n",
      "Epoch 2584, Loss: 0.12740876898169518, Final Batch Loss: 0.05704266205430031\n",
      "Epoch 2585, Loss: 0.12130892276763916, Final Batch Loss: 0.0649527981877327\n",
      "Epoch 2586, Loss: 0.1384405791759491, Final Batch Loss: 0.08395755290985107\n",
      "Epoch 2587, Loss: 0.09458606503903866, Final Batch Loss: 0.027501201257109642\n",
      "Epoch 2588, Loss: 0.10683011263608932, Final Batch Loss: 0.056174542754888535\n",
      "Epoch 2589, Loss: 0.13054383173584938, Final Batch Loss: 0.060261670500040054\n",
      "Epoch 2590, Loss: 0.10533038154244423, Final Batch Loss: 0.03895063325762749\n",
      "Epoch 2591, Loss: 0.14791806042194366, Final Batch Loss: 0.07197611778974533\n",
      "Epoch 2592, Loss: 0.11774224042892456, Final Batch Loss: 0.06750891357660294\n",
      "Epoch 2593, Loss: 0.10469949245452881, Final Batch Loss: 0.043234050273895264\n",
      "Epoch 2594, Loss: 0.12413454055786133, Final Batch Loss: 0.06200191378593445\n",
      "Epoch 2595, Loss: 0.12366670742630959, Final Batch Loss: 0.05886643007397652\n",
      "Epoch 2596, Loss: 0.11816531792283058, Final Batch Loss: 0.052720945328474045\n",
      "Epoch 2597, Loss: 0.12480270490050316, Final Batch Loss: 0.05307546630501747\n",
      "Epoch 2598, Loss: 0.151742085814476, Final Batch Loss: 0.07292366772890091\n",
      "Epoch 2599, Loss: 0.14352146536111832, Final Batch Loss: 0.08435642719268799\n",
      "Epoch 2600, Loss: 0.15408668667078018, Final Batch Loss: 0.07416575402021408\n",
      "Epoch 2601, Loss: 0.1617477610707283, Final Batch Loss: 0.07070554047822952\n",
      "Epoch 2602, Loss: 0.15188883244991302, Final Batch Loss: 0.0870012417435646\n",
      "Epoch 2603, Loss: 0.12551503628492355, Final Batch Loss: 0.06725423038005829\n",
      "Epoch 2604, Loss: 0.1376904882490635, Final Batch Loss: 0.07550353556871414\n",
      "Epoch 2605, Loss: 0.13914934173226357, Final Batch Loss: 0.08303843438625336\n",
      "Epoch 2606, Loss: 0.14707794040441513, Final Batch Loss: 0.07200528681278229\n",
      "Epoch 2607, Loss: 0.13908114284276962, Final Batch Loss: 0.08628299832344055\n",
      "Epoch 2608, Loss: 0.12886248156428337, Final Batch Loss: 0.05688554421067238\n",
      "Epoch 2609, Loss: 0.14880695939064026, Final Batch Loss: 0.08019105345010757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2610, Loss: 0.14131077378988266, Final Batch Loss: 0.08889786899089813\n",
      "Epoch 2611, Loss: 0.13015875220298767, Final Batch Loss: 0.07322563230991364\n",
      "Epoch 2612, Loss: 0.14801697805523872, Final Batch Loss: 0.06183500960469246\n",
      "Epoch 2613, Loss: 0.13839587569236755, Final Batch Loss: 0.06596842408180237\n",
      "Epoch 2614, Loss: 0.13557719439268112, Final Batch Loss: 0.06796975433826447\n",
      "Epoch 2615, Loss: 0.14033840596675873, Final Batch Loss: 0.058716773986816406\n",
      "Epoch 2616, Loss: 0.2724279835820198, Final Batch Loss: 0.1981515735387802\n",
      "Epoch 2617, Loss: 0.11330344527959824, Final Batch Loss: 0.04888557642698288\n",
      "Epoch 2618, Loss: 0.14001059159636497, Final Batch Loss: 0.052620332688093185\n",
      "Epoch 2619, Loss: 0.1244128905236721, Final Batch Loss: 0.05165519937872887\n",
      "Epoch 2620, Loss: 0.10785102471709251, Final Batch Loss: 0.04445359483361244\n",
      "Epoch 2621, Loss: 0.12145250663161278, Final Batch Loss: 0.06870699673891068\n",
      "Epoch 2622, Loss: 0.15517788380384445, Final Batch Loss: 0.08239912986755371\n",
      "Epoch 2623, Loss: 0.14879032969474792, Final Batch Loss: 0.08829577267169952\n",
      "Epoch 2624, Loss: 0.12816780805587769, Final Batch Loss: 0.0679791122674942\n",
      "Epoch 2625, Loss: 0.17925239354372025, Final Batch Loss: 0.08334831893444061\n",
      "Epoch 2626, Loss: 0.14819077774882317, Final Batch Loss: 0.10283738374710083\n",
      "Epoch 2627, Loss: 0.13826529681682587, Final Batch Loss: 0.07219800353050232\n",
      "Epoch 2628, Loss: 0.1301225684583187, Final Batch Loss: 0.0728306919336319\n",
      "Epoch 2629, Loss: 0.12963537871837616, Final Batch Loss: 0.04700516164302826\n",
      "Epoch 2630, Loss: 0.11653153598308563, Final Batch Loss: 0.05690115690231323\n",
      "Epoch 2631, Loss: 0.16273073107004166, Final Batch Loss: 0.1082589402794838\n",
      "Epoch 2632, Loss: 0.13826563954353333, Final Batch Loss: 0.07357422262430191\n",
      "Epoch 2633, Loss: 0.15355197340250015, Final Batch Loss: 0.08089226484298706\n",
      "Epoch 2634, Loss: 0.1623348891735077, Final Batch Loss: 0.10323859751224518\n",
      "Epoch 2635, Loss: 0.16001708805561066, Final Batch Loss: 0.11596328765153885\n",
      "Epoch 2636, Loss: 0.1192309707403183, Final Batch Loss: 0.05890314653515816\n",
      "Epoch 2637, Loss: 0.15392795950174332, Final Batch Loss: 0.06781443953514099\n",
      "Epoch 2638, Loss: 0.08644785173237324, Final Batch Loss: 0.025652093812823296\n",
      "Epoch 2639, Loss: 0.11442649364471436, Final Batch Loss: 0.06456471979618073\n",
      "Epoch 2640, Loss: 0.16428036615252495, Final Batch Loss: 0.10527113825082779\n",
      "Epoch 2641, Loss: 0.14015896245837212, Final Batch Loss: 0.05170581117272377\n",
      "Epoch 2642, Loss: 0.13828115165233612, Final Batch Loss: 0.0592140331864357\n",
      "Epoch 2643, Loss: 0.13523676991462708, Final Batch Loss: 0.08070717006921768\n",
      "Epoch 2644, Loss: 0.15391845256090164, Final Batch Loss: 0.09369683265686035\n",
      "Epoch 2645, Loss: 0.11066711694002151, Final Batch Loss: 0.04151050001382828\n",
      "Epoch 2646, Loss: 0.16815225407481194, Final Batch Loss: 0.122860386967659\n",
      "Epoch 2647, Loss: 0.12329781427979469, Final Batch Loss: 0.05712144449353218\n",
      "Epoch 2648, Loss: 0.10905338823795319, Final Batch Loss: 0.05181867629289627\n",
      "Epoch 2649, Loss: 0.14398521557450294, Final Batch Loss: 0.08316078782081604\n",
      "Epoch 2650, Loss: 0.25156572461128235, Final Batch Loss: 0.1831132024526596\n",
      "Epoch 2651, Loss: 0.13752499595284462, Final Batch Loss: 0.07596691697835922\n",
      "Epoch 2652, Loss: 0.16513945162296295, Final Batch Loss: 0.10471846163272858\n",
      "Epoch 2653, Loss: 0.11270619183778763, Final Batch Loss: 0.0349331796169281\n",
      "Epoch 2654, Loss: 0.11802302300930023, Final Batch Loss: 0.05635042488574982\n",
      "Epoch 2655, Loss: 0.13653941452503204, Final Batch Loss: 0.05301206558942795\n",
      "Epoch 2656, Loss: 0.13650115206837654, Final Batch Loss: 0.08241286873817444\n",
      "Epoch 2657, Loss: 0.1440899297595024, Final Batch Loss: 0.07150151580572128\n",
      "Epoch 2658, Loss: 0.09573887661099434, Final Batch Loss: 0.03890814259648323\n",
      "Epoch 2659, Loss: 0.1557150036096573, Final Batch Loss: 0.07820228487253189\n",
      "Epoch 2660, Loss: 0.1205226220190525, Final Batch Loss: 0.05031970515847206\n",
      "Epoch 2661, Loss: 0.14515260607004166, Final Batch Loss: 0.0786023661494255\n",
      "Epoch 2662, Loss: 0.13750193268060684, Final Batch Loss: 0.06558617204427719\n",
      "Epoch 2663, Loss: 0.1514834314584732, Final Batch Loss: 0.07914543896913528\n",
      "Epoch 2664, Loss: 0.11877888813614845, Final Batch Loss: 0.06657936424016953\n",
      "Epoch 2665, Loss: 0.15552584826946259, Final Batch Loss: 0.08739552646875381\n",
      "Epoch 2666, Loss: 0.11127595230937004, Final Batch Loss: 0.04886983335018158\n",
      "Epoch 2667, Loss: 0.10937712714076042, Final Batch Loss: 0.03139512613415718\n",
      "Epoch 2668, Loss: 0.13740066811442375, Final Batch Loss: 0.07954094558954239\n",
      "Epoch 2669, Loss: 0.15192869305610657, Final Batch Loss: 0.08141762018203735\n",
      "Epoch 2670, Loss: 0.11336688697338104, Final Batch Loss: 0.04473403841257095\n",
      "Epoch 2671, Loss: 0.11151496320962906, Final Batch Loss: 0.04645007848739624\n",
      "Epoch 2672, Loss: 0.14462102949619293, Final Batch Loss: 0.06758025288581848\n",
      "Epoch 2673, Loss: 0.16314011812210083, Final Batch Loss: 0.08272234350442886\n",
      "Epoch 2674, Loss: 0.09246546775102615, Final Batch Loss: 0.038189686834812164\n",
      "Epoch 2675, Loss: 0.0926608107984066, Final Batch Loss: 0.0262170247733593\n",
      "Epoch 2676, Loss: 0.1199096292257309, Final Batch Loss: 0.05902586132287979\n",
      "Epoch 2677, Loss: 0.1287049800157547, Final Batch Loss: 0.056977786123752594\n",
      "Epoch 2678, Loss: 0.14085520803928375, Final Batch Loss: 0.06657016277313232\n",
      "Epoch 2679, Loss: 0.14541182294487953, Final Batch Loss: 0.10599154233932495\n",
      "Epoch 2680, Loss: 0.10415083169937134, Final Batch Loss: 0.05177667737007141\n",
      "Epoch 2681, Loss: 0.09234420210123062, Final Batch Loss: 0.03698721155524254\n",
      "Epoch 2682, Loss: 0.13634510338306427, Final Batch Loss: 0.04435237497091293\n",
      "Epoch 2683, Loss: 0.11374183744192123, Final Batch Loss: 0.04832819104194641\n",
      "Epoch 2684, Loss: 0.11814424023032188, Final Batch Loss: 0.059534382075071335\n",
      "Epoch 2685, Loss: 0.12892813235521317, Final Batch Loss: 0.0711534172296524\n",
      "Epoch 2686, Loss: 0.12598924338817596, Final Batch Loss: 0.07366825640201569\n",
      "Epoch 2687, Loss: 0.13862363994121552, Final Batch Loss: 0.06726709008216858\n",
      "Epoch 2688, Loss: 0.14007557183504105, Final Batch Loss: 0.08365978300571442\n",
      "Epoch 2689, Loss: 0.09496637433767319, Final Batch Loss: 0.041097451001405716\n",
      "Epoch 2690, Loss: 0.13580891862511635, Final Batch Loss: 0.05929656699299812\n",
      "Epoch 2691, Loss: 0.11244506016373634, Final Batch Loss: 0.052113380283117294\n",
      "Epoch 2692, Loss: 0.14549876749515533, Final Batch Loss: 0.059188731014728546\n",
      "Epoch 2693, Loss: 0.12325435876846313, Final Batch Loss: 0.06606731563806534\n",
      "Epoch 2694, Loss: 0.10702254250645638, Final Batch Loss: 0.05135837197303772\n",
      "Epoch 2695, Loss: 0.1162940040230751, Final Batch Loss: 0.05505993217229843\n",
      "Epoch 2696, Loss: 0.12320355698466301, Final Batch Loss: 0.05126677080988884\n",
      "Epoch 2697, Loss: 0.10563481971621513, Final Batch Loss: 0.051483333110809326\n",
      "Epoch 2698, Loss: 0.13691681250929832, Final Batch Loss: 0.07976452261209488\n",
      "Epoch 2699, Loss: 0.12524744495749474, Final Batch Loss: 0.05094412341713905\n",
      "Epoch 2700, Loss: 0.10252467170357704, Final Batch Loss: 0.0479833260178566\n",
      "Epoch 2701, Loss: 0.12117015570402145, Final Batch Loss: 0.0503949373960495\n",
      "Epoch 2702, Loss: 0.1658349111676216, Final Batch Loss: 0.06786973029375076\n",
      "Epoch 2703, Loss: 0.1447269693017006, Final Batch Loss: 0.08261038362979889\n",
      "Epoch 2704, Loss: 0.10534124821424484, Final Batch Loss: 0.046182505786418915\n",
      "Epoch 2705, Loss: 0.10141139104962349, Final Batch Loss: 0.03769969567656517\n",
      "Epoch 2706, Loss: 0.14188601076602936, Final Batch Loss: 0.10158570110797882\n",
      "Epoch 2707, Loss: 0.20681305974721909, Final Batch Loss: 0.11575336754322052\n",
      "Epoch 2708, Loss: 0.13485541939735413, Final Batch Loss: 0.07551105320453644\n",
      "Epoch 2709, Loss: 0.14948976784944534, Final Batch Loss: 0.08571677654981613\n",
      "Epoch 2710, Loss: 0.18505915999412537, Final Batch Loss: 0.1354551911354065\n",
      "Epoch 2711, Loss: 0.11396263167262077, Final Batch Loss: 0.06144643947482109\n",
      "Epoch 2712, Loss: 0.1399530991911888, Final Batch Loss: 0.058590225875377655\n",
      "Epoch 2713, Loss: 0.1636744812130928, Final Batch Loss: 0.08582018315792084\n",
      "Epoch 2714, Loss: 0.1575566679239273, Final Batch Loss: 0.09339184314012527\n",
      "Epoch 2715, Loss: 0.20807813107967377, Final Batch Loss: 0.13009825348854065\n",
      "Epoch 2716, Loss: 0.14309679716825485, Final Batch Loss: 0.08527553081512451\n",
      "Epoch 2717, Loss: 0.12740574032068253, Final Batch Loss: 0.06683746725320816\n",
      "Epoch 2718, Loss: 0.12254109606146812, Final Batch Loss: 0.038049887865781784\n",
      "Epoch 2719, Loss: 0.09922068379819393, Final Batch Loss: 0.029462842270731926\n",
      "Epoch 2720, Loss: 0.1262589767575264, Final Batch Loss: 0.06774604320526123\n",
      "Epoch 2721, Loss: 0.13875649124383926, Final Batch Loss: 0.08227691054344177\n",
      "Epoch 2722, Loss: 0.1348985731601715, Final Batch Loss: 0.06323041021823883\n",
      "Epoch 2723, Loss: 0.13963187485933304, Final Batch Loss: 0.06354741007089615\n",
      "Epoch 2724, Loss: 0.12400459498167038, Final Batch Loss: 0.06728099286556244\n",
      "Epoch 2725, Loss: 0.13128048181533813, Final Batch Loss: 0.07568375021219254\n",
      "Epoch 2726, Loss: 0.12681574746966362, Final Batch Loss: 0.08086975663900375\n",
      "Epoch 2727, Loss: 0.14643612504005432, Final Batch Loss: 0.0681481882929802\n",
      "Epoch 2728, Loss: 0.1078457273542881, Final Batch Loss: 0.050858862698078156\n",
      "Epoch 2729, Loss: 0.10947274416685104, Final Batch Loss: 0.055026907473802567\n",
      "Epoch 2730, Loss: 0.14206696674227715, Final Batch Loss: 0.08663658797740936\n",
      "Epoch 2731, Loss: 0.13429967686533928, Final Batch Loss: 0.07874341309070587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2732, Loss: 0.10157719627022743, Final Batch Loss: 0.039214130491018295\n",
      "Epoch 2733, Loss: 0.10287593305110931, Final Batch Loss: 0.0384143590927124\n",
      "Epoch 2734, Loss: 0.10266920924186707, Final Batch Loss: 0.03376837074756622\n",
      "Epoch 2735, Loss: 0.13125013560056686, Final Batch Loss: 0.0785941630601883\n",
      "Epoch 2736, Loss: 0.09422111511230469, Final Batch Loss: 0.03967547044157982\n",
      "Epoch 2737, Loss: 0.1326228268444538, Final Batch Loss: 0.05661831423640251\n",
      "Epoch 2738, Loss: 0.12201481685042381, Final Batch Loss: 0.0546087883412838\n",
      "Epoch 2739, Loss: 0.14968815073370934, Final Batch Loss: 0.09733815491199493\n",
      "Epoch 2740, Loss: 0.1483963057398796, Final Batch Loss: 0.06903176754713058\n",
      "Epoch 2741, Loss: 0.10672865808010101, Final Batch Loss: 0.02945345640182495\n",
      "Epoch 2742, Loss: 0.12993917986750603, Final Batch Loss: 0.0897422730922699\n",
      "Epoch 2743, Loss: 0.11477541923522949, Final Batch Loss: 0.04416882246732712\n",
      "Epoch 2744, Loss: 0.12461709976196289, Final Batch Loss: 0.07272084057331085\n",
      "Epoch 2745, Loss: 0.1448959782719612, Final Batch Loss: 0.08113556355237961\n",
      "Epoch 2746, Loss: 0.10887131467461586, Final Batch Loss: 0.0461941696703434\n",
      "Epoch 2747, Loss: 0.13503054529428482, Final Batch Loss: 0.07147906720638275\n",
      "Epoch 2748, Loss: 0.11609018966555595, Final Batch Loss: 0.05890914797782898\n",
      "Epoch 2749, Loss: 0.15679357200860977, Final Batch Loss: 0.11157609522342682\n",
      "Epoch 2750, Loss: 0.11851996928453445, Final Batch Loss: 0.05561459809541702\n",
      "Epoch 2751, Loss: 0.18199806660413742, Final Batch Loss: 0.10362372547388077\n",
      "Epoch 2752, Loss: 0.11405092850327492, Final Batch Loss: 0.04034312441945076\n",
      "Epoch 2753, Loss: 0.11671596392989159, Final Batch Loss: 0.0668373629450798\n",
      "Epoch 2754, Loss: 0.11324851959943771, Final Batch Loss: 0.053719859570264816\n",
      "Epoch 2755, Loss: 0.12030722573399544, Final Batch Loss: 0.04894258454442024\n",
      "Epoch 2756, Loss: 0.11307083070278168, Final Batch Loss: 0.06245124340057373\n",
      "Epoch 2757, Loss: 0.11071588844060898, Final Batch Loss: 0.049333374947309494\n",
      "Epoch 2758, Loss: 0.11773877032101154, Final Batch Loss: 0.08773293346166611\n",
      "Epoch 2759, Loss: 0.1575862243771553, Final Batch Loss: 0.09075406193733215\n",
      "Epoch 2760, Loss: 0.11440699175000191, Final Batch Loss: 0.058698900043964386\n",
      "Epoch 2761, Loss: 0.14730911329388618, Final Batch Loss: 0.09923232346773148\n",
      "Epoch 2762, Loss: 0.1242334395647049, Final Batch Loss: 0.07562612742185593\n",
      "Epoch 2763, Loss: 0.1452946849167347, Final Batch Loss: 0.09661956131458282\n",
      "Epoch 2764, Loss: 0.15439487621188164, Final Batch Loss: 0.04768617823719978\n",
      "Epoch 2765, Loss: 0.15482523664832115, Final Batch Loss: 0.061073970049619675\n",
      "Epoch 2766, Loss: 0.14291644841432571, Final Batch Loss: 0.06731076538562775\n",
      "Epoch 2767, Loss: 0.10315515100955963, Final Batch Loss: 0.05432191491127014\n",
      "Epoch 2768, Loss: 0.14149652794003487, Final Batch Loss: 0.031274739652872086\n",
      "Epoch 2769, Loss: 0.16896361857652664, Final Batch Loss: 0.09747648984193802\n",
      "Epoch 2770, Loss: 0.1365489698946476, Final Batch Loss: 0.04821151867508888\n",
      "Epoch 2771, Loss: 0.1481243260204792, Final Batch Loss: 0.050402846187353134\n",
      "Epoch 2772, Loss: 0.16564177721738815, Final Batch Loss: 0.06258238852024078\n",
      "Epoch 2773, Loss: 0.14238177612423897, Final Batch Loss: 0.08972171694040298\n",
      "Epoch 2774, Loss: 0.15984711050987244, Final Batch Loss: 0.08560841530561447\n",
      "Epoch 2775, Loss: 0.18405211716890335, Final Batch Loss: 0.08093459904193878\n",
      "Epoch 2776, Loss: 0.1412956900894642, Final Batch Loss: 0.057278845459222794\n",
      "Epoch 2777, Loss: 0.17034012451767921, Final Batch Loss: 0.11858610808849335\n",
      "Epoch 2778, Loss: 0.151194728910923, Final Batch Loss: 0.0753244161605835\n",
      "Epoch 2779, Loss: 0.13429588079452515, Final Batch Loss: 0.05815450847148895\n",
      "Epoch 2780, Loss: 0.13316944614052773, Final Batch Loss: 0.07806111127138138\n",
      "Epoch 2781, Loss: 0.116130530834198, Final Batch Loss: 0.05611491948366165\n",
      "Epoch 2782, Loss: 0.1321200355887413, Final Batch Loss: 0.08191931992769241\n",
      "Epoch 2783, Loss: 0.0857047364115715, Final Batch Loss: 0.03853817284107208\n",
      "Epoch 2784, Loss: 0.11506879329681396, Final Batch Loss: 0.05719434842467308\n",
      "Epoch 2785, Loss: 0.11353510618209839, Final Batch Loss: 0.047345541417598724\n",
      "Epoch 2786, Loss: 0.11669398099184036, Final Batch Loss: 0.0711524710059166\n",
      "Epoch 2787, Loss: 0.13098428025841713, Final Batch Loss: 0.04086354002356529\n",
      "Epoch 2788, Loss: 0.1280696652829647, Final Batch Loss: 0.060142021626234055\n",
      "Epoch 2789, Loss: 0.1140608862042427, Final Batch Loss: 0.05764621123671532\n",
      "Epoch 2790, Loss: 0.13597184419631958, Final Batch Loss: 0.09443745762109756\n",
      "Epoch 2791, Loss: 0.1457507386803627, Final Batch Loss: 0.08824513107538223\n",
      "Epoch 2792, Loss: 0.13840863853693008, Final Batch Loss: 0.08978141844272614\n",
      "Epoch 2793, Loss: 0.13164270669221878, Final Batch Loss: 0.08537983894348145\n",
      "Epoch 2794, Loss: 0.11872991174459457, Final Batch Loss: 0.05621461570262909\n",
      "Epoch 2795, Loss: 0.1171356625854969, Final Batch Loss: 0.04500972107052803\n",
      "Epoch 2796, Loss: 0.14565066993236542, Final Batch Loss: 0.0853755921125412\n",
      "Epoch 2797, Loss: 0.1219945102930069, Final Batch Loss: 0.05667635053396225\n",
      "Epoch 2798, Loss: 0.15574512630701065, Final Batch Loss: 0.07028912752866745\n",
      "Epoch 2799, Loss: 0.09492563456296921, Final Batch Loss: 0.0491015687584877\n",
      "Epoch 2800, Loss: 0.12340206280350685, Final Batch Loss: 0.06044681742787361\n",
      "Epoch 2801, Loss: 0.2581596300005913, Final Batch Loss: 0.20296379923820496\n",
      "Epoch 2802, Loss: 0.12659171596169472, Final Batch Loss: 0.08116793632507324\n",
      "Epoch 2803, Loss: 0.12665743008255959, Final Batch Loss: 0.060082148760557175\n",
      "Epoch 2804, Loss: 0.10232122242450714, Final Batch Loss: 0.03996527940034866\n",
      "Epoch 2805, Loss: 0.15465808659791946, Final Batch Loss: 0.06552828848361969\n",
      "Epoch 2806, Loss: 0.12816497310996056, Final Batch Loss: 0.061534252017736435\n",
      "Epoch 2807, Loss: 0.13624539971351624, Final Batch Loss: 0.08513548970222473\n",
      "Epoch 2808, Loss: 0.14205832034349442, Final Batch Loss: 0.07984665781259537\n",
      "Epoch 2809, Loss: 0.10069195181131363, Final Batch Loss: 0.04050493985414505\n",
      "Epoch 2810, Loss: 0.12366083264350891, Final Batch Loss: 0.05165065824985504\n",
      "Epoch 2811, Loss: 0.15280232205986977, Final Batch Loss: 0.05831893905997276\n",
      "Epoch 2812, Loss: 0.12272727116942406, Final Batch Loss: 0.05761600658297539\n",
      "Epoch 2813, Loss: 0.14655620977282524, Final Batch Loss: 0.08760550618171692\n",
      "Epoch 2814, Loss: 0.11684170737862587, Final Batch Loss: 0.04456209018826485\n",
      "Epoch 2815, Loss: 0.1262199729681015, Final Batch Loss: 0.048179589211940765\n",
      "Epoch 2816, Loss: 0.13756001368165016, Final Batch Loss: 0.04292907938361168\n",
      "Epoch 2817, Loss: 0.10577615723013878, Final Batch Loss: 0.04871590808033943\n",
      "Epoch 2818, Loss: 0.11179227381944656, Final Batch Loss: 0.048746258020401\n",
      "Epoch 2819, Loss: 0.10615614801645279, Final Batch Loss: 0.052237704396247864\n",
      "Epoch 2820, Loss: 0.10945602506399155, Final Batch Loss: 0.04039771854877472\n",
      "Epoch 2821, Loss: 0.14743302762508392, Final Batch Loss: 0.07227888703346252\n",
      "Epoch 2822, Loss: 0.14634724706411362, Final Batch Loss: 0.07561288774013519\n",
      "Epoch 2823, Loss: 0.11264373734593391, Final Batch Loss: 0.059911131858825684\n",
      "Epoch 2824, Loss: 0.12487183511257172, Final Batch Loss: 0.07177738100290298\n",
      "Epoch 2825, Loss: 0.09784567169845104, Final Batch Loss: 0.024170352146029472\n",
      "Epoch 2826, Loss: 0.11771506443619728, Final Batch Loss: 0.05802324414253235\n",
      "Epoch 2827, Loss: 0.16577981412410736, Final Batch Loss: 0.06676635891199112\n",
      "Epoch 2828, Loss: 0.1076054722070694, Final Batch Loss: 0.035634979605674744\n",
      "Epoch 2829, Loss: 0.11034884303808212, Final Batch Loss: 0.07545531541109085\n",
      "Epoch 2830, Loss: 0.1129811517894268, Final Batch Loss: 0.05609807372093201\n",
      "Epoch 2831, Loss: 0.12739107757806778, Final Batch Loss: 0.06406332552433014\n",
      "Epoch 2832, Loss: 0.09716792218387127, Final Batch Loss: 0.026478750631213188\n",
      "Epoch 2833, Loss: 0.13389500975608826, Final Batch Loss: 0.07344548404216766\n",
      "Epoch 2834, Loss: 0.14157062768936157, Final Batch Loss: 0.07633636891841888\n",
      "Epoch 2835, Loss: 0.11756128445267677, Final Batch Loss: 0.06736160069704056\n",
      "Epoch 2836, Loss: 0.11863073706626892, Final Batch Loss: 0.05817714333534241\n",
      "Epoch 2837, Loss: 0.13414718583226204, Final Batch Loss: 0.07440497726202011\n",
      "Epoch 2838, Loss: 0.09596213325858116, Final Batch Loss: 0.052950527518987656\n",
      "Epoch 2839, Loss: 0.13898999243974686, Final Batch Loss: 0.06362283229827881\n",
      "Epoch 2840, Loss: 0.1143067441880703, Final Batch Loss: 0.05051269009709358\n",
      "Epoch 2841, Loss: 0.11326903104782104, Final Batch Loss: 0.04714871942996979\n",
      "Epoch 2842, Loss: 0.13866528868675232, Final Batch Loss: 0.06836865842342377\n",
      "Epoch 2843, Loss: 0.12009099125862122, Final Batch Loss: 0.05927000194787979\n",
      "Epoch 2844, Loss: 0.1379847191274166, Final Batch Loss: 0.08250220119953156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2845, Loss: 0.25195425748825073, Final Batch Loss: 0.19777542352676392\n",
      "Epoch 2846, Loss: 0.12472829222679138, Final Batch Loss: 0.07555142790079117\n",
      "Epoch 2847, Loss: 0.10632717981934547, Final Batch Loss: 0.050627853721380234\n",
      "Epoch 2848, Loss: 0.12875686585903168, Final Batch Loss: 0.07559449225664139\n",
      "Epoch 2849, Loss: 0.10980872064828873, Final Batch Loss: 0.05298389494419098\n",
      "Epoch 2850, Loss: 0.12401751801371574, Final Batch Loss: 0.07265669852495193\n",
      "Epoch 2851, Loss: 0.1010474693030119, Final Batch Loss: 0.030639944598078728\n",
      "Epoch 2852, Loss: 0.13234561309218407, Final Batch Loss: 0.07259814441204071\n",
      "Epoch 2853, Loss: 0.10899266600608826, Final Batch Loss: 0.06523821502923965\n",
      "Epoch 2854, Loss: 0.12517449632287025, Final Batch Loss: 0.07477796822786331\n",
      "Epoch 2855, Loss: 0.1381404809653759, Final Batch Loss: 0.08064892888069153\n",
      "Epoch 2856, Loss: 0.09924744814634323, Final Batch Loss: 0.04544631391763687\n",
      "Epoch 2857, Loss: 0.10352187231183052, Final Batch Loss: 0.052917372435331345\n",
      "Epoch 2858, Loss: 0.10888360440731049, Final Batch Loss: 0.05039571225643158\n",
      "Epoch 2859, Loss: 0.11423909664154053, Final Batch Loss: 0.06089657545089722\n",
      "Epoch 2860, Loss: 0.10687752813100815, Final Batch Loss: 0.04373590648174286\n",
      "Epoch 2861, Loss: 0.15362544357776642, Final Batch Loss: 0.08825270086526871\n",
      "Epoch 2862, Loss: 0.14012229070067406, Final Batch Loss: 0.10007257014513016\n",
      "Epoch 2863, Loss: 0.14053868502378464, Final Batch Loss: 0.0691308081150055\n",
      "Epoch 2864, Loss: 0.11098058894276619, Final Batch Loss: 0.04770166054368019\n",
      "Epoch 2865, Loss: 0.13676519319415092, Final Batch Loss: 0.07763813436031342\n",
      "Epoch 2866, Loss: 0.10205184295773506, Final Batch Loss: 0.05245576798915863\n",
      "Epoch 2867, Loss: 0.2105746641755104, Final Batch Loss: 0.13330131769180298\n",
      "Epoch 2868, Loss: 0.1287129670381546, Final Batch Loss: 0.06501257419586182\n",
      "Epoch 2869, Loss: 0.12918242812156677, Final Batch Loss: 0.06611906737089157\n",
      "Epoch 2870, Loss: 0.1414184384047985, Final Batch Loss: 0.09682963043451309\n",
      "Epoch 2871, Loss: 0.14851924031972885, Final Batch Loss: 0.06398236751556396\n",
      "Epoch 2872, Loss: 0.12893950566649437, Final Batch Loss: 0.058432687073946\n",
      "Epoch 2873, Loss: 0.1453428864479065, Final Batch Loss: 0.07461071759462357\n",
      "Epoch 2874, Loss: 0.1378057897090912, Final Batch Loss: 0.07539959996938705\n",
      "Epoch 2875, Loss: 0.18225352093577385, Final Batch Loss: 0.12509575486183167\n",
      "Epoch 2876, Loss: 0.14459187164902687, Final Batch Loss: 0.0604427196085453\n",
      "Epoch 2877, Loss: 0.16080164164304733, Final Batch Loss: 0.11636056005954742\n",
      "Epoch 2878, Loss: 0.1665758118033409, Final Batch Loss: 0.06922619044780731\n",
      "Epoch 2879, Loss: 0.11487673223018646, Final Batch Loss: 0.043762125074863434\n",
      "Epoch 2880, Loss: 0.10408583283424377, Final Batch Loss: 0.04557732865214348\n",
      "Epoch 2881, Loss: 0.1408833973109722, Final Batch Loss: 0.04781891033053398\n",
      "Epoch 2882, Loss: 0.10148470848798752, Final Batch Loss: 0.04459363594651222\n",
      "Epoch 2883, Loss: 0.12368032336235046, Final Batch Loss: 0.05442112684249878\n",
      "Epoch 2884, Loss: 0.13546939566731453, Final Batch Loss: 0.07981719821691513\n",
      "Epoch 2885, Loss: 0.10140588134527206, Final Batch Loss: 0.03873319923877716\n",
      "Epoch 2886, Loss: 0.13464004546403885, Final Batch Loss: 0.05398757755756378\n",
      "Epoch 2887, Loss: 0.10427441075444221, Final Batch Loss: 0.046687740832567215\n",
      "Epoch 2888, Loss: 0.12886906787753105, Final Batch Loss: 0.08420029282569885\n",
      "Epoch 2889, Loss: 0.11193357408046722, Final Batch Loss: 0.04712759703397751\n",
      "Epoch 2890, Loss: 0.11902261525392532, Final Batch Loss: 0.05035347491502762\n",
      "Epoch 2891, Loss: 0.16567571088671684, Final Batch Loss: 0.10571365058422089\n",
      "Epoch 2892, Loss: 0.12121330574154854, Final Batch Loss: 0.07047692686319351\n",
      "Epoch 2893, Loss: 0.11403291672468185, Final Batch Loss: 0.05819528549909592\n",
      "Epoch 2894, Loss: 0.1407763808965683, Final Batch Loss: 0.0613289400935173\n",
      "Epoch 2895, Loss: 0.101825300604105, Final Batch Loss: 0.05031159892678261\n",
      "Epoch 2896, Loss: 0.16156169399619102, Final Batch Loss: 0.0507771261036396\n",
      "Epoch 2897, Loss: 0.3288367763161659, Final Batch Loss: 0.25398001074790955\n",
      "Epoch 2898, Loss: 0.11292234063148499, Final Batch Loss: 0.04012395441532135\n",
      "Epoch 2899, Loss: 0.11259178072214127, Final Batch Loss: 0.036752790212631226\n",
      "Epoch 2900, Loss: 0.12114829570055008, Final Batch Loss: 0.052026838064193726\n",
      "Epoch 2901, Loss: 0.1516033411026001, Final Batch Loss: 0.07272292673587799\n",
      "Epoch 2902, Loss: 0.1382121592760086, Final Batch Loss: 0.08852467685937881\n",
      "Epoch 2903, Loss: 0.21139300614595413, Final Batch Loss: 0.10773827880620956\n",
      "Epoch 2904, Loss: 0.14124267548322678, Final Batch Loss: 0.06373288482427597\n",
      "Epoch 2905, Loss: 0.12897279486060143, Final Batch Loss: 0.07370775192975998\n",
      "Epoch 2906, Loss: 0.13808561488986015, Final Batch Loss: 0.08230078220367432\n",
      "Epoch 2907, Loss: 0.12980875000357628, Final Batch Loss: 0.0680314376950264\n",
      "Epoch 2908, Loss: 0.12692579254508018, Final Batch Loss: 0.05367584899067879\n",
      "Epoch 2909, Loss: 0.10940595343708992, Final Batch Loss: 0.0579984076321125\n",
      "Epoch 2910, Loss: 0.16102389618754387, Final Batch Loss: 0.060144972056150436\n",
      "Epoch 2911, Loss: 0.229446928948164, Final Batch Loss: 0.17364831268787384\n",
      "Epoch 2912, Loss: 0.1177314966917038, Final Batch Loss: 0.044422850012779236\n",
      "Epoch 2913, Loss: 0.11573047935962677, Final Batch Loss: 0.0457405149936676\n",
      "Epoch 2914, Loss: 0.15022383630275726, Final Batch Loss: 0.09501288086175919\n",
      "Epoch 2915, Loss: 0.13204200938344002, Final Batch Loss: 0.05450454726815224\n",
      "Epoch 2916, Loss: 0.144554752856493, Final Batch Loss: 0.09615017473697662\n",
      "Epoch 2917, Loss: 0.13635743409395218, Final Batch Loss: 0.061442866921424866\n",
      "Epoch 2918, Loss: 0.1013769842684269, Final Batch Loss: 0.0504823662340641\n",
      "Epoch 2919, Loss: 0.09833208471536636, Final Batch Loss: 0.04792457073926926\n",
      "Epoch 2920, Loss: 0.11254410818219185, Final Batch Loss: 0.061780624091625214\n",
      "Epoch 2921, Loss: 0.12534038722515106, Final Batch Loss: 0.055161252617836\n",
      "Epoch 2922, Loss: 0.08703440241515636, Final Batch Loss: 0.025664838030934334\n",
      "Epoch 2923, Loss: 0.12244455516338348, Final Batch Loss: 0.07727379351854324\n",
      "Epoch 2924, Loss: 0.13117026910185814, Final Batch Loss: 0.04371679946780205\n",
      "Epoch 2925, Loss: 0.12065732479095459, Final Batch Loss: 0.053535692393779755\n",
      "Epoch 2926, Loss: 0.10639232955873013, Final Batch Loss: 0.020793942734599113\n",
      "Epoch 2927, Loss: 0.10009576380252838, Final Batch Loss: 0.026336409151554108\n",
      "Epoch 2928, Loss: 0.18225933238863945, Final Batch Loss: 0.04092135652899742\n",
      "Epoch 2929, Loss: 0.09045896306633949, Final Batch Loss: 0.04811603203415871\n",
      "Epoch 2930, Loss: 0.13098454475402832, Final Batch Loss: 0.06806518882513046\n",
      "Epoch 2931, Loss: 0.11611535772681236, Final Batch Loss: 0.06874195486307144\n",
      "Epoch 2932, Loss: 0.14481624588370323, Final Batch Loss: 0.08321811258792877\n",
      "Epoch 2933, Loss: 0.10142097808420658, Final Batch Loss: 0.029074223712086678\n",
      "Epoch 2934, Loss: 0.10708054900169373, Final Batch Loss: 0.05927305296063423\n",
      "Epoch 2935, Loss: 0.11056008189916611, Final Batch Loss: 0.03709385544061661\n",
      "Epoch 2936, Loss: 0.09891768172383308, Final Batch Loss: 0.032643456012010574\n",
      "Epoch 2937, Loss: 0.08597833290696144, Final Batch Loss: 0.04226512461900711\n",
      "Epoch 2938, Loss: 0.12510009855031967, Final Batch Loss: 0.05095616728067398\n",
      "Epoch 2939, Loss: 0.10965694114565849, Final Batch Loss: 0.0464782752096653\n",
      "Epoch 2940, Loss: 0.10392798483371735, Final Batch Loss: 0.039022885262966156\n",
      "Epoch 2941, Loss: 0.1158699132502079, Final Batch Loss: 0.07102242112159729\n",
      "Epoch 2942, Loss: 0.10783582553267479, Final Batch Loss: 0.07039032131433487\n",
      "Epoch 2943, Loss: 0.09976483136415482, Final Batch Loss: 0.044892068952322006\n",
      "Epoch 2944, Loss: 0.146711565554142, Final Batch Loss: 0.09964322298765182\n",
      "Epoch 2945, Loss: 0.11921394616365433, Final Batch Loss: 0.06677666306495667\n",
      "Epoch 2946, Loss: 0.09680792689323425, Final Batch Loss: 0.03415599465370178\n",
      "Epoch 2947, Loss: 0.10119692236185074, Final Batch Loss: 0.036380164325237274\n",
      "Epoch 2948, Loss: 0.1047203578054905, Final Batch Loss: 0.031773630529642105\n",
      "Epoch 2949, Loss: 0.13182692974805832, Final Batch Loss: 0.08316094428300858\n",
      "Epoch 2950, Loss: 0.12175366282463074, Final Batch Loss: 0.06902971863746643\n",
      "Epoch 2951, Loss: 0.09355037659406662, Final Batch Loss: 0.04883381351828575\n",
      "Epoch 2952, Loss: 0.11402469873428345, Final Batch Loss: 0.057617925107479095\n",
      "Epoch 2953, Loss: 0.11634363606572151, Final Batch Loss: 0.04947039112448692\n",
      "Epoch 2954, Loss: 0.10391489043831825, Final Batch Loss: 0.03426889702677727\n",
      "Epoch 2955, Loss: 0.11949250474572182, Final Batch Loss: 0.05517861619591713\n",
      "Epoch 2956, Loss: 0.09872999787330627, Final Batch Loss: 0.041866548359394073\n",
      "Epoch 2957, Loss: 0.12317149713635445, Final Batch Loss: 0.07777554541826248\n",
      "Epoch 2958, Loss: 0.13658711686730385, Final Batch Loss: 0.08436545729637146\n",
      "Epoch 2959, Loss: 0.10429781675338745, Final Batch Loss: 0.04521067067980766\n",
      "Epoch 2960, Loss: 0.14343231916427612, Final Batch Loss: 0.06901693344116211\n",
      "Epoch 2961, Loss: 0.147616907954216, Final Batch Loss: 0.0946217030286789\n",
      "Epoch 2962, Loss: 0.17394652217626572, Final Batch Loss: 0.04693625122308731\n",
      "Epoch 2963, Loss: 0.14992638677358627, Final Batch Loss: 0.08536148816347122\n",
      "Epoch 2964, Loss: 0.13232888281345367, Final Batch Loss: 0.08863204717636108\n",
      "Epoch 2965, Loss: 0.11255839839577675, Final Batch Loss: 0.06923237442970276\n",
      "Epoch 2966, Loss: 0.08243033289909363, Final Batch Loss: 0.03617521747946739\n",
      "Epoch 2967, Loss: 0.12222512066364288, Final Batch Loss: 0.06090947985649109\n",
      "Epoch 2968, Loss: 0.10016370192170143, Final Batch Loss: 0.053292859345674515\n",
      "Epoch 2969, Loss: 0.1061122827231884, Final Batch Loss: 0.07404094934463501\n",
      "Epoch 2970, Loss: 0.11979592964053154, Final Batch Loss: 0.061754241585731506\n",
      "Epoch 2971, Loss: 0.15064648538827896, Final Batch Loss: 0.09873910248279572\n",
      "Epoch 2972, Loss: 0.08567281253635883, Final Batch Loss: 0.02936813049018383\n",
      "Epoch 2973, Loss: 0.08561555948108435, Final Batch Loss: 0.012932187877595425\n",
      "Epoch 2974, Loss: 0.10478745028376579, Final Batch Loss: 0.042133528739213943\n",
      "Epoch 2975, Loss: 0.10701260715723038, Final Batch Loss: 0.05698256194591522\n",
      "Epoch 2976, Loss: 0.10030599683523178, Final Batch Loss: 0.050878509879112244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2977, Loss: 0.10957768186926842, Final Batch Loss: 0.06754502654075623\n",
      "Epoch 2978, Loss: 0.10008367151021957, Final Batch Loss: 0.03830235078930855\n",
      "Epoch 2979, Loss: 0.11690075322985649, Final Batch Loss: 0.05349244549870491\n",
      "Epoch 2980, Loss: 0.0893569141626358, Final Batch Loss: 0.039355166256427765\n",
      "Epoch 2981, Loss: 0.1286064274609089, Final Batch Loss: 0.07409477233886719\n",
      "Epoch 2982, Loss: 0.146218441426754, Final Batch Loss: 0.07722249627113342\n",
      "Epoch 2983, Loss: 0.09365096688270569, Final Batch Loss: 0.03932763636112213\n",
      "Epoch 2984, Loss: 0.10676797106862068, Final Batch Loss: 0.06332134455442429\n",
      "Epoch 2985, Loss: 0.1392858736217022, Final Batch Loss: 0.0782741829752922\n",
      "Epoch 2986, Loss: 0.12208832800388336, Final Batch Loss: 0.03738325834274292\n",
      "Epoch 2987, Loss: 0.09861031919717789, Final Batch Loss: 0.03418517857789993\n",
      "Epoch 2988, Loss: 0.1375179886817932, Final Batch Loss: 0.0825018361210823\n",
      "Epoch 2989, Loss: 0.12657388299703598, Final Batch Loss: 0.06725768744945526\n",
      "Epoch 2990, Loss: 0.14449267834424973, Final Batch Loss: 0.07565546035766602\n",
      "Epoch 2991, Loss: 0.1256239451467991, Final Batch Loss: 0.057424236088991165\n",
      "Epoch 2992, Loss: 0.11282791197299957, Final Batch Loss: 0.03321345895528793\n",
      "Epoch 2993, Loss: 0.14027130976319313, Final Batch Loss: 0.08186586946249008\n",
      "Epoch 2994, Loss: 0.10631383210420609, Final Batch Loss: 0.03828494995832443\n",
      "Epoch 2995, Loss: 0.12000999227166176, Final Batch Loss: 0.07334859669208527\n",
      "Epoch 2996, Loss: 0.12401024252176285, Final Batch Loss: 0.062482621520757675\n",
      "Epoch 2997, Loss: 0.13433697074651718, Final Batch Loss: 0.08929860591888428\n",
      "Epoch 2998, Loss: 0.10069429129362106, Final Batch Loss: 0.06384080648422241\n",
      "Epoch 2999, Loss: 0.12711960077285767, Final Batch Loss: 0.050434842705726624\n",
      "Epoch 3000, Loss: 0.1458410769701004, Final Batch Loss: 0.09482963383197784\n",
      "Epoch 3001, Loss: 0.160386610776186, Final Batch Loss: 0.10095631331205368\n",
      "Epoch 3002, Loss: 0.09825439378619194, Final Batch Loss: 0.03346392884850502\n",
      "Epoch 3003, Loss: 0.09617037698626518, Final Batch Loss: 0.0507248118519783\n",
      "Epoch 3004, Loss: 0.1647452376782894, Final Batch Loss: 0.06031224504113197\n",
      "Epoch 3005, Loss: 0.1613665372133255, Final Batch Loss: 0.08055735379457474\n",
      "Epoch 3006, Loss: 0.11163663491606712, Final Batch Loss: 0.06979943066835403\n",
      "Epoch 3007, Loss: 0.09786128997802734, Final Batch Loss: 0.04057710990309715\n",
      "Epoch 3008, Loss: 0.14561882615089417, Final Batch Loss: 0.07366833835840225\n",
      "Epoch 3009, Loss: 0.0857063289731741, Final Batch Loss: 0.025162676349282265\n",
      "Epoch 3010, Loss: 0.12770270183682442, Final Batch Loss: 0.07848642766475677\n",
      "Epoch 3011, Loss: 0.10122204199433327, Final Batch Loss: 0.03831559792160988\n",
      "Epoch 3012, Loss: 0.13411922752857208, Final Batch Loss: 0.07234314829111099\n",
      "Epoch 3013, Loss: 0.09805275499820709, Final Batch Loss: 0.05338951572775841\n",
      "Epoch 3014, Loss: 0.16007011383771896, Final Batch Loss: 0.09980669617652893\n",
      "Epoch 3015, Loss: 0.09351146966218948, Final Batch Loss: 0.04144829511642456\n",
      "Epoch 3016, Loss: 0.09990974515676498, Final Batch Loss: 0.034549467265605927\n",
      "Epoch 3017, Loss: 0.10092348977923393, Final Batch Loss: 0.05035065859556198\n",
      "Epoch 3018, Loss: 0.11341078206896782, Final Batch Loss: 0.06379752606153488\n",
      "Epoch 3019, Loss: 0.12090083956718445, Final Batch Loss: 0.05309120565652847\n",
      "Epoch 3020, Loss: 0.08659882470965385, Final Batch Loss: 0.035927239805459976\n",
      "Epoch 3021, Loss: 0.08400743082165718, Final Batch Loss: 0.03302045166492462\n",
      "Epoch 3022, Loss: 0.10773492604494095, Final Batch Loss: 0.052317891269922256\n",
      "Epoch 3023, Loss: 0.1250525489449501, Final Batch Loss: 0.09083210676908493\n",
      "Epoch 3024, Loss: 0.10179256275296211, Final Batch Loss: 0.05289673060178757\n",
      "Epoch 3025, Loss: 0.11938396096229553, Final Batch Loss: 0.051529765129089355\n",
      "Epoch 3026, Loss: 0.13607647642493248, Final Batch Loss: 0.052933190017938614\n",
      "Epoch 3027, Loss: 0.08376340940594673, Final Batch Loss: 0.03135199099779129\n",
      "Epoch 3028, Loss: 0.07793893292546272, Final Batch Loss: 0.02474363148212433\n",
      "Epoch 3029, Loss: 0.08007328025996685, Final Batch Loss: 0.02874215506017208\n",
      "Epoch 3030, Loss: 0.11975912004709244, Final Batch Loss: 0.04349059611558914\n",
      "Epoch 3031, Loss: 0.09670570120215416, Final Batch Loss: 0.03682372346520424\n",
      "Epoch 3032, Loss: 0.13311386480927467, Final Batch Loss: 0.07815947383642197\n",
      "Epoch 3033, Loss: 0.08070345968008041, Final Batch Loss: 0.02886088564991951\n",
      "Epoch 3034, Loss: 0.10237282142043114, Final Batch Loss: 0.054078441113233566\n",
      "Epoch 3035, Loss: 0.09099103324115276, Final Batch Loss: 0.025086162611842155\n",
      "Epoch 3036, Loss: 0.12852301821112633, Final Batch Loss: 0.06676306575536728\n",
      "Epoch 3037, Loss: 0.10325192660093307, Final Batch Loss: 0.05454084277153015\n",
      "Epoch 3038, Loss: 0.1389743871986866, Final Batch Loss: 0.08815760910511017\n",
      "Epoch 3039, Loss: 0.10273800417780876, Final Batch Loss: 0.0453464575111866\n",
      "Epoch 3040, Loss: 0.12164420261979103, Final Batch Loss: 0.06320524960756302\n",
      "Epoch 3041, Loss: 0.08539048209786415, Final Batch Loss: 0.029705602675676346\n",
      "Epoch 3042, Loss: 0.09930470585823059, Final Batch Loss: 0.05515338480472565\n",
      "Epoch 3043, Loss: 0.11600709706544876, Final Batch Loss: 0.06967329233884811\n",
      "Epoch 3044, Loss: 0.14314332231879234, Final Batch Loss: 0.10016415268182755\n",
      "Epoch 3045, Loss: 0.10274514183402061, Final Batch Loss: 0.030275147408246994\n",
      "Epoch 3046, Loss: 0.12324294075369835, Final Batch Loss: 0.07794269919395447\n",
      "Epoch 3047, Loss: 0.13851064816117287, Final Batch Loss: 0.10266408324241638\n",
      "Epoch 3048, Loss: 0.10324008390307426, Final Batch Loss: 0.06897196918725967\n",
      "Epoch 3049, Loss: 0.10892779380083084, Final Batch Loss: 0.04683849215507507\n",
      "Epoch 3050, Loss: 0.15494108945131302, Final Batch Loss: 0.07423900067806244\n",
      "Epoch 3051, Loss: 0.1429498791694641, Final Batch Loss: 0.0625491663813591\n",
      "Epoch 3052, Loss: 0.08804439753293991, Final Batch Loss: 0.036526016891002655\n",
      "Epoch 3053, Loss: 0.08322792872786522, Final Batch Loss: 0.03181721270084381\n",
      "Epoch 3054, Loss: 0.11842397600412369, Final Batch Loss: 0.06376560777425766\n",
      "Epoch 3055, Loss: 0.10191477835178375, Final Batch Loss: 0.05381149426102638\n",
      "Epoch 3056, Loss: 0.11604981124401093, Final Batch Loss: 0.04589439183473587\n",
      "Epoch 3057, Loss: 0.0930803008377552, Final Batch Loss: 0.04935174807906151\n",
      "Epoch 3058, Loss: 0.11214945837855339, Final Batch Loss: 0.06622996926307678\n",
      "Epoch 3059, Loss: 0.13966871052980423, Final Batch Loss: 0.0925840362906456\n",
      "Epoch 3060, Loss: 0.12972018867731094, Final Batch Loss: 0.06694170087575912\n",
      "Epoch 3061, Loss: 0.09852539375424385, Final Batch Loss: 0.060019880533218384\n",
      "Epoch 3062, Loss: 0.08706474304199219, Final Batch Loss: 0.042741142213344574\n",
      "Epoch 3063, Loss: 0.15159442275762558, Final Batch Loss: 0.0830477848649025\n",
      "Epoch 3064, Loss: 0.10721885040402412, Final Batch Loss: 0.04880180582404137\n",
      "Epoch 3065, Loss: 0.0852263430133462, Final Batch Loss: 0.014539332129061222\n",
      "Epoch 3066, Loss: 0.09540458023548126, Final Batch Loss: 0.04605506360530853\n",
      "Epoch 3067, Loss: 0.12236574292182922, Final Batch Loss: 0.07098125666379929\n",
      "Epoch 3068, Loss: 0.12579862400889397, Final Batch Loss: 0.075003981590271\n",
      "Epoch 3069, Loss: 0.13245579972863197, Final Batch Loss: 0.058475393801927567\n",
      "Epoch 3070, Loss: 0.14480207487940788, Final Batch Loss: 0.09582072496414185\n",
      "Epoch 3071, Loss: 0.16555604338645935, Final Batch Loss: 0.04626278579235077\n",
      "Epoch 3072, Loss: 0.11281034350395203, Final Batch Loss: 0.05427263304591179\n",
      "Epoch 3073, Loss: 0.10309870541095734, Final Batch Loss: 0.06308355182409286\n",
      "Epoch 3074, Loss: 0.10869890823960304, Final Batch Loss: 0.05614317208528519\n",
      "Epoch 3075, Loss: 0.11531207896769047, Final Batch Loss: 0.030849458649754524\n",
      "Epoch 3076, Loss: 0.10962526872754097, Final Batch Loss: 0.07407734543085098\n",
      "Epoch 3077, Loss: 0.11448782309889793, Final Batch Loss: 0.08234694600105286\n",
      "Epoch 3078, Loss: 0.10177534818649292, Final Batch Loss: 0.03231599181890488\n",
      "Epoch 3079, Loss: 0.12371983751654625, Final Batch Loss: 0.04533647373318672\n",
      "Epoch 3080, Loss: 0.16407713294029236, Final Batch Loss: 0.08542560786008835\n",
      "Epoch 3081, Loss: 0.08877655863761902, Final Batch Loss: 0.041510604321956635\n",
      "Epoch 3082, Loss: 0.08684885315597057, Final Batch Loss: 0.024908600375056267\n",
      "Epoch 3083, Loss: 0.1216287612915039, Final Batch Loss: 0.0558135062456131\n",
      "Epoch 3084, Loss: 0.08159809187054634, Final Batch Loss: 0.0301479734480381\n",
      "Epoch 3085, Loss: 0.13249076157808304, Final Batch Loss: 0.0625627264380455\n",
      "Epoch 3086, Loss: 0.21308502927422523, Final Batch Loss: 0.05891713872551918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3087, Loss: 0.09309830889105797, Final Batch Loss: 0.042857080698013306\n",
      "Epoch 3088, Loss: 0.11759078130126, Final Batch Loss: 0.05549101158976555\n",
      "Epoch 3089, Loss: 0.12273013591766357, Final Batch Loss: 0.07364296913146973\n",
      "Epoch 3090, Loss: 0.12362335622310638, Final Batch Loss: 0.07172249257564545\n",
      "Epoch 3091, Loss: 0.13945022597908974, Final Batch Loss: 0.08964549005031586\n",
      "Epoch 3092, Loss: 0.09407905489206314, Final Batch Loss: 0.04656744748353958\n",
      "Epoch 3093, Loss: 0.10718626901507378, Final Batch Loss: 0.06131255626678467\n",
      "Epoch 3094, Loss: 0.11320223286747932, Final Batch Loss: 0.024783622473478317\n",
      "Epoch 3095, Loss: 0.11640889942646027, Final Batch Loss: 0.04894474148750305\n",
      "Epoch 3096, Loss: 0.07708225771784782, Final Batch Loss: 0.04348906874656677\n",
      "Epoch 3097, Loss: 0.08105817437171936, Final Batch Loss: 0.03770638629794121\n",
      "Epoch 3098, Loss: 0.12169937416911125, Final Batch Loss: 0.03980572149157524\n",
      "Epoch 3099, Loss: 0.10243294388055801, Final Batch Loss: 0.05126813426613808\n",
      "Epoch 3100, Loss: 0.09316051192581654, Final Batch Loss: 0.029389241710305214\n",
      "Epoch 3101, Loss: 0.1104833334684372, Final Batch Loss: 0.05879085883498192\n",
      "Epoch 3102, Loss: 0.17050866782665253, Final Batch Loss: 0.0886765643954277\n",
      "Epoch 3103, Loss: 0.11729764938354492, Final Batch Loss: 0.06363071501255035\n",
      "Epoch 3104, Loss: 0.12246686592698097, Final Batch Loss: 0.07160702347755432\n",
      "Epoch 3105, Loss: 0.08762096613645554, Final Batch Loss: 0.03787968307733536\n",
      "Epoch 3106, Loss: 0.11743957921862602, Final Batch Loss: 0.059969667345285416\n",
      "Epoch 3107, Loss: 0.10732198134064674, Final Batch Loss: 0.05395982414484024\n",
      "Epoch 3108, Loss: 0.20313698053359985, Final Batch Loss: 0.15780191123485565\n",
      "Epoch 3109, Loss: 0.07087785564363003, Final Batch Loss: 0.02102169208228588\n",
      "Epoch 3110, Loss: 0.10139904916286469, Final Batch Loss: 0.059159960597753525\n",
      "Epoch 3111, Loss: 0.10926594585180283, Final Batch Loss: 0.04608701914548874\n",
      "Epoch 3112, Loss: 0.15082107484340668, Final Batch Loss: 0.09680984169244766\n",
      "Epoch 3113, Loss: 0.14657187461853027, Final Batch Loss: 0.10013240575790405\n",
      "Epoch 3114, Loss: 0.11187904700636864, Final Batch Loss: 0.056787602603435516\n",
      "Epoch 3115, Loss: 0.12966175377368927, Final Batch Loss: 0.06322620809078217\n",
      "Epoch 3116, Loss: 0.18737265467643738, Final Batch Loss: 0.13594453036785126\n",
      "Epoch 3117, Loss: 0.10028867423534393, Final Batch Loss: 0.028954006731510162\n",
      "Epoch 3118, Loss: 0.1807481274008751, Final Batch Loss: 0.11057918518781662\n",
      "Epoch 3119, Loss: 0.15598738193511963, Final Batch Loss: 0.11717751622200012\n",
      "Epoch 3120, Loss: 0.11244481056928635, Final Batch Loss: 0.05587449669837952\n",
      "Epoch 3121, Loss: 0.12199928611516953, Final Batch Loss: 0.07386523485183716\n",
      "Epoch 3122, Loss: 0.06960953399538994, Final Batch Loss: 0.02620437741279602\n",
      "Epoch 3123, Loss: 0.10587939247488976, Final Batch Loss: 0.053434185683727264\n",
      "Epoch 3124, Loss: 0.13051670044660568, Final Batch Loss: 0.07111088186502457\n",
      "Epoch 3125, Loss: 0.1307557374238968, Final Batch Loss: 0.06351985037326813\n",
      "Epoch 3126, Loss: 0.1156829334795475, Final Batch Loss: 0.06867475062608719\n",
      "Epoch 3127, Loss: 0.0812559463083744, Final Batch Loss: 0.045177120715379715\n",
      "Epoch 3128, Loss: 0.11828769370913506, Final Batch Loss: 0.05678902193903923\n",
      "Epoch 3129, Loss: 0.08744766935706139, Final Batch Loss: 0.04364237189292908\n",
      "Epoch 3130, Loss: 0.11185554042458534, Final Batch Loss: 0.05878344923257828\n",
      "Epoch 3131, Loss: 0.08417262323200703, Final Batch Loss: 0.024586426094174385\n",
      "Epoch 3132, Loss: 0.09595415368676186, Final Batch Loss: 0.045512497425079346\n",
      "Epoch 3133, Loss: 0.13048579916357994, Final Batch Loss: 0.07042261213064194\n",
      "Epoch 3134, Loss: 0.09901554137468338, Final Batch Loss: 0.05659014359116554\n",
      "Epoch 3135, Loss: 0.1178528442978859, Final Batch Loss: 0.07000065594911575\n",
      "Epoch 3136, Loss: 0.10384495183825493, Final Batch Loss: 0.039000850170850754\n",
      "Epoch 3137, Loss: 0.12297911569476128, Final Batch Loss: 0.06907624006271362\n",
      "Epoch 3138, Loss: 0.10825507342815399, Final Batch Loss: 0.06480061262845993\n",
      "Epoch 3139, Loss: 0.11634776368737221, Final Batch Loss: 0.05582311376929283\n",
      "Epoch 3140, Loss: 0.12829213961958885, Final Batch Loss: 0.0312323160469532\n",
      "Epoch 3141, Loss: 0.11680307239294052, Final Batch Loss: 0.06355822831392288\n",
      "Epoch 3142, Loss: 0.10949009656906128, Final Batch Loss: 0.04170007258653641\n",
      "Epoch 3143, Loss: 0.10622398927807808, Final Batch Loss: 0.05400581285357475\n",
      "Epoch 3144, Loss: 0.10762710869312286, Final Batch Loss: 0.044766440987586975\n",
      "Epoch 3145, Loss: 0.09214157611131668, Final Batch Loss: 0.043583743274211884\n",
      "Epoch 3146, Loss: 0.10578526183962822, Final Batch Loss: 0.033354613929986954\n",
      "Epoch 3147, Loss: 0.0736392792314291, Final Batch Loss: 0.015672260895371437\n",
      "Epoch 3148, Loss: 0.11813320219516754, Final Batch Loss: 0.06492234766483307\n",
      "Epoch 3149, Loss: 0.09955206140875816, Final Batch Loss: 0.05318979546427727\n",
      "Epoch 3150, Loss: 0.11505550146102905, Final Batch Loss: 0.07861557602882385\n",
      "Epoch 3151, Loss: 0.0881979763507843, Final Batch Loss: 0.036879170686006546\n",
      "Epoch 3152, Loss: 0.0714587327092886, Final Batch Loss: 0.02019697241485119\n",
      "Epoch 3153, Loss: 0.14336449652910233, Final Batch Loss: 0.05102135241031647\n",
      "Epoch 3154, Loss: 0.11491920799016953, Final Batch Loss: 0.06402939558029175\n",
      "Epoch 3155, Loss: 0.08228335715830326, Final Batch Loss: 0.027076615020632744\n",
      "Epoch 3156, Loss: 0.12019991502165794, Final Batch Loss: 0.04853856936097145\n",
      "Epoch 3157, Loss: 0.09568759799003601, Final Batch Loss: 0.03538848087191582\n",
      "Epoch 3158, Loss: 0.08660423010587692, Final Batch Loss: 0.03977513685822487\n",
      "Epoch 3159, Loss: 0.09512537717819214, Final Batch Loss: 0.034286949783563614\n",
      "Epoch 3160, Loss: 0.09990067780017853, Final Batch Loss: 0.06295549869537354\n",
      "Epoch 3161, Loss: 0.08243113197386265, Final Batch Loss: 0.020524339750409126\n",
      "Epoch 3162, Loss: 0.0910585280507803, Final Batch Loss: 0.026472052559256554\n",
      "Epoch 3163, Loss: 0.16373195871710777, Final Batch Loss: 0.12424671649932861\n",
      "Epoch 3164, Loss: 0.1347697302699089, Final Batch Loss: 0.06672380864620209\n",
      "Epoch 3165, Loss: 0.10437696427106857, Final Batch Loss: 0.043054454028606415\n",
      "Epoch 3166, Loss: 0.0832214280962944, Final Batch Loss: 0.031853292137384415\n",
      "Epoch 3167, Loss: 0.09599028900265694, Final Batch Loss: 0.03291405364871025\n",
      "Epoch 3168, Loss: 0.09432146698236465, Final Batch Loss: 0.04041549190878868\n",
      "Epoch 3169, Loss: 0.09834234416484833, Final Batch Loss: 0.04269104450941086\n",
      "Epoch 3170, Loss: 0.08669137395918369, Final Batch Loss: 0.02047513611614704\n",
      "Epoch 3171, Loss: 0.10886973515152931, Final Batch Loss: 0.06067223101854324\n",
      "Epoch 3172, Loss: 0.1484120935201645, Final Batch Loss: 0.0483437180519104\n",
      "Epoch 3173, Loss: 0.08974364027380943, Final Batch Loss: 0.03698459267616272\n",
      "Epoch 3174, Loss: 0.10988812148571014, Final Batch Loss: 0.05138476938009262\n",
      "Epoch 3175, Loss: 0.09131063893437386, Final Batch Loss: 0.04579528793692589\n",
      "Epoch 3176, Loss: 0.10650940425693989, Final Batch Loss: 0.01975119300186634\n",
      "Epoch 3177, Loss: 0.1068650595843792, Final Batch Loss: 0.05010072886943817\n",
      "Epoch 3178, Loss: 0.16461516916751862, Final Batch Loss: 0.09991779923439026\n",
      "Epoch 3179, Loss: 0.130153339356184, Final Batch Loss: 0.06903474777936935\n",
      "Epoch 3180, Loss: 0.10919719934463501, Final Batch Loss: 0.06656283140182495\n",
      "Epoch 3181, Loss: 0.08931781724095345, Final Batch Loss: 0.05073124170303345\n",
      "Epoch 3182, Loss: 0.14645905792713165, Final Batch Loss: 0.10768302530050278\n",
      "Epoch 3183, Loss: 0.13293827325105667, Final Batch Loss: 0.06701145321130753\n",
      "Epoch 3184, Loss: 0.10237791761755943, Final Batch Loss: 0.03402978554368019\n",
      "Epoch 3185, Loss: 0.1319032497704029, Final Batch Loss: 0.07585397362709045\n",
      "Epoch 3186, Loss: 0.12905308417975903, Final Batch Loss: 0.09969271719455719\n",
      "Epoch 3187, Loss: 0.10510726645588875, Final Batch Loss: 0.043516308069229126\n",
      "Epoch 3188, Loss: 0.12026741728186607, Final Batch Loss: 0.053288403898477554\n",
      "Epoch 3189, Loss: 0.0796559751033783, Final Batch Loss: 0.04895828664302826\n",
      "Epoch 3190, Loss: 0.11079367622733116, Final Batch Loss: 0.047636646777391434\n",
      "Epoch 3191, Loss: 0.09828264638781548, Final Batch Loss: 0.05098048970103264\n",
      "Epoch 3192, Loss: 0.08641799539327621, Final Batch Loss: 0.03245437145233154\n",
      "Epoch 3193, Loss: 0.09547171741724014, Final Batch Loss: 0.02725253254175186\n",
      "Epoch 3194, Loss: 0.09145374596118927, Final Batch Loss: 0.043166711926460266\n",
      "Epoch 3195, Loss: 0.10935066640377045, Final Batch Loss: 0.06654400378465652\n",
      "Epoch 3196, Loss: 0.10025978460907936, Final Batch Loss: 0.046115435659885406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3197, Loss: 0.09156960621476173, Final Batch Loss: 0.04507826268672943\n",
      "Epoch 3198, Loss: 0.09523382410407066, Final Batch Loss: 0.03886862099170685\n",
      "Epoch 3199, Loss: 0.09441231936216354, Final Batch Loss: 0.04604356363415718\n",
      "Epoch 3200, Loss: 0.10687627270817757, Final Batch Loss: 0.049852967262268066\n",
      "Epoch 3201, Loss: 0.0979515016078949, Final Batch Loss: 0.0430116131901741\n",
      "Epoch 3202, Loss: 0.06911590695381165, Final Batch Loss: 0.009738359600305557\n",
      "Epoch 3203, Loss: 0.10777230560779572, Final Batch Loss: 0.05345935747027397\n",
      "Epoch 3204, Loss: 0.08632954955101013, Final Batch Loss: 0.04415144398808479\n",
      "Epoch 3205, Loss: 0.15165815874934196, Final Batch Loss: 0.10462899506092072\n",
      "Epoch 3206, Loss: 0.1328662857413292, Final Batch Loss: 0.04555045813322067\n",
      "Epoch 3207, Loss: 0.15428455919027328, Final Batch Loss: 0.054555125534534454\n",
      "Epoch 3208, Loss: 0.1110968329012394, Final Batch Loss: 0.05947867035865784\n",
      "Epoch 3209, Loss: 0.09512358158826828, Final Batch Loss: 0.032612040638923645\n",
      "Epoch 3210, Loss: 0.0638695266097784, Final Batch Loss: 0.01979406736791134\n",
      "Epoch 3211, Loss: 0.07210603356361389, Final Batch Loss: 0.02361806109547615\n",
      "Epoch 3212, Loss: 0.15607237815856934, Final Batch Loss: 0.0807950347661972\n",
      "Epoch 3213, Loss: 0.0810332503169775, Final Batch Loss: 0.025831496343016624\n",
      "Epoch 3214, Loss: 0.07997622434049845, Final Batch Loss: 0.009161257185041904\n",
      "Epoch 3215, Loss: 0.09471913799643517, Final Batch Loss: 0.0444304421544075\n",
      "Epoch 3216, Loss: 0.09492750838398933, Final Batch Loss: 0.04992008954286575\n",
      "Epoch 3217, Loss: 0.1287839226424694, Final Batch Loss: 0.06125417724251747\n",
      "Epoch 3218, Loss: 0.10854868963360786, Final Batch Loss: 0.06650901585817337\n",
      "Epoch 3219, Loss: 0.07889261469244957, Final Batch Loss: 0.021494150161743164\n",
      "Epoch 3220, Loss: 0.14658699929714203, Final Batch Loss: 0.059454768896102905\n",
      "Epoch 3221, Loss: 0.07757829502224922, Final Batch Loss: 0.02793693169951439\n",
      "Epoch 3222, Loss: 0.12142685428261757, Final Batch Loss: 0.08428698778152466\n",
      "Epoch 3223, Loss: 0.09858213737607002, Final Batch Loss: 0.021059799939393997\n",
      "Epoch 3224, Loss: 0.10874856263399124, Final Batch Loss: 0.06877278536558151\n",
      "Epoch 3225, Loss: 0.11015111207962036, Final Batch Loss: 0.05984911695122719\n",
      "Epoch 3226, Loss: 0.08344638347625732, Final Batch Loss: 0.03714384511113167\n",
      "Epoch 3227, Loss: 0.10478734970092773, Final Batch Loss: 0.06726843118667603\n",
      "Epoch 3228, Loss: 0.10189258679747581, Final Batch Loss: 0.05437549576163292\n",
      "Epoch 3229, Loss: 0.10903769358992577, Final Batch Loss: 0.06864546239376068\n",
      "Epoch 3230, Loss: 0.11866653338074684, Final Batch Loss: 0.06023126840591431\n",
      "Epoch 3231, Loss: 0.12598222866654396, Final Batch Loss: 0.08284264802932739\n",
      "Epoch 3232, Loss: 0.10662310943007469, Final Batch Loss: 0.06029482185840607\n",
      "Epoch 3233, Loss: 0.09665197134017944, Final Batch Loss: 0.05102088674902916\n",
      "Epoch 3234, Loss: 0.11498260125517845, Final Batch Loss: 0.06126615032553673\n",
      "Epoch 3235, Loss: 0.1185348592698574, Final Batch Loss: 0.08349577337503433\n",
      "Epoch 3236, Loss: 0.09213485941290855, Final Batch Loss: 0.052454277873039246\n",
      "Epoch 3237, Loss: 0.0806611217558384, Final Batch Loss: 0.036457426846027374\n",
      "Epoch 3238, Loss: 0.1172872744500637, Final Batch Loss: 0.07882450520992279\n",
      "Epoch 3239, Loss: 0.09933559969067574, Final Batch Loss: 0.05255862697958946\n",
      "Epoch 3240, Loss: 0.12984415143728256, Final Batch Loss: 0.050735779106616974\n",
      "Epoch 3241, Loss: 0.06721644103527069, Final Batch Loss: 0.0198698528110981\n",
      "Epoch 3242, Loss: 0.06799228675663471, Final Batch Loss: 0.02432025782763958\n",
      "Epoch 3243, Loss: 0.1349390223622322, Final Batch Loss: 0.05880514532327652\n",
      "Epoch 3244, Loss: 0.08421102538704872, Final Batch Loss: 0.04412328451871872\n",
      "Epoch 3245, Loss: 0.10701817646622658, Final Batch Loss: 0.06359925121068954\n",
      "Epoch 3246, Loss: 0.0767943374812603, Final Batch Loss: 0.01995481178164482\n",
      "Epoch 3247, Loss: 0.1304079368710518, Final Batch Loss: 0.07120590656995773\n",
      "Epoch 3248, Loss: 0.10745295509696007, Final Batch Loss: 0.05626329779624939\n",
      "Epoch 3249, Loss: 0.08968513272702694, Final Batch Loss: 0.029089076444506645\n",
      "Epoch 3250, Loss: 0.10426539182662964, Final Batch Loss: 0.02675696462392807\n",
      "Epoch 3251, Loss: 0.07305153459310532, Final Batch Loss: 0.024287164211273193\n",
      "Epoch 3252, Loss: 0.07668754830956459, Final Batch Loss: 0.028060458600521088\n",
      "Epoch 3253, Loss: 0.0878276489675045, Final Batch Loss: 0.028311368077993393\n",
      "Epoch 3254, Loss: 0.07893606647849083, Final Batch Loss: 0.04424693435430527\n",
      "Epoch 3255, Loss: 0.06143704243004322, Final Batch Loss: 0.017998265102505684\n",
      "Epoch 3256, Loss: 0.10652479901909828, Final Batch Loss: 0.048038650304079056\n",
      "Epoch 3257, Loss: 0.07861260697245598, Final Batch Loss: 0.035032693296670914\n",
      "Epoch 3258, Loss: 0.09057566151022911, Final Batch Loss: 0.03746793791651726\n",
      "Epoch 3259, Loss: 0.08945762366056442, Final Batch Loss: 0.049939218908548355\n",
      "Epoch 3260, Loss: 0.1098196730017662, Final Batch Loss: 0.06735103577375412\n",
      "Epoch 3261, Loss: 0.1039472259581089, Final Batch Loss: 0.058719880878925323\n",
      "Epoch 3262, Loss: 0.1105286292731762, Final Batch Loss: 0.062096305191516876\n",
      "Epoch 3263, Loss: 0.09342552348971367, Final Batch Loss: 0.04877506569027901\n",
      "Epoch 3264, Loss: 0.10661067813634872, Final Batch Loss: 0.053554076701402664\n",
      "Epoch 3265, Loss: 0.10553708299994469, Final Batch Loss: 0.0583830326795578\n",
      "Epoch 3266, Loss: 0.09475281089544296, Final Batch Loss: 0.03518214076757431\n",
      "Epoch 3267, Loss: 0.14794836938381195, Final Batch Loss: 0.08369570225477219\n",
      "Epoch 3268, Loss: 0.0930323414504528, Final Batch Loss: 0.03932365030050278\n",
      "Epoch 3269, Loss: 0.08572229743003845, Final Batch Loss: 0.03811284527182579\n",
      "Epoch 3270, Loss: 0.11491795256733894, Final Batch Loss: 0.05884375795722008\n",
      "Epoch 3271, Loss: 0.10067997872829437, Final Batch Loss: 0.04910700395703316\n",
      "Epoch 3272, Loss: 0.11187878996133804, Final Batch Loss: 0.06728406250476837\n",
      "Epoch 3273, Loss: 0.09517867118120193, Final Batch Loss: 0.03818168863654137\n",
      "Epoch 3274, Loss: 0.0897560864686966, Final Batch Loss: 0.0509374663233757\n",
      "Epoch 3275, Loss: 0.1184091866016388, Final Batch Loss: 0.056392550468444824\n",
      "Epoch 3276, Loss: 0.09572732076048851, Final Batch Loss: 0.033403705805540085\n",
      "Epoch 3277, Loss: 0.126042228192091, Final Batch Loss: 0.06665470451116562\n",
      "Epoch 3278, Loss: 0.11807337030768394, Final Batch Loss: 0.04389289394021034\n",
      "Epoch 3279, Loss: 0.16052736341953278, Final Batch Loss: 0.12501901388168335\n",
      "Epoch 3280, Loss: 0.12050919979810715, Final Batch Loss: 0.07141002267599106\n",
      "Epoch 3281, Loss: 0.10465247184038162, Final Batch Loss: 0.048215288668870926\n",
      "Epoch 3282, Loss: 0.10467987507581711, Final Batch Loss: 0.047134414315223694\n",
      "Epoch 3283, Loss: 0.13961508870124817, Final Batch Loss: 0.0849672332406044\n",
      "Epoch 3284, Loss: 0.09051603451371193, Final Batch Loss: 0.04988185316324234\n",
      "Epoch 3285, Loss: 0.10926106944680214, Final Batch Loss: 0.07323838025331497\n",
      "Epoch 3286, Loss: 0.0894666537642479, Final Batch Loss: 0.03892863541841507\n",
      "Epoch 3287, Loss: 0.079623868688941, Final Batch Loss: 0.02946150116622448\n",
      "Epoch 3288, Loss: 0.09610434994101524, Final Batch Loss: 0.04736625403165817\n",
      "Epoch 3289, Loss: 0.13840848207473755, Final Batch Loss: 0.0693773701786995\n",
      "Epoch 3290, Loss: 0.07810219936072826, Final Batch Loss: 0.01678604446351528\n",
      "Epoch 3291, Loss: 0.07475499622523785, Final Batch Loss: 0.017348801717162132\n",
      "Epoch 3292, Loss: 0.10942161455750465, Final Batch Loss: 0.05038320645689964\n",
      "Epoch 3293, Loss: 0.09165481850504875, Final Batch Loss: 0.04719054698944092\n",
      "Epoch 3294, Loss: 0.07828681170940399, Final Batch Loss: 0.032450079917907715\n",
      "Epoch 3295, Loss: 0.09052568674087524, Final Batch Loss: 0.03934406861662865\n",
      "Epoch 3296, Loss: 0.08210544288158417, Final Batch Loss: 0.03433699905872345\n",
      "Epoch 3297, Loss: 0.11262789368629456, Final Batch Loss: 0.037799105048179626\n",
      "Epoch 3298, Loss: 0.13799050450325012, Final Batch Loss: 0.08344203978776932\n",
      "Epoch 3299, Loss: 0.11627937853336334, Final Batch Loss: 0.047817207872867584\n",
      "Epoch 3300, Loss: 0.09854380786418915, Final Batch Loss: 0.047606177628040314\n",
      "Epoch 3301, Loss: 0.09528777375817299, Final Batch Loss: 0.027683716267347336\n",
      "Epoch 3302, Loss: 0.12150207534432411, Final Batch Loss: 0.04478324577212334\n",
      "Epoch 3303, Loss: 0.08081100881099701, Final Batch Loss: 0.0340149812400341\n",
      "Epoch 3304, Loss: 0.09898701682686806, Final Batch Loss: 0.0709393247961998\n",
      "Epoch 3305, Loss: 0.11666262149810791, Final Batch Loss: 0.06625588983297348\n",
      "Epoch 3306, Loss: 0.0953388661146164, Final Batch Loss: 0.04723304137587547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3307, Loss: 0.0704607330262661, Final Batch Loss: 0.024721190333366394\n",
      "Epoch 3308, Loss: 0.09066560491919518, Final Batch Loss: 0.05128943920135498\n",
      "Epoch 3309, Loss: 0.24284160882234573, Final Batch Loss: 0.05086708813905716\n",
      "Epoch 3310, Loss: 0.09359722211956978, Final Batch Loss: 0.04535512626171112\n",
      "Epoch 3311, Loss: 0.09988795593380928, Final Batch Loss: 0.04914205148816109\n",
      "Epoch 3312, Loss: 0.10347742214798927, Final Batch Loss: 0.03372245654463768\n",
      "Epoch 3313, Loss: 0.08925885148346424, Final Batch Loss: 0.022962139919400215\n",
      "Epoch 3314, Loss: 0.1039254330098629, Final Batch Loss: 0.04797227308154106\n",
      "Epoch 3315, Loss: 0.1242797002196312, Final Batch Loss: 0.06765428930521011\n",
      "Epoch 3316, Loss: 0.0819505900144577, Final Batch Loss: 0.033300623297691345\n",
      "Epoch 3317, Loss: 0.08956507220864296, Final Batch Loss: 0.041704609990119934\n",
      "Epoch 3318, Loss: 0.11266457289457321, Final Batch Loss: 0.07506955415010452\n",
      "Epoch 3319, Loss: 0.13182980194687843, Final Batch Loss: 0.07805114984512329\n",
      "Epoch 3320, Loss: 0.08055994287133217, Final Batch Loss: 0.04959661513566971\n",
      "Epoch 3321, Loss: 0.11954910308122635, Final Batch Loss: 0.08637688308954239\n",
      "Epoch 3322, Loss: 0.08999159559607506, Final Batch Loss: 0.04694419726729393\n",
      "Epoch 3323, Loss: 0.08477267250418663, Final Batch Loss: 0.03905152902007103\n",
      "Epoch 3324, Loss: 0.0904681533575058, Final Batch Loss: 0.04464830458164215\n",
      "Epoch 3325, Loss: 0.09858839586377144, Final Batch Loss: 0.049834366887807846\n",
      "Epoch 3326, Loss: 0.10756908729672432, Final Batch Loss: 0.040685687214136124\n",
      "Epoch 3327, Loss: 0.1446537934243679, Final Batch Loss: 0.03628269210457802\n",
      "Epoch 3328, Loss: 0.07675687223672867, Final Batch Loss: 0.03152618929743767\n",
      "Epoch 3329, Loss: 0.12887701392173767, Final Batch Loss: 0.06782183796167374\n",
      "Epoch 3330, Loss: 0.10510386526584625, Final Batch Loss: 0.05634903162717819\n",
      "Epoch 3331, Loss: 0.08420080319046974, Final Batch Loss: 0.03659861907362938\n",
      "Epoch 3332, Loss: 0.07661129906773567, Final Batch Loss: 0.02305414527654648\n",
      "Epoch 3333, Loss: 0.19787583500146866, Final Batch Loss: 0.12005351483821869\n",
      "Epoch 3334, Loss: 0.1553797461092472, Final Batch Loss: 0.11694374680519104\n",
      "Epoch 3335, Loss: 0.09804466366767883, Final Batch Loss: 0.05126998946070671\n",
      "Epoch 3336, Loss: 0.09193628653883934, Final Batch Loss: 0.04421883821487427\n",
      "Epoch 3337, Loss: 0.10441580414772034, Final Batch Loss: 0.035397760570049286\n",
      "Epoch 3338, Loss: 0.14409003034234047, Final Batch Loss: 0.05975164845585823\n",
      "Epoch 3339, Loss: 0.09448433667421341, Final Batch Loss: 0.0475425161421299\n",
      "Epoch 3340, Loss: 0.09637944400310516, Final Batch Loss: 0.044368159025907516\n",
      "Epoch 3341, Loss: 0.14179707877337933, Final Batch Loss: 0.030887296423316002\n",
      "Epoch 3342, Loss: 0.0848952867090702, Final Batch Loss: 0.0369693785905838\n",
      "Epoch 3343, Loss: 0.11854248493909836, Final Batch Loss: 0.06821631640195847\n",
      "Epoch 3344, Loss: 0.13713889569044113, Final Batch Loss: 0.049615636467933655\n",
      "Epoch 3345, Loss: 0.0919986292719841, Final Batch Loss: 0.0423499159514904\n",
      "Epoch 3346, Loss: 0.12289243936538696, Final Batch Loss: 0.0767655298113823\n",
      "Epoch 3347, Loss: 0.11650517210364342, Final Batch Loss: 0.044297847896814346\n",
      "Epoch 3348, Loss: 0.16272224485874176, Final Batch Loss: 0.12081470340490341\n",
      "Epoch 3349, Loss: 0.16154608130455017, Final Batch Loss: 0.08237587660551071\n",
      "Epoch 3350, Loss: 0.09621777012944221, Final Batch Loss: 0.06294771283864975\n",
      "Epoch 3351, Loss: 0.11633254215121269, Final Batch Loss: 0.033727195113897324\n",
      "Epoch 3352, Loss: 0.09591100364923477, Final Batch Loss: 0.04680856317281723\n",
      "Epoch 3353, Loss: 0.09267155081033707, Final Batch Loss: 0.037484824657440186\n",
      "Epoch 3354, Loss: 0.08715193718671799, Final Batch Loss: 0.04673582687973976\n",
      "Epoch 3355, Loss: 0.0965871512889862, Final Batch Loss: 0.06409332901239395\n",
      "Epoch 3356, Loss: 0.11832873523235321, Final Batch Loss: 0.06702261418104172\n",
      "Epoch 3357, Loss: 0.06364994496107101, Final Batch Loss: 0.02000480517745018\n",
      "Epoch 3358, Loss: 0.0839475467801094, Final Batch Loss: 0.024012893438339233\n",
      "Epoch 3359, Loss: 0.14101596921682358, Final Batch Loss: 0.05335405468940735\n",
      "Epoch 3360, Loss: 0.08929059654474258, Final Batch Loss: 0.023502543568611145\n",
      "Epoch 3361, Loss: 0.14798175543546677, Final Batch Loss: 0.07960589230060577\n",
      "Epoch 3362, Loss: 0.07267661392688751, Final Batch Loss: 0.03278210014104843\n",
      "Epoch 3363, Loss: 0.3180864080786705, Final Batch Loss: 0.2675553858280182\n",
      "Epoch 3364, Loss: 0.12131038308143616, Final Batch Loss: 0.05884362757205963\n",
      "Epoch 3365, Loss: 0.15080387890338898, Final Batch Loss: 0.0966353714466095\n",
      "Epoch 3366, Loss: 0.08298928290605545, Final Batch Loss: 0.04136691614985466\n",
      "Epoch 3367, Loss: 0.18954620137810707, Final Batch Loss: 0.04450691118836403\n",
      "Epoch 3368, Loss: 0.1570153757929802, Final Batch Loss: 0.03888312727212906\n",
      "Epoch 3369, Loss: 0.12693141773343086, Final Batch Loss: 0.05450969561934471\n",
      "Epoch 3370, Loss: 0.09125542268157005, Final Batch Loss: 0.03339899331331253\n",
      "Epoch 3371, Loss: 0.1280003935098648, Final Batch Loss: 0.06538212299346924\n",
      "Epoch 3372, Loss: 0.09194056503474712, Final Batch Loss: 0.026009036228060722\n",
      "Epoch 3373, Loss: 0.13688526675105095, Final Batch Loss: 0.052431900054216385\n",
      "Epoch 3374, Loss: 0.2121218666434288, Final Batch Loss: 0.13958720862865448\n",
      "Epoch 3375, Loss: 0.09732725098729134, Final Batch Loss: 0.04534753039479256\n",
      "Epoch 3376, Loss: 0.11625131964683533, Final Batch Loss: 0.04759699106216431\n",
      "Epoch 3377, Loss: 0.17175371199846268, Final Batch Loss: 0.0730624794960022\n",
      "Epoch 3378, Loss: 0.14905910938978195, Final Batch Loss: 0.07948540896177292\n",
      "Epoch 3379, Loss: 0.11165551468729973, Final Batch Loss: 0.06416743993759155\n",
      "Epoch 3380, Loss: 0.08091162517666817, Final Batch Loss: 0.03414023667573929\n",
      "Epoch 3381, Loss: 0.13866442814469337, Final Batch Loss: 0.09333839267492294\n",
      "Epoch 3382, Loss: 0.14916691929101944, Final Batch Loss: 0.07281806319952011\n",
      "Epoch 3383, Loss: 0.11112506315112114, Final Batch Loss: 0.04315945878624916\n",
      "Epoch 3384, Loss: 0.13476059585809708, Final Batch Loss: 0.06555920094251633\n",
      "Epoch 3385, Loss: 0.16316557675600052, Final Batch Loss: 0.10700958222150803\n",
      "Epoch 3386, Loss: 0.13507892936468124, Final Batch Loss: 0.06613964587450027\n",
      "Epoch 3387, Loss: 0.11455650627613068, Final Batch Loss: 0.05847819894552231\n",
      "Epoch 3388, Loss: 0.10269944369792938, Final Batch Loss: 0.050578124821186066\n",
      "Epoch 3389, Loss: 0.08869141340255737, Final Batch Loss: 0.04412752017378807\n",
      "Epoch 3390, Loss: 0.09725615754723549, Final Batch Loss: 0.040404170751571655\n",
      "Epoch 3391, Loss: 0.17298344522714615, Final Batch Loss: 0.10141442716121674\n",
      "Epoch 3392, Loss: 0.11323105543851852, Final Batch Loss: 0.03563456982374191\n",
      "Epoch 3393, Loss: 0.09922807663679123, Final Batch Loss: 0.04017971456050873\n",
      "Epoch 3394, Loss: 0.07113778032362461, Final Batch Loss: 0.017153529450297356\n",
      "Epoch 3395, Loss: 0.12077414989471436, Final Batch Loss: 0.05787195265293121\n",
      "Epoch 3396, Loss: 0.09594946354627609, Final Batch Loss: 0.054473329335451126\n",
      "Epoch 3397, Loss: 0.08513211086392403, Final Batch Loss: 0.050767287611961365\n",
      "Epoch 3398, Loss: 0.10699111595749855, Final Batch Loss: 0.07945098727941513\n",
      "Epoch 3399, Loss: 0.11531765013933182, Final Batch Loss: 0.06448281556367874\n",
      "Epoch 3400, Loss: 0.1085742898285389, Final Batch Loss: 0.06438572704792023\n",
      "Epoch 3401, Loss: 0.0764559768140316, Final Batch Loss: 0.03417070955038071\n",
      "Epoch 3402, Loss: 0.10742959380149841, Final Batch Loss: 0.0637112706899643\n",
      "Epoch 3403, Loss: 0.11355520039796829, Final Batch Loss: 0.07810597866773605\n",
      "Epoch 3404, Loss: 0.06673190463334322, Final Batch Loss: 0.014982649125158787\n",
      "Epoch 3405, Loss: 0.09821567684412003, Final Batch Loss: 0.05525873601436615\n",
      "Epoch 3406, Loss: 0.08266601711511612, Final Batch Loss: 0.0325363464653492\n",
      "Epoch 3407, Loss: 0.08939472958445549, Final Batch Loss: 0.038473114371299744\n",
      "Epoch 3408, Loss: 0.08611869812011719, Final Batch Loss: 0.04558981582522392\n",
      "Epoch 3409, Loss: 0.1157064139842987, Final Batch Loss: 0.05486974120140076\n",
      "Epoch 3410, Loss: 0.1960761435329914, Final Batch Loss: 0.1508176624774933\n",
      "Epoch 3411, Loss: 0.08817962557077408, Final Batch Loss: 0.039850879460573196\n",
      "Epoch 3412, Loss: 0.09095028042793274, Final Batch Loss: 0.0440051332116127\n",
      "Epoch 3413, Loss: 0.07709814608097076, Final Batch Loss: 0.02142694592475891\n",
      "Epoch 3414, Loss: 0.10421749576926231, Final Batch Loss: 0.058828551322221756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3415, Loss: 0.1539042443037033, Final Batch Loss: 0.06929837167263031\n",
      "Epoch 3416, Loss: 0.08358432166278362, Final Batch Loss: 0.025347338989377022\n",
      "Epoch 3417, Loss: 0.11897072941064835, Final Batch Loss: 0.088821180164814\n",
      "Epoch 3418, Loss: 0.11499505117535591, Final Batch Loss: 0.06964822113513947\n",
      "Epoch 3419, Loss: 0.08926146104931831, Final Batch Loss: 0.04152067378163338\n",
      "Epoch 3420, Loss: 0.12116259150207043, Final Batch Loss: 0.09024304896593094\n",
      "Epoch 3421, Loss: 0.08527279831469059, Final Batch Loss: 0.05403043329715729\n",
      "Epoch 3422, Loss: 0.10376482829451561, Final Batch Loss: 0.0513458177447319\n",
      "Epoch 3423, Loss: 0.14504963159561157, Final Batch Loss: 0.1043490543961525\n",
      "Epoch 3424, Loss: 0.1188163012266159, Final Batch Loss: 0.0743103176355362\n",
      "Epoch 3425, Loss: 0.09891089797019958, Final Batch Loss: 0.04203202947974205\n",
      "Epoch 3426, Loss: 0.11369415372610092, Final Batch Loss: 0.07489737123250961\n",
      "Epoch 3427, Loss: 0.09275796264410019, Final Batch Loss: 0.05164617672562599\n",
      "Epoch 3428, Loss: 0.0744333490729332, Final Batch Loss: 0.028713639825582504\n",
      "Epoch 3429, Loss: 0.10040836036205292, Final Batch Loss: 0.03735163062810898\n",
      "Epoch 3430, Loss: 0.08610149845480919, Final Batch Loss: 0.025451332330703735\n",
      "Epoch 3431, Loss: 0.0839659683406353, Final Batch Loss: 0.04856095090508461\n",
      "Epoch 3432, Loss: 0.10742446407675743, Final Batch Loss: 0.05874377489089966\n",
      "Epoch 3433, Loss: 0.16910094767808914, Final Batch Loss: 0.11067906022071838\n",
      "Epoch 3434, Loss: 0.12205072864890099, Final Batch Loss: 0.05566610023379326\n",
      "Epoch 3435, Loss: 0.1078115738928318, Final Batch Loss: 0.0713469460606575\n",
      "Epoch 3436, Loss: 0.11567996442317963, Final Batch Loss: 0.0591309554874897\n",
      "Epoch 3437, Loss: 0.09915710240602493, Final Batch Loss: 0.03605598956346512\n",
      "Epoch 3438, Loss: 0.10465504974126816, Final Batch Loss: 0.060242000967264175\n",
      "Epoch 3439, Loss: 0.09776323661208153, Final Batch Loss: 0.04787367209792137\n",
      "Epoch 3440, Loss: 0.13720804452896118, Final Batch Loss: 0.07267870754003525\n",
      "Epoch 3441, Loss: 0.08256549015641212, Final Batch Loss: 0.03590555861592293\n",
      "Epoch 3442, Loss: 0.13103505223989487, Final Batch Loss: 0.09464485943317413\n",
      "Epoch 3443, Loss: 0.10116081312298775, Final Batch Loss: 0.05576036125421524\n",
      "Epoch 3444, Loss: 0.13797682896256447, Final Batch Loss: 0.037239108234643936\n",
      "Epoch 3445, Loss: 0.12466073408722878, Final Batch Loss: 0.07510808110237122\n",
      "Epoch 3446, Loss: 0.09899209067225456, Final Batch Loss: 0.05272882804274559\n",
      "Epoch 3447, Loss: 0.08014034107327461, Final Batch Loss: 0.045159049332141876\n",
      "Epoch 3448, Loss: 0.09725025296211243, Final Batch Loss: 0.043824177235364914\n",
      "Epoch 3449, Loss: 0.08598528057336807, Final Batch Loss: 0.04879650101065636\n",
      "Epoch 3450, Loss: 0.09408400021493435, Final Batch Loss: 0.026750652119517326\n",
      "Epoch 3451, Loss: 0.11530141159892082, Final Batch Loss: 0.0596063956618309\n",
      "Epoch 3452, Loss: 0.16041406244039536, Final Batch Loss: 0.12605847418308258\n",
      "Epoch 3453, Loss: 0.12901262193918228, Final Batch Loss: 0.05952734500169754\n",
      "Epoch 3454, Loss: 0.09847064688801765, Final Batch Loss: 0.04397926479578018\n",
      "Epoch 3455, Loss: 0.11692926287651062, Final Batch Loss: 0.07757885754108429\n",
      "Epoch 3456, Loss: 0.09709985181689262, Final Batch Loss: 0.048726119101047516\n",
      "Epoch 3457, Loss: 0.10980359464883804, Final Batch Loss: 0.04050735384225845\n",
      "Epoch 3458, Loss: 0.10144630074501038, Final Batch Loss: 0.06215421482920647\n",
      "Epoch 3459, Loss: 0.10909679532051086, Final Batch Loss: 0.05429864302277565\n",
      "Epoch 3460, Loss: 0.08459705114364624, Final Batch Loss: 0.04393678903579712\n",
      "Epoch 3461, Loss: 0.09006073698401451, Final Batch Loss: 0.03152043744921684\n",
      "Epoch 3462, Loss: 0.08165355399250984, Final Batch Loss: 0.024449996650218964\n",
      "Epoch 3463, Loss: 0.0981222540140152, Final Batch Loss: 0.0573401004076004\n",
      "Epoch 3464, Loss: 0.10534817352890968, Final Batch Loss: 0.06569019705057144\n",
      "Epoch 3465, Loss: 0.07980064675211906, Final Batch Loss: 0.03783333674073219\n",
      "Epoch 3466, Loss: 0.09490112587809563, Final Batch Loss: 0.04194916412234306\n",
      "Epoch 3467, Loss: 0.08207035809755325, Final Batch Loss: 0.019717104732990265\n",
      "Epoch 3468, Loss: 0.09729287028312683, Final Batch Loss: 0.04729675129055977\n",
      "Epoch 3469, Loss: 0.12467730417847633, Final Batch Loss: 0.0824485644698143\n",
      "Epoch 3470, Loss: 0.11585614830255508, Final Batch Loss: 0.07540837675333023\n",
      "Epoch 3471, Loss: 0.08358363807201385, Final Batch Loss: 0.037541020661592484\n",
      "Epoch 3472, Loss: 0.08905741199851036, Final Batch Loss: 0.043022606521844864\n",
      "Epoch 3473, Loss: 0.06298166327178478, Final Batch Loss: 0.022684799507260323\n",
      "Epoch 3474, Loss: 0.07183332554996014, Final Batch Loss: 0.02656668983399868\n",
      "Epoch 3475, Loss: 0.0549591239541769, Final Batch Loss: 0.02459937147796154\n",
      "Epoch 3476, Loss: 0.08303682133555412, Final Batch Loss: 0.05106667801737785\n",
      "Epoch 3477, Loss: 0.12167930603027344, Final Batch Loss: 0.0658777728676796\n",
      "Epoch 3478, Loss: 0.12242230400443077, Final Batch Loss: 0.08926291763782501\n",
      "Epoch 3479, Loss: 0.0969432033598423, Final Batch Loss: 0.05918591096997261\n",
      "Epoch 3480, Loss: 0.09089609980583191, Final Batch Loss: 0.03938557207584381\n",
      "Epoch 3481, Loss: 0.10469046980142593, Final Batch Loss: 0.048746269196271896\n",
      "Epoch 3482, Loss: 0.08092902600765228, Final Batch Loss: 0.025864947587251663\n",
      "Epoch 3483, Loss: 0.08650821074843407, Final Batch Loss: 0.04377403110265732\n",
      "Epoch 3484, Loss: 0.10376192815601826, Final Batch Loss: 0.02950463630259037\n",
      "Epoch 3485, Loss: 0.21099305897951126, Final Batch Loss: 0.062144242227077484\n",
      "Epoch 3486, Loss: 0.06910999491810799, Final Batch Loss: 0.034364454448223114\n",
      "Epoch 3487, Loss: 0.08065776340663433, Final Batch Loss: 0.031020386144518852\n",
      "Epoch 3488, Loss: 0.08325468003749847, Final Batch Loss: 0.03985873609781265\n",
      "Epoch 3489, Loss: 0.15453661233186722, Final Batch Loss: 0.08860458433628082\n",
      "Epoch 3490, Loss: 0.13282140716910362, Final Batch Loss: 0.07171088457107544\n",
      "Epoch 3491, Loss: 0.11386720091104507, Final Batch Loss: 0.06890115141868591\n",
      "Epoch 3492, Loss: 0.09411714598536491, Final Batch Loss: 0.0466962605714798\n",
      "Epoch 3493, Loss: 0.08854401484131813, Final Batch Loss: 0.03927438333630562\n",
      "Epoch 3494, Loss: 0.10150574892759323, Final Batch Loss: 0.060045283287763596\n",
      "Epoch 3495, Loss: 0.1309310831129551, Final Batch Loss: 0.052229609340429306\n",
      "Epoch 3496, Loss: 0.0762028880417347, Final Batch Loss: 0.04110347479581833\n",
      "Epoch 3497, Loss: 0.1172378920018673, Final Batch Loss: 0.04342160001397133\n",
      "Epoch 3498, Loss: 0.11174445226788521, Final Batch Loss: 0.07890404760837555\n",
      "Epoch 3499, Loss: 0.09434424340724945, Final Batch Loss: 0.041802216321229935\n",
      "Epoch 3500, Loss: 0.08904046937823296, Final Batch Loss: 0.049143631011247635\n",
      "Epoch 3501, Loss: 0.07888690754771233, Final Batch Loss: 0.03358292207121849\n",
      "Epoch 3502, Loss: 0.1202915869653225, Final Batch Loss: 0.07102766633033752\n",
      "Epoch 3503, Loss: 0.11651007831096649, Final Batch Loss: 0.06754876673221588\n",
      "Epoch 3504, Loss: 0.0736852902919054, Final Batch Loss: 0.019319193437695503\n",
      "Epoch 3505, Loss: 0.10478897020220757, Final Batch Loss: 0.05649644881486893\n",
      "Epoch 3506, Loss: 0.10155210271477699, Final Batch Loss: 0.05029984936118126\n",
      "Epoch 3507, Loss: 0.10891714692115784, Final Batch Loss: 0.047893866896629333\n",
      "Epoch 3508, Loss: 0.10398735664784908, Final Batch Loss: 0.07548584043979645\n",
      "Epoch 3509, Loss: 0.07203180715441704, Final Batch Loss: 0.03359777852892876\n",
      "Epoch 3510, Loss: 0.08321424573659897, Final Batch Loss: 0.048026710748672485\n",
      "Epoch 3511, Loss: 0.1070278212428093, Final Batch Loss: 0.04610338807106018\n",
      "Epoch 3512, Loss: 0.07086524367332458, Final Batch Loss: 0.028149545192718506\n",
      "Epoch 3513, Loss: 0.08057944849133492, Final Batch Loss: 0.03966570645570755\n",
      "Epoch 3514, Loss: 0.09494158439338207, Final Batch Loss: 0.0661759078502655\n",
      "Epoch 3515, Loss: 0.0804261602461338, Final Batch Loss: 0.04242841526865959\n",
      "Epoch 3516, Loss: 0.08006729558110237, Final Batch Loss: 0.035349659621715546\n",
      "Epoch 3517, Loss: 0.09242554381489754, Final Batch Loss: 0.037948060780763626\n",
      "Epoch 3518, Loss: 0.09937114268541336, Final Batch Loss: 0.04257588088512421\n",
      "Epoch 3519, Loss: 0.10066607221961021, Final Batch Loss: 0.057222332805395126\n",
      "Epoch 3520, Loss: 0.09073181077837944, Final Batch Loss: 0.054736074060201645\n",
      "Epoch 3521, Loss: 0.07468793168663979, Final Batch Loss: 0.03027903288602829\n",
      "Epoch 3522, Loss: 0.08182518556714058, Final Batch Loss: 0.04497160390019417\n",
      "Epoch 3523, Loss: 0.09836225211620331, Final Batch Loss: 0.019107572734355927\n",
      "Epoch 3524, Loss: 0.06818079575896263, Final Batch Loss: 0.03118858113884926\n",
      "Epoch 3525, Loss: 0.1052623875439167, Final Batch Loss: 0.04957374185323715\n",
      "Epoch 3526, Loss: 0.07041569985449314, Final Batch Loss: 0.030681679025292397\n",
      "Epoch 3527, Loss: 0.07024189457297325, Final Batch Loss: 0.03389129042625427\n",
      "Epoch 3528, Loss: 0.11320700496435165, Final Batch Loss: 0.05769997090101242\n",
      "Epoch 3529, Loss: 0.07483108341693878, Final Batch Loss: 0.03632368519902229\n",
      "Epoch 3530, Loss: 0.13333413004875183, Final Batch Loss: 0.09823714941740036\n",
      "Epoch 3531, Loss: 0.11090711690485477, Final Batch Loss: 0.08970499783754349\n",
      "Epoch 3532, Loss: 0.07243631780147552, Final Batch Loss: 0.03771565109491348\n",
      "Epoch 3533, Loss: 0.05922294035553932, Final Batch Loss: 0.023608554154634476\n",
      "Epoch 3534, Loss: 0.08854392543435097, Final Batch Loss: 0.051653631031513214\n",
      "Epoch 3535, Loss: 0.08163255639374256, Final Batch Loss: 0.026060381904244423\n",
      "Epoch 3536, Loss: 0.08525757491588593, Final Batch Loss: 0.05005834996700287\n",
      "Epoch 3537, Loss: 0.08925140649080276, Final Batch Loss: 0.03559822961688042\n",
      "Epoch 3538, Loss: 0.16366937011480331, Final Batch Loss: 0.09690902382135391\n",
      "Epoch 3539, Loss: 0.08741454407572746, Final Batch Loss: 0.016030576080083847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3540, Loss: 0.09580815210938454, Final Batch Loss: 0.06180323287844658\n",
      "Epoch 3541, Loss: 0.0945662185549736, Final Batch Loss: 0.03705355525016785\n",
      "Epoch 3542, Loss: 0.08548973128199577, Final Batch Loss: 0.04631315544247627\n",
      "Epoch 3543, Loss: 0.08064914494752884, Final Batch Loss: 0.026863154023885727\n",
      "Epoch 3544, Loss: 0.10380277037620544, Final Batch Loss: 0.06110834330320358\n",
      "Epoch 3545, Loss: 0.15591013431549072, Final Batch Loss: 0.045075833797454834\n",
      "Epoch 3546, Loss: 0.08418705500662327, Final Batch Loss: 0.05403531715273857\n",
      "Epoch 3547, Loss: 0.10271227732300758, Final Batch Loss: 0.06335136294364929\n",
      "Epoch 3548, Loss: 0.07852798700332642, Final Batch Loss: 0.04011245444417\n",
      "Epoch 3549, Loss: 0.08720880001783371, Final Batch Loss: 0.0638696625828743\n",
      "Epoch 3550, Loss: 0.09594916552305222, Final Batch Loss: 0.042381398379802704\n",
      "Epoch 3551, Loss: 0.05867638252675533, Final Batch Loss: 0.019196892157197\n",
      "Epoch 3552, Loss: 0.08693136647343636, Final Batch Loss: 0.04062286764383316\n",
      "Epoch 3553, Loss: 0.08724777773022652, Final Batch Loss: 0.0462740920484066\n",
      "Epoch 3554, Loss: 0.11269933730363846, Final Batch Loss: 0.07067201286554337\n",
      "Epoch 3555, Loss: 0.08369286730885506, Final Batch Loss: 0.020653527230024338\n",
      "Epoch 3556, Loss: 0.09938488900661469, Final Batch Loss: 0.05670248717069626\n",
      "Epoch 3557, Loss: 0.0976848155260086, Final Batch Loss: 0.050373949110507965\n",
      "Epoch 3558, Loss: 0.09831024333834648, Final Batch Loss: 0.06488414108753204\n",
      "Epoch 3559, Loss: 0.0978136770427227, Final Batch Loss: 0.037607066333293915\n",
      "Epoch 3560, Loss: 0.06924921926110983, Final Batch Loss: 0.01424186211079359\n",
      "Epoch 3561, Loss: 0.09018593281507492, Final Batch Loss: 0.03871443122625351\n",
      "Epoch 3562, Loss: 0.07263841107487679, Final Batch Loss: 0.03306696563959122\n",
      "Epoch 3563, Loss: 0.07466884329915047, Final Batch Loss: 0.03640034422278404\n",
      "Epoch 3564, Loss: 0.056857047602534294, Final Batch Loss: 0.025867268443107605\n",
      "Epoch 3565, Loss: 0.06822777166962624, Final Batch Loss: 0.03282862901687622\n",
      "Epoch 3566, Loss: 0.06181124038994312, Final Batch Loss: 0.02911953814327717\n",
      "Epoch 3567, Loss: 0.07110403850674629, Final Batch Loss: 0.025889232754707336\n",
      "Epoch 3568, Loss: 0.06907183863222599, Final Batch Loss: 0.0240043792873621\n",
      "Epoch 3569, Loss: 0.12153037637472153, Final Batch Loss: 0.07640793174505234\n",
      "Epoch 3570, Loss: 0.09084226191043854, Final Batch Loss: 0.045012373477220535\n",
      "Epoch 3571, Loss: 0.223402239382267, Final Batch Loss: 0.15777868032455444\n",
      "Epoch 3572, Loss: 0.0962216816842556, Final Batch Loss: 0.05768962204456329\n",
      "Epoch 3573, Loss: 0.08379256725311279, Final Batch Loss: 0.050180211663246155\n",
      "Epoch 3574, Loss: 0.07698462903499603, Final Batch Loss: 0.03502136841416359\n",
      "Epoch 3575, Loss: 0.17079729586839676, Final Batch Loss: 0.13341739773750305\n",
      "Epoch 3576, Loss: 0.08844253048300743, Final Batch Loss: 0.03898560255765915\n",
      "Epoch 3577, Loss: 0.08407807722687721, Final Batch Loss: 0.018851373344659805\n",
      "Epoch 3578, Loss: 0.09418846480548382, Final Batch Loss: 0.020228711888194084\n",
      "Epoch 3579, Loss: 0.08965941518545151, Final Batch Loss: 0.025304071605205536\n",
      "Epoch 3580, Loss: 0.11529169976711273, Final Batch Loss: 0.04038769006729126\n",
      "Epoch 3581, Loss: 0.08166936784982681, Final Batch Loss: 0.03754488751292229\n",
      "Epoch 3582, Loss: 0.0745274517685175, Final Batch Loss: 0.024807961657643318\n",
      "Epoch 3583, Loss: 0.11869686469435692, Final Batch Loss: 0.047163691371679306\n",
      "Epoch 3584, Loss: 0.09542232751846313, Final Batch Loss: 0.045846808701753616\n",
      "Epoch 3585, Loss: 0.08597720228135586, Final Batch Loss: 0.018398961052298546\n",
      "Epoch 3586, Loss: 0.12146452814340591, Final Batch Loss: 0.07727526128292084\n",
      "Epoch 3587, Loss: 0.12333348393440247, Final Batch Loss: 0.08026700466871262\n",
      "Epoch 3588, Loss: 0.08694678917527199, Final Batch Loss: 0.03378159925341606\n",
      "Epoch 3589, Loss: 0.0913252905011177, Final Batch Loss: 0.04686330258846283\n",
      "Epoch 3590, Loss: 0.07638472504913807, Final Batch Loss: 0.028921985998749733\n",
      "Epoch 3591, Loss: 0.08801471069455147, Final Batch Loss: 0.0390680655837059\n",
      "Epoch 3592, Loss: 0.06630131788551807, Final Batch Loss: 0.013800794258713722\n",
      "Epoch 3593, Loss: 0.1225050762295723, Final Batch Loss: 0.04697791486978531\n",
      "Epoch 3594, Loss: 0.09734749794006348, Final Batch Loss: 0.0622999370098114\n",
      "Epoch 3595, Loss: 0.12129033356904984, Final Batch Loss: 0.07304364442825317\n",
      "Epoch 3596, Loss: 0.08288943022489548, Final Batch Loss: 0.029415607452392578\n",
      "Epoch 3597, Loss: 0.07792376168072224, Final Batch Loss: 0.026846228167414665\n",
      "Epoch 3598, Loss: 0.08906767889857292, Final Batch Loss: 0.03884128853678703\n",
      "Epoch 3599, Loss: 0.07102042995393276, Final Batch Loss: 0.02515971101820469\n",
      "Epoch 3600, Loss: 0.09685341082513332, Final Batch Loss: 0.06579922139644623\n",
      "Epoch 3601, Loss: 0.08092207461595535, Final Batch Loss: 0.04748985543847084\n",
      "Epoch 3602, Loss: 0.09082407504320145, Final Batch Loss: 0.04844813793897629\n",
      "Epoch 3603, Loss: 0.08802035078406334, Final Batch Loss: 0.057888686656951904\n",
      "Epoch 3604, Loss: 0.08879578858613968, Final Batch Loss: 0.04715826362371445\n",
      "Epoch 3605, Loss: 0.11333713307976723, Final Batch Loss: 0.08158574253320694\n",
      "Epoch 3606, Loss: 0.08887706510722637, Final Batch Loss: 0.06122402846813202\n",
      "Epoch 3607, Loss: 0.07293753325939178, Final Batch Loss: 0.025735877454280853\n",
      "Epoch 3608, Loss: 0.07774107716977596, Final Batch Loss: 0.016506990417838097\n",
      "Epoch 3609, Loss: 0.10032887756824493, Final Batch Loss: 0.05762623995542526\n",
      "Epoch 3610, Loss: 0.08355857990682125, Final Batch Loss: 0.029947297647595406\n",
      "Epoch 3611, Loss: 0.07099282555282116, Final Batch Loss: 0.025331726297736168\n",
      "Epoch 3612, Loss: 0.08889245986938477, Final Batch Loss: 0.03835741803050041\n",
      "Epoch 3613, Loss: 0.09554913640022278, Final Batch Loss: 0.052439190447330475\n",
      "Epoch 3614, Loss: 0.08282111771404743, Final Batch Loss: 0.02683747000992298\n",
      "Epoch 3615, Loss: 0.10151622071862221, Final Batch Loss: 0.051481831818819046\n",
      "Epoch 3616, Loss: 0.11153260990977287, Final Batch Loss: 0.06894899904727936\n",
      "Epoch 3617, Loss: 0.06377041153609753, Final Batch Loss: 0.03315731883049011\n",
      "Epoch 3618, Loss: 0.11384586617350578, Final Batch Loss: 0.05522472783923149\n",
      "Epoch 3619, Loss: 0.1190369576215744, Final Batch Loss: 0.050240129232406616\n",
      "Epoch 3620, Loss: 0.08130883798003197, Final Batch Loss: 0.03173234313726425\n",
      "Epoch 3621, Loss: 0.1450234055519104, Final Batch Loss: 0.08952415734529495\n",
      "Epoch 3622, Loss: 0.06898731924593449, Final Batch Loss: 0.02119774930179119\n",
      "Epoch 3623, Loss: 0.12244444712996483, Final Batch Loss: 0.06548039615154266\n",
      "Epoch 3624, Loss: 0.1052701398730278, Final Batch Loss: 0.061976369470357895\n",
      "Epoch 3625, Loss: 0.08686419948935509, Final Batch Loss: 0.04410525783896446\n",
      "Epoch 3626, Loss: 0.13293670117855072, Final Batch Loss: 0.07764369249343872\n",
      "Epoch 3627, Loss: 0.09986044093966484, Final Batch Loss: 0.056099243462085724\n",
      "Epoch 3628, Loss: 0.06411361694335938, Final Batch Loss: 0.020879562944173813\n",
      "Epoch 3629, Loss: 0.06304601766169071, Final Batch Loss: 0.03387356176972389\n",
      "Epoch 3630, Loss: 0.11074254289269447, Final Batch Loss: 0.06037543714046478\n",
      "Epoch 3631, Loss: 0.12330324947834015, Final Batch Loss: 0.041234374046325684\n",
      "Epoch 3632, Loss: 0.07750847563147545, Final Batch Loss: 0.04497483745217323\n",
      "Epoch 3633, Loss: 0.09547098726034164, Final Batch Loss: 0.048340972512960434\n",
      "Epoch 3634, Loss: 0.08894287794828415, Final Batch Loss: 0.04233517125248909\n",
      "Epoch 3635, Loss: 0.09026544913649559, Final Batch Loss: 0.0499078705906868\n",
      "Epoch 3636, Loss: 0.08223872072994709, Final Batch Loss: 0.02241191826760769\n",
      "Epoch 3637, Loss: 0.11426082253456116, Final Batch Loss: 0.03507973998785019\n",
      "Epoch 3638, Loss: 0.11201057955622673, Final Batch Loss: 0.05235034227371216\n",
      "Epoch 3639, Loss: 0.12516329437494278, Final Batch Loss: 0.0660235658288002\n",
      "Epoch 3640, Loss: 0.09452725574374199, Final Batch Loss: 0.055532995611429214\n",
      "Epoch 3641, Loss: 0.11105764470994473, Final Batch Loss: 0.07997051626443863\n",
      "Epoch 3642, Loss: 0.13407772406935692, Final Batch Loss: 0.07710601389408112\n",
      "Epoch 3643, Loss: 0.37204916402697563, Final Batch Loss: 0.32738688588142395\n",
      "Epoch 3644, Loss: 0.09551435336470604, Final Batch Loss: 0.03460613638162613\n",
      "Epoch 3645, Loss: 0.10070411115884781, Final Batch Loss: 0.05778062716126442\n",
      "Epoch 3646, Loss: 0.10873494297266006, Final Batch Loss: 0.05947761610150337\n",
      "Epoch 3647, Loss: 0.11771394684910774, Final Batch Loss: 0.03526945039629936\n",
      "Epoch 3648, Loss: 0.2905188910663128, Final Batch Loss: 0.22922828793525696\n",
      "Epoch 3649, Loss: 0.06242959201335907, Final Batch Loss: 0.02470020204782486\n",
      "Epoch 3650, Loss: 0.07953394204378128, Final Batch Loss: 0.030455313622951508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3651, Loss: 0.18303466588258743, Final Batch Loss: 0.06790724396705627\n",
      "Epoch 3652, Loss: 0.16515102982521057, Final Batch Loss: 0.09773451834917068\n",
      "Epoch 3653, Loss: 0.10617510601878166, Final Batch Loss: 0.06565443426370621\n",
      "Epoch 3654, Loss: 0.11302854493260384, Final Batch Loss: 0.03790358826518059\n",
      "Epoch 3655, Loss: 0.1441575586795807, Final Batch Loss: 0.07389107346534729\n",
      "Epoch 3656, Loss: 0.1083395667374134, Final Batch Loss: 0.032685961574316025\n",
      "Epoch 3657, Loss: 0.13121555373072624, Final Batch Loss: 0.07252921164035797\n",
      "Epoch 3658, Loss: 0.13675497472286224, Final Batch Loss: 0.07132486999034882\n",
      "Epoch 3659, Loss: 0.09468362480401993, Final Batch Loss: 0.053543560206890106\n",
      "Epoch 3660, Loss: 0.07206645794212818, Final Batch Loss: 0.015906987711787224\n",
      "Epoch 3661, Loss: 0.12833162024617195, Final Batch Loss: 0.06921171396970749\n",
      "Epoch 3662, Loss: 0.1034962423145771, Final Batch Loss: 0.048622049391269684\n",
      "Epoch 3663, Loss: 0.12987340241670609, Final Batch Loss: 0.07598795741796494\n",
      "Epoch 3664, Loss: 0.09020897001028061, Final Batch Loss: 0.03700265288352966\n",
      "Epoch 3665, Loss: 0.08919550105929375, Final Batch Loss: 0.038896024227142334\n",
      "Epoch 3666, Loss: 0.06488402187824249, Final Batch Loss: 0.025205399841070175\n",
      "Epoch 3667, Loss: 0.19589872285723686, Final Batch Loss: 0.15637464821338654\n",
      "Epoch 3668, Loss: 0.08916620537638664, Final Batch Loss: 0.04538804292678833\n",
      "Epoch 3669, Loss: 0.09494396299123764, Final Batch Loss: 0.04407086595892906\n",
      "Epoch 3670, Loss: 0.09632419794797897, Final Batch Loss: 0.05059424042701721\n",
      "Epoch 3671, Loss: 0.13977288454771042, Final Batch Loss: 0.07304709404706955\n",
      "Epoch 3672, Loss: 0.12891860678792, Final Batch Loss: 0.0762423425912857\n",
      "Epoch 3673, Loss: 0.07783503644168377, Final Batch Loss: 0.031143737956881523\n",
      "Epoch 3674, Loss: 0.1327960081398487, Final Batch Loss: 0.050665270537137985\n",
      "Epoch 3675, Loss: 0.1380297690629959, Final Batch Loss: 0.07355103641748428\n",
      "Epoch 3676, Loss: 0.13421928137540817, Final Batch Loss: 0.08672695606946945\n",
      "Epoch 3677, Loss: 0.10006558522582054, Final Batch Loss: 0.03553207591176033\n",
      "Epoch 3678, Loss: 0.11467092856764793, Final Batch Loss: 0.05263487249612808\n",
      "Epoch 3679, Loss: 0.2126525603234768, Final Batch Loss: 0.16347138583660126\n",
      "Epoch 3680, Loss: 0.17576848715543747, Final Batch Loss: 0.07872457057237625\n",
      "Epoch 3681, Loss: 0.13202033936977386, Final Batch Loss: 0.07943302392959595\n",
      "Epoch 3682, Loss: 0.1660275235772133, Final Batch Loss: 0.1045745462179184\n",
      "Epoch 3683, Loss: 0.07278142496943474, Final Batch Loss: 0.03289297968149185\n",
      "Epoch 3684, Loss: 0.26576924696564674, Final Batch Loss: 0.22058573365211487\n",
      "Epoch 3685, Loss: 0.0670010894536972, Final Batch Loss: 0.020885687321424484\n",
      "Epoch 3686, Loss: 0.08294637873768806, Final Batch Loss: 0.023402884602546692\n",
      "Epoch 3687, Loss: 0.10466719791293144, Final Batch Loss: 0.04054751619696617\n",
      "Epoch 3688, Loss: 0.1024949811398983, Final Batch Loss: 0.039359357208013535\n",
      "Epoch 3689, Loss: 0.06488680839538574, Final Batch Loss: 0.019381172955036163\n",
      "Epoch 3690, Loss: 0.13166601583361626, Final Batch Loss: 0.08367538452148438\n",
      "Epoch 3691, Loss: 0.14196845889091492, Final Batch Loss: 0.07914634793996811\n",
      "Epoch 3692, Loss: 0.10509153082966805, Final Batch Loss: 0.03955676779150963\n",
      "Epoch 3693, Loss: 0.09327389672398567, Final Batch Loss: 0.039469145238399506\n",
      "Epoch 3694, Loss: 0.10404307022690773, Final Batch Loss: 0.06655003130435944\n",
      "Epoch 3695, Loss: 0.07362893968820572, Final Batch Loss: 0.038813330233097076\n",
      "Epoch 3696, Loss: 0.12454491853713989, Final Batch Loss: 0.051415398716926575\n",
      "Epoch 3697, Loss: 0.09844970703125, Final Batch Loss: 0.040866415947675705\n",
      "Epoch 3698, Loss: 0.07596132159233093, Final Batch Loss: 0.03302828222513199\n",
      "Epoch 3699, Loss: 0.0717238150537014, Final Batch Loss: 0.025871876627206802\n",
      "Epoch 3700, Loss: 0.10790155082941055, Final Batch Loss: 0.06358075886964798\n",
      "Epoch 3701, Loss: 0.07059228233993053, Final Batch Loss: 0.023713847622275352\n",
      "Epoch 3702, Loss: 0.10540727525949478, Final Batch Loss: 0.05435016006231308\n",
      "Epoch 3703, Loss: 0.09340523555874825, Final Batch Loss: 0.04827119782567024\n",
      "Epoch 3704, Loss: 0.1724805273115635, Final Batch Loss: 0.1258619725704193\n",
      "Epoch 3705, Loss: 0.0760880894958973, Final Batch Loss: 0.043526794761419296\n",
      "Epoch 3706, Loss: 0.06354158371686935, Final Batch Loss: 0.023398734629154205\n",
      "Epoch 3707, Loss: 0.08138367533683777, Final Batch Loss: 0.04018877446651459\n",
      "Epoch 3708, Loss: 0.09393217787146568, Final Batch Loss: 0.05401046201586723\n",
      "Epoch 3709, Loss: 0.07754522189497948, Final Batch Loss: 0.040254607796669006\n",
      "Epoch 3710, Loss: 0.05168049782514572, Final Batch Loss: 0.020432746037840843\n",
      "Epoch 3711, Loss: 0.06939985137432814, Final Batch Loss: 0.014932303689420223\n",
      "Epoch 3712, Loss: 0.06484393775463104, Final Batch Loss: 0.022643063217401505\n",
      "Epoch 3713, Loss: 0.08735208213329315, Final Batch Loss: 0.04568343982100487\n",
      "Epoch 3714, Loss: 0.09178236685693264, Final Batch Loss: 0.06440769881010056\n",
      "Epoch 3715, Loss: 0.06565730273723602, Final Batch Loss: 0.04161357134580612\n",
      "Epoch 3716, Loss: 0.12210477143526077, Final Batch Loss: 0.0736701712012291\n",
      "Epoch 3717, Loss: 0.0842682234942913, Final Batch Loss: 0.047414518892765045\n",
      "Epoch 3718, Loss: 0.13744932413101196, Final Batch Loss: 0.07916298508644104\n",
      "Epoch 3719, Loss: 0.06665662117302418, Final Batch Loss: 0.03726888820528984\n",
      "Epoch 3720, Loss: 0.07163148373365402, Final Batch Loss: 0.039034806191921234\n",
      "Epoch 3721, Loss: 0.07103116996586323, Final Batch Loss: 0.025491410866379738\n",
      "Epoch 3722, Loss: 0.09358485415577888, Final Batch Loss: 0.04624735191464424\n",
      "Epoch 3723, Loss: 0.07638237252831459, Final Batch Loss: 0.041045863181352615\n",
      "Epoch 3724, Loss: 0.11228834465146065, Final Batch Loss: 0.06662244349718094\n",
      "Epoch 3725, Loss: 0.10598405636847019, Final Batch Loss: 0.02835737355053425\n",
      "Epoch 3726, Loss: 0.059944873675704, Final Batch Loss: 0.03424050286412239\n",
      "Epoch 3727, Loss: 0.07430704683065414, Final Batch Loss: 0.02607886493206024\n",
      "Epoch 3728, Loss: 0.07747220434248447, Final Batch Loss: 0.019870014861226082\n",
      "Epoch 3729, Loss: 0.09248817712068558, Final Batch Loss: 0.054160572588443756\n",
      "Epoch 3730, Loss: 0.06591454707086086, Final Batch Loss: 0.02964736334979534\n",
      "Epoch 3731, Loss: 0.08315259777009487, Final Batch Loss: 0.05446908622980118\n",
      "Epoch 3732, Loss: 0.10979160666465759, Final Batch Loss: 0.03321685642004013\n",
      "Epoch 3733, Loss: 0.10101241618394852, Final Batch Loss: 0.054255492985248566\n",
      "Epoch 3734, Loss: 0.11078443378210068, Final Batch Loss: 0.0661894679069519\n",
      "Epoch 3735, Loss: 0.08792552351951599, Final Batch Loss: 0.048182617872953415\n",
      "Epoch 3736, Loss: 0.06891405396163464, Final Batch Loss: 0.03121824376285076\n",
      "Epoch 3737, Loss: 0.09974667802453041, Final Batch Loss: 0.05406574532389641\n",
      "Epoch 3738, Loss: 0.09456032887101173, Final Batch Loss: 0.05098292604088783\n",
      "Epoch 3739, Loss: 0.11275054886937141, Final Batch Loss: 0.05716898664832115\n",
      "Epoch 3740, Loss: 0.07632789015769958, Final Batch Loss: 0.03609754145145416\n",
      "Epoch 3741, Loss: 0.07801654189825058, Final Batch Loss: 0.042420756071805954\n",
      "Epoch 3742, Loss: 0.06845469772815704, Final Batch Loss: 0.04406179115176201\n",
      "Epoch 3743, Loss: 0.07619640603661537, Final Batch Loss: 0.03912653401494026\n",
      "Epoch 3744, Loss: 0.09701905027031898, Final Batch Loss: 0.042642828077077866\n",
      "Epoch 3745, Loss: 0.07044542953372002, Final Batch Loss: 0.03566465154290199\n",
      "Epoch 3746, Loss: 0.06656588241457939, Final Batch Loss: 0.031396929174661636\n",
      "Epoch 3747, Loss: 0.07446635328233242, Final Batch Loss: 0.031116673722863197\n",
      "Epoch 3748, Loss: 0.12542163208127022, Final Batch Loss: 0.05483214184641838\n",
      "Epoch 3749, Loss: 0.09279816225171089, Final Batch Loss: 0.04114331677556038\n",
      "Epoch 3750, Loss: 0.10346072912216187, Final Batch Loss: 0.02743101865053177\n",
      "Epoch 3751, Loss: 0.13654426112771034, Final Batch Loss: 0.04385476931929588\n",
      "Epoch 3752, Loss: 0.06537935510277748, Final Batch Loss: 0.029140252619981766\n",
      "Epoch 3753, Loss: 0.08848848193883896, Final Batch Loss: 0.051040180027484894\n",
      "Epoch 3754, Loss: 0.11473191902041435, Final Batch Loss: 0.03757094964385033\n",
      "Epoch 3755, Loss: 0.06066903844475746, Final Batch Loss: 0.012246489524841309\n",
      "Epoch 3756, Loss: 0.07981534115970135, Final Batch Loss: 0.013868777081370354\n",
      "Epoch 3757, Loss: 0.06475911289453506, Final Batch Loss: 0.03284621611237526\n",
      "Epoch 3758, Loss: 0.07098110392689705, Final Batch Loss: 0.026611436158418655\n",
      "Epoch 3759, Loss: 0.07240048050880432, Final Batch Loss: 0.04040217772126198\n",
      "Epoch 3760, Loss: 0.06479864940047264, Final Batch Loss: 0.03375348821282387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3761, Loss: 0.10171698778867722, Final Batch Loss: 0.06997070461511612\n",
      "Epoch 3762, Loss: 0.12434240058064461, Final Batch Loss: 0.0752372071146965\n",
      "Epoch 3763, Loss: 0.06061769835650921, Final Batch Loss: 0.025988629087805748\n",
      "Epoch 3764, Loss: 0.07746637240052223, Final Batch Loss: 0.05550294369459152\n",
      "Epoch 3765, Loss: 0.06345248408615589, Final Batch Loss: 0.027602145448327065\n",
      "Epoch 3766, Loss: 0.07349726185202599, Final Batch Loss: 0.04468373581767082\n",
      "Epoch 3767, Loss: 0.1345910131931305, Final Batch Loss: 0.10064783692359924\n",
      "Epoch 3768, Loss: 0.12839970737695694, Final Batch Loss: 0.06227519363164902\n",
      "Epoch 3769, Loss: 0.10007607191801071, Final Batch Loss: 0.05500253662467003\n",
      "Epoch 3770, Loss: 0.06585274264216423, Final Batch Loss: 0.023452457040548325\n",
      "Epoch 3771, Loss: 0.09730979055166245, Final Batch Loss: 0.05203630402684212\n",
      "Epoch 3772, Loss: 0.08717028424143791, Final Batch Loss: 0.046585142612457275\n",
      "Epoch 3773, Loss: 0.08060802146792412, Final Batch Loss: 0.04186244308948517\n",
      "Epoch 3774, Loss: 0.10478875786066055, Final Batch Loss: 0.07312741875648499\n",
      "Epoch 3775, Loss: 0.1123734749853611, Final Batch Loss: 0.07695847749710083\n",
      "Epoch 3776, Loss: 0.12428861856460571, Final Batch Loss: 0.08210205286741257\n",
      "Epoch 3777, Loss: 0.1011674515902996, Final Batch Loss: 0.03665461763739586\n",
      "Epoch 3778, Loss: 0.09497873485088348, Final Batch Loss: 0.047594644129276276\n",
      "Epoch 3779, Loss: 0.07858947105705738, Final Batch Loss: 0.05331374704837799\n",
      "Epoch 3780, Loss: 0.05556308105587959, Final Batch Loss: 0.020002778619527817\n",
      "Epoch 3781, Loss: 0.08580467477440834, Final Batch Loss: 0.03527861833572388\n",
      "Epoch 3782, Loss: 0.09735572524368763, Final Batch Loss: 0.06963369995355606\n",
      "Epoch 3783, Loss: 0.07400681264698505, Final Batch Loss: 0.019948774948716164\n",
      "Epoch 3784, Loss: 0.056949615478515625, Final Batch Loss: 0.016751199960708618\n",
      "Epoch 3785, Loss: 0.06246173940598965, Final Batch Loss: 0.029236143454909325\n",
      "Epoch 3786, Loss: 0.06132127344608307, Final Batch Loss: 0.02834007889032364\n",
      "Epoch 3787, Loss: 0.08023261651396751, Final Batch Loss: 0.039613205939531326\n",
      "Epoch 3788, Loss: 0.08535398915410042, Final Batch Loss: 0.032037824392318726\n",
      "Epoch 3789, Loss: 0.06330557353794575, Final Batch Loss: 0.02696063183248043\n",
      "Epoch 3790, Loss: 0.04533168859779835, Final Batch Loss: 0.016879159957170486\n",
      "Epoch 3791, Loss: 0.0713958628475666, Final Batch Loss: 0.02980518713593483\n",
      "Epoch 3792, Loss: 0.10176809504628181, Final Batch Loss: 0.05527094379067421\n",
      "Epoch 3793, Loss: 0.07140410598367453, Final Batch Loss: 0.011955234222114086\n",
      "Epoch 3794, Loss: 0.0682056825608015, Final Batch Loss: 0.04774553328752518\n",
      "Epoch 3795, Loss: 0.06742426753044128, Final Batch Loss: 0.03359203785657883\n",
      "Epoch 3796, Loss: 0.08979227766394615, Final Batch Loss: 0.036395322531461716\n",
      "Epoch 3797, Loss: 0.10808156430721283, Final Batch Loss: 0.06707355380058289\n",
      "Epoch 3798, Loss: 0.057851411402225494, Final Batch Loss: 0.016414307057857513\n",
      "Epoch 3799, Loss: 0.09557541832327843, Final Batch Loss: 0.05894443020224571\n",
      "Epoch 3800, Loss: 0.07479039207100868, Final Batch Loss: 0.028666608035564423\n",
      "Epoch 3801, Loss: 0.06259041465818882, Final Batch Loss: 0.020359622314572334\n",
      "Epoch 3802, Loss: 0.08998570963740349, Final Batch Loss: 0.0595853291451931\n",
      "Epoch 3803, Loss: 0.10180341824889183, Final Batch Loss: 0.048356957733631134\n",
      "Epoch 3804, Loss: 0.08624831773340702, Final Batch Loss: 0.031037433072924614\n",
      "Epoch 3805, Loss: 0.09249382093548775, Final Batch Loss: 0.04957227036356926\n",
      "Epoch 3806, Loss: 0.05968526937067509, Final Batch Loss: 0.023981889709830284\n",
      "Epoch 3807, Loss: 0.05671196058392525, Final Batch Loss: 0.022492550313472748\n",
      "Epoch 3808, Loss: 0.11053623631596565, Final Batch Loss: 0.053036779165267944\n",
      "Epoch 3809, Loss: 0.11444208957254887, Final Batch Loss: 0.02497495897114277\n",
      "Epoch 3810, Loss: 0.059345250017941, Final Batch Loss: 0.014607862569391727\n",
      "Epoch 3811, Loss: 0.06701566465198994, Final Batch Loss: 0.017539387568831444\n",
      "Epoch 3812, Loss: 0.09685207530856133, Final Batch Loss: 0.05989278480410576\n",
      "Epoch 3813, Loss: 0.08904869854450226, Final Batch Loss: 0.028803933411836624\n",
      "Epoch 3814, Loss: 0.08029890060424805, Final Batch Loss: 0.026326961815357208\n",
      "Epoch 3815, Loss: 0.13022977486252785, Final Batch Loss: 0.08743053674697876\n",
      "Epoch 3816, Loss: 0.18117349594831467, Final Batch Loss: 0.042757801711559296\n",
      "Epoch 3817, Loss: 0.06600581854581833, Final Batch Loss: 0.03014335408806801\n",
      "Epoch 3818, Loss: 0.07094082608819008, Final Batch Loss: 0.036480389535427094\n",
      "Epoch 3819, Loss: 0.10186529532074928, Final Batch Loss: 0.03818603232502937\n",
      "Epoch 3820, Loss: 0.14707474410533905, Final Batch Loss: 0.06740468740463257\n",
      "Epoch 3821, Loss: 0.10053735785186291, Final Batch Loss: 0.027146784588694572\n",
      "Epoch 3822, Loss: 0.08206619694828987, Final Batch Loss: 0.03591255843639374\n",
      "Epoch 3823, Loss: 0.10882159695029259, Final Batch Loss: 0.0704062208533287\n",
      "Epoch 3824, Loss: 0.08213297091424465, Final Batch Loss: 0.02878314070403576\n",
      "Epoch 3825, Loss: 0.09492906555533409, Final Batch Loss: 0.04615754634141922\n",
      "Epoch 3826, Loss: 0.07714546099305153, Final Batch Loss: 0.033495862036943436\n",
      "Epoch 3827, Loss: 0.09679845720529556, Final Batch Loss: 0.038034837692976\n",
      "Epoch 3828, Loss: 0.09123068302869797, Final Batch Loss: 0.04898534342646599\n",
      "Epoch 3829, Loss: 0.1139795109629631, Final Batch Loss: 0.07465734332799911\n",
      "Epoch 3830, Loss: 0.11269774287939072, Final Batch Loss: 0.0597853846848011\n",
      "Epoch 3831, Loss: 0.10486873984336853, Final Batch Loss: 0.07499106973409653\n",
      "Epoch 3832, Loss: 0.08409450389444828, Final Batch Loss: 0.021171683445572853\n",
      "Epoch 3833, Loss: 0.08794891089200974, Final Batch Loss: 0.033701032400131226\n",
      "Epoch 3834, Loss: 0.07224777340888977, Final Batch Loss: 0.04143291339278221\n",
      "Epoch 3835, Loss: 0.14749706909060478, Final Batch Loss: 0.11518187820911407\n",
      "Epoch 3836, Loss: 0.0974583700299263, Final Batch Loss: 0.04009576141834259\n",
      "Epoch 3837, Loss: 0.11210763826966286, Final Batch Loss: 0.07242076098918915\n",
      "Epoch 3838, Loss: 0.10906102508306503, Final Batch Loss: 0.05892057716846466\n",
      "Epoch 3839, Loss: 0.06949050351977348, Final Batch Loss: 0.03370390459895134\n",
      "Epoch 3840, Loss: 0.06980261951684952, Final Batch Loss: 0.03473985940217972\n",
      "Epoch 3841, Loss: 0.07472954876720905, Final Batch Loss: 0.01949848048388958\n",
      "Epoch 3842, Loss: 0.15776246786117554, Final Batch Loss: 0.08734364807605743\n",
      "Epoch 3843, Loss: 0.09567863866686821, Final Batch Loss: 0.022213753312826157\n",
      "Epoch 3844, Loss: 0.09068267792463303, Final Batch Loss: 0.03932083770632744\n",
      "Epoch 3845, Loss: 0.06562860868871212, Final Batch Loss: 0.018027832731604576\n",
      "Epoch 3846, Loss: 0.18859479203820229, Final Batch Loss: 0.13778655230998993\n",
      "Epoch 3847, Loss: 0.06780941411852837, Final Batch Loss: 0.03274925798177719\n",
      "Epoch 3848, Loss: 0.06697369366884232, Final Batch Loss: 0.03420250862836838\n",
      "Epoch 3849, Loss: 0.07122798636555672, Final Batch Loss: 0.02680325135588646\n",
      "Epoch 3850, Loss: 0.07920253276824951, Final Batch Loss: 0.045465074479579926\n",
      "Epoch 3851, Loss: 0.09606928750872612, Final Batch Loss: 0.05530461668968201\n",
      "Epoch 3852, Loss: 0.08243508264422417, Final Batch Loss: 0.04851392284035683\n",
      "Epoch 3853, Loss: 0.09846363216638565, Final Batch Loss: 0.06301234662532806\n",
      "Epoch 3854, Loss: 0.07961696293205023, Final Batch Loss: 0.013826495967805386\n",
      "Epoch 3855, Loss: 0.08911009505391121, Final Batch Loss: 0.047114793211221695\n",
      "Epoch 3856, Loss: 0.07972835935652256, Final Batch Loss: 0.027450980618596077\n",
      "Epoch 3857, Loss: 0.08113005012273788, Final Batch Loss: 0.031086254864931107\n",
      "Epoch 3858, Loss: 0.12513554841279984, Final Batch Loss: 0.07661499828100204\n",
      "Epoch 3859, Loss: 0.09077643603086472, Final Batch Loss: 0.05266619101166725\n",
      "Epoch 3860, Loss: 0.11844256147742271, Final Batch Loss: 0.06422767788171768\n",
      "Epoch 3861, Loss: 0.07451869547367096, Final Batch Loss: 0.035689495503902435\n",
      "Epoch 3862, Loss: 0.07478781044483185, Final Batch Loss: 0.032782237976789474\n",
      "Epoch 3863, Loss: 0.08748485520482063, Final Batch Loss: 0.03445850685238838\n",
      "Epoch 3864, Loss: 0.1097339354455471, Final Batch Loss: 0.051407698541879654\n",
      "Epoch 3865, Loss: 0.07634458690881729, Final Batch Loss: 0.045065682381391525\n",
      "Epoch 3866, Loss: 0.06766917929053307, Final Batch Loss: 0.026923291385173798\n",
      "Epoch 3867, Loss: 0.10709739103913307, Final Batch Loss: 0.06807123869657516\n",
      "Epoch 3868, Loss: 0.1163543052971363, Final Batch Loss: 0.07792065292596817\n",
      "Epoch 3869, Loss: 0.08076242730021477, Final Batch Loss: 0.046161994338035583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3870, Loss: 0.12261604890227318, Final Batch Loss: 0.0857582539319992\n",
      "Epoch 3871, Loss: 0.07721258141100407, Final Batch Loss: 0.027857540175318718\n",
      "Epoch 3872, Loss: 0.06301732733845711, Final Batch Loss: 0.0261855386197567\n",
      "Epoch 3873, Loss: 0.06614647433161736, Final Batch Loss: 0.019824065268039703\n",
      "Epoch 3874, Loss: 0.08585136756300926, Final Batch Loss: 0.0541628859937191\n",
      "Epoch 3875, Loss: 0.09890298545360565, Final Batch Loss: 0.04686100035905838\n",
      "Epoch 3876, Loss: 0.09770341962575912, Final Batch Loss: 0.0595049150288105\n",
      "Epoch 3877, Loss: 0.08061512932181358, Final Batch Loss: 0.03290105238556862\n",
      "Epoch 3878, Loss: 0.08576154708862305, Final Batch Loss: 0.041819941252470016\n",
      "Epoch 3879, Loss: 0.1121206060051918, Final Batch Loss: 0.05039886385202408\n",
      "Epoch 3880, Loss: 0.12043817341327667, Final Batch Loss: 0.054642900824546814\n",
      "Epoch 3881, Loss: 0.07682752050459385, Final Batch Loss: 0.049496326595544815\n",
      "Epoch 3882, Loss: 0.09549788758158684, Final Batch Loss: 0.046480681747198105\n",
      "Epoch 3883, Loss: 0.10327450931072235, Final Batch Loss: 0.055431049317121506\n",
      "Epoch 3884, Loss: 0.09108033403754234, Final Batch Loss: 0.034189846366643906\n",
      "Epoch 3885, Loss: 0.07827525585889816, Final Batch Loss: 0.025868911296129227\n",
      "Epoch 3886, Loss: 0.06163320131599903, Final Batch Loss: 0.025927165523171425\n",
      "Epoch 3887, Loss: 0.060499247163534164, Final Batch Loss: 0.031734269112348557\n",
      "Epoch 3888, Loss: 0.06647011265158653, Final Batch Loss: 0.026074517518281937\n",
      "Epoch 3889, Loss: 0.058785052970051765, Final Batch Loss: 0.032024040818214417\n",
      "Epoch 3890, Loss: 0.07749653235077858, Final Batch Loss: 0.03278746083378792\n",
      "Epoch 3891, Loss: 0.07720891758799553, Final Batch Loss: 0.0344553142786026\n",
      "Epoch 3892, Loss: 0.09914534166455269, Final Batch Loss: 0.05788913369178772\n",
      "Epoch 3893, Loss: 0.10109420493245125, Final Batch Loss: 0.06715099513530731\n",
      "Epoch 3894, Loss: 0.08649919927120209, Final Batch Loss: 0.059272654354572296\n",
      "Epoch 3895, Loss: 0.10263759642839432, Final Batch Loss: 0.04822101444005966\n",
      "Epoch 3896, Loss: 0.09148561209440231, Final Batch Loss: 0.0596463717520237\n",
      "Epoch 3897, Loss: 0.09589371457695961, Final Batch Loss: 0.04562944546341896\n",
      "Epoch 3898, Loss: 0.09145573526620865, Final Batch Loss: 0.056334223598241806\n",
      "Epoch 3899, Loss: 0.08823570609092712, Final Batch Loss: 0.04156062752008438\n",
      "Epoch 3900, Loss: 0.0665745958685875, Final Batch Loss: 0.03529521822929382\n",
      "Epoch 3901, Loss: 0.09424733743071556, Final Batch Loss: 0.060374874621629715\n",
      "Epoch 3902, Loss: 0.08365501090884209, Final Batch Loss: 0.03997456282377243\n",
      "Epoch 3903, Loss: 0.058967165648937225, Final Batch Loss: 0.023613695055246353\n",
      "Epoch 3904, Loss: 0.08771984279155731, Final Batch Loss: 0.0438581146299839\n",
      "Epoch 3905, Loss: 0.07541000843048096, Final Batch Loss: 0.041938722133636475\n",
      "Epoch 3906, Loss: 0.0871362891048193, Final Batch Loss: 0.05998508259654045\n",
      "Epoch 3907, Loss: 0.0634165033698082, Final Batch Loss: 0.02358953282237053\n",
      "Epoch 3908, Loss: 0.09065143764019012, Final Batch Loss: 0.04754263535141945\n",
      "Epoch 3909, Loss: 0.0902823656797409, Final Batch Loss: 0.03917337954044342\n",
      "Epoch 3910, Loss: 0.11536437645554543, Final Batch Loss: 0.07690829038619995\n",
      "Epoch 3911, Loss: 0.07727992162108421, Final Batch Loss: 0.033430878072977066\n",
      "Epoch 3912, Loss: 0.11573689803481102, Final Batch Loss: 0.07907024770975113\n",
      "Epoch 3913, Loss: 0.09826606884598732, Final Batch Loss: 0.036935728043317795\n",
      "Epoch 3914, Loss: 0.0710911937057972, Final Batch Loss: 0.02773698791861534\n",
      "Epoch 3915, Loss: 0.08192799612879753, Final Batch Loss: 0.034071508795022964\n",
      "Epoch 3916, Loss: 0.1038547232747078, Final Batch Loss: 0.060240477323532104\n",
      "Epoch 3917, Loss: 0.07908502966165543, Final Batch Loss: 0.03113115206360817\n",
      "Epoch 3918, Loss: 0.13124127313494682, Final Batch Loss: 0.07143711298704147\n",
      "Epoch 3919, Loss: 0.12216607108712196, Final Batch Loss: 0.07615581899881363\n",
      "Epoch 3920, Loss: 0.11479396745562553, Final Batch Loss: 0.06210998445749283\n",
      "Epoch 3921, Loss: 0.09314363077282906, Final Batch Loss: 0.05663510784506798\n",
      "Epoch 3922, Loss: 0.07094701379537582, Final Batch Loss: 0.031370848417282104\n",
      "Epoch 3923, Loss: 0.06889036297798157, Final Batch Loss: 0.026613358408212662\n",
      "Epoch 3924, Loss: 0.11342905461788177, Final Batch Loss: 0.057095304131507874\n",
      "Epoch 3925, Loss: 0.07147869281470776, Final Batch Loss: 0.021129554137587547\n",
      "Epoch 3926, Loss: 0.07430476322770119, Final Batch Loss: 0.030303269624710083\n",
      "Epoch 3927, Loss: 0.07737825438380241, Final Batch Loss: 0.036477502435445786\n",
      "Epoch 3928, Loss: 0.07488464005291462, Final Batch Loss: 0.02015845663845539\n",
      "Epoch 3929, Loss: 0.0581217035651207, Final Batch Loss: 0.032879602164030075\n",
      "Epoch 3930, Loss: 0.06250261701643467, Final Batch Loss: 0.038056325167417526\n",
      "Epoch 3931, Loss: 0.09977265819907188, Final Batch Loss: 0.058554958552122116\n",
      "Epoch 3932, Loss: 0.09098945930600166, Final Batch Loss: 0.046258289366960526\n",
      "Epoch 3933, Loss: 0.08150036260485649, Final Batch Loss: 0.03437305986881256\n",
      "Epoch 3934, Loss: 0.07250769063830376, Final Batch Loss: 0.03274572640657425\n",
      "Epoch 3935, Loss: 0.10647435858845711, Final Batch Loss: 0.06995890289545059\n",
      "Epoch 3936, Loss: 0.07226663827896118, Final Batch Loss: 0.03893815353512764\n",
      "Epoch 3937, Loss: 0.10039496794342995, Final Batch Loss: 0.03755473718047142\n",
      "Epoch 3938, Loss: 0.07132216356694698, Final Batch Loss: 0.027553556486964226\n",
      "Epoch 3939, Loss: 0.0941210612654686, Final Batch Loss: 0.04884343966841698\n",
      "Epoch 3940, Loss: 0.08735542371869087, Final Batch Loss: 0.045112136751413345\n",
      "Epoch 3941, Loss: 0.08174147829413414, Final Batch Loss: 0.038432955741882324\n",
      "Epoch 3942, Loss: 0.09776807203888893, Final Batch Loss: 0.04795248061418533\n",
      "Epoch 3943, Loss: 0.06448896415531635, Final Batch Loss: 0.020444640889763832\n",
      "Epoch 3944, Loss: 0.12286420911550522, Final Batch Loss: 0.052801862359046936\n",
      "Epoch 3945, Loss: 0.06932834163308144, Final Batch Loss: 0.03608034923672676\n",
      "Epoch 3946, Loss: 0.11494109779596329, Final Batch Loss: 0.06344402581453323\n",
      "Epoch 3947, Loss: 0.08464844897389412, Final Batch Loss: 0.04144896939396858\n",
      "Epoch 3948, Loss: 0.08373193815350533, Final Batch Loss: 0.04016491025686264\n",
      "Epoch 3949, Loss: 0.0779329426586628, Final Batch Loss: 0.040646668523550034\n",
      "Epoch 3950, Loss: 0.07361787557601929, Final Batch Loss: 0.04113012179732323\n",
      "Epoch 3951, Loss: 0.10672648623585701, Final Batch Loss: 0.06924119591712952\n",
      "Epoch 3952, Loss: 0.09822903946042061, Final Batch Loss: 0.02303510531783104\n",
      "Epoch 3953, Loss: 0.09226450696587563, Final Batch Loss: 0.05900300666689873\n",
      "Epoch 3954, Loss: 0.06572187133133411, Final Batch Loss: 0.028438957408070564\n",
      "Epoch 3955, Loss: 0.06269119307398796, Final Batch Loss: 0.018947962671518326\n",
      "Epoch 3956, Loss: 0.05646409094333649, Final Batch Loss: 0.025384921580553055\n",
      "Epoch 3957, Loss: 0.11706306412816048, Final Batch Loss: 0.07088479399681091\n",
      "Epoch 3958, Loss: 0.10883838310837746, Final Batch Loss: 0.08047705143690109\n",
      "Epoch 3959, Loss: 0.08407177776098251, Final Batch Loss: 0.03611071780323982\n",
      "Epoch 3960, Loss: 0.0967765748500824, Final Batch Loss: 0.05130423232913017\n",
      "Epoch 3961, Loss: 0.08155835792422295, Final Batch Loss: 0.031083479523658752\n",
      "Epoch 3962, Loss: 0.05262675695121288, Final Batch Loss: 0.01728707365691662\n",
      "Epoch 3963, Loss: 0.06316702999174595, Final Batch Loss: 0.032349999994039536\n",
      "Epoch 3964, Loss: 0.07717321068048477, Final Batch Loss: 0.031992580741643906\n",
      "Epoch 3965, Loss: 0.05854477919638157, Final Batch Loss: 0.025128113105893135\n",
      "Epoch 3966, Loss: 0.06124306842684746, Final Batch Loss: 0.032719578593969345\n",
      "Epoch 3967, Loss: 0.10139591246843338, Final Batch Loss: 0.06857512146234512\n",
      "Epoch 3968, Loss: 0.07515594642609358, Final Batch Loss: 0.063151516020298\n",
      "Epoch 3969, Loss: 0.06672937050461769, Final Batch Loss: 0.024921972304582596\n",
      "Epoch 3970, Loss: 0.06114798132330179, Final Batch Loss: 0.013589893467724323\n",
      "Epoch 3971, Loss: 0.07615124993026257, Final Batch Loss: 0.026497790589928627\n",
      "Epoch 3972, Loss: 0.07702434435486794, Final Batch Loss: 0.016984570771455765\n",
      "Epoch 3973, Loss: 0.10896491259336472, Final Batch Loss: 0.051004067063331604\n",
      "Epoch 3974, Loss: 0.06151694618165493, Final Batch Loss: 0.029076794162392616\n",
      "Epoch 3975, Loss: 0.05749768577516079, Final Batch Loss: 0.018825294449925423\n",
      "Epoch 3976, Loss: 0.07426927611231804, Final Batch Loss: 0.03717092052102089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3977, Loss: 0.079159926623106, Final Batch Loss: 0.046683527529239655\n",
      "Epoch 3978, Loss: 0.061621202155947685, Final Batch Loss: 0.03149964287877083\n",
      "Epoch 3979, Loss: 0.09209638461470604, Final Batch Loss: 0.03319001570343971\n",
      "Epoch 3980, Loss: 0.07113132998347282, Final Batch Loss: 0.03969162330031395\n",
      "Epoch 3981, Loss: 0.08443517610430717, Final Batch Loss: 0.04406525939702988\n",
      "Epoch 3982, Loss: 0.07611767202615738, Final Batch Loss: 0.03793083876371384\n",
      "Epoch 3983, Loss: 0.09522059932351112, Final Batch Loss: 0.05617080628871918\n",
      "Epoch 3984, Loss: 0.08534647896885872, Final Batch Loss: 0.0503196157515049\n",
      "Epoch 3985, Loss: 0.06712792068719864, Final Batch Loss: 0.03484916314482689\n",
      "Epoch 3986, Loss: 0.06678265333175659, Final Batch Loss: 0.030226558446884155\n",
      "Epoch 3987, Loss: 0.0981103703379631, Final Batch Loss: 0.0545615591108799\n",
      "Epoch 3988, Loss: 0.07410074956715107, Final Batch Loss: 0.030837329104542732\n",
      "Epoch 3989, Loss: 0.07900506630539894, Final Batch Loss: 0.033973585814237595\n",
      "Epoch 3990, Loss: 0.07117601856589317, Final Batch Loss: 0.0372556634247303\n",
      "Epoch 3991, Loss: 0.13354628533124924, Final Batch Loss: 0.06419280916452408\n",
      "Epoch 3992, Loss: 0.11960049346089363, Final Batch Loss: 0.06663533300161362\n",
      "Epoch 3993, Loss: 0.07507627084851265, Final Batch Loss: 0.029008351266384125\n",
      "Epoch 3994, Loss: 0.07110034674406052, Final Batch Loss: 0.037029292434453964\n",
      "Epoch 3995, Loss: 0.0912833996117115, Final Batch Loss: 0.03478148207068443\n",
      "Epoch 3996, Loss: 0.1073051393032074, Final Batch Loss: 0.045039303600788116\n",
      "Epoch 3997, Loss: 0.058682005386799574, Final Batch Loss: 0.00775144575163722\n",
      "Epoch 3998, Loss: 0.08534106239676476, Final Batch Loss: 0.03295953944325447\n",
      "Epoch 3999, Loss: 0.11486924067139626, Final Batch Loss: 0.06827069818973541\n",
      "Epoch 4000, Loss: 0.07137081399559975, Final Batch Loss: 0.03746853023767471\n",
      "Epoch 4001, Loss: 0.11470228061079979, Final Batch Loss: 0.07591423392295837\n",
      "Epoch 4002, Loss: 0.07233401015400887, Final Batch Loss: 0.04254966229200363\n",
      "Epoch 4003, Loss: 0.06524430960416794, Final Batch Loss: 0.03531486913561821\n",
      "Epoch 4004, Loss: 0.06735933292657137, Final Batch Loss: 0.007939212955534458\n",
      "Epoch 4005, Loss: 0.08015239052474499, Final Batch Loss: 0.03024023212492466\n",
      "Epoch 4006, Loss: 0.06857330165803432, Final Batch Loss: 0.01856144703924656\n",
      "Epoch 4007, Loss: 0.10765565186738968, Final Batch Loss: 0.051028236746788025\n",
      "Epoch 4008, Loss: 0.08094363287091255, Final Batch Loss: 0.032679636031389236\n",
      "Epoch 4009, Loss: 0.0556322056800127, Final Batch Loss: 0.020186563953757286\n",
      "Epoch 4010, Loss: 0.058618757873773575, Final Batch Loss: 0.026517830789089203\n",
      "Epoch 4011, Loss: 0.059792641550302505, Final Batch Loss: 0.02232453227043152\n",
      "Epoch 4012, Loss: 0.07739768922328949, Final Batch Loss: 0.03544643893837929\n",
      "Epoch 4013, Loss: 0.104075588285923, Final Batch Loss: 0.07545610517263412\n",
      "Epoch 4014, Loss: 0.08025257289409637, Final Batch Loss: 0.04572828486561775\n",
      "Epoch 4015, Loss: 0.061706436797976494, Final Batch Loss: 0.02979571558535099\n",
      "Epoch 4016, Loss: 0.06154862977564335, Final Batch Loss: 0.02188302017748356\n",
      "Epoch 4017, Loss: 0.05287703685462475, Final Batch Loss: 0.018069950863718987\n",
      "Epoch 4018, Loss: 0.0589707437902689, Final Batch Loss: 0.02649608813226223\n",
      "Epoch 4019, Loss: 0.08120196871459484, Final Batch Loss: 0.016787616536021233\n",
      "Epoch 4020, Loss: 0.08260195329785347, Final Batch Loss: 0.049451012164354324\n",
      "Epoch 4021, Loss: 0.07791364751756191, Final Batch Loss: 0.052322037518024445\n",
      "Epoch 4022, Loss: 0.07280859258025885, Final Batch Loss: 0.012762743048369884\n",
      "Epoch 4023, Loss: 0.08354196138679981, Final Batch Loss: 0.057946447283029556\n",
      "Epoch 4024, Loss: 0.06382768414914608, Final Batch Loss: 0.018879888579249382\n",
      "Epoch 4025, Loss: 0.07916821725666523, Final Batch Loss: 0.0165818203240633\n",
      "Epoch 4026, Loss: 0.07720732875168324, Final Batch Loss: 0.05138712376356125\n",
      "Epoch 4027, Loss: 0.11297883093357086, Final Batch Loss: 0.04941600561141968\n",
      "Epoch 4028, Loss: 0.06222439371049404, Final Batch Loss: 0.03347431495785713\n",
      "Epoch 4029, Loss: 0.06777379661798477, Final Batch Loss: 0.023882359266281128\n",
      "Epoch 4030, Loss: 0.07203841768205166, Final Batch Loss: 0.027596166357398033\n",
      "Epoch 4031, Loss: 0.06443743221461773, Final Batch Loss: 0.035977140069007874\n",
      "Epoch 4032, Loss: 0.05551622435450554, Final Batch Loss: 0.030497219413518906\n",
      "Epoch 4033, Loss: 0.08546432107686996, Final Batch Loss: 0.05837450176477432\n",
      "Epoch 4034, Loss: 0.06091617792844772, Final Batch Loss: 0.02481875568628311\n",
      "Epoch 4035, Loss: 0.06358598545193672, Final Batch Loss: 0.037487663328647614\n",
      "Epoch 4036, Loss: 0.061628470197319984, Final Batch Loss: 0.03970605134963989\n",
      "Epoch 4037, Loss: 0.08150367066264153, Final Batch Loss: 0.03881227225065231\n",
      "Epoch 4038, Loss: 0.1082196868956089, Final Batch Loss: 0.07557008415460587\n",
      "Epoch 4039, Loss: 0.08013622835278511, Final Batch Loss: 0.04655857011675835\n",
      "Epoch 4040, Loss: 0.06328966654837132, Final Batch Loss: 0.0311866644769907\n",
      "Epoch 4041, Loss: 0.09371896088123322, Final Batch Loss: 0.06136471405625343\n",
      "Epoch 4042, Loss: 0.06082889251410961, Final Batch Loss: 0.03804181516170502\n",
      "Epoch 4043, Loss: 0.0511489063501358, Final Batch Loss: 0.028484269976615906\n",
      "Epoch 4044, Loss: 0.08720961585640907, Final Batch Loss: 0.041793592274188995\n",
      "Epoch 4045, Loss: 0.05881149135529995, Final Batch Loss: 0.028239456936717033\n",
      "Epoch 4046, Loss: 0.07361666858196259, Final Batch Loss: 0.03503715619444847\n",
      "Epoch 4047, Loss: 0.055747007951140404, Final Batch Loss: 0.020236117765307426\n",
      "Epoch 4048, Loss: 0.06511338613927364, Final Batch Loss: 0.03993971273303032\n",
      "Epoch 4049, Loss: 0.06725059635937214, Final Batch Loss: 0.03764058277010918\n",
      "Epoch 4050, Loss: 0.055075375363230705, Final Batch Loss: 0.019048674032092094\n",
      "Epoch 4051, Loss: 0.05560892075300217, Final Batch Loss: 0.010672040283679962\n",
      "Epoch 4052, Loss: 0.11170150339603424, Final Batch Loss: 0.060996927320957184\n",
      "Epoch 4053, Loss: 0.06721234135329723, Final Batch Loss: 0.04019801691174507\n",
      "Epoch 4054, Loss: 0.07319066114723682, Final Batch Loss: 0.020949916914105415\n",
      "Epoch 4055, Loss: 0.11018501222133636, Final Batch Loss: 0.07227477431297302\n",
      "Epoch 4056, Loss: 0.07784358412027359, Final Batch Loss: 0.05240171030163765\n",
      "Epoch 4057, Loss: 0.0684890653938055, Final Batch Loss: 0.028747690841555595\n",
      "Epoch 4058, Loss: 0.07209592685103416, Final Batch Loss: 0.02334563434123993\n",
      "Epoch 4059, Loss: 0.06942136399447918, Final Batch Loss: 0.020343856886029243\n",
      "Epoch 4060, Loss: 0.11834549903869629, Final Batch Loss: 0.07315399497747421\n",
      "Epoch 4061, Loss: 0.080795181915164, Final Batch Loss: 0.05182615667581558\n",
      "Epoch 4062, Loss: 0.08057871088385582, Final Batch Loss: 0.04598299041390419\n",
      "Epoch 4063, Loss: 0.12781194224953651, Final Batch Loss: 0.06880386173725128\n",
      "Epoch 4064, Loss: 0.07697910815477371, Final Batch Loss: 0.04150805249810219\n",
      "Epoch 4065, Loss: 0.08008435368537903, Final Batch Loss: 0.043266598135232925\n",
      "Epoch 4066, Loss: 0.1007697805762291, Final Batch Loss: 0.05149904638528824\n",
      "Epoch 4067, Loss: 0.07803328149020672, Final Batch Loss: 0.027249639853835106\n",
      "Epoch 4068, Loss: 0.06106306426227093, Final Batch Loss: 0.03162789344787598\n",
      "Epoch 4069, Loss: 0.09881950542330742, Final Batch Loss: 0.06112224608659744\n",
      "Epoch 4070, Loss: 0.06997237354516983, Final Batch Loss: 0.03976696729660034\n",
      "Epoch 4071, Loss: 0.08266489580273628, Final Batch Loss: 0.04459378495812416\n",
      "Epoch 4072, Loss: 0.08848511427640915, Final Batch Loss: 0.0526881217956543\n",
      "Epoch 4073, Loss: 0.11467615514993668, Final Batch Loss: 0.04190099239349365\n",
      "Epoch 4074, Loss: 0.08967967703938484, Final Batch Loss: 0.04954613372683525\n",
      "Epoch 4075, Loss: 0.08630570210516453, Final Batch Loss: 0.06467989087104797\n",
      "Epoch 4076, Loss: 0.05562741030007601, Final Batch Loss: 0.010748581029474735\n",
      "Epoch 4077, Loss: 0.09338757023215294, Final Batch Loss: 0.04989320784807205\n",
      "Epoch 4078, Loss: 0.07240195199847221, Final Batch Loss: 0.027736414223909378\n",
      "Epoch 4079, Loss: 0.09309124201536179, Final Batch Loss: 0.05879291146993637\n",
      "Epoch 4080, Loss: 0.0673284363001585, Final Batch Loss: 0.03017132170498371\n",
      "Epoch 4081, Loss: 0.06130979582667351, Final Batch Loss: 0.02530665323138237\n",
      "Epoch 4082, Loss: 0.05711766146123409, Final Batch Loss: 0.019582176581025124\n",
      "Epoch 4083, Loss: 0.053680114448070526, Final Batch Loss: 0.022920696064829826\n",
      "Epoch 4084, Loss: 0.07272540032863617, Final Batch Loss: 0.03684988245368004\n",
      "Epoch 4085, Loss: 0.05358740221709013, Final Batch Loss: 0.012317056767642498\n",
      "Epoch 4086, Loss: 0.038633918389678, Final Batch Loss: 0.016248326748609543\n",
      "Epoch 4087, Loss: 0.05703361704945564, Final Batch Loss: 0.021675564348697662\n",
      "Epoch 4088, Loss: 0.0849234126508236, Final Batch Loss: 0.036966972053050995\n",
      "Epoch 4089, Loss: 0.10867853090167046, Final Batch Loss: 0.043388571590185165\n",
      "Epoch 4090, Loss: 0.05253957025706768, Final Batch Loss: 0.0321168452501297\n",
      "Epoch 4091, Loss: 0.07201176509261131, Final Batch Loss: 0.03305475041270256\n",
      "Epoch 4092, Loss: 0.07222224399447441, Final Batch Loss: 0.03573036938905716\n",
      "Epoch 4093, Loss: 0.077362060546875, Final Batch Loss: 0.04055042564868927\n",
      "Epoch 4094, Loss: 0.05288369953632355, Final Batch Loss: 0.01693606749176979\n",
      "Epoch 4095, Loss: 0.06709438189864159, Final Batch Loss: 0.014406610280275345\n",
      "Epoch 4096, Loss: 0.0647053811699152, Final Batch Loss: 0.019754445180296898\n",
      "Epoch 4097, Loss: 0.0792880617082119, Final Batch Loss: 0.034791383892297745\n",
      "Epoch 4098, Loss: 0.2658185511827469, Final Batch Loss: 0.21710912883281708\n",
      "Epoch 4099, Loss: 0.07470468059182167, Final Batch Loss: 0.036581046879291534\n",
      "Epoch 4100, Loss: 0.056336402893066406, Final Batch Loss: 0.024328086525201797\n",
      "Epoch 4101, Loss: 0.18023284524679184, Final Batch Loss: 0.1062575951218605\n",
      "Epoch 4102, Loss: 0.11039691232144833, Final Batch Loss: 0.020457757636904716\n",
      "Epoch 4103, Loss: 0.09782181680202484, Final Batch Loss: 0.03992791846394539\n",
      "Epoch 4104, Loss: 0.0904235877096653, Final Batch Loss: 0.04986932873725891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4105, Loss: 0.07131918147206306, Final Batch Loss: 0.022309157997369766\n",
      "Epoch 4106, Loss: 0.09533420205116272, Final Batch Loss: 0.04803141951560974\n",
      "Epoch 4107, Loss: 0.08955268934369087, Final Batch Loss: 0.04253504052758217\n",
      "Epoch 4108, Loss: 0.11684608086943626, Final Batch Loss: 0.07286801189184189\n",
      "Epoch 4109, Loss: 0.07538469508290291, Final Batch Loss: 0.033606164157390594\n",
      "Epoch 4110, Loss: 0.07777158170938492, Final Batch Loss: 0.04534844681620598\n",
      "Epoch 4111, Loss: 0.0743284784257412, Final Batch Loss: 0.045633409172296524\n",
      "Epoch 4112, Loss: 0.0836721770465374, Final Batch Loss: 0.0330551341176033\n",
      "Epoch 4113, Loss: 0.05860993638634682, Final Batch Loss: 0.030618736520409584\n",
      "Epoch 4114, Loss: 0.058729663491249084, Final Batch Loss: 0.027235355228185654\n",
      "Epoch 4115, Loss: 0.05584120750427246, Final Batch Loss: 0.03261098638176918\n",
      "Epoch 4116, Loss: 0.057069769129157066, Final Batch Loss: 0.019113825634121895\n",
      "Epoch 4117, Loss: 0.06356003228574991, Final Batch Loss: 0.010220327414572239\n",
      "Epoch 4118, Loss: 0.049068739637732506, Final Batch Loss: 0.023491818457841873\n",
      "Epoch 4119, Loss: 0.059769975021481514, Final Batch Loss: 0.03372703865170479\n",
      "Epoch 4120, Loss: 0.05445784516632557, Final Batch Loss: 0.014111420139670372\n",
      "Epoch 4121, Loss: 0.05194494966417551, Final Batch Loss: 0.011077036149799824\n",
      "Epoch 4122, Loss: 0.06344745308160782, Final Batch Loss: 0.014017943292856216\n",
      "Epoch 4123, Loss: 0.11317447200417519, Final Batch Loss: 0.056440871208906174\n",
      "Epoch 4124, Loss: 0.06614138558506966, Final Batch Loss: 0.039411045610904694\n",
      "Epoch 4125, Loss: 0.13351693376898766, Final Batch Loss: 0.03468020632863045\n",
      "Epoch 4126, Loss: 0.06365174986422062, Final Batch Loss: 0.03882374241948128\n",
      "Epoch 4127, Loss: 0.09297234192490578, Final Batch Loss: 0.02943423017859459\n",
      "Epoch 4128, Loss: 0.1307927779853344, Final Batch Loss: 0.10268314927816391\n",
      "Epoch 4129, Loss: 0.0942528210580349, Final Batch Loss: 0.055505864322185516\n",
      "Epoch 4130, Loss: 0.06704461574554443, Final Batch Loss: 0.039909813553094864\n",
      "Epoch 4131, Loss: 0.08466534316539764, Final Batch Loss: 0.051254767924547195\n",
      "Epoch 4132, Loss: 0.05156114883720875, Final Batch Loss: 0.028068389743566513\n",
      "Epoch 4133, Loss: 0.08396834693849087, Final Batch Loss: 0.05493304505944252\n",
      "Epoch 4134, Loss: 0.06515436805784702, Final Batch Loss: 0.02215815894305706\n",
      "Epoch 4135, Loss: 0.07395440712571144, Final Batch Loss: 0.033906467258930206\n",
      "Epoch 4136, Loss: 0.05683179013431072, Final Batch Loss: 0.02391190268099308\n",
      "Epoch 4137, Loss: 0.06298322230577469, Final Batch Loss: 0.03974403068423271\n",
      "Epoch 4138, Loss: 0.07831189036369324, Final Batch Loss: 0.05687399208545685\n",
      "Epoch 4139, Loss: 0.073605265468359, Final Batch Loss: 0.03688892722129822\n",
      "Epoch 4140, Loss: 0.10353515669703484, Final Batch Loss: 0.04434908181428909\n",
      "Epoch 4141, Loss: 0.0854899026453495, Final Batch Loss: 0.04503617808222771\n",
      "Epoch 4142, Loss: 0.33458901569247246, Final Batch Loss: 0.30164220929145813\n",
      "Epoch 4143, Loss: 0.07433383166790009, Final Batch Loss: 0.017200209200382233\n",
      "Epoch 4144, Loss: 0.06429621949791908, Final Batch Loss: 0.03835358843207359\n",
      "Epoch 4145, Loss: 0.13066016137599945, Final Batch Loss: 0.07786078006029129\n",
      "Epoch 4146, Loss: 0.08181948214769363, Final Batch Loss: 0.017385900020599365\n",
      "Epoch 4147, Loss: 0.07557930052280426, Final Batch Loss: 0.017400026321411133\n",
      "Epoch 4148, Loss: 0.20673517882823944, Final Batch Loss: 0.15578143298625946\n",
      "Epoch 4149, Loss: 0.08083903789520264, Final Batch Loss: 0.03748913109302521\n",
      "Epoch 4150, Loss: 0.08312656730413437, Final Batch Loss: 0.050557691603899\n",
      "Epoch 4151, Loss: 0.06930364295840263, Final Batch Loss: 0.035537030547857285\n",
      "Epoch 4152, Loss: 0.09135918645188212, Final Batch Loss: 0.006181355100125074\n",
      "Epoch 4153, Loss: 0.07779875211417675, Final Batch Loss: 0.021671531721949577\n",
      "Epoch 4154, Loss: 0.08723561093211174, Final Batch Loss: 0.029841963201761246\n",
      "Epoch 4155, Loss: 0.1219758540391922, Final Batch Loss: 0.09071793407201767\n",
      "Epoch 4156, Loss: 0.06221235543489456, Final Batch Loss: 0.031792767345905304\n",
      "Epoch 4157, Loss: 0.06314341071993113, Final Batch Loss: 0.012255632318556309\n",
      "Epoch 4158, Loss: 0.08977923542261124, Final Batch Loss: 0.05689813569188118\n",
      "Epoch 4159, Loss: 0.09067407995462418, Final Batch Loss: 0.05755165219306946\n",
      "Epoch 4160, Loss: 0.07401591539382935, Final Batch Loss: 0.04253154993057251\n",
      "Epoch 4161, Loss: 0.0945783406496048, Final Batch Loss: 0.04896507039666176\n",
      "Epoch 4162, Loss: 0.07458373159170151, Final Batch Loss: 0.03290833160281181\n",
      "Epoch 4163, Loss: 0.059742946177721024, Final Batch Loss: 0.02468334510922432\n",
      "Epoch 4164, Loss: 0.06205272860825062, Final Batch Loss: 0.026792170479893684\n",
      "Epoch 4165, Loss: 0.1049112118780613, Final Batch Loss: 0.0762731209397316\n",
      "Epoch 4166, Loss: 0.10276491940021515, Final Batch Loss: 0.06570196896791458\n",
      "Epoch 4167, Loss: 0.11143498495221138, Final Batch Loss: 0.046405110508203506\n",
      "Epoch 4168, Loss: 0.0942978523671627, Final Batch Loss: 0.07107590138912201\n",
      "Epoch 4169, Loss: 0.1765480414032936, Final Batch Loss: 0.05483980476856232\n",
      "Epoch 4170, Loss: 0.10563671216368675, Final Batch Loss: 0.057119376957416534\n",
      "Epoch 4171, Loss: 0.06614325568079948, Final Batch Loss: 0.03903483971953392\n",
      "Epoch 4172, Loss: 0.08121511340141296, Final Batch Loss: 0.03862539306282997\n",
      "Epoch 4173, Loss: 0.07368257641792297, Final Batch Loss: 0.033161014318466187\n",
      "Epoch 4174, Loss: 0.10242531821131706, Final Batch Loss: 0.03736046329140663\n",
      "Epoch 4175, Loss: 0.11283736489713192, Final Batch Loss: 0.08528269827365875\n",
      "Epoch 4176, Loss: 0.08105133473873138, Final Batch Loss: 0.05681091174483299\n",
      "Epoch 4177, Loss: 0.105800312012434, Final Batch Loss: 0.045569196343421936\n",
      "Epoch 4178, Loss: 0.07802113518118858, Final Batch Loss: 0.03103714808821678\n",
      "Epoch 4179, Loss: 0.07792668044567108, Final Batch Loss: 0.038730524480342865\n",
      "Epoch 4180, Loss: 0.09170703589916229, Final Batch Loss: 0.026451215147972107\n",
      "Epoch 4181, Loss: 0.09662863239645958, Final Batch Loss: 0.061092399060726166\n",
      "Epoch 4182, Loss: 0.06035148166120052, Final Batch Loss: 0.018286144360899925\n",
      "Epoch 4183, Loss: 0.037177131511271, Final Batch Loss: 0.008613060228526592\n",
      "Epoch 4184, Loss: 0.10032706335186958, Final Batch Loss: 0.04404330626130104\n",
      "Epoch 4185, Loss: 0.04714864445850253, Final Batch Loss: 0.0076300459913909435\n",
      "Epoch 4186, Loss: 0.05379396677017212, Final Batch Loss: 0.018142729997634888\n",
      "Epoch 4187, Loss: 0.05344666354358196, Final Batch Loss: 0.022520476952195168\n",
      "Epoch 4188, Loss: 0.043344756588339806, Final Batch Loss: 0.02152837999165058\n",
      "Epoch 4189, Loss: 0.10747106373310089, Final Batch Loss: 0.07433083653450012\n",
      "Epoch 4190, Loss: 0.07074611447751522, Final Batch Loss: 0.027403296902775764\n",
      "Epoch 4191, Loss: 0.0676654614508152, Final Batch Loss: 0.03419460728764534\n",
      "Epoch 4192, Loss: 0.05388103425502777, Final Batch Loss: 0.018778976052999496\n",
      "Epoch 4193, Loss: 0.05478138476610184, Final Batch Loss: 0.022350400686264038\n",
      "Epoch 4194, Loss: 0.048632215708494186, Final Batch Loss: 0.029545050114393234\n",
      "Epoch 4195, Loss: 0.1025061160326004, Final Batch Loss: 0.04279877990484238\n",
      "Epoch 4196, Loss: 0.060401519760489464, Final Batch Loss: 0.024133609607815742\n",
      "Epoch 4197, Loss: 0.06788890063762665, Final Batch Loss: 0.04562343657016754\n",
      "Epoch 4198, Loss: 0.07007848285138607, Final Batch Loss: 0.02314269356429577\n",
      "Epoch 4199, Loss: 0.06786643527448177, Final Batch Loss: 0.0471455417573452\n",
      "Epoch 4200, Loss: 0.04858187399804592, Final Batch Loss: 0.03268229961395264\n",
      "Epoch 4201, Loss: 0.06695646233856678, Final Batch Loss: 0.02691563032567501\n",
      "Epoch 4202, Loss: 0.06447542272508144, Final Batch Loss: 0.026247775182127953\n",
      "Epoch 4203, Loss: 0.09513938426971436, Final Batch Loss: 0.039246927946805954\n",
      "Epoch 4204, Loss: 0.057274509221315384, Final Batch Loss: 0.024615507572889328\n",
      "Epoch 4205, Loss: 0.050820402801036835, Final Batch Loss: 0.022952938452363014\n",
      "Epoch 4206, Loss: 0.05475371237844229, Final Batch Loss: 0.013857762329280376\n",
      "Epoch 4207, Loss: 0.07685443572700024, Final Batch Loss: 0.047705598175525665\n",
      "Epoch 4208, Loss: 0.08514684438705444, Final Batch Loss: 0.049333490431308746\n",
      "Epoch 4209, Loss: 0.04392852075397968, Final Batch Loss: 0.01612185500562191\n",
      "Epoch 4210, Loss: 0.09897391684353352, Final Batch Loss: 0.08068547397851944\n",
      "Epoch 4211, Loss: 0.08417918160557747, Final Batch Loss: 0.050630029290914536\n",
      "Epoch 4212, Loss: 0.08604307472705841, Final Batch Loss: 0.04772360995411873\n",
      "Epoch 4213, Loss: 0.049979131668806076, Final Batch Loss: 0.026772845536470413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4214, Loss: 0.07500303909182549, Final Batch Loss: 0.039605848491191864\n",
      "Epoch 4215, Loss: 0.0659501114860177, Final Batch Loss: 0.01071563083678484\n",
      "Epoch 4216, Loss: 0.046874433755874634, Final Batch Loss: 0.026051796972751617\n",
      "Epoch 4217, Loss: 0.07069497928023338, Final Batch Loss: 0.036900848150253296\n",
      "Epoch 4218, Loss: 0.10938123241066933, Final Batch Loss: 0.02026304230093956\n",
      "Epoch 4219, Loss: 0.05098225176334381, Final Batch Loss: 0.02469060756266117\n",
      "Epoch 4220, Loss: 0.033126323483884335, Final Batch Loss: 0.009418078698217869\n",
      "Epoch 4221, Loss: 0.044059271924197674, Final Batch Loss: 0.008689737878739834\n",
      "Epoch 4222, Loss: 0.07126602716743946, Final Batch Loss: 0.022695699706673622\n",
      "Epoch 4223, Loss: 0.07772288657724857, Final Batch Loss: 0.04739315062761307\n",
      "Epoch 4224, Loss: 0.05012442544102669, Final Batch Loss: 0.016161654144525528\n",
      "Epoch 4225, Loss: 0.05079421028494835, Final Batch Loss: 0.0185040682554245\n",
      "Epoch 4226, Loss: 0.08654522523283958, Final Batch Loss: 0.06617767363786697\n",
      "Epoch 4227, Loss: 0.06906239688396454, Final Batch Loss: 0.0368790365755558\n",
      "Epoch 4228, Loss: 0.06639687158167362, Final Batch Loss: 0.015956280753016472\n",
      "Epoch 4229, Loss: 0.06332166492938995, Final Batch Loss: 0.042840711772441864\n",
      "Epoch 4230, Loss: 0.05931428074836731, Final Batch Loss: 0.032036952674388885\n",
      "Epoch 4231, Loss: 0.06165129877626896, Final Batch Loss: 0.039571613073349\n",
      "Epoch 4232, Loss: 0.07348145544528961, Final Batch Loss: 0.0352492555975914\n",
      "Epoch 4233, Loss: 0.07902210205793381, Final Batch Loss: 0.05229601263999939\n",
      "Epoch 4234, Loss: 0.05062894895672798, Final Batch Loss: 0.03277839347720146\n",
      "Epoch 4235, Loss: 0.07012333907186985, Final Batch Loss: 0.04640066251158714\n",
      "Epoch 4236, Loss: 0.049783309921622276, Final Batch Loss: 0.027593867853283882\n",
      "Epoch 4237, Loss: 0.09735787287354469, Final Batch Loss: 0.05824154615402222\n",
      "Epoch 4238, Loss: 0.04971339646726847, Final Batch Loss: 0.03704677149653435\n",
      "Epoch 4239, Loss: 0.13468638062477112, Final Batch Loss: 0.10208804905414581\n",
      "Epoch 4240, Loss: 0.09832368046045303, Final Batch Loss: 0.06337841600179672\n",
      "Epoch 4241, Loss: 0.05005716532468796, Final Batch Loss: 0.020407570526003838\n",
      "Epoch 4242, Loss: 0.07499898225069046, Final Batch Loss: 0.04300815984606743\n",
      "Epoch 4243, Loss: 0.05594675429165363, Final Batch Loss: 0.02600877732038498\n",
      "Epoch 4244, Loss: 0.045587917789816856, Final Batch Loss: 0.015728237107396126\n",
      "Epoch 4245, Loss: 0.0943688414990902, Final Batch Loss: 0.0743526965379715\n",
      "Epoch 4246, Loss: 0.07226033508777618, Final Batch Loss: 0.034315112978219986\n",
      "Epoch 4247, Loss: 0.07718931511044502, Final Batch Loss: 0.031701214611530304\n",
      "Epoch 4248, Loss: 0.07592426426708698, Final Batch Loss: 0.05570580065250397\n",
      "Epoch 4249, Loss: 0.056759199127554893, Final Batch Loss: 0.027836686000227928\n",
      "Epoch 4250, Loss: 0.07265675440430641, Final Batch Loss: 0.04140457510948181\n",
      "Epoch 4251, Loss: 0.07394695654511452, Final Batch Loss: 0.036522526293992996\n",
      "Epoch 4252, Loss: 0.07439527288079262, Final Batch Loss: 0.023387718945741653\n",
      "Epoch 4253, Loss: 0.08990584872663021, Final Batch Loss: 0.06352906674146652\n",
      "Epoch 4254, Loss: 0.10123443603515625, Final Batch Loss: 0.053062111139297485\n",
      "Epoch 4255, Loss: 0.058653056621551514, Final Batch Loss: 0.030414018779993057\n",
      "Epoch 4256, Loss: 0.08093570731580257, Final Batch Loss: 0.050294723361730576\n",
      "Epoch 4257, Loss: 0.041185131296515465, Final Batch Loss: 0.022406069561839104\n",
      "Epoch 4258, Loss: 0.08715208247303963, Final Batch Loss: 0.0352034755051136\n",
      "Epoch 4259, Loss: 0.09361198917031288, Final Batch Loss: 0.03716866299510002\n",
      "Epoch 4260, Loss: 0.053083207458257675, Final Batch Loss: 0.022847702726721764\n",
      "Epoch 4261, Loss: 0.08298942819237709, Final Batch Loss: 0.044296201318502426\n",
      "Epoch 4262, Loss: 0.09912603721022606, Final Batch Loss: 0.04342595487833023\n",
      "Epoch 4263, Loss: 0.06932275556027889, Final Batch Loss: 0.0521862767636776\n",
      "Epoch 4264, Loss: 0.04147337190806866, Final Batch Loss: 0.015821054577827454\n",
      "Epoch 4265, Loss: 0.07876911014318466, Final Batch Loss: 0.03880271688103676\n",
      "Epoch 4266, Loss: 0.0515071339905262, Final Batch Loss: 0.015646878629922867\n",
      "Epoch 4267, Loss: 0.07527784258127213, Final Batch Loss: 0.05604131892323494\n",
      "Epoch 4268, Loss: 0.09972500056028366, Final Batch Loss: 0.07965343445539474\n",
      "Epoch 4269, Loss: 0.07358431071043015, Final Batch Loss: 0.027713261544704437\n",
      "Epoch 4270, Loss: 0.08499119058251381, Final Batch Loss: 0.04144690930843353\n",
      "Epoch 4271, Loss: 0.06816010922193527, Final Batch Loss: 0.04887477308511734\n",
      "Epoch 4272, Loss: 0.04914373345673084, Final Batch Loss: 0.024965351447463036\n",
      "Epoch 4273, Loss: 0.06285565346479416, Final Batch Loss: 0.0375981442630291\n",
      "Epoch 4274, Loss: 0.11343511193990707, Final Batch Loss: 0.09272433817386627\n",
      "Epoch 4275, Loss: 0.07145476713776588, Final Batch Loss: 0.02898383140563965\n",
      "Epoch 4276, Loss: 0.060422785580158234, Final Batch Loss: 0.017041724175214767\n",
      "Epoch 4277, Loss: 0.06759050488471985, Final Batch Loss: 0.03674923628568649\n",
      "Epoch 4278, Loss: 0.06674146093428135, Final Batch Loss: 0.015130562707781792\n",
      "Epoch 4279, Loss: 0.05608097091317177, Final Batch Loss: 0.02689613215625286\n",
      "Epoch 4280, Loss: 0.23510248586535454, Final Batch Loss: 0.1959020346403122\n",
      "Epoch 4281, Loss: 0.06513697188347578, Final Batch Loss: 0.05016739293932915\n",
      "Epoch 4282, Loss: 0.16223541274666786, Final Batch Loss: 0.1287539005279541\n",
      "Epoch 4283, Loss: 0.06032928638160229, Final Batch Loss: 0.03076988458633423\n",
      "Epoch 4284, Loss: 0.07375204749405384, Final Batch Loss: 0.015710854902863503\n",
      "Epoch 4285, Loss: 0.0632958048954606, Final Batch Loss: 0.011521310545504093\n",
      "Epoch 4286, Loss: 0.06809413619339466, Final Batch Loss: 0.019191620871424675\n",
      "Epoch 4287, Loss: 0.07245950773358345, Final Batch Loss: 0.02111608162522316\n",
      "Epoch 4288, Loss: 0.06937489658594131, Final Batch Loss: 0.023847315460443497\n",
      "Epoch 4289, Loss: 0.09410366788506508, Final Batch Loss: 0.038000162690877914\n",
      "Epoch 4290, Loss: 0.09553558379411697, Final Batch Loss: 0.043360378593206406\n",
      "Epoch 4291, Loss: 0.05153836216777563, Final Batch Loss: 0.014029393903911114\n",
      "Epoch 4292, Loss: 0.09331220388412476, Final Batch Loss: 0.056349098682403564\n",
      "Epoch 4293, Loss: 0.10143407247960567, Final Batch Loss: 0.08361092209815979\n",
      "Epoch 4294, Loss: 0.0773882158100605, Final Batch Loss: 0.04888312146067619\n",
      "Epoch 4295, Loss: 0.09798672422766685, Final Batch Loss: 0.05517549812793732\n",
      "Epoch 4296, Loss: 0.1022740937769413, Final Batch Loss: 0.07756849378347397\n",
      "Epoch 4297, Loss: 0.049699075520038605, Final Batch Loss: 0.0217397753149271\n",
      "Epoch 4298, Loss: 0.08132379315793514, Final Batch Loss: 0.052888717502355576\n",
      "Epoch 4299, Loss: 0.0795016884803772, Final Batch Loss: 0.00893043726682663\n",
      "Epoch 4300, Loss: 0.07637140527367592, Final Batch Loss: 0.0391574427485466\n",
      "Epoch 4301, Loss: 0.09021714329719543, Final Batch Loss: 0.04965762421488762\n",
      "Epoch 4302, Loss: 0.12558168545365334, Final Batch Loss: 0.08399152010679245\n",
      "Epoch 4303, Loss: 0.13004836067557335, Final Batch Loss: 0.07868824154138565\n",
      "Epoch 4304, Loss: 0.13600413128733635, Final Batch Loss: 0.09460293501615524\n",
      "Epoch 4305, Loss: 0.05873922165483236, Final Batch Loss: 0.014837908558547497\n",
      "Epoch 4306, Loss: 0.07489464432001114, Final Batch Loss: 0.04063768684864044\n",
      "Epoch 4307, Loss: 0.12206905335187912, Final Batch Loss: 0.043383270502090454\n",
      "Epoch 4308, Loss: 0.07682190090417862, Final Batch Loss: 0.022151194512844086\n",
      "Epoch 4309, Loss: 0.12155446782708168, Final Batch Loss: 0.03752238675951958\n",
      "Epoch 4310, Loss: 0.07470983453094959, Final Batch Loss: 0.026591530069708824\n",
      "Epoch 4311, Loss: 0.05705462209880352, Final Batch Loss: 0.027445506304502487\n",
      "Epoch 4312, Loss: 0.09816579520702362, Final Batch Loss: 0.047538284212350845\n",
      "Epoch 4313, Loss: 0.09579957649111748, Final Batch Loss: 0.03984211012721062\n",
      "Epoch 4314, Loss: 0.08864780515432358, Final Batch Loss: 0.04943273216485977\n",
      "Epoch 4315, Loss: 0.08624729886651039, Final Batch Loss: 0.04600183293223381\n",
      "Epoch 4316, Loss: 0.1748010590672493, Final Batch Loss: 0.12255768477916718\n",
      "Epoch 4317, Loss: 0.043283263221383095, Final Batch Loss: 0.011049522086977959\n",
      "Epoch 4318, Loss: 0.07573944702744484, Final Batch Loss: 0.012507695704698563\n",
      "Epoch 4319, Loss: 0.22714461386203766, Final Batch Loss: 0.18387429416179657\n",
      "Epoch 4320, Loss: 0.11757133435457945, Final Batch Loss: 0.014365258626639843\n",
      "Epoch 4321, Loss: 0.0786966010928154, Final Batch Loss: 0.037074968218803406\n",
      "Epoch 4322, Loss: 0.12476107850670815, Final Batch Loss: 0.08536414802074432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4323, Loss: 0.3028346225619316, Final Batch Loss: 0.2798435389995575\n",
      "Epoch 4324, Loss: 0.09044402092695236, Final Batch Loss: 0.051753152161836624\n",
      "Epoch 4325, Loss: 0.2389562577009201, Final Batch Loss: 0.03561468422412872\n",
      "Epoch 4326, Loss: 0.13326319120824337, Final Batch Loss: 0.023558838292956352\n",
      "Epoch 4327, Loss: 0.19822004437446594, Final Batch Loss: 0.1227656826376915\n",
      "Epoch 4328, Loss: 0.06310634315013885, Final Batch Loss: 0.0331001803278923\n",
      "Epoch 4329, Loss: 0.10757585614919662, Final Batch Loss: 0.06973592191934586\n",
      "Epoch 4330, Loss: 0.17723829299211502, Final Batch Loss: 0.0167432501912117\n",
      "Epoch 4331, Loss: 0.1097696591168642, Final Batch Loss: 0.028655195608735085\n",
      "Epoch 4332, Loss: 0.06191580928862095, Final Batch Loss: 0.022086499258875847\n",
      "Epoch 4333, Loss: 0.14118558168411255, Final Batch Loss: 0.05537084490060806\n",
      "Epoch 4334, Loss: 0.13440753147006035, Final Batch Loss: 0.08500558137893677\n",
      "Epoch 4335, Loss: 0.29516376554965973, Final Batch Loss: 0.2552337348461151\n",
      "Epoch 4336, Loss: 0.1473683826625347, Final Batch Loss: 0.10189559310674667\n",
      "Epoch 4337, Loss: 0.13801904395222664, Final Batch Loss: 0.08902667462825775\n",
      "Epoch 4338, Loss: 0.14621379598975182, Final Batch Loss: 0.09346523880958557\n",
      "Epoch 4339, Loss: 0.10824893042445183, Final Batch Loss: 0.04883814603090286\n",
      "Epoch 4340, Loss: 0.10575302690267563, Final Batch Loss: 0.058745309710502625\n",
      "Epoch 4341, Loss: 0.08743451908230782, Final Batch Loss: 0.03701186925172806\n",
      "Epoch 4342, Loss: 0.23091251403093338, Final Batch Loss: 0.17982938885688782\n",
      "Epoch 4343, Loss: 0.09722936153411865, Final Batch Loss: 0.01947757601737976\n",
      "Epoch 4344, Loss: 0.1111827902495861, Final Batch Loss: 0.04913826659321785\n",
      "Epoch 4345, Loss: 0.11671124398708344, Final Batch Loss: 0.06719963997602463\n",
      "Epoch 4346, Loss: 0.057950607500970364, Final Batch Loss: 0.015218830667436123\n",
      "Epoch 4347, Loss: 0.08158186078071594, Final Batch Loss: 0.039696104824543\n",
      "Epoch 4348, Loss: 0.08473807573318481, Final Batch Loss: 0.021609045565128326\n",
      "Epoch 4349, Loss: 0.07685216329991817, Final Batch Loss: 0.0293459240347147\n",
      "Epoch 4350, Loss: 0.08331264182925224, Final Batch Loss: 0.03354474529623985\n",
      "Epoch 4351, Loss: 0.070309117436409, Final Batch Loss: 0.02087634801864624\n",
      "Epoch 4352, Loss: 0.07403088361024857, Final Batch Loss: 0.03491566330194473\n",
      "Epoch 4353, Loss: 0.08009291812777519, Final Batch Loss: 0.034160811454057693\n",
      "Epoch 4354, Loss: 0.062152860686182976, Final Batch Loss: 0.04027564451098442\n",
      "Epoch 4355, Loss: 0.061016444116830826, Final Batch Loss: 0.021194126456975937\n",
      "Epoch 4356, Loss: 0.08588404208421707, Final Batch Loss: 0.054640993475914\n",
      "Epoch 4357, Loss: 0.08847119472920895, Final Batch Loss: 0.02646137960255146\n",
      "Epoch 4358, Loss: 0.05860477313399315, Final Batch Loss: 0.028730792924761772\n",
      "Epoch 4359, Loss: 0.08184288442134857, Final Batch Loss: 0.03647640720009804\n",
      "Epoch 4360, Loss: 0.08360290713608265, Final Batch Loss: 0.028594063594937325\n",
      "Epoch 4361, Loss: 0.06861178949475288, Final Batch Loss: 0.03270193561911583\n",
      "Epoch 4362, Loss: 0.04419525992125273, Final Batch Loss: 0.015158227644860744\n",
      "Epoch 4363, Loss: 0.06989291496574879, Final Batch Loss: 0.017433656379580498\n",
      "Epoch 4364, Loss: 0.06866482645273209, Final Batch Loss: 0.034850455820560455\n",
      "Epoch 4365, Loss: 0.07111054472625256, Final Batch Loss: 0.04628274217247963\n",
      "Epoch 4366, Loss: 0.06525927223265171, Final Batch Loss: 0.013783613219857216\n",
      "Epoch 4367, Loss: 0.053736889734864235, Final Batch Loss: 0.020902512595057487\n",
      "Epoch 4368, Loss: 0.07488756999373436, Final Batch Loss: 0.04300317168235779\n",
      "Epoch 4369, Loss: 0.06633774004876614, Final Batch Loss: 0.02000473253428936\n",
      "Epoch 4370, Loss: 0.09173170290887356, Final Batch Loss: 0.06482163816690445\n",
      "Epoch 4371, Loss: 0.08636763319373131, Final Batch Loss: 0.04356250911951065\n",
      "Epoch 4372, Loss: 0.06977295875549316, Final Batch Loss: 0.042837660759687424\n",
      "Epoch 4373, Loss: 0.07260749861598015, Final Batch Loss: 0.032552797347307205\n",
      "Epoch 4374, Loss: 0.05899500660598278, Final Batch Loss: 0.021082954481244087\n",
      "Epoch 4375, Loss: 0.038886901922523975, Final Batch Loss: 0.010914851911365986\n",
      "Epoch 4376, Loss: 0.08833945542573929, Final Batch Loss: 0.03473774343729019\n",
      "Epoch 4377, Loss: 0.08214161545038223, Final Batch Loss: 0.056201331317424774\n",
      "Epoch 4378, Loss: 0.06786715611815453, Final Batch Loss: 0.04083062708377838\n",
      "Epoch 4379, Loss: 0.11233476921916008, Final Batch Loss: 0.05955882370471954\n",
      "Epoch 4380, Loss: 0.07473178207874298, Final Batch Loss: 0.03733246400952339\n",
      "Epoch 4381, Loss: 0.08418954536318779, Final Batch Loss: 0.03942005708813667\n",
      "Epoch 4382, Loss: 0.055426692590117455, Final Batch Loss: 0.027495039626955986\n",
      "Epoch 4383, Loss: 0.11073202267289162, Final Batch Loss: 0.05836261063814163\n",
      "Epoch 4384, Loss: 0.06799190305173397, Final Batch Loss: 0.021542618051171303\n",
      "Epoch 4385, Loss: 0.05942458752542734, Final Batch Loss: 0.015523427166044712\n",
      "Epoch 4386, Loss: 0.126453198492527, Final Batch Loss: 0.08911024779081345\n",
      "Epoch 4387, Loss: 0.06488977372646332, Final Batch Loss: 0.04276951402425766\n",
      "Epoch 4388, Loss: 0.06795684807002544, Final Batch Loss: 0.026779470965266228\n",
      "Epoch 4389, Loss: 0.06073434092104435, Final Batch Loss: 0.028528789058327675\n",
      "Epoch 4390, Loss: 0.0624912828207016, Final Batch Loss: 0.01996580883860588\n",
      "Epoch 4391, Loss: 0.09916377440094948, Final Batch Loss: 0.031603310257196426\n",
      "Epoch 4392, Loss: 0.04403529688715935, Final Batch Loss: 0.023904988542199135\n",
      "Epoch 4393, Loss: 0.08506520837545395, Final Batch Loss: 0.06417375057935715\n",
      "Epoch 4394, Loss: 0.075478071346879, Final Batch Loss: 0.04704491049051285\n",
      "Epoch 4395, Loss: 0.048348331823945045, Final Batch Loss: 0.01859462261199951\n",
      "Epoch 4396, Loss: 0.08853453956544399, Final Batch Loss: 0.020245512947440147\n",
      "Epoch 4397, Loss: 0.06516440957784653, Final Batch Loss: 0.030073318630456924\n",
      "Epoch 4398, Loss: 0.05326879769563675, Final Batch Loss: 0.021541621536016464\n",
      "Epoch 4399, Loss: 0.11506612971425056, Final Batch Loss: 0.03933707997202873\n",
      "Epoch 4400, Loss: 0.0700113121420145, Final Batch Loss: 0.027892334386706352\n",
      "Epoch 4401, Loss: 0.05100663751363754, Final Batch Loss: 0.04125595465302467\n",
      "Epoch 4402, Loss: 0.0763706136494875, Final Batch Loss: 0.019568348303437233\n",
      "Epoch 4403, Loss: 0.07601741701364517, Final Batch Loss: 0.04113771393895149\n",
      "Epoch 4404, Loss: 0.0641301367431879, Final Batch Loss: 0.023515475913882256\n",
      "Epoch 4405, Loss: 0.11005845293402672, Final Batch Loss: 0.05076401308178902\n",
      "Epoch 4406, Loss: 0.06751484796404839, Final Batch Loss: 0.04037683829665184\n",
      "Epoch 4407, Loss: 0.10260412842035294, Final Batch Loss: 0.0569458082318306\n",
      "Epoch 4408, Loss: 0.09152315184473991, Final Batch Loss: 0.054089076817035675\n",
      "Epoch 4409, Loss: 0.07354304566979408, Final Batch Loss: 0.04709493741393089\n",
      "Epoch 4410, Loss: 0.06837527081370354, Final Batch Loss: 0.04256103187799454\n",
      "Epoch 4411, Loss: 0.10213140025734901, Final Batch Loss: 0.041986025869846344\n",
      "Epoch 4412, Loss: 0.128748320043087, Final Batch Loss: 0.04079137742519379\n",
      "Epoch 4413, Loss: 0.06437966786324978, Final Batch Loss: 0.030737360939383507\n",
      "Epoch 4414, Loss: 0.04960208758711815, Final Batch Loss: 0.013018816709518433\n",
      "Epoch 4415, Loss: 0.06001366302371025, Final Batch Loss: 0.027116164565086365\n",
      "Epoch 4416, Loss: 0.0771394744515419, Final Batch Loss: 0.029483649879693985\n",
      "Epoch 4417, Loss: 0.07847167551517487, Final Batch Loss: 0.05044622719287872\n",
      "Epoch 4418, Loss: 0.0698726586997509, Final Batch Loss: 0.04442942887544632\n",
      "Epoch 4419, Loss: 0.08457008004188538, Final Batch Loss: 0.049270130693912506\n",
      "Epoch 4420, Loss: 0.06016021594405174, Final Batch Loss: 0.028531759977340698\n",
      "Epoch 4421, Loss: 0.05033459886908531, Final Batch Loss: 0.031042445451021194\n",
      "Epoch 4422, Loss: 0.06705019995570183, Final Batch Loss: 0.03519710525870323\n",
      "Epoch 4423, Loss: 0.05931134708225727, Final Batch Loss: 0.02898566983640194\n",
      "Epoch 4424, Loss: 0.06701335310935974, Final Batch Loss: 0.029151789844036102\n",
      "Epoch 4425, Loss: 0.07586720772087574, Final Batch Loss: 0.017673315480351448\n",
      "Epoch 4426, Loss: 0.05871971137821674, Final Batch Loss: 0.026278750970959663\n",
      "Epoch 4427, Loss: 0.05235159583389759, Final Batch Loss: 0.033944252878427505\n",
      "Epoch 4428, Loss: 0.0952645055949688, Final Batch Loss: 0.01775311306118965\n",
      "Epoch 4429, Loss: 0.06763910315930843, Final Batch Loss: 0.02094833366572857\n",
      "Epoch 4430, Loss: 0.058574602007865906, Final Batch Loss: 0.04701725393533707\n",
      "Epoch 4431, Loss: 0.0816374272108078, Final Batch Loss: 0.04191679507493973\n",
      "Epoch 4432, Loss: 0.04292215220630169, Final Batch Loss: 0.015419840812683105\n",
      "Epoch 4433, Loss: 0.0511797983199358, Final Batch Loss: 0.02251623198390007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4434, Loss: 0.07243554666638374, Final Batch Loss: 0.03396352380514145\n",
      "Epoch 4435, Loss: 0.054692426696419716, Final Batch Loss: 0.021031519398093224\n",
      "Epoch 4436, Loss: 0.05337424948811531, Final Batch Loss: 0.00864570215344429\n",
      "Epoch 4437, Loss: 0.04772750288248062, Final Batch Loss: 0.025805117562413216\n",
      "Epoch 4438, Loss: 0.0740908794105053, Final Batch Loss: 0.05159087851643562\n",
      "Epoch 4439, Loss: 0.08303062245249748, Final Batch Loss: 0.06010708212852478\n",
      "Epoch 4440, Loss: 0.06630252301692963, Final Batch Loss: 0.03224990516901016\n",
      "Epoch 4441, Loss: 0.08517689257860184, Final Batch Loss: 0.045279137790203094\n",
      "Epoch 4442, Loss: 0.03477892279624939, Final Batch Loss: 0.011252978816628456\n",
      "Epoch 4443, Loss: 0.1599292792379856, Final Batch Loss: 0.040118541568517685\n",
      "Epoch 4444, Loss: 0.05570372939109802, Final Batch Loss: 0.03181219846010208\n",
      "Epoch 4445, Loss: 0.08554541505873203, Final Batch Loss: 0.05982495844364166\n",
      "Epoch 4446, Loss: 0.08064970374107361, Final Batch Loss: 0.030892979353666306\n",
      "Epoch 4447, Loss: 0.050970411859452724, Final Batch Loss: 0.037770532071590424\n",
      "Epoch 4448, Loss: 0.06143866293132305, Final Batch Loss: 0.04229807108640671\n",
      "Epoch 4449, Loss: 0.09951651096343994, Final Batch Loss: 0.06720516830682755\n",
      "Epoch 4450, Loss: 0.04489833489060402, Final Batch Loss: 0.02422407828271389\n",
      "Epoch 4451, Loss: 0.08634703233838081, Final Batch Loss: 0.028922852128744125\n",
      "Epoch 4452, Loss: 0.05550324358046055, Final Batch Loss: 0.029261404648423195\n",
      "Epoch 4453, Loss: 0.11047144792973995, Final Batch Loss: 0.08858021348714828\n",
      "Epoch 4454, Loss: 0.06528572738170624, Final Batch Loss: 0.03588574752211571\n",
      "Epoch 4455, Loss: 0.14691752567887306, Final Batch Loss: 0.10337366908788681\n",
      "Epoch 4456, Loss: 0.0498996302485466, Final Batch Loss: 0.017185937613248825\n",
      "Epoch 4457, Loss: 0.08473575115203857, Final Batch Loss: 0.05506026744842529\n",
      "Epoch 4458, Loss: 0.05872124619781971, Final Batch Loss: 0.017609721049666405\n",
      "Epoch 4459, Loss: 0.08999061211943626, Final Batch Loss: 0.06241735816001892\n",
      "Epoch 4460, Loss: 0.10293766111135483, Final Batch Loss: 0.06519526243209839\n",
      "Epoch 4461, Loss: 0.07991049438714981, Final Batch Loss: 0.03394705057144165\n",
      "Epoch 4462, Loss: 0.09253594279289246, Final Batch Loss: 0.060613591223955154\n",
      "Epoch 4463, Loss: 0.07843966223299503, Final Batch Loss: 0.04840805009007454\n",
      "Epoch 4464, Loss: 0.07885159179568291, Final Batch Loss: 0.02411802113056183\n",
      "Epoch 4465, Loss: 0.13247787952423096, Final Batch Loss: 0.08930176496505737\n",
      "Epoch 4466, Loss: 0.06831745617091656, Final Batch Loss: 0.02276633121073246\n",
      "Epoch 4467, Loss: 0.06101558543741703, Final Batch Loss: 0.03826593980193138\n",
      "Epoch 4468, Loss: 0.054929498583078384, Final Batch Loss: 0.02580861933529377\n",
      "Epoch 4469, Loss: 0.07919428870081902, Final Batch Loss: 0.048109136521816254\n",
      "Epoch 4470, Loss: 0.06121757999062538, Final Batch Loss: 0.031435877084732056\n",
      "Epoch 4471, Loss: 0.1860632635653019, Final Batch Loss: 0.1380418986082077\n",
      "Epoch 4472, Loss: 0.055393289774656296, Final Batch Loss: 0.02011515572667122\n",
      "Epoch 4473, Loss: 0.06705855391919613, Final Batch Loss: 0.038908787071704865\n",
      "Epoch 4474, Loss: 0.1124328225851059, Final Batch Loss: 0.025252491235733032\n",
      "Epoch 4475, Loss: 0.12746688723564148, Final Batch Loss: 0.025998204946517944\n",
      "Epoch 4476, Loss: 0.13573459535837173, Final Batch Loss: 0.052829496562480927\n",
      "Epoch 4477, Loss: 0.07087063044309616, Final Batch Loss: 0.02765306457877159\n",
      "Epoch 4478, Loss: 0.24120275303721428, Final Batch Loss: 0.19278228282928467\n",
      "Epoch 4479, Loss: 0.09415964968502522, Final Batch Loss: 0.03113352693617344\n",
      "Epoch 4480, Loss: 0.06953437253832817, Final Batch Loss: 0.021878264844417572\n",
      "Epoch 4481, Loss: 0.08360974490642548, Final Batch Loss: 0.06131283566355705\n",
      "Epoch 4482, Loss: 0.0904281698167324, Final Batch Loss: 0.05884241685271263\n",
      "Epoch 4483, Loss: 0.06709527969360352, Final Batch Loss: 0.03209848701953888\n",
      "Epoch 4484, Loss: 0.07630430907011032, Final Batch Loss: 0.029165681451559067\n",
      "Epoch 4485, Loss: 0.1266055405139923, Final Batch Loss: 0.016290761530399323\n",
      "Epoch 4486, Loss: 0.13756388425827026, Final Batch Loss: 0.09684472531080246\n",
      "Epoch 4487, Loss: 0.115838922560215, Final Batch Loss: 0.049633048474788666\n",
      "Epoch 4488, Loss: 0.11125495284795761, Final Batch Loss: 0.0755063146352768\n",
      "Epoch 4489, Loss: 0.13604770973324776, Final Batch Loss: 0.0966678187251091\n",
      "Epoch 4490, Loss: 0.09537340700626373, Final Batch Loss: 0.044458307325839996\n",
      "Epoch 4491, Loss: 0.10301414132118225, Final Batch Loss: 0.07670571655035019\n",
      "Epoch 4492, Loss: 0.06573350355029106, Final Batch Loss: 0.027265485376119614\n",
      "Epoch 4493, Loss: 0.06837843358516693, Final Batch Loss: 0.03198108822107315\n",
      "Epoch 4494, Loss: 0.05767113156616688, Final Batch Loss: 0.016018463298678398\n",
      "Epoch 4495, Loss: 0.045915769413113594, Final Batch Loss: 0.009372884407639503\n",
      "Epoch 4496, Loss: 0.05714012496173382, Final Batch Loss: 0.026432935148477554\n",
      "Epoch 4497, Loss: 0.07948172464966774, Final Batch Loss: 0.026196453720331192\n",
      "Epoch 4498, Loss: 0.08717313408851624, Final Batch Loss: 0.050584129989147186\n",
      "Epoch 4499, Loss: 0.07304668612778187, Final Batch Loss: 0.02743804268538952\n",
      "Epoch 4500, Loss: 0.04477402940392494, Final Batch Loss: 0.01447785273194313\n",
      "Epoch 4501, Loss: 0.08989216759800911, Final Batch Loss: 0.037437546998262405\n",
      "Epoch 4502, Loss: 0.07221778482198715, Final Batch Loss: 0.03066381812095642\n",
      "Epoch 4503, Loss: 0.07365322858095169, Final Batch Loss: 0.017379581928253174\n",
      "Epoch 4504, Loss: 0.0459119975566864, Final Batch Loss: 0.02414041757583618\n",
      "Epoch 4505, Loss: 0.04973214864730835, Final Batch Loss: 0.014596525579690933\n",
      "Epoch 4506, Loss: 0.06010386534035206, Final Batch Loss: 0.02358963154256344\n",
      "Epoch 4507, Loss: 0.11259624920785427, Final Batch Loss: 0.08936919271945953\n",
      "Epoch 4508, Loss: 0.07998020946979523, Final Batch Loss: 0.041616931557655334\n",
      "Epoch 4509, Loss: 0.07453523948788643, Final Batch Loss: 0.036032941192388535\n",
      "Epoch 4510, Loss: 0.06469017453491688, Final Batch Loss: 0.042060885578393936\n",
      "Epoch 4511, Loss: 0.06814192607998848, Final Batch Loss: 0.03681422024965286\n",
      "Epoch 4512, Loss: 0.056493885815143585, Final Batch Loss: 0.026987865567207336\n",
      "Epoch 4513, Loss: 0.08817592263221741, Final Batch Loss: 0.056186944246292114\n",
      "Epoch 4514, Loss: 0.06567739136517048, Final Batch Loss: 0.023537399247288704\n",
      "Epoch 4515, Loss: 0.10070891305804253, Final Batch Loss: 0.05618017911911011\n",
      "Epoch 4516, Loss: 0.056766062043607235, Final Batch Loss: 0.011271833442151546\n",
      "Epoch 4517, Loss: 0.05850519426167011, Final Batch Loss: 0.007135791704058647\n",
      "Epoch 4518, Loss: 0.0882393978536129, Final Batch Loss: 0.02840777114033699\n",
      "Epoch 4519, Loss: 0.05595097318291664, Final Batch Loss: 0.021061308681964874\n",
      "Epoch 4520, Loss: 0.09727642685174942, Final Batch Loss: 0.06426144391298294\n",
      "Epoch 4521, Loss: 0.048235404305160046, Final Batch Loss: 0.011044434271752834\n",
      "Epoch 4522, Loss: 0.11024361476302147, Final Batch Loss: 0.05116733908653259\n",
      "Epoch 4523, Loss: 0.06925912573933601, Final Batch Loss: 0.031848352402448654\n",
      "Epoch 4524, Loss: 0.04582794941961765, Final Batch Loss: 0.02392398566007614\n",
      "Epoch 4525, Loss: 0.048548655584454536, Final Batch Loss: 0.023719385266304016\n",
      "Epoch 4526, Loss: 0.0965174250304699, Final Batch Loss: 0.047150541096925735\n",
      "Epoch 4527, Loss: 0.059874704107642174, Final Batch Loss: 0.024119073525071144\n",
      "Epoch 4528, Loss: 0.12100678123533726, Final Batch Loss: 0.09368700534105301\n",
      "Epoch 4529, Loss: 0.11052799597382545, Final Batch Loss: 0.06801822036504745\n",
      "Epoch 4530, Loss: 0.16205760836601257, Final Batch Loss: 0.0450432226061821\n",
      "Epoch 4531, Loss: 0.041838742792606354, Final Batch Loss: 0.01900603622198105\n",
      "Epoch 4532, Loss: 0.10059416852891445, Final Batch Loss: 0.07036704570055008\n",
      "Epoch 4533, Loss: 0.058255214244127274, Final Batch Loss: 0.026286974549293518\n",
      "Epoch 4534, Loss: 0.09998174384236336, Final Batch Loss: 0.055050868541002274\n",
      "Epoch 4535, Loss: 0.08472390100359917, Final Batch Loss: 0.04900947958230972\n",
      "Epoch 4536, Loss: 0.07420404627919197, Final Batch Loss: 0.042562711983919144\n",
      "Epoch 4537, Loss: 0.06319436803460121, Final Batch Loss: 0.03152420371770859\n",
      "Epoch 4538, Loss: 0.08717300184071064, Final Batch Loss: 0.06074153259396553\n",
      "Epoch 4539, Loss: 0.07444481179118156, Final Batch Loss: 0.02500293031334877\n",
      "Epoch 4540, Loss: 0.10707738250494003, Final Batch Loss: 0.03812480717897415\n",
      "Epoch 4541, Loss: 0.10503313317894936, Final Batch Loss: 0.03817422315478325\n",
      "Epoch 4542, Loss: 0.05973353423178196, Final Batch Loss: 0.018345164135098457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4543, Loss: 0.08989341929554939, Final Batch Loss: 0.04615234211087227\n",
      "Epoch 4544, Loss: 0.0852741189301014, Final Batch Loss: 0.027535732835531235\n",
      "Epoch 4545, Loss: 0.07144432701170444, Final Batch Loss: 0.02809102274477482\n",
      "Epoch 4546, Loss: 0.138629250228405, Final Batch Loss: 0.07670525461435318\n",
      "Epoch 4547, Loss: 0.11216447874903679, Final Batch Loss: 0.07766798138618469\n",
      "Epoch 4548, Loss: 0.06435875222086906, Final Batch Loss: 0.02834787219762802\n",
      "Epoch 4549, Loss: 0.10647319257259369, Final Batch Loss: 0.06413368880748749\n",
      "Epoch 4550, Loss: 0.1166796125471592, Final Batch Loss: 0.07638920843601227\n",
      "Epoch 4551, Loss: 0.0780913382768631, Final Batch Loss: 0.03758952394127846\n",
      "Epoch 4552, Loss: 0.10302074626088142, Final Batch Loss: 0.03845147415995598\n",
      "Epoch 4553, Loss: 0.11078402772545815, Final Batch Loss: 0.06778977066278458\n",
      "Epoch 4554, Loss: 0.13425573706626892, Final Batch Loss: 0.07229481637477875\n",
      "Epoch 4555, Loss: 0.12022531405091286, Final Batch Loss: 0.06391353160142899\n",
      "Epoch 4556, Loss: 0.12675927951931953, Final Batch Loss: 0.04903149977326393\n",
      "Epoch 4557, Loss: 0.05696827732026577, Final Batch Loss: 0.007125968113541603\n",
      "Epoch 4558, Loss: 0.08828246966004372, Final Batch Loss: 0.0386621467769146\n",
      "Epoch 4559, Loss: 0.05733959935605526, Final Batch Loss: 0.02280081994831562\n",
      "Epoch 4560, Loss: 0.07720859348773956, Final Batch Loss: 0.034506890922784805\n",
      "Epoch 4561, Loss: 0.07003941014409065, Final Batch Loss: 0.04210464656352997\n",
      "Epoch 4562, Loss: 0.09279317408800125, Final Batch Loss: 0.040701668709516525\n",
      "Epoch 4563, Loss: 0.06753814965486526, Final Batch Loss: 0.04013299196958542\n",
      "Epoch 4564, Loss: 0.04124606214463711, Final Batch Loss: 0.023169534280896187\n",
      "Epoch 4565, Loss: 0.11916208267211914, Final Batch Loss: 0.07863156497478485\n",
      "Epoch 4566, Loss: 0.08072906732559204, Final Batch Loss: 0.05172932147979736\n",
      "Epoch 4567, Loss: 0.08435734361410141, Final Batch Loss: 0.05199960246682167\n",
      "Epoch 4568, Loss: 0.09021787717938423, Final Batch Loss: 0.03952551260590553\n",
      "Epoch 4569, Loss: 0.0759584978222847, Final Batch Loss: 0.05925619229674339\n",
      "Epoch 4570, Loss: 0.057383377104997635, Final Batch Loss: 0.034810684621334076\n",
      "Epoch 4571, Loss: 0.07404440641403198, Final Batch Loss: 0.038119081407785416\n",
      "Epoch 4572, Loss: 0.0636876542121172, Final Batch Loss: 0.04141378030180931\n",
      "Epoch 4573, Loss: 0.060956383123993874, Final Batch Loss: 0.032066911458969116\n",
      "Epoch 4574, Loss: 0.06897898856550455, Final Batch Loss: 0.01382902730256319\n",
      "Epoch 4575, Loss: 0.06115998327732086, Final Batch Loss: 0.02629789337515831\n",
      "Epoch 4576, Loss: 0.093698401004076, Final Batch Loss: 0.04940125718712807\n",
      "Epoch 4577, Loss: 0.07787109911441803, Final Batch Loss: 0.030325084924697876\n",
      "Epoch 4578, Loss: 0.0652234647423029, Final Batch Loss: 0.03701139986515045\n",
      "Epoch 4579, Loss: 0.06404164060950279, Final Batch Loss: 0.01568910852074623\n",
      "Epoch 4580, Loss: 0.08554856851696968, Final Batch Loss: 0.06118038296699524\n",
      "Epoch 4581, Loss: 0.06491666473448277, Final Batch Loss: 0.026616575196385384\n",
      "Epoch 4582, Loss: 0.08523576706647873, Final Batch Loss: 0.05900312960147858\n",
      "Epoch 4583, Loss: 0.0563771016895771, Final Batch Loss: 0.0271094162017107\n",
      "Epoch 4584, Loss: 0.04599425569176674, Final Batch Loss: 0.01596394181251526\n",
      "Epoch 4585, Loss: 0.08522303774952888, Final Batch Loss: 0.04246539622545242\n",
      "Epoch 4586, Loss: 0.04368522297590971, Final Batch Loss: 0.014504284597933292\n",
      "Epoch 4587, Loss: 0.06193565018475056, Final Batch Loss: 0.02663092501461506\n",
      "Epoch 4588, Loss: 0.08176159858703613, Final Batch Loss: 0.03909588232636452\n",
      "Epoch 4589, Loss: 0.06195018254220486, Final Batch Loss: 0.027415325865149498\n",
      "Epoch 4590, Loss: 0.06239854916930199, Final Batch Loss: 0.0209956057369709\n",
      "Epoch 4591, Loss: 0.07222028449177742, Final Batch Loss: 0.03575066104531288\n",
      "Epoch 4592, Loss: 0.07909037172794342, Final Batch Loss: 0.049706168472766876\n",
      "Epoch 4593, Loss: 0.08898253738880157, Final Batch Loss: 0.038305893540382385\n",
      "Epoch 4594, Loss: 0.07027078419923782, Final Batch Loss: 0.03892119601368904\n",
      "Epoch 4595, Loss: 0.06976379454135895, Final Batch Loss: 0.02931305766105652\n",
      "Epoch 4596, Loss: 0.07611341029405594, Final Batch Loss: 0.030071105808019638\n",
      "Epoch 4597, Loss: 0.05616716854274273, Final Batch Loss: 0.02598649635910988\n",
      "Epoch 4598, Loss: 0.05880853161215782, Final Batch Loss: 0.042209967970848083\n",
      "Epoch 4599, Loss: 0.0994923785328865, Final Batch Loss: 0.043029315769672394\n",
      "Epoch 4600, Loss: 0.04095005802810192, Final Batch Loss: 0.018599174916744232\n",
      "Epoch 4601, Loss: 0.05063080973923206, Final Batch Loss: 0.02040056325495243\n",
      "Epoch 4602, Loss: 0.10771860741078854, Final Batch Loss: 0.07873813062906265\n",
      "Epoch 4603, Loss: 0.050528207793831825, Final Batch Loss: 0.027467330917716026\n",
      "Epoch 4604, Loss: 0.04185232147574425, Final Batch Loss: 0.012303203344345093\n",
      "Epoch 4605, Loss: 0.05946101434528828, Final Batch Loss: 0.019323723390698433\n",
      "Epoch 4606, Loss: 0.08267407305538654, Final Batch Loss: 0.028501415625214577\n",
      "Epoch 4607, Loss: 0.07814973592758179, Final Batch Loss: 0.034187041223049164\n",
      "Epoch 4608, Loss: 0.03365399036556482, Final Batch Loss: 0.012831917963922024\n",
      "Epoch 4609, Loss: 0.07716010697185993, Final Batch Loss: 0.04592989385128021\n",
      "Epoch 4610, Loss: 0.06469621509313583, Final Batch Loss: 0.03779659420251846\n",
      "Epoch 4611, Loss: 0.06183474138379097, Final Batch Loss: 0.044680964201688766\n",
      "Epoch 4612, Loss: 0.034258616622537374, Final Batch Loss: 0.006324657704681158\n",
      "Epoch 4613, Loss: 0.05229797214269638, Final Batch Loss: 0.023116489872336388\n",
      "Epoch 4614, Loss: 0.0469469279050827, Final Batch Loss: 0.009624753147363663\n",
      "Epoch 4615, Loss: 0.07260796427726746, Final Batch Loss: 0.03214021399617195\n",
      "Epoch 4616, Loss: 0.042987074702978134, Final Batch Loss: 0.014703046530485153\n",
      "Epoch 4617, Loss: 0.05749032832682133, Final Batch Loss: 0.023805690929293633\n",
      "Epoch 4618, Loss: 0.10971498861908913, Final Batch Loss: 0.060603126883506775\n",
      "Epoch 4619, Loss: 0.05507009755820036, Final Batch Loss: 0.01051556970924139\n",
      "Epoch 4620, Loss: 0.05917754024267197, Final Batch Loss: 0.02095690369606018\n",
      "Epoch 4621, Loss: 0.1559569574892521, Final Batch Loss: 0.046999525278806686\n",
      "Epoch 4622, Loss: 0.07961342856287956, Final Batch Loss: 0.048678454011678696\n",
      "Epoch 4623, Loss: 0.07736148498952389, Final Batch Loss: 0.05731329694390297\n",
      "Epoch 4624, Loss: 0.0776812806725502, Final Batch Loss: 0.03821077570319176\n",
      "Epoch 4625, Loss: 0.11870334297418594, Final Batch Loss: 0.04728907346725464\n",
      "Epoch 4626, Loss: 0.14255647361278534, Final Batch Loss: 0.11065454035997391\n",
      "Epoch 4627, Loss: 0.06490484438836575, Final Batch Loss: 0.018924878910183907\n",
      "Epoch 4628, Loss: 0.04787996783852577, Final Batch Loss: 0.020983483642339706\n",
      "Epoch 4629, Loss: 0.10148943588137627, Final Batch Loss: 0.060874857008457184\n",
      "Epoch 4630, Loss: 0.10356925427913666, Final Batch Loss: 0.05192618817090988\n",
      "Epoch 4631, Loss: 0.049492571502923965, Final Batch Loss: 0.026501959189772606\n",
      "Epoch 4632, Loss: 0.07845423370599747, Final Batch Loss: 0.055598169565200806\n",
      "Epoch 4633, Loss: 0.1056068129837513, Final Batch Loss: 0.04615478962659836\n",
      "Epoch 4634, Loss: 0.09901384636759758, Final Batch Loss: 0.04614107310771942\n",
      "Epoch 4635, Loss: 0.08758565410971642, Final Batch Loss: 0.051604144275188446\n",
      "Epoch 4636, Loss: 0.10352662950754166, Final Batch Loss: 0.04580501839518547\n",
      "Epoch 4637, Loss: 0.11628575250506401, Final Batch Loss: 0.08002953976392746\n",
      "Epoch 4638, Loss: 0.07982662506401539, Final Batch Loss: 0.02090485952794552\n",
      "Epoch 4639, Loss: 0.056880904361605644, Final Batch Loss: 0.022641418501734734\n",
      "Epoch 4640, Loss: 0.0610938910394907, Final Batch Loss: 0.037491850554943085\n",
      "Epoch 4641, Loss: 0.08041963540017605, Final Batch Loss: 0.05366922914981842\n",
      "Epoch 4642, Loss: 0.07467461004853249, Final Batch Loss: 0.02036220207810402\n",
      "Epoch 4643, Loss: 0.058384284377098083, Final Batch Loss: 0.03168006241321564\n",
      "Epoch 4644, Loss: 0.07835191488265991, Final Batch Loss: 0.05041879415512085\n",
      "Epoch 4645, Loss: 0.051218582317233086, Final Batch Loss: 0.021060679107904434\n",
      "Epoch 4646, Loss: 0.08843759074807167, Final Batch Loss: 0.04597374051809311\n",
      "Epoch 4647, Loss: 0.10565964132547379, Final Batch Loss: 0.07207982242107391\n",
      "Epoch 4648, Loss: 0.07818682864308357, Final Batch Loss: 0.023942749947309494\n",
      "Epoch 4649, Loss: 0.04655071720480919, Final Batch Loss: 0.009862285107374191\n",
      "Epoch 4650, Loss: 0.08158405683934689, Final Batch Loss: 0.05497576296329498\n",
      "Epoch 4651, Loss: 0.05912465415894985, Final Batch Loss: 0.026032770052552223\n",
      "Epoch 4652, Loss: 0.041121638379991055, Final Batch Loss: 0.008037823252379894\n",
      "Epoch 4653, Loss: 0.06347423046827316, Final Batch Loss: 0.019262440502643585\n",
      "Epoch 4654, Loss: 0.12594113498926163, Final Batch Loss: 0.059958286583423615\n",
      "Epoch 4655, Loss: 0.07295847311615944, Final Batch Loss: 0.033134203404188156\n",
      "Epoch 4656, Loss: 0.058154117316007614, Final Batch Loss: 0.015144836157560349\n",
      "Epoch 4657, Loss: 0.08642254583537579, Final Batch Loss: 0.02327280305325985\n",
      "Epoch 4658, Loss: 0.055065274238586426, Final Batch Loss: 0.025272969156503677\n",
      "Epoch 4659, Loss: 0.1154300794005394, Final Batch Loss: 0.08230515569448471\n",
      "Epoch 4660, Loss: 0.10760492086410522, Final Batch Loss: 0.0415184423327446\n",
      "Epoch 4661, Loss: 0.0632131639868021, Final Batch Loss: 0.028497597202658653\n",
      "Epoch 4662, Loss: 0.07874501869082451, Final Batch Loss: 0.05216198042035103\n",
      "Epoch 4663, Loss: 0.08663633093237877, Final Batch Loss: 0.042883239686489105\n",
      "Epoch 4664, Loss: 0.05067187733948231, Final Batch Loss: 0.024671029299497604\n",
      "Epoch 4665, Loss: 0.16192932054400444, Final Batch Loss: 0.13760334253311157\n",
      "Epoch 4666, Loss: 0.09765619412064552, Final Batch Loss: 0.06542804837226868\n",
      "Epoch 4667, Loss: 0.06433901749551296, Final Batch Loss: 0.034186817705631256\n",
      "Epoch 4668, Loss: 0.08422684669494629, Final Batch Loss: 0.0428948737680912\n",
      "Epoch 4669, Loss: 0.11759387701749802, Final Batch Loss: 0.059549007564783096\n",
      "Epoch 4670, Loss: 0.036800725385546684, Final Batch Loss: 0.01815284788608551\n",
      "Epoch 4671, Loss: 0.09310205653309822, Final Batch Loss: 0.04050562158226967\n",
      "Epoch 4672, Loss: 0.0794263407588005, Final Batch Loss: 0.04300014674663544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4673, Loss: 0.07254944927990437, Final Batch Loss: 0.025521358475089073\n",
      "Epoch 4674, Loss: 0.07155112875625491, Final Batch Loss: 0.007356337737292051\n",
      "Epoch 4675, Loss: 0.07314951904118061, Final Batch Loss: 0.025046331807971\n",
      "Epoch 4676, Loss: 0.08425135724246502, Final Batch Loss: 0.06825383752584457\n",
      "Epoch 4677, Loss: 0.07847189530730247, Final Batch Loss: 0.04189389944076538\n",
      "Epoch 4678, Loss: 0.08680876344442368, Final Batch Loss: 0.04521458223462105\n",
      "Epoch 4679, Loss: 0.0875220075249672, Final Batch Loss: 0.02626349776983261\n",
      "Epoch 4680, Loss: 0.08667203597724438, Final Batch Loss: 0.056047890335321426\n",
      "Epoch 4681, Loss: 0.08789278194308281, Final Batch Loss: 0.04251941666007042\n",
      "Epoch 4682, Loss: 0.09897619858384132, Final Batch Loss: 0.06549999862909317\n",
      "Epoch 4683, Loss: 0.08362221717834473, Final Batch Loss: 0.037045784294605255\n",
      "Epoch 4684, Loss: 0.04823511652648449, Final Batch Loss: 0.014766959473490715\n",
      "Epoch 4685, Loss: 0.07001746073365211, Final Batch Loss: 0.03566448763012886\n",
      "Epoch 4686, Loss: 0.04766334034502506, Final Batch Loss: 0.025898106396198273\n",
      "Epoch 4687, Loss: 0.09645890817046165, Final Batch Loss: 0.05575168877840042\n",
      "Epoch 4688, Loss: 0.09160419553518295, Final Batch Loss: 0.04890647158026695\n",
      "Epoch 4689, Loss: 0.05959084816277027, Final Batch Loss: 0.029897907748818398\n",
      "Epoch 4690, Loss: 0.04634180665016174, Final Batch Loss: 0.028261786326766014\n",
      "Epoch 4691, Loss: 0.12171079590916634, Final Batch Loss: 0.054829757660627365\n",
      "Epoch 4692, Loss: 0.04460476152598858, Final Batch Loss: 0.02420661598443985\n",
      "Epoch 4693, Loss: 0.05463561788201332, Final Batch Loss: 0.01198061928153038\n",
      "Epoch 4694, Loss: 0.05595882050693035, Final Batch Loss: 0.03433352708816528\n",
      "Epoch 4695, Loss: 0.0750386193394661, Final Batch Loss: 0.03352784365415573\n",
      "Epoch 4696, Loss: 0.1375294178724289, Final Batch Loss: 0.11666115373373032\n",
      "Epoch 4697, Loss: 0.03847712790593505, Final Batch Loss: 0.006291618105024099\n",
      "Epoch 4698, Loss: 0.066766656935215, Final Batch Loss: 0.039646755903959274\n",
      "Epoch 4699, Loss: 0.04974890127778053, Final Batch Loss: 0.017446152865886688\n",
      "Epoch 4700, Loss: 0.0580429807305336, Final Batch Loss: 0.02841472625732422\n",
      "Epoch 4701, Loss: 0.06649523600935936, Final Batch Loss: 0.027323782444000244\n",
      "Epoch 4702, Loss: 0.06105806492269039, Final Batch Loss: 0.034658435732126236\n",
      "Epoch 4703, Loss: 0.059394609183073044, Final Batch Loss: 0.020307600498199463\n",
      "Epoch 4704, Loss: 0.11382361687719822, Final Batch Loss: 0.09344080835580826\n",
      "Epoch 4705, Loss: 0.09050538763403893, Final Batch Loss: 0.024976734071969986\n",
      "Epoch 4706, Loss: 0.06992216408252716, Final Batch Loss: 0.037774864584207535\n",
      "Epoch 4707, Loss: 0.11119400709867477, Final Batch Loss: 0.050060153007507324\n",
      "Epoch 4708, Loss: 0.043564376421272755, Final Batch Loss: 0.012796672992408276\n",
      "Epoch 4709, Loss: 0.06509861722588539, Final Batch Loss: 0.033604707568883896\n",
      "Epoch 4710, Loss: 0.07364772260189056, Final Batch Loss: 0.041848938912153244\n",
      "Epoch 4711, Loss: 0.11278657987713814, Final Batch Loss: 0.05629913508892059\n",
      "Epoch 4712, Loss: 0.06944156810641289, Final Batch Loss: 0.0329657681286335\n",
      "Epoch 4713, Loss: 0.0585864894092083, Final Batch Loss: 0.02659212425351143\n",
      "Epoch 4714, Loss: 0.05819152109324932, Final Batch Loss: 0.035691794008016586\n",
      "Epoch 4715, Loss: 0.09116459358483553, Final Batch Loss: 0.014075611717998981\n",
      "Epoch 4716, Loss: 0.02553415996953845, Final Batch Loss: 0.0041884067468345165\n",
      "Epoch 4717, Loss: 0.08278341218829155, Final Batch Loss: 0.046934183686971664\n",
      "Epoch 4718, Loss: 0.05413489043712616, Final Batch Loss: 0.01833486184477806\n",
      "Epoch 4719, Loss: 0.05651701241731644, Final Batch Loss: 0.03849107772111893\n",
      "Epoch 4720, Loss: 0.10159453749656677, Final Batch Loss: 0.05555054172873497\n",
      "Epoch 4721, Loss: 0.033709109760820866, Final Batch Loss: 0.009858070872724056\n",
      "Epoch 4722, Loss: 0.06631526164710522, Final Batch Loss: 0.03719063103199005\n",
      "Epoch 4723, Loss: 0.11549252830445766, Final Batch Loss: 0.09952574968338013\n",
      "Epoch 4724, Loss: 0.04000209830701351, Final Batch Loss: 0.02425996959209442\n",
      "Epoch 4725, Loss: 0.08008645102381706, Final Batch Loss: 0.036323387175798416\n",
      "Epoch 4726, Loss: 0.08085853606462479, Final Batch Loss: 0.046847738325595856\n",
      "Epoch 4727, Loss: 0.05705253407359123, Final Batch Loss: 0.025628168135881424\n",
      "Epoch 4728, Loss: 0.06875304132699966, Final Batch Loss: 0.0349046066403389\n",
      "Epoch 4729, Loss: 0.06307544931769371, Final Batch Loss: 0.0378953292965889\n",
      "Epoch 4730, Loss: 0.06257507111877203, Final Batch Loss: 0.014549835585057735\n",
      "Epoch 4731, Loss: 0.053068481385707855, Final Batch Loss: 0.01847199723124504\n",
      "Epoch 4732, Loss: 0.060611484572291374, Final Batch Loss: 0.03873590752482414\n",
      "Epoch 4733, Loss: 0.050075823441147804, Final Batch Loss: 0.0343451052904129\n",
      "Epoch 4734, Loss: 0.09014922007918358, Final Batch Loss: 0.06166965514421463\n",
      "Epoch 4735, Loss: 0.045059530064463615, Final Batch Loss: 0.0216511320322752\n",
      "Epoch 4736, Loss: 0.03444134071469307, Final Batch Loss: 0.014175528660416603\n",
      "Epoch 4737, Loss: 0.08910342305898666, Final Batch Loss: 0.04990647733211517\n",
      "Epoch 4738, Loss: 0.07746083475649357, Final Batch Loss: 0.05247025191783905\n",
      "Epoch 4739, Loss: 0.04933885671198368, Final Batch Loss: 0.020837966352701187\n",
      "Epoch 4740, Loss: 0.06902482360601425, Final Batch Loss: 0.036779481917619705\n",
      "Epoch 4741, Loss: 0.07521622814238071, Final Batch Loss: 0.026736708357930183\n",
      "Epoch 4742, Loss: 0.12030774354934692, Final Batch Loss: 0.0696038156747818\n",
      "Epoch 4743, Loss: 0.05518588423728943, Final Batch Loss: 0.023732665926218033\n",
      "Epoch 4744, Loss: 0.0615063551813364, Final Batch Loss: 0.021442601457238197\n",
      "Epoch 4745, Loss: 0.09627370163798332, Final Batch Loss: 0.028767909854650497\n",
      "Epoch 4746, Loss: 0.052754697389900684, Final Batch Loss: 0.014803861267864704\n",
      "Epoch 4747, Loss: 0.07107137888669968, Final Batch Loss: 0.03501821309328079\n",
      "Epoch 4748, Loss: 0.04382946901023388, Final Batch Loss: 0.023532992228865623\n",
      "Epoch 4749, Loss: 0.05413441359996796, Final Batch Loss: 0.014168620109558105\n",
      "Epoch 4750, Loss: 0.06463445350527763, Final Batch Loss: 0.03068475052714348\n",
      "Epoch 4751, Loss: 0.07011345960199833, Final Batch Loss: 0.028688466176390648\n",
      "Epoch 4752, Loss: 0.05116318352520466, Final Batch Loss: 0.025252103805541992\n",
      "Epoch 4753, Loss: 0.04721121862530708, Final Batch Loss: 0.03568856418132782\n",
      "Epoch 4754, Loss: 0.057317305356264114, Final Batch Loss: 0.03267088532447815\n",
      "Epoch 4755, Loss: 0.06836063787341118, Final Batch Loss: 0.037050407379865646\n",
      "Epoch 4756, Loss: 0.054922424256801605, Final Batch Loss: 0.031458672136068344\n",
      "Epoch 4757, Loss: 0.041262948885560036, Final Batch Loss: 0.024990426376461983\n",
      "Epoch 4758, Loss: 0.08218672499060631, Final Batch Loss: 0.047634296119213104\n",
      "Epoch 4759, Loss: 0.07276762835681438, Final Batch Loss: 0.04308462142944336\n",
      "Epoch 4760, Loss: 0.09447477012872696, Final Batch Loss: 0.07127445191144943\n",
      "Epoch 4761, Loss: 0.05401335284113884, Final Batch Loss: 0.019475672394037247\n",
      "Epoch 4762, Loss: 0.08178592845797539, Final Batch Loss: 0.0362057089805603\n",
      "Epoch 4763, Loss: 0.04779481515288353, Final Batch Loss: 0.013021089136600494\n",
      "Epoch 4764, Loss: 0.04537248983979225, Final Batch Loss: 0.027045411989092827\n",
      "Epoch 4765, Loss: 0.04278700239956379, Final Batch Loss: 0.017133038491010666\n",
      "Epoch 4766, Loss: 0.06143874302506447, Final Batch Loss: 0.025666169822216034\n",
      "Epoch 4767, Loss: 0.06218654662370682, Final Batch Loss: 0.03841947764158249\n",
      "Epoch 4768, Loss: 0.0708399098366499, Final Batch Loss: 0.030721647664904594\n",
      "Epoch 4769, Loss: 0.07333771511912346, Final Batch Loss: 0.05506974831223488\n",
      "Epoch 4770, Loss: 0.08584710769355297, Final Batch Loss: 0.06031738221645355\n",
      "Epoch 4771, Loss: 0.04121231846511364, Final Batch Loss: 0.011153297498822212\n",
      "Epoch 4772, Loss: 0.08349190838634968, Final Batch Loss: 0.05697910860180855\n",
      "Epoch 4773, Loss: 0.09104712307453156, Final Batch Loss: 0.050848860293626785\n",
      "Epoch 4774, Loss: 0.07176338136196136, Final Batch Loss: 0.03963100165128708\n",
      "Epoch 4775, Loss: 0.0599928367882967, Final Batch Loss: 0.03409271687269211\n",
      "Epoch 4776, Loss: 0.0729826558381319, Final Batch Loss: 0.03107604943215847\n",
      "Epoch 4777, Loss: 0.05434861406683922, Final Batch Loss: 0.02951328456401825\n",
      "Epoch 4778, Loss: 0.054167717695236206, Final Batch Loss: 0.032544005662202835\n",
      "Epoch 4779, Loss: 0.05759197473526001, Final Batch Loss: 0.02907778136432171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4780, Loss: 0.04294036515057087, Final Batch Loss: 0.019435662776231766\n",
      "Epoch 4781, Loss: 0.05179005302488804, Final Batch Loss: 0.018781939521431923\n",
      "Epoch 4782, Loss: 0.037482570856809616, Final Batch Loss: 0.016678187996149063\n",
      "Epoch 4783, Loss: 0.035029444843530655, Final Batch Loss: 0.009324280545115471\n",
      "Epoch 4784, Loss: 0.04967552237212658, Final Batch Loss: 0.023493396118283272\n",
      "Epoch 4785, Loss: 0.30022287368774414, Final Batch Loss: 0.2618795931339264\n",
      "Epoch 4786, Loss: 0.0760141871869564, Final Batch Loss: 0.04082120954990387\n",
      "Epoch 4787, Loss: 0.07103541493415833, Final Batch Loss: 0.0365130677819252\n",
      "Epoch 4788, Loss: 0.20559704676270485, Final Batch Loss: 0.16682052612304688\n",
      "Epoch 4789, Loss: 0.07417070865631104, Final Batch Loss: 0.02203105017542839\n",
      "Epoch 4790, Loss: 0.05308869481086731, Final Batch Loss: 0.024419909343123436\n",
      "Epoch 4791, Loss: 0.0516451857984066, Final Batch Loss: 0.014942284673452377\n",
      "Epoch 4792, Loss: 0.10296836122870445, Final Batch Loss: 0.0368385948240757\n",
      "Epoch 4793, Loss: 0.07192690670490265, Final Batch Loss: 0.033949438482522964\n",
      "Epoch 4794, Loss: 0.06242036446928978, Final Batch Loss: 0.0192921943962574\n",
      "Epoch 4795, Loss: 0.08754140883684158, Final Batch Loss: 0.06929171085357666\n",
      "Epoch 4796, Loss: 0.05061157047748566, Final Batch Loss: 0.020282184705138206\n",
      "Epoch 4797, Loss: 0.07533125579357147, Final Batch Loss: 0.01666288822889328\n",
      "Epoch 4798, Loss: 0.08415821753442287, Final Batch Loss: 0.05742723122239113\n",
      "Epoch 4799, Loss: 0.0471296701580286, Final Batch Loss: 0.013167815282940865\n",
      "Epoch 4800, Loss: 0.08717187494039536, Final Batch Loss: 0.03789699822664261\n",
      "Epoch 4801, Loss: 0.0625124154612422, Final Batch Loss: 0.015161815099418163\n",
      "Epoch 4802, Loss: 0.05819956585764885, Final Batch Loss: 0.010211173444986343\n",
      "Epoch 4803, Loss: 0.042373670265078545, Final Batch Loss: 0.022792473435401917\n",
      "Epoch 4804, Loss: 0.038402399979531765, Final Batch Loss: 0.023251932114362717\n",
      "Epoch 4805, Loss: 0.09981846436858177, Final Batch Loss: 0.05988023430109024\n",
      "Epoch 4806, Loss: 0.03476626705378294, Final Batch Loss: 0.007576732896268368\n",
      "Epoch 4807, Loss: 0.07026304118335247, Final Batch Loss: 0.04527668282389641\n",
      "Epoch 4808, Loss: 0.027818667702376842, Final Batch Loss: 0.01641904003918171\n",
      "Epoch 4809, Loss: 0.03049780149012804, Final Batch Loss: 0.011829490773379803\n",
      "Epoch 4810, Loss: 0.10290782526135445, Final Batch Loss: 0.049154751002788544\n",
      "Epoch 4811, Loss: 0.06557407788932323, Final Batch Loss: 0.025110172107815742\n",
      "Epoch 4812, Loss: 0.08811526000499725, Final Batch Loss: 0.01973670721054077\n",
      "Epoch 4813, Loss: 0.0741694662719965, Final Batch Loss: 0.025644710287451744\n",
      "Epoch 4814, Loss: 0.07954883202910423, Final Batch Loss: 0.04178629070520401\n",
      "Epoch 4815, Loss: 0.04594249092042446, Final Batch Loss: 0.02138860709965229\n",
      "Epoch 4816, Loss: 0.08258399181067944, Final Batch Loss: 0.05707397684454918\n",
      "Epoch 4817, Loss: 0.03158645797520876, Final Batch Loss: 0.012259629555046558\n",
      "Epoch 4818, Loss: 0.0757433120161295, Final Batch Loss: 0.04668622836470604\n",
      "Epoch 4819, Loss: 0.05363012012094259, Final Batch Loss: 0.014633926562964916\n",
      "Epoch 4820, Loss: 0.0652603879570961, Final Batch Loss: 0.02400016039609909\n",
      "Epoch 4821, Loss: 0.058526722714304924, Final Batch Loss: 0.03899100050330162\n",
      "Epoch 4822, Loss: 0.10030318424105644, Final Batch Loss: 0.037651460617780685\n",
      "Epoch 4823, Loss: 0.042330069467425346, Final Batch Loss: 0.023400915786623955\n",
      "Epoch 4824, Loss: 0.0736972838640213, Final Batch Loss: 0.031673457473516464\n",
      "Epoch 4825, Loss: 0.09330062009394169, Final Batch Loss: 0.010295258834958076\n",
      "Epoch 4826, Loss: 0.05796306021511555, Final Batch Loss: 0.020918985828757286\n",
      "Epoch 4827, Loss: 0.10846871137619019, Final Batch Loss: 0.06776975095272064\n",
      "Epoch 4828, Loss: 0.08819171041250229, Final Batch Loss: 0.05631782114505768\n",
      "Epoch 4829, Loss: 0.06925959698855877, Final Batch Loss: 0.03006451390683651\n",
      "Epoch 4830, Loss: 0.0529729463160038, Final Batch Loss: 0.029111845418810844\n",
      "Epoch 4831, Loss: 0.04208992049098015, Final Batch Loss: 0.022856680676341057\n",
      "Epoch 4832, Loss: 0.10665535368025303, Final Batch Loss: 0.08020534366369247\n",
      "Epoch 4833, Loss: 0.03580488357692957, Final Batch Loss: 0.014858280308544636\n",
      "Epoch 4834, Loss: 0.0596965029835701, Final Batch Loss: 0.035114604979753494\n",
      "Epoch 4835, Loss: 0.09061567019671202, Final Batch Loss: 0.015608618967235088\n",
      "Epoch 4836, Loss: 0.0557874720543623, Final Batch Loss: 0.029215384274721146\n",
      "Epoch 4837, Loss: 0.0375956054776907, Final Batch Loss: 0.016697997227311134\n",
      "Epoch 4838, Loss: 0.0712455827742815, Final Batch Loss: 0.022985858842730522\n",
      "Epoch 4839, Loss: 0.06379091925919056, Final Batch Loss: 0.03463445231318474\n",
      "Epoch 4840, Loss: 0.10797356627881527, Final Batch Loss: 0.08858635276556015\n",
      "Epoch 4841, Loss: 0.06441506743431091, Final Batch Loss: 0.03232523798942566\n",
      "Epoch 4842, Loss: 0.07506455108523369, Final Batch Loss: 0.038578588515520096\n",
      "Epoch 4843, Loss: 0.055855948477983475, Final Batch Loss: 0.028152650222182274\n",
      "Epoch 4844, Loss: 0.08246658742427826, Final Batch Loss: 0.049192365258932114\n",
      "Epoch 4845, Loss: 0.15957919880747795, Final Batch Loss: 0.11250670254230499\n",
      "Epoch 4846, Loss: 0.05231098458170891, Final Batch Loss: 0.03046097792685032\n",
      "Epoch 4847, Loss: 0.06624951399862766, Final Batch Loss: 0.017412742599844933\n",
      "Epoch 4848, Loss: 0.04646996222436428, Final Batch Loss: 0.012075511738657951\n",
      "Epoch 4849, Loss: 0.07954009436070919, Final Batch Loss: 0.030331680551171303\n",
      "Epoch 4850, Loss: 0.05911409109830856, Final Batch Loss: 0.02867269702255726\n",
      "Epoch 4851, Loss: 0.14096153527498245, Final Batch Loss: 0.04590588063001633\n",
      "Epoch 4852, Loss: 0.05542328767478466, Final Batch Loss: 0.023846233263611794\n",
      "Epoch 4853, Loss: 0.04007297568023205, Final Batch Loss: 0.01662631891667843\n",
      "Epoch 4854, Loss: 0.05373144708573818, Final Batch Loss: 0.007969429716467857\n",
      "Epoch 4855, Loss: 0.08831602521240711, Final Batch Loss: 0.028370970860123634\n",
      "Epoch 4856, Loss: 0.05119153670966625, Final Batch Loss: 0.027578871697187424\n",
      "Epoch 4857, Loss: 0.033357437467202544, Final Batch Loss: 0.0034654082264751196\n",
      "Epoch 4858, Loss: 0.09415971487760544, Final Batch Loss: 0.03127937763929367\n",
      "Epoch 4859, Loss: 0.09373915940523148, Final Batch Loss: 0.07319201529026031\n",
      "Epoch 4860, Loss: 0.05671697296202183, Final Batch Loss: 0.034241799265146255\n",
      "Epoch 4861, Loss: 0.06723100133240223, Final Batch Loss: 0.03105192445218563\n",
      "Epoch 4862, Loss: 0.1505424827337265, Final Batch Loss: 0.097441665828228\n",
      "Epoch 4863, Loss: 0.13108918257057667, Final Batch Loss: 0.0288138035684824\n",
      "Epoch 4864, Loss: 0.06642813794314861, Final Batch Loss: 0.02151048369705677\n",
      "Epoch 4865, Loss: 0.05575433745980263, Final Batch Loss: 0.01472792774438858\n",
      "Epoch 4866, Loss: 0.04974000342190266, Final Batch Loss: 0.02586210146546364\n",
      "Epoch 4867, Loss: 0.05246833898127079, Final Batch Loss: 0.02853856049478054\n",
      "Epoch 4868, Loss: 0.056436678394675255, Final Batch Loss: 0.022167036309838295\n",
      "Epoch 4869, Loss: 0.08724666759371758, Final Batch Loss: 0.05454074218869209\n",
      "Epoch 4870, Loss: 0.0911618173122406, Final Batch Loss: 0.046429991722106934\n",
      "Epoch 4871, Loss: 0.05616013705730438, Final Batch Loss: 0.026305247098207474\n",
      "Epoch 4872, Loss: 0.09498364850878716, Final Batch Loss: 0.037194930016994476\n",
      "Epoch 4873, Loss: 0.06379014067351818, Final Batch Loss: 0.030614087358117104\n",
      "Epoch 4874, Loss: 0.050408726558089256, Final Batch Loss: 0.026009028777480125\n",
      "Epoch 4875, Loss: 0.09714478999376297, Final Batch Loss: 0.06470264494419098\n",
      "Epoch 4876, Loss: 0.0539973434060812, Final Batch Loss: 0.020274171605706215\n",
      "Epoch 4877, Loss: 0.10180021449923515, Final Batch Loss: 0.051580119878053665\n",
      "Epoch 4878, Loss: 0.08237363025546074, Final Batch Loss: 0.036545637995004654\n",
      "Epoch 4879, Loss: 0.16162530705332756, Final Batch Loss: 0.14082571864128113\n",
      "Epoch 4880, Loss: 0.07430925220251083, Final Batch Loss: 0.03963908553123474\n",
      "Epoch 4881, Loss: 0.05915607325732708, Final Batch Loss: 0.04341357573866844\n",
      "Epoch 4882, Loss: 0.05664093978703022, Final Batch Loss: 0.021994663402438164\n",
      "Epoch 4883, Loss: 0.12927597016096115, Final Batch Loss: 0.08935217559337616\n",
      "Epoch 4884, Loss: 0.07031308114528656, Final Batch Loss: 0.03214821219444275\n",
      "Epoch 4885, Loss: 0.044339826330542564, Final Batch Loss: 0.019502315670251846\n",
      "Epoch 4886, Loss: 0.056107623502612114, Final Batch Loss: 0.025285732001066208\n",
      "Epoch 4887, Loss: 0.04396262299269438, Final Batch Loss: 0.011152896098792553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4888, Loss: 0.03292014356702566, Final Batch Loss: 0.010431080125272274\n",
      "Epoch 4889, Loss: 0.056709906086325645, Final Batch Loss: 0.038686662912368774\n",
      "Epoch 4890, Loss: 0.040383354760706425, Final Batch Loss: 0.009952305816113949\n",
      "Epoch 4891, Loss: 0.06755464151501656, Final Batch Loss: 0.040487829595804214\n",
      "Epoch 4892, Loss: 0.05918320454657078, Final Batch Loss: 0.02313329093158245\n",
      "Epoch 4893, Loss: 0.0658460222184658, Final Batch Loss: 0.034094102680683136\n",
      "Epoch 4894, Loss: 0.06847135536372662, Final Batch Loss: 0.04976983368396759\n",
      "Epoch 4895, Loss: 0.0763165969401598, Final Batch Loss: 0.05120637267827988\n",
      "Epoch 4896, Loss: 0.06707335077226162, Final Batch Loss: 0.046760864555835724\n",
      "Epoch 4897, Loss: 0.04589065909385681, Final Batch Loss: 0.024998798966407776\n",
      "Epoch 4898, Loss: 0.05598496459424496, Final Batch Loss: 0.028091706335544586\n",
      "Epoch 4899, Loss: 0.04914701543748379, Final Batch Loss: 0.017519665881991386\n",
      "Epoch 4900, Loss: 0.08017181977629662, Final Batch Loss: 0.05178087577223778\n",
      "Epoch 4901, Loss: 0.08930709958076477, Final Batch Loss: 0.027709785848855972\n",
      "Epoch 4902, Loss: 0.057012349367141724, Final Batch Loss: 0.011733867228031158\n",
      "Epoch 4903, Loss: 0.07152561098337173, Final Batch Loss: 0.024165131151676178\n",
      "Epoch 4904, Loss: 0.042082902044057846, Final Batch Loss: 0.027583319693803787\n",
      "Epoch 4905, Loss: 0.048675255849957466, Final Batch Loss: 0.02080303430557251\n",
      "Epoch 4906, Loss: 0.06313182413578033, Final Batch Loss: 0.028586160391569138\n",
      "Epoch 4907, Loss: 0.05373872630298138, Final Batch Loss: 0.020407604053616524\n",
      "Epoch 4908, Loss: 0.054493797942996025, Final Batch Loss: 0.01620187796652317\n",
      "Epoch 4909, Loss: 0.04450173303484917, Final Batch Loss: 0.028341518715023994\n",
      "Epoch 4910, Loss: 0.045513078570365906, Final Batch Loss: 0.026500433683395386\n",
      "Epoch 4911, Loss: 0.09235434979200363, Final Batch Loss: 0.06986337155103683\n",
      "Epoch 4912, Loss: 0.040905372239649296, Final Batch Loss: 0.010874611325562\n",
      "Epoch 4913, Loss: 0.03661811910569668, Final Batch Loss: 0.021065082401037216\n",
      "Epoch 4914, Loss: 0.03642694279551506, Final Batch Loss: 0.007726253941655159\n",
      "Epoch 4915, Loss: 0.062019748613238335, Final Batch Loss: 0.022835703566670418\n",
      "Epoch 4916, Loss: 0.04877743124961853, Final Batch Loss: 0.029872404411435127\n",
      "Epoch 4917, Loss: 0.050584664568305016, Final Batch Loss: 0.03683027625083923\n",
      "Epoch 4918, Loss: 0.03629021625965834, Final Batch Loss: 0.022574175149202347\n",
      "Epoch 4919, Loss: 0.06553971208631992, Final Batch Loss: 0.021447570994496346\n",
      "Epoch 4920, Loss: 0.02960569690912962, Final Batch Loss: 0.01120877917855978\n",
      "Epoch 4921, Loss: 0.04106283746659756, Final Batch Loss: 0.019794419407844543\n",
      "Epoch 4922, Loss: 0.04254156816750765, Final Batch Loss: 0.011986381374299526\n",
      "Epoch 4923, Loss: 0.044289011508226395, Final Batch Loss: 0.025484396144747734\n",
      "Epoch 4924, Loss: 0.05076638702303171, Final Batch Loss: 0.03563137724995613\n",
      "Epoch 4925, Loss: 0.03031566645950079, Final Batch Loss: 0.009948710910975933\n",
      "Epoch 4926, Loss: 0.04329563304781914, Final Batch Loss: 0.01933915913105011\n",
      "Epoch 4927, Loss: 0.058605020865797997, Final Batch Loss: 0.012964563444256783\n",
      "Epoch 4928, Loss: 0.10494761914014816, Final Batch Loss: 0.06648654490709305\n",
      "Epoch 4929, Loss: 0.042804162949323654, Final Batch Loss: 0.023288439959287643\n",
      "Epoch 4930, Loss: 0.06866518873721361, Final Batch Loss: 0.054169803857803345\n",
      "Epoch 4931, Loss: 0.0508602038025856, Final Batch Loss: 0.030587701126933098\n",
      "Epoch 4932, Loss: 0.06379532068967819, Final Batch Loss: 0.026056110858917236\n",
      "Epoch 4933, Loss: 0.0656944289803505, Final Batch Loss: 0.03430091217160225\n",
      "Epoch 4934, Loss: 0.06245420128107071, Final Batch Loss: 0.04256712272763252\n",
      "Epoch 4935, Loss: 0.06812362186610699, Final Batch Loss: 0.014885546639561653\n",
      "Epoch 4936, Loss: 0.09958045184612274, Final Batch Loss: 0.06837884336709976\n",
      "Epoch 4937, Loss: 0.0802120715379715, Final Batch Loss: 0.047680873423814774\n",
      "Epoch 4938, Loss: 0.07575883530080318, Final Batch Loss: 0.04780837520956993\n",
      "Epoch 4939, Loss: 0.02740753348916769, Final Batch Loss: 0.015253192745149136\n",
      "Epoch 4940, Loss: 0.049364831298589706, Final Batch Loss: 0.02046123705804348\n",
      "Epoch 4941, Loss: 0.039297934621572495, Final Batch Loss: 0.011066494509577751\n",
      "Epoch 4942, Loss: 0.09351557493209839, Final Batch Loss: 0.015205532312393188\n",
      "Epoch 4943, Loss: 0.044422286562621593, Final Batch Loss: 0.01528829988092184\n",
      "Epoch 4944, Loss: 0.04662153869867325, Final Batch Loss: 0.02538675256073475\n",
      "Epoch 4945, Loss: 0.0650527561083436, Final Batch Loss: 0.012374845333397388\n",
      "Epoch 4946, Loss: 0.043136472813785076, Final Batch Loss: 0.010161667130887508\n",
      "Epoch 4947, Loss: 0.036779225803911686, Final Batch Loss: 0.010835976339876652\n",
      "Epoch 4948, Loss: 0.07153515703976154, Final Batch Loss: 0.04470323398709297\n",
      "Epoch 4949, Loss: 0.06824681162834167, Final Batch Loss: 0.031189311295747757\n",
      "Epoch 4950, Loss: 0.049985598772764206, Final Batch Loss: 0.013979773968458176\n",
      "Epoch 4951, Loss: 0.06831451691687107, Final Batch Loss: 0.042450785636901855\n",
      "Epoch 4952, Loss: 0.01912117563188076, Final Batch Loss: 0.009433974511921406\n",
      "Epoch 4953, Loss: 0.04647514037787914, Final Batch Loss: 0.024713696911931038\n",
      "Epoch 4954, Loss: 0.05946814827620983, Final Batch Loss: 0.03730256110429764\n",
      "Epoch 4955, Loss: 0.04039536044001579, Final Batch Loss: 0.015575256198644638\n",
      "Epoch 4956, Loss: 0.025312199257314205, Final Batch Loss: 0.00805147085338831\n",
      "Epoch 4957, Loss: 0.0507908221334219, Final Batch Loss: 0.01660030521452427\n",
      "Epoch 4958, Loss: 0.03952602483332157, Final Batch Loss: 0.021485881879925728\n",
      "Epoch 4959, Loss: 0.07157301530241966, Final Batch Loss: 0.027067605406045914\n",
      "Epoch 4960, Loss: 0.053094842471182346, Final Batch Loss: 0.015024383552372456\n",
      "Epoch 4961, Loss: 0.03911812137812376, Final Batch Loss: 0.01416000071913004\n",
      "Epoch 4962, Loss: 0.0567034836858511, Final Batch Loss: 0.0314018614590168\n",
      "Epoch 4963, Loss: 0.07708133198320866, Final Batch Loss: 0.05369222164154053\n",
      "Epoch 4964, Loss: 0.04133652616292238, Final Batch Loss: 0.011853677220642567\n",
      "Epoch 4965, Loss: 0.08263927511870861, Final Batch Loss: 0.05517803132534027\n",
      "Epoch 4966, Loss: 0.04717699810862541, Final Batch Loss: 0.0334688201546669\n",
      "Epoch 4967, Loss: 0.0675745839253068, Final Batch Loss: 0.0521530881524086\n",
      "Epoch 4968, Loss: 0.09470264054834843, Final Batch Loss: 0.07665341347455978\n",
      "Epoch 4969, Loss: 0.05657001584768295, Final Batch Loss: 0.030640076845884323\n",
      "Epoch 4970, Loss: 0.07283739186823368, Final Batch Loss: 0.05639477074146271\n",
      "Epoch 4971, Loss: 0.054506611078977585, Final Batch Loss: 0.016448240727186203\n",
      "Epoch 4972, Loss: 0.03200762253254652, Final Batch Loss: 0.010168666951358318\n",
      "Epoch 4973, Loss: 0.07721734046936035, Final Batch Loss: 0.03413144871592522\n",
      "Epoch 4974, Loss: 0.10087649524211884, Final Batch Loss: 0.05462026223540306\n",
      "Epoch 4975, Loss: 0.04987973952665925, Final Batch Loss: 0.006008817348629236\n",
      "Epoch 4976, Loss: 0.0488872155547142, Final Batch Loss: 0.023985134437680244\n",
      "Epoch 4977, Loss: 0.032252632081508636, Final Batch Loss: 0.01406426727771759\n",
      "Epoch 4978, Loss: 0.06275985576212406, Final Batch Loss: 0.021920932456851006\n",
      "Epoch 4979, Loss: 0.052508775144815445, Final Batch Loss: 0.010519437491893768\n",
      "Epoch 4980, Loss: 0.04636205825954676, Final Batch Loss: 0.013265558518469334\n",
      "Epoch 4981, Loss: 0.041262022918090224, Final Batch Loss: 0.002039488172158599\n",
      "Epoch 4982, Loss: 0.04907962679862976, Final Batch Loss: 0.021550176665186882\n",
      "Epoch 4983, Loss: 0.03671795874834061, Final Batch Loss: 0.014924207702279091\n",
      "Epoch 4984, Loss: 0.04960061330348253, Final Batch Loss: 0.03767688199877739\n",
      "Epoch 4985, Loss: 0.06257611885666847, Final Batch Loss: 0.018415305763483047\n",
      "Epoch 4986, Loss: 0.042217276990413666, Final Batch Loss: 0.016477398574352264\n",
      "Epoch 4987, Loss: 0.03663442377001047, Final Batch Loss: 0.0075454311445355415\n",
      "Epoch 4988, Loss: 0.03901768196374178, Final Batch Loss: 0.014875923283398151\n",
      "Epoch 4989, Loss: 0.05704828351736069, Final Batch Loss: 0.021013759076595306\n",
      "Epoch 4990, Loss: 0.04043117444962263, Final Batch Loss: 0.01188828144222498\n",
      "Epoch 4991, Loss: 0.061586447060108185, Final Batch Loss: 0.040158629417419434\n",
      "Epoch 4992, Loss: 0.051593877375125885, Final Batch Loss: 0.025321662425994873\n",
      "Epoch 4993, Loss: 0.04894249700009823, Final Batch Loss: 0.032806381583213806\n",
      "Epoch 4994, Loss: 0.03204090055078268, Final Batch Loss: 0.013403725810348988\n",
      "Epoch 4995, Loss: 0.053633651696145535, Final Batch Loss: 0.04044630005955696\n",
      "Epoch 4996, Loss: 0.04185854364186525, Final Batch Loss: 0.01127076055854559\n",
      "Epoch 4997, Loss: 0.04782317392528057, Final Batch Loss: 0.018842065706849098\n",
      "Epoch 4998, Loss: 0.08337170071899891, Final Batch Loss: 0.018574373796582222\n",
      "Epoch 4999, Loss: 0.07313038408756256, Final Batch Loss: 0.028482601046562195\n",
      "Epoch 5000, Loss: 0.16922383941709995, Final Batch Loss: 0.1524299830198288\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  1  0]\n",
      " [ 0 30  2]\n",
      " [ 0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.96000   0.97959        25\n",
      "           1    0.96774   0.93750   0.95238        32\n",
      "           2    0.94118   1.00000   0.96970        32\n",
      "\n",
      "    accuracy                        0.96629        89\n",
      "   macro avg    0.96964   0.96583   0.96722        89\n",
      "weighted avg    0.96725   0.96629   0.96625        89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  2  0]\n",
      " [ 3 24  3]\n",
      " [ 0  5 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90323   0.93333   0.91803        30\n",
      "           1    0.77419   0.80000   0.78689        30\n",
      "           2    0.89286   0.83333   0.86207        30\n",
      "\n",
      "    accuracy                        0.85556        90\n",
      "   macro avg    0.85676   0.85556   0.85566        90\n",
      "weighted avg    0.85676   0.85556   0.85566        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
