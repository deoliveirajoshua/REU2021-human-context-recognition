{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.36992084980011, Final Batch Loss: 1.1454048156738281\n",
      "Epoch 2, Loss: 3.3366039991378784, Final Batch Loss: 1.1298075914382935\n",
      "Epoch 3, Loss: 3.292970299720764, Final Batch Loss: 1.1044026613235474\n",
      "Epoch 4, Loss: 3.2573505640029907, Final Batch Loss: 1.0736380815505981\n",
      "Epoch 5, Loss: 3.255733013153076, Final Batch Loss: 1.0895518064498901\n",
      "Epoch 6, Loss: 3.2408639192581177, Final Batch Loss: 1.0802416801452637\n",
      "Epoch 7, Loss: 3.2171924114227295, Final Batch Loss: 1.0656620264053345\n",
      "Epoch 8, Loss: 3.2212233543395996, Final Batch Loss: 1.0794132947921753\n",
      "Epoch 9, Loss: 3.179232954978943, Final Batch Loss: 1.0497808456420898\n",
      "Epoch 10, Loss: 3.1799468994140625, Final Batch Loss: 1.063114881515503\n",
      "Epoch 11, Loss: 3.177958369255066, Final Batch Loss: 1.0764403343200684\n",
      "Epoch 12, Loss: 3.1267054080963135, Final Batch Loss: 1.0341405868530273\n",
      "Epoch 13, Loss: 3.101980686187744, Final Batch Loss: 1.0312200784683228\n",
      "Epoch 14, Loss: 3.0814080238342285, Final Batch Loss: 1.0323985815048218\n",
      "Epoch 15, Loss: 3.0376598834991455, Final Batch Loss: 1.0126579999923706\n",
      "Epoch 16, Loss: 2.958208382129669, Final Batch Loss: 0.9627305269241333\n",
      "Epoch 17, Loss: 2.91917622089386, Final Batch Loss: 0.9605242013931274\n",
      "Epoch 18, Loss: 2.8797956109046936, Final Batch Loss: 0.9576371908187866\n",
      "Epoch 19, Loss: 2.8013023138046265, Final Batch Loss: 0.9292565584182739\n",
      "Epoch 20, Loss: 2.72529536485672, Final Batch Loss: 0.906186580657959\n",
      "Epoch 21, Loss: 2.6778228878974915, Final Batch Loss: 0.9073438048362732\n",
      "Epoch 22, Loss: 2.63327693939209, Final Batch Loss: 0.9278209209442139\n",
      "Epoch 23, Loss: 2.4434374570846558, Final Batch Loss: 0.7952583432197571\n",
      "Epoch 24, Loss: 2.419478476047516, Final Batch Loss: 0.8215315341949463\n",
      "Epoch 25, Loss: 2.213375210762024, Final Batch Loss: 0.6917028427124023\n",
      "Epoch 26, Loss: 2.2320613861083984, Final Batch Loss: 0.7803910374641418\n",
      "Epoch 27, Loss: 2.031651496887207, Final Batch Loss: 0.6514009237289429\n",
      "Epoch 28, Loss: 2.019464135169983, Final Batch Loss: 0.6980719566345215\n",
      "Epoch 29, Loss: 2.0135388374328613, Final Batch Loss: 0.7566996216773987\n",
      "Epoch 30, Loss: 1.8683286905288696, Final Batch Loss: 0.6564399003982544\n",
      "Epoch 31, Loss: 1.7417318224906921, Final Batch Loss: 0.5771710872650146\n",
      "Epoch 32, Loss: 1.6805328726768494, Final Batch Loss: 0.569210946559906\n",
      "Epoch 33, Loss: 1.5029762089252472, Final Batch Loss: 0.44433823227882385\n",
      "Epoch 34, Loss: 1.4178082346916199, Final Batch Loss: 0.41892075538635254\n",
      "Epoch 35, Loss: 1.322172462940216, Final Batch Loss: 0.40500620007514954\n",
      "Epoch 36, Loss: 1.2453351616859436, Final Batch Loss: 0.3866429030895233\n",
      "Epoch 37, Loss: 1.0851502120494843, Final Batch Loss: 0.2540070414543152\n",
      "Epoch 38, Loss: 1.075134128332138, Final Batch Loss: 0.31230565905570984\n",
      "Epoch 39, Loss: 1.0640974044799805, Final Batch Loss: 0.3820066452026367\n",
      "Epoch 40, Loss: 1.1279671490192413, Final Batch Loss: 0.4519639313220978\n",
      "Epoch 41, Loss: 0.9599269926548004, Final Batch Loss: 0.3095815181732178\n",
      "Epoch 42, Loss: 0.953681617975235, Final Batch Loss: 0.3259966969490051\n",
      "Epoch 43, Loss: 0.8534219264984131, Final Batch Loss: 0.33478203415870667\n",
      "Epoch 44, Loss: 0.8570847809314728, Final Batch Loss: 0.3048580288887024\n",
      "Epoch 45, Loss: 0.6727144122123718, Final Batch Loss: 0.18729782104492188\n",
      "Epoch 46, Loss: 0.7990907281637192, Final Batch Loss: 0.33482515811920166\n",
      "Epoch 47, Loss: 0.8199815899133682, Final Batch Loss: 0.372061163187027\n",
      "Epoch 48, Loss: 0.5816660225391388, Final Batch Loss: 0.15741172432899475\n",
      "Epoch 49, Loss: 0.6239173412322998, Final Batch Loss: 0.18297502398490906\n",
      "Epoch 50, Loss: 0.714786633849144, Final Batch Loss: 0.2680125832557678\n",
      "Epoch 51, Loss: 0.6261925101280212, Final Batch Loss: 0.24613922834396362\n",
      "Epoch 52, Loss: 0.4676550626754761, Final Batch Loss: 0.08488845825195312\n",
      "Epoch 53, Loss: 0.5401061624288559, Final Batch Loss: 0.18627606332302094\n",
      "Epoch 54, Loss: 0.5377157330513, Final Batch Loss: 0.12177500128746033\n",
      "Epoch 55, Loss: 0.5674333721399307, Final Batch Loss: 0.1913166046142578\n",
      "Epoch 56, Loss: 0.49518588185310364, Final Batch Loss: 0.14328281581401825\n",
      "Epoch 57, Loss: 0.4556589275598526, Final Batch Loss: 0.06693579256534576\n",
      "Epoch 58, Loss: 0.4916592091321945, Final Batch Loss: 0.12510566413402557\n",
      "Epoch 59, Loss: 0.4200185313820839, Final Batch Loss: 0.06662892550230026\n",
      "Epoch 60, Loss: 0.4838639795780182, Final Batch Loss: 0.15428426861763\n",
      "Epoch 61, Loss: 0.6194110959768295, Final Batch Loss: 0.25118327140808105\n",
      "Epoch 62, Loss: 0.5616205632686615, Final Batch Loss: 0.21641378104686737\n",
      "Epoch 63, Loss: 0.3803268298506737, Final Batch Loss: 0.06904194504022598\n",
      "Epoch 64, Loss: 0.6498321294784546, Final Batch Loss: 0.2915261685848236\n",
      "Epoch 65, Loss: 0.50783970952034, Final Batch Loss: 0.13767175376415253\n",
      "Epoch 66, Loss: 0.3819205090403557, Final Batch Loss: 0.076517753303051\n",
      "Epoch 67, Loss: 0.5033882558345795, Final Batch Loss: 0.1887311488389969\n",
      "Epoch 68, Loss: 0.4437444880604744, Final Batch Loss: 0.11212830990552902\n",
      "Epoch 69, Loss: 0.6603236794471741, Final Batch Loss: 0.3593197464942932\n",
      "Epoch 70, Loss: 0.46740271896123886, Final Batch Loss: 0.18386918306350708\n",
      "Epoch 71, Loss: 0.41409582644701004, Final Batch Loss: 0.10191399604082108\n",
      "Epoch 72, Loss: 0.35460545867681503, Final Batch Loss: 0.09137558192014694\n",
      "Epoch 73, Loss: 0.3690181374549866, Final Batch Loss: 0.12645137310028076\n",
      "Epoch 74, Loss: 0.3008911944925785, Final Batch Loss: 0.03599870577454567\n",
      "Epoch 75, Loss: 0.38150688260793686, Final Batch Loss: 0.12332529574632645\n",
      "Epoch 76, Loss: 0.2876814752817154, Final Batch Loss: 0.05270114541053772\n",
      "Epoch 77, Loss: 0.3389696776866913, Final Batch Loss: 0.1284133940935135\n",
      "Epoch 78, Loss: 0.5959266647696495, Final Batch Loss: 0.3695390522480011\n",
      "Epoch 79, Loss: 0.4960366189479828, Final Batch Loss: 0.2163895070552826\n",
      "Epoch 80, Loss: 0.3388626016676426, Final Batch Loss: 0.04841983690857887\n",
      "Epoch 81, Loss: 0.2824532985687256, Final Batch Loss: 0.046026602387428284\n",
      "Epoch 82, Loss: 0.4954500049352646, Final Batch Loss: 0.24729324877262115\n",
      "Epoch 83, Loss: 0.4298229217529297, Final Batch Loss: 0.11492923647165298\n",
      "Epoch 84, Loss: 0.44899889826774597, Final Batch Loss: 0.177180677652359\n",
      "Epoch 85, Loss: 0.3995705842971802, Final Batch Loss: 0.14980605244636536\n",
      "Epoch 86, Loss: 0.31680523604154587, Final Batch Loss: 0.02379225194454193\n",
      "Epoch 87, Loss: 0.6515394002199173, Final Batch Loss: 0.3886210024356842\n",
      "Epoch 88, Loss: 0.6829324066638947, Final Batch Loss: 0.3590583801269531\n",
      "Epoch 89, Loss: 0.21898573823273182, Final Batch Loss: 0.019559727981686592\n",
      "Epoch 90, Loss: 0.3161814287304878, Final Batch Loss: 0.06538412719964981\n",
      "Epoch 91, Loss: 0.2945545669645071, Final Batch Loss: 0.0300759207457304\n",
      "Epoch 92, Loss: 0.3024096190929413, Final Batch Loss: 0.07822808623313904\n",
      "Epoch 93, Loss: 0.43500151485204697, Final Batch Loss: 0.1614791452884674\n",
      "Epoch 94, Loss: 0.42934563010931015, Final Batch Loss: 0.20906971395015717\n",
      "Epoch 95, Loss: 0.33148298412561417, Final Batch Loss: 0.10646537691354752\n",
      "Epoch 96, Loss: 0.41859251260757446, Final Batch Loss: 0.12452824413776398\n",
      "Epoch 97, Loss: 0.315723218023777, Final Batch Loss: 0.07430994510650635\n",
      "Epoch 98, Loss: 0.24225159734487534, Final Batch Loss: 0.013832204043865204\n",
      "Epoch 99, Loss: 0.2695390284061432, Final Batch Loss: 0.05404648184776306\n",
      "Epoch 100, Loss: 0.25450554862618446, Final Batch Loss: 0.045491497963666916\n",
      "Epoch 101, Loss: 0.34630704671144485, Final Batch Loss: 0.16755753755569458\n",
      "Epoch 102, Loss: 0.2769107148051262, Final Batch Loss: 0.08096682280302048\n",
      "Epoch 103, Loss: 0.26868554949760437, Final Batch Loss: 0.046539515256881714\n",
      "Epoch 104, Loss: 0.27909594029188156, Final Batch Loss: 0.03134353458881378\n",
      "Epoch 105, Loss: 0.38130906224250793, Final Batch Loss: 0.1667376011610031\n",
      "Epoch 106, Loss: 0.23377211764454842, Final Batch Loss: 0.06144632771611214\n",
      "Epoch 107, Loss: 0.21503123175352812, Final Batch Loss: 0.010339098982512951\n",
      "Epoch 108, Loss: 0.1968412548303604, Final Batch Loss: 0.02674734592437744\n",
      "Epoch 109, Loss: 0.23973678052425385, Final Batch Loss: 0.021242044866085052\n",
      "Epoch 110, Loss: 0.28049707412719727, Final Batch Loss: 0.0818486288189888\n",
      "Epoch 111, Loss: 0.373848058283329, Final Batch Loss: 0.1195530891418457\n",
      "Epoch 112, Loss: 0.21653632074594498, Final Batch Loss: 0.0422842875123024\n",
      "Epoch 113, Loss: 0.23358571901917458, Final Batch Loss: 0.03432592377066612\n",
      "Epoch 114, Loss: 0.21653719618916512, Final Batch Loss: 0.032317232340574265\n",
      "Epoch 115, Loss: 0.2733331397175789, Final Batch Loss: 0.06711488962173462\n",
      "Epoch 116, Loss: 0.172418718226254, Final Batch Loss: 0.009409871883690357\n",
      "Epoch 117, Loss: 0.3904856666922569, Final Batch Loss: 0.18568718433380127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118, Loss: 0.3317769803106785, Final Batch Loss: 0.1893564611673355\n",
      "Epoch 119, Loss: 0.22267486155033112, Final Batch Loss: 0.06096503138542175\n",
      "Epoch 120, Loss: 0.3527325242757797, Final Batch Loss: 0.09014144539833069\n",
      "Epoch 121, Loss: 0.2446000799536705, Final Batch Loss: 0.0927848294377327\n",
      "Epoch 122, Loss: 0.4975327104330063, Final Batch Loss: 0.35922664403915405\n",
      "Epoch 123, Loss: 0.34467407315969467, Final Batch Loss: 0.10626046359539032\n",
      "Epoch 124, Loss: 0.24838127568364143, Final Batch Loss: 0.0543101541697979\n",
      "Epoch 125, Loss: 0.23488404601812363, Final Batch Loss: 0.05662158876657486\n",
      "Epoch 126, Loss: 0.38928162306547165, Final Batch Loss: 0.19245612621307373\n",
      "Epoch 127, Loss: 0.18876244872808456, Final Batch Loss: 0.05229625850915909\n",
      "Epoch 128, Loss: 0.19033879693597555, Final Batch Loss: 0.011469869874417782\n",
      "Epoch 129, Loss: 0.2134115919470787, Final Batch Loss: 0.04569191485643387\n",
      "Epoch 130, Loss: 0.19302432239055634, Final Batch Loss: 0.010876908898353577\n",
      "Epoch 131, Loss: 0.18867924436926842, Final Batch Loss: 0.030848879367113113\n",
      "Epoch 132, Loss: 0.21767592057585716, Final Batch Loss: 0.049798909574747086\n",
      "Epoch 133, Loss: 0.29604000598192215, Final Batch Loss: 0.07571029663085938\n",
      "Epoch 134, Loss: 0.5417304337024689, Final Batch Loss: 0.3886517584323883\n",
      "Epoch 135, Loss: 0.28933553397655487, Final Batch Loss: 0.11082073301076889\n",
      "Epoch 136, Loss: 0.5607604458928108, Final Batch Loss: 0.34167608618736267\n",
      "Epoch 137, Loss: 0.4031519666314125, Final Batch Loss: 0.19015924632549286\n",
      "Epoch 138, Loss: 0.265309676527977, Final Batch Loss: 0.07218360900878906\n",
      "Epoch 139, Loss: 0.19417516514658928, Final Batch Loss: 0.04200960323214531\n",
      "Epoch 140, Loss: 0.21719525381922722, Final Batch Loss: 0.050419796258211136\n",
      "Epoch 141, Loss: 0.2211119830608368, Final Batch Loss: 0.05610636621713638\n",
      "Epoch 142, Loss: 0.24148214608430862, Final Batch Loss: 0.07004978507757187\n",
      "Epoch 143, Loss: 0.2103528529405594, Final Batch Loss: 0.016211993992328644\n",
      "Epoch 144, Loss: 0.2045932672917843, Final Batch Loss: 0.04305462911725044\n",
      "Epoch 145, Loss: 0.23906725645065308, Final Batch Loss: 0.08286586403846741\n",
      "Epoch 146, Loss: 0.15892120264470577, Final Batch Loss: 0.024878161028027534\n",
      "Epoch 147, Loss: 0.13901397213339806, Final Batch Loss: 0.012268275022506714\n",
      "Epoch 148, Loss: 0.17530271224677563, Final Batch Loss: 0.01980326883494854\n",
      "Epoch 149, Loss: 0.1943359673023224, Final Batch Loss: 0.02471093088388443\n",
      "Epoch 150, Loss: 0.37414009124040604, Final Batch Loss: 0.20810076594352722\n",
      "Epoch 151, Loss: 0.24260187149047852, Final Batch Loss: 0.08163465559482574\n",
      "Epoch 152, Loss: 0.19597572647035122, Final Batch Loss: 0.01957315020263195\n",
      "Epoch 153, Loss: 0.18115295469760895, Final Batch Loss: 0.014476753771305084\n",
      "Epoch 154, Loss: 0.19064050447195768, Final Batch Loss: 0.012009094469249249\n",
      "Epoch 155, Loss: 0.17635217308998108, Final Batch Loss: 0.047028593719005585\n",
      "Epoch 156, Loss: 0.20363540202379227, Final Batch Loss: 0.03005284070968628\n",
      "Epoch 157, Loss: 0.2204582467675209, Final Batch Loss: 0.06089664250612259\n",
      "Epoch 158, Loss: 0.1862118300050497, Final Batch Loss: 0.02334952913224697\n",
      "Epoch 159, Loss: 0.37937112152576447, Final Batch Loss: 0.23647832870483398\n",
      "Epoch 160, Loss: 0.24591200053691864, Final Batch Loss: 0.0797681212425232\n",
      "Epoch 161, Loss: 0.18435207474976778, Final Batch Loss: 0.014557850547134876\n",
      "Epoch 162, Loss: 0.1673792116343975, Final Batch Loss: 0.040236737579107285\n",
      "Epoch 163, Loss: 0.2235536351799965, Final Batch Loss: 0.09747299551963806\n",
      "Epoch 164, Loss: 0.28285030648112297, Final Batch Loss: 0.15907076001167297\n",
      "Epoch 165, Loss: 0.1666788039728999, Final Batch Loss: 0.01301159244030714\n",
      "Epoch 166, Loss: 0.17085611447691917, Final Batch Loss: 0.023691684007644653\n",
      "Epoch 167, Loss: 0.27154403924942017, Final Batch Loss: 0.09784675389528275\n",
      "Epoch 168, Loss: 0.23476754128932953, Final Batch Loss: 0.053069308400154114\n",
      "Epoch 169, Loss: 0.1856706105172634, Final Batch Loss: 0.018974043428897858\n",
      "Epoch 170, Loss: 0.20583738759160042, Final Batch Loss: 0.06379863619804382\n",
      "Epoch 171, Loss: 0.15655182674527168, Final Batch Loss: 0.0449862964451313\n",
      "Epoch 172, Loss: 0.13918516039848328, Final Batch Loss: 0.025172419846057892\n",
      "Epoch 173, Loss: 0.24888844788074493, Final Batch Loss: 0.06976159662008286\n",
      "Epoch 174, Loss: 0.18385940790176392, Final Batch Loss: 0.015743859112262726\n",
      "Epoch 175, Loss: 0.21163974329829216, Final Batch Loss: 0.06389937549829483\n",
      "Epoch 176, Loss: 0.2639048248529434, Final Batch Loss: 0.11913751065731049\n",
      "Epoch 177, Loss: 0.15525133162736893, Final Batch Loss: 0.04427552968263626\n",
      "Epoch 178, Loss: 0.1651686690747738, Final Batch Loss: 0.02967989072203636\n",
      "Epoch 179, Loss: 0.1733065713196993, Final Batch Loss: 0.02893112786114216\n",
      "Epoch 180, Loss: 0.25481152534484863, Final Batch Loss: 0.10251200944185257\n",
      "Epoch 181, Loss: 0.13522353232838213, Final Batch Loss: 0.0029785281512886286\n",
      "Epoch 182, Loss: 0.17849285528063774, Final Batch Loss: 0.05806198716163635\n",
      "Epoch 183, Loss: 0.12591246329247952, Final Batch Loss: 0.025965170934796333\n",
      "Epoch 184, Loss: 0.21939237043261528, Final Batch Loss: 0.041798923164606094\n",
      "Epoch 185, Loss: 0.20953186228871346, Final Batch Loss: 0.10570628941059113\n",
      "Epoch 186, Loss: 0.21565047465264797, Final Batch Loss: 0.02928302250802517\n",
      "Epoch 187, Loss: 0.17585300095379353, Final Batch Loss: 0.02192714251577854\n",
      "Epoch 188, Loss: 0.1487540965899825, Final Batch Loss: 0.00517840962857008\n",
      "Epoch 189, Loss: 0.1882959296926856, Final Batch Loss: 0.015187873505055904\n",
      "Epoch 190, Loss: 0.2653426304459572, Final Batch Loss: 0.14821915328502655\n",
      "Epoch 191, Loss: 0.1637586634606123, Final Batch Loss: 0.03627380356192589\n",
      "Epoch 192, Loss: 0.13324544299393892, Final Batch Loss: 0.01242868322879076\n",
      "Epoch 193, Loss: 0.1582965236157179, Final Batch Loss: 0.01691599003970623\n",
      "Epoch 194, Loss: 0.16772322729229927, Final Batch Loss: 0.025385111570358276\n",
      "Epoch 195, Loss: 0.11546522239223123, Final Batch Loss: 0.006698115263134241\n",
      "Epoch 196, Loss: 0.2837591879069805, Final Batch Loss: 0.196594700217247\n",
      "Epoch 197, Loss: 0.1663399413228035, Final Batch Loss: 0.06586757302284241\n",
      "Epoch 198, Loss: 0.16159473173320293, Final Batch Loss: 0.02373785711824894\n",
      "Epoch 199, Loss: 0.1467567514628172, Final Batch Loss: 0.012427063658833504\n",
      "Epoch 200, Loss: 0.16991418227553368, Final Batch Loss: 0.03819845989346504\n",
      "Epoch 201, Loss: 0.08919553644955158, Final Batch Loss: 0.008338643237948418\n",
      "Epoch 202, Loss: 0.15534989722073078, Final Batch Loss: 0.022285519167780876\n",
      "Epoch 203, Loss: 0.12568950094282627, Final Batch Loss: 0.00386064313352108\n",
      "Epoch 204, Loss: 0.13502979464828968, Final Batch Loss: 0.0272871945053339\n",
      "Epoch 205, Loss: 0.1746511533856392, Final Batch Loss: 0.027060966938734055\n",
      "Epoch 206, Loss: 0.11320271249860525, Final Batch Loss: 0.014487612061202526\n",
      "Epoch 207, Loss: 0.16551491245627403, Final Batch Loss: 0.019052822142839432\n",
      "Epoch 208, Loss: 0.2626299764961004, Final Batch Loss: 0.11281167715787888\n",
      "Epoch 209, Loss: 0.24751555174589157, Final Batch Loss: 0.10801003873348236\n",
      "Epoch 210, Loss: 0.10262957657687366, Final Batch Loss: 0.003578581614419818\n",
      "Epoch 211, Loss: 0.1531746075488627, Final Batch Loss: 0.007715581450611353\n",
      "Epoch 212, Loss: 0.13493494503200054, Final Batch Loss: 0.03063935972750187\n",
      "Epoch 213, Loss: 0.13403941690921783, Final Batch Loss: 0.013343144208192825\n",
      "Epoch 214, Loss: 0.10521994344890118, Final Batch Loss: 0.022212322801351547\n",
      "Epoch 215, Loss: 0.23046611994504929, Final Batch Loss: 0.09470866620540619\n",
      "Epoch 216, Loss: 0.145976971834898, Final Batch Loss: 0.04093863442540169\n",
      "Epoch 217, Loss: 0.18254532665014267, Final Batch Loss: 0.03931674361228943\n",
      "Epoch 218, Loss: 0.13704292778857052, Final Batch Loss: 0.0038232647348195314\n",
      "Epoch 219, Loss: 0.1969065833836794, Final Batch Loss: 0.024417197331786156\n",
      "Epoch 220, Loss: 0.20808256790041924, Final Batch Loss: 0.07753073424100876\n",
      "Epoch 221, Loss: 0.12494390551000834, Final Batch Loss: 0.006578599102795124\n",
      "Epoch 222, Loss: 0.12301556952297688, Final Batch Loss: 0.00973724015057087\n",
      "Epoch 223, Loss: 0.20644497498869896, Final Batch Loss: 0.06384104490280151\n",
      "Epoch 224, Loss: 0.27859414368867874, Final Batch Loss: 0.16391249001026154\n",
      "Epoch 225, Loss: 0.11523103900253773, Final Batch Loss: 0.010166482999920845\n",
      "Epoch 226, Loss: 0.1551341786980629, Final Batch Loss: 0.0049993377178907394\n",
      "Epoch 227, Loss: 0.14714897982776165, Final Batch Loss: 0.009679166600108147\n",
      "Epoch 228, Loss: 0.13060777401551604, Final Batch Loss: 0.004776203539222479\n",
      "Epoch 229, Loss: 0.1526370388455689, Final Batch Loss: 0.005521938670426607\n",
      "Epoch 230, Loss: 0.1741965264081955, Final Batch Loss: 0.04879903793334961\n",
      "Epoch 231, Loss: 0.13231464475393295, Final Batch Loss: 0.01032307744026184\n",
      "Epoch 232, Loss: 0.13438063114881516, Final Batch Loss: 0.003886274993419647\n",
      "Epoch 233, Loss: 0.15605966560542583, Final Batch Loss: 0.010107109323143959\n",
      "Epoch 234, Loss: 0.12438224186189473, Final Batch Loss: 0.0024641037452965975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235, Loss: 0.35335410200059414, Final Batch Loss: 0.2611343562602997\n",
      "Epoch 236, Loss: 0.2514330670237541, Final Batch Loss: 0.11579086631536484\n",
      "Epoch 237, Loss: 0.33684225007891655, Final Batch Loss: 0.23563531041145325\n",
      "Epoch 238, Loss: 0.12556118331849575, Final Batch Loss: 0.02112170122563839\n",
      "Epoch 239, Loss: 0.21396151185035706, Final Batch Loss: 0.08606382459402084\n",
      "Epoch 240, Loss: 0.12277889251708984, Final Batch Loss: 0.005810510367155075\n",
      "Epoch 241, Loss: 0.1478027068078518, Final Batch Loss: 0.04326197877526283\n",
      "Epoch 242, Loss: 0.1352172028273344, Final Batch Loss: 0.016716977581381798\n",
      "Epoch 243, Loss: 0.12478489801287651, Final Batch Loss: 0.037265509366989136\n",
      "Epoch 244, Loss: 0.14737479761242867, Final Batch Loss: 0.034180980175733566\n",
      "Epoch 245, Loss: 0.1869364008307457, Final Batch Loss: 0.08727536350488663\n",
      "Epoch 246, Loss: 0.12350593321025372, Final Batch Loss: 0.029864026233553886\n",
      "Epoch 247, Loss: 0.11285614408552647, Final Batch Loss: 0.007017413154244423\n",
      "Epoch 248, Loss: 0.2684386186301708, Final Batch Loss: 0.13085797429084778\n",
      "Epoch 249, Loss: 0.16497653350234032, Final Batch Loss: 0.03145971894264221\n",
      "Epoch 250, Loss: 0.13214771077036858, Final Batch Loss: 0.005739782005548477\n",
      "Epoch 251, Loss: 0.10256856679916382, Final Batch Loss: 0.007938060909509659\n",
      "Epoch 252, Loss: 0.10993807855993509, Final Batch Loss: 0.00937620084732771\n",
      "Epoch 253, Loss: 0.1672486551105976, Final Batch Loss: 0.022208798676729202\n",
      "Epoch 254, Loss: 0.143128564581275, Final Batch Loss: 0.016493579372763634\n",
      "Epoch 255, Loss: 0.1650585439056158, Final Batch Loss: 0.016423607245087624\n",
      "Epoch 256, Loss: 0.49214451387524605, Final Batch Loss: 0.3868151605129242\n",
      "Epoch 257, Loss: 0.1049772989936173, Final Batch Loss: 0.00662192003801465\n",
      "Epoch 258, Loss: 0.16349076014012098, Final Batch Loss: 0.011939751915633678\n",
      "Epoch 259, Loss: 0.1409467700868845, Final Batch Loss: 0.018097681924700737\n",
      "Epoch 260, Loss: 0.08713359944522381, Final Batch Loss: 0.007193351164460182\n",
      "Epoch 261, Loss: 0.13639377616345882, Final Batch Loss: 0.04638689383864403\n",
      "Epoch 262, Loss: 0.10950788110494614, Final Batch Loss: 0.035308271646499634\n",
      "Epoch 263, Loss: 0.16559222945943475, Final Batch Loss: 0.00443196902051568\n",
      "Epoch 264, Loss: 0.15122991427779198, Final Batch Loss: 0.03565676137804985\n",
      "Epoch 265, Loss: 0.1447769347578287, Final Batch Loss: 0.02648763544857502\n",
      "Epoch 266, Loss: 0.31024080514907837, Final Batch Loss: 0.24009235203266144\n",
      "Epoch 267, Loss: 0.3597109839320183, Final Batch Loss: 0.27461615204811096\n",
      "Epoch 268, Loss: 0.3602628670632839, Final Batch Loss: 0.25568732619285583\n",
      "Epoch 269, Loss: 0.15283061377704144, Final Batch Loss: 0.02735755406320095\n",
      "Epoch 270, Loss: 0.1183129446581006, Final Batch Loss: 0.0041570598259568214\n",
      "Epoch 271, Loss: 0.12981758266687393, Final Batch Loss: 0.04470590874552727\n",
      "Epoch 272, Loss: 0.11790504958480597, Final Batch Loss: 0.012719673104584217\n",
      "Epoch 273, Loss: 0.10310655971989036, Final Batch Loss: 0.004617815371602774\n",
      "Epoch 274, Loss: 0.10437289718538523, Final Batch Loss: 0.012843207456171513\n",
      "Epoch 275, Loss: 0.24255740642547607, Final Batch Loss: 0.13939586281776428\n",
      "Epoch 276, Loss: 0.11637111660093069, Final Batch Loss: 0.01045284140855074\n",
      "Epoch 277, Loss: 0.11293157888576388, Final Batch Loss: 0.003872848581522703\n",
      "Epoch 278, Loss: 0.13192805461585522, Final Batch Loss: 0.023827722296118736\n",
      "Epoch 279, Loss: 0.10659571038559079, Final Batch Loss: 0.006310184020549059\n",
      "Epoch 280, Loss: 0.10982371354475617, Final Batch Loss: 0.004082831088453531\n",
      "Epoch 281, Loss: 0.11209088331088424, Final Batch Loss: 0.006303494330495596\n",
      "Epoch 282, Loss: 0.11783146485686302, Final Batch Loss: 0.02719048783183098\n",
      "Epoch 283, Loss: 0.2558124475181103, Final Batch Loss: 0.14570531249046326\n",
      "Epoch 284, Loss: 0.12579232640564442, Final Batch Loss: 0.02106316201388836\n",
      "Epoch 285, Loss: 0.11224568076431751, Final Batch Loss: 0.03112133778631687\n",
      "Epoch 286, Loss: 0.11836772784590721, Final Batch Loss: 0.03622408211231232\n",
      "Epoch 287, Loss: 0.08762608747929335, Final Batch Loss: 0.012492823414504528\n",
      "Epoch 288, Loss: 0.08510596491396427, Final Batch Loss: 0.03148549795150757\n",
      "Epoch 289, Loss: 0.08005868806503713, Final Batch Loss: 0.002300800522789359\n",
      "Epoch 290, Loss: 0.17965073324739933, Final Batch Loss: 0.10795008391141891\n",
      "Epoch 291, Loss: 0.09895975608378649, Final Batch Loss: 0.010868635959923267\n",
      "Epoch 292, Loss: 0.11315537802875042, Final Batch Loss: 0.012982023879885674\n",
      "Epoch 293, Loss: 0.09073831140995026, Final Batch Loss: 0.007470190525054932\n",
      "Epoch 294, Loss: 0.09923642734065652, Final Batch Loss: 0.00652666250243783\n",
      "Epoch 295, Loss: 0.11844213120639324, Final Batch Loss: 0.02219480834901333\n",
      "Epoch 296, Loss: 0.10964229144155979, Final Batch Loss: 0.012839339673519135\n",
      "Epoch 297, Loss: 0.0699578644707799, Final Batch Loss: 0.006718139164149761\n",
      "Epoch 298, Loss: 0.16962303407490253, Final Batch Loss: 0.07267040759325027\n",
      "Epoch 299, Loss: 0.08803700655698776, Final Batch Loss: 0.00958886370062828\n",
      "Epoch 300, Loss: 0.2695946656167507, Final Batch Loss: 0.1561630815267563\n",
      "Epoch 301, Loss: 0.12982844561338425, Final Batch Loss: 0.006672818213701248\n",
      "Epoch 302, Loss: 0.20601965487003326, Final Batch Loss: 0.09922249615192413\n",
      "Epoch 303, Loss: 0.1016021715477109, Final Batch Loss: 0.008034166879951954\n",
      "Epoch 304, Loss: 0.10450973734259605, Final Batch Loss: 0.02426343597471714\n",
      "Epoch 305, Loss: 0.10570468101650476, Final Batch Loss: 0.010776949115097523\n",
      "Epoch 306, Loss: 0.09000385273247957, Final Batch Loss: 0.010364723391830921\n",
      "Epoch 307, Loss: 0.07833370706066489, Final Batch Loss: 0.006787055637687445\n",
      "Epoch 308, Loss: 0.10887258313596249, Final Batch Loss: 0.019013458862900734\n",
      "Epoch 309, Loss: 0.24422847107052803, Final Batch Loss: 0.1652359664440155\n",
      "Epoch 310, Loss: 0.1342563657090068, Final Batch Loss: 0.00709701981395483\n",
      "Epoch 311, Loss: 0.11060059443116188, Final Batch Loss: 0.019961107522249222\n",
      "Epoch 312, Loss: 0.07833784213289618, Final Batch Loss: 0.006932870950549841\n",
      "Epoch 313, Loss: 0.12890148255974054, Final Batch Loss: 0.011168313212692738\n",
      "Epoch 314, Loss: 0.07196274399757385, Final Batch Loss: 0.014378873631358147\n",
      "Epoch 315, Loss: 0.28609638195484877, Final Batch Loss: 0.2175620198249817\n",
      "Epoch 316, Loss: 0.11635347083210945, Final Batch Loss: 0.016997046768665314\n",
      "Epoch 317, Loss: 0.08892213646322489, Final Batch Loss: 0.013872548006474972\n",
      "Epoch 318, Loss: 0.10972313210368156, Final Batch Loss: 0.02498011104762554\n",
      "Epoch 319, Loss: 0.08491085516288877, Final Batch Loss: 0.006826561409980059\n",
      "Epoch 320, Loss: 0.1107815820723772, Final Batch Loss: 0.0019953157752752304\n",
      "Epoch 321, Loss: 0.11127537442371249, Final Batch Loss: 0.007070792373269796\n",
      "Epoch 322, Loss: 0.05902196723036468, Final Batch Loss: 0.0013406656216830015\n",
      "Epoch 323, Loss: 0.15044187754392624, Final Batch Loss: 0.01955406367778778\n",
      "Epoch 324, Loss: 0.1033379235304892, Final Batch Loss: 0.0068369642831385136\n",
      "Epoch 325, Loss: 0.09156130813062191, Final Batch Loss: 0.013591773808002472\n",
      "Epoch 326, Loss: 0.09417809289880097, Final Batch Loss: 0.0033366840798407793\n",
      "Epoch 327, Loss: 0.12222559191286564, Final Batch Loss: 0.023109281435608864\n",
      "Epoch 328, Loss: 0.20506895519793034, Final Batch Loss: 0.10839583724737167\n",
      "Epoch 329, Loss: 0.28162146732211113, Final Batch Loss: 0.17894810438156128\n",
      "Epoch 330, Loss: 0.2044890560209751, Final Batch Loss: 0.09337302297353745\n",
      "Epoch 331, Loss: 0.16285127773880959, Final Batch Loss: 0.04273466393351555\n",
      "Epoch 332, Loss: 0.17046432383358479, Final Batch Loss: 0.03067261539399624\n",
      "Epoch 333, Loss: 0.13400861842092127, Final Batch Loss: 0.0009923711186274886\n",
      "Epoch 334, Loss: 0.10142081417143345, Final Batch Loss: 0.018819276243448257\n",
      "Epoch 335, Loss: 0.12018327228724957, Final Batch Loss: 0.0033565256744623184\n",
      "Epoch 336, Loss: 0.10565155372023582, Final Batch Loss: 0.0024963803589344025\n",
      "Epoch 337, Loss: 0.11620654538273811, Final Batch Loss: 0.012555275112390518\n",
      "Epoch 338, Loss: 0.10035128332674503, Final Batch Loss: 0.02140743099153042\n",
      "Epoch 339, Loss: 0.1414303109049797, Final Batch Loss: 0.03201457858085632\n",
      "Epoch 340, Loss: 0.08212037291377783, Final Batch Loss: 0.013132662512362003\n",
      "Epoch 341, Loss: 0.09531230619177222, Final Batch Loss: 0.004769688006490469\n",
      "Epoch 342, Loss: 0.15614613145589828, Final Batch Loss: 0.05201134830713272\n",
      "Epoch 343, Loss: 0.08999758027493954, Final Batch Loss: 0.012302570044994354\n",
      "Epoch 344, Loss: 0.07797899888828397, Final Batch Loss: 0.005910490173846483\n",
      "Epoch 345, Loss: 0.09333055932074785, Final Batch Loss: 0.014329844154417515\n",
      "Epoch 346, Loss: 0.1394946975633502, Final Batch Loss: 0.013618840835988522\n",
      "Epoch 347, Loss: 0.1101976577192545, Final Batch Loss: 0.01971583627164364\n",
      "Epoch 348, Loss: 0.0802594949491322, Final Batch Loss: 0.004520202521234751\n",
      "Epoch 349, Loss: 0.10120558738708496, Final Batch Loss: 0.007927559316158295\n",
      "Epoch 350, Loss: 0.07352921273559332, Final Batch Loss: 0.009286073967814445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351, Loss: 0.15280137583613396, Final Batch Loss: 0.07003853470087051\n",
      "Epoch 352, Loss: 0.0944706650916487, Final Batch Loss: 0.0019958356861025095\n",
      "Epoch 353, Loss: 0.12757786829024553, Final Batch Loss: 0.014830009080469608\n",
      "Epoch 354, Loss: 0.24963472411036491, Final Batch Loss: 0.14696355164051056\n",
      "Epoch 355, Loss: 0.1513015404343605, Final Batch Loss: 0.044184695929288864\n",
      "Epoch 356, Loss: 0.11791790090501308, Final Batch Loss: 0.030942440032958984\n",
      "Epoch 357, Loss: 0.0894550159573555, Final Batch Loss: 0.01679830253124237\n",
      "Epoch 358, Loss: 0.06986518716439605, Final Batch Loss: 0.005267362575978041\n",
      "Epoch 359, Loss: 0.13744144514203072, Final Batch Loss: 0.059520475566387177\n",
      "Epoch 360, Loss: 0.2888565883040428, Final Batch Loss: 0.22814173996448517\n",
      "Epoch 361, Loss: 0.1306306030601263, Final Batch Loss: 0.021023664623498917\n",
      "Epoch 362, Loss: 0.07437248580390587, Final Batch Loss: 0.0006309492164291441\n",
      "Epoch 363, Loss: 0.11347543820738792, Final Batch Loss: 0.012810468673706055\n",
      "Epoch 364, Loss: 0.05652882670983672, Final Batch Loss: 0.00533423712477088\n",
      "Epoch 365, Loss: 0.113050427287817, Final Batch Loss: 0.018799979239702225\n",
      "Epoch 366, Loss: 0.11958414688706398, Final Batch Loss: 0.024862421676516533\n",
      "Epoch 367, Loss: 0.14707965776324272, Final Batch Loss: 0.0708913803100586\n",
      "Epoch 368, Loss: 0.094499746337533, Final Batch Loss: 0.02828601747751236\n",
      "Epoch 369, Loss: 0.17601582035422325, Final Batch Loss: 0.09697949886322021\n",
      "Epoch 370, Loss: 0.09869568794965744, Final Batch Loss: 0.00692899152636528\n",
      "Epoch 371, Loss: 0.15441327448934317, Final Batch Loss: 0.014163817279040813\n",
      "Epoch 372, Loss: 0.16482089832425117, Final Batch Loss: 0.006037775427103043\n",
      "Epoch 373, Loss: 0.13771579507738352, Final Batch Loss: 0.010169160552322865\n",
      "Epoch 374, Loss: 0.08553944574669003, Final Batch Loss: 0.0012107999064028263\n",
      "Epoch 375, Loss: 0.06180136790499091, Final Batch Loss: 0.0055224779061973095\n",
      "Epoch 376, Loss: 0.0996622834354639, Final Batch Loss: 0.00462193600833416\n",
      "Epoch 377, Loss: 0.09824289660900831, Final Batch Loss: 0.01045986171811819\n",
      "Epoch 378, Loss: 0.11880262941122055, Final Batch Loss: 0.035402849316596985\n",
      "Epoch 379, Loss: 0.12047221511602402, Final Batch Loss: 0.03791607543826103\n",
      "Epoch 380, Loss: 0.10487439297139645, Final Batch Loss: 0.024601388722658157\n",
      "Epoch 381, Loss: 0.09162358799949288, Final Batch Loss: 0.001262953970581293\n",
      "Epoch 382, Loss: 0.12081233784556389, Final Batch Loss: 0.024401769042015076\n",
      "Epoch 383, Loss: 0.08505336311645806, Final Batch Loss: 0.0019388061482459307\n",
      "Epoch 384, Loss: 0.07616525166667998, Final Batch Loss: 0.0033656491432338953\n",
      "Epoch 385, Loss: 0.09306083805859089, Final Batch Loss: 0.028512900695204735\n",
      "Epoch 386, Loss: 0.09722060663625598, Final Batch Loss: 0.00691652437672019\n",
      "Epoch 387, Loss: 0.11243356205523014, Final Batch Loss: 0.017579933628439903\n",
      "Epoch 388, Loss: 0.3762100003659725, Final Batch Loss: 0.30392834544181824\n",
      "Epoch 389, Loss: 0.07881484413519502, Final Batch Loss: 0.006911479402333498\n",
      "Epoch 390, Loss: 0.10287206806242466, Final Batch Loss: 0.01807115040719509\n",
      "Epoch 391, Loss: 0.0904878880828619, Final Batch Loss: 0.017030728980898857\n",
      "Epoch 392, Loss: 0.06902227771934122, Final Batch Loss: 0.001948556280694902\n",
      "Epoch 393, Loss: 0.07657037395983934, Final Batch Loss: 0.005592220462858677\n",
      "Epoch 394, Loss: 0.08970588445663452, Final Batch Loss: 0.010519690811634064\n",
      "Epoch 395, Loss: 0.08070164057426155, Final Batch Loss: 0.0024157154839485884\n",
      "Epoch 396, Loss: 0.10837451461702585, Final Batch Loss: 0.04082382842898369\n",
      "Epoch 397, Loss: 0.13920150324702263, Final Batch Loss: 0.07186952978372574\n",
      "Epoch 398, Loss: 0.06408876099158078, Final Batch Loss: 0.0012214231537654996\n",
      "Epoch 399, Loss: 0.09747320134192705, Final Batch Loss: 0.0096747362986207\n",
      "Epoch 400, Loss: 0.08430060744285583, Final Batch Loss: 0.009226467460393906\n",
      "Epoch 401, Loss: 0.0763449789956212, Final Batch Loss: 0.013128009624779224\n",
      "Epoch 402, Loss: 0.32081788033246994, Final Batch Loss: 0.24521633982658386\n",
      "Epoch 403, Loss: 0.06574542913585901, Final Batch Loss: 0.008697847835719585\n",
      "Epoch 404, Loss: 0.09781389497220516, Final Batch Loss: 0.01367977075278759\n",
      "Epoch 405, Loss: 0.10874172206968069, Final Batch Loss: 0.015493038110435009\n",
      "Epoch 406, Loss: 0.09850915288552642, Final Batch Loss: 0.005876300390809774\n",
      "Epoch 407, Loss: 0.05610661581158638, Final Batch Loss: 0.00435158796608448\n",
      "Epoch 408, Loss: 0.07118164654821157, Final Batch Loss: 0.0012689130380749702\n",
      "Epoch 409, Loss: 0.09296972490847111, Final Batch Loss: 0.023748621344566345\n",
      "Epoch 410, Loss: 0.05818627402186394, Final Batch Loss: 0.0051647815853357315\n",
      "Epoch 411, Loss: 0.08157949522137642, Final Batch Loss: 0.01216457225382328\n",
      "Epoch 412, Loss: 0.08243442326784134, Final Batch Loss: 0.011556724086403847\n",
      "Epoch 413, Loss: 0.27750428579747677, Final Batch Loss: 0.21044206619262695\n",
      "Epoch 414, Loss: 0.07666314137168229, Final Batch Loss: 0.0032998614478856325\n",
      "Epoch 415, Loss: 0.1171159315854311, Final Batch Loss: 0.008045544847846031\n",
      "Epoch 416, Loss: 0.16357823461294174, Final Batch Loss: 0.046641625463962555\n",
      "Epoch 417, Loss: 0.09384849108755589, Final Batch Loss: 0.002191370353102684\n",
      "Epoch 418, Loss: 0.09948021080344915, Final Batch Loss: 0.04053732752799988\n",
      "Epoch 419, Loss: 0.15744400769472122, Final Batch Loss: 0.08493047952651978\n",
      "Epoch 420, Loss: 0.07615342829376459, Final Batch Loss: 0.009747035801410675\n",
      "Epoch 421, Loss: 0.0717825647443533, Final Batch Loss: 0.002032531425356865\n",
      "Epoch 422, Loss: 0.1044068019837141, Final Batch Loss: 0.04558819532394409\n",
      "Epoch 423, Loss: 0.09240327775478363, Final Batch Loss: 0.004663553088903427\n",
      "Epoch 424, Loss: 0.08968207589350641, Final Batch Loss: 0.0032792796846479177\n",
      "Epoch 425, Loss: 0.0705890841782093, Final Batch Loss: 0.017134422436356544\n",
      "Epoch 426, Loss: 0.09937148913741112, Final Batch Loss: 0.02831362746655941\n",
      "Epoch 427, Loss: 0.07507635373622179, Final Batch Loss: 0.01029044296592474\n",
      "Epoch 428, Loss: 0.2919627819210291, Final Batch Loss: 0.23231352865695953\n",
      "Epoch 429, Loss: 0.08388621732592583, Final Batch Loss: 0.013773755170404911\n",
      "Epoch 430, Loss: 0.10426907148212194, Final Batch Loss: 0.03587009012699127\n",
      "Epoch 431, Loss: 0.09379326365888119, Final Batch Loss: 0.013825662434101105\n",
      "Epoch 432, Loss: 0.07579482905566692, Final Batch Loss: 0.0085066519677639\n",
      "Epoch 433, Loss: 0.1443125233054161, Final Batch Loss: 0.07175010442733765\n",
      "Epoch 434, Loss: 0.09046228975057602, Final Batch Loss: 0.008822288364171982\n",
      "Epoch 435, Loss: 0.044166671112179756, Final Batch Loss: 0.005427638068795204\n",
      "Epoch 436, Loss: 0.06275166803970933, Final Batch Loss: 0.004601348657160997\n",
      "Epoch 437, Loss: 0.07325388956815004, Final Batch Loss: 0.003244132734835148\n",
      "Epoch 438, Loss: 0.0812363550066948, Final Batch Loss: 0.018077395856380463\n",
      "Epoch 439, Loss: 0.07186934328638017, Final Batch Loss: 0.003815654432401061\n",
      "Epoch 440, Loss: 0.2524049710482359, Final Batch Loss: 0.20335498452186584\n",
      "Epoch 441, Loss: 0.07153920130804181, Final Batch Loss: 0.0032446985132992268\n",
      "Epoch 442, Loss: 0.08407192397862673, Final Batch Loss: 0.014944445341825485\n",
      "Epoch 443, Loss: 0.06569004524499178, Final Batch Loss: 0.0034633921459317207\n",
      "Epoch 444, Loss: 0.08442146936431527, Final Batch Loss: 0.004254378844052553\n",
      "Epoch 445, Loss: 0.07280034106224775, Final Batch Loss: 0.014067751355469227\n",
      "Epoch 446, Loss: 0.052613707550335675, Final Batch Loss: 0.0008434935589320958\n",
      "Epoch 447, Loss: 0.14715399779379368, Final Batch Loss: 0.08504582941532135\n",
      "Epoch 448, Loss: 0.05734275747090578, Final Batch Loss: 0.0016009816899895668\n",
      "Epoch 449, Loss: 0.1420483272522688, Final Batch Loss: 0.07038070261478424\n",
      "Epoch 450, Loss: 0.09007805213332176, Final Batch Loss: 0.02491062507033348\n",
      "Epoch 451, Loss: 0.09489586157724261, Final Batch Loss: 0.004888508003205061\n",
      "Epoch 452, Loss: 0.1585923545062542, Final Batch Loss: 0.05540074035525322\n",
      "Epoch 453, Loss: 0.15631631761789322, Final Batch Loss: 0.06836871802806854\n",
      "Epoch 454, Loss: 0.08269631769508123, Final Batch Loss: 0.007032389752566814\n",
      "Epoch 455, Loss: 0.10917075350880623, Final Batch Loss: 0.028222285211086273\n",
      "Epoch 456, Loss: 0.13453546538949013, Final Batch Loss: 0.0029200762510299683\n",
      "Epoch 457, Loss: 0.1574962753802538, Final Batch Loss: 0.04544678330421448\n",
      "Epoch 458, Loss: 0.08428447123151273, Final Batch Loss: 0.0016254334477707744\n",
      "Epoch 459, Loss: 0.05148298665881157, Final Batch Loss: 0.00943578127771616\n",
      "Epoch 460, Loss: 0.07872247323393822, Final Batch Loss: 0.012529384344816208\n",
      "Epoch 461, Loss: 0.058745786314830184, Final Batch Loss: 0.00375295034609735\n",
      "Epoch 462, Loss: 0.2657840559259057, Final Batch Loss: 0.23396697640419006\n",
      "Epoch 463, Loss: 0.07523428183048964, Final Batch Loss: 0.007721771486103535\n",
      "Epoch 464, Loss: 0.2790620028972626, Final Batch Loss: 0.22999829053878784\n",
      "Epoch 465, Loss: 0.1265395414084196, Final Batch Loss: 0.08228462189435959\n",
      "Epoch 466, Loss: 0.10374920815229416, Final Batch Loss: 0.022307351231575012\n",
      "Epoch 467, Loss: 0.1437313947826624, Final Batch Loss: 0.020472826436161995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468, Loss: 0.10108701745048165, Final Batch Loss: 0.002932580653578043\n",
      "Epoch 469, Loss: 0.11402864940464497, Final Batch Loss: 0.028007442131638527\n",
      "Epoch 470, Loss: 0.08178546465933323, Final Batch Loss: 0.01751861348748207\n",
      "Epoch 471, Loss: 0.08843241259455681, Final Batch Loss: 0.019337279722094536\n",
      "Epoch 472, Loss: 0.11709127947688103, Final Batch Loss: 0.06860532611608505\n",
      "Epoch 473, Loss: 0.09719687141478062, Final Batch Loss: 0.018913017585873604\n",
      "Epoch 474, Loss: 0.08286744356155396, Final Batch Loss: 0.027579110115766525\n",
      "Epoch 475, Loss: 0.06130481942091137, Final Batch Loss: 0.0014423715183511376\n",
      "Epoch 476, Loss: 0.05355798173695803, Final Batch Loss: 0.00318694394081831\n",
      "Epoch 477, Loss: 0.06863703392446041, Final Batch Loss: 0.008746970444917679\n",
      "Epoch 478, Loss: 0.0794019689783454, Final Batch Loss: 0.010382859967648983\n",
      "Epoch 479, Loss: 0.1856946237385273, Final Batch Loss: 0.14203889667987823\n",
      "Epoch 480, Loss: 0.06313694827258587, Final Batch Loss: 0.011094504967331886\n",
      "Epoch 481, Loss: 0.07177641242742538, Final Batch Loss: 0.03534918650984764\n",
      "Epoch 482, Loss: 0.060525002889335155, Final Batch Loss: 0.0020797597244381905\n",
      "Epoch 483, Loss: 0.09248897712677717, Final Batch Loss: 0.009362940676510334\n",
      "Epoch 484, Loss: 0.07526177633553743, Final Batch Loss: 0.009010103531181812\n",
      "Epoch 485, Loss: 0.10092213656753302, Final Batch Loss: 0.011249317787587643\n",
      "Epoch 486, Loss: 0.05424125166609883, Final Batch Loss: 0.004580362234264612\n",
      "Epoch 487, Loss: 0.050264615565538406, Final Batch Loss: 0.005862075835466385\n",
      "Epoch 488, Loss: 0.07241668086498976, Final Batch Loss: 0.008414116688072681\n",
      "Epoch 489, Loss: 0.08785719703882933, Final Batch Loss: 0.013109802268445492\n",
      "Epoch 490, Loss: 0.05282761692069471, Final Batch Loss: 0.003707757918164134\n",
      "Epoch 491, Loss: 0.07951970584690571, Final Batch Loss: 0.029981691390275955\n",
      "Epoch 492, Loss: 0.07409949460998178, Final Batch Loss: 0.006106663960963488\n",
      "Epoch 493, Loss: 0.1705815838649869, Final Batch Loss: 0.12743732333183289\n",
      "Epoch 494, Loss: 0.3391104154288769, Final Batch Loss: 0.3029260039329529\n",
      "Epoch 495, Loss: 0.08034791704267263, Final Batch Loss: 0.01344299502670765\n",
      "Epoch 496, Loss: 0.06122051831334829, Final Batch Loss: 0.0027571329846978188\n",
      "Epoch 497, Loss: 0.06181290606036782, Final Batch Loss: 0.0032458570785820484\n",
      "Epoch 498, Loss: 0.0747880318085663, Final Batch Loss: 0.0008694060961715877\n",
      "Epoch 499, Loss: 0.08260498940944672, Final Batch Loss: 0.018068335950374603\n",
      "Epoch 500, Loss: 0.083313531242311, Final Batch Loss: 0.014594626612961292\n",
      "Epoch 501, Loss: 0.3067730441689491, Final Batch Loss: 0.25962644815444946\n",
      "Epoch 502, Loss: 0.17306744307279587, Final Batch Loss: 0.09644711017608643\n",
      "Epoch 503, Loss: 0.08581789024174213, Final Batch Loss: 0.010199541226029396\n",
      "Epoch 504, Loss: 0.08661563834175467, Final Batch Loss: 0.004042639862746\n",
      "Epoch 505, Loss: 0.08868626307230443, Final Batch Loss: 0.0017000044463202357\n",
      "Epoch 506, Loss: 0.3864583969116211, Final Batch Loss: 0.3254987299442291\n",
      "Epoch 507, Loss: 0.06600900739431381, Final Batch Loss: 0.01414400339126587\n",
      "Epoch 508, Loss: 0.05912088230252266, Final Batch Loss: 0.006779825314879417\n",
      "Epoch 509, Loss: 0.10170630738139153, Final Batch Loss: 0.017856499180197716\n",
      "Epoch 510, Loss: 0.1741035282611847, Final Batch Loss: 0.07844039797782898\n",
      "Epoch 511, Loss: 0.10364870121702552, Final Batch Loss: 0.002962313126772642\n",
      "Epoch 512, Loss: 0.11225981265306473, Final Batch Loss: 0.0483849011361599\n",
      "Epoch 513, Loss: 0.08487098291516304, Final Batch Loss: 0.02571173943579197\n",
      "Epoch 514, Loss: 0.16159903071820736, Final Batch Loss: 0.10899993032217026\n",
      "Epoch 515, Loss: 0.08375044167041779, Final Batch Loss: 0.0034156516194343567\n",
      "Epoch 516, Loss: 0.08422883786261082, Final Batch Loss: 0.025397615507245064\n",
      "Epoch 517, Loss: 0.09763078717514873, Final Batch Loss: 0.005609467159956694\n",
      "Epoch 518, Loss: 0.10258801374584436, Final Batch Loss: 0.009511821903288364\n",
      "Epoch 519, Loss: 0.19395231641829014, Final Batch Loss: 0.11948473751544952\n",
      "Epoch 520, Loss: 0.2293605376034975, Final Batch Loss: 0.19621171057224274\n",
      "Epoch 521, Loss: 0.07003774878103286, Final Batch Loss: 0.001612538588233292\n",
      "Epoch 522, Loss: 0.058346237521618605, Final Batch Loss: 0.00399194797500968\n",
      "Epoch 523, Loss: 0.06226143357343972, Final Batch Loss: 0.0019201275426894426\n",
      "Epoch 524, Loss: 0.061523656360805035, Final Batch Loss: 0.018029682338237762\n",
      "Epoch 525, Loss: 0.056481297593563795, Final Batch Loss: 0.003967854660004377\n",
      "Epoch 526, Loss: 0.08863821905106306, Final Batch Loss: 0.03297474980354309\n",
      "Epoch 527, Loss: 0.06559747736901045, Final Batch Loss: 0.008965951390564442\n",
      "Epoch 528, Loss: 0.058039771392941475, Final Batch Loss: 0.006637636572122574\n",
      "Epoch 529, Loss: 0.06534610968083143, Final Batch Loss: 0.01294290367513895\n",
      "Epoch 530, Loss: 0.20098952110856771, Final Batch Loss: 0.1745552122592926\n",
      "Epoch 531, Loss: 0.07006308855488896, Final Batch Loss: 0.005353002343326807\n",
      "Epoch 532, Loss: 0.048744543455541134, Final Batch Loss: 0.005668031983077526\n",
      "Epoch 533, Loss: 0.17778913117945194, Final Batch Loss: 0.11197710037231445\n",
      "Epoch 534, Loss: 0.15649658907204866, Final Batch Loss: 0.10488128662109375\n",
      "Epoch 535, Loss: 0.09224696084856987, Final Batch Loss: 0.013407198712229729\n",
      "Epoch 536, Loss: 0.04559229081496596, Final Batch Loss: 0.002477919217199087\n",
      "Epoch 537, Loss: 0.05382241867482662, Final Batch Loss: 0.0060642920434474945\n",
      "Epoch 538, Loss: 0.04960839101113379, Final Batch Loss: 0.0018722827080637217\n",
      "Epoch 539, Loss: 0.05573139723856002, Final Batch Loss: 0.001682629925198853\n",
      "Epoch 540, Loss: 0.06257860222831368, Final Batch Loss: 0.004604729358106852\n",
      "Epoch 541, Loss: 0.08423194848001003, Final Batch Loss: 0.03465324267745018\n",
      "Epoch 542, Loss: 0.07333599147386849, Final Batch Loss: 0.0021694146562367678\n",
      "Epoch 543, Loss: 0.07334089651703835, Final Batch Loss: 0.014333555474877357\n",
      "Epoch 544, Loss: 0.04954021656885743, Final Batch Loss: 0.003964947070926428\n",
      "Epoch 545, Loss: 0.06820621807128191, Final Batch Loss: 0.009554113261401653\n",
      "Epoch 546, Loss: 0.05624764505773783, Final Batch Loss: 0.0011905571445822716\n",
      "Epoch 547, Loss: 0.06047978671267629, Final Batch Loss: 0.006110156420618296\n",
      "Epoch 548, Loss: 0.0652143876068294, Final Batch Loss: 0.009438780136406422\n",
      "Epoch 549, Loss: 0.07753987424075603, Final Batch Loss: 0.04171197488903999\n",
      "Epoch 550, Loss: 0.10744310915470123, Final Batch Loss: 0.03704667463898659\n",
      "Epoch 551, Loss: 0.11038726940751076, Final Batch Loss: 0.0312797836959362\n",
      "Epoch 552, Loss: 0.08096152450889349, Final Batch Loss: 0.012469800189137459\n",
      "Epoch 553, Loss: 0.03544709482230246, Final Batch Loss: 0.0014583461452275515\n",
      "Epoch 554, Loss: 0.06837947235908359, Final Batch Loss: 0.0007877567550167441\n",
      "Epoch 555, Loss: 0.05224156612530351, Final Batch Loss: 0.006440334487706423\n",
      "Epoch 556, Loss: 0.06221291981637478, Final Batch Loss: 0.005643323063850403\n",
      "Epoch 557, Loss: 0.05079011293128133, Final Batch Loss: 0.0015175086446106434\n",
      "Epoch 558, Loss: 0.07910934742540121, Final Batch Loss: 0.01419068593531847\n",
      "Epoch 559, Loss: 0.0419652359560132, Final Batch Loss: 0.0044546956196427345\n",
      "Epoch 560, Loss: 0.07483319682069123, Final Batch Loss: 0.003218732075765729\n",
      "Epoch 561, Loss: 0.07540862634778023, Final Batch Loss: 0.00825495831668377\n",
      "Epoch 562, Loss: 0.054830804001539946, Final Batch Loss: 0.003231657203286886\n",
      "Epoch 563, Loss: 0.05166906863451004, Final Batch Loss: 0.004532111808657646\n",
      "Epoch 564, Loss: 0.06436526007018983, Final Batch Loss: 0.0013562047388404608\n",
      "Epoch 565, Loss: 0.050230949418619275, Final Batch Loss: 0.0030070750508457422\n",
      "Epoch 566, Loss: 0.039772608783096075, Final Batch Loss: 0.004476225469261408\n",
      "Epoch 567, Loss: 0.1663572285324335, Final Batch Loss: 0.09873392432928085\n",
      "Epoch 568, Loss: 0.047518444480374455, Final Batch Loss: 0.0030541468877345324\n",
      "Epoch 569, Loss: 0.07331058755517006, Final Batch Loss: 0.011794978752732277\n",
      "Epoch 570, Loss: 0.3029409572482109, Final Batch Loss: 0.22413234412670135\n",
      "Epoch 571, Loss: 0.10046552307903767, Final Batch Loss: 0.005477851256728172\n",
      "Epoch 572, Loss: 0.0688301008194685, Final Batch Loss: 0.008279114961624146\n",
      "Epoch 573, Loss: 0.06668531335890293, Final Batch Loss: 0.01869513839483261\n",
      "Epoch 574, Loss: 0.07324886228889227, Final Batch Loss: 0.011922125704586506\n",
      "Epoch 575, Loss: 0.07257845043204725, Final Batch Loss: 0.003831477602943778\n",
      "Epoch 576, Loss: 0.06311586033552885, Final Batch Loss: 0.03213655203580856\n",
      "Epoch 577, Loss: 0.0759268319234252, Final Batch Loss: 0.011335424147546291\n",
      "Epoch 578, Loss: 0.24457101710140705, Final Batch Loss: 0.19131535291671753\n",
      "Epoch 579, Loss: 0.07331547955982387, Final Batch Loss: 0.0019566926639527082\n",
      "Epoch 580, Loss: 0.16117435600608587, Final Batch Loss: 0.10365933179855347\n",
      "Epoch 581, Loss: 0.0916754174977541, Final Batch Loss: 0.03896912932395935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582, Loss: 0.068769461940974, Final Batch Loss: 0.006756128277629614\n",
      "Epoch 583, Loss: 0.06836392637342215, Final Batch Loss: 0.012071079574525356\n",
      "Epoch 584, Loss: 0.08009969000704587, Final Batch Loss: 0.0038839795161038637\n",
      "Epoch 585, Loss: 0.06619175523519516, Final Batch Loss: 0.008521024137735367\n",
      "Epoch 586, Loss: 0.08964310400187969, Final Batch Loss: 0.028480863198637962\n",
      "Epoch 587, Loss: 0.04437769646756351, Final Batch Loss: 0.0029819838237017393\n",
      "Epoch 588, Loss: 0.17938430234789848, Final Batch Loss: 0.13799917697906494\n",
      "Epoch 589, Loss: 0.060571314534172416, Final Batch Loss: 0.0034794227685779333\n",
      "Epoch 590, Loss: 0.0510669257491827, Final Batch Loss: 0.008095338940620422\n",
      "Epoch 591, Loss: 0.1301024742424488, Final Batch Loss: 0.04910481348633766\n",
      "Epoch 592, Loss: 0.060164046473801136, Final Batch Loss: 0.0023864898830652237\n",
      "Epoch 593, Loss: 0.25501637905836105, Final Batch Loss: 0.20362503826618195\n",
      "Epoch 594, Loss: 0.07514921203255653, Final Batch Loss: 0.011048788204789162\n",
      "Epoch 595, Loss: 0.051226161420345306, Final Batch Loss: 0.008976401761174202\n",
      "Epoch 596, Loss: 0.07316882396116853, Final Batch Loss: 0.005451955366879702\n",
      "Epoch 597, Loss: 0.05981780181173235, Final Batch Loss: 0.00143474864307791\n",
      "Epoch 598, Loss: 0.062458153115585446, Final Batch Loss: 0.002808043034747243\n",
      "Epoch 599, Loss: 0.19151131063699722, Final Batch Loss: 0.13558714091777802\n",
      "Epoch 600, Loss: 0.06425403617322445, Final Batch Loss: 0.02993781864643097\n",
      "Epoch 601, Loss: 0.03912257682532072, Final Batch Loss: 0.004345430061221123\n",
      "Epoch 602, Loss: 0.06024010805413127, Final Batch Loss: 0.003906921949237585\n",
      "Epoch 603, Loss: 0.0591410924680531, Final Batch Loss: 0.004507152829319239\n",
      "Epoch 604, Loss: 0.05204769968986511, Final Batch Loss: 0.005651015788316727\n",
      "Epoch 605, Loss: 0.05810617655515671, Final Batch Loss: 0.008154332637786865\n",
      "Epoch 606, Loss: 0.10557226557284594, Final Batch Loss: 0.07344669103622437\n",
      "Epoch 607, Loss: 0.04238269804045558, Final Batch Loss: 0.0006113150157034397\n",
      "Epoch 608, Loss: 0.04632641852367669, Final Batch Loss: 0.0017082906560972333\n",
      "Epoch 609, Loss: 0.27028643526136875, Final Batch Loss: 0.21042269468307495\n",
      "Epoch 610, Loss: 0.0832323762588203, Final Batch Loss: 0.034165769815444946\n",
      "Epoch 611, Loss: 0.05783504026476294, Final Batch Loss: 0.0010533347958698869\n",
      "Epoch 612, Loss: 0.034572928911074996, Final Batch Loss: 0.0034423305187374353\n",
      "Epoch 613, Loss: 0.04895281349308789, Final Batch Loss: 0.002700393320992589\n",
      "Epoch 614, Loss: 0.08207702822983265, Final Batch Loss: 0.004116722848266363\n",
      "Epoch 615, Loss: 0.05755682860035449, Final Batch Loss: 0.0009851754875853658\n",
      "Epoch 616, Loss: 0.05960243474692106, Final Batch Loss: 0.03641130030155182\n",
      "Epoch 617, Loss: 0.06302808818873018, Final Batch Loss: 0.001346504664979875\n",
      "Epoch 618, Loss: 0.051060895435512066, Final Batch Loss: 0.004123159684240818\n",
      "Epoch 619, Loss: 0.04807851277291775, Final Batch Loss: 0.005551870912313461\n",
      "Epoch 620, Loss: 0.05905046290718019, Final Batch Loss: 0.0012140737380832434\n",
      "Epoch 621, Loss: 0.06652250420302153, Final Batch Loss: 0.01251325011253357\n",
      "Epoch 622, Loss: 0.05027680494822562, Final Batch Loss: 0.008070968091487885\n",
      "Epoch 623, Loss: 0.03434090502560139, Final Batch Loss: 0.0015230681747198105\n",
      "Epoch 624, Loss: 0.04587068420369178, Final Batch Loss: 0.0009722058894112706\n",
      "Epoch 625, Loss: 0.040207108948379755, Final Batch Loss: 0.005005592945963144\n",
      "Epoch 626, Loss: 0.05831610760651529, Final Batch Loss: 0.003267802996560931\n",
      "Epoch 627, Loss: 0.04482224956154823, Final Batch Loss: 0.001961713656783104\n",
      "Epoch 628, Loss: 0.02721559803467244, Final Batch Loss: 0.001350733800791204\n",
      "Epoch 629, Loss: 0.046880273963324726, Final Batch Loss: 0.0014025958953425288\n",
      "Epoch 630, Loss: 0.03945242828922346, Final Batch Loss: 0.0006390030612237751\n",
      "Epoch 631, Loss: 0.04636320099234581, Final Batch Loss: 0.002247230149805546\n",
      "Epoch 632, Loss: 0.04568302258849144, Final Batch Loss: 0.0022166986018419266\n",
      "Epoch 633, Loss: 0.08564107865095139, Final Batch Loss: 0.04395623132586479\n",
      "Epoch 634, Loss: 0.047891136433463544, Final Batch Loss: 0.0005127938347868621\n",
      "Epoch 635, Loss: 0.0474521117284894, Final Batch Loss: 0.0011544348672032356\n",
      "Epoch 636, Loss: 0.0419770278967917, Final Batch Loss: 0.004174471367150545\n",
      "Epoch 637, Loss: 0.05036755185574293, Final Batch Loss: 0.009510728530585766\n",
      "Epoch 638, Loss: 0.0552531557623297, Final Batch Loss: 0.0010946004185825586\n",
      "Epoch 639, Loss: 0.07003672700375319, Final Batch Loss: 0.02059006132185459\n",
      "Epoch 640, Loss: 0.05260200146585703, Final Batch Loss: 0.0051706451922655106\n",
      "Epoch 641, Loss: 0.08526252745650709, Final Batch Loss: 0.0012868258636444807\n",
      "Epoch 642, Loss: 0.04090469889342785, Final Batch Loss: 0.005303375422954559\n",
      "Epoch 643, Loss: 0.05470077320933342, Final Batch Loss: 0.008788754232227802\n",
      "Epoch 644, Loss: 0.058555259834975004, Final Batch Loss: 0.0074322582222521305\n",
      "Epoch 645, Loss: 0.1652364106848836, Final Batch Loss: 0.13546042144298553\n",
      "Epoch 646, Loss: 0.051237395498901606, Final Batch Loss: 0.005679094698280096\n",
      "Epoch 647, Loss: 0.10513295675627887, Final Batch Loss: 0.0032108190935105085\n",
      "Epoch 648, Loss: 0.6001373566687107, Final Batch Loss: 0.49086064100265503\n",
      "Epoch 649, Loss: 0.14105081150773913, Final Batch Loss: 0.0017302852356806397\n",
      "Epoch 650, Loss: 0.09550769464112818, Final Batch Loss: 0.003109900513663888\n",
      "Epoch 651, Loss: 0.06656886148266494, Final Batch Loss: 0.002807126147672534\n",
      "Epoch 652, Loss: 0.07101122289896011, Final Batch Loss: 0.022028202190995216\n",
      "Epoch 653, Loss: 0.0422527608461678, Final Batch Loss: 0.0025344318710267544\n",
      "Epoch 654, Loss: 0.07753649540245533, Final Batch Loss: 0.035916127264499664\n",
      "Epoch 655, Loss: 0.0781029462814331, Final Batch Loss: 0.02517278678715229\n",
      "Epoch 656, Loss: 0.05043903551995754, Final Batch Loss: 0.005173774436116219\n",
      "Epoch 657, Loss: 0.08104962855577469, Final Batch Loss: 0.027371183037757874\n",
      "Epoch 658, Loss: 0.03629108867608011, Final Batch Loss: 0.003148856805637479\n",
      "Epoch 659, Loss: 0.058359513990581036, Final Batch Loss: 0.006660382263362408\n",
      "Epoch 660, Loss: 0.066678361967206, Final Batch Loss: 0.03896337375044823\n",
      "Epoch 661, Loss: 0.04778034391347319, Final Batch Loss: 0.0010904759401455522\n",
      "Epoch 662, Loss: 0.0534319868311286, Final Batch Loss: 0.01641259528696537\n",
      "Epoch 663, Loss: 0.042008582036942244, Final Batch Loss: 0.005439960863441229\n",
      "Epoch 664, Loss: 0.04856073763221502, Final Batch Loss: 0.009472431614995003\n",
      "Epoch 665, Loss: 0.044382590043824166, Final Batch Loss: 0.0009133901330642402\n",
      "Epoch 666, Loss: 0.07911099214106798, Final Batch Loss: 0.04264918714761734\n",
      "Epoch 667, Loss: 0.061481805983930826, Final Batch Loss: 0.006483211647719145\n",
      "Epoch 668, Loss: 0.056996497325599194, Final Batch Loss: 0.014553730376064777\n",
      "Epoch 669, Loss: 0.04751569218933582, Final Batch Loss: 0.01528853364288807\n",
      "Epoch 670, Loss: 0.054431002485216595, Final Batch Loss: 0.00023166638857219368\n",
      "Epoch 671, Loss: 0.20907662995159626, Final Batch Loss: 0.17050842940807343\n",
      "Epoch 672, Loss: 0.05636481661349535, Final Batch Loss: 0.008618808351457119\n",
      "Epoch 673, Loss: 0.05144685762934387, Final Batch Loss: 0.00282820756547153\n",
      "Epoch 674, Loss: 0.04317577322944999, Final Batch Loss: 0.003410003613680601\n",
      "Epoch 675, Loss: 0.06035379599779844, Final Batch Loss: 0.012258046306669712\n",
      "Epoch 676, Loss: 0.051309830509126186, Final Batch Loss: 0.01788017712533474\n",
      "Epoch 677, Loss: 0.043398443958722055, Final Batch Loss: 0.0018198475008830428\n",
      "Epoch 678, Loss: 0.05119942361488938, Final Batch Loss: 0.0030778036452829838\n",
      "Epoch 679, Loss: 0.07734852842986584, Final Batch Loss: 0.045013077557086945\n",
      "Epoch 680, Loss: 0.05627605877816677, Final Batch Loss: 0.0212979968637228\n",
      "Epoch 681, Loss: 0.05772195477038622, Final Batch Loss: 0.021487604826688766\n",
      "Epoch 682, Loss: 0.09759167209267616, Final Batch Loss: 0.06022930145263672\n",
      "Epoch 683, Loss: 0.03870236861985177, Final Batch Loss: 0.0019369403598830104\n",
      "Epoch 684, Loss: 0.07985289767384529, Final Batch Loss: 0.030326997861266136\n",
      "Epoch 685, Loss: 0.06505128648132086, Final Batch Loss: 0.007818684913218021\n",
      "Epoch 686, Loss: 0.045205042231827974, Final Batch Loss: 0.0022609219886362553\n",
      "Epoch 687, Loss: 0.046618509222753346, Final Batch Loss: 0.0017837054328992963\n",
      "Epoch 688, Loss: 0.03923830529674888, Final Batch Loss: 0.004299515392631292\n",
      "Epoch 689, Loss: 0.06353011942701414, Final Batch Loss: 0.00022223807172849774\n",
      "Epoch 690, Loss: 0.0981155801564455, Final Batch Loss: 0.06064961478114128\n",
      "Epoch 691, Loss: 0.05076381145045161, Final Batch Loss: 0.0057320608757436275\n",
      "Epoch 692, Loss: 0.05071881925687194, Final Batch Loss: 0.01921844854950905\n",
      "Epoch 693, Loss: 0.2710538925603032, Final Batch Loss: 0.24238501489162445\n",
      "Epoch 694, Loss: 0.056257772142998874, Final Batch Loss: 0.001876068185083568\n",
      "Epoch 695, Loss: 0.03639638191089034, Final Batch Loss: 0.00674918619915843\n",
      "Epoch 696, Loss: 0.03870892780832946, Final Batch Loss: 0.002719288459047675\n",
      "Epoch 697, Loss: 0.02892024489119649, Final Batch Loss: 0.0039216005243361\n",
      "Epoch 698, Loss: 0.12607321608811617, Final Batch Loss: 0.10062609612941742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699, Loss: 0.040599838888738304, Final Batch Loss: 0.0007844390929676592\n",
      "Epoch 700, Loss: 0.03392737713875249, Final Batch Loss: 0.0005821472150273621\n",
      "Epoch 701, Loss: 0.044200639706104994, Final Batch Loss: 0.010047424584627151\n",
      "Epoch 702, Loss: 0.0532382745295763, Final Batch Loss: 0.0010646851733326912\n",
      "Epoch 703, Loss: 0.10230251029133797, Final Batch Loss: 0.05411622300744057\n",
      "Epoch 704, Loss: 0.07722457312047482, Final Batch Loss: 0.0444069467484951\n",
      "Epoch 705, Loss: 0.032209038094151765, Final Batch Loss: 0.0007836802978999913\n",
      "Epoch 706, Loss: 0.042725598672404885, Final Batch Loss: 0.002149483421817422\n",
      "Epoch 707, Loss: 0.03828781645279378, Final Batch Loss: 0.0005508147878572345\n",
      "Epoch 708, Loss: 0.04558799532242119, Final Batch Loss: 0.000679998891428113\n",
      "Epoch 709, Loss: 0.11274849716573954, Final Batch Loss: 0.08699803799390793\n",
      "Epoch 710, Loss: 0.06510321609675884, Final Batch Loss: 0.021958911791443825\n",
      "Epoch 711, Loss: 0.13623170740902424, Final Batch Loss: 0.10186246037483215\n",
      "Epoch 712, Loss: 0.048670921474695206, Final Batch Loss: 0.011861346662044525\n",
      "Epoch 713, Loss: 0.04679099330678582, Final Batch Loss: 0.010539881885051727\n",
      "Epoch 714, Loss: 0.05105629516765475, Final Batch Loss: 0.021214373409748077\n",
      "Epoch 715, Loss: 0.06289790198206902, Final Batch Loss: 0.0231210645288229\n",
      "Epoch 716, Loss: 0.03517372644273564, Final Batch Loss: 0.0007794841076247394\n",
      "Epoch 717, Loss: 0.031921074260026217, Final Batch Loss: 0.0028379070572555065\n",
      "Epoch 718, Loss: 0.10344629362225533, Final Batch Loss: 0.07242213189601898\n",
      "Epoch 719, Loss: 0.2117248633876443, Final Batch Loss: 0.18825620412826538\n",
      "Epoch 720, Loss: 0.06471911445260048, Final Batch Loss: 0.005770783871412277\n",
      "Epoch 721, Loss: 0.06490760890301317, Final Batch Loss: 0.0011894128983840346\n",
      "Epoch 722, Loss: 0.04571026290068403, Final Batch Loss: 0.000824616348836571\n",
      "Epoch 723, Loss: 0.04427568952087313, Final Batch Loss: 0.00035594648215919733\n",
      "Epoch 724, Loss: 0.0546531300060451, Final Batch Loss: 0.005738384556025267\n",
      "Epoch 725, Loss: 0.048504358157515526, Final Batch Loss: 0.01782483048737049\n",
      "Epoch 726, Loss: 0.025107880705036223, Final Batch Loss: 0.0016356304986402392\n",
      "Epoch 727, Loss: 0.032006388530135155, Final Batch Loss: 0.005952983163297176\n",
      "Epoch 728, Loss: 0.06720428448170424, Final Batch Loss: 0.029862618073821068\n",
      "Epoch 729, Loss: 0.04298724781256169, Final Batch Loss: 0.0005616991547867656\n",
      "Epoch 730, Loss: 0.028153531718999147, Final Batch Loss: 0.002679137047380209\n",
      "Epoch 731, Loss: 0.025196316244546324, Final Batch Loss: 0.0005140775465406477\n",
      "Epoch 732, Loss: 0.04483865015208721, Final Batch Loss: 0.015907788649201393\n",
      "Epoch 733, Loss: 0.0312186986557208, Final Batch Loss: 0.000900797953363508\n",
      "Epoch 734, Loss: 0.050267893355339766, Final Batch Loss: 0.0010539027862250805\n",
      "Epoch 735, Loss: 0.02757672732695937, Final Batch Loss: 0.0018909214995801449\n",
      "Epoch 736, Loss: 0.02704148436896503, Final Batch Loss: 0.000977691961452365\n",
      "Epoch 737, Loss: 0.05259297788143158, Final Batch Loss: 0.021786270663142204\n",
      "Epoch 738, Loss: 0.07255456922575831, Final Batch Loss: 0.042031411081552505\n",
      "Epoch 739, Loss: 0.02902707038447261, Final Batch Loss: 0.0055319275707006454\n",
      "Epoch 740, Loss: 0.08429502882063389, Final Batch Loss: 0.04871692135930061\n",
      "Epoch 741, Loss: 0.039488671347498894, Final Batch Loss: 0.012651987373828888\n",
      "Epoch 742, Loss: 0.05939050856977701, Final Batch Loss: 0.04049549996852875\n",
      "Epoch 743, Loss: 0.025111344060860574, Final Batch Loss: 0.0008011575555428863\n",
      "Epoch 744, Loss: 0.04142896272242069, Final Batch Loss: 0.008388704620301723\n",
      "Epoch 745, Loss: 0.03583655564580113, Final Batch Loss: 0.0012138705933466554\n",
      "Epoch 746, Loss: 0.041454338701441884, Final Batch Loss: 0.0018563906196504831\n",
      "Epoch 747, Loss: 0.11660522781312466, Final Batch Loss: 0.07067950069904327\n",
      "Epoch 748, Loss: 0.19556264951825142, Final Batch Loss: 0.16167278587818146\n",
      "Epoch 749, Loss: 0.07687360234558582, Final Batch Loss: 0.03799871355295181\n",
      "Epoch 750, Loss: 0.04744633287191391, Final Batch Loss: 0.008597713895142078\n",
      "Epoch 751, Loss: 0.059501543757505715, Final Batch Loss: 0.0005433225305750966\n",
      "Epoch 752, Loss: 0.07752541825175285, Final Batch Loss: 0.004838686436414719\n",
      "Epoch 753, Loss: 0.05655352957546711, Final Batch Loss: 0.002324964851140976\n",
      "Epoch 754, Loss: 0.03691325866384432, Final Batch Loss: 0.0007829747046343982\n",
      "Epoch 755, Loss: 0.03008395741926506, Final Batch Loss: 0.00022211699979379773\n",
      "Epoch 756, Loss: 0.04529422102496028, Final Batch Loss: 0.0042929877527058125\n",
      "Epoch 757, Loss: 0.03436374105513096, Final Batch Loss: 0.004336618818342686\n",
      "Epoch 758, Loss: 0.03810238861478865, Final Batch Loss: 0.0035310129169374704\n",
      "Epoch 759, Loss: 0.03969538351520896, Final Batch Loss: 0.004945611115545034\n",
      "Epoch 760, Loss: 0.03941944148391485, Final Batch Loss: 0.01432731095701456\n",
      "Epoch 761, Loss: 0.04396828627795912, Final Batch Loss: 0.00036944999010302126\n",
      "Epoch 762, Loss: 0.02849914808757603, Final Batch Loss: 0.0025656961370259523\n",
      "Epoch 763, Loss: 0.2344581107608974, Final Batch Loss: 0.2188645899295807\n",
      "Epoch 764, Loss: 0.03518504253588617, Final Batch Loss: 0.0013307633344084024\n",
      "Epoch 765, Loss: 0.03208544570952654, Final Batch Loss: 0.0038208020851016045\n",
      "Epoch 766, Loss: 0.04598857834935188, Final Batch Loss: 0.018369361758232117\n",
      "Epoch 767, Loss: 0.027142080012708902, Final Batch Loss: 0.006661361549049616\n",
      "Epoch 768, Loss: 0.03673643615911715, Final Batch Loss: 0.000122146651847288\n",
      "Epoch 769, Loss: 0.030956729548051953, Final Batch Loss: 0.0027466726023703814\n",
      "Epoch 770, Loss: 0.0354833398014307, Final Batch Loss: 0.003321613185107708\n",
      "Epoch 771, Loss: 0.03274428262375295, Final Batch Loss: 0.001116864150390029\n",
      "Epoch 772, Loss: 0.08026379672810435, Final Batch Loss: 0.05612149462103844\n",
      "Epoch 773, Loss: 0.03516600956209004, Final Batch Loss: 0.0014481816906481981\n",
      "Epoch 774, Loss: 0.030112514039501548, Final Batch Loss: 0.001851564971730113\n",
      "Epoch 775, Loss: 0.04145891859661788, Final Batch Loss: 0.0005615659756585956\n",
      "Epoch 776, Loss: 0.03936091568903066, Final Batch Loss: 0.0002716965100262314\n",
      "Epoch 777, Loss: 0.02651488035917282, Final Batch Loss: 0.0012037018314003944\n",
      "Epoch 778, Loss: 0.037680710200220346, Final Batch Loss: 0.004841064102947712\n",
      "Epoch 779, Loss: 0.044597434578463435, Final Batch Loss: 0.014790736138820648\n",
      "Epoch 780, Loss: 0.06564484536647797, Final Batch Loss: 0.03428734838962555\n",
      "Epoch 781, Loss: 0.025742280209669843, Final Batch Loss: 0.0002691577246878296\n",
      "Epoch 782, Loss: 0.027527333237230778, Final Batch Loss: 0.005431076977401972\n",
      "Epoch 783, Loss: 0.03260487108491361, Final Batch Loss: 0.002376542193815112\n",
      "Epoch 784, Loss: 0.029498348012566566, Final Batch Loss: 0.0006094384007155895\n",
      "Epoch 785, Loss: 0.03521281015127897, Final Batch Loss: 0.005851960740983486\n",
      "Epoch 786, Loss: 0.034469849430024624, Final Batch Loss: 0.011475581675767899\n",
      "Epoch 787, Loss: 0.023885150265414268, Final Batch Loss: 0.00013948680134490132\n",
      "Epoch 788, Loss: 0.04428394231945276, Final Batch Loss: 0.0023977039381861687\n",
      "Epoch 789, Loss: 0.03217084286734462, Final Batch Loss: 0.00734094949439168\n",
      "Epoch 790, Loss: 0.037269470281898975, Final Batch Loss: 0.008132589049637318\n",
      "Epoch 791, Loss: 0.029466743348166347, Final Batch Loss: 0.000797386048361659\n",
      "Epoch 792, Loss: 0.14571496122516692, Final Batch Loss: 0.13761930167675018\n",
      "Epoch 793, Loss: 0.03593481634743512, Final Batch Loss: 0.0038279902655631304\n",
      "Epoch 794, Loss: 0.03315067803487182, Final Batch Loss: 0.003766725305467844\n",
      "Epoch 795, Loss: 0.02964002569206059, Final Batch Loss: 0.003440810600295663\n",
      "Epoch 796, Loss: 0.03518402809277177, Final Batch Loss: 0.001233958639204502\n",
      "Epoch 797, Loss: 0.019379381206817925, Final Batch Loss: 0.0007099007489159703\n",
      "Epoch 798, Loss: 0.030038293451070786, Final Batch Loss: 0.0016607344150543213\n",
      "Epoch 799, Loss: 0.1881087264046073, Final Batch Loss: 0.1681763231754303\n",
      "Epoch 800, Loss: 0.01932014769408852, Final Batch Loss: 0.001279113464988768\n",
      "Epoch 801, Loss: 0.04265792900696397, Final Batch Loss: 0.0005011945031583309\n",
      "Epoch 802, Loss: 0.04533489607274532, Final Batch Loss: 0.0016721822321414948\n",
      "Epoch 803, Loss: 0.04108813514903886, Final Batch Loss: 0.00010037671745521948\n",
      "Epoch 804, Loss: 0.022925662575289607, Final Batch Loss: 0.0035847362596541643\n",
      "Epoch 805, Loss: 0.02002116898074746, Final Batch Loss: 0.0015590195544064045\n",
      "Epoch 806, Loss: 0.022793102893047035, Final Batch Loss: 0.001471560331992805\n",
      "Epoch 807, Loss: 0.04278791323304176, Final Batch Loss: 0.0049506183713674545\n",
      "Epoch 808, Loss: 0.02637922251597047, Final Batch Loss: 0.0030309478752315044\n",
      "Epoch 809, Loss: 0.0386413699015975, Final Batch Loss: 0.018570927903056145\n",
      "Epoch 810, Loss: 0.03128111036494374, Final Batch Loss: 0.007199414540082216\n",
      "Epoch 811, Loss: 0.024457828607410192, Final Batch Loss: 0.002394844079390168\n",
      "Epoch 812, Loss: 0.018373344792053103, Final Batch Loss: 0.002344464883208275\n",
      "Epoch 813, Loss: 0.012292130733840168, Final Batch Loss: 0.001112989499233663\n",
      "Epoch 814, Loss: 0.034829353680834174, Final Batch Loss: 0.0027105154003947973\n",
      "Epoch 815, Loss: 0.020661343005485833, Final Batch Loss: 0.0012807493330910802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 816, Loss: 0.017612781608477235, Final Batch Loss: 0.002522296505048871\n",
      "Epoch 817, Loss: 0.034858232364058495, Final Batch Loss: 0.004421545192599297\n",
      "Epoch 818, Loss: 0.035033283522352576, Final Batch Loss: 0.003727332456037402\n",
      "Epoch 819, Loss: 0.031064807903021574, Final Batch Loss: 0.0022365879267454147\n",
      "Epoch 820, Loss: 0.05594012187793851, Final Batch Loss: 0.0018247677944600582\n",
      "Epoch 821, Loss: 0.029429789166897535, Final Batch Loss: 0.00032876478508114815\n",
      "Epoch 822, Loss: 0.027667724061757326, Final Batch Loss: 0.003984506707638502\n",
      "Epoch 823, Loss: 0.04285054747015238, Final Batch Loss: 0.0026421211659908295\n",
      "Epoch 824, Loss: 0.03168003959581256, Final Batch Loss: 0.0031711948104202747\n",
      "Epoch 825, Loss: 0.025552701568813063, Final Batch Loss: 0.00014101564011070877\n",
      "Epoch 826, Loss: 0.03504766058176756, Final Batch Loss: 0.004678191617131233\n",
      "Epoch 827, Loss: 0.060617951676249504, Final Batch Loss: 0.022881120443344116\n",
      "Epoch 828, Loss: 0.03554421235457994, Final Batch Loss: 0.0004680998681578785\n",
      "Epoch 829, Loss: 0.15134955290704966, Final Batch Loss: 0.12280426174402237\n",
      "Epoch 830, Loss: 0.037097654305398464, Final Batch Loss: 0.015229093842208385\n",
      "Epoch 831, Loss: 0.05256010452285409, Final Batch Loss: 0.0024267849512398243\n",
      "Epoch 832, Loss: 0.07039452390745282, Final Batch Loss: 0.006975727621465921\n",
      "Epoch 833, Loss: 0.050830943626351655, Final Batch Loss: 0.0005217447178438306\n",
      "Epoch 834, Loss: 0.05460004883934744, Final Batch Loss: 0.000245161383645609\n",
      "Epoch 835, Loss: 0.04242702107876539, Final Batch Loss: 0.008400091901421547\n",
      "Epoch 836, Loss: 0.038565860129892826, Final Batch Loss: 0.011515607126057148\n",
      "Epoch 837, Loss: 0.03018632810562849, Final Batch Loss: 0.002669847570359707\n",
      "Epoch 838, Loss: 0.02823397637985181, Final Batch Loss: 0.00013269558257889003\n",
      "Epoch 839, Loss: 0.019526871903508436, Final Batch Loss: 0.00011478136730147526\n",
      "Epoch 840, Loss: 0.039505471009761095, Final Batch Loss: 0.007464248221367598\n",
      "Epoch 841, Loss: 0.03061183076351881, Final Batch Loss: 0.012192357331514359\n",
      "Epoch 842, Loss: 0.04056909237988293, Final Batch Loss: 0.003451382974162698\n",
      "Epoch 843, Loss: 0.0359627885336522, Final Batch Loss: 0.0003918685542885214\n",
      "Epoch 844, Loss: 0.029359501786530018, Final Batch Loss: 0.010851757600903511\n",
      "Epoch 845, Loss: 0.04991985484957695, Final Batch Loss: 0.027210349217057228\n",
      "Epoch 846, Loss: 0.0285107612144202, Final Batch Loss: 0.0019349593203514814\n",
      "Epoch 847, Loss: 0.026819187682121992, Final Batch Loss: 0.0023759366013109684\n",
      "Epoch 848, Loss: 0.035494355484843254, Final Batch Loss: 0.007296964526176453\n",
      "Epoch 849, Loss: 0.03985533909872174, Final Batch Loss: 0.0025339066050946712\n",
      "Epoch 850, Loss: 0.024432625388726592, Final Batch Loss: 0.0025417099241167307\n",
      "Epoch 851, Loss: 0.03314538509584963, Final Batch Loss: 0.012179248034954071\n",
      "Epoch 852, Loss: 0.021652599680237472, Final Batch Loss: 0.0012501984601840377\n",
      "Epoch 853, Loss: 0.019081480088061653, Final Batch Loss: 0.00013463104551192373\n",
      "Epoch 854, Loss: 0.041050808504223824, Final Batch Loss: 0.00819529127329588\n",
      "Epoch 855, Loss: 0.03170933900400996, Final Batch Loss: 0.00874823797494173\n",
      "Epoch 856, Loss: 0.01031204522587359, Final Batch Loss: 0.0020150896161794662\n",
      "Epoch 857, Loss: 0.02582497603725642, Final Batch Loss: 0.001352460472844541\n",
      "Epoch 858, Loss: 0.029357770923525095, Final Batch Loss: 0.004934660159051418\n",
      "Epoch 859, Loss: 0.03135644318535924, Final Batch Loss: 0.00751592917367816\n",
      "Epoch 860, Loss: 0.021717089854064398, Final Batch Loss: 0.00011347925465088338\n",
      "Epoch 861, Loss: 0.028459767811000347, Final Batch Loss: 0.002172885462641716\n",
      "Epoch 862, Loss: 0.05095144952792907, Final Batch Loss: 0.00010892222780967131\n",
      "Epoch 863, Loss: 0.27758572017773986, Final Batch Loss: 0.25658753514289856\n",
      "Epoch 864, Loss: 0.02547027077525854, Final Batch Loss: 0.005373334977775812\n",
      "Epoch 865, Loss: 0.02623617381323129, Final Batch Loss: 0.0010745577747002244\n",
      "Epoch 866, Loss: 0.010982161154970527, Final Batch Loss: 0.0005017768125981092\n",
      "Epoch 867, Loss: 0.02609222731553018, Final Batch Loss: 0.0020740285981446505\n",
      "Epoch 868, Loss: 0.03447759966365993, Final Batch Loss: 0.01517325360327959\n",
      "Epoch 869, Loss: 0.04761760635301471, Final Batch Loss: 0.023953989148139954\n",
      "Epoch 870, Loss: 0.03281813394278288, Final Batch Loss: 0.014164449647068977\n",
      "Epoch 871, Loss: 0.014994619356002659, Final Batch Loss: 0.0004103094688616693\n",
      "Epoch 872, Loss: 0.02753960950212786, Final Batch Loss: 0.00011111659841844812\n",
      "Epoch 873, Loss: 0.041158666368573904, Final Batch Loss: 0.004089786671102047\n",
      "Epoch 874, Loss: 0.0382446973817423, Final Batch Loss: 0.0011900003300979733\n",
      "Epoch 875, Loss: 0.027360801806935342, Final Batch Loss: 5.001177851227112e-05\n",
      "Epoch 876, Loss: 0.09451296599581838, Final Batch Loss: 0.07170076668262482\n",
      "Epoch 877, Loss: 0.026852765819057822, Final Batch Loss: 0.002849897835403681\n",
      "Epoch 878, Loss: 0.09714525379240513, Final Batch Loss: 0.05899205431342125\n",
      "Epoch 879, Loss: 0.03231374965980649, Final Batch Loss: 0.005744839087128639\n",
      "Epoch 880, Loss: 0.06836140621453524, Final Batch Loss: 0.04213787242770195\n",
      "Epoch 881, Loss: 0.026513004209846258, Final Batch Loss: 0.00872076116502285\n",
      "Epoch 882, Loss: 0.040426115854643285, Final Batch Loss: 0.0002029020106419921\n",
      "Epoch 883, Loss: 0.025549669284373522, Final Batch Loss: 0.0017012124881148338\n",
      "Epoch 884, Loss: 0.03496403433382511, Final Batch Loss: 0.004080465063452721\n",
      "Epoch 885, Loss: 0.03165421704761684, Final Batch Loss: 0.007749577984213829\n",
      "Epoch 886, Loss: 0.03274612399400212, Final Batch Loss: 0.0003424593305680901\n",
      "Epoch 887, Loss: 0.03463752381503582, Final Batch Loss: 0.016902009025216103\n",
      "Epoch 888, Loss: 0.035005677957087755, Final Batch Loss: 0.0024757101200520992\n",
      "Epoch 889, Loss: 0.02183572156354785, Final Batch Loss: 0.004676606506109238\n",
      "Epoch 890, Loss: 0.02658176963450387, Final Batch Loss: 0.0002951576025225222\n",
      "Epoch 891, Loss: 0.011569656344363466, Final Batch Loss: 0.00042583272443152964\n",
      "Epoch 892, Loss: 0.029992806492373347, Final Batch Loss: 0.0005538181867450476\n",
      "Epoch 893, Loss: 0.01622430537827313, Final Batch Loss: 0.0030565205961465836\n",
      "Epoch 894, Loss: 0.03355981549248099, Final Batch Loss: 0.004056018777191639\n",
      "Epoch 895, Loss: 0.03155347006395459, Final Batch Loss: 0.0036244518123567104\n",
      "Epoch 896, Loss: 0.03187883645296097, Final Batch Loss: 0.0003940281458199024\n",
      "Epoch 897, Loss: 0.028068456333130598, Final Batch Loss: 0.006177118513733149\n",
      "Epoch 898, Loss: 0.026035042013972998, Final Batch Loss: 0.002818294335156679\n",
      "Epoch 899, Loss: 0.04228296875953674, Final Batch Loss: 0.001605072058737278\n",
      "Epoch 900, Loss: 0.03478827839717269, Final Batch Loss: 0.0017931269248947501\n",
      "Epoch 901, Loss: 0.024087939818855375, Final Batch Loss: 0.0006380157428793609\n",
      "Epoch 902, Loss: 0.03631909564137459, Final Batch Loss: 0.005347752943634987\n",
      "Epoch 903, Loss: 0.03010768350213766, Final Batch Loss: 0.0014816210605204105\n",
      "Epoch 904, Loss: 0.024699288318515755, Final Batch Loss: 0.000165258432389237\n",
      "Epoch 905, Loss: 0.042073007207363844, Final Batch Loss: 0.03128551319241524\n",
      "Epoch 906, Loss: 0.029230432119220495, Final Batch Loss: 0.0033598646987229586\n",
      "Epoch 907, Loss: 0.04005269275512546, Final Batch Loss: 0.00044474692549556494\n",
      "Epoch 908, Loss: 0.02899258374236524, Final Batch Loss: 0.001512783346697688\n",
      "Epoch 909, Loss: 0.022277622716501355, Final Batch Loss: 0.002294715726748109\n",
      "Epoch 910, Loss: 0.0260222633369267, Final Batch Loss: 0.0004978780634701252\n",
      "Epoch 911, Loss: 0.031986705493181944, Final Batch Loss: 0.010156204923987389\n",
      "Epoch 912, Loss: 0.04105334635823965, Final Batch Loss: 0.011039047501981258\n",
      "Epoch 913, Loss: 0.026198034873232245, Final Batch Loss: 0.008817491121590137\n",
      "Epoch 914, Loss: 0.014832584885880351, Final Batch Loss: 0.002781118033453822\n",
      "Epoch 915, Loss: 0.025090687908232212, Final Batch Loss: 0.002243766561150551\n",
      "Epoch 916, Loss: 0.015060814621392637, Final Batch Loss: 0.000772313738707453\n",
      "Epoch 917, Loss: 0.02838133182376623, Final Batch Loss: 0.002306249924004078\n",
      "Epoch 918, Loss: 0.01233568467432633, Final Batch Loss: 0.0009256795165129006\n",
      "Epoch 919, Loss: 0.024905995931476355, Final Batch Loss: 0.005394651088863611\n",
      "Epoch 920, Loss: 0.07941693929024041, Final Batch Loss: 0.07175688445568085\n",
      "Epoch 921, Loss: 0.0409827409312129, Final Batch Loss: 0.004481093026697636\n",
      "Epoch 922, Loss: 0.03290677536278963, Final Batch Loss: 0.008140744641423225\n",
      "Epoch 923, Loss: 0.03150952432770282, Final Batch Loss: 0.00166883144993335\n",
      "Epoch 924, Loss: 0.022037651942810044, Final Batch Loss: 0.0004202854761388153\n",
      "Epoch 925, Loss: 0.021337726386263967, Final Batch Loss: 0.0025007084477692842\n",
      "Epoch 926, Loss: 0.01296273828484118, Final Batch Loss: 0.0004929699935019016\n",
      "Epoch 927, Loss: 0.06523178424686193, Final Batch Loss: 0.03844350576400757\n",
      "Epoch 928, Loss: 0.029128666035830975, Final Batch Loss: 0.009416689164936543\n",
      "Epoch 929, Loss: 0.02895763740525581, Final Batch Loss: 0.00010618139640428126\n",
      "Epoch 930, Loss: 0.027980133891105652, Final Batch Loss: 0.0009381468407809734\n",
      "Epoch 931, Loss: 0.013830033130943775, Final Batch Loss: 0.0003308504819869995\n",
      "Epoch 932, Loss: 0.03459484619088471, Final Batch Loss: 0.005695595871657133\n",
      "Epoch 933, Loss: 0.019121335353702307, Final Batch Loss: 0.0007981094531714916\n",
      "Epoch 934, Loss: 0.026228831964544952, Final Batch Loss: 0.0003656999906525016\n",
      "Epoch 935, Loss: 0.02383036259561777, Final Batch Loss: 0.0006315265782177448\n",
      "Epoch 936, Loss: 0.026580146979540586, Final Batch Loss: 0.004329849034547806\n",
      "Epoch 937, Loss: 0.016275395406410098, Final Batch Loss: 0.004447177983820438\n",
      "Epoch 938, Loss: 0.02320499168126844, Final Batch Loss: 0.0002626814821269363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939, Loss: 0.13645298499614, Final Batch Loss: 0.12813113629817963\n",
      "Epoch 940, Loss: 0.0223635554430075, Final Batch Loss: 0.00011631828965619206\n",
      "Epoch 941, Loss: 0.026963322423398495, Final Batch Loss: 0.010974564589560032\n",
      "Epoch 942, Loss: 0.04108717944473028, Final Batch Loss: 0.016605103388428688\n",
      "Epoch 943, Loss: 0.21210064180195332, Final Batch Loss: 0.19791263341903687\n",
      "Epoch 944, Loss: 0.014759795041754842, Final Batch Loss: 0.0016957297921180725\n",
      "Epoch 945, Loss: 0.07294253050349653, Final Batch Loss: 0.05634726956486702\n",
      "Epoch 946, Loss: 0.027693395502865314, Final Batch Loss: 0.0034661940298974514\n",
      "Epoch 947, Loss: 0.03861948661506176, Final Batch Loss: 0.005018647760152817\n",
      "Epoch 948, Loss: 0.016657473286613822, Final Batch Loss: 0.003003210062161088\n",
      "Epoch 949, Loss: 0.010028188436990604, Final Batch Loss: 0.00028394380933605134\n",
      "Epoch 950, Loss: 0.00965394452214241, Final Batch Loss: 0.00032667117193341255\n",
      "Epoch 951, Loss: 0.020968064898625016, Final Batch Loss: 0.0008111887145787477\n",
      "Epoch 952, Loss: 0.015831928234547377, Final Batch Loss: 0.005666229408234358\n",
      "Epoch 953, Loss: 0.007270171627169475, Final Batch Loss: 0.00025835129781626165\n",
      "Epoch 954, Loss: 0.018326126708416268, Final Batch Loss: 0.0002838570799212903\n",
      "Epoch 955, Loss: 0.026318767573684454, Final Batch Loss: 0.00023355800658464432\n",
      "Epoch 956, Loss: 0.017979583702981472, Final Batch Loss: 0.0017221495509147644\n",
      "Epoch 957, Loss: 0.020644985837861896, Final Batch Loss: 0.002749495906755328\n",
      "Epoch 958, Loss: 0.008259978843852878, Final Batch Loss: 0.0024820901453495026\n",
      "Epoch 959, Loss: 0.011824195738881826, Final Batch Loss: 0.00047120824456214905\n",
      "Epoch 960, Loss: 0.023073258809745312, Final Batch Loss: 0.0023529361933469772\n",
      "Epoch 961, Loss: 0.027113240445032716, Final Batch Loss: 4.1994499042630196e-05\n",
      "Epoch 962, Loss: 0.02013030188390985, Final Batch Loss: 0.0007131770835258067\n",
      "Epoch 963, Loss: 0.017515605548396707, Final Batch Loss: 0.0023606771137565374\n",
      "Epoch 964, Loss: 0.015087485779076815, Final Batch Loss: 0.005816224962472916\n",
      "Epoch 965, Loss: 0.05457326117902994, Final Batch Loss: 0.04236837103962898\n",
      "Epoch 966, Loss: 0.011619088792940602, Final Batch Loss: 0.00025202249526046216\n",
      "Epoch 967, Loss: 0.024927034508436918, Final Batch Loss: 0.0006056497804820538\n",
      "Epoch 968, Loss: 0.04341951943933964, Final Batch Loss: 0.013409743085503578\n",
      "Epoch 969, Loss: 0.052499177400022745, Final Batch Loss: 0.028302591294050217\n",
      "Epoch 970, Loss: 0.02951318444684148, Final Batch Loss: 0.003018477465957403\n",
      "Epoch 971, Loss: 0.008137860393617302, Final Batch Loss: 0.0007670790073461831\n",
      "Epoch 972, Loss: 0.042140837758779526, Final Batch Loss: 0.015037653967738152\n",
      "Epoch 973, Loss: 0.03445432032458484, Final Batch Loss: 0.002340880921110511\n",
      "Epoch 974, Loss: 0.009280001337174326, Final Batch Loss: 0.000970386725384742\n",
      "Epoch 975, Loss: 0.017421906115487218, Final Batch Loss: 0.0028895253781229258\n",
      "Epoch 976, Loss: 0.01530591183109209, Final Batch Loss: 0.000534355582203716\n",
      "Epoch 977, Loss: 0.01758071919903159, Final Batch Loss: 0.009251423180103302\n",
      "Epoch 978, Loss: 0.01793736615218222, Final Batch Loss: 8.76148696988821e-05\n",
      "Epoch 979, Loss: 0.017425392259610817, Final Batch Loss: 0.00044748009531758726\n",
      "Epoch 980, Loss: 0.02390650357119739, Final Batch Loss: 0.00133295520208776\n",
      "Epoch 981, Loss: 0.017071080204914324, Final Batch Loss: 0.00021568201191257685\n",
      "Epoch 982, Loss: 0.026087683847435983, Final Batch Loss: 3.06209440168459e-05\n",
      "Epoch 983, Loss: 0.024532936979085207, Final Batch Loss: 0.00834465678781271\n",
      "Epoch 984, Loss: 0.033757631841581315, Final Batch Loss: 0.0005563629674725235\n",
      "Epoch 985, Loss: 0.015877120778895915, Final Batch Loss: 0.0007498605409637094\n",
      "Epoch 986, Loss: 0.01829713606275618, Final Batch Loss: 0.0008967884350568056\n",
      "Epoch 987, Loss: 0.08856187062337995, Final Batch Loss: 0.07390427589416504\n",
      "Epoch 988, Loss: 0.01624338555848226, Final Batch Loss: 0.00012830056948587298\n",
      "Epoch 989, Loss: 0.022017448442056775, Final Batch Loss: 0.00272259465418756\n",
      "Epoch 990, Loss: 0.03641638535191305, Final Batch Loss: 0.0002097934775520116\n",
      "Epoch 991, Loss: 0.05155105981975794, Final Batch Loss: 0.009059038944542408\n",
      "Epoch 992, Loss: 0.02587052212038543, Final Batch Loss: 0.00018631188140716404\n",
      "Epoch 993, Loss: 0.025730837194714695, Final Batch Loss: 0.00018200190970674157\n",
      "Epoch 994, Loss: 0.027982938569039106, Final Batch Loss: 0.008747023530304432\n",
      "Epoch 995, Loss: 0.028025764971971512, Final Batch Loss: 0.005983143113553524\n",
      "Epoch 996, Loss: 0.013877254677936435, Final Batch Loss: 0.004990282002836466\n",
      "Epoch 997, Loss: 0.02653396944515407, Final Batch Loss: 0.003624617587774992\n",
      "Epoch 998, Loss: 0.01257201237604022, Final Batch Loss: 0.000998293049633503\n",
      "Epoch 999, Loss: 0.01932284573558718, Final Batch Loss: 0.01442681159824133\n",
      "Epoch 1000, Loss: 0.018964590854011476, Final Batch Loss: 0.0003852633526548743\n",
      "Epoch 1001, Loss: 0.013166398217435926, Final Batch Loss: 0.0009555626311339438\n",
      "Epoch 1002, Loss: 0.017570687690749764, Final Batch Loss: 0.00428423099219799\n",
      "Epoch 1003, Loss: 0.02772790566086769, Final Batch Loss: 0.003495762124657631\n",
      "Epoch 1004, Loss: 0.01790961646474898, Final Batch Loss: 0.002207281766459346\n",
      "Epoch 1005, Loss: 0.010770050575956702, Final Batch Loss: 0.002279326319694519\n",
      "Epoch 1006, Loss: 0.014251812594011426, Final Batch Loss: 0.003089542267844081\n",
      "Epoch 1007, Loss: 0.008088558039162308, Final Batch Loss: 9.49188251979649e-05\n",
      "Epoch 1008, Loss: 0.01078974874690175, Final Batch Loss: 0.004227301571518183\n",
      "Epoch 1009, Loss: 0.03213240185868926, Final Batch Loss: 0.000343707186402753\n",
      "Epoch 1010, Loss: 0.03312391694635153, Final Batch Loss: 0.0009586457163095474\n",
      "Epoch 1011, Loss: 0.012938480824232101, Final Batch Loss: 0.002292865887284279\n",
      "Epoch 1012, Loss: 0.009817532729357481, Final Batch Loss: 0.002327140187844634\n",
      "Epoch 1013, Loss: 0.006270979298278689, Final Batch Loss: 0.0013960266951471567\n",
      "Epoch 1014, Loss: 0.007928839419037104, Final Batch Loss: 0.004053495358675718\n",
      "Epoch 1015, Loss: 0.010836445435415953, Final Batch Loss: 0.0009260000078938901\n",
      "Epoch 1016, Loss: 0.010666254442185163, Final Batch Loss: 0.0036455667577683926\n",
      "Epoch 1017, Loss: 0.006290986319072545, Final Batch Loss: 0.0007631679764017463\n",
      "Epoch 1018, Loss: 0.02809098812576849, Final Batch Loss: 6.3760977354832e-05\n",
      "Epoch 1019, Loss: 0.022559474920853972, Final Batch Loss: 0.0030520458240062\n",
      "Epoch 1020, Loss: 0.02997918564506108, Final Batch Loss: 4.026186798000708e-05\n",
      "Epoch 1021, Loss: 0.01688493810070213, Final Batch Loss: 0.0002170100196963176\n",
      "Epoch 1022, Loss: 0.018977885833010077, Final Batch Loss: 0.00773949921131134\n",
      "Epoch 1023, Loss: 0.026039855554699898, Final Batch Loss: 0.013300608843564987\n",
      "Epoch 1024, Loss: 0.005453609068354126, Final Batch Loss: 9.003877494251356e-05\n",
      "Epoch 1025, Loss: 0.010334495309507474, Final Batch Loss: 0.0002825337869580835\n",
      "Epoch 1026, Loss: 0.005901559256017208, Final Batch Loss: 0.0019600309897214174\n",
      "Epoch 1027, Loss: 0.00511848577298224, Final Batch Loss: 0.00029873824678361416\n",
      "Epoch 1028, Loss: 0.011016220174496993, Final Batch Loss: 0.00030739474459551275\n",
      "Epoch 1029, Loss: 0.01702174893580377, Final Batch Loss: 0.007400606758892536\n",
      "Epoch 1030, Loss: 0.011051406152546406, Final Batch Loss: 0.0003865433391183615\n",
      "Epoch 1031, Loss: 0.005809907495859079, Final Batch Loss: 3.7498350138776004e-05\n",
      "Epoch 1032, Loss: 0.0044533103064168245, Final Batch Loss: 0.0004822961345780641\n",
      "Epoch 1033, Loss: 0.02006678469479084, Final Batch Loss: 0.00786413624882698\n",
      "Epoch 1034, Loss: 0.0110663051600568, Final Batch Loss: 0.0005090699414722621\n",
      "Epoch 1035, Loss: 0.0653309282643022, Final Batch Loss: 0.00016037649766076356\n",
      "Epoch 1036, Loss: 0.010554675245657563, Final Batch Loss: 0.0031704220455139875\n",
      "Epoch 1037, Loss: 0.006667349360213848, Final Batch Loss: 4.216678280499764e-05\n",
      "Epoch 1038, Loss: 0.009758372092619538, Final Batch Loss: 0.005627706181257963\n",
      "Epoch 1039, Loss: 0.01439758448395878, Final Batch Loss: 0.006960444618016481\n",
      "Epoch 1040, Loss: 0.008948127506300807, Final Batch Loss: 0.002618084428831935\n",
      "Epoch 1041, Loss: 0.014332404680317268, Final Batch Loss: 0.0004276846011634916\n",
      "Epoch 1042, Loss: 0.017097526462748647, Final Batch Loss: 0.008752119727432728\n",
      "Epoch 1043, Loss: 0.0096617758681532, Final Batch Loss: 0.0002508029283490032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1044, Loss: 0.0033709246272337623, Final Batch Loss: 0.00011998893023701385\n",
      "Epoch 1045, Loss: 0.010945776826702058, Final Batch Loss: 0.002447366015985608\n",
      "Epoch 1046, Loss: 0.035324125114129856, Final Batch Loss: 0.00048369684373028576\n",
      "Epoch 1047, Loss: 0.014996339567005634, Final Batch Loss: 0.007657887879759073\n",
      "Epoch 1048, Loss: 0.00996876928547863, Final Batch Loss: 0.0001860011980170384\n",
      "Epoch 1049, Loss: 0.0086381310102297, Final Batch Loss: 0.00012165975931566209\n",
      "Epoch 1050, Loss: 0.022303409408777952, Final Batch Loss: 0.0008295903680846095\n",
      "Epoch 1051, Loss: 0.005055309447925538, Final Batch Loss: 0.0004993201582692564\n",
      "Epoch 1052, Loss: 0.008703626692295074, Final Batch Loss: 0.0016021925257518888\n",
      "Epoch 1053, Loss: 0.0041757861799851526, Final Batch Loss: 5.41330264240969e-05\n",
      "Epoch 1054, Loss: 0.0030814663332421333, Final Batch Loss: 0.0001570455206092447\n",
      "Epoch 1055, Loss: 0.004562559828627855, Final Batch Loss: 0.00010739272693172097\n",
      "Epoch 1056, Loss: 0.004854857426835224, Final Batch Loss: 0.00039420087705366313\n",
      "Epoch 1057, Loss: 0.0069672634126618505, Final Batch Loss: 0.004874696489423513\n",
      "Epoch 1058, Loss: 0.003961859318224015, Final Batch Loss: 1.3564294931711629e-05\n",
      "Epoch 1059, Loss: 0.0199241986265406, Final Batch Loss: 0.013325212523341179\n",
      "Epoch 1060, Loss: 0.015954483998939395, Final Batch Loss: 0.002342973602935672\n",
      "Epoch 1061, Loss: 0.07625283801462501, Final Batch Loss: 0.0730571374297142\n",
      "Epoch 1062, Loss: 0.027826761128380895, Final Batch Loss: 0.012825832702219486\n",
      "Epoch 1063, Loss: 0.003811970876995474, Final Batch Loss: 0.0006127000669948757\n",
      "Epoch 1064, Loss: 0.010612525744363666, Final Batch Loss: 0.001511766342446208\n",
      "Epoch 1065, Loss: 0.016093781974632293, Final Batch Loss: 0.0003352360217832029\n",
      "Epoch 1066, Loss: 0.0117600989760831, Final Batch Loss: 0.0007535071345046163\n",
      "Epoch 1067, Loss: 0.022641500690951943, Final Batch Loss: 0.0005119733978062868\n",
      "Epoch 1068, Loss: 0.007770697236992419, Final Batch Loss: 0.001841374090872705\n",
      "Epoch 1069, Loss: 0.005063649790827185, Final Batch Loss: 0.00021480181021615863\n",
      "Epoch 1070, Loss: 0.005693673738278449, Final Batch Loss: 0.0005195151316002011\n",
      "Epoch 1071, Loss: 0.0049818683619378135, Final Batch Loss: 0.00018375743820797652\n",
      "Epoch 1072, Loss: 0.027828387799672782, Final Batch Loss: 0.007557515054941177\n",
      "Epoch 1073, Loss: 0.01030457648448646, Final Batch Loss: 0.002787431702017784\n",
      "Epoch 1074, Loss: 0.007982730865478516, Final Batch Loss: 0.002904131542891264\n",
      "Epoch 1075, Loss: 0.003080113441683352, Final Batch Loss: 0.0003114198334515095\n",
      "Epoch 1076, Loss: 0.01883715094299987, Final Batch Loss: 0.0004393362323753536\n",
      "Epoch 1077, Loss: 0.027490695320011582, Final Batch Loss: 8.952136704465374e-05\n",
      "Epoch 1078, Loss: 0.008418440811510663, Final Batch Loss: 7.605388964293525e-05\n",
      "Epoch 1079, Loss: 0.022360656526871026, Final Batch Loss: 0.0014398592757061124\n",
      "Epoch 1080, Loss: 0.015022340463474393, Final Batch Loss: 0.006476114038378\n",
      "Epoch 1081, Loss: 0.011995376320555806, Final Batch Loss: 0.001803997321985662\n",
      "Epoch 1082, Loss: 0.029793257359415293, Final Batch Loss: 0.003207931062206626\n",
      "Epoch 1083, Loss: 0.08226812211796641, Final Batch Loss: 0.07639656215906143\n",
      "Epoch 1084, Loss: 0.0059858306049136445, Final Batch Loss: 8.332163270097226e-05\n",
      "Epoch 1085, Loss: 0.020415887120179832, Final Batch Loss: 0.001101669855415821\n",
      "Epoch 1086, Loss: 0.010919432970695198, Final Batch Loss: 0.0005033834604546428\n",
      "Epoch 1087, Loss: 0.32672908471431583, Final Batch Loss: 0.31904998421669006\n",
      "Epoch 1088, Loss: 0.005822876177262515, Final Batch Loss: 0.0002655013813637197\n",
      "Epoch 1089, Loss: 0.006291583558777347, Final Batch Loss: 0.0004759190196637064\n",
      "Epoch 1090, Loss: 0.0211846397141926, Final Batch Loss: 0.000779466878157109\n",
      "Epoch 1091, Loss: 0.005643943964969367, Final Batch Loss: 0.00023780687479302287\n",
      "Epoch 1092, Loss: 0.004074095617397688, Final Batch Loss: 0.0001222770515596494\n",
      "Epoch 1093, Loss: 0.00748861045576632, Final Batch Loss: 0.0017661673482507467\n",
      "Epoch 1094, Loss: 0.004014487349195406, Final Batch Loss: 0.0001401758927386254\n",
      "Epoch 1095, Loss: 0.016506954159922316, Final Batch Loss: 1.9581004380597733e-05\n",
      "Epoch 1096, Loss: 0.004444717487785965, Final Batch Loss: 0.0006849457859061658\n",
      "Epoch 1097, Loss: 0.005073579115560278, Final Batch Loss: 0.0003919354930985719\n",
      "Epoch 1098, Loss: 0.029953465098515153, Final Batch Loss: 0.021553048864006996\n",
      "Epoch 1099, Loss: 0.003262439917307347, Final Batch Loss: 0.00010671821655705571\n",
      "Epoch 1100, Loss: 0.002870631607947871, Final Batch Loss: 7.141809328459203e-05\n",
      "Epoch 1101, Loss: 0.005877434858120978, Final Batch Loss: 0.001239382429048419\n",
      "Epoch 1102, Loss: 0.012060485314577818, Final Batch Loss: 0.0020293628331273794\n",
      "Epoch 1103, Loss: 0.0042702912469394505, Final Batch Loss: 0.0010865966323763132\n",
      "Epoch 1104, Loss: 0.005298022733768448, Final Batch Loss: 0.00011722193448804319\n",
      "Epoch 1105, Loss: 0.01124804955907166, Final Batch Loss: 0.003957575652748346\n",
      "Epoch 1106, Loss: 0.004195501445792615, Final Batch Loss: 0.0015142988413572311\n",
      "Epoch 1107, Loss: 0.01542175852227956, Final Batch Loss: 0.0018063221359625459\n",
      "Epoch 1108, Loss: 0.0044525181874632835, Final Batch Loss: 7.810723036527634e-05\n",
      "Epoch 1109, Loss: 0.004492325824685395, Final Batch Loss: 0.00018739665392786264\n",
      "Epoch 1110, Loss: 0.00998862914275378, Final Batch Loss: 0.0022933133877813816\n",
      "Epoch 1111, Loss: 0.015354115050286055, Final Batch Loss: 0.0010646508308127522\n",
      "Epoch 1112, Loss: 0.00752079815720208, Final Batch Loss: 0.00021677513723261654\n",
      "Epoch 1113, Loss: 0.016630048070510384, Final Batch Loss: 1.3789765944238752e-05\n",
      "Epoch 1114, Loss: 0.05190986301749945, Final Batch Loss: 0.04009201005101204\n",
      "Epoch 1115, Loss: 0.0435629531275481, Final Batch Loss: 0.0053303781896829605\n",
      "Epoch 1116, Loss: 0.8732429966330528, Final Batch Loss: 0.6676796078681946\n",
      "Epoch 1117, Loss: 0.23585432418622077, Final Batch Loss: 0.0014579410199075937\n",
      "Epoch 1118, Loss: 0.15226672077551484, Final Batch Loss: 0.0034905322827398777\n",
      "Epoch 1119, Loss: 0.08176839537918568, Final Batch Loss: 0.0041601406410336494\n",
      "Epoch 1120, Loss: 0.026201937347650528, Final Batch Loss: 0.01246181782335043\n",
      "Epoch 1121, Loss: 0.01792015810497105, Final Batch Loss: 0.0002626120112836361\n",
      "Epoch 1122, Loss: 0.06526999222114682, Final Batch Loss: 0.039405785501003265\n",
      "Epoch 1123, Loss: 0.030753038823604584, Final Batch Loss: 0.008103994652628899\n",
      "Epoch 1124, Loss: 0.008597911859396845, Final Batch Loss: 0.0006568714161403477\n",
      "Epoch 1125, Loss: 0.030595920601626858, Final Batch Loss: 0.000396650837501511\n",
      "Epoch 1126, Loss: 0.05518307164311409, Final Batch Loss: 0.041524067521095276\n",
      "Epoch 1127, Loss: 0.02273225875251228, Final Batch Loss: 0.00011452564649516717\n",
      "Epoch 1128, Loss: 0.020923371135722846, Final Batch Loss: 0.0009464320610277355\n",
      "Epoch 1129, Loss: 0.010467507410794497, Final Batch Loss: 0.002559515880420804\n",
      "Epoch 1130, Loss: 0.024643760349135846, Final Batch Loss: 0.0009728269069455564\n",
      "Epoch 1131, Loss: 0.01475458755157888, Final Batch Loss: 0.006233396474272013\n",
      "Epoch 1132, Loss: 0.007955999637488276, Final Batch Loss: 0.0006446578190661967\n",
      "Epoch 1133, Loss: 0.011501412722282112, Final Batch Loss: 0.001201497740112245\n",
      "Epoch 1134, Loss: 0.014327972079627216, Final Batch Loss: 0.0018062636954709888\n",
      "Epoch 1135, Loss: 0.01170258759520948, Final Batch Loss: 0.0028925540391355753\n",
      "Epoch 1136, Loss: 0.03306916099973023, Final Batch Loss: 0.0005917095113545656\n",
      "Epoch 1137, Loss: 0.020128105767071247, Final Batch Loss: 0.010239419527351856\n",
      "Epoch 1138, Loss: 0.01757700915914029, Final Batch Loss: 0.004565295297652483\n",
      "Epoch 1139, Loss: 0.01288790674880147, Final Batch Loss: 0.007852409966289997\n",
      "Epoch 1140, Loss: 0.008569561527110636, Final Batch Loss: 0.0012354232603684068\n",
      "Epoch 1141, Loss: 0.007224298547953367, Final Batch Loss: 0.0002083582803606987\n",
      "Epoch 1142, Loss: 0.006182854505823343, Final Batch Loss: 2.2283498765318654e-05\n",
      "Epoch 1143, Loss: 0.004078919348103227, Final Batch Loss: 5.6260661949636415e-05\n",
      "Epoch 1144, Loss: 0.0060544105363078415, Final Batch Loss: 0.0008930466719903052\n",
      "Epoch 1145, Loss: 0.011658819392323494, Final Batch Loss: 0.000814811559394002\n",
      "Epoch 1146, Loss: 0.006336800021017552, Final Batch Loss: 2.6982243070960976e-05\n",
      "Epoch 1147, Loss: 0.019764628261327744, Final Batch Loss: 0.0029050151351839304\n",
      "Epoch 1148, Loss: 0.02179873696877621, Final Batch Loss: 0.00013291099458001554\n",
      "Epoch 1149, Loss: 0.019261508132331073, Final Batch Loss: 0.00973796658217907\n",
      "Epoch 1150, Loss: 0.007160481181927025, Final Batch Loss: 0.0006430480862036347\n",
      "Epoch 1151, Loss: 0.007736701983958483, Final Batch Loss: 0.0034393651876598597\n",
      "Epoch 1152, Loss: 0.025205028126947582, Final Batch Loss: 0.000642837374471128\n",
      "Epoch 1153, Loss: 0.00838473002659157, Final Batch Loss: 0.0005164084141142666\n",
      "Epoch 1154, Loss: 0.023309159325435758, Final Batch Loss: 0.004294846206903458\n",
      "Epoch 1155, Loss: 0.06571357056964189, Final Batch Loss: 0.059812143445014954\n",
      "Epoch 1156, Loss: 0.007939784904010594, Final Batch Loss: 0.004405312705785036\n",
      "Epoch 1157, Loss: 0.012152275303378701, Final Batch Loss: 0.0014298453461378813\n",
      "Epoch 1158, Loss: 0.01787412038538605, Final Batch Loss: 0.0010753520764410496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1159, Loss: 0.014773219329072163, Final Batch Loss: 0.00019433113629929721\n",
      "Epoch 1160, Loss: 0.014956819592043757, Final Batch Loss: 0.0028464875649660826\n",
      "Epoch 1161, Loss: 0.010796267190016806, Final Batch Loss: 0.0002734764711931348\n",
      "Epoch 1162, Loss: 0.008456989657133818, Final Batch Loss: 0.001998823368921876\n",
      "Epoch 1163, Loss: 0.0070234236773103476, Final Batch Loss: 0.000568874180316925\n",
      "Epoch 1164, Loss: 0.005797501071356237, Final Batch Loss: 0.0006254202453419566\n",
      "Epoch 1165, Loss: 0.08940488728694618, Final Batch Loss: 0.08324136584997177\n",
      "Epoch 1166, Loss: 0.008451744040939957, Final Batch Loss: 0.000290127529297024\n",
      "Epoch 1167, Loss: 0.016923315939493477, Final Batch Loss: 0.0003398741828277707\n",
      "Epoch 1168, Loss: 0.06933557326556183, Final Batch Loss: 0.00038430365384556353\n",
      "Epoch 1169, Loss: 0.06956421164795756, Final Batch Loss: 0.005601178389042616\n",
      "Epoch 1170, Loss: 0.012166709755547345, Final Batch Loss: 0.0007374425185844302\n",
      "Epoch 1171, Loss: 0.012520866701379418, Final Batch Loss: 0.00036106002517044544\n",
      "Epoch 1172, Loss: 0.019820103188976645, Final Batch Loss: 0.0035081917885690928\n",
      "Epoch 1173, Loss: 0.023035580990836024, Final Batch Loss: 0.0002517316024750471\n",
      "Epoch 1174, Loss: 0.008648106595501304, Final Batch Loss: 0.0025415399577468634\n",
      "Epoch 1175, Loss: 0.006598305830266327, Final Batch Loss: 0.0006472886889241636\n",
      "Epoch 1176, Loss: 0.08538585249334574, Final Batch Loss: 0.07307414710521698\n",
      "Epoch 1177, Loss: 0.02046497818082571, Final Batch Loss: 0.0015794712817296386\n",
      "Epoch 1178, Loss: 0.009360861731693149, Final Batch Loss: 0.0022885131184011698\n",
      "Epoch 1179, Loss: 0.021766668185591698, Final Batch Loss: 0.0016409331001341343\n",
      "Epoch 1180, Loss: 0.015679992036893964, Final Batch Loss: 0.0031623279210180044\n",
      "Epoch 1181, Loss: 0.017405498132575303, Final Batch Loss: 0.0007778609287925065\n",
      "Epoch 1182, Loss: 0.004970787791535258, Final Batch Loss: 0.0008993782103061676\n",
      "Epoch 1183, Loss: 0.004753563553094864, Final Batch Loss: 0.0015885471366345882\n",
      "Epoch 1184, Loss: 0.015137927373871207, Final Batch Loss: 0.004993067588657141\n",
      "Epoch 1185, Loss: 0.033384295529685915, Final Batch Loss: 0.0009974209824576974\n",
      "Epoch 1186, Loss: 0.016272772365482524, Final Batch Loss: 0.00027207870152778924\n",
      "Epoch 1187, Loss: 0.015242702676914632, Final Batch Loss: 0.0018986667273566127\n",
      "Epoch 1188, Loss: 0.011538663755345624, Final Batch Loss: 5.6760494771879166e-05\n",
      "Epoch 1189, Loss: 0.011329472850775346, Final Batch Loss: 0.00030657261959277093\n",
      "Epoch 1190, Loss: 0.0055145875085145235, Final Batch Loss: 0.0005308921681717038\n",
      "Epoch 1191, Loss: 0.011026303051039577, Final Batch Loss: 0.0003928965888917446\n",
      "Epoch 1192, Loss: 0.004006656614365056, Final Batch Loss: 0.000403510668547824\n",
      "Epoch 1193, Loss: 0.004793118328962009, Final Batch Loss: 6.918270810274407e-05\n",
      "Epoch 1194, Loss: 0.004287618328817189, Final Batch Loss: 0.0005148181226104498\n",
      "Epoch 1195, Loss: 0.0038957837969064713, Final Batch Loss: 0.0011072872439399362\n",
      "Epoch 1196, Loss: 0.003449904324952513, Final Batch Loss: 0.000179058697540313\n",
      "Epoch 1197, Loss: 0.022879143711179495, Final Batch Loss: 0.020294716581702232\n",
      "Epoch 1198, Loss: 0.030129943508654833, Final Batch Loss: 0.00024259602651000023\n",
      "Epoch 1199, Loss: 0.004634155367966741, Final Batch Loss: 0.0006147100939415395\n",
      "Epoch 1200, Loss: 0.01063732779584825, Final Batch Loss: 0.0067223249934613705\n",
      "Epoch 1201, Loss: 0.004317046899814159, Final Batch Loss: 0.0009380272240377963\n",
      "Epoch 1202, Loss: 0.014661799999885261, Final Batch Loss: 0.0008521733107045293\n",
      "Epoch 1203, Loss: 0.017204542993567884, Final Batch Loss: 0.00031542847864329815\n",
      "Epoch 1204, Loss: 0.04520397027954459, Final Batch Loss: 0.042317744344472885\n",
      "Epoch 1205, Loss: 0.01153000007616356, Final Batch Loss: 0.0004999065422452986\n",
      "Epoch 1206, Loss: 0.013209372831624933, Final Batch Loss: 0.00015196525782812387\n",
      "Epoch 1207, Loss: 0.29234514106065035, Final Batch Loss: 0.2492666244506836\n",
      "Epoch 1208, Loss: 0.03049340459983796, Final Batch Loss: 0.011127856560051441\n",
      "Epoch 1209, Loss: 0.006035997066646814, Final Batch Loss: 0.0016164592234417796\n",
      "Epoch 1210, Loss: 0.09154071705415845, Final Batch Loss: 0.06265673041343689\n",
      "Epoch 1211, Loss: 0.08308129804208875, Final Batch Loss: 0.06942325830459595\n",
      "Epoch 1212, Loss: 0.0067477039992809296, Final Batch Loss: 0.001299469149671495\n",
      "Epoch 1213, Loss: 0.014311782026197761, Final Batch Loss: 0.0002596941194497049\n",
      "Epoch 1214, Loss: 0.05361493770033121, Final Batch Loss: 0.0069084325805306435\n",
      "Epoch 1215, Loss: 0.0698611056432128, Final Batch Loss: 0.046322017908096313\n",
      "Epoch 1216, Loss: 0.0252854663413018, Final Batch Loss: 0.0031782423611730337\n",
      "Epoch 1217, Loss: 0.034478866029530764, Final Batch Loss: 0.02626093290746212\n",
      "Epoch 1218, Loss: 0.1611706076655537, Final Batch Loss: 0.15591458976268768\n",
      "Epoch 1219, Loss: 0.03624782944098115, Final Batch Loss: 0.005271823611110449\n",
      "Epoch 1220, Loss: 0.02550318493740633, Final Batch Loss: 0.000869942654389888\n",
      "Epoch 1221, Loss: 0.015949835535138845, Final Batch Loss: 0.0008508493192493916\n",
      "Epoch 1222, Loss: 0.02568714752487722, Final Batch Loss: 3.6711931898025796e-05\n",
      "Epoch 1223, Loss: 0.013156209839507937, Final Batch Loss: 0.0007738817948848009\n",
      "Epoch 1224, Loss: 0.02098082168959081, Final Batch Loss: 0.004236651584506035\n",
      "Epoch 1225, Loss: 0.006184077530633658, Final Batch Loss: 0.0004042900982312858\n",
      "Epoch 1226, Loss: 0.014242307399399579, Final Batch Loss: 0.0009395001688972116\n",
      "Epoch 1227, Loss: 0.01940005662618205, Final Batch Loss: 0.0005117544787935913\n",
      "Epoch 1228, Loss: 0.010337217179767322, Final Batch Loss: 0.00012097000580979511\n",
      "Epoch 1229, Loss: 0.015250577824190259, Final Batch Loss: 0.00119535974226892\n",
      "Epoch 1230, Loss: 0.009338411327917129, Final Batch Loss: 0.000901013903785497\n",
      "Epoch 1231, Loss: 0.011060920543968678, Final Batch Loss: 0.006443517282605171\n",
      "Epoch 1232, Loss: 0.01195417972303403, Final Batch Loss: 2.7654683435685e-05\n",
      "Epoch 1233, Loss: 0.0046867715427652, Final Batch Loss: 0.00035412271972745657\n",
      "Epoch 1234, Loss: 0.006377488549333066, Final Batch Loss: 0.0009637728217057884\n",
      "Epoch 1235, Loss: 0.1481053183088079, Final Batch Loss: 0.14158494770526886\n",
      "Epoch 1236, Loss: 0.022050648694857955, Final Batch Loss: 0.0006587866228073835\n",
      "Epoch 1237, Loss: 0.024602656019851565, Final Batch Loss: 0.0006106533110141754\n",
      "Epoch 1238, Loss: 0.03063902724534273, Final Batch Loss: 0.004193772096186876\n",
      "Epoch 1239, Loss: 0.03975697635905817, Final Batch Loss: 0.00011648639338091016\n",
      "Epoch 1240, Loss: 0.03317907894961536, Final Batch Loss: 0.0012418588157743216\n",
      "Epoch 1241, Loss: 0.019744369463296607, Final Batch Loss: 0.0003532849077600986\n",
      "Epoch 1242, Loss: 0.01003019162453711, Final Batch Loss: 0.0011841211235150695\n",
      "Epoch 1243, Loss: 0.009058563620783389, Final Batch Loss: 0.0015426274621859193\n",
      "Epoch 1244, Loss: 0.018934233114123344, Final Batch Loss: 0.002199791371822357\n",
      "Epoch 1245, Loss: 0.005476914928294718, Final Batch Loss: 0.0007240526610985398\n",
      "Epoch 1246, Loss: 0.011591088492423296, Final Batch Loss: 0.003101855982095003\n",
      "Epoch 1247, Loss: 0.00852192024467513, Final Batch Loss: 0.0008492646156810224\n",
      "Epoch 1248, Loss: 0.0306513337418437, Final Batch Loss: 0.01607169769704342\n",
      "Epoch 1249, Loss: 0.03653578204102814, Final Batch Loss: 0.00028242100961506367\n",
      "Epoch 1250, Loss: 0.016341988142812625, Final Batch Loss: 0.0002597315760795027\n",
      "Epoch 1251, Loss: 0.0065639622625894845, Final Batch Loss: 0.0002441472024656832\n",
      "Epoch 1252, Loss: 0.016214785282500088, Final Batch Loss: 0.0008796305628493428\n",
      "Epoch 1253, Loss: 0.014872029307298362, Final Batch Loss: 0.0016148186987265944\n",
      "Epoch 1254, Loss: 0.018990954078617506, Final Batch Loss: 0.00021322657994460315\n",
      "Epoch 1255, Loss: 0.007744148140773177, Final Batch Loss: 0.0004519348731264472\n",
      "Epoch 1256, Loss: 0.0059111027512699366, Final Batch Loss: 0.0015126854414120317\n",
      "Epoch 1257, Loss: 0.0025462055928073823, Final Batch Loss: 9.847356704995036e-05\n",
      "Epoch 1258, Loss: 0.006774475914426148, Final Batch Loss: 0.002008039504289627\n",
      "Epoch 1259, Loss: 0.005216270015807822, Final Batch Loss: 0.000248121825279668\n",
      "Epoch 1260, Loss: 0.005842883983859792, Final Batch Loss: 0.0003523199411574751\n",
      "Epoch 1261, Loss: 0.007334393099881709, Final Batch Loss: 0.0014425003901124\n",
      "Epoch 1262, Loss: 0.008319097301864531, Final Batch Loss: 0.00011422225361457095\n",
      "Epoch 1263, Loss: 0.004238277790136635, Final Batch Loss: 0.0010525798425078392\n",
      "Epoch 1264, Loss: 0.005048374630860053, Final Batch Loss: 0.00020842508820351213\n",
      "Epoch 1265, Loss: 0.007397188281174749, Final Batch Loss: 0.0005364773678593338\n",
      "Epoch 1266, Loss: 0.018778566387481987, Final Batch Loss: 0.0009831206407397985\n",
      "Epoch 1267, Loss: 0.018854865396860987, Final Batch Loss: 0.0001286692568100989\n",
      "Epoch 1268, Loss: 0.005078535294160247, Final Batch Loss: 0.000453230575658381\n",
      "Epoch 1269, Loss: 0.025271101090766024, Final Batch Loss: 9.807134483708069e-05\n",
      "Epoch 1270, Loss: 0.010223870631307364, Final Batch Loss: 0.008564958348870277\n",
      "Epoch 1271, Loss: 0.019520561036188155, Final Batch Loss: 0.0051782033406198025\n",
      "Epoch 1272, Loss: 0.004002948408015072, Final Batch Loss: 0.0004284869646653533\n",
      "Epoch 1273, Loss: 0.004733506415504962, Final Batch Loss: 0.0008549257763661444\n",
      "Epoch 1274, Loss: 0.002367829903960228, Final Batch Loss: 0.0009805219015106559\n",
      "Epoch 1275, Loss: 0.002825682233378757, Final Batch Loss: 0.00010292104707332328\n",
      "Epoch 1276, Loss: 0.0029457280761562288, Final Batch Loss: 0.0002633352414704859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277, Loss: 0.0037835556595382513, Final Batch Loss: 2.269780270580668e-05\n",
      "Epoch 1278, Loss: 0.014859101385809481, Final Batch Loss: 0.0006047117058187723\n",
      "Epoch 1279, Loss: 0.013684865174582228, Final Batch Loss: 0.00031024854979477823\n",
      "Epoch 1280, Loss: 0.015120852796826512, Final Batch Loss: 0.012448957189917564\n",
      "Epoch 1281, Loss: 0.005372471176087856, Final Batch Loss: 0.0002618107246235013\n",
      "Epoch 1282, Loss: 0.0026778149185702205, Final Batch Loss: 0.00019817380234599113\n",
      "Epoch 1283, Loss: 0.0038690792862325907, Final Batch Loss: 0.000260375440120697\n",
      "Epoch 1284, Loss: 0.009620052762329578, Final Batch Loss: 0.0022411730606108904\n",
      "Epoch 1285, Loss: 0.003870698405080475, Final Batch Loss: 0.00012316009087953717\n",
      "Epoch 1286, Loss: 0.014721649291459471, Final Batch Loss: 0.0007097859052009881\n",
      "Epoch 1287, Loss: 0.002716379123739898, Final Batch Loss: 0.0005613717949017882\n",
      "Epoch 1288, Loss: 0.0045752309742965735, Final Batch Loss: 0.00012199147749925032\n",
      "Epoch 1289, Loss: 0.023501875162764918, Final Batch Loss: 5.0064925744663924e-05\n",
      "Epoch 1290, Loss: 0.005967745382804424, Final Batch Loss: 0.00044399156467989087\n",
      "Epoch 1291, Loss: 0.006170317647047341, Final Batch Loss: 0.00029084912966936827\n",
      "Epoch 1292, Loss: 0.0028756655956385657, Final Batch Loss: 0.00019505950331222266\n",
      "Epoch 1293, Loss: 0.004621759115252644, Final Batch Loss: 0.0006395210511982441\n",
      "Epoch 1294, Loss: 0.016691807191818953, Final Batch Loss: 0.00501608569175005\n",
      "Epoch 1295, Loss: 0.01104763153125532, Final Batch Loss: 0.0002448607992846519\n",
      "Epoch 1296, Loss: 0.005010069347918034, Final Batch Loss: 0.0010142734972760081\n",
      "Epoch 1297, Loss: 0.005168617470189929, Final Batch Loss: 0.0018234805902466178\n",
      "Epoch 1298, Loss: 0.012812656976166181, Final Batch Loss: 7.582949183415622e-05\n",
      "Epoch 1299, Loss: 0.0043681663810275495, Final Batch Loss: 0.0004887407994829118\n",
      "Epoch 1300, Loss: 0.03504506521858275, Final Batch Loss: 0.03193340823054314\n",
      "Epoch 1301, Loss: 0.0016590199447819032, Final Batch Loss: 8.261160837719217e-05\n",
      "Epoch 1302, Loss: 0.015878140926361084, Final Batch Loss: 0.006395031698048115\n",
      "Epoch 1303, Loss: 0.005946890218183398, Final Batch Loss: 0.0012175237061455846\n",
      "Epoch 1304, Loss: 0.0034363562299404293, Final Batch Loss: 0.00046645585098303854\n",
      "Epoch 1305, Loss: 0.004844856302952394, Final Batch Loss: 0.00043354937224648893\n",
      "Epoch 1306, Loss: 0.03467648051446304, Final Batch Loss: 0.0005894791684113443\n",
      "Epoch 1307, Loss: 0.006416923803044483, Final Batch Loss: 0.00033352800528518856\n",
      "Epoch 1308, Loss: 0.0021968462970107794, Final Batch Loss: 0.00012275052722543478\n",
      "Epoch 1309, Loss: 0.0042948019108735025, Final Batch Loss: 4.503171658143401e-05\n",
      "Epoch 1310, Loss: 0.003872906556352973, Final Batch Loss: 5.9759593568742275e-05\n",
      "Epoch 1311, Loss: 0.00831432261475129, Final Batch Loss: 5.353788583306596e-05\n",
      "Epoch 1312, Loss: 0.003525889344018651, Final Batch Loss: 5.956842142040841e-05\n",
      "Epoch 1313, Loss: 0.011150540201924741, Final Batch Loss: 0.008720803074538708\n",
      "Epoch 1314, Loss: 0.00438095087883994, Final Batch Loss: 0.001156611368060112\n",
      "Epoch 1315, Loss: 0.013441152014820545, Final Batch Loss: 1.1982704563706648e-05\n",
      "Epoch 1316, Loss: 0.00393470965900633, Final Batch Loss: 2.0823046725126915e-05\n",
      "Epoch 1317, Loss: 0.006122136139310896, Final Batch Loss: 0.0010774735128507018\n",
      "Epoch 1318, Loss: 0.0021116605203133076, Final Batch Loss: 0.0002263618225697428\n",
      "Epoch 1319, Loss: 0.010844718999578618, Final Batch Loss: 0.00018819105753209442\n",
      "Epoch 1320, Loss: 0.017211645616043825, Final Batch Loss: 0.00011134113447042182\n",
      "Epoch 1321, Loss: 0.011134243221022189, Final Batch Loss: 0.007666208315640688\n",
      "Epoch 1322, Loss: 0.01185011321103957, Final Batch Loss: 1.6349762518075295e-05\n",
      "Epoch 1323, Loss: 0.003335659799631685, Final Batch Loss: 0.0013937114272266626\n",
      "Epoch 1324, Loss: 0.0024571792455390096, Final Batch Loss: 0.0005136022227816284\n",
      "Epoch 1325, Loss: 0.008567189681343734, Final Batch Loss: 0.006824092008173466\n",
      "Epoch 1326, Loss: 0.0020943629497196525, Final Batch Loss: 0.00021685476531274617\n",
      "Epoch 1327, Loss: 0.004724710335722193, Final Batch Loss: 0.00019161167438142002\n",
      "Epoch 1328, Loss: 0.0035253168316558003, Final Batch Loss: 0.00023277022410184145\n",
      "Epoch 1329, Loss: 0.004634272190742195, Final Batch Loss: 0.0022667311131954193\n",
      "Epoch 1330, Loss: 0.011117696471046656, Final Batch Loss: 0.0014353398000821471\n",
      "Epoch 1331, Loss: 0.002217388140707044, Final Batch Loss: 1.75853019754868e-05\n",
      "Epoch 1332, Loss: 0.0040225989650934935, Final Batch Loss: 0.001420825021341443\n",
      "Epoch 1333, Loss: 0.01870943330868613, Final Batch Loss: 0.00012703244283329695\n",
      "Epoch 1334, Loss: 0.0050933631137013435, Final Batch Loss: 0.0021914620883762836\n",
      "Epoch 1335, Loss: 0.006933241616934538, Final Batch Loss: 0.0031914457213133574\n",
      "Epoch 1336, Loss: 0.0030891122587490827, Final Batch Loss: 0.000439320137957111\n",
      "Epoch 1337, Loss: 0.004368684742075857, Final Batch Loss: 0.00010502410441404209\n",
      "Epoch 1338, Loss: 0.00247521951678209, Final Batch Loss: 9.915357804857194e-05\n",
      "Epoch 1339, Loss: 0.012035114290483762, Final Batch Loss: 3.508764348225668e-05\n",
      "Epoch 1340, Loss: 0.003941127342841355, Final Batch Loss: 5.163754030945711e-05\n",
      "Epoch 1341, Loss: 0.011326100182486698, Final Batch Loss: 0.00022670257021673024\n",
      "Epoch 1342, Loss: 0.007064177538268268, Final Batch Loss: 0.00028710695914924145\n",
      "Epoch 1343, Loss: 0.002772504381937324, Final Batch Loss: 2.503753603377845e-05\n",
      "Epoch 1344, Loss: 0.0011824684625025839, Final Batch Loss: 0.0002057488600257784\n",
      "Epoch 1345, Loss: 0.003678648849017918, Final Batch Loss: 0.0017818587366491556\n",
      "Epoch 1346, Loss: 0.0028000730308122, Final Batch Loss: 6.0644342738669366e-05\n",
      "Epoch 1347, Loss: 0.004138809919822961, Final Batch Loss: 0.0009731171885505319\n",
      "Epoch 1348, Loss: 0.009458988788537681, Final Batch Loss: 0.0009199493797495961\n",
      "Epoch 1349, Loss: 0.0022789137437939644, Final Batch Loss: 0.0004144227132201195\n",
      "Epoch 1350, Loss: 0.015975185058778152, Final Batch Loss: 0.00020047961152158678\n",
      "Epoch 1351, Loss: 0.006071057869121432, Final Batch Loss: 0.0011296082520857453\n",
      "Epoch 1352, Loss: 0.0035761986509896815, Final Batch Loss: 0.0017981847049668431\n",
      "Epoch 1353, Loss: 0.0027569422018132173, Final Batch Loss: 1.796811557142064e-05\n",
      "Epoch 1354, Loss: 0.0028965845922357403, Final Batch Loss: 7.617935625603423e-05\n",
      "Epoch 1355, Loss: 0.010906255396548659, Final Batch Loss: 0.0006223997916094959\n",
      "Epoch 1356, Loss: 0.0029615327366627753, Final Batch Loss: 0.0004944003303535283\n",
      "Epoch 1357, Loss: 0.001987383235245943, Final Batch Loss: 0.0004857700550928712\n",
      "Epoch 1358, Loss: 0.002352704483200796, Final Batch Loss: 0.00021128235675860196\n",
      "Epoch 1359, Loss: 0.002111549023538828, Final Batch Loss: 0.0006492831162177026\n",
      "Epoch 1360, Loss: 0.00867636880138889, Final Batch Loss: 0.0016849478706717491\n",
      "Epoch 1361, Loss: 0.003737292696314398, Final Batch Loss: 0.00011301096674287692\n",
      "Epoch 1362, Loss: 0.007655533845536411, Final Batch Loss: 0.0012340216198936105\n",
      "Epoch 1363, Loss: 0.0028513716242741793, Final Batch Loss: 0.0003388386976439506\n",
      "Epoch 1364, Loss: 0.0021597155136987567, Final Batch Loss: 0.0007774859550409019\n",
      "Epoch 1365, Loss: 0.002369312656810507, Final Batch Loss: 0.0012390556512400508\n",
      "Epoch 1366, Loss: 0.015468944271560758, Final Batch Loss: 0.0008786090184003115\n",
      "Epoch 1367, Loss: 0.004500974551774561, Final Batch Loss: 0.002053778385743499\n",
      "Epoch 1368, Loss: 0.01466809818521142, Final Batch Loss: 0.0012984313070774078\n",
      "Epoch 1369, Loss: 0.009734236693475395, Final Batch Loss: 0.007725722622126341\n",
      "Epoch 1370, Loss: 0.0024870516499504447, Final Batch Loss: 0.0010840488830581307\n",
      "Epoch 1371, Loss: 0.0051072671776637435, Final Batch Loss: 0.00027485599275678396\n",
      "Epoch 1372, Loss: 0.005454108235426247, Final Batch Loss: 0.00030472473008558154\n",
      "Epoch 1373, Loss: 0.0038279708242043853, Final Batch Loss: 0.0006355862715281546\n",
      "Epoch 1374, Loss: 0.01158358970133122, Final Batch Loss: 0.00012185859668534249\n",
      "Epoch 1375, Loss: 0.010124245920451358, Final Batch Loss: 1.8030666979029775e-05\n",
      "Epoch 1376, Loss: 0.001022864908009069, Final Batch Loss: 1.846319719334133e-05\n",
      "Epoch 1377, Loss: 0.00709410694980761, Final Batch Loss: 9.493281686445698e-05\n",
      "Epoch 1378, Loss: 0.18971137353219092, Final Batch Loss: 0.1856110394001007\n",
      "Epoch 1379, Loss: 0.0035552299523260444, Final Batch Loss: 6.927989306859672e-05\n",
      "Epoch 1380, Loss: 0.017351573307678336, Final Batch Loss: 3.675461994134821e-05\n",
      "Epoch 1381, Loss: 0.02827699459157884, Final Batch Loss: 0.0003015317488461733\n",
      "Epoch 1382, Loss: 0.0058152690035058185, Final Batch Loss: 3.289982851129025e-05\n",
      "Epoch 1383, Loss: 0.011517349863424897, Final Batch Loss: 0.00011404533870518208\n",
      "Epoch 1384, Loss: 0.01746142326737754, Final Batch Loss: 0.00031154006137512624\n",
      "Epoch 1385, Loss: 0.007597369825816713, Final Batch Loss: 0.0001326880737906322\n",
      "Epoch 1386, Loss: 0.003403430397156626, Final Batch Loss: 0.00015355425421148539\n",
      "Epoch 1387, Loss: 0.003322528373246314, Final Batch Loss: 1.1054788046749309e-05\n",
      "Epoch 1388, Loss: 0.003244537307182327, Final Batch Loss: 0.00032041131635196507\n",
      "Epoch 1389, Loss: 0.003430828684940934, Final Batch Loss: 0.0001968874130398035\n",
      "Epoch 1390, Loss: 0.004735164933663327, Final Batch Loss: 3.1045528885442764e-05\n",
      "Epoch 1391, Loss: 0.006705436739139259, Final Batch Loss: 0.00035588518949225545\n",
      "Epoch 1392, Loss: 0.04508300038287416, Final Batch Loss: 0.0005091250059194863\n",
      "Epoch 1393, Loss: 0.020721416745800525, Final Batch Loss: 0.0052397907711565495\n",
      "Epoch 1394, Loss: 0.004042643413413316, Final Batch Loss: 0.002366823609918356\n",
      "Epoch 1395, Loss: 0.007574049639515579, Final Batch Loss: 0.0034685044083744287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1396, Loss: 0.015503479109611362, Final Batch Loss: 0.013458412140607834\n",
      "Epoch 1397, Loss: 0.009617012285161763, Final Batch Loss: 0.0006852003862150013\n",
      "Epoch 1398, Loss: 0.010279138921760023, Final Batch Loss: 0.00040105043444782495\n",
      "Epoch 1399, Loss: 0.005161758046597242, Final Batch Loss: 0.0009134337306022644\n",
      "Epoch 1400, Loss: 0.37501590431202203, Final Batch Loss: 0.37390321493148804\n",
      "Epoch 1401, Loss: 0.006743648322299123, Final Batch Loss: 0.001088651129975915\n",
      "Epoch 1402, Loss: 0.02064245578367263, Final Batch Loss: 0.0013444061623886228\n",
      "Epoch 1403, Loss: 0.11953865014947951, Final Batch Loss: 0.0002628492657095194\n",
      "Epoch 1404, Loss: 0.06547919451259077, Final Batch Loss: 0.0002549027558416128\n",
      "Epoch 1405, Loss: 0.0068433855776675045, Final Batch Loss: 0.0006045005866326392\n",
      "Epoch 1406, Loss: 0.005364190197724383, Final Batch Loss: 7.495836325688288e-05\n",
      "Epoch 1407, Loss: 0.02751474385149777, Final Batch Loss: 0.0020190675277262926\n",
      "Epoch 1408, Loss: 0.01724803214892745, Final Batch Loss: 0.0023363649379462004\n",
      "Epoch 1409, Loss: 0.023004631861113012, Final Batch Loss: 0.0013800985179841518\n",
      "Epoch 1410, Loss: 0.016650209865474608, Final Batch Loss: 6.386773748090491e-05\n",
      "Epoch 1411, Loss: 0.005357516418371233, Final Batch Loss: 1.890184466901701e-05\n",
      "Epoch 1412, Loss: 0.00924239747109823, Final Batch Loss: 0.0004061332147102803\n",
      "Epoch 1413, Loss: 0.013316090102307498, Final Batch Loss: 0.002273227320984006\n",
      "Epoch 1414, Loss: 0.07845147117041051, Final Batch Loss: 0.06885682791471481\n",
      "Epoch 1415, Loss: 0.003519777092151344, Final Batch Loss: 0.0008075408404693007\n",
      "Epoch 1416, Loss: 0.018054918233247008, Final Batch Loss: 5.4799798817839473e-05\n",
      "Epoch 1417, Loss: 0.035824176855385303, Final Batch Loss: 0.0034125526435673237\n",
      "Epoch 1418, Loss: 0.2658904475392774, Final Batch Loss: 0.2328513115644455\n",
      "Epoch 1419, Loss: 0.03853154843818629, Final Batch Loss: 6.357915845001116e-05\n",
      "Epoch 1420, Loss: 0.006090038295951672, Final Batch Loss: 0.00015366410661954433\n",
      "Epoch 1421, Loss: 0.0187949372921139, Final Batch Loss: 0.0006292727775871754\n",
      "Epoch 1422, Loss: 0.01487645209999755, Final Batch Loss: 0.00034217286156490445\n",
      "Epoch 1423, Loss: 0.0151831628754735, Final Batch Loss: 0.00544546265155077\n",
      "Epoch 1424, Loss: 0.03560767963062972, Final Batch Loss: 0.028540775179862976\n",
      "Epoch 1425, Loss: 0.025906893890351057, Final Batch Loss: 0.01547988597303629\n",
      "Epoch 1426, Loss: 0.007454588299879106, Final Batch Loss: 3.946455035475083e-05\n",
      "Epoch 1427, Loss: 0.00730256934184581, Final Batch Loss: 0.0031176016200333834\n",
      "Epoch 1428, Loss: 0.0030385337668121792, Final Batch Loss: 8.546960452804342e-05\n",
      "Epoch 1429, Loss: 0.0036956901312805712, Final Batch Loss: 0.0006611479329876602\n",
      "Epoch 1430, Loss: 0.03358484199270606, Final Batch Loss: 0.004536143038421869\n",
      "Epoch 1431, Loss: 0.01843036711215973, Final Batch Loss: 0.007436838001012802\n",
      "Epoch 1432, Loss: 0.004714521870482713, Final Batch Loss: 0.0003675070474855602\n",
      "Epoch 1433, Loss: 0.008061302592977881, Final Batch Loss: 0.006003368645906448\n",
      "Epoch 1434, Loss: 0.002939895275630988, Final Batch Loss: 0.00015960635209921747\n",
      "Epoch 1435, Loss: 0.0037312962958822027, Final Batch Loss: 0.00021041360741946846\n",
      "Epoch 1436, Loss: 0.002936642471468076, Final Batch Loss: 0.0002666577638592571\n",
      "Epoch 1437, Loss: 0.0041289604268968105, Final Batch Loss: 0.001902078278362751\n",
      "Epoch 1438, Loss: 0.005234356067376211, Final Batch Loss: 9.566082735545933e-05\n",
      "Epoch 1439, Loss: 0.01135164947481826, Final Batch Loss: 0.0053679561242461205\n",
      "Epoch 1440, Loss: 0.006968676898395643, Final Batch Loss: 0.0002611210511531681\n",
      "Epoch 1441, Loss: 0.2085710286628455, Final Batch Loss: 0.2021024227142334\n",
      "Epoch 1442, Loss: 0.003242991995648481, Final Batch Loss: 0.00015023590822238475\n",
      "Epoch 1443, Loss: 0.002786367083899677, Final Batch Loss: 0.00027354550547897816\n",
      "Epoch 1444, Loss: 0.004862199893977959, Final Batch Loss: 5.490054172696546e-05\n",
      "Epoch 1445, Loss: 0.014347451622597873, Final Batch Loss: 0.004859864711761475\n",
      "Epoch 1446, Loss: 0.016963700734777376, Final Batch Loss: 0.0003797958779614419\n",
      "Epoch 1447, Loss: 0.02106068143621087, Final Batch Loss: 0.016466576606035233\n",
      "Epoch 1448, Loss: 0.004137345182243735, Final Batch Loss: 0.0005885044229216874\n",
      "Epoch 1449, Loss: 0.0049539124775037635, Final Batch Loss: 4.891179924015887e-05\n",
      "Epoch 1450, Loss: 0.00971017635311, Final Batch Loss: 0.00028245619614608586\n",
      "Epoch 1451, Loss: 0.007347493432462215, Final Batch Loss: 0.0004229508340358734\n",
      "Epoch 1452, Loss: 0.023099038749933243, Final Batch Loss: 0.0031555527821183205\n",
      "Epoch 1453, Loss: 0.004379388832603581, Final Batch Loss: 0.0001308789214817807\n",
      "Epoch 1454, Loss: 0.061915646540001035, Final Batch Loss: 0.05454758554697037\n",
      "Epoch 1455, Loss: 0.018015207489952445, Final Batch Loss: 0.007272522896528244\n",
      "Epoch 1456, Loss: 0.019915796641726047, Final Batch Loss: 0.00012286874698475003\n",
      "Epoch 1457, Loss: 0.07581236661644652, Final Batch Loss: 0.0006304465350694954\n",
      "Epoch 1458, Loss: 0.01543557841796428, Final Batch Loss: 0.0006849529454484582\n",
      "Epoch 1459, Loss: 0.00516779741155915, Final Batch Loss: 0.00023921995307318866\n",
      "Epoch 1460, Loss: 0.017607860965654254, Final Batch Loss: 0.001396689796820283\n",
      "Epoch 1461, Loss: 0.01428284464054741, Final Batch Loss: 0.0002854130289051682\n",
      "Epoch 1462, Loss: 0.011868216737639159, Final Batch Loss: 0.004091496579349041\n",
      "Epoch 1463, Loss: 0.016212493210332468, Final Batch Loss: 0.00022304060985334218\n",
      "Epoch 1464, Loss: 0.010865688207559288, Final Batch Loss: 0.0004721410805359483\n",
      "Epoch 1465, Loss: 0.0028852585310232826, Final Batch Loss: 4.9386297177989036e-05\n",
      "Epoch 1466, Loss: 0.0026265739143127576, Final Batch Loss: 0.00020407095144037157\n",
      "Epoch 1467, Loss: 0.010661013904609717, Final Batch Loss: 0.00011992153304163367\n",
      "Epoch 1468, Loss: 0.007193197787273675, Final Batch Loss: 9.825133020058274e-05\n",
      "Epoch 1469, Loss: 0.005577409243414877, Final Batch Loss: 5.149778371560387e-05\n",
      "Epoch 1470, Loss: 0.0052988852257840335, Final Batch Loss: 0.00037713703932240605\n",
      "Epoch 1471, Loss: 0.03452085889875889, Final Batch Loss: 0.0003839717246592045\n",
      "Epoch 1472, Loss: 0.014173714182106778, Final Batch Loss: 0.012763428501784801\n",
      "Epoch 1473, Loss: 0.004307461087591946, Final Batch Loss: 0.0004662120481953025\n",
      "Epoch 1474, Loss: 0.005223850421316456, Final Batch Loss: 0.00010380829189671203\n",
      "Epoch 1475, Loss: 0.01633040199521929, Final Batch Loss: 0.00048469752073287964\n",
      "Epoch 1476, Loss: 0.003211640112567693, Final Batch Loss: 0.0009596720337867737\n",
      "Epoch 1477, Loss: 0.0051087046740576625, Final Batch Loss: 0.0017797881737351418\n",
      "Epoch 1478, Loss: 0.03941615903750062, Final Batch Loss: 0.0013656453229486942\n",
      "Epoch 1479, Loss: 0.009882410522550344, Final Batch Loss: 0.0010503384983167052\n",
      "Epoch 1480, Loss: 0.006854460574686527, Final Batch Loss: 0.002205638913437724\n",
      "Epoch 1481, Loss: 0.0043401706498116255, Final Batch Loss: 0.0016476629534736276\n",
      "Epoch 1482, Loss: 0.0037039112139609642, Final Batch Loss: 4.553679173113778e-05\n",
      "Epoch 1483, Loss: 0.01444096786872251, Final Batch Loss: 6.870918878121302e-05\n",
      "Epoch 1484, Loss: 0.014485499472357333, Final Batch Loss: 0.008809802122414112\n",
      "Epoch 1485, Loss: 0.010780792537843809, Final Batch Loss: 0.003161031985655427\n",
      "Epoch 1486, Loss: 0.010698400612454861, Final Batch Loss: 0.00018197746248915792\n",
      "Epoch 1487, Loss: 0.008825625787721947, Final Batch Loss: 0.00045721346396021545\n",
      "Epoch 1488, Loss: 0.0034671042230911553, Final Batch Loss: 0.0013777684653177857\n",
      "Epoch 1489, Loss: 0.005734826787374914, Final Batch Loss: 0.0034864144399762154\n",
      "Epoch 1490, Loss: 0.006508658989332616, Final Batch Loss: 0.004136660601943731\n",
      "Epoch 1491, Loss: 0.0015435002169397194, Final Batch Loss: 3.3912529033841565e-05\n",
      "Epoch 1492, Loss: 0.004719372952422418, Final Batch Loss: 1.434213208995061e-05\n",
      "Epoch 1493, Loss: 0.003890625885105692, Final Batch Loss: 0.00018283519602846354\n",
      "Epoch 1494, Loss: 0.0022813409559603315, Final Batch Loss: 5.894335845368914e-05\n",
      "Epoch 1495, Loss: 0.003640823357272893, Final Batch Loss: 0.0016187699511647224\n",
      "Epoch 1496, Loss: 0.005162348912563175, Final Batch Loss: 0.0030973460525274277\n",
      "Epoch 1497, Loss: 0.00482933074090397, Final Batch Loss: 0.00010572969767963514\n",
      "Epoch 1498, Loss: 0.004579624161124229, Final Batch Loss: 0.0006322370609268546\n",
      "Epoch 1499, Loss: 0.009879673889372498, Final Batch Loss: 0.0004942957893945277\n",
      "Epoch 1500, Loss: 0.002787528617773205, Final Batch Loss: 0.00038163462886586785\n",
      "Epoch 1501, Loss: 0.007215512916445732, Final Batch Loss: 0.00016788090579211712\n",
      "Epoch 1502, Loss: 0.00382994522806257, Final Batch Loss: 0.0007014409638941288\n",
      "Epoch 1503, Loss: 0.005036326590925455, Final Batch Loss: 0.0016520447097718716\n",
      "Epoch 1504, Loss: 0.002981288158480311, Final Batch Loss: 2.4867975298548117e-05\n",
      "Epoch 1505, Loss: 0.0029157725512050092, Final Batch Loss: 0.00020071695325896144\n",
      "Epoch 1506, Loss: 0.0032185804448090494, Final Batch Loss: 0.00038408429827541113\n",
      "Epoch 1507, Loss: 0.003941691946238279, Final Batch Loss: 0.0009816365782171488\n",
      "Epoch 1508, Loss: 0.0032586344168521464, Final Batch Loss: 0.0011682197218760848\n",
      "Epoch 1509, Loss: 0.0018104573828168213, Final Batch Loss: 0.0006724831182509661\n",
      "Epoch 1510, Loss: 0.002200610697400407, Final Batch Loss: 2.178159229515586e-05\n",
      "Epoch 1511, Loss: 0.008514552493579686, Final Batch Loss: 0.007146180607378483\n",
      "Epoch 1512, Loss: 0.0015396800445159897, Final Batch Loss: 0.000121794015285559\n",
      "Epoch 1513, Loss: 0.004055999175761826, Final Batch Loss: 2.40517983911559e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1514, Loss: 0.002486822195351124, Final Batch Loss: 0.0003178867045789957\n",
      "Epoch 1515, Loss: 0.0017675654744380154, Final Batch Loss: 0.0001207559325848706\n",
      "Epoch 1516, Loss: 0.03343816532287747, Final Batch Loss: 0.0035070122685283422\n",
      "Epoch 1517, Loss: 0.0078024271642789245, Final Batch Loss: 0.005900780204683542\n",
      "Epoch 1518, Loss: 0.0012689375143963844, Final Batch Loss: 0.000497103319503367\n",
      "Epoch 1519, Loss: 0.019842766574583948, Final Batch Loss: 0.002902901964262128\n",
      "Epoch 1520, Loss: 0.009080433868803084, Final Batch Loss: 0.0003428896889090538\n",
      "Epoch 1521, Loss: 0.0035543160483939573, Final Batch Loss: 0.0001148736773757264\n",
      "Epoch 1522, Loss: 0.012900259089292376, Final Batch Loss: 2.092906470352318e-05\n",
      "Epoch 1523, Loss: 0.0011631462330115028, Final Batch Loss: 8.106046152533963e-05\n",
      "Epoch 1524, Loss: 0.0028682919510174543, Final Batch Loss: 0.0006418005214072764\n",
      "Epoch 1525, Loss: 0.02453929651528597, Final Batch Loss: 0.0016733758384361863\n",
      "Epoch 1526, Loss: 0.0025740996352396905, Final Batch Loss: 0.0006633276934735477\n",
      "Epoch 1527, Loss: 0.00840551991132088, Final Batch Loss: 0.007547526620328426\n",
      "Epoch 1528, Loss: 0.004759891704452457, Final Batch Loss: 4.473422450246289e-06\n",
      "Epoch 1529, Loss: 0.004291486504371278, Final Batch Loss: 0.00017751978884916753\n",
      "Epoch 1530, Loss: 0.015950362489093095, Final Batch Loss: 0.00022861809702590108\n",
      "Epoch 1531, Loss: 0.0022767047630622983, Final Batch Loss: 0.00013857887824997306\n",
      "Epoch 1532, Loss: 0.0038547570511582308, Final Batch Loss: 2.4197091988753527e-05\n",
      "Epoch 1533, Loss: 0.009395676461281255, Final Batch Loss: 0.0002017028455156833\n",
      "Epoch 1534, Loss: 0.015658036863896996, Final Batch Loss: 0.004183243960142136\n",
      "Epoch 1535, Loss: 0.0019155102490913123, Final Batch Loss: 0.0004501819785218686\n",
      "Epoch 1536, Loss: 0.008165206148987636, Final Batch Loss: 0.00044598127715289593\n",
      "Epoch 1537, Loss: 0.0072573956567794085, Final Batch Loss: 0.0005793761229142547\n",
      "Epoch 1538, Loss: 0.0018372941340203397, Final Batch Loss: 7.663526776013896e-05\n",
      "Epoch 1539, Loss: 0.01270260777164367, Final Batch Loss: 5.951441198703833e-05\n",
      "Epoch 1540, Loss: 0.002722140750847757, Final Batch Loss: 0.0009032064117491245\n",
      "Epoch 1541, Loss: 0.0069468267138290685, Final Batch Loss: 3.463135726633482e-05\n",
      "Epoch 1542, Loss: 0.0018105923300026916, Final Batch Loss: 2.427252911729738e-05\n",
      "Epoch 1543, Loss: 0.0015992276967153884, Final Batch Loss: 0.00010732303053373471\n",
      "Epoch 1544, Loss: 0.002110433211782947, Final Batch Loss: 0.0010758565040305257\n",
      "Epoch 1545, Loss: 0.003386027936358005, Final Batch Loss: 0.00021572335390374064\n",
      "Epoch 1546, Loss: 0.0013141261879354715, Final Batch Loss: 2.9836781322956085e-05\n",
      "Epoch 1547, Loss: 0.003981593074058765, Final Batch Loss: 3.8146481529111043e-06\n",
      "Epoch 1548, Loss: 0.00750921611324884, Final Batch Loss: 0.0002509983314666897\n",
      "Epoch 1549, Loss: 0.0038930404944039765, Final Batch Loss: 1.3357343959796708e-05\n",
      "Epoch 1550, Loss: 0.007154337734391447, Final Batch Loss: 5.078748654341325e-05\n",
      "Epoch 1551, Loss: 0.0011672434047795832, Final Batch Loss: 0.00021211420244071633\n",
      "Epoch 1552, Loss: 0.0008057367704168428, Final Batch Loss: 6.089177986723371e-05\n",
      "Epoch 1553, Loss: 0.011317203112412244, Final Batch Loss: 0.0003283327096141875\n",
      "Epoch 1554, Loss: 0.002070555536192842, Final Batch Loss: 0.00013981615484226495\n",
      "Epoch 1555, Loss: 0.012675005826167762, Final Batch Loss: 0.0030234709847718477\n",
      "Epoch 1556, Loss: 0.01740707906719763, Final Batch Loss: 0.00014624612231273204\n",
      "Epoch 1557, Loss: 0.29339333350071684, Final Batch Loss: 0.290347158908844\n",
      "Epoch 1558, Loss: 0.015293996053515002, Final Batch Loss: 0.0002575679391156882\n",
      "Epoch 1559, Loss: 0.027759003220126033, Final Batch Loss: 0.0009028132189996541\n",
      "Epoch 1560, Loss: 0.20614636316895485, Final Batch Loss: 0.11547472327947617\n",
      "Epoch 1561, Loss: 0.03478324742172845, Final Batch Loss: 0.0003872772504109889\n",
      "Epoch 1562, Loss: 0.003913893408025615, Final Batch Loss: 0.00023682885512243956\n",
      "Epoch 1563, Loss: 0.013752062470302917, Final Batch Loss: 0.00013291255163494498\n",
      "Epoch 1564, Loss: 0.07718140713404864, Final Batch Loss: 0.0009601282654330134\n",
      "Epoch 1565, Loss: 0.06492085610807408, Final Batch Loss: 0.0001356978464173153\n",
      "Epoch 1566, Loss: 0.02233660058118403, Final Batch Loss: 0.0005655151326209307\n",
      "Epoch 1567, Loss: 0.026464229682460427, Final Batch Loss: 0.002753726439550519\n",
      "Epoch 1568, Loss: 0.023192127351649106, Final Batch Loss: 0.0012979364255443215\n",
      "Epoch 1569, Loss: 0.025741856810782338, Final Batch Loss: 4.965465996065177e-05\n",
      "Epoch 1570, Loss: 0.03508783783763647, Final Batch Loss: 0.0020178041886538267\n",
      "Epoch 1571, Loss: 0.03788143675774336, Final Batch Loss: 0.0006046360358595848\n",
      "Epoch 1572, Loss: 0.02296192874200642, Final Batch Loss: 0.01278962753713131\n",
      "Epoch 1573, Loss: 0.007526308199885534, Final Batch Loss: 5.5709988373564556e-05\n",
      "Epoch 1574, Loss: 0.01178695634007454, Final Batch Loss: 0.004578010644763708\n",
      "Epoch 1575, Loss: 0.006694671930745244, Final Batch Loss: 0.0026855359319597483\n",
      "Epoch 1576, Loss: 0.006637372491240967, Final Batch Loss: 2.3589418560732156e-05\n",
      "Epoch 1577, Loss: 0.009669271297752857, Final Batch Loss: 0.0006648151320405304\n",
      "Epoch 1578, Loss: 0.04540216224268079, Final Batch Loss: 0.0010741041041910648\n",
      "Epoch 1579, Loss: 0.009201318840496242, Final Batch Loss: 0.001497127115726471\n",
      "Epoch 1580, Loss: 0.007761786982882768, Final Batch Loss: 0.005923092365264893\n",
      "Epoch 1581, Loss: 0.003723040907061659, Final Batch Loss: 0.00023281363246496767\n",
      "Epoch 1582, Loss: 0.004406681666296208, Final Batch Loss: 1.0508960258448496e-05\n",
      "Epoch 1583, Loss: 0.0027708181660273112, Final Batch Loss: 0.00010405129432911053\n",
      "Epoch 1584, Loss: 0.020404219685588032, Final Batch Loss: 0.00047355855349451303\n",
      "Epoch 1585, Loss: 0.004099802725249901, Final Batch Loss: 0.00029794618603773415\n",
      "Epoch 1586, Loss: 0.002552443831518758, Final Batch Loss: 0.00011901360267074779\n",
      "Epoch 1587, Loss: 0.007706999749643728, Final Batch Loss: 0.0004058510239701718\n",
      "Epoch 1588, Loss: 0.08194112469209358, Final Batch Loss: 0.07909458875656128\n",
      "Epoch 1589, Loss: 0.0029365001246333122, Final Batch Loss: 0.00017803919035941362\n",
      "Epoch 1590, Loss: 0.0694680001179222, Final Batch Loss: 0.0004091830051038414\n",
      "Epoch 1591, Loss: 0.0962658500066027, Final Batch Loss: 0.00048632302787154913\n",
      "Epoch 1592, Loss: 0.11356577184051275, Final Batch Loss: 0.06786902993917465\n",
      "Epoch 1593, Loss: 0.018221800040919334, Final Batch Loss: 0.0006985462387092412\n",
      "Epoch 1594, Loss: 0.03496164968237281, Final Batch Loss: 0.0020056678913533688\n",
      "Epoch 1595, Loss: 0.05797004047781229, Final Batch Loss: 0.012376155704259872\n",
      "Epoch 1596, Loss: 0.08855400327593088, Final Batch Loss: 0.036970436573028564\n",
      "Epoch 1597, Loss: 0.03304664604365826, Final Batch Loss: 0.015747077763080597\n",
      "Epoch 1598, Loss: 0.033583014737814665, Final Batch Loss: 0.0005837134085595608\n",
      "Epoch 1599, Loss: 0.01906019006855786, Final Batch Loss: 0.0031003437470644712\n",
      "Epoch 1600, Loss: 0.03187384537886828, Final Batch Loss: 0.00019694108050316572\n",
      "Epoch 1601, Loss: 0.0385222639888525, Final Batch Loss: 0.0008402243256568909\n",
      "Epoch 1602, Loss: 0.07597369467839599, Final Batch Loss: 0.04515386372804642\n",
      "Epoch 1603, Loss: 0.005734772508731112, Final Batch Loss: 0.00042879217653535306\n",
      "Epoch 1604, Loss: 0.29664175398647785, Final Batch Loss: 0.26893171668052673\n",
      "Epoch 1605, Loss: 0.014805700979195535, Final Batch Loss: 0.006204601842910051\n",
      "Epoch 1606, Loss: 0.01661162229720503, Final Batch Loss: 0.0018446448957547545\n",
      "Epoch 1607, Loss: 0.012122064203140326, Final Batch Loss: 0.00020177436817903072\n",
      "Epoch 1608, Loss: 0.010066506452858448, Final Batch Loss: 0.003532902104780078\n",
      "Epoch 1609, Loss: 0.04484991042409092, Final Batch Loss: 0.028183134272694588\n",
      "Epoch 1610, Loss: 0.011937393224798143, Final Batch Loss: 0.004074413329362869\n",
      "Epoch 1611, Loss: 0.0136986228171736, Final Batch Loss: 0.0033949052449315786\n",
      "Epoch 1612, Loss: 0.014406176556803985, Final Batch Loss: 3.2051739253802225e-05\n",
      "Epoch 1613, Loss: 0.006975458876695484, Final Batch Loss: 0.00024846516316756606\n",
      "Epoch 1614, Loss: 0.006920292631548364, Final Batch Loss: 7.600396202178672e-05\n",
      "Epoch 1615, Loss: 0.024885427439585328, Final Batch Loss: 0.002783733420073986\n",
      "Epoch 1616, Loss: 0.02021154911199119, Final Batch Loss: 4.00513963541016e-05\n",
      "Epoch 1617, Loss: 0.003533631024765782, Final Batch Loss: 0.00016812786634545773\n",
      "Epoch 1618, Loss: 0.007011403591604903, Final Batch Loss: 0.0001712064549792558\n",
      "Epoch 1619, Loss: 0.008143361890688539, Final Batch Loss: 0.0018061238806694746\n",
      "Epoch 1620, Loss: 0.008111435803584754, Final Batch Loss: 0.0013871478149667382\n",
      "Epoch 1621, Loss: 0.0036288787669036537, Final Batch Loss: 0.00046320960973389447\n",
      "Epoch 1622, Loss: 0.00799006378656486, Final Batch Loss: 9.435046376893297e-05\n",
      "Epoch 1623, Loss: 0.023151962435804307, Final Batch Loss: 0.0005550003843382001\n",
      "Epoch 1624, Loss: 0.011195342056453228, Final Batch Loss: 0.0035481469240039587\n",
      "Epoch 1625, Loss: 0.007933163607958704, Final Batch Loss: 0.00518075143918395\n",
      "Epoch 1626, Loss: 0.003392459089809563, Final Batch Loss: 7.274941162904724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1627, Loss: 0.0055102541809901595, Final Batch Loss: 0.0005625445628538728\n",
      "Epoch 1628, Loss: 0.006342638786009047, Final Batch Loss: 7.795802230248228e-05\n",
      "Epoch 1629, Loss: 0.004377626697532833, Final Batch Loss: 0.0010004546493291855\n",
      "Epoch 1630, Loss: 0.005354898690711707, Final Batch Loss: 0.002880838932469487\n",
      "Epoch 1631, Loss: 0.009371170308440924, Final Batch Loss: 0.002353828167542815\n",
      "Epoch 1632, Loss: 0.004595631151460111, Final Batch Loss: 0.0015433672815561295\n",
      "Epoch 1633, Loss: 0.004841973539441824, Final Batch Loss: 0.001014276989735663\n",
      "Epoch 1634, Loss: 0.02130662224953994, Final Batch Loss: 0.0005153060774318874\n",
      "Epoch 1635, Loss: 0.0033906190074048936, Final Batch Loss: 0.0010959906503558159\n",
      "Epoch 1636, Loss: 0.015190511127002537, Final Batch Loss: 0.007890003733336926\n",
      "Epoch 1637, Loss: 0.002775729284621775, Final Batch Loss: 0.00030562630854547024\n",
      "Epoch 1638, Loss: 0.024957065121270716, Final Batch Loss: 0.021564846858382225\n",
      "Epoch 1639, Loss: 0.007186533999629319, Final Batch Loss: 0.005247546825557947\n",
      "Epoch 1640, Loss: 0.0016043535724747926, Final Batch Loss: 0.0003499897138681263\n",
      "Epoch 1641, Loss: 0.00308336692978628, Final Batch Loss: 0.00039390698657371104\n",
      "Epoch 1642, Loss: 0.010619696229696274, Final Batch Loss: 0.00272736675105989\n",
      "Epoch 1643, Loss: 0.008121936785755679, Final Batch Loss: 0.0004417646850924939\n",
      "Epoch 1644, Loss: 0.03666535054799169, Final Batch Loss: 0.03497403487563133\n",
      "Epoch 1645, Loss: 0.0033439536346122622, Final Batch Loss: 0.0010082381777465343\n",
      "Epoch 1646, Loss: 0.0029028781573288143, Final Batch Loss: 0.00034272007178515196\n",
      "Epoch 1647, Loss: 0.013609385467134416, Final Batch Loss: 0.009198692627251148\n",
      "Epoch 1648, Loss: 0.0022815494376118295, Final Batch Loss: 0.00011400254879845306\n",
      "Epoch 1649, Loss: 0.016178594436496496, Final Batch Loss: 0.007846730761229992\n",
      "Epoch 1650, Loss: 0.013017791381571442, Final Batch Loss: 0.000168057216797024\n",
      "Epoch 1651, Loss: 0.011865307344123721, Final Batch Loss: 0.0006992490962147713\n",
      "Epoch 1652, Loss: 0.004391510665300302, Final Batch Loss: 0.0002329944836674258\n",
      "Epoch 1653, Loss: 0.0037288841922418214, Final Batch Loss: 0.00012103984045097604\n",
      "Epoch 1654, Loss: 0.01401768036885187, Final Batch Loss: 0.000266651448328048\n",
      "Epoch 1655, Loss: 0.001952668302692473, Final Batch Loss: 0.00013249419862404466\n",
      "Epoch 1656, Loss: 0.05484476312994957, Final Batch Loss: 0.03730466216802597\n",
      "Epoch 1657, Loss: 0.006270576879614964, Final Batch Loss: 0.00036007995367981493\n",
      "Epoch 1658, Loss: 0.004857847408857197, Final Batch Loss: 0.0028546967078000307\n",
      "Epoch 1659, Loss: 0.11843950432376005, Final Batch Loss: 0.11401684582233429\n",
      "Epoch 1660, Loss: 0.005488777653226862, Final Batch Loss: 4.221022027195431e-05\n",
      "Epoch 1661, Loss: 0.010652866447344422, Final Batch Loss: 0.0063939630053937435\n",
      "Epoch 1662, Loss: 0.0037063077952552703, Final Batch Loss: 7.34051445760997e-06\n",
      "Epoch 1663, Loss: 0.05472429015208036, Final Batch Loss: 0.052973777055740356\n",
      "Epoch 1664, Loss: 0.005069830978754908, Final Batch Loss: 0.0006035933620296419\n",
      "Epoch 1665, Loss: 0.0067625743122334825, Final Batch Loss: 1.4480088793789037e-05\n",
      "Epoch 1666, Loss: 0.01446239510551095, Final Batch Loss: 0.0005073568318039179\n",
      "Epoch 1667, Loss: 0.050924964249134064, Final Batch Loss: 0.024614226073026657\n",
      "Epoch 1668, Loss: 0.04601999360602349, Final Batch Loss: 0.0010539129143580794\n",
      "Epoch 1669, Loss: 0.002591244934592396, Final Batch Loss: 0.000558862928301096\n",
      "Epoch 1670, Loss: 0.010462289210408926, Final Batch Loss: 0.003240391844883561\n",
      "Epoch 1671, Loss: 0.009781926346477121, Final Batch Loss: 0.00046582770301029086\n",
      "Epoch 1672, Loss: 0.005122892231156584, Final Batch Loss: 6.194077286636457e-05\n",
      "Epoch 1673, Loss: 0.002041309235210065, Final Batch Loss: 8.049395546549931e-05\n",
      "Epoch 1674, Loss: 0.003739769534149673, Final Batch Loss: 2.3012129531707615e-05\n",
      "Epoch 1675, Loss: 0.007281358179170638, Final Batch Loss: 0.0004666029126383364\n",
      "Epoch 1676, Loss: 0.0023329746472882107, Final Batch Loss: 0.0001591275940882042\n",
      "Epoch 1677, Loss: 0.0012585613876581192, Final Batch Loss: 2.866459544748068e-05\n",
      "Epoch 1678, Loss: 0.026539311977103353, Final Batch Loss: 0.0001695288810878992\n",
      "Epoch 1679, Loss: 0.0033971627708524466, Final Batch Loss: 0.0008170135552063584\n",
      "Epoch 1680, Loss: 0.003371471864738851, Final Batch Loss: 1.8219207049696706e-05\n",
      "Epoch 1681, Loss: 0.0033330067235510796, Final Batch Loss: 3.8634490920230746e-05\n",
      "Epoch 1682, Loss: 0.0022129835560917854, Final Batch Loss: 0.0005301132914610207\n",
      "Epoch 1683, Loss: 0.006512499970995123, Final Batch Loss: 1.8526658095652238e-05\n",
      "Epoch 1684, Loss: 0.0021468576596817, Final Batch Loss: 0.00022838222503196448\n",
      "Epoch 1685, Loss: 0.004226883376304613, Final Batch Loss: 3.864840891765198e-06\n",
      "Epoch 1686, Loss: 0.0025998484052252024, Final Batch Loss: 0.00035670868237502873\n",
      "Epoch 1687, Loss: 0.0021594231948256493, Final Batch Loss: 0.00044529320439323783\n",
      "Epoch 1688, Loss: 0.006280918809352443, Final Batch Loss: 0.001409678952768445\n",
      "Epoch 1689, Loss: 0.005884468850126723, Final Batch Loss: 5.4006875870982185e-05\n",
      "Epoch 1690, Loss: 0.004974231369487825, Final Batch Loss: 2.6582229111227207e-05\n",
      "Epoch 1691, Loss: 0.021555708059167955, Final Batch Loss: 6.763850251445547e-05\n",
      "Epoch 1692, Loss: 0.011670835061522666, Final Batch Loss: 4.911609721602872e-05\n",
      "Epoch 1693, Loss: 0.014677888480946422, Final Batch Loss: 0.0014643075410276651\n",
      "Epoch 1694, Loss: 0.0036550754448398948, Final Batch Loss: 0.001165414578281343\n",
      "Epoch 1695, Loss: 0.0023517778081441065, Final Batch Loss: 2.2610131054534577e-05\n",
      "Epoch 1696, Loss: 0.0038204091251827776, Final Batch Loss: 0.0008812039741314948\n",
      "Epoch 1697, Loss: 0.003970267891418189, Final Batch Loss: 0.002162866061553359\n",
      "Epoch 1698, Loss: 0.009298065298935398, Final Batch Loss: 0.0001474370656069368\n",
      "Epoch 1699, Loss: 0.00893616967368871, Final Batch Loss: 0.0010154569754377007\n",
      "Epoch 1700, Loss: 0.023744567355606705, Final Batch Loss: 0.003683149814605713\n",
      "Epoch 1701, Loss: 0.0016824713093228638, Final Batch Loss: 0.00015815376536920667\n",
      "Epoch 1702, Loss: 0.00610351754585281, Final Batch Loss: 0.0009592240094207227\n",
      "Epoch 1703, Loss: 0.006368304850184359, Final Batch Loss: 0.00011730125697795302\n",
      "Epoch 1704, Loss: 0.0018041312523564557, Final Batch Loss: 2.9666751288459636e-05\n",
      "Epoch 1705, Loss: 0.0016716735699446872, Final Batch Loss: 3.247243876103312e-05\n",
      "Epoch 1706, Loss: 0.0017200571201101411, Final Batch Loss: 3.46601773344446e-05\n",
      "Epoch 1707, Loss: 0.0049622884835116565, Final Batch Loss: 0.0008260983158834279\n",
      "Epoch 1708, Loss: 0.0032837229082360864, Final Batch Loss: 0.0004973922041244805\n",
      "Epoch 1709, Loss: 0.001040400515194051, Final Batch Loss: 8.419087680522352e-05\n",
      "Epoch 1710, Loss: 0.0015112136970856227, Final Batch Loss: 8.597094711149111e-05\n",
      "Epoch 1711, Loss: 0.004325186702772044, Final Batch Loss: 0.0009105515200644732\n",
      "Epoch 1712, Loss: 0.0018417013561702333, Final Batch Loss: 2.8055124857928604e-05\n",
      "Epoch 1713, Loss: 0.003060084825847298, Final Batch Loss: 0.002093745395541191\n",
      "Epoch 1714, Loss: 0.0028178091743029654, Final Batch Loss: 0.0003423932066652924\n",
      "Epoch 1715, Loss: 0.003062959964154288, Final Batch Loss: 0.0018059344729408622\n",
      "Epoch 1716, Loss: 0.006228613186976872, Final Batch Loss: 0.0001527846179669723\n",
      "Epoch 1717, Loss: 0.005701560759916902, Final Batch Loss: 0.0015513310208916664\n",
      "Epoch 1718, Loss: 0.001822376718337182, Final Batch Loss: 9.83606805675663e-05\n",
      "Epoch 1719, Loss: 0.023653190259210533, Final Batch Loss: 3.1912841222947463e-05\n",
      "Epoch 1720, Loss: 0.003636319888755679, Final Batch Loss: 0.002165012527257204\n",
      "Epoch 1721, Loss: 0.0025313561491202563, Final Batch Loss: 0.00034466510987840593\n",
      "Epoch 1722, Loss: 0.0035813631548080593, Final Batch Loss: 0.0003178272454533726\n",
      "Epoch 1723, Loss: 0.0022570868022739887, Final Batch Loss: 0.00043542805360630155\n",
      "Epoch 1724, Loss: 0.009444829542189837, Final Batch Loss: 0.0010856345761567354\n",
      "Epoch 1725, Loss: 0.0036319231003290042, Final Batch Loss: 0.00021677678159903735\n",
      "Epoch 1726, Loss: 0.0014735895674675703, Final Batch Loss: 0.0002473394852131605\n",
      "Epoch 1727, Loss: 0.0018128467579572316, Final Batch Loss: 2.9864693260606145e-06\n",
      "Epoch 1728, Loss: 0.006510439019621117, Final Batch Loss: 3.9185553760034963e-05\n",
      "Epoch 1729, Loss: 0.0026308121769034187, Final Batch Loss: 1.426053040631814e-05\n",
      "Epoch 1730, Loss: 0.0017597237601876259, Final Batch Loss: 0.00031063694041222334\n",
      "Epoch 1731, Loss: 0.004765362275065854, Final Batch Loss: 7.196358637884259e-06\n",
      "Epoch 1732, Loss: 0.025947735412046313, Final Batch Loss: 0.004112439230084419\n",
      "Epoch 1733, Loss: 0.005176975158974528, Final Batch Loss: 0.0005381699884310365\n",
      "Epoch 1734, Loss: 0.007445026421919465, Final Batch Loss: 0.003047026228159666\n",
      "Epoch 1735, Loss: 0.001991192635614425, Final Batch Loss: 0.0003158132894895971\n",
      "Epoch 1736, Loss: 0.0038699695141986012, Final Batch Loss: 0.0015883493470028043\n",
      "Epoch 1737, Loss: 0.0027016288368031383, Final Batch Loss: 0.0008710399270057678\n",
      "Epoch 1738, Loss: 0.004017906729131937, Final Batch Loss: 0.001347317360341549\n",
      "Epoch 1739, Loss: 0.004048053262522444, Final Batch Loss: 0.0016981096705421805\n",
      "Epoch 1740, Loss: 0.003163634505654045, Final Batch Loss: 1.304986381001072e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1741, Loss: 0.0021757522772531956, Final Batch Loss: 0.0012086646165698767\n",
      "Epoch 1742, Loss: 0.0024778286265245697, Final Batch Loss: 4.360432740213582e-06\n",
      "Epoch 1743, Loss: 0.016784542607638286, Final Batch Loss: 5.900454198126681e-05\n",
      "Epoch 1744, Loss: 0.006117075303336605, Final Batch Loss: 0.0024735822807997465\n",
      "Epoch 1745, Loss: 0.0014284186181612313, Final Batch Loss: 0.0006931506213732064\n",
      "Epoch 1746, Loss: 0.0012429194757714868, Final Batch Loss: 0.00014691142132505774\n",
      "Epoch 1747, Loss: 0.008513132925145328, Final Batch Loss: 0.002728748368099332\n",
      "Epoch 1748, Loss: 0.00445067113287223, Final Batch Loss: 1.371400685457047e-05\n",
      "Epoch 1749, Loss: 0.06861317699076608, Final Batch Loss: 0.06517653912305832\n",
      "Epoch 1750, Loss: 0.009426218457520008, Final Batch Loss: 0.005835636518895626\n",
      "Epoch 1751, Loss: 0.0019163581018801779, Final Batch Loss: 0.0003051851817872375\n",
      "Epoch 1752, Loss: 0.018952371436171234, Final Batch Loss: 0.0019251051126047969\n",
      "Epoch 1753, Loss: 0.006958545198813226, Final Batch Loss: 5.903899818804348e-06\n",
      "Epoch 1754, Loss: 0.0019323359629197512, Final Batch Loss: 1.6192967450479046e-05\n",
      "Epoch 1755, Loss: 0.005193013392272405, Final Batch Loss: 3.4285636502318084e-05\n",
      "Epoch 1756, Loss: 0.0018353621126152575, Final Batch Loss: 0.00036705867387354374\n",
      "Epoch 1757, Loss: 0.0015784736424393486, Final Batch Loss: 2.3068143491400406e-05\n",
      "Epoch 1758, Loss: 0.0022544573266713996, Final Batch Loss: 1.3921523532189894e-05\n",
      "Epoch 1759, Loss: 0.010262480876917834, Final Batch Loss: 8.815024557407014e-06\n",
      "Epoch 1760, Loss: 0.0013076232016828726, Final Batch Loss: 1.4718653801537585e-05\n",
      "Epoch 1761, Loss: 0.0033564750920049846, Final Batch Loss: 0.0016109782736748457\n",
      "Epoch 1762, Loss: 0.004505379737565818, Final Batch Loss: 4.3541958802961744e-06\n",
      "Epoch 1763, Loss: 0.003933139436412603, Final Batch Loss: 0.00072106794686988\n",
      "Epoch 1764, Loss: 0.002758846152573824, Final Batch Loss: 0.0003882399178110063\n",
      "Epoch 1765, Loss: 0.0010584143601590768, Final Batch Loss: 1.951107697095722e-05\n",
      "Epoch 1766, Loss: 0.0018071134254569188, Final Batch Loss: 0.0010967982234433293\n",
      "Epoch 1767, Loss: 0.007766350427118596, Final Batch Loss: 7.417762390105054e-05\n",
      "Epoch 1768, Loss: 0.0012658940249821171, Final Batch Loss: 0.00013474626757670194\n",
      "Epoch 1769, Loss: 0.01023994329443667, Final Batch Loss: 0.0002146343613276258\n",
      "Epoch 1770, Loss: 0.002956394891953096, Final Batch Loss: 6.160043994896114e-05\n",
      "Epoch 1771, Loss: 0.004104964027646929, Final Batch Loss: 0.001647477620281279\n",
      "Epoch 1772, Loss: 0.00936451819143258, Final Batch Loss: 0.0001326126221101731\n",
      "Epoch 1773, Loss: 0.0019726932514458895, Final Batch Loss: 0.00014972256030887365\n",
      "Epoch 1774, Loss: 0.0027000002446584404, Final Batch Loss: 0.0011088397586718202\n",
      "Epoch 1775, Loss: 0.007412210165057331, Final Batch Loss: 0.004622980952262878\n",
      "Epoch 1776, Loss: 0.006005821516737342, Final Batch Loss: 0.001911679981276393\n",
      "Epoch 1777, Loss: 0.0025396749297215138, Final Batch Loss: 4.385173451737501e-05\n",
      "Epoch 1778, Loss: 0.012112999975215644, Final Batch Loss: 0.009017093107104301\n",
      "Epoch 1779, Loss: 0.03914172650547698, Final Batch Loss: 0.03695175051689148\n",
      "Epoch 1780, Loss: 0.020243611885234714, Final Batch Loss: 0.0036291549913585186\n",
      "Epoch 1781, Loss: 0.046800243959296495, Final Batch Loss: 0.0005361808580346406\n",
      "Epoch 1782, Loss: 0.0621320256832405, Final Batch Loss: 4.11221626563929e-05\n",
      "Epoch 1783, Loss: 0.01876324224849668, Final Batch Loss: 1.2961641004949342e-05\n",
      "Epoch 1784, Loss: 0.017039981321431696, Final Batch Loss: 0.0018197624012827873\n",
      "Epoch 1785, Loss: 0.0027998292935080826, Final Batch Loss: 0.00037529761902987957\n",
      "Epoch 1786, Loss: 0.004482809861656278, Final Batch Loss: 0.00034893600968644023\n",
      "Epoch 1787, Loss: 0.023366710491245613, Final Batch Loss: 0.00038695751572959125\n",
      "Epoch 1788, Loss: 0.01587088653468527, Final Batch Loss: 0.00020818007760681212\n",
      "Epoch 1789, Loss: 0.009099169848923339, Final Batch Loss: 1.6186600987566635e-05\n",
      "Epoch 1790, Loss: 0.018419029976939783, Final Batch Loss: 0.012984057888388634\n",
      "Epoch 1791, Loss: 0.001787083427188918, Final Batch Loss: 0.0003597374015953392\n",
      "Epoch 1792, Loss: 0.0059377995785325766, Final Batch Loss: 0.003820553421974182\n",
      "Epoch 1793, Loss: 0.031026289232613635, Final Batch Loss: 1.030172461469192e-05\n",
      "Epoch 1794, Loss: 0.007490513424272649, Final Batch Loss: 2.677789598237723e-05\n",
      "Epoch 1795, Loss: 0.011983830365352333, Final Batch Loss: 0.000185952871106565\n",
      "Epoch 1796, Loss: 0.0027418296376708895, Final Batch Loss: 0.00017652437963988632\n",
      "Epoch 1797, Loss: 0.0028385817422531545, Final Batch Loss: 0.000897267134860158\n",
      "Epoch 1798, Loss: 0.003403373120818287, Final Batch Loss: 0.0003565142396837473\n",
      "Epoch 1799, Loss: 0.0007270776550285518, Final Batch Loss: 3.774679498746991e-05\n",
      "Epoch 1800, Loss: 0.01804132820348059, Final Batch Loss: 2.359065774726332e-06\n",
      "Epoch 1801, Loss: 0.00276902862242423, Final Batch Loss: 5.7593133533373475e-05\n",
      "Epoch 1802, Loss: 0.001025833961648459, Final Batch Loss: 7.152398211474065e-06\n",
      "Epoch 1803, Loss: 0.010826827463461086, Final Batch Loss: 3.2076117349788547e-05\n",
      "Epoch 1804, Loss: 0.0009918115902110003, Final Batch Loss: 2.7300578949507326e-05\n",
      "Epoch 1805, Loss: 0.0024161280307453126, Final Batch Loss: 7.431078120134771e-05\n",
      "Epoch 1806, Loss: 0.008525755547452718, Final Batch Loss: 0.005848460365086794\n",
      "Epoch 1807, Loss: 0.0035697035491466522, Final Batch Loss: 0.0002923377323895693\n",
      "Epoch 1808, Loss: 0.000755048416522186, Final Batch Loss: 4.730654382001376e-06\n",
      "Epoch 1809, Loss: 0.004152636451181024, Final Batch Loss: 0.0017310564871877432\n",
      "Epoch 1810, Loss: 0.001250297744263662, Final Batch Loss: 5.182435779715888e-05\n",
      "Epoch 1811, Loss: 0.001258531330677215, Final Batch Loss: 2.1085470507387072e-05\n",
      "Epoch 1812, Loss: 0.0008963739383034408, Final Batch Loss: 0.00037676963256672025\n",
      "Epoch 1813, Loss: 0.007220249332021922, Final Batch Loss: 0.0015725565608590841\n",
      "Epoch 1814, Loss: 0.01617196889128536, Final Batch Loss: 0.011249041184782982\n",
      "Epoch 1815, Loss: 0.0018431598437018692, Final Batch Loss: 0.00035006317193619907\n",
      "Epoch 1816, Loss: 0.0006507451762445271, Final Batch Loss: 0.0001935627224156633\n",
      "Epoch 1817, Loss: 0.0013246176849861513, Final Batch Loss: 1.3708139704249334e-05\n",
      "Epoch 1818, Loss: 0.021026365385750978, Final Batch Loss: 3.8146240513015073e-06\n",
      "Epoch 1819, Loss: 0.0035236597796028946, Final Batch Loss: 3.0742994567845017e-06\n",
      "Epoch 1820, Loss: 0.0015228376723825932, Final Batch Loss: 0.0004633864155039191\n",
      "Epoch 1821, Loss: 0.004842534837735002, Final Batch Loss: 2.555205901444424e-05\n",
      "Epoch 1822, Loss: 0.000689543696353212, Final Batch Loss: 0.00010751064110081643\n",
      "Epoch 1823, Loss: 0.002512120350729674, Final Batch Loss: 0.00020397274056449533\n",
      "Epoch 1824, Loss: 0.0019100017671007663, Final Batch Loss: 0.0007135896594263613\n",
      "Epoch 1825, Loss: 0.0011646936472970992, Final Batch Loss: 0.000396885588997975\n",
      "Epoch 1826, Loss: 0.0010234319570372463, Final Batch Loss: 2.7229334591538645e-06\n",
      "Epoch 1827, Loss: 0.02237257093656808, Final Batch Loss: 0.010060491040349007\n",
      "Epoch 1828, Loss: 0.004524530959315598, Final Batch Loss: 0.0017152669606730342\n",
      "Epoch 1829, Loss: 0.00307960546342656, Final Batch Loss: 0.0008501769043505192\n",
      "Epoch 1830, Loss: 0.004162194174568867, Final Batch Loss: 1.9861643522745e-05\n",
      "Epoch 1831, Loss: 0.011230360505578574, Final Batch Loss: 0.007458946201950312\n",
      "Epoch 1832, Loss: 0.002799349633278325, Final Batch Loss: 0.001487966626882553\n",
      "Epoch 1833, Loss: 0.02590853152651107, Final Batch Loss: 7.92894497863017e-05\n",
      "Epoch 1834, Loss: 0.001478457634220831, Final Batch Loss: 0.0007494649034924805\n",
      "Epoch 1835, Loss: 0.002523001574445516, Final Batch Loss: 0.0021580427419394255\n",
      "Epoch 1836, Loss: 0.0020410142533364706, Final Batch Loss: 0.00020356728055048734\n",
      "Epoch 1837, Loss: 0.002995167353674333, Final Batch Loss: 4.667865596275078e-06\n",
      "Epoch 1838, Loss: 0.00032086997816804796, Final Batch Loss: 1.032054569805041e-05\n",
      "Epoch 1839, Loss: 0.025283473718445748, Final Batch Loss: 0.0009844113374128938\n",
      "Epoch 1840, Loss: 0.0010668530740076676, Final Batch Loss: 0.0002108165790559724\n",
      "Epoch 1841, Loss: 0.010143372637685388, Final Batch Loss: 0.001114530023187399\n",
      "Epoch 1842, Loss: 0.00037922992487438023, Final Batch Loss: 0.00011105201701866463\n",
      "Epoch 1843, Loss: 0.006213609951373655, Final Batch Loss: 3.094912244705483e-05\n",
      "Epoch 1844, Loss: 0.0018317118738195859, Final Batch Loss: 4.121351958019659e-05\n",
      "Epoch 1845, Loss: 0.0011629673481365899, Final Batch Loss: 1.890782186819706e-05\n",
      "Epoch 1846, Loss: 0.0011165525065734982, Final Batch Loss: 1.830665860325098e-05\n",
      "Epoch 1847, Loss: 0.000749451919546118, Final Batch Loss: 2.0991425117244944e-05\n",
      "Epoch 1848, Loss: 0.009553849027724937, Final Batch Loss: 0.00021268767886795104\n",
      "Epoch 1849, Loss: 0.001236510037415428, Final Batch Loss: 3.1514889997197315e-05\n",
      "Epoch 1850, Loss: 0.0012366241862764582, Final Batch Loss: 5.471121403388679e-05\n",
      "Epoch 1851, Loss: 0.0009788295137695968, Final Batch Loss: 5.655278800986707e-05\n",
      "Epoch 1852, Loss: 0.0007350685336859897, Final Batch Loss: 3.2187410397455096e-05\n",
      "Epoch 1853, Loss: 0.0037115388840902597, Final Batch Loss: 0.002450150204822421\n",
      "Epoch 1854, Loss: 0.00106930268520955, Final Batch Loss: 0.00011722596536856145\n",
      "Epoch 1855, Loss: 0.0022743848094251007, Final Batch Loss: 1.9115323084406555e-05\n",
      "Epoch 1856, Loss: 0.0017852319751909818, Final Batch Loss: 1.0734645002230536e-05\n",
      "Epoch 1857, Loss: 0.0021740904685429996, Final Batch Loss: 2.834863516909536e-05\n",
      "Epoch 1858, Loss: 0.0008855345222400501, Final Batch Loss: 0.00016095682804007083\n",
      "Epoch 1859, Loss: 0.0015186636301223189, Final Batch Loss: 0.0005010915920138359\n",
      "Epoch 1860, Loss: 0.0019688950096679037, Final Batch Loss: 1.523851551610278e-05\n",
      "Epoch 1861, Loss: 0.0018579072620923398, Final Batch Loss: 5.144811439095065e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1862, Loss: 0.0031444435007870197, Final Batch Loss: 0.00014791314606554806\n",
      "Epoch 1863, Loss: 0.0018491531809559092, Final Batch Loss: 0.00018447321781422943\n",
      "Epoch 1864, Loss: 0.002371855254750699, Final Batch Loss: 0.0006225172546692193\n",
      "Epoch 1865, Loss: 0.0015415410380228423, Final Batch Loss: 8.802770025795326e-05\n",
      "Epoch 1866, Loss: 0.002640334569150582, Final Batch Loss: 0.00018659690977074206\n",
      "Epoch 1867, Loss: 0.004556157946353778, Final Batch Loss: 0.00047726111370138824\n",
      "Epoch 1868, Loss: 0.031142525424002088, Final Batch Loss: 2.315674464625772e-05\n",
      "Epoch 1869, Loss: 0.0007323518802877516, Final Batch Loss: 0.0002594327961560339\n",
      "Epoch 1870, Loss: 0.0011286425178695936, Final Batch Loss: 3.0626350053353235e-05\n",
      "Epoch 1871, Loss: 0.003089126170380041, Final Batch Loss: 0.0017682680627331138\n",
      "Epoch 1872, Loss: 0.0011915422946913168, Final Batch Loss: 3.9056860259734094e-05\n",
      "Epoch 1873, Loss: 0.0014289517421275377, Final Batch Loss: 0.0009960689349099994\n",
      "Epoch 1874, Loss: 0.0016612776671536267, Final Batch Loss: 0.00038624138687737286\n",
      "Epoch 1875, Loss: 0.0009489117364864796, Final Batch Loss: 0.0002543587179388851\n",
      "Epoch 1876, Loss: 0.0008509079198120162, Final Batch Loss: 0.00010687563917599618\n",
      "Epoch 1877, Loss: 0.0007090665167197585, Final Batch Loss: 0.0001316666166530922\n",
      "Epoch 1878, Loss: 0.0012445136089809239, Final Batch Loss: 0.00011622399324551225\n",
      "Epoch 1879, Loss: 0.006898376072058454, Final Batch Loss: 0.00031059575849212706\n",
      "Epoch 1880, Loss: 0.0011434833868406713, Final Batch Loss: 7.774733239784837e-05\n",
      "Epoch 1881, Loss: 0.002435584774502786, Final Batch Loss: 7.641709089512005e-06\n",
      "Epoch 1882, Loss: 0.0023319461179198697, Final Batch Loss: 0.00019459928444121033\n",
      "Epoch 1883, Loss: 0.007926631937152706, Final Batch Loss: 0.0001517028867965564\n",
      "Epoch 1884, Loss: 0.0030398922244785354, Final Batch Loss: 0.00011661641474347562\n",
      "Epoch 1885, Loss: 0.00976832045125775, Final Batch Loss: 7.061960059218109e-05\n",
      "Epoch 1886, Loss: 0.008046980306971818, Final Batch Loss: 0.005041166208684444\n",
      "Epoch 1887, Loss: 0.0012420732236932963, Final Batch Loss: 0.00027619863976724446\n",
      "Epoch 1888, Loss: 0.004410901223309338, Final Batch Loss: 0.003715522587299347\n",
      "Epoch 1889, Loss: 0.002624814655064256, Final Batch Loss: 1.7792184735299088e-05\n",
      "Epoch 1890, Loss: 0.004003858513897285, Final Batch Loss: 0.0017829431453719735\n",
      "Epoch 1891, Loss: 0.004979821569577325, Final Batch Loss: 0.004541968926787376\n",
      "Epoch 1892, Loss: 0.0009196285245707259, Final Batch Loss: 0.00011650535452645272\n",
      "Epoch 1893, Loss: 0.0010773283121352506, Final Batch Loss: 1.4430535202336614e-06\n",
      "Epoch 1894, Loss: 0.004522293533227639, Final Batch Loss: 5.341008727555163e-05\n",
      "Epoch 1895, Loss: 0.0019720355678600754, Final Batch Loss: 1.8884941255237209e-06\n",
      "Epoch 1896, Loss: 0.011912570233107544, Final Batch Loss: 0.0026977660600095987\n",
      "Epoch 1897, Loss: 0.005726373099605553, Final Batch Loss: 3.7506732041947544e-05\n",
      "Epoch 1898, Loss: 0.004707027488620952, Final Batch Loss: 0.003341573989018798\n",
      "Epoch 1899, Loss: 0.002016123093198985, Final Batch Loss: 0.00043816142715513706\n",
      "Epoch 1900, Loss: 0.01007223385386169, Final Batch Loss: 0.004057086072862148\n",
      "Epoch 1901, Loss: 0.014453689218498766, Final Batch Loss: 0.0006578462198376656\n",
      "Epoch 1902, Loss: 0.0006350013663904974, Final Batch Loss: 2.9961543987155892e-05\n",
      "Epoch 1903, Loss: 0.0020948983292328194, Final Batch Loss: 5.751157004851848e-05\n",
      "Epoch 1904, Loss: 0.00038151982880663127, Final Batch Loss: 3.946144715882838e-05\n",
      "Epoch 1905, Loss: 0.0005731273442535212, Final Batch Loss: 2.0704756309442018e-07\n",
      "Epoch 1906, Loss: 0.017953245114767924, Final Batch Loss: 0.00029617981635965407\n",
      "Epoch 1907, Loss: 0.0004089261337867356, Final Batch Loss: 9.034584763867315e-06\n",
      "Epoch 1908, Loss: 0.001110492979933042, Final Batch Loss: 6.910111551405862e-05\n",
      "Epoch 1909, Loss: 0.0031781723664607853, Final Batch Loss: 0.002565821399912238\n",
      "Epoch 1910, Loss: 0.003895894727747873, Final Batch Loss: 3.758164666578523e-06\n",
      "Epoch 1911, Loss: 0.0006894190155435354, Final Batch Loss: 0.00019841379253193736\n",
      "Epoch 1912, Loss: 0.0005335090681910515, Final Batch Loss: 0.00011495495709823444\n",
      "Epoch 1913, Loss: 0.0006826115459261928, Final Batch Loss: 5.414538463810459e-06\n",
      "Epoch 1914, Loss: 0.0009850754977378529, Final Batch Loss: 3.7383240851340815e-05\n",
      "Epoch 1915, Loss: 0.0026266956992913038, Final Batch Loss: 0.0017357119359076023\n",
      "Epoch 1916, Loss: 0.01814370835199952, Final Batch Loss: 1.845645601861179e-05\n",
      "Epoch 1917, Loss: 0.006681406812276691, Final Batch Loss: 0.000911040639039129\n",
      "Epoch 1918, Loss: 0.0015488134886254556, Final Batch Loss: 9.597079042578116e-05\n",
      "Epoch 1919, Loss: 0.0021994433027430205, Final Batch Loss: 2.4265797037514858e-05\n",
      "Epoch 1920, Loss: 0.0008055787620833144, Final Batch Loss: 0.0001446487003704533\n",
      "Epoch 1921, Loss: 0.0016659157195135776, Final Batch Loss: 7.077069767547073e-06\n",
      "Epoch 1922, Loss: 0.0027996658063784707, Final Batch Loss: 1.642959614400752e-05\n",
      "Epoch 1923, Loss: 0.0005634444005409023, Final Batch Loss: 6.374311851686798e-06\n",
      "Epoch 1924, Loss: 0.0173407050606329, Final Batch Loss: 0.0002672094269655645\n",
      "Epoch 1925, Loss: 0.1132944850178319, Final Batch Loss: 0.11224132031202316\n",
      "Epoch 1926, Loss: 0.0014310330770967994, Final Batch Loss: 4.542795431916602e-05\n",
      "Epoch 1927, Loss: 0.0043536435114219785, Final Batch Loss: 0.0020559050608426332\n",
      "Epoch 1928, Loss: 0.03323629031365272, Final Batch Loss: 0.00011089442705269903\n",
      "Epoch 1929, Loss: 0.0526248759124428, Final Batch Loss: 0.00013379780284594744\n",
      "Epoch 1930, Loss: 0.029268279385178175, Final Batch Loss: 1.0841239600267727e-05\n",
      "Epoch 1931, Loss: 0.042536826513241976, Final Batch Loss: 0.00012148573296144605\n",
      "Epoch 1932, Loss: 0.002569269581726985, Final Batch Loss: 5.0786144129233435e-05\n",
      "Epoch 1933, Loss: 0.002191067294916138, Final Batch Loss: 0.000249469158006832\n",
      "Epoch 1934, Loss: 0.005889024963835254, Final Batch Loss: 0.00021003003348596394\n",
      "Epoch 1935, Loss: 0.029693085234612226, Final Batch Loss: 0.002578944433480501\n",
      "Epoch 1936, Loss: 0.003606634825700894, Final Batch Loss: 0.0002626045898068696\n",
      "Epoch 1937, Loss: 0.005590029060840607, Final Batch Loss: 0.002105862135067582\n",
      "Epoch 1938, Loss: 0.2117380446579773, Final Batch Loss: 0.18441607058048248\n",
      "Epoch 1939, Loss: 0.017755491364368936, Final Batch Loss: 2.4612698325654492e-05\n",
      "Epoch 1940, Loss: 0.019648439942102414, Final Batch Loss: 6.384657899616286e-05\n",
      "Epoch 1941, Loss: 0.04048464132938534, Final Batch Loss: 0.0004253057995811105\n",
      "Epoch 1942, Loss: 0.09755400917492807, Final Batch Loss: 0.00526586826890707\n",
      "Epoch 1943, Loss: 0.032634415169013664, Final Batch Loss: 0.00045493696234188974\n",
      "Epoch 1944, Loss: 0.02484317307244055, Final Batch Loss: 0.00021244210074655712\n",
      "Epoch 1945, Loss: 0.022667589073535055, Final Batch Loss: 0.0008501917473040521\n",
      "Epoch 1946, Loss: 0.027149251895025373, Final Batch Loss: 0.00028326117899268866\n",
      "Epoch 1947, Loss: 0.02504525933181867, Final Batch Loss: 7.251877104863524e-05\n",
      "Epoch 1948, Loss: 0.019005712441867217, Final Batch Loss: 6.922156899236143e-05\n",
      "Epoch 1949, Loss: 0.02688752766698599, Final Batch Loss: 0.011032288894057274\n",
      "Epoch 1950, Loss: 0.021301985976606375, Final Batch Loss: 4.782309042639099e-05\n",
      "Epoch 1951, Loss: 0.011728993791621178, Final Batch Loss: 0.0008489281754009426\n",
      "Epoch 1952, Loss: 0.029855971108190715, Final Batch Loss: 0.00021816539810970426\n",
      "Epoch 1953, Loss: 0.010662201362720225, Final Batch Loss: 3.430710785323754e-05\n",
      "Epoch 1954, Loss: 0.0033565470985195134, Final Batch Loss: 3.6599991290131584e-05\n",
      "Epoch 1955, Loss: 0.007893378322478384, Final Batch Loss: 0.0015603419160470366\n",
      "Epoch 1956, Loss: 0.002756722518824972, Final Batch Loss: 3.72651411453262e-05\n",
      "Epoch 1957, Loss: 0.005665888334988267, Final Batch Loss: 2.7842610506922938e-05\n",
      "Epoch 1958, Loss: 0.00953834814572474, Final Batch Loss: 6.85706254444085e-05\n",
      "Epoch 1959, Loss: 0.003718748168921593, Final Batch Loss: 4.893850018561352e-07\n",
      "Epoch 1960, Loss: 0.017389499342243653, Final Batch Loss: 4.659208207158372e-05\n",
      "Epoch 1961, Loss: 0.004900754429399967, Final Batch Loss: 0.0026186001487076283\n",
      "Epoch 1962, Loss: 0.02831985852390062, Final Batch Loss: 9.677400521468371e-05\n",
      "Epoch 1963, Loss: 0.009294945979490876, Final Batch Loss: 0.003850561333820224\n",
      "Epoch 1964, Loss: 0.0020973214850528166, Final Batch Loss: 0.00017930996546056122\n",
      "Epoch 1965, Loss: 0.0023583873771713115, Final Batch Loss: 8.364002133021131e-05\n",
      "Epoch 1966, Loss: 0.0036421678960323334, Final Batch Loss: 0.0004715380200650543\n",
      "Epoch 1967, Loss: 0.00208195045706816, Final Batch Loss: 0.0008923413115553558\n",
      "Epoch 1968, Loss: 0.0032299831182172056, Final Batch Loss: 1.1481428373372182e-05\n",
      "Epoch 1969, Loss: 0.018499736819649115, Final Batch Loss: 0.00029156022355891764\n",
      "Epoch 1970, Loss: 0.006075743572637293, Final Batch Loss: 4.329123385105049e-06\n",
      "Epoch 1971, Loss: 0.0033284613164141774, Final Batch Loss: 0.00043130735866725445\n",
      "Epoch 1972, Loss: 0.0030162791881593876, Final Batch Loss: 0.00010792417015181854\n",
      "Epoch 1973, Loss: 0.00835229127551429, Final Batch Loss: 0.006425493862479925\n",
      "Epoch 1974, Loss: 0.007434652914525941, Final Batch Loss: 0.0003181211941409856\n",
      "Epoch 1975, Loss: 0.014901437447406352, Final Batch Loss: 0.010533870197832584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1976, Loss: 0.0017147556936834008, Final Batch Loss: 4.993073525838554e-05\n",
      "Epoch 1977, Loss: 0.0017758447393134702, Final Batch Loss: 4.184605859336443e-05\n",
      "Epoch 1978, Loss: 0.003499637736240402, Final Batch Loss: 0.0023822709918022156\n",
      "Epoch 1979, Loss: 0.004031866912555415, Final Batch Loss: 9.490516822552308e-05\n",
      "Epoch 1980, Loss: 0.0049667765269987285, Final Batch Loss: 4.46768244728446e-05\n",
      "Epoch 1981, Loss: 0.0037642353418050334, Final Batch Loss: 0.0001221974816871807\n",
      "Epoch 1982, Loss: 0.0017872527641884517, Final Batch Loss: 3.092792394454591e-05\n",
      "Epoch 1983, Loss: 0.03717190778115764, Final Batch Loss: 0.026488834992051125\n",
      "Epoch 1984, Loss: 0.0009933493429343798, Final Batch Loss: 1.2767254702339415e-05\n",
      "Epoch 1985, Loss: 0.008678530830366071, Final Batch Loss: 0.00011716761946445331\n",
      "Epoch 1986, Loss: 0.004366724810097367, Final Batch Loss: 0.0004311700467951596\n",
      "Epoch 1987, Loss: 0.007466995873983251, Final Batch Loss: 1.3162807590560988e-05\n",
      "Epoch 1988, Loss: 0.003672894206829369, Final Batch Loss: 0.0008230169187299907\n",
      "Epoch 1989, Loss: 0.0020858908428635914, Final Batch Loss: 3.1041610782267526e-05\n",
      "Epoch 1990, Loss: 0.0036182951625960413, Final Batch Loss: 3.9483365981141105e-05\n",
      "Epoch 1991, Loss: 0.003842621756120934, Final Batch Loss: 2.2008613086654805e-05\n",
      "Epoch 1992, Loss: 0.003614017157815397, Final Batch Loss: 0.0025656905490905046\n",
      "Epoch 1993, Loss: 0.0037856847047805786, Final Batch Loss: 0.001287315972149372\n",
      "Epoch 1994, Loss: 0.005516322387848049, Final Batch Loss: 0.003916886635124683\n",
      "Epoch 1995, Loss: 0.002952714559796732, Final Batch Loss: 5.111796053824946e-05\n",
      "Epoch 1996, Loss: 0.0011926656479772646, Final Batch Loss: 4.781100506079383e-05\n",
      "Epoch 1997, Loss: 0.0010942346184492635, Final Batch Loss: 6.80101811667555e-06\n",
      "Epoch 1998, Loss: 0.005231400195043534, Final Batch Loss: 0.003787797875702381\n",
      "Epoch 1999, Loss: 0.008686011363352009, Final Batch Loss: 9.868582310446072e-06\n",
      "Epoch 2000, Loss: 0.005376713947043754, Final Batch Loss: 7.902343349996954e-05\n",
      "Epoch 2001, Loss: 0.0010584248739178292, Final Batch Loss: 4.818393790628761e-06\n",
      "Epoch 2002, Loss: 0.013403946766629815, Final Batch Loss: 0.00041929224971681833\n",
      "Epoch 2003, Loss: 0.0021036254584032577, Final Batch Loss: 5.251389666227624e-06\n",
      "Epoch 2004, Loss: 0.006157150637591258, Final Batch Loss: 0.004610439296811819\n",
      "Epoch 2005, Loss: 0.0008366875554202124, Final Batch Loss: 0.0001860724005382508\n",
      "Epoch 2006, Loss: 0.0006236168319446733, Final Batch Loss: 9.969304301193915e-06\n",
      "Epoch 2007, Loss: 0.0015982166369212791, Final Batch Loss: 0.0001654806110309437\n",
      "Epoch 2008, Loss: 0.002339008991839364, Final Batch Loss: 0.0003880102012772113\n",
      "Epoch 2009, Loss: 0.01584417805861449, Final Batch Loss: 0.00011591842485358939\n",
      "Epoch 2010, Loss: 0.0014354373088281136, Final Batch Loss: 7.227714377222583e-06\n",
      "Epoch 2011, Loss: 0.0009154418548860122, Final Batch Loss: 3.811471469816752e-05\n",
      "Epoch 2012, Loss: 0.005385000931710238, Final Batch Loss: 3.1668900192016736e-05\n",
      "Epoch 2013, Loss: 0.003019929128640797, Final Batch Loss: 6.174804730108008e-05\n",
      "Epoch 2014, Loss: 0.0023775369409122504, Final Batch Loss: 0.0018057533307000995\n",
      "Epoch 2015, Loss: 0.006929153576493263, Final Batch Loss: 0.004629600793123245\n",
      "Epoch 2016, Loss: 0.0018512105161789805, Final Batch Loss: 0.00012528433580882847\n",
      "Epoch 2017, Loss: 0.009653343324316666, Final Batch Loss: 2.3369095288217068e-05\n",
      "Epoch 2018, Loss: 0.0035219699202571064, Final Batch Loss: 0.00029450483270920813\n",
      "Epoch 2019, Loss: 0.001187288620712934, Final Batch Loss: 3.917918002116494e-05\n",
      "Epoch 2020, Loss: 0.0046064823554843315, Final Batch Loss: 4.228743819112424e-06\n",
      "Epoch 2021, Loss: 0.0012018683555652387, Final Batch Loss: 6.323535490082577e-05\n",
      "Epoch 2022, Loss: 0.0026507840175327146, Final Batch Loss: 2.9230965083115734e-05\n",
      "Epoch 2023, Loss: 0.020294598783038964, Final Batch Loss: 1.3225492693891283e-05\n",
      "Epoch 2024, Loss: 0.0024831736518535763, Final Batch Loss: 0.0012120072497054935\n",
      "Epoch 2025, Loss: 0.0014936989846319193, Final Batch Loss: 6.531316103064455e-06\n",
      "Epoch 2026, Loss: 0.001081808117305627, Final Batch Loss: 6.0166868934175e-05\n",
      "Epoch 2027, Loss: 0.0023098749516066164, Final Batch Loss: 9.725845302455127e-05\n",
      "Epoch 2028, Loss: 0.004317717737649218, Final Batch Loss: 1.5276886188075878e-05\n",
      "Epoch 2029, Loss: 0.0021917438716627657, Final Batch Loss: 0.0001142330002039671\n",
      "Epoch 2030, Loss: 0.001246714065928245, Final Batch Loss: 5.0022532377624884e-05\n",
      "Epoch 2031, Loss: 0.0013833017146680504, Final Batch Loss: 0.0003375952073838562\n",
      "Epoch 2032, Loss: 0.0029941160464659333, Final Batch Loss: 0.0018173180287703872\n",
      "Epoch 2033, Loss: 0.0013946094404673204, Final Batch Loss: 0.00011456625361461192\n",
      "Epoch 2034, Loss: 0.0024136141582857817, Final Batch Loss: 0.0008914356003515422\n",
      "Epoch 2035, Loss: 0.0008280885613203282, Final Batch Loss: 1.9944776795455255e-05\n",
      "Epoch 2036, Loss: 0.010751239402452484, Final Batch Loss: 0.009045315906405449\n",
      "Epoch 2037, Loss: 0.007586093896861712, Final Batch Loss: 6.060684427211527e-06\n",
      "Epoch 2038, Loss: 0.002900220759329386, Final Batch Loss: 7.908670522738248e-05\n",
      "Epoch 2039, Loss: 0.020585325341812677, Final Batch Loss: 9.975909733839217e-07\n",
      "Epoch 2040, Loss: 0.001166215144621674, Final Batch Loss: 1.6204699932131916e-05\n",
      "Epoch 2041, Loss: 0.004003892398031894, Final Batch Loss: 9.812691860133782e-05\n",
      "Epoch 2042, Loss: 0.0012517246650531888, Final Batch Loss: 0.00010900042252615094\n",
      "Epoch 2043, Loss: 0.0008976141834864393, Final Batch Loss: 9.72721609286964e-05\n",
      "Epoch 2044, Loss: 0.0009617882695351909, Final Batch Loss: 9.473968134443567e-07\n",
      "Epoch 2045, Loss: 0.001516888598416699, Final Batch Loss: 3.956035288865678e-05\n",
      "Epoch 2046, Loss: 0.0022069035433105455, Final Batch Loss: 2.1018306597397896e-06\n",
      "Epoch 2047, Loss: 0.0017965397564694285, Final Batch Loss: 0.00033609557431191206\n",
      "Epoch 2048, Loss: 0.007586765645100968, Final Batch Loss: 2.6044497644761577e-05\n",
      "Epoch 2049, Loss: 0.002005193498916924, Final Batch Loss: 0.00020228803623467684\n",
      "Epoch 2050, Loss: 0.013378021190874279, Final Batch Loss: 0.0008057475788518786\n",
      "Epoch 2051, Loss: 0.0017381150828441605, Final Batch Loss: 0.0007491128635592759\n",
      "Epoch 2052, Loss: 0.0009281016209570225, Final Batch Loss: 4.223267387715168e-05\n",
      "Epoch 2053, Loss: 0.014266274170950055, Final Batch Loss: 0.0107791842892766\n",
      "Epoch 2054, Loss: 0.007031874847598374, Final Batch Loss: 0.002151923254132271\n",
      "Epoch 2055, Loss: 0.00255285068988087, Final Batch Loss: 4.661612820200389e-06\n",
      "Epoch 2056, Loss: 0.0011739087640307844, Final Batch Loss: 0.0005217283614911139\n",
      "Epoch 2057, Loss: 0.0006165326717564312, Final Batch Loss: 4.655326392821735e-06\n",
      "Epoch 2058, Loss: 0.042804029100807384, Final Batch Loss: 0.0006297333166003227\n",
      "Epoch 2059, Loss: 0.003055611188756302, Final Batch Loss: 0.002346568973734975\n",
      "Epoch 2060, Loss: 0.0016109741409309208, Final Batch Loss: 0.0005227804649621248\n",
      "Epoch 2061, Loss: 0.014521184260956943, Final Batch Loss: 0.004522071685642004\n",
      "Epoch 2062, Loss: 0.0020182693860988365, Final Batch Loss: 1.9442175471340306e-05\n",
      "Epoch 2063, Loss: 0.0009401573306604405, Final Batch Loss: 2.8735057640005834e-06\n",
      "Epoch 2064, Loss: 0.0032416445392300375, Final Batch Loss: 0.0001185781802632846\n",
      "Epoch 2065, Loss: 0.0025797357695864775, Final Batch Loss: 3.6075973639526637e-06\n",
      "Epoch 2066, Loss: 0.0015194767784123542, Final Batch Loss: 5.546246029553004e-06\n",
      "Epoch 2067, Loss: 0.001382593417474709, Final Batch Loss: 1.5076019735715818e-05\n",
      "Epoch 2068, Loss: 0.0008784692981862463, Final Batch Loss: 0.00036052035284228623\n",
      "Epoch 2069, Loss: 0.0016234560025623068, Final Batch Loss: 0.00013196362124290317\n",
      "Epoch 2070, Loss: 0.0008077808743109927, Final Batch Loss: 0.00035396008752286434\n",
      "Epoch 2071, Loss: 0.0007130107696866617, Final Batch Loss: 0.00014097742678131908\n",
      "Epoch 2072, Loss: 0.0006278460714383982, Final Batch Loss: 7.6711417932529e-05\n",
      "Epoch 2073, Loss: 0.007130141217203345, Final Batch Loss: 9.703332762001082e-05\n",
      "Epoch 2074, Loss: 0.002596597361844033, Final Batch Loss: 0.0005553442751988769\n",
      "Epoch 2075, Loss: 0.02996550181251223, Final Batch Loss: 6.5814047047751956e-06\n",
      "Epoch 2076, Loss: 0.0010934332094620913, Final Batch Loss: 0.00013908764231018722\n",
      "Epoch 2077, Loss: 0.0011512666096678004, Final Batch Loss: 0.0005592279485426843\n",
      "Epoch 2078, Loss: 0.005174582634936087, Final Batch Loss: 0.00022917594469618052\n",
      "Epoch 2079, Loss: 0.0016593924501648871, Final Batch Loss: 3.01302188745467e-05\n",
      "Epoch 2080, Loss: 0.002531896039727144, Final Batch Loss: 0.00021951341477688402\n",
      "Epoch 2081, Loss: 0.0008949069087975658, Final Batch Loss: 8.84846449480392e-05\n",
      "Epoch 2082, Loss: 0.0014213908161764266, Final Batch Loss: 2.3620772481081076e-05\n",
      "Epoch 2083, Loss: 0.0018481916922610253, Final Batch Loss: 0.00014071990153752267\n",
      "Epoch 2084, Loss: 0.021251586920698173, Final Batch Loss: 3.850857319775969e-05\n",
      "Epoch 2085, Loss: 0.0017852598998615576, Final Batch Loss: 1.1732649909390602e-06\n",
      "Epoch 2086, Loss: 0.0031574477106914856, Final Batch Loss: 0.002203757641837001\n",
      "Epoch 2087, Loss: 0.0031838111171964556, Final Batch Loss: 0.0018903842428699136\n",
      "Epoch 2088, Loss: 0.0031011397659312934, Final Batch Loss: 0.0006035988917574286\n",
      "Epoch 2089, Loss: 0.0015586441732011735, Final Batch Loss: 5.47095260117203e-05\n",
      "Epoch 2090, Loss: 0.0024118944711517543, Final Batch Loss: 0.000376957148546353\n",
      "Epoch 2091, Loss: 0.0018432301021675812, Final Batch Loss: 1.3795799532090314e-05\n",
      "Epoch 2092, Loss: 0.01327446375580621, Final Batch Loss: 5.815130498376675e-05\n",
      "Epoch 2093, Loss: 0.0009443278977414593, Final Batch Loss: 0.00027102703461423516\n",
      "Epoch 2094, Loss: 0.0019437024602666497, Final Batch Loss: 0.0013079758500680327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2095, Loss: 0.0016500788769917563, Final Batch Loss: 0.0006240321090444922\n",
      "Epoch 2096, Loss: 0.002159115159884095, Final Batch Loss: 0.0001907823607325554\n",
      "Epoch 2097, Loss: 0.0010945331887342036, Final Batch Loss: 0.0006682358798570931\n",
      "Epoch 2098, Loss: 0.001913228647026699, Final Batch Loss: 4.754866677103564e-05\n",
      "Epoch 2099, Loss: 0.0014450346557168814, Final Batch Loss: 6.619104624405736e-06\n",
      "Epoch 2100, Loss: 0.0006791665919081424, Final Batch Loss: 8.093525138974655e-06\n",
      "Epoch 2101, Loss: 0.0030052429046918405, Final Batch Loss: 1.6191273971344344e-05\n",
      "Epoch 2102, Loss: 0.001175169895759609, Final Batch Loss: 8.96541041583987e-06\n",
      "Epoch 2103, Loss: 0.001970146404346451, Final Batch Loss: 0.0007653215434402227\n",
      "Epoch 2104, Loss: 0.011815253682243565, Final Batch Loss: 3.4633055747690378e-06\n",
      "Epoch 2105, Loss: 0.004328589006036054, Final Batch Loss: 2.1242267393972725e-05\n",
      "Epoch 2106, Loss: 0.0015481405571335927, Final Batch Loss: 0.0011699923779815435\n",
      "Epoch 2107, Loss: 0.012684214540058747, Final Batch Loss: 0.012012101709842682\n",
      "Epoch 2108, Loss: 0.0005288753163767979, Final Batch Loss: 3.26769077219069e-05\n",
      "Epoch 2109, Loss: 0.0010328849430152331, Final Batch Loss: 1.4367806215886958e-06\n",
      "Epoch 2110, Loss: 0.0015860895509831607, Final Batch Loss: 0.0009677881607785821\n",
      "Epoch 2111, Loss: 0.001325813980656676, Final Batch Loss: 0.00023430331202689558\n",
      "Epoch 2112, Loss: 0.009672708354628412, Final Batch Loss: 4.663696381612681e-05\n",
      "Epoch 2113, Loss: 0.0012472076268750243, Final Batch Loss: 8.331779099535197e-06\n",
      "Epoch 2114, Loss: 0.006616192913838859, Final Batch Loss: 1.0038642130894004e-06\n",
      "Epoch 2115, Loss: 0.0011939806427108124, Final Batch Loss: 0.00018301037198398262\n",
      "Epoch 2116, Loss: 0.0026989536490873434, Final Batch Loss: 0.00023547680757474154\n",
      "Epoch 2117, Loss: 0.0031315519590862095, Final Batch Loss: 0.0005460281972773373\n",
      "Epoch 2118, Loss: 0.00364881225686986, Final Batch Loss: 0.00016782018064986914\n",
      "Epoch 2119, Loss: 0.0025896029123941844, Final Batch Loss: 3.1370595934276935e-06\n",
      "Epoch 2120, Loss: 0.008470104483421892, Final Batch Loss: 0.005887927487492561\n",
      "Epoch 2121, Loss: 0.0017539316645525105, Final Batch Loss: 5.646641056955559e-06\n",
      "Epoch 2122, Loss: 0.002018521958234487, Final Batch Loss: 5.6521163060097024e-05\n",
      "Epoch 2123, Loss: 0.003082331328187138, Final Batch Loss: 0.0014785216189920902\n",
      "Epoch 2124, Loss: 0.005711904290365055, Final Batch Loss: 0.0018526017665863037\n",
      "Epoch 2125, Loss: 0.0013063114702163148, Final Batch Loss: 5.4898073358344845e-06\n",
      "Epoch 2126, Loss: 0.0007030478377600957, Final Batch Loss: 5.038113613409223e-06\n",
      "Epoch 2127, Loss: 0.0006758431045454927, Final Batch Loss: 7.936592737678438e-06\n",
      "Epoch 2128, Loss: 0.00550121976993978, Final Batch Loss: 0.0012559671886265278\n",
      "Epoch 2129, Loss: 0.001332988562353421, Final Batch Loss: 1.5609424735885113e-05\n",
      "Epoch 2130, Loss: 0.001010537689580815, Final Batch Loss: 4.510941289481707e-05\n",
      "Epoch 2131, Loss: 0.0015648889093426988, Final Batch Loss: 0.0012575790751725435\n",
      "Epoch 2132, Loss: 0.0005182331296964549, Final Batch Loss: 9.530128590995446e-05\n",
      "Epoch 2133, Loss: 0.007203471664979588, Final Batch Loss: 0.0001233263174071908\n",
      "Epoch 2134, Loss: 0.0013858966194675304, Final Batch Loss: 0.001161229913122952\n",
      "Epoch 2135, Loss: 0.10088724145316519, Final Batch Loss: 0.09669192135334015\n",
      "Epoch 2136, Loss: 0.00696371155208908, Final Batch Loss: 7.432961137965322e-05\n",
      "Epoch 2137, Loss: 0.041547751519829035, Final Batch Loss: 0.00550609128549695\n",
      "Epoch 2138, Loss: 0.03068812266610621, Final Batch Loss: 2.2943620933801867e-05\n",
      "Epoch 2139, Loss: 0.030250368465203792, Final Batch Loss: 6.14047166891396e-05\n",
      "Epoch 2140, Loss: 0.01078626699745655, Final Batch Loss: 0.00041929574217647314\n",
      "Epoch 2141, Loss: 0.006632641387113836, Final Batch Loss: 8.328214607900009e-05\n",
      "Epoch 2142, Loss: 0.002253170736366883, Final Batch Loss: 0.0003275331691838801\n",
      "Epoch 2143, Loss: 0.0158102010791481, Final Batch Loss: 4.498422640608624e-06\n",
      "Epoch 2144, Loss: 0.0027550587146834005, Final Batch Loss: 2.0327210222603753e-05\n",
      "Epoch 2145, Loss: 0.001105998810089659, Final Batch Loss: 8.532479114364833e-06\n",
      "Epoch 2146, Loss: 0.01690244181372691, Final Batch Loss: 0.0015544707421213388\n",
      "Epoch 2147, Loss: 0.005906162783503532, Final Batch Loss: 0.0017978178802877665\n",
      "Epoch 2148, Loss: 0.0008659860395709984, Final Batch Loss: 2.491959457984194e-05\n",
      "Epoch 2149, Loss: 0.0032743059782660566, Final Batch Loss: 9.293984476244077e-05\n",
      "Epoch 2150, Loss: 0.0016425577487098053, Final Batch Loss: 0.00023530614271294326\n",
      "Epoch 2151, Loss: 0.0013663192294188775, Final Batch Loss: 9.506152855465189e-05\n",
      "Epoch 2152, Loss: 0.0011553495132829994, Final Batch Loss: 0.00019248858734499663\n",
      "Epoch 2153, Loss: 0.0006349128816509619, Final Batch Loss: 0.00016809745284263045\n",
      "Epoch 2154, Loss: 0.007739157881587744, Final Batch Loss: 0.005882736761122942\n",
      "Epoch 2155, Loss: 0.026385175297036767, Final Batch Loss: 0.0014226846396923065\n",
      "Epoch 2156, Loss: 0.0030268521804828197, Final Batch Loss: 0.0015514027327299118\n",
      "Epoch 2157, Loss: 0.0014401508979062783, Final Batch Loss: 1.568428888276685e-05\n",
      "Epoch 2158, Loss: 0.0015586671070195735, Final Batch Loss: 0.0001221484417328611\n",
      "Epoch 2159, Loss: 0.0019022543710889295, Final Batch Loss: 0.00013688283797819167\n",
      "Epoch 2160, Loss: 0.006012219935655594, Final Batch Loss: 0.004369689617305994\n",
      "Epoch 2161, Loss: 0.0018010119092650712, Final Batch Loss: 0.0003902738681063056\n",
      "Epoch 2162, Loss: 0.002434661873849109, Final Batch Loss: 0.0011048874584957957\n",
      "Epoch 2163, Loss: 0.0011228124203626066, Final Batch Loss: 0.0004902429645881057\n",
      "Epoch 2164, Loss: 0.0007478372808691347, Final Batch Loss: 2.572175617387984e-05\n",
      "Epoch 2165, Loss: 0.0025851742684608325, Final Batch Loss: 7.971386366989464e-05\n",
      "Epoch 2166, Loss: 0.00035008210033993237, Final Batch Loss: 1.9154202163917944e-05\n",
      "Epoch 2167, Loss: 0.0015166772354859859, Final Batch Loss: 0.00044595004874281585\n",
      "Epoch 2168, Loss: 0.002372816059505567, Final Batch Loss: 0.00041199297993443906\n",
      "Epoch 2169, Loss: 0.0007732745725661516, Final Batch Loss: 0.0001294320245506242\n",
      "Epoch 2170, Loss: 0.0021153118868824095, Final Batch Loss: 0.00028417567955330014\n",
      "Epoch 2171, Loss: 0.003028203373105498, Final Batch Loss: 4.572757825371809e-05\n",
      "Epoch 2172, Loss: 0.001437209066352807, Final Batch Loss: 0.00017936497170012444\n",
      "Epoch 2173, Loss: 0.0003167773379573191, Final Batch Loss: 5.6529520406911615e-06\n",
      "Epoch 2174, Loss: 0.007056993475998752, Final Batch Loss: 0.0009948468068614602\n",
      "Epoch 2175, Loss: 0.0033488477783976123, Final Batch Loss: 1.703300222288817e-05\n",
      "Epoch 2176, Loss: 0.0008880592795321718, Final Batch Loss: 0.00012933935795444995\n",
      "Epoch 2177, Loss: 0.01174442574057366, Final Batch Loss: 7.779956945341837e-07\n",
      "Epoch 2178, Loss: 0.003100234377598099, Final Batch Loss: 1.1154977073601913e-05\n",
      "Epoch 2179, Loss: 0.0008257893541667727, Final Batch Loss: 7.522413397964556e-06\n",
      "Epoch 2180, Loss: 0.002468338963808492, Final Batch Loss: 0.0015210601268336177\n",
      "Epoch 2181, Loss: 0.02037595917499857, Final Batch Loss: 0.0015297203790396452\n",
      "Epoch 2182, Loss: 0.023907490805868292, Final Batch Loss: 2.3527863959316164e-06\n",
      "Epoch 2183, Loss: 0.002655840231454931, Final Batch Loss: 4.941198858432472e-05\n",
      "Epoch 2184, Loss: 0.008421882806942449, Final Batch Loss: 3.0052851798245683e-06\n",
      "Epoch 2185, Loss: 0.0017684150370769203, Final Batch Loss: 0.0003061771858483553\n",
      "Epoch 2186, Loss: 0.0014920254179742187, Final Batch Loss: 6.194651359692216e-05\n",
      "Epoch 2187, Loss: 0.0005512519273906946, Final Batch Loss: 7.039401680231094e-06\n",
      "Epoch 2188, Loss: 0.0009182040781752221, Final Batch Loss: 1.56226144554239e-06\n",
      "Epoch 2189, Loss: 0.010032370841145166, Final Batch Loss: 2.28295484703267e-05\n",
      "Epoch 2190, Loss: 0.0007154592749429867, Final Batch Loss: 0.000156635491293855\n",
      "Epoch 2191, Loss: 0.004105601164610562, Final Batch Loss: 4.5549782043963205e-06\n",
      "Epoch 2192, Loss: 0.0027981243329122663, Final Batch Loss: 8.690136019140482e-05\n",
      "Epoch 2193, Loss: 0.004786110366694629, Final Batch Loss: 0.0032005321700125933\n",
      "Epoch 2194, Loss: 0.000764779805138005, Final Batch Loss: 6.399645258170494e-07\n",
      "Epoch 2195, Loss: 0.003845599727355875, Final Batch Loss: 0.0024615528527647257\n",
      "Epoch 2196, Loss: 0.003414282912217459, Final Batch Loss: 6.681761533400277e-06\n",
      "Epoch 2197, Loss: 0.013430480103124864, Final Batch Loss: 0.0036892087664455175\n",
      "Epoch 2198, Loss: 0.0024582315072620986, Final Batch Loss: 1.2309463272686116e-05\n",
      "Epoch 2199, Loss: 0.004538692446658388, Final Batch Loss: 0.0016961880028247833\n",
      "Epoch 2200, Loss: 0.0006729474189342, Final Batch Loss: 0.00010405424836790189\n",
      "Epoch 2201, Loss: 0.0020512891096586827, Final Batch Loss: 1.1236556019866839e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2202, Loss: 0.0010044332811958157, Final Batch Loss: 7.390596874756739e-05\n",
      "Epoch 2203, Loss: 0.0006288049416980357, Final Batch Loss: 1.1939272553718183e-05\n",
      "Epoch 2204, Loss: 0.00047227263871718606, Final Batch Loss: 3.4068596050929045e-06\n",
      "Epoch 2205, Loss: 0.0010602145703160204, Final Batch Loss: 9.765174036147073e-05\n",
      "Epoch 2206, Loss: 0.0013124232064001262, Final Batch Loss: 0.00028424366610124707\n",
      "Epoch 2207, Loss: 0.0010079652711283416, Final Batch Loss: 0.0002788944111671299\n",
      "Epoch 2208, Loss: 0.0020735961079481058, Final Batch Loss: 7.099276263033971e-05\n",
      "Epoch 2209, Loss: 0.0019314476594445296, Final Batch Loss: 6.236225453903899e-05\n",
      "Epoch 2210, Loss: 0.0007807152942405082, Final Batch Loss: 1.4724537322763354e-05\n",
      "Epoch 2211, Loss: 0.000872014006745303, Final Batch Loss: 4.4904594687977806e-05\n",
      "Epoch 2212, Loss: 0.010675369276214042, Final Batch Loss: 2.2877860828884877e-05\n",
      "Epoch 2213, Loss: 0.0003763307477129274, Final Batch Loss: 7.729308890702669e-06\n",
      "Epoch 2214, Loss: 0.0010921830632923957, Final Batch Loss: 1.9826200059469556e-06\n",
      "Epoch 2215, Loss: 0.0017474790220148861, Final Batch Loss: 0.000486623786855489\n",
      "Epoch 2216, Loss: 0.018174958546296693, Final Batch Loss: 0.00012321746908128262\n",
      "Epoch 2217, Loss: 0.0005879787677258719, Final Batch Loss: 4.127370266360231e-05\n",
      "Epoch 2218, Loss: 0.0022611795575357974, Final Batch Loss: 4.2215397115796804e-05\n",
      "Epoch 2219, Loss: 0.0018146466027246788, Final Batch Loss: 8.113782678265125e-05\n",
      "Epoch 2220, Loss: 0.005007017869502306, Final Batch Loss: 0.000414631882449612\n",
      "Epoch 2221, Loss: 0.0005402757597039454, Final Batch Loss: 9.98583491309546e-05\n",
      "Epoch 2222, Loss: 0.05023461372041993, Final Batch Loss: 5.144815418134385e-07\n",
      "Epoch 2223, Loss: 0.0020022994685859885, Final Batch Loss: 1.777312354533933e-05\n",
      "Epoch 2224, Loss: 0.00193400913849473, Final Batch Loss: 0.0011009667068719864\n",
      "Epoch 2225, Loss: 0.0027916815897697234, Final Batch Loss: 1.166304082289571e-05\n",
      "Epoch 2226, Loss: 0.0010879907604248729, Final Batch Loss: 5.277446689433418e-05\n",
      "Epoch 2227, Loss: 0.0004084555862391426, Final Batch Loss: 3.4382123885734472e-06\n",
      "Epoch 2228, Loss: 0.019133547211822588, Final Batch Loss: 1.2798591342289e-05\n",
      "Epoch 2229, Loss: 0.002523605289752595, Final Batch Loss: 0.00023442627571057528\n",
      "Epoch 2230, Loss: 0.00140876391378697, Final Batch Loss: 3.8575162761844695e-05\n",
      "Epoch 2231, Loss: 0.0243010469712317, Final Batch Loss: 0.0013442141935229301\n",
      "Epoch 2232, Loss: 0.0010234882502118126, Final Batch Loss: 1.768542279023677e-05\n",
      "Epoch 2233, Loss: 0.0007534632331953617, Final Batch Loss: 2.1443340301630087e-05\n",
      "Epoch 2234, Loss: 0.0028868537046946585, Final Batch Loss: 0.00021756550995633006\n",
      "Epoch 2235, Loss: 0.001119233504141448, Final Batch Loss: 1.3432767445920035e-05\n",
      "Epoch 2236, Loss: 0.0032277497521135956, Final Batch Loss: 0.002554053207859397\n",
      "Epoch 2237, Loss: 0.022011354856658727, Final Batch Loss: 0.004988517612218857\n",
      "Epoch 2238, Loss: 0.003328297461848706, Final Batch Loss: 7.459780317731202e-05\n",
      "Epoch 2239, Loss: 0.0002532507578507648, Final Batch Loss: 5.6403596317977645e-06\n",
      "Epoch 2240, Loss: 0.0006447250561905093, Final Batch Loss: 1.2196156603749841e-05\n",
      "Epoch 2241, Loss: 0.0007443521290042554, Final Batch Loss: 1.9136032278765924e-06\n",
      "Epoch 2242, Loss: 0.0006371481813403079, Final Batch Loss: 1.6217551092267968e-05\n",
      "Epoch 2243, Loss: 0.0022528824556502514, Final Batch Loss: 3.12839329126291e-05\n",
      "Epoch 2244, Loss: 0.002653006056789309, Final Batch Loss: 0.0021158710587769747\n",
      "Epoch 2245, Loss: 0.003035475907381624, Final Batch Loss: 0.00025812885724008083\n",
      "Epoch 2246, Loss: 0.0007868307984608691, Final Batch Loss: 5.689229510608129e-05\n",
      "Epoch 2247, Loss: 0.0007138228320400231, Final Batch Loss: 3.873279638355598e-05\n",
      "Epoch 2248, Loss: 0.0012348856835160404, Final Batch Loss: 0.0003556405717972666\n",
      "Epoch 2249, Loss: 0.005372082756366581, Final Batch Loss: 0.0006798331160098314\n",
      "Epoch 2250, Loss: 0.0004701527359429747, Final Batch Loss: 1.7007492715492845e-05\n",
      "Epoch 2251, Loss: 0.0003171295793436002, Final Batch Loss: 1.778533260221593e-05\n",
      "Epoch 2252, Loss: 0.0013537495105993003, Final Batch Loss: 0.0001766622590366751\n",
      "Epoch 2253, Loss: 0.0036427636587177403, Final Batch Loss: 6.625470268772915e-05\n",
      "Epoch 2254, Loss: 0.0005067853306286452, Final Batch Loss: 7.59169608954835e-07\n",
      "Epoch 2255, Loss: 0.0005099046814294184, Final Batch Loss: 7.529005330297878e-08\n",
      "Epoch 2256, Loss: 0.001636287968722172, Final Batch Loss: 3.2575204386375844e-05\n",
      "Epoch 2257, Loss: 0.004287654533982277, Final Batch Loss: 0.0005859321099705994\n",
      "Epoch 2258, Loss: 0.0014603619642912236, Final Batch Loss: 3.65146888725576e-06\n",
      "Epoch 2259, Loss: 0.0004014475052827038, Final Batch Loss: 6.774131179554388e-05\n",
      "Epoch 2260, Loss: 0.0016017785965232179, Final Batch Loss: 0.0005918093957006931\n",
      "Epoch 2261, Loss: 0.0012236248730914667, Final Batch Loss: 2.9427101253531873e-05\n",
      "Epoch 2262, Loss: 0.0024377931367780548, Final Batch Loss: 4.253851875546388e-05\n",
      "Epoch 2263, Loss: 0.0007580529054393992, Final Batch Loss: 0.0003206648398190737\n",
      "Epoch 2264, Loss: 0.0011099329094577115, Final Batch Loss: 3.434002792346291e-05\n",
      "Epoch 2265, Loss: 0.0018349927704548463, Final Batch Loss: 4.8568370402790606e-05\n",
      "Epoch 2266, Loss: 0.014227693431735133, Final Batch Loss: 8.344619573108503e-07\n",
      "Epoch 2267, Loss: 0.001270992826903239, Final Batch Loss: 0.0006434681126847863\n",
      "Epoch 2268, Loss: 0.013803159137523835, Final Batch Loss: 3.7142488054087153e-06\n",
      "Epoch 2269, Loss: 0.0026659584432309202, Final Batch Loss: 5.119643446960254e-06\n",
      "Epoch 2270, Loss: 0.0007279998785634234, Final Batch Loss: 5.790945124317659e-06\n",
      "Epoch 2271, Loss: 0.0038698412536177784, Final Batch Loss: 0.0034054466523230076\n",
      "Epoch 2272, Loss: 0.0025411125679966062, Final Batch Loss: 8.658308070152998e-05\n",
      "Epoch 2273, Loss: 0.000801349597168155, Final Batch Loss: 5.639430310111493e-05\n",
      "Epoch 2274, Loss: 0.002832329801094602, Final Batch Loss: 1.3230803233454935e-05\n",
      "Epoch 2275, Loss: 0.024190403913962655, Final Batch Loss: 7.700284186284989e-05\n",
      "Epoch 2276, Loss: 0.0014238103613024577, Final Batch Loss: 4.641576379071921e-05\n",
      "Epoch 2277, Loss: 0.0009959784456441412, Final Batch Loss: 2.521403985156212e-05\n",
      "Epoch 2278, Loss: 0.0032176688910112716, Final Batch Loss: 6.107387162046507e-05\n",
      "Epoch 2279, Loss: 0.0004852298952755518, Final Batch Loss: 7.715351966908202e-05\n",
      "Epoch 2280, Loss: 0.0037216010969132185, Final Batch Loss: 0.00013857288286089897\n",
      "Epoch 2281, Loss: 0.0035150989569956437, Final Batch Loss: 0.003274184186011553\n",
      "Epoch 2282, Loss: 0.000776034125010483, Final Batch Loss: 0.00015244506357703358\n",
      "Epoch 2283, Loss: 0.0009773779231636581, Final Batch Loss: 3.0868461635691347e-06\n",
      "Epoch 2284, Loss: 0.0012706659799732734, Final Batch Loss: 8.26245013740845e-06\n",
      "Epoch 2285, Loss: 0.0007864070123559941, Final Batch Loss: 2.402992549832561e-06\n",
      "Epoch 2286, Loss: 0.0017151761334162074, Final Batch Loss: 9.913113672155305e-07\n",
      "Epoch 2287, Loss: 0.010543640011746902, Final Batch Loss: 6.162795034470037e-05\n",
      "Epoch 2288, Loss: 0.0010201029654126614, Final Batch Loss: 0.0005773465964011848\n",
      "Epoch 2289, Loss: 0.0002851590215868782, Final Batch Loss: 4.498400812735781e-06\n",
      "Epoch 2290, Loss: 0.0010254322951368522, Final Batch Loss: 3.8845257222419605e-05\n",
      "Epoch 2291, Loss: 0.0025827803156062146, Final Batch Loss: 1.7253887563128956e-06\n",
      "Epoch 2292, Loss: 0.002403533390861412, Final Batch Loss: 1.2917457752337214e-05\n",
      "Epoch 2293, Loss: 0.0059903021128775435, Final Batch Loss: 8.413359864789527e-06\n",
      "Epoch 2294, Loss: 0.0005759461054140047, Final Batch Loss: 1.3112875194565277e-06\n",
      "Epoch 2295, Loss: 0.0012549645134640741, Final Batch Loss: 7.327990715566557e-06\n",
      "Epoch 2296, Loss: 0.0018624727599672042, Final Batch Loss: 0.00011060368706239387\n",
      "Epoch 2297, Loss: 0.0021172258420847356, Final Batch Loss: 0.00035924403346143663\n",
      "Epoch 2298, Loss: 0.0009055401569639798, Final Batch Loss: 1.6286383470287547e-05\n",
      "Epoch 2299, Loss: 0.0013498248099494958, Final Batch Loss: 1.1066827937611379e-05\n",
      "Epoch 2300, Loss: 0.0012318428343860433, Final Batch Loss: 7.138456567190588e-05\n",
      "Epoch 2301, Loss: 0.0016958822088781744, Final Batch Loss: 0.00083602947415784\n",
      "Epoch 2302, Loss: 0.0005768136829829018, Final Batch Loss: 6.662994110229192e-06\n",
      "Epoch 2303, Loss: 0.03361325239529833, Final Batch Loss: 0.017519673332571983\n",
      "Epoch 2304, Loss: 0.0013503741211025044, Final Batch Loss: 0.0006875350372865796\n",
      "Epoch 2305, Loss: 0.002248759996291483, Final Batch Loss: 3.111132900812663e-05\n",
      "Epoch 2306, Loss: 0.03304221876896918, Final Batch Loss: 0.019455425441265106\n",
      "Epoch 2307, Loss: 0.019182940261089243, Final Batch Loss: 0.00017120498523581773\n",
      "Epoch 2308, Loss: 0.001066273147444008, Final Batch Loss: 2.7175581635674462e-05\n",
      "Epoch 2309, Loss: 0.01198152835786459, Final Batch Loss: 5.0309889047639444e-05\n",
      "Epoch 2310, Loss: 0.0210742197343734, Final Batch Loss: 1.3175706499168882e-06\n",
      "Epoch 2311, Loss: 0.002012052518693963, Final Batch Loss: 1.532675014459528e-05\n",
      "Epoch 2312, Loss: 0.0004458685452846112, Final Batch Loss: 2.8569296773639508e-05\n",
      "Epoch 2313, Loss: 0.006393712712451816, Final Batch Loss: 0.004935458302497864\n",
      "Epoch 2314, Loss: 0.0009103987904381938, Final Batch Loss: 5.679103924194351e-05\n",
      "Epoch 2315, Loss: 0.003245324856834486, Final Batch Loss: 0.00042231709812767804\n",
      "Epoch 2316, Loss: 0.010602081900287885, Final Batch Loss: 7.902039942564443e-05\n",
      "Epoch 2317, Loss: 0.0015255890029948205, Final Batch Loss: 0.0005624877521768212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2318, Loss: 0.0009681063529569656, Final Batch Loss: 0.0004778904840350151\n",
      "Epoch 2319, Loss: 0.001076261767593678, Final Batch Loss: 8.501047705067322e-05\n",
      "Epoch 2320, Loss: 0.0031011541723273695, Final Batch Loss: 0.0010660446714609861\n",
      "Epoch 2321, Loss: 0.0023411316416286354, Final Batch Loss: 1.3865848131899838e-06\n",
      "Epoch 2322, Loss: 0.0008450232853647321, Final Batch Loss: 0.00010571535676717758\n",
      "Epoch 2323, Loss: 0.0007557615535915829, Final Batch Loss: 3.761001426028088e-05\n",
      "Epoch 2324, Loss: 0.02629900540341623, Final Batch Loss: 0.02517080307006836\n",
      "Epoch 2325, Loss: 0.0009271704639104428, Final Batch Loss: 2.097213473462034e-05\n",
      "Epoch 2326, Loss: 0.01184579185610346, Final Batch Loss: 6.30519753030967e-06\n",
      "Epoch 2327, Loss: 0.011786228983510227, Final Batch Loss: 1.3224932445154991e-05\n",
      "Epoch 2328, Loss: 0.012244533165358007, Final Batch Loss: 0.00024534936528652906\n",
      "Epoch 2329, Loss: 0.001128830122411273, Final Batch Loss: 3.3253070341743296e-07\n",
      "Epoch 2330, Loss: 0.010289645155808103, Final Batch Loss: 1.919876467582071e-06\n",
      "Epoch 2331, Loss: 0.0006457749441324268, Final Batch Loss: 3.061595998588018e-05\n",
      "Epoch 2332, Loss: 0.006843711591500323, Final Batch Loss: 3.98560005123727e-05\n",
      "Epoch 2333, Loss: 0.014297291781986132, Final Batch Loss: 3.053867840208113e-05\n",
      "Epoch 2334, Loss: 0.00100670969550265, Final Batch Loss: 1.9780789443757385e-05\n",
      "Epoch 2335, Loss: 0.010464406153914751, Final Batch Loss: 3.118231688858941e-06\n",
      "Epoch 2336, Loss: 0.0017632852323004045, Final Batch Loss: 4.124771658098325e-05\n",
      "Epoch 2337, Loss: 0.002630528120789677, Final Batch Loss: 0.0008732958813197911\n",
      "Epoch 2338, Loss: 0.0011936949158553034, Final Batch Loss: 0.00013290483911987394\n",
      "Epoch 2339, Loss: 0.0020231886678629962, Final Batch Loss: 6.1987607296032365e-06\n",
      "Epoch 2340, Loss: 0.0010346848575863987, Final Batch Loss: 0.000707046187017113\n",
      "Epoch 2341, Loss: 0.013141759003701736, Final Batch Loss: 3.639015631051734e-07\n",
      "Epoch 2342, Loss: 0.01153184708664412, Final Batch Loss: 7.027060746622737e-07\n",
      "Epoch 2343, Loss: 0.00039863592974143103, Final Batch Loss: 0.00010354544792789966\n",
      "Epoch 2344, Loss: 0.0023215407563839108, Final Batch Loss: 0.0003626155375968665\n",
      "Epoch 2345, Loss: 0.0004665887827286497, Final Batch Loss: 0.00023745720682200044\n",
      "Epoch 2346, Loss: 0.012421874278516043, Final Batch Loss: 8.306344534503296e-05\n",
      "Epoch 2347, Loss: 0.002726803286350332, Final Batch Loss: 0.00012291267921682447\n",
      "Epoch 2348, Loss: 0.002830996294505894, Final Batch Loss: 0.0011016071075573564\n",
      "Epoch 2349, Loss: 0.004803352057933807, Final Batch Loss: 0.004390764981508255\n",
      "Epoch 2350, Loss: 0.005967355726170354, Final Batch Loss: 9.099119051825255e-05\n",
      "Epoch 2351, Loss: 0.013866987836081535, Final Batch Loss: 3.9580074371770024e-05\n",
      "Epoch 2352, Loss: 0.0010037328811449697, Final Batch Loss: 2.0815676180063747e-05\n",
      "Epoch 2353, Loss: 0.0017183174186357064, Final Batch Loss: 1.06278730527265e-05\n",
      "Epoch 2354, Loss: 0.04218373089679517, Final Batch Loss: 0.0004584178968798369\n",
      "Epoch 2355, Loss: 0.0006459507494582795, Final Batch Loss: 1.990049349842593e-05\n",
      "Epoch 2356, Loss: 0.0015597515011904761, Final Batch Loss: 1.9572515157051384e-05\n",
      "Epoch 2357, Loss: 0.002044650238531176, Final Batch Loss: 8.321737550431862e-05\n",
      "Epoch 2358, Loss: 0.0005158928252058104, Final Batch Loss: 0.0002164972247555852\n",
      "Epoch 2359, Loss: 0.0013689807092305273, Final Batch Loss: 0.0002798738132696599\n",
      "Epoch 2360, Loss: 0.004411856411024928, Final Batch Loss: 0.0022359113208949566\n",
      "Epoch 2361, Loss: 0.0020662637252826244, Final Batch Loss: 0.000224012735998258\n",
      "Epoch 2362, Loss: 0.0005480365762196016, Final Batch Loss: 1.0000436304835603e-05\n",
      "Epoch 2363, Loss: 0.01970203153541661, Final Batch Loss: 4.2391966417199e-05\n",
      "Epoch 2364, Loss: 0.0012281175368116237, Final Batch Loss: 4.079801874468103e-05\n",
      "Epoch 2365, Loss: 0.014316631041765504, Final Batch Loss: 9.849737580225337e-06\n",
      "Epoch 2366, Loss: 0.001426497441570973, Final Batch Loss: 3.3016422094078735e-05\n",
      "Epoch 2367, Loss: 0.01696735636505764, Final Batch Loss: 0.002312264172360301\n",
      "Epoch 2368, Loss: 0.0006098308731452562, Final Batch Loss: 7.916815957287326e-05\n",
      "Epoch 2369, Loss: 0.005589639680692926, Final Batch Loss: 0.0012672074371948838\n",
      "Epoch 2370, Loss: 0.004132909787585959, Final Batch Loss: 7.599600940011442e-05\n",
      "Epoch 2371, Loss: 0.001225588086526841, Final Batch Loss: 0.000254094775300473\n",
      "Epoch 2372, Loss: 0.008922915701987222, Final Batch Loss: 0.008105290122330189\n",
      "Epoch 2373, Loss: 0.02459836076013744, Final Batch Loss: 6.418093107640743e-05\n",
      "Epoch 2374, Loss: 0.0020691319568868494, Final Batch Loss: 1.4127950635156594e-05\n",
      "Epoch 2375, Loss: 0.0020474068660405464, Final Batch Loss: 7.51986590330489e-05\n",
      "Epoch 2376, Loss: 0.00483322763761862, Final Batch Loss: 2.515927235435811e-06\n",
      "Epoch 2377, Loss: 0.004180665342573775, Final Batch Loss: 4.7808098315726966e-06\n",
      "Epoch 2378, Loss: 0.0008949815291998675, Final Batch Loss: 1.701453402347397e-05\n",
      "Epoch 2379, Loss: 0.001645756754442118, Final Batch Loss: 0.0011223906185477972\n",
      "Epoch 2380, Loss: 0.03747094467689749, Final Batch Loss: 0.0004503304953686893\n",
      "Epoch 2381, Loss: 0.000831593839393463, Final Batch Loss: 7.368006481556222e-05\n",
      "Epoch 2382, Loss: 0.0012159123143646866, Final Batch Loss: 8.157273987308145e-05\n",
      "Epoch 2383, Loss: 0.0003928949372493662, Final Batch Loss: 7.88439137977548e-05\n",
      "Epoch 2384, Loss: 0.0034003602540906286, Final Batch Loss: 2.790210237435531e-05\n",
      "Epoch 2385, Loss: 0.0005505187291419134, Final Batch Loss: 0.00019722619617823511\n",
      "Epoch 2386, Loss: 0.0009273045689042192, Final Batch Loss: 2.4391843908233568e-05\n",
      "Epoch 2387, Loss: 0.0038430495624197647, Final Batch Loss: 0.0029888791032135487\n",
      "Epoch 2388, Loss: 0.0017306840454693884, Final Batch Loss: 0.0004581768880598247\n",
      "Epoch 2389, Loss: 0.0026094896311406046, Final Batch Loss: 0.00036124829784967005\n",
      "Epoch 2390, Loss: 0.00252344592990994, Final Batch Loss: 1.668788718234282e-05\n",
      "Epoch 2391, Loss: 0.00020629051141440868, Final Batch Loss: 5.364283060771413e-05\n",
      "Epoch 2392, Loss: 0.007139385721529834, Final Batch Loss: 0.0020280347671359777\n",
      "Epoch 2393, Loss: 0.0002689574357646052, Final Batch Loss: 4.6041077439440414e-05\n",
      "Epoch 2394, Loss: 0.00032736389107412833, Final Batch Loss: 3.8145778944453923e-06\n",
      "Epoch 2395, Loss: 0.0003090172649535816, Final Batch Loss: 3.2955027563730255e-05\n",
      "Epoch 2396, Loss: 0.000360666841515922, Final Batch Loss: 1.9867869923473336e-05\n",
      "Epoch 2397, Loss: 0.0008464477068628184, Final Batch Loss: 0.00037486819201149046\n",
      "Epoch 2398, Loss: 0.0013789484000881203, Final Batch Loss: 0.0008852244354784489\n",
      "Epoch 2399, Loss: 0.0014902592629368883, Final Batch Loss: 5.745983435190283e-05\n",
      "Epoch 2400, Loss: 0.0015910206093394663, Final Batch Loss: 6.794722139602527e-06\n",
      "Epoch 2401, Loss: 0.0009774307491170475, Final Batch Loss: 1.971626807062421e-05\n",
      "Epoch 2402, Loss: 0.0004496274045777682, Final Batch Loss: 3.08056723952177e-06\n",
      "Epoch 2403, Loss: 0.0006437154653440302, Final Batch Loss: 1.524603362668131e-06\n",
      "Epoch 2404, Loss: 0.0003806538393860137, Final Batch Loss: 5.270290444059356e-07\n",
      "Epoch 2405, Loss: 0.012794016372254191, Final Batch Loss: 3.469532430244726e-06\n",
      "Epoch 2406, Loss: 0.0019091248632321367, Final Batch Loss: 1.5752471881569363e-05\n",
      "Epoch 2407, Loss: 0.0016807125655873278, Final Batch Loss: 7.215283517325588e-07\n",
      "Epoch 2408, Loss: 0.0007817846910143089, Final Batch Loss: 5.144813144397631e-07\n",
      "Epoch 2409, Loss: 0.00042151175875915214, Final Batch Loss: 5.716284067602828e-05\n",
      "Epoch 2410, Loss: 0.0009950617095455527, Final Batch Loss: 4.6125060180202127e-05\n",
      "Epoch 2411, Loss: 0.000823816008050926, Final Batch Loss: 0.0004550332378130406\n",
      "Epoch 2412, Loss: 0.0005528521904238914, Final Batch Loss: 5.333020567377389e-07\n",
      "Epoch 2413, Loss: 0.0005054428693256341, Final Batch Loss: 9.423114534001797e-06\n",
      "Epoch 2414, Loss: 0.0036561629312927835, Final Batch Loss: 3.5255645343568176e-05\n",
      "Epoch 2415, Loss: 0.0038930756272748113, Final Batch Loss: 0.0019035350997000933\n",
      "Epoch 2416, Loss: 0.0012625254166778177, Final Batch Loss: 0.00044770631939172745\n",
      "Epoch 2417, Loss: 0.0003068083456128079, Final Batch Loss: 2.6602060643199366e-06\n",
      "Epoch 2418, Loss: 0.02216320648585679, Final Batch Loss: 3.358099638717249e-05\n",
      "Epoch 2419, Loss: 0.022030081247066846, Final Batch Loss: 3.274803384556435e-05\n",
      "Epoch 2420, Loss: 0.000760899783927016, Final Batch Loss: 0.00014364025264512748\n",
      "Epoch 2421, Loss: 0.0006910140282343491, Final Batch Loss: 1.5151402294577565e-05\n",
      "Epoch 2422, Loss: 0.0004837173873966094, Final Batch Loss: 5.339838025975041e-05\n",
      "Epoch 2423, Loss: 0.0026977688976330683, Final Batch Loss: 0.0003125544753856957\n",
      "Epoch 2424, Loss: 0.00023779850744176656, Final Batch Loss: 5.3472860599868e-05\n",
      "Epoch 2425, Loss: 0.0067721202212851495, Final Batch Loss: 0.00018462046864442527\n",
      "Epoch 2426, Loss: 0.025819647977186833, Final Batch Loss: 4.8394147597718984e-05\n",
      "Epoch 2427, Loss: 0.0005446975083032157, Final Batch Loss: 5.320341369952075e-05\n",
      "Epoch 2428, Loss: 0.0007160566601669416, Final Batch Loss: 0.0001378963643219322\n",
      "Epoch 2429, Loss: 0.0004510598809019939, Final Batch Loss: 1.5120602938623051e-06\n",
      "Epoch 2430, Loss: 0.0016404501220677048, Final Batch Loss: 0.0007800932507961988\n",
      "Epoch 2431, Loss: 0.0009590291799668194, Final Batch Loss: 2.8672718599409563e-06\n",
      "Epoch 2432, Loss: 0.0012437158657121472, Final Batch Loss: 0.0003634949098341167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2433, Loss: 0.003552114612830337, Final Batch Loss: 1.7333739378955215e-05\n",
      "Epoch 2434, Loss: 0.0008043055277084932, Final Batch Loss: 0.0001487620611442253\n",
      "Epoch 2435, Loss: 0.004162968692071445, Final Batch Loss: 1.2403560504026245e-05\n",
      "Epoch 2436, Loss: 0.0016304422460962087, Final Batch Loss: 0.0009120554896071553\n",
      "Epoch 2437, Loss: 0.0036767670026165433, Final Batch Loss: 8.626557973911986e-05\n",
      "Epoch 2438, Loss: 0.033333770181343425, Final Batch Loss: 6.779650721000507e-05\n",
      "Epoch 2439, Loss: 0.0012439354107911527, Final Batch Loss: 1.0038672115797453e-07\n",
      "Epoch 2440, Loss: 0.0022985136893112212, Final Batch Loss: 0.0009761473047547042\n",
      "Epoch 2441, Loss: 0.0014693811608594842, Final Batch Loss: 0.001172989490441978\n",
      "Epoch 2442, Loss: 0.0008319584376295097, Final Batch Loss: 7.948105485411361e-05\n",
      "Epoch 2443, Loss: 0.0007395521494117929, Final Batch Loss: 1.8822504443960497e-07\n",
      "Epoch 2444, Loss: 0.0009405528835486621, Final Batch Loss: 0.0006440911092795432\n",
      "Epoch 2445, Loss: 0.0007288687647815095, Final Batch Loss: 2.5727002139319666e-05\n",
      "Epoch 2446, Loss: 0.01380126273534188, Final Batch Loss: 7.114627351256786e-06\n",
      "Epoch 2447, Loss: 0.00025733584152476396, Final Batch Loss: 2.0721248802146874e-05\n",
      "Epoch 2448, Loss: 0.00017244950140593573, Final Batch Loss: 1.3413064152700827e-05\n",
      "Epoch 2449, Loss: 0.008665342917083763, Final Batch Loss: 0.00021947927598375827\n",
      "Epoch 2450, Loss: 0.00026117255606550316, Final Batch Loss: 3.375424284968176e-06\n",
      "Epoch 2451, Loss: 0.00037258480460877763, Final Batch Loss: 7.2903103500721045e-06\n",
      "Epoch 2452, Loss: 0.00047756415187905077, Final Batch Loss: 1.9270979464636184e-05\n",
      "Epoch 2453, Loss: 0.002146234157407889, Final Batch Loss: 0.0010946401162073016\n",
      "Epoch 2454, Loss: 0.0021753669643658213, Final Batch Loss: 5.858283111592755e-05\n",
      "Epoch 2455, Loss: 0.000379421906927746, Final Batch Loss: 1.3238445717433933e-06\n",
      "Epoch 2456, Loss: 0.0004592812920236611, Final Batch Loss: 9.071941349247936e-06\n",
      "Epoch 2457, Loss: 0.04305306989408564, Final Batch Loss: 0.03368452936410904\n",
      "Epoch 2458, Loss: 0.0016093396880023647, Final Batch Loss: 3.480977102299221e-05\n",
      "Epoch 2459, Loss: 0.12772291938927083, Final Batch Loss: 2.7563824914977886e-05\n",
      "Epoch 2460, Loss: 0.04555213075798292, Final Batch Loss: 1.2046351685057743e-06\n",
      "Epoch 2461, Loss: 0.0013922162761446089, Final Batch Loss: 5.022363620810211e-05\n",
      "Epoch 2462, Loss: 0.002398544915195089, Final Batch Loss: 2.7731221052818e-06\n",
      "Epoch 2463, Loss: 0.02846768981180503, Final Batch Loss: 2.3004537069937214e-05\n",
      "Epoch 2464, Loss: 0.024386021279497072, Final Batch Loss: 0.00023912169854156673\n",
      "Epoch 2465, Loss: 0.017347124172374606, Final Batch Loss: 0.0003656649496406317\n",
      "Epoch 2466, Loss: 0.0016703155706636608, Final Batch Loss: 0.00016201235121116042\n",
      "Epoch 2467, Loss: 0.0014938209042156814, Final Batch Loss: 1.578499905008357e-05\n",
      "Epoch 2468, Loss: 0.0025895211147144437, Final Batch Loss: 0.001591204316355288\n",
      "Epoch 2469, Loss: 0.003481625986751169, Final Batch Loss: 0.00016745546599850059\n",
      "Epoch 2470, Loss: 0.0009478429492446594, Final Batch Loss: 9.322997357230633e-06\n",
      "Epoch 2471, Loss: 0.0015383779827971011, Final Batch Loss: 0.0008295000880025327\n",
      "Epoch 2472, Loss: 0.0031289879989344627, Final Batch Loss: 0.0003802190476562828\n",
      "Epoch 2473, Loss: 0.01189319857803639, Final Batch Loss: 5.182593304198235e-05\n",
      "Epoch 2474, Loss: 0.003969859943026677, Final Batch Loss: 0.000409199419664219\n",
      "Epoch 2475, Loss: 0.0018325831915717572, Final Batch Loss: 4.494545282796025e-05\n",
      "Epoch 2476, Loss: 0.0018057631968986243, Final Batch Loss: 0.000388541491702199\n",
      "Epoch 2477, Loss: 0.0035703297035070136, Final Batch Loss: 0.0012006721226498485\n",
      "Epoch 2478, Loss: 0.002310622890945524, Final Batch Loss: 0.0005356859182938933\n",
      "Epoch 2479, Loss: 0.008231723517383216, Final Batch Loss: 4.791894389200024e-05\n",
      "Epoch 2480, Loss: 0.0015601625200361013, Final Batch Loss: 0.0006608402472920716\n",
      "Epoch 2481, Loss: 0.003934094565920532, Final Batch Loss: 0.0009269711445085704\n",
      "Epoch 2482, Loss: 0.0016777531836851267, Final Batch Loss: 1.567182880535256e-05\n",
      "Epoch 2483, Loss: 0.003569555698959448, Final Batch Loss: 5.408216566138435e-06\n",
      "Epoch 2484, Loss: 0.001143893096013926, Final Batch Loss: 0.0003765107539948076\n",
      "Epoch 2485, Loss: 0.0013113875102135353, Final Batch Loss: 8.519486436853185e-05\n",
      "Epoch 2486, Loss: 0.0024900719872675836, Final Batch Loss: 0.0005333529552444816\n",
      "Epoch 2487, Loss: 0.0011962190474150702, Final Batch Loss: 0.0007618283270858228\n",
      "Epoch 2488, Loss: 0.13609308161539957, Final Batch Loss: 0.13505330681800842\n",
      "Epoch 2489, Loss: 0.0063434304247493856, Final Batch Loss: 8.688336674822494e-05\n",
      "Epoch 2490, Loss: 0.2757908939383924, Final Batch Loss: 0.21461740136146545\n",
      "Epoch 2491, Loss: 0.0631047972055967, Final Batch Loss: 6.371182826114818e-05\n",
      "Epoch 2492, Loss: 0.007994775020051748, Final Batch Loss: 0.0005159627762623131\n",
      "Epoch 2493, Loss: 0.046920166845666245, Final Batch Loss: 0.0004017022729385644\n",
      "Epoch 2494, Loss: 0.1039846413914347, Final Batch Loss: 7.45956931496039e-05\n",
      "Epoch 2495, Loss: 0.08698528446257114, Final Batch Loss: 0.06419593840837479\n",
      "Epoch 2496, Loss: 0.02404328077682294, Final Batch Loss: 0.0004284867609385401\n",
      "Epoch 2497, Loss: 0.05678017137392999, Final Batch Loss: 2.6978348159900634e-06\n",
      "Epoch 2498, Loss: 0.03772386509808712, Final Batch Loss: 0.0001536435156594962\n",
      "Epoch 2499, Loss: 0.006927419715793803, Final Batch Loss: 0.00029344952781684697\n",
      "Epoch 2500, Loss: 0.010494312053197064, Final Batch Loss: 0.00017282903718296438\n",
      "Epoch 2501, Loss: 0.012564640026539564, Final Batch Loss: 0.005386802833527327\n",
      "Epoch 2502, Loss: 0.01163605564579484, Final Batch Loss: 1.4931534678908065e-05\n",
      "Epoch 2503, Loss: 0.00976807571714744, Final Batch Loss: 0.0010918956249952316\n",
      "Epoch 2504, Loss: 0.006503068114398047, Final Batch Loss: 0.00047181962872855365\n",
      "Epoch 2505, Loss: 0.004289006537874229, Final Batch Loss: 0.00020287699589971453\n",
      "Epoch 2506, Loss: 0.03045221045613289, Final Batch Loss: 0.008951536379754543\n",
      "Epoch 2507, Loss: 0.0037326079327613115, Final Batch Loss: 0.000308940710965544\n",
      "Epoch 2508, Loss: 0.006421431200578809, Final Batch Loss: 0.00024750386364758015\n",
      "Epoch 2509, Loss: 0.01804716254264349, Final Batch Loss: 0.00011217754945391789\n",
      "Epoch 2510, Loss: 0.0142933702445589, Final Batch Loss: 0.0001687136827968061\n",
      "Epoch 2511, Loss: 0.002520470645322348, Final Batch Loss: 2.0307836166466586e-05\n",
      "Epoch 2512, Loss: 0.010685852525057271, Final Batch Loss: 7.644740981049836e-05\n",
      "Epoch 2513, Loss: 0.009159334211290115, Final Batch Loss: 1.7389513232046738e-05\n",
      "Epoch 2514, Loss: 0.005579853524977807, Final Batch Loss: 9.353398490929976e-05\n",
      "Epoch 2515, Loss: 0.035452815936878324, Final Batch Loss: 6.909016519784927e-05\n",
      "Epoch 2516, Loss: 0.003988776239566505, Final Batch Loss: 0.0012139534810557961\n",
      "Epoch 2517, Loss: 0.011060943448683247, Final Batch Loss: 0.00030468785553239286\n",
      "Epoch 2518, Loss: 0.003737212231499143, Final Batch Loss: 0.0001558656949782744\n",
      "Epoch 2519, Loss: 0.005929859937168658, Final Batch Loss: 0.0010159116936847568\n",
      "Epoch 2520, Loss: 0.01350845885463059, Final Batch Loss: 0.00045812944881618023\n",
      "Epoch 2521, Loss: 0.06462851911783218, Final Batch Loss: 0.06106818467378616\n",
      "Epoch 2522, Loss: 0.034312029369175434, Final Batch Loss: 0.02973336912691593\n",
      "Epoch 2523, Loss: 0.0038171003689058125, Final Batch Loss: 0.0006420448771677911\n",
      "Epoch 2524, Loss: 0.022727521136403084, Final Batch Loss: 0.020654665306210518\n",
      "Epoch 2525, Loss: 0.0011644502883427776, Final Batch Loss: 7.78500470914878e-05\n",
      "Epoch 2526, Loss: 0.001241229505467345, Final Batch Loss: 5.088137186248787e-06\n",
      "Epoch 2527, Loss: 0.023575910599902272, Final Batch Loss: 0.00747357401996851\n",
      "Epoch 2528, Loss: 0.035202503320761025, Final Batch Loss: 0.0006940548191778362\n",
      "Epoch 2529, Loss: 0.0049977979506365955, Final Batch Loss: 0.000975285132881254\n",
      "Epoch 2530, Loss: 0.01805067518580472, Final Batch Loss: 8.461527613690123e-05\n",
      "Epoch 2531, Loss: 0.011757421249058098, Final Batch Loss: 0.00981473084539175\n",
      "Epoch 2532, Loss: 0.006266422336921096, Final Batch Loss: 0.0006388530600816011\n",
      "Epoch 2533, Loss: 0.014890862148604356, Final Batch Loss: 0.00023093701747711748\n",
      "Epoch 2534, Loss: 0.005643101897135239, Final Batch Loss: 1.3552131576943793e-06\n",
      "Epoch 2535, Loss: 0.004460504715098068, Final Batch Loss: 0.0003274854680057615\n",
      "Epoch 2536, Loss: 0.0027969995862804353, Final Batch Loss: 0.0004817852168343961\n",
      "Epoch 2537, Loss: 0.003417299478314817, Final Batch Loss: 0.0007136074709706008\n",
      "Epoch 2538, Loss: 0.005258823017356917, Final Batch Loss: 0.003171551041305065\n",
      "Epoch 2539, Loss: 0.002784995856927708, Final Batch Loss: 0.0004480135685298592\n",
      "Epoch 2540, Loss: 0.00475731908227317, Final Batch Loss: 0.00047835384611971676\n",
      "Epoch 2541, Loss: 0.004836296786379535, Final Batch Loss: 8.318189793499187e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2542, Loss: 0.013400261988863349, Final Batch Loss: 0.00041505414992570877\n",
      "Epoch 2543, Loss: 0.003967262691730866, Final Batch Loss: 5.6470573326805606e-05\n",
      "Epoch 2544, Loss: 0.0017447473073843867, Final Batch Loss: 0.000452709587989375\n",
      "Epoch 2545, Loss: 0.0029954305973660666, Final Batch Loss: 3.2998610549839213e-05\n",
      "Epoch 2546, Loss: 0.00392172034480609, Final Batch Loss: 0.002375081181526184\n",
      "Epoch 2547, Loss: 0.02274455176666379, Final Batch Loss: 0.01048523560166359\n",
      "Epoch 2548, Loss: 0.019042637868551537, Final Batch Loss: 9.479932487010956e-06\n",
      "Epoch 2549, Loss: 0.0037038765440229326, Final Batch Loss: 0.0025137856137007475\n",
      "Epoch 2550, Loss: 0.0022625601104664383, Final Batch Loss: 1.5377225281554274e-05\n",
      "Epoch 2551, Loss: 0.0017074948555091396, Final Batch Loss: 0.00013438834866974503\n",
      "Epoch 2552, Loss: 0.005276437499560416, Final Batch Loss: 5.705107469111681e-05\n",
      "Epoch 2553, Loss: 0.0065511972643435, Final Batch Loss: 0.0015958143630996346\n",
      "Epoch 2554, Loss: 0.02041432826081291, Final Batch Loss: 0.000905822089407593\n",
      "Epoch 2555, Loss: 0.005646848876494914, Final Batch Loss: 0.0004829348181374371\n",
      "Epoch 2556, Loss: 0.00365744749433361, Final Batch Loss: 0.0023067372385412455\n",
      "Epoch 2557, Loss: 0.002347752328205388, Final Batch Loss: 3.851280052913353e-05\n",
      "Epoch 2558, Loss: 0.0010150806410820223, Final Batch Loss: 4.5401604438666254e-05\n",
      "Epoch 2559, Loss: 0.02960631691121307, Final Batch Loss: 5.213750682742102e-06\n",
      "Epoch 2560, Loss: 0.010610476252622902, Final Batch Loss: 0.0015059574507176876\n",
      "Epoch 2561, Loss: 0.004790104867424816, Final Batch Loss: 0.00397858489304781\n",
      "Epoch 2562, Loss: 0.007814238022547215, Final Batch Loss: 0.005974477622658014\n",
      "Epoch 2563, Loss: 0.0009860192294581793, Final Batch Loss: 1.2290569429751486e-05\n",
      "Epoch 2564, Loss: 0.01371326160733588, Final Batch Loss: 1.2955773854628205e-05\n",
      "Epoch 2565, Loss: 0.09207735082600266, Final Batch Loss: 0.08872964978218079\n",
      "Epoch 2566, Loss: 0.004146080173086375, Final Batch Loss: 0.00283345696516335\n",
      "Epoch 2567, Loss: 0.010514905999116309, Final Batch Loss: 8.639271072752308e-06\n",
      "Epoch 2568, Loss: 0.005203008577154833, Final Batch Loss: 1.6506686733919196e-05\n",
      "Epoch 2569, Loss: 0.010105282795848325, Final Batch Loss: 0.00014148050104267895\n",
      "Epoch 2570, Loss: 0.029220221491414122, Final Batch Loss: 0.00019703844736795872\n",
      "Epoch 2571, Loss: 0.020700025401310995, Final Batch Loss: 0.00023060108651407063\n",
      "Epoch 2572, Loss: 0.0028057314339093864, Final Batch Loss: 0.00010230991756543517\n",
      "Epoch 2573, Loss: 0.0028641765675274655, Final Batch Loss: 0.00018512200040277094\n",
      "Epoch 2574, Loss: 0.0016509880588273518, Final Batch Loss: 2.321282954653725e-05\n",
      "Epoch 2575, Loss: 0.00914247649780009, Final Batch Loss: 6.293949263636023e-05\n",
      "Epoch 2576, Loss: 0.008491187065374106, Final Batch Loss: 0.0003592243301682174\n",
      "Epoch 2577, Loss: 0.0443786159157753, Final Batch Loss: 0.02515464276075363\n",
      "Epoch 2578, Loss: 0.009718728382722475, Final Batch Loss: 9.686817065812647e-06\n",
      "Epoch 2579, Loss: 0.01702696131542325, Final Batch Loss: 0.0012611454585567117\n",
      "Epoch 2580, Loss: 0.0014354670411194093, Final Batch Loss: 4.479602466744836e-06\n",
      "Epoch 2581, Loss: 0.0023874720063759014, Final Batch Loss: 0.00010703409498091787\n",
      "Epoch 2582, Loss: 0.012140947248553857, Final Batch Loss: 0.0002021165273617953\n",
      "Epoch 2583, Loss: 0.005475469748489559, Final Batch Loss: 0.001082868897356093\n",
      "Epoch 2584, Loss: 0.0024001850015338277, Final Batch Loss: 1.547737883811351e-05\n",
      "Epoch 2585, Loss: 0.021805475946166553, Final Batch Loss: 0.00012901252193842083\n",
      "Epoch 2586, Loss: 0.011780993634602055, Final Batch Loss: 0.010656464844942093\n",
      "Epoch 2587, Loss: 0.0017621648403292056, Final Batch Loss: 5.1327657274669036e-05\n",
      "Epoch 2588, Loss: 0.002639877930050716, Final Batch Loss: 1.2315140338614583e-05\n",
      "Epoch 2589, Loss: 0.003673248429549858, Final Batch Loss: 0.0018605893710628152\n",
      "Epoch 2590, Loss: 0.0031221448371070437, Final Batch Loss: 3.0140938179101795e-05\n",
      "Epoch 2591, Loss: 0.0005406854761531577, Final Batch Loss: 6.943491462152451e-05\n",
      "Epoch 2592, Loss: 0.0159064079853124, Final Batch Loss: 7.145353447413072e-05\n",
      "Epoch 2593, Loss: 0.003257675445638597, Final Batch Loss: 0.00013226977898739278\n",
      "Epoch 2594, Loss: 0.0005273318674881011, Final Batch Loss: 0.00011549139162525535\n",
      "Epoch 2595, Loss: 0.001291354768909514, Final Batch Loss: 0.00017684890190139413\n",
      "Epoch 2596, Loss: 0.004293445910661831, Final Batch Loss: 1.9643635823740624e-05\n",
      "Epoch 2597, Loss: 0.001335782348178327, Final Batch Loss: 0.00026010352303273976\n",
      "Epoch 2598, Loss: 0.01137931966513861, Final Batch Loss: 4.520146467257291e-05\n",
      "Epoch 2599, Loss: 0.010396335572295357, Final Batch Loss: 8.388463902520016e-05\n",
      "Epoch 2600, Loss: 0.0010706528773880564, Final Batch Loss: 0.00010586107237031683\n",
      "Epoch 2601, Loss: 0.011323737446218729, Final Batch Loss: 0.0005940820556133986\n",
      "Epoch 2602, Loss: 0.01651267170382198, Final Batch Loss: 0.0001706859766272828\n",
      "Epoch 2603, Loss: 0.008105950153549202, Final Batch Loss: 0.00014214376278687268\n",
      "Epoch 2604, Loss: 0.0006705034129481646, Final Batch Loss: 1.4191081390890758e-05\n",
      "Epoch 2605, Loss: 0.001751001189404633, Final Batch Loss: 5.462587432703003e-05\n",
      "Epoch 2606, Loss: 0.0013009862741455436, Final Batch Loss: 0.000688979693222791\n",
      "Epoch 2607, Loss: 0.028509868110631942, Final Batch Loss: 1.833713577070739e-05\n",
      "Epoch 2608, Loss: 0.0009029878710862249, Final Batch Loss: 0.00034697679802775383\n",
      "Epoch 2609, Loss: 0.0012107217189623043, Final Batch Loss: 0.00021122732141520828\n",
      "Epoch 2610, Loss: 0.010734512412454933, Final Batch Loss: 0.0006753990310244262\n",
      "Epoch 2611, Loss: 0.001517538883490488, Final Batch Loss: 0.0002583994355518371\n",
      "Epoch 2612, Loss: 0.022062021162128076, Final Batch Loss: 0.00011848713620565832\n",
      "Epoch 2613, Loss: 0.0015941178862703964, Final Batch Loss: 0.0006399773992598057\n",
      "Epoch 2614, Loss: 0.0013545317051466554, Final Batch Loss: 0.000501417089253664\n",
      "Epoch 2615, Loss: 0.0007567861589450331, Final Batch Loss: 3.789520178543171e-06\n",
      "Epoch 2616, Loss: 0.0006060730811441317, Final Batch Loss: 0.00012031129153911024\n",
      "Epoch 2617, Loss: 0.0010839656279131304, Final Batch Loss: 3.120350811514072e-05\n",
      "Epoch 2618, Loss: 0.009107579596957294, Final Batch Loss: 1.951240619746386e-06\n",
      "Epoch 2619, Loss: 0.033451103314291686, Final Batch Loss: 0.0008706946391612291\n",
      "Epoch 2620, Loss: 0.006644815274285065, Final Batch Loss: 2.610041065054247e-06\n",
      "Epoch 2621, Loss: 0.0012615181258297525, Final Batch Loss: 8.845177217153832e-05\n",
      "Epoch 2622, Loss: 0.008789643878117204, Final Batch Loss: 0.0038055286277085543\n",
      "Epoch 2623, Loss: 0.0015965847996994853, Final Batch Loss: 0.0005116721731610596\n",
      "Epoch 2624, Loss: 0.019614194054156542, Final Batch Loss: 0.0019015002762898803\n",
      "Epoch 2625, Loss: 0.0066701615978672635, Final Batch Loss: 4.148624066147022e-05\n",
      "Epoch 2626, Loss: 0.0008375017350772396, Final Batch Loss: 0.0001969323930097744\n",
      "Epoch 2627, Loss: 0.002390810986980796, Final Batch Loss: 0.0005870149470865726\n",
      "Epoch 2628, Loss: 0.0020336807228886755, Final Batch Loss: 2.2712210920872167e-06\n",
      "Epoch 2629, Loss: 0.0020961282230018696, Final Batch Loss: 6.336815658869455e-06\n",
      "Epoch 2630, Loss: 0.004354151707957499, Final Batch Loss: 0.0001912665757117793\n",
      "Epoch 2631, Loss: 0.011303198243695078, Final Batch Loss: 4.207307574688457e-05\n",
      "Epoch 2632, Loss: 0.0029689131188206375, Final Batch Loss: 0.0002490986371412873\n",
      "Epoch 2633, Loss: 0.0008863826369633898, Final Batch Loss: 4.268587508704513e-05\n",
      "Epoch 2634, Loss: 0.0010915148886851966, Final Batch Loss: 0.00015200729831121862\n",
      "Epoch 2635, Loss: 0.011171775942784734, Final Batch Loss: 0.00011206140334252268\n",
      "Epoch 2636, Loss: 0.00568806251976639, Final Batch Loss: 0.0038101167883723974\n",
      "Epoch 2637, Loss: 0.0009605432278476655, Final Batch Loss: 0.0001420477346982807\n",
      "Epoch 2638, Loss: 0.0030999667942523956, Final Batch Loss: 0.001930094906128943\n",
      "Epoch 2639, Loss: 0.03960326251490187, Final Batch Loss: 1.5163052921707276e-05\n",
      "Epoch 2640, Loss: 0.003663338209264566, Final Batch Loss: 7.968170052663481e-07\n",
      "Epoch 2641, Loss: 0.02842449559830129, Final Batch Loss: 0.02629462257027626\n",
      "Epoch 2642, Loss: 0.0024733408936299384, Final Batch Loss: 0.000866814749315381\n",
      "Epoch 2643, Loss: 0.01508586690761149, Final Batch Loss: 0.009462002664804459\n",
      "Epoch 2644, Loss: 0.010524832694500219, Final Batch Loss: 3.681662929011509e-05\n",
      "Epoch 2645, Loss: 0.002040091741946526, Final Batch Loss: 9.341818804387003e-05\n",
      "Epoch 2646, Loss: 0.0029897854547016323, Final Batch Loss: 0.00014203781029209495\n",
      "Epoch 2647, Loss: 0.0030706918914802372, Final Batch Loss: 0.0015669002896174788\n",
      "Epoch 2648, Loss: 0.011132782005006447, Final Batch Loss: 2.5300454581156373e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2649, Loss: 0.0030004725035723823, Final Batch Loss: 9.78767729975516e-07\n",
      "Epoch 2650, Loss: 0.001488066918682307, Final Batch Loss: 0.00026067293947562575\n",
      "Epoch 2651, Loss: 0.00169218480004929, Final Batch Loss: 0.0002576958213467151\n",
      "Epoch 2652, Loss: 0.009316135568951722, Final Batch Loss: 3.268036380177364e-05\n",
      "Epoch 2653, Loss: 0.002349843419779063, Final Batch Loss: 7.491125415981514e-06\n",
      "Epoch 2654, Loss: 0.0011553311560419388, Final Batch Loss: 8.513779903296381e-06\n",
      "Epoch 2655, Loss: 0.010875298976316117, Final Batch Loss: 0.00041460595093667507\n",
      "Epoch 2656, Loss: 0.004503045700403163, Final Batch Loss: 2.4836805096128955e-05\n",
      "Epoch 2657, Loss: 0.0012133060372434556, Final Batch Loss: 0.0003510714159347117\n",
      "Epoch 2658, Loss: 0.0020080410758964717, Final Batch Loss: 0.0006363436114042997\n",
      "Epoch 2659, Loss: 0.0014190090878400952, Final Batch Loss: 8.59987922012806e-05\n",
      "Epoch 2660, Loss: 0.0012431205686880276, Final Batch Loss: 0.0001566352293593809\n",
      "Epoch 2661, Loss: 0.001102729049307527, Final Batch Loss: 2.2886775695951656e-05\n",
      "Epoch 2662, Loss: 0.001280209413380362, Final Batch Loss: 2.9633563826791942e-05\n",
      "Epoch 2663, Loss: 0.0008437635406153277, Final Batch Loss: 2.9858012567274272e-05\n",
      "Epoch 2664, Loss: 0.0005693702405551448, Final Batch Loss: 1.643708674237132e-05\n",
      "Epoch 2665, Loss: 0.003468078240985051, Final Batch Loss: 0.0026441144291311502\n",
      "Epoch 2666, Loss: 0.0009190004475385649, Final Batch Loss: 1.1870024536619894e-05\n",
      "Epoch 2667, Loss: 0.0005565555620705709, Final Batch Loss: 6.199628114700317e-05\n",
      "Epoch 2668, Loss: 0.014910436868376564, Final Batch Loss: 1.0746698535513133e-05\n",
      "Epoch 2669, Loss: 0.0015373354272014694, Final Batch Loss: 2.5289498807978816e-05\n",
      "Epoch 2670, Loss: 0.0014159942220430821, Final Batch Loss: 0.00024897849652916193\n",
      "Epoch 2671, Loss: 0.0021920674480497837, Final Batch Loss: 0.0006135014700703323\n",
      "Epoch 2672, Loss: 0.0015004349079390522, Final Batch Loss: 3.8352791307261214e-05\n",
      "Epoch 2673, Loss: 0.0010482243851583917, Final Batch Loss: 5.8125227951677516e-05\n",
      "Epoch 2674, Loss: 0.002501755797311489, Final Batch Loss: 1.226571203005733e-05\n",
      "Epoch 2675, Loss: 0.0006483394390670583, Final Batch Loss: 9.640005009714514e-05\n",
      "Epoch 2676, Loss: 0.0007398169400403276, Final Batch Loss: 0.0002032119664363563\n",
      "Epoch 2677, Loss: 0.008722557686269283, Final Batch Loss: 0.0006499111768789589\n",
      "Epoch 2678, Loss: 0.0009671839361544698, Final Batch Loss: 0.0004080382641404867\n",
      "Epoch 2679, Loss: 0.0018062286762869917, Final Batch Loss: 3.308033774374053e-05\n",
      "Epoch 2680, Loss: 0.00669691093480651, Final Batch Loss: 8.080870429694187e-06\n",
      "Epoch 2681, Loss: 0.0009064957484952174, Final Batch Loss: 7.329697109526023e-05\n",
      "Epoch 2682, Loss: 0.0032652310037519783, Final Batch Loss: 0.001871818327344954\n",
      "Epoch 2683, Loss: 0.0005037303399149096, Final Batch Loss: 1.8049458958557807e-05\n",
      "Epoch 2684, Loss: 0.0012829155803046888, Final Batch Loss: 2.411006971669849e-05\n",
      "Epoch 2685, Loss: 0.0034349172638030723, Final Batch Loss: 0.00012337342195678502\n",
      "Epoch 2686, Loss: 0.0008518590766470879, Final Batch Loss: 3.990365075878799e-05\n",
      "Epoch 2687, Loss: 0.001456730802601669, Final Batch Loss: 2.3527900339104235e-06\n",
      "Epoch 2688, Loss: 0.0009403355434187688, Final Batch Loss: 0.0005211837706156075\n",
      "Epoch 2689, Loss: 0.0018376065127085894, Final Batch Loss: 5.706478259526193e-05\n",
      "Epoch 2690, Loss: 0.012335352192167193, Final Batch Loss: 0.0002543650334700942\n",
      "Epoch 2691, Loss: 0.001005662117677275, Final Batch Loss: 1.2961951142642647e-05\n",
      "Epoch 2692, Loss: 0.002600309861009009, Final Batch Loss: 3.0556424462702125e-05\n",
      "Epoch 2693, Loss: 0.000825787938083522, Final Batch Loss: 0.000498219218570739\n",
      "Epoch 2694, Loss: 0.011951974659496045, Final Batch Loss: 8.94658387551317e-06\n",
      "Epoch 2695, Loss: 0.0002095373829433811, Final Batch Loss: 4.805890966963489e-06\n",
      "Epoch 2696, Loss: 0.0016617817746009678, Final Batch Loss: 0.00017088421736843884\n",
      "Epoch 2697, Loss: 0.011956197799008805, Final Batch Loss: 0.011638455092906952\n",
      "Epoch 2698, Loss: 0.0006613967452722136, Final Batch Loss: 5.214511838858016e-05\n",
      "Epoch 2699, Loss: 0.0010723349550971761, Final Batch Loss: 0.00023277520085684955\n",
      "Epoch 2700, Loss: 0.004629549279343337, Final Batch Loss: 9.62156627792865e-05\n",
      "Epoch 2701, Loss: 0.001278005336644128, Final Batch Loss: 0.000490710895974189\n",
      "Epoch 2702, Loss: 0.0009998766993248864, Final Batch Loss: 3.0429448543145554e-06\n",
      "Epoch 2703, Loss: 0.0036621517756429967, Final Batch Loss: 3.8875728932907805e-05\n",
      "Epoch 2704, Loss: 0.001965180621482432, Final Batch Loss: 0.00013151729945093393\n",
      "Epoch 2705, Loss: 0.008003851362445857, Final Batch Loss: 2.6075598725583404e-05\n",
      "Epoch 2706, Loss: 0.003191435384678698, Final Batch Loss: 1.6940127807174576e-06\n",
      "Epoch 2707, Loss: 0.0010065006208606064, Final Batch Loss: 0.0005680047906935215\n",
      "Epoch 2708, Loss: 0.0008876688370946795, Final Batch Loss: 1.6361387679353356e-05\n",
      "Epoch 2709, Loss: 0.0015311457973439246, Final Batch Loss: 0.00036278978222981095\n",
      "Epoch 2710, Loss: 0.0005466405382321682, Final Batch Loss: 4.627572707249783e-05\n",
      "Epoch 2711, Loss: 0.0016792462702142075, Final Batch Loss: 0.00013432699779514223\n",
      "Epoch 2712, Loss: 0.0008815391875032219, Final Batch Loss: 1.191973115055589e-05\n",
      "Epoch 2713, Loss: 0.003184554647305049, Final Batch Loss: 3.924475458916277e-05\n",
      "Epoch 2714, Loss: 0.002315491161425598, Final Batch Loss: 0.0016626812284812331\n",
      "Epoch 2715, Loss: 0.0006285571143962443, Final Batch Loss: 0.00013403725461103022\n",
      "Epoch 2716, Loss: 0.0021727845924033318, Final Batch Loss: 2.5782388547668234e-05\n",
      "Epoch 2717, Loss: 0.0005049133524153149, Final Batch Loss: 2.1437072064145468e-05\n",
      "Epoch 2718, Loss: 0.0004968219882357516, Final Batch Loss: 7.72332805354381e-06\n",
      "Epoch 2719, Loss: 0.00042813292384380475, Final Batch Loss: 9.223267261404544e-05\n",
      "Epoch 2720, Loss: 0.0013115427573211491, Final Batch Loss: 0.0001243825681740418\n",
      "Epoch 2721, Loss: 0.006471035365393618, Final Batch Loss: 2.6681056624511257e-05\n",
      "Epoch 2722, Loss: 0.0008849358346196823, Final Batch Loss: 3.626773104770109e-05\n",
      "Epoch 2723, Loss: 0.0023937162823131075, Final Batch Loss: 2.0770157789229415e-05\n",
      "Epoch 2724, Loss: 0.0006269336736295372, Final Batch Loss: 6.072747055441141e-05\n",
      "Epoch 2725, Loss: 0.0004741176535389968, Final Batch Loss: 4.498521775531117e-06\n",
      "Epoch 2726, Loss: 0.0014507118066831026, Final Batch Loss: 2.439110176055692e-05\n",
      "Epoch 2727, Loss: 0.000429151298646957, Final Batch Loss: 8.658343517709e-07\n",
      "Epoch 2728, Loss: 0.003943189704841643, Final Batch Loss: 1.0476901479705703e-05\n",
      "Epoch 2729, Loss: 0.0009144941432168707, Final Batch Loss: 0.0005061408155597746\n",
      "Epoch 2730, Loss: 0.0014877750945743173, Final Batch Loss: 0.0008791601867415011\n",
      "Epoch 2731, Loss: 0.000552560098185495, Final Batch Loss: 9.96291510091396e-06\n",
      "Epoch 2732, Loss: 0.000298260269119055, Final Batch Loss: 1.710065953375306e-05\n",
      "Epoch 2733, Loss: 0.001730717864120379, Final Batch Loss: 0.000361068407073617\n",
      "Epoch 2734, Loss: 0.008179830765584484, Final Batch Loss: 0.005674013402312994\n",
      "Epoch 2735, Loss: 0.0005331684005795978, Final Batch Loss: 0.00010995115735568106\n",
      "Epoch 2736, Loss: 0.0016157918435055763, Final Batch Loss: 0.00011592582450248301\n",
      "Epoch 2737, Loss: 0.0015519916159973945, Final Batch Loss: 0.0013012834824621677\n",
      "Epoch 2738, Loss: 0.0003158520285069244, Final Batch Loss: 1.171312942460645e-05\n",
      "Epoch 2739, Loss: 0.001700392911061499, Final Batch Loss: 5.527466328203445e-06\n",
      "Epoch 2740, Loss: 0.00010576705449238943, Final Batch Loss: 3.055507704630145e-06\n",
      "Epoch 2741, Loss: 0.006596733888727613, Final Batch Loss: 0.006059672217816114\n",
      "Epoch 2742, Loss: 0.011984594737441512, Final Batch Loss: 6.52430608170107e-05\n",
      "Epoch 2743, Loss: 0.0013717217661906034, Final Batch Loss: 0.0004383078485261649\n",
      "Epoch 2744, Loss: 0.0009568930727255065, Final Batch Loss: 2.0632742234738544e-05\n",
      "Epoch 2745, Loss: 0.0006814188091084361, Final Batch Loss: 0.000387748732464388\n",
      "Epoch 2746, Loss: 0.025722955188030028, Final Batch Loss: 1.792377770470921e-05\n",
      "Epoch 2747, Loss: 0.0016503992628713604, Final Batch Loss: 6.0983838920947164e-06\n",
      "Epoch 2748, Loss: 0.0005871713278224888, Final Batch Loss: 1.756765755089873e-07\n",
      "Epoch 2749, Loss: 0.031723433537990786, Final Batch Loss: 0.0001759021688485518\n",
      "Epoch 2750, Loss: 0.0015383991822091048, Final Batch Loss: 4.900078238279093e-06\n",
      "Epoch 2751, Loss: 0.0006468221399700269, Final Batch Loss: 0.00020496145589277148\n",
      "Epoch 2752, Loss: 0.004013101482996717, Final Batch Loss: 0.00013167283032089472\n",
      "Epoch 2753, Loss: 0.0008837832720018923, Final Batch Loss: 4.946971603203565e-05\n",
      "Epoch 2754, Loss: 0.0010072849622702051, Final Batch Loss: 5.332877208275022e-06\n",
      "Epoch 2755, Loss: 0.000982661901616666, Final Batch Loss: 5.125878487888258e-06\n",
      "Epoch 2756, Loss: 0.004322788377976394, Final Batch Loss: 2.61162767856149e-05\n",
      "Epoch 2757, Loss: 0.0004928620455757482, Final Batch Loss: 1.1311751222820021e-05\n",
      "Epoch 2758, Loss: 0.0005567331863858271, Final Batch Loss: 3.551085319486447e-05\n",
      "Epoch 2759, Loss: 0.000940328354772646, Final Batch Loss: 7.782105967635289e-05\n",
      "Epoch 2760, Loss: 0.0014666998986285762, Final Batch Loss: 5.339069502952043e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2761, Loss: 0.00033903503526744316, Final Batch Loss: 5.295197752275271e-06\n",
      "Epoch 2762, Loss: 0.0004861994821112603, Final Batch Loss: 0.00011880422243848443\n",
      "Epoch 2763, Loss: 0.0005057211092207581, Final Batch Loss: 0.00019048988178838044\n",
      "Epoch 2764, Loss: 0.03015713506601969, Final Batch Loss: 6.368130470946198e-06\n",
      "Epoch 2765, Loss: 0.28436661878367886, Final Batch Loss: 0.2823762893676758\n",
      "Epoch 2766, Loss: 0.0007774958794470876, Final Batch Loss: 7.528782589361072e-06\n",
      "Epoch 2767, Loss: 0.014228024943804485, Final Batch Loss: 1.1613085007411428e-05\n",
      "Epoch 2768, Loss: 0.041334397268656176, Final Batch Loss: 4.2121966544073075e-05\n",
      "Epoch 2769, Loss: 0.015256206206686329, Final Batch Loss: 0.00011134222586406395\n",
      "Epoch 2770, Loss: 0.0010853595740627497, Final Batch Loss: 5.620563752017915e-05\n",
      "Epoch 2771, Loss: 0.005910672363825142, Final Batch Loss: 0.0002594668185338378\n",
      "Epoch 2772, Loss: 0.1118686179688666, Final Batch Loss: 0.10053517669439316\n",
      "Epoch 2773, Loss: 0.0035472522358759306, Final Batch Loss: 6.730606401106343e-05\n",
      "Epoch 2774, Loss: 0.12303125913604163, Final Batch Loss: 0.12211527675390244\n",
      "Epoch 2775, Loss: 0.014881647133734077, Final Batch Loss: 0.0001389550743624568\n",
      "Epoch 2776, Loss: 0.02890145150013268, Final Batch Loss: 0.002739171264693141\n",
      "Epoch 2777, Loss: 0.006898835767060518, Final Batch Loss: 0.0015978841111063957\n",
      "Epoch 2778, Loss: 0.003804361855145544, Final Batch Loss: 0.00013446511002257466\n",
      "Epoch 2779, Loss: 0.0010854915308300406, Final Batch Loss: 0.00013637798838317394\n",
      "Epoch 2780, Loss: 0.004730047890916467, Final Batch Loss: 0.0010259626433253288\n",
      "Epoch 2781, Loss: 0.0019051317940466106, Final Batch Loss: 0.000476364599307999\n",
      "Epoch 2782, Loss: 0.0022328291524900123, Final Batch Loss: 1.582833647262305e-05\n",
      "Epoch 2783, Loss: 0.014034179563168436, Final Batch Loss: 0.013257436454296112\n",
      "Epoch 2784, Loss: 0.0018631316197570413, Final Batch Loss: 0.0003895601839758456\n",
      "Epoch 2785, Loss: 0.0011552781325008254, Final Batch Loss: 3.143341018585488e-06\n",
      "Epoch 2786, Loss: 0.005649316229209944, Final Batch Loss: 1.4128151633485686e-05\n",
      "Epoch 2787, Loss: 0.010330578981665894, Final Batch Loss: 0.00925617665052414\n",
      "Epoch 2788, Loss: 0.013132358057191595, Final Batch Loss: 8.558429544791579e-05\n",
      "Epoch 2789, Loss: 0.0025858139561023563, Final Batch Loss: 0.00028848470537923276\n",
      "Epoch 2790, Loss: 0.0028234634301043116, Final Batch Loss: 7.854113209759817e-05\n",
      "Epoch 2791, Loss: 0.009618605894502252, Final Batch Loss: 6.447051418945193e-05\n",
      "Epoch 2792, Loss: 0.007828451909517753, Final Batch Loss: 2.5458035452174954e-05\n",
      "Epoch 2793, Loss: 0.004424055965500884, Final Batch Loss: 0.00016134399629663676\n",
      "Epoch 2794, Loss: 0.0007811074974597432, Final Batch Loss: 9.492232493357733e-05\n",
      "Epoch 2795, Loss: 0.022930307080969214, Final Batch Loss: 0.00031702706473879516\n",
      "Epoch 2796, Loss: 0.007199570165539626, Final Batch Loss: 3.0155388230923563e-05\n",
      "Epoch 2797, Loss: 0.022642151663603727, Final Batch Loss: 9.07598077901639e-05\n",
      "Epoch 2798, Loss: 0.0072801579954102635, Final Batch Loss: 0.0004933517775498331\n",
      "Epoch 2799, Loss: 0.0007848971436033025, Final Batch Loss: 0.00020701305766124278\n",
      "Epoch 2800, Loss: 0.004647913883673027, Final Batch Loss: 0.0022918814793229103\n",
      "Epoch 2801, Loss: 0.00876153176261596, Final Batch Loss: 1.4116832289801096e-06\n",
      "Epoch 2802, Loss: 0.002979572396725416, Final Batch Loss: 0.0013568419963121414\n",
      "Epoch 2803, Loss: 0.0006753006534836459, Final Batch Loss: 2.766880015769857e-06\n",
      "Epoch 2804, Loss: 0.000573033896216657, Final Batch Loss: 7.737134728813544e-05\n",
      "Epoch 2805, Loss: 0.006617535022087395, Final Batch Loss: 0.004917329177260399\n",
      "Epoch 2806, Loss: 0.0017964909520742367, Final Batch Loss: 9.881480764306616e-06\n",
      "Epoch 2807, Loss: 0.004738083274787641, Final Batch Loss: 5.721774869016372e-06\n",
      "Epoch 2808, Loss: 0.0009210972493747249, Final Batch Loss: 0.0002985664759762585\n",
      "Epoch 2809, Loss: 0.0004845572038902901, Final Batch Loss: 4.4396503653842956e-05\n",
      "Epoch 2810, Loss: 0.0012259729710422107, Final Batch Loss: 1.3544879948312882e-05\n",
      "Epoch 2811, Loss: 0.001209753318107687, Final Batch Loss: 0.00022077256289776415\n",
      "Epoch 2812, Loss: 0.0005446956802188652, Final Batch Loss: 1.7803833543439396e-05\n",
      "Epoch 2813, Loss: 0.008261627453066467, Final Batch Loss: 8.520023584424052e-06\n",
      "Epoch 2814, Loss: 0.0007239724363898858, Final Batch Loss: 0.0002067842724500224\n",
      "Epoch 2815, Loss: 0.0011794103756983532, Final Batch Loss: 1.2974282071809284e-05\n",
      "Epoch 2816, Loss: 0.0013378184521570802, Final Batch Loss: 0.0004087603883817792\n",
      "Epoch 2817, Loss: 0.0015630782290827483, Final Batch Loss: 0.0009013573289848864\n",
      "Epoch 2818, Loss: 0.005823148807394318, Final Batch Loss: 0.004767389968037605\n",
      "Epoch 2819, Loss: 0.002227726323326351, Final Batch Loss: 2.0352064893813804e-05\n",
      "Epoch 2820, Loss: 0.002079048337691347, Final Batch Loss: 1.031413376040291e-05\n",
      "Epoch 2821, Loss: 0.002083067889088852, Final Batch Loss: 5.3705493883171584e-06\n",
      "Epoch 2822, Loss: 0.03311475703958422, Final Batch Loss: 0.0018589614192023873\n",
      "Epoch 2823, Loss: 0.0012282841198612005, Final Batch Loss: 0.00048534307279624045\n",
      "Epoch 2824, Loss: 0.0017019892402458936, Final Batch Loss: 0.0009023688617162406\n",
      "Epoch 2825, Loss: 0.0013719559501623735, Final Batch Loss: 0.00015826134767848998\n",
      "Epoch 2826, Loss: 0.010434633222757839, Final Batch Loss: 0.001070142723619938\n",
      "Epoch 2827, Loss: 0.0016415903519373387, Final Batch Loss: 0.00032393287983722985\n",
      "Epoch 2828, Loss: 0.002560532491770573, Final Batch Loss: 0.0011982505675405264\n",
      "Epoch 2829, Loss: 0.0007934471741464222, Final Batch Loss: 1.2372047422104515e-05\n",
      "Epoch 2830, Loss: 0.0015044186384329805, Final Batch Loss: 1.560274358780589e-05\n",
      "Epoch 2831, Loss: 0.0005806993649457581, Final Batch Loss: 7.339026342378929e-05\n",
      "Epoch 2832, Loss: 0.0012258766528248088, Final Batch Loss: 7.961732990224846e-06\n",
      "Epoch 2833, Loss: 0.0009681365918368101, Final Batch Loss: 0.00010705397289711982\n",
      "Epoch 2834, Loss: 0.0024424428775091656, Final Batch Loss: 6.858500273665413e-05\n",
      "Epoch 2835, Loss: 0.0006692148572255974, Final Batch Loss: 9.379448783874977e-06\n",
      "Epoch 2836, Loss: 0.012594199215527624, Final Batch Loss: 0.011559836566448212\n",
      "Epoch 2837, Loss: 0.005422753562015714, Final Batch Loss: 4.9932528781937435e-05\n",
      "Epoch 2838, Loss: 0.0009292756876675412, Final Batch Loss: 4.056758189108223e-05\n",
      "Epoch 2839, Loss: 0.002378084493102506, Final Batch Loss: 0.0007767429924570024\n",
      "Epoch 2840, Loss: 0.042599191117915325, Final Batch Loss: 3.499770537018776e-05\n",
      "Epoch 2841, Loss: 0.014110501011600718, Final Batch Loss: 0.0002463808923494071\n",
      "Epoch 2842, Loss: 0.005805791006423533, Final Batch Loss: 0.0030199135653674603\n",
      "Epoch 2843, Loss: 0.0027219955081818625, Final Batch Loss: 0.002152741188183427\n",
      "Epoch 2844, Loss: 0.0011086906888522208, Final Batch Loss: 0.00014730074326507747\n",
      "Epoch 2845, Loss: 0.00299525327864103, Final Batch Loss: 0.00187066534999758\n",
      "Epoch 2846, Loss: 0.002352678857278079, Final Batch Loss: 0.00023193081142380834\n",
      "Epoch 2847, Loss: 0.00143152454529627, Final Batch Loss: 6.9767220338690095e-06\n",
      "Epoch 2848, Loss: 0.0016787654167274013, Final Batch Loss: 0.00013715315435547382\n",
      "Epoch 2849, Loss: 0.00037981116118146474, Final Batch Loss: 1.694025542064992e-07\n",
      "Epoch 2850, Loss: 0.0009973317719413899, Final Batch Loss: 0.00010564680997049436\n",
      "Epoch 2851, Loss: 0.00155299948528409, Final Batch Loss: 0.0007976525230333209\n",
      "Epoch 2852, Loss: 0.0012489966175053269, Final Batch Loss: 0.00014017903595231473\n",
      "Epoch 2853, Loss: 0.020952699524059426, Final Batch Loss: 0.02037089504301548\n",
      "Epoch 2854, Loss: 0.001029354619277001, Final Batch Loss: 1.4235612070478965e-05\n",
      "Epoch 2855, Loss: 0.006540069356560707, Final Batch Loss: 0.0017633577808737755\n",
      "Epoch 2856, Loss: 0.0010233444154437166, Final Batch Loss: 2.438471346977167e-05\n",
      "Epoch 2857, Loss: 0.00460623228809709, Final Batch Loss: 1.1091710803157184e-05\n",
      "Epoch 2858, Loss: 0.0014384108102376558, Final Batch Loss: 1.6187290157176903e-06\n",
      "Epoch 2859, Loss: 0.0016778110220911913, Final Batch Loss: 2.1844047296326607e-05\n",
      "Epoch 2860, Loss: 0.0014678381776320748, Final Batch Loss: 5.3333576943259686e-05\n",
      "Epoch 2861, Loss: 0.01991587653174065, Final Batch Loss: 0.00048210169188678265\n",
      "Epoch 2862, Loss: 0.0015173966239672154, Final Batch Loss: 0.0001005548401735723\n",
      "Epoch 2863, Loss: 0.001888010127004236, Final Batch Loss: 0.0002843046677298844\n",
      "Epoch 2864, Loss: 0.001312834859618306, Final Batch Loss: 4.893759523838526e-06\n",
      "Epoch 2865, Loss: 0.001584942678164225, Final Batch Loss: 0.0002584793546702713\n",
      "Epoch 2866, Loss: 0.004353975178673863, Final Batch Loss: 0.0029905594419687986\n",
      "Epoch 2867, Loss: 0.00041570051598682767, Final Batch Loss: 9.341819350083824e-06\n",
      "Epoch 2868, Loss: 0.000977872419753112, Final Batch Loss: 0.00047822159831412137\n",
      "Epoch 2869, Loss: 0.001662008788116509, Final Batch Loss: 3.137730891467072e-05\n",
      "Epoch 2870, Loss: 0.0009467228319408605, Final Batch Loss: 1.816247277020011e-05\n",
      "Epoch 2871, Loss: 0.005750525509938598, Final Batch Loss: 0.0032905309926718473\n",
      "Epoch 2872, Loss: 0.01799840310741274, Final Batch Loss: 1.534600778541062e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2873, Loss: 0.001615910732652992, Final Batch Loss: 0.0002645438362378627\n",
      "Epoch 2874, Loss: 0.0019130213768221438, Final Batch Loss: 3.331800689920783e-05\n",
      "Epoch 2875, Loss: 0.0019282751891296357, Final Batch Loss: 0.00017870022566057742\n",
      "Epoch 2876, Loss: 0.003284717444330454, Final Batch Loss: 0.0004952895687893033\n",
      "Epoch 2877, Loss: 0.0018558655216054376, Final Batch Loss: 4.203689911719266e-07\n",
      "Epoch 2878, Loss: 0.0008347203402081504, Final Batch Loss: 5.5291762691922486e-05\n",
      "Epoch 2879, Loss: 0.001188331740763715, Final Batch Loss: 1.1607177157202386e-06\n",
      "Epoch 2880, Loss: 0.002385402755294308, Final Batch Loss: 1.0917013923972263e-06\n",
      "Epoch 2881, Loss: 0.000384490196211118, Final Batch Loss: 4.322836957726395e-06\n",
      "Epoch 2882, Loss: 0.0013271984789753333, Final Batch Loss: 8.823344251140952e-05\n",
      "Epoch 2883, Loss: 0.004416444317030255, Final Batch Loss: 6.23181476839818e-05\n",
      "Epoch 2884, Loss: 0.0008322757494170219, Final Batch Loss: 0.00024955839035101235\n",
      "Epoch 2885, Loss: 0.0009654884051997215, Final Batch Loss: 0.00013054955343250185\n",
      "Epoch 2886, Loss: 0.000618930695054587, Final Batch Loss: 0.0001128575750044547\n",
      "Epoch 2887, Loss: 0.0036762453164556064, Final Batch Loss: 0.00042010293691419065\n",
      "Epoch 2888, Loss: 0.0009705333068268374, Final Batch Loss: 6.330371252261102e-05\n",
      "Epoch 2889, Loss: 0.0008979469566838816, Final Batch Loss: 0.0005930625484324992\n",
      "Epoch 2890, Loss: 0.00721861361671472, Final Batch Loss: 8.26901668915525e-06\n",
      "Epoch 2891, Loss: 0.0009098896844079718, Final Batch Loss: 0.00028478424064815044\n",
      "Epoch 2892, Loss: 0.0019779827853199095, Final Batch Loss: 0.0005814103060401976\n",
      "Epoch 2893, Loss: 0.0005641602147079539, Final Batch Loss: 3.3356362109771e-05\n",
      "Epoch 2894, Loss: 0.001499519043136388, Final Batch Loss: 6.865282193757594e-05\n",
      "Epoch 2895, Loss: 0.0009015018440550193, Final Batch Loss: 2.1568863303400576e-05\n",
      "Epoch 2896, Loss: 0.007136548752896488, Final Batch Loss: 3.356311935931444e-05\n",
      "Epoch 2897, Loss: 0.0021352764451876283, Final Batch Loss: 0.0007742085726931691\n",
      "Epoch 2898, Loss: 0.00034970827255165204, Final Batch Loss: 7.295436080312356e-05\n",
      "Epoch 2899, Loss: 0.0008360729698324576, Final Batch Loss: 0.0004103748651687056\n",
      "Epoch 2900, Loss: 0.005051756335888058, Final Batch Loss: 0.0009052292443811893\n",
      "Epoch 2901, Loss: 0.0007256016533574439, Final Batch Loss: 6.022913112246897e-06\n",
      "Epoch 2902, Loss: 0.0004907129659841303, Final Batch Loss: 4.6135206503095105e-05\n",
      "Epoch 2903, Loss: 0.003846238032565452, Final Batch Loss: 0.00015215517487376928\n",
      "Epoch 2904, Loss: 0.00048223297199001536, Final Batch Loss: 6.751952605554834e-05\n",
      "Epoch 2905, Loss: 0.0010898956388700753, Final Batch Loss: 0.00015755341155454516\n",
      "Epoch 2906, Loss: 0.001289984880713746, Final Batch Loss: 0.000628317822702229\n",
      "Epoch 2907, Loss: 0.005406505240671322, Final Batch Loss: 2.2335896119329846e-06\n",
      "Epoch 2908, Loss: 0.0009354629410154303, Final Batch Loss: 1.232143858942436e-05\n",
      "Epoch 2909, Loss: 0.00032313056362909265, Final Batch Loss: 4.3355092202546075e-05\n",
      "Epoch 2910, Loss: 0.0008184882753994316, Final Batch Loss: 0.00014840807125438005\n",
      "Epoch 2911, Loss: 0.0014999649047240382, Final Batch Loss: 2.5474908397882245e-05\n",
      "Epoch 2912, Loss: 0.0013166998542146757, Final Batch Loss: 0.00011483208800200373\n",
      "Epoch 2913, Loss: 0.0038488237660203595, Final Batch Loss: 3.298091542092152e-05\n",
      "Epoch 2914, Loss: 0.0005014831840526313, Final Batch Loss: 0.00010193053458351642\n",
      "Epoch 2915, Loss: 0.002001992914301809, Final Batch Loss: 0.00011502569395815954\n",
      "Epoch 2916, Loss: 0.0026517614678596146, Final Batch Loss: 9.601962665328756e-05\n",
      "Epoch 2917, Loss: 0.025794617613428272, Final Batch Loss: 2.7219080948270857e-05\n",
      "Epoch 2918, Loss: 0.007386172961560078, Final Batch Loss: 0.00021693688177037984\n",
      "Epoch 2919, Loss: 0.0005199788538448047, Final Batch Loss: 1.923524177982472e-05\n",
      "Epoch 2920, Loss: 0.01912589618586935, Final Batch Loss: 0.0005850704619660974\n",
      "Epoch 2921, Loss: 0.000790066741501505, Final Batch Loss: 1.4529782674799208e-05\n",
      "Epoch 2922, Loss: 0.0010850111611944158, Final Batch Loss: 4.342249667388387e-05\n",
      "Epoch 2923, Loss: 0.0005590480031969491, Final Batch Loss: 1.5527726645814255e-05\n",
      "Epoch 2924, Loss: 0.002795740438159555, Final Batch Loss: 0.0014162821462377906\n",
      "Epoch 2925, Loss: 0.00033879338661790825, Final Batch Loss: 2.2651791368843988e-05\n",
      "Epoch 2926, Loss: 0.0014938895728846546, Final Batch Loss: 0.0003164678637403995\n",
      "Epoch 2927, Loss: 0.0004824434872716665, Final Batch Loss: 5.1409093430265784e-05\n",
      "Epoch 2928, Loss: 0.00033346757118124515, Final Batch Loss: 4.28508865297772e-05\n",
      "Epoch 2929, Loss: 0.0008303683644044213, Final Batch Loss: 0.0004473528533708304\n",
      "Epoch 2930, Loss: 0.019164832188380387, Final Batch Loss: 5.445890110422624e-06\n",
      "Epoch 2931, Loss: 0.0009253861098841298, Final Batch Loss: 2.0220180886099115e-05\n",
      "Epoch 2932, Loss: 0.0019333734262545477, Final Batch Loss: 2.239862624264788e-06\n",
      "Epoch 2933, Loss: 0.0016091900997707853, Final Batch Loss: 2.2378191715688445e-05\n",
      "Epoch 2934, Loss: 0.0006648397829849273, Final Batch Loss: 4.0049460949376225e-05\n",
      "Epoch 2935, Loss: 0.000891165946086403, Final Batch Loss: 8.217884897021577e-05\n",
      "Epoch 2936, Loss: 0.0015118028968572617, Final Batch Loss: 2.3531349143013358e-05\n",
      "Epoch 2937, Loss: 0.00032214034581556916, Final Batch Loss: 4.7724090109113604e-05\n",
      "Epoch 2938, Loss: 0.0005813425476830503, Final Batch Loss: 1.0666089877986451e-07\n",
      "Epoch 2939, Loss: 0.00038707506683977044, Final Batch Loss: 8.15642238194414e-08\n",
      "Epoch 2940, Loss: 0.0014908174456991219, Final Batch Loss: 7.089806217663863e-07\n",
      "Epoch 2941, Loss: 0.00013288041373016313, Final Batch Loss: 3.393858787603676e-05\n",
      "Epoch 2942, Loss: 0.0007074813962617554, Final Batch Loss: 1.0603304190226481e-06\n",
      "Epoch 2943, Loss: 0.0032348675886169076, Final Batch Loss: 0.002368269022554159\n",
      "Epoch 2944, Loss: 0.0004575481243591639, Final Batch Loss: 1.3865140317648184e-05\n",
      "Epoch 2945, Loss: 0.0009097981383092701, Final Batch Loss: 0.0002977201947942376\n",
      "Epoch 2946, Loss: 0.00051048984460067, Final Batch Loss: 0.0002933294454123825\n",
      "Epoch 2947, Loss: 0.0013524762180168182, Final Batch Loss: 0.00019271063501946628\n",
      "Epoch 2948, Loss: 0.0007374798296950758, Final Batch Loss: 9.813615179155022e-05\n",
      "Epoch 2949, Loss: 0.0038486116682179272, Final Batch Loss: 0.0003120017936453223\n",
      "Epoch 2950, Loss: 0.00518524918879848, Final Batch Loss: 9.421688446309417e-05\n",
      "Epoch 2951, Loss: 0.016677400768912776, Final Batch Loss: 7.146065854612971e-06\n",
      "Epoch 2952, Loss: 0.0015449805941898376, Final Batch Loss: 0.0008878022781573236\n",
      "Epoch 2953, Loss: 0.014538045565132052, Final Batch Loss: 0.00028672217740677297\n",
      "Epoch 2954, Loss: 0.0008119794401864056, Final Batch Loss: 4.178498784312978e-06\n",
      "Epoch 2955, Loss: 0.0021678520279238, Final Batch Loss: 0.0014626206830143929\n",
      "Epoch 2956, Loss: 0.0020456997320934533, Final Batch Loss: 1.192087779600115e-06\n",
      "Epoch 2957, Loss: 0.0074372380040585995, Final Batch Loss: 0.00020881247473880649\n",
      "Epoch 2958, Loss: 0.005447403993457556, Final Batch Loss: 0.002584737492725253\n",
      "Epoch 2959, Loss: 0.0008160495854099281, Final Batch Loss: 2.0131432393100113e-05\n",
      "Epoch 2960, Loss: 0.002371960348682478, Final Batch Loss: 0.0003602868819143623\n",
      "Epoch 2961, Loss: 0.00041903827877831645, Final Batch Loss: 5.605169644695707e-05\n",
      "Epoch 2962, Loss: 0.013436268829536857, Final Batch Loss: 5.904601493966766e-05\n",
      "Epoch 2963, Loss: 0.0003015121656062547, Final Batch Loss: 6.024839240126312e-05\n",
      "Epoch 2964, Loss: 0.0009260767401428893, Final Batch Loss: 0.0003668316057883203\n",
      "Epoch 2965, Loss: 0.002388969383900985, Final Batch Loss: 2.4289562134072185e-05\n",
      "Epoch 2966, Loss: 0.0010885785304708406, Final Batch Loss: 0.0006693389732390642\n",
      "Epoch 2967, Loss: 0.0005943970718362834, Final Batch Loss: 7.654375076526776e-05\n",
      "Epoch 2968, Loss: 0.004053444805776962, Final Batch Loss: 2.459434199408861e-06\n",
      "Epoch 2969, Loss: 0.000503009058547832, Final Batch Loss: 2.8609545097424416e-06\n",
      "Epoch 2970, Loss: 0.00026341656776196487, Final Batch Loss: 2.0704756309442018e-07\n",
      "Epoch 2971, Loss: 0.00037871612039452884, Final Batch Loss: 1.8995053324033506e-05\n",
      "Epoch 2972, Loss: 0.0005481914413394406, Final Batch Loss: 1.1342654033796862e-05\n",
      "Epoch 2973, Loss: 0.0010276040439975986, Final Batch Loss: 2.070474920401466e-07\n",
      "Epoch 2974, Loss: 0.000726824662706349, Final Batch Loss: 0.0005306735401973128\n",
      "Epoch 2975, Loss: 0.0017510531397419982, Final Batch Loss: 0.001401667483150959\n",
      "Epoch 2976, Loss: 0.0003572756104404107, Final Batch Loss: 0.0001487771369284019\n",
      "Epoch 2977, Loss: 0.0004919884477203595, Final Batch Loss: 7.748410098429304e-06\n",
      "Epoch 2978, Loss: 0.00012805355549971864, Final Batch Loss: 2.8860715701739537e-06\n",
      "Epoch 2979, Loss: 0.00039989764809433836, Final Batch Loss: 2.5603150788811035e-05\n",
      "Epoch 2980, Loss: 0.00021332953474484384, Final Batch Loss: 1.6812125977594405e-05\n",
      "Epoch 2981, Loss: 0.006458613468566909, Final Batch Loss: 0.00016543231322430074\n",
      "Epoch 2982, Loss: 0.002728231978835538, Final Batch Loss: 0.0009705472621135414\n",
      "Epoch 2983, Loss: 0.0018079693568324728, Final Batch Loss: 2.1081091290398035e-06\n",
      "Epoch 2984, Loss: 0.020392342806644592, Final Batch Loss: 4.128306954953587e-06\n",
      "Epoch 2985, Loss: 0.003038903299966478, Final Batch Loss: 1.7991356799029745e-05\n",
      "Epoch 2986, Loss: 0.0012287045974517241, Final Batch Loss: 0.0002583228924777359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2987, Loss: 0.008718308155948762, Final Batch Loss: 1.827352389227599e-05\n",
      "Epoch 2988, Loss: 0.0006234135653357953, Final Batch Loss: 0.00015722682292107493\n",
      "Epoch 2989, Loss: 0.02246401342563331, Final Batch Loss: 0.0003092174883931875\n",
      "Epoch 2990, Loss: 0.006621499675929954, Final Batch Loss: 1.1737704880943056e-05\n",
      "Epoch 2991, Loss: 0.0027674055982060963, Final Batch Loss: 1.876391797850374e-05\n",
      "Epoch 2992, Loss: 0.0003316290051316173, Final Batch Loss: 2.4657304038555594e-06\n",
      "Epoch 2993, Loss: 0.035972566529380856, Final Batch Loss: 1.688852717052214e-05\n",
      "Epoch 2994, Loss: 0.001989379379665479, Final Batch Loss: 0.0003025779442396015\n",
      "Epoch 2995, Loss: 0.0008354673082067166, Final Batch Loss: 4.4375312427291647e-05\n",
      "Epoch 2996, Loss: 0.0011406157191231614, Final Batch Loss: 2.4604980353615247e-05\n",
      "Epoch 2997, Loss: 0.011662752600386739, Final Batch Loss: 0.0002616293786559254\n",
      "Epoch 2998, Loss: 0.004457075614482164, Final Batch Loss: 0.0005410423618741333\n",
      "Epoch 2999, Loss: 0.0019602290517468646, Final Batch Loss: 1.9386966414458584e-06\n",
      "Epoch 3000, Loss: 0.0006612205816054484, Final Batch Loss: 2.775394204945769e-05\n",
      "Epoch 3001, Loss: 0.0006282905560510699, Final Batch Loss: 3.3405438443878666e-05\n",
      "Epoch 3002, Loss: 0.0007482595974579453, Final Batch Loss: 0.00017591251526027918\n",
      "Epoch 3003, Loss: 0.0008793046290520579, Final Batch Loss: 0.0003521915932651609\n",
      "Epoch 3004, Loss: 0.001329280923528131, Final Batch Loss: 7.716943946434185e-05\n",
      "Epoch 3005, Loss: 0.003802586084930226, Final Batch Loss: 0.0015027082990854979\n",
      "Epoch 3006, Loss: 0.0001911989693326177, Final Batch Loss: 1.7334286894765683e-05\n",
      "Epoch 3007, Loss: 0.0003407363683436415, Final Batch Loss: 5.502201929630246e-06\n",
      "Epoch 3008, Loss: 0.0005123423761688173, Final Batch Loss: 0.00020209811918903142\n",
      "Epoch 3009, Loss: 0.01574517675999232, Final Batch Loss: 7.98030032456154e-06\n",
      "Epoch 3010, Loss: 0.0004143502774240915, Final Batch Loss: 1.074068495654501e-05\n",
      "Epoch 3011, Loss: 0.0010545557647674286, Final Batch Loss: 5.333035915100481e-07\n",
      "Epoch 3012, Loss: 0.0015697671769885346, Final Batch Loss: 0.00017485635180491954\n",
      "Epoch 3013, Loss: 0.0014269457024056464, Final Batch Loss: 0.00015639516641385853\n",
      "Epoch 3014, Loss: 0.0012387711431074422, Final Batch Loss: 3.385710806469433e-05\n",
      "Epoch 3015, Loss: 0.003846549599984428, Final Batch Loss: 1.5878929843893275e-05\n",
      "Epoch 3016, Loss: 0.0007537017509093857, Final Batch Loss: 9.505019079369958e-06\n",
      "Epoch 3017, Loss: 0.0008702626655576751, Final Batch Loss: 0.0001319204893661663\n",
      "Epoch 3018, Loss: 0.001183415405193955, Final Batch Loss: 6.769527772121364e-06\n",
      "Epoch 3019, Loss: 0.0005609931126855372, Final Batch Loss: 3.3629062272666488e-06\n",
      "Epoch 3020, Loss: 0.0023103680539406923, Final Batch Loss: 3.7267852803779533e-06\n",
      "Epoch 3021, Loss: 0.0010219617739721798, Final Batch Loss: 1.2548276799861924e-06\n",
      "Epoch 3022, Loss: 0.0005287323651828046, Final Batch Loss: 7.534944870712934e-06\n",
      "Epoch 3023, Loss: 0.0012088743897038512, Final Batch Loss: 9.53275230131112e-05\n",
      "Epoch 3024, Loss: 0.005545304131373996, Final Batch Loss: 3.2752857805462554e-05\n",
      "Epoch 3025, Loss: 0.0006748288978997152, Final Batch Loss: 1.1380292562535033e-05\n",
      "Epoch 3026, Loss: 0.00920053047411784, Final Batch Loss: 1.5923067621770315e-05\n",
      "Epoch 3027, Loss: 0.005441991037514526, Final Batch Loss: 0.0008898907690308988\n",
      "Epoch 3028, Loss: 0.0013372668945521582, Final Batch Loss: 8.335047459695488e-05\n",
      "Epoch 3029, Loss: 0.0014229109801817685, Final Batch Loss: 0.00018017474212683737\n",
      "Epoch 3030, Loss: 0.0017741346964612603, Final Batch Loss: 0.000289867224637419\n",
      "Epoch 3031, Loss: 0.0010196931434620637, Final Batch Loss: 4.511348743108101e-05\n",
      "Epoch 3032, Loss: 0.0006664685934083536, Final Batch Loss: 8.116384560707957e-05\n",
      "Epoch 3033, Loss: 0.0008061155094765127, Final Batch Loss: 0.00014177028788253665\n",
      "Epoch 3034, Loss: 0.0015198357064036827, Final Batch Loss: 4.228735178912757e-06\n",
      "Epoch 3035, Loss: 0.0009832145733525977, Final Batch Loss: 6.529518577735871e-05\n",
      "Epoch 3036, Loss: 0.002160343457944691, Final Batch Loss: 0.00045206109643913805\n",
      "Epoch 3037, Loss: 0.0005320287609720253, Final Batch Loss: 1.1625307706708554e-05\n",
      "Epoch 3038, Loss: 0.0006778847091482021, Final Batch Loss: 4.424676444614306e-05\n",
      "Epoch 3039, Loss: 0.0008266406948678195, Final Batch Loss: 0.0005130527424626052\n",
      "Epoch 3040, Loss: 0.0036178537702653557, Final Batch Loss: 0.003319503040984273\n",
      "Epoch 3041, Loss: 0.0035722548491321504, Final Batch Loss: 0.003071783110499382\n",
      "Epoch 3042, Loss: 0.000529278207977768, Final Batch Loss: 9.186028182739392e-05\n",
      "Epoch 3043, Loss: 0.0009132482978202461, Final Batch Loss: 6.662975010840455e-06\n",
      "Epoch 3044, Loss: 0.006301831590178608, Final Batch Loss: 9.473966997575189e-07\n",
      "Epoch 3045, Loss: 0.009394198748850613, Final Batch Loss: 5.532120485440828e-05\n",
      "Epoch 3046, Loss: 0.0009906201466947095, Final Batch Loss: 2.9848220947314985e-05\n",
      "Epoch 3047, Loss: 0.000533342414200888, Final Batch Loss: 1.8771208488033153e-05\n",
      "Epoch 3048, Loss: 0.08638393766295849, Final Batch Loss: 3.8899393075553235e-06\n",
      "Epoch 3049, Loss: 0.000995612357741038, Final Batch Loss: 3.7017534282313136e-07\n",
      "Epoch 3050, Loss: 0.0018072278908221051, Final Batch Loss: 0.0013118758797645569\n",
      "Epoch 3051, Loss: 0.033140091314635356, Final Batch Loss: 2.0370034690131433e-05\n",
      "Epoch 3052, Loss: 0.0034344821178819984, Final Batch Loss: 0.0004379051679279655\n",
      "Epoch 3053, Loss: 0.002162551048968453, Final Batch Loss: 0.00017899309750646353\n",
      "Epoch 3054, Loss: 0.0238384211905327, Final Batch Loss: 9.034764048010402e-07\n",
      "Epoch 3055, Loss: 0.0011489941098261625, Final Batch Loss: 0.000303612177958712\n",
      "Epoch 3056, Loss: 0.016564874875257374, Final Batch Loss: 2.0878122086287476e-05\n",
      "Epoch 3057, Loss: 0.008839266114591737, Final Batch Loss: 2.371592927374877e-06\n",
      "Epoch 3058, Loss: 0.0049744859570637345, Final Batch Loss: 0.00018933310639113188\n",
      "Epoch 3059, Loss: 0.00603479398523632, Final Batch Loss: 2.771442632365506e-05\n",
      "Epoch 3060, Loss: 0.006005227442074101, Final Batch Loss: 0.0004059063794557005\n",
      "Epoch 3061, Loss: 0.0011025507569684123, Final Batch Loss: 5.08195216752938e-06\n",
      "Epoch 3062, Loss: 0.0017614247044548392, Final Batch Loss: 0.0006965699722059071\n",
      "Epoch 3063, Loss: 0.047391189302288694, Final Batch Loss: 2.508451507310383e-05\n",
      "Epoch 3064, Loss: 0.000587342392464052, Final Batch Loss: 2.4126462449203245e-05\n",
      "Epoch 3065, Loss: 0.00444189237896353, Final Batch Loss: 0.00021870122873224318\n",
      "Epoch 3066, Loss: 0.0031582241447267734, Final Batch Loss: 2.91746459879505e-06\n",
      "Epoch 3067, Loss: 0.005625012016935216, Final Batch Loss: 1.5031348993943539e-05\n",
      "Epoch 3068, Loss: 0.0008203261631933856, Final Batch Loss: 1.154960318672238e-05\n",
      "Epoch 3069, Loss: 0.011942850251216441, Final Batch Loss: 0.00024346570717170835\n",
      "Epoch 3070, Loss: 0.018769178073853254, Final Batch Loss: 0.00021465681493282318\n",
      "Epoch 3071, Loss: 0.0007004115504969377, Final Batch Loss: 5.158274507266469e-05\n",
      "Epoch 3072, Loss: 0.0004929233291477431, Final Batch Loss: 9.09102163859643e-06\n",
      "Epoch 3073, Loss: 0.005733889380280743, Final Batch Loss: 2.3018043066258542e-05\n",
      "Epoch 3074, Loss: 0.0008089609873422887, Final Batch Loss: 2.2651332983514294e-05\n",
      "Epoch 3075, Loss: 0.0005774309756816365, Final Batch Loss: 1.194490323541686e-05\n",
      "Epoch 3076, Loss: 0.003325166238937527, Final Batch Loss: 0.0009626569808460772\n",
      "Epoch 3077, Loss: 0.0018936984415631741, Final Batch Loss: 0.000979613745585084\n",
      "Epoch 3078, Loss: 0.0007368705755652627, Final Batch Loss: 2.8596497941180132e-05\n",
      "Epoch 3079, Loss: 0.019996292714495212, Final Batch Loss: 0.018675321713089943\n",
      "Epoch 3080, Loss: 0.0008636913694317627, Final Batch Loss: 9.975915418181103e-07\n",
      "Epoch 3081, Loss: 0.016431497875601053, Final Batch Loss: 0.0026070945896208286\n",
      "Epoch 3082, Loss: 0.04143498841585824, Final Batch Loss: 0.0020163513254374266\n",
      "Epoch 3083, Loss: 0.0021009227784816176, Final Batch Loss: 3.95207607652992e-05\n",
      "Epoch 3084, Loss: 0.007287631451617926, Final Batch Loss: 0.00030343857361003757\n",
      "Epoch 3085, Loss: 0.011545007946551777, Final Batch Loss: 0.0009220490464940667\n",
      "Epoch 3086, Loss: 0.004727413885120768, Final Batch Loss: 3.536279109539464e-05\n",
      "Epoch 3087, Loss: 0.001766124233085975, Final Batch Loss: 9.72492102846445e-07\n",
      "Epoch 3088, Loss: 0.00041582219273550436, Final Batch Loss: 7.798396836733446e-05\n",
      "Epoch 3089, Loss: 0.00041509076982038096, Final Batch Loss: 2.1925174223724753e-05\n",
      "Epoch 3090, Loss: 0.0025235817302018404, Final Batch Loss: 0.0021176261361688375\n",
      "Epoch 3091, Loss: 0.0034737145203962427, Final Batch Loss: 1.2171828984719468e-06\n",
      "Epoch 3092, Loss: 0.0011327740794513375, Final Batch Loss: 1.3055192539468408e-05\n",
      "Epoch 3093, Loss: 0.0007098710802893038, Final Batch Loss: 9.30432270251913e-06\n",
      "Epoch 3094, Loss: 0.00017468589362579223, Final Batch Loss: 3.438198518779245e-06\n",
      "Epoch 3095, Loss: 0.000884339700860437, Final Batch Loss: 8.143593731801957e-06\n",
      "Epoch 3096, Loss: 0.002017391372646671, Final Batch Loss: 0.00013303149899002165\n",
      "Epoch 3097, Loss: 0.0006075769415474497, Final Batch Loss: 0.0004007871320936829\n",
      "Epoch 3098, Loss: 0.0017512496633571573, Final Batch Loss: 8.365560643142089e-05\n",
      "Epoch 3099, Loss: 0.0010216700677574408, Final Batch Loss: 3.3566459478606703e-06\n",
      "Epoch 3100, Loss: 0.0005427089854492806, Final Batch Loss: 0.00027597887674346566\n",
      "Epoch 3101, Loss: 0.00025805638870224357, Final Batch Loss: 3.3621756301727146e-05\n",
      "Epoch 3102, Loss: 0.0003093046157118806, Final Batch Loss: 6.732033853040775e-06\n",
      "Epoch 3103, Loss: 0.0010301183738192776, Final Batch Loss: 2.4178991225198843e-05\n",
      "Epoch 3104, Loss: 0.001210844520073806, Final Batch Loss: 2.1206553810770856e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3105, Loss: 0.0006260644877329469, Final Batch Loss: 0.00021927048510406166\n",
      "Epoch 3106, Loss: 0.001745204601320438, Final Batch Loss: 8.118200639728457e-06\n",
      "Epoch 3107, Loss: 0.018494522708351724, Final Batch Loss: 2.7829271857626736e-05\n",
      "Epoch 3108, Loss: 0.04260744855127996, Final Batch Loss: 8.658062142785639e-06\n",
      "Epoch 3109, Loss: 0.0009490940371961187, Final Batch Loss: 3.2437035315524554e-06\n",
      "Epoch 3110, Loss: 0.00028091840795241296, Final Batch Loss: 0.00010696362005546689\n",
      "Epoch 3111, Loss: 0.0006304513390205102, Final Batch Loss: 2.152026354451664e-06\n",
      "Epoch 3112, Loss: 0.00046558972098864615, Final Batch Loss: 3.868981002597138e-05\n",
      "Epoch 3113, Loss: 0.00041349894854647573, Final Batch Loss: 2.548209704400506e-05\n",
      "Epoch 3114, Loss: 0.0008265961077995598, Final Batch Loss: 0.00040528152021579444\n",
      "Epoch 3115, Loss: 0.007582647784147412, Final Batch Loss: 0.0016350457444787025\n",
      "Epoch 3116, Loss: 0.0004248657205607742, Final Batch Loss: 3.238589852117002e-05\n",
      "Epoch 3117, Loss: 0.0011778098851209506, Final Batch Loss: 0.0007675890810787678\n",
      "Epoch 3118, Loss: 0.0006634679521084763, Final Batch Loss: 6.7269524151925e-05\n",
      "Epoch 3119, Loss: 0.0005418445871328004, Final Batch Loss: 0.00019316858379170299\n",
      "Epoch 3120, Loss: 0.0005032101180404425, Final Batch Loss: 2.2037493181414902e-05\n",
      "Epoch 3121, Loss: 0.01094316206581425, Final Batch Loss: 9.311856410931796e-05\n",
      "Epoch 3122, Loss: 0.001400257198838517, Final Batch Loss: 3.436775295995176e-05\n",
      "Epoch 3123, Loss: 0.001966911106137559, Final Batch Loss: 0.000982311088591814\n",
      "Epoch 3124, Loss: 0.0014561872767444584, Final Batch Loss: 1.4260232092055958e-05\n",
      "Epoch 3125, Loss: 0.0004220393457217142, Final Batch Loss: 3.252898750361055e-05\n",
      "Epoch 3126, Loss: 0.0008309637360071065, Final Batch Loss: 2.227656113973353e-05\n",
      "Epoch 3127, Loss: 0.010901960151386447, Final Batch Loss: 6.743031553924084e-05\n",
      "Epoch 3128, Loss: 0.0007599486852996051, Final Batch Loss: 0.00010010454570874572\n",
      "Epoch 3129, Loss: 0.002853878730093129, Final Batch Loss: 0.0018927004421129823\n",
      "Epoch 3130, Loss: 0.0007411370679619722, Final Batch Loss: 0.00012152395356679335\n",
      "Epoch 3131, Loss: 0.011296367083559744, Final Batch Loss: 6.875900726299733e-05\n",
      "Epoch 3132, Loss: 0.0006928897346369922, Final Batch Loss: 0.0001939567009685561\n",
      "Epoch 3133, Loss: 0.0011213726211281028, Final Batch Loss: 3.801859202212654e-05\n",
      "Epoch 3134, Loss: 0.0044843910764029715, Final Batch Loss: 1.666159732849337e-05\n",
      "Epoch 3135, Loss: 0.0005287008007144323, Final Batch Loss: 3.839673809125088e-06\n",
      "Epoch 3136, Loss: 0.0006780786970921326, Final Batch Loss: 3.7437468563439324e-05\n",
      "Epoch 3137, Loss: 0.013763504073722288, Final Batch Loss: 0.00015721155796200037\n",
      "Epoch 3138, Loss: 0.0032891695764192264, Final Batch Loss: 8.087200512818526e-06\n",
      "Epoch 3139, Loss: 0.00103428476722911, Final Batch Loss: 0.00023192260414361954\n",
      "Epoch 3140, Loss: 0.004857634674408473, Final Batch Loss: 1.7158003174699843e-05\n",
      "Epoch 3141, Loss: 0.0007715968749835156, Final Batch Loss: 0.00047669114428572357\n",
      "Epoch 3142, Loss: 0.005949554415565217, Final Batch Loss: 8.451115718344226e-06\n",
      "Epoch 3143, Loss: 0.000271600012865747, Final Batch Loss: 2.4029834548855433e-06\n",
      "Epoch 3144, Loss: 0.011705041672030347, Final Batch Loss: 2.4940401999629103e-05\n",
      "Epoch 3145, Loss: 0.0003552451526047662, Final Batch Loss: 6.924742774572223e-05\n",
      "Epoch 3146, Loss: 0.0009353925343020819, Final Batch Loss: 8.485470607411116e-05\n",
      "Epoch 3147, Loss: 0.0007815381868567783, Final Batch Loss: 9.203813533531502e-06\n",
      "Epoch 3148, Loss: 0.004534264953690581, Final Batch Loss: 0.00010278115223627537\n",
      "Epoch 3149, Loss: 0.0007309058382816147, Final Batch Loss: 2.134769965778105e-05\n",
      "Epoch 3150, Loss: 0.0012627780088223517, Final Batch Loss: 0.0008148769848048687\n",
      "Epoch 3151, Loss: 0.018257963893120177, Final Batch Loss: 0.00010655609366949648\n",
      "Epoch 3152, Loss: 0.007283035080035916, Final Batch Loss: 4.0821269067237154e-05\n",
      "Epoch 3153, Loss: 0.0006105259490141179, Final Batch Loss: 5.3321808081818745e-05\n",
      "Epoch 3154, Loss: 0.00079490589996567, Final Batch Loss: 0.000479053269373253\n",
      "Epoch 3155, Loss: 0.0006338643611343286, Final Batch Loss: 5.690529633284314e-06\n",
      "Epoch 3156, Loss: 0.0005860161400050856, Final Batch Loss: 0.00018474043463356793\n",
      "Epoch 3157, Loss: 0.000552238653654058, Final Batch Loss: 1.1700224604282994e-05\n",
      "Epoch 3158, Loss: 0.0006306300024334632, Final Batch Loss: 4.736907158076065e-06\n",
      "Epoch 3159, Loss: 0.008052670362303616, Final Batch Loss: 2.4915405447245575e-05\n",
      "Epoch 3160, Loss: 0.0012013147515972378, Final Batch Loss: 1.2202677680761553e-05\n",
      "Epoch 3161, Loss: 0.004807127930689603, Final Batch Loss: 0.0023612952791154385\n",
      "Epoch 3162, Loss: 0.010218874958809465, Final Batch Loss: 0.009068976156413555\n",
      "Epoch 3163, Loss: 0.0005154746352218353, Final Batch Loss: 2.3841487291065278e-06\n",
      "Epoch 3164, Loss: 0.0015246276598190889, Final Batch Loss: 0.000360214791726321\n",
      "Epoch 3165, Loss: 0.004143731435760856, Final Batch Loss: 0.0029913533944636583\n",
      "Epoch 3166, Loss: 0.0006966835080675082, Final Batch Loss: 1.062188130163122e-05\n",
      "Epoch 3167, Loss: 0.00017177548579638824, Final Batch Loss: 1.5760018868604675e-05\n",
      "Epoch 3168, Loss: 0.0010064418711408507, Final Batch Loss: 0.00023422644881065935\n",
      "Epoch 3169, Loss: 0.001359453410259448, Final Batch Loss: 0.0001806399814086035\n",
      "Epoch 3170, Loss: 0.002398511023784522, Final Batch Loss: 0.00012315520143602043\n",
      "Epoch 3171, Loss: 0.007913244677183684, Final Batch Loss: 0.00010594545165076852\n",
      "Epoch 3172, Loss: 0.04314135770255234, Final Batch Loss: 4.101924423594028e-05\n",
      "Epoch 3173, Loss: 0.0014436815763474442, Final Batch Loss: 5.7281504268758e-06\n",
      "Epoch 3174, Loss: 0.0032746299293648917, Final Batch Loss: 2.224679701612331e-05\n",
      "Epoch 3175, Loss: 0.003490779927233234, Final Batch Loss: 0.00296721956692636\n",
      "Epoch 3176, Loss: 0.0012078839645255357, Final Batch Loss: 8.901237742975354e-05\n",
      "Epoch 3177, Loss: 0.004771918887854554, Final Batch Loss: 0.004311306867748499\n",
      "Epoch 3178, Loss: 0.0021599972242256626, Final Batch Loss: 7.617252413183451e-05\n",
      "Epoch 3179, Loss: 0.0004134801686745959, Final Batch Loss: 4.5173993612479535e-07\n",
      "Epoch 3180, Loss: 0.0017132164211943746, Final Batch Loss: 4.523299867287278e-05\n",
      "Epoch 3181, Loss: 0.000286853569377854, Final Batch Loss: 1.192628678836627e-05\n",
      "Epoch 3182, Loss: 0.0016892811181605794, Final Batch Loss: 9.203606896335259e-05\n",
      "Epoch 3183, Loss: 0.001578857210915885, Final Batch Loss: 9.818779290071689e-06\n",
      "Epoch 3184, Loss: 0.001436950988136232, Final Batch Loss: 8.91064410097897e-05\n",
      "Epoch 3185, Loss: 0.0007522224623244256, Final Batch Loss: 0.000441038137068972\n",
      "Epoch 3186, Loss: 0.0007818909143679775, Final Batch Loss: 2.5022251065820456e-05\n",
      "Epoch 3187, Loss: 0.0013295825906425307, Final Batch Loss: 3.9527230910607614e-07\n",
      "Epoch 3188, Loss: 0.004314290330512449, Final Batch Loss: 0.0013447859091684222\n",
      "Epoch 3189, Loss: 0.0002579098518253886, Final Batch Loss: 7.905165148258675e-06\n",
      "Epoch 3190, Loss: 0.00036619321690523066, Final Batch Loss: 0.00016125885304063559\n",
      "Epoch 3191, Loss: 0.001990203990317241, Final Batch Loss: 1.3425725228444207e-05\n",
      "Epoch 3192, Loss: 0.005919084796914831, Final Batch Loss: 0.0015797314699739218\n",
      "Epoch 3193, Loss: 0.000156594186591974, Final Batch Loss: 1.1675871974148322e-05\n",
      "Epoch 3194, Loss: 0.0008122275285131764, Final Batch Loss: 0.00028683271375484765\n",
      "Epoch 3195, Loss: 0.0011202286113984883, Final Batch Loss: 0.0007652450003661215\n",
      "Epoch 3196, Loss: 0.00012680184590863064, Final Batch Loss: 8.018210792215541e-06\n",
      "Epoch 3197, Loss: 0.0010017979096801355, Final Batch Loss: 1.5434364968314185e-06\n",
      "Epoch 3198, Loss: 0.0005009074743611563, Final Batch Loss: 3.551111603883328e-06\n",
      "Epoch 3199, Loss: 0.017290597324517876, Final Batch Loss: 5.3455237321031746e-06\n",
      "Epoch 3200, Loss: 0.0009189058619085699, Final Batch Loss: 0.0006939049926586449\n",
      "Epoch 3201, Loss: 0.00018652643484529108, Final Batch Loss: 2.8158519853604957e-05\n",
      "Epoch 3202, Loss: 0.00043961724441032857, Final Batch Loss: 0.000127585168229416\n",
      "Epoch 3203, Loss: 0.00019412560084219876, Final Batch Loss: 1.1167970797032467e-06\n",
      "Epoch 3204, Loss: 0.0016999675399347325, Final Batch Loss: 1.2465764484659303e-05\n",
      "Epoch 3205, Loss: 0.00021409759392554406, Final Batch Loss: 1.6580977899138816e-05\n",
      "Epoch 3206, Loss: 0.0004980518460797612, Final Batch Loss: 5.866244464414194e-06\n",
      "Epoch 3207, Loss: 0.007337999064475298, Final Batch Loss: 7.44336866773665e-05\n",
      "Epoch 3208, Loss: 0.00038613612377957907, Final Batch Loss: 1.5402130884467624e-05\n",
      "Epoch 3209, Loss: 0.0008828404825180769, Final Batch Loss: 1.1242242180742323e-05\n",
      "Epoch 3210, Loss: 0.0024771109892753884, Final Batch Loss: 0.00028253498021513224\n",
      "Epoch 3211, Loss: 0.0006069636829124647, Final Batch Loss: 1.1888662811543327e-05\n",
      "Epoch 3212, Loss: 0.0008265846081485506, Final Batch Loss: 1.5345318388426676e-05\n",
      "Epoch 3213, Loss: 0.0009334730129921809, Final Batch Loss: 0.0002608337381388992\n",
      "Epoch 3214, Loss: 0.002276195853482932, Final Batch Loss: 0.0015370143810287118\n",
      "Epoch 3215, Loss: 0.001191081275464967, Final Batch Loss: 0.0003715830098371953\n",
      "Epoch 3216, Loss: 0.0016887278616195545, Final Batch Loss: 1.6336372937075794e-05\n",
      "Epoch 3217, Loss: 0.002820427413098514, Final Batch Loss: 0.0005349891143850982\n",
      "Epoch 3218, Loss: 0.0003420213079152745, Final Batch Loss: 9.611770110495854e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3219, Loss: 0.0011361758661223575, Final Batch Loss: 0.00015421117132063955\n",
      "Epoch 3220, Loss: 0.0003166634378430899, Final Batch Loss: 5.3115432820050046e-05\n",
      "Epoch 3221, Loss: 0.0005626528181892354, Final Batch Loss: 4.365032145869918e-05\n",
      "Epoch 3222, Loss: 0.0014718787169840652, Final Batch Loss: 4.496098335948773e-05\n",
      "Epoch 3223, Loss: 0.0008320308552356437, Final Batch Loss: 0.0005626307683996856\n",
      "Epoch 3224, Loss: 0.0002776269393507391, Final Batch Loss: 5.289994442136958e-05\n",
      "Epoch 3225, Loss: 0.0008622877794550732, Final Batch Loss: 0.00025230576284229755\n",
      "Epoch 3226, Loss: 0.022813210999856892, Final Batch Loss: 1.3865876553609269e-06\n",
      "Epoch 3227, Loss: 0.0003491239622235298, Final Batch Loss: 5.100824637338519e-06\n",
      "Epoch 3228, Loss: 0.0012269193830434233, Final Batch Loss: 0.0003528035304043442\n",
      "Epoch 3229, Loss: 0.0007718826139750945, Final Batch Loss: 2.321442877928348e-07\n",
      "Epoch 3230, Loss: 0.0010623108828440309, Final Batch Loss: 0.0009079081355594099\n",
      "Epoch 3231, Loss: 0.0008287820810437552, Final Batch Loss: 5.652937943523284e-06\n",
      "Epoch 3232, Loss: 0.0006202140816640167, Final Batch Loss: 4.335337962402264e-06\n",
      "Epoch 3233, Loss: 0.0006362338390317746, Final Batch Loss: 3.457018465269357e-06\n",
      "Epoch 3234, Loss: 0.0003855067278664137, Final Batch Loss: 1.555987068968534e-06\n",
      "Epoch 3235, Loss: 0.002946924078742086, Final Batch Loss: 1.9637834611785365e-06\n",
      "Epoch 3236, Loss: 0.0006020087421347853, Final Batch Loss: 1.072184750228189e-05\n",
      "Epoch 3237, Loss: 0.0021130953973624855, Final Batch Loss: 0.00017028275760821998\n",
      "Epoch 3238, Loss: 0.0007183705893112347, Final Batch Loss: 0.0001505978434579447\n",
      "Epoch 3239, Loss: 0.0007508432463509962, Final Batch Loss: 0.0005998167325742543\n",
      "Epoch 3240, Loss: 0.000540102588274749, Final Batch Loss: 3.5386929084779695e-05\n",
      "Epoch 3241, Loss: 0.0015827134702703916, Final Batch Loss: 6.761645636288449e-05\n",
      "Epoch 3242, Loss: 0.000988280644378392, Final Batch Loss: 0.0008527590543963015\n",
      "Epoch 3243, Loss: 0.0005240973841864616, Final Batch Loss: 2.549552300479263e-05\n",
      "Epoch 3244, Loss: 0.009944036530214362, Final Batch Loss: 0.0005877588992007077\n",
      "Epoch 3245, Loss: 0.0008447158070339356, Final Batch Loss: 5.302602585288696e-05\n",
      "Epoch 3246, Loss: 0.0002479111535649281, Final Batch Loss: 6.836461398052052e-05\n",
      "Epoch 3247, Loss: 0.0004762394182762364, Final Batch Loss: 1.4360683053382672e-05\n",
      "Epoch 3248, Loss: 0.0012753596192851546, Final Batch Loss: 9.467107702221256e-06\n",
      "Epoch 3249, Loss: 0.022009754640748724, Final Batch Loss: 5.83472428843379e-05\n",
      "Epoch 3250, Loss: 0.0008982540530269034, Final Batch Loss: 0.0005025031277909875\n",
      "Epoch 3251, Loss: 0.0003540162442732253, Final Batch Loss: 9.347882041765843e-06\n",
      "Epoch 3252, Loss: 0.00036850606238658656, Final Batch Loss: 1.5058003555168398e-07\n",
      "Epoch 3253, Loss: 0.0012802896043240253, Final Batch Loss: 1.3238412748250994e-06\n",
      "Epoch 3254, Loss: 0.00042765927537402604, Final Batch Loss: 2.9134122087270953e-05\n",
      "Epoch 3255, Loss: 0.0002129368222085759, Final Batch Loss: 8.112467912724242e-05\n",
      "Epoch 3256, Loss: 0.0002639455269672908, Final Batch Loss: 7.161431858548895e-05\n",
      "Epoch 3257, Loss: 0.00462324215186527, Final Batch Loss: 7.731377991149202e-05\n",
      "Epoch 3258, Loss: 0.00026597925534588285, Final Batch Loss: 5.510366099770181e-05\n",
      "Epoch 3259, Loss: 0.0006868277268949896, Final Batch Loss: 0.00024686852702870965\n",
      "Epoch 3260, Loss: 0.006824325464549474, Final Batch Loss: 3.106790245510638e-05\n",
      "Epoch 3261, Loss: 0.00043294582656017155, Final Batch Loss: 5.75327658225433e-06\n",
      "Epoch 3262, Loss: 0.0038493432075483724, Final Batch Loss: 0.00105771841481328\n",
      "Epoch 3263, Loss: 0.00016302071678353514, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 3264, Loss: 0.0004934673602292605, Final Batch Loss: 4.103229457541602e-06\n",
      "Epoch 3265, Loss: 0.00033963787427637726, Final Batch Loss: 4.415141302160919e-05\n",
      "Epoch 3266, Loss: 0.00040440462538526845, Final Batch Loss: 2.88611715859588e-07\n",
      "Epoch 3267, Loss: 0.0002951549176941626, Final Batch Loss: 1.676329702604562e-05\n",
      "Epoch 3268, Loss: 0.0001404215126967756, Final Batch Loss: 2.4728615244384855e-05\n",
      "Epoch 3269, Loss: 0.0011611143954723957, Final Batch Loss: 5.583783604379278e-06\n",
      "Epoch 3270, Loss: 0.0008372638985747471, Final Batch Loss: 0.0007401885814033449\n",
      "Epoch 3271, Loss: 0.00032457622728543356, Final Batch Loss: 3.5023906093556434e-05\n",
      "Epoch 3272, Loss: 0.00025274093786720186, Final Batch Loss: 3.770938201341778e-05\n",
      "Epoch 3273, Loss: 0.0002351472674604338, Final Batch Loss: 5.082063694317185e-07\n",
      "Epoch 3274, Loss: 0.00046755740549997427, Final Batch Loss: 1.4134489902062342e-05\n",
      "Epoch 3275, Loss: 0.00024555337404308375, Final Batch Loss: 0.00016181803948711604\n",
      "Epoch 3276, Loss: 0.0004488257327466272, Final Batch Loss: 6.897513958392665e-05\n",
      "Epoch 3277, Loss: 0.0015577224185108207, Final Batch Loss: 0.00017610042414162308\n",
      "Epoch 3278, Loss: 0.0005568707638303749, Final Batch Loss: 4.275891842553392e-05\n",
      "Epoch 3279, Loss: 0.0023505198187194765, Final Batch Loss: 0.0006780702387914062\n",
      "Epoch 3280, Loss: 0.00022971946600591764, Final Batch Loss: 6.613890582229942e-05\n",
      "Epoch 3281, Loss: 0.006494272220152197, Final Batch Loss: 0.00616138381883502\n",
      "Epoch 3282, Loss: 0.000794199385381944, Final Batch Loss: 7.722980626567733e-06\n",
      "Epoch 3283, Loss: 0.0007171504112193361, Final Batch Loss: 0.0003225437831133604\n",
      "Epoch 3284, Loss: 0.0007409090394503437, Final Batch Loss: 2.680448960745707e-05\n",
      "Epoch 3285, Loss: 0.00024315841801580973, Final Batch Loss: 1.5590285329381004e-05\n",
      "Epoch 3286, Loss: 0.0014268345044001762, Final Batch Loss: 3.2562606975261588e-06\n",
      "Epoch 3287, Loss: 0.0007860221665865197, Final Batch Loss: 1.1920915454766146e-07\n",
      "Epoch 3288, Loss: 0.021497414933037362, Final Batch Loss: 2.6692510800785385e-05\n",
      "Epoch 3289, Loss: 0.05355869050617912, Final Batch Loss: 0.05312036722898483\n",
      "Epoch 3290, Loss: 0.000675407238304615, Final Batch Loss: 3.843355807475746e-05\n",
      "Epoch 3291, Loss: 0.0002615193589008413, Final Batch Loss: 5.975318345008418e-05\n",
      "Epoch 3292, Loss: 0.005950785460299812, Final Batch Loss: 5.652822437696159e-06\n",
      "Epoch 3293, Loss: 0.013606377178803086, Final Batch Loss: 0.00031158229103311896\n",
      "Epoch 3294, Loss: 0.006221346498932689, Final Batch Loss: 0.005785407964140177\n",
      "Epoch 3295, Loss: 0.0006957909208722413, Final Batch Loss: 7.106896373443305e-05\n",
      "Epoch 3296, Loss: 0.01191807947907364, Final Batch Loss: 7.049764826660976e-05\n",
      "Epoch 3297, Loss: 0.01974116921701352, Final Batch Loss: 1.1374224413884804e-05\n",
      "Epoch 3298, Loss: 0.000965259038594013, Final Batch Loss: 2.239860577901709e-06\n",
      "Epoch 3299, Loss: 0.0011039351229555905, Final Batch Loss: 0.0006523645133711398\n",
      "Epoch 3300, Loss: 0.005567566091485787, Final Batch Loss: 6.727818254148588e-05\n",
      "Epoch 3301, Loss: 0.00048499136028112844, Final Batch Loss: 1.7779188056010753e-05\n",
      "Epoch 3302, Loss: 0.0015858939150348306, Final Batch Loss: 0.0005289860418997705\n",
      "Epoch 3303, Loss: 0.019035861546399246, Final Batch Loss: 9.774822501640301e-06\n",
      "Epoch 3304, Loss: 0.04229057773045497, Final Batch Loss: 0.040805280208587646\n",
      "Epoch 3305, Loss: 0.007984275047419942, Final Batch Loss: 2.60442520811921e-05\n",
      "Epoch 3306, Loss: 0.0018106682546203956, Final Batch Loss: 0.00015030024223960936\n",
      "Epoch 3307, Loss: 0.018205302957767344, Final Batch Loss: 3.09311258206435e-06\n",
      "Epoch 3308, Loss: 0.00030444634285231587, Final Batch Loss: 2.7740714358515106e-05\n",
      "Epoch 3309, Loss: 0.006116931853284768, Final Batch Loss: 1.1481361980258953e-05\n",
      "Epoch 3310, Loss: 0.016043979406731523, Final Batch Loss: 7.070907940942561e-06\n",
      "Epoch 3311, Loss: 0.0007659464317839593, Final Batch Loss: 0.00036945301690138876\n",
      "Epoch 3312, Loss: 0.001195643431856297, Final Batch Loss: 5.577618139795959e-06\n",
      "Epoch 3313, Loss: 0.014236815826734528, Final Batch Loss: 0.0001622042036615312\n",
      "Epoch 3314, Loss: 0.0002670493340701796, Final Batch Loss: 7.424560317303985e-05\n",
      "Epoch 3315, Loss: 0.0007990874182723928, Final Batch Loss: 4.265674579073675e-05\n",
      "Epoch 3316, Loss: 0.0013860832987120375, Final Batch Loss: 8.863036782713607e-05\n",
      "Epoch 3317, Loss: 0.0017378071352140978, Final Batch Loss: 9.771822806214914e-05\n",
      "Epoch 3318, Loss: 0.0013112114379509876, Final Batch Loss: 2.4092573767120484e-06\n",
      "Epoch 3319, Loss: 0.001036893776472425, Final Batch Loss: 7.5849493441637605e-06\n",
      "Epoch 3320, Loss: 0.0014546745587722398, Final Batch Loss: 0.00011176206317031756\n",
      "Epoch 3321, Loss: 0.000765704688092228, Final Batch Loss: 0.000591927208006382\n",
      "Epoch 3322, Loss: 0.0006376270175678656, Final Batch Loss: 0.00026464383699931204\n",
      "Epoch 3323, Loss: 0.000417425302657648, Final Batch Loss: 2.9500681193894707e-05\n",
      "Epoch 3324, Loss: 0.00023595467246195767, Final Batch Loss: 1.9486205928842537e-05\n",
      "Epoch 3325, Loss: 0.0015677429637435125, Final Batch Loss: 1.5539642845396884e-05\n",
      "Epoch 3326, Loss: 0.0002426803180242132, Final Batch Loss: 1.4555912457581144e-06\n",
      "Epoch 3327, Loss: 0.0006070316358091077, Final Batch Loss: 5.784653694718145e-06\n",
      "Epoch 3328, Loss: 0.0005005452403565869, Final Batch Loss: 0.00011182775051565841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3329, Loss: 0.0016627220411464805, Final Batch Loss: 3.0016375603736378e-05\n",
      "Epoch 3330, Loss: 0.0003988596245108056, Final Batch Loss: 5.10706286149798e-06\n",
      "Epoch 3331, Loss: 0.0003857463143503992, Final Batch Loss: 1.9811513993772678e-05\n",
      "Epoch 3332, Loss: 0.0004107616296096239, Final Batch Loss: 0.00024239513732027262\n",
      "Epoch 3333, Loss: 0.0014688075279991608, Final Batch Loss: 4.574762351694517e-05\n",
      "Epoch 3334, Loss: 0.0001385009236400947, Final Batch Loss: 2.9412585718091577e-05\n",
      "Epoch 3335, Loss: 0.0014318866014946252, Final Batch Loss: 0.0010655857622623444\n",
      "Epoch 3336, Loss: 0.000332799470925238, Final Batch Loss: 8.124611485982314e-05\n",
      "Epoch 3337, Loss: 0.0029323145863600075, Final Batch Loss: 1.9090708519797772e-05\n",
      "Epoch 3338, Loss: 0.0014501111436402425, Final Batch Loss: 0.0001007893806672655\n",
      "Epoch 3339, Loss: 0.0003220163105197571, Final Batch Loss: 2.0202694486215478e-06\n",
      "Epoch 3340, Loss: 0.016812693756946828, Final Batch Loss: 3.255098272347823e-05\n",
      "Epoch 3341, Loss: 0.0013968934945296496, Final Batch Loss: 0.00028260136605240405\n",
      "Epoch 3342, Loss: 0.00032468558492837474, Final Batch Loss: 4.248474579071626e-05\n",
      "Epoch 3343, Loss: 0.0002172861296685369, Final Batch Loss: 1.6689174344719504e-06\n",
      "Epoch 3344, Loss: 0.0008165522920080548, Final Batch Loss: 2.5284423372795573e-06\n",
      "Epoch 3345, Loss: 0.004864252923653112, Final Batch Loss: 2.08722867682809e-05\n",
      "Epoch 3346, Loss: 0.0021213187283137813, Final Batch Loss: 3.17665544571355e-05\n",
      "Epoch 3347, Loss: 0.00032240715518128127, Final Batch Loss: 7.450315752066672e-05\n",
      "Epoch 3348, Loss: 0.0005874436856174725, Final Batch Loss: 8.883735972631257e-06\n",
      "Epoch 3349, Loss: 0.0014026562676008325, Final Batch Loss: 5.796584810013883e-05\n",
      "Epoch 3350, Loss: 0.0002953702896775212, Final Batch Loss: 1.1712592822732404e-05\n",
      "Epoch 3351, Loss: 0.01219187313108705, Final Batch Loss: 0.00029765148065052927\n",
      "Epoch 3352, Loss: 0.0003537298325682059, Final Batch Loss: 6.815187225583941e-05\n",
      "Epoch 3353, Loss: 0.000757604132331835, Final Batch Loss: 2.170848119931179e-06\n",
      "Epoch 3354, Loss: 0.00033047792567231227, Final Batch Loss: 2.1190471670706756e-05\n",
      "Epoch 3355, Loss: 0.01372417733000475, Final Batch Loss: 5.8983783674193546e-05\n",
      "Epoch 3356, Loss: 0.0006032632518326864, Final Batch Loss: 0.00012230539869051427\n",
      "Epoch 3357, Loss: 0.0007193323872343171, Final Batch Loss: 0.00018666608957573771\n",
      "Epoch 3358, Loss: 0.0005285805891617201, Final Batch Loss: 8.450926543446258e-05\n",
      "Epoch 3359, Loss: 0.0016163726704689907, Final Batch Loss: 4.197356247459538e-06\n",
      "Epoch 3360, Loss: 0.008067802962614223, Final Batch Loss: 0.007242757827043533\n",
      "Epoch 3361, Loss: 0.0008485462894896045, Final Batch Loss: 0.00023796789173502475\n",
      "Epoch 3362, Loss: 0.0006985655272728764, Final Batch Loss: 6.90020460751839e-05\n",
      "Epoch 3363, Loss: 0.0004924688619212247, Final Batch Loss: 7.287406333489344e-05\n",
      "Epoch 3364, Loss: 0.0006296469582594, Final Batch Loss: 0.00021881939028389752\n",
      "Epoch 3365, Loss: 0.00048356348315792275, Final Batch Loss: 7.54756229071063e-06\n",
      "Epoch 3366, Loss: 0.00021377566918090452, Final Batch Loss: 1.9152417735313065e-05\n",
      "Epoch 3367, Loss: 0.0007193235014710808, Final Batch Loss: 1.861244709289167e-05\n",
      "Epoch 3368, Loss: 0.0005539432022487745, Final Batch Loss: 0.00019634838099591434\n",
      "Epoch 3369, Loss: 0.00036164965422358364, Final Batch Loss: 0.00020754574507009238\n",
      "Epoch 3370, Loss: 0.004979199811714352, Final Batch Loss: 0.0013792349491268396\n",
      "Epoch 3371, Loss: 0.0005338556011338369, Final Batch Loss: 8.281706868729088e-06\n",
      "Epoch 3372, Loss: 0.023915933879834483, Final Batch Loss: 2.578655767138116e-06\n",
      "Epoch 3373, Loss: 0.003173855318891583, Final Batch Loss: 0.0023640256840735674\n",
      "Epoch 3374, Loss: 0.00046003788338566665, Final Batch Loss: 2.2272997739491984e-06\n",
      "Epoch 3375, Loss: 0.0004396999938762747, Final Batch Loss: 0.0002293297729920596\n",
      "Epoch 3376, Loss: 0.00223741153604351, Final Batch Loss: 0.0017867105780169368\n",
      "Epoch 3377, Loss: 0.0006121021028775431, Final Batch Loss: 2.120639237546129e-06\n",
      "Epoch 3378, Loss: 0.003544989405781962, Final Batch Loss: 0.00024275814939755946\n",
      "Epoch 3379, Loss: 0.0003024257966899313, Final Batch Loss: 1.5696707123424858e-05\n",
      "Epoch 3380, Loss: 0.0031956194870872423, Final Batch Loss: 6.451368244597688e-05\n",
      "Epoch 3381, Loss: 0.00017130923720287683, Final Batch Loss: 2.8484230369940633e-06\n",
      "Epoch 3382, Loss: 0.18633953992684837, Final Batch Loss: 0.1858377456665039\n",
      "Epoch 3383, Loss: 0.0007353612709266599, Final Batch Loss: 5.456636063172482e-05\n",
      "Epoch 3384, Loss: 0.01376116057690524, Final Batch Loss: 1.7948559616343118e-05\n",
      "Epoch 3385, Loss: 0.005759822059189901, Final Batch Loss: 0.003131786361336708\n",
      "Epoch 3386, Loss: 0.0003410505778447259, Final Batch Loss: 3.269201624789275e-05\n",
      "Epoch 3387, Loss: 0.0021422674290079158, Final Batch Loss: 3.445318361627869e-05\n",
      "Epoch 3388, Loss: 0.0024081275332719088, Final Batch Loss: 0.00013708032201975584\n",
      "Epoch 3389, Loss: 0.0014090003605815582, Final Batch Loss: 6.240697257453576e-05\n",
      "Epoch 3390, Loss: 0.027417038654675707, Final Batch Loss: 5.068900645710528e-05\n",
      "Epoch 3391, Loss: 0.0010479114062036388, Final Batch Loss: 4.971896851202473e-05\n",
      "Epoch 3392, Loss: 0.0007188580566435121, Final Batch Loss: 3.501056198729202e-05\n",
      "Epoch 3393, Loss: 0.0023643363383598626, Final Batch Loss: 0.0005021701217629015\n",
      "Epoch 3394, Loss: 0.0007833901022422651, Final Batch Loss: 5.778389549959684e-06\n",
      "Epoch 3395, Loss: 0.003176540427375585, Final Batch Loss: 0.0019583103712648153\n",
      "Epoch 3396, Loss: 0.0007321944281102333, Final Batch Loss: 2.371612481510965e-06\n",
      "Epoch 3397, Loss: 0.0016663491478539072, Final Batch Loss: 9.314882481703535e-05\n",
      "Epoch 3398, Loss: 0.0008981739538285183, Final Batch Loss: 9.730962119647302e-06\n",
      "Epoch 3399, Loss: 0.000622249637672212, Final Batch Loss: 0.00019737884576898068\n",
      "Epoch 3400, Loss: 0.009962392519810237, Final Batch Loss: 0.00932728499174118\n",
      "Epoch 3401, Loss: 0.007151150159188546, Final Batch Loss: 0.006529796402901411\n",
      "Epoch 3402, Loss: 0.0012632530851988122, Final Batch Loss: 0.00022495572920888662\n",
      "Epoch 3403, Loss: 0.004078820100403391, Final Batch Loss: 0.003493481082841754\n",
      "Epoch 3404, Loss: 0.0007156470674090087, Final Batch Loss: 0.00030742018134333193\n",
      "Epoch 3405, Loss: 0.0006141167214082088, Final Batch Loss: 2.764821329037659e-05\n",
      "Epoch 3406, Loss: 0.0010204082645941526, Final Batch Loss: 0.00031307883909903467\n",
      "Epoch 3407, Loss: 0.0007044700760161504, Final Batch Loss: 5.582757876254618e-05\n",
      "Epoch 3408, Loss: 0.00028421240403986303, Final Batch Loss: 1.0207494597125333e-05\n",
      "Epoch 3409, Loss: 0.0008334735903190449, Final Batch Loss: 0.0001716020196909085\n",
      "Epoch 3410, Loss: 0.0003827923137578182, Final Batch Loss: 0.00020132120698690414\n",
      "Epoch 3411, Loss: 0.0005815378171973862, Final Batch Loss: 0.0004087862325832248\n",
      "Epoch 3412, Loss: 0.0008434789069724502, Final Batch Loss: 1.883249387901742e-05\n",
      "Epoch 3413, Loss: 0.0032546299626119435, Final Batch Loss: 2.487964229658246e-05\n",
      "Epoch 3414, Loss: 0.00859488605055958, Final Batch Loss: 0.00030298903584480286\n",
      "Epoch 3415, Loss: 0.0021939681537332945, Final Batch Loss: 0.0001108726064558141\n",
      "Epoch 3416, Loss: 0.0006998267990638851, Final Batch Loss: 1.277942556043854e-05\n",
      "Epoch 3417, Loss: 0.0009305973339905904, Final Batch Loss: 4.9690402192936745e-06\n",
      "Epoch 3418, Loss: 0.0006629648996749893, Final Batch Loss: 0.00035455464967526495\n",
      "Epoch 3419, Loss: 0.0008923453215174959, Final Batch Loss: 1.2647790754272137e-05\n",
      "Epoch 3420, Loss: 0.0005969135127088521, Final Batch Loss: 5.347303886082955e-05\n",
      "Epoch 3421, Loss: 0.001437220023944974, Final Batch Loss: 8.676179277244955e-05\n",
      "Epoch 3422, Loss: 0.0006046579956091591, Final Batch Loss: 4.573740625346545e-06\n",
      "Epoch 3423, Loss: 0.0010146833235467057, Final Batch Loss: 2.089284635076183e-06\n",
      "Epoch 3424, Loss: 0.0024010471388464794, Final Batch Loss: 0.0019288804614916444\n",
      "Epoch 3425, Loss: 0.013468447980500287, Final Batch Loss: 2.2586996806239767e-07\n",
      "Epoch 3426, Loss: 0.0024455273523926735, Final Batch Loss: 0.0016330871731042862\n",
      "Epoch 3427, Loss: 0.0009726183780003339, Final Batch Loss: 0.000285276590147987\n",
      "Epoch 3428, Loss: 0.001273415443392878, Final Batch Loss: 1.270462144020712e-05\n",
      "Epoch 3429, Loss: 0.0016623485134914517, Final Batch Loss: 0.0001160042520496063\n",
      "Epoch 3430, Loss: 0.0011845623994304333, Final Batch Loss: 1.9512408471200615e-06\n",
      "Epoch 3431, Loss: 0.0019178985294274753, Final Batch Loss: 2.860677159333136e-05\n",
      "Epoch 3432, Loss: 0.014065703773667337, Final Batch Loss: 3.5870125429937616e-05\n",
      "Epoch 3433, Loss: 0.0008194149995688349, Final Batch Loss: 0.00014379894128069282\n",
      "Epoch 3434, Loss: 0.014776463372982107, Final Batch Loss: 9.707361459732056e-05\n",
      "Epoch 3435, Loss: 0.0004912658896500943, Final Batch Loss: 1.8016826288658194e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3436, Loss: 0.0006136162774055265, Final Batch Loss: 6.313356425380334e-05\n",
      "Epoch 3437, Loss: 0.002235732856206596, Final Batch Loss: 0.00025138305500149727\n",
      "Epoch 3438, Loss: 0.012343455862719566, Final Batch Loss: 0.0025664803106337786\n",
      "Epoch 3439, Loss: 0.0007702585789957084, Final Batch Loss: 8.647354115964845e-05\n",
      "Epoch 3440, Loss: 0.0007467407049261965, Final Batch Loss: 1.2811309716198593e-05\n",
      "Epoch 3441, Loss: 0.0005113967490615323, Final Batch Loss: 5.611020606011152e-05\n",
      "Epoch 3442, Loss: 0.0020174656344806863, Final Batch Loss: 3.2876084787858417e-06\n",
      "Epoch 3443, Loss: 0.00043606725193967577, Final Batch Loss: 1.727752351143863e-05\n",
      "Epoch 3444, Loss: 0.0030034936062293127, Final Batch Loss: 0.0001473041920689866\n",
      "Epoch 3445, Loss: 0.0004103970295545878, Final Batch Loss: 2.2169226213009097e-05\n",
      "Epoch 3446, Loss: 0.002948902771095163, Final Batch Loss: 1.0044479495263658e-05\n",
      "Epoch 3447, Loss: 0.0003323472737974953, Final Batch Loss: 3.546186417224817e-05\n",
      "Epoch 3448, Loss: 0.0004936931618431117, Final Batch Loss: 5.002232137485407e-05\n",
      "Epoch 3449, Loss: 0.0004571401950670406, Final Batch Loss: 0.000167198057170026\n",
      "Epoch 3450, Loss: 0.0006530535501951817, Final Batch Loss: 2.8636193746933714e-05\n",
      "Epoch 3451, Loss: 0.001112377387471497, Final Batch Loss: 0.0002310596901224926\n",
      "Epoch 3452, Loss: 0.0008515957888448611, Final Batch Loss: 0.0006201406358741224\n",
      "Epoch 3453, Loss: 0.003374319727299735, Final Batch Loss: 0.002919217571616173\n",
      "Epoch 3454, Loss: 0.0006689260480925441, Final Batch Loss: 0.00038347498048096895\n",
      "Epoch 3455, Loss: 0.0013210573579272022, Final Batch Loss: 5.841144229634665e-06\n",
      "Epoch 3456, Loss: 0.0008412165748268308, Final Batch Loss: 5.050603704148671e-06\n",
      "Epoch 3457, Loss: 0.010721024571921589, Final Batch Loss: 2.214760115748504e-06\n",
      "Epoch 3458, Loss: 0.005135727224114817, Final Batch Loss: 9.815009980229661e-05\n",
      "Epoch 3459, Loss: 0.004827992230275413, Final Batch Loss: 4.0003866160986945e-05\n",
      "Epoch 3460, Loss: 0.0006477913557318971, Final Batch Loss: 9.382728603668511e-05\n",
      "Epoch 3461, Loss: 0.0007852928101783618, Final Batch Loss: 0.00016236068040598184\n",
      "Epoch 3462, Loss: 0.0009569928079145029, Final Batch Loss: 0.0007522168452851474\n",
      "Epoch 3463, Loss: 0.0003610216444940306, Final Batch Loss: 0.00014330372505355626\n",
      "Epoch 3464, Loss: 0.010286922450177372, Final Batch Loss: 6.398942787200212e-05\n",
      "Epoch 3465, Loss: 0.00046284480595204514, Final Batch Loss: 5.815878466819413e-06\n",
      "Epoch 3466, Loss: 0.0002826288837241009, Final Batch Loss: 9.204357047565281e-05\n",
      "Epoch 3467, Loss: 0.0006231888619367965, Final Batch Loss: 8.594699465902522e-05\n",
      "Epoch 3468, Loss: 0.0010898814507527277, Final Batch Loss: 0.00021198044123593718\n",
      "Epoch 3469, Loss: 0.001082374612451531, Final Batch Loss: 9.474567195866257e-05\n",
      "Epoch 3470, Loss: 0.014762237662125699, Final Batch Loss: 3.9338133319688495e-06\n",
      "Epoch 3471, Loss: 0.002979591869006981, Final Batch Loss: 1.3230632248451002e-05\n",
      "Epoch 3472, Loss: 0.0010648199481693155, Final Batch Loss: 5.565105766436318e-06\n",
      "Epoch 3473, Loss: 0.004768486236571334, Final Batch Loss: 6.654409662587568e-05\n",
      "Epoch 3474, Loss: 0.0005630246079135759, Final Batch Loss: 1.0979775879604858e-06\n",
      "Epoch 3475, Loss: 0.0005400117115641478, Final Batch Loss: 4.66761521238368e-05\n",
      "Epoch 3476, Loss: 0.0005555159073082905, Final Batch Loss: 2.4719770408410113e-06\n",
      "Epoch 3477, Loss: 0.025575356819899753, Final Batch Loss: 0.0004344490880612284\n",
      "Epoch 3478, Loss: 0.015221133654449659, Final Batch Loss: 1.1072786037402693e-05\n",
      "Epoch 3479, Loss: 0.0013130154220561963, Final Batch Loss: 3.601111166062765e-05\n",
      "Epoch 3480, Loss: 0.0011393636450520717, Final Batch Loss: 8.293831342598423e-05\n",
      "Epoch 3481, Loss: 0.0008110219932859764, Final Batch Loss: 0.0002612606331240386\n",
      "Epoch 3482, Loss: 0.04518463082786184, Final Batch Loss: 0.030424529686570168\n",
      "Epoch 3483, Loss: 0.00014456863792133845, Final Batch Loss: 2.948858366380591e-07\n",
      "Epoch 3484, Loss: 0.017475948203355074, Final Batch Loss: 0.005043820943683386\n",
      "Epoch 3485, Loss: 0.03241709899157286, Final Batch Loss: 0.0034112208522856236\n",
      "Epoch 3486, Loss: 0.004309879244829062, Final Batch Loss: 6.270918674999848e-05\n",
      "Epoch 3487, Loss: 0.009489574207691476, Final Batch Loss: 0.0001754021504893899\n",
      "Epoch 3488, Loss: 0.09644894674420357, Final Batch Loss: 0.0002786107361316681\n",
      "Epoch 3489, Loss: 0.0063582104969555076, Final Batch Loss: 1.8194889435108053e-06\n",
      "Epoch 3490, Loss: 0.0014515829243464395, Final Batch Loss: 0.00017096572264563292\n",
      "Epoch 3491, Loss: 0.0031404271583141963, Final Batch Loss: 2.1959428977424977e-06\n",
      "Epoch 3492, Loss: 0.5009985236974899, Final Batch Loss: 0.48518452048301697\n",
      "Epoch 3493, Loss: 0.001065637888132187, Final Batch Loss: 6.06693447480211e-06\n",
      "Epoch 3494, Loss: 0.004972098054736307, Final Batch Loss: 1.1858152220156626e-06\n",
      "Epoch 3495, Loss: 0.07053550472483039, Final Batch Loss: 0.05509722977876663\n",
      "Epoch 3496, Loss: 0.002784797099593561, Final Batch Loss: 6.593774742214009e-05\n",
      "Epoch 3497, Loss: 0.06430759141221642, Final Batch Loss: 0.0002854880876839161\n",
      "Epoch 3498, Loss: 0.09030192031059414, Final Batch Loss: 0.0019047415116801858\n",
      "Epoch 3499, Loss: 0.015985985577572137, Final Batch Loss: 8.179183350875974e-05\n",
      "Epoch 3500, Loss: 0.00459239594056271, Final Batch Loss: 0.003737835446372628\n",
      "Epoch 3501, Loss: 0.0069059822362760315, Final Batch Loss: 1.5269348295987584e-05\n",
      "Epoch 3502, Loss: 0.0031064219929248793, Final Batch Loss: 8.137225449900143e-06\n",
      "Epoch 3503, Loss: 0.0410825646831654, Final Batch Loss: 0.00015330681344494224\n",
      "Epoch 3504, Loss: 0.010565272626990918, Final Batch Loss: 4.354553675511852e-05\n",
      "Epoch 3505, Loss: 0.022011626409948803, Final Batch Loss: 0.00023648970818612725\n",
      "Epoch 3506, Loss: 0.0032261253691103775, Final Batch Loss: 5.928977770963684e-06\n",
      "Epoch 3507, Loss: 0.004468369632377289, Final Batch Loss: 7.547238783445209e-05\n",
      "Epoch 3508, Loss: 0.015929717045764846, Final Batch Loss: 9.43586837820476e-06\n",
      "Epoch 3509, Loss: 0.018408051706501283, Final Batch Loss: 0.00012356082152109593\n",
      "Epoch 3510, Loss: 0.0035998874809592962, Final Batch Loss: 0.0003339577524457127\n",
      "Epoch 3511, Loss: 0.00088752199371811, Final Batch Loss: 3.527062654029578e-05\n",
      "Epoch 3512, Loss: 0.020622623214876512, Final Batch Loss: 5.1371815061429515e-05\n",
      "Epoch 3513, Loss: 0.0031626067366232746, Final Batch Loss: 6.1423061197274365e-06\n",
      "Epoch 3514, Loss: 0.0018738506187219173, Final Batch Loss: 0.00026418219204060733\n",
      "Epoch 3515, Loss: 0.0023340795769399847, Final Batch Loss: 1.30805301523651e-05\n",
      "Epoch 3516, Loss: 0.0025897989892200712, Final Batch Loss: 2.5598476440791273e-06\n",
      "Epoch 3517, Loss: 0.0021363417617976665, Final Batch Loss: 0.001297765295021236\n",
      "Epoch 3518, Loss: 0.027675223827827722, Final Batch Loss: 0.0007041467470116913\n",
      "Epoch 3519, Loss: 0.0028397513669915497, Final Batch Loss: 0.0015272080199792981\n",
      "Epoch 3520, Loss: 0.005773327487986535, Final Batch Loss: 0.0017547454917803407\n",
      "Epoch 3521, Loss: 0.0016131622105604038, Final Batch Loss: 0.00018450924835633487\n",
      "Epoch 3522, Loss: 0.009136966574260441, Final Batch Loss: 5.420791239885148e-06\n",
      "Epoch 3523, Loss: 0.0014497348020086065, Final Batch Loss: 7.309444481506944e-05\n",
      "Epoch 3524, Loss: 0.01485485229659389, Final Batch Loss: 1.4191679838404525e-05\n",
      "Epoch 3525, Loss: 0.009583576320437714, Final Batch Loss: 3.171866410411894e-05\n",
      "Epoch 3526, Loss: 0.014418056525755674, Final Batch Loss: 0.011157581582665443\n",
      "Epoch 3527, Loss: 0.0009535558710922487, Final Batch Loss: 1.216462260344997e-05\n",
      "Epoch 3528, Loss: 0.010972686621244065, Final Batch Loss: 0.00012409807823132724\n",
      "Epoch 3529, Loss: 0.0012032624198354824, Final Batch Loss: 7.152538046284462e-07\n",
      "Epoch 3530, Loss: 0.006847837872555829, Final Batch Loss: 2.586078153399285e-05\n",
      "Epoch 3531, Loss: 0.0012156948068877682, Final Batch Loss: 6.977205339353532e-05\n",
      "Epoch 3532, Loss: 0.001251670444617048, Final Batch Loss: 0.00038854219019412994\n",
      "Epoch 3533, Loss: 0.0010532517728734092, Final Batch Loss: 2.9174655082897516e-06\n",
      "Epoch 3534, Loss: 0.001424795889761299, Final Batch Loss: 0.000716554292012006\n",
      "Epoch 3535, Loss: 0.012103133834898472, Final Batch Loss: 0.00018121174070984125\n",
      "Epoch 3536, Loss: 0.0012581706105265766, Final Batch Loss: 0.00018991719116456807\n",
      "Epoch 3537, Loss: 0.002071150840492919, Final Batch Loss: 0.0003868949424941093\n",
      "Epoch 3538, Loss: 0.0012010605933028273, Final Batch Loss: 7.594183989567682e-05\n",
      "Epoch 3539, Loss: 0.00454432622063905, Final Batch Loss: 0.002108590677380562\n",
      "Epoch 3540, Loss: 0.0016290181229123846, Final Batch Loss: 6.719703378621489e-05\n",
      "Epoch 3541, Loss: 0.0025334053207188845, Final Batch Loss: 0.0003905337071046233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3542, Loss: 0.002348363836063072, Final Batch Loss: 0.0001687433396000415\n",
      "Epoch 3543, Loss: 0.005935942324867938, Final Batch Loss: 0.00311836414039135\n",
      "Epoch 3544, Loss: 0.00590247720174375, Final Batch Loss: 3.118639506283216e-05\n",
      "Epoch 3545, Loss: 0.004207594072795473, Final Batch Loss: 0.003064156509935856\n",
      "Epoch 3546, Loss: 0.0018127360963262618, Final Batch Loss: 0.0006782259442843497\n",
      "Epoch 3547, Loss: 0.0013689909246750176, Final Batch Loss: 0.0003084483905695379\n",
      "Epoch 3548, Loss: 0.002057261415757239, Final Batch Loss: 0.0005652881227433681\n",
      "Epoch 3549, Loss: 0.002095701696816832, Final Batch Loss: 0.0009940933668985963\n",
      "Epoch 3550, Loss: 0.0013568220783781726, Final Batch Loss: 5.795578545075841e-05\n",
      "Epoch 3551, Loss: 0.019177182955900207, Final Batch Loss: 9.330920875072479e-05\n",
      "Epoch 3552, Loss: 0.0011709878453984857, Final Batch Loss: 0.00038098724326118827\n",
      "Epoch 3553, Loss: 0.001492603787482949, Final Batch Loss: 5.6244887673528865e-05\n",
      "Epoch 3554, Loss: 0.0021317671635188162, Final Batch Loss: 0.00021584396017715335\n",
      "Epoch 3555, Loss: 0.02372246038794401, Final Batch Loss: 5.1878403610317037e-05\n",
      "Epoch 3556, Loss: 0.0011000551021425053, Final Batch Loss: 0.000445784127805382\n",
      "Epoch 3557, Loss: 0.0009319451201008633, Final Batch Loss: 0.00022687956516165286\n",
      "Epoch 3558, Loss: 0.0013043874114373466, Final Batch Loss: 2.0615412722690962e-05\n",
      "Epoch 3559, Loss: 0.0015785902432980947, Final Batch Loss: 0.00010593097977107391\n",
      "Epoch 3560, Loss: 0.0012376656231936067, Final Batch Loss: 0.0007349490188062191\n",
      "Epoch 3561, Loss: 0.0020002731689601205, Final Batch Loss: 3.56006421498023e-05\n",
      "Epoch 3562, Loss: 0.003811429319284798, Final Batch Loss: 7.835921678633895e-06\n",
      "Epoch 3563, Loss: 0.0011192239908268675, Final Batch Loss: 0.00042750214925035834\n",
      "Epoch 3564, Loss: 0.0015089128064573742, Final Batch Loss: 0.0006755948415957391\n",
      "Epoch 3565, Loss: 0.02402235200861469, Final Batch Loss: 0.022237757220864296\n",
      "Epoch 3566, Loss: 0.0013330509668776358, Final Batch Loss: 1.4932434169168118e-06\n",
      "Epoch 3567, Loss: 0.0013238966894277837, Final Batch Loss: 3.378820474608801e-05\n",
      "Epoch 3568, Loss: 0.0009295541676692665, Final Batch Loss: 2.3222077288664877e-05\n",
      "Epoch 3569, Loss: 0.0007989157389829415, Final Batch Loss: 4.2036901959363604e-07\n",
      "Epoch 3570, Loss: 0.0005159957545401994, Final Batch Loss: 5.5503554904134944e-05\n",
      "Epoch 3571, Loss: 0.004978724296961445, Final Batch Loss: 7.268548506544903e-05\n",
      "Epoch 3572, Loss: 0.012283672404009849, Final Batch Loss: 0.0007772680255584419\n",
      "Epoch 3573, Loss: 0.003076878609135747, Final Batch Loss: 0.0017025892157107592\n",
      "Epoch 3574, Loss: 0.008849188263411634, Final Batch Loss: 0.00021733353787567466\n",
      "Epoch 3575, Loss: 0.0016789710789453238, Final Batch Loss: 0.00081455591134727\n",
      "Epoch 3576, Loss: 0.0006823901567258872, Final Batch Loss: 0.0004786707868333906\n",
      "Epoch 3577, Loss: 0.0017395062241121195, Final Batch Loss: 0.00010396115976618603\n",
      "Epoch 3578, Loss: 0.0007911354696261697, Final Batch Loss: 7.201197877293453e-05\n",
      "Epoch 3579, Loss: 0.004540123292827047, Final Batch Loss: 0.0026528481394052505\n",
      "Epoch 3580, Loss: 0.003202919673640281, Final Batch Loss: 0.002277996391057968\n",
      "Epoch 3581, Loss: 0.0025178704454447143, Final Batch Loss: 0.0020376676693558693\n",
      "Epoch 3582, Loss: 0.0013505601091310382, Final Batch Loss: 0.0003539321187417954\n",
      "Epoch 3583, Loss: 0.0015177874884102494, Final Batch Loss: 0.00028366074548102915\n",
      "Epoch 3584, Loss: 0.001933980209287256, Final Batch Loss: 0.0006924244808033109\n",
      "Epoch 3585, Loss: 0.0009127749362960458, Final Batch Loss: 0.00024442546418868005\n",
      "Epoch 3586, Loss: 0.0005648211954394355, Final Batch Loss: 4.321019514463842e-05\n",
      "Epoch 3587, Loss: 0.0006418258255962428, Final Batch Loss: 2.1018188363086665e-06\n",
      "Epoch 3588, Loss: 0.0007199468673206866, Final Batch Loss: 0.0002417991345282644\n",
      "Epoch 3589, Loss: 0.0012604293406184297, Final Batch Loss: 3.1751824280945584e-05\n",
      "Epoch 3590, Loss: 0.0016034699510782957, Final Batch Loss: 0.00026242213789373636\n",
      "Epoch 3591, Loss: 0.0010355555950809503, Final Batch Loss: 1.3519495041691698e-05\n",
      "Epoch 3592, Loss: 0.0006791772227501269, Final Batch Loss: 2.1332174071631016e-07\n",
      "Epoch 3593, Loss: 0.001319785718806088, Final Batch Loss: 8.824490942060947e-05\n",
      "Epoch 3594, Loss: 0.0010050644632428885, Final Batch Loss: 3.570168337319046e-05\n",
      "Epoch 3595, Loss: 0.006258444284867437, Final Batch Loss: 1.4134659977571573e-05\n",
      "Epoch 3596, Loss: 0.0012832850757149572, Final Batch Loss: 6.380591457855189e-06\n",
      "Epoch 3597, Loss: 0.0013358897413127124, Final Batch Loss: 0.0004300060390960425\n",
      "Epoch 3598, Loss: 0.0009071361273527145, Final Batch Loss: 6.142130587249994e-06\n",
      "Epoch 3599, Loss: 0.008861904556397349, Final Batch Loss: 0.001275923801586032\n",
      "Epoch 3600, Loss: 0.0007467885006917641, Final Batch Loss: 8.738988253753632e-05\n",
      "Epoch 3601, Loss: 0.0009966450306819752, Final Batch Loss: 7.99719273345545e-05\n",
      "Epoch 3602, Loss: 0.0006609370466321707, Final Batch Loss: 5.1123875891789794e-05\n",
      "Epoch 3603, Loss: 0.0005017772564315237, Final Batch Loss: 8.089982293313369e-05\n",
      "Epoch 3604, Loss: 0.001015976727103407, Final Batch Loss: 1.4988400835136417e-05\n",
      "Epoch 3605, Loss: 0.009168297343421727, Final Batch Loss: 3.0639057513326406e-05\n",
      "Epoch 3606, Loss: 0.0014530032240145374, Final Batch Loss: 5.355113898986019e-05\n",
      "Epoch 3607, Loss: 0.0008659440281917341, Final Batch Loss: 6.762214616173878e-05\n",
      "Epoch 3608, Loss: 0.0020241223164703115, Final Batch Loss: 9.517511898593511e-06\n",
      "Epoch 3609, Loss: 0.00069099793836358, Final Batch Loss: 2.4335440684808418e-05\n",
      "Epoch 3610, Loss: 0.0007239794257429821, Final Batch Loss: 1.8195031543655205e-06\n",
      "Epoch 3611, Loss: 0.007291810768947471, Final Batch Loss: 0.0016305831959471107\n",
      "Epoch 3612, Loss: 0.0070332678442355245, Final Batch Loss: 0.0047644381411373615\n",
      "Epoch 3613, Loss: 0.0005818370709675946, Final Batch Loss: 1.4561767784471158e-05\n",
      "Epoch 3614, Loss: 0.006560111447470263, Final Batch Loss: 0.00037297344533726573\n",
      "Epoch 3615, Loss: 0.0005956566333225055, Final Batch Loss: 4.692951279139379e-06\n",
      "Epoch 3616, Loss: 0.001444873312721029, Final Batch Loss: 0.00015761193935759366\n",
      "Epoch 3617, Loss: 0.000840925127704395, Final Batch Loss: 1.0828222002601251e-05\n",
      "Epoch 3618, Loss: 0.0029070204764138907, Final Batch Loss: 0.0018809620523825288\n",
      "Epoch 3619, Loss: 0.002473950633429922, Final Batch Loss: 0.0014189854264259338\n",
      "Epoch 3620, Loss: 0.0006595520508199115, Final Batch Loss: 1.0590444617264438e-05\n",
      "Epoch 3621, Loss: 0.003846261637590942, Final Batch Loss: 2.12035247386666e-05\n",
      "Epoch 3622, Loss: 0.000760491335313418, Final Batch Loss: 1.5201492715277709e-05\n",
      "Epoch 3623, Loss: 0.0022136499464977533, Final Batch Loss: 0.0008663808694109321\n",
      "Epoch 3624, Loss: 0.010264534590533003, Final Batch Loss: 0.0011823084205389023\n",
      "Epoch 3625, Loss: 0.0009356655718875118, Final Batch Loss: 7.154161721700802e-05\n",
      "Epoch 3626, Loss: 0.0015043199600768276, Final Batch Loss: 6.729819142492488e-05\n",
      "Epoch 3627, Loss: 0.0005313016326908837, Final Batch Loss: 1.4811640539846849e-05\n",
      "Epoch 3628, Loss: 0.0009656814218033105, Final Batch Loss: 0.00014116802776698023\n",
      "Epoch 3629, Loss: 0.001720772939734161, Final Batch Loss: 4.211688064970076e-05\n",
      "Epoch 3630, Loss: 0.0010362567954871338, Final Batch Loss: 3.5318993468536064e-05\n",
      "Epoch 3631, Loss: 0.0010875720499825547, Final Batch Loss: 8.450911082036328e-06\n",
      "Epoch 3632, Loss: 0.00046993926025606925, Final Batch Loss: 2.6539501050137915e-06\n",
      "Epoch 3633, Loss: 0.0014745948187737667, Final Batch Loss: 4.793304015038302e-06\n",
      "Epoch 3634, Loss: 0.00036075265597901307, Final Batch Loss: 3.214198295609094e-05\n",
      "Epoch 3635, Loss: 0.000599739625613438, Final Batch Loss: 4.99178895552177e-05\n",
      "Epoch 3636, Loss: 0.0020632392224797513, Final Batch Loss: 4.061020081280731e-05\n",
      "Epoch 3637, Loss: 0.0006091402028687298, Final Batch Loss: 7.573557377327234e-05\n",
      "Epoch 3638, Loss: 0.0014239892843761481, Final Batch Loss: 0.00045581089216284454\n",
      "Epoch 3639, Loss: 0.0004692537695518695, Final Batch Loss: 0.00014903028204571456\n",
      "Epoch 3640, Loss: 0.0009464796939937514, Final Batch Loss: 8.588996024627704e-06\n",
      "Epoch 3641, Loss: 0.0003331588304718025, Final Batch Loss: 9.949373634299263e-05\n",
      "Epoch 3642, Loss: 0.0003587697492548614, Final Batch Loss: 1.2076888197043445e-05\n",
      "Epoch 3643, Loss: 0.0012846819590777159, Final Batch Loss: 0.00044255724060349166\n",
      "Epoch 3644, Loss: 0.0005166305636521429, Final Batch Loss: 0.00017688750813249499\n",
      "Epoch 3645, Loss: 0.002703850739635527, Final Batch Loss: 0.0003036152629647404\n",
      "Epoch 3646, Loss: 0.0007635205547558144, Final Batch Loss: 0.00015751566388644278\n",
      "Epoch 3647, Loss: 0.001085417321235127, Final Batch Loss: 2.1332169808374601e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3648, Loss: 0.0013675849186256528, Final Batch Loss: 0.00028897100128233433\n",
      "Epoch 3649, Loss: 0.0005283486598273157, Final Batch Loss: 5.20113007951295e-06\n",
      "Epoch 3650, Loss: 0.0006763977071386762, Final Batch Loss: 0.0003341898263897747\n",
      "Epoch 3651, Loss: 0.0022205763671081513, Final Batch Loss: 0.001516025047749281\n",
      "Epoch 3652, Loss: 0.0005631370504488586, Final Batch Loss: 1.337525372946402e-05\n",
      "Epoch 3653, Loss: 0.0009138297391473316, Final Batch Loss: 6.729760934831575e-05\n",
      "Epoch 3654, Loss: 0.0007223940128824324, Final Batch Loss: 4.1910470827133395e-06\n",
      "Epoch 3655, Loss: 0.00041339104359394696, Final Batch Loss: 1.3928540738561423e-06\n",
      "Epoch 3656, Loss: 0.0005130402023496572, Final Batch Loss: 4.378542143967934e-05\n",
      "Epoch 3657, Loss: 0.001679302571574226, Final Batch Loss: 4.1116116335615516e-05\n",
      "Epoch 3658, Loss: 0.002160030315280892, Final Batch Loss: 0.0015760875539854169\n",
      "Epoch 3659, Loss: 0.0008859998270054348, Final Batch Loss: 8.841591625241563e-05\n",
      "Epoch 3660, Loss: 0.01119708926853491, Final Batch Loss: 0.00011851524322992191\n",
      "Epoch 3661, Loss: 0.005587028550507966, Final Batch Loss: 8.446278661722317e-05\n",
      "Epoch 3662, Loss: 0.009362405740830582, Final Batch Loss: 2.3756489099469036e-05\n",
      "Epoch 3663, Loss: 0.001802332182705868, Final Batch Loss: 0.0007064546225592494\n",
      "Epoch 3664, Loss: 0.0012097234575776383, Final Batch Loss: 0.0006342394044622779\n",
      "Epoch 3665, Loss: 0.00040294905738846865, Final Batch Loss: 1.2761132893501781e-05\n",
      "Epoch 3666, Loss: 0.0012677029008045793, Final Batch Loss: 0.00023592886282131076\n",
      "Epoch 3667, Loss: 0.0008751783407205949, Final Batch Loss: 1.9455148503766395e-05\n",
      "Epoch 3668, Loss: 0.000347361623425968, Final Batch Loss: 2.699849574128166e-05\n",
      "Epoch 3669, Loss: 0.007771388627588749, Final Batch Loss: 0.0010649434989318252\n",
      "Epoch 3670, Loss: 0.0013271210773382336, Final Batch Loss: 0.0001225522137247026\n",
      "Epoch 3671, Loss: 0.0017235764826182276, Final Batch Loss: 0.0011820463696494699\n",
      "Epoch 3672, Loss: 0.0011546227251528762, Final Batch Loss: 5.223880725679919e-05\n",
      "Epoch 3673, Loss: 0.0029757958254776895, Final Batch Loss: 5.6871474953368306e-05\n",
      "Epoch 3674, Loss: 0.0019599921755570904, Final Batch Loss: 1.1795376622103504e-06\n",
      "Epoch 3675, Loss: 0.0012983620981685817, Final Batch Loss: 0.00019562151283025742\n",
      "Epoch 3676, Loss: 0.0017652650028594508, Final Batch Loss: 3.7205506941973e-06\n",
      "Epoch 3677, Loss: 0.006020185093802866, Final Batch Loss: 0.005489268805831671\n",
      "Epoch 3678, Loss: 0.0008914742866181768, Final Batch Loss: 0.00037125987000763416\n",
      "Epoch 3679, Loss: 0.0006367146888806019, Final Batch Loss: 2.0257230062270537e-05\n",
      "Epoch 3680, Loss: 0.00037577180773951113, Final Batch Loss: 7.121833914425224e-05\n",
      "Epoch 3681, Loss: 0.0008569779747631401, Final Batch Loss: 9.917205898091197e-05\n",
      "Epoch 3682, Loss: 0.00039175489655463025, Final Batch Loss: 1.9836770661640912e-05\n",
      "Epoch 3683, Loss: 0.0007370069579337724, Final Batch Loss: 0.00050046865362674\n",
      "Epoch 3684, Loss: 0.00040395677206106484, Final Batch Loss: 0.00020599058188963681\n",
      "Epoch 3685, Loss: 0.00789346790043055, Final Batch Loss: 2.6723599148681387e-05\n",
      "Epoch 3686, Loss: 0.0027087528142146766, Final Batch Loss: 0.00018907961202785373\n",
      "Epoch 3687, Loss: 0.007594756406433589, Final Batch Loss: 1.4642925634689163e-05\n",
      "Epoch 3688, Loss: 0.0006924718991285772, Final Batch Loss: 1.079149114957545e-06\n",
      "Epoch 3689, Loss: 0.0009616744009690592, Final Batch Loss: 2.6926218197331764e-05\n",
      "Epoch 3690, Loss: 0.0005860370292793959, Final Batch Loss: 0.00040959319449029863\n",
      "Epoch 3691, Loss: 0.0004472420637284813, Final Batch Loss: 6.913987363077467e-06\n",
      "Epoch 3692, Loss: 0.0006207582337083295, Final Batch Loss: 0.00021623172506224364\n",
      "Epoch 3693, Loss: 0.000952287536165386, Final Batch Loss: 1.9449680621619336e-06\n",
      "Epoch 3694, Loss: 0.0009754734492162243, Final Batch Loss: 0.0002253905840916559\n",
      "Epoch 3695, Loss: 0.000651708408668128, Final Batch Loss: 8.40734401208465e-07\n",
      "Epoch 3696, Loss: 0.0004215885201119818, Final Batch Loss: 1.6423997294623405e-05\n",
      "Epoch 3697, Loss: 0.00042699168534454657, Final Batch Loss: 1.9951721696997993e-06\n",
      "Epoch 3698, Loss: 0.0005622378957923502, Final Batch Loss: 7.9492645454593e-05\n",
      "Epoch 3699, Loss: 0.0007179275053204037, Final Batch Loss: 8.267425437225029e-05\n",
      "Epoch 3700, Loss: 0.009525099434540607, Final Batch Loss: 0.002272401936352253\n",
      "Epoch 3701, Loss: 0.0010592074831947684, Final Batch Loss: 0.0001772261457517743\n",
      "Epoch 3702, Loss: 0.000430707861596602, Final Batch Loss: 1.2936767234350555e-05\n",
      "Epoch 3703, Loss: 0.0009234486060449854, Final Batch Loss: 0.00045121338916942477\n",
      "Epoch 3704, Loss: 0.0005247976012014988, Final Batch Loss: 2.7166468044015346e-06\n",
      "Epoch 3705, Loss: 0.00043510574414540315, Final Batch Loss: 1.010729556583101e-05\n",
      "Epoch 3706, Loss: 0.0002861372322513489, Final Batch Loss: 1.810544745239895e-05\n",
      "Epoch 3707, Loss: 0.0018535917115514167, Final Batch Loss: 0.0015997928567230701\n",
      "Epoch 3708, Loss: 0.0013758748245891184, Final Batch Loss: 9.630780550651252e-05\n",
      "Epoch 3709, Loss: 0.00308053387561813, Final Batch Loss: 0.002689145039767027\n",
      "Epoch 3710, Loss: 0.0011460227906354703, Final Batch Loss: 9.565010986989364e-05\n",
      "Epoch 3711, Loss: 0.0015106177743291482, Final Batch Loss: 0.001158269471488893\n",
      "Epoch 3712, Loss: 0.00025748410121195775, Final Batch Loss: 3.149568556182203e-06\n",
      "Epoch 3713, Loss: 0.0010144964689970948, Final Batch Loss: 6.49174689897336e-05\n",
      "Epoch 3714, Loss: 0.0006582950445590541, Final Batch Loss: 0.00020507602312136441\n",
      "Epoch 3715, Loss: 0.0002092366285069147, Final Batch Loss: 2.5576091502443887e-05\n",
      "Epoch 3716, Loss: 0.00018789641035255045, Final Batch Loss: 2.0149891497567296e-05\n",
      "Epoch 3717, Loss: 0.04409704427962424, Final Batch Loss: 7.638066745130345e-05\n",
      "Epoch 3718, Loss: 0.0005417791871877853, Final Batch Loss: 0.0003626218531280756\n",
      "Epoch 3719, Loss: 0.00016327268622262636, Final Batch Loss: 1.4316546185000334e-05\n",
      "Epoch 3720, Loss: 0.0013558627133534173, Final Batch Loss: 1.2678708117164206e-05\n",
      "Epoch 3721, Loss: 0.0004889169867965393, Final Batch Loss: 4.986019484931603e-05\n",
      "Epoch 3722, Loss: 0.0005258719979792659, Final Batch Loss: 2.27121245188755e-06\n",
      "Epoch 3723, Loss: 0.00022918037575436756, Final Batch Loss: 1.259789860341698e-05\n",
      "Epoch 3724, Loss: 0.0005588788690147339, Final Batch Loss: 1.0025461051554885e-05\n",
      "Epoch 3725, Loss: 0.0022899940740899183, Final Batch Loss: 0.0003200883511453867\n",
      "Epoch 3726, Loss: 0.001514355522886035, Final Batch Loss: 1.7709027815726586e-05\n",
      "Epoch 3727, Loss: 0.00037711462209699675, Final Batch Loss: 0.00011748977703973651\n",
      "Epoch 3728, Loss: 0.0016073503938969225, Final Batch Loss: 0.00016768486239016056\n",
      "Epoch 3729, Loss: 0.00020179450075374916, Final Batch Loss: 9.780097025213763e-05\n",
      "Epoch 3730, Loss: 0.0012727934372378513, Final Batch Loss: 0.00035749454400502145\n",
      "Epoch 3731, Loss: 0.00043623334204312414, Final Batch Loss: 0.0001252262736670673\n",
      "Epoch 3732, Loss: 0.0007645258447155356, Final Batch Loss: 0.0003334613284096122\n",
      "Epoch 3733, Loss: 0.0004678537297877483, Final Batch Loss: 2.23715505853761e-05\n",
      "Epoch 3734, Loss: 0.00050057554472005, Final Batch Loss: 7.611067121615633e-05\n",
      "Epoch 3735, Loss: 0.0005594793574346113, Final Batch Loss: 1.113580492528854e-05\n",
      "Epoch 3736, Loss: 0.00020553269132506102, Final Batch Loss: 4.198801616439596e-05\n",
      "Epoch 3737, Loss: 0.0004674875285672897, Final Batch Loss: 2.2586805243918207e-06\n",
      "Epoch 3738, Loss: 0.00017181402409960356, Final Batch Loss: 2.8233745297256974e-07\n",
      "Epoch 3739, Loss: 0.00027232950742472894, Final Batch Loss: 5.898041490581818e-05\n",
      "Epoch 3740, Loss: 0.0005604613106697798, Final Batch Loss: 0.0001366245560348034\n",
      "Epoch 3741, Loss: 0.0018046013283310458, Final Batch Loss: 0.001261927536688745\n",
      "Epoch 3742, Loss: 0.0004895957790722605, Final Batch Loss: 4.976117634214461e-05\n",
      "Epoch 3743, Loss: 0.00015957704817992635, Final Batch Loss: 2.385549305472523e-05\n",
      "Epoch 3744, Loss: 0.00023186577459455293, Final Batch Loss: 2.0265390503482195e-06\n",
      "Epoch 3745, Loss: 0.0010497608684545412, Final Batch Loss: 2.791953420455684e-06\n",
      "Epoch 3746, Loss: 0.0004651061462936923, Final Batch Loss: 9.479903383180499e-06\n",
      "Epoch 3747, Loss: 0.0010178649713452614, Final Batch Loss: 6.938996648386819e-06\n",
      "Epoch 3748, Loss: 0.00015554432502540294, Final Batch Loss: 2.2055819499655627e-05\n",
      "Epoch 3749, Loss: 0.0006183227524161339, Final Batch Loss: 0.0001818829623516649\n",
      "Epoch 3750, Loss: 0.0014486033178400248, Final Batch Loss: 0.0008402446983382106\n",
      "Epoch 3751, Loss: 0.001507892786321463, Final Batch Loss: 2.5282341084675863e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3752, Loss: 0.001398079220962245, Final Batch Loss: 3.2089279557112604e-05\n",
      "Epoch 3753, Loss: 0.0005752740544266999, Final Batch Loss: 0.00027273892192170024\n",
      "Epoch 3754, Loss: 0.0016210784815484658, Final Batch Loss: 0.001283142832107842\n",
      "Epoch 3755, Loss: 0.0016719019477022812, Final Batch Loss: 0.000339516467647627\n",
      "Epoch 3756, Loss: 0.00017034383495229122, Final Batch Loss: 3.701697323776898e-06\n",
      "Epoch 3757, Loss: 0.00026612839420181444, Final Batch Loss: 4.2036836589431914e-07\n",
      "Epoch 3758, Loss: 0.001168017159216106, Final Batch Loss: 0.0002825008996296674\n",
      "Epoch 3759, Loss: 0.00022345031175063923, Final Batch Loss: 7.039756019366905e-05\n",
      "Epoch 3760, Loss: 0.00557943491730839, Final Batch Loss: 0.0004813878913410008\n",
      "Epoch 3761, Loss: 0.0002979038649755239, Final Batch Loss: 4.830911620956613e-06\n",
      "Epoch 3762, Loss: 0.0004537143955190004, Final Batch Loss: 5.144807460055745e-07\n",
      "Epoch 3763, Loss: 0.00039233032987340266, Final Batch Loss: 1.2485539855333627e-06\n",
      "Epoch 3764, Loss: 0.00024412991479039192, Final Batch Loss: 3.074089181609452e-05\n",
      "Epoch 3765, Loss: 0.0036145084886811674, Final Batch Loss: 7.092002488207072e-05\n",
      "Epoch 3766, Loss: 0.00021817866553419663, Final Batch Loss: 8.846542982610117e-07\n",
      "Epoch 3767, Loss: 0.000492229824885726, Final Batch Loss: 4.613418423105031e-05\n",
      "Epoch 3768, Loss: 0.0005358367728831581, Final Batch Loss: 1.2485564866437926e-06\n",
      "Epoch 3769, Loss: 0.0017686553546809591, Final Batch Loss: 0.000741691910661757\n",
      "Epoch 3770, Loss: 0.002218885422735184, Final Batch Loss: 8.40089614939643e-06\n",
      "Epoch 3771, Loss: 0.0004903337940049823, Final Batch Loss: 4.523575626080856e-06\n",
      "Epoch 3772, Loss: 0.00027843799034599215, Final Batch Loss: 3.104055213043466e-05\n",
      "Epoch 3773, Loss: 0.003945248938634904, Final Batch Loss: 1.2297336979827378e-06\n",
      "Epoch 3774, Loss: 0.0003915607485396322, Final Batch Loss: 0.0001091529629775323\n",
      "Epoch 3775, Loss: 0.0005905337238800712, Final Batch Loss: 6.642236985499039e-05\n",
      "Epoch 3776, Loss: 0.0005860679048055317, Final Batch Loss: 0.00014609839126933366\n",
      "Epoch 3777, Loss: 0.0009801587889342045, Final Batch Loss: 3.97778194383136e-06\n",
      "Epoch 3778, Loss: 9.983667132473784e-05, Final Batch Loss: 1.8194814401795156e-06\n",
      "Epoch 3779, Loss: 0.00015959226493578171, Final Batch Loss: 7.848752829886507e-06\n",
      "Epoch 3780, Loss: 0.0005319171750670648, Final Batch Loss: 1.3262454558571335e-05\n",
      "Epoch 3781, Loss: 0.0003459470933648845, Final Batch Loss: 3.2625209769321373e-06\n",
      "Epoch 3782, Loss: 0.0011529525481819292, Final Batch Loss: 8.030704520933796e-06\n",
      "Epoch 3783, Loss: 0.0005172121263967711, Final Batch Loss: 5.339056770026218e-06\n",
      "Epoch 3784, Loss: 0.00047578832163708284, Final Batch Loss: 0.00035550768370740116\n",
      "Epoch 3785, Loss: 0.009457341118832119, Final Batch Loss: 0.00028758528060279787\n",
      "Epoch 3786, Loss: 0.0007785129778312694, Final Batch Loss: 1.0352300705562811e-06\n",
      "Epoch 3787, Loss: 0.00033832580677994883, Final Batch Loss: 3.450791439263412e-07\n",
      "Epoch 3788, Loss: 0.000356615657437942, Final Batch Loss: 1.914610584208276e-05\n",
      "Epoch 3789, Loss: 0.005162883106095251, Final Batch Loss: 8.018185326363891e-06\n",
      "Epoch 3790, Loss: 0.0003629314674071793, Final Batch Loss: 3.306406597403111e-06\n",
      "Epoch 3791, Loss: 0.0006728029675286962, Final Batch Loss: 0.00039627018850296736\n",
      "Epoch 3792, Loss: 0.0006522145340568386, Final Batch Loss: 2.707506064325571e-05\n",
      "Epoch 3793, Loss: 0.0011385145990061574, Final Batch Loss: 0.0008826726116240025\n",
      "Epoch 3794, Loss: 0.0023201999720185995, Final Batch Loss: 0.000540821987669915\n",
      "Epoch 3795, Loss: 7.568856199213769e-05, Final Batch Loss: 2.810787918861024e-06\n",
      "Epoch 3796, Loss: 0.00045408916048472747, Final Batch Loss: 6.109485548222438e-05\n",
      "Epoch 3797, Loss: 0.0009883681632345542, Final Batch Loss: 0.00045117383706383407\n",
      "Epoch 3798, Loss: 0.0009762988265720196, Final Batch Loss: 0.0007802403415553272\n",
      "Epoch 3799, Loss: 0.000650630396194174, Final Batch Loss: 2.6896972485701554e-05\n",
      "Epoch 3800, Loss: 0.00020423948406111947, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 3801, Loss: 0.00018928695595832323, Final Batch Loss: 8.658326464683341e-07\n",
      "Epoch 3802, Loss: 0.000815984254131763, Final Batch Loss: 3.4005347515631e-06\n",
      "Epoch 3803, Loss: 0.0003569595737644704, Final Batch Loss: 1.1424281183280982e-05\n",
      "Epoch 3804, Loss: 0.001329344231635332, Final Batch Loss: 0.0009306088904850185\n",
      "Epoch 3805, Loss: 0.0001794901884011324, Final Batch Loss: 4.3291694851177454e-07\n",
      "Epoch 3806, Loss: 0.0003467379283392802, Final Batch Loss: 0.00014224133337847888\n",
      "Epoch 3807, Loss: 0.00036385695784701966, Final Batch Loss: 0.00015180739865172654\n",
      "Epoch 3808, Loss: 9.291819560530712e-05, Final Batch Loss: 3.199737420800375e-06\n",
      "Epoch 3809, Loss: 0.0002937478402600391, Final Batch Loss: 2.696610135899391e-05\n",
      "Epoch 3810, Loss: 0.0019202091680199374, Final Batch Loss: 0.0017491005128249526\n",
      "Epoch 3811, Loss: 0.00014592953672831754, Final Batch Loss: 1.2548341032925237e-07\n",
      "Epoch 3812, Loss: 7.276795995636576e-05, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 3813, Loss: 0.0007366182976511482, Final Batch Loss: 4.266286396159558e-06\n",
      "Epoch 3814, Loss: 0.0004928428024868481, Final Batch Loss: 0.00011931869812542573\n",
      "Epoch 3815, Loss: 0.0012692352938756812, Final Batch Loss: 0.0010730685899034142\n",
      "Epoch 3816, Loss: 0.0005278640214783081, Final Batch Loss: 4.385515694593778e-06\n",
      "Epoch 3817, Loss: 0.0005616079805008667, Final Batch Loss: 8.15642238194414e-08\n",
      "Epoch 3818, Loss: 0.0014301100815146128, Final Batch Loss: 4.580139147947193e-07\n",
      "Epoch 3819, Loss: 0.0028864591138244577, Final Batch Loss: 1.6187248093046946e-06\n",
      "Epoch 3820, Loss: 0.003673177125165239, Final Batch Loss: 0.0028663547709584236\n",
      "Epoch 3821, Loss: 0.00025173890207952354, Final Batch Loss: 0.00015682802768424153\n",
      "Epoch 3822, Loss: 0.0007940287468954921, Final Batch Loss: 0.0001096776541089639\n",
      "Epoch 3823, Loss: 0.026062094169446937, Final Batch Loss: 3.7330678424041253e-06\n",
      "Epoch 3824, Loss: 0.0008863075054250658, Final Batch Loss: 3.55731463059783e-05\n",
      "Epoch 3825, Loss: 0.003375763146323152, Final Batch Loss: 0.0017104530707001686\n",
      "Epoch 3826, Loss: 0.0014350351193570532, Final Batch Loss: 0.0009834724478423595\n",
      "Epoch 3827, Loss: 0.00017594662313058507, Final Batch Loss: 1.6399435480707325e-05\n",
      "Epoch 3828, Loss: 0.00018351580001763068, Final Batch Loss: 7.72308703744784e-06\n",
      "Epoch 3829, Loss: 0.00018374056674019812, Final Batch Loss: 1.2360065966277034e-06\n",
      "Epoch 3830, Loss: 0.02768125728744053, Final Batch Loss: 2.6351290216553025e-06\n",
      "Epoch 3831, Loss: 0.00012163581970980886, Final Batch Loss: 8.093649057627772e-07\n",
      "Epoch 3832, Loss: 0.00018675505089049693, Final Batch Loss: 2.1879828636883758e-05\n",
      "Epoch 3833, Loss: 0.0004911671865670542, Final Batch Loss: 8.15642238194414e-08\n",
      "Epoch 3834, Loss: 0.0014935936051188037, Final Batch Loss: 3.678024222608656e-05\n",
      "Epoch 3835, Loss: 0.0005067363529178692, Final Batch Loss: 2.396700665485696e-06\n",
      "Epoch 3836, Loss: 0.0003136269424430793, Final Batch Loss: 1.7886171917780302e-05\n",
      "Epoch 3837, Loss: 0.00039626547368243337, Final Batch Loss: 2.9885079129599035e-05\n",
      "Epoch 3838, Loss: 0.0002827666903613135, Final Batch Loss: 6.844252493465319e-05\n",
      "Epoch 3839, Loss: 0.00038684655373799615, Final Batch Loss: 6.895533442730084e-05\n",
      "Epoch 3840, Loss: 0.029436908836942166, Final Batch Loss: 0.028470242395997047\n",
      "Epoch 3841, Loss: 0.00021717474510296597, Final Batch Loss: 6.273801318457117e-06\n",
      "Epoch 3842, Loss: 0.005280956822389271, Final Batch Loss: 4.416919909999706e-05\n",
      "Epoch 3843, Loss: 0.00018581839503895026, Final Batch Loss: 1.8549462765804492e-05\n",
      "Epoch 3844, Loss: 0.0004167237930232659, Final Batch Loss: 4.364387132227421e-05\n",
      "Epoch 3845, Loss: 0.000959593871158404, Final Batch Loss: 3.889975062065787e-07\n",
      "Epoch 3846, Loss: 0.046932146775361616, Final Batch Loss: 3.244548133807257e-05\n",
      "Epoch 3847, Loss: 0.01521435851464048, Final Batch Loss: 0.014662480913102627\n",
      "Epoch 3848, Loss: 0.00150309554010164, Final Batch Loss: 0.0012661898508667946\n",
      "Epoch 3849, Loss: 0.017926912936673034, Final Batch Loss: 0.01756611466407776\n",
      "Epoch 3850, Loss: 0.00020993645318867493, Final Batch Loss: 1.0226862059425912e-06\n",
      "Epoch 3851, Loss: 0.00229323794337688, Final Batch Loss: 6.358284008456394e-05\n",
      "Epoch 3852, Loss: 0.0033723578017088585, Final Batch Loss: 3.890338848577812e-05\n",
      "Epoch 3853, Loss: 0.024249944355688058, Final Batch Loss: 0.0006252516177482903\n",
      "Epoch 3854, Loss: 0.0012058489519404247, Final Batch Loss: 0.00019936000171583146\n",
      "Epoch 3855, Loss: 0.02150645200163126, Final Batch Loss: 0.0006835614331066608\n",
      "Epoch 3856, Loss: 0.002122144593158737, Final Batch Loss: 0.0006962923798710108\n",
      "Epoch 3857, Loss: 0.0034775350723066367, Final Batch Loss: 8.411588351009414e-05\n",
      "Epoch 3858, Loss: 0.0195537597968638, Final Batch Loss: 1.3803163767533988e-07\n",
      "Epoch 3859, Loss: 0.012204758118969039, Final Batch Loss: 2.6197378247161396e-05\n",
      "Epoch 3860, Loss: 0.001058241497958079, Final Batch Loss: 0.00015476872795261443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3861, Loss: 0.0023764230109009077, Final Batch Loss: 7.672785613976885e-06\n",
      "Epoch 3862, Loss: 0.002925578331542056, Final Batch Loss: 5.2262053031881806e-06\n",
      "Epoch 3863, Loss: 0.018203629180788994, Final Batch Loss: 0.00046440065489150584\n",
      "Epoch 3864, Loss: 0.0028855421337539156, Final Batch Loss: 5.703005172108533e-06\n",
      "Epoch 3865, Loss: 0.0003610146522987634, Final Batch Loss: 0.0001517402706667781\n",
      "Epoch 3866, Loss: 0.0017511396072222851, Final Batch Loss: 0.0015358419623225927\n",
      "Epoch 3867, Loss: 0.0002568266424987087, Final Batch Loss: 1.9826254629151663e-06\n",
      "Epoch 3868, Loss: 0.0001312406229772023, Final Batch Loss: 1.0101384759764187e-06\n",
      "Epoch 3869, Loss: 0.0006059924053261057, Final Batch Loss: 3.969859972130507e-05\n",
      "Epoch 3870, Loss: 0.0004063728720211657, Final Batch Loss: 2.8547165129566565e-06\n",
      "Epoch 3871, Loss: 0.0003197680343873799, Final Batch Loss: 0.00015579821774736047\n",
      "Epoch 3872, Loss: 0.0014934944920241833, Final Batch Loss: 8.68118368089199e-05\n",
      "Epoch 3873, Loss: 0.009811991592755476, Final Batch Loss: 9.662179536462645e-07\n",
      "Epoch 3874, Loss: 0.0005664286691171583, Final Batch Loss: 0.0001317801361437887\n",
      "Epoch 3875, Loss: 0.0002844883645138907, Final Batch Loss: 2.9676091344299493e-06\n",
      "Epoch 3876, Loss: 0.0015741145634819986, Final Batch Loss: 2.924588079622481e-05\n",
      "Epoch 3877, Loss: 0.0002904167922679335, Final Batch Loss: 0.00017434809706173837\n",
      "Epoch 3878, Loss: 0.001346963705145754, Final Batch Loss: 0.0009735400089994073\n",
      "Epoch 3879, Loss: 0.000998517973584967, Final Batch Loss: 1.7316583580395672e-06\n",
      "Epoch 3880, Loss: 0.00043396541514084674, Final Batch Loss: 8.620354492450133e-06\n",
      "Epoch 3881, Loss: 0.00019796885161582622, Final Batch Loss: 7.529005330297878e-08\n",
      "Epoch 3882, Loss: 0.0001943766892509302, Final Batch Loss: 4.30395630246494e-06\n",
      "Epoch 3883, Loss: 0.003306437796481987, Final Batch Loss: 3.4131114716728916e-06\n",
      "Epoch 3884, Loss: 0.0006280063063286434, Final Batch Loss: 7.905438224042882e-07\n",
      "Epoch 3885, Loss: 0.0012389517064548272, Final Batch Loss: 4.956476459483383e-06\n",
      "Epoch 3886, Loss: 0.0006208836894074921, Final Batch Loss: 6.173522706376389e-06\n",
      "Epoch 3887, Loss: 3.921429333786364e-05, Final Batch Loss: 3.1182066777546424e-06\n",
      "Epoch 3888, Loss: 0.00031123128005816625, Final Batch Loss: 8.783840854675873e-08\n",
      "Epoch 3889, Loss: 0.02192927905139186, Final Batch Loss: 2.158276174668572e-06\n",
      "Epoch 3890, Loss: 0.0008524150798621122, Final Batch Loss: 5.799394057248719e-05\n",
      "Epoch 3891, Loss: 0.0005894748474020162, Final Batch Loss: 7.7859594966867e-06\n",
      "Epoch 3892, Loss: 0.0006070285890018567, Final Batch Loss: 5.3209278121357784e-05\n",
      "Epoch 3893, Loss: 0.002770702601992525, Final Batch Loss: 0.0004101023660041392\n",
      "Epoch 3894, Loss: 0.0008510503173511097, Final Batch Loss: 2.647669816724374e-06\n",
      "Epoch 3895, Loss: 0.00019248671333116363, Final Batch Loss: 5.107045126351295e-06\n",
      "Epoch 3896, Loss: 0.0002833696489688009, Final Batch Loss: 8.07000687927939e-05\n",
      "Epoch 3897, Loss: 0.0010793035544338636, Final Batch Loss: 0.00027134796255268157\n",
      "Epoch 3898, Loss: 0.0009445849063922651, Final Batch Loss: 5.613350003841333e-05\n",
      "Epoch 3899, Loss: 0.002865833797841333, Final Batch Loss: 0.0023526803124696016\n",
      "Epoch 3900, Loss: 0.0002966515748994425, Final Batch Loss: 3.249951987527311e-06\n",
      "Epoch 3901, Loss: 0.001247262311153463, Final Batch Loss: 6.813459549448453e-06\n",
      "Epoch 3902, Loss: 0.0003583967498741458, Final Batch Loss: 3.6390142099662626e-07\n",
      "Epoch 3903, Loss: 0.00012769118455580042, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 3904, Loss: 0.0011235483434575144, Final Batch Loss: 3.541859405231662e-05\n",
      "Epoch 3905, Loss: 9.160186101553336e-05, Final Batch Loss: 4.140941314290103e-07\n",
      "Epoch 3906, Loss: 0.002657324635038094, Final Batch Loss: 9.91311935649719e-07\n",
      "Epoch 3907, Loss: 0.0014079110696911812, Final Batch Loss: 0.0003591304994188249\n",
      "Epoch 3908, Loss: 0.0010373587338108337, Final Batch Loss: 9.479428626946174e-06\n",
      "Epoch 3909, Loss: 0.03172128582809819, Final Batch Loss: 0.0003689221339300275\n",
      "Epoch 3910, Loss: 0.00041155740109388717, Final Batch Loss: 4.460791387828067e-06\n",
      "Epoch 3911, Loss: 0.0005500090373971034, Final Batch Loss: 2.4030876375036314e-05\n",
      "Epoch 3912, Loss: 0.0011193024286058062, Final Batch Loss: 9.850366495811613e-07\n",
      "Epoch 3913, Loss: 3.889695069680954e-05, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 3914, Loss: 0.01654309773402929, Final Batch Loss: 0.0004398890305310488\n",
      "Epoch 3915, Loss: 0.00024050548148579765, Final Batch Loss: 1.1293508350718184e-07\n",
      "Epoch 3916, Loss: 0.00043170560695671156, Final Batch Loss: 8.093653605101281e-07\n",
      "Epoch 3917, Loss: 0.00017592987842363073, Final Batch Loss: 9.185113412968349e-06\n",
      "Epoch 3918, Loss: 0.002409239955341036, Final Batch Loss: 5.2952773330616765e-06\n",
      "Epoch 3919, Loss: 0.01418695304710127, Final Batch Loss: 1.1995756722171791e-05\n",
      "Epoch 3920, Loss: 0.0012662914778047707, Final Batch Loss: 0.000863890687469393\n",
      "Epoch 3921, Loss: 0.0012531492338894168, Final Batch Loss: 2.20115343836369e-05\n",
      "Epoch 3922, Loss: 0.00012175010760984151, Final Batch Loss: 9.115731700148899e-06\n",
      "Epoch 3923, Loss: 0.0008715179084219926, Final Batch Loss: 1.850852754614607e-06\n",
      "Epoch 3924, Loss: 0.017101035977248102, Final Batch Loss: 0.0006446351762861013\n",
      "Epoch 3925, Loss: 0.00028918247392084595, Final Batch Loss: 1.6250020280494937e-06\n",
      "Epoch 3926, Loss: 0.03459782845493464, Final Batch Loss: 6.913813194842078e-06\n",
      "Epoch 3927, Loss: 0.004836691565287765, Final Batch Loss: 7.063707016641274e-05\n",
      "Epoch 3928, Loss: 0.0002038440252363216, Final Batch Loss: 6.217556801857427e-06\n",
      "Epoch 3929, Loss: 0.0007800846051395638, Final Batch Loss: 4.623912900569849e-06\n",
      "Epoch 3930, Loss: 0.0002609082049787048, Final Batch Loss: 4.1409398932046315e-07\n",
      "Epoch 3931, Loss: 0.00020961204336344963, Final Batch Loss: 8.53845904202899e-06\n",
      "Epoch 3932, Loss: 0.005589121093748872, Final Batch Loss: 1.2924716656925739e-06\n",
      "Epoch 3933, Loss: 0.0007354931905751982, Final Batch Loss: 8.093640531114943e-07\n",
      "Epoch 3934, Loss: 0.0018834834081644658, Final Batch Loss: 0.0018403787398710847\n",
      "Epoch 3935, Loss: 0.0003128101125184912, Final Batch Loss: 3.104049392277375e-05\n",
      "Epoch 3936, Loss: 0.0003038549284610781, Final Batch Loss: 3.977754204242956e-06\n",
      "Epoch 3937, Loss: 0.01357150737203483, Final Batch Loss: 6.3177667470881715e-06\n",
      "Epoch 3938, Loss: 0.0019855645687130163, Final Batch Loss: 1.0502469194761943e-05\n",
      "Epoch 3939, Loss: 0.00017725654288369697, Final Batch Loss: 9.006754407892004e-05\n",
      "Epoch 3940, Loss: 0.006096950142818969, Final Batch Loss: 0.0059006307274103165\n",
      "Epoch 3941, Loss: 0.0004099790021427907, Final Batch Loss: 1.336957939201966e-05\n",
      "Epoch 3942, Loss: 0.000996462727925973, Final Batch Loss: 0.0008717720629647374\n",
      "Epoch 3943, Loss: 0.0005173101817490533, Final Batch Loss: 0.00016790074005257338\n",
      "Epoch 3944, Loss: 0.000755656934416038, Final Batch Loss: 2.6718351364252158e-05\n",
      "Epoch 3945, Loss: 0.0005144185461176676, Final Batch Loss: 5.960307134955656e-06\n",
      "Epoch 3946, Loss: 0.00019333893214934506, Final Batch Loss: 1.0790678061312065e-05\n",
      "Epoch 3947, Loss: 0.0008801276530050473, Final Batch Loss: 2.6978923983733694e-07\n",
      "Epoch 3948, Loss: 0.000410199641919462, Final Batch Loss: 2.4593155103502795e-05\n",
      "Epoch 3949, Loss: 0.001896995076094754, Final Batch Loss: 0.001346762292087078\n",
      "Epoch 3950, Loss: 0.0004772222710016649, Final Batch Loss: 2.3776417947374284e-05\n",
      "Epoch 3951, Loss: 0.0002969488159578759, Final Batch Loss: 3.913873297278769e-05\n",
      "Epoch 3952, Loss: 0.0001754670137472658, Final Batch Loss: 1.4430580108637514e-07\n",
      "Epoch 3953, Loss: 8.859436638886109e-05, Final Batch Loss: 1.7433332686778158e-05\n",
      "Epoch 3954, Loss: 0.0003076716402574675, Final Batch Loss: 1.9397522919462062e-05\n",
      "Epoch 3955, Loss: 0.0006939305676496588, Final Batch Loss: 5.5172327847685665e-05\n",
      "Epoch 3956, Loss: 0.00023642031737836078, Final Batch Loss: 7.843303319532424e-05\n",
      "Epoch 3957, Loss: 0.0011500461660034489, Final Batch Loss: 6.813399522798136e-06\n",
      "Epoch 3958, Loss: 6.760744031453214e-05, Final Batch Loss: 2.039069613601896e-06\n",
      "Epoch 3959, Loss: 0.00012483098271331983, Final Batch Loss: 5.502252861333545e-06\n",
      "Epoch 3960, Loss: 0.00012398319984185946, Final Batch Loss: 2.6351506221544696e-07\n",
      "Epoch 3961, Loss: 0.000722418448276585, Final Batch Loss: 3.304872734588571e-05\n",
      "Epoch 3962, Loss: 0.0004793277876160573, Final Batch Loss: 0.00038783863419666886\n",
      "Epoch 3963, Loss: 0.0015300109794225136, Final Batch Loss: 3.946383458242053e-06\n",
      "Epoch 3964, Loss: 0.0003570140579540748, Final Batch Loss: 2.6044686819659546e-05\n",
      "Epoch 3965, Loss: 0.000596327728999313, Final Batch Loss: 0.00034297979436814785\n",
      "Epoch 3966, Loss: 0.0006036747945472598, Final Batch Loss: 3.129908873233944e-05\n",
      "Epoch 3967, Loss: 0.0013942910300102085, Final Batch Loss: 0.00013287679757922888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3968, Loss: 0.0003588238938050381, Final Batch Loss: 6.525111189148447e-07\n",
      "Epoch 3969, Loss: 0.000612695232121041, Final Batch Loss: 2.3726333893137053e-05\n",
      "Epoch 3970, Loss: 0.0003237109895053436, Final Batch Loss: 2.0265406419639476e-06\n",
      "Epoch 3971, Loss: 0.0009927958562911954, Final Batch Loss: 8.607110066805035e-05\n",
      "Epoch 3972, Loss: 0.0032272807438857853, Final Batch Loss: 0.00017338893667329103\n",
      "Epoch 3973, Loss: 0.0010396896744282458, Final Batch Loss: 2.9488575137293083e-07\n",
      "Epoch 3974, Loss: 0.0006467166141135294, Final Batch Loss: 3.513533499699406e-07\n",
      "Epoch 3975, Loss: 8.339103959542626e-05, Final Batch Loss: 8.658332149025227e-07\n",
      "Epoch 3976, Loss: 0.00030989911829237826, Final Batch Loss: 5.951385173830204e-05\n",
      "Epoch 3977, Loss: 9.723306914111163e-05, Final Batch Loss: 5.772218401034479e-07\n",
      "Epoch 3978, Loss: 0.00013642230341304185, Final Batch Loss: 1.3175748847515933e-07\n",
      "Epoch 3979, Loss: 0.0012874918120360235, Final Batch Loss: 2.070165101031307e-05\n",
      "Epoch 3980, Loss: 0.00012538973351183813, Final Batch Loss: 1.9512499420670792e-06\n",
      "Epoch 3981, Loss: 0.0005702692549220956, Final Batch Loss: 3.2123286928253947e-06\n",
      "Epoch 3982, Loss: 0.00028849152658949606, Final Batch Loss: 9.05410634004511e-05\n",
      "Epoch 3983, Loss: 0.00034750252962112427, Final Batch Loss: 0.00010495263995835558\n",
      "Epoch 3984, Loss: 0.00016160909945028834, Final Batch Loss: 5.329186387825757e-05\n",
      "Epoch 3985, Loss: 9.953734138434811e-05, Final Batch Loss: 4.642872681870358e-07\n",
      "Epoch 3986, Loss: 0.0005922978307353333, Final Batch Loss: 1.967318166862242e-05\n",
      "Epoch 3987, Loss: 0.0004463812949779822, Final Batch Loss: 1.8069479210680583e-06\n",
      "Epoch 3988, Loss: 0.00015373384803751833, Final Batch Loss: 4.554950919555267e-06\n",
      "Epoch 3989, Loss: 0.00039917611157136434, Final Batch Loss: 2.1959586149478127e-07\n",
      "Epoch 3990, Loss: 0.0005350763167371042, Final Batch Loss: 0.00042655374272726476\n",
      "Epoch 3991, Loss: 9.797130582001046e-05, Final Batch Loss: 7.089783480296319e-07\n",
      "Epoch 3992, Loss: 0.0005160621140021249, Final Batch Loss: 1.28543533719494e-05\n",
      "Epoch 3993, Loss: 0.00044620156768360175, Final Batch Loss: 0.0003127672534901649\n",
      "Epoch 3994, Loss: 0.00021350920451368438, Final Batch Loss: 4.724343853013124e-06\n",
      "Epoch 3995, Loss: 0.002044157274212921, Final Batch Loss: 1.6630398022243753e-05\n",
      "Epoch 3996, Loss: 0.0006205664685694501, Final Batch Loss: 2.778477210085839e-05\n",
      "Epoch 3997, Loss: 0.000263238722254755, Final Batch Loss: 0.00013692304491996765\n",
      "Epoch 3998, Loss: 0.00033769978631426056, Final Batch Loss: 2.6476679977349704e-06\n",
      "Epoch 3999, Loss: 0.003283981808635872, Final Batch Loss: 4.2597057472448796e-05\n",
      "Epoch 4000, Loss: 0.00023040836299514922, Final Batch Loss: 2.8986016786802793e-06\n",
      "Epoch 4001, Loss: 0.00010344216025259811, Final Batch Loss: 1.1123205695184879e-05\n",
      "Epoch 4002, Loss: 0.00026538787278695963, Final Batch Loss: 4.101328886463307e-05\n",
      "Epoch 4003, Loss: 0.0004141311346756993, Final Batch Loss: 1.4836374248261563e-05\n",
      "Epoch 4004, Loss: 0.0002646661259859684, Final Batch Loss: 1.184470147563843e-05\n",
      "Epoch 4005, Loss: 0.00028404697150108404, Final Batch Loss: 0.00013595506607089192\n",
      "Epoch 4006, Loss: 0.0004182832417427562, Final Batch Loss: 0.00019951097783632576\n",
      "Epoch 4007, Loss: 0.00018209090922027826, Final Batch Loss: 7.563758117612451e-05\n",
      "Epoch 4008, Loss: 0.00020274867347325198, Final Batch Loss: 0.00010928419942501932\n",
      "Epoch 4009, Loss: 0.0010103982140208245, Final Batch Loss: 6.3303277784143575e-06\n",
      "Epoch 4010, Loss: 0.00021122765684111755, Final Batch Loss: 8.156421671401404e-08\n",
      "Epoch 4011, Loss: 0.00023891747332527302, Final Batch Loss: 3.764538632822223e-05\n",
      "Epoch 4012, Loss: 0.0002945608941899991, Final Batch Loss: 2.057902975138859e-06\n",
      "Epoch 4013, Loss: 0.0002255836625408847, Final Batch Loss: 2.1854772057849914e-05\n",
      "Epoch 4014, Loss: 0.00025801231458899565, Final Batch Loss: 7.81734343036078e-06\n",
      "Epoch 4015, Loss: 0.00041764991965465015, Final Batch Loss: 8.526339115633164e-06\n",
      "Epoch 4016, Loss: 0.0010869064753933344, Final Batch Loss: 4.761972377309576e-06\n",
      "Epoch 4017, Loss: 0.004778912395091428, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4018, Loss: 0.00012053171337811364, Final Batch Loss: 1.1920859606107115e-06\n",
      "Epoch 4019, Loss: 8.815356477498426e-05, Final Batch Loss: 3.902457592630526e-06\n",
      "Epoch 4020, Loss: 0.0002638941696204711, Final Batch Loss: 8.519980474375188e-05\n",
      "Epoch 4021, Loss: 0.00019716521046575508, Final Batch Loss: 4.831004389416194e-06\n",
      "Epoch 4022, Loss: 8.823759890219662e-05, Final Batch Loss: 2.3841403162805364e-06\n",
      "Epoch 4023, Loss: 0.0006025390918473761, Final Batch Loss: 4.3919204273379364e-08\n",
      "Epoch 4024, Loss: 0.0003548107688402524, Final Batch Loss: 2.998481795657426e-05\n",
      "Epoch 4025, Loss: 0.0001284129175473936, Final Batch Loss: 7.214897777885199e-06\n",
      "Epoch 4026, Loss: 0.00020654083982662996, Final Batch Loss: 9.705274351290427e-06\n",
      "Epoch 4027, Loss: 0.02090493684499961, Final Batch Loss: 8.714562682143878e-06\n",
      "Epoch 4028, Loss: 0.00011713491801401688, Final Batch Loss: 1.4932433032299741e-06\n",
      "Epoch 4029, Loss: 0.0002712486118525703, Final Batch Loss: 2.6978257210430456e-06\n",
      "Epoch 4030, Loss: 0.00016452975251013413, Final Batch Loss: 3.548114909790456e-05\n",
      "Epoch 4031, Loss: 0.00016110831020199612, Final Batch Loss: 1.0038674957968396e-07\n",
      "Epoch 4032, Loss: 0.00023659579710511025, Final Batch Loss: 1.777936086000409e-05\n",
      "Epoch 4033, Loss: 0.008404872142193653, Final Batch Loss: 6.148678153294895e-07\n",
      "Epoch 4034, Loss: 0.0009572131850745791, Final Batch Loss: 2.547272060837713e-06\n",
      "Epoch 4035, Loss: 0.007665083672691253, Final Batch Loss: 2.0469293303904124e-05\n",
      "Epoch 4036, Loss: 0.00031269254009202996, Final Batch Loss: 3.438191697568982e-06\n",
      "Epoch 4037, Loss: 0.0005175956175662577, Final Batch Loss: 3.157506216666661e-05\n",
      "Epoch 4038, Loss: 0.014861798178230856, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4039, Loss: 0.009921381737513002, Final Batch Loss: 0.003203289583325386\n",
      "Epoch 4040, Loss: 0.00032534396450500935, Final Batch Loss: 2.1378298697527498e-05\n",
      "Epoch 4041, Loss: 6.623694753216114e-05, Final Batch Loss: 1.8758080841507763e-05\n",
      "Epoch 4042, Loss: 0.0004666537520279235, Final Batch Loss: 6.568693152075866e-06\n",
      "Epoch 4043, Loss: 0.0016302021654155396, Final Batch Loss: 3.036632278963225e-06\n",
      "Epoch 4044, Loss: 0.031638038248956946, Final Batch Loss: 2.1582734461844666e-06\n",
      "Epoch 4045, Loss: 0.0002684119775153704, Final Batch Loss: 7.654473961338226e-07\n",
      "Epoch 4046, Loss: 0.0009285361775255296, Final Batch Loss: 6.99962765793316e-05\n",
      "Epoch 4047, Loss: 0.0004801772811333649, Final Batch Loss: 0.0002178794820792973\n",
      "Epoch 4048, Loss: 0.0001942714179676841, Final Batch Loss: 1.1254679520789068e-05\n",
      "Epoch 4049, Loss: 0.00028418628741633256, Final Batch Loss: 4.3919087033827964e-07\n",
      "Epoch 4050, Loss: 0.0007732159792794846, Final Batch Loss: 3.0828759918222204e-05\n",
      "Epoch 4051, Loss: 0.001634104712138651, Final Batch Loss: 3.968898454331793e-05\n",
      "Epoch 4052, Loss: 0.00023533566240985238, Final Batch Loss: 1.6689166386640863e-06\n",
      "Epoch 4053, Loss: 0.0006780304571520901, Final Batch Loss: 1.2610940984814079e-06\n",
      "Epoch 4054, Loss: 0.004498225736824679, Final Batch Loss: 1.1098234608653001e-05\n",
      "Epoch 4055, Loss: 0.0002937418057626928, Final Batch Loss: 1.6689182302798145e-06\n",
      "Epoch 4056, Loss: 0.00033568949402251747, Final Batch Loss: 8.138220437103882e-05\n",
      "Epoch 4057, Loss: 0.00048300269918399863, Final Batch Loss: 5.1795319450320676e-05\n",
      "Epoch 4058, Loss: 0.0017470711231908354, Final Batch Loss: 3.57620820068405e-06\n",
      "Epoch 4059, Loss: 0.0004883440924459137, Final Batch Loss: 8.004310075193644e-05\n",
      "Epoch 4060, Loss: 0.002041976754071584, Final Batch Loss: 2.0077138742635725e-06\n",
      "Epoch 4061, Loss: 0.000609424285357818, Final Batch Loss: 0.0001174455028376542\n",
      "Epoch 4062, Loss: 0.00016734840164644993, Final Batch Loss: 4.360493676358601e-06\n",
      "Epoch 4063, Loss: 0.0004771921012434177, Final Batch Loss: 6.391909118974581e-05\n",
      "Epoch 4064, Loss: 0.0009450775264241429, Final Batch Loss: 1.6312829131948092e-07\n",
      "Epoch 4065, Loss: 0.0012359342908894178, Final Batch Loss: 4.597945007844828e-05\n",
      "Epoch 4066, Loss: 0.00025552513034199364, Final Batch Loss: 0.00019114780297968537\n",
      "Epoch 4067, Loss: 0.00020794623696929193, Final Batch Loss: 4.7620210352761205e-06\n",
      "Epoch 4068, Loss: 0.00019993895239167614, Final Batch Loss: 1.2691979463852476e-05\n",
      "Epoch 4069, Loss: 0.0001575045880599646, Final Batch Loss: 1.8819724573404528e-05\n",
      "Epoch 4070, Loss: 0.00012939801604261447, Final Batch Loss: 1.0289543297403725e-06\n",
      "Epoch 4071, Loss: 0.0002855353793620452, Final Batch Loss: 2.823302338583744e-06\n",
      "Epoch 4072, Loss: 0.00013600202686347984, Final Batch Loss: 2.9488541031241766e-07\n",
      "Epoch 4073, Loss: 8.466118697469938e-05, Final Batch Loss: 3.96519817513763e-06\n",
      "Epoch 4074, Loss: 0.0002555583716912224, Final Batch Loss: 2.1896605630900012e-06\n",
      "Epoch 4075, Loss: 0.0001735949354042532, Final Batch Loss: 1.0916452083620243e-05\n",
      "Epoch 4076, Loss: 4.940754865856434e-05, Final Batch Loss: 2.1708194708480733e-06\n",
      "Epoch 4077, Loss: 0.00013767891687166411, Final Batch Loss: 2.4871231289580464e-05\n",
      "Epoch 4078, Loss: 0.00031051875932996964, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4079, Loss: 0.0002991704732266953, Final Batch Loss: 2.973272967210505e-05\n",
      "Epoch 4080, Loss: 0.0001229956013517608, Final Batch Loss: 9.411255774693927e-08\n",
      "Epoch 4081, Loss: 0.00017178861435240833, Final Batch Loss: 5.946440069237724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4082, Loss: 0.00042363127340649953, Final Batch Loss: 8.463471203867812e-06\n",
      "Epoch 4083, Loss: 0.0004704881976067554, Final Batch Loss: 9.201815555570647e-05\n",
      "Epoch 4084, Loss: 0.0005872607879382485, Final Batch Loss: 1.5308804677260923e-06\n",
      "Epoch 4085, Loss: 0.00010051471221572683, Final Batch Loss: 4.266429129984317e-07\n",
      "Epoch 4086, Loss: 0.00011390027604818442, Final Batch Loss: 1.1920921849650767e-07\n",
      "Epoch 4087, Loss: 0.00016028621848818148, Final Batch Loss: 1.5024507774796803e-05\n",
      "Epoch 4088, Loss: 6.624793968512677e-05, Final Batch Loss: 1.3940229109721258e-05\n",
      "Epoch 4089, Loss: 0.00037025681740487926, Final Batch Loss: 1.770996823324822e-05\n",
      "Epoch 4090, Loss: 0.002114848315159179, Final Batch Loss: 2.917449364758795e-06\n",
      "Epoch 4091, Loss: 0.0003262929592189323, Final Batch Loss: 5.64675453063046e-08\n",
      "Epoch 4092, Loss: 0.00023786000383552164, Final Batch Loss: 0.00013893508003093302\n",
      "Epoch 4093, Loss: 0.00038450644387921784, Final Batch Loss: 2.559807398938574e-06\n",
      "Epoch 4094, Loss: 0.0009020144862006418, Final Batch Loss: 3.432800076552667e-05\n",
      "Epoch 4095, Loss: 0.00012131928451708518, Final Batch Loss: 2.7631314878817648e-05\n",
      "Epoch 4096, Loss: 0.0002449283238092903, Final Batch Loss: 4.0729213651502505e-05\n",
      "Epoch 4097, Loss: 0.0002215985550719779, Final Batch Loss: 2.6176272513112053e-05\n",
      "Epoch 4098, Loss: 9.470330792282766e-05, Final Batch Loss: 2.133198222509236e-06\n",
      "Epoch 4099, Loss: 0.00045170358498580754, Final Batch Loss: 9.195279562845826e-05\n",
      "Epoch 4100, Loss: 0.00011555847413546871, Final Batch Loss: 8.802308002486825e-06\n",
      "Epoch 4101, Loss: 0.00016989124276278744, Final Batch Loss: 5.960436055829632e-07\n",
      "Epoch 4102, Loss: 0.0016727142265153816, Final Batch Loss: 1.5294242984964512e-05\n",
      "Epoch 4103, Loss: 0.0010314096689398866, Final Batch Loss: 1.575868736836128e-05\n",
      "Epoch 4104, Loss: 0.001725977305966353, Final Batch Loss: 6.1486679214795e-07\n",
      "Epoch 4105, Loss: 0.0001464824417780619, Final Batch Loss: 8.760518539929762e-05\n",
      "Epoch 4106, Loss: 0.0022841149620944634, Final Batch Loss: 0.00012981555482838303\n",
      "Epoch 4107, Loss: 0.00026299803221263574, Final Batch Loss: 4.3228378672210965e-06\n",
      "Epoch 4108, Loss: 0.0002829969998856541, Final Batch Loss: 0.0001428320974810049\n",
      "Epoch 4109, Loss: 0.00305498156012618, Final Batch Loss: 4.897851977148093e-05\n",
      "Epoch 4110, Loss: 8.427386137555004e-05, Final Batch Loss: 4.1847347347356845e-06\n",
      "Epoch 4111, Loss: 0.0011541277926880866, Final Batch Loss: 0.0002509686746634543\n",
      "Epoch 4112, Loss: 0.0004147598629060667, Final Batch Loss: 0.0003327665326651186\n",
      "Epoch 4113, Loss: 0.04791708195989486, Final Batch Loss: 2.2911102860234678e-05\n",
      "Epoch 4114, Loss: 0.0007972884532705393, Final Batch Loss: 4.768363055518421e-07\n",
      "Epoch 4115, Loss: 0.00024617102462798357, Final Batch Loss: 3.628634658525698e-05\n",
      "Epoch 4116, Loss: 0.0002297514589599814, Final Batch Loss: 2.0077334283996606e-07\n",
      "Epoch 4117, Loss: 0.0004885690359515138, Final Batch Loss: 0.0002884188143070787\n",
      "Epoch 4118, Loss: 0.0005965478758298559, Final Batch Loss: 2.7318395950715058e-05\n",
      "Epoch 4119, Loss: 0.0005341950381989591, Final Batch Loss: 0.00033400271786376834\n",
      "Epoch 4120, Loss: 0.001553506328491494, Final Batch Loss: 9.881966980174184e-05\n",
      "Epoch 4121, Loss: 0.0006113213239586912, Final Batch Loss: 8.085335866780952e-05\n",
      "Epoch 4122, Loss: 0.00029329281483114755, Final Batch Loss: 3.701754849316785e-07\n",
      "Epoch 4123, Loss: 0.00024945659743025317, Final Batch Loss: 2.1394785107986536e-06\n",
      "Epoch 4124, Loss: 0.012996555000427179, Final Batch Loss: 0.00023398558550979942\n",
      "Epoch 4125, Loss: 0.0013218626684192714, Final Batch Loss: 2.2837614324089373e-06\n",
      "Epoch 4126, Loss: 8.410674354308867e-05, Final Batch Loss: 6.4494656726310495e-06\n",
      "Epoch 4127, Loss: 0.020002822947390086, Final Batch Loss: 1.1293404895695858e-06\n",
      "Epoch 4128, Loss: 0.00044062520464649424, Final Batch Loss: 9.635846799938008e-05\n",
      "Epoch 4129, Loss: 0.001594235400261823, Final Batch Loss: 0.00011610743240453303\n",
      "Epoch 4130, Loss: 0.0025160740042338148, Final Batch Loss: 5.784777749795467e-05\n",
      "Epoch 4131, Loss: 0.0003170820236846339, Final Batch Loss: 0.00014780259516555816\n",
      "Epoch 4132, Loss: 0.010169155246330774, Final Batch Loss: 6.311622200882994e-06\n",
      "Epoch 4133, Loss: 0.00020364967940622591, Final Batch Loss: 5.464526566356653e-06\n",
      "Epoch 4134, Loss: 0.00011971370986429974, Final Batch Loss: 3.7016889109509066e-06\n",
      "Epoch 4135, Loss: 0.026974608459568117, Final Batch Loss: 3.497394936857745e-05\n",
      "Epoch 4136, Loss: 0.001002919438178651, Final Batch Loss: 0.0003906461060978472\n",
      "Epoch 4137, Loss: 0.010639278356393334, Final Batch Loss: 6.391413626261055e-05\n",
      "Epoch 4138, Loss: 0.00021378266410465585, Final Batch Loss: 1.1524844921950717e-05\n",
      "Epoch 4139, Loss: 0.001389775294228457, Final Batch Loss: 0.0008256279397755861\n",
      "Epoch 4140, Loss: 0.0008790848340822777, Final Batch Loss: 1.6563689086979139e-06\n",
      "Epoch 4141, Loss: 0.0007784172248648247, Final Batch Loss: 7.829896276234649e-06\n",
      "Epoch 4142, Loss: 0.0010034299921244383, Final Batch Loss: 8.795372559688985e-05\n",
      "Epoch 4143, Loss: 0.002332980320261413, Final Batch Loss: 5.0945504881383386e-06\n",
      "Epoch 4144, Loss: 0.009862302715191618, Final Batch Loss: 8.941636770032346e-05\n",
      "Epoch 4145, Loss: 0.000335701355652418, Final Batch Loss: 4.6502471377607435e-05\n",
      "Epoch 4146, Loss: 0.0001851644074122305, Final Batch Loss: 5.006669198337477e-06\n",
      "Epoch 4147, Loss: 0.000506732147925959, Final Batch Loss: 4.831097726309963e-07\n",
      "Epoch 4148, Loss: 0.00022204843344297842, Final Batch Loss: 5.307838819135213e-06\n",
      "Epoch 4149, Loss: 0.00023382880635836045, Final Batch Loss: 1.9888789211108815e-06\n",
      "Epoch 4150, Loss: 0.013462853105920658, Final Batch Loss: 8.419508048973512e-06\n",
      "Epoch 4151, Loss: 0.00018832929868040083, Final Batch Loss: 1.1356148661434418e-06\n",
      "Epoch 4152, Loss: 0.0005543221465700299, Final Batch Loss: 9.160264085039671e-07\n",
      "Epoch 4153, Loss: 0.0011777386527001, Final Batch Loss: 1.5748001942483825e-06\n",
      "Epoch 4154, Loss: 0.004308915211353792, Final Batch Loss: 1.4430587214064872e-07\n",
      "Epoch 4155, Loss: 0.0009243101184424063, Final Batch Loss: 1.0666089877986451e-07\n",
      "Epoch 4156, Loss: 0.0005074535629319143, Final Batch Loss: 1.1330009328958113e-05\n",
      "Epoch 4157, Loss: 0.004411349174915813, Final Batch Loss: 0.00019325151515658945\n",
      "Epoch 4158, Loss: 0.004205483051464398, Final Batch Loss: 4.868571977567626e-06\n",
      "Epoch 4159, Loss: 0.00038449428757303394, Final Batch Loss: 9.939401206793264e-05\n",
      "Epoch 4160, Loss: 0.008407026170061727, Final Batch Loss: 1.0476903298695106e-05\n",
      "Epoch 4161, Loss: 0.00010355223002989078, Final Batch Loss: 1.154336041508941e-05\n",
      "Epoch 4162, Loss: 0.000112506523826994, Final Batch Loss: 3.764503020420307e-08\n",
      "Epoch 4163, Loss: 0.0002864298035945012, Final Batch Loss: 4.078206927715655e-07\n",
      "Epoch 4164, Loss: 0.0016598397360212402, Final Batch Loss: 1.2453589079086669e-05\n",
      "Epoch 4165, Loss: 4.416846468302538e-05, Final Batch Loss: 5.075582976132864e-06\n",
      "Epoch 4166, Loss: 0.00018878380541309525, Final Batch Loss: 6.525125968437351e-07\n",
      "Epoch 4167, Loss: 0.0002457022092130501, Final Batch Loss: 8.192889799829572e-05\n",
      "Epoch 4168, Loss: 6.110453432484064e-05, Final Batch Loss: 1.5770960089867003e-05\n",
      "Epoch 4169, Loss: 0.00011354066373314708, Final Batch Loss: 5.304649312165566e-05\n",
      "Epoch 4170, Loss: 8.524624064421005e-05, Final Batch Loss: 7.466213105544739e-07\n",
      "Epoch 4171, Loss: 0.00021621714903119482, Final Batch Loss: 1.6312831974119035e-07\n",
      "Epoch 4172, Loss: 0.0001894364340842003, Final Batch Loss: 5.0504841055953875e-06\n",
      "Epoch 4173, Loss: 0.010055015842681314, Final Batch Loss: 3.0993619475339074e-06\n",
      "Epoch 4174, Loss: 0.0034698279134559584, Final Batch Loss: 6.274169805919882e-08\n",
      "Epoch 4175, Loss: 0.0002960042929771589, Final Batch Loss: 1.4497965821647085e-05\n",
      "Epoch 4176, Loss: 0.01786989110223658, Final Batch Loss: 1.9208104276913218e-05\n",
      "Epoch 4177, Loss: 0.003031362753972644, Final Batch Loss: 5.401272574090399e-05\n",
      "Epoch 4178, Loss: 0.0005130201352585573, Final Batch Loss: 4.184741555945948e-06\n",
      "Epoch 4179, Loss: 0.0004080175785929896, Final Batch Loss: 0.00024318930809386075\n",
      "Epoch 4180, Loss: 0.019043494889046997, Final Batch Loss: 0.000589934119489044\n",
      "Epoch 4181, Loss: 0.0002882967451114382, Final Batch Loss: 2.0202637642796617e-06\n",
      "Epoch 4182, Loss: 0.0002501669214893809, Final Batch Loss: 6.462387887040677e-07\n",
      "Epoch 4183, Loss: 0.00181606576370541, Final Batch Loss: 0.00014803373778704554\n",
      "Epoch 4184, Loss: 0.0005649788781738607, Final Batch Loss: 0.0003121374757029116\n",
      "Epoch 4185, Loss: 0.00014716890126464932, Final Batch Loss: 7.591717690047517e-07\n",
      "Epoch 4186, Loss: 0.000285071691905614, Final Batch Loss: 7.509768693125807e-06\n",
      "Epoch 4187, Loss: 0.00018846495885327386, Final Batch Loss: 7.403484119095083e-07\n",
      "Epoch 4188, Loss: 0.00036346809224596655, Final Batch Loss: 2.635120608829311e-06\n",
      "Epoch 4189, Loss: 0.00015600439292029478, Final Batch Loss: 3.2991854823194444e-05\n",
      "Epoch 4190, Loss: 0.000177284247556031, Final Batch Loss: 1.8822503022875026e-07\n",
      "Epoch 4191, Loss: 0.00044706318658427335, Final Batch Loss: 0.0002769704442471266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4192, Loss: 0.0002279672808072064, Final Batch Loss: 3.695249688462354e-05\n",
      "Epoch 4193, Loss: 0.0004572184188873507, Final Batch Loss: 0.0002175595291191712\n",
      "Epoch 4194, Loss: 0.0006229709179024212, Final Batch Loss: 0.000389548804378137\n",
      "Epoch 4195, Loss: 0.00037604985664074775, Final Batch Loss: 0.0002617624122649431\n",
      "Epoch 4196, Loss: 0.0146461547369654, Final Batch Loss: 7.12093924448709e-06\n",
      "Epoch 4197, Loss: 0.000263145484495908, Final Batch Loss: 3.724126145243645e-05\n",
      "Epoch 4198, Loss: 0.00036399767850525677, Final Batch Loss: 1.4172088413033634e-05\n",
      "Epoch 4199, Loss: 0.00014271839245338924, Final Batch Loss: 7.2901057137642056e-06\n",
      "Epoch 4200, Loss: 0.00024104110707412474, Final Batch Loss: 5.791224612039514e-05\n",
      "Epoch 4201, Loss: 0.0005799613427370787, Final Batch Loss: 8.032990444917232e-05\n",
      "Epoch 4202, Loss: 0.0003034709043276962, Final Batch Loss: 2.0600953575922176e-05\n",
      "Epoch 4203, Loss: 0.0006494133340311237, Final Batch Loss: 3.4712480555754155e-05\n",
      "Epoch 4204, Loss: 0.0002877993539698309, Final Batch Loss: 4.203685932679946e-07\n",
      "Epoch 4205, Loss: 0.0007265695330715971, Final Batch Loss: 0.0004512548621278256\n",
      "Epoch 4206, Loss: 0.0001832411999203032, Final Batch Loss: 4.056714169564657e-05\n",
      "Epoch 4207, Loss: 0.00034379689350316767, Final Batch Loss: 2.541159665270243e-05\n",
      "Epoch 4208, Loss: 0.00031682719327363884, Final Batch Loss: 9.190886885335203e-06\n",
      "Epoch 4209, Loss: 0.0017593729207874276, Final Batch Loss: 2.3543139832327142e-05\n",
      "Epoch 4210, Loss: 0.0009154584695352241, Final Batch Loss: 0.00048581676674075425\n",
      "Epoch 4211, Loss: 0.0002756837998987294, Final Batch Loss: 1.8822518654815212e-08\n",
      "Epoch 4212, Loss: 0.0003817181095655542, Final Batch Loss: 8.306360541610047e-06\n",
      "Epoch 4213, Loss: 0.00010737892444012687, Final Batch Loss: 7.854712748667225e-05\n",
      "Epoch 4214, Loss: 0.00010885837332352821, Final Batch Loss: 9.222997050528647e-07\n",
      "Epoch 4215, Loss: 0.0005131284779054113, Final Batch Loss: 1.920182694448158e-05\n",
      "Epoch 4216, Loss: 0.00011396185891499044, Final Batch Loss: 4.0154018279281445e-06\n",
      "Epoch 4217, Loss: 0.0002044196489805472, Final Batch Loss: 4.6428795030806214e-07\n",
      "Epoch 4218, Loss: 5.2478386351140216e-05, Final Batch Loss: 2.214765117969364e-06\n",
      "Epoch 4219, Loss: 0.018220419539012767, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4220, Loss: 0.00020629483550749228, Final Batch Loss: 1.254833392749788e-07\n",
      "Epoch 4221, Loss: 0.00042318853547840263, Final Batch Loss: 6.336881597235333e-07\n",
      "Epoch 4222, Loss: 0.00013587497232947499, Final Batch Loss: 1.4623105016653426e-05\n",
      "Epoch 4223, Loss: 0.00022743447829043362, Final Batch Loss: 1.1293508350718184e-07\n",
      "Epoch 4224, Loss: 0.001444140805688221, Final Batch Loss: 0.0013080472126603127\n",
      "Epoch 4225, Loss: 0.000277177866337297, Final Batch Loss: 1.7002812455757521e-06\n",
      "Epoch 4226, Loss: 0.0005949150763626676, Final Batch Loss: 0.0004643533320631832\n",
      "Epoch 4227, Loss: 0.0005758472498200717, Final Batch Loss: 1.3657560884894338e-05\n",
      "Epoch 4228, Loss: 0.0008744178048800677, Final Batch Loss: 7.770708907628432e-05\n",
      "Epoch 4229, Loss: 0.00013725127598718245, Final Batch Loss: 9.285721489504795e-07\n",
      "Epoch 4230, Loss: 0.002071590919740629, Final Batch Loss: 2.3088653051672736e-06\n",
      "Epoch 4231, Loss: 0.012112653043487853, Final Batch Loss: 3.701757407270634e-07\n",
      "Epoch 4232, Loss: 0.0018591628668218618, Final Batch Loss: 1.4618763088947162e-06\n",
      "Epoch 4233, Loss: 0.003161674086641142, Final Batch Loss: 2.46571789830341e-06\n",
      "Epoch 4234, Loss: 0.0007493735029129311, Final Batch Loss: 0.0005245453212410212\n",
      "Epoch 4235, Loss: 0.00012094879093638156, Final Batch Loss: 8.306671588798054e-06\n",
      "Epoch 4236, Loss: 0.00019741309563414688, Final Batch Loss: 1.2611000101969694e-06\n",
      "Epoch 4237, Loss: 0.00023368821075564483, Final Batch Loss: 7.735518920526374e-06\n",
      "Epoch 4238, Loss: 0.004783762396982638, Final Batch Loss: 4.216075467411429e-06\n",
      "Epoch 4239, Loss: 0.0005912929752298623, Final Batch Loss: 8.03088994416612e-07\n",
      "Epoch 4240, Loss: 0.0002755599575721135, Final Batch Loss: 6.443429356295383e-06\n",
      "Epoch 4241, Loss: 0.0005679049681930337, Final Batch Loss: 0.00032920646481215954\n",
      "Epoch 4242, Loss: 0.0005123629925947171, Final Batch Loss: 3.736906000995077e-05\n",
      "Epoch 4243, Loss: 0.002505037534319854, Final Batch Loss: 3.8272355595836416e-07\n",
      "Epoch 4244, Loss: 0.0008789701969362795, Final Batch Loss: 9.969258098863065e-05\n",
      "Epoch 4245, Loss: 0.00018842259305529296, Final Batch Loss: 2.9054572223685682e-05\n",
      "Epoch 4246, Loss: 0.001148435155300831, Final Batch Loss: 8.218557013606187e-06\n",
      "Epoch 4247, Loss: 0.1321561655277037, Final Batch Loss: 0.13200229406356812\n",
      "Epoch 4248, Loss: 0.01965437272221493, Final Batch Loss: 2.509666217065387e-07\n",
      "Epoch 4249, Loss: 0.00032595587445172214, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4250, Loss: 0.0024842803250066936, Final Batch Loss: 3.458888386376202e-05\n",
      "Epoch 4251, Loss: 0.0018246698309667408, Final Batch Loss: 0.0005856213974766433\n",
      "Epoch 4252, Loss: 0.013127772748703137, Final Batch Loss: 3.42430139426142e-05\n",
      "Epoch 4253, Loss: 0.0018811650952557102, Final Batch Loss: 0.00016016160952858627\n",
      "Epoch 4254, Loss: 0.0005624674585931189, Final Batch Loss: 2.572405435330438e-07\n",
      "Epoch 4255, Loss: 0.0029101244872435927, Final Batch Loss: 0.0005076659726910293\n",
      "Epoch 4256, Loss: 0.0012024453553749481, Final Batch Loss: 2.897250851674471e-05\n",
      "Epoch 4257, Loss: 0.0067611040685733315, Final Batch Loss: 1.721355874906294e-05\n",
      "Epoch 4258, Loss: 0.015265229261785862, Final Batch Loss: 1.746583620843012e-05\n",
      "Epoch 4259, Loss: 0.0011890252972079907, Final Batch Loss: 0.0009452060330659151\n",
      "Epoch 4260, Loss: 0.0013417028640105855, Final Batch Loss: 9.561463230056688e-06\n",
      "Epoch 4261, Loss: 0.004636066711100284, Final Batch Loss: 0.0040588900446891785\n",
      "Epoch 4262, Loss: 0.00024697902699699625, Final Batch Loss: 6.790515180910006e-05\n",
      "Epoch 4263, Loss: 0.0033680540127534186, Final Batch Loss: 0.0014044486451894045\n",
      "Epoch 4264, Loss: 0.00022084572447056416, Final Batch Loss: 8.356939360965043e-06\n",
      "Epoch 4265, Loss: 0.00023535434229415841, Final Batch Loss: 5.695381332770921e-05\n",
      "Epoch 4266, Loss: 0.002865403830583091, Final Batch Loss: 6.480831871158443e-06\n",
      "Epoch 4267, Loss: 0.0005353994201868773, Final Batch Loss: 4.3825817556353286e-05\n",
      "Epoch 4268, Loss: 0.00998737633926794, Final Batch Loss: 0.0022017613518983126\n",
      "Epoch 4269, Loss: 0.0009019101489684545, Final Batch Loss: 1.7077101801987737e-05\n",
      "Epoch 4270, Loss: 0.00013356952968024416, Final Batch Loss: 7.503399501729291e-06\n",
      "Epoch 4271, Loss: 0.0031804634199943393, Final Batch Loss: 0.0001002572535071522\n",
      "Epoch 4272, Loss: 0.02503834890399048, Final Batch Loss: 9.662182947067777e-07\n",
      "Epoch 4273, Loss: 0.0016539257494514459, Final Batch Loss: 9.441851034353022e-06\n",
      "Epoch 4274, Loss: 0.0005967277411400573, Final Batch Loss: 9.824450899031945e-06\n",
      "Epoch 4275, Loss: 0.0066372403962304816, Final Batch Loss: 7.994528277777135e-05\n",
      "Epoch 4276, Loss: 0.0020380971844815576, Final Batch Loss: 1.2109020417483407e-06\n",
      "Epoch 4277, Loss: 0.002167089252907317, Final Batch Loss: 8.011840691324323e-06\n",
      "Epoch 4278, Loss: 0.0005615211121039465, Final Batch Loss: 0.00012027158663840964\n",
      "Epoch 4279, Loss: 0.00021082125749671832, Final Batch Loss: 6.573228893103078e-05\n",
      "Epoch 4280, Loss: 0.00037177008925937116, Final Batch Loss: 0.00016093273006845266\n",
      "Epoch 4281, Loss: 0.0004542559472611174, Final Batch Loss: 0.00016102618246804923\n",
      "Epoch 4282, Loss: 0.0010449066685396247, Final Batch Loss: 1.637369132367894e-05\n",
      "Epoch 4283, Loss: 0.0011184896429767832, Final Batch Loss: 0.0006460915319621563\n",
      "Epoch 4284, Loss: 0.0004121558122278657, Final Batch Loss: 4.20647811552044e-05\n",
      "Epoch 4285, Loss: 0.012948855682680005, Final Batch Loss: 5.51472612642101e-06\n",
      "Epoch 4286, Loss: 0.015010365408670623, Final Batch Loss: 2.0418672647792846e-05\n",
      "Epoch 4287, Loss: 0.003929254168724583, Final Batch Loss: 1.1838658792839851e-05\n",
      "Epoch 4288, Loss: 0.0003247542645112844, Final Batch Loss: 2.54421047429787e-05\n",
      "Epoch 4289, Loss: 0.0012846101381001063, Final Batch Loss: 8.874081686371937e-05\n",
      "Epoch 4290, Loss: 0.0015269816503860056, Final Batch Loss: 0.0010971593437716365\n",
      "Epoch 4291, Loss: 0.004561497335089371, Final Batch Loss: 0.00032229532371275127\n",
      "Epoch 4292, Loss: 0.0006649101507036903, Final Batch Loss: 1.0728782626756583e-06\n",
      "Epoch 4293, Loss: 0.0007706384494667873, Final Batch Loss: 6.689086876576766e-05\n",
      "Epoch 4294, Loss: 0.00027541058079805225, Final Batch Loss: 4.3826570617966354e-05\n",
      "Epoch 4295, Loss: 0.0012242911361681763, Final Batch Loss: 2.511876300559379e-05\n",
      "Epoch 4296, Loss: 0.0007523720923927613, Final Batch Loss: 0.00046952636330388486\n",
      "Epoch 4297, Loss: 0.005907683099508176, Final Batch Loss: 1.3677537253897754e-06\n",
      "Epoch 4298, Loss: 0.01697390636536511, Final Batch Loss: 6.89506987328059e-06\n",
      "Epoch 4299, Loss: 0.002694863982469542, Final Batch Loss: 4.681633072323166e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4300, Loss: 0.001818753546103835, Final Batch Loss: 4.414576687850058e-05\n",
      "Epoch 4301, Loss: 0.010663314151315717, Final Batch Loss: 4.74317857879214e-06\n",
      "Epoch 4302, Loss: 0.0004410089131852146, Final Batch Loss: 1.5946880012052134e-05\n",
      "Epoch 4303, Loss: 3.733982202902553e-05, Final Batch Loss: 6.901559572725091e-07\n",
      "Epoch 4304, Loss: 0.04967766091738213, Final Batch Loss: 1.6689040194250992e-06\n",
      "Epoch 4305, Loss: 0.00020857349863945274, Final Batch Loss: 7.654182809346821e-06\n",
      "Epoch 4306, Loss: 0.00020838786940657883, Final Batch Loss: 5.797196990897646e-06\n",
      "Epoch 4307, Loss: 0.0003922966479876777, Final Batch Loss: 4.993139373254962e-05\n",
      "Epoch 4308, Loss: 0.0002923707688751165, Final Batch Loss: 0.00015455509128514677\n",
      "Epoch 4309, Loss: 0.0018429586771162576, Final Batch Loss: 4.937580342811998e-06\n",
      "Epoch 4310, Loss: 0.009564792148012202, Final Batch Loss: 0.008958608843386173\n",
      "Epoch 4311, Loss: 0.0007623285982845118, Final Batch Loss: 0.00029525344143621624\n",
      "Epoch 4312, Loss: 0.0011875743439304642, Final Batch Loss: 0.0005142513546161354\n",
      "Epoch 4313, Loss: 0.000205005372663436, Final Batch Loss: 0.00017665141785982996\n",
      "Epoch 4314, Loss: 0.00043397310582804494, Final Batch Loss: 6.230971484910697e-05\n",
      "Epoch 4315, Loss: 0.00029841069772373885, Final Batch Loss: 0.00011097381502622738\n",
      "Epoch 4316, Loss: 0.00014612383074563695, Final Batch Loss: 1.2485534170991741e-06\n",
      "Epoch 4317, Loss: 0.02909305287175812, Final Batch Loss: 0.022940486669540405\n",
      "Epoch 4318, Loss: 7.77219547671848e-05, Final Batch Loss: 6.650607247138396e-07\n",
      "Epoch 4319, Loss: 0.00027505815069162054, Final Batch Loss: 7.785721209074836e-06\n",
      "Epoch 4320, Loss: 0.0010167067157453857, Final Batch Loss: 7.392081897705793e-05\n",
      "Epoch 4321, Loss: 0.00019620118609964265, Final Batch Loss: 2.428068455628818e-06\n",
      "Epoch 4322, Loss: 0.00021362433335525566, Final Batch Loss: 6.21124354438507e-06\n",
      "Epoch 4323, Loss: 0.00010779588956211228, Final Batch Loss: 8.394337783101946e-06\n",
      "Epoch 4324, Loss: 0.0003574225374904927, Final Batch Loss: 6.7194523580837995e-06\n",
      "Epoch 4325, Loss: 0.0014881971819704631, Final Batch Loss: 1.6015585060813464e-05\n",
      "Epoch 4326, Loss: 0.00014278903586273373, Final Batch Loss: 3.551114104993758e-06\n",
      "Epoch 4327, Loss: 0.000511395039211493, Final Batch Loss: 2.0909785234835e-05\n",
      "Epoch 4328, Loss: 0.00022980840890340914, Final Batch Loss: 2.892362090278766e-06\n",
      "Epoch 4329, Loss: 0.00014966829957074879, Final Batch Loss: 2.8861148848591256e-07\n",
      "Epoch 4330, Loss: 0.0005800712096970528, Final Batch Loss: 0.00021935917902737856\n",
      "Epoch 4331, Loss: 0.0014529147156281397, Final Batch Loss: 0.001178892096504569\n",
      "Epoch 4332, Loss: 0.0001604838247430962, Final Batch Loss: 1.1795340242315433e-06\n",
      "Epoch 4333, Loss: 0.00040046776848612353, Final Batch Loss: 0.00014144086162559688\n",
      "Epoch 4334, Loss: 0.00019630125370895257, Final Batch Loss: 8.570174941269215e-06\n",
      "Epoch 4335, Loss: 0.0001813888029573718, Final Batch Loss: 2.6782290660776198e-05\n",
      "Epoch 4336, Loss: 0.0006840712530902238, Final Batch Loss: 2.0265370039851405e-06\n",
      "Epoch 4337, Loss: 0.0001761334812044879, Final Batch Loss: 1.4493185744868242e-06\n",
      "Epoch 4338, Loss: 0.0014958549800212495, Final Batch Loss: 0.0009860590798780322\n",
      "Epoch 4339, Loss: 0.00021943982028460596, Final Batch Loss: 2.8906420993735082e-05\n",
      "Epoch 4340, Loss: 0.0006255555472307606, Final Batch Loss: 0.00018345184798818082\n",
      "Epoch 4341, Loss: 0.0003381299845841568, Final Batch Loss: 1.0979726994264638e-06\n",
      "Epoch 4342, Loss: 5.717250141401564e-05, Final Batch Loss: 4.3919143877246825e-07\n",
      "Epoch 4343, Loss: 0.00014730211660207715, Final Batch Loss: 5.395597327151336e-06\n",
      "Epoch 4344, Loss: 9.358539273307542e-05, Final Batch Loss: 5.320288437360432e-06\n",
      "Epoch 4345, Loss: 8.447902655461803e-05, Final Batch Loss: 3.0810959287919104e-05\n",
      "Epoch 4346, Loss: 9.907559024213697e-05, Final Batch Loss: 6.041765573172597e-06\n",
      "Epoch 4347, Loss: 0.00018216083299193997, Final Batch Loss: 3.789815309573896e-05\n",
      "Epoch 4348, Loss: 0.0007146741900214693, Final Batch Loss: 3.2248808565782383e-06\n",
      "Epoch 4349, Loss: 0.00022758249269827502, Final Batch Loss: 3.4005543056991883e-06\n",
      "Epoch 4350, Loss: 0.00020324827966078374, Final Batch Loss: 8.59558724641829e-07\n",
      "Epoch 4351, Loss: 0.00017651912821747828, Final Batch Loss: 4.918740160064772e-06\n",
      "Epoch 4352, Loss: 0.00010058551784197789, Final Batch Loss: 1.7567658971984201e-07\n",
      "Epoch 4353, Loss: 0.0005335200143008478, Final Batch Loss: 1.016410692500358e-06\n",
      "Epoch 4354, Loss: 0.0007779327479511267, Final Batch Loss: 1.1016867574653588e-05\n",
      "Epoch 4355, Loss: 0.0005401235139288474, Final Batch Loss: 0.00015268645074684173\n",
      "Epoch 4356, Loss: 0.00019195766981283668, Final Batch Loss: 1.7578395272721536e-05\n",
      "Epoch 4357, Loss: 0.0005812729559693253, Final Batch Loss: 8.933910066843964e-06\n",
      "Epoch 4358, Loss: 0.005022230470785871, Final Batch Loss: 0.00022474362049251795\n",
      "Epoch 4359, Loss: 0.00010348789874115027, Final Batch Loss: 2.115233291988261e-05\n",
      "Epoch 4360, Loss: 0.00019725603488041088, Final Batch Loss: 8.055286889430135e-05\n",
      "Epoch 4361, Loss: 0.00047019503745104885, Final Batch Loss: 1.3865783330402337e-06\n",
      "Epoch 4362, Loss: 0.0003738493014679989, Final Batch Loss: 2.516600397939328e-05\n",
      "Epoch 4363, Loss: 0.00010252567153656855, Final Batch Loss: 5.77554055780638e-05\n",
      "Epoch 4364, Loss: 0.0001474535292800283, Final Batch Loss: 1.558957046654541e-05\n",
      "Epoch 4365, Loss: 6.518414954825857e-05, Final Batch Loss: 1.1293453781036078e-06\n",
      "Epoch 4366, Loss: 0.00020926885099470383, Final Batch Loss: 1.4179486242937855e-06\n",
      "Epoch 4367, Loss: 0.007121180959074991, Final Batch Loss: 2.0665451302193105e-05\n",
      "Epoch 4368, Loss: 0.0003163503934047185, Final Batch Loss: 0.00014832620217930526\n",
      "Epoch 4369, Loss: 0.003089542071222695, Final Batch Loss: 8.407367317886383e-07\n",
      "Epoch 4370, Loss: 0.0006281967362156138, Final Batch Loss: 0.0005634544068016112\n",
      "Epoch 4371, Loss: 0.00024402958933933405, Final Batch Loss: 1.0621129149512853e-05\n",
      "Epoch 4372, Loss: 0.005785339162684977, Final Batch Loss: 0.005529267713427544\n",
      "Epoch 4373, Loss: 0.0012730128250950656, Final Batch Loss: 1.135620095737977e-06\n",
      "Epoch 4374, Loss: 0.0002872998084058054, Final Batch Loss: 3.0303708626888692e-06\n",
      "Epoch 4375, Loss: 0.002284876783960499, Final Batch Loss: 0.001245644292794168\n",
      "Epoch 4376, Loss: 0.0004552515583782224, Final Batch Loss: 0.00018974817066919059\n",
      "Epoch 4377, Loss: 0.0002549043983890442, Final Batch Loss: 1.4210027984518092e-05\n",
      "Epoch 4378, Loss: 0.020877381794662142, Final Batch Loss: 1.957517042683321e-06\n",
      "Epoch 4379, Loss: 0.0002459118608157951, Final Batch Loss: 1.1669893638099893e-06\n",
      "Epoch 4380, Loss: 0.03581986922552005, Final Batch Loss: 2.7606336061580805e-07\n",
      "Epoch 4381, Loss: 0.02672455618130698, Final Batch Loss: 1.5058003555168398e-07\n",
      "Epoch 4382, Loss: 0.0002840493980329484, Final Batch Loss: 4.328314389567822e-05\n",
      "Epoch 4383, Loss: 0.00012214682283229195, Final Batch Loss: 2.3852255253586918e-05\n",
      "Epoch 4384, Loss: 0.0004252191592968302, Final Batch Loss: 2.6085444915224798e-05\n",
      "Epoch 4385, Loss: 0.0008942680609038689, Final Batch Loss: 3.074340497732919e-07\n",
      "Epoch 4386, Loss: 5.941633025940973e-05, Final Batch Loss: 2.0538398530334234e-05\n",
      "Epoch 4387, Loss: 0.0012666269246039974, Final Batch Loss: 1.882250728613144e-07\n",
      "Epoch 4388, Loss: 8.171966874215286e-05, Final Batch Loss: 0.0\n",
      "Epoch 4389, Loss: 0.0002720334414334502, Final Batch Loss: 2.4904151359805837e-05\n",
      "Epoch 4390, Loss: 0.0011212329191039316, Final Batch Loss: 0.00010913915320998058\n",
      "Epoch 4391, Loss: 0.0004485430918066413, Final Batch Loss: 2.69784595730016e-06\n",
      "Epoch 4392, Loss: 0.001043043717800174, Final Batch Loss: 0.0009436637628823519\n",
      "Epoch 4393, Loss: 0.0008022377696761396, Final Batch Loss: 4.486029138206504e-05\n",
      "Epoch 4394, Loss: 0.00011091320448031183, Final Batch Loss: 2.164562829420902e-06\n",
      "Epoch 4395, Loss: 0.00025170691020548475, Final Batch Loss: 3.764494636016025e-07\n",
      "Epoch 4396, Loss: 0.00043374734559620265, Final Batch Loss: 1.593541855982039e-05\n",
      "Epoch 4397, Loss: 0.007399056543363258, Final Batch Loss: 0.006949917413294315\n",
      "Epoch 4398, Loss: 0.003363684280884627, Final Batch Loss: 7.81103426561458e-06\n",
      "Epoch 4399, Loss: 0.00021134452254045755, Final Batch Loss: 8.370727300643921e-05\n",
      "Epoch 4400, Loss: 0.00012113858065276872, Final Batch Loss: 6.595751619897783e-05\n",
      "Epoch 4401, Loss: 0.001149803375483316, Final Batch Loss: 1.247786440217169e-05\n",
      "Epoch 4402, Loss: 0.00034203174800495617, Final Batch Loss: 0.00019334083481226116\n",
      "Epoch 4403, Loss: 0.00015010400602477603, Final Batch Loss: 6.0661757743218914e-05\n",
      "Epoch 4404, Loss: 0.00021035573513472627, Final Batch Loss: 3.331494326630491e-06\n",
      "Epoch 4405, Loss: 0.0007724892784608528, Final Batch Loss: 0.0005144887836650014\n",
      "Epoch 4406, Loss: 0.00016270672267637565, Final Batch Loss: 7.384518085018499e-06\n",
      "Epoch 4407, Loss: 0.00024881246099539567, Final Batch Loss: 1.2434031305019744e-05\n",
      "Epoch 4408, Loss: 0.00012458167725526437, Final Batch Loss: 2.032821385000716e-06\n",
      "Epoch 4409, Loss: 0.0009981478287954815, Final Batch Loss: 0.0009109392412938178\n",
      "Epoch 4410, Loss: 0.00011942400578845991, Final Batch Loss: 3.0116007110336795e-07\n",
      "Epoch 4411, Loss: 0.00032602301052975236, Final Batch Loss: 1.2360060281935148e-06\n",
      "Epoch 4412, Loss: 7.282117439899594e-05, Final Batch Loss: 5.979174602543935e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4413, Loss: 0.00010595895037113223, Final Batch Loss: 3.785158332902938e-05\n",
      "Epoch 4414, Loss: 0.0017907169253703614, Final Batch Loss: 1.8822370293491986e-06\n",
      "Epoch 4415, Loss: 9.001113721751608e-05, Final Batch Loss: 4.25663311034441e-05\n",
      "Epoch 4416, Loss: 0.003038023569388315, Final Batch Loss: 0.001608693739399314\n",
      "Epoch 4417, Loss: 0.0015283034790627426, Final Batch Loss: 0.00010943325469270349\n",
      "Epoch 4418, Loss: 0.0014931760088074952, Final Batch Loss: 0.00027194441645406187\n",
      "Epoch 4419, Loss: 7.822872781559909e-05, Final Batch Loss: 9.411256485236663e-08\n",
      "Epoch 4420, Loss: 0.0003239134603063576, Final Batch Loss: 0.0001536884665256366\n",
      "Epoch 4421, Loss: 0.00067607296659844, Final Batch Loss: 3.938252484658733e-05\n",
      "Epoch 4422, Loss: 0.0006774642315576784, Final Batch Loss: 0.00022016024740878493\n",
      "Epoch 4423, Loss: 0.001157519654952921, Final Batch Loss: 0.0008516419329680502\n",
      "Epoch 4424, Loss: 0.003260042391048046, Final Batch Loss: 4.9994723667623475e-05\n",
      "Epoch 4425, Loss: 0.0004712417139671743, Final Batch Loss: 0.00019011394761037081\n",
      "Epoch 4426, Loss: 0.00031804881518837647, Final Batch Loss: 4.20980222770595e-06\n",
      "Epoch 4427, Loss: 0.0001911196095534251, Final Batch Loss: 1.1041544894396793e-05\n",
      "Epoch 4428, Loss: 0.0015373342212114949, Final Batch Loss: 0.0011927797459065914\n",
      "Epoch 4429, Loss: 0.000141565373269259, Final Batch Loss: 1.527627136965748e-05\n",
      "Epoch 4430, Loss: 0.0002536488354962785, Final Batch Loss: 9.157452586805448e-05\n",
      "Epoch 4431, Loss: 0.0007428844037349336, Final Batch Loss: 9.673438762547448e-05\n",
      "Epoch 4432, Loss: 9.155496718449285e-05, Final Batch Loss: 3.5134389690938406e-06\n",
      "Epoch 4433, Loss: 6.965197019326297e-05, Final Batch Loss: 1.4116805004960042e-06\n",
      "Epoch 4434, Loss: 0.00018322316793728533, Final Batch Loss: 1.2611050124178291e-06\n",
      "Epoch 4435, Loss: 0.00038513809886353556, Final Batch Loss: 2.3316881197388284e-05\n",
      "Epoch 4436, Loss: 0.003949417852709303, Final Batch Loss: 2.469001992722042e-05\n",
      "Epoch 4437, Loss: 0.00012111546607229684, Final Batch Loss: 2.2147680738271447e-06\n",
      "Epoch 4438, Loss: 0.0004772114989464171, Final Batch Loss: 0.00035275600384920835\n",
      "Epoch 4439, Loss: 0.0011071984026784776, Final Batch Loss: 1.482504558225628e-05\n",
      "Epoch 4440, Loss: 0.0007415562999995018, Final Batch Loss: 1.417959083482856e-06\n",
      "Epoch 4441, Loss: 0.0010016162123065442, Final Batch Loss: 0.0008298833854496479\n",
      "Epoch 4442, Loss: 0.0002842772682924988, Final Batch Loss: 4.7032113798195496e-05\n",
      "Epoch 4443, Loss: 0.00046757063864788506, Final Batch Loss: 7.365679266513325e-06\n",
      "Epoch 4444, Loss: 6.59638066053958e-05, Final Batch Loss: 1.7128298850366264e-06\n",
      "Epoch 4445, Loss: 0.00016846053313201992, Final Batch Loss: 8.093268661468755e-06\n",
      "Epoch 4446, Loss: 0.0004295037033443805, Final Batch Loss: 1.9190480088582262e-05\n",
      "Epoch 4447, Loss: 0.0018893797641794663, Final Batch Loss: 9.434334060642868e-05\n",
      "Epoch 4448, Loss: 0.00020876118878732086, Final Batch Loss: 6.129618213890353e-06\n",
      "Epoch 4449, Loss: 0.0012802564460798749, Final Batch Loss: 4.843474926019553e-06\n",
      "Epoch 4450, Loss: 0.0002910000821430003, Final Batch Loss: 2.6395513486932032e-05\n",
      "Epoch 4451, Loss: 0.0008438399800070329, Final Batch Loss: 2.6980733309756033e-05\n",
      "Epoch 4452, Loss: 0.005538442749980277, Final Batch Loss: 1.1230689551666728e-06\n",
      "Epoch 4453, Loss: 0.038749009042646776, Final Batch Loss: 8.972048703981272e-07\n",
      "Epoch 4454, Loss: 7.337409806495998e-05, Final Batch Loss: 2.8684009521384723e-05\n",
      "Epoch 4455, Loss: 0.000674308541249502, Final Batch Loss: 9.097510087485716e-07\n",
      "Epoch 4456, Loss: 0.0017871434320113622, Final Batch Loss: 0.001617340836673975\n",
      "Epoch 4457, Loss: 0.017077134129976912, Final Batch Loss: 7.1836848292150535e-06\n",
      "Epoch 4458, Loss: 0.00010935172940662596, Final Batch Loss: 3.0870476621203125e-05\n",
      "Epoch 4459, Loss: 0.00030826350834445293, Final Batch Loss: 4.203683090509003e-07\n",
      "Epoch 4460, Loss: 0.0004128035743633518, Final Batch Loss: 0.00034964445512741804\n",
      "Epoch 4461, Loss: 0.0005581232726399321, Final Batch Loss: 4.8615493142278865e-05\n",
      "Epoch 4462, Loss: 0.00027621361823548796, Final Batch Loss: 8.676474863023032e-06\n",
      "Epoch 4463, Loss: 0.001487094332333072, Final Batch Loss: 0.001438883482478559\n",
      "Epoch 4464, Loss: 0.0007960621792335587, Final Batch Loss: 3.011575699929381e-06\n",
      "Epoch 4465, Loss: 0.0003193875433566973, Final Batch Loss: 2.1332169808374601e-07\n",
      "Epoch 4466, Loss: 0.006931733179953881, Final Batch Loss: 4.9376103561371565e-06\n",
      "Epoch 4467, Loss: 0.012387172983018502, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4468, Loss: 0.01035516786032531, Final Batch Loss: 2.3902930479380302e-05\n",
      "Epoch 4469, Loss: 0.0009781143999134656, Final Batch Loss: 0.0007041096687316895\n",
      "Epoch 4470, Loss: 0.0002815216503222473, Final Batch Loss: 1.5846177120693028e-05\n",
      "Epoch 4471, Loss: 0.00034449068785136205, Final Batch Loss: 1.317575453185782e-07\n",
      "Epoch 4472, Loss: 0.0005735934391850606, Final Batch Loss: 0.0004720904980786145\n",
      "Epoch 4473, Loss: 0.015531598581674189, Final Batch Loss: 6.198583378136391e-06\n",
      "Epoch 4474, Loss: 0.00033064055742215714, Final Batch Loss: 6.110910817369586e-06\n",
      "Epoch 4475, Loss: 0.00045843704356229864, Final Batch Loss: 7.027047104202211e-07\n",
      "Epoch 4476, Loss: 0.0011292165727354586, Final Batch Loss: 0.00019734229135792702\n",
      "Epoch 4477, Loss: 0.000936124284635298, Final Batch Loss: 0.00021644686057697982\n",
      "Epoch 4478, Loss: 0.02173131619247215, Final Batch Loss: 3.7142094697628636e-06\n",
      "Epoch 4479, Loss: 0.0005051751249993686, Final Batch Loss: 0.00030073043308220804\n",
      "Epoch 4480, Loss: 0.1417245329794241, Final Batch Loss: 0.1411864310503006\n",
      "Epoch 4481, Loss: 0.03302549802174326, Final Batch Loss: 5.623784090857953e-05\n",
      "Epoch 4482, Loss: 0.007162315605000913, Final Batch Loss: 3.0743044590053614e-06\n",
      "Epoch 4483, Loss: 0.01762125501409173, Final Batch Loss: 0.005418398883193731\n",
      "Epoch 4484, Loss: 0.0016207636128910963, Final Batch Loss: 2.6664840788725996e-06\n",
      "Epoch 4485, Loss: 0.0021661505816155113, Final Batch Loss: 0.0014809845015406609\n",
      "Epoch 4486, Loss: 0.002381806038272316, Final Batch Loss: 6.650608952440962e-07\n",
      "Epoch 4487, Loss: 0.00925741414539516, Final Batch Loss: 0.0032806426752358675\n",
      "Epoch 4488, Loss: 0.008812816406134516, Final Batch Loss: 0.0001645763695705682\n",
      "Epoch 4489, Loss: 0.007873279202613048, Final Batch Loss: 4.305264155846089e-05\n",
      "Epoch 4490, Loss: 0.0037721593253081664, Final Batch Loss: 0.003104857634752989\n",
      "Epoch 4491, Loss: 0.0018101423120242544, Final Batch Loss: 8.88383510755375e-06\n",
      "Epoch 4492, Loss: 0.004988651082385331, Final Batch Loss: 0.00022014183923602104\n",
      "Epoch 4493, Loss: 0.03485830219648278, Final Batch Loss: 5.144807460055745e-07\n",
      "Epoch 4494, Loss: 0.0014009785509188077, Final Batch Loss: 1.011304175335681e-05\n",
      "Epoch 4495, Loss: 0.01572385521558317, Final Batch Loss: 4.366719622339588e-06\n",
      "Epoch 4496, Loss: 0.0007369982831733068, Final Batch Loss: 2.369334652030375e-05\n",
      "Epoch 4497, Loss: 0.06320177323868847, Final Batch Loss: 3.372344872332178e-05\n",
      "Epoch 4498, Loss: 0.0013105441321386024, Final Batch Loss: 0.0007201358093880117\n",
      "Epoch 4499, Loss: 0.000678063877785462, Final Batch Loss: 2.827440584951546e-05\n",
      "Epoch 4500, Loss: 0.01038355051241524, Final Batch Loss: 2.2764490495319478e-05\n",
      "Epoch 4501, Loss: 0.01342907758862566, Final Batch Loss: 1.4963195098971482e-05\n",
      "Epoch 4502, Loss: 0.018012250334322744, Final Batch Loss: 1.4880349226586986e-05\n",
      "Epoch 4503, Loss: 0.0023024057645670837, Final Batch Loss: 1.851821980380919e-05\n",
      "Epoch 4504, Loss: 0.032573361267168366, Final Batch Loss: 1.0339394975744653e-05\n",
      "Epoch 4505, Loss: 0.006098667304286209, Final Batch Loss: 4.423111931828316e-06\n",
      "Epoch 4506, Loss: 0.0030726169934496284, Final Batch Loss: 0.00021381647093221545\n",
      "Epoch 4507, Loss: 0.0036081714141573684, Final Batch Loss: 1.1920864153580624e-06\n",
      "Epoch 4508, Loss: 0.05909634637646377, Final Batch Loss: 0.05828486755490303\n",
      "Epoch 4509, Loss: 0.0314812351425644, Final Batch Loss: 0.0004876266175415367\n",
      "Epoch 4510, Loss: 0.06092242579325102, Final Batch Loss: 0.0002808576391544193\n",
      "Epoch 4511, Loss: 0.0028705811128020287, Final Batch Loss: 0.0005688892561011016\n",
      "Epoch 4512, Loss: 0.003971636644564569, Final Batch Loss: 0.0014873401960358024\n",
      "Epoch 4513, Loss: 0.018094632192514837, Final Batch Loss: 0.0001607752637937665\n",
      "Epoch 4514, Loss: 0.01209806141196168, Final Batch Loss: 5.119622437632643e-05\n",
      "Epoch 4515, Loss: 0.014779121498577297, Final Batch Loss: 0.002523397095501423\n",
      "Epoch 4516, Loss: 0.007253053561726119, Final Batch Loss: 6.952808325877413e-05\n",
      "Epoch 4517, Loss: 0.0025823901523835957, Final Batch Loss: 0.0011647868668660522\n",
      "Epoch 4518, Loss: 0.003173782071826281, Final Batch Loss: 5.367356425267644e-05\n",
      "Epoch 4519, Loss: 0.006197054870426655, Final Batch Loss: 0.004832773003727198\n",
      "Epoch 4520, Loss: 0.001353012219624361, Final Batch Loss: 4.228416582918726e-05\n",
      "Epoch 4521, Loss: 0.0062796103447908536, Final Batch Loss: 4.863076901528984e-05\n",
      "Epoch 4522, Loss: 0.0045456624357029796, Final Batch Loss: 0.002716285875067115\n",
      "Epoch 4523, Loss: 0.002236741071101278, Final Batch Loss: 0.0011576839024201035\n",
      "Epoch 4524, Loss: 0.0016123951147619664, Final Batch Loss: 1.6877395410119789e-06\n",
      "Epoch 4525, Loss: 0.0013339459227381667, Final Batch Loss: 1.2046338042637217e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4526, Loss: 0.004161923716310412, Final Batch Loss: 0.0024876301176846027\n",
      "Epoch 4527, Loss: 0.12646779645001516, Final Batch Loss: 0.11984502524137497\n",
      "Epoch 4528, Loss: 0.004891301796305925, Final Batch Loss: 0.0013840701431035995\n",
      "Epoch 4529, Loss: 0.039240625221282244, Final Batch Loss: 0.011510021984577179\n",
      "Epoch 4530, Loss: 0.034421845106408, Final Batch Loss: 0.0011228236835449934\n",
      "Epoch 4531, Loss: 0.03379515504866504, Final Batch Loss: 5.301483270159224e-06\n",
      "Epoch 4532, Loss: 0.0442059182387311, Final Batch Loss: 0.00017752012354321778\n",
      "Epoch 4533, Loss: 0.04416179787222063, Final Batch Loss: 3.4821205190382898e-06\n",
      "Epoch 4534, Loss: 0.017808279953897, Final Batch Loss: 9.973510168492794e-05\n",
      "Epoch 4535, Loss: 0.10608196933753788, Final Batch Loss: 0.09101996570825577\n",
      "Epoch 4536, Loss: 0.024100667953462107, Final Batch Loss: 2.9060331144137308e-05\n",
      "Epoch 4537, Loss: 0.05919541139155626, Final Batch Loss: 0.035427581518888474\n",
      "Epoch 4538, Loss: 0.009050880675204098, Final Batch Loss: 0.00014136277604848146\n",
      "Epoch 4539, Loss: 0.00322663025951897, Final Batch Loss: 1.254826997865166e-06\n",
      "Epoch 4540, Loss: 0.004602206958224997, Final Batch Loss: 0.0019826635252684355\n",
      "Epoch 4541, Loss: 0.002045762215857394, Final Batch Loss: 4.5867825974710286e-05\n",
      "Epoch 4542, Loss: 0.045494997772038914, Final Batch Loss: 0.00015126158541534096\n",
      "Epoch 4543, Loss: 0.005733220517868176, Final Batch Loss: 0.00010592382750473917\n",
      "Epoch 4544, Loss: 0.011963189172092825, Final Batch Loss: 0.0020847280975431204\n",
      "Epoch 4545, Loss: 0.003779428865527734, Final Batch Loss: 0.00036620479659177363\n",
      "Epoch 4546, Loss: 0.0029826918616890907, Final Batch Loss: 0.0012003224110230803\n",
      "Epoch 4547, Loss: 0.008771112537942827, Final Batch Loss: 0.00573106249794364\n",
      "Epoch 4548, Loss: 0.00229783440954634, Final Batch Loss: 5.719272667192854e-05\n",
      "Epoch 4549, Loss: 0.0017675842755124904, Final Batch Loss: 7.375612767646089e-05\n",
      "Epoch 4550, Loss: 0.00215405264407309, Final Batch Loss: 1.2378187420836184e-05\n",
      "Epoch 4551, Loss: 0.002371261129155755, Final Batch Loss: 0.0007948743877932429\n",
      "Epoch 4552, Loss: 0.0051154972170479596, Final Batch Loss: 0.0034170884173363447\n",
      "Epoch 4553, Loss: 0.017649601360972156, Final Batch Loss: 2.581571061455179e-05\n",
      "Epoch 4554, Loss: 0.001325574063230306, Final Batch Loss: 0.0005023932899348438\n",
      "Epoch 4555, Loss: 0.002303806584677659, Final Batch Loss: 0.00022624350094702095\n",
      "Epoch 4556, Loss: 0.003563132631825283, Final Batch Loss: 0.00046503214980475605\n",
      "Epoch 4557, Loss: 0.001377408996631857, Final Batch Loss: 8.017478830879554e-05\n",
      "Epoch 4558, Loss: 0.001803139293770073, Final Batch Loss: 4.927745249005966e-05\n",
      "Epoch 4559, Loss: 0.00163042775602662, Final Batch Loss: 2.1509800717467442e-05\n",
      "Epoch 4560, Loss: 0.0017031363968271762, Final Batch Loss: 0.0007662505377084017\n",
      "Epoch 4561, Loss: 0.005307340633407875, Final Batch Loss: 1.2384773981466424e-05\n",
      "Epoch 4562, Loss: 0.001495880846050568, Final Batch Loss: 0.00010801736789289862\n",
      "Epoch 4563, Loss: 0.006452783796703443, Final Batch Loss: 0.0006817388930357993\n",
      "Epoch 4564, Loss: 0.0017726820296957158, Final Batch Loss: 4.7115048801060766e-05\n",
      "Epoch 4565, Loss: 0.000765871587645961, Final Batch Loss: 3.6234803701518103e-05\n",
      "Epoch 4566, Loss: 0.0013724288291996345, Final Batch Loss: 3.192869189660996e-05\n",
      "Epoch 4567, Loss: 0.003415439830860123, Final Batch Loss: 0.0024014338850975037\n",
      "Epoch 4568, Loss: 0.0014517481963594037, Final Batch Loss: 5.728105406888062e-06\n",
      "Epoch 4569, Loss: 0.0032871107396204025, Final Batch Loss: 0.0018189833499491215\n",
      "Epoch 4570, Loss: 0.0013672966888407245, Final Batch Loss: 0.0001432814315194264\n",
      "Epoch 4571, Loss: 0.00096353878507216, Final Batch Loss: 1.0985620974679478e-05\n",
      "Epoch 4572, Loss: 0.002192599873524159, Final Batch Loss: 0.0003442246816121042\n",
      "Epoch 4573, Loss: 0.015639497710253636, Final Batch Loss: 7.258990990521852e-06\n",
      "Epoch 4574, Loss: 0.0008745767281652661, Final Batch Loss: 2.7240241252002306e-05\n",
      "Epoch 4575, Loss: 0.002164012890716549, Final Batch Loss: 0.0001026392201310955\n",
      "Epoch 4576, Loss: 0.002775996850687079, Final Batch Loss: 0.0023132716305553913\n",
      "Epoch 4577, Loss: 0.000650993639283115, Final Batch Loss: 3.561389530659653e-05\n",
      "Epoch 4578, Loss: 0.0011178258080519754, Final Batch Loss: 2.6351497695031867e-07\n",
      "Epoch 4579, Loss: 0.0012210129820005022, Final Batch Loss: 8.093660426311544e-07\n",
      "Epoch 4580, Loss: 0.0007741019026070717, Final Batch Loss: 1.3833424418407958e-05\n",
      "Epoch 4581, Loss: 0.0048033792069190895, Final Batch Loss: 2.2586993964068824e-07\n",
      "Epoch 4582, Loss: 0.007078883412759751, Final Batch Loss: 0.0007747815106995404\n",
      "Epoch 4583, Loss: 0.00107444199238671, Final Batch Loss: 2.6079615054186434e-05\n",
      "Epoch 4584, Loss: 0.0007170097796915798, Final Batch Loss: 2.9722707040491514e-05\n",
      "Epoch 4585, Loss: 0.0012398568142089061, Final Batch Loss: 0.0005462369881570339\n",
      "Epoch 4586, Loss: 0.000832600511785131, Final Batch Loss: 6.974583811825141e-05\n",
      "Epoch 4587, Loss: 0.001643472511204891, Final Batch Loss: 6.085917993914336e-05\n",
      "Epoch 4588, Loss: 0.0010180774352193112, Final Batch Loss: 1.2917918866151012e-05\n",
      "Epoch 4589, Loss: 0.0012161063859821297, Final Batch Loss: 0.00010062216460937634\n",
      "Epoch 4590, Loss: 0.00700819306075573, Final Batch Loss: 0.005526428576558828\n",
      "Epoch 4591, Loss: 0.01533882321746205, Final Batch Loss: 9.780651453183964e-06\n",
      "Epoch 4592, Loss: 0.001018825560095138, Final Batch Loss: 1.635458283999469e-05\n",
      "Epoch 4593, Loss: 0.00042127297274419107, Final Batch Loss: 4.919639104628004e-05\n",
      "Epoch 4594, Loss: 0.005728324977042121, Final Batch Loss: 4.391912966639211e-07\n",
      "Epoch 4595, Loss: 0.0007940272903397272, Final Batch Loss: 4.724336122308159e-06\n",
      "Epoch 4596, Loss: 0.004533718805760145, Final Batch Loss: 0.0003833019291050732\n",
      "Epoch 4597, Loss: 0.0013836837388225831, Final Batch Loss: 0.00010645201109582558\n",
      "Epoch 4598, Loss: 0.009831929026404396, Final Batch Loss: 3.7361838622018695e-05\n",
      "Epoch 4599, Loss: 0.0030370676540769637, Final Batch Loss: 0.00044869002886116505\n",
      "Epoch 4600, Loss: 0.012587564706336707, Final Batch Loss: 0.003871685592457652\n",
      "Epoch 4601, Loss: 0.0005561998223129194, Final Batch Loss: 5.245921420282684e-05\n",
      "Epoch 4602, Loss: 0.0030920661811251193, Final Batch Loss: 0.0002579654974397272\n",
      "Epoch 4603, Loss: 0.002327047106518876, Final Batch Loss: 0.0012970727402716875\n",
      "Epoch 4604, Loss: 0.004175710491836071, Final Batch Loss: 0.00013097713235765696\n",
      "Epoch 4605, Loss: 0.0020931206818204373, Final Batch Loss: 0.0017678113654255867\n",
      "Epoch 4606, Loss: 0.004156780254561454, Final Batch Loss: 0.0031427559442818165\n",
      "Epoch 4607, Loss: 0.0013611316371680005, Final Batch Loss: 3.0294946554931812e-05\n",
      "Epoch 4608, Loss: 0.007596994581035688, Final Batch Loss: 8.394306860282086e-06\n",
      "Epoch 4609, Loss: 0.0032874698808882385, Final Batch Loss: 0.002215399406850338\n",
      "Epoch 4610, Loss: 0.000881728163221851, Final Batch Loss: 0.00027240291819907725\n",
      "Epoch 4611, Loss: 0.005863052174390759, Final Batch Loss: 7.12088294676505e-05\n",
      "Epoch 4612, Loss: 0.0005845132018293953, Final Batch Loss: 1.5720759620307945e-05\n",
      "Epoch 4613, Loss: 0.0019254101334809093, Final Batch Loss: 2.1605357687803917e-05\n",
      "Epoch 4614, Loss: 0.0008857962857291568, Final Batch Loss: 4.335451012593694e-05\n",
      "Epoch 4615, Loss: 0.0015598259797116043, Final Batch Loss: 2.6878480639425106e-05\n",
      "Epoch 4616, Loss: 0.0007235306111397222, Final Batch Loss: 0.0001440484047634527\n",
      "Epoch 4617, Loss: 0.0027428493267507292, Final Batch Loss: 7.52763808122836e-05\n",
      "Epoch 4618, Loss: 0.0006530124460368825, Final Batch Loss: 4.071881903655594e-06\n",
      "Epoch 4619, Loss: 0.0002887960858970473, Final Batch Loss: 6.39314976069727e-06\n",
      "Epoch 4620, Loss: 0.004112124417588348, Final Batch Loss: 1.801687540137209e-05\n",
      "Epoch 4621, Loss: 0.0019069179870712105, Final Batch Loss: 3.729957461473532e-05\n",
      "Epoch 4622, Loss: 0.0002986720355693251, Final Batch Loss: 0.00011096112575614825\n",
      "Epoch 4623, Loss: 0.0004313871977501549, Final Batch Loss: 3.71683927369304e-05\n",
      "Epoch 4624, Loss: 0.00018260416618431918, Final Batch Loss: 3.075397034990601e-05\n",
      "Epoch 4625, Loss: 0.0006610963610000908, Final Batch Loss: 0.0001975592749658972\n",
      "Epoch 4626, Loss: 0.0010951327058137394, Final Batch Loss: 7.874676521169022e-05\n",
      "Epoch 4627, Loss: 0.0010964902248815633, Final Batch Loss: 2.0081504771951586e-05\n",
      "Epoch 4628, Loss: 0.00130090897619084, Final Batch Loss: 2.4594355636509135e-06\n",
      "Epoch 4629, Loss: 0.0005560625968428212, Final Batch Loss: 1.1374485438864212e-05\n",
      "Epoch 4630, Loss: 0.0006699716941511724, Final Batch Loss: 2.7512043743627146e-05\n",
      "Epoch 4631, Loss: 0.0024266718100989237, Final Batch Loss: 0.0001299519935855642\n",
      "Epoch 4632, Loss: 0.0009329642034572316, Final Batch Loss: 2.895519537560176e-05\n",
      "Epoch 4633, Loss: 0.00036012464988743886, Final Batch Loss: 0.00015487342898268253\n",
      "Epoch 4634, Loss: 0.0011317625807123477, Final Batch Loss: 7.40348127692414e-07\n",
      "Epoch 4635, Loss: 0.11822670024412218, Final Batch Loss: 0.11750100553035736\n",
      "Epoch 4636, Loss: 0.000418080497183837, Final Batch Loss: 2.8480288165155798e-05\n",
      "Epoch 4637, Loss: 0.0005725187947973609, Final Batch Loss: 0.0001101704256143421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4638, Loss: 0.0005411033446307556, Final Batch Loss: 9.72492898654309e-07\n",
      "Epoch 4639, Loss: 0.0004106286887690658, Final Batch Loss: 1.0025754818343557e-05\n",
      "Epoch 4640, Loss: 0.004540960454050946, Final Batch Loss: 1.9575204532884527e-06\n",
      "Epoch 4641, Loss: 0.0013784910770482384, Final Batch Loss: 8.157613774528727e-05\n",
      "Epoch 4642, Loss: 0.0005146488224454515, Final Batch Loss: 4.31656053478946e-06\n",
      "Epoch 4643, Loss: 0.001858105188148329, Final Batch Loss: 4.571548561216332e-05\n",
      "Epoch 4644, Loss: 0.008214912289986387, Final Batch Loss: 0.0026001608930528164\n",
      "Epoch 4645, Loss: 0.0005054292159911711, Final Batch Loss: 5.501459600054659e-05\n",
      "Epoch 4646, Loss: 0.0005601103694061749, Final Batch Loss: 0.00014196039410308003\n",
      "Epoch 4647, Loss: 0.00044260641880100593, Final Batch Loss: 6.685128028038889e-05\n",
      "Epoch 4648, Loss: 0.015209081664579571, Final Batch Loss: 2.4413771825493313e-05\n",
      "Epoch 4649, Loss: 0.00274837261531502, Final Batch Loss: 0.0009341362747363746\n",
      "Epoch 4650, Loss: 0.0007735373801551759, Final Batch Loss: 0.00017978243704419583\n",
      "Epoch 4651, Loss: 0.00334270614257548, Final Batch Loss: 0.00024425401352345943\n",
      "Epoch 4652, Loss: 0.002178520429879427, Final Batch Loss: 0.00015588654787279665\n",
      "Epoch 4653, Loss: 0.0006366964807966724, Final Batch Loss: 4.756179987452924e-05\n",
      "Epoch 4654, Loss: 0.00028959040628251387, Final Batch Loss: 4.266362338967156e-06\n",
      "Epoch 4655, Loss: 0.000704094854881987, Final Batch Loss: 0.00011783611262217164\n",
      "Epoch 4656, Loss: 0.0003031289088539779, Final Batch Loss: 3.883644239977002e-06\n",
      "Epoch 4657, Loss: 0.0009750536919455044, Final Batch Loss: 7.573843322461471e-05\n",
      "Epoch 4658, Loss: 0.0011497473606141284, Final Batch Loss: 0.0001178565580630675\n",
      "Epoch 4659, Loss: 0.00030570538865504204, Final Batch Loss: 5.546263764699688e-06\n",
      "Epoch 4660, Loss: 0.0003319955565075361, Final Batch Loss: 1.668918002906139e-06\n",
      "Epoch 4661, Loss: 0.002042820655333344, Final Batch Loss: 0.00020725598733406514\n",
      "Epoch 4662, Loss: 0.002570562301116297, Final Batch Loss: 0.0024546582717448473\n",
      "Epoch 4663, Loss: 0.0002459124370943755, Final Batch Loss: 4.7768669901415706e-05\n",
      "Epoch 4664, Loss: 0.0022478369660348108, Final Batch Loss: 4.172268290858483e-06\n",
      "Epoch 4665, Loss: 0.001178601258288836, Final Batch Loss: 0.0008606346091255546\n",
      "Epoch 4666, Loss: 0.0003052378606298589, Final Batch Loss: 1.518761655461276e-05\n",
      "Epoch 4667, Loss: 0.00046276155626401305, Final Batch Loss: 1.9039507606066763e-05\n",
      "Epoch 4668, Loss: 0.0016538306808797643, Final Batch Loss: 3.0479321139864624e-05\n",
      "Epoch 4669, Loss: 0.0012750453943226603, Final Batch Loss: 1.0200969882134814e-05\n",
      "Epoch 4670, Loss: 0.002506148075553938, Final Batch Loss: 1.8219512639916502e-05\n",
      "Epoch 4671, Loss: 0.0067486123370343876, Final Batch Loss: 1.1920921849650767e-07\n",
      "Epoch 4672, Loss: 0.0007965155721194606, Final Batch Loss: 1.7881295661936747e-06\n",
      "Epoch 4673, Loss: 0.0004978405346491854, Final Batch Loss: 1.5371630297522643e-06\n",
      "Epoch 4674, Loss: 0.0018724281445656743, Final Batch Loss: 1.3677610013473895e-06\n",
      "Epoch 4675, Loss: 0.00030868532485328615, Final Batch Loss: 3.1489384127780795e-05\n",
      "Epoch 4676, Loss: 0.002027225596975768, Final Batch Loss: 0.00010048359399661422\n",
      "Epoch 4677, Loss: 0.0007814468517608475, Final Batch Loss: 1.5646201063646004e-05\n",
      "Epoch 4678, Loss: 0.0018482507002772763, Final Batch Loss: 0.0014089212054386735\n",
      "Epoch 4679, Loss: 0.000776788845541887, Final Batch Loss: 0.00028186888084746897\n",
      "Epoch 4680, Loss: 0.00021531229504034854, Final Batch Loss: 1.7729922547005117e-05\n",
      "Epoch 4681, Loss: 0.0007818005351509782, Final Batch Loss: 5.289034561428707e-06\n",
      "Epoch 4682, Loss: 0.002079135832900647, Final Batch Loss: 4.881192580796778e-06\n",
      "Epoch 4683, Loss: 0.0005128524426254444, Final Batch Loss: 3.082213515881449e-05\n",
      "Epoch 4684, Loss: 0.037623701800839626, Final Batch Loss: 2.327675247215666e-06\n",
      "Epoch 4685, Loss: 0.0005474288600453292, Final Batch Loss: 1.3651541848958004e-05\n",
      "Epoch 4686, Loss: 0.004553222757067488, Final Batch Loss: 2.152000206478988e-06\n",
      "Epoch 4687, Loss: 0.002226077514933422, Final Batch Loss: 5.46615628991276e-05\n",
      "Epoch 4688, Loss: 0.00045134409083402716, Final Batch Loss: 1.7409704014426097e-05\n",
      "Epoch 4689, Loss: 0.001497767192631727, Final Batch Loss: 8.224942575907335e-06\n",
      "Epoch 4690, Loss: 0.00788339922837622, Final Batch Loss: 1.1588066627155058e-05\n",
      "Epoch 4691, Loss: 0.003716846429142606, Final Batch Loss: 3.0994083317636978e-06\n",
      "Epoch 4692, Loss: 0.0007620616088388488, Final Batch Loss: 3.66990570910275e-05\n",
      "Epoch 4693, Loss: 0.002233783138308354, Final Batch Loss: 7.566477961518103e-06\n",
      "Epoch 4694, Loss: 0.0005974454470560886, Final Batch Loss: 1.040848292177543e-05\n",
      "Epoch 4695, Loss: 0.0010729125278885476, Final Batch Loss: 1.6757599951233715e-05\n",
      "Epoch 4696, Loss: 0.0027877698012162, Final Batch Loss: 0.0022719979751855135\n",
      "Epoch 4697, Loss: 0.00029383312357822433, Final Batch Loss: 8.718255412532017e-05\n",
      "Epoch 4698, Loss: 0.0051298583566676825, Final Batch Loss: 0.0007288003689609468\n",
      "Epoch 4699, Loss: 0.00013239871805126313, Final Batch Loss: 2.5075247322092764e-05\n",
      "Epoch 4700, Loss: 0.003147352981613949, Final Batch Loss: 0.0003471295058261603\n",
      "Epoch 4701, Loss: 0.013518638792447746, Final Batch Loss: 0.008399661630392075\n",
      "Epoch 4702, Loss: 0.0030635001021437347, Final Batch Loss: 0.0007591503672301769\n",
      "Epoch 4703, Loss: 0.005735958322475199, Final Batch Loss: 9.215635509463027e-05\n",
      "Epoch 4704, Loss: 0.0016836847207741812, Final Batch Loss: 0.00017140434647444636\n",
      "Epoch 4705, Loss: 0.002086668373522116, Final Batch Loss: 2.0201183360768482e-05\n",
      "Epoch 4706, Loss: 0.009922058205120265, Final Batch Loss: 0.009188327938318253\n",
      "Epoch 4707, Loss: 0.0004201909323455766, Final Batch Loss: 0.00012578048335853964\n",
      "Epoch 4708, Loss: 0.002349090180814528, Final Batch Loss: 4.843554506805958e-06\n",
      "Epoch 4709, Loss: 0.01700756352965982, Final Batch Loss: 1.413518202753039e-05\n",
      "Epoch 4710, Loss: 0.0008125689200824127, Final Batch Loss: 0.00022594688925892115\n",
      "Epoch 4711, Loss: 0.003446591530519072, Final Batch Loss: 1.2522701581474394e-05\n",
      "Epoch 4712, Loss: 0.0004846801166422665, Final Batch Loss: 2.0732986740767956e-05\n",
      "Epoch 4713, Loss: 0.0021533398830797523, Final Batch Loss: 0.00026228968636132777\n",
      "Epoch 4714, Loss: 0.0006263682578264707, Final Batch Loss: 1.5999091829144163e-06\n",
      "Epoch 4715, Loss: 0.0023685168007432367, Final Batch Loss: 9.937607501342427e-06\n",
      "Epoch 4716, Loss: 0.0003342709314893, Final Batch Loss: 2.2214742784854025e-05\n",
      "Epoch 4717, Loss: 0.000241835402448487, Final Batch Loss: 1.0953624041576404e-05\n",
      "Epoch 4718, Loss: 0.0002174333876610035, Final Batch Loss: 1.6925123418332078e-05\n",
      "Epoch 4719, Loss: 0.0019768533877595473, Final Batch Loss: 3.2625159747112775e-06\n",
      "Epoch 4720, Loss: 0.0006364979781210423, Final Batch Loss: 0.00033777582575567067\n",
      "Epoch 4721, Loss: 0.00010333566387998872, Final Batch Loss: 2.6370886189397424e-05\n",
      "Epoch 4722, Loss: 0.0007460242486558855, Final Batch Loss: 0.00019309397612232715\n",
      "Epoch 4723, Loss: 0.008731523415463016, Final Batch Loss: 6.8949334490753245e-06\n",
      "Epoch 4724, Loss: 0.0008451069675174949, Final Batch Loss: 7.384538093901938e-06\n",
      "Epoch 4725, Loss: 0.0017537963258291711, Final Batch Loss: 1.4059126442589331e-05\n",
      "Epoch 4726, Loss: 0.0007424301438732073, Final Batch Loss: 0.00013573997421190143\n",
      "Epoch 4727, Loss: 0.0003228072091587819, Final Batch Loss: 0.00012871478975284845\n",
      "Epoch 4728, Loss: 0.0005491558040375821, Final Batch Loss: 1.138015795731917e-05\n",
      "Epoch 4729, Loss: 0.00390413310014992, Final Batch Loss: 0.0037547245156019926\n",
      "Epoch 4730, Loss: 0.0007334179940698959, Final Batch Loss: 6.5874887695827056e-06\n",
      "Epoch 4731, Loss: 0.00025127009121206356, Final Batch Loss: 1.0602906513668131e-05\n",
      "Epoch 4732, Loss: 0.0007329754716920434, Final Batch Loss: 2.490455335646402e-05\n",
      "Epoch 4733, Loss: 0.00013219244135598274, Final Batch Loss: 5.960449698250159e-07\n",
      "Epoch 4734, Loss: 0.003462412190856412, Final Batch Loss: 7.570158049929887e-05\n",
      "Epoch 4735, Loss: 0.0005144108308741124, Final Batch Loss: 1.7923792256624438e-05\n",
      "Epoch 4736, Loss: 0.00019965199135185685, Final Batch Loss: 1.8087461285176687e-05\n",
      "Epoch 4737, Loss: 0.0004503613818087615, Final Batch Loss: 8.088566391961649e-05\n",
      "Epoch 4738, Loss: 0.0024231986608356237, Final Batch Loss: 0.00023121637059375644\n",
      "Epoch 4739, Loss: 0.0007921048782009166, Final Batch Loss: 0.00015767848526593298\n",
      "Epoch 4740, Loss: 0.00022069998249207856, Final Batch Loss: 9.241140105586965e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4741, Loss: 0.00020556280651362613, Final Batch Loss: 4.5173401304055005e-06\n",
      "Epoch 4742, Loss: 0.0011228289713471895, Final Batch Loss: 1.4566749086952768e-05\n",
      "Epoch 4743, Loss: 0.01233058291109046, Final Batch Loss: 0.0041228593327105045\n",
      "Epoch 4744, Loss: 0.0006123665771156084, Final Batch Loss: 1.3638968084705994e-05\n",
      "Epoch 4745, Loss: 0.0009320639219367877, Final Batch Loss: 0.00019568846619222313\n",
      "Epoch 4746, Loss: 0.0007699498382862657, Final Batch Loss: 4.285146133042872e-06\n",
      "Epoch 4747, Loss: 0.0004407842097862158, Final Batch Loss: 3.3574997360119596e-05\n",
      "Epoch 4748, Loss: 0.0001686388877715217, Final Batch Loss: 1.7157706679427065e-05\n",
      "Epoch 4749, Loss: 0.0020020193260279484, Final Batch Loss: 0.0016144460532814264\n",
      "Epoch 4750, Loss: 0.00037638067715306534, Final Batch Loss: 1.3765008588961791e-05\n",
      "Epoch 4751, Loss: 0.0014628787098445173, Final Batch Loss: 2.484542619640706e-06\n",
      "Epoch 4752, Loss: 0.00575296243550838, Final Batch Loss: 0.0004498915805015713\n",
      "Epoch 4753, Loss: 0.0004648260619433131, Final Batch Loss: 0.00011005534179275855\n",
      "Epoch 4754, Loss: 0.02389164175838232, Final Batch Loss: 2.957618562504649e-05\n",
      "Epoch 4755, Loss: 0.00041905864327418385, Final Batch Loss: 1.3983687495056074e-05\n",
      "Epoch 4756, Loss: 0.0007180746001722582, Final Batch Loss: 7.5600805757858325e-06\n",
      "Epoch 4757, Loss: 0.002231687816674821, Final Batch Loss: 0.00015502092719543725\n",
      "Epoch 4758, Loss: 0.00031291051709558815, Final Batch Loss: 0.00013890385162085295\n",
      "Epoch 4759, Loss: 0.00042115987207580474, Final Batch Loss: 4.285088380129309e-06\n",
      "Epoch 4760, Loss: 0.002010889827943174, Final Batch Loss: 5.877560397493653e-05\n",
      "Epoch 4761, Loss: 0.0011514859288581647, Final Batch Loss: 9.888976637739688e-05\n",
      "Epoch 4762, Loss: 0.0003446538194111781, Final Batch Loss: 1.0213758287136443e-05\n",
      "Epoch 4763, Loss: 0.0004360379894023936, Final Batch Loss: 3.1621161724615376e-06\n",
      "Epoch 4764, Loss: 0.00017039263184415177, Final Batch Loss: 3.784530417760834e-05\n",
      "Epoch 4765, Loss: 0.0004990385627934302, Final Batch Loss: 4.648957201425219e-06\n",
      "Epoch 4766, Loss: 0.0008486895603709854, Final Batch Loss: 2.227138975285925e-05\n",
      "Epoch 4767, Loss: 0.00041976179636549205, Final Batch Loss: 2.89638846879825e-05\n",
      "Epoch 4768, Loss: 0.00027869297855431796, Final Batch Loss: 1.970055109268287e-06\n",
      "Epoch 4769, Loss: 0.0029012818263254303, Final Batch Loss: 3.187247330060927e-06\n",
      "Epoch 4770, Loss: 0.004194629198536859, Final Batch Loss: 2.1923735403106548e-05\n",
      "Epoch 4771, Loss: 0.000555307291506324, Final Batch Loss: 8.889917808119208e-06\n",
      "Epoch 4772, Loss: 0.0005827071418025298, Final Batch Loss: 9.32887451199349e-06\n",
      "Epoch 4773, Loss: 0.00036016999456478516, Final Batch Loss: 1.3688514627574477e-05\n",
      "Epoch 4774, Loss: 0.0053269583513611, Final Batch Loss: 5.8095683925785124e-06\n",
      "Epoch 4775, Loss: 0.0004589599229802843, Final Batch Loss: 1.348236037301831e-05\n",
      "Epoch 4776, Loss: 0.001266516778514415, Final Batch Loss: 1.5685334346926538e-06\n",
      "Epoch 4777, Loss: 0.0009175318009511102, Final Batch Loss: 3.280784949311055e-05\n",
      "Epoch 4778, Loss: 0.01617201442422811, Final Batch Loss: 0.014691701158881187\n",
      "Epoch 4779, Loss: 0.0006013178281136788, Final Batch Loss: 8.94411641638726e-05\n",
      "Epoch 4780, Loss: 0.0004762073222082108, Final Batch Loss: 2.174924884457141e-05\n",
      "Epoch 4781, Loss: 0.0005437778781924862, Final Batch Loss: 5.7188928622053936e-05\n",
      "Epoch 4782, Loss: 0.00017246984134544618, Final Batch Loss: 1.750990850268863e-05\n",
      "Epoch 4783, Loss: 0.013518544032422142, Final Batch Loss: 2.704140797504806e-06\n",
      "Epoch 4784, Loss: 0.0007538131139881443, Final Batch Loss: 2.6529010938247666e-05\n",
      "Epoch 4785, Loss: 0.00038635546661680564, Final Batch Loss: 4.416054434841499e-05\n",
      "Epoch 4786, Loss: 0.0007286051150003914, Final Batch Loss: 0.00036989935324527323\n",
      "Epoch 4787, Loss: 0.022102953069406794, Final Batch Loss: 0.0028910343535244465\n",
      "Epoch 4788, Loss: 0.00015017917939985637, Final Batch Loss: 1.5879164493526332e-05\n",
      "Epoch 4789, Loss: 0.004533612926024944, Final Batch Loss: 0.0021259859204292297\n",
      "Epoch 4790, Loss: 0.0005398141911427956, Final Batch Loss: 0.0004391332622617483\n",
      "Epoch 4791, Loss: 0.0016232224788836902, Final Batch Loss: 1.5860199710004963e-05\n",
      "Epoch 4792, Loss: 0.004433933384376587, Final Batch Loss: 2.8233708349034714e-07\n",
      "Epoch 4793, Loss: 0.0005106041971885134, Final Batch Loss: 0.00042973062954843044\n",
      "Epoch 4794, Loss: 0.000525190806001774, Final Batch Loss: 0.00015652284491807222\n",
      "Epoch 4795, Loss: 0.00044810105828219093, Final Batch Loss: 3.6553068639477715e-05\n",
      "Epoch 4796, Loss: 0.0003033150587725686, Final Batch Loss: 8.331660865223967e-06\n",
      "Epoch 4797, Loss: 0.0005741561562899733, Final Batch Loss: 1.901359973999206e-05\n",
      "Epoch 4798, Loss: 0.0004975526098860428, Final Batch Loss: 3.133647987851873e-05\n",
      "Epoch 4799, Loss: 0.00038788094025221653, Final Batch Loss: 7.503611413994804e-06\n",
      "Epoch 4800, Loss: 0.0006203842085596989, Final Batch Loss: 1.4956315681047272e-05\n",
      "Epoch 4801, Loss: 0.00014369240284395346, Final Batch Loss: 1.951240619746386e-06\n",
      "Epoch 4802, Loss: 0.00020248682631063275, Final Batch Loss: 0.0001111175079131499\n",
      "Epoch 4803, Loss: 0.00032634512172080576, Final Batch Loss: 0.00015398474351968616\n",
      "Epoch 4804, Loss: 0.00032414555971627124, Final Batch Loss: 0.00020955706713721156\n",
      "Epoch 4805, Loss: 0.00022303276477941836, Final Batch Loss: 2.4217790723923827e-06\n",
      "Epoch 4806, Loss: 9.856652650341857e-05, Final Batch Loss: 1.057130612025503e-05\n",
      "Epoch 4807, Loss: 0.00016442578271380626, Final Batch Loss: 7.860484765842557e-05\n",
      "Epoch 4808, Loss: 0.0007748770294710994, Final Batch Loss: 0.00010819226008607075\n",
      "Epoch 4809, Loss: 0.00015383315985673107, Final Batch Loss: 4.304837784729898e-05\n",
      "Epoch 4810, Loss: 0.0005386925004131626, Final Batch Loss: 6.066304922569543e-05\n",
      "Epoch 4811, Loss: 0.0006947743405376627, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4812, Loss: 0.0003758772575963576, Final Batch Loss: 2.57240884593557e-07\n",
      "Epoch 4813, Loss: 0.00027168995802639984, Final Batch Loss: 2.4459008272970095e-05\n",
      "Epoch 4814, Loss: 0.0002619607184897177, Final Batch Loss: 3.721686516655609e-05\n",
      "Epoch 4815, Loss: 0.00034069161029037787, Final Batch Loss: 1.3236861377663445e-05\n",
      "Epoch 4816, Loss: 8.88352446963836e-05, Final Batch Loss: 7.1144445428217296e-06\n",
      "Epoch 4817, Loss: 0.0004459165756998118, Final Batch Loss: 0.0001032864092849195\n",
      "Epoch 4818, Loss: 0.0003032532453275394, Final Batch Loss: 1.1293504798004506e-07\n",
      "Epoch 4819, Loss: 0.0003168983794239466, Final Batch Loss: 1.003861143544782e-06\n",
      "Epoch 4820, Loss: 0.013684562043181359, Final Batch Loss: 3.0742553462914657e-06\n",
      "Epoch 4821, Loss: 0.00046455161509584286, Final Batch Loss: 5.376756689656759e-06\n",
      "Epoch 4822, Loss: 0.00020800388955422022, Final Batch Loss: 4.893838081443391e-07\n",
      "Epoch 4823, Loss: 0.0005711533435714955, Final Batch Loss: 5.803426120110089e-06\n",
      "Epoch 4824, Loss: 0.00026830878960026894, Final Batch Loss: 4.040486601297744e-06\n",
      "Epoch 4825, Loss: 0.00047562476765961037, Final Batch Loss: 5.081938525108853e-06\n",
      "Epoch 4826, Loss: 0.001603497605259463, Final Batch Loss: 4.1409484197174606e-07\n",
      "Epoch 4827, Loss: 0.03694656629522797, Final Batch Loss: 0.0001793354022083804\n",
      "Epoch 4828, Loss: 0.00045075570462893566, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4829, Loss: 0.021222075550781483, Final Batch Loss: 1.1920798215214745e-06\n",
      "Epoch 4830, Loss: 0.0017942951737950352, Final Batch Loss: 1.9198844256607117e-06\n",
      "Epoch 4831, Loss: 0.0006609950287383981, Final Batch Loss: 9.603717626305297e-05\n",
      "Epoch 4832, Loss: 0.02216568358562654, Final Batch Loss: 3.089909296249971e-05\n",
      "Epoch 4833, Loss: 0.00036043080035597086, Final Batch Loss: 3.7406469346024096e-05\n",
      "Epoch 4834, Loss: 0.00011695618036355881, Final Batch Loss: 1.9575147689465666e-06\n",
      "Epoch 4835, Loss: 0.0037752550415461883, Final Batch Loss: 0.0033605804201215506\n",
      "Epoch 4836, Loss: 0.001393849121996027, Final Batch Loss: 6.393155672412831e-06\n",
      "Epoch 4837, Loss: 0.0003965489158872515, Final Batch Loss: 3.665362601168454e-05\n",
      "Epoch 4838, Loss: 0.000912168572540395, Final Batch Loss: 0.00015631313726771623\n",
      "Epoch 4839, Loss: 0.004262776077212038, Final Batch Loss: 2.3527823032054584e-06\n",
      "Epoch 4840, Loss: 0.0011082874380470287, Final Batch Loss: 1.2548344585638915e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4841, Loss: 0.014917668784619309, Final Batch Loss: 2.7495218091644347e-05\n",
      "Epoch 4842, Loss: 0.0022048330611141864, Final Batch Loss: 0.002015194622799754\n",
      "Epoch 4843, Loss: 0.0005759301798207161, Final Batch Loss: 3.6012711461808067e-06\n",
      "Epoch 4844, Loss: 0.00017507362281321548, Final Batch Loss: 5.210060044191778e-05\n",
      "Epoch 4845, Loss: 0.008516021454852307, Final Batch Loss: 3.102296977885999e-05\n",
      "Epoch 4846, Loss: 0.00029826812806277303, Final Batch Loss: 8.131023605528753e-06\n",
      "Epoch 4847, Loss: 0.0005560231074923649, Final Batch Loss: 1.7528582247905433e-05\n",
      "Epoch 4848, Loss: 0.00532592448143987, Final Batch Loss: 0.004708783235400915\n",
      "Epoch 4849, Loss: 0.0004309985845338815, Final Batch Loss: 1.4932477370166453e-06\n",
      "Epoch 4850, Loss: 0.00044418166726245545, Final Batch Loss: 0.00029757688753306866\n",
      "Epoch 4851, Loss: 0.0004327388724050252, Final Batch Loss: 2.6961721232510172e-05\n",
      "Epoch 4852, Loss: 0.0009526081812509801, Final Batch Loss: 1.543853613839019e-05\n",
      "Epoch 4853, Loss: 0.0004472191103559453, Final Batch Loss: 0.00019919243641197681\n",
      "Epoch 4854, Loss: 0.00047396150330314413, Final Batch Loss: 3.069405647693202e-05\n",
      "Epoch 4855, Loss: 0.0005750685747898387, Final Batch Loss: 9.223010692949174e-07\n",
      "Epoch 4856, Loss: 0.0005731111650675302, Final Batch Loss: 3.7204572436166927e-06\n",
      "Epoch 4857, Loss: 0.0005756618702434935, Final Batch Loss: 2.4867491447366774e-05\n",
      "Epoch 4858, Loss: 0.0007923914522507403, Final Batch Loss: 4.15971908296342e-06\n",
      "Epoch 4859, Loss: 0.0024845778971211985, Final Batch Loss: 0.000883024069480598\n",
      "Epoch 4860, Loss: 0.00019252657716606336, Final Batch Loss: 2.0516329186648363e-06\n",
      "Epoch 4861, Loss: 0.0002057520365497112, Final Batch Loss: 3.701758259921917e-07\n",
      "Epoch 4862, Loss: 0.00012244008757988922, Final Batch Loss: 5.395777407102287e-07\n",
      "Epoch 4863, Loss: 0.00042399217454658356, Final Batch Loss: 2.0413723177625798e-05\n",
      "Epoch 4864, Loss: 0.00021558066231364137, Final Batch Loss: 3.5135320786139346e-07\n",
      "Epoch 4865, Loss: 0.0002825007995852502, Final Batch Loss: 0.00012848498590756208\n",
      "Epoch 4866, Loss: 0.0003445828042458743, Final Batch Loss: 4.1551218600943685e-05\n",
      "Epoch 4867, Loss: 0.00015780081230332144, Final Batch Loss: 4.406206790008582e-05\n",
      "Epoch 4868, Loss: 0.00021551917416218203, Final Batch Loss: 2.3128746761358343e-05\n",
      "Epoch 4869, Loss: 0.0007664469376322813, Final Batch Loss: 0.0006161986384540796\n",
      "Epoch 4870, Loss: 0.00045852241601096466, Final Batch Loss: 8.27525946078822e-06\n",
      "Epoch 4871, Loss: 0.0002763105039775837, Final Batch Loss: 4.253783117746934e-06\n",
      "Epoch 4872, Loss: 0.00023242569295689464, Final Batch Loss: 6.150532863102853e-05\n",
      "Epoch 4873, Loss: 0.00011714233642123872, Final Batch Loss: 6.650505383731797e-06\n",
      "Epoch 4874, Loss: 0.00020408517275427585, Final Batch Loss: 7.1333020059682894e-06\n",
      "Epoch 4875, Loss: 0.00013265710276755271, Final Batch Loss: 1.1631366760411765e-05\n",
      "Epoch 4876, Loss: 0.00016677635812811786, Final Batch Loss: 1.1468277989479247e-05\n",
      "Epoch 4877, Loss: 0.0010066173845189041, Final Batch Loss: 1.4742871826456394e-05\n",
      "Epoch 4878, Loss: 0.037286189919655044, Final Batch Loss: 7.905438224042882e-07\n",
      "Epoch 4879, Loss: 0.0002091993889052901, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4880, Loss: 0.0065553306723131755, Final Batch Loss: 9.47397097661451e-07\n",
      "Epoch 4881, Loss: 0.0689623538129922, Final Batch Loss: 9.160214062831074e-07\n",
      "Epoch 4882, Loss: 0.0001315725367021514, Final Batch Loss: 7.999002264114097e-06\n",
      "Epoch 4883, Loss: 0.0002188988473790232, Final Batch Loss: 9.937128197634593e-05\n",
      "Epoch 4884, Loss: 0.0003710208329721354, Final Batch Loss: 0.00019783918105531484\n",
      "Epoch 4885, Loss: 0.0009569938556523994, Final Batch Loss: 2.780188515316695e-05\n",
      "Epoch 4886, Loss: 0.0003370005374563334, Final Batch Loss: 6.487223345175153e-06\n",
      "Epoch 4887, Loss: 0.00019695864011737285, Final Batch Loss: 8.30676708574174e-06\n",
      "Epoch 4888, Loss: 0.0003911405547114555, Final Batch Loss: 4.326120324549265e-05\n",
      "Epoch 4889, Loss: 0.0009168451942969114, Final Batch Loss: 0.00041817687451839447\n",
      "Epoch 4890, Loss: 0.00041026993676496204, Final Batch Loss: 6.117194061516784e-06\n",
      "Epoch 4891, Loss: 0.0019355453841853887, Final Batch Loss: 0.0013771235244348645\n",
      "Epoch 4892, Loss: 0.00887818927628814, Final Batch Loss: 1.2611043302968028e-06\n",
      "Epoch 4893, Loss: 0.000378608048777096, Final Batch Loss: 9.887564374366775e-06\n",
      "Epoch 4894, Loss: 0.012265254915533319, Final Batch Loss: 2.3214421673856123e-07\n",
      "Epoch 4895, Loss: 0.00016522677105967887, Final Batch Loss: 3.8014095480320975e-05\n",
      "Epoch 4896, Loss: 0.00020196952391415834, Final Batch Loss: 5.059947943664156e-05\n",
      "Epoch 4897, Loss: 7.968715908646118e-05, Final Batch Loss: 1.1405752957216464e-05\n",
      "Epoch 4898, Loss: 0.0007674902665257832, Final Batch Loss: 1.3426581517705927e-06\n",
      "Epoch 4899, Loss: 0.0006031999473634642, Final Batch Loss: 1.9585273548727855e-05\n",
      "Epoch 4900, Loss: 0.001335039567493368, Final Batch Loss: 4.335022822488099e-05\n",
      "Epoch 4901, Loss: 0.00011014627077088335, Final Batch Loss: 3.3253078868256125e-07\n",
      "Epoch 4902, Loss: 0.001745328363540466, Final Batch Loss: 1.1643800462479703e-05\n",
      "Epoch 4903, Loss: 0.0001249942088179523, Final Batch Loss: 1.4987104805186391e-05\n",
      "Epoch 4904, Loss: 0.0036624702624976635, Final Batch Loss: 0.0007798840524628758\n",
      "Epoch 4905, Loss: 0.0007312112629733747, Final Batch Loss: 2.4251179638667963e-05\n",
      "Epoch 4906, Loss: 9.586748785750387e-05, Final Batch Loss: 1.6563695908189402e-06\n",
      "Epoch 4907, Loss: 0.0008073434873949736, Final Batch Loss: 0.00023964270076248795\n",
      "Epoch 4908, Loss: 0.0004598958767019212, Final Batch Loss: 8.46545081003569e-05\n",
      "Epoch 4909, Loss: 0.0006048918949090876, Final Batch Loss: 6.452875095419586e-05\n",
      "Epoch 4910, Loss: 0.000682035279169213, Final Batch Loss: 0.0003542696649674326\n",
      "Epoch 4911, Loss: 0.00017296117948717438, Final Batch Loss: 3.514169293339364e-05\n",
      "Epoch 4912, Loss: 0.0012320579994593572, Final Batch Loss: 4.015460035589058e-07\n",
      "Epoch 4913, Loss: 0.0007179364984040149, Final Batch Loss: 3.497969373711385e-05\n",
      "Epoch 4914, Loss: 0.0010582291797618382, Final Batch Loss: 0.0007842814666219056\n",
      "Epoch 4915, Loss: 0.0007591083601710125, Final Batch Loss: 2.9738846478721825e-06\n",
      "Epoch 4916, Loss: 0.0003177052437166594, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 4917, Loss: 0.00019811387528534397, Final Batch Loss: 7.340763659158256e-07\n",
      "Epoch 4918, Loss: 0.0036899480036680643, Final Batch Loss: 1.1920921849650767e-07\n",
      "Epoch 4919, Loss: 0.00042018706159296926, Final Batch Loss: 3.1998212079997757e-07\n",
      "Epoch 4920, Loss: 0.0009359938303532545, Final Batch Loss: 4.407661981531419e-05\n",
      "Epoch 4921, Loss: 0.00011048523992940318, Final Batch Loss: 9.843584848567843e-06\n",
      "Epoch 4922, Loss: 0.0003010940308740828, Final Batch Loss: 4.724553946289234e-05\n",
      "Epoch 4923, Loss: 0.00019858384985127486, Final Batch Loss: 6.897251296322793e-05\n",
      "Epoch 4924, Loss: 0.004563762962789042, Final Batch Loss: 0.004464252851903439\n",
      "Epoch 4925, Loss: 0.0015322644721891265, Final Batch Loss: 0.0012808722676709294\n",
      "Epoch 4926, Loss: 0.0002491714130883338, Final Batch Loss: 0.0001539850636618212\n",
      "Epoch 4927, Loss: 0.00022384741077985382, Final Batch Loss: 1.0263715921610128e-05\n",
      "Epoch 4928, Loss: 0.0003489801804335002, Final Batch Loss: 3.0366556984517956e-06\n",
      "Epoch 4929, Loss: 0.002219295154645806, Final Batch Loss: 0.002048345049843192\n",
      "Epoch 4930, Loss: 0.0003953521036237362, Final Batch Loss: 3.7330710256355815e-06\n",
      "Epoch 4931, Loss: 0.0004504473527049413, Final Batch Loss: 5.069303369964473e-06\n",
      "Epoch 4932, Loss: 0.001217684752191417, Final Batch Loss: 0.00012960005551576614\n",
      "Epoch 4933, Loss: 0.00040416834417555947, Final Batch Loss: 7.911601642263122e-06\n",
      "Epoch 4934, Loss: 0.0017090212750190403, Final Batch Loss: 5.7216162531403825e-05\n",
      "Epoch 4935, Loss: 0.00012959482774022035, Final Batch Loss: 4.7852456191321835e-05\n",
      "Epoch 4936, Loss: 7.288470791877444e-05, Final Batch Loss: 3.011599289948208e-07\n",
      "Epoch 4937, Loss: 0.00033121318483608775, Final Batch Loss: 0.00014947084127925336\n",
      "Epoch 4938, Loss: 0.003121124660538044, Final Batch Loss: 0.0030659418553113937\n",
      "Epoch 4939, Loss: 0.0002987460964050115, Final Batch Loss: 1.1293439001747174e-06\n",
      "Epoch 4940, Loss: 3.4920183054509835e-05, Final Batch Loss: 6.148655415927351e-07\n",
      "Epoch 4941, Loss: 0.00011891916255990509, Final Batch Loss: 3.780004408326931e-05\n",
      "Epoch 4942, Loss: 4.5292247477846104e-05, Final Batch Loss: 4.517394245340256e-07\n",
      "Epoch 4943, Loss: 0.00011878234636242269, Final Batch Loss: 9.07832964003319e-06\n",
      "Epoch 4944, Loss: 0.0005715152531706735, Final Batch Loss: 9.160233389593486e-07\n",
      "Epoch 4945, Loss: 0.0001472348358220188, Final Batch Loss: 1.7402517187292688e-05\n",
      "Epoch 4946, Loss: 0.0005395042935560923, Final Batch Loss: 3.929953163606115e-05\n",
      "Epoch 4947, Loss: 6.604928705655766e-05, Final Batch Loss: 1.2109040881114197e-06\n",
      "Epoch 4948, Loss: 9.535060587495536e-05, Final Batch Loss: 5.583996198765817e-07\n",
      "Epoch 4949, Loss: 9.63788970693713e-05, Final Batch Loss: 2.5723620638018474e-06\n",
      "Epoch 4950, Loss: 0.00019286955284769647, Final Batch Loss: 2.1712090529035777e-05\n",
      "Epoch 4951, Loss: 0.0002290006846834558, Final Batch Loss: 1.6312840500631864e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4952, Loss: 0.000261132914602058, Final Batch Loss: 1.2296011846046895e-05\n",
      "Epoch 4953, Loss: 0.0002564797432569321, Final Batch Loss: 1.8982766050612554e-05\n",
      "Epoch 4954, Loss: 0.000733803171897307, Final Batch Loss: 3.639722126536071e-05\n",
      "Epoch 4955, Loss: 0.0005146955636519124, Final Batch Loss: 7.591706889797933e-07\n",
      "Epoch 4956, Loss: 0.0001334653679805342, Final Batch Loss: 1.4710978575749323e-05\n",
      "Epoch 4957, Loss: 0.0001704275873635197, Final Batch Loss: 3.187256879755296e-06\n",
      "Epoch 4958, Loss: 0.00044330384844215587, Final Batch Loss: 0.0002363045496167615\n",
      "Epoch 4959, Loss: 9.396259702043608e-05, Final Batch Loss: 1.2622298527276143e-05\n",
      "Epoch 4960, Loss: 0.0003714692161338462, Final Batch Loss: 4.8623101065459196e-06\n",
      "Epoch 4961, Loss: 0.00018006292491179465, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 4962, Loss: 0.00028427985864709626, Final Batch Loss: 1.3489426464730059e-06\n",
      "Epoch 4963, Loss: 0.00016143254060807521, Final Batch Loss: 5.640234576276271e-06\n",
      "Epoch 4964, Loss: 0.000214399554351985, Final Batch Loss: 6.6315797084826045e-06\n",
      "Epoch 4965, Loss: 0.0001523971541246283, Final Batch Loss: 1.5074770089995582e-05\n",
      "Epoch 4966, Loss: 7.092315695444995e-05, Final Batch Loss: 3.3565800094947917e-06\n",
      "Epoch 4967, Loss: 0.002896069344217267, Final Batch Loss: 8.783779890109145e-07\n",
      "Epoch 4968, Loss: 0.0009894436180388766, Final Batch Loss: 5.709471793124976e-07\n",
      "Epoch 4969, Loss: 0.001028382836466335, Final Batch Loss: 4.5047113417240325e-06\n",
      "Epoch 4970, Loss: 7.288708275154931e-05, Final Batch Loss: 4.261984213371761e-05\n",
      "Epoch 4971, Loss: 0.0006712215108564124, Final Batch Loss: 4.643982902052812e-05\n",
      "Epoch 4972, Loss: 0.00032911443850025535, Final Batch Loss: 0.00029459118377417326\n",
      "Epoch 4973, Loss: 7.318155439861584e-05, Final Batch Loss: 1.047107252816204e-05\n",
      "Epoch 4974, Loss: 8.55988743069247e-05, Final Batch Loss: 6.83883286001219e-07\n",
      "Epoch 4975, Loss: 0.00013351607015010813, Final Batch Loss: 1.0352301842431189e-06\n",
      "Epoch 4976, Loss: 0.0001471195674014325, Final Batch Loss: 2.572406003764627e-07\n",
      "Epoch 4977, Loss: 0.000175485201907577, Final Batch Loss: 5.25431169080548e-05\n",
      "Epoch 4978, Loss: 0.0004585500792018138, Final Batch Loss: 0.0002709361433517188\n",
      "Epoch 4979, Loss: 6.969267178646987e-05, Final Batch Loss: 1.2202636753499974e-05\n",
      "Epoch 4980, Loss: 0.00013963460150989704, Final Batch Loss: 4.222387360641733e-06\n",
      "Epoch 4981, Loss: 0.00013748430501436815, Final Batch Loss: 1.6410715033998713e-05\n",
      "Epoch 4982, Loss: 0.0004292348658054834, Final Batch Loss: 0.0003589387342799455\n",
      "Epoch 4983, Loss: 5.3944447955700525e-05, Final Batch Loss: 2.6351497695031867e-07\n",
      "Epoch 4984, Loss: 0.016250793628842075, Final Batch Loss: 4.473298304219497e-06\n",
      "Epoch 4985, Loss: 0.0007712732312938897, Final Batch Loss: 4.404339051689021e-06\n",
      "Epoch 4986, Loss: 0.00034969303305842914, Final Batch Loss: 3.895068584824912e-05\n",
      "Epoch 4987, Loss: 9.530828333481622e-05, Final Batch Loss: 1.524602112112916e-06\n",
      "Epoch 4988, Loss: 4.321812775742728e-05, Final Batch Loss: 4.184756107861176e-06\n",
      "Epoch 4989, Loss: 3.196877219124872e-05, Final Batch Loss: 2.4343451059394283e-06\n",
      "Epoch 4990, Loss: 0.00013700803265237482, Final Batch Loss: 7.959161303006113e-05\n",
      "Epoch 4991, Loss: 0.0001346076631421056, Final Batch Loss: 3.325301918266632e-07\n",
      "Epoch 4992, Loss: 0.0002823228588795246, Final Batch Loss: 1.4869602864564513e-06\n",
      "Epoch 4993, Loss: 0.022742272234609118, Final Batch Loss: 0.02251431904733181\n",
      "Epoch 4994, Loss: 0.0002763558950391598, Final Batch Loss: 2.3391461581923068e-05\n",
      "Epoch 4995, Loss: 0.058644311158666085, Final Batch Loss: 9.411257195779399e-08\n",
      "Epoch 4996, Loss: 0.0062787626520730555, Final Batch Loss: 5.977819091640413e-05\n",
      "Epoch 4997, Loss: 0.0026833832241663913, Final Batch Loss: 3.306412281744997e-06\n",
      "Epoch 4998, Loss: 0.00015425258243340068, Final Batch Loss: 1.235282798006665e-05\n",
      "Epoch 4999, Loss: 6.435438444896135e-05, Final Batch Loss: 4.460802301764488e-06\n",
      "Epoch 5000, Loss: 0.00019315117060614284, Final Batch Loss: 2.1027377442806028e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45  0  0]\n",
      " [ 0 47  0]\n",
      " [ 0  0 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        45\n",
      "           1    1.00000   1.00000   1.00000        47\n",
      "           2    1.00000   1.00000   1.00000        38\n",
      "\n",
      "    accuracy                        1.00000       130\n",
      "   macro avg    1.00000   1.00000   1.00000       130\n",
      "weighted avg    1.00000   1.00000   1.00000       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 4)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 4)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 4) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0  0]\n",
      " [ 1 39  0]\n",
      " [ 0  0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.97561   1.00000   0.98765        40\n",
      "         1.0    1.00000   0.97500   0.98734        40\n",
      "         2.0    1.00000   1.00000   1.00000        40\n",
      "\n",
      "    accuracy                        0.99167       120\n",
      "   macro avg    0.99187   0.99167   0.99167       120\n",
      "weighted avg    0.99187   0.99167   0.99167       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    else:\n",
    "        y[k] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.191941738128662, Final Batch Loss: 1.3773088455200195\n",
      "Epoch 2, Loss: 4.216180443763733, Final Batch Loss: 1.4106996059417725\n",
      "Epoch 3, Loss: 4.2418776750564575, Final Batch Loss: 1.4424982070922852\n",
      "Epoch 4, Loss: 4.227945566177368, Final Batch Loss: 1.4305928945541382\n",
      "Epoch 5, Loss: 4.261879563331604, Final Batch Loss: 1.472856879234314\n",
      "Epoch 6, Loss: 4.2112215757369995, Final Batch Loss: 1.4219396114349365\n",
      "Epoch 7, Loss: 4.200379848480225, Final Batch Loss: 1.4116337299346924\n",
      "Epoch 8, Loss: 4.1935014724731445, Final Batch Loss: 1.404161810874939\n",
      "Epoch 9, Loss: 4.190621495246887, Final Batch Loss: 1.402277946472168\n",
      "Epoch 10, Loss: 4.184243679046631, Final Batch Loss: 1.4017337560653687\n",
      "Epoch 11, Loss: 4.162977576255798, Final Batch Loss: 1.3807376623153687\n",
      "Epoch 12, Loss: 4.190198063850403, Final Batch Loss: 1.4114370346069336\n",
      "Epoch 13, Loss: 4.155712366104126, Final Batch Loss: 1.3763595819473267\n",
      "Epoch 14, Loss: 4.154235482215881, Final Batch Loss: 1.3766350746154785\n",
      "Epoch 15, Loss: 4.144557476043701, Final Batch Loss: 1.373262882232666\n",
      "Epoch 16, Loss: 4.1423869132995605, Final Batch Loss: 1.3750154972076416\n",
      "Epoch 17, Loss: 4.135666847229004, Final Batch Loss: 1.367112636566162\n",
      "Epoch 18, Loss: 4.1452858448028564, Final Batch Loss: 1.3859342336654663\n",
      "Epoch 19, Loss: 4.12399435043335, Final Batch Loss: 1.3644099235534668\n",
      "Epoch 20, Loss: 4.132366418838501, Final Batch Loss: 1.375725269317627\n",
      "Epoch 21, Loss: 4.138317584991455, Final Batch Loss: 1.3885115385055542\n",
      "Epoch 22, Loss: 4.126682877540588, Final Batch Loss: 1.3800853490829468\n",
      "Epoch 23, Loss: 4.09548544883728, Final Batch Loss: 1.3452266454696655\n",
      "Epoch 24, Loss: 4.102490544319153, Final Batch Loss: 1.366089105606079\n",
      "Epoch 25, Loss: 4.092809438705444, Final Batch Loss: 1.3667173385620117\n",
      "Epoch 26, Loss: 4.086100339889526, Final Batch Loss: 1.3633252382278442\n",
      "Epoch 27, Loss: 4.0550713539123535, Final Batch Loss: 1.3500416278839111\n",
      "Epoch 28, Loss: 4.062769293785095, Final Batch Loss: 1.3719968795776367\n",
      "Epoch 29, Loss: 4.01020884513855, Final Batch Loss: 1.3314210176467896\n",
      "Epoch 30, Loss: 3.9672634601593018, Final Batch Loss: 1.303087592124939\n",
      "Epoch 31, Loss: 3.9633724689483643, Final Batch Loss: 1.3145307302474976\n",
      "Epoch 32, Loss: 3.9049755334854126, Final Batch Loss: 1.2670701742172241\n",
      "Epoch 33, Loss: 3.873036503791809, Final Batch Loss: 1.2477480173110962\n",
      "Epoch 34, Loss: 3.815018057823181, Final Batch Loss: 1.2122771739959717\n",
      "Epoch 35, Loss: 3.9152631759643555, Final Batch Loss: 1.3440232276916504\n",
      "Epoch 36, Loss: 3.8972952365875244, Final Batch Loss: 1.3430896997451782\n",
      "Epoch 37, Loss: 3.7761296033859253, Final Batch Loss: 1.2308365106582642\n",
      "Epoch 38, Loss: 3.7673747539520264, Final Batch Loss: 1.24329674243927\n",
      "Epoch 39, Loss: 3.697039008140564, Final Batch Loss: 1.223080039024353\n",
      "Epoch 40, Loss: 3.7478301525115967, Final Batch Loss: 1.262253999710083\n",
      "Epoch 41, Loss: 3.6775028705596924, Final Batch Loss: 1.216248869895935\n",
      "Epoch 42, Loss: 3.748080611228943, Final Batch Loss: 1.3221368789672852\n",
      "Epoch 43, Loss: 3.576018810272217, Final Batch Loss: 1.1821249723434448\n",
      "Epoch 44, Loss: 3.620473027229309, Final Batch Loss: 1.2225202322006226\n",
      "Epoch 45, Loss: 3.5562219619750977, Final Batch Loss: 1.1832809448242188\n",
      "Epoch 46, Loss: 3.700785756111145, Final Batch Loss: 1.3579821586608887\n",
      "Epoch 47, Loss: 3.3230355381965637, Final Batch Loss: 0.992847740650177\n",
      "Epoch 48, Loss: 3.3223562240600586, Final Batch Loss: 0.998010516166687\n",
      "Epoch 49, Loss: 3.526048183441162, Final Batch Loss: 1.2466821670532227\n",
      "Epoch 50, Loss: 3.478837251663208, Final Batch Loss: 1.2021654844284058\n",
      "Epoch 51, Loss: 3.3868958950042725, Final Batch Loss: 1.1433213949203491\n",
      "Epoch 52, Loss: 3.390126585960388, Final Batch Loss: 1.1639679670333862\n",
      "Epoch 53, Loss: 3.408146023750305, Final Batch Loss: 1.1955291032791138\n",
      "Epoch 54, Loss: 3.481459856033325, Final Batch Loss: 1.2636269330978394\n",
      "Epoch 55, Loss: 3.2283037900924683, Final Batch Loss: 1.0203202962875366\n",
      "Epoch 56, Loss: 3.379958987236023, Final Batch Loss: 1.2047038078308105\n",
      "Epoch 57, Loss: 3.274943470954895, Final Batch Loss: 1.1088694334030151\n",
      "Epoch 58, Loss: 3.1746444702148438, Final Batch Loss: 1.034814715385437\n",
      "Epoch 59, Loss: 3.173208475112915, Final Batch Loss: 1.0447111129760742\n",
      "Epoch 60, Loss: 3.318346619606018, Final Batch Loss: 1.2113301753997803\n",
      "Epoch 61, Loss: 3.0707053542137146, Final Batch Loss: 0.9635215401649475\n",
      "Epoch 62, Loss: 3.2000876665115356, Final Batch Loss: 1.1305371522903442\n",
      "Epoch 63, Loss: 2.9654839038848877, Final Batch Loss: 0.9232274889945984\n",
      "Epoch 64, Loss: 3.244245409965515, Final Batch Loss: 1.1796280145645142\n",
      "Epoch 65, Loss: 3.050121784210205, Final Batch Loss: 1.0241503715515137\n",
      "Epoch 66, Loss: 2.8713282346725464, Final Batch Loss: 0.8392065167427063\n",
      "Epoch 67, Loss: 3.0711973905563354, Final Batch Loss: 1.020914077758789\n",
      "Epoch 68, Loss: 3.054891049861908, Final Batch Loss: 1.0507359504699707\n",
      "Epoch 69, Loss: 2.8878400325775146, Final Batch Loss: 0.909203290939331\n",
      "Epoch 70, Loss: 3.2763810753822327, Final Batch Loss: 1.329722285270691\n",
      "Epoch 71, Loss: 3.1696608662605286, Final Batch Loss: 1.2417460680007935\n",
      "Epoch 72, Loss: 2.7930906414985657, Final Batch Loss: 0.8066889643669128\n",
      "Epoch 73, Loss: 2.8638477325439453, Final Batch Loss: 0.9086009860038757\n",
      "Epoch 74, Loss: 3.0595956444740295, Final Batch Loss: 1.1281499862670898\n",
      "Epoch 75, Loss: 2.713729441165924, Final Batch Loss: 0.8013802766799927\n",
      "Epoch 76, Loss: 2.782026946544647, Final Batch Loss: 0.9251089692115784\n",
      "Epoch 77, Loss: 2.711133062839508, Final Batch Loss: 0.8792895078659058\n",
      "Epoch 78, Loss: 2.856277287006378, Final Batch Loss: 0.9840773344039917\n",
      "Epoch 79, Loss: 2.863733947277069, Final Batch Loss: 1.0744118690490723\n",
      "Epoch 80, Loss: 2.6768540740013123, Final Batch Loss: 0.8632990121841431\n",
      "Epoch 81, Loss: 2.6765761971473694, Final Batch Loss: 0.8800175189971924\n",
      "Epoch 82, Loss: 2.7459683418273926, Final Batch Loss: 0.980058491230011\n",
      "Epoch 83, Loss: 2.42587810754776, Final Batch Loss: 0.6626715660095215\n",
      "Epoch 84, Loss: 2.4902320504188538, Final Batch Loss: 0.711727499961853\n",
      "Epoch 85, Loss: 2.420896351337433, Final Batch Loss: 0.6883370280265808\n",
      "Epoch 86, Loss: 2.821476936340332, Final Batch Loss: 1.0875678062438965\n",
      "Epoch 87, Loss: 2.409158408641815, Final Batch Loss: 0.6595191359519958\n",
      "Epoch 88, Loss: 2.466427266597748, Final Batch Loss: 0.7794051170349121\n",
      "Epoch 89, Loss: 2.4900102615356445, Final Batch Loss: 0.8106520771980286\n",
      "Epoch 90, Loss: 2.4473599791526794, Final Batch Loss: 0.7677494883537292\n",
      "Epoch 91, Loss: 2.3543718457221985, Final Batch Loss: 0.6897706985473633\n",
      "Epoch 92, Loss: 2.775197923183441, Final Batch Loss: 1.1196527481079102\n",
      "Epoch 93, Loss: 2.4137840270996094, Final Batch Loss: 0.7173393368721008\n",
      "Epoch 94, Loss: 2.3258739709854126, Final Batch Loss: 0.6638972759246826\n",
      "Epoch 95, Loss: 2.526811957359314, Final Batch Loss: 0.9705862998962402\n",
      "Epoch 96, Loss: 2.0347784757614136, Final Batch Loss: 0.40649527311325073\n",
      "Epoch 97, Loss: 2.313235282897949, Final Batch Loss: 0.6935494542121887\n",
      "Epoch 98, Loss: 2.2666326761245728, Final Batch Loss: 0.6145802140235901\n",
      "Epoch 99, Loss: 2.4389394521713257, Final Batch Loss: 0.8104015588760376\n",
      "Epoch 100, Loss: 2.4098254442214966, Final Batch Loss: 0.8023858070373535\n",
      "Epoch 101, Loss: 2.1532697081565857, Final Batch Loss: 0.5478919744491577\n",
      "Epoch 102, Loss: 2.3133641481399536, Final Batch Loss: 0.8498681783676147\n",
      "Epoch 103, Loss: 2.198496997356415, Final Batch Loss: 0.6848025321960449\n",
      "Epoch 104, Loss: 2.327649712562561, Final Batch Loss: 0.7737623453140259\n",
      "Epoch 105, Loss: 2.383208692073822, Final Batch Loss: 0.866366446018219\n",
      "Epoch 106, Loss: 2.283045709133148, Final Batch Loss: 0.7228813767433167\n",
      "Epoch 107, Loss: 2.3217931985855103, Final Batch Loss: 0.8088396191596985\n",
      "Epoch 108, Loss: 2.1883159279823303, Final Batch Loss: 0.6553356051445007\n",
      "Epoch 109, Loss: 2.514506697654724, Final Batch Loss: 0.9796034097671509\n",
      "Epoch 110, Loss: 2.2088488936424255, Final Batch Loss: 0.6992377042770386\n",
      "Epoch 111, Loss: 2.1620267033576965, Final Batch Loss: 0.6457095146179199\n",
      "Epoch 112, Loss: 2.3135260939598083, Final Batch Loss: 0.8136035799980164\n",
      "Epoch 113, Loss: 2.1735950112342834, Final Batch Loss: 0.6649870872497559\n",
      "Epoch 114, Loss: 2.178644061088562, Final Batch Loss: 0.716611385345459\n",
      "Epoch 115, Loss: 2.0983031392097473, Final Batch Loss: 0.681070864200592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Loss: 2.235073983669281, Final Batch Loss: 0.7390227317810059\n",
      "Epoch 117, Loss: 2.2658209204673767, Final Batch Loss: 0.8816837668418884\n",
      "Epoch 118, Loss: 2.2841984629631042, Final Batch Loss: 0.8734487295150757\n",
      "Epoch 119, Loss: 2.1272794008255005, Final Batch Loss: 0.6979336738586426\n",
      "Epoch 120, Loss: 2.177486836910248, Final Batch Loss: 0.7126415371894836\n",
      "Epoch 121, Loss: 2.254896640777588, Final Batch Loss: 0.8607078194618225\n",
      "Epoch 122, Loss: 2.0478065609931946, Final Batch Loss: 0.6463191509246826\n",
      "Epoch 123, Loss: 2.2082031965255737, Final Batch Loss: 0.7810679078102112\n",
      "Epoch 124, Loss: 1.8926373422145844, Final Batch Loss: 0.4493829309940338\n",
      "Epoch 125, Loss: 2.1394415497779846, Final Batch Loss: 0.7836971282958984\n",
      "Epoch 126, Loss: 2.168992817401886, Final Batch Loss: 0.7479113340377808\n",
      "Epoch 127, Loss: 1.9315857887268066, Final Batch Loss: 0.5576208829879761\n",
      "Epoch 128, Loss: 2.1324456334114075, Final Batch Loss: 0.7419420480728149\n",
      "Epoch 129, Loss: 2.3989664912223816, Final Batch Loss: 1.027493953704834\n",
      "Epoch 130, Loss: 1.9752624034881592, Final Batch Loss: 0.6108725070953369\n",
      "Epoch 131, Loss: 1.918238639831543, Final Batch Loss: 0.5425745248794556\n",
      "Epoch 132, Loss: 1.9878469705581665, Final Batch Loss: 0.5679205656051636\n",
      "Epoch 133, Loss: 2.1985272765159607, Final Batch Loss: 0.8186367154121399\n",
      "Epoch 134, Loss: 1.9354096055030823, Final Batch Loss: 0.5277528166770935\n",
      "Epoch 135, Loss: 2.0160481333732605, Final Batch Loss: 0.6013124585151672\n",
      "Epoch 136, Loss: 2.21827232837677, Final Batch Loss: 0.8317962884902954\n",
      "Epoch 137, Loss: 2.1399965286254883, Final Batch Loss: 0.741658627986908\n",
      "Epoch 138, Loss: 2.134302258491516, Final Batch Loss: 0.771892786026001\n",
      "Epoch 139, Loss: 1.962369680404663, Final Batch Loss: 0.6112246513366699\n",
      "Epoch 140, Loss: 2.1463279128074646, Final Batch Loss: 0.7640173435211182\n",
      "Epoch 141, Loss: 1.9229841828346252, Final Batch Loss: 0.5645027160644531\n",
      "Epoch 142, Loss: 2.157856285572052, Final Batch Loss: 0.7729191780090332\n",
      "Epoch 143, Loss: 1.9917240142822266, Final Batch Loss: 0.5740642547607422\n",
      "Epoch 144, Loss: 2.1670498847961426, Final Batch Loss: 0.8237549066543579\n",
      "Epoch 145, Loss: 1.8788057565689087, Final Batch Loss: 0.4944082498550415\n",
      "Epoch 146, Loss: 1.7862038612365723, Final Batch Loss: 0.4498215317726135\n",
      "Epoch 147, Loss: 2.1316915154457092, Final Batch Loss: 0.8458326458930969\n",
      "Epoch 148, Loss: 1.836962878704071, Final Batch Loss: 0.5375922322273254\n",
      "Epoch 149, Loss: 1.9720155596733093, Final Batch Loss: 0.7305881381034851\n",
      "Epoch 150, Loss: 2.0850170850753784, Final Batch Loss: 0.7506977915763855\n",
      "Epoch 151, Loss: 1.8487229943275452, Final Batch Loss: 0.5373459458351135\n",
      "Epoch 152, Loss: 1.9446524381637573, Final Batch Loss: 0.5720653533935547\n",
      "Epoch 153, Loss: 2.003695249557495, Final Batch Loss: 0.6439398527145386\n",
      "Epoch 154, Loss: 1.9064810872077942, Final Batch Loss: 0.593650221824646\n",
      "Epoch 155, Loss: 1.787229835987091, Final Batch Loss: 0.5644509196281433\n",
      "Epoch 156, Loss: 1.9710702300071716, Final Batch Loss: 0.6582216024398804\n",
      "Epoch 157, Loss: 1.8567054867744446, Final Batch Loss: 0.5187544226646423\n",
      "Epoch 158, Loss: 1.9493164420127869, Final Batch Loss: 0.7384071350097656\n",
      "Epoch 159, Loss: 1.7353318631649017, Final Batch Loss: 0.4023036062717438\n",
      "Epoch 160, Loss: 1.9694323539733887, Final Batch Loss: 0.6323347687721252\n",
      "Epoch 161, Loss: 1.928296983242035, Final Batch Loss: 0.6355704665184021\n",
      "Epoch 162, Loss: 1.9525673389434814, Final Batch Loss: 0.5369016528129578\n",
      "Epoch 163, Loss: 1.774607926607132, Final Batch Loss: 0.42868152260780334\n",
      "Epoch 164, Loss: 1.9219794273376465, Final Batch Loss: 0.6734893918037415\n",
      "Epoch 165, Loss: 1.7828286290168762, Final Batch Loss: 0.5627935528755188\n",
      "Epoch 166, Loss: 1.8603888750076294, Final Batch Loss: 0.6234606504440308\n",
      "Epoch 167, Loss: 1.950032651424408, Final Batch Loss: 0.725546658039093\n",
      "Epoch 168, Loss: 1.7812874913215637, Final Batch Loss: 0.5188650488853455\n",
      "Epoch 169, Loss: 1.8665494918823242, Final Batch Loss: 0.592897891998291\n",
      "Epoch 170, Loss: 2.1011393666267395, Final Batch Loss: 0.8598911762237549\n",
      "Epoch 171, Loss: 1.7468673586845398, Final Batch Loss: 0.541618824005127\n",
      "Epoch 172, Loss: 1.8962585926055908, Final Batch Loss: 0.6965426802635193\n",
      "Epoch 173, Loss: 1.734035313129425, Final Batch Loss: 0.5122835636138916\n",
      "Epoch 174, Loss: 1.7685726284980774, Final Batch Loss: 0.5846673250198364\n",
      "Epoch 175, Loss: 1.5481510758399963, Final Batch Loss: 0.2966175079345703\n",
      "Epoch 176, Loss: 1.8376274704933167, Final Batch Loss: 0.6344592571258545\n",
      "Epoch 177, Loss: 1.6654885709285736, Final Batch Loss: 0.47058048844337463\n",
      "Epoch 178, Loss: 1.5911069810390472, Final Batch Loss: 0.40261802077293396\n",
      "Epoch 179, Loss: 1.8886414170265198, Final Batch Loss: 0.6424117088317871\n",
      "Epoch 180, Loss: 1.7837380766868591, Final Batch Loss: 0.5507897734642029\n",
      "Epoch 181, Loss: 1.7725932598114014, Final Batch Loss: 0.590060830116272\n",
      "Epoch 182, Loss: 1.724010705947876, Final Batch Loss: 0.5074558258056641\n",
      "Epoch 183, Loss: 1.6446140110492706, Final Batch Loss: 0.4490666091442108\n",
      "Epoch 184, Loss: 1.8353331685066223, Final Batch Loss: 0.6177892684936523\n",
      "Epoch 185, Loss: 1.6040073335170746, Final Batch Loss: 0.4670160114765167\n",
      "Epoch 186, Loss: 1.8441931009292603, Final Batch Loss: 0.7223880887031555\n",
      "Epoch 187, Loss: 1.8924644589424133, Final Batch Loss: 0.6439241766929626\n",
      "Epoch 188, Loss: 1.891871154308319, Final Batch Loss: 0.6941983103752136\n",
      "Epoch 189, Loss: 1.664064884185791, Final Batch Loss: 0.517432689666748\n",
      "Epoch 190, Loss: 1.6382090151309967, Final Batch Loss: 0.45770594477653503\n",
      "Epoch 191, Loss: 1.627847969532013, Final Batch Loss: 0.4123802185058594\n",
      "Epoch 192, Loss: 1.7398393750190735, Final Batch Loss: 0.5308743119239807\n",
      "Epoch 193, Loss: 2.0396223068237305, Final Batch Loss: 0.9269105792045593\n",
      "Epoch 194, Loss: 1.861363410949707, Final Batch Loss: 0.6956720352172852\n",
      "Epoch 195, Loss: 1.6562231183052063, Final Batch Loss: 0.5201597213745117\n",
      "Epoch 196, Loss: 1.7912108898162842, Final Batch Loss: 0.618942379951477\n",
      "Epoch 197, Loss: 1.7688019275665283, Final Batch Loss: 0.6076816320419312\n",
      "Epoch 198, Loss: 1.6157355904579163, Final Batch Loss: 0.43316078186035156\n",
      "Epoch 199, Loss: 1.7944039702415466, Final Batch Loss: 0.6055312156677246\n",
      "Epoch 200, Loss: 1.8182008266448975, Final Batch Loss: 0.7312557697296143\n",
      "Epoch 201, Loss: 1.9307764768600464, Final Batch Loss: 0.8084279298782349\n",
      "Epoch 202, Loss: 1.6581233143806458, Final Batch Loss: 0.484566330909729\n",
      "Epoch 203, Loss: 2.045203924179077, Final Batch Loss: 0.9051425457000732\n",
      "Epoch 204, Loss: 1.813201904296875, Final Batch Loss: 0.6765017509460449\n",
      "Epoch 205, Loss: 1.5938959121704102, Final Batch Loss: 0.4544258117675781\n",
      "Epoch 206, Loss: 1.5847119092941284, Final Batch Loss: 0.460399329662323\n",
      "Epoch 207, Loss: 2.0008164644241333, Final Batch Loss: 0.892956554889679\n",
      "Epoch 208, Loss: 1.9035176634788513, Final Batch Loss: 0.7841721177101135\n",
      "Epoch 209, Loss: 1.5369660556316376, Final Batch Loss: 0.43648388981819153\n",
      "Epoch 210, Loss: 1.641538143157959, Final Batch Loss: 0.5130425691604614\n",
      "Epoch 211, Loss: 1.748399555683136, Final Batch Loss: 0.6400812268257141\n",
      "Epoch 212, Loss: 1.6227347254753113, Final Batch Loss: 0.49702996015548706\n",
      "Epoch 213, Loss: 1.8338125944137573, Final Batch Loss: 0.6908623576164246\n",
      "Epoch 214, Loss: 1.6539234519004822, Final Batch Loss: 0.561860978603363\n",
      "Epoch 215, Loss: 1.5471409857273102, Final Batch Loss: 0.40473631024360657\n",
      "Epoch 216, Loss: 1.579788088798523, Final Batch Loss: 0.4711049199104309\n",
      "Epoch 217, Loss: 1.5802962481975555, Final Batch Loss: 0.47994914650917053\n",
      "Epoch 218, Loss: 1.8417741060256958, Final Batch Loss: 0.7454443573951721\n",
      "Epoch 219, Loss: 1.5861758589744568, Final Batch Loss: 0.5492075085639954\n",
      "Epoch 220, Loss: 1.462385356426239, Final Batch Loss: 0.35491424798965454\n",
      "Epoch 221, Loss: 1.6390992999076843, Final Batch Loss: 0.5545929670333862\n",
      "Epoch 222, Loss: 1.8722388744354248, Final Batch Loss: 0.742486834526062\n",
      "Epoch 223, Loss: 1.5564987063407898, Final Batch Loss: 0.4394223093986511\n",
      "Epoch 224, Loss: 1.88910973072052, Final Batch Loss: 0.8166631460189819\n",
      "Epoch 225, Loss: 1.4956879317760468, Final Batch Loss: 0.40981343388557434\n",
      "Epoch 226, Loss: 1.9336476922035217, Final Batch Loss: 0.8378418684005737\n",
      "Epoch 227, Loss: 1.476614534854889, Final Batch Loss: 0.5017390251159668\n",
      "Epoch 228, Loss: 1.6863607168197632, Final Batch Loss: 0.5265291333198547\n",
      "Epoch 229, Loss: 1.5810249149799347, Final Batch Loss: 0.46813371777534485\n",
      "Epoch 230, Loss: 1.359349548816681, Final Batch Loss: 0.2994394600391388\n",
      "Epoch 231, Loss: 1.7314202189445496, Final Batch Loss: 0.6227217316627502\n",
      "Epoch 232, Loss: 1.661137342453003, Final Batch Loss: 0.6069080233573914\n",
      "Epoch 233, Loss: 1.9333881735801697, Final Batch Loss: 0.8611602783203125\n",
      "Epoch 234, Loss: 1.566201239824295, Final Batch Loss: 0.5700147747993469\n",
      "Epoch 235, Loss: 1.4403286278247833, Final Batch Loss: 0.42402195930480957\n",
      "Epoch 236, Loss: 1.4359171688556671, Final Batch Loss: 0.39947041869163513\n",
      "Epoch 237, Loss: 1.4381729662418365, Final Batch Loss: 0.4031010568141937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238, Loss: 1.4513638317584991, Final Batch Loss: 0.4516041874885559\n",
      "Epoch 239, Loss: 1.3807607591152191, Final Batch Loss: 0.3655708432197571\n",
      "Epoch 240, Loss: 1.3609640896320343, Final Batch Loss: 0.3416200578212738\n",
      "Epoch 241, Loss: 1.4447070360183716, Final Batch Loss: 0.49941501021385193\n",
      "Epoch 242, Loss: 1.5801140367984772, Final Batch Loss: 0.573606014251709\n",
      "Epoch 243, Loss: 1.6609793305397034, Final Batch Loss: 0.6722415685653687\n",
      "Epoch 244, Loss: 1.493641585111618, Final Batch Loss: 0.4580710530281067\n",
      "Epoch 245, Loss: 1.486601173877716, Final Batch Loss: 0.4639323949813843\n",
      "Epoch 246, Loss: 1.525831937789917, Final Batch Loss: 0.5430471897125244\n",
      "Epoch 247, Loss: 1.4745982587337494, Final Batch Loss: 0.5043842196464539\n",
      "Epoch 248, Loss: 1.4863451719284058, Final Batch Loss: 0.45730137825012207\n",
      "Epoch 249, Loss: 1.6040142178535461, Final Batch Loss: 0.6331064701080322\n",
      "Epoch 250, Loss: 1.5612459778785706, Final Batch Loss: 0.5625686645507812\n",
      "Epoch 251, Loss: 1.52831569314003, Final Batch Loss: 0.5788588523864746\n",
      "Epoch 252, Loss: 1.4298653602600098, Final Batch Loss: 0.42706498503685\n",
      "Epoch 253, Loss: 1.2969876527786255, Final Batch Loss: 0.32600298523902893\n",
      "Epoch 254, Loss: 1.5383572578430176, Final Batch Loss: 0.5807163119316101\n",
      "Epoch 255, Loss: 1.3981598913669586, Final Batch Loss: 0.4083635210990906\n",
      "Epoch 256, Loss: 1.6889704167842865, Final Batch Loss: 0.6931794881820679\n",
      "Epoch 257, Loss: 1.4123075306415558, Final Batch Loss: 0.4151054322719574\n",
      "Epoch 258, Loss: 1.2565287351608276, Final Batch Loss: 0.29389509558677673\n",
      "Epoch 259, Loss: 1.305644154548645, Final Batch Loss: 0.3443800210952759\n",
      "Epoch 260, Loss: 1.3316552340984344, Final Batch Loss: 0.390679270029068\n",
      "Epoch 261, Loss: 1.4891983270645142, Final Batch Loss: 0.5217108726501465\n",
      "Epoch 262, Loss: 1.3808790147304535, Final Batch Loss: 0.42751795053482056\n",
      "Epoch 263, Loss: 1.4057432115077972, Final Batch Loss: 0.3930790424346924\n",
      "Epoch 264, Loss: 1.646980881690979, Final Batch Loss: 0.5890969038009644\n",
      "Epoch 265, Loss: 1.237680047750473, Final Batch Loss: 0.29270288348197937\n",
      "Epoch 266, Loss: 1.5305500626564026, Final Batch Loss: 0.4566192030906677\n",
      "Epoch 267, Loss: 1.4942883551120758, Final Batch Loss: 0.6068440675735474\n",
      "Epoch 268, Loss: 1.385870784521103, Final Batch Loss: 0.47726908326148987\n",
      "Epoch 269, Loss: 1.4499769806861877, Final Batch Loss: 0.48934173583984375\n",
      "Epoch 270, Loss: 1.3352063596248627, Final Batch Loss: 0.34706079959869385\n",
      "Epoch 271, Loss: 1.510500192642212, Final Batch Loss: 0.5273295640945435\n",
      "Epoch 272, Loss: 1.5181328058242798, Final Batch Loss: 0.5837299227714539\n",
      "Epoch 273, Loss: 1.3547854125499725, Final Batch Loss: 0.4612598419189453\n",
      "Epoch 274, Loss: 1.4676654934883118, Final Batch Loss: 0.5367726683616638\n",
      "Epoch 275, Loss: 1.6127521395683289, Final Batch Loss: 0.6896125674247742\n",
      "Epoch 276, Loss: 1.2993690371513367, Final Batch Loss: 0.380922794342041\n",
      "Epoch 277, Loss: 1.3636400401592255, Final Batch Loss: 0.3955524265766144\n",
      "Epoch 278, Loss: 1.465095430612564, Final Batch Loss: 0.4834352731704712\n",
      "Epoch 279, Loss: 1.4038367867469788, Final Batch Loss: 0.5267260670661926\n",
      "Epoch 280, Loss: 1.406308263540268, Final Batch Loss: 0.5052390098571777\n",
      "Epoch 281, Loss: 1.4353585541248322, Final Batch Loss: 0.5918797850608826\n",
      "Epoch 282, Loss: 1.1731951236724854, Final Batch Loss: 0.2375158965587616\n",
      "Epoch 283, Loss: 1.2910724878311157, Final Batch Loss: 0.33831527829170227\n",
      "Epoch 284, Loss: 1.2778388559818268, Final Batch Loss: 0.36870837211608887\n",
      "Epoch 285, Loss: 1.4022493958473206, Final Batch Loss: 0.47834160923957825\n",
      "Epoch 286, Loss: 1.1135663092136383, Final Batch Loss: 0.21156218647956848\n",
      "Epoch 287, Loss: 1.5130119621753693, Final Batch Loss: 0.6724076271057129\n",
      "Epoch 288, Loss: 1.3135575354099274, Final Batch Loss: 0.3996378481388092\n",
      "Epoch 289, Loss: 1.5613676309585571, Final Batch Loss: 0.7365937829017639\n",
      "Epoch 290, Loss: 1.3707305788993835, Final Batch Loss: 0.47157344222068787\n",
      "Epoch 291, Loss: 1.2120656073093414, Final Batch Loss: 0.33352920413017273\n",
      "Epoch 292, Loss: 1.3056647777557373, Final Batch Loss: 0.46984392404556274\n",
      "Epoch 293, Loss: 1.4369261264801025, Final Batch Loss: 0.5692270398139954\n",
      "Epoch 294, Loss: 1.2700810432434082, Final Batch Loss: 0.4883260130882263\n",
      "Epoch 295, Loss: 1.510790854692459, Final Batch Loss: 0.6486407518386841\n",
      "Epoch 296, Loss: 1.1851009130477905, Final Batch Loss: 0.2500793933868408\n",
      "Epoch 297, Loss: 1.4045155942440033, Final Batch Loss: 0.49060460925102234\n",
      "Epoch 298, Loss: 1.2371549010276794, Final Batch Loss: 0.3021571636199951\n",
      "Epoch 299, Loss: 1.4473729133605957, Final Batch Loss: 0.5535621047019958\n",
      "Epoch 300, Loss: 1.1706651449203491, Final Batch Loss: 0.28521841764450073\n",
      "Epoch 301, Loss: 1.3226773738861084, Final Batch Loss: 0.45942553877830505\n",
      "Epoch 302, Loss: 1.4513677656650543, Final Batch Loss: 0.5646324157714844\n",
      "Epoch 303, Loss: 1.5965798795223236, Final Batch Loss: 0.7767840623855591\n",
      "Epoch 304, Loss: 1.3195292949676514, Final Batch Loss: 0.48338183760643005\n",
      "Epoch 305, Loss: 1.4588219821453094, Final Batch Loss: 0.5388913750648499\n",
      "Epoch 306, Loss: 1.3189489245414734, Final Batch Loss: 0.470231294631958\n",
      "Epoch 307, Loss: 1.2794928550720215, Final Batch Loss: 0.35862332582473755\n",
      "Epoch 308, Loss: 1.2098692655563354, Final Batch Loss: 0.333893358707428\n",
      "Epoch 309, Loss: 1.2294501066207886, Final Batch Loss: 0.37938717007637024\n",
      "Epoch 310, Loss: 1.1273506581783295, Final Batch Loss: 0.29273247718811035\n",
      "Epoch 311, Loss: 1.2670864462852478, Final Batch Loss: 0.45616164803504944\n",
      "Epoch 312, Loss: 1.0635319501161575, Final Batch Loss: 0.21366529166698456\n",
      "Epoch 313, Loss: 1.5436066389083862, Final Batch Loss: 0.7076992988586426\n",
      "Epoch 314, Loss: 1.2491621673107147, Final Batch Loss: 0.4641471207141876\n",
      "Epoch 315, Loss: 1.0201673805713654, Final Batch Loss: 0.29196566343307495\n",
      "Epoch 316, Loss: 1.347116768360138, Final Batch Loss: 0.5054070949554443\n",
      "Epoch 317, Loss: 1.151521474123001, Final Batch Loss: 0.3926668167114258\n",
      "Epoch 318, Loss: 1.368370234966278, Final Batch Loss: 0.5369836688041687\n",
      "Epoch 319, Loss: 1.3476236760616302, Final Batch Loss: 0.5002330541610718\n",
      "Epoch 320, Loss: 1.3676696717739105, Final Batch Loss: 0.5637339949607849\n",
      "Epoch 321, Loss: 1.3573985695838928, Final Batch Loss: 0.5774891376495361\n",
      "Epoch 322, Loss: 1.2301503419876099, Final Batch Loss: 0.4517897963523865\n",
      "Epoch 323, Loss: 1.0714741051197052, Final Batch Loss: 0.25630098581314087\n",
      "Epoch 324, Loss: 1.1892887353897095, Final Batch Loss: 0.38599610328674316\n",
      "Epoch 325, Loss: 1.0673384368419647, Final Batch Loss: 0.24275541305541992\n",
      "Epoch 326, Loss: 1.1335904896259308, Final Batch Loss: 0.29246121644973755\n",
      "Epoch 327, Loss: 1.0837514400482178, Final Batch Loss: 0.25956210494041443\n",
      "Epoch 328, Loss: 1.254682034254074, Final Batch Loss: 0.4934874475002289\n",
      "Epoch 329, Loss: 1.3597650527954102, Final Batch Loss: 0.5786280035972595\n",
      "Epoch 330, Loss: 1.4043306410312653, Final Batch Loss: 0.5395885109901428\n",
      "Epoch 331, Loss: 1.1372134983539581, Final Batch Loss: 0.36806198954582214\n",
      "Epoch 332, Loss: 0.9355706572532654, Final Batch Loss: 0.136227548122406\n",
      "Epoch 333, Loss: 0.942747563123703, Final Batch Loss: 0.20811119675636292\n",
      "Epoch 334, Loss: 1.6612948775291443, Final Batch Loss: 0.8873633146286011\n",
      "Epoch 335, Loss: 1.1156704425811768, Final Batch Loss: 0.3340526521205902\n",
      "Epoch 336, Loss: 1.2990966737270355, Final Batch Loss: 0.43659475445747375\n",
      "Epoch 337, Loss: 1.1219044923782349, Final Batch Loss: 0.30841681361198425\n",
      "Epoch 338, Loss: 1.4821322560310364, Final Batch Loss: 0.643375039100647\n",
      "Epoch 339, Loss: 1.2587487399578094, Final Batch Loss: 0.3772001564502716\n",
      "Epoch 340, Loss: 1.052459329366684, Final Batch Loss: 0.2694868743419647\n",
      "Epoch 341, Loss: 0.9889653325080872, Final Batch Loss: 0.18954035639762878\n",
      "Epoch 342, Loss: 1.2150156497955322, Final Batch Loss: 0.4425278604030609\n",
      "Epoch 343, Loss: 1.093803733587265, Final Batch Loss: 0.29691818356513977\n",
      "Epoch 344, Loss: 1.4241753816604614, Final Batch Loss: 0.6489209532737732\n",
      "Epoch 345, Loss: 1.266881287097931, Final Batch Loss: 0.4245606064796448\n",
      "Epoch 346, Loss: 1.476621150970459, Final Batch Loss: 0.7306423187255859\n",
      "Epoch 347, Loss: 1.0179890990257263, Final Batch Loss: 0.3154143989086151\n",
      "Epoch 348, Loss: 1.0851724445819855, Final Batch Loss: 0.2699264585971832\n",
      "Epoch 349, Loss: 1.5530074834823608, Final Batch Loss: 0.7650105357170105\n",
      "Epoch 350, Loss: 1.0684266984462738, Final Batch Loss: 0.33165180683135986\n",
      "Epoch 351, Loss: 1.3689480125904083, Final Batch Loss: 0.627894937992096\n",
      "Epoch 352, Loss: 1.0300305485725403, Final Batch Loss: 0.19556653499603271\n",
      "Epoch 353, Loss: 1.047188252210617, Final Batch Loss: 0.28972697257995605\n",
      "Epoch 354, Loss: 1.2606993615627289, Final Batch Loss: 0.44035157561302185\n",
      "Epoch 355, Loss: 1.3784447610378265, Final Batch Loss: 0.572788417339325\n",
      "Epoch 356, Loss: 1.129355788230896, Final Batch Loss: 0.3416823446750641\n",
      "Epoch 357, Loss: 1.0659434795379639, Final Batch Loss: 0.299381822347641\n",
      "Epoch 358, Loss: 1.228772759437561, Final Batch Loss: 0.49559491872787476\n",
      "Epoch 359, Loss: 0.9885392189025879, Final Batch Loss: 0.22066578269004822\n",
      "Epoch 360, Loss: 1.0635309219360352, Final Batch Loss: 0.3263024091720581\n",
      "Epoch 361, Loss: 1.2048384249210358, Final Batch Loss: 0.4939364790916443\n",
      "Epoch 362, Loss: 1.039784163236618, Final Batch Loss: 0.27937373518943787\n",
      "Epoch 363, Loss: 1.1292617619037628, Final Batch Loss: 0.4062758982181549\n",
      "Epoch 364, Loss: 1.4483627676963806, Final Batch Loss: 0.752912700176239\n",
      "Epoch 365, Loss: 0.9981693029403687, Final Batch Loss: 0.2366521954536438\n",
      "Epoch 366, Loss: 1.1481042206287384, Final Batch Loss: 0.439165860414505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367, Loss: 0.9588837325572968, Final Batch Loss: 0.2224292755126953\n",
      "Epoch 368, Loss: 1.2513839900493622, Final Batch Loss: 0.5081381797790527\n",
      "Epoch 369, Loss: 1.1495431661605835, Final Batch Loss: 0.44022706151008606\n",
      "Epoch 370, Loss: 1.1062564253807068, Final Batch Loss: 0.36789798736572266\n",
      "Epoch 371, Loss: 0.9932963252067566, Final Batch Loss: 0.2732655107975006\n",
      "Epoch 372, Loss: 1.0965668857097626, Final Batch Loss: 0.3051631450653076\n",
      "Epoch 373, Loss: 1.1517189145088196, Final Batch Loss: 0.39363232254981995\n",
      "Epoch 374, Loss: 0.8663430213928223, Final Batch Loss: 0.16970103979110718\n",
      "Epoch 375, Loss: 1.2753191888332367, Final Batch Loss: 0.5631345510482788\n",
      "Epoch 376, Loss: 1.0546168982982635, Final Batch Loss: 0.38109728693962097\n",
      "Epoch 377, Loss: 1.0032325088977814, Final Batch Loss: 0.31977376341819763\n",
      "Epoch 378, Loss: 1.2648912370204926, Final Batch Loss: 0.5651450157165527\n",
      "Epoch 379, Loss: 1.1463593244552612, Final Batch Loss: 0.4172988831996918\n",
      "Epoch 380, Loss: 1.0134764909744263, Final Batch Loss: 0.3337523639202118\n",
      "Epoch 381, Loss: 1.0808302164077759, Final Batch Loss: 0.34779953956604004\n",
      "Epoch 382, Loss: 0.9679409265518188, Final Batch Loss: 0.2478305697441101\n",
      "Epoch 383, Loss: 1.4110329747200012, Final Batch Loss: 0.6439956426620483\n",
      "Epoch 384, Loss: 0.9345163255929947, Final Batch Loss: 0.21031753718852997\n",
      "Epoch 385, Loss: 1.0167362987995148, Final Batch Loss: 0.3159228265285492\n",
      "Epoch 386, Loss: 0.974806159734726, Final Batch Loss: 0.2736918032169342\n",
      "Epoch 387, Loss: 0.9955613911151886, Final Batch Loss: 0.2637838125228882\n",
      "Epoch 388, Loss: 1.1728825867176056, Final Batch Loss: 0.41654759645462036\n",
      "Epoch 389, Loss: 1.2311753630638123, Final Batch Loss: 0.5136078000068665\n",
      "Epoch 390, Loss: 1.0480607151985168, Final Batch Loss: 0.38735172152519226\n",
      "Epoch 391, Loss: 1.197922170162201, Final Batch Loss: 0.4665677547454834\n",
      "Epoch 392, Loss: 1.146404504776001, Final Batch Loss: 0.3930758535861969\n",
      "Epoch 393, Loss: 1.078469842672348, Final Batch Loss: 0.3275970220565796\n",
      "Epoch 394, Loss: 1.1673425436019897, Final Batch Loss: 0.49998512864112854\n",
      "Epoch 395, Loss: 1.1994642913341522, Final Batch Loss: 0.4669235050678253\n",
      "Epoch 396, Loss: 0.9829148948192596, Final Batch Loss: 0.24381482601165771\n",
      "Epoch 397, Loss: 1.0034904479980469, Final Batch Loss: 0.3380427360534668\n",
      "Epoch 398, Loss: 0.9691167175769806, Final Batch Loss: 0.3407314121723175\n",
      "Epoch 399, Loss: 0.9968899190425873, Final Batch Loss: 0.33552634716033936\n",
      "Epoch 400, Loss: 0.9916994273662567, Final Batch Loss: 0.3251039981842041\n",
      "Epoch 401, Loss: 0.921968936920166, Final Batch Loss: 0.2550085484981537\n",
      "Epoch 402, Loss: 1.0726145207881927, Final Batch Loss: 0.346573144197464\n",
      "Epoch 403, Loss: 1.0331099033355713, Final Batch Loss: 0.385684996843338\n",
      "Epoch 404, Loss: 0.8540681600570679, Final Batch Loss: 0.12698039412498474\n",
      "Epoch 405, Loss: 1.036740928888321, Final Batch Loss: 0.35338297486305237\n",
      "Epoch 406, Loss: 1.1171118021011353, Final Batch Loss: 0.4263679087162018\n",
      "Epoch 407, Loss: 0.8669824153184891, Final Batch Loss: 0.20275689661502838\n",
      "Epoch 408, Loss: 1.0335669219493866, Final Batch Loss: 0.4149056375026703\n",
      "Epoch 409, Loss: 1.374768227338791, Final Batch Loss: 0.6833609342575073\n",
      "Epoch 410, Loss: 1.0107797980308533, Final Batch Loss: 0.2880329489707947\n",
      "Epoch 411, Loss: 0.7603665739297867, Final Batch Loss: 0.06946484744548798\n",
      "Epoch 412, Loss: 1.3545236885547638, Final Batch Loss: 0.6339027285575867\n",
      "Epoch 413, Loss: 0.964152067899704, Final Batch Loss: 0.26405709981918335\n",
      "Epoch 414, Loss: 0.9187288284301758, Final Batch Loss: 0.2073984444141388\n",
      "Epoch 415, Loss: 1.096017062664032, Final Batch Loss: 0.40824276208877563\n",
      "Epoch 416, Loss: 1.00973841547966, Final Batch Loss: 0.3122020661830902\n",
      "Epoch 417, Loss: 1.2907381653785706, Final Batch Loss: 0.5704373121261597\n",
      "Epoch 418, Loss: 0.9602752029895782, Final Batch Loss: 0.2672387361526489\n",
      "Epoch 419, Loss: 0.7726157009601593, Final Batch Loss: 0.07876387238502502\n",
      "Epoch 420, Loss: 0.9220644384622574, Final Batch Loss: 0.21889834105968475\n",
      "Epoch 421, Loss: 1.0251579582691193, Final Batch Loss: 0.32034265995025635\n",
      "Epoch 422, Loss: 1.00520658493042, Final Batch Loss: 0.3441019356250763\n",
      "Epoch 423, Loss: 1.2559736967086792, Final Batch Loss: 0.6511530876159668\n",
      "Epoch 424, Loss: 0.91573266685009, Final Batch Loss: 0.2087676078081131\n",
      "Epoch 425, Loss: 0.8569064736366272, Final Batch Loss: 0.17311033606529236\n",
      "Epoch 426, Loss: 0.8436502665281296, Final Batch Loss: 0.16711564362049103\n",
      "Epoch 427, Loss: 0.9431205689907074, Final Batch Loss: 0.2606320083141327\n",
      "Epoch 428, Loss: 1.0556456744670868, Final Batch Loss: 0.357499361038208\n",
      "Epoch 429, Loss: 1.090616524219513, Final Batch Loss: 0.43550214171409607\n",
      "Epoch 430, Loss: 1.0562834441661835, Final Batch Loss: 0.3746245503425598\n",
      "Epoch 431, Loss: 1.2272294759750366, Final Batch Loss: 0.5929180979728699\n",
      "Epoch 432, Loss: 1.0871561169624329, Final Batch Loss: 0.4163118302822113\n",
      "Epoch 433, Loss: 0.8377712517976761, Final Batch Loss: 0.1541355699300766\n",
      "Epoch 434, Loss: 1.11558598279953, Final Batch Loss: 0.4808744192123413\n",
      "Epoch 435, Loss: 1.1202565729618073, Final Batch Loss: 0.46552973985671997\n",
      "Epoch 436, Loss: 1.170335292816162, Final Batch Loss: 0.47240519523620605\n",
      "Epoch 437, Loss: 1.0062078535556793, Final Batch Loss: 0.3289886713027954\n",
      "Epoch 438, Loss: 1.081629902124405, Final Batch Loss: 0.33597230911254883\n",
      "Epoch 439, Loss: 0.8925674706697464, Final Batch Loss: 0.23363377153873444\n",
      "Epoch 440, Loss: 1.033382922410965, Final Batch Loss: 0.3332403898239136\n",
      "Epoch 441, Loss: 1.0522256791591644, Final Batch Loss: 0.43127375841140747\n",
      "Epoch 442, Loss: 0.9722889363765717, Final Batch Loss: 0.3254183530807495\n",
      "Epoch 443, Loss: 1.1264562904834747, Final Batch Loss: 0.42733022570610046\n",
      "Epoch 444, Loss: 1.0424924790859222, Final Batch Loss: 0.3652476966381073\n",
      "Epoch 445, Loss: 1.3048234283924103, Final Batch Loss: 0.6621139049530029\n",
      "Epoch 446, Loss: 0.9774454832077026, Final Batch Loss: 0.25076258182525635\n",
      "Epoch 447, Loss: 0.8738200068473816, Final Batch Loss: 0.17216917872428894\n",
      "Epoch 448, Loss: 1.0010225474834442, Final Batch Loss: 0.34582775831222534\n",
      "Epoch 449, Loss: 0.9703432619571686, Final Batch Loss: 0.3327427804470062\n",
      "Epoch 450, Loss: 0.9067190140485764, Final Batch Loss: 0.17863936722278595\n",
      "Epoch 451, Loss: 1.161387711763382, Final Batch Loss: 0.5896647572517395\n",
      "Epoch 452, Loss: 0.7889760285615921, Final Batch Loss: 0.19245313107967377\n",
      "Epoch 453, Loss: 0.9346350431442261, Final Batch Loss: 0.2391459047794342\n",
      "Epoch 454, Loss: 0.964832991361618, Final Batch Loss: 0.2818082571029663\n",
      "Epoch 455, Loss: 0.9699792861938477, Final Batch Loss: 0.33297574520111084\n",
      "Epoch 456, Loss: 0.9335393309593201, Final Batch Loss: 0.2810556888580322\n",
      "Epoch 457, Loss: 1.0586283206939697, Final Batch Loss: 0.31252121925354004\n",
      "Epoch 458, Loss: 0.9973601996898651, Final Batch Loss: 0.2813883125782013\n",
      "Epoch 459, Loss: 0.8272425085306168, Final Batch Loss: 0.17735107243061066\n",
      "Epoch 460, Loss: 0.959245502948761, Final Batch Loss: 0.28859633207321167\n",
      "Epoch 461, Loss: 0.8500402867794037, Final Batch Loss: 0.2598019540309906\n",
      "Epoch 462, Loss: 0.846497431397438, Final Batch Loss: 0.2050754874944687\n",
      "Epoch 463, Loss: 0.8393574506044388, Final Batch Loss: 0.20672856271266937\n",
      "Epoch 464, Loss: 1.077910989522934, Final Batch Loss: 0.3782760202884674\n",
      "Epoch 465, Loss: 1.0759444534778595, Final Batch Loss: 0.41689956188201904\n",
      "Epoch 466, Loss: 0.8201998770236969, Final Batch Loss: 0.2011163830757141\n",
      "Epoch 467, Loss: 0.810981422662735, Final Batch Loss: 0.23940274119377136\n",
      "Epoch 468, Loss: 1.066836267709732, Final Batch Loss: 0.45391756296157837\n",
      "Epoch 469, Loss: 1.0296472907066345, Final Batch Loss: 0.4375291168689728\n",
      "Epoch 470, Loss: 0.9588008224964142, Final Batch Loss: 0.37429195642471313\n",
      "Epoch 471, Loss: 1.0130587816238403, Final Batch Loss: 0.2981131672859192\n",
      "Epoch 472, Loss: 0.8233307600021362, Final Batch Loss: 0.19889983534812927\n",
      "Epoch 473, Loss: 1.0339671671390533, Final Batch Loss: 0.3730440139770508\n",
      "Epoch 474, Loss: 0.8574591726064682, Final Batch Loss: 0.21678109467029572\n",
      "Epoch 475, Loss: 1.000834196805954, Final Batch Loss: 0.32280367612838745\n",
      "Epoch 476, Loss: 0.9022043347358704, Final Batch Loss: 0.2647860646247864\n",
      "Epoch 477, Loss: 1.1577971279621124, Final Batch Loss: 0.5241780281066895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478, Loss: 1.1895917356014252, Final Batch Loss: 0.5328016877174377\n",
      "Epoch 479, Loss: 1.2737302780151367, Final Batch Loss: 0.5707862377166748\n",
      "Epoch 480, Loss: 1.0092034935951233, Final Batch Loss: 0.39815038442611694\n",
      "Epoch 481, Loss: 1.055022269487381, Final Batch Loss: 0.3358890414237976\n",
      "Epoch 482, Loss: 0.8046786934137344, Final Batch Loss: 0.16472573578357697\n",
      "Epoch 483, Loss: 0.9100694954395294, Final Batch Loss: 0.3191549777984619\n",
      "Epoch 484, Loss: 0.9914953112602234, Final Batch Loss: 0.3452851176261902\n",
      "Epoch 485, Loss: 0.9163239598274231, Final Batch Loss: 0.21950548887252808\n",
      "Epoch 486, Loss: 1.0605765879154205, Final Batch Loss: 0.4498912990093231\n",
      "Epoch 487, Loss: 0.994173139333725, Final Batch Loss: 0.3868243098258972\n",
      "Epoch 488, Loss: 1.2501992881298065, Final Batch Loss: 0.5639543533325195\n",
      "Epoch 489, Loss: 0.9315674006938934, Final Batch Loss: 0.26841115951538086\n",
      "Epoch 490, Loss: 1.169798195362091, Final Batch Loss: 0.49985161423683167\n",
      "Epoch 491, Loss: 0.9925616085529327, Final Batch Loss: 0.3938285708427429\n",
      "Epoch 492, Loss: 1.2042477428913116, Final Batch Loss: 0.559699535369873\n",
      "Epoch 493, Loss: 1.1097473800182343, Final Batch Loss: 0.4264104664325714\n",
      "Epoch 494, Loss: 0.9686749875545502, Final Batch Loss: 0.32223549485206604\n",
      "Epoch 495, Loss: 1.0243432521820068, Final Batch Loss: 0.33832892775535583\n",
      "Epoch 496, Loss: 1.0552457869052887, Final Batch Loss: 0.37739652395248413\n",
      "Epoch 497, Loss: 0.954280436038971, Final Batch Loss: 0.31166115403175354\n",
      "Epoch 498, Loss: 1.0856839418411255, Final Batch Loss: 0.3903946280479431\n",
      "Epoch 499, Loss: 1.4219472408294678, Final Batch Loss: 0.7843689918518066\n",
      "Epoch 500, Loss: 0.9124789834022522, Final Batch Loss: 0.30882683396339417\n",
      "Epoch 501, Loss: 0.8229456841945648, Final Batch Loss: 0.1570981740951538\n",
      "Epoch 502, Loss: 1.006543129682541, Final Batch Loss: 0.336716890335083\n",
      "Epoch 503, Loss: 0.9429653882980347, Final Batch Loss: 0.3281727433204651\n",
      "Epoch 504, Loss: 0.9844387173652649, Final Batch Loss: 0.3979801535606384\n",
      "Epoch 505, Loss: 0.866167888045311, Final Batch Loss: 0.18493406474590302\n",
      "Epoch 506, Loss: 0.8466537445783615, Final Batch Loss: 0.2311532348394394\n",
      "Epoch 507, Loss: 1.0147568583488464, Final Batch Loss: 0.36367425322532654\n",
      "Epoch 508, Loss: 0.8639788329601288, Final Batch Loss: 0.22982949018478394\n",
      "Epoch 509, Loss: 0.9947361350059509, Final Batch Loss: 0.3700273931026459\n",
      "Epoch 510, Loss: 0.9000843465328217, Final Batch Loss: 0.2805216312408447\n",
      "Epoch 511, Loss: 0.8559834063053131, Final Batch Loss: 0.21199211478233337\n",
      "Epoch 512, Loss: 0.9497438967227936, Final Batch Loss: 0.3059055507183075\n",
      "Epoch 513, Loss: 0.9277046620845795, Final Batch Loss: 0.2547895908355713\n",
      "Epoch 514, Loss: 1.0465377271175385, Final Batch Loss: 0.374460905790329\n",
      "Epoch 515, Loss: 1.0992913246154785, Final Batch Loss: 0.4360353648662567\n",
      "Epoch 516, Loss: 0.8482699692249298, Final Batch Loss: 0.2622775435447693\n",
      "Epoch 517, Loss: 0.8085415065288544, Final Batch Loss: 0.19160914421081543\n",
      "Epoch 518, Loss: 0.8664005696773529, Final Batch Loss: 0.29026132822036743\n",
      "Epoch 519, Loss: 0.8066096156835556, Final Batch Loss: 0.16783885657787323\n",
      "Epoch 520, Loss: 0.6978794038295746, Final Batch Loss: 0.1276252269744873\n",
      "Epoch 521, Loss: 0.8242622017860413, Final Batch Loss: 0.17851373553276062\n",
      "Epoch 522, Loss: 0.9188151359558105, Final Batch Loss: 0.31696048378944397\n",
      "Epoch 523, Loss: 1.102309226989746, Final Batch Loss: 0.4464252293109894\n",
      "Epoch 524, Loss: 0.9365890324115753, Final Batch Loss: 0.3217027187347412\n",
      "Epoch 525, Loss: 0.8359805643558502, Final Batch Loss: 0.2259068787097931\n",
      "Epoch 526, Loss: 0.7897513806819916, Final Batch Loss: 0.15177220106124878\n",
      "Epoch 527, Loss: 1.095461368560791, Final Batch Loss: 0.5087278485298157\n",
      "Epoch 528, Loss: 0.8116283267736435, Final Batch Loss: 0.21960632503032684\n",
      "Epoch 529, Loss: 1.116640955209732, Final Batch Loss: 0.4572886824607849\n",
      "Epoch 530, Loss: 1.0831018090248108, Final Batch Loss: 0.47745171189308167\n",
      "Epoch 531, Loss: 0.9802209436893463, Final Batch Loss: 0.3974683880805969\n",
      "Epoch 532, Loss: 0.8540988862514496, Final Batch Loss: 0.2294560670852661\n",
      "Epoch 533, Loss: 0.7864724099636078, Final Batch Loss: 0.20015907287597656\n",
      "Epoch 534, Loss: 0.9363455474376678, Final Batch Loss: 0.2702963352203369\n",
      "Epoch 535, Loss: 1.1325647830963135, Final Batch Loss: 0.512039840221405\n",
      "Epoch 536, Loss: 1.0378243029117584, Final Batch Loss: 0.43488970398902893\n",
      "Epoch 537, Loss: 0.7277026623487473, Final Batch Loss: 0.14563976228237152\n",
      "Epoch 538, Loss: 0.8663954585790634, Final Batch Loss: 0.24510468542575836\n",
      "Epoch 539, Loss: 0.9434553682804108, Final Batch Loss: 0.34914931654930115\n",
      "Epoch 540, Loss: 0.6789025217294693, Final Batch Loss: 0.07585252821445465\n",
      "Epoch 541, Loss: 0.8343001306056976, Final Batch Loss: 0.23758161067962646\n",
      "Epoch 542, Loss: 1.0368213653564453, Final Batch Loss: 0.4661117494106293\n",
      "Epoch 543, Loss: 1.0815458595752716, Final Batch Loss: 0.5015013813972473\n",
      "Epoch 544, Loss: 0.7108727172017097, Final Batch Loss: 0.07641182094812393\n",
      "Epoch 545, Loss: 0.8908632546663284, Final Batch Loss: 0.22374562919139862\n",
      "Epoch 546, Loss: 0.8257452100515366, Final Batch Loss: 0.14118333160877228\n",
      "Epoch 547, Loss: 1.0925767421722412, Final Batch Loss: 0.4635631740093231\n",
      "Epoch 548, Loss: 1.0110134184360504, Final Batch Loss: 0.3782070577144623\n",
      "Epoch 549, Loss: 0.9191096425056458, Final Batch Loss: 0.3503834307193756\n",
      "Epoch 550, Loss: 0.9887100458145142, Final Batch Loss: 0.41436299681663513\n",
      "Epoch 551, Loss: 0.8421481400728226, Final Batch Loss: 0.32143887877464294\n",
      "Epoch 552, Loss: 1.1417227387428284, Final Batch Loss: 0.5666550397872925\n",
      "Epoch 553, Loss: 0.8766880035400391, Final Batch Loss: 0.30032068490982056\n",
      "Epoch 554, Loss: 0.7794810086488724, Final Batch Loss: 0.20259146392345428\n",
      "Epoch 555, Loss: 0.9585990607738495, Final Batch Loss: 0.3522333800792694\n",
      "Epoch 556, Loss: 0.9007832109928131, Final Batch Loss: 0.2720101475715637\n",
      "Epoch 557, Loss: 1.027176022529602, Final Batch Loss: 0.41767701506614685\n",
      "Epoch 558, Loss: 0.8548649698495865, Final Batch Loss: 0.19613678753376007\n",
      "Epoch 559, Loss: 0.7511902078986168, Final Batch Loss: 0.09672843664884567\n",
      "Epoch 560, Loss: 0.9248200207948685, Final Batch Loss: 0.35807251930236816\n",
      "Epoch 561, Loss: 1.0326487123966217, Final Batch Loss: 0.48938295245170593\n",
      "Epoch 562, Loss: 0.9911494851112366, Final Batch Loss: 0.3992501199245453\n",
      "Epoch 563, Loss: 0.8072029203176498, Final Batch Loss: 0.1970687359571457\n",
      "Epoch 564, Loss: 0.8373951613903046, Final Batch Loss: 0.2501586079597473\n",
      "Epoch 565, Loss: 0.8792771100997925, Final Batch Loss: 0.26763272285461426\n",
      "Epoch 566, Loss: 0.913068413734436, Final Batch Loss: 0.3392196595668793\n",
      "Epoch 567, Loss: 0.8778492212295532, Final Batch Loss: 0.23299723863601685\n",
      "Epoch 568, Loss: 0.8277253210544586, Final Batch Loss: 0.1981273889541626\n",
      "Epoch 569, Loss: 0.7616667747497559, Final Batch Loss: 0.1541166603565216\n",
      "Epoch 570, Loss: 1.0254890322685242, Final Batch Loss: 0.4794084131717682\n",
      "Epoch 571, Loss: 0.8049068748950958, Final Batch Loss: 0.23112738132476807\n",
      "Epoch 572, Loss: 0.7997636944055557, Final Batch Loss: 0.19394178688526154\n",
      "Epoch 573, Loss: 0.9886512160301208, Final Batch Loss: 0.40634679794311523\n",
      "Epoch 574, Loss: 0.7179456725716591, Final Batch Loss: 0.0764908567070961\n",
      "Epoch 575, Loss: 0.7757595628499985, Final Batch Loss: 0.22809505462646484\n",
      "Epoch 576, Loss: 0.9150693714618683, Final Batch Loss: 0.2804957330226898\n",
      "Epoch 577, Loss: 0.7190198600292206, Final Batch Loss: 0.1414521336555481\n",
      "Epoch 578, Loss: 0.8415667712688446, Final Batch Loss: 0.23315605521202087\n",
      "Epoch 579, Loss: 1.069438636302948, Final Batch Loss: 0.5427372455596924\n",
      "Epoch 580, Loss: 1.3311273753643036, Final Batch Loss: 0.6851106286048889\n",
      "Epoch 581, Loss: 0.8562110662460327, Final Batch Loss: 0.28954780101776123\n",
      "Epoch 582, Loss: 0.8799587488174438, Final Batch Loss: 0.2775871753692627\n",
      "Epoch 583, Loss: 0.9169903993606567, Final Batch Loss: 0.3177492618560791\n",
      "Epoch 584, Loss: 1.0305864214897156, Final Batch Loss: 0.4234750270843506\n",
      "Epoch 585, Loss: 0.9262632429599762, Final Batch Loss: 0.25588202476501465\n",
      "Epoch 586, Loss: 0.8957214057445526, Final Batch Loss: 0.3380033075809479\n",
      "Epoch 587, Loss: 0.7806350439786911, Final Batch Loss: 0.21907557547092438\n",
      "Epoch 588, Loss: 0.7505887150764465, Final Batch Loss: 0.15669232606887817\n",
      "Epoch 589, Loss: 1.091742843389511, Final Batch Loss: 0.5024991035461426\n",
      "Epoch 590, Loss: 0.8114608973264694, Final Batch Loss: 0.23111315071582794\n",
      "Epoch 591, Loss: 0.9104913175106049, Final Batch Loss: 0.3288685381412506\n",
      "Epoch 592, Loss: 0.9646548926830292, Final Batch Loss: 0.39441078901290894\n",
      "Epoch 593, Loss: 1.1978395283222198, Final Batch Loss: 0.5616670846939087\n",
      "Epoch 594, Loss: 0.8194433450698853, Final Batch Loss: 0.2324829399585724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595, Loss: 0.7391247153282166, Final Batch Loss: 0.1433699131011963\n",
      "Epoch 596, Loss: 0.6537101082503796, Final Batch Loss: 0.048249971121549606\n",
      "Epoch 597, Loss: 0.9150182902812958, Final Batch Loss: 0.3723500072956085\n",
      "Epoch 598, Loss: 0.7257075905799866, Final Batch Loss: 0.15706828236579895\n",
      "Epoch 599, Loss: 0.7448808997869492, Final Batch Loss: 0.17316432297229767\n",
      "Epoch 600, Loss: 0.6982777863740921, Final Batch Loss: 0.1250208169221878\n",
      "Epoch 601, Loss: 0.8664357662200928, Final Batch Loss: 0.28825613856315613\n",
      "Epoch 602, Loss: 1.0448846220970154, Final Batch Loss: 0.5248274803161621\n",
      "Epoch 603, Loss: 1.0538462698459625, Final Batch Loss: 0.4672715663909912\n",
      "Epoch 604, Loss: 0.9664994180202484, Final Batch Loss: 0.38964220881462097\n",
      "Epoch 605, Loss: 0.680861197412014, Final Batch Loss: 0.10498752444982529\n",
      "Epoch 606, Loss: 0.7390241622924805, Final Batch Loss: 0.15336114168167114\n",
      "Epoch 607, Loss: 0.6561589017510414, Final Batch Loss: 0.08702609688043594\n",
      "Epoch 608, Loss: 0.9038529992103577, Final Batch Loss: 0.3591785430908203\n",
      "Epoch 609, Loss: 0.8130277544260025, Final Batch Loss: 0.21677012741565704\n",
      "Epoch 610, Loss: 1.005641520023346, Final Batch Loss: 0.47209253907203674\n",
      "Epoch 611, Loss: 0.8072220236063004, Final Batch Loss: 0.24079006910324097\n",
      "Epoch 612, Loss: 0.9816617965698242, Final Batch Loss: 0.3884473741054535\n",
      "Epoch 613, Loss: 0.8457635045051575, Final Batch Loss: 0.319507896900177\n",
      "Epoch 614, Loss: 1.058121383190155, Final Batch Loss: 0.4868234694004059\n",
      "Epoch 615, Loss: 0.6762541308999062, Final Batch Loss: 0.12211931496858597\n",
      "Epoch 616, Loss: 0.7490032762289047, Final Batch Loss: 0.1425209492444992\n",
      "Epoch 617, Loss: 0.7816653698682785, Final Batch Loss: 0.22165517508983612\n",
      "Epoch 618, Loss: 0.7357512265443802, Final Batch Loss: 0.13978050649166107\n",
      "Epoch 619, Loss: 0.7755848169326782, Final Batch Loss: 0.1673547327518463\n",
      "Epoch 620, Loss: 0.9172249138355255, Final Batch Loss: 0.2844144105911255\n",
      "Epoch 621, Loss: 0.8046928197145462, Final Batch Loss: 0.21470069885253906\n",
      "Epoch 622, Loss: 0.7084827423095703, Final Batch Loss: 0.126930832862854\n",
      "Epoch 623, Loss: 0.9270571172237396, Final Batch Loss: 0.3748244643211365\n",
      "Epoch 624, Loss: 0.8534312099218369, Final Batch Loss: 0.3044792413711548\n",
      "Epoch 625, Loss: 0.6807211488485336, Final Batch Loss: 0.15341784060001373\n",
      "Epoch 626, Loss: 0.7410220801830292, Final Batch Loss: 0.2252177745103836\n",
      "Epoch 627, Loss: 0.6896567344665527, Final Batch Loss: 0.10060268640518188\n",
      "Epoch 628, Loss: 0.8230959326028824, Final Batch Loss: 0.23023982346057892\n",
      "Epoch 629, Loss: 0.836167186498642, Final Batch Loss: 0.3037134110927582\n",
      "Epoch 630, Loss: 0.6215051934123039, Final Batch Loss: 0.07063279300928116\n",
      "Epoch 631, Loss: 0.7873425483703613, Final Batch Loss: 0.2799685001373291\n",
      "Epoch 632, Loss: 0.9051671922206879, Final Batch Loss: 0.3272411525249481\n",
      "Epoch 633, Loss: 0.8711560964584351, Final Batch Loss: 0.3373497724533081\n",
      "Epoch 634, Loss: 0.753750741481781, Final Batch Loss: 0.15556129813194275\n",
      "Epoch 635, Loss: 0.8479885160923004, Final Batch Loss: 0.302447110414505\n",
      "Epoch 636, Loss: 0.912832647562027, Final Batch Loss: 0.3281502425670624\n",
      "Epoch 637, Loss: 0.8385151028633118, Final Batch Loss: 0.3082066774368286\n",
      "Epoch 638, Loss: 0.706047460436821, Final Batch Loss: 0.17174647748470306\n",
      "Epoch 639, Loss: 0.9529410302639008, Final Batch Loss: 0.40610960125923157\n",
      "Epoch 640, Loss: 0.7873342931270599, Final Batch Loss: 0.1918374001979828\n",
      "Epoch 641, Loss: 0.7809018716216087, Final Batch Loss: 0.1191297098994255\n",
      "Epoch 642, Loss: 0.8751674592494965, Final Batch Loss: 0.2738736867904663\n",
      "Epoch 643, Loss: 0.7716565877199173, Final Batch Loss: 0.1727745085954666\n",
      "Epoch 644, Loss: 1.0771585702896118, Final Batch Loss: 0.556156575679779\n",
      "Epoch 645, Loss: 0.6520202308893204, Final Batch Loss: 0.1401054412126541\n",
      "Epoch 646, Loss: 0.7329173982143402, Final Batch Loss: 0.1964426338672638\n",
      "Epoch 647, Loss: 0.8454107344150543, Final Batch Loss: 0.3093262016773224\n",
      "Epoch 648, Loss: 0.7395198047161102, Final Batch Loss: 0.19384247064590454\n",
      "Epoch 649, Loss: 0.7399150878190994, Final Batch Loss: 0.17464785277843475\n",
      "Epoch 650, Loss: 0.9995313137769699, Final Batch Loss: 0.48156678676605225\n",
      "Epoch 651, Loss: 0.7410478442907333, Final Batch Loss: 0.16544903814792633\n",
      "Epoch 652, Loss: 0.6377978622913361, Final Batch Loss: 0.1510995775461197\n",
      "Epoch 653, Loss: 0.8612516820430756, Final Batch Loss: 0.33138394355773926\n",
      "Epoch 654, Loss: 1.1302126049995422, Final Batch Loss: 0.5696136355400085\n",
      "Epoch 655, Loss: 0.9717564880847931, Final Batch Loss: 0.3592471182346344\n",
      "Epoch 656, Loss: 0.7977825850248337, Final Batch Loss: 0.2074267417192459\n",
      "Epoch 657, Loss: 0.687573991715908, Final Batch Loss: 0.12347989529371262\n",
      "Epoch 658, Loss: 0.7125796526670456, Final Batch Loss: 0.12420392036437988\n",
      "Epoch 659, Loss: 0.6765985637903214, Final Batch Loss: 0.13861770927906036\n",
      "Epoch 660, Loss: 0.7128778994083405, Final Batch Loss: 0.17787234485149384\n",
      "Epoch 661, Loss: 0.7132390886545181, Final Batch Loss: 0.21012873947620392\n",
      "Epoch 662, Loss: 0.6825566366314888, Final Batch Loss: 0.0964018777012825\n",
      "Epoch 663, Loss: 0.8306781053543091, Final Batch Loss: 0.27612218260765076\n",
      "Epoch 664, Loss: 0.9505005031824112, Final Batch Loss: 0.4306957423686981\n",
      "Epoch 665, Loss: 0.9203189611434937, Final Batch Loss: 0.3659497797489166\n",
      "Epoch 666, Loss: 0.7184849381446838, Final Batch Loss: 0.16891399025917053\n",
      "Epoch 667, Loss: 0.7910441011190414, Final Batch Loss: 0.2427736073732376\n",
      "Epoch 668, Loss: 0.7305820137262344, Final Batch Loss: 0.21699373424053192\n",
      "Epoch 669, Loss: 0.6914631947875023, Final Batch Loss: 0.11697422713041306\n",
      "Epoch 670, Loss: 0.8575185835361481, Final Batch Loss: 0.306352436542511\n",
      "Epoch 671, Loss: 0.7656056433916092, Final Batch Loss: 0.20805783569812775\n",
      "Epoch 672, Loss: 0.7373355627059937, Final Batch Loss: 0.2352013885974884\n",
      "Epoch 673, Loss: 0.8706246912479401, Final Batch Loss: 0.30749276280403137\n",
      "Epoch 674, Loss: 0.9220196604728699, Final Batch Loss: 0.42039698362350464\n",
      "Epoch 675, Loss: 0.7363108247518539, Final Batch Loss: 0.1935749500989914\n",
      "Epoch 676, Loss: 0.8534531146287918, Final Batch Loss: 0.24587412178516388\n",
      "Epoch 677, Loss: 0.8505634069442749, Final Batch Loss: 0.20869481563568115\n",
      "Epoch 678, Loss: 0.9150737822055817, Final Batch Loss: 0.3270243704319\n",
      "Epoch 679, Loss: 0.7859249413013458, Final Batch Loss: 0.21266648173332214\n",
      "Epoch 680, Loss: 1.0161206126213074, Final Batch Loss: 0.4077271521091461\n",
      "Epoch 681, Loss: 0.7064681649208069, Final Batch Loss: 0.1720673143863678\n",
      "Epoch 682, Loss: 0.871229812502861, Final Batch Loss: 0.36844947934150696\n",
      "Epoch 683, Loss: 0.8188778907060623, Final Batch Loss: 0.17781753838062286\n",
      "Epoch 684, Loss: 0.7487314343452454, Final Batch Loss: 0.17385751008987427\n",
      "Epoch 685, Loss: 0.6225242763757706, Final Batch Loss: 0.07587386667728424\n",
      "Epoch 686, Loss: 0.8067318499088287, Final Batch Loss: 0.21033009886741638\n",
      "Epoch 687, Loss: 0.791002944111824, Final Batch Loss: 0.19475115835666656\n",
      "Epoch 688, Loss: 1.0038330256938934, Final Batch Loss: 0.39682331681251526\n",
      "Epoch 689, Loss: 0.7158436924219131, Final Batch Loss: 0.17890474200248718\n",
      "Epoch 690, Loss: 0.8948150426149368, Final Batch Loss: 0.32047152519226074\n",
      "Epoch 691, Loss: 0.7665264457464218, Final Batch Loss: 0.222763791680336\n",
      "Epoch 692, Loss: 0.6083315536379814, Final Batch Loss: 0.08767919987440109\n",
      "Epoch 693, Loss: 0.8108180612325668, Final Batch Loss: 0.23867662250995636\n",
      "Epoch 694, Loss: 1.1180441975593567, Final Batch Loss: 0.5711168646812439\n",
      "Epoch 695, Loss: 0.6898061633110046, Final Batch Loss: 0.1400359869003296\n",
      "Epoch 696, Loss: 0.7920799404382706, Final Batch Loss: 0.2236367017030716\n",
      "Epoch 697, Loss: 0.9281306862831116, Final Batch Loss: 0.432151198387146\n",
      "Epoch 698, Loss: 0.8026607185602188, Final Batch Loss: 0.24661372601985931\n",
      "Epoch 699, Loss: 0.9233132153749466, Final Batch Loss: 0.38449737429618835\n",
      "Epoch 700, Loss: 0.7433296740055084, Final Batch Loss: 0.2071414738893509\n",
      "Epoch 701, Loss: 1.00998917222023, Final Batch Loss: 0.42181912064552307\n",
      "Epoch 702, Loss: 0.9334199279546738, Final Batch Loss: 0.43405142426490784\n",
      "Epoch 703, Loss: 0.8699319809675217, Final Batch Loss: 0.34219059348106384\n",
      "Epoch 704, Loss: 0.8329591453075409, Final Batch Loss: 0.3468131124973297\n",
      "Epoch 705, Loss: 0.705116517841816, Final Batch Loss: 0.10928068310022354\n",
      "Epoch 706, Loss: 0.7011861652135849, Final Batch Loss: 0.1878032684326172\n",
      "Epoch 707, Loss: 0.8320225030183792, Final Batch Loss: 0.2917082905769348\n",
      "Epoch 708, Loss: 0.7688132524490356, Final Batch Loss: 0.245039165019989\n",
      "Epoch 709, Loss: 0.6683725714683533, Final Batch Loss: 0.13107162714004517\n",
      "Epoch 710, Loss: 0.953540563583374, Final Batch Loss: 0.44646111130714417\n",
      "Epoch 711, Loss: 0.8201584964990616, Final Batch Loss: 0.2940479516983032\n",
      "Epoch 712, Loss: 0.9177230298519135, Final Batch Loss: 0.2840433120727539\n",
      "Epoch 713, Loss: 0.6674117371439934, Final Batch Loss: 0.10886412113904953\n",
      "Epoch 714, Loss: 0.7390368729829788, Final Batch Loss: 0.1281101256608963\n",
      "Epoch 715, Loss: 0.9962591826915741, Final Batch Loss: 0.40049830079078674\n",
      "Epoch 716, Loss: 0.8898671418428421, Final Batch Loss: 0.37262535095214844\n",
      "Epoch 717, Loss: 0.8948944061994553, Final Batch Loss: 0.2899179458618164\n",
      "Epoch 718, Loss: 0.983860582113266, Final Batch Loss: 0.4031044840812683\n",
      "Epoch 719, Loss: 0.803709551692009, Final Batch Loss: 0.21195103228092194\n",
      "Epoch 720, Loss: 0.8201270401477814, Final Batch Loss: 0.248867005109787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721, Loss: 1.4428032785654068, Final Batch Loss: 0.9167686104774475\n",
      "Epoch 722, Loss: 0.9498677253723145, Final Batch Loss: 0.3474029302597046\n",
      "Epoch 723, Loss: 1.1618748307228088, Final Batch Loss: 0.5962326526641846\n",
      "Epoch 724, Loss: 0.6476786956191063, Final Batch Loss: 0.08086582273244858\n",
      "Epoch 725, Loss: 0.9891165792942047, Final Batch Loss: 0.476722776889801\n",
      "Epoch 726, Loss: 0.6271644756197929, Final Batch Loss: 0.09688370674848557\n",
      "Epoch 727, Loss: 0.7727155983448029, Final Batch Loss: 0.26450058817863464\n",
      "Epoch 728, Loss: 0.9175589680671692, Final Batch Loss: 0.3684319853782654\n",
      "Epoch 729, Loss: 0.8379186391830444, Final Batch Loss: 0.3030223250389099\n",
      "Epoch 730, Loss: 0.8437961935997009, Final Batch Loss: 0.3026612102985382\n",
      "Epoch 731, Loss: 0.763929009437561, Final Batch Loss: 0.24194380640983582\n",
      "Epoch 732, Loss: 0.95632503926754, Final Batch Loss: 0.44338393211364746\n",
      "Epoch 733, Loss: 0.728985384106636, Final Batch Loss: 0.23867662250995636\n",
      "Epoch 734, Loss: 0.960701197385788, Final Batch Loss: 0.34020957350730896\n",
      "Epoch 735, Loss: 0.7810678035020828, Final Batch Loss: 0.22327716648578644\n",
      "Epoch 736, Loss: 0.6936075761914253, Final Batch Loss: 0.09125993400812149\n",
      "Epoch 737, Loss: 0.9319131374359131, Final Batch Loss: 0.4335230886936188\n",
      "Epoch 738, Loss: 0.9011179506778717, Final Batch Loss: 0.3980552852153778\n",
      "Epoch 739, Loss: 1.0290421843528748, Final Batch Loss: 0.5309661030769348\n",
      "Epoch 740, Loss: 0.8977063745260239, Final Batch Loss: 0.3378792107105255\n",
      "Epoch 741, Loss: 0.8884417712688446, Final Batch Loss: 0.3388471007347107\n",
      "Epoch 742, Loss: 0.8200724273920059, Final Batch Loss: 0.29793503880500793\n",
      "Epoch 743, Loss: 0.7138057947158813, Final Batch Loss: 0.18277183175086975\n",
      "Epoch 744, Loss: 0.7978492379188538, Final Batch Loss: 0.2520773410797119\n",
      "Epoch 745, Loss: 1.042656347155571, Final Batch Loss: 0.5241519808769226\n",
      "Epoch 746, Loss: 0.8251925110816956, Final Batch Loss: 0.27932122349739075\n",
      "Epoch 747, Loss: 0.6503770500421524, Final Batch Loss: 0.08602012693881989\n",
      "Epoch 748, Loss: 0.834734708070755, Final Batch Loss: 0.2852410078048706\n",
      "Epoch 749, Loss: 1.1990655958652496, Final Batch Loss: 0.6563819050788879\n",
      "Epoch 750, Loss: 0.7120161205530167, Final Batch Loss: 0.23274092376232147\n",
      "Epoch 751, Loss: 0.8477323651313782, Final Batch Loss: 0.2910134792327881\n",
      "Epoch 752, Loss: 1.0644173175096512, Final Batch Loss: 0.555975615978241\n",
      "Epoch 753, Loss: 0.7314793020486832, Final Batch Loss: 0.2164529711008072\n",
      "Epoch 754, Loss: 0.8170648366212845, Final Batch Loss: 0.2814788520336151\n",
      "Epoch 755, Loss: 0.5976264253258705, Final Batch Loss: 0.09437774866819382\n",
      "Epoch 756, Loss: 0.8621450960636139, Final Batch Loss: 0.3388954997062683\n",
      "Epoch 757, Loss: 0.9914954304695129, Final Batch Loss: 0.39360690116882324\n",
      "Epoch 758, Loss: 0.7522074282169342, Final Batch Loss: 0.27853041887283325\n",
      "Epoch 759, Loss: 0.7483409345149994, Final Batch Loss: 0.21378539502620697\n",
      "Epoch 760, Loss: 0.7909063100814819, Final Batch Loss: 0.2260284721851349\n",
      "Epoch 761, Loss: 0.7589668780565262, Final Batch Loss: 0.2904691994190216\n",
      "Epoch 762, Loss: 0.7262208461761475, Final Batch Loss: 0.22088858485221863\n",
      "Epoch 763, Loss: 0.6507962793111801, Final Batch Loss: 0.18498338758945465\n",
      "Epoch 764, Loss: 0.9499540328979492, Final Batch Loss: 0.4811655282974243\n",
      "Epoch 765, Loss: 0.8125618547201157, Final Batch Loss: 0.3268682360649109\n",
      "Epoch 766, Loss: 0.8675995320081711, Final Batch Loss: 0.36170029640197754\n",
      "Epoch 767, Loss: 0.9309156835079193, Final Batch Loss: 0.4005239009857178\n",
      "Epoch 768, Loss: 0.7981332540512085, Final Batch Loss: 0.21537211537361145\n",
      "Epoch 769, Loss: 0.8064350783824921, Final Batch Loss: 0.26145678758621216\n",
      "Epoch 770, Loss: 0.6149574965238571, Final Batch Loss: 0.0929289311170578\n",
      "Epoch 771, Loss: 1.4470978379249573, Final Batch Loss: 0.877066433429718\n",
      "Epoch 772, Loss: 0.7957683652639389, Final Batch Loss: 0.3066711723804474\n",
      "Epoch 773, Loss: 0.6851120442152023, Final Batch Loss: 0.16183699667453766\n",
      "Epoch 774, Loss: 0.6171193271875381, Final Batch Loss: 0.08998052775859833\n",
      "Epoch 775, Loss: 1.0367040634155273, Final Batch Loss: 0.46331626176834106\n",
      "Epoch 776, Loss: 0.710427775979042, Final Batch Loss: 0.16016332805156708\n",
      "Epoch 777, Loss: 0.928226500749588, Final Batch Loss: 0.42848286032676697\n",
      "Epoch 778, Loss: 0.8544943034648895, Final Batch Loss: 0.3032354414463043\n",
      "Epoch 779, Loss: 0.9379530549049377, Final Batch Loss: 0.4632389545440674\n",
      "Epoch 780, Loss: 0.6398413628339767, Final Batch Loss: 0.13133345544338226\n",
      "Epoch 781, Loss: 0.5979411005973816, Final Batch Loss: 0.06119528412818909\n",
      "Epoch 782, Loss: 0.732825294137001, Final Batch Loss: 0.20832088589668274\n",
      "Epoch 783, Loss: 0.947679340839386, Final Batch Loss: 0.45893001556396484\n",
      "Epoch 784, Loss: 0.6455464288592339, Final Batch Loss: 0.11407675594091415\n",
      "Epoch 785, Loss: 0.7935276180505753, Final Batch Loss: 0.27150389552116394\n",
      "Epoch 786, Loss: 0.8685700297355652, Final Batch Loss: 0.32409247756004333\n",
      "Epoch 787, Loss: 0.735567182302475, Final Batch Loss: 0.13997316360473633\n",
      "Epoch 788, Loss: 0.7130496799945831, Final Batch Loss: 0.16750475764274597\n",
      "Epoch 789, Loss: 0.759719043970108, Final Batch Loss: 0.21322906017303467\n",
      "Epoch 790, Loss: 0.9231861084699631, Final Batch Loss: 0.41515052318573\n",
      "Epoch 791, Loss: 0.812559187412262, Final Batch Loss: 0.21349605917930603\n",
      "Epoch 792, Loss: 0.798291802406311, Final Batch Loss: 0.273084819316864\n",
      "Epoch 793, Loss: 0.8424020260572433, Final Batch Loss: 0.33147314190864563\n",
      "Epoch 794, Loss: 0.6007230319082737, Final Batch Loss: 0.04525506868958473\n",
      "Epoch 795, Loss: 0.7679723650217056, Final Batch Loss: 0.2961575984954834\n",
      "Epoch 796, Loss: 0.7891744822263718, Final Batch Loss: 0.24199031293392181\n",
      "Epoch 797, Loss: 0.7224182486534119, Final Batch Loss: 0.175703763961792\n",
      "Epoch 798, Loss: 0.6586126834154129, Final Batch Loss: 0.15144307911396027\n",
      "Epoch 799, Loss: 0.7884277552366257, Final Batch Loss: 0.2526005506515503\n",
      "Epoch 800, Loss: 0.6150858253240585, Final Batch Loss: 0.09265105426311493\n",
      "Epoch 801, Loss: 0.7824878692626953, Final Batch Loss: 0.2644902169704437\n",
      "Epoch 802, Loss: 0.5996470861136913, Final Batch Loss: 0.05984712764620781\n",
      "Epoch 803, Loss: 0.8570074737071991, Final Batch Loss: 0.30939459800720215\n",
      "Epoch 804, Loss: 0.6720535606145859, Final Batch Loss: 0.1774904429912567\n",
      "Epoch 805, Loss: 0.7815498560667038, Final Batch Loss: 0.3331291675567627\n",
      "Epoch 806, Loss: 0.6776499152183533, Final Batch Loss: 0.18136374652385712\n",
      "Epoch 807, Loss: 0.7017994821071625, Final Batch Loss: 0.14858433604240417\n",
      "Epoch 808, Loss: 0.7373710125684738, Final Batch Loss: 0.21363675594329834\n",
      "Epoch 809, Loss: 0.5731033459305763, Final Batch Loss: 0.11566389352083206\n",
      "Epoch 810, Loss: 0.805011048913002, Final Batch Loss: 0.29371413588523865\n",
      "Epoch 811, Loss: 0.8425134718418121, Final Batch Loss: 0.3246648907661438\n",
      "Epoch 812, Loss: 0.6838649958372116, Final Batch Loss: 0.15146906673908234\n",
      "Epoch 813, Loss: 0.8107540756464005, Final Batch Loss: 0.3380422592163086\n",
      "Epoch 814, Loss: 0.8608084172010422, Final Batch Loss: 0.37541401386260986\n",
      "Epoch 815, Loss: 0.6453307121992111, Final Batch Loss: 0.12313953042030334\n",
      "Epoch 816, Loss: 0.7338791191577911, Final Batch Loss: 0.19141525030136108\n",
      "Epoch 817, Loss: 0.6824324727058411, Final Batch Loss: 0.14181090891361237\n",
      "Epoch 818, Loss: 0.7633105963468552, Final Batch Loss: 0.3029560446739197\n",
      "Epoch 819, Loss: 0.825197234749794, Final Batch Loss: 0.3465537130832672\n",
      "Epoch 820, Loss: 0.6451664716005325, Final Batch Loss: 0.13510245084762573\n",
      "Epoch 821, Loss: 0.7293462455272675, Final Batch Loss: 0.19467207789421082\n",
      "Epoch 822, Loss: 0.7388141751289368, Final Batch Loss: 0.2585809528827667\n",
      "Epoch 823, Loss: 0.7395573258399963, Final Batch Loss: 0.1616590917110443\n",
      "Epoch 824, Loss: 0.8787878453731537, Final Batch Loss: 0.3320581316947937\n",
      "Epoch 825, Loss: 0.8540883660316467, Final Batch Loss: 0.4015181064605713\n",
      "Epoch 826, Loss: 0.7513666599988937, Final Batch Loss: 0.28977933526039124\n",
      "Epoch 827, Loss: 0.8429687917232513, Final Batch Loss: 0.2316570281982422\n",
      "Epoch 828, Loss: 0.8492074012756348, Final Batch Loss: 0.32203197479248047\n",
      "Epoch 829, Loss: 0.6899179816246033, Final Batch Loss: 0.2200116068124771\n",
      "Epoch 830, Loss: 0.9436460435390472, Final Batch Loss: 0.39817020297050476\n",
      "Epoch 831, Loss: 1.0973262786865234, Final Batch Loss: 0.5444166660308838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832, Loss: 1.072256475687027, Final Batch Loss: 0.5062206983566284\n",
      "Epoch 833, Loss: 1.0232951641082764, Final Batch Loss: 0.442750483751297\n",
      "Epoch 834, Loss: 0.6199942231178284, Final Batch Loss: 0.12670867145061493\n",
      "Epoch 835, Loss: 0.8679165989160538, Final Batch Loss: 0.3055357038974762\n",
      "Epoch 836, Loss: 1.00065678358078, Final Batch Loss: 0.5161178708076477\n",
      "Epoch 837, Loss: 0.6482257097959518, Final Batch Loss: 0.12155945599079132\n",
      "Epoch 838, Loss: 0.6074093133211136, Final Batch Loss: 0.133855402469635\n",
      "Epoch 839, Loss: 0.922567754983902, Final Batch Loss: 0.3695601522922516\n",
      "Epoch 840, Loss: 0.718572199344635, Final Batch Loss: 0.18666963279247284\n",
      "Epoch 841, Loss: 0.6477004587650299, Final Batch Loss: 0.19618889689445496\n",
      "Epoch 842, Loss: 0.7765980064868927, Final Batch Loss: 0.30222606658935547\n",
      "Epoch 843, Loss: 0.9130120575428009, Final Batch Loss: 0.37918907403945923\n",
      "Epoch 844, Loss: 0.6575108468532562, Final Batch Loss: 0.14563864469528198\n",
      "Epoch 845, Loss: 0.9003803133964539, Final Batch Loss: 0.42181849479675293\n",
      "Epoch 846, Loss: 0.7241994887590408, Final Batch Loss: 0.24849557876586914\n",
      "Epoch 847, Loss: 0.8634853065013885, Final Batch Loss: 0.36646509170532227\n",
      "Epoch 848, Loss: 0.9953768402338028, Final Batch Loss: 0.47802674770355225\n",
      "Epoch 849, Loss: 0.738813653588295, Final Batch Loss: 0.25211459398269653\n",
      "Epoch 850, Loss: 0.615616500377655, Final Batch Loss: 0.07693785429000854\n",
      "Epoch 851, Loss: 0.9933708012104034, Final Batch Loss: 0.4907641112804413\n",
      "Epoch 852, Loss: 0.6061546355485916, Final Batch Loss: 0.11393021047115326\n",
      "Epoch 853, Loss: 0.8043491393327713, Final Batch Loss: 0.32548198103904724\n",
      "Epoch 854, Loss: 0.8946164697408676, Final Batch Loss: 0.3807070553302765\n",
      "Epoch 855, Loss: 0.5984227135777473, Final Batch Loss: 0.12064873427152634\n",
      "Epoch 856, Loss: 0.5536345615983009, Final Batch Loss: 0.08066023141145706\n",
      "Epoch 857, Loss: 0.8638254553079605, Final Batch Loss: 0.4124656617641449\n",
      "Epoch 858, Loss: 0.6467611491680145, Final Batch Loss: 0.1038021445274353\n",
      "Epoch 859, Loss: 0.8685483336448669, Final Batch Loss: 0.37056246399879456\n",
      "Epoch 860, Loss: 0.6174041330814362, Final Batch Loss: 0.1581997126340866\n",
      "Epoch 861, Loss: 0.7510791271924973, Final Batch Loss: 0.264688104391098\n",
      "Epoch 862, Loss: 0.723689392209053, Final Batch Loss: 0.18800194561481476\n",
      "Epoch 863, Loss: 0.6708069741725922, Final Batch Loss: 0.15172073245048523\n",
      "Epoch 864, Loss: 0.6552052944898605, Final Batch Loss: 0.19058877229690552\n",
      "Epoch 865, Loss: 0.8109884560108185, Final Batch Loss: 0.27194932103157043\n",
      "Epoch 866, Loss: 0.6702145412564278, Final Batch Loss: 0.10765907913446426\n",
      "Epoch 867, Loss: 0.5641270354390144, Final Batch Loss: 0.10801837593317032\n",
      "Epoch 868, Loss: 0.776942789554596, Final Batch Loss: 0.22445914149284363\n",
      "Epoch 869, Loss: 0.8650687336921692, Final Batch Loss: 0.33186790347099304\n",
      "Epoch 870, Loss: 0.6212243884801865, Final Batch Loss: 0.07163435220718384\n",
      "Epoch 871, Loss: 0.6153903231024742, Final Batch Loss: 0.09707436710596085\n",
      "Epoch 872, Loss: 0.7388205975294113, Final Batch Loss: 0.20664750039577484\n",
      "Epoch 873, Loss: 0.7100189626216888, Final Batch Loss: 0.2008613795042038\n",
      "Epoch 874, Loss: 0.6903560757637024, Final Batch Loss: 0.20817072689533234\n",
      "Epoch 875, Loss: 0.6912598311901093, Final Batch Loss: 0.22436127066612244\n",
      "Epoch 876, Loss: 0.6241242587566376, Final Batch Loss: 0.1713501214981079\n",
      "Epoch 877, Loss: 0.9022409617900848, Final Batch Loss: 0.38425129652023315\n",
      "Epoch 878, Loss: 0.6236194744706154, Final Batch Loss: 0.11983000487089157\n",
      "Epoch 879, Loss: 0.7100919336080551, Final Batch Loss: 0.2049521952867508\n",
      "Epoch 880, Loss: 0.6746772229671478, Final Batch Loss: 0.1615857183933258\n",
      "Epoch 881, Loss: 0.8289278745651245, Final Batch Loss: 0.3193823993206024\n",
      "Epoch 882, Loss: 0.9378846883773804, Final Batch Loss: 0.30604562163352966\n",
      "Epoch 883, Loss: 0.8188474029302597, Final Batch Loss: 0.339398592710495\n",
      "Epoch 884, Loss: 0.8185449838638306, Final Batch Loss: 0.33566346764564514\n",
      "Epoch 885, Loss: 0.6733854115009308, Final Batch Loss: 0.18484164774417877\n",
      "Epoch 886, Loss: 0.7779509723186493, Final Batch Loss: 0.24688675999641418\n",
      "Epoch 887, Loss: 0.7076203972101212, Final Batch Loss: 0.17582254111766815\n",
      "Epoch 888, Loss: 0.6582528054714203, Final Batch Loss: 0.13253533840179443\n",
      "Epoch 889, Loss: 0.6858564913272858, Final Batch Loss: 0.23875240981578827\n",
      "Epoch 890, Loss: 0.6210616677999496, Final Batch Loss: 0.16310717165470123\n",
      "Epoch 891, Loss: 0.7142797261476517, Final Batch Loss: 0.15607188642024994\n",
      "Epoch 892, Loss: 0.687582865357399, Final Batch Loss: 0.1813448667526245\n",
      "Epoch 893, Loss: 0.783122107386589, Final Batch Loss: 0.27679046988487244\n",
      "Epoch 894, Loss: 0.7187427431344986, Final Batch Loss: 0.2832183241844177\n",
      "Epoch 895, Loss: 0.7536928951740265, Final Batch Loss: 0.2469923347234726\n",
      "Epoch 896, Loss: 0.7454710751771927, Final Batch Loss: 0.2530626952648163\n",
      "Epoch 897, Loss: 0.7535695880651474, Final Batch Loss: 0.21116887032985687\n",
      "Epoch 898, Loss: 0.6440141946077347, Final Batch Loss: 0.12103898823261261\n",
      "Epoch 899, Loss: 0.5433553643524647, Final Batch Loss: 0.0587499774992466\n",
      "Epoch 900, Loss: 0.8254559487104416, Final Batch Loss: 0.31916776299476624\n",
      "Epoch 901, Loss: 0.774562880396843, Final Batch Loss: 0.3153739869594574\n",
      "Epoch 902, Loss: 0.5857571065425873, Final Batch Loss: 0.1351781189441681\n",
      "Epoch 903, Loss: 1.049332544207573, Final Batch Loss: 0.5507378578186035\n",
      "Epoch 904, Loss: 0.5769345387816429, Final Batch Loss: 0.1036997064948082\n",
      "Epoch 905, Loss: 0.8619275838136673, Final Batch Loss: 0.40872302651405334\n",
      "Epoch 906, Loss: 0.6337685808539391, Final Batch Loss: 0.1074591651558876\n",
      "Epoch 907, Loss: 0.7882413566112518, Final Batch Loss: 0.2671022415161133\n",
      "Epoch 908, Loss: 0.6401619911193848, Final Batch Loss: 0.1733148843050003\n",
      "Epoch 909, Loss: 0.6205478757619858, Final Batch Loss: 0.13710865378379822\n",
      "Epoch 910, Loss: 0.6237622946500778, Final Batch Loss: 0.13946489989757538\n",
      "Epoch 911, Loss: 0.8986895829439163, Final Batch Loss: 0.43373429775238037\n",
      "Epoch 912, Loss: 0.6301755309104919, Final Batch Loss: 0.20730532705783844\n",
      "Epoch 913, Loss: 0.7964504063129425, Final Batch Loss: 0.3249528408050537\n",
      "Epoch 914, Loss: 0.8288154155015945, Final Batch Loss: 0.3899385929107666\n",
      "Epoch 915, Loss: 0.9138135313987732, Final Batch Loss: 0.39543816447257996\n",
      "Epoch 916, Loss: 0.7354149520397186, Final Batch Loss: 0.2262263000011444\n",
      "Epoch 917, Loss: 0.8509641140699387, Final Batch Loss: 0.3591265380382538\n",
      "Epoch 918, Loss: 0.6472028493881226, Final Batch Loss: 0.14373880624771118\n",
      "Epoch 919, Loss: 0.8222563117742538, Final Batch Loss: 0.35397177934646606\n",
      "Epoch 920, Loss: 0.9846986383199692, Final Batch Loss: 0.4843052327632904\n",
      "Epoch 921, Loss: 0.6154817044734955, Final Batch Loss: 0.14504078030586243\n",
      "Epoch 922, Loss: 0.7231057435274124, Final Batch Loss: 0.22708815336227417\n",
      "Epoch 923, Loss: 0.8878970891237259, Final Batch Loss: 0.38151296973228455\n",
      "Epoch 924, Loss: 0.8292911946773529, Final Batch Loss: 0.29895177483558655\n",
      "Epoch 925, Loss: 0.9324662983417511, Final Batch Loss: 0.4047107994556427\n",
      "Epoch 926, Loss: 0.7012975811958313, Final Batch Loss: 0.1628158986568451\n",
      "Epoch 927, Loss: 0.7108162045478821, Final Batch Loss: 0.1722182333469391\n",
      "Epoch 928, Loss: 0.6994061917066574, Final Batch Loss: 0.1840105503797531\n",
      "Epoch 929, Loss: 0.8438442051410675, Final Batch Loss: 0.36020219326019287\n",
      "Epoch 930, Loss: 0.8169659078121185, Final Batch Loss: 0.3693661391735077\n",
      "Epoch 931, Loss: 0.8628788739442825, Final Batch Loss: 0.3681734800338745\n",
      "Epoch 932, Loss: 0.7597749382257462, Final Batch Loss: 0.3141307234764099\n",
      "Epoch 933, Loss: 0.6632073372602463, Final Batch Loss: 0.16946928203105927\n",
      "Epoch 934, Loss: 0.6742138415575027, Final Batch Loss: 0.11275194585323334\n",
      "Epoch 935, Loss: 0.7589929848909378, Final Batch Loss: 0.2532340884208679\n",
      "Epoch 936, Loss: 0.7027036398649216, Final Batch Loss: 0.16791029274463654\n",
      "Epoch 937, Loss: 0.7823953777551651, Final Batch Loss: 0.3050602972507477\n",
      "Epoch 938, Loss: 0.7437111437320709, Final Batch Loss: 0.22249159216880798\n",
      "Epoch 939, Loss: 0.9600174576044083, Final Batch Loss: 0.451287180185318\n",
      "Epoch 940, Loss: 0.6768897026777267, Final Batch Loss: 0.23187904059886932\n",
      "Epoch 941, Loss: 0.7821748554706573, Final Batch Loss: 0.30408933758735657\n",
      "Epoch 942, Loss: 0.736816480755806, Final Batch Loss: 0.216330423951149\n",
      "Epoch 943, Loss: 0.6293096169829369, Final Batch Loss: 0.11863746494054794\n",
      "Epoch 944, Loss: 0.9492527842521667, Final Batch Loss: 0.3825158178806305\n",
      "Epoch 945, Loss: 0.7790404260158539, Final Batch Loss: 0.207837775349617\n",
      "Epoch 946, Loss: 0.5975714698433876, Final Batch Loss: 0.11556487530469894\n",
      "Epoch 947, Loss: 0.8454054147005081, Final Batch Loss: 0.35952118039131165\n",
      "Epoch 948, Loss: 0.628446415066719, Final Batch Loss: 0.12841108441352844\n",
      "Epoch 949, Loss: 0.73258475959301, Final Batch Loss: 0.1527930349111557\n",
      "Epoch 950, Loss: 0.7295475602149963, Final Batch Loss: 0.24452124536037445\n",
      "Epoch 951, Loss: 0.6791892796754837, Final Batch Loss: 0.15093733370304108\n",
      "Epoch 952, Loss: 0.7644079178571701, Final Batch Loss: 0.26690754294395447\n",
      "Epoch 953, Loss: 0.8797015100717545, Final Batch Loss: 0.41928789019584656\n",
      "Epoch 954, Loss: 0.5514143407344818, Final Batch Loss: 0.10189013183116913\n",
      "Epoch 955, Loss: 1.3300613313913345, Final Batch Loss: 0.8297649025917053\n",
      "Epoch 956, Loss: 0.715169683098793, Final Batch Loss: 0.25380998849868774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957, Loss: 0.6753793805837631, Final Batch Loss: 0.24451911449432373\n",
      "Epoch 958, Loss: 1.005853533744812, Final Batch Loss: 0.5481370091438293\n",
      "Epoch 959, Loss: 1.1042147129774094, Final Batch Loss: 0.5473409295082092\n",
      "Epoch 960, Loss: 0.7515376955270767, Final Batch Loss: 0.2149873971939087\n",
      "Epoch 961, Loss: 0.8480412662029266, Final Batch Loss: 0.29765430092811584\n",
      "Epoch 962, Loss: 0.7566862553358078, Final Batch Loss: 0.27778875827789307\n",
      "Epoch 963, Loss: 0.7926835119724274, Final Batch Loss: 0.23402151465415955\n",
      "Epoch 964, Loss: 0.6417302489280701, Final Batch Loss: 0.10971984267234802\n",
      "Epoch 965, Loss: 0.8825831413269043, Final Batch Loss: 0.26330357789993286\n",
      "Epoch 966, Loss: 0.74954953789711, Final Batch Loss: 0.2256142497062683\n",
      "Epoch 967, Loss: 0.7864248901605606, Final Batch Loss: 0.2984335124492645\n",
      "Epoch 968, Loss: 0.9254603683948517, Final Batch Loss: 0.37234097719192505\n",
      "Epoch 969, Loss: 0.7588904798030853, Final Batch Loss: 0.25199297070503235\n",
      "Epoch 970, Loss: 0.664740689098835, Final Batch Loss: 0.10626143962144852\n",
      "Epoch 971, Loss: 0.9158707559108734, Final Batch Loss: 0.37592601776123047\n",
      "Epoch 972, Loss: 0.6751763001084328, Final Batch Loss: 0.06744525581598282\n",
      "Epoch 973, Loss: 0.9311355799436569, Final Batch Loss: 0.4366908371448517\n",
      "Epoch 974, Loss: 0.527508333325386, Final Batch Loss: 0.09023691713809967\n",
      "Epoch 975, Loss: 0.7736862599849701, Final Batch Loss: 0.32511910796165466\n",
      "Epoch 976, Loss: 0.7024296373128891, Final Batch Loss: 0.2013762891292572\n",
      "Epoch 977, Loss: 0.5193773126229644, Final Batch Loss: 0.011251694522798061\n",
      "Epoch 978, Loss: 0.7921135127544403, Final Batch Loss: 0.34324589371681213\n",
      "Epoch 979, Loss: 0.9943669438362122, Final Batch Loss: 0.4600496292114258\n",
      "Epoch 980, Loss: 0.7716029733419418, Final Batch Loss: 0.27683091163635254\n",
      "Epoch 981, Loss: 0.703777864575386, Final Batch Loss: 0.21541929244995117\n",
      "Epoch 982, Loss: 0.8300046920776367, Final Batch Loss: 0.36083272099494934\n",
      "Epoch 983, Loss: 0.7672310769557953, Final Batch Loss: 0.287523090839386\n",
      "Epoch 984, Loss: 0.6361328065395355, Final Batch Loss: 0.1732821762561798\n",
      "Epoch 985, Loss: 0.6822355538606644, Final Batch Loss: 0.24154821038246155\n",
      "Epoch 986, Loss: 0.5401745513081551, Final Batch Loss: 0.07390398532152176\n",
      "Epoch 987, Loss: 0.6683478653430939, Final Batch Loss: 0.14783704280853271\n",
      "Epoch 988, Loss: 0.7709985822439194, Final Batch Loss: 0.30614224076271057\n",
      "Epoch 989, Loss: 0.6959187835454941, Final Batch Loss: 0.24773113429546356\n",
      "Epoch 990, Loss: 0.8086872845888138, Final Batch Loss: 0.32968926429748535\n",
      "Epoch 991, Loss: 0.9340066015720367, Final Batch Loss: 0.4551776945590973\n",
      "Epoch 992, Loss: 0.7087949216365814, Final Batch Loss: 0.2473047971725464\n",
      "Epoch 993, Loss: 0.5282316356897354, Final Batch Loss: 0.03846566379070282\n",
      "Epoch 994, Loss: 0.6518895775079727, Final Batch Loss: 0.23370765149593353\n",
      "Epoch 995, Loss: 0.4366192873567343, Final Batch Loss: 0.02748004160821438\n",
      "Epoch 996, Loss: 0.6516179740428925, Final Batch Loss: 0.18046140670776367\n",
      "Epoch 997, Loss: 0.6909635365009308, Final Batch Loss: 0.2656932771205902\n",
      "Epoch 998, Loss: 0.6493346244096756, Final Batch Loss: 0.21887774765491486\n",
      "Epoch 999, Loss: 0.6815428882837296, Final Batch Loss: 0.23868244886398315\n",
      "Epoch 1000, Loss: 0.6946393698453903, Final Batch Loss: 0.15523113310337067\n",
      "Epoch 1001, Loss: 0.5382071658968925, Final Batch Loss: 0.09249579161405563\n",
      "Epoch 1002, Loss: 0.7580913305282593, Final Batch Loss: 0.30902430415153503\n",
      "Epoch 1003, Loss: 0.7224528342485428, Final Batch Loss: 0.22080747783184052\n",
      "Epoch 1004, Loss: 0.6939832419157028, Final Batch Loss: 0.2758469581604004\n",
      "Epoch 1005, Loss: 0.569673202931881, Final Batch Loss: 0.11585531383752823\n",
      "Epoch 1006, Loss: 0.981902465224266, Final Batch Loss: 0.531562328338623\n",
      "Epoch 1007, Loss: 0.8278708904981613, Final Batch Loss: 0.3431856036186218\n",
      "Epoch 1008, Loss: 0.6476928889751434, Final Batch Loss: 0.17412789165973663\n",
      "Epoch 1009, Loss: 0.7115585505962372, Final Batch Loss: 0.24078750610351562\n",
      "Epoch 1010, Loss: 0.6232446283102036, Final Batch Loss: 0.14138846099376678\n",
      "Epoch 1011, Loss: 0.6480257362127304, Final Batch Loss: 0.22225503623485565\n",
      "Epoch 1012, Loss: 0.6698766648769379, Final Batch Loss: 0.2043275386095047\n",
      "Epoch 1013, Loss: 0.726841002702713, Final Batch Loss: 0.28645002841949463\n",
      "Epoch 1014, Loss: 0.7398905009031296, Final Batch Loss: 0.1866709440946579\n",
      "Epoch 1015, Loss: 0.5543489530682564, Final Batch Loss: 0.06392946094274521\n",
      "Epoch 1016, Loss: 0.5595559775829315, Final Batch Loss: 0.14346449077129364\n",
      "Epoch 1017, Loss: 0.8500401079654694, Final Batch Loss: 0.4303964376449585\n",
      "Epoch 1018, Loss: 0.6213940382003784, Final Batch Loss: 0.16468527913093567\n",
      "Epoch 1019, Loss: 0.9282585829496384, Final Batch Loss: 0.3627481758594513\n",
      "Epoch 1020, Loss: 0.7320946604013443, Final Batch Loss: 0.22532601654529572\n",
      "Epoch 1021, Loss: 0.675722673535347, Final Batch Loss: 0.24264709651470184\n",
      "Epoch 1022, Loss: 0.925821378827095, Final Batch Loss: 0.44273653626441956\n",
      "Epoch 1023, Loss: 0.726880669593811, Final Batch Loss: 0.2827551066875458\n",
      "Epoch 1024, Loss: 0.8045433163642883, Final Batch Loss: 0.36744198203086853\n",
      "Epoch 1025, Loss: 0.6148875504732132, Final Batch Loss: 0.12026381492614746\n",
      "Epoch 1026, Loss: 0.6316545009613037, Final Batch Loss: 0.13836760818958282\n",
      "Epoch 1027, Loss: 0.6492199599742889, Final Batch Loss: 0.1629124879837036\n",
      "Epoch 1028, Loss: 0.6636657118797302, Final Batch Loss: 0.19076672196388245\n",
      "Epoch 1029, Loss: 0.8726276606321335, Final Batch Loss: 0.31378674507141113\n",
      "Epoch 1030, Loss: 0.8711129575967789, Final Batch Loss: 0.23921449482440948\n",
      "Epoch 1031, Loss: 0.6833818256855011, Final Batch Loss: 0.16025292873382568\n",
      "Epoch 1032, Loss: 0.8694526553153992, Final Batch Loss: 0.33010193705558777\n",
      "Epoch 1033, Loss: 0.9408861696720123, Final Batch Loss: 0.37847715616226196\n",
      "Epoch 1034, Loss: 0.6302450001239777, Final Batch Loss: 0.17113757133483887\n",
      "Epoch 1035, Loss: 0.6545576453208923, Final Batch Loss: 0.17881442606449127\n",
      "Epoch 1036, Loss: 0.9737407565116882, Final Batch Loss: 0.49377626180648804\n",
      "Epoch 1037, Loss: 0.6996260434389114, Final Batch Loss: 0.195199653506279\n",
      "Epoch 1038, Loss: 0.8312515616416931, Final Batch Loss: 0.32961684465408325\n",
      "Epoch 1039, Loss: 0.6469484716653824, Final Batch Loss: 0.19740425050258636\n",
      "Epoch 1040, Loss: 0.6072606295347214, Final Batch Loss: 0.09175769984722137\n",
      "Epoch 1041, Loss: 0.9267011284828186, Final Batch Loss: 0.39130929112434387\n",
      "Epoch 1042, Loss: 0.6093705743551254, Final Batch Loss: 0.14072416722774506\n",
      "Epoch 1043, Loss: 0.7293081283569336, Final Batch Loss: 0.22516493499279022\n",
      "Epoch 1044, Loss: 0.6773232072591782, Final Batch Loss: 0.16162054240703583\n",
      "Epoch 1045, Loss: 0.6670244634151459, Final Batch Loss: 0.19221262633800507\n",
      "Epoch 1046, Loss: 0.9581254869699478, Final Batch Loss: 0.4695965647697449\n",
      "Epoch 1047, Loss: 0.6732083261013031, Final Batch Loss: 0.14306378364562988\n",
      "Epoch 1048, Loss: 0.49317080713808537, Final Batch Loss: 0.028334731236100197\n",
      "Epoch 1049, Loss: 0.6479047685861588, Final Batch Loss: 0.16806863248348236\n",
      "Epoch 1050, Loss: 0.6479966044425964, Final Batch Loss: 0.20179450511932373\n",
      "Epoch 1051, Loss: 0.7546983659267426, Final Batch Loss: 0.2869301736354828\n",
      "Epoch 1052, Loss: 0.8709122538566589, Final Batch Loss: 0.410214900970459\n",
      "Epoch 1053, Loss: 0.705628514289856, Final Batch Loss: 0.22558149695396423\n",
      "Epoch 1054, Loss: 0.7487408369779587, Final Batch Loss: 0.31354954838752747\n",
      "Epoch 1055, Loss: 0.6492602899670601, Final Batch Loss: 0.11009887605905533\n",
      "Epoch 1056, Loss: 0.46737380884587765, Final Batch Loss: 0.018739258870482445\n",
      "Epoch 1057, Loss: 0.7570857852697372, Final Batch Loss: 0.2799709439277649\n",
      "Epoch 1058, Loss: 0.6488174796104431, Final Batch Loss: 0.20303618907928467\n",
      "Epoch 1059, Loss: 0.5875418782234192, Final Batch Loss: 0.12331438064575195\n",
      "Epoch 1060, Loss: 0.7481110990047455, Final Batch Loss: 0.2348143458366394\n",
      "Epoch 1061, Loss: 0.5613294541835785, Final Batch Loss: 0.10316075384616852\n",
      "Epoch 1062, Loss: 0.5545835867524147, Final Batch Loss: 0.11904356628656387\n",
      "Epoch 1063, Loss: 0.534324873238802, Final Batch Loss: 0.04722963646054268\n",
      "Epoch 1064, Loss: 0.6575332880020142, Final Batch Loss: 0.0955805778503418\n",
      "Epoch 1065, Loss: 0.7086713165044785, Final Batch Loss: 0.2216167449951172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1066, Loss: 0.7650560587644577, Final Batch Loss: 0.30367881059646606\n",
      "Epoch 1067, Loss: 0.5913354903459549, Final Batch Loss: 0.1422785520553589\n",
      "Epoch 1068, Loss: 0.6999241709709167, Final Batch Loss: 0.2693658173084259\n",
      "Epoch 1069, Loss: 0.605014979839325, Final Batch Loss: 0.18070834875106812\n",
      "Epoch 1070, Loss: 0.5824941992759705, Final Batch Loss: 0.1697201281785965\n",
      "Epoch 1071, Loss: 0.9105672985315323, Final Batch Loss: 0.41982245445251465\n",
      "Epoch 1072, Loss: 0.7621124982833862, Final Batch Loss: 0.31349459290504456\n",
      "Epoch 1073, Loss: 0.5457632318139076, Final Batch Loss: 0.06333709508180618\n",
      "Epoch 1074, Loss: 0.6683316379785538, Final Batch Loss: 0.2116517275571823\n",
      "Epoch 1075, Loss: 0.6666107922792435, Final Batch Loss: 0.1768806278705597\n",
      "Epoch 1076, Loss: 0.5817080438137054, Final Batch Loss: 0.13123293220996857\n",
      "Epoch 1077, Loss: 0.7315741926431656, Final Batch Loss: 0.2658192217350006\n",
      "Epoch 1078, Loss: 0.6196579709649086, Final Batch Loss: 0.11602667719125748\n",
      "Epoch 1079, Loss: 0.8117422610521317, Final Batch Loss: 0.3357761800289154\n",
      "Epoch 1080, Loss: 0.7276897877454758, Final Batch Loss: 0.2590509355068207\n",
      "Epoch 1081, Loss: 0.700240358710289, Final Batch Loss: 0.236458882689476\n",
      "Epoch 1082, Loss: 0.5773555412888527, Final Batch Loss: 0.07677149027585983\n",
      "Epoch 1083, Loss: 0.6985601335763931, Final Batch Loss: 0.2571300268173218\n",
      "Epoch 1084, Loss: 0.5888648703694344, Final Batch Loss: 0.1101401075720787\n",
      "Epoch 1085, Loss: 0.6536489725112915, Final Batch Loss: 0.19113261997699738\n",
      "Epoch 1086, Loss: 0.5642565190792084, Final Batch Loss: 0.10025477409362793\n",
      "Epoch 1087, Loss: 0.800175666809082, Final Batch Loss: 0.32292640209198\n",
      "Epoch 1088, Loss: 0.9063639789819717, Final Batch Loss: 0.4562391936779022\n",
      "Epoch 1089, Loss: 0.8029007464647293, Final Batch Loss: 0.3426806330680847\n",
      "Epoch 1090, Loss: 0.7205344289541245, Final Batch Loss: 0.21277694404125214\n",
      "Epoch 1091, Loss: 0.6972742825746536, Final Batch Loss: 0.2630212903022766\n",
      "Epoch 1092, Loss: 0.5679378136992455, Final Batch Loss: 0.09564926475286484\n",
      "Epoch 1093, Loss: 0.537315808236599, Final Batch Loss: 0.10810504108667374\n",
      "Epoch 1094, Loss: 0.9507876187562943, Final Batch Loss: 0.484762042760849\n",
      "Epoch 1095, Loss: 0.514845460653305, Final Batch Loss: 0.044912189245224\n",
      "Epoch 1096, Loss: 0.6485464721918106, Final Batch Loss: 0.17527031898498535\n",
      "Epoch 1097, Loss: 0.5201461315155029, Final Batch Loss: 0.09824787080287933\n",
      "Epoch 1098, Loss: 0.6645099222660065, Final Batch Loss: 0.2536163330078125\n",
      "Epoch 1099, Loss: 0.8150348961353302, Final Batch Loss: 0.3661758601665497\n",
      "Epoch 1100, Loss: 0.5844096690416336, Final Batch Loss: 0.15568093955516815\n",
      "Epoch 1101, Loss: 0.6607660353183746, Final Batch Loss: 0.2194039225578308\n",
      "Epoch 1102, Loss: 0.49208422005176544, Final Batch Loss: 0.03578285872936249\n",
      "Epoch 1103, Loss: 0.5398548245429993, Final Batch Loss: 0.1270434409379959\n",
      "Epoch 1104, Loss: 0.672132670879364, Final Batch Loss: 0.23661723732948303\n",
      "Epoch 1105, Loss: 0.8497831523418427, Final Batch Loss: 0.3813224732875824\n",
      "Epoch 1106, Loss: 0.5933247357606888, Final Batch Loss: 0.15386895835399628\n",
      "Epoch 1107, Loss: 0.850903332233429, Final Batch Loss: 0.44244661927223206\n",
      "Epoch 1108, Loss: 0.5284788534045219, Final Batch Loss: 0.08129670470952988\n",
      "Epoch 1109, Loss: 0.7353299409151077, Final Batch Loss: 0.30416426062583923\n",
      "Epoch 1110, Loss: 0.9825910925865173, Final Batch Loss: 0.5296493172645569\n",
      "Epoch 1111, Loss: 0.6743409931659698, Final Batch Loss: 0.17376451194286346\n",
      "Epoch 1112, Loss: 0.6207959055900574, Final Batch Loss: 0.19556111097335815\n",
      "Epoch 1113, Loss: 0.5497122444212437, Final Batch Loss: 0.05927878990769386\n",
      "Epoch 1114, Loss: 0.5879967659711838, Final Batch Loss: 0.13401202857494354\n",
      "Epoch 1115, Loss: 0.7072717845439911, Final Batch Loss: 0.25845837593078613\n",
      "Epoch 1116, Loss: 0.561303049325943, Final Batch Loss: 0.13315902650356293\n",
      "Epoch 1117, Loss: 0.44948383420705795, Final Batch Loss: 0.0432080402970314\n",
      "Epoch 1118, Loss: 0.4807806722819805, Final Batch Loss: 0.029732923954725266\n",
      "Epoch 1119, Loss: 0.809676855802536, Final Batch Loss: 0.33901044726371765\n",
      "Epoch 1120, Loss: 0.6920429021120071, Final Batch Loss: 0.240871861577034\n",
      "Epoch 1121, Loss: 0.6658869683742523, Final Batch Loss: 0.1768009215593338\n",
      "Epoch 1122, Loss: 0.7303961366415024, Final Batch Loss: 0.25885334610939026\n",
      "Epoch 1123, Loss: 0.7321557849645615, Final Batch Loss: 0.27202922105789185\n",
      "Epoch 1124, Loss: 0.6878974884748459, Final Batch Loss: 0.2124086618423462\n",
      "Epoch 1125, Loss: 0.5537667907774448, Final Batch Loss: 0.04242125526070595\n",
      "Epoch 1126, Loss: 0.5918876081705093, Final Batch Loss: 0.12195611000061035\n",
      "Epoch 1127, Loss: 0.576428584754467, Final Batch Loss: 0.0909327045083046\n",
      "Epoch 1128, Loss: 0.7250536531209946, Final Batch Loss: 0.2288968414068222\n",
      "Epoch 1129, Loss: 0.7361893653869629, Final Batch Loss: 0.240573912858963\n",
      "Epoch 1130, Loss: 0.6419069916009903, Final Batch Loss: 0.14432986080646515\n",
      "Epoch 1131, Loss: 0.6776581555604935, Final Batch Loss: 0.15080766379833221\n",
      "Epoch 1132, Loss: 0.8036765158176422, Final Batch Loss: 0.3553849160671234\n",
      "Epoch 1133, Loss: 0.6897657364606857, Final Batch Loss: 0.1797368824481964\n",
      "Epoch 1134, Loss: 0.6051267459988594, Final Batch Loss: 0.06951888650655746\n",
      "Epoch 1135, Loss: 0.6336941123008728, Final Batch Loss: 0.18213395774364471\n",
      "Epoch 1136, Loss: 0.804663211107254, Final Batch Loss: 0.3103281855583191\n",
      "Epoch 1137, Loss: 0.7790113836526871, Final Batch Loss: 0.31692448258399963\n",
      "Epoch 1138, Loss: 0.7819280922412872, Final Batch Loss: 0.24765169620513916\n",
      "Epoch 1139, Loss: 0.6964540332555771, Final Batch Loss: 0.1932072788476944\n",
      "Epoch 1140, Loss: 0.7986352145671844, Final Batch Loss: 0.32585465908050537\n",
      "Epoch 1141, Loss: 0.6272299885749817, Final Batch Loss: 0.20545831322669983\n",
      "Epoch 1142, Loss: 0.5816072449088097, Final Batch Loss: 0.11903522163629532\n",
      "Epoch 1143, Loss: 0.6914251893758774, Final Batch Loss: 0.1620766669511795\n",
      "Epoch 1144, Loss: 0.5590456128120422, Final Batch Loss: 0.1400536298751831\n",
      "Epoch 1145, Loss: 0.6522992700338364, Final Batch Loss: 0.2215075045824051\n",
      "Epoch 1146, Loss: 0.7191927134990692, Final Batch Loss: 0.28071698546409607\n",
      "Epoch 1147, Loss: 0.5923354625701904, Final Batch Loss: 0.0995631217956543\n",
      "Epoch 1148, Loss: 0.7402558326721191, Final Batch Loss: 0.2467159926891327\n",
      "Epoch 1149, Loss: 0.570611298084259, Final Batch Loss: 0.15390557050704956\n",
      "Epoch 1150, Loss: 0.7503013163805008, Final Batch Loss: 0.2617911398410797\n",
      "Epoch 1151, Loss: 0.6797911375761032, Final Batch Loss: 0.1751352846622467\n",
      "Epoch 1152, Loss: 0.8054003417491913, Final Batch Loss: 0.2780482769012451\n",
      "Epoch 1153, Loss: 0.7625599652528763, Final Batch Loss: 0.2934274971485138\n",
      "Epoch 1154, Loss: 0.7805741727352142, Final Batch Loss: 0.37708303332328796\n",
      "Epoch 1155, Loss: 0.5933911800384521, Final Batch Loss: 0.15212465822696686\n",
      "Epoch 1156, Loss: 0.47752145677804947, Final Batch Loss: 0.07079628854990005\n",
      "Epoch 1157, Loss: 0.5326066724956036, Final Batch Loss: 0.05301738902926445\n",
      "Epoch 1158, Loss: 0.597813069820404, Final Batch Loss: 0.1856609582901001\n",
      "Epoch 1159, Loss: 0.6461704522371292, Final Batch Loss: 0.25658395886421204\n",
      "Epoch 1160, Loss: 0.7419348657131195, Final Batch Loss: 0.2974588871002197\n",
      "Epoch 1161, Loss: 0.633065715432167, Final Batch Loss: 0.1864650547504425\n",
      "Epoch 1162, Loss: 0.7664300799369812, Final Batch Loss: 0.24368692934513092\n",
      "Epoch 1163, Loss: 0.7072393894195557, Final Batch Loss: 0.17584562301635742\n",
      "Epoch 1164, Loss: 0.5993930995464325, Final Batch Loss: 0.15757638216018677\n",
      "Epoch 1165, Loss: 0.4572766087949276, Final Batch Loss: 0.036605190485715866\n",
      "Epoch 1166, Loss: 0.6364374607801437, Final Batch Loss: 0.1551794409751892\n",
      "Epoch 1167, Loss: 0.7018973976373672, Final Batch Loss: 0.28178301453590393\n",
      "Epoch 1168, Loss: 0.8034893274307251, Final Batch Loss: 0.3418441712856293\n",
      "Epoch 1169, Loss: 0.906933531165123, Final Batch Loss: 0.4439939558506012\n",
      "Epoch 1170, Loss: 0.968778058886528, Final Batch Loss: 0.4665655195713043\n",
      "Epoch 1171, Loss: 0.7404541224241257, Final Batch Loss: 0.23541533946990967\n",
      "Epoch 1172, Loss: 0.5412901192903519, Final Batch Loss: 0.11594869196414948\n",
      "Epoch 1173, Loss: 0.5576981604099274, Final Batch Loss: 0.11735080182552338\n",
      "Epoch 1174, Loss: 0.6826698780059814, Final Batch Loss: 0.17674241960048676\n",
      "Epoch 1175, Loss: 0.9669304043054581, Final Batch Loss: 0.4482297897338867\n",
      "Epoch 1176, Loss: 0.7602694779634476, Final Batch Loss: 0.26914161443710327\n",
      "Epoch 1177, Loss: 0.6362399458885193, Final Batch Loss: 0.17157183587551117\n",
      "Epoch 1178, Loss: 0.6618078052997589, Final Batch Loss: 0.20181217789649963\n",
      "Epoch 1179, Loss: 0.8923748731613159, Final Batch Loss: 0.41821548342704773\n",
      "Epoch 1180, Loss: 0.6174105554819107, Final Batch Loss: 0.15556831657886505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1181, Loss: 0.7545508742332458, Final Batch Loss: 0.29698124527931213\n",
      "Epoch 1182, Loss: 0.5472844988107681, Final Batch Loss: 0.11226892471313477\n",
      "Epoch 1183, Loss: 0.7086085230112076, Final Batch Loss: 0.2522980272769928\n",
      "Epoch 1184, Loss: 0.6422143429517746, Final Batch Loss: 0.22811973094940186\n",
      "Epoch 1185, Loss: 0.5037690922617912, Final Batch Loss: 0.08695430308580399\n",
      "Epoch 1186, Loss: 0.7075055539608002, Final Batch Loss: 0.2635466754436493\n",
      "Epoch 1187, Loss: 0.6436076909303665, Final Batch Loss: 0.22658003866672516\n",
      "Epoch 1188, Loss: 0.6854207366704941, Final Batch Loss: 0.24151258170604706\n",
      "Epoch 1189, Loss: 0.5093950852751732, Final Batch Loss: 0.10831090062856674\n",
      "Epoch 1190, Loss: 0.6805614680051804, Final Batch Loss: 0.25378647446632385\n",
      "Epoch 1191, Loss: 1.0628091394901276, Final Batch Loss: 0.6058905720710754\n",
      "Epoch 1192, Loss: 0.8065608143806458, Final Batch Loss: 0.37983381748199463\n",
      "Epoch 1193, Loss: 0.653699666261673, Final Batch Loss: 0.18875791132450104\n",
      "Epoch 1194, Loss: 0.6442564725875854, Final Batch Loss: 0.17035283148288727\n",
      "Epoch 1195, Loss: 0.6060389876365662, Final Batch Loss: 0.18721355497837067\n",
      "Epoch 1196, Loss: 0.5793565288186073, Final Batch Loss: 0.10076964646577835\n",
      "Epoch 1197, Loss: 0.6577203869819641, Final Batch Loss: 0.23432646691799164\n",
      "Epoch 1198, Loss: 0.8403495401144028, Final Batch Loss: 0.3867601156234741\n",
      "Epoch 1199, Loss: 0.6081079691648483, Final Batch Loss: 0.19049976766109467\n",
      "Epoch 1200, Loss: 0.6367869079113007, Final Batch Loss: 0.17117242515087128\n",
      "Epoch 1201, Loss: 0.48113297671079636, Final Batch Loss: 0.08356209844350815\n",
      "Epoch 1202, Loss: 0.520570732653141, Final Batch Loss: 0.10322975367307663\n",
      "Epoch 1203, Loss: 0.5374537408351898, Final Batch Loss: 0.11458040773868561\n",
      "Epoch 1204, Loss: 0.6423239409923553, Final Batch Loss: 0.21424894034862518\n",
      "Epoch 1205, Loss: 0.6163731813430786, Final Batch Loss: 0.17709128558635712\n",
      "Epoch 1206, Loss: 0.7669742852449417, Final Batch Loss: 0.30211082100868225\n",
      "Epoch 1207, Loss: 0.5980904400348663, Final Batch Loss: 0.1415579915046692\n",
      "Epoch 1208, Loss: 0.8385350704193115, Final Batch Loss: 0.4109678566455841\n",
      "Epoch 1209, Loss: 0.5640003532171249, Final Batch Loss: 0.1536729782819748\n",
      "Epoch 1210, Loss: 0.7489404529333115, Final Batch Loss: 0.31459110975265503\n",
      "Epoch 1211, Loss: 0.5977154448628426, Final Batch Loss: 0.12446709722280502\n",
      "Epoch 1212, Loss: 0.5362564697861671, Final Batch Loss: 0.11779320985078812\n",
      "Epoch 1213, Loss: 0.8155952841043472, Final Batch Loss: 0.36282896995544434\n",
      "Epoch 1214, Loss: 0.5705734118819237, Final Batch Loss: 0.08067116886377335\n",
      "Epoch 1215, Loss: 0.5400029048323631, Final Batch Loss: 0.10800770670175552\n",
      "Epoch 1216, Loss: 0.6652432680130005, Final Batch Loss: 0.2373359054327011\n",
      "Epoch 1217, Loss: 0.5709437727928162, Final Batch Loss: 0.16306865215301514\n",
      "Epoch 1218, Loss: 0.63711017370224, Final Batch Loss: 0.21434234082698822\n",
      "Epoch 1219, Loss: 0.6622921526432037, Final Batch Loss: 0.17897076904773712\n",
      "Epoch 1220, Loss: 0.7411998361349106, Final Batch Loss: 0.3103221356868744\n",
      "Epoch 1221, Loss: 0.5102691873908043, Final Batch Loss: 0.06528488546609879\n",
      "Epoch 1222, Loss: 0.5534042418003082, Final Batch Loss: 0.13262879848480225\n",
      "Epoch 1223, Loss: 0.5085247308015823, Final Batch Loss: 0.12852126359939575\n",
      "Epoch 1224, Loss: 0.6104002594947815, Final Batch Loss: 0.14301161468029022\n",
      "Epoch 1225, Loss: 0.5737009793519974, Final Batch Loss: 0.14680048823356628\n",
      "Epoch 1226, Loss: 0.5168295353651047, Final Batch Loss: 0.17548531293869019\n",
      "Epoch 1227, Loss: 0.6130509227514267, Final Batch Loss: 0.19214731454849243\n",
      "Epoch 1228, Loss: 0.6856956779956818, Final Batch Loss: 0.2565214931964874\n",
      "Epoch 1229, Loss: 0.7072527408599854, Final Batch Loss: 0.2838839590549469\n",
      "Epoch 1230, Loss: 0.5320447459816933, Final Batch Loss: 0.09363795071840286\n",
      "Epoch 1231, Loss: 0.44308872893452644, Final Batch Loss: 0.04524556174874306\n",
      "Epoch 1232, Loss: 0.6447068005800247, Final Batch Loss: 0.24948878586292267\n",
      "Epoch 1233, Loss: 0.5889517962932587, Final Batch Loss: 0.18990422785282135\n",
      "Epoch 1234, Loss: 0.5606867223978043, Final Batch Loss: 0.16356532275676727\n",
      "Epoch 1235, Loss: 0.6654883772134781, Final Batch Loss: 0.1799967736005783\n",
      "Epoch 1236, Loss: 0.6116607040166855, Final Batch Loss: 0.12420806288719177\n",
      "Epoch 1237, Loss: 0.5691172331571579, Final Batch Loss: 0.14751878380775452\n",
      "Epoch 1238, Loss: 0.7335581034421921, Final Batch Loss: 0.26821431517601013\n",
      "Epoch 1239, Loss: 0.8142227977514267, Final Batch Loss: 0.3751188814640045\n",
      "Epoch 1240, Loss: 0.7448767870664597, Final Batch Loss: 0.28706514835357666\n",
      "Epoch 1241, Loss: 0.6636310666799545, Final Batch Loss: 0.2470683604478836\n",
      "Epoch 1242, Loss: 0.550755113363266, Final Batch Loss: 0.16077595949172974\n",
      "Epoch 1243, Loss: 0.5337407514452934, Final Batch Loss: 0.0722060576081276\n",
      "Epoch 1244, Loss: 0.6488800197839737, Final Batch Loss: 0.2425469309091568\n",
      "Epoch 1245, Loss: 0.9028649926185608, Final Batch Loss: 0.4663005769252777\n",
      "Epoch 1246, Loss: 0.5470934957265854, Final Batch Loss: 0.1526416391134262\n",
      "Epoch 1247, Loss: 0.5539848357439041, Final Batch Loss: 0.14632634818553925\n",
      "Epoch 1248, Loss: 0.7576069980859756, Final Batch Loss: 0.29448628425598145\n",
      "Epoch 1249, Loss: 0.5232088807970285, Final Batch Loss: 0.028416762128472328\n",
      "Epoch 1250, Loss: 0.5403556898236275, Final Batch Loss: 0.08960869163274765\n",
      "Epoch 1251, Loss: 0.6365477740764618, Final Batch Loss: 0.1859520673751831\n",
      "Epoch 1252, Loss: 0.5746888220310211, Final Batch Loss: 0.11933261156082153\n",
      "Epoch 1253, Loss: 0.7569779455661774, Final Batch Loss: 0.2961535155773163\n",
      "Epoch 1254, Loss: 0.407890971750021, Final Batch Loss: 0.037238847464323044\n",
      "Epoch 1255, Loss: 0.7298188507556915, Final Batch Loss: 0.3191143274307251\n",
      "Epoch 1256, Loss: 0.8523814082145691, Final Batch Loss: 0.4534274637699127\n",
      "Epoch 1257, Loss: 0.787168487906456, Final Batch Loss: 0.36767685413360596\n",
      "Epoch 1258, Loss: 0.665138453245163, Final Batch Loss: 0.22431813180446625\n",
      "Epoch 1259, Loss: 0.6019047796726227, Final Batch Loss: 0.18700246512889862\n",
      "Epoch 1260, Loss: 0.7298656105995178, Final Batch Loss: 0.2791631817817688\n",
      "Epoch 1261, Loss: 0.6392554938793182, Final Batch Loss: 0.2251906841993332\n",
      "Epoch 1262, Loss: 0.567773163318634, Final Batch Loss: 0.20688404142856598\n",
      "Epoch 1263, Loss: 0.49610625952482224, Final Batch Loss: 0.08299534767866135\n",
      "Epoch 1264, Loss: 0.6323462277650833, Final Batch Loss: 0.22190335392951965\n",
      "Epoch 1265, Loss: 0.5521536692976952, Final Batch Loss: 0.1096431240439415\n",
      "Epoch 1266, Loss: 0.6927247643470764, Final Batch Loss: 0.2889142632484436\n",
      "Epoch 1267, Loss: 0.5912186950445175, Final Batch Loss: 0.18436382710933685\n",
      "Epoch 1268, Loss: 0.5792317241430283, Final Batch Loss: 0.15619036555290222\n",
      "Epoch 1269, Loss: 0.49265819042921066, Final Batch Loss: 0.09059975296258926\n",
      "Epoch 1270, Loss: 0.5776383131742477, Final Batch Loss: 0.1804746389389038\n",
      "Epoch 1271, Loss: 0.605541042983532, Final Batch Loss: 0.11537442356348038\n",
      "Epoch 1272, Loss: 0.6531715095043182, Final Batch Loss: 0.21581363677978516\n",
      "Epoch 1273, Loss: 0.7837184369564056, Final Batch Loss: 0.38268357515335083\n",
      "Epoch 1274, Loss: 0.716086283326149, Final Batch Loss: 0.2722949683666229\n",
      "Epoch 1275, Loss: 0.6584364473819733, Final Batch Loss: 0.23106728494167328\n",
      "Epoch 1276, Loss: 0.7497910559177399, Final Batch Loss: 0.2726033329963684\n",
      "Epoch 1277, Loss: 0.5917508602142334, Final Batch Loss: 0.16960366070270538\n",
      "Epoch 1278, Loss: 0.5297552347183228, Final Batch Loss: 0.12574367225170135\n",
      "Epoch 1279, Loss: 0.598710335791111, Final Batch Loss: 0.11950241774320602\n",
      "Epoch 1280, Loss: 0.6873026192188263, Final Batch Loss: 0.19757792353630066\n",
      "Epoch 1281, Loss: 0.5915315598249435, Final Batch Loss: 0.20415043830871582\n",
      "Epoch 1282, Loss: 0.6290688514709473, Final Batch Loss: 0.20253176987171173\n",
      "Epoch 1283, Loss: 0.7995624393224716, Final Batch Loss: 0.2899748384952545\n",
      "Epoch 1284, Loss: 0.8506300896406174, Final Batch Loss: 0.3994717597961426\n",
      "Epoch 1285, Loss: 0.8256371468305588, Final Batch Loss: 0.43965956568717957\n",
      "Epoch 1286, Loss: 0.6088604927062988, Final Batch Loss: 0.13427698612213135\n",
      "Epoch 1287, Loss: 0.7307323217391968, Final Batch Loss: 0.3103603422641754\n",
      "Epoch 1288, Loss: 0.8166974931955338, Final Batch Loss: 0.23008321225643158\n",
      "Epoch 1289, Loss: 0.4812126159667969, Final Batch Loss: 0.07289046049118042\n",
      "Epoch 1290, Loss: 0.6423707008361816, Final Batch Loss: 0.21644310653209686\n",
      "Epoch 1291, Loss: 0.5892202407121658, Final Batch Loss: 0.13053163886070251\n",
      "Epoch 1292, Loss: 0.5454277023673058, Final Batch Loss: 0.10956320911645889\n",
      "Epoch 1293, Loss: 0.5649214088916779, Final Batch Loss: 0.12123093008995056\n",
      "Epoch 1294, Loss: 0.668776348233223, Final Batch Loss: 0.1987275928258896\n",
      "Epoch 1295, Loss: 0.6454841792583466, Final Batch Loss: 0.2583787143230438\n",
      "Epoch 1296, Loss: 0.5247324556112289, Final Batch Loss: 0.08935089409351349\n",
      "Epoch 1297, Loss: 0.6072738021612167, Final Batch Loss: 0.1609703153371811\n",
      "Epoch 1298, Loss: 0.6739851534366608, Final Batch Loss: 0.22101445496082306\n",
      "Epoch 1299, Loss: 0.6290311217308044, Final Batch Loss: 0.18220070004463196\n",
      "Epoch 1300, Loss: 0.5687217935919762, Final Batch Loss: 0.10561517626047134\n",
      "Epoch 1301, Loss: 0.5839614681899548, Final Batch Loss: 0.04214499518275261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1302, Loss: 0.527274988591671, Final Batch Loss: 0.10593972355127335\n",
      "Epoch 1303, Loss: 0.4738258197903633, Final Batch Loss: 0.07228711992502213\n",
      "Epoch 1304, Loss: 0.5240893512964249, Final Batch Loss: 0.14265358448028564\n",
      "Epoch 1305, Loss: 0.49583543092012405, Final Batch Loss: 0.07399747520685196\n",
      "Epoch 1306, Loss: 0.6133247911930084, Final Batch Loss: 0.20332102477550507\n",
      "Epoch 1307, Loss: 0.49476560205221176, Final Batch Loss: 0.08725927025079727\n",
      "Epoch 1308, Loss: 0.612828940153122, Final Batch Loss: 0.23810891807079315\n",
      "Epoch 1309, Loss: 0.5439686626195908, Final Batch Loss: 0.07402479648590088\n",
      "Epoch 1310, Loss: 0.673686608672142, Final Batch Loss: 0.26385512948036194\n",
      "Epoch 1311, Loss: 0.6367832273244858, Final Batch Loss: 0.22952722012996674\n",
      "Epoch 1312, Loss: 0.5095901004970074, Final Batch Loss: 0.03770514950156212\n",
      "Epoch 1313, Loss: 0.46392959356307983, Final Batch Loss: 0.06456419825553894\n",
      "Epoch 1314, Loss: 0.788421556353569, Final Batch Loss: 0.3459039628505707\n",
      "Epoch 1315, Loss: 0.6171921342611313, Final Batch Loss: 0.17391376197338104\n",
      "Epoch 1316, Loss: 0.6305229216814041, Final Batch Loss: 0.16181416809558868\n",
      "Epoch 1317, Loss: 0.5149836838245392, Final Batch Loss: 0.088933065533638\n",
      "Epoch 1318, Loss: 0.7237457931041718, Final Batch Loss: 0.2646137773990631\n",
      "Epoch 1319, Loss: 0.5556471943855286, Final Batch Loss: 0.09111621975898743\n",
      "Epoch 1320, Loss: 0.544582724571228, Final Batch Loss: 0.08930447697639465\n",
      "Epoch 1321, Loss: 0.777796670794487, Final Batch Loss: 0.3750195801258087\n",
      "Epoch 1322, Loss: 0.5762663632631302, Final Batch Loss: 0.16248802840709686\n",
      "Epoch 1323, Loss: 0.7123444080352783, Final Batch Loss: 0.22470524907112122\n",
      "Epoch 1324, Loss: 0.6372753158211708, Final Batch Loss: 0.08637554198503494\n",
      "Epoch 1325, Loss: 0.6742519736289978, Final Batch Loss: 0.1576273888349533\n",
      "Epoch 1326, Loss: 0.5948592498898506, Final Batch Loss: 0.10656020790338516\n",
      "Epoch 1327, Loss: 0.7058119475841522, Final Batch Loss: 0.2551557719707489\n",
      "Epoch 1328, Loss: 0.49946056492626667, Final Batch Loss: 0.005300017073750496\n",
      "Epoch 1329, Loss: 0.5774864852428436, Final Batch Loss: 0.15225711464881897\n",
      "Epoch 1330, Loss: 1.0252701342105865, Final Batch Loss: 0.5988141298294067\n",
      "Epoch 1331, Loss: 0.5484209209680557, Final Batch Loss: 0.13085590302944183\n",
      "Epoch 1332, Loss: 0.5193943157792091, Final Batch Loss: 0.09418118745088577\n",
      "Epoch 1333, Loss: 0.6175632029771805, Final Batch Loss: 0.16007937490940094\n",
      "Epoch 1334, Loss: 0.4794495590031147, Final Batch Loss: 0.03206278756260872\n",
      "Epoch 1335, Loss: 0.537605807185173, Final Batch Loss: 0.07795657217502594\n",
      "Epoch 1336, Loss: 0.9486875683069229, Final Batch Loss: 0.5142301321029663\n",
      "Epoch 1337, Loss: 0.504149541258812, Final Batch Loss: 0.09306459128856659\n",
      "Epoch 1338, Loss: 0.5498628169298172, Final Batch Loss: 0.11458945274353027\n",
      "Epoch 1339, Loss: 0.7605956494808197, Final Batch Loss: 0.3641909658908844\n",
      "Epoch 1340, Loss: 0.6557243019342422, Final Batch Loss: 0.22175432741641998\n",
      "Epoch 1341, Loss: 0.42533918656408787, Final Batch Loss: 0.024995917454361916\n",
      "Epoch 1342, Loss: 0.6327566057443619, Final Batch Loss: 0.22062136232852936\n",
      "Epoch 1343, Loss: 0.7469285875558853, Final Batch Loss: 0.2997692823410034\n",
      "Epoch 1344, Loss: 0.46567805856466293, Final Batch Loss: 0.06912129372358322\n",
      "Epoch 1345, Loss: 0.4321130458265543, Final Batch Loss: 0.026235351338982582\n",
      "Epoch 1346, Loss: 0.6428897678852081, Final Batch Loss: 0.21814778447151184\n",
      "Epoch 1347, Loss: 0.5068518221378326, Final Batch Loss: 0.12404552102088928\n",
      "Epoch 1348, Loss: 0.7722755521535873, Final Batch Loss: 0.3742029368877411\n",
      "Epoch 1349, Loss: 0.5609364360570908, Final Batch Loss: 0.09229683876037598\n",
      "Epoch 1350, Loss: 0.8048154562711716, Final Batch Loss: 0.3830603063106537\n",
      "Epoch 1351, Loss: 0.634824275970459, Final Batch Loss: 0.19883650541305542\n",
      "Epoch 1352, Loss: 0.6110903918743134, Final Batch Loss: 0.1852983981370926\n",
      "Epoch 1353, Loss: 0.5553454980254173, Final Batch Loss: 0.10633846372365952\n",
      "Epoch 1354, Loss: 0.4782009944319725, Final Batch Loss: 0.026211701333522797\n",
      "Epoch 1355, Loss: 0.8890692740678787, Final Batch Loss: 0.47889116406440735\n",
      "Epoch 1356, Loss: 0.6179938018321991, Final Batch Loss: 0.21129941940307617\n",
      "Epoch 1357, Loss: 0.5175052508711815, Final Batch Loss: 0.10481200367212296\n",
      "Epoch 1358, Loss: 0.668257862329483, Final Batch Loss: 0.17624767124652863\n",
      "Epoch 1359, Loss: 0.615383118391037, Final Batch Loss: 0.08991223573684692\n",
      "Epoch 1360, Loss: 0.8727279007434845, Final Batch Loss: 0.4128768742084503\n",
      "Epoch 1361, Loss: 0.7630314528942108, Final Batch Loss: 0.18089339137077332\n",
      "Epoch 1362, Loss: 0.6776018738746643, Final Batch Loss: 0.2251397669315338\n",
      "Epoch 1363, Loss: 0.8121432363986969, Final Batch Loss: 0.36348381638526917\n",
      "Epoch 1364, Loss: 0.702896922826767, Final Batch Loss: 0.3070102632045746\n",
      "Epoch 1365, Loss: 0.8886424750089645, Final Batch Loss: 0.4419872462749481\n",
      "Epoch 1366, Loss: 0.7132819294929504, Final Batch Loss: 0.3166707456111908\n",
      "Epoch 1367, Loss: 0.6180092990398407, Final Batch Loss: 0.24497303366661072\n",
      "Epoch 1368, Loss: 1.0052363127470016, Final Batch Loss: 0.5489923357963562\n",
      "Epoch 1369, Loss: 0.47657443583011627, Final Batch Loss: 0.044144898653030396\n",
      "Epoch 1370, Loss: 0.845936581492424, Final Batch Loss: 0.4460130035877228\n",
      "Epoch 1371, Loss: 0.6776997148990631, Final Batch Loss: 0.2977273762226105\n",
      "Epoch 1372, Loss: 0.6290405169129372, Final Batch Loss: 0.10552626103162766\n",
      "Epoch 1373, Loss: 0.8320538699626923, Final Batch Loss: 0.3308332860469818\n",
      "Epoch 1374, Loss: 0.5596179664134979, Final Batch Loss: 0.12714357674121857\n",
      "Epoch 1375, Loss: 0.678532138466835, Final Batch Loss: 0.20716336369514465\n",
      "Epoch 1376, Loss: 0.5630672797560692, Final Batch Loss: 0.07476017624139786\n",
      "Epoch 1377, Loss: 0.4765869826078415, Final Batch Loss: 0.06884436309337616\n",
      "Epoch 1378, Loss: 0.5931306481361389, Final Batch Loss: 0.16331559419631958\n",
      "Epoch 1379, Loss: 0.6078045964241028, Final Batch Loss: 0.17766401171684265\n",
      "Epoch 1380, Loss: 0.6955578327178955, Final Batch Loss: 0.2780696153640747\n",
      "Epoch 1381, Loss: 0.6440168768167496, Final Batch Loss: 0.23995883762836456\n",
      "Epoch 1382, Loss: 0.5711065232753754, Final Batch Loss: 0.14463281631469727\n",
      "Epoch 1383, Loss: 0.6104391068220139, Final Batch Loss: 0.1904577761888504\n",
      "Epoch 1384, Loss: 0.7858978807926178, Final Batch Loss: 0.3489872217178345\n",
      "Epoch 1385, Loss: 0.6500214189291, Final Batch Loss: 0.23939025402069092\n",
      "Epoch 1386, Loss: 0.4973823353648186, Final Batch Loss: 0.0838194414973259\n",
      "Epoch 1387, Loss: 0.5836474150419235, Final Batch Loss: 0.2173173874616623\n",
      "Epoch 1388, Loss: 0.5379346311092377, Final Batch Loss: 0.16170065104961395\n",
      "Epoch 1389, Loss: 0.5719628185033798, Final Batch Loss: 0.16777576506137848\n",
      "Epoch 1390, Loss: 0.5174108892679214, Final Batch Loss: 0.11045408248901367\n",
      "Epoch 1391, Loss: 0.5462023913860321, Final Batch Loss: 0.12560434639453888\n",
      "Epoch 1392, Loss: 0.5809733718633652, Final Batch Loss: 0.19764544069766998\n",
      "Epoch 1393, Loss: 0.5433645397424698, Final Batch Loss: 0.15400271117687225\n",
      "Epoch 1394, Loss: 0.6166637092828751, Final Batch Loss: 0.2381240427494049\n",
      "Epoch 1395, Loss: 0.517415925860405, Final Batch Loss: 0.130508154630661\n",
      "Epoch 1396, Loss: 0.7677318006753922, Final Batch Loss: 0.4019528329372406\n",
      "Epoch 1397, Loss: 0.5152298212051392, Final Batch Loss: 0.0941358208656311\n",
      "Epoch 1398, Loss: 0.6184442490339279, Final Batch Loss: 0.1298433244228363\n",
      "Epoch 1399, Loss: 1.060129553079605, Final Batch Loss: 0.6031937003135681\n",
      "Epoch 1400, Loss: 0.5205541327595711, Final Batch Loss: 0.08273651450872421\n",
      "Epoch 1401, Loss: 0.8661812841892242, Final Batch Loss: 0.396167129278183\n",
      "Epoch 1402, Loss: 0.7963888645172119, Final Batch Loss: 0.3101595938205719\n",
      "Epoch 1403, Loss: 0.7822271287441254, Final Batch Loss: 0.3273994028568268\n",
      "Epoch 1404, Loss: 0.7065572142601013, Final Batch Loss: 0.16367816925048828\n",
      "Epoch 1405, Loss: 0.9170390665531158, Final Batch Loss: 0.3484176695346832\n",
      "Epoch 1406, Loss: 0.778881773352623, Final Batch Loss: 0.2934655249118805\n",
      "Epoch 1407, Loss: 0.5677418559789658, Final Batch Loss: 0.14420810341835022\n",
      "Epoch 1408, Loss: 0.7671444118022919, Final Batch Loss: 0.31557172536849976\n",
      "Epoch 1409, Loss: 0.4873505011200905, Final Batch Loss: 0.05427774041891098\n",
      "Epoch 1410, Loss: 0.9215372502803802, Final Batch Loss: 0.46703624725341797\n",
      "Epoch 1411, Loss: 0.5917492732405663, Final Batch Loss: 0.1162443533539772\n",
      "Epoch 1412, Loss: 0.6078420728445053, Final Batch Loss: 0.21456491947174072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1413, Loss: 0.6075780838727951, Final Batch Loss: 0.20015187561511993\n",
      "Epoch 1414, Loss: 0.6537426859140396, Final Batch Loss: 0.24871324002742767\n",
      "Epoch 1415, Loss: 0.6545386910438538, Final Batch Loss: 0.22615990042686462\n",
      "Epoch 1416, Loss: 0.8248776644468307, Final Batch Loss: 0.3673075735569\n",
      "Epoch 1417, Loss: 0.6337919533252716, Final Batch Loss: 0.1475437879562378\n",
      "Epoch 1418, Loss: 0.7737754434347153, Final Batch Loss: 0.3232046365737915\n",
      "Epoch 1419, Loss: 0.5762477219104767, Final Batch Loss: 0.15670287609100342\n",
      "Epoch 1420, Loss: 0.5967409908771515, Final Batch Loss: 0.1641780287027359\n",
      "Epoch 1421, Loss: 0.6594857275485992, Final Batch Loss: 0.24501100182533264\n",
      "Epoch 1422, Loss: 0.5297260396182537, Final Batch Loss: 0.043482836335897446\n",
      "Epoch 1423, Loss: 0.7509766221046448, Final Batch Loss: 0.31448861956596375\n",
      "Epoch 1424, Loss: 0.622618705034256, Final Batch Loss: 0.2216101437807083\n",
      "Epoch 1425, Loss: 0.7207545191049576, Final Batch Loss: 0.33413633704185486\n",
      "Epoch 1426, Loss: 0.6478412449359894, Final Batch Loss: 0.18922992050647736\n",
      "Epoch 1427, Loss: 0.7925048619508743, Final Batch Loss: 0.3068704903125763\n",
      "Epoch 1428, Loss: 0.6867295503616333, Final Batch Loss: 0.19612173736095428\n",
      "Epoch 1429, Loss: 0.7387485355138779, Final Batch Loss: 0.2901989221572876\n",
      "Epoch 1430, Loss: 0.5902107059955597, Final Batch Loss: 0.15558461844921112\n",
      "Epoch 1431, Loss: 0.503230482339859, Final Batch Loss: 0.10512466728687286\n",
      "Epoch 1432, Loss: 0.5556392446160316, Final Batch Loss: 0.07713668793439865\n",
      "Epoch 1433, Loss: 0.5213676244020462, Final Batch Loss: 0.09365494549274445\n",
      "Epoch 1434, Loss: 0.6293461173772812, Final Batch Loss: 0.21925170719623566\n",
      "Epoch 1435, Loss: 0.6474007219076157, Final Batch Loss: 0.22046849131584167\n",
      "Epoch 1436, Loss: 0.6303169578313828, Final Batch Loss: 0.24055591225624084\n",
      "Epoch 1437, Loss: 0.5839038044214249, Final Batch Loss: 0.1677808314561844\n",
      "Epoch 1438, Loss: 0.9411682039499283, Final Batch Loss: 0.5507077574729919\n",
      "Epoch 1439, Loss: 0.46381740644574165, Final Batch Loss: 0.04879807308316231\n",
      "Epoch 1440, Loss: 0.49919483810663223, Final Batch Loss: 0.08216913789510727\n",
      "Epoch 1441, Loss: 0.8345471918582916, Final Batch Loss: 0.43842947483062744\n",
      "Epoch 1442, Loss: 0.6838811039924622, Final Batch Loss: 0.24685712158679962\n",
      "Epoch 1443, Loss: 0.7459402829408646, Final Batch Loss: 0.31382495164871216\n",
      "Epoch 1444, Loss: 0.5753870010375977, Final Batch Loss: 0.12319348752498627\n",
      "Epoch 1445, Loss: 0.5603121370077133, Final Batch Loss: 0.15046091377735138\n",
      "Epoch 1446, Loss: 0.6327800452709198, Final Batch Loss: 0.232320636510849\n",
      "Epoch 1447, Loss: 0.8715689778327942, Final Batch Loss: 0.4344500005245209\n",
      "Epoch 1448, Loss: 0.5217007324099541, Final Batch Loss: 0.08630891889333725\n",
      "Epoch 1449, Loss: 0.47831376641988754, Final Batch Loss: 0.08320725709199905\n",
      "Epoch 1450, Loss: 0.5993923097848892, Final Batch Loss: 0.22425949573516846\n",
      "Epoch 1451, Loss: 0.48159924149513245, Final Batch Loss: 0.048802152276039124\n",
      "Epoch 1452, Loss: 0.8291660994291306, Final Batch Loss: 0.4225444197654724\n",
      "Epoch 1453, Loss: 0.611503392457962, Final Batch Loss: 0.18191513419151306\n",
      "Epoch 1454, Loss: 0.6573645025491714, Final Batch Loss: 0.26348960399627686\n",
      "Epoch 1455, Loss: 0.678167387843132, Final Batch Loss: 0.2698308229446411\n",
      "Epoch 1456, Loss: 0.44985795486718416, Final Batch Loss: 0.008714799769222736\n",
      "Epoch 1457, Loss: 0.6726367026567459, Final Batch Loss: 0.30267709493637085\n",
      "Epoch 1458, Loss: 0.514955036342144, Final Batch Loss: 0.1168132796883583\n",
      "Epoch 1459, Loss: 0.6183265745639801, Final Batch Loss: 0.2565484941005707\n",
      "Epoch 1460, Loss: 0.5962953418493271, Final Batch Loss: 0.18540513515472412\n",
      "Epoch 1461, Loss: 0.4970919042825699, Final Batch Loss: 0.07025152444839478\n",
      "Epoch 1462, Loss: 0.41370393708348274, Final Batch Loss: 0.03738455846905708\n",
      "Epoch 1463, Loss: 0.6097719371318817, Final Batch Loss: 0.20358063280582428\n",
      "Epoch 1464, Loss: 0.5476323515176773, Final Batch Loss: 0.15831346809864044\n",
      "Epoch 1465, Loss: 0.5959660112857819, Final Batch Loss: 0.16869617998600006\n",
      "Epoch 1466, Loss: 0.6880231201648712, Final Batch Loss: 0.30629217624664307\n",
      "Epoch 1467, Loss: 1.1817774176597595, Final Batch Loss: 0.8232603073120117\n",
      "Epoch 1468, Loss: 0.6306032538414001, Final Batch Loss: 0.16416004300117493\n",
      "Epoch 1469, Loss: 0.9547081887722015, Final Batch Loss: 0.4876808822154999\n",
      "Epoch 1470, Loss: 0.846952497959137, Final Batch Loss: 0.26545917987823486\n",
      "Epoch 1471, Loss: 0.6842363774776459, Final Batch Loss: 0.20508065819740295\n",
      "Epoch 1472, Loss: 0.5805588513612747, Final Batch Loss: 0.14581075310707092\n",
      "Epoch 1473, Loss: 1.025815263390541, Final Batch Loss: 0.6126416325569153\n",
      "Epoch 1474, Loss: 0.6616179347038269, Final Batch Loss: 0.2074912041425705\n",
      "Epoch 1475, Loss: 0.8263228684663773, Final Batch Loss: 0.29459404945373535\n",
      "Epoch 1476, Loss: 0.7538476586341858, Final Batch Loss: 0.3075253665447235\n",
      "Epoch 1477, Loss: 0.5996880233287811, Final Batch Loss: 0.13105745613574982\n",
      "Epoch 1478, Loss: 0.7522254437208176, Final Batch Loss: 0.30414608120918274\n",
      "Epoch 1479, Loss: 0.7545134276151657, Final Batch Loss: 0.3278377950191498\n",
      "Epoch 1480, Loss: 0.7438800483942032, Final Batch Loss: 0.2977115511894226\n",
      "Epoch 1481, Loss: 0.7225227206945419, Final Batch Loss: 0.3228989541530609\n",
      "Epoch 1482, Loss: 0.7678611278533936, Final Batch Loss: 0.347675621509552\n",
      "Epoch 1483, Loss: 0.7671592086553574, Final Batch Loss: 0.29347920417785645\n",
      "Epoch 1484, Loss: 0.7121307551860809, Final Batch Loss: 0.3339056074619293\n",
      "Epoch 1485, Loss: 0.7039432972669601, Final Batch Loss: 0.26679468154907227\n",
      "Epoch 1486, Loss: 0.6976344138383865, Final Batch Loss: 0.2897433936595917\n",
      "Epoch 1487, Loss: 0.4905583932995796, Final Batch Loss: 0.08136796206235886\n",
      "Epoch 1488, Loss: 0.8708211481571198, Final Batch Loss: 0.45421695709228516\n",
      "Epoch 1489, Loss: 0.7059266120195389, Final Batch Loss: 0.3624115288257599\n",
      "Epoch 1490, Loss: 0.6371162533760071, Final Batch Loss: 0.23185774683952332\n",
      "Epoch 1491, Loss: 0.8303271979093552, Final Batch Loss: 0.3070022761821747\n",
      "Epoch 1492, Loss: 0.9614416509866714, Final Batch Loss: 0.49424082040786743\n",
      "Epoch 1493, Loss: 0.5811419636011124, Final Batch Loss: 0.168708935379982\n",
      "Epoch 1494, Loss: 0.580618679523468, Final Batch Loss: 0.14863598346710205\n",
      "Epoch 1495, Loss: 0.6388317048549652, Final Batch Loss: 0.20629918575286865\n",
      "Epoch 1496, Loss: 0.48298966884613037, Final Batch Loss: 0.04110252857208252\n",
      "Epoch 1497, Loss: 0.8183197677135468, Final Batch Loss: 0.37879666686058044\n",
      "Epoch 1498, Loss: 0.7282323092222214, Final Batch Loss: 0.2512987554073334\n",
      "Epoch 1499, Loss: 0.5440709739923477, Final Batch Loss: 0.13093306124210358\n",
      "Epoch 1500, Loss: 0.6259475201368332, Final Batch Loss: 0.19348585605621338\n",
      "Epoch 1501, Loss: 0.7262200713157654, Final Batch Loss: 0.35125693678855896\n",
      "Epoch 1502, Loss: 0.5915336906909943, Final Batch Loss: 0.1570112258195877\n",
      "Epoch 1503, Loss: 0.5554786622524261, Final Batch Loss: 0.16888010501861572\n",
      "Epoch 1504, Loss: 0.5846727937459946, Final Batch Loss: 0.2343570739030838\n",
      "Epoch 1505, Loss: 0.7011318355798721, Final Batch Loss: 0.33961036801338196\n",
      "Epoch 1506, Loss: 0.5971735417842865, Final Batch Loss: 0.15458080172538757\n",
      "Epoch 1507, Loss: 0.745147630572319, Final Batch Loss: 0.29158738255500793\n",
      "Epoch 1508, Loss: 0.5819051265716553, Final Batch Loss: 0.15755636990070343\n",
      "Epoch 1509, Loss: 0.7568422853946686, Final Batch Loss: 0.2933918833732605\n",
      "Epoch 1510, Loss: 0.6940791755914688, Final Batch Loss: 0.25569507479667664\n",
      "Epoch 1511, Loss: 0.7230875045061111, Final Batch Loss: 0.31512176990509033\n",
      "Epoch 1512, Loss: 0.7947162091732025, Final Batch Loss: 0.3443104922771454\n",
      "Epoch 1513, Loss: 0.6028463244438171, Final Batch Loss: 0.14127829670906067\n",
      "Epoch 1514, Loss: 1.0424277037382126, Final Batch Loss: 0.6457167863845825\n",
      "Epoch 1515, Loss: 0.6641966551542282, Final Batch Loss: 0.2095024585723877\n",
      "Epoch 1516, Loss: 0.5632373541593552, Final Batch Loss: 0.1450623720884323\n",
      "Epoch 1517, Loss: 0.529701329767704, Final Batch Loss: 0.08972535282373428\n",
      "Epoch 1518, Loss: 0.5072816088795662, Final Batch Loss: 0.12016459554433823\n",
      "Epoch 1519, Loss: 0.5526697188615799, Final Batch Loss: 0.1437072455883026\n",
      "Epoch 1520, Loss: 0.5840951651334763, Final Batch Loss: 0.19120346009731293\n",
      "Epoch 1521, Loss: 0.49055055528879166, Final Batch Loss: 0.10493960231542587\n",
      "Epoch 1522, Loss: 0.6053256839513779, Final Batch Loss: 0.1591116189956665\n",
      "Epoch 1523, Loss: 0.42333030328154564, Final Batch Loss: 0.03352638706564903\n",
      "Epoch 1524, Loss: 0.6904526203870773, Final Batch Loss: 0.2910555601119995\n",
      "Epoch 1525, Loss: 0.5120410546660423, Final Batch Loss: 0.09447946399450302\n",
      "Epoch 1526, Loss: 0.6991880536079407, Final Batch Loss: 0.323729008436203\n",
      "Epoch 1527, Loss: 0.539374440908432, Final Batch Loss: 0.18000775575637817\n",
      "Epoch 1528, Loss: 0.7658034861087799, Final Batch Loss: 0.32482287287712097\n",
      "Epoch 1529, Loss: 0.4801947772502899, Final Batch Loss: 0.059280917048454285\n",
      "Epoch 1530, Loss: 0.8971209526062012, Final Batch Loss: 0.47573068737983704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1531, Loss: 0.6314573585987091, Final Batch Loss: 0.2004992812871933\n",
      "Epoch 1532, Loss: 0.6598372906446457, Final Batch Loss: 0.18745188415050507\n",
      "Epoch 1533, Loss: 0.6286830753087997, Final Batch Loss: 0.20539264380931854\n",
      "Epoch 1534, Loss: 0.47422389686107635, Final Batch Loss: 0.07711829245090485\n",
      "Epoch 1535, Loss: 0.5207674503326416, Final Batch Loss: 0.11182871460914612\n",
      "Epoch 1536, Loss: 0.5968103408813477, Final Batch Loss: 0.15971073508262634\n",
      "Epoch 1537, Loss: 0.6489373445510864, Final Batch Loss: 0.19188839197158813\n",
      "Epoch 1538, Loss: 0.6713014245033264, Final Batch Loss: 0.28548362851142883\n",
      "Epoch 1539, Loss: 0.5737373530864716, Final Batch Loss: 0.18427471816539764\n",
      "Epoch 1540, Loss: 0.6340218484401703, Final Batch Loss: 0.18680933117866516\n",
      "Epoch 1541, Loss: 0.5201988629996777, Final Batch Loss: 0.06099861487746239\n",
      "Epoch 1542, Loss: 0.6139802485704422, Final Batch Loss: 0.18555264174938202\n",
      "Epoch 1543, Loss: 0.4096693927422166, Final Batch Loss: 0.015165829099714756\n",
      "Epoch 1544, Loss: 0.49188745953142643, Final Batch Loss: 0.027716929093003273\n",
      "Epoch 1545, Loss: 0.45180749148130417, Final Batch Loss: 0.06746397167444229\n",
      "Epoch 1546, Loss: 0.5108940824866295, Final Batch Loss: 0.11422733217477798\n",
      "Epoch 1547, Loss: 0.450444832444191, Final Batch Loss: 0.10262492299079895\n",
      "Epoch 1548, Loss: 0.41997453570365906, Final Batch Loss: 0.050706639885902405\n",
      "Epoch 1549, Loss: 0.6152632832527161, Final Batch Loss: 0.2508141100406647\n",
      "Epoch 1550, Loss: 0.5047789514064789, Final Batch Loss: 0.0919920802116394\n",
      "Epoch 1551, Loss: 0.5150401145219803, Final Batch Loss: 0.12073270976543427\n",
      "Epoch 1552, Loss: 0.5955918431282043, Final Batch Loss: 0.23586004972457886\n",
      "Epoch 1553, Loss: 0.6448611468076706, Final Batch Loss: 0.22108840942382812\n",
      "Epoch 1554, Loss: 0.76956607401371, Final Batch Loss: 0.40064582228660583\n",
      "Epoch 1555, Loss: 0.5904031544923782, Final Batch Loss: 0.18102984130382538\n",
      "Epoch 1556, Loss: 0.5166860669851303, Final Batch Loss: 0.15182442963123322\n",
      "Epoch 1557, Loss: 0.6270335614681244, Final Batch Loss: 0.26460331678390503\n",
      "Epoch 1558, Loss: 0.522460013628006, Final Batch Loss: 0.14906467497348785\n",
      "Epoch 1559, Loss: 0.622221365571022, Final Batch Loss: 0.22157518565654755\n",
      "Epoch 1560, Loss: 0.5454059839248657, Final Batch Loss: 0.19139714539051056\n",
      "Epoch 1561, Loss: 0.5284820050001144, Final Batch Loss: 0.17759861052036285\n",
      "Epoch 1562, Loss: 0.5519115775823593, Final Batch Loss: 0.1747909039258957\n",
      "Epoch 1563, Loss: 0.5648550540208817, Final Batch Loss: 0.1651025265455246\n",
      "Epoch 1564, Loss: 1.0213687121868134, Final Batch Loss: 0.6546093225479126\n",
      "Epoch 1565, Loss: 0.686118483543396, Final Batch Loss: 0.2759001553058624\n",
      "Epoch 1566, Loss: 0.5039270669221878, Final Batch Loss: 0.12729163467884064\n",
      "Epoch 1567, Loss: 0.6608823537826538, Final Batch Loss: 0.2675403654575348\n",
      "Epoch 1568, Loss: 0.6190141886472702, Final Batch Loss: 0.23071451485157013\n",
      "Epoch 1569, Loss: 0.6619571000337601, Final Batch Loss: 0.23697885870933533\n",
      "Epoch 1570, Loss: 0.5806215703487396, Final Batch Loss: 0.21502403914928436\n",
      "Epoch 1571, Loss: 0.5372434258460999, Final Batch Loss: 0.13531726598739624\n",
      "Epoch 1572, Loss: 0.40415750443935394, Final Batch Loss: 0.0514085590839386\n",
      "Epoch 1573, Loss: 0.8254314363002777, Final Batch Loss: 0.4662284255027771\n",
      "Epoch 1574, Loss: 0.7755557298660278, Final Batch Loss: 0.362008661031723\n",
      "Epoch 1575, Loss: 0.7574751675128937, Final Batch Loss: 0.32116371393203735\n",
      "Epoch 1576, Loss: 0.5394876897335052, Final Batch Loss: 0.0994291603565216\n",
      "Epoch 1577, Loss: 0.5260551422834396, Final Batch Loss: 0.10779953002929688\n",
      "Epoch 1578, Loss: 0.5299645140767097, Final Batch Loss: 0.11558649688959122\n",
      "Epoch 1579, Loss: 0.5338047444820404, Final Batch Loss: 0.1786644011735916\n",
      "Epoch 1580, Loss: 0.8210721462965012, Final Batch Loss: 0.421438604593277\n",
      "Epoch 1581, Loss: 0.5648150444030762, Final Batch Loss: 0.1259986162185669\n",
      "Epoch 1582, Loss: 0.49813370406627655, Final Batch Loss: 0.08733180165290833\n",
      "Epoch 1583, Loss: 0.7290028929710388, Final Batch Loss: 0.34099316596984863\n",
      "Epoch 1584, Loss: 0.6169695258140564, Final Batch Loss: 0.21491457521915436\n",
      "Epoch 1585, Loss: 0.5047319531440735, Final Batch Loss: 0.12554045021533966\n",
      "Epoch 1586, Loss: 0.5597065910696983, Final Batch Loss: 0.1037718877196312\n",
      "Epoch 1587, Loss: 0.6611763089895248, Final Batch Loss: 0.2663387358188629\n",
      "Epoch 1588, Loss: 0.45231734216213226, Final Batch Loss: 0.05212731659412384\n",
      "Epoch 1589, Loss: 0.7259738147258759, Final Batch Loss: 0.2937825620174408\n",
      "Epoch 1590, Loss: 0.8214796483516693, Final Batch Loss: 0.4535995423793793\n",
      "Epoch 1591, Loss: 0.8286524266004562, Final Batch Loss: 0.4608530104160309\n",
      "Epoch 1592, Loss: 0.5437894314527512, Final Batch Loss: 0.11556154489517212\n",
      "Epoch 1593, Loss: 0.4423528164625168, Final Batch Loss: 0.07571125030517578\n",
      "Epoch 1594, Loss: 0.8094880878925323, Final Batch Loss: 0.42790794372558594\n",
      "Epoch 1595, Loss: 0.6567874550819397, Final Batch Loss: 0.24674904346466064\n",
      "Epoch 1596, Loss: 0.6996755748987198, Final Batch Loss: 0.3481334447860718\n",
      "Epoch 1597, Loss: 0.4506097212433815, Final Batch Loss: 0.09797721356153488\n",
      "Epoch 1598, Loss: 0.5307679027318954, Final Batch Loss: 0.15971773862838745\n",
      "Epoch 1599, Loss: 0.743889108300209, Final Batch Loss: 0.2834257185459137\n",
      "Epoch 1600, Loss: 0.5539437234401703, Final Batch Loss: 0.15103425085544586\n",
      "Epoch 1601, Loss: 0.5341288447380066, Final Batch Loss: 0.10843983292579651\n",
      "Epoch 1602, Loss: 0.6289511173963547, Final Batch Loss: 0.18386457860469818\n",
      "Epoch 1603, Loss: 0.6337291598320007, Final Batch Loss: 0.16114595532417297\n",
      "Epoch 1604, Loss: 0.8939911276102066, Final Batch Loss: 0.5186824202537537\n",
      "Epoch 1605, Loss: 0.47171076759696007, Final Batch Loss: 0.06150120124220848\n",
      "Epoch 1606, Loss: 0.6636047512292862, Final Batch Loss: 0.26843398809432983\n",
      "Epoch 1607, Loss: 0.6720081865787506, Final Batch Loss: 0.2451871633529663\n",
      "Epoch 1608, Loss: 0.5372481942176819, Final Batch Loss: 0.10576985776424408\n",
      "Epoch 1609, Loss: 0.6568484902381897, Final Batch Loss: 0.27752870321273804\n",
      "Epoch 1610, Loss: 1.3045831769704819, Final Batch Loss: 0.9327960014343262\n",
      "Epoch 1611, Loss: 0.48119715601205826, Final Batch Loss: 0.11443475633859634\n",
      "Epoch 1612, Loss: 0.5197873413562775, Final Batch Loss: 0.13703712821006775\n",
      "Epoch 1613, Loss: 0.5579632520675659, Final Batch Loss: 0.1723133623600006\n",
      "Epoch 1614, Loss: 0.8077993988990784, Final Batch Loss: 0.4436522424221039\n",
      "Epoch 1615, Loss: 0.7069690972566605, Final Batch Loss: 0.34264764189720154\n",
      "Epoch 1616, Loss: 0.4511067010462284, Final Batch Loss: 0.02869589999318123\n",
      "Epoch 1617, Loss: 0.4573022276163101, Final Batch Loss: 0.07555028796195984\n",
      "Epoch 1618, Loss: 0.4988131448626518, Final Batch Loss: 0.11092279106378555\n",
      "Epoch 1619, Loss: 0.42751563899219036, Final Batch Loss: 0.021048886701464653\n",
      "Epoch 1620, Loss: 0.5077319890260696, Final Batch Loss: 0.1259378045797348\n",
      "Epoch 1621, Loss: 0.5679197236895561, Final Batch Loss: 0.12104866653680801\n",
      "Epoch 1622, Loss: 0.4493519589304924, Final Batch Loss: 0.07920856028795242\n",
      "Epoch 1623, Loss: 0.6498866975307465, Final Batch Loss: 0.31079092621803284\n",
      "Epoch 1624, Loss: 0.5642552822828293, Final Batch Loss: 0.15047767758369446\n",
      "Epoch 1625, Loss: 0.6452816873788834, Final Batch Loss: 0.2514182925224304\n",
      "Epoch 1626, Loss: 0.5204774141311646, Final Batch Loss: 0.15411031246185303\n",
      "Epoch 1627, Loss: 0.6214479207992554, Final Batch Loss: 0.2324780970811844\n",
      "Epoch 1628, Loss: 0.5752116143703461, Final Batch Loss: 0.1874370127916336\n",
      "Epoch 1629, Loss: 0.5649281889200211, Final Batch Loss: 0.15509606897830963\n",
      "Epoch 1630, Loss: 0.5808070003986359, Final Batch Loss: 0.18563152849674225\n",
      "Epoch 1631, Loss: 0.3878113627433777, Final Batch Loss: 0.047182366251945496\n",
      "Epoch 1632, Loss: 0.4729486182332039, Final Batch Loss: 0.0748399868607521\n",
      "Epoch 1633, Loss: 0.5193234980106354, Final Batch Loss: 0.18411609530448914\n",
      "Epoch 1634, Loss: 0.6245769709348679, Final Batch Loss: 0.2606428265571594\n",
      "Epoch 1635, Loss: 0.4193406477570534, Final Batch Loss: 0.06291822344064713\n",
      "Epoch 1636, Loss: 0.5356614291667938, Final Batch Loss: 0.20207233726978302\n",
      "Epoch 1637, Loss: 0.46318449452519417, Final Batch Loss: 0.049833688884973526\n",
      "Epoch 1638, Loss: 0.6176669001579285, Final Batch Loss: 0.2354884147644043\n",
      "Epoch 1639, Loss: 1.0383132249116898, Final Batch Loss: 0.6455607414245605\n",
      "Epoch 1640, Loss: 0.5710519850254059, Final Batch Loss: 0.19298088550567627\n",
      "Epoch 1641, Loss: 0.600697323679924, Final Batch Loss: 0.18036596477031708\n",
      "Epoch 1642, Loss: 0.5161410421133041, Final Batch Loss: 0.10316704213619232\n",
      "Epoch 1643, Loss: 0.5006874948740005, Final Batch Loss: 0.13228031992912292\n",
      "Epoch 1644, Loss: 0.5162663757801056, Final Batch Loss: 0.0811956524848938\n",
      "Epoch 1645, Loss: 0.581811398267746, Final Batch Loss: 0.213306725025177\n",
      "Epoch 1646, Loss: 0.6410268098115921, Final Batch Loss: 0.2715866267681122\n",
      "Epoch 1647, Loss: 0.6652302443981171, Final Batch Loss: 0.2366972714662552\n",
      "Epoch 1648, Loss: 0.6402079910039902, Final Batch Loss: 0.21495287120342255\n",
      "Epoch 1649, Loss: 0.7098825573921204, Final Batch Loss: 0.23121242225170135\n",
      "Epoch 1650, Loss: 0.6426487118005753, Final Batch Loss: 0.2490580528974533\n",
      "Epoch 1651, Loss: 0.8925645649433136, Final Batch Loss: 0.4816625118255615\n",
      "Epoch 1652, Loss: 0.7162009477615356, Final Batch Loss: 0.2796277105808258\n",
      "Epoch 1653, Loss: 0.4769746959209442, Final Batch Loss: 0.08985783159732819\n",
      "Epoch 1654, Loss: 0.6194118410348892, Final Batch Loss: 0.16848035156726837\n",
      "Epoch 1655, Loss: 0.5274094492197037, Final Batch Loss: 0.15787465870380402\n",
      "Epoch 1656, Loss: 0.4906441420316696, Final Batch Loss: 0.12930503487586975\n",
      "Epoch 1657, Loss: 0.45026298612356186, Final Batch Loss: 0.06463143974542618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1658, Loss: 0.6218382716178894, Final Batch Loss: 0.23369312286376953\n",
      "Epoch 1659, Loss: 0.5235511958599091, Final Batch Loss: 0.1482769250869751\n",
      "Epoch 1660, Loss: 0.6648746281862259, Final Batch Loss: 0.29899582266807556\n",
      "Epoch 1661, Loss: 0.7804662138223648, Final Batch Loss: 0.3800119459629059\n",
      "Epoch 1662, Loss: 0.6852188259363174, Final Batch Loss: 0.2368374913930893\n",
      "Epoch 1663, Loss: 0.47336019575595856, Final Batch Loss: 0.11647884547710419\n",
      "Epoch 1664, Loss: 0.7548475861549377, Final Batch Loss: 0.35181939601898193\n",
      "Epoch 1665, Loss: 0.640919417142868, Final Batch Loss: 0.26405251026153564\n",
      "Epoch 1666, Loss: 0.8007359206676483, Final Batch Loss: 0.45075085759162903\n",
      "Epoch 1667, Loss: 0.5487827062606812, Final Batch Loss: 0.2084178626537323\n",
      "Epoch 1668, Loss: 0.6207035779953003, Final Batch Loss: 0.16208386421203613\n",
      "Epoch 1669, Loss: 0.5725972354412079, Final Batch Loss: 0.18521475791931152\n",
      "Epoch 1670, Loss: 0.7065492123365402, Final Batch Loss: 0.35211384296417236\n",
      "Epoch 1671, Loss: 0.5233025848865509, Final Batch Loss: 0.16368918120861053\n",
      "Epoch 1672, Loss: 0.6085154414176941, Final Batch Loss: 0.23504316806793213\n",
      "Epoch 1673, Loss: 0.6355359256267548, Final Batch Loss: 0.26809218525886536\n",
      "Epoch 1674, Loss: 0.5827687829732895, Final Batch Loss: 0.22179460525512695\n",
      "Epoch 1675, Loss: 0.5936816185712814, Final Batch Loss: 0.214284747838974\n",
      "Epoch 1676, Loss: 0.5911740213632584, Final Batch Loss: 0.15993911027908325\n",
      "Epoch 1677, Loss: 0.5346475839614868, Final Batch Loss: 0.1780582070350647\n",
      "Epoch 1678, Loss: 0.44825801998376846, Final Batch Loss: 0.09056844562292099\n",
      "Epoch 1679, Loss: 0.5172007828950882, Final Batch Loss: 0.14245671033859253\n",
      "Epoch 1680, Loss: 0.6426628082990646, Final Batch Loss: 0.2468975931406021\n",
      "Epoch 1681, Loss: 0.5384683459997177, Final Batch Loss: 0.18871088325977325\n",
      "Epoch 1682, Loss: 0.7092174887657166, Final Batch Loss: 0.30634912848472595\n",
      "Epoch 1683, Loss: 0.5142297893762589, Final Batch Loss: 0.10357962548732758\n",
      "Epoch 1684, Loss: 0.8588985204696655, Final Batch Loss: 0.45176205039024353\n",
      "Epoch 1685, Loss: 0.7147325128316879, Final Batch Loss: 0.3385268747806549\n",
      "Epoch 1686, Loss: 0.5068468451499939, Final Batch Loss: 0.07221624255180359\n",
      "Epoch 1687, Loss: 0.6554480791091919, Final Batch Loss: 0.26802581548690796\n",
      "Epoch 1688, Loss: 0.40726234018802643, Final Batch Loss: 0.03339686989784241\n",
      "Epoch 1689, Loss: 0.4961874485015869, Final Batch Loss: 0.12732520699501038\n",
      "Epoch 1690, Loss: 0.6708532273769379, Final Batch Loss: 0.2986239492893219\n",
      "Epoch 1691, Loss: 0.5183696746826172, Final Batch Loss: 0.1336119920015335\n",
      "Epoch 1692, Loss: 0.4830804169178009, Final Batch Loss: 0.12130515277385712\n",
      "Epoch 1693, Loss: 0.4986583888530731, Final Batch Loss: 0.13431453704833984\n",
      "Epoch 1694, Loss: 0.8799880743026733, Final Batch Loss: 0.4398331940174103\n",
      "Epoch 1695, Loss: 0.5006128251552582, Final Batch Loss: 0.07398591935634613\n",
      "Epoch 1696, Loss: 0.5184299945831299, Final Batch Loss: 0.22293317317962646\n",
      "Epoch 1697, Loss: 0.36937823705375195, Final Batch Loss: 0.021806789562106133\n",
      "Epoch 1698, Loss: 0.5827278345823288, Final Batch Loss: 0.20454707741737366\n",
      "Epoch 1699, Loss: 0.72308349609375, Final Batch Loss: 0.3243860602378845\n",
      "Epoch 1700, Loss: 0.5235083699226379, Final Batch Loss: 0.11857849359512329\n",
      "Epoch 1701, Loss: 0.3931163549423218, Final Batch Loss: 0.053219273686409\n",
      "Epoch 1702, Loss: 0.6065122336149216, Final Batch Loss: 0.17818164825439453\n",
      "Epoch 1703, Loss: 0.49300703406333923, Final Batch Loss: 0.13242733478546143\n",
      "Epoch 1704, Loss: 0.4610067680478096, Final Batch Loss: 0.0737384781241417\n",
      "Epoch 1705, Loss: 0.36995628476142883, Final Batch Loss: 0.020020946860313416\n",
      "Epoch 1706, Loss: 0.46541161835193634, Final Batch Loss: 0.129164457321167\n",
      "Epoch 1707, Loss: 0.5709662288427353, Final Batch Loss: 0.19384713470935822\n",
      "Epoch 1708, Loss: 0.600654199719429, Final Batch Loss: 0.24454644322395325\n",
      "Epoch 1709, Loss: 0.5184036195278168, Final Batch Loss: 0.19056181609630585\n",
      "Epoch 1710, Loss: 0.6115974634885788, Final Batch Loss: 0.24064679443836212\n",
      "Epoch 1711, Loss: 0.4852812588214874, Final Batch Loss: 0.13334539532661438\n",
      "Epoch 1712, Loss: 0.4570458345115185, Final Batch Loss: 0.035370226949453354\n",
      "Epoch 1713, Loss: 0.5329962521791458, Final Batch Loss: 0.2273334264755249\n",
      "Epoch 1714, Loss: 0.5016448497772217, Final Batch Loss: 0.14757080376148224\n",
      "Epoch 1715, Loss: 0.5658764839172363, Final Batch Loss: 0.20684510469436646\n",
      "Epoch 1716, Loss: 0.534874938428402, Final Batch Loss: 0.09839006513357162\n",
      "Epoch 1717, Loss: 0.5212565064430237, Final Batch Loss: 0.18243849277496338\n",
      "Epoch 1718, Loss: 0.3654352941084653, Final Batch Loss: 0.0037833668757230043\n",
      "Epoch 1719, Loss: 0.5337193608283997, Final Batch Loss: 0.14144065976142883\n",
      "Epoch 1720, Loss: 0.8228987902402878, Final Batch Loss: 0.42973077297210693\n",
      "Epoch 1721, Loss: 0.5057874917984009, Final Batch Loss: 0.17086045444011688\n",
      "Epoch 1722, Loss: 0.6459098905324936, Final Batch Loss: 0.25803378224372864\n",
      "Epoch 1723, Loss: 0.5250158756971359, Final Batch Loss: 0.1645013988018036\n",
      "Epoch 1724, Loss: 0.5749651938676834, Final Batch Loss: 0.2173990160226822\n",
      "Epoch 1725, Loss: 0.4513394311070442, Final Batch Loss: 0.06251881271600723\n",
      "Epoch 1726, Loss: 0.3836577981710434, Final Batch Loss: 0.06639960408210754\n",
      "Epoch 1727, Loss: 0.5153336077928543, Final Batch Loss: 0.21031732857227325\n",
      "Epoch 1728, Loss: 0.5038628578186035, Final Batch Loss: 0.13650622963905334\n",
      "Epoch 1729, Loss: 0.4908110201358795, Final Batch Loss: 0.10757763683795929\n",
      "Epoch 1730, Loss: 0.654464066028595, Final Batch Loss: 0.3521256446838379\n",
      "Epoch 1731, Loss: 0.4429655596613884, Final Batch Loss: 0.09730211645364761\n",
      "Epoch 1732, Loss: 0.5618901401758194, Final Batch Loss: 0.22994129359722137\n",
      "Epoch 1733, Loss: 0.6307736486196518, Final Batch Loss: 0.24385027587413788\n",
      "Epoch 1734, Loss: 0.4609441012144089, Final Batch Loss: 0.13462376594543457\n",
      "Epoch 1735, Loss: 0.5289801806211472, Final Batch Loss: 0.1848428100347519\n",
      "Epoch 1736, Loss: 0.5087814480066299, Final Batch Loss: 0.10727518796920776\n",
      "Epoch 1737, Loss: 0.5070320218801498, Final Batch Loss: 0.13380610942840576\n",
      "Epoch 1738, Loss: 0.40522783249616623, Final Batch Loss: 0.0639367327094078\n",
      "Epoch 1739, Loss: 0.5031958222389221, Final Batch Loss: 0.16892309486865997\n",
      "Epoch 1740, Loss: 0.5108608454465866, Final Batch Loss: 0.08332863450050354\n",
      "Epoch 1741, Loss: 0.5025363862514496, Final Batch Loss: 0.15118001401424408\n",
      "Epoch 1742, Loss: 0.3825795277953148, Final Batch Loss: 0.10574542731046677\n",
      "Epoch 1743, Loss: 0.5691215544939041, Final Batch Loss: 0.2022533416748047\n",
      "Epoch 1744, Loss: 0.43883016705513, Final Batch Loss: 0.09019200503826141\n",
      "Epoch 1745, Loss: 0.3802112992852926, Final Batch Loss: 0.025461291894316673\n",
      "Epoch 1746, Loss: 0.516044095158577, Final Batch Loss: 0.18586315214633942\n",
      "Epoch 1747, Loss: 0.5502856224775314, Final Batch Loss: 0.1866677850484848\n",
      "Epoch 1748, Loss: 0.4152272008359432, Final Batch Loss: 0.04036874696612358\n",
      "Epoch 1749, Loss: 0.5422718673944473, Final Batch Loss: 0.18384063243865967\n",
      "Epoch 1750, Loss: 0.49799391627311707, Final Batch Loss: 0.13714805245399475\n",
      "Epoch 1751, Loss: 0.5290059447288513, Final Batch Loss: 0.1254902482032776\n",
      "Epoch 1752, Loss: 0.46778780966997147, Final Batch Loss: 0.07464537769556046\n",
      "Epoch 1753, Loss: 0.4662538319826126, Final Batch Loss: 0.13160865008831024\n",
      "Epoch 1754, Loss: 0.6466291099786758, Final Batch Loss: 0.2681460976600647\n",
      "Epoch 1755, Loss: 0.6175190955400467, Final Batch Loss: 0.1972218155860901\n",
      "Epoch 1756, Loss: 0.6757490038871765, Final Batch Loss: 0.3050329387187958\n",
      "Epoch 1757, Loss: 1.0078209191560745, Final Batch Loss: 0.6085626482963562\n",
      "Epoch 1758, Loss: 0.4788353219628334, Final Batch Loss: 0.11353432387113571\n",
      "Epoch 1759, Loss: 0.5567508786916733, Final Batch Loss: 0.15797363221645355\n",
      "Epoch 1760, Loss: 0.6051067262887955, Final Batch Loss: 0.1721622496843338\n",
      "Epoch 1761, Loss: 0.5755975842475891, Final Batch Loss: 0.22563740611076355\n",
      "Epoch 1762, Loss: 0.58036869764328, Final Batch Loss: 0.26043689250946045\n",
      "Epoch 1763, Loss: 0.46894562989473343, Final Batch Loss: 0.11796150356531143\n",
      "Epoch 1764, Loss: 0.4071977026760578, Final Batch Loss: 0.05998129025101662\n",
      "Epoch 1765, Loss: 0.5031927973031998, Final Batch Loss: 0.13063064217567444\n",
      "Epoch 1766, Loss: 0.6709326654672623, Final Batch Loss: 0.321942538022995\n",
      "Epoch 1767, Loss: 0.5382892787456512, Final Batch Loss: 0.20221871137619019\n",
      "Epoch 1768, Loss: 0.4604700058698654, Final Batch Loss: 0.0806131362915039\n",
      "Epoch 1769, Loss: 0.49565352499485016, Final Batch Loss: 0.16462956368923187\n",
      "Epoch 1770, Loss: 0.6309235990047455, Final Batch Loss: 0.26882702112197876\n",
      "Epoch 1771, Loss: 0.5707739740610123, Final Batch Loss: 0.19477799534797668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1772, Loss: 0.5396819859743118, Final Batch Loss: 0.1844392567873001\n",
      "Epoch 1773, Loss: 0.44010022282600403, Final Batch Loss: 0.045940667390823364\n",
      "Epoch 1774, Loss: 0.5931972563266754, Final Batch Loss: 0.2675863802433014\n",
      "Epoch 1775, Loss: 0.5882457196712494, Final Batch Loss: 0.21830205619335175\n",
      "Epoch 1776, Loss: 0.5595580339431763, Final Batch Loss: 0.1475319117307663\n",
      "Epoch 1777, Loss: 0.745454728603363, Final Batch Loss: 0.40290534496307373\n",
      "Epoch 1778, Loss: 0.37523749843239784, Final Batch Loss: 0.013043675571680069\n",
      "Epoch 1779, Loss: 0.3987533859908581, Final Batch Loss: 0.017395880073308945\n",
      "Epoch 1780, Loss: 0.7700518369674683, Final Batch Loss: 0.3158838450908661\n",
      "Epoch 1781, Loss: 0.4850945249199867, Final Batch Loss: 0.11718261986970901\n",
      "Epoch 1782, Loss: 0.5157507061958313, Final Batch Loss: 0.12229444086551666\n",
      "Epoch 1783, Loss: 0.34709860756993294, Final Batch Loss: 0.024525556713342667\n",
      "Epoch 1784, Loss: 0.36252402514219284, Final Batch Loss: 0.063532255589962\n",
      "Epoch 1785, Loss: 0.5945709943771362, Final Batch Loss: 0.2531791925430298\n",
      "Epoch 1786, Loss: 0.41170037165284157, Final Batch Loss: 0.053380269557237625\n",
      "Epoch 1787, Loss: 0.598363608121872, Final Batch Loss: 0.25767749547958374\n",
      "Epoch 1788, Loss: 0.5253761857748032, Final Batch Loss: 0.1475144922733307\n",
      "Epoch 1789, Loss: 0.4383472427725792, Final Batch Loss: 0.05505272001028061\n",
      "Epoch 1790, Loss: 0.5837565660476685, Final Batch Loss: 0.22274498641490936\n",
      "Epoch 1791, Loss: 0.5455458760261536, Final Batch Loss: 0.18522733449935913\n",
      "Epoch 1792, Loss: 0.5688559859991074, Final Batch Loss: 0.1705491691827774\n",
      "Epoch 1793, Loss: 0.7102689743041992, Final Batch Loss: 0.325648695230484\n",
      "Epoch 1794, Loss: 0.4169842377305031, Final Batch Loss: 0.06556306034326553\n",
      "Epoch 1795, Loss: 0.3832961842417717, Final Batch Loss: 0.06033746153116226\n",
      "Epoch 1796, Loss: 0.573668584227562, Final Batch Loss: 0.19723178446292877\n",
      "Epoch 1797, Loss: 0.5854975581169128, Final Batch Loss: 0.2327638417482376\n",
      "Epoch 1798, Loss: 0.6348063349723816, Final Batch Loss: 0.3008388876914978\n",
      "Epoch 1799, Loss: 0.750209853053093, Final Batch Loss: 0.40593603253364563\n",
      "Epoch 1800, Loss: 0.5078361183404922, Final Batch Loss: 0.12746278941631317\n",
      "Epoch 1801, Loss: 0.6283566802740097, Final Batch Loss: 0.27639856934547424\n",
      "Epoch 1802, Loss: 0.4226711466908455, Final Batch Loss: 0.044713281095027924\n",
      "Epoch 1803, Loss: 0.7569836899638176, Final Batch Loss: 0.39970892667770386\n",
      "Epoch 1804, Loss: 0.4092017859220505, Final Batch Loss: 0.06676717102527618\n",
      "Epoch 1805, Loss: 0.5183559060096741, Final Batch Loss: 0.17824359238147736\n",
      "Epoch 1806, Loss: 0.5594412535429001, Final Batch Loss: 0.21901923418045044\n",
      "Epoch 1807, Loss: 0.4235367476940155, Final Batch Loss: 0.09281767904758453\n",
      "Epoch 1808, Loss: 0.43836265802383423, Final Batch Loss: 0.13139207661151886\n",
      "Epoch 1809, Loss: 0.3940253332257271, Final Batch Loss: 0.08359994739294052\n",
      "Epoch 1810, Loss: 0.44407569617033005, Final Batch Loss: 0.11411727219820023\n",
      "Epoch 1811, Loss: 0.6035324186086655, Final Batch Loss: 0.2347029447555542\n",
      "Epoch 1812, Loss: 0.4618644267320633, Final Batch Loss: 0.12194007635116577\n",
      "Epoch 1813, Loss: 0.37954315170645714, Final Batch Loss: 0.03933325037360191\n",
      "Epoch 1814, Loss: 0.6322674453258514, Final Batch Loss: 0.30045026540756226\n",
      "Epoch 1815, Loss: 0.5268119871616364, Final Batch Loss: 0.14669343829154968\n",
      "Epoch 1816, Loss: 0.49325400590896606, Final Batch Loss: 0.1509462296962738\n",
      "Epoch 1817, Loss: 0.7865781635046005, Final Batch Loss: 0.4056526720523834\n",
      "Epoch 1818, Loss: 0.447189599275589, Final Batch Loss: 0.07812663912773132\n",
      "Epoch 1819, Loss: 0.506317213177681, Final Batch Loss: 0.18077903985977173\n",
      "Epoch 1820, Loss: 0.6659024208784103, Final Batch Loss: 0.21401144564151764\n",
      "Epoch 1821, Loss: 0.6281837522983551, Final Batch Loss: 0.240034282207489\n",
      "Epoch 1822, Loss: 0.39214726258069277, Final Batch Loss: 0.011376556940376759\n",
      "Epoch 1823, Loss: 0.6243876516819, Final Batch Loss: 0.24976910650730133\n",
      "Epoch 1824, Loss: 0.5357849150896072, Final Batch Loss: 0.16997669637203217\n",
      "Epoch 1825, Loss: 0.5578361749649048, Final Batch Loss: 0.22406046092510223\n",
      "Epoch 1826, Loss: 0.38996395468711853, Final Batch Loss: 0.05742648243904114\n",
      "Epoch 1827, Loss: 0.4645985811948776, Final Batch Loss: 0.12629267573356628\n",
      "Epoch 1828, Loss: 0.5627964287996292, Final Batch Loss: 0.19172313809394836\n",
      "Epoch 1829, Loss: 0.6001173406839371, Final Batch Loss: 0.16159562766551971\n",
      "Epoch 1830, Loss: 0.3877428532578051, Final Batch Loss: 0.004059514496475458\n",
      "Epoch 1831, Loss: 0.5657560676336288, Final Batch Loss: 0.18546904623508453\n",
      "Epoch 1832, Loss: 0.5741925984621048, Final Batch Loss: 0.24870583415031433\n",
      "Epoch 1833, Loss: 0.5205915123224258, Final Batch Loss: 0.1553746461868286\n",
      "Epoch 1834, Loss: 0.589866504073143, Final Batch Loss: 0.17841099202632904\n",
      "Epoch 1835, Loss: 0.7210257947444916, Final Batch Loss: 0.23875844478607178\n",
      "Epoch 1836, Loss: 0.4215256869792938, Final Batch Loss: 0.022076711058616638\n",
      "Epoch 1837, Loss: 0.7627425938844681, Final Batch Loss: 0.2946605682373047\n",
      "Epoch 1838, Loss: 0.7684856653213501, Final Batch Loss: 0.3136558532714844\n",
      "Epoch 1839, Loss: 0.6615111082792282, Final Batch Loss: 0.22013308107852936\n",
      "Epoch 1840, Loss: 0.47044897079467773, Final Batch Loss: 0.09347400069236755\n",
      "Epoch 1841, Loss: 0.8273271322250366, Final Batch Loss: 0.36701974272727966\n",
      "Epoch 1842, Loss: 0.7097869217395782, Final Batch Loss: 0.22132690250873566\n",
      "Epoch 1843, Loss: 0.6098998300731182, Final Batch Loss: 0.03908243402838707\n",
      "Epoch 1844, Loss: 0.6701234430074692, Final Batch Loss: 0.1542632281780243\n",
      "Epoch 1845, Loss: 0.6537003368139267, Final Batch Loss: 0.1399470716714859\n",
      "Epoch 1846, Loss: 0.6661393791437149, Final Batch Loss: 0.28600722551345825\n",
      "Epoch 1847, Loss: 0.7250872999429703, Final Batch Loss: 0.2612028419971466\n",
      "Epoch 1848, Loss: 0.5106744691729546, Final Batch Loss: 0.08278774470090866\n",
      "Epoch 1849, Loss: 0.5572434961795807, Final Batch Loss: 0.16364046931266785\n",
      "Epoch 1850, Loss: 0.43803954124450684, Final Batch Loss: 0.07251104712486267\n",
      "Epoch 1851, Loss: 0.5998711884021759, Final Batch Loss: 0.22684380412101746\n",
      "Epoch 1852, Loss: 0.6052424311637878, Final Batch Loss: 0.20927882194519043\n",
      "Epoch 1853, Loss: 0.47886160016059875, Final Batch Loss: 0.0894770473241806\n",
      "Epoch 1854, Loss: 0.4781126081943512, Final Batch Loss: 0.0527435839176178\n",
      "Epoch 1855, Loss: 0.4824228249490261, Final Batch Loss: 0.05508356913924217\n",
      "Epoch 1856, Loss: 0.4267694316804409, Final Batch Loss: 0.04636479541659355\n",
      "Epoch 1857, Loss: 0.40090033411979675, Final Batch Loss: 0.07825759053230286\n",
      "Epoch 1858, Loss: 0.9009996354579926, Final Batch Loss: 0.5413267016410828\n",
      "Epoch 1859, Loss: 0.6126536428928375, Final Batch Loss: 0.24744455516338348\n",
      "Epoch 1860, Loss: 0.516157329082489, Final Batch Loss: 0.18179622292518616\n",
      "Epoch 1861, Loss: 0.5313977748155594, Final Batch Loss: 0.16726833581924438\n",
      "Epoch 1862, Loss: 0.6399379223585129, Final Batch Loss: 0.2752039432525635\n",
      "Epoch 1863, Loss: 0.4674093872308731, Final Batch Loss: 0.13030049204826355\n",
      "Epoch 1864, Loss: 0.4791280925273895, Final Batch Loss: 0.13573169708251953\n",
      "Epoch 1865, Loss: 0.7192232459783554, Final Batch Loss: 0.34597286581993103\n",
      "Epoch 1866, Loss: 0.47764456272125244, Final Batch Loss: 0.15193472802639008\n",
      "Epoch 1867, Loss: 0.5704913586378098, Final Batch Loss: 0.19550111889839172\n",
      "Epoch 1868, Loss: 0.538220688700676, Final Batch Loss: 0.22046977281570435\n",
      "Epoch 1869, Loss: 0.3984792195260525, Final Batch Loss: 0.03928818926215172\n",
      "Epoch 1870, Loss: 0.690992146730423, Final Batch Loss: 0.20048470795154572\n",
      "Epoch 1871, Loss: 0.741846889257431, Final Batch Loss: 0.3649500906467438\n",
      "Epoch 1872, Loss: 0.5710812509059906, Final Batch Loss: 0.17959712445735931\n",
      "Epoch 1873, Loss: 0.6388496905565262, Final Batch Loss: 0.2778889834880829\n",
      "Epoch 1874, Loss: 0.5290023684501648, Final Batch Loss: 0.14857642352581024\n",
      "Epoch 1875, Loss: 0.46860258281230927, Final Batch Loss: 0.12230244278907776\n",
      "Epoch 1876, Loss: 0.6143294125795364, Final Batch Loss: 0.27229762077331543\n",
      "Epoch 1877, Loss: 0.7179722636938095, Final Batch Loss: 0.36166343092918396\n",
      "Epoch 1878, Loss: 0.4362717494368553, Final Batch Loss: 0.09937333315610886\n",
      "Epoch 1879, Loss: 0.7136756628751755, Final Batch Loss: 0.37160640954971313\n",
      "Epoch 1880, Loss: 0.45823726058006287, Final Batch Loss: 0.12892454862594604\n",
      "Epoch 1881, Loss: 0.6754291355609894, Final Batch Loss: 0.323390394449234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1882, Loss: 0.4799501895904541, Final Batch Loss: 0.14244230091571808\n",
      "Epoch 1883, Loss: 0.492802232503891, Final Batch Loss: 0.14235399663448334\n",
      "Epoch 1884, Loss: 0.5810713917016983, Final Batch Loss: 0.2016918957233429\n",
      "Epoch 1885, Loss: 0.5345932394266129, Final Batch Loss: 0.20326805114746094\n",
      "Epoch 1886, Loss: 0.4412394016981125, Final Batch Loss: 0.11132590472698212\n",
      "Epoch 1887, Loss: 0.6965030878782272, Final Batch Loss: 0.36205267906188965\n",
      "Epoch 1888, Loss: 0.7109239250421524, Final Batch Loss: 0.35786718130111694\n",
      "Epoch 1889, Loss: 0.5894076824188232, Final Batch Loss: 0.20954842865467072\n",
      "Epoch 1890, Loss: 0.8830673694610596, Final Batch Loss: 0.37689805030822754\n",
      "Epoch 1891, Loss: 0.5113188028335571, Final Batch Loss: 0.09281113743782043\n",
      "Epoch 1892, Loss: 0.6076068431138992, Final Batch Loss: 0.23602603375911713\n",
      "Epoch 1893, Loss: 0.5215033292770386, Final Batch Loss: 0.14475169777870178\n",
      "Epoch 1894, Loss: 0.5860857889056206, Final Batch Loss: 0.11004754155874252\n",
      "Epoch 1895, Loss: 0.5071474239230156, Final Batch Loss: 0.11983407288789749\n",
      "Epoch 1896, Loss: 0.48801954090595245, Final Batch Loss: 0.17346195876598358\n",
      "Epoch 1897, Loss: 0.6452990770339966, Final Batch Loss: 0.29886022210121155\n",
      "Epoch 1898, Loss: 0.42869841307401657, Final Batch Loss: 0.07344204932451248\n",
      "Epoch 1899, Loss: 0.4899512231349945, Final Batch Loss: 0.16116507351398468\n",
      "Epoch 1900, Loss: 0.38716041669249535, Final Batch Loss: 0.03685477003455162\n",
      "Epoch 1901, Loss: 0.4740819036960602, Final Batch Loss: 0.12813542783260345\n",
      "Epoch 1902, Loss: 0.4801791310310364, Final Batch Loss: 0.1370864361524582\n",
      "Epoch 1903, Loss: 0.494773730635643, Final Batch Loss: 0.17869210243225098\n",
      "Epoch 1904, Loss: 0.5382738709449768, Final Batch Loss: 0.18129383027553558\n",
      "Epoch 1905, Loss: 0.38493338227272034, Final Batch Loss: 0.07889066636562347\n",
      "Epoch 1906, Loss: 0.44192592799663544, Final Batch Loss: 0.08394260704517365\n",
      "Epoch 1907, Loss: 0.41441692411899567, Final Batch Loss: 0.1093640923500061\n",
      "Epoch 1908, Loss: 0.5594542026519775, Final Batch Loss: 0.22758619487285614\n",
      "Epoch 1909, Loss: 0.45760612189769745, Final Batch Loss: 0.12919002771377563\n",
      "Epoch 1910, Loss: 0.39572950452566147, Final Batch Loss: 0.06482874602079391\n",
      "Epoch 1911, Loss: 0.5951558351516724, Final Batch Loss: 0.26907655596733093\n",
      "Epoch 1912, Loss: 0.3969760537147522, Final Batch Loss: 0.09429293870925903\n",
      "Epoch 1913, Loss: 0.5147230178117752, Final Batch Loss: 0.21040526032447815\n",
      "Epoch 1914, Loss: 0.5306525528430939, Final Batch Loss: 0.17350196838378906\n",
      "Epoch 1915, Loss: 0.4920550063252449, Final Batch Loss: 0.16106824576854706\n",
      "Epoch 1916, Loss: 0.44694341719150543, Final Batch Loss: 0.0952983945608139\n",
      "Epoch 1917, Loss: 0.48995961248874664, Final Batch Loss: 0.1327090561389923\n",
      "Epoch 1918, Loss: 0.42207828909158707, Final Batch Loss: 0.10611511766910553\n",
      "Epoch 1919, Loss: 0.33320482284761965, Final Batch Loss: 0.002068715402856469\n",
      "Epoch 1920, Loss: 0.5313187092542648, Final Batch Loss: 0.18177677690982819\n",
      "Epoch 1921, Loss: 0.5093251764774323, Final Batch Loss: 0.14432306587696075\n",
      "Epoch 1922, Loss: 0.4316208064556122, Final Batch Loss: 0.09512986242771149\n",
      "Epoch 1923, Loss: 0.6696082949638367, Final Batch Loss: 0.32953667640686035\n",
      "Epoch 1924, Loss: 0.41166646033525467, Final Batch Loss: 0.068276546895504\n",
      "Epoch 1925, Loss: 0.3662719242274761, Final Batch Loss: 0.053095605224370956\n",
      "Epoch 1926, Loss: 0.4199102520942688, Final Batch Loss: 0.0712260752916336\n",
      "Epoch 1927, Loss: 0.7832172214984894, Final Batch Loss: 0.4801713526248932\n",
      "Epoch 1928, Loss: 0.4382166936993599, Final Batch Loss: 0.11535712331533432\n",
      "Epoch 1929, Loss: 0.6695193946361542, Final Batch Loss: 0.34292903542518616\n",
      "Epoch 1930, Loss: 0.4363459646701813, Final Batch Loss: 0.08198243379592896\n",
      "Epoch 1931, Loss: 0.5996899455785751, Final Batch Loss: 0.3043674826622009\n",
      "Epoch 1932, Loss: 0.37443185970187187, Final Batch Loss: 0.05148198828101158\n",
      "Epoch 1933, Loss: 0.5513280183076859, Final Batch Loss: 0.17361077666282654\n",
      "Epoch 1934, Loss: 0.3861576244235039, Final Batch Loss: 0.08031698316335678\n",
      "Epoch 1935, Loss: 0.4929959699511528, Final Batch Loss: 0.11258328706026077\n",
      "Epoch 1936, Loss: 0.3834088519215584, Final Batch Loss: 0.07947275787591934\n",
      "Epoch 1937, Loss: 0.587997168302536, Final Batch Loss: 0.24029338359832764\n",
      "Epoch 1938, Loss: 0.40141887962818146, Final Batch Loss: 0.034940436482429504\n",
      "Epoch 1939, Loss: 0.48645220696926117, Final Batch Loss: 0.13340866565704346\n",
      "Epoch 1940, Loss: 0.718626543879509, Final Batch Loss: 0.39588454365730286\n",
      "Epoch 1941, Loss: 0.31804645992815495, Final Batch Loss: 0.005866343155503273\n",
      "Epoch 1942, Loss: 0.35323013737797737, Final Batch Loss: 0.05661182478070259\n",
      "Epoch 1943, Loss: 0.5025807619094849, Final Batch Loss: 0.16534914076328278\n",
      "Epoch 1944, Loss: 0.7309985011816025, Final Batch Loss: 0.40936926007270813\n",
      "Epoch 1945, Loss: 0.43059077858924866, Final Batch Loss: 0.1029486358165741\n",
      "Epoch 1946, Loss: 0.5147589892148972, Final Batch Loss: 0.16593532264232635\n",
      "Epoch 1947, Loss: 0.5943080186843872, Final Batch Loss: 0.2595665156841278\n",
      "Epoch 1948, Loss: 0.32693937048316, Final Batch Loss: 0.020544733852148056\n",
      "Epoch 1949, Loss: 0.43076029419898987, Final Batch Loss: 0.09245525300502777\n",
      "Epoch 1950, Loss: 0.5352858901023865, Final Batch Loss: 0.2176526039838791\n",
      "Epoch 1951, Loss: 0.44066429138183594, Final Batch Loss: 0.12218445539474487\n",
      "Epoch 1952, Loss: 0.3814091458916664, Final Batch Loss: 0.07169576734304428\n",
      "Epoch 1953, Loss: 0.32214938290417194, Final Batch Loss: 0.016459928825497627\n",
      "Epoch 1954, Loss: 0.5939918011426926, Final Batch Loss: 0.2776465117931366\n",
      "Epoch 1955, Loss: 0.5928390324115753, Final Batch Loss: 0.2576598823070526\n",
      "Epoch 1956, Loss: 0.8539135009050369, Final Batch Loss: 0.4734179973602295\n",
      "Epoch 1957, Loss: 0.7534555941820145, Final Batch Loss: 0.36671578884124756\n",
      "Epoch 1958, Loss: 0.4136071875691414, Final Batch Loss: 0.0765676274895668\n",
      "Epoch 1959, Loss: 0.555104449391365, Final Batch Loss: 0.21107721328735352\n",
      "Epoch 1960, Loss: 0.4366155117750168, Final Batch Loss: 0.08925098180770874\n",
      "Epoch 1961, Loss: 0.5413485914468765, Final Batch Loss: 0.19302970170974731\n",
      "Epoch 1962, Loss: 0.4145507514476776, Final Batch Loss: 0.08826947212219238\n",
      "Epoch 1963, Loss: 0.5383917093276978, Final Batch Loss: 0.2610604465007782\n",
      "Epoch 1964, Loss: 0.6005948036909103, Final Batch Loss: 0.23642854392528534\n",
      "Epoch 1965, Loss: 0.4199124947190285, Final Batch Loss: 0.0846245065331459\n",
      "Epoch 1966, Loss: 0.45736901462078094, Final Batch Loss: 0.12652575969696045\n",
      "Epoch 1967, Loss: 0.4724583923816681, Final Batch Loss: 0.13069239258766174\n",
      "Epoch 1968, Loss: 0.4780992567539215, Final Batch Loss: 0.16881144046783447\n",
      "Epoch 1969, Loss: 0.4843612164258957, Final Batch Loss: 0.13930414617061615\n",
      "Epoch 1970, Loss: 0.6978691667318344, Final Batch Loss: 0.4127751290798187\n",
      "Epoch 1971, Loss: 0.6916672736406326, Final Batch Loss: 0.37126561999320984\n",
      "Epoch 1972, Loss: 0.9538827016949654, Final Batch Loss: 0.6243088245391846\n",
      "Epoch 1973, Loss: 0.5377185493707657, Final Batch Loss: 0.1496441513299942\n",
      "Epoch 1974, Loss: 0.9238502085208893, Final Batch Loss: 0.400682657957077\n",
      "Epoch 1975, Loss: 0.5855116844177246, Final Batch Loss: 0.14923472702503204\n",
      "Epoch 1976, Loss: 0.4959508404135704, Final Batch Loss: 0.1094389483332634\n",
      "Epoch 1977, Loss: 0.6257133185863495, Final Batch Loss: 0.21327006816864014\n",
      "Epoch 1978, Loss: 0.6605221927165985, Final Batch Loss: 0.24964694678783417\n",
      "Epoch 1979, Loss: 0.572952538728714, Final Batch Loss: 0.21783976256847382\n",
      "Epoch 1980, Loss: 0.48405174911022186, Final Batch Loss: 0.15662695467472076\n",
      "Epoch 1981, Loss: 0.4290539175271988, Final Batch Loss: 0.11710172891616821\n",
      "Epoch 1982, Loss: 0.3697703257203102, Final Batch Loss: 0.06696207076311111\n",
      "Epoch 1983, Loss: 0.6081537455320358, Final Batch Loss: 0.21191541850566864\n",
      "Epoch 1984, Loss: 0.6913251876831055, Final Batch Loss: 0.17577220499515533\n",
      "Epoch 1985, Loss: 0.6753495186567307, Final Batch Loss: 0.13321347534656525\n",
      "Epoch 1986, Loss: 0.6098048239946365, Final Batch Loss: 0.2508738040924072\n",
      "Epoch 1987, Loss: 0.6204732060432434, Final Batch Loss: 0.2442370504140854\n",
      "Epoch 1988, Loss: 0.5407744497060776, Final Batch Loss: 0.18501698970794678\n",
      "Epoch 1989, Loss: 0.4428833797574043, Final Batch Loss: 0.06789203733205795\n",
      "Epoch 1990, Loss: 0.39160846173763275, Final Batch Loss: 0.08349541574716568\n",
      "Epoch 1991, Loss: 0.46476731449365616, Final Batch Loss: 0.07446347922086716\n",
      "Epoch 1992, Loss: 0.3439692333340645, Final Batch Loss: 0.06765704602003098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1993, Loss: 0.3921538516879082, Final Batch Loss: 0.09692837297916412\n",
      "Epoch 1994, Loss: 0.37867891415953636, Final Batch Loss: 0.03731172904372215\n",
      "Epoch 1995, Loss: 0.7230814844369888, Final Batch Loss: 0.4119158387184143\n",
      "Epoch 1996, Loss: 0.32846444100141525, Final Batch Loss: 0.018062524497509003\n",
      "Epoch 1997, Loss: 0.5237339660525322, Final Batch Loss: 0.10554421693086624\n",
      "Epoch 1998, Loss: 0.5550625026226044, Final Batch Loss: 0.17637385427951813\n",
      "Epoch 1999, Loss: 0.39566047489643097, Final Batch Loss: 0.0809863805770874\n",
      "Epoch 2000, Loss: 0.3714635483920574, Final Batch Loss: 0.046610068529844284\n",
      "Epoch 2001, Loss: 0.4251490831375122, Final Batch Loss: 0.13350051641464233\n",
      "Epoch 2002, Loss: 0.5308963060379028, Final Batch Loss: 0.15117447078227997\n",
      "Epoch 2003, Loss: 0.37656231969594955, Final Batch Loss: 0.07643767446279526\n",
      "Epoch 2004, Loss: 0.46025238186120987, Final Batch Loss: 0.10970810800790787\n",
      "Epoch 2005, Loss: 0.3761900942772627, Final Batch Loss: 0.01613469235599041\n",
      "Epoch 2006, Loss: 0.3747173622250557, Final Batch Loss: 0.08285734802484512\n",
      "Epoch 2007, Loss: 0.49929196387529373, Final Batch Loss: 0.10037896782159805\n",
      "Epoch 2008, Loss: 0.5257041752338409, Final Batch Loss: 0.16584362089633942\n",
      "Epoch 2009, Loss: 0.39731182903051376, Final Batch Loss: 0.06153237074613571\n",
      "Epoch 2010, Loss: 0.43674302101135254, Final Batch Loss: 0.05399520695209503\n",
      "Epoch 2011, Loss: 0.41590798646211624, Final Batch Loss: 0.08951196819543839\n",
      "Epoch 2012, Loss: 0.45369500666856766, Final Batch Loss: 0.10897669941186905\n",
      "Epoch 2013, Loss: 0.38309282064437866, Final Batch Loss: 0.09167748689651489\n",
      "Epoch 2014, Loss: 0.469065859913826, Final Batch Loss: 0.12272046506404877\n",
      "Epoch 2015, Loss: 0.6444702446460724, Final Batch Loss: 0.3075608015060425\n",
      "Epoch 2016, Loss: 0.7973402291536331, Final Batch Loss: 0.451136976480484\n",
      "Epoch 2017, Loss: 0.39774762839078903, Final Batch Loss: 0.06823324412107468\n",
      "Epoch 2018, Loss: 0.458109974861145, Final Batch Loss: 0.12888698279857635\n",
      "Epoch 2019, Loss: 0.6372213512659073, Final Batch Loss: 0.2411918193101883\n",
      "Epoch 2020, Loss: 0.5709288716316223, Final Batch Loss: 0.19708870351314545\n",
      "Epoch 2021, Loss: 0.4203916862607002, Final Batch Loss: 0.10315961390733719\n",
      "Epoch 2022, Loss: 0.41113755851984024, Final Batch Loss: 0.06920481473207474\n",
      "Epoch 2023, Loss: 0.5638480484485626, Final Batch Loss: 0.26381418108940125\n",
      "Epoch 2024, Loss: 0.3992404416203499, Final Batch Loss: 0.09772851318120956\n",
      "Epoch 2025, Loss: 0.6419700980186462, Final Batch Loss: 0.3419834077358246\n",
      "Epoch 2026, Loss: 0.41150469332933426, Final Batch Loss: 0.06754540652036667\n",
      "Epoch 2027, Loss: 0.534293070435524, Final Batch Loss: 0.20265677571296692\n",
      "Epoch 2028, Loss: 0.4639400541782379, Final Batch Loss: 0.15861696004867554\n",
      "Epoch 2029, Loss: 0.34742797166109085, Final Batch Loss: 0.0706193596124649\n",
      "Epoch 2030, Loss: 0.39941367506980896, Final Batch Loss: 0.0840524286031723\n",
      "Epoch 2031, Loss: 0.4248195290565491, Final Batch Loss: 0.1411508321762085\n",
      "Epoch 2032, Loss: 0.5035439878702164, Final Batch Loss: 0.12783282995224\n",
      "Epoch 2033, Loss: 0.44031883031129837, Final Batch Loss: 0.1711980104446411\n",
      "Epoch 2034, Loss: 0.3909362033009529, Final Batch Loss: 0.0881492868065834\n",
      "Epoch 2035, Loss: 0.36761053651571274, Final Batch Loss: 0.08044099062681198\n",
      "Epoch 2036, Loss: 0.42344316840171814, Final Batch Loss: 0.11434642970561981\n",
      "Epoch 2037, Loss: 0.5101599842309952, Final Batch Loss: 0.20880822837352753\n",
      "Epoch 2038, Loss: 0.5051431953907013, Final Batch Loss: 0.19149792194366455\n",
      "Epoch 2039, Loss: 0.3800797164440155, Final Batch Loss: 0.0770973414182663\n",
      "Epoch 2040, Loss: 0.3885742872953415, Final Batch Loss: 0.07513104379177094\n",
      "Epoch 2041, Loss: 0.5112291947007179, Final Batch Loss: 0.20782305300235748\n",
      "Epoch 2042, Loss: 0.3926587626338005, Final Batch Loss: 0.07438645511865616\n",
      "Epoch 2043, Loss: 0.5982744693756104, Final Batch Loss: 0.2373165637254715\n",
      "Epoch 2044, Loss: 0.3793118819594383, Final Batch Loss: 0.06439755111932755\n",
      "Epoch 2045, Loss: 0.6383554190397263, Final Batch Loss: 0.3558202087879181\n",
      "Epoch 2046, Loss: 0.48988378047943115, Final Batch Loss: 0.22238247096538544\n",
      "Epoch 2047, Loss: 0.5956498086452484, Final Batch Loss: 0.24492432177066803\n",
      "Epoch 2048, Loss: 0.4412756711244583, Final Batch Loss: 0.05718092620372772\n",
      "Epoch 2049, Loss: 0.38903845101594925, Final Batch Loss: 0.06823132187128067\n",
      "Epoch 2050, Loss: 0.4478048011660576, Final Batch Loss: 0.10588022321462631\n",
      "Epoch 2051, Loss: 0.4191526621580124, Final Batch Loss: 0.11771947145462036\n",
      "Epoch 2052, Loss: 0.5493161678314209, Final Batch Loss: 0.24203535914421082\n",
      "Epoch 2053, Loss: 0.49397600442171097, Final Batch Loss: 0.08462043851613998\n",
      "Epoch 2054, Loss: 0.5843802690505981, Final Batch Loss: 0.23714476823806763\n",
      "Epoch 2055, Loss: 0.536270797252655, Final Batch Loss: 0.17205071449279785\n",
      "Epoch 2056, Loss: 0.4667357802391052, Final Batch Loss: 0.14439213275909424\n",
      "Epoch 2057, Loss: 0.49614526331424713, Final Batch Loss: 0.10673762857913971\n",
      "Epoch 2058, Loss: 0.5460790991783142, Final Batch Loss: 0.10613292455673218\n",
      "Epoch 2059, Loss: 0.5811124294996262, Final Batch Loss: 0.15341325104236603\n",
      "Epoch 2060, Loss: 0.5497515648603439, Final Batch Loss: 0.2554733157157898\n",
      "Epoch 2061, Loss: 0.6456872075796127, Final Batch Loss: 0.2904822826385498\n",
      "Epoch 2062, Loss: 0.4643567204475403, Final Batch Loss: 0.11302010715007782\n",
      "Epoch 2063, Loss: 0.39994385093450546, Final Batch Loss: 0.06630068272352219\n",
      "Epoch 2064, Loss: 0.8343532904982567, Final Batch Loss: 0.5343303680419922\n",
      "Epoch 2065, Loss: 1.030386060476303, Final Batch Loss: 0.6769208312034607\n",
      "Epoch 2066, Loss: 0.43335720151662827, Final Batch Loss: 0.07719182223081589\n",
      "Epoch 2067, Loss: 1.009827435016632, Final Batch Loss: 0.642412006855011\n",
      "Epoch 2068, Loss: 0.5290645807981491, Final Batch Loss: 0.16375572979450226\n",
      "Epoch 2069, Loss: 0.5464266538619995, Final Batch Loss: 0.2000739574432373\n",
      "Epoch 2070, Loss: 0.38547695707529783, Final Batch Loss: 0.015450711362063885\n",
      "Epoch 2071, Loss: 0.46782681345939636, Final Batch Loss: 0.13826033473014832\n",
      "Epoch 2072, Loss: 0.36413120850920677, Final Batch Loss: 0.026440557092428207\n",
      "Epoch 2073, Loss: 0.3489587679505348, Final Batch Loss: 0.02049214392900467\n",
      "Epoch 2074, Loss: 0.45890169590711594, Final Batch Loss: 0.10971067100763321\n",
      "Epoch 2075, Loss: 0.3944615423679352, Final Batch Loss: 0.0158856064081192\n",
      "Epoch 2076, Loss: 0.6007306277751923, Final Batch Loss: 0.23112979531288147\n",
      "Epoch 2077, Loss: 0.5248160660266876, Final Batch Loss: 0.27361661195755005\n",
      "Epoch 2078, Loss: 0.33182696625590324, Final Batch Loss: 0.03263014182448387\n",
      "Epoch 2079, Loss: 0.4084426909685135, Final Batch Loss: 0.11429913341999054\n",
      "Epoch 2080, Loss: 0.5181312561035156, Final Batch Loss: 0.1889413744211197\n",
      "Epoch 2081, Loss: 0.4042380750179291, Final Batch Loss: 0.07396385073661804\n",
      "Epoch 2082, Loss: 0.46921253204345703, Final Batch Loss: 0.17198292911052704\n",
      "Epoch 2083, Loss: 0.3400168474763632, Final Batch Loss: 0.02106449566781521\n",
      "Epoch 2084, Loss: 0.4255586266517639, Final Batch Loss: 0.08664852380752563\n",
      "Epoch 2085, Loss: 0.7887338101863861, Final Batch Loss: 0.45572009682655334\n",
      "Epoch 2086, Loss: 0.4654950201511383, Final Batch Loss: 0.15862637758255005\n",
      "Epoch 2087, Loss: 0.4464797228574753, Final Batch Loss: 0.14727692306041718\n",
      "Epoch 2088, Loss: 0.38156188651919365, Final Batch Loss: 0.05467532202601433\n",
      "Epoch 2089, Loss: 0.5116738080978394, Final Batch Loss: 0.14006441831588745\n",
      "Epoch 2090, Loss: 0.4401778429746628, Final Batch Loss: 0.14859141409397125\n",
      "Epoch 2091, Loss: 0.4730268120765686, Final Batch Loss: 0.1928381323814392\n",
      "Epoch 2092, Loss: 0.35118082351982594, Final Batch Loss: 0.025667579844594002\n",
      "Epoch 2093, Loss: 0.5237460434436798, Final Batch Loss: 0.20191466808319092\n",
      "Epoch 2094, Loss: 0.4816101938486099, Final Batch Loss: 0.15111227333545685\n",
      "Epoch 2095, Loss: 0.33017243444919586, Final Batch Loss: 0.06431669741868973\n",
      "Epoch 2096, Loss: 0.5101192146539688, Final Batch Loss: 0.16651444137096405\n",
      "Epoch 2097, Loss: 0.3296955693513155, Final Batch Loss: 0.016770856454968452\n",
      "Epoch 2098, Loss: 0.47043396532535553, Final Batch Loss: 0.1510796695947647\n",
      "Epoch 2099, Loss: 0.4177512899041176, Final Batch Loss: 0.14878611266613007\n",
      "Epoch 2100, Loss: 0.3630761206150055, Final Batch Loss: 0.055055469274520874\n",
      "Epoch 2101, Loss: 0.3433986606542021, Final Batch Loss: 0.0027073773089796305\n",
      "Epoch 2102, Loss: 0.41659143939614296, Final Batch Loss: 0.05513295903801918\n",
      "Epoch 2103, Loss: 0.4824571758508682, Final Batch Loss: 0.1725059300661087\n",
      "Epoch 2104, Loss: 0.4794735014438629, Final Batch Loss: 0.15204386413097382\n",
      "Epoch 2105, Loss: 0.7701039910316467, Final Batch Loss: 0.46654680371284485\n",
      "Epoch 2106, Loss: 0.595380887389183, Final Batch Loss: 0.19850490987300873\n",
      "Epoch 2107, Loss: 0.4564388692378998, Final Batch Loss: 0.15344782173633575\n",
      "Epoch 2108, Loss: 0.5059558004140854, Final Batch Loss: 0.19051896035671234\n",
      "Epoch 2109, Loss: 0.5375712364912033, Final Batch Loss: 0.2290925234556198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2110, Loss: 0.4678097292780876, Final Batch Loss: 0.12001524120569229\n",
      "Epoch 2111, Loss: 0.43361352384090424, Final Batch Loss: 0.10534399747848511\n",
      "Epoch 2112, Loss: 0.6438981741666794, Final Batch Loss: 0.31238654255867004\n",
      "Epoch 2113, Loss: 0.38293930143117905, Final Batch Loss: 0.055848248302936554\n",
      "Epoch 2114, Loss: 0.47736334800720215, Final Batch Loss: 0.13179805874824524\n",
      "Epoch 2115, Loss: 0.4074154868721962, Final Batch Loss: 0.09082024544477463\n",
      "Epoch 2116, Loss: 0.41550634056329727, Final Batch Loss: 0.0955464318394661\n",
      "Epoch 2117, Loss: 0.5639386177062988, Final Batch Loss: 0.22958076000213623\n",
      "Epoch 2118, Loss: 0.4814518690109253, Final Batch Loss: 0.13492174446582794\n",
      "Epoch 2119, Loss: 0.5933102816343307, Final Batch Loss: 0.28101539611816406\n",
      "Epoch 2120, Loss: 0.5622803419828415, Final Batch Loss: 0.1768145114183426\n",
      "Epoch 2121, Loss: 0.4852343797683716, Final Batch Loss: 0.15935076773166656\n",
      "Epoch 2122, Loss: 0.505872368812561, Final Batch Loss: 0.21103711426258087\n",
      "Epoch 2123, Loss: 0.42890047281980515, Final Batch Loss: 0.10704822093248367\n",
      "Epoch 2124, Loss: 0.42420703172683716, Final Batch Loss: 0.06853236258029938\n",
      "Epoch 2125, Loss: 0.5415158271789551, Final Batch Loss: 0.23163795471191406\n",
      "Epoch 2126, Loss: 0.6779500469565392, Final Batch Loss: 0.3863920569419861\n",
      "Epoch 2127, Loss: 0.34348001331090927, Final Batch Loss: 0.03507218509912491\n",
      "Epoch 2128, Loss: 0.6224522143602371, Final Batch Loss: 0.3168606162071228\n",
      "Epoch 2129, Loss: 0.5677314549684525, Final Batch Loss: 0.227692648768425\n",
      "Epoch 2130, Loss: 0.7779366970062256, Final Batch Loss: 0.4410398006439209\n",
      "Epoch 2131, Loss: 0.44266025722026825, Final Batch Loss: 0.12937788665294647\n",
      "Epoch 2132, Loss: 0.5120613873004913, Final Batch Loss: 0.16351722180843353\n",
      "Epoch 2133, Loss: 0.5405748337507248, Final Batch Loss: 0.19432218372821808\n",
      "Epoch 2134, Loss: 0.3839056193828583, Final Batch Loss: 0.09358170628547668\n",
      "Epoch 2135, Loss: 0.5120945274829865, Final Batch Loss: 0.19369131326675415\n",
      "Epoch 2136, Loss: 0.44407446682453156, Final Batch Loss: 0.17068719863891602\n",
      "Epoch 2137, Loss: 0.48368507623672485, Final Batch Loss: 0.20194369554519653\n",
      "Epoch 2138, Loss: 0.3467720299959183, Final Batch Loss: 0.06248529255390167\n",
      "Epoch 2139, Loss: 0.64593406021595, Final Batch Loss: 0.2656673192977905\n",
      "Epoch 2140, Loss: 0.41858217120170593, Final Batch Loss: 0.12236064672470093\n",
      "Epoch 2141, Loss: 0.3455437123775482, Final Batch Loss: 0.07022364437580109\n",
      "Epoch 2142, Loss: 0.39497704058885574, Final Batch Loss: 0.06544172018766403\n",
      "Epoch 2143, Loss: 0.41981668025255203, Final Batch Loss: 0.08803495019674301\n",
      "Epoch 2144, Loss: 0.4143938198685646, Final Batch Loss: 0.12246596068143845\n",
      "Epoch 2145, Loss: 0.6783800050616264, Final Batch Loss: 0.43374332785606384\n",
      "Epoch 2146, Loss: 0.36533219553530216, Final Batch Loss: 0.025168949738144875\n",
      "Epoch 2147, Loss: 0.5050691775977612, Final Batch Loss: 0.039587389677762985\n",
      "Epoch 2148, Loss: 0.5008640959858894, Final Batch Loss: 0.08297119289636612\n",
      "Epoch 2149, Loss: 0.6395484805107117, Final Batch Loss: 0.20692019164562225\n",
      "Epoch 2150, Loss: 0.5638958364725113, Final Batch Loss: 0.17083671689033508\n",
      "Epoch 2151, Loss: 0.509248360991478, Final Batch Loss: 0.1982220709323883\n",
      "Epoch 2152, Loss: 0.45264168083667755, Final Batch Loss: 0.12697748839855194\n",
      "Epoch 2153, Loss: 0.5044264644384384, Final Batch Loss: 0.18110622465610504\n",
      "Epoch 2154, Loss: 0.5183191895484924, Final Batch Loss: 0.15038585662841797\n",
      "Epoch 2155, Loss: 0.37112080305814743, Final Batch Loss: 0.05231261998414993\n",
      "Epoch 2156, Loss: 0.3967536762356758, Final Batch Loss: 0.10491923242807388\n",
      "Epoch 2157, Loss: 0.33321813866496086, Final Batch Loss: 0.059306997805833817\n",
      "Epoch 2158, Loss: 0.37444816157221794, Final Batch Loss: 0.04831350967288017\n",
      "Epoch 2159, Loss: 0.4104878269135952, Final Batch Loss: 0.04957353696227074\n",
      "Epoch 2160, Loss: 0.31879233568906784, Final Batch Loss: 0.04202874004840851\n",
      "Epoch 2161, Loss: 0.2902384093031287, Final Batch Loss: 0.010466664098203182\n",
      "Epoch 2162, Loss: 0.5428674221038818, Final Batch Loss: 0.17917825281620026\n",
      "Epoch 2163, Loss: 0.5747785568237305, Final Batch Loss: 0.2209664136171341\n",
      "Epoch 2164, Loss: 0.3774331174790859, Final Batch Loss: 0.05291874334216118\n",
      "Epoch 2165, Loss: 0.46074341237545013, Final Batch Loss: 0.1639663726091385\n",
      "Epoch 2166, Loss: 0.6371650546789169, Final Batch Loss: 0.3197273015975952\n",
      "Epoch 2167, Loss: 0.45569169521331787, Final Batch Loss: 0.13662338256835938\n",
      "Epoch 2168, Loss: 0.5288382321596146, Final Batch Loss: 0.25826969742774963\n",
      "Epoch 2169, Loss: 0.44801265001296997, Final Batch Loss: 0.10868185758590698\n",
      "Epoch 2170, Loss: 0.5854393541812897, Final Batch Loss: 0.23572209477424622\n",
      "Epoch 2171, Loss: 0.37890593335032463, Final Batch Loss: 0.05692730471491814\n",
      "Epoch 2172, Loss: 0.41617001593112946, Final Batch Loss: 0.14084750413894653\n",
      "Epoch 2173, Loss: 0.328471876680851, Final Batch Loss: 0.025026313960552216\n",
      "Epoch 2174, Loss: 0.5533617287874222, Final Batch Loss: 0.23338237404823303\n",
      "Epoch 2175, Loss: 0.550141416490078, Final Batch Loss: 0.26844316720962524\n",
      "Epoch 2176, Loss: 0.5540117621421814, Final Batch Loss: 0.19125761091709137\n",
      "Epoch 2177, Loss: 0.5122962146997452, Final Batch Loss: 0.14725245535373688\n",
      "Epoch 2178, Loss: 0.4965476989746094, Final Batch Loss: 0.20885972678661346\n",
      "Epoch 2179, Loss: 0.5785311162471771, Final Batch Loss: 0.27568569779396057\n",
      "Epoch 2180, Loss: 0.510286346077919, Final Batch Loss: 0.15805138647556305\n",
      "Epoch 2181, Loss: 0.7108765542507172, Final Batch Loss: 0.1769675761461258\n",
      "Epoch 2182, Loss: 0.6366310864686966, Final Batch Loss: 0.3485020697116852\n",
      "Epoch 2183, Loss: 0.3732433933764696, Final Batch Loss: 0.027908610180020332\n",
      "Epoch 2184, Loss: 0.7786185294389725, Final Batch Loss: 0.3683473467826843\n",
      "Epoch 2185, Loss: 0.5927311182022095, Final Batch Loss: 0.24969419836997986\n",
      "Epoch 2186, Loss: 0.34751757327467203, Final Batch Loss: 0.004669272340834141\n",
      "Epoch 2187, Loss: 0.661876305937767, Final Batch Loss: 0.28287073969841003\n",
      "Epoch 2188, Loss: 0.3380988147109747, Final Batch Loss: 0.021002715453505516\n",
      "Epoch 2189, Loss: 0.5833733081817627, Final Batch Loss: 0.2938312590122223\n",
      "Epoch 2190, Loss: 0.5002806186676025, Final Batch Loss: 0.17118439078330994\n",
      "Epoch 2191, Loss: 0.48047125339508057, Final Batch Loss: 0.08807122707366943\n",
      "Epoch 2192, Loss: 0.3737805588170886, Final Batch Loss: 0.013558502309024334\n",
      "Epoch 2193, Loss: 0.4469881057739258, Final Batch Loss: 0.1271282434463501\n",
      "Epoch 2194, Loss: 0.4286140650510788, Final Batch Loss: 0.1137053370475769\n",
      "Epoch 2195, Loss: 0.5032494962215424, Final Batch Loss: 0.16176961362361908\n",
      "Epoch 2196, Loss: 0.5670208632946014, Final Batch Loss: 0.20980632305145264\n",
      "Epoch 2197, Loss: 0.46862463653087616, Final Batch Loss: 0.17123624682426453\n",
      "Epoch 2198, Loss: 0.5438968688249588, Final Batch Loss: 0.23320479691028595\n",
      "Epoch 2199, Loss: 0.4496382549405098, Final Batch Loss: 0.08903754502534866\n",
      "Epoch 2200, Loss: 0.9021262526512146, Final Batch Loss: 0.5125883221626282\n",
      "Epoch 2201, Loss: 0.4261595755815506, Final Batch Loss: 0.10609650611877441\n",
      "Epoch 2202, Loss: 0.5319692194461823, Final Batch Loss: 0.10390281677246094\n",
      "Epoch 2203, Loss: 0.534439891576767, Final Batch Loss: 0.09762944281101227\n",
      "Epoch 2204, Loss: 0.4292759746313095, Final Batch Loss: 0.08931444585323334\n",
      "Epoch 2205, Loss: 0.44001371785998344, Final Batch Loss: 0.05317595228552818\n",
      "Epoch 2206, Loss: 0.6561156660318375, Final Batch Loss: 0.27052974700927734\n",
      "Epoch 2207, Loss: 0.7353144288063049, Final Batch Loss: 0.35100775957107544\n",
      "Epoch 2208, Loss: 0.486583948135376, Final Batch Loss: 0.14925485849380493\n",
      "Epoch 2209, Loss: 0.40318913757801056, Final Batch Loss: 0.0783899575471878\n",
      "Epoch 2210, Loss: 0.6154428124427795, Final Batch Loss: 0.307413250207901\n",
      "Epoch 2211, Loss: 0.4471499025821686, Final Batch Loss: 0.14223293960094452\n",
      "Epoch 2212, Loss: 0.41923829913139343, Final Batch Loss: 0.13309575617313385\n",
      "Epoch 2213, Loss: 0.46434301137924194, Final Batch Loss: 0.1623927354812622\n",
      "Epoch 2214, Loss: 0.3710515610873699, Final Batch Loss: 0.045918580144643784\n",
      "Epoch 2215, Loss: 0.5402414053678513, Final Batch Loss: 0.19263233244419098\n",
      "Epoch 2216, Loss: 0.5166846439242363, Final Batch Loss: 0.16338695585727692\n",
      "Epoch 2217, Loss: 0.5752753056585789, Final Batch Loss: 0.05595089867711067\n",
      "Epoch 2218, Loss: 0.7970715761184692, Final Batch Loss: 0.3791714310646057\n",
      "Epoch 2219, Loss: 0.43908561766147614, Final Batch Loss: 0.06315448880195618\n",
      "Epoch 2220, Loss: 0.5004538148641586, Final Batch Loss: 0.12864607572555542\n",
      "Epoch 2221, Loss: 0.4853478744626045, Final Batch Loss: 0.08257585018873215\n",
      "Epoch 2222, Loss: 0.5407450050115585, Final Batch Loss: 0.18841002881526947\n",
      "Epoch 2223, Loss: 0.4902207553386688, Final Batch Loss: 0.13016611337661743\n",
      "Epoch 2224, Loss: 0.5608621835708618, Final Batch Loss: 0.14708034694194794\n",
      "Epoch 2225, Loss: 0.4546606242656708, Final Batch Loss: 0.1328752487897873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2226, Loss: 0.5664601549506187, Final Batch Loss: 0.2667155861854553\n",
      "Epoch 2227, Loss: 0.5653653889894485, Final Batch Loss: 0.2109791338443756\n",
      "Epoch 2228, Loss: 0.6070996522903442, Final Batch Loss: 0.3206210136413574\n",
      "Epoch 2229, Loss: 0.3794274404644966, Final Batch Loss: 0.01383645087480545\n",
      "Epoch 2230, Loss: 0.5557140558958054, Final Batch Loss: 0.16959284245967865\n",
      "Epoch 2231, Loss: 0.5583905577659607, Final Batch Loss: 0.17538407444953918\n",
      "Epoch 2232, Loss: 0.5696572661399841, Final Batch Loss: 0.2575480341911316\n",
      "Epoch 2233, Loss: 0.6411250829696655, Final Batch Loss: 0.31999120116233826\n",
      "Epoch 2234, Loss: 0.33847708627581596, Final Batch Loss: 0.004654254764318466\n",
      "Epoch 2235, Loss: 0.3986195847392082, Final Batch Loss: 0.09453370422124863\n",
      "Epoch 2236, Loss: 0.43114178627729416, Final Batch Loss: 0.107705257833004\n",
      "Epoch 2237, Loss: 0.3175062760710716, Final Batch Loss: 0.07216378301382065\n",
      "Epoch 2238, Loss: 0.5315838977694511, Final Batch Loss: 0.2751624584197998\n",
      "Epoch 2239, Loss: 0.3581298850476742, Final Batch Loss: 0.05517758056521416\n",
      "Epoch 2240, Loss: 0.678194984793663, Final Batch Loss: 0.3868544399738312\n",
      "Epoch 2241, Loss: 0.45815493166446686, Final Batch Loss: 0.13841284811496735\n",
      "Epoch 2242, Loss: 0.4790932536125183, Final Batch Loss: 0.150071918964386\n",
      "Epoch 2243, Loss: 0.49199821799993515, Final Batch Loss: 0.2160504013299942\n",
      "Epoch 2244, Loss: 0.3459833450615406, Final Batch Loss: 0.05400862172245979\n",
      "Epoch 2245, Loss: 0.5093348249793053, Final Batch Loss: 0.11414045840501785\n",
      "Epoch 2246, Loss: 0.43019959330558777, Final Batch Loss: 0.08418810367584229\n",
      "Epoch 2247, Loss: 0.3550461046397686, Final Batch Loss: 0.056461479514837265\n",
      "Epoch 2248, Loss: 0.5565710142254829, Final Batch Loss: 0.2596425414085388\n",
      "Epoch 2249, Loss: 0.34221871569752693, Final Batch Loss: 0.05726807191967964\n",
      "Epoch 2250, Loss: 0.3627627305686474, Final Batch Loss: 0.05479481443762779\n",
      "Epoch 2251, Loss: 0.5126053392887115, Final Batch Loss: 0.23317444324493408\n",
      "Epoch 2252, Loss: 0.388910137116909, Final Batch Loss: 0.10803783684968948\n",
      "Epoch 2253, Loss: 0.37328116595745087, Final Batch Loss: 0.06729407608509064\n",
      "Epoch 2254, Loss: 0.40935929864645004, Final Batch Loss: 0.11174016445875168\n",
      "Epoch 2255, Loss: 0.3737057223916054, Final Batch Loss: 0.12628667056560516\n",
      "Epoch 2256, Loss: 0.35633085668087006, Final Batch Loss: 0.06277968734502792\n",
      "Epoch 2257, Loss: 0.3652215376496315, Final Batch Loss: 0.06545331329107285\n",
      "Epoch 2258, Loss: 0.4508376121520996, Final Batch Loss: 0.16983617842197418\n",
      "Epoch 2259, Loss: 0.3894750848412514, Final Batch Loss: 0.1002950444817543\n",
      "Epoch 2260, Loss: 0.3459300845861435, Final Batch Loss: 0.07315120100975037\n",
      "Epoch 2261, Loss: 0.36034610867500305, Final Batch Loss: 0.04583646357059479\n",
      "Epoch 2262, Loss: 0.5086438059806824, Final Batch Loss: 0.23920796811580658\n",
      "Epoch 2263, Loss: 0.3175839651376009, Final Batch Loss: 0.025528104975819588\n",
      "Epoch 2264, Loss: 0.4386088103055954, Final Batch Loss: 0.160583958029747\n",
      "Epoch 2265, Loss: 0.4449707865715027, Final Batch Loss: 0.15790069103240967\n",
      "Epoch 2266, Loss: 0.5176037400960922, Final Batch Loss: 0.17981527745723724\n",
      "Epoch 2267, Loss: 0.4267469793558121, Final Batch Loss: 0.14441178739070892\n",
      "Epoch 2268, Loss: 0.45090996474027634, Final Batch Loss: 0.1355697214603424\n",
      "Epoch 2269, Loss: 0.3362969681620598, Final Batch Loss: 0.037657588720321655\n",
      "Epoch 2270, Loss: 0.4598797485232353, Final Batch Loss: 0.1649177223443985\n",
      "Epoch 2271, Loss: 0.38390813022851944, Final Batch Loss: 0.053019531071186066\n",
      "Epoch 2272, Loss: 0.4039599075913429, Final Batch Loss: 0.10456011444330215\n",
      "Epoch 2273, Loss: 0.3456854671239853, Final Batch Loss: 0.05381159484386444\n",
      "Epoch 2274, Loss: 0.403909794986248, Final Batch Loss: 0.10574526339769363\n",
      "Epoch 2275, Loss: 0.4513084441423416, Final Batch Loss: 0.15173424780368805\n",
      "Epoch 2276, Loss: 0.3608887866139412, Final Batch Loss: 0.06592739373445511\n",
      "Epoch 2277, Loss: 0.4162699729204178, Final Batch Loss: 0.13093030452728271\n",
      "Epoch 2278, Loss: 0.4165830910205841, Final Batch Loss: 0.0739206075668335\n",
      "Epoch 2279, Loss: 0.33736175298690796, Final Batch Loss: 0.02975986897945404\n",
      "Epoch 2280, Loss: 0.552088052034378, Final Batch Loss: 0.1936560720205307\n",
      "Epoch 2281, Loss: 0.4756665602326393, Final Batch Loss: 0.22621330618858337\n",
      "Epoch 2282, Loss: 0.6718263924121857, Final Batch Loss: 0.39758995175361633\n",
      "Epoch 2283, Loss: 0.4962282255291939, Final Batch Loss: 0.12190385907888412\n",
      "Epoch 2284, Loss: 0.8057066351175308, Final Batch Loss: 0.38214024901390076\n",
      "Epoch 2285, Loss: 0.5540100783109665, Final Batch Loss: 0.154340922832489\n",
      "Epoch 2286, Loss: 0.6014335006475449, Final Batch Loss: 0.19082409143447876\n",
      "Epoch 2287, Loss: 0.3733084350824356, Final Batch Loss: 0.0641254186630249\n",
      "Epoch 2288, Loss: 0.4164315015077591, Final Batch Loss: 0.04350621998310089\n",
      "Epoch 2289, Loss: 0.4443930834531784, Final Batch Loss: 0.10284072160720825\n",
      "Epoch 2290, Loss: 0.428356871008873, Final Batch Loss: 0.10288436710834503\n",
      "Epoch 2291, Loss: 0.4837137758731842, Final Batch Loss: 0.13538962602615356\n",
      "Epoch 2292, Loss: 0.4404135197401047, Final Batch Loss: 0.10433705151081085\n",
      "Epoch 2293, Loss: 0.581764280796051, Final Batch Loss: 0.22668027877807617\n",
      "Epoch 2294, Loss: 0.4418117552995682, Final Batch Loss: 0.1052803099155426\n",
      "Epoch 2295, Loss: 0.5362713262438774, Final Batch Loss: 0.2837792634963989\n",
      "Epoch 2296, Loss: 0.34576309472322464, Final Batch Loss: 0.043182045221328735\n",
      "Epoch 2297, Loss: 0.46398182213306427, Final Batch Loss: 0.14117394387722015\n",
      "Epoch 2298, Loss: 0.33025089651346207, Final Batch Loss: 0.061242662370204926\n",
      "Epoch 2299, Loss: 0.4242042526602745, Final Batch Loss: 0.12261243909597397\n",
      "Epoch 2300, Loss: 0.5677509754896164, Final Batch Loss: 0.2352508306503296\n",
      "Epoch 2301, Loss: 0.4855099245905876, Final Batch Loss: 0.19340920448303223\n",
      "Epoch 2302, Loss: 0.5783751904964447, Final Batch Loss: 0.24573296308517456\n",
      "Epoch 2303, Loss: 0.4040135443210602, Final Batch Loss: 0.0742633044719696\n",
      "Epoch 2304, Loss: 0.3025711700320244, Final Batch Loss: 0.042418867349624634\n",
      "Epoch 2305, Loss: 0.39290816336870193, Final Batch Loss: 0.12330163270235062\n",
      "Epoch 2306, Loss: 0.3927929326891899, Final Batch Loss: 0.0908009335398674\n",
      "Epoch 2307, Loss: 0.3159699058160186, Final Batch Loss: 0.013894147239625454\n",
      "Epoch 2308, Loss: 0.5657524168491364, Final Batch Loss: 0.274996280670166\n",
      "Epoch 2309, Loss: 0.35735423117876053, Final Batch Loss: 0.08405711501836777\n",
      "Epoch 2310, Loss: 0.4638129025697708, Final Batch Loss: 0.14544706046581268\n",
      "Epoch 2311, Loss: 0.3647763952612877, Final Batch Loss: 0.09095128625631332\n",
      "Epoch 2312, Loss: 0.4523020014166832, Final Batch Loss: 0.07129468768835068\n",
      "Epoch 2313, Loss: 0.42644737660884857, Final Batch Loss: 0.11365850269794464\n",
      "Epoch 2314, Loss: 0.36441778391599655, Final Batch Loss: 0.0667455866932869\n",
      "Epoch 2315, Loss: 0.4439154490828514, Final Batch Loss: 0.17380642890930176\n",
      "Epoch 2316, Loss: 0.4029241055250168, Final Batch Loss: 0.16400189697742462\n",
      "Epoch 2317, Loss: 0.6263767927885056, Final Batch Loss: 0.30677518248558044\n",
      "Epoch 2318, Loss: 0.4661661982536316, Final Batch Loss: 0.12846706807613373\n",
      "Epoch 2319, Loss: 0.3813927173614502, Final Batch Loss: 0.10649873316287994\n",
      "Epoch 2320, Loss: 0.3047592877410352, Final Batch Loss: 0.0063164918683469296\n",
      "Epoch 2321, Loss: 0.3834374137222767, Final Batch Loss: 0.059421125799417496\n",
      "Epoch 2322, Loss: 0.35908249020576477, Final Batch Loss: 0.06453671306371689\n",
      "Epoch 2323, Loss: 0.6044230163097382, Final Batch Loss: 0.26981356739997864\n",
      "Epoch 2324, Loss: 0.5194112360477448, Final Batch Loss: 0.2092348039150238\n",
      "Epoch 2325, Loss: 0.4307037740945816, Final Batch Loss: 0.12342438846826553\n",
      "Epoch 2326, Loss: 0.4772728681564331, Final Batch Loss: 0.1598220318555832\n",
      "Epoch 2327, Loss: 0.5674638897180557, Final Batch Loss: 0.29653018712997437\n",
      "Epoch 2328, Loss: 0.3979202024638653, Final Batch Loss: 0.05145954713225365\n",
      "Epoch 2329, Loss: 0.47531040012836456, Final Batch Loss: 0.11842542886734009\n",
      "Epoch 2330, Loss: 0.44007735699415207, Final Batch Loss: 0.10615568608045578\n",
      "Epoch 2331, Loss: 0.515619158744812, Final Batch Loss: 0.14921309053897858\n",
      "Epoch 2332, Loss: 0.5354614183306694, Final Batch Loss: 0.26034194231033325\n",
      "Epoch 2333, Loss: 0.3415285353548825, Final Batch Loss: 0.005990006495267153\n",
      "Epoch 2334, Loss: 0.4235612526535988, Final Batch Loss: 0.11870037764310837\n",
      "Epoch 2335, Loss: 0.4033764749765396, Final Batch Loss: 0.1231037825345993\n",
      "Epoch 2336, Loss: 0.3965211510658264, Final Batch Loss: 0.06511138379573822\n",
      "Epoch 2337, Loss: 0.46876566112041473, Final Batch Loss: 0.18280617892742157\n",
      "Epoch 2338, Loss: 0.7458714991807938, Final Batch Loss: 0.42662274837493896\n",
      "Epoch 2339, Loss: 0.34729867428541183, Final Batch Loss: 0.07341509312391281\n",
      "Epoch 2340, Loss: 0.7520956099033356, Final Batch Loss: 0.4506124258041382\n",
      "Epoch 2341, Loss: 0.385601744055748, Final Batch Loss: 0.09705570340156555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2342, Loss: 0.5718972384929657, Final Batch Loss: 0.29750606417655945\n",
      "Epoch 2343, Loss: 0.5413250774145126, Final Batch Loss: 0.22009027004241943\n",
      "Epoch 2344, Loss: 0.3977348804473877, Final Batch Loss: 0.06835347414016724\n",
      "Epoch 2345, Loss: 0.5384121090173721, Final Batch Loss: 0.26136693358421326\n",
      "Epoch 2346, Loss: 0.53351791203022, Final Batch Loss: 0.17421391606330872\n",
      "Epoch 2347, Loss: 0.3178463000804186, Final Batch Loss: 0.012515710666775703\n",
      "Epoch 2348, Loss: 0.4834231436252594, Final Batch Loss: 0.20585644245147705\n",
      "Epoch 2349, Loss: 0.42293374985456467, Final Batch Loss: 0.12147810310125351\n",
      "Epoch 2350, Loss: 0.3695272281765938, Final Batch Loss: 0.0802060142159462\n",
      "Epoch 2351, Loss: 0.37379584461450577, Final Batch Loss: 0.06589585542678833\n",
      "Epoch 2352, Loss: 0.276065681129694, Final Batch Loss: 0.00586860254406929\n",
      "Epoch 2353, Loss: 0.40482111275196075, Final Batch Loss: 0.08334636688232422\n",
      "Epoch 2354, Loss: 0.32922641187906265, Final Batch Loss: 0.055380113422870636\n",
      "Epoch 2355, Loss: 0.4438089281320572, Final Batch Loss: 0.13410356640815735\n",
      "Epoch 2356, Loss: 0.44380994141101837, Final Batch Loss: 0.16444703936576843\n",
      "Epoch 2357, Loss: 0.42482370138168335, Final Batch Loss: 0.13661392033100128\n",
      "Epoch 2358, Loss: 0.3213582169264555, Final Batch Loss: 0.03025384061038494\n",
      "Epoch 2359, Loss: 0.3843754157423973, Final Batch Loss: 0.10897394269704819\n",
      "Epoch 2360, Loss: 0.66313137114048, Final Batch Loss: 0.35146111249923706\n",
      "Epoch 2361, Loss: 0.4254123419523239, Final Batch Loss: 0.11083824932575226\n",
      "Epoch 2362, Loss: 0.46952056139707565, Final Batch Loss: 0.20148447155952454\n",
      "Epoch 2363, Loss: 0.43815453350543976, Final Batch Loss: 0.1672474592924118\n",
      "Epoch 2364, Loss: 0.44662486016750336, Final Batch Loss: 0.1361834555864334\n",
      "Epoch 2365, Loss: 0.3807797506451607, Final Batch Loss: 0.143380269408226\n",
      "Epoch 2366, Loss: 0.6472706869244576, Final Batch Loss: 0.38171157240867615\n",
      "Epoch 2367, Loss: 0.3726734071969986, Final Batch Loss: 0.09668976068496704\n",
      "Epoch 2368, Loss: 0.40003497898578644, Final Batch Loss: 0.11715883016586304\n",
      "Epoch 2369, Loss: 0.41882968693971634, Final Batch Loss: 0.1736508309841156\n",
      "Epoch 2370, Loss: 0.4450509175658226, Final Batch Loss: 0.10310222953557968\n",
      "Epoch 2371, Loss: 0.5377470105886459, Final Batch Loss: 0.1790647655725479\n",
      "Epoch 2372, Loss: 0.44511717557907104, Final Batch Loss: 0.1257603019475937\n",
      "Epoch 2373, Loss: 0.4643448144197464, Final Batch Loss: 0.16492637991905212\n",
      "Epoch 2374, Loss: 0.3327041147276759, Final Batch Loss: 0.014877724461257458\n",
      "Epoch 2375, Loss: 0.5062315538525581, Final Batch Loss: 0.10605768114328384\n",
      "Epoch 2376, Loss: 0.4927044212818146, Final Batch Loss: 0.11658622324466705\n",
      "Epoch 2377, Loss: 0.5156616717576981, Final Batch Loss: 0.15854310989379883\n",
      "Epoch 2378, Loss: 0.5963170677423477, Final Batch Loss: 0.21050535142421722\n",
      "Epoch 2379, Loss: 0.44312962889671326, Final Batch Loss: 0.12106436491012573\n",
      "Epoch 2380, Loss: 0.5865030288696289, Final Batch Loss: 0.27980899810791016\n",
      "Epoch 2381, Loss: 0.5060451552271843, Final Batch Loss: 0.1175621822476387\n",
      "Epoch 2382, Loss: 0.5041847079992294, Final Batch Loss: 0.20028239488601685\n",
      "Epoch 2383, Loss: 0.46998389065265656, Final Batch Loss: 0.15414439141750336\n",
      "Epoch 2384, Loss: 0.53589728474617, Final Batch Loss: 0.21204599738121033\n",
      "Epoch 2385, Loss: 0.3603980913758278, Final Batch Loss: 0.09414076060056686\n",
      "Epoch 2386, Loss: 1.0367185324430466, Final Batch Loss: 0.7806046605110168\n",
      "Epoch 2387, Loss: 0.4393787682056427, Final Batch Loss: 0.16848357021808624\n",
      "Epoch 2388, Loss: 0.43182608485221863, Final Batch Loss: 0.153291255235672\n",
      "Epoch 2389, Loss: 0.5554421320557594, Final Batch Loss: 0.2643204629421234\n",
      "Epoch 2390, Loss: 0.481073260307312, Final Batch Loss: 0.21606364846229553\n",
      "Epoch 2391, Loss: 0.42911410331726074, Final Batch Loss: 0.18081451952457428\n",
      "Epoch 2392, Loss: 0.4184601902961731, Final Batch Loss: 0.10961371660232544\n",
      "Epoch 2393, Loss: 0.348915196955204, Final Batch Loss: 0.06634806841611862\n",
      "Epoch 2394, Loss: 0.3438451290130615, Final Batch Loss: 0.07001221925020218\n",
      "Epoch 2395, Loss: 0.281595204025507, Final Batch Loss: 0.054116588085889816\n",
      "Epoch 2396, Loss: 0.3393423929810524, Final Batch Loss: 0.0604371652007103\n",
      "Epoch 2397, Loss: 0.3968663439154625, Final Batch Loss: 0.062415994703769684\n",
      "Epoch 2398, Loss: 0.3572631776332855, Final Batch Loss: 0.08821126818656921\n",
      "Epoch 2399, Loss: 0.4357928931713104, Final Batch Loss: 0.14324279129505157\n",
      "Epoch 2400, Loss: 0.35846177488565445, Final Batch Loss: 0.08449921011924744\n",
      "Epoch 2401, Loss: 0.32996684312820435, Final Batch Loss: 0.060404300689697266\n",
      "Epoch 2402, Loss: 0.3449926823377609, Final Batch Loss: 0.029752135276794434\n",
      "Epoch 2403, Loss: 0.32379763200879097, Final Batch Loss: 0.03409721329808235\n",
      "Epoch 2404, Loss: 0.32393358275294304, Final Batch Loss: 0.03960924968123436\n",
      "Epoch 2405, Loss: 0.40559719502925873, Final Batch Loss: 0.12198279798030853\n",
      "Epoch 2406, Loss: 0.5777720436453819, Final Batch Loss: 0.31584033370018005\n",
      "Epoch 2407, Loss: 0.4580943435430527, Final Batch Loss: 0.20296019315719604\n",
      "Epoch 2408, Loss: 0.4235154166817665, Final Batch Loss: 0.07816586643457413\n",
      "Epoch 2409, Loss: 0.407867468893528, Final Batch Loss: 0.10708238929510117\n",
      "Epoch 2410, Loss: 0.36078180745244026, Final Batch Loss: 0.036493826657533646\n",
      "Epoch 2411, Loss: 0.6658126264810562, Final Batch Loss: 0.23908622562885284\n",
      "Epoch 2412, Loss: 0.5078862756490707, Final Batch Loss: 0.20569472014904022\n",
      "Epoch 2413, Loss: 0.3554850071668625, Final Batch Loss: 0.11602839827537537\n",
      "Epoch 2414, Loss: 0.34009896218776703, Final Batch Loss: 0.03820019215345383\n",
      "Epoch 2415, Loss: 0.5186970308423042, Final Batch Loss: 0.057435043156147\n",
      "Epoch 2416, Loss: 0.6209630817174911, Final Batch Loss: 0.16616597771644592\n",
      "Epoch 2417, Loss: 0.48571567237377167, Final Batch Loss: 0.19941763579845428\n",
      "Epoch 2418, Loss: 0.36054232716560364, Final Batch Loss: 0.07110469043254852\n",
      "Epoch 2419, Loss: 0.4809018522500992, Final Batch Loss: 0.1326257735490799\n",
      "Epoch 2420, Loss: 0.5848806947469711, Final Batch Loss: 0.23862166702747345\n",
      "Epoch 2421, Loss: 0.4644167721271515, Final Batch Loss: 0.13728570938110352\n",
      "Epoch 2422, Loss: 0.4338947534561157, Final Batch Loss: 0.110957071185112\n",
      "Epoch 2423, Loss: 0.5293009430170059, Final Batch Loss: 0.2413291186094284\n",
      "Epoch 2424, Loss: 0.5248841047286987, Final Batch Loss: 0.1587246060371399\n",
      "Epoch 2425, Loss: 0.3651106543838978, Final Batch Loss: 0.055498141795396805\n",
      "Epoch 2426, Loss: 0.49065840244293213, Final Batch Loss: 0.23038241267204285\n",
      "Epoch 2427, Loss: 0.4002877175807953, Final Batch Loss: 0.09142231941223145\n",
      "Epoch 2428, Loss: 0.33197178691625595, Final Batch Loss: 0.054542504251003265\n",
      "Epoch 2429, Loss: 0.36875634640455246, Final Batch Loss: 0.068904809653759\n",
      "Epoch 2430, Loss: 0.47296229749917984, Final Batch Loss: 0.20338229835033417\n",
      "Epoch 2431, Loss: 0.3471345901489258, Final Batch Loss: 0.06416045129299164\n",
      "Epoch 2432, Loss: 0.3116358872503042, Final Batch Loss: 0.007228737697005272\n",
      "Epoch 2433, Loss: 0.3584211729466915, Final Batch Loss: 0.04777311161160469\n",
      "Epoch 2434, Loss: 0.5566506832838058, Final Batch Loss: 0.16657300293445587\n",
      "Epoch 2435, Loss: 0.478542298078537, Final Batch Loss: 0.21014955639839172\n",
      "Epoch 2436, Loss: 0.5475102812051773, Final Batch Loss: 0.27168533205986023\n",
      "Epoch 2437, Loss: 0.3407061733305454, Final Batch Loss: 0.06074781343340874\n",
      "Epoch 2438, Loss: 0.4158480390906334, Final Batch Loss: 0.10244963318109512\n",
      "Epoch 2439, Loss: 0.43768584728240967, Final Batch Loss: 0.18479938805103302\n",
      "Epoch 2440, Loss: 0.3899291008710861, Final Batch Loss: 0.13823844492435455\n",
      "Epoch 2441, Loss: 0.6588495224714279, Final Batch Loss: 0.3444427251815796\n",
      "Epoch 2442, Loss: 0.3383462280035019, Final Batch Loss: 0.05609627813100815\n",
      "Epoch 2443, Loss: 0.44648274779319763, Final Batch Loss: 0.10788233578205109\n",
      "Epoch 2444, Loss: 0.3843633532524109, Final Batch Loss: 0.12096232920885086\n",
      "Epoch 2445, Loss: 0.4796193912625313, Final Batch Loss: 0.2104302942752838\n",
      "Epoch 2446, Loss: 0.36543142050504684, Final Batch Loss: 0.10120747238397598\n",
      "Epoch 2447, Loss: 0.3052940368652344, Final Batch Loss: 0.06809457391500473\n",
      "Epoch 2448, Loss: 0.31138768047094345, Final Batch Loss: 0.06708941608667374\n",
      "Epoch 2449, Loss: 0.26581139862537384, Final Batch Loss: 0.016122207045555115\n",
      "Epoch 2450, Loss: 0.378917932510376, Final Batch Loss: 0.10417622327804565\n",
      "Epoch 2451, Loss: 0.3236495479941368, Final Batch Loss: 0.04323448985815048\n",
      "Epoch 2452, Loss: 0.3558476194739342, Final Batch Loss: 0.08571130037307739\n",
      "Epoch 2453, Loss: 0.37457726895809174, Final Batch Loss: 0.09115926921367645\n",
      "Epoch 2454, Loss: 0.2761905388906598, Final Batch Loss: 0.013104830868542194\n",
      "Epoch 2455, Loss: 0.3348436076194048, Final Batch Loss: 0.028846370056271553\n",
      "Epoch 2456, Loss: 0.5049763172864914, Final Batch Loss: 0.2113516479730606\n",
      "Epoch 2457, Loss: 0.528404526412487, Final Batch Loss: 0.2751849889755249\n",
      "Epoch 2458, Loss: 0.35909487307071686, Final Batch Loss: 0.057649821043014526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2459, Loss: 0.36220254749059677, Final Batch Loss: 0.07562532275915146\n",
      "Epoch 2460, Loss: 0.3548135682940483, Final Batch Loss: 0.08480986207723618\n",
      "Epoch 2461, Loss: 0.46144379675388336, Final Batch Loss: 0.20784635841846466\n",
      "Epoch 2462, Loss: 0.31631727889180183, Final Batch Loss: 0.051321666687726974\n",
      "Epoch 2463, Loss: 0.44830422103405, Final Batch Loss: 0.1392989605665207\n",
      "Epoch 2464, Loss: 0.33057015389204025, Final Batch Loss: 0.09150579571723938\n",
      "Epoch 2465, Loss: 0.3776345029473305, Final Batch Loss: 0.1026778295636177\n",
      "Epoch 2466, Loss: 0.5511394441127777, Final Batch Loss: 0.3018602728843689\n",
      "Epoch 2467, Loss: 0.44077327102422714, Final Batch Loss: 0.14826186001300812\n",
      "Epoch 2468, Loss: 0.348902340978384, Final Batch Loss: 0.052622344344854355\n",
      "Epoch 2469, Loss: 0.4915359169244766, Final Batch Loss: 0.15478748083114624\n",
      "Epoch 2470, Loss: 0.42481957376003265, Final Batch Loss: 0.16355693340301514\n",
      "Epoch 2471, Loss: 0.41715341806411743, Final Batch Loss: 0.12471047043800354\n",
      "Epoch 2472, Loss: 0.3923798128962517, Final Batch Loss: 0.129180908203125\n",
      "Epoch 2473, Loss: 0.3150767460465431, Final Batch Loss: 0.07317153364419937\n",
      "Epoch 2474, Loss: 0.5506415516138077, Final Batch Loss: 0.34112128615379333\n",
      "Epoch 2475, Loss: 0.4041077494621277, Final Batch Loss: 0.1694391965866089\n",
      "Epoch 2476, Loss: 0.3131968639791012, Final Batch Loss: 0.050707194954156876\n",
      "Epoch 2477, Loss: 0.27680907072499394, Final Batch Loss: 0.004568268079310656\n",
      "Epoch 2478, Loss: 0.4718827083706856, Final Batch Loss: 0.21197862923145294\n",
      "Epoch 2479, Loss: 0.41260627657175064, Final Batch Loss: 0.18960927426815033\n",
      "Epoch 2480, Loss: 0.43083586543798447, Final Batch Loss: 0.05807098001241684\n",
      "Epoch 2481, Loss: 0.31869473308324814, Final Batch Loss: 0.05442575365304947\n",
      "Epoch 2482, Loss: 0.314120652154088, Final Batch Loss: 0.029366346076130867\n",
      "Epoch 2483, Loss: 0.63619364798069, Final Batch Loss: 0.2656659185886383\n",
      "Epoch 2484, Loss: 0.44127144664525986, Final Batch Loss: 0.07563772052526474\n",
      "Epoch 2485, Loss: 0.443812258541584, Final Batch Loss: 0.12644414603710175\n",
      "Epoch 2486, Loss: 0.5161653906106949, Final Batch Loss: 0.18455959856510162\n",
      "Epoch 2487, Loss: 0.3826009687036276, Final Batch Loss: 0.021462177857756615\n",
      "Epoch 2488, Loss: 0.453697144985199, Final Batch Loss: 0.15356585383415222\n",
      "Epoch 2489, Loss: 0.7491059526801109, Final Batch Loss: 0.4346505105495453\n",
      "Epoch 2490, Loss: 0.3472735434770584, Final Batch Loss: 0.04011507332324982\n",
      "Epoch 2491, Loss: 0.34476523473858833, Final Batch Loss: 0.028894905000925064\n",
      "Epoch 2492, Loss: 0.4138607233762741, Final Batch Loss: 0.15232984721660614\n",
      "Epoch 2493, Loss: 0.40738170593976974, Final Batch Loss: 0.0997781828045845\n",
      "Epoch 2494, Loss: 0.44220991525799036, Final Batch Loss: 0.01031856331974268\n",
      "Epoch 2495, Loss: 0.40282007306814194, Final Batch Loss: 0.04452980309724808\n",
      "Epoch 2496, Loss: 0.4946998432278633, Final Batch Loss: 0.211741641163826\n",
      "Epoch 2497, Loss: 0.3722558543086052, Final Batch Loss: 0.079081229865551\n",
      "Epoch 2498, Loss: 0.4619690477848053, Final Batch Loss: 0.13325022161006927\n",
      "Epoch 2499, Loss: 0.3816961199045181, Final Batch Loss: 0.10781583935022354\n",
      "Epoch 2500, Loss: 0.468439981341362, Final Batch Loss: 0.19683431088924408\n",
      "Epoch 2501, Loss: 0.5880020558834076, Final Batch Loss: 0.2858907878398895\n",
      "Epoch 2502, Loss: 0.3435526415705681, Final Batch Loss: 0.0727449581027031\n",
      "Epoch 2503, Loss: 0.4523657560348511, Final Batch Loss: 0.14418621361255646\n",
      "Epoch 2504, Loss: 0.35033899545669556, Final Batch Loss: 0.108713299036026\n",
      "Epoch 2505, Loss: 0.33949962444603443, Final Batch Loss: 0.031186016276478767\n",
      "Epoch 2506, Loss: 0.32087478414177895, Final Batch Loss: 0.03748198226094246\n",
      "Epoch 2507, Loss: 0.4516240134835243, Final Batch Loss: 0.16068966686725616\n",
      "Epoch 2508, Loss: 0.3733854591846466, Final Batch Loss: 0.0778503343462944\n",
      "Epoch 2509, Loss: 0.3226366639137268, Final Batch Loss: 0.07618635892868042\n",
      "Epoch 2510, Loss: 0.32285449653863907, Final Batch Loss: 0.03755766898393631\n",
      "Epoch 2511, Loss: 0.3595447838306427, Final Batch Loss: 0.074221670627594\n",
      "Epoch 2512, Loss: 0.6427326500415802, Final Batch Loss: 0.35229483246803284\n",
      "Epoch 2513, Loss: 0.34148702025413513, Final Batch Loss: 0.06022071838378906\n",
      "Epoch 2514, Loss: 0.4391559511423111, Final Batch Loss: 0.16986095905303955\n",
      "Epoch 2515, Loss: 0.40940937399864197, Final Batch Loss: 0.15320074558258057\n",
      "Epoch 2516, Loss: 0.5114650949835777, Final Batch Loss: 0.24013850092887878\n",
      "Epoch 2517, Loss: 0.46374280750751495, Final Batch Loss: 0.18395094573497772\n",
      "Epoch 2518, Loss: 0.6741441413760185, Final Batch Loss: 0.35952460765838623\n",
      "Epoch 2519, Loss: 0.4288496896624565, Final Batch Loss: 0.18090757727622986\n",
      "Epoch 2520, Loss: 0.37714583426713943, Final Batch Loss: 0.042776890099048615\n",
      "Epoch 2521, Loss: 0.4086240157485008, Final Batch Loss: 0.07098918408155441\n",
      "Epoch 2522, Loss: 0.720771849155426, Final Batch Loss: 0.4755202829837799\n",
      "Epoch 2523, Loss: 0.4100790172815323, Final Batch Loss: 0.10473582148551941\n",
      "Epoch 2524, Loss: 0.7998533844947815, Final Batch Loss: 0.4926289916038513\n",
      "Epoch 2525, Loss: 0.4111281931400299, Final Batch Loss: 0.12346134334802628\n",
      "Epoch 2526, Loss: 0.9947485476732254, Final Batch Loss: 0.5880986452102661\n",
      "Epoch 2527, Loss: 0.47825485467910767, Final Batch Loss: 0.09995445609092712\n",
      "Epoch 2528, Loss: 0.7148896902799606, Final Batch Loss: 0.2713695764541626\n",
      "Epoch 2529, Loss: 0.3613078147172928, Final Batch Loss: 0.03231169283390045\n",
      "Epoch 2530, Loss: 0.4103546813130379, Final Batch Loss: 0.04597308486700058\n",
      "Epoch 2531, Loss: 0.5824330747127533, Final Batch Loss: 0.28293272852897644\n",
      "Epoch 2532, Loss: 0.5703142434358597, Final Batch Loss: 0.21109852194786072\n",
      "Epoch 2533, Loss: 0.4326147735118866, Final Batch Loss: 0.1004125326871872\n",
      "Epoch 2534, Loss: 0.49202753603458405, Final Batch Loss: 0.16171421110630035\n",
      "Epoch 2535, Loss: 0.38751356303691864, Final Batch Loss: 0.09103231132030487\n",
      "Epoch 2536, Loss: 0.4160921722650528, Final Batch Loss: 0.12859386205673218\n",
      "Epoch 2537, Loss: 0.6655781120061874, Final Batch Loss: 0.3534809648990631\n",
      "Epoch 2538, Loss: 0.4603893309831619, Final Batch Loss: 0.18311448395252228\n",
      "Epoch 2539, Loss: 0.3271967340260744, Final Batch Loss: 0.005904840305447578\n",
      "Epoch 2540, Loss: 0.47944512963294983, Final Batch Loss: 0.20105715095996857\n",
      "Epoch 2541, Loss: 0.452475905418396, Final Batch Loss: 0.1431320309638977\n",
      "Epoch 2542, Loss: 0.3006972372531891, Final Batch Loss: 0.0026163458824157715\n",
      "Epoch 2543, Loss: 0.4691865146160126, Final Batch Loss: 0.1566237360239029\n",
      "Epoch 2544, Loss: 0.6835915446281433, Final Batch Loss: 0.42046651244163513\n",
      "Epoch 2545, Loss: 0.3351958720013499, Final Batch Loss: 0.010328653268516064\n",
      "Epoch 2546, Loss: 0.4190743565559387, Final Batch Loss: 0.14454896748065948\n",
      "Epoch 2547, Loss: 0.3103203047066927, Final Batch Loss: 0.026044340804219246\n",
      "Epoch 2548, Loss: 0.5201599597930908, Final Batch Loss: 0.23541101813316345\n",
      "Epoch 2549, Loss: 0.320736899971962, Final Batch Loss: 0.07073838263750076\n",
      "Epoch 2550, Loss: 0.41129064559936523, Final Batch Loss: 0.14689816534519196\n",
      "Epoch 2551, Loss: 0.5424108952283859, Final Batch Loss: 0.2321137934923172\n",
      "Epoch 2552, Loss: 0.40924549102783203, Final Batch Loss: 0.15756580233573914\n",
      "Epoch 2553, Loss: 0.38190748542547226, Final Batch Loss: 0.08629278093576431\n",
      "Epoch 2554, Loss: 0.3734108731150627, Final Batch Loss: 0.050721533596515656\n",
      "Epoch 2555, Loss: 0.4203185439109802, Final Batch Loss: 0.15325245261192322\n",
      "Epoch 2556, Loss: 0.3362260088324547, Final Batch Loss: 0.07272958010435104\n",
      "Epoch 2557, Loss: 0.366268515586853, Final Batch Loss: 0.07348918914794922\n",
      "Epoch 2558, Loss: 0.38808853179216385, Final Batch Loss: 0.07698311656713486\n",
      "Epoch 2559, Loss: 0.3352752774953842, Final Batch Loss: 0.03231368958950043\n",
      "Epoch 2560, Loss: 0.40672872960567474, Final Batch Loss: 0.09359562397003174\n",
      "Epoch 2561, Loss: 0.3696405589580536, Final Batch Loss: 0.08293662965297699\n",
      "Epoch 2562, Loss: 0.3397815003991127, Final Batch Loss: 0.06548565626144409\n",
      "Epoch 2563, Loss: 0.5562215819954872, Final Batch Loss: 0.30128535628318787\n",
      "Epoch 2564, Loss: 0.3079570233821869, Final Batch Loss: 0.04886028170585632\n",
      "Epoch 2565, Loss: 0.42554719001054764, Final Batch Loss: 0.031894050538539886\n",
      "Epoch 2566, Loss: 0.3214266672730446, Final Batch Loss: 0.024712182581424713\n",
      "Epoch 2567, Loss: 0.5212041288614273, Final Batch Loss: 0.1591629683971405\n",
      "Epoch 2568, Loss: 0.5012825652956963, Final Batch Loss: 0.09276974946260452\n",
      "Epoch 2569, Loss: 0.32899209856987, Final Batch Loss: 0.019655540585517883\n",
      "Epoch 2570, Loss: 0.5062621384859085, Final Batch Loss: 0.2562839984893799\n",
      "Epoch 2571, Loss: 0.2975674970075488, Final Batch Loss: 0.008022095076739788\n",
      "Epoch 2572, Loss: 0.42196178436279297, Final Batch Loss: 0.09540548920631409\n",
      "Epoch 2573, Loss: 0.5639065653085709, Final Batch Loss: 0.2069915533065796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2574, Loss: 0.541989840567112, Final Batch Loss: 0.2500869631767273\n",
      "Epoch 2575, Loss: 0.6099756509065628, Final Batch Loss: 0.2802659571170807\n",
      "Epoch 2576, Loss: 0.5766105949878693, Final Batch Loss: 0.18398253619670868\n",
      "Epoch 2577, Loss: 0.5584905836731195, Final Batch Loss: 0.026501784101128578\n",
      "Epoch 2578, Loss: 0.4962911307811737, Final Batch Loss: 0.1394548863172531\n",
      "Epoch 2579, Loss: 0.3981647193431854, Final Batch Loss: 0.03025101125240326\n",
      "Epoch 2580, Loss: 0.5413602739572525, Final Batch Loss: 0.21604159474372864\n",
      "Epoch 2581, Loss: 0.6679289638996124, Final Batch Loss: 0.3412272334098816\n",
      "Epoch 2582, Loss: 0.5023950934410095, Final Batch Loss: 0.1419925093650818\n",
      "Epoch 2583, Loss: 0.5063291788101196, Final Batch Loss: 0.14033383131027222\n",
      "Epoch 2584, Loss: 0.4685470461845398, Final Batch Loss: 0.12040551006793976\n",
      "Epoch 2585, Loss: 0.4058607816696167, Final Batch Loss: 0.08354213833808899\n",
      "Epoch 2586, Loss: 0.39320114254951477, Final Batch Loss: 0.08954319357872009\n",
      "Epoch 2587, Loss: 0.5349660366773605, Final Batch Loss: 0.17218343913555145\n",
      "Epoch 2588, Loss: 0.4749697893857956, Final Batch Loss: 0.13253037631511688\n",
      "Epoch 2589, Loss: 0.4098045602440834, Final Batch Loss: 0.10053489357233047\n",
      "Epoch 2590, Loss: 0.3531573750078678, Final Batch Loss: 0.05174737051129341\n",
      "Epoch 2591, Loss: 0.3662886247038841, Final Batch Loss: 0.1171332523226738\n",
      "Epoch 2592, Loss: 0.4545154348015785, Final Batch Loss: 0.16098730266094208\n",
      "Epoch 2593, Loss: 0.5396716967225075, Final Batch Loss: 0.25772824883461\n",
      "Epoch 2594, Loss: 0.3700839728116989, Final Batch Loss: 0.08445273339748383\n",
      "Epoch 2595, Loss: 0.4359585717320442, Final Batch Loss: 0.1512204110622406\n",
      "Epoch 2596, Loss: 0.39243920147418976, Final Batch Loss: 0.1461886167526245\n",
      "Epoch 2597, Loss: 0.3335251435637474, Final Batch Loss: 0.03540632128715515\n",
      "Epoch 2598, Loss: 0.3119858391582966, Final Batch Loss: 0.04665784910321236\n",
      "Epoch 2599, Loss: 0.5805810391902924, Final Batch Loss: 0.2996354103088379\n",
      "Epoch 2600, Loss: 0.30908023938536644, Final Batch Loss: 0.03173090144991875\n",
      "Epoch 2601, Loss: 0.6758865565061569, Final Batch Loss: 0.3605400025844574\n",
      "Epoch 2602, Loss: 0.4250660724937916, Final Batch Loss: 0.05797213688492775\n",
      "Epoch 2603, Loss: 0.28432462364435196, Final Batch Loss: 0.05433129519224167\n",
      "Epoch 2604, Loss: 0.46873123198747635, Final Batch Loss: 0.20975682139396667\n",
      "Epoch 2605, Loss: 0.38219571858644485, Final Batch Loss: 0.062043435871601105\n",
      "Epoch 2606, Loss: 0.4065440222620964, Final Batch Loss: 0.09820476919412613\n",
      "Epoch 2607, Loss: 0.4282335788011551, Final Batch Loss: 0.1507146805524826\n",
      "Epoch 2608, Loss: 0.540066584944725, Final Batch Loss: 0.27209237217903137\n",
      "Epoch 2609, Loss: 0.42290447652339935, Final Batch Loss: 0.08331210911273956\n",
      "Epoch 2610, Loss: 0.42620478570461273, Final Batch Loss: 0.19278819859027863\n",
      "Epoch 2611, Loss: 0.2660826500505209, Final Batch Loss: 0.024759819731116295\n",
      "Epoch 2612, Loss: 0.30867327749729156, Final Batch Loss: 0.04748396575450897\n",
      "Epoch 2613, Loss: 0.31905677542090416, Final Batch Loss: 0.04320013150572777\n",
      "Epoch 2614, Loss: 0.6091666966676712, Final Batch Loss: 0.3250873386859894\n",
      "Epoch 2615, Loss: 0.4810262769460678, Final Batch Loss: 0.2249177098274231\n",
      "Epoch 2616, Loss: 0.4880794733762741, Final Batch Loss: 0.2657221257686615\n",
      "Epoch 2617, Loss: 0.3952758312225342, Final Batch Loss: 0.0835653692483902\n",
      "Epoch 2618, Loss: 0.35851117968559265, Final Batch Loss: 0.136987566947937\n",
      "Epoch 2619, Loss: 0.36726024001836777, Final Batch Loss: 0.12084388732910156\n",
      "Epoch 2620, Loss: 0.6019399091601372, Final Batch Loss: 0.3372493386268616\n",
      "Epoch 2621, Loss: 0.33058954402804375, Final Batch Loss: 0.051657725125551224\n",
      "Epoch 2622, Loss: 0.30725930258631706, Final Batch Loss: 0.02644358202815056\n",
      "Epoch 2623, Loss: 0.5779776722192764, Final Batch Loss: 0.3120321035385132\n",
      "Epoch 2624, Loss: 0.3479042537510395, Final Batch Loss: 0.03981329873204231\n",
      "Epoch 2625, Loss: 0.3572911322116852, Final Batch Loss: 0.0985950455069542\n",
      "Epoch 2626, Loss: 0.33608849346637726, Final Batch Loss: 0.07668223977088928\n",
      "Epoch 2627, Loss: 0.43878331035375595, Final Batch Loss: 0.18903674185276031\n",
      "Epoch 2628, Loss: 0.3238171115517616, Final Batch Loss: 0.0449909046292305\n",
      "Epoch 2629, Loss: 0.4677402302622795, Final Batch Loss: 0.08456309884786606\n",
      "Epoch 2630, Loss: 0.3652006462216377, Final Batch Loss: 0.10346537083387375\n",
      "Epoch 2631, Loss: 0.2901395782828331, Final Batch Loss: 0.03566325455904007\n",
      "Epoch 2632, Loss: 0.32207823544740677, Final Batch Loss: 0.06634209305047989\n",
      "Epoch 2633, Loss: 0.2880624644458294, Final Batch Loss: 0.030721548944711685\n",
      "Epoch 2634, Loss: 0.5259580314159393, Final Batch Loss: 0.29745030403137207\n",
      "Epoch 2635, Loss: 0.4113616421818733, Final Batch Loss: 0.19191420078277588\n",
      "Epoch 2636, Loss: 0.2294455375522375, Final Batch Loss: 0.01885194145143032\n",
      "Epoch 2637, Loss: 0.47139886021614075, Final Batch Loss: 0.16845440864562988\n",
      "Epoch 2638, Loss: 0.3042808063328266, Final Batch Loss: 0.014886278659105301\n",
      "Epoch 2639, Loss: 0.34830667823553085, Final Batch Loss: 0.04237418621778488\n",
      "Epoch 2640, Loss: 0.5162141025066376, Final Batch Loss: 0.2370944768190384\n",
      "Epoch 2641, Loss: 0.4845479354262352, Final Batch Loss: 0.23283176124095917\n",
      "Epoch 2642, Loss: 0.3055424205958843, Final Batch Loss: 0.030303295701742172\n",
      "Epoch 2643, Loss: 0.34821944683790207, Final Batch Loss: 0.07371515780687332\n",
      "Epoch 2644, Loss: 0.33631037548184395, Final Batch Loss: 0.04656874015927315\n",
      "Epoch 2645, Loss: 0.4358291029930115, Final Batch Loss: 0.1191222295165062\n",
      "Epoch 2646, Loss: 0.3548160120844841, Final Batch Loss: 0.11823195964097977\n",
      "Epoch 2647, Loss: 0.24929312244057655, Final Batch Loss: 0.035555142909288406\n",
      "Epoch 2648, Loss: 0.2809861171990633, Final Batch Loss: 0.025997119024395943\n",
      "Epoch 2649, Loss: 0.4409843683242798, Final Batch Loss: 0.19307808578014374\n",
      "Epoch 2650, Loss: 0.31328824162483215, Final Batch Loss: 0.04064732789993286\n",
      "Epoch 2651, Loss: 0.34696949273347855, Final Batch Loss: 0.10478080809116364\n",
      "Epoch 2652, Loss: 0.2875395193696022, Final Batch Loss: 0.042052388191223145\n",
      "Epoch 2653, Loss: 0.3231884315609932, Final Batch Loss: 0.08183687180280685\n",
      "Epoch 2654, Loss: 0.27383051067590714, Final Batch Loss: 0.015360914170742035\n",
      "Epoch 2655, Loss: 0.385729044675827, Final Batch Loss: 0.09963268041610718\n",
      "Epoch 2656, Loss: 0.41227856278419495, Final Batch Loss: 0.13945266604423523\n",
      "Epoch 2657, Loss: 0.6991501301527023, Final Batch Loss: 0.4683893620967865\n",
      "Epoch 2658, Loss: 0.3519430384039879, Final Batch Loss: 0.1383795142173767\n",
      "Epoch 2659, Loss: 0.4053244963288307, Final Batch Loss: 0.1570766419172287\n",
      "Epoch 2660, Loss: 0.2708904203027487, Final Batch Loss: 0.022518282756209373\n",
      "Epoch 2661, Loss: 0.4439201056957245, Final Batch Loss: 0.11240480840206146\n",
      "Epoch 2662, Loss: 0.29886793717741966, Final Batch Loss: 0.053379837423563004\n",
      "Epoch 2663, Loss: 0.31469663977622986, Final Batch Loss: 0.08818461000919342\n",
      "Epoch 2664, Loss: 0.26159841381013393, Final Batch Loss: 0.02053532563149929\n",
      "Epoch 2665, Loss: 0.2915782630443573, Final Batch Loss: 0.06907577812671661\n",
      "Epoch 2666, Loss: 0.6429222822189331, Final Batch Loss: 0.35658738017082214\n",
      "Epoch 2667, Loss: 0.49871188402175903, Final Batch Loss: 0.23575624823570251\n",
      "Epoch 2668, Loss: 0.2927566170692444, Final Batch Loss: 0.061318524181842804\n",
      "Epoch 2669, Loss: 0.46725938469171524, Final Batch Loss: 0.21519051492214203\n",
      "Epoch 2670, Loss: 0.3198791444301605, Final Batch Loss: 0.05407126247882843\n",
      "Epoch 2671, Loss: 0.32237638160586357, Final Batch Loss: 0.0489361397922039\n",
      "Epoch 2672, Loss: 0.29902392625808716, Final Batch Loss: 0.07578250765800476\n",
      "Epoch 2673, Loss: 0.3005819618701935, Final Batch Loss: 0.07791067659854889\n",
      "Epoch 2674, Loss: 0.2958716079592705, Final Batch Loss: 0.06184232980012894\n",
      "Epoch 2675, Loss: 0.2921483814716339, Final Batch Loss: 0.06095536798238754\n",
      "Epoch 2676, Loss: 0.4129532724618912, Final Batch Loss: 0.15016107261180878\n",
      "Epoch 2677, Loss: 0.45173874497413635, Final Batch Loss: 0.15087002515792847\n",
      "Epoch 2678, Loss: 0.2718646079301834, Final Batch Loss: 0.014668107032775879\n",
      "Epoch 2679, Loss: 0.30328596383333206, Final Batch Loss: 0.05633087456226349\n",
      "Epoch 2680, Loss: 0.2893197163939476, Final Batch Loss: 0.04191530495882034\n",
      "Epoch 2681, Loss: 0.27217257767915726, Final Batch Loss: 0.03644585609436035\n",
      "Epoch 2682, Loss: 0.4808160215616226, Final Batch Loss: 0.19828057289123535\n",
      "Epoch 2683, Loss: 0.2527491971850395, Final Batch Loss: 0.034835852682590485\n",
      "Epoch 2684, Loss: 0.24250189121812582, Final Batch Loss: 0.008339515887200832\n",
      "Epoch 2685, Loss: 0.41165610402822495, Final Batch Loss: 0.1588822454214096\n",
      "Epoch 2686, Loss: 0.30660255625844, Final Batch Loss: 0.05667315796017647\n",
      "Epoch 2687, Loss: 0.4711720049381256, Final Batch Loss: 0.20290470123291016\n",
      "Epoch 2688, Loss: 0.38256534934043884, Final Batch Loss: 0.11405736207962036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2689, Loss: 0.3950093388557434, Final Batch Loss: 0.1654019057750702\n",
      "Epoch 2690, Loss: 0.35293401777744293, Final Batch Loss: 0.04915866255760193\n",
      "Epoch 2691, Loss: 0.5206290930509567, Final Batch Loss: 0.2804074287414551\n",
      "Epoch 2692, Loss: 0.5139672309160233, Final Batch Loss: 0.261889785528183\n",
      "Epoch 2693, Loss: 0.2697650510817766, Final Batch Loss: 0.020724931731820107\n",
      "Epoch 2694, Loss: 0.35069505870342255, Final Batch Loss: 0.1178322359919548\n",
      "Epoch 2695, Loss: 0.6060387045145035, Final Batch Loss: 0.34571316838264465\n",
      "Epoch 2696, Loss: 0.3094603642821312, Final Batch Loss: 0.07321784645318985\n",
      "Epoch 2697, Loss: 0.41970282047986984, Final Batch Loss: 0.18494507670402527\n",
      "Epoch 2698, Loss: 0.5703146755695343, Final Batch Loss: 0.2781698703765869\n",
      "Epoch 2699, Loss: 0.29013006016612053, Final Batch Loss: 0.04509621486067772\n",
      "Epoch 2700, Loss: 0.42598482966423035, Final Batch Loss: 0.1582772135734558\n",
      "Epoch 2701, Loss: 0.40282078087329865, Final Batch Loss: 0.10015026479959488\n",
      "Epoch 2702, Loss: 0.327567994594574, Final Batch Loss: 0.04926881194114685\n",
      "Epoch 2703, Loss: 0.4333503916859627, Final Batch Loss: 0.16534072160720825\n",
      "Epoch 2704, Loss: 0.4394432306289673, Final Batch Loss: 0.18581882119178772\n",
      "Epoch 2705, Loss: 0.3685554265975952, Final Batch Loss: 0.11085662245750427\n",
      "Epoch 2706, Loss: 0.5155401900410652, Final Batch Loss: 0.2540002763271332\n",
      "Epoch 2707, Loss: 0.39144933968782425, Final Batch Loss: 0.11585096269845963\n",
      "Epoch 2708, Loss: 0.6215280741453171, Final Batch Loss: 0.29206499457359314\n",
      "Epoch 2709, Loss: 0.3174401596188545, Final Batch Loss: 0.033551596105098724\n",
      "Epoch 2710, Loss: 0.30547909811139107, Final Batch Loss: 0.04890928789973259\n",
      "Epoch 2711, Loss: 0.4504707008600235, Final Batch Loss: 0.20155026018619537\n",
      "Epoch 2712, Loss: 0.43197881430387497, Final Batch Loss: 0.19512072205543518\n",
      "Epoch 2713, Loss: 0.3636583909392357, Final Batch Loss: 0.12061090022325516\n",
      "Epoch 2714, Loss: 0.3606833815574646, Final Batch Loss: 0.09648019820451736\n",
      "Epoch 2715, Loss: 0.5028175786137581, Final Batch Loss: 0.262286514043808\n",
      "Epoch 2716, Loss: 0.4564606547355652, Final Batch Loss: 0.17117655277252197\n",
      "Epoch 2717, Loss: 0.30187413841485977, Final Batch Loss: 0.02354874461889267\n",
      "Epoch 2718, Loss: 0.4224589914083481, Final Batch Loss: 0.1633412092924118\n",
      "Epoch 2719, Loss: 0.5028155967593193, Final Batch Loss: 0.23269616067409515\n",
      "Epoch 2720, Loss: 0.3253564164042473, Final Batch Loss: 0.08159580081701279\n",
      "Epoch 2721, Loss: 0.41644667088985443, Final Batch Loss: 0.17614351212978363\n",
      "Epoch 2722, Loss: 0.380134642124176, Final Batch Loss: 0.09628322720527649\n",
      "Epoch 2723, Loss: 0.4380137696862221, Final Batch Loss: 0.17923562228679657\n",
      "Epoch 2724, Loss: 0.6336599215865135, Final Batch Loss: 0.336678683757782\n",
      "Epoch 2725, Loss: 0.39986298978328705, Final Batch Loss: 0.17018379271030426\n",
      "Epoch 2726, Loss: 0.4518609344959259, Final Batch Loss: 0.18267372250556946\n",
      "Epoch 2727, Loss: 0.5358462333679199, Final Batch Loss: 0.19572116434574127\n",
      "Epoch 2728, Loss: 0.49421754479408264, Final Batch Loss: 0.2116411179304123\n",
      "Epoch 2729, Loss: 0.3200702704489231, Final Batch Loss: 0.019210312515497208\n",
      "Epoch 2730, Loss: 0.5667214691638947, Final Batch Loss: 0.19375692307949066\n",
      "Epoch 2731, Loss: 0.3784358873963356, Final Batch Loss: 0.15847992897033691\n",
      "Epoch 2732, Loss: 0.5656675696372986, Final Batch Loss: 0.2606566548347473\n",
      "Epoch 2733, Loss: 0.4253621846437454, Final Batch Loss: 0.15886951982975006\n",
      "Epoch 2734, Loss: 0.7714997231960297, Final Batch Loss: 0.492245614528656\n",
      "Epoch 2735, Loss: 0.37222377955913544, Final Batch Loss: 0.0930580347776413\n",
      "Epoch 2736, Loss: 0.37604328617453575, Final Batch Loss: 0.06146242842078209\n",
      "Epoch 2737, Loss: 0.5116409212350845, Final Batch Loss: 0.23979134857654572\n",
      "Epoch 2738, Loss: 0.3542252965271473, Final Batch Loss: 0.043341655284166336\n",
      "Epoch 2739, Loss: 0.4191751629114151, Final Batch Loss: 0.1408267766237259\n",
      "Epoch 2740, Loss: 0.3755185976624489, Final Batch Loss: 0.1073647290468216\n",
      "Epoch 2741, Loss: 0.5779886618256569, Final Batch Loss: 0.3452650010585785\n",
      "Epoch 2742, Loss: 0.36626166105270386, Final Batch Loss: 0.12439382821321487\n",
      "Epoch 2743, Loss: 0.41993606090545654, Final Batch Loss: 0.1504538655281067\n",
      "Epoch 2744, Loss: 0.3796920105814934, Final Batch Loss: 0.08137469738721848\n",
      "Epoch 2745, Loss: 0.3422127664089203, Final Batch Loss: 0.04723271727561951\n",
      "Epoch 2746, Loss: 0.4380599781870842, Final Batch Loss: 0.22751356661319733\n",
      "Epoch 2747, Loss: 0.32009074091911316, Final Batch Loss: 0.054824501276016235\n",
      "Epoch 2748, Loss: 0.46118443459272385, Final Batch Loss: 0.1269550770521164\n",
      "Epoch 2749, Loss: 0.3987679034471512, Final Batch Loss: 0.15794405341148376\n",
      "Epoch 2750, Loss: 0.3407604917883873, Final Batch Loss: 0.06137891113758087\n",
      "Epoch 2751, Loss: 0.5023424997925758, Final Batch Loss: 0.23760248720645905\n",
      "Epoch 2752, Loss: 0.5371682345867157, Final Batch Loss: 0.23199158906936646\n",
      "Epoch 2753, Loss: 0.45216453820466995, Final Batch Loss: 0.18406200408935547\n",
      "Epoch 2754, Loss: 0.34603244066238403, Final Batch Loss: 0.09559252858161926\n",
      "Epoch 2755, Loss: 0.41435834020376205, Final Batch Loss: 0.09659165889024734\n",
      "Epoch 2756, Loss: 0.3461211398243904, Final Batch Loss: 0.08081506937742233\n",
      "Epoch 2757, Loss: 0.49776698648929596, Final Batch Loss: 0.14515283703804016\n",
      "Epoch 2758, Loss: 0.31562624871730804, Final Batch Loss: 0.0577462837100029\n",
      "Epoch 2759, Loss: 0.3247932568192482, Final Batch Loss: 0.08185034990310669\n",
      "Epoch 2760, Loss: 0.3018673285841942, Final Batch Loss: 0.03682229667901993\n",
      "Epoch 2761, Loss: 0.3546188473701477, Final Batch Loss: 0.06746868789196014\n",
      "Epoch 2762, Loss: 0.2793922135606408, Final Batch Loss: 0.008812145330011845\n",
      "Epoch 2763, Loss: 0.3565547689795494, Final Batch Loss: 0.08302180469036102\n",
      "Epoch 2764, Loss: 0.334933876991272, Final Batch Loss: 0.07548744231462479\n",
      "Epoch 2765, Loss: 0.5091449618339539, Final Batch Loss: 0.1556292474269867\n",
      "Epoch 2766, Loss: 0.45498454570770264, Final Batch Loss: 0.17176814377307892\n",
      "Epoch 2767, Loss: 0.33874421566724777, Final Batch Loss: 0.10203836113214493\n",
      "Epoch 2768, Loss: 0.6215596497058868, Final Batch Loss: 0.3441144526004791\n",
      "Epoch 2769, Loss: 0.3809787929058075, Final Batch Loss: 0.07783003151416779\n",
      "Epoch 2770, Loss: 0.45725351572036743, Final Batch Loss: 0.17387497425079346\n",
      "Epoch 2771, Loss: 0.5596911981701851, Final Batch Loss: 0.27818766236305237\n",
      "Epoch 2772, Loss: 0.3834208548069, Final Batch Loss: 0.10037267208099365\n",
      "Epoch 2773, Loss: 0.3720732405781746, Final Batch Loss: 0.13097259402275085\n",
      "Epoch 2774, Loss: 0.5559388548135757, Final Batch Loss: 0.2947503924369812\n",
      "Epoch 2775, Loss: 0.7691886201500893, Final Batch Loss: 0.5052001476287842\n",
      "Epoch 2776, Loss: 0.5901380330324173, Final Batch Loss: 0.1705317348241806\n",
      "Epoch 2777, Loss: 0.5852307230234146, Final Batch Loss: 0.27338990569114685\n",
      "Epoch 2778, Loss: 0.44901663064956665, Final Batch Loss: 0.16201335191726685\n",
      "Epoch 2779, Loss: 0.6470573544502258, Final Batch Loss: 0.27333030104637146\n",
      "Epoch 2780, Loss: 0.8039039671421051, Final Batch Loss: 0.39164867997169495\n",
      "Epoch 2781, Loss: 0.5023839175701141, Final Batch Loss: 0.173996239900589\n",
      "Epoch 2782, Loss: 0.6198375821113586, Final Batch Loss: 0.28616413474082947\n",
      "Epoch 2783, Loss: 0.3425789987668395, Final Batch Loss: 0.011253750883042812\n",
      "Epoch 2784, Loss: 0.5820105075836182, Final Batch Loss: 0.2379215955734253\n",
      "Epoch 2785, Loss: 0.6594733893871307, Final Batch Loss: 0.3293348550796509\n",
      "Epoch 2786, Loss: 0.3966769427061081, Final Batch Loss: 0.1137026995420456\n",
      "Epoch 2787, Loss: 0.4042568653821945, Final Batch Loss: 0.0917060375213623\n",
      "Epoch 2788, Loss: 0.3791813626885414, Final Batch Loss: 0.11691773682832718\n",
      "Epoch 2789, Loss: 0.37308909744024277, Final Batch Loss: 0.06505174189805984\n",
      "Epoch 2790, Loss: 0.37151291221380234, Final Batch Loss: 0.06379417330026627\n",
      "Epoch 2791, Loss: 0.4270947724580765, Final Batch Loss: 0.12050746381282806\n",
      "Epoch 2792, Loss: 0.5100478902459145, Final Batch Loss: 0.25230252742767334\n",
      "Epoch 2793, Loss: 0.29944012174382806, Final Batch Loss: 0.007347142789512873\n",
      "Epoch 2794, Loss: 0.27611991204321384, Final Batch Loss: 0.02525452710688114\n",
      "Epoch 2795, Loss: 0.26201217249035835, Final Batch Loss: 0.02746756747364998\n",
      "Epoch 2796, Loss: 0.35916076600551605, Final Batch Loss: 0.07711093872785568\n",
      "Epoch 2797, Loss: 0.4195003882050514, Final Batch Loss: 0.18001121282577515\n",
      "Epoch 2798, Loss: 0.3703747019171715, Final Batch Loss: 0.10046599060297012\n",
      "Epoch 2799, Loss: 0.4288647472858429, Final Batch Loss: 0.20083527266979218\n",
      "Epoch 2800, Loss: 0.35924258455634117, Final Batch Loss: 0.05878692492842674\n",
      "Epoch 2801, Loss: 0.24929447565227747, Final Batch Loss: 0.009588965214788914\n",
      "Epoch 2802, Loss: 0.38285626471042633, Final Batch Loss: 0.10338832437992096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2803, Loss: 0.5971189141273499, Final Batch Loss: 0.27594926953315735\n",
      "Epoch 2804, Loss: 0.3940463811159134, Final Batch Loss: 0.0869612991809845\n",
      "Epoch 2805, Loss: 0.4804503247141838, Final Batch Loss: 0.24808678030967712\n",
      "Epoch 2806, Loss: 0.3019813671708107, Final Batch Loss: 0.054022520780563354\n",
      "Epoch 2807, Loss: 0.33912786841392517, Final Batch Loss: 0.08321473747491837\n",
      "Epoch 2808, Loss: 0.3920881599187851, Final Batch Loss: 0.07653570175170898\n",
      "Epoch 2809, Loss: 0.5558378994464874, Final Batch Loss: 0.33578333258628845\n",
      "Epoch 2810, Loss: 0.374431774020195, Final Batch Loss: 0.10778872668743134\n",
      "Epoch 2811, Loss: 0.24474315531551838, Final Batch Loss: 0.006382884457707405\n",
      "Epoch 2812, Loss: 0.6137332320213318, Final Batch Loss: 0.3309684991836548\n",
      "Epoch 2813, Loss: 0.41276268661022186, Final Batch Loss: 0.1371503323316574\n",
      "Epoch 2814, Loss: 0.46496719121932983, Final Batch Loss: 0.18176612257957458\n",
      "Epoch 2815, Loss: 0.3198336064815521, Final Batch Loss: 0.08758331835269928\n",
      "Epoch 2816, Loss: 0.35787104070186615, Final Batch Loss: 0.08352626115083694\n",
      "Epoch 2817, Loss: 0.2610347745940089, Final Batch Loss: 0.008365067653357983\n",
      "Epoch 2818, Loss: 0.311643086373806, Final Batch Loss: 0.11835294961929321\n",
      "Epoch 2819, Loss: 0.2366936095058918, Final Batch Loss: 0.03661764785647392\n",
      "Epoch 2820, Loss: 0.4854056164622307, Final Batch Loss: 0.2713838219642639\n",
      "Epoch 2821, Loss: 0.351182222366333, Final Batch Loss: 0.06765712797641754\n",
      "Epoch 2822, Loss: 0.3768467605113983, Final Batch Loss: 0.1513333022594452\n",
      "Epoch 2823, Loss: 0.33534038066864014, Final Batch Loss: 0.07908228784799576\n",
      "Epoch 2824, Loss: 0.30176168121397495, Final Batch Loss: 0.030236775055527687\n",
      "Epoch 2825, Loss: 0.35447514802217484, Final Batch Loss: 0.09479758888483047\n",
      "Epoch 2826, Loss: 0.33234335109591484, Final Batch Loss: 0.040085580199956894\n",
      "Epoch 2827, Loss: 0.5424730479717255, Final Batch Loss: 0.28866031765937805\n",
      "Epoch 2828, Loss: 0.38138049095869064, Final Batch Loss: 0.13715232908725739\n",
      "Epoch 2829, Loss: 0.39163634181022644, Final Batch Loss: 0.15629984438419342\n",
      "Epoch 2830, Loss: 0.33347419649362564, Final Batch Loss: 0.07375603169202805\n",
      "Epoch 2831, Loss: 0.41219208389520645, Final Batch Loss: 0.1720295250415802\n",
      "Epoch 2832, Loss: 0.5126760974526405, Final Batch Loss: 0.23945805430412292\n",
      "Epoch 2833, Loss: 0.3102984353899956, Final Batch Loss: 0.06459248065948486\n",
      "Epoch 2834, Loss: 0.4004557356238365, Final Batch Loss: 0.10786404460668564\n",
      "Epoch 2835, Loss: 0.3338167853653431, Final Batch Loss: 0.05615018680691719\n",
      "Epoch 2836, Loss: 0.4723229482769966, Final Batch Loss: 0.22121858596801758\n",
      "Epoch 2837, Loss: 0.4051569998264313, Final Batch Loss: 0.1493324488401413\n",
      "Epoch 2838, Loss: 0.5113706141710281, Final Batch Loss: 0.14925193786621094\n",
      "Epoch 2839, Loss: 0.5097275525331497, Final Batch Loss: 0.16606080532073975\n",
      "Epoch 2840, Loss: 0.45851995050907135, Final Batch Loss: 0.19316044449806213\n",
      "Epoch 2841, Loss: 0.3282110467553139, Final Batch Loss: 0.07338321208953857\n",
      "Epoch 2842, Loss: 0.38099414855241776, Final Batch Loss: 0.08765296638011932\n",
      "Epoch 2843, Loss: 0.30193302035331726, Final Batch Loss: 0.045898184180259705\n",
      "Epoch 2844, Loss: 0.3466764762997627, Final Batch Loss: 0.08435366302728653\n",
      "Epoch 2845, Loss: 0.40810462832450867, Final Batch Loss: 0.1629815250635147\n",
      "Epoch 2846, Loss: 0.32773739099502563, Final Batch Loss: 0.06518223136663437\n",
      "Epoch 2847, Loss: 0.445814847946167, Final Batch Loss: 0.19588831067085266\n",
      "Epoch 2848, Loss: 0.33578480780124664, Final Batch Loss: 0.11861740797758102\n",
      "Epoch 2849, Loss: 0.3252353295683861, Final Batch Loss: 0.03986240178346634\n",
      "Epoch 2850, Loss: 0.3220898322761059, Final Batch Loss: 0.04310847446322441\n",
      "Epoch 2851, Loss: 0.304932227358222, Final Batch Loss: 0.020979253575205803\n",
      "Epoch 2852, Loss: 0.3400743007659912, Final Batch Loss: 0.0696999728679657\n",
      "Epoch 2853, Loss: 0.35131482034921646, Final Batch Loss: 0.07438860833644867\n",
      "Epoch 2854, Loss: 0.3572191148996353, Final Batch Loss: 0.1011747345328331\n",
      "Epoch 2855, Loss: 0.42720456421375275, Final Batch Loss: 0.13930632174015045\n",
      "Epoch 2856, Loss: 0.3469618856906891, Final Batch Loss: 0.08354656398296356\n",
      "Epoch 2857, Loss: 0.3339296020567417, Final Batch Loss: 0.032721925526857376\n",
      "Epoch 2858, Loss: 0.4579194262623787, Final Batch Loss: 0.2384246289730072\n",
      "Epoch 2859, Loss: 0.3878811299800873, Final Batch Loss: 0.18346205353736877\n",
      "Epoch 2860, Loss: 0.286366980522871, Final Batch Loss: 0.049923550337553024\n",
      "Epoch 2861, Loss: 0.5485135614871979, Final Batch Loss: 0.276580274105072\n",
      "Epoch 2862, Loss: 0.2870672829449177, Final Batch Loss: 0.055659640580415726\n",
      "Epoch 2863, Loss: 0.3657662272453308, Final Batch Loss: 0.08867402374744415\n",
      "Epoch 2864, Loss: 0.38930923491716385, Final Batch Loss: 0.17964231967926025\n",
      "Epoch 2865, Loss: 0.46428076922893524, Final Batch Loss: 0.15352196991443634\n",
      "Epoch 2866, Loss: 0.3977191224694252, Final Batch Loss: 0.18279829621315002\n",
      "Epoch 2867, Loss: 0.3517763316631317, Final Batch Loss: 0.0670672059059143\n",
      "Epoch 2868, Loss: 0.5177696049213409, Final Batch Loss: 0.23104125261306763\n",
      "Epoch 2869, Loss: 0.2799580991268158, Final Batch Loss: 0.018885739147663116\n",
      "Epoch 2870, Loss: 0.29912130534648895, Final Batch Loss: 0.08218088746070862\n",
      "Epoch 2871, Loss: 0.4954952150583267, Final Batch Loss: 0.26407378911972046\n",
      "Epoch 2872, Loss: 0.43765395879745483, Final Batch Loss: 0.1138312816619873\n",
      "Epoch 2873, Loss: 0.3765872120857239, Final Batch Loss: 0.11259986460208893\n",
      "Epoch 2874, Loss: 0.45405085384845734, Final Batch Loss: 0.17478248476982117\n",
      "Epoch 2875, Loss: 0.3953581526875496, Final Batch Loss: 0.1029532179236412\n",
      "Epoch 2876, Loss: 0.4201962426304817, Final Batch Loss: 0.08031091839075089\n",
      "Epoch 2877, Loss: 0.4631818011403084, Final Batch Loss: 0.1941254884004593\n",
      "Epoch 2878, Loss: 0.7950549051165581, Final Batch Loss: 0.5058690905570984\n",
      "Epoch 2879, Loss: 0.5382715314626694, Final Batch Loss: 0.2787400186061859\n",
      "Epoch 2880, Loss: 0.3313184082508087, Final Batch Loss: 0.03504946827888489\n",
      "Epoch 2881, Loss: 0.4499000385403633, Final Batch Loss: 0.2023102045059204\n",
      "Epoch 2882, Loss: 0.29074025293812156, Final Batch Loss: 0.004624785389751196\n",
      "Epoch 2883, Loss: 0.46706050634384155, Final Batch Loss: 0.22666777670383453\n",
      "Epoch 2884, Loss: 0.3235096447169781, Final Batch Loss: 0.035542916506528854\n",
      "Epoch 2885, Loss: 0.33363294042646885, Final Batch Loss: 0.027026662603020668\n",
      "Epoch 2886, Loss: 0.47191420942544937, Final Batch Loss: 0.23414967954158783\n",
      "Epoch 2887, Loss: 0.35961373895406723, Final Batch Loss: 0.09627603739500046\n",
      "Epoch 2888, Loss: 0.5231060236692429, Final Batch Loss: 0.1523321121931076\n",
      "Epoch 2889, Loss: 0.8827616274356842, Final Batch Loss: 0.43380671739578247\n",
      "Epoch 2890, Loss: 0.4731236398220062, Final Batch Loss: 0.05548429489135742\n",
      "Epoch 2891, Loss: 0.38343874365091324, Final Batch Loss: 0.07186352461576462\n",
      "Epoch 2892, Loss: 0.5381733924150467, Final Batch Loss: 0.2881008982658386\n",
      "Epoch 2893, Loss: 0.7090301215648651, Final Batch Loss: 0.4295383393764496\n",
      "Epoch 2894, Loss: 0.3964623548090458, Final Batch Loss: 0.036334771662950516\n",
      "Epoch 2895, Loss: 0.39880991727113724, Final Batch Loss: 0.15736843645572662\n",
      "Epoch 2896, Loss: 0.33726606145501137, Final Batch Loss: 0.03990751877427101\n",
      "Epoch 2897, Loss: 0.5465824902057648, Final Batch Loss: 0.26580119132995605\n",
      "Epoch 2898, Loss: 0.33815155923366547, Final Batch Loss: 0.06801994144916534\n",
      "Epoch 2899, Loss: 0.3423532173037529, Final Batch Loss: 0.06683852523565292\n",
      "Epoch 2900, Loss: 0.3684014454483986, Final Batch Loss: 0.11712700128555298\n",
      "Epoch 2901, Loss: 0.3537883311510086, Final Batch Loss: 0.0885796770453453\n",
      "Epoch 2902, Loss: 0.5097126886248589, Final Batch Loss: 0.23389045894145966\n",
      "Epoch 2903, Loss: 0.46850520372390747, Final Batch Loss: 0.19703440368175507\n",
      "Epoch 2904, Loss: 0.3530892953276634, Final Batch Loss: 0.07836100459098816\n",
      "Epoch 2905, Loss: 0.33071376010775566, Final Batch Loss: 0.05208538845181465\n",
      "Epoch 2906, Loss: 0.46697723865509033, Final Batch Loss: 0.15437717735767365\n",
      "Epoch 2907, Loss: 0.40900641679763794, Final Batch Loss: 0.15586163103580475\n",
      "Epoch 2908, Loss: 0.316576823592186, Final Batch Loss: 0.06931594759225845\n",
      "Epoch 2909, Loss: 0.4898430407047272, Final Batch Loss: 0.23420052230358124\n",
      "Epoch 2910, Loss: 0.33083320409059525, Final Batch Loss: 0.061835795640945435\n",
      "Epoch 2911, Loss: 0.3350836783647537, Final Batch Loss: 0.08628050982952118\n",
      "Epoch 2912, Loss: 0.299203984439373, Final Batch Loss: 0.08999913930892944\n",
      "Epoch 2913, Loss: 0.4571315795183182, Final Batch Loss: 0.21599090099334717\n",
      "Epoch 2914, Loss: 0.312806598842144, Final Batch Loss: 0.06680387258529663\n",
      "Epoch 2915, Loss: 0.31084004789590836, Final Batch Loss: 0.06753628700971603\n",
      "Epoch 2916, Loss: 0.28503958135843277, Final Batch Loss: 0.04049363732337952\n",
      "Epoch 2917, Loss: 0.2592394519597292, Final Batch Loss: 0.026953095570206642\n",
      "Epoch 2918, Loss: 0.28643325716257095, Final Batch Loss: 0.07214473932981491\n",
      "Epoch 2919, Loss: 0.3581973761320114, Final Batch Loss: 0.14822538197040558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2920, Loss: 0.3570455312728882, Final Batch Loss: 0.11687036603689194\n",
      "Epoch 2921, Loss: 0.4498182684183121, Final Batch Loss: 0.2017100304365158\n",
      "Epoch 2922, Loss: 0.279957078397274, Final Batch Loss: 0.042979560792446136\n",
      "Epoch 2923, Loss: 0.49498289823532104, Final Batch Loss: 0.25888538360595703\n",
      "Epoch 2924, Loss: 0.31306564062833786, Final Batch Loss: 0.052293553948402405\n",
      "Epoch 2925, Loss: 0.278657753020525, Final Batch Loss: 0.024644222110509872\n",
      "Epoch 2926, Loss: 0.30213291198015213, Final Batch Loss: 0.06399863958358765\n",
      "Epoch 2927, Loss: 0.3285396061837673, Final Batch Loss: 0.04898626729846001\n",
      "Epoch 2928, Loss: 0.4542417377233505, Final Batch Loss: 0.2346111387014389\n",
      "Epoch 2929, Loss: 0.32365694642066956, Final Batch Loss: 0.09289614111185074\n",
      "Epoch 2930, Loss: 0.24501644261181355, Final Batch Loss: 0.02780579961836338\n",
      "Epoch 2931, Loss: 0.3721056580543518, Final Batch Loss: 0.15072596073150635\n",
      "Epoch 2932, Loss: 0.2943979427218437, Final Batch Loss: 0.06012067198753357\n",
      "Epoch 2933, Loss: 0.4072936102747917, Final Batch Loss: 0.1475020945072174\n",
      "Epoch 2934, Loss: 0.34514860808849335, Final Batch Loss: 0.1372573971748352\n",
      "Epoch 2935, Loss: 0.3615961968898773, Final Batch Loss: 0.11133541911840439\n",
      "Epoch 2936, Loss: 0.475458987057209, Final Batch Loss: 0.21776600182056427\n",
      "Epoch 2937, Loss: 0.2882983013987541, Final Batch Loss: 0.07754355669021606\n",
      "Epoch 2938, Loss: 0.3507082909345627, Final Batch Loss: 0.10053844004869461\n",
      "Epoch 2939, Loss: 0.41904889047145844, Final Batch Loss: 0.1861606389284134\n",
      "Epoch 2940, Loss: 0.31215692311525345, Final Batch Loss: 0.0465080663561821\n",
      "Epoch 2941, Loss: 0.3010900504887104, Final Batch Loss: 0.04045950248837471\n",
      "Epoch 2942, Loss: 0.3754084184765816, Final Batch Loss: 0.15447258949279785\n",
      "Epoch 2943, Loss: 0.31682203710079193, Final Batch Loss: 0.07300277054309845\n",
      "Epoch 2944, Loss: 0.3643781691789627, Final Batch Loss: 0.0771065354347229\n",
      "Epoch 2945, Loss: 0.32539402693510056, Final Batch Loss: 0.10521495342254639\n",
      "Epoch 2946, Loss: 0.2642420846968889, Final Batch Loss: 0.02364870347082615\n",
      "Epoch 2947, Loss: 0.5987663641571999, Final Batch Loss: 0.3789643943309784\n",
      "Epoch 2948, Loss: 0.2660864479839802, Final Batch Loss: 0.04430721327662468\n",
      "Epoch 2949, Loss: 0.551295667886734, Final Batch Loss: 0.2523344159126282\n",
      "Epoch 2950, Loss: 0.388729564845562, Final Batch Loss: 0.13469688594341278\n",
      "Epoch 2951, Loss: 0.3276628777384758, Final Batch Loss: 0.09676287323236465\n",
      "Epoch 2952, Loss: 0.40318844467401505, Final Batch Loss: 0.152952179312706\n",
      "Epoch 2953, Loss: 0.2831355482339859, Final Batch Loss: 0.02758624404668808\n",
      "Epoch 2954, Loss: 0.26984723657369614, Final Batch Loss: 0.04049019515514374\n",
      "Epoch 2955, Loss: 0.29104719310998917, Final Batch Loss: 0.03826422244310379\n",
      "Epoch 2956, Loss: 0.5425051972270012, Final Batch Loss: 0.26474976539611816\n",
      "Epoch 2957, Loss: 0.22661741357296705, Final Batch Loss: 0.013660247437655926\n",
      "Epoch 2958, Loss: 0.3574952185153961, Final Batch Loss: 0.09013788402080536\n",
      "Epoch 2959, Loss: 0.326358862221241, Final Batch Loss: 0.1125662699341774\n",
      "Epoch 2960, Loss: 0.24998429603874683, Final Batch Loss: 0.006091276183724403\n",
      "Epoch 2961, Loss: 0.5064088776707649, Final Batch Loss: 0.24546942114830017\n",
      "Epoch 2962, Loss: 0.3040792793035507, Final Batch Loss: 0.07084295153617859\n",
      "Epoch 2963, Loss: 0.553028330206871, Final Batch Loss: 0.34185102581977844\n",
      "Epoch 2964, Loss: 0.34947220236063004, Final Batch Loss: 0.045225970447063446\n",
      "Epoch 2965, Loss: 0.3920277804136276, Final Batch Loss: 0.13972647488117218\n",
      "Epoch 2966, Loss: 0.597770631313324, Final Batch Loss: 0.2980237305164337\n",
      "Epoch 2967, Loss: 0.4117218852043152, Final Batch Loss: 0.14351709187030792\n",
      "Epoch 2968, Loss: 0.29730235412716866, Final Batch Loss: 0.018577691167593002\n",
      "Epoch 2969, Loss: 0.6099265813827515, Final Batch Loss: 0.3591724932193756\n",
      "Epoch 2970, Loss: 0.25652786530554295, Final Batch Loss: 0.030047664418816566\n",
      "Epoch 2971, Loss: 0.42796193808317184, Final Batch Loss: 0.20128747820854187\n",
      "Epoch 2972, Loss: 0.2593347802758217, Final Batch Loss: 0.04072555899620056\n",
      "Epoch 2973, Loss: 0.353628933429718, Final Batch Loss: 0.05558522045612335\n",
      "Epoch 2974, Loss: 0.2818113137036562, Final Batch Loss: 0.02912297286093235\n",
      "Epoch 2975, Loss: 0.6047593280673027, Final Batch Loss: 0.39608249068260193\n",
      "Epoch 2976, Loss: 0.5406416207551956, Final Batch Loss: 0.2896689176559448\n",
      "Epoch 2977, Loss: 0.31424444541335106, Final Batch Loss: 0.031746719032526016\n",
      "Epoch 2978, Loss: 0.3744363971054554, Final Batch Loss: 0.05261673405766487\n",
      "Epoch 2979, Loss: 0.5301268249750137, Final Batch Loss: 0.1907825917005539\n",
      "Epoch 2980, Loss: 0.4170209467411041, Final Batch Loss: 0.14504840970039368\n",
      "Epoch 2981, Loss: 0.39419686794281006, Final Batch Loss: 0.07449604570865631\n",
      "Epoch 2982, Loss: 0.48381733149290085, Final Batch Loss: 0.20467470586299896\n",
      "Epoch 2983, Loss: 0.32453478500247, Final Batch Loss: 0.06004561111330986\n",
      "Epoch 2984, Loss: 0.26978981122374535, Final Batch Loss: 0.009380970150232315\n",
      "Epoch 2985, Loss: 0.2833809098228812, Final Batch Loss: 0.011766619049012661\n",
      "Epoch 2986, Loss: 0.4180622026324272, Final Batch Loss: 0.15895502269268036\n",
      "Epoch 2987, Loss: 0.3467025086283684, Final Batch Loss: 0.1237872913479805\n",
      "Epoch 2988, Loss: 0.27994153276085854, Final Batch Loss: 0.040923912078142166\n",
      "Epoch 2989, Loss: 0.4030178412795067, Final Batch Loss: 0.11963842064142227\n",
      "Epoch 2990, Loss: 0.2432199502363801, Final Batch Loss: 0.01232674065977335\n",
      "Epoch 2991, Loss: 0.36502428352832794, Final Batch Loss: 0.14982913434505463\n",
      "Epoch 2992, Loss: 0.3718021437525749, Final Batch Loss: 0.1163625493645668\n",
      "Epoch 2993, Loss: 0.3826023265719414, Final Batch Loss: 0.13331559300422668\n",
      "Epoch 2994, Loss: 0.2637084871530533, Final Batch Loss: 0.012933395802974701\n",
      "Epoch 2995, Loss: 0.37328432500362396, Final Batch Loss: 0.14529018104076385\n",
      "Epoch 2996, Loss: 0.33633436262607574, Final Batch Loss: 0.0799495130777359\n",
      "Epoch 2997, Loss: 0.48755259066820145, Final Batch Loss: 0.24668744206428528\n",
      "Epoch 2998, Loss: 0.2667246973142028, Final Batch Loss: 0.008257976733148098\n",
      "Epoch 2999, Loss: 0.4562465026974678, Final Batch Loss: 0.20616567134857178\n",
      "Epoch 3000, Loss: 0.22295347787439823, Final Batch Loss: 0.015986459329724312\n",
      "Epoch 3001, Loss: 0.2681373115628958, Final Batch Loss: 0.02024061791598797\n",
      "Epoch 3002, Loss: 0.38935934752225876, Final Batch Loss: 0.1377979815006256\n",
      "Epoch 3003, Loss: 0.3925151750445366, Final Batch Loss: 0.0764966830611229\n",
      "Epoch 3004, Loss: 0.8389048352837563, Final Batch Loss: 0.6044982075691223\n",
      "Epoch 3005, Loss: 0.4006080701947212, Final Batch Loss: 0.08927176147699356\n",
      "Epoch 3006, Loss: 0.2638253979384899, Final Batch Loss: 0.028535012155771255\n",
      "Epoch 3007, Loss: 0.3054795414209366, Final Batch Loss: 0.0945647731423378\n",
      "Epoch 3008, Loss: 0.37733254581689835, Final Batch Loss: 0.14234700798988342\n",
      "Epoch 3009, Loss: 0.6014105454087257, Final Batch Loss: 0.38043832778930664\n",
      "Epoch 3010, Loss: 0.263766273856163, Final Batch Loss: 0.036056846380233765\n",
      "Epoch 3011, Loss: 0.5539553165435791, Final Batch Loss: 0.30749189853668213\n",
      "Epoch 3012, Loss: 0.47599901258945465, Final Batch Loss: 0.2256011962890625\n",
      "Epoch 3013, Loss: 0.4022810012102127, Final Batch Loss: 0.157144695520401\n",
      "Epoch 3014, Loss: 0.45962199568748474, Final Batch Loss: 0.2256176918745041\n",
      "Epoch 3015, Loss: 0.2570055089890957, Final Batch Loss: 0.044391144067049026\n",
      "Epoch 3016, Loss: 0.40420037508010864, Final Batch Loss: 0.13464121520519257\n",
      "Epoch 3017, Loss: 0.3632187470793724, Final Batch Loss: 0.09577225893735886\n",
      "Epoch 3018, Loss: 0.3303351253271103, Final Batch Loss: 0.08230897039175034\n",
      "Epoch 3019, Loss: 0.3183729872107506, Final Batch Loss: 0.1294865608215332\n",
      "Epoch 3020, Loss: 0.3807358182966709, Final Batch Loss: 0.05718216672539711\n",
      "Epoch 3021, Loss: 0.44123393297195435, Final Batch Loss: 0.16407151520252228\n",
      "Epoch 3022, Loss: 0.4264242947101593, Final Batch Loss: 0.19552497565746307\n",
      "Epoch 3023, Loss: 0.5583969056606293, Final Batch Loss: 0.2545219361782074\n",
      "Epoch 3024, Loss: 0.4087996929883957, Final Batch Loss: 0.1632344275712967\n",
      "Epoch 3025, Loss: 0.3372900225222111, Final Batch Loss: 0.05179368332028389\n",
      "Epoch 3026, Loss: 0.42581768706440926, Final Batch Loss: 0.05914682522416115\n",
      "Epoch 3027, Loss: 0.53983473777771, Final Batch Loss: 0.23982037603855133\n",
      "Epoch 3028, Loss: 0.37008416652679443, Final Batch Loss: 0.08510451018810272\n",
      "Epoch 3029, Loss: 0.5758504271507263, Final Batch Loss: 0.23213745653629303\n",
      "Epoch 3030, Loss: 0.5028367191553116, Final Batch Loss: 0.13674353063106537\n",
      "Epoch 3031, Loss: 0.6334789991378784, Final Batch Loss: 0.3167307674884796\n",
      "Epoch 3032, Loss: 0.4423375725746155, Final Batch Loss: 0.08456398546695709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3033, Loss: 0.5733882635831833, Final Batch Loss: 0.22197701036930084\n",
      "Epoch 3034, Loss: 0.34643952175974846, Final Batch Loss: 0.05455642566084862\n",
      "Epoch 3035, Loss: 0.36848848313093185, Final Batch Loss: 0.08598003536462784\n",
      "Epoch 3036, Loss: 0.37741919606924057, Final Batch Loss: 0.13612228631973267\n",
      "Epoch 3037, Loss: 0.39928365498781204, Final Batch Loss: 0.10787124186754227\n",
      "Epoch 3038, Loss: 0.36142653971910477, Final Batch Loss: 0.1269019991159439\n",
      "Epoch 3039, Loss: 0.411663219332695, Final Batch Loss: 0.1962050199508667\n",
      "Epoch 3040, Loss: 0.44831860810518265, Final Batch Loss: 0.19600093364715576\n",
      "Epoch 3041, Loss: 1.1299313977360725, Final Batch Loss: 0.905410647392273\n",
      "Epoch 3042, Loss: 0.5200876221060753, Final Batch Loss: 0.2562863826751709\n",
      "Epoch 3043, Loss: 0.5354165583848953, Final Batch Loss: 0.3234308660030365\n",
      "Epoch 3044, Loss: 0.40917621552944183, Final Batch Loss: 0.1392156332731247\n",
      "Epoch 3045, Loss: 0.3204941116273403, Final Batch Loss: 0.04063860699534416\n",
      "Epoch 3046, Loss: 0.29291845858097076, Final Batch Loss: 0.07425549626350403\n",
      "Epoch 3047, Loss: 0.3652007356286049, Final Batch Loss: 0.0575561448931694\n",
      "Epoch 3048, Loss: 1.009303256869316, Final Batch Loss: 0.7267659306526184\n",
      "Epoch 3049, Loss: 0.37851282209157944, Final Batch Loss: 0.1618993878364563\n",
      "Epoch 3050, Loss: 0.313758447766304, Final Batch Loss: 0.03961746394634247\n",
      "Epoch 3051, Loss: 0.6460813283920288, Final Batch Loss: 0.2860497832298279\n",
      "Epoch 3052, Loss: 0.45806552469730377, Final Batch Loss: 0.10910063982009888\n",
      "Epoch 3053, Loss: 0.3218739219009876, Final Batch Loss: 0.03665735200047493\n",
      "Epoch 3054, Loss: 0.31021763384342194, Final Batch Loss: 0.037287428975105286\n",
      "Epoch 3055, Loss: 0.2992073968052864, Final Batch Loss: 0.06834035366773605\n",
      "Epoch 3056, Loss: 0.3029335392639041, Final Batch Loss: 0.008176053874194622\n",
      "Epoch 3057, Loss: 0.42306889593601227, Final Batch Loss: 0.163843035697937\n",
      "Epoch 3058, Loss: 0.2625164205674082, Final Batch Loss: 0.002096440875902772\n",
      "Epoch 3059, Loss: 0.37884511053562164, Final Batch Loss: 0.11713192611932755\n",
      "Epoch 3060, Loss: 0.24356754682958126, Final Batch Loss: 0.01734483800828457\n",
      "Epoch 3061, Loss: 0.29322532936930656, Final Batch Loss: 0.05686074122786522\n",
      "Epoch 3062, Loss: 0.27079785242676735, Final Batch Loss: 0.027914103120565414\n",
      "Epoch 3063, Loss: 0.31749555468559265, Final Batch Loss: 0.08355724066495895\n",
      "Epoch 3064, Loss: 0.2595503628253937, Final Batch Loss: 0.07108590751886368\n",
      "Epoch 3065, Loss: 0.44804421067237854, Final Batch Loss: 0.20867906510829926\n",
      "Epoch 3066, Loss: 0.32771213352680206, Final Batch Loss: 0.09796340763568878\n",
      "Epoch 3067, Loss: 0.3919542767107487, Final Batch Loss: 0.043618667870759964\n",
      "Epoch 3068, Loss: 0.4452514052391052, Final Batch Loss: 0.16569717228412628\n",
      "Epoch 3069, Loss: 0.35908128321170807, Final Batch Loss: 0.09538181871175766\n",
      "Epoch 3070, Loss: 0.3917435482144356, Final Batch Loss: 0.17351575195789337\n",
      "Epoch 3071, Loss: 0.34519878774881363, Final Batch Loss: 0.08578920364379883\n",
      "Epoch 3072, Loss: 0.3716391772031784, Final Batch Loss: 0.10525922477245331\n",
      "Epoch 3073, Loss: 0.35168280452489853, Final Batch Loss: 0.04800271987915039\n",
      "Epoch 3074, Loss: 0.5135126262903214, Final Batch Loss: 0.16725322604179382\n",
      "Epoch 3075, Loss: 0.5081789121031761, Final Batch Loss: 0.18107138574123383\n",
      "Epoch 3076, Loss: 0.36850161850452423, Final Batch Loss: 0.11950995028018951\n",
      "Epoch 3077, Loss: 0.294262632727623, Final Batch Loss: 0.06910494714975357\n",
      "Epoch 3078, Loss: 0.5789348632097244, Final Batch Loss: 0.30240294337272644\n",
      "Epoch 3079, Loss: 0.4880797043442726, Final Batch Loss: 0.25861382484436035\n",
      "Epoch 3080, Loss: 0.37919797748327255, Final Batch Loss: 0.10956456512212753\n",
      "Epoch 3081, Loss: 0.3585648536682129, Final Batch Loss: 0.11548684537410736\n",
      "Epoch 3082, Loss: 0.40874870121479034, Final Batch Loss: 0.16962586343288422\n",
      "Epoch 3083, Loss: 0.3036274015903473, Final Batch Loss: 0.015817269682884216\n",
      "Epoch 3084, Loss: 0.4449969008564949, Final Batch Loss: 0.1960475742816925\n",
      "Epoch 3085, Loss: 0.36657434701919556, Final Batch Loss: 0.1373613327741623\n",
      "Epoch 3086, Loss: 0.2548734825104475, Final Batch Loss: 0.026867365464568138\n",
      "Epoch 3087, Loss: 0.22609246615320444, Final Batch Loss: 0.014192485250532627\n",
      "Epoch 3088, Loss: 0.3000565152615309, Final Batch Loss: 0.026764823123812675\n",
      "Epoch 3089, Loss: 0.23603675328195095, Final Batch Loss: 0.01730426959693432\n",
      "Epoch 3090, Loss: 0.312365859746933, Final Batch Loss: 0.09141498804092407\n",
      "Epoch 3091, Loss: 0.2642592191696167, Final Batch Loss: 0.06664569675922394\n",
      "Epoch 3092, Loss: 0.269893242046237, Final Batch Loss: 0.01886359415948391\n",
      "Epoch 3093, Loss: 0.27518340945243835, Final Batch Loss: 0.07103151082992554\n",
      "Epoch 3094, Loss: 0.34400980174541473, Final Batch Loss: 0.1370238959789276\n",
      "Epoch 3095, Loss: 0.2821239084005356, Final Batch Loss: 0.0823303684592247\n",
      "Epoch 3096, Loss: 0.33068716898560524, Final Batch Loss: 0.055481333285570145\n",
      "Epoch 3097, Loss: 0.33059951290488243, Final Batch Loss: 0.057086970657110214\n",
      "Epoch 3098, Loss: 0.28936807438731194, Final Batch Loss: 0.04785105213522911\n",
      "Epoch 3099, Loss: 0.4043126776814461, Final Batch Loss: 0.23134657740592957\n",
      "Epoch 3100, Loss: 0.36078038811683655, Final Batch Loss: 0.11014588177204132\n",
      "Epoch 3101, Loss: 0.24919247068464756, Final Batch Loss: 0.023515993729233742\n",
      "Epoch 3102, Loss: 0.3093600943684578, Final Batch Loss: 0.0839478075504303\n",
      "Epoch 3103, Loss: 0.22061063908040524, Final Batch Loss: 0.01783970557153225\n",
      "Epoch 3104, Loss: 0.32153575122356415, Final Batch Loss: 0.05528290569782257\n",
      "Epoch 3105, Loss: 0.2908501476049423, Final Batch Loss: 0.06469553709030151\n",
      "Epoch 3106, Loss: 0.2967779003083706, Final Batch Loss: 0.05234784260392189\n",
      "Epoch 3107, Loss: 0.576148197054863, Final Batch Loss: 0.3304699659347534\n",
      "Epoch 3108, Loss: 0.30577564984560013, Final Batch Loss: 0.0535864531993866\n",
      "Epoch 3109, Loss: 0.4318855181336403, Final Batch Loss: 0.23257523775100708\n",
      "Epoch 3110, Loss: 0.2373359352350235, Final Batch Loss: 0.030157849192619324\n",
      "Epoch 3111, Loss: 0.34825027734041214, Final Batch Loss: 0.12303172796964645\n",
      "Epoch 3112, Loss: 0.40684961527585983, Final Batch Loss: 0.21126320958137512\n",
      "Epoch 3113, Loss: 0.26252441853284836, Final Batch Loss: 0.06485005468130112\n",
      "Epoch 3114, Loss: 0.23621875792741776, Final Batch Loss: 0.028034113347530365\n",
      "Epoch 3115, Loss: 0.44587600976228714, Final Batch Loss: 0.24265974760055542\n",
      "Epoch 3116, Loss: 0.31598635017871857, Final Batch Loss: 0.07346659153699875\n",
      "Epoch 3117, Loss: 0.4928310588002205, Final Batch Loss: 0.2692566514015198\n",
      "Epoch 3118, Loss: 0.32571205496788025, Final Batch Loss: 0.09217149019241333\n",
      "Epoch 3119, Loss: 0.27357640117406845, Final Batch Loss: 0.03669934719800949\n",
      "Epoch 3120, Loss: 0.28030452132225037, Final Batch Loss: 0.06895212829113007\n",
      "Epoch 3121, Loss: 0.24255845695734024, Final Batch Loss: 0.0605398491024971\n",
      "Epoch 3122, Loss: 0.3013296090066433, Final Batch Loss: 0.051969531923532486\n",
      "Epoch 3123, Loss: 0.41823185235261917, Final Batch Loss: 0.13190865516662598\n",
      "Epoch 3124, Loss: 0.24065238796174526, Final Batch Loss: 0.026240093633532524\n",
      "Epoch 3125, Loss: 0.5092084780335426, Final Batch Loss: 0.24019308388233185\n",
      "Epoch 3126, Loss: 0.29554158076643944, Final Batch Loss: 0.051607582718133926\n",
      "Epoch 3127, Loss: 0.7257242053747177, Final Batch Loss: 0.47722017765045166\n",
      "Epoch 3128, Loss: 0.28877654299139977, Final Batch Loss: 0.06217135861515999\n",
      "Epoch 3129, Loss: 0.5329609960317612, Final Batch Loss: 0.2602338492870331\n",
      "Epoch 3130, Loss: 0.5354350134730339, Final Batch Loss: 0.11843829602003098\n",
      "Epoch 3131, Loss: 0.4240097254514694, Final Batch Loss: 0.09839777648448944\n",
      "Epoch 3132, Loss: 0.31129706650972366, Final Batch Loss: 0.03656146675348282\n",
      "Epoch 3133, Loss: 0.3136320561170578, Final Batch Loss: 0.06787560135126114\n",
      "Epoch 3134, Loss: 0.4752538874745369, Final Batch Loss: 0.20958103239536285\n",
      "Epoch 3135, Loss: 0.5219799801707268, Final Batch Loss: 0.3047172725200653\n",
      "Epoch 3136, Loss: 0.4456625059247017, Final Batch Loss: 0.21443010866641998\n",
      "Epoch 3137, Loss: 0.40702179074287415, Final Batch Loss: 0.13541178405284882\n",
      "Epoch 3138, Loss: 0.3975830227136612, Final Batch Loss: 0.10125715285539627\n",
      "Epoch 3139, Loss: 0.3760634735226631, Final Batch Loss: 0.13865631818771362\n",
      "Epoch 3140, Loss: 0.2764439433813095, Final Batch Loss: 0.04892287403345108\n",
      "Epoch 3141, Loss: 0.24538356065750122, Final Batch Loss: 0.02678050845861435\n",
      "Epoch 3142, Loss: 0.3754383251070976, Final Batch Loss: 0.12457718700170517\n",
      "Epoch 3143, Loss: 0.3990432918071747, Final Batch Loss: 0.14264440536499023\n",
      "Epoch 3144, Loss: 0.2938418909907341, Final Batch Loss: 0.0346161350607872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3145, Loss: 0.29325856268405914, Final Batch Loss: 0.07381011545658112\n",
      "Epoch 3146, Loss: 0.29269421100616455, Final Batch Loss: 0.08827733248472214\n",
      "Epoch 3147, Loss: 0.2850935813039541, Final Batch Loss: 0.026854289695620537\n",
      "Epoch 3148, Loss: 0.47653114050626755, Final Batch Loss: 0.23225611448287964\n",
      "Epoch 3149, Loss: 0.2992897853255272, Final Batch Loss: 0.08465518802404404\n",
      "Epoch 3150, Loss: 0.3436038866639137, Final Batch Loss: 0.1125602200627327\n",
      "Epoch 3151, Loss: 0.2298091221600771, Final Batch Loss: 0.016694659367203712\n",
      "Epoch 3152, Loss: 0.7208843752741814, Final Batch Loss: 0.4796241819858551\n",
      "Epoch 3153, Loss: 0.32484861463308334, Final Batch Loss: 0.1408972293138504\n",
      "Epoch 3154, Loss: 0.34938330203294754, Final Batch Loss: 0.14100639522075653\n",
      "Epoch 3155, Loss: 0.31819953583180904, Final Batch Loss: 0.02086588554084301\n",
      "Epoch 3156, Loss: 0.3589923772960901, Final Batch Loss: 0.02576201595366001\n",
      "Epoch 3157, Loss: 0.27137230336666107, Final Batch Loss: 0.04505445808172226\n",
      "Epoch 3158, Loss: 0.27036701515316963, Final Batch Loss: 0.04597585275769234\n",
      "Epoch 3159, Loss: 0.23661186918616295, Final Batch Loss: 0.0070350803434848785\n",
      "Epoch 3160, Loss: 0.26244500279426575, Final Batch Loss: 0.018519327044487\n",
      "Epoch 3161, Loss: 0.5208873972296715, Final Batch Loss: 0.32761549949645996\n",
      "Epoch 3162, Loss: 0.2074205493554473, Final Batch Loss: 0.014811291359364986\n",
      "Epoch 3163, Loss: 0.3254217356443405, Final Batch Loss: 0.12661853432655334\n",
      "Epoch 3164, Loss: 0.2070710426196456, Final Batch Loss: 0.011016911827027798\n",
      "Epoch 3165, Loss: 0.29789435118436813, Final Batch Loss: 0.05011490732431412\n",
      "Epoch 3166, Loss: 0.25308462232351303, Final Batch Loss: 0.03386583924293518\n",
      "Epoch 3167, Loss: 0.2879389524459839, Final Batch Loss: 0.049816712737083435\n",
      "Epoch 3168, Loss: 0.28122611716389656, Final Batch Loss: 0.03758767619729042\n",
      "Epoch 3169, Loss: 0.5620921924710274, Final Batch Loss: 0.32634076476097107\n",
      "Epoch 3170, Loss: 0.28039607405662537, Final Batch Loss: 0.06365355104207993\n",
      "Epoch 3171, Loss: 0.3574538007378578, Final Batch Loss: 0.11597590893507004\n",
      "Epoch 3172, Loss: 0.2897224873304367, Final Batch Loss: 0.0425538644194603\n",
      "Epoch 3173, Loss: 0.2625642456114292, Final Batch Loss: 0.024015087634325027\n",
      "Epoch 3174, Loss: 0.4224252626299858, Final Batch Loss: 0.23258909583091736\n",
      "Epoch 3175, Loss: 0.3481227979063988, Final Batch Loss: 0.09788957238197327\n",
      "Epoch 3176, Loss: 0.39879754930734634, Final Batch Loss: 0.1814763993024826\n",
      "Epoch 3177, Loss: 0.3931276202201843, Final Batch Loss: 0.07080509513616562\n",
      "Epoch 3178, Loss: 0.38336867839097977, Final Batch Loss: 0.10648085176944733\n",
      "Epoch 3179, Loss: 0.2912911996245384, Final Batch Loss: 0.06736937910318375\n",
      "Epoch 3180, Loss: 0.5551865994930267, Final Batch Loss: 0.28177186846733093\n",
      "Epoch 3181, Loss: 0.32986144721508026, Final Batch Loss: 0.08821965008974075\n",
      "Epoch 3182, Loss: 0.5056725218892097, Final Batch Loss: 0.22819483280181885\n",
      "Epoch 3183, Loss: 0.41531952470541, Final Batch Loss: 0.1698327660560608\n",
      "Epoch 3184, Loss: 0.38160478323698044, Final Batch Loss: 0.09582295268774033\n",
      "Epoch 3185, Loss: 0.39655333012342453, Final Batch Loss: 0.07852538675069809\n",
      "Epoch 3186, Loss: 0.6359423249959946, Final Batch Loss: 0.21322980523109436\n",
      "Epoch 3187, Loss: 0.3845580220222473, Final Batch Loss: 0.10329747200012207\n",
      "Epoch 3188, Loss: 0.3345071002840996, Final Batch Loss: 0.09841460734605789\n",
      "Epoch 3189, Loss: 0.5239192992448807, Final Batch Loss: 0.2435748130083084\n",
      "Epoch 3190, Loss: 0.409006305038929, Final Batch Loss: 0.13434052467346191\n",
      "Epoch 3191, Loss: 0.43613846600055695, Final Batch Loss: 0.13061566650867462\n",
      "Epoch 3192, Loss: 0.45535965263843536, Final Batch Loss: 0.18926283717155457\n",
      "Epoch 3193, Loss: 0.45150240510702133, Final Batch Loss: 0.1518748253583908\n",
      "Epoch 3194, Loss: 0.42388147860765457, Final Batch Loss: 0.23013634979724884\n",
      "Epoch 3195, Loss: 0.3500850424170494, Final Batch Loss: 0.08661545068025589\n",
      "Epoch 3196, Loss: 0.6153984367847443, Final Batch Loss: 0.19751304388046265\n",
      "Epoch 3197, Loss: 0.2949897535145283, Final Batch Loss: 0.05091889575123787\n",
      "Epoch 3198, Loss: 0.5450374633073807, Final Batch Loss: 0.18439948558807373\n",
      "Epoch 3199, Loss: 0.5937667191028595, Final Batch Loss: 0.34671393036842346\n",
      "Epoch 3200, Loss: 0.4277541935443878, Final Batch Loss: 0.1423024833202362\n",
      "Epoch 3201, Loss: 0.4762760400772095, Final Batch Loss: 0.23560838401317596\n",
      "Epoch 3202, Loss: 0.5626989379525185, Final Batch Loss: 0.30530309677124023\n",
      "Epoch 3203, Loss: 0.44975052028894424, Final Batch Loss: 0.2570141851902008\n",
      "Epoch 3204, Loss: 0.4547513797879219, Final Batch Loss: 0.21048983931541443\n",
      "Epoch 3205, Loss: 0.542587623000145, Final Batch Loss: 0.20443247258663177\n",
      "Epoch 3206, Loss: 0.31873495131731033, Final Batch Loss: 0.056972354650497437\n",
      "Epoch 3207, Loss: 0.3025474138557911, Final Batch Loss: 0.03580549731850624\n",
      "Epoch 3208, Loss: 0.4917087256908417, Final Batch Loss: 0.22451192140579224\n",
      "Epoch 3209, Loss: 0.5856089293956757, Final Batch Loss: 0.3459871709346771\n",
      "Epoch 3210, Loss: 0.3054979033768177, Final Batch Loss: 0.0562986321747303\n",
      "Epoch 3211, Loss: 0.41187944263219833, Final Batch Loss: 0.09952107816934586\n",
      "Epoch 3212, Loss: 0.35909800976514816, Final Batch Loss: 0.07476099580526352\n",
      "Epoch 3213, Loss: 0.3761400505900383, Final Batch Loss: 0.14082889258861542\n",
      "Epoch 3214, Loss: 0.3606058284640312, Final Batch Loss: 0.08225605636835098\n",
      "Epoch 3215, Loss: 0.5559331625699997, Final Batch Loss: 0.305630087852478\n",
      "Epoch 3216, Loss: 0.47067371010780334, Final Batch Loss: 0.25106650590896606\n",
      "Epoch 3217, Loss: 0.45415525883436203, Final Batch Loss: 0.22015036642551422\n",
      "Epoch 3218, Loss: 0.47636647522449493, Final Batch Loss: 0.21951840817928314\n",
      "Epoch 3219, Loss: 0.3071313127875328, Final Batch Loss: 0.08434604853391647\n",
      "Epoch 3220, Loss: 0.24242069479078054, Final Batch Loss: 0.01380226667970419\n",
      "Epoch 3221, Loss: 0.40864989906549454, Final Batch Loss: 0.16538648307323456\n",
      "Epoch 3222, Loss: 0.26812272146344185, Final Batch Loss: 0.03837297484278679\n",
      "Epoch 3223, Loss: 0.34405670315027237, Final Batch Loss: 0.08816631883382797\n",
      "Epoch 3224, Loss: 0.3248130939900875, Final Batch Loss: 0.061705369502305984\n",
      "Epoch 3225, Loss: 0.23890813812613487, Final Batch Loss: 0.045371588319540024\n",
      "Epoch 3226, Loss: 0.31875912845134735, Final Batch Loss: 0.06786332279443741\n",
      "Epoch 3227, Loss: 0.43498004972934723, Final Batch Loss: 0.22277644276618958\n",
      "Epoch 3228, Loss: 0.2962172105908394, Final Batch Loss: 0.07743465900421143\n",
      "Epoch 3229, Loss: 0.26536161452531815, Final Batch Loss: 0.016649417579174042\n",
      "Epoch 3230, Loss: 0.4415002316236496, Final Batch Loss: 0.18548919260501862\n",
      "Epoch 3231, Loss: 0.3063695430755615, Final Batch Loss: 0.04221945255994797\n",
      "Epoch 3232, Loss: 0.21041212789714336, Final Batch Loss: 0.016866235062479973\n",
      "Epoch 3233, Loss: 0.20598078472539783, Final Batch Loss: 0.004345334600657225\n",
      "Epoch 3234, Loss: 0.28295663744211197, Final Batch Loss: 0.09259951114654541\n",
      "Epoch 3235, Loss: 0.20663675060495734, Final Batch Loss: 0.0010843663476407528\n",
      "Epoch 3236, Loss: 0.40014058351516724, Final Batch Loss: 0.20832224190235138\n",
      "Epoch 3237, Loss: 0.2624608241021633, Final Batch Loss: 0.057664815336465836\n",
      "Epoch 3238, Loss: 0.24687359109520912, Final Batch Loss: 0.0457695834338665\n",
      "Epoch 3239, Loss: 0.41602054983377457, Final Batch Loss: 0.2098160982131958\n",
      "Epoch 3240, Loss: 0.2522946260869503, Final Batch Loss: 0.02790025994181633\n",
      "Epoch 3241, Loss: 0.2532586269080639, Final Batch Loss: 0.04211156442761421\n",
      "Epoch 3242, Loss: 0.2719590961933136, Final Batch Loss: 0.045283243060112\n",
      "Epoch 3243, Loss: 0.23773830570280552, Final Batch Loss: 0.0034806374460458755\n",
      "Epoch 3244, Loss: 0.3985411077737808, Final Batch Loss: 0.20083922147750854\n",
      "Epoch 3245, Loss: 0.282945241779089, Final Batch Loss: 0.04120134934782982\n",
      "Epoch 3246, Loss: 0.37026024982333183, Final Batch Loss: 0.20251308381557465\n",
      "Epoch 3247, Loss: 0.3715706765651703, Final Batch Loss: 0.10861185938119888\n",
      "Epoch 3248, Loss: 0.5583183243870735, Final Batch Loss: 0.3132364749908447\n",
      "Epoch 3249, Loss: 0.2666466385126114, Final Batch Loss: 0.0173988938331604\n",
      "Epoch 3250, Loss: 0.9530501961708069, Final Batch Loss: 0.496042400598526\n",
      "Epoch 3251, Loss: 0.5105636715888977, Final Batch Loss: 0.13625697791576385\n",
      "Epoch 3252, Loss: 0.6281313747167587, Final Batch Loss: 0.18952615559101105\n",
      "Epoch 3253, Loss: 0.3058856390416622, Final Batch Loss: 0.05566166713833809\n",
      "Epoch 3254, Loss: 0.2990037798881531, Final Batch Loss: 0.05090348422527313\n",
      "Epoch 3255, Loss: 0.2801968790590763, Final Batch Loss: 0.04762895032763481\n",
      "Epoch 3256, Loss: 0.27286504209041595, Final Batch Loss: 0.02856830507516861\n",
      "Epoch 3257, Loss: 0.2710776925086975, Final Batch Loss: 0.0556769073009491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3258, Loss: 0.6001260057091713, Final Batch Loss: 0.3902444839477539\n",
      "Epoch 3259, Loss: 0.3532699719071388, Final Batch Loss: 0.07830555737018585\n",
      "Epoch 3260, Loss: 0.29364149272441864, Final Batch Loss: 0.07962503284215927\n",
      "Epoch 3261, Loss: 0.3386274501681328, Final Batch Loss: 0.14366599917411804\n",
      "Epoch 3262, Loss: 0.30478494614362717, Final Batch Loss: 0.11446318030357361\n",
      "Epoch 3263, Loss: 0.4134254828095436, Final Batch Loss: 0.1516512781381607\n",
      "Epoch 3264, Loss: 0.35912612825632095, Final Batch Loss: 0.15396900475025177\n",
      "Epoch 3265, Loss: 0.34488222748041153, Final Batch Loss: 0.12113965302705765\n",
      "Epoch 3266, Loss: 0.43431125581264496, Final Batch Loss: 0.17195063829421997\n",
      "Epoch 3267, Loss: 0.44697168469429016, Final Batch Loss: 0.19589364528656006\n",
      "Epoch 3268, Loss: 0.3093238715082407, Final Batch Loss: 0.020697468891739845\n",
      "Epoch 3269, Loss: 0.3300086036324501, Final Batch Loss: 0.08710650354623795\n",
      "Epoch 3270, Loss: 0.38334573060274124, Final Batch Loss: 0.07488825172185898\n",
      "Epoch 3271, Loss: 0.47360049188137054, Final Batch Loss: 0.16220590472221375\n",
      "Epoch 3272, Loss: 0.4432986080646515, Final Batch Loss: 0.1408551186323166\n",
      "Epoch 3273, Loss: 0.5021693110466003, Final Batch Loss: 0.20622862875461578\n",
      "Epoch 3274, Loss: 0.4636112153530121, Final Batch Loss: 0.13351714611053467\n",
      "Epoch 3275, Loss: 0.308753177523613, Final Batch Loss: 0.09702807664871216\n",
      "Epoch 3276, Loss: 0.28946276754140854, Final Batch Loss: 0.06718898564577103\n",
      "Epoch 3277, Loss: 0.2818995229899883, Final Batch Loss: 0.041054580360651016\n",
      "Epoch 3278, Loss: 0.3570354953408241, Final Batch Loss: 0.10146711766719818\n",
      "Epoch 3279, Loss: 0.34155211597681046, Final Batch Loss: 0.09547785669565201\n",
      "Epoch 3280, Loss: 0.22260650526732206, Final Batch Loss: 0.008904325775802135\n",
      "Epoch 3281, Loss: 0.4235893040895462, Final Batch Loss: 0.19866234064102173\n",
      "Epoch 3282, Loss: 0.3476588949561119, Final Batch Loss: 0.07550003379583359\n",
      "Epoch 3283, Loss: 0.43186668306589127, Final Batch Loss: 0.2295157015323639\n",
      "Epoch 3284, Loss: 0.3624463528394699, Final Batch Loss: 0.13142938911914825\n",
      "Epoch 3285, Loss: 0.407072477042675, Final Batch Loss: 0.11802314221858978\n",
      "Epoch 3286, Loss: 0.3116301894187927, Final Batch Loss: 0.06144723296165466\n",
      "Epoch 3287, Loss: 0.3395262509584427, Final Batch Loss: 0.12103478610515594\n",
      "Epoch 3288, Loss: 0.24727832898497581, Final Batch Loss: 0.031964171677827835\n",
      "Epoch 3289, Loss: 0.2128773396834731, Final Batch Loss: 0.014333284460008144\n",
      "Epoch 3290, Loss: 0.22674116306006908, Final Batch Loss: 0.02460659109055996\n",
      "Epoch 3291, Loss: 0.28703548945486546, Final Batch Loss: 0.029833966866135597\n",
      "Epoch 3292, Loss: 0.22762161120772362, Final Batch Loss: 0.038671720772981644\n",
      "Epoch 3293, Loss: 0.42045341432094574, Final Batch Loss: 0.21432428061962128\n",
      "Epoch 3294, Loss: 0.35989534109830856, Final Batch Loss: 0.15115535259246826\n",
      "Epoch 3295, Loss: 0.31545862555503845, Final Batch Loss: 0.11553312838077545\n",
      "Epoch 3296, Loss: 0.3475986272096634, Final Batch Loss: 0.13810105621814728\n",
      "Epoch 3297, Loss: 0.40131817013025284, Final Batch Loss: 0.08342525362968445\n",
      "Epoch 3298, Loss: 0.30695419013500214, Final Batch Loss: 0.07394588738679886\n",
      "Epoch 3299, Loss: 0.26438380777835846, Final Batch Loss: 0.0734754428267479\n",
      "Epoch 3300, Loss: 0.5996797680854797, Final Batch Loss: 0.3136231303215027\n",
      "Epoch 3301, Loss: 0.2624810189008713, Final Batch Loss: 0.020711854100227356\n",
      "Epoch 3302, Loss: 0.31100041419267654, Final Batch Loss: 0.029120996594429016\n",
      "Epoch 3303, Loss: 0.6264729052782059, Final Batch Loss: 0.34164613485336304\n",
      "Epoch 3304, Loss: 0.48466865718364716, Final Batch Loss: 0.23033200204372406\n",
      "Epoch 3305, Loss: 0.3986566364765167, Final Batch Loss: 0.1819949597120285\n",
      "Epoch 3306, Loss: 0.2763312831521034, Final Batch Loss: 0.06410980224609375\n",
      "Epoch 3307, Loss: 0.31343740224838257, Final Batch Loss: 0.058385297656059265\n",
      "Epoch 3308, Loss: 0.34867389500141144, Final Batch Loss: 0.05660025775432587\n",
      "Epoch 3309, Loss: 0.31341287307441235, Final Batch Loss: 0.020319847390055656\n",
      "Epoch 3310, Loss: 0.379624105989933, Final Batch Loss: 0.16019223630428314\n",
      "Epoch 3311, Loss: 0.2848185561597347, Final Batch Loss: 0.05053674802184105\n",
      "Epoch 3312, Loss: 0.4073599949479103, Final Batch Loss: 0.07262609153985977\n",
      "Epoch 3313, Loss: 0.4451367035508156, Final Batch Loss: 0.2381204068660736\n",
      "Epoch 3314, Loss: 0.514814481139183, Final Batch Loss: 0.16413062810897827\n",
      "Epoch 3315, Loss: 0.5958910435438156, Final Batch Loss: 0.3343390226364136\n",
      "Epoch 3316, Loss: 0.32691750675439835, Final Batch Loss: 0.03152044862508774\n",
      "Epoch 3317, Loss: 0.29041819646954536, Final Batch Loss: 0.005736444145441055\n",
      "Epoch 3318, Loss: 0.43593423068523407, Final Batch Loss: 0.11304910480976105\n",
      "Epoch 3319, Loss: 0.41012242436408997, Final Batch Loss: 0.09267956763505936\n",
      "Epoch 3320, Loss: 0.44588208943605423, Final Batch Loss: 0.20165011286735535\n",
      "Epoch 3321, Loss: 0.3199080005288124, Final Batch Loss: 0.0827428326010704\n",
      "Epoch 3322, Loss: 0.2931632809340954, Final Batch Loss: 0.007849197834730148\n",
      "Epoch 3323, Loss: 0.24149112403392792, Final Batch Loss: 0.03374791145324707\n",
      "Epoch 3324, Loss: 0.33523353189229965, Final Batch Loss: 0.10619623959064484\n",
      "Epoch 3325, Loss: 0.3710297420620918, Final Batch Loss: 0.04202612489461899\n",
      "Epoch 3326, Loss: 0.29511507600545883, Final Batch Loss: 0.05994243919849396\n",
      "Epoch 3327, Loss: 0.4183511435985565, Final Batch Loss: 0.20618155598640442\n",
      "Epoch 3328, Loss: 0.2501237317919731, Final Batch Loss: 0.03609225153923035\n",
      "Epoch 3329, Loss: 0.25974065717309713, Final Batch Loss: 0.012509389780461788\n",
      "Epoch 3330, Loss: 0.4405694827437401, Final Batch Loss: 0.24762549996376038\n",
      "Epoch 3331, Loss: 0.23922587931156158, Final Batch Loss: 0.08778760582208633\n",
      "Epoch 3332, Loss: 0.3354792222380638, Final Batch Loss: 0.07526366412639618\n",
      "Epoch 3333, Loss: 0.3841123431921005, Final Batch Loss: 0.13585500419139862\n",
      "Epoch 3334, Loss: 0.3168443292379379, Final Batch Loss: 0.10600525140762329\n",
      "Epoch 3335, Loss: 0.34110894799232483, Final Batch Loss: 0.14244306087493896\n",
      "Epoch 3336, Loss: 0.46611855179071426, Final Batch Loss: 0.24045820534229279\n",
      "Epoch 3337, Loss: 0.3551545962691307, Final Batch Loss: 0.09565184265375137\n",
      "Epoch 3338, Loss: 0.2071536686271429, Final Batch Loss: 0.022243639454245567\n",
      "Epoch 3339, Loss: 0.2517183981835842, Final Batch Loss: 0.026880446821451187\n",
      "Epoch 3340, Loss: 0.2194886887446046, Final Batch Loss: 0.011600681580603123\n",
      "Epoch 3341, Loss: 0.27740181144326925, Final Batch Loss: 0.009410462342202663\n",
      "Epoch 3342, Loss: 0.3802417740225792, Final Batch Loss: 0.19581742584705353\n",
      "Epoch 3343, Loss: 0.2955417335033417, Final Batch Loss: 0.06969742476940155\n",
      "Epoch 3344, Loss: 0.4113306924700737, Final Batch Loss: 0.1405772715806961\n",
      "Epoch 3345, Loss: 0.3769981637597084, Final Batch Loss: 0.14936786890029907\n",
      "Epoch 3346, Loss: 0.3797996938228607, Final Batch Loss: 0.19661320745944977\n",
      "Epoch 3347, Loss: 0.2669743709266186, Final Batch Loss: 0.057985950261354446\n",
      "Epoch 3348, Loss: 0.30334389209747314, Final Batch Loss: 0.021759092807769775\n",
      "Epoch 3349, Loss: 0.369916096329689, Final Batch Loss: 0.1353197991847992\n",
      "Epoch 3350, Loss: 0.3718106746673584, Final Batch Loss: 0.10117543488740921\n",
      "Epoch 3351, Loss: 0.2497117482125759, Final Batch Loss: 0.04732741788029671\n",
      "Epoch 3352, Loss: 0.2974601909518242, Final Batch Loss: 0.05647571384906769\n",
      "Epoch 3353, Loss: 0.30698395520448685, Final Batch Loss: 0.07917112112045288\n",
      "Epoch 3354, Loss: 0.5432450547814369, Final Batch Loss: 0.3176208436489105\n",
      "Epoch 3355, Loss: 0.2571901045739651, Final Batch Loss: 0.06194942817091942\n",
      "Epoch 3356, Loss: 0.24964799266308546, Final Batch Loss: 0.007615352980792522\n",
      "Epoch 3357, Loss: 0.30714450776576996, Final Batch Loss: 0.08880698680877686\n",
      "Epoch 3358, Loss: 0.3312559574842453, Final Batch Loss: 0.12678827345371246\n",
      "Epoch 3359, Loss: 0.2227916531264782, Final Batch Loss: 0.031520064920186996\n",
      "Epoch 3360, Loss: 1.3342364430427551, Final Batch Loss: 1.0856033563613892\n",
      "Epoch 3361, Loss: 0.5485521927475929, Final Batch Loss: 0.2873801589012146\n",
      "Epoch 3362, Loss: 0.3405904471874237, Final Batch Loss: 0.14582635462284088\n",
      "Epoch 3363, Loss: 0.6609462797641754, Final Batch Loss: 0.30022692680358887\n",
      "Epoch 3364, Loss: 1.0662181675434113, Final Batch Loss: 0.7069239020347595\n",
      "Epoch 3365, Loss: 0.392280213534832, Final Batch Loss: 0.09628993272781372\n",
      "Epoch 3366, Loss: 0.42508934438228607, Final Batch Loss: 0.12153355777263641\n",
      "Epoch 3367, Loss: 0.43785277754068375, Final Batch Loss: 0.07495326548814774\n",
      "Epoch 3368, Loss: 0.47206801921129227, Final Batch Loss: 0.22391514480113983\n",
      "Epoch 3369, Loss: 0.3718002960085869, Final Batch Loss: 0.09367818385362625\n",
      "Epoch 3370, Loss: 0.44385314732789993, Final Batch Loss: 0.13482129573822021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3371, Loss: 0.2808233704417944, Final Batch Loss: 0.025540677830576897\n",
      "Epoch 3372, Loss: 0.34500980377197266, Final Batch Loss: 0.025756701827049255\n",
      "Epoch 3373, Loss: 0.4738771617412567, Final Batch Loss: 0.2509554326534271\n",
      "Epoch 3374, Loss: 0.27051209658384323, Final Batch Loss: 0.08912328630685806\n",
      "Epoch 3375, Loss: 0.49283454567193985, Final Batch Loss: 0.2898670434951782\n",
      "Epoch 3376, Loss: 0.34987612068653107, Final Batch Loss: 0.10676314681768417\n",
      "Epoch 3377, Loss: 0.4424361139535904, Final Batch Loss: 0.1893414855003357\n",
      "Epoch 3378, Loss: 0.7422980591654778, Final Batch Loss: 0.48750200867652893\n",
      "Epoch 3379, Loss: 0.37724222987890244, Final Batch Loss: 0.11955853551626205\n",
      "Epoch 3380, Loss: 0.3432411253452301, Final Batch Loss: 0.07741021364927292\n",
      "Epoch 3381, Loss: 0.3943394050002098, Final Batch Loss: 0.20467735826969147\n",
      "Epoch 3382, Loss: 0.33058036863803864, Final Batch Loss: 0.06199578940868378\n",
      "Epoch 3383, Loss: 0.37134332209825516, Final Batch Loss: 0.08665279299020767\n",
      "Epoch 3384, Loss: 0.49649249017238617, Final Batch Loss: 0.23467989265918732\n",
      "Epoch 3385, Loss: 0.42545271664857864, Final Batch Loss: 0.18004678189754486\n",
      "Epoch 3386, Loss: 0.33450085297226906, Final Batch Loss: 0.03574836626648903\n",
      "Epoch 3387, Loss: 0.42360611259937286, Final Batch Loss: 0.14114440977573395\n",
      "Epoch 3388, Loss: 0.4160151481628418, Final Batch Loss: 0.11876988410949707\n",
      "Epoch 3389, Loss: 0.37941357120871544, Final Batch Loss: 0.05512657389044762\n",
      "Epoch 3390, Loss: 0.2767054010182619, Final Batch Loss: 0.027288326993584633\n",
      "Epoch 3391, Loss: 0.32998840510845184, Final Batch Loss: 0.03935961425304413\n",
      "Epoch 3392, Loss: 0.3172403499484062, Final Batch Loss: 0.08542276173830032\n",
      "Epoch 3393, Loss: 0.2573123727925122, Final Batch Loss: 0.007295005489140749\n",
      "Epoch 3394, Loss: 0.3535405620932579, Final Batch Loss: 0.06843379884958267\n",
      "Epoch 3395, Loss: 0.370670884847641, Final Batch Loss: 0.16642656922340393\n",
      "Epoch 3396, Loss: 0.3801085278391838, Final Batch Loss: 0.18662312626838684\n",
      "Epoch 3397, Loss: 0.3031499646604061, Final Batch Loss: 0.04687831178307533\n",
      "Epoch 3398, Loss: 0.19593754690140486, Final Batch Loss: 0.013303893618285656\n",
      "Epoch 3399, Loss: 0.22768015787005424, Final Batch Loss: 0.01983976736664772\n",
      "Epoch 3400, Loss: 0.42698418349027634, Final Batch Loss: 0.21328888833522797\n",
      "Epoch 3401, Loss: 0.2468612790107727, Final Batch Loss: 0.026724502444267273\n",
      "Epoch 3402, Loss: 0.19732419261708856, Final Batch Loss: 0.00405076751485467\n",
      "Epoch 3403, Loss: 0.24225789308547974, Final Batch Loss: 0.03490007668733597\n",
      "Epoch 3404, Loss: 0.4059978350996971, Final Batch Loss: 0.22229322791099548\n",
      "Epoch 3405, Loss: 0.3581272214651108, Final Batch Loss: 0.11397789418697357\n",
      "Epoch 3406, Loss: 0.20790445804595947, Final Batch Loss: 0.02423921227455139\n",
      "Epoch 3407, Loss: 0.23099017329514027, Final Batch Loss: 0.028997110202908516\n",
      "Epoch 3408, Loss: 0.22181522846221924, Final Batch Loss: 0.04065254330635071\n",
      "Epoch 3409, Loss: 0.27503009513020515, Final Batch Loss: 0.01684189960360527\n",
      "Epoch 3410, Loss: 0.4370870366692543, Final Batch Loss: 0.2355041205883026\n",
      "Epoch 3411, Loss: 0.2838425412774086, Final Batch Loss: 0.06652909517288208\n",
      "Epoch 3412, Loss: 0.30811135470867157, Final Batch Loss: 0.10280768573284149\n",
      "Epoch 3413, Loss: 0.18550974351819605, Final Batch Loss: 0.0009914882248267531\n",
      "Epoch 3414, Loss: 0.25779662281274796, Final Batch Loss: 0.08441762626171112\n",
      "Epoch 3415, Loss: 0.31223609298467636, Final Batch Loss: 0.12154632806777954\n",
      "Epoch 3416, Loss: 0.28332626819610596, Final Batch Loss: 0.09955275803804398\n",
      "Epoch 3417, Loss: 0.35666506737470627, Final Batch Loss: 0.17662735283374786\n",
      "Epoch 3418, Loss: 0.22518165037035942, Final Batch Loss: 0.02220785990357399\n",
      "Epoch 3419, Loss: 0.37298695743083954, Final Batch Loss: 0.09089802950620651\n",
      "Epoch 3420, Loss: 0.28021690249443054, Final Batch Loss: 0.08474219590425491\n",
      "Epoch 3421, Loss: 0.348822183907032, Final Batch Loss: 0.143520787358284\n",
      "Epoch 3422, Loss: 0.4648729935288429, Final Batch Loss: 0.23890143632888794\n",
      "Epoch 3423, Loss: 0.22685697488486767, Final Batch Loss: 0.017643606290221214\n",
      "Epoch 3424, Loss: 0.29317332804203033, Final Batch Loss: 0.10226090997457504\n",
      "Epoch 3425, Loss: 0.3605664297938347, Final Batch Loss: 0.15042753517627716\n",
      "Epoch 3426, Loss: 0.34545648843050003, Final Batch Loss: 0.09103328734636307\n",
      "Epoch 3427, Loss: 0.26008932664990425, Final Batch Loss: 0.03740186616778374\n",
      "Epoch 3428, Loss: 0.3298276513814926, Final Batch Loss: 0.14536702632904053\n",
      "Epoch 3429, Loss: 0.3120318725705147, Final Batch Loss: 0.0907680094242096\n",
      "Epoch 3430, Loss: 0.21248388662934303, Final Batch Loss: 0.01686302199959755\n",
      "Epoch 3431, Loss: 0.44571661949157715, Final Batch Loss: 0.20559488236904144\n",
      "Epoch 3432, Loss: 0.24275875836610794, Final Batch Loss: 0.05738119035959244\n",
      "Epoch 3433, Loss: 0.2794250324368477, Final Batch Loss: 0.09440875798463821\n",
      "Epoch 3434, Loss: 0.24454480782151222, Final Batch Loss: 0.0579926036298275\n",
      "Epoch 3435, Loss: 0.4052765741944313, Final Batch Loss: 0.16955935955047607\n",
      "Epoch 3436, Loss: 0.5381990447640419, Final Batch Loss: 0.32098641991615295\n",
      "Epoch 3437, Loss: 0.3966536596417427, Final Batch Loss: 0.18132276833057404\n",
      "Epoch 3438, Loss: 0.3464207649230957, Final Batch Loss: 0.13752038776874542\n",
      "Epoch 3439, Loss: 0.39784304797649384, Final Batch Loss: 0.15717057883739471\n",
      "Epoch 3440, Loss: 0.7315832674503326, Final Batch Loss: 0.4735453724861145\n",
      "Epoch 3441, Loss: 0.36540641635656357, Final Batch Loss: 0.06302416324615479\n",
      "Epoch 3442, Loss: 0.34866392612457275, Final Batch Loss: 0.11104937642812729\n",
      "Epoch 3443, Loss: 0.32852301374077797, Final Batch Loss: 0.05188629403710365\n",
      "Epoch 3444, Loss: 0.5565720796585083, Final Batch Loss: 0.2948516309261322\n",
      "Epoch 3445, Loss: 0.30340269953012466, Final Batch Loss: 0.06134219467639923\n",
      "Epoch 3446, Loss: 0.6874992623925209, Final Batch Loss: 0.4485664367675781\n",
      "Epoch 3447, Loss: 0.33448417484760284, Final Batch Loss: 0.11428844183683395\n",
      "Epoch 3448, Loss: 0.23757484927773476, Final Batch Loss: 0.02954931929707527\n",
      "Epoch 3449, Loss: 0.3041079193353653, Final Batch Loss: 0.0910295620560646\n",
      "Epoch 3450, Loss: 0.23771236278116703, Final Batch Loss: 0.02110867388546467\n",
      "Epoch 3451, Loss: 0.3214234635233879, Final Batch Loss: 0.09265105426311493\n",
      "Epoch 3452, Loss: 0.20069786719977856, Final Batch Loss: 0.019717684015631676\n",
      "Epoch 3453, Loss: 0.2673816606402397, Final Batch Loss: 0.06636625528335571\n",
      "Epoch 3454, Loss: 0.41322583705186844, Final Batch Loss: 0.22416594624519348\n",
      "Epoch 3455, Loss: 0.33060790598392487, Final Batch Loss: 0.14155112206935883\n",
      "Epoch 3456, Loss: 0.34787825495004654, Final Batch Loss: 0.09828482568264008\n",
      "Epoch 3457, Loss: 0.31224876642227173, Final Batch Loss: 0.031100749969482422\n",
      "Epoch 3458, Loss: 0.3760802522301674, Final Batch Loss: 0.1488400548696518\n",
      "Epoch 3459, Loss: 0.3653227761387825, Final Batch Loss: 0.17309831082820892\n",
      "Epoch 3460, Loss: 0.39386889338493347, Final Batch Loss: 0.14824050664901733\n",
      "Epoch 3461, Loss: 0.36715828627347946, Final Batch Loss: 0.14563125371932983\n",
      "Epoch 3462, Loss: 0.3761066347360611, Final Batch Loss: 0.15902948379516602\n",
      "Epoch 3463, Loss: 0.3141870051622391, Final Batch Loss: 0.0890582725405693\n",
      "Epoch 3464, Loss: 0.5604881569743156, Final Batch Loss: 0.35868433117866516\n",
      "Epoch 3465, Loss: 0.3335590362548828, Final Batch Loss: 0.08426135033369064\n",
      "Epoch 3466, Loss: 0.2643627319484949, Final Batch Loss: 0.02468368597328663\n",
      "Epoch 3467, Loss: 0.3843449205160141, Final Batch Loss: 0.144623264670372\n",
      "Epoch 3468, Loss: 0.24920614808797836, Final Batch Loss: 0.08284828811883926\n",
      "Epoch 3469, Loss: 0.2731708250939846, Final Batch Loss: 0.04922104999423027\n",
      "Epoch 3470, Loss: 0.34731366485357285, Final Batch Loss: 0.10950995981693268\n",
      "Epoch 3471, Loss: 0.2931205593049526, Final Batch Loss: 0.05830155685544014\n",
      "Epoch 3472, Loss: 0.42971518635749817, Final Batch Loss: 0.21006296575069427\n",
      "Epoch 3473, Loss: 0.28739171475172043, Final Batch Loss: 0.09447187185287476\n",
      "Epoch 3474, Loss: 0.37974246591329575, Final Batch Loss: 0.160114586353302\n",
      "Epoch 3475, Loss: 0.3019412234425545, Final Batch Loss: 0.10632725805044174\n",
      "Epoch 3476, Loss: 0.3835754692554474, Final Batch Loss: 0.1982809603214264\n",
      "Epoch 3477, Loss: 0.4375489503145218, Final Batch Loss: 0.23078453540802002\n",
      "Epoch 3478, Loss: 0.3948126435279846, Final Batch Loss: 0.18565717339515686\n",
      "Epoch 3479, Loss: 0.3489399924874306, Final Batch Loss: 0.12969893217086792\n",
      "Epoch 3480, Loss: 0.33125273883342743, Final Batch Loss: 0.13841481506824493\n",
      "Epoch 3481, Loss: 0.2811259664595127, Final Batch Loss: 0.06124594435095787\n",
      "Epoch 3482, Loss: 0.37225155532360077, Final Batch Loss: 0.17759279906749725\n",
      "Epoch 3483, Loss: 0.40740007162094116, Final Batch Loss: 0.1333640068769455\n",
      "Epoch 3484, Loss: 0.362258218228817, Final Batch Loss: 0.163507342338562\n",
      "Epoch 3485, Loss: 0.2922171875834465, Final Batch Loss: 0.08776713162660599\n",
      "Epoch 3486, Loss: 0.2507879436016083, Final Batch Loss: 0.06357545405626297\n",
      "Epoch 3487, Loss: 0.23511091619729996, Final Batch Loss: 0.0368632972240448\n",
      "Epoch 3488, Loss: 0.2434638007543981, Final Batch Loss: 0.006516547407954931\n",
      "Epoch 3489, Loss: 0.29921838641166687, Final Batch Loss: 0.12440523505210876\n",
      "Epoch 3490, Loss: 0.1769441682845354, Final Batch Loss: 0.02790881134569645\n",
      "Epoch 3491, Loss: 0.17048040474765003, Final Batch Loss: 0.0038659616839140654\n",
      "Epoch 3492, Loss: 0.25620806962251663, Final Batch Loss: 0.06905151903629303\n",
      "Epoch 3493, Loss: 0.21910197660326958, Final Batch Loss: 0.053845930844545364\n",
      "Epoch 3494, Loss: 0.27831462025642395, Final Batch Loss: 0.07957858592271805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3495, Loss: 0.24252765532582998, Final Batch Loss: 0.014910615049302578\n",
      "Epoch 3496, Loss: 0.36020664870738983, Final Batch Loss: 0.15693865716457367\n",
      "Epoch 3497, Loss: 0.29080504924058914, Final Batch Loss: 0.0795324370265007\n",
      "Epoch 3498, Loss: 0.27071335911750793, Final Batch Loss: 0.036147989332675934\n",
      "Epoch 3499, Loss: 0.2852029427886009, Final Batch Loss: 0.08777457475662231\n",
      "Epoch 3500, Loss: 0.24597013927996159, Final Batch Loss: 0.020330974832177162\n",
      "Epoch 3501, Loss: 0.32227324694395065, Final Batch Loss: 0.08375722914934158\n",
      "Epoch 3502, Loss: 0.5241057202219963, Final Batch Loss: 0.35272926092147827\n",
      "Epoch 3503, Loss: 0.3355332389473915, Final Batch Loss: 0.12884685397148132\n",
      "Epoch 3504, Loss: 0.1974152708426118, Final Batch Loss: 0.010201343335211277\n",
      "Epoch 3505, Loss: 0.286342054605484, Final Batch Loss: 0.05714234709739685\n",
      "Epoch 3506, Loss: 0.3270492786541581, Final Batch Loss: 0.013824277557432652\n",
      "Epoch 3507, Loss: 0.30123767256736755, Final Batch Loss: 0.10812295228242874\n",
      "Epoch 3508, Loss: 0.3773818239569664, Final Batch Loss: 0.15695148706436157\n",
      "Epoch 3509, Loss: 0.19405350647866726, Final Batch Loss: 0.01838894747197628\n",
      "Epoch 3510, Loss: 0.37065286934375763, Final Batch Loss: 0.15275849401950836\n",
      "Epoch 3511, Loss: 0.32554956525564194, Final Batch Loss: 0.09414376318454742\n",
      "Epoch 3512, Loss: 0.40957365930080414, Final Batch Loss: 0.07229889929294586\n",
      "Epoch 3513, Loss: 0.2960080951452255, Final Batch Loss: 0.09065030515193939\n",
      "Epoch 3514, Loss: 0.2573946490883827, Final Batch Loss: 0.03509029746055603\n",
      "Epoch 3515, Loss: 0.26304273307323456, Final Batch Loss: 0.06732490658760071\n",
      "Epoch 3516, Loss: 0.26828333735466003, Final Batch Loss: 0.04522038251161575\n",
      "Epoch 3517, Loss: 0.6896619126200676, Final Batch Loss: 0.4829462468624115\n",
      "Epoch 3518, Loss: 0.7847979590296745, Final Batch Loss: 0.5329397320747375\n",
      "Epoch 3519, Loss: 0.463387668132782, Final Batch Loss: 0.1687477082014084\n",
      "Epoch 3520, Loss: 0.3335762694478035, Final Batch Loss: 0.06352917850017548\n",
      "Epoch 3521, Loss: 0.393119752407074, Final Batch Loss: 0.15969334542751312\n",
      "Epoch 3522, Loss: 0.5407817214727402, Final Batch Loss: 0.3162592351436615\n",
      "Epoch 3523, Loss: 0.339028961956501, Final Batch Loss: 0.04889371246099472\n",
      "Epoch 3524, Loss: 0.3799969367682934, Final Batch Loss: 0.04381197318434715\n",
      "Epoch 3525, Loss: 0.25255982857197523, Final Batch Loss: 0.00916281621903181\n",
      "Epoch 3526, Loss: 0.455672949552536, Final Batch Loss: 0.18605318665504456\n",
      "Epoch 3527, Loss: 0.5737816393375397, Final Batch Loss: 0.22683630883693695\n",
      "Epoch 3528, Loss: 0.46131734549999237, Final Batch Loss: 0.1535673439502716\n",
      "Epoch 3529, Loss: 0.5419400408864021, Final Batch Loss: 0.31632256507873535\n",
      "Epoch 3530, Loss: 0.34673226810991764, Final Batch Loss: 0.0192407313734293\n",
      "Epoch 3531, Loss: 0.37489231675863266, Final Batch Loss: 0.08027295023202896\n",
      "Epoch 3532, Loss: 0.4337271451950073, Final Batch Loss: 0.018332213163375854\n",
      "Epoch 3533, Loss: 0.4026245027780533, Final Batch Loss: 0.148204043507576\n",
      "Epoch 3534, Loss: 0.26539345271885395, Final Batch Loss: 0.027422556653618813\n",
      "Epoch 3535, Loss: 0.5585070922970772, Final Batch Loss: 0.2652752101421356\n",
      "Epoch 3536, Loss: 0.29949452355504036, Final Batch Loss: 0.018167544156312943\n",
      "Epoch 3537, Loss: 0.3080737441778183, Final Batch Loss: 0.06933867931365967\n",
      "Epoch 3538, Loss: 0.3288053348660469, Final Batch Loss: 0.0987313762307167\n",
      "Epoch 3539, Loss: 0.24404066428542137, Final Batch Loss: 0.03874324634671211\n",
      "Epoch 3540, Loss: 0.19057829678058624, Final Batch Loss: 0.027272306382656097\n",
      "Epoch 3541, Loss: 0.4036850929260254, Final Batch Loss: 0.21885447204113007\n",
      "Epoch 3542, Loss: 0.4916348084807396, Final Batch Loss: 0.33742740750312805\n",
      "Epoch 3543, Loss: 0.2321900650858879, Final Batch Loss: 0.03168471157550812\n",
      "Epoch 3544, Loss: 0.5057471916079521, Final Batch Loss: 0.2733452320098877\n",
      "Epoch 3545, Loss: 0.3802357241511345, Final Batch Loss: 0.10628203302621841\n",
      "Epoch 3546, Loss: 0.6511781215667725, Final Batch Loss: 0.3380793631076813\n",
      "Epoch 3547, Loss: 0.3877670392394066, Final Batch Loss: 0.18083742260932922\n",
      "Epoch 3548, Loss: 0.46932125091552734, Final Batch Loss: 0.2289670705795288\n",
      "Epoch 3549, Loss: 0.462767094373703, Final Batch Loss: 0.09235276281833649\n",
      "Epoch 3550, Loss: 0.43425241112709045, Final Batch Loss: 0.09880489110946655\n",
      "Epoch 3551, Loss: 0.31253162771463394, Final Batch Loss: 0.07186397165060043\n",
      "Epoch 3552, Loss: 0.3845302611589432, Final Batch Loss: 0.14219479262828827\n",
      "Epoch 3553, Loss: 0.5632178485393524, Final Batch Loss: 0.2251974642276764\n",
      "Epoch 3554, Loss: 0.5082515329122543, Final Batch Loss: 0.23030725121498108\n",
      "Epoch 3555, Loss: 0.49788518249988556, Final Batch Loss: 0.23434309661388397\n",
      "Epoch 3556, Loss: 0.2562071159482002, Final Batch Loss: 0.012713909149169922\n",
      "Epoch 3557, Loss: 0.4054224044084549, Final Batch Loss: 0.06428299844264984\n",
      "Epoch 3558, Loss: 0.5548766106367111, Final Batch Loss: 0.18768297135829926\n",
      "Epoch 3559, Loss: 0.3814852386713028, Final Batch Loss: 0.14102117717266083\n",
      "Epoch 3560, Loss: 0.27060114219784737, Final Batch Loss: 0.028556805104017258\n",
      "Epoch 3561, Loss: 0.21735932119190693, Final Batch Loss: 0.01607544906437397\n",
      "Epoch 3562, Loss: 0.38189938571304083, Final Batch Loss: 0.01037146057933569\n",
      "Epoch 3563, Loss: 0.28249115496873856, Final Batch Loss: 0.01611500233411789\n",
      "Epoch 3564, Loss: 0.3076120428740978, Final Batch Loss: 0.06060068681836128\n",
      "Epoch 3565, Loss: 0.29322249442338943, Final Batch Loss: 0.09953509271144867\n",
      "Epoch 3566, Loss: 0.41328293830156326, Final Batch Loss: 0.16522501409053802\n",
      "Epoch 3567, Loss: 0.31271688640117645, Final Batch Loss: 0.09715190529823303\n",
      "Epoch 3568, Loss: 0.32264795154333115, Final Batch Loss: 0.10750345140695572\n",
      "Epoch 3569, Loss: 0.3310430496931076, Final Batch Loss: 0.08421231806278229\n",
      "Epoch 3570, Loss: 0.37247802317142487, Final Batch Loss: 0.13311201333999634\n",
      "Epoch 3571, Loss: 0.2913772761821747, Final Batch Loss: 0.1445775330066681\n",
      "Epoch 3572, Loss: 0.40927160531282425, Final Batch Loss: 0.16991405189037323\n",
      "Epoch 3573, Loss: 0.26460250467061996, Final Batch Loss: 0.04776856303215027\n",
      "Epoch 3574, Loss: 0.1902916058897972, Final Batch Loss: 0.033838436007499695\n",
      "Epoch 3575, Loss: 0.23781514982692897, Final Batch Loss: 0.003835514886304736\n",
      "Epoch 3576, Loss: 0.25564171373844147, Final Batch Loss: 0.03781493753194809\n",
      "Epoch 3577, Loss: 0.24384980276226997, Final Batch Loss: 0.023149218410253525\n",
      "Epoch 3578, Loss: 0.27154378592967987, Final Batch Loss: 0.044326528906822205\n",
      "Epoch 3579, Loss: 0.2649275385774672, Final Batch Loss: 0.004124256316572428\n",
      "Epoch 3580, Loss: 0.4047119691967964, Final Batch Loss: 0.15788263082504272\n",
      "Epoch 3581, Loss: 0.3999320790171623, Final Batch Loss: 0.20712211728096008\n",
      "Epoch 3582, Loss: 0.31754931807518005, Final Batch Loss: 0.0953902006149292\n",
      "Epoch 3583, Loss: 0.1604102193377912, Final Batch Loss: 0.0064439489506185055\n",
      "Epoch 3584, Loss: 0.2651956304907799, Final Batch Loss: 0.07320192456245422\n",
      "Epoch 3585, Loss: 0.4626127853989601, Final Batch Loss: 0.26236408948898315\n",
      "Epoch 3586, Loss: 0.17863405868411064, Final Batch Loss: 0.0331186018884182\n",
      "Epoch 3587, Loss: 0.4013230428099632, Final Batch Loss: 0.19813546538352966\n",
      "Epoch 3588, Loss: 0.36480075120925903, Final Batch Loss: 0.16015839576721191\n",
      "Epoch 3589, Loss: 0.2569342777132988, Final Batch Loss: 0.031656891107559204\n",
      "Epoch 3590, Loss: 0.29292435199022293, Final Batch Loss: 0.08186487853527069\n",
      "Epoch 3591, Loss: 0.2307644560933113, Final Batch Loss: 0.035239435732364655\n",
      "Epoch 3592, Loss: 0.2377234287559986, Final Batch Loss: 0.04457739368081093\n",
      "Epoch 3593, Loss: 0.1803257055580616, Final Batch Loss: 0.01761576160788536\n",
      "Epoch 3594, Loss: 0.26188010163605213, Final Batch Loss: 0.01512661762535572\n",
      "Epoch 3595, Loss: 0.21704888716340065, Final Batch Loss: 0.056106019765138626\n",
      "Epoch 3596, Loss: 0.3814186751842499, Final Batch Loss: 0.14186245203018188\n",
      "Epoch 3597, Loss: 0.2873024716973305, Final Batch Loss: 0.08978897333145142\n",
      "Epoch 3598, Loss: 0.2721647508442402, Final Batch Loss: 0.046300653368234634\n",
      "Epoch 3599, Loss: 0.34865929931402206, Final Batch Loss: 0.1790965050458908\n",
      "Epoch 3600, Loss: 0.24069657176733017, Final Batch Loss: 0.030995570123195648\n",
      "Epoch 3601, Loss: 0.23964451998472214, Final Batch Loss: 0.06369112432003021\n",
      "Epoch 3602, Loss: 0.3608333058655262, Final Batch Loss: 0.2121313512325287\n",
      "Epoch 3603, Loss: 0.3535710871219635, Final Batch Loss: 0.14076068997383118\n",
      "Epoch 3604, Loss: 0.22117912769317627, Final Batch Loss: 0.014885284006595612\n",
      "Epoch 3605, Loss: 0.4652619957923889, Final Batch Loss: 0.19775976240634918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3606, Loss: 0.4071952849626541, Final Batch Loss: 0.1183282732963562\n",
      "Epoch 3607, Loss: 0.2573290020227432, Final Batch Loss: 0.06927341222763062\n",
      "Epoch 3608, Loss: 0.2962956503033638, Final Batch Loss: 0.1049184650182724\n",
      "Epoch 3609, Loss: 0.18236031709238887, Final Batch Loss: 0.007617536466568708\n",
      "Epoch 3610, Loss: 0.2926788106560707, Final Batch Loss: 0.06356409192085266\n",
      "Epoch 3611, Loss: 0.2282554991543293, Final Batch Loss: 0.042680930346250534\n",
      "Epoch 3612, Loss: 0.20846626022830606, Final Batch Loss: 0.007520301733165979\n",
      "Epoch 3613, Loss: 0.2565976642072201, Final Batch Loss: 0.038938332349061966\n",
      "Epoch 3614, Loss: 0.30015838146209717, Final Batch Loss: 0.06422680616378784\n",
      "Epoch 3615, Loss: 0.1998191550374031, Final Batch Loss: 0.0482465922832489\n",
      "Epoch 3616, Loss: 0.34438324719667435, Final Batch Loss: 0.1608271449804306\n",
      "Epoch 3617, Loss: 0.34079326689243317, Final Batch Loss: 0.11220531910657883\n",
      "Epoch 3618, Loss: 0.18867947347462177, Final Batch Loss: 0.029741892591118813\n",
      "Epoch 3619, Loss: 0.2132243812084198, Final Batch Loss: 0.039089299738407135\n",
      "Epoch 3620, Loss: 0.2757757678627968, Final Batch Loss: 0.05907118320465088\n",
      "Epoch 3621, Loss: 0.20712974108755589, Final Batch Loss: 0.002629527822136879\n",
      "Epoch 3622, Loss: 0.19075127691030502, Final Batch Loss: 0.02743539959192276\n",
      "Epoch 3623, Loss: 0.3749728724360466, Final Batch Loss: 0.18028490245342255\n",
      "Epoch 3624, Loss: 0.23489973694086075, Final Batch Loss: 0.05044008046388626\n",
      "Epoch 3625, Loss: 0.4030052125453949, Final Batch Loss: 0.2512684464454651\n",
      "Epoch 3626, Loss: 0.18245526030659676, Final Batch Loss: 0.015204668045043945\n",
      "Epoch 3627, Loss: 0.2639802359044552, Final Batch Loss: 0.06027426943182945\n",
      "Epoch 3628, Loss: 0.25998762249946594, Final Batch Loss: 0.07883267849683762\n",
      "Epoch 3629, Loss: 0.24296394363045692, Final Batch Loss: 0.061793774366378784\n",
      "Epoch 3630, Loss: 0.29829829186201096, Final Batch Loss: 0.07812664657831192\n",
      "Epoch 3631, Loss: 0.2153354650363326, Final Batch Loss: 0.011041595600545406\n",
      "Epoch 3632, Loss: 0.2346537560224533, Final Batch Loss: 0.05573116987943649\n",
      "Epoch 3633, Loss: 0.24932481348514557, Final Batch Loss: 0.07518687099218369\n",
      "Epoch 3634, Loss: 0.306024506688118, Final Batch Loss: 0.10029720515012741\n",
      "Epoch 3635, Loss: 0.4396680071949959, Final Batch Loss: 0.24254535138607025\n",
      "Epoch 3636, Loss: 0.23233382403850555, Final Batch Loss: 0.0369400680065155\n",
      "Epoch 3637, Loss: 0.2582755610346794, Final Batch Loss: 0.0818500891327858\n",
      "Epoch 3638, Loss: 0.2325619701296091, Final Batch Loss: 0.03081570751965046\n",
      "Epoch 3639, Loss: 0.3164394348859787, Final Batch Loss: 0.0765821784734726\n",
      "Epoch 3640, Loss: 0.26411375403404236, Final Batch Loss: 0.12111832946538925\n",
      "Epoch 3641, Loss: 0.2604367174208164, Final Batch Loss: 0.05568673834204674\n",
      "Epoch 3642, Loss: 0.4797934666275978, Final Batch Loss: 0.2745765447616577\n",
      "Epoch 3643, Loss: 0.3304898254573345, Final Batch Loss: 0.05733281001448631\n",
      "Epoch 3644, Loss: 0.599722221493721, Final Batch Loss: 0.16796715557575226\n",
      "Epoch 3645, Loss: 0.3519795248284936, Final Batch Loss: 0.011121184565126896\n",
      "Epoch 3646, Loss: 0.3258860856294632, Final Batch Loss: 0.0808427557349205\n",
      "Epoch 3647, Loss: 0.28523988276720047, Final Batch Loss: 0.11818566173315048\n",
      "Epoch 3648, Loss: 0.3317128121852875, Final Batch Loss: 0.04446110129356384\n",
      "Epoch 3649, Loss: 0.22105823084712029, Final Batch Loss: 0.02520325407385826\n",
      "Epoch 3650, Loss: 0.2207655319944024, Final Batch Loss: 0.010218308307230473\n",
      "Epoch 3651, Loss: 0.32626476883888245, Final Batch Loss: 0.10543997585773468\n",
      "Epoch 3652, Loss: 0.21819917112588882, Final Batch Loss: 0.020928531885147095\n",
      "Epoch 3653, Loss: 0.334401436150074, Final Batch Loss: 0.11386094242334366\n",
      "Epoch 3654, Loss: 0.3551992252469063, Final Batch Loss: 0.16953089833259583\n",
      "Epoch 3655, Loss: 0.2887941114604473, Final Batch Loss: 0.05030504986643791\n",
      "Epoch 3656, Loss: 0.2408673707395792, Final Batch Loss: 0.025108540430665016\n",
      "Epoch 3657, Loss: 0.41959361732006073, Final Batch Loss: 0.23968766629695892\n",
      "Epoch 3658, Loss: 0.46923981606960297, Final Batch Loss: 0.28220659494400024\n",
      "Epoch 3659, Loss: 0.3739568516612053, Final Batch Loss: 0.10849010199308395\n",
      "Epoch 3660, Loss: 0.34453969448804855, Final Batch Loss: 0.07963035255670547\n",
      "Epoch 3661, Loss: 0.5390897989273071, Final Batch Loss: 0.2747690677642822\n",
      "Epoch 3662, Loss: 0.440856970846653, Final Batch Loss: 0.23001103103160858\n",
      "Epoch 3663, Loss: 0.4497944638133049, Final Batch Loss: 0.21113894879817963\n",
      "Epoch 3664, Loss: 0.2778848856687546, Final Batch Loss: 0.08057782799005508\n",
      "Epoch 3665, Loss: 0.2831708714365959, Final Batch Loss: 0.049542754888534546\n",
      "Epoch 3666, Loss: 0.5533646196126938, Final Batch Loss: 0.23178589344024658\n",
      "Epoch 3667, Loss: 0.26890264730900526, Final Batch Loss: 0.01557073276489973\n",
      "Epoch 3668, Loss: 0.36944229900836945, Final Batch Loss: 0.10994847118854523\n",
      "Epoch 3669, Loss: 0.5886709839105606, Final Batch Loss: 0.24715140461921692\n",
      "Epoch 3670, Loss: 0.40523363649845123, Final Batch Loss: 0.1125192642211914\n",
      "Epoch 3671, Loss: 0.2183435633778572, Final Batch Loss: 0.030273690819740295\n",
      "Epoch 3672, Loss: 0.24551474303007126, Final Batch Loss: 0.019149556756019592\n",
      "Epoch 3673, Loss: 0.22524995543062687, Final Batch Loss: 0.020325662568211555\n",
      "Epoch 3674, Loss: 0.40014127269387245, Final Batch Loss: 0.20162951946258545\n",
      "Epoch 3675, Loss: 0.262934606987983, Final Batch Loss: 0.007540133316069841\n",
      "Epoch 3676, Loss: 0.23683364316821098, Final Batch Loss: 0.0507742278277874\n",
      "Epoch 3677, Loss: 0.3452720642089844, Final Batch Loss: 0.12184976041316986\n",
      "Epoch 3678, Loss: 0.2206394337117672, Final Batch Loss: 0.04587041959166527\n",
      "Epoch 3679, Loss: 0.3790149688720703, Final Batch Loss: 0.1642625629901886\n",
      "Epoch 3680, Loss: 0.2712998017668724, Final Batch Loss: 0.08381614834070206\n",
      "Epoch 3681, Loss: 0.3454158529639244, Final Batch Loss: 0.08996690064668655\n",
      "Epoch 3682, Loss: 0.25657482631504536, Final Batch Loss: 0.023411372676491737\n",
      "Epoch 3683, Loss: 0.6217698827385902, Final Batch Loss: 0.39871907234191895\n",
      "Epoch 3684, Loss: 0.20926289167255163, Final Batch Loss: 0.01560187991708517\n",
      "Epoch 3685, Loss: 0.1753025366924703, Final Batch Loss: 0.0050656660459935665\n",
      "Epoch 3686, Loss: 0.3293228968977928, Final Batch Loss: 0.0539325475692749\n",
      "Epoch 3687, Loss: 0.26828308403491974, Final Batch Loss: 0.10612588375806808\n",
      "Epoch 3688, Loss: 0.3675788789987564, Final Batch Loss: 0.19059942662715912\n",
      "Epoch 3689, Loss: 0.2835400924086571, Final Batch Loss: 0.10446266084909439\n",
      "Epoch 3690, Loss: 0.311877004802227, Final Batch Loss: 0.06350638717412949\n",
      "Epoch 3691, Loss: 0.33078227937221527, Final Batch Loss: 0.09764472395181656\n",
      "Epoch 3692, Loss: 0.24485287815332413, Final Batch Loss: 0.09331390261650085\n",
      "Epoch 3693, Loss: 0.5534414201974869, Final Batch Loss: 0.19378530979156494\n",
      "Epoch 3694, Loss: 0.2324648555368185, Final Batch Loss: 0.01696769706904888\n",
      "Epoch 3695, Loss: 0.420561783015728, Final Batch Loss: 0.17946025729179382\n",
      "Epoch 3696, Loss: 0.4187159389257431, Final Batch Loss: 0.20270033180713654\n",
      "Epoch 3697, Loss: 0.2056970912963152, Final Batch Loss: 0.02384093590080738\n",
      "Epoch 3698, Loss: 1.1144898235797882, Final Batch Loss: 0.7836282849311829\n",
      "Epoch 3699, Loss: 0.26035917922854424, Final Batch Loss: 0.033734310418367386\n",
      "Epoch 3700, Loss: 0.5031590610742569, Final Batch Loss: 0.2078944891691208\n",
      "Epoch 3701, Loss: 0.2553658038377762, Final Batch Loss: 0.0981401652097702\n",
      "Epoch 3702, Loss: 0.32449235767126083, Final Batch Loss: 0.08607719093561172\n",
      "Epoch 3703, Loss: 0.4184267669916153, Final Batch Loss: 0.16946415603160858\n",
      "Epoch 3704, Loss: 0.27818189188838005, Final Batch Loss: 0.05440666154026985\n",
      "Epoch 3705, Loss: 0.25237109512090683, Final Batch Loss: 0.019983790814876556\n",
      "Epoch 3706, Loss: 0.2338639721274376, Final Batch Loss: 0.039130568504333496\n",
      "Epoch 3707, Loss: 0.19370928406715393, Final Batch Loss: 0.03560598939657211\n",
      "Epoch 3708, Loss: 0.2316095493733883, Final Batch Loss: 0.055976320058107376\n",
      "Epoch 3709, Loss: 0.21659794822335243, Final Batch Loss: 0.060356516391038895\n",
      "Epoch 3710, Loss: 0.5243596658110619, Final Batch Loss: 0.3454819619655609\n",
      "Epoch 3711, Loss: 0.2845787820406258, Final Batch Loss: 0.0005165156908333302\n",
      "Epoch 3712, Loss: 0.3467501848936081, Final Batch Loss: 0.1705555021762848\n",
      "Epoch 3713, Loss: 0.21508929505944252, Final Batch Loss: 0.04808427020907402\n",
      "Epoch 3714, Loss: 0.30155568569898605, Final Batch Loss: 0.0871642604470253\n",
      "Epoch 3715, Loss: 0.3472200483083725, Final Batch Loss: 0.1434618979692459\n",
      "Epoch 3716, Loss: 0.2695896662771702, Final Batch Loss: 0.0485454685986042\n",
      "Epoch 3717, Loss: 0.33177056908607483, Final Batch Loss: 0.11610819399356842\n",
      "Epoch 3718, Loss: 0.4661579877138138, Final Batch Loss: 0.2566061317920685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3719, Loss: 0.3008636347949505, Final Batch Loss: 0.03398101404309273\n",
      "Epoch 3720, Loss: 0.22341745719313622, Final Batch Loss: 0.006239209324121475\n",
      "Epoch 3721, Loss: 0.3070216067135334, Final Batch Loss: 0.04276787117123604\n",
      "Epoch 3722, Loss: 0.4969669356942177, Final Batch Loss: 0.2893795371055603\n",
      "Epoch 3723, Loss: 0.408914290368557, Final Batch Loss: 0.24500198662281036\n",
      "Epoch 3724, Loss: 0.25318835489451885, Final Batch Loss: 0.02979464642703533\n",
      "Epoch 3725, Loss: 0.5022404491901398, Final Batch Loss: 0.30957281589508057\n",
      "Epoch 3726, Loss: 0.4014413431286812, Final Batch Loss: 0.15247750282287598\n",
      "Epoch 3727, Loss: 0.3183911666274071, Final Batch Loss: 0.09217523038387299\n",
      "Epoch 3728, Loss: 0.2827095426619053, Final Batch Loss: 0.040631379932165146\n",
      "Epoch 3729, Loss: 0.43592606484889984, Final Batch Loss: 0.18492062389850616\n",
      "Epoch 3730, Loss: 0.2560323253273964, Final Batch Loss: 0.03300512582063675\n",
      "Epoch 3731, Loss: 0.476636677980423, Final Batch Loss: 0.2578293979167938\n",
      "Epoch 3732, Loss: 0.1974858045578003, Final Batch Loss: 0.013298757374286652\n",
      "Epoch 3733, Loss: 0.38522128388285637, Final Batch Loss: 0.0327410064637661\n",
      "Epoch 3734, Loss: 0.49982839822769165, Final Batch Loss: 0.13384778797626495\n",
      "Epoch 3735, Loss: 0.2513140793889761, Final Batch Loss: 0.02138838730752468\n",
      "Epoch 3736, Loss: 0.4230240285396576, Final Batch Loss: 0.1492820531129837\n",
      "Epoch 3737, Loss: 0.4605133384466171, Final Batch Loss: 0.18389488756656647\n",
      "Epoch 3738, Loss: 0.25540968403220177, Final Batch Loss: 0.03385244682431221\n",
      "Epoch 3739, Loss: 0.24387161433696747, Final Batch Loss: 0.0778563916683197\n",
      "Epoch 3740, Loss: 0.31323445588350296, Final Batch Loss: 0.12042080610990524\n",
      "Epoch 3741, Loss: 0.25904757529497147, Final Batch Loss: 0.02366657555103302\n",
      "Epoch 3742, Loss: 0.3358710780739784, Final Batch Loss: 0.102761410176754\n",
      "Epoch 3743, Loss: 0.19638505950570107, Final Batch Loss: 0.04374834522604942\n",
      "Epoch 3744, Loss: 0.3273109495639801, Final Batch Loss: 0.1493196040391922\n",
      "Epoch 3745, Loss: 0.3661324456334114, Final Batch Loss: 0.14327120780944824\n",
      "Epoch 3746, Loss: 0.18395056948065758, Final Batch Loss: 0.020437870174646378\n",
      "Epoch 3747, Loss: 0.16836883570067585, Final Batch Loss: 0.0037897273432463408\n",
      "Epoch 3748, Loss: 0.3707136735320091, Final Batch Loss: 0.21652503311634064\n",
      "Epoch 3749, Loss: 0.2225584276020527, Final Batch Loss: 0.02269226685166359\n",
      "Epoch 3750, Loss: 0.39064789563417435, Final Batch Loss: 0.21651047468185425\n",
      "Epoch 3751, Loss: 0.1900552548468113, Final Batch Loss: 0.042598139494657516\n",
      "Epoch 3752, Loss: 0.31098778545856476, Final Batch Loss: 0.12968666851520538\n",
      "Epoch 3753, Loss: 0.24035662040114403, Final Batch Loss: 0.041545283049345016\n",
      "Epoch 3754, Loss: 0.17733481153845787, Final Batch Loss: 0.014466654509305954\n",
      "Epoch 3755, Loss: 0.24089106917381287, Final Batch Loss: 0.04867243766784668\n",
      "Epoch 3756, Loss: 0.4576329439878464, Final Batch Loss: 0.22801704704761505\n",
      "Epoch 3757, Loss: 0.497357077896595, Final Batch Loss: 0.30295512080192566\n",
      "Epoch 3758, Loss: 0.384102039039135, Final Batch Loss: 0.1644696593284607\n",
      "Epoch 3759, Loss: 0.27055769972503185, Final Batch Loss: 0.02756509743630886\n",
      "Epoch 3760, Loss: 0.39096345379948616, Final Batch Loss: 0.04025993123650551\n",
      "Epoch 3761, Loss: 0.25177597999572754, Final Batch Loss: 0.009802371263504028\n",
      "Epoch 3762, Loss: 0.25755793415009975, Final Batch Loss: 0.018847351893782616\n",
      "Epoch 3763, Loss: 0.23490752279758453, Final Batch Loss: 0.06341279298067093\n",
      "Epoch 3764, Loss: 0.39410804212093353, Final Batch Loss: 0.20591898262500763\n",
      "Epoch 3765, Loss: 0.20803115516901016, Final Batch Loss: 0.02030506730079651\n",
      "Epoch 3766, Loss: 0.39634091407060623, Final Batch Loss: 0.1500178426504135\n",
      "Epoch 3767, Loss: 0.23106691986322403, Final Batch Loss: 0.035161055624485016\n",
      "Epoch 3768, Loss: 0.2185445837676525, Final Batch Loss: 0.052758391946554184\n",
      "Epoch 3769, Loss: 0.344075970351696, Final Batch Loss: 0.14517304301261902\n",
      "Epoch 3770, Loss: 0.29348401725292206, Final Batch Loss: 0.09421661496162415\n",
      "Epoch 3771, Loss: 0.29965224117040634, Final Batch Loss: 0.07867742329835892\n",
      "Epoch 3772, Loss: 0.2642587646842003, Final Batch Loss: 0.07413269579410553\n",
      "Epoch 3773, Loss: 0.25251147523522377, Final Batch Loss: 0.0311770997941494\n",
      "Epoch 3774, Loss: 0.19564174488186836, Final Batch Loss: 0.02660072222352028\n",
      "Epoch 3775, Loss: 0.18410700745880604, Final Batch Loss: 0.00413178838789463\n",
      "Epoch 3776, Loss: 0.7015587761998177, Final Batch Loss: 0.45998692512512207\n",
      "Epoch 3777, Loss: 0.2724693641066551, Final Batch Loss: 0.1086568608880043\n",
      "Epoch 3778, Loss: 0.5810692310333252, Final Batch Loss: 0.35523366928100586\n",
      "Epoch 3779, Loss: 0.31896792352199554, Final Batch Loss: 0.1430293619632721\n",
      "Epoch 3780, Loss: 0.5419201403856277, Final Batch Loss: 0.35998299717903137\n",
      "Epoch 3781, Loss: 0.21431300602853298, Final Batch Loss: 0.026468688622117043\n",
      "Epoch 3782, Loss: 0.404593363404274, Final Batch Loss: 0.1782231628894806\n",
      "Epoch 3783, Loss: 0.21822942234575748, Final Batch Loss: 0.029345961287617683\n",
      "Epoch 3784, Loss: 0.22127461060881615, Final Batch Loss: 0.048823434859514236\n",
      "Epoch 3785, Loss: 0.3469199612736702, Final Batch Loss: 0.10305763781070709\n",
      "Epoch 3786, Loss: 0.14795072935521603, Final Batch Loss: 0.010674914345145226\n",
      "Epoch 3787, Loss: 0.20425162557512522, Final Batch Loss: 0.012779341079294682\n",
      "Epoch 3788, Loss: 0.26701071858406067, Final Batch Loss: 0.09370341151952744\n",
      "Epoch 3789, Loss: 0.3286256194114685, Final Batch Loss: 0.1750461459159851\n",
      "Epoch 3790, Loss: 0.26436376571655273, Final Batch Loss: 0.05025418847799301\n",
      "Epoch 3791, Loss: 0.49406833946704865, Final Batch Loss: 0.18439967930316925\n",
      "Epoch 3792, Loss: 0.5867581516504288, Final Batch Loss: 0.3197738528251648\n",
      "Epoch 3793, Loss: 0.3807276338338852, Final Batch Loss: 0.12326231598854065\n",
      "Epoch 3794, Loss: 0.6280510500073433, Final Batch Loss: 0.42700672149658203\n",
      "Epoch 3795, Loss: 0.36451616883277893, Final Batch Loss: 0.13414132595062256\n",
      "Epoch 3796, Loss: 0.8269260078668594, Final Batch Loss: 0.571704089641571\n",
      "Epoch 3797, Loss: 0.5986528769135475, Final Batch Loss: 0.2902432680130005\n",
      "Epoch 3798, Loss: 0.5931088179349899, Final Batch Loss: 0.3227355182170868\n",
      "Epoch 3799, Loss: 0.3626188114285469, Final Batch Loss: 0.036441706120967865\n",
      "Epoch 3800, Loss: 0.3814506512135267, Final Batch Loss: 0.030162109062075615\n",
      "Epoch 3801, Loss: 0.5845207571983337, Final Batch Loss: 0.20285752415657043\n",
      "Epoch 3802, Loss: 0.4287271797657013, Final Batch Loss: 0.13796596229076385\n",
      "Epoch 3803, Loss: 0.27126670628786087, Final Batch Loss: 0.0453009307384491\n",
      "Epoch 3804, Loss: 0.5003910809755325, Final Batch Loss: 0.20298072695732117\n",
      "Epoch 3805, Loss: 0.3176497220993042, Final Batch Loss: 0.06663558632135391\n",
      "Epoch 3806, Loss: 0.3173511251807213, Final Batch Loss: 0.17101149260997772\n",
      "Epoch 3807, Loss: 0.2527189590036869, Final Batch Loss: 0.0539713017642498\n",
      "Epoch 3808, Loss: 0.25264493748545647, Final Batch Loss: 0.028190258890390396\n",
      "Epoch 3809, Loss: 0.29952598363161087, Final Batch Loss: 0.08605930209159851\n",
      "Epoch 3810, Loss: 0.4394611679017544, Final Batch Loss: 0.25535398721694946\n",
      "Epoch 3811, Loss: 0.4619542062282562, Final Batch Loss: 0.2615986764431\n",
      "Epoch 3812, Loss: 0.4845506623387337, Final Batch Loss: 0.27237680554389954\n",
      "Epoch 3813, Loss: 0.340332162566483, Final Batch Loss: 0.009305533953011036\n",
      "Epoch 3814, Loss: 0.5274075418710709, Final Batch Loss: 0.252183198928833\n",
      "Epoch 3815, Loss: 0.270376056432724, Final Batch Loss: 0.0690394714474678\n",
      "Epoch 3816, Loss: 0.41078615188598633, Final Batch Loss: 0.19227446615695953\n",
      "Epoch 3817, Loss: 0.29945985972881317, Final Batch Loss: 0.06345783174037933\n",
      "Epoch 3818, Loss: 0.26312950998544693, Final Batch Loss: 0.02189014106988907\n",
      "Epoch 3819, Loss: 0.42986875027418137, Final Batch Loss: 0.20239080488681793\n",
      "Epoch 3820, Loss: 0.21906666085124016, Final Batch Loss: 0.039939794689416885\n",
      "Epoch 3821, Loss: 0.4199577569961548, Final Batch Loss: 0.173924058675766\n",
      "Epoch 3822, Loss: 0.24493681639432907, Final Batch Loss: 0.0671166181564331\n",
      "Epoch 3823, Loss: 0.1603348534554243, Final Batch Loss: 0.010096123442053795\n",
      "Epoch 3824, Loss: 0.2579363603144884, Final Batch Loss: 0.018904300406575203\n",
      "Epoch 3825, Loss: 0.27648070082068443, Final Batch Loss: 0.03475554659962654\n",
      "Epoch 3826, Loss: 0.5304810777306557, Final Batch Loss: 0.35313788056373596\n",
      "Epoch 3827, Loss: 0.24898619204759598, Final Batch Loss: 0.08824165165424347\n",
      "Epoch 3828, Loss: 0.2974538132548332, Final Batch Loss: 0.15820905566215515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3829, Loss: 0.24990633875131607, Final Batch Loss: 0.07207835465669632\n",
      "Epoch 3830, Loss: 0.24955618381500244, Final Batch Loss: 0.044364821165800095\n",
      "Epoch 3831, Loss: 0.25993745028972626, Final Batch Loss: 0.09120126068592072\n",
      "Epoch 3832, Loss: 0.2904606759548187, Final Batch Loss: 0.020183861255645752\n",
      "Epoch 3833, Loss: 0.20489759929478168, Final Batch Loss: 0.02596944011747837\n",
      "Epoch 3834, Loss: 0.3233816474676132, Final Batch Loss: 0.12700584530830383\n",
      "Epoch 3835, Loss: 0.2744336798787117, Final Batch Loss: 0.07718491554260254\n",
      "Epoch 3836, Loss: 0.23568155616521835, Final Batch Loss: 0.0766940638422966\n",
      "Epoch 3837, Loss: 0.2531541958451271, Final Batch Loss: 0.024621032178401947\n",
      "Epoch 3838, Loss: 0.16888862196356058, Final Batch Loss: 0.015585535205900669\n",
      "Epoch 3839, Loss: 0.18776369001716375, Final Batch Loss: 0.011235847137868404\n",
      "Epoch 3840, Loss: 0.2768063023686409, Final Batch Loss: 0.07856706529855728\n",
      "Epoch 3841, Loss: 0.30054377019405365, Final Batch Loss: 0.1567206084728241\n",
      "Epoch 3842, Loss: 0.2285434491932392, Final Batch Loss: 0.04413789138197899\n",
      "Epoch 3843, Loss: 0.19109099730849266, Final Batch Loss: 0.05650559812784195\n",
      "Epoch 3844, Loss: 0.2493676319718361, Final Batch Loss: 0.04811565577983856\n",
      "Epoch 3845, Loss: 0.21598820388317108, Final Batch Loss: 0.046033233404159546\n",
      "Epoch 3846, Loss: 0.405483677983284, Final Batch Loss: 0.24803678691387177\n",
      "Epoch 3847, Loss: 0.21555596590042114, Final Batch Loss: 0.060767337679862976\n",
      "Epoch 3848, Loss: 0.36954809725284576, Final Batch Loss: 0.16660304367542267\n",
      "Epoch 3849, Loss: 0.2663648761808872, Final Batch Loss: 0.0567413754761219\n",
      "Epoch 3850, Loss: 0.5081276372075081, Final Batch Loss: 0.31855061650276184\n",
      "Epoch 3851, Loss: 0.24262428656220436, Final Batch Loss: 0.044017527252435684\n",
      "Epoch 3852, Loss: 0.282913351431489, Final Batch Loss: 0.021900394931435585\n",
      "Epoch 3853, Loss: 0.26273687183856964, Final Batch Loss: 0.06009355187416077\n",
      "Epoch 3854, Loss: 0.2688541579991579, Final Batch Loss: 0.02385690249502659\n",
      "Epoch 3855, Loss: 0.29383185505867004, Final Batch Loss: 0.07262028753757477\n",
      "Epoch 3856, Loss: 0.23946842551231384, Final Batch Loss: 0.03090778738260269\n",
      "Epoch 3857, Loss: 0.4617621824145317, Final Batch Loss: 0.23750801384449005\n",
      "Epoch 3858, Loss: 0.28680747747421265, Final Batch Loss: 0.07830002903938293\n",
      "Epoch 3859, Loss: 0.29975881054997444, Final Batch Loss: 0.022223178297281265\n",
      "Epoch 3860, Loss: 0.33466384559869766, Final Batch Loss: 0.036243923008441925\n",
      "Epoch 3861, Loss: 0.43050114065408707, Final Batch Loss: 0.1144304871559143\n",
      "Epoch 3862, Loss: 0.27342384308576584, Final Batch Loss: 0.11692045629024506\n",
      "Epoch 3863, Loss: 0.2329258769750595, Final Batch Loss: 0.032147377729415894\n",
      "Epoch 3864, Loss: 0.21073491126298904, Final Batch Loss: 0.04867267608642578\n",
      "Epoch 3865, Loss: 0.5138064622879028, Final Batch Loss: 0.3591080904006958\n",
      "Epoch 3866, Loss: 0.2043502228334546, Final Batch Loss: 0.013409477658569813\n",
      "Epoch 3867, Loss: 0.22258770931512117, Final Batch Loss: 0.013911155052483082\n",
      "Epoch 3868, Loss: 0.2300371304154396, Final Batch Loss: 0.07029874622821808\n",
      "Epoch 3869, Loss: 0.24892371147871017, Final Batch Loss: 0.03607296943664551\n",
      "Epoch 3870, Loss: 0.3089175373315811, Final Batch Loss: 0.10915648192167282\n",
      "Epoch 3871, Loss: 0.39769190922379494, Final Batch Loss: 0.2650054395198822\n",
      "Epoch 3872, Loss: 0.2617411520332098, Final Batch Loss: 0.028270607814192772\n",
      "Epoch 3873, Loss: 0.221293356269598, Final Batch Loss: 0.016830097883939743\n",
      "Epoch 3874, Loss: 0.24139684438705444, Final Batch Loss: 0.06986413896083832\n",
      "Epoch 3875, Loss: 0.28268791176378727, Final Batch Loss: 0.024406472221016884\n",
      "Epoch 3876, Loss: 0.3171355724334717, Final Batch Loss: 0.14393985271453857\n",
      "Epoch 3877, Loss: 0.37701112776994705, Final Batch Loss: 0.18350578844547272\n",
      "Epoch 3878, Loss: 0.294987753033638, Final Batch Loss: 0.07037313282489777\n",
      "Epoch 3879, Loss: 0.19526399625465274, Final Batch Loss: 0.005040719639509916\n",
      "Epoch 3880, Loss: 0.260080773383379, Final Batch Loss: 0.04380225017666817\n",
      "Epoch 3881, Loss: 0.37726788967847824, Final Batch Loss: 0.13084471225738525\n",
      "Epoch 3882, Loss: 0.3647371679544449, Final Batch Loss: 0.10465896874666214\n",
      "Epoch 3883, Loss: 0.2630733251571655, Final Batch Loss: 0.07054878771305084\n",
      "Epoch 3884, Loss: 0.18864941783249378, Final Batch Loss: 0.029634958133101463\n",
      "Epoch 3885, Loss: 0.20270223170518875, Final Batch Loss: 0.07058229297399521\n",
      "Epoch 3886, Loss: 0.24719608947634697, Final Batch Loss: 0.047057438641786575\n",
      "Epoch 3887, Loss: 0.22703230381011963, Final Batch Loss: 0.09144288301467896\n",
      "Epoch 3888, Loss: 0.23568453919142485, Final Batch Loss: 0.011781695298850536\n",
      "Epoch 3889, Loss: 0.14560391195118427, Final Batch Loss: 0.01693286933004856\n",
      "Epoch 3890, Loss: 0.20262236520648003, Final Batch Loss: 0.055413320660591125\n",
      "Epoch 3891, Loss: 0.3706165999174118, Final Batch Loss: 0.21629828214645386\n",
      "Epoch 3892, Loss: 0.14442975644487888, Final Batch Loss: 0.0016851817490532994\n",
      "Epoch 3893, Loss: 0.24005114007741213, Final Batch Loss: 0.007241611368954182\n",
      "Epoch 3894, Loss: 0.22483495622873306, Final Batch Loss: 0.0645027831196785\n",
      "Epoch 3895, Loss: 0.1703086756169796, Final Batch Loss: 0.020181193947792053\n",
      "Epoch 3896, Loss: 0.23283659666776657, Final Batch Loss: 0.04243069887161255\n",
      "Epoch 3897, Loss: 0.1978862751275301, Final Batch Loss: 0.02310042269527912\n",
      "Epoch 3898, Loss: 0.15394281968474388, Final Batch Loss: 0.03381088003516197\n",
      "Epoch 3899, Loss: 0.4010658636689186, Final Batch Loss: 0.22263050079345703\n",
      "Epoch 3900, Loss: 0.20800945366499946, Final Batch Loss: 0.0006863271701149642\n",
      "Epoch 3901, Loss: 0.30726795829832554, Final Batch Loss: 0.028262311592698097\n",
      "Epoch 3902, Loss: 0.37410686165094376, Final Batch Loss: 0.11584115028381348\n",
      "Epoch 3903, Loss: 0.20560089498758316, Final Batch Loss: 0.02714449167251587\n",
      "Epoch 3904, Loss: 0.25758717209100723, Final Batch Loss: 0.07694977521896362\n",
      "Epoch 3905, Loss: 0.21431232430040836, Final Batch Loss: 0.010455580428242683\n",
      "Epoch 3906, Loss: 0.3263833820819855, Final Batch Loss: 0.12061244249343872\n",
      "Epoch 3907, Loss: 0.3339723199605942, Final Batch Loss: 0.0997728705406189\n",
      "Epoch 3908, Loss: 0.28540538251399994, Final Batch Loss: 0.02376202493906021\n",
      "Epoch 3909, Loss: 0.26523396372795105, Final Batch Loss: 0.083311066031456\n",
      "Epoch 3910, Loss: 0.2095097452402115, Final Batch Loss: 0.04657791554927826\n",
      "Epoch 3911, Loss: 0.2033662311732769, Final Batch Loss: 0.03727630153298378\n",
      "Epoch 3912, Loss: 0.22083264589309692, Final Batch Loss: 0.04560045152902603\n",
      "Epoch 3913, Loss: 0.25419197231531143, Final Batch Loss: 0.10650445520877838\n",
      "Epoch 3914, Loss: 0.2618768811225891, Final Batch Loss: 0.058209970593452454\n",
      "Epoch 3915, Loss: 0.5403173714876175, Final Batch Loss: 0.26380977034568787\n",
      "Epoch 3916, Loss: 0.23804732412099838, Final Batch Loss: 0.07847487926483154\n",
      "Epoch 3917, Loss: 0.3714943900704384, Final Batch Loss: 0.11665652692317963\n",
      "Epoch 3918, Loss: 0.2846355140209198, Final Batch Loss: 0.03289179503917694\n",
      "Epoch 3919, Loss: 0.4492057040333748, Final Batch Loss: 0.2152199000120163\n",
      "Epoch 3920, Loss: 0.24642515555024147, Final Batch Loss: 0.048338305205106735\n",
      "Epoch 3921, Loss: 0.2846880815923214, Final Batch Loss: 0.03785720840096474\n",
      "Epoch 3922, Loss: 0.2328415960073471, Final Batch Loss: 0.03981485962867737\n",
      "Epoch 3923, Loss: 0.24571686261333525, Final Batch Loss: 0.0025748612824827433\n",
      "Epoch 3924, Loss: 0.22874801978468895, Final Batch Loss: 0.02372245118021965\n",
      "Epoch 3925, Loss: 0.24482989870011806, Final Batch Loss: 0.023591918870806694\n",
      "Epoch 3926, Loss: 0.30117012560367584, Final Batch Loss: 0.11363304406404495\n",
      "Epoch 3927, Loss: 0.2315271757543087, Final Batch Loss: 0.05917304381728172\n",
      "Epoch 3928, Loss: 0.1654875073581934, Final Batch Loss: 0.013053828850388527\n",
      "Epoch 3929, Loss: 0.2364552542567253, Final Batch Loss: 0.021685168147087097\n",
      "Epoch 3930, Loss: 0.2945702373981476, Final Batch Loss: 0.13788370788097382\n",
      "Epoch 3931, Loss: 0.3466249331831932, Final Batch Loss: 0.15751901268959045\n",
      "Epoch 3932, Loss: 0.2112790383398533, Final Batch Loss: 0.022906620055437088\n",
      "Epoch 3933, Loss: 0.1845093285664916, Final Batch Loss: 0.012842117808759212\n",
      "Epoch 3934, Loss: 0.23799636587500572, Final Batch Loss: 0.055340107530355453\n",
      "Epoch 3935, Loss: 0.34919171780347824, Final Batch Loss: 0.143645241856575\n",
      "Epoch 3936, Loss: 0.29078951105475426, Final Batch Loss: 0.027063626796007156\n",
      "Epoch 3937, Loss: 0.2111015599220991, Final Batch Loss: 0.02844882570207119\n",
      "Epoch 3938, Loss: 0.29762133583426476, Final Batch Loss: 0.023101944476366043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3939, Loss: 0.39346993714571, Final Batch Loss: 0.13586850464344025\n",
      "Epoch 3940, Loss: 0.38902512937784195, Final Batch Loss: 0.24382437765598297\n",
      "Epoch 3941, Loss: 0.24436748027801514, Final Batch Loss: 0.08954920619726181\n",
      "Epoch 3942, Loss: 0.34642504900693893, Final Batch Loss: 0.16057895123958588\n",
      "Epoch 3943, Loss: 0.15464164316654205, Final Batch Loss: 0.02964838221669197\n",
      "Epoch 3944, Loss: 0.2473931387066841, Final Batch Loss: 0.04444829374551773\n",
      "Epoch 3945, Loss: 0.13027093349955976, Final Batch Loss: 0.0039010883774608374\n",
      "Epoch 3946, Loss: 0.4204500690102577, Final Batch Loss: 0.18574337661266327\n",
      "Epoch 3947, Loss: 0.34274136275053024, Final Batch Loss: 0.16369104385375977\n",
      "Epoch 3948, Loss: 0.18344059959053993, Final Batch Loss: 0.04279780387878418\n",
      "Epoch 3949, Loss: 0.2106301337480545, Final Batch Loss: 0.03494250774383545\n",
      "Epoch 3950, Loss: 0.18895582109689713, Final Batch Loss: 0.02180246263742447\n",
      "Epoch 3951, Loss: 0.33650636672973633, Final Batch Loss: 0.12311581522226334\n",
      "Epoch 3952, Loss: 0.17336983419954777, Final Batch Loss: 0.02178196795284748\n",
      "Epoch 3953, Loss: 0.2346673384308815, Final Batch Loss: 0.0784769058227539\n",
      "Epoch 3954, Loss: 0.22901925444602966, Final Batch Loss: 0.07124483585357666\n",
      "Epoch 3955, Loss: 0.3233818858861923, Final Batch Loss: 0.14055386185646057\n",
      "Epoch 3956, Loss: 0.25444732792675495, Final Batch Loss: 0.028108352795243263\n",
      "Epoch 3957, Loss: 0.20467785373330116, Final Batch Loss: 0.04423722252249718\n",
      "Epoch 3958, Loss: 0.17724297381937504, Final Batch Loss: 0.019110092893242836\n",
      "Epoch 3959, Loss: 0.19849447533488274, Final Batch Loss: 0.046997830271720886\n",
      "Epoch 3960, Loss: 0.2393062263727188, Final Batch Loss: 0.0707564428448677\n",
      "Epoch 3961, Loss: 0.24743161723017693, Final Batch Loss: 0.12254223227500916\n",
      "Epoch 3962, Loss: 0.415945865213871, Final Batch Loss: 0.24210159480571747\n",
      "Epoch 3963, Loss: 0.30307648330926895, Final Batch Loss: 0.07262807339429855\n",
      "Epoch 3964, Loss: 0.3045380525290966, Final Batch Loss: 0.05241965875029564\n",
      "Epoch 3965, Loss: 0.4746078699827194, Final Batch Loss: 0.17174787819385529\n",
      "Epoch 3966, Loss: 0.2958107814192772, Final Batch Loss: 0.11436086148023605\n",
      "Epoch 3967, Loss: 0.33021584153175354, Final Batch Loss: 0.18136847019195557\n",
      "Epoch 3968, Loss: 0.5560735613107681, Final Batch Loss: 0.3195912837982178\n",
      "Epoch 3969, Loss: 0.312772617675364, Final Batch Loss: 0.009130493737757206\n",
      "Epoch 3970, Loss: 0.5624951049685478, Final Batch Loss: 0.011924810707569122\n",
      "Epoch 3971, Loss: 0.9593169987201691, Final Batch Loss: 0.38469019532203674\n",
      "Epoch 3972, Loss: 0.44144172593951225, Final Batch Loss: 0.01599765196442604\n",
      "Epoch 3973, Loss: 0.31284577026963234, Final Batch Loss: 0.026479844003915787\n",
      "Epoch 3974, Loss: 0.5898259282112122, Final Batch Loss: 0.31552332639694214\n",
      "Epoch 3975, Loss: 0.3258608430624008, Final Batch Loss: 0.03262701630592346\n",
      "Epoch 3976, Loss: 0.3249591141939163, Final Batch Loss: 0.06322546303272247\n",
      "Epoch 3977, Loss: 0.5695097297430038, Final Batch Loss: 0.34364715218544006\n",
      "Epoch 3978, Loss: 0.28617124259471893, Final Batch Loss: 0.08730901777744293\n",
      "Epoch 3979, Loss: 0.5277513861656189, Final Batch Loss: 0.2352980077266693\n",
      "Epoch 3980, Loss: 0.5545058250427246, Final Batch Loss: 0.3193245828151703\n",
      "Epoch 3981, Loss: 0.3441308066248894, Final Batch Loss: 0.11353395134210587\n",
      "Epoch 3982, Loss: 0.5709825605154037, Final Batch Loss: 0.24963335692882538\n",
      "Epoch 3983, Loss: 0.2933873478323221, Final Batch Loss: 0.015653857961297035\n",
      "Epoch 3984, Loss: 0.4668610244989395, Final Batch Loss: 0.20270249247550964\n",
      "Epoch 3985, Loss: 0.40417151153087616, Final Batch Loss: 0.1731344759464264\n",
      "Epoch 3986, Loss: 0.24081318080425262, Final Batch Loss: 0.03958815336227417\n",
      "Epoch 3987, Loss: 0.2295747771859169, Final Batch Loss: 0.017313696444034576\n",
      "Epoch 3988, Loss: 0.4058884456753731, Final Batch Loss: 0.16064417362213135\n",
      "Epoch 3989, Loss: 0.3231617957353592, Final Batch Loss: 0.06656443327665329\n",
      "Epoch 3990, Loss: 0.24328504502773285, Final Batch Loss: 0.05417991429567337\n",
      "Epoch 3991, Loss: 0.259090231731534, Final Batch Loss: 0.01570928283035755\n",
      "Epoch 3992, Loss: 0.4327961876988411, Final Batch Loss: 0.20520775020122528\n",
      "Epoch 3993, Loss: 0.2937740460038185, Final Batch Loss: 0.15414051711559296\n",
      "Epoch 3994, Loss: 0.2380261830985546, Final Batch Loss: 0.031191926449537277\n",
      "Epoch 3995, Loss: 0.8081098794937134, Final Batch Loss: 0.5786524415016174\n",
      "Epoch 3996, Loss: 0.24591438472270966, Final Batch Loss: 0.07805714756250381\n",
      "Epoch 3997, Loss: 0.2736458480358124, Final Batch Loss: 0.10110169649124146\n",
      "Epoch 3998, Loss: 0.43172698467969894, Final Batch Loss: 0.20038199424743652\n",
      "Epoch 3999, Loss: 0.25001130998134613, Final Batch Loss: 0.08921647816896439\n",
      "Epoch 4000, Loss: 0.2272086050361395, Final Batch Loss: 0.026245160028338432\n",
      "Epoch 4001, Loss: 0.29640447348356247, Final Batch Loss: 0.120539590716362\n",
      "Epoch 4002, Loss: 0.25818260945379734, Final Batch Loss: 0.0281898844987154\n",
      "Epoch 4003, Loss: 0.19304869137704372, Final Batch Loss: 0.009114978834986687\n",
      "Epoch 4004, Loss: 0.2069813758134842, Final Batch Loss: 0.037094846367836\n",
      "Epoch 4005, Loss: 0.32027432322502136, Final Batch Loss: 0.08054006844758987\n",
      "Epoch 4006, Loss: 0.2254377268254757, Final Batch Loss: 0.04349817708134651\n",
      "Epoch 4007, Loss: 0.3374798782169819, Final Batch Loss: 0.18570064008235931\n",
      "Epoch 4008, Loss: 0.23632127977907658, Final Batch Loss: 0.026522742584347725\n",
      "Epoch 4009, Loss: 0.2743411175906658, Final Batch Loss: 0.039924707263708115\n",
      "Epoch 4010, Loss: 0.4755266159772873, Final Batch Loss: 0.22209322452545166\n",
      "Epoch 4011, Loss: 0.25447767972946167, Final Batch Loss: 0.09089477360248566\n",
      "Epoch 4012, Loss: 0.3147810697555542, Final Batch Loss: 0.13938617706298828\n",
      "Epoch 4013, Loss: 0.229363102465868, Final Batch Loss: 0.051475610584020615\n",
      "Epoch 4014, Loss: 0.20885026827454567, Final Batch Loss: 0.0545571930706501\n",
      "Epoch 4015, Loss: 0.4009139835834503, Final Batch Loss: 0.23356761038303375\n",
      "Epoch 4016, Loss: 0.3471805825829506, Final Batch Loss: 0.1865813285112381\n",
      "Epoch 4017, Loss: 0.3838033303618431, Final Batch Loss: 0.25871261954307556\n",
      "Epoch 4018, Loss: 0.26187550090253353, Final Batch Loss: 0.02153007499873638\n",
      "Epoch 4019, Loss: 0.18225325271487236, Final Batch Loss: 0.03861040621995926\n",
      "Epoch 4020, Loss: 0.36699189990758896, Final Batch Loss: 0.12148178368806839\n",
      "Epoch 4021, Loss: 0.2672719582915306, Final Batch Loss: 0.04715505987405777\n",
      "Epoch 4022, Loss: 0.285156462341547, Final Batch Loss: 0.1516227275133133\n",
      "Epoch 4023, Loss: 0.20139408065006137, Final Batch Loss: 0.004194758366793394\n",
      "Epoch 4024, Loss: 0.41455700248479843, Final Batch Loss: 0.055424369871616364\n",
      "Epoch 4025, Loss: 0.4810458868741989, Final Batch Loss: 0.12745365500450134\n",
      "Epoch 4026, Loss: 0.39403728395700455, Final Batch Loss: 0.10029976069927216\n",
      "Epoch 4027, Loss: 0.31145417131483555, Final Batch Loss: 0.019552865996956825\n",
      "Epoch 4028, Loss: 0.2931877225637436, Final Batch Loss: 0.11037903279066086\n",
      "Epoch 4029, Loss: 0.30871766060590744, Final Batch Loss: 0.13953366875648499\n",
      "Epoch 4030, Loss: 0.27380610816180706, Final Batch Loss: 0.017755692824721336\n",
      "Epoch 4031, Loss: 0.25892142951488495, Final Batch Loss: 0.02754465490579605\n",
      "Epoch 4032, Loss: 0.27367011830210686, Final Batch Loss: 0.031297940760850906\n",
      "Epoch 4033, Loss: 0.3740934580564499, Final Batch Loss: 0.15625226497650146\n",
      "Epoch 4034, Loss: 0.2314547337591648, Final Batch Loss: 0.05512366071343422\n",
      "Epoch 4035, Loss: 0.22541404142975807, Final Batch Loss: 0.05838543549180031\n",
      "Epoch 4036, Loss: 0.24629593268036842, Final Batch Loss: 0.043713223189115524\n",
      "Epoch 4037, Loss: 0.21066395565867424, Final Batch Loss: 0.041957128793001175\n",
      "Epoch 4038, Loss: 0.45527108013629913, Final Batch Loss: 0.21722440421581268\n",
      "Epoch 4039, Loss: 0.2320492211729288, Final Batch Loss: 0.016708651557564735\n",
      "Epoch 4040, Loss: 0.3069341480731964, Final Batch Loss: 0.1305316984653473\n",
      "Epoch 4041, Loss: 0.535813719034195, Final Batch Loss: 0.36762064695358276\n",
      "Epoch 4042, Loss: 0.30305635184049606, Final Batch Loss: 0.1411125212907791\n",
      "Epoch 4043, Loss: 0.1920344103127718, Final Batch Loss: 0.01742113195359707\n",
      "Epoch 4044, Loss: 0.3454262614250183, Final Batch Loss: 0.09763786941766739\n",
      "Epoch 4045, Loss: 0.25166119635105133, Final Batch Loss: 0.05520451068878174\n",
      "Epoch 4046, Loss: 0.6248437613248825, Final Batch Loss: 0.20027217268943787\n",
      "Epoch 4047, Loss: 0.4949199706315994, Final Batch Loss: 0.18700917065143585\n",
      "Epoch 4048, Loss: 0.542338639497757, Final Batch Loss: 0.24379931390285492\n",
      "Epoch 4049, Loss: 0.30648093670606613, Final Batch Loss: 0.03540191054344177\n",
      "Epoch 4050, Loss: 0.29844314604997635, Final Batch Loss: 0.10283207893371582\n",
      "Epoch 4051, Loss: 0.29478811100125313, Final Batch Loss: 0.04668416455388069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4052, Loss: 0.4417055621743202, Final Batch Loss: 0.17564792931079865\n",
      "Epoch 4053, Loss: 0.31454405188560486, Final Batch Loss: 0.12819762527942657\n",
      "Epoch 4054, Loss: 0.3399297297000885, Final Batch Loss: 0.10817128419876099\n",
      "Epoch 4055, Loss: 0.3263111114501953, Final Batch Loss: 0.1665296107530594\n",
      "Epoch 4056, Loss: 0.2815793752670288, Final Batch Loss: 0.07870414108037949\n",
      "Epoch 4057, Loss: 0.42593420669436455, Final Batch Loss: 0.2005281150341034\n",
      "Epoch 4058, Loss: 0.21465444192290306, Final Batch Loss: 0.02752428874373436\n",
      "Epoch 4059, Loss: 0.30408595502376556, Final Batch Loss: 0.08326715975999832\n",
      "Epoch 4060, Loss: 0.7957188859581947, Final Batch Loss: 0.6044062376022339\n",
      "Epoch 4061, Loss: 0.20027392730116844, Final Batch Loss: 0.04589309170842171\n",
      "Epoch 4062, Loss: 0.1898029912263155, Final Batch Loss: 0.00998605228960514\n",
      "Epoch 4063, Loss: 0.1839556060731411, Final Batch Loss: 0.03803615644574165\n",
      "Epoch 4064, Loss: 0.33004122227430344, Final Batch Loss: 0.07766664028167725\n",
      "Epoch 4065, Loss: 0.2572988122701645, Final Batch Loss: 0.03521355986595154\n",
      "Epoch 4066, Loss: 0.4408109560608864, Final Batch Loss: 0.236080601811409\n",
      "Epoch 4067, Loss: 0.26779651641845703, Final Batch Loss: 0.03630591928958893\n",
      "Epoch 4068, Loss: 0.21501341834664345, Final Batch Loss: 0.01737847551703453\n",
      "Epoch 4069, Loss: 0.17130451370030642, Final Batch Loss: 0.0028019296005368233\n",
      "Epoch 4070, Loss: 0.26063382625579834, Final Batch Loss: 0.07638704776763916\n",
      "Epoch 4071, Loss: 0.38135921210050583, Final Batch Loss: 0.20876125991344452\n",
      "Epoch 4072, Loss: 0.17708292789757252, Final Batch Loss: 0.022371144965291023\n",
      "Epoch 4073, Loss: 0.2868209332227707, Final Batch Loss: 0.10874025523662567\n",
      "Epoch 4074, Loss: 0.34223952889442444, Final Batch Loss: 0.19451110064983368\n",
      "Epoch 4075, Loss: 0.38526618480682373, Final Batch Loss: 0.20920896530151367\n",
      "Epoch 4076, Loss: 0.760169006884098, Final Batch Loss: 0.5617998838424683\n",
      "Epoch 4077, Loss: 0.1860105711966753, Final Batch Loss: 0.02588689513504505\n",
      "Epoch 4078, Loss: 0.3230367824435234, Final Batch Loss: 0.06596812605857849\n",
      "Epoch 4079, Loss: 0.523475669324398, Final Batch Loss: 0.2691079080104828\n",
      "Epoch 4080, Loss: 0.31839890591800213, Final Batch Loss: 0.017394816502928734\n",
      "Epoch 4081, Loss: 0.23662078380584717, Final Batch Loss: 0.0098600834608078\n",
      "Epoch 4082, Loss: 0.3180169053375721, Final Batch Loss: 0.057649437338113785\n",
      "Epoch 4083, Loss: 0.38315603882074356, Final Batch Loss: 0.14912763237953186\n",
      "Epoch 4084, Loss: 0.18917169608175755, Final Batch Loss: 0.017237098887562752\n",
      "Epoch 4085, Loss: 0.22489773854613304, Final Batch Loss: 0.044833142310380936\n",
      "Epoch 4086, Loss: 0.23677759617567062, Final Batch Loss: 0.08720436692237854\n",
      "Epoch 4087, Loss: 0.30689022690057755, Final Batch Loss: 0.13138200342655182\n",
      "Epoch 4088, Loss: 0.2376914694905281, Final Batch Loss: 0.017313532531261444\n",
      "Epoch 4089, Loss: 0.2875574715435505, Final Batch Loss: 0.04699122905731201\n",
      "Epoch 4090, Loss: 0.42488785833120346, Final Batch Loss: 0.21651382744312286\n",
      "Epoch 4091, Loss: 0.24723677337169647, Final Batch Loss: 0.06336799263954163\n",
      "Epoch 4092, Loss: 0.46212517470121384, Final Batch Loss: 0.19065256416797638\n",
      "Epoch 4093, Loss: 0.3031560853123665, Final Batch Loss: 0.032523684203624725\n",
      "Epoch 4094, Loss: 0.2442324198782444, Final Batch Loss: 0.05953897163271904\n",
      "Epoch 4095, Loss: 0.23225219547748566, Final Batch Loss: 0.018030807375907898\n",
      "Epoch 4096, Loss: 0.22222350537776947, Final Batch Loss: 0.0318126380443573\n",
      "Epoch 4097, Loss: 0.31954894214868546, Final Batch Loss: 0.12791931629180908\n",
      "Epoch 4098, Loss: 0.20158902555704117, Final Batch Loss: 0.03291182965040207\n",
      "Epoch 4099, Loss: 0.1754059181548655, Final Batch Loss: 0.007514199707657099\n",
      "Epoch 4100, Loss: 0.2244283682666719, Final Batch Loss: 0.005376187618821859\n",
      "Epoch 4101, Loss: 0.2648957930505276, Final Batch Loss: 0.0593813918530941\n",
      "Epoch 4102, Loss: 0.20899436622858047, Final Batch Loss: 0.0615716278553009\n",
      "Epoch 4103, Loss: 0.13760103657841682, Final Batch Loss: 0.006693493574857712\n",
      "Epoch 4104, Loss: 0.17215373925864697, Final Batch Loss: 0.021570300683379173\n",
      "Epoch 4105, Loss: 0.20837267115712166, Final Batch Loss: 0.02753676474094391\n",
      "Epoch 4106, Loss: 0.3514541909098625, Final Batch Loss: 0.0793883353471756\n",
      "Epoch 4107, Loss: 0.241233691573143, Final Batch Loss: 0.07340308278799057\n",
      "Epoch 4108, Loss: 0.20119354128837585, Final Batch Loss: 0.054421424865722656\n",
      "Epoch 4109, Loss: 0.20070584118366241, Final Batch Loss: 0.03957948088645935\n",
      "Epoch 4110, Loss: 0.23064915463328362, Final Batch Loss: 0.052377063781023026\n",
      "Epoch 4111, Loss: 0.36135121434926987, Final Batch Loss: 0.14955095946788788\n",
      "Epoch 4112, Loss: 0.25919438898563385, Final Batch Loss: 0.10132056474685669\n",
      "Epoch 4113, Loss: 0.41560687124729156, Final Batch Loss: 0.27225247025489807\n",
      "Epoch 4114, Loss: 0.2222791314125061, Final Batch Loss: 0.04559791088104248\n",
      "Epoch 4115, Loss: 0.24267826229333878, Final Batch Loss: 0.08695623278617859\n",
      "Epoch 4116, Loss: 0.40118201822042465, Final Batch Loss: 0.20284442603588104\n",
      "Epoch 4117, Loss: 0.17622797563672066, Final Batch Loss: 0.027113083750009537\n",
      "Epoch 4118, Loss: 0.1606347227934748, Final Batch Loss: 0.003887567901983857\n",
      "Epoch 4119, Loss: 0.1789283361285925, Final Batch Loss: 0.006147904321551323\n",
      "Epoch 4120, Loss: 0.24937941879034042, Final Batch Loss: 0.07914388179779053\n",
      "Epoch 4121, Loss: 0.2742862030863762, Final Batch Loss: 0.14214351773262024\n",
      "Epoch 4122, Loss: 0.26729748398065567, Final Batch Loss: 0.091127410531044\n",
      "Epoch 4123, Loss: 0.21434144536033273, Final Batch Loss: 0.006882837507873774\n",
      "Epoch 4124, Loss: 0.2082094307988882, Final Batch Loss: 0.004589764401316643\n",
      "Epoch 4125, Loss: 0.19258349016308784, Final Batch Loss: 0.03593764081597328\n",
      "Epoch 4126, Loss: 0.21397410705685616, Final Batch Loss: 0.03513599932193756\n",
      "Epoch 4127, Loss: 0.14806913523352705, Final Batch Loss: 0.00035545541322790086\n",
      "Epoch 4128, Loss: 0.2042352855205536, Final Batch Loss: 0.04136952757835388\n",
      "Epoch 4129, Loss: 0.1467324811965227, Final Batch Loss: 0.018565649166703224\n",
      "Epoch 4130, Loss: 0.19061730057001114, Final Batch Loss: 0.0379793643951416\n",
      "Epoch 4131, Loss: 0.2353542074561119, Final Batch Loss: 0.04790591448545456\n",
      "Epoch 4132, Loss: 0.16438519675284624, Final Batch Loss: 0.014126581139862537\n",
      "Epoch 4133, Loss: 0.13006198103539646, Final Batch Loss: 0.0020556196104735136\n",
      "Epoch 4134, Loss: 0.33270540088415146, Final Batch Loss: 0.23764614760875702\n",
      "Epoch 4135, Loss: 0.2890304625034332, Final Batch Loss: 0.07816413044929504\n",
      "Epoch 4136, Loss: 0.7682475596666336, Final Batch Loss: 0.5483132004737854\n",
      "Epoch 4137, Loss: 0.17869733646512032, Final Batch Loss: 0.02941838651895523\n",
      "Epoch 4138, Loss: 0.18658603355288506, Final Batch Loss: 0.022446122020483017\n",
      "Epoch 4139, Loss: 0.1859555495902896, Final Batch Loss: 0.011323566548526287\n",
      "Epoch 4140, Loss: 0.21101799607276917, Final Batch Loss: 0.06850320100784302\n",
      "Epoch 4141, Loss: 0.4063149094581604, Final Batch Loss: 0.17870168387889862\n",
      "Epoch 4142, Loss: 0.1794571578502655, Final Batch Loss: 0.017776697874069214\n",
      "Epoch 4143, Loss: 0.15552817564457655, Final Batch Loss: 0.011627527885138988\n",
      "Epoch 4144, Loss: 0.18235192075371742, Final Batch Loss: 0.053036920726299286\n",
      "Epoch 4145, Loss: 0.19497600756585598, Final Batch Loss: 0.025508379563689232\n",
      "Epoch 4146, Loss: 0.2920326143503189, Final Batch Loss: 0.15484973788261414\n",
      "Epoch 4147, Loss: 0.2419267427176237, Final Batch Loss: 0.022541766986250877\n",
      "Epoch 4148, Loss: 0.2502499744296074, Final Batch Loss: 0.070425845682621\n",
      "Epoch 4149, Loss: 0.2790732830762863, Final Batch Loss: 0.12824693322181702\n",
      "Epoch 4150, Loss: 0.29242341220378876, Final Batch Loss: 0.09410037100315094\n",
      "Epoch 4151, Loss: 0.38529176265001297, Final Batch Loss: 0.18250280618667603\n",
      "Epoch 4152, Loss: 0.23755640909075737, Final Batch Loss: 0.05282578244805336\n",
      "Epoch 4153, Loss: 0.203403708525002, Final Batch Loss: 0.009490069933235645\n",
      "Epoch 4154, Loss: 0.2058042474091053, Final Batch Loss: 0.023914065212011337\n",
      "Epoch 4155, Loss: 0.3065793737769127, Final Batch Loss: 0.16984781622886658\n",
      "Epoch 4156, Loss: 0.29258164018392563, Final Batch Loss: 0.11264238506555557\n",
      "Epoch 4157, Loss: 0.44766049832105637, Final Batch Loss: 0.25365105271339417\n",
      "Epoch 4158, Loss: 0.2817531153559685, Final Batch Loss: 0.06797528266906738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4159, Loss: 0.32999421656131744, Final Batch Loss: 0.06992486864328384\n",
      "Epoch 4160, Loss: 0.524701688438654, Final Batch Loss: 0.36201703548431396\n",
      "Epoch 4161, Loss: 0.20659405179321766, Final Batch Loss: 0.022879624739289284\n",
      "Epoch 4162, Loss: 0.35771339386701584, Final Batch Loss: 0.21908491849899292\n",
      "Epoch 4163, Loss: 0.16643957048654556, Final Batch Loss: 0.03642497584223747\n",
      "Epoch 4164, Loss: 0.2614792324602604, Final Batch Loss: 0.0962718054652214\n",
      "Epoch 4165, Loss: 0.2227383591234684, Final Batch Loss: 0.009228590875864029\n",
      "Epoch 4166, Loss: 0.22023622505366802, Final Batch Loss: 0.020281000062823296\n",
      "Epoch 4167, Loss: 0.23939267545938492, Final Batch Loss: 0.048404961824417114\n",
      "Epoch 4168, Loss: 0.3202250599861145, Final Batch Loss: 0.14246951043605804\n",
      "Epoch 4169, Loss: 0.21234238520264626, Final Batch Loss: 0.029613371938467026\n",
      "Epoch 4170, Loss: 0.29608825594186783, Final Batch Loss: 0.03190230578184128\n",
      "Epoch 4171, Loss: 0.23122946545481682, Final Batch Loss: 0.04865175858139992\n",
      "Epoch 4172, Loss: 0.33778323978185654, Final Batch Loss: 0.14443638920783997\n",
      "Epoch 4173, Loss: 0.3877839297056198, Final Batch Loss: 0.19999246299266815\n",
      "Epoch 4174, Loss: 0.24104222655296326, Final Batch Loss: 0.099537193775177\n",
      "Epoch 4175, Loss: 0.27955780923366547, Final Batch Loss: 0.07061392068862915\n",
      "Epoch 4176, Loss: 0.33415765315294266, Final Batch Loss: 0.12853378057479858\n",
      "Epoch 4177, Loss: 0.2852031961083412, Final Batch Loss: 0.06323840469121933\n",
      "Epoch 4178, Loss: 0.3448103740811348, Final Batch Loss: 0.13407303392887115\n",
      "Epoch 4179, Loss: 0.41774046421051025, Final Batch Loss: 0.17801930010318756\n",
      "Epoch 4180, Loss: 0.31367768347263336, Final Batch Loss: 0.10759386420249939\n",
      "Epoch 4181, Loss: 0.23206512443721294, Final Batch Loss: 0.02571178786456585\n",
      "Epoch 4182, Loss: 0.3909074291586876, Final Batch Loss: 0.1684301793575287\n",
      "Epoch 4183, Loss: 0.2695305645465851, Final Batch Loss: 0.058710530400276184\n",
      "Epoch 4184, Loss: 0.2526177205145359, Final Batch Loss: 0.104733407497406\n",
      "Epoch 4185, Loss: 0.4204856902360916, Final Batch Loss: 0.23101806640625\n",
      "Epoch 4186, Loss: 0.1984124481678009, Final Batch Loss: 0.03169407695531845\n",
      "Epoch 4187, Loss: 0.23087031207978725, Final Batch Loss: 0.030829256400465965\n",
      "Epoch 4188, Loss: 0.2127821482717991, Final Batch Loss: 0.059667330235242844\n",
      "Epoch 4189, Loss: 0.21532048285007477, Final Batch Loss: 0.05544012412428856\n",
      "Epoch 4190, Loss: 0.3377957120537758, Final Batch Loss: 0.2131485491991043\n",
      "Epoch 4191, Loss: 0.2147928774356842, Final Batch Loss: 0.0070944130420684814\n",
      "Epoch 4192, Loss: 0.2300483202561736, Final Batch Loss: 0.01124343927949667\n",
      "Epoch 4193, Loss: 0.2448301762342453, Final Batch Loss: 0.06947240978479385\n",
      "Epoch 4194, Loss: 0.2612234652042389, Final Batch Loss: 0.125291109085083\n",
      "Epoch 4195, Loss: 0.24367821216583252, Final Batch Loss: 0.0427059680223465\n",
      "Epoch 4196, Loss: 0.1441865786910057, Final Batch Loss: 0.01886385679244995\n",
      "Epoch 4197, Loss: 0.13743832055479288, Final Batch Loss: 0.00416517723351717\n",
      "Epoch 4198, Loss: 0.14975260570645332, Final Batch Loss: 0.015807557851076126\n",
      "Epoch 4199, Loss: 0.5835717245936394, Final Batch Loss: 0.4320942759513855\n",
      "Epoch 4200, Loss: 0.15708564966917038, Final Batch Loss: 0.012472108006477356\n",
      "Epoch 4201, Loss: 0.24561700597405434, Final Batch Loss: 0.05306292697787285\n",
      "Epoch 4202, Loss: 0.23447885364294052, Final Batch Loss: 0.1033647358417511\n",
      "Epoch 4203, Loss: 0.18683469854295254, Final Batch Loss: 0.011570034548640251\n",
      "Epoch 4204, Loss: 0.23570901155471802, Final Batch Loss: 0.051299601793289185\n",
      "Epoch 4205, Loss: 0.20847390592098236, Final Batch Loss: 0.04892142117023468\n",
      "Epoch 4206, Loss: 0.15498019382357597, Final Batch Loss: 0.0406854972243309\n",
      "Epoch 4207, Loss: 0.19398146867752075, Final Batch Loss: 0.05753728002309799\n",
      "Epoch 4208, Loss: 0.19809157215058804, Final Batch Loss: 0.006559675559401512\n",
      "Epoch 4209, Loss: 0.2426981795579195, Final Batch Loss: 0.01720990426838398\n",
      "Epoch 4210, Loss: 0.10862804856151342, Final Batch Loss: 0.005765895359218121\n",
      "Epoch 4211, Loss: 0.2049495279788971, Final Batch Loss: 0.015329472720623016\n",
      "Epoch 4212, Loss: 0.35098110511898994, Final Batch Loss: 0.17929644882678986\n",
      "Epoch 4213, Loss: 0.1600167779251933, Final Batch Loss: 0.013569462113082409\n",
      "Epoch 4214, Loss: 0.31102360785007477, Final Batch Loss: 0.16416442394256592\n",
      "Epoch 4215, Loss: 0.20384950563311577, Final Batch Loss: 0.058736857026815414\n",
      "Epoch 4216, Loss: 0.24908499419689178, Final Batch Loss: 0.06415106356143951\n",
      "Epoch 4217, Loss: 0.47209054976701736, Final Batch Loss: 0.21844717860221863\n",
      "Epoch 4218, Loss: 0.4008580520749092, Final Batch Loss: 0.17760246992111206\n",
      "Epoch 4219, Loss: 0.2364460026146844, Final Batch Loss: 0.0019326453329995275\n",
      "Epoch 4220, Loss: 0.44801822304725647, Final Batch Loss: 0.1466333568096161\n",
      "Epoch 4221, Loss: 0.3148433566093445, Final Batch Loss: 0.08718952536582947\n",
      "Epoch 4222, Loss: 0.3158285766839981, Final Batch Loss: 0.08397717773914337\n",
      "Epoch 4223, Loss: 0.40113187208771706, Final Batch Loss: 0.29052215814590454\n",
      "Epoch 4224, Loss: 0.23417827114462852, Final Batch Loss: 0.02764827385544777\n",
      "Epoch 4225, Loss: 0.2584866136312485, Final Batch Loss: 0.08558108657598495\n",
      "Epoch 4226, Loss: 0.33531854301691055, Final Batch Loss: 0.12676818668842316\n",
      "Epoch 4227, Loss: 0.38265104591846466, Final Batch Loss: 0.25252944231033325\n",
      "Epoch 4228, Loss: 0.37210648506879807, Final Batch Loss: 0.11639513820409775\n",
      "Epoch 4229, Loss: 0.3438667356967926, Final Batch Loss: 0.13461388647556305\n",
      "Epoch 4230, Loss: 0.23742740973830223, Final Batch Loss: 0.05830974504351616\n",
      "Epoch 4231, Loss: 0.35275737941265106, Final Batch Loss: 0.11380171775817871\n",
      "Epoch 4232, Loss: 0.2861945629119873, Final Batch Loss: 0.09510985016822815\n",
      "Epoch 4233, Loss: 0.2500617206096649, Final Batch Loss: 0.02320096641778946\n",
      "Epoch 4234, Loss: 0.24999497458338737, Final Batch Loss: 0.05100061371922493\n",
      "Epoch 4235, Loss: 0.17746000178158283, Final Batch Loss: 0.01896863617002964\n",
      "Epoch 4236, Loss: 0.2716764137148857, Final Batch Loss: 0.1047758162021637\n",
      "Epoch 4237, Loss: 0.2141406126320362, Final Batch Loss: 0.06391394138336182\n",
      "Epoch 4238, Loss: 0.18986309133470058, Final Batch Loss: 0.02258533053100109\n",
      "Epoch 4239, Loss: 0.2576472759246826, Final Batch Loss: 0.15223127603530884\n",
      "Epoch 4240, Loss: 0.33184923231601715, Final Batch Loss: 0.1436481922864914\n",
      "Epoch 4241, Loss: 0.1610662378370762, Final Batch Loss: 0.03732490539550781\n",
      "Epoch 4242, Loss: 0.4166872277855873, Final Batch Loss: 0.18364550173282623\n",
      "Epoch 4243, Loss: 0.2971184104681015, Final Batch Loss: 0.0761508122086525\n",
      "Epoch 4244, Loss: 0.3229065164923668, Final Batch Loss: 0.15708346664905548\n",
      "Epoch 4245, Loss: 0.3775917962193489, Final Batch Loss: 0.2172541320323944\n",
      "Epoch 4246, Loss: 0.2738466262817383, Final Batch Loss: 0.08081886172294617\n",
      "Epoch 4247, Loss: 0.26568248867988586, Final Batch Loss: 0.0905010923743248\n",
      "Epoch 4248, Loss: 0.20486407354474068, Final Batch Loss: 0.039101775735616684\n",
      "Epoch 4249, Loss: 0.2198093943297863, Final Batch Loss: 0.053643327206373215\n",
      "Epoch 4250, Loss: 0.183339461684227, Final Batch Loss: 0.03173302859067917\n",
      "Epoch 4251, Loss: 0.15008913725614548, Final Batch Loss: 0.03828364238142967\n",
      "Epoch 4252, Loss: 0.15103544387966394, Final Batch Loss: 0.0096594812348485\n",
      "Epoch 4253, Loss: 0.32841699942946434, Final Batch Loss: 0.16196835041046143\n",
      "Epoch 4254, Loss: 0.19919459149241447, Final Batch Loss: 0.04715673252940178\n",
      "Epoch 4255, Loss: 0.1713108941912651, Final Batch Loss: 0.009578622877597809\n",
      "Epoch 4256, Loss: 0.1389983482658863, Final Batch Loss: 0.009881783276796341\n",
      "Epoch 4257, Loss: 0.13729299418628216, Final Batch Loss: 0.016559714451432228\n",
      "Epoch 4258, Loss: 0.3203107789158821, Final Batch Loss: 0.20404495298862457\n",
      "Epoch 4259, Loss: 0.24158760532736778, Final Batch Loss: 0.10455841571092606\n",
      "Epoch 4260, Loss: 0.1959330439567566, Final Batch Loss: 0.05629865825176239\n",
      "Epoch 4261, Loss: 0.3876449763774872, Final Batch Loss: 0.1721172332763672\n",
      "Epoch 4262, Loss: 0.1441985794226639, Final Batch Loss: 0.0008412317256443202\n",
      "Epoch 4263, Loss: 0.3096282482147217, Final Batch Loss: 0.12233352661132812\n",
      "Epoch 4264, Loss: 0.39683057367801666, Final Batch Loss: 0.24790239334106445\n",
      "Epoch 4265, Loss: 0.23182496428489685, Final Batch Loss: 0.05329035967588425\n",
      "Epoch 4266, Loss: 0.21567421779036522, Final Batch Loss: 0.058780331164598465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4267, Loss: 0.21985203120857477, Final Batch Loss: 0.01181607786566019\n",
      "Epoch 4268, Loss: 0.3835838511586189, Final Batch Loss: 0.21792511641979218\n",
      "Epoch 4269, Loss: 0.25991905480623245, Final Batch Loss: 0.11668950319290161\n",
      "Epoch 4270, Loss: 0.20997748151421547, Final Batch Loss: 0.019589345902204514\n",
      "Epoch 4271, Loss: 0.21346235275268555, Final Batch Loss: 0.06686803698539734\n",
      "Epoch 4272, Loss: 0.3229772597551346, Final Batch Loss: 0.178230881690979\n",
      "Epoch 4273, Loss: 0.3025691919028759, Final Batch Loss: 0.13141919672489166\n",
      "Epoch 4274, Loss: 0.30749653559178114, Final Batch Loss: 0.007013673894107342\n",
      "Epoch 4275, Loss: 0.3472494035959244, Final Batch Loss: 0.08358389139175415\n",
      "Epoch 4276, Loss: 0.3418347053229809, Final Batch Loss: 0.05121057853102684\n",
      "Epoch 4277, Loss: 0.19833000749349594, Final Batch Loss: 0.06281454116106033\n",
      "Epoch 4278, Loss: 0.4160339757800102, Final Batch Loss: 0.2574940621852875\n",
      "Epoch 4279, Loss: 0.3212580643594265, Final Batch Loss: 0.13686427474021912\n",
      "Epoch 4280, Loss: 0.26426585763692856, Final Batch Loss: 0.11199870705604553\n",
      "Epoch 4281, Loss: 0.18934284150600433, Final Batch Loss: 0.014637239277362823\n",
      "Epoch 4282, Loss: 0.1866265945136547, Final Batch Loss: 0.020084206014871597\n",
      "Epoch 4283, Loss: 0.1342104636132717, Final Batch Loss: 0.023174162954092026\n",
      "Epoch 4284, Loss: 0.15535095240920782, Final Batch Loss: 0.011278434656560421\n",
      "Epoch 4285, Loss: 0.17436533980071545, Final Batch Loss: 0.016857465729117393\n",
      "Epoch 4286, Loss: 0.2061484344303608, Final Batch Loss: 0.05989179387688637\n",
      "Epoch 4287, Loss: 0.2506400980055332, Final Batch Loss: 0.12614405155181885\n",
      "Epoch 4288, Loss: 0.15154152736067772, Final Batch Loss: 0.01866544410586357\n",
      "Epoch 4289, Loss: 0.16267598094418645, Final Batch Loss: 0.0029047285206615925\n",
      "Epoch 4290, Loss: 0.2805613838136196, Final Batch Loss: 0.11706247925758362\n",
      "Epoch 4291, Loss: 0.2196495458483696, Final Batch Loss: 0.09680506587028503\n",
      "Epoch 4292, Loss: 0.1931910738348961, Final Batch Loss: 0.018361441791057587\n",
      "Epoch 4293, Loss: 0.25953488051891327, Final Batch Loss: 0.1277473121881485\n",
      "Epoch 4294, Loss: 0.12887493334710598, Final Batch Loss: 0.017713891342282295\n",
      "Epoch 4295, Loss: 0.19849994219839573, Final Batch Loss: 0.024323219433426857\n",
      "Epoch 4296, Loss: 0.3154769688844681, Final Batch Loss: 0.16380518674850464\n",
      "Epoch 4297, Loss: 0.2101885825395584, Final Batch Loss: 0.04862905666232109\n",
      "Epoch 4298, Loss: 0.3879515379667282, Final Batch Loss: 0.08747781813144684\n",
      "Epoch 4299, Loss: 0.1640788298100233, Final Batch Loss: 0.007745256647467613\n",
      "Epoch 4300, Loss: 0.21803472004830837, Final Batch Loss: 0.025237297639250755\n",
      "Epoch 4301, Loss: 0.1923515759408474, Final Batch Loss: 0.04172481223940849\n",
      "Epoch 4302, Loss: 0.2134794108569622, Final Batch Loss: 0.024053681641817093\n",
      "Epoch 4303, Loss: 0.19982563704252243, Final Batch Loss: 0.032831452786922455\n",
      "Epoch 4304, Loss: 0.15658937860280275, Final Batch Loss: 0.013640896417200565\n",
      "Epoch 4305, Loss: 0.25422314554452896, Final Batch Loss: 0.07334265857934952\n",
      "Epoch 4306, Loss: 0.354307621717453, Final Batch Loss: 0.20536813139915466\n",
      "Epoch 4307, Loss: 0.24493243545293808, Final Batch Loss: 0.14017342031002045\n",
      "Epoch 4308, Loss: 0.23096857219934464, Final Batch Loss: 0.09646791219711304\n",
      "Epoch 4309, Loss: 0.14952747523784637, Final Batch Loss: 0.04485562816262245\n",
      "Epoch 4310, Loss: 0.17264632880687714, Final Batch Loss: 0.022719673812389374\n",
      "Epoch 4311, Loss: 0.16401180252432823, Final Batch Loss: 0.04101274535059929\n",
      "Epoch 4312, Loss: 0.1964198499917984, Final Batch Loss: 0.027227379381656647\n",
      "Epoch 4313, Loss: 0.1651172060519457, Final Batch Loss: 0.02167135290801525\n",
      "Epoch 4314, Loss: 0.18343878164887428, Final Batch Loss: 0.005377277731895447\n",
      "Epoch 4315, Loss: 0.15989271365106106, Final Batch Loss: 0.0217412319034338\n",
      "Epoch 4316, Loss: 0.34880687296390533, Final Batch Loss: 0.1322403997182846\n",
      "Epoch 4317, Loss: 0.24640897661447525, Final Batch Loss: 0.11773435771465302\n",
      "Epoch 4318, Loss: 0.18702475354075432, Final Batch Loss: 0.03144563362002373\n",
      "Epoch 4319, Loss: 0.1899726465344429, Final Batch Loss: 0.03353258967399597\n",
      "Epoch 4320, Loss: 0.18938546627759933, Final Batch Loss: 0.042610399425029755\n",
      "Epoch 4321, Loss: 0.17002716520801187, Final Batch Loss: 0.0039221481420099735\n",
      "Epoch 4322, Loss: 0.5045492649078369, Final Batch Loss: 0.2748282849788666\n",
      "Epoch 4323, Loss: 0.20346000604331493, Final Batch Loss: 0.02980424277484417\n",
      "Epoch 4324, Loss: 0.3191393092274666, Final Batch Loss: 0.12345302850008011\n",
      "Epoch 4325, Loss: 0.128405733499676, Final Batch Loss: 0.007213687989860773\n",
      "Epoch 4326, Loss: 0.2594661973416805, Final Batch Loss: 0.06195833906531334\n",
      "Epoch 4327, Loss: 0.29887810349464417, Final Batch Loss: 0.13603901863098145\n",
      "Epoch 4328, Loss: 0.18394812289625406, Final Batch Loss: 0.010805160738527775\n",
      "Epoch 4329, Loss: 0.13993043755181134, Final Batch Loss: 0.002058780984953046\n",
      "Epoch 4330, Loss: 0.22074470669031143, Final Batch Loss: 0.08828339725732803\n",
      "Epoch 4331, Loss: 0.3751038685441017, Final Batch Loss: 0.2125384658575058\n",
      "Epoch 4332, Loss: 0.16643596347421408, Final Batch Loss: 0.006099550984799862\n",
      "Epoch 4333, Loss: 0.27823715284466743, Final Batch Loss: 0.04700068011879921\n",
      "Epoch 4334, Loss: 0.2651568930596113, Final Batch Loss: 0.02133919857442379\n",
      "Epoch 4335, Loss: 0.54622433334589, Final Batch Loss: 0.372388631105423\n",
      "Epoch 4336, Loss: 0.22054488211870193, Final Batch Loss: 0.05143626779317856\n",
      "Epoch 4337, Loss: 0.31259308755397797, Final Batch Loss: 0.08326190710067749\n",
      "Epoch 4338, Loss: 0.33087878953665495, Final Batch Loss: 0.005209486000239849\n",
      "Epoch 4339, Loss: 0.601785197854042, Final Batch Loss: 0.32679688930511475\n",
      "Epoch 4340, Loss: 0.35525862127542496, Final Batch Loss: 0.14898204803466797\n",
      "Epoch 4341, Loss: 0.4420526474714279, Final Batch Loss: 0.25127121806144714\n",
      "Epoch 4342, Loss: 0.2091662660241127, Final Batch Loss: 0.06966893374919891\n",
      "Epoch 4343, Loss: 0.3640890046954155, Final Batch Loss: 0.1776561290025711\n",
      "Epoch 4344, Loss: 0.4408429265022278, Final Batch Loss: 0.27550047636032104\n",
      "Epoch 4345, Loss: 0.22835850529372692, Final Batch Loss: 0.01803574524819851\n",
      "Epoch 4346, Loss: 0.3867660388350487, Final Batch Loss: 0.1075207069516182\n",
      "Epoch 4347, Loss: 0.2774176113307476, Final Batch Loss: 0.03618161752820015\n",
      "Epoch 4348, Loss: 0.3630428910255432, Final Batch Loss: 0.1732732057571411\n",
      "Epoch 4349, Loss: 0.26785846054553986, Final Batch Loss: 0.07363561540842056\n",
      "Epoch 4350, Loss: 0.31583569198846817, Final Batch Loss: 0.07961802184581757\n",
      "Epoch 4351, Loss: 0.3288460671901703, Final Batch Loss: 0.12944814562797546\n",
      "Epoch 4352, Loss: 0.2443677019327879, Final Batch Loss: 0.0148236732929945\n",
      "Epoch 4353, Loss: 0.2669830098748207, Final Batch Loss: 0.009674057364463806\n",
      "Epoch 4354, Loss: 0.22788391448557377, Final Batch Loss: 0.02566029317677021\n",
      "Epoch 4355, Loss: 0.2644757516682148, Final Batch Loss: 0.016783561557531357\n",
      "Epoch 4356, Loss: 0.3063761368393898, Final Batch Loss: 0.11319514364004135\n",
      "Epoch 4357, Loss: 0.7342227324843407, Final Batch Loss: 0.6243074536323547\n",
      "Epoch 4358, Loss: 0.21042321249842644, Final Batch Loss: 0.05597643926739693\n",
      "Epoch 4359, Loss: 0.25382280349731445, Final Batch Loss: 0.04535052180290222\n",
      "Epoch 4360, Loss: 0.39563946425914764, Final Batch Loss: 0.20694230496883392\n",
      "Epoch 4361, Loss: 0.23144053295254707, Final Batch Loss: 0.047470446676015854\n",
      "Epoch 4362, Loss: 0.5237840265035629, Final Batch Loss: 0.3750748038291931\n",
      "Epoch 4363, Loss: 0.2732074558734894, Final Batch Loss: 0.04615937918424606\n",
      "Epoch 4364, Loss: 0.40877170860767365, Final Batch Loss: 0.21005524694919586\n",
      "Epoch 4365, Loss: 0.4105910509824753, Final Batch Loss: 0.12225748598575592\n",
      "Epoch 4366, Loss: 0.40750695765018463, Final Batch Loss: 0.19202396273612976\n",
      "Epoch 4367, Loss: 0.4941198602318764, Final Batch Loss: 0.31557920575141907\n",
      "Epoch 4368, Loss: 0.24136481434106827, Final Batch Loss: 0.06876683235168457\n",
      "Epoch 4369, Loss: 0.2652038298547268, Final Batch Loss: 0.04994949325919151\n",
      "Epoch 4370, Loss: 0.3043035678565502, Final Batch Loss: 0.025942903012037277\n",
      "Epoch 4371, Loss: 0.3172367699444294, Final Batch Loss: 0.05168996378779411\n",
      "Epoch 4372, Loss: 0.38590001314878464, Final Batch Loss: 0.20832352340221405\n",
      "Epoch 4373, Loss: 0.2892078533768654, Final Batch Loss: 0.1349038928747177\n",
      "Epoch 4374, Loss: 0.2090593110769987, Final Batch Loss: 0.026070138439536095\n",
      "Epoch 4375, Loss: 0.9229511991143227, Final Batch Loss: 0.7495375871658325\n",
      "Epoch 4376, Loss: 0.45989543944597244, Final Batch Loss: 0.24215474724769592\n",
      "Epoch 4377, Loss: 0.8536317497491837, Final Batch Loss: 0.14489172399044037\n",
      "Epoch 4378, Loss: 0.5725230593234301, Final Batch Loss: 0.03009459562599659\n",
      "Epoch 4379, Loss: 0.6943880915641785, Final Batch Loss: 0.2816273272037506\n",
      "Epoch 4380, Loss: 0.6855999082326889, Final Batch Loss: 0.2645217478275299\n",
      "Epoch 4381, Loss: 0.8921484798192978, Final Batch Loss: 0.4361821711063385\n",
      "Epoch 4382, Loss: 0.48060403764247894, Final Batch Loss: 0.1488833874464035\n",
      "Epoch 4383, Loss: 0.3513300120830536, Final Batch Loss: 0.07151223719120026\n",
      "Epoch 4384, Loss: 1.0601835995912552, Final Batch Loss: 0.674451470375061\n",
      "Epoch 4385, Loss: 0.4882003962993622, Final Batch Loss: 0.07106511294841766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4386, Loss: 0.3672873377799988, Final Batch Loss: 0.12037702649831772\n",
      "Epoch 4387, Loss: 0.4100022166967392, Final Batch Loss: 0.15255650877952576\n",
      "Epoch 4388, Loss: 0.2967095449566841, Final Batch Loss: 0.0723615363240242\n",
      "Epoch 4389, Loss: 0.3008497916162014, Final Batch Loss: 0.05019731447100639\n",
      "Epoch 4390, Loss: 0.27092763036489487, Final Batch Loss: 0.04529312252998352\n",
      "Epoch 4391, Loss: 0.3033907413482666, Final Batch Loss: 0.07897979021072388\n",
      "Epoch 4392, Loss: 0.3584210127592087, Final Batch Loss: 0.11118307709693909\n",
      "Epoch 4393, Loss: 0.4579700604081154, Final Batch Loss: 0.22907403111457825\n",
      "Epoch 4394, Loss: 0.2718783989548683, Final Batch Loss: 0.038176149129867554\n",
      "Epoch 4395, Loss: 0.22796109318733215, Final Batch Loss: 0.023872949182987213\n",
      "Epoch 4396, Loss: 0.30620164424180984, Final Batch Loss: 0.09471801668405533\n",
      "Epoch 4397, Loss: 0.16801892407238483, Final Batch Loss: 0.031166424974799156\n",
      "Epoch 4398, Loss: 0.24730181507766247, Final Batch Loss: 0.026315046474337578\n",
      "Epoch 4399, Loss: 0.2272295355796814, Final Batch Loss: 0.06365799158811569\n",
      "Epoch 4400, Loss: 0.24716605991125107, Final Batch Loss: 0.06862309575080872\n",
      "Epoch 4401, Loss: 0.36064569652080536, Final Batch Loss: 0.13282687962055206\n",
      "Epoch 4402, Loss: 0.28698597848415375, Final Batch Loss: 0.13983838260173798\n",
      "Epoch 4403, Loss: 0.31529587507247925, Final Batch Loss: 0.12413337081670761\n",
      "Epoch 4404, Loss: 0.3673797771334648, Final Batch Loss: 0.13797815144062042\n",
      "Epoch 4405, Loss: 0.29809944331645966, Final Batch Loss: 0.11058526486158371\n",
      "Epoch 4406, Loss: 0.24976227059960365, Final Batch Loss: 0.05647407844662666\n",
      "Epoch 4407, Loss: 0.20089302398264408, Final Batch Loss: 0.012882525101304054\n",
      "Epoch 4408, Loss: 0.364481583237648, Final Batch Loss: 0.11702115833759308\n",
      "Epoch 4409, Loss: 0.23523251805454493, Final Batch Loss: 0.014141098596155643\n",
      "Epoch 4410, Loss: 0.19801565259695053, Final Batch Loss: 0.027226530015468597\n",
      "Epoch 4411, Loss: 0.20334716513752937, Final Batch Loss: 0.016526836901903152\n",
      "Epoch 4412, Loss: 0.3200245052576065, Final Batch Loss: 0.12892788648605347\n",
      "Epoch 4413, Loss: 0.25799232348799706, Final Batch Loss: 0.053719934076070786\n",
      "Epoch 4414, Loss: 0.17211535945534706, Final Batch Loss: 0.02423623576760292\n",
      "Epoch 4415, Loss: 0.16661017201840878, Final Batch Loss: 0.013624856248497963\n",
      "Epoch 4416, Loss: 0.19532585702836514, Final Batch Loss: 0.021303890272974968\n",
      "Epoch 4417, Loss: 0.19800205994397402, Final Batch Loss: 0.011050400324165821\n",
      "Epoch 4418, Loss: 0.3481350392103195, Final Batch Loss: 0.15500183403491974\n",
      "Epoch 4419, Loss: 0.15583395306020975, Final Batch Loss: 0.009060901589691639\n",
      "Epoch 4420, Loss: 0.19674204103648663, Final Batch Loss: 0.025814561173319817\n",
      "Epoch 4421, Loss: 0.1602375777438283, Final Batch Loss: 0.006672714836895466\n",
      "Epoch 4422, Loss: 0.28094901144504547, Final Batch Loss: 0.09036325663328171\n",
      "Epoch 4423, Loss: 0.24024970084428787, Final Batch Loss: 0.054230496287345886\n",
      "Epoch 4424, Loss: 0.29343386739492416, Final Batch Loss: 0.025921396911144257\n",
      "Epoch 4425, Loss: 0.27563637122511864, Final Batch Loss: 0.051924753934144974\n",
      "Epoch 4426, Loss: 0.2885983604937792, Final Batch Loss: 0.013612957671284676\n",
      "Epoch 4427, Loss: 0.3579217232763767, Final Batch Loss: 0.222584068775177\n",
      "Epoch 4428, Loss: 0.3181736543774605, Final Batch Loss: 0.12498952448368073\n",
      "Epoch 4429, Loss: 0.4438815340399742, Final Batch Loss: 0.20747506618499756\n",
      "Epoch 4430, Loss: 0.18618803285062313, Final Batch Loss: 0.022780047729611397\n",
      "Epoch 4431, Loss: 0.19665874168276787, Final Batch Loss: 0.06262817233800888\n",
      "Epoch 4432, Loss: 0.2510330602526665, Final Batch Loss: 0.0970417857170105\n",
      "Epoch 4433, Loss: 0.3932688310742378, Final Batch Loss: 0.09772348403930664\n",
      "Epoch 4434, Loss: 0.34476839005947113, Final Batch Loss: 0.1816290020942688\n",
      "Epoch 4435, Loss: 0.20731496438384056, Final Batch Loss: 0.05138787627220154\n",
      "Epoch 4436, Loss: 0.2637784406542778, Final Batch Loss: 0.12296836078166962\n",
      "Epoch 4437, Loss: 0.2529875226318836, Final Batch Loss: 0.10988939553499222\n",
      "Epoch 4438, Loss: 0.1597225833684206, Final Batch Loss: 0.017663804814219475\n",
      "Epoch 4439, Loss: 0.15780105954036117, Final Batch Loss: 0.005447795148938894\n",
      "Epoch 4440, Loss: 0.24881316348910332, Final Batch Loss: 0.04409859701991081\n",
      "Epoch 4441, Loss: 0.20200203731656075, Final Batch Loss: 0.021117042750120163\n",
      "Epoch 4442, Loss: 0.18383381515741348, Final Batch Loss: 0.030251003801822662\n",
      "Epoch 4443, Loss: 0.23803645744919777, Final Batch Loss: 0.07230890542268753\n",
      "Epoch 4444, Loss: 0.17407166212797165, Final Batch Loss: 0.01338168978691101\n",
      "Epoch 4445, Loss: 0.21892330422997475, Final Batch Loss: 0.04008052870631218\n",
      "Epoch 4446, Loss: 0.18844453804194927, Final Batch Loss: 0.02701207436621189\n",
      "Epoch 4447, Loss: 0.20699193701148033, Final Batch Loss: 0.05581138655543327\n",
      "Epoch 4448, Loss: 0.3268827311694622, Final Batch Loss: 0.1753193885087967\n",
      "Epoch 4449, Loss: 0.5386691391468048, Final Batch Loss: 0.37340182065963745\n",
      "Epoch 4450, Loss: 0.28029007464647293, Final Batch Loss: 0.10427484661340714\n",
      "Epoch 4451, Loss: 0.2414875663816929, Final Batch Loss: 0.04466385021805763\n",
      "Epoch 4452, Loss: 0.3154178038239479, Final Batch Loss: 0.12517546117305756\n",
      "Epoch 4453, Loss: 0.3511950820684433, Final Batch Loss: 0.14605869352817535\n",
      "Epoch 4454, Loss: 0.22681353613734245, Final Batch Loss: 0.04836412891745567\n",
      "Epoch 4455, Loss: 0.2786123901605606, Final Batch Loss: 0.11365650594234467\n",
      "Epoch 4456, Loss: 0.20277885720133781, Final Batch Loss: 0.07628657668828964\n",
      "Epoch 4457, Loss: 0.4781365916132927, Final Batch Loss: 0.3433569073677063\n",
      "Epoch 4458, Loss: 0.2868095263838768, Final Batch Loss: 0.10188765823841095\n",
      "Epoch 4459, Loss: 0.2835725136101246, Final Batch Loss: 0.12602464854717255\n",
      "Epoch 4460, Loss: 0.18640849739313126, Final Batch Loss: 0.040662772953510284\n",
      "Epoch 4461, Loss: 0.2721630558371544, Final Batch Loss: 0.12514936923980713\n",
      "Epoch 4462, Loss: 0.2390347719192505, Final Batch Loss: 0.06000837683677673\n",
      "Epoch 4463, Loss: 0.16398769803345203, Final Batch Loss: 0.010909022763371468\n",
      "Epoch 4464, Loss: 0.24994229339063168, Final Batch Loss: 0.13238690793514252\n",
      "Epoch 4465, Loss: 0.23401018232107162, Final Batch Loss: 0.06930564343929291\n",
      "Epoch 4466, Loss: 0.18280114606022835, Final Batch Loss: 0.04043383523821831\n",
      "Epoch 4467, Loss: 0.24917659163475037, Final Batch Loss: 0.026164136826992035\n",
      "Epoch 4468, Loss: 0.16139826644212008, Final Batch Loss: 0.013313216157257557\n",
      "Epoch 4469, Loss: 0.27689504623413086, Final Batch Loss: 0.06735512614250183\n",
      "Epoch 4470, Loss: 0.17715253680944443, Final Batch Loss: 0.03938387706875801\n",
      "Epoch 4471, Loss: 0.2793353572487831, Final Batch Loss: 0.08519873768091202\n",
      "Epoch 4472, Loss: 0.28081610053777695, Final Batch Loss: 0.09895173460245132\n",
      "Epoch 4473, Loss: 0.2194095030426979, Final Batch Loss: 0.10893590748310089\n",
      "Epoch 4474, Loss: 0.3033677712082863, Final Batch Loss: 0.13119487464427948\n",
      "Epoch 4475, Loss: 0.24321768432855606, Final Batch Loss: 0.04784788191318512\n",
      "Epoch 4476, Loss: 0.3085911050438881, Final Batch Loss: 0.055995792150497437\n",
      "Epoch 4477, Loss: 0.2627275846898556, Final Batch Loss: 0.03127974644303322\n",
      "Epoch 4478, Loss: 0.28045104444026947, Final Batch Loss: 0.13905978202819824\n",
      "Epoch 4479, Loss: 0.15424494165927172, Final Batch Loss: 0.012902242131531239\n",
      "Epoch 4480, Loss: 0.21976269409060478, Final Batch Loss: 0.060601141303777695\n",
      "Epoch 4481, Loss: 0.16981003805994987, Final Batch Loss: 0.028526071459054947\n",
      "Epoch 4482, Loss: 0.22468377277255058, Final Batch Loss: 0.019169006496667862\n",
      "Epoch 4483, Loss: 0.1395094022154808, Final Batch Loss: 0.0138801708817482\n",
      "Epoch 4484, Loss: 0.19750060886144638, Final Batch Loss: 0.043209418654441833\n",
      "Epoch 4485, Loss: 0.6405260935425758, Final Batch Loss: 0.5177921652793884\n",
      "Epoch 4486, Loss: 0.20891300216317177, Final Batch Loss: 0.05698965862393379\n",
      "Epoch 4487, Loss: 0.392148032784462, Final Batch Loss: 0.24115118384361267\n",
      "Epoch 4488, Loss: 0.3242023214697838, Final Batch Loss: 0.13058005273342133\n",
      "Epoch 4489, Loss: 0.26057145558297634, Final Batch Loss: 0.02926572971045971\n",
      "Epoch 4490, Loss: 0.19473717361688614, Final Batch Loss: 0.020412638783454895\n",
      "Epoch 4491, Loss: 0.3519533947110176, Final Batch Loss: 0.16363240778446198\n",
      "Epoch 4492, Loss: 0.17374315112829208, Final Batch Loss: 0.01853220909833908\n",
      "Epoch 4493, Loss: 0.6162974536418915, Final Batch Loss: 0.4530230164527893\n",
      "Epoch 4494, Loss: 0.6184154376387596, Final Batch Loss: 0.4103372097015381\n",
      "Epoch 4495, Loss: 0.3761497959494591, Final Batch Loss: 0.21114377677440643\n",
      "Epoch 4496, Loss: 0.2809387519955635, Final Batch Loss: 0.035974688827991486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4497, Loss: 0.34674860537052155, Final Batch Loss: 0.1911475658416748\n",
      "Epoch 4498, Loss: 0.27531222254037857, Final Batch Loss: 0.08853881061077118\n",
      "Epoch 4499, Loss: 0.27764661610126495, Final Batch Loss: 0.09710202366113663\n",
      "Epoch 4500, Loss: 0.3398411348462105, Final Batch Loss: 0.07447347790002823\n",
      "Epoch 4501, Loss: 0.3409449830651283, Final Batch Loss: 0.11737401783466339\n",
      "Epoch 4502, Loss: 0.3113831803202629, Final Batch Loss: 0.09695363789796829\n",
      "Epoch 4503, Loss: 0.20599961280822754, Final Batch Loss: 0.05331127345561981\n",
      "Epoch 4504, Loss: 0.19820035807788372, Final Batch Loss: 0.023701762780547142\n",
      "Epoch 4505, Loss: 0.20976159535348415, Final Batch Loss: 0.007130226120352745\n",
      "Epoch 4506, Loss: 0.5275391265749931, Final Batch Loss: 0.35749807953834534\n",
      "Epoch 4507, Loss: 0.16113269375637174, Final Batch Loss: 0.006009094882756472\n",
      "Epoch 4508, Loss: 0.2582598403096199, Final Batch Loss: 0.0971977487206459\n",
      "Epoch 4509, Loss: 0.1859649159014225, Final Batch Loss: 0.06485792249441147\n",
      "Epoch 4510, Loss: 0.3188868463039398, Final Batch Loss: 0.13536964356899261\n",
      "Epoch 4511, Loss: 0.27643033117055893, Final Batch Loss: 0.11583170294761658\n",
      "Epoch 4512, Loss: 0.14703806629404426, Final Batch Loss: 0.006360990460962057\n",
      "Epoch 4513, Loss: 0.3467956632375717, Final Batch Loss: 0.15174204111099243\n",
      "Epoch 4514, Loss: 0.18292703106999397, Final Batch Loss: 0.04285110533237457\n",
      "Epoch 4515, Loss: 0.3912171795964241, Final Batch Loss: 0.24115364253520966\n",
      "Epoch 4516, Loss: 0.16727297473698854, Final Batch Loss: 0.01463752705603838\n",
      "Epoch 4517, Loss: 0.24421744793653488, Final Batch Loss: 0.0523994043469429\n",
      "Epoch 4518, Loss: 0.21133284457027912, Final Batch Loss: 0.02857881225645542\n",
      "Epoch 4519, Loss: 0.3165737986564636, Final Batch Loss: 0.11100182682275772\n",
      "Epoch 4520, Loss: 0.3612036667764187, Final Batch Loss: 0.19330309331417084\n",
      "Epoch 4521, Loss: 0.34441983327269554, Final Batch Loss: 0.23859252035617828\n",
      "Epoch 4522, Loss: 0.11686194874346256, Final Batch Loss: 0.008548630401492119\n",
      "Epoch 4523, Loss: 0.17186549492180347, Final Batch Loss: 0.028941502794623375\n",
      "Epoch 4524, Loss: 0.3202020078897476, Final Batch Loss: 0.0726102665066719\n",
      "Epoch 4525, Loss: 0.4226289354264736, Final Batch Loss: 0.29426640272140503\n",
      "Epoch 4526, Loss: 0.19125035032629967, Final Batch Loss: 0.03548267483711243\n",
      "Epoch 4527, Loss: 0.24815262109041214, Final Batch Loss: 0.08940654993057251\n",
      "Epoch 4528, Loss: 0.14447571989148855, Final Batch Loss: 0.014398879371583462\n",
      "Epoch 4529, Loss: 0.12370894383639097, Final Batch Loss: 0.0057562245056033134\n",
      "Epoch 4530, Loss: 0.28496207296848297, Final Batch Loss: 0.18110355734825134\n",
      "Epoch 4531, Loss: 0.18279344029724598, Final Batch Loss: 0.021348679438233376\n",
      "Epoch 4532, Loss: 0.16380386240780354, Final Batch Loss: 0.01835269294679165\n",
      "Epoch 4533, Loss: 0.26514654234051704, Final Batch Loss: 0.1347728967666626\n",
      "Epoch 4534, Loss: 0.15243274252861738, Final Batch Loss: 0.013101468794047832\n",
      "Epoch 4535, Loss: 0.16550485976040363, Final Batch Loss: 0.021336054429411888\n",
      "Epoch 4536, Loss: 0.26704783737659454, Final Batch Loss: 0.07552649080753326\n",
      "Epoch 4537, Loss: 0.21143173798918724, Final Batch Loss: 0.018076103180646896\n",
      "Epoch 4538, Loss: 0.19770711660385132, Final Batch Loss: 0.05801359564065933\n",
      "Epoch 4539, Loss: 0.12903988175094128, Final Batch Loss: 0.018706703558564186\n",
      "Epoch 4540, Loss: 0.12230034731328487, Final Batch Loss: 0.02339099906384945\n",
      "Epoch 4541, Loss: 0.19693800434470177, Final Batch Loss: 0.04164452850818634\n",
      "Epoch 4542, Loss: 0.19336430355906487, Final Batch Loss: 0.046593498438596725\n",
      "Epoch 4543, Loss: 0.47447390854358673, Final Batch Loss: 0.31485486030578613\n",
      "Epoch 4544, Loss: 0.17873413488268852, Final Batch Loss: 0.01863608881831169\n",
      "Epoch 4545, Loss: 0.2494787909090519, Final Batch Loss: 0.11702046543359756\n",
      "Epoch 4546, Loss: 0.21720990724861622, Final Batch Loss: 0.019201183691620827\n",
      "Epoch 4547, Loss: 0.18259987980127335, Final Batch Loss: 0.03387380763888359\n",
      "Epoch 4548, Loss: 0.2100752666592598, Final Batch Loss: 0.06352322548627853\n",
      "Epoch 4549, Loss: 0.19746782258152962, Final Batch Loss: 0.058169301599264145\n",
      "Epoch 4550, Loss: 0.19617094960995018, Final Batch Loss: 0.003072434337809682\n",
      "Epoch 4551, Loss: 0.23805137537419796, Final Batch Loss: 0.024257345125079155\n",
      "Epoch 4552, Loss: 0.2750099077820778, Final Batch Loss: 0.068198062479496\n",
      "Epoch 4553, Loss: 0.21514350920915604, Final Batch Loss: 0.05072012543678284\n",
      "Epoch 4554, Loss: 0.1871607005596161, Final Batch Loss: 0.06269261240959167\n",
      "Epoch 4555, Loss: 0.18657252565026283, Final Batch Loss: 0.0073597244918346405\n",
      "Epoch 4556, Loss: 0.21248790621757507, Final Batch Loss: 0.07757625728845596\n",
      "Epoch 4557, Loss: 0.15034483931958675, Final Batch Loss: 0.012080194428563118\n",
      "Epoch 4558, Loss: 0.19222869724035263, Final Batch Loss: 0.08088332414627075\n",
      "Epoch 4559, Loss: 0.20332931727170944, Final Batch Loss: 0.09172310680150986\n",
      "Epoch 4560, Loss: 0.15371029451489449, Final Batch Loss: 0.061424363404512405\n",
      "Epoch 4561, Loss: 0.1678486606106162, Final Batch Loss: 0.014751928858458996\n",
      "Epoch 4562, Loss: 0.4499167129397392, Final Batch Loss: 0.27796152234077454\n",
      "Epoch 4563, Loss: 0.16939906030893326, Final Batch Loss: 0.02349857985973358\n",
      "Epoch 4564, Loss: 0.25084441155195236, Final Batch Loss: 0.08241448551416397\n",
      "Epoch 4565, Loss: 0.2564693093299866, Final Batch Loss: 0.08508744090795517\n",
      "Epoch 4566, Loss: 0.3688457980751991, Final Batch Loss: 0.17962443828582764\n",
      "Epoch 4567, Loss: 0.24066824465990067, Final Batch Loss: 0.062430888414382935\n",
      "Epoch 4568, Loss: 0.19798250496387482, Final Batch Loss: 0.09997250884771347\n",
      "Epoch 4569, Loss: 0.13904698565602303, Final Batch Loss: 0.05029537156224251\n",
      "Epoch 4570, Loss: 0.2440348044037819, Final Batch Loss: 0.13121967017650604\n",
      "Epoch 4571, Loss: 0.20498877484351397, Final Batch Loss: 0.0130803557112813\n",
      "Epoch 4572, Loss: 0.19164330139756203, Final Batch Loss: 0.006450902670621872\n",
      "Epoch 4573, Loss: 0.2142230048775673, Final Batch Loss: 0.10234319418668747\n",
      "Epoch 4574, Loss: 0.13167711347341537, Final Batch Loss: 0.025598838925361633\n",
      "Epoch 4575, Loss: 0.21034300699830055, Final Batch Loss: 0.060883235186338425\n",
      "Epoch 4576, Loss: 0.19333605095744133, Final Batch Loss: 0.06406496465206146\n",
      "Epoch 4577, Loss: 0.19347605854272842, Final Batch Loss: 0.04245224595069885\n",
      "Epoch 4578, Loss: 0.28344934433698654, Final Batch Loss: 0.12012773007154465\n",
      "Epoch 4579, Loss: 0.2546541467308998, Final Batch Loss: 0.11468887329101562\n",
      "Epoch 4580, Loss: 0.26110459864139557, Final Batch Loss: 0.08293324708938599\n",
      "Epoch 4581, Loss: 0.3997892215847969, Final Batch Loss: 0.16047783195972443\n",
      "Epoch 4582, Loss: 0.21883313730359077, Final Batch Loss: 0.006486866623163223\n",
      "Epoch 4583, Loss: 0.43022579699754715, Final Batch Loss: 0.28426751494407654\n",
      "Epoch 4584, Loss: 0.2201663702726364, Final Batch Loss: 0.04552498459815979\n",
      "Epoch 4585, Loss: 0.26213427260518074, Final Batch Loss: 0.05801675096154213\n",
      "Epoch 4586, Loss: 0.243960402905941, Final Batch Loss: 0.08759701997041702\n",
      "Epoch 4587, Loss: 0.20964619517326355, Final Batch Loss: 0.0643918588757515\n",
      "Epoch 4588, Loss: 0.18112022895365953, Final Batch Loss: 0.012498912401497364\n",
      "Epoch 4589, Loss: 0.23885277286171913, Final Batch Loss: 0.05249048396945\n",
      "Epoch 4590, Loss: 0.3435114622116089, Final Batch Loss: 0.16065293550491333\n",
      "Epoch 4591, Loss: 0.2512514144182205, Final Batch Loss: 0.1142595037817955\n",
      "Epoch 4592, Loss: 0.37807758152484894, Final Batch Loss: 0.11139653623104095\n",
      "Epoch 4593, Loss: 0.47256192564964294, Final Batch Loss: 0.18244381248950958\n",
      "Epoch 4594, Loss: 0.2928282655775547, Final Batch Loss: 0.05232442542910576\n",
      "Epoch 4595, Loss: 0.31903941184282303, Final Batch Loss: 0.1456006020307541\n",
      "Epoch 4596, Loss: 0.18862905725836754, Final Batch Loss: 0.04083951562643051\n",
      "Epoch 4597, Loss: 0.16120729967951775, Final Batch Loss: 0.01953716203570366\n",
      "Epoch 4598, Loss: 0.2049165889620781, Final Batch Loss: 0.0584108904004097\n",
      "Epoch 4599, Loss: 0.25874795764684677, Final Batch Loss: 0.1136159896850586\n",
      "Epoch 4600, Loss: 0.18181218579411507, Final Batch Loss: 0.039460260421037674\n",
      "Epoch 4601, Loss: 0.22281038016080856, Final Batch Loss: 0.09974604845046997\n",
      "Epoch 4602, Loss: 0.3948449343442917, Final Batch Loss: 0.24474115669727325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4603, Loss: 0.2046114206314087, Final Batch Loss: 0.10029895603656769\n",
      "Epoch 4604, Loss: 0.2061837688088417, Final Batch Loss: 0.0532427653670311\n",
      "Epoch 4605, Loss: 0.1580549692735076, Final Batch Loss: 0.013713008724153042\n",
      "Epoch 4606, Loss: 0.21271383576095104, Final Batch Loss: 0.024988515302538872\n",
      "Epoch 4607, Loss: 0.352896086871624, Final Batch Loss: 0.1393059492111206\n",
      "Epoch 4608, Loss: 0.20147307962179184, Final Batch Loss: 0.03901170939207077\n",
      "Epoch 4609, Loss: 0.2607291229069233, Final Batch Loss: 0.1350591629743576\n",
      "Epoch 4610, Loss: 0.19457115232944489, Final Batch Loss: 0.041713275015354156\n",
      "Epoch 4611, Loss: 0.19032463058829308, Final Batch Loss: 0.028936166316270828\n",
      "Epoch 4612, Loss: 0.22893776558339596, Final Batch Loss: 0.028951002284884453\n",
      "Epoch 4613, Loss: 0.17952912487089634, Final Batch Loss: 0.014436105266213417\n",
      "Epoch 4614, Loss: 0.11241372860968113, Final Batch Loss: 0.0083878543227911\n",
      "Epoch 4615, Loss: 0.18121474981307983, Final Batch Loss: 0.026370123028755188\n",
      "Epoch 4616, Loss: 0.13362777046859264, Final Batch Loss: 0.012154905125498772\n",
      "Epoch 4617, Loss: 0.1646050652489066, Final Batch Loss: 0.013917512260377407\n",
      "Epoch 4618, Loss: 0.16000570356845856, Final Batch Loss: 0.051052600145339966\n",
      "Epoch 4619, Loss: 0.19337177090346813, Final Batch Loss: 0.010451165959239006\n",
      "Epoch 4620, Loss: 0.2330513447523117, Final Batch Loss: 0.09695090353488922\n",
      "Epoch 4621, Loss: 0.1241028942167759, Final Batch Loss: 0.03139561042189598\n",
      "Epoch 4622, Loss: 0.1449913177639246, Final Batch Loss: 0.00877600722014904\n",
      "Epoch 4623, Loss: 0.2004241719841957, Final Batch Loss: 0.03815091401338577\n",
      "Epoch 4624, Loss: 0.20094222202897072, Final Batch Loss: 0.044443730264902115\n",
      "Epoch 4625, Loss: 0.27193477377295494, Final Batch Loss: 0.1650857776403427\n",
      "Epoch 4626, Loss: 0.28547994792461395, Final Batch Loss: 0.12903259694576263\n",
      "Epoch 4627, Loss: 0.5034157037734985, Final Batch Loss: 0.20292317867279053\n",
      "Epoch 4628, Loss: 0.1897784285247326, Final Batch Loss: 0.03590304031968117\n",
      "Epoch 4629, Loss: 0.19957714714109898, Final Batch Loss: 0.022208618000149727\n",
      "Epoch 4630, Loss: 0.5470703169703484, Final Batch Loss: 0.2321532666683197\n",
      "Epoch 4631, Loss: 0.4374019578099251, Final Batch Loss: 0.06933657079935074\n",
      "Epoch 4632, Loss: 0.4010162353515625, Final Batch Loss: 0.07710330188274384\n",
      "Epoch 4633, Loss: 0.22642106376588345, Final Batch Loss: 0.020742377266287804\n",
      "Epoch 4634, Loss: 0.3796107769012451, Final Batch Loss: 0.2085370123386383\n",
      "Epoch 4635, Loss: 0.2474619522690773, Final Batch Loss: 0.0929974839091301\n",
      "Epoch 4636, Loss: 0.20860851742327213, Final Batch Loss: 0.02177109755575657\n",
      "Epoch 4637, Loss: 0.1843848971184343, Final Batch Loss: 0.0019836125429719687\n",
      "Epoch 4638, Loss: 0.5046522691845894, Final Batch Loss: 0.3545967936515808\n",
      "Epoch 4639, Loss: 0.2069341354072094, Final Batch Loss: 0.01807306334376335\n",
      "Epoch 4640, Loss: 0.16371454019099474, Final Batch Loss: 0.013430033810436726\n",
      "Epoch 4641, Loss: 0.19644734263420105, Final Batch Loss: 0.01579602062702179\n",
      "Epoch 4642, Loss: 0.25456854328513145, Final Batch Loss: 0.061333272606134415\n",
      "Epoch 4643, Loss: 0.16549943760037422, Final Batch Loss: 0.017243389040231705\n",
      "Epoch 4644, Loss: 0.22121376171708107, Final Batch Loss: 0.03783664479851723\n",
      "Epoch 4645, Loss: 0.25776519998908043, Final Batch Loss: 0.02864706888794899\n",
      "Epoch 4646, Loss: 0.21956924349069595, Final Batch Loss: 0.06990651041269302\n",
      "Epoch 4647, Loss: 0.186996728181839, Final Batch Loss: 0.027322951704263687\n",
      "Epoch 4648, Loss: 0.4021661914885044, Final Batch Loss: 0.24545559287071228\n",
      "Epoch 4649, Loss: 0.3189353942871094, Final Batch Loss: 0.23176944255828857\n",
      "Epoch 4650, Loss: 0.2599007189273834, Final Batch Loss: 0.09772265702486038\n",
      "Epoch 4651, Loss: 0.18810865469276905, Final Batch Loss: 0.009098103269934654\n",
      "Epoch 4652, Loss: 0.1723538488149643, Final Batch Loss: 0.03562717139720917\n",
      "Epoch 4653, Loss: 0.20012763515114784, Final Batch Loss: 0.05216401442885399\n",
      "Epoch 4654, Loss: 0.18909138441085815, Final Batch Loss: 0.044552989304065704\n",
      "Epoch 4655, Loss: 0.16112059727311134, Final Batch Loss: 0.0289471335709095\n",
      "Epoch 4656, Loss: 0.14138378063216805, Final Batch Loss: 0.00601239362731576\n",
      "Epoch 4657, Loss: 0.24549753963947296, Final Batch Loss: 0.09255408495664597\n",
      "Epoch 4658, Loss: 0.3994932249188423, Final Batch Loss: 0.24485056102275848\n",
      "Epoch 4659, Loss: 0.295892845839262, Final Batch Loss: 0.1313345581293106\n",
      "Epoch 4660, Loss: 0.17346426332369447, Final Batch Loss: 0.006552005652338266\n",
      "Epoch 4661, Loss: 0.33419938385486603, Final Batch Loss: 0.17959868907928467\n",
      "Epoch 4662, Loss: 0.3797883912920952, Final Batch Loss: 0.18475258350372314\n",
      "Epoch 4663, Loss: 0.19126392155885696, Final Batch Loss: 0.008251719176769257\n",
      "Epoch 4664, Loss: 0.17802673112601042, Final Batch Loss: 0.007963675074279308\n",
      "Epoch 4665, Loss: 0.13299776334315538, Final Batch Loss: 0.00864450354129076\n",
      "Epoch 4666, Loss: 0.3436097465455532, Final Batch Loss: 0.1919233202934265\n",
      "Epoch 4667, Loss: 0.860025592148304, Final Batch Loss: 0.6873731017112732\n",
      "Epoch 4668, Loss: 0.5856660902500153, Final Batch Loss: 0.43792277574539185\n",
      "Epoch 4669, Loss: 0.19489656388759613, Final Batch Loss: 0.04636576771736145\n",
      "Epoch 4670, Loss: 0.26798143167980015, Final Batch Loss: 0.002395807998254895\n",
      "Epoch 4671, Loss: 0.28964462503790855, Final Batch Loss: 0.02250625565648079\n",
      "Epoch 4672, Loss: 0.22647438943386078, Final Batch Loss: 0.018960997462272644\n",
      "Epoch 4673, Loss: 0.3499470427632332, Final Batch Loss: 0.18219055235385895\n",
      "Epoch 4674, Loss: 0.2914651483297348, Final Batch Loss: 0.1002969816327095\n",
      "Epoch 4675, Loss: 0.21817844547331333, Final Batch Loss: 0.016546638682484627\n",
      "Epoch 4676, Loss: 0.25822019577026367, Final Batch Loss: 0.06355229020118713\n",
      "Epoch 4677, Loss: 0.22359450533986092, Final Batch Loss: 0.04035104438662529\n",
      "Epoch 4678, Loss: 0.2082468941807747, Final Batch Loss: 0.07262074202299118\n",
      "Epoch 4679, Loss: 0.1770471166819334, Final Batch Loss: 0.025746619328856468\n",
      "Epoch 4680, Loss: 0.22661472111940384, Final Batch Loss: 0.0599987767636776\n",
      "Epoch 4681, Loss: 0.19757511466741562, Final Batch Loss: 0.08171578496694565\n",
      "Epoch 4682, Loss: 0.13686569151468575, Final Batch Loss: 0.0024138849694281816\n",
      "Epoch 4683, Loss: 0.20537378638982773, Final Batch Loss: 0.05047205090522766\n",
      "Epoch 4684, Loss: 0.2607514411211014, Final Batch Loss: 0.08876875787973404\n",
      "Epoch 4685, Loss: 0.23715585470199585, Final Batch Loss: 0.0642547756433487\n",
      "Epoch 4686, Loss: 0.23189620673656464, Final Batch Loss: 0.03844207525253296\n",
      "Epoch 4687, Loss: 0.17467027064412832, Final Batch Loss: 0.009818165563046932\n",
      "Epoch 4688, Loss: 0.17276788502931595, Final Batch Loss: 0.027175918221473694\n",
      "Epoch 4689, Loss: 0.19966659508645535, Final Batch Loss: 0.02433757297694683\n",
      "Epoch 4690, Loss: 0.19424620270729065, Final Batch Loss: 0.070603147149086\n",
      "Epoch 4691, Loss: 0.26520831137895584, Final Batch Loss: 0.10090040415525436\n",
      "Epoch 4692, Loss: 0.25690801441669464, Final Batch Loss: 0.10234000533819199\n",
      "Epoch 4693, Loss: 0.2726074680685997, Final Batch Loss: 0.10615179687738419\n",
      "Epoch 4694, Loss: 0.2930690571665764, Final Batch Loss: 0.05197836458683014\n",
      "Epoch 4695, Loss: 0.13838028069585562, Final Batch Loss: 0.007846570573747158\n",
      "Epoch 4696, Loss: 0.1679704301059246, Final Batch Loss: 0.012549452483654022\n",
      "Epoch 4697, Loss: 0.22100812941789627, Final Batch Loss: 0.07526487112045288\n",
      "Epoch 4698, Loss: 0.12918550986796618, Final Batch Loss: 0.012532238848507404\n",
      "Epoch 4699, Loss: 0.13854468427598476, Final Batch Loss: 0.010985707864165306\n",
      "Epoch 4700, Loss: 0.11405261512845755, Final Batch Loss: 0.01203554030507803\n",
      "Epoch 4701, Loss: 0.30194947868585587, Final Batch Loss: 0.13465279340744019\n",
      "Epoch 4702, Loss: 0.5383236147463322, Final Batch Loss: 0.4129140377044678\n",
      "Epoch 4703, Loss: 0.1944160871207714, Final Batch Loss: 0.04484904929995537\n",
      "Epoch 4704, Loss: 0.20961096417158842, Final Batch Loss: 0.01444357167929411\n",
      "Epoch 4705, Loss: 0.25140539929270744, Final Batch Loss: 0.07839632779359818\n",
      "Epoch 4706, Loss: 0.17856520414352417, Final Batch Loss: 0.051653746515512466\n",
      "Epoch 4707, Loss: 0.1612195298075676, Final Batch Loss: 0.024495702236890793\n",
      "Epoch 4708, Loss: 0.19921202957630157, Final Batch Loss: 0.03616585582494736\n",
      "Epoch 4709, Loss: 0.13007045350968838, Final Batch Loss: 0.012731363996863365\n",
      "Epoch 4710, Loss: 0.2549613118171692, Final Batch Loss: 0.1138715147972107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4711, Loss: 0.22850243002176285, Final Batch Loss: 0.054677724838256836\n",
      "Epoch 4712, Loss: 0.20980833284556866, Final Batch Loss: 0.03117918036878109\n",
      "Epoch 4713, Loss: 0.2060791626572609, Final Batch Loss: 0.055666081607341766\n",
      "Epoch 4714, Loss: 0.20690560713410378, Final Batch Loss: 0.08408927172422409\n",
      "Epoch 4715, Loss: 0.20067698508501053, Final Batch Loss: 0.06158033758401871\n",
      "Epoch 4716, Loss: 0.17954575642943382, Final Batch Loss: 0.0323486402630806\n",
      "Epoch 4717, Loss: 0.25687792524695396, Final Batch Loss: 0.13982908427715302\n",
      "Epoch 4718, Loss: 0.25183432549238205, Final Batch Loss: 0.024748757481575012\n",
      "Epoch 4719, Loss: 0.13307231501676142, Final Batch Loss: 0.0037814138922840357\n",
      "Epoch 4720, Loss: 0.21826406195759773, Final Batch Loss: 0.03668062388896942\n",
      "Epoch 4721, Loss: 0.22134467214345932, Final Batch Loss: 0.07599752396345139\n",
      "Epoch 4722, Loss: 0.23729288205504417, Final Batch Loss: 0.04341668263077736\n",
      "Epoch 4723, Loss: 0.2395290918648243, Final Batch Loss: 0.11571093648672104\n",
      "Epoch 4724, Loss: 0.38271093368530273, Final Batch Loss: 0.250401109457016\n",
      "Epoch 4725, Loss: 0.23927965015172958, Final Batch Loss: 0.10913760960102081\n",
      "Epoch 4726, Loss: 0.51435312256217, Final Batch Loss: 0.384595662355423\n",
      "Epoch 4727, Loss: 0.6463372632861137, Final Batch Loss: 0.4860115945339203\n",
      "Epoch 4728, Loss: 0.16573938494548202, Final Batch Loss: 0.004175541456788778\n",
      "Epoch 4729, Loss: 0.3433530852198601, Final Batch Loss: 0.14093609154224396\n",
      "Epoch 4730, Loss: 0.2508707195520401, Final Batch Loss: 0.08040518313646317\n",
      "Epoch 4731, Loss: 0.2852020673453808, Final Batch Loss: 0.13239140808582306\n",
      "Epoch 4732, Loss: 0.18478023540228605, Final Batch Loss: 0.00957034807652235\n",
      "Epoch 4733, Loss: 0.22406078688800335, Final Batch Loss: 0.019974535331130028\n",
      "Epoch 4734, Loss: 0.13136794790625572, Final Batch Loss: 0.017318539321422577\n",
      "Epoch 4735, Loss: 0.2517891526222229, Final Batch Loss: 0.06712660193443298\n",
      "Epoch 4736, Loss: 0.5267651155591011, Final Batch Loss: 0.3107406795024872\n",
      "Epoch 4737, Loss: 0.14694646932184696, Final Batch Loss: 0.02953108586370945\n",
      "Epoch 4738, Loss: 0.6305318251252174, Final Batch Loss: 0.43947258591651917\n",
      "Epoch 4739, Loss: 0.14387093856930733, Final Batch Loss: 0.0313803069293499\n",
      "Epoch 4740, Loss: 0.2840270325541496, Final Batch Loss: 0.0893646702170372\n",
      "Epoch 4741, Loss: 0.21192990988492966, Final Batch Loss: 0.06842789798974991\n",
      "Epoch 4742, Loss: 0.6363004110753536, Final Batch Loss: 0.4827166199684143\n",
      "Epoch 4743, Loss: 0.2819464411586523, Final Batch Loss: 0.02391820214688778\n",
      "Epoch 4744, Loss: 1.0093930959701538, Final Batch Loss: 0.48930636048316956\n",
      "Epoch 4745, Loss: 0.48115573823451996, Final Batch Loss: 0.17365340888500214\n",
      "Epoch 4746, Loss: 0.20765477791428566, Final Batch Loss: 0.06022965908050537\n",
      "Epoch 4747, Loss: 0.4468603879213333, Final Batch Loss: 0.06458045542240143\n",
      "Epoch 4748, Loss: 0.47821078449487686, Final Batch Loss: 0.08582531660795212\n",
      "Epoch 4749, Loss: 0.6054277271032333, Final Batch Loss: 0.27656611800193787\n",
      "Epoch 4750, Loss: 0.35455770790576935, Final Batch Loss: 0.043274179100990295\n",
      "Epoch 4751, Loss: 0.45262302458286285, Final Batch Loss: 0.06302836537361145\n",
      "Epoch 4752, Loss: 0.35405733063817024, Final Batch Loss: 0.06157371774315834\n",
      "Epoch 4753, Loss: 0.2862761542201042, Final Batch Loss: 0.015679627656936646\n",
      "Epoch 4754, Loss: 0.28661636263132095, Final Batch Loss: 0.017584383487701416\n",
      "Epoch 4755, Loss: 0.353427916765213, Final Batch Loss: 0.12126907706260681\n",
      "Epoch 4756, Loss: 0.24285179376602173, Final Batch Loss: 0.06411314755678177\n",
      "Epoch 4757, Loss: 0.2723960727453232, Final Batch Loss: 0.10985821485519409\n",
      "Epoch 4758, Loss: 0.2613179087638855, Final Batch Loss: 0.04908612370491028\n",
      "Epoch 4759, Loss: 0.3236006945371628, Final Batch Loss: 0.08158544450998306\n",
      "Epoch 4760, Loss: 0.3310820609331131, Final Batch Loss: 0.08307503163814545\n",
      "Epoch 4761, Loss: 0.2669912725687027, Final Batch Loss: 0.09089579433202744\n",
      "Epoch 4762, Loss: 0.46641016006469727, Final Batch Loss: 0.31590139865875244\n",
      "Epoch 4763, Loss: 0.28507065400481224, Final Batch Loss: 0.043573904782533646\n",
      "Epoch 4764, Loss: 0.3152984231710434, Final Batch Loss: 0.09585036337375641\n",
      "Epoch 4765, Loss: 0.2943212166428566, Final Batch Loss: 0.10160225629806519\n",
      "Epoch 4766, Loss: 0.26789771020412445, Final Batch Loss: 0.12448164075613022\n",
      "Epoch 4767, Loss: 0.3562641590833664, Final Batch Loss: 0.16809937357902527\n",
      "Epoch 4768, Loss: 0.33703387528657913, Final Batch Loss: 0.08620500564575195\n",
      "Epoch 4769, Loss: 0.1937197484076023, Final Batch Loss: 0.03252488747239113\n",
      "Epoch 4770, Loss: 0.19362206384539604, Final Batch Loss: 0.039963770657777786\n",
      "Epoch 4771, Loss: 0.35704463720321655, Final Batch Loss: 0.12142240256071091\n",
      "Epoch 4772, Loss: 0.2401224598288536, Final Batch Loss: 0.07842769473791122\n",
      "Epoch 4773, Loss: 0.28427836298942566, Final Batch Loss: 0.1300930678844452\n",
      "Epoch 4774, Loss: 0.8208570703864098, Final Batch Loss: 0.5192376375198364\n",
      "Epoch 4775, Loss: 0.18179355189204216, Final Batch Loss: 0.026309870183467865\n",
      "Epoch 4776, Loss: 0.7882692366838455, Final Batch Loss: 0.3672478199005127\n",
      "Epoch 4777, Loss: 0.6154685169458389, Final Batch Loss: 0.3363409638404846\n",
      "Epoch 4778, Loss: 0.5891047641634941, Final Batch Loss: 0.3652520477771759\n",
      "Epoch 4779, Loss: 0.36368460953235626, Final Batch Loss: 0.01577427238225937\n",
      "Epoch 4780, Loss: 0.2759227454662323, Final Batch Loss: 0.034798093140125275\n",
      "Epoch 4781, Loss: 0.342430979013443, Final Batch Loss: 0.06479325145483017\n",
      "Epoch 4782, Loss: 0.36294252425432205, Final Batch Loss: 0.13052044808864594\n",
      "Epoch 4783, Loss: 0.25447530299425125, Final Batch Loss: 0.03835040330886841\n",
      "Epoch 4784, Loss: 0.34964338690042496, Final Batch Loss: 0.13951997458934784\n",
      "Epoch 4785, Loss: 0.28079983592033386, Final Batch Loss: 0.13505934178829193\n",
      "Epoch 4786, Loss: 0.4259437546133995, Final Batch Loss: 0.1926666796207428\n",
      "Epoch 4787, Loss: 0.2991798594594002, Final Batch Loss: 0.0979621484875679\n",
      "Epoch 4788, Loss: 0.30543404072523117, Final Batch Loss: 0.08316406607627869\n",
      "Epoch 4789, Loss: 0.3516581505537033, Final Batch Loss: 0.16818971931934357\n",
      "Epoch 4790, Loss: 0.30905675888061523, Final Batch Loss: 0.12886378169059753\n",
      "Epoch 4791, Loss: 0.42029839009046555, Final Batch Loss: 0.22158226370811462\n",
      "Epoch 4792, Loss: 0.3069887049496174, Final Batch Loss: 0.04189964011311531\n",
      "Epoch 4793, Loss: 0.28565667755901814, Final Batch Loss: 0.015759149566292763\n",
      "Epoch 4794, Loss: 0.43477122485637665, Final Batch Loss: 0.2783146798610687\n",
      "Epoch 4795, Loss: 0.17155396938323975, Final Batch Loss: 0.0348697230219841\n",
      "Epoch 4796, Loss: 0.21129387244582176, Final Batch Loss: 0.055686842650175095\n",
      "Epoch 4797, Loss: 0.33379390835762024, Final Batch Loss: 0.13259072601795197\n",
      "Epoch 4798, Loss: 0.20010263100266457, Final Batch Loss: 0.058700982481241226\n",
      "Epoch 4799, Loss: 0.21479786559939384, Final Batch Loss: 0.036014992743730545\n",
      "Epoch 4800, Loss: 0.2704010345041752, Final Batch Loss: 0.04439597949385643\n",
      "Epoch 4801, Loss: 0.20380330085754395, Final Batch Loss: 0.0472358763217926\n",
      "Epoch 4802, Loss: 0.1718336846679449, Final Batch Loss: 0.009976839646697044\n",
      "Epoch 4803, Loss: 0.24782082438468933, Final Batch Loss: 0.10983683913946152\n",
      "Epoch 4804, Loss: 0.24990982934832573, Final Batch Loss: 0.040592823177576065\n",
      "Epoch 4805, Loss: 0.4030534699559212, Final Batch Loss: 0.17513199150562286\n",
      "Epoch 4806, Loss: 0.23676135018467903, Final Batch Loss: 0.033295366913080215\n",
      "Epoch 4807, Loss: 0.21418224461376667, Final Batch Loss: 0.03091876395046711\n",
      "Epoch 4808, Loss: 0.30920299887657166, Final Batch Loss: 0.17717473208904266\n",
      "Epoch 4809, Loss: 0.16253690980374813, Final Batch Loss: 0.020142605528235435\n",
      "Epoch 4810, Loss: 0.2655113898217678, Final Batch Loss: 0.03169597312808037\n",
      "Epoch 4811, Loss: 0.17449112050235271, Final Batch Loss: 0.025696339085698128\n",
      "Epoch 4812, Loss: 0.14847393706440926, Final Batch Loss: 0.047813668847084045\n",
      "Epoch 4813, Loss: 0.23683308064937592, Final Batch Loss: 0.08271906524896622\n",
      "Epoch 4814, Loss: 0.28891901671886444, Final Batch Loss: 0.15560249984264374\n",
      "Epoch 4815, Loss: 0.15317964181303978, Final Batch Loss: 0.018084749579429626\n",
      "Epoch 4816, Loss: 0.20713770389556885, Final Batch Loss: 0.07481133937835693\n",
      "Epoch 4817, Loss: 0.3234204985201359, Final Batch Loss: 0.20198678970336914\n",
      "Epoch 4818, Loss: 0.14946849830448627, Final Batch Loss: 0.028332499787211418\n",
      "Epoch 4819, Loss: 0.17993213050067425, Final Batch Loss: 0.030113426968455315\n",
      "Epoch 4820, Loss: 0.19130099564790726, Final Batch Loss: 0.04560568183660507\n",
      "Epoch 4821, Loss: 0.22626465559005737, Final Batch Loss: 0.05301479250192642\n",
      "Epoch 4822, Loss: 0.16612716857343912, Final Batch Loss: 0.004087888635694981\n",
      "Epoch 4823, Loss: 0.1902613528072834, Final Batch Loss: 0.03362607583403587\n",
      "Epoch 4824, Loss: 0.2657908499240875, Final Batch Loss: 0.04850435256958008\n",
      "Epoch 4825, Loss: 0.23590765334665775, Final Batch Loss: 0.016410263255238533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4826, Loss: 0.16113224811851978, Final Batch Loss: 0.007798174396157265\n",
      "Epoch 4827, Loss: 0.14657284133136272, Final Batch Loss: 0.028911082074046135\n",
      "Epoch 4828, Loss: 0.3173672705888748, Final Batch Loss: 0.21511931717395782\n",
      "Epoch 4829, Loss: 0.09804652677848935, Final Batch Loss: 0.007112570572644472\n",
      "Epoch 4830, Loss: 0.21278127282857895, Final Batch Loss: 0.04140201210975647\n",
      "Epoch 4831, Loss: 0.20740048587322235, Final Batch Loss: 0.04923931509256363\n",
      "Epoch 4832, Loss: 0.15690824203193188, Final Batch Loss: 0.02600417099893093\n",
      "Epoch 4833, Loss: 0.23799901455640793, Final Batch Loss: 0.09810525178909302\n",
      "Epoch 4834, Loss: 0.2557941563427448, Final Batch Loss: 0.05039142444729805\n",
      "Epoch 4835, Loss: 0.2699071578681469, Final Batch Loss: 0.11557645350694656\n",
      "Epoch 4836, Loss: 0.16277288179844618, Final Batch Loss: 0.012621189467608929\n",
      "Epoch 4837, Loss: 0.14877342758700252, Final Batch Loss: 0.004794541280716658\n",
      "Epoch 4838, Loss: 0.1733928695321083, Final Batch Loss: 0.017210230231285095\n",
      "Epoch 4839, Loss: 0.1614278331398964, Final Batch Loss: 0.0436270609498024\n",
      "Epoch 4840, Loss: 0.20998997427523136, Final Batch Loss: 0.024503415450453758\n",
      "Epoch 4841, Loss: 0.14537286781705916, Final Batch Loss: 0.002783030504360795\n",
      "Epoch 4842, Loss: 0.19018058851361275, Final Batch Loss: 0.09133505821228027\n",
      "Epoch 4843, Loss: 0.24517934024333954, Final Batch Loss: 0.08146867156028748\n",
      "Epoch 4844, Loss: 0.2859457656741142, Final Batch Loss: 0.10922926664352417\n",
      "Epoch 4845, Loss: 0.17023630440235138, Final Batch Loss: 0.04592754319310188\n",
      "Epoch 4846, Loss: 0.44503552466630936, Final Batch Loss: 0.2646216154098511\n",
      "Epoch 4847, Loss: 0.17139923479408026, Final Batch Loss: 0.010943631641566753\n",
      "Epoch 4848, Loss: 0.20801351591944695, Final Batch Loss: 0.034590210765600204\n",
      "Epoch 4849, Loss: 0.16445237398147583, Final Batch Loss: 0.01884646713733673\n",
      "Epoch 4850, Loss: 0.1823004148900509, Final Batch Loss: 0.048113420605659485\n",
      "Epoch 4851, Loss: 0.16187606006860733, Final Batch Loss: 0.029040396213531494\n",
      "Epoch 4852, Loss: 0.45019880682229996, Final Batch Loss: 0.3099587857723236\n",
      "Epoch 4853, Loss: 0.18367191031575203, Final Batch Loss: 0.008629437536001205\n",
      "Epoch 4854, Loss: 0.21737563982605934, Final Batch Loss: 0.1011374294757843\n",
      "Epoch 4855, Loss: 0.2517227530479431, Final Batch Loss: 0.1049242839217186\n",
      "Epoch 4856, Loss: 0.16666275262832642, Final Batch Loss: 0.06802243739366531\n",
      "Epoch 4857, Loss: 0.14630907028913498, Final Batch Loss: 0.012842323631048203\n",
      "Epoch 4858, Loss: 0.16361908987164497, Final Batch Loss: 0.05773944780230522\n",
      "Epoch 4859, Loss: 0.13029718212783337, Final Batch Loss: 0.015463145449757576\n",
      "Epoch 4860, Loss: 0.1893559042364359, Final Batch Loss: 0.03036792017519474\n",
      "Epoch 4861, Loss: 0.14682087674736977, Final Batch Loss: 0.028549924492836\n",
      "Epoch 4862, Loss: 0.18592559080570936, Final Batch Loss: 0.010930459015071392\n",
      "Epoch 4863, Loss: 0.13839991111308336, Final Batch Loss: 0.012898662127554417\n",
      "Epoch 4864, Loss: 0.16069478448480368, Final Batch Loss: 0.01263886597007513\n",
      "Epoch 4865, Loss: 0.08627575170248747, Final Batch Loss: 0.013828041963279247\n",
      "Epoch 4866, Loss: 0.17651398479938507, Final Batch Loss: 0.022575877606868744\n",
      "Epoch 4867, Loss: 0.14403745904564857, Final Batch Loss: 0.03425672650337219\n",
      "Epoch 4868, Loss: 0.17285851016640663, Final Batch Loss: 0.03871079906821251\n",
      "Epoch 4869, Loss: 0.14327337755821645, Final Batch Loss: 0.0020214186515659094\n",
      "Epoch 4870, Loss: 0.23266614973545074, Final Batch Loss: 0.11191093176603317\n",
      "Epoch 4871, Loss: 0.19488481432199478, Final Batch Loss: 0.05118308961391449\n",
      "Epoch 4872, Loss: 0.20006819441914558, Final Batch Loss: 0.0459262989461422\n",
      "Epoch 4873, Loss: 0.21776419505476952, Final Batch Loss: 0.10546469688415527\n",
      "Epoch 4874, Loss: 0.2871345207095146, Final Batch Loss: 0.06570526957511902\n",
      "Epoch 4875, Loss: 0.22667216882109642, Final Batch Loss: 0.05727111175656319\n",
      "Epoch 4876, Loss: 0.2955581098794937, Final Batch Loss: 0.19811226427555084\n",
      "Epoch 4877, Loss: 0.17187708243727684, Final Batch Loss: 0.004632968455553055\n",
      "Epoch 4878, Loss: 0.23499826714396477, Final Batch Loss: 0.05255607143044472\n",
      "Epoch 4879, Loss: 0.1562245194800198, Final Batch Loss: 0.00588794844225049\n",
      "Epoch 4880, Loss: 0.20462362840771675, Final Batch Loss: 0.05982862040400505\n",
      "Epoch 4881, Loss: 0.20350292656803504, Final Batch Loss: 0.0003703493275679648\n",
      "Epoch 4882, Loss: 0.20702513307332993, Final Batch Loss: 0.07698461413383484\n",
      "Epoch 4883, Loss: 0.14650841258116998, Final Batch Loss: 0.00038513742038048804\n",
      "Epoch 4884, Loss: 0.17167849466204643, Final Batch Loss: 0.021742478013038635\n",
      "Epoch 4885, Loss: 0.11363475443795323, Final Batch Loss: 0.002319947350770235\n",
      "Epoch 4886, Loss: 0.20957200229167938, Final Batch Loss: 0.09009519219398499\n",
      "Epoch 4887, Loss: 0.18064599856734276, Final Batch Loss: 0.054113876074552536\n",
      "Epoch 4888, Loss: 0.22338606789708138, Final Batch Loss: 0.04227198287844658\n",
      "Epoch 4889, Loss: 0.1295099062845111, Final Batch Loss: 0.00579585786908865\n",
      "Epoch 4890, Loss: 0.29332220554351807, Final Batch Loss: 0.14384743571281433\n",
      "Epoch 4891, Loss: 0.24003935884684324, Final Batch Loss: 0.012593368999660015\n",
      "Epoch 4892, Loss: 0.2680702954530716, Final Batch Loss: 0.1524045467376709\n",
      "Epoch 4893, Loss: 0.24568622931838036, Final Batch Loss: 0.05212712660431862\n",
      "Epoch 4894, Loss: 0.15730278939008713, Final Batch Loss: 0.01633736491203308\n",
      "Epoch 4895, Loss: 0.22594724223017693, Final Batch Loss: 0.052462268620729446\n",
      "Epoch 4896, Loss: 0.25780319795012474, Final Batch Loss: 0.003979194909334183\n",
      "Epoch 4897, Loss: 0.2842061072587967, Final Batch Loss: 0.11127163469791412\n",
      "Epoch 4898, Loss: 0.19115464575588703, Final Batch Loss: 0.024530353024601936\n",
      "Epoch 4899, Loss: 0.20292603597044945, Final Batch Loss: 0.06764864921569824\n",
      "Epoch 4900, Loss: 0.13736764714121819, Final Batch Loss: 0.030210833996534348\n",
      "Epoch 4901, Loss: 0.2363476250320673, Final Batch Loss: 0.029409343376755714\n",
      "Epoch 4902, Loss: 0.13548717461526394, Final Batch Loss: 0.028075600042939186\n",
      "Epoch 4903, Loss: 0.2223258726298809, Final Batch Loss: 0.11008607596158981\n",
      "Epoch 4904, Loss: 0.32617606222629547, Final Batch Loss: 0.15030989050865173\n",
      "Epoch 4905, Loss: 0.1956491470336914, Final Batch Loss: 0.04688223451375961\n",
      "Epoch 4906, Loss: 0.6211407780647278, Final Batch Loss: 0.5055520534515381\n",
      "Epoch 4907, Loss: 0.21713346987962723, Final Batch Loss: 0.07334697991609573\n",
      "Epoch 4908, Loss: 0.17077378928661346, Final Batch Loss: 0.07203293591737747\n",
      "Epoch 4909, Loss: 0.1788761019706726, Final Batch Loss: 0.034235626459121704\n",
      "Epoch 4910, Loss: 0.4645391032099724, Final Batch Loss: 0.3274648189544678\n",
      "Epoch 4911, Loss: 0.26791662722826004, Final Batch Loss: 0.13664956390857697\n",
      "Epoch 4912, Loss: 0.09573128633201122, Final Batch Loss: 0.00792478583753109\n",
      "Epoch 4913, Loss: 0.11128067364916205, Final Batch Loss: 0.005260893609374762\n",
      "Epoch 4914, Loss: 0.18434205651283264, Final Batch Loss: 0.055648528039455414\n",
      "Epoch 4915, Loss: 0.14301590621471405, Final Batch Loss: 0.03771490976214409\n",
      "Epoch 4916, Loss: 0.2866128757596016, Final Batch Loss: 0.1216496154665947\n",
      "Epoch 4917, Loss: 0.13503353670239449, Final Batch Loss: 0.01387600228190422\n",
      "Epoch 4918, Loss: 0.18115018121898174, Final Batch Loss: 0.02885063923895359\n",
      "Epoch 4919, Loss: 0.17116272449493408, Final Batch Loss: 0.05192062631249428\n",
      "Epoch 4920, Loss: 0.15103899827226996, Final Batch Loss: 0.0077814399264752865\n",
      "Epoch 4921, Loss: 0.2584890238940716, Final Batch Loss: 0.14651326835155487\n",
      "Epoch 4922, Loss: 0.15778510831296444, Final Batch Loss: 0.023740118369460106\n",
      "Epoch 4923, Loss: 0.17436116747558117, Final Batch Loss: 0.019033854827284813\n",
      "Epoch 4924, Loss: 0.2157406508922577, Final Batch Loss: 0.027181044220924377\n",
      "Epoch 4925, Loss: 0.20202933251857758, Final Batch Loss: 0.04427365958690643\n",
      "Epoch 4926, Loss: 0.19084752723574638, Final Batch Loss: 0.055917803198099136\n",
      "Epoch 4927, Loss: 0.20199092477560043, Final Batch Loss: 0.06748568266630173\n",
      "Epoch 4928, Loss: 0.18849758803844452, Final Batch Loss: 0.09740950912237167\n",
      "Epoch 4929, Loss: 0.14193416014313698, Final Batch Loss: 0.009934686124324799\n",
      "Epoch 4930, Loss: 0.3102010414004326, Final Batch Loss: 0.13021798431873322\n",
      "Epoch 4931, Loss: 0.18450654670596123, Final Batch Loss: 0.042428482323884964\n",
      "Epoch 4932, Loss: 0.12278344016522169, Final Batch Loss: 0.010855418629944324\n",
      "Epoch 4933, Loss: 0.15997938066720963, Final Batch Loss: 0.029022280126810074\n",
      "Epoch 4934, Loss: 0.1505934759043157, Final Batch Loss: 0.0040242536924779415\n",
      "Epoch 4935, Loss: 0.14231207687407732, Final Batch Loss: 0.01300839800387621\n",
      "Epoch 4936, Loss: 0.1250458536669612, Final Batch Loss: 0.011127657257020473\n",
      "Epoch 4937, Loss: 0.16269600589293987, Final Batch Loss: 0.0016779807629063725\n",
      "Epoch 4938, Loss: 0.17225638963282108, Final Batch Loss: 0.02338551916182041\n",
      "Epoch 4939, Loss: 0.14264006726443768, Final Batch Loss: 0.00847555510699749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4940, Loss: 0.1431985516101122, Final Batch Loss: 0.005704609677195549\n",
      "Epoch 4941, Loss: 0.13680581375956535, Final Batch Loss: 0.017534393817186356\n",
      "Epoch 4942, Loss: 0.14226146787405014, Final Batch Loss: 0.05043976381421089\n",
      "Epoch 4943, Loss: 0.17367278039455414, Final Batch Loss: 0.09450225532054901\n",
      "Epoch 4944, Loss: 0.29535041749477386, Final Batch Loss: 0.1608518809080124\n",
      "Epoch 4945, Loss: 0.2052983120083809, Final Batch Loss: 0.05724961683154106\n",
      "Epoch 4946, Loss: 0.2078400959726423, Final Batch Loss: 0.00294278166256845\n",
      "Epoch 4947, Loss: 0.22843338549137115, Final Batch Loss: 0.03595364838838577\n",
      "Epoch 4948, Loss: 0.28562432900071144, Final Batch Loss: 0.1331131011247635\n",
      "Epoch 4949, Loss: 0.17857392132282257, Final Batch Loss: 0.04738973453640938\n",
      "Epoch 4950, Loss: 0.23791025951504707, Final Batch Loss: 0.04244257137179375\n",
      "Epoch 4951, Loss: 0.18581206258386374, Final Batch Loss: 0.010339665226638317\n",
      "Epoch 4952, Loss: 0.2134331464767456, Final Batch Loss: 0.06001193821430206\n",
      "Epoch 4953, Loss: 0.1543126255273819, Final Batch Loss: 0.04551370069384575\n",
      "Epoch 4954, Loss: 0.17018446139991283, Final Batch Loss: 0.02452934719622135\n",
      "Epoch 4955, Loss: 0.3410399705171585, Final Batch Loss: 0.09942626953125\n",
      "Epoch 4956, Loss: 0.21160512790083885, Final Batch Loss: 0.06145807355642319\n",
      "Epoch 4957, Loss: 0.24431169033050537, Final Batch Loss: 0.12520566582679749\n",
      "Epoch 4958, Loss: 0.1686863973736763, Final Batch Loss: 0.006526082754135132\n",
      "Epoch 4959, Loss: 0.16326037608087063, Final Batch Loss: 0.023272963240742683\n",
      "Epoch 4960, Loss: 0.22131800837814808, Final Batch Loss: 0.028447503224015236\n",
      "Epoch 4961, Loss: 0.17119894735515118, Final Batch Loss: 0.013200303539633751\n",
      "Epoch 4962, Loss: 0.11437613889575005, Final Batch Loss: 0.008077818900346756\n",
      "Epoch 4963, Loss: 0.17051378265023232, Final Batch Loss: 0.0321757011115551\n",
      "Epoch 4964, Loss: 0.2575474642217159, Final Batch Loss: 0.054584797471761703\n",
      "Epoch 4965, Loss: 0.32163383066654205, Final Batch Loss: 0.07609303295612335\n",
      "Epoch 4966, Loss: 0.17407754948362708, Final Batch Loss: 0.005285599734634161\n",
      "Epoch 4967, Loss: 0.4599000886082649, Final Batch Loss: 0.27338141202926636\n",
      "Epoch 4968, Loss: 0.3677646592259407, Final Batch Loss: 0.1446562260389328\n",
      "Epoch 4969, Loss: 0.2465922925621271, Final Batch Loss: 0.02549680508673191\n",
      "Epoch 4970, Loss: 0.3973255008459091, Final Batch Loss: 0.15949833393096924\n",
      "Epoch 4971, Loss: 0.9715553149580956, Final Batch Loss: 0.7240328788757324\n",
      "Epoch 4972, Loss: 0.24795923754572868, Final Batch Loss: 0.05087541416287422\n",
      "Epoch 4973, Loss: 0.23045232705771923, Final Batch Loss: 0.02364703081548214\n",
      "Epoch 4974, Loss: 0.3406830057501793, Final Batch Loss: 0.06952732056379318\n",
      "Epoch 4975, Loss: 0.29110386967658997, Final Batch Loss: 0.048217713832855225\n",
      "Epoch 4976, Loss: 0.25010108202695847, Final Batch Loss: 0.08477091789245605\n",
      "Epoch 4977, Loss: 0.23067445494234562, Final Batch Loss: 0.01917687989771366\n",
      "Epoch 4978, Loss: 0.46204824000597, Final Batch Loss: 0.24433083832263947\n",
      "Epoch 4979, Loss: 0.15913223288953304, Final Batch Loss: 0.022605305537581444\n",
      "Epoch 4980, Loss: 0.21953817829489708, Final Batch Loss: 0.01854637637734413\n",
      "Epoch 4981, Loss: 0.2059621438384056, Final Batch Loss: 0.0435948371887207\n",
      "Epoch 4982, Loss: 0.22602603770792484, Final Batch Loss: 0.006641829386353493\n",
      "Epoch 4983, Loss: 0.2479020431637764, Final Batch Loss: 0.07151858508586884\n",
      "Epoch 4984, Loss: 0.2858026772737503, Final Batch Loss: 0.13468560576438904\n",
      "Epoch 4985, Loss: 0.34368089213967323, Final Batch Loss: 0.1692487746477127\n",
      "Epoch 4986, Loss: 0.1555729762185365, Final Batch Loss: 0.003536383854225278\n",
      "Epoch 4987, Loss: 0.4980499967932701, Final Batch Loss: 0.3517032563686371\n",
      "Epoch 4988, Loss: 0.20134125277400017, Final Batch Loss: 0.06119436398148537\n",
      "Epoch 4989, Loss: 0.16267673298716545, Final Batch Loss: 0.04218311980366707\n",
      "Epoch 4990, Loss: 0.15588360279798508, Final Batch Loss: 0.011558875441551208\n",
      "Epoch 4991, Loss: 0.21194487065076828, Final Batch Loss: 0.04221545159816742\n",
      "Epoch 4992, Loss: 0.2518918402493, Final Batch Loss: 0.04012100771069527\n",
      "Epoch 4993, Loss: 0.29062583297491074, Final Batch Loss: 0.07673824578523636\n",
      "Epoch 4994, Loss: 0.2793564423918724, Final Batch Loss: 0.10268627107143402\n",
      "Epoch 4995, Loss: 0.22432176023721695, Final Batch Loss: 0.07854736596345901\n",
      "Epoch 4996, Loss: 0.15648473612964153, Final Batch Loss: 0.015956798568367958\n",
      "Epoch 4997, Loss: 0.3745075762271881, Final Batch Loss: 0.17724625766277313\n",
      "Epoch 4998, Loss: 0.2415199689567089, Final Batch Loss: 0.12023749947547913\n",
      "Epoch 4999, Loss: 0.17864527367055416, Final Batch Loss: 0.018927497789263725\n",
      "Epoch 5000, Loss: 0.23714863508939743, Final Batch Loss: 0.09938141703605652\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0  0]\n",
      " [ 0 28  2  0]\n",
      " [ 0  0 25  2]\n",
      " [ 0  1  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        42\n",
      "           1    0.96552   0.93333   0.94915        30\n",
      "           2    0.92593   0.92593   0.92593        27\n",
      "           3    0.93750   0.96774   0.95238        31\n",
      "\n",
      "    accuracy                        0.96154       130\n",
      "   macro avg    0.95724   0.95675   0.95686       130\n",
      "weighted avg    0.96175   0.96154   0.96153       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  5  4  1]\n",
      " [ 1 24  3  2]\n",
      " [ 0  2 21  7]\n",
      " [ 0 10  0 20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95238   0.66667   0.78431        30\n",
      "           1    0.58537   0.80000   0.67606        30\n",
      "           2    0.75000   0.70000   0.72414        30\n",
      "           3    0.66667   0.66667   0.66667        30\n",
      "\n",
      "    accuracy                        0.70833       120\n",
      "   macro avg    0.73860   0.70833   0.71279       120\n",
      "weighted avg    0.73860   0.70833   0.71279       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
