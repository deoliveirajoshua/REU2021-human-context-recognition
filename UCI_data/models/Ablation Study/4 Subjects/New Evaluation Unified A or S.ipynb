{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 4)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def get_act_matrix(batch_size, a_dim):\n",
    "    indexes = np.random.randint(a_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((len(indexes), indexes.max()+1))\n",
    "    one_hot[np.arange(len(indexes)),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "    \n",
    "def get_usr_matrix(batch_size, u_dim):\n",
    "    indexes = np.random.randint(u_dim, size = batch_size)\n",
    "    \n",
    "    one_hot = np.zeros((indexes.size, indexes.max()+1))\n",
    "    one_hot[np.arange(indexes.size),indexes] = 1\n",
    "    return torch.Tensor(indexes).long(), torch.Tensor(one_hot)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.284945011138916, Final Batch Loss: 1.0997529029846191\n",
      "Epoch 2, Loss: 3.2563018798828125, Final Batch Loss: 1.0743340253829956\n",
      "Epoch 3, Loss: 3.2211934328079224, Final Batch Loss: 1.0398589372634888\n",
      "Epoch 4, Loss: 3.301901936531067, Final Batch Loss: 1.1309809684753418\n",
      "Epoch 5, Loss: 3.266425848007202, Final Batch Loss: 1.0965145826339722\n",
      "Epoch 6, Loss: 3.2476807832717896, Final Batch Loss: 1.0807243585586548\n",
      "Epoch 7, Loss: 3.259092926979065, Final Batch Loss: 1.0939464569091797\n",
      "Epoch 8, Loss: 3.204698920249939, Final Batch Loss: 1.0402328968048096\n",
      "Epoch 9, Loss: 3.255707621574402, Final Batch Loss: 1.1032254695892334\n",
      "Epoch 10, Loss: 3.250483512878418, Final Batch Loss: 1.103775978088379\n",
      "Epoch 11, Loss: 3.2693684101104736, Final Batch Loss: 1.1295647621154785\n",
      "Epoch 12, Loss: 3.1832327842712402, Final Batch Loss: 1.0457051992416382\n",
      "Epoch 13, Loss: 3.135536551475525, Final Batch Loss: 1.0017009973526\n",
      "Epoch 14, Loss: 3.2310179471969604, Final Batch Loss: 1.1151323318481445\n",
      "Epoch 15, Loss: 3.1867018938064575, Final Batch Loss: 1.0796188116073608\n",
      "Epoch 16, Loss: 3.094288647174835, Final Batch Loss: 0.9986862540245056\n",
      "Epoch 17, Loss: 3.110121250152588, Final Batch Loss: 1.0310430526733398\n",
      "Epoch 18, Loss: 3.0478322505950928, Final Batch Loss: 0.9908732175827026\n",
      "Epoch 19, Loss: 3.068726658821106, Final Batch Loss: 1.0359545946121216\n",
      "Epoch 20, Loss: 3.0227335691452026, Final Batch Loss: 1.004463791847229\n",
      "Epoch 21, Loss: 2.937838613986969, Final Batch Loss: 0.9574989676475525\n",
      "Epoch 22, Loss: 2.9734597206115723, Final Batch Loss: 1.0227670669555664\n",
      "Epoch 23, Loss: 2.8669621348381042, Final Batch Loss: 0.9452372193336487\n",
      "Epoch 24, Loss: 2.8050938844680786, Final Batch Loss: 0.940329372882843\n",
      "Epoch 25, Loss: 2.6878239512443542, Final Batch Loss: 0.8571319580078125\n",
      "Epoch 26, Loss: 2.5792295932769775, Final Batch Loss: 0.8183299899101257\n",
      "Epoch 27, Loss: 2.4894902110099792, Final Batch Loss: 0.7796888947486877\n",
      "Epoch 28, Loss: 2.3660120368003845, Final Batch Loss: 0.702383816242218\n",
      "Epoch 29, Loss: 2.2569278478622437, Final Batch Loss: 0.6474951505661011\n",
      "Epoch 30, Loss: 2.17106431722641, Final Batch Loss: 0.6768525838851929\n",
      "Epoch 31, Loss: 2.1249261498451233, Final Batch Loss: 0.6852431893348694\n",
      "Epoch 32, Loss: 1.8798301815986633, Final Batch Loss: 0.5578252673149109\n",
      "Epoch 33, Loss: 2.0929537415504456, Final Batch Loss: 0.8422907590866089\n",
      "Epoch 34, Loss: 1.7427216172218323, Final Batch Loss: 0.5404565930366516\n",
      "Epoch 35, Loss: 1.6770551204681396, Final Batch Loss: 0.5465862154960632\n",
      "Epoch 36, Loss: 1.7016777992248535, Final Batch Loss: 0.6148359775543213\n",
      "Epoch 37, Loss: 1.5068792700767517, Final Batch Loss: 0.4706640839576721\n",
      "Epoch 38, Loss: 1.5067164301872253, Final Batch Loss: 0.5584612488746643\n",
      "Epoch 39, Loss: 1.3144041001796722, Final Batch Loss: 0.40315908193588257\n",
      "Epoch 40, Loss: 1.2599017918109894, Final Batch Loss: 0.3896943926811218\n",
      "Epoch 41, Loss: 1.2046448588371277, Final Batch Loss: 0.36565133929252625\n",
      "Epoch 42, Loss: 1.1743590235710144, Final Batch Loss: 0.44037050008773804\n",
      "Epoch 43, Loss: 0.9888039231300354, Final Batch Loss: 0.2784733772277832\n",
      "Epoch 44, Loss: 1.1275620758533478, Final Batch Loss: 0.48008161783218384\n",
      "Epoch 45, Loss: 0.8559197336435318, Final Batch Loss: 0.24426831305027008\n",
      "Epoch 46, Loss: 0.7375129386782646, Final Batch Loss: 0.12498822063207626\n",
      "Epoch 47, Loss: 0.8858051598072052, Final Batch Loss: 0.336424857378006\n",
      "Epoch 48, Loss: 0.8685761988162994, Final Batch Loss: 0.3505334258079529\n",
      "Epoch 49, Loss: 0.629593551158905, Final Batch Loss: 0.19689252972602844\n",
      "Epoch 50, Loss: 0.686852216720581, Final Batch Loss: 0.24457688629627228\n",
      "Epoch 51, Loss: 0.7429381906986237, Final Batch Loss: 0.39058661460876465\n",
      "Epoch 52, Loss: 0.6118402481079102, Final Batch Loss: 0.2291838675737381\n",
      "Epoch 53, Loss: 0.56398506462574, Final Batch Loss: 0.1884058266878128\n",
      "Epoch 54, Loss: 0.4382712095975876, Final Batch Loss: 0.07885079085826874\n",
      "Epoch 55, Loss: 0.6322540789842606, Final Batch Loss: 0.3040821850299835\n",
      "Epoch 56, Loss: 0.4134705811738968, Final Batch Loss: 0.12141185998916626\n",
      "Epoch 57, Loss: 0.3914969637989998, Final Batch Loss: 0.09522690623998642\n",
      "Epoch 58, Loss: 0.37358852475881577, Final Batch Loss: 0.10447101294994354\n",
      "Epoch 59, Loss: 0.3352268561720848, Final Batch Loss: 0.07021753489971161\n",
      "Epoch 60, Loss: 0.33427368849515915, Final Batch Loss: 0.06951109319925308\n",
      "Epoch 61, Loss: 0.43046654015779495, Final Batch Loss: 0.19807487726211548\n",
      "Epoch 62, Loss: 0.4147074818611145, Final Batch Loss: 0.10861414670944214\n",
      "Epoch 63, Loss: 0.36136986315250397, Final Batch Loss: 0.11319631338119507\n",
      "Epoch 64, Loss: 0.3302862346172333, Final Batch Loss: 0.06486377120018005\n",
      "Epoch 65, Loss: 0.41803454607725143, Final Batch Loss: 0.16936013102531433\n",
      "Epoch 66, Loss: 0.24864939227700233, Final Batch Loss: 0.030131738632917404\n",
      "Epoch 67, Loss: 0.26619208231568336, Final Batch Loss: 0.02951158955693245\n",
      "Epoch 68, Loss: 0.2594762071967125, Final Batch Loss: 0.05890354514122009\n",
      "Epoch 69, Loss: 0.2745543047785759, Final Batch Loss: 0.05070355534553528\n",
      "Epoch 70, Loss: 0.3467775285243988, Final Batch Loss: 0.139290452003479\n",
      "Epoch 71, Loss: 0.46301309764385223, Final Batch Loss: 0.28572776913642883\n",
      "Epoch 72, Loss: 0.29074379056692123, Final Batch Loss: 0.09588345140218735\n",
      "Epoch 73, Loss: 0.28129974752664566, Final Batch Loss: 0.120314821600914\n",
      "Epoch 74, Loss: 0.19722820818424225, Final Batch Loss: 0.042203016579151154\n",
      "Epoch 75, Loss: 0.23409701138734818, Final Batch Loss: 0.06738553941249847\n",
      "Epoch 76, Loss: 0.26568031683564186, Final Batch Loss: 0.05969053879380226\n",
      "Epoch 77, Loss: 0.2586403153836727, Final Batch Loss: 0.05733751133084297\n",
      "Epoch 78, Loss: 0.2588745877146721, Final Batch Loss: 0.04499831050634384\n",
      "Epoch 79, Loss: 0.2342945635318756, Final Batch Loss: 0.061842769384384155\n",
      "Epoch 80, Loss: 0.23036706447601318, Final Batch Loss: 0.06496763229370117\n",
      "Epoch 81, Loss: 0.19281748309731483, Final Batch Loss: 0.010615568608045578\n",
      "Epoch 82, Loss: 0.41709834337234497, Final Batch Loss: 0.23595476150512695\n",
      "Epoch 83, Loss: 0.39074835181236267, Final Batch Loss: 0.24582722783088684\n",
      "Epoch 84, Loss: 0.2968638986349106, Final Batch Loss: 0.17647874355316162\n",
      "Epoch 85, Loss: 0.17943326756358147, Final Batch Loss: 0.028143487870693207\n",
      "Epoch 86, Loss: 0.29335977137088776, Final Batch Loss: 0.09931250661611557\n",
      "Epoch 87, Loss: 0.1894423495978117, Final Batch Loss: 0.02643623761832714\n",
      "Epoch 88, Loss: 0.23851455375552177, Final Batch Loss: 0.05295379087328911\n",
      "Epoch 89, Loss: 0.2736917734146118, Final Batch Loss: 0.1254507303237915\n",
      "Epoch 90, Loss: 0.2724558934569359, Final Batch Loss: 0.08360984921455383\n",
      "Epoch 91, Loss: 0.3973659574985504, Final Batch Loss: 0.2556014060974121\n",
      "Epoch 92, Loss: 0.22734874486923218, Final Batch Loss: 0.08231780678033829\n",
      "Epoch 93, Loss: 0.2113095261156559, Final Batch Loss: 0.060553450137376785\n",
      "Epoch 94, Loss: 0.20825459249317646, Final Batch Loss: 0.026577556505799294\n",
      "Epoch 95, Loss: 0.4324266165494919, Final Batch Loss: 0.2751580774784088\n",
      "Epoch 96, Loss: 0.20652727410197258, Final Batch Loss: 0.04031922668218613\n",
      "Epoch 97, Loss: 0.2270945981144905, Final Batch Loss: 0.07569441944360733\n",
      "Epoch 98, Loss: 0.18402903154492378, Final Batch Loss: 0.028821904212236404\n",
      "Epoch 99, Loss: 0.15667344629764557, Final Batch Loss: 0.020008984953165054\n",
      "Epoch 100, Loss: 0.2763477489352226, Final Batch Loss: 0.16475367546081543\n",
      "Epoch 101, Loss: 0.14359537954442203, Final Batch Loss: 0.0027467093896120787\n",
      "Epoch 102, Loss: 0.13787563517689705, Final Batch Loss: 0.016030658036470413\n",
      "Epoch 103, Loss: 0.13230234012007713, Final Batch Loss: 0.02122259885072708\n",
      "Epoch 104, Loss: 0.15945161879062653, Final Batch Loss: 0.02282746136188507\n",
      "Epoch 105, Loss: 0.2121758572757244, Final Batch Loss: 0.05503305792808533\n",
      "Epoch 106, Loss: 0.16955425217747688, Final Batch Loss: 0.036249179393053055\n",
      "Epoch 107, Loss: 0.18415011279284954, Final Batch Loss: 0.021939018741250038\n",
      "Epoch 108, Loss: 0.23755253851413727, Final Batch Loss: 0.09820358455181122\n",
      "Epoch 109, Loss: 0.15479437541216612, Final Batch Loss: 0.012336182408034801\n",
      "Epoch 110, Loss: 0.2969462424516678, Final Batch Loss: 0.164481982588768\n",
      "Epoch 111, Loss: 0.1529725077562034, Final Batch Loss: 0.005466993432492018\n",
      "Epoch 112, Loss: 0.17278285324573517, Final Batch Loss: 0.07188378274440765\n",
      "Epoch 113, Loss: 0.1567938979715109, Final Batch Loss: 0.018374716863036156\n",
      "Epoch 114, Loss: 0.4381362572312355, Final Batch Loss: 0.3064970076084137\n",
      "Epoch 115, Loss: 0.1944035142660141, Final Batch Loss: 0.06706884503364563\n",
      "Epoch 116, Loss: 0.15653910487890244, Final Batch Loss: 0.013210006058216095\n",
      "Epoch 117, Loss: 0.135449746157974, Final Batch Loss: 0.005848610308021307\n",
      "Epoch 118, Loss: 0.17429182305932045, Final Batch Loss: 0.046447377651929855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119, Loss: 0.279108140617609, Final Batch Loss: 0.15210559964179993\n",
      "Epoch 120, Loss: 0.15095418505370617, Final Batch Loss: 0.02341247908771038\n",
      "Epoch 121, Loss: 0.1694929599761963, Final Batch Loss: 0.03934955596923828\n",
      "Epoch 122, Loss: 0.11873220186680555, Final Batch Loss: 0.00279886182397604\n",
      "Epoch 123, Loss: 0.16262786649167538, Final Batch Loss: 0.024239489808678627\n",
      "Epoch 124, Loss: 0.4212644398212433, Final Batch Loss: 0.3312135338783264\n",
      "Epoch 125, Loss: 0.10758883506059647, Final Batch Loss: 0.01974828913807869\n",
      "Epoch 126, Loss: 0.16237087175250053, Final Batch Loss: 0.05247543752193451\n",
      "Epoch 127, Loss: 0.15345566347241402, Final Batch Loss: 0.03687919303774834\n",
      "Epoch 128, Loss: 0.13703599572181702, Final Batch Loss: 0.012004919350147247\n",
      "Epoch 129, Loss: 0.08323369920253754, Final Batch Loss: 0.00395621731877327\n",
      "Epoch 130, Loss: 0.19369086250662804, Final Batch Loss: 0.08472877740859985\n",
      "Epoch 131, Loss: 0.11419832427054644, Final Batch Loss: 0.014242415316402912\n",
      "Epoch 132, Loss: 0.1624254621565342, Final Batch Loss: 0.038445692509412766\n",
      "Epoch 133, Loss: 0.13966352120041847, Final Batch Loss: 0.028480425477027893\n",
      "Epoch 134, Loss: 0.31853490322828293, Final Batch Loss: 0.1956464648246765\n",
      "Epoch 135, Loss: 0.14830768946558237, Final Batch Loss: 0.0060966601595282555\n",
      "Epoch 136, Loss: 0.12411204073578119, Final Batch Loss: 0.012550023384392262\n",
      "Epoch 137, Loss: 0.14121995493769646, Final Batch Loss: 0.009431187063455582\n",
      "Epoch 138, Loss: 0.14303584955632687, Final Batch Loss: 0.015112398192286491\n",
      "Epoch 139, Loss: 0.13830428384244442, Final Batch Loss: 0.029746757820248604\n",
      "Epoch 140, Loss: 0.13250908814370632, Final Batch Loss: 0.005246201530098915\n",
      "Epoch 141, Loss: 0.157739682123065, Final Batch Loss: 0.029302207753062248\n",
      "Epoch 142, Loss: 0.10945830680429935, Final Batch Loss: 0.024576259776949883\n",
      "Epoch 143, Loss: 0.1256565167568624, Final Batch Loss: 0.005097185727208853\n",
      "Epoch 144, Loss: 0.13133328221738338, Final Batch Loss: 0.0031979847699403763\n",
      "Epoch 145, Loss: 0.10702269780449569, Final Batch Loss: 0.0026197757106274366\n",
      "Epoch 146, Loss: 0.11518802121281624, Final Batch Loss: 0.01732783392071724\n",
      "Epoch 147, Loss: 0.26955848187208176, Final Batch Loss: 0.16408850252628326\n",
      "Epoch 148, Loss: 0.1277113277465105, Final Batch Loss: 0.0031754281371831894\n",
      "Epoch 149, Loss: 0.12232674099504948, Final Batch Loss: 0.021958207711577415\n",
      "Epoch 150, Loss: 0.1420458536595106, Final Batch Loss: 0.0213292445987463\n",
      "Epoch 151, Loss: 0.12611041963100433, Final Batch Loss: 0.016604335978627205\n",
      "Epoch 152, Loss: 0.16922706365585327, Final Batch Loss: 0.036873795092105865\n",
      "Epoch 153, Loss: 0.27245960757136345, Final Batch Loss: 0.16194124519824982\n",
      "Epoch 154, Loss: 0.1634606532752514, Final Batch Loss: 0.0488542802631855\n",
      "Epoch 155, Loss: 0.3425882011651993, Final Batch Loss: 0.24454128742218018\n",
      "Epoch 156, Loss: 0.10926018469035625, Final Batch Loss: 0.010850803926587105\n",
      "Epoch 157, Loss: 0.13142597302794456, Final Batch Loss: 0.004786122590303421\n",
      "Epoch 158, Loss: 0.24671900272369385, Final Batch Loss: 0.15486928820610046\n",
      "Epoch 159, Loss: 0.09931552968919277, Final Batch Loss: 0.010389896109700203\n",
      "Epoch 160, Loss: 0.13140704296529293, Final Batch Loss: 0.019510896876454353\n",
      "Epoch 161, Loss: 0.07980407029390335, Final Batch Loss: 0.007554123178124428\n",
      "Epoch 162, Loss: 0.12445988273248076, Final Batch Loss: 0.007719778921455145\n",
      "Epoch 163, Loss: 0.10730079188942909, Final Batch Loss: 0.007966963574290276\n",
      "Epoch 164, Loss: 0.13586462289094925, Final Batch Loss: 0.012014005333185196\n",
      "Epoch 165, Loss: 0.2843763679265976, Final Batch Loss: 0.15842625498771667\n",
      "Epoch 166, Loss: 0.12637506518512964, Final Batch Loss: 0.010435494594275951\n",
      "Epoch 167, Loss: 0.09622992761433125, Final Batch Loss: 0.01965233124792576\n",
      "Epoch 168, Loss: 0.27774082496762276, Final Batch Loss: 0.15741367638111115\n",
      "Epoch 169, Loss: 0.13838174380362034, Final Batch Loss: 0.007710838690400124\n",
      "Epoch 170, Loss: 0.08890924789011478, Final Batch Loss: 0.0033480990678071976\n",
      "Epoch 171, Loss: 0.1481093317270279, Final Batch Loss: 0.014752665534615517\n",
      "Epoch 172, Loss: 0.2417458575218916, Final Batch Loss: 0.15009313821792603\n",
      "Epoch 173, Loss: 0.1175761092454195, Final Batch Loss: 0.016142459586262703\n",
      "Epoch 174, Loss: 0.12506196089088917, Final Batch Loss: 0.026514125987887383\n",
      "Epoch 175, Loss: 0.10537555068731308, Final Batch Loss: 0.011020947247743607\n",
      "Epoch 176, Loss: 0.16337022557854652, Final Batch Loss: 0.05401565507054329\n",
      "Epoch 177, Loss: 0.12692914251238108, Final Batch Loss: 0.008130689151585102\n",
      "Epoch 178, Loss: 0.21505709365010262, Final Batch Loss: 0.14498522877693176\n",
      "Epoch 179, Loss: 0.11227883119136095, Final Batch Loss: 0.009806745685636997\n",
      "Epoch 180, Loss: 0.10319686448201537, Final Batch Loss: 0.004009963478893042\n",
      "Epoch 181, Loss: 0.10496852919459343, Final Batch Loss: 0.012522343546152115\n",
      "Epoch 182, Loss: 0.1104965265840292, Final Batch Loss: 0.011696191504597664\n",
      "Epoch 183, Loss: 0.18710370548069477, Final Batch Loss: 0.11138903349637985\n",
      "Epoch 184, Loss: 0.11566267209127545, Final Batch Loss: 0.006082136649638414\n",
      "Epoch 185, Loss: 0.13949165679514408, Final Batch Loss: 0.029573572799563408\n",
      "Epoch 186, Loss: 0.1084487996995449, Final Batch Loss: 0.022856250405311584\n",
      "Epoch 187, Loss: 0.1741637997329235, Final Batch Loss: 0.03578286990523338\n",
      "Epoch 188, Loss: 0.10650224890559912, Final Batch Loss: 0.008726582862436771\n",
      "Epoch 189, Loss: 0.09367123176343739, Final Batch Loss: 0.003818349214270711\n",
      "Epoch 190, Loss: 0.1369232228025794, Final Batch Loss: 0.011047816835343838\n",
      "Epoch 191, Loss: 0.09054997703060508, Final Batch Loss: 0.007403032388538122\n",
      "Epoch 192, Loss: 0.2264380045235157, Final Batch Loss: 0.13334761559963226\n",
      "Epoch 193, Loss: 0.1304827481508255, Final Batch Loss: 0.02253919467329979\n",
      "Epoch 194, Loss: 0.1358331274241209, Final Batch Loss: 0.06097325682640076\n",
      "Epoch 195, Loss: 0.11608201637864113, Final Batch Loss: 0.005187615752220154\n",
      "Epoch 196, Loss: 0.20549551397562027, Final Batch Loss: 0.1161782369017601\n",
      "Epoch 197, Loss: 0.13456624560058117, Final Batch Loss: 0.027256177738308907\n",
      "Epoch 198, Loss: 0.11945831961929798, Final Batch Loss: 0.021138383075594902\n",
      "Epoch 199, Loss: 0.14591918140649796, Final Batch Loss: 0.06649798154830933\n",
      "Epoch 200, Loss: 0.08829281572252512, Final Batch Loss: 0.010251784697175026\n",
      "Epoch 201, Loss: 0.08997842110693455, Final Batch Loss: 0.015742475166916847\n",
      "Epoch 202, Loss: 0.10609126277267933, Final Batch Loss: 0.021785719320178032\n",
      "Epoch 203, Loss: 0.10818870831280947, Final Batch Loss: 0.015442741103470325\n",
      "Epoch 204, Loss: 0.22776468843221664, Final Batch Loss: 0.11864898353815079\n",
      "Epoch 205, Loss: 0.11870889132842422, Final Batch Loss: 0.007664197590202093\n",
      "Epoch 206, Loss: 0.11046503391116858, Final Batch Loss: 0.015174969099462032\n",
      "Epoch 207, Loss: 0.23829085379838943, Final Batch Loss: 0.13148152828216553\n",
      "Epoch 208, Loss: 0.11485756561160088, Final Batch Loss: 0.01266748458147049\n",
      "Epoch 209, Loss: 0.11124913301318884, Final Batch Loss: 0.010968121699988842\n",
      "Epoch 210, Loss: 0.1568494848906994, Final Batch Loss: 0.03819312900304794\n",
      "Epoch 211, Loss: 0.15728390216827393, Final Batch Loss: 0.06537532806396484\n",
      "Epoch 212, Loss: 0.38821468129754066, Final Batch Loss: 0.3277488052845001\n",
      "Epoch 213, Loss: 0.08230826701037586, Final Batch Loss: 0.0024345822166651487\n",
      "Epoch 214, Loss: 0.07373625133186579, Final Batch Loss: 0.0028474489226937294\n",
      "Epoch 215, Loss: 0.09460990875959396, Final Batch Loss: 0.0033214762806892395\n",
      "Epoch 216, Loss: 0.10848801396787167, Final Batch Loss: 0.030101152136921883\n",
      "Epoch 217, Loss: 0.10947578679770231, Final Batch Loss: 0.007451470009982586\n",
      "Epoch 218, Loss: 0.09589793742634356, Final Batch Loss: 0.002062931889668107\n",
      "Epoch 219, Loss: 0.11083703674376011, Final Batch Loss: 0.02065827138721943\n",
      "Epoch 220, Loss: 0.17410527169704437, Final Batch Loss: 0.06151561439037323\n",
      "Epoch 221, Loss: 0.10645057074725628, Final Batch Loss: 0.02341616339981556\n",
      "Epoch 222, Loss: 0.111926413141191, Final Batch Loss: 0.013960356824100018\n",
      "Epoch 223, Loss: 0.11258485447615385, Final Batch Loss: 0.01251587551087141\n",
      "Epoch 224, Loss: 0.12419944070279598, Final Batch Loss: 0.023149453103542328\n",
      "Epoch 225, Loss: 0.10432937648147345, Final Batch Loss: 0.009796506725251675\n",
      "Epoch 226, Loss: 0.09012467972934246, Final Batch Loss: 0.005853660404682159\n",
      "Epoch 227, Loss: 0.10340865515172482, Final Batch Loss: 0.015765449032187462\n",
      "Epoch 228, Loss: 0.1407734602689743, Final Batch Loss: 0.05325282737612724\n",
      "Epoch 229, Loss: 0.161336749792099, Final Batch Loss: 0.06886370480060577\n",
      "Epoch 230, Loss: 0.3446621708571911, Final Batch Loss: 0.28908684849739075\n",
      "Epoch 231, Loss: 0.11662988131865859, Final Batch Loss: 0.006289137061685324\n",
      "Epoch 232, Loss: 0.41743507608771324, Final Batch Loss: 0.3282942473888397\n",
      "Epoch 233, Loss: 0.1060779057443142, Final Batch Loss: 0.011998429894447327\n",
      "Epoch 234, Loss: 0.0841289209201932, Final Batch Loss: 0.027227994054555893\n",
      "Epoch 235, Loss: 0.09718567878007889, Final Batch Loss: 0.00821245089173317\n",
      "Epoch 236, Loss: 0.10188037529587746, Final Batch Loss: 0.018182044848799706\n",
      "Epoch 237, Loss: 0.08735665958374739, Final Batch Loss: 0.008689655922353268\n",
      "Epoch 238, Loss: 0.08519421890377998, Final Batch Loss: 0.007754633203148842\n",
      "Epoch 239, Loss: 0.09669862408190966, Final Batch Loss: 0.015000258572399616\n",
      "Epoch 240, Loss: 0.2517284620553255, Final Batch Loss: 0.19806352257728577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241, Loss: 0.0790881747379899, Final Batch Loss: 0.012225276790559292\n",
      "Epoch 242, Loss: 0.0748576195910573, Final Batch Loss: 0.008097534067928791\n",
      "Epoch 243, Loss: 0.08836706727743149, Final Batch Loss: 0.004011821001768112\n",
      "Epoch 244, Loss: 0.06824106629937887, Final Batch Loss: 0.00790081825107336\n",
      "Epoch 245, Loss: 0.07597961788997054, Final Batch Loss: 0.004765355493873358\n",
      "Epoch 246, Loss: 0.1055857203900814, Final Batch Loss: 0.03128497675061226\n",
      "Epoch 247, Loss: 0.09995740279555321, Final Batch Loss: 0.008641652762889862\n",
      "Epoch 248, Loss: 0.1061165239661932, Final Batch Loss: 0.01885463111102581\n",
      "Epoch 249, Loss: 0.260799502953887, Final Batch Loss: 0.1780596375465393\n",
      "Epoch 250, Loss: 0.17401877604424953, Final Batch Loss: 0.10471665114164352\n",
      "Epoch 251, Loss: 0.09763850551098585, Final Batch Loss: 0.011844991706311703\n",
      "Epoch 252, Loss: 0.09109336696565151, Final Batch Loss: 0.005849326029419899\n",
      "Epoch 253, Loss: 0.12327567115426064, Final Batch Loss: 0.01954903081059456\n",
      "Epoch 254, Loss: 0.4075891859829426, Final Batch Loss: 0.306460440158844\n",
      "Epoch 255, Loss: 0.1679297536611557, Final Batch Loss: 0.057365600019693375\n",
      "Epoch 256, Loss: 0.07691413536667824, Final Batch Loss: 0.008577762171626091\n",
      "Epoch 257, Loss: 0.10777910519391298, Final Batch Loss: 0.012368523515760899\n",
      "Epoch 258, Loss: 0.2666694661602378, Final Batch Loss: 0.19260236620903015\n",
      "Epoch 259, Loss: 0.10754692181944847, Final Batch Loss: 0.018918747082352638\n",
      "Epoch 260, Loss: 0.15491337329149246, Final Batch Loss: 0.07536501437425613\n",
      "Epoch 261, Loss: 0.09386338433250785, Final Batch Loss: 0.00583043834194541\n",
      "Epoch 262, Loss: 0.08655649982392788, Final Batch Loss: 0.009876811876893044\n",
      "Epoch 263, Loss: 0.08561191521584988, Final Batch Loss: 0.011345291510224342\n",
      "Epoch 264, Loss: 0.08506150497123599, Final Batch Loss: 0.0056249420158565044\n",
      "Epoch 265, Loss: 0.08390936255455017, Final Batch Loss: 0.003914598375558853\n",
      "Epoch 266, Loss: 0.08835857454687357, Final Batch Loss: 0.013016981072723866\n",
      "Epoch 267, Loss: 0.11302229389548302, Final Batch Loss: 0.024300768971443176\n",
      "Epoch 268, Loss: 0.09160944819450378, Final Batch Loss: 0.016200438141822815\n",
      "Epoch 269, Loss: 0.08325139433145523, Final Batch Loss: 0.0079256072640419\n",
      "Epoch 270, Loss: 0.08978048991411924, Final Batch Loss: 0.014741438440978527\n",
      "Epoch 271, Loss: 0.09637149423360825, Final Batch Loss: 0.0074217356741428375\n",
      "Epoch 272, Loss: 0.10672134906053543, Final Batch Loss: 0.022608626633882523\n",
      "Epoch 273, Loss: 0.06949579156935215, Final Batch Loss: 0.0020385105162858963\n",
      "Epoch 274, Loss: 0.09185827523469925, Final Batch Loss: 0.02989017963409424\n",
      "Epoch 275, Loss: 0.087054293602705, Final Batch Loss: 0.020586524158716202\n",
      "Epoch 276, Loss: 0.13964779488742352, Final Batch Loss: 0.02702120505273342\n",
      "Epoch 277, Loss: 0.08644479885697365, Final Batch Loss: 0.016926255077123642\n",
      "Epoch 278, Loss: 0.0670184912160039, Final Batch Loss: 0.010225397534668446\n",
      "Epoch 279, Loss: 0.08726264908909798, Final Batch Loss: 0.00925450399518013\n",
      "Epoch 280, Loss: 0.12133010849356651, Final Batch Loss: 0.05481480434536934\n",
      "Epoch 281, Loss: 0.10410560108721256, Final Batch Loss: 0.03421241044998169\n",
      "Epoch 282, Loss: 0.19123238697648048, Final Batch Loss: 0.10687294602394104\n",
      "Epoch 283, Loss: 0.0715326052159071, Final Batch Loss: 0.004301948472857475\n",
      "Epoch 284, Loss: 0.06873022933723405, Final Batch Loss: 0.0006656337645836174\n",
      "Epoch 285, Loss: 0.07514514680951834, Final Batch Loss: 0.010336908511817455\n",
      "Epoch 286, Loss: 0.0930447403807193, Final Batch Loss: 0.003761581378057599\n",
      "Epoch 287, Loss: 0.12067627534270287, Final Batch Loss: 0.016683731228113174\n",
      "Epoch 288, Loss: 0.059340643929317594, Final Batch Loss: 0.0029217342380434275\n",
      "Epoch 289, Loss: 0.08907438721507788, Final Batch Loss: 0.004485934041440487\n",
      "Epoch 290, Loss: 0.11284935288131237, Final Batch Loss: 0.05602644756436348\n",
      "Epoch 291, Loss: 0.09984731860458851, Final Batch Loss: 0.030507827177643776\n",
      "Epoch 292, Loss: 0.11408412829041481, Final Batch Loss: 0.02719523385167122\n",
      "Epoch 293, Loss: 0.42854717560112476, Final Batch Loss: 0.3658265471458435\n",
      "Epoch 294, Loss: 0.10065515991300344, Final Batch Loss: 0.011199205182492733\n",
      "Epoch 295, Loss: 0.1458084024488926, Final Batch Loss: 0.039193183183670044\n",
      "Epoch 296, Loss: 0.14312255661934614, Final Batch Loss: 0.012701514177024364\n",
      "Epoch 297, Loss: 0.21543626487255096, Final Batch Loss: 0.08205395936965942\n",
      "Epoch 298, Loss: 0.0892594805918634, Final Batch Loss: 0.0027411221526563168\n",
      "Epoch 299, Loss: 0.08849569549784064, Final Batch Loss: 0.006212861742824316\n",
      "Epoch 300, Loss: 0.1794314868748188, Final Batch Loss: 0.10261648893356323\n",
      "Epoch 301, Loss: 0.3419353123754263, Final Batch Loss: 0.2892809808254242\n",
      "Epoch 302, Loss: 0.09602337144315243, Final Batch Loss: 0.0249126348644495\n",
      "Epoch 303, Loss: 0.07936708303168416, Final Batch Loss: 0.005454395432025194\n",
      "Epoch 304, Loss: 0.09417925961315632, Final Batch Loss: 0.02812933549284935\n",
      "Epoch 305, Loss: 0.09571758937090635, Final Batch Loss: 0.006209592334926128\n",
      "Epoch 306, Loss: 0.08253215812146664, Final Batch Loss: 0.010798674076795578\n",
      "Epoch 307, Loss: 0.07965093851089478, Final Batch Loss: 0.019712988287210464\n",
      "Epoch 308, Loss: 0.08660650718957186, Final Batch Loss: 0.012262803502380848\n",
      "Epoch 309, Loss: 0.07785571902059019, Final Batch Loss: 0.0036301405634731054\n",
      "Epoch 310, Loss: 0.0766302477568388, Final Batch Loss: 0.003652602434158325\n",
      "Epoch 311, Loss: 0.21983900107443333, Final Batch Loss: 0.1460149884223938\n",
      "Epoch 312, Loss: 0.09257370792329311, Final Batch Loss: 0.021203285083174706\n",
      "Epoch 313, Loss: 0.09382898360490799, Final Batch Loss: 0.02226031757891178\n",
      "Epoch 314, Loss: 0.07795982668176293, Final Batch Loss: 0.006393557880073786\n",
      "Epoch 315, Loss: 0.06644340325146914, Final Batch Loss: 0.0025151455774903297\n",
      "Epoch 316, Loss: 0.08697704318910837, Final Batch Loss: 0.014509421773254871\n",
      "Epoch 317, Loss: 0.07717895554378629, Final Batch Loss: 0.007322373334318399\n",
      "Epoch 318, Loss: 0.07582124322652817, Final Batch Loss: 0.013647854328155518\n",
      "Epoch 319, Loss: 0.06929098395630717, Final Batch Loss: 0.00457783555611968\n",
      "Epoch 320, Loss: 0.07673021103255451, Final Batch Loss: 0.0034811056684702635\n",
      "Epoch 321, Loss: 0.09966336749494076, Final Batch Loss: 0.04652046039700508\n",
      "Epoch 322, Loss: 0.08119712956249714, Final Batch Loss: 0.007517252117395401\n",
      "Epoch 323, Loss: 0.07671694667078555, Final Batch Loss: 0.0024001284036785364\n",
      "Epoch 324, Loss: 0.13819614239037037, Final Batch Loss: 0.07706806808710098\n",
      "Epoch 325, Loss: 0.22816115617752075, Final Batch Loss: 0.17714866995811462\n",
      "Epoch 326, Loss: 0.10305788088589907, Final Batch Loss: 0.017795268446207047\n",
      "Epoch 327, Loss: 0.08271895791403949, Final Batch Loss: 0.0035532384645193815\n",
      "Epoch 328, Loss: 0.08408810058608651, Final Batch Loss: 0.001911612693220377\n",
      "Epoch 329, Loss: 0.06986695621162653, Final Batch Loss: 0.0022677918896079063\n",
      "Epoch 330, Loss: 0.07873274921439588, Final Batch Loss: 0.0028145068790763617\n",
      "Epoch 331, Loss: 0.09960774052888155, Final Batch Loss: 0.02448936551809311\n",
      "Epoch 332, Loss: 0.07098721899092197, Final Batch Loss: 0.002407548949122429\n",
      "Epoch 333, Loss: 0.09639359917491674, Final Batch Loss: 0.014608132652938366\n",
      "Epoch 334, Loss: 0.07373633794486523, Final Batch Loss: 0.0041947197169065475\n",
      "Epoch 335, Loss: 0.11832267977297306, Final Batch Loss: 0.05721411108970642\n",
      "Epoch 336, Loss: 0.0779661275446415, Final Batch Loss: 0.018395835533738136\n",
      "Epoch 337, Loss: 0.09001010423526168, Final Batch Loss: 0.006601396482437849\n",
      "Epoch 338, Loss: 0.07887997338548303, Final Batch Loss: 0.003066158387809992\n",
      "Epoch 339, Loss: 0.07657777541317046, Final Batch Loss: 0.0028285684529691935\n",
      "Epoch 340, Loss: 0.10136982053518295, Final Batch Loss: 0.04780689999461174\n",
      "Epoch 341, Loss: 0.11036495119333267, Final Batch Loss: 0.037906110286712646\n",
      "Epoch 342, Loss: 0.09182995185256004, Final Batch Loss: 0.020805496722459793\n",
      "Epoch 343, Loss: 0.06593183055520058, Final Batch Loss: 0.00498000904917717\n",
      "Epoch 344, Loss: 0.1097259484231472, Final Batch Loss: 0.06493934988975525\n",
      "Epoch 345, Loss: 0.07198258582502604, Final Batch Loss: 0.015267697162926197\n",
      "Epoch 346, Loss: 0.0974035575054586, Final Batch Loss: 0.0028871106915175915\n",
      "Epoch 347, Loss: 0.12197759561240673, Final Batch Loss: 0.036282751709222794\n",
      "Epoch 348, Loss: 0.04616824921686202, Final Batch Loss: 0.0014742837520316243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349, Loss: 0.15464909747242928, Final Batch Loss: 0.06077319011092186\n",
      "Epoch 350, Loss: 0.070032455958426, Final Batch Loss: 0.010233053006231785\n",
      "Epoch 351, Loss: 0.21602992713451385, Final Batch Loss: 0.12887172400951385\n",
      "Epoch 352, Loss: 0.045470156939700246, Final Batch Loss: 0.00034423195756971836\n",
      "Epoch 353, Loss: 0.0676199090667069, Final Batch Loss: 0.00346797751262784\n",
      "Epoch 354, Loss: 0.06747156847268343, Final Batch Loss: 0.011039084754884243\n",
      "Epoch 355, Loss: 0.0655586221255362, Final Batch Loss: 0.003918650094419718\n",
      "Epoch 356, Loss: 0.07481841964181513, Final Batch Loss: 0.001147394417785108\n",
      "Epoch 357, Loss: 0.061403486877679825, Final Batch Loss: 0.011853275820612907\n",
      "Epoch 358, Loss: 0.07663679198594764, Final Batch Loss: 0.0007195238140411675\n",
      "Epoch 359, Loss: 0.07465857872739434, Final Batch Loss: 0.005969932768493891\n",
      "Epoch 360, Loss: 0.07027029432356358, Final Batch Loss: 0.008077003061771393\n",
      "Epoch 361, Loss: 0.06479293829761446, Final Batch Loss: 0.0011556174140423536\n",
      "Epoch 362, Loss: 0.06955211429158226, Final Batch Loss: 0.0006728415028192103\n",
      "Epoch 363, Loss: 0.06106420513242483, Final Batch Loss: 0.00778889749199152\n",
      "Epoch 364, Loss: 0.06543525122106075, Final Batch Loss: 0.016626423224806786\n",
      "Epoch 365, Loss: 0.0977130588144064, Final Batch Loss: 0.04197186231613159\n",
      "Epoch 366, Loss: 0.1037011444568634, Final Batch Loss: 0.04575440287590027\n",
      "Epoch 367, Loss: 0.07260158052667975, Final Batch Loss: 0.006388665642589331\n",
      "Epoch 368, Loss: 0.0914923194795847, Final Batch Loss: 0.007087463513016701\n",
      "Epoch 369, Loss: 0.10675784759223461, Final Batch Loss: 0.025310812518000603\n",
      "Epoch 370, Loss: 0.2575424569658935, Final Batch Loss: 0.20611143112182617\n",
      "Epoch 371, Loss: 0.08000069251284003, Final Batch Loss: 0.01686803810298443\n",
      "Epoch 372, Loss: 0.060127576580271125, Final Batch Loss: 0.0038446353282779455\n",
      "Epoch 373, Loss: 0.3183402195572853, Final Batch Loss: 0.27223503589630127\n",
      "Epoch 374, Loss: 0.11622913368046284, Final Batch Loss: 0.07139047235250473\n",
      "Epoch 375, Loss: 0.09275270765647292, Final Batch Loss: 0.0026372908614575863\n",
      "Epoch 376, Loss: 0.06488209846429527, Final Batch Loss: 0.002074614865705371\n",
      "Epoch 377, Loss: 0.1058775894343853, Final Batch Loss: 0.03725583851337433\n",
      "Epoch 378, Loss: 0.0633327616378665, Final Batch Loss: 0.013242079876363277\n",
      "Epoch 379, Loss: 0.09425592981278896, Final Batch Loss: 0.03451009467244148\n",
      "Epoch 380, Loss: 0.10501696867868304, Final Batch Loss: 0.004984709899872541\n",
      "Epoch 381, Loss: 0.07846329547464848, Final Batch Loss: 0.020056243985891342\n",
      "Epoch 382, Loss: 0.05872522876597941, Final Batch Loss: 0.002637185389176011\n",
      "Epoch 383, Loss: 0.10368519090116024, Final Batch Loss: 0.038485679775476456\n",
      "Epoch 384, Loss: 0.07858795113861561, Final Batch Loss: 0.009556656703352928\n",
      "Epoch 385, Loss: 0.19641895219683647, Final Batch Loss: 0.11721622198820114\n",
      "Epoch 386, Loss: 0.07971493806689978, Final Batch Loss: 0.012042772956192493\n",
      "Epoch 387, Loss: 0.1455161664634943, Final Batch Loss: 0.08343549072742462\n",
      "Epoch 388, Loss: 0.07178445917088538, Final Batch Loss: 0.0012726319255307317\n",
      "Epoch 389, Loss: 0.09222583286464214, Final Batch Loss: 0.0071239955723285675\n",
      "Epoch 390, Loss: 0.1321314424276352, Final Batch Loss: 0.02396533265709877\n",
      "Epoch 391, Loss: 0.09587514400482178, Final Batch Loss: 0.016360938549041748\n",
      "Epoch 392, Loss: 0.07050867564976215, Final Batch Loss: 0.005667237564921379\n",
      "Epoch 393, Loss: 0.07765569072216749, Final Batch Loss: 0.008043552748858929\n",
      "Epoch 394, Loss: 0.05330657493323088, Final Batch Loss: 0.0073688579723238945\n",
      "Epoch 395, Loss: 0.05849214503541589, Final Batch Loss: 0.006997459102421999\n",
      "Epoch 396, Loss: 0.08451793529093266, Final Batch Loss: 0.01879473216831684\n",
      "Epoch 397, Loss: 0.06173579674214125, Final Batch Loss: 0.013882073573768139\n",
      "Epoch 398, Loss: 0.06740743573755026, Final Batch Loss: 0.0015470394864678383\n",
      "Epoch 399, Loss: 0.08528062887489796, Final Batch Loss: 0.01717490516602993\n",
      "Epoch 400, Loss: 0.052701237029396, Final Batch Loss: 0.0008612902602180839\n",
      "Epoch 401, Loss: 0.07041223254054785, Final Batch Loss: 0.01365941483527422\n",
      "Epoch 402, Loss: 0.07045755442231894, Final Batch Loss: 0.003049851395189762\n",
      "Epoch 403, Loss: 0.058559508295729756, Final Batch Loss: 0.002136479364708066\n",
      "Epoch 404, Loss: 0.07630937173962593, Final Batch Loss: 0.006332235410809517\n",
      "Epoch 405, Loss: 0.06776085309684277, Final Batch Loss: 0.005342436954379082\n",
      "Epoch 406, Loss: 0.06424375995993614, Final Batch Loss: 0.01451043225824833\n",
      "Epoch 407, Loss: 0.04910178272984922, Final Batch Loss: 0.003893995424732566\n",
      "Epoch 408, Loss: 0.08433488942682743, Final Batch Loss: 0.03028545342385769\n",
      "Epoch 409, Loss: 0.06476930342614651, Final Batch Loss: 0.005739354528486729\n",
      "Epoch 410, Loss: 0.05150676076300442, Final Batch Loss: 0.002239217283204198\n",
      "Epoch 411, Loss: 0.06740289158187807, Final Batch Loss: 0.0030930328648537397\n",
      "Epoch 412, Loss: 0.0538036716170609, Final Batch Loss: 0.005250532645732164\n",
      "Epoch 413, Loss: 0.07228718884289265, Final Batch Loss: 0.008163860067725182\n",
      "Epoch 414, Loss: 0.06481065275147557, Final Batch Loss: 0.004110563080757856\n",
      "Epoch 415, Loss: 0.06482450570911169, Final Batch Loss: 0.00934585090726614\n",
      "Epoch 416, Loss: 0.1450595110654831, Final Batch Loss: 0.08683844655752182\n",
      "Epoch 417, Loss: 0.06380691146478057, Final Batch Loss: 0.006415668409317732\n",
      "Epoch 418, Loss: 0.07080686639528722, Final Batch Loss: 0.000614818069152534\n",
      "Epoch 419, Loss: 0.05821366677992046, Final Batch Loss: 0.0016086369287222624\n",
      "Epoch 420, Loss: 0.063211704720743, Final Batch Loss: 0.001118035172112286\n",
      "Epoch 421, Loss: 0.05882109608501196, Final Batch Loss: 0.006337182596325874\n",
      "Epoch 422, Loss: 0.06299293087795377, Final Batch Loss: 0.003956067841500044\n",
      "Epoch 423, Loss: 0.058234782656654716, Final Batch Loss: 0.002359650796279311\n",
      "Epoch 424, Loss: 0.07704133167862892, Final Batch Loss: 0.03371192887425423\n",
      "Epoch 425, Loss: 0.06713291327469051, Final Batch Loss: 0.002396863652393222\n",
      "Epoch 426, Loss: 0.058723678077512886, Final Batch Loss: 0.00012190193956485018\n",
      "Epoch 427, Loss: 0.05254012905061245, Final Batch Loss: 0.0038942862302064896\n",
      "Epoch 428, Loss: 0.06957408704329282, Final Batch Loss: 0.001854988862760365\n",
      "Epoch 429, Loss: 0.07610233034938574, Final Batch Loss: 0.008778538554906845\n",
      "Epoch 430, Loss: 0.09671479521784931, Final Batch Loss: 0.0006962312618270516\n",
      "Epoch 431, Loss: 0.0982612301595509, Final Batch Loss: 0.022587038576602936\n",
      "Epoch 432, Loss: 0.05850990442559123, Final Batch Loss: 0.0019945320673286915\n",
      "Epoch 433, Loss: 0.2247173711657524, Final Batch Loss: 0.16310888528823853\n",
      "Epoch 434, Loss: 0.08959370851516724, Final Batch Loss: 0.019334658980369568\n",
      "Epoch 435, Loss: 0.19429315067827702, Final Batch Loss: 0.15624061226844788\n",
      "Epoch 436, Loss: 0.11117718741297722, Final Batch Loss: 0.018366161733865738\n",
      "Epoch 437, Loss: 0.12024576216936111, Final Batch Loss: 0.04772545024752617\n",
      "Epoch 438, Loss: 0.05996688862796873, Final Batch Loss: 0.001926595694385469\n",
      "Epoch 439, Loss: 0.07541459798812866, Final Batch Loss: 0.017107488587498665\n",
      "Epoch 440, Loss: 0.08021917846053839, Final Batch Loss: 0.005777192302048206\n",
      "Epoch 441, Loss: 0.10407273098826408, Final Batch Loss: 0.021248256787657738\n",
      "Epoch 442, Loss: 0.10953036928549409, Final Batch Loss: 0.007163497153669596\n",
      "Epoch 443, Loss: 0.07440315745770931, Final Batch Loss: 0.013022290542721748\n",
      "Epoch 444, Loss: 0.058846306055784225, Final Batch Loss: 0.007912052795290947\n",
      "Epoch 445, Loss: 0.061612607969436795, Final Batch Loss: 0.00041177315870299935\n",
      "Epoch 446, Loss: 0.1898748418316245, Final Batch Loss: 0.14697420597076416\n",
      "Epoch 447, Loss: 0.05803425470367074, Final Batch Loss: 0.0029415604658424854\n",
      "Epoch 448, Loss: 0.057370534632354975, Final Batch Loss: 0.0033426512964069843\n",
      "Epoch 449, Loss: 0.04836754174903035, Final Batch Loss: 0.003488824237138033\n",
      "Epoch 450, Loss: 0.05312383361160755, Final Batch Loss: 0.00637482013553381\n",
      "Epoch 451, Loss: 0.0853324830532074, Final Batch Loss: 0.029310621321201324\n",
      "Epoch 452, Loss: 0.048587174620479345, Final Batch Loss: 0.0036037717945873737\n",
      "Epoch 453, Loss: 0.058816380449570715, Final Batch Loss: 0.001792564638890326\n",
      "Epoch 454, Loss: 0.07546379568520933, Final Batch Loss: 0.0017066193977370858\n",
      "Epoch 455, Loss: 0.07699636649340391, Final Batch Loss: 0.015216522850096226\n",
      "Epoch 456, Loss: 0.06960514327511191, Final Batch Loss: 0.006527496036142111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457, Loss: 0.07140134274959564, Final Batch Loss: 0.026723256334662437\n",
      "Epoch 458, Loss: 0.06728404806926847, Final Batch Loss: 0.007305872160941362\n",
      "Epoch 459, Loss: 0.04692669352516532, Final Batch Loss: 0.005696484353393316\n",
      "Epoch 460, Loss: 0.05920103332027793, Final Batch Loss: 0.0044790818355977535\n",
      "Epoch 461, Loss: 0.06337394565343857, Final Batch Loss: 0.018218928948044777\n",
      "Epoch 462, Loss: 0.07292184699326754, Final Batch Loss: 0.0037201913073658943\n",
      "Epoch 463, Loss: 0.10114138573408127, Final Batch Loss: 0.03122819773852825\n",
      "Epoch 464, Loss: 0.10710581112653017, Final Batch Loss: 0.05310172960162163\n",
      "Epoch 465, Loss: 0.21594158373773098, Final Batch Loss: 0.15404799580574036\n",
      "Epoch 466, Loss: 0.062192318961024284, Final Batch Loss: 0.008331124670803547\n",
      "Epoch 467, Loss: 0.05503017781302333, Final Batch Loss: 0.0013355589471757412\n",
      "Epoch 468, Loss: 0.06590975914150476, Final Batch Loss: 0.0058830492198467255\n",
      "Epoch 469, Loss: 0.0926882540807128, Final Batch Loss: 0.05162430554628372\n",
      "Epoch 470, Loss: 0.042579948087222874, Final Batch Loss: 0.001729506184346974\n",
      "Epoch 471, Loss: 0.07555656880140305, Final Batch Loss: 0.017333054915070534\n",
      "Epoch 472, Loss: 0.05409538047388196, Final Batch Loss: 0.0036030211485922337\n",
      "Epoch 473, Loss: 0.06082790717482567, Final Batch Loss: 0.010072773322463036\n",
      "Epoch 474, Loss: 0.053852209355682135, Final Batch Loss: 0.004099230747669935\n",
      "Epoch 475, Loss: 0.06688056141138077, Final Batch Loss: 0.01631840690970421\n",
      "Epoch 476, Loss: 0.042947247391566634, Final Batch Loss: 0.0021043315064162016\n",
      "Epoch 477, Loss: 0.07058721990324557, Final Batch Loss: 0.002039719605818391\n",
      "Epoch 478, Loss: 0.053700783755630255, Final Batch Loss: 0.007557606790214777\n",
      "Epoch 479, Loss: 0.32704935036599636, Final Batch Loss: 0.2727010250091553\n",
      "Epoch 480, Loss: 0.06093098735436797, Final Batch Loss: 0.0028697350062429905\n",
      "Epoch 481, Loss: 0.07197588123381138, Final Batch Loss: 0.0167451873421669\n",
      "Epoch 482, Loss: 0.0866727833636105, Final Batch Loss: 0.0030559045262634754\n",
      "Epoch 483, Loss: 0.12157522141933441, Final Batch Loss: 0.037025272846221924\n",
      "Epoch 484, Loss: 0.07290163263678551, Final Batch Loss: 0.020307475700974464\n",
      "Epoch 485, Loss: 0.20222667790949345, Final Batch Loss: 0.1631351113319397\n",
      "Epoch 486, Loss: 0.08928271452896297, Final Batch Loss: 0.002019428415223956\n",
      "Epoch 487, Loss: 0.07666378654539585, Final Batch Loss: 0.03580517694354057\n",
      "Epoch 488, Loss: 0.06336014531552792, Final Batch Loss: 0.00432545505464077\n",
      "Epoch 489, Loss: 0.0606020987033844, Final Batch Loss: 0.011462491005659103\n",
      "Epoch 490, Loss: 0.06459527602419257, Final Batch Loss: 0.008047735318541527\n",
      "Epoch 491, Loss: 0.05231602070853114, Final Batch Loss: 0.0008013430051505566\n",
      "Epoch 492, Loss: 0.06203233217820525, Final Batch Loss: 0.013990271836519241\n",
      "Epoch 493, Loss: 0.07860794477164745, Final Batch Loss: 0.023836851119995117\n",
      "Epoch 494, Loss: 0.05194397363811731, Final Batch Loss: 0.0005949074402451515\n",
      "Epoch 495, Loss: 0.048823032062500715, Final Batch Loss: 0.0028751823119819164\n",
      "Epoch 496, Loss: 0.14967674016952515, Final Batch Loss: 0.11289706081151962\n",
      "Epoch 497, Loss: 0.1192212775349617, Final Batch Loss: 0.06024399399757385\n",
      "Epoch 498, Loss: 0.06417776504531503, Final Batch Loss: 0.005938399583101273\n",
      "Epoch 499, Loss: 0.03143132571130991, Final Batch Loss: 0.0023787859827280045\n",
      "Epoch 500, Loss: 0.06769568147137761, Final Batch Loss: 0.005936613772064447\n",
      "Epoch 501, Loss: 0.04890759056434035, Final Batch Loss: 0.006718638818711042\n",
      "Epoch 502, Loss: 0.21529274620115757, Final Batch Loss: 0.1639665812253952\n",
      "Epoch 503, Loss: 0.04983618203550577, Final Batch Loss: 0.00968403834849596\n",
      "Epoch 504, Loss: 0.04789368715137243, Final Batch Loss: 0.003450225107371807\n",
      "Epoch 505, Loss: 0.06849781330674887, Final Batch Loss: 0.003095570020377636\n",
      "Epoch 506, Loss: 0.06153141940012574, Final Batch Loss: 0.007025215309113264\n",
      "Epoch 507, Loss: 0.05317285913042724, Final Batch Loss: 0.002356291515752673\n",
      "Epoch 508, Loss: 0.08081843703985214, Final Batch Loss: 0.022850429639220238\n",
      "Epoch 509, Loss: 0.05826060567051172, Final Batch Loss: 0.0034654391929507256\n",
      "Epoch 510, Loss: 0.05183737399056554, Final Batch Loss: 0.004271176178008318\n",
      "Epoch 511, Loss: 0.05949176917783916, Final Batch Loss: 0.002938959514722228\n",
      "Epoch 512, Loss: 0.042493440909311175, Final Batch Loss: 0.002518619177863002\n",
      "Epoch 513, Loss: 0.06042864022310823, Final Batch Loss: 0.0006108958041295409\n",
      "Epoch 514, Loss: 0.09633876010775566, Final Batch Loss: 0.057261981070041656\n",
      "Epoch 515, Loss: 0.06209723686333746, Final Batch Loss: 0.00175303069408983\n",
      "Epoch 516, Loss: 0.19811958447098732, Final Batch Loss: 0.14714482426643372\n",
      "Epoch 517, Loss: 0.06138183595612645, Final Batch Loss: 0.0059897382743656635\n",
      "Epoch 518, Loss: 0.04796028370037675, Final Batch Loss: 0.002430784050375223\n",
      "Epoch 519, Loss: 0.05127906519919634, Final Batch Loss: 0.003943145275115967\n",
      "Epoch 520, Loss: 0.08194218052085489, Final Batch Loss: 0.0012609962141141295\n",
      "Epoch 521, Loss: 0.10859651351347566, Final Batch Loss: 0.05624391511082649\n",
      "Epoch 522, Loss: 0.049323055311106145, Final Batch Loss: 0.0014586601173505187\n",
      "Epoch 523, Loss: 0.05798635259270668, Final Batch Loss: 0.006315959617495537\n",
      "Epoch 524, Loss: 0.047307141416240484, Final Batch Loss: 0.0008161499281413853\n",
      "Epoch 525, Loss: 0.1483769528567791, Final Batch Loss: 0.09316983073949814\n",
      "Epoch 526, Loss: 0.05148354568518698, Final Batch Loss: 0.0024617204908281565\n",
      "Epoch 527, Loss: 0.0842363671399653, Final Batch Loss: 0.006480662617832422\n",
      "Epoch 528, Loss: 0.09432763326913118, Final Batch Loss: 0.0007109688594937325\n",
      "Epoch 529, Loss: 0.34175777435302734, Final Batch Loss: 0.24510538578033447\n",
      "Epoch 530, Loss: 0.3672124892473221, Final Batch Loss: 0.29858991503715515\n",
      "Epoch 531, Loss: 0.05219637509435415, Final Batch Loss: 0.0020135147497057915\n",
      "Epoch 532, Loss: 0.06692620273679495, Final Batch Loss: 0.005627230741083622\n",
      "Epoch 533, Loss: 0.0709899093490094, Final Batch Loss: 0.0025660942774266005\n",
      "Epoch 534, Loss: 0.07156267925165594, Final Batch Loss: 0.0010174119379371405\n",
      "Epoch 535, Loss: 0.12835330702364445, Final Batch Loss: 0.06485742330551147\n",
      "Epoch 536, Loss: 0.061565764248371124, Final Batch Loss: 0.01277114637196064\n",
      "Epoch 537, Loss: 0.07036630436778069, Final Batch Loss: 0.016201304271817207\n",
      "Epoch 538, Loss: 0.19021149538457394, Final Batch Loss: 0.13027535378932953\n",
      "Epoch 539, Loss: 0.10643547959625721, Final Batch Loss: 0.06224088743329048\n",
      "Epoch 540, Loss: 0.08821944519877434, Final Batch Loss: 0.02352503128349781\n",
      "Epoch 541, Loss: 0.08089527580887079, Final Batch Loss: 0.008328807540237904\n",
      "Epoch 542, Loss: 0.07585200387984514, Final Batch Loss: 0.008291098289191723\n",
      "Epoch 543, Loss: 0.39335040282458067, Final Batch Loss: 0.3550523817539215\n",
      "Epoch 544, Loss: 0.07438864465802908, Final Batch Loss: 0.01001774799078703\n",
      "Epoch 545, Loss: 0.04999494133517146, Final Batch Loss: 0.00529996445402503\n",
      "Epoch 546, Loss: 0.0975523293018341, Final Batch Loss: 0.03586890175938606\n",
      "Epoch 547, Loss: 0.253690205514431, Final Batch Loss: 0.19536283612251282\n",
      "Epoch 548, Loss: 0.05914266500622034, Final Batch Loss: 0.008295354433357716\n",
      "Epoch 549, Loss: 0.0688115069642663, Final Batch Loss: 0.010640273801982403\n",
      "Epoch 550, Loss: 0.0746375685557723, Final Batch Loss: 0.034367647022008896\n",
      "Epoch 551, Loss: 0.04880051361396909, Final Batch Loss: 0.007633092347532511\n",
      "Epoch 552, Loss: 0.09324882691726089, Final Batch Loss: 0.04477088153362274\n",
      "Epoch 553, Loss: 0.06612115149619058, Final Batch Loss: 0.0007217422244139016\n",
      "Epoch 554, Loss: 0.0644148401916027, Final Batch Loss: 0.00352594256401062\n",
      "Epoch 555, Loss: 0.14215551503002644, Final Batch Loss: 0.07918481528759003\n",
      "Epoch 556, Loss: 0.05912525858730078, Final Batch Loss: 0.007187287323176861\n",
      "Epoch 557, Loss: 0.05150005465839058, Final Batch Loss: 0.0012799907708540559\n",
      "Epoch 558, Loss: 0.0658100382424891, Final Batch Loss: 0.004197732079774141\n",
      "Epoch 559, Loss: 0.08681631740182638, Final Batch Loss: 0.004981751553714275\n",
      "Epoch 560, Loss: 0.06661225034622476, Final Batch Loss: 0.0007697857799939811\n",
      "Epoch 561, Loss: 0.09297141875140369, Final Batch Loss: 0.00368940900079906\n",
      "Epoch 562, Loss: 0.05205269542057067, Final Batch Loss: 0.001744433888234198\n",
      "Epoch 563, Loss: 0.07074590353295207, Final Batch Loss: 0.002424707170575857\n",
      "Epoch 564, Loss: 0.05446001747623086, Final Batch Loss: 0.0028819520957767963\n",
      "Epoch 565, Loss: 0.06388026289641857, Final Batch Loss: 0.01115061342716217\n",
      "Epoch 566, Loss: 0.06922471476718783, Final Batch Loss: 0.004678686615079641\n",
      "Epoch 567, Loss: 0.17573477141559124, Final Batch Loss: 0.13348005712032318\n",
      "Epoch 568, Loss: 0.06002889107912779, Final Batch Loss: 0.0073579540476202965\n",
      "Epoch 569, Loss: 0.03758561937138438, Final Batch Loss: 0.0020141075365245342\n",
      "Epoch 570, Loss: 0.0589018939062953, Final Batch Loss: 0.009307612664997578\n",
      "Epoch 571, Loss: 0.05952758342027664, Final Batch Loss: 0.0033678878098726273\n",
      "Epoch 572, Loss: 0.05596447084099054, Final Batch Loss: 0.005382089875638485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573, Loss: 0.06141557067167014, Final Batch Loss: 0.0011704916832968593\n",
      "Epoch 574, Loss: 0.06043489323928952, Final Batch Loss: 0.006162694189697504\n",
      "Epoch 575, Loss: 0.04871308244764805, Final Batch Loss: 0.004198718816041946\n",
      "Epoch 576, Loss: 0.04744326160289347, Final Batch Loss: 0.0027828963939100504\n",
      "Epoch 577, Loss: 0.2330047646537423, Final Batch Loss: 0.18155306577682495\n",
      "Epoch 578, Loss: 0.04801151982974261, Final Batch Loss: 0.0005525544984266162\n",
      "Epoch 579, Loss: 0.08079199492931366, Final Batch Loss: 0.03467699512839317\n",
      "Epoch 580, Loss: 0.07567756017670035, Final Batch Loss: 0.0042373365722596645\n",
      "Epoch 581, Loss: 0.057646335335448384, Final Batch Loss: 0.003567087696865201\n",
      "Epoch 582, Loss: 0.05095374584197998, Final Batch Loss: 0.007106959819793701\n",
      "Epoch 583, Loss: 0.04979117354378104, Final Batch Loss: 0.0008144467137753963\n",
      "Epoch 584, Loss: 0.051919480320066214, Final Batch Loss: 0.006373997312039137\n",
      "Epoch 585, Loss: 0.06574255041778088, Final Batch Loss: 0.008070540614426136\n",
      "Epoch 586, Loss: 0.21723972633481026, Final Batch Loss: 0.17367716133594513\n",
      "Epoch 587, Loss: 0.06674736691638827, Final Batch Loss: 0.008658986538648605\n",
      "Epoch 588, Loss: 0.06114880787208676, Final Batch Loss: 0.0007013739086687565\n",
      "Epoch 589, Loss: 0.05888990580569953, Final Batch Loss: 0.0011886664433404803\n",
      "Epoch 590, Loss: 0.05890250951051712, Final Batch Loss: 0.008723519742488861\n",
      "Epoch 591, Loss: 0.0429622286465019, Final Batch Loss: 0.002782048424705863\n",
      "Epoch 592, Loss: 0.06520565692335367, Final Batch Loss: 0.007900646887719631\n",
      "Epoch 593, Loss: 0.0674617497716099, Final Batch Loss: 0.003431073622778058\n",
      "Epoch 594, Loss: 0.04264895524829626, Final Batch Loss: 0.011435139924287796\n",
      "Epoch 595, Loss: 0.05637113843113184, Final Batch Loss: 0.005017390474677086\n",
      "Epoch 596, Loss: 0.05128766456618905, Final Batch Loss: 0.0027749636210501194\n",
      "Epoch 597, Loss: 0.055017455480992794, Final Batch Loss: 0.012105973437428474\n",
      "Epoch 598, Loss: 0.04897564009297639, Final Batch Loss: 0.0016961126821115613\n",
      "Epoch 599, Loss: 0.061735555063933134, Final Batch Loss: 0.011362100951373577\n",
      "Epoch 600, Loss: 0.052609443315304816, Final Batch Loss: 0.0010911148274317384\n",
      "Epoch 601, Loss: 0.1914041768759489, Final Batch Loss: 0.16048415005207062\n",
      "Epoch 602, Loss: 0.06089008739218116, Final Batch Loss: 0.0015074959956109524\n",
      "Epoch 603, Loss: 0.09497242420911789, Final Batch Loss: 0.05079757049679756\n",
      "Epoch 604, Loss: 0.05819745408371091, Final Batch Loss: 0.006886991206556559\n",
      "Epoch 605, Loss: 0.09539046697318554, Final Batch Loss: 0.013142682611942291\n",
      "Epoch 606, Loss: 0.055691516725346446, Final Batch Loss: 0.002245333744212985\n",
      "Epoch 607, Loss: 0.07954059913754463, Final Batch Loss: 0.013660093769431114\n",
      "Epoch 608, Loss: 0.28567936923354864, Final Batch Loss: 0.25502052903175354\n",
      "Epoch 609, Loss: 0.07783501408994198, Final Batch Loss: 0.015793483704328537\n",
      "Epoch 610, Loss: 0.049484267830848694, Final Batch Loss: 0.005532970651984215\n",
      "Epoch 611, Loss: 0.05366514599882066, Final Batch Loss: 0.0014113446231931448\n",
      "Epoch 612, Loss: 0.048157325480133295, Final Batch Loss: 0.0024682008661329746\n",
      "Epoch 613, Loss: 0.07250468991696835, Final Batch Loss: 0.02059399150311947\n",
      "Epoch 614, Loss: 0.04832598753273487, Final Batch Loss: 0.011593841016292572\n",
      "Epoch 615, Loss: 0.058533450588583946, Final Batch Loss: 0.009343348443508148\n",
      "Epoch 616, Loss: 0.05777370999567211, Final Batch Loss: 0.0029110282193869352\n",
      "Epoch 617, Loss: 0.05436414759606123, Final Batch Loss: 0.005926133133471012\n",
      "Epoch 618, Loss: 0.04749095253646374, Final Batch Loss: 0.012091930955648422\n",
      "Epoch 619, Loss: 0.05233042826876044, Final Batch Loss: 0.012831171974539757\n",
      "Epoch 620, Loss: 0.04130124009680003, Final Batch Loss: 0.0011388197308406234\n",
      "Epoch 621, Loss: 0.056405373848974705, Final Batch Loss: 0.018050583079457283\n",
      "Epoch 622, Loss: 0.04985536661115475, Final Batch Loss: 0.000271185563178733\n",
      "Epoch 623, Loss: 0.35251050256192684, Final Batch Loss: 0.3175297975540161\n",
      "Epoch 624, Loss: 0.05570650566369295, Final Batch Loss: 0.005552511662244797\n",
      "Epoch 625, Loss: 0.042223975295200944, Final Batch Loss: 0.0038428560364991426\n",
      "Epoch 626, Loss: 0.056625522673130035, Final Batch Loss: 0.008917883038520813\n",
      "Epoch 627, Loss: 0.053627584129571915, Final Batch Loss: 0.00511058047413826\n",
      "Epoch 628, Loss: 0.06456238124519587, Final Batch Loss: 0.007103443145751953\n",
      "Epoch 629, Loss: 0.07844954635947943, Final Batch Loss: 0.0378803052008152\n",
      "Epoch 630, Loss: 0.053712827153503895, Final Batch Loss: 0.006890882737934589\n",
      "Epoch 631, Loss: 0.06012825109064579, Final Batch Loss: 0.009432554244995117\n",
      "Epoch 632, Loss: 0.07532642874866724, Final Batch Loss: 0.03294287249445915\n",
      "Epoch 633, Loss: 0.09554782509803772, Final Batch Loss: 0.05921806022524834\n",
      "Epoch 634, Loss: 0.04430789523757994, Final Batch Loss: 0.002457773545756936\n",
      "Epoch 635, Loss: 0.059376961551606655, Final Batch Loss: 0.014934933744370937\n",
      "Epoch 636, Loss: 0.04659867100417614, Final Batch Loss: 0.0018629468977451324\n",
      "Epoch 637, Loss: 0.05191038263728842, Final Batch Loss: 0.0008668442605994642\n",
      "Epoch 638, Loss: 0.03850160213187337, Final Batch Loss: 0.0043027582578361034\n",
      "Epoch 639, Loss: 0.06525264121592045, Final Batch Loss: 0.01859212853014469\n",
      "Epoch 640, Loss: 0.028683010837994516, Final Batch Loss: 0.001210861257277429\n",
      "Epoch 641, Loss: 0.04686487338040024, Final Batch Loss: 0.001043852069415152\n",
      "Epoch 642, Loss: 0.04810323822312057, Final Batch Loss: 0.0012883997987955809\n",
      "Epoch 643, Loss: 0.03079169988632202, Final Batch Loss: 0.0019283527508378029\n",
      "Epoch 644, Loss: 0.05984627641737461, Final Batch Loss: 0.015193779021501541\n",
      "Epoch 645, Loss: 0.04647523956373334, Final Batch Loss: 0.005530570168048143\n",
      "Epoch 646, Loss: 0.03670253464952111, Final Batch Loss: 0.0033081569708883762\n",
      "Epoch 647, Loss: 0.05654396954923868, Final Batch Loss: 0.0059931715950369835\n",
      "Epoch 648, Loss: 0.03749089443590492, Final Batch Loss: 0.000944785657338798\n",
      "Epoch 649, Loss: 0.04893220355734229, Final Batch Loss: 0.00342935835942626\n",
      "Epoch 650, Loss: 0.0653727212920785, Final Batch Loss: 0.012766736559569836\n",
      "Epoch 651, Loss: 0.057380263693630695, Final Batch Loss: 0.012029687874019146\n",
      "Epoch 652, Loss: 0.051845630165189505, Final Batch Loss: 0.003452522214502096\n",
      "Epoch 653, Loss: 0.04302465682849288, Final Batch Loss: 0.004143313970416784\n",
      "Epoch 654, Loss: 0.07119524898007512, Final Batch Loss: 0.0375342071056366\n",
      "Epoch 655, Loss: 0.04714967537438497, Final Batch Loss: 0.0008501768461428583\n",
      "Epoch 656, Loss: 0.05063631932716817, Final Batch Loss: 0.0009661427466198802\n",
      "Epoch 657, Loss: 0.06260946253314614, Final Batch Loss: 0.0012546577490866184\n",
      "Epoch 658, Loss: 0.11502959299832582, Final Batch Loss: 0.07302249222993851\n",
      "Epoch 659, Loss: 0.06004552450031042, Final Batch Loss: 0.013882668688893318\n",
      "Epoch 660, Loss: 0.05099271330982447, Final Batch Loss: 0.004566690884530544\n",
      "Epoch 661, Loss: 0.044687509653158486, Final Batch Loss: 0.0005332921864464879\n",
      "Epoch 662, Loss: 0.05566226411610842, Final Batch Loss: 0.009980536065995693\n",
      "Epoch 663, Loss: 0.1387697011232376, Final Batch Loss: 0.10555014759302139\n",
      "Epoch 664, Loss: 0.06946494337171316, Final Batch Loss: 0.021528691053390503\n",
      "Epoch 665, Loss: 0.05849370826035738, Final Batch Loss: 0.008668807335197926\n",
      "Epoch 666, Loss: 0.048197776079177856, Final Batch Loss: 0.005659168586134911\n",
      "Epoch 667, Loss: 0.039214617339894176, Final Batch Loss: 0.0018203917425125837\n",
      "Epoch 668, Loss: 0.05547742755152285, Final Batch Loss: 0.002648525172844529\n",
      "Epoch 669, Loss: 0.048705947352573276, Final Batch Loss: 0.0014987795148044825\n",
      "Epoch 670, Loss: 0.06162234314251691, Final Batch Loss: 0.0008968730689957738\n",
      "Epoch 671, Loss: 0.0443986551836133, Final Batch Loss: 0.003024178557097912\n",
      "Epoch 672, Loss: 0.04207410535309464, Final Batch Loss: 0.0005054489010944963\n",
      "Epoch 673, Loss: 0.044740861165337265, Final Batch Loss: 0.0006252637831494212\n",
      "Epoch 674, Loss: 0.05234998185187578, Final Batch Loss: 0.008013159967958927\n",
      "Epoch 675, Loss: 0.05359375668922439, Final Batch Loss: 0.0007160660461522639\n",
      "Epoch 676, Loss: 0.0317055334453471, Final Batch Loss: 0.0002616814454086125\n",
      "Epoch 677, Loss: 0.10203768871724606, Final Batch Loss: 0.047348786145448685\n",
      "Epoch 678, Loss: 0.144892911426723, Final Batch Loss: 0.11570972204208374\n",
      "Epoch 679, Loss: 0.04044796887319535, Final Batch Loss: 0.001157222199253738\n",
      "Epoch 680, Loss: 0.17854865174740553, Final Batch Loss: 0.12658166885375977\n",
      "Epoch 681, Loss: 0.08112678956240416, Final Batch Loss: 0.005890575237572193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682, Loss: 0.06752531265374273, Final Batch Loss: 0.0015185311203822494\n",
      "Epoch 683, Loss: 0.05633325199596584, Final Batch Loss: 0.002025794005021453\n",
      "Epoch 684, Loss: 0.05503540928475559, Final Batch Loss: 0.003110304241999984\n",
      "Epoch 685, Loss: 0.0931624723598361, Final Batch Loss: 0.010449799709022045\n",
      "Epoch 686, Loss: 0.07598406355828047, Final Batch Loss: 0.011989918537437916\n",
      "Epoch 687, Loss: 0.07135194493457675, Final Batch Loss: 0.004479510243982077\n",
      "Epoch 688, Loss: 0.057424524798989296, Final Batch Loss: 0.0034365374594926834\n",
      "Epoch 689, Loss: 0.05260355677455664, Final Batch Loss: 0.005021809600293636\n",
      "Epoch 690, Loss: 0.044976660748943686, Final Batch Loss: 0.0009028606582432985\n",
      "Epoch 691, Loss: 0.05515150213614106, Final Batch Loss: 0.006478243973106146\n",
      "Epoch 692, Loss: 0.042906383983790874, Final Batch Loss: 0.0012999419122934341\n",
      "Epoch 693, Loss: 0.06949056126177311, Final Batch Loss: 0.028619490563869476\n",
      "Epoch 694, Loss: 0.034625829895958304, Final Batch Loss: 0.0012515706475824118\n",
      "Epoch 695, Loss: 0.033134232740849257, Final Batch Loss: 0.0016688569448888302\n",
      "Epoch 696, Loss: 0.07447622762992978, Final Batch Loss: 0.004440596792846918\n",
      "Epoch 697, Loss: 0.11830121092498302, Final Batch Loss: 0.07475637644529343\n",
      "Epoch 698, Loss: 0.07546715717762709, Final Batch Loss: 0.023629872128367424\n",
      "Epoch 699, Loss: 0.17401332780718803, Final Batch Loss: 0.12509384751319885\n",
      "Epoch 700, Loss: 0.05975891510024667, Final Batch Loss: 0.007495787460356951\n",
      "Epoch 701, Loss: 0.0761460093781352, Final Batch Loss: 0.013494645245373249\n",
      "Epoch 702, Loss: 0.042596557177603245, Final Batch Loss: 0.0020525334402918816\n",
      "Epoch 703, Loss: 0.045064539823215455, Final Batch Loss: 0.0005044380086474121\n",
      "Epoch 704, Loss: 0.04950885218568146, Final Batch Loss: 0.0033137809950858355\n",
      "Epoch 705, Loss: 0.06962292082607746, Final Batch Loss: 0.025947585701942444\n",
      "Epoch 706, Loss: 0.060086548735853285, Final Batch Loss: 0.0009369239560328424\n",
      "Epoch 707, Loss: 0.04370291344821453, Final Batch Loss: 0.00026978645473718643\n",
      "Epoch 708, Loss: 0.08629841543734074, Final Batch Loss: 0.04175029322504997\n",
      "Epoch 709, Loss: 0.06479998119175434, Final Batch Loss: 0.028668679296970367\n",
      "Epoch 710, Loss: 0.07557348115369678, Final Batch Loss: 0.027444014325737953\n",
      "Epoch 711, Loss: 0.03891993314027786, Final Batch Loss: 0.0013398751616477966\n",
      "Epoch 712, Loss: 0.04644954111427069, Final Batch Loss: 0.01397834811359644\n",
      "Epoch 713, Loss: 0.03826753329485655, Final Batch Loss: 0.016689427196979523\n",
      "Epoch 714, Loss: 0.05981382913887501, Final Batch Loss: 0.010163222439587116\n",
      "Epoch 715, Loss: 0.05354839749634266, Final Batch Loss: 0.011320885270833969\n",
      "Epoch 716, Loss: 0.03559024428250268, Final Batch Loss: 0.00022727978648617864\n",
      "Epoch 717, Loss: 0.05353765841573477, Final Batch Loss: 0.026855798438191414\n",
      "Epoch 718, Loss: 0.03098382824100554, Final Batch Loss: 0.002112198621034622\n",
      "Epoch 719, Loss: 0.04461154621094465, Final Batch Loss: 0.004668764770030975\n",
      "Epoch 720, Loss: 0.03948279650649056, Final Batch Loss: 0.0006615397869609296\n",
      "Epoch 721, Loss: 0.048894989071413875, Final Batch Loss: 0.002564751310274005\n",
      "Epoch 722, Loss: 0.03956365754129365, Final Batch Loss: 0.0005252117407508194\n",
      "Epoch 723, Loss: 0.04004945466294885, Final Batch Loss: 0.0040505374781787395\n",
      "Epoch 724, Loss: 0.04022332352178637, Final Batch Loss: 0.0002226864598924294\n",
      "Epoch 725, Loss: 0.04403144810930826, Final Batch Loss: 0.00030008648172952235\n",
      "Epoch 726, Loss: 0.07065894361585379, Final Batch Loss: 0.01061464473605156\n",
      "Epoch 727, Loss: 0.0454241787083447, Final Batch Loss: 0.0009668809361755848\n",
      "Epoch 728, Loss: 0.0576505676144734, Final Batch Loss: 0.0010370999807491899\n",
      "Epoch 729, Loss: 0.03800886159297079, Final Batch Loss: 0.0009052486857399344\n",
      "Epoch 730, Loss: 0.03972862591035664, Final Batch Loss: 0.0005542777944356203\n",
      "Epoch 731, Loss: 0.04742655833251774, Final Batch Loss: 0.0019653665367513895\n",
      "Epoch 732, Loss: 0.08875669725239277, Final Batch Loss: 0.06475476175546646\n",
      "Epoch 733, Loss: 0.05108835455030203, Final Batch Loss: 0.007446170784533024\n",
      "Epoch 734, Loss: 0.05359552940353751, Final Batch Loss: 0.01712309755384922\n",
      "Epoch 735, Loss: 0.056925302837044, Final Batch Loss: 0.004342904780060053\n",
      "Epoch 736, Loss: 0.04553755931556225, Final Batch Loss: 0.006328939460217953\n",
      "Epoch 737, Loss: 0.05563114024698734, Final Batch Loss: 0.01213986799120903\n",
      "Epoch 738, Loss: 0.053602716739987954, Final Batch Loss: 0.0003885620681103319\n",
      "Epoch 739, Loss: 0.11002176580950618, Final Batch Loss: 0.07410489767789841\n",
      "Epoch 740, Loss: 0.046049259923165664, Final Batch Loss: 0.00023402678198181093\n",
      "Epoch 741, Loss: 0.049615475814789534, Final Batch Loss: 0.004193659406155348\n",
      "Epoch 742, Loss: 0.08660648949444294, Final Batch Loss: 0.04868396744132042\n",
      "Epoch 743, Loss: 0.04313339421059936, Final Batch Loss: 0.00018390954937785864\n",
      "Epoch 744, Loss: 0.2142669139429927, Final Batch Loss: 0.17021743953227997\n",
      "Epoch 745, Loss: 0.0931121027097106, Final Batch Loss: 0.05551151931285858\n",
      "Epoch 746, Loss: 0.05022284993901849, Final Batch Loss: 0.0009290357120335102\n",
      "Epoch 747, Loss: 0.039433503057807684, Final Batch Loss: 0.0024018590338528156\n",
      "Epoch 748, Loss: 0.05259276879951358, Final Batch Loss: 0.004386651795357466\n",
      "Epoch 749, Loss: 0.05605435185134411, Final Batch Loss: 0.012676093727350235\n",
      "Epoch 750, Loss: 0.05053070141002536, Final Batch Loss: 0.0013188398443162441\n",
      "Epoch 751, Loss: 0.03961042454466224, Final Batch Loss: 0.004148544277995825\n",
      "Epoch 752, Loss: 0.06904404889792204, Final Batch Loss: 0.028264371678233147\n",
      "Epoch 753, Loss: 0.042868516058661044, Final Batch Loss: 0.001827490166760981\n",
      "Epoch 754, Loss: 0.04249024856835604, Final Batch Loss: 0.008011541329324245\n",
      "Epoch 755, Loss: 0.04553622053936124, Final Batch Loss: 0.0024094288237392902\n",
      "Epoch 756, Loss: 0.032205239636823535, Final Batch Loss: 0.0010491327848285437\n",
      "Epoch 757, Loss: 0.05217061936855316, Final Batch Loss: 0.0028892941772937775\n",
      "Epoch 758, Loss: 0.04233667999505997, Final Batch Loss: 0.004736948758363724\n",
      "Epoch 759, Loss: 0.03719575220020488, Final Batch Loss: 0.00033209362300112844\n",
      "Epoch 760, Loss: 0.04820143524557352, Final Batch Loss: 0.006571392063051462\n",
      "Epoch 761, Loss: 0.04977124999277294, Final Batch Loss: 0.002242468995973468\n",
      "Epoch 762, Loss: 0.043282713973894715, Final Batch Loss: 0.003050442086532712\n",
      "Epoch 763, Loss: 0.22756492719054222, Final Batch Loss: 0.1728888750076294\n",
      "Epoch 764, Loss: 0.041599112562835217, Final Batch Loss: 0.005908251740038395\n",
      "Epoch 765, Loss: 0.044069415889680386, Final Batch Loss: 0.008920332416892052\n",
      "Epoch 766, Loss: 0.045698029920458794, Final Batch Loss: 0.006461918354034424\n",
      "Epoch 767, Loss: 0.033744956250302494, Final Batch Loss: 5.2480841986835e-05\n",
      "Epoch 768, Loss: 0.04666180454660207, Final Batch Loss: 0.0019304921152070165\n",
      "Epoch 769, Loss: 0.04022307731793262, Final Batch Loss: 0.0004646753950510174\n",
      "Epoch 770, Loss: 0.03269956656731665, Final Batch Loss: 0.0031744905281811953\n",
      "Epoch 771, Loss: 0.05092110831174068, Final Batch Loss: 0.0001590621832292527\n",
      "Epoch 772, Loss: 0.04923977516591549, Final Batch Loss: 0.008739646524190903\n",
      "Epoch 773, Loss: 0.04688328690826893, Final Batch Loss: 0.013451593928039074\n",
      "Epoch 774, Loss: 0.05920380912721157, Final Batch Loss: 0.0028632748872041702\n",
      "Epoch 775, Loss: 0.04819406336173415, Final Batch Loss: 0.004321766551584005\n",
      "Epoch 776, Loss: 0.037288419087417424, Final Batch Loss: 0.001009436440654099\n",
      "Epoch 777, Loss: 0.04454789659939706, Final Batch Loss: 0.003237203462049365\n",
      "Epoch 778, Loss: 0.0635694582015276, Final Batch Loss: 0.02414707839488983\n",
      "Epoch 779, Loss: 0.03580912249162793, Final Batch Loss: 0.0005806167609989643\n",
      "Epoch 780, Loss: 0.03890237968880683, Final Batch Loss: 0.0011694744462147355\n",
      "Epoch 781, Loss: 0.05389138776808977, Final Batch Loss: 0.008040119893848896\n",
      "Epoch 782, Loss: 0.06371019780635834, Final Batch Loss: 0.02011670172214508\n",
      "Epoch 783, Loss: 0.05248298263177276, Final Batch Loss: 0.0075288391672074795\n",
      "Epoch 784, Loss: 0.041195897152647376, Final Batch Loss: 0.002939857542514801\n",
      "Epoch 785, Loss: 0.043037553783506155, Final Batch Loss: 0.003194331657141447\n",
      "Epoch 786, Loss: 0.05632754601538181, Final Batch Loss: 0.01877184584736824\n",
      "Epoch 787, Loss: 0.05858071427792311, Final Batch Loss: 0.007977123372256756\n",
      "Epoch 788, Loss: 0.2413506517186761, Final Batch Loss: 0.2100638896226883\n",
      "Epoch 789, Loss: 0.047299014404416084, Final Batch Loss: 0.004326988942921162\n",
      "Epoch 790, Loss: 0.03973861038684845, Final Batch Loss: 0.0029719695448875427\n",
      "Epoch 791, Loss: 0.05057451780885458, Final Batch Loss: 0.009861612692475319\n",
      "Epoch 792, Loss: 0.05073927715420723, Final Batch Loss: 0.007522162050008774\n",
      "Epoch 793, Loss: 0.03986286325380206, Final Batch Loss: 0.00223091384395957\n",
      "Epoch 794, Loss: 0.03380068810656667, Final Batch Loss: 0.0029505970887839794\n",
      "Epoch 795, Loss: 0.05589482747018337, Final Batch Loss: 0.023586053401231766\n",
      "Epoch 796, Loss: 0.06551015190780163, Final Batch Loss: 0.029958093538880348\n",
      "Epoch 797, Loss: 0.03329721558839083, Final Batch Loss: 0.006071319803595543\n",
      "Epoch 798, Loss: 0.04172772541642189, Final Batch Loss: 0.003908080048859119\n",
      "Epoch 799, Loss: 0.03344362077768892, Final Batch Loss: 0.0010742269223555923\n",
      "Epoch 800, Loss: 0.04744174098595977, Final Batch Loss: 0.005296593997627497\n",
      "Epoch 801, Loss: 0.08375258184969425, Final Batch Loss: 0.04657893627882004\n",
      "Epoch 802, Loss: 0.03651145595358685, Final Batch Loss: 7.818668382242322e-05\n",
      "Epoch 803, Loss: 0.047061946243047714, Final Batch Loss: 0.002416800707578659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 804, Loss: 0.10676725953817368, Final Batch Loss: 0.06805342435836792\n",
      "Epoch 805, Loss: 0.13900662306696177, Final Batch Loss: 0.1012609526515007\n",
      "Epoch 806, Loss: 0.04548214399255812, Final Batch Loss: 0.003225677413865924\n",
      "Epoch 807, Loss: 0.039221594110131264, Final Batch Loss: 0.0057951174676418304\n",
      "Epoch 808, Loss: 0.048271825653500855, Final Batch Loss: 0.0017697728471830487\n",
      "Epoch 809, Loss: 0.037297701463103294, Final Batch Loss: 0.004262689501047134\n",
      "Epoch 810, Loss: 0.036425364669412374, Final Batch Loss: 0.0070772855542600155\n",
      "Epoch 811, Loss: 0.06672579562291503, Final Batch Loss: 0.028879087418317795\n",
      "Epoch 812, Loss: 0.044198628049343824, Final Batch Loss: 0.005234547425061464\n",
      "Epoch 813, Loss: 0.03469910317653557, Final Batch Loss: 3.724902489921078e-05\n",
      "Epoch 814, Loss: 0.046623146161437035, Final Batch Loss: 0.014850389212369919\n",
      "Epoch 815, Loss: 0.0547995250672102, Final Batch Loss: 0.0005266265943646431\n",
      "Epoch 816, Loss: 0.29826757218688726, Final Batch Loss: 0.2732613980770111\n",
      "Epoch 817, Loss: 0.03671166393905878, Final Batch Loss: 0.009625941514968872\n",
      "Epoch 818, Loss: 0.04163006553426385, Final Batch Loss: 0.0059002479538321495\n",
      "Epoch 819, Loss: 0.04845616649254225, Final Batch Loss: 0.0002682940976228565\n",
      "Epoch 820, Loss: 0.04629378020763397, Final Batch Loss: 0.015652352944016457\n",
      "Epoch 821, Loss: 0.03872439917176962, Final Batch Loss: 0.008154192008078098\n",
      "Epoch 822, Loss: 0.07181158848106861, Final Batch Loss: 0.02632049471139908\n",
      "Epoch 823, Loss: 0.030979139264672995, Final Batch Loss: 0.003355726134032011\n",
      "Epoch 824, Loss: 0.04518984630703926, Final Batch Loss: 0.01112963818013668\n",
      "Epoch 825, Loss: 0.051505898125469685, Final Batch Loss: 0.011392229236662388\n",
      "Epoch 826, Loss: 0.03272763779386878, Final Batch Loss: 0.006180380005389452\n",
      "Epoch 827, Loss: 0.059659463819116354, Final Batch Loss: 0.024652037769556046\n",
      "Epoch 828, Loss: 0.04397476962185465, Final Batch Loss: 0.00026839165366254747\n",
      "Epoch 829, Loss: 0.034393129870295525, Final Batch Loss: 0.0010134843178093433\n",
      "Epoch 830, Loss: 0.038285269401967525, Final Batch Loss: 0.002578127197921276\n",
      "Epoch 831, Loss: 0.04477037728065625, Final Batch Loss: 0.0001732134842313826\n",
      "Epoch 832, Loss: 0.05830145813524723, Final Batch Loss: 0.02032606489956379\n",
      "Epoch 833, Loss: 0.04023084160871804, Final Batch Loss: 0.0013676437083631754\n",
      "Epoch 834, Loss: 0.03720423998311162, Final Batch Loss: 0.0019412138499319553\n",
      "Epoch 835, Loss: 0.03864947892725468, Final Batch Loss: 0.003126653842628002\n",
      "Epoch 836, Loss: 0.038480864372104406, Final Batch Loss: 0.01003870740532875\n",
      "Epoch 837, Loss: 0.02938501203607302, Final Batch Loss: 2.0119754481129348e-05\n",
      "Epoch 838, Loss: 0.031101609580218792, Final Batch Loss: 0.003800719976425171\n",
      "Epoch 839, Loss: 0.03661454930988839, Final Batch Loss: 9.093662811210379e-05\n",
      "Epoch 840, Loss: 0.03991295024752617, Final Batch Loss: 0.008070158772170544\n",
      "Epoch 841, Loss: 0.059749993961304426, Final Batch Loss: 0.025099359452724457\n",
      "Epoch 842, Loss: 0.030938733892980963, Final Batch Loss: 0.00046760874101892114\n",
      "Epoch 843, Loss: 0.037464556749910116, Final Batch Loss: 0.0009388546459376812\n",
      "Epoch 844, Loss: 0.04633074742741883, Final Batch Loss: 0.018168026581406593\n",
      "Epoch 845, Loss: 0.04669832537183538, Final Batch Loss: 0.0007073199958540499\n",
      "Epoch 846, Loss: 0.04882566467858851, Final Batch Loss: 0.0009451066143810749\n",
      "Epoch 847, Loss: 0.03967377624940127, Final Batch Loss: 0.0002856635255739093\n",
      "Epoch 848, Loss: 0.13819116726517677, Final Batch Loss: 0.11140824854373932\n",
      "Epoch 849, Loss: 0.04025470418855548, Final Batch Loss: 0.0019799580331891775\n",
      "Epoch 850, Loss: 0.10496312566101551, Final Batch Loss: 0.028942208737134933\n",
      "Epoch 851, Loss: 0.3712078146636486, Final Batch Loss: 0.3014480173587799\n",
      "Epoch 852, Loss: 0.10029616014799103, Final Batch Loss: 0.0007508079870603979\n",
      "Epoch 853, Loss: 0.10601385124027729, Final Batch Loss: 0.03679835796356201\n",
      "Epoch 854, Loss: 0.04604108526837081, Final Batch Loss: 0.001918190042488277\n",
      "Epoch 855, Loss: 0.04295171773992479, Final Batch Loss: 0.002121064579114318\n",
      "Epoch 856, Loss: 0.03832081487053074, Final Batch Loss: 0.0003521429898682982\n",
      "Epoch 857, Loss: 0.043692621402442455, Final Batch Loss: 0.00654443446546793\n",
      "Epoch 858, Loss: 0.05351037485525012, Final Batch Loss: 0.004219886381179094\n",
      "Epoch 859, Loss: 0.05828503519296646, Final Batch Loss: 0.022560352459549904\n",
      "Epoch 860, Loss: 0.03805648721754551, Final Batch Loss: 0.008867951110005379\n",
      "Epoch 861, Loss: 0.0362924060318619, Final Batch Loss: 0.002599938539788127\n",
      "Epoch 862, Loss: 0.0361344845732674, Final Batch Loss: 0.0015241265064105392\n",
      "Epoch 863, Loss: 0.0592638598755002, Final Batch Loss: 0.0053939903154969215\n",
      "Epoch 864, Loss: 0.04413803480565548, Final Batch Loss: 0.014822709374129772\n",
      "Epoch 865, Loss: 0.05452937167137861, Final Batch Loss: 0.014528964646160603\n",
      "Epoch 866, Loss: 0.04420056799426675, Final Batch Loss: 0.0016799555160105228\n",
      "Epoch 867, Loss: 0.03956336202099919, Final Batch Loss: 0.004624313209205866\n",
      "Epoch 868, Loss: 0.04893975518643856, Final Batch Loss: 0.014505519531667233\n",
      "Epoch 869, Loss: 0.04728215700015426, Final Batch Loss: 0.0030445996671915054\n",
      "Epoch 870, Loss: 0.0598652814514935, Final Batch Loss: 0.0039042537100613117\n",
      "Epoch 871, Loss: 0.03699275804683566, Final Batch Loss: 0.002343658823519945\n",
      "Epoch 872, Loss: 0.15556061128154397, Final Batch Loss: 0.13851624727249146\n",
      "Epoch 873, Loss: 0.033600177499465644, Final Batch Loss: 0.0016875806031748652\n",
      "Epoch 874, Loss: 0.03963527060113847, Final Batch Loss: 0.0014767718967050314\n",
      "Epoch 875, Loss: 0.04119047848507762, Final Batch Loss: 0.0037574837915599346\n",
      "Epoch 876, Loss: 0.031842058095207904, Final Batch Loss: 8.111683564493433e-05\n",
      "Epoch 877, Loss: 0.033182113664224744, Final Batch Loss: 0.0025645827408879995\n",
      "Epoch 878, Loss: 0.12223107181489468, Final Batch Loss: 0.08857271820306778\n",
      "Epoch 879, Loss: 0.03429909469559789, Final Batch Loss: 0.004094711039215326\n",
      "Epoch 880, Loss: 0.0815443187020719, Final Batch Loss: 0.05172451213002205\n",
      "Epoch 881, Loss: 0.05189151968806982, Final Batch Loss: 0.014603378251194954\n",
      "Epoch 882, Loss: 0.07037248834967613, Final Batch Loss: 0.020420344546437263\n",
      "Epoch 883, Loss: 0.05255185533314943, Final Batch Loss: 0.014826680533587933\n",
      "Epoch 884, Loss: 0.03721525054425001, Final Batch Loss: 0.003353816457092762\n",
      "Epoch 885, Loss: 0.05471623397897929, Final Batch Loss: 0.0018335551721975207\n",
      "Epoch 886, Loss: 0.03880417952314019, Final Batch Loss: 0.009771165437996387\n",
      "Epoch 887, Loss: 0.051803347654640675, Final Batch Loss: 0.0235351100564003\n",
      "Epoch 888, Loss: 0.049073158064857125, Final Batch Loss: 0.00268739671446383\n",
      "Epoch 889, Loss: 0.02973617287352681, Final Batch Loss: 0.002683944534510374\n",
      "Epoch 890, Loss: 0.021753193519543856, Final Batch Loss: 0.000499509449582547\n",
      "Epoch 891, Loss: 0.03154825372621417, Final Batch Loss: 0.0021397541277110577\n",
      "Epoch 892, Loss: 0.02654324947798159, Final Batch Loss: 0.00024381103867199272\n",
      "Epoch 893, Loss: 0.0430884666275233, Final Batch Loss: 0.0034277818631380796\n",
      "Epoch 894, Loss: 0.03246843465603888, Final Batch Loss: 0.006240691989660263\n",
      "Epoch 895, Loss: 0.03508009295910597, Final Batch Loss: 0.0025526192039251328\n",
      "Epoch 896, Loss: 0.0385749195702374, Final Batch Loss: 0.0064163669012486935\n",
      "Epoch 897, Loss: 0.03344570123590529, Final Batch Loss: 0.0011289773974567652\n",
      "Epoch 898, Loss: 0.028774168458767235, Final Batch Loss: 0.0005794671596959233\n",
      "Epoch 899, Loss: 0.1380517785437405, Final Batch Loss: 0.12202774733304977\n",
      "Epoch 900, Loss: 0.04004085902124643, Final Batch Loss: 0.014281676150858402\n",
      "Epoch 901, Loss: 0.021736320690251887, Final Batch Loss: 0.0010963954264298081\n",
      "Epoch 902, Loss: 0.029160364298149943, Final Batch Loss: 0.0011346947867423296\n",
      "Epoch 903, Loss: 0.030438215704634786, Final Batch Loss: 0.0021472724620252848\n",
      "Epoch 904, Loss: 0.02181223634397611, Final Batch Loss: 0.0005101505084894598\n",
      "Epoch 905, Loss: 0.03337608464062214, Final Batch Loss: 0.005294805392622948\n",
      "Epoch 906, Loss: 0.05046234326437116, Final Batch Loss: 0.0038574854843318462\n",
      "Epoch 907, Loss: 0.026518070000747684, Final Batch Loss: 3.3229451219085604e-05\n",
      "Epoch 908, Loss: 0.031267206533811986, Final Batch Loss: 0.0016977473860606551\n",
      "Epoch 909, Loss: 0.035251790657639503, Final Batch Loss: 0.0029075839556753635\n",
      "Epoch 910, Loss: 0.02066390385152772, Final Batch Loss: 0.00021900126012042165\n",
      "Epoch 911, Loss: 0.026475312653928995, Final Batch Loss: 0.005483059678226709\n",
      "Epoch 912, Loss: 0.02606669208034873, Final Batch Loss: 0.0017831623554229736\n",
      "Epoch 913, Loss: 0.02540243649855256, Final Batch Loss: 0.007767046801745892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914, Loss: 0.019322558073326945, Final Batch Loss: 0.002867490751668811\n",
      "Epoch 915, Loss: 0.03845927072688937, Final Batch Loss: 0.006673707161098719\n",
      "Epoch 916, Loss: 0.038052722346037626, Final Batch Loss: 0.020381612703204155\n",
      "Epoch 917, Loss: 0.03486251551657915, Final Batch Loss: 0.00957909319549799\n",
      "Epoch 918, Loss: 0.02687325165607035, Final Batch Loss: 0.0030884582083672285\n",
      "Epoch 919, Loss: 0.032826614333316684, Final Batch Loss: 0.0012983388733118773\n",
      "Epoch 920, Loss: 0.03372753062285483, Final Batch Loss: 0.002644255058839917\n",
      "Epoch 921, Loss: 0.026838050689548254, Final Batch Loss: 0.004263893235474825\n",
      "Epoch 922, Loss: 0.0208590105175972, Final Batch Loss: 0.004362541250884533\n",
      "Epoch 923, Loss: 0.07528749108314514, Final Batch Loss: 0.03629518672823906\n",
      "Epoch 924, Loss: 0.032229669828666374, Final Batch Loss: 0.00026691562379710376\n",
      "Epoch 925, Loss: 0.040840884670615196, Final Batch Loss: 0.011223485693335533\n",
      "Epoch 926, Loss: 0.03404777543619275, Final Batch Loss: 0.007386063225567341\n",
      "Epoch 927, Loss: 0.025741421850398183, Final Batch Loss: 0.0033626870717853308\n",
      "Epoch 928, Loss: 0.0271133350324817, Final Batch Loss: 0.00012129108654335141\n",
      "Epoch 929, Loss: 0.021456543705426157, Final Batch Loss: 0.0018669388955458999\n",
      "Epoch 930, Loss: 0.02517045190325007, Final Batch Loss: 0.0008633778779767454\n",
      "Epoch 931, Loss: 0.04981868830509484, Final Batch Loss: 0.01803865283727646\n",
      "Epoch 932, Loss: 0.021560089393460657, Final Batch Loss: 0.00011646022176137194\n",
      "Epoch 933, Loss: 0.13911581435240805, Final Batch Loss: 0.128036230802536\n",
      "Epoch 934, Loss: 0.039318415336310863, Final Batch Loss: 0.015323959290981293\n",
      "Epoch 935, Loss: 0.020151779507159517, Final Batch Loss: 6.361850410030456e-06\n",
      "Epoch 936, Loss: 0.029182578902691603, Final Batch Loss: 0.004496481269598007\n",
      "Epoch 937, Loss: 0.06908445293083787, Final Batch Loss: 0.05339716747403145\n",
      "Epoch 938, Loss: 0.021687095460947603, Final Batch Loss: 0.0003703713300637901\n",
      "Epoch 939, Loss: 0.025241408264264464, Final Batch Loss: 0.0016837480943650007\n",
      "Epoch 940, Loss: 0.029861036222428083, Final Batch Loss: 0.005404804367572069\n",
      "Epoch 941, Loss: 0.03893065685406327, Final Batch Loss: 0.0056131561286747456\n",
      "Epoch 942, Loss: 0.022283354934188537, Final Batch Loss: 0.00012193915608804673\n",
      "Epoch 943, Loss: 0.030007259290869115, Final Batch Loss: 4.9112200940726325e-05\n",
      "Epoch 944, Loss: 0.023647873662412167, Final Batch Loss: 0.006092298310250044\n",
      "Epoch 945, Loss: 0.03245597379282117, Final Batch Loss: 0.009829574264585972\n",
      "Epoch 946, Loss: 0.04948867950588465, Final Batch Loss: 0.03487689793109894\n",
      "Epoch 947, Loss: 0.018956838350277394, Final Batch Loss: 0.0008155814721249044\n",
      "Epoch 948, Loss: 0.03819712903350592, Final Batch Loss: 0.006269952282309532\n",
      "Epoch 949, Loss: 0.05013991519808769, Final Batch Loss: 0.002520916983485222\n",
      "Epoch 950, Loss: 0.03441237402148545, Final Batch Loss: 0.004047507420182228\n",
      "Epoch 951, Loss: 0.024010489461943507, Final Batch Loss: 0.003197214799001813\n",
      "Epoch 952, Loss: 0.016908624675124884, Final Batch Loss: 0.0007713348604738712\n",
      "Epoch 953, Loss: 0.017429550178349018, Final Batch Loss: 0.000882693100720644\n",
      "Epoch 954, Loss: 0.012756123585859314, Final Batch Loss: 0.00011534654186107218\n",
      "Epoch 955, Loss: 0.032849217765033245, Final Batch Loss: 0.017737241461873055\n",
      "Epoch 956, Loss: 0.02625024924054742, Final Batch Loss: 0.011523780412971973\n",
      "Epoch 957, Loss: 0.024709708581212908, Final Batch Loss: 0.0005952283390797675\n",
      "Epoch 958, Loss: 0.009315270697697997, Final Batch Loss: 0.0016908461693674326\n",
      "Epoch 959, Loss: 0.0233360092388466, Final Batch Loss: 0.0012268327409401536\n",
      "Epoch 960, Loss: 0.016098193293146323, Final Batch Loss: 8.505715959472582e-05\n",
      "Epoch 961, Loss: 0.01471858617151156, Final Batch Loss: 0.0001554508344270289\n",
      "Epoch 962, Loss: 0.025308446492999792, Final Batch Loss: 0.00831983145326376\n",
      "Epoch 963, Loss: 0.03636446874588728, Final Batch Loss: 0.009707693010568619\n",
      "Epoch 964, Loss: 0.011665653611999005, Final Batch Loss: 0.0007306832703761756\n",
      "Epoch 965, Loss: 0.01741144448169507, Final Batch Loss: 0.00037208248977549374\n",
      "Epoch 966, Loss: 0.022194619989022613, Final Batch Loss: 0.003260113066062331\n",
      "Epoch 967, Loss: 0.022196079837158322, Final Batch Loss: 0.0012051446828991175\n",
      "Epoch 968, Loss: 0.011723887422704138, Final Batch Loss: 9.483868780080229e-05\n",
      "Epoch 969, Loss: 0.01686963252723217, Final Batch Loss: 0.004602905362844467\n",
      "Epoch 970, Loss: 0.034446389596269, Final Batch Loss: 0.00011538080434547737\n",
      "Epoch 971, Loss: 0.014992289710789919, Final Batch Loss: 0.003978616092354059\n",
      "Epoch 972, Loss: 0.01894991158042103, Final Batch Loss: 0.0011923309648409486\n",
      "Epoch 973, Loss: 0.017462261661421508, Final Batch Loss: 0.0006009411881677806\n",
      "Epoch 974, Loss: 0.04204482864588499, Final Batch Loss: 0.012353497557342052\n",
      "Epoch 975, Loss: 0.02711931458907202, Final Batch Loss: 0.0003578332834877074\n",
      "Epoch 976, Loss: 0.019189498096238822, Final Batch Loss: 0.0008271873812191188\n",
      "Epoch 977, Loss: 0.014045680174604058, Final Batch Loss: 0.0020667638164013624\n",
      "Epoch 978, Loss: 0.012881753413239494, Final Batch Loss: 0.00033050720230676234\n",
      "Epoch 979, Loss: 0.0163678249809891, Final Batch Loss: 0.0019763095770031214\n",
      "Epoch 980, Loss: 0.06568671599961817, Final Batch Loss: 0.05816036835312843\n",
      "Epoch 981, Loss: 0.012491474219132215, Final Batch Loss: 0.000695619557518512\n",
      "Epoch 982, Loss: 0.039472940377891064, Final Batch Loss: 0.007162596099078655\n",
      "Epoch 983, Loss: 0.014687530187075026, Final Batch Loss: 0.00012961817265022546\n",
      "Epoch 984, Loss: 0.024160866625607014, Final Batch Loss: 0.002104977611452341\n",
      "Epoch 985, Loss: 0.019222081173211336, Final Batch Loss: 0.005346531048417091\n",
      "Epoch 986, Loss: 0.009355306450743228, Final Batch Loss: 0.0003224979736842215\n",
      "Epoch 987, Loss: 0.012998165388125926, Final Batch Loss: 0.0009590930421836674\n",
      "Epoch 988, Loss: 0.00724475360220822, Final Batch Loss: 2.726162529143039e-05\n",
      "Epoch 989, Loss: 0.013925982755608857, Final Batch Loss: 0.0016769153298810124\n",
      "Epoch 990, Loss: 0.016479680372867733, Final Batch Loss: 0.0003585573867894709\n",
      "Epoch 991, Loss: 0.008737572323298082, Final Batch Loss: 0.0001389989338349551\n",
      "Epoch 992, Loss: 0.03622811799868941, Final Batch Loss: 0.0009638555347919464\n",
      "Epoch 993, Loss: 0.011935520684346557, Final Batch Loss: 0.0013085203245282173\n",
      "Epoch 994, Loss: 0.016194255091249943, Final Batch Loss: 0.003052755491808057\n",
      "Epoch 995, Loss: 0.01844426163006574, Final Batch Loss: 0.001107052550651133\n",
      "Epoch 996, Loss: 0.02095381102117244, Final Batch Loss: 0.00015336206706706434\n",
      "Epoch 997, Loss: 0.02094654575921595, Final Batch Loss: 0.001437805825844407\n",
      "Epoch 998, Loss: 0.024311713175848126, Final Batch Loss: 0.0024590298999100924\n",
      "Epoch 999, Loss: 0.017495379666797817, Final Batch Loss: 0.0006783698918297887\n",
      "Epoch 1000, Loss: 0.008493164787068963, Final Batch Loss: 0.00031391659285873175\n",
      "Epoch 1001, Loss: 0.009849289082922041, Final Batch Loss: 0.00036080204881727695\n",
      "Epoch 1002, Loss: 0.011386902420781553, Final Batch Loss: 6.200990173965693e-05\n",
      "Epoch 1003, Loss: 0.025791862077312544, Final Batch Loss: 0.0002757311158347875\n",
      "Epoch 1004, Loss: 0.01197151793166995, Final Batch Loss: 0.004275164566934109\n",
      "Epoch 1005, Loss: 0.013785453513264656, Final Batch Loss: 0.0019261380657553673\n",
      "Epoch 1006, Loss: 0.012171959358965978, Final Batch Loss: 0.0003492744581308216\n",
      "Epoch 1007, Loss: 0.012470646703150123, Final Batch Loss: 0.0003249365254305303\n",
      "Epoch 1008, Loss: 0.01601320574991405, Final Batch Loss: 0.0012592568527907133\n",
      "Epoch 1009, Loss: 0.007183807640103623, Final Batch Loss: 0.0003698158252518624\n",
      "Epoch 1010, Loss: 0.01033072147401981, Final Batch Loss: 0.00044391260598786175\n",
      "Epoch 1011, Loss: 0.05021741893142462, Final Batch Loss: 0.0022543580271303654\n",
      "Epoch 1012, Loss: 0.007627002749359235, Final Batch Loss: 0.0002878309169318527\n",
      "Epoch 1013, Loss: 0.03172953025205061, Final Batch Loss: 0.00054529047338292\n",
      "Epoch 1014, Loss: 0.018088967888616025, Final Batch Loss: 0.0013538770144805312\n",
      "Epoch 1015, Loss: 0.019919284619390965, Final Batch Loss: 0.0001588873565196991\n",
      "Epoch 1016, Loss: 0.01964156166650355, Final Batch Loss: 0.003772654104977846\n",
      "Epoch 1017, Loss: 0.1480637553613633, Final Batch Loss: 0.13983036577701569\n",
      "Epoch 1018, Loss: 0.010901858993747737, Final Batch Loss: 9.950665844371542e-05\n",
      "Epoch 1019, Loss: 0.02934937470126897, Final Batch Loss: 0.0016203724080696702\n",
      "Epoch 1020, Loss: 0.00983676128089428, Final Batch Loss: 0.0027604419738054276\n",
      "Epoch 1021, Loss: 0.02123202267102897, Final Batch Loss: 0.002581043401733041\n",
      "Epoch 1022, Loss: 0.01306565129198134, Final Batch Loss: 0.005277806427329779\n",
      "Epoch 1023, Loss: 0.00478092250705231, Final Batch Loss: 0.00012663770758081228\n",
      "Epoch 1024, Loss: 0.04187282259226777, Final Batch Loss: 0.0002622946922201663\n",
      "Epoch 1025, Loss: 0.024916437250794843, Final Batch Loss: 0.0004063125525135547\n",
      "Epoch 1026, Loss: 0.0098864129249705, Final Batch Loss: 5.383933603297919e-05\n",
      "Epoch 1027, Loss: 0.030554993078112602, Final Batch Loss: 0.013303667306900024\n",
      "Epoch 1028, Loss: 0.005757983710282133, Final Batch Loss: 2.4009199478314258e-05\n",
      "Epoch 1029, Loss: 0.010901129571720958, Final Batch Loss: 0.002112066838890314\n",
      "Epoch 1030, Loss: 0.020719079475384206, Final Batch Loss: 0.0009271252783946693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1031, Loss: 0.01871725681849057, Final Batch Loss: 9.542841144138947e-05\n",
      "Epoch 1032, Loss: 0.0028494170401245356, Final Batch Loss: 0.00029947003349661827\n",
      "Epoch 1033, Loss: 0.012307926488574594, Final Batch Loss: 0.0004473141743801534\n",
      "Epoch 1034, Loss: 0.05288841109722853, Final Batch Loss: 0.04068498685956001\n",
      "Epoch 1035, Loss: 0.007420786698958182, Final Batch Loss: 1.6438268630736275e-06\n",
      "Epoch 1036, Loss: 0.028911123066791333, Final Batch Loss: 0.00024216134625021368\n",
      "Epoch 1037, Loss: 0.016285192337818444, Final Batch Loss: 0.006704553961753845\n",
      "Epoch 1038, Loss: 0.02576450537890196, Final Batch Loss: 0.0010445874650031328\n",
      "Epoch 1039, Loss: 0.005437250030809082, Final Batch Loss: 0.00010315469990018755\n",
      "Epoch 1040, Loss: 0.026997344917617738, Final Batch Loss: 0.009254463948309422\n",
      "Epoch 1041, Loss: 0.012245452380739152, Final Batch Loss: 0.0009129060199484229\n",
      "Epoch 1042, Loss: 0.009251225521438755, Final Batch Loss: 7.264759915415198e-05\n",
      "Epoch 1043, Loss: 0.011374296016583685, Final Batch Loss: 1.4241762983147055e-05\n",
      "Epoch 1044, Loss: 0.0158355576422764, Final Batch Loss: 0.00023340182087849826\n",
      "Epoch 1045, Loss: 0.024279227945953608, Final Batch Loss: 0.013546906411647797\n",
      "Epoch 1046, Loss: 0.006225686724064872, Final Batch Loss: 0.00024932969245128334\n",
      "Epoch 1047, Loss: 0.03793179034255445, Final Batch Loss: 0.0003976193256676197\n",
      "Epoch 1048, Loss: 0.021818319335579872, Final Batch Loss: 0.007837972603738308\n",
      "Epoch 1049, Loss: 0.011671199696138501, Final Batch Loss: 0.002019822597503662\n",
      "Epoch 1050, Loss: 0.007636772759724408, Final Batch Loss: 0.000535425788257271\n",
      "Epoch 1051, Loss: 0.025405770167708397, Final Batch Loss: 0.0030876724049448967\n",
      "Epoch 1052, Loss: 0.0074821506859734654, Final Batch Loss: 0.0007968306308612227\n",
      "Epoch 1053, Loss: 0.006868295546155423, Final Batch Loss: 0.00095298484666273\n",
      "Epoch 1054, Loss: 0.008710851448995527, Final Batch Loss: 8.150890789693221e-05\n",
      "Epoch 1055, Loss: 0.01679613592568785, Final Batch Loss: 0.011147004552185535\n",
      "Epoch 1056, Loss: 0.00902137930097524, Final Batch Loss: 0.00022117602929938585\n",
      "Epoch 1057, Loss: 0.1546971369534731, Final Batch Loss: 0.12275213748216629\n",
      "Epoch 1058, Loss: 0.01257724332390353, Final Batch Loss: 0.00036502600414678454\n",
      "Epoch 1059, Loss: 0.009328085114248097, Final Batch Loss: 0.0010796807473525405\n",
      "Epoch 1060, Loss: 0.0388962210927275, Final Batch Loss: 0.00011461356916697696\n",
      "Epoch 1061, Loss: 0.03854266577400267, Final Batch Loss: 0.0015261371154338121\n",
      "Epoch 1062, Loss: 0.0544617916457355, Final Batch Loss: 0.0074505130760371685\n",
      "Epoch 1063, Loss: 0.030394491972401738, Final Batch Loss: 0.002346054883673787\n",
      "Epoch 1064, Loss: 0.02264899166766554, Final Batch Loss: 0.001294878893531859\n",
      "Epoch 1065, Loss: 0.01571820303797722, Final Batch Loss: 0.0024937386624515057\n",
      "Epoch 1066, Loss: 0.02307433681562543, Final Batch Loss: 0.004509238060563803\n",
      "Epoch 1067, Loss: 0.017978782881982625, Final Batch Loss: 0.0009893291862681508\n",
      "Epoch 1068, Loss: 0.036830664961598814, Final Batch Loss: 0.0016705695306882262\n",
      "Epoch 1069, Loss: 0.02767801907612011, Final Batch Loss: 0.0009060522424988449\n",
      "Epoch 1070, Loss: 0.010370192117989063, Final Batch Loss: 0.0023499992676079273\n",
      "Epoch 1071, Loss: 0.010026838339399546, Final Batch Loss: 0.0005512034404091537\n",
      "Epoch 1072, Loss: 0.03012301540002227, Final Batch Loss: 0.020928507670760155\n",
      "Epoch 1073, Loss: 0.01180979036143981, Final Batch Loss: 0.0004654404183384031\n",
      "Epoch 1074, Loss: 0.011714614345692098, Final Batch Loss: 0.0018068673089146614\n",
      "Epoch 1075, Loss: 0.04222695995122194, Final Batch Loss: 0.0073523931205272675\n",
      "Epoch 1076, Loss: 0.022430638608057052, Final Batch Loss: 0.000654488627333194\n",
      "Epoch 1077, Loss: 0.017506024218164384, Final Batch Loss: 0.0005471579497680068\n",
      "Epoch 1078, Loss: 0.01061251075589098, Final Batch Loss: 0.00046402044245041907\n",
      "Epoch 1079, Loss: 0.0202226567780599, Final Batch Loss: 0.0009854104137048125\n",
      "Epoch 1080, Loss: 0.019444332225248218, Final Batch Loss: 0.0022760271094739437\n",
      "Epoch 1081, Loss: 0.006976891541853547, Final Batch Loss: 0.0015283236280083656\n",
      "Epoch 1082, Loss: 0.006048482842743397, Final Batch Loss: 0.0002100253477692604\n",
      "Epoch 1083, Loss: 0.018063663854263723, Final Batch Loss: 0.0001247319160029292\n",
      "Epoch 1084, Loss: 0.024482046952471137, Final Batch Loss: 0.0018360463436692953\n",
      "Epoch 1085, Loss: 0.028824249064200558, Final Batch Loss: 0.00011188584903720766\n",
      "Epoch 1086, Loss: 0.051820001906889956, Final Batch Loss: 5.367711855797097e-05\n",
      "Epoch 1087, Loss: 0.008773911802563816, Final Batch Loss: 0.0007224894943647087\n",
      "Epoch 1088, Loss: 0.010848279664060101, Final Batch Loss: 0.00029212687513791025\n",
      "Epoch 1089, Loss: 0.004257857566699386, Final Batch Loss: 0.0006478689610958099\n",
      "Epoch 1090, Loss: 0.020473242737352848, Final Batch Loss: 0.004149684216827154\n",
      "Epoch 1091, Loss: 0.00584949110634625, Final Batch Loss: 0.00047249626368284225\n",
      "Epoch 1092, Loss: 0.009539221879094839, Final Batch Loss: 0.004202868789434433\n",
      "Epoch 1093, Loss: 0.027138850768096745, Final Batch Loss: 0.0010056853061541915\n",
      "Epoch 1094, Loss: 0.007570598725578748, Final Batch Loss: 0.00017058708181139082\n",
      "Epoch 1095, Loss: 0.0065722845029085875, Final Batch Loss: 0.0023389949928969145\n",
      "Epoch 1096, Loss: 0.012590642785653472, Final Batch Loss: 0.0010188373271375895\n",
      "Epoch 1097, Loss: 0.015576667618006468, Final Batch Loss: 0.0003600635100156069\n",
      "Epoch 1098, Loss: 0.009562569306581281, Final Batch Loss: 6.196844333317131e-05\n",
      "Epoch 1099, Loss: 0.006939200102351606, Final Batch Loss: 0.0016036751912906766\n",
      "Epoch 1100, Loss: 0.012080330168828368, Final Batch Loss: 0.0011043611448258162\n",
      "Epoch 1101, Loss: 0.014693535049445927, Final Batch Loss: 0.00015995989087969065\n",
      "Epoch 1102, Loss: 0.026663791853934526, Final Batch Loss: 0.005858972202986479\n",
      "Epoch 1103, Loss: 0.00573120650369674, Final Batch Loss: 0.0007816554279997945\n",
      "Epoch 1104, Loss: 0.019494719483191147, Final Batch Loss: 0.0003844612801913172\n",
      "Epoch 1105, Loss: 0.00328675213677343, Final Batch Loss: 0.00023330630210693926\n",
      "Epoch 1106, Loss: 0.01258676522411406, Final Batch Loss: 0.0021949068177491426\n",
      "Epoch 1107, Loss: 0.0305547583848238, Final Batch Loss: 0.0024177376180887222\n",
      "Epoch 1108, Loss: 0.020392064165207557, Final Batch Loss: 9.816202509682626e-05\n",
      "Epoch 1109, Loss: 0.008325292947120033, Final Batch Loss: 0.00011147231271024793\n",
      "Epoch 1110, Loss: 0.008190377615392208, Final Batch Loss: 0.0011202206369489431\n",
      "Epoch 1111, Loss: 0.009851756389252841, Final Batch Loss: 0.000955022987909615\n",
      "Epoch 1112, Loss: 0.043251258437521756, Final Batch Loss: 0.036213964223861694\n",
      "Epoch 1113, Loss: 0.01065567007753998, Final Batch Loss: 0.0006437796400859952\n",
      "Epoch 1114, Loss: 0.018143445253372192, Final Batch Loss: 0.002365217311307788\n",
      "Epoch 1115, Loss: 0.027318052598275244, Final Batch Loss: 0.001100069028325379\n",
      "Epoch 1116, Loss: 0.002754903573077172, Final Batch Loss: 0.00046616827603429556\n",
      "Epoch 1117, Loss: 0.0060511638985190075, Final Batch Loss: 5.391124796005897e-05\n",
      "Epoch 1118, Loss: 0.012838994967751205, Final Batch Loss: 0.0020885509438812733\n",
      "Epoch 1119, Loss: 0.006198379804118304, Final Batch Loss: 4.9585254600970075e-05\n",
      "Epoch 1120, Loss: 0.010199624724918976, Final Batch Loss: 0.0002280046755913645\n",
      "Epoch 1121, Loss: 0.005595140843070112, Final Batch Loss: 0.0001324404584011063\n",
      "Epoch 1122, Loss: 0.014745248481631279, Final Batch Loss: 0.009026400744915009\n",
      "Epoch 1123, Loss: 0.03350603848230094, Final Batch Loss: 0.0002348377602174878\n",
      "Epoch 1124, Loss: 0.006233289494048222, Final Batch Loss: 2.2509024347527884e-05\n",
      "Epoch 1125, Loss: 0.0027397149854095915, Final Batch Loss: 3.482101647023228e-06\n",
      "Epoch 1126, Loss: 0.010087782517075539, Final Batch Loss: 0.007595719303935766\n",
      "Epoch 1127, Loss: 0.0027682133950293064, Final Batch Loss: 0.0006109997630119324\n",
      "Epoch 1128, Loss: 0.05062800704035908, Final Batch Loss: 0.00023018999490886927\n",
      "Epoch 1129, Loss: 0.03379687434062362, Final Batch Loss: 0.004092288203537464\n",
      "Epoch 1130, Loss: 0.014533967623719946, Final Batch Loss: 0.00031723352731205523\n",
      "Epoch 1131, Loss: 0.0030668613908346742, Final Batch Loss: 0.0008796728798188269\n",
      "Epoch 1132, Loss: 0.01926801967783831, Final Batch Loss: 0.00034235729253850877\n",
      "Epoch 1133, Loss: 0.01046721783131943, Final Batch Loss: 4.516338594839908e-05\n",
      "Epoch 1134, Loss: 0.012405097473674687, Final Batch Loss: 3.78142467525322e-05\n",
      "Epoch 1135, Loss: 0.006702337268507108, Final Batch Loss: 0.00014346881653182209\n",
      "Epoch 1136, Loss: 0.00786797353066504, Final Batch Loss: 0.002080732025206089\n",
      "Epoch 1137, Loss: 0.0032227537867584033, Final Batch Loss: 1.1531314157764427e-05\n",
      "Epoch 1138, Loss: 0.04380860278615728, Final Batch Loss: 0.0010787034407258034\n",
      "Epoch 1139, Loss: 0.004426810119184665, Final Batch Loss: 0.00019015306315850466\n",
      "Epoch 1140, Loss: 0.003231915907235816, Final Batch Loss: 0.00034530393895693123\n",
      "Epoch 1141, Loss: 0.025680943683255464, Final Batch Loss: 0.0004074840690009296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1142, Loss: 0.002147096209228039, Final Batch Loss: 0.00015305832494050264\n",
      "Epoch 1143, Loss: 0.00357655436209825, Final Batch Loss: 4.423204245540546e-06\n",
      "Epoch 1144, Loss: 0.03644980117678642, Final Batch Loss: 0.027341779321432114\n",
      "Epoch 1145, Loss: 0.016881181625649333, Final Batch Loss: 0.00640593096613884\n",
      "Epoch 1146, Loss: 0.04889029014157131, Final Batch Loss: 0.0233437679708004\n",
      "Epoch 1147, Loss: 0.0074374740943312645, Final Batch Loss: 0.0005561804864555597\n",
      "Epoch 1148, Loss: 0.0038518281653523445, Final Batch Loss: 0.0013384607154875994\n",
      "Epoch 1149, Loss: 0.011783624242525548, Final Batch Loss: 0.0008752392022870481\n",
      "Epoch 1150, Loss: 0.01991188433021307, Final Batch Loss: 0.013420657254755497\n",
      "Epoch 1151, Loss: 0.011479730572318658, Final Batch Loss: 8.222562610171735e-05\n",
      "Epoch 1152, Loss: 0.009111912353546359, Final Batch Loss: 0.00016333723033312708\n",
      "Epoch 1153, Loss: 0.0026611206703819335, Final Batch Loss: 0.000592533964663744\n",
      "Epoch 1154, Loss: 0.020442593144252896, Final Batch Loss: 0.002863917499780655\n",
      "Epoch 1155, Loss: 0.009060421138201491, Final Batch Loss: 2.0389905330375768e-05\n",
      "Epoch 1156, Loss: 0.0029971302810736233, Final Batch Loss: 6.8011086113983765e-06\n",
      "Epoch 1157, Loss: 0.008933950157370418, Final Batch Loss: 4.234624793753028e-05\n",
      "Epoch 1158, Loss: 0.010614507948048413, Final Batch Loss: 0.00022580521181225777\n",
      "Epoch 1159, Loss: 0.04535568715073168, Final Batch Loss: 0.005905624479055405\n",
      "Epoch 1160, Loss: 0.0023261132955667563, Final Batch Loss: 1.1286356311757118e-05\n",
      "Epoch 1161, Loss: 0.003327317455841694, Final Batch Loss: 2.2139087377581745e-05\n",
      "Epoch 1162, Loss: 0.009686138655524701, Final Batch Loss: 0.003903303062543273\n",
      "Epoch 1163, Loss: 0.01590735834906809, Final Batch Loss: 0.00045679372851736844\n",
      "Epoch 1164, Loss: 0.020134442966082133, Final Batch Loss: 0.00018177788297180086\n",
      "Epoch 1165, Loss: 0.00802539667347446, Final Batch Loss: 0.0008247033110819757\n",
      "Epoch 1166, Loss: 0.1332058977568522, Final Batch Loss: 0.12707610428333282\n",
      "Epoch 1167, Loss: 0.017099228803999722, Final Batch Loss: 0.000588415190577507\n",
      "Epoch 1168, Loss: 0.014006412820890546, Final Batch Loss: 0.00012386718299239874\n",
      "Epoch 1169, Loss: 0.01799355715047568, Final Batch Loss: 0.0011712050763890147\n",
      "Epoch 1170, Loss: 0.032653851609211415, Final Batch Loss: 0.00043229543371126056\n",
      "Epoch 1171, Loss: 0.018023809556325432, Final Batch Loss: 7.514483149861917e-05\n",
      "Epoch 1172, Loss: 0.026634764843038283, Final Batch Loss: 0.00014176311378832906\n",
      "Epoch 1173, Loss: 0.03832250810228288, Final Batch Loss: 0.0007241698913276196\n",
      "Epoch 1174, Loss: 0.03921821084804833, Final Batch Loss: 0.02359599620103836\n",
      "Epoch 1175, Loss: 0.012383677123580128, Final Batch Loss: 0.0006432426744140685\n",
      "Epoch 1176, Loss: 0.047632471440010704, Final Batch Loss: 0.00017576270329300314\n",
      "Epoch 1177, Loss: 0.029906262818258256, Final Batch Loss: 0.0006208319100551307\n",
      "Epoch 1178, Loss: 0.009067767998203635, Final Batch Loss: 0.002082214457914233\n",
      "Epoch 1179, Loss: 0.016373176011256874, Final Batch Loss: 0.0012893181992694736\n",
      "Epoch 1180, Loss: 0.03292658645659685, Final Batch Loss: 0.014139288105070591\n",
      "Epoch 1181, Loss: 0.041899275965988636, Final Batch Loss: 0.023942643776535988\n",
      "Epoch 1182, Loss: 0.006986231775954366, Final Batch Loss: 0.0007897331379354\n",
      "Epoch 1183, Loss: 0.027558812755160034, Final Batch Loss: 0.0007095205364748836\n",
      "Epoch 1184, Loss: 0.02617334556998685, Final Batch Loss: 0.0005863148835487664\n",
      "Epoch 1185, Loss: 0.0040474856505170465, Final Batch Loss: 0.0003295892383903265\n",
      "Epoch 1186, Loss: 0.01793138642096892, Final Batch Loss: 0.0012317835353314877\n",
      "Epoch 1187, Loss: 0.003847132647933904, Final Batch Loss: 4.415025614434853e-05\n",
      "Epoch 1188, Loss: 0.020002990262582898, Final Batch Loss: 0.004646840039640665\n",
      "Epoch 1189, Loss: 0.015113106928765774, Final Batch Loss: 0.00026711239479482174\n",
      "Epoch 1190, Loss: 0.006061199237592518, Final Batch Loss: 0.0031710644252598286\n",
      "Epoch 1191, Loss: 0.004185538098681718, Final Batch Loss: 0.0015095891430974007\n",
      "Epoch 1192, Loss: 0.06831286451779306, Final Batch Loss: 0.041814081370830536\n",
      "Epoch 1193, Loss: 0.003846967258141376, Final Batch Loss: 7.441315392497927e-05\n",
      "Epoch 1194, Loss: 0.007730715675279498, Final Batch Loss: 0.003798982361331582\n",
      "Epoch 1195, Loss: 0.02793214633129537, Final Batch Loss: 0.003884674748405814\n",
      "Epoch 1196, Loss: 0.004396514152176678, Final Batch Loss: 0.001230025663971901\n",
      "Epoch 1197, Loss: 0.022867124062031507, Final Batch Loss: 0.017647990956902504\n",
      "Epoch 1198, Loss: 0.00346568098757416, Final Batch Loss: 0.0006386440363712609\n",
      "Epoch 1199, Loss: 0.004108393186470494, Final Batch Loss: 0.0004580755194183439\n",
      "Epoch 1200, Loss: 0.015390454718726687, Final Batch Loss: 0.00013941949873697013\n",
      "Epoch 1201, Loss: 0.022397331602405757, Final Batch Loss: 0.0004643769352696836\n",
      "Epoch 1202, Loss: 0.20251723390538245, Final Batch Loss: 0.19849343597888947\n",
      "Epoch 1203, Loss: 0.009643492470786441, Final Batch Loss: 1.3632881746161729e-05\n",
      "Epoch 1204, Loss: 0.004016640035843011, Final Batch Loss: 7.191267650341615e-05\n",
      "Epoch 1205, Loss: 0.014856805908493698, Final Batch Loss: 0.0014226172352209687\n",
      "Epoch 1206, Loss: 0.046500618336722255, Final Batch Loss: 0.043292269110679626\n",
      "Epoch 1207, Loss: 0.0015021660874481313, Final Batch Loss: 0.00010575685155345127\n",
      "Epoch 1208, Loss: 0.011238498380407691, Final Batch Loss: 0.00203715986572206\n",
      "Epoch 1209, Loss: 0.0251189349219203, Final Batch Loss: 0.004427103325724602\n",
      "Epoch 1210, Loss: 0.02496192418038845, Final Batch Loss: 0.0032402239739894867\n",
      "Epoch 1211, Loss: 0.032717267458792776, Final Batch Loss: 0.0007627666345797479\n",
      "Epoch 1212, Loss: 0.006560721572896, Final Batch Loss: 9.548549860483035e-05\n",
      "Epoch 1213, Loss: 0.007285874569788575, Final Batch Loss: 0.0020636983681470156\n",
      "Epoch 1214, Loss: 0.014259539544582367, Final Batch Loss: 0.008888441137969494\n",
      "Epoch 1215, Loss: 0.0221389876678586, Final Batch Loss: 0.0016481884522363544\n",
      "Epoch 1216, Loss: 0.04664576333016157, Final Batch Loss: 0.00781537126749754\n",
      "Epoch 1217, Loss: 0.029219769407063723, Final Batch Loss: 0.002597218379378319\n",
      "Epoch 1218, Loss: 0.00730903132352978, Final Batch Loss: 0.001040431670844555\n",
      "Epoch 1219, Loss: 0.020119608379900455, Final Batch Loss: 0.01268026977777481\n",
      "Epoch 1220, Loss: 0.004700395744293928, Final Batch Loss: 0.0008254894055426121\n",
      "Epoch 1221, Loss: 0.009619858814403415, Final Batch Loss: 0.005051817744970322\n",
      "Epoch 1222, Loss: 0.036567761562764645, Final Batch Loss: 0.030490044504404068\n",
      "Epoch 1223, Loss: 0.02696167677640915, Final Batch Loss: 0.005515928380191326\n",
      "Epoch 1224, Loss: 0.06853037979453802, Final Batch Loss: 0.02065502665936947\n",
      "Epoch 1225, Loss: 0.01042597065679729, Final Batch Loss: 0.00047801132313907146\n",
      "Epoch 1226, Loss: 0.02321053296327591, Final Batch Loss: 0.00013599079102277756\n",
      "Epoch 1227, Loss: 0.25111133605241776, Final Batch Loss: 0.2306206077337265\n",
      "Epoch 1228, Loss: 0.010214581998297945, Final Batch Loss: 0.0003707129799295217\n",
      "Epoch 1229, Loss: 0.005373517400585115, Final Batch Loss: 0.0018945749616250396\n",
      "Epoch 1230, Loss: 0.02678762236610055, Final Batch Loss: 0.0065259248949587345\n",
      "Epoch 1231, Loss: 0.010947356233373284, Final Batch Loss: 0.0016704511363059282\n",
      "Epoch 1232, Loss: 0.010400832688901573, Final Batch Loss: 0.0009272038587369025\n",
      "Epoch 1233, Loss: 0.01663625449873507, Final Batch Loss: 0.003015513764694333\n",
      "Epoch 1234, Loss: 0.015376790150185116, Final Batch Loss: 0.000169422899489291\n",
      "Epoch 1235, Loss: 0.015834552003070712, Final Batch Loss: 0.0009365386795252562\n",
      "Epoch 1236, Loss: 0.0341112052265089, Final Batch Loss: 0.000161203759489581\n",
      "Epoch 1237, Loss: 0.0075570541666820645, Final Batch Loss: 0.004431716166436672\n",
      "Epoch 1238, Loss: 0.03399156327941455, Final Batch Loss: 0.0004665983433369547\n",
      "Epoch 1239, Loss: 0.0021204116783337668, Final Batch Loss: 0.00011052617628592998\n",
      "Epoch 1240, Loss: 0.007515016674005892, Final Batch Loss: 2.6750109100248665e-05\n",
      "Epoch 1241, Loss: 0.004076394019648433, Final Batch Loss: 0.0011013097828254104\n",
      "Epoch 1242, Loss: 0.013691714848391712, Final Batch Loss: 0.0006929647643119097\n",
      "Epoch 1243, Loss: 0.016839847317896783, Final Batch Loss: 0.0016304311575368047\n",
      "Epoch 1244, Loss: 0.02437480294611305, Final Batch Loss: 0.0011761992936953902\n",
      "Epoch 1245, Loss: 0.022026973660103977, Final Batch Loss: 0.0009402198484167457\n",
      "Epoch 1246, Loss: 0.009810547606321052, Final Batch Loss: 0.00015871998039074242\n",
      "Epoch 1247, Loss: 0.03736678118002601, Final Batch Loss: 0.00014036989887245\n",
      "Epoch 1248, Loss: 0.06625085661653429, Final Batch Loss: 0.05418926104903221\n",
      "Epoch 1249, Loss: 0.0024890191853046417, Final Batch Loss: 0.0002479080867487937\n",
      "Epoch 1250, Loss: 0.009556843084283173, Final Batch Loss: 0.0012775358045473695\n",
      "Epoch 1251, Loss: 0.007880228920839727, Final Batch Loss: 0.0015185539377853274\n",
      "Epoch 1252, Loss: 0.005450047756312415, Final Batch Loss: 6.277530337683856e-05\n",
      "Epoch 1253, Loss: 0.00541825796244666, Final Batch Loss: 0.00030545261688530445\n",
      "Epoch 1254, Loss: 0.04001661925576627, Final Batch Loss: 0.03423537313938141\n",
      "Epoch 1255, Loss: 0.009478366759140044, Final Batch Loss: 0.00782020203769207\n",
      "Epoch 1256, Loss: 0.002463720244122669, Final Batch Loss: 0.0001646562886890024\n",
      "Epoch 1257, Loss: 0.04359401360852644, Final Batch Loss: 0.0008772888104431331\n",
      "Epoch 1258, Loss: 0.01113173812336754, Final Batch Loss: 0.0001821936311898753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1259, Loss: 0.007720771012827754, Final Batch Loss: 0.0024314941838383675\n",
      "Epoch 1260, Loss: 0.012237111455760896, Final Batch Loss: 0.0012472878443077207\n",
      "Epoch 1261, Loss: 0.023421433055773377, Final Batch Loss: 0.0005560151766985655\n",
      "Epoch 1262, Loss: 0.004539934074273333, Final Batch Loss: 0.0004602595290634781\n",
      "Epoch 1263, Loss: 0.0032896309276111424, Final Batch Loss: 0.0003401573048904538\n",
      "Epoch 1264, Loss: 0.017880979501569527, Final Batch Loss: 1.6405056157964282e-05\n",
      "Epoch 1265, Loss: 0.013293407131641288, Final Batch Loss: 1.0521473086555488e-05\n",
      "Epoch 1266, Loss: 0.0026380366762168705, Final Batch Loss: 0.0006303191767074168\n",
      "Epoch 1267, Loss: 0.006221415242180228, Final Batch Loss: 0.002065720036625862\n",
      "Epoch 1268, Loss: 0.00885126796856639, Final Batch Loss: 5.476536534843035e-05\n",
      "Epoch 1269, Loss: 0.004864395770709962, Final Batch Loss: 0.0007735830149613321\n",
      "Epoch 1270, Loss: 0.017822550667915493, Final Batch Loss: 0.01121615618467331\n",
      "Epoch 1271, Loss: 0.003456157515756786, Final Batch Loss: 0.0016451019328087568\n",
      "Epoch 1272, Loss: 0.0013920517085352913, Final Batch Loss: 0.00013744337775278836\n",
      "Epoch 1273, Loss: 0.0035880558425560594, Final Batch Loss: 0.00028287863824516535\n",
      "Epoch 1274, Loss: 0.012613583588972688, Final Batch Loss: 0.0017318502068519592\n",
      "Epoch 1275, Loss: 0.0045325357059482485, Final Batch Loss: 6.57585624139756e-05\n",
      "Epoch 1276, Loss: 0.003981390269473195, Final Batch Loss: 0.0007957549532875419\n",
      "Epoch 1277, Loss: 0.0032486852433066815, Final Batch Loss: 0.0004035784804727882\n",
      "Epoch 1278, Loss: 0.010692507610656321, Final Batch Loss: 0.0016276870155707002\n",
      "Epoch 1279, Loss: 0.0032800598546600668, Final Batch Loss: 2.041419611487072e-05\n",
      "Epoch 1280, Loss: 0.002434749658277724, Final Batch Loss: 0.00010202793782809749\n",
      "Epoch 1281, Loss: 0.0042043093126267195, Final Batch Loss: 0.000616624834947288\n",
      "Epoch 1282, Loss: 0.0044028895208612084, Final Batch Loss: 0.002738826908171177\n",
      "Epoch 1283, Loss: 0.02883542003110051, Final Batch Loss: 0.0012124511413276196\n",
      "Epoch 1284, Loss: 0.012084454065188766, Final Batch Loss: 0.008231289684772491\n",
      "Epoch 1285, Loss: 0.01830302953021601, Final Batch Loss: 0.0005693125422112644\n",
      "Epoch 1286, Loss: 0.028033133086864837, Final Batch Loss: 4.7713067033328116e-05\n",
      "Epoch 1287, Loss: 0.0033511714718770236, Final Batch Loss: 0.00044369130046106875\n",
      "Epoch 1288, Loss: 0.062384011631365865, Final Batch Loss: 0.06064558029174805\n",
      "Epoch 1289, Loss: 0.002886862581362948, Final Batch Loss: 0.0013933830196037889\n",
      "Epoch 1290, Loss: 0.003961330512538552, Final Batch Loss: 0.00013379997108131647\n",
      "Epoch 1291, Loss: 0.022329246578010498, Final Batch Loss: 3.152661884087138e-05\n",
      "Epoch 1292, Loss: 0.011738061293726787, Final Batch Loss: 0.002019033534452319\n",
      "Epoch 1293, Loss: 0.02543235428220214, Final Batch Loss: 8.576294021622743e-06\n",
      "Epoch 1294, Loss: 0.005794974655145779, Final Batch Loss: 0.0001357677683699876\n",
      "Epoch 1295, Loss: 0.036179114191327244, Final Batch Loss: 0.0004870230914093554\n",
      "Epoch 1296, Loss: 0.013045024476014078, Final Batch Loss: 0.0020149715710431337\n",
      "Epoch 1297, Loss: 0.029994282536790706, Final Batch Loss: 3.0430630431510508e-05\n",
      "Epoch 1298, Loss: 0.001842924510128796, Final Batch Loss: 0.0007178264786489308\n",
      "Epoch 1299, Loss: 0.01256016013212502, Final Batch Loss: 0.004821726121008396\n",
      "Epoch 1300, Loss: 0.01111287929234095, Final Batch Loss: 0.002623381093144417\n",
      "Epoch 1301, Loss: 0.006602395893423818, Final Batch Loss: 0.00016597377543803304\n",
      "Epoch 1302, Loss: 0.0025774121713766363, Final Batch Loss: 1.0214014764642343e-05\n",
      "Epoch 1303, Loss: 0.016309120692312717, Final Batch Loss: 0.003203108673915267\n",
      "Epoch 1304, Loss: 0.001674280058068689, Final Batch Loss: 3.8934369513299316e-05\n",
      "Epoch 1305, Loss: 0.016628767945803702, Final Batch Loss: 0.00151266239117831\n",
      "Epoch 1306, Loss: 0.013974848319776356, Final Batch Loss: 0.011219264939427376\n",
      "Epoch 1307, Loss: 0.026674723856558558, Final Batch Loss: 7.888269465183839e-05\n",
      "Epoch 1308, Loss: 0.0038162109194672666, Final Batch Loss: 2.8272239433135837e-05\n",
      "Epoch 1309, Loss: 0.002292717734235339, Final Batch Loss: 0.00024164414207916707\n",
      "Epoch 1310, Loss: 0.03309266134601785, Final Batch Loss: 3.994692087871954e-05\n",
      "Epoch 1311, Loss: 0.0044204932055436075, Final Batch Loss: 7.345696212723851e-05\n",
      "Epoch 1312, Loss: 0.007041695451334817, Final Batch Loss: 3.241611921112053e-05\n",
      "Epoch 1313, Loss: 0.008176850795280188, Final Batch Loss: 0.005755046382546425\n",
      "Epoch 1314, Loss: 0.015001064535681508, Final Batch Loss: 8.783672456047498e-06\n",
      "Epoch 1315, Loss: 0.00487325903668534, Final Batch Loss: 0.0001056528853951022\n",
      "Epoch 1316, Loss: 0.007919476251117885, Final Batch Loss: 0.0010051082354038954\n",
      "Epoch 1317, Loss: 0.08484105014940724, Final Batch Loss: 0.08219844847917557\n",
      "Epoch 1318, Loss: 0.01200244541905704, Final Batch Loss: 3.279537122580223e-05\n",
      "Epoch 1319, Loss: 0.04345115623436868, Final Batch Loss: 0.0004203103017061949\n",
      "Epoch 1320, Loss: 0.015826258342713118, Final Batch Loss: 0.001991287572309375\n",
      "Epoch 1321, Loss: 0.0039017819217406213, Final Batch Loss: 6.399379344657063e-05\n",
      "Epoch 1322, Loss: 0.006971654365770519, Final Batch Loss: 0.0006916545098647475\n",
      "Epoch 1323, Loss: 0.012036060565151274, Final Batch Loss: 0.0016762599116191268\n",
      "Epoch 1324, Loss: 0.0064470333400095114, Final Batch Loss: 2.5061797714442946e-05\n",
      "Epoch 1325, Loss: 0.005112419603392482, Final Batch Loss: 0.0013125570258125663\n",
      "Epoch 1326, Loss: 0.005305231912643649, Final Batch Loss: 0.00022722443100064993\n",
      "Epoch 1327, Loss: 0.0021060423459857702, Final Batch Loss: 0.00019409781089052558\n",
      "Epoch 1328, Loss: 0.006155968294478953, Final Batch Loss: 0.0010094445897266269\n",
      "Epoch 1329, Loss: 0.002772313600871712, Final Batch Loss: 0.0003079843008890748\n",
      "Epoch 1330, Loss: 0.008398775826208293, Final Batch Loss: 0.004233560524880886\n",
      "Epoch 1331, Loss: 0.005942834191955626, Final Batch Loss: 0.0001344769261777401\n",
      "Epoch 1332, Loss: 0.0034650627349037677, Final Batch Loss: 7.317090057767928e-05\n",
      "Epoch 1333, Loss: 0.0016001794574549422, Final Batch Loss: 7.996165368240327e-05\n",
      "Epoch 1334, Loss: 0.016399152344092727, Final Batch Loss: 0.0071267783641815186\n",
      "Epoch 1335, Loss: 0.003269516695581842, Final Batch Loss: 0.00011335721501382068\n",
      "Epoch 1336, Loss: 0.017785508374799974, Final Batch Loss: 0.00014112128701526672\n",
      "Epoch 1337, Loss: 0.027749496832257137, Final Batch Loss: 4.882444045506418e-05\n",
      "Epoch 1338, Loss: 0.0022530105743499007, Final Batch Loss: 4.605768117471598e-05\n",
      "Epoch 1339, Loss: 0.010989797359798104, Final Batch Loss: 0.0008333792793564498\n",
      "Epoch 1340, Loss: 0.004135250084800646, Final Batch Loss: 0.0003162409702781588\n",
      "Epoch 1341, Loss: 0.011667535873129964, Final Batch Loss: 0.001692877965979278\n",
      "Epoch 1342, Loss: 0.0037202596649876796, Final Batch Loss: 0.00012175671145087108\n",
      "Epoch 1343, Loss: 0.0031605312833562493, Final Batch Loss: 0.001394808990880847\n",
      "Epoch 1344, Loss: 0.002479248789313715, Final Batch Loss: 3.869143984047696e-05\n",
      "Epoch 1345, Loss: 0.023314890132496657, Final Batch Loss: 4.3478512452566065e-06\n",
      "Epoch 1346, Loss: 0.008172392495907843, Final Batch Loss: 0.0054322206415236\n",
      "Epoch 1347, Loss: 0.07239396451041102, Final Batch Loss: 0.04925459623336792\n",
      "Epoch 1348, Loss: 0.00208676110196393, Final Batch Loss: 0.00013900121848564595\n",
      "Epoch 1349, Loss: 0.15426203788956627, Final Batch Loss: 0.144983172416687\n",
      "Epoch 1350, Loss: 0.005994940554955974, Final Batch Loss: 0.004341559484601021\n",
      "Epoch 1351, Loss: 0.06332609982928261, Final Batch Loss: 0.007361652795225382\n",
      "Epoch 1352, Loss: 0.04558544419705868, Final Batch Loss: 0.006050685420632362\n",
      "Epoch 1353, Loss: 0.05694277607835829, Final Batch Loss: 0.0013472812715917826\n",
      "Epoch 1354, Loss: 0.14684898289851844, Final Batch Loss: 0.10703692585229874\n",
      "Epoch 1355, Loss: 0.025197707233019173, Final Batch Loss: 0.00024290301371365786\n",
      "Epoch 1356, Loss: 0.0424395720474422, Final Batch Loss: 0.008264687843620777\n",
      "Epoch 1357, Loss: 0.1392838954925537, Final Batch Loss: 0.06981446593999863\n",
      "Epoch 1358, Loss: 0.04131518315989524, Final Batch Loss: 0.0006963127525523305\n",
      "Epoch 1359, Loss: 0.008189466083422303, Final Batch Loss: 0.0010015284642577171\n",
      "Epoch 1360, Loss: 0.019462963618934737, Final Batch Loss: 1.063412673829589e-05\n",
      "Epoch 1361, Loss: 0.2681507091037929, Final Batch Loss: 0.25413885712623596\n",
      "Epoch 1362, Loss: 0.04179068497614935, Final Batch Loss: 0.0006015028920955956\n",
      "Epoch 1363, Loss: 0.015566767891868949, Final Batch Loss: 0.0005003921687602997\n",
      "Epoch 1364, Loss: 0.007638550319825299, Final Batch Loss: 0.00020116027735639364\n",
      "Epoch 1365, Loss: 0.0315984875196591, Final Batch Loss: 0.0008656650315970182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1366, Loss: 0.03549092456523795, Final Batch Loss: 0.00021459355775732547\n",
      "Epoch 1367, Loss: 0.009250862174667418, Final Batch Loss: 0.00170699052978307\n",
      "Epoch 1368, Loss: 0.014096442100708373, Final Batch Loss: 0.0001867515529738739\n",
      "Epoch 1369, Loss: 0.006059873412596062, Final Batch Loss: 0.0003602919459808618\n",
      "Epoch 1370, Loss: 0.02620206036954187, Final Batch Loss: 5.892952322028577e-05\n",
      "Epoch 1371, Loss: 0.01646797760622576, Final Batch Loss: 0.0006664838292635977\n",
      "Epoch 1372, Loss: 0.025447586638620123, Final Batch Loss: 0.00029558929963968694\n",
      "Epoch 1373, Loss: 0.03781939236796461, Final Batch Loss: 0.00020164213492535055\n",
      "Epoch 1374, Loss: 0.03466303460299969, Final Batch Loss: 0.01352563314139843\n",
      "Epoch 1375, Loss: 0.010770217049866915, Final Batch Loss: 0.004216225352138281\n",
      "Epoch 1376, Loss: 0.014293314190581441, Final Batch Loss: 0.002978147938847542\n",
      "Epoch 1377, Loss: 0.02525407844223082, Final Batch Loss: 0.008263258263468742\n",
      "Epoch 1378, Loss: 0.02710490335562099, Final Batch Loss: 3.6138746963843005e-06\n",
      "Epoch 1379, Loss: 0.026032311288872734, Final Batch Loss: 0.00034543490619398654\n",
      "Epoch 1380, Loss: 0.019136646995320916, Final Batch Loss: 0.013754463754594326\n",
      "Epoch 1381, Loss: 0.017376333591528237, Final Batch Loss: 0.0016507211839780211\n",
      "Epoch 1382, Loss: 0.02916140604065731, Final Batch Loss: 0.0005007328581996262\n",
      "Epoch 1383, Loss: 0.007134546642191708, Final Batch Loss: 0.0016785453772172332\n",
      "Epoch 1384, Loss: 0.12520488922018558, Final Batch Loss: 0.11497525125741959\n",
      "Epoch 1385, Loss: 0.024458840140141547, Final Batch Loss: 0.0012537349248304963\n",
      "Epoch 1386, Loss: 0.020578716415911913, Final Batch Loss: 0.0016173296608030796\n",
      "Epoch 1387, Loss: 0.01744739036075771, Final Batch Loss: 0.0013333761598914862\n",
      "Epoch 1388, Loss: 0.009205008740536869, Final Batch Loss: 0.0011044807033613324\n",
      "Epoch 1389, Loss: 0.009592080093852928, Final Batch Loss: 1.3865771961718565e-06\n",
      "Epoch 1390, Loss: 0.03450839244760573, Final Batch Loss: 0.0038939781952649355\n",
      "Epoch 1391, Loss: 0.010287888231687248, Final Batch Loss: 0.0017545911250635982\n",
      "Epoch 1392, Loss: 0.014405346242710948, Final Batch Loss: 0.001044881297275424\n",
      "Epoch 1393, Loss: 0.029300170514034107, Final Batch Loss: 0.0003952333063352853\n",
      "Epoch 1394, Loss: 0.022969553247094154, Final Batch Loss: 0.00045200902968645096\n",
      "Epoch 1395, Loss: 0.024107337347231805, Final Batch Loss: 0.01927107758820057\n",
      "Epoch 1396, Loss: 0.03323615388944745, Final Batch Loss: 0.0232001394033432\n",
      "Epoch 1397, Loss: 0.005018063489842461, Final Batch Loss: 3.621251744334586e-05\n",
      "Epoch 1398, Loss: 0.006136363372206688, Final Batch Loss: 0.0013590973103418946\n",
      "Epoch 1399, Loss: 0.02109171194024384, Final Batch Loss: 0.0008008850272744894\n",
      "Epoch 1400, Loss: 0.0077452067052945495, Final Batch Loss: 0.004088105168193579\n",
      "Epoch 1401, Loss: 0.007311881519854069, Final Batch Loss: 0.0017387184780091047\n",
      "Epoch 1402, Loss: 0.011475921142846346, Final Batch Loss: 0.0013139060465618968\n",
      "Epoch 1403, Loss: 0.007705245167016983, Final Batch Loss: 0.0009057435672730207\n",
      "Epoch 1404, Loss: 0.009938625385984778, Final Batch Loss: 0.0026538213714957237\n",
      "Epoch 1405, Loss: 0.030175657127983868, Final Batch Loss: 0.02107931300997734\n",
      "Epoch 1406, Loss: 0.024932279833592474, Final Batch Loss: 0.0059095160104334354\n",
      "Epoch 1407, Loss: 0.19830854516476393, Final Batch Loss: 0.19570301473140717\n",
      "Epoch 1408, Loss: 0.0037341396091505885, Final Batch Loss: 0.0006889658980071545\n",
      "Epoch 1409, Loss: 0.011310451431199908, Final Batch Loss: 0.0020351011771708727\n",
      "Epoch 1410, Loss: 0.003575378330424428, Final Batch Loss: 0.00045522639993578196\n",
      "Epoch 1411, Loss: 0.0071975881000980735, Final Batch Loss: 0.00023380632046610117\n",
      "Epoch 1412, Loss: 0.0038422351353801787, Final Batch Loss: 0.00030816131038591266\n",
      "Epoch 1413, Loss: 0.00663780065588071, Final Batch Loss: 5.942541974945925e-05\n",
      "Epoch 1414, Loss: 0.003575967813958414, Final Batch Loss: 0.00010684721928555518\n",
      "Epoch 1415, Loss: 0.0061474459234887036, Final Batch Loss: 2.0521505575743504e-05\n",
      "Epoch 1416, Loss: 0.005644339307764312, Final Batch Loss: 5.548650733544491e-05\n",
      "Epoch 1417, Loss: 0.010283299721777439, Final Batch Loss: 0.004117763135582209\n",
      "Epoch 1418, Loss: 0.00824360060505569, Final Batch Loss: 0.002288954798132181\n",
      "Epoch 1419, Loss: 0.010555830798693933, Final Batch Loss: 0.00021561725588981062\n",
      "Epoch 1420, Loss: 0.01262957389735675, Final Batch Loss: 1.8821296180249192e-05\n",
      "Epoch 1421, Loss: 0.017007373040542006, Final Batch Loss: 0.0024909486528486013\n",
      "Epoch 1422, Loss: 0.009874252627923852, Final Batch Loss: 4.5577555283671245e-05\n",
      "Epoch 1423, Loss: 0.037632496969308704, Final Batch Loss: 0.015746530145406723\n",
      "Epoch 1424, Loss: 0.020070733793545514, Final Batch Loss: 0.0006846871110610664\n",
      "Epoch 1425, Loss: 0.049486652482301, Final Batch Loss: 0.0023808875121176243\n",
      "Epoch 1426, Loss: 0.0036599115046556108, Final Batch Loss: 5.960282578598708e-06\n",
      "Epoch 1427, Loss: 0.007115945219993591, Final Batch Loss: 0.0021552599500864744\n",
      "Epoch 1428, Loss: 0.03361919487360865, Final Batch Loss: 0.0008215024136006832\n",
      "Epoch 1429, Loss: 0.007869351207773434, Final Batch Loss: 6.046229464118369e-05\n",
      "Epoch 1430, Loss: 0.0031321090609708335, Final Batch Loss: 3.115390063612722e-05\n",
      "Epoch 1431, Loss: 0.035253296594419226, Final Batch Loss: 5.245080501481425e-06\n",
      "Epoch 1432, Loss: 0.006471967790275812, Final Batch Loss: 0.0035029740538448095\n",
      "Epoch 1433, Loss: 0.013900601141358493, Final Batch Loss: 4.839228859054856e-05\n",
      "Epoch 1434, Loss: 0.006986823806073517, Final Batch Loss: 0.0006423132144846022\n",
      "Epoch 1435, Loss: 0.040340479114092886, Final Batch Loss: 0.03567631542682648\n",
      "Epoch 1436, Loss: 0.011952206143178046, Final Batch Loss: 0.008174565620720387\n",
      "Epoch 1437, Loss: 0.010079195864818757, Final Batch Loss: 1.7246373317902908e-05\n",
      "Epoch 1438, Loss: 0.05505711538717151, Final Batch Loss: 0.05139517784118652\n",
      "Epoch 1439, Loss: 0.01825645682401955, Final Batch Loss: 0.004121643025428057\n",
      "Epoch 1440, Loss: 0.01254561661335174, Final Batch Loss: 8.383650856558233e-05\n",
      "Epoch 1441, Loss: 0.011491715558804572, Final Batch Loss: 0.0002702405909076333\n",
      "Epoch 1442, Loss: 0.024610287975519896, Final Batch Loss: 0.0036973822861909866\n",
      "Epoch 1443, Loss: 0.027417813194915652, Final Batch Loss: 9.308732114732265e-05\n",
      "Epoch 1444, Loss: 0.038129393476992846, Final Batch Loss: 0.013489814475178719\n",
      "Epoch 1445, Loss: 0.007335552818403812, Final Batch Loss: 6.033933095750399e-05\n",
      "Epoch 1446, Loss: 0.026557517936453223, Final Batch Loss: 0.0004250414203852415\n",
      "Epoch 1447, Loss: 0.026010636356659234, Final Batch Loss: 0.0013178932713344693\n",
      "Epoch 1448, Loss: 0.017910708906129003, Final Batch Loss: 0.006295506376773119\n",
      "Epoch 1449, Loss: 0.005806178494822234, Final Batch Loss: 0.0006211193394847214\n",
      "Epoch 1450, Loss: 0.024953577667474747, Final Batch Loss: 0.0024481385480612516\n",
      "Epoch 1451, Loss: 0.015272093238309026, Final Batch Loss: 0.0013880045153200626\n",
      "Epoch 1452, Loss: 0.038544343784451485, Final Batch Loss: 0.003334274748340249\n",
      "Epoch 1453, Loss: 0.05096852406859398, Final Batch Loss: 0.0011933939531445503\n",
      "Epoch 1454, Loss: 0.007589791959617287, Final Batch Loss: 0.0006787321181036532\n",
      "Epoch 1455, Loss: 0.011111619300208986, Final Batch Loss: 0.000852719065733254\n",
      "Epoch 1456, Loss: 0.019349701120518148, Final Batch Loss: 0.0008317481260746717\n",
      "Epoch 1457, Loss: 0.0057376481126993895, Final Batch Loss: 0.0003271868918091059\n",
      "Epoch 1458, Loss: 0.0091595568228513, Final Batch Loss: 0.0028178419452160597\n",
      "Epoch 1459, Loss: 0.006870817422168329, Final Batch Loss: 0.0022197426296770573\n",
      "Epoch 1460, Loss: 0.007062456221319735, Final Batch Loss: 0.0011916238581761718\n",
      "Epoch 1461, Loss: 0.03747445538829197, Final Batch Loss: 1.4911947801010683e-05\n",
      "Epoch 1462, Loss: 0.04979324073065072, Final Batch Loss: 0.045490287244319916\n",
      "Epoch 1463, Loss: 0.004424988073878922, Final Batch Loss: 0.00018167706730309874\n",
      "Epoch 1464, Loss: 0.005799266509711742, Final Batch Loss: 0.001789261237718165\n",
      "Epoch 1465, Loss: 0.006078432657886879, Final Batch Loss: 2.569367097748909e-05\n",
      "Epoch 1466, Loss: 0.04172890749759972, Final Batch Loss: 0.01286789495497942\n",
      "Epoch 1467, Loss: 0.008548723824787885, Final Batch Loss: 0.0004443815560080111\n",
      "Epoch 1468, Loss: 0.0120198501390405, Final Batch Loss: 0.005425521172583103\n",
      "Epoch 1469, Loss: 0.019478349131532013, Final Batch Loss: 0.016511086374521255\n",
      "Epoch 1470, Loss: 0.008721138583496213, Final Batch Loss: 0.002564300550147891\n",
      "Epoch 1471, Loss: 0.015110489184735343, Final Batch Loss: 0.00036009514587931335\n",
      "Epoch 1472, Loss: 0.01826824121963, Final Batch Loss: 8.191182132577524e-05\n",
      "Epoch 1473, Loss: 0.04752827400807291, Final Batch Loss: 0.018865743651986122\n",
      "Epoch 1474, Loss: 0.003888508479576558, Final Batch Loss: 0.0005703258793801069\n",
      "Epoch 1475, Loss: 0.013347769199754111, Final Batch Loss: 0.00017982190183829516\n",
      "Epoch 1476, Loss: 0.04052406130358577, Final Batch Loss: 0.0060751475393772125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1477, Loss: 0.025487714388873428, Final Batch Loss: 0.000442524382378906\n",
      "Epoch 1478, Loss: 0.01365133241051808, Final Batch Loss: 0.0004791499231941998\n",
      "Epoch 1479, Loss: 0.005406405514804646, Final Batch Loss: 0.0001108689175453037\n",
      "Epoch 1480, Loss: 0.0014584514865418896, Final Batch Loss: 0.00019672470807563514\n",
      "Epoch 1481, Loss: 0.008395159617066383, Final Batch Loss: 0.003288552863523364\n",
      "Epoch 1482, Loss: 0.003123333299299702, Final Batch Loss: 0.0002764321106951684\n",
      "Epoch 1483, Loss: 0.004727050196379423, Final Batch Loss: 0.0005280678160488605\n",
      "Epoch 1484, Loss: 0.01264922662085155, Final Batch Loss: 3.618238406488672e-05\n",
      "Epoch 1485, Loss: 0.04693958361167461, Final Batch Loss: 0.0032228827476501465\n",
      "Epoch 1486, Loss: 0.017741499468684196, Final Batch Loss: 8.913292549550533e-05\n",
      "Epoch 1487, Loss: 0.020971984253264964, Final Batch Loss: 0.018066827207803726\n",
      "Epoch 1488, Loss: 0.011214964441023767, Final Batch Loss: 0.00016603863332420588\n",
      "Epoch 1489, Loss: 0.027544844546355307, Final Batch Loss: 0.0013534805038943887\n",
      "Epoch 1490, Loss: 0.05099406158296915, Final Batch Loss: 1.732231794449035e-05\n",
      "Epoch 1491, Loss: 0.00761107582366094, Final Batch Loss: 0.0008930189651437104\n",
      "Epoch 1492, Loss: 0.006597800820600241, Final Batch Loss: 0.0005922056152485311\n",
      "Epoch 1493, Loss: 0.020809987909160554, Final Batch Loss: 0.0017066787695512176\n",
      "Epoch 1494, Loss: 0.010242247895803303, Final Batch Loss: 0.0006700858357362449\n",
      "Epoch 1495, Loss: 0.012222269549965858, Final Batch Loss: 0.00012663868255913258\n",
      "Epoch 1496, Loss: 0.01792637017206289, Final Batch Loss: 0.00014246758655644953\n",
      "Epoch 1497, Loss: 0.008614646038040519, Final Batch Loss: 0.0006002886220812798\n",
      "Epoch 1498, Loss: 0.01730030563339824, Final Batch Loss: 0.00010284755990142003\n",
      "Epoch 1499, Loss: 0.00936515792272985, Final Batch Loss: 0.005497713107615709\n",
      "Epoch 1500, Loss: 0.004334124270826578, Final Batch Loss: 0.00079172826372087\n",
      "Epoch 1501, Loss: 0.005024923790188041, Final Batch Loss: 8.67731505422853e-05\n",
      "Epoch 1502, Loss: 0.013274434953927994, Final Batch Loss: 0.00014657294377684593\n",
      "Epoch 1503, Loss: 0.006944474647752941, Final Batch Loss: 0.0038071866147220135\n",
      "Epoch 1504, Loss: 0.017586313450010493, Final Batch Loss: 0.000372750946553424\n",
      "Epoch 1505, Loss: 0.025343902947497554, Final Batch Loss: 6.238192145247012e-05\n",
      "Epoch 1506, Loss: 0.01479280594503507, Final Batch Loss: 0.0021186545491218567\n",
      "Epoch 1507, Loss: 0.009886689367704093, Final Batch Loss: 0.0003866363549605012\n",
      "Epoch 1508, Loss: 0.006015701568685472, Final Batch Loss: 0.0030507042538374662\n",
      "Epoch 1509, Loss: 0.03696119133383036, Final Batch Loss: 0.011399266310036182\n",
      "Epoch 1510, Loss: 0.005278118420392275, Final Batch Loss: 0.0006382570136338472\n",
      "Epoch 1511, Loss: 0.02343402651604265, Final Batch Loss: 0.0002298150211572647\n",
      "Epoch 1512, Loss: 0.013842284417478368, Final Batch Loss: 0.00032301570172421634\n",
      "Epoch 1513, Loss: 0.012271100407815538, Final Batch Loss: 9.634414163883775e-05\n",
      "Epoch 1514, Loss: 0.03233303630258888, Final Batch Loss: 0.00045376981142908335\n",
      "Epoch 1515, Loss: 0.01481783640338108, Final Batch Loss: 0.003375719301402569\n",
      "Epoch 1516, Loss: 0.0020171303185634315, Final Batch Loss: 0.00024515687255188823\n",
      "Epoch 1517, Loss: 0.005898384886677377, Final Batch Loss: 0.0001966380950761959\n",
      "Epoch 1518, Loss: 0.030772714075283147, Final Batch Loss: 0.00018337486835662276\n",
      "Epoch 1519, Loss: 0.007150480756536126, Final Batch Loss: 0.0013033775612711906\n",
      "Epoch 1520, Loss: 0.020739660831168294, Final Batch Loss: 0.0001681242138147354\n",
      "Epoch 1521, Loss: 0.007436818930727895, Final Batch Loss: 6.613300502067432e-05\n",
      "Epoch 1522, Loss: 0.018810700625181198, Final Batch Loss: 0.0004951565060764551\n",
      "Epoch 1523, Loss: 0.008916375111766683, Final Batch Loss: 1.2001372851955239e-05\n",
      "Epoch 1524, Loss: 0.003955871084144746, Final Batch Loss: 1.4354575796460267e-05\n",
      "Epoch 1525, Loss: 0.00755315300921211, Final Batch Loss: 9.211371798301116e-05\n",
      "Epoch 1526, Loss: 0.008407109253312228, Final Batch Loss: 3.5374145227251574e-05\n",
      "Epoch 1527, Loss: 0.002893568656872958, Final Batch Loss: 0.0003624169039539993\n",
      "Epoch 1528, Loss: 0.04272943522664718, Final Batch Loss: 0.008603431284427643\n",
      "Epoch 1529, Loss: 0.015527190291322768, Final Batch Loss: 0.0005397340864874423\n",
      "Epoch 1530, Loss: 0.009136867709457874, Final Batch Loss: 0.0004263963783159852\n",
      "Epoch 1531, Loss: 0.004269862314686179, Final Batch Loss: 0.0025624758563935757\n",
      "Epoch 1532, Loss: 0.003953982202801853, Final Batch Loss: 0.0005936375819146633\n",
      "Epoch 1533, Loss: 0.009562552091665566, Final Batch Loss: 0.0015438878908753395\n",
      "Epoch 1534, Loss: 0.02082186602638103, Final Batch Loss: 0.0002637389989104122\n",
      "Epoch 1535, Loss: 0.008624493566458113, Final Batch Loss: 0.00017342968203593045\n",
      "Epoch 1536, Loss: 0.0042065062443725765, Final Batch Loss: 3.1160947401076555e-05\n",
      "Epoch 1537, Loss: 0.017426943384634797, Final Batch Loss: 6.216692418092862e-05\n",
      "Epoch 1538, Loss: 0.002037613245192915, Final Batch Loss: 0.0003685319679789245\n",
      "Epoch 1539, Loss: 0.0037552253052126616, Final Batch Loss: 0.00028150391881354153\n",
      "Epoch 1540, Loss: 0.00490240438375622, Final Batch Loss: 0.0018869016785174608\n",
      "Epoch 1541, Loss: 0.0020870323933195323, Final Batch Loss: 0.0004881139611825347\n",
      "Epoch 1542, Loss: 0.003678994282381609, Final Batch Loss: 0.000393874041037634\n",
      "Epoch 1543, Loss: 0.004115237796213478, Final Batch Loss: 0.0022419323213398457\n",
      "Epoch 1544, Loss: 0.004576125618768856, Final Batch Loss: 0.00038919769576750696\n",
      "Epoch 1545, Loss: 0.005398126319050789, Final Batch Loss: 0.0017716512084007263\n",
      "Epoch 1546, Loss: 0.003212427138350904, Final Batch Loss: 0.0010912155266851187\n",
      "Epoch 1547, Loss: 0.0057246846408816054, Final Batch Loss: 0.00035698682768270373\n",
      "Epoch 1548, Loss: 0.009489594143815339, Final Batch Loss: 0.0009879698045551777\n",
      "Epoch 1549, Loss: 0.008205642690882087, Final Batch Loss: 0.002127986866980791\n",
      "Epoch 1550, Loss: 0.0022971761354710907, Final Batch Loss: 0.0011314756702631712\n",
      "Epoch 1551, Loss: 0.006323138659354299, Final Batch Loss: 0.0006792722851969302\n",
      "Epoch 1552, Loss: 0.004498230817262083, Final Batch Loss: 0.000980429700575769\n",
      "Epoch 1553, Loss: 0.0023927349830046296, Final Batch Loss: 0.0002122684381902218\n",
      "Epoch 1554, Loss: 0.004107611865038052, Final Batch Loss: 0.00025663533597253263\n",
      "Epoch 1555, Loss: 0.021613203804008663, Final Batch Loss: 0.016638126224279404\n",
      "Epoch 1556, Loss: 0.003969049692386761, Final Batch Loss: 0.0019452428678050637\n",
      "Epoch 1557, Loss: 0.00855186192347901, Final Batch Loss: 8.112201612675563e-05\n",
      "Epoch 1558, Loss: 0.005341007497918326, Final Batch Loss: 0.00011219934822292998\n",
      "Epoch 1559, Loss: 0.005393679530243389, Final Batch Loss: 0.0001762437605066225\n",
      "Epoch 1560, Loss: 0.0030611900438088924, Final Batch Loss: 0.00148726103361696\n",
      "Epoch 1561, Loss: 0.005874447303995112, Final Batch Loss: 1.7755787666828837e-06\n",
      "Epoch 1562, Loss: 0.005122422560816631, Final Batch Loss: 0.00438289949670434\n",
      "Epoch 1563, Loss: 0.002067725119559327, Final Batch Loss: 1.1505853763082996e-05\n",
      "Epoch 1564, Loss: 0.0033209020330104977, Final Batch Loss: 0.00044532064930535853\n",
      "Epoch 1565, Loss: 0.03206442081136629, Final Batch Loss: 0.0009153180290013552\n",
      "Epoch 1566, Loss: 0.03850629422504426, Final Batch Loss: 4.736796654469799e-06\n",
      "Epoch 1567, Loss: 0.012983209337107837, Final Batch Loss: 0.008761011064052582\n",
      "Epoch 1568, Loss: 0.01771034412490735, Final Batch Loss: 3.4820561722881394e-06\n",
      "Epoch 1569, Loss: 0.004196616471745074, Final Batch Loss: 0.0013682212447747588\n",
      "Epoch 1570, Loss: 0.011093274544691667, Final Batch Loss: 0.006436038762331009\n",
      "Epoch 1571, Loss: 0.004085055901668966, Final Batch Loss: 0.00037587236147373915\n",
      "Epoch 1572, Loss: 0.004482785385334864, Final Batch Loss: 0.0002991171495523304\n",
      "Epoch 1573, Loss: 0.0037161503569222987, Final Batch Loss: 0.000639970472548157\n",
      "Epoch 1574, Loss: 0.015859588980674744, Final Batch Loss: 0.013960512354969978\n",
      "Epoch 1575, Loss: 0.00846808182541281, Final Batch Loss: 0.0005168444477021694\n",
      "Epoch 1576, Loss: 0.012131462237448432, Final Batch Loss: 0.00015477802662644535\n",
      "Epoch 1577, Loss: 0.0021313809156708885, Final Batch Loss: 1.5476562111871317e-05\n",
      "Epoch 1578, Loss: 0.006096449302276596, Final Batch Loss: 0.00031839459552429616\n",
      "Epoch 1579, Loss: 0.01922244660090655, Final Batch Loss: 0.0012823875294998288\n",
      "Epoch 1580, Loss: 0.024439283413812518, Final Batch Loss: 0.018162716180086136\n",
      "Epoch 1581, Loss: 0.02685518842190504, Final Batch Loss: 0.001967799849808216\n",
      "Epoch 1582, Loss: 0.011467888485640287, Final Batch Loss: 0.007803897373378277\n",
      "Epoch 1583, Loss: 0.012145573698944645, Final Batch Loss: 4.255255407770164e-05\n",
      "Epoch 1584, Loss: 0.015067695698235184, Final Batch Loss: 0.000515557883772999\n",
      "Epoch 1585, Loss: 0.0240371678955853, Final Batch Loss: 0.011518560349941254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1586, Loss: 0.008826832985505462, Final Batch Loss: 0.0044078403152525425\n",
      "Epoch 1587, Loss: 0.021947208890196634, Final Batch Loss: 4.056105899508111e-05\n",
      "Epoch 1588, Loss: 0.01713719149120152, Final Batch Loss: 0.003761983709409833\n",
      "Epoch 1589, Loss: 0.0031359864078694955, Final Batch Loss: 0.0001617416419321671\n",
      "Epoch 1590, Loss: 0.012353108264505863, Final Batch Loss: 0.00319269229657948\n",
      "Epoch 1591, Loss: 0.008918211213313043, Final Batch Loss: 0.0044747767969965935\n",
      "Epoch 1592, Loss: 0.006769859872292727, Final Batch Loss: 0.0007402705959975719\n",
      "Epoch 1593, Loss: 0.008490095264278352, Final Batch Loss: 0.000685465638525784\n",
      "Epoch 1594, Loss: 0.008875883487235114, Final Batch Loss: 3.2374055081163533e-06\n",
      "Epoch 1595, Loss: 0.004547740507405251, Final Batch Loss: 0.0014161414001137018\n",
      "Epoch 1596, Loss: 0.012063459260389209, Final Batch Loss: 0.0035369873512536287\n",
      "Epoch 1597, Loss: 0.01284263702109456, Final Batch Loss: 0.0015025421744212508\n",
      "Epoch 1598, Loss: 0.03233054816155345, Final Batch Loss: 1.6167065041372553e-05\n",
      "Epoch 1599, Loss: 0.0057378849014639854, Final Batch Loss: 4.373420961201191e-05\n",
      "Epoch 1600, Loss: 0.05242778058163822, Final Batch Loss: 0.023264873772859573\n",
      "Epoch 1601, Loss: 0.011314564688632345, Final Batch Loss: 9.72488464867638e-07\n",
      "Epoch 1602, Loss: 0.012164489431597758, Final Batch Loss: 0.00010630454198690131\n",
      "Epoch 1603, Loss: 0.00877778395806672, Final Batch Loss: 7.184659625636414e-05\n",
      "Epoch 1604, Loss: 0.0061195206581032835, Final Batch Loss: 8.671453542774543e-05\n",
      "Epoch 1605, Loss: 0.005586434481983815, Final Batch Loss: 3.268802856837283e-06\n",
      "Epoch 1606, Loss: 0.008982123428722844, Final Batch Loss: 0.0002612607495393604\n",
      "Epoch 1607, Loss: 0.006683300802251324, Final Batch Loss: 0.00021522757015191019\n",
      "Epoch 1608, Loss: 0.003328932070871815, Final Batch Loss: 0.0006896121194586158\n",
      "Epoch 1609, Loss: 0.024755564576480538, Final Batch Loss: 0.0005512344068847597\n",
      "Epoch 1610, Loss: 0.0026110003527719527, Final Batch Loss: 0.00012773106573149562\n",
      "Epoch 1611, Loss: 0.009038106305524707, Final Batch Loss: 0.0006378835532814264\n",
      "Epoch 1612, Loss: 0.009675773137132637, Final Batch Loss: 5.792178853880614e-05\n",
      "Epoch 1613, Loss: 0.006149465276394039, Final Batch Loss: 0.0005239027668721974\n",
      "Epoch 1614, Loss: 0.009523126063868403, Final Batch Loss: 0.0008765619713813066\n",
      "Epoch 1615, Loss: 0.013632224057801068, Final Batch Loss: 0.004272348713129759\n",
      "Epoch 1616, Loss: 0.006749601219780743, Final Batch Loss: 0.0007110150763764977\n",
      "Epoch 1617, Loss: 0.0035134278587065637, Final Batch Loss: 0.0001840683980844915\n",
      "Epoch 1618, Loss: 0.006584455841220915, Final Batch Loss: 0.0030860132537782192\n",
      "Epoch 1619, Loss: 0.00831167720753001, Final Batch Loss: 8.43412199174054e-05\n",
      "Epoch 1620, Loss: 0.021938786463579163, Final Batch Loss: 0.0004381945764180273\n",
      "Epoch 1621, Loss: 0.004628321970812976, Final Batch Loss: 0.00029169325716793537\n",
      "Epoch 1622, Loss: 0.018223217222839594, Final Batch Loss: 0.0013929554261267185\n",
      "Epoch 1623, Loss: 0.00640029160422273, Final Batch Loss: 5.010495078749955e-05\n",
      "Epoch 1624, Loss: 0.004234409250784665, Final Batch Loss: 0.0007412974373437464\n",
      "Epoch 1625, Loss: 0.010354651545640081, Final Batch Loss: 0.0021236641332507133\n",
      "Epoch 1626, Loss: 0.007150192395783961, Final Batch Loss: 0.002712974324822426\n",
      "Epoch 1627, Loss: 0.0030096213740762323, Final Batch Loss: 0.0016437049489468336\n",
      "Epoch 1628, Loss: 0.006411424721591175, Final Batch Loss: 0.001646475400775671\n",
      "Epoch 1629, Loss: 0.0036434307985473424, Final Batch Loss: 0.0003355324442964047\n",
      "Epoch 1630, Loss: 0.001907471494632773, Final Batch Loss: 7.14204361429438e-05\n",
      "Epoch 1631, Loss: 0.0019943004081142135, Final Batch Loss: 8.715698641026393e-05\n",
      "Epoch 1632, Loss: 0.013573824333434459, Final Batch Loss: 0.0001171883413917385\n",
      "Epoch 1633, Loss: 0.002698269447137136, Final Batch Loss: 7.418875611620024e-05\n",
      "Epoch 1634, Loss: 0.0064798034727573395, Final Batch Loss: 0.001653658109717071\n",
      "Epoch 1635, Loss: 0.004976833187356533, Final Batch Loss: 8.614129001216497e-06\n",
      "Epoch 1636, Loss: 0.003699454180605244, Final Batch Loss: 7.927283149911091e-05\n",
      "Epoch 1637, Loss: 0.005094681633636355, Final Batch Loss: 0.001083017559722066\n",
      "Epoch 1638, Loss: 0.007736556639429182, Final Batch Loss: 0.0010007688542827964\n",
      "Epoch 1639, Loss: 0.0014542446879204363, Final Batch Loss: 0.00031861959723755717\n",
      "Epoch 1640, Loss: 0.009635190372137004, Final Batch Loss: 1.1079604519181885e-05\n",
      "Epoch 1641, Loss: 0.0028662625700235367, Final Batch Loss: 5.062797572463751e-05\n",
      "Epoch 1642, Loss: 0.008155178278684616, Final Batch Loss: 0.0008197464048862457\n",
      "Epoch 1643, Loss: 0.003235090338421287, Final Batch Loss: 2.7292298909742385e-06\n",
      "Epoch 1644, Loss: 0.0027102105668745935, Final Batch Loss: 0.0010523023083806038\n",
      "Epoch 1645, Loss: 0.03841285640373826, Final Batch Loss: 0.006841966416686773\n",
      "Epoch 1646, Loss: 0.006216284615220502, Final Batch Loss: 7.576009375043213e-05\n",
      "Epoch 1647, Loss: 0.0022868766100145876, Final Batch Loss: 0.0007705928292125463\n",
      "Epoch 1648, Loss: 0.010351587261538953, Final Batch Loss: 0.0005603697500191629\n",
      "Epoch 1649, Loss: 0.020612722510122694, Final Batch Loss: 0.00017086487787310034\n",
      "Epoch 1650, Loss: 0.00215346500317537, Final Batch Loss: 1.3614367162517738e-05\n",
      "Epoch 1651, Loss: 0.027442023146249994, Final Batch Loss: 1.0081846085086e-05\n",
      "Epoch 1652, Loss: 0.006457058694650186, Final Batch Loss: 3.142306741210632e-05\n",
      "Epoch 1653, Loss: 0.006662877392955124, Final Batch Loss: 0.0030147936195135117\n",
      "Epoch 1654, Loss: 0.028485299553722143, Final Batch Loss: 0.0017891502939164639\n",
      "Epoch 1655, Loss: 0.0024826603766996413, Final Batch Loss: 0.00034133120789192617\n",
      "Epoch 1656, Loss: 0.008407921297475696, Final Batch Loss: 0.0005814000032842159\n",
      "Epoch 1657, Loss: 0.0048231526757263055, Final Batch Loss: 4.94392725158832e-06\n",
      "Epoch 1658, Loss: 0.004451464003068395, Final Batch Loss: 9.313826740253717e-05\n",
      "Epoch 1659, Loss: 0.0021590561809716746, Final Batch Loss: 0.0001190881448565051\n",
      "Epoch 1660, Loss: 0.0073188128881156445, Final Batch Loss: 0.0005909954197704792\n",
      "Epoch 1661, Loss: 0.024571836746986264, Final Batch Loss: 6.27415943199594e-07\n",
      "Epoch 1662, Loss: 0.0038891132426215336, Final Batch Loss: 8.680792234372348e-05\n",
      "Epoch 1663, Loss: 0.00434330411371775, Final Batch Loss: 0.002304388675838709\n",
      "Epoch 1664, Loss: 0.01723092357860878, Final Batch Loss: 0.008829779922962189\n",
      "Epoch 1665, Loss: 0.0062221711268648505, Final Batch Loss: 0.003137970343232155\n",
      "Epoch 1666, Loss: 0.014064672082895413, Final Batch Loss: 0.0069648511707782745\n",
      "Epoch 1667, Loss: 0.0028818269856856205, Final Batch Loss: 3.851895598927513e-05\n",
      "Epoch 1668, Loss: 0.002409617096418515, Final Batch Loss: 0.00023771202540956438\n",
      "Epoch 1669, Loss: 0.0009523047101538396, Final Batch Loss: 1.107976095227059e-05\n",
      "Epoch 1670, Loss: 0.014858341921353713, Final Batch Loss: 0.00024180454784072936\n",
      "Epoch 1671, Loss: 0.01631883440859383, Final Batch Loss: 7.783879846101627e-05\n",
      "Epoch 1672, Loss: 0.03057655663906189, Final Batch Loss: 2.058334393950645e-05\n",
      "Epoch 1673, Loss: 0.0028849010122939944, Final Batch Loss: 0.0021328458096832037\n",
      "Epoch 1674, Loss: 0.003852023568470031, Final Batch Loss: 0.0006182440556585789\n",
      "Epoch 1675, Loss: 0.002332701074919896, Final Batch Loss: 3.727710645762272e-05\n",
      "Epoch 1676, Loss: 0.01752649731463407, Final Batch Loss: 1.681451635704434e-06\n",
      "Epoch 1677, Loss: 0.0018088081269524992, Final Batch Loss: 0.0006568289245478809\n",
      "Epoch 1678, Loss: 0.020761998093803413, Final Batch Loss: 0.00015527814684901386\n",
      "Epoch 1679, Loss: 0.003056988054595422, Final Batch Loss: 0.00011489498865557835\n",
      "Epoch 1680, Loss: 0.006927038379217265, Final Batch Loss: 3.305061181890778e-05\n",
      "Epoch 1681, Loss: 0.0053278550622053444, Final Batch Loss: 0.0004999486845918\n",
      "Epoch 1682, Loss: 0.020846504485234618, Final Batch Loss: 0.01621127501130104\n",
      "Epoch 1683, Loss: 0.0041166462178807706, Final Batch Loss: 0.0028608038555830717\n",
      "Epoch 1684, Loss: 0.018098605825798586, Final Batch Loss: 0.00038936754572205245\n",
      "Epoch 1685, Loss: 0.018251774890813977, Final Batch Loss: 0.005027880426496267\n",
      "Epoch 1686, Loss: 0.010698600028263172, Final Batch Loss: 5.57518178538885e-05\n",
      "Epoch 1687, Loss: 0.005711674457415938, Final Batch Loss: 0.00019511126447468996\n",
      "Epoch 1688, Loss: 0.003422925299673807, Final Batch Loss: 0.0027727356646209955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1689, Loss: 0.0037945226940792054, Final Batch Loss: 0.00023932676413096488\n",
      "Epoch 1690, Loss: 0.007970781160111073, Final Batch Loss: 0.00011493874626467004\n",
      "Epoch 1691, Loss: 0.007367110149061773, Final Batch Loss: 7.628711318830028e-05\n",
      "Epoch 1692, Loss: 0.004690991632287478, Final Batch Loss: 2.32141383094131e-06\n",
      "Epoch 1693, Loss: 0.018697820472880267, Final Batch Loss: 0.00018630972772371024\n",
      "Epoch 1694, Loss: 0.002202097384724766, Final Batch Loss: 0.00022191012976691127\n",
      "Epoch 1695, Loss: 0.0031364249298349023, Final Batch Loss: 0.0005770972929894924\n",
      "Epoch 1696, Loss: 0.003847294778097421, Final Batch Loss: 0.0018238233169540763\n",
      "Epoch 1697, Loss: 0.0010944551759166643, Final Batch Loss: 0.0001864087680587545\n",
      "Epoch 1698, Loss: 0.004013130277598975, Final Batch Loss: 1.7138383554993197e-05\n",
      "Epoch 1699, Loss: 0.008863947092322633, Final Batch Loss: 0.00042352007585577667\n",
      "Epoch 1700, Loss: 0.0060975360465818085, Final Batch Loss: 4.493245069170371e-05\n",
      "Epoch 1701, Loss: 0.0030257135804276913, Final Batch Loss: 0.001789276720955968\n",
      "Epoch 1702, Loss: 0.020230850764164643, Final Batch Loss: 9.33567116589984e-06\n",
      "Epoch 1703, Loss: 0.0041609390173107386, Final Batch Loss: 0.0004875861923210323\n",
      "Epoch 1704, Loss: 0.014743705047294497, Final Batch Loss: 0.0030754897743463516\n",
      "Epoch 1705, Loss: 0.006655874622992997, Final Batch Loss: 1.2440451428119559e-05\n",
      "Epoch 1706, Loss: 0.002860129243345, Final Batch Loss: 0.00020153175864834338\n",
      "Epoch 1707, Loss: 0.0012075973208993673, Final Batch Loss: 0.0001975123886950314\n",
      "Epoch 1708, Loss: 0.001719769737974275, Final Batch Loss: 0.00010924938396783546\n",
      "Epoch 1709, Loss: 0.007093061853083782, Final Batch Loss: 0.00020092436170671135\n",
      "Epoch 1710, Loss: 0.0020056343637406826, Final Batch Loss: 0.0006661557126790285\n",
      "Epoch 1711, Loss: 0.02731069128276431, Final Batch Loss: 4.522604649537243e-05\n",
      "Epoch 1712, Loss: 0.00306914295470051, Final Batch Loss: 9.762150511960499e-06\n",
      "Epoch 1713, Loss: 0.002650735143788552, Final Batch Loss: 2.566085413491237e-06\n",
      "Epoch 1714, Loss: 0.0028129215497756377, Final Batch Loss: 6.8430628743954e-05\n",
      "Epoch 1715, Loss: 0.025305238727014512, Final Batch Loss: 0.0003632740117609501\n",
      "Epoch 1716, Loss: 0.0016494146912009455, Final Batch Loss: 0.0001008180042845197\n",
      "Epoch 1717, Loss: 0.006885426788358018, Final Batch Loss: 0.0002547970216255635\n",
      "Epoch 1718, Loss: 0.00223197863670066, Final Batch Loss: 0.0002836912462953478\n",
      "Epoch 1719, Loss: 0.003111999365501106, Final Batch Loss: 0.0017028949223458767\n",
      "Epoch 1720, Loss: 0.0027758849319070578, Final Batch Loss: 0.00029867736157029867\n",
      "Epoch 1721, Loss: 0.03169812320265919, Final Batch Loss: 0.0010653905337676406\n",
      "Epoch 1722, Loss: 0.0011441107562859543, Final Batch Loss: 9.849221532931551e-05\n",
      "Epoch 1723, Loss: 0.008301014575408772, Final Batch Loss: 0.007746068295091391\n",
      "Epoch 1724, Loss: 0.001123269580602937, Final Batch Loss: 1.4661197383247782e-05\n",
      "Epoch 1725, Loss: 0.006938971113413572, Final Batch Loss: 0.001653384417295456\n",
      "Epoch 1726, Loss: 0.017594240178368636, Final Batch Loss: 7.258882760652341e-06\n",
      "Epoch 1727, Loss: 0.008099273647530936, Final Batch Loss: 0.00013283615407999605\n",
      "Epoch 1728, Loss: 0.0028612536407308653, Final Batch Loss: 0.0001428755494998768\n",
      "Epoch 1729, Loss: 0.004242803785018623, Final Batch Loss: 0.0019902014173567295\n",
      "Epoch 1730, Loss: 0.029895224784922902, Final Batch Loss: 2.3086789951776154e-05\n",
      "Epoch 1731, Loss: 0.027866652680131665, Final Batch Loss: 1.6751955627114512e-06\n",
      "Epoch 1732, Loss: 0.02507944533135742, Final Batch Loss: 0.0016458822647109628\n",
      "Epoch 1733, Loss: 0.01216844783630222, Final Batch Loss: 0.0008443794213235378\n",
      "Epoch 1734, Loss: 0.001813194394344464, Final Batch Loss: 0.0009152350830845535\n",
      "Epoch 1735, Loss: 0.01693913107737899, Final Batch Loss: 0.0043731615878641605\n",
      "Epoch 1736, Loss: 0.0364925774774747, Final Batch Loss: 0.0001448525144951418\n",
      "Epoch 1737, Loss: 0.004209613020066172, Final Batch Loss: 0.0003844799939543009\n",
      "Epoch 1738, Loss: 0.0008176045266736764, Final Batch Loss: 3.074085179832764e-05\n",
      "Epoch 1739, Loss: 0.004863224454311421, Final Batch Loss: 3.2312276744050905e-05\n",
      "Epoch 1740, Loss: 0.0038056442590459483, Final Batch Loss: 1.9454661014606245e-05\n",
      "Epoch 1741, Loss: 0.012393915938446298, Final Batch Loss: 0.010769829154014587\n",
      "Epoch 1742, Loss: 0.009800092142540962, Final Batch Loss: 1.3689219485968351e-05\n",
      "Epoch 1743, Loss: 0.0037631685845553875, Final Batch Loss: 0.0009343374986201525\n",
      "Epoch 1744, Loss: 0.0025381578016094863, Final Batch Loss: 0.001399358967319131\n",
      "Epoch 1745, Loss: 0.00413960642163147, Final Batch Loss: 1.1493265446915757e-05\n",
      "Epoch 1746, Loss: 0.023569667298943386, Final Batch Loss: 9.435747415409423e-06\n",
      "Epoch 1747, Loss: 0.008234730958065484, Final Batch Loss: 9.389784099766985e-05\n",
      "Epoch 1748, Loss: 0.039953201170646935, Final Batch Loss: 2.408316322544124e-05\n",
      "Epoch 1749, Loss: 0.005980844609439373, Final Batch Loss: 0.0005263438215479255\n",
      "Epoch 1750, Loss: 0.006297620944678783, Final Batch Loss: 0.004400781821459532\n",
      "Epoch 1751, Loss: 0.007389317390334327, Final Batch Loss: 7.813832053216174e-05\n",
      "Epoch 1752, Loss: 0.0055081415666791145, Final Batch Loss: 4.8581368901068345e-05\n",
      "Epoch 1753, Loss: 0.03662868373794481, Final Batch Loss: 0.0007564934203401208\n",
      "Epoch 1754, Loss: 0.0018941114321933128, Final Batch Loss: 9.688860882306471e-05\n",
      "Epoch 1755, Loss: 0.0032893947791308165, Final Batch Loss: 0.0011495412327349186\n",
      "Epoch 1756, Loss: 0.0050723879830911756, Final Batch Loss: 0.0006337183294817805\n",
      "Epoch 1757, Loss: 0.0007585431230836548, Final Batch Loss: 0.00010572950850473717\n",
      "Epoch 1758, Loss: 0.0014951954071875662, Final Batch Loss: 0.00010057978215627372\n",
      "Epoch 1759, Loss: 0.0033383186964783818, Final Batch Loss: 0.0003028541395906359\n",
      "Epoch 1760, Loss: 0.028182198146168957, Final Batch Loss: 2.601355481601786e-05\n",
      "Epoch 1761, Loss: 0.0043543869633140275, Final Batch Loss: 2.3092981791705824e-05\n",
      "Epoch 1762, Loss: 0.0038785957731306553, Final Batch Loss: 0.00048485404113307595\n",
      "Epoch 1763, Loss: 0.0030824706773273647, Final Batch Loss: 0.0006262627430260181\n",
      "Epoch 1764, Loss: 0.0036149045863567153, Final Batch Loss: 2.270435834361706e-05\n",
      "Epoch 1765, Loss: 0.0012581933406181633, Final Batch Loss: 1.6337056877091527e-05\n",
      "Epoch 1766, Loss: 0.001440647631397951, Final Batch Loss: 3.7017073282186175e-06\n",
      "Epoch 1767, Loss: 0.003099032059253659, Final Batch Loss: 6.349462637444958e-05\n",
      "Epoch 1768, Loss: 0.011233431869186461, Final Batch Loss: 0.005424146540462971\n",
      "Epoch 1769, Loss: 0.0014719633909408003, Final Batch Loss: 8.717458695173264e-05\n",
      "Epoch 1770, Loss: 0.019776971195824444, Final Batch Loss: 0.015889907255768776\n",
      "Epoch 1771, Loss: 0.021589582262095064, Final Batch Loss: 0.006600388791412115\n",
      "Epoch 1772, Loss: 0.0036256530111131724, Final Batch Loss: 5.833108662045561e-05\n",
      "Epoch 1773, Loss: 0.006034809101947758, Final Batch Loss: 7.641671800229233e-06\n",
      "Epoch 1774, Loss: 0.001827000194680295, Final Batch Loss: 1.8255921531817876e-05\n",
      "Epoch 1775, Loss: 0.04047164070107101, Final Batch Loss: 1.932430677697994e-06\n",
      "Epoch 1776, Loss: 0.020019402698380873, Final Batch Loss: 0.01765984483063221\n",
      "Epoch 1777, Loss: 0.006056700986619035, Final Batch Loss: 3.180969315508264e-06\n",
      "Epoch 1778, Loss: 0.0018437454709783196, Final Batch Loss: 0.0002788617857731879\n",
      "Epoch 1779, Loss: 0.020990289256587857, Final Batch Loss: 3.211413059034385e-05\n",
      "Epoch 1780, Loss: 0.013515765778720379, Final Batch Loss: 0.0014097528764978051\n",
      "Epoch 1781, Loss: 0.007884910810389556, Final Batch Loss: 1.6981983208097517e-05\n",
      "Epoch 1782, Loss: 0.005764797271694988, Final Batch Loss: 0.0042441897094249725\n",
      "Epoch 1783, Loss: 0.002127344658219954, Final Batch Loss: 2.7229507395531982e-06\n",
      "Epoch 1784, Loss: 0.0021138269598850457, Final Batch Loss: 7.440955869242316e-06\n",
      "Epoch 1785, Loss: 0.001180901424959302, Final Batch Loss: 4.178908420726657e-05\n",
      "Epoch 1786, Loss: 0.005488913448061794, Final Batch Loss: 0.0022543275263160467\n",
      "Epoch 1787, Loss: 0.003358703944854824, Final Batch Loss: 1.1607131682467298e-06\n",
      "Epoch 1788, Loss: 0.017928420231328346, Final Batch Loss: 0.00023226893972605467\n",
      "Epoch 1789, Loss: 0.03225058026418992, Final Batch Loss: 1.4134103366814088e-05\n",
      "Epoch 1790, Loss: 0.0013751188016613014, Final Batch Loss: 6.134302384452894e-05\n",
      "Epoch 1791, Loss: 0.03819963392743375, Final Batch Loss: 1.5972749679349363e-05\n",
      "Epoch 1792, Loss: 0.001795644133380847, Final Batch Loss: 4.177204755251296e-05\n",
      "Epoch 1793, Loss: 0.0005183634712011553, Final Batch Loss: 4.8502486606594175e-05\n",
      "Epoch 1794, Loss: 0.004968022956745699, Final Batch Loss: 0.00037620015791617334\n",
      "Epoch 1795, Loss: 0.022788557660533115, Final Batch Loss: 9.743118425831199e-06\n",
      "Epoch 1796, Loss: 0.022744181573216338, Final Batch Loss: 0.02152148447930813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1797, Loss: 0.008071123113040812, Final Batch Loss: 0.00018178958271164447\n",
      "Epoch 1798, Loss: 0.0022963125302339904, Final Batch Loss: 0.0017809132114052773\n",
      "Epoch 1799, Loss: 0.05206002791237552, Final Batch Loss: 0.00010572497558314353\n",
      "Epoch 1800, Loss: 0.0023777580654495978, Final Batch Loss: 1.1982775504293386e-05\n",
      "Epoch 1801, Loss: 0.0006695284318993799, Final Batch Loss: 6.446669431170449e-05\n",
      "Epoch 1802, Loss: 0.018249330834805733, Final Batch Loss: 5.951829007244669e-05\n",
      "Epoch 1803, Loss: 0.003766345151234418, Final Batch Loss: 0.0021543772891163826\n",
      "Epoch 1804, Loss: 0.05229107360355556, Final Batch Loss: 0.0018332680920138955\n",
      "Epoch 1805, Loss: 0.012577671383041888, Final Batch Loss: 0.002592404605820775\n",
      "Epoch 1806, Loss: 0.006968371746097546, Final Batch Loss: 6.073097665648675e-06\n",
      "Epoch 1807, Loss: 0.002069615642540157, Final Batch Loss: 2.6860390789806843e-05\n",
      "Epoch 1808, Loss: 0.009305099796620198, Final Batch Loss: 4.668052133638412e-05\n",
      "Epoch 1809, Loss: 0.002290850992721971, Final Batch Loss: 9.120164759224281e-05\n",
      "Epoch 1810, Loss: 0.008581324014812708, Final Batch Loss: 0.003114960389211774\n",
      "Epoch 1811, Loss: 0.0014623371680499986, Final Batch Loss: 8.404235995840281e-05\n",
      "Epoch 1812, Loss: 0.010134126583579928, Final Batch Loss: 0.002891033887863159\n",
      "Epoch 1813, Loss: 0.005775945261120796, Final Batch Loss: 0.0003924423363059759\n",
      "Epoch 1814, Loss: 0.002180695068091154, Final Batch Loss: 8.714059367775917e-05\n",
      "Epoch 1815, Loss: 0.0020013583398394985, Final Batch Loss: 2.0031029634992592e-05\n",
      "Epoch 1816, Loss: 0.0008420305430263397, Final Batch Loss: 5.765735295426566e-06\n",
      "Epoch 1817, Loss: 0.000884065026184544, Final Batch Loss: 0.00016605816199444234\n",
      "Epoch 1818, Loss: 0.0028391850064508617, Final Batch Loss: 0.0011498224921524525\n",
      "Epoch 1819, Loss: 0.006905664224177599, Final Batch Loss: 0.0017528722528368235\n",
      "Epoch 1820, Loss: 0.0009931352633429924, Final Batch Loss: 4.479627023101784e-06\n",
      "Epoch 1821, Loss: 0.011092327011283487, Final Batch Loss: 0.0009479884174652398\n",
      "Epoch 1822, Loss: 0.003155835423967801, Final Batch Loss: 0.00013526943803299218\n",
      "Epoch 1823, Loss: 0.00521912619296927, Final Batch Loss: 0.00013333170500118285\n",
      "Epoch 1824, Loss: 0.004653454932849854, Final Batch Loss: 0.0025216813664883375\n",
      "Epoch 1825, Loss: 0.0014711073890794069, Final Batch Loss: 0.000308334274450317\n",
      "Epoch 1826, Loss: 0.0027091712208857643, Final Batch Loss: 1.4724379980179947e-05\n",
      "Epoch 1827, Loss: 0.0012089791744074319, Final Batch Loss: 1.752860043779947e-05\n",
      "Epoch 1828, Loss: 0.0009407901670783758, Final Batch Loss: 0.00018029272905550897\n",
      "Epoch 1829, Loss: 0.0031338037333625834, Final Batch Loss: 3.872999150189571e-05\n",
      "Epoch 1830, Loss: 0.00046498426229391043, Final Batch Loss: 1.110517700908531e-06\n",
      "Epoch 1831, Loss: 0.0006398956902557984, Final Batch Loss: 0.0001136915961978957\n",
      "Epoch 1832, Loss: 0.00810747676587198, Final Batch Loss: 0.00022699720284435898\n",
      "Epoch 1833, Loss: 0.0020545098050206434, Final Batch Loss: 1.4316563465399668e-05\n",
      "Epoch 1834, Loss: 0.008781926013398333, Final Batch Loss: 1.6460870028822683e-05\n",
      "Epoch 1835, Loss: 0.01896177926028031, Final Batch Loss: 4.978639117325656e-05\n",
      "Epoch 1836, Loss: 0.002008379011613215, Final Batch Loss: 2.290046040798188e-06\n",
      "Epoch 1837, Loss: 0.001130947370256763, Final Batch Loss: 8.585911564296111e-05\n",
      "Epoch 1838, Loss: 0.0080992457587854, Final Batch Loss: 3.571884008124471e-05\n",
      "Epoch 1839, Loss: 0.0010236512025585398, Final Batch Loss: 3.9438848034478724e-05\n",
      "Epoch 1840, Loss: 0.009117345849517733, Final Batch Loss: 0.0007954495376907289\n",
      "Epoch 1841, Loss: 0.032910245354287326, Final Batch Loss: 0.0005098022520542145\n",
      "Epoch 1842, Loss: 0.030753064434975386, Final Batch Loss: 0.006542951334267855\n",
      "Epoch 1843, Loss: 0.00852831534575671, Final Batch Loss: 0.005885980557650328\n",
      "Epoch 1844, Loss: 0.017924104302531774, Final Batch Loss: 2.509669094763467e-08\n",
      "Epoch 1845, Loss: 0.0010241221384603705, Final Batch Loss: 3.651460701803444e-06\n",
      "Epoch 1846, Loss: 0.0013850861942046322, Final Batch Loss: 7.198265666374937e-05\n",
      "Epoch 1847, Loss: 0.005634786928567337, Final Batch Loss: 5.4960437410045415e-06\n",
      "Epoch 1848, Loss: 0.0007314694900060204, Final Batch Loss: 1.0352320032325224e-06\n",
      "Epoch 1849, Loss: 0.00368470219837036, Final Batch Loss: 0.0001436090242350474\n",
      "Epoch 1850, Loss: 0.003135119738544745, Final Batch Loss: 5.954002517682966e-06\n",
      "Epoch 1851, Loss: 0.005082392672193237, Final Batch Loss: 0.00019906154193449765\n",
      "Epoch 1852, Loss: 0.0018546973756201623, Final Batch Loss: 6.62515458316193e-06\n",
      "Epoch 1853, Loss: 0.004851480829529464, Final Batch Loss: 0.0007167888106778264\n",
      "Epoch 1854, Loss: 0.004362560488516465, Final Batch Loss: 0.0002493969222996384\n",
      "Epoch 1855, Loss: 0.054057391302194446, Final Batch Loss: 0.01889709010720253\n",
      "Epoch 1856, Loss: 0.00925490097142756, Final Batch Loss: 0.0020930764731019735\n",
      "Epoch 1857, Loss: 0.004623061413440155, Final Batch Loss: 3.598905823309906e-05\n",
      "Epoch 1858, Loss: 0.004016265674181341, Final Batch Loss: 1.4504935279546771e-05\n",
      "Epoch 1859, Loss: 0.006644404599057907, Final Batch Loss: 6.901576057316561e-07\n",
      "Epoch 1860, Loss: 0.001355786545900628, Final Batch Loss: 0.00021552093676291406\n",
      "Epoch 1861, Loss: 0.0013292809599079192, Final Batch Loss: 0.0005282243364490569\n",
      "Epoch 1862, Loss: 0.007578871911391616, Final Batch Loss: 0.000400755787268281\n",
      "Epoch 1863, Loss: 0.002475275305187097, Final Batch Loss: 1.9008872186532244e-05\n",
      "Epoch 1864, Loss: 0.013307038403581828, Final Batch Loss: 0.012355917133390903\n",
      "Epoch 1865, Loss: 0.026263269492119434, Final Batch Loss: 2.7871587008121423e-05\n",
      "Epoch 1866, Loss: 0.002057133475318551, Final Batch Loss: 0.0009373632492497563\n",
      "Epoch 1867, Loss: 0.02540156350005418, Final Batch Loss: 0.0011140865972265601\n",
      "Epoch 1868, Loss: 0.0014464449050137773, Final Batch Loss: 0.000233340440900065\n",
      "Epoch 1869, Loss: 0.0049198712586076, Final Batch Loss: 2.3147389583755285e-05\n",
      "Epoch 1870, Loss: 0.015579346101731062, Final Batch Loss: 0.011150917038321495\n",
      "Epoch 1871, Loss: 0.032568473135142995, Final Batch Loss: 7.146153620851692e-06\n",
      "Epoch 1872, Loss: 0.006273902778048068, Final Batch Loss: 3.915088018402457e-05\n",
      "Epoch 1873, Loss: 0.017840488735600957, Final Batch Loss: 2.723624675127212e-05\n",
      "Epoch 1874, Loss: 0.006543927127495408, Final Batch Loss: 0.0015732801984995604\n",
      "Epoch 1875, Loss: 0.0009633170702727512, Final Batch Loss: 5.594866524916142e-05\n",
      "Epoch 1876, Loss: 0.012402309395838529, Final Batch Loss: 0.011230161413550377\n",
      "Epoch 1877, Loss: 0.001761522114975378, Final Batch Loss: 0.000366918568033725\n",
      "Epoch 1878, Loss: 0.001747912378050387, Final Batch Loss: 0.00042704283259809017\n",
      "Epoch 1879, Loss: 0.0073565653156038024, Final Batch Loss: 8.695745236764196e-06\n",
      "Epoch 1880, Loss: 0.0013302867737365887, Final Batch Loss: 0.000679713673889637\n",
      "Epoch 1881, Loss: 0.030564830346634153, Final Batch Loss: 1.8069396219289047e-06\n",
      "Epoch 1882, Loss: 0.0007436518208123744, Final Batch Loss: 0.00038710064836777747\n",
      "Epoch 1883, Loss: 0.0029862083902116865, Final Batch Loss: 0.002268856158480048\n",
      "Epoch 1884, Loss: 0.000696846855134936, Final Batch Loss: 3.822535290964879e-05\n",
      "Epoch 1885, Loss: 0.017114865187892292, Final Batch Loss: 4.454649626950413e-07\n",
      "Epoch 1886, Loss: 0.00156507999781752, Final Batch Loss: 9.73718852037564e-06\n",
      "Epoch 1887, Loss: 0.009971958868845832, Final Batch Loss: 0.00011658068251563236\n",
      "Epoch 1888, Loss: 0.020520903344731778, Final Batch Loss: 0.019447609782218933\n",
      "Epoch 1889, Loss: 0.001461107298382558, Final Batch Loss: 0.00034107116516679525\n",
      "Epoch 1890, Loss: 0.0021945460553070006, Final Batch Loss: 1.5057826203701552e-06\n",
      "Epoch 1891, Loss: 0.006678026227746159, Final Batch Loss: 0.0012077384162694216\n",
      "Epoch 1892, Loss: 0.0009654650684751687, Final Batch Loss: 5.144746864971239e-06\n",
      "Epoch 1893, Loss: 0.0049738671514205635, Final Batch Loss: 0.00031688116723671556\n",
      "Epoch 1894, Loss: 0.043082567950477824, Final Batch Loss: 0.04227573797106743\n",
      "Epoch 1895, Loss: 0.0010877890890697017, Final Batch Loss: 8.550910570193082e-05\n",
      "Epoch 1896, Loss: 0.003507023684505839, Final Batch Loss: 4.749291838379577e-05\n",
      "Epoch 1897, Loss: 0.04433612660795916, Final Batch Loss: 1.569041342008859e-05\n",
      "Epoch 1898, Loss: 0.0011073646282966365, Final Batch Loss: 9.573964234732557e-06\n",
      "Epoch 1899, Loss: 0.013524745823815465, Final Batch Loss: 0.012284290976822376\n",
      "Epoch 1900, Loss: 0.0015858572223805822, Final Batch Loss: 1.1380914656911045e-05\n",
      "Epoch 1901, Loss: 0.013317819892108673, Final Batch Loss: 4.874967999057844e-06\n",
      "Epoch 1902, Loss: 0.0013926600659033284, Final Batch Loss: 0.00016631300968583673\n",
      "Epoch 1903, Loss: 0.024579580669524148, Final Batch Loss: 0.0001922322262544185\n",
      "Epoch 1904, Loss: 0.010645616333931684, Final Batch Loss: 0.002279524225741625\n",
      "Epoch 1905, Loss: 0.003941026026950567, Final Batch Loss: 2.614313234516885e-05\n",
      "Epoch 1906, Loss: 0.004911356500088004, Final Batch Loss: 1.3595108612207696e-05\n",
      "Epoch 1907, Loss: 0.0038155908696353436, Final Batch Loss: 0.0006395101081579924\n",
      "Epoch 1908, Loss: 0.00527719380625058, Final Batch Loss: 0.0001707518968032673\n",
      "Epoch 1909, Loss: 0.002673430572031066, Final Batch Loss: 0.0014108652248978615\n",
      "Epoch 1910, Loss: 0.0024668934217970673, Final Batch Loss: 3.739334488273016e-06\n",
      "Epoch 1911, Loss: 0.00574286311166361, Final Batch Loss: 0.0003438401618041098\n",
      "Epoch 1912, Loss: 0.004489821891183965, Final Batch Loss: 0.0002258340100524947\n",
      "Epoch 1913, Loss: 0.03501010560285067, Final Batch Loss: 8.888719457900152e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1914, Loss: 0.007449765122146346, Final Batch Loss: 0.00019148756109643728\n",
      "Epoch 1915, Loss: 0.00269220796872105, Final Batch Loss: 2.3373968360829167e-05\n",
      "Epoch 1916, Loss: 0.0013722646981477737, Final Batch Loss: 1.617870293557644e-05\n",
      "Epoch 1917, Loss: 0.0022837957587853452, Final Batch Loss: 2.4343246423086384e-06\n",
      "Epoch 1918, Loss: 0.026094751425262075, Final Batch Loss: 5.164334288565442e-05\n",
      "Epoch 1919, Loss: 0.000603896398388315, Final Batch Loss: 0.00010181829566136003\n",
      "Epoch 1920, Loss: 0.0033236165854759747, Final Batch Loss: 4.567476935335435e-06\n",
      "Epoch 1921, Loss: 0.001769490132573992, Final Batch Loss: 0.0006906897760927677\n",
      "Epoch 1922, Loss: 0.03095689319889061, Final Batch Loss: 0.0004958240897394717\n",
      "Epoch 1923, Loss: 0.0012114906921851798, Final Batch Loss: 8.400535989494529e-06\n",
      "Epoch 1924, Loss: 0.0025778392591746524, Final Batch Loss: 9.623583173379302e-05\n",
      "Epoch 1925, Loss: 0.0005698002059943974, Final Batch Loss: 6.581180787179619e-05\n",
      "Epoch 1926, Loss: 0.0017999646806856617, Final Batch Loss: 0.0009749759337864816\n",
      "Epoch 1927, Loss: 0.0012282544921617955, Final Batch Loss: 0.00017378944903612137\n",
      "Epoch 1928, Loss: 0.0019248342869104818, Final Batch Loss: 2.63522524619475e-05\n",
      "Epoch 1929, Loss: 0.0019281978020444512, Final Batch Loss: 0.0004000936169177294\n",
      "Epoch 1930, Loss: 0.0018000800191657618, Final Batch Loss: 0.0007048907573334873\n",
      "Epoch 1931, Loss: 0.001375804713461548, Final Batch Loss: 0.0007703504525125027\n",
      "Epoch 1932, Loss: 0.011136079443531344, Final Batch Loss: 3.5426044632913545e-05\n",
      "Epoch 1933, Loss: 0.001461109844967723, Final Batch Loss: 0.0\n",
      "Epoch 1934, Loss: 0.0017001364603856928, Final Batch Loss: 1.2716393939626869e-05\n",
      "Epoch 1935, Loss: 0.002449577586958185, Final Batch Loss: 0.00046112178824841976\n",
      "Epoch 1936, Loss: 0.001695059210760519, Final Batch Loss: 0.0\n",
      "Epoch 1937, Loss: 0.0012832897359893458, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 1938, Loss: 0.01141881964338154, Final Batch Loss: 8.407345148953027e-07\n",
      "Epoch 1939, Loss: 0.006849180190329207, Final Batch Loss: 2.2986187104834244e-05\n",
      "Epoch 1940, Loss: 0.0025032087360159494, Final Batch Loss: 8.783397788647562e-06\n",
      "Epoch 1941, Loss: 0.0020487884648900945, Final Batch Loss: 5.2580075134756044e-05\n",
      "Epoch 1942, Loss: 0.0034209358709631488, Final Batch Loss: 0.00015964747581165284\n",
      "Epoch 1943, Loss: 0.0035932745113314013, Final Batch Loss: 1.116114708565874e-05\n",
      "Epoch 1944, Loss: 0.0008097468708001543, Final Batch Loss: 1.179538230644539e-06\n",
      "Epoch 1945, Loss: 0.0008041105938900728, Final Batch Loss: 1.172554402728565e-05\n",
      "Epoch 1946, Loss: 0.005709005519747734, Final Batch Loss: 0.0021519246511161327\n",
      "Epoch 1947, Loss: 0.001089436060283333, Final Batch Loss: 0.000584266206715256\n",
      "Epoch 1948, Loss: 0.00044656014597421745, Final Batch Loss: 1.1675359019136522e-05\n",
      "Epoch 1949, Loss: 0.001255809111171402, Final Batch Loss: 0.00014508386084344238\n",
      "Epoch 1950, Loss: 0.00859763600237784, Final Batch Loss: 1.2278022040845826e-05\n",
      "Epoch 1951, Loss: 0.0020416058687260374, Final Batch Loss: 9.036668052431196e-05\n",
      "Epoch 1952, Loss: 0.0008745498562348075, Final Batch Loss: 0.0001009526095003821\n",
      "Epoch 1953, Loss: 0.0035355683066882193, Final Batch Loss: 0.001092575374059379\n",
      "Epoch 1954, Loss: 0.002397861378995003, Final Batch Loss: 3.4475397114874795e-05\n",
      "Epoch 1955, Loss: 0.0006306811992544681, Final Batch Loss: 0.00012843860895372927\n",
      "Epoch 1956, Loss: 0.003862768120598048, Final Batch Loss: 0.0028420656453818083\n",
      "Epoch 1957, Loss: 0.015137638485612115, Final Batch Loss: 2.1663548977812752e-05\n",
      "Epoch 1958, Loss: 0.00421641104912851, Final Batch Loss: 0.00017059141828212887\n",
      "Epoch 1959, Loss: 0.0018790288013406098, Final Batch Loss: 0.000396361923776567\n",
      "Epoch 1960, Loss: 0.030384980995393107, Final Batch Loss: 5.897692858525261e-07\n",
      "Epoch 1961, Loss: 0.001740942541800905, Final Batch Loss: 0.00045322682126425207\n",
      "Epoch 1962, Loss: 0.0041420567577006295, Final Batch Loss: 0.0001431349228369072\n",
      "Epoch 1963, Loss: 0.0006459661326516652, Final Batch Loss: 1.90077207662398e-05\n",
      "Epoch 1964, Loss: 0.0010242195476166671, Final Batch Loss: 5.539875928661786e-06\n",
      "Epoch 1965, Loss: 0.003161015803925693, Final Batch Loss: 0.00045062287244945765\n",
      "Epoch 1966, Loss: 0.053872410317126196, Final Batch Loss: 6.7303997639101e-05\n",
      "Epoch 1967, Loss: 0.0022186769783729687, Final Batch Loss: 0.00015918456483632326\n",
      "Epoch 1968, Loss: 0.0060055717040086165, Final Batch Loss: 9.834485535975546e-05\n",
      "Epoch 1969, Loss: 0.003938614059734391, Final Batch Loss: 6.0262293118285015e-05\n",
      "Epoch 1970, Loss: 0.006834956246166257, Final Batch Loss: 3.634763925219886e-05\n",
      "Epoch 1971, Loss: 0.0015521870227530599, Final Batch Loss: 0.0005267436499707401\n",
      "Epoch 1972, Loss: 0.00319223158294335, Final Batch Loss: 8.869369048625231e-05\n",
      "Epoch 1973, Loss: 0.002563848494901322, Final Batch Loss: 7.873323920648545e-05\n",
      "Epoch 1974, Loss: 0.001143184406828368, Final Batch Loss: 4.834848004975356e-05\n",
      "Epoch 1975, Loss: 0.006261022048420273, Final Batch Loss: 0.005411052610725164\n",
      "Epoch 1976, Loss: 0.002820254119455967, Final Batch Loss: 1.6061727592386887e-06\n",
      "Epoch 1977, Loss: 0.015510032608517577, Final Batch Loss: 1.832042698879377e-06\n",
      "Epoch 1978, Loss: 0.02192515983915655, Final Batch Loss: 3.681948146549985e-05\n",
      "Epoch 1979, Loss: 0.001933435967657715, Final Batch Loss: 0.0006286948337219656\n",
      "Epoch 1980, Loss: 0.007544721971498802, Final Batch Loss: 0.004083321429789066\n",
      "Epoch 1981, Loss: 0.003138947844490758, Final Batch Loss: 7.986867785803042e-06\n",
      "Epoch 1982, Loss: 0.00219339516479522, Final Batch Loss: 0.00019600841915234923\n",
      "Epoch 1983, Loss: 0.001870643551228568, Final Batch Loss: 0.0008406474371440709\n",
      "Epoch 1984, Loss: 0.0009460490887249762, Final Batch Loss: 3.3879528018587735e-06\n",
      "Epoch 1985, Loss: 0.0007822428069630405, Final Batch Loss: 7.610104148625396e-06\n",
      "Epoch 1986, Loss: 0.0013113656095811166, Final Batch Loss: 0.00010006632510339841\n",
      "Epoch 1987, Loss: 0.02567774757517327, Final Batch Loss: 8.469929525745101e-06\n",
      "Epoch 1988, Loss: 0.0023142412167089788, Final Batch Loss: 3.5009209113923134e-06\n",
      "Epoch 1989, Loss: 0.0028221465181559324, Final Batch Loss: 0.00015571305993944407\n",
      "Epoch 1990, Loss: 0.0019824925871034793, Final Batch Loss: 6.625155492656631e-06\n",
      "Epoch 1991, Loss: 0.001176978781586513, Final Batch Loss: 9.900785516947508e-05\n",
      "Epoch 1992, Loss: 0.0023113359020499047, Final Batch Loss: 3.271051900810562e-05\n",
      "Epoch 1993, Loss: 0.0018432928363836254, Final Batch Loss: 1.0640348591550719e-05\n",
      "Epoch 1994, Loss: 0.015208937291390612, Final Batch Loss: 2.443507946736645e-05\n",
      "Epoch 1995, Loss: 0.0014849553699605167, Final Batch Loss: 0.0002798593486659229\n",
      "Epoch 1996, Loss: 0.01176174082502257, Final Batch Loss: 3.322011616546661e-05\n",
      "Epoch 1997, Loss: 0.025952301140932832, Final Batch Loss: 8.784190140431747e-05\n",
      "Epoch 1998, Loss: 0.0017092270900320727, Final Batch Loss: 1.3933855370851234e-05\n",
      "Epoch 1999, Loss: 0.002390652953181416, Final Batch Loss: 0.00032894540345296264\n",
      "Epoch 2000, Loss: 0.0036656075608334504, Final Batch Loss: 3.067874786211178e-05\n",
      "Epoch 2001, Loss: 0.0007169045129558071, Final Batch Loss: 0.00015103201440069824\n",
      "Epoch 2002, Loss: 0.006110589681583178, Final Batch Loss: 1.3803170872961346e-07\n",
      "Epoch 2003, Loss: 0.021985270199365914, Final Batch Loss: 0.0038196758832782507\n",
      "Epoch 2004, Loss: 0.001502994368365762, Final Batch Loss: 4.347828962636413e-06\n",
      "Epoch 2005, Loss: 0.00295906605606433, Final Batch Loss: 0.00036482917494140565\n",
      "Epoch 2006, Loss: 0.006140292389318347, Final Batch Loss: 0.003435052465647459\n",
      "Epoch 2007, Loss: 0.001648776902584359, Final Batch Loss: 0.001172753982245922\n",
      "Epoch 2008, Loss: 0.0004942351006320678, Final Batch Loss: 3.5009805287700146e-05\n",
      "Epoch 2009, Loss: 0.007679370493860915, Final Batch Loss: 0.007230277173221111\n",
      "Epoch 2010, Loss: 0.000847501778480364, Final Batch Loss: 5.839104051119648e-05\n",
      "Epoch 2011, Loss: 0.014421788549043413, Final Batch Loss: 1.4812126210017595e-05\n",
      "Epoch 2012, Loss: 0.0037474797854883946, Final Batch Loss: 6.9765656007803045e-06\n",
      "Epoch 2013, Loss: 0.000881623300301726, Final Batch Loss: 1.1781723515014164e-05\n",
      "Epoch 2014, Loss: 0.0008979173944680952, Final Batch Loss: 0.0004908166010864079\n",
      "Epoch 2015, Loss: 0.0009351361406970682, Final Batch Loss: 2.509641717551858e-06\n",
      "Epoch 2016, Loss: 0.002502629122318467, Final Batch Loss: 4.9819758714875206e-05\n",
      "Epoch 2017, Loss: 0.0012859251874033362, Final Batch Loss: 0.00017078837845474482\n",
      "Epoch 2018, Loss: 0.00024355738878512057, Final Batch Loss: 1.3249639778223354e-05\n",
      "Epoch 2019, Loss: 0.0010888752462960838, Final Batch Loss: 4.849820925301174e-06\n",
      "Epoch 2020, Loss: 0.00044408040412236005, Final Batch Loss: 1.0972609743475914e-05\n",
      "Epoch 2021, Loss: 0.3705584323251969, Final Batch Loss: 0.3692474961280823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2022, Loss: 0.0018443073058733717, Final Batch Loss: 7.246220775414258e-05\n",
      "Epoch 2023, Loss: 0.0013626226864289492, Final Batch Loss: 0.00018098016153089702\n",
      "Epoch 2024, Loss: 0.01650021182558703, Final Batch Loss: 2.2461272237706e-06\n",
      "Epoch 2025, Loss: 0.008228098180552479, Final Batch Loss: 9.410050552105531e-05\n",
      "Epoch 2026, Loss: 0.006955797201953828, Final Batch Loss: 0.0006081924657337368\n",
      "Epoch 2027, Loss: 0.013861473458746332, Final Batch Loss: 1.895725836220663e-05\n",
      "Epoch 2028, Loss: 0.007854685885831714, Final Batch Loss: 0.0027450101915746927\n",
      "Epoch 2029, Loss: 0.001347088421425724, Final Batch Loss: 1.1920164070033934e-05\n",
      "Epoch 2030, Loss: 0.002689626213395968, Final Batch Loss: 8.300787885673344e-05\n",
      "Epoch 2031, Loss: 0.004906182701233774, Final Batch Loss: 0.0027615234721451998\n",
      "Epoch 2032, Loss: 0.0025372185627929866, Final Batch Loss: 0.00045657408190891147\n",
      "Epoch 2033, Loss: 0.006386841210769489, Final Batch Loss: 0.0002492806233931333\n",
      "Epoch 2034, Loss: 0.0016172635384918976, Final Batch Loss: 2.6978393634635722e-06\n",
      "Epoch 2035, Loss: 0.004859661326918285, Final Batch Loss: 7.526063564000651e-05\n",
      "Epoch 2036, Loss: 0.023019039326754864, Final Batch Loss: 8.886559953680262e-05\n",
      "Epoch 2037, Loss: 0.0013619159581139684, Final Batch Loss: 0.00020483451953623444\n",
      "Epoch 2038, Loss: 0.08473581867292523, Final Batch Loss: 0.07333984225988388\n",
      "Epoch 2039, Loss: 0.007577742449939251, Final Batch Loss: 0.0012085409834980965\n",
      "Epoch 2040, Loss: 0.03649619479983812, Final Batch Loss: 2.1455598471220583e-05\n",
      "Epoch 2041, Loss: 0.006701006037019397, Final Batch Loss: 4.9250734264205676e-06\n",
      "Epoch 2042, Loss: 0.00471652700798586, Final Batch Loss: 0.001301758922636509\n",
      "Epoch 2043, Loss: 0.011400507210055366, Final Batch Loss: 0.00028827061760239303\n",
      "Epoch 2044, Loss: 0.003877635481330799, Final Batch Loss: 3.370289414306171e-05\n",
      "Epoch 2045, Loss: 0.01007325335558562, Final Batch Loss: 2.7543228497961536e-06\n",
      "Epoch 2046, Loss: 0.006493337859865278, Final Batch Loss: 0.0031060187611728907\n",
      "Epoch 2047, Loss: 0.003431390199693851, Final Batch Loss: 6.127780943643302e-05\n",
      "Epoch 2048, Loss: 0.010050345823401585, Final Batch Loss: 0.0001815972209442407\n",
      "Epoch 2049, Loss: 0.02896267347387038, Final Batch Loss: 0.02592688612639904\n",
      "Epoch 2050, Loss: 0.004666913999244571, Final Batch Loss: 0.0008010613964870572\n",
      "Epoch 2051, Loss: 0.21903861197642982, Final Batch Loss: 0.1985863596200943\n",
      "Epoch 2052, Loss: 0.016941681562457234, Final Batch Loss: 0.0007131478632800281\n",
      "Epoch 2053, Loss: 0.12316268240101635, Final Batch Loss: 0.10314856469631195\n",
      "Epoch 2054, Loss: 0.008091700379736722, Final Batch Loss: 0.0022459784522652626\n",
      "Epoch 2055, Loss: 0.023806203447747976, Final Batch Loss: 0.0006507442449219525\n",
      "Epoch 2056, Loss: 0.06897734370431863, Final Batch Loss: 0.000452761392807588\n",
      "Epoch 2057, Loss: 0.051569553470471874, Final Batch Loss: 0.0003849346248898655\n",
      "Epoch 2058, Loss: 0.016531166969798505, Final Batch Loss: 0.0011182654416188598\n",
      "Epoch 2059, Loss: 0.01620182767510414, Final Batch Loss: 0.01216032449156046\n",
      "Epoch 2060, Loss: 0.010081544518470764, Final Batch Loss: 0.005695932544767857\n",
      "Epoch 2061, Loss: 0.015259777661412954, Final Batch Loss: 0.008156530559062958\n",
      "Epoch 2062, Loss: 0.030611534137278795, Final Batch Loss: 0.010760310105979443\n",
      "Epoch 2063, Loss: 0.03022956769564189, Final Batch Loss: 0.000261308770859614\n",
      "Epoch 2064, Loss: 0.010825584206031635, Final Batch Loss: 0.0002916521916631609\n",
      "Epoch 2065, Loss: 0.004297174484236166, Final Batch Loss: 0.000299432867905125\n",
      "Epoch 2066, Loss: 0.00792375480523333, Final Batch Loss: 0.00042407767614349723\n",
      "Epoch 2067, Loss: 0.043205585330724716, Final Batch Loss: 0.002272642683237791\n",
      "Epoch 2068, Loss: 0.011729511665180326, Final Batch Loss: 0.0007332046516239643\n",
      "Epoch 2069, Loss: 0.012584567535668612, Final Batch Loss: 0.0021533442195504904\n",
      "Epoch 2070, Loss: 0.024291105568408966, Final Batch Loss: 0.0055222949013113976\n",
      "Epoch 2071, Loss: 0.006150150904431939, Final Batch Loss: 0.0012960588792338967\n",
      "Epoch 2072, Loss: 0.005091009947136627, Final Batch Loss: 1.9566907212720253e-05\n",
      "Epoch 2073, Loss: 0.008731001114938408, Final Batch Loss: 0.0009212194127030671\n",
      "Epoch 2074, Loss: 0.004380415251944214, Final Batch Loss: 0.000855206570122391\n",
      "Epoch 2075, Loss: 0.014359287859406322, Final Batch Loss: 1.1355557944625616e-05\n",
      "Epoch 2076, Loss: 0.009450320423638914, Final Batch Loss: 0.00012015135871479288\n",
      "Epoch 2077, Loss: 0.03661298482620623, Final Batch Loss: 0.00015983740740921348\n",
      "Epoch 2078, Loss: 0.003045116551220417, Final Batch Loss: 0.00015316123608499765\n",
      "Epoch 2079, Loss: 0.00650771516666282, Final Batch Loss: 0.00019199094094801694\n",
      "Epoch 2080, Loss: 0.003000943372171605, Final Batch Loss: 5.638224320136942e-05\n",
      "Epoch 2081, Loss: 0.003840806339212577, Final Batch Loss: 2.8614331313292496e-05\n",
      "Epoch 2082, Loss: 0.004891617689281702, Final Batch Loss: 0.0018404630245640874\n",
      "Epoch 2083, Loss: 0.00296216866991017, Final Batch Loss: 7.785363413859159e-05\n",
      "Epoch 2084, Loss: 0.0034547441791801248, Final Batch Loss: 4.987876309314743e-06\n",
      "Epoch 2085, Loss: 0.0028005963540636003, Final Batch Loss: 0.0003187998663634062\n",
      "Epoch 2086, Loss: 0.005321353921317495, Final Batch Loss: 0.00017709618259686977\n",
      "Epoch 2087, Loss: 0.017932827466665913, Final Batch Loss: 4.548694505501771e-06\n",
      "Epoch 2088, Loss: 0.005519020342035219, Final Batch Loss: 0.00390957947820425\n",
      "Epoch 2089, Loss: 0.011188826555553533, Final Batch Loss: 1.1568920854188036e-05\n",
      "Epoch 2090, Loss: 0.001975620922166854, Final Batch Loss: 0.0008004687842912972\n",
      "Epoch 2091, Loss: 0.009777372863027267, Final Batch Loss: 0.00013702762953471392\n",
      "Epoch 2092, Loss: 0.01006507989950478, Final Batch Loss: 0.00030282128136605024\n",
      "Epoch 2093, Loss: 0.01775695465039462, Final Batch Loss: 0.005153522361069918\n",
      "Epoch 2094, Loss: 0.024629109913803404, Final Batch Loss: 1.991205135709606e-05\n",
      "Epoch 2095, Loss: 0.003786727957049152, Final Batch Loss: 5.373457315727137e-05\n",
      "Epoch 2096, Loss: 0.0016430802752438467, Final Batch Loss: 3.9823713450459763e-05\n",
      "Epoch 2097, Loss: 0.0019489251681079622, Final Batch Loss: 2.0037372451042756e-05\n",
      "Epoch 2098, Loss: 0.04046704270876944, Final Batch Loss: 0.004049526061862707\n",
      "Epoch 2099, Loss: 0.0019026095687877387, Final Batch Loss: 0.0001185674627777189\n",
      "Epoch 2100, Loss: 0.0019268273463239893, Final Batch Loss: 0.00021677381300833076\n",
      "Epoch 2101, Loss: 0.0044018751359544694, Final Batch Loss: 0.00257287104614079\n",
      "Epoch 2102, Loss: 0.005703816690584063, Final Batch Loss: 1.0000110705732368e-05\n",
      "Epoch 2103, Loss: 0.03646223997202469, Final Batch Loss: 0.00012055510160280392\n",
      "Epoch 2104, Loss: 0.004389610199723393, Final Batch Loss: 0.0007557416101917624\n",
      "Epoch 2105, Loss: 0.009052567176695447, Final Batch Loss: 3.5047873097937554e-05\n",
      "Epoch 2106, Loss: 0.0028061490738764405, Final Batch Loss: 0.000350220943801105\n",
      "Epoch 2107, Loss: 0.0031581264338456094, Final Batch Loss: 0.001459442893974483\n",
      "Epoch 2108, Loss: 0.003919207738363184, Final Batch Loss: 0.00010746043699327856\n",
      "Epoch 2109, Loss: 0.02192895646840043, Final Batch Loss: 2.426534592814278e-05\n",
      "Epoch 2110, Loss: 0.19084438303252682, Final Batch Loss: 0.1868002563714981\n",
      "Epoch 2111, Loss: 0.00552269842592068, Final Batch Loss: 0.0003306342114228755\n",
      "Epoch 2112, Loss: 0.004486472926373608, Final Batch Loss: 2.9989735139679397e-06\n",
      "Epoch 2113, Loss: 0.012696712277829647, Final Batch Loss: 0.006673422176390886\n",
      "Epoch 2114, Loss: 0.0053847660310566425, Final Batch Loss: 0.0023203063756227493\n",
      "Epoch 2115, Loss: 0.04017529194243252, Final Batch Loss: 0.021850252524018288\n",
      "Epoch 2116, Loss: 0.051387455547228456, Final Batch Loss: 0.04030570760369301\n",
      "Epoch 2117, Loss: 0.0030264403903856874, Final Batch Loss: 0.00015770818572491407\n",
      "Epoch 2118, Loss: 0.04283282069445704, Final Batch Loss: 5.935669832979329e-05\n",
      "Epoch 2119, Loss: 0.01657472737133503, Final Batch Loss: 0.0010546230478212237\n",
      "Epoch 2120, Loss: 0.0269927041081246, Final Batch Loss: 0.00040206857374869287\n",
      "Epoch 2121, Loss: 0.02968757227063179, Final Batch Loss: 0.005024121142923832\n",
      "Epoch 2122, Loss: 0.006099765421822667, Final Batch Loss: 0.0009151946287602186\n",
      "Epoch 2123, Loss: 0.002681300109543372, Final Batch Loss: 6.710421439493075e-05\n",
      "Epoch 2124, Loss: 0.004478512622881681, Final Batch Loss: 0.001459841849282384\n",
      "Epoch 2125, Loss: 0.002133073350705672, Final Batch Loss: 0.00010743889288278297\n",
      "Epoch 2126, Loss: 0.0035521979443728924, Final Batch Loss: 0.0013238986721262336\n",
      "Epoch 2127, Loss: 0.016855406225658953, Final Batch Loss: 0.0006223474629223347\n",
      "Epoch 2128, Loss: 0.00573528409586288, Final Batch Loss: 0.00037158202030695975\n",
      "Epoch 2129, Loss: 0.012917812058731215, Final Batch Loss: 4.752127642859705e-05\n",
      "Epoch 2130, Loss: 0.0029034825856797397, Final Batch Loss: 0.0008551343344151974\n",
      "Epoch 2131, Loss: 0.0034995267778867856, Final Batch Loss: 0.00017267036309931427\n",
      "Epoch 2132, Loss: 0.02490224048960954, Final Batch Loss: 0.0026313753332942724\n",
      "Epoch 2133, Loss: 0.0022324894489429425, Final Batch Loss: 2.2434436687035486e-05\n",
      "Epoch 2134, Loss: 0.011470843128336128, Final Batch Loss: 8.091722702374682e-05\n",
      "Epoch 2135, Loss: 0.0028562275247168145, Final Batch Loss: 3.902429853042122e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2136, Loss: 0.0015807945005690272, Final Batch Loss: 6.7757632677967194e-06\n",
      "Epoch 2137, Loss: 0.013654730399139225, Final Batch Loss: 0.002424786798655987\n",
      "Epoch 2138, Loss: 0.02530420629773289, Final Batch Loss: 0.002416058210656047\n",
      "Epoch 2139, Loss: 0.0017953019596461672, Final Batch Loss: 4.741478551295586e-05\n",
      "Epoch 2140, Loss: 0.0042426927539054304, Final Batch Loss: 0.00017302212654612958\n",
      "Epoch 2141, Loss: 0.0036041110979567748, Final Batch Loss: 5.015190617996268e-05\n",
      "Epoch 2142, Loss: 0.0015372266534541268, Final Batch Loss: 4.4724165491061285e-05\n",
      "Epoch 2143, Loss: 0.005580497730989009, Final Batch Loss: 0.000644306477624923\n",
      "Epoch 2144, Loss: 0.0063981030143622775, Final Batch Loss: 4.9611135182203725e-05\n",
      "Epoch 2145, Loss: 0.011950004729442298, Final Batch Loss: 0.0002516546519473195\n",
      "Epoch 2146, Loss: 0.008786260208580643, Final Batch Loss: 0.0008470072061754763\n",
      "Epoch 2147, Loss: 0.0038503246614709496, Final Batch Loss: 0.001532370806671679\n",
      "Epoch 2148, Loss: 0.0029502238030545413, Final Batch Loss: 0.0013088795822113752\n",
      "Epoch 2149, Loss: 0.011380327021470293, Final Batch Loss: 0.010221423581242561\n",
      "Epoch 2150, Loss: 0.002473935157468077, Final Batch Loss: 2.7161753678228706e-05\n",
      "Epoch 2151, Loss: 0.010757516232843045, Final Batch Loss: 5.507018795469776e-05\n",
      "Epoch 2152, Loss: 0.008504621393512934, Final Batch Loss: 0.003699729684740305\n",
      "Epoch 2153, Loss: 0.0019009513207493, Final Batch Loss: 7.503666893171612e-06\n",
      "Epoch 2154, Loss: 0.0028591896771104075, Final Batch Loss: 2.706298982957378e-05\n",
      "Epoch 2155, Loss: 0.0027200936201552395, Final Batch Loss: 4.8317804612452164e-05\n",
      "Epoch 2156, Loss: 0.0034942806406945692, Final Batch Loss: 4.078202948676335e-07\n",
      "Epoch 2157, Loss: 0.0032049010933405953, Final Batch Loss: 2.2365509721566923e-05\n",
      "Epoch 2158, Loss: 0.031718013782665366, Final Batch Loss: 4.745551632368006e-05\n",
      "Epoch 2159, Loss: 0.0025675162105471827, Final Batch Loss: 0.00012074600817868486\n",
      "Epoch 2160, Loss: 0.004924303037114441, Final Batch Loss: 0.0015201728092506528\n",
      "Epoch 2161, Loss: 0.0065848212398123, Final Batch Loss: 0.00019650135072879493\n",
      "Epoch 2162, Loss: 0.004045634239446372, Final Batch Loss: 0.0023511312901973724\n",
      "Epoch 2163, Loss: 0.014596145054383669, Final Batch Loss: 8.629120566183701e-05\n",
      "Epoch 2164, Loss: 0.001238727694726549, Final Batch Loss: 0.00019420146418269724\n",
      "Epoch 2165, Loss: 0.022835657893892858, Final Batch Loss: 2.4531821054551983e-06\n",
      "Epoch 2166, Loss: 0.01208639214746654, Final Batch Loss: 7.448886753991246e-05\n",
      "Epoch 2167, Loss: 0.0019011365670849045, Final Batch Loss: 7.359108622040367e-06\n",
      "Epoch 2168, Loss: 0.002546971314586699, Final Batch Loss: 0.000582000648137182\n",
      "Epoch 2169, Loss: 0.0031155887991189957, Final Batch Loss: 0.0008745958912186325\n",
      "Epoch 2170, Loss: 0.0014943403148208745, Final Batch Loss: 9.485358168603852e-05\n",
      "Epoch 2171, Loss: 0.08249628733028658, Final Batch Loss: 0.08031339943408966\n",
      "Epoch 2172, Loss: 0.01089124228383298, Final Batch Loss: 2.552753358031623e-05\n",
      "Epoch 2173, Loss: 0.04789269249886274, Final Batch Loss: 0.02076124958693981\n",
      "Epoch 2174, Loss: 0.08261961110383709, Final Batch Loss: 8.093123142316472e-06\n",
      "Epoch 2175, Loss: 0.06116156163625419, Final Batch Loss: 1.5766127035021782e-05\n",
      "Epoch 2176, Loss: 0.0640455647953786, Final Batch Loss: 0.0005591321387328207\n",
      "Epoch 2177, Loss: 0.0059608115698210895, Final Batch Loss: 0.0021700484212487936\n",
      "Epoch 2178, Loss: 0.003369040379766375, Final Batch Loss: 0.0009311929461546242\n",
      "Epoch 2179, Loss: 0.005948138204985298, Final Batch Loss: 0.00037132733268663287\n",
      "Epoch 2180, Loss: 0.005451464629004477, Final Batch Loss: 4.789694139617495e-05\n",
      "Epoch 2181, Loss: 0.013778777181869373, Final Batch Loss: 0.00038752492400817573\n",
      "Epoch 2182, Loss: 0.004805242904694751, Final Batch Loss: 0.00013615380157716572\n",
      "Epoch 2183, Loss: 0.010323440526235572, Final Batch Loss: 3.312700982860406e-06\n",
      "Epoch 2184, Loss: 0.015785903364985643, Final Batch Loss: 3.3503608847240685e-06\n",
      "Epoch 2185, Loss: 0.0017338680372631643, Final Batch Loss: 6.129532266641036e-06\n",
      "Epoch 2186, Loss: 0.0042245595886925, Final Batch Loss: 2.3178645278676413e-05\n",
      "Epoch 2187, Loss: 0.0526592432288453, Final Batch Loss: 0.03285888209939003\n",
      "Epoch 2188, Loss: 0.003141349583529518, Final Batch Loss: 1.7916487195179798e-05\n",
      "Epoch 2189, Loss: 0.008722810132894665, Final Batch Loss: 0.006112891715019941\n",
      "Epoch 2190, Loss: 0.07697065966203809, Final Batch Loss: 0.006451047956943512\n",
      "Epoch 2191, Loss: 0.0016246548875642475, Final Batch Loss: 1.134280682890676e-05\n",
      "Epoch 2192, Loss: 0.006288183620199561, Final Batch Loss: 0.0043317093513906\n",
      "Epoch 2193, Loss: 0.011847531772218645, Final Batch Loss: 0.006325026974081993\n",
      "Epoch 2194, Loss: 0.003508162742946297, Final Batch Loss: 0.00033942953450605273\n",
      "Epoch 2195, Loss: 0.00971991932601668, Final Batch Loss: 0.00034520970075391233\n",
      "Epoch 2196, Loss: 0.007137277512811124, Final Batch Loss: 0.004549373872578144\n",
      "Epoch 2197, Loss: 0.0021764525154139847, Final Batch Loss: 0.000359775876859203\n",
      "Epoch 2198, Loss: 0.0020948428336851066, Final Batch Loss: 2.978997326863464e-05\n",
      "Epoch 2199, Loss: 0.0015194389852695167, Final Batch Loss: 0.00028320017736405134\n",
      "Epoch 2200, Loss: 0.01794121865532361, Final Batch Loss: 0.000171246676472947\n",
      "Epoch 2201, Loss: 0.004117580887395889, Final Batch Loss: 0.0002678974997252226\n",
      "Epoch 2202, Loss: 0.001337445602985099, Final Batch Loss: 0.0\n",
      "Epoch 2203, Loss: 0.0037934378897261922, Final Batch Loss: 8.563552000850905e-06\n",
      "Epoch 2204, Loss: 0.0033075372339226305, Final Batch Loss: 0.0001366193755529821\n",
      "Epoch 2205, Loss: 0.002201049428549595, Final Batch Loss: 0.00013404381752479821\n",
      "Epoch 2206, Loss: 0.0087140774121508, Final Batch Loss: 0.0009994440479204059\n",
      "Epoch 2207, Loss: 0.002329993512830697, Final Batch Loss: 0.0016166764544323087\n",
      "Epoch 2208, Loss: 0.003621065756306052, Final Batch Loss: 0.0005072029307484627\n",
      "Epoch 2209, Loss: 0.002045879722572863, Final Batch Loss: 0.0007591790053993464\n",
      "Epoch 2210, Loss: 0.006974923649977427, Final Batch Loss: 5.1774542953353375e-05\n",
      "Epoch 2211, Loss: 0.0016437337617389858, Final Batch Loss: 0.0001249585475306958\n",
      "Epoch 2212, Loss: 0.006147519488877151, Final Batch Loss: 6.429784843930975e-05\n",
      "Epoch 2213, Loss: 0.004115975709282793, Final Batch Loss: 0.00014940906839910895\n",
      "Epoch 2214, Loss: 0.003483719250652939, Final Batch Loss: 0.00019844158669002354\n",
      "Epoch 2215, Loss: 0.0033068913617171347, Final Batch Loss: 0.0022640235256403685\n",
      "Epoch 2216, Loss: 0.00225168775068596, Final Batch Loss: 0.00040642457315698266\n",
      "Epoch 2217, Loss: 0.023962922226019145, Final Batch Loss: 1.4774856936128344e-05\n",
      "Epoch 2218, Loss: 0.00230215262308775, Final Batch Loss: 2.0500790924415924e-05\n",
      "Epoch 2219, Loss: 0.014865763754642103, Final Batch Loss: 7.320213626371697e-05\n",
      "Epoch 2220, Loss: 0.0033006976591423154, Final Batch Loss: 0.0019948736298829317\n",
      "Epoch 2221, Loss: 0.009057996132654011, Final Batch Loss: 2.1959586149478127e-07\n",
      "Epoch 2222, Loss: 0.22370191448135301, Final Batch Loss: 0.22233787178993225\n",
      "Epoch 2223, Loss: 0.0031517804454779252, Final Batch Loss: 0.0021513495594263077\n",
      "Epoch 2224, Loss: 0.006850713514722884, Final Batch Loss: 0.0011908354936167598\n",
      "Epoch 2225, Loss: 0.02430500169066363, Final Batch Loss: 1.5402070857817307e-05\n",
      "Epoch 2226, Loss: 0.04718049871735275, Final Batch Loss: 0.03821494057774544\n",
      "Epoch 2227, Loss: 0.013032000148086809, Final Batch Loss: 7.349728548433632e-05\n",
      "Epoch 2228, Loss: 0.004454293928574771, Final Batch Loss: 0.0008083937573246658\n",
      "Epoch 2229, Loss: 0.00640356179792434, Final Batch Loss: 0.0019594423938542604\n",
      "Epoch 2230, Loss: 0.012428592534888594, Final Batch Loss: 9.774456884770188e-06\n",
      "Epoch 2231, Loss: 0.004211386257111371, Final Batch Loss: 3.720457925737719e-06\n",
      "Epoch 2232, Loss: 0.006136792842880823, Final Batch Loss: 0.0002058789978036657\n",
      "Epoch 2233, Loss: 0.05469705394534685, Final Batch Loss: 2.1593501514871605e-05\n",
      "Epoch 2234, Loss: 0.002983293932629749, Final Batch Loss: 4.07015613745898e-05\n",
      "Epoch 2235, Loss: 0.01784072459122399, Final Batch Loss: 6.265464617172256e-05\n",
      "Epoch 2236, Loss: 0.015035741525935009, Final Batch Loss: 0.00012743569095619023\n",
      "Epoch 2237, Loss: 0.06537733267759904, Final Batch Loss: 0.05764000117778778\n",
      "Epoch 2238, Loss: 0.003000688702741172, Final Batch Loss: 7.647638994967565e-05\n",
      "Epoch 2239, Loss: 0.0397445319686085, Final Batch Loss: 0.010469581000506878\n",
      "Epoch 2240, Loss: 0.019598759128712118, Final Batch Loss: 0.0026269713416695595\n",
      "Epoch 2241, Loss: 0.005379294598242268, Final Batch Loss: 0.000313079304760322\n",
      "Epoch 2242, Loss: 0.014731498376931995, Final Batch Loss: 0.0043287742882966995\n",
      "Epoch 2243, Loss: 0.038030194700695574, Final Batch Loss: 0.02461337111890316\n",
      "Epoch 2244, Loss: 0.004057527854456566, Final Batch Loss: 0.0001778892328729853\n",
      "Epoch 2245, Loss: 0.012573397194501013, Final Batch Loss: 7.519073551520705e-05\n",
      "Epoch 2246, Loss: 0.0041519795850035734, Final Batch Loss: 8.59460633364506e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2247, Loss: 0.0017404762038495392, Final Batch Loss: 0.00026555414660833776\n",
      "Epoch 2248, Loss: 0.028080703945306595, Final Batch Loss: 9.963512275135145e-05\n",
      "Epoch 2249, Loss: 0.008186956511053722, Final Batch Loss: 7.577763608423993e-05\n",
      "Epoch 2250, Loss: 0.002289955344167538, Final Batch Loss: 0.00023713028349447995\n",
      "Epoch 2251, Loss: 0.017573253229443253, Final Batch Loss: 1.5496985952268005e-06\n",
      "Epoch 2252, Loss: 0.005053345227054251, Final Batch Loss: 2.6978915457220864e-07\n",
      "Epoch 2253, Loss: 0.004069325892487541, Final Batch Loss: 0.002136442344635725\n",
      "Epoch 2254, Loss: 0.005545700507354923, Final Batch Loss: 0.00016896759916562587\n",
      "Epoch 2255, Loss: 0.004314059915486723, Final Batch Loss: 0.00045265129301697016\n",
      "Epoch 2256, Loss: 0.004734902584459633, Final Batch Loss: 0.0003659541835077107\n",
      "Epoch 2257, Loss: 0.002491757142706774, Final Batch Loss: 0.00021027457842137665\n",
      "Epoch 2258, Loss: 0.0037886205609538592, Final Batch Loss: 0.00012039519060635939\n",
      "Epoch 2259, Loss: 0.006216606241650879, Final Batch Loss: 0.003461258253082633\n",
      "Epoch 2260, Loss: 0.010012341779656708, Final Batch Loss: 0.005085176322609186\n",
      "Epoch 2261, Loss: 0.004640278310716894, Final Batch Loss: 3.2248415209323866e-06\n",
      "Epoch 2262, Loss: 0.0029264694603625685, Final Batch Loss: 0.0008396604098379612\n",
      "Epoch 2263, Loss: 0.010436416196171194, Final Batch Loss: 5.5942218750715256e-05\n",
      "Epoch 2264, Loss: 0.0055764911230653524, Final Batch Loss: 0.0031264207791537046\n",
      "Epoch 2265, Loss: 0.002765763652860187, Final Batch Loss: 0.00016401415632572025\n",
      "Epoch 2266, Loss: 0.012963049579411745, Final Batch Loss: 0.0034601492807269096\n",
      "Epoch 2267, Loss: 0.004176259215455502, Final Batch Loss: 0.0003113906132057309\n",
      "Epoch 2268, Loss: 0.01765590349532431, Final Batch Loss: 0.0001142819455708377\n",
      "Epoch 2269, Loss: 0.0017229601799044758, Final Batch Loss: 0.00033441430423408747\n",
      "Epoch 2270, Loss: 0.006049483228707686, Final Batch Loss: 0.00042349062277935445\n",
      "Epoch 2271, Loss: 0.003042321694920247, Final Batch Loss: 1.0791545719257556e-06\n",
      "Epoch 2272, Loss: 0.03960262924374547, Final Batch Loss: 0.0007968936115503311\n",
      "Epoch 2273, Loss: 0.003995622962975176, Final Batch Loss: 4.106240885448642e-05\n",
      "Epoch 2274, Loss: 0.004734634541819105, Final Batch Loss: 2.062804196611978e-05\n",
      "Epoch 2275, Loss: 0.0015961075587256346, Final Batch Loss: 3.3208332752110437e-05\n",
      "Epoch 2276, Loss: 0.003413368249312043, Final Batch Loss: 0.0006241319351829588\n",
      "Epoch 2277, Loss: 0.0018720423395279795, Final Batch Loss: 0.00017522109556011856\n",
      "Epoch 2278, Loss: 0.0037237453634588746, Final Batch Loss: 1.9159762814524584e-05\n",
      "Epoch 2279, Loss: 0.0030753330674997414, Final Batch Loss: 1.3720930837735068e-05\n",
      "Epoch 2280, Loss: 0.013128534479619702, Final Batch Loss: 3.198772537871264e-05\n",
      "Epoch 2281, Loss: 0.001576321039465256, Final Batch Loss: 7.035471207927912e-05\n",
      "Epoch 2282, Loss: 0.0031618427001376403, Final Batch Loss: 1.5752970284665935e-05\n",
      "Epoch 2283, Loss: 0.004108396562514827, Final Batch Loss: 9.296691860072315e-05\n",
      "Epoch 2284, Loss: 0.0075812096474692225, Final Batch Loss: 0.0058753942139446735\n",
      "Epoch 2285, Loss: 0.019269346143119037, Final Batch Loss: 0.0180957168340683\n",
      "Epoch 2286, Loss: 0.002336389100037195, Final Batch Loss: 6.7884161580877844e-06\n",
      "Epoch 2287, Loss: 0.0005831607149957563, Final Batch Loss: 1.1430925042077433e-05\n",
      "Epoch 2288, Loss: 0.11822310509160161, Final Batch Loss: 0.10401981323957443\n",
      "Epoch 2289, Loss: 0.004418296026415192, Final Batch Loss: 0.003632996929809451\n",
      "Epoch 2290, Loss: 0.0017698073063456832, Final Batch Loss: 1.9888977931259433e-06\n",
      "Epoch 2291, Loss: 0.00924097784445621, Final Batch Loss: 0.00021209570695646107\n",
      "Epoch 2292, Loss: 0.014875600929372013, Final Batch Loss: 0.0017340739723294973\n",
      "Epoch 2293, Loss: 0.010368450311943889, Final Batch Loss: 0.0011307962704449892\n",
      "Epoch 2294, Loss: 0.007450373130268417, Final Batch Loss: 4.9518057494424284e-05\n",
      "Epoch 2295, Loss: 0.011060333623390761, Final Batch Loss: 2.9939563319203444e-05\n",
      "Epoch 2296, Loss: 0.007597961666760966, Final Batch Loss: 0.00030640841578133404\n",
      "Epoch 2297, Loss: 0.0027723388684535166, Final Batch Loss: 1.8583092241897248e-05\n",
      "Epoch 2298, Loss: 0.01860974740702659, Final Batch Loss: 0.0035780961625277996\n",
      "Epoch 2299, Loss: 0.00536968715096009, Final Batch Loss: 4.681724021793343e-05\n",
      "Epoch 2300, Loss: 0.006682900740997866, Final Batch Loss: 0.0004579726664815098\n",
      "Epoch 2301, Loss: 0.0015322854469559388, Final Batch Loss: 1.0803576515172608e-05\n",
      "Epoch 2302, Loss: 0.0011979524056187074, Final Batch Loss: 5.772230906586628e-07\n",
      "Epoch 2303, Loss: 0.0017867720744106919, Final Batch Loss: 0.000692550151143223\n",
      "Epoch 2304, Loss: 0.0040611611916574475, Final Batch Loss: 6.211223535501631e-06\n",
      "Epoch 2305, Loss: 0.002581370972620789, Final Batch Loss: 4.555311898002401e-05\n",
      "Epoch 2306, Loss: 0.0014492061573037063, Final Batch Loss: 1.247158525075065e-05\n",
      "Epoch 2307, Loss: 0.0009752842253192284, Final Batch Loss: 1.8885131112256204e-06\n",
      "Epoch 2308, Loss: 0.0015123285411391407, Final Batch Loss: 0.0001511557202320546\n",
      "Epoch 2309, Loss: 0.0015412159264087677, Final Batch Loss: 0.0008584113675169647\n",
      "Epoch 2310, Loss: 0.002071582079224754, Final Batch Loss: 7.660914707230404e-05\n",
      "Epoch 2311, Loss: 0.003478556463960558, Final Batch Loss: 0.00033726770197972655\n",
      "Epoch 2312, Loss: 0.003496088698739186, Final Batch Loss: 0.0014146052999421954\n",
      "Epoch 2313, Loss: 0.0037303688295651227, Final Batch Loss: 0.00225022342056036\n",
      "Epoch 2314, Loss: 0.001970002253074199, Final Batch Loss: 0.0011448089499026537\n",
      "Epoch 2315, Loss: 0.0026411469152662903, Final Batch Loss: 0.0005484023131430149\n",
      "Epoch 2316, Loss: 0.0016197893455682788, Final Batch Loss: 2.957572360173799e-05\n",
      "Epoch 2317, Loss: 0.0011026205638700048, Final Batch Loss: 5.809651156596374e-06\n",
      "Epoch 2318, Loss: 0.019246132345870137, Final Batch Loss: 0.0021039678249508142\n",
      "Epoch 2319, Loss: 0.002367766086535994, Final Batch Loss: 7.5556781666819e-05\n",
      "Epoch 2320, Loss: 0.020510268899670336, Final Batch Loss: 0.000115327573439572\n",
      "Epoch 2321, Loss: 0.003653853325261025, Final Batch Loss: 3.8272384017545846e-07\n",
      "Epoch 2322, Loss: 0.02409188833553344, Final Batch Loss: 0.012801438570022583\n",
      "Epoch 2323, Loss: 0.0065629915916360915, Final Batch Loss: 0.0052442909218370914\n",
      "Epoch 2324, Loss: 0.0018175008117395919, Final Batch Loss: 3.1029467209009454e-05\n",
      "Epoch 2325, Loss: 0.00124245737970341, Final Batch Loss: 1.6286721802316606e-05\n",
      "Epoch 2326, Loss: 0.00192502931895433, Final Batch Loss: 6.244575342861935e-05\n",
      "Epoch 2327, Loss: 0.0014791583016631193, Final Batch Loss: 0.0001218503966811113\n",
      "Epoch 2328, Loss: 0.0024649407132528722, Final Batch Loss: 0.00010444357758387923\n",
      "Epoch 2329, Loss: 0.0033323558745905757, Final Batch Loss: 0.0008117469260469079\n",
      "Epoch 2330, Loss: 0.0016967344017757569, Final Batch Loss: 1.4761946658836678e-05\n",
      "Epoch 2331, Loss: 0.0014832516590104206, Final Batch Loss: 2.5951854695449583e-05\n",
      "Epoch 2332, Loss: 0.002150659231119789, Final Batch Loss: 0.00012452075316105038\n",
      "Epoch 2333, Loss: 0.002586961680208333, Final Batch Loss: 0.00023350947594735771\n",
      "Epoch 2334, Loss: 0.002708608124521561, Final Batch Loss: 3.623364318627864e-05\n",
      "Epoch 2335, Loss: 0.02823433371668216, Final Batch Loss: 4.49228537036106e-05\n",
      "Epoch 2336, Loss: 0.0018929832149297, Final Batch Loss: 0.0005430957535281777\n",
      "Epoch 2337, Loss: 0.004160579992458224, Final Batch Loss: 0.00028243171982467175\n",
      "Epoch 2338, Loss: 0.0039206817164085805, Final Batch Loss: 0.0007799183949828148\n",
      "Epoch 2339, Loss: 0.0026323217462049797, Final Batch Loss: 0.0002120285207638517\n",
      "Epoch 2340, Loss: 0.0034574331366457045, Final Batch Loss: 0.0013502121437340975\n",
      "Epoch 2341, Loss: 0.0007417992583214073, Final Batch Loss: 1.852564855653327e-05\n",
      "Epoch 2342, Loss: 0.0063408185669686645, Final Batch Loss: 0.0016138686332851648\n",
      "Epoch 2343, Loss: 0.04499286523787305, Final Batch Loss: 0.03264978155493736\n",
      "Epoch 2344, Loss: 0.0107509803171979, Final Batch Loss: 3.3566291222086875e-06\n",
      "Epoch 2345, Loss: 0.001078566740034148, Final Batch Loss: 6.420366116799414e-05\n",
      "Epoch 2346, Loss: 0.0008425458754572901, Final Batch Loss: 2.8044987629982643e-06\n",
      "Epoch 2347, Loss: 0.013415217035799287, Final Batch Loss: 1.7785801901482046e-05\n",
      "Epoch 2348, Loss: 0.006329347776045324, Final Batch Loss: 3.9558031858177856e-05\n",
      "Epoch 2349, Loss: 0.005647753598168492, Final Batch Loss: 0.001090201549232006\n",
      "Epoch 2350, Loss: 0.0022128259297460318, Final Batch Loss: 9.848352055996656e-05\n",
      "Epoch 2351, Loss: 0.0009988804561089637, Final Batch Loss: 2.0453628621908138e-06\n",
      "Epoch 2352, Loss: 0.0013119410532453912, Final Batch Loss: 6.88877025822876e-06\n",
      "Epoch 2353, Loss: 0.001610447208804544, Final Batch Loss: 0.00012116322614019737\n",
      "Epoch 2354, Loss: 0.0038356263448804384, Final Batch Loss: 3.03486503980821e-05\n",
      "Epoch 2355, Loss: 0.010236411914320342, Final Batch Loss: 6.51240998195135e-06\n",
      "Epoch 2356, Loss: 0.0040891099197324365, Final Batch Loss: 0.0021465811878442764\n",
      "Epoch 2357, Loss: 0.004348279326222837, Final Batch Loss: 2.775306347757578e-05\n",
      "Epoch 2358, Loss: 0.0030551727541023865, Final Batch Loss: 1.1669544619508088e-05\n",
      "Epoch 2359, Loss: 0.0024028210900723934, Final Batch Loss: 0.00025536364410072565\n",
      "Epoch 2360, Loss: 0.0017238908330909908, Final Batch Loss: 0.0007468506810255349\n",
      "Epoch 2361, Loss: 0.002927612731582485, Final Batch Loss: 0.0002894304343499243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2362, Loss: 0.009706338458272512, Final Batch Loss: 1.752233765728306e-05\n",
      "Epoch 2363, Loss: 0.002153117093257606, Final Batch Loss: 0.0005124973249621689\n",
      "Epoch 2364, Loss: 0.026387623143818928, Final Batch Loss: 5.375594992074184e-05\n",
      "Epoch 2365, Loss: 0.0026074203110511007, Final Batch Loss: 6.430802841350669e-06\n",
      "Epoch 2366, Loss: 0.0073906003090087324, Final Batch Loss: 0.006759014446288347\n",
      "Epoch 2367, Loss: 0.002498945214028936, Final Batch Loss: 0.0003459711733739823\n",
      "Epoch 2368, Loss: 0.0017097415693569928, Final Batch Loss: 5.138426786288619e-06\n",
      "Epoch 2369, Loss: 0.004584151320159435, Final Batch Loss: 0.0002873042249120772\n",
      "Epoch 2370, Loss: 0.0031394445777550573, Final Batch Loss: 2.1185458535910584e-05\n",
      "Epoch 2371, Loss: 0.004772110616613645, Final Batch Loss: 1.7949154425878078e-05\n",
      "Epoch 2372, Loss: 0.012896476952505509, Final Batch Loss: 1.141887537414732e-06\n",
      "Epoch 2373, Loss: 0.0024566042902733898, Final Batch Loss: 2.6602265279507264e-06\n",
      "Epoch 2374, Loss: 0.0073789216912700795, Final Batch Loss: 0.00012185054220026359\n",
      "Epoch 2375, Loss: 0.0024657237336214166, Final Batch Loss: 3.149780604871921e-05\n",
      "Epoch 2376, Loss: 0.0032960625539999455, Final Batch Loss: 0.0011875199852511287\n",
      "Epoch 2377, Loss: 0.007596638257382438, Final Batch Loss: 0.0068677868694067\n",
      "Epoch 2378, Loss: 0.0007092656705935951, Final Batch Loss: 5.223748667049222e-05\n",
      "Epoch 2379, Loss: 0.014397742270375602, Final Batch Loss: 0.012704060412943363\n",
      "Epoch 2380, Loss: 0.00608164828736335, Final Batch Loss: 0.005100581794977188\n",
      "Epoch 2381, Loss: 0.0030520115553827054, Final Batch Loss: 3.6075664411328034e-06\n",
      "Epoch 2382, Loss: 0.0025683323037810624, Final Batch Loss: 0.0002856873325072229\n",
      "Epoch 2383, Loss: 0.004146310599026037, Final Batch Loss: 5.169571886654012e-05\n",
      "Epoch 2384, Loss: 0.0032530549506191164, Final Batch Loss: 0.00028874067356809974\n",
      "Epoch 2385, Loss: 0.050531095770566026, Final Batch Loss: 3.6462854041019455e-05\n",
      "Epoch 2386, Loss: 0.0007328230567509308, Final Batch Loss: 4.2122890590690076e-05\n",
      "Epoch 2387, Loss: 0.0016160892628249712, Final Batch Loss: 6.981017213547602e-05\n",
      "Epoch 2388, Loss: 0.0030078784823217575, Final Batch Loss: 2.923703732449212e-06\n",
      "Epoch 2389, Loss: 0.006977003125939518, Final Batch Loss: 0.0001455089804949239\n",
      "Epoch 2390, Loss: 0.0005527132798306411, Final Batch Loss: 2.5232386178686284e-05\n",
      "Epoch 2391, Loss: 0.0016290947532979771, Final Batch Loss: 0.0006179231568239629\n",
      "Epoch 2392, Loss: 0.004267826880095527, Final Batch Loss: 0.0033545573242008686\n",
      "Epoch 2393, Loss: 0.0054992773820004, Final Batch Loss: 1.9010639107364113e-06\n",
      "Epoch 2394, Loss: 0.0007457549327227753, Final Batch Loss: 2.258525273646228e-05\n",
      "Epoch 2395, Loss: 0.0012215624847158324, Final Batch Loss: 4.4486292608780786e-05\n",
      "Epoch 2396, Loss: 0.0018122677628298334, Final Batch Loss: 8.595578719905461e-07\n",
      "Epoch 2397, Loss: 0.0015047922679514159, Final Batch Loss: 1.7157075490104035e-05\n",
      "Epoch 2398, Loss: 0.0028361126605886966, Final Batch Loss: 0.00016762033919803798\n",
      "Epoch 2399, Loss: 0.007411690989101771, Final Batch Loss: 9.639384370530024e-05\n",
      "Epoch 2400, Loss: 0.004828409876900253, Final Batch Loss: 8.78383801250493e-08\n",
      "Epoch 2401, Loss: 0.0006373963988153264, Final Batch Loss: 4.246449680067599e-05\n",
      "Epoch 2402, Loss: 0.001566390332300216, Final Batch Loss: 3.7318095564842224e-05\n",
      "Epoch 2403, Loss: 0.0008822193376545329, Final Batch Loss: 1.1587184417294338e-05\n",
      "Epoch 2404, Loss: 0.002425995892721744, Final Batch Loss: 1.3175757374028763e-07\n",
      "Epoch 2405, Loss: 0.006130167515948415, Final Batch Loss: 0.0031483396887779236\n",
      "Epoch 2406, Loss: 0.0011193472109880531, Final Batch Loss: 6.142110578366555e-06\n",
      "Epoch 2407, Loss: 0.007093498163158074, Final Batch Loss: 0.0005541911232285202\n",
      "Epoch 2408, Loss: 0.01255656301509589, Final Batch Loss: 0.001132508274167776\n",
      "Epoch 2409, Loss: 0.0010055139355245046, Final Batch Loss: 9.198553016176447e-05\n",
      "Epoch 2410, Loss: 0.0013579495716840029, Final Batch Loss: 0.0008815810433588922\n",
      "Epoch 2411, Loss: 0.0009761425963006332, Final Batch Loss: 9.592628885002341e-06\n",
      "Epoch 2412, Loss: 0.0003860264864670171, Final Batch Loss: 4.002775767730782e-06\n",
      "Epoch 2413, Loss: 0.001553309908558731, Final Batch Loss: 2.599650360934902e-05\n",
      "Epoch 2414, Loss: 0.002583745175797958, Final Batch Loss: 4.529988655121997e-05\n",
      "Epoch 2415, Loss: 0.003902500342519488, Final Batch Loss: 9.900014993036166e-05\n",
      "Epoch 2416, Loss: 0.0020274902035453124, Final Batch Loss: 1.6342293747584336e-05\n",
      "Epoch 2417, Loss: 0.008601438774348935, Final Batch Loss: 2.4382487026741728e-05\n",
      "Epoch 2418, Loss: 0.0006051403140645562, Final Batch Loss: 6.901586857566144e-08\n",
      "Epoch 2419, Loss: 0.0009450079960515723, Final Batch Loss: 3.6205194192007184e-05\n",
      "Epoch 2420, Loss: 0.001202278695473069, Final Batch Loss: 6.135943749541184e-06\n",
      "Epoch 2421, Loss: 0.009946216829121113, Final Batch Loss: 0.002016715705394745\n",
      "Epoch 2422, Loss: 0.0010609136370476335, Final Batch Loss: 0.0002708988031372428\n",
      "Epoch 2423, Loss: 0.0010070803762118885, Final Batch Loss: 1.832034968174412e-06\n",
      "Epoch 2424, Loss: 0.011226386599446414, Final Batch Loss: 0.011017147451639175\n",
      "Epoch 2425, Loss: 0.004674818899729871, Final Batch Loss: 3.871080480166711e-06\n",
      "Epoch 2426, Loss: 0.0026658105015258116, Final Batch Loss: 7.528977903348277e-07\n",
      "Epoch 2427, Loss: 0.009354266949230805, Final Batch Loss: 0.00025615174672566354\n",
      "Epoch 2428, Loss: 0.007332233828492463, Final Batch Loss: 0.0008609282085672021\n",
      "Epoch 2429, Loss: 0.0018014936607642085, Final Batch Loss: 1.2610938711077324e-06\n",
      "Epoch 2430, Loss: 0.002910048177000135, Final Batch Loss: 0.0007911251741461456\n",
      "Epoch 2431, Loss: 0.0011452716862550005, Final Batch Loss: 0.0007224115543067455\n",
      "Epoch 2432, Loss: 0.0001736439789965516, Final Batch Loss: 4.943927706335671e-06\n",
      "Epoch 2433, Loss: 0.0009669669918821455, Final Batch Loss: 3.0303447147161933e-06\n",
      "Epoch 2434, Loss: 0.0011700000613927841, Final Batch Loss: 0.00034539418993517756\n",
      "Epoch 2435, Loss: 0.00037361716385930777, Final Batch Loss: 0.00013151232269592583\n",
      "Epoch 2436, Loss: 0.0007974032905622153, Final Batch Loss: 3.4334007068537176e-05\n",
      "Epoch 2437, Loss: 0.00020703474001493305, Final Batch Loss: 3.092083352385089e-05\n",
      "Epoch 2438, Loss: 0.009293568022258114, Final Batch Loss: 0.00010603412374621257\n",
      "Epoch 2439, Loss: 0.000279218951789062, Final Batch Loss: 7.905438792477071e-07\n",
      "Epoch 2440, Loss: 0.0005892391563975252, Final Batch Loss: 0.0003291729371994734\n",
      "Epoch 2441, Loss: 0.0017306845111306757, Final Batch Loss: 0.0012901086593046784\n",
      "Epoch 2442, Loss: 0.0018108610847775708, Final Batch Loss: 1.2497274838096928e-05\n",
      "Epoch 2443, Loss: 0.0019155661211698316, Final Batch Loss: 6.716933421557769e-05\n",
      "Epoch 2444, Loss: 0.0011925217633574903, Final Batch Loss: 6.274141810536094e-07\n",
      "Epoch 2445, Loss: 0.0027947568087256514, Final Batch Loss: 0.0014229005901142955\n",
      "Epoch 2446, Loss: 0.0008582202376601344, Final Batch Loss: 1.0289609235769603e-06\n",
      "Epoch 2447, Loss: 0.0014903853665089173, Final Batch Loss: 3.011594742474699e-07\n",
      "Epoch 2448, Loss: 0.010467717256688047, Final Batch Loss: 0.00014663676847703755\n",
      "Epoch 2449, Loss: 0.0010812970085680718, Final Batch Loss: 2.461019357724581e-05\n",
      "Epoch 2450, Loss: 0.00032582464064034866, Final Batch Loss: 1.1555767741810996e-05\n",
      "Epoch 2451, Loss: 0.0001670978986112459, Final Batch Loss: 6.719407338096062e-06\n",
      "Epoch 2452, Loss: 0.0014937816249585012, Final Batch Loss: 4.950235961587168e-06\n",
      "Epoch 2453, Loss: 0.0008201479213312268, Final Batch Loss: 0.0003504590131342411\n",
      "Epoch 2454, Loss: 0.0019623488897195784, Final Batch Loss: 9.184861482935958e-06\n",
      "Epoch 2455, Loss: 0.005774848919827491, Final Batch Loss: 0.004361663479357958\n",
      "Epoch 2456, Loss: 0.0002465034121996723, Final Batch Loss: 5.1764996896963567e-05\n",
      "Epoch 2457, Loss: 0.0004205297818771214, Final Batch Loss: 9.17870147532085e-06\n",
      "Epoch 2458, Loss: 0.0004895805250271223, Final Batch Loss: 0.00010273218504153192\n",
      "Epoch 2459, Loss: 0.0022382290135283256, Final Batch Loss: 1.3972176020615734e-05\n",
      "Epoch 2460, Loss: 0.00033172991243191063, Final Batch Loss: 4.181961412541568e-05\n",
      "Epoch 2461, Loss: 0.013568428184953518, Final Batch Loss: 0.0012731434544548392\n",
      "Epoch 2462, Loss: 0.0023269983080353995, Final Batch Loss: 3.0240785235946532e-06\n",
      "Epoch 2463, Loss: 0.0016851187538122758, Final Batch Loss: 8.202977187465876e-05\n",
      "Epoch 2464, Loss: 0.0011885870499099838, Final Batch Loss: 2.5370320145157166e-05\n",
      "Epoch 2465, Loss: 0.0007843943531042896, Final Batch Loss: 0.0004796767025254667\n",
      "Epoch 2466, Loss: 0.008608800908405101, Final Batch Loss: 4.830790203413926e-05\n",
      "Epoch 2467, Loss: 0.0005490993935381994, Final Batch Loss: 0.00016482036153320223\n",
      "Epoch 2468, Loss: 0.0007216169979074039, Final Batch Loss: 0.00010985518019879237\n",
      "Epoch 2469, Loss: 0.0013765242435965774, Final Batch Loss: 2.264958084197133e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2470, Loss: 0.0005299417280184571, Final Batch Loss: 3.8244124880293384e-05\n",
      "Epoch 2471, Loss: 0.0004951293008161883, Final Batch Loss: 4.128268756176112e-06\n",
      "Epoch 2472, Loss: 0.0007209494433482178, Final Batch Loss: 0.00042552343802526593\n",
      "Epoch 2473, Loss: 0.0009494743135292083, Final Batch Loss: 0.0006008177879266441\n",
      "Epoch 2474, Loss: 0.010402442685517599, Final Batch Loss: 2.760602001217194e-06\n",
      "Epoch 2475, Loss: 0.0024952469393610954, Final Batch Loss: 6.618967745453119e-06\n",
      "Epoch 2476, Loss: 0.0005489151226356626, Final Batch Loss: 1.6097925254143775e-05\n",
      "Epoch 2477, Loss: 0.0008080156985670328, Final Batch Loss: 0.0004971256130374968\n",
      "Epoch 2478, Loss: 0.00020521449109978107, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 2479, Loss: 0.0004968738005359796, Final Batch Loss: 6.274169805919882e-08\n",
      "Epoch 2480, Loss: 0.0005697007436538115, Final Batch Loss: 7.813981937943026e-05\n",
      "Epoch 2481, Loss: 0.01137007554370939, Final Batch Loss: 1.3268404472910333e-05\n",
      "Epoch 2482, Loss: 0.0017997218237724155, Final Batch Loss: 0.0009730354067869484\n",
      "Epoch 2483, Loss: 0.0011389780847821385, Final Batch Loss: 0.0001138060397352092\n",
      "Epoch 2484, Loss: 0.0008021029498195276, Final Batch Loss: 0.00013462307106237859\n",
      "Epoch 2485, Loss: 0.000791016824223334, Final Batch Loss: 5.287136082188226e-05\n",
      "Epoch 2486, Loss: 0.0014202282980022574, Final Batch Loss: 2.8985884910071036e-06\n",
      "Epoch 2487, Loss: 0.0014089117307776178, Final Batch Loss: 4.931424427923048e-06\n",
      "Epoch 2488, Loss: 0.0002673160806807573, Final Batch Loss: 9.329221029474866e-06\n",
      "Epoch 2489, Loss: 0.0014319982453123714, Final Batch Loss: 4.3919204273379364e-08\n",
      "Epoch 2490, Loss: 0.0014839366667729337, Final Batch Loss: 1.9913019059458748e-05\n",
      "Epoch 2491, Loss: 0.00031065295843291096, Final Batch Loss: 3.0066483304835856e-05\n",
      "Epoch 2492, Loss: 0.0006032184098785365, Final Batch Loss: 2.5974438813136658e-06\n",
      "Epoch 2493, Loss: 0.03159431021117598, Final Batch Loss: 2.4092521471175132e-06\n",
      "Epoch 2494, Loss: 0.0024490739160683006, Final Batch Loss: 0.0013957653427496552\n",
      "Epoch 2495, Loss: 0.006362369509588461, Final Batch Loss: 1.0301526344846934e-05\n",
      "Epoch 2496, Loss: 0.002221573955466738, Final Batch Loss: 0.0016013398999348283\n",
      "Epoch 2497, Loss: 0.0015440434987681328, Final Batch Loss: 5.70948657241388e-07\n",
      "Epoch 2498, Loss: 0.0049789719269028865, Final Batch Loss: 0.00010714682139223441\n",
      "Epoch 2499, Loss: 0.003445728223596234, Final Batch Loss: 0.0020443261601030827\n",
      "Epoch 2500, Loss: 0.0006870790821267292, Final Batch Loss: 0.0001727358321659267\n",
      "Epoch 2501, Loss: 0.0018077343993354589, Final Batch Loss: 3.3112213714048266e-05\n",
      "Epoch 2502, Loss: 0.002256215491797775, Final Batch Loss: 8.501678530592471e-05\n",
      "Epoch 2503, Loss: 0.002987198269693181, Final Batch Loss: 0.0007279821438714862\n",
      "Epoch 2504, Loss: 0.002403762244284735, Final Batch Loss: 1.76714329427341e-05\n",
      "Epoch 2505, Loss: 0.000485900267449324, Final Batch Loss: 9.065786798601039e-06\n",
      "Epoch 2506, Loss: 0.0017123299585364293, Final Batch Loss: 3.811464921454899e-05\n",
      "Epoch 2507, Loss: 0.00026381504548567136, Final Batch Loss: 2.948855524209648e-07\n",
      "Epoch 2508, Loss: 0.0049487791616229515, Final Batch Loss: 3.2625171115796547e-06\n",
      "Epoch 2509, Loss: 0.0011801308412486833, Final Batch Loss: 1.1418871963542188e-06\n",
      "Epoch 2510, Loss: 0.0036374516903379117, Final Batch Loss: 1.6751919247326441e-06\n",
      "Epoch 2511, Loss: 0.005594458192717866, Final Batch Loss: 5.828531357110478e-06\n",
      "Epoch 2512, Loss: 0.0022170521842781454, Final Batch Loss: 0.00154743785969913\n",
      "Epoch 2513, Loss: 0.0009853503697740962, Final Batch Loss: 2.1583009583991952e-06\n",
      "Epoch 2514, Loss: 0.0007686985836699023, Final Batch Loss: 1.4058669876249041e-05\n",
      "Epoch 2515, Loss: 0.001518558608040621, Final Batch Loss: 6.719418706779834e-06\n",
      "Epoch 2516, Loss: 0.0013742035364430194, Final Batch Loss: 2.6350892312621e-06\n",
      "Epoch 2517, Loss: 0.0006981801416259259, Final Batch Loss: 0.00013753693201579154\n",
      "Epoch 2518, Loss: 0.0005449765332627976, Final Batch Loss: 7.278023872459016e-07\n",
      "Epoch 2519, Loss: 0.0025100468646996887, Final Batch Loss: 2.8208467483636923e-05\n",
      "Epoch 2520, Loss: 0.001295738289172732, Final Batch Loss: 1.3175699677958619e-06\n",
      "Epoch 2521, Loss: 0.001067548138962593, Final Batch Loss: 0.00019914454605896026\n",
      "Epoch 2522, Loss: 0.0011938734216556668, Final Batch Loss: 2.3214415989514237e-07\n",
      "Epoch 2523, Loss: 0.00301075213792501, Final Batch Loss: 6.173009023768827e-05\n",
      "Epoch 2524, Loss: 0.0004890847521892283, Final Batch Loss: 4.318997889640741e-05\n",
      "Epoch 2525, Loss: 0.0008716207794350339, Final Batch Loss: 2.6459352739038877e-05\n",
      "Epoch 2526, Loss: 0.0025145162144326605, Final Batch Loss: 0.0009159068576991558\n",
      "Epoch 2527, Loss: 0.0037812454615959723, Final Batch Loss: 4.197289399598958e-06\n",
      "Epoch 2528, Loss: 0.010277642403252685, Final Batch Loss: 6.280228717514547e-06\n",
      "Epoch 2529, Loss: 0.001041068768245168, Final Batch Loss: 0.0005476356600411236\n",
      "Epoch 2530, Loss: 0.0012520644613687182, Final Batch Loss: 2.8546728572109714e-06\n",
      "Epoch 2531, Loss: 0.002012023765928461, Final Batch Loss: 2.418918847979512e-05\n",
      "Epoch 2532, Loss: 0.0015808994066901505, Final Batch Loss: 0.0002504205913282931\n",
      "Epoch 2533, Loss: 0.0003971393271058332, Final Batch Loss: 1.1424734111642465e-05\n",
      "Epoch 2534, Loss: 0.0009885297622531652, Final Batch Loss: 0.0001344654301647097\n",
      "Epoch 2535, Loss: 0.0006211919462657534, Final Batch Loss: 5.574175884248689e-05\n",
      "Epoch 2536, Loss: 0.0006382596347975777, Final Batch Loss: 2.446725011395756e-05\n",
      "Epoch 2537, Loss: 0.0008956712601957406, Final Batch Loss: 1.5371526842500316e-06\n",
      "Epoch 2538, Loss: 0.0004971348826074973, Final Batch Loss: 0.00011461718531791121\n",
      "Epoch 2539, Loss: 0.0006793600914534181, Final Batch Loss: 0.0004803609335795045\n",
      "Epoch 2540, Loss: 0.0011225400994590018, Final Batch Loss: 3.781403574976139e-05\n",
      "Epoch 2541, Loss: 0.00047107339196372777, Final Batch Loss: 0.00011283562344033271\n",
      "Epoch 2542, Loss: 0.0008114310330711305, Final Batch Loss: 0.00021469968487508595\n",
      "Epoch 2543, Loss: 0.002152357585146092, Final Batch Loss: 0.0011919518001377583\n",
      "Epoch 2544, Loss: 0.0022592781533603556, Final Batch Loss: 0.000102642246929463\n",
      "Epoch 2545, Loss: 0.0007566099520772696, Final Batch Loss: 0.00030552007956430316\n",
      "Epoch 2546, Loss: 0.0005857196592842229, Final Batch Loss: 3.8340142054948956e-05\n",
      "Epoch 2547, Loss: 0.008715760570339626, Final Batch Loss: 3.110186298727058e-05\n",
      "Epoch 2548, Loss: 0.0638108434619653, Final Batch Loss: 8.846515129334875e-07\n",
      "Epoch 2549, Loss: 0.00021933306925348006, Final Batch Loss: 0.00013489843695424497\n",
      "Epoch 2550, Loss: 0.011417540506045043, Final Batch Loss: 1.4266176549426746e-05\n",
      "Epoch 2551, Loss: 0.0011674501131722081, Final Batch Loss: 7.529004619755142e-08\n",
      "Epoch 2552, Loss: 0.12730769252812024, Final Batch Loss: 0.00015218018961604685\n",
      "Epoch 2553, Loss: 0.006532894913107157, Final Batch Loss: 0.0009563821367919445\n",
      "Epoch 2554, Loss: 0.002497619338100776, Final Batch Loss: 3.493131953291595e-05\n",
      "Epoch 2555, Loss: 0.0008370993309654295, Final Batch Loss: 0.00027908175252377987\n",
      "Epoch 2556, Loss: 0.001854485395597294, Final Batch Loss: 0.0005280826007947326\n",
      "Epoch 2557, Loss: 0.003275880004366627, Final Batch Loss: 5.866106221219525e-06\n",
      "Epoch 2558, Loss: 0.0035368923272471875, Final Batch Loss: 0.0019559254869818687\n",
      "Epoch 2559, Loss: 0.02261183770679054, Final Batch Loss: 0.01966513879597187\n",
      "Epoch 2560, Loss: 0.003597704431740567, Final Batch Loss: 0.0027232810389250517\n",
      "Epoch 2561, Loss: 0.0008227929138229229, Final Batch Loss: 4.70617160317488e-05\n",
      "Epoch 2562, Loss: 0.0024173867741410504, Final Batch Loss: 8.645357411296573e-06\n",
      "Epoch 2563, Loss: 0.01358577462087851, Final Batch Loss: 0.005264141596853733\n",
      "Epoch 2564, Loss: 0.0008951170457294211, Final Batch Loss: 0.0002024498680839315\n",
      "Epoch 2565, Loss: 0.004511619711223602, Final Batch Loss: 3.513528952225897e-07\n",
      "Epoch 2566, Loss: 0.0009849545895121992, Final Batch Loss: 0.00042900937842205167\n",
      "Epoch 2567, Loss: 0.0005657801211782498, Final Batch Loss: 4.943924068356864e-06\n",
      "Epoch 2568, Loss: 0.0014977533355704509, Final Batch Loss: 0.0012072052340954542\n",
      "Epoch 2569, Loss: 0.0015365620079137443, Final Batch Loss: 3.3566343518032227e-06\n",
      "Epoch 2570, Loss: 0.06128464993889793, Final Batch Loss: 3.263452890678309e-05\n",
      "Epoch 2571, Loss: 0.0018373555722064339, Final Batch Loss: 9.512851102044806e-05\n",
      "Epoch 2572, Loss: 0.002451197535265237, Final Batch Loss: 0.00019217404769733548\n",
      "Epoch 2573, Loss: 0.0013781570396531606, Final Batch Loss: 8.482407793053426e-06\n",
      "Epoch 2574, Loss: 0.0012687711569014937, Final Batch Loss: 0.00018122108303941786\n",
      "Epoch 2575, Loss: 0.003097799461102113, Final Batch Loss: 0.0014086865121498704\n",
      "Epoch 2576, Loss: 0.00047357343282783404, Final Batch Loss: 2.7476482500787824e-05\n",
      "Epoch 2577, Loss: 0.001062519964079911, Final Batch Loss: 3.657783281596494e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2578, Loss: 0.0019849866066579125, Final Batch Loss: 8.375601282750722e-06\n",
      "Epoch 2579, Loss: 0.001813297945773229, Final Batch Loss: 0.0008969209156930447\n",
      "Epoch 2580, Loss: 0.0017778625406208448, Final Batch Loss: 0.00010120601655216888\n",
      "Epoch 2581, Loss: 0.0007446898944181157, Final Batch Loss: 2.5367071430082433e-05\n",
      "Epoch 2582, Loss: 0.0010412425999675179, Final Batch Loss: 1.957387758011464e-05\n",
      "Epoch 2583, Loss: 0.0022292128996923566, Final Batch Loss: 0.0004197921371087432\n",
      "Epoch 2584, Loss: 0.00044293171231402084, Final Batch Loss: 3.482435568002984e-05\n",
      "Epoch 2585, Loss: 0.0011559238628251478, Final Batch Loss: 0.0001860964548541233\n",
      "Epoch 2586, Loss: 0.0014215705158378, Final Batch Loss: 1.1920916875851617e-07\n",
      "Epoch 2587, Loss: 0.00046040871529839933, Final Batch Loss: 6.929753726581112e-05\n",
      "Epoch 2588, Loss: 0.0001726469031382294, Final Batch Loss: 6.750620286766207e-06\n",
      "Epoch 2589, Loss: 0.0009172947347906302, Final Batch Loss: 1.4196589290804695e-05\n",
      "Epoch 2590, Loss: 0.010646650362332366, Final Batch Loss: 3.3001690553646768e-06\n",
      "Epoch 2591, Loss: 0.0015326059219660237, Final Batch Loss: 0.0001992271572817117\n",
      "Epoch 2592, Loss: 0.0005090870443495987, Final Batch Loss: 3.325301918266632e-07\n",
      "Epoch 2593, Loss: 0.00034978407848029747, Final Batch Loss: 5.671577582688769e-06\n",
      "Epoch 2594, Loss: 0.02502517022730899, Final Batch Loss: 5.93524964642711e-06\n",
      "Epoch 2595, Loss: 0.0010412854496735235, Final Batch Loss: 3.695360419442295e-06\n",
      "Epoch 2596, Loss: 0.0013580181937413727, Final Batch Loss: 8.658341812406434e-07\n",
      "Epoch 2597, Loss: 0.002470564329996705, Final Batch Loss: 0.0008214683039113879\n",
      "Epoch 2598, Loss: 0.0015741843089926988, Final Batch Loss: 0.0009770744945853949\n",
      "Epoch 2599, Loss: 0.0025359365245094523, Final Batch Loss: 7.445190567523241e-05\n",
      "Epoch 2600, Loss: 0.001550113331177272, Final Batch Loss: 0.0011039087548851967\n",
      "Epoch 2601, Loss: 0.0011420784776419168, Final Batch Loss: 4.6176774048944935e-06\n",
      "Epoch 2602, Loss: 0.001577491289936006, Final Batch Loss: 0.000474276312161237\n",
      "Epoch 2603, Loss: 0.0017006754278554581, Final Batch Loss: 4.4097214413341135e-05\n",
      "Epoch 2604, Loss: 0.0009904367761919275, Final Batch Loss: 0.00021927921625319868\n",
      "Epoch 2605, Loss: 0.0012430990318534896, Final Batch Loss: 2.373893221374601e-05\n",
      "Epoch 2606, Loss: 0.0018391297926427796, Final Batch Loss: 9.213727025780827e-05\n",
      "Epoch 2607, Loss: 0.001499458565376699, Final Batch Loss: 0.0005624567857012153\n",
      "Epoch 2608, Loss: 0.0003408211068745004, Final Batch Loss: 1.434109617548529e-05\n",
      "Epoch 2609, Loss: 0.0037905277781220548, Final Batch Loss: 1.3803169451875874e-07\n",
      "Epoch 2610, Loss: 0.0019051802979674903, Final Batch Loss: 5.270291012493544e-07\n",
      "Epoch 2611, Loss: 0.018681266519706696, Final Batch Loss: 0.000593072094488889\n",
      "Epoch 2612, Loss: 0.012622271371583338, Final Batch Loss: 1.8350254322285764e-05\n",
      "Epoch 2613, Loss: 0.0002790605758491438, Final Batch Loss: 4.529185753199272e-05\n",
      "Epoch 2614, Loss: 0.0009206661488860846, Final Batch Loss: 0.00024029891937971115\n",
      "Epoch 2615, Loss: 0.005695211089914665, Final Batch Loss: 0.00043210751027800143\n",
      "Epoch 2616, Loss: 0.0030316639022203162, Final Batch Loss: 0.00023462883837055415\n",
      "Epoch 2617, Loss: 0.001979945194989341, Final Batch Loss: 1.5559746771032223e-06\n",
      "Epoch 2618, Loss: 0.001139776417403482, Final Batch Loss: 9.398382098879665e-05\n",
      "Epoch 2619, Loss: 0.0006032644305378199, Final Batch Loss: 0.0002561580331530422\n",
      "Epoch 2620, Loss: 0.0006790644329157658, Final Batch Loss: 0.00010300399299012497\n",
      "Epoch 2621, Loss: 0.007667457823117729, Final Batch Loss: 3.790771006606519e-05\n",
      "Epoch 2622, Loss: 0.007928381892270409, Final Batch Loss: 0.004321553744375706\n",
      "Epoch 2623, Loss: 0.010511874506391905, Final Batch Loss: 4.736904429591959e-06\n",
      "Epoch 2624, Loss: 0.0033070530316763325, Final Batch Loss: 2.5990679205278866e-05\n",
      "Epoch 2625, Loss: 0.0005109372459628503, Final Batch Loss: 4.561140485748183e-06\n",
      "Epoch 2626, Loss: 0.010455939804160153, Final Batch Loss: 2.298632352903951e-05\n",
      "Epoch 2627, Loss: 0.002810850621067118, Final Batch Loss: 9.411251511437513e-08\n",
      "Epoch 2628, Loss: 0.0031784562452230603, Final Batch Loss: 0.0006891177617944777\n",
      "Epoch 2629, Loss: 0.0005797031026304467, Final Batch Loss: 1.9377357602934353e-05\n",
      "Epoch 2630, Loss: 0.0023893556181064923, Final Batch Loss: 8.482134035148192e-06\n",
      "Epoch 2631, Loss: 0.0016891215127543546, Final Batch Loss: 7.170789467636496e-05\n",
      "Epoch 2632, Loss: 0.003997368272393942, Final Batch Loss: 0.00028962010401301086\n",
      "Epoch 2633, Loss: 0.0011289301510259975, Final Batch Loss: 1.3112912711221725e-06\n",
      "Epoch 2634, Loss: 0.0071013415363267995, Final Batch Loss: 5.944025906501338e-05\n",
      "Epoch 2635, Loss: 0.007908465224318206, Final Batch Loss: 0.003066377015784383\n",
      "Epoch 2636, Loss: 0.0010726545806392096, Final Batch Loss: 0.00048195585259236395\n",
      "Epoch 2637, Loss: 0.0007735178942311904, Final Batch Loss: 1.5434334272868e-06\n",
      "Epoch 2638, Loss: 0.003080299822613597, Final Batch Loss: 0.0005296504241414368\n",
      "Epoch 2639, Loss: 0.0020819162455154583, Final Batch Loss: 0.0004715292598120868\n",
      "Epoch 2640, Loss: 0.0005727473287038265, Final Batch Loss: 1.8822510128302383e-07\n",
      "Epoch 2641, Loss: 0.005985112529742764, Final Batch Loss: 3.736952567123808e-05\n",
      "Epoch 2642, Loss: 0.0024722833768464625, Final Batch Loss: 0.0001011175918392837\n",
      "Epoch 2643, Loss: 0.004654370233765803, Final Batch Loss: 0.00027619427419267595\n",
      "Epoch 2644, Loss: 0.0018149265465581266, Final Batch Loss: 6.926240075699752e-06\n",
      "Epoch 2645, Loss: 0.0005162534362170845, Final Batch Loss: 0.0002912817581091076\n",
      "Epoch 2646, Loss: 0.040359859509408125, Final Batch Loss: 2.009425406868104e-05\n",
      "Epoch 2647, Loss: 0.0007538425254622894, Final Batch Loss: 7.529002488126935e-08\n",
      "Epoch 2648, Loss: 0.004207559046506049, Final Batch Loss: 5.646726890518039e-07\n",
      "Epoch 2649, Loss: 0.0014221001183614135, Final Batch Loss: 0.00041201067506335676\n",
      "Epoch 2650, Loss: 0.003331189544951485, Final Batch Loss: 7.685571290494408e-06\n",
      "Epoch 2651, Loss: 0.0006537352984210543, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 2652, Loss: 0.0003626252437243238, Final Batch Loss: 6.668973219348118e-05\n",
      "Epoch 2653, Loss: 0.000497052569699008, Final Batch Loss: 0.00023280768073163927\n",
      "Epoch 2654, Loss: 0.0027216924113417917, Final Batch Loss: 6.167164883663645e-06\n",
      "Epoch 2655, Loss: 0.0005100084343609979, Final Batch Loss: 4.7056150265234464e-07\n",
      "Epoch 2656, Loss: 0.0003006222398767022, Final Batch Loss: 4.015458330286492e-07\n",
      "Epoch 2657, Loss: 0.00043917825593098314, Final Batch Loss: 6.399632752618345e-07\n",
      "Epoch 2658, Loss: 0.002979941782541573, Final Batch Loss: 6.89036533003673e-05\n",
      "Epoch 2659, Loss: 0.0007455239338014508, Final Batch Loss: 2.358843084948603e-05\n",
      "Epoch 2660, Loss: 0.002035817436990328, Final Batch Loss: 7.335015834541991e-05\n",
      "Epoch 2661, Loss: 0.0011093863856785902, Final Batch Loss: 2.9488280688383384e-06\n",
      "Epoch 2662, Loss: 0.00027304758805257734, Final Batch Loss: 3.971470505348407e-06\n",
      "Epoch 2663, Loss: 0.0008162693811755162, Final Batch Loss: 0.00018537418509367853\n",
      "Epoch 2664, Loss: 0.0003075833287766727, Final Batch Loss: 5.2700838750752155e-06\n",
      "Epoch 2665, Loss: 0.04418677063949872, Final Batch Loss: 0.04183105379343033\n",
      "Epoch 2666, Loss: 0.00037634282489307225, Final Batch Loss: 6.598207983188331e-05\n",
      "Epoch 2667, Loss: 0.00044093150518165203, Final Batch Loss: 2.264951945107896e-06\n",
      "Epoch 2668, Loss: 0.001816384683479555, Final Batch Loss: 0.001597012160345912\n",
      "Epoch 2669, Loss: 0.0005808714540762594, Final Batch Loss: 5.144811439095065e-07\n",
      "Epoch 2670, Loss: 0.006985888845520094, Final Batch Loss: 0.00019682536367326975\n",
      "Epoch 2671, Loss: 0.02008467565428873, Final Batch Loss: 1.365111347695347e-05\n",
      "Epoch 2672, Loss: 0.001347536137473071, Final Batch Loss: 4.040488420287147e-06\n",
      "Epoch 2673, Loss: 0.0010886520867643412, Final Batch Loss: 3.514904165058397e-05\n",
      "Epoch 2674, Loss: 0.000876099136803532, Final Batch Loss: 3.5080931411357597e-05\n",
      "Epoch 2675, Loss: 0.02022814124939032, Final Batch Loss: 3.214532625861466e-05\n",
      "Epoch 2676, Loss: 0.005300726876157569, Final Batch Loss: 3.6907400499330834e-05\n",
      "Epoch 2677, Loss: 0.0007306170155061409, Final Batch Loss: 0.00010787049541249871\n",
      "Epoch 2678, Loss: 0.00037197741539785056, Final Batch Loss: 1.010133473755559e-06\n",
      "Epoch 2679, Loss: 0.0013191485357708643, Final Batch Loss: 9.411255064151192e-08\n",
      "Epoch 2680, Loss: 0.0005583545353147201, Final Batch Loss: 9.955894347513095e-05\n",
      "Epoch 2681, Loss: 0.00031932011552271433, Final Batch Loss: 4.81822389701847e-05\n",
      "Epoch 2682, Loss: 0.0009480452135903761, Final Batch Loss: 0.0004919273196719587\n",
      "Epoch 2683, Loss: 0.0006351063057081774, Final Batch Loss: 0.00010143221879843622\n",
      "Epoch 2684, Loss: 0.00023294961465580855, Final Batch Loss: 1.63871100085089e-05\n",
      "Epoch 2685, Loss: 0.0007314327794745168, Final Batch Loss: 3.137083410820196e-07\n",
      "Epoch 2686, Loss: 0.006028046290722955, Final Batch Loss: 1.1293506929632713e-07\n",
      "Epoch 2687, Loss: 0.01645583835488651, Final Batch Loss: 2.566962211858481e-05\n",
      "Epoch 2688, Loss: 0.00028037624588250765, Final Batch Loss: 2.8672643566096667e-06\n",
      "Epoch 2689, Loss: 0.0027471356734167784, Final Batch Loss: 0.001849480322562158\n",
      "Epoch 2690, Loss: 0.00011533424802223635, Final Batch Loss: 3.764496625535685e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2691, Loss: 0.0013081855613563675, Final Batch Loss: 0.0008884073467925191\n",
      "Epoch 2692, Loss: 0.002997806845087325, Final Batch Loss: 5.1272680138936266e-05\n",
      "Epoch 2693, Loss: 0.012285207658351283, Final Batch Loss: 1.944990799529478e-07\n",
      "Epoch 2694, Loss: 0.0015359080762209487, Final Batch Loss: 5.859813427377958e-06\n",
      "Epoch 2695, Loss: 0.020361036207759753, Final Batch Loss: 0.01837700419127941\n",
      "Epoch 2696, Loss: 0.0004739402065752074, Final Batch Loss: 0.00010831877443706617\n",
      "Epoch 2697, Loss: 0.05993279378162697, Final Batch Loss: 0.0002821575035341084\n",
      "Epoch 2698, Loss: 0.3536258242384065, Final Batch Loss: 0.35232001543045044\n",
      "Epoch 2699, Loss: 0.007167273957747966, Final Batch Loss: 0.00014901795657351613\n",
      "Epoch 2700, Loss: 0.032020358010413474, Final Batch Loss: 1.3168717487133108e-05\n",
      "Epoch 2701, Loss: 0.09203811758197844, Final Batch Loss: 0.00038527906872332096\n",
      "Epoch 2702, Loss: 0.1576102450489998, Final Batch Loss: 0.08382473886013031\n",
      "Epoch 2703, Loss: 0.031778656877577305, Final Batch Loss: 0.0022519920021295547\n",
      "Epoch 2704, Loss: 0.044303445843979716, Final Batch Loss: 0.0038926589768379927\n",
      "Epoch 2705, Loss: 0.07462125291931443, Final Batch Loss: 0.0004746841441374272\n",
      "Epoch 2706, Loss: 0.06798120471648872, Final Batch Loss: 0.0016491811256855726\n",
      "Epoch 2707, Loss: 0.02318510843178956, Final Batch Loss: 3.990215918747708e-05\n",
      "Epoch 2708, Loss: 0.004143017837122898, Final Batch Loss: 1.5351832189480774e-05\n",
      "Epoch 2709, Loss: 0.1182439480908215, Final Batch Loss: 0.1054389700293541\n",
      "Epoch 2710, Loss: 0.0048733706353232265, Final Batch Loss: 0.0032853938173502684\n",
      "Epoch 2711, Loss: 0.028525111920316704, Final Batch Loss: 0.0002282529167132452\n",
      "Epoch 2712, Loss: 0.030508081486914307, Final Batch Loss: 0.014459068886935711\n",
      "Epoch 2713, Loss: 0.0068274115310487105, Final Batch Loss: 1.5407158571179025e-05\n",
      "Epoch 2714, Loss: 0.009051922359503806, Final Batch Loss: 0.0005656281718984246\n",
      "Epoch 2715, Loss: 0.006328145793304429, Final Batch Loss: 2.350680915697012e-05\n",
      "Epoch 2716, Loss: 0.006643639234088283, Final Batch Loss: 3.137086324045413e-08\n",
      "Epoch 2717, Loss: 0.03425179561600089, Final Batch Loss: 0.011182120069861412\n",
      "Epoch 2718, Loss: 0.024616086622700095, Final Batch Loss: 0.0006719925440847874\n",
      "Epoch 2719, Loss: 0.05943819605454337, Final Batch Loss: 0.05803618207573891\n",
      "Epoch 2720, Loss: 0.012243575980185994, Final Batch Loss: 6.901588989194352e-08\n",
      "Epoch 2721, Loss: 0.003817133590928279, Final Batch Loss: 0.00010953562741633505\n",
      "Epoch 2722, Loss: 0.03230895481829066, Final Batch Loss: 6.672141898889095e-05\n",
      "Epoch 2723, Loss: 0.06451639187434921, Final Batch Loss: 0.00010300827125320211\n",
      "Epoch 2724, Loss: 0.02330062771216035, Final Batch Loss: 0.00230390764772892\n",
      "Epoch 2725, Loss: 0.025363822001963854, Final Batch Loss: 0.0003730887547135353\n",
      "Epoch 2726, Loss: 0.004434070720435557, Final Batch Loss: 6.280195066210581e-06\n",
      "Epoch 2727, Loss: 0.03435000496392604, Final Batch Loss: 0.031451962888240814\n",
      "Epoch 2728, Loss: 0.007421791575325187, Final Batch Loss: 9.471226803725585e-05\n",
      "Epoch 2729, Loss: 0.015333461109548807, Final Batch Loss: 0.005935315508395433\n",
      "Epoch 2730, Loss: 0.002221293019829318, Final Batch Loss: 7.050225394777954e-05\n",
      "Epoch 2731, Loss: 0.012866436911281198, Final Batch Loss: 0.0005667807417921722\n",
      "Epoch 2732, Loss: 0.008113895892165601, Final Batch Loss: 0.0019430831307545304\n",
      "Epoch 2733, Loss: 0.005019549535063561, Final Batch Loss: 9.093156404560432e-05\n",
      "Epoch 2734, Loss: 0.005247365072136745, Final Batch Loss: 0.00016350377700291574\n",
      "Epoch 2735, Loss: 0.004130936653155004, Final Batch Loss: 2.886115453293314e-07\n",
      "Epoch 2736, Loss: 0.0009513149209396943, Final Batch Loss: 6.27417193754809e-08\n",
      "Epoch 2737, Loss: 0.007772334822220728, Final Batch Loss: 0.0002133526431862265\n",
      "Epoch 2738, Loss: 0.010708660061936826, Final Batch Loss: 0.0007651415071450174\n",
      "Epoch 2739, Loss: 0.0033854399159736204, Final Batch Loss: 1.98889097191568e-06\n",
      "Epoch 2740, Loss: 0.0020893168111797422, Final Batch Loss: 1.8551218090578914e-05\n",
      "Epoch 2741, Loss: 0.005376501954742707, Final Batch Loss: 0.00022105152311269194\n",
      "Epoch 2742, Loss: 0.002788248340948485, Final Batch Loss: 0.00136465672403574\n",
      "Epoch 2743, Loss: 0.00399187978291593, Final Batch Loss: 2.4282400772790425e-05\n",
      "Epoch 2744, Loss: 0.027282861236017197, Final Batch Loss: 0.0008031513425521553\n",
      "Epoch 2745, Loss: 0.008237072092015296, Final Batch Loss: 0.0004236915847286582\n",
      "Epoch 2746, Loss: 0.009877555344843358, Final Batch Loss: 1.882250728613144e-07\n",
      "Epoch 2747, Loss: 0.017243530950509012, Final Batch Loss: 0.013031261041760445\n",
      "Epoch 2748, Loss: 0.018563790704661187, Final Batch Loss: 1.5497129197683535e-06\n",
      "Epoch 2749, Loss: 0.005357779795303941, Final Batch Loss: 0.0006526145152747631\n",
      "Epoch 2750, Loss: 0.05820696282899007, Final Batch Loss: 0.05633353441953659\n",
      "Epoch 2751, Loss: 0.03703516203677282, Final Batch Loss: 0.035673510283231735\n",
      "Epoch 2752, Loss: 0.013417378504527733, Final Batch Loss: 0.0008357397746294737\n",
      "Epoch 2753, Loss: 0.05472820635259268, Final Batch Loss: 3.5683729947777465e-05\n",
      "Epoch 2754, Loss: 0.05494794249534607, Final Batch Loss: 0.012857518158853054\n",
      "Epoch 2755, Loss: 0.012528555125754792, Final Batch Loss: 1.4134049706626683e-05\n",
      "Epoch 2756, Loss: 0.0021361618855735287, Final Batch Loss: 0.0001776208373485133\n",
      "Epoch 2757, Loss: 0.003330836247187108, Final Batch Loss: 0.0002969871857203543\n",
      "Epoch 2758, Loss: 0.004759992370964028, Final Batch Loss: 6.284251867327839e-05\n",
      "Epoch 2759, Loss: 0.002892372474889271, Final Batch Loss: 0.0001540981902508065\n",
      "Epoch 2760, Loss: 0.009973845182685181, Final Batch Loss: 0.008708919398486614\n",
      "Epoch 2761, Loss: 0.006318462772469502, Final Batch Loss: 6.27420304226689e-05\n",
      "Epoch 2762, Loss: 0.07043612445704639, Final Batch Loss: 0.05791120231151581\n",
      "Epoch 2763, Loss: 0.014955872029531747, Final Batch Loss: 0.00044378358870744705\n",
      "Epoch 2764, Loss: 0.0026534530115895905, Final Batch Loss: 1.2566430086735636e-05\n",
      "Epoch 2765, Loss: 0.0018000060226768255, Final Batch Loss: 0.00013476575259119272\n",
      "Epoch 2766, Loss: 0.0018916934423032217, Final Batch Loss: 9.314610360888764e-05\n",
      "Epoch 2767, Loss: 0.0026501638130866922, Final Batch Loss: 7.146012649172917e-05\n",
      "Epoch 2768, Loss: 0.0011299139878246933, Final Batch Loss: 1.5395184163935483e-05\n",
      "Epoch 2769, Loss: 0.008784294768702239, Final Batch Loss: 0.0031165718100965023\n",
      "Epoch 2770, Loss: 0.007261369668412954, Final Batch Loss: 0.005603624973446131\n",
      "Epoch 2771, Loss: 0.006981217382190152, Final Batch Loss: 2.9111613457644125e-06\n",
      "Epoch 2772, Loss: 0.01013192393747886, Final Batch Loss: 1.3865837900084443e-06\n",
      "Epoch 2773, Loss: 0.0015140026080189273, Final Batch Loss: 0.0002368549903621897\n",
      "Epoch 2774, Loss: 0.0022100270143710077, Final Batch Loss: 0.0001179101673187688\n",
      "Epoch 2775, Loss: 0.004476284459030921, Final Batch Loss: 5.521250727724691e-07\n",
      "Epoch 2776, Loss: 0.0029249989937056853, Final Batch Loss: 6.148664510874369e-07\n",
      "Epoch 2777, Loss: 0.0008455297211185098, Final Batch Loss: 0.00034266826696693897\n",
      "Epoch 2778, Loss: 0.03097681506551453, Final Batch Loss: 1.2622174835996702e-05\n",
      "Epoch 2779, Loss: 0.00800835105474107, Final Batch Loss: 0.006927041802555323\n",
      "Epoch 2780, Loss: 0.0015072340538608842, Final Batch Loss: 0.0011666456703096628\n",
      "Epoch 2781, Loss: 0.0008466635176773707, Final Batch Loss: 2.2147710296849255e-06\n",
      "Epoch 2782, Loss: 0.0011396896588848904, Final Batch Loss: 0.00012996421719435602\n",
      "Epoch 2783, Loss: 0.001135042794814467, Final Batch Loss: 1.5685411369759095e-07\n",
      "Epoch 2784, Loss: 0.007410955907289463, Final Batch Loss: 6.236224180611316e-06\n",
      "Epoch 2785, Loss: 0.0017936114345502574, Final Batch Loss: 4.3227675632806495e-05\n",
      "Epoch 2786, Loss: 0.0024428638571407646, Final Batch Loss: 0.0004492440784815699\n",
      "Epoch 2787, Loss: 0.0031203809048747644, Final Batch Loss: 3.759578976314515e-05\n",
      "Epoch 2788, Loss: 0.0014627803436724207, Final Batch Loss: 2.2335850644594757e-06\n",
      "Epoch 2789, Loss: 0.0008753577330935514, Final Batch Loss: 1.0659559848136269e-05\n",
      "Epoch 2790, Loss: 0.006188953586388379, Final Batch Loss: 0.00366986240260303\n",
      "Epoch 2791, Loss: 0.007767706039885525, Final Batch Loss: 1.1047675798181444e-05\n",
      "Epoch 2792, Loss: 0.0010912259458564222, Final Batch Loss: 0.00017460540402680635\n",
      "Epoch 2793, Loss: 0.0013035151059739292, Final Batch Loss: 0.00030990105005912483\n",
      "Epoch 2794, Loss: 0.018020582851022482, Final Batch Loss: 0.00042192667024210095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795, Loss: 0.0017920746249728836, Final Batch Loss: 7.632797496626154e-05\n",
      "Epoch 2796, Loss: 0.00831210141768679, Final Batch Loss: 0.0009123102645389736\n",
      "Epoch 2797, Loss: 0.0014823397032159846, Final Batch Loss: 3.5632092476589605e-05\n",
      "Epoch 2798, Loss: 0.0017162027761514764, Final Batch Loss: 5.8765592257259414e-05\n",
      "Epoch 2799, Loss: 0.03401971892117217, Final Batch Loss: 3.858512627630262e-06\n",
      "Epoch 2800, Loss: 0.009389321261551231, Final Batch Loss: 0.0009973951382562518\n",
      "Epoch 2801, Loss: 0.0015498395123358932, Final Batch Loss: 7.672909305256326e-06\n",
      "Epoch 2802, Loss: 0.0018787074031934026, Final Batch Loss: 1.21019502330455e-05\n",
      "Epoch 2803, Loss: 0.007152146289399752, Final Batch Loss: 2.3778782178851543e-06\n",
      "Epoch 2804, Loss: 0.0029860380745958537, Final Batch Loss: 0.0017989134648814797\n",
      "Epoch 2805, Loss: 0.013199993059970438, Final Batch Loss: 0.0006130620604380965\n",
      "Epoch 2806, Loss: 0.004589663119986653, Final Batch Loss: 0.001547741936519742\n",
      "Epoch 2807, Loss: 0.01636423956369981, Final Batch Loss: 0.00011325342347845435\n",
      "Epoch 2808, Loss: 0.001975008035515202, Final Batch Loss: 1.0791518434416503e-06\n",
      "Epoch 2809, Loss: 0.0008261183575086761, Final Batch Loss: 4.032046490465291e-05\n",
      "Epoch 2810, Loss: 0.005634909495711327, Final Batch Loss: 0.0031528433319181204\n",
      "Epoch 2811, Loss: 0.023128429347707424, Final Batch Loss: 0.0004949885769747198\n",
      "Epoch 2812, Loss: 0.0008042122426559217, Final Batch Loss: 6.264483818085864e-05\n",
      "Epoch 2813, Loss: 0.0011981097923126072, Final Batch Loss: 0.0002785760734695941\n",
      "Epoch 2814, Loss: 0.0029643147465776565, Final Batch Loss: 3.2561986245127628e-06\n",
      "Epoch 2815, Loss: 0.011693707943777554, Final Batch Loss: 0.00013929074339102954\n",
      "Epoch 2816, Loss: 0.001935498570674099, Final Batch Loss: 0.0006064123008400202\n",
      "Epoch 2817, Loss: 0.00952242278799531, Final Batch Loss: 2.1399046090664342e-05\n",
      "Epoch 2818, Loss: 0.0014307855599327013, Final Batch Loss: 0.00013315257092472166\n",
      "Epoch 2819, Loss: 0.0018826621121661447, Final Batch Loss: 5.313969722919865e-06\n",
      "Epoch 2820, Loss: 0.0021314194200385828, Final Batch Loss: 4.781438110512681e-05\n",
      "Epoch 2821, Loss: 0.0008003967228091824, Final Batch Loss: 6.399637300091854e-07\n",
      "Epoch 2822, Loss: 0.03044957504607737, Final Batch Loss: 0.0037817053962498903\n",
      "Epoch 2823, Loss: 0.0044650849886238575, Final Batch Loss: 1.6505233361385763e-05\n",
      "Epoch 2824, Loss: 0.0066897242668346735, Final Batch Loss: 2.4382245101151057e-05\n",
      "Epoch 2825, Loss: 0.0022146549199533183, Final Batch Loss: 1.0552135790931061e-05\n",
      "Epoch 2826, Loss: 0.016413159435614944, Final Batch Loss: 0.0011743000941351056\n",
      "Epoch 2827, Loss: 0.0013610046335088555, Final Batch Loss: 4.371314207674004e-05\n",
      "Epoch 2828, Loss: 0.0014461068494711071, Final Batch Loss: 0.0004407039377838373\n",
      "Epoch 2829, Loss: 0.008182191915693693, Final Batch Loss: 4.547146090772003e-05\n",
      "Epoch 2830, Loss: 0.0005487057896971237, Final Batch Loss: 1.8320388335268945e-06\n",
      "Epoch 2831, Loss: 0.007060740936140064, Final Batch Loss: 1.1913558410014957e-05\n",
      "Epoch 2832, Loss: 0.016203105789827532, Final Batch Loss: 7.472122888430022e-06\n",
      "Epoch 2833, Loss: 0.0028521155181806535, Final Batch Loss: 0.0011790997814387083\n",
      "Epoch 2834, Loss: 0.006521151168271899, Final Batch Loss: 0.004997939337044954\n",
      "Epoch 2835, Loss: 0.0019319999410072342, Final Batch Loss: 0.00012205618259031326\n",
      "Epoch 2836, Loss: 0.007598208671510065, Final Batch Loss: 4.015460888240341e-07\n",
      "Epoch 2837, Loss: 0.031180086385575123, Final Batch Loss: 9.2349509941414e-06\n",
      "Epoch 2838, Loss: 0.005085451499326155, Final Batch Loss: 0.00039881907287053764\n",
      "Epoch 2839, Loss: 0.002031047384662088, Final Batch Loss: 0.0014354295562952757\n",
      "Epoch 2840, Loss: 0.0017142537762993015, Final Batch Loss: 5.219763988861814e-05\n",
      "Epoch 2841, Loss: 0.0031203745893435553, Final Batch Loss: 0.0001320953160757199\n",
      "Epoch 2842, Loss: 0.0007777383871143684, Final Batch Loss: 9.294513438362628e-05\n",
      "Epoch 2843, Loss: 0.0006709507142659277, Final Batch Loss: 0.00010585496784187853\n",
      "Epoch 2844, Loss: 0.0013350231165532023, Final Batch Loss: 0.00010134972399100661\n",
      "Epoch 2845, Loss: 0.002627652463207397, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 2846, Loss: 0.0029228101179796795, Final Batch Loss: 5.050590061728144e-06\n",
      "Epoch 2847, Loss: 0.0013541718089982169, Final Batch Loss: 2.1196350644459017e-05\n",
      "Epoch 2848, Loss: 0.002204674980021082, Final Batch Loss: 0.0002458999224472791\n",
      "Epoch 2849, Loss: 0.001967287258594297, Final Batch Loss: 0.00020710662647616118\n",
      "Epoch 2850, Loss: 0.0005199665247346275, Final Batch Loss: 0.00014232816465664655\n",
      "Epoch 2851, Loss: 0.0105642953858478, Final Batch Loss: 0.0007862042402848601\n",
      "Epoch 2852, Loss: 0.02973947940108701, Final Batch Loss: 6.255094831431052e-06\n",
      "Epoch 2853, Loss: 0.0028000434867863078, Final Batch Loss: 3.3615466236369684e-05\n",
      "Epoch 2854, Loss: 0.0011583254381548613, Final Batch Loss: 0.00024080820730887353\n",
      "Epoch 2855, Loss: 0.07975346813327633, Final Batch Loss: 0.07888172566890717\n",
      "Epoch 2856, Loss: 0.004412424488691613, Final Batch Loss: 0.00013845402281731367\n",
      "Epoch 2857, Loss: 0.04762473446317017, Final Batch Loss: 0.043843355029821396\n",
      "Epoch 2858, Loss: 0.013865812215954065, Final Batch Loss: 0.003502616658806801\n",
      "Epoch 2859, Loss: 0.002275163592685203, Final Batch Loss: 6.27417193754809e-08\n",
      "Epoch 2860, Loss: 0.009061013770406134, Final Batch Loss: 0.00015369740140158683\n",
      "Epoch 2861, Loss: 0.009551047391141765, Final Batch Loss: 0.006180705968290567\n",
      "Epoch 2862, Loss: 0.015172991814324632, Final Batch Loss: 0.00046612220467068255\n",
      "Epoch 2863, Loss: 0.016760245185196254, Final Batch Loss: 7.233918495330727e-06\n",
      "Epoch 2864, Loss: 0.0008755513117648661, Final Batch Loss: 0.00030133058317005634\n",
      "Epoch 2865, Loss: 0.002017702558077872, Final Batch Loss: 0.00036317360354587436\n",
      "Epoch 2866, Loss: 0.009093006921830238, Final Batch Loss: 1.8029235434369184e-05\n",
      "Epoch 2867, Loss: 0.0046437920100288466, Final Batch Loss: 6.727415893692523e-05\n",
      "Epoch 2868, Loss: 0.0008331855715368874, Final Batch Loss: 8.825383702060208e-05\n",
      "Epoch 2869, Loss: 0.004803543590242043, Final Batch Loss: 0.0015952471876516938\n",
      "Epoch 2870, Loss: 0.07658374750462826, Final Batch Loss: 0.07561009377241135\n",
      "Epoch 2871, Loss: 0.011791124146839138, Final Batch Loss: 7.523132808273658e-05\n",
      "Epoch 2872, Loss: 0.0026951522449962795, Final Batch Loss: 3.793332143686712e-05\n",
      "Epoch 2873, Loss: 0.006732593625201844, Final Batch Loss: 2.4698631023056805e-05\n",
      "Epoch 2874, Loss: 0.002572021199739538, Final Batch Loss: 1.9164217519573867e-05\n",
      "Epoch 2875, Loss: 0.003336075951665407, Final Batch Loss: 3.598685361794196e-05\n",
      "Epoch 2876, Loss: 0.0033011919585987926, Final Batch Loss: 0.00027916047838516533\n",
      "Epoch 2877, Loss: 0.032260168343782425, Final Batch Loss: 0.031433820724487305\n",
      "Epoch 2878, Loss: 0.0031146802939474583, Final Batch Loss: 0.002130692359060049\n",
      "Epoch 2879, Loss: 0.015589774975921955, Final Batch Loss: 8.721075914763787e-07\n",
      "Epoch 2880, Loss: 0.004165247082710266, Final Batch Loss: 0.002625291468575597\n",
      "Epoch 2881, Loss: 0.0009473189566051587, Final Batch Loss: 0.0002125454630004242\n",
      "Epoch 2882, Loss: 0.011766731549869291, Final Batch Loss: 0.0002350215072510764\n",
      "Epoch 2883, Loss: 0.0034336933204031084, Final Batch Loss: 2.9008722776779905e-05\n",
      "Epoch 2884, Loss: 0.007593192087369971, Final Batch Loss: 5.81571803195402e-05\n",
      "Epoch 2885, Loss: 0.0041566605141269974, Final Batch Loss: 0.0006837156834080815\n",
      "Epoch 2886, Loss: 0.00048576495828456245, Final Batch Loss: 4.203901698929258e-05\n",
      "Epoch 2887, Loss: 0.00275150641533628, Final Batch Loss: 5.270281349112338e-07\n",
      "Epoch 2888, Loss: 0.0010680073228286346, Final Batch Loss: 1.8658500266610645e-05\n",
      "Epoch 2889, Loss: 0.08704348909668624, Final Batch Loss: 0.08514206856489182\n",
      "Epoch 2890, Loss: 0.005848640852946119, Final Batch Loss: 3.858571744785877e-06\n",
      "Epoch 2891, Loss: 0.006358090478897793, Final Batch Loss: 2.0740943000419065e-05\n",
      "Epoch 2892, Loss: 0.030735131167602958, Final Batch Loss: 1.3388507795752957e-05\n",
      "Epoch 2893, Loss: 0.07037135073915124, Final Batch Loss: 0.05702025070786476\n",
      "Epoch 2894, Loss: 0.017948131104731146, Final Batch Loss: 4.7305643420259e-06\n",
      "Epoch 2895, Loss: 0.0007186772563727573, Final Batch Loss: 0.00015439656272064894\n",
      "Epoch 2896, Loss: 0.032222948502749205, Final Batch Loss: 0.0236729197204113\n",
      "Epoch 2897, Loss: 0.0018682098249200862, Final Batch Loss: 4.6428760924754897e-07\n",
      "Epoch 2898, Loss: 0.024789467731807235, Final Batch Loss: 4.63015157947666e-06\n",
      "Epoch 2899, Loss: 0.15511146769858897, Final Batch Loss: 0.15127821266651154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2900, Loss: 0.006774648034479469, Final Batch Loss: 0.0006696570198982954\n",
      "Epoch 2901, Loss: 0.00422035836163559, Final Batch Loss: 4.0718769014347345e-06\n",
      "Epoch 2902, Loss: 0.042941173538565636, Final Batch Loss: 0.019267728552222252\n",
      "Epoch 2903, Loss: 0.04373926895823388, Final Batch Loss: 2.039067112491466e-06\n",
      "Epoch 2904, Loss: 0.00892644000123255, Final Batch Loss: 0.0004034297016914934\n",
      "Epoch 2905, Loss: 0.0008011963072931394, Final Batch Loss: 0.00033125330810435116\n",
      "Epoch 2906, Loss: 0.0019014953022633563, Final Batch Loss: 1.2679508472501766e-05\n",
      "Epoch 2907, Loss: 0.0012380719126667827, Final Batch Loss: 0.0006489905063062906\n",
      "Epoch 2908, Loss: 0.007992449816811131, Final Batch Loss: 4.5619224692927673e-05\n",
      "Epoch 2909, Loss: 0.004590243304846808, Final Batch Loss: 0.0035584138240665197\n",
      "Epoch 2910, Loss: 0.03907788154128866, Final Batch Loss: 3.268759883212624e-06\n",
      "Epoch 2911, Loss: 0.0024653767115836445, Final Batch Loss: 6.274170516462618e-08\n",
      "Epoch 2912, Loss: 0.0231677343526826, Final Batch Loss: 1.6474905351060443e-05\n",
      "Epoch 2913, Loss: 0.009043024487823459, Final Batch Loss: 1.254824951502087e-06\n",
      "Epoch 2914, Loss: 0.00372667587930664, Final Batch Loss: 4.140949840802932e-07\n",
      "Epoch 2915, Loss: 0.019837131748658976, Final Batch Loss: 4.705610763267032e-07\n",
      "Epoch 2916, Loss: 0.001596589820110239, Final Batch Loss: 6.1860919231548905e-06\n",
      "Epoch 2917, Loss: 0.001830214969231747, Final Batch Loss: 0.00016304074961226434\n",
      "Epoch 2918, Loss: 0.01664074986547348, Final Batch Loss: 4.571523822960444e-05\n",
      "Epoch 2919, Loss: 0.006718906690366566, Final Batch Loss: 0.0010977763449773192\n",
      "Epoch 2920, Loss: 0.0009652080152591225, Final Batch Loss: 7.089573045959696e-06\n",
      "Epoch 2921, Loss: 0.0029344703652895987, Final Batch Loss: 0.0009615078452043235\n",
      "Epoch 2922, Loss: 0.0013056249736109748, Final Batch Loss: 0.00014885618293192238\n",
      "Epoch 2923, Loss: 0.0025743894366314635, Final Batch Loss: 0.001841437304392457\n",
      "Epoch 2924, Loss: 0.001028038706863299, Final Batch Loss: 0.00012209557462483644\n",
      "Epoch 2925, Loss: 0.001972990154172294, Final Batch Loss: 0.00038601248525083065\n",
      "Epoch 2926, Loss: 0.0014246750088204863, Final Batch Loss: 3.620154529926367e-06\n",
      "Epoch 2927, Loss: 0.004212302737641949, Final Batch Loss: 2.195941988247796e-06\n",
      "Epoch 2928, Loss: 0.0035665621544467285, Final Batch Loss: 0.00018221822392661124\n",
      "Epoch 2929, Loss: 0.017598207748960704, Final Batch Loss: 0.0005973188090138137\n",
      "Epoch 2930, Loss: 0.00314107806480024, Final Batch Loss: 2.004230918828398e-05\n",
      "Epoch 2931, Loss: 0.002576330069132382, Final Batch Loss: 5.234007039689459e-05\n",
      "Epoch 2932, Loss: 0.004003342590294778, Final Batch Loss: 0.00023662392050027847\n",
      "Epoch 2933, Loss: 0.006906559749040753, Final Batch Loss: 0.000592355674598366\n",
      "Epoch 2934, Loss: 0.0025151879162876867, Final Batch Loss: 0.00010606939758872613\n",
      "Epoch 2935, Loss: 0.012333890839727246, Final Batch Loss: 2.7739102733903565e-05\n",
      "Epoch 2936, Loss: 0.0041157121249852935, Final Batch Loss: 1.6223983038798906e-05\n",
      "Epoch 2937, Loss: 0.0146323694405055, Final Batch Loss: 1.4618760815210408e-06\n",
      "Epoch 2938, Loss: 0.0013952706794952974, Final Batch Loss: 0.00013869607937522233\n",
      "Epoch 2939, Loss: 0.0029936087084934115, Final Batch Loss: 0.002227687044069171\n",
      "Epoch 2940, Loss: 0.001815457409065857, Final Batch Loss: 8.795689609542023e-06\n",
      "Epoch 2941, Loss: 0.004677934746723622, Final Batch Loss: 0.00016999151557683945\n",
      "Epoch 2942, Loss: 0.0030086348560871556, Final Batch Loss: 9.042468445841223e-05\n",
      "Epoch 2943, Loss: 0.014504918013699353, Final Batch Loss: 0.012828010134398937\n",
      "Epoch 2944, Loss: 0.00499537451037213, Final Batch Loss: 2.4594257865828695e-06\n",
      "Epoch 2945, Loss: 0.009239231745596044, Final Batch Loss: 0.00011878057557623833\n",
      "Epoch 2946, Loss: 0.004568232776364312, Final Batch Loss: 0.00038081014645285904\n",
      "Epoch 2947, Loss: 0.0034809188509825617, Final Batch Loss: 0.0002572817320469767\n",
      "Epoch 2948, Loss: 0.007107991870725527, Final Batch Loss: 0.00032024914980866015\n",
      "Epoch 2949, Loss: 0.004175565278274007, Final Batch Loss: 4.117995558772236e-05\n",
      "Epoch 2950, Loss: 0.005263462102448102, Final Batch Loss: 6.0103680880274624e-05\n",
      "Epoch 2951, Loss: 0.0036813478218391538, Final Batch Loss: 0.0002815522311720997\n",
      "Epoch 2952, Loss: 0.006183321122080088, Final Batch Loss: 0.0001581599935889244\n",
      "Epoch 2953, Loss: 0.0027817388181574643, Final Batch Loss: 0.0009774506324902177\n",
      "Epoch 2954, Loss: 0.017147956446933676, Final Batch Loss: 1.545789018564392e-05\n",
      "Epoch 2955, Loss: 0.00476671033538878, Final Batch Loss: 0.0036693508736789227\n",
      "Epoch 2956, Loss: 0.006940257109818049, Final Batch Loss: 2.8775728424079716e-05\n",
      "Epoch 2957, Loss: 0.002726161837927066, Final Batch Loss: 6.469663640018553e-05\n",
      "Epoch 2958, Loss: 0.00591426579921972, Final Batch Loss: 4.659737169276923e-05\n",
      "Epoch 2959, Loss: 0.004126371662096062, Final Batch Loss: 1.000679094431689e-05\n",
      "Epoch 2960, Loss: 0.001359847149444704, Final Batch Loss: 5.019326749788888e-07\n",
      "Epoch 2961, Loss: 0.012908060773042962, Final Batch Loss: 0.00016718072583898902\n",
      "Epoch 2962, Loss: 0.011911830282770097, Final Batch Loss: 0.0018543354235589504\n",
      "Epoch 2963, Loss: 0.0016042712959460914, Final Batch Loss: 0.00027025712188333273\n",
      "Epoch 2964, Loss: 0.004068443085891715, Final Batch Loss: 1.1920918296937089e-07\n",
      "Epoch 2965, Loss: 0.003200682025635615, Final Batch Loss: 0.00029558510868810117\n",
      "Epoch 2966, Loss: 0.0029655542930413503, Final Batch Loss: 5.3635671065421775e-05\n",
      "Epoch 2967, Loss: 0.01481751020764932, Final Batch Loss: 0.013319439254701138\n",
      "Epoch 2968, Loss: 0.03490767383482307, Final Batch Loss: 0.0015775338979437947\n",
      "Epoch 2969, Loss: 0.0026649936771718785, Final Batch Loss: 0.00014023719995748252\n",
      "Epoch 2970, Loss: 0.004076170327607542, Final Batch Loss: 0.000103814119938761\n",
      "Epoch 2971, Loss: 0.0037597726734475145, Final Batch Loss: 1.166987431133748e-06\n",
      "Epoch 2972, Loss: 0.0010667891619959846, Final Batch Loss: 2.481094270478934e-05\n",
      "Epoch 2973, Loss: 0.0037276782659318997, Final Batch Loss: 1.0646819646353833e-05\n",
      "Epoch 2974, Loss: 0.0025398371190021862, Final Batch Loss: 6.248706085898448e-06\n",
      "Epoch 2975, Loss: 0.0008127227192744613, Final Batch Loss: 0.0002591608790680766\n",
      "Epoch 2976, Loss: 0.0020527240267256275, Final Batch Loss: 2.8841415769420564e-05\n",
      "Epoch 2977, Loss: 0.0006012287749399547, Final Batch Loss: 1.5226302821247373e-05\n",
      "Epoch 2978, Loss: 0.006751500477548689, Final Batch Loss: 0.005019854288548231\n",
      "Epoch 2979, Loss: 0.0025404759790035314, Final Batch Loss: 4.366737812233623e-06\n",
      "Epoch 2980, Loss: 0.0025095690725720488, Final Batch Loss: 0.00010682615538826212\n",
      "Epoch 2981, Loss: 0.00506548825342179, Final Batch Loss: 1.4755732081539463e-05\n",
      "Epoch 2982, Loss: 0.002866801354684867, Final Batch Loss: 0.0019601660314947367\n",
      "Epoch 2983, Loss: 0.0011491075420053676, Final Batch Loss: 0.00018017773982137442\n",
      "Epoch 2984, Loss: 0.004280023018509382, Final Batch Loss: 5.172516466700472e-05\n",
      "Epoch 2985, Loss: 0.0023563687473142636, Final Batch Loss: 5.2638833949458785e-06\n",
      "Epoch 2986, Loss: 0.009999991740187397, Final Batch Loss: 1.6919206245802343e-05\n",
      "Epoch 2987, Loss: 0.004058693768456578, Final Batch Loss: 0.00225116778165102\n",
      "Epoch 2988, Loss: 0.0022591281922359485, Final Batch Loss: 7.2024013206828386e-06\n",
      "Epoch 2989, Loss: 0.003086476467160537, Final Batch Loss: 7.1084327828430105e-06\n",
      "Epoch 2990, Loss: 0.001767291974829277, Final Batch Loss: 6.863698217784986e-06\n",
      "Epoch 2991, Loss: 0.0008886537743819645, Final Batch Loss: 8.331820936291479e-06\n",
      "Epoch 2992, Loss: 0.0031050044344738126, Final Batch Loss: 0.0003015522379428148\n",
      "Epoch 2993, Loss: 0.0018648948152986122, Final Batch Loss: 1.681397952779662e-05\n",
      "Epoch 2994, Loss: 0.0011609725843300112, Final Batch Loss: 0.0002199945447500795\n",
      "Epoch 2995, Loss: 0.0017452468164265156, Final Batch Loss: 0.001006405334919691\n",
      "Epoch 2996, Loss: 0.0032257384445983917, Final Batch Loss: 8.702889317646623e-05\n",
      "Epoch 2997, Loss: 0.002712046873057261, Final Batch Loss: 0.0009471264202147722\n",
      "Epoch 2998, Loss: 0.0008138773810060229, Final Batch Loss: 5.35151302756276e-05\n",
      "Epoch 2999, Loss: 0.005923267526668496, Final Batch Loss: 0.005021205171942711\n",
      "Epoch 3000, Loss: 0.0006868350276363344, Final Batch Loss: 8.407325822190614e-07\n",
      "Epoch 3001, Loss: 0.020690465113148093, Final Batch Loss: 0.006425941362977028\n",
      "Epoch 3002, Loss: 0.003998566680820659, Final Batch Loss: 0.00015019314014352858\n",
      "Epoch 3003, Loss: 0.001732472968797083, Final Batch Loss: 1.0358167855883949e-05\n",
      "Epoch 3004, Loss: 0.0015035313344924361, Final Batch Loss: 5.941409654042218e-06\n",
      "Epoch 3005, Loss: 0.0008926561225734986, Final Batch Loss: 9.975868806577637e-07\n",
      "Epoch 3006, Loss: 0.004028755798572092, Final Batch Loss: 2.785008655337151e-05\n",
      "Epoch 3007, Loss: 0.02360074353055097, Final Batch Loss: 0.02202635444700718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3008, Loss: 0.0035255852264981513, Final Batch Loss: 1.041508994603646e-06\n",
      "Epoch 3009, Loss: 0.0046687375725014135, Final Batch Loss: 0.00019794276158791035\n",
      "Epoch 3010, Loss: 0.010660689433279913, Final Batch Loss: 5.6596465583425015e-05\n",
      "Epoch 3011, Loss: 0.001603329204954207, Final Batch Loss: 0.000120213080663234\n",
      "Epoch 3012, Loss: 0.0012481300036597531, Final Batch Loss: 2.8138918423792347e-05\n",
      "Epoch 3013, Loss: 0.0029104201657901285, Final Batch Loss: 2.5472963898209855e-06\n",
      "Epoch 3014, Loss: 0.0011447780998423696, Final Batch Loss: 0.0002701167541090399\n",
      "Epoch 3015, Loss: 0.0008972496216301806, Final Batch Loss: 0.000420938478782773\n",
      "Epoch 3016, Loss: 0.004050751973409206, Final Batch Loss: 0.0020974737126380205\n",
      "Epoch 3017, Loss: 0.0015852003562031314, Final Batch Loss: 0.00018882831500377506\n",
      "Epoch 3018, Loss: 0.0005073033799476434, Final Batch Loss: 7.968165505189972e-07\n",
      "Epoch 3019, Loss: 0.0014261128526413813, Final Batch Loss: 0.00011692404223140329\n",
      "Epoch 3020, Loss: 0.0019241316667830688, Final Batch Loss: 9.737113032315392e-06\n",
      "Epoch 3021, Loss: 0.0005454702295537572, Final Batch Loss: 1.7315225704805925e-05\n",
      "Epoch 3022, Loss: 0.0029196381929068593, Final Batch Loss: 1.8437143808114342e-05\n",
      "Epoch 3023, Loss: 0.0009834077659434115, Final Batch Loss: 5.954048447165405e-06\n",
      "Epoch 3024, Loss: 0.0008663331536808982, Final Batch Loss: 0.00018450965580996126\n",
      "Epoch 3025, Loss: 0.007866859414207283, Final Batch Loss: 4.564380651572719e-05\n",
      "Epoch 3026, Loss: 0.005699035042198375, Final Batch Loss: 0.004638289101421833\n",
      "Epoch 3027, Loss: 0.003472863172646612, Final Batch Loss: 0.001136285369284451\n",
      "Epoch 3028, Loss: 0.002083483910666928, Final Batch Loss: 4.454651048035885e-07\n",
      "Epoch 3029, Loss: 0.002068892457828042, Final Batch Loss: 2.8315802410361357e-05\n",
      "Epoch 3030, Loss: 0.0009126917066168971, Final Batch Loss: 0.00037130468990653753\n",
      "Epoch 3031, Loss: 0.0010384675690886525, Final Batch Loss: 3.5762721495302685e-07\n",
      "Epoch 3032, Loss: 0.0019618190635810606, Final Batch Loss: 3.7456054997164756e-05\n",
      "Epoch 3033, Loss: 0.0030213157297112048, Final Batch Loss: 0.0005939881666563451\n",
      "Epoch 3034, Loss: 0.0017779507420527807, Final Batch Loss: 4.824667939828942e-06\n",
      "Epoch 3035, Loss: 0.001902338375657564, Final Batch Loss: 5.179167419555597e-05\n",
      "Epoch 3036, Loss: 0.015326447096271067, Final Batch Loss: 3.0743362344765046e-07\n",
      "Epoch 3037, Loss: 0.000773750802181894, Final Batch Loss: 9.053303074324504e-06\n",
      "Epoch 3038, Loss: 0.0005181786000321154, Final Batch Loss: 5.826969936606474e-05\n",
      "Epoch 3039, Loss: 0.0006494047394767222, Final Batch Loss: 1.9449925048320438e-07\n",
      "Epoch 3040, Loss: 0.0010549060098128393, Final Batch Loss: 0.000370152440154925\n",
      "Epoch 3041, Loss: 0.0006527242949232459, Final Batch Loss: 0.00020878019859082997\n",
      "Epoch 3042, Loss: 0.008452242414932698, Final Batch Loss: 0.00019401469035074115\n",
      "Epoch 3043, Loss: 0.0012916284161974545, Final Batch Loss: 1.311286155214475e-06\n",
      "Epoch 3044, Loss: 0.002366741180594545, Final Batch Loss: 2.7417576347943395e-05\n",
      "Epoch 3045, Loss: 0.001792478738934733, Final Batch Loss: 0.0002334829914616421\n",
      "Epoch 3046, Loss: 0.001690085524899132, Final Batch Loss: 5.395764333115949e-07\n",
      "Epoch 3047, Loss: 0.003810961881754338, Final Batch Loss: 1.2585229342221282e-05\n",
      "Epoch 3048, Loss: 0.0017825888135121204, Final Batch Loss: 6.539622700074688e-05\n",
      "Epoch 3049, Loss: 0.0011636832995236546, Final Batch Loss: 7.466213673978928e-07\n",
      "Epoch 3050, Loss: 0.0028734025690937415, Final Batch Loss: 0.002348891692236066\n",
      "Epoch 3051, Loss: 0.0006874492464703508, Final Batch Loss: 9.561409387970343e-05\n",
      "Epoch 3052, Loss: 0.008097681918115995, Final Batch Loss: 4.297707164369058e-06\n",
      "Epoch 3053, Loss: 0.0007256214139488293, Final Batch Loss: 1.8624761651153676e-05\n",
      "Epoch 3054, Loss: 0.001606320825203511, Final Batch Loss: 7.842693321435945e-07\n",
      "Epoch 3055, Loss: 0.002420616203380632, Final Batch Loss: 8.808578058960848e-06\n",
      "Epoch 3056, Loss: 0.004293859121389687, Final Batch Loss: 0.0007236578967422247\n",
      "Epoch 3057, Loss: 0.0035673886886797845, Final Batch Loss: 0.00014524109428748488\n",
      "Epoch 3058, Loss: 0.03905726985249203, Final Batch Loss: 4.716469265986234e-05\n",
      "Epoch 3059, Loss: 0.001956829975824803, Final Batch Loss: 0.0002090519410558045\n",
      "Epoch 3060, Loss: 0.00047032313887029886, Final Batch Loss: 6.543805648107082e-05\n",
      "Epoch 3061, Loss: 0.020534287847112864, Final Batch Loss: 0.0025515607558190823\n",
      "Epoch 3062, Loss: 0.0015331588219851255, Final Batch Loss: 0.0005041502299718559\n",
      "Epoch 3063, Loss: 0.11605899693677202, Final Batch Loss: 0.11424502730369568\n",
      "Epoch 3064, Loss: 0.0008861815255727379, Final Batch Loss: 5.897706500945787e-07\n",
      "Epoch 3065, Loss: 0.00377365956956055, Final Batch Loss: 0.00016282311116810888\n",
      "Epoch 3066, Loss: 0.010859223875741009, Final Batch Loss: 1.6505691746715456e-05\n",
      "Epoch 3067, Loss: 0.004773060558363795, Final Batch Loss: 0.002467624144628644\n",
      "Epoch 3068, Loss: 0.005047086751801544, Final Batch Loss: 6.637894330197014e-06\n",
      "Epoch 3069, Loss: 0.0042114555391776776, Final Batch Loss: 5.58399904093676e-07\n",
      "Epoch 3070, Loss: 0.002049677302920827, Final Batch Loss: 3.6639937661675503e-06\n",
      "Epoch 3071, Loss: 0.011725618162017781, Final Batch Loss: 4.206237645121291e-05\n",
      "Epoch 3072, Loss: 0.0026260018639732152, Final Batch Loss: 5.3665804443880916e-05\n",
      "Epoch 3073, Loss: 0.0017140454292530194, Final Batch Loss: 0.00021950337395537645\n",
      "Epoch 3074, Loss: 0.015435902891667297, Final Batch Loss: 2.2586992542983353e-07\n",
      "Epoch 3075, Loss: 0.0036161378666292876, Final Batch Loss: 0.002052049385383725\n",
      "Epoch 3076, Loss: 0.002111770496412646, Final Batch Loss: 4.432093555806205e-05\n",
      "Epoch 3077, Loss: 0.0028983936936128885, Final Batch Loss: 0.00019098276970908046\n",
      "Epoch 3078, Loss: 0.0018786103543106947, Final Batch Loss: 3.82723214897851e-07\n",
      "Epoch 3079, Loss: 0.0015606148008373566, Final Batch Loss: 8.870563033269718e-05\n",
      "Epoch 3080, Loss: 0.010973561307764612, Final Batch Loss: 0.00016876192239578813\n",
      "Epoch 3081, Loss: 0.0016086992261818978, Final Batch Loss: 8.156419539773196e-08\n",
      "Epoch 3082, Loss: 0.0010200746692134999, Final Batch Loss: 0.0005100544658489525\n",
      "Epoch 3083, Loss: 0.0009532979499908834, Final Batch Loss: 3.017809603989008e-06\n",
      "Epoch 3084, Loss: 0.0007681154093006626, Final Batch Loss: 0.0004055675526615232\n",
      "Epoch 3085, Loss: 0.0020776067103724927, Final Batch Loss: 0.001590288826264441\n",
      "Epoch 3086, Loss: 0.0037139057531021535, Final Batch Loss: 8.931313641369343e-05\n",
      "Epoch 3087, Loss: 0.001589313120348379, Final Batch Loss: 7.548312714789063e-05\n",
      "Epoch 3088, Loss: 0.005492519019753672, Final Batch Loss: 0.0002032245247391984\n",
      "Epoch 3089, Loss: 0.002062257280272206, Final Batch Loss: 1.179537434836675e-06\n",
      "Epoch 3090, Loss: 0.0004881293652374552, Final Batch Loss: 9.160220884041337e-07\n",
      "Epoch 3091, Loss: 0.005627608757095004, Final Batch Loss: 4.6552313506253995e-06\n",
      "Epoch 3092, Loss: 0.00035952946200268343, Final Batch Loss: 1.2622716894838959e-05\n",
      "Epoch 3093, Loss: 0.0033272402361035347, Final Batch Loss: 0.0017805735114961863\n",
      "Epoch 3094, Loss: 0.002780388400424272, Final Batch Loss: 0.0003172167926095426\n",
      "Epoch 3095, Loss: 0.004678666518884711, Final Batch Loss: 0.00135985913220793\n",
      "Epoch 3096, Loss: 0.003552741418388905, Final Batch Loss: 2.11836195376236e-05\n",
      "Epoch 3097, Loss: 0.004271662735845894, Final Batch Loss: 0.0009255190379917622\n",
      "Epoch 3098, Loss: 0.0017272724362555891, Final Batch Loss: 0.0006110803224146366\n",
      "Epoch 3099, Loss: 0.0025584317263565026, Final Batch Loss: 7.130883022909984e-05\n",
      "Epoch 3100, Loss: 0.000610681097896304, Final Batch Loss: 4.2104678868781775e-05\n",
      "Epoch 3101, Loss: 0.006699112719616096, Final Batch Loss: 6.989003850321751e-06\n",
      "Epoch 3102, Loss: 0.008570911682909355, Final Batch Loss: 0.007725123316049576\n",
      "Epoch 3103, Loss: 0.0005158444469657297, Final Batch Loss: 8.721031576897076e-07\n",
      "Epoch 3104, Loss: 0.0006734425942340749, Final Batch Loss: 1.0828759513969999e-05\n",
      "Epoch 3105, Loss: 0.0010012015409301966, Final Batch Loss: 0.00016555657202843577\n",
      "Epoch 3106, Loss: 0.0012262751006346662, Final Batch Loss: 4.404916035127826e-05\n",
      "Epoch 3107, Loss: 0.0008059944329943391, Final Batch Loss: 3.889926119882148e-06\n",
      "Epoch 3108, Loss: 0.0008740886094074085, Final Batch Loss: 2.697835725484765e-06\n",
      "Epoch 3109, Loss: 0.020781801227713004, Final Batch Loss: 0.019930951297283173\n",
      "Epoch 3110, Loss: 0.0008859870376909385, Final Batch Loss: 1.6818865333334543e-05\n",
      "Epoch 3111, Loss: 0.024641624237119686, Final Batch Loss: 0.02406199276447296\n",
      "Epoch 3112, Loss: 0.0008878637818270363, Final Batch Loss: 0.00016955018509179354\n",
      "Epoch 3113, Loss: 0.0030087757186265662, Final Batch Loss: 7.433544669765979e-05\n",
      "Epoch 3114, Loss: 0.0009938644943758845, Final Batch Loss: 0.00010973503231070936\n",
      "Epoch 3115, Loss: 0.002767352001683321, Final Batch Loss: 9.272909665014595e-06\n",
      "Epoch 3116, Loss: 0.020818529243115336, Final Batch Loss: 0.0007654119399376214\n",
      "Epoch 3117, Loss: 0.004966344554304669, Final Batch Loss: 1.3186990145186428e-05\n",
      "Epoch 3118, Loss: 0.009438739507459104, Final Batch Loss: 0.004322878085076809\n",
      "Epoch 3119, Loss: 0.0010807496755660395, Final Batch Loss: 1.1543862456164788e-05\n",
      "Epoch 3120, Loss: 0.02031182158680167, Final Batch Loss: 0.018438104540109634\n",
      "Epoch 3121, Loss: 0.0031473777489736676, Final Batch Loss: 0.00019190323655493557\n",
      "Epoch 3122, Loss: 0.00048564715689281, Final Batch Loss: 9.553775453241542e-05\n",
      "Epoch 3123, Loss: 0.0011215927406738047, Final Batch Loss: 5.963621151749976e-05\n",
      "Epoch 3124, Loss: 0.003457151495240396, Final Batch Loss: 5.581267396337353e-05\n",
      "Epoch 3125, Loss: 0.0019529014243744314, Final Batch Loss: 0.00039060754352249205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3126, Loss: 0.00047963798783712264, Final Batch Loss: 3.645219067038852e-06\n",
      "Epoch 3127, Loss: 0.0020019646326545626, Final Batch Loss: 0.0008456954965367913\n",
      "Epoch 3128, Loss: 0.0006114994248491712, Final Batch Loss: 7.536613702541217e-05\n",
      "Epoch 3129, Loss: 0.0010437393051461186, Final Batch Loss: 1.5810786635483964e-06\n",
      "Epoch 3130, Loss: 0.0025164025455524097, Final Batch Loss: 1.2390056326694321e-05\n",
      "Epoch 3131, Loss: 0.0005520695726772828, Final Batch Loss: 6.562610451510409e-06\n",
      "Epoch 3132, Loss: 0.005384590989706339, Final Batch Loss: 4.493496453505941e-05\n",
      "Epoch 3133, Loss: 0.0005455643126026644, Final Batch Loss: 1.6312824868691678e-07\n",
      "Epoch 3134, Loss: 0.0017574382976022207, Final Batch Loss: 8.783837301962194e-08\n",
      "Epoch 3135, Loss: 0.0016376947169192135, Final Batch Loss: 2.2087479010224342e-05\n",
      "Epoch 3136, Loss: 0.001982386373583722, Final Batch Loss: 4.56742827736889e-06\n",
      "Epoch 3137, Loss: 0.0008008448130567558, Final Batch Loss: 0.000410756329074502\n",
      "Epoch 3138, Loss: 0.0015336039206452767, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 3139, Loss: 0.0013780080395093819, Final Batch Loss: 1.7567673182838917e-07\n",
      "Epoch 3140, Loss: 0.006751990626071347, Final Batch Loss: 5.378909918363206e-05\n",
      "Epoch 3141, Loss: 0.008906102222681511, Final Batch Loss: 8.251597319031134e-05\n",
      "Epoch 3142, Loss: 0.010032477497588843, Final Batch Loss: 0.001738814520649612\n",
      "Epoch 3143, Loss: 0.01612622606626246, Final Batch Loss: 0.00012647717085201293\n",
      "Epoch 3144, Loss: 0.008203881996450946, Final Batch Loss: 0.00030267363763414323\n",
      "Epoch 3145, Loss: 0.005033143490436487, Final Batch Loss: 0.0023061027750372887\n",
      "Epoch 3146, Loss: 0.0022602669487241656, Final Batch Loss: 7.628616731381044e-05\n",
      "Epoch 3147, Loss: 0.0025231040459630094, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 3148, Loss: 0.0014708012204209808, Final Batch Loss: 1.2284428521525115e-05\n",
      "Epoch 3149, Loss: 0.000990508823804248, Final Batch Loss: 6.085912787057168e-07\n",
      "Epoch 3150, Loss: 0.0021995290007907897, Final Batch Loss: 4.51094820164144e-06\n",
      "Epoch 3151, Loss: 0.012732796040836547, Final Batch Loss: 1.116791281674523e-06\n",
      "Epoch 3152, Loss: 0.0010647553717717528, Final Batch Loss: 0.00023230946680996567\n",
      "Epoch 3153, Loss: 0.00030006250426595216, Final Batch Loss: 5.364160188037204e-06\n",
      "Epoch 3154, Loss: 0.0003295081260148436, Final Batch Loss: 4.6033910621190444e-05\n",
      "Epoch 3155, Loss: 0.0005841751717525767, Final Batch Loss: 1.2967126167495735e-05\n",
      "Epoch 3156, Loss: 0.027917818442801945, Final Batch Loss: 0.016728952527046204\n",
      "Epoch 3157, Loss: 0.02984492148971185, Final Batch Loss: 0.017249638214707375\n",
      "Epoch 3158, Loss: 0.0007998820774908211, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 3159, Loss: 0.0017508991586510092, Final Batch Loss: 0.0005025937571190298\n",
      "Epoch 3160, Loss: 0.00118296478171942, Final Batch Loss: 1.9700789835042087e-06\n",
      "Epoch 3161, Loss: 0.0011135660315630957, Final Batch Loss: 0.0006313918274827302\n",
      "Epoch 3162, Loss: 0.0012467061751522124, Final Batch Loss: 0.00013391266111284494\n",
      "Epoch 3163, Loss: 0.0018675843348319177, Final Batch Loss: 3.750843825400807e-05\n",
      "Epoch 3164, Loss: 0.00303061114391312, Final Batch Loss: 0.0008469857275485992\n",
      "Epoch 3165, Loss: 0.0009777172235772014, Final Batch Loss: 0.00020240110461600125\n",
      "Epoch 3166, Loss: 0.0029200730761829163, Final Batch Loss: 4.3291694851177454e-07\n",
      "Epoch 3167, Loss: 0.0029271213539914243, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 3168, Loss: 0.0004225326410960406, Final Batch Loss: 0.0\n",
      "Epoch 3169, Loss: 0.004128444767957262, Final Batch Loss: 8.243837328336667e-06\n",
      "Epoch 3170, Loss: 0.0004742143355542794, Final Batch Loss: 1.9535698811523616e-05\n",
      "Epoch 3171, Loss: 0.003163478895658045, Final Batch Loss: 2.542529364291113e-05\n",
      "Epoch 3172, Loss: 0.00028101058796892175, Final Batch Loss: 4.7369076128234155e-06\n",
      "Epoch 3173, Loss: 0.0020734420613734983, Final Batch Loss: 8.814640750642866e-06\n",
      "Epoch 3174, Loss: 0.0010083780289278366, Final Batch Loss: 8.604270260548219e-05\n",
      "Epoch 3175, Loss: 0.0027639259624265833, Final Batch Loss: 2.3286047508008778e-05\n",
      "Epoch 3176, Loss: 0.0036178482114337385, Final Batch Loss: 0.0005423960974439979\n",
      "Epoch 3177, Loss: 0.001123068206197786, Final Batch Loss: 7.277990334841888e-07\n",
      "Epoch 3178, Loss: 0.0010404836539237294, Final Batch Loss: 5.5712916946504265e-06\n",
      "Epoch 3179, Loss: 0.0009859499735398458, Final Batch Loss: 8.72107477789541e-07\n",
      "Epoch 3180, Loss: 0.00017048666134167334, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3181, Loss: 0.0021255702140479116, Final Batch Loss: 2.0619436327251606e-05\n",
      "Epoch 3182, Loss: 0.002380036596150603, Final Batch Loss: 0.00026592789799906313\n",
      "Epoch 3183, Loss: 0.0019901434630611448, Final Batch Loss: 1.7567670340667974e-07\n",
      "Epoch 3184, Loss: 0.001100962697819341, Final Batch Loss: 0.00011531951167853549\n",
      "Epoch 3185, Loss: 0.024768827972721397, Final Batch Loss: 1.254833392749788e-07\n",
      "Epoch 3186, Loss: 0.0007172998599713765, Final Batch Loss: 2.0077335705082078e-07\n",
      "Epoch 3187, Loss: 0.003010063262991025, Final Batch Loss: 1.9324270397191867e-06\n",
      "Epoch 3188, Loss: 0.014219278109521838, Final Batch Loss: 0.014078850857913494\n",
      "Epoch 3189, Loss: 0.005377314702144531, Final Batch Loss: 3.8272375491033017e-07\n",
      "Epoch 3190, Loss: 0.001022486321744509, Final Batch Loss: 7.114533218555152e-06\n",
      "Epoch 3191, Loss: 0.006750221873517148, Final Batch Loss: 4.185181751381606e-05\n",
      "Epoch 3192, Loss: 0.004437724076524319, Final Batch Loss: 9.17242778086802e-06\n",
      "Epoch 3193, Loss: 0.022593470057472587, Final Batch Loss: 0.00037511304253712296\n",
      "Epoch 3194, Loss: 0.0018654643645277247, Final Batch Loss: 0.0001917372428579256\n",
      "Epoch 3195, Loss: 0.0005852305475855246, Final Batch Loss: 0.00015880781575106084\n",
      "Epoch 3196, Loss: 0.0014932971962480224, Final Batch Loss: 1.0791472959681414e-06\n",
      "Epoch 3197, Loss: 0.0004981247666080435, Final Batch Loss: 1.317575595294329e-07\n",
      "Epoch 3198, Loss: 0.0014256404507442255, Final Batch Loss: 3.137085613502677e-08\n",
      "Epoch 3199, Loss: 0.0032911126036196947, Final Batch Loss: 0.001200542668811977\n",
      "Epoch 3200, Loss: 0.001203329855343327, Final Batch Loss: 0.0003256744530517608\n",
      "Epoch 3201, Loss: 0.0013734920939896256, Final Batch Loss: 0.00018217031902167946\n",
      "Epoch 3202, Loss: 0.000648311782242672, Final Batch Loss: 1.2911513294966426e-05\n",
      "Epoch 3203, Loss: 0.0011626607889638763, Final Batch Loss: 2.0077334283996606e-07\n",
      "Epoch 3204, Loss: 0.0012181279998912942, Final Batch Loss: 2.8949270927114412e-05\n",
      "Epoch 3205, Loss: 0.0003517307721949692, Final Batch Loss: 2.6351506221544696e-07\n",
      "Epoch 3206, Loss: 0.001321698960964568, Final Batch Loss: 0.00016110808064695448\n",
      "Epoch 3207, Loss: 0.0015414520094054751, Final Batch Loss: 9.233454329660162e-05\n",
      "Epoch 3208, Loss: 0.0004482694075704785, Final Batch Loss: 1.2704711480182596e-05\n",
      "Epoch 3209, Loss: 0.0010046417960438703, Final Batch Loss: 2.2837707547296304e-06\n",
      "Epoch 3210, Loss: 0.00101440654907492, Final Batch Loss: 0.00017631423543207347\n",
      "Epoch 3211, Loss: 0.0007143001785152592, Final Batch Loss: 9.90065818768926e-05\n",
      "Epoch 3212, Loss: 0.04309070488670841, Final Batch Loss: 0.04171082377433777\n",
      "Epoch 3213, Loss: 0.032266636451822706, Final Batch Loss: 0.008809220045804977\n",
      "Epoch 3214, Loss: 0.01605213392213045, Final Batch Loss: 0.014219540171325207\n",
      "Epoch 3215, Loss: 0.004007794428616762, Final Batch Loss: 0.0027783343102782965\n",
      "Epoch 3216, Loss: 0.005120853278640425, Final Batch Loss: 4.2302384827053174e-05\n",
      "Epoch 3217, Loss: 0.0016325894539477304, Final Batch Loss: 0.00021669613488484174\n",
      "Epoch 3218, Loss: 0.0024967527933767997, Final Batch Loss: 8.451177563983947e-05\n",
      "Epoch 3219, Loss: 0.0008873576466847943, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3220, Loss: 0.0008315518643939868, Final Batch Loss: 0.0003016864648088813\n",
      "Epoch 3221, Loss: 0.0006851188882137649, Final Batch Loss: 0.0002493952342774719\n",
      "Epoch 3222, Loss: 0.0007592598403789452, Final Batch Loss: 7.955196451803204e-06\n",
      "Epoch 3223, Loss: 0.00034971768620550847, Final Batch Loss: 1.7567656129813258e-07\n",
      "Epoch 3224, Loss: 0.00022825626274425304, Final Batch Loss: 4.6615596147603355e-06\n",
      "Epoch 3225, Loss: 0.0009018697965075262, Final Batch Loss: 2.2967673430684954e-05\n",
      "Epoch 3226, Loss: 0.006770496293029282, Final Batch Loss: 0.005950553808361292\n",
      "Epoch 3227, Loss: 0.00019441755421212292, Final Batch Loss: 7.164705948525807e-06\n",
      "Epoch 3228, Loss: 0.026316275962017244, Final Batch Loss: 3.6176996218273416e-05\n",
      "Epoch 3229, Loss: 0.030158062058035284, Final Batch Loss: 4.981044912710786e-05\n",
      "Epoch 3230, Loss: 0.003055494591819752, Final Batch Loss: 3.011594458257605e-07\n",
      "Epoch 3231, Loss: 0.0023293364076835132, Final Batch Loss: 3.3817061648733215e-06\n",
      "Epoch 3232, Loss: 0.0010496983195480425, Final Batch Loss: 0.0007897499017417431\n",
      "Epoch 3233, Loss: 0.011582266623918258, Final Batch Loss: 4.692902621172834e-06\n",
      "Epoch 3234, Loss: 0.012974476605450036, Final Batch Loss: 0.0009186387178488076\n",
      "Epoch 3235, Loss: 0.000265643229795387, Final Batch Loss: 3.4288899769308046e-05\n",
      "Epoch 3236, Loss: 0.00038878045711499, Final Batch Loss: 1.970061248357524e-06\n",
      "Epoch 3237, Loss: 0.0010899155471832955, Final Batch Loss: 1.631282628977715e-07\n",
      "Epoch 3238, Loss: 0.017242637870367616, Final Batch Loss: 0.0005966132739558816\n",
      "Epoch 3239, Loss: 0.0006694400271953782, Final Batch Loss: 1.9007709852303378e-05\n",
      "Epoch 3240, Loss: 0.00026012145440290624, Final Batch Loss: 6.901586857566144e-08\n",
      "Epoch 3241, Loss: 0.0008190743915292842, Final Batch Loss: 6.092036983318394e-06\n",
      "Epoch 3242, Loss: 0.0004712159607151989, Final Batch Loss: 0.00010071709402836859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3243, Loss: 0.0005953049803792965, Final Batch Loss: 5.9835325373569503e-05\n",
      "Epoch 3244, Loss: 0.001331436352302262, Final Batch Loss: 1.4918338820280042e-05\n",
      "Epoch 3245, Loss: 0.0009444778697798029, Final Batch Loss: 0.0006128266104497015\n",
      "Epoch 3246, Loss: 0.00031555397665750107, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3247, Loss: 0.0012596740270964801, Final Batch Loss: 0.0004113735631108284\n",
      "Epoch 3248, Loss: 0.00043790084009742714, Final Batch Loss: 4.4608291318581905e-06\n",
      "Epoch 3249, Loss: 0.005747987772338092, Final Batch Loss: 0.0014635758707299829\n",
      "Epoch 3250, Loss: 0.0003278225394751644, Final Batch Loss: 1.976812200155109e-05\n",
      "Epoch 3251, Loss: 0.002858607664165902, Final Batch Loss: 0.002190730767324567\n",
      "Epoch 3252, Loss: 0.002579587827767682, Final Batch Loss: 2.327691163372947e-06\n",
      "Epoch 3253, Loss: 0.00011453652035697814, Final Batch Loss: 3.3253030551350093e-07\n",
      "Epoch 3254, Loss: 0.027511123480508104, Final Batch Loss: 4.5277214667294174e-05\n",
      "Epoch 3255, Loss: 0.0003752131378860213, Final Batch Loss: 9.138558380072936e-05\n",
      "Epoch 3256, Loss: 0.000485044380184263, Final Batch Loss: 6.973464041948318e-05\n",
      "Epoch 3257, Loss: 0.0007050443564367015, Final Batch Loss: 5.537447941605933e-05\n",
      "Epoch 3258, Loss: 0.00041954075277317315, Final Batch Loss: 0.00017941597616299987\n",
      "Epoch 3259, Loss: 0.00030319463985506445, Final Batch Loss: 3.303160337964073e-05\n",
      "Epoch 3260, Loss: 0.0002054452360198411, Final Batch Loss: 1.003858301373839e-06\n",
      "Epoch 3261, Loss: 0.0021613144781440496, Final Batch Loss: 9.837036486715078e-06\n",
      "Epoch 3262, Loss: 0.02081085326426546, Final Batch Loss: 2.2157892090035602e-05\n",
      "Epoch 3263, Loss: 0.0003054829539905768, Final Batch Loss: 5.20313078595791e-05\n",
      "Epoch 3264, Loss: 0.012113799690268934, Final Batch Loss: 0.010343327187001705\n",
      "Epoch 3265, Loss: 0.011915604340174468, Final Batch Loss: 9.937812137650326e-06\n",
      "Epoch 3266, Loss: 0.0001678037415331346, Final Batch Loss: 1.156843518401729e-05\n",
      "Epoch 3267, Loss: 0.0017357950237055775, Final Batch Loss: 0.0003599905758164823\n",
      "Epoch 3268, Loss: 0.02507972103649081, Final Batch Loss: 7.0268042691168375e-06\n",
      "Epoch 3269, Loss: 0.004205446502737686, Final Batch Loss: 3.438138946876279e-06\n",
      "Epoch 3270, Loss: 0.0004225472512189299, Final Batch Loss: 0.0\n",
      "Epoch 3271, Loss: 0.0027670309677887417, Final Batch Loss: 5.282595793687506e-06\n",
      "Epoch 3272, Loss: 0.005913696505331245, Final Batch Loss: 1.192084482681821e-06\n",
      "Epoch 3273, Loss: 0.0005507078149094013, Final Batch Loss: 1.938706191140227e-06\n",
      "Epoch 3274, Loss: 0.00042792762178578414, Final Batch Loss: 5.527315806830302e-06\n",
      "Epoch 3275, Loss: 0.00039364115409590283, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 3276, Loss: 0.004050056682899594, Final Batch Loss: 0.0009109137463383377\n",
      "Epoch 3277, Loss: 0.0004647495770768728, Final Batch Loss: 4.916777470498346e-05\n",
      "Epoch 3278, Loss: 0.0005671404644544964, Final Batch Loss: 2.2963206447457196e-06\n",
      "Epoch 3279, Loss: 0.0006019723203962712, Final Batch Loss: 1.041507744048431e-06\n",
      "Epoch 3280, Loss: 0.02542833748157136, Final Batch Loss: 6.601199856959283e-05\n",
      "Epoch 3281, Loss: 0.0012028199998894706, Final Batch Loss: 0.00019299979612696916\n",
      "Epoch 3282, Loss: 0.00028340020799078047, Final Batch Loss: 9.245978435501456e-05\n",
      "Epoch 3283, Loss: 0.0010451153739268193, Final Batch Loss: 2.329830931557808e-05\n",
      "Epoch 3284, Loss: 0.0021396917509264313, Final Batch Loss: 0.0005659392918460071\n",
      "Epoch 3285, Loss: 0.0014119735205895267, Final Batch Loss: 0.00011844399705296382\n",
      "Epoch 3286, Loss: 0.0008796704187261639, Final Batch Loss: 2.8590524379978888e-05\n",
      "Epoch 3287, Loss: 0.001112654882717834, Final Batch Loss: 1.480683977206354e-06\n",
      "Epoch 3288, Loss: 0.0006458421921706758, Final Batch Loss: 0.00012028929631924257\n",
      "Epoch 3289, Loss: 0.0016948095071711577, Final Batch Loss: 4.3318977986928076e-05\n",
      "Epoch 3290, Loss: 0.0015321296559704933, Final Batch Loss: 2.250715988338925e-05\n",
      "Epoch 3291, Loss: 0.002267833311634604, Final Batch Loss: 0.0001128993826569058\n",
      "Epoch 3292, Loss: 0.002230535068520112, Final Batch Loss: 5.7158420531777665e-05\n",
      "Epoch 3293, Loss: 0.005706647696683831, Final Batch Loss: 8.344596835740958e-07\n",
      "Epoch 3294, Loss: 0.0024058606941252947, Final Batch Loss: 0.00034614207106642425\n",
      "Epoch 3295, Loss: 0.0029978313978062943, Final Batch Loss: 0.00012562227493617684\n",
      "Epoch 3296, Loss: 0.0022234988282434642, Final Batch Loss: 0.0002669655659701675\n",
      "Epoch 3297, Loss: 0.0019020180479856208, Final Batch Loss: 0.001268410705961287\n",
      "Epoch 3298, Loss: 0.000522863665537443, Final Batch Loss: 9.77125673671253e-05\n",
      "Epoch 3299, Loss: 0.0011289980029687285, Final Batch Loss: 0.0005385186523199081\n",
      "Epoch 3300, Loss: 0.0003057644753425848, Final Batch Loss: 2.5906851078616455e-05\n",
      "Epoch 3301, Loss: 0.00020286108519940171, Final Batch Loss: 8.664266715641133e-06\n",
      "Epoch 3302, Loss: 0.003470097122772131, Final Batch Loss: 1.3456832675728947e-05\n",
      "Epoch 3303, Loss: 0.0017130508961145097, Final Batch Loss: 4.078203801327618e-07\n",
      "Epoch 3304, Loss: 0.0010073023986478802, Final Batch Loss: 4.20980722992681e-06\n",
      "Epoch 3305, Loss: 0.0005018273150199093, Final Batch Loss: 2.760592906270176e-06\n",
      "Epoch 3306, Loss: 0.000825529878056841, Final Batch Loss: 0.0002818454522639513\n",
      "Epoch 3307, Loss: 0.0013854842246878718, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 3308, Loss: 0.000822478519694414, Final Batch Loss: 6.209882121765986e-05\n",
      "Epoch 3309, Loss: 0.00037084506223550306, Final Batch Loss: 1.4430591477321286e-07\n",
      "Epoch 3310, Loss: 0.00012602435435837833, Final Batch Loss: 7.497404112655204e-06\n",
      "Epoch 3311, Loss: 0.003554866341801244, Final Batch Loss: 0.0003203829692211002\n",
      "Epoch 3312, Loss: 9.20112961466657e-05, Final Batch Loss: 2.0657074855989777e-05\n",
      "Epoch 3313, Loss: 0.0005551958274736535, Final Batch Loss: 5.031815817346796e-06\n",
      "Epoch 3314, Loss: 0.000663043676468078, Final Batch Loss: 0.0005000400706194341\n",
      "Epoch 3315, Loss: 0.001532464052161231, Final Batch Loss: 4.115773208468454e-06\n",
      "Epoch 3316, Loss: 0.030106870832128152, Final Batch Loss: 1.4681389757242869e-06\n",
      "Epoch 3317, Loss: 0.0014615087752645195, Final Batch Loss: 4.793332209374057e-06\n",
      "Epoch 3318, Loss: 0.00025957699108403176, Final Batch Loss: 5.17753760505002e-05\n",
      "Epoch 3319, Loss: 0.0004895423476920513, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 3320, Loss: 0.0003089898357302445, Final Batch Loss: 2.1833668597537326e-06\n",
      "Epoch 3321, Loss: 0.0021360746468417346, Final Batch Loss: 9.902485180646181e-05\n",
      "Epoch 3322, Loss: 0.0009225881349266274, Final Batch Loss: 0.00018904377066064626\n",
      "Epoch 3323, Loss: 0.004175663198111579, Final Batch Loss: 0.0013089319691061974\n",
      "Epoch 3324, Loss: 0.0006279102290136507, Final Batch Loss: 1.8645418094820343e-05\n",
      "Epoch 3325, Loss: 0.0012203814185340889, Final Batch Loss: 0.00012270496517885476\n",
      "Epoch 3326, Loss: 0.0009624001104384661, Final Batch Loss: 8.71994998306036e-05\n",
      "Epoch 3327, Loss: 0.00021395257101630705, Final Batch Loss: 1.8822504443960497e-07\n",
      "Epoch 3328, Loss: 0.0014995442616054788, Final Batch Loss: 0.0009461138397455215\n",
      "Epoch 3329, Loss: 0.0006223019190656487, Final Batch Loss: 3.733078847290017e-05\n",
      "Epoch 3330, Loss: 0.0011318525824890457, Final Batch Loss: 8.156379180945805e-07\n",
      "Epoch 3331, Loss: 0.0010154469637200236, Final Batch Loss: 7.14713241904974e-05\n",
      "Epoch 3332, Loss: 0.0003997322855866514, Final Batch Loss: 1.0583547918940894e-05\n",
      "Epoch 3333, Loss: 0.0005506531160790473, Final Batch Loss: 0.00023274592240341008\n",
      "Epoch 3334, Loss: 0.0002750450277915206, Final Batch Loss: 4.5801263581779494e-07\n",
      "Epoch 3335, Loss: 0.031084249182825374, Final Batch Loss: 2.3214415989514237e-07\n",
      "Epoch 3336, Loss: 0.005166542843653588, Final Batch Loss: 4.045130845042877e-05\n",
      "Epoch 3337, Loss: 0.0009630274362280034, Final Batch Loss: 0.00010182722326135263\n",
      "Epoch 3338, Loss: 0.0006101867656980176, Final Batch Loss: 0.0003713027108460665\n",
      "Epoch 3339, Loss: 0.0023182169679785147, Final Batch Loss: 0.0012018730631098151\n",
      "Epoch 3340, Loss: 0.0005305932945702807, Final Batch Loss: 9.529620911052916e-06\n",
      "Epoch 3341, Loss: 0.0005860936489625601, Final Batch Loss: 1.7233802282135002e-05\n",
      "Epoch 3342, Loss: 0.0025809590279095573, Final Batch Loss: 8.331522622029297e-06\n",
      "Epoch 3343, Loss: 0.0005081766976218205, Final Batch Loss: 6.0523769207065925e-05\n",
      "Epoch 3344, Loss: 0.0035581281133545417, Final Batch Loss: 2.77938829640334e-06\n",
      "Epoch 3345, Loss: 0.0015714620822109282, Final Batch Loss: 0.00012928686919622123\n",
      "Epoch 3346, Loss: 0.0009010683645556128, Final Batch Loss: 2.7856660835823277e-06\n",
      "Epoch 3347, Loss: 0.0007402442324746517, Final Batch Loss: 9.749278433446307e-06\n",
      "Epoch 3348, Loss: 0.000582814350764238, Final Batch Loss: 5.960147518635495e-06\n",
      "Epoch 3349, Loss: 0.0016006835248845164, Final Batch Loss: 2.0424839021870866e-05\n",
      "Epoch 3350, Loss: 0.0027344401605660096, Final Batch Loss: 0.0001861915661720559\n",
      "Epoch 3351, Loss: 0.0007561953898402862, Final Batch Loss: 8.663941116537899e-06\n",
      "Epoch 3352, Loss: 0.0023777811729814857, Final Batch Loss: 0.0016372916288673878\n",
      "Epoch 3353, Loss: 0.0005600712156592635, Final Batch Loss: 1.973594589799177e-05\n",
      "Epoch 3354, Loss: 0.000977227407929604, Final Batch Loss: 1.5571613403153606e-05\n",
      "Epoch 3355, Loss: 0.00049170465899806, Final Batch Loss: 0.00022191603784449399\n",
      "Epoch 3356, Loss: 0.00118344220391009, Final Batch Loss: 0.0002892935590352863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3357, Loss: 0.00040399046315542364, Final Batch Loss: 1.7316594949079445e-06\n",
      "Epoch 3358, Loss: 0.0006620584426855203, Final Batch Loss: 4.943154999637045e-05\n",
      "Epoch 3359, Loss: 0.0006239573485800065, Final Batch Loss: 0.000428558822022751\n",
      "Epoch 3360, Loss: 0.0003978326349169947, Final Batch Loss: 2.2651722247246653e-05\n",
      "Epoch 3361, Loss: 0.001196664641611278, Final Batch Loss: 0.0006267188000492752\n",
      "Epoch 3362, Loss: 0.0007326207996811718, Final Batch Loss: 0.00023697831784375012\n",
      "Epoch 3363, Loss: 0.0013919852863182314, Final Batch Loss: 0.0009751706966198981\n",
      "Epoch 3364, Loss: 0.0006306168834271375, Final Batch Loss: 0.00018681820074561983\n",
      "Epoch 3365, Loss: 0.011500352837174432, Final Batch Loss: 0.0002290416305186227\n",
      "Epoch 3366, Loss: 0.0014460821876127739, Final Batch Loss: 3.845336686936207e-05\n",
      "Epoch 3367, Loss: 0.002471299279932282, Final Batch Loss: 3.5071916499873623e-06\n",
      "Epoch 3368, Loss: 0.0002906992576754419, Final Batch Loss: 2.5298306354670785e-05\n",
      "Epoch 3369, Loss: 0.001854731614002958, Final Batch Loss: 0.00018475302204024047\n",
      "Epoch 3370, Loss: 0.0002343908345210366, Final Batch Loss: 8.594320388510823e-05\n",
      "Epoch 3371, Loss: 0.0005373665462684585, Final Batch Loss: 4.128274667891674e-06\n",
      "Epoch 3372, Loss: 0.012386970034730993, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 3373, Loss: 0.0016408791507274145, Final Batch Loss: 2.564885107858572e-05\n",
      "Epoch 3374, Loss: 0.00027864251023856923, Final Batch Loss: 2.3004402464721352e-05\n",
      "Epoch 3375, Loss: 0.0002606939960969612, Final Batch Loss: 4.66972342110239e-05\n",
      "Epoch 3376, Loss: 0.00107353428757051, Final Batch Loss: 5.019319360144436e-07\n",
      "Epoch 3377, Loss: 0.00022289881599135697, Final Batch Loss: 2.2900276235304773e-06\n",
      "Epoch 3378, Loss: 0.00022039009775198792, Final Batch Loss: 1.0038630762210232e-06\n",
      "Epoch 3379, Loss: 0.0008092980187939247, Final Batch Loss: 2.975905044877436e-05\n",
      "Epoch 3380, Loss: 0.0007381823961623013, Final Batch Loss: 0.00046326141455210745\n",
      "Epoch 3381, Loss: 0.0030458725486823823, Final Batch Loss: 7.074476889101788e-05\n",
      "Epoch 3382, Loss: 0.0009089822016079552, Final Batch Loss: 1.6940258262820862e-07\n",
      "Epoch 3383, Loss: 0.0007025966356430935, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3384, Loss: 0.0012322269344857695, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3385, Loss: 0.0007953486638143659, Final Batch Loss: 0.00013399106683209538\n",
      "Epoch 3386, Loss: 0.001332030740215373, Final Batch Loss: 1.380316660970493e-07\n",
      "Epoch 3387, Loss: 0.0005869089982297737, Final Batch Loss: 2.2559081116924062e-05\n",
      "Epoch 3388, Loss: 0.0013649866430114344, Final Batch Loss: 3.1934885100781685e-06\n",
      "Epoch 3389, Loss: 0.000265708895312855, Final Batch Loss: 2.332286021555774e-05\n",
      "Epoch 3390, Loss: 0.0002310226888653233, Final Batch Loss: 5.458502414512623e-07\n",
      "Epoch 3391, Loss: 0.00034649443841772154, Final Batch Loss: 0.00012139201862737536\n",
      "Epoch 3392, Loss: 0.0002783658996321492, Final Batch Loss: 1.380316660970493e-07\n",
      "Epoch 3393, Loss: 0.0017232454097779737, Final Batch Loss: 3.0743427714696736e-07\n",
      "Epoch 3394, Loss: 0.0010243275683023967, Final Batch Loss: 1.2089039955753833e-05\n",
      "Epoch 3395, Loss: 0.00045689787848424146, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 3396, Loss: 0.0014757356657355558, Final Batch Loss: 5.0965547416126356e-05\n",
      "Epoch 3397, Loss: 0.00022331403497588553, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 3398, Loss: 0.0006178198818815872, Final Batch Loss: 8.096259989542887e-05\n",
      "Epoch 3399, Loss: 0.0006015248800395057, Final Batch Loss: 0.00018163844652008265\n",
      "Epoch 3400, Loss: 0.00045981592029420426, Final Batch Loss: 4.398725286591798e-05\n",
      "Epoch 3401, Loss: 0.0005209855808061548, Final Batch Loss: 4.5236170990392566e-05\n",
      "Epoch 3402, Loss: 0.0003219632271793671, Final Batch Loss: 9.744376438902691e-05\n",
      "Epoch 3403, Loss: 0.00044174839786137454, Final Batch Loss: 0.0002417588111711666\n",
      "Epoch 3404, Loss: 0.0006556837615789846, Final Batch Loss: 0.00013572178431786597\n",
      "Epoch 3405, Loss: 0.0008242792537203059, Final Batch Loss: 0.0004091253795195371\n",
      "Epoch 3406, Loss: 0.000615504748566309, Final Batch Loss: 2.0991548808524385e-05\n",
      "Epoch 3407, Loss: 6.347334503686852e-05, Final Batch Loss: 1.8195071049831313e-07\n",
      "Epoch 3408, Loss: 0.0005471311660585343, Final Batch Loss: 7.961579285620246e-06\n",
      "Epoch 3409, Loss: 0.0001112853847189399, Final Batch Loss: 1.3928570297139231e-06\n",
      "Epoch 3410, Loss: 0.012763508966600057, Final Batch Loss: 3.3725395041983575e-05\n",
      "Epoch 3411, Loss: 9.076006895725186e-05, Final Batch Loss: 4.705608773747372e-07\n",
      "Epoch 3412, Loss: 0.0005967646879980748, Final Batch Loss: 5.640374638460344e-06\n",
      "Epoch 3413, Loss: 0.0008451378562313039, Final Batch Loss: 5.2019695431226864e-05\n",
      "Epoch 3414, Loss: 0.0026312592017347924, Final Batch Loss: 0.0008848608704283834\n",
      "Epoch 3415, Loss: 0.0003104455281572882, Final Batch Loss: 3.2396714232163504e-05\n",
      "Epoch 3416, Loss: 0.0006716172501910478, Final Batch Loss: 0.0\n",
      "Epoch 3417, Loss: 0.0003266251405875664, Final Batch Loss: 2.9954888304928318e-05\n",
      "Epoch 3418, Loss: 0.0007113885185390245, Final Batch Loss: 2.4677206965861842e-05\n",
      "Epoch 3419, Loss: 0.0007172242767410353, Final Batch Loss: 0.00012059138680342585\n",
      "Epoch 3420, Loss: 0.0010454593352733355, Final Batch Loss: 1.8508485482016113e-06\n",
      "Epoch 3421, Loss: 0.0002525240124668926, Final Batch Loss: 3.311764157842845e-05\n",
      "Epoch 3422, Loss: 0.00022512539726449177, Final Batch Loss: 1.1964111763518304e-05\n",
      "Epoch 3423, Loss: 0.0009273087052861229, Final Batch Loss: 1.5589248505420983e-05\n",
      "Epoch 3424, Loss: 0.002119117860274855, Final Batch Loss: 1.824260107241571e-05\n",
      "Epoch 3425, Loss: 0.00022434471497945196, Final Batch Loss: 1.8320413346373243e-06\n",
      "Epoch 3426, Loss: 0.0020861631369606393, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3427, Loss: 0.0015756422635604395, Final Batch Loss: 3.2155337976291776e-05\n",
      "Epoch 3428, Loss: 0.0004742392775369808, Final Batch Loss: 1.9440092728473246e-05\n",
      "Epoch 3429, Loss: 0.00021172291053517256, Final Batch Loss: 1.588394479767885e-05\n",
      "Epoch 3430, Loss: 0.005199731356697157, Final Batch Loss: 0.0039564999751746655\n",
      "Epoch 3431, Loss: 0.0008615595215815119, Final Batch Loss: 3.2032825401984155e-05\n",
      "Epoch 3432, Loss: 0.0009602738675198452, Final Batch Loss: 9.160241347672127e-07\n",
      "Epoch 3433, Loss: 0.0004073261734447442, Final Batch Loss: 0.0\n",
      "Epoch 3434, Loss: 0.0002839076205418678, Final Batch Loss: 0.0\n",
      "Epoch 3435, Loss: 0.0005860882638444309, Final Batch Loss: 1.6563690223847516e-06\n",
      "Epoch 3436, Loss: 0.000957363452471327, Final Batch Loss: 0.0001031178398989141\n",
      "Epoch 3437, Loss: 0.0001862228546087863, Final Batch Loss: 9.535879144095816e-06\n",
      "Epoch 3438, Loss: 0.0006847970780654578, Final Batch Loss: 0.00031544716330245137\n",
      "Epoch 3439, Loss: 0.002868303366994951, Final Batch Loss: 0.0025384151376783848\n",
      "Epoch 3440, Loss: 0.007572963048005477, Final Batch Loss: 0.0026374547742307186\n",
      "Epoch 3441, Loss: 0.000990110353086493, Final Batch Loss: 2.321797910553869e-05\n",
      "Epoch 3442, Loss: 0.002481720244986718, Final Batch Loss: 1.3175688309274847e-06\n",
      "Epoch 3443, Loss: 0.00018345706484979019, Final Batch Loss: 8.22906440589577e-05\n",
      "Epoch 3444, Loss: 0.00014871261646476341, Final Batch Loss: 1.9763419913942926e-06\n",
      "Epoch 3445, Loss: 0.000606975572736701, Final Batch Loss: 3.389522680663504e-05\n",
      "Epoch 3446, Loss: 0.0006428759625123348, Final Batch Loss: 0.00043974880827590823\n",
      "Epoch 3447, Loss: 0.0008628970917925471, Final Batch Loss: 0.00017275416757911444\n",
      "Epoch 3448, Loss: 0.0027496750154796246, Final Batch Loss: 6.148658258098294e-07\n",
      "Epoch 3449, Loss: 0.00015704457291576546, Final Batch Loss: 9.41731414059177e-05\n",
      "Epoch 3450, Loss: 0.00016289767248167664, Final Batch Loss: 2.321440035757405e-07\n",
      "Epoch 3451, Loss: 0.00026947778388830557, Final Batch Loss: 8.971990723694034e-07\n",
      "Epoch 3452, Loss: 0.00026527290901867673, Final Batch Loss: 1.360761234536767e-05\n",
      "Epoch 3453, Loss: 0.006676021987914282, Final Batch Loss: 2.2398553483071737e-06\n",
      "Epoch 3454, Loss: 8.641337626613677e-05, Final Batch Loss: 1.3613958799396642e-05\n",
      "Epoch 3455, Loss: 0.0005286747000354808, Final Batch Loss: 3.564301005098969e-05\n",
      "Epoch 3456, Loss: 0.0005046122113867568, Final Batch Loss: 5.082055736238544e-07\n",
      "Epoch 3457, Loss: 0.00019138895117976062, Final Batch Loss: 2.798228933897917e-06\n",
      "Epoch 3458, Loss: 0.00011608598951085014, Final Batch Loss: 8.783835170333987e-08\n",
      "Epoch 3459, Loss: 0.00020918805239489302, Final Batch Loss: 0.0\n",
      "Epoch 3460, Loss: 0.00010001163423112303, Final Batch Loss: 1.4242275483411504e-06\n",
      "Epoch 3461, Loss: 0.009446737141843187, Final Batch Loss: 0.0006143120699562132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3462, Loss: 0.0006055065459804609, Final Batch Loss: 0.00028869081870652735\n",
      "Epoch 3463, Loss: 0.0009040100041133314, Final Batch Loss: 3.764503020420307e-08\n",
      "Epoch 3464, Loss: 0.0009331166984338779, Final Batch Loss: 0.0003433913516346365\n",
      "Epoch 3465, Loss: 0.003453743422141997, Final Batch Loss: 5.012190013076179e-05\n",
      "Epoch 3466, Loss: 0.00015679259218615016, Final Batch Loss: 7.529002488126935e-08\n",
      "Epoch 3467, Loss: 0.001103788070452083, Final Batch Loss: 3.4507871760069975e-07\n",
      "Epoch 3468, Loss: 0.0005379680292207922, Final Batch Loss: 6.098307039792417e-06\n",
      "Epoch 3469, Loss: 0.00017551867858855985, Final Batch Loss: 2.0633731764974073e-05\n",
      "Epoch 3470, Loss: 0.010268155534049583, Final Batch Loss: 7.0393848545791116e-06\n",
      "Epoch 3471, Loss: 0.009417059802217409, Final Batch Loss: 0.00206191698089242\n",
      "Epoch 3472, Loss: 0.00016980715736281127, Final Batch Loss: 5.7358538469998166e-05\n",
      "Epoch 3473, Loss: 0.0009441195416002301, Final Batch Loss: 1.915784196171444e-05\n",
      "Epoch 3474, Loss: 0.0004989562148693949, Final Batch Loss: 0.00014917597582098097\n",
      "Epoch 3475, Loss: 0.0009649049652580288, Final Batch Loss: 1.3368645340960938e-05\n",
      "Epoch 3476, Loss: 0.011051659345184817, Final Batch Loss: 1.8445900877850363e-06\n",
      "Epoch 3477, Loss: 0.000589489471167326, Final Batch Loss: 9.278433572035283e-05\n",
      "Epoch 3478, Loss: 0.0003368779104988562, Final Batch Loss: 6.901585436480673e-08\n",
      "Epoch 3479, Loss: 0.0018041812218143605, Final Batch Loss: 0.0\n",
      "Epoch 3480, Loss: 0.00020099116591154598, Final Batch Loss: 0.00013316009426489472\n",
      "Epoch 3481, Loss: 9.617260570848885e-05, Final Batch Loss: 1.0791538898047293e-06\n",
      "Epoch 3482, Loss: 0.0005071955047242227, Final Batch Loss: 1.2710991541098338e-05\n",
      "Epoch 3483, Loss: 0.0007638344514369066, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 3484, Loss: 0.00011158086999785155, Final Batch Loss: 1.179447463073302e-05\n",
      "Epoch 3485, Loss: 0.044152609203592874, Final Batch Loss: 0.043855082243680954\n",
      "Epoch 3486, Loss: 0.0001758173831944987, Final Batch Loss: 6.274141810536094e-07\n",
      "Epoch 3487, Loss: 0.0011751945567084476, Final Batch Loss: 0.0006793540669605136\n",
      "Epoch 3488, Loss: 0.00028299267796683125, Final Batch Loss: 8.946361049311236e-06\n",
      "Epoch 3489, Loss: 0.0006539398455061018, Final Batch Loss: 0.00039695287705399096\n",
      "Epoch 3490, Loss: 0.0009203740601151367, Final Batch Loss: 1.637542482058052e-06\n",
      "Epoch 3491, Loss: 0.0005674972453562077, Final Batch Loss: 0.0003577886091079563\n",
      "Epoch 3492, Loss: 0.00019089172110398067, Final Batch Loss: 1.2760664503730368e-05\n",
      "Epoch 3493, Loss: 0.00015287697169696912, Final Batch Loss: 5.253253038972616e-05\n",
      "Epoch 3494, Loss: 0.000487758711301467, Final Batch Loss: 6.2113997501001e-07\n",
      "Epoch 3495, Loss: 0.00019724079538718797, Final Batch Loss: 6.451701483456418e-05\n",
      "Epoch 3496, Loss: 0.0019080285456993806, Final Batch Loss: 1.0164113746213843e-06\n",
      "Epoch 3497, Loss: 0.0009331014727251841, Final Batch Loss: 4.705608773747372e-07\n",
      "Epoch 3498, Loss: 0.03282792509577348, Final Batch Loss: 5.772222380073799e-07\n",
      "Epoch 3499, Loss: 0.00027945444753640913, Final Batch Loss: 4.768159215018386e-06\n",
      "Epoch 3500, Loss: 0.00015564276691293344, Final Batch Loss: 0.0\n",
      "Epoch 3501, Loss: 0.003470094525255263, Final Batch Loss: 0.0007643599528819323\n",
      "Epoch 3502, Loss: 0.0024203174725698773, Final Batch Loss: 2.1123536498635076e-05\n",
      "Epoch 3503, Loss: 0.0005621892705676146, Final Batch Loss: 0.0003847988846246153\n",
      "Epoch 3504, Loss: 0.00254674563620938, Final Batch Loss: 3.519967867759988e-05\n",
      "Epoch 3505, Loss: 0.0005438179014163325, Final Batch Loss: 2.7327705538482405e-05\n",
      "Epoch 3506, Loss: 0.00038738005969207734, Final Batch Loss: 3.748768358491361e-05\n",
      "Epoch 3507, Loss: 0.000518300526891835, Final Batch Loss: 0.00020846229745075107\n",
      "Epoch 3508, Loss: 0.0008821669762255624, Final Batch Loss: 3.880658186972141e-05\n",
      "Epoch 3509, Loss: 0.0002457893215250806, Final Batch Loss: 1.3858706552127842e-05\n",
      "Epoch 3510, Loss: 0.0030256751233537216, Final Batch Loss: 4.338951475801878e-05\n",
      "Epoch 3511, Loss: 0.0007109886355465278, Final Batch Loss: 0.00031226276769302785\n",
      "Epoch 3512, Loss: 0.00035030878007091815, Final Batch Loss: 1.2371253433229867e-05\n",
      "Epoch 3513, Loss: 0.00024395999804482926, Final Batch Loss: 6.650612363046093e-07\n",
      "Epoch 3514, Loss: 0.00023062990430844366, Final Batch Loss: 3.921295046893647e-06\n",
      "Epoch 3515, Loss: 0.003405439139896771, Final Batch Loss: 3.391038262634538e-05\n",
      "Epoch 3516, Loss: 0.0003419505555939395, Final Batch Loss: 0.00012259486538823694\n",
      "Epoch 3517, Loss: 0.00018163848653784953, Final Batch Loss: 7.551955786766484e-05\n",
      "Epoch 3518, Loss: 0.0042573388125219935, Final Batch Loss: 1.9198703284928342e-06\n",
      "Epoch 3519, Loss: 0.0010580876528933914, Final Batch Loss: 3.13707971599797e-07\n",
      "Epoch 3520, Loss: 0.00016447051712020766, Final Batch Loss: 1.5294643162633292e-05\n",
      "Epoch 3521, Loss: 0.0005507482943585273, Final Batch Loss: 1.0665986565072672e-06\n",
      "Epoch 3522, Loss: 0.00022723526126355864, Final Batch Loss: 1.4517234376398847e-05\n",
      "Epoch 3523, Loss: 0.0006235948894754983, Final Batch Loss: 0.00035180096165277064\n",
      "Epoch 3524, Loss: 0.00042975520695520686, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 3525, Loss: 0.00026171532772423234, Final Batch Loss: 0.0\n",
      "Epoch 3526, Loss: 0.0008044303432903632, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 3527, Loss: 0.00034608185694651183, Final Batch Loss: 1.0665988838809426e-06\n",
      "Epoch 3528, Loss: 0.0005397586246544961, Final Batch Loss: 5.6326596677536145e-05\n",
      "Epoch 3529, Loss: 0.003069285419769585, Final Batch Loss: 0.002208409598097205\n",
      "Epoch 3530, Loss: 0.0025055563728528796, Final Batch Loss: 1.9635581338661723e-05\n",
      "Epoch 3531, Loss: 0.0011500962027639616, Final Batch Loss: 0.0004913890734314919\n",
      "Epoch 3532, Loss: 0.0002835532068274915, Final Batch Loss: 7.091894076438621e-05\n",
      "Epoch 3533, Loss: 0.00045538291004731946, Final Batch Loss: 4.6428675659626606e-07\n",
      "Epoch 3534, Loss: 0.0004234123189235106, Final Batch Loss: 0.0001298909046454355\n",
      "Epoch 3535, Loss: 0.00019318109025334707, Final Batch Loss: 8.024074304557871e-06\n",
      "Epoch 3536, Loss: 0.00014727497728017624, Final Batch Loss: 3.4695640351856127e-06\n",
      "Epoch 3537, Loss: 0.0001692496395868659, Final Batch Loss: 5.64675453063046e-08\n",
      "Epoch 3538, Loss: 0.000307457726080429, Final Batch Loss: 9.97585516415711e-07\n",
      "Epoch 3539, Loss: 0.0013450416169362711, Final Batch Loss: 4.391919361523833e-08\n",
      "Epoch 3540, Loss: 0.012543783657747554, Final Batch Loss: 0.00014253675180952996\n",
      "Epoch 3541, Loss: 0.00029366498347371817, Final Batch Loss: 6.0981474234722555e-06\n",
      "Epoch 3542, Loss: 0.00034558460811240366, Final Batch Loss: 4.41056090494385e-06\n",
      "Epoch 3543, Loss: 0.0007250260268847342, Final Batch Loss: 9.836995559453499e-06\n",
      "Epoch 3544, Loss: 0.0007934455352369696, Final Batch Loss: 3.701011883094907e-05\n",
      "Epoch 3545, Loss: 0.0006040277519545612, Final Batch Loss: 8.156418829230461e-08\n",
      "Epoch 3546, Loss: 0.000559832504222868, Final Batch Loss: 6.462036253651604e-06\n",
      "Epoch 3547, Loss: 0.0028158495952084195, Final Batch Loss: 2.399564255028963e-05\n",
      "Epoch 3548, Loss: 0.0037403817532322137, Final Batch Loss: 1.9070268535870127e-05\n",
      "Epoch 3549, Loss: 0.00047550766339554684, Final Batch Loss: 8.720385267224628e-06\n",
      "Epoch 3550, Loss: 0.00037475924136742833, Final Batch Loss: 7.55993050916004e-06\n",
      "Epoch 3551, Loss: 0.00353005949909857, Final Batch Loss: 2.984431375807617e-05\n",
      "Epoch 3552, Loss: 0.001300542647641123, Final Batch Loss: 6.64405843053828e-06\n",
      "Epoch 3553, Loss: 4.619176525011426e-05, Final Batch Loss: 8.519768925907556e-06\n",
      "Epoch 3554, Loss: 0.003801200978614361, Final Batch Loss: 4.7870303205854725e-06\n",
      "Epoch 3555, Loss: 0.0219912429638498, Final Batch Loss: 0.021847113966941833\n",
      "Epoch 3556, Loss: 0.0009488931781902465, Final Batch Loss: 7.717198400314373e-07\n",
      "Epoch 3557, Loss: 0.00018749195510281425, Final Batch Loss: 3.011598437296925e-07\n",
      "Epoch 3558, Loss: 0.00035628395158937565, Final Batch Loss: 5.082070515527448e-07\n",
      "Epoch 3559, Loss: 0.01573676804664359, Final Batch Loss: 1.0666089877986451e-07\n",
      "Epoch 3560, Loss: 0.00047447290737068215, Final Batch Loss: 5.646754175359092e-08\n",
      "Epoch 3561, Loss: 0.0004956398647664173, Final Batch Loss: 1.9637905097624753e-06\n",
      "Epoch 3562, Loss: 0.0009612068885900271, Final Batch Loss: 5.6467527542736207e-08\n",
      "Epoch 3563, Loss: 0.016874152192031033, Final Batch Loss: 0.00023073867487255484\n",
      "Epoch 3564, Loss: 0.0003121162521892984, Final Batch Loss: 5.4458291742776055e-06\n",
      "Epoch 3565, Loss: 0.0012133715987729943, Final Batch Loss: 4.391919361523833e-08\n",
      "Epoch 3566, Loss: 0.0002233272075500281, Final Batch Loss: 2.7041364774049725e-06\n",
      "Epoch 3567, Loss: 0.005748148076236248, Final Batch Loss: 0.001227943692356348\n",
      "Epoch 3568, Loss: 0.00012468898603401612, Final Batch Loss: 1.3004753782297485e-05\n",
      "Epoch 3569, Loss: 9.6885317361739e-05, Final Batch Loss: 4.258216358721256e-05\n",
      "Epoch 3570, Loss: 0.000365634958143346, Final Batch Loss: 2.8909824322909117e-05\n",
      "Epoch 3571, Loss: 0.0001547472346601353, Final Batch Loss: 1.135613160840876e-06\n",
      "Epoch 3572, Loss: 0.0017798260453929515, Final Batch Loss: 1.0038668563083775e-07\n",
      "Epoch 3573, Loss: 0.0018067075143335387, Final Batch Loss: 0.00015290504961740226\n",
      "Epoch 3574, Loss: 0.001498092684414587, Final Batch Loss: 0.00015848783368710428\n",
      "Epoch 3575, Loss: 0.0005245351151188515, Final Batch Loss: 2.264942168039852e-06\n",
      "Epoch 3576, Loss: 9.002289624504556e-05, Final Batch Loss: 2.948856376860931e-07\n",
      "Epoch 3577, Loss: 0.00047735628686496057, Final Batch Loss: 0.000161524279974401\n",
      "Epoch 3578, Loss: 0.0007183074922068045, Final Batch Loss: 3.3506425097584724e-05\n",
      "Epoch 3579, Loss: 0.00012481088742788415, Final Batch Loss: 4.621814514393918e-05\n",
      "Epoch 3580, Loss: 0.0005465133513951059, Final Batch Loss: 3.8272318647614156e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3581, Loss: 0.008541501096260617, Final Batch Loss: 2.031191070273053e-05\n",
      "Epoch 3582, Loss: 0.0025093551296322403, Final Batch Loss: 9.473944828641834e-07\n",
      "Epoch 3583, Loss: 0.0015371746485470794, Final Batch Loss: 0.0008773884037509561\n",
      "Epoch 3584, Loss: 0.0001359146381219034, Final Batch Loss: 6.436927833419759e-06\n",
      "Epoch 3585, Loss: 0.0008389508700474835, Final Batch Loss: 3.827233285846887e-07\n",
      "Epoch 3586, Loss: 0.0002667596563696861, Final Batch Loss: 6.047965871402994e-05\n",
      "Epoch 3587, Loss: 0.002705909348151181, Final Batch Loss: 1.9906416127923876e-05\n",
      "Epoch 3588, Loss: 0.0005072582644061185, Final Batch Loss: 0.0003847727202810347\n",
      "Epoch 3589, Loss: 0.000507598562307976, Final Batch Loss: 4.542418082564836e-06\n",
      "Epoch 3590, Loss: 0.0014454787105933065, Final Batch Loss: 2.0608606064342894e-05\n",
      "Epoch 3591, Loss: 0.0003208678390365094, Final Batch Loss: 8.149547647917643e-05\n",
      "Epoch 3592, Loss: 0.001204061474709306, Final Batch Loss: 6.090409806347452e-05\n",
      "Epoch 3593, Loss: 0.0010448968669152237, Final Batch Loss: 7.85467909736326e-06\n",
      "Epoch 3594, Loss: 0.00011056942821596749, Final Batch Loss: 2.505314478185028e-05\n",
      "Epoch 3595, Loss: 0.008294170043654958, Final Batch Loss: 7.15251871952205e-07\n",
      "Epoch 3596, Loss: 0.007222014581202529, Final Batch Loss: 0.000376375945052132\n",
      "Epoch 3597, Loss: 0.00019401357394599472, Final Batch Loss: 5.521073489944683e-06\n",
      "Epoch 3598, Loss: 0.0003892778549428044, Final Batch Loss: 1.1920923981278975e-07\n",
      "Epoch 3599, Loss: 0.004801155155291781, Final Batch Loss: 0.0010752793168649077\n",
      "Epoch 3600, Loss: 8.131590448101633e-05, Final Batch Loss: 5.891257842449704e-06\n",
      "Epoch 3601, Loss: 0.00016794296061561909, Final Batch Loss: 5.303465513861738e-05\n",
      "Epoch 3602, Loss: 0.02274880807271984, Final Batch Loss: 2.973117989313323e-05\n",
      "Epoch 3603, Loss: 0.0007128156539693009, Final Batch Loss: 3.162513530696742e-05\n",
      "Epoch 3604, Loss: 0.002645948377903551, Final Batch Loss: 0.0\n",
      "Epoch 3605, Loss: 0.0002755904365585593, Final Batch Loss: 6.813331765442854e-06\n",
      "Epoch 3606, Loss: 0.0010301318179699592, Final Batch Loss: 1.3036878954153508e-05\n",
      "Epoch 3607, Loss: 0.020694210128567647, Final Batch Loss: 0.0040605757385492325\n",
      "Epoch 3608, Loss: 0.003144652104789092, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3609, Loss: 0.003302971947050537, Final Batch Loss: 1.5246023394865915e-06\n",
      "Epoch 3610, Loss: 0.0003695913255796768, Final Batch Loss: 1.1028932931367308e-05\n",
      "Epoch 3611, Loss: 0.002161714249382385, Final Batch Loss: 1.3614782119475421e-06\n",
      "Epoch 3612, Loss: 0.0008679881429998204, Final Batch Loss: 8.398141653742641e-05\n",
      "Epoch 3613, Loss: 0.00022475711216429772, Final Batch Loss: 2.446925009280676e-07\n",
      "Epoch 3614, Loss: 0.008526075165718794, Final Batch Loss: 0.007548759691417217\n",
      "Epoch 3615, Loss: 0.00031253626923444244, Final Batch Loss: 1.9449919363978552e-07\n",
      "Epoch 3616, Loss: 0.0008552568024242646, Final Batch Loss: 7.214896868390497e-06\n",
      "Epoch 3617, Loss: 0.0008148501165123889, Final Batch Loss: 2.0857531126239337e-05\n",
      "Epoch 3618, Loss: 0.0001446015992030425, Final Batch Loss: 3.3880471050906635e-07\n",
      "Epoch 3619, Loss: 0.0015106855153135257, Final Batch Loss: 1.7791047866921872e-05\n",
      "Epoch 3620, Loss: 0.02233357149088988, Final Batch Loss: 0.02213498204946518\n",
      "Epoch 3621, Loss: 0.0003077462185174795, Final Batch Loss: 4.391919361523833e-08\n",
      "Epoch 3622, Loss: 0.0009409950289409608, Final Batch Loss: 0.0001444532535970211\n",
      "Epoch 3623, Loss: 0.014024500575033017, Final Batch Loss: 5.207548383623362e-07\n",
      "Epoch 3624, Loss: 8.773676399798092e-05, Final Batch Loss: 5.019337478984198e-08\n",
      "Epoch 3625, Loss: 0.00033578546208445914, Final Batch Loss: 5.9121961385244504e-05\n",
      "Epoch 3626, Loss: 0.00042560460133245215, Final Batch Loss: 3.08801609207876e-05\n",
      "Epoch 3627, Loss: 0.00019475614249131468, Final Batch Loss: 2.4594185106252553e-06\n",
      "Epoch 3628, Loss: 0.00020647912970161997, Final Batch Loss: 0.0001165176581707783\n",
      "Epoch 3629, Loss: 0.06539398850873113, Final Batch Loss: 0.06415630131959915\n",
      "Epoch 3630, Loss: 0.00015327828413091993, Final Batch Loss: 5.834951366523455e-07\n",
      "Epoch 3631, Loss: 0.0002125965754231629, Final Batch Loss: 5.6467527542736207e-08\n",
      "Epoch 3632, Loss: 0.005689809273462743, Final Batch Loss: 0.0021190911065787077\n",
      "Epoch 3633, Loss: 0.018833746209864444, Final Batch Loss: 1.0038668563083775e-07\n",
      "Epoch 3634, Loss: 0.03298152903880691, Final Batch Loss: 0.030590804293751717\n",
      "Epoch 3635, Loss: 0.013908863507822389, Final Batch Loss: 4.251044083503075e-05\n",
      "Epoch 3636, Loss: 0.021264319988176794, Final Batch Loss: 6.901586857566144e-08\n",
      "Epoch 3637, Loss: 0.006081776363316749, Final Batch Loss: 1.45558897202136e-06\n",
      "Epoch 3638, Loss: 0.004967257347743725, Final Batch Loss: 0.004818787798285484\n",
      "Epoch 3639, Loss: 0.0006082864911149954, Final Batch Loss: 2.1547404685406946e-05\n",
      "Epoch 3640, Loss: 0.0022389754212781554, Final Batch Loss: 2.8879314413643442e-05\n",
      "Epoch 3641, Loss: 0.002119451161888719, Final Batch Loss: 1.3889378351450432e-05\n",
      "Epoch 3642, Loss: 9.490680895396508e-05, Final Batch Loss: 1.854435322456993e-05\n",
      "Epoch 3643, Loss: 0.003660713411591132, Final Batch Loss: 0.00018920311413239688\n",
      "Epoch 3644, Loss: 0.00023656706616748124, Final Batch Loss: 3.9538957935292274e-05\n",
      "Epoch 3645, Loss: 0.00031137155747273937, Final Batch Loss: 1.6178732039406896e-05\n",
      "Epoch 3646, Loss: 0.0004418623425834767, Final Batch Loss: 2.3841816698677576e-07\n",
      "Epoch 3647, Loss: 0.0010670398594108121, Final Batch Loss: 5.64675453063046e-08\n",
      "Epoch 3648, Loss: 0.0007991955612851598, Final Batch Loss: 7.277999429788906e-07\n",
      "Epoch 3649, Loss: 0.0007130331687221769, Final Batch Loss: 0.0005090215126983821\n",
      "Epoch 3650, Loss: 0.0007824900712876115, Final Batch Loss: 6.776613008696586e-05\n",
      "Epoch 3651, Loss: 0.0004344398112152703, Final Batch Loss: 0.00027598682208918035\n",
      "Epoch 3652, Loss: 0.003176091588102281, Final Batch Loss: 0.0022246597800403833\n",
      "Epoch 3653, Loss: 0.0012815945546407193, Final Batch Loss: 2.070473072990353e-07\n",
      "Epoch 3654, Loss: 0.0004997805990001325, Final Batch Loss: 1.6940242630880675e-07\n",
      "Epoch 3655, Loss: 0.000496232414366915, Final Batch Loss: 4.3919204273379364e-08\n",
      "Epoch 3656, Loss: 0.015243047790136188, Final Batch Loss: 0.014902926981449127\n",
      "Epoch 3657, Loss: 0.002212999912444502, Final Batch Loss: 0.0\n",
      "Epoch 3658, Loss: 0.008885872623807245, Final Batch Loss: 8.15642238194414e-08\n",
      "Epoch 3659, Loss: 0.01390301029823604, Final Batch Loss: 1.298740244237706e-06\n",
      "Epoch 3660, Loss: 0.0007555504773932853, Final Batch Loss: 7.52900319866967e-08\n",
      "Epoch 3661, Loss: 0.0009950068670150358, Final Batch Loss: 0.00015207934484351426\n",
      "Epoch 3662, Loss: 0.0012682729575317353, Final Batch Loss: 7.680497947148979e-05\n",
      "Epoch 3663, Loss: 6.190494877955643e-05, Final Batch Loss: 8.47583305585431e-06\n",
      "Epoch 3664, Loss: 0.003143962514798204, Final Batch Loss: 3.576272433747363e-07\n",
      "Epoch 3665, Loss: 0.00021560125556163712, Final Batch Loss: 1.3803169451875874e-07\n",
      "Epoch 3666, Loss: 6.660730105068069e-05, Final Batch Loss: 0.0\n",
      "Epoch 3667, Loss: 0.037918690157653145, Final Batch Loss: 1.0477837122380151e-06\n",
      "Epoch 3668, Loss: 0.023947804695353625, Final Batch Loss: 3.262559857830638e-07\n",
      "Epoch 3669, Loss: 0.00026392016661702655, Final Batch Loss: 3.242132152081467e-05\n",
      "Epoch 3670, Loss: 0.00017837999018155415, Final Batch Loss: 1.1293501955833563e-07\n",
      "Epoch 3671, Loss: 0.0036410240959647844, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3672, Loss: 0.014499210023132036, Final Batch Loss: 2.1582727640634403e-06\n",
      "Epoch 3673, Loss: 0.0007438650013917858, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3674, Loss: 0.000207333885555272, Final Batch Loss: 2.946863060060423e-05\n",
      "Epoch 3675, Loss: 8.223973300403031e-05, Final Batch Loss: 5.6467527542736207e-08\n",
      "Epoch 3676, Loss: 0.01764543878744007, Final Batch Loss: 3.0675659218104556e-05\n",
      "Epoch 3677, Loss: 0.000695059522982433, Final Batch Loss: 1.8822494496362197e-07\n",
      "Epoch 3678, Loss: 0.00020844816754106432, Final Batch Loss: 0.0\n",
      "Epoch 3679, Loss: 8.760456876188982e-05, Final Batch Loss: 2.637112447700929e-05\n",
      "Epoch 3680, Loss: 0.0008647453723824583, Final Batch Loss: 0.00010866068623727188\n",
      "Epoch 3681, Loss: 0.0004838539581015766, Final Batch Loss: 2.3214404620830464e-07\n",
      "Epoch 3682, Loss: 0.0010984405089402571, Final Batch Loss: 7.324561011046171e-05\n",
      "Epoch 3683, Loss: 0.0009479106847720686, Final Batch Loss: 0.0008592039230279624\n",
      "Epoch 3684, Loss: 0.0014397148916032165, Final Batch Loss: 0.0008584628812968731\n",
      "Epoch 3685, Loss: 0.000298419181490317, Final Batch Loss: 5.598325151368044e-05\n",
      "Epoch 3686, Loss: 0.0004442867016458685, Final Batch Loss: 6.2741727369086675e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3687, Loss: 0.013717371824483848, Final Batch Loss: 2.3841816698677576e-07\n",
      "Epoch 3688, Loss: 0.0034472119282327185, Final Batch Loss: 5.520995273400331e-06\n",
      "Epoch 3689, Loss: 0.006317007812413067, Final Batch Loss: 3.87103364118957e-06\n",
      "Epoch 3690, Loss: 0.0004786306690220954, Final Batch Loss: 2.6012568923761137e-05\n",
      "Epoch 3691, Loss: 0.03495610207028221, Final Batch Loss: 0.0002589185896795243\n",
      "Epoch 3692, Loss: 0.1729774588930013, Final Batch Loss: 0.17205466330051422\n",
      "Epoch 3693, Loss: 0.0005211474854149856, Final Batch Loss: 2.482104900991544e-05\n",
      "Epoch 3694, Loss: 0.0463113518217142, Final Batch Loss: 2.444477468088735e-05\n",
      "Epoch 3695, Loss: 0.18478373385732993, Final Batch Loss: 0.0004927510744892061\n",
      "Epoch 3696, Loss: 0.28142724419012666, Final Batch Loss: 0.00017976248636841774\n",
      "Epoch 3697, Loss: 0.24698013511624595, Final Batch Loss: 2.6978286769008264e-06\n",
      "Epoch 3698, Loss: 0.046596064523328096, Final Batch Loss: 0.000204203010071069\n",
      "Epoch 3699, Loss: 0.044518965027236845, Final Batch Loss: 0.00011767740215873346\n",
      "Epoch 3700, Loss: 0.01002911108191995, Final Batch Loss: 1.0666083483101829e-07\n",
      "Epoch 3701, Loss: 0.03655667370185256, Final Batch Loss: 0.018604906275868416\n",
      "Epoch 3702, Loss: 0.021813175815623254, Final Batch Loss: 0.00022656115470454097\n",
      "Epoch 3703, Loss: 0.019090328307356685, Final Batch Loss: 0.0007934120367281139\n",
      "Epoch 3704, Loss: 0.025916495447745547, Final Batch Loss: 0.00040145180537365377\n",
      "Epoch 3705, Loss: 0.010739227291196585, Final Batch Loss: 0.006476240698248148\n",
      "Epoch 3706, Loss: 0.020275479007977992, Final Batch Loss: 0.009214084595441818\n",
      "Epoch 3707, Loss: 0.012589226244017482, Final Batch Loss: 0.010601192712783813\n",
      "Epoch 3708, Loss: 0.009350407402962446, Final Batch Loss: 0.004164930433034897\n",
      "Epoch 3709, Loss: 0.009543440424295113, Final Batch Loss: 3.965225459978683e-06\n",
      "Epoch 3710, Loss: 0.006602538545848802, Final Batch Loss: 0.0005801523802801967\n",
      "Epoch 3711, Loss: 0.017097239498980343, Final Batch Loss: 0.005998560693114996\n",
      "Epoch 3712, Loss: 0.004082407336682081, Final Batch Loss: 0.0\n",
      "Epoch 3713, Loss: 0.0019837334077692503, Final Batch Loss: 7.152523266995559e-07\n",
      "Epoch 3714, Loss: 0.0014249568874902252, Final Batch Loss: 6.274157158259186e-07\n",
      "Epoch 3715, Loss: 0.0028851819570263615, Final Batch Loss: 2.9007764169364236e-05\n",
      "Epoch 3716, Loss: 0.014047427073819563, Final Batch Loss: 0.000192415522178635\n",
      "Epoch 3717, Loss: 0.002861103741452098, Final Batch Loss: 0.0012522938195616007\n",
      "Epoch 3718, Loss: 0.006835904481704347, Final Batch Loss: 0.0001353151601506397\n",
      "Epoch 3719, Loss: 0.004377708643005462, Final Batch Loss: 1.934123065439053e-05\n",
      "Epoch 3720, Loss: 0.003394559782464057, Final Batch Loss: 0.000290722178760916\n",
      "Epoch 3721, Loss: 0.013533314631786197, Final Batch Loss: 0.0003658064524643123\n",
      "Epoch 3722, Loss: 0.0021024712732469197, Final Batch Loss: 4.8471290938323364e-05\n",
      "Epoch 3723, Loss: 0.0015900595026323572, Final Batch Loss: 0.00015842502762097865\n",
      "Epoch 3724, Loss: 0.0038784654389019124, Final Batch Loss: 7.8046832641121e-05\n",
      "Epoch 3725, Loss: 0.009565114343786263, Final Batch Loss: 2.4674294763826765e-05\n",
      "Epoch 3726, Loss: 0.009703826797249349, Final Batch Loss: 2.936283181043109e-06\n",
      "Epoch 3727, Loss: 0.00669372707079674, Final Batch Loss: 4.015364083898021e-06\n",
      "Epoch 3728, Loss: 0.0036831553297815844, Final Batch Loss: 5.452909681480378e-05\n",
      "Epoch 3729, Loss: 0.00800372683443129, Final Batch Loss: 0.0009627236286178231\n",
      "Epoch 3730, Loss: 0.004400996007461799, Final Batch Loss: 2.753825901891105e-05\n",
      "Epoch 3731, Loss: 0.0035152690979884937, Final Batch Loss: 0.0001717386330710724\n",
      "Epoch 3732, Loss: 0.0071922252827789634, Final Batch Loss: 0.0002921885752584785\n",
      "Epoch 3733, Loss: 0.0011714914726326242, Final Batch Loss: 9.388466423843056e-05\n",
      "Epoch 3734, Loss: 0.0016809158150863368, Final Batch Loss: 4.04174679715652e-05\n",
      "Epoch 3735, Loss: 0.002768057835055515, Final Batch Loss: 0.0002807781856972724\n",
      "Epoch 3736, Loss: 0.001017320406390354, Final Batch Loss: 0.0003966318035963923\n",
      "Epoch 3737, Loss: 0.004563532769680023, Final Batch Loss: 0.00040834606625139713\n",
      "Epoch 3738, Loss: 0.003308127401396632, Final Batch Loss: 0.002007167087867856\n",
      "Epoch 3739, Loss: 0.004781959643878508, Final Batch Loss: 0.00011830716539407149\n",
      "Epoch 3740, Loss: 0.04200220335042104, Final Batch Loss: 0.000586855283472687\n",
      "Epoch 3741, Loss: 0.0012865039570897352, Final Batch Loss: 4.1053059248952195e-05\n",
      "Epoch 3742, Loss: 0.003008297637279611, Final Batch Loss: 7.406635995721444e-05\n",
      "Epoch 3743, Loss: 0.001963625574717298, Final Batch Loss: 0.0006812793435528874\n",
      "Epoch 3744, Loss: 0.005885105791094247, Final Batch Loss: 8.62000888446346e-06\n",
      "Epoch 3745, Loss: 0.05233982630306855, Final Batch Loss: 0.04714169725775719\n",
      "Epoch 3746, Loss: 0.005049284489359707, Final Batch Loss: 0.0007645190344192088\n",
      "Epoch 3747, Loss: 0.003438586718402803, Final Batch Loss: 0.0004769775550812483\n",
      "Epoch 3748, Loss: 0.0032012102119551855, Final Batch Loss: 1.1925857506867032e-05\n",
      "Epoch 3749, Loss: 0.010291954012359383, Final Batch Loss: 9.913102303471533e-07\n",
      "Epoch 3750, Loss: 0.0160374995903112, Final Batch Loss: 0.011326435953378677\n",
      "Epoch 3751, Loss: 0.004047657566843554, Final Batch Loss: 0.003288833424448967\n",
      "Epoch 3752, Loss: 0.0015322743843171338, Final Batch Loss: 1.0540520634094719e-06\n",
      "Epoch 3753, Loss: 0.002243020193418488, Final Batch Loss: 0.000326423003571108\n",
      "Epoch 3754, Loss: 0.001994366815779358, Final Batch Loss: 0.0009452143567614257\n",
      "Epoch 3755, Loss: 0.0025802910340644303, Final Batch Loss: 1.5748037185403518e-06\n",
      "Epoch 3756, Loss: 0.002267249386932235, Final Batch Loss: 0.0012860603164881468\n",
      "Epoch 3757, Loss: 0.02665553893893957, Final Batch Loss: 0.0015535480342805386\n",
      "Epoch 3758, Loss: 0.0016311143699567765, Final Batch Loss: 0.0003062492178287357\n",
      "Epoch 3759, Loss: 0.0020806538814213127, Final Batch Loss: 0.00038498282083310187\n",
      "Epoch 3760, Loss: 0.0012717009012703784, Final Batch Loss: 6.480277079390362e-05\n",
      "Epoch 3761, Loss: 0.0009784887588466518, Final Batch Loss: 3.092039696639404e-05\n",
      "Epoch 3762, Loss: 0.003946231752536278, Final Batch Loss: 5.270283622849092e-07\n",
      "Epoch 3763, Loss: 0.0038501638582602027, Final Batch Loss: 1.4805725186306518e-05\n",
      "Epoch 3764, Loss: 0.002442293189233169, Final Batch Loss: 0.0002395165793132037\n",
      "Epoch 3765, Loss: 0.0009810636820475338, Final Batch Loss: 3.3252126740990207e-06\n",
      "Epoch 3766, Loss: 0.0006740030921719153, Final Batch Loss: 1.5119393538043369e-05\n",
      "Epoch 3767, Loss: 0.0016113163219415583, Final Batch Loss: 0.00010974737233482301\n",
      "Epoch 3768, Loss: 0.0005366153527575079, Final Batch Loss: 5.922658965573646e-05\n",
      "Epoch 3769, Loss: 0.0037694484053645283, Final Batch Loss: 0.0014802581863477826\n",
      "Epoch 3770, Loss: 0.00545702688395977, Final Batch Loss: 0.003137699794024229\n",
      "Epoch 3771, Loss: 0.005806818255223334, Final Batch Loss: 0.001879665069282055\n",
      "Epoch 3772, Loss: 0.012968719805940054, Final Batch Loss: 1.9033541320823133e-05\n",
      "Epoch 3773, Loss: 0.0019351615919731557, Final Batch Loss: 5.489710019901395e-06\n",
      "Epoch 3774, Loss: 0.001651621307246387, Final Batch Loss: 0.000988953048363328\n",
      "Epoch 3775, Loss: 0.0015498747816309333, Final Batch Loss: 0.00015499454457312822\n",
      "Epoch 3776, Loss: 0.0015289518996723928, Final Batch Loss: 5.171856173546985e-05\n",
      "Epoch 3777, Loss: 0.0009956789581337944, Final Batch Loss: 0.00018299270595889539\n",
      "Epoch 3778, Loss: 0.0006710163961543003, Final Batch Loss: 1.614170651009772e-05\n",
      "Epoch 3779, Loss: 0.0017420794174540788, Final Batch Loss: 0.0001989732845686376\n",
      "Epoch 3780, Loss: 0.0010942086846625898, Final Batch Loss: 5.302782301441766e-05\n",
      "Epoch 3781, Loss: 0.0006828793993918225, Final Batch Loss: 7.741891022305936e-05\n",
      "Epoch 3782, Loss: 0.015298603277187794, Final Batch Loss: 0.008586454205214977\n",
      "Epoch 3783, Loss: 0.0009983846102841198, Final Batch Loss: 0.00018692346930038184\n",
      "Epoch 3784, Loss: 0.000629264910458005, Final Batch Loss: 2.3199585484690033e-05\n",
      "Epoch 3785, Loss: 0.001007289474728168, Final Batch Loss: 8.651428288430907e-06\n",
      "Epoch 3786, Loss: 0.0022018379240762442, Final Batch Loss: 0.0008043782436288893\n",
      "Epoch 3787, Loss: 0.003738853381946683, Final Batch Loss: 0.0005221109604462981\n",
      "Epoch 3788, Loss: 0.0012718682701233774, Final Batch Loss: 0.0001907588157337159\n",
      "Epoch 3789, Loss: 0.0010354143269069027, Final Batch Loss: 5.980360947432928e-05\n",
      "Epoch 3790, Loss: 0.0003925140335923061, Final Batch Loss: 0.00012836104724556208\n",
      "Epoch 3791, Loss: 0.0027647009410429746, Final Batch Loss: 0.00046310637844726443\n",
      "Epoch 3792, Loss: 0.002287922008690657, Final Batch Loss: 0.0008159012068063021\n",
      "Epoch 3793, Loss: 0.0019772176156038768, Final Batch Loss: 4.504733624344226e-06\n",
      "Epoch 3794, Loss: 0.0019115771988253982, Final Batch Loss: 6.763189503544709e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3795, Loss: 0.000297888755085296, Final Batch Loss: 1.2654598322114907e-05\n",
      "Epoch 3796, Loss: 0.0007060707575874403, Final Batch Loss: 0.00039473079959861934\n",
      "Epoch 3797, Loss: 0.0022329199899786545, Final Batch Loss: 7.34075797481637e-07\n",
      "Epoch 3798, Loss: 0.0010597544533084147, Final Batch Loss: 9.43557097343728e-06\n",
      "Epoch 3799, Loss: 0.0011796509716077708, Final Batch Loss: 0.0006729697925038636\n",
      "Epoch 3800, Loss: 0.004029224772239104, Final Batch Loss: 0.0011128197656944394\n",
      "Epoch 3801, Loss: 0.002070009150884289, Final Batch Loss: 1.2503161087806802e-05\n",
      "Epoch 3802, Loss: 0.0025091519819397945, Final Batch Loss: 9.397936082677916e-06\n",
      "Epoch 3803, Loss: 0.00739363384684566, Final Batch Loss: 1.8383017277301406e-06\n",
      "Epoch 3804, Loss: 0.0009006309919641353, Final Batch Loss: 8.508660539519042e-05\n",
      "Epoch 3805, Loss: 0.0007545725020463578, Final Batch Loss: 9.603294165572152e-05\n",
      "Epoch 3806, Loss: 0.0013893645391362952, Final Batch Loss: 7.66026096243877e-06\n",
      "Epoch 3807, Loss: 0.0009249975321097281, Final Batch Loss: 4.5801263581779494e-07\n",
      "Epoch 3808, Loss: 0.006923403627297375, Final Batch Loss: 5.398842768045142e-05\n",
      "Epoch 3809, Loss: 0.022734612980457314, Final Batch Loss: 8.695581527717877e-06\n",
      "Epoch 3810, Loss: 0.0014037038054084405, Final Batch Loss: 0.00033740352955646813\n",
      "Epoch 3811, Loss: 0.000606830338256259, Final Batch Loss: 8.07455671747448e-06\n",
      "Epoch 3812, Loss: 0.00042634580026401636, Final Batch Loss: 4.3291660745126137e-07\n",
      "Epoch 3813, Loss: 0.0021678901958921415, Final Batch Loss: 8.219122946684365e-07\n",
      "Epoch 3814, Loss: 0.018185220658658352, Final Batch Loss: 1.1920916875851617e-07\n",
      "Epoch 3815, Loss: 0.00044283142779022455, Final Batch Loss: 9.07935609575361e-05\n",
      "Epoch 3816, Loss: 0.0015406786333187483, Final Batch Loss: 2.8115427994634956e-05\n",
      "Epoch 3817, Loss: 0.004218246802338399, Final Batch Loss: 0.003666060045361519\n",
      "Epoch 3818, Loss: 0.001141382375720923, Final Batch Loss: 4.64287808199515e-07\n",
      "Epoch 3819, Loss: 0.0011356750947015826, Final Batch Loss: 3.693587859743275e-05\n",
      "Epoch 3820, Loss: 0.0013881862523703603, Final Batch Loss: 2.2720150809618644e-05\n",
      "Epoch 3821, Loss: 0.0005237653179221979, Final Batch Loss: 3.639009094058565e-07\n",
      "Epoch 3822, Loss: 0.001642675247239822, Final Batch Loss: 5.521177627088036e-06\n",
      "Epoch 3823, Loss: 0.002221260336227715, Final Batch Loss: 0.0002584775211289525\n",
      "Epoch 3824, Loss: 0.036554956634063274, Final Batch Loss: 0.0344933420419693\n",
      "Epoch 3825, Loss: 0.0007799180020811036, Final Batch Loss: 0.00012088092626072466\n",
      "Epoch 3826, Loss: 0.009862377031822689, Final Batch Loss: 0.00019744562450796366\n",
      "Epoch 3827, Loss: 0.015374807375792443, Final Batch Loss: 2.6288403205398936e-06\n",
      "Epoch 3828, Loss: 0.00438075014972128, Final Batch Loss: 5.2972492994740605e-05\n",
      "Epoch 3829, Loss: 0.0016877856978680938, Final Batch Loss: 0.0003834097005892545\n",
      "Epoch 3830, Loss: 0.0006605369194403465, Final Batch Loss: 5.828427219967125e-06\n",
      "Epoch 3831, Loss: 0.0011934310387005098, Final Batch Loss: 0.00010516972542973235\n",
      "Epoch 3832, Loss: 0.0004812122897419613, Final Batch Loss: 1.8218426703242585e-05\n",
      "Epoch 3833, Loss: 0.01740109286038205, Final Batch Loss: 0.0002744066878221929\n",
      "Epoch 3834, Loss: 0.008162947924574837, Final Batch Loss: 3.608522820286453e-05\n",
      "Epoch 3835, Loss: 0.0004906017358621284, Final Batch Loss: 6.650599857493944e-07\n",
      "Epoch 3836, Loss: 0.003606658603530377, Final Batch Loss: 0.00021254712191876024\n",
      "Epoch 3837, Loss: 0.00035295169800519943, Final Batch Loss: 7.431249832734466e-05\n",
      "Epoch 3838, Loss: 0.0003843785816570744, Final Batch Loss: 3.664792893687263e-05\n",
      "Epoch 3839, Loss: 0.0035588372822985548, Final Batch Loss: 1.6940005025389837e-06\n",
      "Epoch 3840, Loss: 0.0008912915218388662, Final Batch Loss: 0.00036623302730731666\n",
      "Epoch 3841, Loss: 0.0009791123447939754, Final Batch Loss: 6.885267794132233e-05\n",
      "Epoch 3842, Loss: 0.0005149982424654809, Final Batch Loss: 1.5748008763694088e-06\n",
      "Epoch 3843, Loss: 0.0006025588627380785, Final Batch Loss: 0.0002896295627579093\n",
      "Epoch 3844, Loss: 0.0039691553538432345, Final Batch Loss: 0.0019894621800631285\n",
      "Epoch 3845, Loss: 0.0010557192581472918, Final Batch Loss: 7.347796054091305e-05\n",
      "Epoch 3846, Loss: 0.0012278745629998866, Final Batch Loss: 1.3803170872961346e-07\n",
      "Epoch 3847, Loss: 0.0020294050948805875, Final Batch Loss: 8.783835170333987e-08\n",
      "Epoch 3848, Loss: 0.0027612742085381115, Final Batch Loss: 6.901588278651616e-08\n",
      "Epoch 3849, Loss: 0.0006058513317839243, Final Batch Loss: 0.00013098651834297925\n",
      "Epoch 3850, Loss: 0.0026724991548690014, Final Batch Loss: 1.9943443476222456e-05\n",
      "Epoch 3851, Loss: 0.0005780112073807686, Final Batch Loss: 3.9965048017620575e-06\n",
      "Epoch 3852, Loss: 0.02858507671226107, Final Batch Loss: 9.059587682713754e-06\n",
      "Epoch 3853, Loss: 0.0028645846687140875, Final Batch Loss: 0.0005729920812882483\n",
      "Epoch 3854, Loss: 0.00024436590161514005, Final Batch Loss: 7.529002488126935e-08\n",
      "Epoch 3855, Loss: 0.0001017859131025034, Final Batch Loss: 9.072165084944572e-06\n",
      "Epoch 3856, Loss: 0.00559736004925071, Final Batch Loss: 1.0257625945087057e-05\n",
      "Epoch 3857, Loss: 0.0012890341968159191, Final Batch Loss: 0.00021627247042488307\n",
      "Epoch 3858, Loss: 0.00038135970680741593, Final Batch Loss: 2.014436904573813e-05\n",
      "Epoch 3859, Loss: 0.0007121389917301713, Final Batch Loss: 1.4416942576644942e-05\n",
      "Epoch 3860, Loss: 0.002442795434035361, Final Batch Loss: 0.0006712105823680758\n",
      "Epoch 3861, Loss: 0.0003256217351008672, Final Batch Loss: 1.4360837667481974e-05\n",
      "Epoch 3862, Loss: 0.0013216765410106746, Final Batch Loss: 3.613870831031818e-06\n",
      "Epoch 3863, Loss: 0.000641945684037637, Final Batch Loss: 6.0303449572529644e-05\n",
      "Epoch 3864, Loss: 0.0007492978111258708, Final Batch Loss: 0.00011002344399457797\n",
      "Epoch 3865, Loss: 0.0005637768681481248, Final Batch Loss: 1.9019926185137592e-05\n",
      "Epoch 3866, Loss: 0.0002248880500701489, Final Batch Loss: 9.830930139287375e-06\n",
      "Epoch 3867, Loss: 0.000774600169279438, Final Batch Loss: 8.156149306159932e-06\n",
      "Epoch 3868, Loss: 0.0005798223282909021, Final Batch Loss: 0.0002507451281417161\n",
      "Epoch 3869, Loss: 0.00043224187356827315, Final Batch Loss: 3.532242772052996e-06\n",
      "Epoch 3870, Loss: 0.0005830320878885686, Final Batch Loss: 0.00037324128788895905\n",
      "Epoch 3871, Loss: 0.0010390940988145303, Final Batch Loss: 0.00030616033473052084\n",
      "Epoch 3872, Loss: 0.015244435267959489, Final Batch Loss: 0.00038255765684880316\n",
      "Epoch 3873, Loss: 0.00031374355967273004, Final Batch Loss: 3.683065369841643e-05\n",
      "Epoch 3874, Loss: 0.0015198419714579359, Final Batch Loss: 0.0008173629175871611\n",
      "Epoch 3875, Loss: 0.0012818203122151317, Final Batch Loss: 2.4773466066108085e-05\n",
      "Epoch 3876, Loss: 0.0004057540008943761, Final Batch Loss: 2.8291187845752575e-05\n",
      "Epoch 3877, Loss: 0.0007337373899645172, Final Batch Loss: 9.22694816836156e-05\n",
      "Epoch 3878, Loss: 0.002102543885257546, Final Batch Loss: 2.9613672722916817e-06\n",
      "Epoch 3879, Loss: 0.011585296917473897, Final Batch Loss: 0.00012055187835358083\n",
      "Epoch 3880, Loss: 0.0014759198456886224, Final Batch Loss: 0.0009209653944708407\n",
      "Epoch 3881, Loss: 0.0030050052810111083, Final Batch Loss: 3.45051012118347e-05\n",
      "Epoch 3882, Loss: 0.007751599776383955, Final Batch Loss: 3.366171586094424e-05\n",
      "Epoch 3883, Loss: 0.0004970329887328262, Final Batch Loss: 5.847380180057371e-06\n",
      "Epoch 3884, Loss: 0.0006591725104954094, Final Batch Loss: 0.0001512472954345867\n",
      "Epoch 3885, Loss: 0.00043984022704535164, Final Batch Loss: 1.538844298920594e-05\n",
      "Epoch 3886, Loss: 0.0008405082826357102, Final Batch Loss: 2.3685946871410124e-05\n",
      "Epoch 3887, Loss: 0.0006124651190475561, Final Batch Loss: 9.381156269228086e-05\n",
      "Epoch 3888, Loss: 0.0011192458841833286, Final Batch Loss: 0.00030519920983351767\n",
      "Epoch 3889, Loss: 0.0007240633576657274, Final Batch Loss: 5.194918230699841e-06\n",
      "Epoch 3890, Loss: 0.0026963561613229103, Final Batch Loss: 0.002577188890427351\n",
      "Epoch 3891, Loss: 0.00015053502897899307, Final Batch Loss: 1.3928499811299844e-06\n",
      "Epoch 3892, Loss: 0.0008676052384544164, Final Batch Loss: 0.00023217192210722715\n",
      "Epoch 3893, Loss: 0.000572370453255644, Final Batch Loss: 2.1269231638143538e-06\n",
      "Epoch 3894, Loss: 0.001089155493900762, Final Batch Loss: 3.0258577680797316e-05\n",
      "Epoch 3895, Loss: 0.0006647854897892103, Final Batch Loss: 0.000382082536816597\n",
      "Epoch 3896, Loss: 0.0016288314436678775, Final Batch Loss: 9.875082469079643e-06\n",
      "Epoch 3897, Loss: 0.0003091756589128636, Final Batch Loss: 3.11038747895509e-05\n",
      "Epoch 3898, Loss: 5.8791277751879534e-05, Final Batch Loss: 3.5887592275685165e-06\n",
      "Epoch 3899, Loss: 0.00036636649747379124, Final Batch Loss: 9.448797209188342e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3900, Loss: 0.0004049044867997509, Final Batch Loss: 1.3803162346448516e-07\n",
      "Epoch 3901, Loss: 0.0016470063801534707, Final Batch Loss: 2.8263917556614615e-05\n",
      "Epoch 3902, Loss: 0.001682136320596328, Final Batch Loss: 3.244694016757421e-05\n",
      "Epoch 3903, Loss: 0.0012094510602764785, Final Batch Loss: 0.0006224040407687426\n",
      "Epoch 3904, Loss: 0.0006208075781160005, Final Batch Loss: 9.222992503055139e-07\n",
      "Epoch 3905, Loss: 0.00016577407524209775, Final Batch Loss: 8.783837301962194e-08\n",
      "Epoch 3906, Loss: 0.0008211402607685159, Final Batch Loss: 7.905407528596697e-07\n",
      "Epoch 3907, Loss: 0.00015204135479507386, Final Batch Loss: 6.506106274173362e-06\n",
      "Epoch 3908, Loss: 0.0006952754483791068, Final Batch Loss: 0.00012561859330162406\n",
      "Epoch 3909, Loss: 0.00043427726359368535, Final Batch Loss: 1.2377608982205857e-05\n",
      "Epoch 3910, Loss: 0.00030673859146190807, Final Batch Loss: 1.3312128430698067e-05\n",
      "Epoch 3911, Loss: 0.0005661836949002463, Final Batch Loss: 5.606803824775852e-05\n",
      "Epoch 3912, Loss: 0.0003459921996977755, Final Batch Loss: 6.838806143605325e-07\n",
      "Epoch 3913, Loss: 0.00024529784582227876, Final Batch Loss: 2.4719827251828974e-06\n",
      "Epoch 3914, Loss: 0.0006846003854654725, Final Batch Loss: 5.019337478984198e-08\n",
      "Epoch 3915, Loss: 0.02437948449369287, Final Batch Loss: 2.436382055748254e-05\n",
      "Epoch 3916, Loss: 0.00016980074167349812, Final Batch Loss: 1.2360050050119753e-06\n",
      "Epoch 3917, Loss: 0.0005057618684531917, Final Batch Loss: 2.0076979581062915e-06\n",
      "Epoch 3918, Loss: 0.008438495115115074, Final Batch Loss: 7.0142959884833544e-06\n",
      "Epoch 3919, Loss: 0.0008164622877302463, Final Batch Loss: 1.4378444575413596e-05\n",
      "Epoch 3920, Loss: 0.00029801902473991504, Final Batch Loss: 1.254057769983774e-05\n",
      "Epoch 3921, Loss: 0.001638274930883199, Final Batch Loss: 0.000498086039442569\n",
      "Epoch 3922, Loss: 0.000455897281341322, Final Batch Loss: 1.4430580108637514e-07\n",
      "Epoch 3923, Loss: 0.00045513640907302033, Final Batch Loss: 2.1842291971552186e-05\n",
      "Epoch 3924, Loss: 0.0003715161219588481, Final Batch Loss: 2.58493673754856e-06\n",
      "Epoch 3925, Loss: 0.0017467009665779187, Final Batch Loss: 1.0934752026514616e-05\n",
      "Epoch 3926, Loss: 0.0007417297187686245, Final Batch Loss: 1.2548339611839765e-07\n",
      "Epoch 3927, Loss: 0.0015532672696281224, Final Batch Loss: 0.00015618900943081826\n",
      "Epoch 3928, Loss: 0.0014877297580824234, Final Batch Loss: 0.0007140662055462599\n",
      "Epoch 3929, Loss: 9.220977383472828e-05, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 3930, Loss: 0.05047505741822533, Final Batch Loss: 2.9652335797436535e-05\n",
      "Epoch 3931, Loss: 0.0012711076124105603, Final Batch Loss: 0.0006927170907147229\n",
      "Epoch 3932, Loss: 0.00046758486592057835, Final Batch Loss: 1.2548345473817335e-08\n",
      "Epoch 3933, Loss: 0.008444783814411494, Final Batch Loss: 1.1455636922619306e-05\n",
      "Epoch 3934, Loss: 0.01201737441624573, Final Batch Loss: 1.9691355191753246e-05\n",
      "Epoch 3935, Loss: 0.00044833841440095057, Final Batch Loss: 8.532841206942976e-07\n",
      "Epoch 3936, Loss: 0.0006167299925436964, Final Batch Loss: 3.218554411432706e-06\n",
      "Epoch 3937, Loss: 0.0022199447121238336, Final Batch Loss: 8.92811658559367e-05\n",
      "Epoch 3938, Loss: 0.02243758701297338, Final Batch Loss: 4.664684456656687e-05\n",
      "Epoch 3939, Loss: 0.0025641715692472644, Final Batch Loss: 8.174964023055509e-06\n",
      "Epoch 3940, Loss: 0.000473932838303881, Final Batch Loss: 6.286575171543518e-06\n",
      "Epoch 3941, Loss: 0.0018531103405621252, Final Batch Loss: 7.221256055345293e-06\n",
      "Epoch 3942, Loss: 0.0003146726470504291, Final Batch Loss: 1.2924668908453896e-06\n",
      "Epoch 3943, Loss: 0.0013004942302359268, Final Batch Loss: 0.00013440898328553885\n",
      "Epoch 3944, Loss: 0.0020659117001144978, Final Batch Loss: 2.195958899164907e-07\n",
      "Epoch 3945, Loss: 0.0004835255786019843, Final Batch Loss: 5.427042560768314e-05\n",
      "Epoch 3946, Loss: 0.0012684286912190146, Final Batch Loss: 1.2171794878668152e-06\n",
      "Epoch 3947, Loss: 0.0008165584549715277, Final Batch Loss: 5.776599209639244e-05\n",
      "Epoch 3948, Loss: 0.0035015480825677514, Final Batch Loss: 0.0007392491679638624\n",
      "Epoch 3949, Loss: 0.0008437536453129724, Final Batch Loss: 0.000135741094709374\n",
      "Epoch 3950, Loss: 0.001828386913985014, Final Batch Loss: 0.00047341763274744153\n",
      "Epoch 3951, Loss: 0.0007887914628099679, Final Batch Loss: 1.8132207060261862e-06\n",
      "Epoch 3952, Loss: 0.0012087728368896933, Final Batch Loss: 1.010133473755559e-06\n",
      "Epoch 3953, Loss: 0.0011314458399738214, Final Batch Loss: 1.9198644167772727e-06\n",
      "Epoch 3954, Loss: 0.0016247211606241763, Final Batch Loss: 5.5354044889099896e-05\n",
      "Epoch 3955, Loss: 0.0024069028186204378, Final Batch Loss: 5.551748108700849e-05\n",
      "Epoch 3956, Loss: 0.0002687708183657378, Final Batch Loss: 0.0\n",
      "Epoch 3957, Loss: 0.0019230147315738577, Final Batch Loss: 3.394257646505139e-06\n",
      "Epoch 3958, Loss: 0.0007764103938825428, Final Batch Loss: 1.8495062249712646e-05\n",
      "Epoch 3959, Loss: 0.0002248192857337017, Final Batch Loss: 6.525104367938184e-07\n",
      "Epoch 3960, Loss: 0.0003903742635884555, Final Batch Loss: 8.977616744232364e-06\n",
      "Epoch 3961, Loss: 0.0010281304130330682, Final Batch Loss: 0.0007521279039792717\n",
      "Epoch 3962, Loss: 0.0009851180802797899, Final Batch Loss: 0.000525470357388258\n",
      "Epoch 3963, Loss: 0.000831959187053144, Final Batch Loss: 3.2653173548169434e-05\n",
      "Epoch 3964, Loss: 0.01940830187049869, Final Batch Loss: 7.955253749969415e-06\n",
      "Epoch 3965, Loss: 0.0027079337655777636, Final Batch Loss: 6.719250905007357e-06\n",
      "Epoch 3966, Loss: 0.0006721825843669649, Final Batch Loss: 4.5612027861352544e-06\n",
      "Epoch 3967, Loss: 0.0003784833431836887, Final Batch Loss: 3.707934183694306e-06\n",
      "Epoch 3968, Loss: 0.003077573230257258, Final Batch Loss: 0.0021372754126787186\n",
      "Epoch 3969, Loss: 0.0005965349764665007, Final Batch Loss: 1.4259922863857355e-05\n",
      "Epoch 3970, Loss: 0.03235475491237594, Final Batch Loss: 0.0015657031908631325\n",
      "Epoch 3971, Loss: 0.0021337992634471448, Final Batch Loss: 7.064341389195761e-06\n",
      "Epoch 3972, Loss: 0.0024754201531322906, Final Batch Loss: 2.3904085537651554e-06\n",
      "Epoch 3973, Loss: 0.0003559816463933885, Final Batch Loss: 1.3803172294046817e-07\n",
      "Epoch 3974, Loss: 0.0016576206253375858, Final Batch Loss: 0.00010158747318200767\n",
      "Epoch 3975, Loss: 0.001366485572361853, Final Batch Loss: 0.00011234499834245071\n",
      "Epoch 3976, Loss: 0.0011882580001838505, Final Batch Loss: 0.0006098416051827371\n",
      "Epoch 3977, Loss: 0.0009283820199925685, Final Batch Loss: 4.630166586139239e-06\n",
      "Epoch 3978, Loss: 0.00045564469837700017, Final Batch Loss: 3.2249696232611313e-05\n",
      "Epoch 3979, Loss: 0.0004469923480279192, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 3980, Loss: 0.007390262726403307, Final Batch Loss: 0.006740476004779339\n",
      "Epoch 3981, Loss: 0.0005842423988724477, Final Batch Loss: 1.1293441275483929e-06\n",
      "Epoch 3982, Loss: 0.00037379245316060405, Final Batch Loss: 8.030880280784913e-07\n",
      "Epoch 3983, Loss: 0.0003170483944359148, Final Batch Loss: 3.469544253675849e-06\n",
      "Epoch 3984, Loss: 0.0004331308452947269, Final Batch Loss: 2.3527688881586073e-06\n",
      "Epoch 3985, Loss: 0.0010579803492873907, Final Batch Loss: 0.0004536602646112442\n",
      "Epoch 3986, Loss: 0.0013186379219405353, Final Batch Loss: 0.0007562950486317277\n",
      "Epoch 3987, Loss: 0.0006722744033709205, Final Batch Loss: 2.8861137479907484e-07\n",
      "Epoch 3988, Loss: 0.0002669046261871699, Final Batch Loss: 5.58373358217068e-06\n",
      "Epoch 3989, Loss: 0.00037411237900641936, Final Batch Loss: 5.395766606852703e-07\n",
      "Epoch 3990, Loss: 0.0007026875864539761, Final Batch Loss: 1.7779257177608088e-05\n",
      "Epoch 3991, Loss: 0.0014392958546523005, Final Batch Loss: 0.0011631364468485117\n",
      "Epoch 3992, Loss: 0.001374162602587603, Final Batch Loss: 0.0008751862915232778\n",
      "Epoch 3993, Loss: 0.033993823279161006, Final Batch Loss: 0.0003950546379201114\n",
      "Epoch 3994, Loss: 0.00039126724732341245, Final Batch Loss: 0.00019778407295234501\n",
      "Epoch 3995, Loss: 0.0004502663540222329, Final Batch Loss: 4.517386003044521e-07\n",
      "Epoch 3996, Loss: 0.005331693420885131, Final Batch Loss: 0.0011827651178464293\n",
      "Epoch 3997, Loss: 0.0009824288221693678, Final Batch Loss: 2.6351466431151493e-07\n",
      "Epoch 3998, Loss: 0.03997570748379076, Final Batch Loss: 8.06834486866137e-06\n",
      "Epoch 3999, Loss: 0.0008657718374251999, Final Batch Loss: 2.170820380342775e-06\n",
      "Epoch 4000, Loss: 0.0007212636373878922, Final Batch Loss: 4.887460818281397e-06\n",
      "Epoch 4001, Loss: 0.002193168141275237, Final Batch Loss: 1.2302873983571772e-05\n",
      "Epoch 4002, Loss: 0.0006068390794098377, Final Batch Loss: 0.00043289578752592206\n",
      "Epoch 4003, Loss: 0.0011922438825422432, Final Batch Loss: 4.9626432883087546e-06\n",
      "Epoch 4004, Loss: 0.0002761131981969811, Final Batch Loss: 1.707080809865147e-05\n",
      "Epoch 4005, Loss: 0.0006981547137456801, Final Batch Loss: 1.1669851573969936e-06\n",
      "Epoch 4006, Loss: 0.00026492480651540973, Final Batch Loss: 2.823373961291509e-07\n",
      "Epoch 4007, Loss: 0.0007488437986467034, Final Batch Loss: 0.0001648622564971447\n",
      "Epoch 4008, Loss: 0.0004941119295835961, Final Batch Loss: 5.14158200530801e-05\n",
      "Epoch 4009, Loss: 0.0003098522622622113, Final Batch Loss: 8.846520813676761e-07\n",
      "Epoch 4010, Loss: 0.006697119527188988, Final Batch Loss: 2.3966938442754326e-06\n",
      "Epoch 4011, Loss: 0.00032517205249860126, Final Batch Loss: 3.3001531392073957e-06\n",
      "Epoch 4012, Loss: 0.00043830461263638654, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4013, Loss: 0.0008418980933129205, Final Batch Loss: 7.923735211079475e-06\n",
      "Epoch 4014, Loss: 0.0013408975501079112, Final Batch Loss: 0.0003211099829059094\n",
      "Epoch 4015, Loss: 0.000798676919657737, Final Batch Loss: 0.0004843386705033481\n",
      "Epoch 4016, Loss: 0.00021675180596503196, Final Batch Loss: 1.3997104360896628e-05\n",
      "Epoch 4017, Loss: 0.0006420139435476813, Final Batch Loss: 7.779927955198218e-07\n",
      "Epoch 4018, Loss: 0.0016609715385129675, Final Batch Loss: 0.00019173677719663829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4019, Loss: 0.00025759154959814623, Final Batch Loss: 0.0\n",
      "Epoch 4020, Loss: 0.00032775150457808877, Final Batch Loss: 7.529006751383349e-08\n",
      "Epoch 4021, Loss: 0.0035713608067453606, Final Batch Loss: 7.729226126684807e-06\n",
      "Epoch 4022, Loss: 0.00017441218506064615, Final Batch Loss: 4.6490908971463796e-06\n",
      "Epoch 4023, Loss: 0.00037603078089887276, Final Batch Loss: 4.7258301492547616e-05\n",
      "Epoch 4024, Loss: 0.002626152365337475, Final Batch Loss: 0.0019123901147395372\n",
      "Epoch 4025, Loss: 0.0011456905558588915, Final Batch Loss: 0.00010453067807247862\n",
      "Epoch 4026, Loss: 0.0012221158540342003, Final Batch Loss: 0.0003431983641348779\n",
      "Epoch 4027, Loss: 0.0026918746589217335, Final Batch Loss: 0.00040176461334340274\n",
      "Epoch 4028, Loss: 0.015447837940882891, Final Batch Loss: 0.001648562727496028\n",
      "Epoch 4029, Loss: 0.0003004170624549829, Final Batch Loss: 1.1293500534748091e-07\n",
      "Epoch 4030, Loss: 0.0032649069362378214, Final Batch Loss: 0.0001496877521276474\n",
      "Epoch 4031, Loss: 0.0008977428478829097, Final Batch Loss: 4.1656570829218253e-05\n",
      "Epoch 4032, Loss: 0.0006346083391690627, Final Batch Loss: 0.0\n",
      "Epoch 4033, Loss: 0.0013574724434874952, Final Batch Loss: 0.0003124181239400059\n",
      "Epoch 4034, Loss: 0.0010650638596132467, Final Batch Loss: 2.4469224513268273e-07\n",
      "Epoch 4035, Loss: 0.015636451417776698, Final Batch Loss: 9.460657565796282e-06\n",
      "Epoch 4036, Loss: 0.00027584499184740707, Final Batch Loss: 7.992690370883793e-06\n",
      "Epoch 4037, Loss: 0.0006936864847375546, Final Batch Loss: 5.876248542335816e-05\n",
      "Epoch 4038, Loss: 0.00031941802740220737, Final Batch Loss: 3.6138656014372827e-06\n",
      "Epoch 4039, Loss: 0.0008321901241288288, Final Batch Loss: 1.823063757910859e-05\n",
      "Epoch 4040, Loss: 0.000623074936811463, Final Batch Loss: 2.121712350344751e-05\n",
      "Epoch 4041, Loss: 0.0012317551618252764, Final Batch Loss: 1.3556741578213405e-05\n",
      "Epoch 4042, Loss: 0.004862822868517469, Final Batch Loss: 2.929984248112305e-06\n",
      "Epoch 4043, Loss: 0.000879222430739901, Final Batch Loss: 1.2158116078353487e-05\n",
      "Epoch 4044, Loss: 0.0018813658562066848, Final Batch Loss: 2.0704737835330889e-07\n",
      "Epoch 4045, Loss: 0.0005294997890814557, Final Batch Loss: 8.858459295879584e-06\n",
      "Epoch 4046, Loss: 0.004912890843115747, Final Batch Loss: 0.00025369576178491116\n",
      "Epoch 4047, Loss: 0.0004570573219098151, Final Batch Loss: 0.00020497979130595922\n",
      "Epoch 4048, Loss: 0.0026199834128419752, Final Batch Loss: 8.776844879321288e-06\n",
      "Epoch 4049, Loss: 0.0009757663938216865, Final Batch Loss: 0.00016936527390498668\n",
      "Epoch 4050, Loss: 0.00047702082520117983, Final Batch Loss: 4.142378020333126e-05\n",
      "Epoch 4051, Loss: 0.00026808278107637307, Final Batch Loss: 1.5163014722929802e-05\n",
      "Epoch 4052, Loss: 0.00039452394148042913, Final Batch Loss: 4.329168348249368e-07\n",
      "Epoch 4053, Loss: 0.0007776523707434535, Final Batch Loss: 0.00010321244189981371\n",
      "Epoch 4054, Loss: 0.0013285029536973525, Final Batch Loss: 1.3050131428826717e-06\n",
      "Epoch 4055, Loss: 0.0013523697321602413, Final Batch Loss: 3.13707971599797e-07\n",
      "Epoch 4056, Loss: 0.0019729611558432225, Final Batch Loss: 4.5111682993592694e-05\n",
      "Epoch 4057, Loss: 0.0013035432448305073, Final Batch Loss: 7.164630915212911e-06\n",
      "Epoch 4058, Loss: 0.0007544840387936347, Final Batch Loss: 1.0666022944860742e-06\n",
      "Epoch 4059, Loss: 0.0003378937208253774, Final Batch Loss: 5.14288512931671e-05\n",
      "Epoch 4060, Loss: 0.00029494658190287737, Final Batch Loss: 1.8320446315556183e-06\n",
      "Epoch 4061, Loss: 0.010718233068473637, Final Batch Loss: 0.00012469642388168722\n",
      "Epoch 4062, Loss: 0.0011956666930927895, Final Batch Loss: 0.0009765480645000935\n",
      "Epoch 4063, Loss: 0.00027600221073953435, Final Batch Loss: 4.084040119778365e-05\n",
      "Epoch 4064, Loss: 0.0008859966076215642, Final Batch Loss: 3.287616209490807e-06\n",
      "Epoch 4065, Loss: 0.0020844568862230517, Final Batch Loss: 2.8119808121118695e-05\n",
      "Epoch 4066, Loss: 0.003492542934640852, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4067, Loss: 0.0007654716787328653, Final Batch Loss: 6.204983492352767e-06\n",
      "Epoch 4068, Loss: 0.0010089275638165418, Final Batch Loss: 0.0003745469730347395\n",
      "Epoch 4069, Loss: 0.027421167793363566, Final Batch Loss: 0.0003298997471574694\n",
      "Epoch 4070, Loss: 0.00046578722535173256, Final Batch Loss: 2.9488577979464026e-07\n",
      "Epoch 4071, Loss: 0.0016192257271541166, Final Batch Loss: 1.392108515574364e-05\n",
      "Epoch 4072, Loss: 0.0005258501332718879, Final Batch Loss: 0.00017296607256866992\n",
      "Epoch 4073, Loss: 0.017195475666085258, Final Batch Loss: 7.577321957796812e-05\n",
      "Epoch 4074, Loss: 0.0011005672536157363, Final Batch Loss: 7.32148737370153e-06\n",
      "Epoch 4075, Loss: 0.0004744819625557284, Final Batch Loss: 6.62520596961258e-06\n",
      "Epoch 4076, Loss: 0.018237642039821367, Final Batch Loss: 1.9741228243219666e-05\n",
      "Epoch 4077, Loss: 0.0013446677330648527, Final Batch Loss: 0.0003273072943557054\n",
      "Epoch 4078, Loss: 0.0006573366022166738, Final Batch Loss: 7.12102109901025e-06\n",
      "Epoch 4079, Loss: 0.0012496390030918292, Final Batch Loss: 1.7567656129813258e-07\n",
      "Epoch 4080, Loss: 0.006564523067027039, Final Batch Loss: 1.5163011084950995e-05\n",
      "Epoch 4081, Loss: 0.0005673775165178085, Final Batch Loss: 2.13319503927778e-06\n",
      "Epoch 4082, Loss: 0.008842440611033453, Final Batch Loss: 3.2122895845532184e-06\n",
      "Epoch 4083, Loss: 0.018310412793653086, Final Batch Loss: 0.018028104677796364\n",
      "Epoch 4084, Loss: 0.014830091598696526, Final Batch Loss: 1.5497005279030418e-06\n",
      "Epoch 4085, Loss: 0.0010108990009030094, Final Batch Loss: 2.6253581381752156e-05\n",
      "Epoch 4086, Loss: 0.002116889092576457, Final Batch Loss: 9.448482160223648e-06\n",
      "Epoch 4087, Loss: 0.00412170980416704, Final Batch Loss: 0.0002993600501213223\n",
      "Epoch 4088, Loss: 0.002153607737909624, Final Batch Loss: 4.943938165524742e-06\n",
      "Epoch 4089, Loss: 0.001561446231789887, Final Batch Loss: 0.00037682155380025506\n",
      "Epoch 4090, Loss: 0.00043955065484624356, Final Batch Loss: 6.88213185640052e-05\n",
      "Epoch 4091, Loss: 0.0008610011864220724, Final Batch Loss: 0.0001448054244974628\n",
      "Epoch 4092, Loss: 0.0016428056551376358, Final Batch Loss: 0.00012673130549956113\n",
      "Epoch 4093, Loss: 0.0011532416538102552, Final Batch Loss: 0.00043503352208063006\n",
      "Epoch 4094, Loss: 0.001780735510692466, Final Batch Loss: 7.27942751836963e-05\n",
      "Epoch 4095, Loss: 0.0009468412426940631, Final Batch Loss: 6.007054980727844e-05\n",
      "Epoch 4096, Loss: 0.002785620052577542, Final Batch Loss: 4.956585826221271e-07\n",
      "Epoch 4097, Loss: 0.001577333038312645, Final Batch Loss: 7.37797790861805e-06\n",
      "Epoch 4098, Loss: 0.0006523049662519043, Final Batch Loss: 2.315143547093612e-06\n",
      "Epoch 4099, Loss: 0.000531247356093445, Final Batch Loss: 8.846520813676761e-07\n",
      "Epoch 4100, Loss: 0.001982609523111023, Final Batch Loss: 0.00023272530233953148\n",
      "Epoch 4101, Loss: 0.0006287236319622025, Final Batch Loss: 3.6195124266669154e-05\n",
      "Epoch 4102, Loss: 0.0017088211316149682, Final Batch Loss: 0.00034103920916095376\n",
      "Epoch 4103, Loss: 0.0007073132219375111, Final Batch Loss: 8.659953164169565e-05\n",
      "Epoch 4104, Loss: 0.0011669445630104747, Final Batch Loss: 3.04112872981932e-05\n",
      "Epoch 4105, Loss: 0.0013190709141781554, Final Batch Loss: 0.0005619022995233536\n",
      "Epoch 4106, Loss: 0.0036504877671177383, Final Batch Loss: 1.4718173588335048e-05\n",
      "Epoch 4107, Loss: 0.0006238331989152357, Final Batch Loss: 2.2350752260535955e-05\n",
      "Epoch 4108, Loss: 0.003933624046283057, Final Batch Loss: 8.156368380696222e-07\n",
      "Epoch 4109, Loss: 0.003517303994158283, Final Batch Loss: 0.002373216673731804\n",
      "Epoch 4110, Loss: 0.0007883962791197519, Final Batch Loss: 6.713345896969258e-07\n",
      "Epoch 4111, Loss: 0.0008228640863308101, Final Batch Loss: 8.425608939433005e-06\n",
      "Epoch 4112, Loss: 0.0019681553885675385, Final Batch Loss: 4.648994035960641e-06\n",
      "Epoch 4113, Loss: 0.0004712784652838309, Final Batch Loss: 7.215280675154645e-07\n",
      "Epoch 4114, Loss: 0.0007516213863709709, Final Batch Loss: 4.630206603906117e-06\n",
      "Epoch 4115, Loss: 0.0004241286396791111, Final Batch Loss: 1.0169739653065335e-05\n",
      "Epoch 4116, Loss: 0.0026580273115541786, Final Batch Loss: 0.0015722829848527908\n",
      "Epoch 4117, Loss: 0.0010452839633217081, Final Batch Loss: 0.00013763061724603176\n",
      "Epoch 4118, Loss: 0.0010404689674032852, Final Batch Loss: 0.0005463962443172932\n",
      "Epoch 4119, Loss: 0.0029525151585403364, Final Batch Loss: 1.7848851712187752e-05\n",
      "Epoch 4120, Loss: 0.0007565285976909308, Final Batch Loss: 4.140946714414895e-07\n",
      "Epoch 4121, Loss: 0.00029571174491138663, Final Batch Loss: 5.608946594293229e-06\n",
      "Epoch 4122, Loss: 0.007289226108696312, Final Batch Loss: 2.8605631086975336e-05\n",
      "Epoch 4123, Loss: 0.0005204855842748657, Final Batch Loss: 8.205289486795664e-05\n",
      "Epoch 4124, Loss: 0.0004739670912385918, Final Batch Loss: 3.145026130368933e-05\n",
      "Epoch 4125, Loss: 0.00048494358721029585, Final Batch Loss: 1.8195073892002256e-07\n",
      "Epoch 4126, Loss: 0.0012927475981996395, Final Batch Loss: 3.431333607295528e-05\n",
      "Epoch 4127, Loss: 0.0008721240010345355, Final Batch Loss: 0.00043699354864656925\n",
      "Epoch 4128, Loss: 0.0010086256224894896, Final Batch Loss: 0.0006364904693327844\n",
      "Epoch 4129, Loss: 0.0037949185352772474, Final Batch Loss: 0.0001484542735852301\n",
      "Epoch 4130, Loss: 0.00955707358662039, Final Batch Loss: 0.003094191662967205\n",
      "Epoch 4131, Loss: 0.012467384178307839, Final Batch Loss: 9.009068890009075e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4132, Loss: 0.0002887659642425433, Final Batch Loss: 2.384180248782286e-07\n",
      "Epoch 4133, Loss: 0.0005924461038375739, Final Batch Loss: 0.00022388175420928746\n",
      "Epoch 4134, Loss: 0.018856156026231474, Final Batch Loss: 2.5568229830241762e-05\n",
      "Epoch 4135, Loss: 0.0003263889520894736, Final Batch Loss: 0.0002252780832350254\n",
      "Epoch 4136, Loss: 0.0005887308034289163, Final Batch Loss: 5.294942457112484e-05\n",
      "Epoch 4137, Loss: 0.0004159132122367737, Final Batch Loss: 1.2459056051739026e-05\n",
      "Epoch 4138, Loss: 0.06814751252386486, Final Batch Loss: 8.167350461008027e-05\n",
      "Epoch 4139, Loss: 0.0008771244447416393, Final Batch Loss: 5.627733116853051e-06\n",
      "Epoch 4140, Loss: 0.0002946591694126255, Final Batch Loss: 1.4279022252594586e-05\n",
      "Epoch 4141, Loss: 0.002699495774550087, Final Batch Loss: 3.2813416055432754e-06\n",
      "Epoch 4142, Loss: 0.003783750702098132, Final Batch Loss: 5.33303648353467e-07\n",
      "Epoch 4143, Loss: 0.0007001152844168246, Final Batch Loss: 0.00021336991630960256\n",
      "Epoch 4144, Loss: 0.0015680264368711505, Final Batch Loss: 4.412675116327591e-05\n",
      "Epoch 4145, Loss: 0.00402567585115321, Final Batch Loss: 0.003502334002405405\n",
      "Epoch 4146, Loss: 0.000712348372417182, Final Batch Loss: 3.990250206697965e-06\n",
      "Epoch 4147, Loss: 0.007091835854225792, Final Batch Loss: 0.0002677017473615706\n",
      "Epoch 4148, Loss: 0.007932428510684986, Final Batch Loss: 0.00031421089079231024\n",
      "Epoch 4149, Loss: 0.00048543454613536596, Final Batch Loss: 4.427417297847569e-05\n",
      "Epoch 4150, Loss: 0.0012376131952009928, Final Batch Loss: 5.458521741275035e-07\n",
      "Epoch 4151, Loss: 0.0007409827576339012, Final Batch Loss: 2.1020698113716207e-05\n",
      "Epoch 4152, Loss: 0.011426062646933133, Final Batch Loss: 0.009457942098379135\n",
      "Epoch 4153, Loss: 0.0011459678125902428, Final Batch Loss: 1.4604250281990971e-05\n",
      "Epoch 4154, Loss: 0.0005514000004041009, Final Batch Loss: 4.339560473454185e-05\n",
      "Epoch 4155, Loss: 0.00667236628234491, Final Batch Loss: 4.2036865011141344e-07\n",
      "Epoch 4156, Loss: 0.00021451722568599507, Final Batch Loss: 2.593151293694973e-05\n",
      "Epoch 4157, Loss: 0.0066560475333972136, Final Batch Loss: 7.315416951314546e-06\n",
      "Epoch 4158, Loss: 0.00034720304182656037, Final Batch Loss: 7.340765364460822e-07\n",
      "Epoch 4159, Loss: 0.0016347922046406893, Final Batch Loss: 4.404368155519478e-06\n",
      "Epoch 4160, Loss: 0.0004987829915990005, Final Batch Loss: 1.3162471987016033e-05\n",
      "Epoch 4161, Loss: 0.0020103874630876817, Final Batch Loss: 0.0017497064545750618\n",
      "Epoch 4162, Loss: 0.00044213345245225355, Final Batch Loss: 9.608276741346344e-05\n",
      "Epoch 4163, Loss: 0.005037378432461992, Final Batch Loss: 0.00011780593194998801\n",
      "Epoch 4164, Loss: 0.0005868230200576363, Final Batch Loss: 0.0002656716387718916\n",
      "Epoch 4165, Loss: 0.00040666541826794855, Final Batch Loss: 0.00011002823885064572\n",
      "Epoch 4166, Loss: 0.0022601976670557633, Final Batch Loss: 0.00011777070176322013\n",
      "Epoch 4167, Loss: 0.0007730978686595336, Final Batch Loss: 1.935237378347665e-05\n",
      "Epoch 4168, Loss: 0.00034885112836491317, Final Batch Loss: 2.611921081552282e-05\n",
      "Epoch 4169, Loss: 0.0004383247085115727, Final Batch Loss: 2.7166622658114647e-06\n",
      "Epoch 4170, Loss: 0.00120570583362678, Final Batch Loss: 5.207546109886607e-07\n",
      "Epoch 4171, Loss: 0.0016094319144031033, Final Batch Loss: 0.00016979473002720624\n",
      "Epoch 4172, Loss: 0.00043215310006416985, Final Batch Loss: 7.21526248526061e-07\n",
      "Epoch 4173, Loss: 0.0005096299611864197, Final Batch Loss: 7.779928523632407e-07\n",
      "Epoch 4174, Loss: 0.00033906598582689185, Final Batch Loss: 1.572715882502962e-05\n",
      "Epoch 4175, Loss: 0.0009956684389180737, Final Batch Loss: 2.507293720555026e-05\n",
      "Epoch 4176, Loss: 0.004905831522592052, Final Batch Loss: 1.2158644494775217e-05\n",
      "Epoch 4177, Loss: 0.00021801992789960423, Final Batch Loss: 7.466240390385792e-07\n",
      "Epoch 4178, Loss: 0.0002839539301930927, Final Batch Loss: 5.034009518567473e-05\n",
      "Epoch 4179, Loss: 0.024689232760692903, Final Batch Loss: 2.158272081942414e-06\n",
      "Epoch 4180, Loss: 0.0003964337993238587, Final Batch Loss: 1.6411813703598455e-05\n",
      "Epoch 4181, Loss: 0.012559603550471365, Final Batch Loss: 0.0022095635067671537\n",
      "Epoch 4182, Loss: 0.000564664091598388, Final Batch Loss: 5.22624623044976e-06\n",
      "Epoch 4183, Loss: 0.0051845570646094075, Final Batch Loss: 3.8272392544058675e-07\n",
      "Epoch 4184, Loss: 0.0007854989003135415, Final Batch Loss: 7.490909865737194e-06\n",
      "Epoch 4185, Loss: 0.0005183229120575561, Final Batch Loss: 3.3691364933474688e-06\n",
      "Epoch 4186, Loss: 0.00016438664169982076, Final Batch Loss: 3.046035999432206e-05\n",
      "Epoch 4187, Loss: 0.0004444817332114326, Final Batch Loss: 1.6316991604981013e-05\n",
      "Epoch 4188, Loss: 0.0015703901881352067, Final Batch Loss: 0.00023321298067457974\n",
      "Epoch 4189, Loss: 0.0004765054235349453, Final Batch Loss: 9.787671615413274e-07\n",
      "Epoch 4190, Loss: 0.0006691519665764645, Final Batch Loss: 0.000195864457054995\n",
      "Epoch 4191, Loss: 0.002467197471560212, Final Batch Loss: 1.2459455319913104e-05\n",
      "Epoch 4192, Loss: 0.0004861247434746474, Final Batch Loss: 0.0003423215530347079\n",
      "Epoch 4193, Loss: 0.0005617542192339897, Final Batch Loss: 0.00032545780413784087\n",
      "Epoch 4194, Loss: 0.0007124891761165486, Final Batch Loss: 9.411251511437513e-08\n",
      "Epoch 4195, Loss: 0.0004585057176882401, Final Batch Loss: 0.00016252177010755986\n",
      "Epoch 4196, Loss: 0.029456898686476052, Final Batch Loss: 1.200125552713871e-05\n",
      "Epoch 4197, Loss: 0.0006094461305110599, Final Batch Loss: 1.481759227317525e-05\n",
      "Epoch 4198, Loss: 0.00034483932540751994, Final Batch Loss: 0.0001207238165079616\n",
      "Epoch 4199, Loss: 0.003232025187479337, Final Batch Loss: 1.0666089877986451e-07\n",
      "Epoch 4200, Loss: 0.001472619391279295, Final Batch Loss: 0.00039337598718702793\n",
      "Epoch 4201, Loss: 0.001197476693050703, Final Batch Loss: 4.2213036067551e-05\n",
      "Epoch 4202, Loss: 0.0026576323725748807, Final Batch Loss: 0.0009981467155739665\n",
      "Epoch 4203, Loss: 0.0010154266929021105, Final Batch Loss: 0.00021028491028118879\n",
      "Epoch 4204, Loss: 0.002690393739612773, Final Batch Loss: 5.3235533414408565e-05\n",
      "Epoch 4205, Loss: 0.0005827632355703827, Final Batch Loss: 1.0352357548981672e-06\n",
      "Epoch 4206, Loss: 0.001550592983903698, Final Batch Loss: 1.769287109709694e-06\n",
      "Epoch 4207, Loss: 0.0016094177990453318, Final Batch Loss: 0.0012814056826755404\n",
      "Epoch 4208, Loss: 0.00011677240468088712, Final Batch Loss: 2.6664718006941257e-06\n",
      "Epoch 4209, Loss: 0.0023168019724835176, Final Batch Loss: 0.00011616983101703227\n",
      "Epoch 4210, Loss: 0.0002795941780391331, Final Batch Loss: 8.344593993570015e-07\n",
      "Epoch 4211, Loss: 0.0006180605196277611, Final Batch Loss: 0.00017913026385940611\n",
      "Epoch 4212, Loss: 0.0002632682126773034, Final Batch Loss: 5.333031936061161e-07\n",
      "Epoch 4213, Loss: 0.00010983209756432188, Final Batch Loss: 1.0226852964478894e-06\n",
      "Epoch 4214, Loss: 0.000527210835571168, Final Batch Loss: 9.943848999682814e-05\n",
      "Epoch 4215, Loss: 0.0002708595945222214, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 4216, Loss: 0.010052198678749846, Final Batch Loss: 4.519975118455477e-05\n",
      "Epoch 4217, Loss: 0.00018354537769482704, Final Batch Loss: 3.7831969166290946e-06\n",
      "Epoch 4218, Loss: 0.0003147364186588675, Final Batch Loss: 0.00016327653429470956\n",
      "Epoch 4219, Loss: 0.00015870369047732424, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 4220, Loss: 0.00020532620050062178, Final Batch Loss: 4.642869839699415e-07\n",
      "Epoch 4221, Loss: 0.002290978343808092, Final Batch Loss: 9.583332575857639e-05\n",
      "Epoch 4222, Loss: 0.00015558269342363928, Final Batch Loss: 7.434375675074989e-06\n",
      "Epoch 4223, Loss: 0.0019998251445940696, Final Batch Loss: 0.0017226228956133127\n",
      "Epoch 4224, Loss: 0.000254436798968527, Final Batch Loss: 3.5448565540718846e-06\n",
      "Epoch 4225, Loss: 0.0005640805029543117, Final Batch Loss: 2.3738801246508956e-05\n",
      "Epoch 4226, Loss: 0.00047890232508507324, Final Batch Loss: 2.635130840644706e-06\n",
      "Epoch 4227, Loss: 0.0005748299095102993, Final Batch Loss: 4.0216777961177286e-06\n",
      "Epoch 4228, Loss: 0.00021976133689349808, Final Batch Loss: 1.405396005793591e-06\n",
      "Epoch 4229, Loss: 0.0015310013641283149, Final Batch Loss: 6.317897714325227e-06\n",
      "Epoch 4230, Loss: 0.0006336873702821322, Final Batch Loss: 0.00033036968670785427\n",
      "Epoch 4231, Loss: 4.777662343258271e-05, Final Batch Loss: 5.684300958819222e-06\n",
      "Epoch 4232, Loss: 0.0003676163250929676, Final Batch Loss: 0.00011353848822182044\n",
      "Epoch 4233, Loss: 0.001991889210330555, Final Batch Loss: 0.0009836060926318169\n",
      "Epoch 4234, Loss: 0.005306045397674097, Final Batch Loss: 2.0767295154655585e-06\n",
      "Epoch 4235, Loss: 0.0011702032206812873, Final Batch Loss: 0.0008790091960690916\n",
      "Epoch 4236, Loss: 0.0004148014586462523, Final Batch Loss: 1.8132150216843002e-06\n",
      "Epoch 4237, Loss: 0.008048127521760762, Final Batch Loss: 0.00563230412080884\n",
      "Epoch 4238, Loss: 0.0006853803533886094, Final Batch Loss: 9.004521416500211e-05\n",
      "Epoch 4239, Loss: 0.0017861154192360118, Final Batch Loss: 0.0004696659161709249\n",
      "Epoch 4240, Loss: 0.00017162938138426398, Final Batch Loss: 7.466066108463565e-06\n",
      "Epoch 4241, Loss: 0.0002875169265053046, Final Batch Loss: 7.27799374544702e-07\n",
      "Epoch 4242, Loss: 0.0016221228070207871, Final Batch Loss: 7.879830809542909e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4243, Loss: 0.00048765654810267733, Final Batch Loss: 1.2360005712253042e-06\n",
      "Epoch 4244, Loss: 0.0007120297341316473, Final Batch Loss: 0.0005313993315212429\n",
      "Epoch 4245, Loss: 0.00032030752845457755, Final Batch Loss: 1.812308983062394e-05\n",
      "Epoch 4246, Loss: 0.0003522106111120138, Final Batch Loss: 3.7644926464963646e-07\n",
      "Epoch 4247, Loss: 0.0005212744808886782, Final Batch Loss: 1.2158729987277184e-05\n",
      "Epoch 4248, Loss: 0.00091485791017476, Final Batch Loss: 2.0263409169274382e-05\n",
      "Epoch 4249, Loss: 0.0006470584685303038, Final Batch Loss: 2.2070080376579426e-05\n",
      "Epoch 4250, Loss: 0.0005699274224753026, Final Batch Loss: 2.745550955296494e-05\n",
      "Epoch 4251, Loss: 0.00045314090747439195, Final Batch Loss: 8.156420250315932e-08\n",
      "Epoch 4252, Loss: 0.0006647707000695391, Final Batch Loss: 4.4546553112922993e-07\n",
      "Epoch 4253, Loss: 0.0010561986346147023, Final Batch Loss: 0.00012137527664890513\n",
      "Epoch 4254, Loss: 0.00012364034046186134, Final Batch Loss: 1.049584534484893e-05\n",
      "Epoch 4255, Loss: 0.004138767908443697, Final Batch Loss: 0.00021014742378611118\n",
      "Epoch 4256, Loss: 0.00020975271101519866, Final Batch Loss: 3.011598153079831e-07\n",
      "Epoch 4257, Loss: 0.000209042955930272, Final Batch Loss: 2.8107758680562256e-06\n",
      "Epoch 4258, Loss: 0.001330599723587511, Final Batch Loss: 0.0012185616651549935\n",
      "Epoch 4259, Loss: 0.00010938644767932715, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4260, Loss: 0.008563775196307688, Final Batch Loss: 2.747212965914514e-05\n",
      "Epoch 4261, Loss: 0.01197743670491036, Final Batch Loss: 0.010898280888795853\n",
      "Epoch 4262, Loss: 0.0004224263484502444, Final Batch Loss: 2.1959149307804182e-06\n",
      "Epoch 4263, Loss: 0.0006728006837875, Final Batch Loss: 1.2980642168258782e-05\n",
      "Epoch 4264, Loss: 0.0030777715292060748, Final Batch Loss: 0.0027172837872058153\n",
      "Epoch 4265, Loss: 0.00033704430097714067, Final Batch Loss: 0.00021517512504942715\n",
      "Epoch 4266, Loss: 0.0003442606223416078, Final Batch Loss: 2.9048726446490036e-06\n",
      "Epoch 4267, Loss: 0.001542094374599401, Final Batch Loss: 0.001214651740156114\n",
      "Epoch 4268, Loss: 0.0004773114196723327, Final Batch Loss: 5.284207873046398e-05\n",
      "Epoch 4269, Loss: 0.0012932915246892662, Final Batch Loss: 7.415580967062851e-06\n",
      "Epoch 4270, Loss: 0.0010772535315481946, Final Batch Loss: 0.00011099692346761003\n",
      "Epoch 4271, Loss: 0.00030438230805884814, Final Batch Loss: 1.3625739484268706e-05\n",
      "Epoch 4272, Loss: 0.00048054476064862683, Final Batch Loss: 0.00012877382687292993\n",
      "Epoch 4273, Loss: 0.00016449786198791116, Final Batch Loss: 2.449517160130199e-05\n",
      "Epoch 4274, Loss: 0.0003452360379867514, Final Batch Loss: 3.19982149221687e-07\n",
      "Epoch 4275, Loss: 6.956783647638076e-05, Final Batch Loss: 1.8257698002344114e-06\n",
      "Epoch 4276, Loss: 0.0002301365116417209, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4277, Loss: 9.439330278837588e-05, Final Batch Loss: 2.4238299374701455e-05\n",
      "Epoch 4278, Loss: 0.00018161670595873147, Final Batch Loss: 7.440380431944504e-05\n",
      "Epoch 4279, Loss: 0.0006436907017359772, Final Batch Loss: 1.5183388768491568e-06\n",
      "Epoch 4280, Loss: 0.00012948164021509, Final Batch Loss: 8.548032928956673e-05\n",
      "Epoch 4281, Loss: 0.0005260975303826854, Final Batch Loss: 0.00020611654326785356\n",
      "Epoch 4282, Loss: 0.00012140744301802897, Final Batch Loss: 8.783835880876723e-08\n",
      "Epoch 4283, Loss: 0.00011159184975895187, Final Batch Loss: 1.2924668908453896e-06\n",
      "Epoch 4284, Loss: 0.0003893433058692608, Final Batch Loss: 3.690850644488819e-05\n",
      "Epoch 4285, Loss: 0.0003797167036054816, Final Batch Loss: 3.074336518693599e-07\n",
      "Epoch 4286, Loss: 0.0002603289985927404, Final Batch Loss: 4.780785275215749e-06\n",
      "Epoch 4287, Loss: 0.000570210000660154, Final Batch Loss: 2.7029976990888827e-05\n",
      "Epoch 4288, Loss: 0.020602480886736885, Final Batch Loss: 0.0001337981375399977\n",
      "Epoch 4289, Loss: 0.00037147109446777904, Final Batch Loss: 2.1206394649198046e-06\n",
      "Epoch 4290, Loss: 0.00011438396813900908, Final Batch Loss: 8.02425802248763e-06\n",
      "Epoch 4291, Loss: 0.001867399474576814, Final Batch Loss: 0.0015246557304635644\n",
      "Epoch 4292, Loss: 0.0013958737558823486, Final Batch Loss: 7.108168119884795e-06\n",
      "Epoch 4293, Loss: 0.010583682174910791, Final Batch Loss: 0.010175487026572227\n",
      "Epoch 4294, Loss: 0.0005110774181957822, Final Batch Loss: 6.068018774385564e-05\n",
      "Epoch 4295, Loss: 0.0013877189476261265, Final Batch Loss: 7.541209015471395e-06\n",
      "Epoch 4296, Loss: 0.0013906928981519684, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 4297, Loss: 0.0003888191231453675, Final Batch Loss: 6.832372491771821e-06\n",
      "Epoch 4298, Loss: 0.00040907252929400784, Final Batch Loss: 7.340736942751391e-07\n",
      "Epoch 4299, Loss: 0.000288665843754643, Final Batch Loss: 6.901586857566144e-08\n",
      "Epoch 4300, Loss: 0.005615653470158577, Final Batch Loss: 0.00018378428649157286\n",
      "Epoch 4301, Loss: 0.0004403826969792135, Final Batch Loss: 0.00017480982933193445\n",
      "Epoch 4302, Loss: 0.0005822958769670095, Final Batch Loss: 3.3880453997880977e-07\n",
      "Epoch 4303, Loss: 0.011629843105765758, Final Batch Loss: 4.103574974578805e-05\n",
      "Epoch 4304, Loss: 0.000570605295479254, Final Batch Loss: 3.3253058973059524e-07\n",
      "Epoch 4305, Loss: 0.0005054570788161072, Final Batch Loss: 5.784473160019843e-06\n",
      "Epoch 4306, Loss: 0.003580067597795278, Final Batch Loss: 0.0010855955770239234\n",
      "Epoch 4307, Loss: 0.0005780481847068586, Final Batch Loss: 5.395541393227177e-06\n",
      "Epoch 4308, Loss: 0.0007223855900519993, Final Batch Loss: 3.1489209504798055e-05\n",
      "Epoch 4309, Loss: 0.00040082040959532605, Final Batch Loss: 6.706749445584137e-06\n",
      "Epoch 4310, Loss: 0.0008192968525690958, Final Batch Loss: 0.0\n",
      "Epoch 4311, Loss: 0.01777276100619929, Final Batch Loss: 3.119593748124316e-05\n",
      "Epoch 4312, Loss: 0.0005483365166583098, Final Batch Loss: 7.810878742020577e-06\n",
      "Epoch 4313, Loss: 0.00021155685757889842, Final Batch Loss: 2.823370266469283e-07\n",
      "Epoch 4314, Loss: 0.0017838848434621468, Final Batch Loss: 0.0004132830654270947\n",
      "Epoch 4315, Loss: 0.00021289959477144293, Final Batch Loss: 4.719849312095903e-05\n",
      "Epoch 4316, Loss: 0.0022346368205035105, Final Batch Loss: 0.0018898876151069999\n",
      "Epoch 4317, Loss: 0.0006694009319971883, Final Batch Loss: 1.1418927670092671e-06\n",
      "Epoch 4318, Loss: 0.0010075947203880276, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 4319, Loss: 0.0014337707034428604, Final Batch Loss: 3.246009146096185e-05\n",
      "Epoch 4320, Loss: 0.0018541212702984922, Final Batch Loss: 1.2791544577339664e-05\n",
      "Epoch 4321, Loss: 0.00029722661565756425, Final Batch Loss: 4.166442158748396e-05\n",
      "Epoch 4322, Loss: 0.0003818250106633059, Final Batch Loss: 0.00015397676907014102\n",
      "Epoch 4323, Loss: 0.00016436200564839964, Final Batch Loss: 1.5246044995365082e-06\n",
      "Epoch 4324, Loss: 0.00037635762919308036, Final Batch Loss: 2.365328782616416e-06\n",
      "Epoch 4325, Loss: 0.000903249550901819, Final Batch Loss: 0.0005998717388138175\n",
      "Epoch 4326, Loss: 9.744772347630715e-05, Final Batch Loss: 4.831100000046717e-07\n",
      "Epoch 4327, Loss: 0.000291730889784958, Final Batch Loss: 5.075694843981182e-06\n",
      "Epoch 4328, Loss: 0.00031636534822609974, Final Batch Loss: 4.6678278522449546e-06\n",
      "Epoch 4329, Loss: 0.00011850389601875122, Final Batch Loss: 2.1332162702947244e-07\n",
      "Epoch 4330, Loss: 0.00122758249835897, Final Batch Loss: 0.0\n",
      "Epoch 4331, Loss: 0.00018535289109422592, Final Batch Loss: 3.074337655561976e-07\n",
      "Epoch 4332, Loss: 0.0003526876594150963, Final Batch Loss: 6.179753199830884e-06\n",
      "Epoch 4333, Loss: 0.00010770706649054773, Final Batch Loss: 1.6197445802390575e-05\n",
      "Epoch 4334, Loss: 0.00024129998200805858, Final Batch Loss: 5.283395876176655e-05\n",
      "Epoch 4335, Loss: 0.0006316957826584257, Final Batch Loss: 1.3238407063909108e-06\n",
      "Epoch 4336, Loss: 0.002693453863273021, Final Batch Loss: 1.6312837658460921e-07\n",
      "Epoch 4337, Loss: 0.00010534220223235025, Final Batch Loss: 1.1920794804609613e-06\n",
      "Epoch 4338, Loss: 0.0001863130992205697, Final Batch Loss: 9.899881661112886e-06\n",
      "Epoch 4339, Loss: 0.00034943707532875123, Final Batch Loss: 4.015367721876828e-06\n",
      "Epoch 4340, Loss: 0.0001881905845948495, Final Batch Loss: 7.5444535468705e-05\n",
      "Epoch 4341, Loss: 0.0003735332647920586, Final Batch Loss: 0.00025150514557026327\n",
      "Epoch 4342, Loss: 0.004864294744038489, Final Batch Loss: 6.37883204035461e-05\n",
      "Epoch 4343, Loss: 0.00040084979264065623, Final Batch Loss: 0.0001683180598774925\n",
      "Epoch 4344, Loss: 0.0010233914290438406, Final Batch Loss: 0.00010449639376020059\n",
      "Epoch 4345, Loss: 0.0005958230150895361, Final Batch Loss: 6.525107778543315e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4346, Loss: 0.027979063102975488, Final Batch Loss: 0.002379216719418764\n",
      "Epoch 4347, Loss: 0.002288370389578631, Final Batch Loss: 1.6416957805631682e-05\n",
      "Epoch 4348, Loss: 0.0003574625791316066, Final Batch Loss: 1.148166347775259e-06\n",
      "Epoch 4349, Loss: 0.0006662853575107874, Final Batch Loss: 1.2377584425848909e-05\n",
      "Epoch 4350, Loss: 0.00029749679742963053, Final Batch Loss: 3.6634690331993625e-05\n",
      "Epoch 4351, Loss: 0.0001799349347493262, Final Batch Loss: 1.5206572243187111e-05\n",
      "Epoch 4352, Loss: 0.002424385915219318, Final Batch Loss: 0.0019834027625620365\n",
      "Epoch 4353, Loss: 0.00012013398372801021, Final Batch Loss: 1.2221287761349231e-05\n",
      "Epoch 4354, Loss: 0.0006921114372744341, Final Batch Loss: 9.556331497151405e-05\n",
      "Epoch 4355, Loss: 0.0006035248612761279, Final Batch Loss: 7.152508487706655e-07\n",
      "Epoch 4356, Loss: 0.00023467364007956348, Final Batch Loss: 0.00011297179298708215\n",
      "Epoch 4357, Loss: 0.0010727080271415446, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 4358, Loss: 0.00015019039796015932, Final Batch Loss: 5.772207600784895e-07\n",
      "Epoch 4359, Loss: 0.0014949296176780535, Final Batch Loss: 1.1293499824205355e-07\n",
      "Epoch 4360, Loss: 0.0002094488954753615, Final Batch Loss: 0.00015277259808499366\n",
      "Epoch 4361, Loss: 0.0002629511832310527, Final Batch Loss: 2.214748292317381e-06\n",
      "Epoch 4362, Loss: 0.014124449309065312, Final Batch Loss: 2.1331754851416918e-06\n",
      "Epoch 4363, Loss: 0.00010542651398282032, Final Batch Loss: 1.5132355656533036e-05\n",
      "Epoch 4364, Loss: 0.0007076627975663996, Final Batch Loss: 1.2548341032925237e-07\n",
      "Epoch 4365, Loss: 0.0010740963307398488, Final Batch Loss: 5.546125066757668e-06\n",
      "Epoch 4366, Loss: 0.00135302832495654, Final Batch Loss: 1.4159515558276325e-05\n",
      "Epoch 4367, Loss: 0.0008115996170090511, Final Batch Loss: 3.679160727187991e-05\n",
      "Epoch 4368, Loss: 0.0005620417341560824, Final Batch Loss: 0.00018235036986880004\n",
      "Epoch 4369, Loss: 0.0003763584463740699, Final Batch Loss: 6.160781776998192e-05\n",
      "Epoch 4370, Loss: 0.0005639011184221943, Final Batch Loss: 3.137085613502677e-08\n",
      "Epoch 4371, Loss: 0.000461663041733118, Final Batch Loss: 7.208740953501547e-06\n",
      "Epoch 4372, Loss: 0.0010018149187089875, Final Batch Loss: 0.0005864282138645649\n",
      "Epoch 4373, Loss: 0.00039450631811632775, Final Batch Loss: 0.00017667541396804154\n",
      "Epoch 4374, Loss: 0.0006109684218245093, Final Batch Loss: 0.0002218856243416667\n",
      "Epoch 4375, Loss: 0.0005634554399875924, Final Batch Loss: 7.863349310355261e-05\n",
      "Epoch 4376, Loss: 0.0017072720067048408, Final Batch Loss: 3.764503020420307e-08\n",
      "Epoch 4377, Loss: 0.0003614961970015429, Final Batch Loss: 0.00015309591253753752\n",
      "Epoch 4378, Loss: 0.0002673250637599267, Final Batch Loss: 0.00011683022603392601\n",
      "Epoch 4379, Loss: 0.00023887712736225808, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4380, Loss: 0.0006380619088304229, Final Batch Loss: 5.184998008189723e-05\n",
      "Epoch 4381, Loss: 0.0011570380310530481, Final Batch Loss: 1.8195071049831313e-07\n",
      "Epoch 4382, Loss: 0.00023816092016204493, Final Batch Loss: 9.247454727301374e-06\n",
      "Epoch 4383, Loss: 0.0004007297454435843, Final Batch Loss: 5.6467534648163564e-08\n",
      "Epoch 4384, Loss: 0.00015928902018913504, Final Batch Loss: 1.443057726646657e-07\n",
      "Epoch 4385, Loss: 0.0008551227292628027, Final Batch Loss: 4.180079122306779e-05\n",
      "Epoch 4386, Loss: 0.00016109062494251702, Final Batch Loss: 2.6664558845368447e-06\n",
      "Epoch 4387, Loss: 0.00039498210253441357, Final Batch Loss: 5.483509539772058e-06\n",
      "Epoch 4388, Loss: 0.0022167604738569935, Final Batch Loss: 1.0200817087024916e-05\n",
      "Epoch 4389, Loss: 0.00018594722973830358, Final Batch Loss: 2.5911697321134852e-06\n",
      "Epoch 4390, Loss: 0.0091808974522678, Final Batch Loss: 5.583989945989742e-07\n",
      "Epoch 4391, Loss: 0.0013737252853616155, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4392, Loss: 0.0003961938855354674, Final Batch Loss: 2.054390643024817e-05\n",
      "Epoch 4393, Loss: 0.001622378615593334, Final Batch Loss: 3.2311004360963125e-06\n",
      "Epoch 4394, Loss: 0.0006911131583606789, Final Batch Loss: 6.274169805919882e-08\n",
      "Epoch 4395, Loss: 0.0012820715292942708, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 4396, Loss: 0.0008678034628246678, Final Batch Loss: 2.2275000446825288e-05\n",
      "Epoch 4397, Loss: 0.00024698042210502535, Final Batch Loss: 5.333023977982521e-07\n",
      "Epoch 4398, Loss: 2.905140024722641e-05, Final Batch Loss: 3.513531510179746e-07\n",
      "Epoch 4399, Loss: 0.0002879967760236468, Final Batch Loss: 0.00011546950554475188\n",
      "Epoch 4400, Loss: 0.00014522856235998916, Final Batch Loss: 1.3908207620261237e-05\n",
      "Epoch 4401, Loss: 0.00032530251041862357, Final Batch Loss: 3.3253013498324435e-07\n",
      "Epoch 4402, Loss: 0.00014352316065924242, Final Batch Loss: 0.0\n",
      "Epoch 4403, Loss: 0.009654153265728382, Final Batch Loss: 1.1374260793672875e-05\n",
      "Epoch 4404, Loss: 0.00011913504988569912, Final Batch Loss: 1.305019964092935e-06\n",
      "Epoch 4405, Loss: 9.914818829770411e-05, Final Batch Loss: 3.701751722928748e-07\n",
      "Epoch 4406, Loss: 0.008145213265834172, Final Batch Loss: 5.144797796674538e-07\n",
      "Epoch 4407, Loss: 0.0035510768939275295, Final Batch Loss: 3.154813020955771e-05\n",
      "Epoch 4408, Loss: 0.0005196121646804386, Final Batch Loss: 9.008942470245529e-06\n",
      "Epoch 4409, Loss: 0.003737707009392466, Final Batch Loss: 1.9449912258551194e-07\n",
      "Epoch 4410, Loss: 0.0010696696713239362, Final Batch Loss: 6.41188444205909e-06\n",
      "Epoch 4411, Loss: 0.0007719826243572925, Final Batch Loss: 1.1920921849650767e-07\n",
      "Epoch 4412, Loss: 7.236109161112836e-05, Final Batch Loss: 1.8822504443960497e-07\n",
      "Epoch 4413, Loss: 0.0007692911658523371, Final Batch Loss: 2.076366035907995e-05\n",
      "Epoch 4414, Loss: 0.0068689436526483405, Final Batch Loss: 1.618711962692032e-06\n",
      "Epoch 4415, Loss: 8.749667865792787e-05, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 4416, Loss: 0.0012248566368051605, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4417, Loss: 0.000807689044449944, Final Batch Loss: 4.096114935236983e-05\n",
      "Epoch 4418, Loss: 0.0041160892869811505, Final Batch Loss: 0.003427329007536173\n",
      "Epoch 4419, Loss: 0.0010015762379680382, Final Batch Loss: 1.6751798739278456e-06\n",
      "Epoch 4420, Loss: 0.0018084871580867912, Final Batch Loss: 1.668903678364586e-06\n",
      "Epoch 4421, Loss: 0.0001860646043496672, Final Batch Loss: 2.227292952738935e-06\n",
      "Epoch 4422, Loss: 0.00023452427950587662, Final Batch Loss: 7.089768701007415e-07\n",
      "Epoch 4423, Loss: 0.0017237009724340169, Final Batch Loss: 2.518485598557163e-05\n",
      "Epoch 4424, Loss: 9.492289427726064e-05, Final Batch Loss: 4.347906724433415e-06\n",
      "Epoch 4425, Loss: 0.00013982470238715905, Final Batch Loss: 1.7755611452230369e-06\n",
      "Epoch 4426, Loss: 0.005739589797940425, Final Batch Loss: 2.2712024474458303e-06\n",
      "Epoch 4427, Loss: 0.0002488089094647705, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 4428, Loss: 0.00029859977092527856, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 4429, Loss: 0.0012729320660582744, Final Batch Loss: 1.067757693817839e-05\n",
      "Epoch 4430, Loss: 0.004393550297606907, Final Batch Loss: 5.709475203730108e-07\n",
      "Epoch 4431, Loss: 0.00034775020321831107, Final Batch Loss: 9.330215834779665e-05\n",
      "Epoch 4432, Loss: 0.00010218714469800716, Final Batch Loss: 9.411251511437513e-08\n",
      "Epoch 4433, Loss: 0.0003446436021476984, Final Batch Loss: 0.0001228601613547653\n",
      "Epoch 4434, Loss: 0.00276949012913974, Final Batch Loss: 4.367539077065885e-05\n",
      "Epoch 4435, Loss: 0.0012376620870782062, Final Batch Loss: 0.00019327306654304266\n",
      "Epoch 4436, Loss: 7.360341510320723e-05, Final Batch Loss: 2.515923142709653e-06\n",
      "Epoch 4437, Loss: 7.902800530246168e-05, Final Batch Loss: 9.536659035802586e-07\n",
      "Epoch 4438, Loss: 0.00022262156174690517, Final Batch Loss: 6.901585436480673e-08\n",
      "Epoch 4439, Loss: 0.00012526676528068492, Final Batch Loss: 1.3036174095759634e-05\n",
      "Epoch 4440, Loss: 0.00028948240651516244, Final Batch Loss: 0.0\n",
      "Epoch 4441, Loss: 0.0008934009929362219, Final Batch Loss: 0.0007956181070767343\n",
      "Epoch 4442, Loss: 0.00013951278552326585, Final Batch Loss: 1.4430580108637514e-07\n",
      "Epoch 4443, Loss: 5.7261639085481875e-05, Final Batch Loss: 1.24841280921828e-05\n",
      "Epoch 4444, Loss: 0.0010830717410499346, Final Batch Loss: 9.2477248472278e-06\n",
      "Epoch 4445, Loss: 0.0002864667026187817, Final Batch Loss: 2.007697275985265e-06\n",
      "Epoch 4446, Loss: 0.0003970092710332551, Final Batch Loss: 9.411254353608456e-08\n",
      "Epoch 4447, Loss: 0.00025027888113982044, Final Batch Loss: 3.721996836247854e-05\n",
      "Epoch 4448, Loss: 0.0004617957765731262, Final Batch Loss: 3.713000478455797e-05\n",
      "Epoch 4449, Loss: 0.0004315952719480265, Final Batch Loss: 0.0002479956892784685\n",
      "Epoch 4450, Loss: 0.00017521930021757726, Final Batch Loss: 2.7185416911379434e-05\n",
      "Epoch 4451, Loss: 8.65578353455021e-05, Final Batch Loss: 5.709484298677125e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4452, Loss: 0.00021490946164703928, Final Batch Loss: 5.245112697593868e-05\n",
      "Epoch 4453, Loss: 0.00021404324286322662, Final Batch Loss: 1.2548332506412407e-07\n",
      "Epoch 4454, Loss: 0.0008420981589551957, Final Batch Loss: 4.4607490963244345e-06\n",
      "Epoch 4455, Loss: 0.00029319960526663635, Final Batch Loss: 2.9864743282814743e-06\n",
      "Epoch 4456, Loss: 7.120035920138434e-05, Final Batch Loss: 2.823370266469283e-07\n",
      "Epoch 4457, Loss: 0.003062271886690837, Final Batch Loss: 1.0666083483101829e-07\n",
      "Epoch 4458, Loss: 0.0017107021708397951, Final Batch Loss: 5.132038950250717e-06\n",
      "Epoch 4459, Loss: 0.00023967782112777059, Final Batch Loss: 9.034731647261651e-07\n",
      "Epoch 4460, Loss: 0.0015410434243676718, Final Batch Loss: 0.0013178560184314847\n",
      "Epoch 4461, Loss: 0.003211600713257212, Final Batch Loss: 1.95592365344055e-05\n",
      "Epoch 4462, Loss: 0.00014434072727453895, Final Batch Loss: 3.6158620787318796e-05\n",
      "Epoch 4463, Loss: 0.00016467079536397478, Final Batch Loss: 7.529002488126935e-08\n",
      "Epoch 4464, Loss: 0.00014952962010283954, Final Batch Loss: 1.4917888620402664e-05\n",
      "Epoch 4465, Loss: 0.003184719827686422, Final Batch Loss: 2.064190766759566e-06\n",
      "Epoch 4466, Loss: 9.905717433866812e-05, Final Batch Loss: 3.060650851693936e-05\n",
      "Epoch 4467, Loss: 8.628090927231824e-05, Final Batch Loss: 1.3331291484064423e-05\n",
      "Epoch 4468, Loss: 0.0005442348885651427, Final Batch Loss: 2.6978906930708035e-07\n",
      "Epoch 4469, Loss: 2.0402728296176065e-05, Final Batch Loss: 0.0\n",
      "Epoch 4470, Loss: 0.00019958391749241855, Final Batch Loss: 2.408731415926013e-05\n",
      "Epoch 4471, Loss: 0.00015932630560655525, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4472, Loss: 0.00020357730591058498, Final Batch Loss: 3.199761522409972e-06\n",
      "Epoch 4473, Loss: 0.00011886309221154079, Final Batch Loss: 0.0\n",
      "Epoch 4474, Loss: 0.00043371002107051027, Final Batch Loss: 2.9739160254393937e-06\n",
      "Epoch 4475, Loss: 3.095995748481073e-05, Final Batch Loss: 1.116796966016409e-06\n",
      "Epoch 4476, Loss: 0.0002891036037908634, Final Batch Loss: 2.7586653231992386e-05\n",
      "Epoch 4477, Loss: 0.0002948281489807414, Final Batch Loss: 8.87723763298709e-06\n",
      "Epoch 4478, Loss: 0.0012747432819537607, Final Batch Loss: 4.1409379036849714e-07\n",
      "Epoch 4479, Loss: 0.01904238601537145, Final Batch Loss: 1.2109017006878275e-06\n",
      "Epoch 4480, Loss: 0.004917092268101442, Final Batch Loss: 1.6438076499980525e-06\n",
      "Epoch 4481, Loss: 0.00014602522423956543, Final Batch Loss: 6.235377077246085e-05\n",
      "Epoch 4482, Loss: 0.0006881474073452409, Final Batch Loss: 5.512129428097978e-05\n",
      "Epoch 4483, Loss: 3.296097423799438e-05, Final Batch Loss: 1.3803168030790403e-07\n",
      "Epoch 4484, Loss: 0.00031234545588176843, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4485, Loss: 0.0005278518437989987, Final Batch Loss: 1.295516540267272e-05\n",
      "Epoch 4486, Loss: 0.00019642378720163833, Final Batch Loss: 0.0\n",
      "Epoch 4487, Loss: 0.0003811704445979558, Final Batch Loss: 0.00020233452960383147\n",
      "Epoch 4488, Loss: 0.00016513206706036954, Final Batch Loss: 1.0666085614730036e-07\n",
      "Epoch 4489, Loss: 0.002630338898212514, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 4490, Loss: 0.0058943768128152385, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 4491, Loss: 0.0001287883540612711, Final Batch Loss: 8.15642238194414e-08\n",
      "Epoch 4492, Loss: 0.0007732593711580193, Final Batch Loss: 1.8696790675676311e-06\n",
      "Epoch 4493, Loss: 0.0004934060307277832, Final Batch Loss: 4.623932909453288e-06\n",
      "Epoch 4494, Loss: 0.0001585662239449448, Final Batch Loss: 1.4774216651858296e-05\n",
      "Epoch 4495, Loss: 0.0038550747735826008, Final Batch Loss: 5.464552941703005e-06\n",
      "Epoch 4496, Loss: 0.0035353138960942943, Final Batch Loss: 3.0115970162114536e-07\n",
      "Epoch 4497, Loss: 0.009621591147151776, Final Batch Loss: 0.009283563122153282\n",
      "Epoch 4498, Loss: 8.973897553232746e-05, Final Batch Loss: 5.207539857110532e-07\n",
      "Epoch 4499, Loss: 0.0001883698805613676, Final Batch Loss: 8.940037514548749e-05\n",
      "Epoch 4500, Loss: 0.0006068825186957838, Final Batch Loss: 1.5031489965622313e-05\n",
      "Epoch 4501, Loss: 0.001004837773507461, Final Batch Loss: 4.2797764763236046e-05\n",
      "Epoch 4502, Loss: 0.0003164062218274921, Final Batch Loss: 3.294172347523272e-05\n",
      "Epoch 4503, Loss: 0.0014294182813046064, Final Batch Loss: 2.791933411572245e-06\n",
      "Epoch 4504, Loss: 0.000558785786779481, Final Batch Loss: 1.5620984413544647e-05\n",
      "Epoch 4505, Loss: 0.0024604277532489505, Final Batch Loss: 0.002302059205248952\n",
      "Epoch 4506, Loss: 0.01208734021474811, Final Batch Loss: 1.2904393770440947e-05\n",
      "Epoch 4507, Loss: 0.00044516434513752756, Final Batch Loss: 4.76835111840046e-07\n",
      "Epoch 4508, Loss: 8.966914629127132e-05, Final Batch Loss: 3.9985665353015065e-05\n",
      "Epoch 4509, Loss: 0.0004743546876397886, Final Batch Loss: 2.823346903824131e-06\n",
      "Epoch 4510, Loss: 0.0005035441718064249, Final Batch Loss: 8.250652172137052e-05\n",
      "Epoch 4511, Loss: 0.0007227753367260448, Final Batch Loss: 1.3343686987354886e-05\n",
      "Epoch 4512, Loss: 0.02850809680239763, Final Batch Loss: 0.00014642419409938157\n",
      "Epoch 4513, Loss: 0.00045904468754542904, Final Batch Loss: 1.449323121960333e-06\n",
      "Epoch 4514, Loss: 0.0013075332993253141, Final Batch Loss: 6.525099820464675e-07\n",
      "Epoch 4515, Loss: 0.002436940460029291, Final Batch Loss: 0.00020491666509769857\n",
      "Epoch 4516, Loss: 0.003070958339345342, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4517, Loss: 0.0003310820218302979, Final Batch Loss: 3.2938667118287412e-06\n",
      "Epoch 4518, Loss: 0.00011957605784118641, Final Batch Loss: 5.484763823915273e-05\n",
      "Epoch 4519, Loss: 6.506627232738538e-05, Final Batch Loss: 2.9362772693275474e-06\n",
      "Epoch 4520, Loss: 0.00010912102745885832, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4521, Loss: 0.0005257735883787973, Final Batch Loss: 0.0001970820449059829\n",
      "Epoch 4522, Loss: 6.183391451486386e-05, Final Batch Loss: 8.601600711699575e-06\n",
      "Epoch 4523, Loss: 0.00023772450890646724, Final Batch Loss: 2.6915620310319355e-06\n",
      "Epoch 4524, Loss: 0.004416503868696964, Final Batch Loss: 2.5472634206380462e-06\n",
      "Epoch 4525, Loss: 0.00014946819146643975, Final Batch Loss: 2.1143664525880013e-06\n",
      "Epoch 4526, Loss: 0.00011454364761220859, Final Batch Loss: 8.721075914763787e-07\n",
      "Epoch 4527, Loss: 0.0003215638521396613, Final Batch Loss: 5.063035587227205e-06\n",
      "Epoch 4528, Loss: 0.0002843729644155246, Final Batch Loss: 1.4434893273573834e-05\n",
      "Epoch 4529, Loss: 0.0010295415268046781, Final Batch Loss: 0.0004002026398666203\n",
      "Epoch 4530, Loss: 0.000440464524217532, Final Batch Loss: 5.985444659017958e-06\n",
      "Epoch 4531, Loss: 0.0004552183099804097, Final Batch Loss: 7.403496056213044e-07\n",
      "Epoch 4532, Loss: 0.0001318229039952712, Final Batch Loss: 2.302571147083654e-06\n",
      "Epoch 4533, Loss: 0.00042881039362896445, Final Batch Loss: 1.4430580108637514e-07\n",
      "Epoch 4534, Loss: 0.0006376402991463692, Final Batch Loss: 3.444455842327443e-06\n",
      "Epoch 4535, Loss: 0.0007758554856991395, Final Batch Loss: 8.501754200551659e-05\n",
      "Epoch 4536, Loss: 0.00020413703794019966, Final Batch Loss: 3.325302486700821e-07\n",
      "Epoch 4537, Loss: 0.0005521627535927109, Final Batch Loss: 0.00010579586523817852\n",
      "Epoch 4538, Loss: 0.000287349195403408, Final Batch Loss: 1.8822518654815212e-08\n",
      "Epoch 4539, Loss: 0.00018709670980854298, Final Batch Loss: 1.6940244051966147e-07\n",
      "Epoch 4540, Loss: 0.0007241787716338877, Final Batch Loss: 4.147087565797847e-06\n",
      "Epoch 4541, Loss: 0.0001392949252476683, Final Batch Loss: 8.598792919656262e-05\n",
      "Epoch 4542, Loss: 0.001097457012383174, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 4543, Loss: 8.836876895657042e-05, Final Batch Loss: 7.89859132055426e-06\n",
      "Epoch 4544, Loss: 0.002454439949360676, Final Batch Loss: 0.0008742735954001546\n",
      "Epoch 4545, Loss: 0.008367034064335144, Final Batch Loss: 6.901585436480673e-08\n",
      "Epoch 4546, Loss: 0.003116335734432596, Final Batch Loss: 8.909274242796528e-07\n",
      "Epoch 4547, Loss: 0.0003243248766011675, Final Batch Loss: 2.584927642601542e-06\n",
      "Epoch 4548, Loss: 0.0038774028071202338, Final Batch Loss: 0.0036760917864739895\n",
      "Epoch 4549, Loss: 0.00026095825796801364, Final Batch Loss: 2.2702730348100886e-05\n",
      "Epoch 4550, Loss: 4.253750506677534e-05, Final Batch Loss: 8.65830259044742e-07\n",
      "Epoch 4551, Loss: 0.00041850314521241216, Final Batch Loss: 1.7567656129813258e-07\n",
      "Epoch 4552, Loss: 0.001122172089878859, Final Batch Loss: 9.222978292200423e-07\n",
      "Epoch 4553, Loss: 0.0011852250463562086, Final Batch Loss: 0.0002179796720156446\n",
      "Epoch 4554, Loss: 0.0010321564077457879, Final Batch Loss: 0.0009028566419146955\n",
      "Epoch 4555, Loss: 8.69317173055606e-05, Final Batch Loss: 1.7508704331703484e-05\n",
      "Epoch 4556, Loss: 0.0002560353045737429, Final Batch Loss: 4.009118583780946e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4557, Loss: 0.0001600235176510978, Final Batch Loss: 1.01013790754223e-06\n",
      "Epoch 4558, Loss: 0.00010007445780502167, Final Batch Loss: 2.139692696800921e-05\n",
      "Epoch 4559, Loss: 7.20592504421802e-05, Final Batch Loss: 1.6061637779785087e-06\n",
      "Epoch 4560, Loss: 0.0001094114607838037, Final Batch Loss: 1.1293499824205355e-07\n",
      "Epoch 4561, Loss: 0.0011287590489246213, Final Batch Loss: 1.9575265923776897e-06\n",
      "Epoch 4562, Loss: 0.00012375038195955312, Final Batch Loss: 3.199819786914304e-07\n",
      "Epoch 4563, Loss: 0.00013734410822507925, Final Batch Loss: 0.00011470492609078065\n",
      "Epoch 4564, Loss: 0.0007227647729450837, Final Batch Loss: 1.6687634342815727e-05\n",
      "Epoch 4565, Loss: 0.00017797217151382938, Final Batch Loss: 0.00010676262900233269\n",
      "Epoch 4566, Loss: 0.00018631032127913727, Final Batch Loss: 3.137085613502677e-08\n",
      "Epoch 4567, Loss: 0.0001356974868258476, Final Batch Loss: 3.137085968774045e-08\n",
      "Epoch 4568, Loss: 0.00013822845289723773, Final Batch Loss: 1.6297801266773604e-05\n",
      "Epoch 4569, Loss: 0.000413685060550506, Final Batch Loss: 8.846530477057968e-07\n",
      "Epoch 4570, Loss: 0.0005637596855194715, Final Batch Loss: 1.9010417418030556e-06\n",
      "Epoch 4571, Loss: 8.314730592928754e-05, Final Batch Loss: 3.9527157014163095e-07\n",
      "Epoch 4572, Loss: 2.5090955034556828e-05, Final Batch Loss: 7.654442129023664e-07\n",
      "Epoch 4573, Loss: 0.00013613451119454112, Final Batch Loss: 6.268982542678714e-05\n",
      "Epoch 4574, Loss: 0.00046868402569089085, Final Batch Loss: 3.913628461305052e-05\n",
      "Epoch 4575, Loss: 0.0017429270432103294, Final Batch Loss: 1.2548332506412407e-07\n",
      "Epoch 4576, Loss: 0.00025057278799067717, Final Batch Loss: 7.215257937787101e-07\n",
      "Epoch 4577, Loss: 9.839449785431498e-05, Final Batch Loss: 1.7441911950299982e-06\n",
      "Epoch 4578, Loss: 4.6759392716921866e-05, Final Batch Loss: 9.67388587014284e-06\n",
      "Epoch 4579, Loss: 0.0018909621901457285, Final Batch Loss: 2.6100058221345535e-06\n",
      "Epoch 4580, Loss: 8.988960360056808e-05, Final Batch Loss: 5.960431508356123e-07\n",
      "Epoch 4581, Loss: 3.1147308710899324e-05, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4582, Loss: 0.0006585063988731044, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4583, Loss: 0.0005415961277321912, Final Batch Loss: 0.00010953997116303071\n",
      "Epoch 4584, Loss: 0.000191858212929219, Final Batch Loss: 0.0\n",
      "Epoch 4585, Loss: 7.394591541753925e-05, Final Batch Loss: 8.783838723047666e-08\n",
      "Epoch 4586, Loss: 5.1424800858512754e-05, Final Batch Loss: 6.988967015786329e-06\n",
      "Epoch 4587, Loss: 6.32246778877743e-05, Final Batch Loss: 3.268743512307992e-06\n",
      "Epoch 4588, Loss: 0.002476961180178705, Final Batch Loss: 2.0704752046185604e-07\n",
      "Epoch 4589, Loss: 0.0001808841680031037, Final Batch Loss: 3.559389369911514e-05\n",
      "Epoch 4590, Loss: 0.00010503437317765929, Final Batch Loss: 8.030880280784913e-07\n",
      "Epoch 4591, Loss: 0.00027027042960980907, Final Batch Loss: 0.00021340353123378009\n",
      "Epoch 4592, Loss: 0.0013515466671378817, Final Batch Loss: 3.3970583899645135e-05\n",
      "Epoch 4593, Loss: 0.004701519264926901, Final Batch Loss: 0.000564974790904671\n",
      "Epoch 4594, Loss: 0.0001715763692118344, Final Batch Loss: 4.868535143032204e-06\n",
      "Epoch 4595, Loss: 0.000561904071350483, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4596, Loss: 0.00018617565319800633, Final Batch Loss: 0.00017389333515893668\n",
      "Epoch 4597, Loss: 0.002598256884084549, Final Batch Loss: 1.3425022189039737e-05\n",
      "Epoch 4598, Loss: 0.00026001046080637025, Final Batch Loss: 0.00024425124865956604\n",
      "Epoch 4599, Loss: 7.445753726642579e-05, Final Batch Loss: 8.563579285691958e-06\n",
      "Epoch 4600, Loss: 0.00021216386039668578, Final Batch Loss: 5.019314812670927e-07\n",
      "Epoch 4601, Loss: 0.0001651438647058967, Final Batch Loss: 7.277990334841888e-07\n",
      "Epoch 4602, Loss: 0.028320357414486352, Final Batch Loss: 0.028143679723143578\n",
      "Epoch 4603, Loss: 0.00015900881929553634, Final Batch Loss: 6.901585436480673e-08\n",
      "Epoch 4604, Loss: 0.11497580092918724, Final Batch Loss: 3.306386588519672e-06\n",
      "Epoch 4605, Loss: 0.08010461945377756, Final Batch Loss: 9.285770647693425e-05\n",
      "Epoch 4606, Loss: 3.092957467742963e-05, Final Batch Loss: 9.29123143578181e-06\n",
      "Epoch 4607, Loss: 0.0021843170159172587, Final Batch Loss: 0.0\n",
      "Epoch 4608, Loss: 0.0005941169120440293, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 4609, Loss: 0.00044976660831252957, Final Batch Loss: 3.701749164974899e-07\n",
      "Epoch 4610, Loss: 0.04344685056639719, Final Batch Loss: 4.19715179305058e-05\n",
      "Epoch 4611, Loss: 0.008122697261184086, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 4612, Loss: 0.0003065712080569938, Final Batch Loss: 4.271193756721914e-05\n",
      "Epoch 4613, Loss: 0.02638386725448072, Final Batch Loss: 0.0\n",
      "Epoch 4614, Loss: 0.06350028838141952, Final Batch Loss: 4.1785383473325055e-06\n",
      "Epoch 4615, Loss: 0.005418294011750646, Final Batch Loss: 3.137086324045413e-08\n",
      "Epoch 4616, Loss: 0.015583447644530679, Final Batch Loss: 2.6940686439047568e-05\n",
      "Epoch 4617, Loss: 0.0018033157102763653, Final Batch Loss: 0.00010365675552748144\n",
      "Epoch 4618, Loss: 0.00020985923038097098, Final Batch Loss: 4.015455488115549e-07\n",
      "Epoch 4619, Loss: 0.01306872071018006, Final Batch Loss: 3.626363650255371e-06\n",
      "Epoch 4620, Loss: 0.01646356609853683, Final Batch Loss: 3.450956864980981e-05\n",
      "Epoch 4621, Loss: 0.0013393372781962398, Final Batch Loss: 1.5685408527588152e-07\n",
      "Epoch 4622, Loss: 0.026260093691234943, Final Batch Loss: 2.126003528246656e-05\n",
      "Epoch 4623, Loss: 0.0017861444503068924, Final Batch Loss: 6.349396426230669e-05\n",
      "Epoch 4624, Loss: 0.012389134062686935, Final Batch Loss: 0.010900995694100857\n",
      "Epoch 4625, Loss: 0.021869752627026173, Final Batch Loss: 9.596021845936775e-05\n",
      "Epoch 4626, Loss: 0.20153633000518312, Final Batch Loss: 0.20143936574459076\n",
      "Epoch 4627, Loss: 0.002663173149812792, Final Batch Loss: 0.00015671926666982472\n",
      "Epoch 4628, Loss: 0.022478944425671443, Final Batch Loss: 2.1959581886221713e-07\n",
      "Epoch 4629, Loss: 0.0014573598455172032, Final Batch Loss: 0.00016992950986605138\n",
      "Epoch 4630, Loss: 0.019061629922362044, Final Batch Loss: 0.0004346897767391056\n",
      "Epoch 4631, Loss: 0.0012300687553761236, Final Batch Loss: 6.079327704355819e-06\n",
      "Epoch 4632, Loss: 0.0014225924151105573, Final Batch Loss: 2.3616970793227665e-05\n",
      "Epoch 4633, Loss: 0.00020495408784881874, Final Batch Loss: 9.975872217182769e-07\n",
      "Epoch 4634, Loss: 0.04640054264598348, Final Batch Loss: 3.952721954192384e-07\n",
      "Epoch 4635, Loss: 0.0011914685965166427, Final Batch Loss: 0.000155607151100412\n",
      "Epoch 4636, Loss: 0.0025779344450711505, Final Batch Loss: 2.85149162664311e-05\n",
      "Epoch 4637, Loss: 0.0070070421852506115, Final Batch Loss: 1.173798864329001e-05\n",
      "Epoch 4638, Loss: 0.0006032469642320848, Final Batch Loss: 4.2036808167722484e-07\n",
      "Epoch 4639, Loss: 0.0002845195751888241, Final Batch Loss: 1.0728774668677943e-06\n",
      "Epoch 4640, Loss: 0.0020158299485046882, Final Batch Loss: 5.619388321065344e-05\n",
      "Epoch 4641, Loss: 0.0008889379878382897, Final Batch Loss: 2.487823621777352e-05\n",
      "Epoch 4642, Loss: 0.001976682644453831, Final Batch Loss: 7.295259274542332e-05\n",
      "Epoch 4643, Loss: 0.003009356281836517, Final Batch Loss: 0.00016870191029738635\n",
      "Epoch 4644, Loss: 0.00015900160042292555, Final Batch Loss: 4.824669758818345e-06\n",
      "Epoch 4645, Loss: 0.0011984719894826412, Final Batch Loss: 0.0005904911668039858\n",
      "Epoch 4646, Loss: 0.00015447183039896117, Final Batch Loss: 9.034753816195007e-07\n",
      "Epoch 4647, Loss: 0.0016146040925377747, Final Batch Loss: 9.793124263524078e-06\n",
      "Epoch 4648, Loss: 0.00030279291968327016, Final Batch Loss: 6.255612970562652e-05\n",
      "Epoch 4649, Loss: 0.0007630517120560398, Final Batch Loss: 8.045585127547383e-05\n",
      "Epoch 4650, Loss: 0.0004508125367692628, Final Batch Loss: 1.2297260809646104e-06\n",
      "Epoch 4651, Loss: 0.0008452269285044167, Final Batch Loss: 0.000516930129379034\n",
      "Epoch 4652, Loss: 0.000571707930419052, Final Batch Loss: 3.639008241407282e-07\n",
      "Epoch 4653, Loss: 0.0002031418389378814, Final Batch Loss: 5.451348260976374e-05\n",
      "Epoch 4654, Loss: 0.015660787361412076, Final Batch Loss: 0.015564840286970139\n",
      "Epoch 4655, Loss: 0.00035485593312500896, Final Batch Loss: 2.007733712616755e-07\n",
      "Epoch 4656, Loss: 0.0009110381179198157, Final Batch Loss: 2.205127020715736e-05\n",
      "Epoch 4657, Loss: 0.0007354490318789431, Final Batch Loss: 5.458516056933149e-07\n",
      "Epoch 4658, Loss: 0.003965703908761498, Final Batch Loss: 0.0026314083952456713\n",
      "Epoch 4659, Loss: 0.000211003107324359, Final Batch Loss: 3.419316271902062e-06\n",
      "Epoch 4660, Loss: 0.00022019563994035707, Final Batch Loss: 1.719110969133908e-06\n",
      "Epoch 4661, Loss: 0.00013934853109276446, Final Batch Loss: 3.5385148748900974e-06\n",
      "Epoch 4662, Loss: 0.00025022265344887273, Final Batch Loss: 9.777017112355679e-05\n",
      "Epoch 4663, Loss: 0.0010940714637399651, Final Batch Loss: 6.325587310129777e-05\n",
      "Epoch 4664, Loss: 0.0035120820616612036, Final Batch Loss: 3.965128144045593e-06\n",
      "Epoch 4665, Loss: 0.0003904935401806142, Final Batch Loss: 2.3096457880456e-05\n",
      "Epoch 4666, Loss: 9.728158602229087e-05, Final Batch Loss: 1.5685418475186452e-07\n",
      "Epoch 4667, Loss: 0.000987402177226926, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 4668, Loss: 0.00024387000178194285, Final Batch Loss: 1.7567674603924388e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4669, Loss: 0.0003603703561338989, Final Batch Loss: 1.4618752857131767e-06\n",
      "Epoch 4670, Loss: 0.0001321341810580634, Final Batch Loss: 3.7740497646154836e-05\n",
      "Epoch 4671, Loss: 0.00017557176761329174, Final Batch Loss: 4.0406168409390375e-05\n",
      "Epoch 4672, Loss: 0.0011568412537599215, Final Batch Loss: 4.178005110588856e-05\n",
      "Epoch 4673, Loss: 0.00018803277635015547, Final Batch Loss: 1.7121170458267443e-05\n",
      "Epoch 4674, Loss: 0.0004796205994352931, Final Batch Loss: 2.3034948753775097e-05\n",
      "Epoch 4675, Loss: 0.00011926913693116603, Final Batch Loss: 1.5685408527588152e-07\n",
      "Epoch 4676, Loss: 0.0003345503610034939, Final Batch Loss: 0.00012340072134975344\n",
      "Epoch 4677, Loss: 0.00030470137198790326, Final Batch Loss: 5.445717306429287e-06\n",
      "Epoch 4678, Loss: 0.00037396361767605413, Final Batch Loss: 1.9371329472051002e-05\n",
      "Epoch 4679, Loss: 0.00018183648718661516, Final Batch Loss: 1.6940249736308033e-07\n",
      "Epoch 4680, Loss: 0.0009637835755711421, Final Batch Loss: 0.0006453182431869209\n",
      "Epoch 4681, Loss: 0.00035700120099591004, Final Batch Loss: 1.8445749674356193e-06\n",
      "Epoch 4682, Loss: 0.0006835751597691342, Final Batch Loss: 4.517393108471879e-07\n",
      "Epoch 4683, Loss: 0.00018133212756765715, Final Batch Loss: 2.421794079054962e-06\n",
      "Epoch 4684, Loss: 0.0003614597917191986, Final Batch Loss: 1.6940245473051618e-07\n",
      "Epoch 4685, Loss: 0.0008037829247768968, Final Batch Loss: 3.997518797405064e-05\n",
      "Epoch 4686, Loss: 0.00016869394744389865, Final Batch Loss: 2.961326345030102e-06\n",
      "Epoch 4687, Loss: 0.0008336723112734035, Final Batch Loss: 0.0004881623317487538\n",
      "Epoch 4688, Loss: 0.0010752305679488927, Final Batch Loss: 0.0\n",
      "Epoch 4689, Loss: 0.01097879814915359, Final Batch Loss: 0.008745883591473103\n",
      "Epoch 4690, Loss: 0.000650535432214383, Final Batch Loss: 9.504721674602479e-05\n",
      "Epoch 4691, Loss: 0.000125525456496689, Final Batch Loss: 5.909968422201928e-06\n",
      "Epoch 4692, Loss: 0.00013681255006758875, Final Batch Loss: 1.5622568980688811e-06\n",
      "Epoch 4693, Loss: 0.037706468770423385, Final Batch Loss: 1.3803169451875874e-07\n",
      "Epoch 4694, Loss: 0.0011813397351438937, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4695, Loss: 0.0003874000489361151, Final Batch Loss: 3.450790302395035e-07\n",
      "Epoch 4696, Loss: 0.0022915770672966573, Final Batch Loss: 5.082069378659071e-07\n",
      "Epoch 4697, Loss: 0.00011584679009501997, Final Batch Loss: 1.988898247873294e-06\n",
      "Epoch 4698, Loss: 0.0037516616721404716, Final Batch Loss: 0.00022623744735028595\n",
      "Epoch 4699, Loss: 0.000639832302567811, Final Batch Loss: 0.00014557215035893023\n",
      "Epoch 4700, Loss: 0.00042920684472846915, Final Batch Loss: 1.5058003555168398e-07\n",
      "Epoch 4701, Loss: 0.00010262964360663318, Final Batch Loss: 3.419372205826221e-06\n",
      "Epoch 4702, Loss: 0.0007822566476534121, Final Batch Loss: 0.0006128895911388099\n",
      "Epoch 4703, Loss: 0.0003459033578110393, Final Batch Loss: 0.00019252307538408786\n",
      "Epoch 4704, Loss: 0.000684647420712281, Final Batch Loss: 0.0005524037405848503\n",
      "Epoch 4705, Loss: 0.0009901907906169072, Final Batch Loss: 6.487214704975486e-06\n",
      "Epoch 4706, Loss: 0.0004100189544260502, Final Batch Loss: 2.0581777789629996e-05\n",
      "Epoch 4707, Loss: 0.0027085423262178665, Final Batch Loss: 3.7580957723548636e-06\n",
      "Epoch 4708, Loss: 0.004577411091304384, Final Batch Loss: 0.003916517365723848\n",
      "Epoch 4709, Loss: 0.0008502171740474296, Final Batch Loss: 1.9575063561205752e-06\n",
      "Epoch 4710, Loss: 0.0008977649777079932, Final Batch Loss: 3.194473174517043e-05\n",
      "Epoch 4711, Loss: 0.0005414006345745292, Final Batch Loss: 2.0014313122374006e-06\n",
      "Epoch 4712, Loss: 0.0005540390540375029, Final Batch Loss: 3.764490941193799e-07\n",
      "Epoch 4713, Loss: 0.00014950238810307326, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 4714, Loss: 9.161682201153099e-05, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4715, Loss: 0.0008797302680250141, Final Batch Loss: 9.913101166603155e-07\n",
      "Epoch 4716, Loss: 0.0007910554732006858, Final Batch Loss: 0.0005801778752356768\n",
      "Epoch 4717, Loss: 0.005045235622539224, Final Batch Loss: 1.1920915454766146e-07\n",
      "Epoch 4718, Loss: 0.000350165537383873, Final Batch Loss: 8.005894051166251e-05\n",
      "Epoch 4719, Loss: 0.0012201199824630748, Final Batch Loss: 0.001101720961742103\n",
      "Epoch 4720, Loss: 0.00026511985197430477, Final Batch Loss: 6.332624616334215e-05\n",
      "Epoch 4721, Loss: 0.00021334009215934202, Final Batch Loss: 3.301751348772086e-05\n",
      "Epoch 4722, Loss: 0.003693819234314333, Final Batch Loss: 1.5685421317357395e-07\n",
      "Epoch 4723, Loss: 0.03975110804094584, Final Batch Loss: 0.00020563545695040375\n",
      "Epoch 4724, Loss: 0.030463761373539455, Final Batch Loss: 2.217026485595852e-05\n",
      "Epoch 4725, Loss: 0.00011340789799385576, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4726, Loss: 0.004932831216137856, Final Batch Loss: 0.00036003923742100596\n",
      "Epoch 4727, Loss: 0.0008547777906642295, Final Batch Loss: 3.008233761647716e-05\n",
      "Epoch 4728, Loss: 0.0020034664994454943, Final Batch Loss: 0.00011054972856072709\n",
      "Epoch 4729, Loss: 0.0006656900604866678, Final Batch Loss: 2.1096328055136837e-05\n",
      "Epoch 4730, Loss: 0.00016323607314916444, Final Batch Loss: 4.234909738443093e-06\n",
      "Epoch 4731, Loss: 0.0005115120329719502, Final Batch Loss: 0.0001528801367385313\n",
      "Epoch 4732, Loss: 0.0002543379996495787, Final Batch Loss: 9.310501627624035e-05\n",
      "Epoch 4733, Loss: 0.00020595079331542365, Final Batch Loss: 3.1212071917252615e-05\n",
      "Epoch 4734, Loss: 0.0004049269227834884, Final Batch Loss: 4.197058660793118e-05\n",
      "Epoch 4735, Loss: 0.00017324370219284901, Final Batch Loss: 9.279120604333002e-06\n",
      "Epoch 4736, Loss: 0.00030165243532565, Final Batch Loss: 5.395779112404853e-07\n",
      "Epoch 4737, Loss: 0.006280901695504326, Final Batch Loss: 1.0854265610760194e-06\n",
      "Epoch 4738, Loss: 0.0014251534503273433, Final Batch Loss: 1.2503243851824664e-05\n",
      "Epoch 4739, Loss: 0.00037077405431773514, Final Batch Loss: 1.1738047760445625e-05\n",
      "Epoch 4740, Loss: 0.00014755225699758512, Final Batch Loss: 7.529003909212406e-08\n",
      "Epoch 4741, Loss: 0.00011977414669672726, Final Batch Loss: 1.0163316801481415e-05\n",
      "Epoch 4742, Loss: 0.00018977616099391525, Final Batch Loss: 2.1332169808374601e-07\n",
      "Epoch 4743, Loss: 0.0002645480390128796, Final Batch Loss: 1.339367463515373e-05\n",
      "Epoch 4744, Loss: 0.0009035028288977287, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4745, Loss: 0.00022320588686852716, Final Batch Loss: 6.669627327937633e-05\n",
      "Epoch 4746, Loss: 0.00040574065726639574, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4747, Loss: 0.003570232509446214, Final Batch Loss: 1.0352287063142285e-06\n",
      "Epoch 4748, Loss: 0.002293812644893478, Final Batch Loss: 5.132106707605999e-06\n",
      "Epoch 4749, Loss: 0.0006409662494775148, Final Batch Loss: 6.964294811950822e-07\n",
      "Epoch 4750, Loss: 0.00042924114586639917, Final Batch Loss: 1.0238559298159089e-05\n",
      "Epoch 4751, Loss: 0.0009110929750022478, Final Batch Loss: 0.00038964312989264727\n",
      "Epoch 4752, Loss: 0.000251147544986452, Final Batch Loss: 0.00011021221143892035\n",
      "Epoch 4753, Loss: 0.0005759743421549501, Final Batch Loss: 4.749343588628108e-06\n",
      "Epoch 4754, Loss: 0.0001954993939961014, Final Batch Loss: 1.8195071049831313e-07\n",
      "Epoch 4755, Loss: 0.0003218522645909161, Final Batch Loss: 8.783840144133137e-08\n",
      "Epoch 4756, Loss: 0.0005787471795883903, Final Batch Loss: 1.1167917364218738e-06\n",
      "Epoch 4757, Loss: 0.0018870209041779162, Final Batch Loss: 2.662821498233825e-05\n",
      "Epoch 4758, Loss: 0.005836418327817228, Final Batch Loss: 9.573600436851848e-06\n",
      "Epoch 4759, Loss: 0.004202296613584622, Final Batch Loss: 1.8142140106647275e-05\n",
      "Epoch 4760, Loss: 0.000557990169909317, Final Batch Loss: 5.194764526095241e-06\n",
      "Epoch 4761, Loss: 0.0002658423691173084, Final Batch Loss: 3.305963036837056e-05\n",
      "Epoch 4762, Loss: 0.0031212719513860065, Final Batch Loss: 3.2584273867541924e-05\n",
      "Epoch 4763, Loss: 0.0008556303364457563, Final Batch Loss: 0.00042902733548544347\n",
      "Epoch 4764, Loss: 0.00018277184426551685, Final Batch Loss: 7.660032861167565e-05\n",
      "Epoch 4765, Loss: 0.010847949208823593, Final Batch Loss: 1.3489321872839355e-06\n",
      "Epoch 4766, Loss: 0.0003405945600434279, Final Batch Loss: 1.706553234726016e-06\n",
      "Epoch 4767, Loss: 8.955316997116824e-05, Final Batch Loss: 3.1370808528663474e-07\n",
      "Epoch 4768, Loss: 0.0008913620501971309, Final Batch Loss: 6.274156021390809e-07\n",
      "Epoch 4769, Loss: 0.00010439497054903768, Final Batch Loss: 3.172341894241981e-05\n",
      "Epoch 4770, Loss: 0.0008006182579265442, Final Batch Loss: 0.00016106473049148917\n",
      "Epoch 4771, Loss: 0.0004809324791965608, Final Batch Loss: 1.2548345473817335e-08\n",
      "Epoch 4772, Loss: 0.0017717230002745055, Final Batch Loss: 6.0069840401411057e-05\n",
      "Epoch 4773, Loss: 0.00013950255015515722, Final Batch Loss: 3.259079676354304e-05\n",
      "Epoch 4774, Loss: 0.00019361893282621168, Final Batch Loss: 0.00010747314081527293\n",
      "Epoch 4775, Loss: 0.0008036954404246899, Final Batch Loss: 3.45078603913862e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4776, Loss: 0.0019518083609000314, Final Batch Loss: 0.0017164679011330009\n",
      "Epoch 4777, Loss: 0.0005087996978545561, Final Batch Loss: 0.00017419661162421107\n",
      "Epoch 4778, Loss: 7.404926691378932e-05, Final Batch Loss: 2.333943484700285e-06\n",
      "Epoch 4779, Loss: 0.00027117091303807683, Final Batch Loss: 4.658675970858894e-05\n",
      "Epoch 4780, Loss: 0.02177010467130458, Final Batch Loss: 3.377571192686446e-05\n",
      "Epoch 4781, Loss: 0.00012701951527560595, Final Batch Loss: 3.6490760976448655e-05\n",
      "Epoch 4782, Loss: 0.00011492032024307264, Final Batch Loss: 1.2673739320234745e-06\n",
      "Epoch 4783, Loss: 0.00027620540095085744, Final Batch Loss: 7.974223990458995e-06\n",
      "Epoch 4784, Loss: 0.0019426078961259918, Final Batch Loss: 2.0516181393759325e-06\n",
      "Epoch 4785, Loss: 0.0008702447991026929, Final Batch Loss: 9.66214088293782e-07\n",
      "Epoch 4786, Loss: 0.00014727972883576967, Final Batch Loss: 1.254833392749788e-07\n",
      "Epoch 4787, Loss: 0.00041816224893409526, Final Batch Loss: 6.618908628297504e-06\n",
      "Epoch 4788, Loss: 0.0005119550305607845, Final Batch Loss: 8.971645911515225e-06\n",
      "Epoch 4789, Loss: 0.00024435792101940024, Final Batch Loss: 6.844843937869882e-06\n",
      "Epoch 4790, Loss: 0.0005073541728961573, Final Batch Loss: 3.6891656236548442e-06\n",
      "Epoch 4791, Loss: 0.0012797709732694784, Final Batch Loss: 2.0175613826722838e-05\n",
      "Epoch 4792, Loss: 0.0003461030495373052, Final Batch Loss: 1.6563639064770541e-06\n",
      "Epoch 4793, Loss: 0.00018769038797472604, Final Batch Loss: 1.575853821123019e-05\n",
      "Epoch 4794, Loss: 0.0002496981876447535, Final Batch Loss: 5.144800070411293e-07\n",
      "Epoch 4795, Loss: 0.002034456927503925, Final Batch Loss: 0.0008803583332337439\n",
      "Epoch 4796, Loss: 0.000977882864390267, Final Batch Loss: 7.55356450099498e-06\n",
      "Epoch 4797, Loss: 0.00015782748550918768, Final Batch Loss: 2.1269111130095553e-06\n",
      "Epoch 4798, Loss: 0.00025844949459497, Final Batch Loss: 7.233633823489072e-06\n",
      "Epoch 4799, Loss: 0.00012058856100338744, Final Batch Loss: 1.1073355381086003e-05\n",
      "Epoch 4800, Loss: 0.0002519112995287287, Final Batch Loss: 6.280074558162596e-06\n",
      "Epoch 4801, Loss: 0.001363696460657593, Final Batch Loss: 1.8194925814896123e-06\n",
      "Epoch 4802, Loss: 0.0022755518730264157, Final Batch Loss: 0.0012176985619589686\n",
      "Epoch 4803, Loss: 0.0012754082708852366, Final Batch Loss: 0.0010207155719399452\n",
      "Epoch 4804, Loss: 7.04755093465792e-05, Final Batch Loss: 7.666807505302131e-06\n",
      "Epoch 4805, Loss: 0.0001808480083127506, Final Batch Loss: 8.880566019797698e-05\n",
      "Epoch 4806, Loss: 0.001954860474427278, Final Batch Loss: 7.905421739451413e-07\n",
      "Epoch 4807, Loss: 0.00017562679761340405, Final Batch Loss: 1.6751783959989552e-06\n",
      "Epoch 4808, Loss: 0.0005082538809801918, Final Batch Loss: 5.836768832523376e-05\n",
      "Epoch 4809, Loss: 0.00027183020756638143, Final Batch Loss: 2.039067112491466e-06\n",
      "Epoch 4810, Loss: 0.00013546826949095703, Final Batch Loss: 2.189648057537852e-06\n",
      "Epoch 4811, Loss: 0.00029254942000989104, Final Batch Loss: 9.053293069882784e-06\n",
      "Epoch 4812, Loss: 7.123598152247723e-05, Final Batch Loss: 1.8124650523532182e-05\n",
      "Epoch 4813, Loss: 0.0003867029888056095, Final Batch Loss: 4.6428675659626606e-07\n",
      "Epoch 4814, Loss: 0.00013236000359029276, Final Batch Loss: 1.3400229363469407e-05\n",
      "Epoch 4815, Loss: 0.001215846032778245, Final Batch Loss: 1.361486852147209e-06\n",
      "Epoch 4816, Loss: 0.00039394434014639046, Final Batch Loss: 4.454656732377771e-07\n",
      "Epoch 4817, Loss: 0.0001448080802788354, Final Batch Loss: 1.0038667141998303e-07\n",
      "Epoch 4818, Loss: 0.00031242643052564745, Final Batch Loss: 5.521243906514428e-07\n",
      "Epoch 4819, Loss: 4.473459942033742e-05, Final Batch Loss: 6.274169805919882e-08\n",
      "Epoch 4820, Loss: 0.001134157366323052, Final Batch Loss: 3.9318296330748126e-05\n",
      "Epoch 4821, Loss: 0.00022706428535457235, Final Batch Loss: 2.411337845842354e-05\n",
      "Epoch 4822, Loss: 0.0035206512602599105, Final Batch Loss: 0.0033765905536711216\n",
      "Epoch 4823, Loss: 0.0005252609043964185, Final Batch Loss: 0.0003541519690770656\n",
      "Epoch 4824, Loss: 0.00035539557038077874, Final Batch Loss: 3.76449037275961e-07\n",
      "Epoch 4825, Loss: 0.0002550348872318864, Final Batch Loss: 8.449723100056872e-05\n",
      "Epoch 4826, Loss: 0.00043932015250902623, Final Batch Loss: 2.051616320386529e-06\n",
      "Epoch 4827, Loss: 0.0020901366115140263, Final Batch Loss: 4.410567271406762e-06\n",
      "Epoch 4828, Loss: 0.0005497083660657154, Final Batch Loss: 4.203687922199606e-07\n",
      "Epoch 4829, Loss: 0.0008177037225323147, Final Batch Loss: 1.8508571884012781e-06\n",
      "Epoch 4830, Loss: 0.0001529742294223979, Final Batch Loss: 9.632771252654493e-05\n",
      "Epoch 4831, Loss: 0.00012502302524808329, Final Batch Loss: 1.2446836990420707e-05\n",
      "Epoch 4832, Loss: 0.0011517786533659091, Final Batch Loss: 1.620382499822881e-05\n",
      "Epoch 4833, Loss: 0.0009352308607049054, Final Batch Loss: 8.443908154731616e-05\n",
      "Epoch 4834, Loss: 9.014083070724155e-05, Final Batch Loss: 3.977733740612166e-06\n",
      "Epoch 4835, Loss: 0.0009707768476800993, Final Batch Loss: 0.00033218300086446106\n",
      "Epoch 4836, Loss: 0.002028453518960305, Final Batch Loss: 0.0016541483346372843\n",
      "Epoch 4837, Loss: 0.0010300898185846563, Final Batch Loss: 4.831101136915095e-07\n",
      "Epoch 4838, Loss: 0.042785629201262054, Final Batch Loss: 6.242437393666478e-06\n",
      "Epoch 4839, Loss: 0.0003810997659456916, Final Batch Loss: 0.00011483783600851893\n",
      "Epoch 4840, Loss: 4.4200807678862475e-05, Final Batch Loss: 4.316507784096757e-06\n",
      "Epoch 4841, Loss: 4.824012610349371e-05, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 4842, Loss: 0.00016905653774301754, Final Batch Loss: 7.466214810847305e-07\n",
      "Epoch 4843, Loss: 0.00038983932972769253, Final Batch Loss: 6.239797221496701e-05\n",
      "Epoch 4844, Loss: 0.00011892072348018701, Final Batch Loss: 1.944960104083293e-06\n",
      "Epoch 4845, Loss: 0.002792073297314346, Final Batch Loss: 0.002258766209706664\n",
      "Epoch 4846, Loss: 0.009781278852244668, Final Batch Loss: 5.960433213658689e-07\n",
      "Epoch 4847, Loss: 0.0001105246853185804, Final Batch Loss: 4.391919361523833e-08\n",
      "Epoch 4848, Loss: 0.0003625110402936116, Final Batch Loss: 1.8925937183666974e-05\n",
      "Epoch 4849, Loss: 0.0003737899533007294, Final Batch Loss: 0.00016730466450098902\n",
      "Epoch 4850, Loss: 0.00011190389204784879, Final Batch Loss: 2.879779913200764e-06\n",
      "Epoch 4851, Loss: 0.00018835983155440772, Final Batch Loss: 1.1204495422134642e-05\n",
      "Epoch 4852, Loss: 0.000674011763294402, Final Batch Loss: 0.00025410301168449223\n",
      "Epoch 4853, Loss: 0.00023891429373179562, Final Batch Loss: 3.837748954538256e-05\n",
      "Epoch 4854, Loss: 0.00015608380635967478, Final Batch Loss: 7.335750706261024e-05\n",
      "Epoch 4855, Loss: 0.0015272175005520694, Final Batch Loss: 0.0008065571892075241\n",
      "Epoch 4856, Loss: 0.00017157538422907237, Final Batch Loss: 0.0\n",
      "Epoch 4857, Loss: 0.00017497840751445892, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 4858, Loss: 0.009885773809401144, Final Batch Loss: 0.0016909906407818198\n",
      "Epoch 4859, Loss: 0.00029175897179811727, Final Batch Loss: 2.5974441086873412e-06\n",
      "Epoch 4860, Loss: 0.0004270158533472568, Final Batch Loss: 9.26797220017761e-05\n",
      "Epoch 4861, Loss: 0.00039951531198312296, Final Batch Loss: 1.095433526643319e-05\n",
      "Epoch 4862, Loss: 0.00010246044908157614, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 4863, Loss: 0.06986620071984362, Final Batch Loss: 0.06980134546756744\n",
      "Epoch 4864, Loss: 0.0006133947863418143, Final Batch Loss: 5.369689824874513e-05\n",
      "Epoch 4865, Loss: 0.0005346302932593971, Final Batch Loss: 0.0004525473923422396\n",
      "Epoch 4866, Loss: 0.00037625237928295974, Final Batch Loss: 2.8508535251603462e-05\n",
      "Epoch 4867, Loss: 0.0005431727928453256, Final Batch Loss: 4.768349981532083e-07\n",
      "Epoch 4868, Loss: 0.0013185399350277294, Final Batch Loss: 2.867256853278377e-06\n",
      "Epoch 4869, Loss: 0.0010378971637692302, Final Batch Loss: 0.00020703526388388127\n",
      "Epoch 4870, Loss: 0.0009985338838305324, Final Batch Loss: 0.0\n",
      "Epoch 4871, Loss: 0.0004885766575171147, Final Batch Loss: 7.905400707386434e-07\n",
      "Epoch 4872, Loss: 0.0011089805375377182, Final Batch Loss: 3.6729707062477246e-05\n",
      "Epoch 4873, Loss: 0.003915336104000744, Final Batch Loss: 9.542335646983702e-06\n",
      "Epoch 4874, Loss: 0.0031366543553303927, Final Batch Loss: 0.0003070902021136135\n",
      "Epoch 4875, Loss: 0.0002957684582725051, Final Batch Loss: 1.0746977750386577e-05\n",
      "Epoch 4876, Loss: 0.00021444539319759315, Final Batch Loss: 8.783840144133137e-08\n",
      "Epoch 4877, Loss: 0.000466223711555358, Final Batch Loss: 0.0002916887460742146\n",
      "Epoch 4878, Loss: 0.0005377109646360623, Final Batch Loss: 0.0003458608698565513\n",
      "Epoch 4879, Loss: 0.0007341752352658659, Final Batch Loss: 0.0004803657066076994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4880, Loss: 0.0009602560930943582, Final Batch Loss: 1.573955887579359e-05\n",
      "Epoch 4881, Loss: 5.809465706363426e-05, Final Batch Loss: 1.5685414211930038e-07\n",
      "Epoch 4882, Loss: 0.0008018744716764559, Final Batch Loss: 1.1732641951311962e-06\n",
      "Epoch 4883, Loss: 0.0002154611393052619, Final Batch Loss: 9.05301931197755e-06\n",
      "Epoch 4884, Loss: 0.0013056791085546138, Final Batch Loss: 3.0252953365561552e-05\n",
      "Epoch 4885, Loss: 0.011817212296591606, Final Batch Loss: 0.0015862858854234219\n",
      "Epoch 4886, Loss: 0.00020472773849178338, Final Batch Loss: 1.4102462046139408e-05\n",
      "Epoch 4887, Loss: 0.00022920478386367904, Final Batch Loss: 9.682891686679795e-05\n",
      "Epoch 4888, Loss: 7.614210601047944e-05, Final Batch Loss: 4.3919200720665685e-08\n",
      "Epoch 4889, Loss: 0.009168521683477593, Final Batch Loss: 3.5385169212531764e-06\n",
      "Epoch 4890, Loss: 0.0079981161857412, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4891, Loss: 0.0010594397408567602, Final Batch Loss: 1.5432751752086915e-05\n",
      "Epoch 4892, Loss: 0.05061347688751994, Final Batch Loss: 9.787145245354623e-06\n",
      "Epoch 4893, Loss: 0.0012743691040668637, Final Batch Loss: 0.00014293847198132426\n",
      "Epoch 4894, Loss: 0.0016037672277455783, Final Batch Loss: 3.7645033756916746e-08\n",
      "Epoch 4895, Loss: 0.0017984789737965912, Final Batch Loss: 0.00027396902441978455\n",
      "Epoch 4896, Loss: 0.0011817724589491263, Final Batch Loss: 0.0008457714575342834\n",
      "Epoch 4897, Loss: 0.001123149908380583, Final Batch Loss: 0.0008554826490581036\n",
      "Epoch 4898, Loss: 0.0006028236894053407, Final Batch Loss: 6.88414802425541e-05\n",
      "Epoch 4899, Loss: 0.00021805784319894883, Final Batch Loss: 1.631260715839744e-06\n",
      "Epoch 4900, Loss: 0.0005027810623232654, Final Batch Loss: 5.019321633881191e-07\n",
      "Epoch 4901, Loss: 0.0007320650497839587, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4902, Loss: 0.00029118524244609034, Final Batch Loss: 1.1920920428565296e-07\n",
      "Epoch 4903, Loss: 0.0014130185882095248, Final Batch Loss: 0.00017423467943444848\n",
      "Epoch 4904, Loss: 0.0007442773639922962, Final Batch Loss: 0.0\n",
      "Epoch 4905, Loss: 0.0008853856263613125, Final Batch Loss: 1.5434336546604754e-06\n",
      "Epoch 4906, Loss: 0.001380461937515065, Final Batch Loss: 0.000892787182237953\n",
      "Epoch 4907, Loss: 0.0001190333050544723, Final Batch Loss: 8.09936045698123e-06\n",
      "Epoch 4908, Loss: 0.0035199092380935326, Final Batch Loss: 0.0003386425378266722\n",
      "Epoch 4909, Loss: 0.00018295837213599953, Final Batch Loss: 8.470065608889854e-07\n",
      "Epoch 4910, Loss: 0.00012875271126588927, Final Batch Loss: 3.764502665148939e-08\n",
      "Epoch 4911, Loss: 9.741259327711305e-05, Final Batch Loss: 6.487301106972154e-06\n",
      "Epoch 4912, Loss: 0.00019094117267393074, Final Batch Loss: 1.8822516878458373e-08\n",
      "Epoch 4913, Loss: 0.0006308830173225033, Final Batch Loss: 3.137077442261216e-07\n",
      "Epoch 4914, Loss: 0.00025109960513702845, Final Batch Loss: 1.8822518654815212e-08\n",
      "Epoch 4915, Loss: 0.0026228368806187063, Final Batch Loss: 8.191080996766686e-05\n",
      "Epoch 4916, Loss: 0.00036745182086406203, Final Batch Loss: 5.583985398516234e-07\n",
      "Epoch 4917, Loss: 0.000571575958019821, Final Batch Loss: 0.0004658479301724583\n",
      "Epoch 4918, Loss: 0.00013661841944667685, Final Batch Loss: 1.411672883477877e-06\n",
      "Epoch 4919, Loss: 0.00014801043116818846, Final Batch Loss: 2.509668917127783e-08\n",
      "Epoch 4920, Loss: 0.00025964465939942727, Final Batch Loss: 2.509668739492099e-08\n",
      "Epoch 4921, Loss: 0.00015223221930682485, Final Batch Loss: 3.086824335696292e-06\n",
      "Epoch 4922, Loss: 0.00028607709330197295, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4923, Loss: 0.006527103600092232, Final Batch Loss: 0.004785966128110886\n",
      "Epoch 4924, Loss: 5.426395330232481e-05, Final Batch Loss: 6.399637868526042e-07\n",
      "Epoch 4925, Loss: 0.027536300687643234, Final Batch Loss: 0.0004577096551656723\n",
      "Epoch 4926, Loss: 0.00047686086759313184, Final Batch Loss: 3.0491617053485243e-06\n",
      "Epoch 4927, Loss: 0.0001268408562964396, Final Batch Loss: 1.4242181123336195e-06\n",
      "Epoch 4928, Loss: 0.00047071629887796007, Final Batch Loss: 0.00013540433428715914\n",
      "Epoch 4929, Loss: 0.001909046302898787, Final Batch Loss: 0.0014156393008306623\n",
      "Epoch 4930, Loss: 0.060808405629359186, Final Batch Loss: 0.0013030460104346275\n",
      "Epoch 4931, Loss: 0.0005526102395378985, Final Batch Loss: 7.001103222137317e-05\n",
      "Epoch 4932, Loss: 0.00010021975776908221, Final Batch Loss: 7.127046956156846e-06\n",
      "Epoch 4933, Loss: 0.00020451892487471923, Final Batch Loss: 1.3112603483023122e-05\n",
      "Epoch 4934, Loss: 0.009673204531736701, Final Batch Loss: 5.188496743357973e-06\n",
      "Epoch 4935, Loss: 0.002182553434977308, Final Batch Loss: 0.0013099260395392776\n",
      "Epoch 4936, Loss: 0.0001937649187198076, Final Batch Loss: 4.956575025971688e-07\n",
      "Epoch 4937, Loss: 0.031207061834720662, Final Batch Loss: 0.03073839843273163\n",
      "Epoch 4938, Loss: 0.0008332043780683307, Final Batch Loss: 0.0006143396603874862\n",
      "Epoch 4939, Loss: 0.008893794030882418, Final Batch Loss: 9.441925067221746e-05\n",
      "Epoch 4940, Loss: 0.04861818277322527, Final Batch Loss: 1.9449803403404076e-06\n",
      "Epoch 4941, Loss: 0.020186709329209407, Final Batch Loss: 1.257824078493286e-05\n",
      "Epoch 4942, Loss: 0.014121979009360075, Final Batch Loss: 0.00019839774176944047\n",
      "Epoch 4943, Loss: 0.021340593229979277, Final Batch Loss: 9.736662832438014e-06\n",
      "Epoch 4944, Loss: 0.0003385205238224387, Final Batch Loss: 5.019336057898727e-08\n",
      "Epoch 4945, Loss: 0.0008334857963028242, Final Batch Loss: 3.137085613502677e-08\n",
      "Epoch 4946, Loss: 0.034847594164602924, Final Batch Loss: 6.10880451858975e-05\n",
      "Epoch 4947, Loss: 0.0008982702320743385, Final Batch Loss: 1.2548344585638915e-08\n",
      "Epoch 4948, Loss: 0.011412345105782151, Final Batch Loss: 7.272535003721714e-05\n",
      "Epoch 4949, Loss: 0.018336621289790855, Final Batch Loss: 3.262559857830638e-07\n",
      "Epoch 4950, Loss: 0.009214903329961999, Final Batch Loss: 4.831091473533888e-07\n",
      "Epoch 4951, Loss: 0.022912727955144874, Final Batch Loss: 1.4242202723835362e-06\n",
      "Epoch 4952, Loss: 0.012083998844900634, Final Batch Loss: 7.838775491109118e-05\n",
      "Epoch 4953, Loss: 0.018015341767750215, Final Batch Loss: 1.797243567125406e-05\n",
      "Epoch 4954, Loss: 0.03365400416078046, Final Batch Loss: 0.002060431055724621\n",
      "Epoch 4955, Loss: 0.03962738998234272, Final Batch Loss: 0.0\n",
      "Epoch 4956, Loss: 0.0011003829713445157, Final Batch Loss: 5.173656973056495e-05\n",
      "Epoch 4957, Loss: 0.000540029359399341, Final Batch Loss: 0.0001522637321613729\n",
      "Epoch 4958, Loss: 0.00022644857176601363, Final Batch Loss: 3.4507843338360544e-07\n",
      "Epoch 4959, Loss: 0.006749395965016447, Final Batch Loss: 8.425908163189888e-06\n",
      "Epoch 4960, Loss: 0.002760247391137227, Final Batch Loss: 2.948855524209648e-07\n",
      "Epoch 4961, Loss: 0.0017435337358620018, Final Batch Loss: 0.0001905174576677382\n",
      "Epoch 4962, Loss: 0.0013983592248649757, Final Batch Loss: 1.882249733853314e-07\n",
      "Epoch 4963, Loss: 0.00028115324905764183, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4964, Loss: 0.00040464048379362794, Final Batch Loss: 2.264951945107896e-06\n",
      "Epoch 4965, Loss: 0.002620835744892247, Final Batch Loss: 0.0011221175082027912\n",
      "Epoch 4966, Loss: 0.0010538216301938519, Final Batch Loss: 0.00012329981836955994\n",
      "Epoch 4967, Loss: 0.0003665647091111168, Final Batch Loss: 0.00013434872380457819\n",
      "Epoch 4968, Loss: 0.0002510325219020615, Final Batch Loss: 3.0115987215140194e-07\n",
      "Epoch 4969, Loss: 0.0002195888109781663, Final Batch Loss: 1.5559808161924593e-06\n",
      "Epoch 4970, Loss: 0.0030324673280119896, Final Batch Loss: 0.00042589468648657203\n",
      "Epoch 4971, Loss: 0.0006397036850103177, Final Batch Loss: 6.121286423876882e-05\n",
      "Epoch 4972, Loss: 0.00016782524744485272, Final Batch Loss: 1.5150147191889118e-05\n",
      "Epoch 4973, Loss: 0.00010043242764368188, Final Batch Loss: 2.3857659471104853e-05\n",
      "Epoch 4974, Loss: 0.00245340140747885, Final Batch Loss: 5.207540425544721e-07\n",
      "Epoch 4975, Loss: 0.00035626373573904857, Final Batch Loss: 0.00010188874875893816\n",
      "Epoch 4976, Loss: 0.002055273493169807, Final Batch Loss: 0.001100266701541841\n",
      "Epoch 4977, Loss: 0.00013030779790312863, Final Batch Loss: 1.568541705410098e-07\n",
      "Epoch 4978, Loss: 0.00016878592768421186, Final Batch Loss: 2.4469235881952045e-07\n",
      "Epoch 4979, Loss: 0.0004044309662276646, Final Batch Loss: 5.1446932047838345e-06\n",
      "Epoch 4980, Loss: 0.00042397010838612914, Final Batch Loss: 4.276898471289314e-05\n",
      "Epoch 4981, Loss: 0.0010068526125905919, Final Batch Loss: 1.2208550288050901e-05\n",
      "Epoch 4982, Loss: 0.0005366869741436631, Final Batch Loss: 2.0077327178569249e-07\n",
      "Epoch 4983, Loss: 0.0020925593839820067, Final Batch Loss: 7.214809102151776e-06\n",
      "Epoch 4984, Loss: 0.0009579963430277338, Final Batch Loss: 6.2741727369086675e-09\n",
      "Epoch 4985, Loss: 0.0002397322950855596, Final Batch Loss: 2.8860868042102084e-06\n",
      "Epoch 4986, Loss: 0.004300366286770441, Final Batch Loss: 0.003170470241457224\n",
      "Epoch 4987, Loss: 0.0003149117219436448, Final Batch Loss: 7.632239430677146e-05\n",
      "Epoch 4988, Loss: 0.0002234068415418733, Final Batch Loss: 4.249036646797322e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4989, Loss: 0.00021546075115708163, Final Batch Loss: 6.274169805919882e-08\n",
      "Epoch 4990, Loss: 0.000176805133378366, Final Batch Loss: 4.897849794360809e-05\n",
      "Epoch 4991, Loss: 8.955323698955908e-05, Final Batch Loss: 2.8861120426881826e-07\n",
      "Epoch 4992, Loss: 0.0006410646419681143, Final Batch Loss: 0.00028556439792737365\n",
      "Epoch 4993, Loss: 0.00018428438814055426, Final Batch Loss: 1.8822518654815212e-08\n",
      "Epoch 4994, Loss: 0.0017149816085293423, Final Batch Loss: 1.2402579159243032e-05\n",
      "Epoch 4995, Loss: 0.0015182484967226628, Final Batch Loss: 0.0003077991714235395\n",
      "Epoch 4996, Loss: 0.0004284328023231865, Final Batch Loss: 1.1607097576415981e-06\n",
      "Epoch 4997, Loss: 0.0011497905943542719, Final Batch Loss: 0.0005070460611023009\n",
      "Epoch 4998, Loss: 0.000359339026545058, Final Batch Loss: 5.996534673613496e-05\n",
      "Epoch 4999, Loss: 0.0019265373814505438, Final Batch Loss: 3.2123173241416225e-06\n",
      "Epoch 5000, Loss: 0.0025719488330651075, Final Batch Loss: 0.0005853799520991743\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53  0  0]\n",
      " [ 1 35  0]\n",
      " [ 0  0 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98148   1.00000   0.99065        53\n",
      "           1    1.00000   0.97222   0.98592        36\n",
      "           2    1.00000   1.00000   1.00000        41\n",
      "\n",
      "    accuracy                        0.99231       130\n",
      "   macro avg    0.99383   0.99074   0.99219       130\n",
      "weighted avg    0.99245   0.99231   0.99229       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=107, out_features=80, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=80, out_features=60, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=60, out_features=50, bias=True)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Linear(in_features=50, out_features=37, bias=True)\n",
       "    (4): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator(z_dim = 107)\n",
    "load_model(gen, \"3 Label 4 Subject GAN Ablation_gen.param\")\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(X_test)\n",
    "latent_vectors = get_noise(size, 100)\n",
    "act_vectors = get_act_matrix(size, 3)\n",
    "usr_vectors = get_usr_matrix(size, 4)\n",
    "\n",
    "to_gen = torch.cat((latent_vectors, act_vectors[1], usr_vectors[1]), 1)\n",
    "fake_features = gen(to_gen).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  0  0]\n",
      " [ 0 41  0]\n",
      " [ 0  0 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        46\n",
      "           1    1.00000   1.00000   1.00000        41\n",
      "           2    1.00000   1.00000   1.00000        43\n",
      "\n",
      "    accuracy                        1.00000       130\n",
      "   macro avg    1.00000   1.00000   1.00000       130\n",
      "weighted avg    1.00000   1.00000   1.00000       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(act_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(act_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    else:\n",
    "        y[k] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.208044171333313, Final Batch Loss: 1.402596354484558\n",
      "Epoch 2, Loss: 4.160281300544739, Final Batch Loss: 1.3558616638183594\n",
      "Epoch 3, Loss: 4.2102391719818115, Final Batch Loss: 1.4122371673583984\n",
      "Epoch 4, Loss: 4.213953375816345, Final Batch Loss: 1.4172205924987793\n",
      "Epoch 5, Loss: 4.233203411102295, Final Batch Loss: 1.4402642250061035\n",
      "Epoch 6, Loss: 4.190505862236023, Final Batch Loss: 1.3955961465835571\n",
      "Epoch 7, Loss: 4.167497754096985, Final Batch Loss: 1.3736603260040283\n",
      "Epoch 8, Loss: 4.163690686225891, Final Batch Loss: 1.370682716369629\n",
      "Epoch 9, Loss: 4.129807710647583, Final Batch Loss: 1.3387665748596191\n",
      "Epoch 10, Loss: 4.194479823112488, Final Batch Loss: 1.408141851425171\n",
      "Epoch 11, Loss: 4.176658630371094, Final Batch Loss: 1.3896214962005615\n",
      "Epoch 12, Loss: 4.144842863082886, Final Batch Loss: 1.3559861183166504\n",
      "Epoch 13, Loss: 4.180180668830872, Final Batch Loss: 1.3935099840164185\n",
      "Epoch 14, Loss: 4.1601643562316895, Final Batch Loss: 1.3777449131011963\n",
      "Epoch 15, Loss: 4.162866830825806, Final Batch Loss: 1.3826335668563843\n",
      "Epoch 16, Loss: 4.15142297744751, Final Batch Loss: 1.3696262836456299\n",
      "Epoch 17, Loss: 4.1759666204452515, Final Batch Loss: 1.3987460136413574\n",
      "Epoch 18, Loss: 4.165153622627258, Final Batch Loss: 1.388807773590088\n",
      "Epoch 19, Loss: 4.13764500617981, Final Batch Loss: 1.3610010147094727\n",
      "Epoch 20, Loss: 4.153306245803833, Final Batch Loss: 1.3790818452835083\n",
      "Epoch 21, Loss: 4.167075514793396, Final Batch Loss: 1.3968000411987305\n",
      "Epoch 22, Loss: 4.132389068603516, Final Batch Loss: 1.3619775772094727\n",
      "Epoch 23, Loss: 4.135971307754517, Final Batch Loss: 1.3685721158981323\n",
      "Epoch 24, Loss: 4.1290576457977295, Final Batch Loss: 1.362695336341858\n",
      "Epoch 25, Loss: 4.117004632949829, Final Batch Loss: 1.3563135862350464\n",
      "Epoch 26, Loss: 4.115389823913574, Final Batch Loss: 1.3510717153549194\n",
      "Epoch 27, Loss: 4.1263896226882935, Final Batch Loss: 1.3736984729766846\n",
      "Epoch 28, Loss: 4.158660411834717, Final Batch Loss: 1.4042530059814453\n",
      "Epoch 29, Loss: 4.158807873725891, Final Batch Loss: 1.416957139968872\n",
      "Epoch 30, Loss: 4.116725325584412, Final Batch Loss: 1.381380319595337\n",
      "Epoch 31, Loss: 4.086010694503784, Final Batch Loss: 1.3565868139266968\n",
      "Epoch 32, Loss: 4.073483228683472, Final Batch Loss: 1.3454160690307617\n",
      "Epoch 33, Loss: 4.091403484344482, Final Batch Loss: 1.3834632635116577\n",
      "Epoch 34, Loss: 4.026787519454956, Final Batch Loss: 1.3437312841415405\n",
      "Epoch 35, Loss: 3.9881643056869507, Final Batch Loss: 1.3138328790664673\n",
      "Epoch 36, Loss: 3.948963761329651, Final Batch Loss: 1.2979179620742798\n",
      "Epoch 37, Loss: 3.8875843286514282, Final Batch Loss: 1.2636518478393555\n",
      "Epoch 38, Loss: 3.7991331815719604, Final Batch Loss: 1.2041985988616943\n",
      "Epoch 39, Loss: 3.7793914079666138, Final Batch Loss: 1.2197506427764893\n",
      "Epoch 40, Loss: 3.682654023170471, Final Batch Loss: 1.1728874444961548\n",
      "Epoch 41, Loss: 3.6740771532058716, Final Batch Loss: 1.201594352722168\n",
      "Epoch 42, Loss: 3.602787137031555, Final Batch Loss: 1.185341715812683\n",
      "Epoch 43, Loss: 3.5585466623306274, Final Batch Loss: 1.1784275770187378\n",
      "Epoch 44, Loss: 3.5248154401779175, Final Batch Loss: 1.1543855667114258\n",
      "Epoch 45, Loss: 3.5199867486953735, Final Batch Loss: 1.2053289413452148\n",
      "Epoch 46, Loss: 3.2701697945594788, Final Batch Loss: 0.9844558835029602\n",
      "Epoch 47, Loss: 3.4223670959472656, Final Batch Loss: 1.2020596265792847\n",
      "Epoch 48, Loss: 3.3992468118667603, Final Batch Loss: 1.2027393579483032\n",
      "Epoch 49, Loss: 3.2851122617721558, Final Batch Loss: 1.107765793800354\n",
      "Epoch 50, Loss: 3.1281535625457764, Final Batch Loss: 0.9784297943115234\n",
      "Epoch 51, Loss: 3.204969644546509, Final Batch Loss: 1.1106164455413818\n",
      "Epoch 52, Loss: 3.0523513555526733, Final Batch Loss: 0.9487805366516113\n",
      "Epoch 53, Loss: 3.1976810693740845, Final Batch Loss: 1.1241267919540405\n",
      "Epoch 54, Loss: 2.956801950931549, Final Batch Loss: 0.9420722126960754\n",
      "Epoch 55, Loss: 2.8281384110450745, Final Batch Loss: 0.8500561118125916\n",
      "Epoch 56, Loss: 3.127246081829071, Final Batch Loss: 1.1715589761734009\n",
      "Epoch 57, Loss: 2.956650674343109, Final Batch Loss: 0.9775124788284302\n",
      "Epoch 58, Loss: 2.972864329814911, Final Batch Loss: 1.0520105361938477\n",
      "Epoch 59, Loss: 2.8572663068771362, Final Batch Loss: 0.9289125204086304\n",
      "Epoch 60, Loss: 2.9979576468467712, Final Batch Loss: 1.0658276081085205\n",
      "Epoch 61, Loss: 3.03421288728714, Final Batch Loss: 1.130268931388855\n",
      "Epoch 62, Loss: 2.8224841356277466, Final Batch Loss: 0.960597574710846\n",
      "Epoch 63, Loss: 2.7587589621543884, Final Batch Loss: 0.8979727029800415\n",
      "Epoch 64, Loss: 2.91444331407547, Final Batch Loss: 1.0777496099472046\n",
      "Epoch 65, Loss: 2.9838377833366394, Final Batch Loss: 1.1656681299209595\n",
      "Epoch 66, Loss: 3.0036773681640625, Final Batch Loss: 1.157881736755371\n",
      "Epoch 67, Loss: 2.6793797612190247, Final Batch Loss: 0.8756835460662842\n",
      "Epoch 68, Loss: 2.677088439464569, Final Batch Loss: 0.8989033102989197\n",
      "Epoch 69, Loss: 2.838186204433441, Final Batch Loss: 1.0241061449050903\n",
      "Epoch 70, Loss: 2.6968818306922913, Final Batch Loss: 0.9123912453651428\n",
      "Epoch 71, Loss: 2.7716111540794373, Final Batch Loss: 0.9712892770767212\n",
      "Epoch 72, Loss: 2.7851868867874146, Final Batch Loss: 1.01518714427948\n",
      "Epoch 73, Loss: 2.6235804557800293, Final Batch Loss: 0.8907828330993652\n",
      "Epoch 74, Loss: 2.8098642826080322, Final Batch Loss: 1.061477541923523\n",
      "Epoch 75, Loss: 2.5662360191345215, Final Batch Loss: 0.8489299416542053\n",
      "Epoch 76, Loss: 2.7538039088249207, Final Batch Loss: 1.069994568824768\n",
      "Epoch 77, Loss: 2.521153509616852, Final Batch Loss: 0.7971031665802002\n",
      "Epoch 78, Loss: 2.508438527584076, Final Batch Loss: 0.8256561160087585\n",
      "Epoch 79, Loss: 2.59336119890213, Final Batch Loss: 0.9249365925788879\n",
      "Epoch 80, Loss: 2.570978581905365, Final Batch Loss: 0.8455098867416382\n",
      "Epoch 81, Loss: 2.507735013961792, Final Batch Loss: 0.8404232859611511\n",
      "Epoch 82, Loss: 2.5423883199691772, Final Batch Loss: 0.8342803120613098\n",
      "Epoch 83, Loss: 2.3847744464874268, Final Batch Loss: 0.7445352673530579\n",
      "Epoch 84, Loss: 2.3703375458717346, Final Batch Loss: 0.7224464416503906\n",
      "Epoch 85, Loss: 2.4042367339134216, Final Batch Loss: 0.8096442222595215\n",
      "Epoch 86, Loss: 2.4356717467308044, Final Batch Loss: 0.8171285390853882\n",
      "Epoch 87, Loss: 2.5778432488441467, Final Batch Loss: 1.014431357383728\n",
      "Epoch 88, Loss: 2.3156204223632812, Final Batch Loss: 0.6580440402030945\n",
      "Epoch 89, Loss: 2.4752131700515747, Final Batch Loss: 0.8793900012969971\n",
      "Epoch 90, Loss: 2.4230706691741943, Final Batch Loss: 0.8322468400001526\n",
      "Epoch 91, Loss: 2.218879818916321, Final Batch Loss: 0.6194000244140625\n",
      "Epoch 92, Loss: 2.3677086234092712, Final Batch Loss: 0.7602388858795166\n",
      "Epoch 93, Loss: 2.476287305355072, Final Batch Loss: 0.9230088591575623\n",
      "Epoch 94, Loss: 2.3348246812820435, Final Batch Loss: 0.7773557901382446\n",
      "Epoch 95, Loss: 2.3515425324440002, Final Batch Loss: 0.8077217936515808\n",
      "Epoch 96, Loss: 2.371140778064728, Final Batch Loss: 0.8347720503807068\n",
      "Epoch 97, Loss: 2.318921983242035, Final Batch Loss: 0.7857128381729126\n",
      "Epoch 98, Loss: 2.232332408428192, Final Batch Loss: 0.7003023028373718\n",
      "Epoch 99, Loss: 2.416223406791687, Final Batch Loss: 0.8636199831962585\n",
      "Epoch 100, Loss: 2.3198869824409485, Final Batch Loss: 0.7658407092094421\n",
      "Epoch 101, Loss: 2.150660812854767, Final Batch Loss: 0.6449025869369507\n",
      "Epoch 102, Loss: 2.181437611579895, Final Batch Loss: 0.6539766192436218\n",
      "Epoch 103, Loss: 2.2150861620903015, Final Batch Loss: 0.7060312628746033\n",
      "Epoch 104, Loss: 2.1493271589279175, Final Batch Loss: 0.6775490641593933\n",
      "Epoch 105, Loss: 2.156295120716095, Final Batch Loss: 0.6835152506828308\n",
      "Epoch 106, Loss: 2.1620091795921326, Final Batch Loss: 0.6948817372322083\n",
      "Epoch 107, Loss: 2.0042665004730225, Final Batch Loss: 0.507242739200592\n",
      "Epoch 108, Loss: 2.148415505886078, Final Batch Loss: 0.696029543876648\n",
      "Epoch 109, Loss: 1.9664276242256165, Final Batch Loss: 0.5358639359474182\n",
      "Epoch 110, Loss: 2.159536898136139, Final Batch Loss: 0.7646174430847168\n",
      "Epoch 111, Loss: 2.2259414196014404, Final Batch Loss: 0.7780725359916687\n",
      "Epoch 112, Loss: 2.414998412132263, Final Batch Loss: 1.042730450630188\n",
      "Epoch 113, Loss: 1.9525070190429688, Final Batch Loss: 0.5809590220451355\n",
      "Epoch 114, Loss: 2.1313629746437073, Final Batch Loss: 0.7249112129211426\n",
      "Epoch 115, Loss: 1.9408812522888184, Final Batch Loss: 0.5686489343643188\n",
      "Epoch 116, Loss: 2.0929911136627197, Final Batch Loss: 0.6862383484840393\n",
      "Epoch 117, Loss: 2.2164170145988464, Final Batch Loss: 0.8188241720199585\n",
      "Epoch 118, Loss: 1.9517082571983337, Final Batch Loss: 0.5056986808776855\n",
      "Epoch 119, Loss: 2.0934261083602905, Final Batch Loss: 0.7303892374038696\n",
      "Epoch 120, Loss: 2.0630237460136414, Final Batch Loss: 0.6997020840644836\n",
      "Epoch 121, Loss: 2.021263897418976, Final Batch Loss: 0.6573402285575867\n",
      "Epoch 122, Loss: 2.181288003921509, Final Batch Loss: 0.8099376559257507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123, Loss: 2.1412729620933533, Final Batch Loss: 0.7736306190490723\n",
      "Epoch 124, Loss: 1.9125550389289856, Final Batch Loss: 0.5828835368156433\n",
      "Epoch 125, Loss: 1.9060199856758118, Final Batch Loss: 0.5330233573913574\n",
      "Epoch 126, Loss: 1.9019542932510376, Final Batch Loss: 0.5371094346046448\n",
      "Epoch 127, Loss: 2.088755249977112, Final Batch Loss: 0.7455096244812012\n",
      "Epoch 128, Loss: 1.9948646426200867, Final Batch Loss: 0.6502655148506165\n",
      "Epoch 129, Loss: 1.8843448162078857, Final Batch Loss: 0.5824071168899536\n",
      "Epoch 130, Loss: 1.9028897881507874, Final Batch Loss: 0.6064978241920471\n",
      "Epoch 131, Loss: 2.111026108264923, Final Batch Loss: 0.798348605632782\n",
      "Epoch 132, Loss: 1.9236676692962646, Final Batch Loss: 0.6375451683998108\n",
      "Epoch 133, Loss: 2.010519802570343, Final Batch Loss: 0.710108757019043\n",
      "Epoch 134, Loss: 1.8861061334609985, Final Batch Loss: 0.6005576252937317\n",
      "Epoch 135, Loss: 1.8728023171424866, Final Batch Loss: 0.5718944668769836\n",
      "Epoch 136, Loss: 1.7501850426197052, Final Batch Loss: 0.4287702143192291\n",
      "Epoch 137, Loss: 1.911073088645935, Final Batch Loss: 0.6469516754150391\n",
      "Epoch 138, Loss: 1.8552448153495789, Final Batch Loss: 0.5953530073165894\n",
      "Epoch 139, Loss: 1.7779105305671692, Final Batch Loss: 0.5469148755073547\n",
      "Epoch 140, Loss: 2.0630542635917664, Final Batch Loss: 0.7726301550865173\n",
      "Epoch 141, Loss: 1.834193229675293, Final Batch Loss: 0.5927007794380188\n",
      "Epoch 142, Loss: 1.8592584133148193, Final Batch Loss: 0.6420106887817383\n",
      "Epoch 143, Loss: 1.8982491493225098, Final Batch Loss: 0.7001500725746155\n",
      "Epoch 144, Loss: 2.072330594062805, Final Batch Loss: 0.8456425070762634\n",
      "Epoch 145, Loss: 1.8604122400283813, Final Batch Loss: 0.5968508720397949\n",
      "Epoch 146, Loss: 1.7671915292739868, Final Batch Loss: 0.5327414870262146\n",
      "Epoch 147, Loss: 1.753162682056427, Final Batch Loss: 0.4895079731941223\n",
      "Epoch 148, Loss: 1.8410552740097046, Final Batch Loss: 0.6151570677757263\n",
      "Epoch 149, Loss: 1.6007132828235626, Final Batch Loss: 0.4218997061252594\n",
      "Epoch 150, Loss: 1.7367124557495117, Final Batch Loss: 0.5274615287780762\n",
      "Epoch 151, Loss: 1.9168484807014465, Final Batch Loss: 0.7123593688011169\n",
      "Epoch 152, Loss: 1.6719380617141724, Final Batch Loss: 0.504558801651001\n",
      "Epoch 153, Loss: 1.854575276374817, Final Batch Loss: 0.6303614974021912\n",
      "Epoch 154, Loss: 1.8751232624053955, Final Batch Loss: 0.7385708093643188\n",
      "Epoch 155, Loss: 1.6875407695770264, Final Batch Loss: 0.536551296710968\n",
      "Epoch 156, Loss: 1.7234538793563843, Final Batch Loss: 0.5807714462280273\n",
      "Epoch 157, Loss: 1.7937118411064148, Final Batch Loss: 0.6543020009994507\n",
      "Epoch 158, Loss: 1.5868147611618042, Final Batch Loss: 0.44765669107437134\n",
      "Epoch 159, Loss: 1.8304210305213928, Final Batch Loss: 0.6659397482872009\n",
      "Epoch 160, Loss: 1.6891512274742126, Final Batch Loss: 0.5671798586845398\n",
      "Epoch 161, Loss: 1.5927111208438873, Final Batch Loss: 0.447378009557724\n",
      "Epoch 162, Loss: 1.5259484946727753, Final Batch Loss: 0.42142221331596375\n",
      "Epoch 163, Loss: 1.557759404182434, Final Batch Loss: 0.41782283782958984\n",
      "Epoch 164, Loss: 1.6628074049949646, Final Batch Loss: 0.6098887920379639\n",
      "Epoch 165, Loss: 1.7639067769050598, Final Batch Loss: 0.6481910347938538\n",
      "Epoch 166, Loss: 1.6998947858810425, Final Batch Loss: 0.5446953773498535\n",
      "Epoch 167, Loss: 1.7471801042556763, Final Batch Loss: 0.6445615887641907\n",
      "Epoch 168, Loss: 1.635729193687439, Final Batch Loss: 0.5181750059127808\n",
      "Epoch 169, Loss: 1.6006144285202026, Final Batch Loss: 0.4865538477897644\n",
      "Epoch 170, Loss: 1.7356300950050354, Final Batch Loss: 0.64516282081604\n",
      "Epoch 171, Loss: 1.6440024971961975, Final Batch Loss: 0.5364812016487122\n",
      "Epoch 172, Loss: 1.7535353302955627, Final Batch Loss: 0.6298323273658752\n",
      "Epoch 173, Loss: 1.6610358953475952, Final Batch Loss: 0.5976126790046692\n",
      "Epoch 174, Loss: 1.656389057636261, Final Batch Loss: 0.6362199783325195\n",
      "Epoch 175, Loss: 1.7928483486175537, Final Batch Loss: 0.7941645383834839\n",
      "Epoch 176, Loss: 1.6183629035949707, Final Batch Loss: 0.5949971675872803\n",
      "Epoch 177, Loss: 1.3235211670398712, Final Batch Loss: 0.24219006299972534\n",
      "Epoch 178, Loss: 1.4655163288116455, Final Batch Loss: 0.43448302149772644\n",
      "Epoch 179, Loss: 1.5137262642383575, Final Batch Loss: 0.48809146881103516\n",
      "Epoch 180, Loss: 1.5134187042713165, Final Batch Loss: 0.4529382288455963\n",
      "Epoch 181, Loss: 1.4796024858951569, Final Batch Loss: 0.4916628301143646\n",
      "Epoch 182, Loss: 1.347151279449463, Final Batch Loss: 0.31623753905296326\n",
      "Epoch 183, Loss: 1.677687168121338, Final Batch Loss: 0.6229282021522522\n",
      "Epoch 184, Loss: 1.5762661695480347, Final Batch Loss: 0.4713327884674072\n",
      "Epoch 185, Loss: 1.2813405990600586, Final Batch Loss: 0.2691164016723633\n",
      "Epoch 186, Loss: 1.6068552732467651, Final Batch Loss: 0.6544424295425415\n",
      "Epoch 187, Loss: 1.3857075572013855, Final Batch Loss: 0.37933826446533203\n",
      "Epoch 188, Loss: 1.555574655532837, Final Batch Loss: 0.6421142220497131\n",
      "Epoch 189, Loss: 1.4255940318107605, Final Batch Loss: 0.36034297943115234\n",
      "Epoch 190, Loss: 1.3873131275177002, Final Batch Loss: 0.3850376307964325\n",
      "Epoch 191, Loss: 1.2525830566883087, Final Batch Loss: 0.30788588523864746\n",
      "Epoch 192, Loss: 1.4378714263439178, Final Batch Loss: 0.4125162661075592\n",
      "Epoch 193, Loss: 1.3654318749904633, Final Batch Loss: 0.4433215856552124\n",
      "Epoch 194, Loss: 1.5893494784832, Final Batch Loss: 0.6184474229812622\n",
      "Epoch 195, Loss: 1.5504423677921295, Final Batch Loss: 0.6238442063331604\n",
      "Epoch 196, Loss: 1.4517557621002197, Final Batch Loss: 0.5102196335792542\n",
      "Epoch 197, Loss: 1.7736539542675018, Final Batch Loss: 0.7830201387405396\n",
      "Epoch 198, Loss: 1.7205653488636017, Final Batch Loss: 0.7739524245262146\n",
      "Epoch 199, Loss: 1.672431230545044, Final Batch Loss: 0.66010582447052\n",
      "Epoch 200, Loss: 1.436926692724228, Final Batch Loss: 0.3970254957675934\n",
      "Epoch 201, Loss: 1.3271450102329254, Final Batch Loss: 0.30835554003715515\n",
      "Epoch 202, Loss: 1.2448727935552597, Final Batch Loss: 0.24724678695201874\n",
      "Epoch 203, Loss: 1.3258834183216095, Final Batch Loss: 0.36988088488578796\n",
      "Epoch 204, Loss: 1.4004695415496826, Final Batch Loss: 0.44507157802581787\n",
      "Epoch 205, Loss: 1.3606604039669037, Final Batch Loss: 0.43973466753959656\n",
      "Epoch 206, Loss: 1.6643251776695251, Final Batch Loss: 0.7380766868591309\n",
      "Epoch 207, Loss: 1.8413611948490143, Final Batch Loss: 0.8974261283874512\n",
      "Epoch 208, Loss: 1.5461733639240265, Final Batch Loss: 0.5787149667739868\n",
      "Epoch 209, Loss: 1.433422327041626, Final Batch Loss: 0.5069597363471985\n",
      "Epoch 210, Loss: 1.3940792381763458, Final Batch Loss: 0.5049067139625549\n",
      "Epoch 211, Loss: 1.4572012424468994, Final Batch Loss: 0.5584507584571838\n",
      "Epoch 212, Loss: 1.3493988513946533, Final Batch Loss: 0.4597887694835663\n",
      "Epoch 213, Loss: 1.8953429758548737, Final Batch Loss: 0.9926102161407471\n",
      "Epoch 214, Loss: 1.5889396369457245, Final Batch Loss: 0.6401637196540833\n",
      "Epoch 215, Loss: 1.6362088024616241, Final Batch Loss: 0.6774570941925049\n",
      "Epoch 216, Loss: 1.5093263983726501, Final Batch Loss: 0.5353866219520569\n",
      "Epoch 217, Loss: 1.413330763578415, Final Batch Loss: 0.5165293216705322\n",
      "Epoch 218, Loss: 1.0822486579418182, Final Batch Loss: 0.24782896041870117\n",
      "Epoch 219, Loss: 1.1987141370773315, Final Batch Loss: 0.30457013845443726\n",
      "Epoch 220, Loss: 1.555716633796692, Final Batch Loss: 0.6225665807723999\n",
      "Epoch 221, Loss: 1.3530840277671814, Final Batch Loss: 0.46680524945259094\n",
      "Epoch 222, Loss: 1.3631269931793213, Final Batch Loss: 0.4235271215438843\n",
      "Epoch 223, Loss: 1.132620319724083, Final Batch Loss: 0.2118859738111496\n",
      "Epoch 224, Loss: 1.636849194765091, Final Batch Loss: 0.7947936058044434\n",
      "Epoch 225, Loss: 1.3890012502670288, Final Batch Loss: 0.5424545407295227\n",
      "Epoch 226, Loss: 1.3115105330944061, Final Batch Loss: 0.3802519738674164\n",
      "Epoch 227, Loss: 1.3425110578536987, Final Batch Loss: 0.4378916621208191\n",
      "Epoch 228, Loss: 1.5605929791927338, Final Batch Loss: 0.5422590374946594\n",
      "Epoch 229, Loss: 1.5300946831703186, Final Batch Loss: 0.6470014452934265\n",
      "Epoch 230, Loss: 1.3408482670783997, Final Batch Loss: 0.4200989902019501\n",
      "Epoch 231, Loss: 1.290709674358368, Final Batch Loss: 0.41834384202957153\n",
      "Epoch 232, Loss: 1.5894907712936401, Final Batch Loss: 0.724563717842102\n",
      "Epoch 233, Loss: 1.053503468632698, Final Batch Loss: 0.20082594454288483\n",
      "Epoch 234, Loss: 1.361555427312851, Final Batch Loss: 0.5178481936454773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235, Loss: 1.1489294618368149, Final Batch Loss: 0.20311687886714935\n",
      "Epoch 236, Loss: 1.1390935778617859, Final Batch Loss: 0.28147727251052856\n",
      "Epoch 237, Loss: 1.5429586470127106, Final Batch Loss: 0.6349425315856934\n",
      "Epoch 238, Loss: 1.26106595993042, Final Batch Loss: 0.4212353825569153\n",
      "Epoch 239, Loss: 1.0384783297777176, Final Batch Loss: 0.16659601032733917\n",
      "Epoch 240, Loss: 1.070555567741394, Final Batch Loss: 0.20458483695983887\n",
      "Epoch 241, Loss: 1.2731884717941284, Final Batch Loss: 0.42690518498420715\n",
      "Epoch 242, Loss: 1.3072589635849, Final Batch Loss: 0.5241759419441223\n",
      "Epoch 243, Loss: 1.282065510749817, Final Batch Loss: 0.43902191519737244\n",
      "Epoch 244, Loss: 1.2781204283237457, Final Batch Loss: 0.5507075786590576\n",
      "Epoch 245, Loss: 1.1333045959472656, Final Batch Loss: 0.252521276473999\n",
      "Epoch 246, Loss: 1.6321991682052612, Final Batch Loss: 0.7898273468017578\n",
      "Epoch 247, Loss: 1.1582668125629425, Final Batch Loss: 0.42522963881492615\n",
      "Epoch 248, Loss: 1.3491166532039642, Final Batch Loss: 0.5291945338249207\n",
      "Epoch 249, Loss: 1.3478997647762299, Final Batch Loss: 0.4704885482788086\n",
      "Epoch 250, Loss: 1.1499263644218445, Final Batch Loss: 0.26079487800598145\n",
      "Epoch 251, Loss: 1.1756379008293152, Final Batch Loss: 0.25339120626449585\n",
      "Epoch 252, Loss: 1.3657475411891937, Final Batch Loss: 0.5881527066230774\n",
      "Epoch 253, Loss: 1.2635875344276428, Final Batch Loss: 0.4008898437023163\n",
      "Epoch 254, Loss: 0.9929306656122208, Final Batch Loss: 0.14267010986804962\n",
      "Epoch 255, Loss: 1.2859811186790466, Final Batch Loss: 0.4953165054321289\n",
      "Epoch 256, Loss: 1.0168403089046478, Final Batch Loss: 0.19066336750984192\n",
      "Epoch 257, Loss: 1.181527316570282, Final Batch Loss: 0.4101732075214386\n",
      "Epoch 258, Loss: 1.2169435918331146, Final Batch Loss: 0.36521172523498535\n",
      "Epoch 259, Loss: 1.5202401876449585, Final Batch Loss: 0.6645051836967468\n",
      "Epoch 260, Loss: 1.378840833902359, Final Batch Loss: 0.55840665102005\n",
      "Epoch 261, Loss: 1.054752692580223, Final Batch Loss: 0.22652281820774078\n",
      "Epoch 262, Loss: 1.3909138143062592, Final Batch Loss: 0.5419065952301025\n",
      "Epoch 263, Loss: 1.3170179426670074, Final Batch Loss: 0.609144926071167\n",
      "Epoch 264, Loss: 1.3683021068572998, Final Batch Loss: 0.5279946327209473\n",
      "Epoch 265, Loss: 1.0844578444957733, Final Batch Loss: 0.27644047141075134\n",
      "Epoch 266, Loss: 1.433386206626892, Final Batch Loss: 0.5129373669624329\n",
      "Epoch 267, Loss: 1.2488577961921692, Final Batch Loss: 0.4453689157962799\n",
      "Epoch 268, Loss: 1.5428619980812073, Final Batch Loss: 0.6697784066200256\n",
      "Epoch 269, Loss: 1.2798681557178497, Final Batch Loss: 0.5357344150543213\n",
      "Epoch 270, Loss: 1.1058688759803772, Final Batch Loss: 0.27675047516822815\n",
      "Epoch 271, Loss: 1.5569278597831726, Final Batch Loss: 0.6835263967514038\n",
      "Epoch 272, Loss: 1.015756070613861, Final Batch Loss: 0.21473562717437744\n",
      "Epoch 273, Loss: 1.1914954781532288, Final Batch Loss: 0.4729985296726227\n",
      "Epoch 274, Loss: 1.370461255311966, Final Batch Loss: 0.5700488090515137\n",
      "Epoch 275, Loss: 1.0746593177318573, Final Batch Loss: 0.28160423040390015\n",
      "Epoch 276, Loss: 1.2206129431724548, Final Batch Loss: 0.4752962589263916\n",
      "Epoch 277, Loss: 0.99844591319561, Final Batch Loss: 0.21313534677028656\n",
      "Epoch 278, Loss: 1.17670539021492, Final Batch Loss: 0.387222021818161\n",
      "Epoch 279, Loss: 1.1070020198822021, Final Batch Loss: 0.270254522562027\n",
      "Epoch 280, Loss: 1.3416175544261932, Final Batch Loss: 0.5879406929016113\n",
      "Epoch 281, Loss: 1.01164311170578, Final Batch Loss: 0.21223270893096924\n",
      "Epoch 282, Loss: 1.0954241454601288, Final Batch Loss: 0.3232228755950928\n",
      "Epoch 283, Loss: 0.9837896525859833, Final Batch Loss: 0.20966875553131104\n",
      "Epoch 284, Loss: 0.9768062829971313, Final Batch Loss: 0.19015300273895264\n",
      "Epoch 285, Loss: 1.3052136898040771, Final Batch Loss: 0.5465388894081116\n",
      "Epoch 286, Loss: 1.2268803119659424, Final Batch Loss: 0.5246986150741577\n",
      "Epoch 287, Loss: 1.1964806616306305, Final Batch Loss: 0.42396053671836853\n",
      "Epoch 288, Loss: 1.145841896533966, Final Batch Loss: 0.41026216745376587\n",
      "Epoch 289, Loss: 1.1542899310588837, Final Batch Loss: 0.4096745550632477\n",
      "Epoch 290, Loss: 1.0206851661205292, Final Batch Loss: 0.2226637303829193\n",
      "Epoch 291, Loss: 1.5557277202606201, Final Batch Loss: 0.7494590878486633\n",
      "Epoch 292, Loss: 1.398534208536148, Final Batch Loss: 0.6073469519615173\n",
      "Epoch 293, Loss: 1.0635083317756653, Final Batch Loss: 0.25009623169898987\n",
      "Epoch 294, Loss: 1.1462856829166412, Final Batch Loss: 0.3407788574695587\n",
      "Epoch 295, Loss: 1.092652678489685, Final Batch Loss: 0.377673476934433\n",
      "Epoch 296, Loss: 1.0706449747085571, Final Batch Loss: 0.2874675393104553\n",
      "Epoch 297, Loss: 0.8822367787361145, Final Batch Loss: 0.14435869455337524\n",
      "Epoch 298, Loss: 1.124277651309967, Final Batch Loss: 0.30539873242378235\n",
      "Epoch 299, Loss: 1.0236373543739319, Final Batch Loss: 0.28824612498283386\n",
      "Epoch 300, Loss: 1.089781641960144, Final Batch Loss: 0.3478119671344757\n",
      "Epoch 301, Loss: 1.145750105381012, Final Batch Loss: 0.36569926142692566\n",
      "Epoch 302, Loss: 1.2627257406711578, Final Batch Loss: 0.4976043701171875\n",
      "Epoch 303, Loss: 1.1240801215171814, Final Batch Loss: 0.34213849902153015\n",
      "Epoch 304, Loss: 1.0509966909885406, Final Batch Loss: 0.3344852328300476\n",
      "Epoch 305, Loss: 1.1440796554088593, Final Batch Loss: 0.4287415146827698\n",
      "Epoch 306, Loss: 1.0524313151836395, Final Batch Loss: 0.36131319403648376\n",
      "Epoch 307, Loss: 1.0834220945835114, Final Batch Loss: 0.3611305356025696\n",
      "Epoch 308, Loss: 1.0239340364933014, Final Batch Loss: 0.2884465157985687\n",
      "Epoch 309, Loss: 0.9708918631076813, Final Batch Loss: 0.2323186993598938\n",
      "Epoch 310, Loss: 1.13547283411026, Final Batch Loss: 0.4001332223415375\n",
      "Epoch 311, Loss: 1.0117852091789246, Final Batch Loss: 0.2888273298740387\n",
      "Epoch 312, Loss: 1.0573616921901703, Final Batch Loss: 0.3505638539791107\n",
      "Epoch 313, Loss: 1.078214168548584, Final Batch Loss: 0.42551788687705994\n",
      "Epoch 314, Loss: 1.1214642524719238, Final Batch Loss: 0.37941595911979675\n",
      "Epoch 315, Loss: 1.152429848909378, Final Batch Loss: 0.4153083562850952\n",
      "Epoch 316, Loss: 1.0612365007400513, Final Batch Loss: 0.25843575596809387\n",
      "Epoch 317, Loss: 1.3588245213031769, Final Batch Loss: 0.6481233835220337\n",
      "Epoch 318, Loss: 1.3987326622009277, Final Batch Loss: 0.7022773623466492\n",
      "Epoch 319, Loss: 1.0042464137077332, Final Batch Loss: 0.26570311188697815\n",
      "Epoch 320, Loss: 1.0387072265148163, Final Batch Loss: 0.30126065015792847\n",
      "Epoch 321, Loss: 1.2410961985588074, Final Batch Loss: 0.5427348613739014\n",
      "Epoch 322, Loss: 1.1215276718139648, Final Batch Loss: 0.35894179344177246\n",
      "Epoch 323, Loss: 1.0048136115074158, Final Batch Loss: 0.2470059096813202\n",
      "Epoch 324, Loss: 0.9479055851697922, Final Batch Loss: 0.21751032769680023\n",
      "Epoch 325, Loss: 0.8891796097159386, Final Batch Loss: 0.12180604785680771\n",
      "Epoch 326, Loss: 0.904114842414856, Final Batch Loss: 0.146377831697464\n",
      "Epoch 327, Loss: 0.9331789761781693, Final Batch Loss: 0.23694758117198944\n",
      "Epoch 328, Loss: 0.8643945157527924, Final Batch Loss: 0.14405933022499084\n",
      "Epoch 329, Loss: 1.112726628780365, Final Batch Loss: 0.4499500095844269\n",
      "Epoch 330, Loss: 1.024981141090393, Final Batch Loss: 0.3106164038181305\n",
      "Epoch 331, Loss: 0.8095588088035583, Final Batch Loss: 0.12030154466629028\n",
      "Epoch 332, Loss: 1.207397699356079, Final Batch Loss: 0.511117160320282\n",
      "Epoch 333, Loss: 0.8099226951599121, Final Batch Loss: 0.15867474675178528\n",
      "Epoch 334, Loss: 1.017524093389511, Final Batch Loss: 0.2627550959587097\n",
      "Epoch 335, Loss: 1.0745247900485992, Final Batch Loss: 0.38023099303245544\n",
      "Epoch 336, Loss: 1.1141033470630646, Final Batch Loss: 0.4787645936012268\n",
      "Epoch 337, Loss: 1.0524499714374542, Final Batch Loss: 0.34823504090309143\n",
      "Epoch 338, Loss: 0.9567129164934158, Final Batch Loss: 0.21756653487682343\n",
      "Epoch 339, Loss: 0.948181539773941, Final Batch Loss: 0.25364232063293457\n",
      "Epoch 340, Loss: 1.0161563158035278, Final Batch Loss: 0.358288049697876\n",
      "Epoch 341, Loss: 1.0050596296787262, Final Batch Loss: 0.3506699502468109\n",
      "Epoch 342, Loss: 1.4218303263187408, Final Batch Loss: 0.7248257994651794\n",
      "Epoch 343, Loss: 1.0030043125152588, Final Batch Loss: 0.276068776845932\n",
      "Epoch 344, Loss: 1.1013470888137817, Final Batch Loss: 0.41257229447364807\n",
      "Epoch 345, Loss: 1.1055870652198792, Final Batch Loss: 0.4022182524204254\n",
      "Epoch 346, Loss: 1.0094569623470306, Final Batch Loss: 0.413307785987854\n",
      "Epoch 347, Loss: 1.0617054104804993, Final Batch Loss: 0.4080899953842163\n",
      "Epoch 348, Loss: 1.0450272262096405, Final Batch Loss: 0.35181641578674316\n",
      "Epoch 349, Loss: 0.8722096234560013, Final Batch Loss: 0.19318397343158722\n",
      "Epoch 350, Loss: 0.9782166481018066, Final Batch Loss: 0.24532586336135864\n",
      "Epoch 351, Loss: 1.1103090643882751, Final Batch Loss: 0.44483494758605957\n",
      "Epoch 352, Loss: 0.8242654204368591, Final Batch Loss: 0.15311011672019958\n",
      "Epoch 353, Loss: 0.8512345850467682, Final Batch Loss: 0.19141250848770142\n",
      "Epoch 354, Loss: 1.2226157784461975, Final Batch Loss: 0.5862311124801636\n",
      "Epoch 355, Loss: 1.041798621416092, Final Batch Loss: 0.3976106345653534\n",
      "Epoch 356, Loss: 1.0008363127708435, Final Batch Loss: 0.37668779492378235\n",
      "Epoch 357, Loss: 0.8255449384450912, Final Batch Loss: 0.14097599685192108\n",
      "Epoch 358, Loss: 1.0781725347042084, Final Batch Loss: 0.4161694645881653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359, Loss: 1.0307234823703766, Final Batch Loss: 0.28586071729660034\n",
      "Epoch 360, Loss: 0.9307059645652771, Final Batch Loss: 0.24113401770591736\n",
      "Epoch 361, Loss: 1.0044749975204468, Final Batch Loss: 0.36378034949302673\n",
      "Epoch 362, Loss: 0.9070173799991608, Final Batch Loss: 0.29491376876831055\n",
      "Epoch 363, Loss: 0.9696199893951416, Final Batch Loss: 0.3686927556991577\n",
      "Epoch 364, Loss: 0.9446964263916016, Final Batch Loss: 0.30767402052879333\n",
      "Epoch 365, Loss: 1.0700596868991852, Final Batch Loss: 0.42744407057762146\n",
      "Epoch 366, Loss: 1.0144591927528381, Final Batch Loss: 0.3881155252456665\n",
      "Epoch 367, Loss: 0.940050333738327, Final Batch Loss: 0.28455212712287903\n",
      "Epoch 368, Loss: 0.833105206489563, Final Batch Loss: 0.14013025164604187\n",
      "Epoch 369, Loss: 1.1234477162361145, Final Batch Loss: 0.5276561975479126\n",
      "Epoch 370, Loss: 0.8378441333770752, Final Batch Loss: 0.1881960928440094\n",
      "Epoch 371, Loss: 1.1107375621795654, Final Batch Loss: 0.4156854450702667\n",
      "Epoch 372, Loss: 0.9579071700572968, Final Batch Loss: 0.31111156940460205\n",
      "Epoch 373, Loss: 0.8141662627458572, Final Batch Loss: 0.20529527962207794\n",
      "Epoch 374, Loss: 0.9371418356895447, Final Batch Loss: 0.31948840618133545\n",
      "Epoch 375, Loss: 0.9768321812152863, Final Batch Loss: 0.3728552758693695\n",
      "Epoch 376, Loss: 0.6825697794556618, Final Batch Loss: 0.11406821757555008\n",
      "Epoch 377, Loss: 0.9271939694881439, Final Batch Loss: 0.31577545404434204\n",
      "Epoch 378, Loss: 0.9871675968170166, Final Batch Loss: 0.3544738292694092\n",
      "Epoch 379, Loss: 1.1386821568012238, Final Batch Loss: 0.5282512903213501\n",
      "Epoch 380, Loss: 0.999274343252182, Final Batch Loss: 0.39950060844421387\n",
      "Epoch 381, Loss: 1.2756918668746948, Final Batch Loss: 0.6324543952941895\n",
      "Epoch 382, Loss: 0.7788165658712387, Final Batch Loss: 0.1081862598657608\n",
      "Epoch 383, Loss: 0.9474290311336517, Final Batch Loss: 0.26857686042785645\n",
      "Epoch 384, Loss: 0.8629089444875717, Final Batch Loss: 0.2032918483018875\n",
      "Epoch 385, Loss: 1.0763132572174072, Final Batch Loss: 0.42634764313697815\n",
      "Epoch 386, Loss: 0.8557829111814499, Final Batch Loss: 0.2466243952512741\n",
      "Epoch 387, Loss: 0.9408945441246033, Final Batch Loss: 0.30202412605285645\n",
      "Epoch 388, Loss: 0.9787898361682892, Final Batch Loss: 0.35821348428726196\n",
      "Epoch 389, Loss: 0.7627135068178177, Final Batch Loss: 0.15721623599529266\n",
      "Epoch 390, Loss: 0.926200807094574, Final Batch Loss: 0.3127894401550293\n",
      "Epoch 391, Loss: 0.8978562951087952, Final Batch Loss: 0.24091416597366333\n",
      "Epoch 392, Loss: 0.8343003690242767, Final Batch Loss: 0.201059490442276\n",
      "Epoch 393, Loss: 0.9310719668865204, Final Batch Loss: 0.3312701880931854\n",
      "Epoch 394, Loss: 0.7837937772274017, Final Batch Loss: 0.17726671695709229\n",
      "Epoch 395, Loss: 0.9978879988193512, Final Batch Loss: 0.44339144229888916\n",
      "Epoch 396, Loss: 0.8687482923269272, Final Batch Loss: 0.24809826910495758\n",
      "Epoch 397, Loss: 0.7802962213754654, Final Batch Loss: 0.1922374814748764\n",
      "Epoch 398, Loss: 1.0480632483959198, Final Batch Loss: 0.5152173042297363\n",
      "Epoch 399, Loss: 0.9257323741912842, Final Batch Loss: 0.3483026921749115\n",
      "Epoch 400, Loss: 0.9525425732135773, Final Batch Loss: 0.37020570039749146\n",
      "Epoch 401, Loss: 0.9079137742519379, Final Batch Loss: 0.2543448209762573\n",
      "Epoch 402, Loss: 1.0410506129264832, Final Batch Loss: 0.3663206100463867\n",
      "Epoch 403, Loss: 0.8665449768304825, Final Batch Loss: 0.2352667599916458\n",
      "Epoch 404, Loss: 1.2499180734157562, Final Batch Loss: 0.5686192512512207\n",
      "Epoch 405, Loss: 1.019720509648323, Final Batch Loss: 0.22560523450374603\n",
      "Epoch 406, Loss: 1.1669546067714691, Final Batch Loss: 0.4558567702770233\n",
      "Epoch 407, Loss: 0.9773490130901337, Final Batch Loss: 0.39363980293273926\n",
      "Epoch 408, Loss: 0.9721057415008545, Final Batch Loss: 0.2697913646697998\n",
      "Epoch 409, Loss: 0.8567902892827988, Final Batch Loss: 0.19588978588581085\n",
      "Epoch 410, Loss: 0.9005507528781891, Final Batch Loss: 0.2872558534145355\n",
      "Epoch 411, Loss: 1.0008853375911713, Final Batch Loss: 0.328396737575531\n",
      "Epoch 412, Loss: 0.7077796310186386, Final Batch Loss: 0.1526128202676773\n",
      "Epoch 413, Loss: 0.8447918146848679, Final Batch Loss: 0.22410018742084503\n",
      "Epoch 414, Loss: 0.8005645424127579, Final Batch Loss: 0.18998406827449799\n",
      "Epoch 415, Loss: 0.810046374797821, Final Batch Loss: 0.19070470333099365\n",
      "Epoch 416, Loss: 0.7770469039678574, Final Batch Loss: 0.19381506741046906\n",
      "Epoch 417, Loss: 0.9849339127540588, Final Batch Loss: 0.41050851345062256\n",
      "Epoch 418, Loss: 0.9396173357963562, Final Batch Loss: 0.3292417824268341\n",
      "Epoch 419, Loss: 0.9649712443351746, Final Batch Loss: 0.3064892292022705\n",
      "Epoch 420, Loss: 0.9420413374900818, Final Batch Loss: 0.30892953276634216\n",
      "Epoch 421, Loss: 0.8060537129640579, Final Batch Loss: 0.21687765419483185\n",
      "Epoch 422, Loss: 0.8371443450450897, Final Batch Loss: 0.1893015205860138\n",
      "Epoch 423, Loss: 1.2198984324932098, Final Batch Loss: 0.6289436221122742\n",
      "Epoch 424, Loss: 0.8795614540576935, Final Batch Loss: 0.3217543661594391\n",
      "Epoch 425, Loss: 1.0635092854499817, Final Batch Loss: 0.48509714007377625\n",
      "Epoch 426, Loss: 0.8699850738048553, Final Batch Loss: 0.26696714758872986\n",
      "Epoch 427, Loss: 1.012545794248581, Final Batch Loss: 0.3861444592475891\n",
      "Epoch 428, Loss: 1.1287517547607422, Final Batch Loss: 0.541659951210022\n",
      "Epoch 429, Loss: 0.7920626103878021, Final Batch Loss: 0.21329669654369354\n",
      "Epoch 430, Loss: 0.9948401749134064, Final Batch Loss: 0.3932849168777466\n",
      "Epoch 431, Loss: 0.8714818358421326, Final Batch Loss: 0.30202290415763855\n",
      "Epoch 432, Loss: 0.898624837398529, Final Batch Loss: 0.25092577934265137\n",
      "Epoch 433, Loss: 0.7793069928884506, Final Batch Loss: 0.1580614298582077\n",
      "Epoch 434, Loss: 0.8462709784507751, Final Batch Loss: 0.2901749312877655\n",
      "Epoch 435, Loss: 0.8756662011146545, Final Batch Loss: 0.21207678318023682\n",
      "Epoch 436, Loss: 0.7564345747232437, Final Batch Loss: 0.1707957535982132\n",
      "Epoch 437, Loss: 0.9505044519901276, Final Batch Loss: 0.4013550579547882\n",
      "Epoch 438, Loss: 0.9162432849407196, Final Batch Loss: 0.2848134934902191\n",
      "Epoch 439, Loss: 0.9112902581691742, Final Batch Loss: 0.2485741376876831\n",
      "Epoch 440, Loss: 0.9517402648925781, Final Batch Loss: 0.31976959109306335\n",
      "Epoch 441, Loss: 0.8793723881244659, Final Batch Loss: 0.33002007007598877\n",
      "Epoch 442, Loss: 0.8192120343446732, Final Batch Loss: 0.1987585574388504\n",
      "Epoch 443, Loss: 0.8283295035362244, Final Batch Loss: 0.2873344421386719\n",
      "Epoch 444, Loss: 0.880361020565033, Final Batch Loss: 0.2560599446296692\n",
      "Epoch 445, Loss: 0.7328580468893051, Final Batch Loss: 0.18187262117862701\n",
      "Epoch 446, Loss: 0.9957238137722015, Final Batch Loss: 0.3331392705440521\n",
      "Epoch 447, Loss: 0.8024974465370178, Final Batch Loss: 0.2708357870578766\n",
      "Epoch 448, Loss: 0.7576747089624405, Final Batch Loss: 0.21381044387817383\n",
      "Epoch 449, Loss: 0.9800578057765961, Final Batch Loss: 0.43189945816993713\n",
      "Epoch 450, Loss: 1.0795704424381256, Final Batch Loss: 0.4387187957763672\n",
      "Epoch 451, Loss: 0.8639136999845505, Final Batch Loss: 0.30841967463493347\n",
      "Epoch 452, Loss: 0.777710884809494, Final Batch Loss: 0.159297376871109\n",
      "Epoch 453, Loss: 0.8801763951778412, Final Batch Loss: 0.30465006828308105\n",
      "Epoch 454, Loss: 1.000407099723816, Final Batch Loss: 0.4345957040786743\n",
      "Epoch 455, Loss: 0.9749272167682648, Final Batch Loss: 0.38897010684013367\n",
      "Epoch 456, Loss: 0.7394952923059464, Final Batch Loss: 0.16869445145130157\n",
      "Epoch 457, Loss: 0.8703389167785645, Final Batch Loss: 0.3276865482330322\n",
      "Epoch 458, Loss: 0.8277401924133301, Final Batch Loss: 0.24290752410888672\n",
      "Epoch 459, Loss: 1.114608958363533, Final Batch Loss: 0.540951669216156\n",
      "Epoch 460, Loss: 1.0324336886405945, Final Batch Loss: 0.44901591539382935\n",
      "Epoch 461, Loss: 0.6830114126205444, Final Batch Loss: 0.17618656158447266\n",
      "Epoch 462, Loss: 1.015748769044876, Final Batch Loss: 0.44942614436149597\n",
      "Epoch 463, Loss: 0.9108873605728149, Final Batch Loss: 0.3247590959072113\n",
      "Epoch 464, Loss: 1.049783170223236, Final Batch Loss: 0.47777271270751953\n",
      "Epoch 465, Loss: 0.7125726193189621, Final Batch Loss: 0.18151268362998962\n",
      "Epoch 466, Loss: 0.9399247914552689, Final Batch Loss: 0.37685132026672363\n",
      "Epoch 467, Loss: 0.7392403334379196, Final Batch Loss: 0.07804687321186066\n",
      "Epoch 468, Loss: 0.8220328837633133, Final Batch Loss: 0.23872701823711395\n",
      "Epoch 469, Loss: 0.88679438829422, Final Batch Loss: 0.2632894814014435\n",
      "Epoch 470, Loss: 0.7328096032142639, Final Batch Loss: 0.17746245861053467\n",
      "Epoch 471, Loss: 0.8975975215435028, Final Batch Loss: 0.3411569893360138\n",
      "Epoch 472, Loss: 0.7268033176660538, Final Batch Loss: 0.19889049232006073\n",
      "Epoch 473, Loss: 1.0427790582180023, Final Batch Loss: 0.39532041549682617\n",
      "Epoch 474, Loss: 0.7553896009922028, Final Batch Loss: 0.14388182759284973\n",
      "Epoch 475, Loss: 0.8845170140266418, Final Batch Loss: 0.2891043722629547\n",
      "Epoch 476, Loss: 0.8203754276037216, Final Batch Loss: 0.19823141396045685\n",
      "Epoch 477, Loss: 0.8858108967542648, Final Batch Loss: 0.24807195365428925\n",
      "Epoch 478, Loss: 0.7398053258657455, Final Batch Loss: 0.16402961313724518\n",
      "Epoch 479, Loss: 1.0056809037923813, Final Batch Loss: 0.44690969586372375\n",
      "Epoch 480, Loss: 0.6401435136795044, Final Batch Loss: 0.09585884213447571\n",
      "Epoch 481, Loss: 0.8670806586742401, Final Batch Loss: 0.27914851903915405\n",
      "Epoch 482, Loss: 0.9475209712982178, Final Batch Loss: 0.41122332215309143\n",
      "Epoch 483, Loss: 0.728242039680481, Final Batch Loss: 0.1642155945301056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484, Loss: 0.9442857205867767, Final Batch Loss: 0.28569501638412476\n",
      "Epoch 485, Loss: 0.8273690193891525, Final Batch Loss: 0.20687805116176605\n",
      "Epoch 486, Loss: 1.1686211377382278, Final Batch Loss: 0.5942797660827637\n",
      "Epoch 487, Loss: 1.1133001446723938, Final Batch Loss: 0.5731255412101746\n",
      "Epoch 488, Loss: 0.9863724708557129, Final Batch Loss: 0.4183967411518097\n",
      "Epoch 489, Loss: 0.6530584096908569, Final Batch Loss: 0.08807897567749023\n",
      "Epoch 490, Loss: 0.8643142580986023, Final Batch Loss: 0.32998886704444885\n",
      "Epoch 491, Loss: 0.8614096939563751, Final Batch Loss: 0.29696711897850037\n",
      "Epoch 492, Loss: 0.8462692648172379, Final Batch Loss: 0.29615285992622375\n",
      "Epoch 493, Loss: 0.7559652477502823, Final Batch Loss: 0.16521187126636505\n",
      "Epoch 494, Loss: 0.8531830459833145, Final Batch Loss: 0.2753623127937317\n",
      "Epoch 495, Loss: 0.9107130467891693, Final Batch Loss: 0.31840914487838745\n",
      "Epoch 496, Loss: 0.9552312791347504, Final Batch Loss: 0.4325924515724182\n",
      "Epoch 497, Loss: 0.9573319256305695, Final Batch Loss: 0.41382312774658203\n",
      "Epoch 498, Loss: 0.651555746793747, Final Batch Loss: 0.14204514026641846\n",
      "Epoch 499, Loss: 1.0169206857681274, Final Batch Loss: 0.4362337589263916\n",
      "Epoch 500, Loss: 0.8008304238319397, Final Batch Loss: 0.2839086651802063\n",
      "Epoch 501, Loss: 0.711581826210022, Final Batch Loss: 0.15855705738067627\n",
      "Epoch 502, Loss: 0.7628389298915863, Final Batch Loss: 0.24095477163791656\n",
      "Epoch 503, Loss: 0.7114569395780563, Final Batch Loss: 0.11559464037418365\n",
      "Epoch 504, Loss: 0.8112786412239075, Final Batch Loss: 0.23546655476093292\n",
      "Epoch 505, Loss: 0.7501357346773148, Final Batch Loss: 0.26103657484054565\n",
      "Epoch 506, Loss: 0.7016545683145523, Final Batch Loss: 0.1222439557313919\n",
      "Epoch 507, Loss: 0.7039764970541, Final Batch Loss: 0.18504184484481812\n",
      "Epoch 508, Loss: 0.6118761524558067, Final Batch Loss: 0.12424268573522568\n",
      "Epoch 509, Loss: 0.8074210733175278, Final Batch Loss: 0.27537405490875244\n",
      "Epoch 510, Loss: 0.6923884451389313, Final Batch Loss: 0.18367648124694824\n",
      "Epoch 511, Loss: 0.8586519956588745, Final Batch Loss: 0.35719189047813416\n",
      "Epoch 512, Loss: 0.8713957071304321, Final Batch Loss: 0.3905041217803955\n",
      "Epoch 513, Loss: 0.896951287984848, Final Batch Loss: 0.36957597732543945\n",
      "Epoch 514, Loss: 0.6245395988225937, Final Batch Loss: 0.14064694941043854\n",
      "Epoch 515, Loss: 0.9034209251403809, Final Batch Loss: 0.32426705956459045\n",
      "Epoch 516, Loss: 0.7519518882036209, Final Batch Loss: 0.2345132827758789\n",
      "Epoch 517, Loss: 0.9805545210838318, Final Batch Loss: 0.4608798325061798\n",
      "Epoch 518, Loss: 0.5989697054028511, Final Batch Loss: 0.06846251338720322\n",
      "Epoch 519, Loss: 0.7863514274358749, Final Batch Loss: 0.2512946128845215\n",
      "Epoch 520, Loss: 1.1755661368370056, Final Batch Loss: 0.6025766134262085\n",
      "Epoch 521, Loss: 0.985284686088562, Final Batch Loss: 0.3733128309249878\n",
      "Epoch 522, Loss: 0.7219647914171219, Final Batch Loss: 0.2063235640525818\n",
      "Epoch 523, Loss: 0.7879609912633896, Final Batch Loss: 0.25354620814323425\n",
      "Epoch 524, Loss: 0.7340017110109329, Final Batch Loss: 0.23827028274536133\n",
      "Epoch 525, Loss: 0.7212795615196228, Final Batch Loss: 0.2079397737979889\n",
      "Epoch 526, Loss: 0.7757003009319305, Final Batch Loss: 0.2763294279575348\n",
      "Epoch 527, Loss: 0.8098232448101044, Final Batch Loss: 0.3366945683956146\n",
      "Epoch 528, Loss: 0.9778111428022385, Final Batch Loss: 0.5096157789230347\n",
      "Epoch 529, Loss: 0.9520400166511536, Final Batch Loss: 0.44455909729003906\n",
      "Epoch 530, Loss: 0.8293355852365494, Final Batch Loss: 0.2949739098548889\n",
      "Epoch 531, Loss: 0.9935034215450287, Final Batch Loss: 0.39061447978019714\n",
      "Epoch 532, Loss: 0.7052630633115768, Final Batch Loss: 0.1604108363389969\n",
      "Epoch 533, Loss: 0.6161247491836548, Final Batch Loss: 0.08825850486755371\n",
      "Epoch 534, Loss: 0.8671647608280182, Final Batch Loss: 0.35432931780815125\n",
      "Epoch 535, Loss: 0.6976484507322311, Final Batch Loss: 0.17713375389575958\n",
      "Epoch 536, Loss: 1.0682892203330994, Final Batch Loss: 0.5356742739677429\n",
      "Epoch 537, Loss: 0.8028198480606079, Final Batch Loss: 0.29930365085601807\n",
      "Epoch 538, Loss: 0.7111448645591736, Final Batch Loss: 0.20434312522411346\n",
      "Epoch 539, Loss: 0.7430718243122101, Final Batch Loss: 0.23488301038742065\n",
      "Epoch 540, Loss: 0.6857107132673264, Final Batch Loss: 0.16757740080356598\n",
      "Epoch 541, Loss: 0.7720495313405991, Final Batch Loss: 0.2637593746185303\n",
      "Epoch 542, Loss: 0.7763182669878006, Final Batch Loss: 0.2049262374639511\n",
      "Epoch 543, Loss: 0.6079877391457558, Final Batch Loss: 0.07554013282060623\n",
      "Epoch 544, Loss: 0.8451451063156128, Final Batch Loss: 0.39471235871315\n",
      "Epoch 545, Loss: 0.8916049003601074, Final Batch Loss: 0.40228158235549927\n",
      "Epoch 546, Loss: 0.8317195624113083, Final Batch Loss: 0.32543882727622986\n",
      "Epoch 547, Loss: 0.73999984562397, Final Batch Loss: 0.22678856551647186\n",
      "Epoch 548, Loss: 1.0161409080028534, Final Batch Loss: 0.5238180756568909\n",
      "Epoch 549, Loss: 0.6556705683469772, Final Batch Loss: 0.16071225702762604\n",
      "Epoch 550, Loss: 0.6569535359740257, Final Batch Loss: 0.10143964737653732\n",
      "Epoch 551, Loss: 0.856311559677124, Final Batch Loss: 0.34374311566352844\n",
      "Epoch 552, Loss: 0.6522480472922325, Final Batch Loss: 0.11297499388456345\n",
      "Epoch 553, Loss: 0.7109041810035706, Final Batch Loss: 0.2181795835494995\n",
      "Epoch 554, Loss: 0.932126522064209, Final Batch Loss: 0.4182259738445282\n",
      "Epoch 555, Loss: 0.6891572177410126, Final Batch Loss: 0.1775810271501541\n",
      "Epoch 556, Loss: 0.7136864066123962, Final Batch Loss: 0.22262752056121826\n",
      "Epoch 557, Loss: 0.958289235830307, Final Batch Loss: 0.4320295751094818\n",
      "Epoch 558, Loss: 0.9517828673124313, Final Batch Loss: 0.4437863230705261\n",
      "Epoch 559, Loss: 0.7615665793418884, Final Batch Loss: 0.14434078335762024\n",
      "Epoch 560, Loss: 0.7907713949680328, Final Batch Loss: 0.17031735181808472\n",
      "Epoch 561, Loss: 0.7872795313596725, Final Batch Loss: 0.19407956302165985\n",
      "Epoch 562, Loss: 0.7417014241218567, Final Batch Loss: 0.2395118921995163\n",
      "Epoch 563, Loss: 0.7105061858892441, Final Batch Loss: 0.21855930984020233\n",
      "Epoch 564, Loss: 0.7987523674964905, Final Batch Loss: 0.2651219069957733\n",
      "Epoch 565, Loss: 0.8474561274051666, Final Batch Loss: 0.3585672676563263\n",
      "Epoch 566, Loss: 0.6189177185297012, Final Batch Loss: 0.09142601490020752\n",
      "Epoch 567, Loss: 0.814474955201149, Final Batch Loss: 0.1687895506620407\n",
      "Epoch 568, Loss: 1.0765653103590012, Final Batch Loss: 0.5532142519950867\n",
      "Epoch 569, Loss: 1.0733745247125626, Final Batch Loss: 0.5723278522491455\n",
      "Epoch 570, Loss: 0.7146428972482681, Final Batch Loss: 0.20577676594257355\n",
      "Epoch 571, Loss: 0.7716394513845444, Final Batch Loss: 0.24065275490283966\n",
      "Epoch 572, Loss: 0.8637710809707642, Final Batch Loss: 0.2976197302341461\n",
      "Epoch 573, Loss: 0.55443474650383, Final Batch Loss: 0.08337201178073883\n",
      "Epoch 574, Loss: 0.6945849359035492, Final Batch Loss: 0.19813911616802216\n",
      "Epoch 575, Loss: 0.7150420695543289, Final Batch Loss: 0.1650354415178299\n",
      "Epoch 576, Loss: 0.9148693680763245, Final Batch Loss: 0.39775967597961426\n",
      "Epoch 577, Loss: 0.7778904289007187, Final Batch Loss: 0.2624913454055786\n",
      "Epoch 578, Loss: 0.8322935700416565, Final Batch Loss: 0.18164411187171936\n",
      "Epoch 579, Loss: 0.969749704003334, Final Batch Loss: 0.43382635712623596\n",
      "Epoch 580, Loss: 0.8315434157848358, Final Batch Loss: 0.3463338613510132\n",
      "Epoch 581, Loss: 0.8086292445659637, Final Batch Loss: 0.2931392192840576\n",
      "Epoch 582, Loss: 0.724712111055851, Final Batch Loss: 0.12418758124113083\n",
      "Epoch 583, Loss: 0.7457207590341568, Final Batch Loss: 0.1601676493883133\n",
      "Epoch 584, Loss: 0.9848911762237549, Final Batch Loss: 0.432451993227005\n",
      "Epoch 585, Loss: 0.9362630248069763, Final Batch Loss: 0.2783023416996002\n",
      "Epoch 586, Loss: 0.707345113158226, Final Batch Loss: 0.14055080711841583\n",
      "Epoch 587, Loss: 0.9071588814258575, Final Batch Loss: 0.36445438861846924\n",
      "Epoch 588, Loss: 0.8494720309972763, Final Batch Loss: 0.2442537397146225\n",
      "Epoch 589, Loss: 0.9423563480377197, Final Batch Loss: 0.40135568380355835\n",
      "Epoch 590, Loss: 0.8015759885311127, Final Batch Loss: 0.2565477192401886\n",
      "Epoch 591, Loss: 0.8480773866176605, Final Batch Loss: 0.288043349981308\n",
      "Epoch 592, Loss: 0.8103744238615036, Final Batch Loss: 0.27027106285095215\n",
      "Epoch 593, Loss: 0.8642456978559494, Final Batch Loss: 0.3287336826324463\n",
      "Epoch 594, Loss: 0.5940336361527443, Final Batch Loss: 0.10073510557413101\n",
      "Epoch 595, Loss: 1.0577523708343506, Final Batch Loss: 0.5429465770721436\n",
      "Epoch 596, Loss: 0.8318511545658112, Final Batch Loss: 0.3368440866470337\n",
      "Epoch 597, Loss: 0.8015918135643005, Final Batch Loss: 0.2975710928440094\n",
      "Epoch 598, Loss: 0.7201943248510361, Final Batch Loss: 0.2049778252840042\n",
      "Epoch 599, Loss: 0.8960444331169128, Final Batch Loss: 0.3436849117279053\n",
      "Epoch 600, Loss: 0.6728948503732681, Final Batch Loss: 0.12702541053295135\n",
      "Epoch 601, Loss: 0.6412730067968369, Final Batch Loss: 0.15260489284992218\n",
      "Epoch 602, Loss: 0.7754682898521423, Final Batch Loss: 0.2380669265985489\n",
      "Epoch 603, Loss: 0.8276736587285995, Final Batch Loss: 0.3218752443790436\n",
      "Epoch 604, Loss: 0.7852754145860672, Final Batch Loss: 0.23922564089298248\n",
      "Epoch 605, Loss: 0.7158149629831314, Final Batch Loss: 0.1510174721479416\n",
      "Epoch 606, Loss: 0.6639636904001236, Final Batch Loss: 0.14262039959430695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 607, Loss: 0.7398370951414108, Final Batch Loss: 0.2080264836549759\n",
      "Epoch 608, Loss: 0.6318686380982399, Final Batch Loss: 0.12024996429681778\n",
      "Epoch 609, Loss: 0.788508951663971, Final Batch Loss: 0.29940834641456604\n",
      "Epoch 610, Loss: 0.6364736109972, Final Batch Loss: 0.17929422855377197\n",
      "Epoch 611, Loss: 0.7861429750919342, Final Batch Loss: 0.2624802589416504\n",
      "Epoch 612, Loss: 0.7715131193399429, Final Batch Loss: 0.25552186369895935\n",
      "Epoch 613, Loss: 0.7135898023843765, Final Batch Loss: 0.22741428017616272\n",
      "Epoch 614, Loss: 0.6553791463375092, Final Batch Loss: 0.15435922145843506\n",
      "Epoch 615, Loss: 0.7543781399726868, Final Batch Loss: 0.2941308915615082\n",
      "Epoch 616, Loss: 0.6287150830030441, Final Batch Loss: 0.16382990777492523\n",
      "Epoch 617, Loss: 0.6104279458522797, Final Batch Loss: 0.12335720658302307\n",
      "Epoch 618, Loss: 0.7350170910358429, Final Batch Loss: 0.28798970580101013\n",
      "Epoch 619, Loss: 0.6732099801301956, Final Batch Loss: 0.18362705409526825\n",
      "Epoch 620, Loss: 0.909346416592598, Final Batch Loss: 0.42220503091812134\n",
      "Epoch 621, Loss: 0.6204393953084946, Final Batch Loss: 0.12204854190349579\n",
      "Epoch 622, Loss: 0.8593448549509048, Final Batch Loss: 0.3891946077346802\n",
      "Epoch 623, Loss: 0.8133733868598938, Final Batch Loss: 0.33831435441970825\n",
      "Epoch 624, Loss: 0.6983545422554016, Final Batch Loss: 0.21183207631111145\n",
      "Epoch 625, Loss: 0.6834487020969391, Final Batch Loss: 0.19241909682750702\n",
      "Epoch 626, Loss: 0.9115627408027649, Final Batch Loss: 0.3892439901828766\n",
      "Epoch 627, Loss: 0.5444327965378761, Final Batch Loss: 0.08320625871419907\n",
      "Epoch 628, Loss: 0.7515059411525726, Final Batch Loss: 0.28225797414779663\n",
      "Epoch 629, Loss: 0.6614888310432434, Final Batch Loss: 0.12218362092971802\n",
      "Epoch 630, Loss: 0.8171986937522888, Final Batch Loss: 0.2793603837490082\n",
      "Epoch 631, Loss: 0.8201567828655243, Final Batch Loss: 0.3084099292755127\n",
      "Epoch 632, Loss: 0.709357738494873, Final Batch Loss: 0.23182620108127594\n",
      "Epoch 633, Loss: 0.8877214342355728, Final Batch Loss: 0.4095512330532074\n",
      "Epoch 634, Loss: 0.9245219230651855, Final Batch Loss: 0.40119484066963196\n",
      "Epoch 635, Loss: 0.7647624909877777, Final Batch Loss: 0.17536389827728271\n",
      "Epoch 636, Loss: 0.7924253940582275, Final Batch Loss: 0.23136231303215027\n",
      "Epoch 637, Loss: 0.9390338063240051, Final Batch Loss: 0.44602784514427185\n",
      "Epoch 638, Loss: 0.7982693612575531, Final Batch Loss: 0.21412211656570435\n",
      "Epoch 639, Loss: 0.7581934630870819, Final Batch Loss: 0.20579156279563904\n",
      "Epoch 640, Loss: 0.73481485247612, Final Batch Loss: 0.18366262316703796\n",
      "Epoch 641, Loss: 0.792316347360611, Final Batch Loss: 0.2728879451751709\n",
      "Epoch 642, Loss: 0.9249946177005768, Final Batch Loss: 0.47056227922439575\n",
      "Epoch 643, Loss: 0.7527788430452347, Final Batch Loss: 0.2960272431373596\n",
      "Epoch 644, Loss: 1.1092349886894226, Final Batch Loss: 0.6548786759376526\n",
      "Epoch 645, Loss: 0.7211324870586395, Final Batch Loss: 0.2732623517513275\n",
      "Epoch 646, Loss: 1.1580020785331726, Final Batch Loss: 0.6399490237236023\n",
      "Epoch 647, Loss: 0.6839175224304199, Final Batch Loss: 0.20990565419197083\n",
      "Epoch 648, Loss: 0.8350017666816711, Final Batch Loss: 0.30554693937301636\n",
      "Epoch 649, Loss: 0.845247745513916, Final Batch Loss: 0.308668851852417\n",
      "Epoch 650, Loss: 0.7753432393074036, Final Batch Loss: 0.26706790924072266\n",
      "Epoch 651, Loss: 0.7744241654872894, Final Batch Loss: 0.2929331660270691\n",
      "Epoch 652, Loss: 0.646233320236206, Final Batch Loss: 0.16645853221416473\n",
      "Epoch 653, Loss: 0.9713534414768219, Final Batch Loss: 0.5478730201721191\n",
      "Epoch 654, Loss: 0.9303680956363678, Final Batch Loss: 0.3816526532173157\n",
      "Epoch 655, Loss: 0.8112854063510895, Final Batch Loss: 0.3168826103210449\n",
      "Epoch 656, Loss: 0.8712237924337387, Final Batch Loss: 0.41512277722358704\n",
      "Epoch 657, Loss: 0.7395166754722595, Final Batch Loss: 0.27747344970703125\n",
      "Epoch 658, Loss: 0.8385925740003586, Final Batch Loss: 0.3486742079257965\n",
      "Epoch 659, Loss: 0.7836138308048248, Final Batch Loss: 0.29367518424987793\n",
      "Epoch 660, Loss: 0.7507313340902328, Final Batch Loss: 0.2824574112892151\n",
      "Epoch 661, Loss: 0.6365145146846771, Final Batch Loss: 0.16503670811653137\n",
      "Epoch 662, Loss: 0.7551621198654175, Final Batch Loss: 0.23478761315345764\n",
      "Epoch 663, Loss: 0.7293040901422501, Final Batch Loss: 0.2149808257818222\n",
      "Epoch 664, Loss: 0.8225966989994049, Final Batch Loss: 0.3760319650173187\n",
      "Epoch 665, Loss: 0.7935790419578552, Final Batch Loss: 0.3149055242538452\n",
      "Epoch 666, Loss: 0.6959712952375412, Final Batch Loss: 0.2409326136112213\n",
      "Epoch 667, Loss: 0.6905847191810608, Final Batch Loss: 0.21930427849292755\n",
      "Epoch 668, Loss: 0.6753079891204834, Final Batch Loss: 0.23926760256290436\n",
      "Epoch 669, Loss: 0.6710777282714844, Final Batch Loss: 0.1886400282382965\n",
      "Epoch 670, Loss: 0.7043220400810242, Final Batch Loss: 0.2172885239124298\n",
      "Epoch 671, Loss: 0.5662275850772858, Final Batch Loss: 0.130112424492836\n",
      "Epoch 672, Loss: 0.8734399825334549, Final Batch Loss: 0.4040234088897705\n",
      "Epoch 673, Loss: 0.8189519643783569, Final Batch Loss: 0.3521541655063629\n",
      "Epoch 674, Loss: 0.7328827381134033, Final Batch Loss: 0.2776806652545929\n",
      "Epoch 675, Loss: 0.5515018776059151, Final Batch Loss: 0.10821688920259476\n",
      "Epoch 676, Loss: 0.4888390675187111, Final Batch Loss: 0.03433201462030411\n",
      "Epoch 677, Loss: 0.6015272736549377, Final Batch Loss: 0.17076702415943146\n",
      "Epoch 678, Loss: 0.589966394007206, Final Batch Loss: 0.1224331334233284\n",
      "Epoch 679, Loss: 0.6588565111160278, Final Batch Loss: 0.19366973638534546\n",
      "Epoch 680, Loss: 0.829990342259407, Final Batch Loss: 0.3755171000957489\n",
      "Epoch 681, Loss: 0.5549075976014137, Final Batch Loss: 0.12475239485502243\n",
      "Epoch 682, Loss: 0.5041113048791885, Final Batch Loss: 0.08757166564464569\n",
      "Epoch 683, Loss: 0.7272058576345444, Final Batch Loss: 0.22005030512809753\n",
      "Epoch 684, Loss: 0.5752250850200653, Final Batch Loss: 0.13792988657951355\n",
      "Epoch 685, Loss: 1.0490180402994156, Final Batch Loss: 0.6281816959381104\n",
      "Epoch 686, Loss: 0.6247735023498535, Final Batch Loss: 0.16163809597492218\n",
      "Epoch 687, Loss: 0.6470727026462555, Final Batch Loss: 0.17564454674720764\n",
      "Epoch 688, Loss: 0.6515299677848816, Final Batch Loss: 0.18510222434997559\n",
      "Epoch 689, Loss: 0.6954932063817978, Final Batch Loss: 0.28110021352767944\n",
      "Epoch 690, Loss: 0.7733024656772614, Final Batch Loss: 0.33108049631118774\n",
      "Epoch 691, Loss: 0.4657811187207699, Final Batch Loss: 0.03975773975253105\n",
      "Epoch 692, Loss: 0.725642591714859, Final Batch Loss: 0.2835536003112793\n",
      "Epoch 693, Loss: 0.5266749262809753, Final Batch Loss: 0.083920419216156\n",
      "Epoch 694, Loss: 0.7092233151197433, Final Batch Loss: 0.267528772354126\n",
      "Epoch 695, Loss: 0.6157748252153397, Final Batch Loss: 0.1697961837053299\n",
      "Epoch 696, Loss: 0.6919812560081482, Final Batch Loss: 0.24174173176288605\n",
      "Epoch 697, Loss: 0.6102845221757889, Final Batch Loss: 0.17326530814170837\n",
      "Epoch 698, Loss: 0.530825600028038, Final Batch Loss: 0.1059008240699768\n",
      "Epoch 699, Loss: 0.633748933672905, Final Batch Loss: 0.15777188539505005\n",
      "Epoch 700, Loss: 0.6495455950498581, Final Batch Loss: 0.2084813266992569\n",
      "Epoch 701, Loss: 0.6235307902097702, Final Batch Loss: 0.23406872153282166\n",
      "Epoch 702, Loss: 0.7696798294782639, Final Batch Loss: 0.3618905544281006\n",
      "Epoch 703, Loss: 0.5288469195365906, Final Batch Loss: 0.10781987011432648\n",
      "Epoch 704, Loss: 0.5017155632376671, Final Batch Loss: 0.061642058193683624\n",
      "Epoch 705, Loss: 0.6543002426624298, Final Batch Loss: 0.20930370688438416\n",
      "Epoch 706, Loss: 0.70123091340065, Final Batch Loss: 0.2417822629213333\n",
      "Epoch 707, Loss: 0.8335994482040405, Final Batch Loss: 0.38479477167129517\n",
      "Epoch 708, Loss: 0.5166973993182182, Final Batch Loss: 0.05836228281259537\n",
      "Epoch 709, Loss: 0.7725065350532532, Final Batch Loss: 0.3353351354598999\n",
      "Epoch 710, Loss: 0.5304601639509201, Final Batch Loss: 0.13528089225292206\n",
      "Epoch 711, Loss: 0.8097371160984039, Final Batch Loss: 0.2900933027267456\n",
      "Epoch 712, Loss: 0.5600246489048004, Final Batch Loss: 0.15441566705703735\n",
      "Epoch 713, Loss: 0.8538970947265625, Final Batch Loss: 0.38355863094329834\n",
      "Epoch 714, Loss: 0.7488442361354828, Final Batch Loss: 0.2739567458629608\n",
      "Epoch 715, Loss: 0.5633863210678101, Final Batch Loss: 0.1475597470998764\n",
      "Epoch 716, Loss: 0.6694653332233429, Final Batch Loss: 0.21220797300338745\n",
      "Epoch 717, Loss: 0.6700550019741058, Final Batch Loss: 0.23476453125476837\n",
      "Epoch 718, Loss: 0.6255840361118317, Final Batch Loss: 0.22083312273025513\n",
      "Epoch 719, Loss: 0.5248825736343861, Final Batch Loss: 0.047591883689165115\n",
      "Epoch 720, Loss: 0.6001408994197845, Final Batch Loss: 0.156664177775383\n",
      "Epoch 721, Loss: 0.6563726663589478, Final Batch Loss: 0.21781392395496368\n",
      "Epoch 722, Loss: 0.4944336265325546, Final Batch Loss: 0.12074893712997437\n",
      "Epoch 723, Loss: 0.6231327950954437, Final Batch Loss: 0.1742958277463913\n",
      "Epoch 724, Loss: 0.5966107547283173, Final Batch Loss: 0.12926465272903442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 725, Loss: 0.47676220163702965, Final Batch Loss: 0.05070848390460014\n",
      "Epoch 726, Loss: 0.48821447417140007, Final Batch Loss: 0.03241635486483574\n",
      "Epoch 727, Loss: 0.5513932332396507, Final Batch Loss: 0.1131368950009346\n",
      "Epoch 728, Loss: 0.8083791583776474, Final Batch Loss: 0.3433544933795929\n",
      "Epoch 729, Loss: 0.7064328044652939, Final Batch Loss: 0.26273417472839355\n",
      "Epoch 730, Loss: 0.5722803324460983, Final Batch Loss: 0.14787894487380981\n",
      "Epoch 731, Loss: 0.5486355945467949, Final Batch Loss: 0.1226375624537468\n",
      "Epoch 732, Loss: 0.5191625878214836, Final Batch Loss: 0.1117025837302208\n",
      "Epoch 733, Loss: 0.626431405544281, Final Batch Loss: 0.15172605216503143\n",
      "Epoch 734, Loss: 0.5325634032487869, Final Batch Loss: 0.09750191867351532\n",
      "Epoch 735, Loss: 0.5029363632202148, Final Batch Loss: 0.07271930575370789\n",
      "Epoch 736, Loss: 0.6634920090436935, Final Batch Loss: 0.18543775379657745\n",
      "Epoch 737, Loss: 0.6173520237207413, Final Batch Loss: 0.14280280470848083\n",
      "Epoch 738, Loss: 0.7032894492149353, Final Batch Loss: 0.17513835430145264\n",
      "Epoch 739, Loss: 0.6627479493618011, Final Batch Loss: 0.22522780299186707\n",
      "Epoch 740, Loss: 0.7432970553636551, Final Batch Loss: 0.3147988021373749\n",
      "Epoch 741, Loss: 0.7170637100934982, Final Batch Loss: 0.2670948803424835\n",
      "Epoch 742, Loss: 0.6777858734130859, Final Batch Loss: 0.24083594977855682\n",
      "Epoch 743, Loss: 0.670579582452774, Final Batch Loss: 0.2646072804927826\n",
      "Epoch 744, Loss: 0.7991424202919006, Final Batch Loss: 0.35269278287887573\n",
      "Epoch 745, Loss: 0.7004427462816238, Final Batch Loss: 0.2019197642803192\n",
      "Epoch 746, Loss: 0.5896052122116089, Final Batch Loss: 0.176721453666687\n",
      "Epoch 747, Loss: 0.9953717440366745, Final Batch Loss: 0.5901446342468262\n",
      "Epoch 748, Loss: 0.6534524410963058, Final Batch Loss: 0.2519020140171051\n",
      "Epoch 749, Loss: 0.689098134636879, Final Batch Loss: 0.21848373115062714\n",
      "Epoch 750, Loss: 0.6151309162378311, Final Batch Loss: 0.166243314743042\n",
      "Epoch 751, Loss: 0.7080291360616684, Final Batch Loss: 0.2658970355987549\n",
      "Epoch 752, Loss: 0.8647859692573547, Final Batch Loss: 0.3357882797718048\n",
      "Epoch 753, Loss: 0.6592535674571991, Final Batch Loss: 0.18347172439098358\n",
      "Epoch 754, Loss: 0.8639875650405884, Final Batch Loss: 0.3268270194530487\n",
      "Epoch 755, Loss: 0.5798431113362312, Final Batch Loss: 0.1102372482419014\n",
      "Epoch 756, Loss: 0.6335527747869492, Final Batch Loss: 0.1632310003042221\n",
      "Epoch 757, Loss: 0.6139729171991348, Final Batch Loss: 0.1335882693529129\n",
      "Epoch 758, Loss: 0.9760345816612244, Final Batch Loss: 0.46655312180519104\n",
      "Epoch 759, Loss: 0.561290942132473, Final Batch Loss: 0.0943591371178627\n",
      "Epoch 760, Loss: 0.7250258475542068, Final Batch Loss: 0.287530779838562\n",
      "Epoch 761, Loss: 0.7923626005649567, Final Batch Loss: 0.29897966980934143\n",
      "Epoch 762, Loss: 0.7879271507263184, Final Batch Loss: 0.32649675011634827\n",
      "Epoch 763, Loss: 0.7282139658927917, Final Batch Loss: 0.226552814245224\n",
      "Epoch 764, Loss: 0.5580490306019783, Final Batch Loss: 0.08466062694787979\n",
      "Epoch 765, Loss: 0.8837232142686844, Final Batch Loss: 0.3428329527378082\n",
      "Epoch 766, Loss: 0.8779821395874023, Final Batch Loss: 0.32646265625953674\n",
      "Epoch 767, Loss: 1.015469804406166, Final Batch Loss: 0.5671402812004089\n",
      "Epoch 768, Loss: 0.5268800482153893, Final Batch Loss: 0.11430943757295609\n",
      "Epoch 769, Loss: 0.7291983515024185, Final Batch Loss: 0.24606333673000336\n",
      "Epoch 770, Loss: 0.6638727933168411, Final Batch Loss: 0.22924092411994934\n",
      "Epoch 771, Loss: 0.7163738161325455, Final Batch Loss: 0.34508201479911804\n",
      "Epoch 772, Loss: 0.646197646856308, Final Batch Loss: 0.2217797189950943\n",
      "Epoch 773, Loss: 0.48388711363077164, Final Batch Loss: 0.08363649994134903\n",
      "Epoch 774, Loss: 0.5838215164840221, Final Batch Loss: 0.03895715996623039\n",
      "Epoch 775, Loss: 0.6257845759391785, Final Batch Loss: 0.180899515748024\n",
      "Epoch 776, Loss: 0.7485384345054626, Final Batch Loss: 0.2478334754705429\n",
      "Epoch 777, Loss: 0.5638705063611269, Final Batch Loss: 0.03034481592476368\n",
      "Epoch 778, Loss: 0.7164671868085861, Final Batch Loss: 0.3178826868534088\n",
      "Epoch 779, Loss: 0.7041434049606323, Final Batch Loss: 0.31047266721725464\n",
      "Epoch 780, Loss: 0.6186730265617371, Final Batch Loss: 0.23013488948345184\n",
      "Epoch 781, Loss: 0.6339979469776154, Final Batch Loss: 0.20335666835308075\n",
      "Epoch 782, Loss: 0.6026183441281319, Final Batch Loss: 0.06968209892511368\n",
      "Epoch 783, Loss: 0.5507752448320389, Final Batch Loss: 0.1454530954360962\n",
      "Epoch 784, Loss: 0.6041268557310104, Final Batch Loss: 0.20822089910507202\n",
      "Epoch 785, Loss: 0.6929669082164764, Final Batch Loss: 0.24562013149261475\n",
      "Epoch 786, Loss: 0.8774485439062119, Final Batch Loss: 0.38600432872772217\n",
      "Epoch 787, Loss: 0.8686365187168121, Final Batch Loss: 0.37028035521507263\n",
      "Epoch 788, Loss: 0.6559499502182007, Final Batch Loss: 0.2307986170053482\n",
      "Epoch 789, Loss: 0.5986733734607697, Final Batch Loss: 0.15632450580596924\n",
      "Epoch 790, Loss: 0.5757476538419724, Final Batch Loss: 0.1674470752477646\n",
      "Epoch 791, Loss: 0.5742855072021484, Final Batch Loss: 0.10872608423233032\n",
      "Epoch 792, Loss: 0.7130071371793747, Final Batch Loss: 0.2953312397003174\n",
      "Epoch 793, Loss: 0.5126247704029083, Final Batch Loss: 0.09875622391700745\n",
      "Epoch 794, Loss: 0.5279280245304108, Final Batch Loss: 0.09796811640262604\n",
      "Epoch 795, Loss: 0.5788700878620148, Final Batch Loss: 0.1347937285900116\n",
      "Epoch 796, Loss: 0.8194625228643417, Final Batch Loss: 0.4368424713611603\n",
      "Epoch 797, Loss: 0.6219153106212616, Final Batch Loss: 0.19898264110088348\n",
      "Epoch 798, Loss: 0.7015058249235153, Final Batch Loss: 0.2512110769748688\n",
      "Epoch 799, Loss: 0.6114411950111389, Final Batch Loss: 0.21726854145526886\n",
      "Epoch 800, Loss: 0.5721918791532516, Final Batch Loss: 0.1171000599861145\n",
      "Epoch 801, Loss: 0.6668388545513153, Final Batch Loss: 0.206825390458107\n",
      "Epoch 802, Loss: 0.7329475730657578, Final Batch Loss: 0.2645857036113739\n",
      "Epoch 803, Loss: 0.664121150970459, Final Batch Loss: 0.20788276195526123\n",
      "Epoch 804, Loss: 0.6747195720672607, Final Batch Loss: 0.1801038235425949\n",
      "Epoch 805, Loss: 0.6166936159133911, Final Batch Loss: 0.1681109070777893\n",
      "Epoch 806, Loss: 0.6711642742156982, Final Batch Loss: 0.22036845982074738\n",
      "Epoch 807, Loss: 0.7455326020717621, Final Batch Loss: 0.30173105001449585\n",
      "Epoch 808, Loss: 0.4239603653550148, Final Batch Loss: 0.027164913713932037\n",
      "Epoch 809, Loss: 0.8648959696292877, Final Batch Loss: 0.44057297706604004\n",
      "Epoch 810, Loss: 0.5814809054136276, Final Batch Loss: 0.18789176642894745\n",
      "Epoch 811, Loss: 0.48853546753525734, Final Batch Loss: 0.04249512031674385\n",
      "Epoch 812, Loss: 0.9852215200662613, Final Batch Loss: 0.435062050819397\n",
      "Epoch 813, Loss: 0.57996666431427, Final Batch Loss: 0.1634422093629837\n",
      "Epoch 814, Loss: 0.6736779361963272, Final Batch Loss: 0.24856577813625336\n",
      "Epoch 815, Loss: 0.5117347314953804, Final Batch Loss: 0.11191775649785995\n",
      "Epoch 816, Loss: 0.6427202522754669, Final Batch Loss: 0.21679918467998505\n",
      "Epoch 817, Loss: 0.5769409239292145, Final Batch Loss: 0.1354038119316101\n",
      "Epoch 818, Loss: 0.43084018863737583, Final Batch Loss: 0.027781913056969643\n",
      "Epoch 819, Loss: 0.5184468179941177, Final Batch Loss: 0.13308918476104736\n",
      "Epoch 820, Loss: 0.616657555103302, Final Batch Loss: 0.21100576221942902\n",
      "Epoch 821, Loss: 0.8109312057495117, Final Batch Loss: 0.41021618247032166\n",
      "Epoch 822, Loss: 0.47197599709033966, Final Batch Loss: 0.07317215204238892\n",
      "Epoch 823, Loss: 0.6516800075769424, Final Batch Loss: 0.28644904494285583\n",
      "Epoch 824, Loss: 0.5413369685411453, Final Batch Loss: 0.1736835241317749\n",
      "Epoch 825, Loss: 0.7629504799842834, Final Batch Loss: 0.38189560174942017\n",
      "Epoch 826, Loss: 0.6038341224193573, Final Batch Loss: 0.21250636875629425\n",
      "Epoch 827, Loss: 0.42630746960639954, Final Batch Loss: 0.031660422682762146\n",
      "Epoch 828, Loss: 0.5889037698507309, Final Batch Loss: 0.21416932344436646\n",
      "Epoch 829, Loss: 0.5307440236210823, Final Batch Loss: 0.11590444296598434\n",
      "Epoch 830, Loss: 0.5338260531425476, Final Batch Loss: 0.15368419885635376\n",
      "Epoch 831, Loss: 0.5864389538764954, Final Batch Loss: 0.20307636260986328\n",
      "Epoch 832, Loss: 0.4991188794374466, Final Batch Loss: 0.1254817098379135\n",
      "Epoch 833, Loss: 0.5856198519468307, Final Batch Loss: 0.18660493195056915\n",
      "Epoch 834, Loss: 0.7153268754482269, Final Batch Loss: 0.3242604732513428\n",
      "Epoch 835, Loss: 0.6634936779737473, Final Batch Loss: 0.3016979694366455\n",
      "Epoch 836, Loss: 0.503791019320488, Final Batch Loss: 0.1359393149614334\n",
      "Epoch 837, Loss: 0.6342122256755829, Final Batch Loss: 0.22681273519992828\n",
      "Epoch 838, Loss: 0.4570159837603569, Final Batch Loss: 0.07501093298196793\n",
      "Epoch 839, Loss: 0.48688724637031555, Final Batch Loss: 0.13594774901866913\n",
      "Epoch 840, Loss: 0.7039583772420883, Final Batch Loss: 0.32343122363090515\n",
      "Epoch 841, Loss: 0.4785337895154953, Final Batch Loss: 0.06844554841518402\n",
      "Epoch 842, Loss: 0.5114496499300003, Final Batch Loss: 0.020499244332313538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843, Loss: 0.465665640309453, Final Batch Loss: 0.023949922993779182\n",
      "Epoch 844, Loss: 0.4330286532640457, Final Batch Loss: 0.08530372381210327\n",
      "Epoch 845, Loss: 0.5113532990217209, Final Batch Loss: 0.1233011931180954\n",
      "Epoch 846, Loss: 0.5944823324680328, Final Batch Loss: 0.23703989386558533\n",
      "Epoch 847, Loss: 0.6787157654762268, Final Batch Loss: 0.23978371918201447\n",
      "Epoch 848, Loss: 0.715111717581749, Final Batch Loss: 0.2977586090564728\n",
      "Epoch 849, Loss: 0.5059854537248611, Final Batch Loss: 0.1350243240594864\n",
      "Epoch 850, Loss: 0.6492274254560471, Final Batch Loss: 0.31305986642837524\n",
      "Epoch 851, Loss: 0.7542665898799896, Final Batch Loss: 0.39204156398773193\n",
      "Epoch 852, Loss: 0.7732418477535248, Final Batch Loss: 0.37014704942703247\n",
      "Epoch 853, Loss: 0.6813816428184509, Final Batch Loss: 0.3212578296661377\n",
      "Epoch 854, Loss: 0.5719940364360809, Final Batch Loss: 0.1743827611207962\n",
      "Epoch 855, Loss: 0.801466777920723, Final Batch Loss: 0.35714855790138245\n",
      "Epoch 856, Loss: 0.5563729554414749, Final Batch Loss: 0.14726082980632782\n",
      "Epoch 857, Loss: 0.5617502778768539, Final Batch Loss: 0.15224817395210266\n",
      "Epoch 858, Loss: 0.4936579018831253, Final Batch Loss: 0.06296855211257935\n",
      "Epoch 859, Loss: 0.6715955883264542, Final Batch Loss: 0.23403878509998322\n",
      "Epoch 860, Loss: 0.4922805726528168, Final Batch Loss: 0.08348549902439117\n",
      "Epoch 861, Loss: 0.4991636872291565, Final Batch Loss: 0.13013070821762085\n",
      "Epoch 862, Loss: 0.6952724754810333, Final Batch Loss: 0.2921738624572754\n",
      "Epoch 863, Loss: 0.6030166745185852, Final Batch Loss: 0.24501624703407288\n",
      "Epoch 864, Loss: 0.556189626455307, Final Batch Loss: 0.1474064290523529\n",
      "Epoch 865, Loss: 0.5193165838718414, Final Batch Loss: 0.20193812251091003\n",
      "Epoch 866, Loss: 0.7402828484773636, Final Batch Loss: 0.35010072588920593\n",
      "Epoch 867, Loss: 0.611974686384201, Final Batch Loss: 0.21345722675323486\n",
      "Epoch 868, Loss: 0.48117029666900635, Final Batch Loss: 0.0766611099243164\n",
      "Epoch 869, Loss: 0.6093729585409164, Final Batch Loss: 0.2519581615924835\n",
      "Epoch 870, Loss: 0.5808040648698807, Final Batch Loss: 0.22195027768611908\n",
      "Epoch 871, Loss: 0.6922463923692703, Final Batch Loss: 0.2484854906797409\n",
      "Epoch 872, Loss: 0.5207905918359756, Final Batch Loss: 0.11832529306411743\n",
      "Epoch 873, Loss: 0.5109972208738327, Final Batch Loss: 0.1168103963136673\n",
      "Epoch 874, Loss: 0.5537900030612946, Final Batch Loss: 0.1744007021188736\n",
      "Epoch 875, Loss: 0.5104546621441841, Final Batch Loss: 0.07475735992193222\n",
      "Epoch 876, Loss: 0.6647569984197617, Final Batch Loss: 0.2747902572154999\n",
      "Epoch 877, Loss: 0.5801706314086914, Final Batch Loss: 0.1645687371492386\n",
      "Epoch 878, Loss: 0.6494603455066681, Final Batch Loss: 0.26030024886131287\n",
      "Epoch 879, Loss: 0.6060951352119446, Final Batch Loss: 0.18861232697963715\n",
      "Epoch 880, Loss: 0.6629420071840286, Final Batch Loss: 0.24141627550125122\n",
      "Epoch 881, Loss: 0.795912891626358, Final Batch Loss: 0.34274375438690186\n",
      "Epoch 882, Loss: 0.7954974472522736, Final Batch Loss: 0.3976376950740814\n",
      "Epoch 883, Loss: 0.5685981959104538, Final Batch Loss: 0.12301729619503021\n",
      "Epoch 884, Loss: 0.5893932431936264, Final Batch Loss: 0.19565150141716003\n",
      "Epoch 885, Loss: 0.5728272385895252, Final Batch Loss: 0.05929094925522804\n",
      "Epoch 886, Loss: 0.6160134375095367, Final Batch Loss: 0.18300752341747284\n",
      "Epoch 887, Loss: 0.7136522233486176, Final Batch Loss: 0.3000180125236511\n",
      "Epoch 888, Loss: 0.45934692211449146, Final Batch Loss: 0.019559847190976143\n",
      "Epoch 889, Loss: 0.6866767406463623, Final Batch Loss: 0.2500104308128357\n",
      "Epoch 890, Loss: 0.754354938864708, Final Batch Loss: 0.31643521785736084\n",
      "Epoch 891, Loss: 0.5586053133010864, Final Batch Loss: 0.14372263848781586\n",
      "Epoch 892, Loss: 0.6256106644868851, Final Batch Loss: 0.2570136487483978\n",
      "Epoch 893, Loss: 0.5239692181348801, Final Batch Loss: 0.20688846707344055\n",
      "Epoch 894, Loss: 0.5437116175889969, Final Batch Loss: 0.14790745079517365\n",
      "Epoch 895, Loss: 0.4790397584438324, Final Batch Loss: 0.10554806888103485\n",
      "Epoch 896, Loss: 0.8733079880475998, Final Batch Loss: 0.5182052254676819\n",
      "Epoch 897, Loss: 0.45008643716573715, Final Batch Loss: 0.07802628725767136\n",
      "Epoch 898, Loss: 0.47663547098636627, Final Batch Loss: 0.06807048618793488\n",
      "Epoch 899, Loss: 0.5684801191091537, Final Batch Loss: 0.1886068433523178\n",
      "Epoch 900, Loss: 0.49122288078069687, Final Batch Loss: 0.07065460830926895\n",
      "Epoch 901, Loss: 0.4580221585929394, Final Batch Loss: 0.06214573606848717\n",
      "Epoch 902, Loss: 0.4380086064338684, Final Batch Loss: 0.021989330649375916\n",
      "Epoch 903, Loss: 0.4866206794977188, Final Batch Loss: 0.06949353218078613\n",
      "Epoch 904, Loss: 0.5424310266971588, Final Batch Loss: 0.14531004428863525\n",
      "Epoch 905, Loss: 0.4541127011179924, Final Batch Loss: 0.08126721531152725\n",
      "Epoch 906, Loss: 0.6085847914218903, Final Batch Loss: 0.2136555016040802\n",
      "Epoch 907, Loss: 0.5451115667819977, Final Batch Loss: 0.16363881528377533\n",
      "Epoch 908, Loss: 0.5789239853620529, Final Batch Loss: 0.18558602035045624\n",
      "Epoch 909, Loss: 0.46521101891994476, Final Batch Loss: 0.06680166721343994\n",
      "Epoch 910, Loss: 0.3983385842293501, Final Batch Loss: 0.023011548444628716\n",
      "Epoch 911, Loss: 0.8039858043193817, Final Batch Loss: 0.4537009596824646\n",
      "Epoch 912, Loss: 0.6441751271486282, Final Batch Loss: 0.2721734941005707\n",
      "Epoch 913, Loss: 0.7318957149982452, Final Batch Loss: 0.34001684188842773\n",
      "Epoch 914, Loss: 0.8158383071422577, Final Batch Loss: 0.4175179898738861\n",
      "Epoch 915, Loss: 0.5943974554538727, Final Batch Loss: 0.2001030594110489\n",
      "Epoch 916, Loss: 0.5403240621089935, Final Batch Loss: 0.14399783313274384\n",
      "Epoch 917, Loss: 0.6226471811532974, Final Batch Loss: 0.2681092321872711\n",
      "Epoch 918, Loss: 0.7479662299156189, Final Batch Loss: 0.3390294909477234\n",
      "Epoch 919, Loss: 0.6187908500432968, Final Batch Loss: 0.19428884983062744\n",
      "Epoch 920, Loss: 0.6776929497718811, Final Batch Loss: 0.27022066712379456\n",
      "Epoch 921, Loss: 0.5762010216712952, Final Batch Loss: 0.1459013968706131\n",
      "Epoch 922, Loss: 0.6052417904138565, Final Batch Loss: 0.1941012591123581\n",
      "Epoch 923, Loss: 0.41208646446466446, Final Batch Loss: 0.04262080043554306\n",
      "Epoch 924, Loss: 0.5438107810914516, Final Batch Loss: 0.05880231782793999\n",
      "Epoch 925, Loss: 0.47820837795734406, Final Batch Loss: 0.05758729577064514\n",
      "Epoch 926, Loss: 0.5871076881885529, Final Batch Loss: 0.1772589236497879\n",
      "Epoch 927, Loss: 0.5964425951242447, Final Batch Loss: 0.24226969480514526\n",
      "Epoch 928, Loss: 0.5842170864343643, Final Batch Loss: 0.15492770075798035\n",
      "Epoch 929, Loss: 0.4287390299141407, Final Batch Loss: 0.038659561425447464\n",
      "Epoch 930, Loss: 0.48404525592923164, Final Batch Loss: 0.0563771016895771\n",
      "Epoch 931, Loss: 0.4367402493953705, Final Batch Loss: 0.10296191275119781\n",
      "Epoch 932, Loss: 0.5834434479475021, Final Batch Loss: 0.22799770534038544\n",
      "Epoch 933, Loss: 0.4475959539413452, Final Batch Loss: 0.0780000388622284\n",
      "Epoch 934, Loss: 0.5590240955352783, Final Batch Loss: 0.21806412935256958\n",
      "Epoch 935, Loss: 0.7099946141242981, Final Batch Loss: 0.33164018392562866\n",
      "Epoch 936, Loss: 0.7206115573644638, Final Batch Loss: 0.390423059463501\n",
      "Epoch 937, Loss: 0.615304097533226, Final Batch Loss: 0.22572652995586395\n",
      "Epoch 938, Loss: 0.4272342287003994, Final Batch Loss: 0.05166726931929588\n",
      "Epoch 939, Loss: 0.7136594206094742, Final Batch Loss: 0.3622763156890869\n",
      "Epoch 940, Loss: 0.3877746108919382, Final Batch Loss: 0.026056954637169838\n",
      "Epoch 941, Loss: 0.4470525160431862, Final Batch Loss: 0.11454299837350845\n",
      "Epoch 942, Loss: 0.47807445377111435, Final Batch Loss: 0.09918241947889328\n",
      "Epoch 943, Loss: 0.5292147472500801, Final Batch Loss: 0.1225876435637474\n",
      "Epoch 944, Loss: 0.482928529381752, Final Batch Loss: 0.13050268590450287\n",
      "Epoch 945, Loss: 0.6305169612169266, Final Batch Loss: 0.274811327457428\n",
      "Epoch 946, Loss: 0.5550937354564667, Final Batch Loss: 0.1916736364364624\n",
      "Epoch 947, Loss: 0.48658932000398636, Final Batch Loss: 0.09805170446634293\n",
      "Epoch 948, Loss: 0.49606853723526, Final Batch Loss: 0.10117305815219879\n",
      "Epoch 949, Loss: 0.5266856849193573, Final Batch Loss: 0.17237640917301178\n",
      "Epoch 950, Loss: 0.473183773458004, Final Batch Loss: 0.07861382514238358\n",
      "Epoch 951, Loss: 0.48701557517051697, Final Batch Loss: 0.06614543497562408\n",
      "Epoch 952, Loss: 0.6303635686635971, Final Batch Loss: 0.19993281364440918\n",
      "Epoch 953, Loss: 0.5056180655956268, Final Batch Loss: 0.15654081106185913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 954, Loss: 0.5233380943536758, Final Batch Loss: 0.1041124165058136\n",
      "Epoch 955, Loss: 0.673588365316391, Final Batch Loss: 0.2772422432899475\n",
      "Epoch 956, Loss: 0.47060082107782364, Final Batch Loss: 0.1214890107512474\n",
      "Epoch 957, Loss: 0.6267038881778717, Final Batch Loss: 0.21725301444530487\n",
      "Epoch 958, Loss: 0.5053177885711193, Final Batch Loss: 0.013071294873952866\n",
      "Epoch 959, Loss: 0.5727593749761581, Final Batch Loss: 0.21677443385124207\n",
      "Epoch 960, Loss: 0.5845059752464294, Final Batch Loss: 0.17122425138950348\n",
      "Epoch 961, Loss: 0.5978566408157349, Final Batch Loss: 0.22521789371967316\n",
      "Epoch 962, Loss: 0.5844951272010803, Final Batch Loss: 0.157793328166008\n",
      "Epoch 963, Loss: 0.4578442648053169, Final Batch Loss: 0.04788493365049362\n",
      "Epoch 964, Loss: 0.5251655131578445, Final Batch Loss: 0.15743160247802734\n",
      "Epoch 965, Loss: 0.5679150819778442, Final Batch Loss: 0.1561291217803955\n",
      "Epoch 966, Loss: 0.6828019171953201, Final Batch Loss: 0.33800771832466125\n",
      "Epoch 967, Loss: 0.4567995071411133, Final Batch Loss: 0.10631592571735382\n",
      "Epoch 968, Loss: 0.5196439623832703, Final Batch Loss: 0.15487132966518402\n",
      "Epoch 969, Loss: 0.7090307772159576, Final Batch Loss: 0.23469199240207672\n",
      "Epoch 970, Loss: 0.9578011333942413, Final Batch Loss: 0.43688639998435974\n",
      "Epoch 971, Loss: 0.5309222638607025, Final Batch Loss: 0.14667347073554993\n",
      "Epoch 972, Loss: 0.5949393957853317, Final Batch Loss: 0.25430697202682495\n",
      "Epoch 973, Loss: 0.6911531686782837, Final Batch Loss: 0.22725839912891388\n",
      "Epoch 974, Loss: 0.6358068138360977, Final Batch Loss: 0.2626180946826935\n",
      "Epoch 975, Loss: 0.6633524745702744, Final Batch Loss: 0.3296724557876587\n",
      "Epoch 976, Loss: 0.769260436296463, Final Batch Loss: 0.35688120126724243\n",
      "Epoch 977, Loss: 0.5625337213277817, Final Batch Loss: 0.1740143895149231\n",
      "Epoch 978, Loss: 0.6247682273387909, Final Batch Loss: 0.2811686098575592\n",
      "Epoch 979, Loss: 0.5129345655441284, Final Batch Loss: 0.19421255588531494\n",
      "Epoch 980, Loss: 0.6002470552921295, Final Batch Loss: 0.16198362410068512\n",
      "Epoch 981, Loss: 0.7153933048248291, Final Batch Loss: 0.30239972472190857\n",
      "Epoch 982, Loss: 0.6047088205814362, Final Batch Loss: 0.25226542353630066\n",
      "Epoch 983, Loss: 0.5368438512086868, Final Batch Loss: 0.17488616704940796\n",
      "Epoch 984, Loss: 0.602017879486084, Final Batch Loss: 0.2564050853252411\n",
      "Epoch 985, Loss: 0.8085827678442001, Final Batch Loss: 0.346711128950119\n",
      "Epoch 986, Loss: 0.6373862475156784, Final Batch Loss: 0.31859493255615234\n",
      "Epoch 987, Loss: 0.42251404747366905, Final Batch Loss: 0.02637438103556633\n",
      "Epoch 988, Loss: 0.5229230523109436, Final Batch Loss: 0.15490517020225525\n",
      "Epoch 989, Loss: 0.5199936032295227, Final Batch Loss: 0.14938397705554962\n",
      "Epoch 990, Loss: 0.3934720903635025, Final Batch Loss: 0.011946097016334534\n",
      "Epoch 991, Loss: 0.6761120110750198, Final Batch Loss: 0.3239804208278656\n",
      "Epoch 992, Loss: 0.5421368181705475, Final Batch Loss: 0.18781667947769165\n",
      "Epoch 993, Loss: 0.49336646124720573, Final Batch Loss: 0.050429534167051315\n",
      "Epoch 994, Loss: 0.8184275776147842, Final Batch Loss: 0.4191858172416687\n",
      "Epoch 995, Loss: 0.7634695619344711, Final Batch Loss: 0.35560542345046997\n",
      "Epoch 996, Loss: 0.6258509010076523, Final Batch Loss: 0.23410405218601227\n",
      "Epoch 997, Loss: 0.48949965089559555, Final Batch Loss: 0.11060821264982224\n",
      "Epoch 998, Loss: 0.559905543923378, Final Batch Loss: 0.19893181324005127\n",
      "Epoch 999, Loss: 0.47015444189310074, Final Batch Loss: 0.1244145855307579\n",
      "Epoch 1000, Loss: 0.546988770365715, Final Batch Loss: 0.19336850941181183\n",
      "Epoch 1001, Loss: 0.6442782282829285, Final Batch Loss: 0.2548111379146576\n",
      "Epoch 1002, Loss: 0.5320500731468201, Final Batch Loss: 0.17674027383327484\n",
      "Epoch 1003, Loss: 0.5448080748319626, Final Batch Loss: 0.20799371600151062\n",
      "Epoch 1004, Loss: 0.5155790597200394, Final Batch Loss: 0.08526560664176941\n",
      "Epoch 1005, Loss: 0.5178574770689011, Final Batch Loss: 0.15463541448116302\n",
      "Epoch 1006, Loss: 0.7081126570701599, Final Batch Loss: 0.3470931351184845\n",
      "Epoch 1007, Loss: 0.39223047718405724, Final Batch Loss: 0.027378913015127182\n",
      "Epoch 1008, Loss: 0.5401567220687866, Final Batch Loss: 0.15849056839942932\n",
      "Epoch 1009, Loss: 0.5520069599151611, Final Batch Loss: 0.19096168875694275\n",
      "Epoch 1010, Loss: 0.4506576657295227, Final Batch Loss: 0.1361670345067978\n",
      "Epoch 1011, Loss: 0.6246796399354935, Final Batch Loss: 0.3028593957424164\n",
      "Epoch 1012, Loss: 0.43920794501900673, Final Batch Loss: 0.0509781576693058\n",
      "Epoch 1013, Loss: 0.39201002568006516, Final Batch Loss: 0.06765640527009964\n",
      "Epoch 1014, Loss: 0.585091769695282, Final Batch Loss: 0.2520882189273834\n",
      "Epoch 1015, Loss: 0.5353931486606598, Final Batch Loss: 0.19148635864257812\n",
      "Epoch 1016, Loss: 0.6969462484121323, Final Batch Loss: 0.31009820103645325\n",
      "Epoch 1017, Loss: 0.6100828051567078, Final Batch Loss: 0.21530412137508392\n",
      "Epoch 1018, Loss: 0.5625825077295303, Final Batch Loss: 0.12626858055591583\n",
      "Epoch 1019, Loss: 0.7315821647644043, Final Batch Loss: 0.3464672267436981\n",
      "Epoch 1020, Loss: 0.6703455746173859, Final Batch Loss: 0.28211021423339844\n",
      "Epoch 1021, Loss: 0.6500446945428848, Final Batch Loss: 0.13701839745044708\n",
      "Epoch 1022, Loss: 0.3912520967423916, Final Batch Loss: 0.05414881929755211\n",
      "Epoch 1023, Loss: 0.5887447744607925, Final Batch Loss: 0.21202147006988525\n",
      "Epoch 1024, Loss: 0.615579754114151, Final Batch Loss: 0.22753235697746277\n",
      "Epoch 1025, Loss: 0.5147468894720078, Final Batch Loss: 0.14550484716892242\n",
      "Epoch 1026, Loss: 0.6214600056409836, Final Batch Loss: 0.1714930534362793\n",
      "Epoch 1027, Loss: 0.6538922339677811, Final Batch Loss: 0.1567443162202835\n",
      "Epoch 1028, Loss: 0.7888264805078506, Final Batch Loss: 0.4205605685710907\n",
      "Epoch 1029, Loss: 0.8742217123508453, Final Batch Loss: 0.5491818785667419\n",
      "Epoch 1030, Loss: 0.5176407396793365, Final Batch Loss: 0.14863380789756775\n",
      "Epoch 1031, Loss: 0.49029676616191864, Final Batch Loss: 0.10031257569789886\n",
      "Epoch 1032, Loss: 0.476209819316864, Final Batch Loss: 0.08288735151290894\n",
      "Epoch 1033, Loss: 0.629216805100441, Final Batch Loss: 0.24477961659431458\n",
      "Epoch 1034, Loss: 0.5743853747844696, Final Batch Loss: 0.23437368869781494\n",
      "Epoch 1035, Loss: 0.5770133435726166, Final Batch Loss: 0.19052962958812714\n",
      "Epoch 1036, Loss: 0.5410420298576355, Final Batch Loss: 0.14031590521335602\n",
      "Epoch 1037, Loss: 0.45832958817481995, Final Batch Loss: 0.07736563682556152\n",
      "Epoch 1038, Loss: 0.5087183564901352, Final Batch Loss: 0.1774900257587433\n",
      "Epoch 1039, Loss: 0.48088543117046356, Final Batch Loss: 0.1266310214996338\n",
      "Epoch 1040, Loss: 0.6282539814710617, Final Batch Loss: 0.3025037348270416\n",
      "Epoch 1041, Loss: 0.38677261862903833, Final Batch Loss: 0.008929611183702946\n",
      "Epoch 1042, Loss: 0.6032411307096481, Final Batch Loss: 0.19867382943630219\n",
      "Epoch 1043, Loss: 0.7046475410461426, Final Batch Loss: 0.23183539509773254\n",
      "Epoch 1044, Loss: 0.6943608373403549, Final Batch Loss: 0.16205237805843353\n",
      "Epoch 1045, Loss: 0.9135365039110184, Final Batch Loss: 0.4368860721588135\n",
      "Epoch 1046, Loss: 0.6655857115983963, Final Batch Loss: 0.2589890658855438\n",
      "Epoch 1047, Loss: 0.47360426001250744, Final Batch Loss: 0.030200568959116936\n",
      "Epoch 1048, Loss: 0.6006952151656151, Final Batch Loss: 0.11489147692918777\n",
      "Epoch 1049, Loss: 0.7672903686761856, Final Batch Loss: 0.3786855638027191\n",
      "Epoch 1050, Loss: 0.5793219059705734, Final Batch Loss: 0.2616412341594696\n",
      "Epoch 1051, Loss: 0.49836403876543045, Final Batch Loss: 0.11072073131799698\n",
      "Epoch 1052, Loss: 0.7511941194534302, Final Batch Loss: 0.31522512435913086\n",
      "Epoch 1053, Loss: 0.709431603550911, Final Batch Loss: 0.34020766615867615\n",
      "Epoch 1054, Loss: 0.6327367424964905, Final Batch Loss: 0.20279836654663086\n",
      "Epoch 1055, Loss: 0.6666085869073868, Final Batch Loss: 0.2626258432865143\n",
      "Epoch 1056, Loss: 0.6692259162664413, Final Batch Loss: 0.2337338775396347\n",
      "Epoch 1057, Loss: 0.5569581538438797, Final Batch Loss: 0.18849198520183563\n",
      "Epoch 1058, Loss: 0.9071649461984634, Final Batch Loss: 0.5756500363349915\n",
      "Epoch 1059, Loss: 0.5062728673219681, Final Batch Loss: 0.13518089056015015\n",
      "Epoch 1060, Loss: 0.4554392844438553, Final Batch Loss: 0.09393024444580078\n",
      "Epoch 1061, Loss: 0.45670008659362793, Final Batch Loss: 0.088611900806427\n",
      "Epoch 1062, Loss: 0.5448106676340103, Final Batch Loss: 0.2121981382369995\n",
      "Epoch 1063, Loss: 0.3884650617837906, Final Batch Loss: 0.07143735885620117\n",
      "Epoch 1064, Loss: 0.39690984040498734, Final Batch Loss: 0.07231651991605759\n",
      "Epoch 1065, Loss: 0.5395314544439316, Final Batch Loss: 0.1384028196334839\n",
      "Epoch 1066, Loss: 0.602962926030159, Final Batch Loss: 0.29034557938575745\n",
      "Epoch 1067, Loss: 0.43102946132421494, Final Batch Loss: 0.11865756660699844\n",
      "Epoch 1068, Loss: 0.440237395465374, Final Batch Loss: 0.11132831126451492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1069, Loss: 0.6113429516553879, Final Batch Loss: 0.3032751679420471\n",
      "Epoch 1070, Loss: 0.47231094539165497, Final Batch Loss: 0.08792346715927124\n",
      "Epoch 1071, Loss: 0.6285771429538727, Final Batch Loss: 0.2895822823047638\n",
      "Epoch 1072, Loss: 0.5337898433208466, Final Batch Loss: 0.16164059937000275\n",
      "Epoch 1073, Loss: 0.4784894734621048, Final Batch Loss: 0.11115199327468872\n",
      "Epoch 1074, Loss: 0.45634786784648895, Final Batch Loss: 0.12362807989120483\n",
      "Epoch 1075, Loss: 0.7342234253883362, Final Batch Loss: 0.40399765968322754\n",
      "Epoch 1076, Loss: 0.6176514029502869, Final Batch Loss: 0.3033527731895447\n",
      "Epoch 1077, Loss: 0.6636159718036652, Final Batch Loss: 0.2811793386936188\n",
      "Epoch 1078, Loss: 0.6076205670833588, Final Batch Loss: 0.18143998086452484\n",
      "Epoch 1079, Loss: 0.4829656183719635, Final Batch Loss: 0.12565647065639496\n",
      "Epoch 1080, Loss: 0.5695581138134003, Final Batch Loss: 0.16667720675468445\n",
      "Epoch 1081, Loss: 0.5646539479494095, Final Batch Loss: 0.18956977128982544\n",
      "Epoch 1082, Loss: 0.5045624822378159, Final Batch Loss: 0.16258351504802704\n",
      "Epoch 1083, Loss: 0.5758510679006577, Final Batch Loss: 0.25675877928733826\n",
      "Epoch 1084, Loss: 0.5829484164714813, Final Batch Loss: 0.23263919353485107\n",
      "Epoch 1085, Loss: 0.40930869430303574, Final Batch Loss: 0.035967178642749786\n",
      "Epoch 1086, Loss: 0.3790072798728943, Final Batch Loss: 0.03310708701610565\n",
      "Epoch 1087, Loss: 0.6344786137342453, Final Batch Loss: 0.3310745060443878\n",
      "Epoch 1088, Loss: 0.382561556994915, Final Batch Loss: 0.06895110756158829\n",
      "Epoch 1089, Loss: 0.47062788903713226, Final Batch Loss: 0.12622220814228058\n",
      "Epoch 1090, Loss: 0.4470202177762985, Final Batch Loss: 0.15491510927677155\n",
      "Epoch 1091, Loss: 0.46522651612758636, Final Batch Loss: 0.13640663027763367\n",
      "Epoch 1092, Loss: 0.5578951239585876, Final Batch Loss: 0.24458594620227814\n",
      "Epoch 1093, Loss: 0.5304790735244751, Final Batch Loss: 0.22693824768066406\n",
      "Epoch 1094, Loss: 0.5041060596704483, Final Batch Loss: 0.18638311326503754\n",
      "Epoch 1095, Loss: 0.4224635362625122, Final Batch Loss: 0.12544403970241547\n",
      "Epoch 1096, Loss: 0.5574671775102615, Final Batch Loss: 0.1752958744764328\n",
      "Epoch 1097, Loss: 0.7383904904127121, Final Batch Loss: 0.43896791338920593\n",
      "Epoch 1098, Loss: 0.595066174864769, Final Batch Loss: 0.2567822337150574\n",
      "Epoch 1099, Loss: 0.6379927843809128, Final Batch Loss: 0.31091222167015076\n",
      "Epoch 1100, Loss: 0.5064676702022552, Final Batch Loss: 0.1499396413564682\n",
      "Epoch 1101, Loss: 0.6953473091125488, Final Batch Loss: 0.3569495975971222\n",
      "Epoch 1102, Loss: 0.3986206501722336, Final Batch Loss: 0.09308072924613953\n",
      "Epoch 1103, Loss: 0.65099236369133, Final Batch Loss: 0.29479068517684937\n",
      "Epoch 1104, Loss: 0.5090673118829727, Final Batch Loss: 0.1371879130601883\n",
      "Epoch 1105, Loss: 0.4742468446493149, Final Batch Loss: 0.112330362200737\n",
      "Epoch 1106, Loss: 0.35514920204877853, Final Batch Loss: 0.024283461272716522\n",
      "Epoch 1107, Loss: 0.4725474566221237, Final Batch Loss: 0.152230367064476\n",
      "Epoch 1108, Loss: 0.38730861991643906, Final Batch Loss: 0.048130400478839874\n",
      "Epoch 1109, Loss: 0.6161188185214996, Final Batch Loss: 0.3231203854084015\n",
      "Epoch 1110, Loss: 0.5012722611427307, Final Batch Loss: 0.14880262315273285\n",
      "Epoch 1111, Loss: 0.5023392587900162, Final Batch Loss: 0.14337581396102905\n",
      "Epoch 1112, Loss: 0.41238244622945786, Final Batch Loss: 0.12731491029262543\n",
      "Epoch 1113, Loss: 0.4215686395764351, Final Batch Loss: 0.1461617648601532\n",
      "Epoch 1114, Loss: 0.451979860663414, Final Batch Loss: 0.15701152384281158\n",
      "Epoch 1115, Loss: 0.3784116581082344, Final Batch Loss: 0.07859718054533005\n",
      "Epoch 1116, Loss: 0.6460409611463547, Final Batch Loss: 0.3176470696926117\n",
      "Epoch 1117, Loss: 0.6612726897001266, Final Batch Loss: 0.35705816745758057\n",
      "Epoch 1118, Loss: 0.5695392936468124, Final Batch Loss: 0.22666876018047333\n",
      "Epoch 1119, Loss: 0.49428071081638336, Final Batch Loss: 0.15202181041240692\n",
      "Epoch 1120, Loss: 0.7672227919101715, Final Batch Loss: 0.3945348262786865\n",
      "Epoch 1121, Loss: 0.5266085714101791, Final Batch Loss: 0.16618214547634125\n",
      "Epoch 1122, Loss: 0.494070366024971, Final Batch Loss: 0.14943939447402954\n",
      "Epoch 1123, Loss: 0.5766623765230179, Final Batch Loss: 0.21786384284496307\n",
      "Epoch 1124, Loss: 0.6858625113964081, Final Batch Loss: 0.31491875648498535\n",
      "Epoch 1125, Loss: 0.3406203808262944, Final Batch Loss: 0.009948757477104664\n",
      "Epoch 1126, Loss: 0.3857172206044197, Final Batch Loss: 0.06181322783231735\n",
      "Epoch 1127, Loss: 0.44393330812454224, Final Batch Loss: 0.08138346672058105\n",
      "Epoch 1128, Loss: 0.4586052894592285, Final Batch Loss: 0.13639554381370544\n",
      "Epoch 1129, Loss: 0.468703031539917, Final Batch Loss: 0.17889690399169922\n",
      "Epoch 1130, Loss: 0.40783367305994034, Final Batch Loss: 0.0989256277680397\n",
      "Epoch 1131, Loss: 0.5425916165113449, Final Batch Loss: 0.280455082654953\n",
      "Epoch 1132, Loss: 0.4448312222957611, Final Batch Loss: 0.1747409999370575\n",
      "Epoch 1133, Loss: 0.4216131791472435, Final Batch Loss: 0.120888851583004\n",
      "Epoch 1134, Loss: 0.4883129447698593, Final Batch Loss: 0.1335485428571701\n",
      "Epoch 1135, Loss: 0.7226122170686722, Final Batch Loss: 0.42055216431617737\n",
      "Epoch 1136, Loss: 0.44731050729751587, Final Batch Loss: 0.08380702137947083\n",
      "Epoch 1137, Loss: 0.5332837849855423, Final Batch Loss: 0.1909610480070114\n",
      "Epoch 1138, Loss: 0.8305673748254776, Final Batch Loss: 0.5195021629333496\n",
      "Epoch 1139, Loss: 0.4705282375216484, Final Batch Loss: 0.10808328539133072\n",
      "Epoch 1140, Loss: 0.5294390767812729, Final Batch Loss: 0.16470938920974731\n",
      "Epoch 1141, Loss: 0.5101345032453537, Final Batch Loss: 0.08866675198078156\n",
      "Epoch 1142, Loss: 0.46163172647356987, Final Batch Loss: 0.06034904345870018\n",
      "Epoch 1143, Loss: 0.48607655614614487, Final Batch Loss: 0.1223260834813118\n",
      "Epoch 1144, Loss: 0.4076323062181473, Final Batch Loss: 0.0869133472442627\n",
      "Epoch 1145, Loss: 0.47899696230888367, Final Batch Loss: 0.1404932588338852\n",
      "Epoch 1146, Loss: 0.47587428987026215, Final Batch Loss: 0.16374148428440094\n",
      "Epoch 1147, Loss: 0.48282434046268463, Final Batch Loss: 0.1491754800081253\n",
      "Epoch 1148, Loss: 0.48564116656780243, Final Batch Loss: 0.18006837368011475\n",
      "Epoch 1149, Loss: 0.4271429255604744, Final Batch Loss: 0.09853910654783249\n",
      "Epoch 1150, Loss: 0.482062891125679, Final Batch Loss: 0.10758186876773834\n",
      "Epoch 1151, Loss: 0.39855703711509705, Final Batch Loss: 0.08078563213348389\n",
      "Epoch 1152, Loss: 0.4626794159412384, Final Batch Loss: 0.11240959167480469\n",
      "Epoch 1153, Loss: 0.34246302116662264, Final Batch Loss: 0.008831624872982502\n",
      "Epoch 1154, Loss: 0.5951098948717117, Final Batch Loss: 0.21246318519115448\n",
      "Epoch 1155, Loss: 0.46816111356019974, Final Batch Loss: 0.11476776748895645\n",
      "Epoch 1156, Loss: 0.4464634209871292, Final Batch Loss: 0.07185548543930054\n",
      "Epoch 1157, Loss: 0.4489303380250931, Final Batch Loss: 0.17711453139781952\n",
      "Epoch 1158, Loss: 0.4558722823858261, Final Batch Loss: 0.13415773212909698\n",
      "Epoch 1159, Loss: 0.5490069538354874, Final Batch Loss: 0.19293685257434845\n",
      "Epoch 1160, Loss: 0.5367171913385391, Final Batch Loss: 0.23560623824596405\n",
      "Epoch 1161, Loss: 0.4664442241191864, Final Batch Loss: 0.1363295614719391\n",
      "Epoch 1162, Loss: 0.5649822801351547, Final Batch Loss: 0.2617277503013611\n",
      "Epoch 1163, Loss: 0.5116902142763138, Final Batch Loss: 0.18647873401641846\n",
      "Epoch 1164, Loss: 0.5264901220798492, Final Batch Loss: 0.2239965945482254\n",
      "Epoch 1165, Loss: 0.4862404689192772, Final Batch Loss: 0.1938437968492508\n",
      "Epoch 1166, Loss: 0.4877983331680298, Final Batch Loss: 0.15669454634189606\n",
      "Epoch 1167, Loss: 0.5487922430038452, Final Batch Loss: 0.19504903256893158\n",
      "Epoch 1168, Loss: 0.48471782356500626, Final Batch Loss: 0.18548095226287842\n",
      "Epoch 1169, Loss: 0.39484697580337524, Final Batch Loss: 0.03531448543071747\n",
      "Epoch 1170, Loss: 0.42749179899692535, Final Batch Loss: 0.023662671446800232\n",
      "Epoch 1171, Loss: 0.7713239639997482, Final Batch Loss: 0.40185508131980896\n",
      "Epoch 1172, Loss: 0.9156272113323212, Final Batch Loss: 0.5640314221382141\n",
      "Epoch 1173, Loss: 0.3585350625216961, Final Batch Loss: 0.06039668247103691\n",
      "Epoch 1174, Loss: 0.4072580114006996, Final Batch Loss: 0.05028008669614792\n",
      "Epoch 1175, Loss: 0.5015693679451942, Final Batch Loss: 0.08066823333501816\n",
      "Epoch 1176, Loss: 0.5052572935819626, Final Batch Loss: 0.12520451843738556\n",
      "Epoch 1177, Loss: 0.7128612399101257, Final Batch Loss: 0.3179749548435211\n",
      "Epoch 1178, Loss: 0.47336383908987045, Final Batch Loss: 0.0675901398062706\n",
      "Epoch 1179, Loss: 0.6668316572904587, Final Batch Loss: 0.301644504070282\n",
      "Epoch 1180, Loss: 0.45536165684461594, Final Batch Loss: 0.062153808772563934\n",
      "Epoch 1181, Loss: 0.5189064741134644, Final Batch Loss: 0.13857083022594452\n",
      "Epoch 1182, Loss: 0.5529951602220535, Final Batch Loss: 0.17925262451171875\n",
      "Epoch 1183, Loss: 0.4165406674146652, Final Batch Loss: 0.12008905410766602\n",
      "Epoch 1184, Loss: 0.6009560227394104, Final Batch Loss: 0.24125558137893677\n",
      "Epoch 1185, Loss: 0.4304136708378792, Final Batch Loss: 0.09653063863515854\n",
      "Epoch 1186, Loss: 0.4952368587255478, Final Batch Loss: 0.17443883419036865\n",
      "Epoch 1187, Loss: 0.42573025077581406, Final Batch Loss: 0.07948357611894608\n",
      "Epoch 1188, Loss: 0.4956022650003433, Final Batch Loss: 0.18503881990909576\n",
      "Epoch 1189, Loss: 0.38408301770687103, Final Batch Loss: 0.05848446488380432\n",
      "Epoch 1190, Loss: 0.663828507065773, Final Batch Loss: 0.3839487135410309\n",
      "Epoch 1191, Loss: 0.44109318405389786, Final Batch Loss: 0.12972323596477509\n",
      "Epoch 1192, Loss: 0.4925820082426071, Final Batch Loss: 0.12558993697166443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1193, Loss: 0.7409309446811676, Final Batch Loss: 0.4254687428474426\n",
      "Epoch 1194, Loss: 0.7941604554653168, Final Batch Loss: 0.38300850987434387\n",
      "Epoch 1195, Loss: 0.3256804272532463, Final Batch Loss: 0.038551636040210724\n",
      "Epoch 1196, Loss: 0.48517657816410065, Final Batch Loss: 0.20616909861564636\n",
      "Epoch 1197, Loss: 0.5489679574966431, Final Batch Loss: 0.273308128118515\n",
      "Epoch 1198, Loss: 0.5369016826152802, Final Batch Loss: 0.17854943871498108\n",
      "Epoch 1199, Loss: 0.7963589131832123, Final Batch Loss: 0.40570715069770813\n",
      "Epoch 1200, Loss: 0.8090362697839737, Final Batch Loss: 0.5005072951316833\n",
      "Epoch 1201, Loss: 0.7309677004814148, Final Batch Loss: 0.339976966381073\n",
      "Epoch 1202, Loss: 0.5158857479691505, Final Batch Loss: 0.11011777073144913\n",
      "Epoch 1203, Loss: 0.5705486834049225, Final Batch Loss: 0.1591963768005371\n",
      "Epoch 1204, Loss: 0.6503675431013107, Final Batch Loss: 0.18326808512210846\n",
      "Epoch 1205, Loss: 0.5900999754667282, Final Batch Loss: 0.24392949044704437\n",
      "Epoch 1206, Loss: 0.5514653325080872, Final Batch Loss: 0.1598307341337204\n",
      "Epoch 1207, Loss: 0.6632245481014252, Final Batch Loss: 0.30991509556770325\n",
      "Epoch 1208, Loss: 0.43081362918019295, Final Batch Loss: 0.031395141035318375\n",
      "Epoch 1209, Loss: 0.5289302170276642, Final Batch Loss: 0.14069253206253052\n",
      "Epoch 1210, Loss: 0.6493600755929947, Final Batch Loss: 0.2802070081233978\n",
      "Epoch 1211, Loss: 0.34443045407533646, Final Batch Loss: 0.020225904881954193\n",
      "Epoch 1212, Loss: 0.43124862015247345, Final Batch Loss: 0.0846903920173645\n",
      "Epoch 1213, Loss: 0.4518034905195236, Final Batch Loss: 0.08888489007949829\n",
      "Epoch 1214, Loss: 0.48172447085380554, Final Batch Loss: 0.15775172412395477\n",
      "Epoch 1215, Loss: 0.44709861278533936, Final Batch Loss: 0.13304157555103302\n",
      "Epoch 1216, Loss: 0.4285094067454338, Final Batch Loss: 0.12261448055505753\n",
      "Epoch 1217, Loss: 0.38315385952591896, Final Batch Loss: 0.039823297411203384\n",
      "Epoch 1218, Loss: 0.4645758345723152, Final Batch Loss: 0.10715378075838089\n",
      "Epoch 1219, Loss: 0.39660609886050224, Final Batch Loss: 0.06069546565413475\n",
      "Epoch 1220, Loss: 0.35699567198753357, Final Batch Loss: 0.05275861918926239\n",
      "Epoch 1221, Loss: 0.4023778438568115, Final Batch Loss: 0.07867759466171265\n",
      "Epoch 1222, Loss: 0.4546375870704651, Final Batch Loss: 0.16625384986400604\n",
      "Epoch 1223, Loss: 0.7998691350221634, Final Batch Loss: 0.4937998056411743\n",
      "Epoch 1224, Loss: 0.4486145079135895, Final Batch Loss: 0.11737369000911713\n",
      "Epoch 1225, Loss: 0.4411839619278908, Final Batch Loss: 0.06976474076509476\n",
      "Epoch 1226, Loss: 0.4402812421321869, Final Batch Loss: 0.1371557116508484\n",
      "Epoch 1227, Loss: 0.36498783994466066, Final Batch Loss: 0.012183804996311665\n",
      "Epoch 1228, Loss: 0.4117477759718895, Final Batch Loss: 0.06413235515356064\n",
      "Epoch 1229, Loss: 0.3558771014213562, Final Batch Loss: 0.05572374165058136\n",
      "Epoch 1230, Loss: 0.3578019328415394, Final Batch Loss: 0.042873043566942215\n",
      "Epoch 1231, Loss: 0.48930615186691284, Final Batch Loss: 0.21266493201255798\n",
      "Epoch 1232, Loss: 0.47131460905075073, Final Batch Loss: 0.1598573625087738\n",
      "Epoch 1233, Loss: 0.540266752243042, Final Batch Loss: 0.2089553326368332\n",
      "Epoch 1234, Loss: 0.5783755779266357, Final Batch Loss: 0.21115900576114655\n",
      "Epoch 1235, Loss: 0.8851724565029144, Final Batch Loss: 0.5766614675521851\n",
      "Epoch 1236, Loss: 0.5448893755674362, Final Batch Loss: 0.14216332137584686\n",
      "Epoch 1237, Loss: 0.45296263694763184, Final Batch Loss: 0.14207415282726288\n",
      "Epoch 1238, Loss: 0.41626348346471786, Final Batch Loss: 0.07660958915948868\n",
      "Epoch 1239, Loss: 0.4803966134786606, Final Batch Loss: 0.15811702609062195\n",
      "Epoch 1240, Loss: 0.36464063450694084, Final Batch Loss: 0.05599909648299217\n",
      "Epoch 1241, Loss: 0.3402429632842541, Final Batch Loss: 0.062319885939359665\n",
      "Epoch 1242, Loss: 0.528016984462738, Final Batch Loss: 0.1727544665336609\n",
      "Epoch 1243, Loss: 0.44458287954330444, Final Batch Loss: 0.1226148009300232\n",
      "Epoch 1244, Loss: 0.4703938364982605, Final Batch Loss: 0.1715526580810547\n",
      "Epoch 1245, Loss: 0.5745775476098061, Final Batch Loss: 0.2820625305175781\n",
      "Epoch 1246, Loss: 0.5351428985595703, Final Batch Loss: 0.15203899145126343\n",
      "Epoch 1247, Loss: 0.5482623428106308, Final Batch Loss: 0.20648494362831116\n",
      "Epoch 1248, Loss: 0.5863557606935501, Final Batch Loss: 0.23653389513492584\n",
      "Epoch 1249, Loss: 0.6077202558517456, Final Batch Loss: 0.3045768141746521\n",
      "Epoch 1250, Loss: 0.5712780952453613, Final Batch Loss: 0.24646024405956268\n",
      "Epoch 1251, Loss: 0.4751306474208832, Final Batch Loss: 0.11156176030635834\n",
      "Epoch 1252, Loss: 0.5660357847809792, Final Batch Loss: 0.1089869812130928\n",
      "Epoch 1253, Loss: 0.7527868002653122, Final Batch Loss: 0.357791006565094\n",
      "Epoch 1254, Loss: 0.4717363566160202, Final Batch Loss: 0.09436492621898651\n",
      "Epoch 1255, Loss: 0.6915357261896133, Final Batch Loss: 0.11884969472885132\n",
      "Epoch 1256, Loss: 0.6099792420864105, Final Batch Loss: 0.13710543513298035\n",
      "Epoch 1257, Loss: 0.48382847011089325, Final Batch Loss: 0.06996850669384003\n",
      "Epoch 1258, Loss: 0.49301882833242416, Final Batch Loss: 0.09544951468706131\n",
      "Epoch 1259, Loss: 0.5887702256441116, Final Batch Loss: 0.1830289661884308\n",
      "Epoch 1260, Loss: 0.5772474557161331, Final Batch Loss: 0.12388984858989716\n",
      "Epoch 1261, Loss: 0.4130359813570976, Final Batch Loss: 0.1207757368683815\n",
      "Epoch 1262, Loss: 0.505677193403244, Final Batch Loss: 0.16296163201332092\n",
      "Epoch 1263, Loss: 0.4958457499742508, Final Batch Loss: 0.18589168787002563\n",
      "Epoch 1264, Loss: 0.5088021904230118, Final Batch Loss: 0.22178249061107635\n",
      "Epoch 1265, Loss: 0.4174632802605629, Final Batch Loss: 0.12062489241361618\n",
      "Epoch 1266, Loss: 0.4533334970474243, Final Batch Loss: 0.15332084894180298\n",
      "Epoch 1267, Loss: 0.5350099503993988, Final Batch Loss: 0.1888255625963211\n",
      "Epoch 1268, Loss: 0.6291931644082069, Final Batch Loss: 0.32023119926452637\n",
      "Epoch 1269, Loss: 0.3888702876865864, Final Batch Loss: 0.04357175901532173\n",
      "Epoch 1270, Loss: 0.3463933542370796, Final Batch Loss: 0.044038839638233185\n",
      "Epoch 1271, Loss: 0.5908631309866905, Final Batch Loss: 0.30456089973449707\n",
      "Epoch 1272, Loss: 0.447505384683609, Final Batch Loss: 0.1534247249364853\n",
      "Epoch 1273, Loss: 0.5209988653659821, Final Batch Loss: 0.2181282490491867\n",
      "Epoch 1274, Loss: 0.5264858901500702, Final Batch Loss: 0.1707734316587448\n",
      "Epoch 1275, Loss: 0.3630596175789833, Final Batch Loss: 0.08366773277521133\n",
      "Epoch 1276, Loss: 0.46686800569295883, Final Batch Loss: 0.19560736417770386\n",
      "Epoch 1277, Loss: 0.3423512428998947, Final Batch Loss: 0.035725414752960205\n",
      "Epoch 1278, Loss: 0.34483952820301056, Final Batch Loss: 0.029974937438964844\n",
      "Epoch 1279, Loss: 0.47038426995277405, Final Batch Loss: 0.14834412932395935\n",
      "Epoch 1280, Loss: 0.38729625940322876, Final Batch Loss: 0.07588181644678116\n",
      "Epoch 1281, Loss: 0.48287180066108704, Final Batch Loss: 0.14814405143260956\n",
      "Epoch 1282, Loss: 0.5228798985481262, Final Batch Loss: 0.19384406507015228\n",
      "Epoch 1283, Loss: 0.5358676165342331, Final Batch Loss: 0.2649492025375366\n",
      "Epoch 1284, Loss: 0.4113209769129753, Final Batch Loss: 0.08666252344846725\n",
      "Epoch 1285, Loss: 0.4407230280339718, Final Batch Loss: 0.04315764829516411\n",
      "Epoch 1286, Loss: 0.3409305065870285, Final Batch Loss: 0.08016127347946167\n",
      "Epoch 1287, Loss: 0.5786013752222061, Final Batch Loss: 0.2715974450111389\n",
      "Epoch 1288, Loss: 0.509159117937088, Final Batch Loss: 0.14384101331233978\n",
      "Epoch 1289, Loss: 0.33202784322202206, Final Batch Loss: 0.028004681691527367\n",
      "Epoch 1290, Loss: 0.39289640635252, Final Batch Loss: 0.1016007736325264\n",
      "Epoch 1291, Loss: 0.3827701434493065, Final Batch Loss: 0.06503968685865402\n",
      "Epoch 1292, Loss: 0.5481071323156357, Final Batch Loss: 0.18781153857707977\n",
      "Epoch 1293, Loss: 0.36872731149196625, Final Batch Loss: 0.06929054856300354\n",
      "Epoch 1294, Loss: 0.29010242968797684, Final Batch Loss: 0.033142365515232086\n",
      "Epoch 1295, Loss: 0.4222591742873192, Final Batch Loss: 0.12486755102872849\n",
      "Epoch 1296, Loss: 0.5205223858356476, Final Batch Loss: 0.22149640321731567\n",
      "Epoch 1297, Loss: 0.7221210449934006, Final Batch Loss: 0.42492541670799255\n",
      "Epoch 1298, Loss: 0.3867759183049202, Final Batch Loss: 0.05795153230428696\n",
      "Epoch 1299, Loss: 0.49305640161037445, Final Batch Loss: 0.22266817092895508\n",
      "Epoch 1300, Loss: 0.5412082225084305, Final Batch Loss: 0.22849725186824799\n",
      "Epoch 1301, Loss: 0.4810512438416481, Final Batch Loss: 0.21358364820480347\n",
      "Epoch 1302, Loss: 0.36500441655516624, Final Batch Loss: 0.04686683043837547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1303, Loss: 0.3798900917172432, Final Batch Loss: 0.0853528156876564\n",
      "Epoch 1304, Loss: 0.38073332607746124, Final Batch Loss: 0.08518686890602112\n",
      "Epoch 1305, Loss: 0.5861071050167084, Final Batch Loss: 0.27225592732429504\n",
      "Epoch 1306, Loss: 0.28814989514648914, Final Batch Loss: 0.01918181963264942\n",
      "Epoch 1307, Loss: 0.4101743921637535, Final Batch Loss: 0.0731959119439125\n",
      "Epoch 1308, Loss: 0.3708141855895519, Final Batch Loss: 0.0580536387860775\n",
      "Epoch 1309, Loss: 0.47230320423841476, Final Batch Loss: 0.11785352975130081\n",
      "Epoch 1310, Loss: 0.3107022624462843, Final Batch Loss: 0.018268166109919548\n",
      "Epoch 1311, Loss: 0.5598445385694504, Final Batch Loss: 0.24541674554347992\n",
      "Epoch 1312, Loss: 0.40021462738513947, Final Batch Loss: 0.12764409184455872\n",
      "Epoch 1313, Loss: 0.42916565388441086, Final Batch Loss: 0.1199803575873375\n",
      "Epoch 1314, Loss: 0.42192794382572174, Final Batch Loss: 0.10545660555362701\n",
      "Epoch 1315, Loss: 0.46065187454223633, Final Batch Loss: 0.12234760820865631\n",
      "Epoch 1316, Loss: 0.386495441198349, Final Batch Loss: 0.05861051380634308\n",
      "Epoch 1317, Loss: 0.44059839844703674, Final Batch Loss: 0.1229550689458847\n",
      "Epoch 1318, Loss: 0.5011315494775772, Final Batch Loss: 0.23784120380878448\n",
      "Epoch 1319, Loss: 0.4444016367197037, Final Batch Loss: 0.15697266161441803\n",
      "Epoch 1320, Loss: 0.5303505659103394, Final Batch Loss: 0.24947203695774078\n",
      "Epoch 1321, Loss: 0.38445746526122093, Final Batch Loss: 0.04195183143019676\n",
      "Epoch 1322, Loss: 0.3789992779493332, Final Batch Loss: 0.09672024846076965\n",
      "Epoch 1323, Loss: 0.47775454819202423, Final Batch Loss: 0.18042148649692535\n",
      "Epoch 1324, Loss: 0.7514048665761948, Final Batch Loss: 0.4499184489250183\n",
      "Epoch 1325, Loss: 0.6948362663388252, Final Batch Loss: 0.38526254892349243\n",
      "Epoch 1326, Loss: 0.42267293483018875, Final Batch Loss: 0.1557343453168869\n",
      "Epoch 1327, Loss: 0.4086095988750458, Final Batch Loss: 0.09900417923927307\n",
      "Epoch 1328, Loss: 0.3919871896505356, Final Batch Loss: 0.09024759382009506\n",
      "Epoch 1329, Loss: 0.37194813042879105, Final Batch Loss: 0.07835746556520462\n",
      "Epoch 1330, Loss: 0.2775528058409691, Final Batch Loss: 0.04169759154319763\n",
      "Epoch 1331, Loss: 0.4279150813817978, Final Batch Loss: 0.12652944028377533\n",
      "Epoch 1332, Loss: 0.44845691323280334, Final Batch Loss: 0.15265627205371857\n",
      "Epoch 1333, Loss: 0.4125765413045883, Final Batch Loss: 0.11753832548856735\n",
      "Epoch 1334, Loss: 0.47915439307689667, Final Batch Loss: 0.17661871016025543\n",
      "Epoch 1335, Loss: 0.4072669520974159, Final Batch Loss: 0.09544871002435684\n",
      "Epoch 1336, Loss: 0.4589899554848671, Final Batch Loss: 0.12235381454229355\n",
      "Epoch 1337, Loss: 0.41088204830884933, Final Batch Loss: 0.11691699177026749\n",
      "Epoch 1338, Loss: 0.45523497462272644, Final Batch Loss: 0.18105220794677734\n",
      "Epoch 1339, Loss: 0.419380322098732, Final Batch Loss: 0.15278774499893188\n",
      "Epoch 1340, Loss: 0.4683119207620621, Final Batch Loss: 0.15779508650302887\n",
      "Epoch 1341, Loss: 0.39362916350364685, Final Batch Loss: 0.1189420074224472\n",
      "Epoch 1342, Loss: 0.425067275762558, Final Batch Loss: 0.15850535035133362\n",
      "Epoch 1343, Loss: 0.4145700931549072, Final Batch Loss: 0.07734465599060059\n",
      "Epoch 1344, Loss: 0.334447905421257, Final Batch Loss: 0.07483404874801636\n",
      "Epoch 1345, Loss: 0.3770366534590721, Final Batch Loss: 0.08353077620267868\n",
      "Epoch 1346, Loss: 0.3354382887482643, Final Batch Loss: 0.05836932361125946\n",
      "Epoch 1347, Loss: 0.37169502675533295, Final Batch Loss: 0.09664158523082733\n",
      "Epoch 1348, Loss: 0.3884008228778839, Final Batch Loss: 0.09632213413715363\n",
      "Epoch 1349, Loss: 0.577278696000576, Final Batch Loss: 0.30694523453712463\n",
      "Epoch 1350, Loss: 0.44766049087047577, Final Batch Loss: 0.19207781553268433\n",
      "Epoch 1351, Loss: 0.48407014459371567, Final Batch Loss: 0.22379904985427856\n",
      "Epoch 1352, Loss: 0.3990468755364418, Final Batch Loss: 0.06821665912866592\n",
      "Epoch 1353, Loss: 0.3742302432656288, Final Batch Loss: 0.1107340082526207\n",
      "Epoch 1354, Loss: 0.3055444620549679, Final Batch Loss: 0.024894874542951584\n",
      "Epoch 1355, Loss: 0.3307303683832288, Final Batch Loss: 0.008030776865780354\n",
      "Epoch 1356, Loss: 0.374071903526783, Final Batch Loss: 0.08802054077386856\n",
      "Epoch 1357, Loss: 0.5118871331214905, Final Batch Loss: 0.21375887095928192\n",
      "Epoch 1358, Loss: 0.47739720344543457, Final Batch Loss: 0.16081970930099487\n",
      "Epoch 1359, Loss: 0.41252636909484863, Final Batch Loss: 0.11972181499004364\n",
      "Epoch 1360, Loss: 0.5137060880661011, Final Batch Loss: 0.1829632669687271\n",
      "Epoch 1361, Loss: 0.3024719301611185, Final Batch Loss: 0.025000566616654396\n",
      "Epoch 1362, Loss: 0.6277274042367935, Final Batch Loss: 0.32236170768737793\n",
      "Epoch 1363, Loss: 0.46592600643634796, Final Batch Loss: 0.10116840898990631\n",
      "Epoch 1364, Loss: 0.5854819566011429, Final Batch Loss: 0.2700362801551819\n",
      "Epoch 1365, Loss: 0.5090595781803131, Final Batch Loss: 0.24765567481517792\n",
      "Epoch 1366, Loss: 0.45647338777780533, Final Batch Loss: 0.12453917413949966\n",
      "Epoch 1367, Loss: 0.4146498441696167, Final Batch Loss: 0.1216331422328949\n",
      "Epoch 1368, Loss: 0.3527309000492096, Final Batch Loss: 0.06806224584579468\n",
      "Epoch 1369, Loss: 0.4263603240251541, Final Batch Loss: 0.1422916054725647\n",
      "Epoch 1370, Loss: 0.4809894412755966, Final Batch Loss: 0.17509956657886505\n",
      "Epoch 1371, Loss: 0.27635935321450233, Final Batch Loss: 0.04085275158286095\n",
      "Epoch 1372, Loss: 0.39758285135030746, Final Batch Loss: 0.1174662634730339\n",
      "Epoch 1373, Loss: 0.390494704246521, Final Batch Loss: 0.0910191535949707\n",
      "Epoch 1374, Loss: 0.4243771657347679, Final Batch Loss: 0.10809297114610672\n",
      "Epoch 1375, Loss: 0.31844980269670486, Final Batch Loss: 0.0273691788315773\n",
      "Epoch 1376, Loss: 0.4847676455974579, Final Batch Loss: 0.17049770057201385\n",
      "Epoch 1377, Loss: 0.2549987267702818, Final Batch Loss: 0.02880554459989071\n",
      "Epoch 1378, Loss: 0.3660532981157303, Final Batch Loss: 0.10578850656747818\n",
      "Epoch 1379, Loss: 0.41531041264533997, Final Batch Loss: 0.15126876533031464\n",
      "Epoch 1380, Loss: 0.4216039925813675, Final Batch Loss: 0.13177365064620972\n",
      "Epoch 1381, Loss: 0.4697270691394806, Final Batch Loss: 0.21953366696834564\n",
      "Epoch 1382, Loss: 0.3514269758015871, Final Batch Loss: 0.02181442268192768\n",
      "Epoch 1383, Loss: 0.5233090817928314, Final Batch Loss: 0.2192208617925644\n",
      "Epoch 1384, Loss: 0.4592496007680893, Final Batch Loss: 0.17562787234783173\n",
      "Epoch 1385, Loss: 0.3643724322319031, Final Batch Loss: 0.018738165497779846\n",
      "Epoch 1386, Loss: 0.34148629382252693, Final Batch Loss: 0.049879226833581924\n",
      "Epoch 1387, Loss: 0.4117198958992958, Final Batch Loss: 0.1163615956902504\n",
      "Epoch 1388, Loss: 0.4269907847046852, Final Batch Loss: 0.12183811515569687\n",
      "Epoch 1389, Loss: 0.4494170844554901, Final Batch Loss: 0.15752720832824707\n",
      "Epoch 1390, Loss: 0.344856895506382, Final Batch Loss: 0.07113324850797653\n",
      "Epoch 1391, Loss: 0.37564682215452194, Final Batch Loss: 0.10609560459852219\n",
      "Epoch 1392, Loss: 0.4872288703918457, Final Batch Loss: 0.16800177097320557\n",
      "Epoch 1393, Loss: 0.5465075373649597, Final Batch Loss: 0.23821023106575012\n",
      "Epoch 1394, Loss: 0.39868932217359543, Final Batch Loss: 0.11133634299039841\n",
      "Epoch 1395, Loss: 0.4967358335852623, Final Batch Loss: 0.24946080148220062\n",
      "Epoch 1396, Loss: 0.376885287463665, Final Batch Loss: 0.12878166139125824\n",
      "Epoch 1397, Loss: 0.4317493438720703, Final Batch Loss: 0.1270206719636917\n",
      "Epoch 1398, Loss: 0.3784824013710022, Final Batch Loss: 0.07029461860656738\n",
      "Epoch 1399, Loss: 0.29268191009759903, Final Batch Loss: 0.04884670674800873\n",
      "Epoch 1400, Loss: 0.37457404285669327, Final Batch Loss: 0.06655047088861465\n",
      "Epoch 1401, Loss: 0.37713848054409027, Final Batch Loss: 0.1132020577788353\n",
      "Epoch 1402, Loss: 0.4556574821472168, Final Batch Loss: 0.13690797984600067\n",
      "Epoch 1403, Loss: 0.3705141395330429, Final Batch Loss: 0.08432817459106445\n",
      "Epoch 1404, Loss: 0.5003376752138138, Final Batch Loss: 0.19759643077850342\n",
      "Epoch 1405, Loss: 0.44998598098754883, Final Batch Loss: 0.15304136276245117\n",
      "Epoch 1406, Loss: 0.33638836443424225, Final Batch Loss: 0.08667252957820892\n",
      "Epoch 1407, Loss: 0.39940229058265686, Final Batch Loss: 0.16230091452598572\n",
      "Epoch 1408, Loss: 0.3773699998855591, Final Batch Loss: 0.11636239290237427\n",
      "Epoch 1409, Loss: 0.25941091403365135, Final Batch Loss: 0.019417401403188705\n",
      "Epoch 1410, Loss: 0.5424842908978462, Final Batch Loss: 0.20573650300502777\n",
      "Epoch 1411, Loss: 0.3062761966139078, Final Batch Loss: 0.027620503678917885\n",
      "Epoch 1412, Loss: 0.588879182934761, Final Batch Loss: 0.2798515856266022\n",
      "Epoch 1413, Loss: 0.35847151279449463, Final Batch Loss: 0.10432928055524826\n",
      "Epoch 1414, Loss: 0.36374638974666595, Final Batch Loss: 0.08490677922964096\n",
      "Epoch 1415, Loss: 0.507191613316536, Final Batch Loss: 0.16281349956989288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1416, Loss: 0.5614662021398544, Final Batch Loss: 0.16494271159172058\n",
      "Epoch 1417, Loss: 0.5174801126122475, Final Batch Loss: 0.12400440126657486\n",
      "Epoch 1418, Loss: 0.38919420540332794, Final Batch Loss: 0.12350260466337204\n",
      "Epoch 1419, Loss: 0.3300846070051193, Final Batch Loss: 0.034529849886894226\n",
      "Epoch 1420, Loss: 0.3837101571261883, Final Batch Loss: 0.05387907847762108\n",
      "Epoch 1421, Loss: 0.4468386769294739, Final Batch Loss: 0.18794919550418854\n",
      "Epoch 1422, Loss: 0.39093995839357376, Final Batch Loss: 0.12330663949251175\n",
      "Epoch 1423, Loss: 0.3941180408000946, Final Batch Loss: 0.11847130954265594\n",
      "Epoch 1424, Loss: 0.2968521825969219, Final Batch Loss: 0.02635544165968895\n",
      "Epoch 1425, Loss: 0.332226175814867, Final Batch Loss: 0.051367152482271194\n",
      "Epoch 1426, Loss: 0.45041242241859436, Final Batch Loss: 0.13154523074626923\n",
      "Epoch 1427, Loss: 0.4376153200864792, Final Batch Loss: 0.17879891395568848\n",
      "Epoch 1428, Loss: 0.3651576265692711, Final Batch Loss: 0.11746007204055786\n",
      "Epoch 1429, Loss: 0.4074796140193939, Final Batch Loss: 0.12455558776855469\n",
      "Epoch 1430, Loss: 0.45702603459358215, Final Batch Loss: 0.11628144979476929\n",
      "Epoch 1431, Loss: 0.44537321478128433, Final Batch Loss: 0.18834319710731506\n",
      "Epoch 1432, Loss: 0.42961813509464264, Final Batch Loss: 0.10915583372116089\n",
      "Epoch 1433, Loss: 0.43858280777931213, Final Batch Loss: 0.19382618367671967\n",
      "Epoch 1434, Loss: 0.511655643582344, Final Batch Loss: 0.23852479457855225\n",
      "Epoch 1435, Loss: 0.42837242782115936, Final Batch Loss: 0.17836140096187592\n",
      "Epoch 1436, Loss: 0.27619678527116776, Final Batch Loss: 0.05392702668905258\n",
      "Epoch 1437, Loss: 0.35945209115743637, Final Batch Loss: 0.07340312749147415\n",
      "Epoch 1438, Loss: 0.5483300909399986, Final Batch Loss: 0.2187977284193039\n",
      "Epoch 1439, Loss: 0.3065780997276306, Final Batch Loss: 0.04085012525320053\n",
      "Epoch 1440, Loss: 0.43490926176309586, Final Batch Loss: 0.1714499145746231\n",
      "Epoch 1441, Loss: 0.5229837149381638, Final Batch Loss: 0.20986685156822205\n",
      "Epoch 1442, Loss: 0.42204393446445465, Final Batch Loss: 0.1653149425983429\n",
      "Epoch 1443, Loss: 0.4776965379714966, Final Batch Loss: 0.19671125710010529\n",
      "Epoch 1444, Loss: 0.3857123553752899, Final Batch Loss: 0.13441775739192963\n",
      "Epoch 1445, Loss: 0.4978116750717163, Final Batch Loss: 0.21520394086837769\n",
      "Epoch 1446, Loss: 0.3168630376458168, Final Batch Loss: 0.05492185801267624\n",
      "Epoch 1447, Loss: 0.32375313341617584, Final Batch Loss: 0.03877998888492584\n",
      "Epoch 1448, Loss: 0.4153467267751694, Final Batch Loss: 0.099236398935318\n",
      "Epoch 1449, Loss: 0.4578229933977127, Final Batch Loss: 0.17456765472888947\n",
      "Epoch 1450, Loss: 0.5504210144281387, Final Batch Loss: 0.2570168077945709\n",
      "Epoch 1451, Loss: 0.501415453851223, Final Batch Loss: 0.2279890924692154\n",
      "Epoch 1452, Loss: 0.3798450231552124, Final Batch Loss: 0.11334098130464554\n",
      "Epoch 1453, Loss: 0.3932732343673706, Final Batch Loss: 0.14054422080516815\n",
      "Epoch 1454, Loss: 0.39307430386543274, Final Batch Loss: 0.15287694334983826\n",
      "Epoch 1455, Loss: 0.5688496381044388, Final Batch Loss: 0.33036619424819946\n",
      "Epoch 1456, Loss: 0.3823365494608879, Final Batch Loss: 0.10990775376558304\n",
      "Epoch 1457, Loss: 0.5326867029070854, Final Batch Loss: 0.258871465921402\n",
      "Epoch 1458, Loss: 0.4258817210793495, Final Batch Loss: 0.11331024020910263\n",
      "Epoch 1459, Loss: 0.5318874344229698, Final Batch Loss: 0.2853245437145233\n",
      "Epoch 1460, Loss: 0.4014260843396187, Final Batch Loss: 0.10859517008066177\n",
      "Epoch 1461, Loss: 0.37054650485515594, Final Batch Loss: 0.14627601206302643\n",
      "Epoch 1462, Loss: 0.5299157127737999, Final Batch Loss: 0.27130308747291565\n",
      "Epoch 1463, Loss: 0.4359479993581772, Final Batch Loss: 0.16858112812042236\n",
      "Epoch 1464, Loss: 0.3254955932497978, Final Batch Loss: 0.0741288810968399\n",
      "Epoch 1465, Loss: 0.3520258218050003, Final Batch Loss: 0.08505834639072418\n",
      "Epoch 1466, Loss: 0.5632659569382668, Final Batch Loss: 0.24491393566131592\n",
      "Epoch 1467, Loss: 0.4647294282913208, Final Batch Loss: 0.18388505280017853\n",
      "Epoch 1468, Loss: 0.36752527952194214, Final Batch Loss: 0.1275796890258789\n",
      "Epoch 1469, Loss: 0.3672030344605446, Final Batch Loss: 0.08284690231084824\n",
      "Epoch 1470, Loss: 0.577302098274231, Final Batch Loss: 0.310884565114975\n",
      "Epoch 1471, Loss: 0.6649073511362076, Final Batch Loss: 0.3871861696243286\n",
      "Epoch 1472, Loss: 0.39303652942180634, Final Batch Loss: 0.10661450028419495\n",
      "Epoch 1473, Loss: 0.3413192704319954, Final Batch Loss: 0.08029308915138245\n",
      "Epoch 1474, Loss: 0.28857592958956957, Final Batch Loss: 0.011596512980759144\n",
      "Epoch 1475, Loss: 0.3949689045548439, Final Batch Loss: 0.09334511309862137\n",
      "Epoch 1476, Loss: 0.4013441503047943, Final Batch Loss: 0.07605433464050293\n",
      "Epoch 1477, Loss: 0.5791802331805229, Final Batch Loss: 0.2769651710987091\n",
      "Epoch 1478, Loss: 0.3972817286849022, Final Batch Loss: 0.06268232315778732\n",
      "Epoch 1479, Loss: 0.34042702801525593, Final Batch Loss: 0.012742208316922188\n",
      "Epoch 1480, Loss: 0.3446614667773247, Final Batch Loss: 0.05586286634206772\n",
      "Epoch 1481, Loss: 0.435753270983696, Final Batch Loss: 0.13640685379505157\n",
      "Epoch 1482, Loss: 0.46718912571668625, Final Batch Loss: 0.22834481298923492\n",
      "Epoch 1483, Loss: 0.3611454889178276, Final Batch Loss: 0.05392228811979294\n",
      "Epoch 1484, Loss: 0.33990953862667084, Final Batch Loss: 0.034910768270492554\n",
      "Epoch 1485, Loss: 0.28670690953731537, Final Batch Loss: 0.024558082222938538\n",
      "Epoch 1486, Loss: 0.4773062616586685, Final Batch Loss: 0.15901625156402588\n",
      "Epoch 1487, Loss: 0.3544364795088768, Final Batch Loss: 0.08761254698038101\n",
      "Epoch 1488, Loss: 0.4224820211529732, Final Batch Loss: 0.1948011815547943\n",
      "Epoch 1489, Loss: 0.32844091206789017, Final Batch Loss: 0.06480767577886581\n",
      "Epoch 1490, Loss: 0.36253081262111664, Final Batch Loss: 0.1023288443684578\n",
      "Epoch 1491, Loss: 0.3154594376683235, Final Batch Loss: 0.046529293060302734\n",
      "Epoch 1492, Loss: 0.34266144037246704, Final Batch Loss: 0.0726112574338913\n",
      "Epoch 1493, Loss: 0.33671193569898605, Final Batch Loss: 0.11102660000324249\n",
      "Epoch 1494, Loss: 0.29022909328341484, Final Batch Loss: 0.051134590059518814\n",
      "Epoch 1495, Loss: 0.26807647943496704, Final Batch Loss: 0.05511964112520218\n",
      "Epoch 1496, Loss: 0.3862270936369896, Final Batch Loss: 0.14516682922840118\n",
      "Epoch 1497, Loss: 0.3845165893435478, Final Batch Loss: 0.10970267653465271\n",
      "Epoch 1498, Loss: 0.41744697093963623, Final Batch Loss: 0.18486085534095764\n",
      "Epoch 1499, Loss: 0.2628225740045309, Final Batch Loss: 0.01354956440627575\n",
      "Epoch 1500, Loss: 0.29975277930498123, Final Batch Loss: 0.060521043837070465\n",
      "Epoch 1501, Loss: 0.41693032532930374, Final Batch Loss: 0.1008450835943222\n",
      "Epoch 1502, Loss: 0.4636678695678711, Final Batch Loss: 0.19751150906085968\n",
      "Epoch 1503, Loss: 0.31646034866571426, Final Batch Loss: 0.03391408175230026\n",
      "Epoch 1504, Loss: 0.8147713094949722, Final Batch Loss: 0.3494511544704437\n",
      "Epoch 1505, Loss: 0.33954015257768333, Final Batch Loss: 0.0023720699828118086\n",
      "Epoch 1506, Loss: 0.6626782119274139, Final Batch Loss: 0.04994717240333557\n",
      "Epoch 1507, Loss: 0.6455442607402802, Final Batch Loss: 0.18786410987377167\n",
      "Epoch 1508, Loss: 0.525210052728653, Final Batch Loss: 0.10044169425964355\n",
      "Epoch 1509, Loss: 0.5190049558877945, Final Batch Loss: 0.11315672099590302\n",
      "Epoch 1510, Loss: 0.44246190786361694, Final Batch Loss: 0.09145569801330566\n",
      "Epoch 1511, Loss: 0.370286563411355, Final Batch Loss: 0.02223358489573002\n",
      "Epoch 1512, Loss: 0.5575754046440125, Final Batch Loss: 0.15904977917671204\n",
      "Epoch 1513, Loss: 0.4053371027112007, Final Batch Loss: 0.10808568447828293\n",
      "Epoch 1514, Loss: 0.40634823590517044, Final Batch Loss: 0.08136966079473495\n",
      "Epoch 1515, Loss: 0.36708521842956543, Final Batch Loss: 0.10008744150400162\n",
      "Epoch 1516, Loss: 0.4449470490217209, Final Batch Loss: 0.13754287362098694\n",
      "Epoch 1517, Loss: 0.4023030698299408, Final Batch Loss: 0.14405785501003265\n",
      "Epoch 1518, Loss: 0.7655819207429886, Final Batch Loss: 0.511056661605835\n",
      "Epoch 1519, Loss: 0.6028621196746826, Final Batch Loss: 0.3081773519515991\n",
      "Epoch 1520, Loss: 0.4626568630337715, Final Batch Loss: 0.12355317920446396\n",
      "Epoch 1521, Loss: 0.3940855823457241, Final Batch Loss: 0.05384248122572899\n",
      "Epoch 1522, Loss: 0.4504140466451645, Final Batch Loss: 0.1336153745651245\n",
      "Epoch 1523, Loss: 0.5020832866430283, Final Batch Loss: 0.18181122839450836\n",
      "Epoch 1524, Loss: 0.40212638676166534, Final Batch Loss: 0.1544337123632431\n",
      "Epoch 1525, Loss: 0.4607291892170906, Final Batch Loss: 0.18218287825584412\n",
      "Epoch 1526, Loss: 0.40574657917022705, Final Batch Loss: 0.1147368848323822\n",
      "Epoch 1527, Loss: 0.5772561505436897, Final Batch Loss: 0.25998350977897644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1528, Loss: 0.4017394557595253, Final Batch Loss: 0.11449155956506729\n",
      "Epoch 1529, Loss: 0.5583004206418991, Final Batch Loss: 0.12635838985443115\n",
      "Epoch 1530, Loss: 0.4587477743625641, Final Batch Loss: 0.13160540163516998\n",
      "Epoch 1531, Loss: 0.35038020461797714, Final Batch Loss: 0.049974121153354645\n",
      "Epoch 1532, Loss: 0.31510185450315475, Final Batch Loss: 0.03702381253242493\n",
      "Epoch 1533, Loss: 0.3427407443523407, Final Batch Loss: 0.08128124475479126\n",
      "Epoch 1534, Loss: 0.38659494183957577, Final Batch Loss: 0.02828202210366726\n",
      "Epoch 1535, Loss: 0.3705604523420334, Final Batch Loss: 0.028172895312309265\n",
      "Epoch 1536, Loss: 0.42890946567058563, Final Batch Loss: 0.1669957935810089\n",
      "Epoch 1537, Loss: 0.2933811694383621, Final Batch Loss: 0.047380298376083374\n",
      "Epoch 1538, Loss: 0.3828418105840683, Final Batch Loss: 0.11148342490196228\n",
      "Epoch 1539, Loss: 0.33176466822624207, Final Batch Loss: 0.041829913854599\n",
      "Epoch 1540, Loss: 0.2811394650489092, Final Batch Loss: 0.02041909284889698\n",
      "Epoch 1541, Loss: 0.28816622123122215, Final Batch Loss: 0.04716021940112114\n",
      "Epoch 1542, Loss: 0.28168507758527994, Final Batch Loss: 0.01432537380605936\n",
      "Epoch 1543, Loss: 0.32052651047706604, Final Batch Loss: 0.059920474886894226\n",
      "Epoch 1544, Loss: 0.3794717341661453, Final Batch Loss: 0.09545574337244034\n",
      "Epoch 1545, Loss: 0.3396064266562462, Final Batch Loss: 0.10960499942302704\n",
      "Epoch 1546, Loss: 0.36882416158914566, Final Batch Loss: 0.15578509867191315\n",
      "Epoch 1547, Loss: 0.3655497506260872, Final Batch Loss: 0.10685306787490845\n",
      "Epoch 1548, Loss: 0.4261915013194084, Final Batch Loss: 0.1226624920964241\n",
      "Epoch 1549, Loss: 0.3969186544418335, Final Batch Loss: 0.13361519575119019\n",
      "Epoch 1550, Loss: 0.4550141841173172, Final Batch Loss: 0.16642071306705475\n",
      "Epoch 1551, Loss: 0.3258116692304611, Final Batch Loss: 0.10437691956758499\n",
      "Epoch 1552, Loss: 0.5093573331832886, Final Batch Loss: 0.25282609462738037\n",
      "Epoch 1553, Loss: 0.38659272342920303, Final Batch Loss: 0.16367921233177185\n",
      "Epoch 1554, Loss: 0.4774148166179657, Final Batch Loss: 0.13762439787387848\n",
      "Epoch 1555, Loss: 0.43337418884038925, Final Batch Loss: 0.1583835631608963\n",
      "Epoch 1556, Loss: 0.5127137303352356, Final Batch Loss: 0.16041149199008942\n",
      "Epoch 1557, Loss: 0.4428033083677292, Final Batch Loss: 0.18671274185180664\n",
      "Epoch 1558, Loss: 0.38891715556383133, Final Batch Loss: 0.10551656037569046\n",
      "Epoch 1559, Loss: 0.4509933441877365, Final Batch Loss: 0.16285748779773712\n",
      "Epoch 1560, Loss: 0.3925846070051193, Final Batch Loss: 0.08072122931480408\n",
      "Epoch 1561, Loss: 0.30663125216960907, Final Batch Loss: 0.06745980679988861\n",
      "Epoch 1562, Loss: 0.3329925052821636, Final Batch Loss: 0.03888927027583122\n",
      "Epoch 1563, Loss: 0.8043700307607651, Final Batch Loss: 0.5103956460952759\n",
      "Epoch 1564, Loss: 0.3734772875905037, Final Batch Loss: 0.05919512361288071\n",
      "Epoch 1565, Loss: 0.47815108858048916, Final Batch Loss: 0.026387741789221764\n",
      "Epoch 1566, Loss: 0.74917171895504, Final Batch Loss: 0.25860580801963806\n",
      "Epoch 1567, Loss: 0.5123708993196487, Final Batch Loss: 0.18997442722320557\n",
      "Epoch 1568, Loss: 0.36939227022230625, Final Batch Loss: 0.02063884772360325\n",
      "Epoch 1569, Loss: 0.49898776412010193, Final Batch Loss: 0.17025159299373627\n",
      "Epoch 1570, Loss: 0.4381756857037544, Final Batch Loss: 0.1174582913517952\n",
      "Epoch 1571, Loss: 0.3582313507795334, Final Batch Loss: 0.09828967601060867\n",
      "Epoch 1572, Loss: 0.4345377907156944, Final Batch Loss: 0.10321802645921707\n",
      "Epoch 1573, Loss: 0.45629608631134033, Final Batch Loss: 0.12920714914798737\n",
      "Epoch 1574, Loss: 0.327708475291729, Final Batch Loss: 0.09585893899202347\n",
      "Epoch 1575, Loss: 0.4171755090355873, Final Batch Loss: 0.10869292169809341\n",
      "Epoch 1576, Loss: 0.4056221693754196, Final Batch Loss: 0.1482260674238205\n",
      "Epoch 1577, Loss: 0.288445383310318, Final Batch Loss: 0.06605195999145508\n",
      "Epoch 1578, Loss: 0.31712503358721733, Final Batch Loss: 0.046896737068891525\n",
      "Epoch 1579, Loss: 0.39644064009189606, Final Batch Loss: 0.05729691684246063\n",
      "Epoch 1580, Loss: 0.33659958839416504, Final Batch Loss: 0.046653181314468384\n",
      "Epoch 1581, Loss: 0.41747040301561356, Final Batch Loss: 0.17707256972789764\n",
      "Epoch 1582, Loss: 0.393376961350441, Final Batch Loss: 0.14209313690662384\n",
      "Epoch 1583, Loss: 0.2268490083515644, Final Batch Loss: 0.005291912704706192\n",
      "Epoch 1584, Loss: 0.25877221301198006, Final Batch Loss: 0.03048473224043846\n",
      "Epoch 1585, Loss: 0.304795578122139, Final Batch Loss: 0.05842328816652298\n",
      "Epoch 1586, Loss: 0.2885090671479702, Final Batch Loss: 0.03786638006567955\n",
      "Epoch 1587, Loss: 0.49139152467250824, Final Batch Loss: 0.22807319462299347\n",
      "Epoch 1588, Loss: 0.39793121814727783, Final Batch Loss: 0.19309763610363007\n",
      "Epoch 1589, Loss: 0.30355093255639076, Final Batch Loss: 0.050819698721170425\n",
      "Epoch 1590, Loss: 0.2882615439593792, Final Batch Loss: 0.05420665815472603\n",
      "Epoch 1591, Loss: 0.4366031214594841, Final Batch Loss: 0.1488172858953476\n",
      "Epoch 1592, Loss: 0.38710732758045197, Final Batch Loss: 0.14854055643081665\n",
      "Epoch 1593, Loss: 0.38596808165311813, Final Batch Loss: 0.09023343771696091\n",
      "Epoch 1594, Loss: 0.4395079165697098, Final Batch Loss: 0.20474117994308472\n",
      "Epoch 1595, Loss: 0.3790496364235878, Final Batch Loss: 0.11162407696247101\n",
      "Epoch 1596, Loss: 0.40053513646125793, Final Batch Loss: 0.14301933348178864\n",
      "Epoch 1597, Loss: 0.35488515347242355, Final Batch Loss: 0.12652577459812164\n",
      "Epoch 1598, Loss: 0.256131861358881, Final Batch Loss: 0.020028408616781235\n",
      "Epoch 1599, Loss: 0.32001008465886116, Final Batch Loss: 0.03817733749747276\n",
      "Epoch 1600, Loss: 0.24045146256685257, Final Batch Loss: 0.042607590556144714\n",
      "Epoch 1601, Loss: 0.42149344086647034, Final Batch Loss: 0.19306789338588715\n",
      "Epoch 1602, Loss: 0.34409360587596893, Final Batch Loss: 0.10199404507875443\n",
      "Epoch 1603, Loss: 0.3998056873679161, Final Batch Loss: 0.06890460103750229\n",
      "Epoch 1604, Loss: 0.4384317845106125, Final Batch Loss: 0.10138478875160217\n",
      "Epoch 1605, Loss: 0.46178264170885086, Final Batch Loss: 0.1820032000541687\n",
      "Epoch 1606, Loss: 0.42940109968185425, Final Batch Loss: 0.18803486227989197\n",
      "Epoch 1607, Loss: 0.44267497956752777, Final Batch Loss: 0.19207505881786346\n",
      "Epoch 1608, Loss: 0.4168327562510967, Final Batch Loss: 0.03171401843428612\n",
      "Epoch 1609, Loss: 0.8984846323728561, Final Batch Loss: 0.5077289938926697\n",
      "Epoch 1610, Loss: 0.4184727147221565, Final Batch Loss: 0.06439419835805893\n",
      "Epoch 1611, Loss: 0.5455038845539093, Final Batch Loss: 0.17500385642051697\n",
      "Epoch 1612, Loss: 0.6119199246168137, Final Batch Loss: 0.16706621646881104\n",
      "Epoch 1613, Loss: 0.3857446759939194, Final Batch Loss: 0.05152997374534607\n",
      "Epoch 1614, Loss: 0.5838169753551483, Final Batch Loss: 0.18476086854934692\n",
      "Epoch 1615, Loss: 0.5238078832626343, Final Batch Loss: 0.1759861409664154\n",
      "Epoch 1616, Loss: 0.5269688591361046, Final Batch Loss: 0.26083579659461975\n",
      "Epoch 1617, Loss: 0.5229976624250412, Final Batch Loss: 0.26948702335357666\n",
      "Epoch 1618, Loss: 0.3554377779364586, Final Batch Loss: 0.07476406544446945\n",
      "Epoch 1619, Loss: 0.5070242956280708, Final Batch Loss: 0.2202635109424591\n",
      "Epoch 1620, Loss: 0.4829866290092468, Final Batch Loss: 0.20554576814174652\n",
      "Epoch 1621, Loss: 0.42584193497896194, Final Batch Loss: 0.11158930510282516\n",
      "Epoch 1622, Loss: 0.3880240395665169, Final Batch Loss: 0.11181125044822693\n",
      "Epoch 1623, Loss: 0.34596458822488785, Final Batch Loss: 0.07843498140573502\n",
      "Epoch 1624, Loss: 0.3759819269180298, Final Batch Loss: 0.06763321906328201\n",
      "Epoch 1625, Loss: 0.4632248729467392, Final Batch Loss: 0.08844469487667084\n",
      "Epoch 1626, Loss: 0.3596024066209793, Final Batch Loss: 0.06313203275203705\n",
      "Epoch 1627, Loss: 0.46450281143188477, Final Batch Loss: 0.15736739337444305\n",
      "Epoch 1628, Loss: 0.4582037180662155, Final Batch Loss: 0.14152085781097412\n",
      "Epoch 1629, Loss: 0.25923729315400124, Final Batch Loss: 0.04128110036253929\n",
      "Epoch 1630, Loss: 0.3134434688836336, Final Batch Loss: 0.011724846437573433\n",
      "Epoch 1631, Loss: 0.51993328332901, Final Batch Loss: 0.14944161474704742\n",
      "Epoch 1632, Loss: 0.42022790014743805, Final Batch Loss: 0.12851785123348236\n",
      "Epoch 1633, Loss: 0.3807512894272804, Final Batch Loss: 0.13315017521381378\n",
      "Epoch 1634, Loss: 0.5359816551208496, Final Batch Loss: 0.22717717289924622\n",
      "Epoch 1635, Loss: 0.4499596655368805, Final Batch Loss: 0.12521731853485107\n",
      "Epoch 1636, Loss: 0.41706258058547974, Final Batch Loss: 0.11181189119815826\n",
      "Epoch 1637, Loss: 0.4344869703054428, Final Batch Loss: 0.14204713702201843\n",
      "Epoch 1638, Loss: 0.5023527592420578, Final Batch Loss: 0.20134642720222473\n",
      "Epoch 1639, Loss: 0.4331808090209961, Final Batch Loss: 0.1864437460899353\n",
      "Epoch 1640, Loss: 0.5518778637051582, Final Batch Loss: 0.287088543176651\n",
      "Epoch 1641, Loss: 0.3899030014872551, Final Batch Loss: 0.16377829015254974\n",
      "Epoch 1642, Loss: 0.3380906768143177, Final Batch Loss: 0.03247556462883949\n",
      "Epoch 1643, Loss: 0.33515555411577225, Final Batch Loss: 0.08512420952320099\n",
      "Epoch 1644, Loss: 0.3046282120049, Final Batch Loss: 0.049279797822237015\n",
      "Epoch 1645, Loss: 0.36166520416736603, Final Batch Loss: 0.08488045632839203\n",
      "Epoch 1646, Loss: 0.42328692227602005, Final Batch Loss: 0.16740106046199799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1647, Loss: 0.5222330242395401, Final Batch Loss: 0.2753549814224243\n",
      "Epoch 1648, Loss: 0.405520536005497, Final Batch Loss: 0.1531660109758377\n",
      "Epoch 1649, Loss: 0.3720525652170181, Final Batch Loss: 0.08551391959190369\n",
      "Epoch 1650, Loss: 0.30208995565772057, Final Batch Loss: 0.039250608533620834\n",
      "Epoch 1651, Loss: 0.42034031450748444, Final Batch Loss: 0.20077209174633026\n",
      "Epoch 1652, Loss: 0.3007066510617733, Final Batch Loss: 0.044405508786439896\n",
      "Epoch 1653, Loss: 0.3122268505394459, Final Batch Loss: 0.05943853035569191\n",
      "Epoch 1654, Loss: 0.3672984018921852, Final Batch Loss: 0.13358153402805328\n",
      "Epoch 1655, Loss: 0.3603934273123741, Final Batch Loss: 0.09360944479703903\n",
      "Epoch 1656, Loss: 0.7853729501366615, Final Batch Loss: 0.5444270968437195\n",
      "Epoch 1657, Loss: 0.5431085750460625, Final Batch Loss: 0.3236618936061859\n",
      "Epoch 1658, Loss: 0.26447026059031487, Final Batch Loss: 0.01283116266131401\n",
      "Epoch 1659, Loss: 0.43947478383779526, Final Batch Loss: 0.17050866782665253\n",
      "Epoch 1660, Loss: 0.36132578179240227, Final Batch Loss: 0.041332077234983444\n",
      "Epoch 1661, Loss: 0.3624316491186619, Final Batch Loss: 0.052632395178079605\n",
      "Epoch 1662, Loss: 0.40243029594421387, Final Batch Loss: 0.06470860540866852\n",
      "Epoch 1663, Loss: 0.5177228450775146, Final Batch Loss: 0.2316243052482605\n",
      "Epoch 1664, Loss: 1.2539861053228378, Final Batch Loss: 0.9801920652389526\n",
      "Epoch 1665, Loss: 0.55913345515728, Final Batch Loss: 0.19648833572864532\n",
      "Epoch 1666, Loss: 0.4015004560351372, Final Batch Loss: 0.09018582850694656\n",
      "Epoch 1667, Loss: 0.5376625210046768, Final Batch Loss: 0.10075849294662476\n",
      "Epoch 1668, Loss: 0.5091367363929749, Final Batch Loss: 0.15927720069885254\n",
      "Epoch 1669, Loss: 0.41804277151823044, Final Batch Loss: 0.1592681109905243\n",
      "Epoch 1670, Loss: 0.45044591277837753, Final Batch Loss: 0.19942867755889893\n",
      "Epoch 1671, Loss: 0.34162514843046665, Final Batch Loss: 0.020928675308823586\n",
      "Epoch 1672, Loss: 0.5474664270877838, Final Batch Loss: 0.2371390014886856\n",
      "Epoch 1673, Loss: 0.4509836286306381, Final Batch Loss: 0.13690483570098877\n",
      "Epoch 1674, Loss: 0.2898710137233138, Final Batch Loss: 0.0062962910160422325\n",
      "Epoch 1675, Loss: 0.6120927035808563, Final Batch Loss: 0.26505333185195923\n",
      "Epoch 1676, Loss: 0.34343937039375305, Final Batch Loss: 0.06512882560491562\n",
      "Epoch 1677, Loss: 0.3816989064216614, Final Batch Loss: 0.1010190099477768\n",
      "Epoch 1678, Loss: 0.37185944616794586, Final Batch Loss: 0.11730939149856567\n",
      "Epoch 1679, Loss: 0.3575756102800369, Final Batch Loss: 0.07997331023216248\n",
      "Epoch 1680, Loss: 0.3684585317969322, Final Batch Loss: 0.0901196151971817\n",
      "Epoch 1681, Loss: 0.5109683647751808, Final Batch Loss: 0.2159440964460373\n",
      "Epoch 1682, Loss: 0.3686807230114937, Final Batch Loss: 0.036829374730587006\n",
      "Epoch 1683, Loss: 0.43837545067071915, Final Batch Loss: 0.07005802541971207\n",
      "Epoch 1684, Loss: 0.3552794009447098, Final Batch Loss: 0.05452592670917511\n",
      "Epoch 1685, Loss: 0.5056480243802071, Final Batch Loss: 0.2520897388458252\n",
      "Epoch 1686, Loss: 0.620176151394844, Final Batch Loss: 0.3469809591770172\n",
      "Epoch 1687, Loss: 0.3571161478757858, Final Batch Loss: 0.10223240405321121\n",
      "Epoch 1688, Loss: 0.4314900413155556, Final Batch Loss: 0.11404845863580704\n",
      "Epoch 1689, Loss: 0.5990602523088455, Final Batch Loss: 0.25462445616722107\n",
      "Epoch 1690, Loss: 0.7190510630607605, Final Batch Loss: 0.36874791979789734\n",
      "Epoch 1691, Loss: 0.5276503339409828, Final Batch Loss: 0.3129557967185974\n",
      "Epoch 1692, Loss: 0.37152595818042755, Final Batch Loss: 0.0869961827993393\n",
      "Epoch 1693, Loss: 0.6526637673377991, Final Batch Loss: 0.25881823897361755\n",
      "Epoch 1694, Loss: 0.4699183255434036, Final Batch Loss: 0.14935366809368134\n",
      "Epoch 1695, Loss: 0.6811007857322693, Final Batch Loss: 0.287849485874176\n",
      "Epoch 1696, Loss: 0.6111781448125839, Final Batch Loss: 0.27788153290748596\n",
      "Epoch 1697, Loss: 0.4137863293290138, Final Batch Loss: 0.10620708018541336\n",
      "Epoch 1698, Loss: 0.5724000409245491, Final Batch Loss: 0.2878859043121338\n",
      "Epoch 1699, Loss: 0.4919917583465576, Final Batch Loss: 0.14671635627746582\n",
      "Epoch 1700, Loss: 0.2816637456417084, Final Batch Loss: 0.027842938899993896\n",
      "Epoch 1701, Loss: 0.3776910752058029, Final Batch Loss: 0.08513005077838898\n",
      "Epoch 1702, Loss: 0.5159883797168732, Final Batch Loss: 0.22562746703624725\n",
      "Epoch 1703, Loss: 0.45473096519708633, Final Batch Loss: 0.1736448109149933\n",
      "Epoch 1704, Loss: 0.4029112607240677, Final Batch Loss: 0.1118466705083847\n",
      "Epoch 1705, Loss: 0.6395459026098251, Final Batch Loss: 0.3674892783164978\n",
      "Epoch 1706, Loss: 0.4818399101495743, Final Batch Loss: 0.19586218893527985\n",
      "Epoch 1707, Loss: 0.32087068259716034, Final Batch Loss: 0.07530810683965683\n",
      "Epoch 1708, Loss: 0.3766239210963249, Final Batch Loss: 0.1359792947769165\n",
      "Epoch 1709, Loss: 0.2925850637257099, Final Batch Loss: 0.0404132716357708\n",
      "Epoch 1710, Loss: 0.4413774833083153, Final Batch Loss: 0.10619866102933884\n",
      "Epoch 1711, Loss: 0.3168335109949112, Final Batch Loss: 0.11652550101280212\n",
      "Epoch 1712, Loss: 0.5307984203100204, Final Batch Loss: 0.24673329293727875\n",
      "Epoch 1713, Loss: 0.2583279274404049, Final Batch Loss: 0.03282533213496208\n",
      "Epoch 1714, Loss: 0.3018385246396065, Final Batch Loss: 0.07809657603502274\n",
      "Epoch 1715, Loss: 0.46298936009407043, Final Batch Loss: 0.20467126369476318\n",
      "Epoch 1716, Loss: 0.5435760617256165, Final Batch Loss: 0.20831404626369476\n",
      "Epoch 1717, Loss: 0.337112657725811, Final Batch Loss: 0.09814728051424026\n",
      "Epoch 1718, Loss: 0.2856270596385002, Final Batch Loss: 0.0929223895072937\n",
      "Epoch 1719, Loss: 0.35740383714437485, Final Batch Loss: 0.10872592777013779\n",
      "Epoch 1720, Loss: 0.28749170526862144, Final Batch Loss: 0.05677495524287224\n",
      "Epoch 1721, Loss: 0.30201249569654465, Final Batch Loss: 0.049520038068294525\n",
      "Epoch 1722, Loss: 0.5130019634962082, Final Batch Loss: 0.24389061331748962\n",
      "Epoch 1723, Loss: 0.2863052859902382, Final Batch Loss: 0.08637312799692154\n",
      "Epoch 1724, Loss: 0.38291746377944946, Final Batch Loss: 0.18013834953308105\n",
      "Epoch 1725, Loss: 0.31954045593738556, Final Batch Loss: 0.07947900891304016\n",
      "Epoch 1726, Loss: 0.2718004137277603, Final Batch Loss: 0.05309970676898956\n",
      "Epoch 1727, Loss: 0.3996632918715477, Final Batch Loss: 0.17542339861392975\n",
      "Epoch 1728, Loss: 0.38639792054891586, Final Batch Loss: 0.08075084537267685\n",
      "Epoch 1729, Loss: 0.3655095249414444, Final Batch Loss: 0.1310717612504959\n",
      "Epoch 1730, Loss: 0.4606849104166031, Final Batch Loss: 0.12852586805820465\n",
      "Epoch 1731, Loss: 0.34810323268175125, Final Batch Loss: 0.10786549746990204\n",
      "Epoch 1732, Loss: 0.5197468101978302, Final Batch Loss: 0.265868604183197\n",
      "Epoch 1733, Loss: 0.3237121067941189, Final Batch Loss: 0.04732372984290123\n",
      "Epoch 1734, Loss: 0.38718579709529877, Final Batch Loss: 0.09262602031230927\n",
      "Epoch 1735, Loss: 0.3845922574400902, Final Batch Loss: 0.11911166459321976\n",
      "Epoch 1736, Loss: 0.6581638604402542, Final Batch Loss: 0.41492459177970886\n",
      "Epoch 1737, Loss: 0.4264543280005455, Final Batch Loss: 0.1220158115029335\n",
      "Epoch 1738, Loss: 0.49001358449459076, Final Batch Loss: 0.19574452936649323\n",
      "Epoch 1739, Loss: 0.44713980704545975, Final Batch Loss: 0.1925611048936844\n",
      "Epoch 1740, Loss: 0.39924703538417816, Final Batch Loss: 0.1741451770067215\n",
      "Epoch 1741, Loss: 0.25510043278336525, Final Batch Loss: 0.03129785880446434\n",
      "Epoch 1742, Loss: 0.3655751645565033, Final Batch Loss: 0.09500271826982498\n",
      "Epoch 1743, Loss: 0.30156296119093895, Final Batch Loss: 0.049543317407369614\n",
      "Epoch 1744, Loss: 0.35584499686956406, Final Batch Loss: 0.06452491134405136\n",
      "Epoch 1745, Loss: 0.4351038336753845, Final Batch Loss: 0.21187730133533478\n",
      "Epoch 1746, Loss: 0.335171677172184, Final Batch Loss: 0.10251592099666595\n",
      "Epoch 1747, Loss: 0.37158194184303284, Final Batch Loss: 0.14206838607788086\n",
      "Epoch 1748, Loss: 0.3426748141646385, Final Batch Loss: 0.1291457861661911\n",
      "Epoch 1749, Loss: 0.28273982368409634, Final Batch Loss: 0.03119141422212124\n",
      "Epoch 1750, Loss: 0.4239608645439148, Final Batch Loss: 0.1939035952091217\n",
      "Epoch 1751, Loss: 0.5895035713911057, Final Batch Loss: 0.37761738896369934\n",
      "Epoch 1752, Loss: 0.41821905225515366, Final Batch Loss: 0.15678712725639343\n",
      "Epoch 1753, Loss: 0.3196363002061844, Final Batch Loss: 0.07409658282995224\n",
      "Epoch 1754, Loss: 0.5763041377067566, Final Batch Loss: 0.2432372123003006\n",
      "Epoch 1755, Loss: 0.35296597331762314, Final Batch Loss: 0.09847897291183472\n",
      "Epoch 1756, Loss: 0.25783736538141966, Final Batch Loss: 0.0036198748275637627\n",
      "Epoch 1757, Loss: 0.3817790448665619, Final Batch Loss: 0.1735875904560089\n",
      "Epoch 1758, Loss: 0.2684727758169174, Final Batch Loss: 0.03402502089738846\n",
      "Epoch 1759, Loss: 0.35041508823633194, Final Batch Loss: 0.12338831275701523\n",
      "Epoch 1760, Loss: 0.28605715185403824, Final Batch Loss: 0.010133087635040283\n",
      "Epoch 1761, Loss: 0.2383144674822688, Final Batch Loss: 0.010433743707835674\n",
      "Epoch 1762, Loss: 0.48369836062192917, Final Batch Loss: 0.25000447034835815\n",
      "Epoch 1763, Loss: 0.28499279730021954, Final Batch Loss: 0.01399180106818676\n",
      "Epoch 1764, Loss: 0.30103640258312225, Final Batch Loss: 0.07897336035966873\n",
      "Epoch 1765, Loss: 0.3119445890188217, Final Batch Loss: 0.12415317445993423\n",
      "Epoch 1766, Loss: 0.3013618993572891, Final Batch Loss: 0.006078134756535292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1767, Loss: 0.42679544538259506, Final Batch Loss: 0.11371856182813644\n",
      "Epoch 1768, Loss: 0.2415422387421131, Final Batch Loss: 0.020668935030698776\n",
      "Epoch 1769, Loss: 0.2440917231142521, Final Batch Loss: 0.023036759346723557\n",
      "Epoch 1770, Loss: 0.5560977309942245, Final Batch Loss: 0.3063589334487915\n",
      "Epoch 1771, Loss: 0.28636911511421204, Final Batch Loss: 0.07180116325616837\n",
      "Epoch 1772, Loss: 0.29601327516138554, Final Batch Loss: 0.028784068301320076\n",
      "Epoch 1773, Loss: 0.4984276667237282, Final Batch Loss: 0.25747260451316833\n",
      "Epoch 1774, Loss: 0.2670648153871298, Final Batch Loss: 0.0234257560223341\n",
      "Epoch 1775, Loss: 0.4178442507982254, Final Batch Loss: 0.13960812985897064\n",
      "Epoch 1776, Loss: 0.319535031914711, Final Batch Loss: 0.07735083252191544\n",
      "Epoch 1777, Loss: 0.4693056792020798, Final Batch Loss: 0.2300807237625122\n",
      "Epoch 1778, Loss: 0.5219193547964096, Final Batch Loss: 0.28710880875587463\n",
      "Epoch 1779, Loss: 0.24267981946468353, Final Batch Loss: 0.07066725194454193\n",
      "Epoch 1780, Loss: 0.34120456129312515, Final Batch Loss: 0.04215420037508011\n",
      "Epoch 1781, Loss: 0.2524314699694514, Final Batch Loss: 0.011169704608619213\n",
      "Epoch 1782, Loss: 0.28628499805927277, Final Batch Loss: 0.02596832811832428\n",
      "Epoch 1783, Loss: 0.6155694872140884, Final Batch Loss: 0.30657699704170227\n",
      "Epoch 1784, Loss: 0.2820107713341713, Final Batch Loss: 0.09058310836553574\n",
      "Epoch 1785, Loss: 0.22377694211900234, Final Batch Loss: 0.023858068510890007\n",
      "Epoch 1786, Loss: 0.4409293234348297, Final Batch Loss: 0.17173437774181366\n",
      "Epoch 1787, Loss: 0.4196113795042038, Final Batch Loss: 0.18407906591892242\n",
      "Epoch 1788, Loss: 0.38490255177021027, Final Batch Loss: 0.12913697957992554\n",
      "Epoch 1789, Loss: 0.35490749776363373, Final Batch Loss: 0.15627777576446533\n",
      "Epoch 1790, Loss: 0.3332160636782646, Final Batch Loss: 0.06045747548341751\n",
      "Epoch 1791, Loss: 0.23409058339893818, Final Batch Loss: 0.023859703913331032\n",
      "Epoch 1792, Loss: 0.25962433591485023, Final Batch Loss: 0.03598397597670555\n",
      "Epoch 1793, Loss: 0.24664697982370853, Final Batch Loss: 0.026672037318348885\n",
      "Epoch 1794, Loss: 0.32552897185087204, Final Batch Loss: 0.1060735210776329\n",
      "Epoch 1795, Loss: 0.2792926598340273, Final Batch Loss: 0.030827553942799568\n",
      "Epoch 1796, Loss: 0.44327427446842194, Final Batch Loss: 0.17551060020923615\n",
      "Epoch 1797, Loss: 0.2738882452249527, Final Batch Loss: 0.04314771294593811\n",
      "Epoch 1798, Loss: 0.25000160560011864, Final Batch Loss: 0.0556698776781559\n",
      "Epoch 1799, Loss: 0.3511379659175873, Final Batch Loss: 0.1183563694357872\n",
      "Epoch 1800, Loss: 0.3487771525979042, Final Batch Loss: 0.13261494040489197\n",
      "Epoch 1801, Loss: 0.32082123309373856, Final Batch Loss: 0.10868201404809952\n",
      "Epoch 1802, Loss: 0.2729371562600136, Final Batch Loss: 0.04265616834163666\n",
      "Epoch 1803, Loss: 0.5098834857344627, Final Batch Loss: 0.2508942484855652\n",
      "Epoch 1804, Loss: 0.3467443287372589, Final Batch Loss: 0.1252036988735199\n",
      "Epoch 1805, Loss: 0.42299194633960724, Final Batch Loss: 0.06991919875144958\n",
      "Epoch 1806, Loss: 0.6742485761642456, Final Batch Loss: 0.2877296805381775\n",
      "Epoch 1807, Loss: 0.4126325882971287, Final Batch Loss: 0.04415767267346382\n",
      "Epoch 1808, Loss: 0.46205979213118553, Final Batch Loss: 0.03556771203875542\n",
      "Epoch 1809, Loss: 0.44776130467653275, Final Batch Loss: 0.09588120132684708\n",
      "Epoch 1810, Loss: 0.6196487098932266, Final Batch Loss: 0.29358965158462524\n",
      "Epoch 1811, Loss: 0.3603946752846241, Final Batch Loss: 0.033580366522073746\n",
      "Epoch 1812, Loss: 0.3671238571405411, Final Batch Loss: 0.09585859626531601\n",
      "Epoch 1813, Loss: 0.4707566797733307, Final Batch Loss: 0.20609597861766815\n",
      "Epoch 1814, Loss: 0.4060421288013458, Final Batch Loss: 0.11517128348350525\n",
      "Epoch 1815, Loss: 0.3976533114910126, Final Batch Loss: 0.1517249345779419\n",
      "Epoch 1816, Loss: 0.25677074305713177, Final Batch Loss: 0.018151765689253807\n",
      "Epoch 1817, Loss: 0.3761342614889145, Final Batch Loss: 0.11918091773986816\n",
      "Epoch 1818, Loss: 0.3040398880839348, Final Batch Loss: 0.0329047366976738\n",
      "Epoch 1819, Loss: 0.3234057128429413, Final Batch Loss: 0.06698981672525406\n",
      "Epoch 1820, Loss: 0.35557911545038223, Final Batch Loss: 0.12213405966758728\n",
      "Epoch 1821, Loss: 0.36740801483392715, Final Batch Loss: 0.13377276062965393\n",
      "Epoch 1822, Loss: 0.2603186145424843, Final Batch Loss: 0.027526721358299255\n",
      "Epoch 1823, Loss: 0.34038739651441574, Final Batch Loss: 0.09515319764614105\n",
      "Epoch 1824, Loss: 0.47065554559230804, Final Batch Loss: 0.21217191219329834\n",
      "Epoch 1825, Loss: 0.6060711145401001, Final Batch Loss: 0.3398532271385193\n",
      "Epoch 1826, Loss: 0.3217026814818382, Final Batch Loss: 0.06298186630010605\n",
      "Epoch 1827, Loss: 0.3280409947037697, Final Batch Loss: 0.04508557170629501\n",
      "Epoch 1828, Loss: 0.31464390456676483, Final Batch Loss: 0.1200842633843422\n",
      "Epoch 1829, Loss: 0.2369520105421543, Final Batch Loss: 0.03162089362740517\n",
      "Epoch 1830, Loss: 0.2786626163870096, Final Batch Loss: 0.023108432069420815\n",
      "Epoch 1831, Loss: 0.3248682990670204, Final Batch Loss: 0.11696131527423859\n",
      "Epoch 1832, Loss: 0.2798130288720131, Final Batch Loss: 0.0704544186592102\n",
      "Epoch 1833, Loss: 0.3096395283937454, Final Batch Loss: 0.10450290143489838\n",
      "Epoch 1834, Loss: 0.28373877611011267, Final Batch Loss: 0.010794608853757381\n",
      "Epoch 1835, Loss: 0.3728511855006218, Final Batch Loss: 0.12315908074378967\n",
      "Epoch 1836, Loss: 0.2515598302707076, Final Batch Loss: 0.013468540273606777\n",
      "Epoch 1837, Loss: 0.4943199083209038, Final Batch Loss: 0.2670074701309204\n",
      "Epoch 1838, Loss: 0.4302036091685295, Final Batch Loss: 0.20553405582904816\n",
      "Epoch 1839, Loss: 0.3119198977947235, Final Batch Loss: 0.04092980921268463\n",
      "Epoch 1840, Loss: 0.3993185833096504, Final Batch Loss: 0.08717125654220581\n",
      "Epoch 1841, Loss: 0.4330368936061859, Final Batch Loss: 0.18305228650569916\n",
      "Epoch 1842, Loss: 0.3889595791697502, Final Batch Loss: 0.0911983847618103\n",
      "Epoch 1843, Loss: 0.39168138056993484, Final Batch Loss: 0.20916567742824554\n",
      "Epoch 1844, Loss: 0.3977719470858574, Final Batch Loss: 0.2166229784488678\n",
      "Epoch 1845, Loss: 0.30520258843898773, Final Batch Loss: 0.06853798776865005\n",
      "Epoch 1846, Loss: 0.23393915640190244, Final Batch Loss: 0.005206980276852846\n",
      "Epoch 1847, Loss: 0.42304591834545135, Final Batch Loss: 0.11217445135116577\n",
      "Epoch 1848, Loss: 0.5615229606628418, Final Batch Loss: 0.3865191638469696\n",
      "Epoch 1849, Loss: 0.4704827517271042, Final Batch Loss: 0.17274411022663116\n",
      "Epoch 1850, Loss: 0.3549303114414215, Final Batch Loss: 0.11015783995389938\n",
      "Epoch 1851, Loss: 0.33427055925130844, Final Batch Loss: 0.06314051896333694\n",
      "Epoch 1852, Loss: 0.3863269090652466, Final Batch Loss: 0.13640162348747253\n",
      "Epoch 1853, Loss: 0.4289647489786148, Final Batch Loss: 0.18236030638217926\n",
      "Epoch 1854, Loss: 0.35583333298563957, Final Batch Loss: 0.050173405557870865\n",
      "Epoch 1855, Loss: 0.5904140025377274, Final Batch Loss: 0.33278945088386536\n",
      "Epoch 1856, Loss: 0.39702556282281876, Final Batch Loss: 0.08272714167833328\n",
      "Epoch 1857, Loss: 0.46796609461307526, Final Batch Loss: 0.18546496331691742\n",
      "Epoch 1858, Loss: 0.33732785284519196, Final Batch Loss: 0.1041429191827774\n",
      "Epoch 1859, Loss: 0.4815579652786255, Final Batch Loss: 0.2028317004442215\n",
      "Epoch 1860, Loss: 0.3924572914838791, Final Batch Loss: 0.09106999635696411\n",
      "Epoch 1861, Loss: 0.3991888761520386, Final Batch Loss: 0.1651569902896881\n",
      "Epoch 1862, Loss: 0.2928430326282978, Final Batch Loss: 0.045231666415929794\n",
      "Epoch 1863, Loss: 0.24475159868597984, Final Batch Loss: 0.005953136831521988\n",
      "Epoch 1864, Loss: 0.2541254051029682, Final Batch Loss: 0.008958932012319565\n",
      "Epoch 1865, Loss: 0.3731972798705101, Final Batch Loss: 0.13256986439228058\n",
      "Epoch 1866, Loss: 0.23715391382575035, Final Batch Loss: 0.01778816059231758\n",
      "Epoch 1867, Loss: 0.3811865970492363, Final Batch Loss: 0.150509312748909\n",
      "Epoch 1868, Loss: 0.2742781564593315, Final Batch Loss: 0.06011665612459183\n",
      "Epoch 1869, Loss: 0.27852070331573486, Final Batch Loss: 0.03802024573087692\n",
      "Epoch 1870, Loss: 0.1984859392978251, Final Batch Loss: 0.007084077689796686\n",
      "Epoch 1871, Loss: 0.34589486569166183, Final Batch Loss: 0.090885229408741\n",
      "Epoch 1872, Loss: 0.3512554168701172, Final Batch Loss: 0.07705935835838318\n",
      "Epoch 1873, Loss: 0.27983495965600014, Final Batch Loss: 0.059011828154325485\n",
      "Epoch 1874, Loss: 0.32500573992729187, Final Batch Loss: 0.14149358868598938\n",
      "Epoch 1875, Loss: 0.5412686988711357, Final Batch Loss: 0.27061915397644043\n",
      "Epoch 1876, Loss: 0.24084807187318802, Final Batch Loss: 0.023441925644874573\n",
      "Epoch 1877, Loss: 0.2844224087893963, Final Batch Loss: 0.04096239432692528\n",
      "Epoch 1878, Loss: 0.4015013799071312, Final Batch Loss: 0.18132539093494415\n",
      "Epoch 1879, Loss: 0.4778870642185211, Final Batch Loss: 0.17316874861717224\n",
      "Epoch 1880, Loss: 0.3762141615152359, Final Batch Loss: 0.14337877929210663\n",
      "Epoch 1881, Loss: 0.3457345515489578, Final Batch Loss: 0.049850255250930786\n",
      "Epoch 1882, Loss: 0.4967585727572441, Final Batch Loss: 0.29063549637794495\n",
      "Epoch 1883, Loss: 0.28096265718340874, Final Batch Loss: 0.05537745729088783\n",
      "Epoch 1884, Loss: 0.39136970415711403, Final Batch Loss: 0.0550241582095623\n",
      "Epoch 1885, Loss: 0.6008626446127892, Final Batch Loss: 0.3784869313240051\n",
      "Epoch 1886, Loss: 0.25692107528448105, Final Batch Loss: 0.045448288321495056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1887, Loss: 0.4538489580154419, Final Batch Loss: 0.08707478642463684\n",
      "Epoch 1888, Loss: 0.5345030426979065, Final Batch Loss: 0.1343403160572052\n",
      "Epoch 1889, Loss: 0.30388771556317806, Final Batch Loss: 0.006768396124243736\n",
      "Epoch 1890, Loss: 0.5028551667928696, Final Batch Loss: 0.2248794138431549\n",
      "Epoch 1891, Loss: 0.2389998696744442, Final Batch Loss: 0.026279840618371964\n",
      "Epoch 1892, Loss: 0.6888660490512848, Final Batch Loss: 0.3637821078300476\n",
      "Epoch 1893, Loss: 0.3989192321896553, Final Batch Loss: 0.15512549877166748\n",
      "Epoch 1894, Loss: 0.4733598232269287, Final Batch Loss: 0.25242915749549866\n",
      "Epoch 1895, Loss: 0.344879612326622, Final Batch Loss: 0.07317906618118286\n",
      "Epoch 1896, Loss: 0.2991616055369377, Final Batch Loss: 0.054036304354667664\n",
      "Epoch 1897, Loss: 0.3107631541788578, Final Batch Loss: 0.05497751012444496\n",
      "Epoch 1898, Loss: 0.6473527923226357, Final Batch Loss: 0.34830793738365173\n",
      "Epoch 1899, Loss: 0.3042645528912544, Final Batch Loss: 0.031515397131443024\n",
      "Epoch 1900, Loss: 0.3625304251909256, Final Batch Loss: 0.13419334590435028\n",
      "Epoch 1901, Loss: 0.3350335583090782, Final Batch Loss: 0.0848776251077652\n",
      "Epoch 1902, Loss: 0.2766943406313658, Final Batch Loss: 0.01831013523042202\n",
      "Epoch 1903, Loss: 0.40507905930280685, Final Batch Loss: 0.13885299861431122\n",
      "Epoch 1904, Loss: 0.34955285489559174, Final Batch Loss: 0.14062944054603577\n",
      "Epoch 1905, Loss: 0.36177439987659454, Final Batch Loss: 0.1613553911447525\n",
      "Epoch 1906, Loss: 0.33048803824931383, Final Batch Loss: 0.012524780817329884\n",
      "Epoch 1907, Loss: 0.4667814373970032, Final Batch Loss: 0.26109352707862854\n",
      "Epoch 1908, Loss: 0.39712613821029663, Final Batch Loss: 0.10093837976455688\n",
      "Epoch 1909, Loss: 0.34028957039117813, Final Batch Loss: 0.10095935314893723\n",
      "Epoch 1910, Loss: 0.5000294893980026, Final Batch Loss: 0.26905328035354614\n",
      "Epoch 1911, Loss: 0.3361164629459381, Final Batch Loss: 0.08809101581573486\n",
      "Epoch 1912, Loss: 0.3428577706217766, Final Batch Loss: 0.13022704422473907\n",
      "Epoch 1913, Loss: 0.47536278516054153, Final Batch Loss: 0.23788726329803467\n",
      "Epoch 1914, Loss: 0.2712283208966255, Final Batch Loss: 0.0450211837887764\n",
      "Epoch 1915, Loss: 0.4187343195080757, Final Batch Loss: 0.13967178761959076\n",
      "Epoch 1916, Loss: 0.42001907527446747, Final Batch Loss: 0.14635169506072998\n",
      "Epoch 1917, Loss: 0.4108215272426605, Final Batch Loss: 0.1694575548171997\n",
      "Epoch 1918, Loss: 0.3009672909975052, Final Batch Loss: 0.10490473359823227\n",
      "Epoch 1919, Loss: 0.3527827337384224, Final Batch Loss: 0.11396055668592453\n",
      "Epoch 1920, Loss: 0.3537101671099663, Final Batch Loss: 0.12686391174793243\n",
      "Epoch 1921, Loss: 0.3051241710782051, Final Batch Loss: 0.036507800221443176\n",
      "Epoch 1922, Loss: 0.32419871538877487, Final Batch Loss: 0.0705341026186943\n",
      "Epoch 1923, Loss: 0.21435802057385445, Final Batch Loss: 0.0349324606359005\n",
      "Epoch 1924, Loss: 0.22358749620616436, Final Batch Loss: 0.02792871557176113\n",
      "Epoch 1925, Loss: 0.24311476945877075, Final Batch Loss: 0.03549867123365402\n",
      "Epoch 1926, Loss: 0.30376600474119186, Final Batch Loss: 0.1111554503440857\n",
      "Epoch 1927, Loss: 0.367718867957592, Final Batch Loss: 0.1442086398601532\n",
      "Epoch 1928, Loss: 0.3796970769762993, Final Batch Loss: 0.09176614135503769\n",
      "Epoch 1929, Loss: 0.5058492794632912, Final Batch Loss: 0.3122434616088867\n",
      "Epoch 1930, Loss: 0.28858961164951324, Final Batch Loss: 0.11121676862239838\n",
      "Epoch 1931, Loss: 0.2405350343324244, Final Batch Loss: 0.005065491888672113\n",
      "Epoch 1932, Loss: 0.3604372665286064, Final Batch Loss: 0.11104226112365723\n",
      "Epoch 1933, Loss: 0.25535179302096367, Final Batch Loss: 0.04149724170565605\n",
      "Epoch 1934, Loss: 0.3079298511147499, Final Batch Loss: 0.10748735070228577\n",
      "Epoch 1935, Loss: 0.378870852291584, Final Batch Loss: 0.13491125404834747\n",
      "Epoch 1936, Loss: 0.23893805034458637, Final Batch Loss: 0.01009131409227848\n",
      "Epoch 1937, Loss: 0.3290463462471962, Final Batch Loss: 0.09533002972602844\n",
      "Epoch 1938, Loss: 0.1823771558701992, Final Batch Loss: 0.033253263682127\n",
      "Epoch 1939, Loss: 0.22419557720422745, Final Batch Loss: 0.025816742330789566\n",
      "Epoch 1940, Loss: 0.25822962541133165, Final Batch Loss: 0.01205096859484911\n",
      "Epoch 1941, Loss: 0.2724379114806652, Final Batch Loss: 0.03284498676657677\n",
      "Epoch 1942, Loss: 0.33357003331184387, Final Batch Loss: 0.14146827161312103\n",
      "Epoch 1943, Loss: 0.31015919893980026, Final Batch Loss: 0.07058294862508774\n",
      "Epoch 1944, Loss: 0.3023535683751106, Final Batch Loss: 0.024584263563156128\n",
      "Epoch 1945, Loss: 0.27825620025396347, Final Batch Loss: 0.090439572930336\n",
      "Epoch 1946, Loss: 0.3503558561205864, Final Batch Loss: 0.1724640280008316\n",
      "Epoch 1947, Loss: 0.5930157154798508, Final Batch Loss: 0.3674054443836212\n",
      "Epoch 1948, Loss: 0.23284423723816872, Final Batch Loss: 0.013731349259614944\n",
      "Epoch 1949, Loss: 0.5594743937253952, Final Batch Loss: 0.15114404261112213\n",
      "Epoch 1950, Loss: 0.41243593394756317, Final Batch Loss: 0.07143916189670563\n",
      "Epoch 1951, Loss: 0.5433932170271873, Final Batch Loss: 0.23726895451545715\n",
      "Epoch 1952, Loss: 0.5019083470106125, Final Batch Loss: 0.23075330257415771\n",
      "Epoch 1953, Loss: 0.33069873601198196, Final Batch Loss: 0.11060211807489395\n",
      "Epoch 1954, Loss: 0.6029337346553802, Final Batch Loss: 0.22835379838943481\n",
      "Epoch 1955, Loss: 0.3556724786758423, Final Batch Loss: 0.07087354362010956\n",
      "Epoch 1956, Loss: 0.3725387454032898, Final Batch Loss: 0.15435950458049774\n",
      "Epoch 1957, Loss: 0.3852907717227936, Final Batch Loss: 0.08315529674291611\n",
      "Epoch 1958, Loss: 0.4165009409189224, Final Batch Loss: 0.18381552398204803\n",
      "Epoch 1959, Loss: 0.3319542519748211, Final Batch Loss: 0.01811813935637474\n",
      "Epoch 1960, Loss: 0.32184229185804725, Final Batch Loss: 0.005408534314483404\n",
      "Epoch 1961, Loss: 0.26794900745153427, Final Batch Loss: 0.022828809916973114\n",
      "Epoch 1962, Loss: 0.3298381045460701, Final Batch Loss: 0.07618358731269836\n",
      "Epoch 1963, Loss: 0.38749708980321884, Final Batch Loss: 0.09088578075170517\n",
      "Epoch 1964, Loss: 0.36843162775039673, Final Batch Loss: 0.11129254102706909\n",
      "Epoch 1965, Loss: 0.3345706984400749, Final Batch Loss: 0.0692606195807457\n",
      "Epoch 1966, Loss: 0.2507468443363905, Final Batch Loss: 0.031127071008086205\n",
      "Epoch 1967, Loss: 0.3788689821958542, Final Batch Loss: 0.1557142585515976\n",
      "Epoch 1968, Loss: 0.34240100532770157, Final Batch Loss: 0.09850611537694931\n",
      "Epoch 1969, Loss: 0.44086530804634094, Final Batch Loss: 0.21428002417087555\n",
      "Epoch 1970, Loss: 0.3754357472062111, Final Batch Loss: 0.1430603265762329\n",
      "Epoch 1971, Loss: 0.29801738262176514, Final Batch Loss: 0.06406039744615555\n",
      "Epoch 1972, Loss: 0.2930974215269089, Final Batch Loss: 0.07550352811813354\n",
      "Epoch 1973, Loss: 0.3530283123254776, Final Batch Loss: 0.11253032088279724\n",
      "Epoch 1974, Loss: 0.28902366757392883, Final Batch Loss: 0.07426957786083221\n",
      "Epoch 1975, Loss: 0.6692964881658554, Final Batch Loss: 0.34678393602371216\n",
      "Epoch 1976, Loss: 0.38736768811941147, Final Batch Loss: 0.1379547119140625\n",
      "Epoch 1977, Loss: 0.49934226274490356, Final Batch Loss: 0.21133430302143097\n",
      "Epoch 1978, Loss: 0.3053685314953327, Final Batch Loss: 0.037028227001428604\n",
      "Epoch 1979, Loss: 0.4029593914747238, Final Batch Loss: 0.09288053214550018\n",
      "Epoch 1980, Loss: 0.41744473576545715, Final Batch Loss: 0.149347186088562\n",
      "Epoch 1981, Loss: 0.310209222137928, Final Batch Loss: 0.07319101691246033\n",
      "Epoch 1982, Loss: 0.2795354537665844, Final Batch Loss: 0.03229456767439842\n",
      "Epoch 1983, Loss: 0.26308612525463104, Final Batch Loss: 0.049359165132045746\n",
      "Epoch 1984, Loss: 0.38359711319208145, Final Batch Loss: 0.14121687412261963\n",
      "Epoch 1985, Loss: 0.3111981004476547, Final Batch Loss: 0.09175924956798553\n",
      "Epoch 1986, Loss: 0.39539193361997604, Final Batch Loss: 0.14733541011810303\n",
      "Epoch 1987, Loss: 0.37410324066877365, Final Batch Loss: 0.13915802538394928\n",
      "Epoch 1988, Loss: 0.26758838817477226, Final Batch Loss: 0.05416132137179375\n",
      "Epoch 1989, Loss: 0.4336979612708092, Final Batch Loss: 0.22418759763240814\n",
      "Epoch 1990, Loss: 0.43910885602235794, Final Batch Loss: 0.22334587574005127\n",
      "Epoch 1991, Loss: 0.43046946078538895, Final Batch Loss: 0.17949193716049194\n",
      "Epoch 1992, Loss: 0.3741140067577362, Final Batch Loss: 0.143965944647789\n",
      "Epoch 1993, Loss: 0.31695371866226196, Final Batch Loss: 0.07511180639266968\n",
      "Epoch 1994, Loss: 0.2544804587960243, Final Batch Loss: 0.031178630888462067\n",
      "Epoch 1995, Loss: 0.3263207897543907, Final Batch Loss: 0.11365509033203125\n",
      "Epoch 1996, Loss: 0.3774093985557556, Final Batch Loss: 0.10609292984008789\n",
      "Epoch 1997, Loss: 0.26665278896689415, Final Batch Loss: 0.057756680995225906\n",
      "Epoch 1998, Loss: 0.5763576999306679, Final Batch Loss: 0.2798736095428467\n",
      "Epoch 1999, Loss: 0.3932701125741005, Final Batch Loss: 0.1475176364183426\n",
      "Epoch 2000, Loss: 0.25420976243913174, Final Batch Loss: 0.025906091555953026\n",
      "Epoch 2001, Loss: 0.31519192457199097, Final Batch Loss: 0.09095913171768188\n",
      "Epoch 2002, Loss: 0.3746107220649719, Final Batch Loss: 0.1559358835220337\n",
      "Epoch 2003, Loss: 0.4621951952576637, Final Batch Loss: 0.25120675563812256\n",
      "Epoch 2004, Loss: 0.33901297301054, Final Batch Loss: 0.13992883265018463\n",
      "Epoch 2005, Loss: 0.24449385702610016, Final Batch Loss: 0.019683808088302612\n",
      "Epoch 2006, Loss: 0.21863228548318148, Final Batch Loss: 0.009559881873428822\n",
      "Epoch 2007, Loss: 0.3361068516969681, Final Batch Loss: 0.13067397475242615\n",
      "Epoch 2008, Loss: 0.26828807964921, Final Batch Loss: 0.02388632670044899\n",
      "Epoch 2009, Loss: 0.31674372404813766, Final Batch Loss: 0.13177940249443054\n",
      "Epoch 2010, Loss: 0.3093782812356949, Final Batch Loss: 0.12088964134454727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2011, Loss: 0.2166435644030571, Final Batch Loss: 0.05074777454137802\n",
      "Epoch 2012, Loss: 0.2909645065665245, Final Batch Loss: 0.06423308700323105\n",
      "Epoch 2013, Loss: 0.48638156801462173, Final Batch Loss: 0.2999485731124878\n",
      "Epoch 2014, Loss: 0.30655457079410553, Final Batch Loss: 0.11457287520170212\n",
      "Epoch 2015, Loss: 0.4740276336669922, Final Batch Loss: 0.23065093159675598\n",
      "Epoch 2016, Loss: 0.5183393210172653, Final Batch Loss: 0.29402846097946167\n",
      "Epoch 2017, Loss: 0.34021177887916565, Final Batch Loss: 0.0905478224158287\n",
      "Epoch 2018, Loss: 0.35212960466742516, Final Batch Loss: 0.0517365001142025\n",
      "Epoch 2019, Loss: 0.6233010515570641, Final Batch Loss: 0.4305005967617035\n",
      "Epoch 2020, Loss: 0.32449357211589813, Final Batch Loss: 0.10448276251554489\n",
      "Epoch 2021, Loss: 0.3189572347328067, Final Batch Loss: 0.012096012942492962\n",
      "Epoch 2022, Loss: 0.4290090948343277, Final Batch Loss: 0.1591111570596695\n",
      "Epoch 2023, Loss: 0.2470630626194179, Final Batch Loss: 0.003222889732569456\n",
      "Epoch 2024, Loss: 0.44197453558444977, Final Batch Loss: 0.11717280745506287\n",
      "Epoch 2025, Loss: 0.26062170788645744, Final Batch Loss: 0.027026589959859848\n",
      "Epoch 2026, Loss: 0.29662409983575344, Final Batch Loss: 0.01765943132340908\n",
      "Epoch 2027, Loss: 0.4468209445476532, Final Batch Loss: 0.13658766448497772\n",
      "Epoch 2028, Loss: 0.4651445150375366, Final Batch Loss: 0.24106404185295105\n",
      "Epoch 2029, Loss: 0.5378734916448593, Final Batch Loss: 0.26834067702293396\n",
      "Epoch 2030, Loss: 0.3604629635810852, Final Batch Loss: 0.14550676941871643\n",
      "Epoch 2031, Loss: 0.3530232533812523, Final Batch Loss: 0.10923951864242554\n",
      "Epoch 2032, Loss: 0.2871166616678238, Final Batch Loss: 0.06482978910207748\n",
      "Epoch 2033, Loss: 0.5745192170143127, Final Batch Loss: 0.34525179862976074\n",
      "Epoch 2034, Loss: 0.4199799969792366, Final Batch Loss: 0.12488467991352081\n",
      "Epoch 2035, Loss: 0.3300001919269562, Final Batch Loss: 0.10890509188175201\n",
      "Epoch 2036, Loss: 0.3330110162496567, Final Batch Loss: 0.07361596822738647\n",
      "Epoch 2037, Loss: 0.31471726298332214, Final Batch Loss: 0.0914059579372406\n",
      "Epoch 2038, Loss: 0.3925263285636902, Final Batch Loss: 0.1820470094680786\n",
      "Epoch 2039, Loss: 0.6242844462394714, Final Batch Loss: 0.3292604386806488\n",
      "Epoch 2040, Loss: 0.5245183408260345, Final Batch Loss: 0.33306145668029785\n",
      "Epoch 2041, Loss: 0.3797091692686081, Final Batch Loss: 0.1707662045955658\n",
      "Epoch 2042, Loss: 0.5387713015079498, Final Batch Loss: 0.2761649489402771\n",
      "Epoch 2043, Loss: 0.5079422891139984, Final Batch Loss: 0.28012171387672424\n",
      "Epoch 2044, Loss: 0.4920981824398041, Final Batch Loss: 0.1860133409500122\n",
      "Epoch 2045, Loss: 0.42532581835985184, Final Batch Loss: 0.09479852765798569\n",
      "Epoch 2046, Loss: 0.29504634253680706, Final Batch Loss: 0.00960606150329113\n",
      "Epoch 2047, Loss: 0.3585902899503708, Final Batch Loss: 0.09062060713768005\n",
      "Epoch 2048, Loss: 0.35172051936388016, Final Batch Loss: 0.10258764773607254\n",
      "Epoch 2049, Loss: 0.7663414776325226, Final Batch Loss: 0.4537464380264282\n",
      "Epoch 2050, Loss: 0.31519508361816406, Final Batch Loss: 0.13600623607635498\n",
      "Epoch 2051, Loss: 0.3760465979576111, Final Batch Loss: 0.0728679820895195\n",
      "Epoch 2052, Loss: 0.27340812887996435, Final Batch Loss: 0.013727433048188686\n",
      "Epoch 2053, Loss: 0.2573038600385189, Final Batch Loss: 0.013745438307523727\n",
      "Epoch 2054, Loss: 0.21989747136831284, Final Batch Loss: 0.02470528334379196\n",
      "Epoch 2055, Loss: 0.4298532009124756, Final Batch Loss: 0.16914093494415283\n",
      "Epoch 2056, Loss: 0.24711468070745468, Final Batch Loss: 0.0712311714887619\n",
      "Epoch 2057, Loss: 0.4145146980881691, Final Batch Loss: 0.18840950727462769\n",
      "Epoch 2058, Loss: 0.32693294435739517, Final Batch Loss: 0.06573515385389328\n",
      "Epoch 2059, Loss: 0.3645137846469879, Final Batch Loss: 0.16231289505958557\n",
      "Epoch 2060, Loss: 0.2464570514857769, Final Batch Loss: 0.051406677812337875\n",
      "Epoch 2061, Loss: 0.2691676951944828, Final Batch Loss: 0.03925362601876259\n",
      "Epoch 2062, Loss: 0.4466603472828865, Final Batch Loss: 0.1937972903251648\n",
      "Epoch 2063, Loss: 0.2500848490744829, Final Batch Loss: 0.0204452071338892\n",
      "Epoch 2064, Loss: 0.5362723097205162, Final Batch Loss: 0.29588446021080017\n",
      "Epoch 2065, Loss: 0.25909859128296375, Final Batch Loss: 0.028177985921502113\n",
      "Epoch 2066, Loss: 0.2461700551211834, Final Batch Loss: 0.049918029457330704\n",
      "Epoch 2067, Loss: 0.23248011618852615, Final Batch Loss: 0.008005328476428986\n",
      "Epoch 2068, Loss: 0.24462327593937516, Final Batch Loss: 0.005870150867849588\n",
      "Epoch 2069, Loss: 0.4107768386602402, Final Batch Loss: 0.1038326621055603\n",
      "Epoch 2070, Loss: 0.44198431819677353, Final Batch Loss: 0.23711064457893372\n",
      "Epoch 2071, Loss: 0.28864817321300507, Final Batch Loss: 0.08326691389083862\n",
      "Epoch 2072, Loss: 0.39819957315921783, Final Batch Loss: 0.18931585550308228\n",
      "Epoch 2073, Loss: 0.29759717732667923, Final Batch Loss: 0.10507068037986755\n",
      "Epoch 2074, Loss: 0.31954530626535416, Final Batch Loss: 0.07766422629356384\n",
      "Epoch 2075, Loss: 0.2615737020969391, Final Batch Loss: 0.026026271283626556\n",
      "Epoch 2076, Loss: 0.38586824387311935, Final Batch Loss: 0.1585879772901535\n",
      "Epoch 2077, Loss: 0.44892289489507675, Final Batch Loss: 0.19351637363433838\n",
      "Epoch 2078, Loss: 0.5458835065364838, Final Batch Loss: 0.28188416361808777\n",
      "Epoch 2079, Loss: 0.31983180344104767, Final Batch Loss: 0.08828802406787872\n",
      "Epoch 2080, Loss: 0.4099583178758621, Final Batch Loss: 0.13128191232681274\n",
      "Epoch 2081, Loss: 0.33343303948640823, Final Batch Loss: 0.10641364008188248\n",
      "Epoch 2082, Loss: 0.3387114107608795, Final Batch Loss: 0.14173202216625214\n",
      "Epoch 2083, Loss: 0.47540032118558884, Final Batch Loss: 0.2249637097120285\n",
      "Epoch 2084, Loss: 0.4143289476633072, Final Batch Loss: 0.1839662790298462\n",
      "Epoch 2085, Loss: 0.5056541934609413, Final Batch Loss: 0.27651047706604004\n",
      "Epoch 2086, Loss: 0.402513712644577, Final Batch Loss: 0.22682473063468933\n",
      "Epoch 2087, Loss: 0.5010787472128868, Final Batch Loss: 0.2877051532268524\n",
      "Epoch 2088, Loss: 0.2780100554227829, Final Batch Loss: 0.05263570696115494\n",
      "Epoch 2089, Loss: 0.3098580986261368, Final Batch Loss: 0.08568555116653442\n",
      "Epoch 2090, Loss: 0.293186966329813, Final Batch Loss: 0.019859645515680313\n",
      "Epoch 2091, Loss: 0.3126506507396698, Final Batch Loss: 0.06962593644857407\n",
      "Epoch 2092, Loss: 0.23020491190254688, Final Batch Loss: 0.015120210126042366\n",
      "Epoch 2093, Loss: 0.34983763843774796, Final Batch Loss: 0.10758795589208603\n",
      "Epoch 2094, Loss: 0.25555069744586945, Final Batch Loss: 0.061984457075595856\n",
      "Epoch 2095, Loss: 0.2679492412135005, Final Batch Loss: 0.008735152892768383\n",
      "Epoch 2096, Loss: 0.2288532368838787, Final Batch Loss: 0.028494957834482193\n",
      "Epoch 2097, Loss: 0.5520487576723099, Final Batch Loss: 0.32918912172317505\n",
      "Epoch 2098, Loss: 0.26844221726059914, Final Batch Loss: 0.055094826966524124\n",
      "Epoch 2099, Loss: 0.38662969321012497, Final Batch Loss: 0.07487345486879349\n",
      "Epoch 2100, Loss: 0.47675370424985886, Final Batch Loss: 0.20664726197719574\n",
      "Epoch 2101, Loss: 0.3186970502138138, Final Batch Loss: 0.10719498991966248\n",
      "Epoch 2102, Loss: 0.4323132634162903, Final Batch Loss: 0.18580622971057892\n",
      "Epoch 2103, Loss: 0.32571448385715485, Final Batch Loss: 0.0709109753370285\n",
      "Epoch 2104, Loss: 0.41669274121522903, Final Batch Loss: 0.17230470478534698\n",
      "Epoch 2105, Loss: 0.4685795158147812, Final Batch Loss: 0.13240273296833038\n",
      "Epoch 2106, Loss: 0.26864198222756386, Final Batch Loss: 0.06134944036602974\n",
      "Epoch 2107, Loss: 0.4359712079167366, Final Batch Loss: 0.22888803482055664\n",
      "Epoch 2108, Loss: 0.42723869532346725, Final Batch Loss: 0.13179025053977966\n",
      "Epoch 2109, Loss: 0.23945808969438076, Final Batch Loss: 0.01740509830415249\n",
      "Epoch 2110, Loss: 0.48243068158626556, Final Batch Loss: 0.16753409802913666\n",
      "Epoch 2111, Loss: 0.4445801377296448, Final Batch Loss: 0.19392797350883484\n",
      "Epoch 2112, Loss: 0.6508328095078468, Final Batch Loss: 0.37839722633361816\n",
      "Epoch 2113, Loss: 0.4440169036388397, Final Batch Loss: 0.13635101914405823\n",
      "Epoch 2114, Loss: 0.3233662396669388, Final Batch Loss: 0.10717813670635223\n",
      "Epoch 2115, Loss: 0.29419590532779694, Final Batch Loss: 0.0361003577709198\n",
      "Epoch 2116, Loss: 0.31767021864652634, Final Batch Loss: 0.09521277993917465\n",
      "Epoch 2117, Loss: 0.32712535560131073, Final Batch Loss: 0.146922305226326\n",
      "Epoch 2118, Loss: 0.29565319418907166, Final Batch Loss: 0.11186779290437698\n",
      "Epoch 2119, Loss: 0.31836066395044327, Final Batch Loss: 0.07176430523395538\n",
      "Epoch 2120, Loss: 0.28172459453344345, Final Batch Loss: 0.04513360559940338\n",
      "Epoch 2121, Loss: 0.3282982036471367, Final Batch Loss: 0.0842554122209549\n",
      "Epoch 2122, Loss: 0.5704333633184433, Final Batch Loss: 0.34935814142227173\n",
      "Epoch 2123, Loss: 0.2619361951947212, Final Batch Loss: 0.05501469969749451\n",
      "Epoch 2124, Loss: 0.30880821868777275, Final Batch Loss: 0.04163559898734093\n",
      "Epoch 2125, Loss: 0.32806091755628586, Final Batch Loss: 0.06175161153078079\n",
      "Epoch 2126, Loss: 0.3794264644384384, Final Batch Loss: 0.16654731333255768\n",
      "Epoch 2127, Loss: 0.30606649816036224, Final Batch Loss: 0.10785671323537827\n",
      "Epoch 2128, Loss: 0.2710216250270605, Final Batch Loss: 0.019842786714434624\n",
      "Epoch 2129, Loss: 0.5183698385953903, Final Batch Loss: 0.29576563835144043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2130, Loss: 0.38164106756448746, Final Batch Loss: 0.18370790779590607\n",
      "Epoch 2131, Loss: 0.43281684815883636, Final Batch Loss: 0.15367941558361053\n",
      "Epoch 2132, Loss: 0.3597010597586632, Final Batch Loss: 0.16422763466835022\n",
      "Epoch 2133, Loss: 0.4321504160761833, Final Batch Loss: 0.2648316025733948\n",
      "Epoch 2134, Loss: 0.29610898345708847, Final Batch Loss: 0.06505896896123886\n",
      "Epoch 2135, Loss: 0.23953744024038315, Final Batch Loss: 0.018308736383914948\n",
      "Epoch 2136, Loss: 0.2770184725522995, Final Batch Loss: 0.021817125380039215\n",
      "Epoch 2137, Loss: 0.2976546175777912, Final Batch Loss: 0.04645906016230583\n",
      "Epoch 2138, Loss: 0.24713685922324657, Final Batch Loss: 0.0279396902769804\n",
      "Epoch 2139, Loss: 0.34174148738384247, Final Batch Loss: 0.10318422317504883\n",
      "Epoch 2140, Loss: 0.5694350302219391, Final Batch Loss: 0.42193126678466797\n",
      "Epoch 2141, Loss: 0.3253502678126097, Final Batch Loss: 0.027627242729067802\n",
      "Epoch 2142, Loss: 0.6069855988025665, Final Batch Loss: 0.324181467294693\n",
      "Epoch 2143, Loss: 0.5029380470514297, Final Batch Loss: 0.2529347240924835\n",
      "Epoch 2144, Loss: 0.2579802945256233, Final Batch Loss: 0.051472701132297516\n",
      "Epoch 2145, Loss: 0.41101667284965515, Final Batch Loss: 0.15234330296516418\n",
      "Epoch 2146, Loss: 0.21014109998941422, Final Batch Loss: 0.023112386465072632\n",
      "Epoch 2147, Loss: 0.7641486302018166, Final Batch Loss: 0.5812471508979797\n",
      "Epoch 2148, Loss: 0.37000010907649994, Final Batch Loss: 0.14938580989837646\n",
      "Epoch 2149, Loss: 0.2491576299071312, Final Batch Loss: 0.06068109720945358\n",
      "Epoch 2150, Loss: 0.4857117086648941, Final Batch Loss: 0.27496325969696045\n",
      "Epoch 2151, Loss: 0.3948509842157364, Final Batch Loss: 0.2082940638065338\n",
      "Epoch 2152, Loss: 0.29067976772785187, Final Batch Loss: 0.07373025268316269\n",
      "Epoch 2153, Loss: 0.220344515517354, Final Batch Loss: 0.018323177471756935\n",
      "Epoch 2154, Loss: 0.3413534313440323, Final Batch Loss: 0.10931779444217682\n",
      "Epoch 2155, Loss: 0.18856750056147575, Final Batch Loss: 0.031872380524873734\n",
      "Epoch 2156, Loss: 0.24837349355220795, Final Batch Loss: 0.028508566319942474\n",
      "Epoch 2157, Loss: 0.25621432065963745, Final Batch Loss: 0.06495778262615204\n",
      "Epoch 2158, Loss: 0.3466944769024849, Final Batch Loss: 0.14433534443378448\n",
      "Epoch 2159, Loss: 0.2881386410444975, Final Batch Loss: 0.019340625032782555\n",
      "Epoch 2160, Loss: 0.2790227308869362, Final Batch Loss: 0.022490687668323517\n",
      "Epoch 2161, Loss: 0.723884828388691, Final Batch Loss: 0.5056347250938416\n",
      "Epoch 2162, Loss: 0.27739423513412476, Final Batch Loss: 0.025261424481868744\n",
      "Epoch 2163, Loss: 0.6662752851843834, Final Batch Loss: 0.43718358874320984\n",
      "Epoch 2164, Loss: 0.364369198679924, Final Batch Loss: 0.08396974951028824\n",
      "Epoch 2165, Loss: 0.4850621968507767, Final Batch Loss: 0.14428573846817017\n",
      "Epoch 2166, Loss: 0.29048557858914137, Final Batch Loss: 0.014406654052436352\n",
      "Epoch 2167, Loss: 0.31446421705186367, Final Batch Loss: 0.01642928086221218\n",
      "Epoch 2168, Loss: 0.24903454491868615, Final Batch Loss: 0.005196771118789911\n",
      "Epoch 2169, Loss: 0.5690696686506271, Final Batch Loss: 0.21081073582172394\n",
      "Epoch 2170, Loss: 0.3979001119732857, Final Batch Loss: 0.15525463223457336\n",
      "Epoch 2171, Loss: 0.33534734323620796, Final Batch Loss: 0.04218660667538643\n",
      "Epoch 2172, Loss: 0.4124329909682274, Final Batch Loss: 0.12393917888402939\n",
      "Epoch 2173, Loss: 0.31140779703855515, Final Batch Loss: 0.07591632008552551\n",
      "Epoch 2174, Loss: 0.27278745733201504, Final Batch Loss: 0.017635008320212364\n",
      "Epoch 2175, Loss: 0.4812368080019951, Final Batch Loss: 0.2733931243419647\n",
      "Epoch 2176, Loss: 0.224016010761261, Final Batch Loss: 0.021008774638175964\n",
      "Epoch 2177, Loss: 0.25936952233314514, Final Batch Loss: 0.07419037818908691\n",
      "Epoch 2178, Loss: 0.3354051187634468, Final Batch Loss: 0.09033609181642532\n",
      "Epoch 2179, Loss: 0.325989730656147, Final Batch Loss: 0.13028255105018616\n",
      "Epoch 2180, Loss: 0.23512224107980728, Final Batch Loss: 0.06576602160930634\n",
      "Epoch 2181, Loss: 0.33428822085261345, Final Batch Loss: 0.06055205687880516\n",
      "Epoch 2182, Loss: 0.2717067040503025, Final Batch Loss: 0.05962913855910301\n",
      "Epoch 2183, Loss: 0.25186340510845184, Final Batch Loss: 0.09950985759496689\n",
      "Epoch 2184, Loss: 0.3483639657497406, Final Batch Loss: 0.12396012991666794\n",
      "Epoch 2185, Loss: 0.49884428828954697, Final Batch Loss: 0.3020705282688141\n",
      "Epoch 2186, Loss: 0.3178022801876068, Final Batch Loss: 0.07471407204866409\n",
      "Epoch 2187, Loss: 0.3575075641274452, Final Batch Loss: 0.10200441628694534\n",
      "Epoch 2188, Loss: 0.31694257259368896, Final Batch Loss: 0.06814473867416382\n",
      "Epoch 2189, Loss: 0.38341792672872543, Final Batch Loss: 0.11127505451440811\n",
      "Epoch 2190, Loss: 0.4380258470773697, Final Batch Loss: 0.14123481512069702\n",
      "Epoch 2191, Loss: 0.2758481502532959, Final Batch Loss: 0.038279175758361816\n",
      "Epoch 2192, Loss: 0.5055912509560585, Final Batch Loss: 0.2002570480108261\n",
      "Epoch 2193, Loss: 0.2804286517202854, Final Batch Loss: 0.038155656307935715\n",
      "Epoch 2194, Loss: 0.31884609907865524, Final Batch Loss: 0.06722527742385864\n",
      "Epoch 2195, Loss: 0.3259119987487793, Final Batch Loss: 0.034277141094207764\n",
      "Epoch 2196, Loss: 0.3521213196218014, Final Batch Loss: 0.0544368140399456\n",
      "Epoch 2197, Loss: 0.5023439526557922, Final Batch Loss: 0.20339635014533997\n",
      "Epoch 2198, Loss: 0.3379882164299488, Final Batch Loss: 0.04083682969212532\n",
      "Epoch 2199, Loss: 0.350152350962162, Final Batch Loss: 0.13095343112945557\n",
      "Epoch 2200, Loss: 0.34785085916519165, Final Batch Loss: 0.0868040919303894\n",
      "Epoch 2201, Loss: 0.3843417763710022, Final Batch Loss: 0.09357573837041855\n",
      "Epoch 2202, Loss: 0.3154482766985893, Final Batch Loss: 0.11092884838581085\n",
      "Epoch 2203, Loss: 0.4873701259493828, Final Batch Loss: 0.2672826945781708\n",
      "Epoch 2204, Loss: 0.3252228796482086, Final Batch Loss: 0.13011915981769562\n",
      "Epoch 2205, Loss: 0.3080604746937752, Final Batch Loss: 0.10417697578668594\n",
      "Epoch 2206, Loss: 0.39934664964675903, Final Batch Loss: 0.17482125759124756\n",
      "Epoch 2207, Loss: 0.47161970287561417, Final Batch Loss: 0.2814112603664398\n",
      "Epoch 2208, Loss: 0.3116631731390953, Final Batch Loss: 0.09664998203516006\n",
      "Epoch 2209, Loss: 0.2851964645087719, Final Batch Loss: 0.04299971088767052\n",
      "Epoch 2210, Loss: 0.24716720823198557, Final Batch Loss: 0.01253566239029169\n",
      "Epoch 2211, Loss: 0.22860164567828178, Final Batch Loss: 0.04927634075284004\n",
      "Epoch 2212, Loss: 0.25342245399951935, Final Batch Loss: 0.05786857008934021\n",
      "Epoch 2213, Loss: 0.1856365855783224, Final Batch Loss: 0.020013784989714622\n",
      "Epoch 2214, Loss: 0.270635724067688, Final Batch Loss: 0.019100330770015717\n",
      "Epoch 2215, Loss: 0.28282126784324646, Final Batch Loss: 0.11606448888778687\n",
      "Epoch 2216, Loss: 0.299648642539978, Final Batch Loss: 0.13225306570529938\n",
      "Epoch 2217, Loss: 0.4014147222042084, Final Batch Loss: 0.22487419843673706\n",
      "Epoch 2218, Loss: 0.34207890927791595, Final Batch Loss: 0.12037937343120575\n",
      "Epoch 2219, Loss: 0.3466074988245964, Final Batch Loss: 0.18583758175373077\n",
      "Epoch 2220, Loss: 0.3930091932415962, Final Batch Loss: 0.15156926214694977\n",
      "Epoch 2221, Loss: 0.3830852657556534, Final Batch Loss: 0.11887913942337036\n",
      "Epoch 2222, Loss: 0.22129254136234522, Final Batch Loss: 0.005910822190344334\n",
      "Epoch 2223, Loss: 0.4314916282892227, Final Batch Loss: 0.21569402515888214\n",
      "Epoch 2224, Loss: 0.46403543651103973, Final Batch Loss: 0.22247450053691864\n",
      "Epoch 2225, Loss: 0.2681196816265583, Final Batch Loss: 0.05881481245160103\n",
      "Epoch 2226, Loss: 0.5638158470392227, Final Batch Loss: 0.29236146807670593\n",
      "Epoch 2227, Loss: 0.23058143258094788, Final Batch Loss: 0.02185368537902832\n",
      "Epoch 2228, Loss: 0.32732249796390533, Final Batch Loss: 0.0969507023692131\n",
      "Epoch 2229, Loss: 0.3392784222960472, Final Batch Loss: 0.125461146235466\n",
      "Epoch 2230, Loss: 0.5781649500131607, Final Batch Loss: 0.3324755132198334\n",
      "Epoch 2231, Loss: 0.4423545077443123, Final Batch Loss: 0.16803927719593048\n",
      "Epoch 2232, Loss: 0.32659655064344406, Final Batch Loss: 0.09406278282403946\n",
      "Epoch 2233, Loss: 0.30992409586906433, Final Batch Loss: 0.12403549998998642\n",
      "Epoch 2234, Loss: 0.3828857094049454, Final Batch Loss: 0.19842848181724548\n",
      "Epoch 2235, Loss: 0.36006129533052444, Final Batch Loss: 0.14449740946292877\n",
      "Epoch 2236, Loss: 0.38867922872304916, Final Batch Loss: 0.1603047400712967\n",
      "Epoch 2237, Loss: 0.3482922539114952, Final Batch Loss: 0.09446471184492111\n",
      "Epoch 2238, Loss: 0.2581105874851346, Final Batch Loss: 0.00960842240601778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2239, Loss: 0.4826320707798004, Final Batch Loss: 0.30543607473373413\n",
      "Epoch 2240, Loss: 0.47867464274168015, Final Batch Loss: 0.2510051727294922\n",
      "Epoch 2241, Loss: 0.2536771073937416, Final Batch Loss: 0.006571583449840546\n",
      "Epoch 2242, Loss: 0.2885802499949932, Final Batch Loss: 0.026258882135152817\n",
      "Epoch 2243, Loss: 0.36013059318065643, Final Batch Loss: 0.1115020290017128\n",
      "Epoch 2244, Loss: 0.36071331799030304, Final Batch Loss: 0.11502904444932938\n",
      "Epoch 2245, Loss: 0.2876939959824085, Final Batch Loss: 0.05970066413283348\n",
      "Epoch 2246, Loss: 0.3087790906429291, Final Batch Loss: 0.09424511343240738\n",
      "Epoch 2247, Loss: 0.2489645667374134, Final Batch Loss: 0.044245097786188126\n",
      "Epoch 2248, Loss: 0.3123568370938301, Final Batch Loss: 0.08503637462854385\n",
      "Epoch 2249, Loss: 0.31378741562366486, Final Batch Loss: 0.10073031485080719\n",
      "Epoch 2250, Loss: 0.2565734423696995, Final Batch Loss: 0.03162341192364693\n",
      "Epoch 2251, Loss: 0.2072099894285202, Final Batch Loss: 0.015349864959716797\n",
      "Epoch 2252, Loss: 0.22231712564826012, Final Batch Loss: 0.030176762491464615\n",
      "Epoch 2253, Loss: 0.27318983525037766, Final Batch Loss: 0.10201980173587799\n",
      "Epoch 2254, Loss: 0.2508738785982132, Final Batch Loss: 0.07863380759954453\n",
      "Epoch 2255, Loss: 0.3241519033908844, Final Batch Loss: 0.07592456042766571\n",
      "Epoch 2256, Loss: 0.3944801837205887, Final Batch Loss: 0.2144315093755722\n",
      "Epoch 2257, Loss: 0.2950453981757164, Final Batch Loss: 0.15426085889339447\n",
      "Epoch 2258, Loss: 0.3881043419241905, Final Batch Loss: 0.19799387454986572\n",
      "Epoch 2259, Loss: 0.22169987484812737, Final Batch Loss: 0.018533658236265182\n",
      "Epoch 2260, Loss: 0.2787485644221306, Final Batch Loss: 0.01637227088212967\n",
      "Epoch 2261, Loss: 0.2797230929136276, Final Batch Loss: 0.06422857195138931\n",
      "Epoch 2262, Loss: 0.2182597778737545, Final Batch Loss: 0.0010356418788433075\n",
      "Epoch 2263, Loss: 0.2443666523322463, Final Batch Loss: 0.008550665341317654\n",
      "Epoch 2264, Loss: 0.36009472608566284, Final Batch Loss: 0.11570827662944794\n",
      "Epoch 2265, Loss: 0.32989952713251114, Final Batch Loss: 0.1386551707983017\n",
      "Epoch 2266, Loss: 0.25225067138671875, Final Batch Loss: 0.09341754764318466\n",
      "Epoch 2267, Loss: 0.218087550252676, Final Batch Loss: 0.025038976222276688\n",
      "Epoch 2268, Loss: 0.3550344929099083, Final Batch Loss: 0.13178272545337677\n",
      "Epoch 2269, Loss: 0.43753020465373993, Final Batch Loss: 0.17009715735912323\n",
      "Epoch 2270, Loss: 0.2512570656836033, Final Batch Loss: 0.048794087022542953\n",
      "Epoch 2271, Loss: 0.2910686358809471, Final Batch Loss: 0.10343551635742188\n",
      "Epoch 2272, Loss: 0.3249720297753811, Final Batch Loss: 0.043165821582078934\n",
      "Epoch 2273, Loss: 0.32595840841531754, Final Batch Loss: 0.12943598628044128\n",
      "Epoch 2274, Loss: 0.31476324051618576, Final Batch Loss: 0.0588560476899147\n",
      "Epoch 2275, Loss: 0.29166582226753235, Final Batch Loss: 0.08846559375524521\n",
      "Epoch 2276, Loss: 0.35243675857782364, Final Batch Loss: 0.11286666244268417\n",
      "Epoch 2277, Loss: 0.2165239304304123, Final Batch Loss: 0.06293217837810516\n",
      "Epoch 2278, Loss: 0.19440510659478605, Final Batch Loss: 0.0030546390917152166\n",
      "Epoch 2279, Loss: 0.21320322155952454, Final Batch Loss: 0.01108270138502121\n",
      "Epoch 2280, Loss: 0.20413031987845898, Final Batch Loss: 0.018132491037249565\n",
      "Epoch 2281, Loss: 0.23764322698116302, Final Batch Loss: 0.06261581927537918\n",
      "Epoch 2282, Loss: 0.24780379608273506, Final Batch Loss: 0.0421716533601284\n",
      "Epoch 2283, Loss: 0.2926854304969311, Final Batch Loss: 0.04892926290631294\n",
      "Epoch 2284, Loss: 0.4222230613231659, Final Batch Loss: 0.17675751447677612\n",
      "Epoch 2285, Loss: 0.4011099487543106, Final Batch Loss: 0.1392025500535965\n",
      "Epoch 2286, Loss: 0.22170086577534676, Final Batch Loss: 0.023001473397016525\n",
      "Epoch 2287, Loss: 0.39790043234825134, Final Batch Loss: 0.0761689692735672\n",
      "Epoch 2288, Loss: 0.25960749201476574, Final Batch Loss: 0.0305319931358099\n",
      "Epoch 2289, Loss: 0.39179420471191406, Final Batch Loss: 0.1672370731830597\n",
      "Epoch 2290, Loss: 0.18758499389514327, Final Batch Loss: 0.006256540771573782\n",
      "Epoch 2291, Loss: 0.1967566180974245, Final Batch Loss: 0.020624497905373573\n",
      "Epoch 2292, Loss: 0.19360629841685295, Final Batch Loss: 0.022469352930784225\n",
      "Epoch 2293, Loss: 0.18749882280826569, Final Batch Loss: 0.02995886653661728\n",
      "Epoch 2294, Loss: 0.167670346039813, Final Batch Loss: 0.0007060311618261039\n",
      "Epoch 2295, Loss: 0.2915572188794613, Final Batch Loss: 0.1352723389863968\n",
      "Epoch 2296, Loss: 0.6035471335053444, Final Batch Loss: 0.41194573044776917\n",
      "Epoch 2297, Loss: 0.3653459772467613, Final Batch Loss: 0.19661004841327667\n",
      "Epoch 2298, Loss: 0.46190938353538513, Final Batch Loss: 0.1373143196105957\n",
      "Epoch 2299, Loss: 0.6718075796961784, Final Batch Loss: 0.4366151988506317\n",
      "Epoch 2300, Loss: 0.21323716267943382, Final Batch Loss: 0.030842524021863937\n",
      "Epoch 2301, Loss: 0.260523309931159, Final Batch Loss: 0.023283345624804497\n",
      "Epoch 2302, Loss: 0.4059087038040161, Final Batch Loss: 0.0946628749370575\n",
      "Epoch 2303, Loss: 0.7213549688458443, Final Batch Loss: 0.4296073913574219\n",
      "Epoch 2304, Loss: 0.3262331038713455, Final Batch Loss: 0.06924024224281311\n",
      "Epoch 2305, Loss: 0.25950032100081444, Final Batch Loss: 0.038953762501478195\n",
      "Epoch 2306, Loss: 0.32929011434316635, Final Batch Loss: 0.07734238356351852\n",
      "Epoch 2307, Loss: 0.4154282212257385, Final Batch Loss: 0.12345361709594727\n",
      "Epoch 2308, Loss: 0.22561069950461388, Final Batch Loss: 0.0266331247985363\n",
      "Epoch 2309, Loss: 0.2601838447153568, Final Batch Loss: 0.04576490446925163\n",
      "Epoch 2310, Loss: 0.3750869110226631, Final Batch Loss: 0.1826503723859787\n",
      "Epoch 2311, Loss: 0.24736681208014488, Final Batch Loss: 0.05454463139176369\n",
      "Epoch 2312, Loss: 0.33391813933849335, Final Batch Loss: 0.0895819291472435\n",
      "Epoch 2313, Loss: 0.40409883111715317, Final Batch Loss: 0.1961323618888855\n",
      "Epoch 2314, Loss: 0.31889550387859344, Final Batch Loss: 0.07457772642374039\n",
      "Epoch 2315, Loss: 0.26303487829864025, Final Batch Loss: 0.01614091359078884\n",
      "Epoch 2316, Loss: 0.3721980154514313, Final Batch Loss: 0.13294827938079834\n",
      "Epoch 2317, Loss: 0.32634807378053665, Final Batch Loss: 0.12001274526119232\n",
      "Epoch 2318, Loss: 0.49866995960474014, Final Batch Loss: 0.30047330260276794\n",
      "Epoch 2319, Loss: 0.5205551236867905, Final Batch Loss: 0.18869540095329285\n",
      "Epoch 2320, Loss: 0.8439201861619949, Final Batch Loss: 0.4177004098892212\n",
      "Epoch 2321, Loss: 0.4579610675573349, Final Batch Loss: 0.11738388240337372\n",
      "Epoch 2322, Loss: 0.6041897237300873, Final Batch Loss: 0.2112874537706375\n",
      "Epoch 2323, Loss: 0.5516435280442238, Final Batch Loss: 0.264408141374588\n",
      "Epoch 2324, Loss: 0.41340167820453644, Final Batch Loss: 0.11459152400493622\n",
      "Epoch 2325, Loss: 0.40230388985946774, Final Batch Loss: 0.0028328155167400837\n",
      "Epoch 2326, Loss: 0.6253885477781296, Final Batch Loss: 0.2370615452528\n",
      "Epoch 2327, Loss: 0.451300784945488, Final Batch Loss: 0.07115618884563446\n",
      "Epoch 2328, Loss: 0.5020251274108887, Final Batch Loss: 0.2485717535018921\n",
      "Epoch 2329, Loss: 0.30932755395770073, Final Batch Loss: 0.02278577908873558\n",
      "Epoch 2330, Loss: 0.4541703760623932, Final Batch Loss: 0.14899002015590668\n",
      "Epoch 2331, Loss: 0.5619779676198959, Final Batch Loss: 0.27277812361717224\n",
      "Epoch 2332, Loss: 0.43170754611492157, Final Batch Loss: 0.06973004341125488\n",
      "Epoch 2333, Loss: 0.48386380821466446, Final Batch Loss: 0.12306288629770279\n",
      "Epoch 2334, Loss: 0.48824477940797806, Final Batch Loss: 0.19640567898750305\n",
      "Epoch 2335, Loss: 0.3537634424865246, Final Batch Loss: 0.05549691244959831\n",
      "Epoch 2336, Loss: 0.2693743221461773, Final Batch Loss: 0.004131641238927841\n",
      "Epoch 2337, Loss: 0.4685193672776222, Final Batch Loss: 0.18857744336128235\n",
      "Epoch 2338, Loss: 0.2480321042239666, Final Batch Loss: 0.020190928131341934\n",
      "Epoch 2339, Loss: 0.3995649516582489, Final Batch Loss: 0.14891988039016724\n",
      "Epoch 2340, Loss: 0.36344432830810547, Final Batch Loss: 0.09967460483312607\n",
      "Epoch 2341, Loss: 0.44412002712488174, Final Batch Loss: 0.21427826583385468\n",
      "Epoch 2342, Loss: 0.548296608030796, Final Batch Loss: 0.3050098419189453\n",
      "Epoch 2343, Loss: 0.31792116165161133, Final Batch Loss: 0.0421975702047348\n",
      "Epoch 2344, Loss: 0.7519528865814209, Final Batch Loss: 0.4928418695926666\n",
      "Epoch 2345, Loss: 0.3138347715139389, Final Batch Loss: 0.023906365036964417\n",
      "Epoch 2346, Loss: 0.2446397808380425, Final Batch Loss: 0.005889114458113909\n",
      "Epoch 2347, Loss: 0.3207719847559929, Final Batch Loss: 0.07145703583955765\n",
      "Epoch 2348, Loss: 0.2833462692797184, Final Batch Loss: 0.044351112097501755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2349, Loss: 0.39764638990163803, Final Batch Loss: 0.15588054060935974\n",
      "Epoch 2350, Loss: 0.34400610625743866, Final Batch Loss: 0.08724929392337799\n",
      "Epoch 2351, Loss: 0.27850404754281044, Final Batch Loss: 0.03874977305531502\n",
      "Epoch 2352, Loss: 0.4549393132328987, Final Batch Loss: 0.2502925395965576\n",
      "Epoch 2353, Loss: 0.34709352999925613, Final Batch Loss: 0.1291273832321167\n",
      "Epoch 2354, Loss: 0.2852061465382576, Final Batch Loss: 0.06123724579811096\n",
      "Epoch 2355, Loss: 0.3555891811847687, Final Batch Loss: 0.1617497205734253\n",
      "Epoch 2356, Loss: 0.3491279259324074, Final Batch Loss: 0.08003852516412735\n",
      "Epoch 2357, Loss: 0.3043205365538597, Final Batch Loss: 0.08739807456731796\n",
      "Epoch 2358, Loss: 0.33650295436382294, Final Batch Loss: 0.16864700615406036\n",
      "Epoch 2359, Loss: 0.2701387591660023, Final Batch Loss: 0.09524406492710114\n",
      "Epoch 2360, Loss: 0.31290361285209656, Final Batch Loss: 0.06714796274900436\n",
      "Epoch 2361, Loss: 0.3576810136437416, Final Batch Loss: 0.08835365623235703\n",
      "Epoch 2362, Loss: 0.45828545838594437, Final Batch Loss: 0.2074304223060608\n",
      "Epoch 2363, Loss: 0.4032030627131462, Final Batch Loss: 0.1840568631887436\n",
      "Epoch 2364, Loss: 0.364835761487484, Final Batch Loss: 0.07578589767217636\n",
      "Epoch 2365, Loss: 0.3407029118388891, Final Batch Loss: 0.018221741542220116\n",
      "Epoch 2366, Loss: 0.359534814953804, Final Batch Loss: 0.15750238299369812\n",
      "Epoch 2367, Loss: 0.3456881418824196, Final Batch Loss: 0.13088344037532806\n",
      "Epoch 2368, Loss: 0.3115442730486393, Final Batch Loss: 0.02478310838341713\n",
      "Epoch 2369, Loss: 0.3288365751504898, Final Batch Loss: 0.08125889301300049\n",
      "Epoch 2370, Loss: 0.3175795152783394, Final Batch Loss: 0.13215357065200806\n",
      "Epoch 2371, Loss: 0.2262531854212284, Final Batch Loss: 0.03163422271609306\n",
      "Epoch 2372, Loss: 0.3749288246035576, Final Batch Loss: 0.1373768299818039\n",
      "Epoch 2373, Loss: 0.18639058992266655, Final Batch Loss: 0.020980630069971085\n",
      "Epoch 2374, Loss: 0.2661943584680557, Final Batch Loss: 0.04420307278633118\n",
      "Epoch 2375, Loss: 0.3024631552398205, Final Batch Loss: 0.039260853081941605\n",
      "Epoch 2376, Loss: 0.2673796718008816, Final Batch Loss: 0.004367426503449678\n",
      "Epoch 2377, Loss: 0.3293817788362503, Final Batch Loss: 0.136777862906456\n",
      "Epoch 2378, Loss: 0.22225629538297653, Final Batch Loss: 0.09340696781873703\n",
      "Epoch 2379, Loss: 0.2737930044531822, Final Batch Loss: 0.10962517559528351\n",
      "Epoch 2380, Loss: 0.3968932032585144, Final Batch Loss: 0.14789050817489624\n",
      "Epoch 2381, Loss: 0.27291252464056015, Final Batch Loss: 0.03513085097074509\n",
      "Epoch 2382, Loss: 0.444204643368721, Final Batch Loss: 0.1749030500650406\n",
      "Epoch 2383, Loss: 0.22849394846707582, Final Batch Loss: 0.011215959675610065\n",
      "Epoch 2384, Loss: 0.37915387004613876, Final Batch Loss: 0.14853250980377197\n",
      "Epoch 2385, Loss: 0.26194837130606174, Final Batch Loss: 0.008044788613915443\n",
      "Epoch 2386, Loss: 0.3838324397802353, Final Batch Loss: 0.16004297137260437\n",
      "Epoch 2387, Loss: 0.25011996272951365, Final Batch Loss: 0.00844548735767603\n",
      "Epoch 2388, Loss: 0.39610543847084045, Final Batch Loss: 0.17121201753616333\n",
      "Epoch 2389, Loss: 0.2953658998012543, Final Batch Loss: 0.11510773748159409\n",
      "Epoch 2390, Loss: 0.5645750164985657, Final Batch Loss: 0.3440670073032379\n",
      "Epoch 2391, Loss: 0.21087107248604298, Final Batch Loss: 0.01953510381281376\n",
      "Epoch 2392, Loss: 0.30532294139266014, Final Batch Loss: 0.0611010305583477\n",
      "Epoch 2393, Loss: 0.33846374601125717, Final Batch Loss: 0.013593398034572601\n",
      "Epoch 2394, Loss: 0.38631392270326614, Final Batch Loss: 0.08594486862421036\n",
      "Epoch 2395, Loss: 0.31310808658599854, Final Batch Loss: 0.1128159686923027\n",
      "Epoch 2396, Loss: 0.2810491472482681, Final Batch Loss: 0.07315933704376221\n",
      "Epoch 2397, Loss: 0.32324282079935074, Final Batch Loss: 0.09330105036497116\n",
      "Epoch 2398, Loss: 0.28245267271995544, Final Batch Loss: 0.06928343325853348\n",
      "Epoch 2399, Loss: 0.24701275303959846, Final Batch Loss: 0.062458585947752\n",
      "Epoch 2400, Loss: 0.16754743084311485, Final Batch Loss: 0.02395416796207428\n",
      "Epoch 2401, Loss: 0.18421263713389635, Final Batch Loss: 0.00747296679764986\n",
      "Epoch 2402, Loss: 0.2537815012037754, Final Batch Loss: 0.046362873166799545\n",
      "Epoch 2403, Loss: 0.23031871765851974, Final Batch Loss: 0.07063481956720352\n",
      "Epoch 2404, Loss: 0.3391871675848961, Final Batch Loss: 0.1574927568435669\n",
      "Epoch 2405, Loss: 0.3279130831360817, Final Batch Loss: 0.12422849237918854\n",
      "Epoch 2406, Loss: 0.2832675725221634, Final Batch Loss: 0.09823844581842422\n",
      "Epoch 2407, Loss: 0.2899825870990753, Final Batch Loss: 0.10864560306072235\n",
      "Epoch 2408, Loss: 0.2824075222015381, Final Batch Loss: 0.15769949555397034\n",
      "Epoch 2409, Loss: 0.3008960112929344, Final Batch Loss: 0.1639593094587326\n",
      "Epoch 2410, Loss: 0.282223142683506, Final Batch Loss: 0.07163151353597641\n",
      "Epoch 2411, Loss: 0.25977589562535286, Final Batch Loss: 0.05202886834740639\n",
      "Epoch 2412, Loss: 0.347378496080637, Final Batch Loss: 0.22739270329475403\n",
      "Epoch 2413, Loss: 0.256745059043169, Final Batch Loss: 0.030384976416826248\n",
      "Epoch 2414, Loss: 0.21519766002893448, Final Batch Loss: 0.05785027891397476\n",
      "Epoch 2415, Loss: 0.24425719678401947, Final Batch Loss: 0.08330828696489334\n",
      "Epoch 2416, Loss: 0.2933376133441925, Final Batch Loss: 0.09644361585378647\n",
      "Epoch 2417, Loss: 0.3941726088523865, Final Batch Loss: 0.17212921380996704\n",
      "Epoch 2418, Loss: 0.23773721605539322, Final Batch Loss: 0.038802072405815125\n",
      "Epoch 2419, Loss: 0.3222236856818199, Final Batch Loss: 0.11361093074083328\n",
      "Epoch 2420, Loss: 0.30067744851112366, Final Batch Loss: 0.15076108276844025\n",
      "Epoch 2421, Loss: 0.2815850079059601, Final Batch Loss: 0.07985109090805054\n",
      "Epoch 2422, Loss: 0.24931057542562485, Final Batch Loss: 0.08830803632736206\n",
      "Epoch 2423, Loss: 0.1934148408472538, Final Batch Loss: 0.045129064470529556\n",
      "Epoch 2424, Loss: 0.20212966948747635, Final Batch Loss: 0.0065999627113342285\n",
      "Epoch 2425, Loss: 0.49508824944496155, Final Batch Loss: 0.2868269979953766\n",
      "Epoch 2426, Loss: 0.21021513640880585, Final Batch Loss: 0.02985493093729019\n",
      "Epoch 2427, Loss: 0.5537730604410172, Final Batch Loss: 0.3782234489917755\n",
      "Epoch 2428, Loss: 0.38942260295152664, Final Batch Loss: 0.08343859761953354\n",
      "Epoch 2429, Loss: 0.3566935695707798, Final Batch Loss: 0.036486316472291946\n",
      "Epoch 2430, Loss: 0.3640097975730896, Final Batch Loss: 0.05610266327857971\n",
      "Epoch 2431, Loss: 0.2985537275671959, Final Batch Loss: 0.05277760326862335\n",
      "Epoch 2432, Loss: 0.20898935198783875, Final Batch Loss: 0.017547711730003357\n",
      "Epoch 2433, Loss: 0.2670927122235298, Final Batch Loss: 0.05171225219964981\n",
      "Epoch 2434, Loss: 0.24479407537728548, Final Batch Loss: 0.01077726949006319\n",
      "Epoch 2435, Loss: 0.34306391328573227, Final Batch Loss: 0.10718876123428345\n",
      "Epoch 2436, Loss: 0.39448632299900055, Final Batch Loss: 0.15907813608646393\n",
      "Epoch 2437, Loss: 0.32299042493104935, Final Batch Loss: 0.15220844745635986\n",
      "Epoch 2438, Loss: 0.42946957051754, Final Batch Loss: 0.15625491738319397\n",
      "Epoch 2439, Loss: 0.41893867403268814, Final Batch Loss: 0.22426025569438934\n",
      "Epoch 2440, Loss: 0.28214411437511444, Final Batch Loss: 0.07670388370752335\n",
      "Epoch 2441, Loss: 0.40450894087553024, Final Batch Loss: 0.06023808568716049\n",
      "Epoch 2442, Loss: 0.33118147403001785, Final Batch Loss: 0.11118664592504501\n",
      "Epoch 2443, Loss: 0.2714264392852783, Final Batch Loss: 0.040337733924388885\n",
      "Epoch 2444, Loss: 0.326590433716774, Final Batch Loss: 0.1003849133849144\n",
      "Epoch 2445, Loss: 0.38646697998046875, Final Batch Loss: 0.09671329706907272\n",
      "Epoch 2446, Loss: 0.27183400839567184, Final Batch Loss: 0.05492863059043884\n",
      "Epoch 2447, Loss: 0.47034870088100433, Final Batch Loss: 0.22387030720710754\n",
      "Epoch 2448, Loss: 0.49797965586185455, Final Batch Loss: 0.2543562948703766\n",
      "Epoch 2449, Loss: 0.4690438434481621, Final Batch Loss: 0.2248394638299942\n",
      "Epoch 2450, Loss: 0.5902026444673538, Final Batch Loss: 0.2052115947008133\n",
      "Epoch 2451, Loss: 0.5258810371160507, Final Batch Loss: 0.24537277221679688\n",
      "Epoch 2452, Loss: 0.2872908376157284, Final Batch Loss: 0.01816559210419655\n",
      "Epoch 2453, Loss: 0.432942196726799, Final Batch Loss: 0.1821371167898178\n",
      "Epoch 2454, Loss: 0.3067491874098778, Final Batch Loss: 0.06413894146680832\n",
      "Epoch 2455, Loss: 0.5220447182655334, Final Batch Loss: 0.21659506857395172\n",
      "Epoch 2456, Loss: 0.30305361095815897, Final Batch Loss: 0.008155309595167637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2457, Loss: 0.26869146153330803, Final Batch Loss: 0.05150587484240532\n",
      "Epoch 2458, Loss: 0.35385438054800034, Final Batch Loss: 0.15397389233112335\n",
      "Epoch 2459, Loss: 0.3985312879085541, Final Batch Loss: 0.156751811504364\n",
      "Epoch 2460, Loss: 0.4802909716963768, Final Batch Loss: 0.22566235065460205\n",
      "Epoch 2461, Loss: 0.3974369764328003, Final Batch Loss: 0.21961839497089386\n",
      "Epoch 2462, Loss: 0.3324001133441925, Final Batch Loss: 0.1476931869983673\n",
      "Epoch 2463, Loss: 0.5179133862257004, Final Batch Loss: 0.30792519450187683\n",
      "Epoch 2464, Loss: 0.31235049292445183, Final Batch Loss: 0.058582011610269547\n",
      "Epoch 2465, Loss: 0.4698996916413307, Final Batch Loss: 0.215079203248024\n",
      "Epoch 2466, Loss: 0.2610866464674473, Final Batch Loss: 0.03036314621567726\n",
      "Epoch 2467, Loss: 0.3392324298620224, Final Batch Loss: 0.14505569636821747\n",
      "Epoch 2468, Loss: 0.26531700044870377, Final Batch Loss: 0.10234998911619186\n",
      "Epoch 2469, Loss: 0.31074030697345734, Final Batch Loss: 0.14651255309581757\n",
      "Epoch 2470, Loss: 0.30794183164834976, Final Batch Loss: 0.11582580208778381\n",
      "Epoch 2471, Loss: 0.4408970773220062, Final Batch Loss: 0.14095675945281982\n",
      "Epoch 2472, Loss: 0.5462023764848709, Final Batch Loss: 0.3191421926021576\n",
      "Epoch 2473, Loss: 0.31559940427541733, Final Batch Loss: 0.058529943227767944\n",
      "Epoch 2474, Loss: 0.48370613902807236, Final Batch Loss: 0.252450555562973\n",
      "Epoch 2475, Loss: 0.32739417999982834, Final Batch Loss: 0.119218610227108\n",
      "Epoch 2476, Loss: 0.3098030984401703, Final Batch Loss: 0.08716502785682678\n",
      "Epoch 2477, Loss: 0.28045284003019333, Final Batch Loss: 0.07428368926048279\n",
      "Epoch 2478, Loss: 0.2721703499555588, Final Batch Loss: 0.08611693233251572\n",
      "Epoch 2479, Loss: 0.2670787423849106, Final Batch Loss: 0.089283287525177\n",
      "Epoch 2480, Loss: 0.6005419120192528, Final Batch Loss: 0.4227212965488434\n",
      "Epoch 2481, Loss: 0.20552480220794678, Final Batch Loss: 0.028376221656799316\n",
      "Epoch 2482, Loss: 0.2540115788578987, Final Batch Loss: 0.08186867088079453\n",
      "Epoch 2483, Loss: 0.2687891125679016, Final Batch Loss: 0.10412321239709854\n",
      "Epoch 2484, Loss: 0.2840454801917076, Final Batch Loss: 0.09460575878620148\n",
      "Epoch 2485, Loss: 0.17254159972071648, Final Batch Loss: 0.01528533548116684\n",
      "Epoch 2486, Loss: 0.1772423069924116, Final Batch Loss: 0.01708434335887432\n",
      "Epoch 2487, Loss: 0.37285972386598587, Final Batch Loss: 0.18010081350803375\n",
      "Epoch 2488, Loss: 0.25786279141902924, Final Batch Loss: 0.10271207988262177\n",
      "Epoch 2489, Loss: 0.26584451645612717, Final Batch Loss: 0.01374664157629013\n",
      "Epoch 2490, Loss: 0.4802183210849762, Final Batch Loss: 0.2931293547153473\n",
      "Epoch 2491, Loss: 0.2819347381591797, Final Batch Loss: 0.10422836989164352\n",
      "Epoch 2492, Loss: 0.332127183675766, Final Batch Loss: 0.11912998557090759\n",
      "Epoch 2493, Loss: 0.21252495236694813, Final Batch Loss: 0.021816039457917213\n",
      "Epoch 2494, Loss: 0.19704947248101234, Final Batch Loss: 0.03849685564637184\n",
      "Epoch 2495, Loss: 0.2040050271898508, Final Batch Loss: 0.013713749125599861\n",
      "Epoch 2496, Loss: 0.21050520241260529, Final Batch Loss: 0.04622006416320801\n",
      "Epoch 2497, Loss: 0.24229103326797485, Final Batch Loss: 0.059690624475479126\n",
      "Epoch 2498, Loss: 0.18415194377303123, Final Batch Loss: 0.019299890846014023\n",
      "Epoch 2499, Loss: 0.4039210006594658, Final Batch Loss: 0.18283729255199432\n",
      "Epoch 2500, Loss: 0.19824872352182865, Final Batch Loss: 0.019981900230050087\n",
      "Epoch 2501, Loss: 0.21355029940605164, Final Batch Loss: 0.06627681106328964\n",
      "Epoch 2502, Loss: 0.3381182327866554, Final Batch Loss: 0.14002713561058044\n",
      "Epoch 2503, Loss: 0.17107454128563404, Final Batch Loss: 0.0024820659309625626\n",
      "Epoch 2504, Loss: 0.3552630916237831, Final Batch Loss: 0.13771450519561768\n",
      "Epoch 2505, Loss: 0.3831426352262497, Final Batch Loss: 0.22195778787136078\n",
      "Epoch 2506, Loss: 0.4042128399014473, Final Batch Loss: 0.1737101823091507\n",
      "Epoch 2507, Loss: 0.2376616895198822, Final Batch Loss: 0.05614480376243591\n",
      "Epoch 2508, Loss: 0.3302217125892639, Final Batch Loss: 0.14492473006248474\n",
      "Epoch 2509, Loss: 0.24038591980934143, Final Batch Loss: 0.0790724903345108\n",
      "Epoch 2510, Loss: 0.2470935694873333, Final Batch Loss: 0.08254561573266983\n",
      "Epoch 2511, Loss: 0.4515593573451042, Final Batch Loss: 0.2840256690979004\n",
      "Epoch 2512, Loss: 0.26198242977261543, Final Batch Loss: 0.03901712968945503\n",
      "Epoch 2513, Loss: 0.2526082582771778, Final Batch Loss: 0.09317544847726822\n",
      "Epoch 2514, Loss: 0.23398766526952386, Final Batch Loss: 0.004616080317646265\n",
      "Epoch 2515, Loss: 0.33459075540304184, Final Batch Loss: 0.1899329125881195\n",
      "Epoch 2516, Loss: 0.4274101108312607, Final Batch Loss: 0.22733457386493683\n",
      "Epoch 2517, Loss: 0.18395548313856125, Final Batch Loss: 0.02929488569498062\n",
      "Epoch 2518, Loss: 0.2925485372543335, Final Batch Loss: 0.10497807711362839\n",
      "Epoch 2519, Loss: 0.27365338429808617, Final Batch Loss: 0.06189276650547981\n",
      "Epoch 2520, Loss: 0.22733322903513908, Final Batch Loss: 0.009640228003263474\n",
      "Epoch 2521, Loss: 0.2383933924138546, Final Batch Loss: 0.08562988042831421\n",
      "Epoch 2522, Loss: 0.2980627566576004, Final Batch Loss: 0.179840549826622\n",
      "Epoch 2523, Loss: 0.1655966080725193, Final Batch Loss: 0.04490063339471817\n",
      "Epoch 2524, Loss: 0.31219861656427383, Final Batch Loss: 0.1477111428976059\n",
      "Epoch 2525, Loss: 0.48017319291830063, Final Batch Loss: 0.21007393300533295\n",
      "Epoch 2526, Loss: 0.2699911314994097, Final Batch Loss: 0.026622863486409187\n",
      "Epoch 2527, Loss: 0.31171702593564987, Final Batch Loss: 0.11522131413221359\n",
      "Epoch 2528, Loss: 0.23891331814229488, Final Batch Loss: 0.01033720187842846\n",
      "Epoch 2529, Loss: 0.27800242975354195, Final Batch Loss: 0.05894125625491142\n",
      "Epoch 2530, Loss: 0.5381353199481964, Final Batch Loss: 0.29099857807159424\n",
      "Epoch 2531, Loss: 0.2577802259474993, Final Batch Loss: 0.022648455575108528\n",
      "Epoch 2532, Loss: 0.23997445683926344, Final Batch Loss: 0.004975582472980022\n",
      "Epoch 2533, Loss: 0.3270922265946865, Final Batch Loss: 0.05869056656956673\n",
      "Epoch 2534, Loss: 0.2648106310516596, Final Batch Loss: 0.024747783318161964\n",
      "Epoch 2535, Loss: 0.30801384150981903, Final Batch Loss: 0.08352714776992798\n",
      "Epoch 2536, Loss: 0.27127374708652496, Final Batch Loss: 0.1024366244673729\n",
      "Epoch 2537, Loss: 0.3381836265325546, Final Batch Loss: 0.16573737561702728\n",
      "Epoch 2538, Loss: 0.2427271455526352, Final Batch Loss: 0.09316857159137726\n",
      "Epoch 2539, Loss: 0.26074784249067307, Final Batch Loss: 0.11431730538606644\n",
      "Epoch 2540, Loss: 0.3628145307302475, Final Batch Loss: 0.09703078866004944\n",
      "Epoch 2541, Loss: 0.3190311901271343, Final Batch Loss: 0.17320114374160767\n",
      "Epoch 2542, Loss: 0.23479173704981804, Final Batch Loss: 0.028344135731458664\n",
      "Epoch 2543, Loss: 0.27465586736798286, Final Batch Loss: 0.04605749621987343\n",
      "Epoch 2544, Loss: 0.2347587551921606, Final Batch Loss: 0.021260453388094902\n",
      "Epoch 2545, Loss: 0.3087342903017998, Final Batch Loss: 0.07805631309747696\n",
      "Epoch 2546, Loss: 0.22668684646487236, Final Batch Loss: 0.06835827231407166\n",
      "Epoch 2547, Loss: 0.19060435751453042, Final Batch Loss: 0.00603472301736474\n",
      "Epoch 2548, Loss: 0.2212200053036213, Final Batch Loss: 0.08469519019126892\n",
      "Epoch 2549, Loss: 0.2039606049656868, Final Batch Loss: 0.07690074294805527\n",
      "Epoch 2550, Loss: 0.2550652250647545, Final Batch Loss: 0.0942242369055748\n",
      "Epoch 2551, Loss: 0.17404219880700111, Final Batch Loss: 0.021643321961164474\n",
      "Epoch 2552, Loss: 0.2921535409986973, Final Batch Loss: 0.13750223815441132\n",
      "Epoch 2553, Loss: 0.3126116022467613, Final Batch Loss: 0.13408426940441132\n",
      "Epoch 2554, Loss: 0.25203850120306015, Final Batch Loss: 0.07689069211483002\n",
      "Epoch 2555, Loss: 0.1417130483314395, Final Batch Loss: 0.0031381575390696526\n",
      "Epoch 2556, Loss: 0.19900821894407272, Final Batch Loss: 0.0852573812007904\n",
      "Epoch 2557, Loss: 0.31147975474596024, Final Batch Loss: 0.17497073113918304\n",
      "Epoch 2558, Loss: 0.5085333287715912, Final Batch Loss: 0.2964482009410858\n",
      "Epoch 2559, Loss: 0.2137992773205042, Final Batch Loss: 0.029807696118950844\n",
      "Epoch 2560, Loss: 0.2217276655137539, Final Batch Loss: 0.05318548157811165\n",
      "Epoch 2561, Loss: 0.21980275213718414, Final Batch Loss: 0.06808020174503326\n",
      "Epoch 2562, Loss: 0.23323674872517586, Final Batch Loss: 0.06069829687476158\n",
      "Epoch 2563, Loss: 0.266122791916132, Final Batch Loss: 0.0505308173596859\n",
      "Epoch 2564, Loss: 0.1562287979759276, Final Batch Loss: 0.00574524188414216\n",
      "Epoch 2565, Loss: 0.23711784929037094, Final Batch Loss: 0.07261454313993454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2566, Loss: 0.27773261815309525, Final Batch Loss: 0.13872970640659332\n",
      "Epoch 2567, Loss: 0.20607253536581993, Final Batch Loss: 0.013521265238523483\n",
      "Epoch 2568, Loss: 0.192144937813282, Final Batch Loss: 0.03814787417650223\n",
      "Epoch 2569, Loss: 0.19917304441332817, Final Batch Loss: 0.03447544202208519\n",
      "Epoch 2570, Loss: 0.1858372911810875, Final Batch Loss: 0.02140379697084427\n",
      "Epoch 2571, Loss: 0.14990256470628083, Final Batch Loss: 0.0021863405127078295\n",
      "Epoch 2572, Loss: 0.21317033097147942, Final Batch Loss: 0.07489559799432755\n",
      "Epoch 2573, Loss: 0.21473528817296028, Final Batch Loss: 0.054544154554605484\n",
      "Epoch 2574, Loss: 0.25162407010793686, Final Batch Loss: 0.08496744185686111\n",
      "Epoch 2575, Loss: 0.26550089195370674, Final Batch Loss: 0.11064530909061432\n",
      "Epoch 2576, Loss: 0.2734806276857853, Final Batch Loss: 0.14879941940307617\n",
      "Epoch 2577, Loss: 0.3348750062286854, Final Batch Loss: 0.18461917340755463\n",
      "Epoch 2578, Loss: 0.2771172313950956, Final Batch Loss: 0.00465764245018363\n",
      "Epoch 2579, Loss: 0.37727152183651924, Final Batch Loss: 0.03363065794110298\n",
      "Epoch 2580, Loss: 0.2478729598224163, Final Batch Loss: 0.017775241285562515\n",
      "Epoch 2581, Loss: 0.32946786284446716, Final Batch Loss: 0.12020520120859146\n",
      "Epoch 2582, Loss: 0.3116576597094536, Final Batch Loss: 0.12833017110824585\n",
      "Epoch 2583, Loss: 0.44551126658916473, Final Batch Loss: 0.2526620626449585\n",
      "Epoch 2584, Loss: 0.23621593415737152, Final Batch Loss: 0.05586957186460495\n",
      "Epoch 2585, Loss: 0.24599721282720566, Final Batch Loss: 0.020017802715301514\n",
      "Epoch 2586, Loss: 0.21191280335187912, Final Batch Loss: 0.05119770020246506\n",
      "Epoch 2587, Loss: 0.1314880447462201, Final Batch Loss: 0.012639564462006092\n",
      "Epoch 2588, Loss: 0.23165065795183182, Final Batch Loss: 0.040955327451229095\n",
      "Epoch 2589, Loss: 0.24268562532961369, Final Batch Loss: 0.030703255906701088\n",
      "Epoch 2590, Loss: 0.20124120824038982, Final Batch Loss: 0.02317667566239834\n",
      "Epoch 2591, Loss: 0.24775360897183418, Final Batch Loss: 0.019631896167993546\n",
      "Epoch 2592, Loss: 0.31214480847120285, Final Batch Loss: 0.14657004177570343\n",
      "Epoch 2593, Loss: 0.20723376236855984, Final Batch Loss: 0.009071147069334984\n",
      "Epoch 2594, Loss: 0.2969781681895256, Final Batch Loss: 0.09677710384130478\n",
      "Epoch 2595, Loss: 0.2326986249536276, Final Batch Loss: 0.01698932610452175\n",
      "Epoch 2596, Loss: 0.2182702161371708, Final Batch Loss: 0.011828076094388962\n",
      "Epoch 2597, Loss: 0.19170448929071426, Final Batch Loss: 0.043004125356674194\n",
      "Epoch 2598, Loss: 0.15826028725132346, Final Batch Loss: 0.001147524919360876\n",
      "Epoch 2599, Loss: 0.1360305044800043, Final Batch Loss: 0.00831650011241436\n",
      "Epoch 2600, Loss: 0.26887957006692886, Final Batch Loss: 0.08753500878810883\n",
      "Epoch 2601, Loss: 0.14311547204852104, Final Batch Loss: 0.008835848420858383\n",
      "Epoch 2602, Loss: 0.1919943504035473, Final Batch Loss: 0.04735735058784485\n",
      "Epoch 2603, Loss: 0.2600948102772236, Final Batch Loss: 0.12942230701446533\n",
      "Epoch 2604, Loss: 0.22033315896987915, Final Batch Loss: 0.04288259893655777\n",
      "Epoch 2605, Loss: 0.3092776834964752, Final Batch Loss: 0.1341811865568161\n",
      "Epoch 2606, Loss: 0.18398496136069298, Final Batch Loss: 0.026837464421987534\n",
      "Epoch 2607, Loss: 0.25132036209106445, Final Batch Loss: 0.08817364275455475\n",
      "Epoch 2608, Loss: 0.19569190964102745, Final Batch Loss: 0.04053817316889763\n",
      "Epoch 2609, Loss: 0.19997724890708923, Final Batch Loss: 0.003247871994972229\n",
      "Epoch 2610, Loss: 0.18953564763069153, Final Batch Loss: 0.037010252475738525\n",
      "Epoch 2611, Loss: 0.2025889754295349, Final Batch Loss: 0.05949627608060837\n",
      "Epoch 2612, Loss: 0.17852317169308662, Final Batch Loss: 0.023772474378347397\n",
      "Epoch 2613, Loss: 0.21470867469906807, Final Batch Loss: 0.07728774845600128\n",
      "Epoch 2614, Loss: 0.16387087851762772, Final Batch Loss: 0.041426848620176315\n",
      "Epoch 2615, Loss: 0.2040466144680977, Final Batch Loss: 0.05764211341738701\n",
      "Epoch 2616, Loss: 0.24878180027008057, Final Batch Loss: 0.10110287368297577\n",
      "Epoch 2617, Loss: 0.49067626893520355, Final Batch Loss: 0.3513077199459076\n",
      "Epoch 2618, Loss: 0.23766792519018054, Final Batch Loss: 0.004201717209070921\n",
      "Epoch 2619, Loss: 0.4711332619190216, Final Batch Loss: 0.26394256949424744\n",
      "Epoch 2620, Loss: 0.4752633571624756, Final Batch Loss: 0.3153877556324005\n",
      "Epoch 2621, Loss: 0.22526350617408752, Final Batch Loss: 0.01882891356945038\n",
      "Epoch 2622, Loss: 0.4203140214085579, Final Batch Loss: 0.19467996060848236\n",
      "Epoch 2623, Loss: 0.4620319530367851, Final Batch Loss: 0.3050018846988678\n",
      "Epoch 2624, Loss: 0.2665417045354843, Final Batch Loss: 0.08576539903879166\n",
      "Epoch 2625, Loss: 0.23705411888659, Final Batch Loss: 0.025526883080601692\n",
      "Epoch 2626, Loss: 0.4189917668700218, Final Batch Loss: 0.1878819763660431\n",
      "Epoch 2627, Loss: 0.3570147380232811, Final Batch Loss: 0.1592802256345749\n",
      "Epoch 2628, Loss: 0.48607489466667175, Final Batch Loss: 0.3189869821071625\n",
      "Epoch 2629, Loss: 0.2149384394288063, Final Batch Loss: 0.0436505526304245\n",
      "Epoch 2630, Loss: 0.22507373429834843, Final Batch Loss: 0.01966080255806446\n",
      "Epoch 2631, Loss: 0.479786179959774, Final Batch Loss: 0.21170730888843536\n",
      "Epoch 2632, Loss: 0.29576197266578674, Final Batch Loss: 0.07977748662233353\n",
      "Epoch 2633, Loss: 0.28869229555130005, Final Batch Loss: 0.09099118411540985\n",
      "Epoch 2634, Loss: 0.822741188108921, Final Batch Loss: 0.6058194041252136\n",
      "Epoch 2635, Loss: 0.23781032487750053, Final Batch Loss: 0.0455666147172451\n",
      "Epoch 2636, Loss: 0.2289617918431759, Final Batch Loss: 0.025026526302099228\n",
      "Epoch 2637, Loss: 0.39672042429447174, Final Batch Loss: 0.15103872120380402\n",
      "Epoch 2638, Loss: 0.294327549636364, Final Batch Loss: 0.06084582209587097\n",
      "Epoch 2639, Loss: 0.6201302111148834, Final Batch Loss: 0.3597347140312195\n",
      "Epoch 2640, Loss: 0.342298299074173, Final Batch Loss: 0.04213714599609375\n",
      "Epoch 2641, Loss: 0.448390893638134, Final Batch Loss: 0.2100619077682495\n",
      "Epoch 2642, Loss: 0.2747024670243263, Final Batch Loss: 0.10094459354877472\n",
      "Epoch 2643, Loss: 0.3982502296566963, Final Batch Loss: 0.17032429575920105\n",
      "Epoch 2644, Loss: 0.3521275669336319, Final Batch Loss: 0.11354230344295502\n",
      "Epoch 2645, Loss: 0.3125845715403557, Final Batch Loss: 0.1503400355577469\n",
      "Epoch 2646, Loss: 0.3394901305437088, Final Batch Loss: 0.13652294874191284\n",
      "Epoch 2647, Loss: 0.21206477656960487, Final Batch Loss: 0.023061249405145645\n",
      "Epoch 2648, Loss: 0.22582540335133672, Final Batch Loss: 0.006446999032050371\n",
      "Epoch 2649, Loss: 0.17713721934705973, Final Batch Loss: 0.006820769049227238\n",
      "Epoch 2650, Loss: 0.36710549890995026, Final Batch Loss: 0.20330409705638885\n",
      "Epoch 2651, Loss: 0.2684275135397911, Final Batch Loss: 0.10464650392532349\n",
      "Epoch 2652, Loss: 0.3593868874013424, Final Batch Loss: 0.20526547729969025\n",
      "Epoch 2653, Loss: 0.44721662253141403, Final Batch Loss: 0.2924765646457672\n",
      "Epoch 2654, Loss: 0.19149199686944485, Final Batch Loss: 0.014965234324336052\n",
      "Epoch 2655, Loss: 0.45849117636680603, Final Batch Loss: 0.2524215877056122\n",
      "Epoch 2656, Loss: 0.2460634894669056, Final Batch Loss: 0.039472099393606186\n",
      "Epoch 2657, Loss: 0.3126906752586365, Final Batch Loss: 0.10466078668832779\n",
      "Epoch 2658, Loss: 0.22724124044179916, Final Batch Loss: 0.037253424525260925\n",
      "Epoch 2659, Loss: 0.23637526482343674, Final Batch Loss: 0.06473594158887863\n",
      "Epoch 2660, Loss: 0.26616087555885315, Final Batch Loss: 0.07364491373300552\n",
      "Epoch 2661, Loss: 0.41089385747909546, Final Batch Loss: 0.21964474022388458\n",
      "Epoch 2662, Loss: 0.27802468836307526, Final Batch Loss: 0.080463707447052\n",
      "Epoch 2663, Loss: 0.34149375557899475, Final Batch Loss: 0.07300486415624619\n",
      "Epoch 2664, Loss: 0.3255634531378746, Final Batch Loss: 0.14437712728977203\n",
      "Epoch 2665, Loss: 0.542723536491394, Final Batch Loss: 0.3305182158946991\n",
      "Epoch 2666, Loss: 0.41409898549318314, Final Batch Loss: 0.27591827511787415\n",
      "Epoch 2667, Loss: 0.28295423462986946, Final Batch Loss: 0.05593619868159294\n",
      "Epoch 2668, Loss: 0.20090630277991295, Final Batch Loss: 0.03248028829693794\n",
      "Epoch 2669, Loss: 0.2660995973274112, Final Batch Loss: 0.01201664935797453\n",
      "Epoch 2670, Loss: 0.18841176759451628, Final Batch Loss: 0.010115738026797771\n",
      "Epoch 2671, Loss: 0.5092845633625984, Final Batch Loss: 0.23743581771850586\n",
      "Epoch 2672, Loss: 0.17644036188721657, Final Batch Loss: 0.0030287988483905792\n",
      "Epoch 2673, Loss: 0.38736817985773087, Final Batch Loss: 0.18453620374202728\n",
      "Epoch 2674, Loss: 0.3106078952550888, Final Batch Loss: 0.19125650823116302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2675, Loss: 0.2605537660419941, Final Batch Loss: 0.03004639968276024\n",
      "Epoch 2676, Loss: 0.5965612009167671, Final Batch Loss: 0.36159729957580566\n",
      "Epoch 2677, Loss: 0.4154297113418579, Final Batch Loss: 0.21822144091129303\n",
      "Epoch 2678, Loss: 0.326488196849823, Final Batch Loss: 0.08994946628808975\n",
      "Epoch 2679, Loss: 0.34900153800845146, Final Batch Loss: 0.03355177864432335\n",
      "Epoch 2680, Loss: 0.35964789241552353, Final Batch Loss: 0.156357079744339\n",
      "Epoch 2681, Loss: 0.2712520398199558, Final Batch Loss: 0.03184211626648903\n",
      "Epoch 2682, Loss: 0.3273376598954201, Final Batch Loss: 0.06838624179363251\n",
      "Epoch 2683, Loss: 0.2080166656523943, Final Batch Loss: 0.03017091192305088\n",
      "Epoch 2684, Loss: 0.2645799145102501, Final Batch Loss: 0.055585943162441254\n",
      "Epoch 2685, Loss: 0.3918118178844452, Final Batch Loss: 0.15107621252536774\n",
      "Epoch 2686, Loss: 0.16915293922647834, Final Batch Loss: 0.0054748146794736385\n",
      "Epoch 2687, Loss: 0.1613893024623394, Final Batch Loss: 0.0370236411690712\n",
      "Epoch 2688, Loss: 0.24690668284893036, Final Batch Loss: 0.05579903721809387\n",
      "Epoch 2689, Loss: 0.17680669948458672, Final Batch Loss: 0.056382086127996445\n",
      "Epoch 2690, Loss: 0.18234718218445778, Final Batch Loss: 0.0317501537501812\n",
      "Epoch 2691, Loss: 0.20649881660938263, Final Batch Loss: 0.03997092694044113\n",
      "Epoch 2692, Loss: 0.2898053228855133, Final Batch Loss: 0.11928322166204453\n",
      "Epoch 2693, Loss: 0.3019449710845947, Final Batch Loss: 0.11931096762418747\n",
      "Epoch 2694, Loss: 0.3215469792485237, Final Batch Loss: 0.19779735803604126\n",
      "Epoch 2695, Loss: 0.20787326246500015, Final Batch Loss: 0.06522735953330994\n",
      "Epoch 2696, Loss: 0.23331380262970924, Final Batch Loss: 0.03377782180905342\n",
      "Epoch 2697, Loss: 0.3438294306397438, Final Batch Loss: 0.14230228960514069\n",
      "Epoch 2698, Loss: 0.18159451708197594, Final Batch Loss: 0.04646500200033188\n",
      "Epoch 2699, Loss: 0.29069825634360313, Final Batch Loss: 0.1578029841184616\n",
      "Epoch 2700, Loss: 0.21761335991322994, Final Batch Loss: 0.02832069806754589\n",
      "Epoch 2701, Loss: 0.18684570863842964, Final Batch Loss: 0.036215510219335556\n",
      "Epoch 2702, Loss: 0.784243181347847, Final Batch Loss: 0.6086719036102295\n",
      "Epoch 2703, Loss: 0.4301042929291725, Final Batch Loss: 0.2574867308139801\n",
      "Epoch 2704, Loss: 0.26264534518122673, Final Batch Loss: 0.06233504042029381\n",
      "Epoch 2705, Loss: 0.45550230145454407, Final Batch Loss: 0.22607117891311646\n",
      "Epoch 2706, Loss: 0.23620884120464325, Final Batch Loss: 0.08182690292596817\n",
      "Epoch 2707, Loss: 0.3566015213727951, Final Batch Loss: 0.1830243468284607\n",
      "Epoch 2708, Loss: 0.27473196387290955, Final Batch Loss: 0.10402964800596237\n",
      "Epoch 2709, Loss: 0.279032826423645, Final Batch Loss: 0.12895087897777557\n",
      "Epoch 2710, Loss: 0.2750381678342819, Final Batch Loss: 0.06781182438135147\n",
      "Epoch 2711, Loss: 0.24727454781532288, Final Batch Loss: 0.07494888454675674\n",
      "Epoch 2712, Loss: 0.2023036740720272, Final Batch Loss: 0.043798331171274185\n",
      "Epoch 2713, Loss: 0.20391084253787994, Final Batch Loss: 0.0682075172662735\n",
      "Epoch 2714, Loss: 0.156335037201643, Final Batch Loss: 0.029405318200588226\n",
      "Epoch 2715, Loss: 0.3777357116341591, Final Batch Loss: 0.222314715385437\n",
      "Epoch 2716, Loss: 0.17908387258648872, Final Batch Loss: 0.033442627638578415\n",
      "Epoch 2717, Loss: 0.18629221059381962, Final Batch Loss: 0.012599067762494087\n",
      "Epoch 2718, Loss: 0.2316965889185667, Final Batch Loss: 0.025594083592295647\n",
      "Epoch 2719, Loss: 0.26187727600336075, Final Batch Loss: 0.07130163908004761\n",
      "Epoch 2720, Loss: 0.508988730609417, Final Batch Loss: 0.30175185203552246\n",
      "Epoch 2721, Loss: 0.20172297954559326, Final Batch Loss: 0.04095157980918884\n",
      "Epoch 2722, Loss: 0.23310265317559242, Final Batch Loss: 0.040313269942998886\n",
      "Epoch 2723, Loss: 0.304794579744339, Final Batch Loss: 0.08019158989191055\n",
      "Epoch 2724, Loss: 0.21261491626501083, Final Batch Loss: 0.025086984038352966\n",
      "Epoch 2725, Loss: 0.3789122402667999, Final Batch Loss: 0.20499034225940704\n",
      "Epoch 2726, Loss: 0.1732095694169402, Final Batch Loss: 0.007634385488927364\n",
      "Epoch 2727, Loss: 0.22095287404954433, Final Batch Loss: 0.02749207429587841\n",
      "Epoch 2728, Loss: 0.2545837387442589, Final Batch Loss: 0.0631074532866478\n",
      "Epoch 2729, Loss: 0.2071519042365253, Final Batch Loss: 0.006261370610445738\n",
      "Epoch 2730, Loss: 0.337195448577404, Final Batch Loss: 0.13227394223213196\n",
      "Epoch 2731, Loss: 0.25116032361984253, Final Batch Loss: 0.08434417843818665\n",
      "Epoch 2732, Loss: 0.264115110039711, Final Batch Loss: 0.08555783331394196\n",
      "Epoch 2733, Loss: 0.25406987965106964, Final Batch Loss: 0.11964482814073563\n",
      "Epoch 2734, Loss: 0.3466385528445244, Final Batch Loss: 0.09403965622186661\n",
      "Epoch 2735, Loss: 0.331665962934494, Final Batch Loss: 0.1525706797838211\n",
      "Epoch 2736, Loss: 0.8185921907424927, Final Batch Loss: 0.6394954323768616\n",
      "Epoch 2737, Loss: 0.4034810960292816, Final Batch Loss: 0.18864783644676208\n",
      "Epoch 2738, Loss: 0.3061279132962227, Final Batch Loss: 0.16900645196437836\n",
      "Epoch 2739, Loss: 0.16715200431644917, Final Batch Loss: 0.02860088087618351\n",
      "Epoch 2740, Loss: 0.22156939655542374, Final Batch Loss: 0.050496429204940796\n",
      "Epoch 2741, Loss: 0.275916188955307, Final Batch Loss: 0.09458276629447937\n",
      "Epoch 2742, Loss: 0.23266078531742096, Final Batch Loss: 0.06286726146936417\n",
      "Epoch 2743, Loss: 0.2434244602918625, Final Batch Loss: 0.06560879200696945\n",
      "Epoch 2744, Loss: 0.2844902351498604, Final Batch Loss: 0.11595449596643448\n",
      "Epoch 2745, Loss: 0.3561673164367676, Final Batch Loss: 0.153718039393425\n",
      "Epoch 2746, Loss: 0.3235084116458893, Final Batch Loss: 0.03620700538158417\n",
      "Epoch 2747, Loss: 0.5334899500012398, Final Batch Loss: 0.302685022354126\n",
      "Epoch 2748, Loss: 0.42817023023962975, Final Batch Loss: 0.2994913160800934\n",
      "Epoch 2749, Loss: 0.22249372024089098, Final Batch Loss: 0.013352696783840656\n",
      "Epoch 2750, Loss: 0.3478705361485481, Final Batch Loss: 0.10032332688570023\n",
      "Epoch 2751, Loss: 0.5659310668706894, Final Batch Loss: 0.32258814573287964\n",
      "Epoch 2752, Loss: 0.19042061641812325, Final Batch Loss: 0.01954985037446022\n",
      "Epoch 2753, Loss: 0.309722401201725, Final Batch Loss: 0.11064586788415909\n",
      "Epoch 2754, Loss: 0.2453681044280529, Final Batch Loss: 0.03387724235653877\n",
      "Epoch 2755, Loss: 0.2488886285573244, Final Batch Loss: 0.020252371206879616\n",
      "Epoch 2756, Loss: 0.17349126748740673, Final Batch Loss: 0.026766246184706688\n",
      "Epoch 2757, Loss: 0.22038905322551727, Final Batch Loss: 0.004254341125488281\n",
      "Epoch 2758, Loss: 0.2738698348402977, Final Batch Loss: 0.07465360313653946\n",
      "Epoch 2759, Loss: 0.2614188604056835, Final Batch Loss: 0.032835159450769424\n",
      "Epoch 2760, Loss: 0.208403455093503, Final Batch Loss: 0.02212037332355976\n",
      "Epoch 2761, Loss: 0.293563112616539, Final Batch Loss: 0.14367467164993286\n",
      "Epoch 2762, Loss: 0.28720858320593834, Final Batch Loss: 0.1256970912218094\n",
      "Epoch 2763, Loss: 0.2143292399123311, Final Batch Loss: 0.01419223565608263\n",
      "Epoch 2764, Loss: 0.21578172966837883, Final Batch Loss: 0.09558669477701187\n",
      "Epoch 2765, Loss: 0.14545060973614454, Final Batch Loss: 0.009606863372027874\n",
      "Epoch 2766, Loss: 0.15346755646169186, Final Batch Loss: 0.014198897406458855\n",
      "Epoch 2767, Loss: 0.3088258132338524, Final Batch Loss: 0.11933185905218124\n",
      "Epoch 2768, Loss: 0.2731640264391899, Final Batch Loss: 0.08148418366909027\n",
      "Epoch 2769, Loss: 0.31109383702278137, Final Batch Loss: 0.1555142104625702\n",
      "Epoch 2770, Loss: 0.236888088285923, Final Batch Loss: 0.06780268996953964\n",
      "Epoch 2771, Loss: 0.33681154251098633, Final Batch Loss: 0.20120954513549805\n",
      "Epoch 2772, Loss: 0.2525087520480156, Final Batch Loss: 0.09607767313718796\n",
      "Epoch 2773, Loss: 0.25969913601875305, Final Batch Loss: 0.1296609789133072\n",
      "Epoch 2774, Loss: 0.28934550285339355, Final Batch Loss: 0.13742773234844208\n",
      "Epoch 2775, Loss: 0.19063830375671387, Final Batch Loss: 0.03246885538101196\n",
      "Epoch 2776, Loss: 0.20631874538958073, Final Batch Loss: 0.021756792441010475\n",
      "Epoch 2777, Loss: 0.28014180809259415, Final Batch Loss: 0.14192789793014526\n",
      "Epoch 2778, Loss: 0.2230401337146759, Final Batch Loss: 0.08024889975786209\n",
      "Epoch 2779, Loss: 0.2007442582398653, Final Batch Loss: 0.01848437823355198\n",
      "Epoch 2780, Loss: 0.3079744055867195, Final Batch Loss: 0.07368765771389008\n",
      "Epoch 2781, Loss: 0.2324613332748413, Final Batch Loss: 0.00949268788099289\n",
      "Epoch 2782, Loss: 0.2648960701189935, Final Batch Loss: 0.006712479051202536\n",
      "Epoch 2783, Loss: 0.33273133635520935, Final Batch Loss: 0.19069071114063263\n",
      "Epoch 2784, Loss: 0.2520816223695874, Final Batch Loss: 0.01062787789851427\n",
      "Epoch 2785, Loss: 0.37597111985087395, Final Batch Loss: 0.2109893262386322\n",
      "Epoch 2786, Loss: 0.2895580306649208, Final Batch Loss: 0.07284191250801086\n",
      "Epoch 2787, Loss: 0.26256826519966125, Final Batch Loss: 0.06314433366060257\n",
      "Epoch 2788, Loss: 0.1555564533919096, Final Batch Loss: 0.010125664994120598\n",
      "Epoch 2789, Loss: 0.1619323855265975, Final Batch Loss: 0.012595213018357754\n",
      "Epoch 2790, Loss: 0.5159854888916016, Final Batch Loss: 0.29454755783081055\n",
      "Epoch 2791, Loss: 0.2400236465036869, Final Batch Loss: 0.05796344205737114\n",
      "Epoch 2792, Loss: 0.2094964124262333, Final Batch Loss: 0.0632520318031311\n",
      "Epoch 2793, Loss: 0.23623840510845184, Final Batch Loss: 0.06917574256658554\n",
      "Epoch 2794, Loss: 0.24752040952444077, Final Batch Loss: 0.06742948293685913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2795, Loss: 0.22829069197177887, Final Batch Loss: 0.05873945355415344\n",
      "Epoch 2796, Loss: 0.25450148433446884, Final Batch Loss: 0.02131512761116028\n",
      "Epoch 2797, Loss: 0.17383135482668877, Final Batch Loss: 0.03643106296658516\n",
      "Epoch 2798, Loss: 0.17549274489283562, Final Batch Loss: 0.029329553246498108\n",
      "Epoch 2799, Loss: 0.258137721568346, Final Batch Loss: 0.048612307757139206\n",
      "Epoch 2800, Loss: 0.14683241210877895, Final Batch Loss: 0.017289334908127785\n",
      "Epoch 2801, Loss: 0.43578440696001053, Final Batch Loss: 0.26954856514930725\n",
      "Epoch 2802, Loss: 0.3289225846529007, Final Batch Loss: 0.1939709335565567\n",
      "Epoch 2803, Loss: 0.36627233773469925, Final Batch Loss: 0.1880788505077362\n",
      "Epoch 2804, Loss: 0.24297422915697098, Final Batch Loss: 0.01856909692287445\n",
      "Epoch 2805, Loss: 0.4921392425894737, Final Batch Loss: 0.2895907461643219\n",
      "Epoch 2806, Loss: 0.5145631805062294, Final Batch Loss: 0.28876423835754395\n",
      "Epoch 2807, Loss: 0.20667747780680656, Final Batch Loss: 0.024233121424913406\n",
      "Epoch 2808, Loss: 0.14531133137643337, Final Batch Loss: 0.018982594832777977\n",
      "Epoch 2809, Loss: 0.15201159566640854, Final Batch Loss: 0.03421247750520706\n",
      "Epoch 2810, Loss: 0.42421597987413406, Final Batch Loss: 0.2503224015235901\n",
      "Epoch 2811, Loss: 0.14859675464686006, Final Batch Loss: 0.001912458217702806\n",
      "Epoch 2812, Loss: 0.14550795074319467, Final Batch Loss: 0.000963841041084379\n",
      "Epoch 2813, Loss: 0.20009946450591087, Final Batch Loss: 0.05517134442925453\n",
      "Epoch 2814, Loss: 0.15529245883226395, Final Batch Loss: 0.038869068026542664\n",
      "Epoch 2815, Loss: 0.13976148422807455, Final Batch Loss: 0.012983175925910473\n",
      "Epoch 2816, Loss: 0.18117805570363998, Final Batch Loss: 0.04368928074836731\n",
      "Epoch 2817, Loss: 0.27596743777394295, Final Batch Loss: 0.13389216363430023\n",
      "Epoch 2818, Loss: 0.28419171273708344, Final Batch Loss: 0.020845577120780945\n",
      "Epoch 2819, Loss: 0.2951117902994156, Final Batch Loss: 0.030083224177360535\n",
      "Epoch 2820, Loss: 0.19811308616772294, Final Batch Loss: 0.002061466220766306\n",
      "Epoch 2821, Loss: 0.4810045659542084, Final Batch Loss: 0.20086491107940674\n",
      "Epoch 2822, Loss: 0.3092588111758232, Final Batch Loss: 0.04718336462974548\n",
      "Epoch 2823, Loss: 0.23243612423539162, Final Batch Loss: 0.019201863557100296\n",
      "Epoch 2824, Loss: 0.33020278811454773, Final Batch Loss: 0.15185685455799103\n",
      "Epoch 2825, Loss: 0.20534469466656446, Final Batch Loss: 0.015592965297400951\n",
      "Epoch 2826, Loss: 0.1934235580265522, Final Batch Loss: 0.016553368419408798\n",
      "Epoch 2827, Loss: 0.19076039642095566, Final Batch Loss: 0.05669606477022171\n",
      "Epoch 2828, Loss: 0.27537723630666733, Final Batch Loss: 0.14200299978256226\n",
      "Epoch 2829, Loss: 0.14320267736911774, Final Batch Loss: 0.01194126158952713\n",
      "Epoch 2830, Loss: 0.2914753407239914, Final Batch Loss: 0.06016770750284195\n",
      "Epoch 2831, Loss: 0.5366623029112816, Final Batch Loss: 0.3885424733161926\n",
      "Epoch 2832, Loss: 0.19826646521687508, Final Batch Loss: 0.023212093859910965\n",
      "Epoch 2833, Loss: 0.2988680973649025, Final Batch Loss: 0.13958725333213806\n",
      "Epoch 2834, Loss: 0.21199428662657738, Final Batch Loss: 0.05306162312626839\n",
      "Epoch 2835, Loss: 0.21597592160105705, Final Batch Loss: 0.027212519198656082\n",
      "Epoch 2836, Loss: 0.2713000550866127, Final Batch Loss: 0.12431281805038452\n",
      "Epoch 2837, Loss: 0.5914599522948265, Final Batch Loss: 0.40125003457069397\n",
      "Epoch 2838, Loss: 0.2841145694255829, Final Batch Loss: 0.12509524822235107\n",
      "Epoch 2839, Loss: 0.49096468836069107, Final Batch Loss: 0.23094888031482697\n",
      "Epoch 2840, Loss: 0.2586689256131649, Final Batch Loss: 0.09145382791757584\n",
      "Epoch 2841, Loss: 0.35467640310525894, Final Batch Loss: 0.16533388197422028\n",
      "Epoch 2842, Loss: 0.2492178212851286, Final Batch Loss: 0.024785777553915977\n",
      "Epoch 2843, Loss: 0.39747167378664017, Final Batch Loss: 0.1829870045185089\n",
      "Epoch 2844, Loss: 0.21062397211790085, Final Batch Loss: 0.09550613909959793\n",
      "Epoch 2845, Loss: 0.36006756871938705, Final Batch Loss: 0.1486886739730835\n",
      "Epoch 2846, Loss: 0.29117418080568314, Final Batch Loss: 0.05915521830320358\n",
      "Epoch 2847, Loss: 0.44194064289331436, Final Batch Loss: 0.08992622047662735\n",
      "Epoch 2848, Loss: 0.4198048338294029, Final Batch Loss: 0.0995434895157814\n",
      "Epoch 2849, Loss: 0.29516565054655075, Final Batch Loss: 0.0317465141415596\n",
      "Epoch 2850, Loss: 0.3643747940659523, Final Batch Loss: 0.09998338669538498\n",
      "Epoch 2851, Loss: 0.26718586683273315, Final Batch Loss: 0.11650294065475464\n",
      "Epoch 2852, Loss: 0.2409023940563202, Final Batch Loss: 0.08285246044397354\n",
      "Epoch 2853, Loss: 0.1838180273771286, Final Batch Loss: 0.03273145854473114\n",
      "Epoch 2854, Loss: 0.21828890591859818, Final Batch Loss: 0.04047156870365143\n",
      "Epoch 2855, Loss: 0.3845881149172783, Final Batch Loss: 0.21954040229320526\n",
      "Epoch 2856, Loss: 0.1864469163119793, Final Batch Loss: 0.041425902396440506\n",
      "Epoch 2857, Loss: 0.3558591529726982, Final Batch Loss: 0.1730968952178955\n",
      "Epoch 2858, Loss: 0.17543781315907836, Final Batch Loss: 0.0049652657471597195\n",
      "Epoch 2859, Loss: 0.3596128076314926, Final Batch Loss: 0.17653147876262665\n",
      "Epoch 2860, Loss: 0.2032446227967739, Final Batch Loss: 0.04751402512192726\n",
      "Epoch 2861, Loss: 0.27592381089925766, Final Batch Loss: 0.089401476085186\n",
      "Epoch 2862, Loss: 0.28548847138881683, Final Batch Loss: 0.06112368404865265\n",
      "Epoch 2863, Loss: 0.3271724283695221, Final Batch Loss: 0.04828815162181854\n",
      "Epoch 2864, Loss: 0.23118732124567032, Final Batch Loss: 0.03304962068796158\n",
      "Epoch 2865, Loss: 0.23360609263181686, Final Batch Loss: 0.033090993762016296\n",
      "Epoch 2866, Loss: 0.17964233830571175, Final Batch Loss: 0.03915228322148323\n",
      "Epoch 2867, Loss: 0.3390449211001396, Final Batch Loss: 0.16962724924087524\n",
      "Epoch 2868, Loss: 0.1640540398657322, Final Batch Loss: 0.02465716004371643\n",
      "Epoch 2869, Loss: 0.22281594015657902, Final Batch Loss: 0.03055589087307453\n",
      "Epoch 2870, Loss: 0.30564000457525253, Final Batch Loss: 0.17645035684108734\n",
      "Epoch 2871, Loss: 0.21170754730701447, Final Batch Loss: 0.05228235572576523\n",
      "Epoch 2872, Loss: 0.21531157940626144, Final Batch Loss: 0.03419630974531174\n",
      "Epoch 2873, Loss: 0.19104182999581099, Final Batch Loss: 0.01369457971304655\n",
      "Epoch 2874, Loss: 0.27647729218006134, Final Batch Loss: 0.10478556156158447\n",
      "Epoch 2875, Loss: 0.1464365040883422, Final Batch Loss: 0.008013083599507809\n",
      "Epoch 2876, Loss: 0.16448115184903145, Final Batch Loss: 0.03179681673645973\n",
      "Epoch 2877, Loss: 0.23082976043224335, Final Batch Loss: 0.10313393920660019\n",
      "Epoch 2878, Loss: 0.1654901932924986, Final Batch Loss: 0.017903177067637444\n",
      "Epoch 2879, Loss: 0.24526653438806534, Final Batch Loss: 0.07355532795190811\n",
      "Epoch 2880, Loss: 0.13432748150080442, Final Batch Loss: 0.014667618088424206\n",
      "Epoch 2881, Loss: 0.24565145000815392, Final Batch Loss: 0.06134934350848198\n",
      "Epoch 2882, Loss: 0.15923413075506687, Final Batch Loss: 0.016666876152157784\n",
      "Epoch 2883, Loss: 0.147616408765316, Final Batch Loss: 0.052718568593263626\n",
      "Epoch 2884, Loss: 0.23589526116847992, Final Batch Loss: 0.03828243166208267\n",
      "Epoch 2885, Loss: 0.15945683978497982, Final Batch Loss: 0.018139051273465157\n",
      "Epoch 2886, Loss: 0.31689804047346115, Final Batch Loss: 0.19864521920681\n",
      "Epoch 2887, Loss: 0.19857480376958847, Final Batch Loss: 0.015361331403255463\n",
      "Epoch 2888, Loss: 0.19560134410858154, Final Batch Loss: 0.023503199219703674\n",
      "Epoch 2889, Loss: 0.2571272552013397, Final Batch Loss: 0.05758867785334587\n",
      "Epoch 2890, Loss: 1.2888249084353447, Final Batch Loss: 1.1298598051071167\n",
      "Epoch 2891, Loss: 0.1751219853758812, Final Batch Loss: 0.040134795010089874\n",
      "Epoch 2892, Loss: 1.06254131346941, Final Batch Loss: 0.7378584146499634\n",
      "Epoch 2893, Loss: 0.36447229608893394, Final Batch Loss: 0.03001093491911888\n",
      "Epoch 2894, Loss: 0.7817321270704269, Final Batch Loss: 0.37313714623451233\n",
      "Epoch 2895, Loss: 0.7318614274263382, Final Batch Loss: 0.13225258886814117\n",
      "Epoch 2896, Loss: 0.6318527609109879, Final Batch Loss: 0.31591498851776123\n",
      "Epoch 2897, Loss: 0.34624457731842995, Final Batch Loss: 0.04429762437939644\n",
      "Epoch 2898, Loss: 0.4053524062037468, Final Batch Loss: 0.014840371906757355\n",
      "Epoch 2899, Loss: 0.5257531255483627, Final Batch Loss: 0.18743044137954712\n",
      "Epoch 2900, Loss: 0.43806540220975876, Final Batch Loss: 0.10775349289178848\n",
      "Epoch 2901, Loss: 0.31501874327659607, Final Batch Loss: 0.03650519251823425\n",
      "Epoch 2902, Loss: 0.47973138093948364, Final Batch Loss: 0.1389264464378357\n",
      "Epoch 2903, Loss: 0.5139365419745445, Final Batch Loss: 0.11749621480703354\n",
      "Epoch 2904, Loss: 0.3420307859778404, Final Batch Loss: 0.11822878569364548\n",
      "Epoch 2905, Loss: 0.33148252218961716, Final Batch Loss: 0.13362088799476624\n",
      "Epoch 2906, Loss: 0.26188586838543415, Final Batch Loss: 0.028996402397751808\n",
      "Epoch 2907, Loss: 0.27328110858798027, Final Batch Loss: 0.05321817472577095\n",
      "Epoch 2908, Loss: 0.34474654495716095, Final Batch Loss: 0.10900165140628815\n",
      "Epoch 2909, Loss: 0.26611295342445374, Final Batch Loss: 0.09664984792470932\n",
      "Epoch 2910, Loss: 0.30301738530397415, Final Batch Loss: 0.11634830385446548\n",
      "Epoch 2911, Loss: 0.41172394156455994, Final Batch Loss: 0.16112960875034332\n",
      "Epoch 2912, Loss: 0.25443851947784424, Final Batch Loss: 0.02368505299091339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2913, Loss: 0.2611061632633209, Final Batch Loss: 0.08465071022510529\n",
      "Epoch 2914, Loss: 0.40549706667661667, Final Batch Loss: 0.2285790741443634\n",
      "Epoch 2915, Loss: 0.2983834892511368, Final Batch Loss: 0.1064520850777626\n",
      "Epoch 2916, Loss: 0.29977020900696516, Final Batch Loss: 0.013964938931167126\n",
      "Epoch 2917, Loss: 0.26047103852033615, Final Batch Loss: 0.03408072888851166\n",
      "Epoch 2918, Loss: 0.35904406011104584, Final Batch Loss: 0.192336767911911\n",
      "Epoch 2919, Loss: 0.22739852592349052, Final Batch Loss: 0.013688009232282639\n",
      "Epoch 2920, Loss: 0.3773241862654686, Final Batch Loss: 0.13914191722869873\n",
      "Epoch 2921, Loss: 0.21559675596654415, Final Batch Loss: 0.021994857117533684\n",
      "Epoch 2922, Loss: 0.35973455011844635, Final Batch Loss: 0.1530955284833908\n",
      "Epoch 2923, Loss: 0.38229574263095856, Final Batch Loss: 0.15443147718906403\n",
      "Epoch 2924, Loss: 0.31286320835351944, Final Batch Loss: 0.10195508599281311\n",
      "Epoch 2925, Loss: 0.32590552419424057, Final Batch Loss: 0.14956273138523102\n",
      "Epoch 2926, Loss: 0.31463247537612915, Final Batch Loss: 0.08037561923265457\n",
      "Epoch 2927, Loss: 0.5771635323762894, Final Batch Loss: 0.364436537027359\n",
      "Epoch 2928, Loss: 0.5530246645212173, Final Batch Loss: 0.36411944031715393\n",
      "Epoch 2929, Loss: 0.4718035161495209, Final Batch Loss: 0.20948342978954315\n",
      "Epoch 2930, Loss: 0.3662501499056816, Final Batch Loss: 0.09723495692014694\n",
      "Epoch 2931, Loss: 0.38426225632429123, Final Batch Loss: 0.1013280525803566\n",
      "Epoch 2932, Loss: 0.5371496677398682, Final Batch Loss: 0.15357816219329834\n",
      "Epoch 2933, Loss: 0.41693515330553055, Final Batch Loss: 0.09122588485479355\n",
      "Epoch 2934, Loss: 0.3331400752067566, Final Batch Loss: 0.08863769471645355\n",
      "Epoch 2935, Loss: 0.32888027280569077, Final Batch Loss: 0.04934892803430557\n",
      "Epoch 2936, Loss: 0.28432334028184414, Final Batch Loss: 0.025908922776579857\n",
      "Epoch 2937, Loss: 0.4611913189291954, Final Batch Loss: 0.2678554952144623\n",
      "Epoch 2938, Loss: 0.2635141387581825, Final Batch Loss: 0.09395327419042587\n",
      "Epoch 2939, Loss: 0.2625002209097147, Final Batch Loss: 0.01857099123299122\n",
      "Epoch 2940, Loss: 0.41181425750255585, Final Batch Loss: 0.22106295824050903\n",
      "Epoch 2941, Loss: 0.3215361088514328, Final Batch Loss: 0.10030703246593475\n",
      "Epoch 2942, Loss: 0.3394775465130806, Final Batch Loss: 0.15499110519886017\n",
      "Epoch 2943, Loss: 0.2727181017398834, Final Batch Loss: 0.09052307158708572\n",
      "Epoch 2944, Loss: 0.2883075103163719, Final Batch Loss: 0.13090181350708008\n",
      "Epoch 2945, Loss: 0.3204954043030739, Final Batch Loss: 0.04807820916175842\n",
      "Epoch 2946, Loss: 0.2583828568458557, Final Batch Loss: 0.07216626405715942\n",
      "Epoch 2947, Loss: 0.3445826545357704, Final Batch Loss: 0.16200149059295654\n",
      "Epoch 2948, Loss: 0.3164774999022484, Final Batch Loss: 0.11281035095453262\n",
      "Epoch 2949, Loss: 0.23078975453972816, Final Batch Loss: 0.03635772690176964\n",
      "Epoch 2950, Loss: 0.35757002234458923, Final Batch Loss: 0.16126613318920135\n",
      "Epoch 2951, Loss: 0.23719916120171547, Final Batch Loss: 0.052453313022851944\n",
      "Epoch 2952, Loss: 0.4715508706867695, Final Batch Loss: 0.3026777505874634\n",
      "Epoch 2953, Loss: 0.2117069996893406, Final Batch Loss: 0.013764511793851852\n",
      "Epoch 2954, Loss: 0.2680909112095833, Final Batch Loss: 0.08975710719823837\n",
      "Epoch 2955, Loss: 0.38116776943206787, Final Batch Loss: 0.12204709649085999\n",
      "Epoch 2956, Loss: 0.2636833041906357, Final Batch Loss: 0.08608736842870712\n",
      "Epoch 2957, Loss: 0.2849220111966133, Final Batch Loss: 0.08377429842948914\n",
      "Epoch 2958, Loss: 0.2639966383576393, Final Batch Loss: 0.10227982699871063\n",
      "Epoch 2959, Loss: 0.3735367879271507, Final Batch Loss: 0.1779680699110031\n",
      "Epoch 2960, Loss: 0.35536181926727295, Final Batch Loss: 0.20637759566307068\n",
      "Epoch 2961, Loss: 0.33906662836670876, Final Batch Loss: 0.020033884793519974\n",
      "Epoch 2962, Loss: 0.39450886379927397, Final Batch Loss: 0.012784677557647228\n",
      "Epoch 2963, Loss: 0.6522387564182281, Final Batch Loss: 0.34338775277137756\n",
      "Epoch 2964, Loss: 0.23019194602966309, Final Batch Loss: 0.03439699113368988\n",
      "Epoch 2965, Loss: 0.2681105714291334, Final Batch Loss: 0.021444758400321007\n",
      "Epoch 2966, Loss: 0.32810600101947784, Final Batch Loss: 0.04959939420223236\n",
      "Epoch 2967, Loss: 0.40465283393859863, Final Batch Loss: 0.1651119887828827\n",
      "Epoch 2968, Loss: 0.3470548912882805, Final Batch Loss: 0.12944228947162628\n",
      "Epoch 2969, Loss: 0.36478742212057114, Final Batch Loss: 0.17460444569587708\n",
      "Epoch 2970, Loss: 0.39030711352825165, Final Batch Loss: 0.16628921031951904\n",
      "Epoch 2971, Loss: 0.2723357453942299, Final Batch Loss: 0.08868124336004257\n",
      "Epoch 2972, Loss: 0.27900734916329384, Final Batch Loss: 0.03518151119351387\n",
      "Epoch 2973, Loss: 0.5677147507667542, Final Batch Loss: 0.23318541049957275\n",
      "Epoch 2974, Loss: 0.8896020948886871, Final Batch Loss: 0.6139025092124939\n",
      "Epoch 2975, Loss: 0.34058233350515366, Final Batch Loss: 0.10070827603340149\n",
      "Epoch 2976, Loss: 0.24326958134770393, Final Batch Loss: 0.04785463586449623\n",
      "Epoch 2977, Loss: 0.3165922537446022, Final Batch Loss: 0.08542278409004211\n",
      "Epoch 2978, Loss: 0.182580741122365, Final Batch Loss: 0.017803827300667763\n",
      "Epoch 2979, Loss: 0.22333531454205513, Final Batch Loss: 0.04008355364203453\n",
      "Epoch 2980, Loss: 0.3332966938614845, Final Batch Loss: 0.1686571091413498\n",
      "Epoch 2981, Loss: 0.24603590369224548, Final Batch Loss: 0.04766055941581726\n",
      "Epoch 2982, Loss: 0.24769537895917892, Final Batch Loss: 0.03149288892745972\n",
      "Epoch 2983, Loss: 0.34525347501039505, Final Batch Loss: 0.11249452084302902\n",
      "Epoch 2984, Loss: 0.3233327865600586, Final Batch Loss: 0.08900948613882065\n",
      "Epoch 2985, Loss: 0.21002746373414993, Final Batch Loss: 0.010881580412387848\n",
      "Epoch 2986, Loss: 0.3110179901123047, Final Batch Loss: 0.1595582216978073\n",
      "Epoch 2987, Loss: 0.23306161910295486, Final Batch Loss: 0.03377057611942291\n",
      "Epoch 2988, Loss: 0.20535938255488873, Final Batch Loss: 0.016904635354876518\n",
      "Epoch 2989, Loss: 0.2704725619405508, Final Batch Loss: 0.023448040708899498\n",
      "Epoch 2990, Loss: 0.2166314534842968, Final Batch Loss: 0.01602502539753914\n",
      "Epoch 2991, Loss: 0.42664871737360954, Final Batch Loss: 0.29707154631614685\n",
      "Epoch 2992, Loss: 0.19016148522496223, Final Batch Loss: 0.03249652311205864\n",
      "Epoch 2993, Loss: 0.30658167600631714, Final Batch Loss: 0.0842001736164093\n",
      "Epoch 2994, Loss: 0.22605955228209496, Final Batch Loss: 0.09253116697072983\n",
      "Epoch 2995, Loss: 0.18644368462264538, Final Batch Loss: 0.0168581735342741\n",
      "Epoch 2996, Loss: 0.23031975328922272, Final Batch Loss: 0.06368698924779892\n",
      "Epoch 2997, Loss: 0.2726425416767597, Final Batch Loss: 0.1578047275543213\n",
      "Epoch 2998, Loss: 0.23686590790748596, Final Batch Loss: 0.09279792010784149\n",
      "Epoch 2999, Loss: 0.18741912208497524, Final Batch Loss: 0.0205043014138937\n",
      "Epoch 3000, Loss: 0.27485033869743347, Final Batch Loss: 0.07792921364307404\n",
      "Epoch 3001, Loss: 0.17446064855903387, Final Batch Loss: 0.014314754866063595\n",
      "Epoch 3002, Loss: 0.29703570157289505, Final Batch Loss: 0.13287165760993958\n",
      "Epoch 3003, Loss: 0.17516924068331718, Final Batch Loss: 0.024934250861406326\n",
      "Epoch 3004, Loss: 0.48389726132154465, Final Batch Loss: 0.30189457535743713\n",
      "Epoch 3005, Loss: 0.4092377796769142, Final Batch Loss: 0.24039451777935028\n",
      "Epoch 3006, Loss: 0.4785148352384567, Final Batch Loss: 0.21710996329784393\n",
      "Epoch 3007, Loss: 0.31297565437853336, Final Batch Loss: 0.017929011955857277\n",
      "Epoch 3008, Loss: 0.24066131561994553, Final Batch Loss: 0.02069087326526642\n",
      "Epoch 3009, Loss: 0.2753623202443123, Final Batch Loss: 0.0650150254368782\n",
      "Epoch 3010, Loss: 0.4048580080270767, Final Batch Loss: 0.2382727861404419\n",
      "Epoch 3011, Loss: 0.2588162338361144, Final Batch Loss: 0.007968827150762081\n",
      "Epoch 3012, Loss: 0.4212867319583893, Final Batch Loss: 0.17415504157543182\n",
      "Epoch 3013, Loss: 0.31082678958773613, Final Batch Loss: 0.06015675887465477\n",
      "Epoch 3014, Loss: 0.2445055954158306, Final Batch Loss: 0.0711699053645134\n",
      "Epoch 3015, Loss: 0.22708984464406967, Final Batch Loss: 0.0687234178185463\n",
      "Epoch 3016, Loss: 0.28434519097208977, Final Batch Loss: 0.031092587858438492\n",
      "Epoch 3017, Loss: 0.20623283088207245, Final Batch Loss: 0.03702842444181442\n",
      "Epoch 3018, Loss: 0.22546799667179585, Final Batch Loss: 0.028546186164021492\n",
      "Epoch 3019, Loss: 0.23676708340644836, Final Batch Loss: 0.08935900777578354\n",
      "Epoch 3020, Loss: 0.28489475697278976, Final Batch Loss: 0.1497330665588379\n",
      "Epoch 3021, Loss: 0.24627608805894852, Final Batch Loss: 0.05777760595083237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3022, Loss: 0.2337687686085701, Final Batch Loss: 0.10017632693052292\n",
      "Epoch 3023, Loss: 0.18095600698143244, Final Batch Loss: 0.012139790691435337\n",
      "Epoch 3024, Loss: 0.34740836173295975, Final Batch Loss: 0.19978725910186768\n",
      "Epoch 3025, Loss: 0.26933006569743156, Final Batch Loss: 0.1128588318824768\n",
      "Epoch 3026, Loss: 0.2996476888656616, Final Batch Loss: 0.11835458129644394\n",
      "Epoch 3027, Loss: 0.31221015751361847, Final Batch Loss: 0.12319579720497131\n",
      "Epoch 3028, Loss: 0.2491287812590599, Final Batch Loss: 0.07569845020771027\n",
      "Epoch 3029, Loss: 0.19280991330742836, Final Batch Loss: 0.03176790848374367\n",
      "Epoch 3030, Loss: 0.1919841282069683, Final Batch Loss: 0.04024399444460869\n",
      "Epoch 3031, Loss: 0.2284591756761074, Final Batch Loss: 0.08557858318090439\n",
      "Epoch 3032, Loss: 0.17112202057614923, Final Batch Loss: 0.003917133901268244\n",
      "Epoch 3033, Loss: 0.11742142541334033, Final Batch Loss: 0.002762857358902693\n",
      "Epoch 3034, Loss: 0.1997884027659893, Final Batch Loss: 0.04895341396331787\n",
      "Epoch 3035, Loss: 0.1863948181271553, Final Batch Loss: 0.03163626790046692\n",
      "Epoch 3036, Loss: 0.22898045927286148, Final Batch Loss: 0.06963687390089035\n",
      "Epoch 3037, Loss: 0.15542145818471909, Final Batch Loss: 0.023293066769838333\n",
      "Epoch 3038, Loss: 0.2910090386867523, Final Batch Loss: 0.11615727841854095\n",
      "Epoch 3039, Loss: 0.23534735292196274, Final Batch Loss: 0.05632125586271286\n",
      "Epoch 3040, Loss: 0.21889947354793549, Final Batch Loss: 0.0526144802570343\n",
      "Epoch 3041, Loss: 0.18081980012357235, Final Batch Loss: 0.02512284927070141\n",
      "Epoch 3042, Loss: 0.24116025865077972, Final Batch Loss: 0.11051279306411743\n",
      "Epoch 3043, Loss: 0.18402662128210068, Final Batch Loss: 0.04668912664055824\n",
      "Epoch 3044, Loss: 0.20486433431506157, Final Batch Loss: 0.04695868864655495\n",
      "Epoch 3045, Loss: 0.2264309637248516, Final Batch Loss: 0.09440208971500397\n",
      "Epoch 3046, Loss: 0.24967530369758606, Final Batch Loss: 0.11164312809705734\n",
      "Epoch 3047, Loss: 0.27287837490439415, Final Batch Loss: 0.05553850904107094\n",
      "Epoch 3048, Loss: 0.23933589458465576, Final Batch Loss: 0.09332675486803055\n",
      "Epoch 3049, Loss: 0.24975013360381126, Final Batch Loss: 0.11880394071340561\n",
      "Epoch 3050, Loss: 0.17559826467186213, Final Batch Loss: 0.013909892179071903\n",
      "Epoch 3051, Loss: 0.23273835331201553, Final Batch Loss: 0.09722727537155151\n",
      "Epoch 3052, Loss: 0.1544459331780672, Final Batch Loss: 0.006802594289183617\n",
      "Epoch 3053, Loss: 0.20735058933496475, Final Batch Loss: 0.04907337948679924\n",
      "Epoch 3054, Loss: 0.26696327328681946, Final Batch Loss: 0.12102331966161728\n",
      "Epoch 3055, Loss: 0.19948801025748253, Final Batch Loss: 0.042288731783628464\n",
      "Epoch 3056, Loss: 0.2261287160217762, Final Batch Loss: 0.045662034302949905\n",
      "Epoch 3057, Loss: 0.27588846907019615, Final Batch Loss: 0.023324955254793167\n",
      "Epoch 3058, Loss: 0.33951229602098465, Final Batch Loss: 0.1190195232629776\n",
      "Epoch 3059, Loss: 0.25400716811418533, Final Batch Loss: 0.0985703095793724\n",
      "Epoch 3060, Loss: 0.2362193465232849, Final Batch Loss: 0.035744115710258484\n",
      "Epoch 3061, Loss: 0.23301711678504944, Final Batch Loss: 0.07731874287128448\n",
      "Epoch 3062, Loss: 0.15781930834054947, Final Batch Loss: 0.03996266797184944\n",
      "Epoch 3063, Loss: 0.15922871977090836, Final Batch Loss: 0.03931140527129173\n",
      "Epoch 3064, Loss: 0.20183365885168314, Final Batch Loss: 0.005704493261873722\n",
      "Epoch 3065, Loss: 0.1914229430258274, Final Batch Loss: 0.05433226749300957\n",
      "Epoch 3066, Loss: 0.16793944733217359, Final Batch Loss: 0.0038715158589184284\n",
      "Epoch 3067, Loss: 0.171961834654212, Final Batch Loss: 0.010505897924304008\n",
      "Epoch 3068, Loss: 0.2129889838397503, Final Batch Loss: 0.06854857504367828\n",
      "Epoch 3069, Loss: 0.14389704912900925, Final Batch Loss: 0.0221138596534729\n",
      "Epoch 3070, Loss: 0.14778965048026294, Final Batch Loss: 0.0015297987265512347\n",
      "Epoch 3071, Loss: 0.12244534306228161, Final Batch Loss: 0.018028831109404564\n",
      "Epoch 3072, Loss: 0.2096494324505329, Final Batch Loss: 0.03203325346112251\n",
      "Epoch 3073, Loss: 0.3356190398335457, Final Batch Loss: 0.20060844719409943\n",
      "Epoch 3074, Loss: 0.28704166412353516, Final Batch Loss: 0.12080516666173935\n",
      "Epoch 3075, Loss: 0.2335355244576931, Final Batch Loss: 0.06072014197707176\n",
      "Epoch 3076, Loss: 0.2992991507053375, Final Batch Loss: 0.12061291188001633\n",
      "Epoch 3077, Loss: 0.2185107208788395, Final Batch Loss: 0.05444012209773064\n",
      "Epoch 3078, Loss: 0.24157022312283516, Final Batch Loss: 0.031230349093675613\n",
      "Epoch 3079, Loss: 0.208356324583292, Final Batch Loss: 0.07410190254449844\n",
      "Epoch 3080, Loss: 0.25271977484226227, Final Batch Loss: 0.06903324276208878\n",
      "Epoch 3081, Loss: 0.141983182169497, Final Batch Loss: 0.010593187995254993\n",
      "Epoch 3082, Loss: 0.16755394637584686, Final Batch Loss: 0.030979551374912262\n",
      "Epoch 3083, Loss: 0.33593080192804337, Final Batch Loss: 0.1543622463941574\n",
      "Epoch 3084, Loss: 0.2143927700817585, Final Batch Loss: 0.08725009858608246\n",
      "Epoch 3085, Loss: 0.20783135294914246, Final Batch Loss: 0.0395149290561676\n",
      "Epoch 3086, Loss: 0.15367752499878407, Final Batch Loss: 0.021647313609719276\n",
      "Epoch 3087, Loss: 0.19916393980383873, Final Batch Loss: 0.09052950143814087\n",
      "Epoch 3088, Loss: 0.25233056396245956, Final Batch Loss: 0.10119336098432541\n",
      "Epoch 3089, Loss: 0.21021590009331703, Final Batch Loss: 0.02234795317053795\n",
      "Epoch 3090, Loss: 0.5348686203360558, Final Batch Loss: 0.3199521005153656\n",
      "Epoch 3091, Loss: 0.14443446788936853, Final Batch Loss: 0.011457891203463078\n",
      "Epoch 3092, Loss: 0.15986331109888852, Final Batch Loss: 0.001250396715477109\n",
      "Epoch 3093, Loss: 0.30743318423628807, Final Batch Loss: 0.1560857892036438\n",
      "Epoch 3094, Loss: 0.43104366585612297, Final Batch Loss: 0.25709572434425354\n",
      "Epoch 3095, Loss: 0.18971831072121859, Final Batch Loss: 0.007480950094759464\n",
      "Epoch 3096, Loss: 0.22564115934073925, Final Batch Loss: 0.024231476709246635\n",
      "Epoch 3097, Loss: 0.2371082715690136, Final Batch Loss: 0.01908034458756447\n",
      "Epoch 3098, Loss: 0.21989724412560463, Final Batch Loss: 0.038814086467027664\n",
      "Epoch 3099, Loss: 0.2272309549152851, Final Batch Loss: 0.057121846824884415\n",
      "Epoch 3100, Loss: 0.23007460311055183, Final Batch Loss: 0.030234914273023605\n",
      "Epoch 3101, Loss: 0.29975876584649086, Final Batch Loss: 0.1724107712507248\n",
      "Epoch 3102, Loss: 0.18112081289291382, Final Batch Loss: 0.026749029755592346\n",
      "Epoch 3103, Loss: 0.15583370998501778, Final Batch Loss: 0.027990534901618958\n",
      "Epoch 3104, Loss: 0.18441206775605679, Final Batch Loss: 0.023702731356024742\n",
      "Epoch 3105, Loss: 0.2774582803249359, Final Batch Loss: 0.09835228323936462\n",
      "Epoch 3106, Loss: 0.17398280650377274, Final Batch Loss: 0.03807881474494934\n",
      "Epoch 3107, Loss: 0.14944612188264728, Final Batch Loss: 0.004965085070580244\n",
      "Epoch 3108, Loss: 0.17021408630535007, Final Batch Loss: 0.0026893983595073223\n",
      "Epoch 3109, Loss: 0.2624988704919815, Final Batch Loss: 0.06525034457445145\n",
      "Epoch 3110, Loss: 0.16039934195578098, Final Batch Loss: 0.01850041188299656\n",
      "Epoch 3111, Loss: 0.19298886694014072, Final Batch Loss: 0.02425115741789341\n",
      "Epoch 3112, Loss: 0.22025688737630844, Final Batch Loss: 0.09790508449077606\n",
      "Epoch 3113, Loss: 0.15051291836425662, Final Batch Loss: 0.004831395577639341\n",
      "Epoch 3114, Loss: 0.19363189861178398, Final Batch Loss: 0.03413696214556694\n",
      "Epoch 3115, Loss: 0.3486405983567238, Final Batch Loss: 0.19956956803798676\n",
      "Epoch 3116, Loss: 0.268271304666996, Final Batch Loss: 0.09483134746551514\n",
      "Epoch 3117, Loss: 0.3298345897346735, Final Batch Loss: 0.03103366680443287\n",
      "Epoch 3118, Loss: 0.36855563521385193, Final Batch Loss: 0.1899108588695526\n",
      "Epoch 3119, Loss: 0.2081213928759098, Final Batch Loss: 0.047261208295822144\n",
      "Epoch 3120, Loss: 0.4997270256280899, Final Batch Loss: 0.30798861384391785\n",
      "Epoch 3121, Loss: 0.35344525426626205, Final Batch Loss: 0.18560858070850372\n",
      "Epoch 3122, Loss: 0.23793775402009487, Final Batch Loss: 0.026790013536810875\n",
      "Epoch 3123, Loss: 0.3261255472898483, Final Batch Loss: 0.14202409982681274\n",
      "Epoch 3124, Loss: 0.3730071373283863, Final Batch Loss: 0.2099706381559372\n",
      "Epoch 3125, Loss: 0.2599082663655281, Final Batch Loss: 0.09336671978235245\n",
      "Epoch 3126, Loss: 0.2709541586227715, Final Batch Loss: 0.0029963520355522633\n",
      "Epoch 3127, Loss: 0.2953733876347542, Final Batch Loss: 0.06414664536714554\n",
      "Epoch 3128, Loss: 0.296261802315712, Final Batch Loss: 0.11166734248399734\n",
      "Epoch 3129, Loss: 0.3321506194770336, Final Batch Loss: 0.1902838945388794\n",
      "Epoch 3130, Loss: 0.2191847376525402, Final Batch Loss: 0.03757302835583687\n",
      "Epoch 3131, Loss: 0.40701255574822426, Final Batch Loss: 0.03290434554219246\n",
      "Epoch 3132, Loss: 0.45589443668723106, Final Batch Loss: 0.055762242525815964\n",
      "Epoch 3133, Loss: 0.45840366184711456, Final Batch Loss: 0.1634749323129654\n",
      "Epoch 3134, Loss: 0.43951231986284256, Final Batch Loss: 0.23766084015369415\n",
      "Epoch 3135, Loss: 0.5228750854730606, Final Batch Loss: 0.26304954290390015\n",
      "Epoch 3136, Loss: 0.2592550767585635, Final Batch Loss: 0.007528792135417461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3137, Loss: 0.4087216332554817, Final Batch Loss: 0.16307665407657623\n",
      "Epoch 3138, Loss: 0.28663067519664764, Final Batch Loss: 0.08018659055233002\n",
      "Epoch 3139, Loss: 0.22177006676793098, Final Batch Loss: 0.03958899900317192\n",
      "Epoch 3140, Loss: 0.29258424043655396, Final Batch Loss: 0.028072021901607513\n",
      "Epoch 3141, Loss: 0.19685120042413473, Final Batch Loss: 0.009008183144032955\n",
      "Epoch 3142, Loss: 0.20389341935515404, Final Batch Loss: 0.046787526458501816\n",
      "Epoch 3143, Loss: 0.2194632850587368, Final Batch Loss: 0.0362427718937397\n",
      "Epoch 3144, Loss: 0.20326494053006172, Final Batch Loss: 0.03950676694512367\n",
      "Epoch 3145, Loss: 0.2714019864797592, Final Batch Loss: 0.11936189234256744\n",
      "Epoch 3146, Loss: 0.2624578922986984, Final Batch Loss: 0.09694864600896835\n",
      "Epoch 3147, Loss: 0.15566921047866344, Final Batch Loss: 0.015703236684203148\n",
      "Epoch 3148, Loss: 0.20792920142412186, Final Batch Loss: 0.0446244478225708\n",
      "Epoch 3149, Loss: 0.3829898238182068, Final Batch Loss: 0.15350279211997986\n",
      "Epoch 3150, Loss: 0.21810563281178474, Final Batch Loss: 0.08070040494203568\n",
      "Epoch 3151, Loss: 0.21060572564601898, Final Batch Loss: 0.0572376549243927\n",
      "Epoch 3152, Loss: 0.38538965582847595, Final Batch Loss: 0.10832405090332031\n",
      "Epoch 3153, Loss: 0.3456073999404907, Final Batch Loss: 0.04887774586677551\n",
      "Epoch 3154, Loss: 0.2095051296055317, Final Batch Loss: 0.00477227196097374\n",
      "Epoch 3155, Loss: 0.2639009915292263, Final Batch Loss: 0.10853895545005798\n",
      "Epoch 3156, Loss: 0.17323311604559422, Final Batch Loss: 0.024441631510853767\n",
      "Epoch 3157, Loss: 0.2730390094220638, Final Batch Loss: 0.14449645578861237\n",
      "Epoch 3158, Loss: 0.25686225667595863, Final Batch Loss: 0.12231136858463287\n",
      "Epoch 3159, Loss: 0.2615436799824238, Final Batch Loss: 0.11993509531021118\n",
      "Epoch 3160, Loss: 0.2728227972984314, Final Batch Loss: 0.09868783503770828\n",
      "Epoch 3161, Loss: 0.4373665899038315, Final Batch Loss: 0.2549037039279938\n",
      "Epoch 3162, Loss: 0.24410263542085886, Final Batch Loss: 0.013291710056364536\n",
      "Epoch 3163, Loss: 0.6852785125374794, Final Batch Loss: 0.44352856278419495\n",
      "Epoch 3164, Loss: 0.5291090831160545, Final Batch Loss: 0.3108249604701996\n",
      "Epoch 3165, Loss: 0.2159045673906803, Final Batch Loss: 0.035999711602926254\n",
      "Epoch 3166, Loss: 0.18231847137212753, Final Batch Loss: 0.055430199950933456\n",
      "Epoch 3167, Loss: 0.21392486616969109, Final Batch Loss: 0.038512181490659714\n",
      "Epoch 3168, Loss: 0.14761200826615095, Final Batch Loss: 0.004459458403289318\n",
      "Epoch 3169, Loss: 0.20504869148135185, Final Batch Loss: 0.03597525134682655\n",
      "Epoch 3170, Loss: 0.5035011768341064, Final Batch Loss: 0.28436508774757385\n",
      "Epoch 3171, Loss: 0.22048668935894966, Final Batch Loss: 0.03249431774020195\n",
      "Epoch 3172, Loss: 0.22046244516968727, Final Batch Loss: 0.044785913079977036\n",
      "Epoch 3173, Loss: 0.20396243035793304, Final Batch Loss: 0.06201620399951935\n",
      "Epoch 3174, Loss: 0.168051369022578, Final Batch Loss: 0.004180617164820433\n",
      "Epoch 3175, Loss: 0.2088312953710556, Final Batch Loss: 0.061636731028556824\n",
      "Epoch 3176, Loss: 0.42550425976514816, Final Batch Loss: 0.2543005347251892\n",
      "Epoch 3177, Loss: 0.33997540175914764, Final Batch Loss: 0.1653454750776291\n",
      "Epoch 3178, Loss: 0.45679593458771706, Final Batch Loss: 0.051372233778238297\n",
      "Epoch 3179, Loss: 0.44452595710754395, Final Batch Loss: 0.06379850208759308\n",
      "Epoch 3180, Loss: 0.4560728147625923, Final Batch Loss: 0.10508973151445389\n",
      "Epoch 3181, Loss: 0.33896053582429886, Final Batch Loss: 0.07529765367507935\n",
      "Epoch 3182, Loss: 0.4031941071152687, Final Batch Loss: 0.09299734979867935\n",
      "Epoch 3183, Loss: 0.3743872344493866, Final Batch Loss: 0.06989511847496033\n",
      "Epoch 3184, Loss: 0.517848789691925, Final Batch Loss: 0.27055755257606506\n",
      "Epoch 3185, Loss: 0.21539192646741867, Final Batch Loss: 0.03134670853614807\n",
      "Epoch 3186, Loss: 0.24630228243768215, Final Batch Loss: 0.014563767239451408\n",
      "Epoch 3187, Loss: 0.24859851691871881, Final Batch Loss: 0.010725037194788456\n",
      "Epoch 3188, Loss: 0.2194726448506117, Final Batch Loss: 0.019015973433852196\n",
      "Epoch 3189, Loss: 0.24818589352071285, Final Batch Loss: 0.018329767510294914\n",
      "Epoch 3190, Loss: 0.4285981357097626, Final Batch Loss: 0.16922634840011597\n",
      "Epoch 3191, Loss: 0.20156918466091156, Final Batch Loss: 0.036953963339328766\n",
      "Epoch 3192, Loss: 0.16592822968959808, Final Batch Loss: 0.05382673814892769\n",
      "Epoch 3193, Loss: 0.17397581599652767, Final Batch Loss: 0.023577092215418816\n",
      "Epoch 3194, Loss: 0.16091394401155412, Final Batch Loss: 0.002096347277984023\n",
      "Epoch 3195, Loss: 0.32084570825099945, Final Batch Loss: 0.18111251294612885\n",
      "Epoch 3196, Loss: 0.21851928532123566, Final Batch Loss: 0.026170507073402405\n",
      "Epoch 3197, Loss: 0.2084164172410965, Final Batch Loss: 0.04386815428733826\n",
      "Epoch 3198, Loss: 0.23977543413639069, Final Batch Loss: 0.07435530424118042\n",
      "Epoch 3199, Loss: 0.35642169788479805, Final Batch Loss: 0.22469176352024078\n",
      "Epoch 3200, Loss: 0.1915053129196167, Final Batch Loss: 0.019308730959892273\n",
      "Epoch 3201, Loss: 0.29832377284765244, Final Batch Loss: 0.11526999622583389\n",
      "Epoch 3202, Loss: 0.32758910208940506, Final Batch Loss: 0.16736920177936554\n",
      "Epoch 3203, Loss: 0.23969050496816635, Final Batch Loss: 0.06514646857976913\n",
      "Epoch 3204, Loss: 0.2721122056245804, Final Batch Loss: 0.09336937963962555\n",
      "Epoch 3205, Loss: 0.17897837096825242, Final Batch Loss: 0.006137596908956766\n",
      "Epoch 3206, Loss: 0.3333132788538933, Final Batch Loss: 0.11472301930189133\n",
      "Epoch 3207, Loss: 0.19455434381961823, Final Batch Loss: 0.0374913364648819\n",
      "Epoch 3208, Loss: 0.29215335473418236, Final Batch Loss: 0.12920916080474854\n",
      "Epoch 3209, Loss: 0.344194196164608, Final Batch Loss: 0.17058326303958893\n",
      "Epoch 3210, Loss: 0.33125142753124237, Final Batch Loss: 0.12258006632328033\n",
      "Epoch 3211, Loss: 0.20922377333045006, Final Batch Loss: 0.04162241891026497\n",
      "Epoch 3212, Loss: 0.32352666556835175, Final Batch Loss: 0.06593106687068939\n",
      "Epoch 3213, Loss: 0.1840116549283266, Final Batch Loss: 0.015763359144330025\n",
      "Epoch 3214, Loss: 0.3187696263194084, Final Batch Loss: 0.10162052512168884\n",
      "Epoch 3215, Loss: 0.27230124175548553, Final Batch Loss: 0.0793537050485611\n",
      "Epoch 3216, Loss: 0.21535793878138065, Final Batch Loss: 0.023116501048207283\n",
      "Epoch 3217, Loss: 0.20858816802501678, Final Batch Loss: 0.017012573778629303\n",
      "Epoch 3218, Loss: 0.17950243223458529, Final Batch Loss: 0.015363690443336964\n",
      "Epoch 3219, Loss: 0.3129741922020912, Final Batch Loss: 0.13615961372852325\n",
      "Epoch 3220, Loss: 0.17442142125219107, Final Batch Loss: 0.014636165462434292\n",
      "Epoch 3221, Loss: 0.2226859088987112, Final Batch Loss: 0.022234199568629265\n",
      "Epoch 3222, Loss: 0.1428300398401916, Final Batch Loss: 0.007519386243075132\n",
      "Epoch 3223, Loss: 0.2806474454700947, Final Batch Loss: 0.06192626431584358\n",
      "Epoch 3224, Loss: 0.4635694846510887, Final Batch Loss: 0.327587366104126\n",
      "Epoch 3225, Loss: 0.1380521021783352, Final Batch Loss: 0.0357242114841938\n",
      "Epoch 3226, Loss: 0.2824643477797508, Final Batch Loss: 0.09896879643201828\n",
      "Epoch 3227, Loss: 0.3739309124648571, Final Batch Loss: 0.24836379289627075\n",
      "Epoch 3228, Loss: 0.1659387480467558, Final Batch Loss: 0.008885292336344719\n",
      "Epoch 3229, Loss: 0.6656354814767838, Final Batch Loss: 0.30624520778656006\n",
      "Epoch 3230, Loss: 0.3259008824825287, Final Batch Loss: 0.1088939979672432\n",
      "Epoch 3231, Loss: 0.37795500829815865, Final Batch Loss: 0.015349913388490677\n",
      "Epoch 3232, Loss: 0.572925254702568, Final Batch Loss: 0.15992702543735504\n",
      "Epoch 3233, Loss: 0.322212124010548, Final Batch Loss: 0.00329506560228765\n",
      "Epoch 3234, Loss: 0.580621674656868, Final Batch Loss: 0.2905367910861969\n",
      "Epoch 3235, Loss: 0.31479449197649956, Final Batch Loss: 0.04478048160672188\n",
      "Epoch 3236, Loss: 0.44319748878479004, Final Batch Loss: 0.12312689423561096\n",
      "Epoch 3237, Loss: 0.3750290051102638, Final Batch Loss: 0.06699099391698837\n",
      "Epoch 3238, Loss: 0.4665221571922302, Final Batch Loss: 0.1969490796327591\n",
      "Epoch 3239, Loss: 0.3841744214296341, Final Batch Loss: 0.13269616663455963\n",
      "Epoch 3240, Loss: 0.3360244706273079, Final Batch Loss: 0.12652157247066498\n",
      "Epoch 3241, Loss: 0.4410094916820526, Final Batch Loss: 0.23717734217643738\n",
      "Epoch 3242, Loss: 0.38410235196352005, Final Batch Loss: 0.15414471924304962\n",
      "Epoch 3243, Loss: 0.32085495442152023, Final Batch Loss: 0.11079432815313339\n",
      "Epoch 3244, Loss: 0.4239937290549278, Final Batch Loss: 0.23959292471408844\n",
      "Epoch 3245, Loss: 0.33628787845373154, Final Batch Loss: 0.12003814429044724\n",
      "Epoch 3246, Loss: 0.29237715899944305, Final Batch Loss: 0.044008880853652954\n",
      "Epoch 3247, Loss: 0.1923055425286293, Final Batch Loss: 0.026395343244075775\n",
      "Epoch 3248, Loss: 0.32260503619909286, Final Batch Loss: 0.10987566411495209\n",
      "Epoch 3249, Loss: 0.3156631886959076, Final Batch Loss: 0.07305172830820084\n",
      "Epoch 3250, Loss: 0.23655641078948975, Final Batch Loss: 0.03493908792734146\n",
      "Epoch 3251, Loss: 0.2953873351216316, Final Batch Loss: 0.09695040434598923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3252, Loss: 0.3310205116868019, Final Batch Loss: 0.12985102832317352\n",
      "Epoch 3253, Loss: 0.21109935641288757, Final Batch Loss: 0.04089267551898956\n",
      "Epoch 3254, Loss: 0.38212981075048447, Final Batch Loss: 0.20309118926525116\n",
      "Epoch 3255, Loss: 0.3543376252055168, Final Batch Loss: 0.1844896823167801\n",
      "Epoch 3256, Loss: 0.2348652258515358, Final Batch Loss: 0.04845912754535675\n",
      "Epoch 3257, Loss: 0.16959599405527115, Final Batch Loss: 0.028826452791690826\n",
      "Epoch 3258, Loss: 0.3809371367096901, Final Batch Loss: 0.1874508410692215\n",
      "Epoch 3259, Loss: 0.2462637685239315, Final Batch Loss: 0.05598174408078194\n",
      "Epoch 3260, Loss: 0.34940140694379807, Final Batch Loss: 0.17305390536785126\n",
      "Epoch 3261, Loss: 0.24679624661803246, Final Batch Loss: 0.04160679504275322\n",
      "Epoch 3262, Loss: 0.2169226035475731, Final Batch Loss: 0.06280756741762161\n",
      "Epoch 3263, Loss: 0.21948323398828506, Final Batch Loss: 0.04146018624305725\n",
      "Epoch 3264, Loss: 0.21637516468763351, Final Batch Loss: 0.03193497657775879\n",
      "Epoch 3265, Loss: 0.268205925822258, Final Batch Loss: 0.09308583289384842\n",
      "Epoch 3266, Loss: 0.15939314663410187, Final Batch Loss: 0.037231653928756714\n",
      "Epoch 3267, Loss: 0.4610528349876404, Final Batch Loss: 0.2603938579559326\n",
      "Epoch 3268, Loss: 0.235271655023098, Final Batch Loss: 0.03686932474374771\n",
      "Epoch 3269, Loss: 0.32264402508735657, Final Batch Loss: 0.1363849937915802\n",
      "Epoch 3270, Loss: 0.28874025493860245, Final Batch Loss: 0.11865401268005371\n",
      "Epoch 3271, Loss: 0.1837749765254557, Final Batch Loss: 0.0045788646675646305\n",
      "Epoch 3272, Loss: 0.3127246107906103, Final Batch Loss: 0.02954617701470852\n",
      "Epoch 3273, Loss: 0.21467268839478493, Final Batch Loss: 0.03917312994599342\n",
      "Epoch 3274, Loss: 0.2179592289030552, Final Batch Loss: 0.03410230949521065\n",
      "Epoch 3275, Loss: 0.27507954835891724, Final Batch Loss: 0.09849055856466293\n",
      "Epoch 3276, Loss: 0.37189681082963943, Final Batch Loss: 0.1604822874069214\n",
      "Epoch 3277, Loss: 0.2179130781441927, Final Batch Loss: 0.026159072294831276\n",
      "Epoch 3278, Loss: 0.2374700829386711, Final Batch Loss: 0.046101123094558716\n",
      "Epoch 3279, Loss: 0.23843586258590221, Final Batch Loss: 0.021458176895976067\n",
      "Epoch 3280, Loss: 0.20777304470539093, Final Batch Loss: 0.04467035084962845\n",
      "Epoch 3281, Loss: 0.15061681531369686, Final Batch Loss: 0.02410651557147503\n",
      "Epoch 3282, Loss: 0.20132660120725632, Final Batch Loss: 0.04125214368104935\n",
      "Epoch 3283, Loss: 0.23419203236699104, Final Batch Loss: 0.03858591988682747\n",
      "Epoch 3284, Loss: 0.16550282016396523, Final Batch Loss: 0.028690658509731293\n",
      "Epoch 3285, Loss: 0.18072846485301852, Final Batch Loss: 0.006019837688654661\n",
      "Epoch 3286, Loss: 0.21628891304135323, Final Batch Loss: 0.061994753777980804\n",
      "Epoch 3287, Loss: 0.27358295768499374, Final Batch Loss: 0.062212951481342316\n",
      "Epoch 3288, Loss: 0.21514060348272324, Final Batch Loss: 0.039513155817985535\n",
      "Epoch 3289, Loss: 0.15715955384075642, Final Batch Loss: 0.00019739754498004913\n",
      "Epoch 3290, Loss: 0.2357904314994812, Final Batch Loss: 0.06655717641115189\n",
      "Epoch 3291, Loss: 0.20838748663663864, Final Batch Loss: 0.022696442902088165\n",
      "Epoch 3292, Loss: 0.2546779662370682, Final Batch Loss: 0.10090123862028122\n",
      "Epoch 3293, Loss: 0.22221334278583527, Final Batch Loss: 0.08729854971170425\n",
      "Epoch 3294, Loss: 0.45840083807706833, Final Batch Loss: 0.2938927710056305\n",
      "Epoch 3295, Loss: 0.17472418770194054, Final Batch Loss: 0.04302585497498512\n",
      "Epoch 3296, Loss: 0.2216586023569107, Final Batch Loss: 0.073653943836689\n",
      "Epoch 3297, Loss: 0.2013283483684063, Final Batch Loss: 0.08068230748176575\n",
      "Epoch 3298, Loss: 0.14443874917924404, Final Batch Loss: 0.005319217219948769\n",
      "Epoch 3299, Loss: 0.16981652565300465, Final Batch Loss: 0.023933755233883858\n",
      "Epoch 3300, Loss: 0.23581082373857498, Final Batch Loss: 0.08018171787261963\n",
      "Epoch 3301, Loss: 0.25214145332574844, Final Batch Loss: 0.11264988034963608\n",
      "Epoch 3302, Loss: 0.16681987419724464, Final Batch Loss: 0.03352982923388481\n",
      "Epoch 3303, Loss: 0.11935822293162346, Final Batch Loss: 0.005283433943986893\n",
      "Epoch 3304, Loss: 0.30624863877892494, Final Batch Loss: 0.18755114078521729\n",
      "Epoch 3305, Loss: 0.3303254544734955, Final Batch Loss: 0.17575328052043915\n",
      "Epoch 3306, Loss: 0.26260510832071304, Final Batch Loss: 0.03335341066122055\n",
      "Epoch 3307, Loss: 0.20018963515758514, Final Batch Loss: 0.04118921607732773\n",
      "Epoch 3308, Loss: 0.15649830922484398, Final Batch Loss: 0.015895310789346695\n",
      "Epoch 3309, Loss: 0.2703513167798519, Final Batch Loss: 0.1314593255519867\n",
      "Epoch 3310, Loss: 0.15721971355378628, Final Batch Loss: 0.003910860046744347\n",
      "Epoch 3311, Loss: 0.16912919888272882, Final Batch Loss: 0.003256662283092737\n",
      "Epoch 3312, Loss: 0.17236476857215166, Final Batch Loss: 0.009945453144609928\n",
      "Epoch 3313, Loss: 0.18687332794070244, Final Batch Loss: 0.04495600610971451\n",
      "Epoch 3314, Loss: 0.2131507843732834, Final Batch Loss: 0.07344205677509308\n",
      "Epoch 3315, Loss: 0.2538457214832306, Final Batch Loss: 0.11313877254724503\n",
      "Epoch 3316, Loss: 0.27786623127758503, Final Batch Loss: 0.030170584097504616\n",
      "Epoch 3317, Loss: 0.2004016637802124, Final Batch Loss: 0.058744877576828\n",
      "Epoch 3318, Loss: 0.23132041096687317, Final Batch Loss: 0.04635878652334213\n",
      "Epoch 3319, Loss: 0.18856722861528397, Final Batch Loss: 0.014748096466064453\n",
      "Epoch 3320, Loss: 0.23925112560391426, Final Batch Loss: 0.040271151810884476\n",
      "Epoch 3321, Loss: 0.1418415883090347, Final Batch Loss: 0.0031345465686172247\n",
      "Epoch 3322, Loss: 0.3687042370438576, Final Batch Loss: 0.2201978713274002\n",
      "Epoch 3323, Loss: 0.17192920669913292, Final Batch Loss: 0.03522755578160286\n",
      "Epoch 3324, Loss: 0.19852482085116208, Final Batch Loss: 0.0019723318982869387\n",
      "Epoch 3325, Loss: 0.160000991076231, Final Batch Loss: 0.019733410328626633\n",
      "Epoch 3326, Loss: 0.7230885811150074, Final Batch Loss: 0.5679687261581421\n",
      "Epoch 3327, Loss: 0.4614589810371399, Final Batch Loss: 0.2919897437095642\n",
      "Epoch 3328, Loss: 0.5616600215435028, Final Batch Loss: 0.15149886906147003\n",
      "Epoch 3329, Loss: 0.615663930773735, Final Batch Loss: 0.30056849122047424\n",
      "Epoch 3330, Loss: 0.3591604884713888, Final Batch Loss: 0.023564374074339867\n",
      "Epoch 3331, Loss: 0.4513891786336899, Final Batch Loss: 0.1664048284292221\n",
      "Epoch 3332, Loss: 0.24897474667523056, Final Batch Loss: 0.001345901400782168\n",
      "Epoch 3333, Loss: 0.3262724503874779, Final Batch Loss: 0.0639435201883316\n",
      "Epoch 3334, Loss: 0.6698776632547379, Final Batch Loss: 0.24220822751522064\n",
      "Epoch 3335, Loss: 0.6166640520095825, Final Batch Loss: 0.32929229736328125\n",
      "Epoch 3336, Loss: 0.3125236742198467, Final Batch Loss: 0.033760007470846176\n",
      "Epoch 3337, Loss: 0.3359174281358719, Final Batch Loss: 0.08220717310905457\n",
      "Epoch 3338, Loss: 0.4077504873275757, Final Batch Loss: 0.1336534023284912\n",
      "Epoch 3339, Loss: 0.2241841747891158, Final Batch Loss: 0.0009695112239569426\n",
      "Epoch 3340, Loss: 0.23696983233094215, Final Batch Loss: 0.0048021189868450165\n",
      "Epoch 3341, Loss: 0.37858687341213226, Final Batch Loss: 0.17252542078495026\n",
      "Epoch 3342, Loss: 0.27552536875009537, Final Batch Loss: 0.11977878212928772\n",
      "Epoch 3343, Loss: 0.482242114841938, Final Batch Loss: 0.2792697846889496\n",
      "Epoch 3344, Loss: 0.5643254145979881, Final Batch Loss: 0.36798131465911865\n",
      "Epoch 3345, Loss: 0.2601311206817627, Final Batch Loss: 0.09217550605535507\n",
      "Epoch 3346, Loss: 0.2157801240682602, Final Batch Loss: 0.023238621652126312\n",
      "Epoch 3347, Loss: 0.475550077855587, Final Batch Loss: 0.27072980999946594\n",
      "Epoch 3348, Loss: 0.25509233213961124, Final Batch Loss: 0.026704872027039528\n",
      "Epoch 3349, Loss: 0.39864372834563255, Final Batch Loss: 0.26135504245758057\n",
      "Epoch 3350, Loss: 0.1775957839563489, Final Batch Loss: 0.0049226852133870125\n",
      "Epoch 3351, Loss: 0.25380364805459976, Final Batch Loss: 0.0788809210062027\n",
      "Epoch 3352, Loss: 0.2048339508473873, Final Batch Loss: 0.0588827021420002\n",
      "Epoch 3353, Loss: 0.2339881956577301, Final Batch Loss: 0.08778834342956543\n",
      "Epoch 3354, Loss: 0.3012383058667183, Final Batch Loss: 0.11244004964828491\n",
      "Epoch 3355, Loss: 0.19427523389458656, Final Batch Loss: 0.03948676213622093\n",
      "Epoch 3356, Loss: 0.18744793720543385, Final Batch Loss: 0.008997222408652306\n",
      "Epoch 3357, Loss: 0.17675493843853474, Final Batch Loss: 0.010278554633259773\n",
      "Epoch 3358, Loss: 0.34874312207102776, Final Batch Loss: 0.2261151820421219\n",
      "Epoch 3359, Loss: 0.5870917439460754, Final Batch Loss: 0.4220134913921356\n",
      "Epoch 3360, Loss: 0.20681595988571644, Final Batch Loss: 0.019804837182164192\n",
      "Epoch 3361, Loss: 0.49361737817525864, Final Batch Loss: 0.2608201503753662\n",
      "Epoch 3362, Loss: 0.27948563173413277, Final Batch Loss: 0.04671463742852211\n",
      "Epoch 3363, Loss: 0.242850661277771, Final Batch Loss: 0.04493797570466995\n",
      "Epoch 3364, Loss: 0.5631133317947388, Final Batch Loss: 0.42996495962142944\n",
      "Epoch 3365, Loss: 0.594932533800602, Final Batch Loss: 0.3472459316253662\n",
      "Epoch 3366, Loss: 0.574299730360508, Final Batch Loss: 0.07003619521856308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3367, Loss: 1.3127508163452148, Final Batch Loss: 0.8740822672843933\n",
      "Epoch 3368, Loss: 0.35299813747406006, Final Batch Loss: 0.0880834087729454\n",
      "Epoch 3369, Loss: 0.9453599750995636, Final Batch Loss: 0.5047987103462219\n",
      "Epoch 3370, Loss: 0.41320538334548473, Final Batch Loss: 0.02332851104438305\n",
      "Epoch 3371, Loss: 0.45891910791397095, Final Batch Loss: 0.13527467846870422\n",
      "Epoch 3372, Loss: 0.3950938656926155, Final Batch Loss: 0.10280690342187881\n",
      "Epoch 3373, Loss: 0.33245301246643066, Final Batch Loss: 0.09627304971218109\n",
      "Epoch 3374, Loss: 0.30763138737529516, Final Batch Loss: 0.014209910295903683\n",
      "Epoch 3375, Loss: 0.4938850700855255, Final Batch Loss: 0.19746069610118866\n",
      "Epoch 3376, Loss: 0.35885559022426605, Final Batch Loss: 0.10450027883052826\n",
      "Epoch 3377, Loss: 0.2578106541186571, Final Batch Loss: 0.018418552353978157\n",
      "Epoch 3378, Loss: 0.3517187833786011, Final Batch Loss: 0.10566648840904236\n",
      "Epoch 3379, Loss: 0.20721750147640705, Final Batch Loss: 0.017462195828557014\n",
      "Epoch 3380, Loss: 0.2433733344078064, Final Batch Loss: 0.04027906060218811\n",
      "Epoch 3381, Loss: 0.3776612728834152, Final Batch Loss: 0.19160665571689606\n",
      "Epoch 3382, Loss: 0.352683387696743, Final Batch Loss: 0.19258153438568115\n",
      "Epoch 3383, Loss: 0.2468104436993599, Final Batch Loss: 0.06261155754327774\n",
      "Epoch 3384, Loss: 0.32825184613466263, Final Batch Loss: 0.11270810663700104\n",
      "Epoch 3385, Loss: 0.3820740394294262, Final Batch Loss: 0.20172075927257538\n",
      "Epoch 3386, Loss: 0.24639024958014488, Final Batch Loss: 0.051190685480833054\n",
      "Epoch 3387, Loss: 0.3480863571166992, Final Batch Loss: 0.17996874451637268\n",
      "Epoch 3388, Loss: 0.19671572744846344, Final Batch Loss: 0.03166799247264862\n",
      "Epoch 3389, Loss: 0.2881765365600586, Final Batch Loss: 0.07797982543706894\n",
      "Epoch 3390, Loss: 0.2639234811067581, Final Batch Loss: 0.09702243655920029\n",
      "Epoch 3391, Loss: 0.18587883934378624, Final Batch Loss: 0.02507404237985611\n",
      "Epoch 3392, Loss: 0.23242996260523796, Final Batch Loss: 0.04942530021071434\n",
      "Epoch 3393, Loss: 0.19899406097829342, Final Batch Loss: 0.03073258511722088\n",
      "Epoch 3394, Loss: 0.24611348286271095, Final Batch Loss: 0.12821821868419647\n",
      "Epoch 3395, Loss: 0.21215014345943928, Final Batch Loss: 0.018691690638661385\n",
      "Epoch 3396, Loss: 0.35469385981559753, Final Batch Loss: 0.17503932118415833\n",
      "Epoch 3397, Loss: 0.21893680840730667, Final Batch Loss: 0.04644298553466797\n",
      "Epoch 3398, Loss: 0.7571182027459145, Final Batch Loss: 0.5314333438873291\n",
      "Epoch 3399, Loss: 0.599620521068573, Final Batch Loss: 0.3716306984424591\n",
      "Epoch 3400, Loss: 0.23734896630048752, Final Batch Loss: 0.06355458498001099\n",
      "Epoch 3401, Loss: 0.27916012331843376, Final Batch Loss: 0.03502485528588295\n",
      "Epoch 3402, Loss: 0.28893680311739445, Final Batch Loss: 0.026549452915787697\n",
      "Epoch 3403, Loss: 0.3232138827443123, Final Batch Loss: 0.08663292974233627\n",
      "Epoch 3404, Loss: 0.3483360558748245, Final Batch Loss: 0.1146511510014534\n",
      "Epoch 3405, Loss: 0.2993287667632103, Final Batch Loss: 0.10913898050785065\n",
      "Epoch 3406, Loss: 0.20214008539915085, Final Batch Loss: 0.01360994577407837\n",
      "Epoch 3407, Loss: 0.18742978502996266, Final Batch Loss: 0.0015493996907025576\n",
      "Epoch 3408, Loss: 0.43087418377399445, Final Batch Loss: 0.18254032731056213\n",
      "Epoch 3409, Loss: 0.18605324625968933, Final Batch Loss: 0.010954521596431732\n",
      "Epoch 3410, Loss: 0.131333110621199, Final Batch Loss: 0.0002988853957504034\n",
      "Epoch 3411, Loss: 0.25365058332681656, Final Batch Loss: 0.09146056324243546\n",
      "Epoch 3412, Loss: 0.20697003975510597, Final Batch Loss: 0.034996744245290756\n",
      "Epoch 3413, Loss: 0.1858843145892024, Final Batch Loss: 0.006976853124797344\n",
      "Epoch 3414, Loss: 0.18479903368279338, Final Batch Loss: 0.004828463774174452\n",
      "Epoch 3415, Loss: 0.15893469005823135, Final Batch Loss: 0.04625222086906433\n",
      "Epoch 3416, Loss: 0.220268115401268, Final Batch Loss: 0.06498482823371887\n",
      "Epoch 3417, Loss: 0.2293325811624527, Final Batch Loss: 0.08137177675962448\n",
      "Epoch 3418, Loss: 0.23543448001146317, Final Batch Loss: 0.04481755569577217\n",
      "Epoch 3419, Loss: 0.1920966785401106, Final Batch Loss: 0.027270009741187096\n",
      "Epoch 3420, Loss: 0.20926344767212868, Final Batch Loss: 0.04922223463654518\n",
      "Epoch 3421, Loss: 0.2208872213959694, Final Batch Loss: 0.06614223122596741\n",
      "Epoch 3422, Loss: 0.1841699192300439, Final Batch Loss: 0.007950619794428349\n",
      "Epoch 3423, Loss: 0.18133841175585985, Final Batch Loss: 0.00356381107121706\n",
      "Epoch 3424, Loss: 0.30219898372888565, Final Batch Loss: 0.12518537044525146\n",
      "Epoch 3425, Loss: 0.2688290812075138, Final Batch Loss: 0.12663550674915314\n",
      "Epoch 3426, Loss: 0.2049870789051056, Final Batch Loss: 0.0623965747654438\n",
      "Epoch 3427, Loss: 0.41734104603528976, Final Batch Loss: 0.2187129110097885\n",
      "Epoch 3428, Loss: 0.2775219138711691, Final Batch Loss: 0.027996664866805077\n",
      "Epoch 3429, Loss: 0.24683210998773575, Final Batch Loss: 0.048904165625572205\n",
      "Epoch 3430, Loss: 0.2708970718085766, Final Batch Loss: 0.15099337697029114\n",
      "Epoch 3431, Loss: 0.30663059651851654, Final Batch Loss: 0.13875456154346466\n",
      "Epoch 3432, Loss: 0.18947841972112656, Final Batch Loss: 0.04875027760863304\n",
      "Epoch 3433, Loss: 0.31662924215197563, Final Batch Loss: 0.17183911800384521\n",
      "Epoch 3434, Loss: 0.24296268820762634, Final Batch Loss: 0.07270938158035278\n",
      "Epoch 3435, Loss: 0.48645856231451035, Final Batch Loss: 0.09654059261083603\n",
      "Epoch 3436, Loss: 0.4491406623274088, Final Batch Loss: 0.02014077641069889\n",
      "Epoch 3437, Loss: 0.4259439557790756, Final Batch Loss: 0.2029704600572586\n",
      "Epoch 3438, Loss: 0.20886231400072575, Final Batch Loss: 0.017906034365296364\n",
      "Epoch 3439, Loss: 0.2560046911239624, Final Batch Loss: 0.09740979224443436\n",
      "Epoch 3440, Loss: 0.32212454453110695, Final Batch Loss: 0.03696655109524727\n",
      "Epoch 3441, Loss: 0.147447451017797, Final Batch Loss: 0.005279934965074062\n",
      "Epoch 3442, Loss: 0.3240705728530884, Final Batch Loss: 0.14829833805561066\n",
      "Epoch 3443, Loss: 0.16347230412065983, Final Batch Loss: 0.02131756581366062\n",
      "Epoch 3444, Loss: 0.17007740773260593, Final Batch Loss: 0.016703912988305092\n",
      "Epoch 3445, Loss: 0.17849724367260933, Final Batch Loss: 0.03029070422053337\n",
      "Epoch 3446, Loss: 0.36348022520542145, Final Batch Loss: 0.20962515473365784\n",
      "Epoch 3447, Loss: 0.1706391256302595, Final Batch Loss: 0.025690870359539986\n",
      "Epoch 3448, Loss: 0.1858164370059967, Final Batch Loss: 0.03732118010520935\n",
      "Epoch 3449, Loss: 0.19294297229498625, Final Batch Loss: 0.008827420882880688\n",
      "Epoch 3450, Loss: 0.23638756573200226, Final Batch Loss: 0.03329917788505554\n",
      "Epoch 3451, Loss: 0.438631072640419, Final Batch Loss: 0.2742682099342346\n",
      "Epoch 3452, Loss: 0.15914708259515464, Final Batch Loss: 0.0029550257604569197\n",
      "Epoch 3453, Loss: 0.18028695415705442, Final Batch Loss: 0.010448652319610119\n",
      "Epoch 3454, Loss: 0.4924621656537056, Final Batch Loss: 0.2691843509674072\n",
      "Epoch 3455, Loss: 0.30711547285318375, Final Batch Loss: 0.07753041386604309\n",
      "Epoch 3456, Loss: 0.5067499727010727, Final Batch Loss: 0.3028404712677002\n",
      "Epoch 3457, Loss: 0.32741720974445343, Final Batch Loss: 0.06126585602760315\n",
      "Epoch 3458, Loss: 0.25935085117816925, Final Batch Loss: 0.08570963144302368\n",
      "Epoch 3459, Loss: 0.18043154198676348, Final Batch Loss: 0.005702515132725239\n",
      "Epoch 3460, Loss: 0.26549065113067627, Final Batch Loss: 0.09949252009391785\n",
      "Epoch 3461, Loss: 0.231581661850214, Final Batch Loss: 0.013416748493909836\n",
      "Epoch 3462, Loss: 0.3118627220392227, Final Batch Loss: 0.11142251640558243\n",
      "Epoch 3463, Loss: 0.3150659694802016, Final Batch Loss: 0.0026167079340666533\n",
      "Epoch 3464, Loss: 0.14958013407886028, Final Batch Loss: 0.015647849068045616\n",
      "Epoch 3465, Loss: 0.4429914504289627, Final Batch Loss: 0.2708958387374878\n",
      "Epoch 3466, Loss: 0.16643458046019077, Final Batch Loss: 0.01712590642273426\n",
      "Epoch 3467, Loss: 0.17747964337468147, Final Batch Loss: 0.041502270847558975\n",
      "Epoch 3468, Loss: 0.19238535314798355, Final Batch Loss: 0.04074028134346008\n",
      "Epoch 3469, Loss: 0.2465965934097767, Final Batch Loss: 0.03884841874241829\n",
      "Epoch 3470, Loss: 0.18563668057322502, Final Batch Loss: 0.047900110483169556\n",
      "Epoch 3471, Loss: 0.20284480601549149, Final Batch Loss: 0.06123737990856171\n",
      "Epoch 3472, Loss: 0.14882600895361975, Final Batch Loss: 0.00041247374610975385\n",
      "Epoch 3473, Loss: 0.2696775160729885, Final Batch Loss: 0.11483315378427505\n",
      "Epoch 3474, Loss: 0.22056828811764717, Final Batch Loss: 0.040368665009737015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3475, Loss: 0.23131590150296688, Final Batch Loss: 0.01857973448932171\n",
      "Epoch 3476, Loss: 0.19478439819067717, Final Batch Loss: 0.012398148886859417\n",
      "Epoch 3477, Loss: 0.2475174441933632, Final Batch Loss: 0.08269509673118591\n",
      "Epoch 3478, Loss: 0.1945728361606598, Final Batch Loss: 0.053935080766677856\n",
      "Epoch 3479, Loss: 0.19743335992097855, Final Batch Loss: 0.0305163636803627\n",
      "Epoch 3480, Loss: 0.19429080933332443, Final Batch Loss: 0.04519902169704437\n",
      "Epoch 3481, Loss: 0.1463751532137394, Final Batch Loss: 0.03611825779080391\n",
      "Epoch 3482, Loss: 0.2104014791548252, Final Batch Loss: 0.06915093213319778\n",
      "Epoch 3483, Loss: 0.20518866553902626, Final Batch Loss: 0.04945148900151253\n",
      "Epoch 3484, Loss: 0.1419756580144167, Final Batch Loss: 0.028501858934760094\n",
      "Epoch 3485, Loss: 0.25169961154460907, Final Batch Loss: 0.08249405026435852\n",
      "Epoch 3486, Loss: 0.5370473563671112, Final Batch Loss: 0.3804594576358795\n",
      "Epoch 3487, Loss: 0.2656966559588909, Final Batch Loss: 0.144954115152359\n",
      "Epoch 3488, Loss: 0.2555367276072502, Final Batch Loss: 0.07036267220973969\n",
      "Epoch 3489, Loss: 0.24167818576097488, Final Batch Loss: 0.037738069891929626\n",
      "Epoch 3490, Loss: 0.32032736390829086, Final Batch Loss: 0.10371386259794235\n",
      "Epoch 3491, Loss: 0.2694438099861145, Final Batch Loss: 0.05923188477754593\n",
      "Epoch 3492, Loss: 0.28350676596164703, Final Batch Loss: 0.12955719232559204\n",
      "Epoch 3493, Loss: 0.26947857439517975, Final Batch Loss: 0.09151233732700348\n",
      "Epoch 3494, Loss: 0.41880543529987335, Final Batch Loss: 0.22413723170757294\n",
      "Epoch 3495, Loss: 0.2551387548446655, Final Batch Loss: 0.10971148312091827\n",
      "Epoch 3496, Loss: 0.6365743465721607, Final Batch Loss: 0.5344616174697876\n",
      "Epoch 3497, Loss: 0.20009449683129787, Final Batch Loss: 0.026216043159365654\n",
      "Epoch 3498, Loss: 0.5283816754817963, Final Batch Loss: 0.28339242935180664\n",
      "Epoch 3499, Loss: 0.3205925449728966, Final Batch Loss: 0.07676521688699722\n",
      "Epoch 3500, Loss: 0.2853744179010391, Final Batch Loss: 0.12632393836975098\n",
      "Epoch 3501, Loss: 0.42031724005937576, Final Batch Loss: 0.14354926347732544\n",
      "Epoch 3502, Loss: 0.3163965493440628, Final Batch Loss: 0.07284984737634659\n",
      "Epoch 3503, Loss: 0.4821630045771599, Final Batch Loss: 0.2476089894771576\n",
      "Epoch 3504, Loss: 0.2727094255387783, Final Batch Loss: 0.048910241574048996\n",
      "Epoch 3505, Loss: 0.7760897278785706, Final Batch Loss: 0.38248762488365173\n",
      "Epoch 3506, Loss: 0.6476412266492844, Final Batch Loss: 0.2411705106496811\n",
      "Epoch 3507, Loss: 0.28139497339725494, Final Batch Loss: 0.0360594168305397\n",
      "Epoch 3508, Loss: 0.34435898065567017, Final Batch Loss: 0.1530211716890335\n",
      "Epoch 3509, Loss: 0.8672540187835693, Final Batch Loss: 0.5995272397994995\n",
      "Epoch 3510, Loss: 0.2957691326737404, Final Batch Loss: 0.06864998489618301\n",
      "Epoch 3511, Loss: 0.2692369520664215, Final Batch Loss: 0.06939144432544708\n",
      "Epoch 3512, Loss: 0.27877697348594666, Final Batch Loss: 0.07009091228246689\n",
      "Epoch 3513, Loss: 0.543797105550766, Final Batch Loss: 0.27323880791664124\n",
      "Epoch 3514, Loss: 0.2520412765443325, Final Batch Loss: 0.04481034353375435\n",
      "Epoch 3515, Loss: 0.3837592229247093, Final Batch Loss: 0.10000336170196533\n",
      "Epoch 3516, Loss: 0.33656590431928635, Final Batch Loss: 0.08477924019098282\n",
      "Epoch 3517, Loss: 0.2406177669763565, Final Batch Loss: 0.04781491309404373\n",
      "Epoch 3518, Loss: 0.49823205173015594, Final Batch Loss: 0.2357199341058731\n",
      "Epoch 3519, Loss: 0.25598391192033887, Final Batch Loss: 0.004793525207787752\n",
      "Epoch 3520, Loss: 0.2891910830512643, Final Batch Loss: 0.011882775463163853\n",
      "Epoch 3521, Loss: 0.3011082112789154, Final Batch Loss: 0.12053623050451279\n",
      "Epoch 3522, Loss: 0.323860228061676, Final Batch Loss: 0.09087709337472916\n",
      "Epoch 3523, Loss: 0.342917338013649, Final Batch Loss: 0.15823900699615479\n",
      "Epoch 3524, Loss: 0.5105379223823547, Final Batch Loss: 0.28989213705062866\n",
      "Epoch 3525, Loss: 0.24013875797390938, Final Batch Loss: 0.036528509110212326\n",
      "Epoch 3526, Loss: 0.18453849852085114, Final Batch Loss: 0.03612365946173668\n",
      "Epoch 3527, Loss: 0.17470646928995848, Final Batch Loss: 0.011211725883185863\n",
      "Epoch 3528, Loss: 0.25253330916166306, Final Batch Loss: 0.07438322901725769\n",
      "Epoch 3529, Loss: 0.18939824774861336, Final Batch Loss: 0.04160812124609947\n",
      "Epoch 3530, Loss: 0.1963735856115818, Final Batch Loss: 0.04576161131262779\n",
      "Epoch 3531, Loss: 0.2685415856540203, Final Batch Loss: 0.03420921042561531\n",
      "Epoch 3532, Loss: 0.36493318527936935, Final Batch Loss: 0.16459332406520844\n",
      "Epoch 3533, Loss: 0.3153191842138767, Final Batch Loss: 0.16821934282779694\n",
      "Epoch 3534, Loss: 0.30696696788072586, Final Batch Loss: 0.10664114356040955\n",
      "Epoch 3535, Loss: 0.3080824837088585, Final Batch Loss: 0.11971849203109741\n",
      "Epoch 3536, Loss: 0.3548161908984184, Final Batch Loss: 0.2049713134765625\n",
      "Epoch 3537, Loss: 0.16479543782770634, Final Batch Loss: 0.011966841295361519\n",
      "Epoch 3538, Loss: 0.19848692789673805, Final Batch Loss: 0.04367154464125633\n",
      "Epoch 3539, Loss: 0.1880799774080515, Final Batch Loss: 0.03121057339012623\n",
      "Epoch 3540, Loss: 0.3321707025170326, Final Batch Loss: 0.20599712431430817\n",
      "Epoch 3541, Loss: 0.1937909433618188, Final Batch Loss: 0.0078993896022439\n",
      "Epoch 3542, Loss: 0.22948088496923447, Final Batch Loss: 0.054867833852767944\n",
      "Epoch 3543, Loss: 0.24777639657258987, Final Batch Loss: 0.0771726593375206\n",
      "Epoch 3544, Loss: 0.37407808750867844, Final Batch Loss: 0.22505775094032288\n",
      "Epoch 3545, Loss: 0.25845562294125557, Final Batch Loss: 0.05138656869530678\n",
      "Epoch 3546, Loss: 0.4578317254781723, Final Batch Loss: 0.16089409589767456\n",
      "Epoch 3547, Loss: 0.5611453875899315, Final Batch Loss: 0.276872843503952\n",
      "Epoch 3548, Loss: 0.1378813642077148, Final Batch Loss: 0.00714920787140727\n",
      "Epoch 3549, Loss: 0.3091260688379407, Final Batch Loss: 0.008680460043251514\n",
      "Epoch 3550, Loss: 0.4824891611933708, Final Batch Loss: 0.22982428967952728\n",
      "Epoch 3551, Loss: 0.24008191004395485, Final Batch Loss: 0.03440488502383232\n",
      "Epoch 3552, Loss: 0.22069376707077026, Final Batch Loss: 0.07406486570835114\n",
      "Epoch 3553, Loss: 0.31121644750237465, Final Batch Loss: 0.04459642246365547\n",
      "Epoch 3554, Loss: 0.23411426693201065, Final Batch Loss: 0.0506734773516655\n",
      "Epoch 3555, Loss: 0.21644378453493118, Final Batch Loss: 0.05399755388498306\n",
      "Epoch 3556, Loss: 0.4100823476910591, Final Batch Loss: 0.23072874546051025\n",
      "Epoch 3557, Loss: 0.28546421974897385, Final Batch Loss: 0.11038351058959961\n",
      "Epoch 3558, Loss: 0.19376484397798777, Final Batch Loss: 0.015211031772196293\n",
      "Epoch 3559, Loss: 0.18979866802692413, Final Batch Loss: 0.03633543848991394\n",
      "Epoch 3560, Loss: 0.19687609281390905, Final Batch Loss: 0.007290630601346493\n",
      "Epoch 3561, Loss: 0.17760177701711655, Final Batch Loss: 0.04975485801696777\n",
      "Epoch 3562, Loss: 0.24448613822460175, Final Batch Loss: 0.08004432916641235\n",
      "Epoch 3563, Loss: 0.26150305569171906, Final Batch Loss: 0.06991595029830933\n",
      "Epoch 3564, Loss: 0.22067146375775337, Final Batch Loss: 0.050008829683065414\n",
      "Epoch 3565, Loss: 0.24228183832019567, Final Batch Loss: 0.015377744100987911\n",
      "Epoch 3566, Loss: 0.18800729513168335, Final Batch Loss: 0.08236236125230789\n",
      "Epoch 3567, Loss: 0.17686380073428154, Final Batch Loss: 0.05897337570786476\n",
      "Epoch 3568, Loss: 0.2104005254805088, Final Batch Loss: 0.04801878333091736\n",
      "Epoch 3569, Loss: 0.19664040207862854, Final Batch Loss: 0.0860680341720581\n",
      "Epoch 3570, Loss: 0.2966960296034813, Final Batch Loss: 0.1964084357023239\n",
      "Epoch 3571, Loss: 0.1754616368561983, Final Batch Loss: 0.029863210394978523\n",
      "Epoch 3572, Loss: 0.168174983933568, Final Batch Loss: 0.006046010181307793\n",
      "Epoch 3573, Loss: 0.11876136064529419, Final Batch Loss: 0.008828308433294296\n",
      "Epoch 3574, Loss: 0.2758074626326561, Final Batch Loss: 0.10066765546798706\n",
      "Epoch 3575, Loss: 0.20822985842823982, Final Batch Loss: 0.057082343846559525\n",
      "Epoch 3576, Loss: 0.24776367098093033, Final Batch Loss: 0.06517714262008667\n",
      "Epoch 3577, Loss: 0.2540367292240262, Final Batch Loss: 0.014806476421654224\n",
      "Epoch 3578, Loss: 0.47081518173217773, Final Batch Loss: 0.3218132257461548\n",
      "Epoch 3579, Loss: 0.26442261040210724, Final Batch Loss: 0.0929512307047844\n",
      "Epoch 3580, Loss: 0.4021936357021332, Final Batch Loss: 0.21266816556453705\n",
      "Epoch 3581, Loss: 0.23941316734999418, Final Batch Loss: 0.012432592920958996\n",
      "Epoch 3582, Loss: 0.2651781290769577, Final Batch Loss: 0.09860732406377792\n",
      "Epoch 3583, Loss: 0.20826001837849617, Final Batch Loss: 0.03493449464440346\n",
      "Epoch 3584, Loss: 0.23725510574877262, Final Batch Loss: 0.015769602730870247\n",
      "Epoch 3585, Loss: 0.23235434293746948, Final Batch Loss: 0.03789561986923218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3586, Loss: 0.1630148310214281, Final Batch Loss: 0.01736033894121647\n",
      "Epoch 3587, Loss: 0.1841088067740202, Final Batch Loss: 0.009112117812037468\n",
      "Epoch 3588, Loss: 0.29909564182162285, Final Batch Loss: 0.11681811511516571\n",
      "Epoch 3589, Loss: 0.22112134099006653, Final Batch Loss: 0.037177421152591705\n",
      "Epoch 3590, Loss: 0.3282937780022621, Final Batch Loss: 0.12569083273410797\n",
      "Epoch 3591, Loss: 0.40441886335611343, Final Batch Loss: 0.2656778395175934\n",
      "Epoch 3592, Loss: 0.17426680773496628, Final Batch Loss: 0.0503307580947876\n",
      "Epoch 3593, Loss: 0.19374419003725052, Final Batch Loss: 0.07116036862134933\n",
      "Epoch 3594, Loss: 0.3034820333123207, Final Batch Loss: 0.06418690085411072\n",
      "Epoch 3595, Loss: 0.18645241297781467, Final Batch Loss: 0.01340235210955143\n",
      "Epoch 3596, Loss: 0.19032132998108864, Final Batch Loss: 0.09112919867038727\n",
      "Epoch 3597, Loss: 0.2458490002900362, Final Batch Loss: 0.021435650065541267\n",
      "Epoch 3598, Loss: 0.18036369234323502, Final Batch Loss: 0.05569939315319061\n",
      "Epoch 3599, Loss: 0.2773229624144733, Final Batch Loss: 0.005794032942503691\n",
      "Epoch 3600, Loss: 0.1559930443763733, Final Batch Loss: 0.025529038161039352\n",
      "Epoch 3601, Loss: 0.4005664065480232, Final Batch Loss: 0.21833793818950653\n",
      "Epoch 3602, Loss: 0.13080755062401295, Final Batch Loss: 0.007669249549508095\n",
      "Epoch 3603, Loss: 0.1801145188510418, Final Batch Loss: 0.037250373512506485\n",
      "Epoch 3604, Loss: 0.39677875488996506, Final Batch Loss: 0.20504039525985718\n",
      "Epoch 3605, Loss: 0.16239213198423386, Final Batch Loss: 0.019744250923395157\n",
      "Epoch 3606, Loss: 0.30341989919543266, Final Batch Loss: 0.13626137375831604\n",
      "Epoch 3607, Loss: 0.11513048061169684, Final Batch Loss: 0.0005793462041765451\n",
      "Epoch 3608, Loss: 0.15844089444726706, Final Batch Loss: 0.01108581479638815\n",
      "Epoch 3609, Loss: 0.21512055210769176, Final Batch Loss: 0.008850691840052605\n",
      "Epoch 3610, Loss: 0.1832091435790062, Final Batch Loss: 0.07104945182800293\n",
      "Epoch 3611, Loss: 0.34590980410575867, Final Batch Loss: 0.14003793895244598\n",
      "Epoch 3612, Loss: 0.16003256849944592, Final Batch Loss: 0.01738111861050129\n",
      "Epoch 3613, Loss: 0.15649345517158508, Final Batch Loss: 0.023463744670152664\n",
      "Epoch 3614, Loss: 0.13638709113001823, Final Batch Loss: 0.014594931155443192\n",
      "Epoch 3615, Loss: 0.1879960112273693, Final Batch Loss: 0.046402040868997574\n",
      "Epoch 3616, Loss: 0.12846187525428832, Final Batch Loss: 0.003421019995585084\n",
      "Epoch 3617, Loss: 0.23601016402244568, Final Batch Loss: 0.06306485086679459\n",
      "Epoch 3618, Loss: 0.5652950666844845, Final Batch Loss: 0.40695005655288696\n",
      "Epoch 3619, Loss: 0.2069285847246647, Final Batch Loss: 0.04174171760678291\n",
      "Epoch 3620, Loss: 0.277663916349411, Final Batch Loss: 0.07560165226459503\n",
      "Epoch 3621, Loss: 0.3663111850619316, Final Batch Loss: 0.21034348011016846\n",
      "Epoch 3622, Loss: 0.18127491883933544, Final Batch Loss: 0.028089528903365135\n",
      "Epoch 3623, Loss: 0.2044642362743616, Final Batch Loss: 0.015604773536324501\n",
      "Epoch 3624, Loss: 0.2723778188228607, Final Batch Loss: 0.06344692409038544\n",
      "Epoch 3625, Loss: 0.17980484291911125, Final Batch Loss: 0.03198292478919029\n",
      "Epoch 3626, Loss: 0.3286204971373081, Final Batch Loss: 0.19296720623970032\n",
      "Epoch 3627, Loss: 0.18760390300303698, Final Batch Loss: 0.010083858855068684\n",
      "Epoch 3628, Loss: 0.5343013852834702, Final Batch Loss: 0.3883233666419983\n",
      "Epoch 3629, Loss: 0.17246082797646523, Final Batch Loss: 0.003960397094488144\n",
      "Epoch 3630, Loss: 0.21318403631448746, Final Batch Loss: 0.03368345648050308\n",
      "Epoch 3631, Loss: 0.32115650177001953, Final Batch Loss: 0.13998714089393616\n",
      "Epoch 3632, Loss: 0.31603260338306427, Final Batch Loss: 0.14713025093078613\n",
      "Epoch 3633, Loss: 0.3234754502773285, Final Batch Loss: 0.062456995248794556\n",
      "Epoch 3634, Loss: 0.2284831665456295, Final Batch Loss: 0.03766518458724022\n",
      "Epoch 3635, Loss: 0.20736171677708626, Final Batch Loss: 0.032174546271562576\n",
      "Epoch 3636, Loss: 0.1336151696741581, Final Batch Loss: 0.010914314538240433\n",
      "Epoch 3637, Loss: 0.6151224449276924, Final Batch Loss: 0.4500354528427124\n",
      "Epoch 3638, Loss: 0.4945094883441925, Final Batch Loss: 0.3043983280658722\n",
      "Epoch 3639, Loss: 0.5550770834088326, Final Batch Loss: 0.10138604789972305\n",
      "Epoch 3640, Loss: 0.7292683571577072, Final Batch Loss: 0.34422996640205383\n",
      "Epoch 3641, Loss: 0.33929356932640076, Final Batch Loss: 0.1073666512966156\n",
      "Epoch 3642, Loss: 0.7871803939342499, Final Batch Loss: 0.5507857799530029\n",
      "Epoch 3643, Loss: 0.27584489434957504, Final Batch Loss: 0.036449939012527466\n",
      "Epoch 3644, Loss: 0.21629710961133242, Final Batch Loss: 0.009183545596897602\n",
      "Epoch 3645, Loss: 0.3019697144627571, Final Batch Loss: 0.07957977801561356\n",
      "Epoch 3646, Loss: 0.3574603870511055, Final Batch Loss: 0.15498913824558258\n",
      "Epoch 3647, Loss: 0.3830210939049721, Final Batch Loss: 0.1797070950269699\n",
      "Epoch 3648, Loss: 0.2533974777907133, Final Batch Loss: 0.02001366578042507\n",
      "Epoch 3649, Loss: 0.26317668706178665, Final Batch Loss: 0.05204927176237106\n",
      "Epoch 3650, Loss: 0.28621917217969894, Final Batch Loss: 0.10520806163549423\n",
      "Epoch 3651, Loss: 0.30988598987460136, Final Batch Loss: 0.15110786259174347\n",
      "Epoch 3652, Loss: 0.33342989534139633, Final Batch Loss: 0.12305599451065063\n",
      "Epoch 3653, Loss: 0.3194383829832077, Final Batch Loss: 0.07887512445449829\n",
      "Epoch 3654, Loss: 0.20089946687221527, Final Batch Loss: 0.04250596463680267\n",
      "Epoch 3655, Loss: 0.2584526091814041, Final Batch Loss: 0.07400796562433243\n",
      "Epoch 3656, Loss: 0.18912819726392627, Final Batch Loss: 0.0010768244974315166\n",
      "Epoch 3657, Loss: 0.31435340642929077, Final Batch Loss: 0.1890309602022171\n",
      "Epoch 3658, Loss: 0.24520890414714813, Final Batch Loss: 0.08678487688302994\n",
      "Epoch 3659, Loss: 0.33210286870598793, Final Batch Loss: 0.05996333435177803\n",
      "Epoch 3660, Loss: 0.2285088263452053, Final Batch Loss: 0.037136297672986984\n",
      "Epoch 3661, Loss: 0.2217998392879963, Final Batch Loss: 0.0524459145963192\n",
      "Epoch 3662, Loss: 0.19173265248537064, Final Batch Loss: 0.022050008177757263\n",
      "Epoch 3663, Loss: 0.2592256963253021, Final Batch Loss: 0.09926008433103561\n",
      "Epoch 3664, Loss: 0.19653579220175743, Final Batch Loss: 0.06348486989736557\n",
      "Epoch 3665, Loss: 0.16328349709510803, Final Batch Loss: 0.028632279485464096\n",
      "Epoch 3666, Loss: 0.291934359818697, Final Batch Loss: 0.1949979066848755\n",
      "Epoch 3667, Loss: 0.2578698769211769, Final Batch Loss: 0.0672580823302269\n",
      "Epoch 3668, Loss: 0.19787415117025375, Final Batch Loss: 0.054590169340372086\n",
      "Epoch 3669, Loss: 0.2404511570930481, Final Batch Loss: 0.09373214840888977\n",
      "Epoch 3670, Loss: 0.21746130660176277, Final Batch Loss: 0.047729697078466415\n",
      "Epoch 3671, Loss: 0.19732950627803802, Final Batch Loss: 0.04234941303730011\n",
      "Epoch 3672, Loss: 0.12828557286411524, Final Batch Loss: 0.004135449416935444\n",
      "Epoch 3673, Loss: 0.3478858396410942, Final Batch Loss: 0.2075451761484146\n",
      "Epoch 3674, Loss: 0.28095442056655884, Final Batch Loss: 0.15425950288772583\n",
      "Epoch 3675, Loss: 0.21878263726830482, Final Batch Loss: 0.10649226605892181\n",
      "Epoch 3676, Loss: 0.16484427452087402, Final Batch Loss: 0.012191005051136017\n",
      "Epoch 3677, Loss: 0.16737112496048212, Final Batch Loss: 0.004180640913546085\n",
      "Epoch 3678, Loss: 0.23980960622429848, Final Batch Loss: 0.1320631504058838\n",
      "Epoch 3679, Loss: 0.2338622733950615, Final Batch Loss: 0.06199505925178528\n",
      "Epoch 3680, Loss: 0.2750376686453819, Final Batch Loss: 0.10929635912179947\n",
      "Epoch 3681, Loss: 0.1341449422761798, Final Batch Loss: 0.010935674421489239\n",
      "Epoch 3682, Loss: 0.1925986148416996, Final Batch Loss: 0.03948440030217171\n",
      "Epoch 3683, Loss: 0.20114657655358315, Final Batch Loss: 0.04077902063727379\n",
      "Epoch 3684, Loss: 0.1521402969956398, Final Batch Loss: 0.04387640580534935\n",
      "Epoch 3685, Loss: 0.18273880518972874, Final Batch Loss: 0.023128299042582512\n",
      "Epoch 3686, Loss: 0.33138225600123405, Final Batch Loss: 0.2151850163936615\n",
      "Epoch 3687, Loss: 0.3853817731142044, Final Batch Loss: 0.20231664180755615\n",
      "Epoch 3688, Loss: 0.23375927656888962, Final Batch Loss: 0.08464298397302628\n",
      "Epoch 3689, Loss: 0.23063881695270538, Final Batch Loss: 0.06451405584812164\n",
      "Epoch 3690, Loss: 0.20390834473073483, Final Batch Loss: 0.020750490948557854\n",
      "Epoch 3691, Loss: 0.23747718706727028, Final Batch Loss: 0.03042205050587654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3692, Loss: 0.42254920303821564, Final Batch Loss: 0.28052258491516113\n",
      "Epoch 3693, Loss: 0.20214445888996124, Final Batch Loss: 0.034788064658641815\n",
      "Epoch 3694, Loss: 0.3276421129703522, Final Batch Loss: 0.15668617188930511\n",
      "Epoch 3695, Loss: 0.5174202360212803, Final Batch Loss: 0.3587953746318817\n",
      "Epoch 3696, Loss: 0.28291428834199905, Final Batch Loss: 0.10535187274217606\n",
      "Epoch 3697, Loss: 0.35124894976615906, Final Batch Loss: 0.11077633500099182\n",
      "Epoch 3698, Loss: 0.3126159841194749, Final Batch Loss: 0.01503660622984171\n",
      "Epoch 3699, Loss: 0.351468987762928, Final Batch Loss: 0.0719204768538475\n",
      "Epoch 3700, Loss: 0.37674856558442116, Final Batch Loss: 0.12428012490272522\n",
      "Epoch 3701, Loss: 0.24926856346428394, Final Batch Loss: 0.022930728271603584\n",
      "Epoch 3702, Loss: 0.3638360947370529, Final Batch Loss: 0.18307487666606903\n",
      "Epoch 3703, Loss: 0.384562611579895, Final Batch Loss: 0.22516009211540222\n",
      "Epoch 3704, Loss: 0.26998770236968994, Final Batch Loss: 0.07893668115139008\n",
      "Epoch 3705, Loss: 0.2656039074063301, Final Batch Loss: 0.11119081825017929\n",
      "Epoch 3706, Loss: 0.2163979336619377, Final Batch Loss: 0.03153657168149948\n",
      "Epoch 3707, Loss: 0.28290895372629166, Final Batch Loss: 0.08754708617925644\n",
      "Epoch 3708, Loss: 0.46778106689453125, Final Batch Loss: 0.3007097542285919\n",
      "Epoch 3709, Loss: 0.20191239938139915, Final Batch Loss: 0.04413439705967903\n",
      "Epoch 3710, Loss: 0.16913378983736038, Final Batch Loss: 0.012255426496267319\n",
      "Epoch 3711, Loss: 0.1935231313109398, Final Batch Loss: 0.06475400179624557\n",
      "Epoch 3712, Loss: 0.3643532171845436, Final Batch Loss: 0.16322819888591766\n",
      "Epoch 3713, Loss: 0.43475914001464844, Final Batch Loss: 0.24505996704101562\n",
      "Epoch 3714, Loss: 0.20080157555639744, Final Batch Loss: 0.0191518422216177\n",
      "Epoch 3715, Loss: 0.2783341035246849, Final Batch Loss: 0.07636135816574097\n",
      "Epoch 3716, Loss: 0.18877789936959743, Final Batch Loss: 0.02125570736825466\n",
      "Epoch 3717, Loss: 0.16878555715084076, Final Batch Loss: 0.021321415901184082\n",
      "Epoch 3718, Loss: 0.17482316680252552, Final Batch Loss: 0.004528949037194252\n",
      "Epoch 3719, Loss: 0.23374271392822266, Final Batch Loss: 0.11061587929725647\n",
      "Epoch 3720, Loss: 0.18644776195287704, Final Batch Loss: 0.07214532047510147\n",
      "Epoch 3721, Loss: 0.16365848667919636, Final Batch Loss: 0.019190752878785133\n",
      "Epoch 3722, Loss: 0.1678513230290264, Final Batch Loss: 0.0038205028977245092\n",
      "Epoch 3723, Loss: 0.14359858992975205, Final Batch Loss: 0.0012738517252728343\n",
      "Epoch 3724, Loss: 0.1857239529490471, Final Batch Loss: 0.019463643431663513\n",
      "Epoch 3725, Loss: 0.11656365636736155, Final Batch Loss: 0.009057932533323765\n",
      "Epoch 3726, Loss: 0.20246370136737823, Final Batch Loss: 0.06631549447774887\n",
      "Epoch 3727, Loss: 0.1674109883606434, Final Batch Loss: 0.06284383684396744\n",
      "Epoch 3728, Loss: 0.22092007100582123, Final Batch Loss: 0.06454911828041077\n",
      "Epoch 3729, Loss: 0.16853098012506962, Final Batch Loss: 0.030927149578928947\n",
      "Epoch 3730, Loss: 0.17079845815896988, Final Batch Loss: 0.06371589004993439\n",
      "Epoch 3731, Loss: 0.26697036623954773, Final Batch Loss: 0.09345362335443497\n",
      "Epoch 3732, Loss: 0.23672327771782875, Final Batch Loss: 0.12167857587337494\n",
      "Epoch 3733, Loss: 0.18250573333352804, Final Batch Loss: 0.01417881902307272\n",
      "Epoch 3734, Loss: 0.5299562513828278, Final Batch Loss: 0.32416418194770813\n",
      "Epoch 3735, Loss: 0.48330385982990265, Final Batch Loss: 0.2299206405878067\n",
      "Epoch 3736, Loss: 0.2874036803841591, Final Batch Loss: 0.11602799594402313\n",
      "Epoch 3737, Loss: 0.17077715322375298, Final Batch Loss: 0.031133409589529037\n",
      "Epoch 3738, Loss: 0.15793516486883163, Final Batch Loss: 0.04312065243721008\n",
      "Epoch 3739, Loss: 0.21355727687478065, Final Batch Loss: 0.02125077322125435\n",
      "Epoch 3740, Loss: 0.40256963670253754, Final Batch Loss: 0.18409846723079681\n",
      "Epoch 3741, Loss: 0.20690998435020447, Final Batch Loss: 0.09949388355016708\n",
      "Epoch 3742, Loss: 0.26497916877269745, Final Batch Loss: 0.11418228596448898\n",
      "Epoch 3743, Loss: 0.3738109990954399, Final Batch Loss: 0.19994808733463287\n",
      "Epoch 3744, Loss: 0.24883630126714706, Final Batch Loss: 0.04412725567817688\n",
      "Epoch 3745, Loss: 0.23146886378526688, Final Batch Loss: 0.07070711255073547\n",
      "Epoch 3746, Loss: 0.19622740149497986, Final Batch Loss: 0.033055178821086884\n",
      "Epoch 3747, Loss: 0.16637384030036628, Final Batch Loss: 0.0035154956858605146\n",
      "Epoch 3748, Loss: 0.22426744550466537, Final Batch Loss: 0.07329640537500381\n",
      "Epoch 3749, Loss: 0.18151357024908066, Final Batch Loss: 0.03700002282857895\n",
      "Epoch 3750, Loss: 0.1515912562608719, Final Batch Loss: 0.029533326625823975\n",
      "Epoch 3751, Loss: 0.23087690770626068, Final Batch Loss: 0.12088999152183533\n",
      "Epoch 3752, Loss: 0.14852496422827244, Final Batch Loss: 0.0170790683478117\n",
      "Epoch 3753, Loss: 0.19051292724907398, Final Batch Loss: 0.022128934040665627\n",
      "Epoch 3754, Loss: 0.1715627908706665, Final Batch Loss: 0.045508336275815964\n",
      "Epoch 3755, Loss: 0.1437474526464939, Final Batch Loss: 0.020248308777809143\n",
      "Epoch 3756, Loss: 0.33927595615386963, Final Batch Loss: 0.24304768443107605\n",
      "Epoch 3757, Loss: 0.15534433349967003, Final Batch Loss: 0.013498790562152863\n",
      "Epoch 3758, Loss: 0.2619237154722214, Final Batch Loss: 0.05746352672576904\n",
      "Epoch 3759, Loss: 0.12257368117570877, Final Batch Loss: 0.010750852525234222\n",
      "Epoch 3760, Loss: 0.1776481680572033, Final Batch Loss: 0.025893423706293106\n",
      "Epoch 3761, Loss: 0.2141103781759739, Final Batch Loss: 0.0861862301826477\n",
      "Epoch 3762, Loss: 0.15570976585149765, Final Batch Loss: 0.019355572760105133\n",
      "Epoch 3763, Loss: 0.1732644960284233, Final Batch Loss: 0.044695425778627396\n",
      "Epoch 3764, Loss: 0.18609005212783813, Final Batch Loss: 0.047914937138557434\n",
      "Epoch 3765, Loss: 0.14280732721090317, Final Batch Loss: 0.016781501471996307\n",
      "Epoch 3766, Loss: 0.1623526206240058, Final Batch Loss: 0.00881884153932333\n",
      "Epoch 3767, Loss: 0.3367764726281166, Final Batch Loss: 0.11844966560602188\n",
      "Epoch 3768, Loss: 0.27136458456516266, Final Batch Loss: 0.133292093873024\n",
      "Epoch 3769, Loss: 0.2913271263241768, Final Batch Loss: 0.13530157506465912\n",
      "Epoch 3770, Loss: 0.12940430734306574, Final Batch Loss: 0.015587047673761845\n",
      "Epoch 3771, Loss: 0.1971723437309265, Final Batch Loss: 0.054498523473739624\n",
      "Epoch 3772, Loss: 0.27689845860004425, Final Batch Loss: 0.135135680437088\n",
      "Epoch 3773, Loss: 0.31573711335659027, Final Batch Loss: 0.16990754008293152\n",
      "Epoch 3774, Loss: 0.2368423193693161, Final Batch Loss: 0.1152346134185791\n",
      "Epoch 3775, Loss: 0.2044531535357237, Final Batch Loss: 0.026512769982218742\n",
      "Epoch 3776, Loss: 0.23478754982352257, Final Batch Loss: 0.03284813091158867\n",
      "Epoch 3777, Loss: 0.17575273290276527, Final Batch Loss: 0.04117264226078987\n",
      "Epoch 3778, Loss: 0.1590755619108677, Final Batch Loss: 0.03150750696659088\n",
      "Epoch 3779, Loss: 0.14105118811130524, Final Batch Loss: 0.0347294919192791\n",
      "Epoch 3780, Loss: 0.285616010427475, Final Batch Loss: 0.15441511571407318\n",
      "Epoch 3781, Loss: 0.17308610118925571, Final Batch Loss: 0.012454727664589882\n",
      "Epoch 3782, Loss: 0.21597196534276009, Final Batch Loss: 0.06555439531803131\n",
      "Epoch 3783, Loss: 0.26663027331233025, Final Batch Loss: 0.09403917193412781\n",
      "Epoch 3784, Loss: 0.23375901207327843, Final Batch Loss: 0.1173660010099411\n",
      "Epoch 3785, Loss: 0.12360947392880917, Final Batch Loss: 0.023847049102187157\n",
      "Epoch 3786, Loss: 0.20880595222115517, Final Batch Loss: 0.036459971219301224\n",
      "Epoch 3787, Loss: 0.20316753163933754, Final Batch Loss: 0.05349685624241829\n",
      "Epoch 3788, Loss: 0.1628265604376793, Final Batch Loss: 0.06552252173423767\n",
      "Epoch 3789, Loss: 0.16460698656737804, Final Batch Loss: 0.02410595677793026\n",
      "Epoch 3790, Loss: 0.1746400110423565, Final Batch Loss: 0.02116958424448967\n",
      "Epoch 3791, Loss: 0.18216566741466522, Final Batch Loss: 0.03492383658885956\n",
      "Epoch 3792, Loss: 0.14003866165876389, Final Batch Loss: 0.00615813210606575\n",
      "Epoch 3793, Loss: 0.233097892254591, Final Batch Loss: 0.09621182084083557\n",
      "Epoch 3794, Loss: 0.1278318427503109, Final Batch Loss: 0.007985074073076248\n",
      "Epoch 3795, Loss: 0.209746103733778, Final Batch Loss: 0.10416600853204727\n",
      "Epoch 3796, Loss: 0.321980994194746, Final Batch Loss: 0.1801992654800415\n",
      "Epoch 3797, Loss: 0.15797563549131155, Final Batch Loss: 0.01378303300589323\n",
      "Epoch 3798, Loss: 0.25866148993372917, Final Batch Loss: 0.10945912450551987\n",
      "Epoch 3799, Loss: 0.1887911930680275, Final Batch Loss: 0.05166270211338997\n",
      "Epoch 3800, Loss: 0.17955456674098969, Final Batch Loss: 0.03529076278209686\n",
      "Epoch 3801, Loss: 0.45045483857393265, Final Batch Loss: 0.21935339272022247\n",
      "Epoch 3802, Loss: 0.22762037441134453, Final Batch Loss: 0.05526893958449364\n",
      "Epoch 3803, Loss: 0.23848845437169075, Final Batch Loss: 0.03654878959059715\n",
      "Epoch 3804, Loss: 0.3998240828514099, Final Batch Loss: 0.20648035407066345\n",
      "Epoch 3805, Loss: 0.34526268392801285, Final Batch Loss: 0.12879310548305511\n",
      "Epoch 3806, Loss: 0.17942848801612854, Final Batch Loss: 0.06958175450563431\n",
      "Epoch 3807, Loss: 0.26684851944446564, Final Batch Loss: 0.08705784380435944\n",
      "Epoch 3808, Loss: 0.22375861182808876, Final Batch Loss: 0.05303313210606575\n",
      "Epoch 3809, Loss: 0.43909819424152374, Final Batch Loss: 0.17352114617824554\n",
      "Epoch 3810, Loss: 0.13298588973702863, Final Batch Loss: 0.0008874235791154206\n",
      "Epoch 3811, Loss: 0.16152269602753222, Final Batch Loss: 0.002362059662118554\n",
      "Epoch 3812, Loss: 0.23340059840120375, Final Batch Loss: 0.0014125334564596415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3813, Loss: 0.2538512945175171, Final Batch Loss: 0.03194914758205414\n",
      "Epoch 3814, Loss: 0.20350730419158936, Final Batch Loss: 0.040285624563694\n",
      "Epoch 3815, Loss: 0.2709075137972832, Final Batch Loss: 0.10924779623746872\n",
      "Epoch 3816, Loss: 0.29332734644412994, Final Batch Loss: 0.14747819304466248\n",
      "Epoch 3817, Loss: 0.1561821699142456, Final Batch Loss: 0.026162568479776382\n",
      "Epoch 3818, Loss: 0.1845524199306965, Final Batch Loss: 0.05073222890496254\n",
      "Epoch 3819, Loss: 0.18183747306466103, Final Batch Loss: 0.04034378007054329\n",
      "Epoch 3820, Loss: 0.42514052242040634, Final Batch Loss: 0.24698308110237122\n",
      "Epoch 3821, Loss: 0.12481637997552752, Final Batch Loss: 0.005326140206307173\n",
      "Epoch 3822, Loss: 0.19150286098010838, Final Batch Loss: 0.0033366375137120485\n",
      "Epoch 3823, Loss: 0.2792046517133713, Final Batch Loss: 0.10036573559045792\n",
      "Epoch 3824, Loss: 0.24384921789169312, Final Batch Loss: 0.08508318662643433\n",
      "Epoch 3825, Loss: 0.11690541310235858, Final Batch Loss: 0.0030934656970202923\n",
      "Epoch 3826, Loss: 0.21030249074101448, Final Batch Loss: 0.06518910080194473\n",
      "Epoch 3827, Loss: 0.19333583861589432, Final Batch Loss: 0.04705274477601051\n",
      "Epoch 3828, Loss: 0.20939231663942337, Final Batch Loss: 0.07442883402109146\n",
      "Epoch 3829, Loss: 0.13129374443087727, Final Batch Loss: 0.001689781085588038\n",
      "Epoch 3830, Loss: 0.33247217535972595, Final Batch Loss: 0.16045193374156952\n",
      "Epoch 3831, Loss: 0.19820762798190117, Final Batch Loss: 0.023376774042844772\n",
      "Epoch 3832, Loss: 0.4113652631640434, Final Batch Loss: 0.17292402684688568\n",
      "Epoch 3833, Loss: 0.19712626561522484, Final Batch Loss: 0.04557150974869728\n",
      "Epoch 3834, Loss: 0.23807524517178535, Final Batch Loss: 0.04046447202563286\n",
      "Epoch 3835, Loss: 0.2179466299712658, Final Batch Loss: 0.04702068492770195\n",
      "Epoch 3836, Loss: 0.2589140683412552, Final Batch Loss: 0.09292104095220566\n",
      "Epoch 3837, Loss: 0.1288862805813551, Final Batch Loss: 0.0165842417627573\n",
      "Epoch 3838, Loss: 0.19402508810162544, Final Batch Loss: 0.05278510972857475\n",
      "Epoch 3839, Loss: 0.18814997375011444, Final Batch Loss: 0.022013574838638306\n",
      "Epoch 3840, Loss: 0.09742955114052165, Final Batch Loss: 0.0001820809702621773\n",
      "Epoch 3841, Loss: 0.0970988288463559, Final Batch Loss: 0.00030459798290394247\n",
      "Epoch 3842, Loss: 0.16758953407406807, Final Batch Loss: 0.06358474493026733\n",
      "Epoch 3843, Loss: 0.2908983901143074, Final Batch Loss: 0.14490918815135956\n",
      "Epoch 3844, Loss: 0.20351528748869896, Final Batch Loss: 0.038053471595048904\n",
      "Epoch 3845, Loss: 0.2810148447751999, Final Batch Loss: 0.1236301064491272\n",
      "Epoch 3846, Loss: 0.1855728179216385, Final Batch Loss: 0.03806746378540993\n",
      "Epoch 3847, Loss: 0.23143881559371948, Final Batch Loss: 0.0762820690870285\n",
      "Epoch 3848, Loss: 0.09831193462014198, Final Batch Loss: 0.00805758312344551\n",
      "Epoch 3849, Loss: 0.26445627957582474, Final Batch Loss: 0.09540652483701706\n",
      "Epoch 3850, Loss: 0.290184885263443, Final Batch Loss: 0.14803799986839294\n",
      "Epoch 3851, Loss: 0.25202010199427605, Final Batch Loss: 0.13030368089675903\n",
      "Epoch 3852, Loss: 0.4006138741970062, Final Batch Loss: 0.2434092015028\n",
      "Epoch 3853, Loss: 0.24298665672540665, Final Batch Loss: 0.06948501616716385\n",
      "Epoch 3854, Loss: 0.20898205041885376, Final Batch Loss: 0.06427954137325287\n",
      "Epoch 3855, Loss: 0.5573589503765106, Final Batch Loss: 0.3239099979400635\n",
      "Epoch 3856, Loss: 0.20366395823657513, Final Batch Loss: 0.02079940401017666\n",
      "Epoch 3857, Loss: 0.289041206240654, Final Batch Loss: 0.07640252262353897\n",
      "Epoch 3858, Loss: 0.1973651424050331, Final Batch Loss: 0.04658115655183792\n",
      "Epoch 3859, Loss: 0.21903441101312637, Final Batch Loss: 0.10055732727050781\n",
      "Epoch 3860, Loss: 0.1513568600639701, Final Batch Loss: 0.014612163417041302\n",
      "Epoch 3861, Loss: 0.37736626714468, Final Batch Loss: 0.24834324419498444\n",
      "Epoch 3862, Loss: 0.31641699001193047, Final Batch Loss: 0.1737215518951416\n",
      "Epoch 3863, Loss: 0.2338731698691845, Final Batch Loss: 0.09993942081928253\n",
      "Epoch 3864, Loss: 0.18746161554008722, Final Batch Loss: 0.011235822923481464\n",
      "Epoch 3865, Loss: 0.20934747904539108, Final Batch Loss: 0.045623648911714554\n",
      "Epoch 3866, Loss: 0.1833329200744629, Final Batch Loss: 0.046799421310424805\n",
      "Epoch 3867, Loss: 0.20797693729400635, Final Batch Loss: 0.08174866437911987\n",
      "Epoch 3868, Loss: 0.3798435255885124, Final Batch Loss: 0.22819769382476807\n",
      "Epoch 3869, Loss: 0.13664047792553902, Final Batch Loss: 0.01827399432659149\n",
      "Epoch 3870, Loss: 0.1985094929113984, Final Batch Loss: 0.009785921312868595\n",
      "Epoch 3871, Loss: 0.2082161195576191, Final Batch Loss: 0.047300878912210464\n",
      "Epoch 3872, Loss: 0.1859937559638638, Final Batch Loss: 0.0002731483255047351\n",
      "Epoch 3873, Loss: 0.18687252327799797, Final Batch Loss: 0.06326354295015335\n",
      "Epoch 3874, Loss: 0.21745414659380913, Final Batch Loss: 0.07923275977373123\n",
      "Epoch 3875, Loss: 0.21701455116271973, Final Batch Loss: 0.0470162034034729\n",
      "Epoch 3876, Loss: 0.21007361449301243, Final Batch Loss: 0.02378334291279316\n",
      "Epoch 3877, Loss: 0.17312678508460522, Final Batch Loss: 0.020848548039793968\n",
      "Epoch 3878, Loss: 0.23799163848161697, Final Batch Loss: 0.09782414138317108\n",
      "Epoch 3879, Loss: 0.17588957026600838, Final Batch Loss: 0.0518241822719574\n",
      "Epoch 3880, Loss: 0.18241031002253294, Final Batch Loss: 0.010255652479827404\n",
      "Epoch 3881, Loss: 0.1915202308446169, Final Batch Loss: 0.012000130489468575\n",
      "Epoch 3882, Loss: 0.1688721887767315, Final Batch Loss: 0.04888864979147911\n",
      "Epoch 3883, Loss: 0.17443469911813736, Final Batch Loss: 0.038603536784648895\n",
      "Epoch 3884, Loss: 0.24647382646799088, Final Batch Loss: 0.09313372522592545\n",
      "Epoch 3885, Loss: 0.1652216836810112, Final Batch Loss: 0.05115359649062157\n",
      "Epoch 3886, Loss: 0.12470537051558495, Final Batch Loss: 0.017671626061201096\n",
      "Epoch 3887, Loss: 0.22903618216514587, Final Batch Loss: 0.11172697693109512\n",
      "Epoch 3888, Loss: 0.12479845248162746, Final Batch Loss: 0.03021014668047428\n",
      "Epoch 3889, Loss: 0.20072386786341667, Final Batch Loss: 0.06212460249662399\n",
      "Epoch 3890, Loss: 0.19820880889892578, Final Batch Loss: 0.10840866714715958\n",
      "Epoch 3891, Loss: 0.14610532531514764, Final Batch Loss: 0.0017092772759497166\n",
      "Epoch 3892, Loss: 0.12940093874931335, Final Batch Loss: 0.036310888826847076\n",
      "Epoch 3893, Loss: 0.1362482476979494, Final Batch Loss: 0.005125442519783974\n",
      "Epoch 3894, Loss: 0.15815957949962467, Final Batch Loss: 0.001185275032185018\n",
      "Epoch 3895, Loss: 0.17179784551262856, Final Batch Loss: 0.03388257697224617\n",
      "Epoch 3896, Loss: 0.4229101538658142, Final Batch Loss: 0.3005458414554596\n",
      "Epoch 3897, Loss: 0.2344564124941826, Final Batch Loss: 0.044939279556274414\n",
      "Epoch 3898, Loss: 0.31548661552369595, Final Batch Loss: 0.024617454037070274\n",
      "Epoch 3899, Loss: 0.21464089304208755, Final Batch Loss: 0.036799006164073944\n",
      "Epoch 3900, Loss: 0.16580785810947418, Final Batch Loss: 0.0019841566681861877\n",
      "Epoch 3901, Loss: 0.19684997014701366, Final Batch Loss: 0.025094768032431602\n",
      "Epoch 3902, Loss: 0.24236388131976128, Final Batch Loss: 0.0944058820605278\n",
      "Epoch 3903, Loss: 0.1730396207422018, Final Batch Loss: 0.01804485358297825\n",
      "Epoch 3904, Loss: 0.19130509532988071, Final Batch Loss: 0.028285933658480644\n",
      "Epoch 3905, Loss: 0.3680943101644516, Final Batch Loss: 0.24462248384952545\n",
      "Epoch 3906, Loss: 0.1980169080197811, Final Batch Loss: 0.07321091741323471\n",
      "Epoch 3907, Loss: 0.15745387226343155, Final Batch Loss: 0.020545594394207\n",
      "Epoch 3908, Loss: 0.14357692282646894, Final Batch Loss: 0.012267167679965496\n",
      "Epoch 3909, Loss: 0.14897535555064678, Final Batch Loss: 0.02326924167573452\n",
      "Epoch 3910, Loss: 0.12106931442394853, Final Batch Loss: 0.007358870003372431\n",
      "Epoch 3911, Loss: 0.16398460511118174, Final Batch Loss: 0.011243448592722416\n",
      "Epoch 3912, Loss: 0.13620918011292815, Final Batch Loss: 0.004931384231895208\n",
      "Epoch 3913, Loss: 0.1564871184527874, Final Batch Loss: 0.03521564230322838\n",
      "Epoch 3914, Loss: 0.12134183431044221, Final Batch Loss: 0.004329292569309473\n",
      "Epoch 3915, Loss: 0.25185445323586464, Final Batch Loss: 0.1211245059967041\n",
      "Epoch 3916, Loss: 0.13333253096789122, Final Batch Loss: 0.013177300803363323\n",
      "Epoch 3917, Loss: 0.17455384135246277, Final Batch Loss: 0.07858112454414368\n",
      "Epoch 3918, Loss: 0.25252585113048553, Final Batch Loss: 0.1716855764389038\n",
      "Epoch 3919, Loss: 0.18034549290314317, Final Batch Loss: 0.007290395442396402\n",
      "Epoch 3920, Loss: 0.2056670133024454, Final Batch Loss: 0.017592960968613625\n",
      "Epoch 3921, Loss: 0.2656147629022598, Final Batch Loss: 0.1311195194721222\n",
      "Epoch 3922, Loss: 0.4994930922985077, Final Batch Loss: 0.32978400588035583\n",
      "Epoch 3923, Loss: 0.3408387005329132, Final Batch Loss: 0.07658639550209045\n",
      "Epoch 3924, Loss: 0.570320226252079, Final Batch Loss: 0.28886109590530396\n",
      "Epoch 3925, Loss: 0.7977916970849037, Final Batch Loss: 0.4155002236366272\n",
      "Epoch 3926, Loss: 0.3976294957101345, Final Batch Loss: 0.050902899354696274\n",
      "Epoch 3927, Loss: 0.4083651229739189, Final Batch Loss: 0.09138839691877365\n",
      "Epoch 3928, Loss: 0.2899256944656372, Final Batch Loss: 0.038428276777267456\n",
      "Epoch 3929, Loss: 0.4458368867635727, Final Batch Loss: 0.13692530989646912\n",
      "Epoch 3930, Loss: 0.19325776398181915, Final Batch Loss: 0.03355662524700165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3931, Loss: 0.18513950938358903, Final Batch Loss: 0.00198625260964036\n",
      "Epoch 3932, Loss: 0.267761655151844, Final Batch Loss: 0.02689586579799652\n",
      "Epoch 3933, Loss: 0.5728782787919044, Final Batch Loss: 0.37363097071647644\n",
      "Epoch 3934, Loss: 0.3807240277528763, Final Batch Loss: 0.12810350954532623\n",
      "Epoch 3935, Loss: 0.2069532573223114, Final Batch Loss: 0.07485485076904297\n",
      "Epoch 3936, Loss: 0.14379874244332314, Final Batch Loss: 0.01112309843301773\n",
      "Epoch 3937, Loss: 0.23875622591003776, Final Batch Loss: 0.00555926701053977\n",
      "Epoch 3938, Loss: 0.2538832724094391, Final Batch Loss: 0.041151151061058044\n",
      "Epoch 3939, Loss: 0.2479957938194275, Final Batch Loss: 0.03977265954017639\n",
      "Epoch 3940, Loss: 0.2953006699681282, Final Batch Loss: 0.07466082274913788\n",
      "Epoch 3941, Loss: 0.19434066489338875, Final Batch Loss: 0.05112588778138161\n",
      "Epoch 3942, Loss: 0.3720857948064804, Final Batch Loss: 0.16534896194934845\n",
      "Epoch 3943, Loss: 0.33330795355141163, Final Batch Loss: 0.17598968744277954\n",
      "Epoch 3944, Loss: 0.4102548658847809, Final Batch Loss: 0.2223724126815796\n",
      "Epoch 3945, Loss: 0.42422671616077423, Final Batch Loss: 0.29958289861679077\n",
      "Epoch 3946, Loss: 0.16270366311073303, Final Batch Loss: 0.07221697270870209\n",
      "Epoch 3947, Loss: 0.20517680048942566, Final Batch Loss: 0.06024351716041565\n",
      "Epoch 3948, Loss: 0.19792102091014385, Final Batch Loss: 0.02697843872010708\n",
      "Epoch 3949, Loss: 0.20095921494066715, Final Batch Loss: 0.026516104117035866\n",
      "Epoch 3950, Loss: 0.14268302684649825, Final Batch Loss: 0.006863453891128302\n",
      "Epoch 3951, Loss: 0.4782017022371292, Final Batch Loss: 0.34282588958740234\n",
      "Epoch 3952, Loss: 0.17339164018630981, Final Batch Loss: 0.0556667223572731\n",
      "Epoch 3953, Loss: 0.25629185140132904, Final Batch Loss: 0.12223196029663086\n",
      "Epoch 3954, Loss: 0.19374290108680725, Final Batch Loss: 0.09562307596206665\n",
      "Epoch 3955, Loss: 0.2613542191684246, Final Batch Loss: 0.10405302047729492\n",
      "Epoch 3956, Loss: 0.14273983053863049, Final Batch Loss: 0.02732945792376995\n",
      "Epoch 3957, Loss: 0.33938276022672653, Final Batch Loss: 0.23926961421966553\n",
      "Epoch 3958, Loss: 0.20125690195709467, Final Batch Loss: 0.007783696986734867\n",
      "Epoch 3959, Loss: 0.17497261986136436, Final Batch Loss: 0.04427168145775795\n",
      "Epoch 3960, Loss: 0.14446326973848045, Final Batch Loss: 0.0015815559308975935\n",
      "Epoch 3961, Loss: 0.12728882720693946, Final Batch Loss: 0.005002202000468969\n",
      "Epoch 3962, Loss: 0.25016849488019943, Final Batch Loss: 0.08963237702846527\n",
      "Epoch 3963, Loss: 0.22139160707592964, Final Batch Loss: 0.10597282648086548\n",
      "Epoch 3964, Loss: 0.23878030106425285, Final Batch Loss: 0.11232871562242508\n",
      "Epoch 3965, Loss: 0.14224946405738592, Final Batch Loss: 0.0093689588829875\n",
      "Epoch 3966, Loss: 0.21297078393399715, Final Batch Loss: 0.028060762211680412\n",
      "Epoch 3967, Loss: 0.28745073080062866, Final Batch Loss: 0.03851158916950226\n",
      "Epoch 3968, Loss: 0.26558494195342064, Final Batch Loss: 0.051019955426454544\n",
      "Epoch 3969, Loss: 0.33289436250925064, Final Batch Loss: 0.1161557212471962\n",
      "Epoch 3970, Loss: 0.2546830177307129, Final Batch Loss: 0.1083831936120987\n",
      "Epoch 3971, Loss: 0.2539119850844145, Final Batch Loss: 0.019425971433520317\n",
      "Epoch 3972, Loss: 0.2625054642558098, Final Batch Loss: 0.11625152081251144\n",
      "Epoch 3973, Loss: 0.5460597090423107, Final Batch Loss: 0.35422268509864807\n",
      "Epoch 3974, Loss: 0.2071315012872219, Final Batch Loss: 0.026524264365434647\n",
      "Epoch 3975, Loss: 0.20793497189879417, Final Batch Loss: 0.09315239638090134\n",
      "Epoch 3976, Loss: 0.1842823028564453, Final Batch Loss: 0.07412000000476837\n",
      "Epoch 3977, Loss: 0.20330829173326492, Final Batch Loss: 0.02195580303668976\n",
      "Epoch 3978, Loss: 0.2675732783973217, Final Batch Loss: 0.09114086627960205\n",
      "Epoch 3979, Loss: 0.161980104399845, Final Batch Loss: 0.0020413219463080168\n",
      "Epoch 3980, Loss: 0.17156251892447472, Final Batch Loss: 0.04318349435925484\n",
      "Epoch 3981, Loss: 0.1872858926653862, Final Batch Loss: 0.05852639675140381\n",
      "Epoch 3982, Loss: 0.15764587558805943, Final Batch Loss: 0.009239638224244118\n",
      "Epoch 3983, Loss: 0.3221197538077831, Final Batch Loss: 0.22767335176467896\n",
      "Epoch 3984, Loss: 0.15421299077570438, Final Batch Loss: 0.0151043850928545\n",
      "Epoch 3985, Loss: 0.15428759902715683, Final Batch Loss: 0.04029829427599907\n",
      "Epoch 3986, Loss: 0.14827735163271427, Final Batch Loss: 0.02749662660062313\n",
      "Epoch 3987, Loss: 0.14215250592678785, Final Batch Loss: 0.007336298935115337\n",
      "Epoch 3988, Loss: 0.13590152189135551, Final Batch Loss: 0.031167086213827133\n",
      "Epoch 3989, Loss: 0.14609172940254211, Final Batch Loss: 0.012485496699810028\n",
      "Epoch 3990, Loss: 0.1283810567110777, Final Batch Loss: 0.0046143364161252975\n",
      "Epoch 3991, Loss: 0.1309658243553713, Final Batch Loss: 0.0017276211874559522\n",
      "Epoch 3992, Loss: 0.15696560870856047, Final Batch Loss: 0.00930320005863905\n",
      "Epoch 3993, Loss: 0.1101407203823328, Final Batch Loss: 0.02638102136552334\n",
      "Epoch 3994, Loss: 0.12359908130019903, Final Batch Loss: 0.011125738732516766\n",
      "Epoch 3995, Loss: 0.09909478528425097, Final Batch Loss: 0.004856306593865156\n",
      "Epoch 3996, Loss: 0.1547030694782734, Final Batch Loss: 0.009077876806259155\n",
      "Epoch 3997, Loss: 0.12276611477136612, Final Batch Loss: 0.027853254228830338\n",
      "Epoch 3998, Loss: 0.15277978777885437, Final Batch Loss: 0.06150935962796211\n",
      "Epoch 3999, Loss: 0.10401171259582043, Final Batch Loss: 0.0063248928636312485\n",
      "Epoch 4000, Loss: 0.12084090709686279, Final Batch Loss: 0.03414599224925041\n",
      "Epoch 4001, Loss: 0.1353106764581753, Final Batch Loss: 0.00015540099411737174\n",
      "Epoch 4002, Loss: 0.1184433235321194, Final Batch Loss: 0.003622157732024789\n",
      "Epoch 4003, Loss: 0.09079506248235703, Final Batch Loss: 0.0028313659131526947\n",
      "Epoch 4004, Loss: 0.21209776401519775, Final Batch Loss: 0.12377113848924637\n",
      "Epoch 4005, Loss: 0.1575225330889225, Final Batch Loss: 0.02268943563103676\n",
      "Epoch 4006, Loss: 0.45119379833340645, Final Batch Loss: 0.34819501638412476\n",
      "Epoch 4007, Loss: 0.2520848549902439, Final Batch Loss: 0.12156658619642258\n",
      "Epoch 4008, Loss: 0.23110269848257303, Final Batch Loss: 0.012518883682787418\n",
      "Epoch 4009, Loss: 0.17727806977927685, Final Batch Loss: 0.020705988630652428\n",
      "Epoch 4010, Loss: 0.33342038840055466, Final Batch Loss: 0.15664684772491455\n",
      "Epoch 4011, Loss: 0.22411064058542252, Final Batch Loss: 0.05802842974662781\n",
      "Epoch 4012, Loss: 0.208240513689816, Final Batch Loss: 0.013330859132111073\n",
      "Epoch 4013, Loss: 0.31884972751140594, Final Batch Loss: 0.15361180901527405\n",
      "Epoch 4014, Loss: 0.18659155257046223, Final Batch Loss: 0.012195969000458717\n",
      "Epoch 4015, Loss: 0.32364748790860176, Final Batch Loss: 0.17749756574630737\n",
      "Epoch 4016, Loss: 0.2577348090708256, Final Batch Loss: 0.09606477618217468\n",
      "Epoch 4017, Loss: 0.31314102560281754, Final Batch Loss: 0.1663576066493988\n",
      "Epoch 4018, Loss: 0.7575405165553093, Final Batch Loss: 0.5781313180923462\n",
      "Epoch 4019, Loss: 0.302279569208622, Final Batch Loss: 0.10345428436994553\n",
      "Epoch 4020, Loss: 0.4549318552017212, Final Batch Loss: 0.28827813267707825\n",
      "Epoch 4021, Loss: 0.17370281741023064, Final Batch Loss: 0.03493703156709671\n",
      "Epoch 4022, Loss: 0.18444349244236946, Final Batch Loss: 0.08042087405920029\n",
      "Epoch 4023, Loss: 0.35121817514300346, Final Batch Loss: 0.011962521821260452\n",
      "Epoch 4024, Loss: 0.3553937301039696, Final Batch Loss: 0.19182541966438293\n",
      "Epoch 4025, Loss: 0.3193281218409538, Final Batch Loss: 0.12410110980272293\n",
      "Epoch 4026, Loss: 0.24803975224494934, Final Batch Loss: 0.07191665470600128\n",
      "Epoch 4027, Loss: 0.2323068492114544, Final Batch Loss: 0.016524847596883774\n",
      "Epoch 4028, Loss: 0.16717072948813438, Final Batch Loss: 0.009516756981611252\n",
      "Epoch 4029, Loss: 0.1639154115691781, Final Batch Loss: 0.013426297344267368\n",
      "Epoch 4030, Loss: 0.1553826043382287, Final Batch Loss: 0.013821450062096119\n",
      "Epoch 4031, Loss: 0.15882781706750393, Final Batch Loss: 0.021166091784834862\n",
      "Epoch 4032, Loss: 0.13805457949638367, Final Batch Loss: 0.01575232297182083\n",
      "Epoch 4033, Loss: 0.14660089276731014, Final Batch Loss: 0.0276810210198164\n",
      "Epoch 4034, Loss: 0.13412447646260262, Final Batch Loss: 0.032375089824199677\n",
      "Epoch 4035, Loss: 0.1866510845720768, Final Batch Loss: 0.04369804635643959\n",
      "Epoch 4036, Loss: 0.17906157579272985, Final Batch Loss: 0.013689613901078701\n",
      "Epoch 4037, Loss: 0.14882629085332155, Final Batch Loss: 0.008935888297855854\n",
      "Epoch 4038, Loss: 0.18186702206730843, Final Batch Loss: 0.0700157880783081\n",
      "Epoch 4039, Loss: 0.2129725143313408, Final Batch Loss: 0.06309293955564499\n",
      "Epoch 4040, Loss: 0.12752222083508968, Final Batch Loss: 0.012119365856051445\n",
      "Epoch 4041, Loss: 0.1875324510037899, Final Batch Loss: 0.038221824914216995\n",
      "Epoch 4042, Loss: 0.17091927863657475, Final Batch Loss: 0.020408952608704567\n",
      "Epoch 4043, Loss: 0.13602563051972538, Final Batch Loss: 0.0013873247662559152\n",
      "Epoch 4044, Loss: 0.1776055432856083, Final Batch Loss: 0.020248394459486008\n",
      "Epoch 4045, Loss: 0.25737667456269264, Final Batch Loss: 0.15272116661071777\n",
      "Epoch 4046, Loss: 0.15091557428240776, Final Batch Loss: 0.027604222297668457\n",
      "Epoch 4047, Loss: 0.16340291127562523, Final Batch Loss: 0.03988128900527954\n",
      "Epoch 4048, Loss: 0.17714941129088402, Final Batch Loss: 0.09691739827394485\n",
      "Epoch 4049, Loss: 0.155571770388633, Final Batch Loss: 0.00530121149495244\n",
      "Epoch 4050, Loss: 0.21629326045513153, Final Batch Loss: 0.08204858005046844\n",
      "Epoch 4051, Loss: 0.375963494181633, Final Batch Loss: 0.22999294102191925\n",
      "Epoch 4052, Loss: 0.1438018111512065, Final Batch Loss: 0.009425113908946514\n",
      "Epoch 4053, Loss: 0.3626609966158867, Final Batch Loss: 0.2750273644924164\n",
      "Epoch 4054, Loss: 0.16847645491361618, Final Batch Loss: 0.010968692600727081\n",
      "Epoch 4055, Loss: 0.17675656639039516, Final Batch Loss: 0.025944625958800316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4056, Loss: 0.16985179111361504, Final Batch Loss: 0.05474790930747986\n",
      "Epoch 4057, Loss: 0.14680508896708488, Final Batch Loss: 0.02303776517510414\n",
      "Epoch 4058, Loss: 0.21025853976607323, Final Batch Loss: 0.058070190250873566\n",
      "Epoch 4059, Loss: 0.16583886626176536, Final Batch Loss: 0.0006643224041908979\n",
      "Epoch 4060, Loss: 0.1482016290538013, Final Batch Loss: 0.003474689554423094\n",
      "Epoch 4061, Loss: 0.3239165097475052, Final Batch Loss: 0.2244134396314621\n",
      "Epoch 4062, Loss: 0.14316635578870773, Final Batch Loss: 0.04583101347088814\n",
      "Epoch 4063, Loss: 0.23245799914002419, Final Batch Loss: 0.050208915024995804\n",
      "Epoch 4064, Loss: 0.23875932395458221, Final Batch Loss: 0.07904534786939621\n",
      "Epoch 4065, Loss: 0.19828442856669426, Final Batch Loss: 0.06179288029670715\n",
      "Epoch 4066, Loss: 0.1548044178634882, Final Batch Loss: 0.01584627665579319\n",
      "Epoch 4067, Loss: 0.5610739104449749, Final Batch Loss: 0.4079059660434723\n",
      "Epoch 4068, Loss: 0.24261731654405594, Final Batch Loss: 0.1055133193731308\n",
      "Epoch 4069, Loss: 0.14125771448016167, Final Batch Loss: 0.015108861029148102\n",
      "Epoch 4070, Loss: 0.46703948453068733, Final Batch Loss: 0.3437994718551636\n",
      "Epoch 4071, Loss: 0.30209121853113174, Final Batch Loss: 0.11458286643028259\n",
      "Epoch 4072, Loss: 0.27008799090981483, Final Batch Loss: 0.12492114305496216\n",
      "Epoch 4073, Loss: 0.19059964828193188, Final Batch Loss: 0.015981649979948997\n",
      "Epoch 4074, Loss: 0.2823099121451378, Final Batch Loss: 0.12160372734069824\n",
      "Epoch 4075, Loss: 0.2514350712299347, Final Batch Loss: 0.11081212759017944\n",
      "Epoch 4076, Loss: 0.30588680505752563, Final Batch Loss: 0.08934654295444489\n",
      "Epoch 4077, Loss: 0.300262238830328, Final Batch Loss: 0.05840115621685982\n",
      "Epoch 4078, Loss: 0.13212278904393315, Final Batch Loss: 0.00394809665158391\n",
      "Epoch 4079, Loss: 0.31152206659317017, Final Batch Loss: 0.16813971102237701\n",
      "Epoch 4080, Loss: 0.2644384354352951, Final Batch Loss: 0.09413624554872513\n",
      "Epoch 4081, Loss: 0.1777418851852417, Final Batch Loss: 0.024158883839845657\n",
      "Epoch 4082, Loss: 0.17042575404047966, Final Batch Loss: 0.04052847623825073\n",
      "Epoch 4083, Loss: 0.1580649195238948, Final Batch Loss: 0.012482847087085247\n",
      "Epoch 4084, Loss: 0.18853432685136795, Final Batch Loss: 0.07615085691213608\n",
      "Epoch 4085, Loss: 0.16452037915587425, Final Batch Loss: 0.017842408269643784\n",
      "Epoch 4086, Loss: 0.3299832344055176, Final Batch Loss: 0.13405732810497284\n",
      "Epoch 4087, Loss: 0.3672224134206772, Final Batch Loss: 0.23020663857460022\n",
      "Epoch 4088, Loss: 0.1845426708459854, Final Batch Loss: 0.03393407538533211\n",
      "Epoch 4089, Loss: 0.17392588779330254, Final Batch Loss: 0.03202882036566734\n",
      "Epoch 4090, Loss: 0.15500352438539267, Final Batch Loss: 0.0074792904779314995\n",
      "Epoch 4091, Loss: 0.3613820858299732, Final Batch Loss: 0.22561971843242645\n",
      "Epoch 4092, Loss: 0.2720547914505005, Final Batch Loss: 0.06763844937086105\n",
      "Epoch 4093, Loss: 0.3245955854654312, Final Batch Loss: 0.19878317415714264\n",
      "Epoch 4094, Loss: 0.17817528592422605, Final Batch Loss: 0.006456103641539812\n",
      "Epoch 4095, Loss: 0.12870821147225797, Final Batch Loss: 0.0032700838055461645\n",
      "Epoch 4096, Loss: 0.17343365028500557, Final Batch Loss: 0.03770192340016365\n",
      "Epoch 4097, Loss: 0.32877257093787193, Final Batch Loss: 0.23007579147815704\n",
      "Epoch 4098, Loss: 0.17993217334151268, Final Batch Loss: 0.024878453463315964\n",
      "Epoch 4099, Loss: 0.15482136979699135, Final Batch Loss: 0.05086323618888855\n",
      "Epoch 4100, Loss: 0.21865876019001007, Final Batch Loss: 0.13103823363780975\n",
      "Epoch 4101, Loss: 0.404315322637558, Final Batch Loss: 0.2472590208053589\n",
      "Epoch 4102, Loss: 0.2234385348856449, Final Batch Loss: 0.05087430402636528\n",
      "Epoch 4103, Loss: 0.286762822419405, Final Batch Loss: 0.17393271625041962\n",
      "Epoch 4104, Loss: 0.1649915650486946, Final Batch Loss: 0.01751265488564968\n",
      "Epoch 4105, Loss: 0.31888336688280106, Final Batch Loss: 0.1771896779537201\n",
      "Epoch 4106, Loss: 0.1889696903526783, Final Batch Loss: 0.0634615421295166\n",
      "Epoch 4107, Loss: 0.14880068972706795, Final Batch Loss: 0.010226096957921982\n",
      "Epoch 4108, Loss: 0.12651805579662323, Final Batch Loss: 0.0009362958371639252\n",
      "Epoch 4109, Loss: 0.2097729928791523, Final Batch Loss: 0.08301694691181183\n",
      "Epoch 4110, Loss: 0.20264893025159836, Final Batch Loss: 0.06520330905914307\n",
      "Epoch 4111, Loss: 0.11592119932174683, Final Batch Loss: 0.0024984553456306458\n",
      "Epoch 4112, Loss: 0.1391467247158289, Final Batch Loss: 0.011493997648358345\n",
      "Epoch 4113, Loss: 0.34324049949645996, Final Batch Loss: 0.20302586257457733\n",
      "Epoch 4114, Loss: 0.1339129451662302, Final Batch Loss: 0.02485409937798977\n",
      "Epoch 4115, Loss: 0.16854075528681278, Final Batch Loss: 0.1025209054350853\n",
      "Epoch 4116, Loss: 0.14488114370033145, Final Batch Loss: 0.0065915207378566265\n",
      "Epoch 4117, Loss: 0.20665587857365608, Final Batch Loss: 0.035384971648454666\n",
      "Epoch 4118, Loss: 0.25215645879507065, Final Batch Loss: 0.057360321283340454\n",
      "Epoch 4119, Loss: 0.15667688474059105, Final Batch Loss: 0.05183876305818558\n",
      "Epoch 4120, Loss: 0.19642122089862823, Final Batch Loss: 0.03527062386274338\n",
      "Epoch 4121, Loss: 0.2837533466517925, Final Batch Loss: 0.15935926139354706\n",
      "Epoch 4122, Loss: 0.34641116484999657, Final Batch Loss: 0.17844432592391968\n",
      "Epoch 4123, Loss: 0.10634918697178364, Final Batch Loss: 0.008980749174952507\n",
      "Epoch 4124, Loss: 0.3992580287158489, Final Batch Loss: 0.2428147941827774\n",
      "Epoch 4125, Loss: 0.26781268790364265, Final Batch Loss: 0.16342803835868835\n",
      "Epoch 4126, Loss: 0.1999085582792759, Final Batch Loss: 0.07686696946620941\n",
      "Epoch 4127, Loss: 0.13051109900698066, Final Batch Loss: 0.003961028065532446\n",
      "Epoch 4128, Loss: 0.1740785774309188, Final Batch Loss: 0.001504482002928853\n",
      "Epoch 4129, Loss: 0.13349737413227558, Final Batch Loss: 0.04427538439631462\n",
      "Epoch 4130, Loss: 0.1446808986365795, Final Batch Loss: 0.03702004626393318\n",
      "Epoch 4131, Loss: 0.12027864018455148, Final Batch Loss: 0.006717434618622065\n",
      "Epoch 4132, Loss: 0.19990860670804977, Final Batch Loss: 0.048373930156230927\n",
      "Epoch 4133, Loss: 0.198269322514534, Final Batch Loss: 0.059116631746292114\n",
      "Epoch 4134, Loss: 0.24911627173423767, Final Batch Loss: 0.0970187857747078\n",
      "Epoch 4135, Loss: 0.11022586235776544, Final Batch Loss: 0.005503377411514521\n",
      "Epoch 4136, Loss: 0.28311830945312977, Final Batch Loss: 0.18024718761444092\n",
      "Epoch 4137, Loss: 0.22761036455631256, Final Batch Loss: 0.13324718177318573\n",
      "Epoch 4138, Loss: 0.1251979684457183, Final Batch Loss: 0.011512531898915768\n",
      "Epoch 4139, Loss: 0.14524407405406237, Final Batch Loss: 0.007840779609978199\n",
      "Epoch 4140, Loss: 0.47655827552080154, Final Batch Loss: 0.3060712516307831\n",
      "Epoch 4141, Loss: 0.12865385715849698, Final Batch Loss: 0.002680707024410367\n",
      "Epoch 4142, Loss: 0.15929007669910789, Final Batch Loss: 0.004333974327892065\n",
      "Epoch 4143, Loss: 0.27960294112563133, Final Batch Loss: 0.1568358689546585\n",
      "Epoch 4144, Loss: 0.14135925786104053, Final Batch Loss: 0.0016749160131439567\n",
      "Epoch 4145, Loss: 0.08033135114237666, Final Batch Loss: 0.007672689389437437\n",
      "Epoch 4146, Loss: 0.38067008182406425, Final Batch Loss: 0.2802382707595825\n",
      "Epoch 4147, Loss: 0.18546037981286645, Final Batch Loss: 0.005105374846607447\n",
      "Epoch 4148, Loss: 0.12779228948056698, Final Batch Loss: 0.002460760995745659\n",
      "Epoch 4149, Loss: 0.30152779817581177, Final Batch Loss: 0.17963707447052002\n",
      "Epoch 4150, Loss: 0.16696959594264627, Final Batch Loss: 0.005155591759830713\n",
      "Epoch 4151, Loss: 0.15568595193326473, Final Batch Loss: 0.0010992344468832016\n",
      "Epoch 4152, Loss: 0.13176565803587437, Final Batch Loss: 0.020035699009895325\n",
      "Epoch 4153, Loss: 0.22231823205947876, Final Batch Loss: 0.03929808735847473\n",
      "Epoch 4154, Loss: 0.16785878594964743, Final Batch Loss: 0.015382631681859493\n",
      "Epoch 4155, Loss: 0.18248794972896576, Final Batch Loss: 0.03315068781375885\n",
      "Epoch 4156, Loss: 0.18399784539360553, Final Batch Loss: 0.0007277635158970952\n",
      "Epoch 4157, Loss: 0.1738656349480152, Final Batch Loss: 0.04575835540890694\n",
      "Epoch 4158, Loss: 0.21099673211574554, Final Batch Loss: 0.06437008082866669\n",
      "Epoch 4159, Loss: 0.1902431584894657, Final Batch Loss: 0.028966188430786133\n",
      "Epoch 4160, Loss: 0.17490628734230995, Final Batch Loss: 0.03281886875629425\n",
      "Epoch 4161, Loss: 0.14221831783652306, Final Batch Loss: 0.04059280827641487\n",
      "Epoch 4162, Loss: 0.06893999374005944, Final Batch Loss: 0.0007400052854791284\n",
      "Epoch 4163, Loss: 0.12528932839632034, Final Batch Loss: 0.019896909594535828\n",
      "Epoch 4164, Loss: 0.1303398134186864, Final Batch Loss: 0.011120886541903019\n",
      "Epoch 4165, Loss: 0.22318226844072342, Final Batch Loss: 0.1011999249458313\n",
      "Epoch 4166, Loss: 0.12745473883114755, Final Batch Loss: 0.003056868677958846\n",
      "Epoch 4167, Loss: 0.32082222774624825, Final Batch Loss: 0.19860392808914185\n",
      "Epoch 4168, Loss: 0.17604702711105347, Final Batch Loss: 0.04510498046875\n",
      "Epoch 4169, Loss: 0.1436110306531191, Final Batch Loss: 0.00970461405813694\n",
      "Epoch 4170, Loss: 0.36132200062274933, Final Batch Loss: 0.263716459274292\n",
      "Epoch 4171, Loss: 0.14624383300542831, Final Batch Loss: 0.06752675771713257\n",
      "Epoch 4172, Loss: 0.14195950329303741, Final Batch Loss: 0.024807915091514587\n",
      "Epoch 4173, Loss: 0.11116580822272226, Final Batch Loss: 0.0007551402668468654\n",
      "Epoch 4174, Loss: 0.15828592982143164, Final Batch Loss: 0.010892736725509167\n",
      "Epoch 4175, Loss: 0.12882878817617893, Final Batch Loss: 0.02226707898080349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4176, Loss: 0.11554883257485926, Final Batch Loss: 0.0031725747976452112\n",
      "Epoch 4177, Loss: 0.11668423376977444, Final Batch Loss: 0.022392386570572853\n",
      "Epoch 4178, Loss: 0.13254911452531815, Final Batch Loss: 0.015707876533269882\n",
      "Epoch 4179, Loss: 0.1364140845835209, Final Batch Loss: 0.039628349244594574\n",
      "Epoch 4180, Loss: 0.12715305015444756, Final Batch Loss: 0.005000568926334381\n",
      "Epoch 4181, Loss: 0.201373890042305, Final Batch Loss: 0.038753144443035126\n",
      "Epoch 4182, Loss: 0.10320103354752064, Final Batch Loss: 0.009216656908392906\n",
      "Epoch 4183, Loss: 0.1548183634877205, Final Batch Loss: 0.041772596538066864\n",
      "Epoch 4184, Loss: 0.2440837323665619, Final Batch Loss: 0.11738596111536026\n",
      "Epoch 4185, Loss: 0.21252446807920933, Final Batch Loss: 0.004691699519753456\n",
      "Epoch 4186, Loss: 0.09725910774432123, Final Batch Loss: 0.0029806008096784353\n",
      "Epoch 4187, Loss: 0.13257312215864658, Final Batch Loss: 0.023395681753754616\n",
      "Epoch 4188, Loss: 0.43326402083039284, Final Batch Loss: 0.3245188295841217\n",
      "Epoch 4189, Loss: 0.15404964238405228, Final Batch Loss: 0.05880741775035858\n",
      "Epoch 4190, Loss: 0.2396642006933689, Final Batch Loss: 0.07094351947307587\n",
      "Epoch 4191, Loss: 0.19941813219338655, Final Batch Loss: 0.010904614813625813\n",
      "Epoch 4192, Loss: 0.14814693853259087, Final Batch Loss: 0.031554948538541794\n",
      "Epoch 4193, Loss: 0.14887644909322262, Final Batch Loss: 0.013076527044177055\n",
      "Epoch 4194, Loss: 0.22937193140387535, Final Batch Loss: 0.08402636647224426\n",
      "Epoch 4195, Loss: 0.14712617173790932, Final Batch Loss: 0.042827434837818146\n",
      "Epoch 4196, Loss: 0.2866518199443817, Final Batch Loss: 0.11925381422042847\n",
      "Epoch 4197, Loss: 0.18326346203684807, Final Batch Loss: 0.029640624299645424\n",
      "Epoch 4198, Loss: 0.31579385697841644, Final Batch Loss: 0.1753770112991333\n",
      "Epoch 4199, Loss: 0.33303336054086685, Final Batch Loss: 0.040850602090358734\n",
      "Epoch 4200, Loss: 0.2413433939218521, Final Batch Loss: 0.13564789295196533\n",
      "Epoch 4201, Loss: 0.2974349334836006, Final Batch Loss: 0.1462254673242569\n",
      "Epoch 4202, Loss: 0.22195716202259064, Final Batch Loss: 0.03532259538769722\n",
      "Epoch 4203, Loss: 0.21102957800030708, Final Batch Loss: 0.041006628423929214\n",
      "Epoch 4204, Loss: 0.21805902943015099, Final Batch Loss: 0.054765451699495316\n",
      "Epoch 4205, Loss: 0.2068510763347149, Final Batch Loss: 0.025221791118383408\n",
      "Epoch 4206, Loss: 0.3827071338891983, Final Batch Loss: 0.1358194351196289\n",
      "Epoch 4207, Loss: 0.13785608857870102, Final Batch Loss: 0.014525007456541061\n",
      "Epoch 4208, Loss: 0.23347215354442596, Final Batch Loss: 0.07253767549991608\n",
      "Epoch 4209, Loss: 0.13100369088351727, Final Batch Loss: 0.030635012313723564\n",
      "Epoch 4210, Loss: 0.21289140731096268, Final Batch Loss: 0.0759870857000351\n",
      "Epoch 4211, Loss: 0.14481151476502419, Final Batch Loss: 0.025642454624176025\n",
      "Epoch 4212, Loss: 0.25497565418481827, Final Batch Loss: 0.11097917705774307\n",
      "Epoch 4213, Loss: 0.1657213270664215, Final Batch Loss: 0.04036915302276611\n",
      "Epoch 4214, Loss: 0.23358067870140076, Final Batch Loss: 0.10357879102230072\n",
      "Epoch 4215, Loss: 0.13927659019827843, Final Batch Loss: 0.02483057603240013\n",
      "Epoch 4216, Loss: 0.2058396004140377, Final Batch Loss: 0.03716697171330452\n",
      "Epoch 4217, Loss: 0.20805905014276505, Final Batch Loss: 0.05739276483654976\n",
      "Epoch 4218, Loss: 0.16147683560848236, Final Batch Loss: 0.010607872158288956\n",
      "Epoch 4219, Loss: 0.18218334391713142, Final Batch Loss: 0.04551365599036217\n",
      "Epoch 4220, Loss: 0.1505038533359766, Final Batch Loss: 0.023813394829630852\n",
      "Epoch 4221, Loss: 0.12762199714779854, Final Batch Loss: 0.01616947166621685\n",
      "Epoch 4222, Loss: 0.24727953225374222, Final Batch Loss: 0.10937448590993881\n",
      "Epoch 4223, Loss: 0.28707147389650345, Final Batch Loss: 0.1479817032814026\n",
      "Epoch 4224, Loss: 0.19630150124430656, Final Batch Loss: 0.050981804728507996\n",
      "Epoch 4225, Loss: 0.41064562648534775, Final Batch Loss: 0.27055054903030396\n",
      "Epoch 4226, Loss: 0.27744661271572113, Final Batch Loss: 0.12470623105764389\n",
      "Epoch 4227, Loss: 0.35171765089035034, Final Batch Loss: 0.17139790952205658\n",
      "Epoch 4228, Loss: 0.16433728486299515, Final Batch Loss: 0.05486628785729408\n",
      "Epoch 4229, Loss: 0.14022201672196388, Final Batch Loss: 0.023225590586662292\n",
      "Epoch 4230, Loss: 0.18991102650761604, Final Batch Loss: 0.07466775178909302\n",
      "Epoch 4231, Loss: 0.21427233703434467, Final Batch Loss: 0.005921134725213051\n",
      "Epoch 4232, Loss: 0.23083024844527245, Final Batch Loss: 0.06651975959539413\n",
      "Epoch 4233, Loss: 0.23256046324968338, Final Batch Loss: 0.0331922322511673\n",
      "Epoch 4234, Loss: 0.29597535729408264, Final Batch Loss: 0.11720369011163712\n",
      "Epoch 4235, Loss: 0.17511773854494095, Final Batch Loss: 0.023071061819791794\n",
      "Epoch 4236, Loss: 0.15852588415145874, Final Batch Loss: 0.012557066977024078\n",
      "Epoch 4237, Loss: 0.15684388112276793, Final Batch Loss: 0.00511042308062315\n",
      "Epoch 4238, Loss: 0.13416890613734722, Final Batch Loss: 0.026411382481455803\n",
      "Epoch 4239, Loss: 0.182527806609869, Final Batch Loss: 0.07750460505485535\n",
      "Epoch 4240, Loss: 0.2542114183306694, Final Batch Loss: 0.11522381007671356\n",
      "Epoch 4241, Loss: 0.11565578915178776, Final Batch Loss: 0.02073836885392666\n",
      "Epoch 4242, Loss: 0.18471220135688782, Final Batch Loss: 0.10063139349222183\n",
      "Epoch 4243, Loss: 0.13741199485957623, Final Batch Loss: 0.014695556834340096\n",
      "Epoch 4244, Loss: 0.2880241200327873, Final Batch Loss: 0.14890092611312866\n",
      "Epoch 4245, Loss: 0.29197272658348083, Final Batch Loss: 0.13226547837257385\n",
      "Epoch 4246, Loss: 0.24305389449000359, Final Batch Loss: 0.13656440377235413\n",
      "Epoch 4247, Loss: 0.2907715439796448, Final Batch Loss: 0.19695648550987244\n",
      "Epoch 4248, Loss: 0.2652944065630436, Final Batch Loss: 0.1137995570898056\n",
      "Epoch 4249, Loss: 0.13367556035518646, Final Batch Loss: 0.019655555486679077\n",
      "Epoch 4250, Loss: 0.15214352682232857, Final Batch Loss: 0.017142489552497864\n",
      "Epoch 4251, Loss: 0.16615873202681541, Final Batch Loss: 0.0527799054980278\n",
      "Epoch 4252, Loss: 0.32279083877801895, Final Batch Loss: 0.14413265883922577\n",
      "Epoch 4253, Loss: 0.17843535169959068, Final Batch Loss: 0.062257517129182816\n",
      "Epoch 4254, Loss: 0.10738728102296591, Final Batch Loss: 0.015349271707236767\n",
      "Epoch 4255, Loss: 0.11275285296142101, Final Batch Loss: 0.022159671410918236\n",
      "Epoch 4256, Loss: 0.11917633656412363, Final Batch Loss: 0.01236645970493555\n",
      "Epoch 4257, Loss: 0.2109525315463543, Final Batch Loss: 0.0511036179959774\n",
      "Epoch 4258, Loss: 0.15251848474144936, Final Batch Loss: 0.043776266276836395\n",
      "Epoch 4259, Loss: 0.0979119073599577, Final Batch Loss: 0.018576329573988914\n",
      "Epoch 4260, Loss: 0.14243115857243538, Final Batch Loss: 0.051529280841350555\n",
      "Epoch 4261, Loss: 0.24891840666532516, Final Batch Loss: 0.08959247916936874\n",
      "Epoch 4262, Loss: 0.1909223049879074, Final Batch Loss: 0.052001629024744034\n",
      "Epoch 4263, Loss: 0.22161610424518585, Final Batch Loss: 0.019975941628217697\n",
      "Epoch 4264, Loss: 0.19323307555168867, Final Batch Loss: 0.013361121527850628\n",
      "Epoch 4265, Loss: 0.3853399008512497, Final Batch Loss: 0.13692113757133484\n",
      "Epoch 4266, Loss: 0.39207636564970016, Final Batch Loss: 0.18243159353733063\n",
      "Epoch 4267, Loss: 0.2219766490161419, Final Batch Loss: 0.09125484526157379\n",
      "Epoch 4268, Loss: 0.14916307013481855, Final Batch Loss: 0.012476569972932339\n",
      "Epoch 4269, Loss: 0.16769864037632942, Final Batch Loss: 0.05030513182282448\n",
      "Epoch 4270, Loss: 0.6612526401877403, Final Batch Loss: 0.5096219778060913\n",
      "Epoch 4271, Loss: 0.183026458369568, Final Batch Loss: 0.00233042542822659\n",
      "Epoch 4272, Loss: 0.4423174411058426, Final Batch Loss: 0.11300167441368103\n",
      "Epoch 4273, Loss: 0.5810055732727051, Final Batch Loss: 0.18479257822036743\n",
      "Epoch 4274, Loss: 0.6298764497041702, Final Batch Loss: 0.24338215589523315\n",
      "Epoch 4275, Loss: 0.3714001439511776, Final Batch Loss: 0.04422039911150932\n",
      "Epoch 4276, Loss: 0.26245544478297234, Final Batch Loss: 0.045399073511362076\n",
      "Epoch 4277, Loss: 0.298571839928627, Final Batch Loss: 0.03438952565193176\n",
      "Epoch 4278, Loss: 0.21094068884849548, Final Batch Loss: 0.04341502487659454\n",
      "Epoch 4279, Loss: 0.35584525018930435, Final Batch Loss: 0.11538976430892944\n",
      "Epoch 4280, Loss: 0.13446039333939552, Final Batch Loss: 0.007580012083053589\n",
      "Epoch 4281, Loss: 0.16627961350604892, Final Batch Loss: 0.002230189274996519\n",
      "Epoch 4282, Loss: 0.14267090102657676, Final Batch Loss: 0.004137122537940741\n",
      "Epoch 4283, Loss: 0.34084316343069077, Final Batch Loss: 0.23123690485954285\n",
      "Epoch 4284, Loss: 0.22146281227469444, Final Batch Loss: 0.11098339408636093\n",
      "Epoch 4285, Loss: 0.6428361646831036, Final Batch Loss: 0.49963656067848206\n",
      "Epoch 4286, Loss: 0.34774482250213623, Final Batch Loss: 0.0839308574795723\n",
      "Epoch 4287, Loss: 0.34564611315727234, Final Batch Loss: 0.07825380563735962\n",
      "Epoch 4288, Loss: 0.33817892149090767, Final Batch Loss: 0.04707973077893257\n",
      "Epoch 4289, Loss: 0.44759342819452286, Final Batch Loss: 0.27788662910461426\n",
      "Epoch 4290, Loss: 0.3258378505706787, Final Batch Loss: 0.10650596767663956\n",
      "Epoch 4291, Loss: 0.3642166592180729, Final Batch Loss: 0.018059726804494858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4292, Loss: 0.6506843715906143, Final Batch Loss: 0.3511129319667816\n",
      "Epoch 4293, Loss: 1.2233207523822784, Final Batch Loss: 0.7788721919059753\n",
      "Epoch 4294, Loss: 0.25938618183135986, Final Batch Loss: 0.009993121027946472\n",
      "Epoch 4295, Loss: 0.2395028485916555, Final Batch Loss: 0.005647735204547644\n",
      "Epoch 4296, Loss: 0.4175676815211773, Final Batch Loss: 0.021002348512411118\n",
      "Epoch 4297, Loss: 0.30510255554690957, Final Batch Loss: 0.006005494389683008\n",
      "Epoch 4298, Loss: 0.332595132291317, Final Batch Loss: 0.10567770153284073\n",
      "Epoch 4299, Loss: 0.26717132329940796, Final Batch Loss: 0.12245315313339233\n",
      "Epoch 4300, Loss: 0.22053557634353638, Final Batch Loss: 0.02593061327934265\n",
      "Epoch 4301, Loss: 0.22204669937491417, Final Batch Loss: 0.0500652901828289\n",
      "Epoch 4302, Loss: 0.24878847366198897, Final Batch Loss: 0.007317868527024984\n",
      "Epoch 4303, Loss: 0.5188139453530312, Final Batch Loss: 0.32598820328712463\n",
      "Epoch 4304, Loss: 0.18936747685074806, Final Batch Loss: 0.04325747862458229\n",
      "Epoch 4305, Loss: 0.34864191710948944, Final Batch Loss: 0.15186414122581482\n",
      "Epoch 4306, Loss: 0.27196628600358963, Final Batch Loss: 0.10415282100439072\n",
      "Epoch 4307, Loss: 0.3237555995583534, Final Batch Loss: 0.15297624468803406\n",
      "Epoch 4308, Loss: 0.3739130198955536, Final Batch Loss: 0.08775843679904938\n",
      "Epoch 4309, Loss: 0.23216848447918892, Final Batch Loss: 0.05339370295405388\n",
      "Epoch 4310, Loss: 0.4023790657520294, Final Batch Loss: 0.23109975457191467\n",
      "Epoch 4311, Loss: 0.20313340844586492, Final Batch Loss: 0.00525591941550374\n",
      "Epoch 4312, Loss: 0.3353896550834179, Final Batch Loss: 0.045719023793935776\n",
      "Epoch 4313, Loss: 0.18752409890294075, Final Batch Loss: 0.01660976931452751\n",
      "Epoch 4314, Loss: 0.23037193343043327, Final Batch Loss: 0.05698065832257271\n",
      "Epoch 4315, Loss: 0.28515591844916344, Final Batch Loss: 0.032036323100328445\n",
      "Epoch 4316, Loss: 0.3033348321914673, Final Batch Loss: 0.09942284971475601\n",
      "Epoch 4317, Loss: 0.328266441822052, Final Batch Loss: 0.14746922254562378\n",
      "Epoch 4318, Loss: 0.1783486413769424, Final Batch Loss: 0.006433639209717512\n",
      "Epoch 4319, Loss: 0.30950892716646194, Final Batch Loss: 0.1402370184659958\n",
      "Epoch 4320, Loss: 0.25923776254057884, Final Batch Loss: 0.10037903487682343\n",
      "Epoch 4321, Loss: 0.2547026611864567, Final Batch Loss: 0.061396967619657516\n",
      "Epoch 4322, Loss: 0.18105261772871017, Final Batch Loss: 0.032683003693819046\n",
      "Epoch 4323, Loss: 0.2532825544476509, Final Batch Loss: 0.07497778534889221\n",
      "Epoch 4324, Loss: 0.1736556130927056, Final Batch Loss: 0.0021513316314667463\n",
      "Epoch 4325, Loss: 0.3052436523139477, Final Batch Loss: 0.1574869602918625\n",
      "Epoch 4326, Loss: 0.16310089640319347, Final Batch Loss: 0.026216557249426842\n",
      "Epoch 4327, Loss: 0.13532225135713816, Final Batch Loss: 0.009500649757683277\n",
      "Epoch 4328, Loss: 0.15440717356977984, Final Batch Loss: 0.0005766080575995147\n",
      "Epoch 4329, Loss: 0.16138925403356552, Final Batch Loss: 0.046374134719371796\n",
      "Epoch 4330, Loss: 0.2820369824767113, Final Batch Loss: 0.14675584435462952\n",
      "Epoch 4331, Loss: 0.20948323979973793, Final Batch Loss: 0.05752073600888252\n",
      "Epoch 4332, Loss: 0.1956113949418068, Final Batch Loss: 0.056760676205158234\n",
      "Epoch 4333, Loss: 0.1733039729297161, Final Batch Loss: 0.033165425062179565\n",
      "Epoch 4334, Loss: 0.19153320044279099, Final Batch Loss: 0.02023918926715851\n",
      "Epoch 4335, Loss: 0.1810110316146165, Final Batch Loss: 0.003741490887477994\n",
      "Epoch 4336, Loss: 0.25136564671993256, Final Batch Loss: 0.10100626200437546\n",
      "Epoch 4337, Loss: 0.5024099461734295, Final Batch Loss: 0.3418407440185547\n",
      "Epoch 4338, Loss: 0.24545837193727493, Final Batch Loss: 0.08492989093065262\n",
      "Epoch 4339, Loss: 0.3169590122997761, Final Batch Loss: 0.1782664805650711\n",
      "Epoch 4340, Loss: 0.2537207752466202, Final Batch Loss: 0.034243613481521606\n",
      "Epoch 4341, Loss: 0.18793074041604996, Final Batch Loss: 0.02533971518278122\n",
      "Epoch 4342, Loss: 0.24374553002417088, Final Batch Loss: 0.020136231556534767\n",
      "Epoch 4343, Loss: 0.24929464235901833, Final Batch Loss: 0.11624198406934738\n",
      "Epoch 4344, Loss: 0.1671634428203106, Final Batch Loss: 0.016546126455068588\n",
      "Epoch 4345, Loss: 0.16407980024814606, Final Batch Loss: 0.012868903577327728\n",
      "Epoch 4346, Loss: 0.17901628836989403, Final Batch Loss: 0.06491563469171524\n",
      "Epoch 4347, Loss: 0.20237288903445005, Final Batch Loss: 0.009056228213012218\n",
      "Epoch 4348, Loss: 0.3082168698310852, Final Batch Loss: 0.14864958822727203\n",
      "Epoch 4349, Loss: 0.1800994612276554, Final Batch Loss: 0.042815402150154114\n",
      "Epoch 4350, Loss: 0.1316206938936375, Final Batch Loss: 0.00041947135468944907\n",
      "Epoch 4351, Loss: 0.180519824847579, Final Batch Loss: 0.016381805762648582\n",
      "Epoch 4352, Loss: 0.21975879929959774, Final Batch Loss: 0.014470068737864494\n",
      "Epoch 4353, Loss: 0.24269942566752434, Final Batch Loss: 0.09634251147508621\n",
      "Epoch 4354, Loss: 0.12102822889573872, Final Batch Loss: 0.0035988104064017534\n",
      "Epoch 4355, Loss: 0.389823067933321, Final Batch Loss: 0.09431199729442596\n",
      "Epoch 4356, Loss: 0.14282256737351418, Final Batch Loss: 0.026330910623073578\n",
      "Epoch 4357, Loss: 0.13994073099456728, Final Batch Loss: 0.0011709441896528006\n",
      "Epoch 4358, Loss: 0.17587821558117867, Final Batch Loss: 0.10524031519889832\n",
      "Epoch 4359, Loss: 0.159596957731992, Final Batch Loss: 0.005503248888999224\n",
      "Epoch 4360, Loss: 0.27278849855065346, Final Batch Loss: 0.16579551994800568\n",
      "Epoch 4361, Loss: 0.1418286911211908, Final Batch Loss: 0.0024868748150765896\n",
      "Epoch 4362, Loss: 0.12404491263441741, Final Batch Loss: 0.000907527981325984\n",
      "Epoch 4363, Loss: 0.1896618790924549, Final Batch Loss: 0.0869586169719696\n",
      "Epoch 4364, Loss: 0.19619712978601456, Final Batch Loss: 0.054158348590135574\n",
      "Epoch 4365, Loss: 0.15757353603839874, Final Batch Loss: 0.011086195707321167\n",
      "Epoch 4366, Loss: 0.2063330076634884, Final Batch Loss: 0.07304876297712326\n",
      "Epoch 4367, Loss: 0.15653882920742035, Final Batch Loss: 0.03629419952630997\n",
      "Epoch 4368, Loss: 0.1694205105304718, Final Batch Loss: 0.03871140629053116\n",
      "Epoch 4369, Loss: 0.20034240186214447, Final Batch Loss: 0.09267356246709824\n",
      "Epoch 4370, Loss: 0.552816104143858, Final Batch Loss: 0.4247354567050934\n",
      "Epoch 4371, Loss: 0.5343515165150166, Final Batch Loss: 0.3616088628768921\n",
      "Epoch 4372, Loss: 0.2817273624241352, Final Batch Loss: 0.047859761863946915\n",
      "Epoch 4373, Loss: 0.35926129296422005, Final Batch Loss: 0.05094419792294502\n",
      "Epoch 4374, Loss: 0.3177236318588257, Final Batch Loss: 0.12502864003181458\n",
      "Epoch 4375, Loss: 0.19137557037174702, Final Batch Loss: 0.011535720899701118\n",
      "Epoch 4376, Loss: 0.2804664447903633, Final Batch Loss: 0.049677714705467224\n",
      "Epoch 4377, Loss: 0.4258996397256851, Final Batch Loss: 0.14395272731781006\n",
      "Epoch 4378, Loss: 0.44062480330467224, Final Batch Loss: 0.2866300642490387\n",
      "Epoch 4379, Loss: 0.32279442250728607, Final Batch Loss: 0.1559169739484787\n",
      "Epoch 4380, Loss: 0.273798082023859, Final Batch Loss: 0.031627725809812546\n",
      "Epoch 4381, Loss: 0.29656023532152176, Final Batch Loss: 0.022264860570430756\n",
      "Epoch 4382, Loss: 0.49866077303886414, Final Batch Loss: 0.17748351395130157\n",
      "Epoch 4383, Loss: 0.3124251961708069, Final Batch Loss: 0.04312388598918915\n",
      "Epoch 4384, Loss: 0.2327789068222046, Final Batch Loss: 0.010706275701522827\n",
      "Epoch 4385, Loss: 0.3170841336250305, Final Batch Loss: 0.1070694699883461\n",
      "Epoch 4386, Loss: 0.26002655550837517, Final Batch Loss: 0.12457524985074997\n",
      "Epoch 4387, Loss: 0.250319667160511, Final Batch Loss: 0.06294042617082596\n",
      "Epoch 4388, Loss: 0.2407988514751196, Final Batch Loss: 0.028771711513400078\n",
      "Epoch 4389, Loss: 0.17892834544181824, Final Batch Loss: 0.03741505742073059\n",
      "Epoch 4390, Loss: 0.1274840384721756, Final Batch Loss: 0.03179154172539711\n",
      "Epoch 4391, Loss: 0.28339532017707825, Final Batch Loss: 0.14196065068244934\n",
      "Epoch 4392, Loss: 0.29412098601460457, Final Batch Loss: 0.06500066071748734\n",
      "Epoch 4393, Loss: 0.14983645966276526, Final Batch Loss: 0.007523996289819479\n",
      "Epoch 4394, Loss: 0.14794741198420525, Final Batch Loss: 0.049321215599775314\n",
      "Epoch 4395, Loss: 0.1267174892127514, Final Batch Loss: 0.03449627757072449\n",
      "Epoch 4396, Loss: 0.1999645815230906, Final Batch Loss: 0.006871639285236597\n",
      "Epoch 4397, Loss: 0.3652642257511616, Final Batch Loss: 0.21397191286087036\n",
      "Epoch 4398, Loss: 0.1853239298798144, Final Batch Loss: 0.005843298975378275\n",
      "Epoch 4399, Loss: 0.2921702414751053, Final Batch Loss: 0.08261547237634659\n",
      "Epoch 4400, Loss: 0.2602221518754959, Final Batch Loss: 0.09589412063360214\n",
      "Epoch 4401, Loss: 0.2599257007241249, Final Batch Loss: 0.07872627675533295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4402, Loss: 0.5249423235654831, Final Batch Loss: 0.3401534855365753\n",
      "Epoch 4403, Loss: 0.4585433527827263, Final Batch Loss: 0.2781299948692322\n",
      "Epoch 4404, Loss: 0.299894493073225, Final Batch Loss: 0.05120675638318062\n",
      "Epoch 4405, Loss: 0.3374280221760273, Final Batch Loss: 0.0508568175137043\n",
      "Epoch 4406, Loss: 0.22865105886012316, Final Batch Loss: 0.014714007265865803\n",
      "Epoch 4407, Loss: 0.24510428309440613, Final Batch Loss: 0.05918983370065689\n",
      "Epoch 4408, Loss: 0.2912243977189064, Final Batch Loss: 0.10323408991098404\n",
      "Epoch 4409, Loss: 0.553802840411663, Final Batch Loss: 0.31424349546432495\n",
      "Epoch 4410, Loss: 0.22037262842059135, Final Batch Loss: 0.08154242485761642\n",
      "Epoch 4411, Loss: 0.33806776255369186, Final Batch Loss: 0.18272297084331512\n",
      "Epoch 4412, Loss: 0.2897712104022503, Final Batch Loss: 0.1136765331029892\n",
      "Epoch 4413, Loss: 0.256776787340641, Final Batch Loss: 0.03547368943691254\n",
      "Epoch 4414, Loss: 0.1428279682295397, Final Batch Loss: 0.001913393964059651\n",
      "Epoch 4415, Loss: 0.16208156337961555, Final Batch Loss: 0.007274688687175512\n",
      "Epoch 4416, Loss: 0.21192917600274086, Final Batch Loss: 0.05627427622675896\n",
      "Epoch 4417, Loss: 0.16660061106085777, Final Batch Loss: 0.027956780046224594\n",
      "Epoch 4418, Loss: 0.356067169457674, Final Batch Loss: 0.21424105763435364\n",
      "Epoch 4419, Loss: 0.28075721114873886, Final Batch Loss: 0.11274600028991699\n",
      "Epoch 4420, Loss: 0.20032043009996414, Final Batch Loss: 0.05540025979280472\n",
      "Epoch 4421, Loss: 0.24519210308790207, Final Batch Loss: 0.042512230575084686\n",
      "Epoch 4422, Loss: 0.28262385725975037, Final Batch Loss: 0.10631746053695679\n",
      "Epoch 4423, Loss: 0.264316082932055, Final Batch Loss: 0.013841823674738407\n",
      "Epoch 4424, Loss: 0.1659191339276731, Final Batch Loss: 0.003088237252086401\n",
      "Epoch 4425, Loss: 0.24099604040384293, Final Batch Loss: 0.0619329959154129\n",
      "Epoch 4426, Loss: 0.23074635490775108, Final Batch Loss: 0.05984537675976753\n",
      "Epoch 4427, Loss: 0.19286910444498062, Final Batch Loss: 0.06088541820645332\n",
      "Epoch 4428, Loss: 0.2334435060620308, Final Batch Loss: 0.108499675989151\n",
      "Epoch 4429, Loss: 0.18049327097833157, Final Batch Loss: 0.021422429010272026\n",
      "Epoch 4430, Loss: 0.3832448199391365, Final Batch Loss: 0.20777703821659088\n",
      "Epoch 4431, Loss: 0.2768453061580658, Final Batch Loss: 0.11337492614984512\n",
      "Epoch 4432, Loss: 0.21137945353984833, Final Batch Loss: 0.0836406722664833\n",
      "Epoch 4433, Loss: 0.15510295890271664, Final Batch Loss: 0.004345482215285301\n",
      "Epoch 4434, Loss: 0.15962080203462392, Final Batch Loss: 0.0014421186642721295\n",
      "Epoch 4435, Loss: 0.274390134960413, Final Batch Loss: 0.13666294515132904\n",
      "Epoch 4436, Loss: 0.25549858063459396, Final Batch Loss: 0.12685279548168182\n",
      "Epoch 4437, Loss: 0.17147051356732845, Final Batch Loss: 0.02775878645479679\n",
      "Epoch 4438, Loss: 0.20395705476403236, Final Batch Loss: 0.010888602584600449\n",
      "Epoch 4439, Loss: 0.29658225923776627, Final Batch Loss: 0.20345506072044373\n",
      "Epoch 4440, Loss: 0.3008834049105644, Final Batch Loss: 0.11519332975149155\n",
      "Epoch 4441, Loss: 0.13880397519096732, Final Batch Loss: 0.004568883683532476\n",
      "Epoch 4442, Loss: 0.24402489513158798, Final Batch Loss: 0.06098095327615738\n",
      "Epoch 4443, Loss: 0.22158614546060562, Final Batch Loss: 0.06207192689180374\n",
      "Epoch 4444, Loss: 0.10645719361491501, Final Batch Loss: 0.0021797691006213427\n",
      "Epoch 4445, Loss: 0.16853435896337032, Final Batch Loss: 0.019031649455428123\n",
      "Epoch 4446, Loss: 0.1831165850162506, Final Batch Loss: 0.029278144240379333\n",
      "Epoch 4447, Loss: 0.1836001593619585, Final Batch Loss: 0.010801689699292183\n",
      "Epoch 4448, Loss: 0.16239842493087053, Final Batch Loss: 0.00654024351388216\n",
      "Epoch 4449, Loss: 0.1992404442280531, Final Batch Loss: 0.023614687845110893\n",
      "Epoch 4450, Loss: 0.15076431015040725, Final Batch Loss: 0.0014276517322286963\n",
      "Epoch 4451, Loss: 0.3527335189282894, Final Batch Loss: 0.21348270773887634\n",
      "Epoch 4452, Loss: 0.21144958958029747, Final Batch Loss: 0.08500378578901291\n",
      "Epoch 4453, Loss: 0.2534334883093834, Final Batch Loss: 0.10844943672418594\n",
      "Epoch 4454, Loss: 0.35918698087334633, Final Batch Loss: 0.2252034693956375\n",
      "Epoch 4455, Loss: 0.18006662279367447, Final Batch Loss: 0.027936536818742752\n",
      "Epoch 4456, Loss: 0.15265741385519505, Final Batch Loss: 0.024393895640969276\n",
      "Epoch 4457, Loss: 0.2060520052909851, Final Batch Loss: 0.060388896614313126\n",
      "Epoch 4458, Loss: 0.18146491423249245, Final Batch Loss: 0.05522429943084717\n",
      "Epoch 4459, Loss: 0.20047993585467339, Final Batch Loss: 0.06259021162986755\n",
      "Epoch 4460, Loss: 0.09785102773457766, Final Batch Loss: 0.009622030891478062\n",
      "Epoch 4461, Loss: 0.34701042249798775, Final Batch Loss: 0.23611927032470703\n",
      "Epoch 4462, Loss: 0.3200916275382042, Final Batch Loss: 0.15818747878074646\n",
      "Epoch 4463, Loss: 0.16806599777191877, Final Batch Loss: 0.015157277695834637\n",
      "Epoch 4464, Loss: 0.1543302033096552, Final Batch Loss: 0.02910665236413479\n",
      "Epoch 4465, Loss: 0.12116666045039892, Final Batch Loss: 0.00726598035544157\n",
      "Epoch 4466, Loss: 0.18020948395133018, Final Batch Loss: 0.04755307361483574\n",
      "Epoch 4467, Loss: 0.1617976906709373, Final Batch Loss: 0.007007453124970198\n",
      "Epoch 4468, Loss: 0.15733063220977783, Final Batch Loss: 0.05551822483539581\n",
      "Epoch 4469, Loss: 0.22815627604722977, Final Batch Loss: 0.06569046527147293\n",
      "Epoch 4470, Loss: 0.14380010776221752, Final Batch Loss: 0.009127287194132805\n",
      "Epoch 4471, Loss: 0.2658456042408943, Final Batch Loss: 0.08564526587724686\n",
      "Epoch 4472, Loss: 0.09767083078622818, Final Batch Loss: 0.013035930693149567\n",
      "Epoch 4473, Loss: 0.12970053777098656, Final Batch Loss: 0.01834665611386299\n",
      "Epoch 4474, Loss: 0.1349893994629383, Final Batch Loss: 0.03444257378578186\n",
      "Epoch 4475, Loss: 0.1610351800918579, Final Batch Loss: 0.0356203056871891\n",
      "Epoch 4476, Loss: 0.1886196993291378, Final Batch Loss: 0.060598548501729965\n",
      "Epoch 4477, Loss: 0.1375212725251913, Final Batch Loss: 0.017290858551859856\n",
      "Epoch 4478, Loss: 0.18045632913708687, Final Batch Loss: 0.07214502990245819\n",
      "Epoch 4479, Loss: 0.10104005970060825, Final Batch Loss: 0.020756246522068977\n",
      "Epoch 4480, Loss: 0.16962205292657018, Final Batch Loss: 0.002871294040232897\n",
      "Epoch 4481, Loss: 0.3084216043353081, Final Batch Loss: 0.1876073181629181\n",
      "Epoch 4482, Loss: 0.11637633666396141, Final Batch Loss: 0.03471469506621361\n",
      "Epoch 4483, Loss: 0.11075944919139147, Final Batch Loss: 0.014090117998421192\n",
      "Epoch 4484, Loss: 0.3040051721036434, Final Batch Loss: 0.16054730117321014\n",
      "Epoch 4485, Loss: 0.14849905110895634, Final Batch Loss: 0.0266219824552536\n",
      "Epoch 4486, Loss: 0.4283973202109337, Final Batch Loss: 0.1677478700876236\n",
      "Epoch 4487, Loss: 0.22989745810627937, Final Batch Loss: 0.03295515850186348\n",
      "Epoch 4488, Loss: 0.2551973005756736, Final Batch Loss: 0.0068176379427313805\n",
      "Epoch 4489, Loss: 0.15704279951751232, Final Batch Loss: 0.021253710612654686\n",
      "Epoch 4490, Loss: 0.14529042690992355, Final Batch Loss: 0.01628652960062027\n",
      "Epoch 4491, Loss: 0.15221102256327868, Final Batch Loss: 0.005727869458496571\n",
      "Epoch 4492, Loss: 0.2581119202077389, Final Batch Loss: 0.10190705209970474\n",
      "Epoch 4493, Loss: 0.21735807694494724, Final Batch Loss: 0.027242908254265785\n",
      "Epoch 4494, Loss: 0.1273860028013587, Final Batch Loss: 0.014023798517882824\n",
      "Epoch 4495, Loss: 0.27319692075252533, Final Batch Loss: 0.11826572567224503\n",
      "Epoch 4496, Loss: 0.20298310741782188, Final Batch Loss: 0.06176430359482765\n",
      "Epoch 4497, Loss: 0.4376918040215969, Final Batch Loss: 0.3260074555873871\n",
      "Epoch 4498, Loss: 0.11984699708409607, Final Batch Loss: 0.0029768955428153276\n",
      "Epoch 4499, Loss: 0.18802502751350403, Final Batch Loss: 0.011398665606975555\n",
      "Epoch 4500, Loss: 0.35773367434740067, Final Batch Loss: 0.17224030196666718\n",
      "Epoch 4501, Loss: 0.24425466731190681, Final Batch Loss: 0.08205997943878174\n",
      "Epoch 4502, Loss: 0.11224901559762657, Final Batch Loss: 0.0019023593049496412\n",
      "Epoch 4503, Loss: 0.19249803572893143, Final Batch Loss: 0.06739064306020737\n",
      "Epoch 4504, Loss: 0.1233138213865459, Final Batch Loss: 0.007254812400788069\n",
      "Epoch 4505, Loss: 0.1427423544228077, Final Batch Loss: 0.012233920395374298\n",
      "Epoch 4506, Loss: 0.12095913547091186, Final Batch Loss: 0.0021081145387142897\n",
      "Epoch 4507, Loss: 0.18014086969196796, Final Batch Loss: 0.009975550696253777\n",
      "Epoch 4508, Loss: 0.1919863186776638, Final Batch Loss: 0.08669159561395645\n",
      "Epoch 4509, Loss: 0.12196830241009593, Final Batch Loss: 0.005030616652220488\n",
      "Epoch 4510, Loss: 0.2454475648701191, Final Batch Loss: 0.03322804346680641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4511, Loss: 0.24037155508995056, Final Batch Loss: 0.08937181532382965\n",
      "Epoch 4512, Loss: 0.1520273475907743, Final Batch Loss: 0.002282956149429083\n",
      "Epoch 4513, Loss: 0.2115657739341259, Final Batch Loss: 0.03688884153962135\n",
      "Epoch 4514, Loss: 0.4479920230805874, Final Batch Loss: 0.2952471673488617\n",
      "Epoch 4515, Loss: 0.21572491899132729, Final Batch Loss: 0.04017079249024391\n",
      "Epoch 4516, Loss: 0.29244598746299744, Final Batch Loss: 0.13547734916210175\n",
      "Epoch 4517, Loss: 0.2039421834051609, Final Batch Loss: 0.06500119715929031\n",
      "Epoch 4518, Loss: 0.2531706467270851, Final Batch Loss: 0.08472727984189987\n",
      "Epoch 4519, Loss: 0.18792669917456806, Final Batch Loss: 0.0019534423481673002\n",
      "Epoch 4520, Loss: 0.19741864129900932, Final Batch Loss: 0.05658482760190964\n",
      "Epoch 4521, Loss: 0.23829424753785133, Final Batch Loss: 0.031469862908124924\n",
      "Epoch 4522, Loss: 0.2594878822565079, Final Batch Loss: 0.08018467575311661\n",
      "Epoch 4523, Loss: 0.20637282356619835, Final Batch Loss: 0.05936063081026077\n",
      "Epoch 4524, Loss: 0.178341094404459, Final Batch Loss: 0.023946668952703476\n",
      "Epoch 4525, Loss: 0.20892608910799026, Final Batch Loss: 0.06607244163751602\n",
      "Epoch 4526, Loss: 0.21129884757101536, Final Batch Loss: 0.10151943564414978\n",
      "Epoch 4527, Loss: 0.17321912944316864, Final Batch Loss: 0.05961994826793671\n",
      "Epoch 4528, Loss: 0.1310483980923891, Final Batch Loss: 0.04889596998691559\n",
      "Epoch 4529, Loss: 0.19001732021570206, Final Batch Loss: 0.08189794421195984\n",
      "Epoch 4530, Loss: 0.20323751494288445, Final Batch Loss: 0.03358813375234604\n",
      "Epoch 4531, Loss: 0.31644125282764435, Final Batch Loss: 0.1769077479839325\n",
      "Epoch 4532, Loss: 0.10766900330781937, Final Batch Loss: 0.013815484941005707\n",
      "Epoch 4533, Loss: 0.09643941378453746, Final Batch Loss: 0.0006433465168811381\n",
      "Epoch 4534, Loss: 0.06728347227908671, Final Batch Loss: 0.002126112813130021\n",
      "Epoch 4535, Loss: 0.13341000862419605, Final Batch Loss: 0.02070315182209015\n",
      "Epoch 4536, Loss: 0.15315202996134758, Final Batch Loss: 0.07085151970386505\n",
      "Epoch 4537, Loss: 0.0880881164339371, Final Batch Loss: 0.0009200897184200585\n",
      "Epoch 4538, Loss: 0.14237058348953724, Final Batch Loss: 0.013918759301304817\n",
      "Epoch 4539, Loss: 0.24901043623685837, Final Batch Loss: 0.13426172733306885\n",
      "Epoch 4540, Loss: 0.11456013564020395, Final Batch Loss: 0.009220764972269535\n",
      "Epoch 4541, Loss: 0.16753000626340508, Final Batch Loss: 0.006230069790035486\n",
      "Epoch 4542, Loss: 0.13296395726501942, Final Batch Loss: 0.02305070124566555\n",
      "Epoch 4543, Loss: 0.19044488389045, Final Batch Loss: 0.015195217914879322\n",
      "Epoch 4544, Loss: 0.18064728006720543, Final Batch Loss: 0.0812903419137001\n",
      "Epoch 4545, Loss: 0.18797904253005981, Final Batch Loss: 0.060513269156217575\n",
      "Epoch 4546, Loss: 0.12508899718523026, Final Batch Loss: 0.004234142601490021\n",
      "Epoch 4547, Loss: 0.14726996049284935, Final Batch Loss: 0.03640846535563469\n",
      "Epoch 4548, Loss: 0.2583056092262268, Final Batch Loss: 0.09303654730319977\n",
      "Epoch 4549, Loss: 0.33814482390880585, Final Batch Loss: 0.20176975429058075\n",
      "Epoch 4550, Loss: 0.23576927557587624, Final Batch Loss: 0.025493621826171875\n",
      "Epoch 4551, Loss: 0.44243529438972473, Final Batch Loss: 0.2937406301498413\n",
      "Epoch 4552, Loss: 0.2172727957367897, Final Batch Loss: 0.012660324573516846\n",
      "Epoch 4553, Loss: 0.22534006088972092, Final Batch Loss: 0.05320299416780472\n",
      "Epoch 4554, Loss: 0.15127556584775448, Final Batch Loss: 0.02397576905786991\n",
      "Epoch 4555, Loss: 0.16255193762481213, Final Batch Loss: 0.027553832158446312\n",
      "Epoch 4556, Loss: 0.18728757463395596, Final Batch Loss: 0.018515264615416527\n",
      "Epoch 4557, Loss: 0.3007223531603813, Final Batch Loss: 0.08831329643726349\n",
      "Epoch 4558, Loss: 0.15690163522958755, Final Batch Loss: 0.04039079323410988\n",
      "Epoch 4559, Loss: 0.33757901936769485, Final Batch Loss: 0.17416536808013916\n",
      "Epoch 4560, Loss: 0.20925238728523254, Final Batch Loss: 0.07006384432315826\n",
      "Epoch 4561, Loss: 0.1258043460547924, Final Batch Loss: 0.030562326312065125\n",
      "Epoch 4562, Loss: 0.1811918467283249, Final Batch Loss: 0.0966838002204895\n",
      "Epoch 4563, Loss: 0.4334636963903904, Final Batch Loss: 0.3306129276752472\n",
      "Epoch 4564, Loss: 0.31547999382019043, Final Batch Loss: 0.17871522903442383\n",
      "Epoch 4565, Loss: 0.18823401164263487, Final Batch Loss: 0.015497441403567791\n",
      "Epoch 4566, Loss: 0.28859349340200424, Final Batch Loss: 0.041768163442611694\n",
      "Epoch 4567, Loss: 0.19391919672489166, Final Batch Loss: 0.029652021825313568\n",
      "Epoch 4568, Loss: 0.32286485261283815, Final Batch Loss: 0.0003417504485696554\n",
      "Epoch 4569, Loss: 0.14431509049609303, Final Batch Loss: 0.005978618282824755\n",
      "Epoch 4570, Loss: 0.12014762591570616, Final Batch Loss: 0.011203809641301632\n",
      "Epoch 4571, Loss: 0.15925802290439606, Final Batch Loss: 0.021935991942882538\n",
      "Epoch 4572, Loss: 0.1008751853951253, Final Batch Loss: 0.0008984632440842688\n",
      "Epoch 4573, Loss: 0.2538040429353714, Final Batch Loss: 0.08839362859725952\n",
      "Epoch 4574, Loss: 0.22124584764242172, Final Batch Loss: 0.09521202743053436\n",
      "Epoch 4575, Loss: 0.2953132763504982, Final Batch Loss: 0.18084333837032318\n",
      "Epoch 4576, Loss: 0.1430363990366459, Final Batch Loss: 0.041392553597688675\n",
      "Epoch 4577, Loss: 0.3078112453222275, Final Batch Loss: 0.14243362843990326\n",
      "Epoch 4578, Loss: 0.21299725398421288, Final Batch Loss: 0.021404769271612167\n",
      "Epoch 4579, Loss: 0.34307554364204407, Final Batch Loss: 0.10292407870292664\n",
      "Epoch 4580, Loss: 0.3240373358130455, Final Batch Loss: 0.15957550704479218\n",
      "Epoch 4581, Loss: 0.24891451001167297, Final Batch Loss: 0.07900545746088028\n",
      "Epoch 4582, Loss: 0.25154145061969757, Final Batch Loss: 0.07509239763021469\n",
      "Epoch 4583, Loss: 0.30523376539349556, Final Batch Loss: 0.048809733241796494\n",
      "Epoch 4584, Loss: 0.16744747571647167, Final Batch Loss: 0.0044385697692632675\n",
      "Epoch 4585, Loss: 0.2051301822066307, Final Batch Loss: 0.06066859886050224\n",
      "Epoch 4586, Loss: 0.2688448131084442, Final Batch Loss: 0.09412498772144318\n",
      "Epoch 4587, Loss: 0.5716505646705627, Final Batch Loss: 0.43855029344558716\n",
      "Epoch 4588, Loss: 0.18110544234514236, Final Batch Loss: 0.024646833539009094\n",
      "Epoch 4589, Loss: 0.48558594286441803, Final Batch Loss: 0.2903766334056854\n",
      "Epoch 4590, Loss: 0.22766082640737295, Final Batch Loss: 0.009726344607770443\n",
      "Epoch 4591, Loss: 0.24441694468259811, Final Batch Loss: 0.01718682050704956\n",
      "Epoch 4592, Loss: 0.4343845471739769, Final Batch Loss: 0.20304524898529053\n",
      "Epoch 4593, Loss: 0.34170452505350113, Final Batch Loss: 0.1510748565196991\n",
      "Epoch 4594, Loss: 0.14101306581869721, Final Batch Loss: 0.003052393440157175\n",
      "Epoch 4595, Loss: 0.19398518279194832, Final Batch Loss: 0.04046701267361641\n",
      "Epoch 4596, Loss: 0.2917190492153168, Final Batch Loss: 0.10747964680194855\n",
      "Epoch 4597, Loss: 0.23414306715130806, Final Batch Loss: 0.02707485482096672\n",
      "Epoch 4598, Loss: 0.28523267805576324, Final Batch Loss: 0.10189554840326309\n",
      "Epoch 4599, Loss: 0.20189691707491875, Final Batch Loss: 0.047418493777513504\n",
      "Epoch 4600, Loss: 0.2852798365056515, Final Batch Loss: 0.17103752493858337\n",
      "Epoch 4601, Loss: 0.32260747253894806, Final Batch Loss: 0.1670953929424286\n",
      "Epoch 4602, Loss: 0.24905050545930862, Final Batch Loss: 0.07616524398326874\n",
      "Epoch 4603, Loss: 0.12661132402718067, Final Batch Loss: 0.02329239808022976\n",
      "Epoch 4604, Loss: 0.3225301541388035, Final Batch Loss: 0.2196837216615677\n",
      "Epoch 4605, Loss: 0.18528173491358757, Final Batch Loss: 0.06080961227416992\n",
      "Epoch 4606, Loss: 0.13927536271512508, Final Batch Loss: 0.022968491539359093\n",
      "Epoch 4607, Loss: 0.18133249133825302, Final Batch Loss: 0.047390714287757874\n",
      "Epoch 4608, Loss: 0.137032900005579, Final Batch Loss: 0.05230376124382019\n",
      "Epoch 4609, Loss: 0.20603609085083008, Final Batch Loss: 0.07128268480300903\n",
      "Epoch 4610, Loss: 0.10307168716099113, Final Batch Loss: 0.001421769498847425\n",
      "Epoch 4611, Loss: 0.3119696266949177, Final Batch Loss: 0.17179523408412933\n",
      "Epoch 4612, Loss: 0.13306203112006187, Final Batch Loss: 0.013864468783140182\n",
      "Epoch 4613, Loss: 0.17999921832233667, Final Batch Loss: 0.010605872608721256\n",
      "Epoch 4614, Loss: 0.16861610859632492, Final Batch Loss: 0.01997886598110199\n",
      "Epoch 4615, Loss: 0.18971317261457443, Final Batch Loss: 0.0363975390791893\n",
      "Epoch 4616, Loss: 0.21316853910684586, Final Batch Loss: 0.11448319256305695\n",
      "Epoch 4617, Loss: 0.12093097693286836, Final Batch Loss: 0.0037035977002233267\n",
      "Epoch 4618, Loss: 0.18468925543129444, Final Batch Loss: 0.01999870128929615\n",
      "Epoch 4619, Loss: 0.18056264147162437, Final Batch Loss: 0.035864848643541336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4620, Loss: 0.36197205632925034, Final Batch Loss: 0.24911701679229736\n",
      "Epoch 4621, Loss: 0.1576077975332737, Final Batch Loss: 0.008135493844747543\n",
      "Epoch 4622, Loss: 0.24119500070810318, Final Batch Loss: 0.15481379628181458\n",
      "Epoch 4623, Loss: 0.24139203503727913, Final Batch Loss: 0.11223342269659042\n",
      "Epoch 4624, Loss: 0.5782293975353241, Final Batch Loss: 0.41750651597976685\n",
      "Epoch 4625, Loss: 0.1519104866310954, Final Batch Loss: 0.015086228959262371\n",
      "Epoch 4626, Loss: 0.5795630291104317, Final Batch Loss: 0.3446328639984131\n",
      "Epoch 4627, Loss: 0.20627234131097794, Final Batch Loss: 0.025598518550395966\n",
      "Epoch 4628, Loss: 0.16356072947382927, Final Batch Loss: 0.006253283470869064\n",
      "Epoch 4629, Loss: 0.1800444582477212, Final Batch Loss: 0.006047391332685947\n",
      "Epoch 4630, Loss: 0.21989133208990097, Final Batch Loss: 0.07737696915864944\n",
      "Epoch 4631, Loss: 0.2131650261580944, Final Batch Loss: 0.03965600207448006\n",
      "Epoch 4632, Loss: 0.09539476223289967, Final Batch Loss: 0.01830897107720375\n",
      "Epoch 4633, Loss: 0.42940932139754295, Final Batch Loss: 0.31512242555618286\n",
      "Epoch 4634, Loss: 0.18860071152448654, Final Batch Loss: 0.014815002679824829\n",
      "Epoch 4635, Loss: 0.30245157703757286, Final Batch Loss: 0.056029658764600754\n",
      "Epoch 4636, Loss: 0.31313442438840866, Final Batch Loss: 0.06389985233545303\n",
      "Epoch 4637, Loss: 0.16316805314272642, Final Batch Loss: 0.010861526243388653\n",
      "Epoch 4638, Loss: 0.23795519769191742, Final Batch Loss: 0.12971702218055725\n",
      "Epoch 4639, Loss: 0.2144116759300232, Final Batch Loss: 0.0684162974357605\n",
      "Epoch 4640, Loss: 0.11560708796605468, Final Batch Loss: 0.004274589475244284\n",
      "Epoch 4641, Loss: 0.37068964540958405, Final Batch Loss: 0.17349182069301605\n",
      "Epoch 4642, Loss: 0.24864817410707474, Final Batch Loss: 0.08442264795303345\n",
      "Epoch 4643, Loss: 0.1891159489750862, Final Batch Loss: 0.04847760498523712\n",
      "Epoch 4644, Loss: 0.26692498475313187, Final Batch Loss: 0.10134334862232208\n",
      "Epoch 4645, Loss: 0.19211842864751816, Final Batch Loss: 0.05405639484524727\n",
      "Epoch 4646, Loss: 0.2861780375242233, Final Batch Loss: 0.10935743153095245\n",
      "Epoch 4647, Loss: 0.18008526973426342, Final Batch Loss: 0.026759451255202293\n",
      "Epoch 4648, Loss: 0.18845958076417446, Final Batch Loss: 0.022083019837737083\n",
      "Epoch 4649, Loss: 0.2108175791800022, Final Batch Loss: 0.08765798807144165\n",
      "Epoch 4650, Loss: 0.2757171541452408, Final Batch Loss: 0.13849574327468872\n",
      "Epoch 4651, Loss: 0.39134591072797775, Final Batch Loss: 0.2383105605840683\n",
      "Epoch 4652, Loss: 0.172527345828712, Final Batch Loss: 0.01313087623566389\n",
      "Epoch 4653, Loss: 0.19468228332698345, Final Batch Loss: 0.016181452199816704\n",
      "Epoch 4654, Loss: 0.12389027699828148, Final Batch Loss: 0.017803683876991272\n",
      "Epoch 4655, Loss: 0.2190638929605484, Final Batch Loss: 0.090467669069767\n",
      "Epoch 4656, Loss: 0.15035135741345584, Final Batch Loss: 0.003518362296745181\n",
      "Epoch 4657, Loss: 0.19757239520549774, Final Batch Loss: 0.04464859515428543\n",
      "Epoch 4658, Loss: 0.17280788626521826, Final Batch Loss: 0.013547792099416256\n",
      "Epoch 4659, Loss: 0.23040985316038132, Final Batch Loss: 0.10364167392253876\n",
      "Epoch 4660, Loss: 0.13139238022267818, Final Batch Loss: 0.03823629394173622\n",
      "Epoch 4661, Loss: 0.15707338973879814, Final Batch Loss: 0.06194145604968071\n",
      "Epoch 4662, Loss: 0.1690484918653965, Final Batch Loss: 0.07131104916334152\n",
      "Epoch 4663, Loss: 0.16567512229084969, Final Batch Loss: 0.038726065307855606\n",
      "Epoch 4664, Loss: 0.3208572193980217, Final Batch Loss: 0.20567868649959564\n",
      "Epoch 4665, Loss: 0.16223127767443657, Final Batch Loss: 0.08411465585231781\n",
      "Epoch 4666, Loss: 0.1524827112443745, Final Batch Loss: 0.0005970974452793598\n",
      "Epoch 4667, Loss: 0.1381568795768544, Final Batch Loss: 0.0015631503192707896\n",
      "Epoch 4668, Loss: 0.34635281935334206, Final Batch Loss: 0.21491117775440216\n",
      "Epoch 4669, Loss: 0.43165596947073936, Final Batch Loss: 0.3077284097671509\n",
      "Epoch 4670, Loss: 0.11529152654111385, Final Batch Loss: 0.02594647742807865\n",
      "Epoch 4671, Loss: 0.16152298729866743, Final Batch Loss: 0.01510301511734724\n",
      "Epoch 4672, Loss: 0.1717527098953724, Final Batch Loss: 0.0817914828658104\n",
      "Epoch 4673, Loss: 0.1611731592565775, Final Batch Loss: 0.017787570133805275\n",
      "Epoch 4674, Loss: 0.13487205654382706, Final Batch Loss: 0.007440108805894852\n",
      "Epoch 4675, Loss: 0.297265637665987, Final Batch Loss: 0.18433721363544464\n",
      "Epoch 4676, Loss: 0.11763234529644251, Final Batch Loss: 0.004612375982105732\n",
      "Epoch 4677, Loss: 0.23897434398531914, Final Batch Loss: 0.12892389297485352\n",
      "Epoch 4678, Loss: 0.10996823059394956, Final Batch Loss: 0.0073814173229038715\n",
      "Epoch 4679, Loss: 0.2409779541194439, Final Batch Loss: 0.12061023712158203\n",
      "Epoch 4680, Loss: 0.31258605048060417, Final Batch Loss: 0.16679759323596954\n",
      "Epoch 4681, Loss: 0.12016949499957263, Final Batch Loss: 0.0008504509460180998\n",
      "Epoch 4682, Loss: 0.1880171000957489, Final Batch Loss: 0.05427611619234085\n",
      "Epoch 4683, Loss: 0.165194071829319, Final Batch Loss: 0.023950882256031036\n",
      "Epoch 4684, Loss: 0.22219958901405334, Final Batch Loss: 0.03862118721008301\n",
      "Epoch 4685, Loss: 0.12323489121627063, Final Batch Loss: 0.0006203398806974292\n",
      "Epoch 4686, Loss: 0.15448019024915993, Final Batch Loss: 0.0038370799738913774\n",
      "Epoch 4687, Loss: 0.1912817396223545, Final Batch Loss: 0.08006207644939423\n",
      "Epoch 4688, Loss: 0.18950756080448627, Final Batch Loss: 0.029350275173783302\n",
      "Epoch 4689, Loss: 0.33334070816636086, Final Batch Loss: 0.21173664927482605\n",
      "Epoch 4690, Loss: 0.20275619067251682, Final Batch Loss: 0.08240292221307755\n",
      "Epoch 4691, Loss: 0.19216983392834663, Final Batch Loss: 0.08305852115154266\n",
      "Epoch 4692, Loss: 0.10198567993938923, Final Batch Loss: 0.022891804575920105\n",
      "Epoch 4693, Loss: 0.11150297522544861, Final Batch Loss: 0.012092389166355133\n",
      "Epoch 4694, Loss: 0.11682528862729669, Final Batch Loss: 0.0040997848846018314\n",
      "Epoch 4695, Loss: 0.10567635670304298, Final Batch Loss: 0.01894637942314148\n",
      "Epoch 4696, Loss: 0.3671415485441685, Final Batch Loss: 0.2420070767402649\n",
      "Epoch 4697, Loss: 0.11032960377633572, Final Batch Loss: 0.01743979938328266\n",
      "Epoch 4698, Loss: 0.15629548765718937, Final Batch Loss: 0.011278772726655006\n",
      "Epoch 4699, Loss: 0.19702400546520948, Final Batch Loss: 0.009993243031203747\n",
      "Epoch 4700, Loss: 0.168331116437912, Final Batch Loss: 0.048398882150650024\n",
      "Epoch 4701, Loss: 0.36168037727475166, Final Batch Loss: 0.1774163842201233\n",
      "Epoch 4702, Loss: 0.22561334073543549, Final Batch Loss: 0.0911763608455658\n",
      "Epoch 4703, Loss: 0.1277532186359167, Final Batch Loss: 0.018462592735886574\n",
      "Epoch 4704, Loss: 0.17438652738928795, Final Batch Loss: 0.02966279163956642\n",
      "Epoch 4705, Loss: 0.1712527945637703, Final Batch Loss: 0.01206035166978836\n",
      "Epoch 4706, Loss: 0.17100650072097778, Final Batch Loss: 0.07269004732370377\n",
      "Epoch 4707, Loss: 0.23604604229331017, Final Batch Loss: 0.15078048408031464\n",
      "Epoch 4708, Loss: 0.12484832666814327, Final Batch Loss: 0.017034007236361504\n",
      "Epoch 4709, Loss: 0.25249604508280754, Final Batch Loss: 0.1409546285867691\n",
      "Epoch 4710, Loss: 0.2612799219787121, Final Batch Loss: 0.17017140984535217\n",
      "Epoch 4711, Loss: 0.1878741830587387, Final Batch Loss: 0.11666783690452576\n",
      "Epoch 4712, Loss: 0.1041896129027009, Final Batch Loss: 0.011279874481260777\n",
      "Epoch 4713, Loss: 0.17038124427199364, Final Batch Loss: 0.045222532004117966\n",
      "Epoch 4714, Loss: 0.32062096893787384, Final Batch Loss: 0.10895441472530365\n",
      "Epoch 4715, Loss: 0.12499318271875381, Final Batch Loss: 0.0348656140267849\n",
      "Epoch 4716, Loss: 0.16077156737446785, Final Batch Loss: 0.0210789255797863\n",
      "Epoch 4717, Loss: 0.17608759924769402, Final Batch Loss: 0.021582182496786118\n",
      "Epoch 4718, Loss: 0.16361963376402855, Final Batch Loss: 0.01951364055275917\n",
      "Epoch 4719, Loss: 0.15310796722769737, Final Batch Loss: 0.03882763534784317\n",
      "Epoch 4720, Loss: 0.12512246146798134, Final Batch Loss: 0.01853404939174652\n",
      "Epoch 4721, Loss: 0.17971255630254745, Final Batch Loss: 0.050122134387493134\n",
      "Epoch 4722, Loss: 0.2006663903594017, Final Batch Loss: 0.0695042610168457\n",
      "Epoch 4723, Loss: 0.11247790418565273, Final Batch Loss: 0.01562461443245411\n",
      "Epoch 4724, Loss: 0.164563849568367, Final Batch Loss: 0.04254894331097603\n",
      "Epoch 4725, Loss: 0.14216808788478374, Final Batch Loss: 0.024288048967719078\n",
      "Epoch 4726, Loss: 0.21941844373941422, Final Batch Loss: 0.05224230885505676\n",
      "Epoch 4727, Loss: 0.0914556611678563, Final Batch Loss: 0.0009417686960659921\n",
      "Epoch 4728, Loss: 0.1877145953476429, Final Batch Loss: 0.10347288846969604\n",
      "Epoch 4729, Loss: 0.17042233794927597, Final Batch Loss: 0.05430208891630173\n",
      "Epoch 4730, Loss: 0.10178455535788089, Final Batch Loss: 0.0009786431910470128\n",
      "Epoch 4731, Loss: 0.1801298502832651, Final Batch Loss: 0.01891760714352131\n",
      "Epoch 4732, Loss: 0.11702236300334334, Final Batch Loss: 0.0007110177539288998\n",
      "Epoch 4733, Loss: 0.10320576466619968, Final Batch Loss: 0.016340669244527817\n",
      "Epoch 4734, Loss: 0.35016367956995964, Final Batch Loss: 0.2744414806365967\n",
      "Epoch 4735, Loss: 0.12767703644931316, Final Batch Loss: 0.016729509457945824\n",
      "Epoch 4736, Loss: 0.1591895967721939, Final Batch Loss: 0.07969962060451508\n",
      "Epoch 4737, Loss: 0.16708030179142952, Final Batch Loss: 0.04329483583569527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4738, Loss: 0.09806342422962189, Final Batch Loss: 0.008512957021594048\n",
      "Epoch 4739, Loss: 0.3645642362535, Final Batch Loss: 0.2588719427585602\n",
      "Epoch 4740, Loss: 0.10964975878596306, Final Batch Loss: 0.014916520565748215\n",
      "Epoch 4741, Loss: 0.10112450085580349, Final Batch Loss: 0.012999607250094414\n",
      "Epoch 4742, Loss: 0.342053584754467, Final Batch Loss: 0.27294009923934937\n",
      "Epoch 4743, Loss: 0.3186875879764557, Final Batch Loss: 0.1813517063856125\n",
      "Epoch 4744, Loss: 0.13520499505102634, Final Batch Loss: 0.01556633971631527\n",
      "Epoch 4745, Loss: 0.07826047856360674, Final Batch Loss: 0.013366187922656536\n",
      "Epoch 4746, Loss: 0.11267565563321114, Final Batch Loss: 0.02159157395362854\n",
      "Epoch 4747, Loss: 0.1253312360495329, Final Batch Loss: 0.02185080759227276\n",
      "Epoch 4748, Loss: 0.12817781418561935, Final Batch Loss: 0.008887097239494324\n",
      "Epoch 4749, Loss: 0.25750797614455223, Final Batch Loss: 0.20123685896396637\n",
      "Epoch 4750, Loss: 0.1535705290734768, Final Batch Loss: 0.052171044051647186\n",
      "Epoch 4751, Loss: 0.10057242744369432, Final Batch Loss: 0.0006034091929905117\n",
      "Epoch 4752, Loss: 0.10845432430505753, Final Batch Loss: 0.020184677094221115\n",
      "Epoch 4753, Loss: 0.13596569374203682, Final Batch Loss: 0.043628595769405365\n",
      "Epoch 4754, Loss: 0.15863651130348444, Final Batch Loss: 0.0068576643243432045\n",
      "Epoch 4755, Loss: 0.07291093748062849, Final Batch Loss: 0.002751794643700123\n",
      "Epoch 4756, Loss: 0.10068381205201149, Final Batch Loss: 0.015725284814834595\n",
      "Epoch 4757, Loss: 0.15135261788964272, Final Batch Loss: 0.06917193531990051\n",
      "Epoch 4758, Loss: 0.12406938895583153, Final Batch Loss: 0.00506943091750145\n",
      "Epoch 4759, Loss: 0.15356184169650078, Final Batch Loss: 0.02925010770559311\n",
      "Epoch 4760, Loss: 0.15482159764360404, Final Batch Loss: 0.00010438696335768327\n",
      "Epoch 4761, Loss: 0.16568985424237326, Final Batch Loss: 0.0002027287264354527\n",
      "Epoch 4762, Loss: 0.08238187758252025, Final Batch Loss: 0.005943141411989927\n",
      "Epoch 4763, Loss: 0.11567649990320206, Final Batch Loss: 0.014588911086320877\n",
      "Epoch 4764, Loss: 0.1095248181372881, Final Batch Loss: 0.011345120146870613\n",
      "Epoch 4765, Loss: 0.1276692128740251, Final Batch Loss: 0.004158766474574804\n",
      "Epoch 4766, Loss: 0.10221437737345695, Final Batch Loss: 0.017080429941415787\n",
      "Epoch 4767, Loss: 0.16754557751119137, Final Batch Loss: 0.09863701462745667\n",
      "Epoch 4768, Loss: 0.08969416376203299, Final Batch Loss: 0.0078217638656497\n",
      "Epoch 4769, Loss: 0.25011545047163963, Final Batch Loss: 0.1609792709350586\n",
      "Epoch 4770, Loss: 0.1584094874560833, Final Batch Loss: 0.05715750530362129\n",
      "Epoch 4771, Loss: 0.13156499899923801, Final Batch Loss: 0.024763381108641624\n",
      "Epoch 4772, Loss: 0.1307680291356519, Final Batch Loss: 0.001037163776345551\n",
      "Epoch 4773, Loss: 0.11252317391335964, Final Batch Loss: 0.014969976618885994\n",
      "Epoch 4774, Loss: 0.3801180087029934, Final Batch Loss: 0.27547797560691833\n",
      "Epoch 4775, Loss: 0.3216901645064354, Final Batch Loss: 0.13806061446666718\n",
      "Epoch 4776, Loss: 0.21916434250306338, Final Batch Loss: 0.0018375375075265765\n",
      "Epoch 4777, Loss: 0.29655247926712036, Final Batch Loss: 0.06471420079469681\n",
      "Epoch 4778, Loss: 0.25545550836250186, Final Batch Loss: 0.002657547127455473\n",
      "Epoch 4779, Loss: 0.3212045356631279, Final Batch Loss: 0.14086537063121796\n",
      "Epoch 4780, Loss: 0.3819105848670006, Final Batch Loss: 0.21447251737117767\n",
      "Epoch 4781, Loss: 0.3902342673391104, Final Batch Loss: 0.01661977730691433\n",
      "Epoch 4782, Loss: 0.22741924040019512, Final Batch Loss: 0.022603577002882957\n",
      "Epoch 4783, Loss: 0.16685475036501884, Final Batch Loss: 0.014800924807786942\n",
      "Epoch 4784, Loss: 0.20093511790037155, Final Batch Loss: 0.02686627209186554\n",
      "Epoch 4785, Loss: 0.192672248929739, Final Batch Loss: 0.037415292114019394\n",
      "Epoch 4786, Loss: 0.30904077365994453, Final Batch Loss: 0.13746853172779083\n",
      "Epoch 4787, Loss: 0.12022626027464867, Final Batch Loss: 0.01845908910036087\n",
      "Epoch 4788, Loss: 0.21208105608820915, Final Batch Loss: 0.06589513272047043\n",
      "Epoch 4789, Loss: 0.12237155809998512, Final Batch Loss: 0.01628326252102852\n",
      "Epoch 4790, Loss: 0.12472756230272353, Final Batch Loss: 0.002761062467470765\n",
      "Epoch 4791, Loss: 0.10885052941739559, Final Batch Loss: 0.010004909709095955\n",
      "Epoch 4792, Loss: 0.15639045275747776, Final Batch Loss: 0.007747555151581764\n",
      "Epoch 4793, Loss: 0.10052016796544194, Final Batch Loss: 0.002667446155101061\n",
      "Epoch 4794, Loss: 0.28673236444592476, Final Batch Loss: 0.19689492881298065\n",
      "Epoch 4795, Loss: 0.08050861395895481, Final Batch Loss: 0.008198076859116554\n",
      "Epoch 4796, Loss: 0.15606557577848434, Final Batch Loss: 0.037977028638124466\n",
      "Epoch 4797, Loss: 0.1592325195670128, Final Batch Loss: 0.04151167348027229\n",
      "Epoch 4798, Loss: 0.10279338487816858, Final Batch Loss: 3.458240462350659e-05\n",
      "Epoch 4799, Loss: 0.14556125551462173, Final Batch Loss: 0.04484610632061958\n",
      "Epoch 4800, Loss: 0.1907801628112793, Final Batch Loss: 0.03956794738769531\n",
      "Epoch 4801, Loss: 0.11492872424423695, Final Batch Loss: 0.027756204828619957\n",
      "Epoch 4802, Loss: 0.2909909002482891, Final Batch Loss: 0.17864298820495605\n",
      "Epoch 4803, Loss: 0.11829733103513718, Final Batch Loss: 0.041627272963523865\n",
      "Epoch 4804, Loss: 0.17504224553704262, Final Batch Loss: 0.0941680446267128\n",
      "Epoch 4805, Loss: 0.23630299791693687, Final Batch Loss: 0.08598259091377258\n",
      "Epoch 4806, Loss: 0.2769765444099903, Final Batch Loss: 0.13894806802272797\n",
      "Epoch 4807, Loss: 0.23151913285255432, Final Batch Loss: 0.040317997336387634\n",
      "Epoch 4808, Loss: 0.2579931765794754, Final Batch Loss: 0.0461001843214035\n",
      "Epoch 4809, Loss: 0.13813391514122486, Final Batch Loss: 0.016552144661545753\n",
      "Epoch 4810, Loss: 0.3604418635368347, Final Batch Loss: 0.1990659385919571\n",
      "Epoch 4811, Loss: 0.40580177679657936, Final Batch Loss: 0.28984034061431885\n",
      "Epoch 4812, Loss: 0.7171590775251389, Final Batch Loss: 0.4946339726448059\n",
      "Epoch 4813, Loss: 0.345687223598361, Final Batch Loss: 0.026826990768313408\n",
      "Epoch 4814, Loss: 0.16691530868411064, Final Batch Loss: 0.015017278492450714\n",
      "Epoch 4815, Loss: 0.331748653203249, Final Batch Loss: 0.21084320545196533\n",
      "Epoch 4816, Loss: 0.2991652935743332, Final Batch Loss: 0.0915675237774849\n",
      "Epoch 4817, Loss: 0.21397439017891884, Final Batch Loss: 0.06701827049255371\n",
      "Epoch 4818, Loss: 0.15957219991832972, Final Batch Loss: 0.0050119394436478615\n",
      "Epoch 4819, Loss: 0.16211666725575924, Final Batch Loss: 0.02385074459016323\n",
      "Epoch 4820, Loss: 0.15379457361996174, Final Batch Loss: 0.00895761139690876\n",
      "Epoch 4821, Loss: 0.1412851195782423, Final Batch Loss: 0.019544051960110664\n",
      "Epoch 4822, Loss: 0.0682992700021714, Final Batch Loss: 0.0016101996880024672\n",
      "Epoch 4823, Loss: 0.14692780375480652, Final Batch Loss: 0.030751626938581467\n",
      "Epoch 4824, Loss: 0.33975717052817345, Final Batch Loss: 0.21777130663394928\n",
      "Epoch 4825, Loss: 0.25553176179528236, Final Batch Loss: 0.1061476543545723\n",
      "Epoch 4826, Loss: 0.1042039655148983, Final Batch Loss: 0.023429851979017258\n",
      "Epoch 4827, Loss: 0.20192968100309372, Final Batch Loss: 0.07437971234321594\n",
      "Epoch 4828, Loss: 0.20308387279510498, Final Batch Loss: 0.07188879698514938\n",
      "Epoch 4829, Loss: 0.31222087517380714, Final Batch Loss: 0.06043582782149315\n",
      "Epoch 4830, Loss: 0.6145788580179214, Final Batch Loss: 0.38328081369400024\n",
      "Epoch 4831, Loss: 0.5832953304052353, Final Batch Loss: 0.2398272007703781\n",
      "Epoch 4832, Loss: 0.5835858583450317, Final Batch Loss: 0.1780746430158615\n",
      "Epoch 4833, Loss: 0.5910401940345764, Final Batch Loss: 0.23221082985401154\n",
      "Epoch 4834, Loss: 0.25638036523014307, Final Batch Loss: 0.013220862485468388\n",
      "Epoch 4835, Loss: 0.277269184589386, Final Batch Loss: 0.06797805428504944\n",
      "Epoch 4836, Loss: 0.26118987426161766, Final Batch Loss: 0.03837926313281059\n",
      "Epoch 4837, Loss: 0.23135054484009743, Final Batch Loss: 0.03371046110987663\n",
      "Epoch 4838, Loss: 0.168394198641181, Final Batch Loss: 0.017418554052710533\n",
      "Epoch 4839, Loss: 0.32424432784318924, Final Batch Loss: 0.15899790823459625\n",
      "Epoch 4840, Loss: 0.27451150864362717, Final Batch Loss: 0.13179828226566315\n",
      "Epoch 4841, Loss: 0.23744458705186844, Final Batch Loss: 0.04968377947807312\n",
      "Epoch 4842, Loss: 0.2072473280131817, Final Batch Loss: 0.026162657886743546\n",
      "Epoch 4843, Loss: 0.2967570275068283, Final Batch Loss: 0.10828665643930435\n",
      "Epoch 4844, Loss: 0.19105392321944237, Final Batch Loss: 0.028530102223157883\n",
      "Epoch 4845, Loss: 0.16105347429402173, Final Batch Loss: 0.002581048058345914\n",
      "Epoch 4846, Loss: 0.16727584600448608, Final Batch Loss: 0.026576675474643707\n",
      "Epoch 4847, Loss: 0.14287485764361918, Final Batch Loss: 0.0029786063823848963\n",
      "Epoch 4848, Loss: 0.1904158815741539, Final Batch Loss: 0.037146687507629395\n",
      "Epoch 4849, Loss: 0.15325188264250755, Final Batch Loss: 0.019009385257959366\n",
      "Epoch 4850, Loss: 0.1568734161555767, Final Batch Loss: 0.04478533938527107\n",
      "Epoch 4851, Loss: 0.13860092358663678, Final Batch Loss: 0.00697098346427083\n",
      "Epoch 4852, Loss: 0.41217078268527985, Final Batch Loss: 0.26473549008369446\n",
      "Epoch 4853, Loss: 0.16462982073426247, Final Batch Loss: 0.025052282959222794\n",
      "Epoch 4854, Loss: 0.26802094280719757, Final Batch Loss: 0.09250078350305557\n",
      "Epoch 4855, Loss: 0.14641456305980682, Final Batch Loss: 0.037551719695329666\n",
      "Epoch 4856, Loss: 0.21330657973885536, Final Batch Loss: 0.12180624157190323\n",
      "Epoch 4857, Loss: 0.14717411948367953, Final Batch Loss: 0.003351911436766386\n",
      "Epoch 4858, Loss: 0.1640513286110945, Final Batch Loss: 0.0009190708515234292\n",
      "Epoch 4859, Loss: 0.23008118942379951, Final Batch Loss: 0.06460029631853104\n",
      "Epoch 4860, Loss: 0.23167777433991432, Final Batch Loss: 0.058426592499017715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4861, Loss: 0.19886874593794346, Final Batch Loss: 0.01898898370563984\n",
      "Epoch 4862, Loss: 0.1373995179310441, Final Batch Loss: 0.008958426304161549\n",
      "Epoch 4863, Loss: 0.39793575555086136, Final Batch Loss: 0.2688280940055847\n",
      "Epoch 4864, Loss: 0.1483327429741621, Final Batch Loss: 0.02845117636024952\n",
      "Epoch 4865, Loss: 0.20396841689944267, Final Batch Loss: 0.053159449249506\n",
      "Epoch 4866, Loss: 0.17140673100948334, Final Batch Loss: 0.06954295933246613\n",
      "Epoch 4867, Loss: 0.17469352670013905, Final Batch Loss: 0.03064718283712864\n",
      "Epoch 4868, Loss: 0.14128515776246786, Final Batch Loss: 0.011528155766427517\n",
      "Epoch 4869, Loss: 0.2205457855015993, Final Batch Loss: 0.007787054404616356\n",
      "Epoch 4870, Loss: 0.11820053122937679, Final Batch Loss: 0.031036389991641045\n",
      "Epoch 4871, Loss: 0.19148256815969944, Final Batch Loss: 0.01610925979912281\n",
      "Epoch 4872, Loss: 0.1355189885944128, Final Batch Loss: 0.019263116642832756\n",
      "Epoch 4873, Loss: 0.17470603808760643, Final Batch Loss: 0.08667387813329697\n",
      "Epoch 4874, Loss: 0.15262224804610014, Final Batch Loss: 0.014005488716065884\n",
      "Epoch 4875, Loss: 0.5497074574232101, Final Batch Loss: 0.4367561936378479\n",
      "Epoch 4876, Loss: 0.15723375231027603, Final Batch Loss: 0.027302201837301254\n",
      "Epoch 4877, Loss: 0.11613234132528305, Final Batch Loss: 0.024127822369337082\n",
      "Epoch 4878, Loss: 0.2731455974280834, Final Batch Loss: 0.17534685134887695\n",
      "Epoch 4879, Loss: 0.12480245903134346, Final Batch Loss: 0.03692827746272087\n",
      "Epoch 4880, Loss: 0.19864921644330025, Final Batch Loss: 0.057069338858127594\n",
      "Epoch 4881, Loss: 0.13553429394960403, Final Batch Loss: 0.00957949087023735\n",
      "Epoch 4882, Loss: 0.1973911551758647, Final Batch Loss: 0.008455838076770306\n",
      "Epoch 4883, Loss: 0.11639211606234312, Final Batch Loss: 0.011964715085923672\n",
      "Epoch 4884, Loss: 0.1628716066479683, Final Batch Loss: 0.022651925683021545\n",
      "Epoch 4885, Loss: 0.10317629156634212, Final Batch Loss: 0.004276044201105833\n",
      "Epoch 4886, Loss: 0.14544406160712242, Final Batch Loss: 0.01805836334824562\n",
      "Epoch 4887, Loss: 0.3245701342821121, Final Batch Loss: 0.22399789094924927\n",
      "Epoch 4888, Loss: 0.2851030305027962, Final Batch Loss: 0.11676714569330215\n",
      "Epoch 4889, Loss: 0.13238969072699547, Final Batch Loss: 0.02151188999414444\n",
      "Epoch 4890, Loss: 0.27729492262005806, Final Batch Loss: 0.15646348893642426\n",
      "Epoch 4891, Loss: 0.22288433834910393, Final Batch Loss: 0.05682752653956413\n",
      "Epoch 4892, Loss: 0.23912418261170387, Final Batch Loss: 0.06445706635713577\n",
      "Epoch 4893, Loss: 0.2270083799958229, Final Batch Loss: 0.021558105945587158\n",
      "Epoch 4894, Loss: 0.2922096624970436, Final Batch Loss: 0.10791630297899246\n",
      "Epoch 4895, Loss: 0.17363805510103703, Final Batch Loss: 0.026530331000685692\n",
      "Epoch 4896, Loss: 0.1422792775556445, Final Batch Loss: 0.012527319602668285\n",
      "Epoch 4897, Loss: 0.18532165081705898, Final Batch Loss: 0.0009209656855091453\n",
      "Epoch 4898, Loss: 0.15429500117897987, Final Batch Loss: 0.022033385932445526\n",
      "Epoch 4899, Loss: 0.29327816888689995, Final Batch Loss: 0.16475149989128113\n",
      "Epoch 4900, Loss: 0.1249263621866703, Final Batch Loss: 0.008577175438404083\n",
      "Epoch 4901, Loss: 0.11067528277635574, Final Batch Loss: 0.02591775357723236\n",
      "Epoch 4902, Loss: 0.27194375917315483, Final Batch Loss: 0.16168490052223206\n",
      "Epoch 4903, Loss: 0.12764419801533222, Final Batch Loss: 0.010961296036839485\n",
      "Epoch 4904, Loss: 0.12164447642862797, Final Batch Loss: 0.028960255905985832\n",
      "Epoch 4905, Loss: 0.28673693910241127, Final Batch Loss: 0.16797932982444763\n",
      "Epoch 4906, Loss: 0.21647758409380913, Final Batch Loss: 0.034281205385923386\n",
      "Epoch 4907, Loss: 0.17121092975139618, Final Batch Loss: 0.03239412605762482\n",
      "Epoch 4908, Loss: 0.1574004888534546, Final Batch Loss: 0.04195001348853111\n",
      "Epoch 4909, Loss: 0.1321897692978382, Final Batch Loss: 0.03565484285354614\n",
      "Epoch 4910, Loss: 0.19388144463300705, Final Batch Loss: 0.08331684023141861\n",
      "Epoch 4911, Loss: 0.24911435693502426, Final Batch Loss: 0.012041911482810974\n",
      "Epoch 4912, Loss: 0.11950891418382525, Final Batch Loss: 0.0015006992034614086\n",
      "Epoch 4913, Loss: 0.10094396350905299, Final Batch Loss: 0.002454239409416914\n",
      "Epoch 4914, Loss: 0.15942654013633728, Final Batch Loss: 0.024753190577030182\n",
      "Epoch 4915, Loss: 0.1984310932457447, Final Batch Loss: 0.09044425189495087\n",
      "Epoch 4916, Loss: 0.22263238579034805, Final Batch Loss: 0.09428802877664566\n",
      "Epoch 4917, Loss: 0.1696807835251093, Final Batch Loss: 0.023183250799775124\n",
      "Epoch 4918, Loss: 0.1252318900078535, Final Batch Loss: 0.02572905458509922\n",
      "Epoch 4919, Loss: 0.2648719400167465, Final Batch Loss: 0.15346188843250275\n",
      "Epoch 4920, Loss: 0.11878505581989884, Final Batch Loss: 0.003979040775448084\n",
      "Epoch 4921, Loss: 0.16780379600822926, Final Batch Loss: 0.02822207100689411\n",
      "Epoch 4922, Loss: 0.21563829109072685, Final Batch Loss: 0.08193352073431015\n",
      "Epoch 4923, Loss: 0.17223073821514845, Final Batch Loss: 0.01548281591385603\n",
      "Epoch 4924, Loss: 0.21536465361714363, Final Batch Loss: 0.10546793788671494\n",
      "Epoch 4925, Loss: 0.2116169948130846, Final Batch Loss: 0.010569589212536812\n",
      "Epoch 4926, Loss: 0.1829574704170227, Final Batch Loss: 0.00991911068558693\n",
      "Epoch 4927, Loss: 0.16353539004921913, Final Batch Loss: 0.014189463108778\n",
      "Epoch 4928, Loss: 0.2315036877989769, Final Batch Loss: 0.08417147397994995\n",
      "Epoch 4929, Loss: 0.18971994519233704, Final Batch Loss: 0.05282239615917206\n",
      "Epoch 4930, Loss: 0.22780266776680946, Final Batch Loss: 0.1326248198747635\n",
      "Epoch 4931, Loss: 0.10786015872145072, Final Batch Loss: 0.0007624063291586936\n",
      "Epoch 4932, Loss: 0.08771283249370754, Final Batch Loss: 0.0023121132981032133\n",
      "Epoch 4933, Loss: 0.1753400955349207, Final Batch Loss: 0.09944947808980942\n",
      "Epoch 4934, Loss: 0.13030938524752855, Final Batch Loss: 0.011960969306528568\n",
      "Epoch 4935, Loss: 0.11161578446626663, Final Batch Loss: 0.01169871911406517\n",
      "Epoch 4936, Loss: 0.1789768636226654, Final Batch Loss: 0.04870801791548729\n",
      "Epoch 4937, Loss: 0.16757295653223991, Final Batch Loss: 0.023941297084093094\n",
      "Epoch 4938, Loss: 0.15474466234445572, Final Batch Loss: 0.04579559341073036\n",
      "Epoch 4939, Loss: 0.12971909996122122, Final Batch Loss: 0.009412183426320553\n",
      "Epoch 4940, Loss: 0.11026384681463242, Final Batch Loss: 0.03241400793194771\n",
      "Epoch 4941, Loss: 0.14611756056547165, Final Batch Loss: 0.05468589439988136\n",
      "Epoch 4942, Loss: 0.12407177314162254, Final Batch Loss: 0.027258355170488358\n",
      "Epoch 4943, Loss: 0.21039400435984135, Final Batch Loss: 0.01843552477657795\n",
      "Epoch 4944, Loss: 0.14321288093924522, Final Batch Loss: 0.026407286524772644\n",
      "Epoch 4945, Loss: 0.15867327526211739, Final Batch Loss: 0.0541408434510231\n",
      "Epoch 4946, Loss: 0.1554684191942215, Final Batch Loss: 0.03477298840880394\n",
      "Epoch 4947, Loss: 0.29930195957422256, Final Batch Loss: 0.23271238803863525\n",
      "Epoch 4948, Loss: 0.2389493640512228, Final Batch Loss: 0.028784742578864098\n",
      "Epoch 4949, Loss: 0.13242289889603853, Final Batch Loss: 0.01338436920195818\n",
      "Epoch 4950, Loss: 0.14374268800020218, Final Batch Loss: 0.012381136417388916\n",
      "Epoch 4951, Loss: 0.2214498072862625, Final Batch Loss: 0.03755880147218704\n",
      "Epoch 4952, Loss: 0.15281512029469013, Final Batch Loss: 0.015857214108109474\n",
      "Epoch 4953, Loss: 0.3388901837170124, Final Batch Loss: 0.21628886461257935\n",
      "Epoch 4954, Loss: 0.10984467342495918, Final Batch Loss: 0.045582979917526245\n",
      "Epoch 4955, Loss: 0.16619861498475075, Final Batch Loss: 0.021960530430078506\n",
      "Epoch 4956, Loss: 0.1542352770920843, Final Batch Loss: 0.0024431084748357534\n",
      "Epoch 4957, Loss: 0.09184726513922215, Final Batch Loss: 0.01188972033560276\n",
      "Epoch 4958, Loss: 0.15758710727095604, Final Batch Loss: 0.03720642998814583\n",
      "Epoch 4959, Loss: 0.48257103376090527, Final Batch Loss: 0.3912115693092346\n",
      "Epoch 4960, Loss: 0.6264116503298283, Final Batch Loss: 0.4048672616481781\n",
      "Epoch 4961, Loss: 0.5269326865673065, Final Batch Loss: 0.09134693443775177\n",
      "Epoch 4962, Loss: 0.4284745305776596, Final Batch Loss: 0.15183639526367188\n",
      "Epoch 4963, Loss: 0.39615456759929657, Final Batch Loss: 0.07244141399860382\n",
      "Epoch 4964, Loss: 0.33697514794766903, Final Batch Loss: 0.01633462868630886\n",
      "Epoch 4965, Loss: 0.3583486005663872, Final Batch Loss: 0.09809912741184235\n",
      "Epoch 4966, Loss: 0.22943521663546562, Final Batch Loss: 0.012800704687833786\n",
      "Epoch 4967, Loss: 0.8275900557637215, Final Batch Loss: 0.5857530832290649\n",
      "Epoch 4968, Loss: 0.4714578613638878, Final Batch Loss: 0.28432485461235046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4969, Loss: 0.3180893659591675, Final Batch Loss: 0.02424507588148117\n",
      "Epoch 4970, Loss: 0.2514737723977305, Final Batch Loss: 0.00035335408756509423\n",
      "Epoch 4971, Loss: 0.14888514950871468, Final Batch Loss: 0.03466518595814705\n",
      "Epoch 4972, Loss: 0.18993560131639242, Final Batch Loss: 0.01429308857768774\n",
      "Epoch 4973, Loss: 0.31204796209931374, Final Batch Loss: 0.18517427146434784\n",
      "Epoch 4974, Loss: 0.13414493575692177, Final Batch Loss: 0.012211695313453674\n",
      "Epoch 4975, Loss: 0.20877769961953163, Final Batch Loss: 0.06065962091088295\n",
      "Epoch 4976, Loss: 0.2125321663916111, Final Batch Loss: 0.05060240998864174\n",
      "Epoch 4977, Loss: 0.15165827609598637, Final Batch Loss: 0.018443042412400246\n",
      "Epoch 4978, Loss: 0.18764149770140648, Final Batch Loss: 0.04203500226140022\n",
      "Epoch 4979, Loss: 0.6482780501246452, Final Batch Loss: 0.4987388849258423\n",
      "Epoch 4980, Loss: 0.1639898531138897, Final Batch Loss: 0.02782561257481575\n",
      "Epoch 4981, Loss: 0.25602205097675323, Final Batch Loss: 0.1259150356054306\n",
      "Epoch 4982, Loss: 0.2848067283630371, Final Batch Loss: 0.13155972957611084\n",
      "Epoch 4983, Loss: 0.21014667302370071, Final Batch Loss: 0.1179506927728653\n",
      "Epoch 4984, Loss: 0.11860690638422966, Final Batch Loss: 0.0006516091525554657\n",
      "Epoch 4985, Loss: 0.23019104450941086, Final Batch Loss: 0.10587479919195175\n",
      "Epoch 4986, Loss: 0.27154863253235817, Final Batch Loss: 0.08099377900362015\n",
      "Epoch 4987, Loss: 0.2540844827890396, Final Batch Loss: 0.0819246768951416\n",
      "Epoch 4988, Loss: 0.20986566320061684, Final Batch Loss: 0.07544740289449692\n",
      "Epoch 4989, Loss: 0.15270193526521325, Final Batch Loss: 0.00555995712056756\n",
      "Epoch 4990, Loss: 0.08887659199535847, Final Batch Loss: 0.010493190959095955\n",
      "Epoch 4991, Loss: 0.14062475971877575, Final Batch Loss: 0.003999942913651466\n",
      "Epoch 4992, Loss: 0.2607177272439003, Final Batch Loss: 0.09609999507665634\n",
      "Epoch 4993, Loss: 0.2988150864839554, Final Batch Loss: 0.1552940458059311\n",
      "Epoch 4994, Loss: 0.16865885257720947, Final Batch Loss: 0.031367309391498566\n",
      "Epoch 4995, Loss: 0.21055316552519798, Final Batch Loss: 0.08872435986995697\n",
      "Epoch 4996, Loss: 0.17093859240412712, Final Batch Loss: 0.03669477254152298\n",
      "Epoch 4997, Loss: 0.16357164084911346, Final Batch Loss: 0.06666810810565948\n",
      "Epoch 4998, Loss: 0.2212815135717392, Final Batch Loss: 0.06277361512184143\n",
      "Epoch 4999, Loss: 0.18225722759962082, Final Batch Loss: 0.02518969401717186\n",
      "Epoch 5000, Loss: 0.2288093864917755, Final Batch Loss: 0.08741883188486099\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0  0  0]\n",
      " [ 1 28  3  1]\n",
      " [ 0  1 24  0]\n",
      " [ 0  0  0 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97674   1.00000   0.98824        42\n",
      "           1    0.96552   0.84848   0.90323        33\n",
      "           2    0.88889   0.96000   0.92308        25\n",
      "           3    0.96774   1.00000   0.98361        30\n",
      "\n",
      "    accuracy                        0.95385       130\n",
      "   macro avg    0.94972   0.95212   0.94954       130\n",
      "weighted avg    0.95492   0.95385   0.95306       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  0  0  0]\n",
      " [ 0 34  0  0]\n",
      " [ 0  0 25  0]\n",
      " [ 0  0  0 32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000        39\n",
      "           1    1.00000   1.00000   1.00000        34\n",
      "           2    1.00000   1.00000   1.00000        25\n",
      "           3    1.00000   1.00000   1.00000        32\n",
      "\n",
      "    accuracy                        1.00000       130\n",
      "   macro avg    1.00000   1.00000   1.00000       130\n",
      "weighted avg    1.00000   1.00000   1.00000       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(usr_vectors[0], preds.cpu()))\n",
    "print(metrics.classification_report(usr_vectors[0], preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
