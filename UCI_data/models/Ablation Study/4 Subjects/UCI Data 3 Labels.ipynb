{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>128 tBodyGyro-mad()-Y</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>382 fBodyAccJerk-bandsEnergy()-1,8</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.976353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.989038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.994122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.993142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.992542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>0.065142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.839256</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>0.091791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.854278</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.907561</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.170686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.815380</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.910648</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.178939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.822905</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>-0.073681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.834215</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  58 tGravityAcc-energy()-Y  \\\n",
       "0                   0.056483             -0.375426                  -0.970905   \n",
       "1                   0.102764             -0.383430                  -0.970583   \n",
       "2                   0.102764             -0.401602                  -0.970368   \n",
       "3                   0.095753             -0.400278                  -0.969400   \n",
       "4                   0.094059             -0.400477                  -0.967051   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.918375   \n",
       "7348               -0.068919             -0.358934                  -0.902880   \n",
       "7349               -0.068919             -0.377025                  -0.907561   \n",
       "7350               -0.040009             -0.440050                  -0.910648   \n",
       "7351               -0.047491             -0.432003                  -0.910579   \n",
       "\n",
       "      59 tGravityAcc-energy()-Z  128 tBodyGyro-mad()-Y  ...  \\\n",
       "0                     -0.975510              -0.976353  ...   \n",
       "1                     -0.978500              -0.989038  ...   \n",
       "2                     -0.981672              -0.994122  ...   \n",
       "3                     -0.982420              -0.993142  ...   \n",
       "4                     -0.984363              -0.992542  ...   \n",
       "...                         ...                    ...  ...   \n",
       "7347                  -0.995193               0.065142  ...   \n",
       "7348                  -0.995151               0.091791  ...   \n",
       "7349                  -0.995450               0.170686  ...   \n",
       "7350                  -0.998824               0.178939  ...   \n",
       "7351                  -0.998144              -0.073681  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      382 fBodyAccJerk-bandsEnergy()-1,8  504 fBodyAccMag-std()  \\\n",
       "0                              -0.999986              -0.956134   \n",
       "1                              -0.999996              -0.975866   \n",
       "2                              -0.999994              -0.989015   \n",
       "3                              -0.999998              -0.986742   \n",
       "4                              -0.999995              -0.990063   \n",
       "...                                  ...                    ...   \n",
       "7347                           -0.839256              -0.232600   \n",
       "7348                           -0.854278              -0.275373   \n",
       "7349                           -0.815380              -0.220288   \n",
       "7350                           -0.822905              -0.234539   \n",
       "7351                           -0.834215              -0.342670   \n",
       "\n",
       "      505 fBodyAccMag-mad()  509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                 -0.948870                 -0.998285         5        1  \n",
       "1                 -0.975777                 -0.999472         5        1  \n",
       "2                 -0.985594                 -0.999807         5        1  \n",
       "3                 -0.983524                 -0.999770         5        1  \n",
       "4                 -0.992324                 -0.999873         5        1  \n",
       "...                     ...                       ...       ...      ...  \n",
       "7347              -0.007392                 -0.584282         2       30  \n",
       "7348              -0.172448                 -0.632536         2       30  \n",
       "7349              -0.216074                 -0.641170         2       30  \n",
       "7350              -0.220443                 -0.663579         2       30  \n",
       "7351              -0.146649                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.4814471006393433, Final Batch Loss: 1.1777361631393433\n",
      "Epoch 2, Loss: 3.472521185874939, Final Batch Loss: 1.184507966041565\n",
      "Epoch 3, Loss: 3.4592950344085693, Final Batch Loss: 1.1837799549102783\n",
      "Epoch 4, Loss: 3.4006080627441406, Final Batch Loss: 1.1252830028533936\n",
      "Epoch 5, Loss: 3.4011149406433105, Final Batch Loss: 1.138095736503601\n",
      "Epoch 6, Loss: 3.3646942377090454, Final Batch Loss: 1.1092960834503174\n",
      "Epoch 7, Loss: 3.3321115970611572, Final Batch Loss: 1.08525812625885\n",
      "Epoch 8, Loss: 3.340017318725586, Final Batch Loss: 1.1138802766799927\n",
      "Epoch 9, Loss: 3.3290618658065796, Final Batch Loss: 1.121427297592163\n",
      "Epoch 10, Loss: 3.2716625928878784, Final Batch Loss: 1.0692479610443115\n",
      "Epoch 11, Loss: 3.2728869915008545, Final Batch Loss: 1.1004146337509155\n",
      "Epoch 12, Loss: 3.2577006816864014, Final Batch Loss: 1.1047099828720093\n",
      "Epoch 13, Loss: 3.159664034843445, Final Batch Loss: 1.0257675647735596\n",
      "Epoch 14, Loss: 3.14940083026886, Final Batch Loss: 1.0592069625854492\n",
      "Epoch 15, Loss: 3.08016836643219, Final Batch Loss: 1.035446286201477\n",
      "Epoch 16, Loss: 3.0123572945594788, Final Batch Loss: 1.0107673406600952\n",
      "Epoch 17, Loss: 2.9148404598236084, Final Batch Loss: 0.9416658282279968\n",
      "Epoch 18, Loss: 2.8159478902816772, Final Batch Loss: 0.9167541265487671\n",
      "Epoch 19, Loss: 2.7270748615264893, Final Batch Loss: 0.8969441056251526\n",
      "Epoch 20, Loss: 2.572556436061859, Final Batch Loss: 0.803320050239563\n",
      "Epoch 21, Loss: 2.503387987613678, Final Batch Loss: 0.7925862073898315\n",
      "Epoch 22, Loss: 2.4316272735595703, Final Batch Loss: 0.8183906674385071\n",
      "Epoch 23, Loss: 2.3025590777397156, Final Batch Loss: 0.7512024641036987\n",
      "Epoch 24, Loss: 2.210504651069641, Final Batch Loss: 0.7430475354194641\n",
      "Epoch 25, Loss: 2.137378215789795, Final Batch Loss: 0.7608767747879028\n",
      "Epoch 26, Loss: 2.03300279378891, Final Batch Loss: 0.7586269974708557\n",
      "Epoch 27, Loss: 1.8156103491783142, Final Batch Loss: 0.5850899815559387\n",
      "Epoch 28, Loss: 1.704464077949524, Final Batch Loss: 0.5554156303405762\n",
      "Epoch 29, Loss: 1.4864295423030853, Final Batch Loss: 0.441831111907959\n",
      "Epoch 30, Loss: 1.4660136699676514, Final Batch Loss: 0.5052574872970581\n",
      "Epoch 31, Loss: 1.313861072063446, Final Batch Loss: 0.44052016735076904\n",
      "Epoch 32, Loss: 1.2328241169452667, Final Batch Loss: 0.3954310417175293\n",
      "Epoch 33, Loss: 1.0980857908725739, Final Batch Loss: 0.30077388882637024\n",
      "Epoch 34, Loss: 0.9270559549331665, Final Batch Loss: 0.26922038197517395\n",
      "Epoch 35, Loss: 0.9458605349063873, Final Batch Loss: 0.3475768566131592\n",
      "Epoch 36, Loss: 0.7936743795871735, Final Batch Loss: 0.2539622485637665\n",
      "Epoch 37, Loss: 0.7777884304523468, Final Batch Loss: 0.2264527827501297\n",
      "Epoch 38, Loss: 0.7296186536550522, Final Batch Loss: 0.21789103746414185\n",
      "Epoch 39, Loss: 0.6084504574537277, Final Batch Loss: 0.2380492240190506\n",
      "Epoch 40, Loss: 0.6503192782402039, Final Batch Loss: 0.17996683716773987\n",
      "Epoch 41, Loss: 0.5389936119318008, Final Batch Loss: 0.1321248859167099\n",
      "Epoch 42, Loss: 0.5583086609840393, Final Batch Loss: 0.17927522957324982\n",
      "Epoch 43, Loss: 0.43964991718530655, Final Batch Loss: 0.11681153625249863\n",
      "Epoch 44, Loss: 0.42347169667482376, Final Batch Loss: 0.06513761729001999\n",
      "Epoch 45, Loss: 0.49789556860923767, Final Batch Loss: 0.1508452147245407\n",
      "Epoch 46, Loss: 0.5780666917562485, Final Batch Loss: 0.24075743556022644\n",
      "Epoch 47, Loss: 0.5394886136054993, Final Batch Loss: 0.18312086164951324\n",
      "Epoch 48, Loss: 0.45388586819171906, Final Batch Loss: 0.10109315812587738\n",
      "Epoch 49, Loss: 0.42297618836164474, Final Batch Loss: 0.11733903735876083\n",
      "Epoch 50, Loss: 0.45984092354774475, Final Batch Loss: 0.13185428082942963\n",
      "Epoch 51, Loss: 0.4050845801830292, Final Batch Loss: 0.10121521353721619\n",
      "Epoch 52, Loss: 0.4543789103627205, Final Batch Loss: 0.19102983176708221\n",
      "Epoch 53, Loss: 0.48808205127716064, Final Batch Loss: 0.2486051619052887\n",
      "Epoch 54, Loss: 0.445317342877388, Final Batch Loss: 0.1648922711610794\n",
      "Epoch 55, Loss: 0.3458881750702858, Final Batch Loss: 0.07611900568008423\n",
      "Epoch 56, Loss: 0.4139136001467705, Final Batch Loss: 0.12433139234781265\n",
      "Epoch 57, Loss: 0.39649660885334015, Final Batch Loss: 0.10810931771993637\n",
      "Epoch 58, Loss: 0.36271171271800995, Final Batch Loss: 0.09263963997364044\n",
      "Epoch 59, Loss: 0.2578412741422653, Final Batch Loss: 0.06508747488260269\n",
      "Epoch 60, Loss: 0.3531067743897438, Final Batch Loss: 0.1098039373755455\n",
      "Epoch 61, Loss: 0.3178301192820072, Final Batch Loss: 0.05104940012097359\n",
      "Epoch 62, Loss: 0.355258584022522, Final Batch Loss: 0.07065872102975845\n",
      "Epoch 63, Loss: 0.32692088186740875, Final Batch Loss: 0.06292050331830978\n",
      "Epoch 64, Loss: 0.31989289075136185, Final Batch Loss: 0.08785233646631241\n",
      "Epoch 65, Loss: 0.3561769351363182, Final Batch Loss: 0.09916955232620239\n",
      "Epoch 66, Loss: 0.35927557945251465, Final Batch Loss: 0.12420068681240082\n",
      "Epoch 67, Loss: 0.3771447539329529, Final Batch Loss: 0.16034096479415894\n",
      "Epoch 68, Loss: 0.3079848363995552, Final Batch Loss: 0.07616212218999863\n",
      "Epoch 69, Loss: 0.30952785909175873, Final Batch Loss: 0.08124391734600067\n",
      "Epoch 70, Loss: 0.4881707802414894, Final Batch Loss: 0.2914895713329315\n",
      "Epoch 71, Loss: 0.26427317410707474, Final Batch Loss: 0.075271375477314\n",
      "Epoch 72, Loss: 0.26177162304520607, Final Batch Loss: 0.05844710394740105\n",
      "Epoch 73, Loss: 0.3725323975086212, Final Batch Loss: 0.14699538052082062\n",
      "Epoch 74, Loss: 0.2932826057076454, Final Batch Loss: 0.09033229947090149\n",
      "Epoch 75, Loss: 0.3271755501627922, Final Batch Loss: 0.12439941614866257\n",
      "Epoch 76, Loss: 0.28738006949424744, Final Batch Loss: 0.06972714513540268\n",
      "Epoch 77, Loss: 0.3430658355355263, Final Batch Loss: 0.13203373551368713\n",
      "Epoch 78, Loss: 0.38752473145723343, Final Batch Loss: 0.19387060403823853\n",
      "Epoch 79, Loss: 0.266090452671051, Final Batch Loss: 0.06728693842887878\n",
      "Epoch 80, Loss: 0.37875089049339294, Final Batch Loss: 0.17051878571510315\n",
      "Epoch 81, Loss: 0.3579566329717636, Final Batch Loss: 0.15761317312717438\n",
      "Epoch 82, Loss: 0.2787625193595886, Final Batch Loss: 0.10983820259571075\n",
      "Epoch 83, Loss: 0.31258707493543625, Final Batch Loss: 0.1346561461687088\n",
      "Epoch 84, Loss: 0.3104580342769623, Final Batch Loss: 0.1070023775100708\n",
      "Epoch 85, Loss: 0.23009667173027992, Final Batch Loss: 0.03464541956782341\n",
      "Epoch 86, Loss: 0.3338898494839668, Final Batch Loss: 0.13277260959148407\n",
      "Epoch 87, Loss: 0.2818800136446953, Final Batch Loss: 0.0784420520067215\n",
      "Epoch 88, Loss: 0.2915702685713768, Final Batch Loss: 0.10599227994680405\n",
      "Epoch 89, Loss: 0.27222931385040283, Final Batch Loss: 0.0619218647480011\n",
      "Epoch 90, Loss: 0.29920272529125214, Final Batch Loss: 0.1283167153596878\n",
      "Epoch 91, Loss: 0.26067738980054855, Final Batch Loss: 0.06463702023029327\n",
      "Epoch 92, Loss: 0.22307058796286583, Final Batch Loss: 0.050134193152189255\n",
      "Epoch 93, Loss: 0.29867710918188095, Final Batch Loss: 0.0785658210515976\n",
      "Epoch 94, Loss: 0.37702830135822296, Final Batch Loss: 0.16231831908226013\n",
      "Epoch 95, Loss: 0.2579403296113014, Final Batch Loss: 0.04994514584541321\n",
      "Epoch 96, Loss: 0.2889895662665367, Final Batch Loss: 0.166107639670372\n",
      "Epoch 97, Loss: 0.2496567741036415, Final Batch Loss: 0.049334123730659485\n",
      "Epoch 98, Loss: 0.19291841611266136, Final Batch Loss: 0.04798497259616852\n",
      "Epoch 99, Loss: 0.22554898634552956, Final Batch Loss: 0.05127466842532158\n",
      "Epoch 100, Loss: 0.20816078409552574, Final Batch Loss: 0.033780697733163834\n",
      "Epoch 101, Loss: 0.31741898506879807, Final Batch Loss: 0.11200923472642899\n",
      "Epoch 102, Loss: 0.2370600812137127, Final Batch Loss: 0.04863883927464485\n",
      "Epoch 103, Loss: 0.24551307410001755, Final Batch Loss: 0.08174827694892883\n",
      "Epoch 104, Loss: 0.33053673803806305, Final Batch Loss: 0.15598039329051971\n",
      "Epoch 105, Loss: 0.24049735814332962, Final Batch Loss: 0.09279688447713852\n",
      "Epoch 106, Loss: 0.32855433970689774, Final Batch Loss: 0.17664600908756256\n",
      "Epoch 107, Loss: 0.2217044234275818, Final Batch Loss: 0.06220778822898865\n",
      "Epoch 108, Loss: 0.2342507466673851, Final Batch Loss: 0.10506334155797958\n",
      "Epoch 109, Loss: 0.3403206914663315, Final Batch Loss: 0.1855258196592331\n",
      "Epoch 110, Loss: 0.21658264845609665, Final Batch Loss: 0.033925533294677734\n",
      "Epoch 111, Loss: 0.22336630150675774, Final Batch Loss: 0.03731211647391319\n",
      "Epoch 112, Loss: 0.17920316010713577, Final Batch Loss: 0.03886398673057556\n",
      "Epoch 113, Loss: 0.1896374113857746, Final Batch Loss: 0.03393280878663063\n",
      "Epoch 114, Loss: 0.3212331272661686, Final Batch Loss: 0.16068725287914276\n",
      "Epoch 115, Loss: 0.2298448532819748, Final Batch Loss: 0.08944123983383179\n",
      "Epoch 116, Loss: 0.2652111053466797, Final Batch Loss: 0.07248426228761673\n",
      "Epoch 117, Loss: 0.23570307344198227, Final Batch Loss: 0.09790406376123428\n",
      "Epoch 118, Loss: 0.18280230835080147, Final Batch Loss: 0.05307161062955856\n",
      "Epoch 119, Loss: 0.20317132398486137, Final Batch Loss: 0.0350060798227787\n",
      "Epoch 120, Loss: 0.2099153697490692, Final Batch Loss: 0.06662360578775406\n",
      "Epoch 121, Loss: 0.2234891690313816, Final Batch Loss: 0.06292138993740082\n",
      "Epoch 122, Loss: 0.22523405030369759, Final Batch Loss: 0.03768991306424141\n",
      "Epoch 123, Loss: 0.17000044509768486, Final Batch Loss: 0.03749783709645271\n",
      "Epoch 124, Loss: 0.17506692558526993, Final Batch Loss: 0.05709245800971985\n",
      "Epoch 125, Loss: 0.18322255834937096, Final Batch Loss: 0.04719378799200058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126, Loss: 0.2462015077471733, Final Batch Loss: 0.0879911407828331\n",
      "Epoch 127, Loss: 0.2564992383122444, Final Batch Loss: 0.11644817143678665\n",
      "Epoch 128, Loss: 0.18170084431767464, Final Batch Loss: 0.05923212319612503\n",
      "Epoch 129, Loss: 0.2078096643090248, Final Batch Loss: 0.04885488748550415\n",
      "Epoch 130, Loss: 0.19459549337625504, Final Batch Loss: 0.03895267844200134\n",
      "Epoch 131, Loss: 0.2209814190864563, Final Batch Loss: 0.09960527718067169\n",
      "Epoch 132, Loss: 0.1845463514328003, Final Batch Loss: 0.039505552500486374\n",
      "Epoch 133, Loss: 0.13268250972032547, Final Batch Loss: 0.00862947478890419\n",
      "Epoch 134, Loss: 0.21389389783143997, Final Batch Loss: 0.08293462544679642\n",
      "Epoch 135, Loss: 0.19913628697395325, Final Batch Loss: 0.02026320993900299\n",
      "Epoch 136, Loss: 0.2137036845088005, Final Batch Loss: 0.06344785541296005\n",
      "Epoch 137, Loss: 0.1838129200041294, Final Batch Loss: 0.03179159015417099\n",
      "Epoch 138, Loss: 0.21746187657117844, Final Batch Loss: 0.05023981258273125\n",
      "Epoch 139, Loss: 0.16376058012247086, Final Batch Loss: 0.0647909939289093\n",
      "Epoch 140, Loss: 0.22859201580286026, Final Batch Loss: 0.09854847937822342\n",
      "Epoch 141, Loss: 0.2030821181833744, Final Batch Loss: 0.06543295830488205\n",
      "Epoch 142, Loss: 0.24782558158040047, Final Batch Loss: 0.15257959067821503\n",
      "Epoch 143, Loss: 0.244402214884758, Final Batch Loss: 0.11639707535505295\n",
      "Epoch 144, Loss: 0.1525211613625288, Final Batch Loss: 0.026647521182894707\n",
      "Epoch 145, Loss: 0.13828332722187042, Final Batch Loss: 0.01460057869553566\n",
      "Epoch 146, Loss: 0.21272439509630203, Final Batch Loss: 0.048961132764816284\n",
      "Epoch 147, Loss: 0.29165516048669815, Final Batch Loss: 0.15329784154891968\n",
      "Epoch 148, Loss: 0.18002981320023537, Final Batch Loss: 0.09531981498003006\n",
      "Epoch 149, Loss: 0.1721399463713169, Final Batch Loss: 0.04104173555970192\n",
      "Epoch 150, Loss: 0.15018361806869507, Final Batch Loss: 0.03243540972471237\n",
      "Epoch 151, Loss: 0.15460962429642677, Final Batch Loss: 0.014924146234989166\n",
      "Epoch 152, Loss: 0.2051217518746853, Final Batch Loss: 0.045790109783411026\n",
      "Epoch 153, Loss: 0.18696410581469536, Final Batch Loss: 0.04304094985127449\n",
      "Epoch 154, Loss: 0.20979107916355133, Final Batch Loss: 0.08064478635787964\n",
      "Epoch 155, Loss: 0.222551878541708, Final Batch Loss: 0.0761909931898117\n",
      "Epoch 156, Loss: 0.13646582700312138, Final Batch Loss: 0.024533187970519066\n",
      "Epoch 157, Loss: 0.11142209358513355, Final Batch Loss: 0.008573697879910469\n",
      "Epoch 158, Loss: 0.1565938126295805, Final Batch Loss: 0.029083212837576866\n",
      "Epoch 159, Loss: 0.2140454202890396, Final Batch Loss: 0.05815931409597397\n",
      "Epoch 160, Loss: 0.1906241774559021, Final Batch Loss: 0.06225579231977463\n",
      "Epoch 161, Loss: 0.16479836031794548, Final Batch Loss: 0.04412439838051796\n",
      "Epoch 162, Loss: 0.13860568962991238, Final Batch Loss: 0.016026919707655907\n",
      "Epoch 163, Loss: 0.29632459953427315, Final Batch Loss: 0.19073055684566498\n",
      "Epoch 164, Loss: 0.2532617077231407, Final Batch Loss: 0.1574024111032486\n",
      "Epoch 165, Loss: 0.2231905721127987, Final Batch Loss: 0.06700123101472855\n",
      "Epoch 166, Loss: 0.16992440819740295, Final Batch Loss: 0.02063310146331787\n",
      "Epoch 167, Loss: 0.1858723722398281, Final Batch Loss: 0.05731480196118355\n",
      "Epoch 168, Loss: 0.14876144379377365, Final Batch Loss: 0.03284183144569397\n",
      "Epoch 169, Loss: 0.3155519999563694, Final Batch Loss: 0.16520275175571442\n",
      "Epoch 170, Loss: 0.2205557730048895, Final Batch Loss: 0.1568858027458191\n",
      "Epoch 171, Loss: 0.11151361092925072, Final Batch Loss: 0.003739655017852783\n",
      "Epoch 172, Loss: 0.1619919938966632, Final Batch Loss: 0.013192425481975079\n",
      "Epoch 173, Loss: 0.26042597368359566, Final Batch Loss: 0.11632540076971054\n",
      "Epoch 174, Loss: 0.15624812245368958, Final Batch Loss: 0.03373164311051369\n",
      "Epoch 175, Loss: 0.11925076972693205, Final Batch Loss: 0.015230691991746426\n",
      "Epoch 176, Loss: 0.12343032099306583, Final Batch Loss: 0.031047433614730835\n",
      "Epoch 177, Loss: 0.17121328227221966, Final Batch Loss: 0.06680841743946075\n",
      "Epoch 178, Loss: 0.1632448211312294, Final Batch Loss: 0.03443185240030289\n",
      "Epoch 179, Loss: 0.20217270031571388, Final Batch Loss: 0.08029640465974808\n",
      "Epoch 180, Loss: 0.15884528309106827, Final Batch Loss: 0.030297014862298965\n",
      "Epoch 181, Loss: 0.20915111526846886, Final Batch Loss: 0.10404480993747711\n",
      "Epoch 182, Loss: 0.24597249180078506, Final Batch Loss: 0.1398594081401825\n",
      "Epoch 183, Loss: 0.23261535912752151, Final Batch Loss: 0.11984317749738693\n",
      "Epoch 184, Loss: 0.19598547369241714, Final Batch Loss: 0.03518925607204437\n",
      "Epoch 185, Loss: 0.23228175938129425, Final Batch Loss: 0.13535527884960175\n",
      "Epoch 186, Loss: 0.17766815796494484, Final Batch Loss: 0.04571139067411423\n",
      "Epoch 187, Loss: 0.14536673529073596, Final Batch Loss: 0.005735039245337248\n",
      "Epoch 188, Loss: 0.14237675443291664, Final Batch Loss: 0.032091233879327774\n",
      "Epoch 189, Loss: 0.24483156204223633, Final Batch Loss: 0.12383435666561127\n",
      "Epoch 190, Loss: 0.12686322070658207, Final Batch Loss: 0.013590840622782707\n",
      "Epoch 191, Loss: 0.1749703325331211, Final Batch Loss: 0.04110299050807953\n",
      "Epoch 192, Loss: 0.20597874745726585, Final Batch Loss: 0.10229290276765823\n",
      "Epoch 193, Loss: 0.3147246241569519, Final Batch Loss: 0.19614474475383759\n",
      "Epoch 194, Loss: 0.1506408341228962, Final Batch Loss: 0.026510771363973618\n",
      "Epoch 195, Loss: 0.15548636484891176, Final Batch Loss: 0.01249216590076685\n",
      "Epoch 196, Loss: 0.14656106010079384, Final Batch Loss: 0.01221945509314537\n",
      "Epoch 197, Loss: 0.167439267039299, Final Batch Loss: 0.03494727984070778\n",
      "Epoch 198, Loss: 0.16641519218683243, Final Batch Loss: 0.032003745436668396\n",
      "Epoch 199, Loss: 0.14965347945690155, Final Batch Loss: 0.0792696550488472\n",
      "Epoch 200, Loss: 0.2492382489144802, Final Batch Loss: 0.13610155880451202\n",
      "Epoch 201, Loss: 0.14885127311572433, Final Batch Loss: 0.005733040627092123\n",
      "Epoch 202, Loss: 0.14966417849063873, Final Batch Loss: 0.02194417640566826\n",
      "Epoch 203, Loss: 0.11550621967762709, Final Batch Loss: 0.014035346917808056\n",
      "Epoch 204, Loss: 0.13681639730930328, Final Batch Loss: 0.024617407470941544\n",
      "Epoch 205, Loss: 0.2422584854066372, Final Batch Loss: 0.13715551793575287\n",
      "Epoch 206, Loss: 0.16280208341777325, Final Batch Loss: 0.027868742123246193\n",
      "Epoch 207, Loss: 0.09448855184018612, Final Batch Loss: 0.03281443566083908\n",
      "Epoch 208, Loss: 0.1504492275416851, Final Batch Loss: 0.0574495792388916\n",
      "Epoch 209, Loss: 0.13641271740198135, Final Batch Loss: 0.045936472713947296\n",
      "Epoch 210, Loss: 0.12120888195931911, Final Batch Loss: 0.019593825563788414\n",
      "Epoch 211, Loss: 0.12113779410719872, Final Batch Loss: 0.028652630746364594\n",
      "Epoch 212, Loss: 0.150411918759346, Final Batch Loss: 0.037054289132356644\n",
      "Epoch 213, Loss: 0.1663319319486618, Final Batch Loss: 0.03839639574289322\n",
      "Epoch 214, Loss: 0.15757129527628422, Final Batch Loss: 0.0725783109664917\n",
      "Epoch 215, Loss: 0.15509356185793877, Final Batch Loss: 0.01742761954665184\n",
      "Epoch 216, Loss: 0.11348466947674751, Final Batch Loss: 0.029443472623825073\n",
      "Epoch 217, Loss: 0.15324949845671654, Final Batch Loss: 0.07008510828018188\n",
      "Epoch 218, Loss: 0.18014364317059517, Final Batch Loss: 0.07789505273103714\n",
      "Epoch 219, Loss: 0.08116712979972363, Final Batch Loss: 0.016140976920723915\n",
      "Epoch 220, Loss: 0.18702852725982666, Final Batch Loss: 0.07632196694612503\n",
      "Epoch 221, Loss: 0.10834216792136431, Final Batch Loss: 0.007975966669619083\n",
      "Epoch 222, Loss: 0.13092570379376411, Final Batch Loss: 0.023569509387016296\n",
      "Epoch 223, Loss: 0.14441895484924316, Final Batch Loss: 0.04660756513476372\n",
      "Epoch 224, Loss: 0.11971580609679222, Final Batch Loss: 0.01654789224267006\n",
      "Epoch 225, Loss: 0.141294302418828, Final Batch Loss: 0.024655526503920555\n",
      "Epoch 226, Loss: 0.10135181434452534, Final Batch Loss: 0.012376083061099052\n",
      "Epoch 227, Loss: 0.11053157225251198, Final Batch Loss: 0.03591235354542732\n",
      "Epoch 228, Loss: 0.11075119581073523, Final Batch Loss: 0.010070218704640865\n",
      "Epoch 229, Loss: 0.18840492516756058, Final Batch Loss: 0.09740953147411346\n",
      "Epoch 230, Loss: 0.09845246002078056, Final Batch Loss: 0.01627587154507637\n",
      "Epoch 231, Loss: 0.13337084092199802, Final Batch Loss: 0.06406053155660629\n",
      "Epoch 232, Loss: 0.1368998885154724, Final Batch Loss: 0.02608998864889145\n",
      "Epoch 233, Loss: 0.13339472189545631, Final Batch Loss: 0.04050386697053909\n",
      "Epoch 234, Loss: 0.14764566719532013, Final Batch Loss: 0.04253823682665825\n",
      "Epoch 235, Loss: 0.11678045149892569, Final Batch Loss: 0.014234970323741436\n",
      "Epoch 236, Loss: 0.1756323203444481, Final Batch Loss: 0.07219201326370239\n",
      "Epoch 237, Loss: 0.2388130947947502, Final Batch Loss: 0.1602267026901245\n",
      "Epoch 238, Loss: 0.0971994660794735, Final Batch Loss: 0.03728405758738518\n",
      "Epoch 239, Loss: 0.11716821044683456, Final Batch Loss: 0.02355252578854561\n",
      "Epoch 240, Loss: 0.16506756469607353, Final Batch Loss: 0.06329911202192307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241, Loss: 0.13304214365780354, Final Batch Loss: 0.0211318451911211\n",
      "Epoch 242, Loss: 0.10164246475324035, Final Batch Loss: 0.004845344927161932\n",
      "Epoch 243, Loss: 0.15451393648982048, Final Batch Loss: 0.06173365190625191\n",
      "Epoch 244, Loss: 0.08714896347373724, Final Batch Loss: 0.011792954988777637\n",
      "Epoch 245, Loss: 0.13777418434619904, Final Batch Loss: 0.0545109286904335\n",
      "Epoch 246, Loss: 0.17091432213783264, Final Batch Loss: 0.08114676177501678\n",
      "Epoch 247, Loss: 0.15995559841394424, Final Batch Loss: 0.05241568386554718\n",
      "Epoch 248, Loss: 0.09406059328466654, Final Batch Loss: 0.011067316867411137\n",
      "Epoch 249, Loss: 0.18932900577783585, Final Batch Loss: 0.06673019379377365\n",
      "Epoch 250, Loss: 0.11441925074905157, Final Batch Loss: 0.014838672243058681\n",
      "Epoch 251, Loss: 0.16560954600572586, Final Batch Loss: 0.10286173224449158\n",
      "Epoch 252, Loss: 0.10909834783524275, Final Batch Loss: 0.009300812147557735\n",
      "Epoch 253, Loss: 0.1459927298128605, Final Batch Loss: 0.0787452980875969\n",
      "Epoch 254, Loss: 0.12269427999854088, Final Batch Loss: 0.042438097298145294\n",
      "Epoch 255, Loss: 0.15319612249732018, Final Batch Loss: 0.041474781930446625\n",
      "Epoch 256, Loss: 0.11801398918032646, Final Batch Loss: 0.03278994560241699\n",
      "Epoch 257, Loss: 0.1307801976799965, Final Batch Loss: 0.05504253879189491\n",
      "Epoch 258, Loss: 0.15936542302370071, Final Batch Loss: 0.08756189793348312\n",
      "Epoch 259, Loss: 0.15609099715948105, Final Batch Loss: 0.025554213672876358\n",
      "Epoch 260, Loss: 0.11806473322212696, Final Batch Loss: 0.019912483170628548\n",
      "Epoch 261, Loss: 0.09982344880700111, Final Batch Loss: 0.007612269371747971\n",
      "Epoch 262, Loss: 0.09542108792811632, Final Batch Loss: 0.012176123447716236\n",
      "Epoch 263, Loss: 0.09538846090435982, Final Batch Loss: 0.014727955684065819\n",
      "Epoch 264, Loss: 0.11272785812616348, Final Batch Loss: 0.01750117912888527\n",
      "Epoch 265, Loss: 0.1323412023484707, Final Batch Loss: 0.043434541672468185\n",
      "Epoch 266, Loss: 0.0857287086546421, Final Batch Loss: 0.02982308529317379\n",
      "Epoch 267, Loss: 0.10514296405017376, Final Batch Loss: 0.01295853964984417\n",
      "Epoch 268, Loss: 0.1091572092846036, Final Batch Loss: 0.009289492852985859\n",
      "Epoch 269, Loss: 0.12228335812687874, Final Batch Loss: 0.0557112991809845\n",
      "Epoch 270, Loss: 0.12582050636410713, Final Batch Loss: 0.04404347389936447\n",
      "Epoch 271, Loss: 0.10814989823848009, Final Batch Loss: 0.008575045503675938\n",
      "Epoch 272, Loss: 0.13673325814306736, Final Batch Loss: 0.027228886261582375\n",
      "Epoch 273, Loss: 0.11539927870035172, Final Batch Loss: 0.06997213512659073\n",
      "Epoch 274, Loss: 0.09865162521600723, Final Batch Loss: 0.016385827213525772\n",
      "Epoch 275, Loss: 0.07898731948807836, Final Batch Loss: 0.0067305550910532475\n",
      "Epoch 276, Loss: 0.10234958119690418, Final Batch Loss: 0.028178857639431953\n",
      "Epoch 277, Loss: 0.222573634237051, Final Batch Loss: 0.11877530068159103\n",
      "Epoch 278, Loss: 0.0967890708707273, Final Batch Loss: 0.005405066069215536\n",
      "Epoch 279, Loss: 0.10671799955889583, Final Batch Loss: 0.007272220682352781\n",
      "Epoch 280, Loss: 0.12516304664313793, Final Batch Loss: 0.015673043206334114\n",
      "Epoch 281, Loss: 0.09429747052490711, Final Batch Loss: 0.031042154878377914\n",
      "Epoch 282, Loss: 0.29869653657078743, Final Batch Loss: 0.2420780211687088\n",
      "Epoch 283, Loss: 0.095994692761451, Final Batch Loss: 0.005243231076747179\n",
      "Epoch 284, Loss: 0.1837588269263506, Final Batch Loss: 0.11812558025121689\n",
      "Epoch 285, Loss: 0.08722371980547905, Final Batch Loss: 0.021182114258408546\n",
      "Epoch 286, Loss: 0.12916219234466553, Final Batch Loss: 0.0443853922188282\n",
      "Epoch 287, Loss: 0.083722785115242, Final Batch Loss: 0.0081232450902462\n",
      "Epoch 288, Loss: 0.09632173925638199, Final Batch Loss: 0.012749671936035156\n",
      "Epoch 289, Loss: 0.12735941633582115, Final Batch Loss: 0.050448790192604065\n",
      "Epoch 290, Loss: 0.1151198260486126, Final Batch Loss: 0.03813549876213074\n",
      "Epoch 291, Loss: 0.1965724490582943, Final Batch Loss: 0.13308237493038177\n",
      "Epoch 292, Loss: 0.1749943010509014, Final Batch Loss: 0.09885572642087936\n",
      "Epoch 293, Loss: 0.10121411830186844, Final Batch Loss: 0.03140372037887573\n",
      "Epoch 294, Loss: 0.09209819603711367, Final Batch Loss: 0.007875305600464344\n",
      "Epoch 295, Loss: 0.09481588192284107, Final Batch Loss: 0.0181474220007658\n",
      "Epoch 296, Loss: 0.11544762272387743, Final Batch Loss: 0.013864082284271717\n",
      "Epoch 297, Loss: 0.16744251362979412, Final Batch Loss: 0.07669738680124283\n",
      "Epoch 298, Loss: 0.12264810875058174, Final Batch Loss: 0.03166942298412323\n",
      "Epoch 299, Loss: 0.07368094613775611, Final Batch Loss: 0.006670424249023199\n",
      "Epoch 300, Loss: 0.13640105910599232, Final Batch Loss: 0.08831804990768433\n",
      "Epoch 301, Loss: 0.09007881116122007, Final Batch Loss: 0.004944349639117718\n",
      "Epoch 302, Loss: 0.0645371088758111, Final Batch Loss: 0.010931489057838917\n",
      "Epoch 303, Loss: 0.08812562236562371, Final Batch Loss: 0.00436315918341279\n",
      "Epoch 304, Loss: 0.08714881632477045, Final Batch Loss: 0.004775849170982838\n",
      "Epoch 305, Loss: 0.09710205113515258, Final Batch Loss: 0.007406254764646292\n",
      "Epoch 306, Loss: 0.09294716455042362, Final Batch Loss: 0.01677592471241951\n",
      "Epoch 307, Loss: 0.06186973722651601, Final Batch Loss: 0.005716355983167887\n",
      "Epoch 308, Loss: 0.09290679171681404, Final Batch Loss: 0.014260634779930115\n",
      "Epoch 309, Loss: 0.1701747141778469, Final Batch Loss: 0.08568190783262253\n",
      "Epoch 310, Loss: 0.19366374053061008, Final Batch Loss: 0.12870445847511292\n",
      "Epoch 311, Loss: 0.0621324647217989, Final Batch Loss: 0.003156891092658043\n",
      "Epoch 312, Loss: 0.1282257391139865, Final Batch Loss: 0.013874570839107037\n",
      "Epoch 313, Loss: 0.15059952437877655, Final Batch Loss: 0.09676194936037064\n",
      "Epoch 314, Loss: 0.1058710515499115, Final Batch Loss: 0.017753932625055313\n",
      "Epoch 315, Loss: 0.14121340215206146, Final Batch Loss: 0.029005326330661774\n",
      "Epoch 316, Loss: 0.13649171963334084, Final Batch Loss: 0.06458049267530441\n",
      "Epoch 317, Loss: 0.09806944895535707, Final Batch Loss: 0.00687797088176012\n",
      "Epoch 318, Loss: 0.08007630240172148, Final Batch Loss: 0.009798736311495304\n",
      "Epoch 319, Loss: 0.08946130657568574, Final Batch Loss: 0.007295659277588129\n",
      "Epoch 320, Loss: 0.0879756547510624, Final Batch Loss: 0.01759544014930725\n",
      "Epoch 321, Loss: 0.08246110752224922, Final Batch Loss: 0.0064420029520988464\n",
      "Epoch 322, Loss: 0.10112727619707584, Final Batch Loss: 0.02561177872121334\n",
      "Epoch 323, Loss: 0.0856784526258707, Final Batch Loss: 0.017103737220168114\n",
      "Epoch 324, Loss: 0.10549002885818481, Final Batch Loss: 0.03169338405132294\n",
      "Epoch 325, Loss: 0.12157869525253773, Final Batch Loss: 0.07606400549411774\n",
      "Epoch 326, Loss: 0.08583031967282295, Final Batch Loss: 0.03713727369904518\n",
      "Epoch 327, Loss: 0.06176825985312462, Final Batch Loss: 0.00939314253628254\n",
      "Epoch 328, Loss: 0.09253772906959057, Final Batch Loss: 0.04635673761367798\n",
      "Epoch 329, Loss: 0.11973817646503448, Final Batch Loss: 0.05112641304731369\n",
      "Epoch 330, Loss: 0.08860272355377674, Final Batch Loss: 0.03105228766798973\n",
      "Epoch 331, Loss: 0.07718469481915236, Final Batch Loss: 0.012340917252004147\n",
      "Epoch 332, Loss: 0.08792117238044739, Final Batch Loss: 0.023563101887702942\n",
      "Epoch 333, Loss: 0.14026508666574955, Final Batch Loss: 0.0748235359787941\n",
      "Epoch 334, Loss: 0.14121243730187416, Final Batch Loss: 0.10257048904895782\n",
      "Epoch 335, Loss: 0.07567768357694149, Final Batch Loss: 0.04793893173336983\n",
      "Epoch 336, Loss: 0.09300282411277294, Final Batch Loss: 0.013713683933019638\n",
      "Epoch 337, Loss: 0.13169493153691292, Final Batch Loss: 0.04883383587002754\n",
      "Epoch 338, Loss: 0.07573671080172062, Final Batch Loss: 0.031960658729076385\n",
      "Epoch 339, Loss: 0.10727277398109436, Final Batch Loss: 0.05227525904774666\n",
      "Epoch 340, Loss: 0.09201282076537609, Final Batch Loss: 0.010186607018113136\n",
      "Epoch 341, Loss: 0.08436925522983074, Final Batch Loss: 0.0029193004593253136\n",
      "Epoch 342, Loss: 0.07010558806359768, Final Batch Loss: 0.026446789503097534\n",
      "Epoch 343, Loss: 0.08636700175702572, Final Batch Loss: 0.021471509709954262\n",
      "Epoch 344, Loss: 0.10211615078151226, Final Batch Loss: 0.05759919434785843\n",
      "Epoch 345, Loss: 0.11664820089936256, Final Batch Loss: 0.06701263040304184\n",
      "Epoch 346, Loss: 0.09720407985150814, Final Batch Loss: 0.05436573177576065\n",
      "Epoch 347, Loss: 0.08253882639110088, Final Batch Loss: 0.0179935060441494\n",
      "Epoch 348, Loss: 0.0895489752292633, Final Batch Loss: 0.02965143695473671\n",
      "Epoch 349, Loss: 0.045814442448318005, Final Batch Loss: 0.002102185972034931\n",
      "Epoch 350, Loss: 0.12352509424090385, Final Batch Loss: 0.022630244493484497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351, Loss: 0.14095104485750198, Final Batch Loss: 0.07609681785106659\n",
      "Epoch 352, Loss: 0.1503780521452427, Final Batch Loss: 0.09884055703878403\n",
      "Epoch 353, Loss: 0.06263836612924933, Final Batch Loss: 0.004322079475969076\n",
      "Epoch 354, Loss: 0.09294847398996353, Final Batch Loss: 0.0253647118806839\n",
      "Epoch 355, Loss: 0.04646920319646597, Final Batch Loss: 0.005221444182097912\n",
      "Epoch 356, Loss: 0.07653062045574188, Final Batch Loss: 0.012231936678290367\n",
      "Epoch 357, Loss: 0.08793478086590767, Final Batch Loss: 0.022923842072486877\n",
      "Epoch 358, Loss: 0.08887429907917976, Final Batch Loss: 0.030470959842205048\n",
      "Epoch 359, Loss: 0.07180103100836277, Final Batch Loss: 0.021458487957715988\n",
      "Epoch 360, Loss: 0.07738976832479239, Final Batch Loss: 0.013050866313278675\n",
      "Epoch 361, Loss: 0.0733901048079133, Final Batch Loss: 0.005294543690979481\n",
      "Epoch 362, Loss: 0.08933037891983986, Final Batch Loss: 0.06001516431570053\n",
      "Epoch 363, Loss: 0.05133946845307946, Final Batch Loss: 0.004818641114979982\n",
      "Epoch 364, Loss: 0.09138596057891846, Final Batch Loss: 0.01212533749639988\n",
      "Epoch 365, Loss: 0.08250654302537441, Final Batch Loss: 0.04620775580406189\n",
      "Epoch 366, Loss: 0.07766838651150465, Final Batch Loss: 0.015267917886376381\n",
      "Epoch 367, Loss: 0.08258207328617573, Final Batch Loss: 0.034254420548677444\n",
      "Epoch 368, Loss: 0.10860669426620007, Final Batch Loss: 0.06449751555919647\n",
      "Epoch 369, Loss: 0.04942082427442074, Final Batch Loss: 0.006290338933467865\n",
      "Epoch 370, Loss: 0.04482418205589056, Final Batch Loss: 0.007987454533576965\n",
      "Epoch 371, Loss: 0.08968465682119131, Final Batch Loss: 0.010649099014699459\n",
      "Epoch 372, Loss: 0.04825366346631199, Final Batch Loss: 0.0016694968799129128\n",
      "Epoch 373, Loss: 0.04312343709170818, Final Batch Loss: 0.011534150689840317\n",
      "Epoch 374, Loss: 0.06333454139530659, Final Batch Loss: 0.014514429494738579\n",
      "Epoch 375, Loss: 0.038552721263840795, Final Batch Loss: 0.0031347537878900766\n",
      "Epoch 376, Loss: 0.10933518083766103, Final Batch Loss: 0.06746180355548859\n",
      "Epoch 377, Loss: 0.09270667843520641, Final Batch Loss: 0.02087813802063465\n",
      "Epoch 378, Loss: 0.0478519294410944, Final Batch Loss: 0.006122976541519165\n",
      "Epoch 379, Loss: 0.09459705278277397, Final Batch Loss: 0.05870707333087921\n",
      "Epoch 380, Loss: 0.07033945713192225, Final Batch Loss: 0.013814851641654968\n",
      "Epoch 381, Loss: 0.0792951537296176, Final Batch Loss: 0.011666062287986279\n",
      "Epoch 382, Loss: 0.10091943293809891, Final Batch Loss: 0.042857397347688675\n",
      "Epoch 383, Loss: 0.07054705917835236, Final Batch Loss: 0.042086392641067505\n",
      "Epoch 384, Loss: 0.08265770459547639, Final Batch Loss: 0.006722571793943644\n",
      "Epoch 385, Loss: 0.04216663213446736, Final Batch Loss: 0.006710076238960028\n",
      "Epoch 386, Loss: 0.0915580652654171, Final Batch Loss: 0.027763236314058304\n",
      "Epoch 387, Loss: 0.047493512742221355, Final Batch Loss: 0.0038755396381020546\n",
      "Epoch 388, Loss: 0.08195094857364893, Final Batch Loss: 0.03040355071425438\n",
      "Epoch 389, Loss: 0.07418920565396547, Final Batch Loss: 0.04142811894416809\n",
      "Epoch 390, Loss: 0.0525035634636879, Final Batch Loss: 0.005298536270856857\n",
      "Epoch 391, Loss: 0.0374632584862411, Final Batch Loss: 0.004128708969801664\n",
      "Epoch 392, Loss: 0.051666667219251394, Final Batch Loss: 0.006209248211234808\n",
      "Epoch 393, Loss: 0.04494743561372161, Final Batch Loss: 0.005400390829890966\n",
      "Epoch 394, Loss: 0.06574845872819424, Final Batch Loss: 0.014730338007211685\n",
      "Epoch 395, Loss: 0.029743270482867956, Final Batch Loss: 0.002309365663677454\n",
      "Epoch 396, Loss: 0.07511876430362463, Final Batch Loss: 0.014061045832931995\n",
      "Epoch 397, Loss: 0.035679751075804234, Final Batch Loss: 0.0031140651553869247\n",
      "Epoch 398, Loss: 0.060190339805558324, Final Batch Loss: 0.0038705982733517885\n",
      "Epoch 399, Loss: 0.12118697073310614, Final Batch Loss: 0.033991698175668716\n",
      "Epoch 400, Loss: 0.07348413486033678, Final Batch Loss: 0.0028780708089470863\n",
      "Epoch 401, Loss: 0.07349610980600119, Final Batch Loss: 0.03886028006672859\n",
      "Epoch 402, Loss: 0.08392096683382988, Final Batch Loss: 0.01901109702885151\n",
      "Epoch 403, Loss: 0.038819897221401334, Final Batch Loss: 0.01890709437429905\n",
      "Epoch 404, Loss: 0.06909293681383133, Final Batch Loss: 0.0160682313144207\n",
      "Epoch 405, Loss: 0.06341059599071741, Final Batch Loss: 0.011885146610438824\n",
      "Epoch 406, Loss: 0.08669011248275638, Final Batch Loss: 0.025979910045862198\n",
      "Epoch 407, Loss: 0.0515624163672328, Final Batch Loss: 0.021683314815163612\n",
      "Epoch 408, Loss: 0.14359110221266747, Final Batch Loss: 0.06339001655578613\n",
      "Epoch 409, Loss: 0.05976750981062651, Final Batch Loss: 0.008936460129916668\n",
      "Epoch 410, Loss: 0.07998289074748755, Final Batch Loss: 0.05584317445755005\n",
      "Epoch 411, Loss: 0.1089257849380374, Final Batch Loss: 0.06636357307434082\n",
      "Epoch 412, Loss: 0.0529560437425971, Final Batch Loss: 0.01342714298516512\n",
      "Epoch 413, Loss: 0.10822303220629692, Final Batch Loss: 0.055991820991039276\n",
      "Epoch 414, Loss: 0.04127246281132102, Final Batch Loss: 0.002411905210465193\n",
      "Epoch 415, Loss: 0.09122706390917301, Final Batch Loss: 0.009043475612998009\n",
      "Epoch 416, Loss: 0.061032929457724094, Final Batch Loss: 0.01334220077842474\n",
      "Epoch 417, Loss: 0.044646704103797674, Final Batch Loss: 0.005331326741725206\n",
      "Epoch 418, Loss: 0.06259878724813461, Final Batch Loss: 0.009778845123946667\n",
      "Epoch 419, Loss: 0.04618708183988929, Final Batch Loss: 0.005549354944378138\n",
      "Epoch 420, Loss: 0.025218606635462493, Final Batch Loss: 0.0007786943460814655\n",
      "Epoch 421, Loss: 0.09748189337551594, Final Batch Loss: 0.034703224897384644\n",
      "Epoch 422, Loss: 0.06802214356139302, Final Batch Loss: 0.004595900420099497\n",
      "Epoch 423, Loss: 0.05988601315766573, Final Batch Loss: 0.0040333447977900505\n",
      "Epoch 424, Loss: 0.02064251760020852, Final Batch Loss: 0.003907999489456415\n",
      "Epoch 425, Loss: 0.054400918539613485, Final Batch Loss: 0.03920798748731613\n",
      "Epoch 426, Loss: 0.04897873383015394, Final Batch Loss: 0.009057432413101196\n",
      "Epoch 427, Loss: 0.17306899093091488, Final Batch Loss: 0.13007667660713196\n",
      "Epoch 428, Loss: 0.07251672074198723, Final Batch Loss: 0.013437110930681229\n",
      "Epoch 429, Loss: 0.06725146668031812, Final Batch Loss: 0.006686140317469835\n",
      "Epoch 430, Loss: 0.1232951944693923, Final Batch Loss: 0.07183675467967987\n",
      "Epoch 431, Loss: 0.04512766795232892, Final Batch Loss: 0.007073899265378714\n",
      "Epoch 432, Loss: 0.10216616839170456, Final Batch Loss: 0.05481089651584625\n",
      "Epoch 433, Loss: 0.03548290999606252, Final Batch Loss: 0.005013506393879652\n",
      "Epoch 434, Loss: 0.05496937269344926, Final Batch Loss: 0.006156061310321093\n",
      "Epoch 435, Loss: 0.05040367040783167, Final Batch Loss: 0.008139722980558872\n",
      "Epoch 436, Loss: 0.05143981100991368, Final Batch Loss: 0.007455536164343357\n",
      "Epoch 437, Loss: 0.068310153670609, Final Batch Loss: 0.010505576618015766\n",
      "Epoch 438, Loss: 0.03562198765575886, Final Batch Loss: 0.005103178322315216\n",
      "Epoch 439, Loss: 0.03890655911527574, Final Batch Loss: 0.0032818808685988188\n",
      "Epoch 440, Loss: 0.025618636049330235, Final Batch Loss: 0.006195881403982639\n",
      "Epoch 441, Loss: 0.03630949975922704, Final Batch Loss: 0.0061422912403941154\n",
      "Epoch 442, Loss: 0.04926053434610367, Final Batch Loss: 0.013688771054148674\n",
      "Epoch 443, Loss: 0.06716050207614899, Final Batch Loss: 0.03203644976019859\n",
      "Epoch 444, Loss: 0.05447760969400406, Final Batch Loss: 0.005345992743968964\n",
      "Epoch 445, Loss: 0.02281412808224559, Final Batch Loss: 0.0033806972205638885\n",
      "Epoch 446, Loss: 0.05363806802779436, Final Batch Loss: 0.0024029980413615704\n",
      "Epoch 447, Loss: 0.052390712313354015, Final Batch Loss: 0.00598490983247757\n",
      "Epoch 448, Loss: 0.025443343445658684, Final Batch Loss: 0.005212499760091305\n",
      "Epoch 449, Loss: 0.09384457115083933, Final Batch Loss: 0.07448114454746246\n",
      "Epoch 450, Loss: 0.05986134381964803, Final Batch Loss: 0.0075835795141756535\n",
      "Epoch 451, Loss: 0.038166307378560305, Final Batch Loss: 0.004904238972812891\n",
      "Epoch 452, Loss: 0.01823930023238063, Final Batch Loss: 0.0035949372686445713\n",
      "Epoch 453, Loss: 0.032397602684795856, Final Batch Loss: 0.0038240840658545494\n",
      "Epoch 454, Loss: 0.047098598908632994, Final Batch Loss: 0.02228856086730957\n",
      "Epoch 455, Loss: 0.02352734748274088, Final Batch Loss: 0.0032335352152585983\n",
      "Epoch 456, Loss: 0.0264213178306818, Final Batch Loss: 0.004733089357614517\n",
      "Epoch 457, Loss: 0.023049562703818083, Final Batch Loss: 0.0021216562017798424\n",
      "Epoch 458, Loss: 0.03169074887409806, Final Batch Loss: 0.006308479700237513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459, Loss: 0.027551967650651932, Final Batch Loss: 0.009409154765307903\n",
      "Epoch 460, Loss: 0.04256077343598008, Final Batch Loss: 0.007323598023504019\n",
      "Epoch 461, Loss: 0.07691872538998723, Final Batch Loss: 0.053625065833330154\n",
      "Epoch 462, Loss: 0.03484201128594577, Final Batch Loss: 0.002098212717100978\n",
      "Epoch 463, Loss: 0.06894617155194283, Final Batch Loss: 0.007539382204413414\n",
      "Epoch 464, Loss: 0.05652805045247078, Final Batch Loss: 0.04227888211607933\n",
      "Epoch 465, Loss: 0.0660056381020695, Final Batch Loss: 0.0559479221701622\n",
      "Epoch 466, Loss: 0.07386921718716621, Final Batch Loss: 0.04064038768410683\n",
      "Epoch 467, Loss: 0.040823332499712706, Final Batch Loss: 0.008167999796569347\n",
      "Epoch 468, Loss: 0.1253538466989994, Final Batch Loss: 0.09576092660427094\n",
      "Epoch 469, Loss: 0.030847095884382725, Final Batch Loss: 0.003641103394329548\n",
      "Epoch 470, Loss: 0.042260438203811646, Final Batch Loss: 0.007642347365617752\n",
      "Epoch 471, Loss: 0.10707242414355278, Final Batch Loss: 0.04392661899328232\n",
      "Epoch 472, Loss: 0.034084408078342676, Final Batch Loss: 0.006807105150073767\n",
      "Epoch 473, Loss: 0.029797470895573497, Final Batch Loss: 0.0027581125032156706\n",
      "Epoch 474, Loss: 0.08110883319750428, Final Batch Loss: 0.0015853294171392918\n",
      "Epoch 475, Loss: 0.04859829135239124, Final Batch Loss: 0.02731344662606716\n",
      "Epoch 476, Loss: 0.03295294474810362, Final Batch Loss: 0.00904660951346159\n",
      "Epoch 477, Loss: 0.044611685210838914, Final Batch Loss: 0.0021398647222667933\n",
      "Epoch 478, Loss: 0.044299095403403044, Final Batch Loss: 0.003982087131589651\n",
      "Epoch 479, Loss: 0.0883420966565609, Final Batch Loss: 0.013413166627287865\n",
      "Epoch 480, Loss: 0.09463334875181317, Final Batch Loss: 0.05025428533554077\n",
      "Epoch 481, Loss: 0.02392261754721403, Final Batch Loss: 0.007904129102826118\n",
      "Epoch 482, Loss: 0.060641600750386715, Final Batch Loss: 0.014503058977425098\n",
      "Epoch 483, Loss: 0.03401748463511467, Final Batch Loss: 0.008931036107242107\n",
      "Epoch 484, Loss: 0.06011954229325056, Final Batch Loss: 0.006510513834655285\n",
      "Epoch 485, Loss: 0.043513418175280094, Final Batch Loss: 0.0012966161593794823\n",
      "Epoch 486, Loss: 0.03153553209267557, Final Batch Loss: 0.0017642085440456867\n",
      "Epoch 487, Loss: 0.03243674756959081, Final Batch Loss: 0.010197740979492664\n",
      "Epoch 488, Loss: 0.03797039994969964, Final Batch Loss: 0.003986672963947058\n",
      "Epoch 489, Loss: 0.05886941263452172, Final Batch Loss: 0.007558851037174463\n",
      "Epoch 490, Loss: 0.11217481829226017, Final Batch Loss: 0.05610807612538338\n",
      "Epoch 491, Loss: 0.029720029095187783, Final Batch Loss: 0.003212030278518796\n",
      "Epoch 492, Loss: 0.04407432163134217, Final Batch Loss: 0.004141590092331171\n",
      "Epoch 493, Loss: 0.0880398191511631, Final Batch Loss: 0.04460696503520012\n",
      "Epoch 494, Loss: 0.04067534487694502, Final Batch Loss: 0.00508097792044282\n",
      "Epoch 495, Loss: 0.0371726518496871, Final Batch Loss: 0.015520880930125713\n",
      "Epoch 496, Loss: 0.029745599254965782, Final Batch Loss: 0.010903272777795792\n",
      "Epoch 497, Loss: 0.03107538679614663, Final Batch Loss: 0.014174288138747215\n",
      "Epoch 498, Loss: 0.019897752907127142, Final Batch Loss: 0.0006740554235875607\n",
      "Epoch 499, Loss: 0.08073718007653952, Final Batch Loss: 0.04535222053527832\n",
      "Epoch 500, Loss: 0.026304231258109212, Final Batch Loss: 0.01041209977120161\n",
      "Epoch 501, Loss: 0.048407834488898516, Final Batch Loss: 0.006077601108700037\n",
      "Epoch 502, Loss: 0.05002349684946239, Final Batch Loss: 0.0038623432628810406\n",
      "Epoch 503, Loss: 0.020104597555473447, Final Batch Loss: 0.0036654865834861994\n",
      "Epoch 504, Loss: 0.03210988128557801, Final Batch Loss: 0.004174320492893457\n",
      "Epoch 505, Loss: 0.05922164267394692, Final Batch Loss: 0.001325771794654429\n",
      "Epoch 506, Loss: 0.02105484902858734, Final Batch Loss: 0.00537178386002779\n",
      "Epoch 507, Loss: 0.03190512675791979, Final Batch Loss: 0.0024476218968629837\n",
      "Epoch 508, Loss: 0.014830223750323057, Final Batch Loss: 0.0008496870286762714\n",
      "Epoch 509, Loss: 0.03351603704504669, Final Batch Loss: 0.002726559294387698\n",
      "Epoch 510, Loss: 0.018113634083420038, Final Batch Loss: 0.007478372659534216\n",
      "Epoch 511, Loss: 0.014455157448537648, Final Batch Loss: 0.0015881956787779927\n",
      "Epoch 512, Loss: 0.014101721229963005, Final Batch Loss: 0.0015011689392849803\n",
      "Epoch 513, Loss: 0.04518394637852907, Final Batch Loss: 0.00782769639045\n",
      "Epoch 514, Loss: 0.05326930433511734, Final Batch Loss: 0.03162507340312004\n",
      "Epoch 515, Loss: 0.018996973056346178, Final Batch Loss: 0.0030772495083510876\n",
      "Epoch 516, Loss: 0.032713519874960184, Final Batch Loss: 0.00611075246706605\n",
      "Epoch 517, Loss: 0.07852070312947035, Final Batch Loss: 0.05975620076060295\n",
      "Epoch 518, Loss: 0.08961283043026924, Final Batch Loss: 0.03373483195900917\n",
      "Epoch 519, Loss: 0.028427901212126017, Final Batch Loss: 0.009380956180393696\n",
      "Epoch 520, Loss: 0.08461276069283485, Final Batch Loss: 0.06988509744405746\n",
      "Epoch 521, Loss: 0.04876058432273567, Final Batch Loss: 0.002852672478184104\n",
      "Epoch 522, Loss: 0.04374555218964815, Final Batch Loss: 0.005103698931634426\n",
      "Epoch 523, Loss: 0.0592336431145668, Final Batch Loss: 0.0189194492995739\n",
      "Epoch 524, Loss: 0.02503066323697567, Final Batch Loss: 0.005611710716038942\n",
      "Epoch 525, Loss: 0.01712662191130221, Final Batch Loss: 0.003500123508274555\n",
      "Epoch 526, Loss: 0.053424733225256205, Final Batch Loss: 0.004091993439942598\n",
      "Epoch 527, Loss: 0.025550946593284607, Final Batch Loss: 0.0025010723620653152\n",
      "Epoch 528, Loss: 0.05063488055020571, Final Batch Loss: 0.020457591861486435\n",
      "Epoch 529, Loss: 0.03349690930917859, Final Batch Loss: 0.01350143738090992\n",
      "Epoch 530, Loss: 0.05276948306709528, Final Batch Loss: 0.020860010758042336\n",
      "Epoch 531, Loss: 0.027143381536006927, Final Batch Loss: 0.005106443073600531\n",
      "Epoch 532, Loss: 0.03575935121625662, Final Batch Loss: 0.003001207485795021\n",
      "Epoch 533, Loss: 0.03887360543012619, Final Batch Loss: 0.0069601163268089294\n",
      "Epoch 534, Loss: 0.033436811179853976, Final Batch Loss: 0.0011233572149649262\n",
      "Epoch 535, Loss: 0.03865725174546242, Final Batch Loss: 0.014641446992754936\n",
      "Epoch 536, Loss: 0.027357948012650013, Final Batch Loss: 0.0057417345233261585\n",
      "Epoch 537, Loss: 0.039046244230121374, Final Batch Loss: 0.016435546800494194\n",
      "Epoch 538, Loss: 0.03235001768916845, Final Batch Loss: 0.0038575483486056328\n",
      "Epoch 539, Loss: 0.03600630594883114, Final Batch Loss: 0.001456464291550219\n",
      "Epoch 540, Loss: 0.02989781997166574, Final Batch Loss: 0.0037717546802014112\n",
      "Epoch 541, Loss: 0.018479693215340376, Final Batch Loss: 0.008733493275940418\n",
      "Epoch 542, Loss: 0.014273825276177377, Final Batch Loss: 0.0006302568945102394\n",
      "Epoch 543, Loss: 0.045423814095556736, Final Batch Loss: 0.03206216171383858\n",
      "Epoch 544, Loss: 0.010246132151223719, Final Batch Loss: 0.0005697963060811162\n",
      "Epoch 545, Loss: 0.014996683748904616, Final Batch Loss: 0.0008420721278525889\n",
      "Epoch 546, Loss: 0.060250173322856426, Final Batch Loss: 0.020126711577177048\n",
      "Epoch 547, Loss: 0.05991608276963234, Final Batch Loss: 0.03404267877340317\n",
      "Epoch 548, Loss: 0.013005813118070364, Final Batch Loss: 0.0018893801607191563\n",
      "Epoch 549, Loss: 0.019853044534102082, Final Batch Loss: 0.0012537443544715643\n",
      "Epoch 550, Loss: 0.03735639387741685, Final Batch Loss: 0.0025883950293064117\n",
      "Epoch 551, Loss: 0.016412476892583072, Final Batch Loss: 0.0018486109329387546\n",
      "Epoch 552, Loss: 0.014033396728336811, Final Batch Loss: 0.0021792356856167316\n",
      "Epoch 553, Loss: 0.022161060478538275, Final Batch Loss: 0.0061635118909180164\n",
      "Epoch 554, Loss: 0.02708524325862527, Final Batch Loss: 0.013778334483504295\n",
      "Epoch 555, Loss: 0.01254171202890575, Final Batch Loss: 0.0020032809115946293\n",
      "Epoch 556, Loss: 0.027562506031244993, Final Batch Loss: 0.002663023304194212\n",
      "Epoch 557, Loss: 0.017228935146704316, Final Batch Loss: 0.00219449563883245\n",
      "Epoch 558, Loss: 0.00799539714353159, Final Batch Loss: 0.0008145447936840355\n",
      "Epoch 559, Loss: 0.011453436804004014, Final Batch Loss: 0.001554531161673367\n",
      "Epoch 560, Loss: 0.029300761525519192, Final Batch Loss: 0.0015169616090133786\n",
      "Epoch 561, Loss: 0.01740667107515037, Final Batch Loss: 0.002387002343311906\n",
      "Epoch 562, Loss: 0.023396615404635668, Final Batch Loss: 0.0010904492810368538\n",
      "Epoch 563, Loss: 0.022083977237343788, Final Batch Loss: 0.007183505687862635\n",
      "Epoch 564, Loss: 0.04070954234339297, Final Batch Loss: 0.0015797505620867014\n",
      "Epoch 565, Loss: 0.06512973317876458, Final Batch Loss: 0.05605311319231987\n",
      "Epoch 566, Loss: 0.04595772363245487, Final Batch Loss: 0.0011921608820557594\n",
      "Epoch 567, Loss: 0.04404807277023792, Final Batch Loss: 0.00880769919604063\n",
      "Epoch 568, Loss: 0.022994325030595064, Final Batch Loss: 0.003496999852359295\n",
      "Epoch 569, Loss: 0.04332168586552143, Final Batch Loss: 0.026321612298488617\n",
      "Epoch 570, Loss: 0.015899320598691702, Final Batch Loss: 0.0044412449933588505\n",
      "Epoch 571, Loss: 0.026231972500681877, Final Batch Loss: 0.014015202410519123\n",
      "Epoch 572, Loss: 0.038460473995655775, Final Batch Loss: 0.004716415423899889\n",
      "Epoch 573, Loss: 0.020490412367507815, Final Batch Loss: 0.0014739229809492826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 574, Loss: 0.024258106481283903, Final Batch Loss: 0.004318223800510168\n",
      "Epoch 575, Loss: 0.09363345196470618, Final Batch Loss: 0.07864658534526825\n",
      "Epoch 576, Loss: 0.016326898243278265, Final Batch Loss: 0.002299309941008687\n",
      "Epoch 577, Loss: 0.010373771481681615, Final Batch Loss: 0.0008052478660829365\n",
      "Epoch 578, Loss: 0.01823589112609625, Final Batch Loss: 0.009201162494719028\n",
      "Epoch 579, Loss: 0.01534269715193659, Final Batch Loss: 0.0015322827966883779\n",
      "Epoch 580, Loss: 0.03882199584040791, Final Batch Loss: 0.0012086775386705995\n",
      "Epoch 581, Loss: 0.00869021809194237, Final Batch Loss: 0.001266972511075437\n",
      "Epoch 582, Loss: 0.015580491861328483, Final Batch Loss: 0.0007115623448044062\n",
      "Epoch 583, Loss: 0.03237652685493231, Final Batch Loss: 0.015513010323047638\n",
      "Epoch 584, Loss: 0.03587257117033005, Final Batch Loss: 0.01144427340477705\n",
      "Epoch 585, Loss: 0.09807442734017968, Final Batch Loss: 0.0862557590007782\n",
      "Epoch 586, Loss: 0.01882925839163363, Final Batch Loss: 0.0019599327351897955\n",
      "Epoch 587, Loss: 0.02038405602797866, Final Batch Loss: 0.0028646131977438927\n",
      "Epoch 588, Loss: 0.03429242048878223, Final Batch Loss: 0.0010856484295800328\n",
      "Epoch 589, Loss: 0.016418595798313618, Final Batch Loss: 0.003833930939435959\n",
      "Epoch 590, Loss: 0.08810712769627571, Final Batch Loss: 0.024980342015624046\n",
      "Epoch 591, Loss: 0.02901264652609825, Final Batch Loss: 0.015872573480010033\n",
      "Epoch 592, Loss: 0.059629369992762804, Final Batch Loss: 0.045112352818250656\n",
      "Epoch 593, Loss: 0.02880697464570403, Final Batch Loss: 0.004392471630126238\n",
      "Epoch 594, Loss: 0.03909830027259886, Final Batch Loss: 0.004830357618629932\n",
      "Epoch 595, Loss: 0.014447895577177405, Final Batch Loss: 0.0005750118289142847\n",
      "Epoch 596, Loss: 0.018199032521806657, Final Batch Loss: 0.0017572041833773255\n",
      "Epoch 597, Loss: 0.02086649532429874, Final Batch Loss: 0.010388744994997978\n",
      "Epoch 598, Loss: 0.023346213158220053, Final Batch Loss: 0.0024201557971537113\n",
      "Epoch 599, Loss: 0.03791501512750983, Final Batch Loss: 0.01776324212551117\n",
      "Epoch 600, Loss: 0.017071249894797802, Final Batch Loss: 0.0019857273437082767\n",
      "Epoch 601, Loss: 0.017169701866805553, Final Batch Loss: 0.0066066402941942215\n",
      "Epoch 602, Loss: 0.006409553694538772, Final Batch Loss: 0.001428246614523232\n",
      "Epoch 603, Loss: 0.02401579823344946, Final Batch Loss: 0.004477684386074543\n",
      "Epoch 604, Loss: 0.028801180655136704, Final Batch Loss: 0.02217010222375393\n",
      "Epoch 605, Loss: 0.0332832420244813, Final Batch Loss: 0.011620081961154938\n",
      "Epoch 606, Loss: 0.017531737685203552, Final Batch Loss: 0.0077536641620099545\n",
      "Epoch 607, Loss: 0.016381313209421933, Final Batch Loss: 0.001858817762695253\n",
      "Epoch 608, Loss: 0.0268806463573128, Final Batch Loss: 0.0021333990152925253\n",
      "Epoch 609, Loss: 0.03980242204852402, Final Batch Loss: 0.0010344984475523233\n",
      "Epoch 610, Loss: 0.025416812859475613, Final Batch Loss: 0.006140677258372307\n",
      "Epoch 611, Loss: 0.0301422601332888, Final Batch Loss: 0.0012137893354520202\n",
      "Epoch 612, Loss: 0.028312669310253114, Final Batch Loss: 0.0007954530301503837\n",
      "Epoch 613, Loss: 0.03502456110436469, Final Batch Loss: 0.0018827748717740178\n",
      "Epoch 614, Loss: 0.04249915143009275, Final Batch Loss: 0.001223240396939218\n",
      "Epoch 615, Loss: 0.019269627751782537, Final Batch Loss: 0.002330246614292264\n",
      "Epoch 616, Loss: 0.03030052757821977, Final Batch Loss: 0.003523502266034484\n",
      "Epoch 617, Loss: 0.01954687130637467, Final Batch Loss: 0.0012941018212586641\n",
      "Epoch 618, Loss: 0.03126606112346053, Final Batch Loss: 0.005219143815338612\n",
      "Epoch 619, Loss: 0.036957187694497406, Final Batch Loss: 0.0012688833521679044\n",
      "Epoch 620, Loss: 0.023711489280685782, Final Batch Loss: 0.010783664882183075\n",
      "Epoch 621, Loss: 0.014902901370078325, Final Batch Loss: 0.004606683272868395\n",
      "Epoch 622, Loss: 0.011751674581319094, Final Batch Loss: 0.0034261150285601616\n",
      "Epoch 623, Loss: 0.0108207818120718, Final Batch Loss: 0.006267452146857977\n",
      "Epoch 624, Loss: 0.03133920580148697, Final Batch Loss: 0.002862861379981041\n",
      "Epoch 625, Loss: 0.014556539477780461, Final Batch Loss: 0.004941865336149931\n",
      "Epoch 626, Loss: 0.021071462600957602, Final Batch Loss: 0.0007217793609015644\n",
      "Epoch 627, Loss: 0.01451455196365714, Final Batch Loss: 0.003999384585767984\n",
      "Epoch 628, Loss: 0.023770778672769666, Final Batch Loss: 0.010239743627607822\n",
      "Epoch 629, Loss: 0.011910127592273057, Final Batch Loss: 0.001003638026304543\n",
      "Epoch 630, Loss: 0.02291900757700205, Final Batch Loss: 0.00195432361215353\n",
      "Epoch 631, Loss: 0.07816405780613422, Final Batch Loss: 0.05864643678069115\n",
      "Epoch 632, Loss: 0.019995444221422076, Final Batch Loss: 0.011608831584453583\n",
      "Epoch 633, Loss: 0.04628815874457359, Final Batch Loss: 0.00610234122723341\n",
      "Epoch 634, Loss: 0.02366810606326908, Final Batch Loss: 0.0013032344868406653\n",
      "Epoch 635, Loss: 0.03467631002422422, Final Batch Loss: 0.0008181127486750484\n",
      "Epoch 636, Loss: 0.0076034971280023456, Final Batch Loss: 0.002073468640446663\n",
      "Epoch 637, Loss: 0.014048503944650292, Final Batch Loss: 0.008019545115530491\n",
      "Epoch 638, Loss: 0.02205485268495977, Final Batch Loss: 0.003704971168190241\n",
      "Epoch 639, Loss: 0.017763373150955886, Final Batch Loss: 0.0008348996634595096\n",
      "Epoch 640, Loss: 0.06630346947349608, Final Batch Loss: 0.035739537328481674\n",
      "Epoch 641, Loss: 0.05512067605741322, Final Batch Loss: 0.04457644373178482\n",
      "Epoch 642, Loss: 0.005744433787185699, Final Batch Loss: 0.0007735371473245323\n",
      "Epoch 643, Loss: 0.012123119784519076, Final Batch Loss: 0.005401058588176966\n",
      "Epoch 644, Loss: 0.02869757218286395, Final Batch Loss: 0.01347854919731617\n",
      "Epoch 645, Loss: 0.019296701240818948, Final Batch Loss: 0.000571077864151448\n",
      "Epoch 646, Loss: 0.010604324983432889, Final Batch Loss: 0.002302137902006507\n",
      "Epoch 647, Loss: 0.012672731070779264, Final Batch Loss: 0.0014015064807608724\n",
      "Epoch 648, Loss: 0.018359737121500075, Final Batch Loss: 0.012085902504622936\n",
      "Epoch 649, Loss: 0.01034983922727406, Final Batch Loss: 0.0036433155182749033\n",
      "Epoch 650, Loss: 0.031177082331851125, Final Batch Loss: 0.0018012654036283493\n",
      "Epoch 651, Loss: 0.03959218313684687, Final Batch Loss: 0.0008197742863558233\n",
      "Epoch 652, Loss: 0.024134294886607677, Final Batch Loss: 0.0003004789468832314\n",
      "Epoch 653, Loss: 0.031497146701440215, Final Batch Loss: 0.012201182544231415\n",
      "Epoch 654, Loss: 0.006949160364456475, Final Batch Loss: 0.0016826182836666703\n",
      "Epoch 655, Loss: 0.027744361199438572, Final Batch Loss: 0.014169774018228054\n",
      "Epoch 656, Loss: 0.00948161497944966, Final Batch Loss: 0.00035679881693795323\n",
      "Epoch 657, Loss: 0.019903621869161725, Final Batch Loss: 0.001344491494819522\n",
      "Epoch 658, Loss: 0.007725713308900595, Final Batch Loss: 0.0009719436056911945\n",
      "Epoch 659, Loss: 0.016047397803049535, Final Batch Loss: 0.00029549672035500407\n",
      "Epoch 660, Loss: 0.025643573026172817, Final Batch Loss: 0.001493804040364921\n",
      "Epoch 661, Loss: 0.01665651380608324, Final Batch Loss: 0.00017245208437088877\n",
      "Epoch 662, Loss: 0.016701649874448776, Final Batch Loss: 0.003635943867266178\n",
      "Epoch 663, Loss: 0.026009682100266218, Final Batch Loss: 0.00862343143671751\n",
      "Epoch 664, Loss: 0.028993221349082887, Final Batch Loss: 0.021005546674132347\n",
      "Epoch 665, Loss: 0.00869633979164064, Final Batch Loss: 0.0015958005096763372\n",
      "Epoch 666, Loss: 0.022201504034455866, Final Batch Loss: 0.0007959850481711328\n",
      "Epoch 667, Loss: 0.029875335399992764, Final Batch Loss: 0.001207472407259047\n",
      "Epoch 668, Loss: 0.03110899857711047, Final Batch Loss: 0.001860119285993278\n",
      "Epoch 669, Loss: 0.013870712835341692, Final Batch Loss: 0.002460901625454426\n",
      "Epoch 670, Loss: 0.022387003293260932, Final Batch Loss: 0.0023881637025624514\n",
      "Epoch 671, Loss: 0.012330283992923796, Final Batch Loss: 0.0005627298960462213\n",
      "Epoch 672, Loss: 0.007413790415739641, Final Batch Loss: 0.000275689730187878\n",
      "Epoch 673, Loss: 0.006768246530555189, Final Batch Loss: 0.0006743330741301179\n",
      "Epoch 674, Loss: 0.04880408465396613, Final Batch Loss: 0.0016422505723312497\n",
      "Epoch 675, Loss: 0.04149835085263476, Final Batch Loss: 0.0006853046943433583\n",
      "Epoch 676, Loss: 0.011927936575375497, Final Batch Loss: 0.001390443998388946\n",
      "Epoch 677, Loss: 0.0513396913302131, Final Batch Loss: 0.0004601616528816521\n",
      "Epoch 678, Loss: 0.03637823835015297, Final Batch Loss: 0.02767948806285858\n",
      "Epoch 679, Loss: 0.008204832556657493, Final Batch Loss: 0.0017914880299940705\n",
      "Epoch 680, Loss: 0.018439501989632845, Final Batch Loss: 0.0010788501240313053\n",
      "Epoch 681, Loss: 0.02638945449143648, Final Batch Loss: 0.007075822912156582\n",
      "Epoch 682, Loss: 0.006423907354474068, Final Batch Loss: 0.0011239342857152224\n",
      "Epoch 683, Loss: 0.024296999676153064, Final Batch Loss: 0.0024127711076289415\n",
      "Epoch 684, Loss: 0.007505156914703548, Final Batch Loss: 0.002365067368373275\n",
      "Epoch 685, Loss: 0.01044478762196377, Final Batch Loss: 0.00044040713692083955\n",
      "Epoch 686, Loss: 0.04952837899327278, Final Batch Loss: 0.006817844696342945\n",
      "Epoch 687, Loss: 0.04817160405218601, Final Batch Loss: 0.036107387393713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688, Loss: 0.02207811188418418, Final Batch Loss: 0.006193836685270071\n",
      "Epoch 689, Loss: 0.008768511237576604, Final Batch Loss: 0.0008322859648615122\n",
      "Epoch 690, Loss: 0.004386699816677719, Final Batch Loss: 0.0006395349628292024\n",
      "Epoch 691, Loss: 0.014620512025430799, Final Batch Loss: 0.0018736303318291903\n",
      "Epoch 692, Loss: 0.03718717658193782, Final Batch Loss: 0.0020768758840858936\n",
      "Epoch 693, Loss: 0.013056554598733783, Final Batch Loss: 0.0016765461768954992\n",
      "Epoch 694, Loss: 0.013247681665234268, Final Batch Loss: 0.0008757304167374969\n",
      "Epoch 695, Loss: 0.006002227863064036, Final Batch Loss: 0.0011192564852535725\n",
      "Epoch 696, Loss: 0.00823848182335496, Final Batch Loss: 0.003220276441425085\n",
      "Epoch 697, Loss: 0.007112949155271053, Final Batch Loss: 0.0036465241573750973\n",
      "Epoch 698, Loss: 0.02383671933785081, Final Batch Loss: 0.01855926588177681\n",
      "Epoch 699, Loss: 0.0225549740716815, Final Batch Loss: 0.006460372358560562\n",
      "Epoch 700, Loss: 0.010788858169689775, Final Batch Loss: 0.001960000954568386\n",
      "Epoch 701, Loss: 0.009841686129220761, Final Batch Loss: 0.0002416419010842219\n",
      "Epoch 702, Loss: 0.028525181347504258, Final Batch Loss: 0.0031760346610099077\n",
      "Epoch 703, Loss: 0.021472222870215774, Final Batch Loss: 0.001016335329040885\n",
      "Epoch 704, Loss: 0.05202705808915198, Final Batch Loss: 0.0010211404878646135\n",
      "Epoch 705, Loss: 0.013286703499034047, Final Batch Loss: 0.003014553338289261\n",
      "Epoch 706, Loss: 0.005784049862995744, Final Batch Loss: 0.0010410435497760773\n",
      "Epoch 707, Loss: 0.02639787527732551, Final Batch Loss: 0.0033693506848067045\n",
      "Epoch 708, Loss: 0.023308807983994484, Final Batch Loss: 0.0054992614313960075\n",
      "Epoch 709, Loss: 0.01413301331922412, Final Batch Loss: 0.006233955733478069\n",
      "Epoch 710, Loss: 0.009290985355619341, Final Batch Loss: 0.0068090553395450115\n",
      "Epoch 711, Loss: 0.01356584916356951, Final Batch Loss: 0.0005500378319993615\n",
      "Epoch 712, Loss: 0.008947359950980172, Final Batch Loss: 0.00028891031979583204\n",
      "Epoch 713, Loss: 0.0150614915182814, Final Batch Loss: 0.00040529377292841673\n",
      "Epoch 714, Loss: 0.012562834192067385, Final Batch Loss: 0.003820036770775914\n",
      "Epoch 715, Loss: 0.04713885784440208, Final Batch Loss: 0.00022008999076206237\n",
      "Epoch 716, Loss: 0.008129882626235485, Final Batch Loss: 0.0033740138169378042\n",
      "Epoch 717, Loss: 0.030244320136262104, Final Batch Loss: 0.00026156517560593784\n",
      "Epoch 718, Loss: 0.008937721722759306, Final Batch Loss: 0.0030480206478387117\n",
      "Epoch 719, Loss: 0.030491982237435877, Final Batch Loss: 0.02369924820959568\n",
      "Epoch 720, Loss: 0.07181204156950116, Final Batch Loss: 0.06715871393680573\n",
      "Epoch 721, Loss: 0.008783167926594615, Final Batch Loss: 0.0030218290630728006\n",
      "Epoch 722, Loss: 0.015292560565285385, Final Batch Loss: 0.0016288607148453593\n",
      "Epoch 723, Loss: 0.026374902692623436, Final Batch Loss: 0.0008209726074710488\n",
      "Epoch 724, Loss: 0.01599838986294344, Final Batch Loss: 0.0006618255865760148\n",
      "Epoch 725, Loss: 0.027887604665011168, Final Batch Loss: 0.005500965751707554\n",
      "Epoch 726, Loss: 0.019628431153250858, Final Batch Loss: 0.00037787036853842437\n",
      "Epoch 727, Loss: 0.010552003746852279, Final Batch Loss: 0.004928631708025932\n",
      "Epoch 728, Loss: 0.057138539385050535, Final Batch Loss: 0.0045166234485805035\n",
      "Epoch 729, Loss: 0.013155033171642572, Final Batch Loss: 0.0006089334492571652\n",
      "Epoch 730, Loss: 0.022283871192485094, Final Batch Loss: 0.002916408237069845\n",
      "Epoch 731, Loss: 0.0508210263797082, Final Batch Loss: 0.0004017926403321326\n",
      "Epoch 732, Loss: 0.03297598415520042, Final Batch Loss: 0.0007767364149913192\n",
      "Epoch 733, Loss: 0.03098364791367203, Final Batch Loss: 0.026506423950195312\n",
      "Epoch 734, Loss: 0.049198852153494954, Final Batch Loss: 0.02594383992254734\n",
      "Epoch 735, Loss: 0.009408447658643126, Final Batch Loss: 0.0022450489923357964\n",
      "Epoch 736, Loss: 0.010125880711711943, Final Batch Loss: 0.004548679105937481\n",
      "Epoch 737, Loss: 0.008917036466300488, Final Batch Loss: 0.0033274213783442974\n",
      "Epoch 738, Loss: 0.012918319902382791, Final Batch Loss: 0.0018325763521715999\n",
      "Epoch 739, Loss: 0.01680336007848382, Final Batch Loss: 0.004245103802531958\n",
      "Epoch 740, Loss: 0.020175995654426515, Final Batch Loss: 0.0011031931499019265\n",
      "Epoch 741, Loss: 0.011263704247539863, Final Batch Loss: 0.00034906770451925695\n",
      "Epoch 742, Loss: 0.022010588087141514, Final Batch Loss: 0.0050034187734127045\n",
      "Epoch 743, Loss: 0.015834558522328734, Final Batch Loss: 0.0016979014035314322\n",
      "Epoch 744, Loss: 0.025093716103583574, Final Batch Loss: 0.01064187753945589\n",
      "Epoch 745, Loss: 0.018993118312209845, Final Batch Loss: 0.0021145513746887445\n",
      "Epoch 746, Loss: 0.007329190149903297, Final Batch Loss: 0.0010768445208668709\n",
      "Epoch 747, Loss: 0.00615706667304039, Final Batch Loss: 0.002489362843334675\n",
      "Epoch 748, Loss: 0.05134527914924547, Final Batch Loss: 0.04803665354847908\n",
      "Epoch 749, Loss: 0.007159369764849544, Final Batch Loss: 0.0007627543527632952\n",
      "Epoch 750, Loss: 0.016211048932746053, Final Batch Loss: 0.0011708695674315095\n",
      "Epoch 751, Loss: 0.025048998068086803, Final Batch Loss: 0.0010452506830915809\n",
      "Epoch 752, Loss: 0.006450570945162326, Final Batch Loss: 0.0005848140572197735\n",
      "Epoch 753, Loss: 0.07090454816352576, Final Batch Loss: 0.06331714242696762\n",
      "Epoch 754, Loss: 0.008252030238509178, Final Batch Loss: 0.004530871752649546\n",
      "Epoch 755, Loss: 0.013196026207879186, Final Batch Loss: 0.0025820813607424498\n",
      "Epoch 756, Loss: 0.1357732554897666, Final Batch Loss: 0.08331213146448135\n",
      "Epoch 757, Loss: 0.009334639995358884, Final Batch Loss: 0.0012793514179065824\n",
      "Epoch 758, Loss: 0.02716870594304055, Final Batch Loss: 0.0004522184608504176\n",
      "Epoch 759, Loss: 0.04517391882836819, Final Batch Loss: 0.022365964949131012\n",
      "Epoch 760, Loss: 0.03993109310977161, Final Batch Loss: 0.001978303072974086\n",
      "Epoch 761, Loss: 0.013313371338881552, Final Batch Loss: 0.007890789769589901\n",
      "Epoch 762, Loss: 0.0226823128759861, Final Batch Loss: 0.011525217443704605\n",
      "Epoch 763, Loss: 0.16557942517101765, Final Batch Loss: 0.12441012263298035\n",
      "Epoch 764, Loss: 0.012614759616553783, Final Batch Loss: 0.001674397848546505\n",
      "Epoch 765, Loss: 0.026131037157028913, Final Batch Loss: 0.00614557508379221\n",
      "Epoch 766, Loss: 0.06365929823368788, Final Batch Loss: 0.021576890721917152\n",
      "Epoch 767, Loss: 0.009058710653334856, Final Batch Loss: 0.0013670965563505888\n",
      "Epoch 768, Loss: 0.013855315221007913, Final Batch Loss: 0.0006539220339618623\n",
      "Epoch 769, Loss: 0.015973481349647045, Final Batch Loss: 0.0051660239696502686\n",
      "Epoch 770, Loss: 0.007204933906905353, Final Batch Loss: 0.00108954100869596\n",
      "Epoch 771, Loss: 0.024859322293195873, Final Batch Loss: 0.0008792605367489159\n",
      "Epoch 772, Loss: 0.010242786258459091, Final Batch Loss: 0.0033672505524009466\n",
      "Epoch 773, Loss: 0.009125791257247329, Final Batch Loss: 0.0016995975747704506\n",
      "Epoch 774, Loss: 0.005062065087258816, Final Batch Loss: 0.0006141329649835825\n",
      "Epoch 775, Loss: 0.026071773609146476, Final Batch Loss: 0.003765235422179103\n",
      "Epoch 776, Loss: 0.02167749567888677, Final Batch Loss: 0.00312812440097332\n",
      "Epoch 777, Loss: 0.017624752363190055, Final Batch Loss: 0.0029068337753415108\n",
      "Epoch 778, Loss: 0.016783967847004533, Final Batch Loss: 0.0035627298057079315\n",
      "Epoch 779, Loss: 0.007897919305833057, Final Batch Loss: 0.00016967070405371487\n",
      "Epoch 780, Loss: 0.020679407753050327, Final Batch Loss: 0.00473101157695055\n",
      "Epoch 781, Loss: 0.08439785102382302, Final Batch Loss: 0.07044444978237152\n",
      "Epoch 782, Loss: 0.012417838210240006, Final Batch Loss: 0.0012569268001243472\n",
      "Epoch 783, Loss: 0.010417399113066494, Final Batch Loss: 0.001278771203942597\n",
      "Epoch 784, Loss: 0.009051984176039696, Final Batch Loss: 0.0018992011900991201\n",
      "Epoch 785, Loss: 0.025846778182312846, Final Batch Loss: 0.0033645799849182367\n",
      "Epoch 786, Loss: 0.013558955630287528, Final Batch Loss: 0.0005065733566880226\n",
      "Epoch 787, Loss: 0.012028123601339757, Final Batch Loss: 0.0011406353441998363\n",
      "Epoch 788, Loss: 0.008813849417492747, Final Batch Loss: 0.00200636126101017\n",
      "Epoch 789, Loss: 0.007257378427311778, Final Batch Loss: 0.0040543354116380215\n",
      "Epoch 790, Loss: 0.018644691503141075, Final Batch Loss: 0.0007575727649964392\n",
      "Epoch 791, Loss: 0.053157512098550797, Final Batch Loss: 0.03310127928853035\n",
      "Epoch 792, Loss: 0.008750305278226733, Final Batch Loss: 0.00426187738776207\n",
      "Epoch 793, Loss: 0.0038330956595018506, Final Batch Loss: 0.0015977114671841264\n",
      "Epoch 794, Loss: 0.021395597839727998, Final Batch Loss: 0.001110495300963521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 795, Loss: 0.022693099454045296, Final Batch Loss: 0.0070685469545423985\n",
      "Epoch 796, Loss: 0.0036801054957322776, Final Batch Loss: 0.0005827327840961516\n",
      "Epoch 797, Loss: 0.015571453608572483, Final Batch Loss: 0.004637781996279955\n",
      "Epoch 798, Loss: 0.00565740730962716, Final Batch Loss: 0.0003710278251674026\n",
      "Epoch 799, Loss: 0.013443493749946356, Final Batch Loss: 0.0039329808205366135\n",
      "Epoch 800, Loss: 0.01010323443915695, Final Batch Loss: 0.0006641335785388947\n",
      "Epoch 801, Loss: 0.015065808081999421, Final Batch Loss: 0.0016009265091270208\n",
      "Epoch 802, Loss: 0.009573303745128214, Final Batch Loss: 0.005849556531757116\n",
      "Epoch 803, Loss: 0.006493602762930095, Final Batch Loss: 0.002347802510485053\n",
      "Epoch 804, Loss: 0.03900789702311158, Final Batch Loss: 0.004668254405260086\n",
      "Epoch 805, Loss: 0.006240258633624762, Final Batch Loss: 0.0006142620113678277\n",
      "Epoch 806, Loss: 0.01025562232825905, Final Batch Loss: 0.001823871280066669\n",
      "Epoch 807, Loss: 0.0089002211461775, Final Batch Loss: 0.0007846331573091447\n",
      "Epoch 808, Loss: 0.003988673386629671, Final Batch Loss: 0.0004695685929618776\n",
      "Epoch 809, Loss: 0.007949432823807001, Final Batch Loss: 0.005183371249586344\n",
      "Epoch 810, Loss: 0.00968753476627171, Final Batch Loss: 0.003702508984133601\n",
      "Epoch 811, Loss: 0.003080853377468884, Final Batch Loss: 0.0006569502875208855\n",
      "Epoch 812, Loss: 0.013211075798608363, Final Batch Loss: 0.004373711068183184\n",
      "Epoch 813, Loss: 0.04434671897615772, Final Batch Loss: 0.0002298021427122876\n",
      "Epoch 814, Loss: 0.007255521137267351, Final Batch Loss: 0.004182224627584219\n",
      "Epoch 815, Loss: 0.004918601509416476, Final Batch Loss: 0.00047253145021386445\n",
      "Epoch 816, Loss: 0.00807455470203422, Final Batch Loss: 0.000299960927804932\n",
      "Epoch 817, Loss: 0.004033961042296141, Final Batch Loss: 0.0004092016606591642\n",
      "Epoch 818, Loss: 0.01568793156184256, Final Batch Loss: 0.0005820710211992264\n",
      "Epoch 819, Loss: 0.027877210348378867, Final Batch Loss: 0.0015429550549015403\n",
      "Epoch 820, Loss: 0.06629467895254493, Final Batch Loss: 0.055857498198747635\n",
      "Epoch 821, Loss: 0.010918936983216554, Final Batch Loss: 0.0038498579524457455\n",
      "Epoch 822, Loss: 0.013160920469090343, Final Batch Loss: 0.009621452540159225\n",
      "Epoch 823, Loss: 0.002892008807975799, Final Batch Loss: 0.0006805433076806366\n",
      "Epoch 824, Loss: 0.004890536132734269, Final Batch Loss: 0.0005866438732482493\n",
      "Epoch 825, Loss: 0.009967278805561364, Final Batch Loss: 0.0005134526873007417\n",
      "Epoch 826, Loss: 0.010036287363618612, Final Batch Loss: 0.005849001929163933\n",
      "Epoch 827, Loss: 0.02242207038216293, Final Batch Loss: 0.015164879150688648\n",
      "Epoch 828, Loss: 0.012496309936977923, Final Batch Loss: 0.0013247126480564475\n",
      "Epoch 829, Loss: 0.03761455160565674, Final Batch Loss: 0.029403144493699074\n",
      "Epoch 830, Loss: 0.01657156931469217, Final Batch Loss: 0.0007815806311555207\n",
      "Epoch 831, Loss: 0.014521181583404541, Final Batch Loss: 0.0030802316032350063\n",
      "Epoch 832, Loss: 0.017946734733413905, Final Batch Loss: 0.0005828595603816211\n",
      "Epoch 833, Loss: 0.02080999338068068, Final Batch Loss: 0.0028548266272991896\n",
      "Epoch 834, Loss: 0.018402086570858955, Final Batch Loss: 0.006037022452801466\n",
      "Epoch 835, Loss: 0.028926138766109943, Final Batch Loss: 0.0015028584748506546\n",
      "Epoch 836, Loss: 0.010481502627953887, Final Batch Loss: 0.001532707829028368\n",
      "Epoch 837, Loss: 0.0032374515431001782, Final Batch Loss: 0.0008529451442882419\n",
      "Epoch 838, Loss: 0.006680144200799987, Final Batch Loss: 0.00045174555270932615\n",
      "Epoch 839, Loss: 0.00759939500130713, Final Batch Loss: 0.00289390841498971\n",
      "Epoch 840, Loss: 0.00947044079657644, Final Batch Loss: 0.000842916895635426\n",
      "Epoch 841, Loss: 0.022891845437698066, Final Batch Loss: 0.01291970256716013\n",
      "Epoch 842, Loss: 0.005504104163264856, Final Batch Loss: 0.0004857374296989292\n",
      "Epoch 843, Loss: 0.03250515926629305, Final Batch Loss: 0.001973257400095463\n",
      "Epoch 844, Loss: 0.0211946185445413, Final Batch Loss: 0.000851165852509439\n",
      "Epoch 845, Loss: 0.00683218811172992, Final Batch Loss: 0.001659882953390479\n",
      "Epoch 846, Loss: 0.037784004118293524, Final Batch Loss: 0.002036657650023699\n",
      "Epoch 847, Loss: 0.006333998288027942, Final Batch Loss: 0.0004379462916404009\n",
      "Epoch 848, Loss: 0.004405455139931291, Final Batch Loss: 0.0002476000809110701\n",
      "Epoch 849, Loss: 0.011341158882714808, Final Batch Loss: 0.0025171388406306505\n",
      "Epoch 850, Loss: 0.0036965080071240664, Final Batch Loss: 0.0012202709913253784\n",
      "Epoch 851, Loss: 0.0026118375826627016, Final Batch Loss: 0.0008757165633141994\n",
      "Epoch 852, Loss: 0.00401418868204928, Final Batch Loss: 4.793973857886158e-05\n",
      "Epoch 853, Loss: 0.012108233291655779, Final Batch Loss: 0.007961485534906387\n",
      "Epoch 854, Loss: 0.007609387161210179, Final Batch Loss: 0.00034884229535236955\n",
      "Epoch 855, Loss: 0.0038515172200277448, Final Batch Loss: 0.001568354549817741\n",
      "Epoch 856, Loss: 0.007413152139633894, Final Batch Loss: 0.001812489004805684\n",
      "Epoch 857, Loss: 0.003001133824000135, Final Batch Loss: 0.0004846374795306474\n",
      "Epoch 858, Loss: 0.0031119026243686676, Final Batch Loss: 0.0005669898237101734\n",
      "Epoch 859, Loss: 0.005299151176586747, Final Batch Loss: 0.000264578964561224\n",
      "Epoch 860, Loss: 0.013858420483302325, Final Batch Loss: 0.00040775322122499347\n",
      "Epoch 861, Loss: 0.008810559009361896, Final Batch Loss: 1.3226946975919418e-05\n",
      "Epoch 862, Loss: 0.010719508165493608, Final Batch Loss: 0.0005773179582320154\n",
      "Epoch 863, Loss: 0.003845638857455924, Final Batch Loss: 0.0002442407712806016\n",
      "Epoch 864, Loss: 0.004177456954494119, Final Batch Loss: 0.002055345568805933\n",
      "Epoch 865, Loss: 0.03576338535640389, Final Batch Loss: 0.004756887909024954\n",
      "Epoch 866, Loss: 0.009161966823739931, Final Batch Loss: 0.0001731411030050367\n",
      "Epoch 867, Loss: 0.009873890841845423, Final Batch Loss: 0.0009727310971356928\n",
      "Epoch 868, Loss: 0.00904579902999103, Final Batch Loss: 0.0015469053760170937\n",
      "Epoch 869, Loss: 0.006245160358957946, Final Batch Loss: 0.00327160838060081\n",
      "Epoch 870, Loss: 0.05096771311946213, Final Batch Loss: 0.0004038659390062094\n",
      "Epoch 871, Loss: 0.033172465628013015, Final Batch Loss: 0.0033613338600844145\n",
      "Epoch 872, Loss: 0.008928172523155808, Final Batch Loss: 0.0030360259115695953\n",
      "Epoch 873, Loss: 0.03696877683978528, Final Batch Loss: 0.0056863329373300076\n",
      "Epoch 874, Loss: 0.03973645338555798, Final Batch Loss: 0.016547828912734985\n",
      "Epoch 875, Loss: 0.005095749162137508, Final Batch Loss: 0.0005293976282700896\n",
      "Epoch 876, Loss: 0.002021749853156507, Final Batch Loss: 0.0005264371866360307\n",
      "Epoch 877, Loss: 0.004240634269081056, Final Batch Loss: 0.001410202356055379\n",
      "Epoch 878, Loss: 0.005220759427174926, Final Batch Loss: 0.0028722460847347975\n",
      "Epoch 879, Loss: 0.00988829463312868, Final Batch Loss: 0.00020206208864692599\n",
      "Epoch 880, Loss: 0.003810207766946405, Final Batch Loss: 0.0006757850642316043\n",
      "Epoch 881, Loss: 0.011295583448372781, Final Batch Loss: 0.007395497057586908\n",
      "Epoch 882, Loss: 0.02088655740953982, Final Batch Loss: 0.019248588010668755\n",
      "Epoch 883, Loss: 0.0031896886066533625, Final Batch Loss: 0.0012025819160044193\n",
      "Epoch 884, Loss: 0.004669268790166825, Final Batch Loss: 0.0029761502519249916\n",
      "Epoch 885, Loss: 0.034715841815341264, Final Batch Loss: 0.0006289309239946306\n",
      "Epoch 886, Loss: 0.03548938961466774, Final Batch Loss: 0.0007382743642665446\n",
      "Epoch 887, Loss: 0.012496312614530325, Final Batch Loss: 0.002348322421312332\n",
      "Epoch 888, Loss: 0.00695487461052835, Final Batch Loss: 0.002230120822787285\n",
      "Epoch 889, Loss: 0.007431111240293831, Final Batch Loss: 0.000539496832061559\n",
      "Epoch 890, Loss: 0.008644222965813242, Final Batch Loss: 0.00016206745931413025\n",
      "Epoch 891, Loss: 0.007245886867167428, Final Batch Loss: 0.00035833954461850226\n",
      "Epoch 892, Loss: 0.017418840317986906, Final Batch Loss: 0.0026688582729548216\n",
      "Epoch 893, Loss: 0.011199528351426125, Final Batch Loss: 0.0028117261826992035\n",
      "Epoch 894, Loss: 0.003223668085411191, Final Batch Loss: 0.0005615629488602281\n",
      "Epoch 895, Loss: 0.0032683704630471766, Final Batch Loss: 0.0007569095469079912\n",
      "Epoch 896, Loss: 0.006568182143382728, Final Batch Loss: 0.003134659957140684\n",
      "Epoch 897, Loss: 0.007867612526752055, Final Batch Loss: 0.002894518431276083\n",
      "Epoch 898, Loss: 0.0035076853237114847, Final Batch Loss: 0.00036671996349468827\n",
      "Epoch 899, Loss: 0.004678855650126934, Final Batch Loss: 0.001967047806829214\n",
      "Epoch 900, Loss: 0.01566413903492503, Final Batch Loss: 0.0004655264492612332\n",
      "Epoch 901, Loss: 0.014648709387984127, Final Batch Loss: 0.000777302251663059\n",
      "Epoch 902, Loss: 0.01602719136280939, Final Batch Loss: 0.0008549901540391147\n",
      "Epoch 903, Loss: 0.02545826742425561, Final Batch Loss: 0.0019067544490098953\n",
      "Epoch 904, Loss: 0.01624989276751876, Final Batch Loss: 0.002275648294016719\n",
      "Epoch 905, Loss: 0.003201150306267664, Final Batch Loss: 0.0004561348760034889\n",
      "Epoch 906, Loss: 0.018494946823921055, Final Batch Loss: 0.0009739507222548127\n",
      "Epoch 907, Loss: 0.00960769213270396, Final Batch Loss: 0.0011269239475950599\n",
      "Epoch 908, Loss: 0.0024640829069539905, Final Batch Loss: 0.0004574015038087964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 909, Loss: 0.009694695530924946, Final Batch Loss: 0.0006915347767062485\n",
      "Epoch 910, Loss: 0.0032495378982275724, Final Batch Loss: 0.00042441231198608875\n",
      "Epoch 911, Loss: 0.0038410518900491297, Final Batch Loss: 0.0003911884850822389\n",
      "Epoch 912, Loss: 0.002786654222290963, Final Batch Loss: 0.0004763133474625647\n",
      "Epoch 913, Loss: 0.007047713850624859, Final Batch Loss: 0.00173046940471977\n",
      "Epoch 914, Loss: 0.11721804057015106, Final Batch Loss: 0.10163906216621399\n",
      "Epoch 915, Loss: 0.004156980605330318, Final Batch Loss: 0.00038044125540181994\n",
      "Epoch 916, Loss: 0.00837102229706943, Final Batch Loss: 0.0036093557719141245\n",
      "Epoch 917, Loss: 0.004920587409287691, Final Batch Loss: 0.0013698312686756253\n",
      "Epoch 918, Loss: 0.004850858429563232, Final Batch Loss: 0.0001683907612459734\n",
      "Epoch 919, Loss: 0.0025892428820952773, Final Batch Loss: 0.00036970549263060093\n",
      "Epoch 920, Loss: 0.003909500068402849, Final Batch Loss: 0.00012516351125668734\n",
      "Epoch 921, Loss: 0.005000583070795983, Final Batch Loss: 0.000807619362603873\n",
      "Epoch 922, Loss: 0.004132923320867121, Final Batch Loss: 0.002703688805922866\n",
      "Epoch 923, Loss: 0.004439883778104559, Final Batch Loss: 0.00027132805553264916\n",
      "Epoch 924, Loss: 0.04252036102116108, Final Batch Loss: 0.033309515565633774\n",
      "Epoch 925, Loss: 0.0062530735158361495, Final Batch Loss: 0.00428333505988121\n",
      "Epoch 926, Loss: 0.007981448987266049, Final Batch Loss: 0.00016276157111860812\n",
      "Epoch 927, Loss: 0.0034962111967615783, Final Batch Loss: 0.0012326164869591594\n",
      "Epoch 928, Loss: 0.011944972386118025, Final Batch Loss: 0.0065364898182451725\n",
      "Epoch 929, Loss: 0.0036425288708414882, Final Batch Loss: 0.0022421563044190407\n",
      "Epoch 930, Loss: 0.002749949460849166, Final Batch Loss: 0.0002720017801038921\n",
      "Epoch 931, Loss: 0.0020054154738318175, Final Batch Loss: 0.00036150161758996546\n",
      "Epoch 932, Loss: 0.0042869001044891775, Final Batch Loss: 0.0008849131991155446\n",
      "Epoch 933, Loss: 0.011265564942732453, Final Batch Loss: 0.0023005735129117966\n",
      "Epoch 934, Loss: 0.010200787801295519, Final Batch Loss: 0.00013601290993392467\n",
      "Epoch 935, Loss: 0.0016954316815827042, Final Batch Loss: 0.0011180719593539834\n",
      "Epoch 936, Loss: 0.009374316141474992, Final Batch Loss: 0.0007072978769429028\n",
      "Epoch 937, Loss: 0.001716771861538291, Final Batch Loss: 0.00033781997626647353\n",
      "Epoch 938, Loss: 0.004633089833077975, Final Batch Loss: 0.0001684213784756139\n",
      "Epoch 939, Loss: 0.008449470420600846, Final Batch Loss: 0.0007745918701402843\n",
      "Epoch 940, Loss: 0.003177770006004721, Final Batch Loss: 0.0005887654260732234\n",
      "Epoch 941, Loss: 0.016446481691673398, Final Batch Loss: 0.0008710587280802429\n",
      "Epoch 942, Loss: 0.004959748650435358, Final Batch Loss: 0.0014185917098075151\n",
      "Epoch 943, Loss: 0.006124010367784649, Final Batch Loss: 0.0007755639380775392\n",
      "Epoch 944, Loss: 0.03532439807895571, Final Batch Loss: 0.03061281517148018\n",
      "Epoch 945, Loss: 0.0029324703064048663, Final Batch Loss: 0.00015721518138889223\n",
      "Epoch 946, Loss: 0.007948836428113282, Final Batch Loss: 0.0029419618658721447\n",
      "Epoch 947, Loss: 0.00568715383997187, Final Batch Loss: 0.0033456578385084867\n",
      "Epoch 948, Loss: 0.016672597907017916, Final Batch Loss: 0.0007777090067975223\n",
      "Epoch 949, Loss: 0.005026928731240332, Final Batch Loss: 0.001495581935159862\n",
      "Epoch 950, Loss: 0.010230140993371606, Final Batch Loss: 0.0025636237114667892\n",
      "Epoch 951, Loss: 0.009711534949019551, Final Batch Loss: 0.002067208755761385\n",
      "Epoch 952, Loss: 0.00534559425432235, Final Batch Loss: 0.002922862069681287\n",
      "Epoch 953, Loss: 0.006821903836680576, Final Batch Loss: 0.00012792900088243186\n",
      "Epoch 954, Loss: 0.0030891156202415004, Final Batch Loss: 0.00019367488857824355\n",
      "Epoch 955, Loss: 0.0026888062129728496, Final Batch Loss: 0.00025556195760145783\n",
      "Epoch 956, Loss: 0.017127265309682116, Final Batch Loss: 0.00033902665018104017\n",
      "Epoch 957, Loss: 0.001365966396406293, Final Batch Loss: 0.00036432608612813056\n",
      "Epoch 958, Loss: 0.004679474048316479, Final Batch Loss: 0.0011791579890996218\n",
      "Epoch 959, Loss: 0.011902264086529613, Final Batch Loss: 0.0029962200205773115\n",
      "Epoch 960, Loss: 0.010074503436044324, Final Batch Loss: 2.0860177755821496e-05\n",
      "Epoch 961, Loss: 0.016024198732338846, Final Batch Loss: 0.0077248127199709415\n",
      "Epoch 962, Loss: 0.042027497838716954, Final Batch Loss: 0.029406292364001274\n",
      "Epoch 963, Loss: 0.00792652546078898, Final Batch Loss: 0.0002451275067869574\n",
      "Epoch 964, Loss: 0.011319683602778241, Final Batch Loss: 0.00031435300479643047\n",
      "Epoch 965, Loss: 0.02200213889591396, Final Batch Loss: 0.0024586014915257692\n",
      "Epoch 966, Loss: 0.015435938374139369, Final Batch Loss: 0.0019428975647315383\n",
      "Epoch 967, Loss: 0.005528774578124285, Final Batch Loss: 0.0027872705832123756\n",
      "Epoch 968, Loss: 0.023569351207697764, Final Batch Loss: 0.00024126764037646353\n",
      "Epoch 969, Loss: 0.007095060253050178, Final Batch Loss: 0.0005457600927911699\n",
      "Epoch 970, Loss: 0.0035583089338615537, Final Batch Loss: 0.0005252364790067077\n",
      "Epoch 971, Loss: 0.0018350326572544873, Final Batch Loss: 0.000501220696605742\n",
      "Epoch 972, Loss: 0.0036684309015981853, Final Batch Loss: 0.0013908285181969404\n",
      "Epoch 973, Loss: 0.008985577442217618, Final Batch Loss: 0.0001752046518959105\n",
      "Epoch 974, Loss: 0.00457526178797707, Final Batch Loss: 0.00027815968496724963\n",
      "Epoch 975, Loss: 0.00524509052047506, Final Batch Loss: 0.0005568329361267388\n",
      "Epoch 976, Loss: 0.0028366291662678123, Final Batch Loss: 0.0007764468900859356\n",
      "Epoch 977, Loss: 0.0021171341577428393, Final Batch Loss: 6.153660797281191e-05\n",
      "Epoch 978, Loss: 0.027439442463219166, Final Batch Loss: 0.004030460957437754\n",
      "Epoch 979, Loss: 0.03297723154173582, Final Batch Loss: 5.4981788707664236e-05\n",
      "Epoch 980, Loss: 0.0223520933650434, Final Batch Loss: 0.0016967998817563057\n",
      "Epoch 981, Loss: 0.010326904244720936, Final Batch Loss: 0.001354241045191884\n",
      "Epoch 982, Loss: 0.006981555023230612, Final Batch Loss: 0.0030894058290868998\n",
      "Epoch 983, Loss: 0.0016042201314121485, Final Batch Loss: 0.0003593185683712363\n",
      "Epoch 984, Loss: 0.0034228340518893674, Final Batch Loss: 0.0001607898302609101\n",
      "Epoch 985, Loss: 0.0027400259859859943, Final Batch Loss: 0.000519510533194989\n",
      "Epoch 986, Loss: 0.02438147272914648, Final Batch Loss: 0.002049516886472702\n",
      "Epoch 987, Loss: 0.0038973857881501317, Final Batch Loss: 0.0007638036622665823\n",
      "Epoch 988, Loss: 0.006191028187458869, Final Batch Loss: 0.00012110234092688188\n",
      "Epoch 989, Loss: 0.0052992373530287296, Final Batch Loss: 0.0003212550946045667\n",
      "Epoch 990, Loss: 0.0039711701683700085, Final Batch Loss: 0.00018189754337072372\n",
      "Epoch 991, Loss: 0.010254602486384101, Final Batch Loss: 0.0007411224651150405\n",
      "Epoch 992, Loss: 0.009360177675262094, Final Batch Loss: 0.0014289978425949812\n",
      "Epoch 993, Loss: 0.021538121392950416, Final Batch Loss: 0.004743875004351139\n",
      "Epoch 994, Loss: 0.0017039517406374216, Final Batch Loss: 0.0007666433230042458\n",
      "Epoch 995, Loss: 0.005471855285577476, Final Batch Loss: 0.003161435015499592\n",
      "Epoch 996, Loss: 0.013567313086241484, Final Batch Loss: 0.003257160307839513\n",
      "Epoch 997, Loss: 0.028520933556137607, Final Batch Loss: 4.248178447596729e-05\n",
      "Epoch 998, Loss: 0.004805353528354317, Final Batch Loss: 0.0005166049231775105\n",
      "Epoch 999, Loss: 0.003972116275690496, Final Batch Loss: 0.0013034705771133304\n",
      "Epoch 1000, Loss: 0.010611555306240916, Final Batch Loss: 0.0019686194136738777\n",
      "Epoch 1001, Loss: 0.004346133617218584, Final Batch Loss: 0.0007374893757514656\n",
      "Epoch 1002, Loss: 0.07728119730018079, Final Batch Loss: 0.04319284111261368\n",
      "Epoch 1003, Loss: 0.05403524450957775, Final Batch Loss: 0.04719090834259987\n",
      "Epoch 1004, Loss: 0.024887798237614334, Final Batch Loss: 0.0007190970936790109\n",
      "Epoch 1005, Loss: 0.010743923194240779, Final Batch Loss: 0.0007598954252898693\n",
      "Epoch 1006, Loss: 0.0038521181559190154, Final Batch Loss: 0.0013836764264851809\n",
      "Epoch 1007, Loss: 0.0030062528676353395, Final Batch Loss: 0.0015548116061836481\n",
      "Epoch 1008, Loss: 0.0064456522959517315, Final Batch Loss: 0.00022503705986309797\n",
      "Epoch 1009, Loss: 0.007850316527765244, Final Batch Loss: 0.0060101719573140144\n",
      "Epoch 1010, Loss: 0.009985657525248826, Final Batch Loss: 0.002733224770054221\n",
      "Epoch 1011, Loss: 0.0026878234348259866, Final Batch Loss: 0.0007414530264213681\n",
      "Epoch 1012, Loss: 0.010650034993886948, Final Batch Loss: 0.0017864024266600609\n",
      "Epoch 1013, Loss: 0.004039308099891059, Final Batch Loss: 0.00012450040958356112\n",
      "Epoch 1014, Loss: 0.012194887269288301, Final Batch Loss: 0.0039909519255161285\n",
      "Epoch 1015, Loss: 0.002431808621622622, Final Batch Loss: 0.0008320455090142787\n",
      "Epoch 1016, Loss: 0.00447994124260731, Final Batch Loss: 0.0002655664284247905\n",
      "Epoch 1017, Loss: 0.0017960361146833748, Final Batch Loss: 0.0005029294406995177\n",
      "Epoch 1018, Loss: 0.014400565240066499, Final Batch Loss: 0.012890352867543697\n",
      "Epoch 1019, Loss: 0.003425695758778602, Final Batch Loss: 0.0008301870548166335\n",
      "Epoch 1020, Loss: 0.01338892467902042, Final Batch Loss: 0.00042102509178221226\n",
      "Epoch 1021, Loss: 0.0056114246835932136, Final Batch Loss: 0.0037410862278193235\n",
      "Epoch 1022, Loss: 0.03065183147555217, Final Batch Loss: 0.0014559610281139612\n",
      "Epoch 1023, Loss: 0.002340659048059024, Final Batch Loss: 0.001208636094816029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1024, Loss: 0.0037479293532669544, Final Batch Loss: 0.002283381298184395\n",
      "Epoch 1025, Loss: 0.03173742152284831, Final Batch Loss: 0.0252070315182209\n",
      "Epoch 1026, Loss: 0.023524743563029915, Final Batch Loss: 0.000507761724293232\n",
      "Epoch 1027, Loss: 0.006032377888914198, Final Batch Loss: 0.004427498672157526\n",
      "Epoch 1028, Loss: 0.025769200990907848, Final Batch Loss: 0.0006433221278712153\n",
      "Epoch 1029, Loss: 0.021927574009168893, Final Batch Loss: 0.0008011549944058061\n",
      "Epoch 1030, Loss: 0.008711242699064314, Final Batch Loss: 0.004243324510753155\n",
      "Epoch 1031, Loss: 0.015243207395542413, Final Batch Loss: 0.0010050729615613818\n",
      "Epoch 1032, Loss: 0.005008630338124931, Final Batch Loss: 0.0005676085129380226\n",
      "Epoch 1033, Loss: 0.0023428522690664977, Final Batch Loss: 0.0002875719510484487\n",
      "Epoch 1034, Loss: 0.13412668576347642, Final Batch Loss: 0.13200443983078003\n",
      "Epoch 1035, Loss: 0.007836657896405086, Final Batch Loss: 6.412758375518024e-05\n",
      "Epoch 1036, Loss: 0.0038375277654267848, Final Batch Loss: 0.0005974158993922174\n",
      "Epoch 1037, Loss: 0.010025420924648643, Final Batch Loss: 0.0024726034607738256\n",
      "Epoch 1038, Loss: 0.00975505553651601, Final Batch Loss: 0.0006871499354019761\n",
      "Epoch 1039, Loss: 0.009603251135558821, Final Batch Loss: 0.0001884094817796722\n",
      "Epoch 1040, Loss: 0.023747632279992104, Final Batch Loss: 0.001453944481909275\n",
      "Epoch 1041, Loss: 0.010059602791443467, Final Batch Loss: 0.0007808208465576172\n",
      "Epoch 1042, Loss: 0.015390121261589229, Final Batch Loss: 0.0012896311236545444\n",
      "Epoch 1043, Loss: 0.007709010795224458, Final Batch Loss: 0.0005443987320177257\n",
      "Epoch 1044, Loss: 0.004162214550888166, Final Batch Loss: 0.0023588226176798344\n",
      "Epoch 1045, Loss: 0.00748270214535296, Final Batch Loss: 0.005094326566904783\n",
      "Epoch 1046, Loss: 0.00832943084242288, Final Batch Loss: 7.387997175101191e-05\n",
      "Epoch 1047, Loss: 0.013145481992978603, Final Batch Loss: 0.0002465831348672509\n",
      "Epoch 1048, Loss: 0.009091634303331375, Final Batch Loss: 0.006155665963888168\n",
      "Epoch 1049, Loss: 0.014276151487138122, Final Batch Loss: 0.0008868274162523448\n",
      "Epoch 1050, Loss: 0.0027786297141574323, Final Batch Loss: 0.0007783037144690752\n",
      "Epoch 1051, Loss: 0.005093617946840823, Final Batch Loss: 0.0018161410698667169\n",
      "Epoch 1052, Loss: 0.010049816104583442, Final Batch Loss: 0.0011284885695204139\n",
      "Epoch 1053, Loss: 0.005320722004398704, Final Batch Loss: 0.0012656364124268293\n",
      "Epoch 1054, Loss: 0.008021570683922619, Final Batch Loss: 0.0007375061395578086\n",
      "Epoch 1055, Loss: 0.003584682708606124, Final Batch Loss: 0.001162144704721868\n",
      "Epoch 1056, Loss: 0.005220166232902557, Final Batch Loss: 0.0006920736050233245\n",
      "Epoch 1057, Loss: 0.004698095377534628, Final Batch Loss: 0.0010075740283355117\n",
      "Epoch 1058, Loss: 0.009287452616263181, Final Batch Loss: 0.001411912147887051\n",
      "Epoch 1059, Loss: 0.0025299542176071554, Final Batch Loss: 0.0003829649940598756\n",
      "Epoch 1060, Loss: 0.00808904122095555, Final Batch Loss: 0.0007230721530504525\n",
      "Epoch 1061, Loss: 0.0044215015368536115, Final Batch Loss: 0.001464633271098137\n",
      "Epoch 1062, Loss: 0.07463274977635592, Final Batch Loss: 0.06641910970211029\n",
      "Epoch 1063, Loss: 0.0251855980604887, Final Batch Loss: 0.004286730196326971\n",
      "Epoch 1064, Loss: 0.017689010128378868, Final Batch Loss: 0.0036678474862128496\n",
      "Epoch 1065, Loss: 0.0030009034380782396, Final Batch Loss: 0.0004662361170630902\n",
      "Epoch 1066, Loss: 0.006033954181475565, Final Batch Loss: 0.0001537875214125961\n",
      "Epoch 1067, Loss: 0.011597450473345816, Final Batch Loss: 0.0003125094808638096\n",
      "Epoch 1068, Loss: 0.007299995981156826, Final Batch Loss: 0.00128179881721735\n",
      "Epoch 1069, Loss: 0.00323999224929139, Final Batch Loss: 0.0005862743710167706\n",
      "Epoch 1070, Loss: 0.002171410247683525, Final Batch Loss: 0.0002190630475524813\n",
      "Epoch 1071, Loss: 0.02611183183034882, Final Batch Loss: 0.024014508351683617\n",
      "Epoch 1072, Loss: 0.009179350483464077, Final Batch Loss: 0.00048536216490902007\n",
      "Epoch 1073, Loss: 0.003016214759554714, Final Batch Loss: 0.000718761992175132\n",
      "Epoch 1074, Loss: 0.0018002507567871362, Final Batch Loss: 0.00042294434388168156\n",
      "Epoch 1075, Loss: 0.024630143358081114, Final Batch Loss: 7.466034003300592e-05\n",
      "Epoch 1076, Loss: 0.030466244381386787, Final Batch Loss: 0.004018798936158419\n",
      "Epoch 1077, Loss: 0.0051472458289936185, Final Batch Loss: 0.0008396570337936282\n",
      "Epoch 1078, Loss: 0.29142252693418413, Final Batch Loss: 0.2620660066604614\n",
      "Epoch 1079, Loss: 0.009744306444190443, Final Batch Loss: 0.0016286143800243735\n",
      "Epoch 1080, Loss: 0.01351564156357199, Final Batch Loss: 0.0010155937634408474\n",
      "Epoch 1081, Loss: 0.014456893943133764, Final Batch Loss: 0.0001395607105223462\n",
      "Epoch 1082, Loss: 0.011674534529447556, Final Batch Loss: 0.00023064692504703999\n",
      "Epoch 1083, Loss: 0.00386361638084054, Final Batch Loss: 0.0009001955622807145\n",
      "Epoch 1084, Loss: 0.01942344891722314, Final Batch Loss: 0.0003851139626931399\n",
      "Epoch 1085, Loss: 0.004287357674911618, Final Batch Loss: 0.0011553594376891851\n",
      "Epoch 1086, Loss: 0.022760513704270124, Final Batch Loss: 0.00432213768362999\n",
      "Epoch 1087, Loss: 0.0033198700402863324, Final Batch Loss: 0.0007369579398073256\n",
      "Epoch 1088, Loss: 0.0037228113797027618, Final Batch Loss: 0.0003528147062752396\n",
      "Epoch 1089, Loss: 0.00783318537287414, Final Batch Loss: 0.005492578726261854\n",
      "Epoch 1090, Loss: 0.0035116540384478867, Final Batch Loss: 0.0007616356597281992\n",
      "Epoch 1091, Loss: 0.016461717401398346, Final Batch Loss: 0.0001708132040221244\n",
      "Epoch 1092, Loss: 0.04392756341258064, Final Batch Loss: 0.0002600823645479977\n",
      "Epoch 1093, Loss: 0.0032873310847207904, Final Batch Loss: 0.0018011444481089711\n",
      "Epoch 1094, Loss: 0.006466409249696881, Final Batch Loss: 0.0008795579778961837\n",
      "Epoch 1095, Loss: 0.008702702616574243, Final Batch Loss: 0.00031186515116132796\n",
      "Epoch 1096, Loss: 0.010198368923738599, Final Batch Loss: 0.0006138014141470194\n",
      "Epoch 1097, Loss: 0.007466148032108322, Final Batch Loss: 0.0047264862805604935\n",
      "Epoch 1098, Loss: 0.003985723134974251, Final Batch Loss: 4.5449651224771515e-05\n",
      "Epoch 1099, Loss: 0.019873928918968886, Final Batch Loss: 0.0029613326769322157\n",
      "Epoch 1100, Loss: 0.004146988736465573, Final Batch Loss: 0.001812941045500338\n",
      "Epoch 1101, Loss: 0.0044688384514302015, Final Batch Loss: 0.0014549819752573967\n",
      "Epoch 1102, Loss: 0.008314881008118391, Final Batch Loss: 0.0009228292037732899\n",
      "Epoch 1103, Loss: 0.017579769250005484, Final Batch Loss: 0.014696268364787102\n",
      "Epoch 1104, Loss: 0.02159342532104347, Final Batch Loss: 0.00011696656292770058\n",
      "Epoch 1105, Loss: 0.008988731249701232, Final Batch Loss: 0.0026002610102295876\n",
      "Epoch 1106, Loss: 0.00703541818074882, Final Batch Loss: 0.0012634338345378637\n",
      "Epoch 1107, Loss: 0.005552686867304146, Final Batch Loss: 0.0020459359511733055\n",
      "Epoch 1108, Loss: 0.02258081524632871, Final Batch Loss: 0.00243370165117085\n",
      "Epoch 1109, Loss: 0.004299911670386791, Final Batch Loss: 0.0006495284615084529\n",
      "Epoch 1110, Loss: 0.0037734874640591443, Final Batch Loss: 0.00029664405155926943\n",
      "Epoch 1111, Loss: 0.0023231937375385314, Final Batch Loss: 0.000322732754284516\n",
      "Epoch 1112, Loss: 0.047635875205742195, Final Batch Loss: 0.03928021714091301\n",
      "Epoch 1113, Loss: 0.0014025115415279288, Final Batch Loss: 5.520617196452804e-05\n",
      "Epoch 1114, Loss: 0.03772136371117085, Final Batch Loss: 0.02633366361260414\n",
      "Epoch 1115, Loss: 0.0043459898442961276, Final Batch Loss: 0.001755443518050015\n",
      "Epoch 1116, Loss: 0.032722841715440154, Final Batch Loss: 0.003855263814330101\n",
      "Epoch 1117, Loss: 0.011136616085423157, Final Batch Loss: 0.00042225487413816154\n",
      "Epoch 1118, Loss: 0.02215665380936116, Final Batch Loss: 0.0018404207658022642\n",
      "Epoch 1119, Loss: 0.003584810590837151, Final Batch Loss: 0.0016568502178415656\n",
      "Epoch 1120, Loss: 0.027903940062969923, Final Batch Loss: 0.0038380813784897327\n",
      "Epoch 1121, Loss: 0.00237176867085509, Final Batch Loss: 0.00042094223317690194\n",
      "Epoch 1122, Loss: 0.010990289389155805, Final Batch Loss: 0.0005602659657597542\n",
      "Epoch 1123, Loss: 0.008795026486041024, Final Batch Loss: 0.00016582608805038035\n",
      "Epoch 1124, Loss: 0.049398166593164206, Final Batch Loss: 0.04256158322095871\n",
      "Epoch 1125, Loss: 0.011785665759816766, Final Batch Loss: 0.009367833845317364\n",
      "Epoch 1126, Loss: 0.019180509261786938, Final Batch Loss: 0.005246581044048071\n",
      "Epoch 1127, Loss: 0.006755085720214993, Final Batch Loss: 0.005340276751667261\n",
      "Epoch 1128, Loss: 0.01255616417620331, Final Batch Loss: 0.0020150684285908937\n",
      "Epoch 1129, Loss: 0.008959233615314588, Final Batch Loss: 0.0004777925496455282\n",
      "Epoch 1130, Loss: 0.008221150608733296, Final Batch Loss: 0.0028297174721956253\n",
      "Epoch 1131, Loss: 0.02228543779347092, Final Batch Loss: 0.0006530039245262742\n",
      "Epoch 1132, Loss: 0.009546117100398988, Final Batch Loss: 0.0006489455117844045\n",
      "Epoch 1133, Loss: 0.0036343421088531613, Final Batch Loss: 0.0006955971475690603\n",
      "Epoch 1134, Loss: 0.01043830782873556, Final Batch Loss: 0.00016874977154657245\n",
      "Epoch 1135, Loss: 0.03757223946740851, Final Batch Loss: 0.00037522712955251336\n",
      "Epoch 1136, Loss: 0.008635059464722872, Final Batch Loss: 0.0016755628166720271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1137, Loss: 0.002854384947568178, Final Batch Loss: 0.001142479246482253\n",
      "Epoch 1138, Loss: 0.0030599489400628954, Final Batch Loss: 0.00044731333036907017\n",
      "Epoch 1139, Loss: 0.014584163553081453, Final Batch Loss: 0.010698662139475346\n",
      "Epoch 1140, Loss: 0.008273788262158632, Final Batch Loss: 0.0009104417404159904\n",
      "Epoch 1141, Loss: 0.009571750084433006, Final Batch Loss: 4.3542375351535156e-05\n",
      "Epoch 1142, Loss: 0.002090886380756274, Final Batch Loss: 0.0002345064713153988\n",
      "Epoch 1143, Loss: 0.0029018994537182152, Final Batch Loss: 0.0005605695187114179\n",
      "Epoch 1144, Loss: 0.014803550788201392, Final Batch Loss: 0.0015229174168780446\n",
      "Epoch 1145, Loss: 0.003027619852218777, Final Batch Loss: 0.0008177378331311047\n",
      "Epoch 1146, Loss: 0.005739387386711314, Final Batch Loss: 0.00029049321892671287\n",
      "Epoch 1147, Loss: 0.002300575462868437, Final Batch Loss: 0.00035857109469361603\n",
      "Epoch 1148, Loss: 0.0031800198776181787, Final Batch Loss: 0.0008869017474353313\n",
      "Epoch 1149, Loss: 0.03194106312002987, Final Batch Loss: 0.00032188266050070524\n",
      "Epoch 1150, Loss: 0.003608294005971402, Final Batch Loss: 0.0006953683914616704\n",
      "Epoch 1151, Loss: 0.002224908414063975, Final Batch Loss: 0.000411659391829744\n",
      "Epoch 1152, Loss: 0.004891834891168401, Final Batch Loss: 0.00024645260418765247\n",
      "Epoch 1153, Loss: 0.0031706297013442963, Final Batch Loss: 0.00043816296965815127\n",
      "Epoch 1154, Loss: 0.002070665570499841, Final Batch Loss: 7.839696627343073e-05\n",
      "Epoch 1155, Loss: 0.008231513609644026, Final Batch Loss: 0.005893627181649208\n",
      "Epoch 1156, Loss: 0.008905306603992358, Final Batch Loss: 0.00023592860088683665\n",
      "Epoch 1157, Loss: 0.0019132029410684481, Final Batch Loss: 0.0001575249625602737\n",
      "Epoch 1158, Loss: 0.002129134285496548, Final Batch Loss: 0.0002819550863932818\n",
      "Epoch 1159, Loss: 0.033310402679489926, Final Batch Loss: 0.031867820769548416\n",
      "Epoch 1160, Loss: 0.011602192651480436, Final Batch Loss: 0.0010756375268101692\n",
      "Epoch 1161, Loss: 0.00797044619685039, Final Batch Loss: 0.0008972442010417581\n",
      "Epoch 1162, Loss: 0.0063242288888432086, Final Batch Loss: 0.0005531061324290931\n",
      "Epoch 1163, Loss: 0.0019687866151798517, Final Batch Loss: 0.0005994612001813948\n",
      "Epoch 1164, Loss: 0.024246606044471264, Final Batch Loss: 0.021759100258350372\n",
      "Epoch 1165, Loss: 0.005509429131052457, Final Batch Loss: 0.0001682997535681352\n",
      "Epoch 1166, Loss: 0.005054132547229528, Final Batch Loss: 0.0008469629101455212\n",
      "Epoch 1167, Loss: 0.002736380571150221, Final Batch Loss: 0.00013289345952216536\n",
      "Epoch 1168, Loss: 0.005805046588648111, Final Batch Loss: 6.775051588192582e-05\n",
      "Epoch 1169, Loss: 0.004472895758226514, Final Batch Loss: 0.0013601029058918357\n",
      "Epoch 1170, Loss: 0.0026630009233485907, Final Batch Loss: 0.00042704984662123024\n",
      "Epoch 1171, Loss: 0.001994924619793892, Final Batch Loss: 0.00023682904429733753\n",
      "Epoch 1172, Loss: 0.004185007826890796, Final Batch Loss: 0.0002201684401370585\n",
      "Epoch 1173, Loss: 0.003179621766321361, Final Batch Loss: 0.0006352530908770859\n",
      "Epoch 1174, Loss: 0.017850621487013996, Final Batch Loss: 0.0003249464207328856\n",
      "Epoch 1175, Loss: 0.003147141746012494, Final Batch Loss: 0.0003160611668135971\n",
      "Epoch 1176, Loss: 0.0026155914238188416, Final Batch Loss: 0.00031132347066886723\n",
      "Epoch 1177, Loss: 0.006455959053710103, Final Batch Loss: 0.0002860219683498144\n",
      "Epoch 1178, Loss: 0.0021242243237793446, Final Batch Loss: 0.001180425169877708\n",
      "Epoch 1179, Loss: 0.0021833674181834795, Final Batch Loss: 0.00011341981735313311\n",
      "Epoch 1180, Loss: 0.006199386611115187, Final Batch Loss: 0.00030813898774795234\n",
      "Epoch 1181, Loss: 0.012131270719692111, Final Batch Loss: 0.002480907831341028\n",
      "Epoch 1182, Loss: 0.01030565207474865, Final Batch Loss: 0.00039168159128166735\n",
      "Epoch 1183, Loss: 0.003323290206026286, Final Batch Loss: 0.0015788618475198746\n",
      "Epoch 1184, Loss: 0.017244291258975863, Final Batch Loss: 0.0014924652641639113\n",
      "Epoch 1185, Loss: 0.0026618323172442615, Final Batch Loss: 0.0007655082154087722\n",
      "Epoch 1186, Loss: 0.003110868012299761, Final Batch Loss: 0.00012076864368282259\n",
      "Epoch 1187, Loss: 0.002084224732243456, Final Batch Loss: 7.675834058318287e-05\n",
      "Epoch 1188, Loss: 0.002056573204754386, Final Batch Loss: 2.905054861912504e-05\n",
      "Epoch 1189, Loss: 0.0043568084365688264, Final Batch Loss: 0.0029160045087337494\n",
      "Epoch 1190, Loss: 0.0028902085323352367, Final Batch Loss: 0.0014244408812373877\n",
      "Epoch 1191, Loss: 0.0016905316151678562, Final Batch Loss: 0.00047037540934979916\n",
      "Epoch 1192, Loss: 0.0022976105683483183, Final Batch Loss: 0.0005854428745806217\n",
      "Epoch 1193, Loss: 0.006087138419388793, Final Batch Loss: 0.0001231122005265206\n",
      "Epoch 1194, Loss: 0.0023115117655834183, Final Batch Loss: 0.0003207994159311056\n",
      "Epoch 1195, Loss: 0.01593027080525644, Final Batch Loss: 0.0002872894110623747\n",
      "Epoch 1196, Loss: 0.0034557739418232813, Final Batch Loss: 0.0002811696904245764\n",
      "Epoch 1197, Loss: 0.002988998719956726, Final Batch Loss: 0.00142132886685431\n",
      "Epoch 1198, Loss: 0.00466807305929251, Final Batch Loss: 0.00011086350423283875\n",
      "Epoch 1199, Loss: 0.03697254303006048, Final Batch Loss: 1.773451549524907e-05\n",
      "Epoch 1200, Loss: 0.0032376032322645187, Final Batch Loss: 0.001019807648845017\n",
      "Epoch 1201, Loss: 0.0017042903054971248, Final Batch Loss: 0.00016564276302233338\n",
      "Epoch 1202, Loss: 0.025759287760592997, Final Batch Loss: 0.02458958514034748\n",
      "Epoch 1203, Loss: 0.0021675132593372837, Final Batch Loss: 0.0009271472808904946\n",
      "Epoch 1204, Loss: 0.00208798362291418, Final Batch Loss: 0.0010462604695931077\n",
      "Epoch 1205, Loss: 0.0009803053799259942, Final Batch Loss: 3.979300890932791e-05\n",
      "Epoch 1206, Loss: 0.0060226905916351825, Final Batch Loss: 0.0027016045060008764\n",
      "Epoch 1207, Loss: 0.013399653005762957, Final Batch Loss: 0.00014935001672711223\n",
      "Epoch 1208, Loss: 0.009355449315989972, Final Batch Loss: 2.7753727408708073e-05\n",
      "Epoch 1209, Loss: 0.007337631051996141, Final Batch Loss: 2.8360611395328306e-05\n",
      "Epoch 1210, Loss: 0.008007517317309976, Final Batch Loss: 0.002080738777294755\n",
      "Epoch 1211, Loss: 0.0015177637378656073, Final Batch Loss: 2.9538086891989224e-05\n",
      "Epoch 1212, Loss: 0.0017902167892316356, Final Batch Loss: 0.00017534570361021906\n",
      "Epoch 1213, Loss: 0.014503865932056215, Final Batch Loss: 7.18424198566936e-05\n",
      "Epoch 1214, Loss: 0.008008252782019554, Final Batch Loss: 5.3301057050703093e-05\n",
      "Epoch 1215, Loss: 0.0069002044619992375, Final Batch Loss: 0.0007658250397071242\n",
      "Epoch 1216, Loss: 0.010148326109629124, Final Batch Loss: 0.0007220879197120667\n",
      "Epoch 1217, Loss: 0.0066985618614126, Final Batch Loss: 9.721532114781439e-05\n",
      "Epoch 1218, Loss: 0.004435970608028583, Final Batch Loss: 0.00016355501429643482\n",
      "Epoch 1219, Loss: 0.010300367837771773, Final Batch Loss: 0.0007657024543732405\n",
      "Epoch 1220, Loss: 0.002960428304504603, Final Batch Loss: 0.0001438455656170845\n",
      "Epoch 1221, Loss: 0.002436366368783638, Final Batch Loss: 0.00025098773767240345\n",
      "Epoch 1222, Loss: 0.0018771679024212062, Final Batch Loss: 0.0001993457553908229\n",
      "Epoch 1223, Loss: 0.007668242265935987, Final Batch Loss: 0.0009093706612475216\n",
      "Epoch 1224, Loss: 0.0015245182148646563, Final Batch Loss: 0.0005741639761254191\n",
      "Epoch 1225, Loss: 0.010584576360997744, Final Batch Loss: 0.0001185035944217816\n",
      "Epoch 1226, Loss: 0.04276350769214332, Final Batch Loss: 0.039104484021663666\n",
      "Epoch 1227, Loss: 0.006490483210654929, Final Batch Loss: 0.00531880185008049\n",
      "Epoch 1228, Loss: 0.016191229835385457, Final Batch Loss: 0.0004108619468752295\n",
      "Epoch 1229, Loss: 0.07190329860895872, Final Batch Loss: 0.011483111418783665\n",
      "Epoch 1230, Loss: 0.008350244461325929, Final Batch Loss: 0.0003748377494048327\n",
      "Epoch 1231, Loss: 0.07657028909306973, Final Batch Loss: 0.07213698327541351\n",
      "Epoch 1232, Loss: 0.10970349630224518, Final Batch Loss: 0.00016118513303808868\n",
      "Epoch 1233, Loss: 0.04819169547408819, Final Batch Loss: 0.005102221854031086\n",
      "Epoch 1234, Loss: 0.04410843417281285, Final Batch Loss: 0.0014580688439309597\n",
      "Epoch 1235, Loss: 0.07604280754458159, Final Batch Loss: 0.07319974154233932\n",
      "Epoch 1236, Loss: 0.011669538158457726, Final Batch Loss: 0.0006131326663307846\n",
      "Epoch 1237, Loss: 0.0042676947778090835, Final Batch Loss: 0.0017021861858665943\n",
      "Epoch 1238, Loss: 0.009403243195265532, Final Batch Loss: 0.0026590998750180006\n",
      "Epoch 1239, Loss: 0.008595781051553786, Final Batch Loss: 0.0013243756256997585\n",
      "Epoch 1240, Loss: 0.024013095651753247, Final Batch Loss: 0.001917775603942573\n",
      "Epoch 1241, Loss: 0.0026784353249240667, Final Batch Loss: 0.001120750093832612\n",
      "Epoch 1242, Loss: 0.017473763378802687, Final Batch Loss: 0.0008126668399199843\n",
      "Epoch 1243, Loss: 0.03946558269672096, Final Batch Loss: 0.0012744006235152483\n",
      "Epoch 1244, Loss: 0.02736279438249767, Final Batch Loss: 0.0038074932526797056\n",
      "Epoch 1245, Loss: 0.013527771108783782, Final Batch Loss: 0.0018396932864561677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1246, Loss: 0.008314977516420186, Final Batch Loss: 0.0018242454389110208\n",
      "Epoch 1247, Loss: 0.0038792137638665736, Final Batch Loss: 0.0010949881980195642\n",
      "Epoch 1248, Loss: 0.006445208913646638, Final Batch Loss: 0.0013601296814158559\n",
      "Epoch 1249, Loss: 0.008273107509012334, Final Batch Loss: 0.0008715634467080235\n",
      "Epoch 1250, Loss: 0.009826035602600314, Final Batch Loss: 0.00013495727034751326\n",
      "Epoch 1251, Loss: 0.033755659009329975, Final Batch Loss: 0.0019275810336694121\n",
      "Epoch 1252, Loss: 0.0180544521426782, Final Batch Loss: 0.010692674666643143\n",
      "Epoch 1253, Loss: 0.004819130524992943, Final Batch Loss: 0.0014761330094188452\n",
      "Epoch 1254, Loss: 0.006850095349363983, Final Batch Loss: 0.0038442176301032305\n",
      "Epoch 1255, Loss: 0.005937386420555413, Final Batch Loss: 0.000529143144376576\n",
      "Epoch 1256, Loss: 0.008789478786638938, Final Batch Loss: 0.00020261753525119275\n",
      "Epoch 1257, Loss: 0.028418220987077802, Final Batch Loss: 0.00018984678899869323\n",
      "Epoch 1258, Loss: 0.004729672509711236, Final Batch Loss: 0.002793509978801012\n",
      "Epoch 1259, Loss: 0.007182611618191004, Final Batch Loss: 0.0019938908517360687\n",
      "Epoch 1260, Loss: 0.03735824544855859, Final Batch Loss: 7.669451588299125e-05\n",
      "Epoch 1261, Loss: 0.005511643481440842, Final Batch Loss: 0.0013728628400713205\n",
      "Epoch 1262, Loss: 0.02052605466451496, Final Batch Loss: 0.0005940151168033481\n",
      "Epoch 1263, Loss: 0.0019005556678166613, Final Batch Loss: 0.00014679411833640188\n",
      "Epoch 1264, Loss: 0.008437840268015862, Final Batch Loss: 0.006316788028925657\n",
      "Epoch 1265, Loss: 0.002884464331145864, Final Batch Loss: 8.40388165670447e-05\n",
      "Epoch 1266, Loss: 0.0014818041527178138, Final Batch Loss: 0.0007131154998205602\n",
      "Epoch 1267, Loss: 0.011827205307781696, Final Batch Loss: 0.008948052302002907\n",
      "Epoch 1268, Loss: 0.01646288877236657, Final Batch Loss: 0.00040188999264501035\n",
      "Epoch 1269, Loss: 0.006149588502012193, Final Batch Loss: 0.00310823624022305\n",
      "Epoch 1270, Loss: 0.016022927564335987, Final Batch Loss: 0.003239577868953347\n",
      "Epoch 1271, Loss: 0.027532737061847, Final Batch Loss: 0.0004754751571454108\n",
      "Epoch 1272, Loss: 0.009711387916468084, Final Batch Loss: 0.0012323834234848619\n",
      "Epoch 1273, Loss: 0.007240475621074438, Final Batch Loss: 0.0009822440333664417\n",
      "Epoch 1274, Loss: 0.0029543600976467133, Final Batch Loss: 0.0011913655325770378\n",
      "Epoch 1275, Loss: 0.002009067189646885, Final Batch Loss: 0.0006032721721567214\n",
      "Epoch 1276, Loss: 0.0039443543064408, Final Batch Loss: 0.0018584125209599733\n",
      "Epoch 1277, Loss: 0.0037210131995379925, Final Batch Loss: 0.0010566789424046874\n",
      "Epoch 1278, Loss: 0.01663170475512743, Final Batch Loss: 0.0012707695132121444\n",
      "Epoch 1279, Loss: 0.004370339214801788, Final Batch Loss: 0.0017272940604016185\n",
      "Epoch 1280, Loss: 0.0030091102235019207, Final Batch Loss: 0.00025329162599518895\n",
      "Epoch 1281, Loss: 0.00311963859712705, Final Batch Loss: 0.0005653296830132604\n",
      "Epoch 1282, Loss: 0.005556105374125764, Final Batch Loss: 0.0001165775756817311\n",
      "Epoch 1283, Loss: 0.004157792602200061, Final Batch Loss: 0.00038203276926651597\n",
      "Epoch 1284, Loss: 0.012424362928868504, Final Batch Loss: 4.4718723074765876e-05\n",
      "Epoch 1285, Loss: 0.0026479906227905303, Final Batch Loss: 0.00048047371092252433\n",
      "Epoch 1286, Loss: 0.007115842017810792, Final Batch Loss: 0.0009472998208366334\n",
      "Epoch 1287, Loss: 0.030418697861023247, Final Batch Loss: 0.00036119541618973017\n",
      "Epoch 1288, Loss: 0.006782519973057788, Final Batch Loss: 9.564228093950078e-05\n",
      "Epoch 1289, Loss: 0.003304856305476278, Final Batch Loss: 0.0012280249502509832\n",
      "Epoch 1290, Loss: 0.01911229304096196, Final Batch Loss: 8.378540223930031e-05\n",
      "Epoch 1291, Loss: 0.003978367778472602, Final Batch Loss: 0.0018422275315970182\n",
      "Epoch 1292, Loss: 0.019812969083432108, Final Batch Loss: 9.824091102927923e-05\n",
      "Epoch 1293, Loss: 0.0017447859572712332, Final Batch Loss: 0.0008827708079479635\n",
      "Epoch 1294, Loss: 0.008264819567557424, Final Batch Loss: 0.0008054762147367001\n",
      "Epoch 1295, Loss: 0.0017578723782207817, Final Batch Loss: 0.00029065299895592034\n",
      "Epoch 1296, Loss: 0.011322531965561211, Final Batch Loss: 0.0005633432883769274\n",
      "Epoch 1297, Loss: 0.0038973427726887167, Final Batch Loss: 0.0008546268800273538\n",
      "Epoch 1298, Loss: 0.010624463233398274, Final Batch Loss: 0.008525731973350048\n",
      "Epoch 1299, Loss: 0.002097931253956631, Final Batch Loss: 0.0001702111039776355\n",
      "Epoch 1300, Loss: 0.00393256543611642, Final Batch Loss: 0.00011327803076710552\n",
      "Epoch 1301, Loss: 0.0018377896340098232, Final Batch Loss: 0.0002149605134036392\n",
      "Epoch 1302, Loss: 0.011701092473231256, Final Batch Loss: 0.005367797799408436\n",
      "Epoch 1303, Loss: 0.005283208447508514, Final Batch Loss: 0.0018087010830640793\n",
      "Epoch 1304, Loss: 0.015923746570479125, Final Batch Loss: 0.014769499190151691\n",
      "Epoch 1305, Loss: 0.027315386338159442, Final Batch Loss: 0.007774736732244492\n",
      "Epoch 1306, Loss: 0.008927206217776984, Final Batch Loss: 0.002317889593541622\n",
      "Epoch 1307, Loss: 0.011213355173822492, Final Batch Loss: 0.0030814295168966055\n",
      "Epoch 1308, Loss: 0.007595455532282358, Final Batch Loss: 3.526990985847078e-05\n",
      "Epoch 1309, Loss: 0.007024917824310251, Final Batch Loss: 5.877537478227168e-05\n",
      "Epoch 1310, Loss: 0.0049289510934613645, Final Batch Loss: 0.0027506661135703325\n",
      "Epoch 1311, Loss: 0.008386650210013613, Final Batch Loss: 0.00012415918172337115\n",
      "Epoch 1312, Loss: 0.0444867100159172, Final Batch Loss: 0.03552314266562462\n",
      "Epoch 1313, Loss: 0.011734267609426752, Final Batch Loss: 0.00022753150551579893\n",
      "Epoch 1314, Loss: 0.003140630025882274, Final Batch Loss: 0.0018058239948004484\n",
      "Epoch 1315, Loss: 0.0021332679607439786, Final Batch Loss: 0.00022797987912781537\n",
      "Epoch 1316, Loss: 0.01791119307745248, Final Batch Loss: 0.0012228909181430936\n",
      "Epoch 1317, Loss: 0.08385484013706446, Final Batch Loss: 0.08202064782381058\n",
      "Epoch 1318, Loss: 0.0046446827400359325, Final Batch Loss: 2.0401021174620837e-05\n",
      "Epoch 1319, Loss: 0.04438410568400286, Final Batch Loss: 7.678536348976195e-05\n",
      "Epoch 1320, Loss: 0.018522376121836714, Final Batch Loss: 0.0001225510350195691\n",
      "Epoch 1321, Loss: 0.002698935946682468, Final Batch Loss: 0.00036044258740730584\n",
      "Epoch 1322, Loss: 0.0029822579817846417, Final Batch Loss: 0.0011413280153647065\n",
      "Epoch 1323, Loss: 0.006520817754790187, Final Batch Loss: 0.00232401629909873\n",
      "Epoch 1324, Loss: 0.026669760700315237, Final Batch Loss: 0.003542528720572591\n",
      "Epoch 1325, Loss: 0.014742110623046756, Final Batch Loss: 0.000553949736058712\n",
      "Epoch 1326, Loss: 0.00418707390781492, Final Batch Loss: 0.0015318787191063166\n",
      "Epoch 1327, Loss: 0.005536272219615057, Final Batch Loss: 0.0036221067421138287\n",
      "Epoch 1328, Loss: 0.016510943649336696, Final Batch Loss: 0.0026070112362504005\n",
      "Epoch 1329, Loss: 0.002724339603446424, Final Batch Loss: 0.0009475388214923441\n",
      "Epoch 1330, Loss: 0.00524811667855829, Final Batch Loss: 0.0035516303032636642\n",
      "Epoch 1331, Loss: 0.011042737809475511, Final Batch Loss: 0.000930914597120136\n",
      "Epoch 1332, Loss: 0.03325781729654409, Final Batch Loss: 0.0002570462238509208\n",
      "Epoch 1333, Loss: 0.023111847782274708, Final Batch Loss: 0.0006852172082290053\n",
      "Epoch 1334, Loss: 0.009515342651866376, Final Batch Loss: 0.007852651178836823\n",
      "Epoch 1335, Loss: 0.00706238804559689, Final Batch Loss: 0.00018572427507024258\n",
      "Epoch 1336, Loss: 0.01732861082564341, Final Batch Loss: 0.00011166855256306008\n",
      "Epoch 1337, Loss: 0.0017025070410454646, Final Batch Loss: 0.00013661921548191458\n",
      "Epoch 1338, Loss: 0.002313361852429807, Final Batch Loss: 0.0010008937679231167\n",
      "Epoch 1339, Loss: 0.010112750605912879, Final Batch Loss: 0.00028780035790987313\n",
      "Epoch 1340, Loss: 0.008513031993061304, Final Batch Loss: 0.0006503670010715723\n",
      "Epoch 1341, Loss: 0.002398264841758646, Final Batch Loss: 0.00021315809863153845\n",
      "Epoch 1342, Loss: 0.0015268755378201604, Final Batch Loss: 0.0001329706865362823\n",
      "Epoch 1343, Loss: 0.0032475473126396537, Final Batch Loss: 0.00026425370015203953\n",
      "Epoch 1344, Loss: 0.003088747092988342, Final Batch Loss: 0.0008663538028486073\n",
      "Epoch 1345, Loss: 0.0022838866570964456, Final Batch Loss: 0.0006025180337019265\n",
      "Epoch 1346, Loss: 0.010149501293199137, Final Batch Loss: 0.003702342277392745\n",
      "Epoch 1347, Loss: 0.006004028371535242, Final Batch Loss: 7.900118362158537e-05\n",
      "Epoch 1348, Loss: 0.01839215960353613, Final Batch Loss: 0.012221502140164375\n",
      "Epoch 1349, Loss: 0.008032138925045729, Final Batch Loss: 0.00025068758986890316\n",
      "Epoch 1350, Loss: 0.016051056642027106, Final Batch Loss: 0.00010865585500141606\n",
      "Epoch 1351, Loss: 0.0038540346304216655, Final Batch Loss: 2.9944627385702915e-05\n",
      "Epoch 1352, Loss: 0.004386911721667275, Final Batch Loss: 0.0003663748793769628\n",
      "Epoch 1353, Loss: 0.0028985945391468704, Final Batch Loss: 0.0006816874374635518\n",
      "Epoch 1354, Loss: 0.0026861512451432645, Final Batch Loss: 0.001289471285417676\n",
      "Epoch 1355, Loss: 0.0037761263083666563, Final Batch Loss: 0.0020969912875443697\n",
      "Epoch 1356, Loss: 0.003297287446912378, Final Batch Loss: 0.0015319217927753925\n",
      "Epoch 1357, Loss: 0.0036847358860541135, Final Batch Loss: 0.0003904016630258411\n",
      "Epoch 1358, Loss: 0.002190964645706117, Final Batch Loss: 0.0006722962716594338\n",
      "Epoch 1359, Loss: 0.0017779985792003572, Final Batch Loss: 0.0008656365680508316\n",
      "Epoch 1360, Loss: 0.00659795376486727, Final Batch Loss: 5.108470577397384e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1361, Loss: 0.00409185147145763, Final Batch Loss: 0.0008903946145437658\n",
      "Epoch 1362, Loss: 0.002206836987170391, Final Batch Loss: 0.00016355256957467645\n",
      "Epoch 1363, Loss: 0.0034266439615748823, Final Batch Loss: 0.0009738668450154364\n",
      "Epoch 1364, Loss: 0.006217896065209061, Final Batch Loss: 0.0004972883616574109\n",
      "Epoch 1365, Loss: 0.001041323019308038, Final Batch Loss: 0.0001561174140078947\n",
      "Epoch 1366, Loss: 0.002526968950405717, Final Batch Loss: 0.0002553884405642748\n",
      "Epoch 1367, Loss: 0.0022817958961240947, Final Batch Loss: 0.0008704985375516117\n",
      "Epoch 1368, Loss: 0.007213740609586239, Final Batch Loss: 0.00018849025946110487\n",
      "Epoch 1369, Loss: 0.007346712460275739, Final Batch Loss: 0.0010955702746286988\n",
      "Epoch 1370, Loss: 0.0026488541916478425, Final Batch Loss: 0.001659226487390697\n",
      "Epoch 1371, Loss: 0.007035519745841157, Final Batch Loss: 3.9254249713849276e-05\n",
      "Epoch 1372, Loss: 0.0023713157133897766, Final Batch Loss: 4.655982775148004e-05\n",
      "Epoch 1373, Loss: 0.011561267361685168, Final Batch Loss: 0.00010092817683471367\n",
      "Epoch 1374, Loss: 0.0012655529862968251, Final Batch Loss: 0.0002921086270362139\n",
      "Epoch 1375, Loss: 0.011990585800958797, Final Batch Loss: 0.0002927824389189482\n",
      "Epoch 1376, Loss: 0.000962198173510842, Final Batch Loss: 0.0001170669129351154\n",
      "Epoch 1377, Loss: 0.0029140198312234133, Final Batch Loss: 0.001971500925719738\n",
      "Epoch 1378, Loss: 0.00523961809813045, Final Batch Loss: 0.004193474072962999\n",
      "Epoch 1379, Loss: 0.0055385190062224865, Final Batch Loss: 0.0031927383970469236\n",
      "Epoch 1380, Loss: 0.002369977650232613, Final Batch Loss: 0.0008651238167658448\n",
      "Epoch 1381, Loss: 0.0012006940596620552, Final Batch Loss: 0.000843914458528161\n",
      "Epoch 1382, Loss: 0.00263387530867476, Final Batch Loss: 0.00020770893024746329\n",
      "Epoch 1383, Loss: 0.010625457856804132, Final Batch Loss: 0.009771997109055519\n",
      "Epoch 1384, Loss: 0.0010518316266825423, Final Batch Loss: 0.00017087585001718253\n",
      "Epoch 1385, Loss: 0.008626697692307062, Final Batch Loss: 2.326573849131819e-05\n",
      "Epoch 1386, Loss: 0.0034157400150434114, Final Batch Loss: 0.00029976540827192366\n",
      "Epoch 1387, Loss: 0.005259944584395271, Final Batch Loss: 7.496389298466966e-05\n",
      "Epoch 1388, Loss: 0.003744639085198287, Final Batch Loss: 2.7843394491355866e-05\n",
      "Epoch 1389, Loss: 0.004931164701702073, Final Batch Loss: 0.001490518799982965\n",
      "Epoch 1390, Loss: 0.0028355501272017136, Final Batch Loss: 3.2515512430109084e-05\n",
      "Epoch 1391, Loss: 0.1766837154282257, Final Batch Loss: 0.16551464796066284\n",
      "Epoch 1392, Loss: 0.0009080693307623733, Final Batch Loss: 1.8796952645061538e-05\n",
      "Epoch 1393, Loss: 0.0035639197449199855, Final Batch Loss: 0.0007922124932520092\n",
      "Epoch 1394, Loss: 0.054749173345044255, Final Batch Loss: 0.003496289486065507\n",
      "Epoch 1395, Loss: 0.07618409534916282, Final Batch Loss: 0.052115123718976974\n",
      "Epoch 1396, Loss: 0.004219569556880742, Final Batch Loss: 0.00021945394109934568\n",
      "Epoch 1397, Loss: 0.007110974518582225, Final Batch Loss: 0.0013687233440577984\n",
      "Epoch 1398, Loss: 0.004257909895386547, Final Batch Loss: 0.00014068320160731673\n",
      "Epoch 1399, Loss: 0.009812212767428719, Final Batch Loss: 0.00019397212599869817\n",
      "Epoch 1400, Loss: 0.012023112154565752, Final Batch Loss: 0.001365580945275724\n",
      "Epoch 1401, Loss: 0.025180306227412075, Final Batch Loss: 0.0006259496440179646\n",
      "Epoch 1402, Loss: 0.007129467368940823, Final Batch Loss: 0.0001939743378898129\n",
      "Epoch 1403, Loss: 0.0019186483696103096, Final Batch Loss: 0.0005563616286963224\n",
      "Epoch 1404, Loss: 0.002273968100780621, Final Batch Loss: 0.0006048582727089524\n",
      "Epoch 1405, Loss: 0.04656737530604005, Final Batch Loss: 0.036943480372428894\n",
      "Epoch 1406, Loss: 0.010233391483779997, Final Batch Loss: 0.00022621324751526117\n",
      "Epoch 1407, Loss: 0.002185044257203117, Final Batch Loss: 0.00022806526976637542\n",
      "Epoch 1408, Loss: 0.007434328057570383, Final Batch Loss: 0.0011259708553552628\n",
      "Epoch 1409, Loss: 0.058624063443858176, Final Batch Loss: 0.0006351869669742882\n",
      "Epoch 1410, Loss: 0.008441399433650076, Final Batch Loss: 0.00012767442967742682\n",
      "Epoch 1411, Loss: 0.01643660041736439, Final Batch Loss: 0.0005063120624981821\n",
      "Epoch 1412, Loss: 0.011072664114180952, Final Batch Loss: 0.000624626933131367\n",
      "Epoch 1413, Loss: 0.003477574762655422, Final Batch Loss: 0.00020334604778327048\n",
      "Epoch 1414, Loss: 0.0017252762336283922, Final Batch Loss: 0.00036788545548915863\n",
      "Epoch 1415, Loss: 0.013569517061114311, Final Batch Loss: 0.0058838059194386005\n",
      "Epoch 1416, Loss: 0.0027178855962119997, Final Batch Loss: 0.0003224598476663232\n",
      "Epoch 1417, Loss: 0.003576838586013764, Final Batch Loss: 0.001872993540018797\n",
      "Epoch 1418, Loss: 0.01817450870294124, Final Batch Loss: 0.0014536852249875665\n",
      "Epoch 1419, Loss: 0.00249584749690257, Final Batch Loss: 0.00031484992359764874\n",
      "Epoch 1420, Loss: 0.0016962835798040032, Final Batch Loss: 0.0003935322165489197\n",
      "Epoch 1421, Loss: 0.036435482499655336, Final Batch Loss: 0.034167420119047165\n",
      "Epoch 1422, Loss: 0.0019198647933080792, Final Batch Loss: 0.0007673194631934166\n",
      "Epoch 1423, Loss: 0.003502276085782796, Final Batch Loss: 0.0017442869720980525\n",
      "Epoch 1424, Loss: 0.014897165005095303, Final Batch Loss: 0.00026110082399100065\n",
      "Epoch 1425, Loss: 0.003475665987934917, Final Batch Loss: 0.0005581130390055478\n",
      "Epoch 1426, Loss: 0.0017698476876830682, Final Batch Loss: 9.291117021348327e-05\n",
      "Epoch 1427, Loss: 0.0034183844982180744, Final Batch Loss: 0.0004382542392704636\n",
      "Epoch 1428, Loss: 0.015846367576159537, Final Batch Loss: 0.0011957433307543397\n",
      "Epoch 1429, Loss: 0.004107089058379643, Final Batch Loss: 0.00019369534857105464\n",
      "Epoch 1430, Loss: 0.0037074710126034915, Final Batch Loss: 0.0024410616606473923\n",
      "Epoch 1431, Loss: 0.005144392838701606, Final Batch Loss: 0.0010014793369919062\n",
      "Epoch 1432, Loss: 0.002699879987630993, Final Batch Loss: 0.0007496676407754421\n",
      "Epoch 1433, Loss: 0.0030098994611762464, Final Batch Loss: 0.0009456885163672268\n",
      "Epoch 1434, Loss: 0.003015556721948087, Final Batch Loss: 0.00017816288163885474\n",
      "Epoch 1435, Loss: 0.005544608284253627, Final Batch Loss: 0.00415283627808094\n",
      "Epoch 1436, Loss: 0.0036420305841602385, Final Batch Loss: 0.00013655266957357526\n",
      "Epoch 1437, Loss: 0.005522213643416762, Final Batch Loss: 0.00029163534054532647\n",
      "Epoch 1438, Loss: 0.00754140957724303, Final Batch Loss: 0.00015936826821416616\n",
      "Epoch 1439, Loss: 0.0022146303963381797, Final Batch Loss: 0.00033705923124216497\n",
      "Epoch 1440, Loss: 0.006516062487207819, Final Batch Loss: 7.984514377312735e-05\n",
      "Epoch 1441, Loss: 0.010580530652077869, Final Batch Loss: 0.000129201594972983\n",
      "Epoch 1442, Loss: 0.0012209255946800113, Final Batch Loss: 0.0004897823091596365\n",
      "Epoch 1443, Loss: 0.03267342410981655, Final Batch Loss: 0.03007703274488449\n",
      "Epoch 1444, Loss: 0.008064508205279708, Final Batch Loss: 0.000896622717846185\n",
      "Epoch 1445, Loss: 0.0023841908550821245, Final Batch Loss: 0.0013096818001940846\n",
      "Epoch 1446, Loss: 0.0035518945660442114, Final Batch Loss: 0.0006457295385189354\n",
      "Epoch 1447, Loss: 0.003199926344677806, Final Batch Loss: 0.0006637195474468172\n",
      "Epoch 1448, Loss: 0.007097757370502222, Final Batch Loss: 9.893754759104922e-05\n",
      "Epoch 1449, Loss: 0.0012354891077848151, Final Batch Loss: 9.181104542221874e-05\n",
      "Epoch 1450, Loss: 0.0020723692141473293, Final Batch Loss: 0.00037548376712948084\n",
      "Epoch 1451, Loss: 0.0022187726572155952, Final Batch Loss: 0.0006226570112630725\n",
      "Epoch 1452, Loss: 0.0016776555348769762, Final Batch Loss: 0.00011478758096927777\n",
      "Epoch 1453, Loss: 0.0019163205579388887, Final Batch Loss: 0.0005795388715341687\n",
      "Epoch 1454, Loss: 0.0022403079929063097, Final Batch Loss: 0.0001956278720172122\n",
      "Epoch 1455, Loss: 0.0016135720070451498, Final Batch Loss: 0.00012371825869195163\n",
      "Epoch 1456, Loss: 0.002495637396350503, Final Batch Loss: 0.0005222879117354751\n",
      "Epoch 1457, Loss: 0.0023845358518883586, Final Batch Loss: 0.0007496295147575438\n",
      "Epoch 1458, Loss: 0.006758628267562017, Final Batch Loss: 0.00037381271249614656\n",
      "Epoch 1459, Loss: 0.0026167287142015994, Final Batch Loss: 0.000714567955583334\n",
      "Epoch 1460, Loss: 0.00133310399542097, Final Batch Loss: 7.658520189579576e-05\n",
      "Epoch 1461, Loss: 0.002412282978184521, Final Batch Loss: 0.00042250208207406104\n",
      "Epoch 1462, Loss: 0.028241725492989644, Final Batch Loss: 0.026703987270593643\n",
      "Epoch 1463, Loss: 0.0031480221077799797, Final Batch Loss: 5.9495214372873306e-05\n",
      "Epoch 1464, Loss: 0.004232427920214832, Final Batch Loss: 0.0003759144456125796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1465, Loss: 0.008041502413107082, Final Batch Loss: 0.006232371553778648\n",
      "Epoch 1466, Loss: 0.0018819593533407897, Final Batch Loss: 0.00015265060937963426\n",
      "Epoch 1467, Loss: 0.0068617867364082485, Final Batch Loss: 9.208029950968921e-05\n",
      "Epoch 1468, Loss: 0.007638436276465654, Final Batch Loss: 0.0006480918382294476\n",
      "Epoch 1469, Loss: 0.0014695694553665817, Final Batch Loss: 0.00038657349068671465\n",
      "Epoch 1470, Loss: 0.001026072357490193, Final Batch Loss: 0.00010975225450238213\n",
      "Epoch 1471, Loss: 0.011369228333933279, Final Batch Loss: 0.00033768333378247917\n",
      "Epoch 1472, Loss: 0.001003940706141293, Final Batch Loss: 0.0001224921434186399\n",
      "Epoch 1473, Loss: 0.003656675515230745, Final Batch Loss: 0.0015480427537113428\n",
      "Epoch 1474, Loss: 0.002433596004266292, Final Batch Loss: 0.0007195458747446537\n",
      "Epoch 1475, Loss: 0.006493127984867897, Final Batch Loss: 0.00010211587505182251\n",
      "Epoch 1476, Loss: 0.004872737918049097, Final Batch Loss: 0.0017456429777666926\n",
      "Epoch 1477, Loss: 0.0030195885919965804, Final Batch Loss: 0.0003496222198009491\n",
      "Epoch 1478, Loss: 0.005857716460013762, Final Batch Loss: 0.00029763850034214556\n",
      "Epoch 1479, Loss: 0.01892798303742893, Final Batch Loss: 0.0002720991906244308\n",
      "Epoch 1480, Loss: 0.011013282521162182, Final Batch Loss: 0.0009412882500328124\n",
      "Epoch 1481, Loss: 0.007225145353004336, Final Batch Loss: 0.001020135940052569\n",
      "Epoch 1482, Loss: 0.016288752027321607, Final Batch Loss: 0.001887517049908638\n",
      "Epoch 1483, Loss: 0.014538206916768104, Final Batch Loss: 0.0005906496080569923\n",
      "Epoch 1484, Loss: 0.004117743228562176, Final Batch Loss: 0.003108750097453594\n",
      "Epoch 1485, Loss: 0.008001594149391167, Final Batch Loss: 0.0001391721743857488\n",
      "Epoch 1486, Loss: 0.014302923809736967, Final Batch Loss: 0.0017649214714765549\n",
      "Epoch 1487, Loss: 0.0008916212427720893, Final Batch Loss: 4.928220369038172e-05\n",
      "Epoch 1488, Loss: 0.0032211285943049006, Final Batch Loss: 0.00010238814138574526\n",
      "Epoch 1489, Loss: 0.008213193679694086, Final Batch Loss: 0.0017010702285915613\n",
      "Epoch 1490, Loss: 0.00727979707880877, Final Batch Loss: 0.00039177676080726087\n",
      "Epoch 1491, Loss: 0.006717180192936212, Final Batch Loss: 5.833116301801056e-05\n",
      "Epoch 1492, Loss: 0.0015237216866808012, Final Batch Loss: 0.00017757814202923328\n",
      "Epoch 1493, Loss: 0.002387402346357703, Final Batch Loss: 0.001121549867093563\n",
      "Epoch 1494, Loss: 0.0022776441765017807, Final Batch Loss: 0.0005407269345596433\n",
      "Epoch 1495, Loss: 0.022106257471023127, Final Batch Loss: 0.021094193682074547\n",
      "Epoch 1496, Loss: 0.0016728006594348699, Final Batch Loss: 0.0005813551251776516\n",
      "Epoch 1497, Loss: 0.018049535967293195, Final Batch Loss: 0.000194158565136604\n",
      "Epoch 1498, Loss: 0.00945536929066293, Final Batch Loss: 6.494804983958602e-05\n",
      "Epoch 1499, Loss: 0.001193573756609112, Final Batch Loss: 0.0003150625270791352\n",
      "Epoch 1500, Loss: 0.011650547341560014, Final Batch Loss: 0.00022828341752756387\n",
      "Epoch 1501, Loss: 0.0007071105792419985, Final Batch Loss: 0.00018225707754027098\n",
      "Epoch 1502, Loss: 0.0049473384278826416, Final Batch Loss: 0.0024487427435815334\n",
      "Epoch 1503, Loss: 0.0009251972805941477, Final Batch Loss: 0.00011369117419235408\n",
      "Epoch 1504, Loss: 0.03125742945121601, Final Batch Loss: 0.0007504262612201273\n",
      "Epoch 1505, Loss: 0.0016594639891991392, Final Batch Loss: 0.00025654034106992185\n",
      "Epoch 1506, Loss: 0.004511669161729515, Final Batch Loss: 0.000531278841663152\n",
      "Epoch 1507, Loss: 0.002766163321211934, Final Batch Loss: 0.0018944028997793794\n",
      "Epoch 1508, Loss: 0.007404028729069978, Final Batch Loss: 0.0003238823264837265\n",
      "Epoch 1509, Loss: 0.001836123998145922, Final Batch Loss: 1.3312941518961452e-05\n",
      "Epoch 1510, Loss: 0.0020331356208771467, Final Batch Loss: 0.0001937542692758143\n",
      "Epoch 1511, Loss: 0.0009718630462884903, Final Batch Loss: 0.00019047738169319928\n",
      "Epoch 1512, Loss: 0.001223128114361316, Final Batch Loss: 0.00015092553803697228\n",
      "Epoch 1513, Loss: 0.0018283892422914505, Final Batch Loss: 0.0004397742741275579\n",
      "Epoch 1514, Loss: 0.0015906121598163736, Final Batch Loss: 9.940607014868874e-06\n",
      "Epoch 1515, Loss: 0.0067333137631067075, Final Batch Loss: 8.711071131983772e-05\n",
      "Epoch 1516, Loss: 0.006377837562467903, Final Batch Loss: 9.353843051940203e-05\n",
      "Epoch 1517, Loss: 0.009110596991376951, Final Batch Loss: 0.00821478758007288\n",
      "Epoch 1518, Loss: 0.0014808488267590292, Final Batch Loss: 0.00011261169129284099\n",
      "Epoch 1519, Loss: 0.00036212393024470657, Final Batch Loss: 5.990155477775261e-05\n",
      "Epoch 1520, Loss: 0.0062021590492804535, Final Batch Loss: 9.793329081730917e-05\n",
      "Epoch 1521, Loss: 0.006298312306171283, Final Batch Loss: 0.0006710290326736867\n",
      "Epoch 1522, Loss: 0.0011386649202904664, Final Batch Loss: 0.00011105437442893162\n",
      "Epoch 1523, Loss: 0.0007145019953895826, Final Batch Loss: 5.315109228831716e-05\n",
      "Epoch 1524, Loss: 0.0005579788594332058, Final Batch Loss: 3.061887764488347e-05\n",
      "Epoch 1525, Loss: 0.0026300581521354616, Final Batch Loss: 0.0020592964719980955\n",
      "Epoch 1526, Loss: 0.004478342685615644, Final Batch Loss: 0.00014654028927907348\n",
      "Epoch 1527, Loss: 0.00684000829278375, Final Batch Loss: 3.3210886613233015e-05\n",
      "Epoch 1528, Loss: 0.0012605965894181281, Final Batch Loss: 0.0002978790726047009\n",
      "Epoch 1529, Loss: 0.006320802582195029, Final Batch Loss: 0.0002776330802589655\n",
      "Epoch 1530, Loss: 0.002440769283566624, Final Batch Loss: 0.00013770093210041523\n",
      "Epoch 1531, Loss: 0.0013482506619766355, Final Batch Loss: 0.00023944172426126897\n",
      "Epoch 1532, Loss: 0.02712664066348225, Final Batch Loss: 0.026290791109204292\n",
      "Epoch 1533, Loss: 0.0120272985950578, Final Batch Loss: 0.00022702434216625988\n",
      "Epoch 1534, Loss: 0.007908735773526132, Final Batch Loss: 0.002998794661834836\n",
      "Epoch 1535, Loss: 0.00228343651178875, Final Batch Loss: 2.1236923203105107e-05\n",
      "Epoch 1536, Loss: 0.008802084368653595, Final Batch Loss: 0.0006177685572765768\n",
      "Epoch 1537, Loss: 0.009584500759956427, Final Batch Loss: 0.008621212095022202\n",
      "Epoch 1538, Loss: 0.009801157371839508, Final Batch Loss: 0.0002813996688928455\n",
      "Epoch 1539, Loss: 0.0021707458872697316, Final Batch Loss: 9.451331425225362e-05\n",
      "Epoch 1540, Loss: 0.0034667688014451414, Final Batch Loss: 0.0008592968806624413\n",
      "Epoch 1541, Loss: 0.009115403117903043, Final Batch Loss: 0.00010462423233548179\n",
      "Epoch 1542, Loss: 0.0013953717425465584, Final Batch Loss: 0.0003394709783606231\n",
      "Epoch 1543, Loss: 0.007901784410933033, Final Batch Loss: 6.335947546176612e-05\n",
      "Epoch 1544, Loss: 0.0012063624162692577, Final Batch Loss: 0.00012268676073290408\n",
      "Epoch 1545, Loss: 0.006445278006140143, Final Batch Loss: 0.001987338764593005\n",
      "Epoch 1546, Loss: 0.001371380320051685, Final Batch Loss: 5.205435445532203e-05\n",
      "Epoch 1547, Loss: 0.0018021389842033386, Final Batch Loss: 2.3075612261891365e-05\n",
      "Epoch 1548, Loss: 0.0011042640380765079, Final Batch Loss: 1.2203772712382488e-05\n",
      "Epoch 1549, Loss: 0.0010671823024495097, Final Batch Loss: 5.434433205664391e-06\n",
      "Epoch 1550, Loss: 0.0007823614432709292, Final Batch Loss: 3.759638639166951e-05\n",
      "Epoch 1551, Loss: 0.0008510954030498397, Final Batch Loss: 3.857895717374049e-05\n",
      "Epoch 1552, Loss: 0.004798392110387795, Final Batch Loss: 0.001437586615793407\n",
      "Epoch 1553, Loss: 0.024121802678564563, Final Batch Loss: 0.0231894813477993\n",
      "Epoch 1554, Loss: 0.0015188739052973688, Final Batch Loss: 0.0004921119543723762\n",
      "Epoch 1555, Loss: 0.0027027622854802758, Final Batch Loss: 0.000947683525737375\n",
      "Epoch 1556, Loss: 0.01591041113715619, Final Batch Loss: 0.0009340753313153982\n",
      "Epoch 1557, Loss: 0.0012220137869007885, Final Batch Loss: 0.0005518674734048545\n",
      "Epoch 1558, Loss: 0.0029017409251537174, Final Batch Loss: 0.0013267415342852473\n",
      "Epoch 1559, Loss: 0.0020011226733913645, Final Batch Loss: 0.00038469917490147054\n",
      "Epoch 1560, Loss: 0.0011659323645289987, Final Batch Loss: 0.00029499619267880917\n",
      "Epoch 1561, Loss: 0.0010475655071786605, Final Batch Loss: 6.700633821310475e-05\n",
      "Epoch 1562, Loss: 0.0022642350231762975, Final Batch Loss: 0.000852768833283335\n",
      "Epoch 1563, Loss: 0.002749977633357048, Final Batch Loss: 0.0005206090281717479\n",
      "Epoch 1564, Loss: 0.0012746195134241134, Final Batch Loss: 0.00024304259568452835\n",
      "Epoch 1565, Loss: 0.0006152068435767433, Final Batch Loss: 1.6039664842537604e-05\n",
      "Epoch 1566, Loss: 0.0008871580575942062, Final Batch Loss: 1.7372592992614955e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1567, Loss: 0.0015491153462789953, Final Batch Loss: 0.0002208924270235002\n",
      "Epoch 1568, Loss: 0.0017294532881351188, Final Batch Loss: 8.181022712960839e-05\n",
      "Epoch 1569, Loss: 0.0007122469069145154, Final Batch Loss: 1.0382271284470335e-05\n",
      "Epoch 1570, Loss: 0.0014316977685666643, Final Batch Loss: 0.00010956436017295346\n",
      "Epoch 1571, Loss: 0.0011807839473476633, Final Batch Loss: 0.00018343575356993824\n",
      "Epoch 1572, Loss: 0.0014987398608354852, Final Batch Loss: 0.0011232738615944982\n",
      "Epoch 1573, Loss: 0.00202874414389953, Final Batch Loss: 0.001124442322179675\n",
      "Epoch 1574, Loss: 0.012421458668541163, Final Batch Loss: 0.0003627643163781613\n",
      "Epoch 1575, Loss: 0.0012815825175493956, Final Batch Loss: 0.000540207780431956\n",
      "Epoch 1576, Loss: 0.0006219031347427517, Final Batch Loss: 0.00010716074029915035\n",
      "Epoch 1577, Loss: 0.0013722460716962814, Final Batch Loss: 0.00011329009430482984\n",
      "Epoch 1578, Loss: 0.0026237115052936133, Final Batch Loss: 2.6689867809182033e-05\n",
      "Epoch 1579, Loss: 0.011703413212671876, Final Batch Loss: 0.00024808035232126713\n",
      "Epoch 1580, Loss: 0.0025875810242723674, Final Batch Loss: 0.0016296058893203735\n",
      "Epoch 1581, Loss: 0.0016158582002390176, Final Batch Loss: 0.0004987627035006881\n",
      "Epoch 1582, Loss: 0.020061533809894172, Final Batch Loss: 1.051544586516684e-05\n",
      "Epoch 1583, Loss: 0.0022247724409680814, Final Batch Loss: 1.8186663510277867e-05\n",
      "Epoch 1584, Loss: 0.00298785709310323, Final Batch Loss: 0.0013997560599818826\n",
      "Epoch 1585, Loss: 0.0005918108217883855, Final Batch Loss: 5.419326771516353e-05\n",
      "Epoch 1586, Loss: 0.0009129698883043602, Final Batch Loss: 0.0003486917703412473\n",
      "Epoch 1587, Loss: 0.0037104212569829542, Final Batch Loss: 2.2215292119653895e-05\n",
      "Epoch 1588, Loss: 0.0009660196083132178, Final Batch Loss: 0.00016490076086483896\n",
      "Epoch 1589, Loss: 0.0006684087056783028, Final Batch Loss: 7.451000419678167e-05\n",
      "Epoch 1590, Loss: 0.004263425100361928, Final Batch Loss: 0.0010419259779155254\n",
      "Epoch 1591, Loss: 0.03122194027673686, Final Batch Loss: 0.0010386024368926883\n",
      "Epoch 1592, Loss: 0.001239138888195157, Final Batch Loss: 0.0005845976411364973\n",
      "Epoch 1593, Loss: 0.0020246772473910823, Final Batch Loss: 0.001057651243172586\n",
      "Epoch 1594, Loss: 0.0014799329510424286, Final Batch Loss: 0.0002454473578836769\n",
      "Epoch 1595, Loss: 0.003588481224142015, Final Batch Loss: 0.001504538580775261\n",
      "Epoch 1596, Loss: 0.001179632032290101, Final Batch Loss: 0.00045940958079881966\n",
      "Epoch 1597, Loss: 0.0005115679523441941, Final Batch Loss: 8.097296813502908e-05\n",
      "Epoch 1598, Loss: 0.03356565101421438, Final Batch Loss: 0.00018142149201594293\n",
      "Epoch 1599, Loss: 0.005491050222190097, Final Batch Loss: 0.004594933241605759\n",
      "Epoch 1600, Loss: 0.001977837266167626, Final Batch Loss: 0.0003292790788691491\n",
      "Epoch 1601, Loss: 0.004652391202398576, Final Batch Loss: 0.00023631415388081223\n",
      "Epoch 1602, Loss: 0.0046348734467756, Final Batch Loss: 0.0037357532419264317\n",
      "Epoch 1603, Loss: 0.006705598687403835, Final Batch Loss: 7.450646080542356e-05\n",
      "Epoch 1604, Loss: 0.0020439779764274135, Final Batch Loss: 0.0001263620360987261\n",
      "Epoch 1605, Loss: 0.004621126077836379, Final Batch Loss: 0.00024845721782185137\n",
      "Epoch 1606, Loss: 0.07004840119043365, Final Batch Loss: 0.06469914317131042\n",
      "Epoch 1607, Loss: 0.0016319946444127709, Final Batch Loss: 0.000674400303978473\n",
      "Epoch 1608, Loss: 0.02193994913250208, Final Batch Loss: 0.017807794734835625\n",
      "Epoch 1609, Loss: 0.03846761130262166, Final Batch Loss: 0.024478314444422722\n",
      "Epoch 1610, Loss: 0.0029109298338880762, Final Batch Loss: 0.00023878457432147115\n",
      "Epoch 1611, Loss: 0.019152265280354186, Final Batch Loss: 2.3404840248986147e-05\n",
      "Epoch 1612, Loss: 0.040304665970325004, Final Batch Loss: 0.0001116990388254635\n",
      "Epoch 1613, Loss: 0.003177965758368373, Final Batch Loss: 0.0013292862568050623\n",
      "Epoch 1614, Loss: 0.011332701789797284, Final Batch Loss: 0.0008849505102261901\n",
      "Epoch 1615, Loss: 0.033928226825082675, Final Batch Loss: 0.0004783894692081958\n",
      "Epoch 1616, Loss: 0.03129704469756689, Final Batch Loss: 0.026295313611626625\n",
      "Epoch 1617, Loss: 0.016643144972476875, Final Batch Loss: 5.213133044890128e-05\n",
      "Epoch 1618, Loss: 0.004939290942274965, Final Batch Loss: 0.00016872449486982077\n",
      "Epoch 1619, Loss: 0.13913607370341197, Final Batch Loss: 0.1346929520368576\n",
      "Epoch 1620, Loss: 0.00230859374278225, Final Batch Loss: 0.0004460801719687879\n",
      "Epoch 1621, Loss: 0.03302731394069269, Final Batch Loss: 0.0005232871626503766\n",
      "Epoch 1622, Loss: 0.06967703439295292, Final Batch Loss: 0.029998335987329483\n",
      "Epoch 1623, Loss: 0.012373239442240447, Final Batch Loss: 0.009093252941966057\n",
      "Epoch 1624, Loss: 0.0014192809248925187, Final Batch Loss: 2.5802590243984014e-05\n",
      "Epoch 1625, Loss: 0.0024098959984257817, Final Batch Loss: 0.001398436725139618\n",
      "Epoch 1626, Loss: 0.0017838221392594278, Final Batch Loss: 0.0005141574656590819\n",
      "Epoch 1627, Loss: 0.0018533580732764676, Final Batch Loss: 5.241537292022258e-05\n",
      "Epoch 1628, Loss: 0.022588183128391393, Final Batch Loss: 0.00017960714467335492\n",
      "Epoch 1629, Loss: 0.01604035042691976, Final Batch Loss: 0.00026464363327249885\n",
      "Epoch 1630, Loss: 0.003058259084355086, Final Batch Loss: 0.0015898451674729586\n",
      "Epoch 1631, Loss: 0.002506594988517463, Final Batch Loss: 0.0006455225520767272\n",
      "Epoch 1632, Loss: 0.01112784305587411, Final Batch Loss: 0.001675024745054543\n",
      "Epoch 1633, Loss: 0.004951159935444593, Final Batch Loss: 0.0009822160936892033\n",
      "Epoch 1634, Loss: 0.0036924836967955343, Final Batch Loss: 1.8620739865582436e-05\n",
      "Epoch 1635, Loss: 0.012623568443814293, Final Batch Loss: 0.005511756055057049\n",
      "Epoch 1636, Loss: 0.002164449426345527, Final Batch Loss: 0.0010486653773114085\n",
      "Epoch 1637, Loss: 0.009768091142177582, Final Batch Loss: 0.002606957219541073\n",
      "Epoch 1638, Loss: 0.004666677414206788, Final Batch Loss: 0.0002021601831074804\n",
      "Epoch 1639, Loss: 0.0009402633040735964, Final Batch Loss: 3.289035885245539e-05\n",
      "Epoch 1640, Loss: 0.0018318674410693347, Final Batch Loss: 0.0005280100158415735\n",
      "Epoch 1641, Loss: 0.008588398457504809, Final Batch Loss: 0.0017881026724353433\n",
      "Epoch 1642, Loss: 0.004920099745504558, Final Batch Loss: 0.00018885187455452979\n",
      "Epoch 1643, Loss: 0.12808961107657524, Final Batch Loss: 0.12676435708999634\n",
      "Epoch 1644, Loss: 0.0012598833927768283, Final Batch Loss: 5.037654045736417e-05\n",
      "Epoch 1645, Loss: 0.003809587098658085, Final Batch Loss: 0.002629432827234268\n",
      "Epoch 1646, Loss: 0.00860036414815113, Final Batch Loss: 0.0006516328430734575\n",
      "Epoch 1647, Loss: 0.0014629986544605345, Final Batch Loss: 0.00022732597426511347\n",
      "Epoch 1648, Loss: 0.005875789727724623, Final Batch Loss: 7.251532952068374e-05\n",
      "Epoch 1649, Loss: 0.0016666373703628778, Final Batch Loss: 0.000492321269121021\n",
      "Epoch 1650, Loss: 0.0021282591187627986, Final Batch Loss: 0.001160376239567995\n",
      "Epoch 1651, Loss: 0.019314528442919254, Final Batch Loss: 0.01766757108271122\n",
      "Epoch 1652, Loss: 0.0008766302198637277, Final Batch Loss: 0.0001137631043093279\n",
      "Epoch 1653, Loss: 0.006071032345062122, Final Batch Loss: 0.0005019063246436417\n",
      "Epoch 1654, Loss: 0.0015178939829638693, Final Batch Loss: 5.198596409172751e-05\n",
      "Epoch 1655, Loss: 0.002562514040619135, Final Batch Loss: 0.00020592112559825182\n",
      "Epoch 1656, Loss: 0.001213277704664506, Final Batch Loss: 0.00014523339632432908\n",
      "Epoch 1657, Loss: 0.0019000115571543574, Final Batch Loss: 0.00048399704974144697\n",
      "Epoch 1658, Loss: 0.0015721227682661265, Final Batch Loss: 6.841489812359214e-05\n",
      "Epoch 1659, Loss: 0.028809892373828916, Final Batch Loss: 5.8635498135117814e-05\n",
      "Epoch 1660, Loss: 0.0037973284197505563, Final Batch Loss: 0.002586911665275693\n",
      "Epoch 1661, Loss: 0.007031194283626974, Final Batch Loss: 0.006204517558217049\n",
      "Epoch 1662, Loss: 0.002323357795830816, Final Batch Loss: 0.0003024740144610405\n",
      "Epoch 1663, Loss: 0.0023625569010619074, Final Batch Loss: 0.0004045307287015021\n",
      "Epoch 1664, Loss: 0.0018634350271895528, Final Batch Loss: 0.0008706891676411033\n",
      "Epoch 1665, Loss: 0.00570049523958005, Final Batch Loss: 0.004837172105908394\n",
      "Epoch 1666, Loss: 0.010815995454322547, Final Batch Loss: 0.0003227027482353151\n",
      "Epoch 1667, Loss: 0.005460213636979461, Final Batch Loss: 0.0011029548477381468\n",
      "Epoch 1668, Loss: 0.0019945842650486156, Final Batch Loss: 0.0001850444677984342\n",
      "Epoch 1669, Loss: 0.001529340079287067, Final Batch Loss: 0.0006192804430611432\n",
      "Epoch 1670, Loss: 0.0027299034991301596, Final Batch Loss: 0.0002238591550849378\n",
      "Epoch 1671, Loss: 0.006130880516138859, Final Batch Loss: 0.001085346331819892\n",
      "Epoch 1672, Loss: 0.0014790108034503646, Final Batch Loss: 0.00011878691293532029\n",
      "Epoch 1673, Loss: 0.001963828457519412, Final Batch Loss: 0.0005918305250816047\n",
      "Epoch 1674, Loss: 0.0060531404305947945, Final Batch Loss: 0.0004310770018491894\n",
      "Epoch 1675, Loss: 0.0065758832497522235, Final Batch Loss: 0.0007340279407799244\n",
      "Epoch 1676, Loss: 0.0017203350435011089, Final Batch Loss: 7.601332617923617e-05\n",
      "Epoch 1677, Loss: 0.0008870961173670366, Final Batch Loss: 0.00020990763732697815\n",
      "Epoch 1678, Loss: 0.0010007437667809427, Final Batch Loss: 0.00026706207427196205\n",
      "Epoch 1679, Loss: 0.00284962217847351, Final Batch Loss: 0.00013323161692824215\n",
      "Epoch 1680, Loss: 0.0009554709540680051, Final Batch Loss: 0.00011443332186900079\n",
      "Epoch 1681, Loss: 0.0018047909688903019, Final Batch Loss: 0.0010443102801218629\n",
      "Epoch 1682, Loss: 0.006239929731236771, Final Batch Loss: 0.005187319591641426\n",
      "Epoch 1683, Loss: 0.001172905438579619, Final Batch Loss: 0.00018418030231259763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1684, Loss: 0.009336464339867234, Final Batch Loss: 0.001032523694448173\n",
      "Epoch 1685, Loss: 0.0017284707864746451, Final Batch Loss: 0.0004489563871175051\n",
      "Epoch 1686, Loss: 0.0026690659869927913, Final Batch Loss: 0.0010546647245064378\n",
      "Epoch 1687, Loss: 0.00834061170462519, Final Batch Loss: 0.002433215267956257\n",
      "Epoch 1688, Loss: 0.0013437783491099253, Final Batch Loss: 6.182417564559728e-05\n",
      "Epoch 1689, Loss: 0.010759183907794068, Final Batch Loss: 5.9813031839439645e-05\n",
      "Epoch 1690, Loss: 0.0006698081124341115, Final Batch Loss: 0.00021671778813470155\n",
      "Epoch 1691, Loss: 0.0017042096660588868, Final Batch Loss: 6.837072578491643e-05\n",
      "Epoch 1692, Loss: 0.0015615444717695937, Final Batch Loss: 0.0010916517348960042\n",
      "Epoch 1693, Loss: 0.001403602393111214, Final Batch Loss: 0.0002208788355346769\n",
      "Epoch 1694, Loss: 0.005128635631990619, Final Batch Loss: 0.00019661687838379294\n",
      "Epoch 1695, Loss: 0.008345300193468574, Final Batch Loss: 8.847317803883925e-05\n",
      "Epoch 1696, Loss: 0.0011098832401330583, Final Batch Loss: 3.7136363971512765e-05\n",
      "Epoch 1697, Loss: 0.009431161030079238, Final Batch Loss: 5.029675958212465e-05\n",
      "Epoch 1698, Loss: 0.0009267029236070812, Final Batch Loss: 9.80173354037106e-05\n",
      "Epoch 1699, Loss: 0.0006726445644744672, Final Batch Loss: 5.968036566628143e-05\n",
      "Epoch 1700, Loss: 0.0010487413001101231, Final Batch Loss: 2.7580177629715763e-05\n",
      "Epoch 1701, Loss: 0.001333687047008425, Final Batch Loss: 0.00036384700797498226\n",
      "Epoch 1702, Loss: 0.0013799659645883366, Final Batch Loss: 0.00015893839008640498\n",
      "Epoch 1703, Loss: 0.01185297459596768, Final Batch Loss: 0.00030105822952464223\n",
      "Epoch 1704, Loss: 0.005249449313851073, Final Batch Loss: 0.00129775982350111\n",
      "Epoch 1705, Loss: 0.006807152982219122, Final Batch Loss: 0.00023107619199436158\n",
      "Epoch 1706, Loss: 0.0008535575907444581, Final Batch Loss: 5.675783904734999e-05\n",
      "Epoch 1707, Loss: 0.0012334383700363105, Final Batch Loss: 2.407319516350981e-05\n",
      "Epoch 1708, Loss: 0.02419388738053385, Final Batch Loss: 0.00031152027077041566\n",
      "Epoch 1709, Loss: 0.005825083644594997, Final Batch Loss: 0.0006225326796993613\n",
      "Epoch 1710, Loss: 0.020275219867471606, Final Batch Loss: 0.0009638389456085861\n",
      "Epoch 1711, Loss: 0.005944269330939278, Final Batch Loss: 0.00012084559421055019\n",
      "Epoch 1712, Loss: 0.0012802365017705597, Final Batch Loss: 3.786429442698136e-05\n",
      "Epoch 1713, Loss: 0.0009924582263920456, Final Batch Loss: 0.00021318909421097487\n",
      "Epoch 1714, Loss: 0.0011028333101421595, Final Batch Loss: 0.0005787303671240807\n",
      "Epoch 1715, Loss: 0.002523005736293271, Final Batch Loss: 0.0012688500573858619\n",
      "Epoch 1716, Loss: 0.009171871817670763, Final Batch Loss: 0.004394871648401022\n",
      "Epoch 1717, Loss: 0.010445932653965428, Final Batch Loss: 0.0025602062232792377\n",
      "Epoch 1718, Loss: 0.0051103918813169, Final Batch Loss: 0.003191672032698989\n",
      "Epoch 1719, Loss: 0.0009924990881700069, Final Batch Loss: 0.0002875009085983038\n",
      "Epoch 1720, Loss: 0.00143088806362357, Final Batch Loss: 0.00015997390437405556\n",
      "Epoch 1721, Loss: 0.0029336646548472345, Final Batch Loss: 0.00012408779002726078\n",
      "Epoch 1722, Loss: 0.0006271045858738944, Final Batch Loss: 6.999913603067398e-05\n",
      "Epoch 1723, Loss: 0.00483183708274737, Final Batch Loss: 0.002801318187266588\n",
      "Epoch 1724, Loss: 0.0015220779168885201, Final Batch Loss: 0.00019581924425438046\n",
      "Epoch 1725, Loss: 0.0010899097542278469, Final Batch Loss: 0.0003206698165740818\n",
      "Epoch 1726, Loss: 0.0008790320753178094, Final Batch Loss: 5.3902189392829314e-05\n",
      "Epoch 1727, Loss: 0.0005691406549885869, Final Batch Loss: 0.0002246382209705189\n",
      "Epoch 1728, Loss: 0.001169079536339268, Final Batch Loss: 0.0004952880553901196\n",
      "Epoch 1729, Loss: 0.006106849730713293, Final Batch Loss: 0.00015192868886515498\n",
      "Epoch 1730, Loss: 0.0009720295383885968, Final Batch Loss: 5.160277578397654e-05\n",
      "Epoch 1731, Loss: 0.005777156766271219, Final Batch Loss: 0.000448473118012771\n",
      "Epoch 1732, Loss: 0.025386192777659744, Final Batch Loss: 0.019547119736671448\n",
      "Epoch 1733, Loss: 0.01869155332678929, Final Batch Loss: 0.017938368022441864\n",
      "Epoch 1734, Loss: 0.002367278837482445, Final Batch Loss: 0.0018174081342294812\n",
      "Epoch 1735, Loss: 0.0010816018329933286, Final Batch Loss: 0.0005195783451199532\n",
      "Epoch 1736, Loss: 0.0021155266149435192, Final Batch Loss: 0.0002495206717867404\n",
      "Epoch 1737, Loss: 0.00078563965507783, Final Batch Loss: 7.0584675995633e-05\n",
      "Epoch 1738, Loss: 0.001168308110209182, Final Batch Loss: 9.56901058088988e-05\n",
      "Epoch 1739, Loss: 0.0038024958630558103, Final Batch Loss: 0.0026692701503634453\n",
      "Epoch 1740, Loss: 0.0005987663453197456, Final Batch Loss: 1.1393595741537865e-05\n",
      "Epoch 1741, Loss: 0.000860969623317942, Final Batch Loss: 6.384134758263826e-05\n",
      "Epoch 1742, Loss: 0.026689836813602597, Final Batch Loss: 0.025120681151747704\n",
      "Epoch 1743, Loss: 0.001738705686875619, Final Batch Loss: 1.0911709978245199e-05\n",
      "Epoch 1744, Loss: 0.007709298573900014, Final Batch Loss: 0.0020173497032374144\n",
      "Epoch 1745, Loss: 0.0008993348455987871, Final Batch Loss: 0.00018790914327837527\n",
      "Epoch 1746, Loss: 0.0007997618959052488, Final Batch Loss: 0.0001419783802703023\n",
      "Epoch 1747, Loss: 0.009640331038099248, Final Batch Loss: 4.729128704639152e-05\n",
      "Epoch 1748, Loss: 0.001488125795731321, Final Batch Loss: 0.0006793282809667289\n",
      "Epoch 1749, Loss: 0.02173537296766881, Final Batch Loss: 0.02125406451523304\n",
      "Epoch 1750, Loss: 0.007428007025737315, Final Batch Loss: 0.00267997570335865\n",
      "Epoch 1751, Loss: 0.0003622196309152059, Final Batch Loss: 3.5788347304333e-05\n",
      "Epoch 1752, Loss: 0.0006413607443391811, Final Batch Loss: 3.278238364146091e-05\n",
      "Epoch 1753, Loss: 0.0015747062861919403, Final Batch Loss: 0.0006209738785400987\n",
      "Epoch 1754, Loss: 0.0009734978666529059, Final Batch Loss: 0.00012931661331094801\n",
      "Epoch 1755, Loss: 0.01979701779782772, Final Batch Loss: 0.016317658126354218\n",
      "Epoch 1756, Loss: 0.012414889672072604, Final Batch Loss: 0.010442567989230156\n",
      "Epoch 1757, Loss: 0.02673521375982091, Final Batch Loss: 0.0005875734495930374\n",
      "Epoch 1758, Loss: 0.012711613097053487, Final Batch Loss: 0.00010309392382623628\n",
      "Epoch 1759, Loss: 0.0019148495484841987, Final Batch Loss: 0.00022638168593402952\n",
      "Epoch 1760, Loss: 0.008356567472219467, Final Batch Loss: 0.001163691165857017\n",
      "Epoch 1761, Loss: 0.012333320977631956, Final Batch Loss: 0.00016979366773739457\n",
      "Epoch 1762, Loss: 0.008221250434871763, Final Batch Loss: 0.0033788164146244526\n",
      "Epoch 1763, Loss: 0.0070668080879841, Final Batch Loss: 0.00035892464802600443\n",
      "Epoch 1764, Loss: 0.0026263196778018028, Final Batch Loss: 0.0014589903876185417\n",
      "Epoch 1765, Loss: 0.0013714282104047015, Final Batch Loss: 2.2078820620663464e-05\n",
      "Epoch 1766, Loss: 0.0018290297884959728, Final Batch Loss: 0.00026706737116910517\n",
      "Epoch 1767, Loss: 0.0010220668482361361, Final Batch Loss: 5.628298094961792e-05\n",
      "Epoch 1768, Loss: 0.011915269133169204, Final Batch Loss: 0.000635439355392009\n",
      "Epoch 1769, Loss: 0.015175955079030246, Final Batch Loss: 0.01379752904176712\n",
      "Epoch 1770, Loss: 0.0007533887110184878, Final Batch Loss: 0.00022461294429376721\n",
      "Epoch 1771, Loss: 0.0026229472423437983, Final Batch Loss: 0.0012600841000676155\n",
      "Epoch 1772, Loss: 0.0035636470856843516, Final Batch Loss: 0.002974470378831029\n",
      "Epoch 1773, Loss: 0.013394375826464966, Final Batch Loss: 0.00030466585303656757\n",
      "Epoch 1774, Loss: 0.004069114715093747, Final Batch Loss: 0.00043274564086459577\n",
      "Epoch 1775, Loss: 0.0009605139784980565, Final Batch Loss: 0.00013577137724496424\n",
      "Epoch 1776, Loss: 0.0029446239350363612, Final Batch Loss: 0.001530798734165728\n",
      "Epoch 1777, Loss: 0.0018562979676062241, Final Batch Loss: 0.00015449822240043432\n",
      "Epoch 1778, Loss: 0.011324685183353722, Final Batch Loss: 0.0012809202307835221\n",
      "Epoch 1779, Loss: 0.0011218410800211132, Final Batch Loss: 0.00013193360064178705\n",
      "Epoch 1780, Loss: 0.0012047917189192958, Final Batch Loss: 6.768626190023497e-05\n",
      "Epoch 1781, Loss: 0.0011238732258789241, Final Batch Loss: 0.0006978712044656277\n",
      "Epoch 1782, Loss: 0.004396474148961715, Final Batch Loss: 0.00022704970615450293\n",
      "Epoch 1783, Loss: 0.008015553758013994, Final Batch Loss: 0.003485431196168065\n",
      "Epoch 1784, Loss: 0.0032075788476504385, Final Batch Loss: 0.0018991065444424748\n",
      "Epoch 1785, Loss: 0.0011386156547814608, Final Batch Loss: 0.0003790377813857049\n",
      "Epoch 1786, Loss: 0.0017095913353841752, Final Batch Loss: 0.0005019951495341957\n",
      "Epoch 1787, Loss: 0.0016383549955207855, Final Batch Loss: 0.0002671829133760184\n",
      "Epoch 1788, Loss: 0.020813251176150516, Final Batch Loss: 0.0010314591927453876\n",
      "Epoch 1789, Loss: 0.001198784651933238, Final Batch Loss: 0.00018002022989094257\n",
      "Epoch 1790, Loss: 0.002536481013521552, Final Batch Loss: 0.0010907597607001662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1791, Loss: 0.005221733954385854, Final Batch Loss: 0.0001450393901905045\n",
      "Epoch 1792, Loss: 0.001739699102472514, Final Batch Loss: 0.0013763317838311195\n",
      "Epoch 1793, Loss: 0.027564852542127483, Final Batch Loss: 0.026095272973179817\n",
      "Epoch 1794, Loss: 0.0008914512727642432, Final Batch Loss: 0.00010106265835929662\n",
      "Epoch 1795, Loss: 0.0012728266956401058, Final Batch Loss: 7.811698742443696e-05\n",
      "Epoch 1796, Loss: 0.009748044998559635, Final Batch Loss: 9.331045293947682e-05\n",
      "Epoch 1797, Loss: 0.001893247797852382, Final Batch Loss: 0.0006231344304978848\n",
      "Epoch 1798, Loss: 0.002381394413532689, Final Batch Loss: 0.0006604696391150355\n",
      "Epoch 1799, Loss: 0.0024647691170684993, Final Batch Loss: 0.0008212233078666031\n",
      "Epoch 1800, Loss: 0.006098327197832987, Final Batch Loss: 0.00035523512633517385\n",
      "Epoch 1801, Loss: 0.00448391264944803, Final Batch Loss: 0.0001596006768522784\n",
      "Epoch 1802, Loss: 0.0034764420706778765, Final Batch Loss: 0.001354325795546174\n",
      "Epoch 1803, Loss: 0.0022777698177378625, Final Batch Loss: 0.00021074924734421074\n",
      "Epoch 1804, Loss: 0.0010347890347475186, Final Batch Loss: 0.0003205699904356152\n",
      "Epoch 1805, Loss: 0.0008461005563731305, Final Batch Loss: 0.0001081572481780313\n",
      "Epoch 1806, Loss: 0.001596665068063885, Final Batch Loss: 0.0005553020746447146\n",
      "Epoch 1807, Loss: 0.0004653984478864004, Final Batch Loss: 1.2953209989063907e-05\n",
      "Epoch 1808, Loss: 0.003951270955440123, Final Batch Loss: 0.0030444725416600704\n",
      "Epoch 1809, Loss: 0.011683003016514704, Final Batch Loss: 0.00030943608726374805\n",
      "Epoch 1810, Loss: 0.0009279293717554538, Final Batch Loss: 1.5208743207040243e-05\n",
      "Epoch 1811, Loss: 0.007138584216590971, Final Batch Loss: 0.0006851024809293449\n",
      "Epoch 1812, Loss: 0.0010717588156694546, Final Batch Loss: 0.00018400083354208618\n",
      "Epoch 1813, Loss: 0.0017618216224946082, Final Batch Loss: 0.0002006381400860846\n",
      "Epoch 1814, Loss: 0.005855779450939735, Final Batch Loss: 2.4370758183067665e-05\n",
      "Epoch 1815, Loss: 0.002880078500311356, Final Batch Loss: 7.334601104957983e-05\n",
      "Epoch 1816, Loss: 0.0025327579642180353, Final Batch Loss: 0.00045707583194598556\n",
      "Epoch 1817, Loss: 0.004918557329801843, Final Batch Loss: 0.0033887268509715796\n",
      "Epoch 1818, Loss: 0.001691054945695214, Final Batch Loss: 2.668924571480602e-05\n",
      "Epoch 1819, Loss: 0.007632553912117146, Final Batch Loss: 0.00018032391380984336\n",
      "Epoch 1820, Loss: 0.0062799203988106456, Final Batch Loss: 3.8716589187970385e-05\n",
      "Epoch 1821, Loss: 0.0007989959340193309, Final Batch Loss: 0.00015440222341567278\n",
      "Epoch 1822, Loss: 0.0007211822903627763, Final Batch Loss: 2.1791254766867496e-05\n",
      "Epoch 1823, Loss: 0.008953654556535184, Final Batch Loss: 0.0008700332837179303\n",
      "Epoch 1824, Loss: 0.0026517211517784745, Final Batch Loss: 0.0016996246995404363\n",
      "Epoch 1825, Loss: 0.0012846950558014214, Final Batch Loss: 0.00015426913159899414\n",
      "Epoch 1826, Loss: 0.02118484696256928, Final Batch Loss: 0.020009776577353477\n",
      "Epoch 1827, Loss: 0.0012189161643618718, Final Batch Loss: 9.738474909681827e-05\n",
      "Epoch 1828, Loss: 0.004542416223557666, Final Batch Loss: 0.004165410064160824\n",
      "Epoch 1829, Loss: 0.004666324253776111, Final Batch Loss: 5.735580634791404e-05\n",
      "Epoch 1830, Loss: 0.0009956137801054865, Final Batch Loss: 0.0003384777228347957\n",
      "Epoch 1831, Loss: 0.0005832847091369331, Final Batch Loss: 0.0001278802374145016\n",
      "Epoch 1832, Loss: 0.0015567227092105895, Final Batch Loss: 0.0004961976082995534\n",
      "Epoch 1833, Loss: 0.005136535517522134, Final Batch Loss: 0.0001613340136827901\n",
      "Epoch 1834, Loss: 0.0011582050938159227, Final Batch Loss: 0.0002772693696897477\n",
      "Epoch 1835, Loss: 0.006490172876510769, Final Batch Loss: 0.000487420242279768\n",
      "Epoch 1836, Loss: 0.0016407004441134632, Final Batch Loss: 0.0002966747561004013\n",
      "Epoch 1837, Loss: 0.0011265876237303019, Final Batch Loss: 0.00034091738052666187\n",
      "Epoch 1838, Loss: 0.0010174724302487448, Final Batch Loss: 0.0007042336510494351\n",
      "Epoch 1839, Loss: 0.0021988489461364225, Final Batch Loss: 6.498409493360668e-05\n",
      "Epoch 1840, Loss: 0.0013142228708602488, Final Batch Loss: 0.00045642603072337806\n",
      "Epoch 1841, Loss: 0.002606473135529086, Final Batch Loss: 0.00021369624300859869\n",
      "Epoch 1842, Loss: 0.0008527753670932725, Final Batch Loss: 0.00034049872192554176\n",
      "Epoch 1843, Loss: 0.0037058384623378515, Final Batch Loss: 0.002278147963806987\n",
      "Epoch 1844, Loss: 0.001176774239866063, Final Batch Loss: 0.0001789435336831957\n",
      "Epoch 1845, Loss: 0.0004977895514457487, Final Batch Loss: 9.733394108479843e-05\n",
      "Epoch 1846, Loss: 0.0029702125539188273, Final Batch Loss: 1.792908733477816e-05\n",
      "Epoch 1847, Loss: 0.003249061221140437, Final Batch Loss: 0.00245585385710001\n",
      "Epoch 1848, Loss: 0.0019795109110418707, Final Batch Loss: 0.00020299784955568612\n",
      "Epoch 1849, Loss: 0.0004499099654822203, Final Batch Loss: 4.447929768502945e-06\n",
      "Epoch 1850, Loss: 0.005942498770309612, Final Batch Loss: 4.821564652957022e-05\n",
      "Epoch 1851, Loss: 0.0008165897597791627, Final Batch Loss: 0.0001433637662557885\n",
      "Epoch 1852, Loss: 0.005642602685838938, Final Batch Loss: 0.00034709920873865485\n",
      "Epoch 1853, Loss: 0.025100198079599068, Final Batch Loss: 0.024556202813982964\n",
      "Epoch 1854, Loss: 0.0021129723099875264, Final Batch Loss: 0.0014316777233034372\n",
      "Epoch 1855, Loss: 0.006641302548814565, Final Batch Loss: 0.0005570577923208475\n",
      "Epoch 1856, Loss: 0.012767743261065334, Final Batch Loss: 0.0005252858973108232\n",
      "Epoch 1857, Loss: 0.0017014678742270917, Final Batch Loss: 0.000402280391426757\n",
      "Epoch 1858, Loss: 0.026404170304886065, Final Batch Loss: 0.0017279169987887144\n",
      "Epoch 1859, Loss: 0.0027708623820217326, Final Batch Loss: 0.00016464789223391563\n",
      "Epoch 1860, Loss: 0.0013956750481156632, Final Batch Loss: 0.00017652813403401524\n",
      "Epoch 1861, Loss: 0.013696085603442043, Final Batch Loss: 0.008775020018219948\n",
      "Epoch 1862, Loss: 0.007268120476510376, Final Batch Loss: 0.0018728113500401378\n",
      "Epoch 1863, Loss: 0.009160760135273449, Final Batch Loss: 0.0002544952731113881\n",
      "Epoch 1864, Loss: 0.0021618694154312834, Final Batch Loss: 0.0016872748965397477\n",
      "Epoch 1865, Loss: 0.010456238524056971, Final Batch Loss: 0.0010156811913475394\n",
      "Epoch 1866, Loss: 0.0036037271056557074, Final Batch Loss: 0.0001769004884408787\n",
      "Epoch 1867, Loss: 0.0017630407819524407, Final Batch Loss: 0.000802427704911679\n",
      "Epoch 1868, Loss: 0.027242244301305618, Final Batch Loss: 0.00011599723802646622\n",
      "Epoch 1869, Loss: 0.0011697851077769883, Final Batch Loss: 3.674304025480524e-05\n",
      "Epoch 1870, Loss: 0.004460906256099406, Final Batch Loss: 1.3523032066586893e-05\n",
      "Epoch 1871, Loss: 0.0030209410761017352, Final Batch Loss: 0.0022536676842719316\n",
      "Epoch 1872, Loss: 0.0021302329550962895, Final Batch Loss: 0.00012908063945360482\n",
      "Epoch 1873, Loss: 0.0004674488154705614, Final Batch Loss: 0.00010580297384876758\n",
      "Epoch 1874, Loss: 0.005276464267808478, Final Batch Loss: 0.00047580499085597694\n",
      "Epoch 1875, Loss: 0.00175845404737629, Final Batch Loss: 0.0008369297138415277\n",
      "Epoch 1876, Loss: 0.0008381130173802376, Final Batch Loss: 8.348343544639647e-05\n",
      "Epoch 1877, Loss: 0.013320888218004256, Final Batch Loss: 0.0003775719669647515\n",
      "Epoch 1878, Loss: 0.004325697162130382, Final Batch Loss: 0.0009886804036796093\n",
      "Epoch 1879, Loss: 0.0007101307892298792, Final Batch Loss: 3.8913367461645976e-05\n",
      "Epoch 1880, Loss: 0.008838080640998669, Final Batch Loss: 0.00043290219036862254\n",
      "Epoch 1881, Loss: 0.0013092421140754595, Final Batch Loss: 8.114126103464514e-05\n",
      "Epoch 1882, Loss: 0.0018500713231333066, Final Batch Loss: 3.537773227435537e-05\n",
      "Epoch 1883, Loss: 0.004228055680869147, Final Batch Loss: 0.0002552364894654602\n",
      "Epoch 1884, Loss: 0.0013698640977963805, Final Batch Loss: 0.0002917373785749078\n",
      "Epoch 1885, Loss: 0.004495845254041342, Final Batch Loss: 6.6520346990728285e-06\n",
      "Epoch 1886, Loss: 0.0012370377444312908, Final Batch Loss: 0.0008479465614072978\n",
      "Epoch 1887, Loss: 0.0012100722960894927, Final Batch Loss: 0.0006848290213383734\n",
      "Epoch 1888, Loss: 0.0007773614379402716, Final Batch Loss: 1.2583335774252191e-05\n",
      "Epoch 1889, Loss: 0.00681252425420098, Final Batch Loss: 0.0006496603018604219\n",
      "Epoch 1890, Loss: 0.006371940871758852, Final Batch Loss: 3.097437001997605e-05\n",
      "Epoch 1891, Loss: 0.0018769751186482608, Final Batch Loss: 0.0005155379767529666\n",
      "Epoch 1892, Loss: 0.0006445246108341962, Final Batch Loss: 0.00030400915420614183\n",
      "Epoch 1893, Loss: 0.0010940389474853873, Final Batch Loss: 0.0008193285320885479\n",
      "Epoch 1894, Loss: 0.011713028652593493, Final Batch Loss: 0.00010498194023966789\n",
      "Epoch 1895, Loss: 0.0009703039686428383, Final Batch Loss: 0.00019700969278346747\n",
      "Epoch 1896, Loss: 0.0014033710467629135, Final Batch Loss: 0.00032880372600629926\n",
      "Epoch 1897, Loss: 0.002403774415142834, Final Batch Loss: 0.0013061835197731853\n",
      "Epoch 1898, Loss: 0.011633951304247603, Final Batch Loss: 0.0004486056277528405\n",
      "Epoch 1899, Loss: 0.001025801379000768, Final Batch Loss: 0.0002793435996863991\n",
      "Epoch 1900, Loss: 0.0010447963140904903, Final Batch Loss: 0.00036716394242830575\n",
      "Epoch 1901, Loss: 0.002640522856381722, Final Batch Loss: 0.0001859208132373169\n",
      "Epoch 1902, Loss: 0.0067112764227204025, Final Batch Loss: 0.0004254010855220258\n",
      "Epoch 1903, Loss: 0.000842849665787071, Final Batch Loss: 0.00018538851873017848\n",
      "Epoch 1904, Loss: 0.003032285654626321, Final Batch Loss: 1.7465434211771935e-05\n",
      "Epoch 1905, Loss: 0.001855338821769692, Final Batch Loss: 0.001170627772808075\n",
      "Epoch 1906, Loss: 0.002565857459558174, Final Batch Loss: 0.00017044672858901322\n",
      "Epoch 1907, Loss: 0.00042620963358785957, Final Batch Loss: 0.00011879696103278548\n",
      "Epoch 1908, Loss: 0.006932747954124352, Final Batch Loss: 4.685122621594928e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1909, Loss: 0.0006164647274999879, Final Batch Loss: 4.274950333638117e-05\n",
      "Epoch 1910, Loss: 0.0011194282269570976, Final Batch Loss: 0.000257225357927382\n",
      "Epoch 1911, Loss: 0.0044980658567510545, Final Batch Loss: 0.00039539963472634554\n",
      "Epoch 1912, Loss: 0.000775919021180016, Final Batch Loss: 1.3175058484193869e-05\n",
      "Epoch 1913, Loss: 0.00043715482752304524, Final Batch Loss: 0.00021311125601641834\n",
      "Epoch 1914, Loss: 0.0007621735458087642, Final Batch Loss: 5.11979051225353e-05\n",
      "Epoch 1915, Loss: 0.0014045277202967554, Final Batch Loss: 0.00019739827257581055\n",
      "Epoch 1916, Loss: 0.0011380394134903327, Final Batch Loss: 0.0008066145819611847\n",
      "Epoch 1917, Loss: 0.001210467606142629, Final Batch Loss: 1.5089150110725313e-05\n",
      "Epoch 1918, Loss: 0.0008771673901719623, Final Batch Loss: 1.0812394066306297e-05\n",
      "Epoch 1919, Loss: 0.003675611354992725, Final Batch Loss: 9.373744251206517e-05\n",
      "Epoch 1920, Loss: 0.002840977569576353, Final Batch Loss: 0.0005201369058340788\n",
      "Epoch 1921, Loss: 0.00041943753967643715, Final Batch Loss: 5.961445640423335e-05\n",
      "Epoch 1922, Loss: 0.001991531200474128, Final Batch Loss: 0.0008567869081161916\n",
      "Epoch 1923, Loss: 0.0030848755268380046, Final Batch Loss: 0.0006081117317080498\n",
      "Epoch 1924, Loss: 0.0006160887824080419, Final Batch Loss: 2.5318451662315056e-05\n",
      "Epoch 1925, Loss: 0.0017318807695119176, Final Batch Loss: 5.6383538321824744e-05\n",
      "Epoch 1926, Loss: 0.001882478129118681, Final Batch Loss: 0.0003013786335941404\n",
      "Epoch 1927, Loss: 0.0060999067791271955, Final Batch Loss: 0.005555005744099617\n",
      "Epoch 1928, Loss: 0.004448839143151417, Final Batch Loss: 0.00040104673826135695\n",
      "Epoch 1929, Loss: 0.003880276926793158, Final Batch Loss: 0.0035105126444250345\n",
      "Epoch 1930, Loss: 0.0015086625917319907, Final Batch Loss: 2.0713820049422793e-05\n",
      "Epoch 1931, Loss: 0.006570506880962057, Final Batch Loss: 5.009142842027359e-05\n",
      "Epoch 1932, Loss: 0.0006094520285842009, Final Batch Loss: 0.00010972083691740409\n",
      "Epoch 1933, Loss: 0.0007191626045823796, Final Batch Loss: 2.263038004457485e-05\n",
      "Epoch 1934, Loss: 0.0005577934061875567, Final Batch Loss: 7.007431122474372e-05\n",
      "Epoch 1935, Loss: 0.0036819866800215095, Final Batch Loss: 1.670673373155296e-05\n",
      "Epoch 1936, Loss: 0.0009383252472616732, Final Batch Loss: 0.0002713357098400593\n",
      "Epoch 1937, Loss: 0.0005505956869455986, Final Batch Loss: 7.618903327966109e-05\n",
      "Epoch 1938, Loss: 0.005726657866034657, Final Batch Loss: 0.0003048240614589304\n",
      "Epoch 1939, Loss: 0.00029618549888255075, Final Batch Loss: 1.640605478314683e-05\n",
      "Epoch 1940, Loss: 0.019821138361294288, Final Batch Loss: 0.019524360075592995\n",
      "Epoch 1941, Loss: 0.0013106313272146508, Final Batch Loss: 0.000676653056871146\n",
      "Epoch 1942, Loss: 0.00018816805186361307, Final Batch Loss: 1.0709199159464333e-05\n",
      "Epoch 1943, Loss: 0.000518740960615105, Final Batch Loss: 2.613638025650289e-05\n",
      "Epoch 1944, Loss: 0.0010276866996719036, Final Batch Loss: 2.0356328604975715e-05\n",
      "Epoch 1945, Loss: 0.0051879874808946624, Final Batch Loss: 5.034978676121682e-05\n",
      "Epoch 1946, Loss: 0.001348607975160121, Final Batch Loss: 2.9100634492351674e-05\n",
      "Epoch 1947, Loss: 0.0011715171349351294, Final Batch Loss: 0.0006802799180150032\n",
      "Epoch 1948, Loss: 0.00555424066260457, Final Batch Loss: 0.00020104440045543015\n",
      "Epoch 1949, Loss: 0.001102894384530373, Final Batch Loss: 9.289915033150464e-05\n",
      "Epoch 1950, Loss: 0.00034600249637151137, Final Batch Loss: 9.265815606340766e-05\n",
      "Epoch 1951, Loss: 0.024812457500956953, Final Batch Loss: 0.02002030797302723\n",
      "Epoch 1952, Loss: 0.004804934116691584, Final Batch Loss: 4.103515311726369e-05\n",
      "Epoch 1953, Loss: 0.003333574757562019, Final Batch Loss: 0.002568682888522744\n",
      "Epoch 1954, Loss: 0.0009319104756286833, Final Batch Loss: 0.0005050496547482908\n",
      "Epoch 1955, Loss: 0.0035426589784037787, Final Batch Loss: 3.894372275681235e-05\n",
      "Epoch 1956, Loss: 0.0015753785373817664, Final Batch Loss: 0.0012837767135351896\n",
      "Epoch 1957, Loss: 0.0023294745569728548, Final Batch Loss: 2.5824419935815968e-05\n",
      "Epoch 1958, Loss: 0.001530106455902569, Final Batch Loss: 0.0009895386174321175\n",
      "Epoch 1959, Loss: 0.004757737053296296, Final Batch Loss: 3.7880974559811875e-05\n",
      "Epoch 1960, Loss: 0.01219198371109087, Final Batch Loss: 0.01190075371414423\n",
      "Epoch 1961, Loss: 0.0005682709270331543, Final Batch Loss: 0.0004572108737193048\n",
      "Epoch 1962, Loss: 0.0022245447553359554, Final Batch Loss: 1.0929151358141098e-05\n",
      "Epoch 1963, Loss: 0.0015293414617190138, Final Batch Loss: 6.262045644689351e-05\n",
      "Epoch 1964, Loss: 0.0031869185040704906, Final Batch Loss: 0.000314066419377923\n",
      "Epoch 1965, Loss: 0.0010617907901178114, Final Batch Loss: 0.00024226514506153762\n",
      "Epoch 1966, Loss: 0.005691865677363239, Final Batch Loss: 0.00013399049930740148\n",
      "Epoch 1967, Loss: 0.000243968050199328, Final Batch Loss: 3.8752139516873285e-05\n",
      "Epoch 1968, Loss: 0.0006087291512812953, Final Batch Loss: 4.521465962170623e-05\n",
      "Epoch 1969, Loss: 0.00218881628870804, Final Batch Loss: 1.970417088159593e-06\n",
      "Epoch 1970, Loss: 0.007613486508489586, Final Batch Loss: 0.0003985523071605712\n",
      "Epoch 1971, Loss: 0.00029932103916507913, Final Batch Loss: 1.1512903256516438e-05\n",
      "Epoch 1972, Loss: 0.0007051927968859673, Final Batch Loss: 0.00020411725563462824\n",
      "Epoch 1973, Loss: 0.0010437982236908283, Final Batch Loss: 1.2489788787206635e-05\n",
      "Epoch 1974, Loss: 0.005138608670677058, Final Batch Loss: 0.0014993615914136171\n",
      "Epoch 1975, Loss: 0.000695643451763317, Final Batch Loss: 0.00014707962691318244\n",
      "Epoch 1976, Loss: 0.0005221308601903729, Final Batch Loss: 5.588055864791386e-05\n",
      "Epoch 1977, Loss: 0.0007703797564317938, Final Batch Loss: 1.13125097414013e-05\n",
      "Epoch 1978, Loss: 0.004125819279579446, Final Batch Loss: 0.00013915530871599913\n",
      "Epoch 1979, Loss: 0.0019639895908767357, Final Batch Loss: 0.0013136676279827952\n",
      "Epoch 1980, Loss: 0.0011169051431352273, Final Batch Loss: 0.0005808302666991949\n",
      "Epoch 1981, Loss: 0.00041779123785090633, Final Batch Loss: 3.737165025086142e-05\n",
      "Epoch 1982, Loss: 0.002184200449846685, Final Batch Loss: 0.00015000882558524609\n",
      "Epoch 1983, Loss: 0.0008631464006612077, Final Batch Loss: 0.0004236290988046676\n",
      "Epoch 1984, Loss: 0.0013639285098179244, Final Batch Loss: 0.00014859165821690112\n",
      "Epoch 1985, Loss: 0.0004715453542303294, Final Batch Loss: 0.00024160482280422002\n",
      "Epoch 1986, Loss: 0.0009283666440751404, Final Batch Loss: 5.1041453843936324e-05\n",
      "Epoch 1987, Loss: 0.000769481630413793, Final Batch Loss: 4.424604412633926e-06\n",
      "Epoch 1988, Loss: 0.0006767893219148391, Final Batch Loss: 1.0417586054245476e-05\n",
      "Epoch 1989, Loss: 0.005143253059941344, Final Batch Loss: 0.000453974207630381\n",
      "Epoch 1990, Loss: 0.003552711525117047, Final Batch Loss: 0.002746827434748411\n",
      "Epoch 1991, Loss: 0.006528565572807565, Final Batch Loss: 0.00046695180935785174\n",
      "Epoch 1992, Loss: 0.0003406008836464025, Final Batch Loss: 5.042116390541196e-05\n",
      "Epoch 1993, Loss: 0.00014741000813955907, Final Batch Loss: 4.233015715726651e-06\n",
      "Epoch 1994, Loss: 0.002777394183794968, Final Batch Loss: 0.00017496988584753126\n",
      "Epoch 1995, Loss: 0.004440682809217833, Final Batch Loss: 0.0001487910485593602\n",
      "Epoch 1996, Loss: 0.00034976669849129394, Final Batch Loss: 6.64267863612622e-05\n",
      "Epoch 1997, Loss: 0.0003538408873282606, Final Batch Loss: 1.0779020158224739e-05\n",
      "Epoch 1998, Loss: 0.005751653399784118, Final Batch Loss: 0.004935675300657749\n",
      "Epoch 1999, Loss: 0.006465797444434429, Final Batch Loss: 6.392264367605094e-06\n",
      "Epoch 2000, Loss: 0.00021626183661282994, Final Batch Loss: 5.453157427837141e-05\n",
      "Epoch 2001, Loss: 0.0006840232817921788, Final Batch Loss: 0.00015779367822688073\n",
      "Epoch 2002, Loss: 0.00048130328650586307, Final Batch Loss: 4.096884367754683e-05\n",
      "Epoch 2003, Loss: 0.0055824769151513465, Final Batch Loss: 5.7828015997074544e-05\n",
      "Epoch 2004, Loss: 0.004433119464010815, Final Batch Loss: 2.4549370209570043e-05\n",
      "Epoch 2005, Loss: 0.0004813607592950575, Final Batch Loss: 4.8819427320268005e-05\n",
      "Epoch 2006, Loss: 0.0007809841263224371, Final Batch Loss: 0.00015891832299530506\n",
      "Epoch 2007, Loss: 8.52812227094546e-05, Final Batch Loss: 4.482797157834284e-05\n",
      "Epoch 2008, Loss: 0.008113130617857678, Final Batch Loss: 1.0620027751429006e-05\n",
      "Epoch 2009, Loss: 0.0049210656361537986, Final Batch Loss: 0.0012621600180864334\n",
      "Epoch 2010, Loss: 0.004957081713655498, Final Batch Loss: 0.00014865297998767346\n",
      "Epoch 2011, Loss: 0.0013239966247056145, Final Batch Loss: 5.458842861116864e-05\n",
      "Epoch 2012, Loss: 0.005152101280145871, Final Batch Loss: 9.99146232061321e-06\n",
      "Epoch 2013, Loss: 0.00875736567650165, Final Batch Loss: 1.9639772290247492e-05\n",
      "Epoch 2014, Loss: 0.004725052451249212, Final Batch Loss: 0.00029779315809719265\n",
      "Epoch 2015, Loss: 0.0007295741306734271, Final Batch Loss: 6.944253982510418e-06\n",
      "Epoch 2016, Loss: 0.012695255878497846, Final Batch Loss: 0.0001809737441362813\n",
      "Epoch 2017, Loss: 0.0004906848480459303, Final Batch Loss: 0.0001094914841814898\n",
      "Epoch 2018, Loss: 0.00019691289435286308, Final Batch Loss: 9.138676432485227e-06\n",
      "Epoch 2019, Loss: 0.00021305884092726046, Final Batch Loss: 1.2249017345311586e-05\n",
      "Epoch 2020, Loss: 0.0010228189885310712, Final Batch Loss: 1.2852130566898268e-05\n",
      "Epoch 2021, Loss: 0.0008454111175524304, Final Batch Loss: 1.535936644359026e-05\n",
      "Epoch 2022, Loss: 0.018838135667465394, Final Batch Loss: 5.2306011639302596e-05\n",
      "Epoch 2023, Loss: 0.0007725591713096946, Final Batch Loss: 0.00046404742170125246\n",
      "Epoch 2024, Loss: 0.00503446923539741, Final Batch Loss: 6.971717084525153e-05\n",
      "Epoch 2025, Loss: 0.005538711877306923, Final Batch Loss: 0.0003253706672694534\n",
      "Epoch 2026, Loss: 0.005108719764393754, Final Batch Loss: 0.00014532999193761498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2027, Loss: 0.003705753682879731, Final Batch Loss: 0.00041716478881426156\n",
      "Epoch 2028, Loss: 0.0006264699186431244, Final Batch Loss: 0.00016991283337119967\n",
      "Epoch 2029, Loss: 0.00045523102107836166, Final Batch Loss: 3.842637852358166e-06\n",
      "Epoch 2030, Loss: 0.00040005621121963486, Final Batch Loss: 0.00015266136324498802\n",
      "Epoch 2031, Loss: 0.006630030504311435, Final Batch Loss: 0.00015416504174936563\n",
      "Epoch 2032, Loss: 0.000339842947141733, Final Batch Loss: 1.995648563024588e-05\n",
      "Epoch 2033, Loss: 0.0030881095553922933, Final Batch Loss: 0.0027934543322771788\n",
      "Epoch 2034, Loss: 0.0010416442091809586, Final Batch Loss: 0.0003869847860187292\n",
      "Epoch 2035, Loss: 0.003140801163681317, Final Batch Loss: 1.3137534551788121e-05\n",
      "Epoch 2036, Loss: 0.0004336712408985477, Final Batch Loss: 5.3901963838143274e-05\n",
      "Epoch 2037, Loss: 0.0004300566179153975, Final Batch Loss: 5.1840102969435975e-05\n",
      "Epoch 2038, Loss: 0.0021941107497696066, Final Batch Loss: 3.1647887226426974e-06\n",
      "Epoch 2039, Loss: 0.0006571289195562713, Final Batch Loss: 0.0004622325941454619\n",
      "Epoch 2040, Loss: 0.0029405777149804635, Final Batch Loss: 6.548811143147759e-06\n",
      "Epoch 2041, Loss: 0.000322082707498339, Final Batch Loss: 2.6259958758600987e-05\n",
      "Epoch 2042, Loss: 0.03441618132637814, Final Batch Loss: 0.03366399556398392\n",
      "Epoch 2043, Loss: 0.000912271803827025, Final Batch Loss: 4.8255882575176656e-05\n",
      "Epoch 2044, Loss: 0.01917507720645517, Final Batch Loss: 0.018641890957951546\n",
      "Epoch 2045, Loss: 0.02689959143754095, Final Batch Loss: 0.0016673729987815022\n",
      "Epoch 2046, Loss: 0.0007725871837465093, Final Batch Loss: 4.983415419701487e-05\n",
      "Epoch 2047, Loss: 0.011227435781620443, Final Batch Loss: 0.0006268391152843833\n",
      "Epoch 2048, Loss: 0.009003885206766427, Final Batch Loss: 3.3106625778600574e-05\n",
      "Epoch 2049, Loss: 0.0007277057120518293, Final Batch Loss: 2.5939978513633832e-05\n",
      "Epoch 2050, Loss: 0.0005457203224068508, Final Batch Loss: 0.00010312617814633995\n",
      "Epoch 2051, Loss: 0.0005820485821459442, Final Batch Loss: 0.00020792853320017457\n",
      "Epoch 2052, Loss: 0.006881560853798874, Final Batch Loss: 0.00013191097241360694\n",
      "Epoch 2053, Loss: 0.006948825583094731, Final Batch Loss: 0.0002355549077037722\n",
      "Epoch 2054, Loss: 0.01245950916199945, Final Batch Loss: 0.0001592882035765797\n",
      "Epoch 2055, Loss: 0.001045572746079415, Final Batch Loss: 0.00033469509799033403\n",
      "Epoch 2056, Loss: 0.0007451751462212997, Final Batch Loss: 3.0370270906132646e-05\n",
      "Epoch 2057, Loss: 0.0008080280240392312, Final Batch Loss: 0.00010790448868647218\n",
      "Epoch 2058, Loss: 0.0020374454034026712, Final Batch Loss: 0.0011048639426007867\n",
      "Epoch 2059, Loss: 0.00039110191937652417, Final Batch Loss: 4.234561129123904e-05\n",
      "Epoch 2060, Loss: 0.0005753149453084916, Final Batch Loss: 2.8449871024349704e-05\n",
      "Epoch 2061, Loss: 0.00829104965669103, Final Batch Loss: 0.00039558325079269707\n",
      "Epoch 2062, Loss: 0.003950976715714205, Final Batch Loss: 1.7073391063604504e-05\n",
      "Epoch 2063, Loss: 0.0009171211277134717, Final Batch Loss: 0.00014615556574426591\n",
      "Epoch 2064, Loss: 0.00551777430518996, Final Batch Loss: 0.00036077233380638063\n",
      "Epoch 2065, Loss: 0.0014933589627617039, Final Batch Loss: 0.0012218060437589884\n",
      "Epoch 2066, Loss: 0.0010057640702143544, Final Batch Loss: 8.138356861309148e-06\n",
      "Epoch 2067, Loss: 0.004583485955663491, Final Batch Loss: 0.00011686236393870786\n",
      "Epoch 2068, Loss: 0.0012481320300139487, Final Batch Loss: 0.0001829532120609656\n",
      "Epoch 2069, Loss: 0.0007141675960156135, Final Batch Loss: 0.0001941337832249701\n",
      "Epoch 2070, Loss: 0.025831699473201297, Final Batch Loss: 0.0217049028724432\n",
      "Epoch 2071, Loss: 0.010742998449131846, Final Batch Loss: 9.752670302987099e-05\n",
      "Epoch 2072, Loss: 0.005525577769731171, Final Batch Loss: 3.884972829837352e-05\n",
      "Epoch 2073, Loss: 0.0012831360509153455, Final Batch Loss: 7.373603875748813e-05\n",
      "Epoch 2074, Loss: 0.004226309800287709, Final Batch Loss: 5.745436646975577e-05\n",
      "Epoch 2075, Loss: 0.0002116145942636649, Final Batch Loss: 8.39327822177438e-06\n",
      "Epoch 2076, Loss: 0.0031140875216806307, Final Batch Loss: 0.002119550248607993\n",
      "Epoch 2077, Loss: 0.0015694465582782868, Final Batch Loss: 1.0978215868817642e-05\n",
      "Epoch 2078, Loss: 0.0005745632661273703, Final Batch Loss: 0.00022926305246073753\n",
      "Epoch 2079, Loss: 0.001495675191108603, Final Batch Loss: 0.00011195854312973097\n",
      "Epoch 2080, Loss: 0.01768574136076495, Final Batch Loss: 0.01593855395913124\n",
      "Epoch 2081, Loss: 0.00029121882835170254, Final Batch Loss: 0.00011782401270465925\n",
      "Epoch 2082, Loss: 0.0004903443114017136, Final Batch Loss: 3.8324193155858666e-05\n",
      "Epoch 2083, Loss: 0.0025546826946083456, Final Batch Loss: 0.0018164383945986629\n",
      "Epoch 2084, Loss: 0.01438539384980686, Final Batch Loss: 0.012917257845401764\n",
      "Epoch 2085, Loss: 0.00046281004324555397, Final Batch Loss: 8.383503882214427e-06\n",
      "Epoch 2086, Loss: 0.000595768251514528, Final Batch Loss: 0.00012028820492560044\n",
      "Epoch 2087, Loss: 0.0006165863742353395, Final Batch Loss: 0.00011140663991682231\n",
      "Epoch 2088, Loss: 0.0025966472167056054, Final Batch Loss: 0.00015550156240351498\n",
      "Epoch 2089, Loss: 0.000859077012137277, Final Batch Loss: 9.795538062462583e-06\n",
      "Epoch 2090, Loss: 0.0008913295168895274, Final Batch Loss: 7.586916035506874e-05\n",
      "Epoch 2091, Loss: 0.0029722311592195183, Final Batch Loss: 0.0002988215710502118\n",
      "Epoch 2092, Loss: 0.004216385626932606, Final Batch Loss: 0.00033116809208877385\n",
      "Epoch 2093, Loss: 0.001522265316452831, Final Batch Loss: 0.00023891327145975083\n",
      "Epoch 2094, Loss: 0.0007324195285036694, Final Batch Loss: 4.855765655520372e-05\n",
      "Epoch 2095, Loss: 0.0009480377598265477, Final Batch Loss: 1.893273747555213e-06\n",
      "Epoch 2096, Loss: 0.0006321752277926862, Final Batch Loss: 2.166763579225517e-06\n",
      "Epoch 2097, Loss: 0.0009148530371021479, Final Batch Loss: 0.00023759782197885215\n",
      "Epoch 2098, Loss: 0.0005005723273825424, Final Batch Loss: 2.975479674205417e-06\n",
      "Epoch 2099, Loss: 0.0027034895538236015, Final Batch Loss: 3.8323043554555625e-05\n",
      "Epoch 2100, Loss: 0.0005192153257667087, Final Batch Loss: 0.00024698718334548175\n",
      "Epoch 2101, Loss: 0.0007252834711835021, Final Batch Loss: 2.1880181520828046e-05\n",
      "Epoch 2102, Loss: 0.0008833583706291392, Final Batch Loss: 0.00016457536548841745\n",
      "Epoch 2103, Loss: 0.014476693933829665, Final Batch Loss: 0.00171887397300452\n",
      "Epoch 2104, Loss: 0.01567792391142575, Final Batch Loss: 0.015080470591783524\n",
      "Epoch 2105, Loss: 0.0002973305802242976, Final Batch Loss: 3.3657763651717687e-06\n",
      "Epoch 2106, Loss: 0.0008203576526284451, Final Batch Loss: 2.3748501916998066e-05\n",
      "Epoch 2107, Loss: 0.0004550738131001708, Final Batch Loss: 9.729880730446894e-06\n",
      "Epoch 2108, Loss: 0.052867888822220266, Final Batch Loss: 0.03223922848701477\n",
      "Epoch 2109, Loss: 0.00428066049789777, Final Batch Loss: 3.61603670171462e-05\n",
      "Epoch 2110, Loss: 0.06905593886040151, Final Batch Loss: 0.05390550196170807\n",
      "Epoch 2111, Loss: 0.0014943080605007708, Final Batch Loss: 0.00033303507370874286\n",
      "Epoch 2112, Loss: 0.013705044490052387, Final Batch Loss: 0.000407303188694641\n",
      "Epoch 2113, Loss: 0.006379181315423921, Final Batch Loss: 0.00028882644255645573\n",
      "Epoch 2114, Loss: 0.021956572541967034, Final Batch Loss: 0.0007655096123926342\n",
      "Epoch 2115, Loss: 0.010128359575901413, Final Batch Loss: 3.450474832789041e-05\n",
      "Epoch 2116, Loss: 0.001341349048743723, Final Batch Loss: 2.2757343685952947e-05\n",
      "Epoch 2117, Loss: 0.0029370322663453408, Final Batch Loss: 5.576882540481165e-05\n",
      "Epoch 2118, Loss: 0.004612987890141085, Final Batch Loss: 0.0001972020254470408\n",
      "Epoch 2119, Loss: 0.0036188432131893933, Final Batch Loss: 0.0009288029395975173\n",
      "Epoch 2120, Loss: 0.001164800429251045, Final Batch Loss: 0.00023071630857884884\n",
      "Epoch 2121, Loss: 0.0012164278596173972, Final Batch Loss: 0.0004035062447655946\n",
      "Epoch 2122, Loss: 0.002340348597499542, Final Batch Loss: 0.00015102575707715005\n",
      "Epoch 2123, Loss: 0.004258652767020976, Final Batch Loss: 5.8103727496927604e-05\n",
      "Epoch 2124, Loss: 0.001229848634920927, Final Batch Loss: 6.946497251192341e-06\n",
      "Epoch 2125, Loss: 0.004883532237727195, Final Batch Loss: 0.0014874717453494668\n",
      "Epoch 2126, Loss: 0.03336244591628201, Final Batch Loss: 0.00019241267000325024\n",
      "Epoch 2127, Loss: 0.0004511938968789764, Final Batch Loss: 0.00011109420302091166\n",
      "Epoch 2128, Loss: 0.025067527079954743, Final Batch Loss: 0.0015821931883692741\n",
      "Epoch 2129, Loss: 0.0019454642897471786, Final Batch Loss: 0.00048876489745453\n",
      "Epoch 2130, Loss: 0.0042107293811568525, Final Batch Loss: 4.5539341954281554e-05\n",
      "Epoch 2131, Loss: 0.005332596425432712, Final Batch Loss: 0.0009518791921436787\n",
      "Epoch 2132, Loss: 0.0024985980126075447, Final Batch Loss: 0.0005658598965965211\n",
      "Epoch 2133, Loss: 0.004614545265212655, Final Batch Loss: 0.001630340120755136\n",
      "Epoch 2134, Loss: 0.0007043668592814356, Final Batch Loss: 0.00018609079415909946\n",
      "Epoch 2135, Loss: 0.0006297113395703491, Final Batch Loss: 5.9888374380534515e-05\n",
      "Epoch 2136, Loss: 0.007093971664289711, Final Batch Loss: 3.8620270061073825e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2137, Loss: 0.004026296697702492, Final Batch Loss: 2.0820563804591075e-05\n",
      "Epoch 2138, Loss: 0.004874716076301411, Final Batch Loss: 0.001119864173233509\n",
      "Epoch 2139, Loss: 0.016393367783166468, Final Batch Loss: 0.010744261555373669\n",
      "Epoch 2140, Loss: 0.005378590154577978, Final Batch Loss: 0.004904790315777063\n",
      "Epoch 2141, Loss: 0.0015708753708167933, Final Batch Loss: 0.0001187991801998578\n",
      "Epoch 2142, Loss: 0.003274760441854596, Final Batch Loss: 0.0028236117213964462\n",
      "Epoch 2143, Loss: 0.0013303069572430104, Final Batch Loss: 0.00044766717473976314\n",
      "Epoch 2144, Loss: 0.0006050416923244484, Final Batch Loss: 8.732460992177948e-05\n",
      "Epoch 2145, Loss: 0.00800068561147782, Final Batch Loss: 5.269795292406343e-05\n",
      "Epoch 2146, Loss: 0.002938333447673358, Final Batch Loss: 0.0001721978624118492\n",
      "Epoch 2147, Loss: 0.0011887143773492426, Final Batch Loss: 0.00020812393631786108\n",
      "Epoch 2148, Loss: 0.020567574305459857, Final Batch Loss: 0.018808307126164436\n",
      "Epoch 2149, Loss: 0.0010813303233589977, Final Batch Loss: 0.000293112505460158\n",
      "Epoch 2150, Loss: 0.03266234457259998, Final Batch Loss: 0.0319858156144619\n",
      "Epoch 2151, Loss: 0.0023836629479774274, Final Batch Loss: 8.059468382271007e-05\n",
      "Epoch 2152, Loss: 0.0008162735321093351, Final Batch Loss: 0.0001738769351504743\n",
      "Epoch 2153, Loss: 0.021499463939107955, Final Batch Loss: 0.0037474255077540874\n",
      "Epoch 2154, Loss: 0.001801789563614875, Final Batch Loss: 0.00012099105515517294\n",
      "Epoch 2155, Loss: 0.030793582467595115, Final Batch Loss: 0.0004712497757282108\n",
      "Epoch 2156, Loss: 0.0015844140871195123, Final Batch Loss: 0.0011214795522391796\n",
      "Epoch 2157, Loss: 0.0015002311847638339, Final Batch Loss: 0.0009044877951964736\n",
      "Epoch 2158, Loss: 0.0008725171064725146, Final Batch Loss: 0.0003038144204765558\n",
      "Epoch 2159, Loss: 0.001031585670716595, Final Batch Loss: 0.0005109590128995478\n",
      "Epoch 2160, Loss: 0.06808853807160631, Final Batch Loss: 0.06716211885213852\n",
      "Epoch 2161, Loss: 0.004826876742299646, Final Batch Loss: 0.0005522104329429567\n",
      "Epoch 2162, Loss: 0.0013427354715531692, Final Batch Loss: 0.0002477951638866216\n",
      "Epoch 2163, Loss: 0.009217635029926896, Final Batch Loss: 0.0002593318931758404\n",
      "Epoch 2164, Loss: 0.004614846227923408, Final Batch Loss: 0.0004463671939447522\n",
      "Epoch 2165, Loss: 0.01628110808087513, Final Batch Loss: 0.0002100378624163568\n",
      "Epoch 2166, Loss: 0.00633625453338027, Final Batch Loss: 0.001825958490371704\n",
      "Epoch 2167, Loss: 0.0026594280207064003, Final Batch Loss: 0.001393115846440196\n",
      "Epoch 2168, Loss: 0.0008173181049642153, Final Batch Loss: 8.002160029718652e-05\n",
      "Epoch 2169, Loss: 0.0015355115901911631, Final Batch Loss: 0.0001266498729819432\n",
      "Epoch 2170, Loss: 0.00999831550871022, Final Batch Loss: 0.009015049785375595\n",
      "Epoch 2171, Loss: 0.002633792464621365, Final Batch Loss: 0.0014238132862374187\n",
      "Epoch 2172, Loss: 0.002083686675177887, Final Batch Loss: 0.00027224785299040377\n",
      "Epoch 2173, Loss: 0.005101509916130453, Final Batch Loss: 0.00019897095626220107\n",
      "Epoch 2174, Loss: 0.002078169258311391, Final Batch Loss: 0.0007688933983445168\n",
      "Epoch 2175, Loss: 0.005348572245566174, Final Batch Loss: 0.0001257196709048003\n",
      "Epoch 2176, Loss: 0.0011048313026549295, Final Batch Loss: 0.00026497169164940715\n",
      "Epoch 2177, Loss: 0.0010682528518373147, Final Batch Loss: 0.00017103225400205702\n",
      "Epoch 2178, Loss: 0.0019164612676831894, Final Batch Loss: 8.367152622668073e-05\n",
      "Epoch 2179, Loss: 0.0029481425299309194, Final Batch Loss: 0.002110745059326291\n",
      "Epoch 2180, Loss: 0.009709395671961829, Final Batch Loss: 9.246353874914348e-05\n",
      "Epoch 2181, Loss: 0.0010647457820596173, Final Batch Loss: 0.0002672451373655349\n",
      "Epoch 2182, Loss: 0.006993406423134729, Final Batch Loss: 0.0001804962521418929\n",
      "Epoch 2183, Loss: 0.00048215862625511363, Final Batch Loss: 0.00012764823623001575\n",
      "Epoch 2184, Loss: 0.0021477611880982295, Final Batch Loss: 0.0001278639683732763\n",
      "Epoch 2185, Loss: 0.0016025249278754927, Final Batch Loss: 1.475931640015915e-05\n",
      "Epoch 2186, Loss: 0.0041593589776312, Final Batch Loss: 0.00011157734115840867\n",
      "Epoch 2187, Loss: 0.0024614532994746696, Final Batch Loss: 6.06363573751878e-05\n",
      "Epoch 2188, Loss: 0.0015363653728854842, Final Batch Loss: 0.0008820716175250709\n",
      "Epoch 2189, Loss: 0.000825135835839319, Final Batch Loss: 1.3447845049086027e-05\n",
      "Epoch 2190, Loss: 0.001160805724794045, Final Batch Loss: 0.0003083406772930175\n",
      "Epoch 2191, Loss: 0.001793304312741384, Final Batch Loss: 0.0009742978145368397\n",
      "Epoch 2192, Loss: 0.0007667035861231852, Final Batch Loss: 4.6229473809944466e-05\n",
      "Epoch 2193, Loss: 0.0018129384006897453, Final Batch Loss: 4.344506669440307e-05\n",
      "Epoch 2194, Loss: 0.0006302142792264931, Final Batch Loss: 6.368447066051885e-05\n",
      "Epoch 2195, Loss: 0.0003191297910234425, Final Batch Loss: 5.9069436247227713e-05\n",
      "Epoch 2196, Loss: 0.00033352159516653046, Final Batch Loss: 0.00014880308299325407\n",
      "Epoch 2197, Loss: 0.002425204133032821, Final Batch Loss: 0.00013754457177128643\n",
      "Epoch 2198, Loss: 0.001761980736773694, Final Batch Loss: 1.6666050214553252e-05\n",
      "Epoch 2199, Loss: 0.0005216151039348915, Final Batch Loss: 9.166353265754879e-06\n",
      "Epoch 2200, Loss: 0.0007710801510256715, Final Batch Loss: 0.00021179163013584912\n",
      "Epoch 2201, Loss: 0.005737371291616, Final Batch Loss: 0.003421708010137081\n",
      "Epoch 2202, Loss: 0.0031173076713457704, Final Batch Loss: 9.142731869360432e-05\n",
      "Epoch 2203, Loss: 0.0011128132609883323, Final Batch Loss: 0.00018862604338210076\n",
      "Epoch 2204, Loss: 0.0017907167493831366, Final Batch Loss: 0.0013422737829387188\n",
      "Epoch 2205, Loss: 0.0008127908949973062, Final Batch Loss: 0.0004736696428153664\n",
      "Epoch 2206, Loss: 0.0009029199063661508, Final Batch Loss: 0.00022963708033785224\n",
      "Epoch 2207, Loss: 0.00042333393366789096, Final Batch Loss: 4.43398903371417e-06\n",
      "Epoch 2208, Loss: 0.0006746965991624165, Final Batch Loss: 0.00013626190775539726\n",
      "Epoch 2209, Loss: 0.00033594034357520286, Final Batch Loss: 1.599806455487851e-05\n",
      "Epoch 2210, Loss: 0.012727187189739197, Final Batch Loss: 0.0003244985709898174\n",
      "Epoch 2211, Loss: 0.004955818651069421, Final Batch Loss: 8.922041888581589e-05\n",
      "Epoch 2212, Loss: 0.005490585295774508, Final Batch Loss: 9.564872743794695e-05\n",
      "Epoch 2213, Loss: 0.0016688803734723479, Final Batch Loss: 0.0006969628157094121\n",
      "Epoch 2214, Loss: 0.0012411592178978026, Final Batch Loss: 0.00022139199427329004\n",
      "Epoch 2215, Loss: 0.0011847815876535606, Final Batch Loss: 0.00013010678230784833\n",
      "Epoch 2216, Loss: 0.003311130654765293, Final Batch Loss: 0.0005987039185129106\n",
      "Epoch 2217, Loss: 0.0006349211762426421, Final Batch Loss: 0.00015332800103351474\n",
      "Epoch 2218, Loss: 0.0012268014506844338, Final Batch Loss: 4.516167609835975e-05\n",
      "Epoch 2219, Loss: 0.048713736003264785, Final Batch Loss: 0.04390186443924904\n",
      "Epoch 2220, Loss: 0.015759593923576176, Final Batch Loss: 0.01475429441779852\n",
      "Epoch 2221, Loss: 0.028072138084098697, Final Batch Loss: 0.00016952422447502613\n",
      "Epoch 2222, Loss: 0.01439581293379888, Final Batch Loss: 0.00063456961652264\n",
      "Epoch 2223, Loss: 0.013579632293840405, Final Batch Loss: 7.644845027243719e-05\n",
      "Epoch 2224, Loss: 0.005619487375952303, Final Batch Loss: 0.0005761052016168833\n",
      "Epoch 2225, Loss: 0.0013070458371657878, Final Batch Loss: 2.8944603400304914e-05\n",
      "Epoch 2226, Loss: 0.001490215998273925, Final Batch Loss: 1.8340268070460297e-05\n",
      "Epoch 2227, Loss: 0.0016430318682978395, Final Batch Loss: 3.113158527412452e-05\n",
      "Epoch 2228, Loss: 0.004259287510649301, Final Batch Loss: 4.183770215604454e-05\n",
      "Epoch 2229, Loss: 0.0017419771193090128, Final Batch Loss: 2.0315057554398663e-05\n",
      "Epoch 2230, Loss: 0.0025709340698085725, Final Batch Loss: 0.0009988357778638601\n",
      "Epoch 2231, Loss: 0.00996315199881792, Final Batch Loss: 0.0018488699570298195\n",
      "Epoch 2232, Loss: 0.0010866289812838659, Final Batch Loss: 0.00022429034288506955\n",
      "Epoch 2233, Loss: 0.0008661364699946716, Final Batch Loss: 9.483177564106882e-05\n",
      "Epoch 2234, Loss: 0.0052978716703364626, Final Batch Loss: 0.00010216348164249212\n",
      "Epoch 2235, Loss: 0.00051545925452956, Final Batch Loss: 1.3184693671064451e-05\n",
      "Epoch 2236, Loss: 0.0036798623914364725, Final Batch Loss: 0.0029603668954223394\n",
      "Epoch 2237, Loss: 0.0012077402279828675, Final Batch Loss: 8.561742288293317e-05\n",
      "Epoch 2238, Loss: 0.0022829053923487663, Final Batch Loss: 0.0016251987544819713\n",
      "Epoch 2239, Loss: 0.0016100133652798831, Final Batch Loss: 0.0002263140631839633\n",
      "Epoch 2240, Loss: 0.005170630320208147, Final Batch Loss: 0.0008833300089463592\n",
      "Epoch 2241, Loss: 0.000537337768037105, Final Batch Loss: 5.179895742912777e-05\n",
      "Epoch 2242, Loss: 0.0011870270100189373, Final Batch Loss: 0.00023324151698034257\n",
      "Epoch 2243, Loss: 0.0006912591416039504, Final Batch Loss: 8.307421376230195e-05\n",
      "Epoch 2244, Loss: 0.011985291886958294, Final Batch Loss: 0.00016734965902287513\n",
      "Epoch 2245, Loss: 0.0025410777307115495, Final Batch Loss: 0.0014368065167218447\n",
      "Epoch 2246, Loss: 0.05671416863333434, Final Batch Loss: 0.05478953197598457\n",
      "Epoch 2247, Loss: 0.00903389692757628, Final Batch Loss: 2.115647293976508e-05\n",
      "Epoch 2248, Loss: 0.013270408831886016, Final Batch Loss: 0.0001232027861988172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2249, Loss: 0.0011016252828994766, Final Batch Loss: 2.182027674280107e-05\n",
      "Epoch 2250, Loss: 0.0009590651679900475, Final Batch Loss: 0.00011336530587868765\n",
      "Epoch 2251, Loss: 0.0007012221758486703, Final Batch Loss: 3.2722760806791484e-05\n",
      "Epoch 2252, Loss: 0.0007695827225688845, Final Batch Loss: 0.00017662806203588843\n",
      "Epoch 2253, Loss: 0.0011645013073575683, Final Batch Loss: 0.00010585739073576406\n",
      "Epoch 2254, Loss: 0.001804788043955341, Final Batch Loss: 9.404573938809335e-05\n",
      "Epoch 2255, Loss: 0.0013134837463439908, Final Batch Loss: 3.142485729767941e-05\n",
      "Epoch 2256, Loss: 0.0018247873085783795, Final Batch Loss: 0.0006870970246382058\n",
      "Epoch 2257, Loss: 0.000843783636810258, Final Batch Loss: 0.00047431938583031297\n",
      "Epoch 2258, Loss: 0.002222158336735447, Final Batch Loss: 1.495854121458251e-05\n",
      "Epoch 2259, Loss: 0.04851963680994231, Final Batch Loss: 0.04775582253932953\n",
      "Epoch 2260, Loss: 0.0010073119774460793, Final Batch Loss: 0.00033323877141810954\n",
      "Epoch 2261, Loss: 0.0007956064328027423, Final Batch Loss: 3.3709056879160926e-05\n",
      "Epoch 2262, Loss: 0.0066135425586253405, Final Batch Loss: 0.0038573250640183687\n",
      "Epoch 2263, Loss: 0.0015993698289094027, Final Batch Loss: 3.74868068320211e-05\n",
      "Epoch 2264, Loss: 0.008877107233274728, Final Batch Loss: 0.005516537465155125\n",
      "Epoch 2265, Loss: 0.0008074161578406347, Final Batch Loss: 2.4020233468036167e-05\n",
      "Epoch 2266, Loss: 0.0037785645690746605, Final Batch Loss: 0.0006405945168808103\n",
      "Epoch 2267, Loss: 0.014554721648892155, Final Batch Loss: 4.112779788556509e-05\n",
      "Epoch 2268, Loss: 0.005154722020961344, Final Batch Loss: 7.890566485002637e-05\n",
      "Epoch 2269, Loss: 0.0020877436591035803, Final Batch Loss: 8.072934178926516e-06\n",
      "Epoch 2270, Loss: 0.0006235929613467306, Final Batch Loss: 0.0001414994039805606\n",
      "Epoch 2271, Loss: 0.00030397361842915416, Final Batch Loss: 7.147897849790752e-05\n",
      "Epoch 2272, Loss: 0.0037636771448887885, Final Batch Loss: 0.0030391355976462364\n",
      "Epoch 2273, Loss: 0.0013366969651542604, Final Batch Loss: 0.0001823888742364943\n",
      "Epoch 2274, Loss: 0.0007113016908988357, Final Batch Loss: 7.370956882368773e-05\n",
      "Epoch 2275, Loss: 0.0006376582241500728, Final Batch Loss: 0.0003094203711953014\n",
      "Epoch 2276, Loss: 0.0011952834611292928, Final Batch Loss: 0.00015396915841847658\n",
      "Epoch 2277, Loss: 0.006255809566937387, Final Batch Loss: 0.0033382975962013006\n",
      "Epoch 2278, Loss: 0.005659215501509607, Final Batch Loss: 0.0004239437694195658\n",
      "Epoch 2279, Loss: 0.0013261929088912439, Final Batch Loss: 4.7711404477013275e-05\n",
      "Epoch 2280, Loss: 0.0005763132612628397, Final Batch Loss: 5.1611725211841986e-05\n",
      "Epoch 2281, Loss: 0.00035529514752852265, Final Batch Loss: 2.815338120853994e-05\n",
      "Epoch 2282, Loss: 0.000416884504375048, Final Batch Loss: 0.0001824141654651612\n",
      "Epoch 2283, Loss: 0.0007205649380921386, Final Batch Loss: 0.0005093577201478183\n",
      "Epoch 2284, Loss: 0.00261812903045211, Final Batch Loss: 0.0001231788337463513\n",
      "Epoch 2285, Loss: 0.004275777293514693, Final Batch Loss: 3.552576890797354e-05\n",
      "Epoch 2286, Loss: 0.011474544066004455, Final Batch Loss: 0.00012486797641031444\n",
      "Epoch 2287, Loss: 0.0005592214856733335, Final Batch Loss: 1.4107483366387896e-05\n",
      "Epoch 2288, Loss: 0.0009522401378490031, Final Batch Loss: 0.00020185894391033798\n",
      "Epoch 2289, Loss: 0.001382700225804001, Final Batch Loss: 0.00045509531628340483\n",
      "Epoch 2290, Loss: 0.002906065623392351, Final Batch Loss: 0.0002185553457820788\n",
      "Epoch 2291, Loss: 0.0005971100408714847, Final Batch Loss: 9.20880938792834e-06\n",
      "Epoch 2292, Loss: 0.0028290218324400485, Final Batch Loss: 0.00013298739213496447\n",
      "Epoch 2293, Loss: 0.0003956154214392882, Final Batch Loss: 1.759182123350911e-05\n",
      "Epoch 2294, Loss: 0.004061364219523966, Final Batch Loss: 0.0006890981458127499\n",
      "Epoch 2295, Loss: 0.0011429676596890204, Final Batch Loss: 9.11744064069353e-05\n",
      "Epoch 2296, Loss: 0.001621265873836819, Final Batch Loss: 0.00011485743016237393\n",
      "Epoch 2297, Loss: 0.0011332589747325983, Final Batch Loss: 2.020183819695376e-05\n",
      "Epoch 2298, Loss: 0.0005689107820217032, Final Batch Loss: 4.802694093086757e-05\n",
      "Epoch 2299, Loss: 0.013147102239599917, Final Batch Loss: 5.789803253719583e-05\n",
      "Epoch 2300, Loss: 0.0008784571255091578, Final Batch Loss: 0.00033314654137939215\n",
      "Epoch 2301, Loss: 0.001815769930544775, Final Batch Loss: 0.0015019961865618825\n",
      "Epoch 2302, Loss: 0.0009748976117407437, Final Batch Loss: 3.1088620744412765e-05\n",
      "Epoch 2303, Loss: 0.0010530169238336384, Final Batch Loss: 4.668792098527774e-05\n",
      "Epoch 2304, Loss: 0.0007553333707619458, Final Batch Loss: 5.4030679166316986e-05\n",
      "Epoch 2305, Loss: 0.0003735048339876812, Final Batch Loss: 5.098677866044454e-05\n",
      "Epoch 2306, Loss: 0.0006964306594454683, Final Batch Loss: 4.88371224491857e-05\n",
      "Epoch 2307, Loss: 0.01200752123259008, Final Batch Loss: 0.0004026067617814988\n",
      "Epoch 2308, Loss: 0.0012130062241340056, Final Batch Loss: 3.10247705783695e-05\n",
      "Epoch 2309, Loss: 0.000848445350129623, Final Batch Loss: 5.7964927691500634e-05\n",
      "Epoch 2310, Loss: 0.0008249434868048411, Final Batch Loss: 5.9930065617663786e-05\n",
      "Epoch 2311, Loss: 0.00323789865069557, Final Batch Loss: 0.00018189586990047246\n",
      "Epoch 2312, Loss: 0.0016260104021057487, Final Batch Loss: 0.000583177839871496\n",
      "Epoch 2313, Loss: 0.0023485561869165394, Final Batch Loss: 4.398769306135364e-05\n",
      "Epoch 2314, Loss: 0.0010114999167853966, Final Batch Loss: 0.0001285488106077537\n",
      "Epoch 2315, Loss: 0.0013541995867853984, Final Batch Loss: 0.00024051703803706914\n",
      "Epoch 2316, Loss: 0.0005473696000990458, Final Batch Loss: 9.357742237625644e-05\n",
      "Epoch 2317, Loss: 0.002356829108975944, Final Batch Loss: 9.910059816320427e-06\n",
      "Epoch 2318, Loss: 0.0013370613305596635, Final Batch Loss: 4.9748996389098465e-05\n",
      "Epoch 2319, Loss: 0.0008850159692883608, Final Batch Loss: 9.007989319798071e-06\n",
      "Epoch 2320, Loss: 0.0024125133277266286, Final Batch Loss: 6.647814734606072e-05\n",
      "Epoch 2321, Loss: 0.0015495183179154992, Final Batch Loss: 0.000911389070097357\n",
      "Epoch 2322, Loss: 0.000873811382916756, Final Batch Loss: 0.0001715549879008904\n",
      "Epoch 2323, Loss: 0.0009863853629212826, Final Batch Loss: 0.0002027214359259233\n",
      "Epoch 2324, Loss: 0.0014900995884090662, Final Batch Loss: 0.00018539142911322415\n",
      "Epoch 2325, Loss: 0.00031191696689347737, Final Batch Loss: 4.608567905961536e-05\n",
      "Epoch 2326, Loss: 0.0035467084526317194, Final Batch Loss: 0.0006070452509447932\n",
      "Epoch 2327, Loss: 0.005027413052630436, Final Batch Loss: 7.965228178363759e-06\n",
      "Epoch 2328, Loss: 0.0006624284651479684, Final Batch Loss: 7.785157504258677e-05\n",
      "Epoch 2329, Loss: 0.0014892901017447002, Final Batch Loss: 3.954003477701917e-05\n",
      "Epoch 2330, Loss: 0.0011822880987892859, Final Batch Loss: 1.6671874618623406e-05\n",
      "Epoch 2331, Loss: 0.005723531809053384, Final Batch Loss: 0.0007223183056339622\n",
      "Epoch 2332, Loss: 0.00047003514191601425, Final Batch Loss: 0.00014183600433170795\n",
      "Epoch 2333, Loss: 0.0014232282919692807, Final Batch Loss: 0.0011707975063472986\n",
      "Epoch 2334, Loss: 0.0025215909045073204, Final Batch Loss: 4.688643093686551e-05\n",
      "Epoch 2335, Loss: 0.0025760061107575893, Final Batch Loss: 0.0019765691831707954\n",
      "Epoch 2336, Loss: 0.0006203744160302449, Final Batch Loss: 1.0185543942498043e-05\n",
      "Epoch 2337, Loss: 0.0003735220234375447, Final Batch Loss: 6.710900197504088e-05\n",
      "Epoch 2338, Loss: 0.004129543493036181, Final Batch Loss: 0.000492262770421803\n",
      "Epoch 2339, Loss: 0.001172367192339152, Final Batch Loss: 0.000640319543890655\n",
      "Epoch 2340, Loss: 0.0007220488550956361, Final Batch Loss: 2.8057336749043316e-05\n",
      "Epoch 2341, Loss: 0.0008447366417385638, Final Batch Loss: 0.0001609360333532095\n",
      "Epoch 2342, Loss: 0.0005600201402558014, Final Batch Loss: 0.00013751797087024897\n",
      "Epoch 2343, Loss: 0.001380682990202331, Final Batch Loss: 7.596225259476341e-06\n",
      "Epoch 2344, Loss: 0.0006294552276813192, Final Batch Loss: 2.289375515829306e-05\n",
      "Epoch 2345, Loss: 0.006556799737154506, Final Batch Loss: 0.005932986736297607\n",
      "Epoch 2346, Loss: 0.00530849551432766, Final Batch Loss: 0.0012163560604676604\n",
      "Epoch 2347, Loss: 0.01277125942579005, Final Batch Loss: 0.0001309026702074334\n",
      "Epoch 2348, Loss: 0.0055042609965312295, Final Batch Loss: 3.112327976850793e-05\n",
      "Epoch 2349, Loss: 0.033962277721002465, Final Batch Loss: 0.0331914909183979\n",
      "Epoch 2350, Loss: 0.0018654101877473295, Final Batch Loss: 0.0009923320030793548\n",
      "Epoch 2351, Loss: 0.03830936219310388, Final Batch Loss: 0.0007097175694070756\n",
      "Epoch 2352, Loss: 0.07037422300709295, Final Batch Loss: 5.335711102816276e-05\n",
      "Epoch 2353, Loss: 0.003691219624670339, Final Batch Loss: 2.397201933490578e-05\n",
      "Epoch 2354, Loss: 0.0014141661522444338, Final Batch Loss: 0.00010980074875988066\n",
      "Epoch 2355, Loss: 0.0005894692294532433, Final Batch Loss: 0.00013964557729195803\n",
      "Epoch 2356, Loss: 0.0012124980239605065, Final Batch Loss: 4.064815220772289e-05\n",
      "Epoch 2357, Loss: 0.0016564264660701156, Final Batch Loss: 0.0009178141481243074\n",
      "Epoch 2358, Loss: 0.0008075469377217814, Final Batch Loss: 0.0003914847911801189\n",
      "Epoch 2359, Loss: 0.0005599994983640499, Final Batch Loss: 3.219063364667818e-05\n",
      "Epoch 2360, Loss: 0.001580863397975918, Final Batch Loss: 1.4634475519414991e-05\n",
      "Epoch 2361, Loss: 0.0008200253796530887, Final Batch Loss: 4.6857414417900145e-05\n",
      "Epoch 2362, Loss: 0.006276541065744823, Final Batch Loss: 4.4141310354461893e-05\n",
      "Epoch 2363, Loss: 0.0024214633740484715, Final Batch Loss: 0.0007034040754660964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2364, Loss: 0.00935502431821078, Final Batch Loss: 0.0022314791567623615\n",
      "Epoch 2365, Loss: 0.0013566193811129779, Final Batch Loss: 0.00014888981240801513\n",
      "Epoch 2366, Loss: 0.027449374705611262, Final Batch Loss: 0.008929897099733353\n",
      "Epoch 2367, Loss: 0.001193255273392424, Final Batch Loss: 0.000276917708106339\n",
      "Epoch 2368, Loss: 0.0010409478127257898, Final Batch Loss: 7.755694969091564e-05\n",
      "Epoch 2369, Loss: 0.0013196432428230764, Final Batch Loss: 2.6652081942302175e-05\n",
      "Epoch 2370, Loss: 0.0028332348738331348, Final Batch Loss: 0.0002427440049359575\n",
      "Epoch 2371, Loss: 0.0004985527166354586, Final Batch Loss: 1.143183635576861e-05\n",
      "Epoch 2372, Loss: 0.0034370066205156036, Final Batch Loss: 6.0424783441703767e-05\n",
      "Epoch 2373, Loss: 0.004957600023772102, Final Batch Loss: 0.0044768559746444225\n",
      "Epoch 2374, Loss: 0.0007744687900412828, Final Batch Loss: 2.4181368644349277e-05\n",
      "Epoch 2375, Loss: 0.03378096372762229, Final Batch Loss: 0.0325760617852211\n",
      "Epoch 2376, Loss: 0.004849160264711827, Final Batch Loss: 0.004458235111087561\n",
      "Epoch 2377, Loss: 0.03494135847722646, Final Batch Loss: 0.018726076930761337\n",
      "Epoch 2378, Loss: 0.00096411595814061, Final Batch Loss: 7.4323347689642105e-06\n",
      "Epoch 2379, Loss: 0.004831971140447422, Final Batch Loss: 2.7675885576172732e-05\n",
      "Epoch 2380, Loss: 0.004085319589194114, Final Batch Loss: 7.16618478691089e-06\n",
      "Epoch 2381, Loss: 0.0011479698659968562, Final Batch Loss: 7.838651799829677e-05\n",
      "Epoch 2382, Loss: 0.0014076784500502981, Final Batch Loss: 6.592200952582061e-05\n",
      "Epoch 2383, Loss: 0.0003327700978843495, Final Batch Loss: 7.363585609709844e-05\n",
      "Epoch 2384, Loss: 0.006108802364906296, Final Batch Loss: 0.0026845962274819613\n",
      "Epoch 2385, Loss: 0.004473482811590657, Final Batch Loss: 2.5387591449543834e-05\n",
      "Epoch 2386, Loss: 0.003262916514358949, Final Batch Loss: 0.0001044205782818608\n",
      "Epoch 2387, Loss: 0.0002481830379110761, Final Batch Loss: 4.494188033277169e-05\n",
      "Epoch 2388, Loss: 0.006359314807923511, Final Batch Loss: 0.000457517133327201\n",
      "Epoch 2389, Loss: 0.0017893284966703504, Final Batch Loss: 0.00028887559892609715\n",
      "Epoch 2390, Loss: 0.002422895922791213, Final Batch Loss: 0.0013575049815699458\n",
      "Epoch 2391, Loss: 0.0021885219393880107, Final Batch Loss: 7.049799751257524e-05\n",
      "Epoch 2392, Loss: 0.0004382423430797644, Final Batch Loss: 2.19339708564803e-05\n",
      "Epoch 2393, Loss: 0.0008746476014493965, Final Batch Loss: 3.411000216146931e-05\n",
      "Epoch 2394, Loss: 0.030550947245501447, Final Batch Loss: 3.2794960134197026e-05\n",
      "Epoch 2395, Loss: 0.001270653053325077, Final Batch Loss: 1.0330592886020895e-05\n",
      "Epoch 2396, Loss: 0.0034505485091358423, Final Batch Loss: 0.0015201902715489268\n",
      "Epoch 2397, Loss: 0.004529714409727603, Final Batch Loss: 0.00022765662288293242\n",
      "Epoch 2398, Loss: 0.0009966252837330103, Final Batch Loss: 0.0007756662089377642\n",
      "Epoch 2399, Loss: 0.002001042666961439, Final Batch Loss: 0.0009485906339250505\n",
      "Epoch 2400, Loss: 0.0012334166385699064, Final Batch Loss: 3.931930405087769e-05\n",
      "Epoch 2401, Loss: 0.0012304912379477173, Final Batch Loss: 0.0002781075891107321\n",
      "Epoch 2402, Loss: 0.001412322701071389, Final Batch Loss: 0.00016344730101991445\n",
      "Epoch 2403, Loss: 0.0008494380253978306, Final Batch Loss: 1.2126018191338517e-05\n",
      "Epoch 2404, Loss: 0.0006724077938997652, Final Batch Loss: 1.6968886484391987e-05\n",
      "Epoch 2405, Loss: 0.004621824562491383, Final Batch Loss: 3.1824427423998713e-05\n",
      "Epoch 2406, Loss: 0.00036244602051738184, Final Batch Loss: 2.9700438972213306e-05\n",
      "Epoch 2407, Loss: 0.0013279725098982453, Final Batch Loss: 7.585887215100229e-05\n",
      "Epoch 2408, Loss: 0.005784448265330866, Final Batch Loss: 0.00020461033273022622\n",
      "Epoch 2409, Loss: 0.0011643607940641232, Final Batch Loss: 0.00010171876783715561\n",
      "Epoch 2410, Loss: 0.0008807734577658266, Final Batch Loss: 3.520095788189792e-06\n",
      "Epoch 2411, Loss: 0.0005060415533080231, Final Batch Loss: 5.856943243998103e-05\n",
      "Epoch 2412, Loss: 0.0018224813320557587, Final Batch Loss: 7.035294402157888e-05\n",
      "Epoch 2413, Loss: 0.014084175899824913, Final Batch Loss: 6.025658422004199e-06\n",
      "Epoch 2414, Loss: 0.00047578289377270266, Final Batch Loss: 4.576148057822138e-05\n",
      "Epoch 2415, Loss: 0.005401881760917604, Final Batch Loss: 0.003920422401279211\n",
      "Epoch 2416, Loss: 0.002817503751430195, Final Batch Loss: 4.133575566811487e-05\n",
      "Epoch 2417, Loss: 0.00037733762292191386, Final Batch Loss: 7.089647988323122e-05\n",
      "Epoch 2418, Loss: 0.007346508500631899, Final Batch Loss: 0.0001410568947903812\n",
      "Epoch 2419, Loss: 0.002527590113459155, Final Batch Loss: 0.0010400846367701888\n",
      "Epoch 2420, Loss: 0.0008707194283488207, Final Batch Loss: 7.452860154444352e-05\n",
      "Epoch 2421, Loss: 0.0008454703729512403, Final Batch Loss: 1.684846392890904e-05\n",
      "Epoch 2422, Loss: 0.0014011537423357368, Final Batch Loss: 0.0006851694197393954\n",
      "Epoch 2423, Loss: 0.00044096598139731213, Final Batch Loss: 0.00010735364776337519\n",
      "Epoch 2424, Loss: 0.0023394138406729326, Final Batch Loss: 7.959573122207075e-05\n",
      "Epoch 2425, Loss: 0.0014333960971271154, Final Batch Loss: 0.0007923634257167578\n",
      "Epoch 2426, Loss: 0.004486943638767116, Final Batch Loss: 7.477366307284683e-05\n",
      "Epoch 2427, Loss: 0.017526109440950677, Final Batch Loss: 0.00016200271784327924\n",
      "Epoch 2428, Loss: 0.0020472820615395904, Final Batch Loss: 0.0007519330247305334\n",
      "Epoch 2429, Loss: 0.0004983707985957153, Final Batch Loss: 8.722823258722201e-05\n",
      "Epoch 2430, Loss: 0.00041653620792203583, Final Batch Loss: 9.03355612535961e-06\n",
      "Epoch 2431, Loss: 0.0020811197318835184, Final Batch Loss: 0.001231081783771515\n",
      "Epoch 2432, Loss: 0.0009764293627085863, Final Batch Loss: 2.969040178868454e-05\n",
      "Epoch 2433, Loss: 0.0010655384394340217, Final Batch Loss: 0.0003427570918574929\n",
      "Epoch 2434, Loss: 0.0003806898257607827, Final Batch Loss: 2.1445603124448098e-05\n",
      "Epoch 2435, Loss: 0.003607404723879881, Final Batch Loss: 0.0002665712090674788\n",
      "Epoch 2436, Loss: 0.001848791871452704, Final Batch Loss: 0.0010370139498263597\n",
      "Epoch 2437, Loss: 0.000492080351250479, Final Batch Loss: 3.4637039789231494e-05\n",
      "Epoch 2438, Loss: 0.0004833608472836204, Final Batch Loss: 8.088250615401193e-05\n",
      "Epoch 2439, Loss: 0.000994660091237165, Final Batch Loss: 3.1437521101906896e-05\n",
      "Epoch 2440, Loss: 0.0006592791687580757, Final Batch Loss: 9.872260125121102e-05\n",
      "Epoch 2441, Loss: 0.001502688795881113, Final Batch Loss: 2.622576357680373e-05\n",
      "Epoch 2442, Loss: 0.00029032129532424733, Final Batch Loss: 0.00010575018677627668\n",
      "Epoch 2443, Loss: 0.0004447348492249148, Final Batch Loss: 1.9898654500138946e-05\n",
      "Epoch 2444, Loss: 0.0016761833685450256, Final Batch Loss: 0.0012401794083416462\n",
      "Epoch 2445, Loss: 0.0008724561776034534, Final Batch Loss: 4.5780965592712164e-05\n",
      "Epoch 2446, Loss: 0.01015255507081747, Final Batch Loss: 1.4640332665294409e-05\n",
      "Epoch 2447, Loss: 0.001989226377190789, Final Batch Loss: 3.137066596536897e-05\n",
      "Epoch 2448, Loss: 0.002537460943131009, Final Batch Loss: 1.8044713215203956e-05\n",
      "Epoch 2449, Loss: 0.0016242370038526133, Final Batch Loss: 0.0002162711025448516\n",
      "Epoch 2450, Loss: 0.000573262602529212, Final Batch Loss: 2.5500896754238056e-06\n",
      "Epoch 2451, Loss: 0.0011244565030210651, Final Batch Loss: 5.237500590737909e-05\n",
      "Epoch 2452, Loss: 0.0006438717391574755, Final Batch Loss: 6.853451486676931e-05\n",
      "Epoch 2453, Loss: 0.0003921859242836945, Final Batch Loss: 0.00022549627465195954\n",
      "Epoch 2454, Loss: 0.0005601293123618234, Final Batch Loss: 7.145379640860483e-05\n",
      "Epoch 2455, Loss: 0.0007936176843941212, Final Batch Loss: 0.00012094972771592438\n",
      "Epoch 2456, Loss: 0.0011486343209980987, Final Batch Loss: 0.0008142293081618845\n",
      "Epoch 2457, Loss: 0.0005453408921312075, Final Batch Loss: 2.8968741389689967e-05\n",
      "Epoch 2458, Loss: 0.0007787002796248998, Final Batch Loss: 1.4224260667106137e-05\n",
      "Epoch 2459, Loss: 0.0005815542572236154, Final Batch Loss: 0.0004396815493237227\n",
      "Epoch 2460, Loss: 0.0004270897297828924, Final Batch Loss: 2.190585291828029e-05\n",
      "Epoch 2461, Loss: 0.0005814410687889904, Final Batch Loss: 0.00030219266773201525\n",
      "Epoch 2462, Loss: 0.0003775874720304273, Final Batch Loss: 2.28974167839624e-05\n",
      "Epoch 2463, Loss: 0.0006804235381423496, Final Batch Loss: 9.840375423664227e-05\n",
      "Epoch 2464, Loss: 0.008648186550090031, Final Batch Loss: 1.3999501788930502e-05\n",
      "Epoch 2465, Loss: 0.001166505564469844, Final Batch Loss: 0.0001253936206921935\n",
      "Epoch 2466, Loss: 0.0003557455784175545, Final Batch Loss: 7.106911652954295e-05\n",
      "Epoch 2467, Loss: 0.000688604623064748, Final Batch Loss: 1.2376918675727211e-05\n",
      "Epoch 2468, Loss: 0.0008232643158407882, Final Batch Loss: 0.0001222327700816095\n",
      "Epoch 2469, Loss: 0.00044834156506112777, Final Batch Loss: 0.00032212742371484637\n",
      "Epoch 2470, Loss: 0.0003789649508689763, Final Batch Loss: 4.529685611487366e-06\n",
      "Epoch 2471, Loss: 0.002792723384573037, Final Batch Loss: 6.607677732972661e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2472, Loss: 0.00023401131147693377, Final Batch Loss: 2.466719706717413e-05\n",
      "Epoch 2473, Loss: 0.000677296171488706, Final Batch Loss: 0.00010982348612742499\n",
      "Epoch 2474, Loss: 0.00028320453293417813, Final Batch Loss: 1.3065172424830962e-05\n",
      "Epoch 2475, Loss: 0.0004323768662288785, Final Batch Loss: 9.22381950658746e-05\n",
      "Epoch 2476, Loss: 0.004007043855381198, Final Batch Loss: 3.8567770388908684e-05\n",
      "Epoch 2477, Loss: 0.00042828230652958155, Final Batch Loss: 3.457484854152426e-05\n",
      "Epoch 2478, Loss: 0.0006549003774125595, Final Batch Loss: 4.819478272111155e-05\n",
      "Epoch 2479, Loss: 0.0002665418760443572, Final Batch Loss: 6.100035534473136e-06\n",
      "Epoch 2480, Loss: 0.00035973139165434986, Final Batch Loss: 0.00010779061994981021\n",
      "Epoch 2481, Loss: 0.0007880927296355367, Final Batch Loss: 0.00013713189400732517\n",
      "Epoch 2482, Loss: 0.0012208270345581695, Final Batch Loss: 7.398480374831706e-05\n",
      "Epoch 2483, Loss: 0.01195372294750996, Final Batch Loss: 0.00035985445720143616\n",
      "Epoch 2484, Loss: 0.001367632816254627, Final Batch Loss: 3.9745442336425185e-05\n",
      "Epoch 2485, Loss: 0.017586103203939274, Final Batch Loss: 0.0019559713546186686\n",
      "Epoch 2486, Loss: 0.004415772980792099, Final Batch Loss: 3.0596365832025185e-06\n",
      "Epoch 2487, Loss: 0.0003487745125312358, Final Batch Loss: 0.0001332097890553996\n",
      "Epoch 2488, Loss: 0.0012521203680080362, Final Batch Loss: 5.6331475207116455e-05\n",
      "Epoch 2489, Loss: 0.0020300969044910744, Final Batch Loss: 0.00016180860984604806\n",
      "Epoch 2490, Loss: 0.0009010084468172863, Final Batch Loss: 0.00012143341882620007\n",
      "Epoch 2491, Loss: 0.0015251304266712395, Final Batch Loss: 2.8607506465050392e-05\n",
      "Epoch 2492, Loss: 0.000593455621128669, Final Batch Loss: 4.856704254052602e-05\n",
      "Epoch 2493, Loss: 0.004609220559359528, Final Batch Loss: 0.00017387335537932813\n",
      "Epoch 2494, Loss: 0.0007295527684618719, Final Batch Loss: 0.00027377213700674474\n",
      "Epoch 2495, Loss: 0.0011949086756430916, Final Batch Loss: 1.0026923519035336e-05\n",
      "Epoch 2496, Loss: 0.0008200505544664338, Final Batch Loss: 0.00023889348085504025\n",
      "Epoch 2497, Loss: 0.019691681853146292, Final Batch Loss: 0.019127564504742622\n",
      "Epoch 2498, Loss: 0.0015170306141953915, Final Batch Loss: 0.00014534017827827483\n",
      "Epoch 2499, Loss: 0.02844060107599944, Final Batch Loss: 0.001673334394581616\n",
      "Epoch 2500, Loss: 0.00047748523502377793, Final Batch Loss: 0.00024258976918645203\n",
      "Epoch 2501, Loss: 0.0007262550934683532, Final Batch Loss: 0.0001216633027070202\n",
      "Epoch 2502, Loss: 0.0005578908967436291, Final Batch Loss: 6.485402263933793e-05\n",
      "Epoch 2503, Loss: 0.00027389750721340533, Final Batch Loss: 1.607317062735092e-05\n",
      "Epoch 2504, Loss: 0.00013729017882724293, Final Batch Loss: 0.0001047929617925547\n",
      "Epoch 2505, Loss: 0.002690507022634847, Final Batch Loss: 1.783408151823096e-05\n",
      "Epoch 2506, Loss: 0.00021284489821482566, Final Batch Loss: 7.430324785673292e-06\n",
      "Epoch 2507, Loss: 0.00014553885193890892, Final Batch Loss: 1.2123204214731231e-05\n",
      "Epoch 2508, Loss: 0.0007890544657129794, Final Batch Loss: 0.0004988113068975508\n",
      "Epoch 2509, Loss: 0.0021229941776255146, Final Batch Loss: 3.446193295530975e-05\n",
      "Epoch 2510, Loss: 0.0004134640030315495, Final Batch Loss: 2.687957930902485e-06\n",
      "Epoch 2511, Loss: 0.00045936904916743515, Final Batch Loss: 2.1150503016542643e-05\n",
      "Epoch 2512, Loss: 0.00020054385822732002, Final Batch Loss: 1.859116309788078e-05\n",
      "Epoch 2513, Loss: 0.0007438552711391822, Final Batch Loss: 9.898007556330413e-05\n",
      "Epoch 2514, Loss: 0.006681660946924239, Final Batch Loss: 0.0003125287767034024\n",
      "Epoch 2515, Loss: 0.005078081674582791, Final Batch Loss: 4.1527724533807486e-05\n",
      "Epoch 2516, Loss: 0.031063612761499826, Final Batch Loss: 0.030658407136797905\n",
      "Epoch 2517, Loss: 0.0003771891779251746, Final Batch Loss: 1.4237803952710237e-05\n",
      "Epoch 2518, Loss: 0.00040610394444229314, Final Batch Loss: 1.0732540431490634e-05\n",
      "Epoch 2519, Loss: 0.005986382911942201, Final Batch Loss: 0.00024391297483816743\n",
      "Epoch 2520, Loss: 0.00032291321804223116, Final Batch Loss: 9.832523574004881e-06\n",
      "Epoch 2521, Loss: 0.0005231693539826665, Final Batch Loss: 3.8567031879210845e-05\n",
      "Epoch 2522, Loss: 0.0006958805934118573, Final Batch Loss: 2.4896562536014244e-05\n",
      "Epoch 2523, Loss: 0.0008657395883346908, Final Batch Loss: 0.00048281342606060207\n",
      "Epoch 2524, Loss: 0.0012594719883054495, Final Batch Loss: 0.00026264568441547453\n",
      "Epoch 2525, Loss: 0.0006549530990014318, Final Batch Loss: 7.626345177413896e-05\n",
      "Epoch 2526, Loss: 0.0003307522931663698, Final Batch Loss: 1.276228658753098e-06\n",
      "Epoch 2527, Loss: 0.000622246037437435, Final Batch Loss: 4.006274593848502e-06\n",
      "Epoch 2528, Loss: 0.0009104905329877511, Final Batch Loss: 0.00015057744167279452\n",
      "Epoch 2529, Loss: 0.0043893150868825614, Final Batch Loss: 0.00014134598313830793\n",
      "Epoch 2530, Loss: 9.487044985689863e-05, Final Batch Loss: 2.6412442366563482e-06\n",
      "Epoch 2531, Loss: 0.0004802980911335908, Final Batch Loss: 0.00011530014307936653\n",
      "Epoch 2532, Loss: 0.001017421396682039, Final Batch Loss: 0.0006764319259673357\n",
      "Epoch 2533, Loss: 0.00088263330871996, Final Batch Loss: 1.472527401347179e-05\n",
      "Epoch 2534, Loss: 0.002223753537691664, Final Batch Loss: 1.651696948101744e-05\n",
      "Epoch 2535, Loss: 0.004278355321730487, Final Batch Loss: 0.0031712637282907963\n",
      "Epoch 2536, Loss: 0.0003163550136378035, Final Batch Loss: 0.00017309517716057599\n",
      "Epoch 2537, Loss: 0.002375554460058993, Final Batch Loss: 3.627578962550615e-06\n",
      "Epoch 2538, Loss: 0.0007772506796754897, Final Batch Loss: 0.00010846505028894171\n",
      "Epoch 2539, Loss: 0.0005554862509598024, Final Batch Loss: 8.411783346673474e-05\n",
      "Epoch 2540, Loss: 9.888329805107787e-05, Final Batch Loss: 2.358215169806499e-05\n",
      "Epoch 2541, Loss: 0.0001997247636609245, Final Batch Loss: 9.118906018557027e-05\n",
      "Epoch 2542, Loss: 0.00041264056926593184, Final Batch Loss: 0.0003163591318298131\n",
      "Epoch 2543, Loss: 0.006535369855555473, Final Batch Loss: 4.622475171345286e-05\n",
      "Epoch 2544, Loss: 0.0007397704303002683, Final Batch Loss: 1.790816713764798e-05\n",
      "Epoch 2545, Loss: 0.00045297482574824244, Final Batch Loss: 0.00037706259172409773\n",
      "Epoch 2546, Loss: 0.00051245581562398, Final Batch Loss: 9.98031537164934e-05\n",
      "Epoch 2547, Loss: 0.0006599272965104319, Final Batch Loss: 0.0004434502334333956\n",
      "Epoch 2548, Loss: 0.003510076130623929, Final Batch Loss: 0.0028846641071140766\n",
      "Epoch 2549, Loss: 0.00046665519039379433, Final Batch Loss: 0.00019253608479630202\n",
      "Epoch 2550, Loss: 0.0002561337059887592, Final Batch Loss: 3.712917532538995e-05\n",
      "Epoch 2551, Loss: 0.00046549046601285227, Final Batch Loss: 4.1422314097872004e-05\n",
      "Epoch 2552, Loss: 0.0005517566532944329, Final Batch Loss: 3.5679688153322786e-05\n",
      "Epoch 2553, Loss: 0.00044492793631434324, Final Batch Loss: 5.616558610199718e-06\n",
      "Epoch 2554, Loss: 0.0036904180778947193, Final Batch Loss: 0.0035866990219801664\n",
      "Epoch 2555, Loss: 0.00027602585032582283, Final Batch Loss: 5.733007128583267e-05\n",
      "Epoch 2556, Loss: 0.0007553481959803321, Final Batch Loss: 4.812598945136415e-06\n",
      "Epoch 2557, Loss: 0.0012411026982590556, Final Batch Loss: 0.00016978303028736264\n",
      "Epoch 2558, Loss: 0.001294830726692453, Final Batch Loss: 0.000796591630205512\n",
      "Epoch 2559, Loss: 0.002310564519575564, Final Batch Loss: 0.00011517196981003508\n",
      "Epoch 2560, Loss: 0.0018856565293390304, Final Batch Loss: 0.0007457082392647862\n",
      "Epoch 2561, Loss: 0.00046450757872662507, Final Batch Loss: 0.0001683462323853746\n",
      "Epoch 2562, Loss: 0.0006601647628485807, Final Batch Loss: 1.0180739081988577e-05\n",
      "Epoch 2563, Loss: 0.00037555923518084455, Final Batch Loss: 6.336458682199009e-06\n",
      "Epoch 2564, Loss: 0.0008507703460054472, Final Batch Loss: 0.0004039521736558527\n",
      "Epoch 2565, Loss: 0.009769684402272105, Final Batch Loss: 0.0048910039477050304\n",
      "Epoch 2566, Loss: 0.00010520871683183941, Final Batch Loss: 3.4545696507848334e-06\n",
      "Epoch 2567, Loss: 0.0010141841194126755, Final Batch Loss: 0.00019579667423386127\n",
      "Epoch 2568, Loss: 0.001286183498450555, Final Batch Loss: 5.936848174314946e-05\n",
      "Epoch 2569, Loss: 0.0005605823935184162, Final Batch Loss: 2.9188715416239575e-05\n",
      "Epoch 2570, Loss: 0.005220401013502851, Final Batch Loss: 0.00017890040180645883\n",
      "Epoch 2571, Loss: 0.0015621690690750256, Final Batch Loss: 6.386504537658766e-05\n",
      "Epoch 2572, Loss: 0.012164138824118709, Final Batch Loss: 9.893318747344892e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2573, Loss: 0.012215635120810475, Final Batch Loss: 0.0002444919664412737\n",
      "Epoch 2574, Loss: 0.0024738315150898416, Final Batch Loss: 7.443439244525507e-05\n",
      "Epoch 2575, Loss: 0.00018039138376479968, Final Batch Loss: 7.573117181891575e-05\n",
      "Epoch 2576, Loss: 0.0003043505275854841, Final Batch Loss: 0.00016177422367036343\n",
      "Epoch 2577, Loss: 0.0007697178225498646, Final Batch Loss: 0.0003277369833085686\n",
      "Epoch 2578, Loss: 0.0008713860152056441, Final Batch Loss: 0.0003498565929476172\n",
      "Epoch 2579, Loss: 0.0021327496106096078, Final Batch Loss: 9.909694199450314e-06\n",
      "Epoch 2580, Loss: 0.00039917747835716, Final Batch Loss: 1.0054652193502989e-05\n",
      "Epoch 2581, Loss: 0.00858897825673921, Final Batch Loss: 2.3857333872001618e-05\n",
      "Epoch 2582, Loss: 0.0001891773281386122, Final Batch Loss: 4.1922285163309425e-05\n",
      "Epoch 2583, Loss: 0.000425736558099743, Final Batch Loss: 0.00021980676683597267\n",
      "Epoch 2584, Loss: 0.00021698866385122528, Final Batch Loss: 1.247349337063497e-05\n",
      "Epoch 2585, Loss: 0.0007967126257426571, Final Batch Loss: 1.816342046367936e-05\n",
      "Epoch 2586, Loss: 0.00012471865466068266, Final Batch Loss: 6.142064194136765e-06\n",
      "Epoch 2587, Loss: 0.0002716905510169454, Final Batch Loss: 4.454502777662128e-05\n",
      "Epoch 2588, Loss: 0.006160074801300652, Final Batch Loss: 0.0001321269228355959\n",
      "Epoch 2589, Loss: 0.0003250327195019054, Final Batch Loss: 6.794440650992328e-06\n",
      "Epoch 2590, Loss: 0.0032309825824086147, Final Batch Loss: 3.81917061531567e-06\n",
      "Epoch 2591, Loss: 0.0007585884451373204, Final Batch Loss: 1.1359808240740676e-06\n",
      "Epoch 2592, Loss: 0.0003676974283735035, Final Batch Loss: 0.00010152337199542671\n",
      "Epoch 2593, Loss: 0.0011546988707777928, Final Batch Loss: 1.4780906894884538e-05\n",
      "Epoch 2594, Loss: 0.0004610961113939993, Final Batch Loss: 7.976062624948099e-05\n",
      "Epoch 2595, Loss: 0.0012288935904507525, Final Batch Loss: 0.0003840261197183281\n",
      "Epoch 2596, Loss: 0.0008900925786292646, Final Batch Loss: 0.0007877075695432723\n",
      "Epoch 2597, Loss: 0.009023845710544265, Final Batch Loss: 1.0550900697126053e-05\n",
      "Epoch 2598, Loss: 0.000591591695410898, Final Batch Loss: 1.851045453804545e-05\n",
      "Epoch 2599, Loss: 0.0017393858179275412, Final Batch Loss: 2.1851352357771248e-05\n",
      "Epoch 2600, Loss: 4.758033264806727e-05, Final Batch Loss: 2.4677767214598134e-05\n",
      "Epoch 2601, Loss: 0.0004918419929254014, Final Batch Loss: 2.655264552231529e-06\n",
      "Epoch 2602, Loss: 0.0008164782957464922, Final Batch Loss: 2.062930798274465e-05\n",
      "Epoch 2603, Loss: 0.01325875843394897, Final Batch Loss: 5.646779391099699e-05\n",
      "Epoch 2604, Loss: 0.0005890785851079272, Final Batch Loss: 1.8700071450439282e-05\n",
      "Epoch 2605, Loss: 0.0011620253717410378, Final Batch Loss: 0.0010144429979845881\n",
      "Epoch 2606, Loss: 0.00030407416124944575, Final Batch Loss: 6.714714254485443e-05\n",
      "Epoch 2607, Loss: 0.005082909541670233, Final Batch Loss: 0.004869361873716116\n",
      "Epoch 2608, Loss: 0.0003154041314701317, Final Batch Loss: 1.0317382475477643e-05\n",
      "Epoch 2609, Loss: 0.0006219050846993923, Final Batch Loss: 0.00016971166769508272\n",
      "Epoch 2610, Loss: 0.0006312894511211198, Final Batch Loss: 0.0003120964684057981\n",
      "Epoch 2611, Loss: 0.0005921422416577116, Final Batch Loss: 0.00013052759459242225\n",
      "Epoch 2612, Loss: 0.000217627711208479, Final Batch Loss: 8.774176421866287e-06\n",
      "Epoch 2613, Loss: 0.0006494100889540277, Final Batch Loss: 4.2369269067421556e-05\n",
      "Epoch 2614, Loss: 0.00015761199392727576, Final Batch Loss: 7.510174327762797e-05\n",
      "Epoch 2615, Loss: 0.0005445928256904153, Final Batch Loss: 2.6739146505860845e-06\n",
      "Epoch 2616, Loss: 0.00035293819519210956, Final Batch Loss: 5.64904757993645e-06\n",
      "Epoch 2617, Loss: 0.0002886138972826302, Final Batch Loss: 0.00010386241046944633\n",
      "Epoch 2618, Loss: 0.0037042777257738635, Final Batch Loss: 2.554027014411986e-05\n",
      "Epoch 2619, Loss: 0.0004157936928095296, Final Batch Loss: 0.00011324135266477242\n",
      "Epoch 2620, Loss: 0.0004425682254804997, Final Batch Loss: 1.5363750208052807e-05\n",
      "Epoch 2621, Loss: 0.0002698167954804376, Final Batch Loss: 9.825597226154059e-05\n",
      "Epoch 2622, Loss: 0.026932222997857025, Final Batch Loss: 3.1171304726740345e-05\n",
      "Epoch 2623, Loss: 0.015122591808903962, Final Batch Loss: 0.014541469514369965\n",
      "Epoch 2624, Loss: 0.0018270126020070165, Final Batch Loss: 6.341357948258519e-05\n",
      "Epoch 2625, Loss: 0.000531619162984498, Final Batch Loss: 1.6595688521192642e-06\n",
      "Epoch 2626, Loss: 0.003350938543007942, Final Batch Loss: 3.144108995911665e-05\n",
      "Epoch 2627, Loss: 0.0022904701727384236, Final Batch Loss: 3.105774158029817e-05\n",
      "Epoch 2628, Loss: 0.0012329147211858071, Final Batch Loss: 0.0010139088844880462\n",
      "Epoch 2629, Loss: 0.00030496777799271513, Final Batch Loss: 2.7602307454799302e-05\n",
      "Epoch 2630, Loss: 0.0010191973415203393, Final Batch Loss: 3.713835030794144e-05\n",
      "Epoch 2631, Loss: 0.0032540184911340475, Final Batch Loss: 0.00022936926688998938\n",
      "Epoch 2632, Loss: 0.0006626256435993128, Final Batch Loss: 0.00029968173475936055\n",
      "Epoch 2633, Loss: 0.0006903475114086177, Final Batch Loss: 0.00035872182343155146\n",
      "Epoch 2634, Loss: 0.00030322260136017576, Final Batch Loss: 2.8654965717578307e-05\n",
      "Epoch 2635, Loss: 0.0014381170039996505, Final Batch Loss: 0.0007164903217926621\n",
      "Epoch 2636, Loss: 0.00028983863739995286, Final Batch Loss: 0.00011544783046701923\n",
      "Epoch 2637, Loss: 0.0017391465662512928, Final Batch Loss: 0.0010049783159047365\n",
      "Epoch 2638, Loss: 0.0004149097094341414, Final Batch Loss: 1.1108848411822692e-05\n",
      "Epoch 2639, Loss: 0.0011002578248735517, Final Batch Loss: 0.0006309268646873534\n",
      "Epoch 2640, Loss: 0.011569578025955707, Final Batch Loss: 0.00018008032930083573\n",
      "Epoch 2641, Loss: 0.001072281979759282, Final Batch Loss: 3.153102625219617e-06\n",
      "Epoch 2642, Loss: 0.0003662816648102307, Final Batch Loss: 9.793798199098092e-07\n",
      "Epoch 2643, Loss: 0.00032622666913084686, Final Batch Loss: 0.00010850784747162834\n",
      "Epoch 2644, Loss: 0.0007434464059770107, Final Batch Loss: 4.5403568947222084e-05\n",
      "Epoch 2645, Loss: 0.0034852954777306877, Final Batch Loss: 0.00011074794747401029\n",
      "Epoch 2646, Loss: 0.017681342838841374, Final Batch Loss: 0.01731356605887413\n",
      "Epoch 2647, Loss: 0.00019031235206057318, Final Batch Loss: 3.5720655432669446e-05\n",
      "Epoch 2648, Loss: 0.004516457629506476, Final Batch Loss: 0.004244967829436064\n",
      "Epoch 2649, Loss: 0.00356501181886415, Final Batch Loss: 3.603355071390979e-05\n",
      "Epoch 2650, Loss: 0.006908257179020438, Final Batch Loss: 0.00567778293043375\n",
      "Epoch 2651, Loss: 0.004319939740526024, Final Batch Loss: 5.4551004723180085e-05\n",
      "Epoch 2652, Loss: 0.0026407499663037015, Final Batch Loss: 2.169127947126981e-05\n",
      "Epoch 2653, Loss: 0.01833357739724306, Final Batch Loss: 7.455927516275551e-06\n",
      "Epoch 2654, Loss: 0.0012886129024991533, Final Batch Loss: 1.7245756680495106e-05\n",
      "Epoch 2655, Loss: 0.0019309155468363315, Final Batch Loss: 0.0015666598919779062\n",
      "Epoch 2656, Loss: 0.0004357197067292873, Final Batch Loss: 3.0440951377386227e-05\n",
      "Epoch 2657, Loss: 0.0007189776806626469, Final Batch Loss: 0.0005161591107025743\n",
      "Epoch 2658, Loss: 0.00011990133566541772, Final Batch Loss: 2.9847403766325442e-06\n",
      "Epoch 2659, Loss: 0.005379371974413516, Final Batch Loss: 0.005259554833173752\n",
      "Epoch 2660, Loss: 0.0022672121122013777, Final Batch Loss: 0.00035779402242042124\n",
      "Epoch 2661, Loss: 0.001906883786432445, Final Batch Loss: 1.5563186025246978e-05\n",
      "Epoch 2662, Loss: 0.00023873354075476527, Final Batch Loss: 5.2217714255675673e-05\n",
      "Epoch 2663, Loss: 0.0002688818949536653, Final Batch Loss: 0.00017548025061842054\n",
      "Epoch 2664, Loss: 0.0048956177779473364, Final Batch Loss: 7.044368248898536e-05\n",
      "Epoch 2665, Loss: 0.0021811349142808467, Final Batch Loss: 8.11010249890387e-05\n",
      "Epoch 2666, Loss: 0.000446515756266308, Final Batch Loss: 1.0631078112055548e-05\n",
      "Epoch 2667, Loss: 0.00013232271157903597, Final Batch Loss: 2.5433109840378165e-05\n",
      "Epoch 2668, Loss: 0.0005376027329475619, Final Batch Loss: 0.00030996627174317837\n",
      "Epoch 2669, Loss: 0.0003075946369790472, Final Batch Loss: 5.311001950758509e-05\n",
      "Epoch 2670, Loss: 9.394250128025305e-05, Final Batch Loss: 5.988088105368661e-06\n",
      "Epoch 2671, Loss: 0.002877939113204775, Final Batch Loss: 3.218417077732738e-06\n",
      "Epoch 2672, Loss: 0.0005196297206566669, Final Batch Loss: 0.0003500278398860246\n",
      "Epoch 2673, Loss: 0.00013091591426928062, Final Batch Loss: 2.6571726266411133e-05\n",
      "Epoch 2674, Loss: 0.0004404742612678092, Final Batch Loss: 4.56337547802832e-05\n",
      "Epoch 2675, Loss: 0.0036001894404762425, Final Batch Loss: 0.00028233882039785385\n",
      "Epoch 2676, Loss: 0.0006538556554005481, Final Batch Loss: 3.2864038075786084e-05\n",
      "Epoch 2677, Loss: 0.00018414794135424017, Final Batch Loss: 1.0681985713745235e-06\n",
      "Epoch 2678, Loss: 9.716940348880598e-05, Final Batch Loss: 7.138164619391318e-06\n",
      "Epoch 2679, Loss: 0.002549203250964638, Final Batch Loss: 0.002262413501739502\n",
      "Epoch 2680, Loss: 0.00010341730694563012, Final Batch Loss: 7.116857432265533e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2681, Loss: 0.0008249104357673787, Final Batch Loss: 0.0003376716049388051\n",
      "Epoch 2682, Loss: 0.0002627641551953275, Final Batch Loss: 0.00014295843720901757\n",
      "Epoch 2683, Loss: 0.0016833695199238718, Final Batch Loss: 0.0016452778363600373\n",
      "Epoch 2684, Loss: 0.0007422940725518856, Final Batch Loss: 3.528013257891871e-05\n",
      "Epoch 2685, Loss: 0.0003299977224742179, Final Batch Loss: 1.1858673133247066e-05\n",
      "Epoch 2686, Loss: 0.008974273630883545, Final Batch Loss: 1.2980537576368079e-05\n",
      "Epoch 2687, Loss: 0.00022739199812349398, Final Batch Loss: 2.9018696295679547e-05\n",
      "Epoch 2688, Loss: 0.0008429457202510093, Final Batch Loss: 9.208201845467556e-06\n",
      "Epoch 2689, Loss: 0.01971441285331821, Final Batch Loss: 1.475479712098604e-05\n",
      "Epoch 2690, Loss: 0.000955114810494706, Final Batch Loss: 0.00029985554283484817\n",
      "Epoch 2691, Loss: 0.0009842472500167787, Final Batch Loss: 0.0001604659337317571\n",
      "Epoch 2692, Loss: 0.0002858046009350801, Final Batch Loss: 2.984548336826265e-05\n",
      "Epoch 2693, Loss: 0.005279571887513157, Final Batch Loss: 8.218123548431322e-05\n",
      "Epoch 2694, Loss: 0.00016190804149118776, Final Batch Loss: 3.5317809761181707e-06\n",
      "Epoch 2695, Loss: 0.002582170334790135, Final Batch Loss: 0.0004284499154891819\n",
      "Epoch 2696, Loss: 0.0007464373629773036, Final Batch Loss: 1.882627111626789e-05\n",
      "Epoch 2697, Loss: 0.0003149198691971833, Final Batch Loss: 2.117453004757408e-05\n",
      "Epoch 2698, Loss: 0.001360174544970505, Final Batch Loss: 2.2007603547535837e-05\n",
      "Epoch 2699, Loss: 0.0002660198479134124, Final Batch Loss: 0.00010036038293037564\n",
      "Epoch 2700, Loss: 0.0007810902025084943, Final Batch Loss: 0.00042609369847923517\n",
      "Epoch 2701, Loss: 0.000253739738582226, Final Batch Loss: 1.1172146514581982e-05\n",
      "Epoch 2702, Loss: 0.0013055743947916199, Final Batch Loss: 0.0004743497120216489\n",
      "Epoch 2703, Loss: 0.0033065705974877346, Final Batch Loss: 0.0031512617133557796\n",
      "Epoch 2704, Loss: 0.00021010247291997075, Final Batch Loss: 9.454524115426466e-05\n",
      "Epoch 2705, Loss: 0.0010127566583832959, Final Batch Loss: 2.336827492399607e-05\n",
      "Epoch 2706, Loss: 0.000630305312370183, Final Batch Loss: 1.745044210110791e-05\n",
      "Epoch 2707, Loss: 0.005791200241219485, Final Batch Loss: 5.261967089609243e-05\n",
      "Epoch 2708, Loss: 0.008117270466755144, Final Batch Loss: 6.66412161081098e-05\n",
      "Epoch 2709, Loss: 0.00048714713148001465, Final Batch Loss: 5.3289982133719604e-06\n",
      "Epoch 2710, Loss: 0.0006589612621610286, Final Batch Loss: 1.374963358102832e-05\n",
      "Epoch 2711, Loss: 0.0006047947099432349, Final Batch Loss: 0.00011180048750247806\n",
      "Epoch 2712, Loss: 0.006874177826830419, Final Batch Loss: 4.2518240661593154e-05\n",
      "Epoch 2713, Loss: 0.0002344938911846839, Final Batch Loss: 3.750085670617409e-05\n",
      "Epoch 2714, Loss: 0.0006335187304102874, Final Batch Loss: 2.056922767224023e-06\n",
      "Epoch 2715, Loss: 0.002310635260073468, Final Batch Loss: 0.0008051034528762102\n",
      "Epoch 2716, Loss: 0.0035306577283336082, Final Batch Loss: 2.1442063371068798e-05\n",
      "Epoch 2717, Loss: 0.0029730059031862766, Final Batch Loss: 0.00194843381177634\n",
      "Epoch 2718, Loss: 0.00048461796905030496, Final Batch Loss: 5.1406841521384194e-05\n",
      "Epoch 2719, Loss: 0.0007799687518854626, Final Batch Loss: 2.8929218387929723e-05\n",
      "Epoch 2720, Loss: 0.0003688204087666236, Final Batch Loss: 0.00010460646444698796\n",
      "Epoch 2721, Loss: 0.011560270591871813, Final Batch Loss: 0.0001639431284274906\n",
      "Epoch 2722, Loss: 0.0010796284072966955, Final Batch Loss: 5.453086032503052e-06\n",
      "Epoch 2723, Loss: 0.005777205267804675, Final Batch Loss: 0.002785212593153119\n",
      "Epoch 2724, Loss: 0.00025678036217868794, Final Batch Loss: 2.3473543478758074e-05\n",
      "Epoch 2725, Loss: 0.0002898541133617982, Final Batch Loss: 5.4138268751557916e-05\n",
      "Epoch 2726, Loss: 0.0006929138471605256, Final Batch Loss: 0.00023707518994342536\n",
      "Epoch 2727, Loss: 0.0007405839819512039, Final Batch Loss: 6.605270300497068e-06\n",
      "Epoch 2728, Loss: 0.0003806263084698003, Final Batch Loss: 7.187041774159297e-06\n",
      "Epoch 2729, Loss: 0.013777638465398923, Final Batch Loss: 0.0002414685150142759\n",
      "Epoch 2730, Loss: 0.0005042253324063495, Final Batch Loss: 5.1452137995511293e-05\n",
      "Epoch 2731, Loss: 0.008916726110328455, Final Batch Loss: 1.0100433428306133e-05\n",
      "Epoch 2732, Loss: 0.0003934036303689936, Final Batch Loss: 2.5488867322565056e-05\n",
      "Epoch 2733, Loss: 0.001982914371183142, Final Batch Loss: 0.001489559537731111\n",
      "Epoch 2734, Loss: 0.00024105020202114247, Final Batch Loss: 0.00011149664351250976\n",
      "Epoch 2735, Loss: 0.0003415844403207302, Final Batch Loss: 3.380102862138301e-05\n",
      "Epoch 2736, Loss: 0.004648334750527283, Final Batch Loss: 0.00011743933282559738\n",
      "Epoch 2737, Loss: 0.007534704767749645, Final Batch Loss: 0.0032065147534012794\n",
      "Epoch 2738, Loss: 0.0006030506351635267, Final Batch Loss: 7.497671958844876e-06\n",
      "Epoch 2739, Loss: 0.003410187619010685, Final Batch Loss: 2.7712329028872773e-05\n",
      "Epoch 2740, Loss: 0.0436887773394119, Final Batch Loss: 0.00017345436208415776\n",
      "Epoch 2741, Loss: 0.00029011061178607633, Final Batch Loss: 9.283800864068326e-06\n",
      "Epoch 2742, Loss: 0.00538783713545854, Final Batch Loss: 4.384734893392306e-06\n",
      "Epoch 2743, Loss: 0.0003565141405488248, Final Batch Loss: 1.1734701729437802e-05\n",
      "Epoch 2744, Loss: 0.0010951809308608063, Final Batch Loss: 0.0006314477068372071\n",
      "Epoch 2745, Loss: 0.0004521731818840635, Final Batch Loss: 2.402804284429294e-06\n",
      "Epoch 2746, Loss: 0.0005174004636501195, Final Batch Loss: 1.3466302334563807e-05\n",
      "Epoch 2747, Loss: 0.0003770094622268516, Final Batch Loss: 6.597605079150526e-06\n",
      "Epoch 2748, Loss: 0.00048676154654003767, Final Batch Loss: 5.679943342329352e-07\n",
      "Epoch 2749, Loss: 0.00022078395704738796, Final Batch Loss: 1.377736043650657e-05\n",
      "Epoch 2750, Loss: 0.0016647044321871363, Final Batch Loss: 0.0005591416265815496\n",
      "Epoch 2751, Loss: 0.00028279153025323467, Final Batch Loss: 7.43297050576075e-07\n",
      "Epoch 2752, Loss: 0.0011501687758936896, Final Batch Loss: 0.0010849611135199666\n",
      "Epoch 2753, Loss: 0.0010251951689497218, Final Batch Loss: 4.055339559272397e-06\n",
      "Epoch 2754, Loss: 0.0006675374932001432, Final Batch Loss: 9.022367066791048e-07\n",
      "Epoch 2755, Loss: 0.0017598604772501858, Final Batch Loss: 7.77840796217788e-06\n",
      "Epoch 2756, Loss: 0.00011937360341107706, Final Batch Loss: 9.491646778769791e-05\n",
      "Epoch 2757, Loss: 0.0005381557202781551, Final Batch Loss: 7.740905857644975e-06\n",
      "Epoch 2758, Loss: 0.0005106360929403309, Final Batch Loss: 1.2318212156969821e-06\n",
      "Epoch 2759, Loss: 0.0001622324070922332, Final Batch Loss: 2.9673954486497678e-05\n",
      "Epoch 2760, Loss: 0.007034475373416171, Final Batch Loss: 1.325312382505217e-06\n",
      "Epoch 2761, Loss: 0.00010931097222055541, Final Batch Loss: 1.3042781574768014e-06\n",
      "Epoch 2762, Loss: 0.0009104863329412183, Final Batch Loss: 2.512059836590197e-05\n",
      "Epoch 2763, Loss: 8.744846218178282e-05, Final Batch Loss: 1.3832571312377695e-05\n",
      "Epoch 2764, Loss: 0.0006671429728157818, Final Batch Loss: 0.0002729001280386001\n",
      "Epoch 2765, Loss: 0.0008707054086585231, Final Batch Loss: 6.568163257725246e-07\n",
      "Epoch 2766, Loss: 0.0008755949447731837, Final Batch Loss: 1.2113566299376544e-05\n",
      "Epoch 2767, Loss: 0.0022415000207729463, Final Batch Loss: 0.0018426832975819707\n",
      "Epoch 2768, Loss: 0.00029367877141339704, Final Batch Loss: 0.00010379603190813214\n",
      "Epoch 2769, Loss: 0.0003918851134585566, Final Batch Loss: 0.00026622609584592283\n",
      "Epoch 2770, Loss: 9.98992613858718e-05, Final Batch Loss: 2.1153350644453894e-06\n",
      "Epoch 2771, Loss: 0.0018088016722686007, Final Batch Loss: 1.588658051332459e-05\n",
      "Epoch 2772, Loss: 0.039704566610453185, Final Batch Loss: 0.03844030201435089\n",
      "Epoch 2773, Loss: 0.0022628403776252526, Final Batch Loss: 1.3900901649321895e-05\n",
      "Epoch 2774, Loss: 0.00024059392580966232, Final Batch Loss: 3.657574052340351e-05\n",
      "Epoch 2775, Loss: 0.0002110312198055908, Final Batch Loss: 3.1224768463289365e-05\n",
      "Epoch 2776, Loss: 0.0010900972847593948, Final Batch Loss: 0.00017184762691613287\n",
      "Epoch 2777, Loss: 0.0029498929070541635, Final Batch Loss: 0.00018229405395686626\n",
      "Epoch 2778, Loss: 0.00020168484888927196, Final Batch Loss: 5.952705123490887e-06\n",
      "Epoch 2779, Loss: 0.0008556720713386312, Final Batch Loss: 0.000138720337417908\n",
      "Epoch 2780, Loss: 0.0015496946643906995, Final Batch Loss: 1.1500788787088823e-05\n",
      "Epoch 2781, Loss: 0.0006819458803875023, Final Batch Loss: 1.3085199498164002e-05\n",
      "Epoch 2782, Loss: 0.00019392113972571678, Final Batch Loss: 2.1574058337137103e-05\n",
      "Epoch 2783, Loss: 0.0006027545932738576, Final Batch Loss: 4.657948375097476e-05\n",
      "Epoch 2784, Loss: 0.011084756781656324, Final Batch Loss: 4.256359261489706e-06\n",
      "Epoch 2785, Loss: 0.00025401262973900884, Final Batch Loss: 0.00011332110443618149\n",
      "Epoch 2786, Loss: 0.0019154090696247295, Final Batch Loss: 7.083563832566142e-05\n",
      "Epoch 2787, Loss: 0.0013633330781885888, Final Batch Loss: 1.80691022251267e-05\n",
      "Epoch 2788, Loss: 0.0007081186049617827, Final Batch Loss: 0.00016922139911912382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2789, Loss: 0.005089738551760092, Final Batch Loss: 0.0003641681687440723\n",
      "Epoch 2790, Loss: 0.0007253303774632514, Final Batch Loss: 0.00012638617772608995\n",
      "Epoch 2791, Loss: 0.009848475852777483, Final Batch Loss: 8.100807463051751e-06\n",
      "Epoch 2792, Loss: 0.00043744093090936076, Final Batch Loss: 0.00020229410438332707\n",
      "Epoch 2793, Loss: 0.00359272796777077, Final Batch Loss: 0.0004008299729321152\n",
      "Epoch 2794, Loss: 0.00031333958759205416, Final Batch Loss: 0.00012669754505623132\n",
      "Epoch 2795, Loss: 0.0036100777306273812, Final Batch Loss: 2.627251888043247e-06\n",
      "Epoch 2796, Loss: 0.0006704282695864094, Final Batch Loss: 2.2523459847434424e-05\n",
      "Epoch 2797, Loss: 0.023245440366736148, Final Batch Loss: 5.271491318126209e-05\n",
      "Epoch 2798, Loss: 0.0008821487135719508, Final Batch Loss: 0.0004500896902754903\n",
      "Epoch 2799, Loss: 0.0008942346757976338, Final Batch Loss: 0.0006039467407390475\n",
      "Epoch 2800, Loss: 0.00012917800631839782, Final Batch Loss: 1.6326153854606673e-05\n",
      "Epoch 2801, Loss: 0.002390931207628455, Final Batch Loss: 0.00198769336566329\n",
      "Epoch 2802, Loss: 0.013919966780576942, Final Batch Loss: 6.848354587418726e-06\n",
      "Epoch 2803, Loss: 0.00019289443298475817, Final Batch Loss: 0.0001462941727368161\n",
      "Epoch 2804, Loss: 0.003146173316054046, Final Batch Loss: 4.3820426071761176e-05\n",
      "Epoch 2805, Loss: 0.00024812212905089837, Final Batch Loss: 0.0001812376722227782\n",
      "Epoch 2806, Loss: 0.0001775619975887821, Final Batch Loss: 1.0063959962280933e-05\n",
      "Epoch 2807, Loss: 0.00016036376564443344, Final Batch Loss: 0.00012750116002280265\n",
      "Epoch 2808, Loss: 0.0005184491146792425, Final Batch Loss: 0.00012106363283237442\n",
      "Epoch 2809, Loss: 0.0003018229253939353, Final Batch Loss: 3.175221354467794e-05\n",
      "Epoch 2810, Loss: 0.000163305587193463, Final Batch Loss: 2.9132757845218293e-05\n",
      "Epoch 2811, Loss: 0.00015344744861067738, Final Batch Loss: 1.2752045222441666e-05\n",
      "Epoch 2812, Loss: 0.0005864622671651887, Final Batch Loss: 7.011623893049546e-06\n",
      "Epoch 2813, Loss: 6.288771032814111e-05, Final Batch Loss: 1.8722100776358275e-06\n",
      "Epoch 2814, Loss: 0.00033971578068303643, Final Batch Loss: 4.8335959945688955e-06\n",
      "Epoch 2815, Loss: 0.00044321755922283046, Final Batch Loss: 1.6671776393195614e-05\n",
      "Epoch 2816, Loss: 0.0004979427358193789, Final Batch Loss: 0.0002717014285735786\n",
      "Epoch 2817, Loss: 0.00020641673472709954, Final Batch Loss: 9.019268327392638e-05\n",
      "Epoch 2818, Loss: 0.0008147189364535734, Final Batch Loss: 6.662686064373702e-05\n",
      "Epoch 2819, Loss: 0.00011727003038686235, Final Batch Loss: 2.705604310904164e-05\n",
      "Epoch 2820, Loss: 9.271874534988456e-05, Final Batch Loss: 1.5356732774307602e-06\n",
      "Epoch 2821, Loss: 0.08692084405993228, Final Batch Loss: 5.7965000451076776e-05\n",
      "Epoch 2822, Loss: 0.00034811087243724614, Final Batch Loss: 0.00018623328651301563\n",
      "Epoch 2823, Loss: 0.0006095616481616162, Final Batch Loss: 1.2270313163753599e-05\n",
      "Epoch 2824, Loss: 0.0013007875213588704, Final Batch Loss: 6.689250767522026e-06\n",
      "Epoch 2825, Loss: 0.0005183953489904525, Final Batch Loss: 2.338876402063761e-05\n",
      "Epoch 2826, Loss: 0.004503342555835843, Final Batch Loss: 0.0003734324418473989\n",
      "Epoch 2827, Loss: 0.05283512081950903, Final Batch Loss: 0.01924879476428032\n",
      "Epoch 2828, Loss: 0.00021424849546747282, Final Batch Loss: 1.5182413335423917e-05\n",
      "Epoch 2829, Loss: 0.0008027821950236103, Final Batch Loss: 0.0006296057836152613\n",
      "Epoch 2830, Loss: 0.0010605821153149009, Final Batch Loss: 0.00028561719227582216\n",
      "Epoch 2831, Loss: 0.004083000334503595, Final Batch Loss: 0.002705302555114031\n",
      "Epoch 2832, Loss: 0.0007757543316984084, Final Batch Loss: 0.00020552694331854582\n",
      "Epoch 2833, Loss: 0.0030040370183996856, Final Batch Loss: 0.0009408441837877035\n",
      "Epoch 2834, Loss: 0.002140512107871473, Final Batch Loss: 0.00012955744750797749\n",
      "Epoch 2835, Loss: 0.0019010802498087287, Final Batch Loss: 0.00019803605391643941\n",
      "Epoch 2836, Loss: 0.0007785326124576386, Final Batch Loss: 3.498210207908414e-05\n",
      "Epoch 2837, Loss: 0.0003175939846187248, Final Batch Loss: 6.562938324350398e-06\n",
      "Epoch 2838, Loss: 0.0008368420603801496, Final Batch Loss: 6.628732808167115e-05\n",
      "Epoch 2839, Loss: 0.00189891921763774, Final Batch Loss: 0.001233863877132535\n",
      "Epoch 2840, Loss: 0.003053008796996437, Final Batch Loss: 0.0006202220683917403\n",
      "Epoch 2841, Loss: 0.0004770753002958372, Final Batch Loss: 0.00018659597844816744\n",
      "Epoch 2842, Loss: 0.0009050766675500199, Final Batch Loss: 0.0001732810924295336\n",
      "Epoch 2843, Loss: 0.0006950914585104329, Final Batch Loss: 0.00037138312472961843\n",
      "Epoch 2844, Loss: 0.0009664021763455821, Final Batch Loss: 0.0008023655391298234\n",
      "Epoch 2845, Loss: 0.0010986669185513165, Final Batch Loss: 2.666744330781512e-05\n",
      "Epoch 2846, Loss: 0.0022714059814461507, Final Batch Loss: 0.0019001810578629375\n",
      "Epoch 2847, Loss: 0.0002635193341120612, Final Batch Loss: 8.307272946694866e-05\n",
      "Epoch 2848, Loss: 0.00118059225496836, Final Batch Loss: 0.00040003127651289105\n",
      "Epoch 2849, Loss: 0.0006134860595921054, Final Batch Loss: 1.7324869986623526e-05\n",
      "Epoch 2850, Loss: 0.0006786568255847669, Final Batch Loss: 1.4463802472164389e-05\n",
      "Epoch 2851, Loss: 0.0032262941167573445, Final Batch Loss: 0.0027332021854817867\n",
      "Epoch 2852, Loss: 0.00017588050468475558, Final Batch Loss: 2.0410076103871688e-05\n",
      "Epoch 2853, Loss: 0.0005668762969435193, Final Batch Loss: 0.00025267142336815596\n",
      "Epoch 2854, Loss: 0.00057045590801863, Final Batch Loss: 0.00036818048101849854\n",
      "Epoch 2855, Loss: 0.0005756835744250566, Final Batch Loss: 4.011215060018003e-05\n",
      "Epoch 2856, Loss: 0.00040708263259148225, Final Batch Loss: 1.0071380529552698e-05\n",
      "Epoch 2857, Loss: 0.006115370346378768, Final Batch Loss: 5.710215191356838e-05\n",
      "Epoch 2858, Loss: 0.00010522626234887866, Final Batch Loss: 4.970558802597225e-05\n",
      "Epoch 2859, Loss: 0.00038004337329766713, Final Batch Loss: 2.8562390070874244e-06\n",
      "Epoch 2860, Loss: 0.0004043317894684151, Final Batch Loss: 2.0999075786676258e-05\n",
      "Epoch 2861, Loss: 0.00025139674107776955, Final Batch Loss: 0.0001001044875010848\n",
      "Epoch 2862, Loss: 0.0006150453264126554, Final Batch Loss: 2.3327767848968506e-05\n",
      "Epoch 2863, Loss: 0.0007598233921726205, Final Batch Loss: 2.6996556243830128e-06\n",
      "Epoch 2864, Loss: 0.0039948478297446854, Final Batch Loss: 9.279841469833627e-05\n",
      "Epoch 2865, Loss: 0.0038959967914706795, Final Batch Loss: 2.292089629918337e-05\n",
      "Epoch 2866, Loss: 0.0006662797995886649, Final Batch Loss: 4.387146873341408e-06\n",
      "Epoch 2867, Loss: 0.0022545439314853866, Final Batch Loss: 3.5476859920891e-05\n",
      "Epoch 2868, Loss: 0.00042283906077500433, Final Batch Loss: 4.164072743151337e-05\n",
      "Epoch 2869, Loss: 0.0002467610866005998, Final Batch Loss: 0.00011299546167720109\n",
      "Epoch 2870, Loss: 0.0003978154418291524, Final Batch Loss: 2.7679187041940168e-05\n",
      "Epoch 2871, Loss: 0.0002975938459712779, Final Batch Loss: 2.7640116968541406e-05\n",
      "Epoch 2872, Loss: 0.0003569324762793258, Final Batch Loss: 4.153458576183766e-06\n",
      "Epoch 2873, Loss: 0.0013232651326688938, Final Batch Loss: 1.5520417946390808e-06\n",
      "Epoch 2874, Loss: 0.0007381629329756834, Final Batch Loss: 0.0005402460228651762\n",
      "Epoch 2875, Loss: 0.0007419665889756288, Final Batch Loss: 0.000634755298960954\n",
      "Epoch 2876, Loss: 0.00026795068697538227, Final Batch Loss: 5.29592034581583e-05\n",
      "Epoch 2877, Loss: 0.0032835036399774253, Final Batch Loss: 0.0025654276832938194\n",
      "Epoch 2878, Loss: 0.0008000740635907277, Final Batch Loss: 0.0005046920268796384\n",
      "Epoch 2879, Loss: 0.0009766447328729555, Final Batch Loss: 4.0013947000261396e-05\n",
      "Epoch 2880, Loss: 0.00010706923058023676, Final Batch Loss: 4.146346327615902e-06\n",
      "Epoch 2881, Loss: 0.0003636889632616658, Final Batch Loss: 3.259587174397893e-05\n",
      "Epoch 2882, Loss: 0.0002476402405591216, Final Batch Loss: 4.4339714804664254e-05\n",
      "Epoch 2883, Loss: 0.005944352207734482, Final Batch Loss: 5.570229041040875e-05\n",
      "Epoch 2884, Loss: 0.000249663973022507, Final Batch Loss: 1.341658730780182e-06\n",
      "Epoch 2885, Loss: 0.00025440799618081655, Final Batch Loss: 1.2903063179692253e-05\n",
      "Epoch 2886, Loss: 0.00030169748424668796, Final Batch Loss: 2.4684970412636176e-05\n",
      "Epoch 2887, Loss: 0.00014663367301182006, Final Batch Loss: 8.562748007534537e-06\n",
      "Epoch 2888, Loss: 0.00016025076638470637, Final Batch Loss: 4.847604031965602e-06\n",
      "Epoch 2889, Loss: 0.00027516106638358906, Final Batch Loss: 6.743724225088954e-05\n",
      "Epoch 2890, Loss: 0.0008205980993807316, Final Batch Loss: 0.0004020928463432938\n",
      "Epoch 2891, Loss: 0.00015504253769904608, Final Batch Loss: 4.8780029828776605e-06\n",
      "Epoch 2892, Loss: 0.01276630928987288, Final Batch Loss: 0.01268264465034008\n",
      "Epoch 2893, Loss: 0.00018039154497273557, Final Batch Loss: 2.4776447844487848e-06\n",
      "Epoch 2894, Loss: 0.0009982017190850456, Final Batch Loss: 0.0009002347942441702\n",
      "Epoch 2895, Loss: 0.001478171482176549, Final Batch Loss: 6.448430667660432e-06\n",
      "Epoch 2896, Loss: 0.007618354662554339, Final Batch Loss: 2.3687025532126427e-05\n",
      "Epoch 2897, Loss: 0.00035708159157366026, Final Batch Loss: 1.5566469301120378e-05\n",
      "Epoch 2898, Loss: 0.00011099152072802099, Final Batch Loss: 1.596442984919122e-06\n",
      "Epoch 2899, Loss: 0.0010870738769881427, Final Batch Loss: 0.00011816836922662333\n",
      "Epoch 2900, Loss: 0.0007092095911502838, Final Batch Loss: 9.153525752481073e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2901, Loss: 0.0002849375923688058, Final Batch Loss: 8.45134854898788e-06\n",
      "Epoch 2902, Loss: 0.001817966825910844, Final Batch Loss: 0.0017349736299365759\n",
      "Epoch 2903, Loss: 0.00043132536393386545, Final Batch Loss: 7.098185051290784e-06\n",
      "Epoch 2904, Loss: 0.0004783739095728379, Final Batch Loss: 1.744131077430211e-05\n",
      "Epoch 2905, Loss: 0.000371142628864618, Final Batch Loss: 3.670144724310376e-05\n",
      "Epoch 2906, Loss: 0.00013051933819951955, Final Batch Loss: 4.9844453315017745e-05\n",
      "Epoch 2907, Loss: 0.0001274916903639678, Final Batch Loss: 3.400255445740186e-05\n",
      "Epoch 2908, Loss: 0.000496770502650179, Final Batch Loss: 0.00019919616170227528\n",
      "Epoch 2909, Loss: 0.0001285794851355604, Final Batch Loss: 1.1416296729294118e-05\n",
      "Epoch 2910, Loss: 0.0007885828381404281, Final Batch Loss: 1.67666730703786e-05\n",
      "Epoch 2911, Loss: 0.00036883136635879055, Final Batch Loss: 0.00024857817334122956\n",
      "Epoch 2912, Loss: 0.00015976932718331227, Final Batch Loss: 9.70915425568819e-06\n",
      "Epoch 2913, Loss: 0.00015524386253673583, Final Batch Loss: 3.960580215789378e-05\n",
      "Epoch 2914, Loss: 0.0003340091643622145, Final Batch Loss: 7.45848155929707e-05\n",
      "Epoch 2915, Loss: 0.0004628745919035282, Final Batch Loss: 0.0001249787164852023\n",
      "Epoch 2916, Loss: 0.0001687428925833956, Final Batch Loss: 1.5637310752936173e-06\n",
      "Epoch 2917, Loss: 0.00033276185058639385, Final Batch Loss: 0.00022696565429214388\n",
      "Epoch 2918, Loss: 0.00027084150065093127, Final Batch Loss: 1.717994791761157e-06\n",
      "Epoch 2919, Loss: 0.00012633337610168383, Final Batch Loss: 8.874245395418257e-06\n",
      "Epoch 2920, Loss: 0.0009886129046208225, Final Batch Loss: 0.0005232021794654429\n",
      "Epoch 2921, Loss: 5.066231187811354e-05, Final Batch Loss: 4.875612830801401e-06\n",
      "Epoch 2922, Loss: 8.173111564246938e-05, Final Batch Loss: 2.366581065871287e-05\n",
      "Epoch 2923, Loss: 0.0003126443571090931, Final Batch Loss: 2.0064771888428368e-05\n",
      "Epoch 2924, Loss: 0.0039846606905484805, Final Batch Loss: 0.00011513128265505657\n",
      "Epoch 2925, Loss: 0.00015367266678367741, Final Batch Loss: 2.46090094151441e-05\n",
      "Epoch 2926, Loss: 0.00039020156327751465, Final Batch Loss: 5.7838045904645696e-05\n",
      "Epoch 2927, Loss: 0.004181901214906247, Final Batch Loss: 0.003989038988947868\n",
      "Epoch 2928, Loss: 0.00016501986465300433, Final Batch Loss: 3.2251969969365746e-05\n",
      "Epoch 2929, Loss: 0.00023450946991943056, Final Batch Loss: 9.156851774605457e-06\n",
      "Epoch 2930, Loss: 0.032047047210653545, Final Batch Loss: 0.02488025650382042\n",
      "Epoch 2931, Loss: 9.405431046616286e-05, Final Batch Loss: 2.776767360046506e-06\n",
      "Epoch 2932, Loss: 0.00016943050150075578, Final Batch Loss: 5.861852059751982e-06\n",
      "Epoch 2933, Loss: 0.00018214349984191358, Final Batch Loss: 1.4181016013026237e-05\n",
      "Epoch 2934, Loss: 0.0004160123689871398, Final Batch Loss: 2.6085372155648656e-06\n",
      "Epoch 2935, Loss: 0.00029682674812647747, Final Batch Loss: 1.3715475688513834e-05\n",
      "Epoch 2936, Loss: 0.0005481550797412638, Final Batch Loss: 0.0004695574170909822\n",
      "Epoch 2937, Loss: 0.00045384912300505675, Final Batch Loss: 6.023274181643501e-06\n",
      "Epoch 2938, Loss: 0.021982980088296245, Final Batch Loss: 1.3720530205318937e-06\n",
      "Epoch 2939, Loss: 0.00028849505724792834, Final Batch Loss: 0.00011340520723024383\n",
      "Epoch 2940, Loss: 0.0001327448153460864, Final Batch Loss: 7.334067777264863e-05\n",
      "Epoch 2941, Loss: 0.0006974856805754825, Final Batch Loss: 0.00012041152513120323\n",
      "Epoch 2942, Loss: 0.02133910107659176, Final Batch Loss: 0.0031388967763632536\n",
      "Epoch 2943, Loss: 0.0009300381784669298, Final Batch Loss: 7.72612384025706e-06\n",
      "Epoch 2944, Loss: 0.0006442665935537661, Final Batch Loss: 7.827623448974919e-06\n",
      "Epoch 2945, Loss: 0.006890650278364774, Final Batch Loss: 2.9363349312916398e-05\n",
      "Epoch 2946, Loss: 0.00042192860928480513, Final Batch Loss: 3.0424340366153046e-05\n",
      "Epoch 2947, Loss: 0.0007173615776991937, Final Batch Loss: 3.989042670582421e-05\n",
      "Epoch 2948, Loss: 0.00042585236587910913, Final Batch Loss: 0.0001057315239449963\n",
      "Epoch 2949, Loss: 0.0013841581312590279, Final Batch Loss: 0.0011323600774630904\n",
      "Epoch 2950, Loss: 0.008081708389909181, Final Batch Loss: 1.171042640635278e-06\n",
      "Epoch 2951, Loss: 0.0005646396311931312, Final Batch Loss: 7.07086655893363e-05\n",
      "Epoch 2952, Loss: 0.0007689148715144256, Final Batch Loss: 0.000568470626603812\n",
      "Epoch 2953, Loss: 0.004317537124734372, Final Batch Loss: 0.002242465503513813\n",
      "Epoch 2954, Loss: 0.0013851015537511557, Final Batch Loss: 0.00048528864863328636\n",
      "Epoch 2955, Loss: 0.000544608774362132, Final Batch Loss: 0.00016176566714420915\n",
      "Epoch 2956, Loss: 0.0012534294974102522, Final Batch Loss: 1.0728717825259082e-06\n",
      "Epoch 2957, Loss: 0.0007100061266100965, Final Batch Loss: 6.049629155313596e-05\n",
      "Epoch 2958, Loss: 0.00026419301502755843, Final Batch Loss: 1.6087946278275922e-05\n",
      "Epoch 2959, Loss: 0.0032852296899363864, Final Batch Loss: 0.0020719205494970083\n",
      "Epoch 2960, Loss: 0.0006021946755936369, Final Batch Loss: 3.461489541223273e-05\n",
      "Epoch 2961, Loss: 0.007104463107680203, Final Batch Loss: 4.2271411075489596e-05\n",
      "Epoch 2962, Loss: 0.0037248689113766886, Final Batch Loss: 0.0033833463676273823\n",
      "Epoch 2963, Loss: 0.009633335099351825, Final Batch Loss: 0.009529413655400276\n",
      "Epoch 2964, Loss: 0.0012113691118429415, Final Batch Loss: 0.0009732288308441639\n",
      "Epoch 2965, Loss: 0.0005209728115005419, Final Batch Loss: 3.946329525206238e-05\n",
      "Epoch 2966, Loss: 0.004981846966984449, Final Batch Loss: 5.291706111165695e-05\n",
      "Epoch 2967, Loss: 0.00026610975328367203, Final Batch Loss: 0.00010036176536232233\n",
      "Epoch 2968, Loss: 0.0008524073782609776, Final Batch Loss: 6.370904156938195e-05\n",
      "Epoch 2969, Loss: 0.0032185027484956663, Final Batch Loss: 5.5059921578504145e-05\n",
      "Epoch 2970, Loss: 0.00042026622213597875, Final Batch Loss: 4.459670890355483e-05\n",
      "Epoch 2971, Loss: 0.0005829126384924166, Final Batch Loss: 0.0002867504954338074\n",
      "Epoch 2972, Loss: 0.0005991428324705339, Final Batch Loss: 1.3994139408168849e-05\n",
      "Epoch 2973, Loss: 0.0013512999321392272, Final Batch Loss: 1.9451126718195155e-05\n",
      "Epoch 2974, Loss: 0.0028481318877311423, Final Batch Loss: 0.0017814509337767959\n",
      "Epoch 2975, Loss: 9.033785408973927e-05, Final Batch Loss: 2.4401431801379658e-05\n",
      "Epoch 2976, Loss: 0.00044382452324498445, Final Batch Loss: 0.0001361095637548715\n",
      "Epoch 2977, Loss: 0.00011046325926145073, Final Batch Loss: 5.6700653658481315e-05\n",
      "Epoch 2978, Loss: 0.001677994783676695, Final Batch Loss: 0.0014498960226774216\n",
      "Epoch 2979, Loss: 9.119064952756162e-05, Final Batch Loss: 2.1223199837550055e-06\n",
      "Epoch 2980, Loss: 0.0005581007685577788, Final Batch Loss: 4.452380835573422e-06\n",
      "Epoch 2981, Loss: 0.0003976261359639466, Final Batch Loss: 0.0002005976566579193\n",
      "Epoch 2982, Loss: 0.0006625438472838141, Final Batch Loss: 0.0004455277812667191\n",
      "Epoch 2983, Loss: 0.0009225537833117414, Final Batch Loss: 0.000553762773051858\n",
      "Epoch 2984, Loss: 0.003453265868301969, Final Batch Loss: 0.00014163008017931134\n",
      "Epoch 2985, Loss: 0.0003394687009858899, Final Batch Loss: 5.1105809689033777e-05\n",
      "Epoch 2986, Loss: 0.00031962644061422907, Final Batch Loss: 0.00021695882605854422\n",
      "Epoch 2987, Loss: 0.00013424222288449528, Final Batch Loss: 7.480408385163173e-05\n",
      "Epoch 2988, Loss: 0.0004868877222179435, Final Batch Loss: 1.2089400115655735e-05\n",
      "Epoch 2989, Loss: 0.0009600539015082177, Final Batch Loss: 2.7436191885499284e-05\n",
      "Epoch 2990, Loss: 0.00013309536279848544, Final Batch Loss: 2.0031575331813656e-06\n",
      "Epoch 2991, Loss: 0.0013284739397931844, Final Batch Loss: 0.0002953596122097224\n",
      "Epoch 2992, Loss: 0.0003867553286909242, Final Batch Loss: 9.024149221659172e-06\n",
      "Epoch 2993, Loss: 8.031282595766243e-05, Final Batch Loss: 6.818012479925528e-06\n",
      "Epoch 2994, Loss: 0.0005767911206930876, Final Batch Loss: 3.498460864648223e-05\n",
      "Epoch 2995, Loss: 0.0020982248897780664, Final Batch Loss: 3.575456139515154e-05\n",
      "Epoch 2996, Loss: 0.00046430851944023743, Final Batch Loss: 3.187046240782365e-05\n",
      "Epoch 2997, Loss: 0.0016316474648192525, Final Batch Loss: 0.00038752451655454934\n",
      "Epoch 2998, Loss: 0.0019900835686712526, Final Batch Loss: 6.737901276210323e-05\n",
      "Epoch 2999, Loss: 0.00671084691566648, Final Batch Loss: 0.00011050108878407627\n",
      "Epoch 3000, Loss: 0.0005615061236312613, Final Batch Loss: 0.0004228346806485206\n",
      "Epoch 3001, Loss: 0.0006492853644886054, Final Batch Loss: 6.304471025941893e-05\n",
      "Epoch 3002, Loss: 0.00018759005979518406, Final Batch Loss: 8.387064008275047e-05\n",
      "Epoch 3003, Loss: 3.789032962231431e-05, Final Batch Loss: 3.4709992178250104e-06\n",
      "Epoch 3004, Loss: 0.00023155991584644653, Final Batch Loss: 9.353512723464519e-05\n",
      "Epoch 3005, Loss: 0.0002953476468974259, Final Batch Loss: 6.705555279040709e-06\n",
      "Epoch 3006, Loss: 0.00037990656892361585, Final Batch Loss: 2.7534990294952877e-05\n",
      "Epoch 3007, Loss: 0.0013678102609446796, Final Batch Loss: 4.340512987255352e-06\n",
      "Epoch 3008, Loss: 0.00011894353883690201, Final Batch Loss: 3.3821852412074804e-06\n",
      "Epoch 3009, Loss: 0.004359649667094345, Final Batch Loss: 1.8143138731829822e-05\n",
      "Epoch 3010, Loss: 0.000770550046581775, Final Batch Loss: 5.4553180234506726e-05\n",
      "Epoch 3011, Loss: 0.000698468618793413, Final Batch Loss: 0.00044577286462299526\n",
      "Epoch 3012, Loss: 0.0008396249322686344, Final Batch Loss: 0.00024603703059256077\n",
      "Epoch 3013, Loss: 0.0010640451810104423, Final Batch Loss: 9.85717724688584e-06\n",
      "Epoch 3014, Loss: 0.013988979199893947, Final Batch Loss: 1.3911393580201548e-05\n",
      "Epoch 3015, Loss: 0.0002748021906882059, Final Batch Loss: 1.2461296137189493e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3016, Loss: 0.000499845471495064, Final Batch Loss: 0.00029507384169846773\n",
      "Epoch 3017, Loss: 0.0004266426834789172, Final Batch Loss: 2.197188138097772e-07\n",
      "Epoch 3018, Loss: 0.000309761899188743, Final Batch Loss: 0.00011044475104426965\n",
      "Epoch 3019, Loss: 0.02093577662799362, Final Batch Loss: 5.093067557027098e-06\n",
      "Epoch 3020, Loss: 0.0004067732079420239, Final Batch Loss: 3.39727703249082e-05\n",
      "Epoch 3021, Loss: 0.002067469453322701, Final Batch Loss: 2.9290247766766697e-05\n",
      "Epoch 3022, Loss: 0.03865459018470574, Final Batch Loss: 9.323396625404712e-06\n",
      "Epoch 3023, Loss: 0.12130145031551365, Final Batch Loss: 0.12096169590950012\n",
      "Epoch 3024, Loss: 0.00016459514017697074, Final Batch Loss: 5.752187007601606e-06\n",
      "Epoch 3025, Loss: 0.0019680314871948212, Final Batch Loss: 1.855347363743931e-05\n",
      "Epoch 3026, Loss: 0.00026551448900136165, Final Batch Loss: 5.092974970466457e-05\n",
      "Epoch 3027, Loss: 0.0004385493784866412, Final Batch Loss: 9.850756214291323e-06\n",
      "Epoch 3028, Loss: 0.004483333861571737, Final Batch Loss: 0.00013457979366648942\n",
      "Epoch 3029, Loss: 0.0004504278695094399, Final Batch Loss: 8.187690400518477e-05\n",
      "Epoch 3030, Loss: 0.00043937715236097574, Final Batch Loss: 6.843133451184258e-05\n",
      "Epoch 3031, Loss: 0.0005798083402623888, Final Batch Loss: 3.440147338551469e-05\n",
      "Epoch 3032, Loss: 0.0064057211143335735, Final Batch Loss: 2.1714527065341827e-06\n",
      "Epoch 3033, Loss: 0.0001114588030759478, Final Batch Loss: 1.6818121366668493e-05\n",
      "Epoch 3034, Loss: 0.0006163993966765702, Final Batch Loss: 1.070758662535809e-05\n",
      "Epoch 3035, Loss: 0.001929666439536959, Final Batch Loss: 0.0003715003258548677\n",
      "Epoch 3036, Loss: 0.00043528574497031514, Final Batch Loss: 2.271476296300534e-05\n",
      "Epoch 3037, Loss: 0.0004228616307955235, Final Batch Loss: 4.0739672840572894e-05\n",
      "Epoch 3038, Loss: 0.001884175695522572, Final Batch Loss: 8.895829523680732e-05\n",
      "Epoch 3039, Loss: 0.000676085143823002, Final Batch Loss: 1.3053407201368827e-05\n",
      "Epoch 3040, Loss: 0.00010519195711822249, Final Batch Loss: 2.3603108274983242e-05\n",
      "Epoch 3041, Loss: 0.01644549730917788, Final Batch Loss: 3.0591148970415816e-05\n",
      "Epoch 3042, Loss: 0.00010942801191049512, Final Batch Loss: 7.371603260253323e-06\n",
      "Epoch 3043, Loss: 0.001708650728687644, Final Batch Loss: 4.655152588384226e-05\n",
      "Epoch 3044, Loss: 0.0021936716730124317, Final Batch Loss: 0.0013456902233883739\n",
      "Epoch 3045, Loss: 0.0024074170360108837, Final Batch Loss: 3.913746331818402e-05\n",
      "Epoch 3046, Loss: 0.0034059950376104098, Final Batch Loss: 1.984049958991818e-05\n",
      "Epoch 3047, Loss: 0.0014247264189179987, Final Batch Loss: 0.0010652911150828004\n",
      "Epoch 3048, Loss: 0.0004639631661120802, Final Batch Loss: 0.0001735132245812565\n",
      "Epoch 3049, Loss: 0.0010566651180852205, Final Batch Loss: 0.00016338416025973856\n",
      "Epoch 3050, Loss: 0.0004211778250464704, Final Batch Loss: 3.270132219768129e-05\n",
      "Epoch 3051, Loss: 0.00018384277336735977, Final Batch Loss: 5.9320909713278525e-06\n",
      "Epoch 3052, Loss: 0.0005382400463531667, Final Batch Loss: 3.945422122342279e-06\n",
      "Epoch 3053, Loss: 0.0004948986770614283, Final Batch Loss: 1.8687716874410398e-05\n",
      "Epoch 3054, Loss: 0.0002200733306381153, Final Batch Loss: 2.6333376808906905e-05\n",
      "Epoch 3055, Loss: 0.00024856833852027194, Final Batch Loss: 5.469317784445593e-06\n",
      "Epoch 3056, Loss: 0.006120160345744807, Final Batch Loss: 3.0174385756254196e-05\n",
      "Epoch 3057, Loss: 0.0010424299271107884, Final Batch Loss: 2.086699714709539e-05\n",
      "Epoch 3058, Loss: 0.0007415473955916241, Final Batch Loss: 0.00022366871417034417\n",
      "Epoch 3059, Loss: 0.0004630541807273403, Final Batch Loss: 0.00019877094018738717\n",
      "Epoch 3060, Loss: 0.0005477719532791525, Final Batch Loss: 0.0001809753302950412\n",
      "Epoch 3061, Loss: 0.0015278217470040545, Final Batch Loss: 0.0012906668707728386\n",
      "Epoch 3062, Loss: 0.000412109541684913, Final Batch Loss: 1.1587443623284344e-05\n",
      "Epoch 3063, Loss: 0.001480141159845516, Final Batch Loss: 0.00030067007173784077\n",
      "Epoch 3064, Loss: 0.001007765153190121, Final Batch Loss: 0.00041579551179893315\n",
      "Epoch 3065, Loss: 0.0005723747744923458, Final Batch Loss: 0.0004367610381450504\n",
      "Epoch 3066, Loss: 0.000743170356599876, Final Batch Loss: 5.090624199510785e-06\n",
      "Epoch 3067, Loss: 0.00041157334362651454, Final Batch Loss: 4.4362359403749e-06\n",
      "Epoch 3068, Loss: 0.0001575592759763822, Final Batch Loss: 1.527312269899994e-05\n",
      "Epoch 3069, Loss: 0.00029030587029410526, Final Batch Loss: 6.859434506623074e-06\n",
      "Epoch 3070, Loss: 0.002082587205222808, Final Batch Loss: 2.4915323592722416e-05\n",
      "Epoch 3071, Loss: 0.0001707042356429156, Final Batch Loss: 4.907527181785554e-05\n",
      "Epoch 3072, Loss: 0.000555363338207826, Final Batch Loss: 7.343165634665638e-05\n",
      "Epoch 3073, Loss: 5.712017627956811e-05, Final Batch Loss: 4.188563252682798e-06\n",
      "Epoch 3074, Loss: 0.0013385503034442081, Final Batch Loss: 1.1636620001809206e-05\n",
      "Epoch 3075, Loss: 0.00019863629268002114, Final Batch Loss: 5.845178293384379e-06\n",
      "Epoch 3076, Loss: 0.0001409081522751876, Final Batch Loss: 1.8722602135312627e-06\n",
      "Epoch 3077, Loss: 0.00017578375809534919, Final Batch Loss: 8.954869554145262e-05\n",
      "Epoch 3078, Loss: 0.00019860332213283982, Final Batch Loss: 0.00010798778384923935\n",
      "Epoch 3079, Loss: 0.0002107136733684456, Final Batch Loss: 0.00012052350211888552\n",
      "Epoch 3080, Loss: 0.0013999770126247313, Final Batch Loss: 2.5123848899966106e-05\n",
      "Epoch 3081, Loss: 0.00015333948977058753, Final Batch Loss: 5.106416210765019e-05\n",
      "Epoch 3082, Loss: 0.0005107025290271849, Final Batch Loss: 0.000475822773296386\n",
      "Epoch 3083, Loss: 0.0063472975546119415, Final Batch Loss: 1.2107723250665003e-06\n",
      "Epoch 3084, Loss: 0.003665187076876464, Final Batch Loss: 9.731688805914018e-06\n",
      "Epoch 3085, Loss: 0.000591628751863027, Final Batch Loss: 1.7192563973367214e-05\n",
      "Epoch 3086, Loss: 0.0014151131472317502, Final Batch Loss: 0.0006020977743901312\n",
      "Epoch 3087, Loss: 0.016731810435885563, Final Batch Loss: 3.823899896815419e-05\n",
      "Epoch 3088, Loss: 0.000820680710603483, Final Batch Loss: 0.0004794042033609003\n",
      "Epoch 3089, Loss: 0.0004278679407434538, Final Batch Loss: 0.00022755474492441863\n",
      "Epoch 3090, Loss: 0.0004319076656429388, Final Batch Loss: 5.8550726862449665e-06\n",
      "Epoch 3091, Loss: 0.0039010799664538354, Final Batch Loss: 0.0027315823826938868\n",
      "Epoch 3092, Loss: 0.00013888831381336786, Final Batch Loss: 4.116832133149728e-05\n",
      "Epoch 3093, Loss: 0.00036807054857490584, Final Batch Loss: 3.976940206484869e-05\n",
      "Epoch 3094, Loss: 0.0003935744571208488, Final Batch Loss: 0.00029224029276520014\n",
      "Epoch 3095, Loss: 0.00038352596493496094, Final Batch Loss: 2.2029753381502815e-05\n",
      "Epoch 3096, Loss: 0.00013077205403533299, Final Batch Loss: 1.541182973596733e-05\n",
      "Epoch 3097, Loss: 0.00038070058508310467, Final Batch Loss: 7.333462417591363e-05\n",
      "Epoch 3098, Loss: 0.0006493970395240467, Final Batch Loss: 0.00017836294136941433\n",
      "Epoch 3099, Loss: 0.00024420200861641206, Final Batch Loss: 0.0002066093438770622\n",
      "Epoch 3100, Loss: 0.0001695192368060816, Final Batch Loss: 6.419276905944571e-05\n",
      "Epoch 3101, Loss: 9.789127034309786e-05, Final Batch Loss: 1.2872731531388126e-05\n",
      "Epoch 3102, Loss: 0.0007133089056878816, Final Batch Loss: 1.8646835087565705e-05\n",
      "Epoch 3103, Loss: 0.00036075679963687435, Final Batch Loss: 0.00011889557936228812\n",
      "Epoch 3104, Loss: 0.0007275332172866911, Final Batch Loss: 4.0751780034042895e-05\n",
      "Epoch 3105, Loss: 0.0007310246228371398, Final Batch Loss: 1.2321260328462813e-05\n",
      "Epoch 3106, Loss: 0.0003460240623098798, Final Batch Loss: 0.00010214663780061528\n",
      "Epoch 3107, Loss: 0.0006730796703777742, Final Batch Loss: 4.2063762521138415e-05\n",
      "Epoch 3108, Loss: 0.00015355525147242588, Final Batch Loss: 2.7090504772786517e-06\n",
      "Epoch 3109, Loss: 0.001669064482939575, Final Batch Loss: 6.0045990721846465e-06\n",
      "Epoch 3110, Loss: 0.0007196779970399803, Final Batch Loss: 1.612988671695348e-05\n",
      "Epoch 3111, Loss: 0.0028466810763347894, Final Batch Loss: 0.002224626950919628\n",
      "Epoch 3112, Loss: 0.0005914036719332216, Final Batch Loss: 2.833451253536623e-05\n",
      "Epoch 3113, Loss: 0.0003849943241220899, Final Batch Loss: 8.677779987920076e-06\n",
      "Epoch 3114, Loss: 0.011614856150117703, Final Batch Loss: 0.011221513152122498\n",
      "Epoch 3115, Loss: 0.000847155628434848, Final Batch Loss: 3.5481083614286035e-05\n",
      "Epoch 3116, Loss: 0.00038912338868613006, Final Batch Loss: 2.67163204625831e-06\n",
      "Epoch 3117, Loss: 0.000254604649853718, Final Batch Loss: 2.4619921532575972e-05\n",
      "Epoch 3118, Loss: 0.0007120176742319018, Final Batch Loss: 8.280832844320685e-06\n",
      "Epoch 3119, Loss: 0.0003877329800161533, Final Batch Loss: 6.597385799977928e-05\n",
      "Epoch 3120, Loss: 0.00027516532645677216, Final Batch Loss: 3.4066502848872915e-05\n",
      "Epoch 3121, Loss: 0.0004975490519427694, Final Batch Loss: 5.187318674870767e-05\n",
      "Epoch 3122, Loss: 0.0005124990839249222, Final Batch Loss: 1.8452248696121387e-05\n",
      "Epoch 3123, Loss: 0.000120762980714062, Final Batch Loss: 1.3837466212862637e-06\n",
      "Epoch 3124, Loss: 0.0161817397311097, Final Batch Loss: 9.571906048222445e-06\n",
      "Epoch 3125, Loss: 0.0023649630445561343, Final Batch Loss: 2.7510093332239194e-06\n",
      "Epoch 3126, Loss: 0.0040559046901762486, Final Batch Loss: 0.0009704731637611985\n",
      "Epoch 3127, Loss: 0.006510832666208444, Final Batch Loss: 1.1515395271999296e-05\n",
      "Epoch 3128, Loss: 0.0004570592755044345, Final Batch Loss: 4.657276804209687e-05\n",
      "Epoch 3129, Loss: 0.001966438620002009, Final Batch Loss: 0.0018680458888411522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3130, Loss: 0.004965089949109824, Final Batch Loss: 2.719542317208834e-05\n",
      "Epoch 3131, Loss: 0.00010796316598771227, Final Batch Loss: 1.376737031932862e-06\n",
      "Epoch 3132, Loss: 0.0002687149608391337, Final Batch Loss: 0.0001523092796560377\n",
      "Epoch 3133, Loss: 0.0017148045048998029, Final Batch Loss: 9.59709650487639e-05\n",
      "Epoch 3134, Loss: 0.0006245036802283721, Final Batch Loss: 9.457702617510222e-06\n",
      "Epoch 3135, Loss: 0.003806726636298663, Final Batch Loss: 1.638480512156093e-06\n",
      "Epoch 3136, Loss: 0.00046825932986394037, Final Batch Loss: 0.00041929815779440105\n",
      "Epoch 3137, Loss: 9.110668383982556e-05, Final Batch Loss: 5.4983865993563086e-05\n",
      "Epoch 3138, Loss: 0.00029843236507076654, Final Batch Loss: 6.7917585511168e-06\n",
      "Epoch 3139, Loss: 0.002173642299567291, Final Batch Loss: 1.2124007298552897e-05\n",
      "Epoch 3140, Loss: 0.00101111238473095, Final Batch Loss: 0.0006996780866757035\n",
      "Epoch 3141, Loss: 0.0028828670527900613, Final Batch Loss: 1.8839417634808342e-06\n",
      "Epoch 3142, Loss: 4.36372224612569e-05, Final Batch Loss: 9.796533959161025e-06\n",
      "Epoch 3143, Loss: 7.04272360962932e-05, Final Batch Loss: 3.3824191632447764e-05\n",
      "Epoch 3144, Loss: 0.0001314395703957416, Final Batch Loss: 9.011353540699929e-06\n",
      "Epoch 3145, Loss: 0.0003466168609520537, Final Batch Loss: 4.962127604812849e-06\n",
      "Epoch 3146, Loss: 4.636691414816596e-05, Final Batch Loss: 2.636547151269042e-06\n",
      "Epoch 3147, Loss: 0.07394956697680755, Final Batch Loss: 0.047208625823259354\n",
      "Epoch 3148, Loss: 0.10172589729245374, Final Batch Loss: 0.10156501829624176\n",
      "Epoch 3149, Loss: 0.03677409108786378, Final Batch Loss: 0.00017675351409707218\n",
      "Epoch 3150, Loss: 0.0521906285212026, Final Batch Loss: 0.00011965880548814312\n",
      "Epoch 3151, Loss: 0.015266274796886137, Final Batch Loss: 3.478333746897988e-05\n",
      "Epoch 3152, Loss: 0.0011855106422444806, Final Batch Loss: 9.199501073453575e-05\n",
      "Epoch 3153, Loss: 0.010383783199358732, Final Batch Loss: 0.00862456951290369\n",
      "Epoch 3154, Loss: 0.0011579055426409468, Final Batch Loss: 0.0002109746274072677\n",
      "Epoch 3155, Loss: 0.000806343014119193, Final Batch Loss: 8.372368756681681e-05\n",
      "Epoch 3156, Loss: 0.0006930393137736246, Final Batch Loss: 0.00040127112879417837\n",
      "Epoch 3157, Loss: 0.0012097051949240267, Final Batch Loss: 5.481770494952798e-05\n",
      "Epoch 3158, Loss: 0.0007012630885583349, Final Batch Loss: 1.4434779586736113e-05\n",
      "Epoch 3159, Loss: 0.008367078437004238, Final Batch Loss: 0.0002335549215786159\n",
      "Epoch 3160, Loss: 0.003291770459327381, Final Batch Loss: 1.7246689822059125e-05\n",
      "Epoch 3161, Loss: 0.0006910024312674068, Final Batch Loss: 0.0003886531922034919\n",
      "Epoch 3162, Loss: 0.005177016166271642, Final Batch Loss: 6.436672993004322e-05\n",
      "Epoch 3163, Loss: 0.0009346178994746879, Final Batch Loss: 0.00013301445869728923\n",
      "Epoch 3164, Loss: 0.0010383838962297887, Final Batch Loss: 0.00045075162779539824\n",
      "Epoch 3165, Loss: 0.007607685300172307, Final Batch Loss: 0.00011727865785360336\n",
      "Epoch 3166, Loss: 0.001056720400811173, Final Batch Loss: 0.00021829111210536212\n",
      "Epoch 3167, Loss: 0.001103644652175717, Final Batch Loss: 0.000384519255021587\n",
      "Epoch 3168, Loss: 0.0005677863955497742, Final Batch Loss: 0.00010700614075176418\n",
      "Epoch 3169, Loss: 0.020583378747687675, Final Batch Loss: 3.9663995266892016e-05\n",
      "Epoch 3170, Loss: 0.0004582125984597951, Final Batch Loss: 9.971977851819247e-05\n",
      "Epoch 3171, Loss: 0.0024091698232950876, Final Batch Loss: 2.051455703622196e-05\n",
      "Epoch 3172, Loss: 0.0008496488226228394, Final Batch Loss: 4.5797765778843313e-05\n",
      "Epoch 3173, Loss: 0.03544071096985135, Final Batch Loss: 0.034443456679582596\n",
      "Epoch 3174, Loss: 0.009346190199721605, Final Batch Loss: 0.0006720185629092157\n",
      "Epoch 3175, Loss: 0.003789399725064868, Final Batch Loss: 2.6755475118989125e-05\n",
      "Epoch 3176, Loss: 0.01355384190537734, Final Batch Loss: 4.970473673893139e-05\n",
      "Epoch 3177, Loss: 0.0008161398527590791, Final Batch Loss: 1.0108715287060477e-05\n",
      "Epoch 3178, Loss: 0.0017214526669704355, Final Batch Loss: 0.0009121772018261254\n",
      "Epoch 3179, Loss: 0.0007094258980941959, Final Batch Loss: 8.52832235977985e-05\n",
      "Epoch 3180, Loss: 0.00038277301428024657, Final Batch Loss: 5.166304254089482e-05\n",
      "Epoch 3181, Loss: 0.003989255987107754, Final Batch Loss: 0.0033889003098011017\n",
      "Epoch 3182, Loss: 0.0028265442088013515, Final Batch Loss: 0.0025585670955479145\n",
      "Epoch 3183, Loss: 0.002704270329559222, Final Batch Loss: 0.00020100962137803435\n",
      "Epoch 3184, Loss: 0.0003818083932856098, Final Batch Loss: 0.00015347528096754104\n",
      "Epoch 3185, Loss: 0.006402807335689431, Final Batch Loss: 0.006018123123794794\n",
      "Epoch 3186, Loss: 0.0002323047647223575, Final Batch Loss: 1.1612695743679069e-05\n",
      "Epoch 3187, Loss: 0.00012860507376899477, Final Batch Loss: 8.054086720221676e-06\n",
      "Epoch 3188, Loss: 0.00037124730079085566, Final Batch Loss: 0.0001619724789634347\n",
      "Epoch 3189, Loss: 0.0026778907486004755, Final Batch Loss: 9.315561328548938e-05\n",
      "Epoch 3190, Loss: 0.0005457822480821051, Final Batch Loss: 0.000324666645610705\n",
      "Epoch 3191, Loss: 0.020152844750555232, Final Batch Loss: 0.00015521064051426947\n",
      "Epoch 3192, Loss: 0.005720077810110524, Final Batch Loss: 0.00010446037049405277\n",
      "Epoch 3193, Loss: 0.011625591323536355, Final Batch Loss: 0.0001928473066072911\n",
      "Epoch 3194, Loss: 0.000814802129752934, Final Batch Loss: 0.00020969573233742267\n",
      "Epoch 3195, Loss: 0.0003043670253646269, Final Batch Loss: 5.4435690799437e-06\n",
      "Epoch 3196, Loss: 0.0006701419988530688, Final Batch Loss: 0.0005095985834486783\n",
      "Epoch 3197, Loss: 0.00046486547216773033, Final Batch Loss: 3.5223300073994324e-05\n",
      "Epoch 3198, Loss: 0.013337677653908031, Final Batch Loss: 0.0014500588877126575\n",
      "Epoch 3199, Loss: 0.0002249469694106665, Final Batch Loss: 5.712136498914333e-06\n",
      "Epoch 3200, Loss: 0.0017129577390733175, Final Batch Loss: 2.411947207292542e-05\n",
      "Epoch 3201, Loss: 0.0014378216583281755, Final Batch Loss: 0.0005286222440190613\n",
      "Epoch 3202, Loss: 0.001380500061713974, Final Batch Loss: 2.2979058485361747e-05\n",
      "Epoch 3203, Loss: 0.0018872024811571464, Final Batch Loss: 7.506136898882687e-05\n",
      "Epoch 3204, Loss: 0.0004758458035212243, Final Batch Loss: 1.157172846433241e-05\n",
      "Epoch 3205, Loss: 0.00030748529752600007, Final Batch Loss: 5.138029155205004e-05\n",
      "Epoch 3206, Loss: 0.0012073672360202181, Final Batch Loss: 1.3213898455433082e-05\n",
      "Epoch 3207, Loss: 0.0006295124039752409, Final Batch Loss: 0.00016438867896795273\n",
      "Epoch 3208, Loss: 0.009707102200991358, Final Batch Loss: 2.5111758077400737e-05\n",
      "Epoch 3209, Loss: 0.0005708363282792561, Final Batch Loss: 3.459321760601597e-06\n",
      "Epoch 3210, Loss: 0.0026027704880107194, Final Batch Loss: 0.0013732211664319038\n",
      "Epoch 3211, Loss: 0.017382850934154703, Final Batch Loss: 1.1784233720391057e-05\n",
      "Epoch 3212, Loss: 0.0006385992141986208, Final Batch Loss: 5.003935712011298e-06\n",
      "Epoch 3213, Loss: 0.0005257700540823862, Final Batch Loss: 0.00015380217519123107\n",
      "Epoch 3214, Loss: 0.012881473150628153, Final Batch Loss: 4.781743700732477e-05\n",
      "Epoch 3215, Loss: 0.0006729049655405106, Final Batch Loss: 2.3170878193923272e-05\n",
      "Epoch 3216, Loss: 0.00035762082916335203, Final Batch Loss: 4.1041439544642344e-05\n",
      "Epoch 3217, Loss: 0.0004717913761851378, Final Batch Loss: 0.00014645136252511293\n",
      "Epoch 3218, Loss: 0.0008606710034655407, Final Batch Loss: 0.0005970178171992302\n",
      "Epoch 3219, Loss: 0.0005611596716335043, Final Batch Loss: 0.00011930930486414582\n",
      "Epoch 3220, Loss: 0.0010610080862534232, Final Batch Loss: 8.314071601489559e-05\n",
      "Epoch 3221, Loss: 0.0005474090721691027, Final Batch Loss: 0.0002732144494075328\n",
      "Epoch 3222, Loss: 0.0023117732889659237, Final Batch Loss: 3.782721978495829e-05\n",
      "Epoch 3223, Loss: 0.0009019853496283758, Final Batch Loss: 5.8128545788349584e-05\n",
      "Epoch 3224, Loss: 0.0028759061569871847, Final Batch Loss: 8.580277062719688e-05\n",
      "Epoch 3225, Loss: 0.0001291235148528358, Final Batch Loss: 1.2630784112843685e-05\n",
      "Epoch 3226, Loss: 0.001291034830501303, Final Batch Loss: 0.0003360791888553649\n",
      "Epoch 3227, Loss: 0.0015825046684767585, Final Batch Loss: 3.3962201996473595e-05\n",
      "Epoch 3228, Loss: 0.0001361015119982767, Final Batch Loss: 1.1753777471312787e-05\n",
      "Epoch 3229, Loss: 0.001146290946053341, Final Batch Loss: 0.0005527517641894519\n",
      "Epoch 3230, Loss: 0.00041736709863471333, Final Batch Loss: 2.3692375179962255e-05\n",
      "Epoch 3231, Loss: 0.000590986994211562, Final Batch Loss: 6.527703953906894e-05\n",
      "Epoch 3232, Loss: 0.0019467298479867168, Final Batch Loss: 0.0017437041969969869\n",
      "Epoch 3233, Loss: 0.0006305823735601734, Final Batch Loss: 5.045976649853401e-05\n",
      "Epoch 3234, Loss: 0.0003689285003929399, Final Batch Loss: 0.00010419845784781501\n",
      "Epoch 3235, Loss: 0.00133374040842682, Final Batch Loss: 4.2399037738505285e-06\n",
      "Epoch 3236, Loss: 0.00012171093385404674, Final Batch Loss: 1.3123618373356294e-05\n",
      "Epoch 3237, Loss: 0.00047400895709870383, Final Batch Loss: 6.036937338649295e-05\n",
      "Epoch 3238, Loss: 0.004554524208288058, Final Batch Loss: 1.911145773192402e-05\n",
      "Epoch 3239, Loss: 0.0002457461259837146, Final Batch Loss: 6.299112101260107e-06\n",
      "Epoch 3240, Loss: 8.850429549056571e-05, Final Batch Loss: 1.80773622560082e-05\n",
      "Epoch 3241, Loss: 0.0002358622987230774, Final Batch Loss: 0.0001329125661868602\n",
      "Epoch 3242, Loss: 0.0003946610158891417, Final Batch Loss: 2.4525670596631244e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3243, Loss: 0.00023489472732762806, Final Batch Loss: 4.642717613023706e-05\n",
      "Epoch 3244, Loss: 0.0007131842467060778, Final Batch Loss: 2.6480327505851164e-05\n",
      "Epoch 3245, Loss: 0.00030249429619289003, Final Batch Loss: 2.453889828757383e-05\n",
      "Epoch 3246, Loss: 7.810412807884859e-05, Final Batch Loss: 1.4210146218829323e-05\n",
      "Epoch 3247, Loss: 0.0007399526293738745, Final Batch Loss: 0.0004092082381248474\n",
      "Epoch 3248, Loss: 0.0006621360580538749, Final Batch Loss: 1.5071119378262665e-05\n",
      "Epoch 3249, Loss: 0.00025549949350534007, Final Batch Loss: 4.8014735511969775e-05\n",
      "Epoch 3250, Loss: 0.0002596225258457707, Final Batch Loss: 2.3960796170285903e-05\n",
      "Epoch 3251, Loss: 0.0005699817811546382, Final Batch Loss: 5.1646475185407326e-05\n",
      "Epoch 3252, Loss: 0.0005920862640778068, Final Batch Loss: 1.690039425739087e-05\n",
      "Epoch 3253, Loss: 0.0013716980665776646, Final Batch Loss: 2.363292696827557e-05\n",
      "Epoch 3254, Loss: 0.00023425436870638805, Final Batch Loss: 3.0385947411559755e-06\n",
      "Epoch 3255, Loss: 0.00033071998586819973, Final Batch Loss: 9.14325391931925e-06\n",
      "Epoch 3256, Loss: 0.0004381280423331191, Final Batch Loss: 4.709753739007283e-06\n",
      "Epoch 3257, Loss: 0.00041024363235919736, Final Batch Loss: 0.000155274014105089\n",
      "Epoch 3258, Loss: 0.0003974001228925772, Final Batch Loss: 0.0002082572755170986\n",
      "Epoch 3259, Loss: 0.00037639647416654043, Final Batch Loss: 3.20008875860367e-05\n",
      "Epoch 3260, Loss: 0.0006942285963305039, Final Batch Loss: 1.1594083844101988e-05\n",
      "Epoch 3261, Loss: 0.000696276081725955, Final Batch Loss: 0.00023541980772279203\n",
      "Epoch 3262, Loss: 0.000944936771702487, Final Batch Loss: 0.00012102197069907561\n",
      "Epoch 3263, Loss: 0.00043304449354764074, Final Batch Loss: 0.00021900665888097137\n",
      "Epoch 3264, Loss: 0.0004769790066347923, Final Batch Loss: 8.192103268811479e-05\n",
      "Epoch 3265, Loss: 0.019179134935257025, Final Batch Loss: 1.9813538528978825e-05\n",
      "Epoch 3266, Loss: 0.0002530150013626553, Final Batch Loss: 3.490402741590515e-05\n",
      "Epoch 3267, Loss: 0.0013615984644275159, Final Batch Loss: 0.00018874142551794648\n",
      "Epoch 3268, Loss: 0.0024909675266826525, Final Batch Loss: 0.00208706920966506\n",
      "Epoch 3269, Loss: 0.0008044701608014293, Final Batch Loss: 2.6874135073740035e-05\n",
      "Epoch 3270, Loss: 0.0010132073584827594, Final Batch Loss: 0.0002884009445551783\n",
      "Epoch 3271, Loss: 0.0004696697551480611, Final Batch Loss: 1.5068607353896368e-05\n",
      "Epoch 3272, Loss: 0.00026915137277683243, Final Batch Loss: 0.00013727153418585658\n",
      "Epoch 3273, Loss: 0.0002969222450701636, Final Batch Loss: 2.267306626890786e-07\n",
      "Epoch 3274, Loss: 0.00085304124513641, Final Batch Loss: 0.00027931007207371294\n",
      "Epoch 3275, Loss: 0.0007000645782682113, Final Batch Loss: 0.00017589968047104776\n",
      "Epoch 3276, Loss: 0.00017620106336835306, Final Batch Loss: 1.441506356059108e-05\n",
      "Epoch 3277, Loss: 0.0008436428252025507, Final Batch Loss: 0.0006590827251784503\n",
      "Epoch 3278, Loss: 0.002259144195704721, Final Batch Loss: 0.0016908312682062387\n",
      "Epoch 3279, Loss: 0.0009221372893080115, Final Batch Loss: 0.00014105996524449438\n",
      "Epoch 3280, Loss: 0.0009176112926070346, Final Batch Loss: 0.0006260823574848473\n",
      "Epoch 3281, Loss: 0.0004754335141115007, Final Batch Loss: 8.686650289746467e-06\n",
      "Epoch 3282, Loss: 0.0006574287381226895, Final Batch Loss: 2.3188576960819773e-05\n",
      "Epoch 3283, Loss: 0.0005137309999554418, Final Batch Loss: 4.641347550204955e-05\n",
      "Epoch 3284, Loss: 0.0002936927576229209, Final Batch Loss: 4.9527461669640616e-05\n",
      "Epoch 3285, Loss: 0.0017619055906834546, Final Batch Loss: 3.415745231905021e-05\n",
      "Epoch 3286, Loss: 0.0006364921027852688, Final Batch Loss: 0.00023251521633937955\n",
      "Epoch 3287, Loss: 0.000698880510753952, Final Batch Loss: 0.0004014032892882824\n",
      "Epoch 3288, Loss: 0.0012575795408338308, Final Batch Loss: 0.00012085762136848643\n",
      "Epoch 3289, Loss: 0.0010868618101085303, Final Batch Loss: 0.0010338617721572518\n",
      "Epoch 3290, Loss: 0.00015059500947245397, Final Batch Loss: 5.1013583288295195e-05\n",
      "Epoch 3291, Loss: 0.0020136910534347408, Final Batch Loss: 0.001166728907264769\n",
      "Epoch 3292, Loss: 0.001996678634895943, Final Batch Loss: 0.001767397508956492\n",
      "Epoch 3293, Loss: 0.0003204273416486103, Final Batch Loss: 5.3483974625123665e-05\n",
      "Epoch 3294, Loss: 0.00011993754469585838, Final Batch Loss: 2.241993570351042e-05\n",
      "Epoch 3295, Loss: 0.0021747125447291182, Final Batch Loss: 7.19899071555119e-06\n",
      "Epoch 3296, Loss: 0.00016323584713973105, Final Batch Loss: 3.9068905607564375e-05\n",
      "Epoch 3297, Loss: 0.0005637755893985741, Final Batch Loss: 9.25358253880404e-05\n",
      "Epoch 3298, Loss: 0.0010948599956464022, Final Batch Loss: 0.00013649817265104502\n",
      "Epoch 3299, Loss: 0.00023498243353969883, Final Batch Loss: 7.68260179029312e-06\n",
      "Epoch 3300, Loss: 0.001697389254331938, Final Batch Loss: 0.0013483738293871284\n",
      "Epoch 3301, Loss: 0.00033453459036536515, Final Batch Loss: 4.181087206234224e-05\n",
      "Epoch 3302, Loss: 0.00011418841495469678, Final Batch Loss: 5.9589885495370254e-05\n",
      "Epoch 3303, Loss: 0.0007063506736812997, Final Batch Loss: 1.3064428458164912e-05\n",
      "Epoch 3304, Loss: 0.0011895240750163794, Final Batch Loss: 0.00010822104377439246\n",
      "Epoch 3305, Loss: 0.0003320371888548834, Final Batch Loss: 0.00012052922829752788\n",
      "Epoch 3306, Loss: 0.0006399495196092175, Final Batch Loss: 2.591843258414883e-05\n",
      "Epoch 3307, Loss: 6.178854118843446e-05, Final Batch Loss: 9.783408131625038e-06\n",
      "Epoch 3308, Loss: 9.902981128107058e-05, Final Batch Loss: 3.0993005566415377e-06\n",
      "Epoch 3309, Loss: 0.00029911292222095653, Final Batch Loss: 4.5487489842344075e-05\n",
      "Epoch 3310, Loss: 0.0002775330567601486, Final Batch Loss: 1.161828822660027e-05\n",
      "Epoch 3311, Loss: 0.0002525517120375298, Final Batch Loss: 2.947694156318903e-05\n",
      "Epoch 3312, Loss: 0.00019098957636742853, Final Batch Loss: 0.00011845830886159092\n",
      "Epoch 3313, Loss: 0.00023027105271467008, Final Batch Loss: 0.00013035601295996457\n",
      "Epoch 3314, Loss: 0.0034272660850547254, Final Batch Loss: 0.00016474910080432892\n",
      "Epoch 3315, Loss: 0.00013366461644181982, Final Batch Loss: 4.171982436673716e-05\n",
      "Epoch 3316, Loss: 4.1946488749999844e-05, Final Batch Loss: 1.5356746416728129e-06\n",
      "Epoch 3317, Loss: 0.0006170625060804014, Final Batch Loss: 3.1577878871758003e-06\n",
      "Epoch 3318, Loss: 0.00013565734479925595, Final Batch Loss: 6.800112896598876e-05\n",
      "Epoch 3319, Loss: 0.004410674006976478, Final Batch Loss: 1.0066200957226101e-05\n",
      "Epoch 3320, Loss: 0.0002865579244826222, Final Batch Loss: 0.00021361587278079242\n",
      "Epoch 3321, Loss: 0.00012097641710795415, Final Batch Loss: 2.1270652439397963e-07\n",
      "Epoch 3322, Loss: 0.0006351907072712493, Final Batch Loss: 6.635200861637713e-06\n",
      "Epoch 3323, Loss: 0.0002385291772952769, Final Batch Loss: 1.6397429135395214e-05\n",
      "Epoch 3324, Loss: 0.00033869047547341324, Final Batch Loss: 5.060031253378838e-05\n",
      "Epoch 3325, Loss: 0.0007021894853096455, Final Batch Loss: 0.00020121580746490508\n",
      "Epoch 3326, Loss: 8.625637292425381e-05, Final Batch Loss: 2.1582996851066127e-05\n",
      "Epoch 3327, Loss: 0.0004932280153298052, Final Batch Loss: 2.8475596991484053e-05\n",
      "Epoch 3328, Loss: 8.053227770687954e-05, Final Batch Loss: 8.064105259109056e-07\n",
      "Epoch 3329, Loss: 0.0004478639284570818, Final Batch Loss: 9.995183972932864e-06\n",
      "Epoch 3330, Loss: 0.00034846691278289654, Final Batch Loss: 7.5135708357265685e-06\n",
      "Epoch 3331, Loss: 9.483759959039162e-05, Final Batch Loss: 4.4734620132658165e-06\n",
      "Epoch 3332, Loss: 0.00030544024775736034, Final Batch Loss: 0.00022599557996727526\n",
      "Epoch 3333, Loss: 0.000274052785243839, Final Batch Loss: 2.135869362973608e-05\n",
      "Epoch 3334, Loss: 0.00030663004145026207, Final Batch Loss: 4.4890046410728246e-05\n",
      "Epoch 3335, Loss: 0.0002324061870240257, Final Batch Loss: 0.00019502344366628677\n",
      "Epoch 3336, Loss: 0.008505584521117271, Final Batch Loss: 9.208672054228373e-06\n",
      "Epoch 3337, Loss: 0.0004252977596479468, Final Batch Loss: 0.00013612610928248614\n",
      "Epoch 3338, Loss: 0.0032940250985120656, Final Batch Loss: 1.5237763363984413e-05\n",
      "Epoch 3339, Loss: 0.0008285729409180931, Final Batch Loss: 0.0007705669268034399\n",
      "Epoch 3340, Loss: 0.004263933114998508, Final Batch Loss: 0.0001324491749983281\n",
      "Epoch 3341, Loss: 0.0005897958617424592, Final Batch Loss: 1.2987919035367668e-05\n",
      "Epoch 3342, Loss: 0.0008821716555189596, Final Batch Loss: 6.030540475876478e-07\n",
      "Epoch 3343, Loss: 0.0002137527881131973, Final Batch Loss: 2.4255397875094786e-05\n",
      "Epoch 3344, Loss: 0.0001958422001280269, Final Batch Loss: 2.7230710202275077e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3345, Loss: 0.00012885380965599325, Final Batch Loss: 8.699091267772019e-06\n",
      "Epoch 3346, Loss: 0.0001840430740003285, Final Batch Loss: 9.747044487085077e-07\n",
      "Epoch 3347, Loss: 0.00011917248457393725, Final Batch Loss: 6.31486227575806e-06\n",
      "Epoch 3348, Loss: 0.028999873718930758, Final Batch Loss: 0.001204110449180007\n",
      "Epoch 3349, Loss: 0.000240372301050229, Final Batch Loss: 1.310143488808535e-05\n",
      "Epoch 3350, Loss: 0.00023162714569480158, Final Batch Loss: 0.00014515381189994514\n",
      "Epoch 3351, Loss: 0.00016015038892192024, Final Batch Loss: 7.059014137666964e-07\n",
      "Epoch 3352, Loss: 7.443577396770706e-05, Final Batch Loss: 3.8019712519599125e-05\n",
      "Epoch 3353, Loss: 0.0003220883768335625, Final Batch Loss: 4.616270871338202e-06\n",
      "Epoch 3354, Loss: 0.013333211973076686, Final Batch Loss: 0.0002667732478585094\n",
      "Epoch 3355, Loss: 0.04520448489347473, Final Batch Loss: 0.043307263404130936\n",
      "Epoch 3356, Loss: 0.0004125226223550271, Final Batch Loss: 0.00011424391414038837\n",
      "Epoch 3357, Loss: 0.000915757078473689, Final Batch Loss: 2.8291502530919388e-05\n",
      "Epoch 3358, Loss: 0.0013068400221527554, Final Batch Loss: 9.044423495652154e-05\n",
      "Epoch 3359, Loss: 0.010462277554324828, Final Batch Loss: 0.0006180445780046284\n",
      "Epoch 3360, Loss: 0.01616992918093274, Final Batch Loss: 2.767456635410781e-06\n",
      "Epoch 3361, Loss: 0.028496623443061253, Final Batch Loss: 0.0025936970487236977\n",
      "Epoch 3362, Loss: 0.04813034221660928, Final Batch Loss: 0.04089060053229332\n",
      "Epoch 3363, Loss: 0.000920559958103695, Final Batch Loss: 1.108641481550876e-05\n",
      "Epoch 3364, Loss: 0.055854403297416866, Final Batch Loss: 0.00031128048431128263\n",
      "Epoch 3365, Loss: 0.03342563792830333, Final Batch Loss: 0.0024331382010132074\n",
      "Epoch 3366, Loss: 0.0015371192421298474, Final Batch Loss: 0.00011629264918155968\n",
      "Epoch 3367, Loss: 0.011346537256031297, Final Batch Loss: 1.3459575711749494e-05\n",
      "Epoch 3368, Loss: 0.007612783811055124, Final Batch Loss: 0.007074484135955572\n",
      "Epoch 3369, Loss: 0.005701409070752561, Final Batch Loss: 0.0010869514662772417\n",
      "Epoch 3370, Loss: 0.0010219513496849686, Final Batch Loss: 3.312929766252637e-05\n",
      "Epoch 3371, Loss: 0.000440711053670384, Final Batch Loss: 6.674807809758931e-05\n",
      "Epoch 3372, Loss: 0.017502336064353585, Final Batch Loss: 0.0001944400428328663\n",
      "Epoch 3373, Loss: 0.00022732824209015234, Final Batch Loss: 1.0214548638032284e-06\n",
      "Epoch 3374, Loss: 0.0004576097308017779, Final Batch Loss: 0.0003548536915332079\n",
      "Epoch 3375, Loss: 0.003716083010658622, Final Batch Loss: 9.111845429288223e-05\n",
      "Epoch 3376, Loss: 0.0004195842357148649, Final Batch Loss: 0.00013897109602112323\n",
      "Epoch 3377, Loss: 0.001391639805660816, Final Batch Loss: 5.452336699818261e-05\n",
      "Epoch 3378, Loss: 0.0008744672668399289, Final Batch Loss: 0.0001836947340052575\n",
      "Epoch 3379, Loss: 0.0045561540973722, Final Batch Loss: 0.00011920186079805717\n",
      "Epoch 3380, Loss: 0.000648986067972146, Final Batch Loss: 0.00013023252540733665\n",
      "Epoch 3381, Loss: 0.0012321496906224638, Final Batch Loss: 0.00017644041508901864\n",
      "Epoch 3382, Loss: 0.0006681348786514718, Final Batch Loss: 0.00025419172015972435\n",
      "Epoch 3383, Loss: 0.00033805395651143044, Final Batch Loss: 0.00017983364523388445\n",
      "Epoch 3384, Loss: 0.0008743257822061423, Final Batch Loss: 0.00043418718269094825\n",
      "Epoch 3385, Loss: 0.0005733915459131822, Final Batch Loss: 0.0001230906054843217\n",
      "Epoch 3386, Loss: 0.0010429884205223061, Final Batch Loss: 8.626012277090922e-05\n",
      "Epoch 3387, Loss: 0.0007335045520449057, Final Batch Loss: 3.271084278821945e-05\n",
      "Epoch 3388, Loss: 0.00013775173965768772, Final Batch Loss: 4.195571364107309e-06\n",
      "Epoch 3389, Loss: 0.008785275887930766, Final Batch Loss: 6.129987741587684e-05\n",
      "Epoch 3390, Loss: 0.0003109104400209617, Final Batch Loss: 0.00018570326210465282\n",
      "Epoch 3391, Loss: 0.0005349850907805376, Final Batch Loss: 0.0004062813532073051\n",
      "Epoch 3392, Loss: 0.00024521326486137696, Final Batch Loss: 9.209473500959575e-05\n",
      "Epoch 3393, Loss: 0.007552688504802063, Final Batch Loss: 3.142494824714959e-05\n",
      "Epoch 3394, Loss: 0.0005051825755799655, Final Batch Loss: 5.099976624478586e-05\n",
      "Epoch 3395, Loss: 0.00038419051514893, Final Batch Loss: 9.443198791814211e-07\n",
      "Epoch 3396, Loss: 0.0003593413712223992, Final Batch Loss: 5.373591193347238e-05\n",
      "Epoch 3397, Loss: 0.00023377162506221794, Final Batch Loss: 5.37665473530069e-05\n",
      "Epoch 3398, Loss: 0.000721840639016591, Final Batch Loss: 5.8190125855617225e-05\n",
      "Epoch 3399, Loss: 0.000453959346486954, Final Batch Loss: 0.00034671113826334476\n",
      "Epoch 3400, Loss: 0.0012395250851113815, Final Batch Loss: 1.8429203919367865e-05\n",
      "Epoch 3401, Loss: 0.00021191777977946913, Final Batch Loss: 9.507842150924262e-06\n",
      "Epoch 3402, Loss: 0.0005623633223876823, Final Batch Loss: 0.0001848912361310795\n",
      "Epoch 3403, Loss: 0.00046379891409742413, Final Batch Loss: 9.73848636931507e-06\n",
      "Epoch 3404, Loss: 0.0007015631163085345, Final Batch Loss: 0.0005682834307663143\n",
      "Epoch 3405, Loss: 0.001440047097275965, Final Batch Loss: 0.001083972048945725\n",
      "Epoch 3406, Loss: 8.026966224861098e-05, Final Batch Loss: 9.64825721894158e-06\n",
      "Epoch 3407, Loss: 0.0009409630656591617, Final Batch Loss: 0.0008523185970261693\n",
      "Epoch 3408, Loss: 0.00031281510746339336, Final Batch Loss: 2.4077708076220006e-05\n",
      "Epoch 3409, Loss: 0.00043319187716406304, Final Batch Loss: 5.765950845670886e-06\n",
      "Epoch 3410, Loss: 0.000351618007698562, Final Batch Loss: 4.659753176383674e-05\n",
      "Epoch 3411, Loss: 0.0007168331649154425, Final Batch Loss: 0.0001640038244659081\n",
      "Epoch 3412, Loss: 0.000625338241661666, Final Batch Loss: 0.00013940130884293467\n",
      "Epoch 3413, Loss: 0.00014877310150041012, Final Batch Loss: 1.5707291822764091e-06\n",
      "Epoch 3414, Loss: 0.0010840671311598271, Final Batch Loss: 0.0005414016777649522\n",
      "Epoch 3415, Loss: 0.0002828060351021122, Final Batch Loss: 0.00012919685104861856\n",
      "Epoch 3416, Loss: 0.00030024048680843407, Final Batch Loss: 9.700182772576227e-07\n",
      "Epoch 3417, Loss: 0.00026847280605579726, Final Batch Loss: 8.916615479392931e-05\n",
      "Epoch 3418, Loss: 0.00021261922029225389, Final Batch Loss: 2.330561983399093e-05\n",
      "Epoch 3419, Loss: 0.0002906982645072276, Final Batch Loss: 0.00010903520887950435\n",
      "Epoch 3420, Loss: 0.0004798601003130898, Final Batch Loss: 3.901086529367603e-06\n",
      "Epoch 3421, Loss: 0.0001286361257371027, Final Batch Loss: 4.361861283541657e-05\n",
      "Epoch 3422, Loss: 0.0008858383807819337, Final Batch Loss: 0.00030967078055255115\n",
      "Epoch 3423, Loss: 0.00038757895890739746, Final Batch Loss: 4.696082396549173e-05\n",
      "Epoch 3424, Loss: 0.0007885780651122332, Final Batch Loss: 7.28334198356606e-05\n",
      "Epoch 3425, Loss: 0.0002300461746926885, Final Batch Loss: 7.329617073992267e-05\n",
      "Epoch 3426, Loss: 0.0002387166314292699, Final Batch Loss: 4.49035142082721e-05\n",
      "Epoch 3427, Loss: 0.00036023238135385327, Final Batch Loss: 2.270291224704124e-05\n",
      "Epoch 3428, Loss: 0.0004017945880150364, Final Batch Loss: 3.212661249563098e-05\n",
      "Epoch 3429, Loss: 0.0007240653030748945, Final Batch Loss: 0.00011981562420260161\n",
      "Epoch 3430, Loss: 0.0006318731175269932, Final Batch Loss: 0.00016091784345917404\n",
      "Epoch 3431, Loss: 0.0001557194955239538, Final Batch Loss: 7.935144822113216e-06\n",
      "Epoch 3432, Loss: 7.515682773373555e-05, Final Batch Loss: 3.279812153778039e-05\n",
      "Epoch 3433, Loss: 0.0005168914649402723, Final Batch Loss: 0.0003857265692204237\n",
      "Epoch 3434, Loss: 0.00014676130240331986, Final Batch Loss: 4.964439085597405e-06\n",
      "Epoch 3435, Loss: 0.0011065937360399403, Final Batch Loss: 0.00010199766256846488\n",
      "Epoch 3436, Loss: 0.00023153396068664733, Final Batch Loss: 0.00016752237570472062\n",
      "Epoch 3437, Loss: 0.00032523642948945053, Final Batch Loss: 2.6177156541962177e-05\n",
      "Epoch 3438, Loss: 0.0008907096109851409, Final Batch Loss: 3.688392325784662e-06\n",
      "Epoch 3439, Loss: 0.0009622983998269774, Final Batch Loss: 4.241349233780056e-05\n",
      "Epoch 3440, Loss: 0.0003880222648149356, Final Batch Loss: 0.0002877302758861333\n",
      "Epoch 3441, Loss: 0.006690079000691185, Final Batch Loss: 3.789700349443592e-05\n",
      "Epoch 3442, Loss: 0.0002403630669505219, Final Batch Loss: 0.00017416155606042594\n",
      "Epoch 3443, Loss: 0.0007083050559231197, Final Batch Loss: 1.0547845704422798e-05\n",
      "Epoch 3444, Loss: 0.0001656393833400216, Final Batch Loss: 9.132859850069508e-05\n",
      "Epoch 3445, Loss: 0.00020342893913039006, Final Batch Loss: 6.0314669099170715e-05\n",
      "Epoch 3446, Loss: 0.00270390169134771, Final Batch Loss: 6.99320480634924e-06\n",
      "Epoch 3447, Loss: 0.0008644836980238324, Final Batch Loss: 1.3524730093195103e-05\n",
      "Epoch 3448, Loss: 0.00035924183760016604, Final Batch Loss: 1.0635282023940817e-06\n",
      "Epoch 3449, Loss: 0.00029574761720141396, Final Batch Loss: 2.593079989310354e-05\n",
      "Epoch 3450, Loss: 4.055421374005164e-05, Final Batch Loss: 7.853719239392376e-07\n",
      "Epoch 3451, Loss: 0.00048466238990840793, Final Batch Loss: 2.5687743345770286e-06\n",
      "Epoch 3452, Loss: 0.00033545839471571526, Final Batch Loss: 8.905605000109063e-07\n",
      "Epoch 3453, Loss: 0.00019082819767390902, Final Batch Loss: 2.482318677721196e-06\n",
      "Epoch 3454, Loss: 0.0005084130170871504, Final Batch Loss: 2.7277452318230644e-05\n",
      "Epoch 3455, Loss: 0.00015378990065073594, Final Batch Loss: 5.872748079127632e-05\n",
      "Epoch 3456, Loss: 9.176648995889991e-05, Final Batch Loss: 3.153176976411487e-06\n",
      "Epoch 3457, Loss: 0.0002901762036344735, Final Batch Loss: 2.1091878807055764e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3458, Loss: 0.0009201506336466991, Final Batch Loss: 1.1937810086237732e-05\n",
      "Epoch 3459, Loss: 0.0009487012139288709, Final Batch Loss: 0.00013070067507214844\n",
      "Epoch 3460, Loss: 0.002990102658259275, Final Batch Loss: 7.73330611991696e-05\n",
      "Epoch 3461, Loss: 0.0006101989674789365, Final Batch Loss: 1.027866528602317e-05\n",
      "Epoch 3462, Loss: 0.0012184273614366248, Final Batch Loss: 2.2532290131493937e-06\n",
      "Epoch 3463, Loss: 0.008829281307043857, Final Batch Loss: 1.334316584689077e-05\n",
      "Epoch 3464, Loss: 0.0003137261901429156, Final Batch Loss: 2.6175779566983692e-05\n",
      "Epoch 3465, Loss: 0.0006435164577851538, Final Batch Loss: 0.0005509098991751671\n",
      "Epoch 3466, Loss: 0.00018053008736274023, Final Batch Loss: 1.4725830510542437e-07\n",
      "Epoch 3467, Loss: 0.0006855602550785989, Final Batch Loss: 0.0005931433406658471\n",
      "Epoch 3468, Loss: 0.00014894816195010208, Final Batch Loss: 4.6896428102627397e-05\n",
      "Epoch 3469, Loss: 0.003959950365242548, Final Batch Loss: 2.7700545615516603e-05\n",
      "Epoch 3470, Loss: 0.0001958276743607712, Final Batch Loss: 5.859729753865395e-06\n",
      "Epoch 3471, Loss: 0.00017928632541952538, Final Batch Loss: 3.4803156268026214e-06\n",
      "Epoch 3472, Loss: 6.559183748322539e-05, Final Batch Loss: 2.5841691240202636e-05\n",
      "Epoch 3473, Loss: 0.00019220282229071017, Final Batch Loss: 3.5668253985932097e-06\n",
      "Epoch 3474, Loss: 0.00032642739461152814, Final Batch Loss: 0.0001745650079101324\n",
      "Epoch 3475, Loss: 5.196029542275937e-05, Final Batch Loss: 1.1617258678597864e-05\n",
      "Epoch 3476, Loss: 0.0003204612003173679, Final Batch Loss: 0.00016166482237167656\n",
      "Epoch 3477, Loss: 0.00031826670903001286, Final Batch Loss: 6.030562076375645e-07\n",
      "Epoch 3478, Loss: 0.00013399336785369087, Final Batch Loss: 2.513844628992956e-05\n",
      "Epoch 3479, Loss: 0.00033239245385630056, Final Batch Loss: 0.0001157286242232658\n",
      "Epoch 3480, Loss: 0.00018442314467392862, Final Batch Loss: 0.00010806032514665276\n",
      "Epoch 3481, Loss: 0.0010541096908127656, Final Batch Loss: 2.070027585432399e-05\n",
      "Epoch 3482, Loss: 0.00019642204279080033, Final Batch Loss: 1.6915237210923806e-05\n",
      "Epoch 3483, Loss: 0.0034331130773352925, Final Batch Loss: 3.737118822755292e-05\n",
      "Epoch 3484, Loss: 0.0003249553992645815, Final Batch Loss: 3.7204401451162994e-05\n",
      "Epoch 3485, Loss: 0.00015753764319015318, Final Batch Loss: 2.7627415875031147e-06\n",
      "Epoch 3486, Loss: 0.0002970247915072832, Final Batch Loss: 0.00011130019993288442\n",
      "Epoch 3487, Loss: 9.15469854589901e-05, Final Batch Loss: 2.1256317268125713e-05\n",
      "Epoch 3488, Loss: 6.771170956199057e-05, Final Batch Loss: 9.81040830083657e-06\n",
      "Epoch 3489, Loss: 0.00025114978961937595, Final Batch Loss: 1.7712243788992055e-05\n",
      "Epoch 3490, Loss: 8.120676102407742e-05, Final Batch Loss: 2.1433670553960837e-05\n",
      "Epoch 3491, Loss: 0.0003028330138477031, Final Batch Loss: 0.0002197029534727335\n",
      "Epoch 3492, Loss: 0.0003148433333990397, Final Batch Loss: 2.7967964342678897e-05\n",
      "Epoch 3493, Loss: 0.0003619634120468618, Final Batch Loss: 7.7368019901769e-07\n",
      "Epoch 3494, Loss: 0.0032829984647833044, Final Batch Loss: 4.6606692194473e-06\n",
      "Epoch 3495, Loss: 0.0005212028554524295, Final Batch Loss: 0.00033636472653597593\n",
      "Epoch 3496, Loss: 0.0006714857577208022, Final Batch Loss: 4.3310851651767734e-06\n",
      "Epoch 3497, Loss: 5.045982697993168e-05, Final Batch Loss: 2.2681841073790565e-05\n",
      "Epoch 3498, Loss: 0.00021750809804643723, Final Batch Loss: 5.866949663868581e-07\n",
      "Epoch 3499, Loss: 9.895543234961224e-05, Final Batch Loss: 3.435946837271331e-06\n",
      "Epoch 3500, Loss: 0.0011669913478726812, Final Batch Loss: 2.1924647626292426e-06\n",
      "Epoch 3501, Loss: 0.0005135233122928184, Final Batch Loss: 7.507435839215759e-06\n",
      "Epoch 3502, Loss: 2.7581301083046128e-05, Final Batch Loss: 9.069178759091301e-07\n",
      "Epoch 3503, Loss: 0.000627410131301076, Final Batch Loss: 1.8021371488430304e-06\n",
      "Epoch 3504, Loss: 0.00013048044638708234, Final Batch Loss: 7.303989150386769e-06\n",
      "Epoch 3505, Loss: 0.00016103168672998436, Final Batch Loss: 3.396209649508819e-06\n",
      "Epoch 3506, Loss: 0.020151142385657295, Final Batch Loss: 0.018122846260666847\n",
      "Epoch 3507, Loss: 0.00023044760928314645, Final Batch Loss: 1.615702967683319e-05\n",
      "Epoch 3508, Loss: 0.0019224698917241767, Final Batch Loss: 0.0018010339699685574\n",
      "Epoch 3509, Loss: 0.003314823212349438, Final Batch Loss: 2.238512934127357e-05\n",
      "Epoch 3510, Loss: 0.016937046960265434, Final Batch Loss: 1.011294898489723e-05\n",
      "Epoch 3511, Loss: 0.0037388443379313685, Final Batch Loss: 0.0005464168498292565\n",
      "Epoch 3512, Loss: 7.67209558034665e-05, Final Batch Loss: 1.4167372683004942e-05\n",
      "Epoch 3513, Loss: 0.00011967490081588039, Final Batch Loss: 2.5082910724449903e-05\n",
      "Epoch 3514, Loss: 0.00041888515079335775, Final Batch Loss: 5.896972652408294e-06\n",
      "Epoch 3515, Loss: 0.0009002461447380483, Final Batch Loss: 0.00041697302367538214\n",
      "Epoch 3516, Loss: 0.003679148474475369, Final Batch Loss: 0.0003157106402795762\n",
      "Epoch 3517, Loss: 0.0011497770974528976, Final Batch Loss: 8.421212260145694e-05\n",
      "Epoch 3518, Loss: 0.003365409509569872, Final Batch Loss: 2.3873064492363483e-05\n",
      "Epoch 3519, Loss: 0.00011404579038298834, Final Batch Loss: 6.825290483902791e-07\n",
      "Epoch 3520, Loss: 0.0001526975211163517, Final Batch Loss: 5.6247565225930884e-05\n",
      "Epoch 3521, Loss: 0.0001546622152091004, Final Batch Loss: 3.407771509955637e-05\n",
      "Epoch 3522, Loss: 0.0010132125698874006, Final Batch Loss: 0.0005197601276449859\n",
      "Epoch 3523, Loss: 0.00042325040203650133, Final Batch Loss: 5.51356652067625e-06\n",
      "Epoch 3524, Loss: 0.0003996243394794874, Final Batch Loss: 1.0909820048254915e-05\n",
      "Epoch 3525, Loss: 0.0004519068752415478, Final Batch Loss: 0.00011205791088286787\n",
      "Epoch 3526, Loss: 0.003970222005591495, Final Batch Loss: 7.762148015899584e-06\n",
      "Epoch 3527, Loss: 8.419969617534662e-05, Final Batch Loss: 1.7827665942604654e-05\n",
      "Epoch 3528, Loss: 0.00012369512205623323, Final Batch Loss: 6.981555088714231e-06\n",
      "Epoch 3529, Loss: 0.0022505177039420232, Final Batch Loss: 0.0012021446600556374\n",
      "Epoch 3530, Loss: 0.00025049263854270976, Final Batch Loss: 2.440225898681092e-06\n",
      "Epoch 3531, Loss: 0.004584461094054859, Final Batch Loss: 9.878704440779984e-05\n",
      "Epoch 3532, Loss: 0.010076719787321053, Final Batch Loss: 0.000159406554303132\n",
      "Epoch 3533, Loss: 0.0001180587787530385, Final Batch Loss: 3.517232835292816e-05\n",
      "Epoch 3534, Loss: 9.526847793495108e-05, Final Batch Loss: 3.608894303397392e-06\n",
      "Epoch 3535, Loss: 0.00015210580932034645, Final Batch Loss: 1.64673419931205e-05\n",
      "Epoch 3536, Loss: 0.0004408119020808954, Final Batch Loss: 6.766108708688989e-05\n",
      "Epoch 3537, Loss: 0.00014935424587747548, Final Batch Loss: 3.3159536542370915e-05\n",
      "Epoch 3538, Loss: 0.00012218723531987052, Final Batch Loss: 3.131817720714025e-05\n",
      "Epoch 3539, Loss: 0.0002510688746042433, Final Batch Loss: 8.902260560716968e-06\n",
      "Epoch 3540, Loss: 0.00025237485169782303, Final Batch Loss: 0.0001706956682028249\n",
      "Epoch 3541, Loss: 0.001923153746247408, Final Batch Loss: 8.591699952376075e-06\n",
      "Epoch 3542, Loss: 0.00040122501195583027, Final Batch Loss: 7.437394742737524e-06\n",
      "Epoch 3543, Loss: 0.0004135014532948844, Final Batch Loss: 0.00014159359852783382\n",
      "Epoch 3544, Loss: 7.375580003099458e-05, Final Batch Loss: 2.9053651360300137e-06\n",
      "Epoch 3545, Loss: 0.00018095433733833488, Final Batch Loss: 1.4832761735306121e-05\n",
      "Epoch 3546, Loss: 0.00016453120133519405, Final Batch Loss: 1.3352467249205802e-05\n",
      "Epoch 3547, Loss: 0.0027894575678146794, Final Batch Loss: 0.002604992361739278\n",
      "Epoch 3548, Loss: 3.403747405172908e-05, Final Batch Loss: 3.1483300517720636e-06\n",
      "Epoch 3549, Loss: 0.0037397339056042256, Final Batch Loss: 0.0031438327860087156\n",
      "Epoch 3550, Loss: 0.00014261430294482125, Final Batch Loss: 6.942103709661751e-07\n",
      "Epoch 3551, Loss: 0.00023217163789013284, Final Batch Loss: 0.00014180118159856647\n",
      "Epoch 3552, Loss: 0.00012896107898541231, Final Batch Loss: 1.7460496337662335e-06\n",
      "Epoch 3553, Loss: 0.00128897281956597, Final Batch Loss: 7.528399692091625e-06\n",
      "Epoch 3554, Loss: 0.00021340602324926294, Final Batch Loss: 0.0001232774811796844\n",
      "Epoch 3555, Loss: 0.00023138326218941074, Final Batch Loss: 7.549872407253133e-07\n",
      "Epoch 3556, Loss: 0.000298247859973344, Final Batch Loss: 4.992352842236869e-06\n",
      "Epoch 3557, Loss: 0.00013451820632326417, Final Batch Loss: 6.576970190508291e-05\n",
      "Epoch 3558, Loss: 4.819615787710063e-05, Final Batch Loss: 9.242689884558786e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3559, Loss: 0.0009633586068957811, Final Batch Loss: 1.8270709915668704e-05\n",
      "Epoch 3560, Loss: 7.199891342679621e-05, Final Batch Loss: 9.439686436962802e-06\n",
      "Epoch 3561, Loss: 0.0015209574412438087, Final Batch Loss: 0.00129397539421916\n",
      "Epoch 3562, Loss: 8.289056290777808e-05, Final Batch Loss: 2.211117816841579e-06\n",
      "Epoch 3563, Loss: 8.517752894476871e-05, Final Batch Loss: 4.099594207218615e-06\n",
      "Epoch 3564, Loss: 8.272649756690953e-05, Final Batch Loss: 1.042777148541063e-05\n",
      "Epoch 3565, Loss: 0.0005311698369041551, Final Batch Loss: 0.00013653784117195755\n",
      "Epoch 3566, Loss: 4.882216853729915e-05, Final Batch Loss: 1.0393652701168321e-05\n",
      "Epoch 3567, Loss: 7.324708906253363e-05, Final Batch Loss: 2.8750412184308516e-07\n",
      "Epoch 3568, Loss: 0.00015067452349626365, Final Batch Loss: 4.604722505519021e-07\n",
      "Epoch 3569, Loss: 5.4593938557445654e-05, Final Batch Loss: 3.503682137306896e-06\n",
      "Epoch 3570, Loss: 0.0005420119079104779, Final Batch Loss: 1.963445726005375e-07\n",
      "Epoch 3571, Loss: 0.0002752853361016605, Final Batch Loss: 1.4001012459630147e-05\n",
      "Epoch 3572, Loss: 0.0017709376770653762, Final Batch Loss: 0.0016178252408280969\n",
      "Epoch 3573, Loss: 7.340283991652541e-05, Final Batch Loss: 1.583076300448738e-05\n",
      "Epoch 3574, Loss: 0.00012114424680476077, Final Batch Loss: 1.5142846677917987e-05\n",
      "Epoch 3575, Loss: 0.00023851898004068062, Final Batch Loss: 7.542159437434748e-05\n",
      "Epoch 3576, Loss: 0.0005495189536190992, Final Batch Loss: 5.259200293039612e-07\n",
      "Epoch 3577, Loss: 0.0004007310867564229, Final Batch Loss: 0.0003686929994728416\n",
      "Epoch 3578, Loss: 0.00022428602824220434, Final Batch Loss: 7.669271872146055e-05\n",
      "Epoch 3579, Loss: 0.00013949413551017642, Final Batch Loss: 5.352991138352081e-05\n",
      "Epoch 3580, Loss: 0.00024194402431021444, Final Batch Loss: 1.885253550426569e-05\n",
      "Epoch 3581, Loss: 0.0015540613130724523, Final Batch Loss: 0.001436859369277954\n",
      "Epoch 3582, Loss: 5.7172318065568106e-05, Final Batch Loss: 5.291797151585342e-06\n",
      "Epoch 3583, Loss: 5.64250417482981e-05, Final Batch Loss: 4.4082271415391006e-06\n",
      "Epoch 3584, Loss: 0.0002653602122393295, Final Batch Loss: 4.6280993615255284e-07\n",
      "Epoch 3585, Loss: 0.00020471791322052013, Final Batch Loss: 3.3263586374232545e-05\n",
      "Epoch 3586, Loss: 0.00012490323206293397, Final Batch Loss: 3.362929055583663e-05\n",
      "Epoch 3587, Loss: 0.0008646344576845877, Final Batch Loss: 8.671869727550074e-05\n",
      "Epoch 3588, Loss: 0.0011720607817551354, Final Batch Loss: 0.0010155681520700455\n",
      "Epoch 3589, Loss: 0.0002258351423733984, Final Batch Loss: 6.058008693798911e-06\n",
      "Epoch 3590, Loss: 0.00011506521332194097, Final Batch Loss: 4.6965644287411124e-05\n",
      "Epoch 3591, Loss: 0.00011104649092885666, Final Batch Loss: 1.1500377695483621e-05\n",
      "Epoch 3592, Loss: 0.001061801822288544, Final Batch Loss: 1.7063977793441154e-05\n",
      "Epoch 3593, Loss: 0.00011531378822837723, Final Batch Loss: 3.0938110285205767e-05\n",
      "Epoch 3594, Loss: 0.00039547976120957173, Final Batch Loss: 7.145002746256068e-05\n",
      "Epoch 3595, Loss: 4.827337602364423e-05, Final Batch Loss: 2.554661705289618e-06\n",
      "Epoch 3596, Loss: 6.058115718587942e-05, Final Batch Loss: 1.8231673948321259e-06\n",
      "Epoch 3597, Loss: 0.002297541695952532, Final Batch Loss: 4.380178506835364e-05\n",
      "Epoch 3598, Loss: 0.002131565376544131, Final Batch Loss: 1.3510278904504958e-06\n",
      "Epoch 3599, Loss: 0.0003127534748728067, Final Batch Loss: 1.1500108030304546e-06\n",
      "Epoch 3600, Loss: 5.9646565659932094e-05, Final Batch Loss: 5.9455928749230225e-06\n",
      "Epoch 3601, Loss: 3.2847083730302984e-05, Final Batch Loss: 1.4726015251653735e-05\n",
      "Epoch 3602, Loss: 0.00010174808411989034, Final Batch Loss: 2.734792303726863e-07\n",
      "Epoch 3603, Loss: 0.013767983913453463, Final Batch Loss: 1.3510178860087763e-06\n",
      "Epoch 3604, Loss: 0.0003147874069355794, Final Batch Loss: 1.5427049504523893e-07\n",
      "Epoch 3605, Loss: 9.104849232244305e-05, Final Batch Loss: 1.9277329556643963e-05\n",
      "Epoch 3606, Loss: 6.547551402036333e-05, Final Batch Loss: 1.2108874216210097e-05\n",
      "Epoch 3607, Loss: 0.0004209691869618837, Final Batch Loss: 2.855138518498279e-05\n",
      "Epoch 3608, Loss: 0.000540268978511449, Final Batch Loss: 0.00011275320866843686\n",
      "Epoch 3609, Loss: 0.0006887161912345618, Final Batch Loss: 6.385108008544194e-06\n",
      "Epoch 3610, Loss: 0.00011163856424900587, Final Batch Loss: 3.854132501146523e-06\n",
      "Epoch 3611, Loss: 0.0010835851022648058, Final Batch Loss: 1.5660549479434849e-06\n",
      "Epoch 3612, Loss: 6.267370974910591e-05, Final Batch Loss: 3.389274070286774e-07\n",
      "Epoch 3613, Loss: 0.0001790975275071105, Final Batch Loss: 2.4133229089784436e-05\n",
      "Epoch 3614, Loss: 0.0001032074615068268, Final Batch Loss: 2.030010182352271e-05\n",
      "Epoch 3615, Loss: 0.00032175344699680863, Final Batch Loss: 2.7604494334809715e-06\n",
      "Epoch 3616, Loss: 0.00012720253835141193, Final Batch Loss: 6.2404360505752265e-06\n",
      "Epoch 3617, Loss: 0.00036368643304740544, Final Batch Loss: 3.008921521541197e-05\n",
      "Epoch 3618, Loss: 0.00024507562920916826, Final Batch Loss: 6.959925667615607e-05\n",
      "Epoch 3619, Loss: 0.00017451547682867385, Final Batch Loss: 3.84168561140541e-05\n",
      "Epoch 3620, Loss: 0.0001975341419893084, Final Batch Loss: 0.00013707987091038376\n",
      "Epoch 3621, Loss: 0.00038583024661420495, Final Batch Loss: 2.8890519388369285e-05\n",
      "Epoch 3622, Loss: 0.00013925798907621356, Final Batch Loss: 3.1133897664403776e-06\n",
      "Epoch 3623, Loss: 8.391419387976384e-05, Final Batch Loss: 3.202284517556109e-07\n",
      "Epoch 3624, Loss: 0.00013162050845494377, Final Batch Loss: 5.11875941811013e-06\n",
      "Epoch 3625, Loss: 7.169970638187806e-05, Final Batch Loss: 1.5052909247970092e-06\n",
      "Epoch 3626, Loss: 6.766922410861298e-05, Final Batch Loss: 3.6462495245359605e-06\n",
      "Epoch 3627, Loss: 0.00023868370226409752, Final Batch Loss: 1.4739687685505487e-05\n",
      "Epoch 3628, Loss: 6.454848971770843e-05, Final Batch Loss: 5.4854817790328525e-06\n",
      "Epoch 3629, Loss: 0.0004296730548958294, Final Batch Loss: 0.00032760491012595594\n",
      "Epoch 3630, Loss: 0.00013317550656211097, Final Batch Loss: 2.8400998417055234e-05\n",
      "Epoch 3631, Loss: 0.001337409506078302, Final Batch Loss: 4.230742263189313e-07\n",
      "Epoch 3632, Loss: 0.00460083999496419, Final Batch Loss: 0.00046121719060465693\n",
      "Epoch 3633, Loss: 0.00011660239397315308, Final Batch Loss: 3.5150569601682946e-05\n",
      "Epoch 3634, Loss: 0.00029375964504652075, Final Batch Loss: 1.695571882009972e-05\n",
      "Epoch 3635, Loss: 9.389789875058341e-05, Final Batch Loss: 3.674255367513979e-06\n",
      "Epoch 3636, Loss: 3.748296921912697e-05, Final Batch Loss: 2.716034487093566e-06\n",
      "Epoch 3637, Loss: 6.97482955729356e-05, Final Batch Loss: 5.249407877272461e-06\n",
      "Epoch 3638, Loss: 0.001664427782088751, Final Batch Loss: 2.5080389605136588e-05\n",
      "Epoch 3639, Loss: 0.00046978127011243487, Final Batch Loss: 4.4759972297470085e-06\n",
      "Epoch 3640, Loss: 0.0002191289750044234, Final Batch Loss: 0.0001051080398610793\n",
      "Epoch 3641, Loss: 0.0006816024542786181, Final Batch Loss: 0.00021462954464368522\n",
      "Epoch 3642, Loss: 9.810041410673875e-05, Final Batch Loss: 8.983312000054866e-06\n",
      "Epoch 3643, Loss: 0.0007402425460441009, Final Batch Loss: 1.4351651316246716e-06\n",
      "Epoch 3644, Loss: 2.7798303563031368e-05, Final Batch Loss: 5.452895948110381e-06\n",
      "Epoch 3645, Loss: 0.012826618960389169, Final Batch Loss: 8.305861410917714e-05\n",
      "Epoch 3646, Loss: 0.0073322334264958045, Final Batch Loss: 0.007247318048030138\n",
      "Epoch 3647, Loss: 0.001589476140907209, Final Batch Loss: 9.825324923440348e-06\n",
      "Epoch 3648, Loss: 0.00010984308255501674, Final Batch Loss: 6.338420007523382e-06\n",
      "Epoch 3649, Loss: 4.442015415406786e-05, Final Batch Loss: 4.006087692687288e-06\n",
      "Epoch 3650, Loss: 0.00011088099464018342, Final Batch Loss: 4.324237181663193e-07\n",
      "Epoch 3651, Loss: 0.0001275703907595016, Final Batch Loss: 9.567208326188847e-05\n",
      "Epoch 3652, Loss: 0.0003168726216244977, Final Batch Loss: 3.465024201432243e-05\n",
      "Epoch 3653, Loss: 0.0038346953415384633, Final Batch Loss: 0.000119234602607321\n",
      "Epoch 3654, Loss: 0.0004717409465229139, Final Batch Loss: 6.051863601896912e-05\n",
      "Epoch 3655, Loss: 3.4137238799303304e-05, Final Batch Loss: 1.1233363693463616e-05\n",
      "Epoch 3656, Loss: 9.478842247290231e-05, Final Batch Loss: 8.484791464979935e-07\n",
      "Epoch 3657, Loss: 8.193527378352883e-05, Final Batch Loss: 3.571467686924734e-06\n",
      "Epoch 3658, Loss: 0.0002337102023375337, Final Batch Loss: 0.00013738160487264395\n",
      "Epoch 3659, Loss: 4.664441894419724e-05, Final Batch Loss: 9.732010767038446e-06\n",
      "Epoch 3660, Loss: 7.426886941175326e-05, Final Batch Loss: 1.376047839585226e-05\n",
      "Epoch 3661, Loss: 7.458616482836078e-05, Final Batch Loss: 4.7982226533349603e-05\n",
      "Epoch 3662, Loss: 0.0001398450239094018, Final Batch Loss: 1.5987897086233716e-06\n",
      "Epoch 3663, Loss: 0.0001473900192650035, Final Batch Loss: 8.208497456507757e-05\n",
      "Epoch 3664, Loss: 0.0015493632481593522, Final Batch Loss: 6.387692337739281e-06\n",
      "Epoch 3665, Loss: 0.0002461190896951848, Final Batch Loss: 8.835422136144189e-07\n",
      "Epoch 3666, Loss: 9.98151822386717e-05, Final Batch Loss: 4.4803869059251156e-06\n",
      "Epoch 3667, Loss: 0.01429324801824805, Final Batch Loss: 1.5660232293157605e-06\n",
      "Epoch 3668, Loss: 0.00015765051307425892, Final Batch Loss: 3.262874770371127e-06\n",
      "Epoch 3669, Loss: 0.019310374208998837, Final Batch Loss: 2.5429776542296167e-06\n",
      "Epoch 3670, Loss: 0.06771010949887568, Final Batch Loss: 0.06591632217168808\n",
      "Epoch 3671, Loss: 0.0002201047348080465, Final Batch Loss: 2.8118622594774934e-06\n",
      "Epoch 3672, Loss: 0.0004053033444506582, Final Batch Loss: 6.21447543380782e-06\n",
      "Epoch 3673, Loss: 6.170868130084273e-05, Final Batch Loss: 1.8278429934071028e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3674, Loss: 6.659389691776596e-05, Final Batch Loss: 2.6053929104818963e-05\n",
      "Epoch 3675, Loss: 0.0005015273236494977, Final Batch Loss: 9.730570309329778e-05\n",
      "Epoch 3676, Loss: 0.0030983540036686463, Final Batch Loss: 7.1752856456441805e-06\n",
      "Epoch 3677, Loss: 0.0003995225197286345, Final Batch Loss: 0.00015857505786698312\n",
      "Epoch 3678, Loss: 0.0010898682667175308, Final Batch Loss: 0.0006536783184856176\n",
      "Epoch 3679, Loss: 0.001110030853169519, Final Batch Loss: 2.617822474348941e-06\n",
      "Epoch 3680, Loss: 0.00041304620208393317, Final Batch Loss: 6.28719681117218e-06\n",
      "Epoch 3681, Loss: 0.000681338227877859, Final Batch Loss: 0.0004359305021353066\n",
      "Epoch 3682, Loss: 0.0001464431879867334, Final Batch Loss: 3.785904118558392e-05\n",
      "Epoch 3683, Loss: 0.00026770678186949226, Final Batch Loss: 5.3430844673130196e-06\n",
      "Epoch 3684, Loss: 4.460761999780516e-05, Final Batch Loss: 1.2248082157384488e-06\n",
      "Epoch 3685, Loss: 0.0004820753763965513, Final Batch Loss: 4.0203832440965925e-07\n",
      "Epoch 3686, Loss: 0.0006666757526545553, Final Batch Loss: 4.056223770021461e-05\n",
      "Epoch 3687, Loss: 0.00011292818739150334, Final Batch Loss: 2.337429947374403e-07\n",
      "Epoch 3688, Loss: 0.0005797682515549241, Final Batch Loss: 4.650505070458166e-05\n",
      "Epoch 3689, Loss: 4.0425770293950336e-05, Final Batch Loss: 3.5971775105281267e-06\n",
      "Epoch 3690, Loss: 0.0067137920282220875, Final Batch Loss: 9.49855075305095e-06\n",
      "Epoch 3691, Loss: 0.0002207883417213452, Final Batch Loss: 3.727910552697722e-06\n",
      "Epoch 3692, Loss: 0.0002848244439519476, Final Batch Loss: 1.0893385478993878e-05\n",
      "Epoch 3693, Loss: 0.00020903480435663369, Final Batch Loss: 1.573003646626603e-05\n",
      "Epoch 3694, Loss: 0.024196875055622513, Final Batch Loss: 8.033834456000477e-05\n",
      "Epoch 3695, Loss: 0.0005533842850127257, Final Batch Loss: 2.3142338250181638e-05\n",
      "Epoch 3696, Loss: 0.0004988216605852358, Final Batch Loss: 0.00014970997290220112\n",
      "Epoch 3697, Loss: 0.0005350786123017315, Final Batch Loss: 5.845132182002999e-05\n",
      "Epoch 3698, Loss: 0.0006127881752036046, Final Batch Loss: 6.0764195950469e-05\n",
      "Epoch 3699, Loss: 0.0021022301798439003, Final Batch Loss: 1.1793686098826583e-05\n",
      "Epoch 3700, Loss: 0.00033349726709275274, Final Batch Loss: 3.961823495046701e-06\n",
      "Epoch 3701, Loss: 0.00013588400315711624, Final Batch Loss: 4.384755357023096e-06\n",
      "Epoch 3702, Loss: 0.00018392741549178027, Final Batch Loss: 2.2327189071802422e-05\n",
      "Epoch 3703, Loss: 0.0003399095583063172, Final Batch Loss: 1.9493452327878913e-06\n",
      "Epoch 3704, Loss: 0.0011400589864933863, Final Batch Loss: 6.653768650721759e-06\n",
      "Epoch 3705, Loss: 0.0003365386000950821, Final Batch Loss: 3.270919114584103e-05\n",
      "Epoch 3706, Loss: 0.00022083187650423497, Final Batch Loss: 1.7615770047996193e-05\n",
      "Epoch 3707, Loss: 0.0004301318308534974, Final Batch Loss: 1.942387370945653e-06\n",
      "Epoch 3708, Loss: 0.00018409116546536097, Final Batch Loss: 3.5084094633930363e-06\n",
      "Epoch 3709, Loss: 0.00011075416841777042, Final Batch Loss: 5.6247878092108294e-05\n",
      "Epoch 3710, Loss: 0.00038675255154885235, Final Batch Loss: 0.0003501201281324029\n",
      "Epoch 3711, Loss: 0.0031874249871179927, Final Batch Loss: 0.0001189607210108079\n",
      "Epoch 3712, Loss: 0.000183662242761784, Final Batch Loss: 5.564895673160208e-06\n",
      "Epoch 3713, Loss: 0.0034679456148296595, Final Batch Loss: 0.00309088290669024\n",
      "Epoch 3714, Loss: 0.0005444548387458781, Final Batch Loss: 5.564905222854577e-06\n",
      "Epoch 3715, Loss: 6.837275850557489e-05, Final Batch Loss: 1.0633850251906551e-05\n",
      "Epoch 3716, Loss: 9.945686269929865e-05, Final Batch Loss: 5.2826813771389425e-05\n",
      "Epoch 3717, Loss: 0.00027081911866844166, Final Batch Loss: 2.6753014026326127e-05\n",
      "Epoch 3718, Loss: 0.00032206545074586757, Final Batch Loss: 4.610505493474193e-05\n",
      "Epoch 3719, Loss: 0.0006571409030584618, Final Batch Loss: 0.000522567075677216\n",
      "Epoch 3720, Loss: 0.00023121992489905097, Final Batch Loss: 0.0001348388468613848\n",
      "Epoch 3721, Loss: 0.0005652532754538697, Final Batch Loss: 8.981781320471782e-06\n",
      "Epoch 3722, Loss: 0.00011859057849505916, Final Batch Loss: 6.369398761307821e-05\n",
      "Epoch 3723, Loss: 0.0019087395658061723, Final Batch Loss: 1.2529278137662914e-05\n",
      "Epoch 3724, Loss: 9.79203880433488e-05, Final Batch Loss: 2.0335687622718979e-07\n",
      "Epoch 3725, Loss: 0.00022172301987666287, Final Batch Loss: 3.830823061434785e-06\n",
      "Epoch 3726, Loss: 0.0005519466849364107, Final Batch Loss: 1.0529000064707361e-05\n",
      "Epoch 3727, Loss: 0.0001598975431988947, Final Batch Loss: 9.794194193091244e-05\n",
      "Epoch 3728, Loss: 0.0015187660210358445, Final Batch Loss: 4.4015741877956316e-05\n",
      "Epoch 3729, Loss: 0.0002279047930642264, Final Batch Loss: 9.006989785120822e-06\n",
      "Epoch 3730, Loss: 0.0010787719902509707, Final Batch Loss: 9.498277904640418e-06\n",
      "Epoch 3731, Loss: 0.0011719555122908787, Final Batch Loss: 1.4156000361253973e-05\n",
      "Epoch 3732, Loss: 0.0070885212771827355, Final Batch Loss: 0.0005758201004937291\n",
      "Epoch 3733, Loss: 0.00010677225600375095, Final Batch Loss: 2.0781601051567122e-05\n",
      "Epoch 3734, Loss: 0.0001377955577481771, Final Batch Loss: 9.105506251216866e-06\n",
      "Epoch 3735, Loss: 0.0006864120750833536, Final Batch Loss: 2.4194596335291862e-05\n",
      "Epoch 3736, Loss: 0.0001691592115093954, Final Batch Loss: 3.5944769479101524e-05\n",
      "Epoch 3737, Loss: 0.0008586847936840059, Final Batch Loss: 0.0008041781256906688\n",
      "Epoch 3738, Loss: 0.0003777775236812886, Final Batch Loss: 1.9733608496608213e-05\n",
      "Epoch 3739, Loss: 0.00011356066715961788, Final Batch Loss: 2.3467391656595282e-05\n",
      "Epoch 3740, Loss: 0.0004822626515306183, Final Batch Loss: 1.1334283954056446e-05\n",
      "Epoch 3741, Loss: 9.4719629487372e-05, Final Batch Loss: 2.5101015125983395e-05\n",
      "Epoch 3742, Loss: 0.01130879722222744, Final Batch Loss: 2.0882342141703703e-05\n",
      "Epoch 3743, Loss: 6.156128756629187e-05, Final Batch Loss: 4.17907949668006e-06\n",
      "Epoch 3744, Loss: 0.005424241628134041, Final Batch Loss: 0.005377965047955513\n",
      "Epoch 3745, Loss: 0.0009356851260235999, Final Batch Loss: 5.091831917525269e-05\n",
      "Epoch 3746, Loss: 0.0002235917309008073, Final Batch Loss: 5.034219066146761e-05\n",
      "Epoch 3747, Loss: 0.0002494267318979837, Final Batch Loss: 4.670268026529811e-05\n",
      "Epoch 3748, Loss: 0.0001801358230295591, Final Batch Loss: 4.483710654312745e-05\n",
      "Epoch 3749, Loss: 8.768088264332619e-05, Final Batch Loss: 2.2278569304035045e-05\n",
      "Epoch 3750, Loss: 4.184677317198293e-05, Final Batch Loss: 8.671810860505502e-07\n",
      "Epoch 3751, Loss: 0.00014356864357978338, Final Batch Loss: 9.161381603917107e-05\n",
      "Epoch 3752, Loss: 0.003480982210021466, Final Batch Loss: 8.91072559170425e-05\n",
      "Epoch 3753, Loss: 7.957961497595534e-05, Final Batch Loss: 3.1728955946164206e-05\n",
      "Epoch 3754, Loss: 0.0002166996542882771, Final Batch Loss: 1.4748999319635914e-06\n",
      "Epoch 3755, Loss: 0.0003885398182319477, Final Batch Loss: 5.7911864132620394e-05\n",
      "Epoch 3756, Loss: 0.0003552988800947787, Final Batch Loss: 8.28519114293158e-05\n",
      "Epoch 3757, Loss: 0.0004176120578449627, Final Batch Loss: 3.966493295592954e-06\n",
      "Epoch 3758, Loss: 0.0002457705450069625, Final Batch Loss: 3.4498374589020386e-05\n",
      "Epoch 3759, Loss: 0.002080148442473728, Final Batch Loss: 7.989648293005303e-05\n",
      "Epoch 3760, Loss: 0.0011710726275850902, Final Batch Loss: 1.3040164049016312e-05\n",
      "Epoch 3761, Loss: 6.496129162769648e-05, Final Batch Loss: 6.825029686297057e-06\n",
      "Epoch 3762, Loss: 0.00011385771722416393, Final Batch Loss: 1.564071499160491e-05\n",
      "Epoch 3763, Loss: 0.0008619235223008559, Final Batch Loss: 6.311076816700734e-08\n",
      "Epoch 3764, Loss: 0.0002838738146238029, Final Batch Loss: 1.6286001482512802e-05\n",
      "Epoch 3765, Loss: 0.0004258777480572462, Final Batch Loss: 0.0003912275133188814\n",
      "Epoch 3766, Loss: 0.002451900332744117, Final Batch Loss: 0.0018703147070482373\n",
      "Epoch 3767, Loss: 0.00012508943291322794, Final Batch Loss: 5.470409814734012e-05\n",
      "Epoch 3768, Loss: 0.000198360338316661, Final Batch Loss: 3.31915060769461e-07\n",
      "Epoch 3769, Loss: 0.00457965923123993, Final Batch Loss: 0.0006544661591760814\n",
      "Epoch 3770, Loss: 0.0002730701073687669, Final Batch Loss: 2.762755002549966e-06\n",
      "Epoch 3771, Loss: 0.00035173207470506895, Final Batch Loss: 1.7724458302836865e-05\n",
      "Epoch 3772, Loss: 4.786050625682492e-05, Final Batch Loss: 2.1738118505254533e-07\n",
      "Epoch 3773, Loss: 0.005822007774668236, Final Batch Loss: 2.8305632895353483e-06\n",
      "Epoch 3774, Loss: 0.0005133150989422575, Final Batch Loss: 3.5384015063755214e-05\n",
      "Epoch 3775, Loss: 0.0002858899715647567, Final Batch Loss: 0.00019498854817356914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3776, Loss: 9.513383520243224e-05, Final Batch Loss: 2.3301172404899262e-05\n",
      "Epoch 3777, Loss: 0.00020130332268308848, Final Batch Loss: 0.00011836283374577761\n",
      "Epoch 3778, Loss: 0.00013852529673386016, Final Batch Loss: 7.830344657122623e-07\n",
      "Epoch 3779, Loss: 0.00013365969789447263, Final Batch Loss: 6.257967470446602e-05\n",
      "Epoch 3780, Loss: 6.70621775498148e-05, Final Batch Loss: 3.81328645744361e-05\n",
      "Epoch 3781, Loss: 0.02300493982329499, Final Batch Loss: 0.015073485672473907\n",
      "Epoch 3782, Loss: 0.00031780069548403844, Final Batch Loss: 0.00027065043104812503\n",
      "Epoch 3783, Loss: 0.0001488105658609129, Final Batch Loss: 5.212330052017933e-06\n",
      "Epoch 3784, Loss: 0.00017362645485263783, Final Batch Loss: 6.448282874771394e-06\n",
      "Epoch 3785, Loss: 0.0009479108230152633, Final Batch Loss: 0.0009051194647327065\n",
      "Epoch 3786, Loss: 0.0022792361669417005, Final Batch Loss: 0.0011875899508595467\n",
      "Epoch 3787, Loss: 0.0002086176009470364, Final Batch Loss: 1.0880632544285618e-05\n",
      "Epoch 3788, Loss: 0.00030171995604177937, Final Batch Loss: 5.563043669098988e-05\n",
      "Epoch 3789, Loss: 8.582875830143166e-05, Final Batch Loss: 7.877049483795417e-07\n",
      "Epoch 3790, Loss: 0.00011974717381235678, Final Batch Loss: 1.8325945347896777e-05\n",
      "Epoch 3791, Loss: 0.00010442175465641412, Final Batch Loss: 8.087458240879641e-07\n",
      "Epoch 3792, Loss: 4.8178925965203234e-05, Final Batch Loss: 5.469585744322103e-07\n",
      "Epoch 3793, Loss: 0.0008592891790613066, Final Batch Loss: 4.528614954324439e-05\n",
      "Epoch 3794, Loss: 3.926907811546698e-05, Final Batch Loss: 7.888063919381239e-06\n",
      "Epoch 3795, Loss: 0.0008699362260813359, Final Batch Loss: 0.0006336592487059534\n",
      "Epoch 3796, Loss: 0.00019070175130764255, Final Batch Loss: 4.5206001232145354e-05\n",
      "Epoch 3797, Loss: 0.00010140731319552287, Final Batch Loss: 2.0381961803650483e-05\n",
      "Epoch 3798, Loss: 0.0002360413818678353, Final Batch Loss: 7.787598588038236e-05\n",
      "Epoch 3799, Loss: 0.0214058825513348, Final Batch Loss: 0.021267129108309746\n",
      "Epoch 3800, Loss: 0.011041748872230528, Final Batch Loss: 0.010959748178720474\n",
      "Epoch 3801, Loss: 0.01060803887912698, Final Batch Loss: 1.3673702596861403e-06\n",
      "Epoch 3802, Loss: 0.0002566711782492348, Final Batch Loss: 0.00021545910567510873\n",
      "Epoch 3803, Loss: 0.0004256700776750222, Final Batch Loss: 9.693207539385185e-05\n",
      "Epoch 3804, Loss: 7.46750221765069e-05, Final Batch Loss: 8.928865895541094e-07\n",
      "Epoch 3805, Loss: 0.004694055707659572, Final Batch Loss: 0.00010661133273970336\n",
      "Epoch 3806, Loss: 0.0009433611758140614, Final Batch Loss: 7.985416232259013e-06\n",
      "Epoch 3807, Loss: 0.0007094253962804942, Final Batch Loss: 0.0006989152170717716\n",
      "Epoch 3808, Loss: 0.0003257549610680144, Final Batch Loss: 5.452503955893917e-06\n",
      "Epoch 3809, Loss: 0.006963571613596287, Final Batch Loss: 0.00011646510392893106\n",
      "Epoch 3810, Loss: 0.0001603452783456305, Final Batch Loss: 0.00013327620399650186\n",
      "Epoch 3811, Loss: 3.45777407346759e-05, Final Batch Loss: 1.4491620277112816e-06\n",
      "Epoch 3812, Loss: 2.733454675762914e-05, Final Batch Loss: 1.1470056961115915e-05\n",
      "Epoch 3813, Loss: 0.01205726880561997, Final Batch Loss: 7.987752724147867e-06\n",
      "Epoch 3814, Loss: 0.00038609508192166686, Final Batch Loss: 6.768408638890833e-06\n",
      "Epoch 3815, Loss: 0.0012233547531650402, Final Batch Loss: 0.0008434207993559539\n",
      "Epoch 3816, Loss: 0.001625852589427268, Final Batch Loss: 1.1640250932032359e-06\n",
      "Epoch 3817, Loss: 0.0002535642908014779, Final Batch Loss: 1.6011164234441821e-06\n",
      "Epoch 3818, Loss: 0.00037498997335205786, Final Batch Loss: 1.8670391000341624e-05\n",
      "Epoch 3819, Loss: 0.0009063069373951294, Final Batch Loss: 0.0003952582774218172\n",
      "Epoch 3820, Loss: 0.0005542236798277145, Final Batch Loss: 1.7998205237290676e-07\n",
      "Epoch 3821, Loss: 0.0003934247979486827, Final Batch Loss: 0.00017903122352436185\n",
      "Epoch 3822, Loss: 0.0003020492586074397, Final Batch Loss: 8.517356764059514e-05\n",
      "Epoch 3823, Loss: 0.00024214081349782646, Final Batch Loss: 3.472597018117085e-05\n",
      "Epoch 3824, Loss: 0.0004449278517171251, Final Batch Loss: 3.0386658522729704e-08\n",
      "Epoch 3825, Loss: 0.0002877824863389833, Final Batch Loss: 0.00022607255959883332\n",
      "Epoch 3826, Loss: 0.0016692017024979577, Final Batch Loss: 4.232745595800225e-06\n",
      "Epoch 3827, Loss: 0.0008796491072189383, Final Batch Loss: 0.0007599563687108457\n",
      "Epoch 3828, Loss: 0.0004365409222373273, Final Batch Loss: 6.238398782443255e-05\n",
      "Epoch 3829, Loss: 7.371808787226541e-05, Final Batch Loss: 5.142355163911816e-08\n",
      "Epoch 3830, Loss: 0.0001770915573615639, Final Batch Loss: 2.1784230739285704e-06\n",
      "Epoch 3831, Loss: 4.783379463901838e-05, Final Batch Loss: 3.6463953279053385e-07\n",
      "Epoch 3832, Loss: 3.4931517376435295e-05, Final Batch Loss: 2.82829233810844e-07\n",
      "Epoch 3833, Loss: 0.0002483868360343422, Final Batch Loss: 3.669760246793885e-07\n",
      "Epoch 3834, Loss: 2.2967396375861426e-05, Final Batch Loss: 5.516311603059876e-07\n",
      "Epoch 3835, Loss: 6.0788862356275786e-05, Final Batch Loss: 4.568829172058031e-05\n",
      "Epoch 3836, Loss: 0.00019444190547801554, Final Batch Loss: 1.625483673706185e-05\n",
      "Epoch 3837, Loss: 6.718552799611643e-05, Final Batch Loss: 2.2415654257201822e-06\n",
      "Epoch 3838, Loss: 0.0015619127959354273, Final Batch Loss: 1.0985941401031596e-07\n",
      "Epoch 3839, Loss: 4.817508397536585e-05, Final Batch Loss: 2.2520071070175618e-05\n",
      "Epoch 3840, Loss: 0.00014168763857469457, Final Batch Loss: 1.1944185871470836e-06\n",
      "Epoch 3841, Loss: 0.0016130187741509872, Final Batch Loss: 4.1430419514654204e-05\n",
      "Epoch 3842, Loss: 6.322000785985438e-05, Final Batch Loss: 1.2575249002111377e-06\n",
      "Epoch 3843, Loss: 2.2521061055158498e-05, Final Batch Loss: 3.019783662239206e-06\n",
      "Epoch 3844, Loss: 0.03442821598946466, Final Batch Loss: 2.1994574126438238e-06\n",
      "Epoch 3845, Loss: 9.252442544038786e-05, Final Batch Loss: 1.2435081089279265e-06\n",
      "Epoch 3846, Loss: 0.00014990899035183247, Final Batch Loss: 0.00010209531319560483\n",
      "Epoch 3847, Loss: 0.05085499914639513, Final Batch Loss: 3.1748659239383414e-05\n",
      "Epoch 3848, Loss: 0.0020996802777517587, Final Batch Loss: 0.00028669965104199946\n",
      "Epoch 3849, Loss: 0.0009247694706573384, Final Batch Loss: 1.3610087989945896e-05\n",
      "Epoch 3850, Loss: 0.00040393662129645236, Final Batch Loss: 0.00029401032952591777\n",
      "Epoch 3851, Loss: 0.0006149074563381873, Final Batch Loss: 3.431074446780258e-06\n",
      "Epoch 3852, Loss: 0.00021496906674656202, Final Batch Loss: 3.597095656004967e-06\n",
      "Epoch 3853, Loss: 0.0025151151457976084, Final Batch Loss: 4.815380452782847e-05\n",
      "Epoch 3854, Loss: 9.698468784336001e-05, Final Batch Loss: 1.1277741577941924e-05\n",
      "Epoch 3855, Loss: 0.00020511094226094428, Final Batch Loss: 1.9838489606627263e-05\n",
      "Epoch 3856, Loss: 0.00011108744229204603, Final Batch Loss: 5.359447186492616e-06\n",
      "Epoch 3857, Loss: 0.00012436233009793796, Final Batch Loss: 4.3281950638629496e-05\n",
      "Epoch 3858, Loss: 1.5991327700248803e-05, Final Batch Loss: 3.3563730994501384e-06\n",
      "Epoch 3859, Loss: 0.00015342340088864148, Final Batch Loss: 1.9493647869239794e-06\n",
      "Epoch 3860, Loss: 0.0003544372639083804, Final Batch Loss: 1.8933222634132107e-07\n",
      "Epoch 3861, Loss: 6.0039875279471744e-05, Final Batch Loss: 1.6946205505519174e-06\n",
      "Epoch 3862, Loss: 0.00016075975145213306, Final Batch Loss: 9.847923502093181e-05\n",
      "Epoch 3863, Loss: 0.00016462160419905558, Final Batch Loss: 3.6206980439601466e-05\n",
      "Epoch 3864, Loss: 0.0002708526262722444, Final Batch Loss: 5.158563726581633e-05\n",
      "Epoch 3865, Loss: 0.00039537460543215275, Final Batch Loss: 5.7542696595191956e-05\n",
      "Epoch 3866, Loss: 0.00022246900698519312, Final Batch Loss: 1.5816938685020432e-05\n",
      "Epoch 3867, Loss: 0.00010973601729347138, Final Batch Loss: 5.733169928134885e-06\n",
      "Epoch 3868, Loss: 0.0004533510218607262, Final Batch Loss: 7.171779725467786e-05\n",
      "Epoch 3869, Loss: 0.0019979796024927055, Final Batch Loss: 1.0969390132231638e-05\n",
      "Epoch 3870, Loss: 0.00010113625387475622, Final Batch Loss: 3.085398248003912e-07\n",
      "Epoch 3871, Loss: 0.00021523905706999358, Final Batch Loss: 0.0001797312288545072\n",
      "Epoch 3872, Loss: 0.0003629685343184974, Final Batch Loss: 0.0003115576400887221\n",
      "Epoch 3873, Loss: 0.0005192678563616937, Final Batch Loss: 7.944106982904486e-06\n",
      "Epoch 3874, Loss: 0.0007487635157303885, Final Batch Loss: 0.0002617718419060111\n",
      "Epoch 3875, Loss: 0.00040841717600414995, Final Batch Loss: 4.244615411153063e-06\n",
      "Epoch 3876, Loss: 0.0008389306205174307, Final Batch Loss: 3.272399737852538e-07\n",
      "Epoch 3877, Loss: 0.0005419732369773556, Final Batch Loss: 4.824805000680499e-05\n",
      "Epoch 3878, Loss: 0.00016252742403821685, Final Batch Loss: 2.5010427862071083e-07\n",
      "Epoch 3879, Loss: 0.00026622943096299423, Final Batch Loss: 1.3596348253486212e-05\n",
      "Epoch 3880, Loss: 0.0002223417563982366, Final Batch Loss: 3.220824964955682e-06\n",
      "Epoch 3881, Loss: 0.00019578829278543708, Final Batch Loss: 1.3743870113103185e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3882, Loss: 0.0005049341216363246, Final Batch Loss: 1.813801827665884e-05\n",
      "Epoch 3883, Loss: 0.00011608414629904473, Final Batch Loss: 2.4776787199698447e-07\n",
      "Epoch 3884, Loss: 0.004630767594790086, Final Batch Loss: 6.115251744631678e-05\n",
      "Epoch 3885, Loss: 4.635216646420304e-05, Final Batch Loss: 2.647384098963812e-05\n",
      "Epoch 3886, Loss: 2.8533786917250836e-05, Final Batch Loss: 3.0268488444562536e-06\n",
      "Epoch 3887, Loss: 0.00020970618425053544, Final Batch Loss: 0.00013893590949010104\n",
      "Epoch 3888, Loss: 0.0018811802365235053, Final Batch Loss: 0.000595677993260324\n",
      "Epoch 3889, Loss: 4.619945545414339e-05, Final Batch Loss: 3.7398828567347664e-07\n",
      "Epoch 3890, Loss: 0.005100689064420294, Final Batch Loss: 0.0049970922991633415\n",
      "Epoch 3891, Loss: 0.00011928359720059234, Final Batch Loss: 1.5636979924238403e-06\n",
      "Epoch 3892, Loss: 4.5068724830343854e-05, Final Batch Loss: 9.219606909027789e-06\n",
      "Epoch 3893, Loss: 0.021842337831913028, Final Batch Loss: 0.021582674235105515\n",
      "Epoch 3894, Loss: 0.0001709105163172353, Final Batch Loss: 6.772827873646747e-06\n",
      "Epoch 3895, Loss: 0.0013720625429414213, Final Batch Loss: 0.000573705299757421\n",
      "Epoch 3896, Loss: 0.0032911689650063636, Final Batch Loss: 1.5510029697907157e-05\n",
      "Epoch 3897, Loss: 0.030149377023917623, Final Batch Loss: 8.577661355957389e-05\n",
      "Epoch 3898, Loss: 0.0036040525446878746, Final Batch Loss: 6.092879630159587e-06\n",
      "Epoch 3899, Loss: 6.868175432828139e-05, Final Batch Loss: 7.308034128072904e-06\n",
      "Epoch 3900, Loss: 0.00010884988114412408, Final Batch Loss: 1.0460293196956627e-05\n",
      "Epoch 3901, Loss: 0.0006599443677259842, Final Batch Loss: 2.1636475139530376e-05\n",
      "Epoch 3902, Loss: 0.00040989047283801483, Final Batch Loss: 2.8882204787805676e-05\n",
      "Epoch 3903, Loss: 0.005414938894205079, Final Batch Loss: 5.773425755251083e-07\n",
      "Epoch 3904, Loss: 0.00043735454278248653, Final Batch Loss: 2.2134947812446626e-06\n",
      "Epoch 3905, Loss: 0.004182879431027686, Final Batch Loss: 5.324290759745054e-05\n",
      "Epoch 3906, Loss: 0.000572557244595373, Final Batch Loss: 0.0002523637958802283\n",
      "Epoch 3907, Loss: 0.00018774839736579452, Final Batch Loss: 1.1991767678409815e-05\n",
      "Epoch 3908, Loss: 0.0025347775481350254, Final Batch Loss: 2.0673998733400367e-05\n",
      "Epoch 3909, Loss: 0.0004564617764231116, Final Batch Loss: 8.181024213627097e-08\n",
      "Epoch 3910, Loss: 0.00024221380772360135, Final Batch Loss: 1.2250360668986104e-05\n",
      "Epoch 3911, Loss: 0.0010614342581902747, Final Batch Loss: 5.748794865212403e-05\n",
      "Epoch 3912, Loss: 0.00021263188500597607, Final Batch Loss: 5.539523408515379e-05\n",
      "Epoch 3913, Loss: 9.770196118097374e-05, Final Batch Loss: 1.6525467572137131e-06\n",
      "Epoch 3914, Loss: 8.963679647422396e-05, Final Batch Loss: 2.833671896951273e-05\n",
      "Epoch 3915, Loss: 3.344567880958493e-05, Final Batch Loss: 1.8849746993510053e-05\n",
      "Epoch 3916, Loss: 0.00014857411224511452, Final Batch Loss: 6.116683653090149e-05\n",
      "Epoch 3917, Loss: 0.0029724873456871137, Final Batch Loss: 2.012661389017012e-05\n",
      "Epoch 3918, Loss: 3.878970787241087e-05, Final Batch Loss: 2.991913277128333e-07\n",
      "Epoch 3919, Loss: 0.0001111340779971215, Final Batch Loss: 8.096459168882575e-06\n",
      "Epoch 3920, Loss: 8.293020914607041e-05, Final Batch Loss: 2.9310679110494675e-06\n",
      "Epoch 3921, Loss: 0.000580149790039286, Final Batch Loss: 5.000772944185883e-05\n",
      "Epoch 3922, Loss: 0.0022681588743580505, Final Batch Loss: 0.0019873911514878273\n",
      "Epoch 3923, Loss: 0.00039064790689735673, Final Batch Loss: 0.0001543015823699534\n",
      "Epoch 3924, Loss: 0.00026258204161422327, Final Batch Loss: 0.00024287597625516355\n",
      "Epoch 3925, Loss: 0.00021188669006733107, Final Batch Loss: 6.397036486305296e-05\n",
      "Epoch 3926, Loss: 0.0007375487220997456, Final Batch Loss: 5.643349504680373e-05\n",
      "Epoch 3927, Loss: 0.0004307252517037341, Final Batch Loss: 5.329317218638607e-07\n",
      "Epoch 3928, Loss: 6.641148684138898e-05, Final Batch Loss: 1.146360591519624e-05\n",
      "Epoch 3929, Loss: 0.00048788729486659577, Final Batch Loss: 2.645939957801602e-06\n",
      "Epoch 3930, Loss: 8.012091529963072e-05, Final Batch Loss: 1.1001302482327446e-05\n",
      "Epoch 3931, Loss: 0.0005834473831782816, Final Batch Loss: 2.8107931939302944e-05\n",
      "Epoch 3932, Loss: 0.00017832699722930556, Final Batch Loss: 1.2251402040419634e-05\n",
      "Epoch 3933, Loss: 0.003978921495672694, Final Batch Loss: 4.361451374279568e-06\n",
      "Epoch 3934, Loss: 0.00010485111465641239, Final Batch Loss: 2.8117535748606315e-06\n",
      "Epoch 3935, Loss: 9.178003369925136e-05, Final Batch Loss: 2.961358632092015e-06\n",
      "Epoch 3936, Loss: 0.0009787603412405588, Final Batch Loss: 0.00041233652154915035\n",
      "Epoch 3937, Loss: 0.000615004425526422, Final Batch Loss: 1.1627203093667049e-05\n",
      "Epoch 3938, Loss: 0.0006576093933290394, Final Batch Loss: 0.0006217010668478906\n",
      "Epoch 3939, Loss: 0.0035703588218893856, Final Batch Loss: 0.0002024620771408081\n",
      "Epoch 3940, Loss: 9.750363142302376e-05, Final Batch Loss: 4.1930657062039245e-06\n",
      "Epoch 3941, Loss: 7.340921456489014e-05, Final Batch Loss: 1.3158179172023665e-05\n",
      "Epoch 3942, Loss: 0.0001250253176294791, Final Batch Loss: 0.0001086062184185721\n",
      "Epoch 3943, Loss: 0.0001016410933516454, Final Batch Loss: 2.7487054467201233e-05\n",
      "Epoch 3944, Loss: 0.0001439540619685431, Final Batch Loss: 5.050810614193324e-06\n",
      "Epoch 3945, Loss: 0.0002664070694322618, Final Batch Loss: 4.908602591058298e-07\n",
      "Epoch 3946, Loss: 0.00012562021220219322, Final Batch Loss: 1.7773534636944532e-05\n",
      "Epoch 3947, Loss: 0.0003792559145949781, Final Batch Loss: 2.527595279389061e-05\n",
      "Epoch 3948, Loss: 0.0002251639452879317, Final Batch Loss: 7.761356755509041e-06\n",
      "Epoch 3949, Loss: 0.000273544905212475, Final Batch Loss: 0.00013408277300186455\n",
      "Epoch 3950, Loss: 0.00029165297360123077, Final Batch Loss: 4.1840007725113537e-07\n",
      "Epoch 3951, Loss: 0.00022174765399540775, Final Batch Loss: 8.99982187547721e-05\n",
      "Epoch 3952, Loss: 0.0007113909814506769, Final Batch Loss: 0.0002528646436985582\n",
      "Epoch 3953, Loss: 0.00022150787117425352, Final Batch Loss: 1.010355117614381e-05\n",
      "Epoch 3954, Loss: 0.0001461332885810407, Final Batch Loss: 9.545662760501727e-05\n",
      "Epoch 3955, Loss: 0.0006270117009989917, Final Batch Loss: 0.0001374344719806686\n",
      "Epoch 3956, Loss: 0.00010209760148427449, Final Batch Loss: 2.0101924746995792e-07\n",
      "Epoch 3957, Loss: 0.00011042214833878461, Final Batch Loss: 4.2540938238744275e-07\n",
      "Epoch 3958, Loss: 2.9210512707322778e-05, Final Batch Loss: 1.0074221563627361e-06\n",
      "Epoch 3959, Loss: 0.00011522572003741516, Final Batch Loss: 1.0883554750762414e-05\n",
      "Epoch 3960, Loss: 0.00013066003145922878, Final Batch Loss: 7.082361435095663e-07\n",
      "Epoch 3961, Loss: 0.0006496813221019693, Final Batch Loss: 9.53340349951759e-06\n",
      "Epoch 3962, Loss: 0.00013251204836706165, Final Batch Loss: 6.662397208856419e-05\n",
      "Epoch 3963, Loss: 0.00020677038446592633, Final Batch Loss: 3.487479261821136e-05\n",
      "Epoch 3964, Loss: 0.0007411738806695212, Final Batch Loss: 0.00034615659387782216\n",
      "Epoch 3965, Loss: 0.00014576010880773538, Final Batch Loss: 2.4565438252466265e-06\n",
      "Epoch 3966, Loss: 0.00030401844560401514, Final Batch Loss: 0.00012308292207308114\n",
      "Epoch 3967, Loss: 9.046434161064099e-05, Final Batch Loss: 1.015418820315972e-05\n",
      "Epoch 3968, Loss: 0.00012842340402130503, Final Batch Loss: 2.4743419999140315e-05\n",
      "Epoch 3969, Loss: 6.209642697285744e-05, Final Batch Loss: 4.588152023643488e-06\n",
      "Epoch 3970, Loss: 0.00015477750275749713, Final Batch Loss: 7.521018414990976e-05\n",
      "Epoch 3971, Loss: 6.0981968772466644e-05, Final Batch Loss: 2.076028431474697e-05\n",
      "Epoch 3972, Loss: 0.00017901876344694756, Final Batch Loss: 7.770882803015411e-06\n",
      "Epoch 3973, Loss: 0.00011420667578931898, Final Batch Loss: 1.573064764670562e-05\n",
      "Epoch 3974, Loss: 0.00011601049482123926, Final Batch Loss: 1.5890200302237645e-05\n",
      "Epoch 3975, Loss: 0.0007614377354911994, Final Batch Loss: 2.8873615519842133e-05\n",
      "Epoch 3976, Loss: 0.000217852444620803, Final Batch Loss: 1.879213232314214e-05\n",
      "Epoch 3977, Loss: 0.00032509837137695285, Final Batch Loss: 5.148996478965273e-06\n",
      "Epoch 3978, Loss: 8.063297286753368e-05, Final Batch Loss: 1.608133288755198e-06\n",
      "Epoch 3979, Loss: 0.0002443082084937487, Final Batch Loss: 9.853074880084023e-05\n",
      "Epoch 3980, Loss: 0.0017783364005481417, Final Batch Loss: 0.0017139242263510823\n",
      "Epoch 3981, Loss: 7.463718793587759e-05, Final Batch Loss: 1.0752028174465522e-06\n",
      "Epoch 3982, Loss: 0.0006178965813887771, Final Batch Loss: 0.0002687320520635694\n",
      "Epoch 3983, Loss: 5.032324656895071e-05, Final Batch Loss: 1.689921873548883e-06\n",
      "Epoch 3984, Loss: 0.0002694371869438328, Final Batch Loss: 0.00018285754777025431\n",
      "Epoch 3985, Loss: 0.0007031297845969675, Final Batch Loss: 2.0435740225366317e-05\n",
      "Epoch 3986, Loss: 0.00028489134547271533, Final Batch Loss: 1.430499651178252e-06\n",
      "Epoch 3987, Loss: 0.0028759775741491467, Final Batch Loss: 0.00031787194893695414\n",
      "Epoch 3988, Loss: 7.539613397966605e-05, Final Batch Loss: 5.140173016116023e-05\n",
      "Epoch 3989, Loss: 0.00028146730983280577, Final Batch Loss: 0.0001261556171812117\n",
      "Epoch 3990, Loss: 0.00015196299250419543, Final Batch Loss: 4.153254849370569e-06\n",
      "Epoch 3991, Loss: 0.009939936726368614, Final Batch Loss: 9.790013791644014e-06\n",
      "Epoch 3992, Loss: 6.340248364722356e-05, Final Batch Loss: 1.3436167137115262e-05\n",
      "Epoch 3993, Loss: 3.913288969670248e-05, Final Batch Loss: 3.1881811537459726e-06\n",
      "Epoch 3994, Loss: 0.00037991513818269596, Final Batch Loss: 0.0001359692105324939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3995, Loss: 0.00022513984936267661, Final Batch Loss: 1.3720452898269286e-06\n",
      "Epoch 3996, Loss: 2.6913246813364822e-05, Final Batch Loss: 8.414697845182673e-07\n",
      "Epoch 3997, Loss: 0.00010831304780367645, Final Batch Loss: 3.2629263841954526e-06\n",
      "Epoch 3998, Loss: 0.00012112715916146044, Final Batch Loss: 6.988865948187595e-07\n",
      "Epoch 3999, Loss: 0.00036691646442932324, Final Batch Loss: 7.736808242952975e-07\n",
      "Epoch 4000, Loss: 0.0001448812963644741, Final Batch Loss: 7.244096195790917e-05\n",
      "Epoch 4001, Loss: 0.00032698512495699106, Final Batch Loss: 1.107322077587014e-05\n",
      "Epoch 4002, Loss: 0.00013872179204099666, Final Batch Loss: 7.035663429633132e-07\n",
      "Epoch 4003, Loss: 0.00018300860210729297, Final Batch Loss: 1.4804970305704046e-05\n",
      "Epoch 4004, Loss: 0.00023469957886845805, Final Batch Loss: 7.904560334281996e-06\n",
      "Epoch 4005, Loss: 0.0001517218750919369, Final Batch Loss: 1.1687175316410503e-07\n",
      "Epoch 4006, Loss: 0.002397275647240349, Final Batch Loss: 4.183976898275432e-07\n",
      "Epoch 4007, Loss: 0.00035293576183903497, Final Batch Loss: 1.3394294001045637e-05\n",
      "Epoch 4008, Loss: 0.00010249033857689938, Final Batch Loss: 1.8395157894701697e-06\n",
      "Epoch 4009, Loss: 0.00076681025666403, Final Batch Loss: 5.230842816672521e-06\n",
      "Epoch 4010, Loss: 0.00032280488858305034, Final Batch Loss: 6.446196039178176e-06\n",
      "Epoch 4011, Loss: 9.394263543072157e-05, Final Batch Loss: 1.0095460311276838e-05\n",
      "Epoch 4012, Loss: 0.00021662794176791067, Final Batch Loss: 1.0775464716061833e-06\n",
      "Epoch 4013, Loss: 0.0001038620288227321, Final Batch Loss: 1.0144343605134054e-06\n",
      "Epoch 4014, Loss: 6.780415503726545e-05, Final Batch Loss: 5.633163482343662e-07\n",
      "Epoch 4015, Loss: 0.00016469401089125313, Final Batch Loss: 2.2914737201062962e-05\n",
      "Epoch 4016, Loss: 3.3757800338207744e-05, Final Batch Loss: 2.384121216891799e-06\n",
      "Epoch 4017, Loss: 0.0022514947589797885, Final Batch Loss: 6.872027142890147e-07\n",
      "Epoch 4018, Loss: 2.7426443239164655e-05, Final Batch Loss: 2.288284349560854e-06\n",
      "Epoch 4019, Loss: 2.6923504265141673e-05, Final Batch Loss: 1.3303100786288269e-05\n",
      "Epoch 4020, Loss: 0.002366528125548939, Final Batch Loss: 1.3599126759800129e-05\n",
      "Epoch 4021, Loss: 1.1485601191907335e-05, Final Batch Loss: 6.077286229810852e-07\n",
      "Epoch 4022, Loss: 0.0001233588973263977, Final Batch Loss: 2.765187127806712e-05\n",
      "Epoch 4023, Loss: 8.394830683755572e-05, Final Batch Loss: 4.520180937106488e-06\n",
      "Epoch 4024, Loss: 0.0015677871997468174, Final Batch Loss: 0.0013838429003953934\n",
      "Epoch 4025, Loss: 0.0002004062755815994, Final Batch Loss: 1.4959576333239966e-07\n",
      "Epoch 4026, Loss: 0.0006176352708280319, Final Batch Loss: 1.0940155334537849e-05\n",
      "Epoch 4027, Loss: 0.00014625201038143132, Final Batch Loss: 1.654708648857195e-05\n",
      "Epoch 4028, Loss: 4.587758439811296e-05, Final Batch Loss: 2.7221429263590835e-05\n",
      "Epoch 4029, Loss: 6.418607472369331e-05, Final Batch Loss: 5.926941412326414e-06\n",
      "Epoch 4030, Loss: 0.0003187285711021559, Final Batch Loss: 3.249024587148597e-07\n",
      "Epoch 4031, Loss: 0.002083324896375416, Final Batch Loss: 3.220918370061554e-05\n",
      "Epoch 4032, Loss: 0.005723699480313371, Final Batch Loss: 4.1929692997655366e-06\n",
      "Epoch 4033, Loss: 7.58709859951523e-05, Final Batch Loss: 5.189079388401296e-07\n",
      "Epoch 4034, Loss: 9.153294513453147e-05, Final Batch Loss: 2.0591755856003147e-06\n",
      "Epoch 4035, Loss: 7.98286037024809e-05, Final Batch Loss: 1.1179286957485601e-05\n",
      "Epoch 4036, Loss: 0.00011293496436337591, Final Batch Loss: 5.055879591964185e-05\n",
      "Epoch 4037, Loss: 0.00010102042188009364, Final Batch Loss: 4.658174020732986e-06\n",
      "Epoch 4038, Loss: 0.0004179927163932007, Final Batch Loss: 0.00035006305552087724\n",
      "Epoch 4039, Loss: 0.0001793641276890412, Final Batch Loss: 3.2851789001142606e-05\n",
      "Epoch 4040, Loss: 0.0004651493665051021, Final Batch Loss: 9.863880450211582e-07\n",
      "Epoch 4041, Loss: 0.0024331806971531478, Final Batch Loss: 7.4622266765800305e-06\n",
      "Epoch 4042, Loss: 3.9334817529379507e-05, Final Batch Loss: 3.765438350455952e-06\n",
      "Epoch 4043, Loss: 2.900209909739715e-05, Final Batch Loss: 8.227700050156272e-07\n",
      "Epoch 4044, Loss: 0.00015684983372921124, Final Batch Loss: 0.00011966353486059234\n",
      "Epoch 4045, Loss: 0.000115700408059638, Final Batch Loss: 8.413357136305422e-06\n",
      "Epoch 4046, Loss: 0.000808692701639302, Final Batch Loss: 3.608681026889826e-06\n",
      "Epoch 4047, Loss: 0.00010901271707552951, Final Batch Loss: 3.303198900539428e-05\n",
      "Epoch 4048, Loss: 0.00030583694206143264, Final Batch Loss: 3.35177492161165e-06\n",
      "Epoch 4049, Loss: 7.960425955388928e-05, Final Batch Loss: 8.53464280226035e-06\n",
      "Epoch 4050, Loss: 2.8379653713273e-05, Final Batch Loss: 2.837489091689349e-06\n",
      "Epoch 4051, Loss: 0.00011914365006759908, Final Batch Loss: 6.100641485318192e-07\n",
      "Epoch 4052, Loss: 6.777845828764839e-05, Final Batch Loss: 3.5340153772267513e-06\n",
      "Epoch 4053, Loss: 0.000390686886248659, Final Batch Loss: 3.4218830933241406e-06\n",
      "Epoch 4054, Loss: 7.859021206968464e-05, Final Batch Loss: 2.240916364826262e-05\n",
      "Epoch 4055, Loss: 0.00026189724303549156, Final Batch Loss: 3.8820289773866534e-05\n",
      "Epoch 4056, Loss: 0.0010485837992746383, Final Batch Loss: 7.286324398592114e-05\n",
      "Epoch 4057, Loss: 0.000251871479122201, Final Batch Loss: 5.0450315029593185e-05\n",
      "Epoch 4058, Loss: 5.6746993465139894e-05, Final Batch Loss: 3.693131986892695e-07\n",
      "Epoch 4059, Loss: 0.004411581318663593, Final Batch Loss: 1.2294710813876009e-06\n",
      "Epoch 4060, Loss: 0.00014512251618725713, Final Batch Loss: 0.00010959736391669139\n",
      "Epoch 4061, Loss: 0.0002541528758683853, Final Batch Loss: 1.353339257548214e-06\n",
      "Epoch 4062, Loss: 0.0031897564156793123, Final Batch Loss: 4.604724495038681e-07\n",
      "Epoch 4063, Loss: 1.4026802432454133e-05, Final Batch Loss: 1.6759198615545756e-06\n",
      "Epoch 4064, Loss: 0.00021888131232117303, Final Batch Loss: 4.840552719542757e-06\n",
      "Epoch 4065, Loss: 0.00020191118164802901, Final Batch Loss: 1.9884791981894523e-05\n",
      "Epoch 4066, Loss: 1.031245369631506e-05, Final Batch Loss: 1.250514515049872e-06\n",
      "Epoch 4067, Loss: 2.1133057202860073e-05, Final Batch Loss: 1.729668042571575e-06\n",
      "Epoch 4068, Loss: 5.547205500988639e-05, Final Batch Loss: 7.119417659851024e-06\n",
      "Epoch 4069, Loss: 3.73487510501036e-05, Final Batch Loss: 3.9034881638144725e-07\n",
      "Epoch 4070, Loss: 0.007592596502718152, Final Batch Loss: 3.131932999167475e-06\n",
      "Epoch 4071, Loss: 0.00010130475493497215, Final Batch Loss: 7.986340642673895e-05\n",
      "Epoch 4072, Loss: 8.708552877578768e-05, Final Batch Loss: 5.734825390391052e-05\n",
      "Epoch 4073, Loss: 0.00011806813654402504, Final Batch Loss: 9.483966096013319e-06\n",
      "Epoch 4074, Loss: 0.00020425246015065568, Final Batch Loss: 8.297838007820246e-07\n",
      "Epoch 4075, Loss: 2.9600116477013216e-05, Final Batch Loss: 1.4468544122792082e-06\n",
      "Epoch 4076, Loss: 0.00024683556591753586, Final Batch Loss: 8.414707508563879e-07\n",
      "Epoch 4077, Loss: 0.00016641760976199294, Final Batch Loss: 1.700465327303391e-05\n",
      "Epoch 4078, Loss: 8.581799556850456e-05, Final Batch Loss: 2.9355293008848093e-05\n",
      "Epoch 4079, Loss: 8.409406041209877e-05, Final Batch Loss: 3.784118007388315e-06\n",
      "Epoch 4080, Loss: 0.00023648405010590068, Final Batch Loss: 1.397744995301764e-06\n",
      "Epoch 4081, Loss: 0.00023306841467274353, Final Batch Loss: 5.017290823161602e-05\n",
      "Epoch 4082, Loss: 0.00018138458108296618, Final Batch Loss: 1.6536017938051373e-05\n",
      "Epoch 4083, Loss: 3.2433247525887055e-05, Final Batch Loss: 1.799819813186332e-07\n",
      "Epoch 4084, Loss: 9.271082700301747e-05, Final Batch Loss: 1.869949350918887e-08\n",
      "Epoch 4085, Loss: 0.0001782150947633454, Final Batch Loss: 4.487855562729237e-07\n",
      "Epoch 4086, Loss: 5.5135747061285656e-05, Final Batch Loss: 1.9075529053225182e-05\n",
      "Epoch 4087, Loss: 8.33391266326089e-05, Final Batch Loss: 1.9634424575087905e-07\n",
      "Epoch 4088, Loss: 7.362966471191612e-05, Final Batch Loss: 2.477677298884373e-07\n",
      "Epoch 4089, Loss: 0.00012564753524202388, Final Batch Loss: 2.1213416403043084e-05\n",
      "Epoch 4090, Loss: 0.00017262891014979687, Final Batch Loss: 1.706672446744051e-05\n",
      "Epoch 4091, Loss: 0.0002131559444933373, Final Batch Loss: 0.00020013973698951304\n",
      "Epoch 4092, Loss: 0.00021108675559844414, Final Batch Loss: 3.0456087642960483e-06\n",
      "Epoch 4093, Loss: 5.8906247431878e-05, Final Batch Loss: 8.969700502348132e-06\n",
      "Epoch 4094, Loss: 0.002985147022940282, Final Batch Loss: 3.342523484661797e-07\n",
      "Epoch 4095, Loss: 0.0009645042100601131, Final Batch Loss: 3.118757012998685e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4096, Loss: 0.0091770469371113, Final Batch Loss: 0.009062360040843487\n",
      "Epoch 4097, Loss: 3.0506637088478783e-05, Final Batch Loss: 1.425834881274568e-07\n",
      "Epoch 4098, Loss: 5.530636099138064e-05, Final Batch Loss: 2.4699535060790367e-05\n",
      "Epoch 4099, Loss: 0.0004577366030389385, Final Batch Loss: 4.034261564811459e-06\n",
      "Epoch 4100, Loss: 0.00029943307708890643, Final Batch Loss: 2.591449265310075e-05\n",
      "Epoch 4101, Loss: 0.0002215399082388103, Final Batch Loss: 1.535653723294672e-06\n",
      "Epoch 4102, Loss: 0.00010261407894773811, Final Batch Loss: 6.077332415088676e-08\n",
      "Epoch 4103, Loss: 6.905574264237657e-05, Final Batch Loss: 4.8326546675525606e-05\n",
      "Epoch 4104, Loss: 0.00012709389754661515, Final Batch Loss: 2.197186148578112e-07\n",
      "Epoch 4105, Loss: 3.182206444307667e-05, Final Batch Loss: 3.365902330187964e-07\n",
      "Epoch 4106, Loss: 0.00013215181297709933, Final Batch Loss: 9.964663149730768e-06\n",
      "Epoch 4107, Loss: 0.00012853813723268104, Final Batch Loss: 5.247028457233682e-05\n",
      "Epoch 4108, Loss: 0.0003281626014484118, Final Batch Loss: 3.1789031140760926e-07\n",
      "Epoch 4109, Loss: 0.0001803176774046733, Final Batch Loss: 1.0018134162237402e-05\n",
      "Epoch 4110, Loss: 0.00019772169119747218, Final Batch Loss: 3.2724106091563954e-08\n",
      "Epoch 4111, Loss: 5.5861918895061535e-05, Final Batch Loss: 9.513263421467855e-07\n",
      "Epoch 4112, Loss: 4.90113264959291e-05, Final Batch Loss: 8.812043006400927e-07\n",
      "Epoch 4113, Loss: 1.941827758855652e-05, Final Batch Loss: 6.754620244464604e-06\n",
      "Epoch 4114, Loss: 7.235985934883615e-05, Final Batch Loss: 4.6748699134013805e-08\n",
      "Epoch 4115, Loss: 7.508880246831495e-05, Final Batch Loss: 8.882255286835061e-08\n",
      "Epoch 4116, Loss: 0.00022459177216660464, Final Batch Loss: 3.992100573668722e-06\n",
      "Epoch 4117, Loss: 0.00012763141717186954, Final Batch Loss: 3.001182676598546e-06\n",
      "Epoch 4118, Loss: 2.3170378085524135e-05, Final Batch Loss: 1.6481997590744868e-05\n",
      "Epoch 4119, Loss: 0.00023548333365397411, Final Batch Loss: 1.876876467576949e-06\n",
      "Epoch 4120, Loss: 0.0002567743060239991, Final Batch Loss: 5.796820801151625e-07\n",
      "Epoch 4121, Loss: 6.683917445116094e-05, Final Batch Loss: 2.0919283088005614e-06\n",
      "Epoch 4122, Loss: 1.9206444676456158e-05, Final Batch Loss: 3.03376987176307e-06\n",
      "Epoch 4123, Loss: 0.003942458886740496, Final Batch Loss: 1.4047718650544994e-06\n",
      "Epoch 4124, Loss: 7.66386656891882e-05, Final Batch Loss: 4.043732246827858e-07\n",
      "Epoch 4125, Loss: 0.00014222235722627374, Final Batch Loss: 3.1086051421880256e-06\n",
      "Epoch 4126, Loss: 0.0001322455940311329, Final Batch Loss: 1.566080385373425e-07\n",
      "Epoch 4127, Loss: 8.295275108594069e-05, Final Batch Loss: 1.0565123602646054e-06\n",
      "Epoch 4128, Loss: 5.6633979966136394e-05, Final Batch Loss: 3.5737352845899295e-06\n",
      "Epoch 4129, Loss: 1.0688098996070039e-05, Final Batch Loss: 4.310048552724766e-06\n",
      "Epoch 4130, Loss: 3.3406710826966446e-05, Final Batch Loss: 1.0574112820904702e-05\n",
      "Epoch 4131, Loss: 5.197263135414687e-05, Final Batch Loss: 1.893250100692967e-06\n",
      "Epoch 4132, Loss: 1.4889595831846236e-05, Final Batch Loss: 2.0148183921264717e-06\n",
      "Epoch 4133, Loss: 8.232090465298825e-05, Final Batch Loss: 5.446171371659148e-07\n",
      "Epoch 4134, Loss: 0.000337932873662794, Final Batch Loss: 7.116299821063876e-05\n",
      "Epoch 4135, Loss: 7.46194677958556e-05, Final Batch Loss: 4.627776888810331e-06\n",
      "Epoch 4136, Loss: 3.963218705393956e-05, Final Batch Loss: 1.7179750102513935e-06\n",
      "Epoch 4137, Loss: 5.7586090463246364e-05, Final Batch Loss: 6.544820507770055e-08\n",
      "Epoch 4138, Loss: 5.268302447802853e-05, Final Batch Loss: 8.20801687950734e-06\n",
      "Epoch 4139, Loss: 0.0002516644972274662, Final Batch Loss: 3.0736346161575057e-06\n",
      "Epoch 4140, Loss: 6.721721638314193e-05, Final Batch Loss: 6.12405074207345e-07\n",
      "Epoch 4141, Loss: 0.00012601730736605532, Final Batch Loss: 2.220556325482903e-07\n",
      "Epoch 4142, Loss: 0.00012402989341353532, Final Batch Loss: 7.709904457442462e-05\n",
      "Epoch 4143, Loss: 3.623243514994101e-05, Final Batch Loss: 2.409402259218041e-05\n",
      "Epoch 4144, Loss: 4.166214571910132e-05, Final Batch Loss: 3.2490325452272373e-07\n",
      "Epoch 4145, Loss: 5.1427869948383886e-05, Final Batch Loss: 2.786042841762537e-06\n",
      "Epoch 4146, Loss: 0.005772221532424737, Final Batch Loss: 8.909400094125886e-06\n",
      "Epoch 4147, Loss: 0.00016411676551797427, Final Batch Loss: 6.0119789850432426e-05\n",
      "Epoch 4148, Loss: 0.00025707666736707324, Final Batch Loss: 1.0870106962102e-05\n",
      "Epoch 4149, Loss: 0.0003339276336191688, Final Batch Loss: 0.00024730051518417895\n",
      "Epoch 4150, Loss: 0.01802087418627707, Final Batch Loss: 5.410880930867279e-06\n",
      "Epoch 4151, Loss: 0.0005810853326693177, Final Batch Loss: 0.0004919437342323363\n",
      "Epoch 4152, Loss: 6.051084437785903e-05, Final Batch Loss: 1.8552476831246167e-05\n",
      "Epoch 4153, Loss: 0.00015361204123109928, Final Batch Loss: 5.375797172746388e-06\n",
      "Epoch 4154, Loss: 7.601084126918067e-05, Final Batch Loss: 8.508139330842823e-07\n",
      "Epoch 4155, Loss: 0.00010856567223527236, Final Batch Loss: 4.778588845510967e-05\n",
      "Epoch 4156, Loss: 0.0001615454129932914, Final Batch Loss: 9.724448318593204e-06\n",
      "Epoch 4157, Loss: 0.002188621339655583, Final Batch Loss: 3.5013542856177082e-06\n",
      "Epoch 4158, Loss: 0.0063030515193531755, Final Batch Loss: 0.00010320847650291398\n",
      "Epoch 4159, Loss: 0.0020958922959835036, Final Batch Loss: 2.2501613784697838e-05\n",
      "Epoch 4160, Loss: 0.0002283444125623646, Final Batch Loss: 1.9060345948673785e-05\n",
      "Epoch 4161, Loss: 0.0004796165994775947, Final Batch Loss: 0.0003940293681807816\n",
      "Epoch 4162, Loss: 0.004225568882247899, Final Batch Loss: 3.5302691685501486e-05\n",
      "Epoch 4163, Loss: 0.004385194151836913, Final Batch Loss: 7.479684427380562e-07\n",
      "Epoch 4164, Loss: 6.494855915661901e-05, Final Batch Loss: 1.0724791536631528e-05\n",
      "Epoch 4165, Loss: 2.609336615932989e-05, Final Batch Loss: 2.2204940250958316e-06\n",
      "Epoch 4166, Loss: 0.00033454417462053243, Final Batch Loss: 0.00026765273651108146\n",
      "Epoch 4167, Loss: 0.00043539204693843203, Final Batch Loss: 2.7206808681512484e-06\n",
      "Epoch 4168, Loss: 7.659991206310224e-05, Final Batch Loss: 1.1778138286899775e-05\n",
      "Epoch 4169, Loss: 0.0003880751792166848, Final Batch Loss: 0.00017499543901067227\n",
      "Epoch 4170, Loss: 0.0007636670053443595, Final Batch Loss: 4.5579884044855135e-07\n",
      "Epoch 4171, Loss: 4.231533307574864e-05, Final Batch Loss: 3.0361600238393294e-06\n",
      "Epoch 4172, Loss: 3.6864068988506915e-05, Final Batch Loss: 5.88076500207535e-06\n",
      "Epoch 4173, Loss: 0.00020535992143777548, Final Batch Loss: 2.164358647860354e-06\n",
      "Epoch 4174, Loss: 2.6677860660129227e-05, Final Batch Loss: 7.5419443419377785e-06\n",
      "Epoch 4175, Loss: 0.00044389993308868725, Final Batch Loss: 1.2329743185546249e-05\n",
      "Epoch 4176, Loss: 7.818382619007025e-05, Final Batch Loss: 1.059666283254046e-05\n",
      "Epoch 4177, Loss: 3.6685663644675515e-05, Final Batch Loss: 3.181165766363847e-06\n",
      "Epoch 4178, Loss: 0.00018678118340176297, Final Batch Loss: 1.2625775525521021e-05\n",
      "Epoch 4179, Loss: 0.006280237059399951, Final Batch Loss: 6.323344859993085e-05\n",
      "Epoch 4180, Loss: 0.0005711377980333054, Final Batch Loss: 1.5396917660837062e-05\n",
      "Epoch 4181, Loss: 0.0013719835951633286, Final Batch Loss: 0.0012079712469130754\n",
      "Epoch 4182, Loss: 0.00025826383716776036, Final Batch Loss: 4.77992398373317e-05\n",
      "Epoch 4183, Loss: 0.003032062788975054, Final Batch Loss: 1.2177866892670863e-06\n",
      "Epoch 4184, Loss: 1.9364072272765043e-05, Final Batch Loss: 3.8801283608336234e-07\n",
      "Epoch 4185, Loss: 0.0005327290150489716, Final Batch Loss: 5.957730991212884e-06\n",
      "Epoch 4186, Loss: 0.0016177375709958142, Final Batch Loss: 5.840947778779082e-06\n",
      "Epoch 4187, Loss: 0.0003158303406962659, Final Batch Loss: 2.8772254154318944e-05\n",
      "Epoch 4188, Loss: 5.6526651860622223e-05, Final Batch Loss: 4.097443706996273e-06\n",
      "Epoch 4189, Loss: 9.337678466181387e-05, Final Batch Loss: 1.3510039025277365e-06\n",
      "Epoch 4190, Loss: 0.00014740914832600538, Final Batch Loss: 1.6431664562333026e-06\n",
      "Epoch 4191, Loss: 9.007086373458151e-05, Final Batch Loss: 4.8422203690279275e-05\n",
      "Epoch 4192, Loss: 5.386042666088997e-05, Final Batch Loss: 8.64851159576574e-08\n",
      "Epoch 4193, Loss: 0.00028442992970667547, Final Batch Loss: 2.818799657688942e-06\n",
      "Epoch 4194, Loss: 0.0001230654579558177, Final Batch Loss: 1.5427236576215364e-05\n",
      "Epoch 4195, Loss: 0.0003753264209080953, Final Batch Loss: 0.00027090348885394633\n",
      "Epoch 4196, Loss: 0.00011437614375608973, Final Batch Loss: 2.332858093723189e-05\n",
      "Epoch 4197, Loss: 0.00019211804828955792, Final Batch Loss: 7.96365347923711e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4198, Loss: 0.0004662443843699293, Final Batch Loss: 0.0003308284212835133\n",
      "Epoch 4199, Loss: 0.00015647994632672635, Final Batch Loss: 5.095106189401122e-06\n",
      "Epoch 4200, Loss: 6.902590575919021e-05, Final Batch Loss: 3.974635183112696e-05\n",
      "Epoch 4201, Loss: 0.0003570118756215379, Final Batch Loss: 6.685045264021028e-07\n",
      "Epoch 4202, Loss: 0.0010568592388153775, Final Batch Loss: 2.2919453840586357e-05\n",
      "Epoch 4203, Loss: 0.0015759095051635086, Final Batch Loss: 3.7045876979391323e-06\n",
      "Epoch 4204, Loss: 0.00010927836592600215, Final Batch Loss: 6.502463293145411e-06\n",
      "Epoch 4205, Loss: 9.07537204284381e-05, Final Batch Loss: 1.5917820519462111e-06\n",
      "Epoch 4206, Loss: 8.684643830747518e-05, Final Batch Loss: 2.9217858354968484e-07\n",
      "Epoch 4207, Loss: 7.899850697867805e-05, Final Batch Loss: 2.0591078282450326e-05\n",
      "Epoch 4208, Loss: 0.0004607101909641642, Final Batch Loss: 0.0003879998403135687\n",
      "Epoch 4209, Loss: 0.00025502286553091835, Final Batch Loss: 0.00020104301802348346\n",
      "Epoch 4210, Loss: 3.0098041861492675e-05, Final Batch Loss: 1.4676917089673225e-05\n",
      "Epoch 4211, Loss: 0.024682320885403897, Final Batch Loss: 1.2925793271278962e-06\n",
      "Epoch 4212, Loss: 0.005955434942734428, Final Batch Loss: 0.005852658301591873\n",
      "Epoch 4213, Loss: 2.925206717918627e-05, Final Batch Loss: 4.099648322153371e-06\n",
      "Epoch 4214, Loss: 6.849358624094748e-05, Final Batch Loss: 6.9177717705315445e-06\n",
      "Epoch 4215, Loss: 0.007149707313146791, Final Batch Loss: 0.006962490268051624\n",
      "Epoch 4216, Loss: 0.025708752607442875, Final Batch Loss: 5.752186098106904e-06\n",
      "Epoch 4217, Loss: 0.002684271334146615, Final Batch Loss: 0.002507565077394247\n",
      "Epoch 4218, Loss: 0.0005531332462851424, Final Batch Loss: 4.9860227591125295e-05\n",
      "Epoch 4219, Loss: 0.00018305741275526088, Final Batch Loss: 1.6595530496488209e-06\n",
      "Epoch 4220, Loss: 0.00018433362856740132, Final Batch Loss: 3.8384761865017936e-05\n",
      "Epoch 4221, Loss: 5.39033219411067e-05, Final Batch Loss: 2.314056928298669e-07\n",
      "Epoch 4222, Loss: 0.00043270930109429173, Final Batch Loss: 4.099802390555851e-05\n",
      "Epoch 4223, Loss: 0.0071421584725612774, Final Batch Loss: 0.000561641005333513\n",
      "Epoch 4224, Loss: 0.0002538373082643375, Final Batch Loss: 0.00018716082558967173\n",
      "Epoch 4225, Loss: 0.00018678108244785108, Final Batch Loss: 0.0001157726437668316\n",
      "Epoch 4226, Loss: 6.843840446890681e-05, Final Batch Loss: 1.1757106221921276e-06\n",
      "Epoch 4227, Loss: 0.00013886597844248172, Final Batch Loss: 3.433193342061713e-05\n",
      "Epoch 4228, Loss: 0.0024197302018365008, Final Batch Loss: 0.0021329852752387524\n",
      "Epoch 4229, Loss: 9.818844591791276e-05, Final Batch Loss: 2.209057674917858e-05\n",
      "Epoch 4230, Loss: 0.0009942087240233377, Final Batch Loss: 5.025086011301028e-06\n",
      "Epoch 4231, Loss: 0.0006169337593746604, Final Batch Loss: 3.7444788176799193e-06\n",
      "Epoch 4232, Loss: 7.05631800883566e-05, Final Batch Loss: 7.009614819253329e-06\n",
      "Epoch 4233, Loss: 0.00016722476721042767, Final Batch Loss: 3.3440013794461265e-05\n",
      "Epoch 4234, Loss: 0.0008438306285825092, Final Batch Loss: 1.1954987712670118e-05\n",
      "Epoch 4235, Loss: 0.0002623166292323731, Final Batch Loss: 4.139911106904037e-05\n",
      "Epoch 4236, Loss: 0.00011935552129216376, Final Batch Loss: 6.480805950559443e-06\n",
      "Epoch 4237, Loss: 0.0001819142489694059, Final Batch Loss: 4.4619664549827576e-05\n",
      "Epoch 4238, Loss: 0.00866470087566995, Final Batch Loss: 3.0083176170592196e-05\n",
      "Epoch 4239, Loss: 0.00015834593068575487, Final Batch Loss: 1.6398495063185692e-05\n",
      "Epoch 4240, Loss: 0.00010576605563983321, Final Batch Loss: 3.293543340987526e-05\n",
      "Epoch 4241, Loss: 0.0006340257641568314, Final Batch Loss: 6.8803019530605525e-06\n",
      "Epoch 4242, Loss: 0.0031097204773686826, Final Batch Loss: 9.095721179619431e-05\n",
      "Epoch 4243, Loss: 0.00010690748217712098, Final Batch Loss: 2.1807788925798377e-06\n",
      "Epoch 4244, Loss: 6.789628878323128e-05, Final Batch Loss: 9.873569069895893e-06\n",
      "Epoch 4245, Loss: 0.0001778617297532037, Final Batch Loss: 2.513671643100679e-05\n",
      "Epoch 4246, Loss: 0.001347288620308973, Final Batch Loss: 6.341123662423342e-05\n",
      "Epoch 4247, Loss: 0.00018042583360511344, Final Batch Loss: 2.8909596949233674e-05\n",
      "Epoch 4248, Loss: 0.0005864275399289909, Final Batch Loss: 1.0161656064155977e-05\n",
      "Epoch 4249, Loss: 1.7266355143874534e-05, Final Batch Loss: 2.1597199975076364e-06\n",
      "Epoch 4250, Loss: 5.7985590956377564e-05, Final Batch Loss: 1.5940760931698605e-05\n",
      "Epoch 4251, Loss: 0.00014023574112798087, Final Batch Loss: 7.074555469444022e-06\n",
      "Epoch 4252, Loss: 2.531972631913959e-05, Final Batch Loss: 7.44422550269519e-06\n",
      "Epoch 4253, Loss: 0.00031783957024345, Final Batch Loss: 3.477932523310301e-06\n",
      "Epoch 4254, Loss: 3.415039827814326e-05, Final Batch Loss: 5.803599833598128e-06\n",
      "Epoch 4255, Loss: 8.31125062177307e-05, Final Batch Loss: 4.764374534715898e-05\n",
      "Epoch 4256, Loss: 0.01699899463164911, Final Batch Loss: 0.01537005789577961\n",
      "Epoch 4257, Loss: 0.00015547061173037946, Final Batch Loss: 1.4749078900422319e-06\n",
      "Epoch 4258, Loss: 4.747136790683726e-05, Final Batch Loss: 7.360044946835842e-06\n",
      "Epoch 4259, Loss: 0.00046597624896094203, Final Batch Loss: 5.3420764743350446e-05\n",
      "Epoch 4260, Loss: 0.0012937569075575084, Final Batch Loss: 1.736663193696586e-06\n",
      "Epoch 4261, Loss: 0.00013416076308203628, Final Batch Loss: 8.911656186683103e-05\n",
      "Epoch 4262, Loss: 6.621263855777215e-05, Final Batch Loss: 2.5496685339021496e-05\n",
      "Epoch 4263, Loss: 0.00011163559247506782, Final Batch Loss: 1.8821974663296714e-05\n",
      "Epoch 4264, Loss: 1.3499488773049961e-05, Final Batch Loss: 1.6057978200478829e-06\n",
      "Epoch 4265, Loss: 0.0010433220727463777, Final Batch Loss: 3.900828687619651e-06\n",
      "Epoch 4266, Loss: 0.0002515893502277322, Final Batch Loss: 0.00011045029532397166\n",
      "Epoch 4267, Loss: 0.00010129765723831952, Final Batch Loss: 4.022302891826257e-05\n",
      "Epoch 4268, Loss: 0.0001184809716505697, Final Batch Loss: 7.731328878435306e-06\n",
      "Epoch 4269, Loss: 0.00038588132156291977, Final Batch Loss: 0.00013549979485105723\n",
      "Epoch 4270, Loss: 0.0001602285228727851, Final Batch Loss: 9.972225234378129e-05\n",
      "Epoch 4271, Loss: 0.0001235337640537182, Final Batch Loss: 1.5586514564347453e-05\n",
      "Epoch 4272, Loss: 0.001291967570068664, Final Batch Loss: 3.414786988287233e-06\n",
      "Epoch 4273, Loss: 6.38667588646058e-05, Final Batch Loss: 1.657688153500203e-05\n",
      "Epoch 4274, Loss: 5.386451402955572e-05, Final Batch Loss: 3.944334457628429e-05\n",
      "Epoch 4275, Loss: 3.499704803289205e-05, Final Batch Loss: 3.2067230222310172e-06\n",
      "Epoch 4276, Loss: 0.00048749595458730255, Final Batch Loss: 8.064076268965437e-07\n",
      "Epoch 4277, Loss: 0.0003457211460045073, Final Batch Loss: 4.682233338826336e-05\n",
      "Epoch 4278, Loss: 0.00014847439115328598, Final Batch Loss: 7.715265383012593e-05\n",
      "Epoch 4279, Loss: 0.0002249410499644, Final Batch Loss: 1.604539284016937e-05\n",
      "Epoch 4280, Loss: 0.00013058961872047803, Final Batch Loss: 3.1320107609644765e-06\n",
      "Epoch 4281, Loss: 0.0008685159637025208, Final Batch Loss: 0.0005510579794645309\n",
      "Epoch 4282, Loss: 0.0006839871321062674, Final Batch Loss: 7.809020644344855e-06\n",
      "Epoch 4283, Loss: 3.369001842656871e-05, Final Batch Loss: 9.883870916382875e-06\n",
      "Epoch 4284, Loss: 0.0013627775078930426, Final Batch Loss: 0.00010945389658445492\n",
      "Epoch 4285, Loss: 0.0001263059666598565, Final Batch Loss: 9.831126226345077e-05\n",
      "Epoch 4286, Loss: 0.0001725417779283589, Final Batch Loss: 6.778564909382112e-08\n",
      "Epoch 4287, Loss: 0.0003146649676182278, Final Batch Loss: 2.4308671981998486e-06\n",
      "Epoch 4288, Loss: 0.0003403980463190237, Final Batch Loss: 0.0003003586898557842\n",
      "Epoch 4289, Loss: 0.00012849413212734362, Final Batch Loss: 1.6198249568333267e-06\n",
      "Epoch 4290, Loss: 5.11439893671195e-05, Final Batch Loss: 7.271140020748135e-06\n",
      "Epoch 4291, Loss: 0.000388260988984257, Final Batch Loss: 2.8198555810377002e-05\n",
      "Epoch 4292, Loss: 0.00022097004875831772, Final Batch Loss: 2.0173161829006858e-05\n",
      "Epoch 4293, Loss: 8.955144897981882e-05, Final Batch Loss: 3.8100137089713826e-07\n",
      "Epoch 4294, Loss: 0.00013784401267002977, Final Batch Loss: 2.5781071144592715e-06\n",
      "Epoch 4295, Loss: 0.0005500540909224583, Final Batch Loss: 9.653493862060714e-07\n",
      "Epoch 4296, Loss: 0.0006794743670184289, Final Batch Loss: 9.326170697931957e-07\n",
      "Epoch 4297, Loss: 0.0002655668758961838, Final Batch Loss: 1.0491890861885622e-05\n",
      "Epoch 4298, Loss: 7.622687826369656e-05, Final Batch Loss: 1.1148374142067041e-05\n",
      "Epoch 4299, Loss: 0.0013793793696095236, Final Batch Loss: 0.0012541518080979586\n",
      "Epoch 4300, Loss: 0.0007725845753157046, Final Batch Loss: 0.0006612616125494242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4301, Loss: 0.0002191021726503095, Final Batch Loss: 0.00011885856656590477\n",
      "Epoch 4302, Loss: 3.1478647997573717e-05, Final Batch Loss: 3.0456026252068114e-06\n",
      "Epoch 4303, Loss: 0.01198384062581681, Final Batch Loss: 2.1877435756323393e-06\n",
      "Epoch 4304, Loss: 0.0005036957572883694, Final Batch Loss: 0.00028669179300777614\n",
      "Epoch 4305, Loss: 0.03056681522866711, Final Batch Loss: 0.029429886490106583\n",
      "Epoch 4306, Loss: 0.0006304729240582674, Final Batch Loss: 4.962100774719147e-06\n",
      "Epoch 4307, Loss: 0.026741356579805142, Final Batch Loss: 0.002874603495001793\n",
      "Epoch 4308, Loss: 0.03559235064312816, Final Batch Loss: 0.00108683155849576\n",
      "Epoch 4309, Loss: 0.021703956028659377, Final Batch Loss: 5.469539701152826e-07\n",
      "Epoch 4310, Loss: 1.94987171653338e-05, Final Batch Loss: 1.9610808976722183e-06\n",
      "Epoch 4311, Loss: 0.0003209651595170726, Final Batch Loss: 1.2050467375956941e-05\n",
      "Epoch 4312, Loss: 0.4257107563316822, Final Batch Loss: 0.3412860333919525\n",
      "Epoch 4313, Loss: 0.009577338436429272, Final Batch Loss: 1.7914955606102012e-05\n",
      "Epoch 4314, Loss: 0.0021287816525727976, Final Batch Loss: 0.001878770417533815\n",
      "Epoch 4315, Loss: 0.05568253816818469, Final Batch Loss: 0.001903061056509614\n",
      "Epoch 4316, Loss: 0.04188584352959879, Final Batch Loss: 8.292825077660382e-05\n",
      "Epoch 4317, Loss: 0.014045547157365945, Final Batch Loss: 2.3929920644150116e-05\n",
      "Epoch 4318, Loss: 0.00021430423021229217, Final Batch Loss: 8.81760297488654e-06\n",
      "Epoch 4319, Loss: 0.0009197487470373744, Final Batch Loss: 5.531658462132327e-05\n",
      "Epoch 4320, Loss: 0.015544626345217694, Final Batch Loss: 0.01505722850561142\n",
      "Epoch 4321, Loss: 0.0003298853443993721, Final Batch Loss: 7.669219485251233e-05\n",
      "Epoch 4322, Loss: 0.009853465177002363, Final Batch Loss: 7.928464037831873e-05\n",
      "Epoch 4323, Loss: 0.010899957800575066, Final Batch Loss: 0.010671144351363182\n",
      "Epoch 4324, Loss: 0.0008670597380842082, Final Batch Loss: 7.671275670873001e-05\n",
      "Epoch 4325, Loss: 0.0023942291131788807, Final Batch Loss: 6.93951506036683e-06\n",
      "Epoch 4326, Loss: 0.006094529653637437, Final Batch Loss: 0.005777650512754917\n",
      "Epoch 4327, Loss: 0.00026283697661710903, Final Batch Loss: 3.191224095644429e-05\n",
      "Epoch 4328, Loss: 0.016104960929169465, Final Batch Loss: 2.6950278879667167e-06\n",
      "Epoch 4329, Loss: 0.0008063160566962324, Final Batch Loss: 8.742070349399e-05\n",
      "Epoch 4330, Loss: 0.0005620912997983396, Final Batch Loss: 0.00034462916664779186\n",
      "Epoch 4331, Loss: 0.0003705817744048545, Final Batch Loss: 2.2024689315003343e-05\n",
      "Epoch 4332, Loss: 0.031940604792907834, Final Batch Loss: 4.520639777183533e-05\n",
      "Epoch 4333, Loss: 0.01059081029961817, Final Batch Loss: 0.0002594025863800198\n",
      "Epoch 4334, Loss: 0.00030764277471462265, Final Batch Loss: 1.4013682630320545e-05\n",
      "Epoch 4335, Loss: 0.00011917838378394663, Final Batch Loss: 3.8005625810910715e-06\n",
      "Epoch 4336, Loss: 0.00014875186843710253, Final Batch Loss: 3.58090710506076e-06\n",
      "Epoch 4337, Loss: 0.0005841347701789346, Final Batch Loss: 3.65489067917224e-05\n",
      "Epoch 4338, Loss: 0.0005946773599134758, Final Batch Loss: 0.00012024807801935822\n",
      "Epoch 4339, Loss: 0.03523256214793946, Final Batch Loss: 2.2843114493298344e-05\n",
      "Epoch 4340, Loss: 0.000382397936846246, Final Batch Loss: 1.447435533918906e-05\n",
      "Epoch 4341, Loss: 0.00019151808555761818, Final Batch Loss: 2.4407980163232423e-05\n",
      "Epoch 4342, Loss: 0.0009537233272567391, Final Batch Loss: 0.0005847571301274002\n",
      "Epoch 4343, Loss: 0.00013775535262539051, Final Batch Loss: 5.768521077698097e-06\n",
      "Epoch 4344, Loss: 0.0004555097366392147, Final Batch Loss: 0.00015410530613735318\n",
      "Epoch 4345, Loss: 0.00046653834033349995, Final Batch Loss: 1.7053034753189422e-05\n",
      "Epoch 4346, Loss: 8.310810335387941e-05, Final Batch Loss: 3.994688086095266e-05\n",
      "Epoch 4347, Loss: 0.00021222664872766472, Final Batch Loss: 1.8441576685290784e-05\n",
      "Epoch 4348, Loss: 0.004042255259264493, Final Batch Loss: 2.688164749997668e-05\n",
      "Epoch 4349, Loss: 0.00012829937986680306, Final Batch Loss: 5.3436226153280586e-05\n",
      "Epoch 4350, Loss: 0.0006723958231305005, Final Batch Loss: 2.7258933187113144e-05\n",
      "Epoch 4351, Loss: 0.0008767641284066485, Final Batch Loss: 1.9793655155808665e-05\n",
      "Epoch 4352, Loss: 0.0003828600329143228, Final Batch Loss: 5.983582013868727e-06\n",
      "Epoch 4353, Loss: 0.001151017550000688, Final Batch Loss: 8.090799383353442e-05\n",
      "Epoch 4354, Loss: 0.00024132098525342371, Final Batch Loss: 2.080317358377215e-07\n",
      "Epoch 4355, Loss: 0.0010620676475809887, Final Batch Loss: 0.00045025916188023984\n",
      "Epoch 4356, Loss: 0.00026416856053401716, Final Batch Loss: 3.018111237906851e-05\n",
      "Epoch 4357, Loss: 0.0014751809067092836, Final Batch Loss: 0.00047191980411298573\n",
      "Epoch 4358, Loss: 0.0007640366620762506, Final Batch Loss: 2.5909781470545568e-05\n",
      "Epoch 4359, Loss: 0.00038587788731092587, Final Batch Loss: 0.0002994200913235545\n",
      "Epoch 4360, Loss: 0.008589664962528332, Final Batch Loss: 0.008326953276991844\n",
      "Epoch 4361, Loss: 0.00029157571043469943, Final Batch Loss: 0.00016968842828646302\n",
      "Epoch 4362, Loss: 0.0002897342674259562, Final Batch Loss: 2.2648244339507073e-05\n",
      "Epoch 4363, Loss: 0.0017990470951190218, Final Batch Loss: 0.0015772402985021472\n",
      "Epoch 4364, Loss: 0.0005095463866382488, Final Batch Loss: 1.2991179573873524e-05\n",
      "Epoch 4365, Loss: 0.00014629845099989325, Final Batch Loss: 3.615046080085449e-05\n",
      "Epoch 4366, Loss: 0.004367188961623469, Final Batch Loss: 3.318341987323947e-05\n",
      "Epoch 4367, Loss: 0.0016084653252619319, Final Batch Loss: 0.0015076749259606004\n",
      "Epoch 4368, Loss: 0.0005365617571442272, Final Batch Loss: 8.173413334588986e-06\n",
      "Epoch 4369, Loss: 0.0001152899149019504, Final Batch Loss: 3.3712673030095175e-05\n",
      "Epoch 4370, Loss: 0.00031961038621375337, Final Batch Loss: 0.00027271229191683233\n",
      "Epoch 4371, Loss: 0.00016705179223208688, Final Batch Loss: 8.049639291130006e-05\n",
      "Epoch 4372, Loss: 0.00023651085393794347, Final Batch Loss: 0.00012025223986711353\n",
      "Epoch 4373, Loss: 0.0005957765461062081, Final Batch Loss: 0.0003081423055846244\n",
      "Epoch 4374, Loss: 0.00032368243864766555, Final Batch Loss: 1.1235123565711547e-05\n",
      "Epoch 4375, Loss: 0.00029082667015245534, Final Batch Loss: 7.345262474700576e-06\n",
      "Epoch 4376, Loss: 0.00017742647105478682, Final Batch Loss: 2.3809527192497626e-05\n",
      "Epoch 4377, Loss: 0.000555351695538775, Final Batch Loss: 8.858830824465258e-07\n",
      "Epoch 4378, Loss: 7.204335452115629e-05, Final Batch Loss: 7.320431905100122e-06\n",
      "Epoch 4379, Loss: 0.00031427239446202293, Final Batch Loss: 8.367127884412184e-05\n",
      "Epoch 4380, Loss: 0.0002782246765491436, Final Batch Loss: 1.2840587260143366e-05\n",
      "Epoch 4381, Loss: 0.00021290068843882182, Final Batch Loss: 3.4569843592180405e-06\n",
      "Epoch 4382, Loss: 0.00036711706525238696, Final Batch Loss: 2.142357152479235e-05\n",
      "Epoch 4383, Loss: 9.094819233723683e-05, Final Batch Loss: 4.242322575009894e-06\n",
      "Epoch 4384, Loss: 0.0006139667420939077, Final Batch Loss: 2.6985700969817117e-05\n",
      "Epoch 4385, Loss: 0.0003907796362909721, Final Batch Loss: 1.9864879504893906e-05\n",
      "Epoch 4386, Loss: 0.00013110275358485524, Final Batch Loss: 1.568842890264932e-05\n",
      "Epoch 4387, Loss: 0.002058798218058655, Final Batch Loss: 0.0019393217517063022\n",
      "Epoch 4388, Loss: 0.00031042236332723405, Final Batch Loss: 0.0001823151105782017\n",
      "Epoch 4389, Loss: 0.00016918669507504092, Final Batch Loss: 3.982919679401675e-06\n",
      "Epoch 4390, Loss: 0.00011914551947711516, Final Batch Loss: 5.726688527829538e-07\n",
      "Epoch 4391, Loss: 8.528308626409853e-05, Final Batch Loss: 6.084113192628138e-05\n",
      "Epoch 4392, Loss: 0.00013740167787545943, Final Batch Loss: 4.363706921139965e-06\n",
      "Epoch 4393, Loss: 0.0002322111376997782, Final Batch Loss: 2.652943294378929e-06\n",
      "Epoch 4394, Loss: 0.0005024432084610453, Final Batch Loss: 1.0082489097840153e-05\n",
      "Epoch 4395, Loss: 0.000241914754951722, Final Batch Loss: 0.00018488321802578866\n",
      "Epoch 4396, Loss: 0.00016918525489018066, Final Batch Loss: 2.568783202150371e-06\n",
      "Epoch 4397, Loss: 0.0004211531449982431, Final Batch Loss: 0.000143755940371193\n",
      "Epoch 4398, Loss: 0.00014993455988587812, Final Batch Loss: 3.438173735048622e-05\n",
      "Epoch 4399, Loss: 0.002708869826165028, Final Batch Loss: 5.409745062934235e-05\n",
      "Epoch 4400, Loss: 0.00012025600312881579, Final Batch Loss: 1.7226718682650244e-06\n",
      "Epoch 4401, Loss: 0.00020394827879499644, Final Batch Loss: 9.651373693486676e-05\n",
      "Epoch 4402, Loss: 0.00012976434527445235, Final Batch Loss: 8.439248631475493e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4403, Loss: 0.0002126976123690838, Final Batch Loss: 6.087244037189521e-05\n",
      "Epoch 4404, Loss: 0.0005178397445462224, Final Batch Loss: 1.5193332103535795e-07\n",
      "Epoch 4405, Loss: 0.0007632559609191958, Final Batch Loss: 3.981887493864633e-05\n",
      "Epoch 4406, Loss: 0.0006253634419408627, Final Batch Loss: 4.721376171801239e-06\n",
      "Epoch 4407, Loss: 0.0003868439243888133, Final Batch Loss: 9.519892955722753e-06\n",
      "Epoch 4408, Loss: 0.00011838869068014901, Final Batch Loss: 7.925549653009512e-06\n",
      "Epoch 4409, Loss: 0.0007521125216953806, Final Batch Loss: 1.4387732335308101e-05\n",
      "Epoch 4410, Loss: 0.00015602930511704471, Final Batch Loss: 2.454248942740378e-06\n",
      "Epoch 4411, Loss: 0.00013864693391951732, Final Batch Loss: 2.0414558093762025e-05\n",
      "Epoch 4412, Loss: 0.0011257668229518458, Final Batch Loss: 3.1670675525674596e-05\n",
      "Epoch 4413, Loss: 0.00024059999213932315, Final Batch Loss: 0.00019182836695108563\n",
      "Epoch 4414, Loss: 5.1865101795556257e-05, Final Batch Loss: 4.546153377305018e-06\n",
      "Epoch 4415, Loss: 0.00041585168946767226, Final Batch Loss: 1.7713171473587863e-05\n",
      "Epoch 4416, Loss: 0.002246892470793682, Final Batch Loss: 1.692499063210562e-05\n",
      "Epoch 4417, Loss: 0.000217570508539211, Final Batch Loss: 7.073592132655904e-05\n",
      "Epoch 4418, Loss: 0.00445036310929936, Final Batch Loss: 6.378535999829182e-06\n",
      "Epoch 4419, Loss: 0.00015942784875733196, Final Batch Loss: 4.8286615310644265e-06\n",
      "Epoch 4420, Loss: 0.0001066032509697834, Final Batch Loss: 2.2238242308958434e-05\n",
      "Epoch 4421, Loss: 0.00016985720412776573, Final Batch Loss: 1.342129962722538e-05\n",
      "Epoch 4422, Loss: 9.850017522694543e-05, Final Batch Loss: 6.567750824615359e-05\n",
      "Epoch 4423, Loss: 4.4332907236821484e-05, Final Batch Loss: 1.9914414224331267e-06\n",
      "Epoch 4424, Loss: 0.0036844498747541365, Final Batch Loss: 2.8048154945281567e-06\n",
      "Epoch 4425, Loss: 0.0002458390790707199, Final Batch Loss: 5.6639721151441336e-05\n",
      "Epoch 4426, Loss: 0.00014114649582097627, Final Batch Loss: 1.0448251259731478e-06\n",
      "Epoch 4427, Loss: 0.00015856947993597714, Final Batch Loss: 1.261284251086181e-05\n",
      "Epoch 4428, Loss: 0.00023368420534097822, Final Batch Loss: 4.055297722516116e-06\n",
      "Epoch 4429, Loss: 0.00014125333746051183, Final Batch Loss: 1.2008916201011743e-05\n",
      "Epoch 4430, Loss: 0.006709059352033364, Final Batch Loss: 1.0206248589383904e-05\n",
      "Epoch 4431, Loss: 0.0006423609229386784, Final Batch Loss: 0.0003279983066022396\n",
      "Epoch 4432, Loss: 0.0001465057757741306, Final Batch Loss: 5.0697017286438495e-06\n",
      "Epoch 4433, Loss: 9.381010568176862e-05, Final Batch Loss: 2.5531340725137852e-05\n",
      "Epoch 4434, Loss: 0.0008068859751801938, Final Batch Loss: 0.0003967898664996028\n",
      "Epoch 4435, Loss: 0.0001713541942081065, Final Batch Loss: 4.391030233819038e-05\n",
      "Epoch 4436, Loss: 0.00044600801629712805, Final Batch Loss: 0.0003339432878419757\n",
      "Epoch 4437, Loss: 0.0001853762751125032, Final Batch Loss: 1.7811240468290634e-05\n",
      "Epoch 4438, Loss: 0.00014937254309188575, Final Batch Loss: 6.589192344108596e-05\n",
      "Epoch 4439, Loss: 0.0012652948262257269, Final Batch Loss: 0.001189116621389985\n",
      "Epoch 4440, Loss: 0.0016374507849832298, Final Batch Loss: 3.23970198223833e-05\n",
      "Epoch 4441, Loss: 0.00019793736282736063, Final Batch Loss: 2.0839925127802417e-05\n",
      "Epoch 4442, Loss: 0.0008199994153983425, Final Batch Loss: 4.093535608262755e-05\n",
      "Epoch 4443, Loss: 0.00015007932961452752, Final Batch Loss: 3.408823613426648e-05\n",
      "Epoch 4444, Loss: 0.00022119143250165507, Final Batch Loss: 0.0001429557305527851\n",
      "Epoch 4445, Loss: 0.00017932418177224463, Final Batch Loss: 4.8140962462639436e-05\n",
      "Epoch 4446, Loss: 0.0005877389266970567, Final Batch Loss: 0.00032357830787077546\n",
      "Epoch 4447, Loss: 0.0018459773345966823, Final Batch Loss: 0.0015428471378982067\n",
      "Epoch 4448, Loss: 0.0008763639925746247, Final Batch Loss: 6.16836259723641e-05\n",
      "Epoch 4449, Loss: 0.0003361539856996387, Final Batch Loss: 1.9814688130281866e-05\n",
      "Epoch 4450, Loss: 0.00016445290020783432, Final Batch Loss: 2.2141564841149375e-05\n",
      "Epoch 4451, Loss: 0.0009596306565526902, Final Batch Loss: 1.1476743111416e-06\n",
      "Epoch 4452, Loss: 0.00027784640406025574, Final Batch Loss: 0.00014401903899852186\n",
      "Epoch 4453, Loss: 0.0005413956205302384, Final Batch Loss: 0.00037336096283979714\n",
      "Epoch 4454, Loss: 0.0041611569622546085, Final Batch Loss: 0.004121121019124985\n",
      "Epoch 4455, Loss: 0.00028911060690006707, Final Batch Loss: 4.494560926104896e-06\n",
      "Epoch 4456, Loss: 0.00018480698417988606, Final Batch Loss: 9.708240395411849e-05\n",
      "Epoch 4457, Loss: 0.0002935112643172033, Final Batch Loss: 0.00013538576604332775\n",
      "Epoch 4458, Loss: 0.0003462614249656326, Final Batch Loss: 1.2740611964545678e-05\n",
      "Epoch 4459, Loss: 0.0004630083203664981, Final Batch Loss: 0.00012885802425444126\n",
      "Epoch 4460, Loss: 0.0001328180326254369, Final Batch Loss: 1.4445206488744589e-06\n",
      "Epoch 4461, Loss: 0.0003540828879522451, Final Batch Loss: 3.861347522615688e-06\n",
      "Epoch 4462, Loss: 0.003541865746228723, Final Batch Loss: 1.7217371350852773e-05\n",
      "Epoch 4463, Loss: 0.00032009855976866675, Final Batch Loss: 5.808095465908991e-06\n",
      "Epoch 4464, Loss: 0.00015100725431693718, Final Batch Loss: 3.321755139040761e-05\n",
      "Epoch 4465, Loss: 0.00014641880079580005, Final Batch Loss: 6.85177874402143e-05\n",
      "Epoch 4466, Loss: 0.0004891546468570596, Final Batch Loss: 1.961811176443007e-05\n",
      "Epoch 4467, Loss: 0.00041524295056660776, Final Batch Loss: 7.4671411312010605e-06\n",
      "Epoch 4468, Loss: 8.597704390922445e-05, Final Batch Loss: 2.012483946600696e-06\n",
      "Epoch 4469, Loss: 0.0010007268838307937, Final Batch Loss: 1.2958252227690537e-05\n",
      "Epoch 4470, Loss: 0.018389393266261322, Final Batch Loss: 0.000372430426068604\n",
      "Epoch 4471, Loss: 0.00019427937877480872, Final Batch Loss: 1.751899253576994e-05\n",
      "Epoch 4472, Loss: 0.0001696375998108124, Final Batch Loss: 6.885400125611341e-06\n",
      "Epoch 4473, Loss: 7.281509851964074e-05, Final Batch Loss: 6.740686785633443e-06\n",
      "Epoch 4474, Loss: 0.0003517074801493436, Final Batch Loss: 0.00016496633179485798\n",
      "Epoch 4475, Loss: 0.0002656952025290593, Final Batch Loss: 4.885229145656922e-07\n",
      "Epoch 4476, Loss: 0.0001512913911483338, Final Batch Loss: 2.6271443402947625e-06\n",
      "Epoch 4477, Loss: 0.00029562456029452733, Final Batch Loss: 2.1971513888274785e-06\n",
      "Epoch 4478, Loss: 0.0011036113755835686, Final Batch Loss: 0.0002825283445417881\n",
      "Epoch 4479, Loss: 4.950549282511929e-05, Final Batch Loss: 1.2840698218496982e-05\n",
      "Epoch 4480, Loss: 0.00011111005505881622, Final Batch Loss: 4.050650659337407e-06\n",
      "Epoch 4481, Loss: 0.0004169261192146223, Final Batch Loss: 0.00036770093720406294\n",
      "Epoch 4482, Loss: 0.00027751362358685583, Final Batch Loss: 7.002606434980407e-05\n",
      "Epoch 4483, Loss: 0.00022054527380532818, Final Batch Loss: 5.427170435723383e-06\n",
      "Epoch 4484, Loss: 0.0005476923925016308, Final Batch Loss: 7.890625056461431e-06\n",
      "Epoch 4485, Loss: 9.113837222685106e-05, Final Batch Loss: 6.343532731989399e-06\n",
      "Epoch 4486, Loss: 0.00014393190713235526, Final Batch Loss: 7.089061455189949e-06\n",
      "Epoch 4487, Loss: 0.00041585331564419903, Final Batch Loss: 6.2989020079839975e-06\n",
      "Epoch 4488, Loss: 0.00010863810166483745, Final Batch Loss: 1.9011764379683882e-05\n",
      "Epoch 4489, Loss: 0.0012215312090120278, Final Batch Loss: 0.00014048263255972415\n",
      "Epoch 4490, Loss: 6.478246086771833e-05, Final Batch Loss: 1.0318905879103113e-05\n",
      "Epoch 4491, Loss: 0.0004561355017358437, Final Batch Loss: 0.00022524787345901132\n",
      "Epoch 4492, Loss: 5.08947509842983e-05, Final Batch Loss: 1.9470548977551516e-06\n",
      "Epoch 4493, Loss: 0.00029122745036147535, Final Batch Loss: 0.00016266359307337552\n",
      "Epoch 4494, Loss: 0.00028072357508790446, Final Batch Loss: 5.324490302882623e-06\n",
      "Epoch 4495, Loss: 0.0002729076222749427, Final Batch Loss: 3.2405470847152174e-05\n",
      "Epoch 4496, Loss: 0.0002616790545744152, Final Batch Loss: 2.617830659801257e-06\n",
      "Epoch 4497, Loss: 0.00029744616767857224, Final Batch Loss: 4.538854045676999e-05\n",
      "Epoch 4498, Loss: 0.00010139412415810511, Final Batch Loss: 2.7674236662278417e-06\n",
      "Epoch 4499, Loss: 0.0021617110251099803, Final Batch Loss: 0.00039286824176087976\n",
      "Epoch 4500, Loss: 0.0001939456724358024, Final Batch Loss: 2.3941991457832046e-05\n",
      "Epoch 4501, Loss: 4.1719017644936685e-05, Final Batch Loss: 7.326844752242323e-06\n",
      "Epoch 4502, Loss: 0.0003722021956491517, Final Batch Loss: 1.558445546834264e-05\n",
      "Epoch 4503, Loss: 0.003431669912970392, Final Batch Loss: 7.945646939333528e-05\n",
      "Epoch 4504, Loss: 0.0004985385689906252, Final Batch Loss: 4.031995104014641e-06\n",
      "Epoch 4505, Loss: 0.0005659710841428023, Final Batch Loss: 4.385782449389808e-05\n",
      "Epoch 4506, Loss: 0.0003449519590503769, Final Batch Loss: 2.9803513825754635e-05\n",
      "Epoch 4507, Loss: 9.114788360875536e-05, Final Batch Loss: 1.7039727708834107e-06\n",
      "Epoch 4508, Loss: 0.00028321063473413233, Final Batch Loss: 0.00022713630460202694\n",
      "Epoch 4509, Loss: 0.0002804155636795258, Final Batch Loss: 1.7577275457369979e-06\n",
      "Epoch 4510, Loss: 8.892519326764159e-05, Final Batch Loss: 4.478943083086051e-05\n",
      "Epoch 4511, Loss: 0.000902138791843754, Final Batch Loss: 4.2116621443710756e-06\n",
      "Epoch 4512, Loss: 0.005810931477753911, Final Batch Loss: 4.7050416469573975e-06\n",
      "Epoch 4513, Loss: 7.813364572939463e-05, Final Batch Loss: 1.3978373317513615e-05\n",
      "Epoch 4514, Loss: 0.0008553396910429001, Final Batch Loss: 0.0006523513584397733\n",
      "Epoch 4515, Loss: 0.0004157640796620399, Final Batch Loss: 0.0002850449236575514\n",
      "Epoch 4516, Loss: 0.0002917528890975518, Final Batch Loss: 1.6154159311554395e-05\n",
      "Epoch 4517, Loss: 0.00024260563077405095, Final Batch Loss: 8.11108184279874e-05\n",
      "Epoch 4518, Loss: 0.0006984403053138521, Final Batch Loss: 0.0005810920265503228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4519, Loss: 0.00035162156746082474, Final Batch Loss: 1.080538822861854e-05\n",
      "Epoch 4520, Loss: 6.906061389599927e-05, Final Batch Loss: 3.224474494345486e-05\n",
      "Epoch 4521, Loss: 0.00018416221973893698, Final Batch Loss: 0.0001388694508932531\n",
      "Epoch 4522, Loss: 0.00022065636949264444, Final Batch Loss: 1.8463411834090948e-05\n",
      "Epoch 4523, Loss: 0.0001501251781519386, Final Batch Loss: 1.6068377590272576e-05\n",
      "Epoch 4524, Loss: 0.002173367225623224, Final Batch Loss: 0.0019847764633595943\n",
      "Epoch 4525, Loss: 0.00010582944037196285, Final Batch Loss: 2.7814605800813297e-06\n",
      "Epoch 4526, Loss: 0.00019440592723185546, Final Batch Loss: 2.2392282517103013e-06\n",
      "Epoch 4527, Loss: 0.00013562228832597611, Final Batch Loss: 0.00010232842760160565\n",
      "Epoch 4528, Loss: 0.0003909157821908593, Final Batch Loss: 6.544599455082789e-05\n",
      "Epoch 4529, Loss: 5.697475262422813e-05, Final Batch Loss: 1.7163538359454833e-05\n",
      "Epoch 4530, Loss: 0.00015532940051343758, Final Batch Loss: 2.8458047381718643e-05\n",
      "Epoch 4531, Loss: 0.00011024283867300255, Final Batch Loss: 6.163419129734393e-06\n",
      "Epoch 4532, Loss: 6.234388092707377e-05, Final Batch Loss: 2.931048584287055e-06\n",
      "Epoch 4533, Loss: 4.126544126847875e-05, Final Batch Loss: 2.346695509913843e-06\n",
      "Epoch 4534, Loss: 0.0004856738196394872, Final Batch Loss: 1.8346192518947646e-05\n",
      "Epoch 4535, Loss: 0.00010887283707461393, Final Batch Loss: 4.5345979060584796e-07\n",
      "Epoch 4536, Loss: 0.0001856064518506173, Final Batch Loss: 0.00016288523329421878\n",
      "Epoch 4537, Loss: 6.2647416712025e-05, Final Batch Loss: 1.7904413880387438e-06\n",
      "Epoch 4538, Loss: 0.00034337354452418367, Final Batch Loss: 1.5566955653412151e-06\n",
      "Epoch 4539, Loss: 4.895224719803082e-05, Final Batch Loss: 2.1375260985223576e-05\n",
      "Epoch 4540, Loss: 0.00012911350313515868, Final Batch Loss: 7.649397957720794e-06\n",
      "Epoch 4541, Loss: 0.004436096643530618, Final Batch Loss: 5.938929007243132e-06\n",
      "Epoch 4542, Loss: 0.0024222755355367553, Final Batch Loss: 4.898974111711141e-06\n",
      "Epoch 4543, Loss: 4.6218067858205814e-05, Final Batch Loss: 6.311076816700734e-08\n",
      "Epoch 4544, Loss: 0.0003452896571616293, Final Batch Loss: 9.368835890199989e-05\n",
      "Epoch 4545, Loss: 0.001116270519560203, Final Batch Loss: 0.00012822425924241543\n",
      "Epoch 4546, Loss: 4.214735076857323e-05, Final Batch Loss: 1.7553986708662705e-06\n",
      "Epoch 4547, Loss: 0.0001918285524880048, Final Batch Loss: 7.65864024288021e-05\n",
      "Epoch 4548, Loss: 0.00015486095799133182, Final Batch Loss: 8.5165083874017e-05\n",
      "Epoch 4549, Loss: 0.0022084352435740584, Final Batch Loss: 1.5076197996677365e-06\n",
      "Epoch 4550, Loss: 0.00035595300778368255, Final Batch Loss: 1.104742750612786e-05\n",
      "Epoch 4551, Loss: 5.9830207192135276e-05, Final Batch Loss: 4.39878795077675e-06\n",
      "Epoch 4552, Loss: 7.328682295337785e-05, Final Batch Loss: 6.745385690010153e-06\n",
      "Epoch 4553, Loss: 4.8309374278687756e-05, Final Batch Loss: 2.6389122922410024e-06\n",
      "Epoch 4554, Loss: 8.624450583738508e-05, Final Batch Loss: 8.13745009509148e-06\n",
      "Epoch 4555, Loss: 3.487224216769391e-05, Final Batch Loss: 2.9824875582562527e-06\n",
      "Epoch 4556, Loss: 0.0006864765819045715, Final Batch Loss: 4.0049235394690186e-05\n",
      "Epoch 4557, Loss: 0.00023053968379826983, Final Batch Loss: 3.3128188078990206e-05\n",
      "Epoch 4558, Loss: 0.00015178955038663844, Final Batch Loss: 1.5239889989970834e-06\n",
      "Epoch 4559, Loss: 0.00022649736274615861, Final Batch Loss: 1.5086530765984207e-05\n",
      "Epoch 4560, Loss: 0.0002536679866125269, Final Batch Loss: 1.5894373746050405e-06\n",
      "Epoch 4561, Loss: 0.0003008497915288899, Final Batch Loss: 2.6047611754620448e-05\n",
      "Epoch 4562, Loss: 0.00020009470210879954, Final Batch Loss: 1.1500120535856695e-06\n",
      "Epoch 4563, Loss: 9.939361132182967e-05, Final Batch Loss: 1.820822376430442e-06\n",
      "Epoch 4564, Loss: 3.7369667552411556e-05, Final Batch Loss: 9.679413778940216e-06\n",
      "Epoch 4565, Loss: 7.415463687721058e-05, Final Batch Loss: 3.9477358768635895e-06\n",
      "Epoch 4566, Loss: 0.00022975532738200855, Final Batch Loss: 2.0207511624903418e-05\n",
      "Epoch 4567, Loss: 0.0001573116346662573, Final Batch Loss: 5.602143119176617e-06\n",
      "Epoch 4568, Loss: 1.5361613804998342e-05, Final Batch Loss: 1.0518351700739004e-06\n",
      "Epoch 4569, Loss: 0.0003874624308082275, Final Batch Loss: 3.304371057311073e-05\n",
      "Epoch 4570, Loss: 0.0016834749912959523, Final Batch Loss: 0.0016613423358649015\n",
      "Epoch 4571, Loss: 8.527957470505498e-05, Final Batch Loss: 3.530765388859436e-05\n",
      "Epoch 4572, Loss: 0.0002704017169889994, Final Batch Loss: 0.00011073546920670196\n",
      "Epoch 4573, Loss: 0.00017434735627830378, Final Batch Loss: 1.522892307548318e-05\n",
      "Epoch 4574, Loss: 5.8221096594479604e-05, Final Batch Loss: 8.508183668709535e-07\n",
      "Epoch 4575, Loss: 5.279096967569785e-05, Final Batch Loss: 1.0658493010851089e-05\n",
      "Epoch 4576, Loss: 8.619898295592066e-05, Final Batch Loss: 4.791727974406967e-07\n",
      "Epoch 4577, Loss: 0.000111342253148905, Final Batch Loss: 1.1644313417491503e-05\n",
      "Epoch 4578, Loss: 0.0016635360052532633, Final Batch Loss: 2.4939181457739323e-06\n",
      "Epoch 4579, Loss: 0.00021079053294670302, Final Batch Loss: 8.880041423253715e-05\n",
      "Epoch 4580, Loss: 0.00018507940455947391, Final Batch Loss: 9.723665925776004e-07\n",
      "Epoch 4581, Loss: 0.0003466201801529678, Final Batch Loss: 3.819061475951457e-06\n",
      "Epoch 4582, Loss: 0.0005042665361543186, Final Batch Loss: 0.0004327705828472972\n",
      "Epoch 4583, Loss: 0.0003938395980185305, Final Batch Loss: 0.00010837857553269714\n",
      "Epoch 4584, Loss: 0.0001693724179858691, Final Batch Loss: 2.7323540052748285e-06\n",
      "Epoch 4585, Loss: 0.00015150880449255055, Final Batch Loss: 1.0284531981596956e-06\n",
      "Epoch 4586, Loss: 0.0006341700411667262, Final Batch Loss: 1.9236379102949286e-06\n",
      "Epoch 4587, Loss: 0.00021744255718658678, Final Batch Loss: 0.00011518252722453326\n",
      "Epoch 4588, Loss: 5.75413350816234e-05, Final Batch Loss: 1.793917363102082e-05\n",
      "Epoch 4589, Loss: 9.659722121568848e-05, Final Batch Loss: 8.414735361839121e-07\n",
      "Epoch 4590, Loss: 0.00011148548583150841, Final Batch Loss: 3.5152661439497024e-05\n",
      "Epoch 4591, Loss: 4.8109305680554826e-05, Final Batch Loss: 1.1081673619628418e-05\n",
      "Epoch 4592, Loss: 0.00017552422832523007, Final Batch Loss: 3.0664166843052953e-05\n",
      "Epoch 4593, Loss: 3.296519400919351e-05, Final Batch Loss: 1.64318055340118e-06\n",
      "Epoch 4594, Loss: 0.0018459078419255093, Final Batch Loss: 0.001759352977387607\n",
      "Epoch 4595, Loss: 0.00010385770792709081, Final Batch Loss: 6.4696446315792855e-06\n",
      "Epoch 4596, Loss: 0.00010093902687913214, Final Batch Loss: 2.3116770080378046e-06\n",
      "Epoch 4597, Loss: 7.906899008958135e-05, Final Batch Loss: 1.9011180484085344e-05\n",
      "Epoch 4598, Loss: 0.0001629008706913737, Final Batch Loss: 6.675372333120322e-06\n",
      "Epoch 4599, Loss: 0.0003217615667381324, Final Batch Loss: 0.00017304519133176655\n",
      "Epoch 4600, Loss: 0.0004651977687899489, Final Batch Loss: 4.019715197500773e-05\n",
      "Epoch 4601, Loss: 0.0016593088948866352, Final Batch Loss: 2.2565611288882792e-05\n",
      "Epoch 4602, Loss: 0.0024838062236085534, Final Batch Loss: 0.00037265062564983964\n",
      "Epoch 4603, Loss: 0.0007520346753153717, Final Batch Loss: 0.0006107112276367843\n",
      "Epoch 4604, Loss: 0.0005189047078602016, Final Batch Loss: 0.00018414542137179524\n",
      "Epoch 4605, Loss: 9.080846575670876e-05, Final Batch Loss: 2.897320155170746e-05\n",
      "Epoch 4606, Loss: 0.0004571972990561335, Final Batch Loss: 2.05455626201001e-06\n",
      "Epoch 4607, Loss: 0.0034855341064030654, Final Batch Loss: 2.418987060082145e-05\n",
      "Epoch 4608, Loss: 0.00019695325499924365, Final Batch Loss: 0.00012851502106059343\n",
      "Epoch 4609, Loss: 0.00018235359675600193, Final Batch Loss: 6.59335455566179e-06\n",
      "Epoch 4610, Loss: 8.599755710747559e-05, Final Batch Loss: 2.002130167966243e-05\n",
      "Epoch 4611, Loss: 0.0001088952943177901, Final Batch Loss: 1.4959579175410909e-07\n",
      "Epoch 4612, Loss: 0.0004776006462634541, Final Batch Loss: 0.00044421490747481585\n",
      "Epoch 4613, Loss: 6.288688746280968e-05, Final Batch Loss: 1.941521986736916e-05\n",
      "Epoch 4614, Loss: 0.00022702603610014194, Final Batch Loss: 9.302075341111049e-06\n",
      "Epoch 4615, Loss: 3.944006721212645e-05, Final Batch Loss: 3.220869530196069e-06\n",
      "Epoch 4616, Loss: 0.0001871013730578852, Final Batch Loss: 1.9820847683149623e-06\n",
      "Epoch 4617, Loss: 0.00016307840314766509, Final Batch Loss: 4.6670244046254084e-05\n",
      "Epoch 4618, Loss: 7.37201467018167e-05, Final Batch Loss: 3.3048986551875714e-06\n",
      "Epoch 4619, Loss: 5.1068192078673746e-05, Final Batch Loss: 2.5596533305360936e-05\n",
      "Epoch 4620, Loss: 5.4113327223603847e-05, Final Batch Loss: 6.044123892934294e-06\n",
      "Epoch 4621, Loss: 0.0006247171986615285, Final Batch Loss: 0.0002014302444877103\n",
      "Epoch 4622, Loss: 0.00013158733145246515, Final Batch Loss: 7.034067675704136e-05\n",
      "Epoch 4623, Loss: 7.113119136192836e-05, Final Batch Loss: 2.6668200007406995e-05\n",
      "Epoch 4624, Loss: 7.59175256916933e-05, Final Batch Loss: 2.5383872070960933e-06\n",
      "Epoch 4625, Loss: 0.00011413430419793258, Final Batch Loss: 3.8100060351098364e-07\n",
      "Epoch 4626, Loss: 0.00038467651756946, Final Batch Loss: 0.0002444645797368139\n",
      "Epoch 4627, Loss: 0.00020785136689482897, Final Batch Loss: 2.98005465992901e-06\n",
      "Epoch 4628, Loss: 0.00011011627429979853, Final Batch Loss: 2.250857505714521e-06\n",
      "Epoch 4629, Loss: 0.00022658089801552705, Final Batch Loss: 6.967009539948776e-06\n",
      "Epoch 4630, Loss: 0.00020402577865752392, Final Batch Loss: 5.6127584684873e-05\n",
      "Epoch 4631, Loss: 0.0003441950339038158, Final Batch Loss: 2.0089539248147048e-05\n",
      "Epoch 4632, Loss: 7.612253693878301e-05, Final Batch Loss: 4.964644540450536e-05\n",
      "Epoch 4633, Loss: 0.0002574846998868452, Final Batch Loss: 4.37538028563722e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4634, Loss: 8.203616380342282e-05, Final Batch Loss: 1.8365844880463555e-05\n",
      "Epoch 4635, Loss: 0.0002574732958464665, Final Batch Loss: 5.048838147558854e-07\n",
      "Epoch 4636, Loss: 3.462045788182877e-05, Final Batch Loss: 1.6375921404687688e-05\n",
      "Epoch 4637, Loss: 6.193193985382095e-05, Final Batch Loss: 6.184014637256041e-06\n",
      "Epoch 4638, Loss: 0.0001838371945268591, Final Batch Loss: 5.986869291518815e-05\n",
      "Epoch 4639, Loss: 0.0002710325425141491, Final Batch Loss: 8.859001536620781e-05\n",
      "Epoch 4640, Loss: 6.541617949551437e-05, Final Batch Loss: 4.058112608618103e-05\n",
      "Epoch 4641, Loss: 3.406755510582116e-05, Final Batch Loss: 4.7216096277225006e-07\n",
      "Epoch 4642, Loss: 0.0003061966235691216, Final Batch Loss: 1.9412396795814857e-05\n",
      "Epoch 4643, Loss: 2.8652070113821537e-05, Final Batch Loss: 2.613084461700055e-06\n",
      "Epoch 4644, Loss: 6.752196975412517e-05, Final Batch Loss: 3.272406274845707e-07\n",
      "Epoch 4645, Loss: 0.00011230829932173947, Final Batch Loss: 4.085585715074558e-06\n",
      "Epoch 4646, Loss: 9.976749697671039e-05, Final Batch Loss: 9.741271242091898e-06\n",
      "Epoch 4647, Loss: 0.0002567514925431169, Final Batch Loss: 3.319424649816938e-05\n",
      "Epoch 4648, Loss: 5.312844587024301e-05, Final Batch Loss: 7.240249033202417e-06\n",
      "Epoch 4649, Loss: 0.00010313591155863833, Final Batch Loss: 3.3375916245859116e-05\n",
      "Epoch 4650, Loss: 8.49196203489555e-05, Final Batch Loss: 1.018066359392833e-05\n",
      "Epoch 4651, Loss: 8.30630328891857e-05, Final Batch Loss: 6.8596223172789905e-06\n",
      "Epoch 4652, Loss: 0.0017813093259064772, Final Batch Loss: 4.870946213486604e-06\n",
      "Epoch 4653, Loss: 0.0024456548142097745, Final Batch Loss: 2.451910177114769e-06\n",
      "Epoch 4654, Loss: 0.00010933980911431718, Final Batch Loss: 5.039120424044086e-06\n",
      "Epoch 4655, Loss: 0.00016278022349069943, Final Batch Loss: 4.973687737219734e-06\n",
      "Epoch 4656, Loss: 0.0002806959964800626, Final Batch Loss: 8.399871148867533e-06\n",
      "Epoch 4657, Loss: 4.045723915169219e-05, Final Batch Loss: 5.259197450868669e-07\n",
      "Epoch 4658, Loss: 0.017804274550144328, Final Batch Loss: 0.017717139795422554\n",
      "Epoch 4659, Loss: 0.00014224085316527635, Final Batch Loss: 8.247163350461051e-05\n",
      "Epoch 4660, Loss: 0.0002956680082206731, Final Batch Loss: 2.2018184608896263e-06\n",
      "Epoch 4661, Loss: 3.938491499866359e-05, Final Batch Loss: 2.4017914256546646e-05\n",
      "Epoch 4662, Loss: 0.0030861484929118888, Final Batch Loss: 4.330517185735516e-05\n",
      "Epoch 4663, Loss: 7.790667763174497e-05, Final Batch Loss: 4.838474865209719e-07\n",
      "Epoch 4664, Loss: 6.000104167469544e-05, Final Batch Loss: 1.7056663637049496e-05\n",
      "Epoch 4665, Loss: 5.7112620197585784e-05, Final Batch Loss: 1.7407577615813352e-05\n",
      "Epoch 4666, Loss: 4.743646468341467e-05, Final Batch Loss: 5.284667622618144e-06\n",
      "Epoch 4667, Loss: 0.00021213893705862574, Final Batch Loss: 6.390799535438418e-05\n",
      "Epoch 4668, Loss: 0.036493154082563706, Final Batch Loss: 1.2030992365907878e-05\n",
      "Epoch 4669, Loss: 8.46152115627774e-05, Final Batch Loss: 3.4884302294813097e-05\n",
      "Epoch 4670, Loss: 0.003266760182668804, Final Batch Loss: 0.0028452244587242603\n",
      "Epoch 4671, Loss: 0.029845790941180894, Final Batch Loss: 1.5797799278516322e-05\n",
      "Epoch 4672, Loss: 0.001477280216931831, Final Batch Loss: 0.00010519628267502412\n",
      "Epoch 4673, Loss: 0.002097714488627389, Final Batch Loss: 0.00034333308576606214\n",
      "Epoch 4674, Loss: 0.0001004554760584142, Final Batch Loss: 3.8840866181999445e-05\n",
      "Epoch 4675, Loss: 0.0009202798751175578, Final Batch Loss: 6.661262432317017e-06\n",
      "Epoch 4676, Loss: 0.00495696723828587, Final Batch Loss: 3.942578041460365e-05\n",
      "Epoch 4677, Loss: 0.0002748475562839303, Final Batch Loss: 5.3239247790770605e-05\n",
      "Epoch 4678, Loss: 0.004122306072531501, Final Batch Loss: 4.8751815484138206e-05\n",
      "Epoch 4679, Loss: 0.00017801981994125526, Final Batch Loss: 4.655979864764959e-06\n",
      "Epoch 4680, Loss: 0.0035977274128526915, Final Batch Loss: 2.2414624254452065e-05\n",
      "Epoch 4681, Loss: 0.0001973698745132424, Final Batch Loss: 7.537608325947076e-06\n",
      "Epoch 4682, Loss: 0.00039185161244859046, Final Batch Loss: 3.805278765867115e-06\n",
      "Epoch 4683, Loss: 0.00040623285894980654, Final Batch Loss: 0.00015504735347349197\n",
      "Epoch 4684, Loss: 0.0005164173744560685, Final Batch Loss: 4.455538510228507e-05\n",
      "Epoch 4685, Loss: 0.0021418343603727408, Final Batch Loss: 7.390243263216689e-05\n",
      "Epoch 4686, Loss: 0.0004969365036231466, Final Batch Loss: 0.00015866529429331422\n",
      "Epoch 4687, Loss: 8.121487098833313e-05, Final Batch Loss: 5.738172148994636e-06\n",
      "Epoch 4688, Loss: 0.0018862948563764803, Final Batch Loss: 0.0014305830700322986\n",
      "Epoch 4689, Loss: 0.0003301754959466052, Final Batch Loss: 0.0001381448091706261\n",
      "Epoch 4690, Loss: 0.00014935865328880027, Final Batch Loss: 0.00010664120054570958\n",
      "Epoch 4691, Loss: 0.00012389002586132847, Final Batch Loss: 3.741599357454106e-05\n",
      "Epoch 4692, Loss: 0.00031651649373998225, Final Batch Loss: 2.1644129901687847e-06\n",
      "Epoch 4693, Loss: 0.0002510624563001329, Final Batch Loss: 3.0572864488931373e-06\n",
      "Epoch 4694, Loss: 0.003159095615046681, Final Batch Loss: 2.4576709620305337e-05\n",
      "Epoch 4695, Loss: 0.00015482753315154696, Final Batch Loss: 7.025592822174076e-06\n",
      "Epoch 4696, Loss: 0.00013573930118582211, Final Batch Loss: 4.693785012932494e-05\n",
      "Epoch 4697, Loss: 0.00013559056606027298, Final Batch Loss: 6.768828461645171e-05\n",
      "Epoch 4698, Loss: 9.954133383871522e-05, Final Batch Loss: 3.2322470360668376e-05\n",
      "Epoch 4699, Loss: 0.00036215799264027737, Final Batch Loss: 1.9433893612585962e-05\n",
      "Epoch 4700, Loss: 0.00016049899568315595, Final Batch Loss: 0.00011541238927748054\n",
      "Epoch 4701, Loss: 0.00014455541440838715, Final Batch Loss: 2.6191310098511167e-05\n",
      "Epoch 4702, Loss: 0.0007249050831887871, Final Batch Loss: 0.00035400845808908343\n",
      "Epoch 4703, Loss: 9.16582030185964e-05, Final Batch Loss: 2.1302901586750522e-05\n",
      "Epoch 4704, Loss: 0.0002214491705672117, Final Batch Loss: 0.0001268352207262069\n",
      "Epoch 4705, Loss: 0.0006876819643366616, Final Batch Loss: 6.39748977846466e-05\n",
      "Epoch 4706, Loss: 8.475164008814318e-05, Final Batch Loss: 3.064226575588691e-06\n",
      "Epoch 4707, Loss: 0.00010203872170677641, Final Batch Loss: 4.235210326442029e-06\n",
      "Epoch 4708, Loss: 0.0005791644293822173, Final Batch Loss: 1.8956311578222085e-06\n",
      "Epoch 4709, Loss: 0.00010776783346955199, Final Batch Loss: 5.5424898164346814e-05\n",
      "Epoch 4710, Loss: 0.00020885798244307807, Final Batch Loss: 2.7557719022297533e-06\n",
      "Epoch 4711, Loss: 0.000581038708332926, Final Batch Loss: 0.00024364130513276905\n",
      "Epoch 4712, Loss: 0.0008900655066099716, Final Batch Loss: 2.424260128464084e-05\n",
      "Epoch 4713, Loss: 0.016224370735471894, Final Batch Loss: 6.560851943504531e-06\n",
      "Epoch 4714, Loss: 0.01036648485819569, Final Batch Loss: 1.9096630694548367e-06\n",
      "Epoch 4715, Loss: 0.0005179503168619704, Final Batch Loss: 3.7347690522437915e-05\n",
      "Epoch 4716, Loss: 0.0006165443546706229, Final Batch Loss: 1.2971147043572273e-05\n",
      "Epoch 4717, Loss: 0.00023373068142973352, Final Batch Loss: 3.985036528320052e-06\n",
      "Epoch 4718, Loss: 0.059441536059694045, Final Batch Loss: 3.828592980426038e-06\n",
      "Epoch 4719, Loss: 2.9243435164971743e-05, Final Batch Loss: 7.1403792389901355e-06\n",
      "Epoch 4720, Loss: 0.00029072538018226624, Final Batch Loss: 0.00018613095744512975\n",
      "Epoch 4721, Loss: 0.0022410906367440475, Final Batch Loss: 0.0015863596927374601\n",
      "Epoch 4722, Loss: 9.010949042931315e-05, Final Batch Loss: 7.947223821247462e-07\n",
      "Epoch 4723, Loss: 0.0001651741004025098, Final Batch Loss: 2.519719782867469e-05\n",
      "Epoch 4724, Loss: 0.00016304094788210932, Final Batch Loss: 0.00010264515003655106\n",
      "Epoch 4725, Loss: 0.00024145007773768157, Final Batch Loss: 9.322904224973172e-05\n",
      "Epoch 4726, Loss: 0.00026789620460476726, Final Batch Loss: 0.00011760530469473451\n",
      "Epoch 4727, Loss: 0.0001405153288942529, Final Batch Loss: 6.27778354100883e-05\n",
      "Epoch 4728, Loss: 8.682237967150286e-05, Final Batch Loss: 2.81598750007106e-05\n",
      "Epoch 4729, Loss: 0.00037198374775471166, Final Batch Loss: 6.88935469952412e-05\n",
      "Epoch 4730, Loss: 0.0024557379947509617, Final Batch Loss: 5.000951932743192e-05\n",
      "Epoch 4731, Loss: 0.00016136013618961442, Final Batch Loss: 2.1292305973474868e-05\n",
      "Epoch 4732, Loss: 0.0001558577827154295, Final Batch Loss: 1.640816094550246e-06\n",
      "Epoch 4733, Loss: 0.00016934376253630035, Final Batch Loss: 4.269734563422389e-05\n",
      "Epoch 4734, Loss: 0.00020890283121843822, Final Batch Loss: 1.742152016959153e-05\n",
      "Epoch 4735, Loss: 0.00034793066879501566, Final Batch Loss: 1.6579768271185458e-05\n",
      "Epoch 4736, Loss: 0.00015576553960272577, Final Batch Loss: 2.4656956156832166e-05\n",
      "Epoch 4737, Loss: 0.00015635223735444015, Final Batch Loss: 8.074809557001572e-06\n",
      "Epoch 4738, Loss: 0.00016275911821139744, Final Batch Loss: 0.00012917858839500695\n",
      "Epoch 4739, Loss: 6.259855945245363e-05, Final Batch Loss: 1.663203875068575e-05\n",
      "Epoch 4740, Loss: 0.001381963501444261, Final Batch Loss: 4.551612073555589e-05\n",
      "Epoch 4741, Loss: 0.00010732639020716306, Final Batch Loss: 1.7094274880946614e-05\n",
      "Epoch 4742, Loss: 0.013358752342355729, Final Batch Loss: 1.1900189747393597e-05\n",
      "Epoch 4743, Loss: 0.0004111181442567613, Final Batch Loss: 8.138694829540327e-05\n",
      "Epoch 4744, Loss: 0.00012942752800881863, Final Batch Loss: 6.411137292161584e-06\n",
      "Epoch 4745, Loss: 7.719391578575596e-05, Final Batch Loss: 1.3744471289101057e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4746, Loss: 0.0002483522657712456, Final Batch Loss: 2.0005998521810398e-05\n",
      "Epoch 4747, Loss: 0.0001254771768799401, Final Batch Loss: 7.238594662339892e-06\n",
      "Epoch 4748, Loss: 0.0001786610228009522, Final Batch Loss: 8.166723273461685e-05\n",
      "Epoch 4749, Loss: 0.0017226889576704707, Final Batch Loss: 1.680189961916767e-05\n",
      "Epoch 4750, Loss: 0.0002036147052422166, Final Batch Loss: 6.729827873641625e-05\n",
      "Epoch 4751, Loss: 0.00015167547303462925, Final Batch Loss: 2.7791268166765803e-06\n",
      "Epoch 4752, Loss: 0.00022540711324836593, Final Batch Loss: 1.7098003809223883e-05\n",
      "Epoch 4753, Loss: 0.00012418457117746584, Final Batch Loss: 3.991967605543323e-05\n",
      "Epoch 4754, Loss: 0.0009540847822790965, Final Batch Loss: 2.1755447960458696e-05\n",
      "Epoch 4755, Loss: 0.0001029456798278261, Final Batch Loss: 2.4973100153147243e-05\n",
      "Epoch 4756, Loss: 0.00012683871864282992, Final Batch Loss: 2.870577918656636e-05\n",
      "Epoch 4757, Loss: 0.0021575222635874525, Final Batch Loss: 0.0017951761838048697\n",
      "Epoch 4758, Loss: 0.001147132607002277, Final Batch Loss: 0.0009442602749913931\n",
      "Epoch 4759, Loss: 0.00039561218363814987, Final Batch Loss: 0.00030805871938355267\n",
      "Epoch 4760, Loss: 0.0007546835804532748, Final Batch Loss: 0.0006601116037927568\n",
      "Epoch 4761, Loss: 0.00030866019551467616, Final Batch Loss: 7.5869702413911e-06\n",
      "Epoch 4762, Loss: 0.000660830120978062, Final Batch Loss: 0.0003466926864348352\n",
      "Epoch 4763, Loss: 0.00023415351643052418, Final Batch Loss: 0.00012443670129869133\n",
      "Epoch 4764, Loss: 0.0003918200236512348, Final Batch Loss: 1.573307963553816e-05\n",
      "Epoch 4765, Loss: 9.631624016037676e-05, Final Batch Loss: 1.075474574463442e-05\n",
      "Epoch 4766, Loss: 5.985852749290643e-05, Final Batch Loss: 2.7509442588780075e-05\n",
      "Epoch 4767, Loss: 0.00019253225491411285, Final Batch Loss: 1.3889949514123145e-05\n",
      "Epoch 4768, Loss: 0.0006164004826132441, Final Batch Loss: 1.2026468539261259e-05\n",
      "Epoch 4769, Loss: 0.00027333396633366647, Final Batch Loss: 2.2485567114927107e-06\n",
      "Epoch 4770, Loss: 0.000344144460541429, Final Batch Loss: 0.0002551385259721428\n",
      "Epoch 4771, Loss: 0.00013017382298130542, Final Batch Loss: 1.7856167687568814e-05\n",
      "Epoch 4772, Loss: 0.0006158791657071561, Final Batch Loss: 0.000396432529669255\n",
      "Epoch 4773, Loss: 0.000696914314175956, Final Batch Loss: 3.999219188699499e-06\n",
      "Epoch 4774, Loss: 0.0038361797815014143, Final Batch Loss: 4.946318586007692e-05\n",
      "Epoch 4775, Loss: 0.00033821550096035935, Final Batch Loss: 0.00015726572019048035\n",
      "Epoch 4776, Loss: 0.003640310987975681, Final Batch Loss: 0.0002650172100402415\n",
      "Epoch 4777, Loss: 0.001053103114827536, Final Batch Loss: 0.0009238799684680998\n",
      "Epoch 4778, Loss: 0.0011849124684886192, Final Batch Loss: 1.175297893496463e-05\n",
      "Epoch 4779, Loss: 0.0003510825840749021, Final Batch Loss: 1.3276417121232953e-06\n",
      "Epoch 4780, Loss: 0.000489661189931212, Final Batch Loss: 0.00032270787050947547\n",
      "Epoch 4781, Loss: 3.698709015509394e-05, Final Batch Loss: 1.0752201262675953e-07\n",
      "Epoch 4782, Loss: 0.0019835884668282233, Final Batch Loss: 0.0018059444846585393\n",
      "Epoch 4783, Loss: 0.0008193207231670385, Final Batch Loss: 2.7661650165100582e-05\n",
      "Epoch 4784, Loss: 0.00014205637853592634, Final Batch Loss: 1.735223486321047e-05\n",
      "Epoch 4785, Loss: 0.0001248353755727294, Final Batch Loss: 7.734120117675047e-06\n",
      "Epoch 4786, Loss: 0.00017734114277345725, Final Batch Loss: 8.204374921660929e-07\n",
      "Epoch 4787, Loss: 0.00032622728031128645, Final Batch Loss: 0.00016152460011653602\n",
      "Epoch 4788, Loss: 0.0003319208335597068, Final Batch Loss: 0.00010674657096387818\n",
      "Epoch 4789, Loss: 0.00012296095155761577, Final Batch Loss: 3.974956416641362e-05\n",
      "Epoch 4790, Loss: 0.00023228190548252314, Final Batch Loss: 0.00019720103591680527\n",
      "Epoch 4791, Loss: 9.655306485001347e-05, Final Batch Loss: 7.539774287579348e-06\n",
      "Epoch 4792, Loss: 8.122063172777416e-05, Final Batch Loss: 1.1257300684519578e-05\n",
      "Epoch 4793, Loss: 0.000317418816848658, Final Batch Loss: 5.196610072744079e-05\n",
      "Epoch 4794, Loss: 7.242333958856761e-05, Final Batch Loss: 3.097873923252337e-05\n",
      "Epoch 4795, Loss: 0.00018454117798683, Final Batch Loss: 6.383351319527719e-06\n",
      "Epoch 4796, Loss: 0.00018090198784648237, Final Batch Loss: 1.1546791256478173e-06\n",
      "Epoch 4797, Loss: 0.0001280365368074854, Final Batch Loss: 1.1614046343311202e-05\n",
      "Epoch 4798, Loss: 0.00013419866775166156, Final Batch Loss: 1.2435081089279265e-06\n",
      "Epoch 4799, Loss: 0.0003410873541724868, Final Batch Loss: 1.003402576316148e-05\n",
      "Epoch 4800, Loss: 0.0010563347639163112, Final Batch Loss: 2.7487255920277676e-06\n",
      "Epoch 4801, Loss: 4.584358885040274e-05, Final Batch Loss: 8.999040801427327e-07\n",
      "Epoch 4802, Loss: 0.0005799950522487052, Final Batch Loss: 6.0961334384046495e-05\n",
      "Epoch 4803, Loss: 0.00020779812257387675, Final Batch Loss: 4.676707976614125e-05\n",
      "Epoch 4804, Loss: 5.326717837306205e-05, Final Batch Loss: 2.328002665308304e-06\n",
      "Epoch 4805, Loss: 0.00025365805322508095, Final Batch Loss: 1.1781567991420161e-05\n",
      "Epoch 4806, Loss: 0.00044445998037190293, Final Batch Loss: 5.8969640122086275e-06\n",
      "Epoch 4807, Loss: 0.00028163382103230106, Final Batch Loss: 1.2550651263154577e-05\n",
      "Epoch 4808, Loss: 0.00010257116900902474, Final Batch Loss: 2.335064891667571e-05\n",
      "Epoch 4809, Loss: 9.897767154143366e-05, Final Batch Loss: 2.711389925025287e-06\n",
      "Epoch 4810, Loss: 0.00011418122176110046, Final Batch Loss: 8.591762707510497e-06\n",
      "Epoch 4811, Loss: 0.0005019925738452002, Final Batch Loss: 3.1098665203899145e-05\n",
      "Epoch 4812, Loss: 8.238108648583875e-05, Final Batch Loss: 7.343731795117492e-06\n",
      "Epoch 4813, Loss: 3.706710140249925e-05, Final Batch Loss: 1.1132135114166886e-05\n",
      "Epoch 4814, Loss: 0.004098937687558646, Final Batch Loss: 2.8889489840366878e-06\n",
      "Epoch 4815, Loss: 0.00019622192485257983, Final Batch Loss: 7.304715109057724e-05\n",
      "Epoch 4816, Loss: 9.311308531323448e-05, Final Batch Loss: 6.5210206230403855e-06\n",
      "Epoch 4817, Loss: 0.0004294125707247076, Final Batch Loss: 1.3066188557786518e-06\n",
      "Epoch 4818, Loss: 0.00011877735300913628, Final Batch Loss: 2.699679271245259e-06\n",
      "Epoch 4819, Loss: 5.783492360933451e-05, Final Batch Loss: 5.198256076255348e-06\n",
      "Epoch 4820, Loss: 0.00023173793033492984, Final Batch Loss: 3.8762824260629714e-05\n",
      "Epoch 4821, Loss: 7.795594865456223e-05, Final Batch Loss: 3.0367813451448455e-05\n",
      "Epoch 4822, Loss: 0.0002802468716254225, Final Batch Loss: 3.972593549406156e-05\n",
      "Epoch 4823, Loss: 0.00017983011457545217, Final Batch Loss: 7.727258343948051e-05\n",
      "Epoch 4824, Loss: 0.0020533871356747113, Final Batch Loss: 0.00010646608279785141\n",
      "Epoch 4825, Loss: 0.0017267157581954962, Final Batch Loss: 7.80895607022103e-06\n",
      "Epoch 4826, Loss: 0.001311843980147387, Final Batch Loss: 1.8359218302066438e-05\n",
      "Epoch 4827, Loss: 0.00010961766201944556, Final Batch Loss: 6.286081043072045e-05\n",
      "Epoch 4828, Loss: 0.0001180392391688656, Final Batch Loss: 0.00010046483657788485\n",
      "Epoch 4829, Loss: 0.00016089452765299939, Final Batch Loss: 9.650171705288813e-06\n",
      "Epoch 4830, Loss: 0.00010774031397886574, Final Batch Loss: 2.04006937565282e-05\n",
      "Epoch 4831, Loss: 0.0011979115583926614, Final Batch Loss: 6.829593530710554e-06\n",
      "Epoch 4832, Loss: 5.3135127132009075e-05, Final Batch Loss: 1.668899244577915e-06\n",
      "Epoch 4833, Loss: 0.00018557775001681875, Final Batch Loss: 8.484491991112009e-05\n",
      "Epoch 4834, Loss: 2.3138504730013665e-05, Final Batch Loss: 5.841076927026734e-06\n",
      "Epoch 4835, Loss: 0.0003147524257656187, Final Batch Loss: 4.777447247761302e-05\n",
      "Epoch 4836, Loss: 0.0004332111652729509, Final Batch Loss: 5.742378107242985e-06\n",
      "Epoch 4837, Loss: 0.0003501957562548341, Final Batch Loss: 6.032172677805647e-05\n",
      "Epoch 4838, Loss: 0.00015151369825616712, Final Batch Loss: 8.55592679727124e-06\n",
      "Epoch 4839, Loss: 0.0027732227497381245, Final Batch Loss: 0.0002726783277466893\n",
      "Epoch 4840, Loss: 0.00015786238304826838, Final Batch Loss: 1.4328268207464134e-06\n",
      "Epoch 4841, Loss: 0.0002725779804677586, Final Batch Loss: 0.00021149319945834577\n",
      "Epoch 4842, Loss: 0.00027293864332023077, Final Batch Loss: 8.221049210987985e-05\n",
      "Epoch 4843, Loss: 0.00017566807218827307, Final Batch Loss: 0.00015205731324385852\n",
      "Epoch 4844, Loss: 0.0001137542260689628, Final Batch Loss: 1.6362056598495656e-08\n",
      "Epoch 4845, Loss: 0.0002914780343417078, Final Batch Loss: 9.399763075634837e-05\n",
      "Epoch 4846, Loss: 7.915628339105751e-05, Final Batch Loss: 3.590086635085754e-06\n",
      "Epoch 4847, Loss: 0.00014747320346941706, Final Batch Loss: 3.492502946755849e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4848, Loss: 0.0002736878304858692, Final Batch Loss: 2.2564767277799547e-05\n",
      "Epoch 4849, Loss: 0.0007006502341937448, Final Batch Loss: 4.33728528150823e-05\n",
      "Epoch 4850, Loss: 0.00015158424776018364, Final Batch Loss: 7.901317985670175e-06\n",
      "Epoch 4851, Loss: 0.0001397546395764948, Final Batch Loss: 9.65351546255988e-07\n",
      "Epoch 4852, Loss: 9.588563261786476e-05, Final Batch Loss: 2.832294012478087e-05\n",
      "Epoch 4853, Loss: 0.00014240692166822555, Final Batch Loss: 2.475271912771859e-06\n",
      "Epoch 4854, Loss: 1.1444459090625969e-05, Final Batch Loss: 3.4126387049582263e-07\n",
      "Epoch 4855, Loss: 8.508443625032669e-05, Final Batch Loss: 2.1200130504439585e-06\n",
      "Epoch 4856, Loss: 5.6374006817350164e-05, Final Batch Loss: 1.707380943116732e-05\n",
      "Epoch 4857, Loss: 0.003782325793054042, Final Batch Loss: 5.0578141781443264e-06\n",
      "Epoch 4858, Loss: 0.00024605636281194165, Final Batch Loss: 2.3318014427786693e-05\n",
      "Epoch 4859, Loss: 0.00015710498610133072, Final Batch Loss: 3.281085446360521e-05\n",
      "Epoch 4860, Loss: 0.00011788233769038925, Final Batch Loss: 9.052807581610978e-05\n",
      "Epoch 4861, Loss: 4.4420758058549836e-05, Final Batch Loss: 5.322033757693134e-06\n",
      "Epoch 4862, Loss: 0.0029102077342031407, Final Batch Loss: 0.0028009035158902407\n",
      "Epoch 4863, Loss: 0.0003366019263921771, Final Batch Loss: 2.4693839804967865e-05\n",
      "Epoch 4864, Loss: 7.629070341863553e-05, Final Batch Loss: 7.427272521454142e-06\n",
      "Epoch 4865, Loss: 0.0005852022586623207, Final Batch Loss: 6.622612272622064e-05\n",
      "Epoch 4866, Loss: 0.00020808043336728588, Final Batch Loss: 7.319759606616572e-05\n",
      "Epoch 4867, Loss: 0.0003838003235614451, Final Batch Loss: 0.00034633875475265086\n",
      "Epoch 4868, Loss: 4.495694963679853e-05, Final Batch Loss: 8.999057854452985e-07\n",
      "Epoch 4869, Loss: 0.00020619450697267894, Final Batch Loss: 0.00011491427721921355\n",
      "Epoch 4870, Loss: 0.0002968059889099095, Final Batch Loss: 5.6881723139667884e-05\n",
      "Epoch 4871, Loss: 7.933075585242477e-05, Final Batch Loss: 6.461437442339957e-05\n",
      "Epoch 4872, Loss: 2.7159117053088266e-05, Final Batch Loss: 3.0643222999060526e-06\n",
      "Epoch 4873, Loss: 0.00014815742270002374, Final Batch Loss: 6.487779501185287e-06\n",
      "Epoch 4874, Loss: 8.575615720474161e-05, Final Batch Loss: 4.0472430555382743e-05\n",
      "Epoch 4875, Loss: 6.484833374997834e-05, Final Batch Loss: 1.0103353815793525e-05\n",
      "Epoch 4876, Loss: 0.000680973889075176, Final Batch Loss: 2.7206890536035644e-06\n",
      "Epoch 4877, Loss: 0.00012536092981463298, Final Batch Loss: 1.8608085156301968e-05\n",
      "Epoch 4878, Loss: 0.00016050007798185106, Final Batch Loss: 7.945254765218124e-05\n",
      "Epoch 4879, Loss: 0.00011351866260156385, Final Batch Loss: 2.0872807908745017e-06\n",
      "Epoch 4880, Loss: 0.000480977185361553, Final Batch Loss: 0.0004177751543466002\n",
      "Epoch 4881, Loss: 8.923618554490531e-05, Final Batch Loss: 1.1920852784896852e-06\n",
      "Epoch 4882, Loss: 5.423735456133727e-05, Final Batch Loss: 5.099806003272533e-06\n",
      "Epoch 4883, Loss: 0.0001321265672231675, Final Batch Loss: 7.845938853279222e-06\n",
      "Epoch 4884, Loss: 0.0005970998545876682, Final Batch Loss: 2.127063112311589e-07\n",
      "Epoch 4885, Loss: 7.678294423385523e-05, Final Batch Loss: 3.553954229573719e-05\n",
      "Epoch 4886, Loss: 0.00011462727314892618, Final Batch Loss: 8.625062832834374e-07\n",
      "Epoch 4887, Loss: 8.823173357086489e-05, Final Batch Loss: 6.602806934097316e-06\n",
      "Epoch 4888, Loss: 5.619263129119645e-05, Final Batch Loss: 6.144425697129918e-06\n",
      "Epoch 4889, Loss: 0.00014221206765796524, Final Batch Loss: 5.060166949988343e-05\n",
      "Epoch 4890, Loss: 0.00021204429867793806, Final Batch Loss: 3.0764163966523483e-05\n",
      "Epoch 4891, Loss: 0.0041647238424502575, Final Batch Loss: 2.7347516606823774e-06\n",
      "Epoch 4892, Loss: 0.00017173639253087458, Final Batch Loss: 1.9049889488087501e-06\n",
      "Epoch 4893, Loss: 0.0002779907426884165, Final Batch Loss: 6.652946467511356e-05\n",
      "Epoch 4894, Loss: 0.000638942330624559, Final Batch Loss: 2.9792392524541356e-05\n",
      "Epoch 4895, Loss: 0.00013274698721943423, Final Batch Loss: 3.5618344554677606e-05\n",
      "Epoch 4896, Loss: 0.0008417811777690076, Final Batch Loss: 7.948329766804818e-06\n",
      "Epoch 4897, Loss: 0.00040487630576535594, Final Batch Loss: 2.2189216906554066e-05\n",
      "Epoch 4898, Loss: 0.0003265472059865715, Final Batch Loss: 0.00020108693570364267\n",
      "Epoch 4899, Loss: 0.00017149469931609929, Final Batch Loss: 9.814997611101717e-05\n",
      "Epoch 4900, Loss: 0.00015713846096332418, Final Batch Loss: 3.4818571293726563e-05\n",
      "Epoch 4901, Loss: 7.703683877480216e-05, Final Batch Loss: 1.1049909517168999e-05\n",
      "Epoch 4902, Loss: 0.00020653990071650696, Final Batch Loss: 7.316143069147074e-07\n",
      "Epoch 4903, Loss: 0.0002651442828209838, Final Batch Loss: 2.2338301278068684e-05\n",
      "Epoch 4904, Loss: 0.00011416978122724686, Final Batch Loss: 6.744183338014409e-05\n",
      "Epoch 4905, Loss: 3.4539942248557054e-05, Final Batch Loss: 9.443148201171425e-07\n",
      "Epoch 4906, Loss: 4.497555232774175e-05, Final Batch Loss: 5.726694780605612e-07\n",
      "Epoch 4907, Loss: 0.0001109620243369136, Final Batch Loss: 4.763372999150306e-06\n",
      "Epoch 4908, Loss: 0.000134313226226368, Final Batch Loss: 8.412582246819511e-05\n",
      "Epoch 4909, Loss: 0.0015126771957056917, Final Batch Loss: 2.725397052927292e-06\n",
      "Epoch 4910, Loss: 0.00010034783008450177, Final Batch Loss: 2.849223164957948e-06\n",
      "Epoch 4911, Loss: 4.6506174385285703e-05, Final Batch Loss: 1.4188094610290136e-06\n",
      "Epoch 4912, Loss: 9.932050670613535e-05, Final Batch Loss: 1.3478113942255732e-05\n",
      "Epoch 4913, Loss: 9.895966604744899e-05, Final Batch Loss: 3.4104366932297125e-05\n",
      "Epoch 4914, Loss: 0.00016458746131320368, Final Batch Loss: 7.5560869845503476e-06\n",
      "Epoch 4915, Loss: 2.7012263217329746e-05, Final Batch Loss: 3.0876049095240887e-06\n",
      "Epoch 4916, Loss: 0.0028044992723152973, Final Batch Loss: 1.5688488929299638e-05\n",
      "Epoch 4917, Loss: 0.00013171644469878174, Final Batch Loss: 1.7530739171434107e-07\n",
      "Epoch 4918, Loss: 0.0002291886485181749, Final Batch Loss: 0.00016240676632151008\n",
      "Epoch 4919, Loss: 6.518299460367416e-05, Final Batch Loss: 6.109190962888533e-06\n",
      "Epoch 4920, Loss: 5.219866420702601e-05, Final Batch Loss: 1.2672380762523971e-05\n",
      "Epoch 4921, Loss: 5.323915188171213e-05, Final Batch Loss: 1.6829521598538122e-07\n",
      "Epoch 4922, Loss: 0.00010509698881833174, Final Batch Loss: 2.5033084511960624e-06\n",
      "Epoch 4923, Loss: 0.0001042593485180987, Final Batch Loss: 6.023064997862093e-06\n",
      "Epoch 4924, Loss: 0.00037752147363789845, Final Batch Loss: 0.00034357953700236976\n",
      "Epoch 4925, Loss: 0.00010231888154521585, Final Batch Loss: 5.1947718020528555e-05\n",
      "Epoch 4926, Loss: 0.0007989544619704247, Final Batch Loss: 2.1947444110992365e-06\n",
      "Epoch 4927, Loss: 1.8141120222026075e-05, Final Batch Loss: 1.035462105392071e-06\n",
      "Epoch 4928, Loss: 0.00016289105042233132, Final Batch Loss: 3.386849130038172e-05\n",
      "Epoch 4929, Loss: 0.002282623752762447, Final Batch Loss: 3.9813305193092674e-05\n",
      "Epoch 4930, Loss: 0.0003191930381944985, Final Batch Loss: 4.718921445601154e-06\n",
      "Epoch 4931, Loss: 0.0004048414921271615, Final Batch Loss: 0.00010708647459978238\n",
      "Epoch 4932, Loss: 0.00017801184071686293, Final Batch Loss: 2.8679630759143038e-06\n",
      "Epoch 4933, Loss: 0.0018497259152354673, Final Batch Loss: 0.0015513775870203972\n",
      "Epoch 4934, Loss: 6.396779826900456e-05, Final Batch Loss: 1.368861376249697e-05\n",
      "Epoch 4935, Loss: 3.801624876587084e-05, Final Batch Loss: 5.492943842000386e-07\n",
      "Epoch 4936, Loss: 0.00013382925612859253, Final Batch Loss: 9.79374135567923e-07\n",
      "Epoch 4937, Loss: 3.187115612490743e-05, Final Batch Loss: 1.3883970950701041e-06\n",
      "Epoch 4938, Loss: 0.00011984374486928573, Final Batch Loss: 9.046506602317095e-05\n",
      "Epoch 4939, Loss: 1.876819487733883e-05, Final Batch Loss: 7.79234596848255e-06\n",
      "Epoch 4940, Loss: 0.00010018834473157767, Final Batch Loss: 1.546314342704136e-05\n",
      "Epoch 4941, Loss: 8.817726052257058e-05, Final Batch Loss: 2.1293192276061745e-06\n",
      "Epoch 4942, Loss: 0.00411722056378494, Final Batch Loss: 0.0040456498973071575\n",
      "Epoch 4943, Loss: 0.0003141374072583858, Final Batch Loss: 6.489893712569028e-05\n",
      "Epoch 4944, Loss: 0.00011492259673673288, Final Batch Loss: 4.3242235392426664e-07\n",
      "Epoch 4945, Loss: 3.1719839277855044e-05, Final Batch Loss: 7.012310732079641e-09\n",
      "Epoch 4946, Loss: 0.0008627788156445604, Final Batch Loss: 0.0007417270680889487\n",
      "Epoch 4947, Loss: 8.802885341196998e-05, Final Batch Loss: 1.2855880981987866e-07\n",
      "Epoch 4948, Loss: 0.0035514610754034948, Final Batch Loss: 4.417709351400845e-05\n",
      "Epoch 4949, Loss: 0.00010955429297609953, Final Batch Loss: 2.6925858946924563e-06\n",
      "Epoch 4950, Loss: 0.00030331334346556105, Final Batch Loss: 0.00016524437523912638\n",
      "Epoch 4951, Loss: 9.612764006305952e-05, Final Batch Loss: 1.6389956726925448e-05\n",
      "Epoch 4952, Loss: 0.00015386899121949682, Final Batch Loss: 6.17035311734071e-06\n",
      "Epoch 4953, Loss: 5.096436325402465e-05, Final Batch Loss: 2.6153265935136005e-05\n",
      "Epoch 4954, Loss: 9.344214277007268e-05, Final Batch Loss: 4.160229764238466e-06\n",
      "Epoch 4955, Loss: 6.655110666997643e-05, Final Batch Loss: 7.40960672374058e-07\n",
      "Epoch 4956, Loss: 0.00013126294925314141, Final Batch Loss: 5.976204920443706e-05\n",
      "Epoch 4957, Loss: 0.0003620687057264149, Final Batch Loss: 5.255284486338496e-05\n",
      "Epoch 4958, Loss: 0.0002604572711106812, Final Batch Loss: 3.132159918095567e-07\n",
      "Epoch 4959, Loss: 0.00010140992890228517, Final Batch Loss: 3.33275856974069e-05\n",
      "Epoch 4960, Loss: 4.048963910463499e-05, Final Batch Loss: 1.6514626622665673e-05\n",
      "Epoch 4961, Loss: 4.677203833125532e-05, Final Batch Loss: 1.4059764907869976e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4962, Loss: 9.278463335249398e-05, Final Batch Loss: 5.048834736953722e-07\n",
      "Epoch 4963, Loss: 7.500520268877153e-05, Final Batch Loss: 1.285567122977227e-06\n",
      "Epoch 4964, Loss: 9.257406009055558e-05, Final Batch Loss: 5.868466814717976e-06\n",
      "Epoch 4965, Loss: 3.518561914006568e-05, Final Batch Loss: 1.5847934264456853e-05\n",
      "Epoch 4966, Loss: 8.713193735587765e-05, Final Batch Loss: 7.947280522557776e-08\n",
      "Epoch 4967, Loss: 0.0036027095497956907, Final Batch Loss: 5.828987468703417e-06\n",
      "Epoch 4968, Loss: 4.7330184088423266e-05, Final Batch Loss: 3.5643322462419746e-06\n",
      "Epoch 4969, Loss: 2.174785981878813e-05, Final Batch Loss: 1.2995956240047235e-06\n",
      "Epoch 4970, Loss: 0.0001583709577062109, Final Batch Loss: 1.4024312804394867e-06\n",
      "Epoch 4971, Loss: 7.709058127147728e-05, Final Batch Loss: 7.256682238221401e-06\n",
      "Epoch 4972, Loss: 3.610251678765053e-05, Final Batch Loss: 1.153908760898048e-05\n",
      "Epoch 4973, Loss: 4.081505994690815e-05, Final Batch Loss: 1.2438778867362998e-05\n",
      "Epoch 4974, Loss: 0.00014127283975540195, Final Batch Loss: 7.96724452811759e-06\n",
      "Epoch 4975, Loss: 7.251295801324886e-05, Final Batch Loss: 4.0763547985989135e-06\n",
      "Epoch 4976, Loss: 4.452515986486105e-05, Final Batch Loss: 2.143587335012853e-05\n",
      "Epoch 4977, Loss: 0.0008777651182754198, Final Batch Loss: 0.0008165580220520496\n",
      "Epoch 4978, Loss: 2.9046519102848833e-05, Final Batch Loss: 5.394321306084748e-06\n",
      "Epoch 4979, Loss: 0.0011355668962096388, Final Batch Loss: 5.611473625322105e-06\n",
      "Epoch 4980, Loss: 4.5961708565300796e-05, Final Batch Loss: 1.43476672747056e-05\n",
      "Epoch 4981, Loss: 8.48085148845712e-05, Final Batch Loss: 1.757707877914072e-06\n",
      "Epoch 4982, Loss: 5.633927958115237e-05, Final Batch Loss: 2.4215014491346665e-06\n",
      "Epoch 4983, Loss: 0.0001548254967929097, Final Batch Loss: 6.387626490322873e-05\n",
      "Epoch 4984, Loss: 0.001878632553598436, Final Batch Loss: 1.7811174984672107e-05\n",
      "Epoch 4985, Loss: 0.00013769427371101983, Final Batch Loss: 6.311076816700734e-08\n",
      "Epoch 4986, Loss: 0.00048001051334267686, Final Batch Loss: 3.365902330187964e-07\n",
      "Epoch 4987, Loss: 0.00013002719958876696, Final Batch Loss: 1.8675517594601843e-06\n",
      "Epoch 4988, Loss: 0.00043231607969573815, Final Batch Loss: 2.8304889383434784e-06\n",
      "Epoch 4989, Loss: 5.291300294629764e-05, Final Batch Loss: 1.1873862604261376e-06\n",
      "Epoch 4990, Loss: 4.136402503718273e-05, Final Batch Loss: 4.2774945541168563e-07\n",
      "Epoch 4991, Loss: 5.333281615094165e-05, Final Batch Loss: 5.270585006655892e-06\n",
      "Epoch 4992, Loss: 3.927149975879729e-05, Final Batch Loss: 8.695102451383718e-07\n",
      "Epoch 4993, Loss: 5.038530071033165e-05, Final Batch Loss: 5.980848072795197e-06\n",
      "Epoch 4994, Loss: 0.00011624190415204794, Final Batch Loss: 1.2388275081320899e-06\n",
      "Epoch 4995, Loss: 0.00022404056232971925, Final Batch Loss: 1.587096789990028e-06\n",
      "Epoch 4996, Loss: 1.721935086607118e-05, Final Batch Loss: 6.226475306903012e-06\n",
      "Epoch 4997, Loss: 0.00013789252943752217, Final Batch Loss: 1.8828617612598464e-05\n",
      "Epoch 4998, Loss: 2.1716949731853674e-05, Final Batch Loss: 9.559987574903062e-07\n",
      "Epoch 4999, Loss: 0.00030690289986523567, Final Batch Loss: 0.0002828201395459473\n",
      "Epoch 5000, Loss: 9.143578245129902e-05, Final Batch Loss: 3.054778426303528e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0  0]\n",
      " [ 0 29  0]\n",
      " [ 0  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        40\n",
      "           1      1.000     1.000     1.000        29\n",
      "           2      1.000     1.000     1.000        29\n",
      "\n",
      "    accuracy                          1.000        98\n",
      "   macro avg      1.000     1.000     1.000        98\n",
      "weighted avg      1.000     1.000     1.000        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../../saved_models/UCI 3 Label 4 Subject Classifier Ablation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
