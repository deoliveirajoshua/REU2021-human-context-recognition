{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '90 tBodyAccJerk-max()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>475 fBodyGyro-bandsEnergy()-1,8</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>382 fBodyAccJerk-bandsEnergy()-1,8</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.839256</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>-0.029411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.854278</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.907561</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.815380</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.910648</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.822905</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>-0.129277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.834215</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  58 tGravityAcc-energy()-Y  \\\n",
       "0                   0.056483             -0.375426                  -0.970905   \n",
       "1                   0.102764             -0.383430                  -0.970583   \n",
       "2                   0.102764             -0.401602                  -0.970368   \n",
       "3                   0.095753             -0.400278                  -0.969400   \n",
       "4                   0.094059             -0.400477                  -0.967051   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.918375   \n",
       "7348               -0.068919             -0.358934                  -0.902880   \n",
       "7349               -0.068919             -0.377025                  -0.907561   \n",
       "7350               -0.040009             -0.440050                  -0.910648   \n",
       "7351               -0.047491             -0.432003                  -0.910579   \n",
       "\n",
       "      59 tGravityAcc-energy()-Z  475 fBodyGyro-bandsEnergy()-1,8  ...  \\\n",
       "0                     -0.975510                        -0.999454  ...   \n",
       "1                     -0.978500                        -0.999856  ...   \n",
       "2                     -0.981672                        -0.999954  ...   \n",
       "3                     -0.982420                        -0.999931  ...   \n",
       "4                     -0.984363                        -0.999926  ...   \n",
       "...                         ...                              ...  ...   \n",
       "7347                  -0.995193                        -0.053258  ...   \n",
       "7348                  -0.995151                        -0.029411  ...   \n",
       "7349                  -0.995450                         0.161404  ...   \n",
       "7350                  -0.998824                         0.193585  ...   \n",
       "7351                  -0.998144                        -0.129277  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      382 fBodyAccJerk-bandsEnergy()-1,8  504 fBodyAccMag-std()  \\\n",
       "0                              -0.999986              -0.956134   \n",
       "1                              -0.999996              -0.975866   \n",
       "2                              -0.999994              -0.989015   \n",
       "3                              -0.999998              -0.986742   \n",
       "4                              -0.999995              -0.990063   \n",
       "...                                  ...                    ...   \n",
       "7347                           -0.839256              -0.232600   \n",
       "7348                           -0.854278              -0.275373   \n",
       "7349                           -0.815380              -0.220288   \n",
       "7350                           -0.822905              -0.234539   \n",
       "7351                           -0.834215              -0.342670   \n",
       "\n",
       "      505 fBodyAccMag-mad()  509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                 -0.948870                 -0.998285         5        1  \n",
       "1                 -0.975777                 -0.999472         5        1  \n",
       "2                 -0.985594                 -0.999807         5        1  \n",
       "3                 -0.983524                 -0.999770         5        1  \n",
       "4                 -0.992324                 -0.999873         5        1  \n",
       "...                     ...                       ...       ...      ...  \n",
       "7347              -0.007392                 -0.584282         2       30  \n",
       "7348              -0.172448                 -0.632536         2       30  \n",
       "7349              -0.216074                 -0.641170         2       30  \n",
       "7350              -0.220443                 -0.663579         2       30  \n",
       "7351              -0.146649                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.457769393920898, Final Batch Loss: 1.146440863609314\n",
      "Epoch 2, Loss: 4.390068173408508, Final Batch Loss: 1.069634199142456\n",
      "Epoch 3, Loss: 4.412440180778503, Final Batch Loss: 1.1101917028427124\n",
      "Epoch 4, Loss: 4.375040411949158, Final Batch Loss: 1.0773537158966064\n",
      "Epoch 5, Loss: 4.371672630310059, Final Batch Loss: 1.0861682891845703\n",
      "Epoch 6, Loss: 4.372067332267761, Final Batch Loss: 1.107374906539917\n",
      "Epoch 7, Loss: 4.328176975250244, Final Batch Loss: 1.0817281007766724\n",
      "Epoch 8, Loss: 4.303474068641663, Final Batch Loss: 1.0794011354446411\n",
      "Epoch 9, Loss: 4.231568694114685, Final Batch Loss: 1.0335440635681152\n",
      "Epoch 10, Loss: 4.207246422767639, Final Batch Loss: 1.0552442073822021\n",
      "Epoch 11, Loss: 4.145345091819763, Final Batch Loss: 1.0586446523666382\n",
      "Epoch 12, Loss: 4.047257900238037, Final Batch Loss: 1.0281922817230225\n",
      "Epoch 13, Loss: 3.916011691093445, Final Batch Loss: 0.9660921692848206\n",
      "Epoch 14, Loss: 3.7454282641410828, Final Batch Loss: 0.9128726124763489\n",
      "Epoch 15, Loss: 3.544351100921631, Final Batch Loss: 0.8334714770317078\n",
      "Epoch 16, Loss: 3.3798094391822815, Final Batch Loss: 0.7951186299324036\n",
      "Epoch 17, Loss: 3.1528669595718384, Final Batch Loss: 0.7471373081207275\n",
      "Epoch 18, Loss: 3.0108503699302673, Final Batch Loss: 0.7516656517982483\n",
      "Epoch 19, Loss: 2.7744359970092773, Final Batch Loss: 0.6333004236221313\n",
      "Epoch 20, Loss: 2.6375938653945923, Final Batch Loss: 0.6487932801246643\n",
      "Epoch 21, Loss: 2.4967989921569824, Final Batch Loss: 0.5657849311828613\n",
      "Epoch 22, Loss: 2.410022556781769, Final Batch Loss: 0.6045045256614685\n",
      "Epoch 23, Loss: 2.366131544113159, Final Batch Loss: 0.6085731983184814\n",
      "Epoch 24, Loss: 2.196958541870117, Final Batch Loss: 0.4728504419326782\n",
      "Epoch 25, Loss: 2.0498918890953064, Final Batch Loss: 0.42595207691192627\n",
      "Epoch 26, Loss: 2.084188997745514, Final Batch Loss: 0.5253766179084778\n",
      "Epoch 27, Loss: 1.9743047058582306, Final Batch Loss: 0.4547456204891205\n",
      "Epoch 28, Loss: 1.9786668419837952, Final Batch Loss: 0.504985511302948\n",
      "Epoch 29, Loss: 1.8695033490657806, Final Batch Loss: 0.44779035449028015\n",
      "Epoch 30, Loss: 1.8430227637290955, Final Batch Loss: 0.46060165762901306\n",
      "Epoch 31, Loss: 1.7919408679008484, Final Batch Loss: 0.5086638331413269\n",
      "Epoch 32, Loss: 1.5571779012680054, Final Batch Loss: 0.3766312599182129\n",
      "Epoch 33, Loss: 1.4778913259506226, Final Batch Loss: 0.3399921953678131\n",
      "Epoch 34, Loss: 1.3917046189308167, Final Batch Loss: 0.3493318259716034\n",
      "Epoch 35, Loss: 1.2401919960975647, Final Batch Loss: 0.28805994987487793\n",
      "Epoch 36, Loss: 1.1787849366664886, Final Batch Loss: 0.31264054775238037\n",
      "Epoch 37, Loss: 1.0365987867116928, Final Batch Loss: 0.27758732438087463\n",
      "Epoch 38, Loss: 1.0027316510677338, Final Batch Loss: 0.18642354011535645\n",
      "Epoch 39, Loss: 0.9857282638549805, Final Batch Loss: 0.2732512652873993\n",
      "Epoch 40, Loss: 0.7793144583702087, Final Batch Loss: 0.1448449045419693\n",
      "Epoch 41, Loss: 0.823223352432251, Final Batch Loss: 0.27334198355674744\n",
      "Epoch 42, Loss: 0.7143327370285988, Final Batch Loss: 0.07128279656171799\n",
      "Epoch 43, Loss: 0.7215532064437866, Final Batch Loss: 0.18919657170772552\n",
      "Epoch 44, Loss: 0.6093064546585083, Final Batch Loss: 0.1397545486688614\n",
      "Epoch 45, Loss: 0.6907530575990677, Final Batch Loss: 0.14911533892154694\n",
      "Epoch 46, Loss: 0.6123333722352982, Final Batch Loss: 0.17768919467926025\n",
      "Epoch 47, Loss: 0.5679415240883827, Final Batch Loss: 0.12048458307981491\n",
      "Epoch 48, Loss: 0.5589938536286354, Final Batch Loss: 0.09217482060194016\n",
      "Epoch 49, Loss: 0.5890573561191559, Final Batch Loss: 0.1479102224111557\n",
      "Epoch 50, Loss: 0.6848600655794144, Final Batch Loss: 0.22173570096492767\n",
      "Epoch 51, Loss: 0.526072695851326, Final Batch Loss: 0.15353260934352875\n",
      "Epoch 52, Loss: 0.5585770756006241, Final Batch Loss: 0.13524040579795837\n",
      "Epoch 53, Loss: 0.6379821598529816, Final Batch Loss: 0.19935089349746704\n",
      "Epoch 54, Loss: 0.5584976002573967, Final Batch Loss: 0.1578952521085739\n",
      "Epoch 55, Loss: 0.4700872004032135, Final Batch Loss: 0.07618305832147598\n",
      "Epoch 56, Loss: 0.44263357669115067, Final Batch Loss: 0.08774682879447937\n",
      "Epoch 57, Loss: 0.45200004428625107, Final Batch Loss: 0.09727775305509567\n",
      "Epoch 58, Loss: 0.48947589844465256, Final Batch Loss: 0.06592471897602081\n",
      "Epoch 59, Loss: 0.4797976240515709, Final Batch Loss: 0.10687211900949478\n",
      "Epoch 60, Loss: 0.4969946816563606, Final Batch Loss: 0.09268929809331894\n",
      "Epoch 61, Loss: 0.5466190055012703, Final Batch Loss: 0.19446778297424316\n",
      "Epoch 62, Loss: 0.5368311554193497, Final Batch Loss: 0.19492606818675995\n",
      "Epoch 63, Loss: 0.4511698707938194, Final Batch Loss: 0.1483098566532135\n",
      "Epoch 64, Loss: 0.4340536817908287, Final Batch Loss: 0.08537954837083817\n",
      "Epoch 65, Loss: 0.3823383152484894, Final Batch Loss: 0.06753790378570557\n",
      "Epoch 66, Loss: 0.4362516328692436, Final Batch Loss: 0.07483837753534317\n",
      "Epoch 67, Loss: 0.40937767177820206, Final Batch Loss: 0.10603813081979752\n",
      "Epoch 68, Loss: 0.37324705347418785, Final Batch Loss: 0.04657312110066414\n",
      "Epoch 69, Loss: 0.4907916262745857, Final Batch Loss: 0.20719677209854126\n",
      "Epoch 70, Loss: 0.4525297209620476, Final Batch Loss: 0.13641871511936188\n",
      "Epoch 71, Loss: 0.31305335089564323, Final Batch Loss: 0.04439309611916542\n",
      "Epoch 72, Loss: 0.3473978377878666, Final Batch Loss: 0.08868485689163208\n",
      "Epoch 73, Loss: 0.3543616086244583, Final Batch Loss: 0.1065286174416542\n",
      "Epoch 74, Loss: 0.32811593264341354, Final Batch Loss: 0.07511571049690247\n",
      "Epoch 75, Loss: 0.3819598853588104, Final Batch Loss: 0.10640659183263779\n",
      "Epoch 76, Loss: 0.29576741345226765, Final Batch Loss: 0.026848332956433296\n",
      "Epoch 77, Loss: 0.38430447317659855, Final Batch Loss: 0.023145871236920357\n",
      "Epoch 78, Loss: 0.4115671142935753, Final Batch Loss: 0.13623826205730438\n",
      "Epoch 79, Loss: 0.28987571224570274, Final Batch Loss: 0.03630363568663597\n",
      "Epoch 80, Loss: 0.2776442412286997, Final Batch Loss: 0.021969256922602654\n",
      "Epoch 81, Loss: 0.29156068339943886, Final Batch Loss: 0.04888894036412239\n",
      "Epoch 82, Loss: 0.3192916177213192, Final Batch Loss: 0.06079631671309471\n",
      "Epoch 83, Loss: 0.36036907136440277, Final Batch Loss: 0.09792501479387283\n",
      "Epoch 84, Loss: 0.3059437908232212, Final Batch Loss: 0.04716486111283302\n",
      "Epoch 85, Loss: 0.3371395096182823, Final Batch Loss: 0.05130364000797272\n",
      "Epoch 86, Loss: 0.3095231056213379, Final Batch Loss: 0.07979586720466614\n",
      "Epoch 87, Loss: 0.28341737389564514, Final Batch Loss: 0.03194138780236244\n",
      "Epoch 88, Loss: 0.3868025690317154, Final Batch Loss: 0.13175860047340393\n",
      "Epoch 89, Loss: 0.3387359753251076, Final Batch Loss: 0.07553727924823761\n",
      "Epoch 90, Loss: 0.3015480414032936, Final Batch Loss: 0.09338375180959702\n",
      "Epoch 91, Loss: 0.41798555478453636, Final Batch Loss: 0.20836015045642853\n",
      "Epoch 92, Loss: 0.28519999794662, Final Batch Loss: 0.02633029781281948\n",
      "Epoch 93, Loss: 0.270555105060339, Final Batch Loss: 0.040293220430612564\n",
      "Epoch 94, Loss: 0.3029472455382347, Final Batch Loss: 0.03151316195726395\n",
      "Epoch 95, Loss: 0.2785322293639183, Final Batch Loss: 0.06369780749082565\n",
      "Epoch 96, Loss: 0.2573189549148083, Final Batch Loss: 0.03514901176095009\n",
      "Epoch 97, Loss: 0.2619365584105253, Final Batch Loss: 0.0260754581540823\n",
      "Epoch 98, Loss: 0.2622533030807972, Final Batch Loss: 0.028833642601966858\n",
      "Epoch 99, Loss: 0.314100356772542, Final Batch Loss: 0.026127846911549568\n",
      "Epoch 100, Loss: 0.2465699315071106, Final Batch Loss: 0.02421446703374386\n",
      "Epoch 101, Loss: 0.37814347818493843, Final Batch Loss: 0.16132105886936188\n",
      "Epoch 102, Loss: 0.3662646785378456, Final Batch Loss: 0.15135295689105988\n",
      "Epoch 103, Loss: 0.27812138199806213, Final Batch Loss: 0.02495887130498886\n",
      "Epoch 104, Loss: 0.34259123355150223, Final Batch Loss: 0.12291816622018814\n",
      "Epoch 105, Loss: 0.2964939810335636, Final Batch Loss: 0.11368296295404434\n",
      "Epoch 106, Loss: 0.2581129912286997, Final Batch Loss: 0.023622246459126472\n",
      "Epoch 107, Loss: 0.2843690663576126, Final Batch Loss: 0.042000044137239456\n",
      "Epoch 108, Loss: 0.22695329412817955, Final Batch Loss: 0.04711243137717247\n",
      "Epoch 109, Loss: 0.25205037649720907, Final Batch Loss: 0.010899308137595654\n",
      "Epoch 110, Loss: 0.3096016235649586, Final Batch Loss: 0.10372460633516312\n",
      "Epoch 111, Loss: 0.4590310677886009, Final Batch Loss: 0.2779446244239807\n",
      "Epoch 112, Loss: 0.42811252921819687, Final Batch Loss: 0.23452357947826385\n",
      "Epoch 113, Loss: 0.2524130456149578, Final Batch Loss: 0.034777771681547165\n",
      "Epoch 114, Loss: 0.2757770325988531, Final Batch Loss: 0.020254893228411674\n",
      "Epoch 115, Loss: 0.2518256679177284, Final Batch Loss: 0.03710158169269562\n",
      "Epoch 116, Loss: 0.3049333728849888, Final Batch Loss: 0.08676011115312576\n",
      "Epoch 117, Loss: 0.2326258420944214, Final Batch Loss: 0.015630528330802917\n",
      "Epoch 118, Loss: 0.2690579406917095, Final Batch Loss: 0.05479249358177185\n",
      "Epoch 119, Loss: 0.22487953305244446, Final Batch Loss: 0.03550250828266144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss: 0.2451737094670534, Final Batch Loss: 0.010310972109436989\n",
      "Epoch 121, Loss: 0.24262148886919022, Final Batch Loss: 0.052426036447286606\n",
      "Epoch 122, Loss: 0.22171949967741966, Final Batch Loss: 0.031474266201257706\n",
      "Epoch 123, Loss: 0.2834993340075016, Final Batch Loss: 0.09172043204307556\n",
      "Epoch 124, Loss: 0.23817967996001244, Final Batch Loss: 0.06899315863847733\n",
      "Epoch 125, Loss: 0.3495092839002609, Final Batch Loss: 0.12502041459083557\n",
      "Epoch 126, Loss: 0.28057385608553886, Final Batch Loss: 0.039726417511701584\n",
      "Epoch 127, Loss: 0.24902889039367437, Final Batch Loss: 0.009856908582150936\n",
      "Epoch 128, Loss: 0.2017357274889946, Final Batch Loss: 0.011057410389184952\n",
      "Epoch 129, Loss: 0.21373450569808483, Final Batch Loss: 0.017132816836237907\n",
      "Epoch 130, Loss: 0.21426062658429146, Final Batch Loss: 0.01968548819422722\n",
      "Epoch 131, Loss: 0.19799176044762135, Final Batch Loss: 0.022607414051890373\n",
      "Epoch 132, Loss: 0.2573509179055691, Final Batch Loss: 0.06338771432638168\n",
      "Epoch 133, Loss: 0.2533150166273117, Final Batch Loss: 0.05457499995827675\n",
      "Epoch 134, Loss: 0.2280743159353733, Final Batch Loss: 0.06015031412243843\n",
      "Epoch 135, Loss: 0.28402394242584705, Final Batch Loss: 0.12851464748382568\n",
      "Epoch 136, Loss: 0.25416444800794125, Final Batch Loss: 0.02614273875951767\n",
      "Epoch 137, Loss: 0.22156352642923594, Final Batch Loss: 0.013993632979691029\n",
      "Epoch 138, Loss: 0.29430217295885086, Final Batch Loss: 0.08738645166158676\n",
      "Epoch 139, Loss: 0.24373956583440304, Final Batch Loss: 0.03005494736135006\n",
      "Epoch 140, Loss: 0.22980585601180792, Final Batch Loss: 0.008846837095916271\n",
      "Epoch 141, Loss: 0.22548915073275566, Final Batch Loss: 0.034951597452163696\n",
      "Epoch 142, Loss: 0.2774157263338566, Final Batch Loss: 0.09914620965719223\n",
      "Epoch 143, Loss: 0.2195247858762741, Final Batch Loss: 0.026755833998322487\n",
      "Epoch 144, Loss: 0.1749743428081274, Final Batch Loss: 0.015943830832839012\n",
      "Epoch 145, Loss: 0.2024780474603176, Final Batch Loss: 0.040077921003103256\n",
      "Epoch 146, Loss: 0.332640390843153, Final Batch Loss: 0.14849568903446198\n",
      "Epoch 147, Loss: 0.2270895503461361, Final Batch Loss: 0.07052827626466751\n",
      "Epoch 148, Loss: 0.19140522554516792, Final Batch Loss: 0.019644642248749733\n",
      "Epoch 149, Loss: 0.20299681555479765, Final Batch Loss: 0.012492253445088863\n",
      "Epoch 150, Loss: 0.4104926846921444, Final Batch Loss: 0.24742288887500763\n",
      "Epoch 151, Loss: 0.22722062841057777, Final Batch Loss: 0.04406076669692993\n",
      "Epoch 152, Loss: 0.2508401907980442, Final Batch Loss: 0.056683897972106934\n",
      "Epoch 153, Loss: 0.26118213683366776, Final Batch Loss: 0.12508060038089752\n",
      "Epoch 154, Loss: 0.22057382576167583, Final Batch Loss: 0.02830430306494236\n",
      "Epoch 155, Loss: 0.19335022661834955, Final Batch Loss: 0.015087795443832874\n",
      "Epoch 156, Loss: 0.2287965603172779, Final Batch Loss: 0.04780510067939758\n",
      "Epoch 157, Loss: 0.24966275319457054, Final Batch Loss: 0.06307249516248703\n",
      "Epoch 158, Loss: 0.23400313034653664, Final Batch Loss: 0.06448028236627579\n",
      "Epoch 159, Loss: 0.2243169117718935, Final Batch Loss: 0.045889463275671005\n",
      "Epoch 160, Loss: 0.3020087778568268, Final Batch Loss: 0.09027084708213806\n",
      "Epoch 161, Loss: 0.2260279320180416, Final Batch Loss: 0.02282387763261795\n",
      "Epoch 162, Loss: 0.29797351360321045, Final Batch Loss: 0.0887095108628273\n",
      "Epoch 163, Loss: 0.18414228409528732, Final Batch Loss: 0.01991896517574787\n",
      "Epoch 164, Loss: 0.22377720475196838, Final Batch Loss: 0.035459693521261215\n",
      "Epoch 165, Loss: 0.18603953160345554, Final Batch Loss: 0.016289083287119865\n",
      "Epoch 166, Loss: 0.21622661128640175, Final Batch Loss: 0.018631018698215485\n",
      "Epoch 167, Loss: 0.29187846183776855, Final Batch Loss: 0.09670590609312057\n",
      "Epoch 168, Loss: 0.21817488595843315, Final Batch Loss: 0.025601409375667572\n",
      "Epoch 169, Loss: 0.18350119329988956, Final Batch Loss: 0.027857428416609764\n",
      "Epoch 170, Loss: 0.2021805625408888, Final Batch Loss: 0.020253727212548256\n",
      "Epoch 171, Loss: 0.18900611251592636, Final Batch Loss: 0.020660893991589546\n",
      "Epoch 172, Loss: 0.18940744176506996, Final Batch Loss: 0.03167212754487991\n",
      "Epoch 173, Loss: 0.19222511537373066, Final Batch Loss: 0.01785486750304699\n",
      "Epoch 174, Loss: 0.17540405318140984, Final Batch Loss: 0.023172779008746147\n",
      "Epoch 175, Loss: 0.24400199949741364, Final Batch Loss: 0.06471581012010574\n",
      "Epoch 176, Loss: 0.17894252762198448, Final Batch Loss: 0.019893277436494827\n",
      "Epoch 177, Loss: 0.2619224414229393, Final Batch Loss: 0.10548920184373856\n",
      "Epoch 178, Loss: 0.18229779321700335, Final Batch Loss: 0.012770180590450764\n",
      "Epoch 179, Loss: 0.21410707011818886, Final Batch Loss: 0.05621546134352684\n",
      "Epoch 180, Loss: 0.20281298831105232, Final Batch Loss: 0.030808554962277412\n",
      "Epoch 181, Loss: 0.33189390785992146, Final Batch Loss: 0.2005639672279358\n",
      "Epoch 182, Loss: 0.17969535384327173, Final Batch Loss: 0.010616854764521122\n",
      "Epoch 183, Loss: 0.22810603491961956, Final Batch Loss: 0.09812667220830917\n",
      "Epoch 184, Loss: 0.16946355067193508, Final Batch Loss: 0.01737404800951481\n",
      "Epoch 185, Loss: 0.1930593177676201, Final Batch Loss: 0.033141035586595535\n",
      "Epoch 186, Loss: 0.19302266277372837, Final Batch Loss: 0.021864673122763634\n",
      "Epoch 187, Loss: 0.14521253341808915, Final Batch Loss: 0.004825665149837732\n",
      "Epoch 188, Loss: 0.19806914404034615, Final Batch Loss: 0.04089922085404396\n",
      "Epoch 189, Loss: 0.1656841803342104, Final Batch Loss: 0.02417961321771145\n",
      "Epoch 190, Loss: 0.18247588723897934, Final Batch Loss: 0.02332005836069584\n",
      "Epoch 191, Loss: 0.19663015380501747, Final Batch Loss: 0.08969520777463913\n",
      "Epoch 192, Loss: 0.17801862955093384, Final Batch Loss: 0.012523896992206573\n",
      "Epoch 193, Loss: 0.2896316070109606, Final Batch Loss: 0.12358408421278\n",
      "Epoch 194, Loss: 0.18689298257231712, Final Batch Loss: 0.03402077034115791\n",
      "Epoch 195, Loss: 0.17053579166531563, Final Batch Loss: 0.04838058352470398\n",
      "Epoch 196, Loss: 0.23647796176373959, Final Batch Loss: 0.0838121697306633\n",
      "Epoch 197, Loss: 0.29189271107316017, Final Batch Loss: 0.1564430445432663\n",
      "Epoch 198, Loss: 0.21625985763967037, Final Batch Loss: 0.07423178106546402\n",
      "Epoch 199, Loss: 0.18036007694900036, Final Batch Loss: 0.027175530791282654\n",
      "Epoch 200, Loss: 0.1825730511918664, Final Batch Loss: 0.0115886265411973\n",
      "Epoch 201, Loss: 0.2483961097896099, Final Batch Loss: 0.09626784175634384\n",
      "Epoch 202, Loss: 0.18801402114331722, Final Batch Loss: 0.017209874466061592\n",
      "Epoch 203, Loss: 0.170950248837471, Final Batch Loss: 0.022383451461791992\n",
      "Epoch 204, Loss: 0.20642300695180893, Final Batch Loss: 0.060554951429367065\n",
      "Epoch 205, Loss: 0.30497184954583645, Final Batch Loss: 0.1861788034439087\n",
      "Epoch 206, Loss: 0.21428260579705238, Final Batch Loss: 0.037759970873594284\n",
      "Epoch 207, Loss: 0.18386769760400057, Final Batch Loss: 0.009636941365897655\n",
      "Epoch 208, Loss: 0.15423011034727097, Final Batch Loss: 0.010740313678979874\n",
      "Epoch 209, Loss: 0.18044024799019098, Final Batch Loss: 0.015504282899200916\n",
      "Epoch 210, Loss: 0.21613657101988792, Final Batch Loss: 0.08784403651952744\n",
      "Epoch 211, Loss: 0.1837653173133731, Final Batch Loss: 0.009663580916821957\n",
      "Epoch 212, Loss: 0.22567962855100632, Final Batch Loss: 0.06541244685649872\n",
      "Epoch 213, Loss: 0.19600405544042587, Final Batch Loss: 0.054841041564941406\n",
      "Epoch 214, Loss: 0.13440739084035158, Final Batch Loss: 0.01385276485234499\n",
      "Epoch 215, Loss: 0.19301814958453178, Final Batch Loss: 0.034702807664871216\n",
      "Epoch 216, Loss: 0.22446878626942635, Final Batch Loss: 0.05751820281147957\n",
      "Epoch 217, Loss: 0.18892121873795986, Final Batch Loss: 0.026507338508963585\n",
      "Epoch 218, Loss: 0.2805480733513832, Final Batch Loss: 0.12009220570325851\n",
      "Epoch 219, Loss: 0.3424715790897608, Final Batch Loss: 0.2260085493326187\n",
      "Epoch 220, Loss: 0.15461807418614626, Final Batch Loss: 0.01229331735521555\n",
      "Epoch 221, Loss: 0.27775445580482483, Final Batch Loss: 0.11091900616884232\n",
      "Epoch 222, Loss: 0.17691903747618198, Final Batch Loss: 0.02860977314412594\n",
      "Epoch 223, Loss: 0.20813502371311188, Final Batch Loss: 0.06871003657579422\n",
      "Epoch 224, Loss: 0.24167700856924057, Final Batch Loss: 0.08788660913705826\n",
      "Epoch 225, Loss: 0.22464949265122414, Final Batch Loss: 0.1003442108631134\n",
      "Epoch 226, Loss: 0.16312466003000736, Final Batch Loss: 0.026048114523291588\n",
      "Epoch 227, Loss: 0.1637207679450512, Final Batch Loss: 0.02210104465484619\n",
      "Epoch 228, Loss: 0.16940409503877163, Final Batch Loss: 0.050036411732435226\n",
      "Epoch 229, Loss: 0.2366901971399784, Final Batch Loss: 0.09838327765464783\n",
      "Epoch 230, Loss: 0.18585887365043163, Final Batch Loss: 0.023202145472168922\n",
      "Epoch 231, Loss: 0.14157059136778116, Final Batch Loss: 0.015773048624396324\n",
      "Epoch 232, Loss: 0.14617400150746107, Final Batch Loss: 0.011989387683570385\n",
      "Epoch 233, Loss: 0.17792438343167305, Final Batch Loss: 0.039176348596811295\n",
      "Epoch 234, Loss: 0.22506865113973618, Final Batch Loss: 0.10145183652639389\n",
      "Epoch 235, Loss: 0.20678602531552315, Final Batch Loss: 0.07357067614793777\n",
      "Epoch 236, Loss: 0.31352788023650646, Final Batch Loss: 0.16302968561649323\n",
      "Epoch 237, Loss: 0.1771331112831831, Final Batch Loss: 0.06512212008237839\n",
      "Epoch 238, Loss: 0.2248685620725155, Final Batch Loss: 0.11031480878591537\n",
      "Epoch 239, Loss: 0.28950411826372147, Final Batch Loss: 0.1501275897026062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss: 0.19685936719179153, Final Batch Loss: 0.060843680053949356\n",
      "Epoch 241, Loss: 0.1426277793943882, Final Batch Loss: 0.00837700068950653\n",
      "Epoch 242, Loss: 0.22459707222878933, Final Batch Loss: 0.1098017692565918\n",
      "Epoch 243, Loss: 0.16121829114854336, Final Batch Loss: 0.0213553998619318\n",
      "Epoch 244, Loss: 0.2507699355483055, Final Batch Loss: 0.10820525884628296\n",
      "Epoch 245, Loss: 0.1835449580103159, Final Batch Loss: 0.017953665927052498\n",
      "Epoch 246, Loss: 0.16560995299369097, Final Batch Loss: 0.013411336578428745\n",
      "Epoch 247, Loss: 0.22994307801127434, Final Batch Loss: 0.10204612463712692\n",
      "Epoch 248, Loss: 0.15199083648622036, Final Batch Loss: 0.04352225735783577\n",
      "Epoch 249, Loss: 0.1473011216148734, Final Batch Loss: 0.01102957408875227\n",
      "Epoch 250, Loss: 0.19139580987393856, Final Batch Loss: 0.09389414638280869\n",
      "Epoch 251, Loss: 0.12329406477510929, Final Batch Loss: 0.013445589691400528\n",
      "Epoch 252, Loss: 0.27673517540097237, Final Batch Loss: 0.14980274438858032\n",
      "Epoch 253, Loss: 0.20231955125927925, Final Batch Loss: 0.05724802985787392\n",
      "Epoch 254, Loss: 0.1476300023496151, Final Batch Loss: 0.02918258309364319\n",
      "Epoch 255, Loss: 0.2495767418295145, Final Batch Loss: 0.12647531926631927\n",
      "Epoch 256, Loss: 0.22512187249958515, Final Batch Loss: 0.1070285439491272\n",
      "Epoch 257, Loss: 0.26211866084486246, Final Batch Loss: 0.1484532505273819\n",
      "Epoch 258, Loss: 0.21509752608835697, Final Batch Loss: 0.09309575706720352\n",
      "Epoch 259, Loss: 0.16480985097587109, Final Batch Loss: 0.015423941425979137\n",
      "Epoch 260, Loss: 0.15623680129647255, Final Batch Loss: 0.018135525286197662\n",
      "Epoch 261, Loss: 0.14273656997829676, Final Batch Loss: 0.013589718379080296\n",
      "Epoch 262, Loss: 0.21839657984673977, Final Batch Loss: 0.093517005443573\n",
      "Epoch 263, Loss: 0.13495234120637178, Final Batch Loss: 0.004811112768948078\n",
      "Epoch 264, Loss: 0.12155172601342201, Final Batch Loss: 0.003833198919892311\n",
      "Epoch 265, Loss: 0.13623581361025572, Final Batch Loss: 0.014325299300253391\n",
      "Epoch 266, Loss: 0.14712518267333508, Final Batch Loss: 0.017443403601646423\n",
      "Epoch 267, Loss: 0.1816945131868124, Final Batch Loss: 0.04804642125964165\n",
      "Epoch 268, Loss: 0.14182166196405888, Final Batch Loss: 0.007028080523014069\n",
      "Epoch 269, Loss: 0.15732324682176113, Final Batch Loss: 0.02557866834104061\n",
      "Epoch 270, Loss: 0.13425706792622805, Final Batch Loss: 0.012426109053194523\n",
      "Epoch 271, Loss: 0.13407432287931442, Final Batch Loss: 0.020282676443457603\n",
      "Epoch 272, Loss: 0.21389433927834034, Final Batch Loss: 0.08045538514852524\n",
      "Epoch 273, Loss: 0.11764703877270222, Final Batch Loss: 0.019918758422136307\n",
      "Epoch 274, Loss: 0.22504282277077436, Final Batch Loss: 0.09487199783325195\n",
      "Epoch 275, Loss: 0.19536278769373894, Final Batch Loss: 0.017440728843212128\n",
      "Epoch 276, Loss: 0.15508820675313473, Final Batch Loss: 0.02199726365506649\n",
      "Epoch 277, Loss: 0.16723251529037952, Final Batch Loss: 0.028499962761998177\n",
      "Epoch 278, Loss: 0.14733368903398514, Final Batch Loss: 0.03263891860842705\n",
      "Epoch 279, Loss: 0.2092765048146248, Final Batch Loss: 0.12265539169311523\n",
      "Epoch 280, Loss: 0.17767116986215115, Final Batch Loss: 0.0526854544878006\n",
      "Epoch 281, Loss: 0.18982211872935295, Final Batch Loss: 0.08260080218315125\n",
      "Epoch 282, Loss: 0.1669371984899044, Final Batch Loss: 0.022211095318198204\n",
      "Epoch 283, Loss: 0.1683469321578741, Final Batch Loss: 0.050333812832832336\n",
      "Epoch 284, Loss: 0.1528490255586803, Final Batch Loss: 0.005886866245418787\n",
      "Epoch 285, Loss: 0.13233928009867668, Final Batch Loss: 0.010478958487510681\n",
      "Epoch 286, Loss: 0.1570254359394312, Final Batch Loss: 0.020559312775731087\n",
      "Epoch 287, Loss: 0.2422325573861599, Final Batch Loss: 0.1206052303314209\n",
      "Epoch 288, Loss: 0.13032632414251566, Final Batch Loss: 0.014315218664705753\n",
      "Epoch 289, Loss: 0.20606277510523796, Final Batch Loss: 0.0840141773223877\n",
      "Epoch 290, Loss: 0.15366875007748604, Final Batch Loss: 0.029413970187306404\n",
      "Epoch 291, Loss: 0.1431387485936284, Final Batch Loss: 0.009473969228565693\n",
      "Epoch 292, Loss: 0.13141962885856628, Final Batch Loss: 0.02231297828257084\n",
      "Epoch 293, Loss: 0.23011036589741707, Final Batch Loss: 0.11416241526603699\n",
      "Epoch 294, Loss: 0.14907237142324448, Final Batch Loss: 0.01676965318620205\n",
      "Epoch 295, Loss: 0.11984788021072745, Final Batch Loss: 0.006666784640401602\n",
      "Epoch 296, Loss: 0.13008176861330867, Final Batch Loss: 0.007770467083901167\n",
      "Epoch 297, Loss: 0.2327411286532879, Final Batch Loss: 0.12514205276966095\n",
      "Epoch 298, Loss: 0.1510651484131813, Final Batch Loss: 0.01628153957426548\n",
      "Epoch 299, Loss: 0.20931168645620346, Final Batch Loss: 0.09459001570940018\n",
      "Epoch 300, Loss: 0.15872518811374903, Final Batch Loss: 0.010365339927375317\n",
      "Epoch 301, Loss: 0.1302698291838169, Final Batch Loss: 0.016155550256371498\n",
      "Epoch 302, Loss: 0.1297851549461484, Final Batch Loss: 0.014036801643669605\n",
      "Epoch 303, Loss: 0.13821812719106674, Final Batch Loss: 0.006242077797651291\n",
      "Epoch 304, Loss: 0.17386209033429623, Final Batch Loss: 0.06665340811014175\n",
      "Epoch 305, Loss: 0.14182649366557598, Final Batch Loss: 0.059681449085474014\n",
      "Epoch 306, Loss: 0.11976316012442112, Final Batch Loss: 0.010642041452229023\n",
      "Epoch 307, Loss: 0.1489025317132473, Final Batch Loss: 0.02499491721391678\n",
      "Epoch 308, Loss: 0.22207037825137377, Final Batch Loss: 0.1341821700334549\n",
      "Epoch 309, Loss: 0.1298733693547547, Final Batch Loss: 0.0054084123112261295\n",
      "Epoch 310, Loss: 0.1315221507102251, Final Batch Loss: 0.014771156013011932\n",
      "Epoch 311, Loss: 0.1287325583398342, Final Batch Loss: 0.011424470692873001\n",
      "Epoch 312, Loss: 0.14553546719253063, Final Batch Loss: 0.01641002483665943\n",
      "Epoch 313, Loss: 0.18847172521054745, Final Batch Loss: 0.060018960386514664\n",
      "Epoch 314, Loss: 0.11562765808776021, Final Batch Loss: 0.004763318691402674\n",
      "Epoch 315, Loss: 0.19981087744235992, Final Batch Loss: 0.09975874423980713\n",
      "Epoch 316, Loss: 0.13400239869952202, Final Batch Loss: 0.00920187123119831\n",
      "Epoch 317, Loss: 0.12305639800615609, Final Batch Loss: 0.0029459011275321245\n",
      "Epoch 318, Loss: 0.11922107450664043, Final Batch Loss: 0.01683320663869381\n",
      "Epoch 319, Loss: 0.13668236369267106, Final Batch Loss: 0.005604133475571871\n",
      "Epoch 320, Loss: 0.14623919315636158, Final Batch Loss: 0.03315548598766327\n",
      "Epoch 321, Loss: 0.11693706549704075, Final Batch Loss: 0.011420543305575848\n",
      "Epoch 322, Loss: 0.13202545512467623, Final Batch Loss: 0.010783902369439602\n",
      "Epoch 323, Loss: 0.11447877157479525, Final Batch Loss: 0.009248572401702404\n",
      "Epoch 324, Loss: 0.1196686215698719, Final Batch Loss: 0.011467565782368183\n",
      "Epoch 325, Loss: 0.1270275665447116, Final Batch Loss: 0.010771694593131542\n",
      "Epoch 326, Loss: 0.18846164271235466, Final Batch Loss: 0.09142271429300308\n",
      "Epoch 327, Loss: 0.11301655694842339, Final Batch Loss: 0.013045839965343475\n",
      "Epoch 328, Loss: 0.2218495775014162, Final Batch Loss: 0.12468095868825912\n",
      "Epoch 329, Loss: 0.1524652549996972, Final Batch Loss: 0.04401056468486786\n",
      "Epoch 330, Loss: 0.19912213645875454, Final Batch Loss: 0.10001656413078308\n",
      "Epoch 331, Loss: 0.12522329483181238, Final Batch Loss: 0.014006142504513264\n",
      "Epoch 332, Loss: 0.18450339883565903, Final Batch Loss: 0.08215678483247757\n",
      "Epoch 333, Loss: 0.15497200563549995, Final Batch Loss: 0.06752943992614746\n",
      "Epoch 334, Loss: 0.11644090199843049, Final Batch Loss: 0.006820884067565203\n",
      "Epoch 335, Loss: 0.14250980131328106, Final Batch Loss: 0.01503567025065422\n",
      "Epoch 336, Loss: 0.11544143804349005, Final Batch Loss: 0.0023117142263799906\n",
      "Epoch 337, Loss: 0.11144802067428827, Final Batch Loss: 0.011331216432154179\n",
      "Epoch 338, Loss: 0.12183797545731068, Final Batch Loss: 0.016740482300519943\n",
      "Epoch 339, Loss: 0.15303888730704784, Final Batch Loss: 0.027078891173005104\n",
      "Epoch 340, Loss: 0.15921224281191826, Final Batch Loss: 0.06455060094594955\n",
      "Epoch 341, Loss: 0.12675541825592518, Final Batch Loss: 0.017225930467247963\n",
      "Epoch 342, Loss: 0.12537997588515282, Final Batch Loss: 0.010431300848722458\n",
      "Epoch 343, Loss: 0.11430538562126458, Final Batch Loss: 0.0029362209606915712\n",
      "Epoch 344, Loss: 0.1551097296178341, Final Batch Loss: 0.0718664601445198\n",
      "Epoch 345, Loss: 0.12273904774338007, Final Batch Loss: 0.014052520506083965\n",
      "Epoch 346, Loss: 0.143963941372931, Final Batch Loss: 0.012108144350349903\n",
      "Epoch 347, Loss: 0.18959699291735888, Final Batch Loss: 0.0894799530506134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348, Loss: 0.17781518725678325, Final Batch Loss: 0.0968487486243248\n",
      "Epoch 349, Loss: 0.1150191267952323, Final Batch Loss: 0.014377185143530369\n",
      "Epoch 350, Loss: 0.12006821390241385, Final Batch Loss: 0.008457624353468418\n",
      "Epoch 351, Loss: 0.11379152908921242, Final Batch Loss: 0.02270098775625229\n",
      "Epoch 352, Loss: 0.10378975095227361, Final Batch Loss: 0.005519338417798281\n",
      "Epoch 353, Loss: 0.1290700063109398, Final Batch Loss: 0.04507720470428467\n",
      "Epoch 354, Loss: 0.11447644513100386, Final Batch Loss: 0.012549950741231441\n",
      "Epoch 355, Loss: 0.11510985344648361, Final Batch Loss: 0.013472862541675568\n",
      "Epoch 356, Loss: 0.2925402335822582, Final Batch Loss: 0.21946358680725098\n",
      "Epoch 357, Loss: 0.11414703447371721, Final Batch Loss: 0.015289101749658585\n",
      "Epoch 358, Loss: 0.18110225722193718, Final Batch Loss: 0.08024723082780838\n",
      "Epoch 359, Loss: 0.11510254815220833, Final Batch Loss: 0.008614413440227509\n",
      "Epoch 360, Loss: 0.10232042288407683, Final Batch Loss: 0.005527095403522253\n",
      "Epoch 361, Loss: 0.1029137372970581, Final Batch Loss: 0.016034649685025215\n",
      "Epoch 362, Loss: 0.14739085640758276, Final Batch Loss: 0.058739494532346725\n",
      "Epoch 363, Loss: 0.1218888284638524, Final Batch Loss: 0.012124910019338131\n",
      "Epoch 364, Loss: 0.11439784336835146, Final Batch Loss: 0.013515333645045757\n",
      "Epoch 365, Loss: 0.12040167767554522, Final Batch Loss: 0.009817291982471943\n",
      "Epoch 366, Loss: 0.101479358272627, Final Batch Loss: 0.0030727649573236704\n",
      "Epoch 367, Loss: 0.11491652578115463, Final Batch Loss: 0.018453383818268776\n",
      "Epoch 368, Loss: 0.10536533733829856, Final Batch Loss: 0.006451645400375128\n",
      "Epoch 369, Loss: 0.09699452761560678, Final Batch Loss: 0.009050230495631695\n",
      "Epoch 370, Loss: 0.10773399192839861, Final Batch Loss: 0.009244726039469242\n",
      "Epoch 371, Loss: 0.1208853293210268, Final Batch Loss: 0.018891986459493637\n",
      "Epoch 372, Loss: 0.12833143258467317, Final Batch Loss: 0.00776066305115819\n",
      "Epoch 373, Loss: 0.12103340402245522, Final Batch Loss: 0.025341959670186043\n",
      "Epoch 374, Loss: 0.16234137397259474, Final Batch Loss: 0.07240528613328934\n",
      "Epoch 375, Loss: 0.1050863116979599, Final Batch Loss: 0.01681556925177574\n",
      "Epoch 376, Loss: 0.11019414523616433, Final Batch Loss: 0.00396617641672492\n",
      "Epoch 377, Loss: 0.13510430417954922, Final Batch Loss: 0.013584519736468792\n",
      "Epoch 378, Loss: 0.16593379899859428, Final Batch Loss: 0.04310460388660431\n",
      "Epoch 379, Loss: 0.12249984871596098, Final Batch Loss: 0.009635466150939465\n",
      "Epoch 380, Loss: 0.11885442258790135, Final Batch Loss: 0.007252393756061792\n",
      "Epoch 381, Loss: 0.14628644287586212, Final Batch Loss: 0.03350408002734184\n",
      "Epoch 382, Loss: 0.09778131544589996, Final Batch Loss: 0.020821768790483475\n",
      "Epoch 383, Loss: 0.128828932531178, Final Batch Loss: 0.02519003488123417\n",
      "Epoch 384, Loss: 0.07832454866729677, Final Batch Loss: 0.0021491197403520346\n",
      "Epoch 385, Loss: 0.12434239685535431, Final Batch Loss: 0.018842153251171112\n",
      "Epoch 386, Loss: 0.0977527778595686, Final Batch Loss: 0.019231848418712616\n",
      "Epoch 387, Loss: 0.17956934124231339, Final Batch Loss: 0.09895303845405579\n",
      "Epoch 388, Loss: 0.1021518143825233, Final Batch Loss: 0.00490582874044776\n",
      "Epoch 389, Loss: 0.14827833697199821, Final Batch Loss: 0.03389989584684372\n",
      "Epoch 390, Loss: 0.15473835077136755, Final Batch Loss: 0.06068963184952736\n",
      "Epoch 391, Loss: 0.17473739758133888, Final Batch Loss: 0.09539703279733658\n",
      "Epoch 392, Loss: 0.11402748804539442, Final Batch Loss: 0.009104008786380291\n",
      "Epoch 393, Loss: 0.13011923804879189, Final Batch Loss: 0.02814088575541973\n",
      "Epoch 394, Loss: 0.13570094481110573, Final Batch Loss: 0.04370905086398125\n",
      "Epoch 395, Loss: 0.10295040067285299, Final Batch Loss: 0.011255920864641666\n",
      "Epoch 396, Loss: 0.09622298181056976, Final Batch Loss: 0.013512525707483292\n",
      "Epoch 397, Loss: 0.11313995346426964, Final Batch Loss: 0.04320800304412842\n",
      "Epoch 398, Loss: 0.09297124249860644, Final Batch Loss: 0.004736748989671469\n",
      "Epoch 399, Loss: 0.09101545764133334, Final Batch Loss: 0.007594994734972715\n",
      "Epoch 400, Loss: 0.14284902717918158, Final Batch Loss: 0.0613582544028759\n",
      "Epoch 401, Loss: 0.10875879228115082, Final Batch Loss: 0.010436464101076126\n",
      "Epoch 402, Loss: 0.15767641831189394, Final Batch Loss: 0.07788211852312088\n",
      "Epoch 403, Loss: 0.16925349459052086, Final Batch Loss: 0.10049507021903992\n",
      "Epoch 404, Loss: 0.11051873117685318, Final Batch Loss: 0.028048591688275337\n",
      "Epoch 405, Loss: 0.10396394738927484, Final Batch Loss: 0.006543178576976061\n",
      "Epoch 406, Loss: 0.1975078582763672, Final Batch Loss: 0.1021558940410614\n",
      "Epoch 407, Loss: 0.11701233591884375, Final Batch Loss: 0.009128631092607975\n",
      "Epoch 408, Loss: 0.14017854444682598, Final Batch Loss: 0.047628361731767654\n",
      "Epoch 409, Loss: 0.09189479984343052, Final Batch Loss: 0.008861789479851723\n",
      "Epoch 410, Loss: 0.09610472060739994, Final Batch Loss: 0.00954699981957674\n",
      "Epoch 411, Loss: 0.10570121835917234, Final Batch Loss: 0.01893494464457035\n",
      "Epoch 412, Loss: 0.09505231957882643, Final Batch Loss: 0.009007512591779232\n",
      "Epoch 413, Loss: 0.10302644409239292, Final Batch Loss: 0.007789291441440582\n",
      "Epoch 414, Loss: 0.1373080937191844, Final Batch Loss: 0.06806743144989014\n",
      "Epoch 415, Loss: 0.09129752032458782, Final Batch Loss: 0.009353318251669407\n",
      "Epoch 416, Loss: 0.10254631005227566, Final Batch Loss: 0.009837540797889233\n",
      "Epoch 417, Loss: 0.08772857347503304, Final Batch Loss: 0.003951388876885176\n",
      "Epoch 418, Loss: 0.09397627785801888, Final Batch Loss: 0.007488463073968887\n",
      "Epoch 419, Loss: 0.07043587532825768, Final Batch Loss: 0.0025639731902629137\n",
      "Epoch 420, Loss: 0.1028245473280549, Final Batch Loss: 0.017412403598427773\n",
      "Epoch 421, Loss: 0.10740892635658383, Final Batch Loss: 0.037116922438144684\n",
      "Epoch 422, Loss: 0.161637419834733, Final Batch Loss: 0.0827256515622139\n",
      "Epoch 423, Loss: 0.0924597168341279, Final Batch Loss: 0.011914811097085476\n",
      "Epoch 424, Loss: 0.07654304662719369, Final Batch Loss: 0.004811825696378946\n",
      "Epoch 425, Loss: 0.08312268578447402, Final Batch Loss: 0.0025376903358846903\n",
      "Epoch 426, Loss: 0.07491874042898417, Final Batch Loss: 0.009928890503942966\n",
      "Epoch 427, Loss: 0.1072847219184041, Final Batch Loss: 0.014554505236446857\n",
      "Epoch 428, Loss: 0.0786329684779048, Final Batch Loss: 0.018756719306111336\n",
      "Epoch 429, Loss: 0.07250705407932401, Final Batch Loss: 0.006542517337948084\n",
      "Epoch 430, Loss: 0.08857446443289518, Final Batch Loss: 0.02046196348965168\n",
      "Epoch 431, Loss: 0.09679569955915213, Final Batch Loss: 0.013025344349443913\n",
      "Epoch 432, Loss: 0.08732131216675043, Final Batch Loss: 0.008210121653974056\n",
      "Epoch 433, Loss: 0.07675601949449629, Final Batch Loss: 0.0016085648676380515\n",
      "Epoch 434, Loss: 0.10109546966850758, Final Batch Loss: 0.017192522063851357\n",
      "Epoch 435, Loss: 0.10657313838601112, Final Batch Loss: 0.006785660982131958\n",
      "Epoch 436, Loss: 0.060114048421382904, Final Batch Loss: 0.0029318807646632195\n",
      "Epoch 437, Loss: 0.10126890521496534, Final Batch Loss: 0.00804234016686678\n",
      "Epoch 438, Loss: 0.09938132204115391, Final Batch Loss: 0.018625909462571144\n",
      "Epoch 439, Loss: 0.09024686925113201, Final Batch Loss: 0.010754228569567204\n",
      "Epoch 440, Loss: 0.0812954124994576, Final Batch Loss: 0.014887775294482708\n",
      "Epoch 441, Loss: 0.11739327386021614, Final Batch Loss: 0.044006649404764175\n",
      "Epoch 442, Loss: 0.08579385280609131, Final Batch Loss: 0.010988511145114899\n",
      "Epoch 443, Loss: 0.09237312851473689, Final Batch Loss: 0.037327684462070465\n",
      "Epoch 444, Loss: 0.07217161497101188, Final Batch Loss: 0.010565687902271748\n",
      "Epoch 445, Loss: 0.09275043942034245, Final Batch Loss: 0.029269183054566383\n",
      "Epoch 446, Loss: 0.054318408947438, Final Batch Loss: 0.004275318700820208\n",
      "Epoch 447, Loss: 0.0835389974527061, Final Batch Loss: 0.004688028711825609\n",
      "Epoch 448, Loss: 0.08238197397440672, Final Batch Loss: 0.008617792278528214\n",
      "Epoch 449, Loss: 0.08987709414213896, Final Batch Loss: 0.012122011743485928\n",
      "Epoch 450, Loss: 0.09697550197597593, Final Batch Loss: 0.001672655693255365\n",
      "Epoch 451, Loss: 0.06507494021207094, Final Batch Loss: 0.004072148352861404\n",
      "Epoch 452, Loss: 0.10386222787201405, Final Batch Loss: 0.044399917125701904\n",
      "Epoch 453, Loss: 0.08833107817918062, Final Batch Loss: 0.014280348084867\n",
      "Epoch 454, Loss: 0.08841917011886835, Final Batch Loss: 0.014134022407233715\n",
      "Epoch 455, Loss: 0.07599865784868598, Final Batch Loss: 0.008973382413387299\n",
      "Epoch 456, Loss: 0.09501417819410563, Final Batch Loss: 0.004754278343170881\n",
      "Epoch 457, Loss: 0.07981818728148937, Final Batch Loss: 0.013744019903242588\n",
      "Epoch 458, Loss: 0.06502106820698828, Final Batch Loss: 0.0018480609869584441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459, Loss: 0.0846488825045526, Final Batch Loss: 0.005432274658232927\n",
      "Epoch 460, Loss: 0.06736651854589581, Final Batch Loss: 0.005886859726160765\n",
      "Epoch 461, Loss: 0.07874093670397997, Final Batch Loss: 0.0054190028458833694\n",
      "Epoch 462, Loss: 0.11038694716989994, Final Batch Loss: 0.04605371132493019\n",
      "Epoch 463, Loss: 0.07053914992138743, Final Batch Loss: 0.005467146169394255\n",
      "Epoch 464, Loss: 0.07497482560575008, Final Batch Loss: 0.006890427321195602\n",
      "Epoch 465, Loss: 0.08696308545768261, Final Batch Loss: 0.026108724996447563\n",
      "Epoch 466, Loss: 0.08459362015128136, Final Batch Loss: 0.010744597762823105\n",
      "Epoch 467, Loss: 0.067362145986408, Final Batch Loss: 0.0023988126777112484\n",
      "Epoch 468, Loss: 0.06808916851878166, Final Batch Loss: 0.005590485874563456\n",
      "Epoch 469, Loss: 0.0665858956053853, Final Batch Loss: 0.008895336650311947\n",
      "Epoch 470, Loss: 0.08041307143867016, Final Batch Loss: 0.009941527619957924\n",
      "Epoch 471, Loss: 0.09056669927667826, Final Batch Loss: 0.0015587237430736423\n",
      "Epoch 472, Loss: 0.0663663218729198, Final Batch Loss: 0.005903161596506834\n",
      "Epoch 473, Loss: 0.07926010014489293, Final Batch Loss: 0.006813655141741037\n",
      "Epoch 474, Loss: 0.07490286929532886, Final Batch Loss: 0.004355214070528746\n",
      "Epoch 475, Loss: 0.12939301505684853, Final Batch Loss: 0.056421760469675064\n",
      "Epoch 476, Loss: 0.062105063116177917, Final Batch Loss: 0.0028586287517100573\n",
      "Epoch 477, Loss: 0.09148216433823109, Final Batch Loss: 0.015198901295661926\n",
      "Epoch 478, Loss: 0.09095914475619793, Final Batch Loss: 0.009703153744339943\n",
      "Epoch 479, Loss: 0.10830597206950188, Final Batch Loss: 0.05250921845436096\n",
      "Epoch 480, Loss: 0.09094277303665876, Final Batch Loss: 0.028186043724417686\n",
      "Epoch 481, Loss: 0.07404123269952834, Final Batch Loss: 0.0029143106658011675\n",
      "Epoch 482, Loss: 0.08208669256418943, Final Batch Loss: 0.011914271861314774\n",
      "Epoch 483, Loss: 0.0609645489603281, Final Batch Loss: 0.0047856783494353294\n",
      "Epoch 484, Loss: 0.06530574010685086, Final Batch Loss: 0.005609592888504267\n",
      "Epoch 485, Loss: 0.06736399978399277, Final Batch Loss: 0.00890500470995903\n",
      "Epoch 486, Loss: 0.128632340580225, Final Batch Loss: 0.085472472012043\n",
      "Epoch 487, Loss: 0.05065690027549863, Final Batch Loss: 0.004453043919056654\n",
      "Epoch 488, Loss: 0.07847987860441208, Final Batch Loss: 0.011368588544428349\n",
      "Epoch 489, Loss: 0.09094350785017014, Final Batch Loss: 0.013890150934457779\n",
      "Epoch 490, Loss: 0.06478375056758523, Final Batch Loss: 0.0019178376533091068\n",
      "Epoch 491, Loss: 0.06126099149696529, Final Batch Loss: 0.0037899783346801996\n",
      "Epoch 492, Loss: 0.09809454530477524, Final Batch Loss: 0.04072609916329384\n",
      "Epoch 493, Loss: 0.06830844236537814, Final Batch Loss: 0.006637013051658869\n",
      "Epoch 494, Loss: 0.10245941579341888, Final Batch Loss: 0.036284927278757095\n",
      "Epoch 495, Loss: 0.07510199258103967, Final Batch Loss: 0.01754804514348507\n",
      "Epoch 496, Loss: 0.0704685770906508, Final Batch Loss: 0.006727940868586302\n",
      "Epoch 497, Loss: 0.08095668163150549, Final Batch Loss: 0.01436364371329546\n",
      "Epoch 498, Loss: 0.09980245865881443, Final Batch Loss: 0.02477700263261795\n",
      "Epoch 499, Loss: 0.06216463819146156, Final Batch Loss: 0.006808057427406311\n",
      "Epoch 500, Loss: 0.09297397639602423, Final Batch Loss: 0.04066774621605873\n",
      "Epoch 501, Loss: 0.058862429577857256, Final Batch Loss: 0.012459900230169296\n",
      "Epoch 502, Loss: 0.11486872378736734, Final Batch Loss: 0.07104743272066116\n",
      "Epoch 503, Loss: 0.065948068164289, Final Batch Loss: 0.012332476675510406\n",
      "Epoch 504, Loss: 0.0612286776304245, Final Batch Loss: 0.0056527405977249146\n",
      "Epoch 505, Loss: 0.05223943525925279, Final Batch Loss: 0.006287630181759596\n",
      "Epoch 506, Loss: 0.06913118343800306, Final Batch Loss: 0.008438167162239552\n",
      "Epoch 507, Loss: 0.08810793701559305, Final Batch Loss: 0.053334008902311325\n",
      "Epoch 508, Loss: 0.051435243571177125, Final Batch Loss: 0.0029439872596412897\n",
      "Epoch 509, Loss: 0.05555286607705057, Final Batch Loss: 0.003013421082869172\n",
      "Epoch 510, Loss: 0.05843692319467664, Final Batch Loss: 0.005746385548263788\n",
      "Epoch 511, Loss: 0.046332122990861535, Final Batch Loss: 0.002670947229489684\n",
      "Epoch 512, Loss: 0.048073252430185676, Final Batch Loss: 0.002303995890542865\n",
      "Epoch 513, Loss: 0.06955880019813776, Final Batch Loss: 0.010435103438794613\n",
      "Epoch 514, Loss: 0.057630330324172974, Final Batch Loss: 0.013088536448776722\n",
      "Epoch 515, Loss: 0.05804420984350145, Final Batch Loss: 0.002633022842928767\n",
      "Epoch 516, Loss: 0.11325842421501875, Final Batch Loss: 0.07218646258115768\n",
      "Epoch 517, Loss: 0.10761492792516947, Final Batch Loss: 0.07355860620737076\n",
      "Epoch 518, Loss: 0.06943292217329144, Final Batch Loss: 0.010589353740215302\n",
      "Epoch 519, Loss: 0.07326973462477326, Final Batch Loss: 0.007186036091297865\n",
      "Epoch 520, Loss: 0.07722303364425898, Final Batch Loss: 0.00834034476429224\n",
      "Epoch 521, Loss: 0.09579185675829649, Final Batch Loss: 0.03309667855501175\n",
      "Epoch 522, Loss: 0.05259569641202688, Final Batch Loss: 0.011042602360248566\n",
      "Epoch 523, Loss: 0.048556701047345996, Final Batch Loss: 0.0024998916778713465\n",
      "Epoch 524, Loss: 0.0538341267965734, Final Batch Loss: 0.004957188386470079\n",
      "Epoch 525, Loss: 0.05225799651816487, Final Batch Loss: 0.01567276008427143\n",
      "Epoch 526, Loss: 0.05924771400168538, Final Batch Loss: 0.0062505328096449375\n",
      "Epoch 527, Loss: 0.049268811009824276, Final Batch Loss: 0.003201083978638053\n",
      "Epoch 528, Loss: 0.0785678222309798, Final Batch Loss: 0.003644566750153899\n",
      "Epoch 529, Loss: 0.046907999785616994, Final Batch Loss: 0.002259338041767478\n",
      "Epoch 530, Loss: 0.04389960318803787, Final Batch Loss: 0.009997682645916939\n",
      "Epoch 531, Loss: 0.07925348402932286, Final Batch Loss: 0.050043415278196335\n",
      "Epoch 532, Loss: 0.06996235530823469, Final Batch Loss: 0.018962545320391655\n",
      "Epoch 533, Loss: 0.06509479833766818, Final Batch Loss: 0.0013242759741842747\n",
      "Epoch 534, Loss: 0.053499738685786724, Final Batch Loss: 0.014582161791622639\n",
      "Epoch 535, Loss: 0.049727069679647684, Final Batch Loss: 0.008045469410717487\n",
      "Epoch 536, Loss: 0.04548510070890188, Final Batch Loss: 0.009194348938763142\n",
      "Epoch 537, Loss: 0.04999420698732138, Final Batch Loss: 0.00495133874937892\n",
      "Epoch 538, Loss: 0.051558872452005744, Final Batch Loss: 0.0034981134813278913\n",
      "Epoch 539, Loss: 0.03449802100658417, Final Batch Loss: 0.002175654750317335\n",
      "Epoch 540, Loss: 0.043388473335653543, Final Batch Loss: 0.01340334489941597\n",
      "Epoch 541, Loss: 0.06091946456581354, Final Batch Loss: 0.021538548171520233\n",
      "Epoch 542, Loss: 0.05429608398117125, Final Batch Loss: 0.0025997834745794535\n",
      "Epoch 543, Loss: 0.04732589062768966, Final Batch Loss: 0.0018211245769634843\n",
      "Epoch 544, Loss: 0.05470869061537087, Final Batch Loss: 0.0035428230185061693\n",
      "Epoch 545, Loss: 0.03675884893164039, Final Batch Loss: 0.0016406509093940258\n",
      "Epoch 546, Loss: 0.08006485691294074, Final Batch Loss: 0.04880344867706299\n",
      "Epoch 547, Loss: 0.056233519804663956, Final Batch Loss: 0.0013488616095855832\n",
      "Epoch 548, Loss: 0.043803490698337555, Final Batch Loss: 0.00402813870459795\n",
      "Epoch 549, Loss: 0.07990155275911093, Final Batch Loss: 0.0515756756067276\n",
      "Epoch 550, Loss: 0.04843217309098691, Final Batch Loss: 0.0013660549884662032\n",
      "Epoch 551, Loss: 0.05473941704258323, Final Batch Loss: 0.007258351426571608\n",
      "Epoch 552, Loss: 0.04860006459057331, Final Batch Loss: 0.014184754341840744\n",
      "Epoch 553, Loss: 0.0488352223765105, Final Batch Loss: 0.002125548431649804\n",
      "Epoch 554, Loss: 0.06914246967062354, Final Batch Loss: 0.037437062710523605\n",
      "Epoch 555, Loss: 0.029828771948814392, Final Batch Loss: 0.006692387163639069\n",
      "Epoch 556, Loss: 0.03497746936045587, Final Batch Loss: 0.0022319944109767675\n",
      "Epoch 557, Loss: 0.03757261671125889, Final Batch Loss: 0.0008695230353623629\n",
      "Epoch 558, Loss: 0.05167804379016161, Final Batch Loss: 0.017302321270108223\n",
      "Epoch 559, Loss: 0.0937420497648418, Final Batch Loss: 0.0711958035826683\n",
      "Epoch 560, Loss: 0.0353812663233839, Final Batch Loss: 0.0009190923883579671\n",
      "Epoch 561, Loss: 0.05293082445859909, Final Batch Loss: 0.008348160423338413\n",
      "Epoch 562, Loss: 0.04768608952872455, Final Batch Loss: 0.000885792775079608\n",
      "Epoch 563, Loss: 0.03934855689294636, Final Batch Loss: 0.002042233245447278\n",
      "Epoch 564, Loss: 0.043197122402489185, Final Batch Loss: 0.004408781882375479\n",
      "Epoch 565, Loss: 0.0368218362564221, Final Batch Loss: 0.0016175127821043134\n",
      "Epoch 566, Loss: 0.03951235394924879, Final Batch Loss: 0.010551395826041698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567, Loss: 0.0355448923073709, Final Batch Loss: 0.013364375568926334\n",
      "Epoch 568, Loss: 0.028955673682503402, Final Batch Loss: 0.0016485612140968442\n",
      "Epoch 569, Loss: 0.0415177782997489, Final Batch Loss: 0.009390211664140224\n",
      "Epoch 570, Loss: 0.04061217023991048, Final Batch Loss: 0.002174421912059188\n",
      "Epoch 571, Loss: 0.028410052647814155, Final Batch Loss: 0.002712297486141324\n",
      "Epoch 572, Loss: 0.03146246378310025, Final Batch Loss: 0.0007942814845591784\n",
      "Epoch 573, Loss: 0.03716350509785116, Final Batch Loss: 0.0025965075474232435\n",
      "Epoch 574, Loss: 0.08389081805944443, Final Batch Loss: 0.047007281333208084\n",
      "Epoch 575, Loss: 0.046504518075380474, Final Batch Loss: 0.0007832507253624499\n",
      "Epoch 576, Loss: 0.016927728662267327, Final Batch Loss: 0.0018097558058798313\n",
      "Epoch 577, Loss: 0.05731971003115177, Final Batch Loss: 0.01813001185655594\n",
      "Epoch 578, Loss: 0.023039762629196048, Final Batch Loss: 0.0023912189062684774\n",
      "Epoch 579, Loss: 0.023249897174537182, Final Batch Loss: 0.006018093321472406\n",
      "Epoch 580, Loss: 0.02164574945345521, Final Batch Loss: 0.0024742763489484787\n",
      "Epoch 581, Loss: 0.028061719611287117, Final Batch Loss: 0.0019023548811674118\n",
      "Epoch 582, Loss: 0.0732361008413136, Final Batch Loss: 0.052110735327005386\n",
      "Epoch 583, Loss: 0.030348328640684485, Final Batch Loss: 0.0038560722023248672\n",
      "Epoch 584, Loss: 0.05568316392600536, Final Batch Loss: 0.021544111892580986\n",
      "Epoch 585, Loss: 0.0797668220475316, Final Batch Loss: 0.0511225201189518\n",
      "Epoch 586, Loss: 0.04807364218868315, Final Batch Loss: 0.0021798659581691027\n",
      "Epoch 587, Loss: 0.027637106366455555, Final Batch Loss: 0.004206898622214794\n",
      "Epoch 588, Loss: 0.03524211619514972, Final Batch Loss: 0.0011282797204330564\n",
      "Epoch 589, Loss: 0.0492712608538568, Final Batch Loss: 0.007739512715488672\n",
      "Epoch 590, Loss: 0.025944959139451385, Final Batch Loss: 0.0005377351772040129\n",
      "Epoch 591, Loss: 0.03263687272556126, Final Batch Loss: 0.002583971945568919\n",
      "Epoch 592, Loss: 0.028025814332067966, Final Batch Loss: 0.008905944414436817\n",
      "Epoch 593, Loss: 0.03300008736550808, Final Batch Loss: 0.010569361038506031\n",
      "Epoch 594, Loss: 0.025120313744992018, Final Batch Loss: 0.004980497993528843\n",
      "Epoch 595, Loss: 0.020419118169229478, Final Batch Loss: 0.00017317681340500712\n",
      "Epoch 596, Loss: 0.05990032758563757, Final Batch Loss: 0.03132626786828041\n",
      "Epoch 597, Loss: 0.03180921939201653, Final Batch Loss: 0.003604818833991885\n",
      "Epoch 598, Loss: 0.027702778577804565, Final Batch Loss: 0.007002948317676783\n",
      "Epoch 599, Loss: 0.02290645765606314, Final Batch Loss: 0.0010639805113896728\n",
      "Epoch 600, Loss: 0.025478051393292844, Final Batch Loss: 0.0005181798478588462\n",
      "Epoch 601, Loss: 0.04308840585872531, Final Batch Loss: 0.0003605779493227601\n",
      "Epoch 602, Loss: 0.01847631298005581, Final Batch Loss: 0.0008097172249108553\n",
      "Epoch 603, Loss: 0.029988589114509523, Final Batch Loss: 0.001093529281206429\n",
      "Epoch 604, Loss: 0.06452130852267146, Final Batch Loss: 0.002199872862547636\n",
      "Epoch 605, Loss: 0.026934011955745518, Final Batch Loss: 0.0015525358030572534\n",
      "Epoch 606, Loss: 0.03556815616320819, Final Batch Loss: 0.001295071910135448\n",
      "Epoch 607, Loss: 0.024995436193421483, Final Batch Loss: 0.0034072373528033495\n",
      "Epoch 608, Loss: 0.05045269289985299, Final Batch Loss: 0.019167007878422737\n",
      "Epoch 609, Loss: 0.020197642617858946, Final Batch Loss: 0.0016267519677057862\n",
      "Epoch 610, Loss: 0.027706396067515016, Final Batch Loss: 0.0008058003149926662\n",
      "Epoch 611, Loss: 0.027932228345889598, Final Batch Loss: 0.0005404833354987204\n",
      "Epoch 612, Loss: 0.027785514379502274, Final Batch Loss: 0.0002015101636061445\n",
      "Epoch 613, Loss: 0.05294352490454912, Final Batch Loss: 0.03481743857264519\n",
      "Epoch 614, Loss: 0.019825511932140216, Final Batch Loss: 0.00034987935214303434\n",
      "Epoch 615, Loss: 0.02773863761103712, Final Batch Loss: 0.00015630919369868934\n",
      "Epoch 616, Loss: 0.03864351904485375, Final Batch Loss: 0.0015699617797508836\n",
      "Epoch 617, Loss: 0.09495191089808941, Final Batch Loss: 0.0192379392683506\n",
      "Epoch 618, Loss: 0.03197044077387545, Final Batch Loss: 0.0002109207125613466\n",
      "Epoch 619, Loss: 0.02256970456801355, Final Batch Loss: 0.002761373994871974\n",
      "Epoch 620, Loss: 0.01852875971235335, Final Batch Loss: 0.0032775383442640305\n",
      "Epoch 621, Loss: 0.02116110362112522, Final Batch Loss: 0.0008456921204924583\n",
      "Epoch 622, Loss: 0.022793891024775803, Final Batch Loss: 0.0016429402166977525\n",
      "Epoch 623, Loss: 0.028551836381666362, Final Batch Loss: 0.009408198297023773\n",
      "Epoch 624, Loss: 0.07744072703644633, Final Batch Loss: 0.06317044049501419\n",
      "Epoch 625, Loss: 0.020976082189008594, Final Batch Loss: 0.0061532179825007915\n",
      "Epoch 626, Loss: 0.03457147418521345, Final Batch Loss: 0.006506781559437513\n",
      "Epoch 627, Loss: 0.033029416343197227, Final Batch Loss: 0.018036216497421265\n",
      "Epoch 628, Loss: 0.031093007302843034, Final Batch Loss: 0.001617879024706781\n",
      "Epoch 629, Loss: 0.02752298815175891, Final Batch Loss: 0.003074358217418194\n",
      "Epoch 630, Loss: 0.039611597545444965, Final Batch Loss: 0.0065748062916100025\n",
      "Epoch 631, Loss: 0.023362795007415116, Final Batch Loss: 0.0018004478188231587\n",
      "Epoch 632, Loss: 0.02850473509170115, Final Batch Loss: 0.009365552105009556\n",
      "Epoch 633, Loss: 0.02520660072332248, Final Batch Loss: 0.000808189099188894\n",
      "Epoch 634, Loss: 0.02291290950961411, Final Batch Loss: 0.0005986539181321859\n",
      "Epoch 635, Loss: 0.020127868745476007, Final Batch Loss: 0.009316853247582912\n",
      "Epoch 636, Loss: 0.016987610899377614, Final Batch Loss: 0.0008399364887736738\n",
      "Epoch 637, Loss: 0.037815229792613536, Final Batch Loss: 0.0007546491106040776\n",
      "Epoch 638, Loss: 0.027805018238723278, Final Batch Loss: 0.007761542219668627\n",
      "Epoch 639, Loss: 0.015528574935160577, Final Batch Loss: 0.0015227635158225894\n",
      "Epoch 640, Loss: 0.015718030859716237, Final Batch Loss: 0.003449489362537861\n",
      "Epoch 641, Loss: 0.02666523400694132, Final Batch Loss: 0.0011544174049049616\n",
      "Epoch 642, Loss: 0.011777607607655227, Final Batch Loss: 0.0025108701083809137\n",
      "Epoch 643, Loss: 0.010948161827400327, Final Batch Loss: 0.0007054191082715988\n",
      "Epoch 644, Loss: 0.06312160892412066, Final Batch Loss: 0.04299241304397583\n",
      "Epoch 645, Loss: 0.038043762382585555, Final Batch Loss: 0.0006990547408349812\n",
      "Epoch 646, Loss: 0.03143373437342234, Final Batch Loss: 0.0003576476883608848\n",
      "Epoch 647, Loss: 0.040469960193149745, Final Batch Loss: 0.0012597384629771113\n",
      "Epoch 648, Loss: 0.024113553343340755, Final Batch Loss: 0.013444027863442898\n",
      "Epoch 649, Loss: 0.03831845452077687, Final Batch Loss: 0.0036284588277339935\n",
      "Epoch 650, Loss: 0.02664242300670594, Final Batch Loss: 0.0016474128933623433\n",
      "Epoch 651, Loss: 0.04409935069270432, Final Batch Loss: 0.005656897556036711\n",
      "Epoch 652, Loss: 0.018240340577904135, Final Batch Loss: 0.0007427021046169102\n",
      "Epoch 653, Loss: 0.01988258631899953, Final Batch Loss: 0.003189769573509693\n",
      "Epoch 654, Loss: 0.008072075550444424, Final Batch Loss: 0.0006032383535057306\n",
      "Epoch 655, Loss: 0.03879389772191644, Final Batch Loss: 0.0029710333328694105\n",
      "Epoch 656, Loss: 0.032556192134507, Final Batch Loss: 0.0017350312555208802\n",
      "Epoch 657, Loss: 0.03998383949510753, Final Batch Loss: 0.019077403470873833\n",
      "Epoch 658, Loss: 0.029113594442605972, Final Batch Loss: 0.007958408445119858\n",
      "Epoch 659, Loss: 0.019970090594142675, Final Batch Loss: 0.004784265998750925\n",
      "Epoch 660, Loss: 0.024332191795110703, Final Batch Loss: 0.0023717996664345264\n",
      "Epoch 661, Loss: 0.01498548174276948, Final Batch Loss: 0.005620249081403017\n",
      "Epoch 662, Loss: 0.025986950611695647, Final Batch Loss: 0.020382532849907875\n",
      "Epoch 663, Loss: 0.006695255637168884, Final Batch Loss: 0.0013819689629599452\n",
      "Epoch 664, Loss: 0.013277732126880437, Final Batch Loss: 0.001637337147258222\n",
      "Epoch 665, Loss: 0.01929617793939542, Final Batch Loss: 0.00020107235468458384\n",
      "Epoch 666, Loss: 0.034678106545470655, Final Batch Loss: 0.004927747882902622\n",
      "Epoch 667, Loss: 0.020748671609908342, Final Batch Loss: 0.007544472813606262\n",
      "Epoch 668, Loss: 0.014682813198305666, Final Batch Loss: 0.0031723137944936752\n",
      "Epoch 669, Loss: 0.03503017500042915, Final Batch Loss: 0.001512023969553411\n",
      "Epoch 670, Loss: 0.013522331428248435, Final Batch Loss: 0.00019005249487236142\n",
      "Epoch 671, Loss: 0.01895988266915083, Final Batch Loss: 0.0006761732511222363\n",
      "Epoch 672, Loss: 0.009312038600910455, Final Batch Loss: 0.0023087351582944393\n",
      "Epoch 673, Loss: 0.009887342457659543, Final Batch Loss: 0.00026464054826647043\n",
      "Epoch 674, Loss: 0.016218732460401952, Final Batch Loss: 0.0010982692474499345\n",
      "Epoch 675, Loss: 0.028453376493416727, Final Batch Loss: 0.0003585638478398323\n",
      "Epoch 676, Loss: 0.013111048960126936, Final Batch Loss: 0.0010488074040040374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677, Loss: 0.008056907798163593, Final Batch Loss: 0.004118194337934256\n",
      "Epoch 678, Loss: 0.009244050306733698, Final Batch Loss: 0.000510095211211592\n",
      "Epoch 679, Loss: 0.014507730957120657, Final Batch Loss: 0.0008588818018324673\n",
      "Epoch 680, Loss: 0.006094079639296979, Final Batch Loss: 0.0008391502196900547\n",
      "Epoch 681, Loss: 0.02289185835979879, Final Batch Loss: 0.002080216770991683\n",
      "Epoch 682, Loss: 0.022998095955699682, Final Batch Loss: 0.0022896667942404747\n",
      "Epoch 683, Loss: 0.022114544990472496, Final Batch Loss: 0.0019059866899624467\n",
      "Epoch 684, Loss: 0.03434478264534846, Final Batch Loss: 0.002735113026574254\n",
      "Epoch 685, Loss: 0.029576490749605, Final Batch Loss: 0.0010015334701165557\n",
      "Epoch 686, Loss: 0.016622931812889874, Final Batch Loss: 0.0010170802706852555\n",
      "Epoch 687, Loss: 0.0221240627579391, Final Batch Loss: 0.006968627218157053\n",
      "Epoch 688, Loss: 0.0726000911090523, Final Batch Loss: 0.06367937475442886\n",
      "Epoch 689, Loss: 0.015198408742435277, Final Batch Loss: 0.0016123484820127487\n",
      "Epoch 690, Loss: 0.04281868820544332, Final Batch Loss: 0.0013826790964230895\n",
      "Epoch 691, Loss: 0.0417262950213626, Final Batch Loss: 0.0019642894621938467\n",
      "Epoch 692, Loss: 0.031215675524435937, Final Batch Loss: 0.008990548551082611\n",
      "Epoch 693, Loss: 0.017048656416591257, Final Batch Loss: 0.0006631789146922529\n",
      "Epoch 694, Loss: 0.013416930451057851, Final Batch Loss: 0.0020156814716756344\n",
      "Epoch 695, Loss: 0.019026101974304765, Final Batch Loss: 0.002715633250772953\n",
      "Epoch 696, Loss: 0.022377862595021725, Final Batch Loss: 0.008019722066819668\n",
      "Epoch 697, Loss: 0.03480718657374382, Final Batch Loss: 0.014271034859120846\n",
      "Epoch 698, Loss: 0.017864562920294702, Final Batch Loss: 0.0012821961427107453\n",
      "Epoch 699, Loss: 0.02673769509419799, Final Batch Loss: 0.004015285987406969\n",
      "Epoch 700, Loss: 0.018951017525978386, Final Batch Loss: 0.0035449464339762926\n",
      "Epoch 701, Loss: 0.0163349153008312, Final Batch Loss: 0.0011196443811058998\n",
      "Epoch 702, Loss: 0.021384937223047018, Final Batch Loss: 0.0021681152284145355\n",
      "Epoch 703, Loss: 0.016564209247007966, Final Batch Loss: 0.003566288622096181\n",
      "Epoch 704, Loss: 0.012419731123372912, Final Batch Loss: 0.002936556236818433\n",
      "Epoch 705, Loss: 0.024883863632567227, Final Batch Loss: 0.0025167285930365324\n",
      "Epoch 706, Loss: 0.008023861330002546, Final Batch Loss: 0.0009847348555922508\n",
      "Epoch 707, Loss: 0.04948068701196462, Final Batch Loss: 0.0006184048252180219\n",
      "Epoch 708, Loss: 0.010970576549880207, Final Batch Loss: 0.0016482180217280984\n",
      "Epoch 709, Loss: 0.02524457301478833, Final Batch Loss: 0.013796786777675152\n",
      "Epoch 710, Loss: 0.11115259409416467, Final Batch Loss: 0.0956287682056427\n",
      "Epoch 711, Loss: 0.013191955513320863, Final Batch Loss: 9.329814929515123e-05\n",
      "Epoch 712, Loss: 0.0065079429623438045, Final Batch Loss: 0.00023674491967540234\n",
      "Epoch 713, Loss: 0.06628891511354595, Final Batch Loss: 0.00024606671649962664\n",
      "Epoch 714, Loss: 0.03485946042928845, Final Batch Loss: 0.0018542931647971272\n",
      "Epoch 715, Loss: 0.0074979065102525055, Final Batch Loss: 0.0030726951081305742\n",
      "Epoch 716, Loss: 0.040578475687652826, Final Batch Loss: 0.024009430781006813\n",
      "Epoch 717, Loss: 0.02495933638419956, Final Batch Loss: 0.006045335903763771\n",
      "Epoch 718, Loss: 0.03594037669245154, Final Batch Loss: 0.01482467819005251\n",
      "Epoch 719, Loss: 0.017290418210905045, Final Batch Loss: 0.0005509416223503649\n",
      "Epoch 720, Loss: 0.015796515333931893, Final Batch Loss: 0.0003123711794614792\n",
      "Epoch 721, Loss: 0.02497648901771754, Final Batch Loss: 0.001797372940927744\n",
      "Epoch 722, Loss: 0.027599354973062873, Final Batch Loss: 0.017009194940328598\n",
      "Epoch 723, Loss: 0.006596512132091448, Final Batch Loss: 0.0003232277522329241\n",
      "Epoch 724, Loss: 0.009442367649171501, Final Batch Loss: 0.002459948416799307\n",
      "Epoch 725, Loss: 0.03928164881654084, Final Batch Loss: 0.0029168196488171816\n",
      "Epoch 726, Loss: 0.025151289883069694, Final Batch Loss: 0.0011966422898694873\n",
      "Epoch 727, Loss: 0.0088528695050627, Final Batch Loss: 0.001608021091669798\n",
      "Epoch 728, Loss: 0.012395955622196198, Final Batch Loss: 0.0011761242058128119\n",
      "Epoch 729, Loss: 0.014668000163510442, Final Batch Loss: 0.004339666571468115\n",
      "Epoch 730, Loss: 0.004856285755522549, Final Batch Loss: 0.0013158125802874565\n",
      "Epoch 731, Loss: 0.018149265852116514, Final Batch Loss: 0.00011512387573020533\n",
      "Epoch 732, Loss: 0.028119692113250494, Final Batch Loss: 0.0006070079398341477\n",
      "Epoch 733, Loss: 0.00998177973087877, Final Batch Loss: 0.002131188753992319\n",
      "Epoch 734, Loss: 0.009386423509567976, Final Batch Loss: 0.0012312113540247083\n",
      "Epoch 735, Loss: 0.0029511614120565355, Final Batch Loss: 4.0235259803012013e-05\n",
      "Epoch 736, Loss: 0.02783513581380248, Final Batch Loss: 0.006311630364507437\n",
      "Epoch 737, Loss: 0.009009110304759815, Final Batch Loss: 0.0003387636097613722\n",
      "Epoch 738, Loss: 0.029296187218278646, Final Batch Loss: 0.024883201345801353\n",
      "Epoch 739, Loss: 0.006314006459433585, Final Batch Loss: 0.0017528487369418144\n",
      "Epoch 740, Loss: 0.024102349882014096, Final Batch Loss: 0.005513747688382864\n",
      "Epoch 741, Loss: 0.022409317462006584, Final Batch Loss: 0.0003250841109547764\n",
      "Epoch 742, Loss: 0.011848618189105764, Final Batch Loss: 0.00033779270597733557\n",
      "Epoch 743, Loss: 0.020892243832349777, Final Batch Loss: 0.010613266378641129\n",
      "Epoch 744, Loss: 0.02891528350301087, Final Batch Loss: 0.0025021519977599382\n",
      "Epoch 745, Loss: 0.014612256258260459, Final Batch Loss: 0.0035688523203134537\n",
      "Epoch 746, Loss: 0.008926665672333911, Final Batch Loss: 0.00047195880324579775\n",
      "Epoch 747, Loss: 0.017383340513333678, Final Batch Loss: 0.0015972335822880268\n",
      "Epoch 748, Loss: 0.013538241269998252, Final Batch Loss: 0.0019583075772970915\n",
      "Epoch 749, Loss: 0.010176240699365735, Final Batch Loss: 0.001013413886539638\n",
      "Epoch 750, Loss: 0.012394482444506139, Final Batch Loss: 0.0013485053787007928\n",
      "Epoch 751, Loss: 0.015254439669661224, Final Batch Loss: 0.002171326894313097\n",
      "Epoch 752, Loss: 0.009303948114393279, Final Batch Loss: 0.0002656727738212794\n",
      "Epoch 753, Loss: 0.006831994920503348, Final Batch Loss: 0.0004987305146642029\n",
      "Epoch 754, Loss: 0.006826184544479474, Final Batch Loss: 0.0004401066980790347\n",
      "Epoch 755, Loss: 0.014126357331406325, Final Batch Loss: 0.0006465333863161504\n",
      "Epoch 756, Loss: 0.023933438496896997, Final Batch Loss: 0.00044884977978654206\n",
      "Epoch 757, Loss: 0.0033846955047920346, Final Batch Loss: 0.0002719793701544404\n",
      "Epoch 758, Loss: 0.009318385302321985, Final Batch Loss: 0.00048469685134477913\n",
      "Epoch 759, Loss: 0.03080405737273395, Final Batch Loss: 0.0039744689129292965\n",
      "Epoch 760, Loss: 0.026661758311092854, Final Batch Loss: 0.0016938982298597693\n",
      "Epoch 761, Loss: 0.029271411221998278, Final Batch Loss: 8.065321162575856e-05\n",
      "Epoch 762, Loss: 0.008402223349548876, Final Batch Loss: 0.0005225783097557724\n",
      "Epoch 763, Loss: 0.01201308995950967, Final Batch Loss: 0.001551329274661839\n",
      "Epoch 764, Loss: 0.044862913666293025, Final Batch Loss: 0.0029047962743788958\n",
      "Epoch 765, Loss: 0.04375940730096772, Final Batch Loss: 0.03896118700504303\n",
      "Epoch 766, Loss: 0.03176341135986149, Final Batch Loss: 0.004701205994933844\n",
      "Epoch 767, Loss: 0.04275130032328889, Final Batch Loss: 0.00011276773875579238\n",
      "Epoch 768, Loss: 0.00528342931647785, Final Batch Loss: 0.0003921581956092268\n",
      "Epoch 769, Loss: 0.018196440243627876, Final Batch Loss: 0.0009951204992830753\n",
      "Epoch 770, Loss: 0.015765494521474466, Final Batch Loss: 0.0001169972529169172\n",
      "Epoch 771, Loss: 0.02138623152859509, Final Batch Loss: 0.0012428975896909833\n",
      "Epoch 772, Loss: 0.02138886455213651, Final Batch Loss: 0.0005590831278823316\n",
      "Epoch 773, Loss: 0.020175532263237983, Final Batch Loss: 0.0002921593841165304\n",
      "Epoch 774, Loss: 0.012537597853224725, Final Batch Loss: 0.0005541805294342339\n",
      "Epoch 775, Loss: 0.025379783823154867, Final Batch Loss: 0.0008520341943949461\n",
      "Epoch 776, Loss: 0.009338298346847296, Final Batch Loss: 0.002296368358656764\n",
      "Epoch 777, Loss: 0.012616708350833505, Final Batch Loss: 0.0032736684661358595\n",
      "Epoch 778, Loss: 0.017014702752931044, Final Batch Loss: 0.00028108482365496457\n",
      "Epoch 779, Loss: 0.012192932772450149, Final Batch Loss: 0.00543399341404438\n",
      "Epoch 780, Loss: 0.027258820366114378, Final Batch Loss: 0.019586971029639244\n",
      "Epoch 781, Loss: 0.010574568063020706, Final Batch Loss: 0.00034722546115517616\n",
      "Epoch 782, Loss: 0.006285694660618901, Final Batch Loss: 0.0017371888970956206\n",
      "Epoch 783, Loss: 0.02836937381653115, Final Batch Loss: 0.01711060293018818\n",
      "Epoch 784, Loss: 0.010358411236666143, Final Batch Loss: 0.0027553001418709755\n",
      "Epoch 785, Loss: 0.020241741207428277, Final Batch Loss: 0.0012942892499268055\n",
      "Epoch 786, Loss: 0.017382971942424774, Final Batch Loss: 0.0017805499956011772\n",
      "Epoch 787, Loss: 0.009760919667314738, Final Batch Loss: 0.0018684075912460685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 788, Loss: 0.028969921986572444, Final Batch Loss: 0.001731889438815415\n",
      "Epoch 789, Loss: 0.015351528534665704, Final Batch Loss: 0.0019699984695762396\n",
      "Epoch 790, Loss: 0.012975533143617213, Final Batch Loss: 0.001206916174851358\n",
      "Epoch 791, Loss: 0.027824335105833597, Final Batch Loss: 0.00017157669935841113\n",
      "Epoch 792, Loss: 0.007989618461579084, Final Batch Loss: 0.0005457834340631962\n",
      "Epoch 793, Loss: 0.02455506951082498, Final Batch Loss: 0.012354757636785507\n",
      "Epoch 794, Loss: 0.008237976813688874, Final Batch Loss: 0.0022672296036034822\n",
      "Epoch 795, Loss: 0.004359943501185626, Final Batch Loss: 0.00019904895452782512\n",
      "Epoch 796, Loss: 0.025658506201580167, Final Batch Loss: 0.004124405328184366\n",
      "Epoch 797, Loss: 0.008510841522365808, Final Batch Loss: 0.0013109603896737099\n",
      "Epoch 798, Loss: 0.020198337937472388, Final Batch Loss: 0.0002469077880959958\n",
      "Epoch 799, Loss: 0.023785938476066804, Final Batch Loss: 5.3913008741801605e-05\n",
      "Epoch 800, Loss: 0.014798225696722511, Final Batch Loss: 0.00011231491953367367\n",
      "Epoch 801, Loss: 0.007295502175111324, Final Batch Loss: 0.0023355665616691113\n",
      "Epoch 802, Loss: 0.013243618697742932, Final Batch Loss: 0.00014036351058166474\n",
      "Epoch 803, Loss: 0.032339833458536305, Final Batch Loss: 0.00012649166455958039\n",
      "Epoch 804, Loss: 0.02680385985877365, Final Batch Loss: 0.021553857252001762\n",
      "Epoch 805, Loss: 0.04449003252375405, Final Batch Loss: 0.0001767093053786084\n",
      "Epoch 806, Loss: 0.01424980431329459, Final Batch Loss: 0.0009713734034448862\n",
      "Epoch 807, Loss: 0.009250977340343525, Final Batch Loss: 2.093383409373928e-05\n",
      "Epoch 808, Loss: 0.050374040263704956, Final Batch Loss: 0.03794208914041519\n",
      "Epoch 809, Loss: 0.010430517693748698, Final Batch Loss: 0.0001329164661001414\n",
      "Epoch 810, Loss: 0.10943241155473515, Final Batch Loss: 0.07704196125268936\n",
      "Epoch 811, Loss: 0.0052328555611893535, Final Batch Loss: 0.0014421067899093032\n",
      "Epoch 812, Loss: 0.0116832140047336, Final Batch Loss: 0.00013832237164024264\n",
      "Epoch 813, Loss: 0.01597768923966214, Final Batch Loss: 0.0006019595894031227\n",
      "Epoch 814, Loss: 0.0066309795511187986, Final Batch Loss: 0.00015442307631019503\n",
      "Epoch 815, Loss: 0.028898180462419987, Final Batch Loss: 0.016884343698620796\n",
      "Epoch 816, Loss: 0.03153139306232333, Final Batch Loss: 0.02411217801272869\n",
      "Epoch 817, Loss: 0.00936244142940268, Final Batch Loss: 0.0005436189821921289\n",
      "Epoch 818, Loss: 0.012645351758692414, Final Batch Loss: 0.0003185284440405667\n",
      "Epoch 819, Loss: 0.01767718029441312, Final Batch Loss: 0.0030149456579238176\n",
      "Epoch 820, Loss: 0.10580971499439329, Final Batch Loss: 0.09375979751348495\n",
      "Epoch 821, Loss: 0.013609010289655998, Final Batch Loss: 0.0005806362605653703\n",
      "Epoch 822, Loss: 0.008906979681341909, Final Batch Loss: 0.00024262779334094375\n",
      "Epoch 823, Loss: 0.05722313141450286, Final Batch Loss: 0.047125864773988724\n",
      "Epoch 824, Loss: 0.03955026314361021, Final Batch Loss: 0.029526330530643463\n",
      "Epoch 825, Loss: 0.007792103569954634, Final Batch Loss: 0.002828270895406604\n",
      "Epoch 826, Loss: 0.030850356095470488, Final Batch Loss: 0.0011978087713941932\n",
      "Epoch 827, Loss: 0.011526785805472173, Final Batch Loss: 0.00012461656297091395\n",
      "Epoch 828, Loss: 0.017458007438108325, Final Batch Loss: 0.005761079024523497\n",
      "Epoch 829, Loss: 0.012378697283565998, Final Batch Loss: 0.0015465192263945937\n",
      "Epoch 830, Loss: 0.006355368910590187, Final Batch Loss: 0.0002829728473443538\n",
      "Epoch 831, Loss: 0.0471242779167369, Final Batch Loss: 0.04046722874045372\n",
      "Epoch 832, Loss: 0.013237714185379446, Final Batch Loss: 0.0011324379593133926\n",
      "Epoch 833, Loss: 0.01704939897172153, Final Batch Loss: 0.003630436258390546\n",
      "Epoch 834, Loss: 0.011224096349906176, Final Batch Loss: 0.0013497121399268508\n",
      "Epoch 835, Loss: 0.005551355658099055, Final Batch Loss: 0.0005189510993659496\n",
      "Epoch 836, Loss: 0.006609882664633915, Final Batch Loss: 0.00014963708235882223\n",
      "Epoch 837, Loss: 0.01017217111075297, Final Batch Loss: 0.004323526751250029\n",
      "Epoch 838, Loss: 0.026470698474440724, Final Batch Loss: 0.0007064677192829549\n",
      "Epoch 839, Loss: 0.01665636943653226, Final Batch Loss: 0.0014199950965121388\n",
      "Epoch 840, Loss: 0.01230823461082764, Final Batch Loss: 0.0003535818250384182\n",
      "Epoch 841, Loss: 0.020266750711016357, Final Batch Loss: 0.012259860523045063\n",
      "Epoch 842, Loss: 0.06230468617286533, Final Batch Loss: 0.034855496138334274\n",
      "Epoch 843, Loss: 0.015826907503651455, Final Batch Loss: 0.00032305033528245986\n",
      "Epoch 844, Loss: 0.011687597259879112, Final Batch Loss: 0.0002831956371665001\n",
      "Epoch 845, Loss: 0.005534808035008609, Final Batch Loss: 0.0005474257050082088\n",
      "Epoch 846, Loss: 0.02396349108312279, Final Batch Loss: 0.0014839478535577655\n",
      "Epoch 847, Loss: 0.004462645156309009, Final Batch Loss: 0.0010885579977184534\n",
      "Epoch 848, Loss: 0.009887462365441024, Final Batch Loss: 0.0016650236211717129\n",
      "Epoch 849, Loss: 0.021919241233263165, Final Batch Loss: 9.096955182030797e-05\n",
      "Epoch 850, Loss: 0.019828541204333305, Final Batch Loss: 0.006003879476338625\n",
      "Epoch 851, Loss: 0.006819903675932437, Final Batch Loss: 0.0006404885207302868\n",
      "Epoch 852, Loss: 0.019390488625504076, Final Batch Loss: 0.0013813419500365853\n",
      "Epoch 853, Loss: 0.034097512951120734, Final Batch Loss: 0.018895037472248077\n",
      "Epoch 854, Loss: 0.019434069166891277, Final Batch Loss: 0.012551598250865936\n",
      "Epoch 855, Loss: 0.012573853193316609, Final Batch Loss: 0.0008597538690082729\n",
      "Epoch 856, Loss: 0.010335421655327082, Final Batch Loss: 0.0014780735364183784\n",
      "Epoch 857, Loss: 0.008529114944394678, Final Batch Loss: 0.0010477532632648945\n",
      "Epoch 858, Loss: 0.010765283281216398, Final Batch Loss: 0.0010337081039324403\n",
      "Epoch 859, Loss: 0.004162519442616031, Final Batch Loss: 0.00102680129930377\n",
      "Epoch 860, Loss: 0.016948713804595172, Final Batch Loss: 0.0019272846402600408\n",
      "Epoch 861, Loss: 0.007029405620414764, Final Batch Loss: 0.0005647948128171265\n",
      "Epoch 862, Loss: 0.008326085051521659, Final Batch Loss: 0.0005816759075969458\n",
      "Epoch 863, Loss: 0.00945818245963892, Final Batch Loss: 8.648153016110882e-05\n",
      "Epoch 864, Loss: 0.010153172828722745, Final Batch Loss: 0.0008140982245095074\n",
      "Epoch 865, Loss: 0.011846785362649825, Final Batch Loss: 2.0603112716344185e-05\n",
      "Epoch 866, Loss: 0.004563877489999868, Final Batch Loss: 0.0001572963228682056\n",
      "Epoch 867, Loss: 0.0075714654522016644, Final Batch Loss: 0.004481086041778326\n",
      "Epoch 868, Loss: 0.0051988085033372045, Final Batch Loss: 0.002949709305539727\n",
      "Epoch 869, Loss: 0.005112463375553489, Final Batch Loss: 0.001016972935758531\n",
      "Epoch 870, Loss: 0.007920928619569167, Final Batch Loss: 0.0006152382702566683\n",
      "Epoch 871, Loss: 0.0031815760376048274, Final Batch Loss: 6.651617150055245e-05\n",
      "Epoch 872, Loss: 0.005366932367905974, Final Batch Loss: 0.0005415654741227627\n",
      "Epoch 873, Loss: 0.008189408388716402, Final Batch Loss: 4.387488661450334e-05\n",
      "Epoch 874, Loss: 0.012396148682455532, Final Batch Loss: 0.00022745916794519871\n",
      "Epoch 875, Loss: 0.0213944228598848, Final Batch Loss: 0.000545116956345737\n",
      "Epoch 876, Loss: 0.006396568911441136, Final Batch Loss: 7.316092523979023e-05\n",
      "Epoch 877, Loss: 0.02308582526165992, Final Batch Loss: 0.0005881739780306816\n",
      "Epoch 878, Loss: 0.02994142926763743, Final Batch Loss: 0.0004760833689942956\n",
      "Epoch 879, Loss: 0.006387782545061782, Final Batch Loss: 0.0020373689476400614\n",
      "Epoch 880, Loss: 0.023037348844809458, Final Batch Loss: 0.001137026702053845\n",
      "Epoch 881, Loss: 0.014535783178871498, Final Batch Loss: 0.00043300402467139065\n",
      "Epoch 882, Loss: 0.012181949685327709, Final Batch Loss: 0.002251829020678997\n",
      "Epoch 883, Loss: 0.021400368073955178, Final Batch Loss: 0.0005632010288536549\n",
      "Epoch 884, Loss: 0.005809298250824213, Final Batch Loss: 0.0004569588927552104\n",
      "Epoch 885, Loss: 0.005898243020055816, Final Batch Loss: 0.003947792574763298\n",
      "Epoch 886, Loss: 0.027335151680745184, Final Batch Loss: 0.018277708441019058\n",
      "Epoch 887, Loss: 0.003805066502536647, Final Batch Loss: 0.0017182090086862445\n",
      "Epoch 888, Loss: 0.002279970358358696, Final Batch Loss: 0.00025333845405839384\n",
      "Epoch 889, Loss: 0.0038935852062422782, Final Batch Loss: 0.00011415398330427706\n",
      "Epoch 890, Loss: 0.026078206225065514, Final Batch Loss: 0.00010287037002854049\n",
      "Epoch 891, Loss: 0.00719018061136012, Final Batch Loss: 4.7761266614543274e-05\n",
      "Epoch 892, Loss: 0.0034272102057002485, Final Batch Loss: 0.00022211193572729826\n",
      "Epoch 893, Loss: 0.022543565137311816, Final Batch Loss: 0.003744536079466343\n",
      "Epoch 894, Loss: 0.022069520608056337, Final Batch Loss: 0.000732863147277385\n",
      "Epoch 895, Loss: 0.01803900266531855, Final Batch Loss: 0.011121969670057297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896, Loss: 0.020382574817631394, Final Batch Loss: 0.015333588235080242\n",
      "Epoch 897, Loss: 0.01482306607067585, Final Batch Loss: 0.0015203588409349322\n",
      "Epoch 898, Loss: 0.006378163350746036, Final Batch Loss: 0.0010260387789458036\n",
      "Epoch 899, Loss: 0.015673760091885924, Final Batch Loss: 0.0010957116028293967\n",
      "Epoch 900, Loss: 0.007465623435564339, Final Batch Loss: 0.0022686838638037443\n",
      "Epoch 901, Loss: 0.009930690019245958, Final Batch Loss: 3.438104977249168e-05\n",
      "Epoch 902, Loss: 0.0027115880511701107, Final Batch Loss: 0.00023493151820730418\n",
      "Epoch 903, Loss: 0.002955790443593287, Final Batch Loss: 2.758071968855802e-05\n",
      "Epoch 904, Loss: 0.023467423090551165, Final Batch Loss: 2.3600108761456795e-05\n",
      "Epoch 905, Loss: 0.009051994842593558, Final Batch Loss: 0.0025553028099238873\n",
      "Epoch 906, Loss: 0.012324244482442737, Final Batch Loss: 0.006948974449187517\n",
      "Epoch 907, Loss: 0.07155894601601176, Final Batch Loss: 0.06908071041107178\n",
      "Epoch 908, Loss: 0.02157669560983777, Final Batch Loss: 0.002503790659829974\n",
      "Epoch 909, Loss: 0.03761750063858926, Final Batch Loss: 0.005764745641499758\n",
      "Epoch 910, Loss: 0.022609367035329342, Final Batch Loss: 0.01279064267873764\n",
      "Epoch 911, Loss: 0.016423813300207257, Final Batch Loss: 0.0017001339001581073\n",
      "Epoch 912, Loss: 0.05599241342861205, Final Batch Loss: 0.04293133690953255\n",
      "Epoch 913, Loss: 0.03957442998944316, Final Batch Loss: 0.00020621671865228564\n",
      "Epoch 914, Loss: 0.01848913513822481, Final Batch Loss: 0.0009448185446672142\n",
      "Epoch 915, Loss: 0.020536542899208143, Final Batch Loss: 0.000160231749759987\n",
      "Epoch 916, Loss: 0.05629328987561166, Final Batch Loss: 0.010616232641041279\n",
      "Epoch 917, Loss: 0.023289550154004246, Final Batch Loss: 0.0014623553724959493\n",
      "Epoch 918, Loss: 0.005782527120118175, Final Batch Loss: 5.158099611435318e-06\n",
      "Epoch 919, Loss: 0.007584410428535193, Final Batch Loss: 0.0005912376218475401\n",
      "Epoch 920, Loss: 0.01961210826266324, Final Batch Loss: 7.317741255974397e-05\n",
      "Epoch 921, Loss: 0.016362771508283913, Final Batch Loss: 0.002351067727431655\n",
      "Epoch 922, Loss: 0.0073087389464490116, Final Batch Loss: 0.001128818141296506\n",
      "Epoch 923, Loss: 0.010320675661205314, Final Batch Loss: 0.00012616980529855937\n",
      "Epoch 924, Loss: 0.015628762543201447, Final Batch Loss: 0.0002087486209347844\n",
      "Epoch 925, Loss: 0.004595070786308497, Final Batch Loss: 0.000612839066889137\n",
      "Epoch 926, Loss: 0.006751085631549358, Final Batch Loss: 9.552459232509136e-05\n",
      "Epoch 927, Loss: 0.006994252442382276, Final Batch Loss: 0.0005836699274368584\n",
      "Epoch 928, Loss: 0.012470135756302625, Final Batch Loss: 0.007403586059808731\n",
      "Epoch 929, Loss: 0.011576405144296587, Final Batch Loss: 0.0020815071184188128\n",
      "Epoch 930, Loss: 0.05406522296834737, Final Batch Loss: 0.03064793162047863\n",
      "Epoch 931, Loss: 0.01568075898103416, Final Batch Loss: 0.0005882222903892398\n",
      "Epoch 932, Loss: 0.0017872308490041178, Final Batch Loss: 5.938934555160813e-05\n",
      "Epoch 933, Loss: 0.020720621658256277, Final Batch Loss: 8.838853682391346e-05\n",
      "Epoch 934, Loss: 0.009511036056210287, Final Batch Loss: 0.00023951895127538592\n",
      "Epoch 935, Loss: 0.006007453775964677, Final Batch Loss: 0.0005177499842830002\n",
      "Epoch 936, Loss: 0.005837031654664315, Final Batch Loss: 0.00016972185403574258\n",
      "Epoch 937, Loss: 0.010380120715126395, Final Batch Loss: 0.0020496975630521774\n",
      "Epoch 938, Loss: 0.007784057961544022, Final Batch Loss: 0.0004565687559079379\n",
      "Epoch 939, Loss: 0.004027818351460155, Final Batch Loss: 8.159057324519381e-05\n",
      "Epoch 940, Loss: 0.006677203986328095, Final Batch Loss: 0.0007474443409591913\n",
      "Epoch 941, Loss: 0.007337433751672506, Final Batch Loss: 0.004433168563991785\n",
      "Epoch 942, Loss: 0.010404938890133053, Final Batch Loss: 0.000278409686870873\n",
      "Epoch 943, Loss: 0.009750300319865346, Final Batch Loss: 0.0008111754432320595\n",
      "Epoch 944, Loss: 0.004605726935551502, Final Batch Loss: 0.00022774854733143002\n",
      "Epoch 945, Loss: 0.0023096839722711593, Final Batch Loss: 3.627073601819575e-05\n",
      "Epoch 946, Loss: 0.012026477459585294, Final Batch Loss: 0.003770998679101467\n",
      "Epoch 947, Loss: 0.0028645531565416604, Final Batch Loss: 0.00037237079231999815\n",
      "Epoch 948, Loss: 0.010746864099928644, Final Batch Loss: 7.16094727977179e-05\n",
      "Epoch 949, Loss: 0.004745643236674368, Final Batch Loss: 0.0005086934543214738\n",
      "Epoch 950, Loss: 0.007598433112434577, Final Batch Loss: 9.603000216884539e-05\n",
      "Epoch 951, Loss: 0.03269984811777249, Final Batch Loss: 0.0011041753459721804\n",
      "Epoch 952, Loss: 0.0023437923518940806, Final Batch Loss: 0.00025198099319823086\n",
      "Epoch 953, Loss: 0.006496502319350839, Final Batch Loss: 0.001946633099578321\n",
      "Epoch 954, Loss: 0.005661800067173317, Final Batch Loss: 0.0009004383464343846\n",
      "Epoch 955, Loss: 0.007199883490102366, Final Batch Loss: 0.0010157738579437137\n",
      "Epoch 956, Loss: 0.002570563316112384, Final Batch Loss: 0.0006449397769756615\n",
      "Epoch 957, Loss: 0.010746479965746403, Final Batch Loss: 0.00037571846041828394\n",
      "Epoch 958, Loss: 0.00994693028042093, Final Batch Loss: 0.0020248445216566324\n",
      "Epoch 959, Loss: 0.012507907272492957, Final Batch Loss: 3.4345841868343996e-06\n",
      "Epoch 960, Loss: 0.016535025933990255, Final Batch Loss: 0.013764006085693836\n",
      "Epoch 961, Loss: 0.00794680852413876, Final Batch Loss: 9.108240919886157e-05\n",
      "Epoch 962, Loss: 0.03721749084070325, Final Batch Loss: 0.0010986928828060627\n",
      "Epoch 963, Loss: 0.0833933633111883, Final Batch Loss: 0.08108869194984436\n",
      "Epoch 964, Loss: 0.016496563446708024, Final Batch Loss: 0.0004539277870208025\n",
      "Epoch 965, Loss: 0.013644465361721814, Final Batch Loss: 0.0003342479467391968\n",
      "Epoch 966, Loss: 0.021258372977172257, Final Batch Loss: 5.556176256504841e-05\n",
      "Epoch 967, Loss: 0.011599348246818408, Final Batch Loss: 0.000349612528225407\n",
      "Epoch 968, Loss: 0.0057136755203828216, Final Batch Loss: 0.0006609719712287188\n",
      "Epoch 969, Loss: 0.004516206448897719, Final Batch Loss: 0.0008845303673297167\n",
      "Epoch 970, Loss: 0.012772832204063889, Final Batch Loss: 0.00011715795699274167\n",
      "Epoch 971, Loss: 0.008993264054879546, Final Batch Loss: 0.0009221103391610086\n",
      "Epoch 972, Loss: 0.029440308164339513, Final Batch Loss: 0.0005517078679986298\n",
      "Epoch 973, Loss: 0.005764619098044932, Final Batch Loss: 0.0022167505230754614\n",
      "Epoch 974, Loss: 0.007271045818924904, Final Batch Loss: 0.0002744878875091672\n",
      "Epoch 975, Loss: 0.01181189646013081, Final Batch Loss: 0.0006433535018004477\n",
      "Epoch 976, Loss: 0.0042521265568211675, Final Batch Loss: 0.0009665035177022219\n",
      "Epoch 977, Loss: 0.01726915960898623, Final Batch Loss: 0.0012848037295043468\n",
      "Epoch 978, Loss: 0.024166917661204934, Final Batch Loss: 0.020878152921795845\n",
      "Epoch 979, Loss: 0.0019488280486257281, Final Batch Loss: 3.324387580505572e-05\n",
      "Epoch 980, Loss: 0.01172932464396581, Final Batch Loss: 0.00042996203410439193\n",
      "Epoch 981, Loss: 0.008855109990690835, Final Batch Loss: 0.0001274447567993775\n",
      "Epoch 982, Loss: 0.020313948683906347, Final Batch Loss: 0.000586753070820123\n",
      "Epoch 983, Loss: 0.004408853244967759, Final Batch Loss: 0.002524968469515443\n",
      "Epoch 984, Loss: 0.006307212170213461, Final Batch Loss: 0.0007242534193210304\n",
      "Epoch 985, Loss: 0.0077567899716086686, Final Batch Loss: 0.0005057856324128807\n",
      "Epoch 986, Loss: 0.004656505479943007, Final Batch Loss: 5.545176099985838e-05\n",
      "Epoch 987, Loss: 0.010623395850416273, Final Batch Loss: 0.007317769806832075\n",
      "Epoch 988, Loss: 0.0019639758829725906, Final Batch Loss: 0.00017884645785670727\n",
      "Epoch 989, Loss: 0.044471433175203856, Final Batch Loss: 9.891951776808128e-05\n",
      "Epoch 990, Loss: 0.007228150527225807, Final Batch Loss: 0.00010783970355987549\n",
      "Epoch 991, Loss: 0.006661830353550613, Final Batch Loss: 0.0008839852525852621\n",
      "Epoch 992, Loss: 0.005761332344263792, Final Batch Loss: 8.393640746362507e-05\n",
      "Epoch 993, Loss: 0.004641493665985763, Final Batch Loss: 0.0005635142442770302\n",
      "Epoch 994, Loss: 0.009526972426101565, Final Batch Loss: 0.0004893653676845133\n",
      "Epoch 995, Loss: 0.007651646404610801, Final Batch Loss: 3.956157797802007e-06\n",
      "Epoch 996, Loss: 0.004199266288196668, Final Batch Loss: 0.0017570903291925788\n",
      "Epoch 997, Loss: 0.03425697673810646, Final Batch Loss: 0.0005747111863456666\n",
      "Epoch 998, Loss: 0.004404468112625182, Final Batch Loss: 0.000380696845240891\n",
      "Epoch 999, Loss: 0.00282904805499129, Final Batch Loss: 0.0004864663351327181\n",
      "Epoch 1000, Loss: 0.0046686234418302774, Final Batch Loss: 3.0108349164947867e-05\n",
      "Epoch 1001, Loss: 0.037659984052879736, Final Batch Loss: 0.03547142818570137\n",
      "Epoch 1002, Loss: 0.016670993325533345, Final Batch Loss: 0.0005012775654904544\n",
      "Epoch 1003, Loss: 0.008263971481937915, Final Batch Loss: 0.0005544392042793334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1004, Loss: 0.011902887257747352, Final Batch Loss: 0.0003955221036449075\n",
      "Epoch 1005, Loss: 0.010481606223038398, Final Batch Loss: 0.00022878915478941053\n",
      "Epoch 1006, Loss: 0.005893033987376839, Final Batch Loss: 0.0008780165226198733\n",
      "Epoch 1007, Loss: 0.002631309151183814, Final Batch Loss: 0.00044456790783442557\n",
      "Epoch 1008, Loss: 0.022162472072523087, Final Batch Loss: 0.011365472339093685\n",
      "Epoch 1009, Loss: 0.010078929961309768, Final Batch Loss: 0.0001788932568160817\n",
      "Epoch 1010, Loss: 0.04848291462985799, Final Batch Loss: 0.03002885729074478\n",
      "Epoch 1011, Loss: 0.005200943414820358, Final Batch Loss: 0.00028056869632564485\n",
      "Epoch 1012, Loss: 0.016478791367262602, Final Batch Loss: 0.011868201196193695\n",
      "Epoch 1013, Loss: 0.028385103098116815, Final Batch Loss: 0.013466437347233295\n",
      "Epoch 1014, Loss: 0.021017545484937727, Final Batch Loss: 0.0011388984275981784\n",
      "Epoch 1015, Loss: 0.009112343424931169, Final Batch Loss: 0.0010230945190414786\n",
      "Epoch 1016, Loss: 0.011155646003317088, Final Batch Loss: 0.0009914259426295757\n",
      "Epoch 1017, Loss: 0.017627153149078367, Final Batch Loss: 4.401990372571163e-05\n",
      "Epoch 1018, Loss: 0.0090181227424182, Final Batch Loss: 0.0018626837991178036\n",
      "Epoch 1019, Loss: 0.01006928106653504, Final Batch Loss: 0.0002543938753660768\n",
      "Epoch 1020, Loss: 0.007648316153790802, Final Batch Loss: 0.0005044114659540355\n",
      "Epoch 1021, Loss: 0.020682912407210097, Final Batch Loss: 0.0013492695288732648\n",
      "Epoch 1022, Loss: 0.00674539094325155, Final Batch Loss: 0.0007471381686627865\n",
      "Epoch 1023, Loss: 0.0013186747528379783, Final Batch Loss: 4.878148320131004e-05\n",
      "Epoch 1024, Loss: 0.012613994214916602, Final Batch Loss: 0.0014166304608806968\n",
      "Epoch 1025, Loss: 0.0029951709148008376, Final Batch Loss: 0.0007806012872606516\n",
      "Epoch 1026, Loss: 0.01793926497339271, Final Batch Loss: 0.00032871236908249557\n",
      "Epoch 1027, Loss: 0.0038299615098367212, Final Batch Loss: 3.027073216799181e-05\n",
      "Epoch 1028, Loss: 0.007305478386115283, Final Batch Loss: 0.0009462192538194358\n",
      "Epoch 1029, Loss: 0.008279976987978444, Final Batch Loss: 0.003283462254330516\n",
      "Epoch 1030, Loss: 0.004248515848303214, Final Batch Loss: 0.00047942737000994384\n",
      "Epoch 1031, Loss: 0.0074398268916411325, Final Batch Loss: 0.0003928236837964505\n",
      "Epoch 1032, Loss: 0.07058366923592985, Final Batch Loss: 0.0003457525745034218\n",
      "Epoch 1033, Loss: 0.0045904511353001, Final Batch Loss: 0.0005892920889891684\n",
      "Epoch 1034, Loss: 0.004949985479470342, Final Batch Loss: 0.0006852273945696652\n",
      "Epoch 1035, Loss: 0.00768136844271794, Final Batch Loss: 0.0026240528095513582\n",
      "Epoch 1036, Loss: 0.014018362271599472, Final Batch Loss: 0.001055715954862535\n",
      "Epoch 1037, Loss: 0.010157949494896457, Final Batch Loss: 0.0004266234755050391\n",
      "Epoch 1038, Loss: 0.00538825971307233, Final Batch Loss: 0.00031425594352185726\n",
      "Epoch 1039, Loss: 0.010945455982437124, Final Batch Loss: 3.611982901929878e-05\n",
      "Epoch 1040, Loss: 0.012429851689375937, Final Batch Loss: 0.003912626300007105\n",
      "Epoch 1041, Loss: 0.003376274660695344, Final Batch Loss: 0.0004418193129822612\n",
      "Epoch 1042, Loss: 0.0035933922335971147, Final Batch Loss: 0.0015988625818863511\n",
      "Epoch 1043, Loss: 0.003854924929328263, Final Batch Loss: 0.0004887758404947817\n",
      "Epoch 1044, Loss: 0.0019386027997825295, Final Batch Loss: 0.0002534432278480381\n",
      "Epoch 1045, Loss: 0.00563984113978222, Final Batch Loss: 0.001190435723401606\n",
      "Epoch 1046, Loss: 0.00285283854464069, Final Batch Loss: 0.0003908048092853278\n",
      "Epoch 1047, Loss: 0.0072257102583535016, Final Batch Loss: 0.0023373581934720278\n",
      "Epoch 1048, Loss: 0.0049204877723241225, Final Batch Loss: 0.00014697764709126204\n",
      "Epoch 1049, Loss: 0.004519881680607796, Final Batch Loss: 0.0002656045544426888\n",
      "Epoch 1050, Loss: 0.0030196030065781088, Final Batch Loss: 1.2863901247328613e-05\n",
      "Epoch 1051, Loss: 0.004815846390556544, Final Batch Loss: 0.000903247797396034\n",
      "Epoch 1052, Loss: 0.021223601075689658, Final Batch Loss: 2.0293640773161314e-05\n",
      "Epoch 1053, Loss: 0.005221473780693486, Final Batch Loss: 0.00015444272139575332\n",
      "Epoch 1054, Loss: 0.006947594054508954, Final Batch Loss: 0.0001540077937534079\n",
      "Epoch 1055, Loss: 0.003899307559549925, Final Batch Loss: 2.6736395739135332e-05\n",
      "Epoch 1056, Loss: 0.026753191439638613, Final Batch Loss: 4.28502207796555e-05\n",
      "Epoch 1057, Loss: 0.004045041918288916, Final Batch Loss: 0.0005567235639318824\n",
      "Epoch 1058, Loss: 0.01182891198550351, Final Batch Loss: 0.0005620261654257774\n",
      "Epoch 1059, Loss: 0.01169599548302358, Final Batch Loss: 6.78349970257841e-05\n",
      "Epoch 1060, Loss: 0.020700821187347174, Final Batch Loss: 0.00037233089096844196\n",
      "Epoch 1061, Loss: 0.007148286575102247, Final Batch Loss: 0.00017226581985596567\n",
      "Epoch 1062, Loss: 0.0034792087972164154, Final Batch Loss: 0.0005297684692777693\n",
      "Epoch 1063, Loss: 0.020356665860163048, Final Batch Loss: 0.0002448419400025159\n",
      "Epoch 1064, Loss: 0.004152893248829059, Final Batch Loss: 0.00023648682690691203\n",
      "Epoch 1065, Loss: 0.008777172606642125, Final Batch Loss: 5.527639223146252e-05\n",
      "Epoch 1066, Loss: 0.026965967961587012, Final Batch Loss: 0.02456268109381199\n",
      "Epoch 1067, Loss: 0.010005498101236299, Final Batch Loss: 0.006101456005126238\n",
      "Epoch 1068, Loss: 0.009325438408666287, Final Batch Loss: 6.258455300667265e-07\n",
      "Epoch 1069, Loss: 0.013317806995473802, Final Batch Loss: 0.00023561966372653842\n",
      "Epoch 1070, Loss: 0.0040147246909327805, Final Batch Loss: 0.0001293116365559399\n",
      "Epoch 1071, Loss: 0.005127187061589211, Final Batch Loss: 0.001471556257456541\n",
      "Epoch 1072, Loss: 0.00733057624893263, Final Batch Loss: 0.0018685180693864822\n",
      "Epoch 1073, Loss: 0.0036405781588655373, Final Batch Loss: 5.304494607116794e-06\n",
      "Epoch 1074, Loss: 0.02071412069926737, Final Batch Loss: 9.113246778724715e-05\n",
      "Epoch 1075, Loss: 0.012829543076804839, Final Batch Loss: 0.00017407954146619886\n",
      "Epoch 1076, Loss: 0.004028662224300206, Final Batch Loss: 0.0008656096179038286\n",
      "Epoch 1077, Loss: 0.008258453744929284, Final Batch Loss: 0.0005633853143081069\n",
      "Epoch 1078, Loss: 0.0027828272577608004, Final Batch Loss: 0.0008236050489358604\n",
      "Epoch 1079, Loss: 0.004720410159279709, Final Batch Loss: 2.9324672141228803e-05\n",
      "Epoch 1080, Loss: 0.015088174201082438, Final Batch Loss: 0.010884868912398815\n",
      "Epoch 1081, Loss: 0.020653158135246485, Final Batch Loss: 0.004019167739897966\n",
      "Epoch 1082, Loss: 0.0023772561398800462, Final Batch Loss: 0.0009825858287513256\n",
      "Epoch 1083, Loss: 0.002589023672044277, Final Batch Loss: 0.0008590337238274515\n",
      "Epoch 1084, Loss: 0.0068205209681764245, Final Batch Loss: 0.0001808030647225678\n",
      "Epoch 1085, Loss: 0.008473009977024049, Final Batch Loss: 0.000281471642665565\n",
      "Epoch 1086, Loss: 0.005116475163958967, Final Batch Loss: 0.0011944180587306619\n",
      "Epoch 1087, Loss: 0.003074560809182003, Final Batch Loss: 0.0011532778153195977\n",
      "Epoch 1088, Loss: 0.0038837262109154835, Final Batch Loss: 0.0018883071606978774\n",
      "Epoch 1089, Loss: 0.006520022521726787, Final Batch Loss: 0.0010357723804190755\n",
      "Epoch 1090, Loss: 0.012980673724086955, Final Batch Loss: 0.00046407818445004523\n",
      "Epoch 1091, Loss: 0.02934395585907623, Final Batch Loss: 0.0006393917719833553\n",
      "Epoch 1092, Loss: 0.005527614994207397, Final Batch Loss: 0.00044847463141195476\n",
      "Epoch 1093, Loss: 0.012866388977272436, Final Batch Loss: 0.0004471854481380433\n",
      "Epoch 1094, Loss: 0.029779189731925726, Final Batch Loss: 0.01637793891131878\n",
      "Epoch 1095, Loss: 0.005360215378459543, Final Batch Loss: 0.002524611772969365\n",
      "Epoch 1096, Loss: 0.004820321684064766, Final Batch Loss: 2.187907057304983e-06\n",
      "Epoch 1097, Loss: 0.0036090144130866975, Final Batch Loss: 0.0004538368375506252\n",
      "Epoch 1098, Loss: 0.029961259569972754, Final Batch Loss: 0.00022209198505152017\n",
      "Epoch 1099, Loss: 0.0031279771064873785, Final Batch Loss: 0.0017721011536195874\n",
      "Epoch 1100, Loss: 0.004657286423025653, Final Batch Loss: 0.00030613926355727017\n",
      "Epoch 1101, Loss: 0.014881224487908185, Final Batch Loss: 0.00024322792887687683\n",
      "Epoch 1102, Loss: 0.011254167366132606, Final Batch Loss: 0.00010045868839370087\n",
      "Epoch 1103, Loss: 0.00856923074752558, Final Batch Loss: 4.55964618595317e-05\n",
      "Epoch 1104, Loss: 0.0033898768815561198, Final Batch Loss: 0.0001193474090541713\n",
      "Epoch 1105, Loss: 0.005745803675381467, Final Batch Loss: 0.0008121749851852655\n",
      "Epoch 1106, Loss: 0.002781686654088844, Final Batch Loss: 1.4993672266427893e-05\n",
      "Epoch 1107, Loss: 0.002925381879322231, Final Batch Loss: 0.00014298068708740175\n",
      "Epoch 1108, Loss: 0.0021788935919175856, Final Batch Loss: 8.622919995104894e-05\n",
      "Epoch 1109, Loss: 0.0012138937995587185, Final Batch Loss: 5.543067800317658e-06\n",
      "Epoch 1110, Loss: 0.02695413667242974, Final Batch Loss: 0.0016125276451930404\n",
      "Epoch 1111, Loss: 0.0538217150606215, Final Batch Loss: 0.05166350677609444\n",
      "Epoch 1112, Loss: 0.001749381691297458, Final Batch Loss: 3.1191802918328904e-06\n",
      "Epoch 1113, Loss: 0.006874099053675309, Final Batch Loss: 0.0003132070123683661\n",
      "Epoch 1114, Loss: 0.004576038336381316, Final Batch Loss: 0.0010044401278719306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1115, Loss: 0.003618463466409594, Final Batch Loss: 0.0010382910259068012\n",
      "Epoch 1116, Loss: 0.004506113793468103, Final Batch Loss: 0.0003142515488434583\n",
      "Epoch 1117, Loss: 0.028282179933739826, Final Batch Loss: 0.0027046233881264925\n",
      "Epoch 1118, Loss: 0.01582711935043335, Final Batch Loss: 0.0019125817343592644\n",
      "Epoch 1119, Loss: 0.009951063453627285, Final Batch Loss: 3.116725565632805e-05\n",
      "Epoch 1120, Loss: 0.004529062120127492, Final Batch Loss: 5.063820572104305e-05\n",
      "Epoch 1121, Loss: 0.00854285822060774, Final Batch Loss: 6.016772749717347e-05\n",
      "Epoch 1122, Loss: 0.008124702027998865, Final Batch Loss: 0.0018295267364010215\n",
      "Epoch 1123, Loss: 0.007009387059952132, Final Batch Loss: 0.00014191171794664115\n",
      "Epoch 1124, Loss: 0.0028445903735700995, Final Batch Loss: 0.00044006670941598713\n",
      "Epoch 1125, Loss: 0.004464830213692039, Final Batch Loss: 0.0008720977348275483\n",
      "Epoch 1126, Loss: 0.0019899856197298504, Final Batch Loss: 0.00010064282832900062\n",
      "Epoch 1127, Loss: 0.0032948495645541698, Final Batch Loss: 0.001807842985726893\n",
      "Epoch 1128, Loss: 0.006801573006669059, Final Batch Loss: 0.00034802162554115057\n",
      "Epoch 1129, Loss: 0.0027606604853644967, Final Batch Loss: 0.0010391130344942212\n",
      "Epoch 1130, Loss: 0.0028409425140125677, Final Batch Loss: 0.00013114708417560905\n",
      "Epoch 1131, Loss: 0.00297121936455369, Final Batch Loss: 0.00034765774034895003\n",
      "Epoch 1132, Loss: 0.004041664738906547, Final Batch Loss: 0.0018684427486732602\n",
      "Epoch 1133, Loss: 0.0042242787894792855, Final Batch Loss: 0.00021227227989584208\n",
      "Epoch 1134, Loss: 0.013765420284471475, Final Batch Loss: 0.007034141104668379\n",
      "Epoch 1135, Loss: 0.0030473163060378283, Final Batch Loss: 0.0018771608592942357\n",
      "Epoch 1136, Loss: 0.001738343620672822, Final Batch Loss: 0.0007751083467155695\n",
      "Epoch 1137, Loss: 0.001450252590529999, Final Batch Loss: 6.610660875594476e-06\n",
      "Epoch 1138, Loss: 0.0051846555434167385, Final Batch Loss: 0.0025754470843821764\n",
      "Epoch 1139, Loss: 0.003768914299143944, Final Batch Loss: 8.20619534351863e-05\n",
      "Epoch 1140, Loss: 0.006310088065220043, Final Batch Loss: 0.0005932203494012356\n",
      "Epoch 1141, Loss: 0.006887630588607863, Final Batch Loss: 0.0028024103958159685\n",
      "Epoch 1142, Loss: 0.006769323990738485, Final Batch Loss: 9.403209696756676e-05\n",
      "Epoch 1143, Loss: 0.03691313456511125, Final Batch Loss: 0.028859956189990044\n",
      "Epoch 1144, Loss: 0.005642781674396247, Final Batch Loss: 0.00016717438120394945\n",
      "Epoch 1145, Loss: 0.01888734033855144, Final Batch Loss: 0.015358456410467625\n",
      "Epoch 1146, Loss: 0.014035491120012011, Final Batch Loss: 9.719753143144771e-05\n",
      "Epoch 1147, Loss: 0.005167546813027002, Final Batch Loss: 0.00017275290156248957\n",
      "Epoch 1148, Loss: 0.00244754106097389, Final Batch Loss: 0.0014637402491644025\n",
      "Epoch 1149, Loss: 0.005913559787586564, Final Batch Loss: 3.255883711972274e-05\n",
      "Epoch 1150, Loss: 0.047297666322265286, Final Batch Loss: 8.366583642782643e-05\n",
      "Epoch 1151, Loss: 0.0021687742846552283, Final Batch Loss: 0.0003825940366368741\n",
      "Epoch 1152, Loss: 0.024702352995518595, Final Batch Loss: 0.02287464030086994\n",
      "Epoch 1153, Loss: 0.006381838960805908, Final Batch Loss: 0.0012259249342605472\n",
      "Epoch 1154, Loss: 0.003269243723480031, Final Batch Loss: 0.0019718960393220186\n",
      "Epoch 1155, Loss: 0.0047405855293618515, Final Batch Loss: 0.0004622952255886048\n",
      "Epoch 1156, Loss: 0.002881043699744623, Final Batch Loss: 0.0002739961782936007\n",
      "Epoch 1157, Loss: 0.002930763381300494, Final Batch Loss: 0.0015502007445320487\n",
      "Epoch 1158, Loss: 0.005128368077066625, Final Batch Loss: 3.1340425721282372e-06\n",
      "Epoch 1159, Loss: 0.0009766983494046144, Final Batch Loss: 0.00021974177798256278\n",
      "Epoch 1160, Loss: 0.003002432466018945, Final Batch Loss: 0.0018393573118373752\n",
      "Epoch 1161, Loss: 0.005774785768153379, Final Batch Loss: 3.7132998841116205e-05\n",
      "Epoch 1162, Loss: 0.030007317778654397, Final Batch Loss: 0.0032631512731313705\n",
      "Epoch 1163, Loss: 0.010407095644040965, Final Batch Loss: 0.002959944074973464\n",
      "Epoch 1164, Loss: 0.0006617906728934031, Final Batch Loss: 5.249199966783635e-05\n",
      "Epoch 1165, Loss: 0.02128978059045039, Final Batch Loss: 0.00030008083558641374\n",
      "Epoch 1166, Loss: 0.013525328162359074, Final Batch Loss: 0.012802060693502426\n",
      "Epoch 1167, Loss: 0.004119226156035438, Final Batch Loss: 0.00017238866712432355\n",
      "Epoch 1168, Loss: 0.0014980118330640835, Final Batch Loss: 2.461068106640596e-06\n",
      "Epoch 1169, Loss: 0.0011026596839656122, Final Batch Loss: 0.00018744751287158579\n",
      "Epoch 1170, Loss: 0.0028088724211556837, Final Batch Loss: 0.00021038639533799142\n",
      "Epoch 1171, Loss: 0.00228141805564519, Final Batch Loss: 7.754909893264994e-05\n",
      "Epoch 1172, Loss: 0.01956103220800287, Final Batch Loss: 5.723943104385398e-05\n",
      "Epoch 1173, Loss: 0.001440600237401668, Final Batch Loss: 0.00010012662824010476\n",
      "Epoch 1174, Loss: 0.022965282580116764, Final Batch Loss: 0.00038763938937336206\n",
      "Epoch 1175, Loss: 0.004645950859412551, Final Batch Loss: 0.00022094394080340862\n",
      "Epoch 1176, Loss: 0.008416777418460697, Final Batch Loss: 0.00048198853619396687\n",
      "Epoch 1177, Loss: 0.02570807890879223, Final Batch Loss: 7.781002932460979e-05\n",
      "Epoch 1178, Loss: 0.007934877849038457, Final Batch Loss: 4.5188437070464715e-05\n",
      "Epoch 1179, Loss: 0.001914217893499881, Final Batch Loss: 0.00013477336324285716\n",
      "Epoch 1180, Loss: 0.00978716321696993, Final Batch Loss: 0.0077913966961205006\n",
      "Epoch 1181, Loss: 0.005219513284828281, Final Batch Loss: 3.9449278119718656e-05\n",
      "Epoch 1182, Loss: 0.03697317204205319, Final Batch Loss: 0.005535776261240244\n",
      "Epoch 1183, Loss: 0.005252393486443907, Final Batch Loss: 0.0005126447067596018\n",
      "Epoch 1184, Loss: 0.0032865139946807176, Final Batch Loss: 0.0017515859799459577\n",
      "Epoch 1185, Loss: 0.007019771455816226, Final Batch Loss: 4.138298754696734e-05\n",
      "Epoch 1186, Loss: 0.002491710474714637, Final Batch Loss: 0.00046156058670021594\n",
      "Epoch 1187, Loss: 0.016218736971495673, Final Batch Loss: 0.0009980301838368177\n",
      "Epoch 1188, Loss: 0.0375316871504765, Final Batch Loss: 0.030915124341845512\n",
      "Epoch 1189, Loss: 0.08186434843810275, Final Batch Loss: 0.06504781544208527\n",
      "Epoch 1190, Loss: 0.013976153219118714, Final Batch Loss: 0.00013519922504201531\n",
      "Epoch 1191, Loss: 0.023076530691469088, Final Batch Loss: 8.079051622189581e-05\n",
      "Epoch 1192, Loss: 0.06024608976440504, Final Batch Loss: 0.0005292603163979948\n",
      "Epoch 1193, Loss: 0.04230731737334281, Final Batch Loss: 0.004803887102752924\n",
      "Epoch 1194, Loss: 0.006887582712806761, Final Batch Loss: 0.0010685973102226853\n",
      "Epoch 1195, Loss: 0.05119662103243172, Final Batch Loss: 0.00017561903223395348\n",
      "Epoch 1196, Loss: 0.003936634631827474, Final Batch Loss: 0.001279196236282587\n",
      "Epoch 1197, Loss: 0.004271749465260655, Final Batch Loss: 0.000306985923089087\n",
      "Epoch 1198, Loss: 0.005073672393336892, Final Batch Loss: 0.0029115413781255484\n",
      "Epoch 1199, Loss: 0.019450755178695545, Final Batch Loss: 9.367315215058625e-05\n",
      "Epoch 1200, Loss: 0.01609678380191326, Final Batch Loss: 0.00047148659359663725\n",
      "Epoch 1201, Loss: 0.0077065042714821175, Final Batch Loss: 0.00023438928474206477\n",
      "Epoch 1202, Loss: 0.014794462127611041, Final Batch Loss: 0.0012946107890456915\n",
      "Epoch 1203, Loss: 0.015065384737681597, Final Batch Loss: 7.807117071934044e-05\n",
      "Epoch 1204, Loss: 0.0023856529587646946, Final Batch Loss: 0.0001844880316639319\n",
      "Epoch 1205, Loss: 0.030651639914140105, Final Batch Loss: 0.00756570091471076\n",
      "Epoch 1206, Loss: 0.009382919291965663, Final Batch Loss: 0.0049732099287211895\n",
      "Epoch 1207, Loss: 0.00811288776458241, Final Batch Loss: 0.0002577359846327454\n",
      "Epoch 1208, Loss: 0.009919950825860724, Final Batch Loss: 0.000443025870481506\n",
      "Epoch 1209, Loss: 0.004072647076100111, Final Batch Loss: 0.0007662118296138942\n",
      "Epoch 1210, Loss: 0.018001463773543946, Final Batch Loss: 0.00021375475625973195\n",
      "Epoch 1211, Loss: 0.010523712233407423, Final Batch Loss: 0.0023619295097887516\n",
      "Epoch 1212, Loss: 0.006520369563077111, Final Batch Loss: 7.090825965860859e-05\n",
      "Epoch 1213, Loss: 0.003753656055778265, Final Batch Loss: 0.0017224154435098171\n",
      "Epoch 1214, Loss: 0.0056199305690824986, Final Batch Loss: 4.6751840272918344e-05\n",
      "Epoch 1215, Loss: 0.004749443647597218, Final Batch Loss: 4.7565587010467425e-05\n",
      "Epoch 1216, Loss: 0.01571622211486101, Final Batch Loss: 0.011461920104920864\n",
      "Epoch 1217, Loss: 0.00537524895844399, Final Batch Loss: 3.302865297882818e-05\n",
      "Epoch 1218, Loss: 0.0017299094652116764, Final Batch Loss: 3.912610191036947e-05\n",
      "Epoch 1219, Loss: 0.0018025729550572578, Final Batch Loss: 1.813698690966703e-05\n",
      "Epoch 1220, Loss: 0.0052265522826928645, Final Batch Loss: 0.000176049696165137\n",
      "Epoch 1221, Loss: 0.024469213152769953, Final Batch Loss: 0.00010544108226895332\n",
      "Epoch 1222, Loss: 0.0010193371344939806, Final Batch Loss: 1.6538928321097046e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1223, Loss: 0.02179828757471114, Final Batch Loss: 1.82073545147432e-05\n",
      "Epoch 1224, Loss: 0.006203392054885626, Final Batch Loss: 0.001021681702695787\n",
      "Epoch 1225, Loss: 0.014248812272853684, Final Batch Loss: 0.0010679414262995124\n",
      "Epoch 1226, Loss: 0.00329099633381702, Final Batch Loss: 9.870226494967937e-05\n",
      "Epoch 1227, Loss: 0.002799091103952378, Final Batch Loss: 0.00018092204118147492\n",
      "Epoch 1228, Loss: 0.004929776156131993, Final Batch Loss: 2.2209043891052715e-05\n",
      "Epoch 1229, Loss: 0.014418639919313136, Final Batch Loss: 0.0038285786285996437\n",
      "Epoch 1230, Loss: 0.0022112164879217744, Final Batch Loss: 0.0003186410467606038\n",
      "Epoch 1231, Loss: 0.0047104509139899164, Final Batch Loss: 9.352187043987215e-05\n",
      "Epoch 1232, Loss: 0.0012448977795429528, Final Batch Loss: 0.00019694806542247534\n",
      "Epoch 1233, Loss: 0.006563100439962, Final Batch Loss: 0.00042239727918058634\n",
      "Epoch 1234, Loss: 0.002620260784169659, Final Batch Loss: 0.0011083058780059218\n",
      "Epoch 1235, Loss: 0.012056099309120327, Final Batch Loss: 0.0011246601352468133\n",
      "Epoch 1236, Loss: 0.008579005661886185, Final Batch Loss: 0.0006421420257538557\n",
      "Epoch 1237, Loss: 0.002742706914432347, Final Batch Loss: 0.0005412887549027801\n",
      "Epoch 1238, Loss: 0.00943222106070607, Final Batch Loss: 5.6999382650246844e-05\n",
      "Epoch 1239, Loss: 0.003024151285899279, Final Batch Loss: 9.098871487367433e-06\n",
      "Epoch 1240, Loss: 0.014448244066443294, Final Batch Loss: 0.008986294269561768\n",
      "Epoch 1241, Loss: 0.006845634517958388, Final Batch Loss: 0.0010628922609612346\n",
      "Epoch 1242, Loss: 0.00194653005382861, Final Batch Loss: 3.86982828786131e-05\n",
      "Epoch 1243, Loss: 0.010856550943572074, Final Batch Loss: 0.002901816973462701\n",
      "Epoch 1244, Loss: 0.016744861961342394, Final Batch Loss: 0.012830663472414017\n",
      "Epoch 1245, Loss: 0.00436578037624713, Final Batch Loss: 0.001254912931472063\n",
      "Epoch 1246, Loss: 0.0016636299551464617, Final Batch Loss: 0.0001837637828430161\n",
      "Epoch 1247, Loss: 0.004227182149861619, Final Batch Loss: 6.088861937314505e-06\n",
      "Epoch 1248, Loss: 0.01968958039651625, Final Batch Loss: 0.0008730156696401536\n",
      "Epoch 1249, Loss: 0.005709910954465158, Final Batch Loss: 0.0036203470081090927\n",
      "Epoch 1250, Loss: 0.0017657602729741484, Final Batch Loss: 0.0009406055905856192\n",
      "Epoch 1251, Loss: 0.010021511086961254, Final Batch Loss: 0.00034290680196136236\n",
      "Epoch 1252, Loss: 0.0020878220784652513, Final Batch Loss: 0.0004074382595717907\n",
      "Epoch 1253, Loss: 0.0032781136615085416, Final Batch Loss: 9.728135046316311e-05\n",
      "Epoch 1254, Loss: 0.026174153161264258, Final Batch Loss: 5.069371036370285e-05\n",
      "Epoch 1255, Loss: 0.034886682173237205, Final Batch Loss: 0.03269163519144058\n",
      "Epoch 1256, Loss: 0.009735302609442442, Final Batch Loss: 1.3556115845858585e-05\n",
      "Epoch 1257, Loss: 0.023892386656370945, Final Batch Loss: 2.767554542515427e-05\n",
      "Epoch 1258, Loss: 0.046388019873120356, Final Batch Loss: 0.0427824966609478\n",
      "Epoch 1259, Loss: 0.031184834137093276, Final Batch Loss: 0.024853596463799477\n",
      "Epoch 1260, Loss: 0.1473854635260068, Final Batch Loss: 0.12321591377258301\n",
      "Epoch 1261, Loss: 0.007139857294532703, Final Batch Loss: 3.07235932268668e-05\n",
      "Epoch 1262, Loss: 0.021469217841513455, Final Batch Loss: 0.0016922205686569214\n",
      "Epoch 1263, Loss: 0.0024008378095459193, Final Batch Loss: 0.00037068992969579995\n",
      "Epoch 1264, Loss: 0.016055217944085598, Final Batch Loss: 0.0006420346908271313\n",
      "Epoch 1265, Loss: 0.0019021043262910098, Final Batch Loss: 0.0001092783932108432\n",
      "Epoch 1266, Loss: 0.011521460022777319, Final Batch Loss: 0.0046921479515731335\n",
      "Epoch 1267, Loss: 0.04490013822214678, Final Batch Loss: 0.03952857851982117\n",
      "Epoch 1268, Loss: 0.0020722389308502898, Final Batch Loss: 5.907333979848772e-05\n",
      "Epoch 1269, Loss: 0.010331005192711018, Final Batch Loss: 0.00023083608539309353\n",
      "Epoch 1270, Loss: 0.004464356403332204, Final Batch Loss: 0.0009203776135109365\n",
      "Epoch 1271, Loss: 0.00545460544526577, Final Batch Loss: 0.0003158609615638852\n",
      "Epoch 1272, Loss: 0.025807517988141626, Final Batch Loss: 0.002762553049251437\n",
      "Epoch 1273, Loss: 0.0041878578485921025, Final Batch Loss: 5.274213617667556e-05\n",
      "Epoch 1274, Loss: 0.058032575630932115, Final Batch Loss: 0.00018617940077092499\n",
      "Epoch 1275, Loss: 0.007648374943528324, Final Batch Loss: 0.00018912414088845253\n",
      "Epoch 1276, Loss: 0.008158224576618522, Final Batch Loss: 0.000748954713344574\n",
      "Epoch 1277, Loss: 0.0020741032349178568, Final Batch Loss: 0.00016615445201750845\n",
      "Epoch 1278, Loss: 0.004236000735545531, Final Batch Loss: 0.00017784535884857178\n",
      "Epoch 1279, Loss: 0.011492011081145392, Final Batch Loss: 2.0538593616947765e-06\n",
      "Epoch 1280, Loss: 0.0030328532739076763, Final Batch Loss: 0.0007889436674304307\n",
      "Epoch 1281, Loss: 0.0013909498738939874, Final Batch Loss: 0.0004876061575487256\n",
      "Epoch 1282, Loss: 0.01667287947202567, Final Batch Loss: 0.0001942823437275365\n",
      "Epoch 1283, Loss: 0.0032441804505651817, Final Batch Loss: 4.270298813935369e-05\n",
      "Epoch 1284, Loss: 0.0020729817042592913, Final Batch Loss: 7.113150786608458e-05\n",
      "Epoch 1285, Loss: 0.007829971771570854, Final Batch Loss: 0.00017496648069936782\n",
      "Epoch 1286, Loss: 0.028217123355716467, Final Batch Loss: 0.00019939104095101357\n",
      "Epoch 1287, Loss: 0.033035883330740035, Final Batch Loss: 0.0012286397395655513\n",
      "Epoch 1288, Loss: 0.00780014498741366, Final Batch Loss: 0.0016385001363232732\n",
      "Epoch 1289, Loss: 0.0043013028625864536, Final Batch Loss: 0.0027969188522547483\n",
      "Epoch 1290, Loss: 0.004411030968185514, Final Batch Loss: 0.0012143304338678718\n",
      "Epoch 1291, Loss: 0.013336667441762984, Final Batch Loss: 0.010143357329070568\n",
      "Epoch 1292, Loss: 0.0022142843663459644, Final Batch Loss: 6.323946581687778e-05\n",
      "Epoch 1293, Loss: 0.02125132502987981, Final Batch Loss: 0.002042254200205207\n",
      "Epoch 1294, Loss: 0.0038726487546227872, Final Batch Loss: 0.0005305817467160523\n",
      "Epoch 1295, Loss: 0.004511882754741237, Final Batch Loss: 0.0003610677376855165\n",
      "Epoch 1296, Loss: 0.022891110158525407, Final Batch Loss: 0.0004060060018673539\n",
      "Epoch 1297, Loss: 0.0012304165793466382, Final Batch Loss: 8.465340215479955e-05\n",
      "Epoch 1298, Loss: 0.005096952932944987, Final Batch Loss: 6.332214979920536e-06\n",
      "Epoch 1299, Loss: 0.01085915620205924, Final Batch Loss: 0.005734503734856844\n",
      "Epoch 1300, Loss: 0.0021034549936302938, Final Batch Loss: 7.251195347635075e-05\n",
      "Epoch 1301, Loss: 0.0031045502109918743, Final Batch Loss: 0.00011569922207854688\n",
      "Epoch 1302, Loss: 0.002974834671476856, Final Batch Loss: 0.0001515158946858719\n",
      "Epoch 1303, Loss: 0.003518878176691942, Final Batch Loss: 0.0006536095752380788\n",
      "Epoch 1304, Loss: 0.003933957093977369, Final Batch Loss: 0.00018013642693404108\n",
      "Epoch 1305, Loss: 0.01172813557786867, Final Batch Loss: 0.0025269549805670977\n",
      "Epoch 1306, Loss: 0.0025035975995706394, Final Batch Loss: 0.0001648657926125452\n",
      "Epoch 1307, Loss: 0.0031395579571835697, Final Batch Loss: 0.0005633232067339122\n",
      "Epoch 1308, Loss: 0.002945391141111031, Final Batch Loss: 0.0019003994530066848\n",
      "Epoch 1309, Loss: 0.0011194642866030335, Final Batch Loss: 2.221010799985379e-05\n",
      "Epoch 1310, Loss: 0.0014076972292969003, Final Batch Loss: 0.0003300935204606503\n",
      "Epoch 1311, Loss: 0.0011907810403499752, Final Batch Loss: 0.0004953180905431509\n",
      "Epoch 1312, Loss: 0.0017241621535504237, Final Batch Loss: 0.0004748059727717191\n",
      "Epoch 1313, Loss: 0.012436494755093008, Final Batch Loss: 0.0018460644641891122\n",
      "Epoch 1314, Loss: 0.0033818324736785144, Final Batch Loss: 0.00045194601989351213\n",
      "Epoch 1315, Loss: 0.002898775608628057, Final Batch Loss: 0.0016865114448592067\n",
      "Epoch 1316, Loss: 0.0029259035472932737, Final Batch Loss: 5.607182902167551e-05\n",
      "Epoch 1317, Loss: 0.005830094298289623, Final Batch Loss: 6.380408740369603e-05\n",
      "Epoch 1318, Loss: 0.003401479305466637, Final Batch Loss: 0.001731405034661293\n",
      "Epoch 1319, Loss: 0.003537524549756199, Final Batch Loss: 0.0007867961539886892\n",
      "Epoch 1320, Loss: 0.016376102983485907, Final Batch Loss: 0.000545213813893497\n",
      "Epoch 1321, Loss: 0.005009903661630233, Final Batch Loss: 3.4271452022949234e-06\n",
      "Epoch 1322, Loss: 0.0021034305755165406, Final Batch Loss: 8.492966298945248e-05\n",
      "Epoch 1323, Loss: 0.0016450451512355357, Final Batch Loss: 3.885997284669429e-05\n",
      "Epoch 1324, Loss: 0.002970486028061714, Final Batch Loss: 0.00015444094606209546\n",
      "Epoch 1325, Loss: 0.017722833465086296, Final Batch Loss: 0.001146251568570733\n",
      "Epoch 1326, Loss: 0.0036311453939106286, Final Batch Loss: 3.1017905257613165e-06\n",
      "Epoch 1327, Loss: 0.003670714737381786, Final Batch Loss: 0.001762370578944683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1328, Loss: 0.004663742147386074, Final Batch Loss: 0.001070767524652183\n",
      "Epoch 1329, Loss: 0.01271413186987047, Final Batch Loss: 0.0109030120074749\n",
      "Epoch 1330, Loss: 0.0024718945351196453, Final Batch Loss: 2.3246437194757164e-05\n",
      "Epoch 1331, Loss: 0.00904181606892962, Final Batch Loss: 0.0001287102495552972\n",
      "Epoch 1332, Loss: 0.004426180719747208, Final Batch Loss: 0.00013097927148919553\n",
      "Epoch 1333, Loss: 0.005323995414073579, Final Batch Loss: 0.0027411312330514193\n",
      "Epoch 1334, Loss: 0.001982977319130441, Final Batch Loss: 3.9372647734126076e-05\n",
      "Epoch 1335, Loss: 0.009338352450868115, Final Batch Loss: 0.0001958616339834407\n",
      "Epoch 1336, Loss: 0.005965556549199391, Final Batch Loss: 0.00011262307089054957\n",
      "Epoch 1337, Loss: 0.003375197236891836, Final Batch Loss: 0.0001908107806229964\n",
      "Epoch 1338, Loss: 0.008033751684706658, Final Batch Loss: 0.004297235980629921\n",
      "Epoch 1339, Loss: 0.012625500385183841, Final Batch Loss: 2.858706284314394e-05\n",
      "Epoch 1340, Loss: 0.0023914446937851608, Final Batch Loss: 0.0006980117759667337\n",
      "Epoch 1341, Loss: 0.004515255655860528, Final Batch Loss: 0.002178356284275651\n",
      "Epoch 1342, Loss: 0.0013782824607915245, Final Batch Loss: 0.0007148236036300659\n",
      "Epoch 1343, Loss: 0.013706337004805391, Final Batch Loss: 7.649205144844018e-07\n",
      "Epoch 1344, Loss: 0.0006030561635270715, Final Batch Loss: 6.168782419990748e-05\n",
      "Epoch 1345, Loss: 0.0013602446906588739, Final Batch Loss: 2.0078534362255596e-05\n",
      "Epoch 1346, Loss: 0.01961319460951927, Final Batch Loss: 1.4842454220342916e-05\n",
      "Epoch 1347, Loss: 0.006920415151398629, Final Batch Loss: 0.00015560846077278256\n",
      "Epoch 1348, Loss: 0.001139024825533852, Final Batch Loss: 0.0001300096046179533\n",
      "Epoch 1349, Loss: 0.0023009298056422267, Final Batch Loss: 4.429760519997217e-05\n",
      "Epoch 1350, Loss: 0.01593570971454028, Final Batch Loss: 0.0003095438005402684\n",
      "Epoch 1351, Loss: 0.009238319318683352, Final Batch Loss: 6.172150460770354e-05\n",
      "Epoch 1352, Loss: 0.004422389640239999, Final Batch Loss: 0.000426651124143973\n",
      "Epoch 1353, Loss: 0.00722479386604391, Final Batch Loss: 0.0006873784586787224\n",
      "Epoch 1354, Loss: 0.004603319626767188, Final Batch Loss: 0.0004036755708511919\n",
      "Epoch 1355, Loss: 0.00643124501038983, Final Batch Loss: 1.9869430616381578e-05\n",
      "Epoch 1356, Loss: 0.009584077895851806, Final Batch Loss: 0.002942608902230859\n",
      "Epoch 1357, Loss: 0.0017751147970557213, Final Batch Loss: 0.0008335001184605062\n",
      "Epoch 1358, Loss: 0.005875251634279266, Final Batch Loss: 0.0029873382300138474\n",
      "Epoch 1359, Loss: 0.0025658824160927907, Final Batch Loss: 0.0005853693000972271\n",
      "Epoch 1360, Loss: 0.04048285377211869, Final Batch Loss: 0.0004654836084228009\n",
      "Epoch 1361, Loss: 0.0026690480444813147, Final Batch Loss: 0.0006910076481290162\n",
      "Epoch 1362, Loss: 0.0014022255381860305, Final Batch Loss: 3.8721442251699045e-05\n",
      "Epoch 1363, Loss: 0.013805978906020755, Final Batch Loss: 0.010207216255366802\n",
      "Epoch 1364, Loss: 0.0008233688495238312, Final Batch Loss: 6.954931450309232e-05\n",
      "Epoch 1365, Loss: 0.010270755650708452, Final Batch Loss: 8.216107380576432e-05\n",
      "Epoch 1366, Loss: 0.012785527636879124, Final Batch Loss: 0.0001244976738234982\n",
      "Epoch 1367, Loss: 0.00450386408920167, Final Batch Loss: 6.411081267287955e-05\n",
      "Epoch 1368, Loss: 0.001181007937702816, Final Batch Loss: 0.00010908625699812546\n",
      "Epoch 1369, Loss: 0.0020789743575733155, Final Batch Loss: 0.00013219341053627431\n",
      "Epoch 1370, Loss: 0.007563900813693181, Final Batch Loss: 0.00028166986885480583\n",
      "Epoch 1371, Loss: 0.0005669463059803093, Final Batch Loss: 3.4693582620093366e-06\n",
      "Epoch 1372, Loss: 0.0064018719131127, Final Batch Loss: 0.0052437917329370975\n",
      "Epoch 1373, Loss: 0.004280156223103404, Final Batch Loss: 0.00043935736175626516\n",
      "Epoch 1374, Loss: 0.01325658737187041, Final Batch Loss: 7.487745460821316e-05\n",
      "Epoch 1375, Loss: 0.001345430079709331, Final Batch Loss: 9.68751646723831e-06\n",
      "Epoch 1376, Loss: 0.0008301124835270457, Final Batch Loss: 7.359429582720622e-05\n",
      "Epoch 1377, Loss: 0.003958246488764416, Final Batch Loss: 0.00025895502767525613\n",
      "Epoch 1378, Loss: 0.005944067001109943, Final Batch Loss: 0.0023436571937054396\n",
      "Epoch 1379, Loss: 0.003976876560955134, Final Batch Loss: 9.188374860968906e-06\n",
      "Epoch 1380, Loss: 0.0025627122377045453, Final Batch Loss: 9.171090641757473e-05\n",
      "Epoch 1381, Loss: 0.007900624557805713, Final Batch Loss: 7.833744894014671e-05\n",
      "Epoch 1382, Loss: 0.02233783112023957, Final Batch Loss: 0.0007706721662543714\n",
      "Epoch 1383, Loss: 0.0022871635301271453, Final Batch Loss: 0.0008535729139111936\n",
      "Epoch 1384, Loss: 0.03162015418638475, Final Batch Loss: 0.002681491896510124\n",
      "Epoch 1385, Loss: 0.002467691636411473, Final Batch Loss: 0.0001456438476452604\n",
      "Epoch 1386, Loss: 0.009604629638488404, Final Batch Loss: 0.00023985143343452364\n",
      "Epoch 1387, Loss: 0.0027876046078745276, Final Batch Loss: 0.001727558672428131\n",
      "Epoch 1388, Loss: 0.004405836021760479, Final Batch Loss: 0.00015399632684420794\n",
      "Epoch 1389, Loss: 0.014982485066866502, Final Batch Loss: 0.000116464972961694\n",
      "Epoch 1390, Loss: 0.0003606740319810342, Final Batch Loss: 0.00016819463053252548\n",
      "Epoch 1391, Loss: 0.0054660100286128, Final Batch Loss: 0.004426419734954834\n",
      "Epoch 1392, Loss: 0.002669487672392279, Final Batch Loss: 0.0005322257638908923\n",
      "Epoch 1393, Loss: 0.007027840598311741, Final Batch Loss: 9.423297160537913e-05\n",
      "Epoch 1394, Loss: 0.001835515216953354, Final Batch Loss: 3.835812458419241e-05\n",
      "Epoch 1395, Loss: 0.0008244649968673912, Final Batch Loss: 3.1266561109077884e-06\n",
      "Epoch 1396, Loss: 0.0006643954318406031, Final Batch Loss: 8.94061258804868e-07\n",
      "Epoch 1397, Loss: 0.0024894509551813826, Final Batch Loss: 0.0006390571943484247\n",
      "Epoch 1398, Loss: 0.0037622383215420996, Final Batch Loss: 9.893182323139627e-06\n",
      "Epoch 1399, Loss: 0.009214689489454031, Final Batch Loss: 0.002291756682097912\n",
      "Epoch 1400, Loss: 0.10791629922459833, Final Batch Loss: 0.10712272673845291\n",
      "Epoch 1401, Loss: 0.0025744780505192466, Final Batch Loss: 0.00010531486623222008\n",
      "Epoch 1402, Loss: 0.04104863930842839, Final Batch Loss: 0.0010336391860619187\n",
      "Epoch 1403, Loss: 0.07569955541111995, Final Batch Loss: 0.00018435409583617002\n",
      "Epoch 1404, Loss: 0.06937933006338426, Final Batch Loss: 5.818062709295191e-05\n",
      "Epoch 1405, Loss: 0.0025733102520462126, Final Batch Loss: 0.0002261368208564818\n",
      "Epoch 1406, Loss: 0.0029427890258375555, Final Batch Loss: 0.0003980140609201044\n",
      "Epoch 1407, Loss: 0.0031234341295203194, Final Batch Loss: 3.426439070608467e-05\n",
      "Epoch 1408, Loss: 0.01883805444231257, Final Batch Loss: 0.0005666788783855736\n",
      "Epoch 1409, Loss: 0.0011047750263060152, Final Batch Loss: 1.4702341104566585e-06\n",
      "Epoch 1410, Loss: 0.01530741568421945, Final Batch Loss: 0.0008187726489268243\n",
      "Epoch 1411, Loss: 0.0072244887705892324, Final Batch Loss: 0.0004244385927449912\n",
      "Epoch 1412, Loss: 0.004930642076942604, Final Batch Loss: 6.850202771602198e-05\n",
      "Epoch 1413, Loss: 0.008518381684552878, Final Batch Loss: 0.000259114196524024\n",
      "Epoch 1414, Loss: 0.0007281136422534473, Final Batch Loss: 0.00016229816537816077\n",
      "Epoch 1415, Loss: 0.0023316729348152876, Final Batch Loss: 0.000739620067179203\n",
      "Epoch 1416, Loss: 0.001418762854882516, Final Batch Loss: 0.00024212842981796712\n",
      "Epoch 1417, Loss: 0.003053874068427831, Final Batch Loss: 0.0004322266613598913\n",
      "Epoch 1418, Loss: 0.0012818084505852312, Final Batch Loss: 0.00028858226141892374\n",
      "Epoch 1419, Loss: 0.009091155894566327, Final Batch Loss: 0.00016610685270279646\n",
      "Epoch 1420, Loss: 0.002172467648051679, Final Batch Loss: 0.00045976703404448926\n",
      "Epoch 1421, Loss: 0.0013943755820946535, Final Batch Loss: 1.9529112250893377e-05\n",
      "Epoch 1422, Loss: 0.003868032043101266, Final Batch Loss: 0.0008050429751165211\n",
      "Epoch 1423, Loss: 0.005808724439702928, Final Batch Loss: 0.0006791202467866242\n",
      "Epoch 1424, Loss: 0.007795069908752339, Final Batch Loss: 5.14196181029547e-05\n",
      "Epoch 1425, Loss: 0.004275213927030563, Final Batch Loss: 0.00013610045425593853\n",
      "Epoch 1426, Loss: 0.002288189542014152, Final Batch Loss: 0.0005161400767974555\n",
      "Epoch 1427, Loss: 0.004110928945010528, Final Batch Loss: 0.0005972956423647702\n",
      "Epoch 1428, Loss: 0.004806956661923323, Final Batch Loss: 6.633235898334533e-06\n",
      "Epoch 1429, Loss: 0.0038025971298338845, Final Batch Loss: 0.00017762188508640975\n",
      "Epoch 1430, Loss: 0.008783911354839802, Final Batch Loss: 0.004134247079491615\n",
      "Epoch 1431, Loss: 0.0011537950649653794, Final Batch Loss: 2.058385325653944e-05\n",
      "Epoch 1432, Loss: 0.002723896125758074, Final Batch Loss: 1.7831399645729107e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1433, Loss: 0.002323945999251009, Final Batch Loss: 7.13470262780902e-06\n",
      "Epoch 1434, Loss: 0.0018156922087655403, Final Batch Loss: 8.36701292428188e-05\n",
      "Epoch 1435, Loss: 0.005846538144396618, Final Batch Loss: 0.0014929388416931033\n",
      "Epoch 1436, Loss: 0.00989757664501667, Final Batch Loss: 0.005627179052680731\n",
      "Epoch 1437, Loss: 0.007774384750518948, Final Batch Loss: 0.00012498618161771446\n",
      "Epoch 1438, Loss: 0.0046719638630747795, Final Batch Loss: 0.0005277227028273046\n",
      "Epoch 1439, Loss: 0.0022375344669853803, Final Batch Loss: 0.001513035618700087\n",
      "Epoch 1440, Loss: 0.0021670976329914993, Final Batch Loss: 1.6413154298788868e-05\n",
      "Epoch 1441, Loss: 0.006693548391922377, Final Batch Loss: 0.00037526924279518425\n",
      "Epoch 1442, Loss: 0.0013089148123981431, Final Batch Loss: 5.072045314591378e-05\n",
      "Epoch 1443, Loss: 0.0032999736577039585, Final Batch Loss: 0.00023737414448987693\n",
      "Epoch 1444, Loss: 0.006252709659747779, Final Batch Loss: 0.0008263355703093112\n",
      "Epoch 1445, Loss: 0.0030575051641790196, Final Batch Loss: 0.00019368664652574807\n",
      "Epoch 1446, Loss: 0.012979167593584862, Final Batch Loss: 7.831001857994124e-05\n",
      "Epoch 1447, Loss: 0.0067509769287426025, Final Batch Loss: 0.0007391805411316454\n",
      "Epoch 1448, Loss: 0.0016446915687993169, Final Batch Loss: 0.00026047538267448545\n",
      "Epoch 1449, Loss: 0.003902774551534094, Final Batch Loss: 0.001540722674690187\n",
      "Epoch 1450, Loss: 0.0038650876085739583, Final Batch Loss: 8.509086910635233e-05\n",
      "Epoch 1451, Loss: 0.0015098489820957184, Final Batch Loss: 6.569462129846215e-05\n",
      "Epoch 1452, Loss: 0.0038690967485308647, Final Batch Loss: 0.0029668703209608793\n",
      "Epoch 1453, Loss: 0.0035287868813611567, Final Batch Loss: 0.0007792129763402045\n",
      "Epoch 1454, Loss: 0.0008255278953583911, Final Batch Loss: 4.177440132480115e-05\n",
      "Epoch 1455, Loss: 0.004626157635357231, Final Batch Loss: 0.0011246359208598733\n",
      "Epoch 1456, Loss: 0.0027251991123193875, Final Batch Loss: 2.809021680150181e-05\n",
      "Epoch 1457, Loss: 0.01563592224556487, Final Batch Loss: 0.012055263854563236\n",
      "Epoch 1458, Loss: 0.042412990776938386, Final Batch Loss: 0.04139510542154312\n",
      "Epoch 1459, Loss: 0.008157228206982836, Final Batch Loss: 0.00012144516222178936\n",
      "Epoch 1460, Loss: 0.015601945013713703, Final Batch Loss: 6.521472187159816e-06\n",
      "Epoch 1461, Loss: 0.004358649504638379, Final Batch Loss: 2.9825930596416583e-06\n",
      "Epoch 1462, Loss: 0.01143385551404208, Final Batch Loss: 0.009433778934180737\n",
      "Epoch 1463, Loss: 0.016370106241083704, Final Batch Loss: 5.6816686992533505e-05\n",
      "Epoch 1464, Loss: 0.027207390652620234, Final Batch Loss: 0.00019380594312679023\n",
      "Epoch 1465, Loss: 0.01493653667603212, Final Batch Loss: 1.8484724932932295e-05\n",
      "Epoch 1466, Loss: 0.008419834222877398, Final Batch Loss: 0.00562116177752614\n",
      "Epoch 1467, Loss: 0.012631949706701562, Final Batch Loss: 0.009881009347736835\n",
      "Epoch 1468, Loss: 0.0014413681856240146, Final Batch Loss: 2.135102840838954e-05\n",
      "Epoch 1469, Loss: 0.004141451144732855, Final Batch Loss: 7.248856036312645e-06\n",
      "Epoch 1470, Loss: 0.009240107330697356, Final Batch Loss: 4.0671522583579645e-05\n",
      "Epoch 1471, Loss: 0.0014038508088560775, Final Batch Loss: 8.100265404209495e-06\n",
      "Epoch 1472, Loss: 0.0036215527507010847, Final Batch Loss: 0.0010259886039420962\n",
      "Epoch 1473, Loss: 0.006147247608168982, Final Batch Loss: 0.0001658439141465351\n",
      "Epoch 1474, Loss: 0.004832806997001171, Final Batch Loss: 0.0011326944222673774\n",
      "Epoch 1475, Loss: 0.01733219840025413, Final Batch Loss: 1.0222847777185962e-05\n",
      "Epoch 1476, Loss: 0.002834299266396556, Final Batch Loss: 0.0007265251479111612\n",
      "Epoch 1477, Loss: 0.012412783922627568, Final Batch Loss: 0.0013920326018705964\n",
      "Epoch 1478, Loss: 0.016633116210869048, Final Batch Loss: 0.0076197292655706406\n",
      "Epoch 1479, Loss: 0.03443232402787544, Final Batch Loss: 0.028361760079860687\n",
      "Epoch 1480, Loss: 0.0018542841062298976, Final Batch Loss: 0.00012899073772132397\n",
      "Epoch 1481, Loss: 0.006886039269375033, Final Batch Loss: 6.039646905264817e-06\n",
      "Epoch 1482, Loss: 0.011490444972878322, Final Batch Loss: 0.009668351151049137\n",
      "Epoch 1483, Loss: 0.004004096917924471, Final Batch Loss: 0.00022876924776937813\n",
      "Epoch 1484, Loss: 0.011378610533938627, Final Batch Loss: 1.646138662181329e-05\n",
      "Epoch 1485, Loss: 0.003458209481323138, Final Batch Loss: 0.00026231762603856623\n",
      "Epoch 1486, Loss: 0.0020688050690296222, Final Batch Loss: 1.1939800060645211e-05\n",
      "Epoch 1487, Loss: 0.0008210087835323066, Final Batch Loss: 0.0001323487376794219\n",
      "Epoch 1488, Loss: 0.006977429788094014, Final Batch Loss: 0.0002511150378268212\n",
      "Epoch 1489, Loss: 0.0013007563684368506, Final Batch Loss: 0.0001360441674478352\n",
      "Epoch 1490, Loss: 0.001438823077478446, Final Batch Loss: 0.00022718736727256328\n",
      "Epoch 1491, Loss: 0.004908702907414408, Final Batch Loss: 4.274222374078818e-05\n",
      "Epoch 1492, Loss: 0.002136730166967027, Final Batch Loss: 0.00019289425108581781\n",
      "Epoch 1493, Loss: 0.005139218963449821, Final Batch Loss: 0.0007000517216511071\n",
      "Epoch 1494, Loss: 0.002068439789582044, Final Batch Loss: 0.00010514108726056293\n",
      "Epoch 1495, Loss: 0.005008486843507853, Final Batch Loss: 1.8988752344739623e-05\n",
      "Epoch 1496, Loss: 0.01829956488654716, Final Batch Loss: 0.00012163814244559035\n",
      "Epoch 1497, Loss: 0.00802231201964787, Final Batch Loss: 2.1109619865455898e-06\n",
      "Epoch 1498, Loss: 0.002554620587034151, Final Batch Loss: 0.0007675423403270543\n",
      "Epoch 1499, Loss: 0.0013684361110790633, Final Batch Loss: 0.00010911287245107815\n",
      "Epoch 1500, Loss: 0.015995677036698908, Final Batch Loss: 0.0009359570103697479\n",
      "Epoch 1501, Loss: 0.003969324270656216, Final Batch Loss: 7.070972060319036e-05\n",
      "Epoch 1502, Loss: 0.025130702561000362, Final Batch Loss: 0.0005835631745867431\n",
      "Epoch 1503, Loss: 0.0006233707395040256, Final Batch Loss: 5.098205747344764e-06\n",
      "Epoch 1504, Loss: 0.0028129575948696584, Final Batch Loss: 0.000953917857259512\n",
      "Epoch 1505, Loss: 0.01345895572740119, Final Batch Loss: 0.009372006170451641\n",
      "Epoch 1506, Loss: 0.003192324540577829, Final Batch Loss: 0.0005176932318136096\n",
      "Epoch 1507, Loss: 0.0019180809322278947, Final Batch Loss: 0.0002642245090100914\n",
      "Epoch 1508, Loss: 0.000856022619700525, Final Batch Loss: 8.819443610263988e-05\n",
      "Epoch 1509, Loss: 0.004676939829096227, Final Batch Loss: 6.069153187127085e-06\n",
      "Epoch 1510, Loss: 0.009569323403411545, Final Batch Loss: 0.00013132848835084587\n",
      "Epoch 1511, Loss: 0.010518831739318557, Final Batch Loss: 0.008510969579219818\n",
      "Epoch 1512, Loss: 0.004378150862976327, Final Batch Loss: 2.7687643523677252e-05\n",
      "Epoch 1513, Loss: 0.0014445869393284738, Final Batch Loss: 9.611040923118708e-07\n",
      "Epoch 1514, Loss: 0.00321646525117103, Final Batch Loss: 0.0007246843888424337\n",
      "Epoch 1515, Loss: 0.004009642325399909, Final Batch Loss: 8.71205484145321e-05\n",
      "Epoch 1516, Loss: 0.0066831347066909075, Final Batch Loss: 0.0015611812705174088\n",
      "Epoch 1517, Loss: 0.008011216879822314, Final Batch Loss: 0.0009796845261007547\n",
      "Epoch 1518, Loss: 0.001663028946495615, Final Batch Loss: 4.023172368761152e-05\n",
      "Epoch 1519, Loss: 0.003212765892385505, Final Batch Loss: 0.00043764617294073105\n",
      "Epoch 1520, Loss: 0.0025938326871255413, Final Batch Loss: 0.00024142915208358318\n",
      "Epoch 1521, Loss: 0.0020696110877906904, Final Batch Loss: 5.1927214371971786e-05\n",
      "Epoch 1522, Loss: 0.002270252618473023, Final Batch Loss: 5.744783265981823e-05\n",
      "Epoch 1523, Loss: 0.0011050322937080637, Final Batch Loss: 0.0004670961352530867\n",
      "Epoch 1524, Loss: 0.015607873409862805, Final Batch Loss: 1.0849292266357224e-05\n",
      "Epoch 1525, Loss: 0.0012494031616370194, Final Batch Loss: 5.490837793331593e-06\n",
      "Epoch 1526, Loss: 0.018274920541443862, Final Batch Loss: 4.4387197704054415e-05\n",
      "Epoch 1527, Loss: 0.013446436525555328, Final Batch Loss: 0.00043828049092553556\n",
      "Epoch 1528, Loss: 0.040086820166834514, Final Batch Loss: 2.91779051622143e-05\n",
      "Epoch 1529, Loss: 0.000604749617195921, Final Batch Loss: 1.0776206181617454e-05\n",
      "Epoch 1530, Loss: 0.020752454627654515, Final Batch Loss: 0.00025824198382906616\n",
      "Epoch 1531, Loss: 0.007490842283004895, Final Batch Loss: 0.001076057436875999\n",
      "Epoch 1532, Loss: 0.004764527140650898, Final Batch Loss: 0.0006603174260817468\n",
      "Epoch 1533, Loss: 0.019435587339103222, Final Batch Loss: 0.0012058293214067817\n",
      "Epoch 1534, Loss: 0.019750082516111434, Final Batch Loss: 0.006914282217621803\n",
      "Epoch 1535, Loss: 0.01216236996697262, Final Batch Loss: 0.010272021405398846\n",
      "Epoch 1536, Loss: 0.02477477225693292, Final Batch Loss: 1.6511006833752617e-05\n",
      "Epoch 1537, Loss: 0.0022734530648449436, Final Batch Loss: 0.00021124871273059398\n",
      "Epoch 1538, Loss: 0.002163608205592027, Final Batch Loss: 0.001176671707071364\n",
      "Epoch 1539, Loss: 0.002397429856500821, Final Batch Loss: 5.8834189985645935e-05\n",
      "Epoch 1540, Loss: 0.0013027341810811777, Final Batch Loss: 8.722994971321896e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1541, Loss: 0.003084553187363781, Final Batch Loss: 0.0005485929432325065\n",
      "Epoch 1542, Loss: 0.002920964077929966, Final Batch Loss: 0.001736813341267407\n",
      "Epoch 1543, Loss: 0.00158439546066802, Final Batch Loss: 0.000898753060027957\n",
      "Epoch 1544, Loss: 0.005096358130685985, Final Batch Loss: 0.0037891475949436426\n",
      "Epoch 1545, Loss: 0.003884504229063168, Final Batch Loss: 0.0018803969724103808\n",
      "Epoch 1546, Loss: 0.001304620920564048, Final Batch Loss: 3.160868800478056e-05\n",
      "Epoch 1547, Loss: 0.0014576947276054852, Final Batch Loss: 3.3303065265499754e-06\n",
      "Epoch 1548, Loss: 0.014907361983205192, Final Batch Loss: 0.00015458585403393954\n",
      "Epoch 1549, Loss: 0.010083046479849145, Final Batch Loss: 0.0005168319912627339\n",
      "Epoch 1550, Loss: 0.0012241757940500975, Final Batch Loss: 0.00026373984292149544\n",
      "Epoch 1551, Loss: 0.00039290331915253773, Final Batch Loss: 8.601870649727061e-05\n",
      "Epoch 1552, Loss: 0.0010047299256257247, Final Batch Loss: 4.5804492401657626e-05\n",
      "Epoch 1553, Loss: 0.002594881540744609, Final Batch Loss: 2.125840865119244e-06\n",
      "Epoch 1554, Loss: 0.0009356114678666927, Final Batch Loss: 0.0003060001181438565\n",
      "Epoch 1555, Loss: 0.006339295592624694, Final Batch Loss: 0.00046346758608706295\n",
      "Epoch 1556, Loss: 0.006997689451964106, Final Batch Loss: 3.445847687544301e-05\n",
      "Epoch 1557, Loss: 0.00386774203798268, Final Batch Loss: 0.0002764468372333795\n",
      "Epoch 1558, Loss: 0.0008581046022300143, Final Batch Loss: 5.082996722194366e-05\n",
      "Epoch 1559, Loss: 0.008761011180467904, Final Batch Loss: 0.0019276818493381143\n",
      "Epoch 1560, Loss: 0.0013601886603282765, Final Batch Loss: 0.0003532750706654042\n",
      "Epoch 1561, Loss: 0.0029142335552023724, Final Batch Loss: 0.0001701429282547906\n",
      "Epoch 1562, Loss: 0.0036073470472501867, Final Batch Loss: 1.4255273299568216e-06\n",
      "Epoch 1563, Loss: 0.00122330440353835, Final Batch Loss: 6.799336551921442e-05\n",
      "Epoch 1564, Loss: 0.0028413007012204616, Final Batch Loss: 9.317612239101436e-06\n",
      "Epoch 1565, Loss: 0.0012762542828568257, Final Batch Loss: 0.0006037263665348291\n",
      "Epoch 1566, Loss: 0.0025286940508522093, Final Batch Loss: 0.000293939869152382\n",
      "Epoch 1567, Loss: 0.009712197519547772, Final Batch Loss: 2.60017259279266e-06\n",
      "Epoch 1568, Loss: 0.002925630826212, Final Batch Loss: 6.724058039253578e-05\n",
      "Epoch 1569, Loss: 0.0008439343218924478, Final Batch Loss: 0.0004440553020685911\n",
      "Epoch 1570, Loss: 0.0021157992887310684, Final Batch Loss: 3.313942579552531e-05\n",
      "Epoch 1571, Loss: 0.00589460862101987, Final Batch Loss: 0.00012292889005038887\n",
      "Epoch 1572, Loss: 0.002178791438382177, Final Batch Loss: 2.910653165599797e-06\n",
      "Epoch 1573, Loss: 0.0012735074142256053, Final Batch Loss: 2.5793460736167617e-05\n",
      "Epoch 1574, Loss: 0.007468401447113138, Final Batch Loss: 0.004591765347868204\n",
      "Epoch 1575, Loss: 0.0016153005853993818, Final Batch Loss: 0.0006448643398471177\n",
      "Epoch 1576, Loss: 0.0010095972975250334, Final Batch Loss: 0.00015080987941473722\n",
      "Epoch 1577, Loss: 0.0016792496389825828, Final Batch Loss: 2.6230147341266274e-05\n",
      "Epoch 1578, Loss: 0.0014031914361112285, Final Batch Loss: 6.441336154239252e-06\n",
      "Epoch 1579, Loss: 0.0018051174738502596, Final Batch Loss: 0.00011813960736617446\n",
      "Epoch 1580, Loss: 0.0010429742069391068, Final Batch Loss: 9.923343895934522e-05\n",
      "Epoch 1581, Loss: 0.0029087923612678424, Final Batch Loss: 0.001363623421639204\n",
      "Epoch 1582, Loss: 0.0006963261621422134, Final Batch Loss: 1.9619401427917182e-05\n",
      "Epoch 1583, Loss: 0.0031401091182488017, Final Batch Loss: 0.001703595626167953\n",
      "Epoch 1584, Loss: 0.0031128337632253533, Final Batch Loss: 2.329655944777187e-05\n",
      "Epoch 1585, Loss: 0.0020147215136603336, Final Batch Loss: 1.3404363016888965e-05\n",
      "Epoch 1586, Loss: 0.0025479412288405, Final Batch Loss: 0.00017153145745396614\n",
      "Epoch 1587, Loss: 0.0021010265554650687, Final Batch Loss: 0.00010205971921095625\n",
      "Epoch 1588, Loss: 0.002173119646613486, Final Batch Loss: 6.568706157850102e-05\n",
      "Epoch 1589, Loss: 0.002088542460114695, Final Batch Loss: 0.0004978763754479587\n",
      "Epoch 1590, Loss: 0.0011436549139034469, Final Batch Loss: 4.875464583165012e-05\n",
      "Epoch 1591, Loss: 0.0012175116717116907, Final Batch Loss: 0.00013525136455427855\n",
      "Epoch 1592, Loss: 0.0009229097267962061, Final Batch Loss: 0.0002231100806966424\n",
      "Epoch 1593, Loss: 0.0012126180154155008, Final Batch Loss: 0.0001769248628988862\n",
      "Epoch 1594, Loss: 0.0028693871572613716, Final Batch Loss: 0.00035774227580986917\n",
      "Epoch 1595, Loss: 0.0011234211924602278, Final Batch Loss: 3.900158480973914e-05\n",
      "Epoch 1596, Loss: 0.001448113933292916, Final Batch Loss: 3.1294792279368266e-05\n",
      "Epoch 1597, Loss: 0.026696144675952382, Final Batch Loss: 0.014718885533511639\n",
      "Epoch 1598, Loss: 0.003954969542064646, Final Batch Loss: 1.421836259396514e-05\n",
      "Epoch 1599, Loss: 0.012518806557636708, Final Batch Loss: 0.0011653306428343058\n",
      "Epoch 1600, Loss: 0.017806681182264583, Final Batch Loss: 0.0031243006233125925\n",
      "Epoch 1601, Loss: 0.01246128510683775, Final Batch Loss: 0.0007799768354743719\n",
      "Epoch 1602, Loss: 0.0014470306050498039, Final Batch Loss: 0.00042578205466270447\n",
      "Epoch 1603, Loss: 0.0058610969499568455, Final Batch Loss: 6.792577187297866e-05\n",
      "Epoch 1604, Loss: 0.0012720395425276365, Final Batch Loss: 1.0655854566721246e-05\n",
      "Epoch 1605, Loss: 0.003203636842954438, Final Batch Loss: 0.00032236622064374387\n",
      "Epoch 1606, Loss: 0.004460859308892395, Final Batch Loss: 4.5363252866081893e-05\n",
      "Epoch 1607, Loss: 0.026541707586147822, Final Batch Loss: 6.546683289343491e-05\n",
      "Epoch 1608, Loss: 0.0031482988333664252, Final Batch Loss: 1.0748763997980859e-05\n",
      "Epoch 1609, Loss: 0.0035525464918464422, Final Batch Loss: 0.00033500607241876423\n",
      "Epoch 1610, Loss: 0.02649857931828592, Final Batch Loss: 6.0567050240933895e-05\n",
      "Epoch 1611, Loss: 0.003181313950335607, Final Batch Loss: 0.0002034807694144547\n",
      "Epoch 1612, Loss: 0.0068839238956570625, Final Batch Loss: 0.0005935062654316425\n",
      "Epoch 1613, Loss: 0.007636697715497576, Final Batch Loss: 0.00020785741799045354\n",
      "Epoch 1614, Loss: 0.004620337751475745, Final Batch Loss: 1.9566776245483197e-05\n",
      "Epoch 1615, Loss: 0.007279939629370347, Final Batch Loss: 0.00041449841228313744\n",
      "Epoch 1616, Loss: 0.02027466216350149, Final Batch Loss: 2.4531544113415293e-05\n",
      "Epoch 1617, Loss: 0.0003704020018631127, Final Batch Loss: 7.114650361472741e-05\n",
      "Epoch 1618, Loss: 0.021985603612847626, Final Batch Loss: 0.008723806589841843\n",
      "Epoch 1619, Loss: 0.0027741641679313034, Final Batch Loss: 0.00044787186197936535\n",
      "Epoch 1620, Loss: 0.0010805206329678185, Final Batch Loss: 6.350208423100412e-05\n",
      "Epoch 1621, Loss: 0.001196426514070481, Final Batch Loss: 0.00047621395788155496\n",
      "Epoch 1622, Loss: 0.006781819502066355, Final Batch Loss: 0.005931209307163954\n",
      "Epoch 1623, Loss: 0.0004875205268035643, Final Batch Loss: 3.714933336596005e-05\n",
      "Epoch 1624, Loss: 0.001221312482812209, Final Batch Loss: 0.00034557070466689765\n",
      "Epoch 1625, Loss: 0.0021012723009334877, Final Batch Loss: 0.00025849518715403974\n",
      "Epoch 1626, Loss: 0.0057517602981533855, Final Batch Loss: 0.0018320061499252915\n",
      "Epoch 1627, Loss: 0.001439332052541431, Final Batch Loss: 0.0005266389925964177\n",
      "Epoch 1628, Loss: 0.004105013838852756, Final Batch Loss: 0.003273242386057973\n",
      "Epoch 1629, Loss: 0.0013562820640800055, Final Batch Loss: 0.0002961725404020399\n",
      "Epoch 1630, Loss: 0.0019382229420443764, Final Batch Loss: 2.9669818104594015e-05\n",
      "Epoch 1631, Loss: 0.0032085802231449634, Final Batch Loss: 0.0008833843166939914\n",
      "Epoch 1632, Loss: 0.0019019272240257123, Final Batch Loss: 2.1091202142997645e-05\n",
      "Epoch 1633, Loss: 0.002491462029865943, Final Batch Loss: 1.5351499314419925e-05\n",
      "Epoch 1634, Loss: 0.000945401145145297, Final Batch Loss: 0.00022414121485780925\n",
      "Epoch 1635, Loss: 0.0005999937493470497, Final Batch Loss: 6.704043335048482e-05\n",
      "Epoch 1636, Loss: 0.001423254725523293, Final Batch Loss: 7.153057958930731e-05\n",
      "Epoch 1637, Loss: 0.004871172975981608, Final Batch Loss: 0.003146366449072957\n",
      "Epoch 1638, Loss: 0.0015620380654581822, Final Batch Loss: 9.054557449417189e-05\n",
      "Epoch 1639, Loss: 0.007366839388851076, Final Batch Loss: 0.0006871397490613163\n",
      "Epoch 1640, Loss: 0.008070345254964195, Final Batch Loss: 0.0001295113324886188\n",
      "Epoch 1641, Loss: 0.0005784727927675704, Final Batch Loss: 8.795783287496306e-06\n",
      "Epoch 1642, Loss: 0.0007134659026633017, Final Batch Loss: 0.000342818588251248\n",
      "Epoch 1643, Loss: 0.05290660494938493, Final Batch Loss: 0.04996514320373535\n",
      "Epoch 1644, Loss: 0.0012899297871626914, Final Batch Loss: 0.00016543181845918298\n",
      "Epoch 1645, Loss: 0.002224149061476055, Final Batch Loss: 1.2446117580111604e-05\n",
      "Epoch 1646, Loss: 0.001009878957120236, Final Batch Loss: 6.47340712021105e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1647, Loss: 0.004708612941612955, Final Batch Loss: 0.0012479252181947231\n",
      "Epoch 1648, Loss: 0.004709058815933531, Final Batch Loss: 0.0006468510255217552\n",
      "Epoch 1649, Loss: 0.003692107457027305, Final Batch Loss: 0.0012329999590292573\n",
      "Epoch 1650, Loss: 0.01073746179099544, Final Batch Loss: 3.95834467781242e-05\n",
      "Epoch 1651, Loss: 0.0008580308167438488, Final Batch Loss: 0.0004400048637762666\n",
      "Epoch 1652, Loss: 0.0038136978109832853, Final Batch Loss: 0.0006222667288966477\n",
      "Epoch 1653, Loss: 0.002913280894063064, Final Batch Loss: 0.0002750091953203082\n",
      "Epoch 1654, Loss: 0.01922957411375137, Final Batch Loss: 2.1084117634018185e-06\n",
      "Epoch 1655, Loss: 0.0026811277894012164, Final Batch Loss: 5.184382825973444e-05\n",
      "Epoch 1656, Loss: 0.00040059123739411007, Final Batch Loss: 5.939891252637608e-06\n",
      "Epoch 1657, Loss: 0.021666045591700822, Final Batch Loss: 0.01038913894444704\n",
      "Epoch 1658, Loss: 0.08572690743312705, Final Batch Loss: 0.07748840004205704\n",
      "Epoch 1659, Loss: 0.004175564961769851, Final Batch Loss: 6.6280226747039706e-06\n",
      "Epoch 1660, Loss: 0.06441794113925425, Final Batch Loss: 2.823844988597557e-05\n",
      "Epoch 1661, Loss: 0.04675366145602311, Final Batch Loss: 0.0063857813365757465\n",
      "Epoch 1662, Loss: 0.024641103931571706, Final Batch Loss: 1.827057531045284e-05\n",
      "Epoch 1663, Loss: 0.005146659997990355, Final Batch Loss: 0.00045308753033168614\n",
      "Epoch 1664, Loss: 0.0068778275162912905, Final Batch Loss: 0.0010177590884268284\n",
      "Epoch 1665, Loss: 0.003639835922513157, Final Batch Loss: 0.0010783495381474495\n",
      "Epoch 1666, Loss: 0.0016909025812310574, Final Batch Loss: 6.620758995268261e-06\n",
      "Epoch 1667, Loss: 0.0027917790848732693, Final Batch Loss: 1.7769662008504383e-05\n",
      "Epoch 1668, Loss: 0.00653748596960213, Final Batch Loss: 0.00017686739738564938\n",
      "Epoch 1669, Loss: 0.012175381183624268, Final Batch Loss: 0.004136055242270231\n",
      "Epoch 1670, Loss: 0.008365542329556774, Final Batch Loss: 0.002369309077039361\n",
      "Epoch 1671, Loss: 0.004026428928682435, Final Batch Loss: 5.5032010095601436e-06\n",
      "Epoch 1672, Loss: 0.0018091550082317553, Final Batch Loss: 0.00012165933003416285\n",
      "Epoch 1673, Loss: 0.001373566758047673, Final Batch Loss: 2.0293939087423496e-05\n",
      "Epoch 1674, Loss: 0.0014399106767086778, Final Batch Loss: 5.173200406716205e-05\n",
      "Epoch 1675, Loss: 0.0024071470397757366, Final Batch Loss: 0.000439872412243858\n",
      "Epoch 1676, Loss: 0.0010408520211058203, Final Batch Loss: 3.186798494425602e-05\n",
      "Epoch 1677, Loss: 0.00201691132679116, Final Batch Loss: 0.0007848704699426889\n",
      "Epoch 1678, Loss: 0.0030210581026040018, Final Batch Loss: 0.00027478509582579136\n",
      "Epoch 1679, Loss: 0.0010078595460072393, Final Batch Loss: 1.8485685359337367e-05\n",
      "Epoch 1680, Loss: 0.002245500152639579, Final Batch Loss: 0.0011135352542623878\n",
      "Epoch 1681, Loss: 0.0009495656695435173, Final Batch Loss: 8.530346349289175e-06\n",
      "Epoch 1682, Loss: 0.0009134539286606014, Final Batch Loss: 0.00024938699789345264\n",
      "Epoch 1683, Loss: 0.020527751301415265, Final Batch Loss: 0.0023263876792043447\n",
      "Epoch 1684, Loss: 0.0009198375082632992, Final Batch Loss: 3.634339736890979e-05\n",
      "Epoch 1685, Loss: 0.006230262428289279, Final Batch Loss: 0.0027498966082930565\n",
      "Epoch 1686, Loss: 0.003974842737079598, Final Batch Loss: 0.00015521283785346895\n",
      "Epoch 1687, Loss: 0.0013552254167734645, Final Batch Loss: 9.033131209434941e-05\n",
      "Epoch 1688, Loss: 0.01690065629372839, Final Batch Loss: 0.0002459513198118657\n",
      "Epoch 1689, Loss: 0.005101558577734977, Final Batch Loss: 0.0006696638301946223\n",
      "Epoch 1690, Loss: 0.0014955660735722631, Final Batch Loss: 0.00015789279132150114\n",
      "Epoch 1691, Loss: 0.003186652626027353, Final Batch Loss: 0.00020337522437330335\n",
      "Epoch 1692, Loss: 0.025731534726219252, Final Batch Loss: 5.5227807024493814e-05\n",
      "Epoch 1693, Loss: 0.0013363171019591391, Final Batch Loss: 0.00018846355669666082\n",
      "Epoch 1694, Loss: 0.004117471173231024, Final Batch Loss: 0.0003072948311455548\n",
      "Epoch 1695, Loss: 0.006113850249676034, Final Batch Loss: 0.0007551875314675272\n",
      "Epoch 1696, Loss: 0.0009258727513952181, Final Batch Loss: 0.0002694282738957554\n",
      "Epoch 1697, Loss: 0.005192700128205274, Final Batch Loss: 1.5149500143252226e-07\n",
      "Epoch 1698, Loss: 0.004674600815633312, Final Batch Loss: 0.0005621982854790986\n",
      "Epoch 1699, Loss: 0.006409474954125471, Final Batch Loss: 0.00019387229986023158\n",
      "Epoch 1700, Loss: 0.0008603819660493173, Final Batch Loss: 1.9272520148660988e-05\n",
      "Epoch 1701, Loss: 0.0027053548910771497, Final Batch Loss: 9.46870495681651e-05\n",
      "Epoch 1702, Loss: 0.0018720779989962466, Final Batch Loss: 8.103646541712806e-05\n",
      "Epoch 1703, Loss: 0.0005563897975662258, Final Batch Loss: 3.677329732454382e-05\n",
      "Epoch 1704, Loss: 0.001854748039477272, Final Batch Loss: 5.448696538223885e-05\n",
      "Epoch 1705, Loss: 0.0017824433525674976, Final Batch Loss: 1.133801561081782e-05\n",
      "Epoch 1706, Loss: 0.0017003904249577317, Final Batch Loss: 8.587563206674531e-05\n",
      "Epoch 1707, Loss: 0.0007576610005344264, Final Batch Loss: 0.00025286944583058357\n",
      "Epoch 1708, Loss: 0.00381006136740325, Final Batch Loss: 8.666721259942278e-05\n",
      "Epoch 1709, Loss: 0.001929344467498595, Final Batch Loss: 1.2903401511721313e-05\n",
      "Epoch 1710, Loss: 0.000667670839902712, Final Batch Loss: 5.319550837157294e-06\n",
      "Epoch 1711, Loss: 0.021819958647029125, Final Batch Loss: 1.6056650565587915e-05\n",
      "Epoch 1712, Loss: 0.00815843370219227, Final Batch Loss: 0.007284985389560461\n",
      "Epoch 1713, Loss: 0.0014551725784457403, Final Batch Loss: 1.2914317437662248e-07\n",
      "Epoch 1714, Loss: 0.011678908413159661, Final Batch Loss: 0.00927879847586155\n",
      "Epoch 1715, Loss: 0.002433902001939714, Final Batch Loss: 0.0004086567787453532\n",
      "Epoch 1716, Loss: 0.007528100039053243, Final Batch Loss: 0.00012150205293437466\n",
      "Epoch 1717, Loss: 0.031590423051966354, Final Batch Loss: 0.03085886687040329\n",
      "Epoch 1718, Loss: 0.0011464389871207459, Final Batch Loss: 1.385768769068818e-06\n",
      "Epoch 1719, Loss: 0.13114798433889518, Final Batch Loss: 0.0002370803995290771\n",
      "Epoch 1720, Loss: 0.010275498207192868, Final Batch Loss: 0.0009926360798999667\n",
      "Epoch 1721, Loss: 0.0018294648180017248, Final Batch Loss: 0.00012802962737623602\n",
      "Epoch 1722, Loss: 0.03015458586105524, Final Batch Loss: 1.452446394978324e-05\n",
      "Epoch 1723, Loss: 0.03794907087285537, Final Batch Loss: 0.013346661813557148\n",
      "Epoch 1724, Loss: 0.0013187627992010675, Final Batch Loss: 0.0006964489002712071\n",
      "Epoch 1725, Loss: 0.00045858211524318904, Final Batch Loss: 7.332672248594463e-05\n",
      "Epoch 1726, Loss: 0.008388383808778599, Final Batch Loss: 0.0023442807141691446\n",
      "Epoch 1727, Loss: 0.0025440273457206786, Final Batch Loss: 0.0010987588902935386\n",
      "Epoch 1728, Loss: 0.0009656185138737783, Final Batch Loss: 0.00033136026468127966\n",
      "Epoch 1729, Loss: 0.006909497024025768, Final Batch Loss: 0.0022648731246590614\n",
      "Epoch 1730, Loss: 0.004121598874917254, Final Batch Loss: 0.0011084958678111434\n",
      "Epoch 1731, Loss: 0.002263732945721131, Final Batch Loss: 0.00010413221752969548\n",
      "Epoch 1732, Loss: 0.002245358824438881, Final Batch Loss: 7.11684042471461e-05\n",
      "Epoch 1733, Loss: 0.004444088859600015, Final Batch Loss: 0.0006054012919776142\n",
      "Epoch 1734, Loss: 0.0034653776783670764, Final Batch Loss: 3.286577339167707e-05\n",
      "Epoch 1735, Loss: 0.008609697622887325, Final Batch Loss: 2.3990018235053867e-05\n",
      "Epoch 1736, Loss: 0.003332390489958925, Final Batch Loss: 6.037954517523758e-05\n",
      "Epoch 1737, Loss: 0.006292403908446431, Final Batch Loss: 0.0007716501131653786\n",
      "Epoch 1738, Loss: 0.0010662996355677024, Final Batch Loss: 0.000213848557905294\n",
      "Epoch 1739, Loss: 0.001809262961614877, Final Batch Loss: 0.0006943279295228422\n",
      "Epoch 1740, Loss: 0.005557116314577115, Final Batch Loss: 3.1789093668521673e-07\n",
      "Epoch 1741, Loss: 0.0025677281300886534, Final Batch Loss: 0.00022622104734182358\n",
      "Epoch 1742, Loss: 0.040626127331051975, Final Batch Loss: 0.0005528368637897074\n",
      "Epoch 1743, Loss: 0.0020950848866050364, Final Batch Loss: 1.7894608390633948e-05\n",
      "Epoch 1744, Loss: 0.01581871079542907, Final Batch Loss: 0.0001114156111725606\n",
      "Epoch 1745, Loss: 0.003587062721635448, Final Batch Loss: 5.413558756117709e-05\n",
      "Epoch 1746, Loss: 0.0029281030938363983, Final Batch Loss: 1.1613278729782905e-05\n",
      "Epoch 1747, Loss: 0.004242913819325622, Final Batch Loss: 0.0001141027532867156\n",
      "Epoch 1748, Loss: 0.0012751682079397142, Final Batch Loss: 3.5660326830111444e-05\n",
      "Epoch 1749, Loss: 0.002207149052992463, Final Batch Loss: 0.0014471830800175667\n",
      "Epoch 1750, Loss: 0.0022800903898314573, Final Batch Loss: 1.455384335713461e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751, Loss: 0.005342577773262747, Final Batch Loss: 0.00013914839655626565\n",
      "Epoch 1752, Loss: 0.0029054612532490864, Final Batch Loss: 6.045644113328308e-05\n",
      "Epoch 1753, Loss: 0.0028210040472913533, Final Batch Loss: 0.0008496667142026126\n",
      "Epoch 1754, Loss: 0.007371056879492244, Final Batch Loss: 0.00025583227397874\n",
      "Epoch 1755, Loss: 0.000948122147747199, Final Batch Loss: 0.0003323289565742016\n",
      "Epoch 1756, Loss: 0.0018394448343315162, Final Batch Loss: 7.469184492947534e-05\n",
      "Epoch 1757, Loss: 0.0021285114344209433, Final Batch Loss: 0.0006576388259418309\n",
      "Epoch 1758, Loss: 0.003338159338454716, Final Batch Loss: 3.687932621687651e-05\n",
      "Epoch 1759, Loss: 0.003271132954978384, Final Batch Loss: 0.002660727361217141\n",
      "Epoch 1760, Loss: 0.013399609557382064, Final Batch Loss: 0.010278012603521347\n",
      "Epoch 1761, Loss: 0.0015622305509168655, Final Batch Loss: 0.0004787491634488106\n",
      "Epoch 1762, Loss: 0.001739133662340464, Final Batch Loss: 1.9747199985431507e-05\n",
      "Epoch 1763, Loss: 0.0017593970806046855, Final Batch Loss: 3.4778753615682945e-05\n",
      "Epoch 1764, Loss: 0.0009320495883002877, Final Batch Loss: 2.671792753972113e-05\n",
      "Epoch 1765, Loss: 0.0008552297065307357, Final Batch Loss: 2.1680668851331575e-06\n",
      "Epoch 1766, Loss: 0.001896308283903636, Final Batch Loss: 5.6282151490449905e-05\n",
      "Epoch 1767, Loss: 0.0017812872247304767, Final Batch Loss: 0.0003685596166178584\n",
      "Epoch 1768, Loss: 0.0019372655915503856, Final Batch Loss: 0.0013247155584394932\n",
      "Epoch 1769, Loss: 0.0006223379414223018, Final Batch Loss: 1.4363012269313913e-05\n",
      "Epoch 1770, Loss: 0.004903956829366507, Final Batch Loss: 8.257950685219839e-05\n",
      "Epoch 1771, Loss: 0.000558674757485278, Final Batch Loss: 0.0001548428408568725\n",
      "Epoch 1772, Loss: 0.02521112043177709, Final Batch Loss: 5.346752004697919e-06\n",
      "Epoch 1773, Loss: 0.003114322458714014, Final Batch Loss: 4.686931424657814e-05\n",
      "Epoch 1774, Loss: 0.0008364846289623529, Final Batch Loss: 3.8665428292006254e-05\n",
      "Epoch 1775, Loss: 0.009393677290063351, Final Batch Loss: 0.0059343320317566395\n",
      "Epoch 1776, Loss: 0.0007824909206419761, Final Batch Loss: 1.249203592124104e-06\n",
      "Epoch 1777, Loss: 0.0069548026076518, Final Batch Loss: 0.0052459463477134705\n",
      "Epoch 1778, Loss: 0.0005280950167616538, Final Batch Loss: 4.465229267225368e-06\n",
      "Epoch 1779, Loss: 0.00045398461224976927, Final Batch Loss: 2.6641893782652915e-05\n",
      "Epoch 1780, Loss: 0.0007019004624453373, Final Batch Loss: 0.0002676427538972348\n",
      "Epoch 1781, Loss: 0.005199292236625297, Final Batch Loss: 1.8576378124635085e-06\n",
      "Epoch 1782, Loss: 0.0004683889910666039, Final Batch Loss: 9.160268746200018e-06\n",
      "Epoch 1783, Loss: 0.0029975260913488455, Final Batch Loss: 0.00011185761104570702\n",
      "Epoch 1784, Loss: 0.0006337084723782027, Final Batch Loss: 2.658747871464584e-05\n",
      "Epoch 1785, Loss: 0.0017824046226451173, Final Batch Loss: 0.0004724283644463867\n",
      "Epoch 1786, Loss: 0.004830167787304163, Final Batch Loss: 2.7839325866807485e-06\n",
      "Epoch 1787, Loss: 0.039203394670039415, Final Batch Loss: 0.001359054702334106\n",
      "Epoch 1788, Loss: 0.0029486695675586816, Final Batch Loss: 3.929846207029186e-05\n",
      "Epoch 1789, Loss: 0.0034997782568098046, Final Batch Loss: 3.613963781390339e-05\n",
      "Epoch 1790, Loss: 0.0007590145096401102, Final Batch Loss: 4.840198926103767e-06\n",
      "Epoch 1791, Loss: 0.0057661623977764975, Final Batch Loss: 0.004858104977756739\n",
      "Epoch 1792, Loss: 0.000978339659923222, Final Batch Loss: 6.307980947894976e-05\n",
      "Epoch 1793, Loss: 0.0015146597361308523, Final Batch Loss: 0.00013175875938031822\n",
      "Epoch 1794, Loss: 0.003181378386216238, Final Batch Loss: 2.8718277462758124e-05\n",
      "Epoch 1795, Loss: 0.013230157923317165, Final Batch Loss: 2.463432065269444e-05\n",
      "Epoch 1796, Loss: 0.0022457483064499684, Final Batch Loss: 7.308854401344433e-05\n",
      "Epoch 1797, Loss: 0.0030437640325544635, Final Batch Loss: 1.5784617062308826e-05\n",
      "Epoch 1798, Loss: 0.0031807203085918445, Final Batch Loss: 3.41192826454062e-05\n",
      "Epoch 1799, Loss: 0.0012322479642534745, Final Batch Loss: 1.0835520697582979e-05\n",
      "Epoch 1800, Loss: 0.0018123462577932514, Final Batch Loss: 0.0003558410971891135\n",
      "Epoch 1801, Loss: 0.0041162906081808615, Final Batch Loss: 1.5031971088319551e-05\n",
      "Epoch 1802, Loss: 0.005845795800269116, Final Batch Loss: 0.00010543945973040536\n",
      "Epoch 1803, Loss: 0.002026334492256865, Final Batch Loss: 0.0002782249648589641\n",
      "Epoch 1804, Loss: 0.002054708364084945, Final Batch Loss: 1.6200176105485298e-05\n",
      "Epoch 1805, Loss: 0.00434939455044514, Final Batch Loss: 1.8627697500051e-05\n",
      "Epoch 1806, Loss: 0.0023740214382996783, Final Batch Loss: 4.564065602608025e-05\n",
      "Epoch 1807, Loss: 0.0004396347576403059, Final Batch Loss: 7.327569619519636e-05\n",
      "Epoch 1808, Loss: 0.00028865925924037583, Final Batch Loss: 2.6679896109271795e-05\n",
      "Epoch 1809, Loss: 0.001706067084796814, Final Batch Loss: 4.0903009903558996e-06\n",
      "Epoch 1810, Loss: 0.004991223628167063, Final Batch Loss: 0.00029045052360743284\n",
      "Epoch 1811, Loss: 0.0022249455214478076, Final Batch Loss: 8.2678823673632e-05\n",
      "Epoch 1812, Loss: 0.00032031082082539797, Final Batch Loss: 5.385947224567644e-05\n",
      "Epoch 1813, Loss: 0.022900558527908288, Final Batch Loss: 1.1528623872436583e-05\n",
      "Epoch 1814, Loss: 0.0015309762748074718, Final Batch Loss: 0.0011086243903264403\n",
      "Epoch 1815, Loss: 0.0005284441431285813, Final Batch Loss: 0.00012066834460711107\n",
      "Epoch 1816, Loss: 0.0013132377593763067, Final Batch Loss: 4.3709812302950013e-07\n",
      "Epoch 1817, Loss: 0.0006237464949663263, Final Batch Loss: 5.0482736696721986e-05\n",
      "Epoch 1818, Loss: 0.0007011208872427233, Final Batch Loss: 0.0001752229145495221\n",
      "Epoch 1819, Loss: 0.0009015346527121437, Final Batch Loss: 6.908597697474761e-06\n",
      "Epoch 1820, Loss: 0.007378536351438925, Final Batch Loss: 1.8278245761393919e-06\n",
      "Epoch 1821, Loss: 0.007331685745157301, Final Batch Loss: 0.004942221101373434\n",
      "Epoch 1822, Loss: 0.00108853611163795, Final Batch Loss: 0.0002027097943937406\n",
      "Epoch 1823, Loss: 0.0019648996021714993, Final Batch Loss: 6.990825204411522e-05\n",
      "Epoch 1824, Loss: 0.00107244315358912, Final Batch Loss: 4.3135419218742754e-06\n",
      "Epoch 1825, Loss: 0.0009264250620617531, Final Batch Loss: 7.147709402488545e-05\n",
      "Epoch 1826, Loss: 0.001179849226900842, Final Batch Loss: 0.00035994616337120533\n",
      "Epoch 1827, Loss: 0.0009455036015424412, Final Batch Loss: 0.00041290410445071757\n",
      "Epoch 1828, Loss: 0.0012668801937252283, Final Batch Loss: 0.00018349853053223342\n",
      "Epoch 1829, Loss: 0.006956139222893398, Final Batch Loss: 0.002959521720185876\n",
      "Epoch 1830, Loss: 0.008082236134214327, Final Batch Loss: 0.006957324221730232\n",
      "Epoch 1831, Loss: 0.004259979138851122, Final Batch Loss: 3.2533400826650904e-06\n",
      "Epoch 1832, Loss: 0.008341518977733386, Final Batch Loss: 1.2417633143968487e-08\n",
      "Epoch 1833, Loss: 0.0018070355017698603, Final Batch Loss: 2.878435952879954e-05\n",
      "Epoch 1834, Loss: 0.006314947546343319, Final Batch Loss: 0.0003811500209849328\n",
      "Epoch 1835, Loss: 0.017321930528851226, Final Batch Loss: 0.0005509545444510877\n",
      "Epoch 1836, Loss: 0.0011355554161127657, Final Batch Loss: 0.00017183490854222327\n",
      "Epoch 1837, Loss: 0.010475757582753431, Final Batch Loss: 0.0001013782384688966\n",
      "Epoch 1838, Loss: 0.004651373950764537, Final Batch Loss: 0.001949149533174932\n",
      "Epoch 1839, Loss: 0.030002204701304436, Final Batch Loss: 0.001888084807433188\n",
      "Epoch 1840, Loss: 0.0007665965167689137, Final Batch Loss: 0.0002852619218174368\n",
      "Epoch 1841, Loss: 0.0009555253127473406, Final Batch Loss: 5.316235183272511e-05\n",
      "Epoch 1842, Loss: 0.005113906247061095, Final Batch Loss: 5.634783519781195e-06\n",
      "Epoch 1843, Loss: 0.013375405309488997, Final Batch Loss: 0.00011911452747881413\n",
      "Epoch 1844, Loss: 0.0036885905219605775, Final Batch Loss: 1.0243203178106342e-05\n",
      "Epoch 1845, Loss: 0.001903426251374185, Final Batch Loss: 0.0002556148392613977\n",
      "Epoch 1846, Loss: 0.0021330800518626347, Final Batch Loss: 0.0005019202944822609\n",
      "Epoch 1847, Loss: 0.005828026602102909, Final Batch Loss: 0.003660206450149417\n",
      "Epoch 1848, Loss: 0.0008996117539936677, Final Batch Loss: 6.328910239972174e-05\n",
      "Epoch 1849, Loss: 0.0006544989964822889, Final Batch Loss: 9.373347893415485e-06\n",
      "Epoch 1850, Loss: 0.0009571729315211996, Final Batch Loss: 0.00042578528518788517\n",
      "Epoch 1851, Loss: 0.0020909748200210743, Final Batch Loss: 0.001433985773473978\n",
      "Epoch 1852, Loss: 0.005767620372353122, Final Batch Loss: 9.801879059523344e-05\n",
      "Epoch 1853, Loss: 0.0006299202650552616, Final Batch Loss: 0.00014962509158067405\n",
      "Epoch 1854, Loss: 0.0031934089493006468, Final Batch Loss: 0.00101477128919214\n",
      "Epoch 1855, Loss: 0.0007314138238143642, Final Batch Loss: 5.421275636763312e-05\n",
      "Epoch 1856, Loss: 0.0012164922809461132, Final Batch Loss: 0.00013756193220615387\n",
      "Epoch 1857, Loss: 0.005853204493178055, Final Batch Loss: 0.00013878531171940267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1858, Loss: 0.08248163294774713, Final Batch Loss: 0.08085715025663376\n",
      "Epoch 1859, Loss: 0.0007385130775219295, Final Batch Loss: 0.00019644851272460073\n",
      "Epoch 1860, Loss: 0.0042382263782201335, Final Batch Loss: 6.412538641598076e-05\n",
      "Epoch 1861, Loss: 0.07689862803090364, Final Batch Loss: 0.0585087426006794\n",
      "Epoch 1862, Loss: 0.0178653828043025, Final Batch Loss: 0.00027145023341290653\n",
      "Epoch 1863, Loss: 0.1312915706075728, Final Batch Loss: 0.0631687343120575\n",
      "Epoch 1864, Loss: 0.015809428374268464, Final Batch Loss: 1.6493975635967217e-05\n",
      "Epoch 1865, Loss: 0.041120509209576994, Final Batch Loss: 0.0002743093646131456\n",
      "Epoch 1866, Loss: 0.0028225563874002546, Final Batch Loss: 0.0004185641882941127\n",
      "Epoch 1867, Loss: 0.0035190680500818416, Final Batch Loss: 0.00017051711620297283\n",
      "Epoch 1868, Loss: 0.0026227133348584175, Final Batch Loss: 0.0012479760916903615\n",
      "Epoch 1869, Loss: 0.004062024745508097, Final Batch Loss: 0.0013441168703138828\n",
      "Epoch 1870, Loss: 0.0011437377543188632, Final Batch Loss: 0.00015383238496724516\n",
      "Epoch 1871, Loss: 0.016552799095734372, Final Batch Loss: 5.684216375811957e-06\n",
      "Epoch 1872, Loss: 0.0036031043564435095, Final Batch Loss: 0.0002598131832201034\n",
      "Epoch 1873, Loss: 0.002671980226296, Final Batch Loss: 0.0014023416442796588\n",
      "Epoch 1874, Loss: 0.0011216405437153298, Final Batch Loss: 5.520474587683566e-05\n",
      "Epoch 1875, Loss: 0.01785693819692824, Final Batch Loss: 0.007691513746976852\n",
      "Epoch 1876, Loss: 0.004567410973322694, Final Batch Loss: 2.9709191949223168e-05\n",
      "Epoch 1877, Loss: 0.0019514212663125363, Final Batch Loss: 2.853460500773508e-06\n",
      "Epoch 1878, Loss: 0.0043269655434414744, Final Batch Loss: 0.002067251829430461\n",
      "Epoch 1879, Loss: 0.0034895069038611837, Final Batch Loss: 0.002218004083260894\n",
      "Epoch 1880, Loss: 0.0010570718841336202, Final Batch Loss: 5.179318759473972e-05\n",
      "Epoch 1881, Loss: 0.0009010380017571151, Final Batch Loss: 0.00015431680367328227\n",
      "Epoch 1882, Loss: 0.003551896437244295, Final Batch Loss: 3.6011024917570467e-07\n",
      "Epoch 1883, Loss: 0.0037025063720648177, Final Batch Loss: 6.135067815193906e-05\n",
      "Epoch 1884, Loss: 0.0039497222896898165, Final Batch Loss: 0.0004213670326862484\n",
      "Epoch 1885, Loss: 0.0017997986869886518, Final Batch Loss: 0.0003414951206650585\n",
      "Epoch 1886, Loss: 0.03441344917519018, Final Batch Loss: 0.004469497594982386\n",
      "Epoch 1887, Loss: 0.0028175011175335385, Final Batch Loss: 9.215022146236151e-06\n",
      "Epoch 1888, Loss: 0.033103386322181905, Final Batch Loss: 4.4813892600359395e-05\n",
      "Epoch 1889, Loss: 0.0009708750585559756, Final Batch Loss: 9.823077562032267e-05\n",
      "Epoch 1890, Loss: 0.003617575050157029, Final Batch Loss: 7.926705438876525e-05\n",
      "Epoch 1891, Loss: 0.022825076650406118, Final Batch Loss: 9.078705261345021e-06\n",
      "Epoch 1892, Loss: 0.03666822389527624, Final Batch Loss: 2.6696495751821203e-06\n",
      "Epoch 1893, Loss: 0.0017766552919056267, Final Batch Loss: 0.0006604953086934984\n",
      "Epoch 1894, Loss: 0.010514892055653036, Final Batch Loss: 0.000582918815780431\n",
      "Epoch 1895, Loss: 0.0025048560164577793, Final Batch Loss: 4.545069168671034e-05\n",
      "Epoch 1896, Loss: 0.0036822767870035022, Final Batch Loss: 0.00026994242216460407\n",
      "Epoch 1897, Loss: 0.004076031211297959, Final Batch Loss: 0.0009790108306333423\n",
      "Epoch 1898, Loss: 0.000909325375687331, Final Batch Loss: 0.00022314376838039607\n",
      "Epoch 1899, Loss: 0.005089180849608965, Final Batch Loss: 0.00014558325347024947\n",
      "Epoch 1900, Loss: 0.003927097714040428, Final Batch Loss: 0.0023985423613339663\n",
      "Epoch 1901, Loss: 0.0040861451416276395, Final Batch Loss: 0.00019741489086300135\n",
      "Epoch 1902, Loss: 0.0009880870493361726, Final Batch Loss: 0.00019906416127923876\n",
      "Epoch 1903, Loss: 0.013154920776287327, Final Batch Loss: 1.4363398804562166e-05\n",
      "Epoch 1904, Loss: 0.0058329445309937, Final Batch Loss: 0.0007011659909039736\n",
      "Epoch 1905, Loss: 0.0050518380958237685, Final Batch Loss: 7.42354677640833e-05\n",
      "Epoch 1906, Loss: 0.0014188676959747681, Final Batch Loss: 2.5448442102060653e-05\n",
      "Epoch 1907, Loss: 0.029955558751680655, Final Batch Loss: 1.0226507583865896e-05\n",
      "Epoch 1908, Loss: 0.0021551387490035268, Final Batch Loss: 1.8964959963341244e-05\n",
      "Epoch 1909, Loss: 0.004375131407869048, Final Batch Loss: 0.00047086854465305805\n",
      "Epoch 1910, Loss: 0.0024820203470881097, Final Batch Loss: 0.0017507137963548303\n",
      "Epoch 1911, Loss: 0.002768204692984, Final Batch Loss: 0.0002363690291531384\n",
      "Epoch 1912, Loss: 0.0014179706058712327, Final Batch Loss: 8.177697054634336e-06\n",
      "Epoch 1913, Loss: 0.010754364775493741, Final Batch Loss: 0.00081657461123541\n",
      "Epoch 1914, Loss: 0.003305663267383352, Final Batch Loss: 0.0010082655353471637\n",
      "Epoch 1915, Loss: 0.000716341248335084, Final Batch Loss: 3.431424920563586e-05\n",
      "Epoch 1916, Loss: 0.001982374222279759, Final Batch Loss: 3.768840178963728e-05\n",
      "Epoch 1917, Loss: 0.0013075687893433496, Final Batch Loss: 0.00018708850257098675\n",
      "Epoch 1918, Loss: 0.014068027405301109, Final Batch Loss: 0.010846290737390518\n",
      "Epoch 1919, Loss: 0.0003225969148843433, Final Batch Loss: 1.047754176397575e-05\n",
      "Epoch 1920, Loss: 0.0026597500836942345, Final Batch Loss: 0.0015604397049173713\n",
      "Epoch 1921, Loss: 0.000888318638317287, Final Batch Loss: 0.00012891927326563746\n",
      "Epoch 1922, Loss: 0.002818298202328151, Final Batch Loss: 0.0013891813578084111\n",
      "Epoch 1923, Loss: 0.0038514966727234423, Final Batch Loss: 0.0008567908662371337\n",
      "Epoch 1924, Loss: 0.012836413079639897, Final Batch Loss: 0.00018174247816205025\n",
      "Epoch 1925, Loss: 0.0007724495299044065, Final Batch Loss: 2.7138223231304437e-05\n",
      "Epoch 1926, Loss: 0.00113145225259359, Final Batch Loss: 0.000293239630991593\n",
      "Epoch 1927, Loss: 0.0019257418971392326, Final Batch Loss: 0.000137849579914473\n",
      "Epoch 1928, Loss: 0.0027210770786041394, Final Batch Loss: 0.00048853550106287\n",
      "Epoch 1929, Loss: 0.01642204606469022, Final Batch Loss: 7.511085277656093e-05\n",
      "Epoch 1930, Loss: 0.0017145592501037754, Final Batch Loss: 0.00016724964370951056\n",
      "Epoch 1931, Loss: 0.022622631970079965, Final Batch Loss: 1.533052090962883e-05\n",
      "Epoch 1932, Loss: 0.0175185363041237, Final Batch Loss: 0.01029029581695795\n",
      "Epoch 1933, Loss: 0.0005991161306155846, Final Batch Loss: 8.664742927066982e-05\n",
      "Epoch 1934, Loss: 0.0017380586796207353, Final Batch Loss: 0.000424283993197605\n",
      "Epoch 1935, Loss: 0.0037147864122744068, Final Batch Loss: 1.1792791156040039e-05\n",
      "Epoch 1936, Loss: 0.003048767008294817, Final Batch Loss: 0.00019633212650660425\n",
      "Epoch 1937, Loss: 0.003665291582080954, Final Batch Loss: 5.736889647778298e-07\n",
      "Epoch 1938, Loss: 0.006910800002515316, Final Batch Loss: 0.00012672771117649972\n",
      "Epoch 1939, Loss: 0.002455507798003964, Final Batch Loss: 0.0002372243907302618\n",
      "Epoch 1940, Loss: 0.0014086280098126736, Final Batch Loss: 4.318970604799688e-05\n",
      "Epoch 1941, Loss: 0.00089113497051585, Final Batch Loss: 1.704554415482562e-05\n",
      "Epoch 1942, Loss: 0.0017041853279806674, Final Batch Loss: 3.650916914921254e-05\n",
      "Epoch 1943, Loss: 0.0007550212367277709, Final Batch Loss: 1.1775705388572533e-05\n",
      "Epoch 1944, Loss: 0.000765724395023426, Final Batch Loss: 4.302944216760807e-05\n",
      "Epoch 1945, Loss: 0.0014301311748567969, Final Batch Loss: 4.2237748857587576e-05\n",
      "Epoch 1946, Loss: 0.0018964398105367763, Final Batch Loss: 4.942185682921263e-07\n",
      "Epoch 1947, Loss: 0.002590404576039873, Final Batch Loss: 4.8408444854430854e-05\n",
      "Epoch 1948, Loss: 0.0013328390596143436, Final Batch Loss: 5.2134138968540356e-05\n",
      "Epoch 1949, Loss: 0.0009295263334934134, Final Batch Loss: 9.478248102823272e-06\n",
      "Epoch 1950, Loss: 0.0015593807402183302, Final Batch Loss: 0.00011533223005244508\n",
      "Epoch 1951, Loss: 0.0013965087691758526, Final Batch Loss: 1.7103926438721828e-05\n",
      "Epoch 1952, Loss: 0.0009477396502006741, Final Batch Loss: 5.761501142842462e-06\n",
      "Epoch 1953, Loss: 0.00254722836888277, Final Batch Loss: 2.781545731522783e-07\n",
      "Epoch 1954, Loss: 0.0014884829179209191, Final Batch Loss: 0.00020796859462279826\n",
      "Epoch 1955, Loss: 0.005606611637631431, Final Batch Loss: 0.001496588927693665\n",
      "Epoch 1956, Loss: 0.0015840069227124332, Final Batch Loss: 8.671922842040658e-06\n",
      "Epoch 1957, Loss: 0.005050684043453657, Final Batch Loss: 7.360447852988727e-06\n",
      "Epoch 1958, Loss: 0.0024185696479435137, Final Batch Loss: 5.411131951404968e-06\n",
      "Epoch 1959, Loss: 0.014815703114436474, Final Batch Loss: 3.838086558971554e-05\n",
      "Epoch 1960, Loss: 0.0074186501442454755, Final Batch Loss: 0.004633283708244562\n",
      "Epoch 1961, Loss: 0.0019183749609510414, Final Batch Loss: 1.0595664207357913e-05\n",
      "Epoch 1962, Loss: 0.0076656625751638785, Final Batch Loss: 3.5617369576357305e-05\n",
      "Epoch 1963, Loss: 0.013725890355999582, Final Batch Loss: 5.69324656680692e-05\n",
      "Epoch 1964, Loss: 0.0032533892954234034, Final Batch Loss: 0.0009096571593545377\n",
      "Epoch 1965, Loss: 0.001881089096514188, Final Batch Loss: 7.477420240320498e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1966, Loss: 0.0015417807226185687, Final Batch Loss: 4.6787827159278095e-06\n",
      "Epoch 1967, Loss: 0.008707795816008002, Final Batch Loss: 0.005512468051165342\n",
      "Epoch 1968, Loss: 0.0017232581842563377, Final Batch Loss: 8.195531790988753e-07\n",
      "Epoch 1969, Loss: 0.005942971314652823, Final Batch Loss: 0.005364429671317339\n",
      "Epoch 1970, Loss: 0.0019585721456678584, Final Batch Loss: 0.0011283099884167314\n",
      "Epoch 1971, Loss: 0.0018261971436004387, Final Batch Loss: 0.0006461974699050188\n",
      "Epoch 1972, Loss: 0.000407266409638396, Final Batch Loss: 1.4501853911497165e-05\n",
      "Epoch 1973, Loss: 0.004664526022679638, Final Batch Loss: 0.00023144728038460016\n",
      "Epoch 1974, Loss: 0.0006919365914654918, Final Batch Loss: 2.504942676750943e-05\n",
      "Epoch 1975, Loss: 0.02199001065309858, Final Batch Loss: 0.0017843828536570072\n",
      "Epoch 1976, Loss: 0.0004898673068964854, Final Batch Loss: 1.5793362763361074e-05\n",
      "Epoch 1977, Loss: 0.0022939990667509846, Final Batch Loss: 0.00010675231897039339\n",
      "Epoch 1978, Loss: 0.0017785137169994414, Final Batch Loss: 2.295429294463247e-05\n",
      "Epoch 1979, Loss: 0.002599064726382494, Final Batch Loss: 0.0008869711309671402\n",
      "Epoch 1980, Loss: 0.020333542070147814, Final Batch Loss: 5.3916559409117326e-05\n",
      "Epoch 1981, Loss: 0.0010656177400960587, Final Batch Loss: 4.5197593863122165e-06\n",
      "Epoch 1982, Loss: 0.0007268417630257318, Final Batch Loss: 3.991903577116318e-05\n",
      "Epoch 1983, Loss: 0.0023092864430509508, Final Batch Loss: 0.0008957621757872403\n",
      "Epoch 1984, Loss: 0.0006909501680638641, Final Batch Loss: 9.827816393226385e-05\n",
      "Epoch 1985, Loss: 0.009350466334581142, Final Batch Loss: 0.006993637885898352\n",
      "Epoch 1986, Loss: 0.003986411087680608, Final Batch Loss: 0.001179561368189752\n",
      "Epoch 1987, Loss: 0.000853430523420684, Final Batch Loss: 4.2288535041734576e-05\n",
      "Epoch 1988, Loss: 0.0021037137921666726, Final Batch Loss: 0.00014800803910475224\n",
      "Epoch 1989, Loss: 0.0023157138384704012, Final Batch Loss: 5.860620512976311e-05\n",
      "Epoch 1990, Loss: 0.000298014395411883, Final Batch Loss: 6.680647857137956e-07\n",
      "Epoch 1991, Loss: 0.00736344612960238, Final Batch Loss: 0.00560821034014225\n",
      "Epoch 1992, Loss: 0.0008723421874492487, Final Batch Loss: 5.850956313224742e-06\n",
      "Epoch 1993, Loss: 0.002178811773774214, Final Batch Loss: 4.320165317039937e-05\n",
      "Epoch 1994, Loss: 0.009651365816807811, Final Batch Loss: 4.7756070671312045e-06\n",
      "Epoch 1995, Loss: 0.010915765749814454, Final Batch Loss: 0.00992687325924635\n",
      "Epoch 1996, Loss: 0.0008454244743916206, Final Batch Loss: 4.440611519385129e-05\n",
      "Epoch 1997, Loss: 0.0002434817979519721, Final Batch Loss: 9.274890544475056e-06\n",
      "Epoch 1998, Loss: 0.0004367276378616225, Final Batch Loss: 5.5544020142406225e-05\n",
      "Epoch 1999, Loss: 0.0011114758726762375, Final Batch Loss: 5.368978236219846e-06\n",
      "Epoch 2000, Loss: 0.001497903235360809, Final Batch Loss: 8.717111654732435e-07\n",
      "Epoch 2001, Loss: 0.05170140716654714, Final Batch Loss: 0.00022901354532223195\n",
      "Epoch 2002, Loss: 0.0010800576146721141, Final Batch Loss: 1.6501073332619853e-05\n",
      "Epoch 2003, Loss: 0.00133203685436456, Final Batch Loss: 1.579572017362807e-05\n",
      "Epoch 2004, Loss: 0.0037616298359353095, Final Batch Loss: 0.0003738146333489567\n",
      "Epoch 2005, Loss: 0.001766317269357387, Final Batch Loss: 7.687658217037097e-05\n",
      "Epoch 2006, Loss: 0.005945058534052805, Final Batch Loss: 1.8247863408760168e-05\n",
      "Epoch 2007, Loss: 0.0007237224344862625, Final Batch Loss: 0.0002839330118149519\n",
      "Epoch 2008, Loss: 0.003186426406045939, Final Batch Loss: 7.551720500487136e-06\n",
      "Epoch 2009, Loss: 0.0028356736584100872, Final Batch Loss: 0.0005917861708439887\n",
      "Epoch 2010, Loss: 0.031483772792853415, Final Batch Loss: 0.00015764917770866305\n",
      "Epoch 2011, Loss: 0.0020369897538330406, Final Batch Loss: 0.0003466961206868291\n",
      "Epoch 2012, Loss: 0.002142659679520875, Final Batch Loss: 0.0006961848703213036\n",
      "Epoch 2013, Loss: 0.004925972374621779, Final Batch Loss: 0.00046381389256566763\n",
      "Epoch 2014, Loss: 0.0015733203763375059, Final Batch Loss: 0.0007752607925795019\n",
      "Epoch 2015, Loss: 0.0006229361924852128, Final Batch Loss: 3.2433335945825092e-06\n",
      "Epoch 2016, Loss: 0.005363386582757812, Final Batch Loss: 0.0001639706315472722\n",
      "Epoch 2017, Loss: 0.011892029433511198, Final Batch Loss: 0.000820385233964771\n",
      "Epoch 2018, Loss: 0.0016550680302316323, Final Batch Loss: 0.0010516393231227994\n",
      "Epoch 2019, Loss: 0.0008306193885800894, Final Batch Loss: 5.083992800791748e-05\n",
      "Epoch 2020, Loss: 0.003597414121031761, Final Batch Loss: 0.002612600801512599\n",
      "Epoch 2021, Loss: 0.02795548550784588, Final Batch Loss: 1.0938645573332906e-05\n",
      "Epoch 2022, Loss: 0.0030521616426995024, Final Batch Loss: 1.667179458308965e-05\n",
      "Epoch 2023, Loss: 0.0024690978478929537, Final Batch Loss: 9.660742534833844e-07\n",
      "Epoch 2024, Loss: 0.000722845182394849, Final Batch Loss: 1.2765186738761258e-06\n",
      "Epoch 2025, Loss: 0.0020966837619198486, Final Batch Loss: 0.0015002730069682002\n",
      "Epoch 2026, Loss: 0.0010292011538695078, Final Batch Loss: 6.959033635212108e-05\n",
      "Epoch 2027, Loss: 0.0015039308709674515, Final Batch Loss: 0.00011337752948747948\n",
      "Epoch 2028, Loss: 0.00043544401705730706, Final Batch Loss: 0.00010094488243339583\n",
      "Epoch 2029, Loss: 0.014822598153841682, Final Batch Loss: 0.00047540650120936334\n",
      "Epoch 2030, Loss: 0.001022069349346566, Final Batch Loss: 2.7419706384534948e-05\n",
      "Epoch 2031, Loss: 0.001775042779627256, Final Batch Loss: 0.00017380989447701722\n",
      "Epoch 2032, Loss: 0.0023451828747047543, Final Batch Loss: 1.4901160305669237e-08\n",
      "Epoch 2033, Loss: 0.0013908742603234714, Final Batch Loss: 1.916803557833191e-05\n",
      "Epoch 2034, Loss: 0.0010235256340820342, Final Batch Loss: 0.00023008142306935042\n",
      "Epoch 2035, Loss: 0.012564566080982331, Final Batch Loss: 0.0007366968784481287\n",
      "Epoch 2036, Loss: 0.0013738005109189544, Final Batch Loss: 3.54131952917669e-05\n",
      "Epoch 2037, Loss: 0.002116125135216862, Final Batch Loss: 0.0010036489693447948\n",
      "Epoch 2038, Loss: 0.0015426513855345547, Final Batch Loss: 0.00023060590319801122\n",
      "Epoch 2039, Loss: 0.006119113696513523, Final Batch Loss: 1.2982870430278126e-05\n",
      "Epoch 2040, Loss: 0.0007502690859837458, Final Batch Loss: 0.0001385745854349807\n",
      "Epoch 2041, Loss: 0.0008140141526382649, Final Batch Loss: 0.00016839844465721399\n",
      "Epoch 2042, Loss: 0.0018873994376917835, Final Batch Loss: 0.0006520437891595066\n",
      "Epoch 2043, Loss: 0.0003166500355291646, Final Batch Loss: 3.254401599406265e-05\n",
      "Epoch 2044, Loss: 0.008675910445163026, Final Batch Loss: 0.00010174029739573598\n",
      "Epoch 2045, Loss: 0.00511631928566203, Final Batch Loss: 2.1074463802506216e-05\n",
      "Epoch 2046, Loss: 0.003003472367709037, Final Batch Loss: 0.002510094316676259\n",
      "Epoch 2047, Loss: 0.0017998899602389429, Final Batch Loss: 8.986195462057367e-05\n",
      "Epoch 2048, Loss: 0.0020953993926013936, Final Batch Loss: 1.503812109149294e-05\n",
      "Epoch 2049, Loss: 0.0019329808210386545, Final Batch Loss: 4.420662662596442e-07\n",
      "Epoch 2050, Loss: 0.0032927584543358535, Final Batch Loss: 0.0009229955612681806\n",
      "Epoch 2051, Loss: 0.0022538819175679237, Final Batch Loss: 0.0007383619085885584\n",
      "Epoch 2052, Loss: 0.0023588200128870085, Final Batch Loss: 0.0006258744397200644\n",
      "Epoch 2053, Loss: 0.0007352872635237873, Final Batch Loss: 9.085644705919549e-05\n",
      "Epoch 2054, Loss: 0.013977138080917939, Final Batch Loss: 3.176358404743951e-06\n",
      "Epoch 2055, Loss: 0.021516607877856586, Final Batch Loss: 0.01560742687433958\n",
      "Epoch 2056, Loss: 0.039160557331342716, Final Batch Loss: 8.093333599390462e-05\n",
      "Epoch 2057, Loss: 0.009382253982039401, Final Batch Loss: 6.089843009249307e-05\n",
      "Epoch 2058, Loss: 0.004448561419849284, Final Batch Loss: 0.0033038381952792406\n",
      "Epoch 2059, Loss: 0.00205642003857065, Final Batch Loss: 0.0002552738878875971\n",
      "Epoch 2060, Loss: 0.002007267154112924, Final Batch Loss: 5.354547829483636e-05\n",
      "Epoch 2061, Loss: 0.009977977417293005, Final Batch Loss: 0.0035769680980592966\n",
      "Epoch 2062, Loss: 0.0017850316289695911, Final Batch Loss: 1.9851613615173846e-05\n",
      "Epoch 2063, Loss: 0.03851626082905568, Final Batch Loss: 0.009601919911801815\n",
      "Epoch 2064, Loss: 0.0034908447196357884, Final Batch Loss: 0.0018754230113700032\n",
      "Epoch 2065, Loss: 0.001063891511876136, Final Batch Loss: 6.68868888169527e-05\n",
      "Epoch 2066, Loss: 0.0035284565965412185, Final Batch Loss: 3.756817022804171e-05\n",
      "Epoch 2067, Loss: 0.0021079431753605604, Final Batch Loss: 0.0002933608484454453\n",
      "Epoch 2068, Loss: 0.003365114149346482, Final Batch Loss: 9.90285407169722e-05\n",
      "Epoch 2069, Loss: 0.0010833294145413674, Final Batch Loss: 0.0001208011744893156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2070, Loss: 0.006863608126877807, Final Batch Loss: 0.005909511353820562\n",
      "Epoch 2071, Loss: 0.04749546400125837, Final Batch Loss: 0.00010098309576278552\n",
      "Epoch 2072, Loss: 0.007409323719912209, Final Batch Loss: 2.2314648958854377e-05\n",
      "Epoch 2073, Loss: 0.0041681083566800226, Final Batch Loss: 3.9099788409657776e-05\n",
      "Epoch 2074, Loss: 0.0024552069189667236, Final Batch Loss: 0.00021091038070153445\n",
      "Epoch 2075, Loss: 0.0021581265118300053, Final Batch Loss: 2.48352051812617e-07\n",
      "Epoch 2076, Loss: 0.005284237980959006, Final Batch Loss: 0.00197466928511858\n",
      "Epoch 2077, Loss: 0.0016268914914689958, Final Batch Loss: 0.0005385910044424236\n",
      "Epoch 2078, Loss: 0.0008187086932593957, Final Batch Loss: 4.236726090312004e-05\n",
      "Epoch 2079, Loss: 0.009205403417581692, Final Batch Loss: 0.002527006668969989\n",
      "Epoch 2080, Loss: 0.0009368881819682429, Final Batch Loss: 3.0085977414273657e-05\n",
      "Epoch 2081, Loss: 0.0013274935190565884, Final Batch Loss: 0.0002894301142077893\n",
      "Epoch 2082, Loss: 0.0030957804192439653, Final Batch Loss: 0.0005250110989436507\n",
      "Epoch 2083, Loss: 0.0007458658383256989, Final Batch Loss: 1.7146938262158073e-05\n",
      "Epoch 2084, Loss: 0.003929113838239573, Final Batch Loss: 6.192077125888318e-05\n",
      "Epoch 2085, Loss: 0.0010073373960040044, Final Batch Loss: 5.2140680054435506e-05\n",
      "Epoch 2086, Loss: 0.0008206654310924932, Final Batch Loss: 0.000222100512473844\n",
      "Epoch 2087, Loss: 0.005558926532103214, Final Batch Loss: 0.004238888155668974\n",
      "Epoch 2088, Loss: 0.00641625663593004, Final Batch Loss: 2.4584334823885e-05\n",
      "Epoch 2089, Loss: 0.01736957062894362, Final Batch Loss: 0.00231429492123425\n",
      "Epoch 2090, Loss: 0.007162698851971072, Final Batch Loss: 3.0644601793028414e-05\n",
      "Epoch 2091, Loss: 0.0027104079908895073, Final Batch Loss: 8.879562301444821e-06\n",
      "Epoch 2092, Loss: 0.0020788628098671325, Final Batch Loss: 0.0001580451353220269\n",
      "Epoch 2093, Loss: 0.01035739340022701, Final Batch Loss: 9.009211680677254e-06\n",
      "Epoch 2094, Loss: 0.002928865244030021, Final Batch Loss: 0.0001830048713600263\n",
      "Epoch 2095, Loss: 0.013662019307957962, Final Batch Loss: 0.00029423157684504986\n",
      "Epoch 2096, Loss: 0.0034828692441806197, Final Batch Loss: 0.0013469700934365392\n",
      "Epoch 2097, Loss: 0.02583739487454295, Final Batch Loss: 0.0008949832408688962\n",
      "Epoch 2098, Loss: 0.004498252201301511, Final Batch Loss: 0.00029786009690724313\n",
      "Epoch 2099, Loss: 0.0014807949964961153, Final Batch Loss: 4.991438800061587e-06\n",
      "Epoch 2100, Loss: 0.01109884543257067, Final Batch Loss: 0.00057083839783445\n",
      "Epoch 2101, Loss: 0.012986911699044867, Final Batch Loss: 2.5920295229298063e-05\n",
      "Epoch 2102, Loss: 0.0027518249044078402, Final Batch Loss: 3.1376366678159684e-05\n",
      "Epoch 2103, Loss: 0.0026611856101226294, Final Batch Loss: 0.000187948506209068\n",
      "Epoch 2104, Loss: 0.0018503155806683935, Final Batch Loss: 0.0006121212500147521\n",
      "Epoch 2105, Loss: 0.003327133279526606, Final Batch Loss: 0.0019190601306036115\n",
      "Epoch 2106, Loss: 0.002951586968265474, Final Batch Loss: 0.0011275040451437235\n",
      "Epoch 2107, Loss: 0.005056638779933564, Final Batch Loss: 0.00017611349176149815\n",
      "Epoch 2108, Loss: 0.004171324018443556, Final Batch Loss: 5.766368758486351e-06\n",
      "Epoch 2109, Loss: 0.000566241578781046, Final Batch Loss: 0.0003039315633941442\n",
      "Epoch 2110, Loss: 0.00046347708484972827, Final Batch Loss: 0.00016980525106191635\n",
      "Epoch 2111, Loss: 0.004573934769723564, Final Batch Loss: 0.002769108861684799\n",
      "Epoch 2112, Loss: 0.0021580876427833573, Final Batch Loss: 1.0643002497090492e-05\n",
      "Epoch 2113, Loss: 0.0030911838184692897, Final Batch Loss: 6.994464638410136e-05\n",
      "Epoch 2114, Loss: 0.0038702630408806726, Final Batch Loss: 0.0001635121152503416\n",
      "Epoch 2115, Loss: 0.007907014500233345, Final Batch Loss: 0.00013904499064665288\n",
      "Epoch 2116, Loss: 0.0038658887351630256, Final Batch Loss: 0.00015237591287586838\n",
      "Epoch 2117, Loss: 0.0004778710549544485, Final Batch Loss: 5.545332442125073e-06\n",
      "Epoch 2118, Loss: 0.0016806334315333515, Final Batch Loss: 0.000281541288131848\n",
      "Epoch 2119, Loss: 0.0031172365343081765, Final Batch Loss: 0.00033363638794980943\n",
      "Epoch 2120, Loss: 0.0010607972435536794, Final Batch Loss: 0.0001099894943763502\n",
      "Epoch 2121, Loss: 0.0018779839665512554, Final Batch Loss: 0.001784420688636601\n",
      "Epoch 2122, Loss: 0.00027427233771959436, Final Batch Loss: 5.443278951133834e-06\n",
      "Epoch 2123, Loss: 0.0031301369017455727, Final Batch Loss: 0.001318395952694118\n",
      "Epoch 2124, Loss: 0.004293592268368229, Final Batch Loss: 0.0024783082772046328\n",
      "Epoch 2125, Loss: 0.00039483498858317034, Final Batch Loss: 1.224682364409091e-05\n",
      "Epoch 2126, Loss: 0.0006968669731577393, Final Batch Loss: 1.3644115824718028e-05\n",
      "Epoch 2127, Loss: 0.0017810484168876428, Final Batch Loss: 0.00020333740394562483\n",
      "Epoch 2128, Loss: 0.0003710723588028486, Final Batch Loss: 2.0239997411408694e-06\n",
      "Epoch 2129, Loss: 0.004035216647025663, Final Batch Loss: 0.00015567446826025844\n",
      "Epoch 2130, Loss: 0.002681308532373805, Final Batch Loss: 1.1822784472315107e-05\n",
      "Epoch 2131, Loss: 0.00039662696599407354, Final Batch Loss: 1.4982798347773496e-05\n",
      "Epoch 2132, Loss: 0.0009646032140153693, Final Batch Loss: 2.6147465177928098e-05\n",
      "Epoch 2133, Loss: 0.00016173843869182747, Final Batch Loss: 2.433191730233375e-05\n",
      "Epoch 2134, Loss: 0.0020913206917612115, Final Batch Loss: 1.9482433344819583e-05\n",
      "Epoch 2135, Loss: 0.0014031090649950784, Final Batch Loss: 2.5708170142024755e-05\n",
      "Epoch 2136, Loss: 0.00039231107712112134, Final Batch Loss: 1.3205160030338448e-05\n",
      "Epoch 2137, Loss: 0.00034606796498337644, Final Batch Loss: 2.5106668545049615e-05\n",
      "Epoch 2138, Loss: 0.0007236354995256988, Final Batch Loss: 6.125372601673007e-05\n",
      "Epoch 2139, Loss: 0.0009051183005794883, Final Batch Loss: 0.00020550510089378804\n",
      "Epoch 2140, Loss: 0.00045611996483785333, Final Batch Loss: 8.286912816402037e-06\n",
      "Epoch 2141, Loss: 0.0002974883835236142, Final Batch Loss: 4.793153607351996e-07\n",
      "Epoch 2142, Loss: 0.0014840886206002324, Final Batch Loss: 1.4472384464170318e-05\n",
      "Epoch 2143, Loss: 0.042244096978379275, Final Batch Loss: 1.7955486555365496e-06\n",
      "Epoch 2144, Loss: 0.0010695225837480393, Final Batch Loss: 1.149335457739653e-05\n",
      "Epoch 2145, Loss: 0.017692652390906005, Final Batch Loss: 6.363800639519468e-05\n",
      "Epoch 2146, Loss: 0.0003938129739253782, Final Batch Loss: 3.0496994440909475e-06\n",
      "Epoch 2147, Loss: 0.0016085924362414517, Final Batch Loss: 7.264357554959133e-05\n",
      "Epoch 2148, Loss: 0.005715558614610927, Final Batch Loss: 0.002932197181507945\n",
      "Epoch 2149, Loss: 0.0015166202501859516, Final Batch Loss: 0.0006329752504825592\n",
      "Epoch 2150, Loss: 0.0019290732161607593, Final Batch Loss: 5.100184353068471e-05\n",
      "Epoch 2151, Loss: 0.0005759940650023054, Final Batch Loss: 0.00037485428038053215\n",
      "Epoch 2152, Loss: 0.0009269580459658755, Final Batch Loss: 1.777089164534118e-05\n",
      "Epoch 2153, Loss: 0.0014115131089056376, Final Batch Loss: 4.025589078082703e-05\n",
      "Epoch 2154, Loss: 0.00029025409821770154, Final Batch Loss: 2.7440204576123506e-05\n",
      "Epoch 2155, Loss: 0.0025001541962410556, Final Batch Loss: 1.725027868815232e-05\n",
      "Epoch 2156, Loss: 0.0004143591188281448, Final Batch Loss: 1.1672566557763275e-07\n",
      "Epoch 2157, Loss: 0.0010763201180452597, Final Batch Loss: 1.0565589946054388e-05\n",
      "Epoch 2158, Loss: 0.0015087346912423527, Final Batch Loss: 8.493591394653777e-07\n",
      "Epoch 2159, Loss: 0.001062265375367133, Final Batch Loss: 1.7939923054655083e-05\n",
      "Epoch 2160, Loss: 0.0036039505512235337, Final Batch Loss: 1.3600068086816464e-05\n",
      "Epoch 2161, Loss: 0.0020400805387907894, Final Batch Loss: 0.0008722496568225324\n",
      "Epoch 2162, Loss: 0.0026792435746756382, Final Batch Loss: 0.00010894957085838541\n",
      "Epoch 2163, Loss: 0.0015859599697876092, Final Batch Loss: 3.725287456290971e-08\n",
      "Epoch 2164, Loss: 0.002543253511248622, Final Batch Loss: 0.0005519397673197091\n",
      "Epoch 2165, Loss: 0.0012699148375645564, Final Batch Loss: 7.351138151534542e-07\n",
      "Epoch 2166, Loss: 0.0006866893108963268, Final Batch Loss: 0.0005303163197822869\n",
      "Epoch 2167, Loss: 0.0013945936043455731, Final Batch Loss: 6.5940163040068e-05\n",
      "Epoch 2168, Loss: 0.0005631972126138862, Final Batch Loss: 5.307080937200226e-05\n",
      "Epoch 2169, Loss: 0.00026804809385794215, Final Batch Loss: 4.0074930439004675e-05\n",
      "Epoch 2170, Loss: 0.0002152193089841603, Final Batch Loss: 5.1905112741224e-07\n",
      "Epoch 2171, Loss: 0.002287588009494357, Final Batch Loss: 0.0012201002100482583\n",
      "Epoch 2172, Loss: 0.02856985122343758, Final Batch Loss: 8.09709308668971e-05\n",
      "Epoch 2173, Loss: 8.045207505347207e-05, Final Batch Loss: 9.20533602766227e-06\n",
      "Epoch 2174, Loss: 0.0027797631919384003, Final Batch Loss: 0.000115145870950073\n",
      "Epoch 2175, Loss: 0.0004223731630190741, Final Batch Loss: 4.395438736537471e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2176, Loss: 0.011736352089371849, Final Batch Loss: 6.705516852889559e-08\n",
      "Epoch 2177, Loss: 0.0005713803548133001, Final Batch Loss: 0.00011325407103868201\n",
      "Epoch 2178, Loss: 0.0028495307633420452, Final Batch Loss: 0.0014445740962401032\n",
      "Epoch 2179, Loss: 0.00045672258420381695, Final Batch Loss: 6.226251571206376e-05\n",
      "Epoch 2180, Loss: 0.0015623237850377336, Final Batch Loss: 0.001157820806838572\n",
      "Epoch 2181, Loss: 0.0016479182741022669, Final Batch Loss: 2.9098147933837026e-05\n",
      "Epoch 2182, Loss: 0.0025062463246285915, Final Batch Loss: 4.138721851631999e-05\n",
      "Epoch 2183, Loss: 0.0005692423073924147, Final Batch Loss: 0.00014952593483030796\n",
      "Epoch 2184, Loss: 0.0018320654512535839, Final Batch Loss: 5.053562290413538e-06\n",
      "Epoch 2185, Loss: 0.0008141429025272373, Final Batch Loss: 5.761799184256233e-05\n",
      "Epoch 2186, Loss: 0.00029571308641607175, Final Batch Loss: 1.4429015209316276e-06\n",
      "Epoch 2187, Loss: 0.0008437743060767389, Final Batch Loss: 2.4188927909563063e-06\n",
      "Epoch 2188, Loss: 0.00022870199973112904, Final Batch Loss: 1.481425715610385e-05\n",
      "Epoch 2189, Loss: 0.0009043517566169612, Final Batch Loss: 5.558814518735744e-05\n",
      "Epoch 2190, Loss: 0.012076142240402987, Final Batch Loss: 4.13933266827371e-05\n",
      "Epoch 2191, Loss: 0.0008721899309058756, Final Batch Loss: 3.2285843332147124e-08\n",
      "Epoch 2192, Loss: 0.012768018320230112, Final Batch Loss: 3.203738287993474e-07\n",
      "Epoch 2193, Loss: 0.012104088087653508, Final Batch Loss: 1.0417232260806486e-05\n",
      "Epoch 2194, Loss: 0.015980855605448596, Final Batch Loss: 0.0004222776915412396\n",
      "Epoch 2195, Loss: 0.001072592451237142, Final Batch Loss: 0.0005220736493356526\n",
      "Epoch 2196, Loss: 0.009709394973469898, Final Batch Loss: 0.009014627896249294\n",
      "Epoch 2197, Loss: 0.0010523061975504788, Final Batch Loss: 6.953816296118021e-07\n",
      "Epoch 2198, Loss: 0.002068541514745448, Final Batch Loss: 1.8690865545067936e-05\n",
      "Epoch 2199, Loss: 0.0022556812611753685, Final Batch Loss: 2.9057193273729354e-07\n",
      "Epoch 2200, Loss: 0.001512527946033515, Final Batch Loss: 0.0006824224255979061\n",
      "Epoch 2201, Loss: 0.0004527997008381135, Final Batch Loss: 1.0604559292914928e-06\n",
      "Epoch 2202, Loss: 0.0029529993012147315, Final Batch Loss: 7.379847829724895e-06\n",
      "Epoch 2203, Loss: 0.00166780090512475, Final Batch Loss: 3.553650458343327e-06\n",
      "Epoch 2204, Loss: 0.02649918401272089, Final Batch Loss: 2.9553899594247923e-07\n",
      "Epoch 2205, Loss: 0.0007870197150623426, Final Batch Loss: 0.00014947094314265996\n",
      "Epoch 2206, Loss: 0.0014008157304488122, Final Batch Loss: 0.00011860308586619794\n",
      "Epoch 2207, Loss: 0.02353638070053421, Final Batch Loss: 0.0002260797336930409\n",
      "Epoch 2208, Loss: 0.00046466679486911744, Final Batch Loss: 0.00012276296911295503\n",
      "Epoch 2209, Loss: 0.0011361958240740933, Final Batch Loss: 6.342294364003465e-05\n",
      "Epoch 2210, Loss: 0.0014906454473475605, Final Batch Loss: 2.105998873958015e-06\n",
      "Epoch 2211, Loss: 0.0014100019955662901, Final Batch Loss: 3.476935717117158e-08\n",
      "Epoch 2212, Loss: 0.0014498120759469657, Final Batch Loss: 4.1474740442026814e-07\n",
      "Epoch 2213, Loss: 0.0006215277699084254, Final Batch Loss: 2.720027077884879e-05\n",
      "Epoch 2214, Loss: 0.0012504353107942734, Final Batch Loss: 0.00014053634367883205\n",
      "Epoch 2215, Loss: 0.0006613604878111801, Final Batch Loss: 4.812793577002594e-06\n",
      "Epoch 2216, Loss: 0.0049769539618864655, Final Batch Loss: 0.0016751777147874236\n",
      "Epoch 2217, Loss: 0.004245774762239307, Final Batch Loss: 0.0003808454202953726\n",
      "Epoch 2218, Loss: 0.0002927735858975211, Final Batch Loss: 2.0046258214279078e-05\n",
      "Epoch 2219, Loss: 0.0008179288561223075, Final Batch Loss: 5.632056854665279e-06\n",
      "Epoch 2220, Loss: 0.0003477835098237847, Final Batch Loss: 4.388540764921345e-05\n",
      "Epoch 2221, Loss: 0.0003918686543329386, Final Batch Loss: 4.3456526327645406e-05\n",
      "Epoch 2222, Loss: 0.002098055832902901, Final Batch Loss: 0.0018471470102667809\n",
      "Epoch 2223, Loss: 0.0004900245994576835, Final Batch Loss: 9.714313819131348e-06\n",
      "Epoch 2224, Loss: 0.02653691613340925, Final Batch Loss: 2.603665598144289e-05\n",
      "Epoch 2225, Loss: 0.0013117909547872841, Final Batch Loss: 2.1129060769453645e-05\n",
      "Epoch 2226, Loss: 0.0021113264956511557, Final Batch Loss: 0.0001554700284032151\n",
      "Epoch 2227, Loss: 0.0004736773335025646, Final Batch Loss: 5.5519238230772316e-05\n",
      "Epoch 2228, Loss: 0.008583377706600004, Final Batch Loss: 2.330306415387895e-05\n",
      "Epoch 2229, Loss: 0.0027085669280495495, Final Batch Loss: 0.00029355924925766885\n",
      "Epoch 2230, Loss: 0.000740632000088226, Final Batch Loss: 8.707681990927085e-05\n",
      "Epoch 2231, Loss: 0.0013577881545643322, Final Batch Loss: 0.000994645175524056\n",
      "Epoch 2232, Loss: 0.0007877701973484363, Final Batch Loss: 0.0006887190975248814\n",
      "Epoch 2233, Loss: 0.0005043327328166924, Final Batch Loss: 0.0002282373170601204\n",
      "Epoch 2234, Loss: 0.015478761077247327, Final Batch Loss: 7.00524469721131e-06\n",
      "Epoch 2235, Loss: 0.0003010337532032281, Final Batch Loss: 4.5906079321866855e-05\n",
      "Epoch 2236, Loss: 0.001621206960408017, Final Batch Loss: 0.0010148792061954737\n",
      "Epoch 2237, Loss: 0.0006988357581576565, Final Batch Loss: 2.647698602231685e-05\n",
      "Epoch 2238, Loss: 0.0011358526941194214, Final Batch Loss: 9.71044414654898e-07\n",
      "Epoch 2239, Loss: 0.003851779463730054, Final Batch Loss: 3.064886186621152e-05\n",
      "Epoch 2240, Loss: 0.0008157321426551789, Final Batch Loss: 2.80381937045604e-06\n",
      "Epoch 2241, Loss: 0.009263638639804839, Final Batch Loss: 4.4703465817974575e-08\n",
      "Epoch 2242, Loss: 0.001649963032832602, Final Batch Loss: 5.426165444077924e-06\n",
      "Epoch 2243, Loss: 0.034021825340460055, Final Batch Loss: 0.02776608057320118\n",
      "Epoch 2244, Loss: 0.0023423234028996376, Final Batch Loss: 7.392839961539721e-06\n",
      "Epoch 2245, Loss: 0.00239494297420606, Final Batch Loss: 0.00012247471022419631\n",
      "Epoch 2246, Loss: 0.02415772742824629, Final Batch Loss: 0.0005809969152323902\n",
      "Epoch 2247, Loss: 0.0021887164602958364, Final Batch Loss: 0.00015623400395270437\n",
      "Epoch 2248, Loss: 0.008411585229623597, Final Batch Loss: 8.475302456645295e-05\n",
      "Epoch 2249, Loss: 0.003626865195656137, Final Batch Loss: 1.4274416571424808e-05\n",
      "Epoch 2250, Loss: 0.0019434163186815567, Final Batch Loss: 9.881034202408046e-06\n",
      "Epoch 2251, Loss: 0.0007694281314911677, Final Batch Loss: 7.599531386404124e-07\n",
      "Epoch 2252, Loss: 0.0017815216124006383, Final Batch Loss: 5.2154035756757366e-08\n",
      "Epoch 2253, Loss: 0.0017046255263721832, Final Batch Loss: 2.883290335375932e-06\n",
      "Epoch 2254, Loss: 0.0002583384939498501, Final Batch Loss: 1.756393066898454e-05\n",
      "Epoch 2255, Loss: 0.001374198518533376, Final Batch Loss: 8.05609488452319e-06\n",
      "Epoch 2256, Loss: 0.00027043815498473123, Final Batch Loss: 7.512329466408119e-05\n",
      "Epoch 2257, Loss: 0.0005477841477841139, Final Batch Loss: 0.00017780701455194503\n",
      "Epoch 2258, Loss: 0.0013573075339081697, Final Batch Loss: 6.62718593957834e-05\n",
      "Epoch 2259, Loss: 0.004227638318297977, Final Batch Loss: 3.2085017664940096e-06\n",
      "Epoch 2260, Loss: 0.0003086175747739617, Final Batch Loss: 1.945766962307971e-05\n",
      "Epoch 2261, Loss: 0.0007058950714053935, Final Batch Loss: 2.764026248769369e-06\n",
      "Epoch 2262, Loss: 0.0003536961958161555, Final Batch Loss: 4.644170985557139e-07\n",
      "Epoch 2263, Loss: 0.004512529951171018, Final Batch Loss: 0.003000977449119091\n",
      "Epoch 2264, Loss: 0.018181323717726627, Final Batch Loss: 3.295535498182289e-05\n",
      "Epoch 2265, Loss: 0.0006391718925442547, Final Batch Loss: 2.75047350442037e-05\n",
      "Epoch 2266, Loss: 0.0005670331593137234, Final Batch Loss: 2.0301260519772768e-05\n",
      "Epoch 2267, Loss: 0.0004955041804350913, Final Batch Loss: 0.000122858677059412\n",
      "Epoch 2268, Loss: 0.0018753757649392355, Final Batch Loss: 5.133031663717702e-06\n",
      "Epoch 2269, Loss: 0.005756178020419611, Final Batch Loss: 1.0552897037996445e-05\n",
      "Epoch 2270, Loss: 0.0014746829874638934, Final Batch Loss: 0.00011491990881040692\n",
      "Epoch 2271, Loss: 0.0013432171763270162, Final Batch Loss: 0.00016241089906543493\n",
      "Epoch 2272, Loss: 0.002746298846489026, Final Batch Loss: 4.991844093638065e-07\n",
      "Epoch 2273, Loss: 0.0003831700214504963, Final Batch Loss: 2.0504432541201822e-05\n",
      "Epoch 2274, Loss: 0.0012336314539425075, Final Batch Loss: 0.00015214883023872972\n",
      "Epoch 2275, Loss: 0.0006254002934156233, Final Batch Loss: 9.983619975173497e-07\n",
      "Epoch 2276, Loss: 0.0053466817535081645, Final Batch Loss: 0.00030145590426400304\n",
      "Epoch 2277, Loss: 0.016657325699270586, Final Batch Loss: 8.797441114438698e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2278, Loss: 0.0025646612875789288, Final Batch Loss: 1.3028652574575972e-05\n",
      "Epoch 2279, Loss: 0.0005852373142261058, Final Batch Loss: 7.272513175848871e-05\n",
      "Epoch 2280, Loss: 0.0010149074569199001, Final Batch Loss: 2.162999771826435e-05\n",
      "Epoch 2281, Loss: 0.0035437946680758614, Final Batch Loss: 0.0022583187092095613\n",
      "Epoch 2282, Loss: 0.007382041880191537, Final Batch Loss: 0.00041711318772286177\n",
      "Epoch 2283, Loss: 0.003882792577314831, Final Batch Loss: 1.4000727787788492e-05\n",
      "Epoch 2284, Loss: 0.0012245368352523656, Final Batch Loss: 1.3774421859125141e-05\n",
      "Epoch 2285, Loss: 0.0005051872212789021, Final Batch Loss: 0.00017366220708936453\n",
      "Epoch 2286, Loss: 0.002634839569509495, Final Batch Loss: 7.069313869578764e-05\n",
      "Epoch 2287, Loss: 0.0022098975896369666, Final Batch Loss: 0.0011083825957030058\n",
      "Epoch 2288, Loss: 0.00147756975638913, Final Batch Loss: 0.00012287759454920888\n",
      "Epoch 2289, Loss: 0.00020204812972224317, Final Batch Loss: 2.253320417366922e-05\n",
      "Epoch 2290, Loss: 0.0005758938459621277, Final Batch Loss: 3.1279760150937364e-05\n",
      "Epoch 2291, Loss: 0.002899095430620946, Final Batch Loss: 0.0001790089881978929\n",
      "Epoch 2292, Loss: 0.0003778427835641196, Final Batch Loss: 0.0001347770303254947\n",
      "Epoch 2293, Loss: 0.0002172395113575476, Final Batch Loss: 3.258236347392085e-06\n",
      "Epoch 2294, Loss: 0.0018708298443925742, Final Batch Loss: 3.898821432812838e-06\n",
      "Epoch 2295, Loss: 0.0013365988870646106, Final Batch Loss: 0.0001059081478160806\n",
      "Epoch 2296, Loss: 0.0014525353180943057, Final Batch Loss: 0.00016130485164467245\n",
      "Epoch 2297, Loss: 0.003668093161010688, Final Batch Loss: 1.4404422188363242e-07\n",
      "Epoch 2298, Loss: 0.0005933794468546694, Final Batch Loss: 3.9932324398250785e-06\n",
      "Epoch 2299, Loss: 0.0020100424299016595, Final Batch Loss: 2.0720028260257095e-05\n",
      "Epoch 2300, Loss: 0.0008670411190792038, Final Batch Loss: 6.779957288927108e-07\n",
      "Epoch 2301, Loss: 0.006912996785104042, Final Batch Loss: 0.0007962852250784636\n",
      "Epoch 2302, Loss: 0.024904301744754775, Final Batch Loss: 0.010554983280599117\n",
      "Epoch 2303, Loss: 0.03645701129062218, Final Batch Loss: 4.7274475946323946e-05\n",
      "Epoch 2304, Loss: 0.0008267699317912047, Final Batch Loss: 6.970572485442972e-06\n",
      "Epoch 2305, Loss: 0.00023499854614783544, Final Batch Loss: 1.6247149687842466e-05\n",
      "Epoch 2306, Loss: 0.0110438040101144, Final Batch Loss: 5.989882265566848e-05\n",
      "Epoch 2307, Loss: 0.011881696339173686, Final Batch Loss: 1.6316565734086907e-06\n",
      "Epoch 2308, Loss: 0.001352325472225857, Final Batch Loss: 0.0005936833913438022\n",
      "Epoch 2309, Loss: 0.00057966615412397, Final Batch Loss: 8.766771202317614e-07\n",
      "Epoch 2310, Loss: 0.0010289876954630017, Final Batch Loss: 0.00013286307512316853\n",
      "Epoch 2311, Loss: 0.010383483007899486, Final Batch Loss: 0.00012940196029376239\n",
      "Epoch 2312, Loss: 0.0010065507849503774, Final Batch Loss: 5.304983278620057e-05\n",
      "Epoch 2313, Loss: 0.01893734620171017, Final Batch Loss: 2.733663859544322e-05\n",
      "Epoch 2314, Loss: 0.0014428375325223897, Final Batch Loss: 3.900980300386436e-05\n",
      "Epoch 2315, Loss: 0.0025117951445281506, Final Batch Loss: 0.00011597890261327848\n",
      "Epoch 2316, Loss: 0.0026623686935636215, Final Batch Loss: 0.00012031709047732875\n",
      "Epoch 2317, Loss: 0.0005571060391957872, Final Batch Loss: 0.0003779427206609398\n",
      "Epoch 2318, Loss: 0.004371101647848263, Final Batch Loss: 0.001281748409382999\n",
      "Epoch 2319, Loss: 0.0012416118934197584, Final Batch Loss: 3.682909664348699e-06\n",
      "Epoch 2320, Loss: 0.0013046080060803433, Final Batch Loss: 1.512417270532751e-06\n",
      "Epoch 2321, Loss: 0.0002501126919014496, Final Batch Loss: 1.002481712930603e-05\n",
      "Epoch 2322, Loss: 0.000703901417182351, Final Batch Loss: 1.312339099968085e-05\n",
      "Epoch 2323, Loss: 0.0012397810714901425, Final Batch Loss: 5.883049743715674e-05\n",
      "Epoch 2324, Loss: 0.002613559387100395, Final Batch Loss: 3.4441145544406027e-05\n",
      "Epoch 2325, Loss: 0.00160672151162089, Final Batch Loss: 1.0033332955572405e-06\n",
      "Epoch 2326, Loss: 0.005829005562191014, Final Batch Loss: 2.031975054705981e-05\n",
      "Epoch 2327, Loss: 0.004608231309248367, Final Batch Loss: 1.922760930028744e-05\n",
      "Epoch 2328, Loss: 0.0010488770894880872, Final Batch Loss: 0.00013255933299660683\n",
      "Epoch 2329, Loss: 0.001054269943779218, Final Batch Loss: 1.9344455722603016e-05\n",
      "Epoch 2330, Loss: 0.005799082173325587, Final Batch Loss: 0.0007294411770999432\n",
      "Epoch 2331, Loss: 0.012138775433413684, Final Batch Loss: 0.00039895562804304063\n",
      "Epoch 2332, Loss: 0.0025406182157894364, Final Batch Loss: 2.5086168534471653e-05\n",
      "Epoch 2333, Loss: 0.0013662106757692527, Final Batch Loss: 7.95247542555444e-05\n",
      "Epoch 2334, Loss: 0.010179872030903425, Final Batch Loss: 4.594505753630074e-07\n",
      "Epoch 2335, Loss: 0.0021597346931230277, Final Batch Loss: 0.0008463403210043907\n",
      "Epoch 2336, Loss: 0.005365162767702714, Final Batch Loss: 0.004741793964058161\n",
      "Epoch 2337, Loss: 0.0012262834170542192, Final Batch Loss: 9.945470083039254e-06\n",
      "Epoch 2338, Loss: 0.011395742651075125, Final Batch Loss: 3.8647751352982596e-05\n",
      "Epoch 2339, Loss: 0.01802682989364257, Final Batch Loss: 0.0008037097286432981\n",
      "Epoch 2340, Loss: 0.004187141836155206, Final Batch Loss: 1.685590177658014e-05\n",
      "Epoch 2341, Loss: 0.0010327224299544469, Final Batch Loss: 9.368889004690573e-05\n",
      "Epoch 2342, Loss: 0.02323753829841735, Final Batch Loss: 2.2735657694283873e-05\n",
      "Epoch 2343, Loss: 0.011757459025602657, Final Batch Loss: 2.1730372736783465e-06\n",
      "Epoch 2344, Loss: 0.00703777089711366, Final Batch Loss: 1.4176176591718104e-05\n",
      "Epoch 2345, Loss: 0.0016606199060333893, Final Batch Loss: 4.757429996971041e-05\n",
      "Epoch 2346, Loss: 0.000669402455969248, Final Batch Loss: 9.739623055793345e-05\n",
      "Epoch 2347, Loss: 0.004782839309200426, Final Batch Loss: 2.1854998522030655e-07\n",
      "Epoch 2348, Loss: 0.0009757320003700443, Final Batch Loss: 0.00039040669798851013\n",
      "Epoch 2349, Loss: 0.003183855747920461, Final Batch Loss: 3.272741741966456e-05\n",
      "Epoch 2350, Loss: 0.0005149748212716077, Final Batch Loss: 9.235523612005636e-05\n",
      "Epoch 2351, Loss: 0.0017837368900472939, Final Batch Loss: 6.498379207187099e-06\n",
      "Epoch 2352, Loss: 0.0003974805695179384, Final Batch Loss: 0.00015201255155261606\n",
      "Epoch 2353, Loss: 0.0008578949345974252, Final Batch Loss: 0.0003758176462724805\n",
      "Epoch 2354, Loss: 0.0009780901273188647, Final Batch Loss: 5.971152495476417e-05\n",
      "Epoch 2355, Loss: 0.00044717229502566624, Final Batch Loss: 2.1103138351463713e-05\n",
      "Epoch 2356, Loss: 0.0004107247732463293, Final Batch Loss: 9.046623745234683e-06\n",
      "Epoch 2357, Loss: 0.0016139337751610583, Final Batch Loss: 3.052118017876637e-06\n",
      "Epoch 2358, Loss: 0.005053780856542289, Final Batch Loss: 0.004397143144160509\n",
      "Epoch 2359, Loss: 0.0011337385294609703, Final Batch Loss: 0.00031323128496296704\n",
      "Epoch 2360, Loss: 0.0025472486631770153, Final Batch Loss: 3.80305755243171e-05\n",
      "Epoch 2361, Loss: 0.0010005352814914659, Final Batch Loss: 4.251911013852805e-05\n",
      "Epoch 2362, Loss: 0.0025247175653930753, Final Batch Loss: 0.000820786866825074\n",
      "Epoch 2363, Loss: 0.002217402226960985, Final Batch Loss: 7.079954229993746e-06\n",
      "Epoch 2364, Loss: 0.0018450602514832326, Final Batch Loss: 1.514949445891034e-07\n",
      "Epoch 2365, Loss: 0.0019612521573435515, Final Batch Loss: 5.2226241677999496e-05\n",
      "Epoch 2366, Loss: 0.0013367073770496063, Final Batch Loss: 0.00014704381464980543\n",
      "Epoch 2367, Loss: 0.000727592663224641, Final Batch Loss: 4.283815997041529e-06\n",
      "Epoch 2368, Loss: 0.0008194554834517476, Final Batch Loss: 7.226958587125409e-07\n",
      "Epoch 2369, Loss: 0.0006025187267368892, Final Batch Loss: 9.23018014873378e-05\n",
      "Epoch 2370, Loss: 0.0008383377462450881, Final Batch Loss: 0.00019390865054447204\n",
      "Epoch 2371, Loss: 0.00058656207875174, Final Batch Loss: 0.0003212331503164023\n",
      "Epoch 2372, Loss: 0.00018931641443487024, Final Batch Loss: 0.00014429613656830043\n",
      "Epoch 2373, Loss: 0.06525885520568409, Final Batch Loss: 0.06517786532640457\n",
      "Epoch 2374, Loss: 0.0034622388557181694, Final Batch Loss: 0.002489405917003751\n",
      "Epoch 2375, Loss: 0.0004973463219357654, Final Batch Loss: 3.468766954028979e-05\n",
      "Epoch 2376, Loss: 0.0068412561595323496, Final Batch Loss: 3.2662843295838684e-05\n",
      "Epoch 2377, Loss: 0.002150954644093872, Final Batch Loss: 0.0005967743927612901\n",
      "Epoch 2378, Loss: 0.003454620034972322, Final Batch Loss: 2.2074311345932074e-05\n",
      "Epoch 2379, Loss: 0.0037758345188194653, Final Batch Loss: 2.82553428405663e-05\n",
      "Epoch 2380, Loss: 0.0044923246850885334, Final Batch Loss: 1.0550286788202357e-05\n",
      "Epoch 2381, Loss: 0.00394498760215356, Final Batch Loss: 3.277900759712793e-05\n",
      "Epoch 2382, Loss: 0.0013348917382245418, Final Batch Loss: 4.214184809825383e-05\n",
      "Epoch 2383, Loss: 0.0008545324544684263, Final Batch Loss: 1.890948806249071e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2384, Loss: 0.0017366743668389972, Final Batch Loss: 4.71710336569231e-05\n",
      "Epoch 2385, Loss: 0.0017576132486283313, Final Batch Loss: 3.770808325498365e-05\n",
      "Epoch 2386, Loss: 0.0010486199462320656, Final Batch Loss: 0.00014428187569137663\n",
      "Epoch 2387, Loss: 0.0018409955937386258, Final Batch Loss: 1.7809723431128077e-05\n",
      "Epoch 2388, Loss: 0.006863466260256246, Final Batch Loss: 0.004830143880099058\n",
      "Epoch 2389, Loss: 0.0005166066219999266, Final Batch Loss: 7.450569228240056e-08\n",
      "Epoch 2390, Loss: 0.002243241260657669, Final Batch Loss: 1.874032932391856e-05\n",
      "Epoch 2391, Loss: 0.0004810798318430898, Final Batch Loss: 1.1052598893002141e-05\n",
      "Epoch 2392, Loss: 0.001678724009252619, Final Batch Loss: 0.0001458582264604047\n",
      "Epoch 2393, Loss: 0.005492340816999786, Final Batch Loss: 0.0012701906962320209\n",
      "Epoch 2394, Loss: 0.0004209694598102942, Final Batch Loss: 0.00016993505414575338\n",
      "Epoch 2395, Loss: 0.0006145986535557313, Final Batch Loss: 2.6248000722262077e-05\n",
      "Epoch 2396, Loss: 0.0011195251935021133, Final Batch Loss: 3.8246056988100463e-07\n",
      "Epoch 2397, Loss: 0.001627976816962473, Final Batch Loss: 3.490727613097988e-05\n",
      "Epoch 2398, Loss: 0.021057628049068633, Final Batch Loss: 4.967053435223079e-09\n",
      "Epoch 2399, Loss: 0.0006746181898051873, Final Batch Loss: 0.00016930943820625544\n",
      "Epoch 2400, Loss: 0.002329750727184887, Final Batch Loss: 1.5894543992089893e-07\n",
      "Epoch 2401, Loss: 0.00018684084307096782, Final Batch Loss: 1.4429056136577856e-06\n",
      "Epoch 2402, Loss: 0.0006483269407908665, Final Batch Loss: 2.019551357079763e-05\n",
      "Epoch 2403, Loss: 0.001241934412973933, Final Batch Loss: 4.306253686081618e-06\n",
      "Epoch 2404, Loss: 0.0009530998199238638, Final Batch Loss: 5.438891435005644e-07\n",
      "Epoch 2405, Loss: 0.024581583612189206, Final Batch Loss: 3.432042603890295e-06\n",
      "Epoch 2406, Loss: 0.0432396493088163, Final Batch Loss: 4.259914203430526e-05\n",
      "Epoch 2407, Loss: 0.0013842755070072599, Final Batch Loss: 0.0001114073020289652\n",
      "Epoch 2408, Loss: 0.0005603860290648299, Final Batch Loss: 2.5041743356268853e-05\n",
      "Epoch 2409, Loss: 0.025268531717301812, Final Batch Loss: 2.8692120395135134e-05\n",
      "Epoch 2410, Loss: 0.015947943508649587, Final Batch Loss: 1.874998702078301e-06\n",
      "Epoch 2411, Loss: 0.0012636811197808129, Final Batch Loss: 2.880832653318066e-06\n",
      "Epoch 2412, Loss: 0.0032016461354942294, Final Batch Loss: 1.2254877219675109e-05\n",
      "Epoch 2413, Loss: 0.034451362119853, Final Batch Loss: 7.12762357579777e-07\n",
      "Epoch 2414, Loss: 0.05036291819669714, Final Batch Loss: 2.769261300272774e-05\n",
      "Epoch 2415, Loss: 0.0009398436104675056, Final Batch Loss: 7.913537046988495e-06\n",
      "Epoch 2416, Loss: 0.0077452732948586345, Final Batch Loss: 0.005540899466723204\n",
      "Epoch 2417, Loss: 0.00177067400636588, Final Batch Loss: 9.856291399046313e-06\n",
      "Epoch 2418, Loss: 0.0015094789559952915, Final Batch Loss: 0.0002871725882869214\n",
      "Epoch 2419, Loss: 0.0006503947879537009, Final Batch Loss: 6.790452607674524e-05\n",
      "Epoch 2420, Loss: 0.002009158684813883, Final Batch Loss: 0.0003500352322589606\n",
      "Epoch 2421, Loss: 0.0011880138590640854, Final Batch Loss: 4.809743040823378e-05\n",
      "Epoch 2422, Loss: 0.0012364689255264238, Final Batch Loss: 0.0007512735319323838\n",
      "Epoch 2423, Loss: 0.0020878828727290966, Final Batch Loss: 0.0012769600143656135\n",
      "Epoch 2424, Loss: 0.0024620141557534225, Final Batch Loss: 3.3928816264960915e-05\n",
      "Epoch 2425, Loss: 0.0019105428265504543, Final Batch Loss: 1.316267628226342e-07\n",
      "Epoch 2426, Loss: 0.0006940080675121862, Final Batch Loss: 1.7332829884253442e-05\n",
      "Epoch 2427, Loss: 0.0016691586024535354, Final Batch Loss: 6.0382280935300514e-05\n",
      "Epoch 2428, Loss: 0.001613439888387802, Final Batch Loss: 0.0013965582475066185\n",
      "Epoch 2429, Loss: 0.0006458236950948049, Final Batch Loss: 2.605169584057876e-06\n",
      "Epoch 2430, Loss: 0.0003607515129715466, Final Batch Loss: 2.903133690779214e-06\n",
      "Epoch 2431, Loss: 0.0028050884471326754, Final Batch Loss: 6.283267453000008e-07\n",
      "Epoch 2432, Loss: 0.0011915275572391693, Final Batch Loss: 0.0006064308690838516\n",
      "Epoch 2433, Loss: 0.0002892515367420856, Final Batch Loss: 3.618518894654699e-05\n",
      "Epoch 2434, Loss: 0.0023611419237568043, Final Batch Loss: 4.099435682292096e-05\n",
      "Epoch 2435, Loss: 0.0009359195805700438, Final Batch Loss: 1.7906417269841768e-05\n",
      "Epoch 2436, Loss: 0.0003924244210793404, Final Batch Loss: 1.8665583411348052e-05\n",
      "Epoch 2437, Loss: 0.001228072733283625, Final Batch Loss: 9.38190714805387e-05\n",
      "Epoch 2438, Loss: 0.000697758536261972, Final Batch Loss: 0.0001949756551766768\n",
      "Epoch 2439, Loss: 0.02038255500156083, Final Batch Loss: 0.00024917928385548294\n",
      "Epoch 2440, Loss: 0.0006327623659672099, Final Batch Loss: 0.0003525861829984933\n",
      "Epoch 2441, Loss: 0.00011410954448365374, Final Batch Loss: 7.80187747295713e-06\n",
      "Epoch 2442, Loss: 0.02699424714955967, Final Batch Loss: 0.0007615878712385893\n",
      "Epoch 2443, Loss: 0.002320196421351284, Final Batch Loss: 0.0005460105021484196\n",
      "Epoch 2444, Loss: 0.0032119012903422117, Final Batch Loss: 0.0008044231217354536\n",
      "Epoch 2445, Loss: 0.0017951183543729599, Final Batch Loss: 1.1175858816159234e-07\n",
      "Epoch 2446, Loss: 0.00036252219979360234, Final Batch Loss: 8.800667274044827e-05\n",
      "Epoch 2447, Loss: 0.001154214176494861, Final Batch Loss: 0.0003029493091162294\n",
      "Epoch 2448, Loss: 0.00042673050484154373, Final Batch Loss: 3.41578597726766e-05\n",
      "Epoch 2449, Loss: 0.00037549443732132204, Final Batch Loss: 8.999947021948174e-05\n",
      "Epoch 2450, Loss: 0.007445168360391108, Final Batch Loss: 1.1269840797467623e-05\n",
      "Epoch 2451, Loss: 0.0002373750476181158, Final Batch Loss: 7.177341103670187e-07\n",
      "Epoch 2452, Loss: 0.008919495510781417, Final Batch Loss: 0.008730092085897923\n",
      "Epoch 2453, Loss: 0.008353284468284983, Final Batch Loss: 7.996382009878289e-06\n",
      "Epoch 2454, Loss: 0.00372270135267172, Final Batch Loss: 0.0003439958381932229\n",
      "Epoch 2455, Loss: 0.002570839968029759, Final Batch Loss: 0.0003406817268114537\n",
      "Epoch 2456, Loss: 0.00259566149497914, Final Batch Loss: 5.530262114916695e-06\n",
      "Epoch 2457, Loss: 0.011281552481477775, Final Batch Loss: 3.1067654617800144e-06\n",
      "Epoch 2458, Loss: 0.001524484829587891, Final Batch Loss: 6.7069836404698435e-06\n",
      "Epoch 2459, Loss: 0.0005373105759645114, Final Batch Loss: 0.00013352003588806838\n",
      "Epoch 2460, Loss: 0.001379111557412216, Final Batch Loss: 1.3982147493152297e-06\n",
      "Epoch 2461, Loss: 0.0015340486702370981, Final Batch Loss: 7.067521892167861e-06\n",
      "Epoch 2462, Loss: 0.0013674937436007895, Final Batch Loss: 1.0342344467062503e-05\n",
      "Epoch 2463, Loss: 0.0012613320547529838, Final Batch Loss: 8.09625532838254e-07\n",
      "Epoch 2464, Loss: 0.0029576046799775213, Final Batch Loss: 0.001428936026059091\n",
      "Epoch 2465, Loss: 0.0003565612832971965, Final Batch Loss: 1.715590951789636e-05\n",
      "Epoch 2466, Loss: 0.006320978020085022, Final Batch Loss: 1.0785763151943684e-05\n",
      "Epoch 2467, Loss: 0.0003028434184670914, Final Batch Loss: 7.061631913529709e-05\n",
      "Epoch 2468, Loss: 0.0004928251437377185, Final Batch Loss: 0.00013939524069428444\n",
      "Epoch 2469, Loss: 0.0017668544633124839, Final Batch Loss: 0.00010412862320663407\n",
      "Epoch 2470, Loss: 0.0014538921920230763, Final Batch Loss: 1.7384683914656307e-08\n",
      "Epoch 2471, Loss: 0.0015968503794283606, Final Batch Loss: 9.82634628599044e-06\n",
      "Epoch 2472, Loss: 0.0026900210043550032, Final Batch Loss: 0.0013241609558463097\n",
      "Epoch 2473, Loss: 0.002686407358851284, Final Batch Loss: 0.0008789959247224033\n",
      "Epoch 2474, Loss: 0.02023421393460012, Final Batch Loss: 2.89559338852996e-05\n",
      "Epoch 2475, Loss: 0.0019407354872136295, Final Batch Loss: 4.718697610428535e-08\n",
      "Epoch 2476, Loss: 0.0015394651600217912, Final Batch Loss: 0.00035883847158402205\n",
      "Epoch 2477, Loss: 0.00019880272836303448, Final Batch Loss: 2.45868676529426e-07\n",
      "Epoch 2478, Loss: 0.001178584363515256, Final Batch Loss: 0.0007346512866206467\n",
      "Epoch 2479, Loss: 0.00024795365311547357, Final Batch Loss: 1.837804575188784e-07\n",
      "Epoch 2480, Loss: 0.0005407538087638386, Final Batch Loss: 0.0002314195007784292\n",
      "Epoch 2481, Loss: 0.0020519110440773147, Final Batch Loss: 1.4702128510180046e-06\n",
      "Epoch 2482, Loss: 0.015432791534330192, Final Batch Loss: 1.0927491445045234e-07\n",
      "Epoch 2483, Loss: 0.001173584514617687, Final Batch Loss: 3.4626729757292196e-05\n",
      "Epoch 2484, Loss: 0.0015956924071360845, Final Batch Loss: 3.822155485977419e-05\n",
      "Epoch 2485, Loss: 0.001109776106886784, Final Batch Loss: 2.053789785350091e-06\n",
      "Epoch 2486, Loss: 0.0023293038248084486, Final Batch Loss: 0.0011830594157800078\n",
      "Epoch 2487, Loss: 0.029343525152398797, Final Batch Loss: 1.3131561900081579e-05\n",
      "Epoch 2488, Loss: 0.005964408523141174, Final Batch Loss: 3.187825495842844e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2489, Loss: 0.000488340127049014, Final Batch Loss: 6.755144568160176e-07\n",
      "Epoch 2490, Loss: 0.0011325039413350169, Final Batch Loss: 7.899537013145164e-05\n",
      "Epoch 2491, Loss: 0.0012872654097009217, Final Batch Loss: 3.9611120882909745e-05\n",
      "Epoch 2492, Loss: 0.0018666477626538835, Final Batch Loss: 0.0006069240625947714\n",
      "Epoch 2493, Loss: 0.0009769967674628788, Final Batch Loss: 1.44041598559852e-06\n",
      "Epoch 2494, Loss: 0.00026571532544039655, Final Batch Loss: 2.059390135400463e-05\n",
      "Epoch 2495, Loss: 0.0003873454152198974, Final Batch Loss: 0.00017542095156386495\n",
      "Epoch 2496, Loss: 0.0002954082685846515, Final Batch Loss: 2.4611028948129388e-06\n",
      "Epoch 2497, Loss: 0.0003602438225698279, Final Batch Loss: 3.6058115711057326e-06\n",
      "Epoch 2498, Loss: 0.0002050916618827614, Final Batch Loss: 6.064251010684529e-06\n",
      "Epoch 2499, Loss: 0.0028618413571166457, Final Batch Loss: 1.0007644050347153e-05\n",
      "Epoch 2500, Loss: 0.010568746593207834, Final Batch Loss: 3.307975248389994e-06\n",
      "Epoch 2501, Loss: 0.0015447909281647298, Final Batch Loss: 4.0408005588687956e-05\n",
      "Epoch 2502, Loss: 0.0034911996190203354, Final Batch Loss: 0.002952949143946171\n",
      "Epoch 2503, Loss: 0.0026966094847011846, Final Batch Loss: 4.000229455414228e-05\n",
      "Epoch 2504, Loss: 0.002839989099811646, Final Batch Loss: 0.0001279960124520585\n",
      "Epoch 2505, Loss: 0.0029218766940175556, Final Batch Loss: 0.00012037841224810109\n",
      "Epoch 2506, Loss: 0.0006351624851959059, Final Batch Loss: 2.5201376047334634e-05\n",
      "Epoch 2507, Loss: 0.0010410077808913343, Final Batch Loss: 1.192090124391143e-07\n",
      "Epoch 2508, Loss: 0.0017181330113089643, Final Batch Loss: 0.0009518808801658452\n",
      "Epoch 2509, Loss: 0.00022882717348693404, Final Batch Loss: 2.1572444893536158e-05\n",
      "Epoch 2510, Loss: 0.025413699723685568, Final Batch Loss: 9.956586836779024e-06\n",
      "Epoch 2511, Loss: 0.0001444372937839944, Final Batch Loss: 3.297947841929272e-06\n",
      "Epoch 2512, Loss: 0.012500882518452272, Final Batch Loss: 0.006802478805184364\n",
      "Epoch 2513, Loss: 0.0022966756241658004, Final Batch Loss: 0.001932530663907528\n",
      "Epoch 2514, Loss: 0.020344269380075275, Final Batch Loss: 9.651665095589124e-06\n",
      "Epoch 2515, Loss: 0.008615323971753241, Final Batch Loss: 0.002628960646688938\n",
      "Epoch 2516, Loss: 0.0006896926975059614, Final Batch Loss: 7.417184406222077e-06\n",
      "Epoch 2517, Loss: 0.0008281758346129209, Final Batch Loss: 8.044976857490838e-05\n",
      "Epoch 2518, Loss: 0.0002887817140617699, Final Batch Loss: 1.0283011761202943e-05\n",
      "Epoch 2519, Loss: 0.0003315009071229724, Final Batch Loss: 1.5713003449491225e-05\n",
      "Epoch 2520, Loss: 0.0004218392250550096, Final Batch Loss: 1.1828257811430376e-05\n",
      "Epoch 2521, Loss: 0.0007316052870010026, Final Batch Loss: 4.8121088184416294e-05\n",
      "Epoch 2522, Loss: 0.000708467916410882, Final Batch Loss: 1.75827881321311e-06\n",
      "Epoch 2523, Loss: 0.00020465742352371308, Final Batch Loss: 3.725280066646519e-07\n",
      "Epoch 2524, Loss: 0.00043090954568469897, Final Batch Loss: 2.304499503225088e-05\n",
      "Epoch 2525, Loss: 0.015806411238372675, Final Batch Loss: 4.5701806811848655e-05\n",
      "Epoch 2526, Loss: 0.00016931642858253326, Final Batch Loss: 3.3177402656292543e-06\n",
      "Epoch 2527, Loss: 0.014081998821893649, Final Batch Loss: 7.75479475123575e-06\n",
      "Epoch 2528, Loss: 0.0018839269469026476, Final Batch Loss: 0.00018143054330721498\n",
      "Epoch 2529, Loss: 0.0005342192671378143, Final Batch Loss: 7.920899224700406e-05\n",
      "Epoch 2530, Loss: 0.041171221710101236, Final Batch Loss: 6.377520185196772e-05\n",
      "Epoch 2531, Loss: 0.01685388640265728, Final Batch Loss: 2.781534362839011e-07\n",
      "Epoch 2532, Loss: 0.0014181528476910898, Final Batch Loss: 6.501337338704616e-06\n",
      "Epoch 2533, Loss: 0.0241510595951695, Final Batch Loss: 0.00011617466225288808\n",
      "Epoch 2534, Loss: 0.03315364876470994, Final Batch Loss: 0.008993410505354404\n",
      "Epoch 2535, Loss: 0.001167369695394882, Final Batch Loss: 1.765023080224637e-05\n",
      "Epoch 2536, Loss: 0.007805606818692468, Final Batch Loss: 1.4858352187729906e-05\n",
      "Epoch 2537, Loss: 0.028384209526393533, Final Batch Loss: 5.475510533869965e-06\n",
      "Epoch 2538, Loss: 0.0007691617046674537, Final Batch Loss: 2.2600026738928136e-07\n",
      "Epoch 2539, Loss: 0.0013323017167294893, Final Batch Loss: 3.422142299314146e-06\n",
      "Epoch 2540, Loss: 0.004147392774484615, Final Batch Loss: 7.365033980022417e-06\n",
      "Epoch 2541, Loss: 0.011391968789723705, Final Batch Loss: 8.692182404956839e-07\n",
      "Epoch 2542, Loss: 0.0011539796469151042, Final Batch Loss: 0.0001823691272875294\n",
      "Epoch 2543, Loss: 0.0020982029891456477, Final Batch Loss: 0.0005130685167387128\n",
      "Epoch 2544, Loss: 0.004844187853450421, Final Batch Loss: 0.0026169270277023315\n",
      "Epoch 2545, Loss: 0.00751915764703881, Final Batch Loss: 0.00031208136351779103\n",
      "Epoch 2546, Loss: 0.0005519630341837001, Final Batch Loss: 5.21538993325521e-07\n",
      "Epoch 2547, Loss: 0.001988275173061993, Final Batch Loss: 7.853602437535301e-05\n",
      "Epoch 2548, Loss: 0.002023041910433676, Final Batch Loss: 0.0010115945478901267\n",
      "Epoch 2549, Loss: 0.0012245134603290353, Final Batch Loss: 6.286332063609734e-05\n",
      "Epoch 2550, Loss: 0.0055985024373512715, Final Batch Loss: 0.00017929742170963436\n",
      "Epoch 2551, Loss: 0.0012934225233038887, Final Batch Loss: 0.00012980362225789577\n",
      "Epoch 2552, Loss: 0.0012772832997143269, Final Batch Loss: 0.0004964349791407585\n",
      "Epoch 2553, Loss: 0.003304439269413706, Final Batch Loss: 0.0024594326969236135\n",
      "Epoch 2554, Loss: 0.001871294116426725, Final Batch Loss: 0.0013330900110304356\n",
      "Epoch 2555, Loss: 0.0005173447789275087, Final Batch Loss: 0.00019970255380030721\n",
      "Epoch 2556, Loss: 0.004470094165071714, Final Batch Loss: 1.1175848158018198e-07\n",
      "Epoch 2557, Loss: 0.005814344931422966, Final Batch Loss: 0.0038800975307822227\n",
      "Epoch 2558, Loss: 0.018232758269732585, Final Batch Loss: 5.889046587981284e-05\n",
      "Epoch 2559, Loss: 0.0019470699808152858, Final Batch Loss: 0.00017182657029479742\n",
      "Epoch 2560, Loss: 0.007408205681713298, Final Batch Loss: 0.004989039618521929\n",
      "Epoch 2561, Loss: 0.0012304532210691832, Final Batch Loss: 0.001023390213958919\n",
      "Epoch 2562, Loss: 0.0005805699075835946, Final Batch Loss: 1.8451902406013687e-06\n",
      "Epoch 2563, Loss: 0.002605296801448276, Final Batch Loss: 9.305177627538797e-06\n",
      "Epoch 2564, Loss: 0.0009919799790623074, Final Batch Loss: 6.091665909480071e-06\n",
      "Epoch 2565, Loss: 0.00027969941470473714, Final Batch Loss: 2.197876483478467e-06\n",
      "Epoch 2566, Loss: 0.0002555688161010039, Final Batch Loss: 1.088776934921043e-05\n",
      "Epoch 2567, Loss: 0.0066581073915585876, Final Batch Loss: 0.00017513234342914075\n",
      "Epoch 2568, Loss: 0.0002834880074260582, Final Batch Loss: 4.273916147212731e-06\n",
      "Epoch 2569, Loss: 0.0018136497674277052, Final Batch Loss: 6.603782094316557e-05\n",
      "Epoch 2570, Loss: 0.0003812485858816217, Final Batch Loss: 2.5082456431846367e-06\n",
      "Epoch 2571, Loss: 0.0011046472793623252, Final Batch Loss: 2.3046561636874685e-06\n",
      "Epoch 2572, Loss: 0.0017401405348067556, Final Batch Loss: 3.7252888773764425e-08\n",
      "Epoch 2573, Loss: 0.002017519436776638, Final Batch Loss: 0.00042919142288155854\n",
      "Epoch 2574, Loss: 0.0002280358612551936, Final Batch Loss: 1.1240267667744774e-05\n",
      "Epoch 2575, Loss: 0.0016351240410585888, Final Batch Loss: 6.880526780150831e-05\n",
      "Epoch 2576, Loss: 0.00018488638670532964, Final Batch Loss: 2.8863527404610068e-05\n",
      "Epoch 2577, Loss: 0.0002896365294873249, Final Batch Loss: 8.581882138969377e-05\n",
      "Epoch 2578, Loss: 0.0008287243917948217, Final Batch Loss: 1.134912690758938e-05\n",
      "Epoch 2579, Loss: 0.00034058961318805814, Final Batch Loss: 3.776052835746668e-05\n",
      "Epoch 2580, Loss: 0.0015737292331436947, Final Batch Loss: 6.531616350002878e-07\n",
      "Epoch 2581, Loss: 0.0008828937116049929, Final Batch Loss: 4.510934013524093e-05\n",
      "Epoch 2582, Loss: 0.0007736172589325463, Final Batch Loss: 4.7186990315140065e-08\n",
      "Epoch 2583, Loss: 0.0002834863999510162, Final Batch Loss: 8.59284284615569e-07\n",
      "Epoch 2584, Loss: 0.0009020686748044682, Final Batch Loss: 1.3879468497179914e-05\n",
      "Epoch 2585, Loss: 0.008764127750055195, Final Batch Loss: 7.214156084955903e-06\n",
      "Epoch 2586, Loss: 0.0011582407362311642, Final Batch Loss: 7.972059847816126e-07\n",
      "Epoch 2587, Loss: 0.0002713729209062876, Final Batch Loss: 0.00011327239917591214\n",
      "Epoch 2588, Loss: 0.006730498367687687, Final Batch Loss: 7.489740528399125e-05\n",
      "Epoch 2589, Loss: 0.0014857906789984554, Final Batch Loss: 0.00015226533287204802\n",
      "Epoch 2590, Loss: 0.019518505594533053, Final Batch Loss: 4.23706769652199e-05\n",
      "Epoch 2591, Loss: 0.0013699895062018186, Final Batch Loss: 0.00023303774651139975\n",
      "Epoch 2592, Loss: 0.00025276606152146996, Final Batch Loss: 2.051294131888426e-06\n",
      "Epoch 2593, Loss: 0.0006743351941622677, Final Batch Loss: 1.7980373741011135e-06\n",
      "Epoch 2594, Loss: 0.001545048249681713, Final Batch Loss: 0.0008358035702258348\n",
      "Epoch 2595, Loss: 0.0050349395014563925, Final Batch Loss: 1.0537470188864972e-05\n",
      "Epoch 2596, Loss: 0.00043687077661047624, Final Batch Loss: 4.0729602801548026e-07\n",
      "Epoch 2597, Loss: 0.0004502108861288434, Final Batch Loss: 3.4047700410155812e-06\n",
      "Epoch 2598, Loss: 0.0006778581482649315, Final Batch Loss: 0.0004249447083566338\n",
      "Epoch 2599, Loss: 0.0013830770694767125, Final Batch Loss: 0.00015769826131872833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2600, Loss: 0.0003926606150344014, Final Batch Loss: 1.3059885532129556e-05\n",
      "Epoch 2601, Loss: 0.0027228137651036377, Final Batch Loss: 0.0022830984089523554\n",
      "Epoch 2602, Loss: 0.0015751363729350487, Final Batch Loss: 1.2740359807139612e-06\n",
      "Epoch 2603, Loss: 0.0007268597169840518, Final Batch Loss: 9.189042060597785e-08\n",
      "Epoch 2604, Loss: 0.012091908312868327, Final Batch Loss: 0.000959600496571511\n",
      "Epoch 2605, Loss: 0.0009906959837735485, Final Batch Loss: 2.287254346811096e-06\n",
      "Epoch 2606, Loss: 0.0003098023844358977, Final Batch Loss: 1.0570769518380985e-05\n",
      "Epoch 2607, Loss: 0.002225918584372266, Final Batch Loss: 2.7180727556697093e-05\n",
      "Epoch 2608, Loss: 0.00015694466992499656, Final Batch Loss: 4.581924713420449e-06\n",
      "Epoch 2609, Loss: 0.0007378204209089745, Final Batch Loss: 0.00010962876694975421\n",
      "Epoch 2610, Loss: 0.0002602829918032512, Final Batch Loss: 1.3134546861692797e-05\n",
      "Epoch 2611, Loss: 0.002015509824559558, Final Batch Loss: 5.347962724044919e-05\n",
      "Epoch 2612, Loss: 0.0005946586729805858, Final Batch Loss: 2.0289558051445056e-06\n",
      "Epoch 2613, Loss: 0.0005932635281169496, Final Batch Loss: 5.232384410192026e-06\n",
      "Epoch 2614, Loss: 0.001144889978604624, Final Batch Loss: 0.000282676744973287\n",
      "Epoch 2615, Loss: 0.05331651206188326, Final Batch Loss: 4.825233645533444e-06\n",
      "Epoch 2616, Loss: 0.012801475050466138, Final Batch Loss: 1.4901131351052754e-07\n",
      "Epoch 2617, Loss: 0.011613949201148444, Final Batch Loss: 1.9371424286873662e-07\n",
      "Epoch 2618, Loss: 0.0005298707401379943, Final Batch Loss: 0.0001777645229594782\n",
      "Epoch 2619, Loss: 0.0018636310153397062, Final Batch Loss: 3.144013362543774e-06\n",
      "Epoch 2620, Loss: 0.00408401406093617, Final Batch Loss: 7.728228956693783e-05\n",
      "Epoch 2621, Loss: 0.0014981755084590986, Final Batch Loss: 0.000279670231975615\n",
      "Epoch 2622, Loss: 0.0007023604507594428, Final Batch Loss: 2.431332632113481e-06\n",
      "Epoch 2623, Loss: 0.001842176410718821, Final Batch Loss: 5.585170583799481e-06\n",
      "Epoch 2624, Loss: 0.0002544969602240599, Final Batch Loss: 1.1774815902754199e-05\n",
      "Epoch 2625, Loss: 0.0010881378766498528, Final Batch Loss: 9.656749170972034e-05\n",
      "Epoch 2626, Loss: 0.0003746609245354193, Final Batch Loss: 8.159567187249195e-06\n",
      "Epoch 2627, Loss: 0.0024637526278752375, Final Batch Loss: 1.6639597788525862e-07\n",
      "Epoch 2628, Loss: 0.0004512063779316122, Final Batch Loss: 5.21536151154578e-07\n",
      "Epoch 2629, Loss: 0.0015185217621365155, Final Batch Loss: 1.6663821043039206e-06\n",
      "Epoch 2630, Loss: 0.001363605303311033, Final Batch Loss: 8.344492812284443e-07\n",
      "Epoch 2631, Loss: 0.0015682756366004469, Final Batch Loss: 2.2713311409461312e-05\n",
      "Epoch 2632, Loss: 0.006547579767357092, Final Batch Loss: 0.00026280811289325356\n",
      "Epoch 2633, Loss: 0.0002491882668209655, Final Batch Loss: 1.7259980040762457e-06\n",
      "Epoch 2634, Loss: 0.00017888232865459486, Final Batch Loss: 1.216925369362798e-07\n",
      "Epoch 2635, Loss: 0.0010267527013638755, Final Batch Loss: 0.00026324574719183147\n",
      "Epoch 2636, Loss: 0.0020206298941047862, Final Batch Loss: 0.0004321240121498704\n",
      "Epoch 2637, Loss: 0.0008044936676014913, Final Batch Loss: 3.461753294686787e-06\n",
      "Epoch 2638, Loss: 0.0013039348405072815, Final Batch Loss: 9.948004844773095e-06\n",
      "Epoch 2639, Loss: 0.0015433195148943923, Final Batch Loss: 0.0010838115122169256\n",
      "Epoch 2640, Loss: 0.0027070479845860973, Final Batch Loss: 0.00175138667691499\n",
      "Epoch 2641, Loss: 0.0014426344350795262, Final Batch Loss: 0.00010512860171729699\n",
      "Epoch 2642, Loss: 0.0008573632821935462, Final Batch Loss: 0.0007060202769935131\n",
      "Epoch 2643, Loss: 0.001142247340794711, Final Batch Loss: 0.00014230354281608015\n",
      "Epoch 2644, Loss: 0.00022456464967035572, Final Batch Loss: 6.8814674705208745e-06\n",
      "Epoch 2645, Loss: 0.0015664756137994118, Final Batch Loss: 8.815361798042431e-05\n",
      "Epoch 2646, Loss: 0.0005483508314227947, Final Batch Loss: 3.1166739518084796e-06\n",
      "Epoch 2647, Loss: 0.0008556504972148105, Final Batch Loss: 2.9749979148618877e-05\n",
      "Epoch 2648, Loss: 0.0001462443024138338, Final Batch Loss: 4.849784090765752e-05\n",
      "Epoch 2649, Loss: 0.0004801444520126097, Final Batch Loss: 2.4327455321326852e-05\n",
      "Epoch 2650, Loss: 5.986984137962281e-05, Final Batch Loss: 6.25844904789119e-07\n",
      "Epoch 2651, Loss: 0.0016994357501971535, Final Batch Loss: 9.970932296710089e-05\n",
      "Epoch 2652, Loss: 0.0007302594531211071, Final Batch Loss: 3.793010546360165e-05\n",
      "Epoch 2653, Loss: 0.0005077650283737967, Final Batch Loss: 1.2243643823239836e-06\n",
      "Epoch 2654, Loss: 0.0006330367648388346, Final Batch Loss: 0.0004379414895083755\n",
      "Epoch 2655, Loss: 0.00014040173937246436, Final Batch Loss: 0.0\n",
      "Epoch 2656, Loss: 0.0004831531541640288, Final Batch Loss: 1.0021835805673618e-05\n",
      "Epoch 2657, Loss: 0.008222261474202242, Final Batch Loss: 3.8963198676356114e-06\n",
      "Epoch 2658, Loss: 0.0011243953595112544, Final Batch Loss: 4.5809898438164964e-05\n",
      "Epoch 2659, Loss: 0.0006411262038454879, Final Batch Loss: 4.581885150400922e-06\n",
      "Epoch 2660, Loss: 0.004851425544984522, Final Batch Loss: 0.00355099537409842\n",
      "Epoch 2661, Loss: 0.0009820644609135343, Final Batch Loss: 0.0009203076479025185\n",
      "Epoch 2662, Loss: 0.00044747787615051493, Final Batch Loss: 2.7069866064266535e-06\n",
      "Epoch 2663, Loss: 0.0008301098896481562, Final Batch Loss: 2.146234328392893e-05\n",
      "Epoch 2664, Loss: 0.0010458691904204898, Final Batch Loss: 0.0002829214499797672\n",
      "Epoch 2665, Loss: 0.004239667422552884, Final Batch Loss: 5.072033673059195e-05\n",
      "Epoch 2666, Loss: 0.004211730010865722, Final Batch Loss: 0.003508225781843066\n",
      "Epoch 2667, Loss: 0.0013163802627786936, Final Batch Loss: 4.22168295699521e-06\n",
      "Epoch 2668, Loss: 0.0006001159736115369, Final Batch Loss: 0.00014190685760695487\n",
      "Epoch 2669, Loss: 0.00017781520750759228, Final Batch Loss: 1.0405822195025394e-06\n",
      "Epoch 2670, Loss: 0.0008343075751326978, Final Batch Loss: 1.1303956853225827e-05\n",
      "Epoch 2671, Loss: 0.0024485261401423486, Final Batch Loss: 9.53303424466867e-06\n",
      "Epoch 2672, Loss: 0.00038773449858808817, Final Batch Loss: 5.811395453747537e-07\n",
      "Epoch 2673, Loss: 0.0017346172317047603, Final Batch Loss: 0.0005161287845112383\n",
      "Epoch 2674, Loss: 0.0004722973571915645, Final Batch Loss: 1.1366872058715671e-05\n",
      "Epoch 2675, Loss: 0.001612215128261596, Final Batch Loss: 0.0003823577135335654\n",
      "Epoch 2676, Loss: 0.0011740196569007821, Final Batch Loss: 0.00021774496417492628\n",
      "Epoch 2677, Loss: 0.0012799410988009186, Final Batch Loss: 0.0009315986535511911\n",
      "Epoch 2678, Loss: 0.00020191172325212392, Final Batch Loss: 5.162902652955381e-06\n",
      "Epoch 2679, Loss: 0.0008887291146493226, Final Batch Loss: 6.573292466782732e-06\n",
      "Epoch 2680, Loss: 9.886921702673135e-05, Final Batch Loss: 3.5387975003686734e-06\n",
      "Epoch 2681, Loss: 0.0014341253881866578, Final Batch Loss: 0.0012963084736838937\n",
      "Epoch 2682, Loss: 0.00018346480942454946, Final Batch Loss: 1.6959020285867155e-05\n",
      "Epoch 2683, Loss: 0.00814072593811943, Final Batch Loss: 6.421879788831575e-06\n",
      "Epoch 2684, Loss: 0.002755987635623569, Final Batch Loss: 1.1672412938423804e-06\n",
      "Epoch 2685, Loss: 0.016536815953259065, Final Batch Loss: 1.1250830539211165e-05\n",
      "Epoch 2686, Loss: 0.0007965706099639647, Final Batch Loss: 0.00011462919792393222\n",
      "Epoch 2687, Loss: 0.000650354384539753, Final Batch Loss: 6.705520405603238e-08\n",
      "Epoch 2688, Loss: 0.0002593970338011786, Final Batch Loss: 2.4338476123375585e-07\n",
      "Epoch 2689, Loss: 0.001626548724289023, Final Batch Loss: 4.817502031073673e-06\n",
      "Epoch 2690, Loss: 0.0016603017920715502, Final Batch Loss: 1.6723895896575414e-05\n",
      "Epoch 2691, Loss: 0.0005954502958047669, Final Batch Loss: 0.0001055515676853247\n",
      "Epoch 2692, Loss: 0.002890039118938148, Final Batch Loss: 0.0014264442725107074\n",
      "Epoch 2693, Loss: 0.0008839500733301975, Final Batch Loss: 4.1861003410303965e-05\n",
      "Epoch 2694, Loss: 0.000679216165735852, Final Batch Loss: 2.6653564418666065e-05\n",
      "Epoch 2695, Loss: 0.00039831483127272804, Final Batch Loss: 7.109816124284407e-06\n",
      "Epoch 2696, Loss: 0.0009414157721039373, Final Batch Loss: 0.000535226019565016\n",
      "Epoch 2697, Loss: 0.0009350100299343467, Final Batch Loss: 9.590030458639376e-06\n",
      "Epoch 2698, Loss: 0.0007661817871849053, Final Batch Loss: 0.0\n",
      "Epoch 2699, Loss: 0.0007429537333010217, Final Batch Loss: 1.7384685691013146e-08\n",
      "Epoch 2700, Loss: 0.0005808371638522658, Final Batch Loss: 4.209342932881555e-06\n",
      "Epoch 2701, Loss: 0.0008664291023023907, Final Batch Loss: 1.7706794324112707e-06\n",
      "Epoch 2702, Loss: 0.000492951679007092, Final Batch Loss: 2.905717337853275e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2703, Loss: 0.014010930375661701, Final Batch Loss: 0.0004746629565488547\n",
      "Epoch 2704, Loss: 0.001000102977741335, Final Batch Loss: 1.260920998902293e-05\n",
      "Epoch 2705, Loss: 0.005150558741206623, Final Batch Loss: 6.481555374193704e-06\n",
      "Epoch 2706, Loss: 0.00011672921823446814, Final Batch Loss: 1.1076342616433976e-06\n",
      "Epoch 2707, Loss: 0.00992453598883003, Final Batch Loss: 0.005463120061904192\n",
      "Epoch 2708, Loss: 0.0009622727445730561, Final Batch Loss: 2.2351357529259985e-06\n",
      "Epoch 2709, Loss: 0.0037402556127972275, Final Batch Loss: 1.8179063090428826e-06\n",
      "Epoch 2710, Loss: 0.0012258178630872862, Final Batch Loss: 0.0002960527781397104\n",
      "Epoch 2711, Loss: 0.00022694074777973583, Final Batch Loss: 1.2409640476107597e-05\n",
      "Epoch 2712, Loss: 0.0010476325869603897, Final Batch Loss: 8.02803406259045e-05\n",
      "Epoch 2713, Loss: 0.0004630658804671839, Final Batch Loss: 0.00017528636089991778\n",
      "Epoch 2714, Loss: 0.002674675764865242, Final Batch Loss: 0.00019598806102294475\n",
      "Epoch 2715, Loss: 0.00036355947486299556, Final Batch Loss: 0.0002399664808763191\n",
      "Epoch 2716, Loss: 0.0008218839288929303, Final Batch Loss: 5.5426939979952294e-06\n",
      "Epoch 2717, Loss: 0.00022809539586887695, Final Batch Loss: 1.926155346154701e-05\n",
      "Epoch 2718, Loss: 0.002032595906257484, Final Batch Loss: 5.719125965697458e-06\n",
      "Epoch 2719, Loss: 0.0006448258732234535, Final Batch Loss: 5.7611100601207e-06\n",
      "Epoch 2720, Loss: 0.0009218410304825397, Final Batch Loss: 2.980230107141324e-08\n",
      "Epoch 2721, Loss: 0.0003775896730076056, Final Batch Loss: 7.253194780787453e-06\n",
      "Epoch 2722, Loss: 0.014549330148838635, Final Batch Loss: 4.467669896257576e-06\n",
      "Epoch 2723, Loss: 0.007882356620967812, Final Batch Loss: 1.3162664913579647e-07\n",
      "Epoch 2724, Loss: 0.00031396528356708586, Final Batch Loss: 2.1565414499491453e-05\n",
      "Epoch 2725, Loss: 0.00011480830289656296, Final Batch Loss: 9.599957593309227e-06\n",
      "Epoch 2726, Loss: 0.04448498943202139, Final Batch Loss: 1.682264519331511e-05\n",
      "Epoch 2727, Loss: 0.000570963751670206, Final Batch Loss: 4.371887189336121e-05\n",
      "Epoch 2728, Loss: 0.00022764800814911723, Final Batch Loss: 1.5518984582740813e-05\n",
      "Epoch 2729, Loss: 0.006969332186599786, Final Batch Loss: 8.213953151425812e-06\n",
      "Epoch 2730, Loss: 0.0059500284060050035, Final Batch Loss: 7.236772944452241e-05\n",
      "Epoch 2731, Loss: 0.0007921578444438637, Final Batch Loss: 4.7985664423322305e-05\n",
      "Epoch 2732, Loss: 0.0011575941625778796, Final Batch Loss: 5.401507951319218e-05\n",
      "Epoch 2733, Loss: 0.0013472104130869411, Final Batch Loss: 1.0877722615987295e-06\n",
      "Epoch 2734, Loss: 0.08128567194989955, Final Batch Loss: 2.1432429093692917e-06\n",
      "Epoch 2735, Loss: 0.00576605992137047, Final Batch Loss: 0.0053446609526872635\n",
      "Epoch 2736, Loss: 0.025907295835679633, Final Batch Loss: 9.412465828972927e-07\n",
      "Epoch 2737, Loss: 0.0003133437239739578, Final Batch Loss: 1.8790524336509407e-05\n",
      "Epoch 2738, Loss: 0.001132650148065295, Final Batch Loss: 0.00020679175213444978\n",
      "Epoch 2739, Loss: 0.0003140486913366658, Final Batch Loss: 6.134285399639339e-07\n",
      "Epoch 2740, Loss: 0.0011677456760708083, Final Batch Loss: 2.0613254037016304e-07\n",
      "Epoch 2741, Loss: 0.000565800550248241, Final Batch Loss: 6.377533281920478e-05\n",
      "Epoch 2742, Loss: 0.003025784099008888, Final Batch Loss: 3.5280289012007415e-05\n",
      "Epoch 2743, Loss: 0.000157991527885315, Final Batch Loss: 2.2871032342663966e-05\n",
      "Epoch 2744, Loss: 0.000919172402973345, Final Batch Loss: 2.9697623176616617e-05\n",
      "Epoch 2745, Loss: 0.0012404441076796502, Final Batch Loss: 5.179742584004998e-05\n",
      "Epoch 2746, Loss: 0.00590032486434211, Final Batch Loss: 0.005711401347070932\n",
      "Epoch 2747, Loss: 0.0005715596535083023, Final Batch Loss: 1.7445026969653554e-05\n",
      "Epoch 2748, Loss: 0.0007138872788345907, Final Batch Loss: 0.00030542799504473805\n",
      "Epoch 2749, Loss: 0.05044456023733801, Final Batch Loss: 0.00026102978154085577\n",
      "Epoch 2750, Loss: 0.0036970130895497277, Final Batch Loss: 0.000867392576765269\n",
      "Epoch 2751, Loss: 0.00015101902135938872, Final Batch Loss: 1.944967698364053e-05\n",
      "Epoch 2752, Loss: 0.0026343790959799662, Final Batch Loss: 0.00014723195636179298\n",
      "Epoch 2753, Loss: 0.0037019190913269995, Final Batch Loss: 2.8485612347139977e-05\n",
      "Epoch 2754, Loss: 0.00036957694101147354, Final Batch Loss: 8.839120710035786e-05\n",
      "Epoch 2755, Loss: 0.001230914154916718, Final Batch Loss: 1.085280132429034e-06\n",
      "Epoch 2756, Loss: 0.0011247514703427441, Final Batch Loss: 8.762586367083713e-05\n",
      "Epoch 2757, Loss: 0.004034599760416313, Final Batch Loss: 8.333845471497625e-06\n",
      "Epoch 2758, Loss: 0.0331579706096079, Final Batch Loss: 3.278243809745618e-07\n",
      "Epoch 2759, Loss: 0.0030133103835510155, Final Batch Loss: 6.655798756582954e-07\n",
      "Epoch 2760, Loss: 0.00040858964712242596, Final Batch Loss: 0.00011583062587305903\n",
      "Epoch 2761, Loss: 0.0016806347921374254, Final Batch Loss: 0.0005135206156410277\n",
      "Epoch 2762, Loss: 0.0011755766162480086, Final Batch Loss: 3.87429196280209e-07\n",
      "Epoch 2763, Loss: 0.00020053631851624232, Final Batch Loss: 2.62767916865414e-05\n",
      "Epoch 2764, Loss: 0.0012995106080779806, Final Batch Loss: 0.00012849473569076508\n",
      "Epoch 2765, Loss: 0.0010089073748531519, Final Batch Loss: 0.0002880953252315521\n",
      "Epoch 2766, Loss: 0.0008530004906788236, Final Batch Loss: 3.443341483944096e-05\n",
      "Epoch 2767, Loss: 0.0011462781051250204, Final Batch Loss: 6.134262093837606e-07\n",
      "Epoch 2768, Loss: 0.001344722943031229, Final Batch Loss: 0.0009610161068849266\n",
      "Epoch 2769, Loss: 0.0010198449836025247, Final Batch Loss: 5.93987169850152e-06\n",
      "Epoch 2770, Loss: 0.0006458371281041764, Final Batch Loss: 7.518649363191798e-05\n",
      "Epoch 2771, Loss: 0.0006641697736995411, Final Batch Loss: 0.0003544560167938471\n",
      "Epoch 2772, Loss: 0.00016687942252247012, Final Batch Loss: 4.245410309522413e-05\n",
      "Epoch 2773, Loss: 0.0196548500280187, Final Batch Loss: 5.1316263125045225e-05\n",
      "Epoch 2774, Loss: 0.004511804620051407, Final Batch Loss: 1.991163480852265e-05\n",
      "Epoch 2775, Loss: 0.0008692969859112054, Final Batch Loss: 3.4172044252045453e-06\n",
      "Epoch 2776, Loss: 0.0008702836457814556, Final Batch Loss: 4.7059536882443354e-05\n",
      "Epoch 2777, Loss: 0.00018172672002947365, Final Batch Loss: 3.4098245578206843e-06\n",
      "Epoch 2778, Loss: 0.000766577388276346, Final Batch Loss: 0.0005560850258916616\n",
      "Epoch 2779, Loss: 0.0012154041505709756, Final Batch Loss: 4.3770680349553004e-05\n",
      "Epoch 2780, Loss: 0.00031730243608762976, Final Batch Loss: 2.7789859814220108e-05\n",
      "Epoch 2781, Loss: 0.0004770548383135065, Final Batch Loss: 7.698889135099307e-07\n",
      "Epoch 2782, Loss: 0.000687388862388616, Final Batch Loss: 1.346431872661924e-05\n",
      "Epoch 2783, Loss: 0.02115555347592135, Final Batch Loss: 5.637546678372019e-07\n",
      "Epoch 2784, Loss: 0.0002458740468682663, Final Batch Loss: 5.801133283966919e-06\n",
      "Epoch 2785, Loss: 0.0009136203916568775, Final Batch Loss: 7.129891309887171e-05\n",
      "Epoch 2786, Loss: 0.0019487119243422057, Final Batch Loss: 1.7824171663960442e-05\n",
      "Epoch 2787, Loss: 0.0005546276370296255, Final Batch Loss: 9.135471918853e-05\n",
      "Epoch 2788, Loss: 0.0007877559760345321, Final Batch Loss: 5.9922908803855535e-06\n",
      "Epoch 2789, Loss: 0.001243026530573843, Final Batch Loss: 0.0006782550481148064\n",
      "Epoch 2790, Loss: 0.02197268937015906, Final Batch Loss: 6.212294101715088e-05\n",
      "Epoch 2791, Loss: 0.027218916936362803, Final Batch Loss: 9.865988977253437e-05\n",
      "Epoch 2792, Loss: 0.003106875422417943, Final Batch Loss: 1.0908298463618848e-05\n",
      "Epoch 2793, Loss: 0.003345323908433784, Final Batch Loss: 0.00027492482331581414\n",
      "Epoch 2794, Loss: 0.0022744305824744515, Final Batch Loss: 6.815780943725258e-05\n",
      "Epoch 2795, Loss: 0.005591091754467925, Final Batch Loss: 4.5471064368030056e-05\n",
      "Epoch 2796, Loss: 0.0007087805082761633, Final Batch Loss: 1.440443071487607e-07\n",
      "Epoch 2797, Loss: 0.0013865990231352043, Final Batch Loss: 1.041864470607834e-05\n",
      "Epoch 2798, Loss: 0.005201698969358404, Final Batch Loss: 4.502228875935543e-06\n",
      "Epoch 2799, Loss: 0.013413813238003058, Final Batch Loss: 0.0002501429698895663\n",
      "Epoch 2800, Loss: 0.0010235676945740124, Final Batch Loss: 2.39935234276345e-05\n",
      "Epoch 2801, Loss: 0.0005381670234783087, Final Batch Loss: 0.00013708116603083909\n",
      "Epoch 2802, Loss: 0.0014544124423991889, Final Batch Loss: 0.00012676675396505743\n",
      "Epoch 2803, Loss: 0.00215447277128078, Final Batch Loss: 1.9941869595641037e-06\n",
      "Epoch 2804, Loss: 0.0008616534223619965, Final Batch Loss: 1.2175788469903637e-05\n",
      "Epoch 2805, Loss: 0.0007591750634219352, Final Batch Loss: 3.725269834831124e-07\n",
      "Epoch 2806, Loss: 0.0011487980955280364, Final Batch Loss: 1.77514084498398e-05\n",
      "Epoch 2807, Loss: 0.0015889650303506642, Final Batch Loss: 1.4503019883704837e-05\n",
      "Epoch 2808, Loss: 8.233847711380804e-05, Final Batch Loss: 3.5456854675430804e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2809, Loss: 0.0017175653047161177, Final Batch Loss: 0.00017590547213330865\n",
      "Epoch 2810, Loss: 0.004960765758369234, Final Batch Loss: 0.0034075595904141665\n",
      "Epoch 2811, Loss: 0.0013559244262069114, Final Batch Loss: 7.764830115775112e-06\n",
      "Epoch 2812, Loss: 0.0005312898624652007, Final Batch Loss: 5.530497219297104e-06\n",
      "Epoch 2813, Loss: 0.005385103273169989, Final Batch Loss: 1.28396425225219e-06\n",
      "Epoch 2814, Loss: 0.00042461366501811426, Final Batch Loss: 2.5760893549886532e-05\n",
      "Epoch 2815, Loss: 0.03565128791342431, Final Batch Loss: 0.0351945124566555\n",
      "Epoch 2816, Loss: 0.019269653083142657, Final Batch Loss: 1.879987507891201e-06\n",
      "Epoch 2817, Loss: 0.0014355731300383923, Final Batch Loss: 0.0013104811077937484\n",
      "Epoch 2818, Loss: 0.09006257014698349, Final Batch Loss: 0.0893561914563179\n",
      "Epoch 2819, Loss: 0.006078786132093228, Final Batch Loss: 0.005333060398697853\n",
      "Epoch 2820, Loss: 0.004446451275725849, Final Batch Loss: 0.002928809029981494\n",
      "Epoch 2821, Loss: 0.0016727694164728746, Final Batch Loss: 8.498854003846645e-05\n",
      "Epoch 2822, Loss: 0.008222826174460351, Final Batch Loss: 0.0006700670928694308\n",
      "Epoch 2823, Loss: 0.0013081046031402366, Final Batch Loss: 1.4379234016814735e-06\n",
      "Epoch 2824, Loss: 0.0021139124291948974, Final Batch Loss: 0.00021776679204776883\n",
      "Epoch 2825, Loss: 0.02016254536283668, Final Batch Loss: 0.018750125542283058\n",
      "Epoch 2826, Loss: 0.0012586613665916957, Final Batch Loss: 2.1289903088472784e-05\n",
      "Epoch 2827, Loss: 0.004387317909277044, Final Batch Loss: 0.00019517051987349987\n",
      "Epoch 2828, Loss: 0.0026092055486515164, Final Batch Loss: 0.00025314802769571543\n",
      "Epoch 2829, Loss: 0.0014719801902174368, Final Batch Loss: 1.2419134691299405e-05\n",
      "Epoch 2830, Loss: 0.0020737480954267085, Final Batch Loss: 8.431417518295348e-05\n",
      "Epoch 2831, Loss: 0.00539768880844349, Final Batch Loss: 0.00017665146151557565\n",
      "Epoch 2832, Loss: 0.0013864769171050284, Final Batch Loss: 6.321194814518094e-05\n",
      "Epoch 2833, Loss: 0.0021579197127721272, Final Batch Loss: 0.00031982510699890554\n",
      "Epoch 2834, Loss: 0.0005840268731844844, Final Batch Loss: 2.405278974038083e-05\n",
      "Epoch 2835, Loss: 0.0006172921239340212, Final Batch Loss: 1.5516758139710873e-05\n",
      "Epoch 2836, Loss: 0.0010908738004218321, Final Batch Loss: 5.656618668581359e-05\n",
      "Epoch 2837, Loss: 0.0011758351233766007, Final Batch Loss: 4.869935310125584e-06\n",
      "Epoch 2838, Loss: 0.0006032172314007767, Final Batch Loss: 3.2206313335336745e-05\n",
      "Epoch 2839, Loss: 0.000913153009605594, Final Batch Loss: 0.00015939156583044678\n",
      "Epoch 2840, Loss: 0.0018692378671403276, Final Batch Loss: 3.8170055631781e-06\n",
      "Epoch 2841, Loss: 0.0016201049911614973, Final Batch Loss: 0.000594545213971287\n",
      "Epoch 2842, Loss: 0.0029699669321416877, Final Batch Loss: 2.1366467990446836e-05\n",
      "Epoch 2843, Loss: 0.000522415726663894, Final Batch Loss: 1.8511293092160486e-05\n",
      "Epoch 2844, Loss: 0.0012594351792358793, Final Batch Loss: 0.00029373393044807017\n",
      "Epoch 2845, Loss: 0.0004653104242606787, Final Batch Loss: 3.585194281185977e-05\n",
      "Epoch 2846, Loss: 0.004236712787133001, Final Batch Loss: 8.2742235463229e-06\n",
      "Epoch 2847, Loss: 0.0030564415210392326, Final Batch Loss: 0.0025396558921784163\n",
      "Epoch 2848, Loss: 0.0012620005545613822, Final Batch Loss: 0.00038592537748627365\n",
      "Epoch 2849, Loss: 0.00019621257979451912, Final Batch Loss: 1.0594630111881997e-05\n",
      "Epoch 2850, Loss: 0.0005010736567783169, Final Batch Loss: 0.00016659736866131425\n",
      "Epoch 2851, Loss: 0.007621916689458885, Final Batch Loss: 2.6831972718355246e-05\n",
      "Epoch 2852, Loss: 0.001796287353556636, Final Batch Loss: 7.078015755723754e-07\n",
      "Epoch 2853, Loss: 0.00037542333996043453, Final Batch Loss: 1.8849165144274593e-06\n",
      "Epoch 2854, Loss: 0.0014469766501861159, Final Batch Loss: 0.00012277001223992556\n",
      "Epoch 2855, Loss: 0.018011691402989527, Final Batch Loss: 3.8889897950866725e-06\n",
      "Epoch 2856, Loss: 0.009491987540968694, Final Batch Loss: 1.478265767218545e-05\n",
      "Epoch 2857, Loss: 0.0005514968934221542, Final Batch Loss: 1.4965559785196092e-05\n",
      "Epoch 2858, Loss: 0.005842176870373805, Final Batch Loss: 4.723370238934876e-06\n",
      "Epoch 2859, Loss: 0.0007004121562204091, Final Batch Loss: 2.3420032448484562e-05\n",
      "Epoch 2860, Loss: 0.00161564743029885, Final Batch Loss: 0.0001278189884033054\n",
      "Epoch 2861, Loss: 0.001719661837341846, Final Batch Loss: 8.478076051687822e-05\n",
      "Epoch 2862, Loss: 0.002759698060458504, Final Batch Loss: 6.208813374541933e-08\n",
      "Epoch 2863, Loss: 0.00036045686101715546, Final Batch Loss: 1.917242116178386e-06\n",
      "Epoch 2864, Loss: 0.00035491441303747706, Final Batch Loss: 4.504090247792192e-05\n",
      "Epoch 2865, Loss: 0.0007131655866032816, Final Batch Loss: 2.3365073502645828e-05\n",
      "Epoch 2866, Loss: 0.000756371136958478, Final Batch Loss: 5.221908213570714e-05\n",
      "Epoch 2867, Loss: 0.006105578585447802, Final Batch Loss: 1.0315293366147671e-05\n",
      "Epoch 2868, Loss: 0.0010141271673091978, Final Batch Loss: 4.3842530430993065e-05\n",
      "Epoch 2869, Loss: 0.000753823511331575, Final Batch Loss: 0.00017273017147090286\n",
      "Epoch 2870, Loss: 0.0005803369604109321, Final Batch Loss: 8.413434443355072e-06\n",
      "Epoch 2871, Loss: 0.005845949928016125, Final Batch Loss: 2.1531625407078536e-06\n",
      "Epoch 2872, Loss: 0.0013879443285986781, Final Batch Loss: 0.0009841547580435872\n",
      "Epoch 2873, Loss: 0.0011044161637983052, Final Batch Loss: 0.0008468254818581045\n",
      "Epoch 2874, Loss: 0.0004113503855478484, Final Batch Loss: 4.3346910388208926e-05\n",
      "Epoch 2875, Loss: 0.00591809720845049, Final Batch Loss: 9.42814858717611e-06\n",
      "Epoch 2876, Loss: 0.003091238482738845, Final Batch Loss: 0.000188768157386221\n",
      "Epoch 2877, Loss: 0.0007222457211355504, Final Batch Loss: 5.989772489556344e-06\n",
      "Epoch 2878, Loss: 0.00029988651294843294, Final Batch Loss: 1.9228637029300444e-05\n",
      "Epoch 2879, Loss: 0.0006004492133797612, Final Batch Loss: 0.00016792304813861847\n",
      "Epoch 2880, Loss: 0.001795662299741707, Final Batch Loss: 1.686277869339392e-06\n",
      "Epoch 2881, Loss: 0.0007666503457812723, Final Batch Loss: 1.775677105797513e-06\n",
      "Epoch 2882, Loss: 0.0034939823344757315, Final Batch Loss: 0.002836488885805011\n",
      "Epoch 2883, Loss: 0.00021911523890594253, Final Batch Loss: 2.504739495634567e-05\n",
      "Epoch 2884, Loss: 0.0013820977134244572, Final Batch Loss: 7.698930204469434e-08\n",
      "Epoch 2885, Loss: 0.001065360788075509, Final Batch Loss: 1.6639593525269447e-07\n",
      "Epoch 2886, Loss: 0.012847983786627992, Final Batch Loss: 1.0753564083643141e-06\n",
      "Epoch 2887, Loss: 0.01184720437595388, Final Batch Loss: 0.000859878899063915\n",
      "Epoch 2888, Loss: 0.000650703877909109, Final Batch Loss: 0.00043745877337642014\n",
      "Epoch 2889, Loss: 0.0012100526146241464, Final Batch Loss: 0.00027596045401878655\n",
      "Epoch 2890, Loss: 0.00038455363642242446, Final Batch Loss: 2.724332034631516e-06\n",
      "Epoch 2891, Loss: 0.0006102032530179713, Final Batch Loss: 2.7607078664004803e-05\n",
      "Epoch 2892, Loss: 0.0002574179943621857, Final Batch Loss: 2.0191115254419856e-05\n",
      "Epoch 2893, Loss: 0.0002641080864123069, Final Batch Loss: 3.294319685664959e-05\n",
      "Epoch 2894, Loss: 0.0003698592914957999, Final Batch Loss: 1.5646186568574194e-07\n",
      "Epoch 2895, Loss: 0.001019480754621327, Final Batch Loss: 0.0005522309802472591\n",
      "Epoch 2896, Loss: 0.0013653362111654133, Final Batch Loss: 0.000964574923273176\n",
      "Epoch 2897, Loss: 0.0003622606081989943, Final Batch Loss: 1.4941429071768653e-05\n",
      "Epoch 2898, Loss: 0.00046451608068309724, Final Batch Loss: 1.2307227734709159e-05\n",
      "Epoch 2899, Loss: 0.00038236554610193707, Final Batch Loss: 3.516763899824582e-05\n",
      "Epoch 2900, Loss: 0.0005357181290435165, Final Batch Loss: 3.253408920045331e-07\n",
      "Epoch 2901, Loss: 0.0014431351110033575, Final Batch Loss: 8.031071774894372e-05\n",
      "Epoch 2902, Loss: 0.001190038785807701, Final Batch Loss: 0.000364624778740108\n",
      "Epoch 2903, Loss: 0.00044932055516255787, Final Batch Loss: 1.1039734999940265e-05\n",
      "Epoch 2904, Loss: 0.0005082337288513372, Final Batch Loss: 1.8402702153252903e-06\n",
      "Epoch 2905, Loss: 0.00021265316172502935, Final Batch Loss: 7.970270962687209e-05\n",
      "Epoch 2906, Loss: 0.019299919432341994, Final Batch Loss: 1.0679150364012457e-07\n",
      "Epoch 2907, Loss: 0.00012387785500322934, Final Batch Loss: 4.278756023268215e-06\n",
      "Epoch 2908, Loss: 0.0009501970671408344, Final Batch Loss: 6.949158705538139e-05\n",
      "Epoch 2909, Loss: 0.021422089291888824, Final Batch Loss: 7.922387226244609e-07\n",
      "Epoch 2910, Loss: 0.000318533202062099, Final Batch Loss: 7.588975222461158e-06\n",
      "Epoch 2911, Loss: 0.009531988971730243, Final Batch Loss: 3.61819388672302e-06\n",
      "Epoch 2912, Loss: 0.00021450613348861225, Final Batch Loss: 1.6091973520815372e-05\n",
      "Epoch 2913, Loss: 0.0006164625100950616, Final Batch Loss: 9.536615266370063e-07\n",
      "Epoch 2914, Loss: 0.00972262112190947, Final Batch Loss: 0.0020362171344459057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2915, Loss: 0.0005527108787646284, Final Batch Loss: 0.00022383814211934805\n",
      "Epoch 2916, Loss: 0.0008142307074194832, Final Batch Loss: 5.9723120102717075e-06\n",
      "Epoch 2917, Loss: 0.001366065796901239, Final Batch Loss: 0.000870315358042717\n",
      "Epoch 2918, Loss: 0.0017631191967666382, Final Batch Loss: 0.00126484758220613\n",
      "Epoch 2919, Loss: 0.0006044530746294186, Final Batch Loss: 0.0002305488014826551\n",
      "Epoch 2920, Loss: 0.000558942817406205, Final Batch Loss: 7.724850547674578e-06\n",
      "Epoch 2921, Loss: 0.001401231063027808, Final Batch Loss: 4.671251190302428e-06\n",
      "Epoch 2922, Loss: 0.0011655149282887578, Final Batch Loss: 0.000163501754286699\n",
      "Epoch 2923, Loss: 0.0031518872015396937, Final Batch Loss: 4.221979281737731e-07\n",
      "Epoch 2924, Loss: 0.0003740920146810822, Final Batch Loss: 1.5392122804769315e-05\n",
      "Epoch 2925, Loss: 0.00024398141158599174, Final Batch Loss: 0.0001010245832731016\n",
      "Epoch 2926, Loss: 0.0004304123602310028, Final Batch Loss: 5.389218244999938e-07\n",
      "Epoch 2927, Loss: 0.0007004033148803046, Final Batch Loss: 2.5083576815632114e-07\n",
      "Epoch 2928, Loss: 0.0023113448660296854, Final Batch Loss: 0.00016143823449965566\n",
      "Epoch 2929, Loss: 0.000405554214012227, Final Batch Loss: 2.0790123016922735e-05\n",
      "Epoch 2930, Loss: 0.00014877209559926996, Final Batch Loss: 1.0590895726636518e-05\n",
      "Epoch 2931, Loss: 0.00021870851196581498, Final Batch Loss: 5.0359849410597235e-06\n",
      "Epoch 2932, Loss: 0.0004887966151727596, Final Batch Loss: 8.840782538754866e-05\n",
      "Epoch 2933, Loss: 0.00024385289771089447, Final Batch Loss: 1.6862782103999052e-06\n",
      "Epoch 2934, Loss: 0.0003883418316945608, Final Batch Loss: 0.0002248730743303895\n",
      "Epoch 2935, Loss: 0.0020174554811092094, Final Batch Loss: 0.001123463618569076\n",
      "Epoch 2936, Loss: 0.00042287364885851275, Final Batch Loss: 0.00023387114924844354\n",
      "Epoch 2937, Loss: 0.0013441191404126585, Final Batch Loss: 5.217574653215706e-06\n",
      "Epoch 2938, Loss: 0.00021279785187289235, Final Batch Loss: 0.00013939864584244788\n",
      "Epoch 2939, Loss: 0.0006026844128541597, Final Batch Loss: 1.1920911902052467e-07\n",
      "Epoch 2940, Loss: 0.0013641076880048786, Final Batch Loss: 2.5828603611444123e-07\n",
      "Epoch 2941, Loss: 0.0006064567082901817, Final Batch Loss: 9.93409301486281e-08\n",
      "Epoch 2942, Loss: 0.0028414398466338753, Final Batch Loss: 0.0007149155717343092\n",
      "Epoch 2943, Loss: 0.021096419116474863, Final Batch Loss: 7.57568413973786e-05\n",
      "Epoch 2944, Loss: 0.00032261853812087793, Final Batch Loss: 6.694985131616704e-06\n",
      "Epoch 2945, Loss: 0.0022536113979185757, Final Batch Loss: 3.86656074624625e-06\n",
      "Epoch 2946, Loss: 0.004360032749900711, Final Batch Loss: 0.00034275863436050713\n",
      "Epoch 2947, Loss: 0.002638304570609762, Final Batch Loss: 0.0025681708939373493\n",
      "Epoch 2948, Loss: 0.0007732676785963122, Final Batch Loss: 7.613529305672273e-06\n",
      "Epoch 2949, Loss: 0.0005248881050192722, Final Batch Loss: 2.4337994091183646e-06\n",
      "Epoch 2950, Loss: 0.00030314751900561987, Final Batch Loss: 2.2600040949782851e-07\n",
      "Epoch 2951, Loss: 0.00032865594516806595, Final Batch Loss: 3.695339955811505e-06\n",
      "Epoch 2952, Loss: 0.0003071982835081144, Final Batch Loss: 1.015738916976261e-06\n",
      "Epoch 2953, Loss: 0.0036933139726897934, Final Batch Loss: 8.549162885174155e-06\n",
      "Epoch 2954, Loss: 0.00017645595562498784, Final Batch Loss: 9.151067388302181e-06\n",
      "Epoch 2955, Loss: 0.0018354150124650914, Final Batch Loss: 3.570095213945024e-05\n",
      "Epoch 2956, Loss: 0.0006769224137315177, Final Batch Loss: 2.6373609216534533e-06\n",
      "Epoch 2957, Loss: 0.000826607683848124, Final Batch Loss: 8.650295058032498e-05\n",
      "Epoch 2958, Loss: 0.00014255141468311194, Final Batch Loss: 2.2258051103563048e-05\n",
      "Epoch 2959, Loss: 0.00026576277377898805, Final Batch Loss: 2.96762227662839e-05\n",
      "Epoch 2960, Loss: 0.0005869571009498031, Final Batch Loss: 4.077719950146275e-06\n",
      "Epoch 2961, Loss: 0.00023319738163252168, Final Batch Loss: 2.2848387004614779e-07\n",
      "Epoch 2962, Loss: 0.000378211143356566, Final Batch Loss: 1.7334731410301174e-06\n",
      "Epoch 2963, Loss: 8.679800157551654e-05, Final Batch Loss: 3.9438509702449664e-05\n",
      "Epoch 2964, Loss: 0.00037131229260012333, Final Batch Loss: 3.3699827781674685e-06\n",
      "Epoch 2965, Loss: 0.04380247693188721, Final Batch Loss: 7.602881669299677e-05\n",
      "Epoch 2966, Loss: 0.00036214700165260183, Final Batch Loss: 2.682202477899409e-07\n",
      "Epoch 2967, Loss: 0.0008308190917887259, Final Batch Loss: 3.0736842745682225e-05\n",
      "Epoch 2968, Loss: 0.13025552135241014, Final Batch Loss: 0.12849795818328857\n",
      "Epoch 2969, Loss: 0.01188824617128148, Final Batch Loss: 5.041503641223244e-07\n",
      "Epoch 2970, Loss: 0.001482270575252187, Final Batch Loss: 0.0011441066162660718\n",
      "Epoch 2971, Loss: 0.008274633641121909, Final Batch Loss: 0.006416585296392441\n",
      "Epoch 2972, Loss: 0.011275806304183789, Final Batch Loss: 0.010302672162652016\n",
      "Epoch 2973, Loss: 0.000875619487487711, Final Batch Loss: 0.00027832630439661443\n",
      "Epoch 2974, Loss: 0.00039398045169036777, Final Batch Loss: 9.859411420620745e-07\n",
      "Epoch 2975, Loss: 0.024842214595992118, Final Batch Loss: 0.024315515533089638\n",
      "Epoch 2976, Loss: 0.034423230859829346, Final Batch Loss: 0.0313321053981781\n",
      "Epoch 2977, Loss: 0.10206569251340625, Final Batch Loss: 7.773373909003567e-07\n",
      "Epoch 2978, Loss: 0.15272419642133173, Final Batch Loss: 2.7970629162155092e-05\n",
      "Epoch 2979, Loss: 0.12479673450434348, Final Batch Loss: 0.03477077931165695\n",
      "Epoch 2980, Loss: 0.07680635590804741, Final Batch Loss: 0.00043126902892254293\n",
      "Epoch 2981, Loss: 0.08501731907017529, Final Batch Loss: 0.002280607121065259\n",
      "Epoch 2982, Loss: 0.056855155213270336, Final Batch Loss: 0.0004883781657554209\n",
      "Epoch 2983, Loss: 0.025721740603330545, Final Batch Loss: 0.00022115612227935344\n",
      "Epoch 2984, Loss: 0.03686131483846111, Final Batch Loss: 0.023865574970841408\n",
      "Epoch 2985, Loss: 0.005495270233950578, Final Batch Loss: 0.00021178483439143747\n",
      "Epoch 2986, Loss: 0.021962385158985853, Final Batch Loss: 0.010253808461129665\n",
      "Epoch 2987, Loss: 0.01732283300952986, Final Batch Loss: 0.0002065338776446879\n",
      "Epoch 2988, Loss: 0.014106916612945497, Final Batch Loss: 0.0032521735411137342\n",
      "Epoch 2989, Loss: 0.022102362476289272, Final Batch Loss: 0.004618057049810886\n",
      "Epoch 2990, Loss: 0.005198751192438067, Final Batch Loss: 2.711961315071676e-05\n",
      "Epoch 2991, Loss: 0.004655639524571598, Final Batch Loss: 0.0010904582450166345\n",
      "Epoch 2992, Loss: 0.006204905221238732, Final Batch Loss: 0.0007215238292701542\n",
      "Epoch 2993, Loss: 0.004640300554456189, Final Batch Loss: 0.0003341298724990338\n",
      "Epoch 2994, Loss: 0.003188049522577785, Final Batch Loss: 5.052289634477347e-05\n",
      "Epoch 2995, Loss: 0.013766156043857336, Final Batch Loss: 0.006307206582278013\n",
      "Epoch 2996, Loss: 0.004411452100612223, Final Batch Loss: 0.0005828493740409613\n",
      "Epoch 2997, Loss: 0.012267189536942169, Final Batch Loss: 0.0019670675974339247\n",
      "Epoch 2998, Loss: 0.005123093840666115, Final Batch Loss: 0.0014490713365375996\n",
      "Epoch 2999, Loss: 0.003361794981174171, Final Batch Loss: 0.0005087765748612583\n",
      "Epoch 3000, Loss: 0.004482349759200588, Final Batch Loss: 7.907560211606324e-05\n",
      "Epoch 3001, Loss: 0.0016717527760192752, Final Batch Loss: 0.00022194314806256443\n",
      "Epoch 3002, Loss: 0.005947890895185992, Final Batch Loss: 0.00015877760597504675\n",
      "Epoch 3003, Loss: 0.0037377974076662213, Final Batch Loss: 0.0005787162808701396\n",
      "Epoch 3004, Loss: 0.005505818728124723, Final Batch Loss: 0.0002980268618557602\n",
      "Epoch 3005, Loss: 0.0014896544307703152, Final Batch Loss: 0.0002468017628416419\n",
      "Epoch 3006, Loss: 0.002267971489345655, Final Batch Loss: 0.0006002052687108517\n",
      "Epoch 3007, Loss: 0.0023800249764462933, Final Batch Loss: 0.0005627385107800364\n",
      "Epoch 3008, Loss: 0.009950526109605562, Final Batch Loss: 1.9940889615099877e-05\n",
      "Epoch 3009, Loss: 0.004831870159250684, Final Batch Loss: 0.003064833814278245\n",
      "Epoch 3010, Loss: 0.0038355274009518325, Final Batch Loss: 0.001087732845917344\n",
      "Epoch 3011, Loss: 0.006445187005738262, Final Batch Loss: 0.0007395604625344276\n",
      "Epoch 3012, Loss: 0.011756723222788423, Final Batch Loss: 0.004974097013473511\n",
      "Epoch 3013, Loss: 0.0008414990043092985, Final Batch Loss: 5.4347085097106174e-05\n",
      "Epoch 3014, Loss: 0.004458167728444096, Final Batch Loss: 0.00316459103487432\n",
      "Epoch 3015, Loss: 0.0006982347258599475, Final Batch Loss: 8.205545600503683e-05\n",
      "Epoch 3016, Loss: 0.0009810261440179602, Final Batch Loss: 2.5257072593376506e-06\n",
      "Epoch 3017, Loss: 0.0016286265599774197, Final Batch Loss: 0.0003962728369515389\n",
      "Epoch 3018, Loss: 0.01207436308504839, Final Batch Loss: 2.5663883207016625e-05\n",
      "Epoch 3019, Loss: 0.0023713698610663414, Final Batch Loss: 0.00010810911771841347\n",
      "Epoch 3020, Loss: 0.002106890096911229, Final Batch Loss: 0.0006267883582040668\n",
      "Epoch 3021, Loss: 0.008626696702322079, Final Batch Loss: 5.04869012729614e-06\n",
      "Epoch 3022, Loss: 0.0008330474993272219, Final Batch Loss: 0.0003978805907536298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3023, Loss: 0.013668895682258153, Final Batch Loss: 5.410945504991105e-06\n",
      "Epoch 3024, Loss: 0.0014932566014635995, Final Batch Loss: 5.016668751522957e-07\n",
      "Epoch 3025, Loss: 0.007593728165375069, Final Batch Loss: 0.0007001399644650519\n",
      "Epoch 3026, Loss: 0.006422884282073937, Final Batch Loss: 0.004943993408232927\n",
      "Epoch 3027, Loss: 0.0010933400838553098, Final Batch Loss: 7.251867941704404e-07\n",
      "Epoch 3028, Loss: 0.005199025440560945, Final Batch Loss: 1.1715424079739023e-05\n",
      "Epoch 3029, Loss: 0.0014153203665046021, Final Batch Loss: 0.00019332503143232316\n",
      "Epoch 3030, Loss: 0.009537449441268109, Final Batch Loss: 0.0009086753707379103\n",
      "Epoch 3031, Loss: 0.0007591414978378452, Final Batch Loss: 6.506325007649139e-05\n",
      "Epoch 3032, Loss: 0.0025831959064817056, Final Batch Loss: 0.0006086305365897715\n",
      "Epoch 3033, Loss: 0.0008465315768262371, Final Batch Loss: 0.0001435165322618559\n",
      "Epoch 3034, Loss: 0.005536983488127589, Final Batch Loss: 0.00018928793724626303\n",
      "Epoch 3035, Loss: 0.0010644628928275779, Final Batch Loss: 0.0003476807614788413\n",
      "Epoch 3036, Loss: 0.0025627727663959377, Final Batch Loss: 0.0019240854308009148\n",
      "Epoch 3037, Loss: 0.0015384358121082187, Final Batch Loss: 0.00011978906695730984\n",
      "Epoch 3038, Loss: 0.0016771368536865339, Final Batch Loss: 0.00031253884662874043\n",
      "Epoch 3039, Loss: 0.0030020055310160387, Final Batch Loss: 5.646616409649141e-05\n",
      "Epoch 3040, Loss: 0.000851931417855667, Final Batch Loss: 0.00030478162807412446\n",
      "Epoch 3041, Loss: 0.0006845866300864145, Final Batch Loss: 9.890400542644784e-05\n",
      "Epoch 3042, Loss: 0.0009274475232814439, Final Batch Loss: 6.221530202310532e-05\n",
      "Epoch 3043, Loss: 0.003479253631667234, Final Batch Loss: 0.00036694295704364777\n",
      "Epoch 3044, Loss: 0.002005976360578643, Final Batch Loss: 4.099999841855606e-06\n",
      "Epoch 3045, Loss: 0.000878081627888605, Final Batch Loss: 0.0001213362265843898\n",
      "Epoch 3046, Loss: 0.005176648603082867, Final Batch Loss: 0.004179561045020819\n",
      "Epoch 3047, Loss: 0.0004846572633141477, Final Batch Loss: 7.045171969366493e-06\n",
      "Epoch 3048, Loss: 0.032112539906847815, Final Batch Loss: 1.2101453648938332e-05\n",
      "Epoch 3049, Loss: 0.00043566695967456326, Final Batch Loss: 0.0001246522879227996\n",
      "Epoch 3050, Loss: 0.0008029624150367454, Final Batch Loss: 4.532017919700593e-05\n",
      "Epoch 3051, Loss: 0.0011054829192289617, Final Batch Loss: 8.635753329144791e-05\n",
      "Epoch 3052, Loss: 0.0005845147752552293, Final Batch Loss: 6.764142744941637e-05\n",
      "Epoch 3053, Loss: 0.009015330357669882, Final Batch Loss: 6.359824055834906e-06\n",
      "Epoch 3054, Loss: 0.0034098244505003095, Final Batch Loss: 0.0025345690082758665\n",
      "Epoch 3055, Loss: 0.003211720300896559, Final Batch Loss: 0.0018853697692975402\n",
      "Epoch 3056, Loss: 0.000805513234809041, Final Batch Loss: 0.0003564704384189099\n",
      "Epoch 3057, Loss: 0.0011020006604667287, Final Batch Loss: 0.0004742247692774981\n",
      "Epoch 3058, Loss: 0.00040886081478674896, Final Batch Loss: 1.2480672012316063e-05\n",
      "Epoch 3059, Loss: 0.0012773716007359326, Final Batch Loss: 0.0004689969646278769\n",
      "Epoch 3060, Loss: 0.0004664197185775265, Final Batch Loss: 0.00016998674254864454\n",
      "Epoch 3061, Loss: 0.001951613823621301, Final Batch Loss: 1.0902844223892316e-05\n",
      "Epoch 3062, Loss: 0.0004073158206665539, Final Batch Loss: 8.169271495717112e-06\n",
      "Epoch 3063, Loss: 0.001293345594604034, Final Batch Loss: 0.00011646654456853867\n",
      "Epoch 3064, Loss: 0.0003662021090349299, Final Batch Loss: 4.045458808832336e-06\n",
      "Epoch 3065, Loss: 0.0014875665729050525, Final Batch Loss: 0.00019005096692126244\n",
      "Epoch 3066, Loss: 0.0018060493748635054, Final Batch Loss: 0.0002442887343931943\n",
      "Epoch 3067, Loss: 0.001390594188023897, Final Batch Loss: 2.300800224475097e-05\n",
      "Epoch 3068, Loss: 0.0023434523641299165, Final Batch Loss: 5.075813078292413e-06\n",
      "Epoch 3069, Loss: 0.0006085906425141729, Final Batch Loss: 6.60177247482352e-05\n",
      "Epoch 3070, Loss: 0.001325428518384797, Final Batch Loss: 5.364379376260331e-07\n",
      "Epoch 3071, Loss: 0.0010544960723564145, Final Batch Loss: 9.693453648651484e-06\n",
      "Epoch 3072, Loss: 0.0008074541365203913, Final Batch Loss: 1.695763785392046e-05\n",
      "Epoch 3073, Loss: 0.0012210208942633471, Final Batch Loss: 8.135058124025818e-06\n",
      "Epoch 3074, Loss: 0.0032818959134601755, Final Batch Loss: 2.7643194698612206e-05\n",
      "Epoch 3075, Loss: 0.0007396500368486159, Final Batch Loss: 0.00011043380800401792\n",
      "Epoch 3076, Loss: 0.0030450013603058323, Final Batch Loss: 3.099268951700651e-06\n",
      "Epoch 3077, Loss: 0.018960046474603587, Final Batch Loss: 2.8432312319637276e-05\n",
      "Epoch 3078, Loss: 0.002067706096568145, Final Batch Loss: 9.294905612478033e-05\n",
      "Epoch 3079, Loss: 0.006713647895594477, Final Batch Loss: 2.2730755517841317e-05\n",
      "Epoch 3080, Loss: 0.0006594526639673859, Final Batch Loss: 3.2112759072333574e-05\n",
      "Epoch 3081, Loss: 0.011433718343141663, Final Batch Loss: 0.00011161580187035725\n",
      "Epoch 3082, Loss: 0.00506810967635829, Final Batch Loss: 0.0002867064904421568\n",
      "Epoch 3083, Loss: 0.0007586700089632359, Final Batch Loss: 7.773940888000652e-05\n",
      "Epoch 3084, Loss: 0.0003461341493675718, Final Batch Loss: 1.9219403839088045e-05\n",
      "Epoch 3085, Loss: 0.0008061110947892303, Final Batch Loss: 4.80353191960603e-05\n",
      "Epoch 3086, Loss: 0.0016940938021434704, Final Batch Loss: 2.391587804595474e-05\n",
      "Epoch 3087, Loss: 0.0016064349983935244, Final Batch Loss: 0.00010712558287195861\n",
      "Epoch 3088, Loss: 0.0008820980192467687, Final Batch Loss: 1.2269466424186248e-05\n",
      "Epoch 3089, Loss: 0.001328647626678503, Final Batch Loss: 3.1886982014839305e-06\n",
      "Epoch 3090, Loss: 0.00033671940013846324, Final Batch Loss: 1.937148681463441e-07\n",
      "Epoch 3091, Loss: 0.000715333532752993, Final Batch Loss: 1.0185111932514701e-05\n",
      "Epoch 3092, Loss: 0.0006910394440637901, Final Batch Loss: 0.00016615008644293994\n",
      "Epoch 3093, Loss: 0.00361766287824139, Final Batch Loss: 0.0023056096397340298\n",
      "Epoch 3094, Loss: 0.0016287502949126065, Final Batch Loss: 0.0003249408910050988\n",
      "Epoch 3095, Loss: 0.0004820680187549442, Final Batch Loss: 1.1701453331625089e-05\n",
      "Epoch 3096, Loss: 0.0015475700638489798, Final Batch Loss: 0.00033467626781202853\n",
      "Epoch 3097, Loss: 0.0008280515626211127, Final Batch Loss: 7.3230780799349304e-06\n",
      "Epoch 3098, Loss: 0.000577235779928742, Final Batch Loss: 6.60760561004281e-05\n",
      "Epoch 3099, Loss: 0.0027794634479505476, Final Batch Loss: 0.00021040323190391064\n",
      "Epoch 3100, Loss: 0.0017734303746692603, Final Batch Loss: 4.6080403990345076e-05\n",
      "Epoch 3101, Loss: 0.0005168805837456603, Final Batch Loss: 4.9400634452467784e-05\n",
      "Epoch 3102, Loss: 0.00023104923366190633, Final Batch Loss: 6.340284744510427e-05\n",
      "Epoch 3103, Loss: 0.0001129904394474579, Final Batch Loss: 1.8903878299170174e-05\n",
      "Epoch 3104, Loss: 0.0007885779438439044, Final Batch Loss: 1.7384685691013146e-08\n",
      "Epoch 3105, Loss: 0.0009757516381796449, Final Batch Loss: 2.8903770726174116e-05\n",
      "Epoch 3106, Loss: 0.0004283826587538897, Final Batch Loss: 5.041533199801052e-07\n",
      "Epoch 3107, Loss: 0.00087396736125811, Final Batch Loss: 1.3351349480217323e-05\n",
      "Epoch 3108, Loss: 0.0002318007705071068, Final Batch Loss: 6.56849488223088e-06\n",
      "Epoch 3109, Loss: 0.0068102886634733295, Final Batch Loss: 1.8125099813914858e-05\n",
      "Epoch 3110, Loss: 0.0012762772712449078, Final Batch Loss: 0.0010514064924791455\n",
      "Epoch 3111, Loss: 0.014179120641756526, Final Batch Loss: 2.3096731638361234e-07\n",
      "Epoch 3112, Loss: 0.014929245095117949, Final Batch Loss: 0.01430931594222784\n",
      "Epoch 3113, Loss: 0.0013907165084674489, Final Batch Loss: 0.0008682963089086115\n",
      "Epoch 3114, Loss: 0.0014082354919082718, Final Batch Loss: 1.738965693220962e-05\n",
      "Epoch 3115, Loss: 0.03407065544433863, Final Batch Loss: 0.0004653490905184299\n",
      "Epoch 3116, Loss: 0.06872061035392107, Final Batch Loss: 4.6053784899413586e-05\n",
      "Epoch 3117, Loss: 0.04721618853363907, Final Batch Loss: 9.280570520786569e-05\n",
      "Epoch 3118, Loss: 0.011064728591009043, Final Batch Loss: 0.00043694497435353696\n",
      "Epoch 3119, Loss: 0.00247369540502973, Final Batch Loss: 3.1292202606891806e-07\n",
      "Epoch 3120, Loss: 0.00855681742541492, Final Batch Loss: 0.0013525470858439803\n",
      "Epoch 3121, Loss: 0.0013439280592137948, Final Batch Loss: 2.526420576032251e-05\n",
      "Epoch 3122, Loss: 0.0032293718177243136, Final Batch Loss: 0.002750840038061142\n",
      "Epoch 3123, Loss: 0.0016830273088999093, Final Batch Loss: 0.0004025243397336453\n",
      "Epoch 3124, Loss: 0.018182135536221722, Final Batch Loss: 1.4876130762786488e-06\n",
      "Epoch 3125, Loss: 0.015019136586488457, Final Batch Loss: 3.635821121861227e-05\n",
      "Epoch 3126, Loss: 0.002465672507241834, Final Batch Loss: 0.0008879248052835464\n",
      "Epoch 3127, Loss: 0.003066218545427546, Final Batch Loss: 0.0014709443785250187\n",
      "Epoch 3128, Loss: 0.004633589377590397, Final Batch Loss: 8.219233677664306e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3129, Loss: 0.0016003427444957197, Final Batch Loss: 0.00012211967259645462\n",
      "Epoch 3130, Loss: 0.0017678355710586402, Final Batch Loss: 1.783124730536656e-06\n",
      "Epoch 3131, Loss: 0.001138047744461801, Final Batch Loss: 0.0002209543454227969\n",
      "Epoch 3132, Loss: 0.0017199828544107731, Final Batch Loss: 3.2201434805756435e-05\n",
      "Epoch 3133, Loss: 0.0009042391102411784, Final Batch Loss: 0.00021806203585583717\n",
      "Epoch 3134, Loss: 0.0025689361314107373, Final Batch Loss: 4.735611128126038e-06\n",
      "Epoch 3135, Loss: 0.0009525452460366068, Final Batch Loss: 1.782110302883666e-05\n",
      "Epoch 3136, Loss: 0.0035269043919470278, Final Batch Loss: 4.636302946892101e-06\n",
      "Epoch 3137, Loss: 0.00202792286287945, Final Batch Loss: 4.470345515983354e-08\n",
      "Epoch 3138, Loss: 0.0015634094743290916, Final Batch Loss: 0.0005556900869123638\n",
      "Epoch 3139, Loss: 0.002150651504052803, Final Batch Loss: 0.0017414743779227138\n",
      "Epoch 3140, Loss: 0.001305341216114364, Final Batch Loss: 4.967053435223079e-09\n",
      "Epoch 3141, Loss: 0.0005872634582715364, Final Batch Loss: 6.606141482734529e-07\n",
      "Epoch 3142, Loss: 0.0005947120662312955, Final Batch Loss: 4.2996573029085994e-05\n",
      "Epoch 3143, Loss: 0.0016788510438345838, Final Batch Loss: 1.0334671969758347e-05\n",
      "Epoch 3144, Loss: 0.0028888920205645263, Final Batch Loss: 0.00011008305591531098\n",
      "Epoch 3145, Loss: 0.0015110087297216523, Final Batch Loss: 0.00019790099759120494\n",
      "Epoch 3146, Loss: 0.0010266180870530661, Final Batch Loss: 8.992770017357543e-05\n",
      "Epoch 3147, Loss: 0.002520699199521914, Final Batch Loss: 0.00011959686526097357\n",
      "Epoch 3148, Loss: 0.0010955382246038425, Final Batch Loss: 1.6788059156169766e-06\n",
      "Epoch 3149, Loss: 0.001145755389813985, Final Batch Loss: 5.861053864464338e-07\n",
      "Epoch 3150, Loss: 0.02128107754310804, Final Batch Loss: 2.5977008135669166e-06\n",
      "Epoch 3151, Loss: 0.0009352647308844553, Final Batch Loss: 2.682196793557523e-07\n",
      "Epoch 3152, Loss: 0.002154660651285667, Final Batch Loss: 0.00011319350596750155\n",
      "Epoch 3153, Loss: 0.004354740754934028, Final Batch Loss: 0.0007327827042900026\n",
      "Epoch 3154, Loss: 0.00057819639630452, Final Batch Loss: 5.811424443891156e-07\n",
      "Epoch 3155, Loss: 0.0009084106677619275, Final Batch Loss: 4.154977432335727e-05\n",
      "Epoch 3156, Loss: 0.016667734744260088, Final Batch Loss: 0.0005311925197020173\n",
      "Epoch 3157, Loss: 0.001500987600593362, Final Batch Loss: 0.000907468143850565\n",
      "Epoch 3158, Loss: 0.0007065272839099634, Final Batch Loss: 0.0005005167331546545\n",
      "Epoch 3159, Loss: 0.020224098198013962, Final Batch Loss: 4.137278665439226e-06\n",
      "Epoch 3160, Loss: 0.0013516919025278185, Final Batch Loss: 4.430334229255095e-06\n",
      "Epoch 3161, Loss: 0.0005630821044348977, Final Batch Loss: 2.558019502885145e-07\n",
      "Epoch 3162, Loss: 0.0009900482061766525, Final Batch Loss: 2.7243538625043584e-06\n",
      "Epoch 3163, Loss: 0.001008840605209116, Final Batch Loss: 0.00022432877449318767\n",
      "Epoch 3164, Loss: 0.00046275174827314913, Final Batch Loss: 2.7094392862636596e-06\n",
      "Epoch 3165, Loss: 0.003126278897980228, Final Batch Loss: 0.001449761912226677\n",
      "Epoch 3166, Loss: 0.003560029725122149, Final Batch Loss: 1.884145058284048e-05\n",
      "Epoch 3167, Loss: 0.0007896626057117828, Final Batch Loss: 3.1564422897645272e-06\n",
      "Epoch 3168, Loss: 0.0004779927953677543, Final Batch Loss: 4.09759059039061e-06\n",
      "Epoch 3169, Loss: 0.0012236170950927772, Final Batch Loss: 0.00012128314847359434\n",
      "Epoch 3170, Loss: 0.0015072708556544967, Final Batch Loss: 0.00036988724605180323\n",
      "Epoch 3171, Loss: 0.0022054958672015346, Final Batch Loss: 1.3503768968803342e-05\n",
      "Epoch 3172, Loss: 0.0010674950462998822, Final Batch Loss: 1.5238591004163027e-05\n",
      "Epoch 3173, Loss: 0.00019859348602579985, Final Batch Loss: 1.0182437648609266e-07\n",
      "Epoch 3174, Loss: 0.0007069857570058957, Final Batch Loss: 5.031023192714201e-06\n",
      "Epoch 3175, Loss: 0.0008900364118744619, Final Batch Loss: 0.00018836831441149116\n",
      "Epoch 3176, Loss: 0.0010740534198703244, Final Batch Loss: 4.8329762648791075e-05\n",
      "Epoch 3177, Loss: 0.008821699550026096, Final Batch Loss: 2.201295137638226e-05\n",
      "Epoch 3178, Loss: 0.0017455167981097475, Final Batch Loss: 0.00016251746274065226\n",
      "Epoch 3179, Loss: 0.0011850602263621113, Final Batch Loss: 0.0010502254590392113\n",
      "Epoch 3180, Loss: 0.0012021730908600148, Final Batch Loss: 3.674940307973884e-05\n",
      "Epoch 3181, Loss: 0.0014600412687286735, Final Batch Loss: 0.0010933690937235951\n",
      "Epoch 3182, Loss: 0.0011878733075718628, Final Batch Loss: 2.8609374567167833e-06\n",
      "Epoch 3183, Loss: 0.0003810186681221239, Final Batch Loss: 7.047292456263676e-05\n",
      "Epoch 3184, Loss: 0.0014870402492306312, Final Batch Loss: 0.00012874747335445136\n",
      "Epoch 3185, Loss: 0.000806223782547022, Final Batch Loss: 4.2714377741503995e-06\n",
      "Epoch 3186, Loss: 0.0015197238753899, Final Batch Loss: 6.70254448777996e-05\n",
      "Epoch 3187, Loss: 0.0008946262746576394, Final Batch Loss: 8.121055543597322e-07\n",
      "Epoch 3188, Loss: 0.0041114548439509235, Final Batch Loss: 0.0038372210692614317\n",
      "Epoch 3189, Loss: 0.002406213869107887, Final Batch Loss: 0.0004718910495284945\n",
      "Epoch 3190, Loss: 0.0007861980047891848, Final Batch Loss: 0.0001335335400654003\n",
      "Epoch 3191, Loss: 0.0004955965256101535, Final Batch Loss: 3.8494417253787105e-07\n",
      "Epoch 3192, Loss: 0.0011462736383123229, Final Batch Loss: 1.7384621742166928e-07\n",
      "Epoch 3193, Loss: 0.00035177475001546554, Final Batch Loss: 9.634167327021714e-06\n",
      "Epoch 3194, Loss: 0.00029856126639060676, Final Batch Loss: 0.00015720633382443339\n",
      "Epoch 3195, Loss: 0.00038932471761654597, Final Batch Loss: 1.8169032045989297e-05\n",
      "Epoch 3196, Loss: 0.0014018467409186997, Final Batch Loss: 6.151015986688435e-05\n",
      "Epoch 3197, Loss: 0.000413297477280139, Final Batch Loss: 7.475104212062433e-05\n",
      "Epoch 3198, Loss: 0.0004398405653773807, Final Batch Loss: 7.322278543142602e-05\n",
      "Epoch 3199, Loss: 0.04160255386796052, Final Batch Loss: 8.947093010647222e-05\n",
      "Epoch 3200, Loss: 0.0012909942015539855, Final Batch Loss: 0.000597373757045716\n",
      "Epoch 3201, Loss: 0.0005264531760076352, Final Batch Loss: 0.00021040602587163448\n",
      "Epoch 3202, Loss: 0.00021680120335076936, Final Batch Loss: 0.00010263576405122876\n",
      "Epoch 3203, Loss: 0.0022865671506338003, Final Batch Loss: 5.786585575151548e-07\n",
      "Epoch 3204, Loss: 0.010908052032391424, Final Batch Loss: 1.7857439161161892e-05\n",
      "Epoch 3205, Loss: 0.017226092822966166, Final Batch Loss: 0.00029473446193151176\n",
      "Epoch 3206, Loss: 0.0003684383599420471, Final Batch Loss: 1.8750041590465116e-06\n",
      "Epoch 3207, Loss: 0.0027889709890587255, Final Batch Loss: 0.0003528895031195134\n",
      "Epoch 3208, Loss: 0.0009982824846161975, Final Batch Loss: 1.713630268795896e-07\n",
      "Epoch 3209, Loss: 0.008797355672868434, Final Batch Loss: 0.008028914220631123\n",
      "Epoch 3210, Loss: 0.0012252568558324128, Final Batch Loss: 0.00014240306336432695\n",
      "Epoch 3211, Loss: 0.0017033949116012082, Final Batch Loss: 0.0003460900916252285\n",
      "Epoch 3212, Loss: 0.0010303884373570327, Final Batch Loss: 3.8752263208152726e-05\n",
      "Epoch 3213, Loss: 0.0013453680658130907, Final Batch Loss: 7.687549805268645e-05\n",
      "Epoch 3214, Loss: 0.0010967385229605497, Final Batch Loss: 1.6117761560963118e-06\n",
      "Epoch 3215, Loss: 0.0026780928747029975, Final Batch Loss: 0.0001256318500963971\n",
      "Epoch 3216, Loss: 0.0007288743854587665, Final Batch Loss: 1.545698796689976e-05\n",
      "Epoch 3217, Loss: 0.00443471575545118, Final Batch Loss: 8.204839105019346e-06\n",
      "Epoch 3218, Loss: 0.0005050293436852371, Final Batch Loss: 4.7683329285064247e-07\n",
      "Epoch 3219, Loss: 0.0006731830217177048, Final Batch Loss: 0.00012891371443402022\n",
      "Epoch 3220, Loss: 0.0006110395779614919, Final Batch Loss: 3.3028509278665297e-06\n",
      "Epoch 3221, Loss: 0.0005944280474068364, Final Batch Loss: 5.9824829804711044e-05\n",
      "Epoch 3222, Loss: 0.0003329596636376664, Final Batch Loss: 3.238301133023924e-06\n",
      "Epoch 3223, Loss: 0.00038086787446900416, Final Batch Loss: 6.757936353096738e-05\n",
      "Epoch 3224, Loss: 0.00048083572619361803, Final Batch Loss: 0.00024131352256517857\n",
      "Epoch 3225, Loss: 0.0006066931453005964, Final Batch Loss: 2.6199957119388273e-06\n",
      "Epoch 3226, Loss: 0.002666931144631235, Final Batch Loss: 0.0017969211330637336\n",
      "Epoch 3227, Loss: 0.0004028248988561245, Final Batch Loss: 3.226028866265551e-06\n",
      "Epoch 3228, Loss: 0.0008195597833946522, Final Batch Loss: 0.0004773031978402287\n",
      "Epoch 3229, Loss: 0.0008156974775674897, Final Batch Loss: 4.967053435223079e-09\n",
      "Epoch 3230, Loss: 0.0007896791850043883, Final Batch Loss: 1.7880757923194324e-06\n",
      "Epoch 3231, Loss: 0.000360952461164743, Final Batch Loss: 1.430462475582317e-06\n",
      "Epoch 3232, Loss: 0.0021664422947651474, Final Batch Loss: 1.4131055650068447e-06\n",
      "Epoch 3233, Loss: 0.00026524398708716035, Final Batch Loss: 1.8820632249116898e-05\n",
      "Epoch 3234, Loss: 0.0006331700024020392, Final Batch Loss: 0.00039853985072113574\n",
      "Epoch 3235, Loss: 0.0005576661757231705, Final Batch Loss: 1.1250077704971773e-06\n",
      "Epoch 3236, Loss: 0.0009839272611316119, Final Batch Loss: 1.0820487659657374e-05\n",
      "Epoch 3237, Loss: 0.0007144898572732927, Final Batch Loss: 5.344155943021178e-05\n",
      "Epoch 3238, Loss: 0.0004313993576943176, Final Batch Loss: 1.62447558977874e-05\n",
      "Epoch 3239, Loss: 4.6997229219414294e-05, Final Batch Loss: 4.2144060898863245e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3240, Loss: 0.0005057952548668254, Final Batch Loss: 5.598629286396317e-05\n",
      "Epoch 3241, Loss: 0.00042736676459753653, Final Batch Loss: 8.127331057039555e-06\n",
      "Epoch 3242, Loss: 0.00025182339231832884, Final Batch Loss: 4.175836147624068e-05\n",
      "Epoch 3243, Loss: 0.0017394382593920454, Final Batch Loss: 0.0002567904884926975\n",
      "Epoch 3244, Loss: 0.0006695354724897129, Final Batch Loss: 9.437390957600655e-08\n",
      "Epoch 3245, Loss: 0.0005768403352703899, Final Batch Loss: 0.00018620594346430153\n",
      "Epoch 3246, Loss: 0.0007273872415680671, Final Batch Loss: 1.562904435559176e-05\n",
      "Epoch 3247, Loss: 0.001013775010505924, Final Batch Loss: 0.0002313646109541878\n",
      "Epoch 3248, Loss: 0.0008845766697049839, Final Batch Loss: 7.475282473023981e-07\n",
      "Epoch 3249, Loss: 0.00037786891729751915, Final Batch Loss: 3.3279169997513236e-07\n",
      "Epoch 3250, Loss: 0.0009216229300363921, Final Batch Loss: 3.804321386269294e-05\n",
      "Epoch 3251, Loss: 0.0004834165738429874, Final Batch Loss: 6.272122118389234e-05\n",
      "Epoch 3252, Loss: 0.0007854551258503761, Final Batch Loss: 2.8808787533307623e-07\n",
      "Epoch 3253, Loss: 0.0008453859077235393, Final Batch Loss: 0.000471692270366475\n",
      "Epoch 3254, Loss: 0.000334140827817464, Final Batch Loss: 1.7210563783010002e-06\n",
      "Epoch 3255, Loss: 0.0004832645062826657, Final Batch Loss: 5.215401799318897e-08\n",
      "Epoch 3256, Loss: 0.0004316771325072466, Final Batch Loss: 5.4637563806636535e-08\n",
      "Epoch 3257, Loss: 0.0005310356555128237, Final Batch Loss: 0.000252368685323745\n",
      "Epoch 3258, Loss: 0.00032293928052240517, Final Batch Loss: 1.299972427659668e-05\n",
      "Epoch 3259, Loss: 0.0003974549117629067, Final Batch Loss: 8.222009455494117e-06\n",
      "Epoch 3260, Loss: 0.0011791703291237354, Final Batch Loss: 0.00042323756497353315\n",
      "Epoch 3261, Loss: 0.00030489530763588846, Final Batch Loss: 2.4837929231580347e-05\n",
      "Epoch 3262, Loss: 9.48946897665337e-05, Final Batch Loss: 6.630914981542446e-07\n",
      "Epoch 3263, Loss: 0.00023457227052858798, Final Batch Loss: 4.6664074034197256e-05\n",
      "Epoch 3264, Loss: 0.0010652233104337938, Final Batch Loss: 8.725770385353826e-06\n",
      "Epoch 3265, Loss: 0.00023272070257007726, Final Batch Loss: 5.393682386056753e-06\n",
      "Epoch 3266, Loss: 0.0002839593616941194, Final Batch Loss: 7.4505792646561986e-09\n",
      "Epoch 3267, Loss: 0.003473386843324988, Final Batch Loss: 2.9207794796093367e-05\n",
      "Epoch 3268, Loss: 0.001734557343297638, Final Batch Loss: 0.0005817448254674673\n",
      "Epoch 3269, Loss: 0.00023229022372106556, Final Batch Loss: 3.0316929041873664e-05\n",
      "Epoch 3270, Loss: 0.0019152756749463151, Final Batch Loss: 0.0014290489489212632\n",
      "Epoch 3271, Loss: 0.07280744310355658, Final Batch Loss: 0.07263987511396408\n",
      "Epoch 3272, Loss: 0.03535569476207456, Final Batch Loss: 0.035094648599624634\n",
      "Epoch 3273, Loss: 0.002343797410503612, Final Batch Loss: 5.217525540501811e-06\n",
      "Epoch 3274, Loss: 0.006944749327885802, Final Batch Loss: 5.815432814415544e-05\n",
      "Epoch 3275, Loss: 0.0008517425976606319, Final Batch Loss: 0.0006873084348626435\n",
      "Epoch 3276, Loss: 0.009364408389956225, Final Batch Loss: 0.0\n",
      "Epoch 3277, Loss: 0.0006894312755321153, Final Batch Loss: 2.428939478704706e-05\n",
      "Epoch 3278, Loss: 0.00025480261319899, Final Batch Loss: 4.411450572661124e-05\n",
      "Epoch 3279, Loss: 0.0011847288678836776, Final Batch Loss: 0.0006312127225100994\n",
      "Epoch 3280, Loss: 0.00860717952309642, Final Batch Loss: 0.003648134181275964\n",
      "Epoch 3281, Loss: 0.0007967399214976467, Final Batch Loss: 0.00011283386993454769\n",
      "Epoch 3282, Loss: 0.0013250869403691468, Final Batch Loss: 2.4909120384108974e-06\n",
      "Epoch 3283, Loss: 0.0020897530084766913, Final Batch Loss: 0.00015628492110408843\n",
      "Epoch 3284, Loss: 0.004660611130020698, Final Batch Loss: 0.00035874685272574425\n",
      "Epoch 3285, Loss: 0.005688606015610276, Final Batch Loss: 5.034087735111825e-05\n",
      "Epoch 3286, Loss: 0.0020649997604778036, Final Batch Loss: 0.00044058929779566824\n",
      "Epoch 3287, Loss: 0.003554374910891056, Final Batch Loss: 0.00031069928081706166\n",
      "Epoch 3288, Loss: 0.0005609055624518078, Final Batch Loss: 8.731232810532674e-06\n",
      "Epoch 3289, Loss: 0.0020327771635493264, Final Batch Loss: 0.001223612343892455\n",
      "Epoch 3290, Loss: 0.003159962987410836, Final Batch Loss: 0.0004169022140558809\n",
      "Epoch 3291, Loss: 0.03747541363190976, Final Batch Loss: 0.036089327186346054\n",
      "Epoch 3292, Loss: 0.0002716720737225842, Final Batch Loss: 0.0001186467197840102\n",
      "Epoch 3293, Loss: 0.0007895910548540996, Final Batch Loss: 5.075971785117872e-06\n",
      "Epoch 3294, Loss: 0.011210133893655438, Final Batch Loss: 7.712621481914539e-06\n",
      "Epoch 3295, Loss: 0.003632813202173679, Final Batch Loss: 1.9868210188178637e-08\n",
      "Epoch 3296, Loss: 0.0006461395471433207, Final Batch Loss: 2.937818180726026e-06\n",
      "Epoch 3297, Loss: 0.0005769367389802937, Final Batch Loss: 2.2103358787717298e-07\n",
      "Epoch 3298, Loss: 0.005338967643183423, Final Batch Loss: 4.122520113014616e-05\n",
      "Epoch 3299, Loss: 0.002676286074233758, Final Batch Loss: 1.661459350543737e-06\n",
      "Epoch 3300, Loss: 0.0024227415145787745, Final Batch Loss: 1.1895775742232217e-06\n",
      "Epoch 3301, Loss: 0.0013104664776619757, Final Batch Loss: 2.7406773369875737e-05\n",
      "Epoch 3302, Loss: 0.007882969628496994, Final Batch Loss: 5.9604587931971764e-08\n",
      "Epoch 3303, Loss: 0.0005596438022621442, Final Batch Loss: 0.00012807323946617544\n",
      "Epoch 3304, Loss: 0.002479842267348431, Final Batch Loss: 0.00019833901023957878\n",
      "Epoch 3305, Loss: 0.008926229222254278, Final Batch Loss: 2.856050400623644e-07\n",
      "Epoch 3306, Loss: 0.011456117339250227, Final Batch Loss: 2.0116537768899434e-07\n",
      "Epoch 3307, Loss: 0.0012689979538151874, Final Batch Loss: 2.4835193812577927e-07\n",
      "Epoch 3308, Loss: 0.001165863184724003, Final Batch Loss: 0.00026319993776269257\n",
      "Epoch 3309, Loss: 0.0011654694030767132, Final Batch Loss: 9.06475634110393e-07\n",
      "Epoch 3310, Loss: 0.0009463146183747995, Final Batch Loss: 5.68723805827176e-07\n",
      "Epoch 3311, Loss: 0.0009086607610697683, Final Batch Loss: 6.600717370019993e-06\n",
      "Epoch 3312, Loss: 0.0021209484548307955, Final Batch Loss: 0.001303496421314776\n",
      "Epoch 3313, Loss: 0.0009847333458310459, Final Batch Loss: 3.621966243372299e-05\n",
      "Epoch 3314, Loss: 0.0008286959273391403, Final Batch Loss: 0.0003761004190891981\n",
      "Epoch 3315, Loss: 0.0008667849733683397, Final Batch Loss: 1.4017042303748894e-05\n",
      "Epoch 3316, Loss: 0.00044865336349175777, Final Batch Loss: 5.0436541641829535e-05\n",
      "Epoch 3317, Loss: 0.007793347227561753, Final Batch Loss: 0.000904455257114023\n",
      "Epoch 3318, Loss: 0.0007427235555041989, Final Batch Loss: 5.878156571270665e-06\n",
      "Epoch 3319, Loss: 0.0011851680210384075, Final Batch Loss: 7.782237662468106e-05\n",
      "Epoch 3320, Loss: 0.0011665671354421647, Final Batch Loss: 1.8911277948063798e-05\n",
      "Epoch 3321, Loss: 0.0015963955465849722, Final Batch Loss: 0.00017286342335864902\n",
      "Epoch 3322, Loss: 0.0005618718205369078, Final Batch Loss: 5.1365961553528905e-05\n",
      "Epoch 3323, Loss: 0.000693653737130262, Final Batch Loss: 1.524863932900189e-06\n",
      "Epoch 3324, Loss: 0.003985203283541239, Final Batch Loss: 7.947283364728719e-08\n",
      "Epoch 3325, Loss: 0.0008318493223669066, Final Batch Loss: 6.955612207093509e-06\n",
      "Epoch 3326, Loss: 0.002424997688649455, Final Batch Loss: 0.0018121595494449139\n",
      "Epoch 3327, Loss: 0.0018744259396044072, Final Batch Loss: 0.00010199919779552147\n",
      "Epoch 3328, Loss: 0.00028845555516454624, Final Batch Loss: 1.5184560652414802e-05\n",
      "Epoch 3329, Loss: 0.00039266454041353427, Final Batch Loss: 7.515193283325061e-05\n",
      "Epoch 3330, Loss: 0.00039275796086712944, Final Batch Loss: 2.930545406343299e-07\n",
      "Epoch 3331, Loss: 0.000333079688317639, Final Batch Loss: 3.650768860552489e-07\n",
      "Epoch 3332, Loss: 0.000628953603154514, Final Batch Loss: 0.0001132198958657682\n",
      "Epoch 3333, Loss: 0.0009732241674953457, Final Batch Loss: 2.856037042420212e-07\n",
      "Epoch 3334, Loss: 0.004352702951706533, Final Batch Loss: 3.2534049410060106e-07\n",
      "Epoch 3335, Loss: 0.0004539226282531672, Final Batch Loss: 1.2665975646086736e-07\n",
      "Epoch 3336, Loss: 0.0031393287752052856, Final Batch Loss: 2.6323793917981675e-06\n",
      "Epoch 3337, Loss: 0.000557287348783575, Final Batch Loss: 7.994579937076196e-05\n",
      "Epoch 3338, Loss: 0.001813628365113118, Final Batch Loss: 3.253407214742765e-07\n",
      "Epoch 3339, Loss: 0.0021455707574205007, Final Batch Loss: 9.874423267319798e-05\n",
      "Epoch 3340, Loss: 0.0003434727414060035, Final Batch Loss: 8.139503734128084e-06\n",
      "Epoch 3341, Loss: 0.0003311376784367326, Final Batch Loss: 1.0430797914295908e-07\n",
      "Epoch 3342, Loss: 0.0007179794301919173, Final Batch Loss: 0.0001658010296523571\n",
      "Epoch 3343, Loss: 0.00241337827173993, Final Batch Loss: 0.0002271509583806619\n",
      "Epoch 3344, Loss: 0.018166699541325215, Final Batch Loss: 0.0012459909776225686\n",
      "Epoch 3345, Loss: 0.0009298685727117117, Final Batch Loss: 5.946501551079564e-05\n",
      "Epoch 3346, Loss: 0.0008885770330380183, Final Batch Loss: 8.13544393167831e-05\n",
      "Epoch 3347, Loss: 0.00019784953477142153, Final Batch Loss: 3.3030849522219796e-07\n",
      "Epoch 3348, Loss: 0.001621329224690271, Final Batch Loss: 9.71081590250833e-06\n",
      "Epoch 3349, Loss: 0.0004940370345138945, Final Batch Loss: 7.791793905198574e-05\n",
      "Epoch 3350, Loss: 0.0005450562566693407, Final Batch Loss: 2.9776274459436536e-06\n",
      "Epoch 3351, Loss: 0.00037469971903192345, Final Batch Loss: 4.142248144489713e-06\n",
      "Epoch 3352, Loss: 0.0009300128294853494, Final Batch Loss: 0.0003135497390758246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3353, Loss: 0.001146678047007299, Final Batch Loss: 2.0749726900248788e-05\n",
      "Epoch 3354, Loss: 0.00022098826048022602, Final Batch Loss: 0.00014305250078905374\n",
      "Epoch 3355, Loss: 0.000845099326397758, Final Batch Loss: 0.0003234473115298897\n",
      "Epoch 3356, Loss: 0.0002629742284625536, Final Batch Loss: 0.00012308088480494916\n",
      "Epoch 3357, Loss: 0.00614488786959555, Final Batch Loss: 0.00511548575013876\n",
      "Epoch 3358, Loss: 0.0007108883720263748, Final Batch Loss: 2.955385696168378e-07\n",
      "Epoch 3359, Loss: 0.0017046146044918942, Final Batch Loss: 2.1358256674375298e-07\n",
      "Epoch 3360, Loss: 0.0012126318324590102, Final Batch Loss: 0.00038092685281299055\n",
      "Epoch 3361, Loss: 0.00824304263611797, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 3362, Loss: 0.0013475122104864568, Final Batch Loss: 8.191703091142699e-05\n",
      "Epoch 3363, Loss: 0.000497272899337986, Final Batch Loss: 7.400087270070799e-06\n",
      "Epoch 3364, Loss: 0.0041727165480551776, Final Batch Loss: 0.004018085543066263\n",
      "Epoch 3365, Loss: 0.0006314133461273741, Final Batch Loss: 1.0248037142446265e-05\n",
      "Epoch 3366, Loss: 0.00024948324630713614, Final Batch Loss: 1.9569472442526603e-06\n",
      "Epoch 3367, Loss: 0.0002609444409245043, Final Batch Loss: 1.8666201867745258e-05\n",
      "Epoch 3368, Loss: 0.0008064067933446495, Final Batch Loss: 0.0005786338588222861\n",
      "Epoch 3369, Loss: 0.00020129191307205474, Final Batch Loss: 3.974250648752786e-05\n",
      "Epoch 3370, Loss: 0.00044711566806654446, Final Batch Loss: 1.1257303413003683e-05\n",
      "Epoch 3371, Loss: 0.0008759058604823622, Final Batch Loss: 6.208778700056428e-07\n",
      "Epoch 3372, Loss: 0.00021082726561871823, Final Batch Loss: 3.5363973438506946e-06\n",
      "Epoch 3373, Loss: 0.00034448686164978426, Final Batch Loss: 1.1329568224027753e-05\n",
      "Epoch 3374, Loss: 0.0001787132275694603, Final Batch Loss: 7.624291811225703e-07\n",
      "Epoch 3375, Loss: 0.009225288395100506, Final Batch Loss: 0.0009026718325912952\n",
      "Epoch 3376, Loss: 0.00034731023612266654, Final Batch Loss: 1.6639575051158317e-07\n",
      "Epoch 3377, Loss: 0.00029569221260317136, Final Batch Loss: 1.6240608601947315e-05\n",
      "Epoch 3378, Loss: 0.003903996161170653, Final Batch Loss: 0.00014817329065408558\n",
      "Epoch 3379, Loss: 0.001800737274606945, Final Batch Loss: 0.0004399725003167987\n",
      "Epoch 3380, Loss: 0.0022512351752084214, Final Batch Loss: 4.917678234050982e-05\n",
      "Epoch 3381, Loss: 0.00039404038989232504, Final Batch Loss: 4.852298388868803e-06\n",
      "Epoch 3382, Loss: 0.00043572551150106165, Final Batch Loss: 9.934084488349981e-08\n",
      "Epoch 3383, Loss: 0.015377330877527129, Final Batch Loss: 0.014924801886081696\n",
      "Epoch 3384, Loss: 0.0003451719203440007, Final Batch Loss: 3.474714685580693e-05\n",
      "Epoch 3385, Loss: 0.0007561584043287439, Final Batch Loss: 6.860975190647878e-06\n",
      "Epoch 3386, Loss: 0.0009597224125172943, Final Batch Loss: 0.0003602064971346408\n",
      "Epoch 3387, Loss: 0.0005963686817267444, Final Batch Loss: 0.00010249359911540523\n",
      "Epoch 3388, Loss: 0.0004443828474904876, Final Batch Loss: 5.889248495805077e-05\n",
      "Epoch 3389, Loss: 0.002405417173577007, Final Batch Loss: 0.001985093578696251\n",
      "Epoch 3390, Loss: 0.0011907281209460052, Final Batch Loss: 5.806060016766423e-06\n",
      "Epoch 3391, Loss: 0.0404679786588531, Final Batch Loss: 0.00015934609109535813\n",
      "Epoch 3392, Loss: 0.00013839907528279127, Final Batch Loss: 2.2848375635931006e-07\n",
      "Epoch 3393, Loss: 0.0005263604539322841, Final Batch Loss: 7.152480065997224e-07\n",
      "Epoch 3394, Loss: 0.000337982821292826, Final Batch Loss: 5.215408236836083e-05\n",
      "Epoch 3395, Loss: 0.0005870221575605683, Final Batch Loss: 4.670746056945063e-05\n",
      "Epoch 3396, Loss: 0.004387647248222493, Final Batch Loss: 5.958823021501303e-05\n",
      "Epoch 3397, Loss: 0.0002971452408928599, Final Batch Loss: 3.595561065594666e-05\n",
      "Epoch 3398, Loss: 0.003155114365654299, Final Batch Loss: 0.0015143650816753507\n",
      "Epoch 3399, Loss: 0.0008590078648609278, Final Batch Loss: 1.4901139877565583e-07\n",
      "Epoch 3400, Loss: 0.0015917761747914483, Final Batch Loss: 0.0005372176528908312\n",
      "Epoch 3401, Loss: 0.0005810385796394257, Final Batch Loss: 7.13435883881175e-06\n",
      "Epoch 3402, Loss: 0.0010750875262601767, Final Batch Loss: 1.2290111953916494e-05\n",
      "Epoch 3403, Loss: 0.0015724318872401, Final Batch Loss: 4.4951585209673794e-07\n",
      "Epoch 3404, Loss: 0.0005049787414463935, Final Batch Loss: 9.646746548241936e-06\n",
      "Epoch 3405, Loss: 0.0006166822631712421, Final Batch Loss: 1.1503508176247124e-05\n",
      "Epoch 3406, Loss: 0.008816732250124915, Final Batch Loss: 5.256516669760458e-05\n",
      "Epoch 3407, Loss: 0.00024003814314710326, Final Batch Loss: 4.162154709774768e-06\n",
      "Epoch 3408, Loss: 0.0029949960080557503, Final Batch Loss: 0.0023665966000407934\n",
      "Epoch 3409, Loss: 0.0006178820185027689, Final Batch Loss: 7.574707865387609e-07\n",
      "Epoch 3410, Loss: 0.00041692163631523727, Final Batch Loss: 7.202183951449115e-07\n",
      "Epoch 3411, Loss: 0.0026111924889846705, Final Batch Loss: 0.00013985931582283229\n",
      "Epoch 3412, Loss: 0.0006166729908727575, Final Batch Loss: 2.7794470952358097e-05\n",
      "Epoch 3413, Loss: 0.004980498308590597, Final Batch Loss: 1.1424200607734747e-07\n",
      "Epoch 3414, Loss: 0.0011932352040275873, Final Batch Loss: 4.065177108714124e-06\n",
      "Epoch 3415, Loss: 0.00072071787508321, Final Batch Loss: 5.066358426120132e-07\n",
      "Epoch 3416, Loss: 0.00037140242147870595, Final Batch Loss: 9.438795132155064e-06\n",
      "Epoch 3417, Loss: 0.0029326194871828193, Final Batch Loss: 0.0023284556809812784\n",
      "Epoch 3418, Loss: 0.001963942744623637, Final Batch Loss: 4.06463113904465e-05\n",
      "Epoch 3419, Loss: 0.001334750424575759, Final Batch Loss: 0.00031762124854139984\n",
      "Epoch 3420, Loss: 0.00040033138941453217, Final Batch Loss: 1.5422134538312093e-06\n",
      "Epoch 3421, Loss: 0.0007057715241174378, Final Batch Loss: 2.7318783679675107e-08\n",
      "Epoch 3422, Loss: 0.00016366078824603392, Final Batch Loss: 7.599498417221184e-07\n",
      "Epoch 3423, Loss: 0.001489658371610858, Final Batch Loss: 4.4510699808597565e-05\n",
      "Epoch 3424, Loss: 0.000638495099337888, Final Batch Loss: 0.0002648659283295274\n",
      "Epoch 3425, Loss: 0.0003281623994553229, Final Batch Loss: 2.3493556000175886e-05\n",
      "Epoch 3426, Loss: 0.0008440603594408458, Final Batch Loss: 3.6231901958672097e-06\n",
      "Epoch 3427, Loss: 0.05067190572299296, Final Batch Loss: 8.575458923587576e-05\n",
      "Epoch 3428, Loss: 0.0004342725151218474, Final Batch Loss: 3.5616805689642206e-05\n",
      "Epoch 3429, Loss: 0.0005001280113674511, Final Batch Loss: 1.2020117310385103e-06\n",
      "Epoch 3430, Loss: 0.0001377821392907208, Final Batch Loss: 2.9627265121234814e-06\n",
      "Epoch 3431, Loss: 0.0036299294006312266, Final Batch Loss: 0.0032040553633123636\n",
      "Epoch 3432, Loss: 0.0009000139507406857, Final Batch Loss: 0.0007084810640662909\n",
      "Epoch 3433, Loss: 0.0006353413682518294, Final Batch Loss: 1.6011157640605234e-05\n",
      "Epoch 3434, Loss: 0.0018264431182615226, Final Batch Loss: 6.727021172991954e-06\n",
      "Epoch 3435, Loss: 0.0011046123217965942, Final Batch Loss: 4.3757518142228946e-05\n",
      "Epoch 3436, Loss: 0.0007777752659876569, Final Batch Loss: 3.446850996624562e-06\n",
      "Epoch 3437, Loss: 0.0003619459930632729, Final Batch Loss: 3.642884985310957e-05\n",
      "Epoch 3438, Loss: 0.00037911327945039375, Final Batch Loss: 3.1695559300715104e-05\n",
      "Epoch 3439, Loss: 0.0002276776467624586, Final Batch Loss: 3.238138378947042e-05\n",
      "Epoch 3440, Loss: 0.0006181304688652745, Final Batch Loss: 1.7380165445501916e-05\n",
      "Epoch 3441, Loss: 0.0008207089185816585, Final Batch Loss: 2.9802231438225135e-07\n",
      "Epoch 3442, Loss: 0.0003341204665048281, Final Batch Loss: 2.4413691789959557e-05\n",
      "Epoch 3443, Loss: 0.0008977792313089594, Final Batch Loss: 7.951103907544166e-05\n",
      "Epoch 3444, Loss: 0.0009328556676564403, Final Batch Loss: 3.377587063368992e-07\n",
      "Epoch 3445, Loss: 0.0002925094522652216, Final Batch Loss: 9.978544403566048e-05\n",
      "Epoch 3446, Loss: 0.0002643077245920722, Final Batch Loss: 1.2655576028919313e-05\n",
      "Epoch 3447, Loss: 0.003762159230348061, Final Batch Loss: 5.140857979313296e-07\n",
      "Epoch 3448, Loss: 0.0013050311190454522, Final Batch Loss: 5.7861714594764635e-05\n",
      "Epoch 3449, Loss: 0.0012547791811812203, Final Batch Loss: 0.0006689985748380423\n",
      "Epoch 3450, Loss: 0.00102784800765221, Final Batch Loss: 0.000761179777327925\n",
      "Epoch 3451, Loss: 7.947451501877367e-05, Final Batch Loss: 1.4702176258651889e-06\n",
      "Epoch 3452, Loss: 0.004588431740558008, Final Batch Loss: 3.555422154022381e-05\n",
      "Epoch 3453, Loss: 0.0001342838368145749, Final Batch Loss: 2.6746984076453373e-06\n",
      "Epoch 3454, Loss: 0.0008737281804371833, Final Batch Loss: 3.9487886738243105e-07\n",
      "Epoch 3455, Loss: 0.0001680584919085959, Final Batch Loss: 1.729274845274631e-05\n",
      "Epoch 3456, Loss: 0.00041378702326255734, Final Batch Loss: 6.942795607756125e-06\n",
      "Epoch 3457, Loss: 0.0013748752062383574, Final Batch Loss: 0.00021283210662659258\n",
      "Epoch 3458, Loss: 0.0009619717596365263, Final Batch Loss: 4.9670518365019234e-08\n",
      "Epoch 3459, Loss: 0.00026242943067700253, Final Batch Loss: 0.00014339153131004423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3460, Loss: 6.638726415530982e-05, Final Batch Loss: 1.5744980146337184e-06\n",
      "Epoch 3461, Loss: 0.00010620626437685132, Final Batch Loss: 3.352512749188463e-06\n",
      "Epoch 3462, Loss: 0.0007823910316915317, Final Batch Loss: 9.213807175001421e-07\n",
      "Epoch 3463, Loss: 0.0006062154534447473, Final Batch Loss: 0.00041762899491004646\n",
      "Epoch 3464, Loss: 0.00020346085011624382, Final Batch Loss: 3.088672019657679e-05\n",
      "Epoch 3465, Loss: 0.000973521175183123, Final Batch Loss: 0.000397743220673874\n",
      "Epoch 3466, Loss: 0.0003709021664235479, Final Batch Loss: 1.261597162738326e-06\n",
      "Epoch 3467, Loss: 0.0002655865816905134, Final Batch Loss: 3.652980694823782e-06\n",
      "Epoch 3468, Loss: 0.00030092335555309546, Final Batch Loss: 0.00018140702741220593\n",
      "Epoch 3469, Loss: 0.0005091749953862745, Final Batch Loss: 4.857679596170783e-05\n",
      "Epoch 3470, Loss: 7.996942349564051e-05, Final Batch Loss: 2.5512532374705188e-05\n",
      "Epoch 3471, Loss: 0.0001230968518939335, Final Batch Loss: 3.749033567146398e-05\n",
      "Epoch 3472, Loss: 0.00012226338662912895, Final Batch Loss: 5.5065102060325444e-05\n",
      "Epoch 3473, Loss: 0.0005133990562171675, Final Batch Loss: 3.615334571804851e-05\n",
      "Epoch 3474, Loss: 0.0003269106223342533, Final Batch Loss: 3.867042323690839e-05\n",
      "Epoch 3475, Loss: 0.000703149054061214, Final Batch Loss: 1.1288017958577257e-05\n",
      "Epoch 3476, Loss: 0.0001017626658494919, Final Batch Loss: 1.1523319471962168e-06\n",
      "Epoch 3477, Loss: 0.0001705489021333051, Final Batch Loss: 6.831582595623331e-06\n",
      "Epoch 3478, Loss: 0.0008184314010577509, Final Batch Loss: 1.0803205441334285e-06\n",
      "Epoch 3479, Loss: 0.0004560033295604171, Final Batch Loss: 3.948781852614047e-07\n",
      "Epoch 3480, Loss: 0.0006974575969991292, Final Batch Loss: 2.5828538241512433e-07\n",
      "Epoch 3481, Loss: 0.0004427804763054155, Final Batch Loss: 2.2276092295214767e-06\n",
      "Epoch 3482, Loss: 0.0019464187553239753, Final Batch Loss: 0.00017198767454829067\n",
      "Epoch 3483, Loss: 0.016646060670609586, Final Batch Loss: 0.00014290782564785331\n",
      "Epoch 3484, Loss: 0.00026459199784767407, Final Batch Loss: 1.4404417925106827e-07\n",
      "Epoch 3485, Loss: 0.00017219330629814067, Final Batch Loss: 5.036308266426204e-06\n",
      "Epoch 3486, Loss: 0.0008205903413909255, Final Batch Loss: 1.0753450624179095e-05\n",
      "Epoch 3487, Loss: 0.013890793430618942, Final Batch Loss: 0.0002818433858919889\n",
      "Epoch 3488, Loss: 0.0005244989079074003, Final Batch Loss: 0.00016740168211981654\n",
      "Epoch 3489, Loss: 0.0002796920625769417, Final Batch Loss: 8.090556548268069e-06\n",
      "Epoch 3490, Loss: 0.0013699675462248706, Final Batch Loss: 2.5578763143130345e-06\n",
      "Epoch 3491, Loss: 0.0012863990714322426, Final Batch Loss: 8.230749517679214e-05\n",
      "Epoch 3492, Loss: 0.00022180279756867094, Final Batch Loss: 8.397629244427662e-06\n",
      "Epoch 3493, Loss: 0.0001993941905311658, Final Batch Loss: 8.942307431425434e-06\n",
      "Epoch 3494, Loss: 0.0006963887281017378, Final Batch Loss: 0.00017056451179087162\n",
      "Epoch 3495, Loss: 0.001064606101863319, Final Batch Loss: 0.00020865746773779392\n",
      "Epoch 3496, Loss: 0.0012091159806004725, Final Batch Loss: 4.380339305498637e-05\n",
      "Epoch 3497, Loss: 0.00549871872510721, Final Batch Loss: 2.5580277451808797e-07\n",
      "Epoch 3498, Loss: 0.004672872351875412, Final Batch Loss: 0.00045014460920356214\n",
      "Epoch 3499, Loss: 0.0004887687973678112, Final Batch Loss: 0.00013791867240797728\n",
      "Epoch 3500, Loss: 0.0008687492105821093, Final Batch Loss: 3.2782341463644116e-07\n",
      "Epoch 3501, Loss: 0.0002115213792421855, Final Batch Loss: 5.792161027784459e-05\n",
      "Epoch 3502, Loss: 0.016309091754010296, Final Batch Loss: 6.709879016852938e-06\n",
      "Epoch 3503, Loss: 0.0013153958916518604, Final Batch Loss: 0.0009562295745126903\n",
      "Epoch 3504, Loss: 0.004622403050234425, Final Batch Loss: 0.00021316406491678208\n",
      "Epoch 3505, Loss: 0.00047271941002691165, Final Batch Loss: 0.0001457847683923319\n",
      "Epoch 3506, Loss: 0.0010877525860450987, Final Batch Loss: 3.866538918373408e-06\n",
      "Epoch 3507, Loss: 0.00026771263856062433, Final Batch Loss: 1.3261721505841706e-05\n",
      "Epoch 3508, Loss: 0.00020989366129242626, Final Batch Loss: 1.0927504945357214e-07\n",
      "Epoch 3509, Loss: 0.0005426545376394643, Final Batch Loss: 2.0443352696020156e-05\n",
      "Epoch 3510, Loss: 0.00022387068850093783, Final Batch Loss: 2.9057184747216525e-07\n",
      "Epoch 3511, Loss: 0.0001007091450446751, Final Batch Loss: 1.552129106130451e-05\n",
      "Epoch 3512, Loss: 0.00023807229115391237, Final Batch Loss: 6.332924158414244e-07\n",
      "Epoch 3513, Loss: 0.00041169757469106116, Final Batch Loss: 6.225583547347924e-06\n",
      "Epoch 3514, Loss: 0.0003434157924431247, Final Batch Loss: 2.0613238405076117e-07\n",
      "Epoch 3515, Loss: 0.0014088959787841304, Final Batch Loss: 2.585201400506776e-06\n",
      "Epoch 3516, Loss: 0.0007063996309852882, Final Batch Loss: 1.6962004565357347e-06\n",
      "Epoch 3517, Loss: 0.0009170412083676638, Final Batch Loss: 8.766799055592855e-07\n",
      "Epoch 3518, Loss: 0.0034790428762785375, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 3519, Loss: 0.0004430590586252947, Final Batch Loss: 1.2044827144563897e-06\n",
      "Epoch 3520, Loss: 0.00020449836483749095, Final Batch Loss: 8.971210263553075e-06\n",
      "Epoch 3521, Loss: 0.008143326711433474, Final Batch Loss: 0.0009519222658127546\n",
      "Epoch 3522, Loss: 0.00029424912401054826, Final Batch Loss: 8.071386332630937e-07\n",
      "Epoch 3523, Loss: 0.00028213284531375393, Final Batch Loss: 5.284117651171982e-05\n",
      "Epoch 3524, Loss: 0.0014291798652266152, Final Batch Loss: 4.1446255636401474e-06\n",
      "Epoch 3525, Loss: 0.0008138501839312084, Final Batch Loss: 0.00010768116771942005\n",
      "Epoch 3526, Loss: 0.0010941954715235624, Final Batch Loss: 0.0006750789470970631\n",
      "Epoch 3527, Loss: 0.00010943251436401624, Final Batch Loss: 6.402089638868347e-05\n",
      "Epoch 3528, Loss: 0.0011442788551221383, Final Batch Loss: 1.38827056161972e-06\n",
      "Epoch 3529, Loss: 0.0002312458454980515, Final Batch Loss: 6.431204383261502e-05\n",
      "Epoch 3530, Loss: 0.00016925500767683843, Final Batch Loss: 1.5548912415397353e-05\n",
      "Epoch 3531, Loss: 0.00027535220397112425, Final Batch Loss: 8.015658750082366e-06\n",
      "Epoch 3532, Loss: 0.0007481044376618229, Final Batch Loss: 0.0007327787461690605\n",
      "Epoch 3533, Loss: 0.005609621065559622, Final Batch Loss: 0.0009560007601976395\n",
      "Epoch 3534, Loss: 0.0005684087591326659, Final Batch Loss: 1.4901157641133977e-08\n",
      "Epoch 3535, Loss: 0.00038552489968424197, Final Batch Loss: 2.259916072944179e-06\n",
      "Epoch 3536, Loss: 0.008503310067832448, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 3537, Loss: 0.001714796035571453, Final Batch Loss: 5.836221816934994e-07\n",
      "Epoch 3538, Loss: 0.0001634866785025224, Final Batch Loss: 5.4504245781572536e-05\n",
      "Epoch 3539, Loss: 0.0003499487793305889, Final Batch Loss: 7.256120443344116e-05\n",
      "Epoch 3540, Loss: 0.005821603733977554, Final Batch Loss: 8.399379294132814e-05\n",
      "Epoch 3541, Loss: 0.014422396392546943, Final Batch Loss: 5.287080057314597e-06\n",
      "Epoch 3542, Loss: 0.0001321506601357214, Final Batch Loss: 5.314718123372586e-07\n",
      "Epoch 3543, Loss: 7.836592067178572e-05, Final Batch Loss: 1.2473609785956796e-05\n",
      "Epoch 3544, Loss: 0.0005035583508288255, Final Batch Loss: 2.3136248273658566e-05\n",
      "Epoch 3545, Loss: 0.0012144304037065012, Final Batch Loss: 8.149677887558937e-05\n",
      "Epoch 3546, Loss: 0.0006444788486987818, Final Batch Loss: 0.0002898250240832567\n",
      "Epoch 3547, Loss: 0.001062484661815688, Final Batch Loss: 7.944949174998328e-05\n",
      "Epoch 3548, Loss: 0.017893381207613857, Final Batch Loss: 1.9147186321788467e-05\n",
      "Epoch 3549, Loss: 0.0004544125513348263, Final Batch Loss: 5.649599188473076e-06\n",
      "Epoch 3550, Loss: 0.0006843549799668835, Final Batch Loss: 0.000222988091991283\n",
      "Epoch 3551, Loss: 0.00022226337432584842, Final Batch Loss: 2.1427083993330598e-05\n",
      "Epoch 3552, Loss: 0.0006646718939009588, Final Batch Loss: 5.7505047152517363e-05\n",
      "Epoch 3553, Loss: 0.0005581549758062465, Final Batch Loss: 4.389556488604285e-05\n",
      "Epoch 3554, Loss: 0.0032243021225895063, Final Batch Loss: 2.905536575781298e-06\n",
      "Epoch 3555, Loss: 0.00047438699766644277, Final Batch Loss: 5.5551412515342236e-05\n",
      "Epoch 3556, Loss: 0.00012346094626991544, Final Batch Loss: 2.4094000764307566e-05\n",
      "Epoch 3557, Loss: 0.01455848404543758, Final Batch Loss: 2.344390168218524e-06\n",
      "Epoch 3558, Loss: 0.0003357969678461359, Final Batch Loss: 3.278243809745618e-07\n",
      "Epoch 3559, Loss: 0.00034517065773798095, Final Batch Loss: 6.183943241921952e-07\n",
      "Epoch 3560, Loss: 0.0004968541235825796, Final Batch Loss: 5.314706754688814e-07\n",
      "Epoch 3561, Loss: 0.007644463215456199, Final Batch Loss: 3.228574314562138e-07\n",
      "Epoch 3562, Loss: 0.000687049232510617, Final Batch Loss: 0.00014822774392087013\n",
      "Epoch 3563, Loss: 0.004516012133535696, Final Batch Loss: 4.429441105457954e-05\n",
      "Epoch 3564, Loss: 0.000288370177258912, Final Batch Loss: 4.16962484450778e-06\n",
      "Epoch 3565, Loss: 0.0004979991414302276, Final Batch Loss: 1.4727162351846346e-06\n",
      "Epoch 3566, Loss: 0.0005067612037237268, Final Batch Loss: 4.7307275963248685e-05\n",
      "Epoch 3567, Loss: 0.00032440466543448565, Final Batch Loss: 3.4842348668462364e-06\n",
      "Epoch 3568, Loss: 0.00035837329869536916, Final Batch Loss: 1.3379096344579011e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3569, Loss: 0.0004697220853131512, Final Batch Loss: 5.46375531484955e-08\n",
      "Epoch 3570, Loss: 0.028289518542578662, Final Batch Loss: 2.1283319711074e-06\n",
      "Epoch 3571, Loss: 0.00023665363050895394, Final Batch Loss: 2.284782112838002e-06\n",
      "Epoch 3572, Loss: 0.00010781877301724307, Final Batch Loss: 9.189045613311464e-08\n",
      "Epoch 3573, Loss: 0.000123709416584461, Final Batch Loss: 9.493064681009855e-06\n",
      "Epoch 3574, Loss: 0.0009599750794677675, Final Batch Loss: 2.6548129881120985e-06\n",
      "Epoch 3575, Loss: 0.00022361967636186364, Final Batch Loss: 1.7881335168112855e-07\n",
      "Epoch 3576, Loss: 0.0002949348563561216, Final Batch Loss: 8.589257049607113e-05\n",
      "Epoch 3577, Loss: 0.002603655744792377, Final Batch Loss: 3.0547209917131113e-07\n",
      "Epoch 3578, Loss: 0.0005781316267530201, Final Batch Loss: 1.8062592062051408e-05\n",
      "Epoch 3579, Loss: 0.04588100776891224, Final Batch Loss: 9.797661914490163e-05\n",
      "Epoch 3580, Loss: 0.008808724234810938, Final Batch Loss: 1.8129689749457611e-07\n",
      "Epoch 3581, Loss: 0.00033555543814145494, Final Batch Loss: 0.0002535431121941656\n",
      "Epoch 3582, Loss: 0.0003198630378165035, Final Batch Loss: 1.3907532547818846e-06\n",
      "Epoch 3583, Loss: 0.03062145056173904, Final Batch Loss: 4.3528067180886865e-05\n",
      "Epoch 3584, Loss: 0.002448202663799748, Final Batch Loss: 0.001520241959951818\n",
      "Epoch 3585, Loss: 0.0009058958248715498, Final Batch Loss: 0.000364625797374174\n",
      "Epoch 3586, Loss: 0.0006106211294536479, Final Batch Loss: 0.00030033153598196805\n",
      "Epoch 3587, Loss: 0.0003412818150536623, Final Batch Loss: 5.859214797965251e-05\n",
      "Epoch 3588, Loss: 0.0018405497758067213, Final Batch Loss: 9.958085865946487e-05\n",
      "Epoch 3589, Loss: 0.0022118469642009586, Final Batch Loss: 3.351917621330358e-05\n",
      "Epoch 3590, Loss: 0.0015040211656014435, Final Batch Loss: 0.00024355639470741153\n",
      "Epoch 3591, Loss: 0.0017022254414769122, Final Batch Loss: 0.0002587806375231594\n",
      "Epoch 3592, Loss: 0.0006344135063045542, Final Batch Loss: 0.00010531298903515562\n",
      "Epoch 3593, Loss: 0.0002837489537341753, Final Batch Loss: 1.7938991732080467e-05\n",
      "Epoch 3594, Loss: 0.008500504187395563, Final Batch Loss: 0.007396323140710592\n",
      "Epoch 3595, Loss: 0.0007743573960397043, Final Batch Loss: 1.1796101716754492e-05\n",
      "Epoch 3596, Loss: 0.0008014439963517361, Final Batch Loss: 1.3865719665773213e-05\n",
      "Epoch 3597, Loss: 0.0005236887727733119, Final Batch Loss: 4.445491867954843e-07\n",
      "Epoch 3598, Loss: 0.0016369563327316428, Final Batch Loss: 4.098073986824602e-05\n",
      "Epoch 3599, Loss: 0.02707391606463716, Final Batch Loss: 3.8963357837928925e-06\n",
      "Epoch 3600, Loss: 0.0013803082838421687, Final Batch Loss: 0.0008459964883513749\n",
      "Epoch 3601, Loss: 0.000926774820072751, Final Batch Loss: 9.534992386761587e-06\n",
      "Epoch 3602, Loss: 0.000342162771630683, Final Batch Loss: 0.00024015021335799247\n",
      "Epoch 3603, Loss: 0.0003848558662866708, Final Batch Loss: 0.00014397788618225604\n",
      "Epoch 3604, Loss: 0.001100397605910075, Final Batch Loss: 2.905716200984898e-07\n",
      "Epoch 3605, Loss: 0.0007698050812905421, Final Batch Loss: 3.252411988796666e-05\n",
      "Epoch 3606, Loss: 0.004186083635431714, Final Batch Loss: 0.00015387813618872315\n",
      "Epoch 3607, Loss: 0.00034366474301350536, Final Batch Loss: 0.00021024835587013513\n",
      "Epoch 3608, Loss: 0.0008185827359739051, Final Batch Loss: 2.6573661671136506e-07\n",
      "Epoch 3609, Loss: 0.003646586701506749, Final Batch Loss: 0.0031811732333153486\n",
      "Epoch 3610, Loss: 0.0008656172994960798, Final Batch Loss: 1.7450814993935637e-05\n",
      "Epoch 3611, Loss: 0.016271295186015777, Final Batch Loss: 0.006470793858170509\n",
      "Epoch 3612, Loss: 0.0002547668832448835, Final Batch Loss: 6.841006779723102e-06\n",
      "Epoch 3613, Loss: 0.00019719988586075488, Final Batch Loss: 4.673820149037056e-05\n",
      "Epoch 3614, Loss: 0.0006549307272507576, Final Batch Loss: 1.3805933122057468e-05\n",
      "Epoch 3615, Loss: 0.06018250121269375, Final Batch Loss: 0.00010792926332214847\n",
      "Epoch 3616, Loss: 0.010329559007004718, Final Batch Loss: 2.887132177420426e-05\n",
      "Epoch 3617, Loss: 0.028727569090733596, Final Batch Loss: 1.1319408258714247e-05\n",
      "Epoch 3618, Loss: 0.001625347911613062, Final Batch Loss: 6.839786510681733e-05\n",
      "Epoch 3619, Loss: 0.0014349429318372131, Final Batch Loss: 1.966901209016214e-06\n",
      "Epoch 3620, Loss: 0.002940222868346609, Final Batch Loss: 0.002172564622014761\n",
      "Epoch 3621, Loss: 0.0007696264628975769, Final Batch Loss: 1.0356951861467678e-05\n",
      "Epoch 3622, Loss: 0.004636583478713874, Final Batch Loss: 0.0015458790585398674\n",
      "Epoch 3623, Loss: 0.014694134238652623, Final Batch Loss: 5.867822892469121e-06\n",
      "Epoch 3624, Loss: 0.0010944977329927497, Final Batch Loss: 4.009344775113277e-05\n",
      "Epoch 3625, Loss: 0.0007075526591506787, Final Batch Loss: 0.00013421430776361376\n",
      "Epoch 3626, Loss: 0.0003780358811127371, Final Batch Loss: 3.270078377681784e-05\n",
      "Epoch 3627, Loss: 0.01004264505354513, Final Batch Loss: 2.7361378670320846e-05\n",
      "Epoch 3628, Loss: 0.018016159008197974, Final Batch Loss: 1.4975461226640618e-06\n",
      "Epoch 3629, Loss: 0.001361265693049063, Final Batch Loss: 2.9754739443887956e-05\n",
      "Epoch 3630, Loss: 0.00143439676583057, Final Batch Loss: 1.050519927048299e-06\n",
      "Epoch 3631, Loss: 0.008664191593197756, Final Batch Loss: 1.462778527638875e-06\n",
      "Epoch 3632, Loss: 0.0011658831645036116, Final Batch Loss: 0.0007899727788753808\n",
      "Epoch 3633, Loss: 0.00928215924068354, Final Batch Loss: 7.235750672407448e-05\n",
      "Epoch 3634, Loss: 0.0007068171689752489, Final Batch Loss: 7.738675776636228e-05\n",
      "Epoch 3635, Loss: 0.012466562213376164, Final Batch Loss: 0.0003040713781956583\n",
      "Epoch 3636, Loss: 0.002957302515824267, Final Batch Loss: 1.3919917364546563e-05\n",
      "Epoch 3637, Loss: 0.004469804800010024, Final Batch Loss: 1.2044761206198018e-06\n",
      "Epoch 3638, Loss: 0.003237595654809411, Final Batch Loss: 4.2664073589548934e-06\n",
      "Epoch 3639, Loss: 0.021957990652822446, Final Batch Loss: 1.8799759118337533e-06\n",
      "Epoch 3640, Loss: 0.0009743117225298192, Final Batch Loss: 1.0801752068800852e-05\n",
      "Epoch 3641, Loss: 0.0007857253331167158, Final Batch Loss: 1.1065025319112465e-05\n",
      "Epoch 3642, Loss: 0.0010777895509903601, Final Batch Loss: 1.78813579054804e-07\n",
      "Epoch 3643, Loss: 0.0009101177533921145, Final Batch Loss: 1.5770024219818879e-06\n",
      "Epoch 3644, Loss: 0.0012982528533029836, Final Batch Loss: 0.0009176731109619141\n",
      "Epoch 3645, Loss: 0.0011515355945448391, Final Batch Loss: 0.0005882426630705595\n",
      "Epoch 3646, Loss: 0.00033091687074460197, Final Batch Loss: 9.437390957600655e-08\n",
      "Epoch 3647, Loss: 0.0014397980557987466, Final Batch Loss: 0.0006649436545558274\n",
      "Epoch 3648, Loss: 0.00048204256253825406, Final Batch Loss: 2.7567020310925727e-07\n",
      "Epoch 3649, Loss: 0.024162199815691565, Final Batch Loss: 3.934118649340235e-05\n",
      "Epoch 3650, Loss: 0.014118715665972559, Final Batch Loss: 5.9056237660115585e-05\n",
      "Epoch 3651, Loss: 0.0027687707015502383, Final Batch Loss: 0.002530449302867055\n",
      "Epoch 3652, Loss: 0.0010559190365366788, Final Batch Loss: 2.4835264511580135e-08\n",
      "Epoch 3653, Loss: 0.0005376183908083476, Final Batch Loss: 7.350749365286902e-05\n",
      "Epoch 3654, Loss: 0.0005343064312910428, Final Batch Loss: 5.105691889184527e-05\n",
      "Epoch 3655, Loss: 0.00043722003465518355, Final Batch Loss: 0.00014138944970909506\n",
      "Epoch 3656, Loss: 0.0002021218033405603, Final Batch Loss: 8.472800982417539e-05\n",
      "Epoch 3657, Loss: 0.0011938997922698036, Final Batch Loss: 9.707670687930658e-05\n",
      "Epoch 3658, Loss: 0.033723760514021706, Final Batch Loss: 4.060342234879499e-06\n",
      "Epoch 3659, Loss: 0.0006263656637202075, Final Batch Loss: 4.5944989324198104e-07\n",
      "Epoch 3660, Loss: 0.007978426205227152, Final Batch Loss: 0.0008331523858942091\n",
      "Epoch 3661, Loss: 0.0011689452431369318, Final Batch Loss: 4.967033078173699e-07\n",
      "Epoch 3662, Loss: 0.0004283667176423478, Final Batch Loss: 1.0965700312226545e-05\n",
      "Epoch 3663, Loss: 0.0029175286908866838, Final Batch Loss: 7.756938430247828e-05\n",
      "Epoch 3664, Loss: 0.01840913675550837, Final Batch Loss: 0.0024341808166354895\n",
      "Epoch 3665, Loss: 0.0009050560656760354, Final Batch Loss: 0.0004022502980660647\n",
      "Epoch 3666, Loss: 0.0006488838844234124, Final Batch Loss: 2.5996589101850986e-05\n",
      "Epoch 3667, Loss: 0.0011993660398275097, Final Batch Loss: 2.461102440065588e-06\n",
      "Epoch 3668, Loss: 0.0004766357196785975, Final Batch Loss: 2.014519486692734e-05\n",
      "Epoch 3669, Loss: 0.0012735815726045985, Final Batch Loss: 0.00011024090781575069\n",
      "Epoch 3670, Loss: 0.0009004436706163688, Final Batch Loss: 1.807728949643206e-05\n",
      "Epoch 3671, Loss: 0.0010288092544215033, Final Batch Loss: 5.711475751013495e-06\n",
      "Epoch 3672, Loss: 0.0002111774849709036, Final Batch Loss: 3.2011187158786925e-06\n",
      "Epoch 3673, Loss: 0.0004767723040686178, Final Batch Loss: 1.115091549763747e-06\n",
      "Epoch 3674, Loss: 0.0004219663243247851, Final Batch Loss: 4.5448189212038415e-07\n",
      "Epoch 3675, Loss: 0.0005383621594319266, Final Batch Loss: 2.9131208520993823e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3676, Loss: 0.0001271270807592373, Final Batch Loss: 5.066199719294673e-06\n",
      "Epoch 3677, Loss: 0.00036392308629729087, Final Batch Loss: 1.0669006769603584e-05\n",
      "Epoch 3678, Loss: 0.0002281274391862098, Final Batch Loss: 4.910846473649144e-05\n",
      "Epoch 3679, Loss: 0.0002254179853160565, Final Batch Loss: 3.725287101019603e-08\n",
      "Epoch 3680, Loss: 0.00035963697678198514, Final Batch Loss: 0.00013006200606469065\n",
      "Epoch 3681, Loss: 0.0012437918123850977, Final Batch Loss: 2.168024593629525e-06\n",
      "Epoch 3682, Loss: 0.00019552286767066107, Final Batch Loss: 8.518386493960861e-07\n",
      "Epoch 3683, Loss: 0.019554177819372853, Final Batch Loss: 0.00010943412780761719\n",
      "Epoch 3684, Loss: 0.000577033641839364, Final Batch Loss: 9.189040639512314e-08\n",
      "Epoch 3685, Loss: 0.0012882806374818756, Final Batch Loss: 2.8063800527888816e-07\n",
      "Epoch 3686, Loss: 0.000544079714018153, Final Batch Loss: 3.607928738347255e-05\n",
      "Epoch 3687, Loss: 0.004220489932777127, Final Batch Loss: 1.635666922084056e-05\n",
      "Epoch 3688, Loss: 0.00023699764005868929, Final Batch Loss: 1.3609907000500243e-05\n",
      "Epoch 3689, Loss: 0.00029983582783188467, Final Batch Loss: 1.3013515172133339e-06\n",
      "Epoch 3690, Loss: 0.0007223328276069196, Final Batch Loss: 1.4652785296220827e-07\n",
      "Epoch 3691, Loss: 0.0002800458405545214, Final Batch Loss: 7.840000762371346e-06\n",
      "Epoch 3692, Loss: 0.00023692101035521773, Final Batch Loss: 2.6274080937582767e-06\n",
      "Epoch 3693, Loss: 0.0001623731542963469, Final Batch Loss: 6.258407552195422e-07\n",
      "Epoch 3694, Loss: 0.000474308315460803, Final Batch Loss: 0.00024309282889589667\n",
      "Epoch 3695, Loss: 0.0004797523142769933, Final Batch Loss: 0.00010874084546230733\n",
      "Epoch 3696, Loss: 0.0005093861216209916, Final Batch Loss: 2.3915706606203457e-06\n",
      "Epoch 3697, Loss: 0.0005043221881351201, Final Batch Loss: 1.6847505321493372e-05\n",
      "Epoch 3698, Loss: 0.005804942493341514, Final Batch Loss: 1.4416040357900783e-05\n",
      "Epoch 3699, Loss: 0.003810258752309892, Final Batch Loss: 0.003278279909864068\n",
      "Epoch 3700, Loss: 0.0006766122807277952, Final Batch Loss: 4.17230836546878e-07\n",
      "Epoch 3701, Loss: 0.0043757197563536465, Final Batch Loss: 0.00026450303266756237\n",
      "Epoch 3702, Loss: 0.0010530631327299034, Final Batch Loss: 4.6193142111405905e-07\n",
      "Epoch 3703, Loss: 0.0006424248817893385, Final Batch Loss: 8.324848749907687e-05\n",
      "Epoch 3704, Loss: 0.0003203115047654137, Final Batch Loss: 0.0001126562783611007\n",
      "Epoch 3705, Loss: 0.00038183038850547746, Final Batch Loss: 4.1830833652056754e-05\n",
      "Epoch 3706, Loss: 0.00048128604726116464, Final Batch Loss: 3.3576027362869354e-06\n",
      "Epoch 3707, Loss: 0.005782398460723925, Final Batch Loss: 0.0020514994394034147\n",
      "Epoch 3708, Loss: 0.00015154553921092884, Final Batch Loss: 8.273866114905104e-05\n",
      "Epoch 3709, Loss: 0.004921702551428098, Final Batch Loss: 7.52501136958017e-07\n",
      "Epoch 3710, Loss: 0.0009730366855364991, Final Batch Loss: 1.899659400805831e-05\n",
      "Epoch 3711, Loss: 0.00019994169178971788, Final Batch Loss: 1.3170694728614762e-05\n",
      "Epoch 3712, Loss: 0.0003622904223448131, Final Batch Loss: 6.976710574235767e-05\n",
      "Epoch 3713, Loss: 0.0006976506101636915, Final Batch Loss: 3.965467112720944e-05\n",
      "Epoch 3714, Loss: 0.0006473003941209754, Final Batch Loss: 0.00040070401155389845\n",
      "Epoch 3715, Loss: 0.00016804333063191734, Final Batch Loss: 5.083562427898869e-06\n",
      "Epoch 3716, Loss: 0.0009005502288346179, Final Batch Loss: 0.0002667140506673604\n",
      "Epoch 3717, Loss: 0.04131306666931778, Final Batch Loss: 3.3830543543444946e-05\n",
      "Epoch 3718, Loss: 0.000139918108288839, Final Batch Loss: 1.0374386874900665e-05\n",
      "Epoch 3719, Loss: 0.002431389427272279, Final Batch Loss: 0.00012814528599847108\n",
      "Epoch 3720, Loss: 0.004163561528457649, Final Batch Loss: 4.564231403492158e-06\n",
      "Epoch 3721, Loss: 0.0011550986569091037, Final Batch Loss: 7.322658802877413e-06\n",
      "Epoch 3722, Loss: 0.013366959734185002, Final Batch Loss: 2.2077945232013008e-06\n",
      "Epoch 3723, Loss: 0.0004558933602041293, Final Batch Loss: 9.189040639512314e-08\n",
      "Epoch 3724, Loss: 0.001974202175915707, Final Batch Loss: 2.8910064429510385e-05\n",
      "Epoch 3725, Loss: 0.0005513334599527298, Final Batch Loss: 0.0001887597027234733\n",
      "Epoch 3726, Loss: 0.0007170854693185902, Final Batch Loss: 1.4106168464422808e-06\n",
      "Epoch 3727, Loss: 0.012215154167279252, Final Batch Loss: 1.9437009541434236e-05\n",
      "Epoch 3728, Loss: 0.0006779595396437799, Final Batch Loss: 1.1721874216163997e-05\n",
      "Epoch 3729, Loss: 0.003128412896330701, Final Batch Loss: 0.00019889854593202472\n",
      "Epoch 3730, Loss: 0.0006853244713056483, Final Batch Loss: 0.0004133993061259389\n",
      "Epoch 3731, Loss: 0.0010142417377210222, Final Batch Loss: 0.0006971033872105181\n",
      "Epoch 3732, Loss: 0.003812778238170722, Final Batch Loss: 0.0030642428901046515\n",
      "Epoch 3733, Loss: 0.0011095654826931423, Final Batch Loss: 2.8918066163896583e-05\n",
      "Epoch 3734, Loss: 0.0019067149733018596, Final Batch Loss: 4.8573088861303404e-05\n",
      "Epoch 3735, Loss: 0.004530057215561101, Final Batch Loss: 1.5894283933448605e-06\n",
      "Epoch 3736, Loss: 0.0004157354596827645, Final Batch Loss: 1.352536492049694e-05\n",
      "Epoch 3737, Loss: 0.0005298119714325367, Final Batch Loss: 1.209448896588583e-06\n",
      "Epoch 3738, Loss: 0.02156111544434225, Final Batch Loss: 1.7309529312115046e-06\n",
      "Epoch 3739, Loss: 0.0014113349679973908, Final Batch Loss: 0.0007950956933200359\n",
      "Epoch 3740, Loss: 0.000817146186818718, Final Batch Loss: 5.512707502930425e-06\n",
      "Epoch 3741, Loss: 0.002689326458494179, Final Batch Loss: 0.00030413648346439004\n",
      "Epoch 3742, Loss: 0.0020566362595673127, Final Batch Loss: 6.416511951101711e-06\n",
      "Epoch 3743, Loss: 0.000672103382385103, Final Batch Loss: 1.78694990609074e-05\n",
      "Epoch 3744, Loss: 0.00027088179376733024, Final Batch Loss: 2.0646441043936647e-05\n",
      "Epoch 3745, Loss: 0.00016152854692563778, Final Batch Loss: 5.861084559910523e-07\n",
      "Epoch 3746, Loss: 0.0016562922392040491, Final Batch Loss: 0.0005249145906418562\n",
      "Epoch 3747, Loss: 0.00071590012521483, Final Batch Loss: 0.00015940626326482743\n",
      "Epoch 3748, Loss: 0.000342978331843824, Final Batch Loss: 8.66739298999164e-07\n",
      "Epoch 3749, Loss: 0.027622264326964796, Final Batch Loss: 1.3135836525179911e-05\n",
      "Epoch 3750, Loss: 0.0020018448267364874, Final Batch Loss: 0.000728183367755264\n",
      "Epoch 3751, Loss: 0.031246212955011288, Final Batch Loss: 0.00047145519056357443\n",
      "Epoch 3752, Loss: 0.0018856475246593618, Final Batch Loss: 2.232630549769965e-06\n",
      "Epoch 3753, Loss: 0.0050680407682648365, Final Batch Loss: 2.908119085986982e-06\n",
      "Epoch 3754, Loss: 0.000482055659517755, Final Batch Loss: 1.1622786360021564e-06\n",
      "Epoch 3755, Loss: 0.0005730727789341472, Final Batch Loss: 4.867688403464854e-07\n",
      "Epoch 3756, Loss: 0.0004871011169598205, Final Batch Loss: 0.00032895724871195853\n",
      "Epoch 3757, Loss: 0.005072439194691469, Final Batch Loss: 2.4065045636234572e-06\n",
      "Epoch 3758, Loss: 0.006465289993684564, Final Batch Loss: 1.413420704921009e-05\n",
      "Epoch 3759, Loss: 0.0020313526765676215, Final Batch Loss: 0.0011757301399484277\n",
      "Epoch 3760, Loss: 0.00023132994465413503, Final Batch Loss: 5.9265850723022595e-05\n",
      "Epoch 3761, Loss: 0.0025884898323056404, Final Batch Loss: 8.532701940566767e-06\n",
      "Epoch 3762, Loss: 0.00038317036614898825, Final Batch Loss: 1.2916601008328144e-05\n",
      "Epoch 3763, Loss: 0.0004339438588996103, Final Batch Loss: 2.4835264511580135e-08\n",
      "Epoch 3764, Loss: 0.009591935412061048, Final Batch Loss: 5.935548301749805e-07\n",
      "Epoch 3765, Loss: 0.0006262511233217083, Final Batch Loss: 1.8994287529494613e-05\n",
      "Epoch 3766, Loss: 0.0003398803464733646, Final Batch Loss: 8.786072612565476e-06\n",
      "Epoch 3767, Loss: 0.0008616095997240336, Final Batch Loss: 4.107421318622073e-06\n",
      "Epoch 3768, Loss: 0.0006793301140675112, Final Batch Loss: 1.490111714019804e-07\n",
      "Epoch 3769, Loss: 0.01615257837011086, Final Batch Loss: 7.3552605499571655e-06\n",
      "Epoch 3770, Loss: 0.0019846698705805466, Final Batch Loss: 0.00014083094720263034\n",
      "Epoch 3771, Loss: 0.0019489901351334993, Final Batch Loss: 0.00021778915834147483\n",
      "Epoch 3772, Loss: 0.004716847666713875, Final Batch Loss: 0.004231845028698444\n",
      "Epoch 3773, Loss: 0.0011310600020806305, Final Batch Loss: 1.96687087736791e-05\n",
      "Epoch 3774, Loss: 0.0005734960241170484, Final Batch Loss: 2.35682546190219e-06\n",
      "Epoch 3775, Loss: 0.001117255738734002, Final Batch Loss: 5.587898499470612e-07\n",
      "Epoch 3776, Loss: 0.011667593844777002, Final Batch Loss: 4.375628577690804e-06\n",
      "Epoch 3777, Loss: 0.0014229303615138633, Final Batch Loss: 4.184539648122154e-06\n",
      "Epoch 3778, Loss: 0.0012291969583202444, Final Batch Loss: 4.388279648992466e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3779, Loss: 0.0001680159223269584, Final Batch Loss: 3.1638976452086354e-06\n",
      "Epoch 3780, Loss: 0.004360225804703077, Final Batch Loss: 0.0019147334387525916\n",
      "Epoch 3781, Loss: 0.002352743378651212, Final Batch Loss: 2.5051764168892987e-05\n",
      "Epoch 3782, Loss: 0.0007186203329183627, Final Batch Loss: 0.00010880245827138424\n",
      "Epoch 3783, Loss: 0.00030019590940355556, Final Batch Loss: 9.95176287688082e-06\n",
      "Epoch 3784, Loss: 0.0011793996101232551, Final Batch Loss: 1.4578118907593307e-06\n",
      "Epoch 3785, Loss: 0.002650245434779208, Final Batch Loss: 0.00016336444241460413\n",
      "Epoch 3786, Loss: 0.0012365023488882798, Final Batch Loss: 4.395827772896155e-07\n",
      "Epoch 3787, Loss: 0.0009160635381704196, Final Batch Loss: 0.0002563943271525204\n",
      "Epoch 3788, Loss: 0.002056806471955497, Final Batch Loss: 0.0005317943869158626\n",
      "Epoch 3789, Loss: 0.00012977929145563394, Final Batch Loss: 3.888916035066359e-05\n",
      "Epoch 3790, Loss: 0.00023552995662612375, Final Batch Loss: 1.5959158190526068e-05\n",
      "Epoch 3791, Loss: 0.014600398001675785, Final Batch Loss: 1.4615860891353805e-05\n",
      "Epoch 3792, Loss: 0.000433731931479997, Final Batch Loss: 0.0001638772082515061\n",
      "Epoch 3793, Loss: 0.0005746296556026209, Final Batch Loss: 0.00022419373271986842\n",
      "Epoch 3794, Loss: 0.00042920241442168106, Final Batch Loss: 2.7318789008745625e-08\n",
      "Epoch 3795, Loss: 0.0029434058378683403, Final Batch Loss: 0.0008712690323591232\n",
      "Epoch 3796, Loss: 0.0017113152553065447, Final Batch Loss: 7.388781523332e-05\n",
      "Epoch 3797, Loss: 0.0004946168119204231, Final Batch Loss: 0.00018887018086388707\n",
      "Epoch 3798, Loss: 0.029053704971374827, Final Batch Loss: 4.1884370148181915e-05\n",
      "Epoch 3799, Loss: 0.0078985242289491, Final Batch Loss: 0.000163214688654989\n",
      "Epoch 3800, Loss: 0.0006213420256244717, Final Batch Loss: 3.6257533793104813e-06\n",
      "Epoch 3801, Loss: 0.00042500682593527017, Final Batch Loss: 1.237923697772203e-05\n",
      "Epoch 3802, Loss: 0.0009545570273985504, Final Batch Loss: 1.112530935643008e-05\n",
      "Epoch 3803, Loss: 0.004304911605643724, Final Batch Loss: 1.7633006166306586e-07\n",
      "Epoch 3804, Loss: 0.0006405048598452368, Final Batch Loss: 1.2417608274972736e-07\n",
      "Epoch 3805, Loss: 0.0005149700391484657, Final Batch Loss: 2.3740934921079315e-05\n",
      "Epoch 3806, Loss: 0.0003013030597003308, Final Batch Loss: 1.7036596773323254e-06\n",
      "Epoch 3807, Loss: 0.00030704329856234835, Final Batch Loss: 9.512787983112503e-06\n",
      "Epoch 3808, Loss: 0.0016002883094188292, Final Batch Loss: 5.960079306532862e-06\n",
      "Epoch 3809, Loss: 0.0010710521310102195, Final Batch Loss: 0.000534691964276135\n",
      "Epoch 3810, Loss: 0.0003749763418454677, Final Batch Loss: 0.0001488731795689091\n",
      "Epoch 3811, Loss: 0.0006960358604715111, Final Batch Loss: 9.313097848462348e-07\n",
      "Epoch 3812, Loss: 0.0007740372784610372, Final Batch Loss: 8.392784366151318e-06\n",
      "Epoch 3813, Loss: 0.0009998841997003183, Final Batch Loss: 7.626258593518287e-06\n",
      "Epoch 3814, Loss: 0.0017296019298029819, Final Batch Loss: 7.947277680386833e-08\n",
      "Epoch 3815, Loss: 0.0017418711468053516, Final Batch Loss: 8.949160837801173e-05\n",
      "Epoch 3816, Loss: 0.0002326267713215202, Final Batch Loss: 4.503222953644581e-05\n",
      "Epoch 3817, Loss: 0.0001771354955053539, Final Batch Loss: 1.212805091199698e-05\n",
      "Epoch 3818, Loss: 0.0012320187506702496, Final Batch Loss: 2.9476219424395822e-05\n",
      "Epoch 3819, Loss: 0.00045595120172947645, Final Batch Loss: 8.060519030550495e-05\n",
      "Epoch 3820, Loss: 0.0008942592951370898, Final Batch Loss: 3.7400507153506624e-06\n",
      "Epoch 3821, Loss: 0.0001744956874745185, Final Batch Loss: 1.547199076412653e-06\n",
      "Epoch 3822, Loss: 0.0003032217896361544, Final Batch Loss: 4.983204053132795e-05\n",
      "Epoch 3823, Loss: 0.00038495521437198477, Final Batch Loss: 1.7111073020714684e-06\n",
      "Epoch 3824, Loss: 0.0001715732175426865, Final Batch Loss: 1.6391250312608463e-07\n",
      "Epoch 3825, Loss: 0.00018959539193019737, Final Batch Loss: 2.48959240707336e-05\n",
      "Epoch 3826, Loss: 0.0007535097429354209, Final Batch Loss: 0.0004732400120701641\n",
      "Epoch 3827, Loss: 0.000336308432451915, Final Batch Loss: 2.541110006859526e-05\n",
      "Epoch 3828, Loss: 0.000626041959549184, Final Batch Loss: 5.6000299082370475e-06\n",
      "Epoch 3829, Loss: 0.0018360171670792624, Final Batch Loss: 2.908041096816305e-06\n",
      "Epoch 3830, Loss: 0.0002512440460122889, Final Batch Loss: 6.878293788759038e-05\n",
      "Epoch 3831, Loss: 0.00289644796794164, Final Batch Loss: 9.11592724150978e-06\n",
      "Epoch 3832, Loss: 0.008030460651255567, Final Batch Loss: 1.7384668637987488e-07\n",
      "Epoch 3833, Loss: 0.0011174234105055803, Final Batch Loss: 8.869524208421353e-06\n",
      "Epoch 3834, Loss: 0.0004187420126982033, Final Batch Loss: 3.102614573435858e-05\n",
      "Epoch 3835, Loss: 0.019461092491837917, Final Batch Loss: 3.440324144321494e-05\n",
      "Epoch 3836, Loss: 0.00023179600248113275, Final Batch Loss: 1.0243769793305546e-05\n",
      "Epoch 3837, Loss: 0.0009521339306957088, Final Batch Loss: 0.00011896310024894774\n",
      "Epoch 3838, Loss: 0.00039698842192592565, Final Batch Loss: 2.41607576754177e-05\n",
      "Epoch 3839, Loss: 0.0005217098023422295, Final Batch Loss: 4.268817065167241e-06\n",
      "Epoch 3840, Loss: 0.0006370238479576074, Final Batch Loss: 6.389209738699719e-05\n",
      "Epoch 3841, Loss: 0.0019100408717349637, Final Batch Loss: 0.0014433851465582848\n",
      "Epoch 3842, Loss: 0.0010677771642804146, Final Batch Loss: 0.00022109622659627348\n",
      "Epoch 3843, Loss: 0.0007032455469015986, Final Batch Loss: 0.000411693355999887\n",
      "Epoch 3844, Loss: 0.0007736982033748063, Final Batch Loss: 0.0005792322917841375\n",
      "Epoch 3845, Loss: 0.0005388338004195248, Final Batch Loss: 1.5167356650636066e-05\n",
      "Epoch 3846, Loss: 0.0005800728649774101, Final Batch Loss: 9.964132914319634e-05\n",
      "Epoch 3847, Loss: 0.00026844843523576856, Final Batch Loss: 3.3939650165848434e-05\n",
      "Epoch 3848, Loss: 0.007504791966027824, Final Batch Loss: 6.233610179151583e-07\n",
      "Epoch 3849, Loss: 0.00220277227299448, Final Batch Loss: 1.4851134437776636e-06\n",
      "Epoch 3850, Loss: 0.003380562262464082, Final Batch Loss: 0.00021564071357715875\n",
      "Epoch 3851, Loss: 0.03531352179652458, Final Batch Loss: 9.645134014135692e-06\n",
      "Epoch 3852, Loss: 0.00041125505108041693, Final Batch Loss: 5.463757091206389e-08\n",
      "Epoch 3853, Loss: 0.0007565692358184606, Final Batch Loss: 0.00017214419494848698\n",
      "Epoch 3854, Loss: 0.0010591159825708019, Final Batch Loss: 1.4192712114891037e-05\n",
      "Epoch 3855, Loss: 0.0004192077208244882, Final Batch Loss: 3.702899266500026e-05\n",
      "Epoch 3856, Loss: 0.0003847995940304827, Final Batch Loss: 3.4628083085408434e-05\n",
      "Epoch 3857, Loss: 0.0030491015168081503, Final Batch Loss: 4.618861566996202e-06\n",
      "Epoch 3858, Loss: 0.00019287176110083237, Final Batch Loss: 3.072604158660397e-05\n",
      "Epoch 3859, Loss: 0.00033880257615237497, Final Batch Loss: 3.0540588340954855e-05\n",
      "Epoch 3860, Loss: 0.0032695242553018034, Final Batch Loss: 7.776088750688359e-05\n",
      "Epoch 3861, Loss: 0.0012970107857199764, Final Batch Loss: 3.4817060168279568e-06\n",
      "Epoch 3862, Loss: 0.00107451994939467, Final Batch Loss: 4.718698320971271e-08\n",
      "Epoch 3863, Loss: 0.0003695640052683302, Final Batch Loss: 4.0331133277504705e-06\n",
      "Epoch 3864, Loss: 0.00015097023251087194, Final Batch Loss: 3.650767155249923e-07\n",
      "Epoch 3865, Loss: 0.07814592494673889, Final Batch Loss: 0.07695652544498444\n",
      "Epoch 3866, Loss: 0.000511797952640336, Final Batch Loss: 0.00011045527207897976\n",
      "Epoch 3867, Loss: 0.0009618302301532822, Final Batch Loss: 0.0006031302618794143\n",
      "Epoch 3868, Loss: 0.0028152326704002917, Final Batch Loss: 0.0007036537281237543\n",
      "Epoch 3869, Loss: 0.0017985055164775332, Final Batch Loss: 2.9802309953197437e-08\n",
      "Epoch 3870, Loss: 0.006367196554492693, Final Batch Loss: 0.002387502696365118\n",
      "Epoch 3871, Loss: 0.012104858989914646, Final Batch Loss: 0.0005908113089390099\n",
      "Epoch 3872, Loss: 0.0031244393521774327, Final Batch Loss: 5.5876622354844585e-05\n",
      "Epoch 3873, Loss: 0.007940883569546031, Final Batch Loss: 3.923956057860778e-07\n",
      "Epoch 3874, Loss: 0.0003772589607251575, Final Batch Loss: 2.5595223632990383e-05\n",
      "Epoch 3875, Loss: 0.0019772968076949837, Final Batch Loss: 1.8725110066952766e-06\n",
      "Epoch 3876, Loss: 0.0007558421320936759, Final Batch Loss: 1.283352048631059e-05\n",
      "Epoch 3877, Loss: 0.0003927047118850169, Final Batch Loss: 0.00013422861229628325\n",
      "Epoch 3878, Loss: 0.0035198748846596573, Final Batch Loss: 3.7222289392957464e-05\n",
      "Epoch 3879, Loss: 0.0012618454602488782, Final Batch Loss: 8.488626917824149e-05\n",
      "Epoch 3880, Loss: 0.000636454155028332, Final Batch Loss: 5.951765342615545e-05\n",
      "Epoch 3881, Loss: 0.0005405129875271086, Final Batch Loss: 3.665561280286056e-06\n",
      "Epoch 3882, Loss: 0.0009248535352526233, Final Batch Loss: 1.4148859918350354e-05\n",
      "Epoch 3883, Loss: 0.00037460015755641507, Final Batch Loss: 0.00014821722288616002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3884, Loss: 0.00032577047113591107, Final Batch Loss: 1.146678641816834e-05\n",
      "Epoch 3885, Loss: 0.0005445729348139139, Final Batch Loss: 7.311277295229957e-05\n",
      "Epoch 3886, Loss: 0.000282836712358403, Final Batch Loss: 2.9354494472499937e-05\n",
      "Epoch 3887, Loss: 0.00122666564934093, Final Batch Loss: 1.3907705920246372e-07\n",
      "Epoch 3888, Loss: 0.0008741494411879103, Final Batch Loss: 0.00033928430639207363\n",
      "Epoch 3889, Loss: 0.0004300931107081851, Final Batch Loss: 2.543071104810224e-06\n",
      "Epoch 3890, Loss: 0.00018689383887249278, Final Batch Loss: 2.0013918401673436e-05\n",
      "Epoch 3891, Loss: 0.0003110057318735926, Final Batch Loss: 6.700205995002761e-05\n",
      "Epoch 3892, Loss: 0.00017158564833152923, Final Batch Loss: 7.21919741408783e-06\n",
      "Epoch 3893, Loss: 0.0013619879700854653, Final Batch Loss: 4.497302143136039e-06\n",
      "Epoch 3894, Loss: 0.0006245511751217236, Final Batch Loss: 8.791604955149523e-07\n",
      "Epoch 3895, Loss: 0.0006775986130378442, Final Batch Loss: 0.0002805406984407455\n",
      "Epoch 3896, Loss: 0.0006626366862292343, Final Batch Loss: 2.8931446649949066e-05\n",
      "Epoch 3897, Loss: 0.00020350306979821653, Final Batch Loss: 3.352734267991764e-07\n",
      "Epoch 3898, Loss: 0.0007661523927708913, Final Batch Loss: 5.718981356039876e-06\n",
      "Epoch 3899, Loss: 0.0008103619099983916, Final Batch Loss: 2.664716475919704e-06\n",
      "Epoch 3900, Loss: 0.0001452329979656497, Final Batch Loss: 1.7997839677263983e-05\n",
      "Epoch 3901, Loss: 0.0010129906163456326, Final Batch Loss: 3.2186548196477816e-05\n",
      "Epoch 3902, Loss: 0.00026440940837346716, Final Batch Loss: 3.2989977626129985e-05\n",
      "Epoch 3903, Loss: 0.00016000093785351055, Final Batch Loss: 4.321315145716653e-07\n",
      "Epoch 3904, Loss: 0.0005844693150720559, Final Batch Loss: 4.16464899899438e-06\n",
      "Epoch 3905, Loss: 0.0021560418581429985, Final Batch Loss: 0.0018107566284015775\n",
      "Epoch 3906, Loss: 9.777624234175164e-05, Final Batch Loss: 9.784865824258304e-07\n",
      "Epoch 3907, Loss: 5.7585406750604307e-05, Final Batch Loss: 1.8403692592983134e-05\n",
      "Epoch 3908, Loss: 0.0003433008294848605, Final Batch Loss: 1.2665972803915793e-07\n",
      "Epoch 3909, Loss: 0.00020869681429758202, Final Batch Loss: 1.838104253693018e-05\n",
      "Epoch 3910, Loss: 0.0003342445993439469, Final Batch Loss: 0.00026406030519865453\n",
      "Epoch 3911, Loss: 3.2928722248470876e-05, Final Batch Loss: 3.4940396744786995e-06\n",
      "Epoch 3912, Loss: 0.0004746960671582201, Final Batch Loss: 7.425192507071188e-06\n",
      "Epoch 3913, Loss: 0.0013130770694260718, Final Batch Loss: 0.0011169773060828447\n",
      "Epoch 3914, Loss: 0.0014052695441932883, Final Batch Loss: 0.0009611339191906154\n",
      "Epoch 3915, Loss: 0.0002591767411104229, Final Batch Loss: 9.659576608100906e-05\n",
      "Epoch 3916, Loss: 8.863039403195216e-05, Final Batch Loss: 8.766745054344938e-07\n",
      "Epoch 3917, Loss: 0.00027573443730943836, Final Batch Loss: 5.75602643948514e-06\n",
      "Epoch 3918, Loss: 0.00454339701718709, Final Batch Loss: 0.00441457936540246\n",
      "Epoch 3919, Loss: 0.010629045872519782, Final Batch Loss: 1.0459415534569416e-05\n",
      "Epoch 3920, Loss: 0.0022333348754273175, Final Batch Loss: 2.552988235038356e-06\n",
      "Epoch 3921, Loss: 0.009646020175296144, Final Batch Loss: 4.24894869865966e-06\n",
      "Epoch 3922, Loss: 0.0001977219453692669, Final Batch Loss: 0.0\n",
      "Epoch 3923, Loss: 0.00011411740797484526, Final Batch Loss: 3.978282620664686e-06\n",
      "Epoch 3924, Loss: 7.889581172548787e-05, Final Batch Loss: 1.3956954489913187e-06\n",
      "Epoch 3925, Loss: 0.00021926361705482122, Final Batch Loss: 1.0948766430374235e-05\n",
      "Epoch 3926, Loss: 0.0003605301386073734, Final Batch Loss: 7.003505402281007e-07\n",
      "Epoch 3927, Loss: 0.00011937241333725979, Final Batch Loss: 4.1075559238379356e-06\n",
      "Epoch 3928, Loss: 0.00011451939940343436, Final Batch Loss: 1.4760266822122503e-05\n",
      "Epoch 3929, Loss: 6.8625560743385e-05, Final Batch Loss: 5.9401536418590695e-06\n",
      "Epoch 3930, Loss: 0.00014429113207370392, Final Batch Loss: 6.195998594193952e-06\n",
      "Epoch 3931, Loss: 0.00013364183051578493, Final Batch Loss: 2.2848381320272892e-07\n",
      "Epoch 3932, Loss: 8.576357002709756e-05, Final Batch Loss: 1.44044392413889e-07\n",
      "Epoch 3933, Loss: 0.0047364295846819005, Final Batch Loss: 0.004504427779465914\n",
      "Epoch 3934, Loss: 0.00037567138103122844, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 3935, Loss: 0.0001696015688139596, Final Batch Loss: 1.0306439435225911e-06\n",
      "Epoch 3936, Loss: 0.00010958705865959928, Final Batch Loss: 4.59679176856298e-05\n",
      "Epoch 3937, Loss: 0.00020244546489323056, Final Batch Loss: 1.9619814395355206e-07\n",
      "Epoch 3938, Loss: 0.000921623998465293, Final Batch Loss: 7.230853498185752e-06\n",
      "Epoch 3939, Loss: 0.001161489622973022, Final Batch Loss: 0.0006422893493436277\n",
      "Epoch 3940, Loss: 0.008329978785468484, Final Batch Loss: 2.0836112071265234e-06\n",
      "Epoch 3941, Loss: 0.00013032005864488383, Final Batch Loss: 6.804801273574412e-07\n",
      "Epoch 3942, Loss: 0.01589251282712212, Final Batch Loss: 0.015705827623605728\n",
      "Epoch 3943, Loss: 0.0004098762440776227, Final Batch Loss: 5.687209636562329e-07\n",
      "Epoch 3944, Loss: 0.16336184443571256, Final Batch Loss: 0.08397059887647629\n",
      "Epoch 3945, Loss: 0.0034285853921574017, Final Batch Loss: 5.800773124065017e-06\n",
      "Epoch 3946, Loss: 0.06524783205532003, Final Batch Loss: 0.0002496702363714576\n",
      "Epoch 3947, Loss: 0.03221852846763795, Final Batch Loss: 0.001028509926982224\n",
      "Epoch 3948, Loss: 0.051975203765323386, Final Batch Loss: 0.04978914558887482\n",
      "Epoch 3949, Loss: 0.007598429103836679, Final Batch Loss: 7.405149972328218e-06\n",
      "Epoch 3950, Loss: 0.002332802047021687, Final Batch Loss: 0.00021160584583412856\n",
      "Epoch 3951, Loss: 0.002104564222463523, Final Batch Loss: 0.00012521083408501\n",
      "Epoch 3952, Loss: 0.0028452005062717944, Final Batch Loss: 0.0016383080510422587\n",
      "Epoch 3953, Loss: 0.011049322642065817, Final Batch Loss: 4.323304528952576e-05\n",
      "Epoch 3954, Loss: 0.0010766226259875111, Final Batch Loss: 0.0004343356704339385\n",
      "Epoch 3955, Loss: 0.0006609650145037449, Final Batch Loss: 1.0293052582710516e-05\n",
      "Epoch 3956, Loss: 0.003123467802652158, Final Batch Loss: 0.00013648242747876793\n",
      "Epoch 3957, Loss: 0.0010626530201989226, Final Batch Loss: 0.0006506681675091386\n",
      "Epoch 3958, Loss: 0.0006750362435923307, Final Batch Loss: 1.2086015885870438e-05\n",
      "Epoch 3959, Loss: 0.000632107259662007, Final Batch Loss: 2.698096250242088e-05\n",
      "Epoch 3960, Loss: 0.01862664688087534, Final Batch Loss: 0.0003293519839644432\n",
      "Epoch 3961, Loss: 0.01247847016020387, Final Batch Loss: 6.876010957057588e-06\n",
      "Epoch 3962, Loss: 0.003217417789528554, Final Batch Loss: 2.1779987946501933e-06\n",
      "Epoch 3963, Loss: 0.0006187289994841194, Final Batch Loss: 1.5273484450517572e-06\n",
      "Epoch 3964, Loss: 0.0006376986239047255, Final Batch Loss: 0.0003168201947119087\n",
      "Epoch 3965, Loss: 0.0018524782062740996, Final Batch Loss: 0.00045153312385082245\n",
      "Epoch 3966, Loss: 0.0008502609389324789, Final Batch Loss: 1.232100203196751e-05\n",
      "Epoch 3967, Loss: 0.0004641789514820971, Final Batch Loss: 1.0679152495640665e-07\n",
      "Epoch 3968, Loss: 0.001509436965079658, Final Batch Loss: 7.087359790602932e-06\n",
      "Epoch 3969, Loss: 0.0006831740829511546, Final Batch Loss: 6.258018402149901e-06\n",
      "Epoch 3970, Loss: 0.023508025287810597, Final Batch Loss: 1.6505224266438745e-05\n",
      "Epoch 3971, Loss: 0.0033564652658242267, Final Batch Loss: 1.3925087841926143e-05\n",
      "Epoch 3972, Loss: 0.0008561385257053189, Final Batch Loss: 8.59052743180655e-05\n",
      "Epoch 3973, Loss: 0.0009275059892388526, Final Batch Loss: 0.00031288096215575933\n",
      "Epoch 3974, Loss: 0.0004010563989140792, Final Batch Loss: 3.0099135983618908e-06\n",
      "Epoch 3975, Loss: 0.0003830837513305596, Final Batch Loss: 5.016520844947081e-06\n",
      "Epoch 3976, Loss: 0.0003956238568889603, Final Batch Loss: 1.259125269825745e-06\n",
      "Epoch 3977, Loss: 0.0005966373500996269, Final Batch Loss: 9.571617556503043e-05\n",
      "Epoch 3978, Loss: 0.0008759922566241585, Final Batch Loss: 0.00034410544321872294\n",
      "Epoch 3979, Loss: 0.00297407428479346, Final Batch Loss: 0.0002006896975217387\n",
      "Epoch 3980, Loss: 0.0010097714148287196, Final Batch Loss: 0.0005042901029810309\n",
      "Epoch 3981, Loss: 0.000656997253827285, Final Batch Loss: 0.0003565996594261378\n",
      "Epoch 3982, Loss: 0.000256434428592911, Final Batch Loss: 2.5335431928397156e-05\n",
      "Epoch 3983, Loss: 0.00046123094580252655, Final Batch Loss: 0.00031892224797047675\n",
      "Epoch 3984, Loss: 0.0005038685042109137, Final Batch Loss: 1.9966639683843823e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3985, Loss: 0.0006500732829408662, Final Batch Loss: 4.52000222139759e-07\n",
      "Epoch 3986, Loss: 0.0010703496936912416, Final Batch Loss: 0.0008932616910897195\n",
      "Epoch 3987, Loss: 0.0006315817336144391, Final Batch Loss: 5.725022128899582e-05\n",
      "Epoch 3988, Loss: 0.00040822310438670684, Final Batch Loss: 8.535310189472511e-05\n",
      "Epoch 3989, Loss: 0.0005011517131734422, Final Batch Loss: 6.705514721261352e-08\n",
      "Epoch 3990, Loss: 0.00032033335156711473, Final Batch Loss: 6.928992775101506e-07\n",
      "Epoch 3991, Loss: 0.0004919568827972398, Final Batch Loss: 3.066474528168328e-05\n",
      "Epoch 3992, Loss: 0.0005837772623635828, Final Batch Loss: 0.0001234515948453918\n",
      "Epoch 3993, Loss: 0.001762083909852663, Final Batch Loss: 0.0015389472246170044\n",
      "Epoch 3994, Loss: 0.0007895072158135008, Final Batch Loss: 0.0005615896661765873\n",
      "Epoch 3995, Loss: 0.00404073156278173, Final Batch Loss: 1.671304380579386e-05\n",
      "Epoch 3996, Loss: 0.0006247821668310394, Final Batch Loss: 6.457162982087539e-08\n",
      "Epoch 3997, Loss: 0.00031259138177119894, Final Batch Loss: 2.1048237613285892e-05\n",
      "Epoch 3998, Loss: 0.0001844821808845154, Final Batch Loss: 9.226744623447303e-06\n",
      "Epoch 3999, Loss: 0.0001883839277070365, Final Batch Loss: 7.698489753238391e-06\n",
      "Epoch 4000, Loss: 0.0005372504483602825, Final Batch Loss: 1.0361417480453383e-05\n",
      "Epoch 4001, Loss: 0.00029306939315176805, Final Batch Loss: 2.309675579681425e-07\n",
      "Epoch 4002, Loss: 0.0004688093185905018, Final Batch Loss: 0.0003904259065166116\n",
      "Epoch 4003, Loss: 0.000630190602919356, Final Batch Loss: 1.1498556204969645e-06\n",
      "Epoch 4004, Loss: 0.00012082384273526259, Final Batch Loss: 5.926792437094264e-05\n",
      "Epoch 4005, Loss: 0.0004437521927229682, Final Batch Loss: 2.8907013529533288e-06\n",
      "Epoch 4006, Loss: 0.0005230694328020036, Final Batch Loss: 1.6142707863764372e-06\n",
      "Epoch 4007, Loss: 0.0006367949244996396, Final Batch Loss: 1.4901157641133977e-08\n",
      "Epoch 4008, Loss: 0.0015885746379353805, Final Batch Loss: 2.2050558982300572e-05\n",
      "Epoch 4009, Loss: 0.000615290173299865, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 4010, Loss: 0.00032508862614122336, Final Batch Loss: 5.292099103826331e-06\n",
      "Epoch 4011, Loss: 0.0001617090592844761, Final Batch Loss: 2.5703720893943682e-06\n",
      "Epoch 4012, Loss: 0.0005575023774326837, Final Batch Loss: 3.8922826206544414e-05\n",
      "Epoch 4013, Loss: 0.0019392681406316115, Final Batch Loss: 0.0011899833334609866\n",
      "Epoch 4014, Loss: 0.0008832821404212154, Final Batch Loss: 1.7367035979987122e-05\n",
      "Epoch 4015, Loss: 0.0001748372966687839, Final Batch Loss: 3.005049222792877e-07\n",
      "Epoch 4016, Loss: 0.00033608704325160943, Final Batch Loss: 0.0001465859531890601\n",
      "Epoch 4017, Loss: 0.016312190524331527, Final Batch Loss: 0.0003239715879317373\n",
      "Epoch 4018, Loss: 0.0004526273436340489, Final Batch Loss: 4.892493734587333e-07\n",
      "Epoch 4019, Loss: 0.002734923589741811, Final Batch Loss: 0.002368972869589925\n",
      "Epoch 4020, Loss: 0.00015965908309567567, Final Batch Loss: 1.6316365645252517e-06\n",
      "Epoch 4021, Loss: 0.0004145187917856674, Final Batch Loss: 1.0157505130337086e-06\n",
      "Epoch 4022, Loss: 0.0011968794296990382, Final Batch Loss: 2.5443145204917528e-05\n",
      "Epoch 4023, Loss: 0.0010903392208092555, Final Batch Loss: 0.00039494989323429763\n",
      "Epoch 4024, Loss: 0.0003483087675704155, Final Batch Loss: 7.984886906342581e-05\n",
      "Epoch 4025, Loss: 0.0007954880493343808, Final Batch Loss: 0.00017133326036855578\n",
      "Epoch 4026, Loss: 0.0006343386868365997, Final Batch Loss: 0.0003857555566355586\n",
      "Epoch 4027, Loss: 0.00019893754324584734, Final Batch Loss: 8.45967406348791e-06\n",
      "Epoch 4028, Loss: 0.00035226294539825176, Final Batch Loss: 2.5206559257640038e-06\n",
      "Epoch 4029, Loss: 0.0017111104461946525, Final Batch Loss: 0.0012857293477281928\n",
      "Epoch 4030, Loss: 0.00018139195981348166, Final Batch Loss: 1.0222266610071529e-05\n",
      "Epoch 4031, Loss: 0.0015958123476593755, Final Batch Loss: 0.0015121569158509374\n",
      "Epoch 4032, Loss: 0.0001328376050935276, Final Batch Loss: 2.8063678314538265e-07\n",
      "Epoch 4033, Loss: 0.00022524732048623264, Final Batch Loss: 2.147813756891992e-05\n",
      "Epoch 4034, Loss: 0.0004378570653393865, Final Batch Loss: 3.228582912129241e-08\n",
      "Epoch 4035, Loss: 8.41478110942262e-05, Final Batch Loss: 1.2974891433259472e-05\n",
      "Epoch 4036, Loss: 0.00012325214720476652, Final Batch Loss: 1.7089723769458942e-05\n",
      "Epoch 4037, Loss: 0.00018836161879676183, Final Batch Loss: 3.3030764257091505e-07\n",
      "Epoch 4038, Loss: 0.0007551169201178709, Final Batch Loss: 1.5611063645337708e-05\n",
      "Epoch 4039, Loss: 0.00046780450043115707, Final Batch Loss: 0.00040852339589037\n",
      "Epoch 4040, Loss: 0.0001822341739625699, Final Batch Loss: 3.4796492400346324e-05\n",
      "Epoch 4041, Loss: 0.0001431788238619447, Final Batch Loss: 7.053146759972151e-07\n",
      "Epoch 4042, Loss: 0.0013169242984076845, Final Batch Loss: 0.00101162726059556\n",
      "Epoch 4043, Loss: 8.896733288565883e-05, Final Batch Loss: 1.5933677786961198e-05\n",
      "Epoch 4044, Loss: 0.0004748744372591318, Final Batch Loss: 1.4652473510068376e-06\n",
      "Epoch 4045, Loss: 8.582000106116539e-05, Final Batch Loss: 6.457126460190921e-07\n",
      "Epoch 4046, Loss: 0.0028867224878013076, Final Batch Loss: 4.097664259461453e-06\n",
      "Epoch 4047, Loss: 0.0003774781989704934, Final Batch Loss: 8.680551400175318e-05\n",
      "Epoch 4048, Loss: 0.005959757719779191, Final Batch Loss: 6.953871434234316e-08\n",
      "Epoch 4049, Loss: 8.273350052334649e-05, Final Batch Loss: 1.2417633143968487e-08\n",
      "Epoch 4050, Loss: 0.00022089632146204963, Final Batch Loss: 3.7252885221050747e-08\n",
      "Epoch 4051, Loss: 0.0013436319350148551, Final Batch Loss: 8.174373215297237e-05\n",
      "Epoch 4052, Loss: 0.0009816706260608044, Final Batch Loss: 1.6843929188326e-05\n",
      "Epoch 4053, Loss: 0.001247029684179779, Final Batch Loss: 8.940691031966708e-08\n",
      "Epoch 4054, Loss: 0.0009119040510086052, Final Batch Loss: 4.204222477710573e-06\n",
      "Epoch 4055, Loss: 0.000850839025872574, Final Batch Loss: 1.2417609696058207e-07\n",
      "Epoch 4056, Loss: 7.743715650576632e-05, Final Batch Loss: 6.680634214717429e-07\n",
      "Epoch 4057, Loss: 0.0010223618951386015, Final Batch Loss: 4.7430798986169975e-06\n",
      "Epoch 4058, Loss: 0.0005515987122635124, Final Batch Loss: 0.00026737485313788056\n",
      "Epoch 4059, Loss: 0.07848520870356879, Final Batch Loss: 0.07816240191459656\n",
      "Epoch 4060, Loss: 0.0004705681908490078, Final Batch Loss: 0.00019918593170586973\n",
      "Epoch 4061, Loss: 0.0017471991595812142, Final Batch Loss: 0.00040285103023052216\n",
      "Epoch 4062, Loss: 0.0021157984429009957, Final Batch Loss: 2.3860358851379715e-05\n",
      "Epoch 4063, Loss: 0.003118409280432388, Final Batch Loss: 0.0005138157866895199\n",
      "Epoch 4064, Loss: 0.0018283816389157437, Final Batch Loss: 3.720754466485232e-05\n",
      "Epoch 4065, Loss: 0.002087905115331523, Final Batch Loss: 0.000684752594679594\n",
      "Epoch 4066, Loss: 0.0031271322368411347, Final Batch Loss: 0.00039109602221287787\n",
      "Epoch 4067, Loss: 0.001557473942739307, Final Batch Loss: 2.0761417545145378e-06\n",
      "Epoch 4068, Loss: 0.0010203130168520147, Final Batch Loss: 2.519026747904718e-05\n",
      "Epoch 4069, Loss: 0.001107208533312587, Final Batch Loss: 8.294816780107794e-07\n",
      "Epoch 4070, Loss: 0.00034829029914362764, Final Batch Loss: 2.2896872451383388e-06\n",
      "Epoch 4071, Loss: 0.00034715603169388487, Final Batch Loss: 6.3422353377973195e-06\n",
      "Epoch 4072, Loss: 0.0010344122056267224, Final Batch Loss: 8.590944344177842e-05\n",
      "Epoch 4073, Loss: 0.0005068299140091881, Final Batch Loss: 1.0430790808868551e-07\n",
      "Epoch 4074, Loss: 0.002593438116946345, Final Batch Loss: 2.082927676383406e-05\n",
      "Epoch 4075, Loss: 0.00012708772646874422, Final Batch Loss: 3.2804928196128458e-06\n",
      "Epoch 4076, Loss: 0.00024966963772499184, Final Batch Loss: 1.1175851000189141e-07\n",
      "Epoch 4077, Loss: 0.0003849029626508127, Final Batch Loss: 1.359901489195181e-05\n",
      "Epoch 4078, Loss: 0.000892795878371544, Final Batch Loss: 3.0569981390726753e-06\n",
      "Epoch 4079, Loss: 0.00047197669846354984, Final Batch Loss: 5.51211996935308e-05\n",
      "Epoch 4080, Loss: 0.00028062121782568283, Final Batch Loss: 9.390390914632007e-05\n",
      "Epoch 4081, Loss: 0.0029837869296898134, Final Batch Loss: 0.0023249080404639244\n",
      "Epoch 4082, Loss: 0.0006767166942580616, Final Batch Loss: 1.8874747809149994e-07\n",
      "Epoch 4083, Loss: 0.00018630583872436546, Final Batch Loss: 0.00010918147745542228\n",
      "Epoch 4084, Loss: 0.0008443609340247349, Final Batch Loss: 8.030819117266219e-06\n",
      "Epoch 4085, Loss: 0.0005609322388409055, Final Batch Loss: 0.0004749492509290576\n",
      "Epoch 4086, Loss: 0.00029022004673606716, Final Batch Loss: 8.897017687559128e-05\n",
      "Epoch 4087, Loss: 0.0007651798387087183, Final Batch Loss: 2.264404065499548e-05\n",
      "Epoch 4088, Loss: 0.0004894888420494681, Final Batch Loss: 4.1347243495692965e-06\n",
      "Epoch 4089, Loss: 0.00040445883496431634, Final Batch Loss: 6.240486254682764e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4090, Loss: 0.0003911359090125188, Final Batch Loss: 6.870915967738256e-05\n",
      "Epoch 4091, Loss: 0.00038133283612751256, Final Batch Loss: 4.420647883307538e-07\n",
      "Epoch 4092, Loss: 0.00016064243777691445, Final Batch Loss: 6.332923021545867e-07\n",
      "Epoch 4093, Loss: 0.0004443608213478001, Final Batch Loss: 8.34074762678938e-06\n",
      "Epoch 4094, Loss: 0.00017574968023836846, Final Batch Loss: 1.8940778318210505e-05\n",
      "Epoch 4095, Loss: 0.00021325523709947447, Final Batch Loss: 1.5596150433339062e-06\n",
      "Epoch 4096, Loss: 0.0008797489790595137, Final Batch Loss: 0.00011284501670161262\n",
      "Epoch 4097, Loss: 0.0002772308507701382, Final Batch Loss: 3.084636773564853e-05\n",
      "Epoch 4098, Loss: 0.00043187802953070786, Final Batch Loss: 5.910762865823926e-07\n",
      "Epoch 4099, Loss: 0.00031642357225791784, Final Batch Loss: 6.594247679458931e-05\n",
      "Epoch 4100, Loss: 0.00017691995162749663, Final Batch Loss: 9.093411063076928e-05\n",
      "Epoch 4101, Loss: 7.78654625719355e-05, Final Batch Loss: 5.3911203394818585e-06\n",
      "Epoch 4102, Loss: 0.00019317898949111623, Final Batch Loss: 1.1672563005049597e-07\n",
      "Epoch 4103, Loss: 6.228165199928526e-05, Final Batch Loss: 2.7318783679675107e-08\n",
      "Epoch 4104, Loss: 0.00013925698567618383, Final Batch Loss: 4.731057561002672e-05\n",
      "Epoch 4105, Loss: 0.001160586103537753, Final Batch Loss: 1.6688680943843792e-06\n",
      "Epoch 4106, Loss: 1.1524271645413364e-05, Final Batch Loss: 4.96705077068782e-08\n",
      "Epoch 4107, Loss: 0.000968156067149728, Final Batch Loss: 4.967053435223079e-09\n",
      "Epoch 4108, Loss: 0.016003231387713868, Final Batch Loss: 4.420642483182746e-07\n",
      "Epoch 4109, Loss: 0.00020804041696464992, Final Batch Loss: 7.526537501689745e-06\n",
      "Epoch 4110, Loss: 0.00014320363536057812, Final Batch Loss: 3.278243809745618e-07\n",
      "Epoch 4111, Loss: 0.00016976875929231028, Final Batch Loss: 1.0753395827123313e-06\n",
      "Epoch 4112, Loss: 0.00036727300903294235, Final Batch Loss: 7.661455310881138e-05\n",
      "Epoch 4113, Loss: 0.0012225478494656272, Final Batch Loss: 0.0\n",
      "Epoch 4114, Loss: 0.00015067401244550638, Final Batch Loss: 7.624345812473621e-07\n",
      "Epoch 4115, Loss: 0.00040363473873838984, Final Batch Loss: 7.698928783383963e-08\n",
      "Epoch 4116, Loss: 0.0005159748887777482, Final Batch Loss: 1.043079933538138e-07\n",
      "Epoch 4117, Loss: 0.0002067801332259478, Final Batch Loss: 1.0679138995328685e-07\n",
      "Epoch 4118, Loss: 0.00036267819632485043, Final Batch Loss: 0.00030180421890690923\n",
      "Epoch 4119, Loss: 0.0003856596822515712, Final Batch Loss: 9.440235771762673e-06\n",
      "Epoch 4120, Loss: 0.00010241943266464659, Final Batch Loss: 1.4404178045879235e-06\n",
      "Epoch 4121, Loss: 0.00200050368827398, Final Batch Loss: 9.934106870446158e-09\n",
      "Epoch 4122, Loss: 0.0001495193141636264, Final Batch Loss: 7.245483720907941e-05\n",
      "Epoch 4123, Loss: 0.0018800841498887166, Final Batch Loss: 0.00015241427172441036\n",
      "Epoch 4124, Loss: 0.0022684745223635616, Final Batch Loss: 3.2285836226719766e-08\n",
      "Epoch 4125, Loss: 0.0008994716281449655, Final Batch Loss: 0.0006658608908765018\n",
      "Epoch 4126, Loss: 0.0003903200286003994, Final Batch Loss: 0.0001230471534654498\n",
      "Epoch 4127, Loss: 0.001148374430158583, Final Batch Loss: 0.0009669510764069855\n",
      "Epoch 4128, Loss: 0.0002879293801214544, Final Batch Loss: 2.0613190088170086e-07\n",
      "Epoch 4129, Loss: 0.0005995488671430849, Final Batch Loss: 4.07296141702318e-07\n",
      "Epoch 4130, Loss: 0.000137264792329006, Final Batch Loss: 1.804873136279639e-05\n",
      "Epoch 4131, Loss: 0.00020446915974758895, Final Batch Loss: 1.7384685691013146e-08\n",
      "Epoch 4132, Loss: 0.00012559792867250508, Final Batch Loss: 6.944565393496305e-05\n",
      "Epoch 4133, Loss: 0.0002463427638303983, Final Batch Loss: 3.6678495689557167e-06\n",
      "Epoch 4134, Loss: 0.00011258957010795712, Final Batch Loss: 2.3786154997651465e-05\n",
      "Epoch 4135, Loss: 0.021728350792955098, Final Batch Loss: 0.021515099331736565\n",
      "Epoch 4136, Loss: 0.0005088546668048366, Final Batch Loss: 1.493104991823202e-05\n",
      "Epoch 4137, Loss: 0.0008054794046046254, Final Batch Loss: 2.3841793961310032e-07\n",
      "Epoch 4138, Loss: 0.0002742592014044476, Final Batch Loss: 4.644152511446009e-07\n",
      "Epoch 4139, Loss: 0.00011051996926880747, Final Batch Loss: 3.476935717117158e-08\n",
      "Epoch 4140, Loss: 0.0008297687700178358, Final Batch Loss: 1.5170244296314195e-05\n",
      "Epoch 4141, Loss: 0.0001439322173837354, Final Batch Loss: 4.221952849547961e-07\n",
      "Epoch 4142, Loss: 0.00021902483376834425, Final Batch Loss: 5.517999397852691e-06\n",
      "Epoch 4143, Loss: 0.00046380736259266087, Final Batch Loss: 3.948773326101218e-07\n",
      "Epoch 4144, Loss: 0.0001330985178356059, Final Batch Loss: 2.0327432139310986e-05\n",
      "Epoch 4145, Loss: 0.0002856071493226864, Final Batch Loss: 3.551428164882964e-07\n",
      "Epoch 4146, Loss: 0.0003109862700512167, Final Batch Loss: 1.0783402103697881e-05\n",
      "Epoch 4147, Loss: 0.0003515594914156317, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4148, Loss: 0.00024055167523329146, Final Batch Loss: 3.4120192140107974e-05\n",
      "Epoch 4149, Loss: 0.0006776300236595034, Final Batch Loss: 8.443984711448138e-08\n",
      "Epoch 4150, Loss: 0.0006378631869665696, Final Batch Loss: 1.4486370673694182e-05\n",
      "Epoch 4151, Loss: 0.0017021008061419707, Final Batch Loss: 3.9696631574770436e-05\n",
      "Epoch 4152, Loss: 0.0003298363499197876, Final Batch Loss: 0.0001192953423014842\n",
      "Epoch 4153, Loss: 0.0007589909801026806, Final Batch Loss: 2.849529846571386e-05\n",
      "Epoch 4154, Loss: 0.0008787568303887383, Final Batch Loss: 0.00027447822503745556\n",
      "Epoch 4155, Loss: 9.809886705625104e-05, Final Batch Loss: 6.607737304875627e-06\n",
      "Epoch 4156, Loss: 0.000931461031143499, Final Batch Loss: 1.8104365153703839e-06\n",
      "Epoch 4157, Loss: 0.00022395202449843055, Final Batch Loss: 5.153644087840803e-05\n",
      "Epoch 4158, Loss: 0.0070108153172441234, Final Batch Loss: 0.0001430285192327574\n",
      "Epoch 4159, Loss: 6.999187625922332e-05, Final Batch Loss: 1.5397817776374723e-07\n",
      "Epoch 4160, Loss: 0.0013709198246942833, Final Batch Loss: 0.0009828128386288881\n",
      "Epoch 4161, Loss: 0.00022097858736813691, Final Batch Loss: 3.476934651303054e-08\n",
      "Epoch 4162, Loss: 0.001410762890600381, Final Batch Loss: 0.0011400877265259624\n",
      "Epoch 4163, Loss: 0.0006438403042920982, Final Batch Loss: 1.2427707588358317e-05\n",
      "Epoch 4164, Loss: 0.0011325398481858429, Final Batch Loss: 6.265039701247588e-06\n",
      "Epoch 4165, Loss: 0.00027546691214297425, Final Batch Loss: 2.980222859605419e-07\n",
      "Epoch 4166, Loss: 0.00010583587572909892, Final Batch Loss: 1.869094376161229e-05\n",
      "Epoch 4167, Loss: 0.0010230309750305366, Final Batch Loss: 5.463754959578182e-08\n",
      "Epoch 4168, Loss: 4.6682187985425116e-05, Final Batch Loss: 6.401548944268143e-06\n",
      "Epoch 4169, Loss: 0.003941806115108193, Final Batch Loss: 7.230868504848331e-06\n",
      "Epoch 4170, Loss: 0.00018147973901250225, Final Batch Loss: 2.250009174531442e-06\n",
      "Epoch 4171, Loss: 9.906664945447119e-05, Final Batch Loss: 8.273628736787941e-06\n",
      "Epoch 4172, Loss: 0.00014124047629593406, Final Batch Loss: 8.909240023058373e-06\n",
      "Epoch 4173, Loss: 0.00010128990925295511, Final Batch Loss: 8.286272532131989e-06\n",
      "Epoch 4174, Loss: 9.530387075784574e-05, Final Batch Loss: 8.443982579819931e-08\n",
      "Epoch 4175, Loss: 0.0010075801363029768, Final Batch Loss: 2.483517675955227e-07\n",
      "Epoch 4176, Loss: 0.0007660591367084635, Final Batch Loss: 1.199527673634293e-06\n",
      "Epoch 4177, Loss: 8.661504580231849e-05, Final Batch Loss: 2.7581510948948562e-05\n",
      "Epoch 4178, Loss: 0.0007170853100433305, Final Batch Loss: 0.0006379043334163725\n",
      "Epoch 4179, Loss: 0.00014994588696026767, Final Batch Loss: 7.325119895540411e-06\n",
      "Epoch 4180, Loss: 0.00011364171518835064, Final Batch Loss: 2.073650875900057e-06\n",
      "Epoch 4181, Loss: 0.0018925062822177097, Final Batch Loss: 9.114400540966017e-07\n",
      "Epoch 4182, Loss: 0.00024270633271505915, Final Batch Loss: 1.9868211964535476e-08\n",
      "Epoch 4183, Loss: 0.0023189217390608974, Final Batch Loss: 0.0020235187839716673\n",
      "Epoch 4184, Loss: 0.00014199732277120347, Final Batch Loss: 4.201831416139612e-06\n",
      "Epoch 4185, Loss: 0.002434546373478952, Final Batch Loss: 0.00018108932999894023\n",
      "Epoch 4186, Loss: 5.5892833188408986e-05, Final Batch Loss: 7.278470093297074e-06\n",
      "Epoch 4187, Loss: 0.00012234463184412903, Final Batch Loss: 4.221993421538173e-08\n",
      "Epoch 4188, Loss: 0.0006861871546162135, Final Batch Loss: 1.2417632255790068e-08\n",
      "Epoch 4189, Loss: 0.0004415902694745455, Final Batch Loss: 8.927853195928037e-05\n",
      "Epoch 4190, Loss: 0.0014011944212768412, Final Batch Loss: 4.2219741658300336e-07\n",
      "Epoch 4191, Loss: 0.010462755794449663, Final Batch Loss: 1.216927358882458e-07\n",
      "Epoch 4192, Loss: 0.00041513564190154284, Final Batch Loss: 1.0306406466042972e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4193, Loss: 0.00015250125079546706, Final Batch Loss: 4.32112619819236e-06\n",
      "Epoch 4194, Loss: 0.025835768529759662, Final Batch Loss: 8.583897397329565e-06\n",
      "Epoch 4195, Loss: 0.0008815350468758254, Final Batch Loss: 1.2417633143968487e-08\n",
      "Epoch 4196, Loss: 0.0006329495336672153, Final Batch Loss: 7.326298714360746e-07\n",
      "Epoch 4197, Loss: 0.0032015878755373706, Final Batch Loss: 5.33894990439876e-06\n",
      "Epoch 4198, Loss: 0.0004888896801276132, Final Batch Loss: 0.00011923749843845144\n",
      "Epoch 4199, Loss: 0.0018081278800901046, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 4200, Loss: 0.00044130974674772006, Final Batch Loss: 6.652577576460317e-05\n",
      "Epoch 4201, Loss: 0.000424211408653008, Final Batch Loss: 5.96045985901128e-08\n",
      "Epoch 4202, Loss: 0.0002473652402841253, Final Batch Loss: 2.968969965877477e-05\n",
      "Epoch 4203, Loss: 0.0009367659004055895, Final Batch Loss: 3.355789158376865e-05\n",
      "Epoch 4204, Loss: 0.00045348686717261444, Final Batch Loss: 0.0001949667203007266\n",
      "Epoch 4205, Loss: 0.0029616481210723578, Final Batch Loss: 9.96229937300086e-05\n",
      "Epoch 4206, Loss: 0.0003454647771832242, Final Batch Loss: 2.5206641112163197e-06\n",
      "Epoch 4207, Loss: 0.00020569815569260186, Final Batch Loss: 1.4901157641133977e-08\n",
      "Epoch 4208, Loss: 0.00035969167583971284, Final Batch Loss: 5.829126530443318e-05\n",
      "Epoch 4209, Loss: 0.004185586404673813, Final Batch Loss: 4.462543984118383e-06\n",
      "Epoch 4210, Loss: 0.06575242646067636, Final Batch Loss: 0.0629158541560173\n",
      "Epoch 4211, Loss: 6.661666884610895e-05, Final Batch Loss: 2.7178584787179716e-05\n",
      "Epoch 4212, Loss: 0.011135139306134079, Final Batch Loss: 0.010680531151592731\n",
      "Epoch 4213, Loss: 0.00046347009447345044, Final Batch Loss: 2.158086317649577e-06\n",
      "Epoch 4214, Loss: 0.0003104600327787921, Final Batch Loss: 3.6783345422009006e-05\n",
      "Epoch 4215, Loss: 0.0009625222173781367, Final Batch Loss: 0.0004371002141851932\n",
      "Epoch 4216, Loss: 0.00033797310607042164, Final Batch Loss: 3.5575616493588313e-05\n",
      "Epoch 4217, Loss: 0.0002927310674749606, Final Batch Loss: 7.013055892457487e-06\n",
      "Epoch 4218, Loss: 0.0069738570164190605, Final Batch Loss: 0.00016820560267660767\n",
      "Epoch 4219, Loss: 0.007186027568025111, Final Batch Loss: 7.177337124630867e-07\n",
      "Epoch 4220, Loss: 0.00045238819912896133, Final Batch Loss: 1.0182449017293038e-07\n",
      "Epoch 4221, Loss: 0.0007357215071692735, Final Batch Loss: 8.940691031966708e-08\n",
      "Epoch 4222, Loss: 0.003312207525254962, Final Batch Loss: 1.7136301266873488e-07\n",
      "Epoch 4223, Loss: 0.014497185097752663, Final Batch Loss: 0.00034878344740718603\n",
      "Epoch 4224, Loss: 0.004937159839755623, Final Batch Loss: 0.004607980605214834\n",
      "Epoch 4225, Loss: 0.0008600380961070186, Final Batch Loss: 2.0165834939689375e-06\n",
      "Epoch 4226, Loss: 0.030091136723058298, Final Batch Loss: 0.0005265007494017482\n",
      "Epoch 4227, Loss: 0.02400489598585409, Final Batch Loss: 5.476632577483542e-05\n",
      "Epoch 4228, Loss: 0.002313838156624115, Final Batch Loss: 2.777606096060481e-05\n",
      "Epoch 4229, Loss: 0.030236508337566192, Final Batch Loss: 6.114107691246318e-06\n",
      "Epoch 4230, Loss: 0.00041565232641005423, Final Batch Loss: 1.608628917892929e-05\n",
      "Epoch 4231, Loss: 0.04928846868938308, Final Batch Loss: 2.7317867079545977e-06\n",
      "Epoch 4232, Loss: 0.0009501252388872672, Final Batch Loss: 1.102673286368372e-05\n",
      "Epoch 4233, Loss: 0.00592250165209407, Final Batch Loss: 9.630039130570367e-05\n",
      "Epoch 4234, Loss: 0.0009429165938854567, Final Batch Loss: 1.5869436538196169e-06\n",
      "Epoch 4235, Loss: 0.0013287769537555505, Final Batch Loss: 9.85946257969772e-07\n",
      "Epoch 4236, Loss: 0.00033937875923584215, Final Batch Loss: 1.0273492080159485e-05\n",
      "Epoch 4237, Loss: 0.002058402260445291, Final Batch Loss: 0.0003163254295941442\n",
      "Epoch 4238, Loss: 0.00043655945228238124, Final Batch Loss: 0.0002532161306589842\n",
      "Epoch 4239, Loss: 0.001181451341835782, Final Batch Loss: 1.7483780538896099e-06\n",
      "Epoch 4240, Loss: 0.005759528932685498, Final Batch Loss: 0.0037565662059932947\n",
      "Epoch 4241, Loss: 0.0011292580566077959, Final Batch Loss: 4.175086723989807e-05\n",
      "Epoch 4242, Loss: 0.00016592672182014212, Final Batch Loss: 8.11763820820488e-05\n",
      "Epoch 4243, Loss: 0.043405040059951716, Final Batch Loss: 9.874677743937355e-06\n",
      "Epoch 4244, Loss: 0.004070070071321652, Final Batch Loss: 3.650768860552489e-07\n",
      "Epoch 4245, Loss: 0.0031609476754965726, Final Batch Loss: 4.619085302692838e-06\n",
      "Epoch 4246, Loss: 0.0004871643750448129, Final Batch Loss: 9.415443491889164e-05\n",
      "Epoch 4247, Loss: 0.0005256741690118361, Final Batch Loss: 2.448681016176124e-06\n",
      "Epoch 4248, Loss: 0.0007569294248241931, Final Batch Loss: 0.0\n",
      "Epoch 4249, Loss: 0.0035056177875958383, Final Batch Loss: 0.0003884711768478155\n",
      "Epoch 4250, Loss: 0.0037897834554314613, Final Batch Loss: 0.0005158653948456049\n",
      "Epoch 4251, Loss: 0.0007982125607668422, Final Batch Loss: 0.0002787715056911111\n",
      "Epoch 4252, Loss: 0.001747349935612874, Final Batch Loss: 0.00050503941019997\n",
      "Epoch 4253, Loss: 0.0018462123362610328, Final Batch Loss: 6.730288646394911e-07\n",
      "Epoch 4254, Loss: 0.015555203881376656, Final Batch Loss: 0.00028368105995468795\n",
      "Epoch 4255, Loss: 0.0016252829882432707, Final Batch Loss: 0.0005460114916786551\n",
      "Epoch 4256, Loss: 0.00041311097720608814, Final Batch Loss: 0.00030956065165810287\n",
      "Epoch 4257, Loss: 0.0005551607755478472, Final Batch Loss: 0.00013278750702738762\n",
      "Epoch 4258, Loss: 0.0003494419401022242, Final Batch Loss: 4.0481279484083643e-07\n",
      "Epoch 4259, Loss: 0.00013409017014964775, Final Batch Loss: 2.1223722797003575e-05\n",
      "Epoch 4260, Loss: 0.0002309210006643525, Final Batch Loss: 1.9868210188178637e-08\n",
      "Epoch 4261, Loss: 0.001277291949463688, Final Batch Loss: 3.89631395592005e-06\n",
      "Epoch 4262, Loss: 0.0018467763147782534, Final Batch Loss: 0.0004157166404183954\n",
      "Epoch 4263, Loss: 0.000247940763074439, Final Batch Loss: 5.559583951253444e-05\n",
      "Epoch 4264, Loss: 0.001527769894892117, Final Batch Loss: 0.0010354084661230445\n",
      "Epoch 4265, Loss: 0.00292430318222614, Final Batch Loss: 0.00022791391529608518\n",
      "Epoch 4266, Loss: 0.0007555362826678902, Final Batch Loss: 6.794653018005192e-05\n",
      "Epoch 4267, Loss: 0.0006792047593577877, Final Batch Loss: 9.934097278119225e-08\n",
      "Epoch 4268, Loss: 0.0003542924432622385, Final Batch Loss: 9.260348633688409e-06\n",
      "Epoch 4269, Loss: 0.00047782693081899197, Final Batch Loss: 1.6191975191759411e-06\n",
      "Epoch 4270, Loss: 0.0002492382295713469, Final Batch Loss: 6.076460067561129e-06\n",
      "Epoch 4271, Loss: 0.011922598602723156, Final Batch Loss: 8.402769890381023e-05\n",
      "Epoch 4272, Loss: 0.0008589795652369503, Final Batch Loss: 0.0004449962580110878\n",
      "Epoch 4273, Loss: 0.006671099989944196, Final Batch Loss: 0.00024210609262809157\n",
      "Epoch 4274, Loss: 0.0012480855608600905, Final Batch Loss: 1.0058089401354664e-06\n",
      "Epoch 4275, Loss: 0.0005397643568922916, Final Batch Loss: 1.7384683914656307e-08\n",
      "Epoch 4276, Loss: 0.004595046847498452, Final Batch Loss: 2.2525046006194316e-06\n",
      "Epoch 4277, Loss: 0.00041549235129423323, Final Batch Loss: 1.7955276234715711e-06\n",
      "Epoch 4278, Loss: 0.0004204186218426109, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 4279, Loss: 0.0028645638485613745, Final Batch Loss: 0.0010582002578303218\n",
      "Epoch 4280, Loss: 0.00043257896429338416, Final Batch Loss: 1.4652793822733656e-07\n",
      "Epoch 4281, Loss: 0.0009415741587872617, Final Batch Loss: 0.0006711903843097389\n",
      "Epoch 4282, Loss: 0.0009860420868790243, Final Batch Loss: 0.00012182420323370025\n",
      "Epoch 4283, Loss: 0.00035276580820209347, Final Batch Loss: 8.517398782714736e-06\n",
      "Epoch 4284, Loss: 0.001561299795866944, Final Batch Loss: 0.0003819528501480818\n",
      "Epoch 4285, Loss: 0.00016467762543204145, Final Batch Loss: 1.4901158529312397e-08\n",
      "Epoch 4286, Loss: 0.0007237534182777949, Final Batch Loss: 1.1672549504737617e-07\n",
      "Epoch 4287, Loss: 0.00020171219682652008, Final Batch Loss: 5.2760329708689824e-05\n",
      "Epoch 4288, Loss: 9.114145541033736e-05, Final Batch Loss: 1.4901157641133977e-08\n",
      "Epoch 4289, Loss: 0.025637101452502975, Final Batch Loss: 2.597492675704416e-05\n",
      "Epoch 4290, Loss: 0.0002575097059889231, Final Batch Loss: 5.222014442551881e-05\n",
      "Epoch 4291, Loss: 0.00029016278494964354, Final Batch Loss: 6.118755209172377e-06\n",
      "Epoch 4292, Loss: 0.01659865093870394, Final Batch Loss: 0.0002054602955467999\n",
      "Epoch 4293, Loss: 5.3010907038242294e-05, Final Batch Loss: 4.917362161904748e-07\n",
      "Epoch 4294, Loss: 0.0015015599219623255, Final Batch Loss: 0.00015385377628263086\n",
      "Epoch 4295, Loss: 0.0007018581600277685, Final Batch Loss: 0.0003423403250053525\n",
      "Epoch 4296, Loss: 0.0006837675116457831, Final Batch Loss: 2.309616093043587e-06\n",
      "Epoch 4297, Loss: 0.004111032463697484, Final Batch Loss: 0.003934922162443399\n",
      "Epoch 4298, Loss: 0.00023675772791875715, Final Batch Loss: 5.06634307839704e-07\n",
      "Epoch 4299, Loss: 0.005194319757720223, Final Batch Loss: 0.004583964589983225\n",
      "Epoch 4300, Loss: 0.0007655647236788354, Final Batch Loss: 0.00017524904978927225\n",
      "Epoch 4301, Loss: 0.00029895410988522997, Final Batch Loss: 2.9802313505911115e-08\n",
      "Epoch 4302, Loss: 0.005982084348943317, Final Batch Loss: 1.4801662473473698e-06\n",
      "Epoch 4303, Loss: 0.00013546326727009728, Final Batch Loss: 2.488331483618822e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4304, Loss: 0.0003024325087608304, Final Batch Loss: 0.0001259486743947491\n",
      "Epoch 4305, Loss: 0.000284759340729579, Final Batch Loss: 7.127666776796104e-07\n",
      "Epoch 4306, Loss: 0.0002468455301518624, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4307, Loss: 0.0001328367103212713, Final Batch Loss: 9.437380299459619e-08\n",
      "Epoch 4308, Loss: 0.0005844503693879233, Final Batch Loss: 1.038266873365501e-05\n",
      "Epoch 4309, Loss: 0.00018120215190720046, Final Batch Loss: 7.052995351841673e-05\n",
      "Epoch 4310, Loss: 0.0008342526689375518, Final Batch Loss: 0.0007682893774472177\n",
      "Epoch 4311, Loss: 9.65899889706634e-05, Final Batch Loss: 5.7355562603333965e-05\n",
      "Epoch 4312, Loss: 0.00040579432652521064, Final Batch Loss: 5.5120151955634356e-05\n",
      "Epoch 4313, Loss: 0.000514173744704749, Final Batch Loss: 1.001701002678601e-05\n",
      "Epoch 4314, Loss: 0.00014063867365621263, Final Batch Loss: 1.0952089724014513e-06\n",
      "Epoch 4315, Loss: 0.0031606435804860666, Final Batch Loss: 0.00215116492472589\n",
      "Epoch 4316, Loss: 7.2873356771197e-05, Final Batch Loss: 1.0927334415100631e-06\n",
      "Epoch 4317, Loss: 0.00017351271708321292, Final Batch Loss: 5.292906644172035e-05\n",
      "Epoch 4318, Loss: 0.00010548170598667639, Final Batch Loss: 4.34615003541694e-07\n",
      "Epoch 4319, Loss: 5.767675975221209e-05, Final Batch Loss: 1.0361213753640186e-05\n",
      "Epoch 4320, Loss: 0.0008156306348610087, Final Batch Loss: 0.0007295878021977842\n",
      "Epoch 4321, Loss: 0.0002163007902655778, Final Batch Loss: 2.2351736461700966e-08\n",
      "Epoch 4322, Loss: 0.00810747841057946, Final Batch Loss: 2.600432162580546e-05\n",
      "Epoch 4323, Loss: 0.0002363632416972905, Final Batch Loss: 1.0803074701470905e-06\n",
      "Epoch 4324, Loss: 0.00038154514413690777, Final Batch Loss: 5.016704562876839e-07\n",
      "Epoch 4325, Loss: 0.0029401451283774804, Final Batch Loss: 0.0023208160419017076\n",
      "Epoch 4326, Loss: 0.007836671811674023, Final Batch Loss: 7.452858699252829e-05\n",
      "Epoch 4327, Loss: 0.00016564340785407694, Final Batch Loss: 9.068976942216977e-05\n",
      "Epoch 4328, Loss: 0.0004488368722377345, Final Batch Loss: 4.5095381210558116e-05\n",
      "Epoch 4329, Loss: 0.0007266477041412145, Final Batch Loss: 3.250099689466879e-05\n",
      "Epoch 4330, Loss: 0.003595245886018006, Final Batch Loss: 1.9123071126614377e-07\n",
      "Epoch 4331, Loss: 0.0005347569713194389, Final Batch Loss: 2.177441092499066e-05\n",
      "Epoch 4332, Loss: 0.0003785556282309699, Final Batch Loss: 8.36782328406116e-06\n",
      "Epoch 4333, Loss: 0.0003630301675450198, Final Batch Loss: 5.215401799318897e-08\n",
      "Epoch 4334, Loss: 0.00037243994120217394, Final Batch Loss: 6.51852969895117e-05\n",
      "Epoch 4335, Loss: 0.0010869934212678345, Final Batch Loss: 0.0002917061501648277\n",
      "Epoch 4336, Loss: 0.00037392629883470363, Final Batch Loss: 5.962155682937009e-06\n",
      "Epoch 4337, Loss: 0.009092073155443359, Final Batch Loss: 0.0002772214647848159\n",
      "Epoch 4338, Loss: 0.0002740700897447823, Final Batch Loss: 6.431390374928014e-06\n",
      "Epoch 4339, Loss: 0.00028296259506532806, Final Batch Loss: 4.750446805701358e-06\n",
      "Epoch 4340, Loss: 0.0032847462216523127, Final Batch Loss: 0.0004836058069486171\n",
      "Epoch 4341, Loss: 0.0019134784106427105, Final Batch Loss: 0.001513320836238563\n",
      "Epoch 4342, Loss: 0.0001882762553577777, Final Batch Loss: 7.937585905892774e-05\n",
      "Epoch 4343, Loss: 0.0011609028224484064, Final Batch Loss: 0.0005043681594543159\n",
      "Epoch 4344, Loss: 0.0006044765747592606, Final Batch Loss: 9.934106870446158e-09\n",
      "Epoch 4345, Loss: 0.00567009150472586, Final Batch Loss: 8.021143003134057e-05\n",
      "Epoch 4346, Loss: 0.0003725222159118857, Final Batch Loss: 0.0002165370824513957\n",
      "Epoch 4347, Loss: 0.0001415909791830927, Final Batch Loss: 6.258051143959165e-05\n",
      "Epoch 4348, Loss: 0.0002589309874565515, Final Batch Loss: 6.749705335096223e-06\n",
      "Epoch 4349, Loss: 0.00010875818041711227, Final Batch Loss: 1.3659381181696517e-07\n",
      "Epoch 4350, Loss: 0.00013171898399377824, Final Batch Loss: 4.387930403026985e-06\n",
      "Epoch 4351, Loss: 0.00027869289260706864, Final Batch Loss: 6.13113006693311e-05\n",
      "Epoch 4352, Loss: 0.00018341886334383162, Final Batch Loss: 5.662386683980003e-07\n",
      "Epoch 4353, Loss: 8.740400517126545e-05, Final Batch Loss: 1.555960079713259e-05\n",
      "Epoch 4354, Loss: 0.00035620095720645395, Final Batch Loss: 6.45716440317301e-08\n",
      "Epoch 4355, Loss: 0.00029599180067663156, Final Batch Loss: 7.698924520127548e-08\n",
      "Epoch 4356, Loss: 0.00020799440272867287, Final Batch Loss: 4.9670518365019234e-08\n",
      "Epoch 4357, Loss: 0.0006451432298035797, Final Batch Loss: 3.161404265483725e-06\n",
      "Epoch 4358, Loss: 0.0011351210905559128, Final Batch Loss: 0.001009362400509417\n",
      "Epoch 4359, Loss: 0.0003016121206655953, Final Batch Loss: 3.0745029562240234e-06\n",
      "Epoch 4360, Loss: 0.00011194165949746093, Final Batch Loss: 5.619664807454683e-05\n",
      "Epoch 4361, Loss: 0.000543339458090486, Final Batch Loss: 0.00017437465430703014\n",
      "Epoch 4362, Loss: 0.000365685692486295, Final Batch Loss: 4.4705175241688266e-05\n",
      "Epoch 4363, Loss: 0.0001385451830628881, Final Batch Loss: 8.990270998765482e-07\n",
      "Epoch 4364, Loss: 0.00022153555039494677, Final Batch Loss: 4.2467911498533795e-07\n",
      "Epoch 4365, Loss: 0.0002077848325825471, Final Batch Loss: 5.4482566156366374e-06\n",
      "Epoch 4366, Loss: 0.0006615867982873169, Final Batch Loss: 5.470307951327413e-05\n",
      "Epoch 4367, Loss: 0.00047948114297469147, Final Batch Loss: 0.0003151141572743654\n",
      "Epoch 4368, Loss: 0.00022171596356201917, Final Batch Loss: 6.440835568355396e-05\n",
      "Epoch 4369, Loss: 0.0003321222461636353, Final Batch Loss: 3.8950456655584276e-05\n",
      "Epoch 4370, Loss: 4.5744775434286566e-05, Final Batch Loss: 7.904209269327112e-06\n",
      "Epoch 4371, Loss: 0.00012150770968810676, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4372, Loss: 0.02885957344665968, Final Batch Loss: 6.457162982087539e-08\n",
      "Epoch 4373, Loss: 0.000371147636542446, Final Batch Loss: 0.00010700467828428373\n",
      "Epoch 4374, Loss: 0.0004529254065346322, Final Batch Loss: 0.0003120852343272418\n",
      "Epoch 4375, Loss: 9.715457957781837e-05, Final Batch Loss: 2.227665390819311e-06\n",
      "Epoch 4376, Loss: 0.0005278942135191755, Final Batch Loss: 0.0004404971841722727\n",
      "Epoch 4377, Loss: 0.0001590739251753348, Final Batch Loss: 2.831206131759245e-07\n",
      "Epoch 4378, Loss: 0.00013087290153634967, Final Batch Loss: 3.188605660398025e-06\n",
      "Epoch 4379, Loss: 0.00017216269316122634, Final Batch Loss: 6.82228128425777e-05\n",
      "Epoch 4380, Loss: 0.0009297337364841951, Final Batch Loss: 7.598880984005518e-06\n",
      "Epoch 4381, Loss: 0.00023849325445723935, Final Batch Loss: 1.589454967643178e-07\n",
      "Epoch 4382, Loss: 0.0005300303728290601, Final Batch Loss: 0.0001662800059420988\n",
      "Epoch 4383, Loss: 0.00025348216388465517, Final Batch Loss: 1.807979629120382e-06\n",
      "Epoch 4384, Loss: 0.00038566013830632073, Final Batch Loss: 6.15910209944559e-07\n",
      "Epoch 4385, Loss: 0.0006106674554753333, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 4386, Loss: 0.00040265352856749814, Final Batch Loss: 1.8378034383204067e-07\n",
      "Epoch 4387, Loss: 0.000708844663677155, Final Batch Loss: 1.5666291801608168e-05\n",
      "Epoch 4388, Loss: 0.0002121989650163414, Final Batch Loss: 7.450574912581942e-08\n",
      "Epoch 4389, Loss: 0.0003387361642523956, Final Batch Loss: 3.1292378821490274e-07\n",
      "Epoch 4390, Loss: 0.00035339174314685806, Final Batch Loss: 0.0002760063798632473\n",
      "Epoch 4391, Loss: 0.0006350602361635538, Final Batch Loss: 1.9293294826638885e-05\n",
      "Epoch 4392, Loss: 0.004808538709767163, Final Batch Loss: 0.0\n",
      "Epoch 4393, Loss: 7.311461255676832e-05, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4394, Loss: 0.00010835892771865474, Final Batch Loss: 2.0786146706086583e-06\n",
      "Epoch 4395, Loss: 0.0006255386251723394, Final Batch Loss: 1.2406533642206341e-05\n",
      "Epoch 4396, Loss: 0.00020180124259638887, Final Batch Loss: 1.912310239049475e-07\n",
      "Epoch 4397, Loss: 0.00014259511590353213, Final Batch Loss: 7.674034350202419e-07\n",
      "Epoch 4398, Loss: 0.0004893764271400869, Final Batch Loss: 7.36579459044151e-05\n",
      "Epoch 4399, Loss: 0.012954288074254805, Final Batch Loss: 1.8626424491685611e-07\n",
      "Epoch 4400, Loss: 0.00019356276115445326, Final Batch Loss: 4.072968238233443e-07\n",
      "Epoch 4401, Loss: 0.00043386104175624496, Final Batch Loss: 3.581125611162861e-06\n",
      "Epoch 4402, Loss: 0.0001275693292654978, Final Batch Loss: 3.079566113228793e-07\n",
      "Epoch 4403, Loss: 0.00017647591994318645, Final Batch Loss: 0.0\n",
      "Epoch 4404, Loss: 6.10879613986981e-05, Final Batch Loss: 1.5918841427264852e-06\n",
      "Epoch 4405, Loss: 0.0005739842053458233, Final Batch Loss: 8.915775993045827e-07\n",
      "Epoch 4406, Loss: 0.0003780834758799756, Final Batch Loss: 2.6307005100534298e-05\n",
      "Epoch 4407, Loss: 0.00015723765681308066, Final Batch Loss: 2.9802313505911115e-08\n",
      "Epoch 4408, Loss: 0.0012021851125609828, Final Batch Loss: 4.619341780198738e-07\n",
      "Epoch 4409, Loss: 0.00017696683744361508, Final Batch Loss: 5.97947973801638e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4410, Loss: 0.0006556601654779115, Final Batch Loss: 1.266596996174485e-07\n",
      "Epoch 4411, Loss: 0.00027151964945915097, Final Batch Loss: 2.898082357205567e-06\n",
      "Epoch 4412, Loss: 0.00034774685991578735, Final Batch Loss: 0.00015998799062799662\n",
      "Epoch 4413, Loss: 0.0004799825546797365, Final Batch Loss: 8.276219887193292e-06\n",
      "Epoch 4414, Loss: 9.142113799498475e-05, Final Batch Loss: 2.3071272607921856e-06\n",
      "Epoch 4415, Loss: 0.00020518066678221203, Final Batch Loss: 2.1358293622597557e-07\n",
      "Epoch 4416, Loss: 0.00023874169426107983, Final Batch Loss: 4.106482447241433e-05\n",
      "Epoch 4417, Loss: 7.45927024254911e-05, Final Batch Loss: 9.685746960030883e-08\n",
      "Epoch 4418, Loss: 0.0004396524054754991, Final Batch Loss: 0.00019741161668207496\n",
      "Epoch 4419, Loss: 0.000814361903394456, Final Batch Loss: 1.8565202481113374e-05\n",
      "Epoch 4420, Loss: 0.00014104561000749527, Final Batch Loss: 2.528158120185253e-06\n",
      "Epoch 4421, Loss: 0.0010967582744854099, Final Batch Loss: 5.9604559510262334e-08\n",
      "Epoch 4422, Loss: 0.00015822951144173203, Final Batch Loss: 5.960443445474084e-07\n",
      "Epoch 4423, Loss: 0.0003638362659330596, Final Batch Loss: 2.513177605578676e-06\n",
      "Epoch 4424, Loss: 0.0005124421654727485, Final Batch Loss: 0.00016825324564706534\n",
      "Epoch 4425, Loss: 0.0002986370154758333, Final Batch Loss: 9.194408630719408e-05\n",
      "Epoch 4426, Loss: 0.0009214298997903825, Final Batch Loss: 0.0005374853499233723\n",
      "Epoch 4427, Loss: 0.0003148101932310965, Final Batch Loss: 3.1981089705368504e-05\n",
      "Epoch 4428, Loss: 0.0005198501817176293, Final Batch Loss: 0.00010315156396245584\n",
      "Epoch 4429, Loss: 0.0016994830730254762, Final Batch Loss: 5.0970975280506536e-05\n",
      "Epoch 4430, Loss: 0.00025120642021647654, Final Batch Loss: 1.530053668830078e-05\n",
      "Epoch 4431, Loss: 0.00048462280471994745, Final Batch Loss: 1.4925761888662237e-06\n",
      "Epoch 4432, Loss: 0.0003916180028227245, Final Batch Loss: 2.2549663754034555e-06\n",
      "Epoch 4433, Loss: 0.0001297365222399094, Final Batch Loss: 3.1414344903168967e-06\n",
      "Epoch 4434, Loss: 0.00015770847778640018, Final Batch Loss: 3.953110717702657e-05\n",
      "Epoch 4435, Loss: 0.000628504269720942, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 4436, Loss: 9.568028735884582e-05, Final Batch Loss: 2.1178753740969114e-05\n",
      "Epoch 4437, Loss: 0.00029130024746137906, Final Batch Loss: 7.202221041779922e-08\n",
      "Epoch 4438, Loss: 0.00012530339381555677, Final Batch Loss: 1.7141701391665265e-05\n",
      "Epoch 4439, Loss: 0.00020298569253895948, Final Batch Loss: 4.470345515983354e-08\n",
      "Epoch 4440, Loss: 0.00030669635549429586, Final Batch Loss: 1.9868190292982035e-07\n",
      "Epoch 4441, Loss: 0.00021095214466626544, Final Batch Loss: 4.470345160711986e-08\n",
      "Epoch 4442, Loss: 0.00025251289753214223, Final Batch Loss: 0.00012836568930651993\n",
      "Epoch 4443, Loss: 0.00018314870783342485, Final Batch Loss: 0.00015642512880731374\n",
      "Epoch 4444, Loss: 0.0002218142358287878, Final Batch Loss: 6.503872555185808e-06\n",
      "Epoch 4445, Loss: 0.000891856615226061, Final Batch Loss: 3.593361498133163e-06\n",
      "Epoch 4446, Loss: 0.00010441883023304399, Final Batch Loss: 2.768635022221133e-05\n",
      "Epoch 4447, Loss: 0.00031753277164625615, Final Batch Loss: 5.46375531484955e-08\n",
      "Epoch 4448, Loss: 0.009361188395814679, Final Batch Loss: 1.2717387107841205e-05\n",
      "Epoch 4449, Loss: 0.0005260681755316909, Final Batch Loss: 0.0002574294339865446\n",
      "Epoch 4450, Loss: 0.001256181917824506, Final Batch Loss: 9.735324510984356e-07\n",
      "Epoch 4451, Loss: 5.681234171106553e-05, Final Batch Loss: 4.793158154825505e-07\n",
      "Epoch 4452, Loss: 9.61457426456036e-05, Final Batch Loss: 3.6479941627476364e-06\n",
      "Epoch 4453, Loss: 9.939421565263729e-05, Final Batch Loss: 2.7815357839244825e-07\n",
      "Epoch 4454, Loss: 0.00016047563894971972, Final Batch Loss: 5.421181413112208e-06\n",
      "Epoch 4455, Loss: 0.0009926583657033916, Final Batch Loss: 7.823032319720369e-07\n",
      "Epoch 4456, Loss: 0.0008584905596418224, Final Batch Loss: 2.4835264511580135e-08\n",
      "Epoch 4457, Loss: 0.00010350009323722986, Final Batch Loss: 2.9802313505911115e-08\n",
      "Epoch 4458, Loss: 0.00012523756393534313, Final Batch Loss: 4.47033272621411e-07\n",
      "Epoch 4459, Loss: 0.0003359346228535287, Final Batch Loss: 0.0001902936928672716\n",
      "Epoch 4460, Loss: 7.614922105858568e-05, Final Batch Loss: 6.630950792896328e-07\n",
      "Epoch 4461, Loss: 0.000152572961013675, Final Batch Loss: 2.73186941512904e-07\n",
      "Epoch 4462, Loss: 0.00022070735820989285, Final Batch Loss: 9.238535199074249e-07\n",
      "Epoch 4463, Loss: 0.00184247647121083, Final Batch Loss: 1.4218451724445913e-05\n",
      "Epoch 4464, Loss: 0.0001409714027431619, Final Batch Loss: 4.482343229028629e-06\n",
      "Epoch 4465, Loss: 0.0003649013797257794, Final Batch Loss: 8.210684609366581e-05\n",
      "Epoch 4466, Loss: 0.00036942833048669854, Final Batch Loss: 0.0\n",
      "Epoch 4467, Loss: 6.639643311245891e-05, Final Batch Loss: 3.408217162359506e-05\n",
      "Epoch 4468, Loss: 7.58722679421453e-05, Final Batch Loss: 2.1606577149668738e-07\n",
      "Epoch 4469, Loss: 6.756290940757026e-05, Final Batch Loss: 6.486128313554218e-06\n",
      "Epoch 4470, Loss: 4.381729277724844e-05, Final Batch Loss: 3.6207427456247387e-06\n",
      "Epoch 4471, Loss: 0.00019172417250956642, Final Batch Loss: 5.160132332093781e-06\n",
      "Epoch 4472, Loss: 0.00022480744905806205, Final Batch Loss: 0.0002096943062497303\n",
      "Epoch 4473, Loss: 0.00010356218535889639, Final Batch Loss: 5.728281757910736e-05\n",
      "Epoch 4474, Loss: 0.01326717383653886, Final Batch Loss: 0.0004066968394909054\n",
      "Epoch 4475, Loss: 0.0013049641957962876, Final Batch Loss: 1.5397846198084153e-07\n",
      "Epoch 4476, Loss: 0.003214260549299297, Final Batch Loss: 4.221953133765055e-07\n",
      "Epoch 4477, Loss: 0.0005852700742252637, Final Batch Loss: 0.00036264932714402676\n",
      "Epoch 4478, Loss: 0.000273009725447082, Final Batch Loss: 1.6092950545498752e-06\n",
      "Epoch 4479, Loss: 0.0007581943300465355, Final Batch Loss: 0.000529728305991739\n",
      "Epoch 4480, Loss: 0.00022274521745657694, Final Batch Loss: 1.6986874697977328e-06\n",
      "Epoch 4481, Loss: 0.0002561404519703103, Final Batch Loss: 5.712107409294731e-08\n",
      "Epoch 4482, Loss: 0.0004539654291875195, Final Batch Loss: 0.0002713675203267485\n",
      "Epoch 4483, Loss: 0.00014401203816305497, Final Batch Loss: 3.0503309972118586e-05\n",
      "Epoch 4484, Loss: 0.00010570331596682081, Final Batch Loss: 9.083089935302269e-06\n",
      "Epoch 4485, Loss: 0.0014315854605229106, Final Batch Loss: 0.0007747823256067932\n",
      "Epoch 4486, Loss: 0.0013565671088144882, Final Batch Loss: 0.0002799687208607793\n",
      "Epoch 4487, Loss: 0.00029144497557354043, Final Batch Loss: 5.40106293556164e-06\n",
      "Epoch 4488, Loss: 0.00011260796389933603, Final Batch Loss: 6.804754661970946e-07\n",
      "Epoch 4489, Loss: 0.0003196488039520773, Final Batch Loss: 7.500123047066154e-07\n",
      "Epoch 4490, Loss: 0.00014753831871416878, Final Batch Loss: 1.4156054817249242e-07\n",
      "Epoch 4491, Loss: 0.00016243416212091688, Final Batch Loss: 2.1136505893082358e-05\n",
      "Epoch 4492, Loss: 0.00012643507352549932, Final Batch Loss: 4.417763648234541e-06\n",
      "Epoch 4493, Loss: 0.00011949767394980881, Final Batch Loss: 4.69109982077498e-05\n",
      "Epoch 4494, Loss: 0.00301239715068391, Final Batch Loss: 2.756697483619064e-07\n",
      "Epoch 4495, Loss: 0.00028120112816765186, Final Batch Loss: 9.934105094089318e-09\n",
      "Epoch 4496, Loss: 3.757265608328453e-05, Final Batch Loss: 2.3617315036972286e-06\n",
      "Epoch 4497, Loss: 0.003580497778841618, Final Batch Loss: 5.314705617820437e-07\n",
      "Epoch 4498, Loss: 0.00016872835891490467, Final Batch Loss: 6.034884449945821e-07\n",
      "Epoch 4499, Loss: 0.00015071005191202858, Final Batch Loss: 3.83430369765847e-06\n",
      "Epoch 4500, Loss: 0.0012897773758595577, Final Batch Loss: 0.0010332464007660747\n",
      "Epoch 4501, Loss: 0.00012022101583397671, Final Batch Loss: 1.0349366675654892e-05\n",
      "Epoch 4502, Loss: 7.634494875219389e-05, Final Batch Loss: 3.1740466511109844e-05\n",
      "Epoch 4503, Loss: 5.492709072996149e-05, Final Batch Loss: 5.985215807413624e-07\n",
      "Epoch 4504, Loss: 0.00018445644491293933, Final Batch Loss: 4.3993200961267576e-05\n",
      "Epoch 4505, Loss: 0.0001406406126989168, Final Batch Loss: 5.512430288945325e-05\n",
      "Epoch 4506, Loss: 5.4531889361442154e-05, Final Batch Loss: 2.955377453872643e-07\n",
      "Epoch 4507, Loss: 0.00013044659931438218, Final Batch Loss: 2.103442284351331e-06\n",
      "Epoch 4508, Loss: 0.0005476937858475139, Final Batch Loss: 0.00027101268642582\n",
      "Epoch 4509, Loss: 0.00010812109758262523, Final Batch Loss: 2.207747456850484e-06\n",
      "Epoch 4510, Loss: 0.0006415943746560515, Final Batch Loss: 2.4684807158337208e-06\n",
      "Epoch 4511, Loss: 0.0004390994017740013, Final Batch Loss: 5.7769746490521356e-05\n",
      "Epoch 4512, Loss: 0.00010149251706437212, Final Batch Loss: 3.973640971821624e-08\n",
      "Epoch 4513, Loss: 0.0004629145669241552, Final Batch Loss: 3.4767735996865667e-06\n",
      "Epoch 4514, Loss: 0.0003642940186523447, Final Batch Loss: 7.549801352979557e-07\n",
      "Epoch 4515, Loss: 7.050492490634497e-05, Final Batch Loss: 2.908937312895432e-05\n",
      "Epoch 4516, Loss: 0.0003381707553367086, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4517, Loss: 2.0568228620732043e-05, Final Batch Loss: 2.4835210865603585e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4518, Loss: 0.0001070906798759097, Final Batch Loss: 9.550423783366568e-06\n",
      "Epoch 4519, Loss: 0.0003880272852256894, Final Batch Loss: 0.0002374528703512624\n",
      "Epoch 4520, Loss: 7.574662777187768e-05, Final Batch Loss: 1.2292314750084188e-05\n",
      "Epoch 4521, Loss: 0.0008374162346171943, Final Batch Loss: 0.00077176553895697\n",
      "Epoch 4522, Loss: 0.0005003771093470277, Final Batch Loss: 7.641081901965663e-05\n",
      "Epoch 4523, Loss: 0.005534455612178135, Final Batch Loss: 0.00014789316628593951\n",
      "Epoch 4524, Loss: 0.00024176390797947533, Final Batch Loss: 0.0\n",
      "Epoch 4525, Loss: 0.00018404375430236541, Final Batch Loss: 1.10763164684613e-06\n",
      "Epoch 4526, Loss: 0.0001621158898643671, Final Batch Loss: 2.260002958109908e-07\n",
      "Epoch 4527, Loss: 4.725453709397698e-05, Final Batch Loss: 4.874881597061176e-06\n",
      "Epoch 4528, Loss: 0.00016869296450705562, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 4529, Loss: 0.00011844119808301912, Final Batch Loss: 5.582229732681299e-06\n",
      "Epoch 4530, Loss: 0.0001361316080696895, Final Batch Loss: 3.7252885221050747e-08\n",
      "Epoch 4531, Loss: 0.0009395621332259907, Final Batch Loss: 0.0009031507652252913\n",
      "Epoch 4532, Loss: 0.00013799026081073862, Final Batch Loss: 3.1788934506948863e-07\n",
      "Epoch 4533, Loss: 0.0001428657439532799, Final Batch Loss: 1.1101132031399175e-06\n",
      "Epoch 4534, Loss: 0.010280625945746635, Final Batch Loss: 1.7384685691013146e-08\n",
      "Epoch 4535, Loss: 0.00016990572220265676, Final Batch Loss: 8.816420518087398e-07\n",
      "Epoch 4536, Loss: 0.0003764810430482157, Final Batch Loss: 2.9553891067735094e-07\n",
      "Epoch 4537, Loss: 0.0007797867908720946, Final Batch Loss: 0.0002205405617132783\n",
      "Epoch 4538, Loss: 0.0005877803724558817, Final Batch Loss: 3.5514139540282486e-07\n",
      "Epoch 4539, Loss: 0.00042105342964759984, Final Batch Loss: 8.717086643628136e-07\n",
      "Epoch 4540, Loss: 0.0016899435371016125, Final Batch Loss: 1.9868210188178637e-08\n",
      "Epoch 4541, Loss: 0.0003477412938082125, Final Batch Loss: 0.0\n",
      "Epoch 4542, Loss: 0.0007286240584107873, Final Batch Loss: 0.0006944538909010589\n",
      "Epoch 4543, Loss: 0.00011435642397561452, Final Batch Loss: 1.4901158529312397e-08\n",
      "Epoch 4544, Loss: 0.000661208106379263, Final Batch Loss: 3.0547229812327714e-07\n",
      "Epoch 4545, Loss: 0.0018774696964101167, Final Batch Loss: 4.973585237166844e-05\n",
      "Epoch 4546, Loss: 0.00016345373563808607, Final Batch Loss: 5.165701963960601e-07\n",
      "Epoch 4547, Loss: 0.0003397188020244357, Final Batch Loss: 1.1049040040234104e-05\n",
      "Epoch 4548, Loss: 2.8066235884693924e-05, Final Batch Loss: 4.470344094897882e-08\n",
      "Epoch 4549, Loss: 0.00014585887254270347, Final Batch Loss: 1.492546630288416e-06\n",
      "Epoch 4550, Loss: 0.002117733278282685, Final Batch Loss: 0.00023165806487668306\n",
      "Epoch 4551, Loss: 0.00035515824220055947, Final Batch Loss: 9.246629815606866e-06\n",
      "Epoch 4552, Loss: 5.1962615543743595e-05, Final Batch Loss: 1.3518740161089227e-05\n",
      "Epoch 4553, Loss: 7.43918049010972e-05, Final Batch Loss: 0.0\n",
      "Epoch 4554, Loss: 8.080660060727496e-05, Final Batch Loss: 1.323701781075215e-06\n",
      "Epoch 4555, Loss: 2.628923825298557e-05, Final Batch Loss: 3.228582912129241e-08\n",
      "Epoch 4556, Loss: 0.0002661542753230606, Final Batch Loss: 2.6555091608315706e-05\n",
      "Epoch 4557, Loss: 0.00034894286697317867, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4558, Loss: 0.002564201322002191, Final Batch Loss: 7.308162821573205e-06\n",
      "Epoch 4559, Loss: 0.0005297163079376332, Final Batch Loss: 1.9197417714167386e-05\n",
      "Epoch 4560, Loss: 0.00010836149445481169, Final Batch Loss: 3.2782432413114293e-07\n",
      "Epoch 4561, Loss: 9.943115912847134e-05, Final Batch Loss: 1.4875796523483586e-06\n",
      "Epoch 4562, Loss: 3.0136448856410425e-05, Final Batch Loss: 5.78656852212589e-07\n",
      "Epoch 4563, Loss: 0.0002545878281807745, Final Batch Loss: 0.0002250674442620948\n",
      "Epoch 4564, Loss: 8.703022569989116e-05, Final Batch Loss: 2.688986023713369e-05\n",
      "Epoch 4565, Loss: 0.00028523870969365817, Final Batch Loss: 0.0001328936341451481\n",
      "Epoch 4566, Loss: 5.2236643568903673e-05, Final Batch Loss: 1.3568212125392165e-05\n",
      "Epoch 4567, Loss: 0.00016297911493978745, Final Batch Loss: 6.705518984517767e-08\n",
      "Epoch 4568, Loss: 0.0007081162048052647, Final Batch Loss: 4.618868842953816e-06\n",
      "Epoch 4569, Loss: 0.0001241563506653165, Final Batch Loss: 3.1540568556920334e-07\n",
      "Epoch 4570, Loss: 5.96045524492439e-05, Final Batch Loss: 2.235172935627361e-08\n",
      "Epoch 4571, Loss: 2.0807479415907437e-05, Final Batch Loss: 1.6291636484311312e-06\n",
      "Epoch 4572, Loss: 3.822058384628235e-05, Final Batch Loss: 1.837805569948614e-07\n",
      "Epoch 4573, Loss: 6.0777160797442775e-05, Final Batch Loss: 2.2158235879032873e-05\n",
      "Epoch 4574, Loss: 2.520926326354811e-05, Final Batch Loss: 1.0380889534644666e-06\n",
      "Epoch 4575, Loss: 3.529600086693563e-05, Final Batch Loss: 2.2351734685344127e-08\n",
      "Epoch 4576, Loss: 0.00023051105154081597, Final Batch Loss: 6.700213270960376e-05\n",
      "Epoch 4577, Loss: 0.00028153526727692224, Final Batch Loss: 3.2565858418820426e-05\n",
      "Epoch 4578, Loss: 3.152128579131386e-05, Final Batch Loss: 2.1087427739985287e-05\n",
      "Epoch 4579, Loss: 5.492056720868277e-05, Final Batch Loss: 2.1903579181525856e-06\n",
      "Epoch 4580, Loss: 5.171501258871558e-05, Final Batch Loss: 1.4404433557047014e-07\n",
      "Epoch 4581, Loss: 1.2143960617549965e-05, Final Batch Loss: 5.9604559510262334e-08\n",
      "Epoch 4582, Loss: 6.223765967661166e-05, Final Batch Loss: 5.5375949159497395e-06\n",
      "Epoch 4583, Loss: 0.00011291819397030167, Final Batch Loss: 7.947279101472304e-08\n",
      "Epoch 4584, Loss: 0.00015394512956845574, Final Batch Loss: 9.812617645366117e-05\n",
      "Epoch 4585, Loss: 0.0002577770616056796, Final Batch Loss: 1.6639579314414732e-07\n",
      "Epoch 4586, Loss: 0.00017587653474038234, Final Batch Loss: 0.0\n",
      "Epoch 4587, Loss: 0.00011341488206539907, Final Batch Loss: 3.7997673985046276e-07\n",
      "Epoch 4588, Loss: 8.541769746273076e-05, Final Batch Loss: 1.986818460864015e-07\n",
      "Epoch 4589, Loss: 0.0035964072010585824, Final Batch Loss: 0.0015604463405907154\n",
      "Epoch 4590, Loss: 5.6787602808583415e-05, Final Batch Loss: 8.443985421990874e-08\n",
      "Epoch 4591, Loss: 8.10791309504566e-05, Final Batch Loss: 1.1920667475351365e-06\n",
      "Epoch 4592, Loss: 0.00013633573237825658, Final Batch Loss: 2.8312084054959996e-07\n",
      "Epoch 4593, Loss: 7.495760348774638e-05, Final Batch Loss: 1.0877662361963303e-06\n",
      "Epoch 4594, Loss: 4.096059166158739e-05, Final Batch Loss: 7.202175424936286e-07\n",
      "Epoch 4595, Loss: 0.0002081180937238969, Final Batch Loss: 0.0\n",
      "Epoch 4596, Loss: 5.582096650869062e-05, Final Batch Loss: 5.294341463013552e-06\n",
      "Epoch 4597, Loss: 5.1100660357406014e-05, Final Batch Loss: 2.542977881603292e-06\n",
      "Epoch 4598, Loss: 0.0003372088504716153, Final Batch Loss: 4.967052991133869e-09\n",
      "Epoch 4599, Loss: 0.00012315047991151573, Final Batch Loss: 3.973639550736152e-08\n",
      "Epoch 4600, Loss: 7.66471720403672e-05, Final Batch Loss: 4.7186990315140065e-08\n",
      "Epoch 4601, Loss: 0.00010523712172272326, Final Batch Loss: 7.698918835785662e-08\n",
      "Epoch 4602, Loss: 2.619383131907682e-05, Final Batch Loss: 2.235172935627361e-08\n",
      "Epoch 4603, Loss: 3.163656651850033e-05, Final Batch Loss: 1.380900721414946e-05\n",
      "Epoch 4604, Loss: 0.00017939436247615959, Final Batch Loss: 3.883122917613946e-05\n",
      "Epoch 4605, Loss: 0.004978338357204848, Final Batch Loss: 3.119181201327592e-06\n",
      "Epoch 4606, Loss: 0.0001243255451299774, Final Batch Loss: 9.83469817583682e-07\n",
      "Epoch 4607, Loss: 0.00019260401758458556, Final Batch Loss: 1.7384617478910513e-07\n",
      "Epoch 4608, Loss: 0.00034288126562387333, Final Batch Loss: 0.00029030509176664054\n",
      "Epoch 4609, Loss: 0.00020106439234268692, Final Batch Loss: 6.730249992870085e-07\n",
      "Epoch 4610, Loss: 3.7875935390729865e-05, Final Batch Loss: 3.6756060239895305e-07\n",
      "Epoch 4611, Loss: 0.0031582912311023392, Final Batch Loss: 0.0\n",
      "Epoch 4612, Loss: 6.871481248937883e-05, Final Batch Loss: 4.967052991133869e-09\n",
      "Epoch 4613, Loss: 6.475047760545749e-05, Final Batch Loss: 1.1920909059881524e-07\n",
      "Epoch 4614, Loss: 1.4838186185528457e-05, Final Batch Loss: 1.4901157641133977e-08\n",
      "Epoch 4615, Loss: 0.0004579193655445124, Final Batch Loss: 7.996814019861631e-07\n",
      "Epoch 4616, Loss: 0.0005496966639384482, Final Batch Loss: 1.077824322237575e-06\n",
      "Epoch 4617, Loss: 9.024836163007421e-05, Final Batch Loss: 1.8898940652434248e-06\n",
      "Epoch 4618, Loss: 0.00018074111312671448, Final Batch Loss: 3.3849133615149185e-05\n",
      "Epoch 4619, Loss: 0.02292920918580421, Final Batch Loss: 3.990651293861447e-06\n",
      "Epoch 4620, Loss: 0.00043324686157575343, Final Batch Loss: 5.34918399353046e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4621, Loss: 0.00024535035350936596, Final Batch Loss: 2.7863236027769744e-05\n",
      "Epoch 4622, Loss: 0.0014589402802016593, Final Batch Loss: 9.412381700713013e-07\n",
      "Epoch 4623, Loss: 8.35731156030306e-05, Final Batch Loss: 1.1672249229377485e-06\n",
      "Epoch 4624, Loss: 0.00013669947520611458, Final Batch Loss: 4.18944182456471e-06\n",
      "Epoch 4625, Loss: 0.0006014302188077636, Final Batch Loss: 0.0005448765004985034\n",
      "Epoch 4626, Loss: 0.0004931572459554445, Final Batch Loss: 0.0004627441812772304\n",
      "Epoch 4627, Loss: 0.00029162915095071185, Final Batch Loss: 2.4338484649888414e-07\n",
      "Epoch 4628, Loss: 0.0002516977834829959, Final Batch Loss: 1.2765191286234767e-06\n",
      "Epoch 4629, Loss: 0.00023065934919941355, Final Batch Loss: 0.00012187229003757238\n",
      "Epoch 4630, Loss: 0.00011529267521837028, Final Batch Loss: 4.91732862428762e-07\n",
      "Epoch 4631, Loss: 0.0004957571261456906, Final Batch Loss: 0.00039982449379749596\n",
      "Epoch 4632, Loss: 0.00010214005169473239, Final Batch Loss: 9.685552413429832e-07\n",
      "Epoch 4633, Loss: 0.0007207607235386604, Final Batch Loss: 1.3137517953509814e-06\n",
      "Epoch 4634, Loss: 0.0014054729379027187, Final Batch Loss: 7.4505792646561986e-09\n",
      "Epoch 4635, Loss: 0.00020219005546096014, Final Batch Loss: 8.664102097100113e-06\n",
      "Epoch 4636, Loss: 0.0002303751073213789, Final Batch Loss: 3.5610730719781714e-06\n",
      "Epoch 4637, Loss: 3.3092185731220525e-05, Final Batch Loss: 1.5148580132517964e-05\n",
      "Epoch 4638, Loss: 1.7878518590919157e-05, Final Batch Loss: 1.3411029442522704e-07\n",
      "Epoch 4639, Loss: 0.00012244216182466516, Final Batch Loss: 1.3907711604588258e-07\n",
      "Epoch 4640, Loss: 4.9302028969577805e-05, Final Batch Loss: 1.3410841575023369e-06\n",
      "Epoch 4641, Loss: 0.00037913114283583127, Final Batch Loss: 9.535160643281415e-06\n",
      "Epoch 4642, Loss: 0.0006016775773787231, Final Batch Loss: 0.00027765994309447706\n",
      "Epoch 4643, Loss: 3.9196347159986544e-05, Final Batch Loss: 3.476927474821423e-07\n",
      "Epoch 4644, Loss: 1.84366501039257e-05, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4645, Loss: 0.008026429533686041, Final Batch Loss: 5.066365815764584e-07\n",
      "Epoch 4646, Loss: 0.00010597970181436267, Final Batch Loss: 1.291432027983319e-07\n",
      "Epoch 4647, Loss: 0.00020548232237160846, Final Batch Loss: 2.8796093829441816e-05\n",
      "Epoch 4648, Loss: 5.998372652982198e-05, Final Batch Loss: 1.8129667012090067e-07\n",
      "Epoch 4649, Loss: 5.977052046546305e-05, Final Batch Loss: 3.5637169730762253e-06\n",
      "Epoch 4650, Loss: 5.4556401153149636e-05, Final Batch Loss: 1.5605886801495217e-05\n",
      "Epoch 4651, Loss: 0.004520984658384464, Final Batch Loss: 6.953872855319787e-08\n",
      "Epoch 4652, Loss: 9.946832642526715e-05, Final Batch Loss: 9.85937276709592e-07\n",
      "Epoch 4653, Loss: 5.9510438859433634e-05, Final Batch Loss: 1.0579556146694813e-06\n",
      "Epoch 4654, Loss: 2.9444855272231507e-05, Final Batch Loss: 0.0\n",
      "Epoch 4655, Loss: 7.212358437413968e-05, Final Batch Loss: 3.725278077126859e-07\n",
      "Epoch 4656, Loss: 5.78744681343224e-05, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 4657, Loss: 0.00012435324515536195, Final Batch Loss: 2.202038922405336e-05\n",
      "Epoch 4658, Loss: 0.002004031483011204, Final Batch Loss: 2.8122563890065067e-05\n",
      "Epoch 4659, Loss: 9.38705752560054e-05, Final Batch Loss: 2.320569365110714e-05\n",
      "Epoch 4660, Loss: 0.0006203632882488819, Final Batch Loss: 1.5323070101658232e-06\n",
      "Epoch 4661, Loss: 0.00010976259783390674, Final Batch Loss: 5.463754249035446e-08\n",
      "Epoch 4662, Loss: 4.633715559521079e-05, Final Batch Loss: 1.1920917586394353e-07\n",
      "Epoch 4663, Loss: 0.0007206860900623724, Final Batch Loss: 2.1282901343511185e-06\n",
      "Epoch 4664, Loss: 2.2647533114650287e-05, Final Batch Loss: 4.154673206357984e-06\n",
      "Epoch 4665, Loss: 2.545795231867487e-05, Final Batch Loss: 3.1043882131598366e-07\n",
      "Epoch 4666, Loss: 7.21245846673213e-05, Final Batch Loss: 2.9802313505911115e-08\n",
      "Epoch 4667, Loss: 3.9829647221267805e-05, Final Batch Loss: 5.880174740013899e-06\n",
      "Epoch 4668, Loss: 0.0011727053789556408, Final Batch Loss: 1.1424207713162104e-07\n",
      "Epoch 4669, Loss: 6.185832944538561e-05, Final Batch Loss: 0.0\n",
      "Epoch 4670, Loss: 0.0010440206207249503, Final Batch Loss: 0.0010142653482034802\n",
      "Epoch 4671, Loss: 5.409762911767757e-05, Final Batch Loss: 1.005821332000778e-06\n",
      "Epoch 4672, Loss: 6.0396968365239445e-05, Final Batch Loss: 0.0\n",
      "Epoch 4673, Loss: 1.8227189457320492e-05, Final Batch Loss: 4.986345174984308e-06\n",
      "Epoch 4674, Loss: 3.6060696402273607e-05, Final Batch Loss: 3.106801159447059e-06\n",
      "Epoch 4675, Loss: 0.000198179920317898, Final Batch Loss: 2.831209542364377e-07\n",
      "Epoch 4676, Loss: 0.00026067799251450197, Final Batch Loss: 1.0678894568627584e-06\n",
      "Epoch 4677, Loss: 5.5760092275036754e-05, Final Batch Loss: 2.7318785456031947e-08\n",
      "Epoch 4678, Loss: 0.0016508088597220194, Final Batch Loss: 7.295326668099733e-06\n",
      "Epoch 4679, Loss: 1.1333107639899254e-05, Final Batch Loss: 5.463755670120918e-08\n",
      "Epoch 4680, Loss: 3.212430257804044e-05, Final Batch Loss: 4.718651496204984e-07\n",
      "Epoch 4681, Loss: 0.00017866613348616056, Final Batch Loss: 7.202221041779922e-08\n",
      "Epoch 4682, Loss: 0.0005422806300430238, Final Batch Loss: 1.2106188478355762e-05\n",
      "Epoch 4683, Loss: 0.000568149270293361, Final Batch Loss: 2.4312312234542333e-06\n",
      "Epoch 4684, Loss: 1.6186291702524613e-05, Final Batch Loss: 5.066346489002171e-07\n",
      "Epoch 4685, Loss: 2.1214160206284305e-05, Final Batch Loss: 2.7318783679675107e-08\n",
      "Epoch 4686, Loss: 0.00010099708902089333, Final Batch Loss: 2.9601903861475876e-06\n",
      "Epoch 4687, Loss: 0.00027343934122203706, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 4688, Loss: 0.0003048053613383672, Final Batch Loss: 0.00029166656895540655\n",
      "Epoch 4689, Loss: 0.00010900269400337947, Final Batch Loss: 1.4156059080505656e-07\n",
      "Epoch 4690, Loss: 0.00020456061609053222, Final Batch Loss: 3.725288166833707e-08\n",
      "Epoch 4691, Loss: 6.893307711131058e-05, Final Batch Loss: 2.7318785456031947e-08\n",
      "Epoch 4692, Loss: 5.27493402842083e-05, Final Batch Loss: 2.4842194761731662e-05\n",
      "Epoch 4693, Loss: 2.381947956564545e-05, Final Batch Loss: 4.402829290484078e-06\n",
      "Epoch 4694, Loss: 0.00020125634318901575, Final Batch Loss: 1.3324982319318224e-05\n",
      "Epoch 4695, Loss: 0.0029426136866277375, Final Batch Loss: 1.2591303857334424e-06\n",
      "Epoch 4696, Loss: 1.819229782995535e-05, Final Batch Loss: 3.2680757158232154e-06\n",
      "Epoch 4697, Loss: 0.0003945691369153792, Final Batch Loss: 2.0990526536479592e-05\n",
      "Epoch 4698, Loss: 3.5889037349079445e-05, Final Batch Loss: 1.4279966080721351e-06\n",
      "Epoch 4699, Loss: 3.680226654978469e-05, Final Batch Loss: 7.695791282458231e-06\n",
      "Epoch 4700, Loss: 0.033036285194839365, Final Batch Loss: 9.983543804992223e-07\n",
      "Epoch 4701, Loss: 4.516370324836316e-05, Final Batch Loss: 3.7944892028463073e-06\n",
      "Epoch 4702, Loss: 0.0002424015401629731, Final Batch Loss: 3.8890750147402287e-05\n",
      "Epoch 4703, Loss: 0.0003581015555198519, Final Batch Loss: 3.079551049722795e-07\n",
      "Epoch 4704, Loss: 0.00010783943933923013, Final Batch Loss: 2.235172935627361e-08\n",
      "Epoch 4705, Loss: 0.00017119781114161015, Final Batch Loss: 1.3460285117616877e-06\n",
      "Epoch 4706, Loss: 0.0011765503477363382, Final Batch Loss: 6.498396032839082e-06\n",
      "Epoch 4707, Loss: 0.0006810556152458958, Final Batch Loss: 1.321197601100721e-06\n",
      "Epoch 4708, Loss: 8.204711380699337e-05, Final Batch Loss: 2.5083559762606455e-07\n",
      "Epoch 4709, Loss: 0.0005859527793745656, Final Batch Loss: 2.0116115138080204e-06\n",
      "Epoch 4710, Loss: 0.00022890263448971382, Final Batch Loss: 0.0001507558481534943\n",
      "Epoch 4711, Loss: 6.043728626536904e-05, Final Batch Loss: 2.991921064676717e-05\n",
      "Epoch 4712, Loss: 7.829165588191245e-05, Final Batch Loss: 5.212392352405004e-06\n",
      "Epoch 4713, Loss: 0.00027660063597068074, Final Batch Loss: 5.7192442000086885e-06\n",
      "Epoch 4714, Loss: 5.818334463825181e-05, Final Batch Loss: 5.9604619906394873e-08\n",
      "Epoch 4715, Loss: 0.0001523692581031355, Final Batch Loss: 1.862848876044154e-05\n",
      "Epoch 4716, Loss: 0.00018464060713085928, Final Batch Loss: 7.247439498314634e-05\n",
      "Epoch 4717, Loss: 0.00015279716797067522, Final Batch Loss: 4.035364781884709e-06\n",
      "Epoch 4718, Loss: 0.00012666524827764647, Final Batch Loss: 4.967052191773291e-08\n",
      "Epoch 4719, Loss: 0.0009603239394095908, Final Batch Loss: 8.617683420197864e-07\n",
      "Epoch 4720, Loss: 0.014874802452141012, Final Batch Loss: 8.459637319901958e-05\n",
      "Epoch 4721, Loss: 0.005035639057041408, Final Batch Loss: 1.013839846564224e-05\n",
      "Epoch 4722, Loss: 0.000239506371144671, Final Batch Loss: 4.306319169700146e-05\n",
      "Epoch 4723, Loss: 5.836612459653168e-05, Final Batch Loss: 2.4835264511580135e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4724, Loss: 0.00012326078763180703, Final Batch Loss: 6.036596914782422e-06\n",
      "Epoch 4725, Loss: 0.00017239009517311388, Final Batch Loss: 0.0\n",
      "Epoch 4726, Loss: 0.0002012391930747981, Final Batch Loss: 4.61650097349775e-06\n",
      "Epoch 4727, Loss: 0.000549230812737278, Final Batch Loss: 0.0005374040338210762\n",
      "Epoch 4728, Loss: 0.009249511951793465, Final Batch Loss: 2.5007641397678526e-06\n",
      "Epoch 4729, Loss: 2.0590346366589074e-05, Final Batch Loss: 2.66722304331779e-06\n",
      "Epoch 4730, Loss: 0.00018462264029039943, Final Batch Loss: 2.75901743407303e-06\n",
      "Epoch 4731, Loss: 2.5448950339068688e-05, Final Batch Loss: 7.953407475724816e-06\n",
      "Epoch 4732, Loss: 0.00038011016096106687, Final Batch Loss: 0.00013216280785854906\n",
      "Epoch 4733, Loss: 2.214886527518445e-05, Final Batch Loss: 1.7384683914656307e-08\n",
      "Epoch 4734, Loss: 3.61887609869882e-05, Final Batch Loss: 7.136507065297337e-06\n",
      "Epoch 4735, Loss: 0.013884525736386877, Final Batch Loss: 5.612722020487126e-07\n",
      "Epoch 4736, Loss: 0.0006480771799033391, Final Batch Loss: 2.093525154123199e-06\n",
      "Epoch 4737, Loss: 0.0002307080849277554, Final Batch Loss: 0.0\n",
      "Epoch 4738, Loss: 0.001536216300792148, Final Batch Loss: 2.1606638256344013e-07\n",
      "Epoch 4739, Loss: 3.7905940176941044e-05, Final Batch Loss: 2.235172935627361e-08\n",
      "Epoch 4740, Loss: 0.0002408854352271561, Final Batch Loss: 2.9802317058624794e-08\n",
      "Epoch 4741, Loss: 0.010945740261263381, Final Batch Loss: 1.052991024153016e-06\n",
      "Epoch 4742, Loss: 0.000259087546282899, Final Batch Loss: 0.00019493677245918661\n",
      "Epoch 4743, Loss: 0.0005213237927819137, Final Batch Loss: 0.00017713931447360665\n",
      "Epoch 4744, Loss: 0.0015874826790422958, Final Batch Loss: 1.2272616004338488e-05\n",
      "Epoch 4745, Loss: 0.0001578655795810846, Final Batch Loss: 1.477647288083972e-06\n",
      "Epoch 4746, Loss: 4.5844920350646134e-05, Final Batch Loss: 5.080975370219676e-06\n",
      "Epoch 4747, Loss: 4.2753908473969204e-05, Final Batch Loss: 4.693815753853414e-07\n",
      "Epoch 4748, Loss: 7.79692913965846e-05, Final Batch Loss: 4.360645561973797e-06\n",
      "Epoch 4749, Loss: 0.0014688578930872609, Final Batch Loss: 0.001367100398056209\n",
      "Epoch 4750, Loss: 0.00021025681849096145, Final Batch Loss: 3.330203298901324e-06\n",
      "Epoch 4751, Loss: 0.0002781996890917071, Final Batch Loss: 0.0002514495572540909\n",
      "Epoch 4752, Loss: 0.0001477699448741987, Final Batch Loss: 1.4329804116641753e-06\n",
      "Epoch 4753, Loss: 0.0012334377902334381, Final Batch Loss: 0.001151356496848166\n",
      "Epoch 4754, Loss: 0.0002420545482095804, Final Batch Loss: 5.041513873038639e-07\n",
      "Epoch 4755, Loss: 0.0029812980340011563, Final Batch Loss: 1.7508318705949932e-06\n",
      "Epoch 4756, Loss: 2.9492783500728592e-05, Final Batch Loss: 3.228582912129241e-08\n",
      "Epoch 4757, Loss: 0.0001670116542982214, Final Batch Loss: 3.511455361149274e-06\n",
      "Epoch 4758, Loss: 9.935234220392886e-05, Final Batch Loss: 8.319657354149967e-07\n",
      "Epoch 4759, Loss: 0.00023203011210171098, Final Batch Loss: 4.834960691368906e-06\n",
      "Epoch 4760, Loss: 0.00017797961294263587, Final Batch Loss: 9.362701689497044e-07\n",
      "Epoch 4761, Loss: 1.543995881547744e-05, Final Batch Loss: 1.2193969496365753e-06\n",
      "Epoch 4762, Loss: 0.012839786445226764, Final Batch Loss: 7.442651985911652e-05\n",
      "Epoch 4763, Loss: 2.4050224283200805e-05, Final Batch Loss: 1.0543401003815234e-05\n",
      "Epoch 4764, Loss: 0.00048017024064961333, Final Batch Loss: 2.731862025484588e-07\n",
      "Epoch 4765, Loss: 0.0001257436972537107, Final Batch Loss: 5.9324515859771054e-06\n",
      "Epoch 4766, Loss: 0.0008883755570714413, Final Batch Loss: 1.1672433402054594e-06\n",
      "Epoch 4767, Loss: 0.00020271274661354255, Final Batch Loss: 6.953775937290629e-07\n",
      "Epoch 4768, Loss: 2.718492260100902e-05, Final Batch Loss: 1.4205320439941715e-06\n",
      "Epoch 4769, Loss: 0.00017204805212145402, Final Batch Loss: 3.303069604498887e-07\n",
      "Epoch 4770, Loss: 0.000294627920993662, Final Batch Loss: 1.0688886504794937e-05\n",
      "Epoch 4771, Loss: 8.285972441512968e-06, Final Batch Loss: 1.3907730078699387e-07\n",
      "Epoch 4772, Loss: 0.00016318739849907615, Final Batch Loss: 3.3527444998071587e-07\n",
      "Epoch 4773, Loss: 3.0136629462163e-05, Final Batch Loss: 1.564620077942891e-07\n",
      "Epoch 4774, Loss: 0.0003276420247857459, Final Batch Loss: 1.1840198567369953e-05\n",
      "Epoch 4775, Loss: 0.005512310562608036, Final Batch Loss: 9.513765689916909e-05\n",
      "Epoch 4776, Loss: 0.028506335536064853, Final Batch Loss: 6.730253403475217e-07\n",
      "Epoch 4777, Loss: 0.00014756028849660652, Final Batch Loss: 2.6672350941225886e-06\n",
      "Epoch 4778, Loss: 0.00013518442233362293, Final Batch Loss: 8.172591333277524e-05\n",
      "Epoch 4779, Loss: 0.0005003395290259505, Final Batch Loss: 2.689866414584685e-05\n",
      "Epoch 4780, Loss: 0.0001383014205202926, Final Batch Loss: 3.3700078347465023e-05\n",
      "Epoch 4781, Loss: 0.00017284336536249612, Final Batch Loss: 7.812618605385069e-06\n",
      "Epoch 4782, Loss: 0.00023787120562701602, Final Batch Loss: 6.630948519159574e-07\n",
      "Epoch 4783, Loss: 0.0020727819365049527, Final Batch Loss: 4.296462350339425e-07\n",
      "Epoch 4784, Loss: 0.0009444946872463333, Final Batch Loss: 0.0009059614967554808\n",
      "Epoch 4785, Loss: 0.00046383637163671665, Final Batch Loss: 0.00036019342951476574\n",
      "Epoch 4786, Loss: 0.00015690668018919496, Final Batch Loss: 3.0247474569478072e-06\n",
      "Epoch 4787, Loss: 0.00047117962003540015, Final Batch Loss: 1.7757321984390728e-05\n",
      "Epoch 4788, Loss: 0.00022182045108820603, Final Batch Loss: 2.777978079393506e-05\n",
      "Epoch 4789, Loss: 0.0005758603128924733, Final Batch Loss: 0.00031979483901523054\n",
      "Epoch 4790, Loss: 0.00036469224592394767, Final Batch Loss: 1.614289004692182e-07\n",
      "Epoch 4791, Loss: 0.00016368331989724538, Final Batch Loss: 4.750444986711955e-06\n",
      "Epoch 4792, Loss: 0.0001391550437119804, Final Batch Loss: 0.00011253901902819052\n",
      "Epoch 4793, Loss: 0.00013675555806003103, Final Batch Loss: 0.0001312761305598542\n",
      "Epoch 4794, Loss: 0.00012459248699769887, Final Batch Loss: 8.170647447514057e-07\n",
      "Epoch 4795, Loss: 0.006847407817758722, Final Batch Loss: 3.4444053653714946e-06\n",
      "Epoch 4796, Loss: 0.0003155428335048782, Final Batch Loss: 9.934092304320075e-08\n",
      "Epoch 4797, Loss: 0.00045779422362102196, Final Batch Loss: 1.4106044545769691e-06\n",
      "Epoch 4798, Loss: 0.0009660838777563185, Final Batch Loss: 1.7210541045642458e-06\n",
      "Epoch 4799, Loss: 0.002064117608824745, Final Batch Loss: 0.00029018803616054356\n",
      "Epoch 4800, Loss: 0.0008623376952527906, Final Batch Loss: 2.5552149963914417e-05\n",
      "Epoch 4801, Loss: 0.00033148440400054824, Final Batch Loss: 1.912309244289645e-07\n",
      "Epoch 4802, Loss: 0.002971712440285046, Final Batch Loss: 1.3733647392655257e-06\n",
      "Epoch 4803, Loss: 0.0010531511798035353, Final Batch Loss: 0.0009627572726458311\n",
      "Epoch 4804, Loss: 0.00011204178116486219, Final Batch Loss: 1.1672563005049597e-07\n",
      "Epoch 4805, Loss: 5.997111065880745e-05, Final Batch Loss: 6.213314463821007e-06\n",
      "Epoch 4806, Loss: 0.00034765915364687316, Final Batch Loss: 5.140845473761146e-07\n",
      "Epoch 4807, Loss: 0.0004190416329947766, Final Batch Loss: 0.0002808350545819849\n",
      "Epoch 4808, Loss: 6.420885938496212e-05, Final Batch Loss: 2.3219731701829005e-06\n",
      "Epoch 4809, Loss: 0.0003973168809352501, Final Batch Loss: 1.700845496088732e-05\n",
      "Epoch 4810, Loss: 0.00020164692330126854, Final Batch Loss: 1.5347840189861017e-06\n",
      "Epoch 4811, Loss: 0.00016448104088340187, Final Batch Loss: 9.647983824834228e-05\n",
      "Epoch 4812, Loss: 9.02872171764102e-05, Final Batch Loss: 1.276502302971494e-06\n",
      "Epoch 4813, Loss: 1.640087236864929e-05, Final Batch Loss: 1.1324581237204256e-06\n",
      "Epoch 4814, Loss: 0.00022025219516308425, Final Batch Loss: 1.1324651723043644e-06\n",
      "Epoch 4815, Loss: 0.00021565681686297467, Final Batch Loss: 5.575007162406109e-05\n",
      "Epoch 4816, Loss: 3.0376830181921832e-05, Final Batch Loss: 1.1158968845847994e-05\n",
      "Epoch 4817, Loss: 8.774751631790423e-05, Final Batch Loss: 4.690984951594146e-06\n",
      "Epoch 4818, Loss: 0.00015076553654580493, Final Batch Loss: 4.502384854276897e-06\n",
      "Epoch 4819, Loss: 0.00010390468332843739, Final Batch Loss: 2.8063686841051094e-07\n",
      "Epoch 4820, Loss: 0.00032317315744023745, Final Batch Loss: 2.0613187245999143e-07\n",
      "Epoch 4821, Loss: 0.00010195628480369479, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4822, Loss: 9.222639607386895e-05, Final Batch Loss: 4.718696899885799e-08\n",
      "Epoch 4823, Loss: 0.0009858607227215543, Final Batch Loss: 0.0008751093992032111\n",
      "Epoch 4824, Loss: 8.363229787633486e-05, Final Batch Loss: 3.725287811562339e-08\n",
      "Epoch 4825, Loss: 0.00022746070862922352, Final Batch Loss: 9.017513366416097e-05\n",
      "Epoch 4826, Loss: 0.0001491468528911355, Final Batch Loss: 2.1569940145127475e-05\n",
      "Epoch 4827, Loss: 5.583043912338326e-05, Final Batch Loss: 7.988608558662236e-06\n",
      "Epoch 4828, Loss: 0.0003513623217941131, Final Batch Loss: 5.155168310011504e-06\n",
      "Epoch 4829, Loss: 0.0001167269333279819, Final Batch Loss: 5.9604616353681195e-08\n",
      "Epoch 4830, Loss: 0.00013049580434909558, Final Batch Loss: 6.457162982087539e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4831, Loss: 0.00018667685844775406, Final Batch Loss: 7.70498900237726e-06\n",
      "Epoch 4832, Loss: 0.00039675220637036546, Final Batch Loss: 6.397980905603617e-05\n",
      "Epoch 4833, Loss: 0.00011640582590644044, Final Batch Loss: 5.138900087331422e-05\n",
      "Epoch 4834, Loss: 0.0001925441263921357, Final Batch Loss: 1.39077044991609e-07\n",
      "Epoch 4835, Loss: 0.00037610102742746676, Final Batch Loss: 1.5683735909988172e-05\n",
      "Epoch 4836, Loss: 0.00020251158960604698, Final Batch Loss: 1.3946737453807145e-05\n",
      "Epoch 4837, Loss: 0.0005871352052508882, Final Batch Loss: 2.284739139213343e-06\n",
      "Epoch 4838, Loss: 0.0002578653488853888, Final Batch Loss: 5.795756351290038e-06\n",
      "Epoch 4839, Loss: 6.824255513038224e-05, Final Batch Loss: 8.124700798362028e-06\n",
      "Epoch 4840, Loss: 5.6834399856597884e-05, Final Batch Loss: 4.685895419243025e-06\n",
      "Epoch 4841, Loss: 1.94059030693694e-05, Final Batch Loss: 1.986820485910812e-08\n",
      "Epoch 4842, Loss: 5.9302893077983754e-05, Final Batch Loss: 2.8796554033760913e-05\n",
      "Epoch 4843, Loss: 9.656649854150601e-05, Final Batch Loss: 2.4116976419463754e-05\n",
      "Epoch 4844, Loss: 0.014027032001422413, Final Batch Loss: 0.013879970647394657\n",
      "Epoch 4845, Loss: 0.00020290051770643913, Final Batch Loss: 5.105552645545686e-06\n",
      "Epoch 4846, Loss: 0.0024681072209205013, Final Batch Loss: 0.0024162842892110348\n",
      "Epoch 4847, Loss: 0.0005502748739445451, Final Batch Loss: 1.8824706558007165e-06\n",
      "Epoch 4848, Loss: 0.0005667364977313127, Final Batch Loss: 1.2169267904482695e-07\n",
      "Epoch 4849, Loss: 0.0002491189259217208, Final Batch Loss: 3.702638196045882e-06\n",
      "Epoch 4850, Loss: 0.00010152774315486113, Final Batch Loss: 1.6887919684904773e-07\n",
      "Epoch 4851, Loss: 7.036311853880761e-05, Final Batch Loss: 8.837957466312218e-06\n",
      "Epoch 4852, Loss: 0.00011748003885259095, Final Batch Loss: 3.427255705901189e-07\n",
      "Epoch 4853, Loss: 0.00045267943079352335, Final Batch Loss: 5.389227339946956e-07\n",
      "Epoch 4854, Loss: 0.00016549717549807497, Final Batch Loss: 5.96045985901128e-08\n",
      "Epoch 4855, Loss: 0.00019290435935204187, Final Batch Loss: 2.1487072444870137e-05\n",
      "Epoch 4856, Loss: 0.0010411396057179445, Final Batch Loss: 1.0579566378510208e-06\n",
      "Epoch 4857, Loss: 4.285045179130975e-05, Final Batch Loss: 1.2331428479228634e-05\n",
      "Epoch 4858, Loss: 5.4888757460958004e-05, Final Batch Loss: 4.3879322220163886e-06\n",
      "Epoch 4859, Loss: 9.259591448884663e-05, Final Batch Loss: 9.934105982267738e-09\n",
      "Epoch 4860, Loss: 8.541615335388997e-05, Final Batch Loss: 2.4586785229985253e-07\n",
      "Epoch 4861, Loss: 0.00015839081339663608, Final Batch Loss: 5.582239737123018e-06\n",
      "Epoch 4862, Loss: 0.00014403957356856623, Final Batch Loss: 7.4505792646561986e-09\n",
      "Epoch 4863, Loss: 0.0001403714862817651, Final Batch Loss: 1.8953835024149157e-05\n",
      "Epoch 4864, Loss: 9.549203551273422e-05, Final Batch Loss: 3.7749296666333976e-07\n",
      "Epoch 4865, Loss: 0.0006374579793373414, Final Batch Loss: 0.00020563458383549005\n",
      "Epoch 4866, Loss: 0.0026899118115579768, Final Batch Loss: 0.0\n",
      "Epoch 4867, Loss: 2.3972589303866698e-05, Final Batch Loss: 2.741639264058904e-06\n",
      "Epoch 4868, Loss: 8.403569609072292e-05, Final Batch Loss: 2.590159965620842e-06\n",
      "Epoch 4869, Loss: 0.0001503451512689935, Final Batch Loss: 7.487672701245174e-05\n",
      "Epoch 4870, Loss: 3.426862166122646e-05, Final Batch Loss: 5.215404996761208e-08\n",
      "Epoch 4871, Loss: 0.00011530874576237693, Final Batch Loss: 9.685606983111938e-07\n",
      "Epoch 4872, Loss: 7.834046209609369e-05, Final Batch Loss: 3.9713508158456534e-05\n",
      "Epoch 4873, Loss: 3.8813123865111265e-05, Final Batch Loss: 2.806201337079983e-06\n",
      "Epoch 4874, Loss: 0.0002943370049024452, Final Batch Loss: 1.796929609554354e-05\n",
      "Epoch 4875, Loss: 0.0001340581757554027, Final Batch Loss: 2.4835267176115394e-09\n",
      "Epoch 4876, Loss: 0.032848791382463105, Final Batch Loss: 2.6573658828965563e-07\n",
      "Epoch 4877, Loss: 0.0002350085040063732, Final Batch Loss: 4.6690072963428975e-07\n",
      "Epoch 4878, Loss: 4.080299399333853e-05, Final Batch Loss: 3.799762851031119e-07\n",
      "Epoch 4879, Loss: 0.0011760039296291325, Final Batch Loss: 7.127609364943055e-07\n",
      "Epoch 4880, Loss: 0.00010568910788322228, Final Batch Loss: 1.41560619226766e-07\n",
      "Epoch 4881, Loss: 0.00018180585382054915, Final Batch Loss: 6.45716440317301e-08\n",
      "Epoch 4882, Loss: 0.00041125798952634796, Final Batch Loss: 0.0002978338743560016\n",
      "Epoch 4883, Loss: 0.00023559924920846242, Final Batch Loss: 2.2509409973281436e-05\n",
      "Epoch 4884, Loss: 5.178310758502391e-05, Final Batch Loss: 1.7384683914656307e-08\n",
      "Epoch 4885, Loss: 0.0002792790876355866, Final Batch Loss: 9.850063179328572e-06\n",
      "Epoch 4886, Loss: 0.00012596537362696836, Final Batch Loss: 4.711631845566444e-05\n",
      "Epoch 4887, Loss: 0.000114438692705221, Final Batch Loss: 1.44044392413889e-07\n",
      "Epoch 4888, Loss: 0.001136235893227422, Final Batch Loss: 1.3063113328826148e-06\n",
      "Epoch 4889, Loss: 0.00018427627685468906, Final Batch Loss: 0.00010000759357353672\n",
      "Epoch 4890, Loss: 6.834701468960702e-05, Final Batch Loss: 1.5795043282196275e-06\n",
      "Epoch 4891, Loss: 5.95668770984048e-05, Final Batch Loss: 1.746229645505082e-05\n",
      "Epoch 4892, Loss: 0.00045020694534514405, Final Batch Loss: 2.731877657424775e-08\n",
      "Epoch 4893, Loss: 0.0001117434621846769, Final Batch Loss: 4.5369419240159914e-05\n",
      "Epoch 4894, Loss: 0.00012357356081338366, Final Batch Loss: 1.8899390852311626e-06\n",
      "Epoch 4895, Loss: 0.00016638517828937438, Final Batch Loss: 4.0729648276283115e-07\n",
      "Epoch 4896, Loss: 0.00037236530442896765, Final Batch Loss: 8.620000880910084e-05\n",
      "Epoch 4897, Loss: 0.00019464814599245983, Final Batch Loss: 2.781533510187728e-07\n",
      "Epoch 4898, Loss: 0.0002574206027929904, Final Batch Loss: 1.3536587175622117e-05\n",
      "Epoch 4899, Loss: 2.211199756629867e-05, Final Batch Loss: 4.204217020742362e-06\n",
      "Epoch 4900, Loss: 0.0001207961685167902, Final Batch Loss: 8.906092989491299e-05\n",
      "Epoch 4901, Loss: 0.00038168357921719576, Final Batch Loss: 3.7252885221050747e-08\n",
      "Epoch 4902, Loss: 2.989588847279734e-05, Final Batch Loss: 7.4505792646561986e-09\n",
      "Epoch 4903, Loss: 0.00020971368940081447, Final Batch Loss: 2.9709437512792647e-05\n",
      "Epoch 4904, Loss: 0.00019711099508867846, Final Batch Loss: 1.1238359547860455e-05\n",
      "Epoch 4905, Loss: 0.00722091578327877, Final Batch Loss: 2.4338456228178984e-07\n",
      "Epoch 4906, Loss: 0.0005914837638556492, Final Batch Loss: 5.6989774748217314e-06\n",
      "Epoch 4907, Loss: 0.00261902174921147, Final Batch Loss: 2.4835259182509617e-08\n",
      "Epoch 4908, Loss: 0.0009808101372357214, Final Batch Loss: 9.934095146491018e-08\n",
      "Epoch 4909, Loss: 0.0037024925251785135, Final Batch Loss: 5.910762297389738e-07\n",
      "Epoch 4910, Loss: 0.0005713459959224565, Final Batch Loss: 1.939594767463859e-06\n",
      "Epoch 4911, Loss: 0.0004761777136081946, Final Batch Loss: 0.00042951773502863944\n",
      "Epoch 4912, Loss: 0.00011317042481095996, Final Batch Loss: 2.171419509977568e-05\n",
      "Epoch 4913, Loss: 0.0002709671252887347, Final Batch Loss: 0.00011313825962133706\n",
      "Epoch 4914, Loss: 6.94354703227873e-05, Final Batch Loss: 1.7454436601838097e-05\n",
      "Epoch 4915, Loss: 0.00012356043703221076, Final Batch Loss: 2.8856600238214014e-06\n",
      "Epoch 4916, Loss: 0.0003844717393803876, Final Batch Loss: 0.0001613191416254267\n",
      "Epoch 4917, Loss: 0.00022005697132954083, Final Batch Loss: 3.0993194286565995e-06\n",
      "Epoch 4918, Loss: 0.023415974566347586, Final Batch Loss: 4.619336380073946e-07\n",
      "Epoch 4919, Loss: 0.0005328696288415813, Final Batch Loss: 1.0630205906636547e-05\n",
      "Epoch 4920, Loss: 0.012524977537850646, Final Batch Loss: 7.523973636125447e-06\n",
      "Epoch 4921, Loss: 8.574583625886589e-05, Final Batch Loss: 1.1606464795477223e-05\n",
      "Epoch 4922, Loss: 0.00016389669349337055, Final Batch Loss: 2.4858893539203564e-06\n",
      "Epoch 4923, Loss: 0.028064075566476276, Final Batch Loss: 1.1076446071456303e-06\n",
      "Epoch 4924, Loss: 0.010821252259233916, Final Batch Loss: 5.140883558851783e-07\n",
      "Epoch 4925, Loss: 0.0002782627725537168, Final Batch Loss: 0.00013644022692460567\n",
      "Epoch 4926, Loss: 0.0019816836102108937, Final Batch Loss: 0.0004836864536628127\n",
      "Epoch 4927, Loss: 0.012836731984862126, Final Batch Loss: 0.0005012816400267184\n",
      "Epoch 4928, Loss: 0.01649702264694497, Final Batch Loss: 0.005821647588163614\n",
      "Epoch 4929, Loss: 0.011733679508324713, Final Batch Loss: 0.004641108680516481\n",
      "Epoch 4930, Loss: 0.0016587945330641674, Final Batch Loss: 9.437389536515184e-08\n",
      "Epoch 4931, Loss: 0.00011128621008538175, Final Batch Loss: 1.952983257069718e-05\n",
      "Epoch 4932, Loss: 0.0011801817449850205, Final Batch Loss: 0.0009758064989000559\n",
      "Epoch 4933, Loss: 0.02425038863282225, Final Batch Loss: 3.377571147211711e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4934, Loss: 0.004482618615838874, Final Batch Loss: 3.3228816391783766e-06\n",
      "Epoch 4935, Loss: 0.004752915585413575, Final Batch Loss: 6.284374103415757e-05\n",
      "Epoch 4936, Loss: 0.0008399934486931215, Final Batch Loss: 3.377573136731371e-07\n",
      "Epoch 4937, Loss: 0.0007801918718541856, Final Batch Loss: 0.0005954628577455878\n",
      "Epoch 4938, Loss: 0.00031110216938401436, Final Batch Loss: 1.7384685691013146e-08\n",
      "Epoch 4939, Loss: 0.00042111311267944984, Final Batch Loss: 2.9900736990384758e-05\n",
      "Epoch 4940, Loss: 0.011483313917779014, Final Batch Loss: 4.949388312525116e-06\n",
      "Epoch 4941, Loss: 0.0002023291090154089, Final Batch Loss: 2.8410668164724484e-06\n",
      "Epoch 4942, Loss: 0.009688531839856296, Final Batch Loss: 6.592870704480447e-06\n",
      "Epoch 4943, Loss: 0.0005179681047593476, Final Batch Loss: 0.00022075804008636624\n",
      "Epoch 4944, Loss: 0.0003469029561529169, Final Batch Loss: 3.9795679185772315e-05\n",
      "Epoch 4945, Loss: 0.00046051412073211395, Final Batch Loss: 2.0438551473489497e-06\n",
      "Epoch 4946, Loss: 0.006646848673881323, Final Batch Loss: 8.220859308494255e-05\n",
      "Epoch 4947, Loss: 0.0004591200049617328, Final Batch Loss: 2.6129002435482107e-05\n",
      "Epoch 4948, Loss: 0.00848932841030603, Final Batch Loss: 1.812969827597044e-07\n",
      "Epoch 4949, Loss: 0.001232526650710497, Final Batch Loss: 0.001001613913103938\n",
      "Epoch 4950, Loss: 0.0019079871890426148, Final Batch Loss: 8.637332211947069e-05\n",
      "Epoch 4951, Loss: 0.0003698456637835079, Final Batch Loss: 8.046516200010956e-07\n",
      "Epoch 4952, Loss: 0.006041926367288397, Final Batch Loss: 0.005461262539029121\n",
      "Epoch 4953, Loss: 0.0009375247645948548, Final Batch Loss: 0.0007868555258028209\n",
      "Epoch 4954, Loss: 0.0003376373888386297, Final Batch Loss: 3.0560015147784725e-05\n",
      "Epoch 4955, Loss: 0.0006067093277124513, Final Batch Loss: 5.542759481613757e-06\n",
      "Epoch 4956, Loss: 0.0003503130834729973, Final Batch Loss: 4.7186986762426386e-08\n",
      "Epoch 4957, Loss: 6.0110921239697745e-05, Final Batch Loss: 1.3907707341331843e-07\n",
      "Epoch 4958, Loss: 0.0025231579847968533, Final Batch Loss: 0.0002392177120782435\n",
      "Epoch 4959, Loss: 8.840886403049808e-05, Final Batch Loss: 2.5066989110200666e-05\n",
      "Epoch 4960, Loss: 0.00030293049274376926, Final Batch Loss: 9.934085909435453e-08\n",
      "Epoch 4961, Loss: 0.0010676427318685455, Final Batch Loss: 0.000698226795066148\n",
      "Epoch 4962, Loss: 0.000294587949099423, Final Batch Loss: 0.0001974168699234724\n",
      "Epoch 4963, Loss: 0.00035540320777727175, Final Batch Loss: 4.1421221794735175e-06\n",
      "Epoch 4964, Loss: 0.0002723818278695944, Final Batch Loss: 7.251773581629095e-07\n",
      "Epoch 4965, Loss: 0.0005511629083230218, Final Batch Loss: 6.630984898947645e-07\n",
      "Epoch 4966, Loss: 0.0006320185577806114, Final Batch Loss: 2.6547761535766767e-06\n",
      "Epoch 4967, Loss: 0.018421889488308807, Final Batch Loss: 1.9005312424269505e-05\n",
      "Epoch 4968, Loss: 0.000216779112633958, Final Batch Loss: 1.157024144049501e-05\n",
      "Epoch 4969, Loss: 0.0011259375626195833, Final Batch Loss: 3.444379444772494e-06\n",
      "Epoch 4970, Loss: 0.00032109245842093515, Final Batch Loss: 1.6713571540094563e-06\n",
      "Epoch 4971, Loss: 0.0012667032380022647, Final Batch Loss: 1.8750221215668716e-06\n",
      "Epoch 4972, Loss: 0.0005188132131479506, Final Batch Loss: 3.8317416510835756e-06\n",
      "Epoch 4973, Loss: 0.00018062667913909536, Final Batch Loss: 3.1893549021333456e-05\n",
      "Epoch 4974, Loss: 0.002943314297908728, Final Batch Loss: 2.858413381545688e-06\n",
      "Epoch 4975, Loss: 0.0003822533169568487, Final Batch Loss: 1.932140321514453e-06\n",
      "Epoch 4976, Loss: 0.00041045712168852333, Final Batch Loss: 0.0001493133167969063\n",
      "Epoch 4977, Loss: 0.0002946705681097228, Final Batch Loss: 0.00016047600365709513\n",
      "Epoch 4978, Loss: 0.0006645522298640572, Final Batch Loss: 5.085910379420966e-05\n",
      "Epoch 4979, Loss: 0.00013041602565522226, Final Batch Loss: 2.4835259182509617e-08\n",
      "Epoch 4980, Loss: 0.0002707702467432682, Final Batch Loss: 3.270729621362989e-06\n",
      "Epoch 4981, Loss: 0.003240043898586009, Final Batch Loss: 7.1838289841252845e-06\n",
      "Epoch 4982, Loss: 8.934128322835022e-05, Final Batch Loss: 8.021677331271349e-07\n",
      "Epoch 4983, Loss: 0.0004508010217705305, Final Batch Loss: 0.0002706410887185484\n",
      "Epoch 4984, Loss: 5.336120034371561e-05, Final Batch Loss: 2.2923546566744335e-05\n",
      "Epoch 4985, Loss: 0.00024274617999253678, Final Batch Loss: 5.637178674078314e-06\n",
      "Epoch 4986, Loss: 8.99392891824391e-05, Final Batch Loss: 2.876728649425786e-05\n",
      "Epoch 4987, Loss: 0.0007763159858309443, Final Batch Loss: 7.450580152834618e-09\n",
      "Epoch 4988, Loss: 0.0004021928762085736, Final Batch Loss: 4.6817149268463254e-05\n",
      "Epoch 4989, Loss: 0.001973337920460949, Final Batch Loss: 1.3907727236528444e-07\n",
      "Epoch 4990, Loss: 0.0006999714655648859, Final Batch Loss: 8.534366315871011e-06\n",
      "Epoch 4991, Loss: 0.0026594589357955556, Final Batch Loss: 1.7955167095351499e-06\n",
      "Epoch 4992, Loss: 0.0035906381417589728, Final Batch Loss: 8.493552741128951e-07\n",
      "Epoch 4993, Loss: 0.00023684874759055674, Final Batch Loss: 2.111796675308142e-05\n",
      "Epoch 4994, Loss: 6.391401893779403e-05, Final Batch Loss: 3.968382316088537e-06\n",
      "Epoch 4995, Loss: 0.0003673741607599368, Final Batch Loss: 0.00017236470011994243\n",
      "Epoch 4996, Loss: 0.001915759620942481, Final Batch Loss: 2.3841721485950984e-07\n",
      "Epoch 4997, Loss: 0.000985483197382564, Final Batch Loss: 0.00012108084774808958\n",
      "Epoch 4998, Loss: 0.00011272601696532547, Final Batch Loss: 3.352746773543913e-07\n",
      "Epoch 4999, Loss: 0.00013907053636330602, Final Batch Loss: 7.028291406641074e-07\n",
      "Epoch 5000, Loss: 0.00023187782948497215, Final Batch Loss: 1.1672545241481203e-07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  0  0]\n",
      " [ 1 39  0]\n",
      " [ 0  0 42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     1.000     0.992        59\n",
      "           1      1.000     0.975     0.987        40\n",
      "           2      1.000     1.000     1.000        42\n",
      "\n",
      "    accuracy                          0.993       141\n",
      "   macro avg      0.994     0.992     0.993       141\n",
      "weighted avg      0.993     0.993     0.993       141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../../saved_models/UCI 3 Label 6 Subject Classifier Ablation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
