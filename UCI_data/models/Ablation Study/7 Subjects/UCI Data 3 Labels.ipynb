{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '90 tBodyAccJerk-max()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>59 tGravityAcc-energy()-Z</th>\n",
       "      <th>475 fBodyGyro-bandsEnergy()-1,8</th>\n",
       "      <th>...</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>382 fBodyAccJerk-bandsEnergy()-1,8</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.975510</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.978500</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.981672</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.982420</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.984363</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.995193</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.839256</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.995151</td>\n",
       "      <td>-0.029411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.854278</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.907561</td>\n",
       "      <td>-0.995450</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.815380</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.910648</td>\n",
       "      <td>-0.998824</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.822905</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>-0.129277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.834215</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  58 tGravityAcc-energy()-Y  \\\n",
       "0                   0.056483             -0.375426                  -0.970905   \n",
       "1                   0.102764             -0.383430                  -0.970583   \n",
       "2                   0.102764             -0.401602                  -0.970368   \n",
       "3                   0.095753             -0.400278                  -0.969400   \n",
       "4                   0.094059             -0.400477                  -0.967051   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.918375   \n",
       "7348               -0.068919             -0.358934                  -0.902880   \n",
       "7349               -0.068919             -0.377025                  -0.907561   \n",
       "7350               -0.040009             -0.440050                  -0.910648   \n",
       "7351               -0.047491             -0.432003                  -0.910579   \n",
       "\n",
       "      59 tGravityAcc-energy()-Z  475 fBodyGyro-bandsEnergy()-1,8  ...  \\\n",
       "0                     -0.975510                        -0.999454  ...   \n",
       "1                     -0.978500                        -0.999856  ...   \n",
       "2                     -0.981672                        -0.999954  ...   \n",
       "3                     -0.982420                        -0.999931  ...   \n",
       "4                     -0.984363                        -0.999926  ...   \n",
       "...                         ...                              ...  ...   \n",
       "7347                  -0.995193                        -0.053258  ...   \n",
       "7348                  -0.995151                        -0.029411  ...   \n",
       "7349                  -0.995450                         0.161404  ...   \n",
       "7350                  -0.998824                         0.193585  ...   \n",
       "7351                  -0.998144                        -0.129277  ...   \n",
       "\n",
       "      282 fBodyAcc-energy()-X  303 fBodyAcc-bandsEnergy()-1,8  \\\n",
       "0                   -0.999968                       -0.999963   \n",
       "1                   -0.999991                       -0.999996   \n",
       "2                   -0.999969                       -0.999989   \n",
       "3                   -0.999975                       -0.999989   \n",
       "4                   -0.999990                       -0.999994   \n",
       "...                       ...                             ...   \n",
       "7347                -0.674230                       -0.684177   \n",
       "7348                -0.705580                       -0.726986   \n",
       "7349                -0.692379                       -0.655263   \n",
       "7350                -0.693098                       -0.643425   \n",
       "7351                -0.731037                       -0.709495   \n",
       "\n",
       "      311 fBodyAcc-bandsEnergy()-1,16  315 fBodyAcc-bandsEnergy()-1,24  \\\n",
       "0                           -0.999969                        -0.999971   \n",
       "1                           -0.999994                        -0.999992   \n",
       "2                           -0.999983                        -0.999972   \n",
       "3                           -0.999986                        -0.999977   \n",
       "4                           -0.999993                        -0.999991   \n",
       "...                               ...                              ...   \n",
       "7347                        -0.666429                        -0.668164   \n",
       "7348                        -0.704444                        -0.705435   \n",
       "7349                        -0.674515                        -0.684729   \n",
       "7350                        -0.677215                        -0.685088   \n",
       "7351                        -0.728519                        -0.727441   \n",
       "\n",
       "      382 fBodyAccJerk-bandsEnergy()-1,8  504 fBodyAccMag-std()  \\\n",
       "0                              -0.999986              -0.956134   \n",
       "1                              -0.999996              -0.975866   \n",
       "2                              -0.999994              -0.989015   \n",
       "3                              -0.999998              -0.986742   \n",
       "4                              -0.999995              -0.990063   \n",
       "...                                  ...                    ...   \n",
       "7347                           -0.839256              -0.232600   \n",
       "7348                           -0.854278              -0.275373   \n",
       "7349                           -0.815380              -0.220288   \n",
       "7350                           -0.822905              -0.234539   \n",
       "7351                           -0.834215              -0.342670   \n",
       "\n",
       "      505 fBodyAccMag-mad()  509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                 -0.948870                 -0.998285         5        1  \n",
       "1                 -0.975777                 -0.999472         5        1  \n",
       "2                 -0.985594                 -0.999807         5        1  \n",
       "3                 -0.983524                 -0.999770         5        1  \n",
       "4                 -0.992324                 -0.999873         5        1  \n",
       "...                     ...                       ...       ...      ...  \n",
       "7347              -0.007392                 -0.584282         2       30  \n",
       "7348              -0.172448                 -0.632536         2       30  \n",
       "7349              -0.216074                 -0.641170         2       30  \n",
       "7350              -0.220443                 -0.663579         2       30  \n",
       "7351              -0.146649                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11, 14])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8, 11, 14])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.544497013092041, Final Batch Loss: 1.1437498331069946\n",
      "Epoch 2, Loss: 4.51960015296936, Final Batch Loss: 1.125669002532959\n",
      "Epoch 3, Loss: 4.488173723220825, Final Batch Loss: 1.1098932027816772\n",
      "Epoch 4, Loss: 4.447431802749634, Final Batch Loss: 1.1050631999969482\n",
      "Epoch 5, Loss: 4.394918322563171, Final Batch Loss: 1.096889615058899\n",
      "Epoch 6, Loss: 4.314075708389282, Final Batch Loss: 1.0594778060913086\n",
      "Epoch 7, Loss: 4.2284663915634155, Final Batch Loss: 1.046815276145935\n",
      "Epoch 8, Loss: 4.135945022106171, Final Batch Loss: 0.9962549805641174\n",
      "Epoch 9, Loss: 4.001615345478058, Final Batch Loss: 0.9627048373222351\n",
      "Epoch 10, Loss: 3.9079261422157288, Final Batch Loss: 0.9746745824813843\n",
      "Epoch 11, Loss: 3.7514487504959106, Final Batch Loss: 0.9223863482475281\n",
      "Epoch 12, Loss: 3.6251659393310547, Final Batch Loss: 0.9064236283302307\n",
      "Epoch 13, Loss: 3.4765474796295166, Final Batch Loss: 0.8427290320396423\n",
      "Epoch 14, Loss: 3.360130727291107, Final Batch Loss: 0.813667356967926\n",
      "Epoch 15, Loss: 3.1948391795158386, Final Batch Loss: 0.8104095458984375\n",
      "Epoch 16, Loss: 2.994791269302368, Final Batch Loss: 0.7500610947608948\n",
      "Epoch 17, Loss: 2.7946082949638367, Final Batch Loss: 0.6566133499145508\n",
      "Epoch 18, Loss: 2.651474177837372, Final Batch Loss: 0.6078792810440063\n",
      "Epoch 19, Loss: 2.394761025905609, Final Batch Loss: 0.5684751868247986\n",
      "Epoch 20, Loss: 2.170470893383026, Final Batch Loss: 0.528571605682373\n",
      "Epoch 21, Loss: 2.0041474401950836, Final Batch Loss: 0.47189730405807495\n",
      "Epoch 22, Loss: 1.810086965560913, Final Batch Loss: 0.4431725740432739\n",
      "Epoch 23, Loss: 1.5785233676433563, Final Batch Loss: 0.43220046162605286\n",
      "Epoch 24, Loss: 1.3900737464427948, Final Batch Loss: 0.35061389207839966\n",
      "Epoch 25, Loss: 1.3615470230579376, Final Batch Loss: 0.3372412323951721\n",
      "Epoch 26, Loss: 1.2222362458705902, Final Batch Loss: 0.2914794981479645\n",
      "Epoch 27, Loss: 1.1328450739383698, Final Batch Loss: 0.2702968418598175\n",
      "Epoch 28, Loss: 1.0241200178861618, Final Batch Loss: 0.2157539278268814\n",
      "Epoch 29, Loss: 0.9860742688179016, Final Batch Loss: 0.2474106401205063\n",
      "Epoch 30, Loss: 0.9346418231725693, Final Batch Loss: 0.23724985122680664\n",
      "Epoch 31, Loss: 0.9091209024190903, Final Batch Loss: 0.22286683320999146\n",
      "Epoch 32, Loss: 0.9352750182151794, Final Batch Loss: 0.28483930230140686\n",
      "Epoch 33, Loss: 0.9025443345308304, Final Batch Loss: 0.2825797498226166\n",
      "Epoch 34, Loss: 0.8770810961723328, Final Batch Loss: 0.2691107392311096\n",
      "Epoch 35, Loss: 0.7932341545820236, Final Batch Loss: 0.20015592873096466\n",
      "Epoch 36, Loss: 0.7501628398895264, Final Batch Loss: 0.20206718146800995\n",
      "Epoch 37, Loss: 0.718386098742485, Final Batch Loss: 0.16513915359973907\n",
      "Epoch 38, Loss: 0.671764075756073, Final Batch Loss: 0.1530875265598297\n",
      "Epoch 39, Loss: 0.6825237274169922, Final Batch Loss: 0.22594963014125824\n",
      "Epoch 40, Loss: 0.6113935708999634, Final Batch Loss: 0.1282995492219925\n",
      "Epoch 41, Loss: 0.6311367824673653, Final Batch Loss: 0.16598761081695557\n",
      "Epoch 42, Loss: 0.7687551230192184, Final Batch Loss: 0.1888716071844101\n",
      "Epoch 43, Loss: 0.654222272336483, Final Batch Loss: 0.11441906541585922\n",
      "Epoch 44, Loss: 0.5934956222772598, Final Batch Loss: 0.19521698355674744\n",
      "Epoch 45, Loss: 0.5961941704154015, Final Batch Loss: 0.12112114578485489\n",
      "Epoch 46, Loss: 0.6100916564464569, Final Batch Loss: 0.17878498136997223\n",
      "Epoch 47, Loss: 0.6248589605093002, Final Batch Loss: 0.16681118309497833\n",
      "Epoch 48, Loss: 0.5345136225223541, Final Batch Loss: 0.11090530455112457\n",
      "Epoch 49, Loss: 0.4961444139480591, Final Batch Loss: 0.14323268830776215\n",
      "Epoch 50, Loss: 0.5559863373637199, Final Batch Loss: 0.12745799124240875\n",
      "Epoch 51, Loss: 0.5546940490603447, Final Batch Loss: 0.16374459862709045\n",
      "Epoch 52, Loss: 0.5075508281588554, Final Batch Loss: 0.10307363420724869\n",
      "Epoch 53, Loss: 0.5618416666984558, Final Batch Loss: 0.12347990274429321\n",
      "Epoch 54, Loss: 0.42260371893644333, Final Batch Loss: 0.08888384699821472\n",
      "Epoch 55, Loss: 0.46647943556308746, Final Batch Loss: 0.1243562251329422\n",
      "Epoch 56, Loss: 0.4834124222397804, Final Batch Loss: 0.10781465470790863\n",
      "Epoch 57, Loss: 0.5411516651511192, Final Batch Loss: 0.1297946274280548\n",
      "Epoch 58, Loss: 0.46333616226911545, Final Batch Loss: 0.10770759731531143\n",
      "Epoch 59, Loss: 0.4763671085238457, Final Batch Loss: 0.14431677758693695\n",
      "Epoch 60, Loss: 0.4217115789651871, Final Batch Loss: 0.09860339760780334\n",
      "Epoch 61, Loss: 0.4592181518673897, Final Batch Loss: 0.1079878881573677\n",
      "Epoch 62, Loss: 0.46645446866750717, Final Batch Loss: 0.08682649582624435\n",
      "Epoch 63, Loss: 0.4739174023270607, Final Batch Loss: 0.16478368639945984\n",
      "Epoch 64, Loss: 0.4080139398574829, Final Batch Loss: 0.10910005867481232\n",
      "Epoch 65, Loss: 0.430459588766098, Final Batch Loss: 0.07032884657382965\n",
      "Epoch 66, Loss: 0.38391344994306564, Final Batch Loss: 0.07224448770284653\n",
      "Epoch 67, Loss: 0.4150885045528412, Final Batch Loss: 0.09347902983427048\n",
      "Epoch 68, Loss: 0.45185646414756775, Final Batch Loss: 0.11088801920413971\n",
      "Epoch 69, Loss: 0.3846437782049179, Final Batch Loss: 0.0821164920926094\n",
      "Epoch 70, Loss: 0.4222260192036629, Final Batch Loss: 0.06830240041017532\n",
      "Epoch 71, Loss: 0.42220327258110046, Final Batch Loss: 0.10425879806280136\n",
      "Epoch 72, Loss: 0.35082871466875076, Final Batch Loss: 0.10310620814561844\n",
      "Epoch 73, Loss: 0.40974265336990356, Final Batch Loss: 0.12084097415208817\n",
      "Epoch 74, Loss: 0.3884924240410328, Final Batch Loss: 0.04566800966858864\n",
      "Epoch 75, Loss: 0.3868505358695984, Final Batch Loss: 0.06241977959871292\n",
      "Epoch 76, Loss: 0.3171665370464325, Final Batch Loss: 0.06402929127216339\n",
      "Epoch 77, Loss: 0.37720736116170883, Final Batch Loss: 0.05091390013694763\n",
      "Epoch 78, Loss: 0.37737149000167847, Final Batch Loss: 0.08094804733991623\n",
      "Epoch 79, Loss: 0.3835708312690258, Final Batch Loss: 0.07703793793916702\n",
      "Epoch 80, Loss: 0.31578080356121063, Final Batch Loss: 0.12596559524536133\n",
      "Epoch 81, Loss: 0.3641033358871937, Final Batch Loss: 0.051658112555742264\n",
      "Epoch 82, Loss: 0.332936055958271, Final Batch Loss: 0.0938904657959938\n",
      "Epoch 83, Loss: 0.29085035622119904, Final Batch Loss: 0.08497614413499832\n",
      "Epoch 84, Loss: 0.34832990914583206, Final Batch Loss: 0.1334984004497528\n",
      "Epoch 85, Loss: 0.35613152384757996, Final Batch Loss: 0.09292272478342056\n",
      "Epoch 86, Loss: 0.324100773781538, Final Batch Loss: 0.04098005220293999\n",
      "Epoch 87, Loss: 0.3500695079565048, Final Batch Loss: 0.06306546926498413\n",
      "Epoch 88, Loss: 0.3315613865852356, Final Batch Loss: 0.10694055259227753\n",
      "Epoch 89, Loss: 0.36843055486679077, Final Batch Loss: 0.10800444334745407\n",
      "Epoch 90, Loss: 0.3138454854488373, Final Batch Loss: 0.09828023612499237\n",
      "Epoch 91, Loss: 0.35233547165989876, Final Batch Loss: 0.13597974181175232\n",
      "Epoch 92, Loss: 0.3163083717226982, Final Batch Loss: 0.02712959796190262\n",
      "Epoch 93, Loss: 0.384999617934227, Final Batch Loss: 0.09855520725250244\n",
      "Epoch 94, Loss: 0.30084139108657837, Final Batch Loss: 0.04669909551739693\n",
      "Epoch 95, Loss: 0.333559587597847, Final Batch Loss: 0.10670328885316849\n",
      "Epoch 96, Loss: 0.3288286440074444, Final Batch Loss: 0.12666800618171692\n",
      "Epoch 97, Loss: 0.29951058328151703, Final Batch Loss: 0.0565144345164299\n",
      "Epoch 98, Loss: 0.2678440026938915, Final Batch Loss: 0.052871085703372955\n",
      "Epoch 99, Loss: 0.35590848699212074, Final Batch Loss: 0.13004834949970245\n",
      "Epoch 100, Loss: 0.29717960208654404, Final Batch Loss: 0.062123965471982956\n",
      "Epoch 101, Loss: 0.3312619477510452, Final Batch Loss: 0.12430194020271301\n",
      "Epoch 102, Loss: 0.2386532537639141, Final Batch Loss: 0.05422581732273102\n",
      "Epoch 103, Loss: 0.28779686614871025, Final Batch Loss: 0.037629757076501846\n",
      "Epoch 104, Loss: 0.26159316301345825, Final Batch Loss: 0.07469785958528519\n",
      "Epoch 105, Loss: 0.3008992336690426, Final Batch Loss: 0.11334347724914551\n",
      "Epoch 106, Loss: 0.28195090778172016, Final Batch Loss: 0.044249240309000015\n",
      "Epoch 107, Loss: 0.31963061168789864, Final Batch Loss: 0.1017066091299057\n",
      "Epoch 108, Loss: 0.23879006132483482, Final Batch Loss: 0.0726623609662056\n",
      "Epoch 109, Loss: 0.26334800384938717, Final Batch Loss: 0.027475060895085335\n",
      "Epoch 110, Loss: 0.3522627651691437, Final Batch Loss: 0.11356572061777115\n",
      "Epoch 111, Loss: 0.34415963664650917, Final Batch Loss: 0.12599490582942963\n",
      "Epoch 112, Loss: 0.2532651871442795, Final Batch Loss: 0.07154607027769089\n",
      "Epoch 113, Loss: 0.2953750714659691, Final Batch Loss: 0.08920234441757202\n",
      "Epoch 114, Loss: 0.22752298787236214, Final Batch Loss: 0.05953409895300865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Loss: 0.30550675466656685, Final Batch Loss: 0.04339483007788658\n",
      "Epoch 116, Loss: 0.28542768210172653, Final Batch Loss: 0.07478931546211243\n",
      "Epoch 117, Loss: 0.24551522359251976, Final Batch Loss: 0.06809774786233902\n",
      "Epoch 118, Loss: 0.30336274206638336, Final Batch Loss: 0.06528592109680176\n",
      "Epoch 119, Loss: 0.2453579194843769, Final Batch Loss: 0.05800565332174301\n",
      "Epoch 120, Loss: 0.3232276551425457, Final Batch Loss: 0.06850449740886688\n",
      "Epoch 121, Loss: 0.2487070970237255, Final Batch Loss: 0.07293286919593811\n",
      "Epoch 122, Loss: 0.2950787805020809, Final Batch Loss: 0.09510622918605804\n",
      "Epoch 123, Loss: 0.25798143073916435, Final Batch Loss: 0.0704159140586853\n",
      "Epoch 124, Loss: 0.30003365129232407, Final Batch Loss: 0.0610421784222126\n",
      "Epoch 125, Loss: 0.22882471978664398, Final Batch Loss: 0.0340760312974453\n",
      "Epoch 126, Loss: 0.27031663060188293, Final Batch Loss: 0.05203733220696449\n",
      "Epoch 127, Loss: 0.2398884892463684, Final Batch Loss: 0.03159111738204956\n",
      "Epoch 128, Loss: 0.23219545185565948, Final Batch Loss: 0.04492573067545891\n",
      "Epoch 129, Loss: 0.24206846207380295, Final Batch Loss: 0.04844155162572861\n",
      "Epoch 130, Loss: 0.27804312482476234, Final Batch Loss: 0.06963032484054565\n",
      "Epoch 131, Loss: 0.22988563030958176, Final Batch Loss: 0.05229102820158005\n",
      "Epoch 132, Loss: 0.2406260296702385, Final Batch Loss: 0.03798595815896988\n",
      "Epoch 133, Loss: 0.23116424307227135, Final Batch Loss: 0.07974203675985336\n",
      "Epoch 134, Loss: 0.19904342480003834, Final Batch Loss: 0.07504404336214066\n",
      "Epoch 135, Loss: 0.21213797479867935, Final Batch Loss: 0.08322005718946457\n",
      "Epoch 136, Loss: 0.20269374549388885, Final Batch Loss: 0.03345699980854988\n",
      "Epoch 137, Loss: 0.21365150436758995, Final Batch Loss: 0.03225835785269737\n",
      "Epoch 138, Loss: 0.2590992599725723, Final Batch Loss: 0.05749959871172905\n",
      "Epoch 139, Loss: 0.23317616805434227, Final Batch Loss: 0.04996209964156151\n",
      "Epoch 140, Loss: 0.1881965957581997, Final Batch Loss: 0.03569731488823891\n",
      "Epoch 141, Loss: 0.19408536702394485, Final Batch Loss: 0.02542312629520893\n",
      "Epoch 142, Loss: 0.2185933217406273, Final Batch Loss: 0.0768236592411995\n",
      "Epoch 143, Loss: 0.2144908756017685, Final Batch Loss: 0.0512542687356472\n",
      "Epoch 144, Loss: 0.21811405755579472, Final Batch Loss: 0.10651560872793198\n",
      "Epoch 145, Loss: 0.19023058377206326, Final Batch Loss: 0.059629250317811966\n",
      "Epoch 146, Loss: 0.16128191351890564, Final Batch Loss: 0.03181985020637512\n",
      "Epoch 147, Loss: 0.20021414197981358, Final Batch Loss: 0.029252825304865837\n",
      "Epoch 148, Loss: 0.18573160097002983, Final Batch Loss: 0.040648575872182846\n",
      "Epoch 149, Loss: 0.2516362965106964, Final Batch Loss: 0.10052023082971573\n",
      "Epoch 150, Loss: 0.19526141323149204, Final Batch Loss: 0.02712511457502842\n",
      "Epoch 151, Loss: 0.22980698943138123, Final Batch Loss: 0.044947054237127304\n",
      "Epoch 152, Loss: 0.2366870753467083, Final Batch Loss: 0.08130255341529846\n",
      "Epoch 153, Loss: 0.1875266134738922, Final Batch Loss: 0.08377566933631897\n",
      "Epoch 154, Loss: 0.2232966050505638, Final Batch Loss: 0.03099837154150009\n",
      "Epoch 155, Loss: 0.23411466367542744, Final Batch Loss: 0.013860000297427177\n",
      "Epoch 156, Loss: 0.2498686071485281, Final Batch Loss: 0.08537224680185318\n",
      "Epoch 157, Loss: 0.23961419239640236, Final Batch Loss: 0.10077954083681107\n",
      "Epoch 158, Loss: 0.1998101994395256, Final Batch Loss: 0.05290302261710167\n",
      "Epoch 159, Loss: 0.22787383757531643, Final Batch Loss: 0.022754328325390816\n",
      "Epoch 160, Loss: 0.16403816640377045, Final Batch Loss: 0.03441818058490753\n",
      "Epoch 161, Loss: 0.20158258080482483, Final Batch Loss: 0.05931331217288971\n",
      "Epoch 162, Loss: 0.19316989555954933, Final Batch Loss: 0.019059643149375916\n",
      "Epoch 163, Loss: 0.15237059071660042, Final Batch Loss: 0.022634396329522133\n",
      "Epoch 164, Loss: 0.21590036153793335, Final Batch Loss: 0.09609956294298172\n",
      "Epoch 165, Loss: 0.19505117647349834, Final Batch Loss: 0.08078780770301819\n",
      "Epoch 166, Loss: 0.13080466352403164, Final Batch Loss: 0.017767373472452164\n",
      "Epoch 167, Loss: 0.18205764330923557, Final Batch Loss: 0.060428325086832047\n",
      "Epoch 168, Loss: 0.23700808733701706, Final Batch Loss: 0.08591379970312119\n",
      "Epoch 169, Loss: 0.16590110585093498, Final Batch Loss: 0.01966296136379242\n",
      "Epoch 170, Loss: 0.21083138138055801, Final Batch Loss: 0.06133636087179184\n",
      "Epoch 171, Loss: 0.1789537351578474, Final Batch Loss: 0.03256957605481148\n",
      "Epoch 172, Loss: 0.1869766879826784, Final Batch Loss: 0.030256425961852074\n",
      "Epoch 173, Loss: 0.15369412675499916, Final Batch Loss: 0.033925194293260574\n",
      "Epoch 174, Loss: 0.1815124675631523, Final Batch Loss: 0.02520638331770897\n",
      "Epoch 175, Loss: 0.15678700059652328, Final Batch Loss: 0.031694285571575165\n",
      "Epoch 176, Loss: 0.2243376113474369, Final Batch Loss: 0.024378564208745956\n",
      "Epoch 177, Loss: 0.24442578107118607, Final Batch Loss: 0.0922325924038887\n",
      "Epoch 178, Loss: 0.24462535977363586, Final Batch Loss: 0.050835613161325455\n",
      "Epoch 179, Loss: 0.1894500032067299, Final Batch Loss: 0.018340792506933212\n",
      "Epoch 180, Loss: 0.18676700070500374, Final Batch Loss: 0.044992733746767044\n",
      "Epoch 181, Loss: 0.18391150888055563, Final Batch Loss: 0.012149843387305737\n",
      "Epoch 182, Loss: 0.18815078027546406, Final Batch Loss: 0.01338166557252407\n",
      "Epoch 183, Loss: 0.1692460961639881, Final Batch Loss: 0.028308477252721786\n",
      "Epoch 184, Loss: 0.17846033908426762, Final Batch Loss: 0.06163136661052704\n",
      "Epoch 185, Loss: 0.1574985459446907, Final Batch Loss: 0.01785653457045555\n",
      "Epoch 186, Loss: 0.16796944942325354, Final Batch Loss: 0.04662569984793663\n",
      "Epoch 187, Loss: 0.18931705504655838, Final Batch Loss: 0.04316631332039833\n",
      "Epoch 188, Loss: 0.16774548031389713, Final Batch Loss: 0.033280570060014725\n",
      "Epoch 189, Loss: 0.20966027677059174, Final Batch Loss: 0.06275327503681183\n",
      "Epoch 190, Loss: 0.1483068037778139, Final Batch Loss: 0.03905678167939186\n",
      "Epoch 191, Loss: 0.14433079957962036, Final Batch Loss: 0.05283886566758156\n",
      "Epoch 192, Loss: 0.16223029419779778, Final Batch Loss: 0.0533866211771965\n",
      "Epoch 193, Loss: 0.1812855377793312, Final Batch Loss: 0.0945863202214241\n",
      "Epoch 194, Loss: 0.13742459937930107, Final Batch Loss: 0.00896931067109108\n",
      "Epoch 195, Loss: 0.17319738771766424, Final Batch Loss: 0.03184663504362106\n",
      "Epoch 196, Loss: 0.1690262984484434, Final Batch Loss: 0.023350665345788002\n",
      "Epoch 197, Loss: 0.17826681770384312, Final Batch Loss: 0.05008454993367195\n",
      "Epoch 198, Loss: 0.19623515382409096, Final Batch Loss: 0.07465183734893799\n",
      "Epoch 199, Loss: 0.20089852437376976, Final Batch Loss: 0.06962931156158447\n",
      "Epoch 200, Loss: 0.1644788272678852, Final Batch Loss: 0.06417498737573624\n",
      "Epoch 201, Loss: 0.16191760264337063, Final Batch Loss: 0.03447042033076286\n",
      "Epoch 202, Loss: 0.15448431111872196, Final Batch Loss: 0.0470329225063324\n",
      "Epoch 203, Loss: 0.18125691264867783, Final Batch Loss: 0.05030588060617447\n",
      "Epoch 204, Loss: 0.16955989226698875, Final Batch Loss: 0.05027778819203377\n",
      "Epoch 205, Loss: 0.1597958691418171, Final Batch Loss: 0.03697120398283005\n",
      "Epoch 206, Loss: 0.17459304444491863, Final Batch Loss: 0.040135547518730164\n",
      "Epoch 207, Loss: 0.14184142649173737, Final Batch Loss: 0.04356009513139725\n",
      "Epoch 208, Loss: 0.15344622172415257, Final Batch Loss: 0.042819827795028687\n",
      "Epoch 209, Loss: 0.16597234085202217, Final Batch Loss: 0.023782698437571526\n",
      "Epoch 210, Loss: 0.13595413696020842, Final Batch Loss: 0.014039077796041965\n",
      "Epoch 211, Loss: 0.15438136458396912, Final Batch Loss: 0.02191810868680477\n",
      "Epoch 212, Loss: 0.11883610300719738, Final Batch Loss: 0.02940536104142666\n",
      "Epoch 213, Loss: 0.18275843188166618, Final Batch Loss: 0.0330352857708931\n",
      "Epoch 214, Loss: 0.1812584139406681, Final Batch Loss: 0.06279434263706207\n",
      "Epoch 215, Loss: 0.1258883886039257, Final Batch Loss: 0.026455042883753777\n",
      "Epoch 216, Loss: 0.1710782591253519, Final Batch Loss: 0.034165509045124054\n",
      "Epoch 217, Loss: 0.14871821645647287, Final Batch Loss: 0.01306206826120615\n",
      "Epoch 218, Loss: 0.17690090835094452, Final Batch Loss: 0.08064272254705429\n",
      "Epoch 219, Loss: 0.16161590442061424, Final Batch Loss: 0.0445881262421608\n",
      "Epoch 220, Loss: 0.15157867688685656, Final Batch Loss: 0.02923869900405407\n",
      "Epoch 221, Loss: 0.17444489151239395, Final Batch Loss: 0.02733491361141205\n",
      "Epoch 222, Loss: 0.13263944536447525, Final Batch Loss: 0.05269933119416237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223, Loss: 0.13618990126997232, Final Batch Loss: 0.04378967359662056\n",
      "Epoch 224, Loss: 0.12543479073792696, Final Batch Loss: 0.027987156063318253\n",
      "Epoch 225, Loss: 0.13879752065986395, Final Batch Loss: 0.05343678593635559\n",
      "Epoch 226, Loss: 0.17044368758797646, Final Batch Loss: 0.09230217337608337\n",
      "Epoch 227, Loss: 0.1617447305470705, Final Batch Loss: 0.01860053651034832\n",
      "Epoch 228, Loss: 0.14989147149026394, Final Batch Loss: 0.05027686059474945\n",
      "Epoch 229, Loss: 0.14878124184906483, Final Batch Loss: 0.06144703924655914\n",
      "Epoch 230, Loss: 0.14440820273011923, Final Batch Loss: 0.029436422511935234\n",
      "Epoch 231, Loss: 0.1380008328706026, Final Batch Loss: 0.010106809437274933\n",
      "Epoch 232, Loss: 0.13606238272041082, Final Batch Loss: 0.012877118773758411\n",
      "Epoch 233, Loss: 0.10773233976215124, Final Batch Loss: 0.011527190916240215\n",
      "Epoch 234, Loss: 0.16547244414687157, Final Batch Loss: 0.06897768378257751\n",
      "Epoch 235, Loss: 0.14475617557764053, Final Batch Loss: 0.012060058303177357\n",
      "Epoch 236, Loss: 0.12483653612434864, Final Batch Loss: 0.036137353628873825\n",
      "Epoch 237, Loss: 0.1608551274985075, Final Batch Loss: 0.01730908267199993\n",
      "Epoch 238, Loss: 0.11543066240847111, Final Batch Loss: 0.025033313781023026\n",
      "Epoch 239, Loss: 0.17665302753448486, Final Batch Loss: 0.01844136044383049\n",
      "Epoch 240, Loss: 0.18211647681891918, Final Batch Loss: 0.10080177336931229\n",
      "Epoch 241, Loss: 0.15379536524415016, Final Batch Loss: 0.07870005071163177\n",
      "Epoch 242, Loss: 0.14309730287641287, Final Batch Loss: 0.010609135963022709\n",
      "Epoch 243, Loss: 0.111629837192595, Final Batch Loss: 0.04149939492344856\n",
      "Epoch 244, Loss: 0.1367240771651268, Final Batch Loss: 0.051055908203125\n",
      "Epoch 245, Loss: 0.17140540480613708, Final Batch Loss: 0.0328124538064003\n",
      "Epoch 246, Loss: 0.17720541171729565, Final Batch Loss: 0.07997767627239227\n",
      "Epoch 247, Loss: 0.12010297365486622, Final Batch Loss: 0.017506618052721024\n",
      "Epoch 248, Loss: 0.15132130309939384, Final Batch Loss: 0.011607903987169266\n",
      "Epoch 249, Loss: 0.18963774666190147, Final Batch Loss: 0.08058460801839828\n",
      "Epoch 250, Loss: 0.11824090220034122, Final Batch Loss: 0.04466318339109421\n",
      "Epoch 251, Loss: 0.13747813925147057, Final Batch Loss: 0.03974093124270439\n",
      "Epoch 252, Loss: 0.11882615089416504, Final Batch Loss: 0.020867420360445976\n",
      "Epoch 253, Loss: 0.1857847049832344, Final Batch Loss: 0.054182980209589005\n",
      "Epoch 254, Loss: 0.14207481499761343, Final Batch Loss: 0.01176400762051344\n",
      "Epoch 255, Loss: 0.12897760793566704, Final Batch Loss: 0.049398910254240036\n",
      "Epoch 256, Loss: 0.1501608993858099, Final Batch Loss: 0.03665938600897789\n",
      "Epoch 257, Loss: 0.11055628303438425, Final Batch Loss: 0.011912932619452477\n",
      "Epoch 258, Loss: 0.17526825703680515, Final Batch Loss: 0.04050145670771599\n",
      "Epoch 259, Loss: 0.1348099485039711, Final Batch Loss: 0.023474745452404022\n",
      "Epoch 260, Loss: 0.13353039976209402, Final Batch Loss: 0.07209143042564392\n",
      "Epoch 261, Loss: 0.12373895011842251, Final Batch Loss: 0.008512429893016815\n",
      "Epoch 262, Loss: 0.15496032405644655, Final Batch Loss: 0.015297899954020977\n",
      "Epoch 263, Loss: 0.13189051114022732, Final Batch Loss: 0.030944786965847015\n",
      "Epoch 264, Loss: 0.1332596279680729, Final Batch Loss: 0.057465411722660065\n",
      "Epoch 265, Loss: 0.1274520680308342, Final Batch Loss: 0.032139454036951065\n",
      "Epoch 266, Loss: 0.12985242158174515, Final Batch Loss: 0.020904896780848503\n",
      "Epoch 267, Loss: 0.14517803210765123, Final Batch Loss: 0.03564703091979027\n",
      "Epoch 268, Loss: 0.11107136495411396, Final Batch Loss: 0.04897686839103699\n",
      "Epoch 269, Loss: 0.1569329909980297, Final Batch Loss: 0.05805239826440811\n",
      "Epoch 270, Loss: 0.12347830552607775, Final Batch Loss: 0.03797135874629021\n",
      "Epoch 271, Loss: 0.11699398420751095, Final Batch Loss: 0.0095453392714262\n",
      "Epoch 272, Loss: 0.12112843245267868, Final Batch Loss: 0.012624673545360565\n",
      "Epoch 273, Loss: 0.14201876427978277, Final Batch Loss: 0.05437372624874115\n",
      "Epoch 274, Loss: 0.11098200641572475, Final Batch Loss: 0.024205246940255165\n",
      "Epoch 275, Loss: 0.12726637907326221, Final Batch Loss: 0.052517231553792953\n",
      "Epoch 276, Loss: 0.14103364199399948, Final Batch Loss: 0.030224015936255455\n",
      "Epoch 277, Loss: 0.15888825803995132, Final Batch Loss: 0.05102214589715004\n",
      "Epoch 278, Loss: 0.16136383824050426, Final Batch Loss: 0.06067293882369995\n",
      "Epoch 279, Loss: 0.11548933014273643, Final Batch Loss: 0.0139398742467165\n",
      "Epoch 280, Loss: 0.11730638705193996, Final Batch Loss: 0.03628300875425339\n",
      "Epoch 281, Loss: 0.11250837054103613, Final Batch Loss: 0.019072068855166435\n",
      "Epoch 282, Loss: 0.09905768744647503, Final Batch Loss: 0.016529496759176254\n",
      "Epoch 283, Loss: 0.17363499477505684, Final Batch Loss: 0.03826114535331726\n",
      "Epoch 284, Loss: 0.11114647053182125, Final Batch Loss: 0.024165507405996323\n",
      "Epoch 285, Loss: 0.11122263502329588, Final Batch Loss: 0.009951543994247913\n",
      "Epoch 286, Loss: 0.09854795085266232, Final Batch Loss: 0.0064543564803898335\n",
      "Epoch 287, Loss: 0.10291876178234816, Final Batch Loss: 0.049187954515218735\n",
      "Epoch 288, Loss: 0.111151616089046, Final Batch Loss: 0.021304354071617126\n",
      "Epoch 289, Loss: 0.14481389615684748, Final Batch Loss: 0.06333909928798676\n",
      "Epoch 290, Loss: 0.0872123884037137, Final Batch Loss: 0.011686489917337894\n",
      "Epoch 291, Loss: 0.13588454388082027, Final Batch Loss: 0.008836161345243454\n",
      "Epoch 292, Loss: 0.10799328703433275, Final Batch Loss: 0.01691526547074318\n",
      "Epoch 293, Loss: 0.12254342995584011, Final Batch Loss: 0.01331302709877491\n",
      "Epoch 294, Loss: 0.125329015776515, Final Batch Loss: 0.06237821653485298\n",
      "Epoch 295, Loss: 0.1316111497581005, Final Batch Loss: 0.03294847160577774\n",
      "Epoch 296, Loss: 0.10870105493813753, Final Batch Loss: 0.05227876454591751\n",
      "Epoch 297, Loss: 0.12846248876303434, Final Batch Loss: 0.04540802538394928\n",
      "Epoch 298, Loss: 0.1275300569832325, Final Batch Loss: 0.04410191997885704\n",
      "Epoch 299, Loss: 0.10459020175039768, Final Batch Loss: 0.020767157897353172\n",
      "Epoch 300, Loss: 0.09573414921760559, Final Batch Loss: 0.015785587951540947\n",
      "Epoch 301, Loss: 0.0888967365026474, Final Batch Loss: 0.017940783873200417\n",
      "Epoch 302, Loss: 0.07486346084624529, Final Batch Loss: 0.011550008319318295\n",
      "Epoch 303, Loss: 0.0892879581078887, Final Batch Loss: 0.017867136746644974\n",
      "Epoch 304, Loss: 0.11755814496427774, Final Batch Loss: 0.01946033537387848\n",
      "Epoch 305, Loss: 0.1066195834428072, Final Batch Loss: 0.03521418944001198\n",
      "Epoch 306, Loss: 0.09269383689388633, Final Batch Loss: 0.00970279611647129\n",
      "Epoch 307, Loss: 0.10921451449394226, Final Batch Loss: 0.03622359409928322\n",
      "Epoch 308, Loss: 0.10806873440742493, Final Batch Loss: 0.03059685416519642\n",
      "Epoch 309, Loss: 0.1324541550129652, Final Batch Loss: 0.02959616109728813\n",
      "Epoch 310, Loss: 0.08804946718737483, Final Batch Loss: 0.005193804856389761\n",
      "Epoch 311, Loss: 0.09481453150510788, Final Batch Loss: 0.016879795119166374\n",
      "Epoch 312, Loss: 0.09532721899449825, Final Batch Loss: 0.03158314526081085\n",
      "Epoch 313, Loss: 0.1375589780509472, Final Batch Loss: 0.07974980771541595\n",
      "Epoch 314, Loss: 0.08444600319489837, Final Batch Loss: 0.007290143985301256\n",
      "Epoch 315, Loss: 0.09903017617762089, Final Batch Loss: 0.03478899225592613\n",
      "Epoch 316, Loss: 0.13477997668087482, Final Batch Loss: 0.04393365979194641\n",
      "Epoch 317, Loss: 0.10117316525429487, Final Batch Loss: 0.025223931297659874\n",
      "Epoch 318, Loss: 0.12748597748577595, Final Batch Loss: 0.028551312163472176\n",
      "Epoch 319, Loss: 0.10020696185529232, Final Batch Loss: 0.03741154074668884\n",
      "Epoch 320, Loss: 0.12196777015924454, Final Batch Loss: 0.04863841086626053\n",
      "Epoch 321, Loss: 0.13604486733675003, Final Batch Loss: 0.01949251815676689\n",
      "Epoch 322, Loss: 0.11100030690431595, Final Batch Loss: 0.04211621358990669\n",
      "Epoch 323, Loss: 0.14485061913728714, Final Batch Loss: 0.08891329169273376\n",
      "Epoch 324, Loss: 0.09063361026346684, Final Batch Loss: 0.005468575283885002\n",
      "Epoch 325, Loss: 0.095607774797827, Final Batch Loss: 0.006707475055009127\n",
      "Epoch 326, Loss: 0.10016403533518314, Final Batch Loss: 0.01778305321931839\n",
      "Epoch 327, Loss: 0.08639500197023153, Final Batch Loss: 0.010466736741364002\n",
      "Epoch 328, Loss: 0.10200492478907108, Final Batch Loss: 0.05490813031792641\n",
      "Epoch 329, Loss: 0.06535310205072165, Final Batch Loss: 0.01942320168018341\n",
      "Epoch 330, Loss: 0.06960171367973089, Final Batch Loss: 0.010559950955212116\n",
      "Epoch 331, Loss: 0.10897511802613735, Final Batch Loss: 0.024930806830525398\n",
      "Epoch 332, Loss: 0.07954379078000784, Final Batch Loss: 0.019995158538222313\n",
      "Epoch 333, Loss: 0.1266955342143774, Final Batch Loss: 0.05200891196727753\n",
      "Epoch 334, Loss: 0.11152308667078614, Final Batch Loss: 0.05922393128275871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335, Loss: 0.09712478006258607, Final Batch Loss: 0.04318307712674141\n",
      "Epoch 336, Loss: 0.09998304676264524, Final Batch Loss: 0.040581829845905304\n",
      "Epoch 337, Loss: 0.10008667316287756, Final Batch Loss: 0.039186857640743256\n",
      "Epoch 338, Loss: 0.08372974209487438, Final Batch Loss: 0.023752901703119278\n",
      "Epoch 339, Loss: 0.07099988870322704, Final Batch Loss: 0.010285258293151855\n",
      "Epoch 340, Loss: 0.07643634919077158, Final Batch Loss: 0.01143522746860981\n",
      "Epoch 341, Loss: 0.11239140294492245, Final Batch Loss: 0.02873143181204796\n",
      "Epoch 342, Loss: 0.11990685760974884, Final Batch Loss: 0.04899563267827034\n",
      "Epoch 343, Loss: 0.059459175914525986, Final Batch Loss: 0.02519122138619423\n",
      "Epoch 344, Loss: 0.09687604010105133, Final Batch Loss: 0.021797293797135353\n",
      "Epoch 345, Loss: 0.0919281542301178, Final Batch Loss: 0.01797475665807724\n",
      "Epoch 346, Loss: 0.07918830029666424, Final Batch Loss: 0.026142636314034462\n",
      "Epoch 347, Loss: 0.13445621822029352, Final Batch Loss: 0.037614960223436356\n",
      "Epoch 348, Loss: 0.09046187717467546, Final Batch Loss: 0.015349364839494228\n",
      "Epoch 349, Loss: 0.08773498935624957, Final Batch Loss: 0.007356822025030851\n",
      "Epoch 350, Loss: 0.07363466173410416, Final Batch Loss: 0.006506303325295448\n",
      "Epoch 351, Loss: 0.1189278643578291, Final Batch Loss: 0.07121308892965317\n",
      "Epoch 352, Loss: 0.08772806823253632, Final Batch Loss: 0.02379964292049408\n",
      "Epoch 353, Loss: 0.07280312944203615, Final Batch Loss: 0.009310713969171047\n",
      "Epoch 354, Loss: 0.11034123413264751, Final Batch Loss: 0.03881639987230301\n",
      "Epoch 355, Loss: 0.08370879478752613, Final Batch Loss: 0.006455330178141594\n",
      "Epoch 356, Loss: 0.08595948340371251, Final Batch Loss: 0.005517023149877787\n",
      "Epoch 357, Loss: 0.1180500416085124, Final Batch Loss: 0.01831638626754284\n",
      "Epoch 358, Loss: 0.11114904657006264, Final Batch Loss: 0.042719896882772446\n",
      "Epoch 359, Loss: 0.07132281456142664, Final Batch Loss: 0.022126326337456703\n",
      "Epoch 360, Loss: 0.0828891396522522, Final Batch Loss: 0.00976497121155262\n",
      "Epoch 361, Loss: 0.0673218434676528, Final Batch Loss: 0.01105151604861021\n",
      "Epoch 362, Loss: 0.07799154054373503, Final Batch Loss: 0.005037554539740086\n",
      "Epoch 363, Loss: 0.07653783494606614, Final Batch Loss: 0.004208581987768412\n",
      "Epoch 364, Loss: 0.0775948571972549, Final Batch Loss: 0.006161953788250685\n",
      "Epoch 365, Loss: 0.11306196823716164, Final Batch Loss: 0.031325072050094604\n",
      "Epoch 366, Loss: 0.08037388324737549, Final Batch Loss: 0.027752401307225227\n",
      "Epoch 367, Loss: 0.0785842458717525, Final Batch Loss: 0.019309600815176964\n",
      "Epoch 368, Loss: 0.06629714742302895, Final Batch Loss: 0.01864008419215679\n",
      "Epoch 369, Loss: 0.09161844849586487, Final Batch Loss: 0.029744407162070274\n",
      "Epoch 370, Loss: 0.05913071986287832, Final Batch Loss: 0.015422340482473373\n",
      "Epoch 371, Loss: 0.0917773935943842, Final Batch Loss: 0.020533625036478043\n",
      "Epoch 372, Loss: 0.07799285743385553, Final Batch Loss: 0.007577561307698488\n",
      "Epoch 373, Loss: 0.07338363863527775, Final Batch Loss: 0.009459206834435463\n",
      "Epoch 374, Loss: 0.07214209018275142, Final Batch Loss: 0.011226474307477474\n",
      "Epoch 375, Loss: 0.04866787837818265, Final Batch Loss: 0.013094992376863956\n",
      "Epoch 376, Loss: 0.06960581056773663, Final Batch Loss: 0.023030366748571396\n",
      "Epoch 377, Loss: 0.06054277438670397, Final Batch Loss: 0.010477310046553612\n",
      "Epoch 378, Loss: 0.05784276779741049, Final Batch Loss: 0.021332722157239914\n",
      "Epoch 379, Loss: 0.05881242547184229, Final Batch Loss: 0.01963174156844616\n",
      "Epoch 380, Loss: 0.09382845275104046, Final Batch Loss: 0.008239740505814552\n",
      "Epoch 381, Loss: 0.07092235516756773, Final Batch Loss: 0.01954270526766777\n",
      "Epoch 382, Loss: 0.09484146162867546, Final Batch Loss: 0.029511721804738045\n",
      "Epoch 383, Loss: 0.06758231669664383, Final Batch Loss: 0.0236556064337492\n",
      "Epoch 384, Loss: 0.07994321268051863, Final Batch Loss: 0.0396270826458931\n",
      "Epoch 385, Loss: 0.041226029861718416, Final Batch Loss: 0.008337912149727345\n",
      "Epoch 386, Loss: 0.08430421631783247, Final Batch Loss: 0.031277015805244446\n",
      "Epoch 387, Loss: 0.044185709208250046, Final Batch Loss: 0.009983754716813564\n",
      "Epoch 388, Loss: 0.04537791828624904, Final Batch Loss: 0.0024154416751116514\n",
      "Epoch 389, Loss: 0.0620568860322237, Final Batch Loss: 0.01357452291995287\n",
      "Epoch 390, Loss: 0.05558541766367853, Final Batch Loss: 0.008504969999194145\n",
      "Epoch 391, Loss: 0.09494197135791183, Final Batch Loss: 0.04838266968727112\n",
      "Epoch 392, Loss: 0.0670471303164959, Final Batch Loss: 0.015357468277215958\n",
      "Epoch 393, Loss: 0.06361307157203555, Final Batch Loss: 0.013761766254901886\n",
      "Epoch 394, Loss: 0.06583093293011189, Final Batch Loss: 0.0056098089553415775\n",
      "Epoch 395, Loss: 0.07470917655155063, Final Batch Loss: 0.006485891994088888\n",
      "Epoch 396, Loss: 0.045441797003149986, Final Batch Loss: 0.004189297556877136\n",
      "Epoch 397, Loss: 0.05511133372783661, Final Batch Loss: 0.009003489278256893\n",
      "Epoch 398, Loss: 0.06363876885734499, Final Batch Loss: 0.002779105445370078\n",
      "Epoch 399, Loss: 0.03598885820247233, Final Batch Loss: 0.003262411104515195\n",
      "Epoch 400, Loss: 0.07911334000527859, Final Batch Loss: 0.005847579799592495\n",
      "Epoch 401, Loss: 0.04107695957645774, Final Batch Loss: 0.007812058087438345\n",
      "Epoch 402, Loss: 0.040962652303278446, Final Batch Loss: 0.00785619392991066\n",
      "Epoch 403, Loss: 0.05311840586364269, Final Batch Loss: 0.022039182484149933\n",
      "Epoch 404, Loss: 0.057090035174041986, Final Batch Loss: 0.019558295607566833\n",
      "Epoch 405, Loss: 0.0767270065844059, Final Batch Loss: 0.025158090516924858\n",
      "Epoch 406, Loss: 0.04355085175484419, Final Batch Loss: 0.007937218993902206\n",
      "Epoch 407, Loss: 0.0571177895180881, Final Batch Loss: 0.00424130167812109\n",
      "Epoch 408, Loss: 0.03681793063879013, Final Batch Loss: 0.007780185900628567\n",
      "Epoch 409, Loss: 0.06645698985084891, Final Batch Loss: 0.003939282614737749\n",
      "Epoch 410, Loss: 0.06416000053286552, Final Batch Loss: 0.02318056859076023\n",
      "Epoch 411, Loss: 0.0356568843126297, Final Batch Loss: 0.0037045269273221493\n",
      "Epoch 412, Loss: 0.047371464781463146, Final Batch Loss: 0.011219736188650131\n",
      "Epoch 413, Loss: 0.08262513717636466, Final Batch Loss: 0.036611754447221756\n",
      "Epoch 414, Loss: 0.07206697063520551, Final Batch Loss: 0.005241192411631346\n",
      "Epoch 415, Loss: 0.08299594186246395, Final Batch Loss: 0.03596938028931618\n",
      "Epoch 416, Loss: 0.09251362271606922, Final Batch Loss: 0.02807692065834999\n",
      "Epoch 417, Loss: 0.056900289142504334, Final Batch Loss: 0.010863636620342731\n",
      "Epoch 418, Loss: 0.06510729715228081, Final Batch Loss: 0.004416218958795071\n",
      "Epoch 419, Loss: 0.06529838196001947, Final Batch Loss: 0.01739940233528614\n",
      "Epoch 420, Loss: 0.060659843031316996, Final Batch Loss: 0.011563222855329514\n",
      "Epoch 421, Loss: 0.06028951844200492, Final Batch Loss: 0.00530977314338088\n",
      "Epoch 422, Loss: 0.07356818113476038, Final Batch Loss: 0.014335211366415024\n",
      "Epoch 423, Loss: 0.051454697735607624, Final Batch Loss: 0.008116054348647594\n",
      "Epoch 424, Loss: 0.06747786048799753, Final Batch Loss: 0.004584603942930698\n",
      "Epoch 425, Loss: 0.09316911641508341, Final Batch Loss: 0.017569376155734062\n",
      "Epoch 426, Loss: 0.07140172272920609, Final Batch Loss: 0.030473116785287857\n",
      "Epoch 427, Loss: 0.06407105969265103, Final Batch Loss: 0.004618412349373102\n",
      "Epoch 428, Loss: 0.043680955190211535, Final Batch Loss: 0.005451673176139593\n",
      "Epoch 429, Loss: 0.041682684794068336, Final Batch Loss: 0.004125696606934071\n",
      "Epoch 430, Loss: 0.054093066370114684, Final Batch Loss: 0.002955010859295726\n",
      "Epoch 431, Loss: 0.03372661583125591, Final Batch Loss: 0.004748086910694838\n",
      "Epoch 432, Loss: 0.0661236378364265, Final Batch Loss: 0.002900834660977125\n",
      "Epoch 433, Loss: 0.04079907387495041, Final Batch Loss: 0.008388970978558064\n",
      "Epoch 434, Loss: 0.07599025592207909, Final Batch Loss: 0.027922501787543297\n",
      "Epoch 435, Loss: 0.06760950991883874, Final Batch Loss: 0.006131719797849655\n",
      "Epoch 436, Loss: 0.043147246818989515, Final Batch Loss: 0.004413727670907974\n",
      "Epoch 437, Loss: 0.05429622088558972, Final Batch Loss: 0.02047906629741192\n",
      "Epoch 438, Loss: 0.031030599726364017, Final Batch Loss: 0.008377786725759506\n",
      "Epoch 439, Loss: 0.05017556017264724, Final Batch Loss: 0.0087233642116189\n",
      "Epoch 440, Loss: 0.08558230753988028, Final Batch Loss: 0.024498261511325836\n",
      "Epoch 441, Loss: 0.03601488727144897, Final Batch Loss: 0.007391512859612703\n",
      "Epoch 442, Loss: 0.04462650092318654, Final Batch Loss: 0.013072957284748554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443, Loss: 0.035296618938446045, Final Batch Loss: 0.013995804823935032\n",
      "Epoch 444, Loss: 0.031200594967231154, Final Batch Loss: 0.0030734355095773935\n",
      "Epoch 445, Loss: 0.04652591282501817, Final Batch Loss: 0.006376899778842926\n",
      "Epoch 446, Loss: 0.05923529947176576, Final Batch Loss: 0.03225693479180336\n",
      "Epoch 447, Loss: 0.04298777226358652, Final Batch Loss: 0.0041181715205311775\n",
      "Epoch 448, Loss: 0.06021619029343128, Final Batch Loss: 0.029784228652715683\n",
      "Epoch 449, Loss: 0.035430185962468386, Final Batch Loss: 0.006297202780842781\n",
      "Epoch 450, Loss: 0.03997471462935209, Final Batch Loss: 0.0048753246665000916\n",
      "Epoch 451, Loss: 0.03788637276738882, Final Batch Loss: 0.0031008035875856876\n",
      "Epoch 452, Loss: 0.04236604692414403, Final Batch Loss: 0.009237434715032578\n",
      "Epoch 453, Loss: 0.05431798519566655, Final Batch Loss: 0.03161323443055153\n",
      "Epoch 454, Loss: 0.021341873332858086, Final Batch Loss: 0.003310499247163534\n",
      "Epoch 455, Loss: 0.024884918937459588, Final Batch Loss: 0.008156978525221348\n",
      "Epoch 456, Loss: 0.03840494295582175, Final Batch Loss: 0.005338694434612989\n",
      "Epoch 457, Loss: 0.025224098353646696, Final Batch Loss: 0.0012616364983841777\n",
      "Epoch 458, Loss: 0.02092213137075305, Final Batch Loss: 0.003416232066228986\n",
      "Epoch 459, Loss: 0.037645027972757816, Final Batch Loss: 0.005879195407032967\n",
      "Epoch 460, Loss: 0.04332064976915717, Final Batch Loss: 0.0022083651274442673\n",
      "Epoch 461, Loss: 0.03971712151542306, Final Batch Loss: 0.025012055411934853\n",
      "Epoch 462, Loss: 0.05884718941524625, Final Batch Loss: 0.04261718690395355\n",
      "Epoch 463, Loss: 0.03750072221737355, Final Batch Loss: 0.011728525161743164\n",
      "Epoch 464, Loss: 0.05553166172467172, Final Batch Loss: 0.03783136233687401\n",
      "Epoch 465, Loss: 0.05809806229081005, Final Batch Loss: 0.013284212909638882\n",
      "Epoch 466, Loss: 0.03419058653526008, Final Batch Loss: 0.012462343089282513\n",
      "Epoch 467, Loss: 0.06243338389322162, Final Batch Loss: 0.009136584587395191\n",
      "Epoch 468, Loss: 0.04270708467811346, Final Batch Loss: 0.004021868109703064\n",
      "Epoch 469, Loss: 0.05120920017361641, Final Batch Loss: 0.0178535096347332\n",
      "Epoch 470, Loss: 0.05775345372967422, Final Batch Loss: 0.002450749045237899\n",
      "Epoch 471, Loss: 0.04017670056782663, Final Batch Loss: 0.0033953182864934206\n",
      "Epoch 472, Loss: 0.041524972300976515, Final Batch Loss: 0.010840868577361107\n",
      "Epoch 473, Loss: 0.06359596364200115, Final Batch Loss: 0.004704387858510017\n",
      "Epoch 474, Loss: 0.0391224822960794, Final Batch Loss: 0.008254855871200562\n",
      "Epoch 475, Loss: 0.07507576863281429, Final Batch Loss: 0.03633866831660271\n",
      "Epoch 476, Loss: 0.02311607776209712, Final Batch Loss: 0.0014586062170565128\n",
      "Epoch 477, Loss: 0.05614813230931759, Final Batch Loss: 0.013534949161112309\n",
      "Epoch 478, Loss: 0.03071749210357666, Final Batch Loss: 0.006876384373754263\n",
      "Epoch 479, Loss: 0.056118122301995754, Final Batch Loss: 0.004119613207876682\n",
      "Epoch 480, Loss: 0.033875472843647, Final Batch Loss: 0.0054687997326254845\n",
      "Epoch 481, Loss: 0.03777918312698603, Final Batch Loss: 0.002995896153151989\n",
      "Epoch 482, Loss: 0.06173437740653753, Final Batch Loss: 0.028938433155417442\n",
      "Epoch 483, Loss: 0.037285164929926395, Final Batch Loss: 0.004038611426949501\n",
      "Epoch 484, Loss: 0.03579395939595997, Final Batch Loss: 0.0039002445992082357\n",
      "Epoch 485, Loss: 0.026695105712860823, Final Batch Loss: 0.0038040834479033947\n",
      "Epoch 486, Loss: 0.03221430419944227, Final Batch Loss: 0.010758253745734692\n",
      "Epoch 487, Loss: 0.03316192142665386, Final Batch Loss: 0.009762362577021122\n",
      "Epoch 488, Loss: 0.037149895215407014, Final Batch Loss: 0.0020089782774448395\n",
      "Epoch 489, Loss: 0.0442707403562963, Final Batch Loss: 0.017158150672912598\n",
      "Epoch 490, Loss: 0.07397198386024684, Final Batch Loss: 0.050666939467191696\n",
      "Epoch 491, Loss: 0.018811765825375915, Final Batch Loss: 0.003309509949758649\n",
      "Epoch 492, Loss: 0.043111463892273605, Final Batch Loss: 0.012533511035144329\n",
      "Epoch 493, Loss: 0.011352680274285376, Final Batch Loss: 0.0034431484527885914\n",
      "Epoch 494, Loss: 0.04346224036999047, Final Batch Loss: 0.021683089435100555\n",
      "Epoch 495, Loss: 0.026374753331765532, Final Batch Loss: 0.014128852635622025\n",
      "Epoch 496, Loss: 0.023131705354899168, Final Batch Loss: 0.004423848818987608\n",
      "Epoch 497, Loss: 0.041505223605781794, Final Batch Loss: 0.01139128115028143\n",
      "Epoch 498, Loss: 0.03663049777969718, Final Batch Loss: 0.006544557865709066\n",
      "Epoch 499, Loss: 0.018505538115277886, Final Batch Loss: 0.002628799295052886\n",
      "Epoch 500, Loss: 0.03190996451303363, Final Batch Loss: 0.016259759664535522\n",
      "Epoch 501, Loss: 0.03639136359561235, Final Batch Loss: 0.02571103908121586\n",
      "Epoch 502, Loss: 0.0464235576801002, Final Batch Loss: 0.025277970358729362\n",
      "Epoch 503, Loss: 0.034809252712875605, Final Batch Loss: 0.0032286907080560923\n",
      "Epoch 504, Loss: 0.03916002076584846, Final Batch Loss: 0.00809666607528925\n",
      "Epoch 505, Loss: 0.029464728431776166, Final Batch Loss: 0.002016037469729781\n",
      "Epoch 506, Loss: 0.022237453144043684, Final Batch Loss: 0.0022597857750952244\n",
      "Epoch 507, Loss: 0.05270263319835067, Final Batch Loss: 0.004195015877485275\n",
      "Epoch 508, Loss: 0.05389030836522579, Final Batch Loss: 0.002907969057559967\n",
      "Epoch 509, Loss: 0.038100495003163815, Final Batch Loss: 0.01512069720774889\n",
      "Epoch 510, Loss: 0.02620910166297108, Final Batch Loss: 0.0013756860280409455\n",
      "Epoch 511, Loss: 0.02272415638435632, Final Batch Loss: 0.0018956471467390656\n",
      "Epoch 512, Loss: 0.05339663592167199, Final Batch Loss: 0.03686489164829254\n",
      "Epoch 513, Loss: 0.01565738581120968, Final Batch Loss: 0.004138826392591\n",
      "Epoch 514, Loss: 0.026207804679870605, Final Batch Loss: 0.010097572579979897\n",
      "Epoch 515, Loss: 0.025308042764663696, Final Batch Loss: 0.002251760335639119\n",
      "Epoch 516, Loss: 0.024700419744476676, Final Batch Loss: 0.002224575262516737\n",
      "Epoch 517, Loss: 0.04763333173468709, Final Batch Loss: 0.015662172809243202\n",
      "Epoch 518, Loss: 0.03451804257929325, Final Batch Loss: 0.004470475018024445\n",
      "Epoch 519, Loss: 0.01747551967855543, Final Batch Loss: 0.0014300880720838904\n",
      "Epoch 520, Loss: 0.010027611395344138, Final Batch Loss: 0.004382193088531494\n",
      "Epoch 521, Loss: 0.026211664313450456, Final Batch Loss: 0.005474566947668791\n",
      "Epoch 522, Loss: 0.02278269687667489, Final Batch Loss: 0.0022022174671292305\n",
      "Epoch 523, Loss: 0.01621678424999118, Final Batch Loss: 0.0031066120136529207\n",
      "Epoch 524, Loss: 0.05451170646119863, Final Batch Loss: 0.002906167646870017\n",
      "Epoch 525, Loss: 0.015997997019439936, Final Batch Loss: 0.002744840458035469\n",
      "Epoch 526, Loss: 0.022253345465287566, Final Batch Loss: 0.005584427155554295\n",
      "Epoch 527, Loss: 0.06013348791748285, Final Batch Loss: 0.0021688141860067844\n",
      "Epoch 528, Loss: 0.038101137382909656, Final Batch Loss: 0.003376219654455781\n",
      "Epoch 529, Loss: 0.011630618246272206, Final Batch Loss: 0.0017392055597156286\n",
      "Epoch 530, Loss: 0.1095906242262572, Final Batch Loss: 0.07179854065179825\n",
      "Epoch 531, Loss: 0.03687282500322908, Final Batch Loss: 0.012668441981077194\n",
      "Epoch 532, Loss: 0.038935159565880895, Final Batch Loss: 0.014914624392986298\n",
      "Epoch 533, Loss: 0.03174228721763939, Final Batch Loss: 0.022077063098549843\n",
      "Epoch 534, Loss: 0.048982612788677216, Final Batch Loss: 0.02550433948636055\n",
      "Epoch 535, Loss: 0.03863794123753905, Final Batch Loss: 0.005111736711114645\n",
      "Epoch 536, Loss: 0.025289722718298435, Final Batch Loss: 0.004159384872764349\n",
      "Epoch 537, Loss: 0.033689349656924605, Final Batch Loss: 0.0019919166807085276\n",
      "Epoch 538, Loss: 0.04253717651590705, Final Batch Loss: 0.02104215696454048\n",
      "Epoch 539, Loss: 0.039967885706573725, Final Batch Loss: 0.0013546578120440245\n",
      "Epoch 540, Loss: 0.038413214264437556, Final Batch Loss: 0.02220723405480385\n",
      "Epoch 541, Loss: 0.02097436285112053, Final Batch Loss: 0.0013015911681577563\n",
      "Epoch 542, Loss: 0.028769297641701996, Final Batch Loss: 0.003706385148689151\n",
      "Epoch 543, Loss: 0.04258284252136946, Final Batch Loss: 0.02709566056728363\n",
      "Epoch 544, Loss: 0.021440655691549182, Final Batch Loss: 0.00663721701130271\n",
      "Epoch 545, Loss: 0.031306322664022446, Final Batch Loss: 0.004807803314179182\n",
      "Epoch 546, Loss: 0.02977795002516359, Final Batch Loss: 0.005773140117526054\n",
      "Epoch 547, Loss: 0.022903506876900792, Final Batch Loss: 0.0018174315337091684\n",
      "Epoch 548, Loss: 0.03273249987978488, Final Batch Loss: 0.0014269220409914851\n",
      "Epoch 549, Loss: 0.043588751927018166, Final Batch Loss: 0.013007370755076408\n",
      "Epoch 550, Loss: 0.030499891377985477, Final Batch Loss: 0.0014265482313930988\n",
      "Epoch 551, Loss: 0.038204878801479936, Final Batch Loss: 0.0022488359827548265\n",
      "Epoch 552, Loss: 0.025312907760962844, Final Batch Loss: 0.0047754948027431965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553, Loss: 0.036659552715718746, Final Batch Loss: 0.018637657165527344\n",
      "Epoch 554, Loss: 0.03344027744606137, Final Batch Loss: 0.004789082799106836\n",
      "Epoch 555, Loss: 0.015581498155370355, Final Batch Loss: 0.0036358898505568504\n",
      "Epoch 556, Loss: 0.03213783341925591, Final Batch Loss: 0.019804900512099266\n",
      "Epoch 557, Loss: 0.017236387124285102, Final Batch Loss: 0.006757974158972502\n",
      "Epoch 558, Loss: 0.028763690032064915, Final Batch Loss: 0.01964566297829151\n",
      "Epoch 559, Loss: 0.017568481212947518, Final Batch Loss: 0.006577752530574799\n",
      "Epoch 560, Loss: 0.045989079400897026, Final Batch Loss: 0.0012625791132450104\n",
      "Epoch 561, Loss: 0.028542042011395097, Final Batch Loss: 0.006985136307775974\n",
      "Epoch 562, Loss: 0.02583841187879443, Final Batch Loss: 0.001305182697251439\n",
      "Epoch 563, Loss: 0.029963107663206756, Final Batch Loss: 0.00881432555615902\n",
      "Epoch 564, Loss: 0.027406689478084445, Final Batch Loss: 0.013363274745643139\n",
      "Epoch 565, Loss: 0.0268028958234936, Final Batch Loss: 0.007083012722432613\n",
      "Epoch 566, Loss: 0.038594097597524524, Final Batch Loss: 0.006286312360316515\n",
      "Epoch 567, Loss: 0.02062218775972724, Final Batch Loss: 0.0028573693707585335\n",
      "Epoch 568, Loss: 0.06595123640727252, Final Batch Loss: 0.015147841535508633\n",
      "Epoch 569, Loss: 0.020976052852347493, Final Batch Loss: 0.0008409732254222035\n",
      "Epoch 570, Loss: 0.01621412963140756, Final Batch Loss: 0.0011979987611994147\n",
      "Epoch 571, Loss: 0.020197340287268162, Final Batch Loss: 0.002399319550022483\n",
      "Epoch 572, Loss: 0.046245819074101746, Final Batch Loss: 0.002210478065535426\n",
      "Epoch 573, Loss: 0.025481746764853597, Final Batch Loss: 0.0031519425101578236\n",
      "Epoch 574, Loss: 0.04731072555296123, Final Batch Loss: 0.00238612643443048\n",
      "Epoch 575, Loss: 0.016548973275348544, Final Batch Loss: 0.008888582699000835\n",
      "Epoch 576, Loss: 0.03211794444359839, Final Batch Loss: 0.004192243795841932\n",
      "Epoch 577, Loss: 0.03205039643216878, Final Batch Loss: 0.018170081079006195\n",
      "Epoch 578, Loss: 0.033285248558968306, Final Batch Loss: 0.006548849865794182\n",
      "Epoch 579, Loss: 0.022130173980258405, Final Batch Loss: 0.0015600750921294093\n",
      "Epoch 580, Loss: 0.011758695356547832, Final Batch Loss: 0.0017964333528652787\n",
      "Epoch 581, Loss: 0.018805237719789147, Final Batch Loss: 0.001891093561425805\n",
      "Epoch 582, Loss: 0.014171818271279335, Final Batch Loss: 0.0021331936586648226\n",
      "Epoch 583, Loss: 0.021228146040812135, Final Batch Loss: 0.0022300039418041706\n",
      "Epoch 584, Loss: 0.012325622490607202, Final Batch Loss: 0.002587168477475643\n",
      "Epoch 585, Loss: 0.06853621080517769, Final Batch Loss: 0.024754110723733902\n",
      "Epoch 586, Loss: 0.016260829637758434, Final Batch Loss: 0.0020610562060028315\n",
      "Epoch 587, Loss: 0.03174971090629697, Final Batch Loss: 0.0017470750026404858\n",
      "Epoch 588, Loss: 0.00826598471030593, Final Batch Loss: 0.0010678521357476711\n",
      "Epoch 589, Loss: 0.02251361310482025, Final Batch Loss: 0.0034099190961569548\n",
      "Epoch 590, Loss: 0.03497977298684418, Final Batch Loss: 0.02854376845061779\n",
      "Epoch 591, Loss: 0.013425368932075799, Final Batch Loss: 0.0015076383715495467\n",
      "Epoch 592, Loss: 0.026925551937893033, Final Batch Loss: 0.0018858362454921007\n",
      "Epoch 593, Loss: 0.013595398515462875, Final Batch Loss: 0.0038592847995460033\n",
      "Epoch 594, Loss: 0.028201058856211603, Final Batch Loss: 0.0030109325889497995\n",
      "Epoch 595, Loss: 0.07192405499517918, Final Batch Loss: 0.004651645664125681\n",
      "Epoch 596, Loss: 0.008317177649587393, Final Batch Loss: 0.0008623233297839761\n",
      "Epoch 597, Loss: 0.009604576509445906, Final Batch Loss: 0.0029184254817664623\n",
      "Epoch 598, Loss: 0.03965968429110944, Final Batch Loss: 0.017938824370503426\n",
      "Epoch 599, Loss: 0.027160494588315487, Final Batch Loss: 0.017597777768969536\n",
      "Epoch 600, Loss: 0.026075256057083607, Final Batch Loss: 0.0016196666983887553\n",
      "Epoch 601, Loss: 0.017230154015123844, Final Batch Loss: 0.006508407182991505\n",
      "Epoch 602, Loss: 0.021359613398090005, Final Batch Loss: 0.01232621818780899\n",
      "Epoch 603, Loss: 0.0362875412683934, Final Batch Loss: 0.006387413013726473\n",
      "Epoch 604, Loss: 0.01613105263095349, Final Batch Loss: 0.0015391159104183316\n",
      "Epoch 605, Loss: 0.01364412426482886, Final Batch Loss: 0.001966615207493305\n",
      "Epoch 606, Loss: 0.04143199045211077, Final Batch Loss: 0.011233609169721603\n",
      "Epoch 607, Loss: 0.039763585198670626, Final Batch Loss: 0.0023960028775036335\n",
      "Epoch 608, Loss: 0.022621620446443558, Final Batch Loss: 0.012447873130440712\n",
      "Epoch 609, Loss: 0.03367404011078179, Final Batch Loss: 0.009566725231707096\n",
      "Epoch 610, Loss: 0.01169656787533313, Final Batch Loss: 0.004598588217049837\n",
      "Epoch 611, Loss: 0.013722174568101764, Final Batch Loss: 0.004016883205622435\n",
      "Epoch 612, Loss: 0.011863339925184846, Final Batch Loss: 0.002048512687906623\n",
      "Epoch 613, Loss: 0.015597191522829235, Final Batch Loss: 0.00122268742416054\n",
      "Epoch 614, Loss: 0.019177832175046206, Final Batch Loss: 0.001354703912511468\n",
      "Epoch 615, Loss: 0.011564039275981486, Final Batch Loss: 0.007099593058228493\n",
      "Epoch 616, Loss: 0.03002146235667169, Final Batch Loss: 0.013651818037033081\n",
      "Epoch 617, Loss: 0.009715793654322624, Final Batch Loss: 0.004842774476855993\n",
      "Epoch 618, Loss: 0.02886200707871467, Final Batch Loss: 0.010478896088898182\n",
      "Epoch 619, Loss: 0.026374315842986107, Final Batch Loss: 0.0017871111631393433\n",
      "Epoch 620, Loss: 0.017383872997015715, Final Batch Loss: 0.0034335667733103037\n",
      "Epoch 621, Loss: 0.022475463338196278, Final Batch Loss: 0.011635905131697655\n",
      "Epoch 622, Loss: 0.022043273551389575, Final Batch Loss: 0.004220604430884123\n",
      "Epoch 623, Loss: 0.029725226806476712, Final Batch Loss: 0.0064298734068870544\n",
      "Epoch 624, Loss: 0.013022543862462044, Final Batch Loss: 0.004170858301222324\n",
      "Epoch 625, Loss: 0.013016974669881165, Final Batch Loss: 0.00441453093662858\n",
      "Epoch 626, Loss: 0.03769930894486606, Final Batch Loss: 0.00316101242788136\n",
      "Epoch 627, Loss: 0.012407604022882879, Final Batch Loss: 0.002644301624968648\n",
      "Epoch 628, Loss: 0.024555905489251018, Final Batch Loss: 0.012477447278797626\n",
      "Epoch 629, Loss: 0.019942722748965025, Final Batch Loss: 0.00352284568361938\n",
      "Epoch 630, Loss: 0.02140797395259142, Final Batch Loss: 0.005605757702142\n",
      "Epoch 631, Loss: 0.02172491094097495, Final Batch Loss: 0.005961885675787926\n",
      "Epoch 632, Loss: 0.028557130484841764, Final Batch Loss: 0.009815751574933529\n",
      "Epoch 633, Loss: 0.0195651410613209, Final Batch Loss: 0.003321945434436202\n",
      "Epoch 634, Loss: 0.010103141714353114, Final Batch Loss: 0.0005386066040955484\n",
      "Epoch 635, Loss: 0.04964588629081845, Final Batch Loss: 0.02025468461215496\n",
      "Epoch 636, Loss: 0.03150662058033049, Final Batch Loss: 0.004296759143471718\n",
      "Epoch 637, Loss: 0.021451584063470364, Final Batch Loss: 0.008333827368915081\n",
      "Epoch 638, Loss: 0.017985613783821464, Final Batch Loss: 0.004927398636937141\n",
      "Epoch 639, Loss: 0.023555532679893076, Final Batch Loss: 0.009926728904247284\n",
      "Epoch 640, Loss: 0.026947102742269635, Final Batch Loss: 0.0053627947345376015\n",
      "Epoch 641, Loss: 0.02611191524192691, Final Batch Loss: 0.006303779315203428\n",
      "Epoch 642, Loss: 0.020563850470352918, Final Batch Loss: 0.001709955045953393\n",
      "Epoch 643, Loss: 0.008140896330587566, Final Batch Loss: 0.0019828779622912407\n",
      "Epoch 644, Loss: 0.04377773078158498, Final Batch Loss: 0.034581638872623444\n",
      "Epoch 645, Loss: 0.02223173587117344, Final Batch Loss: 0.0032614138908684254\n",
      "Epoch 646, Loss: 0.0301083269296214, Final Batch Loss: 0.0015001398278400302\n",
      "Epoch 647, Loss: 0.007930151303298771, Final Batch Loss: 0.0018437383696436882\n",
      "Epoch 648, Loss: 0.02360271057114005, Final Batch Loss: 0.0009993213461712003\n",
      "Epoch 649, Loss: 0.01849505177233368, Final Batch Loss: 0.0032071855384856462\n",
      "Epoch 650, Loss: 0.02306637476431206, Final Batch Loss: 0.0006697953795082867\n",
      "Epoch 651, Loss: 0.007163669244619086, Final Batch Loss: 0.0023097076918929815\n",
      "Epoch 652, Loss: 0.027655344340018928, Final Batch Loss: 0.008806626312434673\n",
      "Epoch 653, Loss: 0.009284598636440933, Final Batch Loss: 0.00279472628608346\n",
      "Epoch 654, Loss: 0.04123984696343541, Final Batch Loss: 0.005031674634665251\n",
      "Epoch 655, Loss: 0.027641247026622295, Final Batch Loss: 0.001032333355396986\n",
      "Epoch 656, Loss: 0.03303557599429041, Final Batch Loss: 0.022471383213996887\n",
      "Epoch 657, Loss: 0.05540683132130653, Final Batch Loss: 0.0006317178485915065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658, Loss: 0.023831878672353923, Final Batch Loss: 0.00131334294565022\n",
      "Epoch 659, Loss: 0.017267997143790126, Final Batch Loss: 0.006237301975488663\n",
      "Epoch 660, Loss: 0.014333950355648994, Final Batch Loss: 0.0011168511118739843\n",
      "Epoch 661, Loss: 0.018282898468896747, Final Batch Loss: 0.0020511560142040253\n",
      "Epoch 662, Loss: 0.007404524367302656, Final Batch Loss: 0.002340632723644376\n",
      "Epoch 663, Loss: 0.019527201540768147, Final Batch Loss: 0.0024367670994251966\n",
      "Epoch 664, Loss: 0.02057218411937356, Final Batch Loss: 0.0007039979100227356\n",
      "Epoch 665, Loss: 0.018255084520205855, Final Batch Loss: 0.00122939539141953\n",
      "Epoch 666, Loss: 0.007856446434743702, Final Batch Loss: 0.0012180522317066789\n",
      "Epoch 667, Loss: 0.013254437013529241, Final Batch Loss: 0.0017925201682373881\n",
      "Epoch 668, Loss: 0.028242562199011445, Final Batch Loss: 0.0035983282141387463\n",
      "Epoch 669, Loss: 0.03293033386580646, Final Batch Loss: 0.00509961973875761\n",
      "Epoch 670, Loss: 0.028956608613952994, Final Batch Loss: 0.004285726230591536\n",
      "Epoch 671, Loss: 0.02436365920584649, Final Batch Loss: 0.002196141052991152\n",
      "Epoch 672, Loss: 0.008672759926412255, Final Batch Loss: 0.0008238439331762493\n",
      "Epoch 673, Loss: 0.014356352912727743, Final Batch Loss: 0.00528987031430006\n",
      "Epoch 674, Loss: 0.014907900709658861, Final Batch Loss: 0.0010605367133393884\n",
      "Epoch 675, Loss: 0.015925414860248566, Final Batch Loss: 0.0033921310678124428\n",
      "Epoch 676, Loss: 0.013626279367599636, Final Batch Loss: 0.0039100609719753265\n",
      "Epoch 677, Loss: 0.01430916803656146, Final Batch Loss: 0.006106303073465824\n",
      "Epoch 678, Loss: 0.010865834599826485, Final Batch Loss: 0.0007492120494134724\n",
      "Epoch 679, Loss: 0.014567592064850032, Final Batch Loss: 0.00047028728295117617\n",
      "Epoch 680, Loss: 0.007265279069542885, Final Batch Loss: 0.0012717777863144875\n",
      "Epoch 681, Loss: 0.014378643594682217, Final Batch Loss: 0.0022083695512264967\n",
      "Epoch 682, Loss: 0.008889553777407855, Final Batch Loss: 0.0009674985776655376\n",
      "Epoch 683, Loss: 0.005658120557200164, Final Batch Loss: 0.0009653651504777372\n",
      "Epoch 684, Loss: 0.030351851251907647, Final Batch Loss: 0.001562098041176796\n",
      "Epoch 685, Loss: 0.019931875402107835, Final Batch Loss: 0.0037944475188851357\n",
      "Epoch 686, Loss: 0.026239283964969218, Final Batch Loss: 0.0010527021950110793\n",
      "Epoch 687, Loss: 0.03055884107016027, Final Batch Loss: 0.005483610555529594\n",
      "Epoch 688, Loss: 0.01873874373268336, Final Batch Loss: 0.011797843500971794\n",
      "Epoch 689, Loss: 0.00853795709554106, Final Batch Loss: 0.0012632400030270219\n",
      "Epoch 690, Loss: 0.009989134006900713, Final Batch Loss: 0.0004879560729023069\n",
      "Epoch 691, Loss: 0.006680993537884206, Final Batch Loss: 0.0006248893914744258\n",
      "Epoch 692, Loss: 0.029697244288399816, Final Batch Loss: 0.002474307082593441\n",
      "Epoch 693, Loss: 0.01436443510465324, Final Batch Loss: 0.003898708149790764\n",
      "Epoch 694, Loss: 0.03224584588315338, Final Batch Loss: 0.002260020235553384\n",
      "Epoch 695, Loss: 0.007246381079312414, Final Batch Loss: 0.002891900483518839\n",
      "Epoch 696, Loss: 0.005490190698765218, Final Batch Loss: 0.0019092552829533815\n",
      "Epoch 697, Loss: 0.021165599464438856, Final Batch Loss: 0.009059141390025616\n",
      "Epoch 698, Loss: 0.019186780555173755, Final Batch Loss: 0.001200448372401297\n",
      "Epoch 699, Loss: 0.014919978159014136, Final Batch Loss: 0.003374164691194892\n",
      "Epoch 700, Loss: 0.026463849178981036, Final Batch Loss: 0.001484505133703351\n",
      "Epoch 701, Loss: 0.008941576175857335, Final Batch Loss: 0.001175642479211092\n",
      "Epoch 702, Loss: 0.014057488180696964, Final Batch Loss: 0.003043977776542306\n",
      "Epoch 703, Loss: 0.004195511428406462, Final Batch Loss: 0.00036391286994330585\n",
      "Epoch 704, Loss: 0.01114942057756707, Final Batch Loss: 0.004665665328502655\n",
      "Epoch 705, Loss: 0.003513996343826875, Final Batch Loss: 0.0003637920890469104\n",
      "Epoch 706, Loss: 0.01282601075945422, Final Batch Loss: 0.0007844549254514277\n",
      "Epoch 707, Loss: 0.03425143507774919, Final Batch Loss: 0.006837430410087109\n",
      "Epoch 708, Loss: 0.05348323722137138, Final Batch Loss: 0.005483884364366531\n",
      "Epoch 709, Loss: 0.016289960651192814, Final Batch Loss: 0.007324887439608574\n",
      "Epoch 710, Loss: 0.020368535246234387, Final Batch Loss: 0.01431529875844717\n",
      "Epoch 711, Loss: 0.010207944316789508, Final Batch Loss: 0.0012204790255054832\n",
      "Epoch 712, Loss: 0.012753653398249298, Final Batch Loss: 0.0012399990810081363\n",
      "Epoch 713, Loss: 0.009966818732209504, Final Batch Loss: 0.001648872741498053\n",
      "Epoch 714, Loss: 0.014042039343621582, Final Batch Loss: 0.0008337560575455427\n",
      "Epoch 715, Loss: 0.029554608277976513, Final Batch Loss: 0.025023339316248894\n",
      "Epoch 716, Loss: 0.0091857515508309, Final Batch Loss: 0.0019468858372420073\n",
      "Epoch 717, Loss: 0.005694453255273402, Final Batch Loss: 0.002799880923703313\n",
      "Epoch 718, Loss: 0.009851743467152119, Final Batch Loss: 0.005037867464125156\n",
      "Epoch 719, Loss: 0.014010078273713589, Final Batch Loss: 0.0005887484876438975\n",
      "Epoch 720, Loss: 0.017811768600950018, Final Batch Loss: 0.001886142767034471\n",
      "Epoch 721, Loss: 0.01441858196631074, Final Batch Loss: 0.0030737374909222126\n",
      "Epoch 722, Loss: 0.018963218200951815, Final Batch Loss: 0.004419239237904549\n",
      "Epoch 723, Loss: 0.01630749143077992, Final Batch Loss: 0.00027053491794504225\n",
      "Epoch 724, Loss: 0.00726061558816582, Final Batch Loss: 0.0003288086736574769\n",
      "Epoch 725, Loss: 0.024863046419341117, Final Batch Loss: 0.0005643035401590168\n",
      "Epoch 726, Loss: 0.029238513845484704, Final Batch Loss: 0.0012052888050675392\n",
      "Epoch 727, Loss: 0.013809557363856584, Final Batch Loss: 0.008164389058947563\n",
      "Epoch 728, Loss: 0.006738077790942043, Final Batch Loss: 0.002515343716368079\n",
      "Epoch 729, Loss: 0.008920814958401024, Final Batch Loss: 0.0039096977561712265\n",
      "Epoch 730, Loss: 0.02368217025650665, Final Batch Loss: 0.007190259639173746\n",
      "Epoch 731, Loss: 0.009787585004232824, Final Batch Loss: 0.0007727009360678494\n",
      "Epoch 732, Loss: 0.01077389091369696, Final Batch Loss: 0.0011586707551032305\n",
      "Epoch 733, Loss: 0.010411881288746372, Final Batch Loss: 0.00043821908184327185\n",
      "Epoch 734, Loss: 0.015803697053343058, Final Batch Loss: 0.0005552526563405991\n",
      "Epoch 735, Loss: 0.007654384127818048, Final Batch Loss: 0.00031068388489075005\n",
      "Epoch 736, Loss: 0.0068866274086758494, Final Batch Loss: 0.004061788786202669\n",
      "Epoch 737, Loss: 0.003922430158127099, Final Batch Loss: 0.0009046591585502028\n",
      "Epoch 738, Loss: 0.014654562924988568, Final Batch Loss: 0.008392252027988434\n",
      "Epoch 739, Loss: 0.013913607806898654, Final Batch Loss: 0.0044058337807655334\n",
      "Epoch 740, Loss: 0.013500665198080242, Final Batch Loss: 0.009286276064813137\n",
      "Epoch 741, Loss: 0.01562400400871411, Final Batch Loss: 0.008711445145308971\n",
      "Epoch 742, Loss: 0.03691946994513273, Final Batch Loss: 0.002228514291346073\n",
      "Epoch 743, Loss: 0.020178795035462826, Final Batch Loss: 0.0009970010723918676\n",
      "Epoch 744, Loss: 0.0055110775283537805, Final Batch Loss: 0.0005499275866895914\n",
      "Epoch 745, Loss: 0.004597273014951497, Final Batch Loss: 0.0005597329582087696\n",
      "Epoch 746, Loss: 0.008383209991734475, Final Batch Loss: 0.0009247272391803563\n",
      "Epoch 747, Loss: 0.003681622038129717, Final Batch Loss: 0.0007055600872263312\n",
      "Epoch 748, Loss: 0.016463476902572438, Final Batch Loss: 0.010852212086319923\n",
      "Epoch 749, Loss: 0.024397567729465663, Final Batch Loss: 0.0016756975091993809\n",
      "Epoch 750, Loss: 0.004662626801291481, Final Batch Loss: 0.002744643483310938\n",
      "Epoch 751, Loss: 0.00677340199763421, Final Batch Loss: 0.002403039252385497\n",
      "Epoch 752, Loss: 0.0041335527203045785, Final Batch Loss: 0.0009175233426503837\n",
      "Epoch 753, Loss: 0.011046537896618247, Final Batch Loss: 0.007176422979682684\n",
      "Epoch 754, Loss: 0.008065259316936135, Final Batch Loss: 0.0005876574432477355\n",
      "Epoch 755, Loss: 0.010658642189810053, Final Batch Loss: 0.0004070779832545668\n",
      "Epoch 756, Loss: 0.02419049304444343, Final Batch Loss: 0.012287013232707977\n",
      "Epoch 757, Loss: 0.04723912218469195, Final Batch Loss: 0.0002993773377966136\n",
      "Epoch 758, Loss: 0.009022016951348633, Final Batch Loss: 0.0038834454026073217\n",
      "Epoch 759, Loss: 0.008072863623965532, Final Batch Loss: 0.0006091028335504234\n",
      "Epoch 760, Loss: 0.020728692936245352, Final Batch Loss: 0.0007963976240716875\n",
      "Epoch 761, Loss: 0.007837274592020549, Final Batch Loss: 0.004286063369363546\n",
      "Epoch 762, Loss: 0.007358489034231752, Final Batch Loss: 0.00111004535574466\n",
      "Epoch 763, Loss: 0.011313478549709544, Final Batch Loss: 0.0007209558971226215\n",
      "Epoch 764, Loss: 0.010643248446285725, Final Batch Loss: 0.0015571443364024162\n",
      "Epoch 765, Loss: 0.032635171548463404, Final Batch Loss: 0.02265644259750843\n",
      "Epoch 766, Loss: 0.010695637844037265, Final Batch Loss: 0.0010802893666550517\n",
      "Epoch 767, Loss: 0.025668811082141474, Final Batch Loss: 0.00043406119220890105\n",
      "Epoch 768, Loss: 0.010580779460724443, Final Batch Loss: 0.007424984127283096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 769, Loss: 0.021184651617659256, Final Batch Loss: 0.01319415494799614\n",
      "Epoch 770, Loss: 0.015087080464581959, Final Batch Loss: 0.00019019700994249433\n",
      "Epoch 771, Loss: 0.00670949078630656, Final Batch Loss: 0.0015364590799435973\n",
      "Epoch 772, Loss: 0.027559953276067972, Final Batch Loss: 0.00894129741936922\n",
      "Epoch 773, Loss: 0.01453596045030281, Final Batch Loss: 0.0023410466965287924\n",
      "Epoch 774, Loss: 0.0262202161247842, Final Batch Loss: 0.02340766414999962\n",
      "Epoch 775, Loss: 0.002817066211719066, Final Batch Loss: 0.0005872636684216559\n",
      "Epoch 776, Loss: 0.02858038357226178, Final Batch Loss: 0.01057401578873396\n",
      "Epoch 777, Loss: 0.012233187968377024, Final Batch Loss: 0.010038027539849281\n",
      "Epoch 778, Loss: 0.024025389924645424, Final Batch Loss: 0.0022000311873853207\n",
      "Epoch 779, Loss: 0.029578320012660697, Final Batch Loss: 0.0004771089006680995\n",
      "Epoch 780, Loss: 0.01654230259009637, Final Batch Loss: 0.0003408601332921535\n",
      "Epoch 781, Loss: 0.04027131415205076, Final Batch Loss: 0.002830056706443429\n",
      "Epoch 782, Loss: 0.01204032325767912, Final Batch Loss: 0.006506537552922964\n",
      "Epoch 783, Loss: 0.018280385993421078, Final Batch Loss: 0.0031727973837405443\n",
      "Epoch 784, Loss: 0.0374423743924126, Final Batch Loss: 0.012324237264692783\n",
      "Epoch 785, Loss: 0.006909318617545068, Final Batch Loss: 0.0009526950307190418\n",
      "Epoch 786, Loss: 0.04119347594678402, Final Batch Loss: 0.025492804124951363\n",
      "Epoch 787, Loss: 0.006357201607897878, Final Batch Loss: 0.0009379140683449805\n",
      "Epoch 788, Loss: 0.01619055081391707, Final Batch Loss: 0.0004257303080521524\n",
      "Epoch 789, Loss: 0.020466202404350042, Final Batch Loss: 0.005175548605620861\n",
      "Epoch 790, Loss: 0.010001612594351172, Final Batch Loss: 0.0038254598621279\n",
      "Epoch 791, Loss: 0.011972385225817561, Final Batch Loss: 0.002763505792245269\n",
      "Epoch 792, Loss: 0.008211449283408001, Final Batch Loss: 0.0003973782586399466\n",
      "Epoch 793, Loss: 0.023804386844858527, Final Batch Loss: 0.0057206167839467525\n",
      "Epoch 794, Loss: 0.0036378001095727086, Final Batch Loss: 0.001203792984597385\n",
      "Epoch 795, Loss: 0.007950845174491405, Final Batch Loss: 0.0010768590727820992\n",
      "Epoch 796, Loss: 0.003437827792367898, Final Batch Loss: 0.0004441652854438871\n",
      "Epoch 797, Loss: 0.010851239669136703, Final Batch Loss: 0.0009640904609113932\n",
      "Epoch 798, Loss: 0.006387847097357735, Final Batch Loss: 0.0003243777609895915\n",
      "Epoch 799, Loss: 0.004717547330074012, Final Batch Loss: 0.000670859997626394\n",
      "Epoch 800, Loss: 0.004149775311816484, Final Batch Loss: 0.0017723878845572472\n",
      "Epoch 801, Loss: 0.0054864256526343524, Final Batch Loss: 0.0020534635987132788\n",
      "Epoch 802, Loss: 0.03234146838076413, Final Batch Loss: 0.0016203232808038592\n",
      "Epoch 803, Loss: 0.013362992787733674, Final Batch Loss: 0.006984591484069824\n",
      "Epoch 804, Loss: 0.023139761615311727, Final Batch Loss: 0.00040134284063242376\n",
      "Epoch 805, Loss: 0.008585654577473179, Final Batch Loss: 0.0002541418944019824\n",
      "Epoch 806, Loss: 0.03304004832170904, Final Batch Loss: 0.014940639026463032\n",
      "Epoch 807, Loss: 0.005001776269637048, Final Batch Loss: 0.001961515750735998\n",
      "Epoch 808, Loss: 0.011658008443191648, Final Batch Loss: 0.004246990196406841\n",
      "Epoch 809, Loss: 0.01482341266819276, Final Batch Loss: 0.0009338426170870662\n",
      "Epoch 810, Loss: 0.0055426619946956635, Final Batch Loss: 0.001588688581250608\n",
      "Epoch 811, Loss: 0.00331689408631064, Final Batch Loss: 0.0007694603409618139\n",
      "Epoch 812, Loss: 0.019854156591463834, Final Batch Loss: 0.017320457845926285\n",
      "Epoch 813, Loss: 0.0014209848013706505, Final Batch Loss: 0.0004741253505926579\n",
      "Epoch 814, Loss: 0.005231078015640378, Final Batch Loss: 0.0011663618497550488\n",
      "Epoch 815, Loss: 0.02304943636409007, Final Batch Loss: 0.00040791291394270957\n",
      "Epoch 816, Loss: 0.03204851970076561, Final Batch Loss: 0.0011126399040222168\n",
      "Epoch 817, Loss: 0.02334050790523179, Final Batch Loss: 0.0009741854155436158\n",
      "Epoch 818, Loss: 0.037606099096592516, Final Batch Loss: 0.022806378081440926\n",
      "Epoch 819, Loss: 0.009405542339663953, Final Batch Loss: 0.005384845193475485\n",
      "Epoch 820, Loss: 0.012492975103668869, Final Batch Loss: 0.0013380300952121615\n",
      "Epoch 821, Loss: 0.008568617224227637, Final Batch Loss: 0.0010301952715963125\n",
      "Epoch 822, Loss: 0.004087747147423215, Final Batch Loss: 0.0003421390429139137\n",
      "Epoch 823, Loss: 0.005934474116656929, Final Batch Loss: 0.0005766309914179146\n",
      "Epoch 824, Loss: 0.009571975358994678, Final Batch Loss: 0.00018157134763896465\n",
      "Epoch 825, Loss: 0.006092141731642187, Final Batch Loss: 0.0006114100106060505\n",
      "Epoch 826, Loss: 0.006390894006472081, Final Batch Loss: 0.002222443697974086\n",
      "Epoch 827, Loss: 0.003925638331566006, Final Batch Loss: 0.0011597828706726432\n",
      "Epoch 828, Loss: 0.004113703645998612, Final Batch Loss: 0.0008726940141059458\n",
      "Epoch 829, Loss: 0.01055034578894265, Final Batch Loss: 0.0013168692821636796\n",
      "Epoch 830, Loss: 0.0036719776690006256, Final Batch Loss: 0.0005044045392423868\n",
      "Epoch 831, Loss: 0.008715044183190912, Final Batch Loss: 0.001643656869418919\n",
      "Epoch 832, Loss: 0.009367709048092365, Final Batch Loss: 0.004343512002378702\n",
      "Epoch 833, Loss: 0.01236514066113159, Final Batch Loss: 0.000652889022603631\n",
      "Epoch 834, Loss: 0.003114386578090489, Final Batch Loss: 0.0004595420614350587\n",
      "Epoch 835, Loss: 0.003165917471051216, Final Batch Loss: 0.0013826030772179365\n",
      "Epoch 836, Loss: 0.005028992716688663, Final Batch Loss: 0.0017668043728917837\n",
      "Epoch 837, Loss: 0.004196451074676588, Final Batch Loss: 0.0008548471960239112\n",
      "Epoch 838, Loss: 0.019265896640717983, Final Batch Loss: 0.0005448921001516283\n",
      "Epoch 839, Loss: 0.05054526872118004, Final Batch Loss: 0.037868816405534744\n",
      "Epoch 840, Loss: 0.02495446742977947, Final Batch Loss: 0.002940461505204439\n",
      "Epoch 841, Loss: 0.00638880068436265, Final Batch Loss: 0.0005158776184543967\n",
      "Epoch 842, Loss: 0.05037116975290701, Final Batch Loss: 0.0012946006609126925\n",
      "Epoch 843, Loss: 0.01693966332823038, Final Batch Loss: 0.0032419166527688503\n",
      "Epoch 844, Loss: 0.0024955908593256027, Final Batch Loss: 0.0002720509364735335\n",
      "Epoch 845, Loss: 0.0034705517755355686, Final Batch Loss: 0.00044920152868144214\n",
      "Epoch 846, Loss: 0.014982436841819435, Final Batch Loss: 0.00606907531619072\n",
      "Epoch 847, Loss: 0.021763824217487127, Final Batch Loss: 0.0009589531109668314\n",
      "Epoch 848, Loss: 0.006603333575185388, Final Batch Loss: 0.00039108010241761804\n",
      "Epoch 849, Loss: 0.0266873009968549, Final Batch Loss: 0.011018658988177776\n",
      "Epoch 850, Loss: 0.04627063640509732, Final Batch Loss: 0.0003966928052250296\n",
      "Epoch 851, Loss: 0.015851640375331044, Final Batch Loss: 0.013791983015835285\n",
      "Epoch 852, Loss: 0.0022344645112752914, Final Batch Loss: 0.0005440117092803121\n",
      "Epoch 853, Loss: 0.005159343651030213, Final Batch Loss: 0.00029434554744511843\n",
      "Epoch 854, Loss: 0.0036815796920564026, Final Batch Loss: 0.0003619563649408519\n",
      "Epoch 855, Loss: 0.01667000589077361, Final Batch Loss: 0.0009897183626890182\n",
      "Epoch 856, Loss: 0.020341608149465173, Final Batch Loss: 0.0015342175029218197\n",
      "Epoch 857, Loss: 0.005672072293236852, Final Batch Loss: 0.001283037243410945\n",
      "Epoch 858, Loss: 0.009542373853037134, Final Batch Loss: 0.0007950516301207244\n",
      "Epoch 859, Loss: 0.02414592995774001, Final Batch Loss: 0.004829161334782839\n",
      "Epoch 860, Loss: 0.008775902446359396, Final Batch Loss: 0.0009136958396993577\n",
      "Epoch 861, Loss: 0.02207106485730037, Final Batch Loss: 0.0029728510417044163\n",
      "Epoch 862, Loss: 0.01604769640835002, Final Batch Loss: 0.0006916704005561769\n",
      "Epoch 863, Loss: 0.06302122859051451, Final Batch Loss: 0.0005209799273870885\n",
      "Epoch 864, Loss: 0.031917147323838435, Final Batch Loss: 0.009498756378889084\n",
      "Epoch 865, Loss: 0.015009628143161535, Final Batch Loss: 0.00287988455966115\n",
      "Epoch 866, Loss: 0.00906868203310296, Final Batch Loss: 0.0019143131794407964\n",
      "Epoch 867, Loss: 0.004998148651793599, Final Batch Loss: 0.0015686153201386333\n",
      "Epoch 868, Loss: 0.00857561151497066, Final Batch Loss: 0.004421429708600044\n",
      "Epoch 869, Loss: 0.01568389910971746, Final Batch Loss: 0.0019295904785394669\n",
      "Epoch 870, Loss: 0.005729203985538334, Final Batch Loss: 0.0028002550825476646\n",
      "Epoch 871, Loss: 0.008818602014798671, Final Batch Loss: 0.0026420848444104195\n",
      "Epoch 872, Loss: 0.019631619681604207, Final Batch Loss: 0.000656090909615159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873, Loss: 0.01688514743000269, Final Batch Loss: 0.0013830186799168587\n",
      "Epoch 874, Loss: 0.007094851636793464, Final Batch Loss: 0.003992846235632896\n",
      "Epoch 875, Loss: 0.008313475467730314, Final Batch Loss: 0.0007935396279208362\n",
      "Epoch 876, Loss: 0.006568511511432007, Final Batch Loss: 0.00045410069287754595\n",
      "Epoch 877, Loss: 0.003745977330254391, Final Batch Loss: 0.0014465460553765297\n",
      "Epoch 878, Loss: 0.003892029111739248, Final Batch Loss: 0.001039021648466587\n",
      "Epoch 879, Loss: 0.016590263519901782, Final Batch Loss: 0.0007837586454115808\n",
      "Epoch 880, Loss: 0.00765313470037654, Final Batch Loss: 0.0005978698027320206\n",
      "Epoch 881, Loss: 0.010184389946516603, Final Batch Loss: 0.003226915607228875\n",
      "Epoch 882, Loss: 0.00365635403431952, Final Batch Loss: 0.0007105041295289993\n",
      "Epoch 883, Loss: 0.007218060316517949, Final Batch Loss: 0.000922998005989939\n",
      "Epoch 884, Loss: 0.004372856288682669, Final Batch Loss: 0.0010865560034289956\n",
      "Epoch 885, Loss: 0.007387176156044006, Final Batch Loss: 0.0020836368203163147\n",
      "Epoch 886, Loss: 0.0033038996771210805, Final Batch Loss: 0.00040835433173924685\n",
      "Epoch 887, Loss: 0.005680686837877147, Final Batch Loss: 0.0002113034570356831\n",
      "Epoch 888, Loss: 0.009437954460736364, Final Batch Loss: 0.0019484636140987277\n",
      "Epoch 889, Loss: 0.0029141464328859, Final Batch Loss: 0.0014021421084180474\n",
      "Epoch 890, Loss: 0.0055483426549471915, Final Batch Loss: 0.0012009931961074471\n",
      "Epoch 891, Loss: 0.011459852801635861, Final Batch Loss: 0.004938123747706413\n",
      "Epoch 892, Loss: 0.013530449708923697, Final Batch Loss: 0.00041568430606275797\n",
      "Epoch 893, Loss: 0.015920594058115967, Final Batch Loss: 0.0002058662212220952\n",
      "Epoch 894, Loss: 0.004014658523374237, Final Batch Loss: 0.0009166061063297093\n",
      "Epoch 895, Loss: 0.001976648170966655, Final Batch Loss: 0.00023955543292686343\n",
      "Epoch 896, Loss: 0.003876836010022089, Final Batch Loss: 0.0013144061667844653\n",
      "Epoch 897, Loss: 0.003578199743060395, Final Batch Loss: 0.0002135955437552184\n",
      "Epoch 898, Loss: 0.012937240593601018, Final Batch Loss: 0.010417299345135689\n",
      "Epoch 899, Loss: 0.0033543380559422076, Final Batch Loss: 0.0006684981053695083\n",
      "Epoch 900, Loss: 0.013915572024416178, Final Batch Loss: 0.001303379307501018\n",
      "Epoch 901, Loss: 0.010605504736304283, Final Batch Loss: 0.0017446359852328897\n",
      "Epoch 902, Loss: 0.02026803873013705, Final Batch Loss: 0.0009338248055428267\n",
      "Epoch 903, Loss: 0.012382910994347185, Final Batch Loss: 0.00034422625321894884\n",
      "Epoch 904, Loss: 0.002624059867230244, Final Batch Loss: 0.0006578912725672126\n",
      "Epoch 905, Loss: 0.01405315488227643, Final Batch Loss: 0.00041924635297618806\n",
      "Epoch 906, Loss: 0.004761598276672885, Final Batch Loss: 0.001706197508610785\n",
      "Epoch 907, Loss: 0.005299709766404703, Final Batch Loss: 0.0007045776583254337\n",
      "Epoch 908, Loss: 0.004513641295488924, Final Batch Loss: 0.0010144429979845881\n",
      "Epoch 909, Loss: 0.013316842669155449, Final Batch Loss: 0.0007387206424027681\n",
      "Epoch 910, Loss: 0.002738446622970514, Final Batch Loss: 0.0009890712099149823\n",
      "Epoch 911, Loss: 0.0030511038203258067, Final Batch Loss: 0.0015262902015820146\n",
      "Epoch 912, Loss: 0.02646574703976512, Final Batch Loss: 0.0025822939351201057\n",
      "Epoch 913, Loss: 0.0036783031246159226, Final Batch Loss: 0.0007101091323420405\n",
      "Epoch 914, Loss: 0.011703158379532397, Final Batch Loss: 0.0013905562227591872\n",
      "Epoch 915, Loss: 0.0024818909296300262, Final Batch Loss: 0.0004029293777421117\n",
      "Epoch 916, Loss: 0.01589079189579934, Final Batch Loss: 0.0005143786547705531\n",
      "Epoch 917, Loss: 0.0041580314573366195, Final Batch Loss: 0.000789138488471508\n",
      "Epoch 918, Loss: 0.026072599459439516, Final Batch Loss: 0.00279154721647501\n",
      "Epoch 919, Loss: 0.005832355469465256, Final Batch Loss: 0.0008674904238432646\n",
      "Epoch 920, Loss: 0.003010384476510808, Final Batch Loss: 0.0010466399835422635\n",
      "Epoch 921, Loss: 0.005194814351852983, Final Batch Loss: 0.0014174113748595119\n",
      "Epoch 922, Loss: 0.011183216935023665, Final Batch Loss: 7.201149128377438e-05\n",
      "Epoch 923, Loss: 0.004480721079744399, Final Batch Loss: 0.0014794283779338002\n",
      "Epoch 924, Loss: 0.0025427072250749916, Final Batch Loss: 0.0004902455257251859\n",
      "Epoch 925, Loss: 0.004939851554809138, Final Batch Loss: 0.000461560528492555\n",
      "Epoch 926, Loss: 0.0022763195011066273, Final Batch Loss: 6.178616604302078e-05\n",
      "Epoch 927, Loss: 0.0028981781797483563, Final Batch Loss: 0.0003016387054231018\n",
      "Epoch 928, Loss: 0.001882761178421788, Final Batch Loss: 0.000306315952911973\n",
      "Epoch 929, Loss: 0.008059353189310059, Final Batch Loss: 0.0028538790065795183\n",
      "Epoch 930, Loss: 0.0015055050753289834, Final Batch Loss: 0.00016577560745645314\n",
      "Epoch 931, Loss: 0.003573799767764285, Final Batch Loss: 0.0015006858156993985\n",
      "Epoch 932, Loss: 0.003009555861353874, Final Batch Loss: 0.0008589851204305887\n",
      "Epoch 933, Loss: 0.003656346583738923, Final Batch Loss: 0.00042574567487463355\n",
      "Epoch 934, Loss: 0.0030584858905058354, Final Batch Loss: 0.0015048558125272393\n",
      "Epoch 935, Loss: 0.004470349958864972, Final Batch Loss: 0.0006137156160548329\n",
      "Epoch 936, Loss: 0.0028784628375433385, Final Batch Loss: 0.0011130287311971188\n",
      "Epoch 937, Loss: 0.0018036496476270258, Final Batch Loss: 0.0007758730789646506\n",
      "Epoch 938, Loss: 0.004615814541466534, Final Batch Loss: 0.0010464134393259883\n",
      "Epoch 939, Loss: 0.013284447457408533, Final Batch Loss: 0.0007772852550260723\n",
      "Epoch 940, Loss: 0.020112876023631543, Final Batch Loss: 0.00032941607059910893\n",
      "Epoch 941, Loss: 0.0012652113146032207, Final Batch Loss: 0.00025512176216579974\n",
      "Epoch 942, Loss: 0.0032591498747933656, Final Batch Loss: 9.720306843519211e-05\n",
      "Epoch 943, Loss: 0.023801159637514502, Final Batch Loss: 0.000604505417868495\n",
      "Epoch 944, Loss: 0.016464985703350976, Final Batch Loss: 0.0006044007022865117\n",
      "Epoch 945, Loss: 0.07108721218537539, Final Batch Loss: 0.03991808369755745\n",
      "Epoch 946, Loss: 0.002561707195127383, Final Batch Loss: 0.000574197038076818\n",
      "Epoch 947, Loss: 0.0052264991390984505, Final Batch Loss: 0.0033123777247965336\n",
      "Epoch 948, Loss: 0.016663564136251807, Final Batch Loss: 0.0019367197528481483\n",
      "Epoch 949, Loss: 0.008757194736972451, Final Batch Loss: 0.0051719434559345245\n",
      "Epoch 950, Loss: 0.015088316911715083, Final Batch Loss: 0.00021239717898424715\n",
      "Epoch 951, Loss: 0.0035616711247712374, Final Batch Loss: 0.0013667652383446693\n",
      "Epoch 952, Loss: 0.028317190590314567, Final Batch Loss: 0.024224616587162018\n",
      "Epoch 953, Loss: 0.006404262618161738, Final Batch Loss: 0.0016108102863654494\n",
      "Epoch 954, Loss: 0.01992772938683629, Final Batch Loss: 0.004556324332952499\n",
      "Epoch 955, Loss: 0.005573435220867395, Final Batch Loss: 0.0010547495912760496\n",
      "Epoch 956, Loss: 0.037719135492807254, Final Batch Loss: 0.0005181895103305578\n",
      "Epoch 957, Loss: 0.003741960448678583, Final Batch Loss: 0.0014146090252324939\n",
      "Epoch 958, Loss: 0.00245742779225111, Final Batch Loss: 0.0006038524443283677\n",
      "Epoch 959, Loss: 0.005056670372141525, Final Batch Loss: 0.001666972879320383\n",
      "Epoch 960, Loss: 0.013314959243871272, Final Batch Loss: 0.009265931323170662\n",
      "Epoch 961, Loss: 0.0030901993231964298, Final Batch Loss: 0.00036530449870042503\n",
      "Epoch 962, Loss: 0.01858513872139156, Final Batch Loss: 0.016108186915516853\n",
      "Epoch 963, Loss: 0.009690876468084753, Final Batch Loss: 0.0008562334114685655\n",
      "Epoch 964, Loss: 0.004890852433163673, Final Batch Loss: 0.0008584486204199493\n",
      "Epoch 965, Loss: 0.004121567209949717, Final Batch Loss: 0.0004422323254402727\n",
      "Epoch 966, Loss: 0.0024172305420506746, Final Batch Loss: 0.001108395284973085\n",
      "Epoch 967, Loss: 0.0038296819548122585, Final Batch Loss: 0.00040525844087824225\n",
      "Epoch 968, Loss: 0.006851698621176183, Final Batch Loss: 0.004074617754667997\n",
      "Epoch 969, Loss: 0.022934951790375635, Final Batch Loss: 0.0003189536218997091\n",
      "Epoch 970, Loss: 0.013682805001735687, Final Batch Loss: 0.008576097898185253\n",
      "Epoch 971, Loss: 0.01062799323699437, Final Batch Loss: 0.00032222815207205713\n",
      "Epoch 972, Loss: 0.006636979465838522, Final Batch Loss: 0.000569118419662118\n",
      "Epoch 973, Loss: 0.0022993971360847354, Final Batch Loss: 0.00027202608180232346\n",
      "Epoch 974, Loss: 0.008003173454198986, Final Batch Loss: 0.0005512781790457666\n",
      "Epoch 975, Loss: 0.004334445053245872, Final Batch Loss: 0.000365040497854352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 976, Loss: 0.015394414949696511, Final Batch Loss: 0.00037030602106824517\n",
      "Epoch 977, Loss: 0.003779041871894151, Final Batch Loss: 0.0008458193624392152\n",
      "Epoch 978, Loss: 0.0060495946381706744, Final Batch Loss: 0.000312333955662325\n",
      "Epoch 979, Loss: 0.005293859809171408, Final Batch Loss: 0.0009196758619509637\n",
      "Epoch 980, Loss: 0.0076874416845384985, Final Batch Loss: 0.0009201411157846451\n",
      "Epoch 981, Loss: 0.011198185267858207, Final Batch Loss: 0.006010148674249649\n",
      "Epoch 982, Loss: 0.004560670990031213, Final Batch Loss: 0.001460135797969997\n",
      "Epoch 983, Loss: 0.004514505330007523, Final Batch Loss: 0.001999383559450507\n",
      "Epoch 984, Loss: 0.01958981946518179, Final Batch Loss: 0.00018203518993686885\n",
      "Epoch 985, Loss: 0.0022619257724727504, Final Batch Loss: 0.0005242150509729981\n",
      "Epoch 986, Loss: 0.011145684140501544, Final Batch Loss: 0.0034369672648608685\n",
      "Epoch 987, Loss: 0.0038481811934616417, Final Batch Loss: 0.00044525755220092833\n",
      "Epoch 988, Loss: 0.007178709303843789, Final Batch Loss: 0.0022744680754840374\n",
      "Epoch 989, Loss: 0.006600195818464272, Final Batch Loss: 0.00019401694589760154\n",
      "Epoch 990, Loss: 0.018235093564726412, Final Batch Loss: 0.0008732489659450948\n",
      "Epoch 991, Loss: 0.007735572289675474, Final Batch Loss: 0.00028007043874822557\n",
      "Epoch 992, Loss: 0.016966019000392407, Final Batch Loss: 0.001642031827941537\n",
      "Epoch 993, Loss: 0.010548719670623541, Final Batch Loss: 0.00214531272649765\n",
      "Epoch 994, Loss: 0.003506630950141698, Final Batch Loss: 0.00026358693139627576\n",
      "Epoch 995, Loss: 0.02699978614691645, Final Batch Loss: 0.008732016198337078\n",
      "Epoch 996, Loss: 0.01016188319772482, Final Batch Loss: 0.004620813764631748\n",
      "Epoch 997, Loss: 0.016224874154431745, Final Batch Loss: 0.0005606427439488471\n",
      "Epoch 998, Loss: 0.02172155922744423, Final Batch Loss: 0.0001370524405501783\n",
      "Epoch 999, Loss: 0.003477776423096657, Final Batch Loss: 0.0004886317765340209\n",
      "Epoch 1000, Loss: 0.012794187292456627, Final Batch Loss: 0.00017085857689380646\n",
      "Epoch 1001, Loss: 0.004383497609524056, Final Batch Loss: 0.00019169473671354353\n",
      "Epoch 1002, Loss: 0.003351778461365029, Final Batch Loss: 0.00021181401098147035\n",
      "Epoch 1003, Loss: 0.01073597522918135, Final Batch Loss: 0.0019034971483051777\n",
      "Epoch 1004, Loss: 0.017255937331356108, Final Batch Loss: 0.002268481068313122\n",
      "Epoch 1005, Loss: 0.013109555700793862, Final Batch Loss: 0.007730359677225351\n",
      "Epoch 1006, Loss: 0.0057418048672843724, Final Batch Loss: 0.0030235666781663895\n",
      "Epoch 1007, Loss: 0.002412974732578732, Final Batch Loss: 0.000891761330422014\n",
      "Epoch 1008, Loss: 0.0023370851413346827, Final Batch Loss: 0.00030093255918473005\n",
      "Epoch 1009, Loss: 0.0025948331167455763, Final Batch Loss: 0.0005882814875803888\n",
      "Epoch 1010, Loss: 0.0030945421021897346, Final Batch Loss: 0.00033836477086879313\n",
      "Epoch 1011, Loss: 0.006114467047154903, Final Batch Loss: 0.0005186216440051794\n",
      "Epoch 1012, Loss: 0.0026750967954285443, Final Batch Loss: 0.00030550442170351744\n",
      "Epoch 1013, Loss: 0.0014932280464563519, Final Batch Loss: 0.0003902894095517695\n",
      "Epoch 1014, Loss: 0.004630967188859358, Final Batch Loss: 0.0011866047279909253\n",
      "Epoch 1015, Loss: 0.004220997856464237, Final Batch Loss: 0.0001426898525096476\n",
      "Epoch 1016, Loss: 0.0038021930668037385, Final Batch Loss: 0.0006256730412133038\n",
      "Epoch 1017, Loss: 0.04046221886528656, Final Batch Loss: 0.0014858008362352848\n",
      "Epoch 1018, Loss: 0.004472211003303528, Final Batch Loss: 0.0016599056543782353\n",
      "Epoch 1019, Loss: 0.004148431966314092, Final Batch Loss: 0.0023977339733392\n",
      "Epoch 1020, Loss: 0.005755387479439378, Final Batch Loss: 0.001282027456909418\n",
      "Epoch 1021, Loss: 0.015193650557193905, Final Batch Loss: 0.0002278756583109498\n",
      "Epoch 1022, Loss: 0.0028881850303150713, Final Batch Loss: 0.00032612180802971125\n",
      "Epoch 1023, Loss: 0.030029589135665447, Final Batch Loss: 0.0009665297693572938\n",
      "Epoch 1024, Loss: 0.002068613684969023, Final Batch Loss: 0.0006661619991064072\n",
      "Epoch 1025, Loss: 0.001959377113962546, Final Batch Loss: 0.0006045044283382595\n",
      "Epoch 1026, Loss: 0.009051018714671955, Final Batch Loss: 0.004505809396505356\n",
      "Epoch 1027, Loss: 0.0014608001365559176, Final Batch Loss: 0.00019896206504199654\n",
      "Epoch 1028, Loss: 0.0076566110365092754, Final Batch Loss: 0.0008023529662750661\n",
      "Epoch 1029, Loss: 0.0015153354397625662, Final Batch Loss: 0.0006411520880647004\n",
      "Epoch 1030, Loss: 0.02264311190810986, Final Batch Loss: 0.0003133453137706965\n",
      "Epoch 1031, Loss: 0.015598523896187544, Final Batch Loss: 0.0008614631369709969\n",
      "Epoch 1032, Loss: 0.021560556429903954, Final Batch Loss: 0.0007223034044727683\n",
      "Epoch 1033, Loss: 0.008378516242373735, Final Batch Loss: 0.0008784023229964077\n",
      "Epoch 1034, Loss: 0.006054485449567437, Final Batch Loss: 0.0003659026697278023\n",
      "Epoch 1035, Loss: 0.033686061564367265, Final Batch Loss: 0.0008121886639855802\n",
      "Epoch 1036, Loss: 0.0034146441030316055, Final Batch Loss: 0.000745018245652318\n",
      "Epoch 1037, Loss: 0.013247335387859493, Final Batch Loss: 0.0012908957432955503\n",
      "Epoch 1038, Loss: 0.0008665919594932348, Final Batch Loss: 0.0005294756847433746\n",
      "Epoch 1039, Loss: 0.014292402716819197, Final Batch Loss: 0.0005611249944195151\n",
      "Epoch 1040, Loss: 0.02133166423300281, Final Batch Loss: 0.004829770419746637\n",
      "Epoch 1041, Loss: 0.007026110193692148, Final Batch Loss: 0.002338720951229334\n",
      "Epoch 1042, Loss: 0.0014946612573112361, Final Batch Loss: 9.967406367650256e-05\n",
      "Epoch 1043, Loss: 0.0036526705662254244, Final Batch Loss: 0.000608303991612047\n",
      "Epoch 1044, Loss: 0.00560360137023963, Final Batch Loss: 0.0003540094767231494\n",
      "Epoch 1045, Loss: 0.0036587649083230644, Final Batch Loss: 0.0003334911016281694\n",
      "Epoch 1046, Loss: 0.005750356009230018, Final Batch Loss: 0.0034604952670633793\n",
      "Epoch 1047, Loss: 0.0049869619542732835, Final Batch Loss: 0.0010597483487799764\n",
      "Epoch 1048, Loss: 0.006837510387413204, Final Batch Loss: 0.003552597016096115\n",
      "Epoch 1049, Loss: 0.004270688645192422, Final Batch Loss: 0.00020467610738705844\n",
      "Epoch 1050, Loss: 0.0046664015389978886, Final Batch Loss: 0.0003954012063331902\n",
      "Epoch 1051, Loss: 0.004051869691465981, Final Batch Loss: 0.0006414578529074788\n",
      "Epoch 1052, Loss: 0.0014859024086035788, Final Batch Loss: 0.00019473204156383872\n",
      "Epoch 1053, Loss: 0.0048095485544763505, Final Batch Loss: 0.0003631651634350419\n",
      "Epoch 1054, Loss: 0.012925580333103426, Final Batch Loss: 0.0001963709364645183\n",
      "Epoch 1055, Loss: 0.018051267856208142, Final Batch Loss: 0.002071856055408716\n",
      "Epoch 1056, Loss: 0.0021321141393855214, Final Batch Loss: 0.00027068424969911575\n",
      "Epoch 1057, Loss: 0.002356306547881104, Final Batch Loss: 9.823621076066047e-05\n",
      "Epoch 1058, Loss: 0.004762307740747929, Final Batch Loss: 0.002399296034127474\n",
      "Epoch 1059, Loss: 0.0033003349672071636, Final Batch Loss: 0.00024668441619724035\n",
      "Epoch 1060, Loss: 0.022861704812385142, Final Batch Loss: 0.01593702659010887\n",
      "Epoch 1061, Loss: 0.00773317355196923, Final Batch Loss: 0.0008555000531487167\n",
      "Epoch 1062, Loss: 0.006264298892347142, Final Batch Loss: 0.00018045752949547023\n",
      "Epoch 1063, Loss: 0.004556544095976278, Final Batch Loss: 0.00025503055076114833\n",
      "Epoch 1064, Loss: 0.006939221857464872, Final Batch Loss: 0.00018120869935955852\n",
      "Epoch 1065, Loss: 0.006782522839785088, Final Batch Loss: 0.00012687587877735496\n",
      "Epoch 1066, Loss: 0.002946970140328631, Final Batch Loss: 0.0016080496134236455\n",
      "Epoch 1067, Loss: 0.05889322710572742, Final Batch Loss: 0.0005911263870075345\n",
      "Epoch 1068, Loss: 0.0033942698210012168, Final Batch Loss: 0.0021821775007992983\n",
      "Epoch 1069, Loss: 0.0035670262877829373, Final Batch Loss: 0.0006152581190690398\n",
      "Epoch 1070, Loss: 0.002067822773824446, Final Batch Loss: 0.00040642262320034206\n",
      "Epoch 1071, Loss: 0.044748071872163564, Final Batch Loss: 0.00023814986343495548\n",
      "Epoch 1072, Loss: 0.002291804092237726, Final Batch Loss: 0.0006713696639053524\n",
      "Epoch 1073, Loss: 0.008376339708775049, Final Batch Loss: 0.0014938422245904803\n",
      "Epoch 1074, Loss: 0.0038795993314124644, Final Batch Loss: 0.00017867522547021508\n",
      "Epoch 1075, Loss: 0.010186209168750793, Final Batch Loss: 0.00022408502991311252\n",
      "Epoch 1076, Loss: 0.0019215558131691068, Final Batch Loss: 0.0005578771815635264\n",
      "Epoch 1077, Loss: 0.005505287233972922, Final Batch Loss: 0.0004550337034743279\n",
      "Epoch 1078, Loss: 0.008533871208783239, Final Batch Loss: 0.0012592406710609794\n",
      "Epoch 1079, Loss: 0.004284640257537831, Final Batch Loss: 6.779441173421219e-05\n",
      "Epoch 1080, Loss: 0.0023412111622747034, Final Batch Loss: 0.00038153750938363373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1081, Loss: 0.021710449567763135, Final Batch Loss: 0.020876973867416382\n",
      "Epoch 1082, Loss: 0.010689219954656437, Final Batch Loss: 0.008966322988271713\n",
      "Epoch 1083, Loss: 0.006430132343666628, Final Batch Loss: 0.00018486249609850347\n",
      "Epoch 1084, Loss: 0.011451080674305558, Final Batch Loss: 0.007107527926564217\n",
      "Epoch 1085, Loss: 0.0008123886909743305, Final Batch Loss: 3.51711169059854e-05\n",
      "Epoch 1086, Loss: 0.004254726707586087, Final Batch Loss: 0.003480276558548212\n",
      "Epoch 1087, Loss: 0.010242676886264235, Final Batch Loss: 0.0004886660608462989\n",
      "Epoch 1088, Loss: 0.0018269246502313763, Final Batch Loss: 0.0002812936727423221\n",
      "Epoch 1089, Loss: 0.0024288175045512617, Final Batch Loss: 0.0008811381412670016\n",
      "Epoch 1090, Loss: 0.0017110655171563849, Final Batch Loss: 0.00029692306998185813\n",
      "Epoch 1091, Loss: 0.0034459068992873654, Final Batch Loss: 0.0008838202338665724\n",
      "Epoch 1092, Loss: 0.012738837642245926, Final Batch Loss: 0.01105880830436945\n",
      "Epoch 1093, Loss: 0.0014253861008910462, Final Batch Loss: 0.00013768051576334983\n",
      "Epoch 1094, Loss: 0.004066672612680122, Final Batch Loss: 0.0010600531240925193\n",
      "Epoch 1095, Loss: 0.0037906610523350537, Final Batch Loss: 0.0010445635998621583\n",
      "Epoch 1096, Loss: 0.0021969244116917253, Final Batch Loss: 0.00046853598905727267\n",
      "Epoch 1097, Loss: 0.011637412870186381, Final Batch Loss: 0.008273889310657978\n",
      "Epoch 1098, Loss: 0.0025999792851507664, Final Batch Loss: 0.00039796449709683657\n",
      "Epoch 1099, Loss: 0.003303630288428394, Final Batch Loss: 3.1483166821999475e-05\n",
      "Epoch 1100, Loss: 0.003424067450396251, Final Batch Loss: 0.0022614924237132072\n",
      "Epoch 1101, Loss: 0.004750642154249363, Final Batch Loss: 0.0007620854303240776\n",
      "Epoch 1102, Loss: 0.007057350769173354, Final Batch Loss: 0.005820877384394407\n",
      "Epoch 1103, Loss: 0.003615094319684431, Final Batch Loss: 0.0010430171387270093\n",
      "Epoch 1104, Loss: 0.002564280148362741, Final Batch Loss: 0.0003676310006994754\n",
      "Epoch 1105, Loss: 0.0030647649546153843, Final Batch Loss: 0.0012068840442225337\n",
      "Epoch 1106, Loss: 0.002524619674659334, Final Batch Loss: 0.0006222565425559878\n",
      "Epoch 1107, Loss: 0.016761500664870255, Final Batch Loss: 0.014921327121555805\n",
      "Epoch 1108, Loss: 0.00481752073392272, Final Batch Loss: 0.000294325640425086\n",
      "Epoch 1109, Loss: 0.001669522185693495, Final Batch Loss: 0.00027104857144877315\n",
      "Epoch 1110, Loss: 0.0019595051126088947, Final Batch Loss: 0.00013987653073854744\n",
      "Epoch 1111, Loss: 0.02583101627533324, Final Batch Loss: 0.0009118579910136759\n",
      "Epoch 1112, Loss: 0.002360893369768746, Final Batch Loss: 0.000379473582142964\n",
      "Epoch 1113, Loss: 0.0013042379869148135, Final Batch Loss: 0.000684548809658736\n",
      "Epoch 1114, Loss: 0.0030581829050788656, Final Batch Loss: 0.0014139213599264622\n",
      "Epoch 1115, Loss: 0.006487920065410435, Final Batch Loss: 0.0019950747955590487\n",
      "Epoch 1116, Loss: 0.0005702379130525514, Final Batch Loss: 5.315340240485966e-05\n",
      "Epoch 1117, Loss: 0.0010215333313681185, Final Batch Loss: 0.00028731097700074315\n",
      "Epoch 1118, Loss: 0.017187730758450925, Final Batch Loss: 0.01415904238820076\n",
      "Epoch 1119, Loss: 0.004610446922015399, Final Batch Loss: 0.0011887062573805451\n",
      "Epoch 1120, Loss: 0.002005716029088944, Final Batch Loss: 0.0005778290797024965\n",
      "Epoch 1121, Loss: 0.0023016757040750235, Final Batch Loss: 0.0006103471969254315\n",
      "Epoch 1122, Loss: 0.0019979239150416106, Final Batch Loss: 0.0001788436493370682\n",
      "Epoch 1123, Loss: 0.007158958789659664, Final Batch Loss: 0.002146972343325615\n",
      "Epoch 1124, Loss: 0.005325861886376515, Final Batch Loss: 0.0013988424325361848\n",
      "Epoch 1125, Loss: 0.00279615237377584, Final Batch Loss: 0.0016573985340073705\n",
      "Epoch 1126, Loss: 0.003472791111562401, Final Batch Loss: 0.00024401533300988376\n",
      "Epoch 1127, Loss: 0.0056765043482300825, Final Batch Loss: 0.00015623035142198205\n",
      "Epoch 1128, Loss: 0.04214668546046596, Final Batch Loss: 0.00012845220044255257\n",
      "Epoch 1129, Loss: 0.0012382271379465237, Final Batch Loss: 0.0001305552723351866\n",
      "Epoch 1130, Loss: 0.0017790644997148775, Final Batch Loss: 0.0004973058239556849\n",
      "Epoch 1131, Loss: 0.0012627994365175255, Final Batch Loss: 0.00019646366126835346\n",
      "Epoch 1132, Loss: 0.0011952682980336249, Final Batch Loss: 0.00012355273065622896\n",
      "Epoch 1133, Loss: 0.015459211601410061, Final Batch Loss: 0.0004359728191047907\n",
      "Epoch 1134, Loss: 0.001885800633317558, Final Batch Loss: 4.4276017433730885e-05\n",
      "Epoch 1135, Loss: 0.011562873842194676, Final Batch Loss: 0.0006510991370305419\n",
      "Epoch 1136, Loss: 0.001746459340211004, Final Batch Loss: 0.00030263446387834847\n",
      "Epoch 1137, Loss: 0.011731272737961262, Final Batch Loss: 0.0010773716494441032\n",
      "Epoch 1138, Loss: 0.008368555223569274, Final Batch Loss: 0.0002617612190078944\n",
      "Epoch 1139, Loss: 0.005672299936122727, Final Batch Loss: 0.004834451712667942\n",
      "Epoch 1140, Loss: 0.002044052023848053, Final Batch Loss: 4.618429011316039e-05\n",
      "Epoch 1141, Loss: 0.007480268002836965, Final Batch Loss: 0.0062508294358849525\n",
      "Epoch 1142, Loss: 0.015165883480221964, Final Batch Loss: 0.012907874770462513\n",
      "Epoch 1143, Loss: 0.003623519151005894, Final Batch Loss: 0.0016169294249266386\n",
      "Epoch 1144, Loss: 0.0018323978292755783, Final Batch Loss: 0.0004080414364580065\n",
      "Epoch 1145, Loss: 0.0026693990657804534, Final Batch Loss: 0.0006354794022627175\n",
      "Epoch 1146, Loss: 0.00354485961725004, Final Batch Loss: 0.0001480818900745362\n",
      "Epoch 1147, Loss: 0.004203478019917384, Final Batch Loss: 0.0004781269235536456\n",
      "Epoch 1148, Loss: 0.007985854026628658, Final Batch Loss: 0.0001556442875880748\n",
      "Epoch 1149, Loss: 0.0016271050262730569, Final Batch Loss: 0.0005531319766305387\n",
      "Epoch 1150, Loss: 0.016831314540468156, Final Batch Loss: 0.0007573479088023305\n",
      "Epoch 1151, Loss: 0.0017978254036279395, Final Batch Loss: 0.00017304740322288126\n",
      "Epoch 1152, Loss: 0.009373327120556496, Final Batch Loss: 0.00018697584164328873\n",
      "Epoch 1153, Loss: 0.017952982510905713, Final Batch Loss: 0.00015447262558154762\n",
      "Epoch 1154, Loss: 0.0021930614675511606, Final Batch Loss: 0.0010391438845545053\n",
      "Epoch 1155, Loss: 0.0018356219225097448, Final Batch Loss: 0.00020864245016127825\n",
      "Epoch 1156, Loss: 0.002802135582896881, Final Batch Loss: 0.00020907064026687294\n",
      "Epoch 1157, Loss: 0.02081514339079149, Final Batch Loss: 0.019480258226394653\n",
      "Epoch 1158, Loss: 0.008411773684201762, Final Batch Loss: 0.0003782610292546451\n",
      "Epoch 1159, Loss: 0.001978702988708392, Final Batch Loss: 0.000511884456500411\n",
      "Epoch 1160, Loss: 0.005081232862721663, Final Batch Loss: 0.002401010598987341\n",
      "Epoch 1161, Loss: 0.006513047948828898, Final Batch Loss: 0.00020064479031134397\n",
      "Epoch 1162, Loss: 0.001034882225212641, Final Batch Loss: 0.00030621158657595515\n",
      "Epoch 1163, Loss: 0.001760612751240842, Final Batch Loss: 0.0008307844400405884\n",
      "Epoch 1164, Loss: 0.002880168700357899, Final Batch Loss: 0.0008378109778277576\n",
      "Epoch 1165, Loss: 0.0019161365053150803, Final Batch Loss: 0.0006079997401684523\n",
      "Epoch 1166, Loss: 0.005838303695782088, Final Batch Loss: 0.003573432331904769\n",
      "Epoch 1167, Loss: 0.003086121112573892, Final Batch Loss: 0.0004293620295356959\n",
      "Epoch 1168, Loss: 0.0011920312972506508, Final Batch Loss: 7.166962313931435e-05\n",
      "Epoch 1169, Loss: 0.005064080090960488, Final Batch Loss: 0.0038010228890925646\n",
      "Epoch 1170, Loss: 0.0009689940779935569, Final Batch Loss: 0.0001965913688763976\n",
      "Epoch 1171, Loss: 0.002686625753995031, Final Batch Loss: 0.0008454942726530135\n",
      "Epoch 1172, Loss: 0.0015721218514954671, Final Batch Loss: 0.00021391574409790337\n",
      "Epoch 1173, Loss: 0.002749747844063677, Final Batch Loss: 0.0017894755583256483\n",
      "Epoch 1174, Loss: 0.0029387346585281193, Final Batch Loss: 0.00035958061926066875\n",
      "Epoch 1175, Loss: 0.0018908958445535973, Final Batch Loss: 0.00021763356926385313\n",
      "Epoch 1176, Loss: 0.002131729073880706, Final Batch Loss: 0.00021165740326978266\n",
      "Epoch 1177, Loss: 0.014922381727956235, Final Batch Loss: 0.001929936115629971\n",
      "Epoch 1178, Loss: 0.00894281652290374, Final Batch Loss: 0.00013213342754170299\n",
      "Epoch 1179, Loss: 0.0033694483136059716, Final Batch Loss: 0.0002364044194109738\n",
      "Epoch 1180, Loss: 0.0016956519029918127, Final Batch Loss: 6.325626600300893e-05\n",
      "Epoch 1181, Loss: 0.004091620532562956, Final Batch Loss: 0.0005426941788755357\n",
      "Epoch 1182, Loss: 0.0025185282247548457, Final Batch Loss: 4.800186070497148e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1183, Loss: 0.0034651335736270994, Final Batch Loss: 0.000592690019402653\n",
      "Epoch 1184, Loss: 0.001982225672691129, Final Batch Loss: 0.0006564697250723839\n",
      "Epoch 1185, Loss: 0.0013899457990191877, Final Batch Loss: 0.00011117104440927505\n",
      "Epoch 1186, Loss: 0.0006689507827104535, Final Batch Loss: 0.0002143937163054943\n",
      "Epoch 1187, Loss: 0.0015967540093697608, Final Batch Loss: 0.00047613264177925885\n",
      "Epoch 1188, Loss: 0.0014409934228751808, Final Batch Loss: 0.00035038890200667083\n",
      "Epoch 1189, Loss: 0.0011035889110644348, Final Batch Loss: 0.0002516508393455297\n",
      "Epoch 1190, Loss: 0.000907498222659342, Final Batch Loss: 5.442819383461028e-05\n",
      "Epoch 1191, Loss: 0.0008561370905226795, Final Batch Loss: 0.0003011160297319293\n",
      "Epoch 1192, Loss: 0.0007055740970827173, Final Batch Loss: 0.0003293415647931397\n",
      "Epoch 1193, Loss: 0.019080436279182322, Final Batch Loss: 0.000494531646836549\n",
      "Epoch 1194, Loss: 0.0017602666121092625, Final Batch Loss: 0.00026326169609092176\n",
      "Epoch 1195, Loss: 0.004528455581748858, Final Batch Loss: 0.0008513466455042362\n",
      "Epoch 1196, Loss: 0.010890474597545108, Final Batch Loss: 0.0006793744978494942\n",
      "Epoch 1197, Loss: 0.0034619491307239514, Final Batch Loss: 5.452321420307271e-05\n",
      "Epoch 1198, Loss: 0.002303221757756546, Final Batch Loss: 0.00035821256460621953\n",
      "Epoch 1199, Loss: 0.002606123758596368, Final Batch Loss: 0.001183724612928927\n",
      "Epoch 1200, Loss: 0.001464384884457104, Final Batch Loss: 0.0010511676082387567\n",
      "Epoch 1201, Loss: 0.009391936764586717, Final Batch Loss: 0.005801004357635975\n",
      "Epoch 1202, Loss: 0.0013756524167547468, Final Batch Loss: 0.0008120941347442567\n",
      "Epoch 1203, Loss: 0.0025969114576582797, Final Batch Loss: 0.002118568168953061\n",
      "Epoch 1204, Loss: 0.0030594395066145808, Final Batch Loss: 8.510655607096851e-05\n",
      "Epoch 1205, Loss: 0.041963289309933316, Final Batch Loss: 0.0004645795270334929\n",
      "Epoch 1206, Loss: 0.003325631103507476, Final Batch Loss: 0.0009797754464671016\n",
      "Epoch 1207, Loss: 0.020181824736937415, Final Batch Loss: 0.01939932256937027\n",
      "Epoch 1208, Loss: 0.001519204415671993, Final Batch Loss: 4.5658489398192614e-05\n",
      "Epoch 1209, Loss: 0.0016494741721544415, Final Batch Loss: 0.00017831493460107595\n",
      "Epoch 1210, Loss: 0.0020659952497226186, Final Batch Loss: 0.00010893695434788242\n",
      "Epoch 1211, Loss: 0.0014842761593172327, Final Batch Loss: 4.488347622100264e-05\n",
      "Epoch 1212, Loss: 0.006094398209825158, Final Batch Loss: 0.0014539429685100913\n",
      "Epoch 1213, Loss: 0.0006612760407733731, Final Batch Loss: 4.7150599129963666e-05\n",
      "Epoch 1214, Loss: 0.004261249472619966, Final Batch Loss: 0.001157899503596127\n",
      "Epoch 1215, Loss: 0.03506658528931439, Final Batch Loss: 0.011126370169222355\n",
      "Epoch 1216, Loss: 0.0014157296973280609, Final Batch Loss: 0.0002764208766166121\n",
      "Epoch 1217, Loss: 0.0011679691378958523, Final Batch Loss: 0.00035625783493742347\n",
      "Epoch 1218, Loss: 0.0017380636236339342, Final Batch Loss: 0.001014498993754387\n",
      "Epoch 1219, Loss: 0.01044576485583093, Final Batch Loss: 0.00023795799643266946\n",
      "Epoch 1220, Loss: 0.0067021087888861075, Final Batch Loss: 0.001275304821319878\n",
      "Epoch 1221, Loss: 0.00296806322876364, Final Batch Loss: 0.0016577051719650626\n",
      "Epoch 1222, Loss: 0.005913563159992918, Final Batch Loss: 0.0012712054885923862\n",
      "Epoch 1223, Loss: 0.004820013593416661, Final Batch Loss: 0.0009598772739991546\n",
      "Epoch 1224, Loss: 0.0031701992847956717, Final Batch Loss: 0.00012424253509379923\n",
      "Epoch 1225, Loss: 0.0064172115962719545, Final Batch Loss: 0.0006620436906814575\n",
      "Epoch 1226, Loss: 0.0065533357264939696, Final Batch Loss: 0.005264428444206715\n",
      "Epoch 1227, Loss: 0.000964140024734661, Final Batch Loss: 0.00017132841458078474\n",
      "Epoch 1228, Loss: 0.0018475701654097065, Final Batch Loss: 0.0001288092025788501\n",
      "Epoch 1229, Loss: 0.007801756699336693, Final Batch Loss: 0.0022691020276397467\n",
      "Epoch 1230, Loss: 0.0014239114098018035, Final Batch Loss: 0.0006346010486595333\n",
      "Epoch 1231, Loss: 0.005947810335783288, Final Batch Loss: 0.0009067022474482656\n",
      "Epoch 1232, Loss: 0.003807512897765264, Final Batch Loss: 0.00020999890693929046\n",
      "Epoch 1233, Loss: 0.006806637116824277, Final Batch Loss: 0.0001248428743565455\n",
      "Epoch 1234, Loss: 0.004808945115655661, Final Batch Loss: 0.0021996975410729647\n",
      "Epoch 1235, Loss: 0.0070833206991665065, Final Batch Loss: 0.0031041502952575684\n",
      "Epoch 1236, Loss: 0.019686120911501348, Final Batch Loss: 0.0010661674896255136\n",
      "Epoch 1237, Loss: 0.0044903013040311635, Final Batch Loss: 0.0003034136607311666\n",
      "Epoch 1238, Loss: 0.0009613219590391964, Final Batch Loss: 0.00023698776203673333\n",
      "Epoch 1239, Loss: 0.026492785429582, Final Batch Loss: 0.019305279478430748\n",
      "Epoch 1240, Loss: 0.0013472553837345913, Final Batch Loss: 0.0008470867178402841\n",
      "Epoch 1241, Loss: 0.060871029942063615, Final Batch Loss: 0.05273933708667755\n",
      "Epoch 1242, Loss: 0.0020338324829936028, Final Batch Loss: 9.798182873055339e-05\n",
      "Epoch 1243, Loss: 0.030677967573865317, Final Batch Loss: 0.01476550754159689\n",
      "Epoch 1244, Loss: 0.003650976788776461, Final Batch Loss: 0.0029140645638108253\n",
      "Epoch 1245, Loss: 0.0019243439892306924, Final Batch Loss: 0.0004538709472399205\n",
      "Epoch 1246, Loss: 0.0030880124249961227, Final Batch Loss: 0.0008760771597735584\n",
      "Epoch 1247, Loss: 0.04774024047947023, Final Batch Loss: 0.04720548912882805\n",
      "Epoch 1248, Loss: 0.01606464639189653, Final Batch Loss: 0.00040785683086141944\n",
      "Epoch 1249, Loss: 0.003273354552220553, Final Batch Loss: 0.0014741081977263093\n",
      "Epoch 1250, Loss: 0.02015921811835142, Final Batch Loss: 0.01350363902747631\n",
      "Epoch 1251, Loss: 0.02456849956070073, Final Batch Loss: 0.00020229998335707933\n",
      "Epoch 1252, Loss: 0.009232570184394717, Final Batch Loss: 0.0009056966518983245\n",
      "Epoch 1253, Loss: 0.0017574059893377125, Final Batch Loss: 0.0005834134062752128\n",
      "Epoch 1254, Loss: 0.0032704702171031386, Final Batch Loss: 0.0005479585379362106\n",
      "Epoch 1255, Loss: 0.020671292433689814, Final Batch Loss: 0.018555156886577606\n",
      "Epoch 1256, Loss: 0.00244396147900261, Final Batch Loss: 0.0003150617703795433\n",
      "Epoch 1257, Loss: 0.0031330898636952043, Final Batch Loss: 0.000493547588121146\n",
      "Epoch 1258, Loss: 0.00749145436566323, Final Batch Loss: 0.0011639798758551478\n",
      "Epoch 1259, Loss: 0.0032999444229062647, Final Batch Loss: 0.0011163585586473346\n",
      "Epoch 1260, Loss: 0.0043701828544726595, Final Batch Loss: 0.0005222437321208417\n",
      "Epoch 1261, Loss: 0.02155306003987789, Final Batch Loss: 0.0012541880132630467\n",
      "Epoch 1262, Loss: 0.010593966348096728, Final Batch Loss: 0.0006772982887923717\n",
      "Epoch 1263, Loss: 0.021457994429511018, Final Batch Loss: 0.007126402575522661\n",
      "Epoch 1264, Loss: 0.0038506610435433686, Final Batch Loss: 0.002324741566553712\n",
      "Epoch 1265, Loss: 0.0020483685075305402, Final Batch Loss: 0.00020429491996765137\n",
      "Epoch 1266, Loss: 0.006075802550185472, Final Batch Loss: 0.002193563152104616\n",
      "Epoch 1267, Loss: 0.00326260578003712, Final Batch Loss: 0.0011262602638453245\n",
      "Epoch 1268, Loss: 0.0023635749821551144, Final Batch Loss: 0.00020570398191921413\n",
      "Epoch 1269, Loss: 0.0024958107387647033, Final Batch Loss: 0.0012396967504173517\n",
      "Epoch 1270, Loss: 0.03456770463526482, Final Batch Loss: 9.762004629010335e-05\n",
      "Epoch 1271, Loss: 0.0035945368435932323, Final Batch Loss: 0.00024686622782610357\n",
      "Epoch 1272, Loss: 0.0016915634805627633, Final Batch Loss: 0.000483544310554862\n",
      "Epoch 1273, Loss: 0.00187178811756894, Final Batch Loss: 0.00029905640985816717\n",
      "Epoch 1274, Loss: 0.007453416765201837, Final Batch Loss: 0.0007176329381763935\n",
      "Epoch 1275, Loss: 0.002131030174496118, Final Batch Loss: 0.0007614404894411564\n",
      "Epoch 1276, Loss: 0.026948439131956547, Final Batch Loss: 0.001926966244354844\n",
      "Epoch 1277, Loss: 0.0022909662511665374, Final Batch Loss: 0.0009092886466532946\n",
      "Epoch 1278, Loss: 0.002571782883023843, Final Batch Loss: 0.0006815052474848926\n",
      "Epoch 1279, Loss: 0.005892695131478831, Final Batch Loss: 0.0006567724631167948\n",
      "Epoch 1280, Loss: 0.0019656324366224, Final Batch Loss: 0.00019396153220441192\n",
      "Epoch 1281, Loss: 0.0008679976526764221, Final Batch Loss: 8.969182817963883e-05\n",
      "Epoch 1282, Loss: 0.003109963610768318, Final Batch Loss: 0.002417478011921048\n",
      "Epoch 1283, Loss: 0.0010891061756410636, Final Batch Loss: 0.00010796142305480316\n",
      "Epoch 1284, Loss: 0.0018628582474775612, Final Batch Loss: 0.0008873409824445844\n",
      "Epoch 1285, Loss: 0.0013721568539040163, Final Batch Loss: 0.0001865327503765002\n",
      "Epoch 1286, Loss: 0.001875290705356747, Final Batch Loss: 0.00027169918757863343\n",
      "Epoch 1287, Loss: 0.0008943475259002298, Final Batch Loss: 3.27310262946412e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1288, Loss: 0.0008277829620055854, Final Batch Loss: 0.00015659170458093286\n",
      "Epoch 1289, Loss: 0.010857012966880575, Final Batch Loss: 0.0008368506678380072\n",
      "Epoch 1290, Loss: 0.006117254320997745, Final Batch Loss: 0.001361012808047235\n",
      "Epoch 1291, Loss: 0.0027838284004246816, Final Batch Loss: 0.0009899813449010253\n",
      "Epoch 1292, Loss: 0.00294788958854042, Final Batch Loss: 0.00012742294347845018\n",
      "Epoch 1293, Loss: 0.0018746209098026156, Final Batch Loss: 0.00045913082431070507\n",
      "Epoch 1294, Loss: 0.0010328053904231638, Final Batch Loss: 0.0002698005991987884\n",
      "Epoch 1295, Loss: 0.0012211906141601503, Final Batch Loss: 6.665076944045722e-05\n",
      "Epoch 1296, Loss: 0.001335417000518646, Final Batch Loss: 0.0004110252484679222\n",
      "Epoch 1297, Loss: 0.001853852405474754, Final Batch Loss: 0.0012964359484612942\n",
      "Epoch 1298, Loss: 0.0011163115705130622, Final Batch Loss: 0.0002071311610052362\n",
      "Epoch 1299, Loss: 0.0007918029223219492, Final Batch Loss: 0.00017885930719785392\n",
      "Epoch 1300, Loss: 0.02257585132610984, Final Batch Loss: 0.014917525462806225\n",
      "Epoch 1301, Loss: 0.0018954378319904208, Final Batch Loss: 0.0003762941632885486\n",
      "Epoch 1302, Loss: 0.004342891625128686, Final Batch Loss: 0.0021557901054620743\n",
      "Epoch 1303, Loss: 0.0028432949620764703, Final Batch Loss: 0.00047843079664744437\n",
      "Epoch 1304, Loss: 0.0035379824112169445, Final Batch Loss: 0.0007948583806864917\n",
      "Epoch 1305, Loss: 0.0025809164508245885, Final Batch Loss: 0.0012775443028658628\n",
      "Epoch 1306, Loss: 0.01205958501304849, Final Batch Loss: 4.412540511111729e-05\n",
      "Epoch 1307, Loss: 0.0017749331600498408, Final Batch Loss: 0.0005201743333600461\n",
      "Epoch 1308, Loss: 0.002746692145592533, Final Batch Loss: 0.00017433537868782878\n",
      "Epoch 1309, Loss: 0.0015837055689189583, Final Batch Loss: 0.00030748502467758954\n",
      "Epoch 1310, Loss: 0.002178734779590741, Final Batch Loss: 0.0006856296095065773\n",
      "Epoch 1311, Loss: 0.040746322949416935, Final Batch Loss: 0.0012923654867336154\n",
      "Epoch 1312, Loss: 0.002539655371947447, Final Batch Loss: 0.00028729080804623663\n",
      "Epoch 1313, Loss: 0.003279669617768377, Final Batch Loss: 0.00016071589197963476\n",
      "Epoch 1314, Loss: 0.023322853274294175, Final Batch Loss: 0.0002328891569050029\n",
      "Epoch 1315, Loss: 0.003925640005036257, Final Batch Loss: 0.0003745730791706592\n",
      "Epoch 1316, Loss: 0.0038222403891268186, Final Batch Loss: 0.00010210199252469465\n",
      "Epoch 1317, Loss: 0.008606220304500312, Final Batch Loss: 0.0050802999176084995\n",
      "Epoch 1318, Loss: 0.007104531629011035, Final Batch Loss: 0.001864997553639114\n",
      "Epoch 1319, Loss: 0.0007017696352704661, Final Batch Loss: 2.497286732250359e-05\n",
      "Epoch 1320, Loss: 0.0034774860978359357, Final Batch Loss: 0.0020543786231428385\n",
      "Epoch 1321, Loss: 0.004271331577911042, Final Batch Loss: 0.00022116878244560212\n",
      "Epoch 1322, Loss: 0.0038548646989511326, Final Batch Loss: 0.001606521662324667\n",
      "Epoch 1323, Loss: 0.0041914487228496, Final Batch Loss: 0.00016612003673799336\n",
      "Epoch 1324, Loss: 0.0031160991347860545, Final Batch Loss: 0.00015048276691231877\n",
      "Epoch 1325, Loss: 0.0013788399010081775, Final Batch Loss: 7.804099004715681e-05\n",
      "Epoch 1326, Loss: 0.0045326137042138726, Final Batch Loss: 0.000320876861223951\n",
      "Epoch 1327, Loss: 0.0011840977531392127, Final Batch Loss: 0.00025974729214794934\n",
      "Epoch 1328, Loss: 0.00272208288879483, Final Batch Loss: 0.0013497652253136039\n",
      "Epoch 1329, Loss: 0.010580547765130177, Final Batch Loss: 0.0003495299897622317\n",
      "Epoch 1330, Loss: 0.014922132162610069, Final Batch Loss: 0.00025512638967484236\n",
      "Epoch 1331, Loss: 0.002294549864018336, Final Batch Loss: 0.0003144362417515367\n",
      "Epoch 1332, Loss: 0.0011719457470462658, Final Batch Loss: 0.00010922615911113098\n",
      "Epoch 1333, Loss: 0.003571773508156184, Final Batch Loss: 0.0006268795114010572\n",
      "Epoch 1334, Loss: 0.0008582387090427801, Final Batch Loss: 0.00032527107396163046\n",
      "Epoch 1335, Loss: 0.0019080352067248896, Final Batch Loss: 0.0010511622531339526\n",
      "Epoch 1336, Loss: 0.001136098857386969, Final Batch Loss: 0.00031109058181755245\n",
      "Epoch 1337, Loss: 0.0005916441441513598, Final Batch Loss: 0.00022917304886505008\n",
      "Epoch 1338, Loss: 0.0017370692185068037, Final Batch Loss: 0.0002522261056583375\n",
      "Epoch 1339, Loss: 0.01875604088854743, Final Batch Loss: 0.000108678090327885\n",
      "Epoch 1340, Loss: 0.0020266062856535427, Final Batch Loss: 0.00043691834434866905\n",
      "Epoch 1341, Loss: 0.00280816359736491, Final Batch Loss: 9.102646436076611e-05\n",
      "Epoch 1342, Loss: 0.00421481451485306, Final Batch Loss: 0.0010284987511113286\n",
      "Epoch 1343, Loss: 0.001260290875507053, Final Batch Loss: 0.00011282296327408403\n",
      "Epoch 1344, Loss: 0.001857211216702126, Final Batch Loss: 0.00018864205048885196\n",
      "Epoch 1345, Loss: 0.00442536712216679, Final Batch Loss: 0.0034672801848500967\n",
      "Epoch 1346, Loss: 0.050610228418008774, Final Batch Loss: 2.79657087958185e-05\n",
      "Epoch 1347, Loss: 0.023994152506929822, Final Batch Loss: 0.0001556271017761901\n",
      "Epoch 1348, Loss: 0.022934297032406903, Final Batch Loss: 0.00039745745016261935\n",
      "Epoch 1349, Loss: 0.06534888251917437, Final Batch Loss: 0.0005251451511867344\n",
      "Epoch 1350, Loss: 0.013001475934288464, Final Batch Loss: 0.0003431914374232292\n",
      "Epoch 1351, Loss: 0.003338902344694361, Final Batch Loss: 0.0008125425665639341\n",
      "Epoch 1352, Loss: 0.0039410955214407295, Final Batch Loss: 0.000728906539734453\n",
      "Epoch 1353, Loss: 0.021131233253981918, Final Batch Loss: 0.00041601707926020026\n",
      "Epoch 1354, Loss: 0.01661168305145111, Final Batch Loss: 0.0001535168121336028\n",
      "Epoch 1355, Loss: 0.004590585100231692, Final Batch Loss: 7.95885716797784e-05\n",
      "Epoch 1356, Loss: 0.004285789676941931, Final Batch Loss: 0.0009616691386327147\n",
      "Epoch 1357, Loss: 0.004240502865286544, Final Batch Loss: 0.002586324932053685\n",
      "Epoch 1358, Loss: 0.00409409700660035, Final Batch Loss: 0.0012314155464991927\n",
      "Epoch 1359, Loss: 0.0018042368683381937, Final Batch Loss: 0.0004958958015777171\n",
      "Epoch 1360, Loss: 0.002683663842617534, Final Batch Loss: 0.0004389994137454778\n",
      "Epoch 1361, Loss: 0.0012500474695116282, Final Batch Loss: 0.00042152838432230055\n",
      "Epoch 1362, Loss: 0.003734632773557678, Final Batch Loss: 0.00036321088555268943\n",
      "Epoch 1363, Loss: 0.0012041390145896003, Final Batch Loss: 0.00020018908253405243\n",
      "Epoch 1364, Loss: 0.002533554368710611, Final Batch Loss: 0.0007702038274146616\n",
      "Epoch 1365, Loss: 0.003970774996560067, Final Batch Loss: 0.0005582608282566071\n",
      "Epoch 1366, Loss: 0.0016969975404208526, Final Batch Loss: 0.0008139254059642553\n",
      "Epoch 1367, Loss: 0.020354539155960083, Final Batch Loss: 0.0004090061702299863\n",
      "Epoch 1368, Loss: 0.010058940039016306, Final Batch Loss: 0.0005739224143326283\n",
      "Epoch 1369, Loss: 0.01713241549441591, Final Batch Loss: 0.013769326731562614\n",
      "Epoch 1370, Loss: 0.002225783042376861, Final Batch Loss: 0.001143008703365922\n",
      "Epoch 1371, Loss: 0.0387419048929587, Final Batch Loss: 0.0013414027635008097\n",
      "Epoch 1372, Loss: 0.008843496936606243, Final Batch Loss: 0.0006860743742436171\n",
      "Epoch 1373, Loss: 0.00342474746867083, Final Batch Loss: 0.000586276117246598\n",
      "Epoch 1374, Loss: 0.0017342225182801485, Final Batch Loss: 0.0001677442924119532\n",
      "Epoch 1375, Loss: 0.001545018472825177, Final Batch Loss: 0.0004913907032459974\n",
      "Epoch 1376, Loss: 0.006214348381035961, Final Batch Loss: 0.0018782042898237705\n",
      "Epoch 1377, Loss: 0.001639038324356079, Final Batch Loss: 0.0006167102255858481\n",
      "Epoch 1378, Loss: 0.005029575346270576, Final Batch Loss: 0.0024487765040248632\n",
      "Epoch 1379, Loss: 0.0011111402345704846, Final Batch Loss: 0.00025493730208836496\n",
      "Epoch 1380, Loss: 0.0023070850293152034, Final Batch Loss: 0.0005633760592900217\n",
      "Epoch 1381, Loss: 0.0010095709330926184, Final Batch Loss: 0.0004690850619226694\n",
      "Epoch 1382, Loss: 0.0024646423262311146, Final Batch Loss: 0.000117050702101551\n",
      "Epoch 1383, Loss: 0.005385601623856928, Final Batch Loss: 8.264992356998846e-05\n",
      "Epoch 1384, Loss: 0.00827266849228181, Final Batch Loss: 0.00011637124407570809\n",
      "Epoch 1385, Loss: 0.005258965102257207, Final Batch Loss: 0.0002779297938104719\n",
      "Epoch 1386, Loss: 0.0020702301990240812, Final Batch Loss: 0.0006192721193656325\n",
      "Epoch 1387, Loss: 0.0013527460760087706, Final Batch Loss: 0.0003861550067085773\n",
      "Epoch 1388, Loss: 0.02855700991494814, Final Batch Loss: 4.199035174679011e-05\n",
      "Epoch 1389, Loss: 0.06811640688829357, Final Batch Loss: 8.746927051106468e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1390, Loss: 0.013436804700177163, Final Batch Loss: 0.01097978837788105\n",
      "Epoch 1391, Loss: 0.003050027102290187, Final Batch Loss: 0.0013859363971278071\n",
      "Epoch 1392, Loss: 0.0022282334393821657, Final Batch Loss: 0.0002542296424508095\n",
      "Epoch 1393, Loss: 0.001108069802285172, Final Batch Loss: 0.0002897159429267049\n",
      "Epoch 1394, Loss: 0.0037159308849368244, Final Batch Loss: 0.001742093125358224\n",
      "Epoch 1395, Loss: 0.03342044296005042, Final Batch Loss: 0.0002646370849106461\n",
      "Epoch 1396, Loss: 0.024046301492489874, Final Batch Loss: 0.0010298938723281026\n",
      "Epoch 1397, Loss: 0.009048452440765686, Final Batch Loss: 0.002397223375737667\n",
      "Epoch 1398, Loss: 0.00489894297788851, Final Batch Loss: 0.00021118807489983737\n",
      "Epoch 1399, Loss: 0.004306506831198931, Final Batch Loss: 0.002952820621430874\n",
      "Epoch 1400, Loss: 0.006584100156032946, Final Batch Loss: 9.372886415803805e-05\n",
      "Epoch 1401, Loss: 0.0031316744862124324, Final Batch Loss: 7.07843282725662e-05\n",
      "Epoch 1402, Loss: 0.004600377869792283, Final Batch Loss: 0.00035103014670312405\n",
      "Epoch 1403, Loss: 0.0012450807553250343, Final Batch Loss: 0.0002727978571783751\n",
      "Epoch 1404, Loss: 0.0034696892835199833, Final Batch Loss: 0.0013574904296547174\n",
      "Epoch 1405, Loss: 0.002325884759557084, Final Batch Loss: 2.4263261366286315e-05\n",
      "Epoch 1406, Loss: 0.006741661054547876, Final Batch Loss: 0.0001111441379180178\n",
      "Epoch 1407, Loss: 0.0016245139049715362, Final Batch Loss: 0.00011296115553705022\n",
      "Epoch 1408, Loss: 0.002750418905634433, Final Batch Loss: 0.0004859375476371497\n",
      "Epoch 1409, Loss: 0.001667040298343636, Final Batch Loss: 0.00024225829110946506\n",
      "Epoch 1410, Loss: 0.002975167124532163, Final Batch Loss: 0.0006912574172019958\n",
      "Epoch 1411, Loss: 0.001549907319713384, Final Batch Loss: 0.0008744451915845275\n",
      "Epoch 1412, Loss: 0.019632894414826296, Final Batch Loss: 0.00047268698108382523\n",
      "Epoch 1413, Loss: 0.0018192294664913788, Final Batch Loss: 0.0004287144693080336\n",
      "Epoch 1414, Loss: 0.011870953181642108, Final Batch Loss: 0.00014905560237821192\n",
      "Epoch 1415, Loss: 0.0022193072509253398, Final Batch Loss: 0.0006013383390381932\n",
      "Epoch 1416, Loss: 0.008360004925634712, Final Batch Loss: 0.006385790649801493\n",
      "Epoch 1417, Loss: 0.0015749764352221973, Final Batch Loss: 7.9938537965063e-05\n",
      "Epoch 1418, Loss: 0.0013506400864571333, Final Batch Loss: 0.0007578601944260299\n",
      "Epoch 1419, Loss: 0.0038743774057365954, Final Batch Loss: 0.0003720398817677051\n",
      "Epoch 1420, Loss: 0.0065012790728360415, Final Batch Loss: 0.0001261664874618873\n",
      "Epoch 1421, Loss: 0.006120791789726354, Final Batch Loss: 0.002759958617389202\n",
      "Epoch 1422, Loss: 0.0010774289112305269, Final Batch Loss: 0.00016627331206109375\n",
      "Epoch 1423, Loss: 0.0007847526139812544, Final Batch Loss: 0.00021143392950762063\n",
      "Epoch 1424, Loss: 0.001523861676105298, Final Batch Loss: 0.00020989912445656955\n",
      "Epoch 1425, Loss: 0.0012509307998698205, Final Batch Loss: 0.00027556836721487343\n",
      "Epoch 1426, Loss: 0.0008215093657781836, Final Batch Loss: 0.00014429158181883395\n",
      "Epoch 1427, Loss: 0.002387282220297493, Final Batch Loss: 0.0005380619550123811\n",
      "Epoch 1428, Loss: 0.009020035970024765, Final Batch Loss: 0.008547000586986542\n",
      "Epoch 1429, Loss: 0.0012799730466213077, Final Batch Loss: 0.00010189755994360894\n",
      "Epoch 1430, Loss: 0.005446781215141527, Final Batch Loss: 0.0019308776827529073\n",
      "Epoch 1431, Loss: 0.0021182626369409263, Final Batch Loss: 0.0007995800697244704\n",
      "Epoch 1432, Loss: 0.0010254970256937668, Final Batch Loss: 6.767940067220479e-05\n",
      "Epoch 1433, Loss: 0.0010799153460538946, Final Batch Loss: 8.64890098455362e-05\n",
      "Epoch 1434, Loss: 0.016777577489847317, Final Batch Loss: 0.00011554968659766018\n",
      "Epoch 1435, Loss: 0.002203020667366218, Final Batch Loss: 0.0007751735392957926\n",
      "Epoch 1436, Loss: 0.0015841151580389123, Final Batch Loss: 4.981122401659377e-05\n",
      "Epoch 1437, Loss: 0.004412506314110942, Final Batch Loss: 0.0008879749220795929\n",
      "Epoch 1438, Loss: 0.005664045820594765, Final Batch Loss: 0.0035670048091560602\n",
      "Epoch 1439, Loss: 0.019346754801517818, Final Batch Loss: 6.631189171457663e-05\n",
      "Epoch 1440, Loss: 0.0011103902143076994, Final Batch Loss: 0.0007019471959210932\n",
      "Epoch 1441, Loss: 0.0023794157459633425, Final Batch Loss: 0.00010184063285123557\n",
      "Epoch 1442, Loss: 0.0014578251575585455, Final Batch Loss: 0.00042832057806663215\n",
      "Epoch 1443, Loss: 0.0019399720476940274, Final Batch Loss: 8.169533248292282e-05\n",
      "Epoch 1444, Loss: 0.002973019640194252, Final Batch Loss: 6.493566615972668e-05\n",
      "Epoch 1445, Loss: 0.0018403839494567364, Final Batch Loss: 4.683828592533246e-05\n",
      "Epoch 1446, Loss: 0.0049987638121820055, Final Batch Loss: 0.004093635361641645\n",
      "Epoch 1447, Loss: 0.0015014461532700807, Final Batch Loss: 0.00038170049083419144\n",
      "Epoch 1448, Loss: 0.005343623779481277, Final Batch Loss: 0.00029882084345445037\n",
      "Epoch 1449, Loss: 0.009450480341911316, Final Batch Loss: 0.005883213132619858\n",
      "Epoch 1450, Loss: 0.0035350807374925353, Final Batch Loss: 0.0018344235140830278\n",
      "Epoch 1451, Loss: 0.013039522455073893, Final Batch Loss: 0.0007244240259751678\n",
      "Epoch 1452, Loss: 0.0008177319396054372, Final Batch Loss: 0.00016187662549782544\n",
      "Epoch 1453, Loss: 0.0009665072320785839, Final Batch Loss: 0.00025609650765545666\n",
      "Epoch 1454, Loss: 0.000925273765460588, Final Batch Loss: 5.803673411719501e-05\n",
      "Epoch 1455, Loss: 0.0009243792519555427, Final Batch Loss: 0.00029445617110468447\n",
      "Epoch 1456, Loss: 0.0007937753143778536, Final Batch Loss: 5.279611286823638e-05\n",
      "Epoch 1457, Loss: 0.0017040385428117588, Final Batch Loss: 8.906745642889291e-05\n",
      "Epoch 1458, Loss: 0.008100029057459324, Final Batch Loss: 0.00019733583030756563\n",
      "Epoch 1459, Loss: 0.001394787188473856, Final Batch Loss: 5.362381853046827e-05\n",
      "Epoch 1460, Loss: 0.001699612766969949, Final Batch Loss: 0.00040618289494886994\n",
      "Epoch 1461, Loss: 0.017265228871110594, Final Batch Loss: 0.00013897819735575467\n",
      "Epoch 1462, Loss: 0.0014950124750612304, Final Batch Loss: 0.0006887851632200181\n",
      "Epoch 1463, Loss: 0.0034337217948632315, Final Batch Loss: 0.0001273436500923708\n",
      "Epoch 1464, Loss: 0.01892381441575708, Final Batch Loss: 0.002333038952201605\n",
      "Epoch 1465, Loss: 0.0005145405666553415, Final Batch Loss: 6.275626219576225e-05\n",
      "Epoch 1466, Loss: 0.0015061759295349475, Final Batch Loss: 6.088400914450176e-05\n",
      "Epoch 1467, Loss: 0.011288136753137223, Final Batch Loss: 0.010522437281906605\n",
      "Epoch 1468, Loss: 0.0008592720332671888, Final Batch Loss: 0.00021391910559032112\n",
      "Epoch 1469, Loss: 0.00087752215040382, Final Batch Loss: 0.0002570748620200902\n",
      "Epoch 1470, Loss: 0.006537382199894637, Final Batch Loss: 0.0011336118914186954\n",
      "Epoch 1471, Loss: 0.0007925621321192011, Final Batch Loss: 0.00042723381193354726\n",
      "Epoch 1472, Loss: 0.03563134571595583, Final Batch Loss: 0.0004768080252688378\n",
      "Epoch 1473, Loss: 0.014816514478297904, Final Batch Loss: 0.0003139213367830962\n",
      "Epoch 1474, Loss: 0.0038891963486094028, Final Batch Loss: 0.0012556565925478935\n",
      "Epoch 1475, Loss: 0.007789610885083675, Final Batch Loss: 0.0003043189353775233\n",
      "Epoch 1476, Loss: 0.008376185884117149, Final Batch Loss: 0.00018360289686825126\n",
      "Epoch 1477, Loss: 0.0025396253768121824, Final Batch Loss: 0.0007312134839594364\n",
      "Epoch 1478, Loss: 0.002477354064467363, Final Batch Loss: 0.0004856359155382961\n",
      "Epoch 1479, Loss: 0.003927368325093994, Final Batch Loss: 5.185629197512753e-05\n",
      "Epoch 1480, Loss: 0.0046213601672207005, Final Batch Loss: 6.713037873851135e-05\n",
      "Epoch 1481, Loss: 0.004791060913703404, Final Batch Loss: 0.0005332417204044759\n",
      "Epoch 1482, Loss: 0.001546088718896499, Final Batch Loss: 5.983591472613625e-05\n",
      "Epoch 1483, Loss: 0.0013826832873746753, Final Batch Loss: 9.823511936701834e-05\n",
      "Epoch 1484, Loss: 0.0020113355421926826, Final Batch Loss: 0.00023449238506145775\n",
      "Epoch 1485, Loss: 0.016240315717368503, Final Batch Loss: 1.7905842469190247e-05\n",
      "Epoch 1486, Loss: 0.0008996684991871007, Final Batch Loss: 0.00027320784283801913\n",
      "Epoch 1487, Loss: 0.0035773411218542606, Final Batch Loss: 0.0009484069305472076\n",
      "Epoch 1488, Loss: 0.0017130338528659195, Final Batch Loss: 9.029321518028155e-05\n",
      "Epoch 1489, Loss: 0.0032871178118512034, Final Batch Loss: 0.000288531300611794\n",
      "Epoch 1490, Loss: 0.0026729307282948866, Final Batch Loss: 0.00014282371557783335\n",
      "Epoch 1491, Loss: 0.01565877279790584, Final Batch Loss: 0.0032576164230704308\n",
      "Epoch 1492, Loss: 0.0009513749464531429, Final Batch Loss: 0.0002188432845287025\n",
      "Epoch 1493, Loss: 0.004381203863886185, Final Batch Loss: 0.0020637493580579758\n",
      "Epoch 1494, Loss: 0.0008957885111158248, Final Batch Loss: 5.057394810137339e-05\n",
      "Epoch 1495, Loss: 0.005150977820449043, Final Batch Loss: 0.004079832695424557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1496, Loss: 0.013188035678467713, Final Batch Loss: 0.01253246609121561\n",
      "Epoch 1497, Loss: 0.0037449504670803435, Final Batch Loss: 5.013679765397683e-05\n",
      "Epoch 1498, Loss: 0.006567679927684367, Final Batch Loss: 0.006083569023758173\n",
      "Epoch 1499, Loss: 0.010618296902975999, Final Batch Loss: 0.00012311995669733733\n",
      "Epoch 1500, Loss: 0.00033551422166056, Final Batch Loss: 8.423234976362437e-05\n",
      "Epoch 1501, Loss: 0.010328458127332851, Final Batch Loss: 0.00016100748325698078\n",
      "Epoch 1502, Loss: 0.010054127778857946, Final Batch Loss: 0.0008248306112363935\n",
      "Epoch 1503, Loss: 0.0018215555464848876, Final Batch Loss: 0.0004676769895013422\n",
      "Epoch 1504, Loss: 0.001536909447168, Final Batch Loss: 0.0002879348467104137\n",
      "Epoch 1505, Loss: 0.0012690030052908696, Final Batch Loss: 0.00035105625283904374\n",
      "Epoch 1506, Loss: 0.010014488427259494, Final Batch Loss: 4.6705055865459144e-05\n",
      "Epoch 1507, Loss: 0.003791790717514232, Final Batch Loss: 0.0003359833499416709\n",
      "Epoch 1508, Loss: 0.0019721935386769474, Final Batch Loss: 0.00029698156868107617\n",
      "Epoch 1509, Loss: 0.01790978440112667, Final Batch Loss: 0.00011473750782897696\n",
      "Epoch 1510, Loss: 0.000994164976873435, Final Batch Loss: 0.00042137273703701794\n",
      "Epoch 1511, Loss: 0.0013316198310349137, Final Batch Loss: 0.0003271695168223232\n",
      "Epoch 1512, Loss: 0.00278680058545433, Final Batch Loss: 0.0007324411417357624\n",
      "Epoch 1513, Loss: 0.002000075503019616, Final Batch Loss: 0.0004976832424290478\n",
      "Epoch 1514, Loss: 0.018551016342826188, Final Batch Loss: 0.003266772022470832\n",
      "Epoch 1515, Loss: 0.0005491461497513228, Final Batch Loss: 1.0792474313348066e-05\n",
      "Epoch 1516, Loss: 0.059681874234229326, Final Batch Loss: 0.059078529477119446\n",
      "Epoch 1517, Loss: 0.00223843110143207, Final Batch Loss: 0.00172065116930753\n",
      "Epoch 1518, Loss: 0.0014669580123154446, Final Batch Loss: 9.086698264582083e-05\n",
      "Epoch 1519, Loss: 0.0010914915619650856, Final Batch Loss: 3.871645458275452e-05\n",
      "Epoch 1520, Loss: 0.011869083534293168, Final Batch Loss: 1.1111374078609515e-05\n",
      "Epoch 1521, Loss: 0.0229014441210893, Final Batch Loss: 0.006681954953819513\n",
      "Epoch 1522, Loss: 0.0018681576439121272, Final Batch Loss: 3.6113426176598296e-05\n",
      "Epoch 1523, Loss: 0.00985809974372387, Final Batch Loss: 0.009340645745396614\n",
      "Epoch 1524, Loss: 0.0018526929488871247, Final Batch Loss: 0.00015429293853230774\n",
      "Epoch 1525, Loss: 0.008172123471013037, Final Batch Loss: 4.6485871280310676e-05\n",
      "Epoch 1526, Loss: 0.0032773378407000564, Final Batch Loss: 0.0026059430092573166\n",
      "Epoch 1527, Loss: 0.024967320714495145, Final Batch Loss: 0.00017796516476664692\n",
      "Epoch 1528, Loss: 0.005807372683193535, Final Batch Loss: 0.0014925035648047924\n",
      "Epoch 1529, Loss: 0.014883834344800562, Final Batch Loss: 0.0006390300113707781\n",
      "Epoch 1530, Loss: 0.011996649162028916, Final Batch Loss: 0.0002526343159843236\n",
      "Epoch 1531, Loss: 0.007704214222030714, Final Batch Loss: 0.00038399433833546937\n",
      "Epoch 1532, Loss: 0.008136450356687419, Final Batch Loss: 0.0002503986470401287\n",
      "Epoch 1533, Loss: 0.010050913260784, Final Batch Loss: 0.0002767600817605853\n",
      "Epoch 1534, Loss: 0.001167061724117957, Final Batch Loss: 6.394981755875051e-05\n",
      "Epoch 1535, Loss: 0.012813677778467536, Final Batch Loss: 0.007917419075965881\n",
      "Epoch 1536, Loss: 0.0014840678268228658, Final Batch Loss: 0.0002136149996658787\n",
      "Epoch 1537, Loss: 0.003952734696213156, Final Batch Loss: 0.00073866022285074\n",
      "Epoch 1538, Loss: 0.049685639096423984, Final Batch Loss: 0.0006800855044275522\n",
      "Epoch 1539, Loss: 0.001405675309797516, Final Batch Loss: 4.459750562091358e-05\n",
      "Epoch 1540, Loss: 0.00755444448441267, Final Batch Loss: 0.0008832248277030885\n",
      "Epoch 1541, Loss: 0.005206545873079449, Final Batch Loss: 0.0007931384025141597\n",
      "Epoch 1542, Loss: 0.01650699607853312, Final Batch Loss: 0.00010677498357836157\n",
      "Epoch 1543, Loss: 0.0034193334577139467, Final Batch Loss: 0.00013785494957119226\n",
      "Epoch 1544, Loss: 0.0162722120876424, Final Batch Loss: 0.006246498785912991\n",
      "Epoch 1545, Loss: 0.002144798942026682, Final Batch Loss: 0.00036471529165282845\n",
      "Epoch 1546, Loss: 0.0036073835799470544, Final Batch Loss: 0.0013468536781147122\n",
      "Epoch 1547, Loss: 0.0019225082942284644, Final Batch Loss: 0.00028421025490388274\n",
      "Epoch 1548, Loss: 0.0041678845445858315, Final Batch Loss: 0.0001909081038320437\n",
      "Epoch 1549, Loss: 0.0018035186367342249, Final Batch Loss: 0.0004530098813120276\n",
      "Epoch 1550, Loss: 0.0025473795394646004, Final Batch Loss: 0.0006793821230530739\n",
      "Epoch 1551, Loss: 0.002135184084181674, Final Batch Loss: 0.0005079468828625977\n",
      "Epoch 1552, Loss: 0.0019693921640282497, Final Batch Loss: 0.0007180583197623491\n",
      "Epoch 1553, Loss: 0.0011337585310684517, Final Batch Loss: 0.00028176780324429274\n",
      "Epoch 1554, Loss: 0.0026183304144069552, Final Batch Loss: 0.0018495055846869946\n",
      "Epoch 1555, Loss: 0.004255678915797034, Final Batch Loss: 5.9373753174440935e-05\n",
      "Epoch 1556, Loss: 0.0018203116196673363, Final Batch Loss: 0.001312512089498341\n",
      "Epoch 1557, Loss: 0.018907799358203192, Final Batch Loss: 0.00132839591242373\n",
      "Epoch 1558, Loss: 0.0019216907458030619, Final Batch Loss: 0.0002684656355995685\n",
      "Epoch 1559, Loss: 0.0030985230041551404, Final Batch Loss: 0.002000011969357729\n",
      "Epoch 1560, Loss: 0.0022923176147742197, Final Batch Loss: 0.0001469302223995328\n",
      "Epoch 1561, Loss: 0.0025078862163354643, Final Batch Loss: 0.00010602156544337049\n",
      "Epoch 1562, Loss: 0.0007398086745524779, Final Batch Loss: 0.00017881821258924901\n",
      "Epoch 1563, Loss: 0.0005173097088118084, Final Batch Loss: 9.555589349474758e-05\n",
      "Epoch 1564, Loss: 0.0024306847335537896, Final Batch Loss: 0.00022059351613279432\n",
      "Epoch 1565, Loss: 0.0007669414771953598, Final Batch Loss: 8.873673505149782e-05\n",
      "Epoch 1566, Loss: 0.0029736889991909266, Final Batch Loss: 0.0008222528849728405\n",
      "Epoch 1567, Loss: 0.0016148428549058735, Final Batch Loss: 0.000296425394481048\n",
      "Epoch 1568, Loss: 0.0018005676829488948, Final Batch Loss: 0.0003355692024342716\n",
      "Epoch 1569, Loss: 0.0010507132265047403, Final Batch Loss: 0.0003766625886783004\n",
      "Epoch 1570, Loss: 0.0010460298653924838, Final Batch Loss: 0.00016107836563605815\n",
      "Epoch 1571, Loss: 0.002173747516280855, Final Batch Loss: 1.7819735148805194e-05\n",
      "Epoch 1572, Loss: 0.0009427607947145589, Final Batch Loss: 0.00026468795840628445\n",
      "Epoch 1573, Loss: 0.0034735078406811226, Final Batch Loss: 0.0032137806992977858\n",
      "Epoch 1574, Loss: 0.0019343366848261212, Final Batch Loss: 1.1756496860471088e-05\n",
      "Epoch 1575, Loss: 0.001749175033182837, Final Batch Loss: 0.0010062322253361344\n",
      "Epoch 1576, Loss: 0.0007047861072351225, Final Batch Loss: 9.343360579805449e-05\n",
      "Epoch 1577, Loss: 0.0334597650798969, Final Batch Loss: 6.18194171693176e-05\n",
      "Epoch 1578, Loss: 0.0005640373055939563, Final Batch Loss: 0.0001405145594617352\n",
      "Epoch 1579, Loss: 0.0022898898969287984, Final Batch Loss: 0.00026622190489433706\n",
      "Epoch 1580, Loss: 0.001494692660344299, Final Batch Loss: 4.790590173797682e-05\n",
      "Epoch 1581, Loss: 0.011590055291890167, Final Batch Loss: 0.0003725968999788165\n",
      "Epoch 1582, Loss: 0.0010226836056972388, Final Batch Loss: 0.0006170325796119869\n",
      "Epoch 1583, Loss: 0.0015385306760435924, Final Batch Loss: 0.00013775291154161096\n",
      "Epoch 1584, Loss: 0.0004609287316270638, Final Batch Loss: 0.00017296084843110293\n",
      "Epoch 1585, Loss: 0.0024029656924540177, Final Batch Loss: 0.0017888247966766357\n",
      "Epoch 1586, Loss: 0.013379791256738827, Final Batch Loss: 0.0004948943387717009\n",
      "Epoch 1587, Loss: 0.00126861600074335, Final Batch Loss: 4.39587420260068e-05\n",
      "Epoch 1588, Loss: 0.000741487765480997, Final Batch Loss: 0.00012312810576986521\n",
      "Epoch 1589, Loss: 0.0015451508515980095, Final Batch Loss: 0.00036298626218922436\n",
      "Epoch 1590, Loss: 0.0013154332555131987, Final Batch Loss: 0.00040544228977523744\n",
      "Epoch 1591, Loss: 0.06732135843776632, Final Batch Loss: 5.569981294684112e-05\n",
      "Epoch 1592, Loss: 0.0017809877681429498, Final Batch Loss: 0.0008519014227204025\n",
      "Epoch 1593, Loss: 0.0008621910419606138, Final Batch Loss: 2.1883624867768958e-05\n",
      "Epoch 1594, Loss: 0.00524281296384288, Final Batch Loss: 0.002945606131106615\n",
      "Epoch 1595, Loss: 0.0018935448242700659, Final Batch Loss: 0.00011952627392020077\n",
      "Epoch 1596, Loss: 0.0020790836242667865, Final Batch Loss: 5.1661900215549394e-05\n",
      "Epoch 1597, Loss: 0.01150070654693991, Final Batch Loss: 0.000254712620517239\n",
      "Epoch 1598, Loss: 0.006991662632572115, Final Batch Loss: 0.004403062164783478\n",
      "Epoch 1599, Loss: 0.000908687341507175, Final Batch Loss: 2.8724623916787095e-05\n",
      "Epoch 1600, Loss: 0.007885266291850712, Final Batch Loss: 0.00038478896021842957\n",
      "Epoch 1601, Loss: 0.0014943864225642756, Final Batch Loss: 0.000718407507520169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1602, Loss: 0.0021863875299459323, Final Batch Loss: 0.0005081737181171775\n",
      "Epoch 1603, Loss: 0.006340371035548742, Final Batch Loss: 2.657435652508866e-05\n",
      "Epoch 1604, Loss: 0.0011437561661296058, Final Batch Loss: 3.311975524411537e-05\n",
      "Epoch 1605, Loss: 0.0011272172559984028, Final Batch Loss: 0.000147052007378079\n",
      "Epoch 1606, Loss: 0.0011529780294949887, Final Batch Loss: 7.710086356382817e-05\n",
      "Epoch 1607, Loss: 0.0019142158489557914, Final Batch Loss: 8.461594552500173e-05\n",
      "Epoch 1608, Loss: 0.043412513532530284, Final Batch Loss: 5.923371281824075e-05\n",
      "Epoch 1609, Loss: 0.0008045240901992656, Final Batch Loss: 3.6920246202498674e-05\n",
      "Epoch 1610, Loss: 0.0014073868296691217, Final Batch Loss: 0.0002718267496675253\n",
      "Epoch 1611, Loss: 0.0004790728671650868, Final Batch Loss: 0.0002420490636723116\n",
      "Epoch 1612, Loss: 0.03378436058119405, Final Batch Loss: 0.03266723453998566\n",
      "Epoch 1613, Loss: 0.005051450687460601, Final Batch Loss: 0.0028313607908785343\n",
      "Epoch 1614, Loss: 0.002442735254589934, Final Batch Loss: 0.0011446051066741347\n",
      "Epoch 1615, Loss: 0.0008025234019441996, Final Batch Loss: 0.0001554221089463681\n",
      "Epoch 1616, Loss: 0.00849930793447129, Final Batch Loss: 0.00012910395162180066\n",
      "Epoch 1617, Loss: 0.0008526443198206834, Final Batch Loss: 0.0001026168538373895\n",
      "Epoch 1618, Loss: 0.0008334478770848364, Final Batch Loss: 6.417534314095974e-05\n",
      "Epoch 1619, Loss: 0.011226160466321744, Final Batch Loss: 0.0003285622224211693\n",
      "Epoch 1620, Loss: 0.00546670587209519, Final Batch Loss: 0.00010732024384196848\n",
      "Epoch 1621, Loss: 0.02984095109786722, Final Batch Loss: 0.00011008937144652009\n",
      "Epoch 1622, Loss: 0.0021217930770944804, Final Batch Loss: 0.00012974461424164474\n",
      "Epoch 1623, Loss: 0.018178614613134414, Final Batch Loss: 0.0031093263532966375\n",
      "Epoch 1624, Loss: 0.02232723833003547, Final Batch Loss: 0.00016066980606410652\n",
      "Epoch 1625, Loss: 0.032800134242279455, Final Batch Loss: 0.031127819791436195\n",
      "Epoch 1626, Loss: 0.050570668710861355, Final Batch Loss: 0.00035320522147230804\n",
      "Epoch 1627, Loss: 0.0026083367556566373, Final Batch Loss: 0.00021434352674987167\n",
      "Epoch 1628, Loss: 0.010564977215835825, Final Batch Loss: 0.0008080072002485394\n",
      "Epoch 1629, Loss: 0.016729841037886217, Final Batch Loss: 0.007746093440800905\n",
      "Epoch 1630, Loss: 0.006109165900852531, Final Batch Loss: 0.00044857256580144167\n",
      "Epoch 1631, Loss: 0.012145435553975403, Final Batch Loss: 0.0016595169436186552\n",
      "Epoch 1632, Loss: 0.006982084829360247, Final Batch Loss: 0.00043177511543035507\n",
      "Epoch 1633, Loss: 0.019195290355128236, Final Batch Loss: 0.0006611287244595587\n",
      "Epoch 1634, Loss: 0.010431998292915523, Final Batch Loss: 0.009328806772828102\n",
      "Epoch 1635, Loss: 0.007635868532815948, Final Batch Loss: 0.0004719772841781378\n",
      "Epoch 1636, Loss: 0.00594029514468275, Final Batch Loss: 0.002942285966128111\n",
      "Epoch 1637, Loss: 0.007449603668646887, Final Batch Loss: 0.002217858098447323\n",
      "Epoch 1638, Loss: 0.002844412860213197, Final Batch Loss: 2.9634325983352028e-05\n",
      "Epoch 1639, Loss: 0.0012233820962137543, Final Batch Loss: 6.345540896290913e-05\n",
      "Epoch 1640, Loss: 0.0438115487631876, Final Batch Loss: 0.041900090873241425\n",
      "Epoch 1641, Loss: 0.0028396002198860515, Final Batch Loss: 0.0008699863683432341\n",
      "Epoch 1642, Loss: 0.0013755508334725164, Final Batch Loss: 7.466312672477216e-05\n",
      "Epoch 1643, Loss: 0.0016458664249512367, Final Batch Loss: 0.00011479648674139753\n",
      "Epoch 1644, Loss: 0.0014276523761509452, Final Batch Loss: 0.00033375181374140084\n",
      "Epoch 1645, Loss: 0.005869350512512028, Final Batch Loss: 0.0003827443579211831\n",
      "Epoch 1646, Loss: 0.011996025743428618, Final Batch Loss: 0.00013205302821006626\n",
      "Epoch 1647, Loss: 0.0024743535614106804, Final Batch Loss: 0.0003566297818906605\n",
      "Epoch 1648, Loss: 0.013086606049910188, Final Batch Loss: 0.0005232227267697453\n",
      "Epoch 1649, Loss: 0.0038100189121905714, Final Batch Loss: 0.0001477525511290878\n",
      "Epoch 1650, Loss: 0.001144537833170034, Final Batch Loss: 0.00028392148669809103\n",
      "Epoch 1651, Loss: 0.002632739342516288, Final Batch Loss: 0.0009682379895821214\n",
      "Epoch 1652, Loss: 0.0014992185751907527, Final Batch Loss: 0.0004010740958619863\n",
      "Epoch 1653, Loss: 0.017174200838780962, Final Batch Loss: 0.01501325611025095\n",
      "Epoch 1654, Loss: 0.002523410315916408, Final Batch Loss: 0.00010473206202732399\n",
      "Epoch 1655, Loss: 0.0022551871952600777, Final Batch Loss: 0.0004393824783619493\n",
      "Epoch 1656, Loss: 0.0019642944425868336, Final Batch Loss: 0.001105749630369246\n",
      "Epoch 1657, Loss: 0.0024682387411303353, Final Batch Loss: 4.12344052165281e-05\n",
      "Epoch 1658, Loss: 0.0013579779188148677, Final Batch Loss: 0.00021305303380358964\n",
      "Epoch 1659, Loss: 0.0009065583362826146, Final Batch Loss: 0.00010468732943991199\n",
      "Epoch 1660, Loss: 0.0017103751888498664, Final Batch Loss: 0.0003703644615598023\n",
      "Epoch 1661, Loss: 0.0027261789873591624, Final Batch Loss: 0.0009816819801926613\n",
      "Epoch 1662, Loss: 0.0009629350861359853, Final Batch Loss: 0.0004838098248001188\n",
      "Epoch 1663, Loss: 0.001347735698800534, Final Batch Loss: 0.00034429001971147954\n",
      "Epoch 1664, Loss: 0.001131350923969876, Final Batch Loss: 4.835123399971053e-05\n",
      "Epoch 1665, Loss: 0.0065423574997112155, Final Batch Loss: 0.00047187661402858794\n",
      "Epoch 1666, Loss: 0.0010237107053399086, Final Batch Loss: 0.0001443458313588053\n",
      "Epoch 1667, Loss: 0.004960378515534103, Final Batch Loss: 7.153494516387582e-05\n",
      "Epoch 1668, Loss: 0.0011297849196125753, Final Batch Loss: 0.00011825880937976763\n",
      "Epoch 1669, Loss: 0.0025662326079327613, Final Batch Loss: 0.0005512441275641322\n",
      "Epoch 1670, Loss: 0.0019111805158900097, Final Batch Loss: 0.0005315847811289132\n",
      "Epoch 1671, Loss: 0.020173810269625392, Final Batch Loss: 9.448266791878268e-05\n",
      "Epoch 1672, Loss: 0.0031834544788580388, Final Batch Loss: 0.0023258535657078028\n",
      "Epoch 1673, Loss: 0.026259896956617013, Final Batch Loss: 0.0004801139293704182\n",
      "Epoch 1674, Loss: 0.006692094262689352, Final Batch Loss: 0.0003935174026992172\n",
      "Epoch 1675, Loss: 0.0011871174938278273, Final Batch Loss: 0.00011219336010981351\n",
      "Epoch 1676, Loss: 0.03474642624496482, Final Batch Loss: 0.0003014901594724506\n",
      "Epoch 1677, Loss: 0.005592646586592309, Final Batch Loss: 0.004008935298770666\n",
      "Epoch 1678, Loss: 0.0022874662026879378, Final Batch Loss: 0.0001537200150778517\n",
      "Epoch 1679, Loss: 0.011038092779926956, Final Batch Loss: 0.0014096148079261184\n",
      "Epoch 1680, Loss: 0.024188966519432142, Final Batch Loss: 0.0014626557240262628\n",
      "Epoch 1681, Loss: 0.0011449262528913096, Final Batch Loss: 0.0005048839375376701\n",
      "Epoch 1682, Loss: 0.0016938036715146154, Final Batch Loss: 0.00021084569743834436\n",
      "Epoch 1683, Loss: 0.0020336834641057067, Final Batch Loss: 0.0005362447118386626\n",
      "Epoch 1684, Loss: 0.0008917401864891872, Final Batch Loss: 0.00020557164680212736\n",
      "Epoch 1685, Loss: 0.011694824905134737, Final Batch Loss: 0.006431317422538996\n",
      "Epoch 1686, Loss: 0.022967454024183098, Final Batch Loss: 0.021336613222956657\n",
      "Epoch 1687, Loss: 0.0014509371103486046, Final Batch Loss: 0.0003176046593580395\n",
      "Epoch 1688, Loss: 0.0015242321096593514, Final Batch Loss: 0.0001291944645345211\n",
      "Epoch 1689, Loss: 0.0023194871027953923, Final Batch Loss: 0.0010476199677214026\n",
      "Epoch 1690, Loss: 0.0026320852630306035, Final Batch Loss: 0.0005404989933595061\n",
      "Epoch 1691, Loss: 0.0024780308012850583, Final Batch Loss: 0.0003091895196121186\n",
      "Epoch 1692, Loss: 0.0024996684514917433, Final Batch Loss: 0.0014035175554454327\n",
      "Epoch 1693, Loss: 0.002935004624305293, Final Batch Loss: 0.0008268046658486128\n",
      "Epoch 1694, Loss: 0.0017583971057320014, Final Batch Loss: 0.0002869738091249019\n",
      "Epoch 1695, Loss: 0.02104919006524142, Final Batch Loss: 0.00027695175958797336\n",
      "Epoch 1696, Loss: 0.00248791350168176, Final Batch Loss: 0.0001609105966053903\n",
      "Epoch 1697, Loss: 0.0007879312615841627, Final Batch Loss: 0.0001374620624119416\n",
      "Epoch 1698, Loss: 0.005198853701585904, Final Batch Loss: 0.0022188585717231035\n",
      "Epoch 1699, Loss: 0.001410882396157831, Final Batch Loss: 0.0006471768137998879\n",
      "Epoch 1700, Loss: 0.01333474301645765, Final Batch Loss: 0.00016747138579376042\n",
      "Epoch 1701, Loss: 0.0007805351633578539, Final Batch Loss: 8.155657269526273e-05\n",
      "Epoch 1702, Loss: 0.0009827747962845024, Final Batch Loss: 0.000210625643376261\n",
      "Epoch 1703, Loss: 0.0008702879204065539, Final Batch Loss: 0.0005156644620001316\n",
      "Epoch 1704, Loss: 0.0017445070843677968, Final Batch Loss: 0.0001285076723434031\n",
      "Epoch 1705, Loss: 0.0014372913683473598, Final Batch Loss: 5.2559695177478716e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1706, Loss: 0.0018098048967658542, Final Batch Loss: 8.788261038716882e-05\n",
      "Epoch 1707, Loss: 0.00274211801297497, Final Batch Loss: 0.0001447715621907264\n",
      "Epoch 1708, Loss: 0.0029337249870877713, Final Batch Loss: 0.0003372856881469488\n",
      "Epoch 1709, Loss: 0.0017039754129655194, Final Batch Loss: 0.00048406203859485686\n",
      "Epoch 1710, Loss: 0.0021189590479480103, Final Batch Loss: 0.00014179341087583452\n",
      "Epoch 1711, Loss: 0.0005609219770121854, Final Batch Loss: 0.0003092616389039904\n",
      "Epoch 1712, Loss: 0.001215510186739266, Final Batch Loss: 0.0001504363026469946\n",
      "Epoch 1713, Loss: 0.0014163931627990678, Final Batch Loss: 0.0006900963489897549\n",
      "Epoch 1714, Loss: 0.0008701660408405587, Final Batch Loss: 0.0003076854918617755\n",
      "Epoch 1715, Loss: 0.00162768000154756, Final Batch Loss: 0.0002520382113289088\n",
      "Epoch 1716, Loss: 0.0010378823762948741, Final Batch Loss: 0.0003110396210104227\n",
      "Epoch 1717, Loss: 0.0016214255738304928, Final Batch Loss: 0.0010428467066958547\n",
      "Epoch 1718, Loss: 0.0006459979667852167, Final Batch Loss: 4.723267556983046e-05\n",
      "Epoch 1719, Loss: 0.007033149780909298, Final Batch Loss: 4.8280253395205364e-05\n",
      "Epoch 1720, Loss: 0.0014482961341855116, Final Batch Loss: 0.0008706041844561696\n",
      "Epoch 1721, Loss: 0.0009118750895140693, Final Batch Loss: 0.00014037874643690884\n",
      "Epoch 1722, Loss: 0.0017797239997889847, Final Batch Loss: 0.0003059947048313916\n",
      "Epoch 1723, Loss: 0.0007989364767126972, Final Batch Loss: 2.4958464564406313e-05\n",
      "Epoch 1724, Loss: 0.0021446501414175145, Final Batch Loss: 0.0011387926060706377\n",
      "Epoch 1725, Loss: 0.005248515139101073, Final Batch Loss: 0.0009694964974187315\n",
      "Epoch 1726, Loss: 0.0006812110550526995, Final Batch Loss: 0.000267089024418965\n",
      "Epoch 1727, Loss: 0.004005933740700129, Final Batch Loss: 0.00032318945159204304\n",
      "Epoch 1728, Loss: 0.001339394111710135, Final Batch Loss: 0.00022812304086983204\n",
      "Epoch 1729, Loss: 0.0007492838121834211, Final Batch Loss: 0.00014585234748665243\n",
      "Epoch 1730, Loss: 0.0004721188288385747, Final Batch Loss: 0.00021585379727184772\n",
      "Epoch 1731, Loss: 0.0023339193721767515, Final Batch Loss: 6.0918391682207584e-05\n",
      "Epoch 1732, Loss: 0.000875201618327992, Final Batch Loss: 3.959521200158633e-05\n",
      "Epoch 1733, Loss: 0.0018610696424730122, Final Batch Loss: 0.00020825298270210624\n",
      "Epoch 1734, Loss: 0.02490210984251462, Final Batch Loss: 0.0002918736427091062\n",
      "Epoch 1735, Loss: 0.000513758266606601, Final Batch Loss: 2.429412052151747e-05\n",
      "Epoch 1736, Loss: 0.0019768608326558024, Final Batch Loss: 9.130973921855912e-05\n",
      "Epoch 1737, Loss: 0.0035329321763128974, Final Batch Loss: 0.0003595030284486711\n",
      "Epoch 1738, Loss: 0.000430268220952712, Final Batch Loss: 4.719925345852971e-05\n",
      "Epoch 1739, Loss: 0.0009500162705080584, Final Batch Loss: 0.0002587889030110091\n",
      "Epoch 1740, Loss: 0.0013606872817035764, Final Batch Loss: 0.0002171591913793236\n",
      "Epoch 1741, Loss: 0.0005672525385307381, Final Batch Loss: 1.8555636415840127e-05\n",
      "Epoch 1742, Loss: 0.0006688198500341969, Final Batch Loss: 8.011791578610428e-06\n",
      "Epoch 1743, Loss: 0.0014845442346995696, Final Batch Loss: 0.0001503032399341464\n",
      "Epoch 1744, Loss: 0.0012755593706970103, Final Batch Loss: 0.0005919252289459109\n",
      "Epoch 1745, Loss: 0.0009683804382802919, Final Batch Loss: 7.719494169577956e-05\n",
      "Epoch 1746, Loss: 0.012145820335717872, Final Batch Loss: 0.0004883847432211041\n",
      "Epoch 1747, Loss: 0.004812577491975389, Final Batch Loss: 0.0040846834890544415\n",
      "Epoch 1748, Loss: 0.03359644694501185, Final Batch Loss: 4.300405635149218e-05\n",
      "Epoch 1749, Loss: 0.0008455125571344979, Final Batch Loss: 8.799044735496864e-05\n",
      "Epoch 1750, Loss: 0.0008228761798818596, Final Batch Loss: 0.00018863222794607282\n",
      "Epoch 1751, Loss: 0.008671700692502782, Final Batch Loss: 0.00036764430114999413\n",
      "Epoch 1752, Loss: 0.010485571587196318, Final Batch Loss: 0.009948920458555222\n",
      "Epoch 1753, Loss: 0.006517381458252203, Final Batch Loss: 0.0036758496426045895\n",
      "Epoch 1754, Loss: 0.001668601224082522, Final Batch Loss: 6.176877650432289e-05\n",
      "Epoch 1755, Loss: 0.001984594488021685, Final Batch Loss: 5.8584584621712565e-05\n",
      "Epoch 1756, Loss: 0.0018308415601495653, Final Batch Loss: 0.0005470811738632619\n",
      "Epoch 1757, Loss: 0.0015427567341248505, Final Batch Loss: 0.0010773971443995833\n",
      "Epoch 1758, Loss: 0.004843231741688214, Final Batch Loss: 0.00017927617591340095\n",
      "Epoch 1759, Loss: 0.0006664694374194369, Final Batch Loss: 0.00031410172232426703\n",
      "Epoch 1760, Loss: 0.0015311354582081549, Final Batch Loss: 0.0003151573764625937\n",
      "Epoch 1761, Loss: 0.0010693963777157478, Final Batch Loss: 0.00011312915739836171\n",
      "Epoch 1762, Loss: 0.00843872239056509, Final Batch Loss: 0.0007670483901165426\n",
      "Epoch 1763, Loss: 0.0068486524069157895, Final Batch Loss: 3.912937609129585e-05\n",
      "Epoch 1764, Loss: 0.001126685572671704, Final Batch Loss: 0.0007810575189068913\n",
      "Epoch 1765, Loss: 0.0004245072777848691, Final Batch Loss: 4.918371996609494e-05\n",
      "Epoch 1766, Loss: 0.0016013206150091719, Final Batch Loss: 0.0008423394174315035\n",
      "Epoch 1767, Loss: 0.001498245823313482, Final Batch Loss: 9.829882765188813e-05\n",
      "Epoch 1768, Loss: 0.0011561740466277115, Final Batch Loss: 0.00045367106213234365\n",
      "Epoch 1769, Loss: 0.0009528396021778462, Final Batch Loss: 0.00022763166634831578\n",
      "Epoch 1770, Loss: 0.0040051055839285254, Final Batch Loss: 0.001006998703815043\n",
      "Epoch 1771, Loss: 0.0013118059723637998, Final Batch Loss: 0.00041576233343221247\n",
      "Epoch 1772, Loss: 0.0030703132215421647, Final Batch Loss: 0.002108019543811679\n",
      "Epoch 1773, Loss: 0.012635145940294024, Final Batch Loss: 6.328659947030246e-05\n",
      "Epoch 1774, Loss: 0.01251767305075191, Final Batch Loss: 0.00041800583130680025\n",
      "Epoch 1775, Loss: 0.0013952014815004077, Final Batch Loss: 8.443849219474941e-05\n",
      "Epoch 1776, Loss: 0.0036714995512738824, Final Batch Loss: 0.00026704033371061087\n",
      "Epoch 1777, Loss: 0.0037119119806447998, Final Batch Loss: 0.0005867742584086955\n",
      "Epoch 1778, Loss: 0.003246374544687569, Final Batch Loss: 0.00134621886536479\n",
      "Epoch 1779, Loss: 0.0017877111822599545, Final Batch Loss: 0.0005403748364187777\n",
      "Epoch 1780, Loss: 0.0008501591873937286, Final Batch Loss: 0.00037184334360063076\n",
      "Epoch 1781, Loss: 0.0013273672084324062, Final Batch Loss: 0.0008418497745878994\n",
      "Epoch 1782, Loss: 0.0009356667214888148, Final Batch Loss: 8.159940625773743e-05\n",
      "Epoch 1783, Loss: 0.0012288286379771307, Final Batch Loss: 0.00035344428033567965\n",
      "Epoch 1784, Loss: 0.0010928645206149668, Final Batch Loss: 0.000359785626642406\n",
      "Epoch 1785, Loss: 0.0003818873010459356, Final Batch Loss: 0.00010640738037182018\n",
      "Epoch 1786, Loss: 0.0008711524969839957, Final Batch Loss: 3.780626502702944e-05\n",
      "Epoch 1787, Loss: 0.00023117506498238072, Final Batch Loss: 2.532700455049053e-05\n",
      "Epoch 1788, Loss: 0.010796212372952141, Final Batch Loss: 0.00013533853052649647\n",
      "Epoch 1789, Loss: 0.09439794464560691, Final Batch Loss: 0.08768350630998611\n",
      "Epoch 1790, Loss: 0.0013509355194400996, Final Batch Loss: 0.0005095655214972794\n",
      "Epoch 1791, Loss: 0.002422332872811239, Final Batch Loss: 7.599477248732e-05\n",
      "Epoch 1792, Loss: 0.005910713545745239, Final Batch Loss: 0.003225532593205571\n",
      "Epoch 1793, Loss: 0.01366373524069786, Final Batch Loss: 0.0008991502108983696\n",
      "Epoch 1794, Loss: 0.0030250915224314667, Final Batch Loss: 0.0003782846324611455\n",
      "Epoch 1795, Loss: 0.012570100429002196, Final Batch Loss: 0.00014791981084272265\n",
      "Epoch 1796, Loss: 0.0008571131984353997, Final Batch Loss: 0.0005389666766859591\n",
      "Epoch 1797, Loss: 0.0013705026103707496, Final Batch Loss: 0.0002784157986752689\n",
      "Epoch 1798, Loss: 0.0024764364679867867, Final Batch Loss: 0.0005569548229686916\n",
      "Epoch 1799, Loss: 0.02929228551511187, Final Batch Loss: 0.00012569401587825269\n",
      "Epoch 1800, Loss: 0.012638600615900941, Final Batch Loss: 0.0001335356937488541\n",
      "Epoch 1801, Loss: 0.00163289783813525, Final Batch Loss: 0.00015327474102377892\n",
      "Epoch 1802, Loss: 0.008785287471255288, Final Batch Loss: 0.0021894166711717844\n",
      "Epoch 1803, Loss: 0.0018018926930380985, Final Batch Loss: 0.0008354564197361469\n",
      "Epoch 1804, Loss: 0.0027260384522378445, Final Batch Loss: 0.00021790935716126114\n",
      "Epoch 1805, Loss: 0.030917615673388354, Final Batch Loss: 0.00026266914210282266\n",
      "Epoch 1806, Loss: 0.0032689859144738875, Final Batch Loss: 0.002377936150878668\n",
      "Epoch 1807, Loss: 0.023838903580326587, Final Batch Loss: 0.0006888174102641642\n",
      "Epoch 1808, Loss: 0.016898011846933514, Final Batch Loss: 0.006307499948889017\n",
      "Epoch 1809, Loss: 0.002487883270077873, Final Batch Loss: 9.601593774277717e-05\n",
      "Epoch 1810, Loss: 0.0022832617396488786, Final Batch Loss: 2.4669345293659717e-05\n",
      "Epoch 1811, Loss: 0.0012538782430056017, Final Batch Loss: 7.834644929971546e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1812, Loss: 0.002701171917578904, Final Batch Loss: 4.23583660449367e-05\n",
      "Epoch 1813, Loss: 0.04252917772100773, Final Batch Loss: 0.0402812659740448\n",
      "Epoch 1814, Loss: 0.020451711432542652, Final Batch Loss: 0.0004644949804060161\n",
      "Epoch 1815, Loss: 0.004815291249542497, Final Batch Loss: 0.0009113958803936839\n",
      "Epoch 1816, Loss: 0.00250452860200312, Final Batch Loss: 0.00035331942490302026\n",
      "Epoch 1817, Loss: 0.014488520835584495, Final Batch Loss: 0.012622633948922157\n",
      "Epoch 1818, Loss: 0.0043402086303103715, Final Batch Loss: 0.0003061076276935637\n",
      "Epoch 1819, Loss: 0.0010971230149152689, Final Batch Loss: 0.000181163486558944\n",
      "Epoch 1820, Loss: 0.0022784380125813186, Final Batch Loss: 0.00012960795720573515\n",
      "Epoch 1821, Loss: 0.014101579479756765, Final Batch Loss: 0.00034621707163751125\n",
      "Epoch 1822, Loss: 0.03392732123029418, Final Batch Loss: 0.03285996615886688\n",
      "Epoch 1823, Loss: 0.003085706048295833, Final Batch Loss: 0.0018539675511419773\n",
      "Epoch 1824, Loss: 0.004911557509331033, Final Batch Loss: 0.004115383606404066\n",
      "Epoch 1825, Loss: 0.002758264890871942, Final Batch Loss: 0.0008478557574562728\n",
      "Epoch 1826, Loss: 0.008879260501998942, Final Batch Loss: 9.534288983559236e-05\n",
      "Epoch 1827, Loss: 0.0023037185601424426, Final Batch Loss: 0.00022727080795448273\n",
      "Epoch 1828, Loss: 0.0010102426240337081, Final Batch Loss: 0.00011874868505401537\n",
      "Epoch 1829, Loss: 0.002281275432324037, Final Batch Loss: 0.00040990213165059686\n",
      "Epoch 1830, Loss: 0.0005872066285519395, Final Batch Loss: 4.523768075159751e-05\n",
      "Epoch 1831, Loss: 0.003827140462817624, Final Batch Loss: 0.0017320397309958935\n",
      "Epoch 1832, Loss: 0.0015723152755526826, Final Batch Loss: 0.0005434944177977741\n",
      "Epoch 1833, Loss: 0.0006974558273213916, Final Batch Loss: 0.00018423162691760808\n",
      "Epoch 1834, Loss: 0.0007442355672537815, Final Batch Loss: 0.00028121357900090516\n",
      "Epoch 1835, Loss: 0.002782560040941462, Final Batch Loss: 0.00034263203269802034\n",
      "Epoch 1836, Loss: 0.0031139043167058844, Final Batch Loss: 0.0001273903762921691\n",
      "Epoch 1837, Loss: 0.0004883481706201565, Final Batch Loss: 0.00018099453882314265\n",
      "Epoch 1838, Loss: 0.0023345475128735416, Final Batch Loss: 0.0004512137093115598\n",
      "Epoch 1839, Loss: 0.010492428511497565, Final Batch Loss: 0.009693000465631485\n",
      "Epoch 1840, Loss: 0.0009001978687592782, Final Batch Loss: 2.9352529963944107e-05\n",
      "Epoch 1841, Loss: 0.0010089254938066006, Final Batch Loss: 0.00033776022610254586\n",
      "Epoch 1842, Loss: 0.0020471242860367056, Final Batch Loss: 5.102646900922991e-05\n",
      "Epoch 1843, Loss: 0.011780693443142809, Final Batch Loss: 6.124693027231842e-05\n",
      "Epoch 1844, Loss: 0.001353456304059364, Final Batch Loss: 0.00033728519338183105\n",
      "Epoch 1845, Loss: 0.0017978036630665883, Final Batch Loss: 0.0007033044239506125\n",
      "Epoch 1846, Loss: 0.0005965955278952606, Final Batch Loss: 0.0001822117337724194\n",
      "Epoch 1847, Loss: 0.018444533794536255, Final Batch Loss: 0.0002657316217664629\n",
      "Epoch 1848, Loss: 0.0011878922705363948, Final Batch Loss: 3.754620047402568e-05\n",
      "Epoch 1849, Loss: 0.014189864235959249, Final Batch Loss: 5.220184175414033e-05\n",
      "Epoch 1850, Loss: 0.01859464948938694, Final Batch Loss: 7.482192449970171e-05\n",
      "Epoch 1851, Loss: 0.0014961381166358478, Final Batch Loss: 0.00010371492680860683\n",
      "Epoch 1852, Loss: 0.0024612448760308325, Final Batch Loss: 0.0001538637443445623\n",
      "Epoch 1853, Loss: 0.0025553684718033765, Final Batch Loss: 0.002032484160736203\n",
      "Epoch 1854, Loss: 0.001889405211841222, Final Batch Loss: 0.0008836527704261243\n",
      "Epoch 1855, Loss: 0.0011428886791691184, Final Batch Loss: 0.00012559538299683481\n",
      "Epoch 1856, Loss: 0.024585962702985853, Final Batch Loss: 0.00012353432248346508\n",
      "Epoch 1857, Loss: 0.00193243553803768, Final Batch Loss: 0.001199856516905129\n",
      "Epoch 1858, Loss: 0.00934048552880995, Final Batch Loss: 1.1862535757245496e-05\n",
      "Epoch 1859, Loss: 0.00456644018413499, Final Batch Loss: 0.0001472212461521849\n",
      "Epoch 1860, Loss: 0.016124787522130646, Final Batch Loss: 0.00019362446619197726\n",
      "Epoch 1861, Loss: 0.012726639019092545, Final Batch Loss: 0.008634406141936779\n",
      "Epoch 1862, Loss: 0.02597279939800501, Final Batch Loss: 0.025426508858799934\n",
      "Epoch 1863, Loss: 0.001253442444067332, Final Batch Loss: 0.0006515237037092447\n",
      "Epoch 1864, Loss: 0.0027121215098304674, Final Batch Loss: 0.0002218783338321373\n",
      "Epoch 1865, Loss: 0.0021072398812975734, Final Batch Loss: 0.0007131511811167002\n",
      "Epoch 1866, Loss: 0.006731181871145964, Final Batch Loss: 0.0001428290270268917\n",
      "Epoch 1867, Loss: 0.0017536437881062739, Final Batch Loss: 0.00035470654256641865\n",
      "Epoch 1868, Loss: 0.004623255892511224, Final Batch Loss: 0.00011138310946989805\n",
      "Epoch 1869, Loss: 0.0025112873991020024, Final Batch Loss: 0.0013408656232059002\n",
      "Epoch 1870, Loss: 0.0007477009494323283, Final Batch Loss: 0.00012822668941225857\n",
      "Epoch 1871, Loss: 0.003325977821077686, Final Batch Loss: 0.0014522615820169449\n",
      "Epoch 1872, Loss: 0.003132454978185706, Final Batch Loss: 9.998164023272693e-05\n",
      "Epoch 1873, Loss: 0.0017932577466126531, Final Batch Loss: 0.00012808862084057182\n",
      "Epoch 1874, Loss: 0.00041061271804210264, Final Batch Loss: 2.3511218387284316e-05\n",
      "Epoch 1875, Loss: 0.011264497756201308, Final Batch Loss: 0.00030826046713627875\n",
      "Epoch 1876, Loss: 0.0016389768497901969, Final Batch Loss: 5.237223376752809e-05\n",
      "Epoch 1877, Loss: 0.0024147207805071957, Final Batch Loss: 0.00028830787050537765\n",
      "Epoch 1878, Loss: 0.0011861206876346841, Final Batch Loss: 6.508479418698698e-05\n",
      "Epoch 1879, Loss: 0.001595437148353085, Final Batch Loss: 0.00028060449403710663\n",
      "Epoch 1880, Loss: 0.00043246291534160264, Final Batch Loss: 6.496921560028568e-05\n",
      "Epoch 1881, Loss: 0.002552894960899721, Final Batch Loss: 0.00042236820445396006\n",
      "Epoch 1882, Loss: 0.0011875740965479054, Final Batch Loss: 3.93897935282439e-05\n",
      "Epoch 1883, Loss: 0.0010720515565481037, Final Batch Loss: 6.524648779304698e-05\n",
      "Epoch 1884, Loss: 0.0005712944694096223, Final Batch Loss: 0.0001406380906701088\n",
      "Epoch 1885, Loss: 0.003781756735406816, Final Batch Loss: 0.002299836603924632\n",
      "Epoch 1886, Loss: 0.0008029688215174247, Final Batch Loss: 6.489491352112964e-05\n",
      "Epoch 1887, Loss: 0.0017185035758302547, Final Batch Loss: 0.00013401235628407449\n",
      "Epoch 1888, Loss: 0.00046865356580383377, Final Batch Loss: 7.163966074585915e-05\n",
      "Epoch 1889, Loss: 0.0021389461326180026, Final Batch Loss: 0.00010265412856824696\n",
      "Epoch 1890, Loss: 0.003173911405610852, Final Batch Loss: 0.0020627921912819147\n",
      "Epoch 1891, Loss: 0.001276878931093961, Final Batch Loss: 0.0002542552538216114\n",
      "Epoch 1892, Loss: 0.0009161630114249419, Final Batch Loss: 4.329172588768415e-05\n",
      "Epoch 1893, Loss: 0.0013717432511839434, Final Batch Loss: 1.2072595382051077e-05\n",
      "Epoch 1894, Loss: 0.0010288857884006575, Final Batch Loss: 0.0006041574524715543\n",
      "Epoch 1895, Loss: 0.0007667422760277987, Final Batch Loss: 0.00024361767282243818\n",
      "Epoch 1896, Loss: 0.002781161811981292, Final Batch Loss: 9.807495189306792e-06\n",
      "Epoch 1897, Loss: 0.03122669617368956, Final Batch Loss: 4.9382633733330294e-05\n",
      "Epoch 1898, Loss: 0.0007751186167297419, Final Batch Loss: 0.00020314600260462612\n",
      "Epoch 1899, Loss: 0.000756341189116938, Final Batch Loss: 0.00027180660981684923\n",
      "Epoch 1900, Loss: 0.0006465993224082922, Final Batch Loss: 9.840031270869076e-05\n",
      "Epoch 1901, Loss: 0.0008447437539871316, Final Batch Loss: 3.894972542184405e-05\n",
      "Epoch 1902, Loss: 0.0004227076206007041, Final Batch Loss: 0.00013124255929142237\n",
      "Epoch 1903, Loss: 0.01003649224549008, Final Batch Loss: 1.7275006030104123e-05\n",
      "Epoch 1904, Loss: 0.0008201416603696998, Final Batch Loss: 2.1581277906079777e-05\n",
      "Epoch 1905, Loss: 0.0014644662078353576, Final Batch Loss: 0.0007074017776176333\n",
      "Epoch 1906, Loss: 0.002574188692960888, Final Batch Loss: 0.00020566757302731276\n",
      "Epoch 1907, Loss: 0.0013657114177476615, Final Batch Loss: 0.0007202480337582529\n",
      "Epoch 1908, Loss: 0.0006933972726983484, Final Batch Loss: 0.00045591560774482787\n",
      "Epoch 1909, Loss: 0.0008759117117733695, Final Batch Loss: 0.0004976671771146357\n",
      "Epoch 1910, Loss: 0.0005347389815142378, Final Batch Loss: 0.0002427909494144842\n",
      "Epoch 1911, Loss: 0.00032337642915081233, Final Batch Loss: 7.321584416786209e-05\n",
      "Epoch 1912, Loss: 0.0007772928365739062, Final Batch Loss: 0.0003404047747608274\n",
      "Epoch 1913, Loss: 0.0053559776170004625, Final Batch Loss: 0.00449811527505517\n",
      "Epoch 1914, Loss: 0.0017360325218760408, Final Batch Loss: 0.00011751207057386637\n",
      "Epoch 1915, Loss: 0.00042346810732851736, Final Batch Loss: 0.00021014217054471374\n",
      "Epoch 1916, Loss: 0.00036928787267243024, Final Batch Loss: 0.0002246298099635169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1917, Loss: 0.001564073230838403, Final Batch Loss: 0.00031845620833337307\n",
      "Epoch 1918, Loss: 0.00048061161032819655, Final Batch Loss: 1.5201918358798139e-05\n",
      "Epoch 1919, Loss: 0.0008786130783846602, Final Batch Loss: 0.00030252704164013267\n",
      "Epoch 1920, Loss: 0.024887815547117498, Final Batch Loss: 0.0023208479396998882\n",
      "Epoch 1921, Loss: 0.0077412012815329945, Final Batch Loss: 0.0001722353626973927\n",
      "Epoch 1922, Loss: 0.01004494008157053, Final Batch Loss: 0.009744838811457157\n",
      "Epoch 1923, Loss: 0.0019175136112608016, Final Batch Loss: 0.001410465920343995\n",
      "Epoch 1924, Loss: 0.014469928577454994, Final Batch Loss: 8.07597316452302e-05\n",
      "Epoch 1925, Loss: 0.016604998672846705, Final Batch Loss: 0.015868891030550003\n",
      "Epoch 1926, Loss: 0.007658742557396181, Final Batch Loss: 0.0006788294995203614\n",
      "Epoch 1927, Loss: 0.009678059184807353, Final Batch Loss: 0.009187046438455582\n",
      "Epoch 1928, Loss: 0.008974156371550635, Final Batch Loss: 0.006151323672384024\n",
      "Epoch 1929, Loss: 0.002238960201793816, Final Batch Loss: 9.196934115607291e-05\n",
      "Epoch 1930, Loss: 0.0011845115186588373, Final Batch Loss: 4.943730527884327e-05\n",
      "Epoch 1931, Loss: 0.010853276849957183, Final Batch Loss: 0.002121421042829752\n",
      "Epoch 1932, Loss: 0.0015948853688314557, Final Batch Loss: 0.0001987576688406989\n",
      "Epoch 1933, Loss: 0.0021318384242476895, Final Batch Loss: 0.0009387153550051153\n",
      "Epoch 1934, Loss: 0.0005972708313493058, Final Batch Loss: 0.00012873068044427782\n",
      "Epoch 1935, Loss: 0.0012169485780759715, Final Batch Loss: 0.00021784902492072433\n",
      "Epoch 1936, Loss: 0.007997975087164377, Final Batch Loss: 0.0070917136035859585\n",
      "Epoch 1937, Loss: 0.0030025967134861276, Final Batch Loss: 0.00021898737759329379\n",
      "Epoch 1938, Loss: 0.0038167837847140618, Final Batch Loss: 0.0007433792343363166\n",
      "Epoch 1939, Loss: 0.018110850971424952, Final Batch Loss: 0.002628065412864089\n",
      "Epoch 1940, Loss: 0.001424170292011695, Final Batch Loss: 0.000182973628398031\n",
      "Epoch 1941, Loss: 0.0010233694065391319, Final Batch Loss: 0.000290385854896158\n",
      "Epoch 1942, Loss: 0.0013492307807609905, Final Batch Loss: 3.344026845297776e-05\n",
      "Epoch 1943, Loss: 0.0022269882829277776, Final Batch Loss: 0.0006824593292549253\n",
      "Epoch 1944, Loss: 0.019044179470256495, Final Batch Loss: 0.00022954044106882066\n",
      "Epoch 1945, Loss: 0.001026489888317883, Final Batch Loss: 3.831235517282039e-05\n",
      "Epoch 1946, Loss: 0.0010327837590011768, Final Batch Loss: 0.000126862563774921\n",
      "Epoch 1947, Loss: 0.002776040098979138, Final Batch Loss: 0.0001366339420201257\n",
      "Epoch 1948, Loss: 0.0008478412419208325, Final Batch Loss: 0.0001179556202259846\n",
      "Epoch 1949, Loss: 0.003845088700472843, Final Batch Loss: 0.002344429725781083\n",
      "Epoch 1950, Loss: 0.002125895829522051, Final Batch Loss: 9.550436516292393e-05\n",
      "Epoch 1951, Loss: 0.0015985379432095215, Final Batch Loss: 0.00016053131548687816\n",
      "Epoch 1952, Loss: 0.0009943105396814644, Final Batch Loss: 0.00024032666988205165\n",
      "Epoch 1953, Loss: 0.0008144377170538064, Final Batch Loss: 0.00013864842185284942\n",
      "Epoch 1954, Loss: 0.0013223915666458197, Final Batch Loss: 0.00016364567272830755\n",
      "Epoch 1955, Loss: 0.0006386841705534607, Final Batch Loss: 0.00014326543896459043\n",
      "Epoch 1956, Loss: 0.0011364476376911625, Final Batch Loss: 0.0003364223230164498\n",
      "Epoch 1957, Loss: 0.004831750731682405, Final Batch Loss: 0.001005064696073532\n",
      "Epoch 1958, Loss: 0.000787625558587024, Final Batch Loss: 0.00028029948589392006\n",
      "Epoch 1959, Loss: 0.0006228883939911611, Final Batch Loss: 0.00010305227624485269\n",
      "Epoch 1960, Loss: 0.0012701180821750313, Final Batch Loss: 0.0005250825779512525\n",
      "Epoch 1961, Loss: 0.0006216516521817539, Final Batch Loss: 3.399492197786458e-05\n",
      "Epoch 1962, Loss: 0.001860625809058547, Final Batch Loss: 3.1051669793669134e-05\n",
      "Epoch 1963, Loss: 0.0017451448811698356, Final Batch Loss: 0.001486538560129702\n",
      "Epoch 1964, Loss: 0.005650381179293618, Final Batch Loss: 0.000652108050417155\n",
      "Epoch 1965, Loss: 0.0025097579600696918, Final Batch Loss: 2.8273218049434945e-05\n",
      "Epoch 1966, Loss: 0.0026743822963908315, Final Batch Loss: 0.0022978801280260086\n",
      "Epoch 1967, Loss: 0.00047588619781890884, Final Batch Loss: 8.490262553095818e-05\n",
      "Epoch 1968, Loss: 0.0014001638701302, Final Batch Loss: 0.0011671242536976933\n",
      "Epoch 1969, Loss: 0.0007751975172141101, Final Batch Loss: 2.9009519494138658e-05\n",
      "Epoch 1970, Loss: 0.0009943937839125283, Final Batch Loss: 0.00021645770175382495\n",
      "Epoch 1971, Loss: 0.042572199779897346, Final Batch Loss: 0.041762825101614\n",
      "Epoch 1972, Loss: 0.0037502062041312456, Final Batch Loss: 3.31322371494025e-05\n",
      "Epoch 1973, Loss: 0.0010964018329104874, Final Batch Loss: 0.00046211580047383904\n",
      "Epoch 1974, Loss: 0.013590847083833069, Final Batch Loss: 9.96789603959769e-05\n",
      "Epoch 1975, Loss: 0.0004862567875534296, Final Batch Loss: 2.546743053244427e-05\n",
      "Epoch 1976, Loss: 0.011613996146479622, Final Batch Loss: 0.007938601076602936\n",
      "Epoch 1977, Loss: 0.0006022903871780727, Final Batch Loss: 3.066530916839838e-05\n",
      "Epoch 1978, Loss: 0.0009119165115407668, Final Batch Loss: 6.662573287030682e-05\n",
      "Epoch 1979, Loss: 0.0006973234849283472, Final Batch Loss: 7.956917397677898e-05\n",
      "Epoch 1980, Loss: 0.003925515207811259, Final Batch Loss: 7.594886119477451e-05\n",
      "Epoch 1981, Loss: 0.001232196344062686, Final Batch Loss: 0.0006687607383355498\n",
      "Epoch 1982, Loss: 0.0011082307319156826, Final Batch Loss: 7.294749957509339e-05\n",
      "Epoch 1983, Loss: 0.0023926863650558516, Final Batch Loss: 0.00018346084107179195\n",
      "Epoch 1984, Loss: 0.006060505533241667, Final Batch Loss: 0.005751787219196558\n",
      "Epoch 1985, Loss: 0.0005749100164393894, Final Batch Loss: 6.530239625135437e-05\n",
      "Epoch 1986, Loss: 0.017695999289571773, Final Batch Loss: 3.913368709618226e-05\n",
      "Epoch 1987, Loss: 0.0010833971900865436, Final Batch Loss: 4.1791441617533565e-05\n",
      "Epoch 1988, Loss: 0.0009898650532704778, Final Batch Loss: 0.00043746051960624754\n",
      "Epoch 1989, Loss: 0.002463933102262672, Final Batch Loss: 7.473797450074926e-05\n",
      "Epoch 1990, Loss: 0.0019718545372597873, Final Batch Loss: 0.0006186712998896837\n",
      "Epoch 1991, Loss: 0.003239447240048321, Final Batch Loss: 0.0001219464247697033\n",
      "Epoch 1992, Loss: 0.0013633427006425336, Final Batch Loss: 0.0001772432733559981\n",
      "Epoch 1993, Loss: 0.0013365617487579584, Final Batch Loss: 0.00029566322336904705\n",
      "Epoch 1994, Loss: 0.003039447787159588, Final Batch Loss: 0.0003736102662514895\n",
      "Epoch 1995, Loss: 0.0026596432144287974, Final Batch Loss: 0.0009218327468261123\n",
      "Epoch 1996, Loss: 0.007608314823301043, Final Batch Loss: 0.00010226704034721479\n",
      "Epoch 1997, Loss: 0.008027876276173629, Final Batch Loss: 0.007556308526545763\n",
      "Epoch 1998, Loss: 0.005371854324039305, Final Batch Loss: 0.00040831530350260437\n",
      "Epoch 1999, Loss: 0.0033673727011773735, Final Batch Loss: 0.0016968145500868559\n",
      "Epoch 2000, Loss: 0.0014165197244437877, Final Batch Loss: 0.0010353808756917715\n",
      "Epoch 2001, Loss: 0.0009348873281851411, Final Batch Loss: 0.00011536542297108099\n",
      "Epoch 2002, Loss: 0.0008862191898515448, Final Batch Loss: 0.00011982969590462744\n",
      "Epoch 2003, Loss: 0.0010518825583858415, Final Batch Loss: 0.00026718503795564175\n",
      "Epoch 2004, Loss: 0.0027000475965905935, Final Batch Loss: 3.570418630260974e-05\n",
      "Epoch 2005, Loss: 0.0013309185960679315, Final Batch Loss: 0.0010521886870265007\n",
      "Epoch 2006, Loss: 0.000795413987361826, Final Batch Loss: 0.0002386456762906164\n",
      "Epoch 2007, Loss: 0.0005249836158327525, Final Batch Loss: 0.00016948273696471006\n",
      "Epoch 2008, Loss: 0.008511089898092905, Final Batch Loss: 0.0001346236967947334\n",
      "Epoch 2009, Loss: 0.001026296267809812, Final Batch Loss: 0.00010736007970990613\n",
      "Epoch 2010, Loss: 0.0013955036629340611, Final Batch Loss: 6.863183079985902e-05\n",
      "Epoch 2011, Loss: 0.003856376264593564, Final Batch Loss: 0.00024471760843880475\n",
      "Epoch 2012, Loss: 0.0011180384008184774, Final Batch Loss: 7.114800246199593e-05\n",
      "Epoch 2013, Loss: 0.0005966367534711026, Final Batch Loss: 7.587175059597939e-05\n",
      "Epoch 2014, Loss: 0.0005170218501007184, Final Batch Loss: 0.00038826814852654934\n",
      "Epoch 2015, Loss: 0.012382751658151392, Final Batch Loss: 3.847782136290334e-05\n",
      "Epoch 2016, Loss: 0.0011237000071560033, Final Batch Loss: 0.0004268496122676879\n",
      "Epoch 2017, Loss: 0.029017619428486796, Final Batch Loss: 0.028387295082211494\n",
      "Epoch 2018, Loss: 0.03795041044213576, Final Batch Loss: 0.0002377984201302752\n",
      "Epoch 2019, Loss: 0.0017899482481880113, Final Batch Loss: 0.0008175863767974079\n",
      "Epoch 2020, Loss: 0.0011836301564471796, Final Batch Loss: 0.00013624021084979177\n",
      "Epoch 2021, Loss: 0.0005297413918015081, Final Batch Loss: 0.00010039772314485162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2022, Loss: 0.031849556078668684, Final Batch Loss: 0.0006631716387346387\n",
      "Epoch 2023, Loss: 0.0007959840877447277, Final Batch Loss: 0.00021231330174487084\n",
      "Epoch 2024, Loss: 0.0026807759422808886, Final Batch Loss: 0.00015070888912305236\n",
      "Epoch 2025, Loss: 0.0004933116870233789, Final Batch Loss: 0.00012750107271131128\n",
      "Epoch 2026, Loss: 0.0013074653688818216, Final Batch Loss: 0.00023919907107483596\n",
      "Epoch 2027, Loss: 0.0009984952921513468, Final Batch Loss: 0.00018848912441171706\n",
      "Epoch 2028, Loss: 0.01166474012643448, Final Batch Loss: 5.3546882554655895e-05\n",
      "Epoch 2029, Loss: 0.00137096103571821, Final Batch Loss: 0.000546654628124088\n",
      "Epoch 2030, Loss: 0.003838625918433536, Final Batch Loss: 6.153278081910685e-05\n",
      "Epoch 2031, Loss: 0.0037195749537204392, Final Batch Loss: 0.00011906539293704554\n",
      "Epoch 2032, Loss: 0.0013527106202673167, Final Batch Loss: 0.000397278752643615\n",
      "Epoch 2033, Loss: 0.0011760095367208123, Final Batch Loss: 0.0001278840791201219\n",
      "Epoch 2034, Loss: 0.0010579717200016603, Final Batch Loss: 0.00010832227417267859\n",
      "Epoch 2035, Loss: 0.00405087236140389, Final Batch Loss: 0.00021334610937628895\n",
      "Epoch 2036, Loss: 0.006337533632176928, Final Batch Loss: 0.0005039935349486768\n",
      "Epoch 2037, Loss: 0.0010657173297659028, Final Batch Loss: 7.662019925191998e-05\n",
      "Epoch 2038, Loss: 0.002565723414591048, Final Batch Loss: 0.00013013358693569899\n",
      "Epoch 2039, Loss: 0.0006700551930407528, Final Batch Loss: 9.740499081090093e-05\n",
      "Epoch 2040, Loss: 0.0006810981176386122, Final Batch Loss: 0.00015480942965950817\n",
      "Epoch 2041, Loss: 0.0020901143143419176, Final Batch Loss: 0.00016689817130099982\n",
      "Epoch 2042, Loss: 0.010608987984596752, Final Batch Loss: 7.990781159605831e-05\n",
      "Epoch 2043, Loss: 0.003141819703159854, Final Batch Loss: 0.000454240565886721\n",
      "Epoch 2044, Loss: 0.00102982129828888, Final Batch Loss: 6.79554941598326e-05\n",
      "Epoch 2045, Loss: 0.006220403123734286, Final Batch Loss: 0.0002464141871314496\n",
      "Epoch 2046, Loss: 0.0015371214394690469, Final Batch Loss: 0.0006039298605173826\n",
      "Epoch 2047, Loss: 0.0015825077207409777, Final Batch Loss: 0.00015122276090551168\n",
      "Epoch 2048, Loss: 0.0006249434700293932, Final Batch Loss: 3.4087104722857475e-05\n",
      "Epoch 2049, Loss: 0.0006975843425607309, Final Batch Loss: 2.615180710563436e-05\n",
      "Epoch 2050, Loss: 0.0030229654657887295, Final Batch Loss: 0.0002483042480889708\n",
      "Epoch 2051, Loss: 0.0024126014268404106, Final Batch Loss: 0.0022763004526495934\n",
      "Epoch 2052, Loss: 0.0008626853887108155, Final Batch Loss: 9.636540926294401e-05\n",
      "Epoch 2053, Loss: 0.0007746166866127169, Final Batch Loss: 1.9631259419838898e-05\n",
      "Epoch 2054, Loss: 0.0017484516865806654, Final Batch Loss: 0.0002069802867481485\n",
      "Epoch 2055, Loss: 0.0018616978923091665, Final Batch Loss: 0.0013758966233581305\n",
      "Epoch 2056, Loss: 0.0007318569296330679, Final Batch Loss: 5.668014273396693e-05\n",
      "Epoch 2057, Loss: 0.001057280009263195, Final Batch Loss: 4.008377072750591e-05\n",
      "Epoch 2058, Loss: 0.0004009042986581335, Final Batch Loss: 4.556943895295262e-05\n",
      "Epoch 2059, Loss: 0.00021053085220046341, Final Batch Loss: 9.415885870112106e-05\n",
      "Epoch 2060, Loss: 0.001045201119268313, Final Batch Loss: 0.00016980509099084884\n",
      "Epoch 2061, Loss: 0.0006563003189512528, Final Batch Loss: 6.585810479009524e-05\n",
      "Epoch 2062, Loss: 0.0006327903538476676, Final Batch Loss: 0.00021269629360176623\n",
      "Epoch 2063, Loss: 0.00110930285154609, Final Batch Loss: 0.000606901478022337\n",
      "Epoch 2064, Loss: 0.0006161119817988947, Final Batch Loss: 0.00022851313406135887\n",
      "Epoch 2065, Loss: 0.0006049667463230435, Final Batch Loss: 0.00016575668996665627\n",
      "Epoch 2066, Loss: 0.0002663675550138578, Final Batch Loss: 2.4525070330128074e-05\n",
      "Epoch 2067, Loss: 0.0015708992032159586, Final Batch Loss: 3.872324668918736e-05\n",
      "Epoch 2068, Loss: 0.0008570300378778484, Final Batch Loss: 0.0001856838644016534\n",
      "Epoch 2069, Loss: 0.002266153671371285, Final Batch Loss: 0.00040937052108347416\n",
      "Epoch 2070, Loss: 0.0017363627594022546, Final Batch Loss: 0.0015783020062372088\n",
      "Epoch 2071, Loss: 0.0016886372777662473, Final Batch Loss: 2.168817627534736e-05\n",
      "Epoch 2072, Loss: 0.000733803922230436, Final Batch Loss: 8.862195682013407e-05\n",
      "Epoch 2073, Loss: 0.0022621357566094957, Final Batch Loss: 0.00044085344416089356\n",
      "Epoch 2074, Loss: 0.0009020128363772528, Final Batch Loss: 0.0005132149090059102\n",
      "Epoch 2075, Loss: 0.0006405985259334557, Final Batch Loss: 0.00015984982019290328\n",
      "Epoch 2076, Loss: 0.014370352662808727, Final Batch Loss: 7.902963261585683e-06\n",
      "Epoch 2077, Loss: 0.006026632717293978, Final Batch Loss: 2.1730516891693696e-05\n",
      "Epoch 2078, Loss: 0.0002783949394142837, Final Batch Loss: 1.3374757145356853e-05\n",
      "Epoch 2079, Loss: 0.0011724990508810151, Final Batch Loss: 0.0009202791843563318\n",
      "Epoch 2080, Loss: 0.000884423207025975, Final Batch Loss: 1.7711567124933936e-05\n",
      "Epoch 2081, Loss: 0.0003044748300453648, Final Batch Loss: 0.00014260016905609518\n",
      "Epoch 2082, Loss: 0.0006931843308848329, Final Batch Loss: 0.0003597006725613028\n",
      "Epoch 2083, Loss: 0.0027996066564810462, Final Batch Loss: 7.962916424730793e-05\n",
      "Epoch 2084, Loss: 0.0025338772538816556, Final Batch Loss: 0.0006128961103968322\n",
      "Epoch 2085, Loss: 0.0004761461023008451, Final Batch Loss: 0.0002962533326353878\n",
      "Epoch 2086, Loss: 0.00046041206587688066, Final Batch Loss: 9.463992319069803e-05\n",
      "Epoch 2087, Loss: 0.00041801168481470086, Final Batch Loss: 9.904077160172164e-05\n",
      "Epoch 2088, Loss: 0.0010303640337951947, Final Batch Loss: 4.4779055315302685e-05\n",
      "Epoch 2089, Loss: 0.0009091090323636308, Final Batch Loss: 0.0005063381977379322\n",
      "Epoch 2090, Loss: 0.00039521049620816484, Final Batch Loss: 9.060928277904168e-05\n",
      "Epoch 2091, Loss: 0.0007262990402523428, Final Batch Loss: 2.411380410194397e-05\n",
      "Epoch 2092, Loss: 0.0003713019068527501, Final Batch Loss: 8.508317114319652e-05\n",
      "Epoch 2093, Loss: 0.0002576917277110624, Final Batch Loss: 0.00016360008157789707\n",
      "Epoch 2094, Loss: 0.0008169522989192046, Final Batch Loss: 0.0002987560292240232\n",
      "Epoch 2095, Loss: 0.0026450364239281043, Final Batch Loss: 0.00034616535413078964\n",
      "Epoch 2096, Loss: 0.0010840226386790164, Final Batch Loss: 0.0005444377311505377\n",
      "Epoch 2097, Loss: 0.0012619816297956277, Final Batch Loss: 4.154624548391439e-05\n",
      "Epoch 2098, Loss: 0.0015368284075520933, Final Batch Loss: 0.00046931521501392126\n",
      "Epoch 2099, Loss: 0.00040875087506719865, Final Batch Loss: 6.801749259466305e-05\n",
      "Epoch 2100, Loss: 0.0005310621490934864, Final Batch Loss: 0.00010055126767838374\n",
      "Epoch 2101, Loss: 0.0008468664655083558, Final Batch Loss: 2.16106836887775e-05\n",
      "Epoch 2102, Loss: 0.0006416743199224584, Final Batch Loss: 8.90679657459259e-05\n",
      "Epoch 2103, Loss: 0.0010807467660924885, Final Batch Loss: 2.082747596432455e-05\n",
      "Epoch 2104, Loss: 0.0005376664266805165, Final Batch Loss: 0.00022835038544144481\n",
      "Epoch 2105, Loss: 0.00034326762761338614, Final Batch Loss: 3.0818137020105496e-05\n",
      "Epoch 2106, Loss: 0.017305789504462155, Final Batch Loss: 7.758609717711806e-05\n",
      "Epoch 2107, Loss: 0.000665303577989107, Final Batch Loss: 0.0004901188658550382\n",
      "Epoch 2108, Loss: 0.0011405036593714613, Final Batch Loss: 1.0208051207882818e-05\n",
      "Epoch 2109, Loss: 0.0014637934045822476, Final Batch Loss: 0.00042367243440821767\n",
      "Epoch 2110, Loss: 0.008293679362395778, Final Batch Loss: 0.00015511325909756124\n",
      "Epoch 2111, Loss: 0.007036120936390944, Final Batch Loss: 0.00030670262640342116\n",
      "Epoch 2112, Loss: 0.0013192071201046929, Final Batch Loss: 0.00015970422828104347\n",
      "Epoch 2113, Loss: 0.0010246494057355449, Final Batch Loss: 0.0002581143635325134\n",
      "Epoch 2114, Loss: 0.00036249953973310767, Final Batch Loss: 1.787815199350007e-05\n",
      "Epoch 2115, Loss: 0.00016918454912229208, Final Batch Loss: 6.681249215034768e-05\n",
      "Epoch 2116, Loss: 0.0011581327125895768, Final Batch Loss: 0.00018887784972321242\n",
      "Epoch 2117, Loss: 0.007082895182975335, Final Batch Loss: 4.757820352097042e-05\n",
      "Epoch 2118, Loss: 0.0016423468623543158, Final Batch Loss: 0.0001416089216945693\n",
      "Epoch 2119, Loss: 0.015094254951691255, Final Batch Loss: 0.014728719368577003\n",
      "Epoch 2120, Loss: 0.002665868651092751, Final Batch Loss: 0.00025259319227188826\n",
      "Epoch 2121, Loss: 0.0021815906875417568, Final Batch Loss: 0.000936141877900809\n",
      "Epoch 2122, Loss: 0.010951358639431419, Final Batch Loss: 5.934834553045221e-05\n",
      "Epoch 2123, Loss: 0.001335517161351163, Final Batch Loss: 0.0002564539317972958\n",
      "Epoch 2124, Loss: 0.00047693675878690556, Final Batch Loss: 0.00010908405238296837\n",
      "Epoch 2125, Loss: 0.00425844281562604, Final Batch Loss: 0.0010186429135501385\n",
      "Epoch 2126, Loss: 0.00024411957565462217, Final Batch Loss: 3.365983138792217e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2127, Loss: 0.0004236004724589293, Final Batch Loss: 0.00010646908049238846\n",
      "Epoch 2128, Loss: 0.0011483843773021363, Final Batch Loss: 0.00040094551513902843\n",
      "Epoch 2129, Loss: 0.01246750198333757, Final Batch Loss: 9.232041338691488e-05\n",
      "Epoch 2130, Loss: 0.019299288795082248, Final Batch Loss: 0.0012924103066325188\n",
      "Epoch 2131, Loss: 0.0324821449466981, Final Batch Loss: 0.031916987150907516\n",
      "Epoch 2132, Loss: 0.00789458237704821, Final Batch Loss: 0.004158853553235531\n",
      "Epoch 2133, Loss: 0.010509654704947025, Final Batch Loss: 0.0006697963108308613\n",
      "Epoch 2134, Loss: 0.0042678229219745845, Final Batch Loss: 7.465129601769149e-05\n",
      "Epoch 2135, Loss: 0.025541112896462437, Final Batch Loss: 0.0002775551110971719\n",
      "Epoch 2136, Loss: 0.0018863140358007513, Final Batch Loss: 0.0004615885263774544\n",
      "Epoch 2137, Loss: 0.0012736230419250205, Final Batch Loss: 0.00017587030015420169\n",
      "Epoch 2138, Loss: 0.0012741523314616643, Final Batch Loss: 0.0005472048651427031\n",
      "Epoch 2139, Loss: 0.0008297844251501374, Final Batch Loss: 3.716764331329614e-05\n",
      "Epoch 2140, Loss: 0.005940560266026296, Final Batch Loss: 0.0001495957694714889\n",
      "Epoch 2141, Loss: 0.0015993264205462765, Final Batch Loss: 0.0004552106256596744\n",
      "Epoch 2142, Loss: 0.008920691776438616, Final Batch Loss: 0.0001916283945320174\n",
      "Epoch 2143, Loss: 0.003104243089183001, Final Batch Loss: 5.893765410291962e-05\n",
      "Epoch 2144, Loss: 0.0009289824956795201, Final Batch Loss: 0.0006780143594369292\n",
      "Epoch 2145, Loss: 0.0034933137794723734, Final Batch Loss: 0.0005494734505191445\n",
      "Epoch 2146, Loss: 0.0008178378484444693, Final Batch Loss: 0.00015221744251903147\n",
      "Epoch 2147, Loss: 0.014110525145952124, Final Batch Loss: 0.0008634501718915999\n",
      "Epoch 2148, Loss: 0.0028306787135079503, Final Batch Loss: 0.0008164435275830328\n",
      "Epoch 2149, Loss: 0.006790789368096739, Final Batch Loss: 0.00028577225748449564\n",
      "Epoch 2150, Loss: 0.00028995411412324756, Final Batch Loss: 5.0586688303155825e-05\n",
      "Epoch 2151, Loss: 0.02023689285852015, Final Batch Loss: 0.004254210274666548\n",
      "Epoch 2152, Loss: 0.0008020342320378404, Final Batch Loss: 4.9482154281577095e-05\n",
      "Epoch 2153, Loss: 0.0020310446452640463, Final Batch Loss: 3.620727875386365e-05\n",
      "Epoch 2154, Loss: 0.009721103829178901, Final Batch Loss: 1.030600742524257e-05\n",
      "Epoch 2155, Loss: 0.0006960149949009065, Final Batch Loss: 0.00019004559726454318\n",
      "Epoch 2156, Loss: 0.00245054584229365, Final Batch Loss: 0.0002963453880511224\n",
      "Epoch 2157, Loss: 0.0004950162619934417, Final Batch Loss: 0.0001756919955369085\n",
      "Epoch 2158, Loss: 0.0010857165325433016, Final Batch Loss: 0.00017319618200417608\n",
      "Epoch 2159, Loss: 0.0017068149900296703, Final Batch Loss: 0.0006351620540954173\n",
      "Epoch 2160, Loss: 0.0007217228776426055, Final Batch Loss: 7.370780076598749e-05\n",
      "Epoch 2161, Loss: 0.0007297935908354702, Final Batch Loss: 0.0001725882029859349\n",
      "Epoch 2162, Loss: 0.0003370260128576774, Final Batch Loss: 3.3479493140475824e-05\n",
      "Epoch 2163, Loss: 0.0006728453299729154, Final Batch Loss: 8.367525151697919e-05\n",
      "Epoch 2164, Loss: 0.00046355018639587797, Final Batch Loss: 6.49730718578212e-05\n",
      "Epoch 2165, Loss: 0.0006500481613329612, Final Batch Loss: 0.00011319616169203073\n",
      "Epoch 2166, Loss: 0.01921522455086233, Final Batch Loss: 0.00011493547208374366\n",
      "Epoch 2167, Loss: 0.0021971409951220267, Final Batch Loss: 0.000679488992318511\n",
      "Epoch 2168, Loss: 0.09768328913742153, Final Batch Loss: 0.0451483353972435\n",
      "Epoch 2169, Loss: 0.0025142637750832364, Final Batch Loss: 0.00023671372036915272\n",
      "Epoch 2170, Loss: 0.0009502038810751401, Final Batch Loss: 0.00025299214757978916\n",
      "Epoch 2171, Loss: 0.05777008809673134, Final Batch Loss: 0.057476725429296494\n",
      "Epoch 2172, Loss: 0.0021613209501083475, Final Batch Loss: 0.0002710644621402025\n",
      "Epoch 2173, Loss: 0.006975238495215308, Final Batch Loss: 8.824842370813712e-05\n",
      "Epoch 2174, Loss: 0.0020872583700111136, Final Batch Loss: 0.00027825459255836904\n",
      "Epoch 2175, Loss: 0.009580200890923152, Final Batch Loss: 0.002132148714736104\n",
      "Epoch 2176, Loss: 0.003767486021388322, Final Batch Loss: 0.0009618832846172154\n",
      "Epoch 2177, Loss: 0.00462982029421255, Final Batch Loss: 0.00042480725096538663\n",
      "Epoch 2178, Loss: 0.026519618506426923, Final Batch Loss: 0.003383324481546879\n",
      "Epoch 2179, Loss: 0.00107018172275275, Final Batch Loss: 0.00018771419127006084\n",
      "Epoch 2180, Loss: 0.0010351640157750808, Final Batch Loss: 3.0729512218385935e-05\n",
      "Epoch 2181, Loss: 0.0018848948820959777, Final Batch Loss: 0.0003459201834630221\n",
      "Epoch 2182, Loss: 0.0012813584471587092, Final Batch Loss: 0.0004382156766951084\n",
      "Epoch 2183, Loss: 0.005950964994553942, Final Batch Loss: 0.0005194834666326642\n",
      "Epoch 2184, Loss: 0.0016818208969198167, Final Batch Loss: 0.00014669464144390076\n",
      "Epoch 2185, Loss: 0.0012804883808712475, Final Batch Loss: 0.0004247412725817412\n",
      "Epoch 2186, Loss: 0.000979608710622415, Final Batch Loss: 0.0003443072200752795\n",
      "Epoch 2187, Loss: 0.0021688918204745278, Final Batch Loss: 0.0009363213321194053\n",
      "Epoch 2188, Loss: 0.001331972158368444, Final Batch Loss: 3.496576027828269e-05\n",
      "Epoch 2189, Loss: 0.0008241611467383336, Final Batch Loss: 4.641331543098204e-05\n",
      "Epoch 2190, Loss: 0.004213708889437839, Final Batch Loss: 0.00048539837007410824\n",
      "Epoch 2191, Loss: 0.0032388812687713653, Final Batch Loss: 0.0003093534323852509\n",
      "Epoch 2192, Loss: 0.002590621414128691, Final Batch Loss: 0.0003957186418119818\n",
      "Epoch 2193, Loss: 0.0010509103813092224, Final Batch Loss: 0.00019268265168648213\n",
      "Epoch 2194, Loss: 0.00099894398044853, Final Batch Loss: 1.9540437278919853e-05\n",
      "Epoch 2195, Loss: 0.0010783284524222836, Final Batch Loss: 6.20454375166446e-05\n",
      "Epoch 2196, Loss: 0.0006198421506269369, Final Batch Loss: 0.00019506461103446782\n",
      "Epoch 2197, Loss: 0.00061532121617347, Final Batch Loss: 9.281675738748163e-05\n",
      "Epoch 2198, Loss: 0.0002618355556478491, Final Batch Loss: 7.812614785507321e-05\n",
      "Epoch 2199, Loss: 0.0009317499097960535, Final Batch Loss: 5.1727973186643794e-05\n",
      "Epoch 2200, Loss: 0.0010887000753427856, Final Batch Loss: 0.0006954422569833696\n",
      "Epoch 2201, Loss: 0.0018860462732845917, Final Batch Loss: 0.00039122605812735856\n",
      "Epoch 2202, Loss: 0.002770703249552753, Final Batch Loss: 5.763571971328929e-05\n",
      "Epoch 2203, Loss: 0.0006052888966223691, Final Batch Loss: 4.502671436057426e-05\n",
      "Epoch 2204, Loss: 0.0008613271529611666, Final Batch Loss: 0.00027695216704159975\n",
      "Epoch 2205, Loss: 0.0004981845559086651, Final Batch Loss: 0.00020795931050088257\n",
      "Epoch 2206, Loss: 0.022624135861406103, Final Batch Loss: 0.005614434834569693\n",
      "Epoch 2207, Loss: 0.0073596714792074636, Final Batch Loss: 0.0003276095085311681\n",
      "Epoch 2208, Loss: 0.011089847361290595, Final Batch Loss: 0.0013274207012727857\n",
      "Epoch 2209, Loss: 0.0019425548834988149, Final Batch Loss: 0.00017027044668793678\n",
      "Epoch 2210, Loss: 0.012907007885587518, Final Batch Loss: 2.3414266252075322e-05\n",
      "Epoch 2211, Loss: 0.015935595496557653, Final Batch Loss: 0.015537326224148273\n",
      "Epoch 2212, Loss: 0.0034862451866501942, Final Batch Loss: 0.00010558872600086033\n",
      "Epoch 2213, Loss: 0.08507536898832768, Final Batch Loss: 0.010421687737107277\n",
      "Epoch 2214, Loss: 0.003741838678251952, Final Batch Loss: 0.0004129226435907185\n",
      "Epoch 2215, Loss: 0.013601194841612596, Final Batch Loss: 0.009519357234239578\n",
      "Epoch 2216, Loss: 0.000954356903093867, Final Batch Loss: 0.00046312424819916487\n",
      "Epoch 2217, Loss: 0.001887173653813079, Final Batch Loss: 0.000677941832691431\n",
      "Epoch 2218, Loss: 0.0042129574285354465, Final Batch Loss: 0.0005599767901003361\n",
      "Epoch 2219, Loss: 0.001910120872707921, Final Batch Loss: 0.0008411192684434354\n",
      "Epoch 2220, Loss: 0.0019201515024178661, Final Batch Loss: 0.0015395336085930467\n",
      "Epoch 2221, Loss: 0.005880849566892721, Final Batch Loss: 0.0005848651635460556\n",
      "Epoch 2222, Loss: 0.00109116877138149, Final Batch Loss: 0.0002830125158652663\n",
      "Epoch 2223, Loss: 0.006357537720759865, Final Batch Loss: 0.0005252373521216214\n",
      "Epoch 2224, Loss: 0.017151408013887703, Final Batch Loss: 0.00022969325073063374\n",
      "Epoch 2225, Loss: 0.0007893141228123568, Final Batch Loss: 8.918171806726605e-05\n",
      "Epoch 2226, Loss: 0.01845410346868448, Final Batch Loss: 0.00023369249538518488\n",
      "Epoch 2227, Loss: 0.001442784381652018, Final Batch Loss: 0.0010084803216159344\n",
      "Epoch 2228, Loss: 0.002645119617227465, Final Batch Loss: 0.00042751431465148926\n",
      "Epoch 2229, Loss: 0.005984546529361978, Final Batch Loss: 0.002692276379093528\n",
      "Epoch 2230, Loss: 0.0031774446324561723, Final Batch Loss: 0.00015001828433014452\n",
      "Epoch 2231, Loss: 0.012183150698547252, Final Batch Loss: 8.308698306791484e-05\n",
      "Epoch 2232, Loss: 0.0034692163462750614, Final Batch Loss: 0.0013729247730225325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2233, Loss: 0.005178719526156783, Final Batch Loss: 0.0006051710806787014\n",
      "Epoch 2234, Loss: 0.004677775054005906, Final Batch Loss: 0.0005081379786133766\n",
      "Epoch 2235, Loss: 0.0008907230876502581, Final Batch Loss: 2.3281107132788748e-05\n",
      "Epoch 2236, Loss: 0.014620564892538823, Final Batch Loss: 7.127829303499311e-05\n",
      "Epoch 2237, Loss: 0.0018034546519629657, Final Batch Loss: 0.0008876857464201748\n",
      "Epoch 2238, Loss: 0.0014675529091618955, Final Batch Loss: 8.382345549762249e-05\n",
      "Epoch 2239, Loss: 0.0012390411720843986, Final Batch Loss: 0.00044330774107947946\n",
      "Epoch 2240, Loss: 0.00109949910256546, Final Batch Loss: 1.8910053768195212e-05\n",
      "Epoch 2241, Loss: 0.0036623805499402806, Final Batch Loss: 0.00034448778023943305\n",
      "Epoch 2242, Loss: 0.011411081577534787, Final Batch Loss: 0.00032563196145929396\n",
      "Epoch 2243, Loss: 0.0011819724459201097, Final Batch Loss: 0.00020766272791661322\n",
      "Epoch 2244, Loss: 0.0005417057109298185, Final Batch Loss: 7.409510726574808e-05\n",
      "Epoch 2245, Loss: 0.0012313342886045575, Final Batch Loss: 0.00031890408718027174\n",
      "Epoch 2246, Loss: 0.000987010818789713, Final Batch Loss: 0.00039329208084382117\n",
      "Epoch 2247, Loss: 0.0016958273918135092, Final Batch Loss: 0.0005723646027036011\n",
      "Epoch 2248, Loss: 0.0009215434656653088, Final Batch Loss: 0.0002422625111648813\n",
      "Epoch 2249, Loss: 0.00038137336650834186, Final Batch Loss: 1.0009239304054063e-05\n",
      "Epoch 2250, Loss: 0.006250256148632616, Final Batch Loss: 0.0005124922026880085\n",
      "Epoch 2251, Loss: 0.0019492789142532274, Final Batch Loss: 0.0003812205686699599\n",
      "Epoch 2252, Loss: 0.0007174098718678579, Final Batch Loss: 0.00023442687233909965\n",
      "Epoch 2253, Loss: 0.0007866899359214585, Final Batch Loss: 0.00026506782160140574\n",
      "Epoch 2254, Loss: 0.0010611869220156223, Final Batch Loss: 0.00021653802832588553\n",
      "Epoch 2255, Loss: 0.0014291578263510019, Final Batch Loss: 0.0004587416769936681\n",
      "Epoch 2256, Loss: 0.0008212245156755671, Final Batch Loss: 0.00033875007648020983\n",
      "Epoch 2257, Loss: 0.0008608405114500783, Final Batch Loss: 0.00035399189800955355\n",
      "Epoch 2258, Loss: 0.001981835230253637, Final Batch Loss: 0.0008027121075429022\n",
      "Epoch 2259, Loss: 0.0024769298288447317, Final Batch Loss: 0.0011685718782246113\n",
      "Epoch 2260, Loss: 0.0007960259208630305, Final Batch Loss: 0.00027489446802064776\n",
      "Epoch 2261, Loss: 0.002594011055862211, Final Batch Loss: 5.004846116207773e-06\n",
      "Epoch 2262, Loss: 0.0007412175318677328, Final Batch Loss: 0.00017204854520969093\n",
      "Epoch 2263, Loss: 0.006915916314028436, Final Batch Loss: 0.00038770961691625416\n",
      "Epoch 2264, Loss: 0.00888140924507752, Final Batch Loss: 0.008358247578144073\n",
      "Epoch 2265, Loss: 0.0044531142702908255, Final Batch Loss: 6.287349242484197e-05\n",
      "Epoch 2266, Loss: 0.0012490733097365592, Final Batch Loss: 3.826122701866552e-05\n",
      "Epoch 2267, Loss: 0.0020080012909602374, Final Batch Loss: 0.0003097228764090687\n",
      "Epoch 2268, Loss: 0.001962209847988561, Final Batch Loss: 7.026845560176298e-05\n",
      "Epoch 2269, Loss: 0.001189483893540455, Final Batch Loss: 3.7490670365514234e-05\n",
      "Epoch 2270, Loss: 0.0022164814254210796, Final Batch Loss: 0.0019646326545625925\n",
      "Epoch 2271, Loss: 0.02229638681455981, Final Batch Loss: 0.00042701742495410144\n",
      "Epoch 2272, Loss: 0.0007676647583139129, Final Batch Loss: 0.00016479988698847592\n",
      "Epoch 2273, Loss: 0.0010225072655885015, Final Batch Loss: 0.000556843529921025\n",
      "Epoch 2274, Loss: 0.00031188470165943727, Final Batch Loss: 0.00012062339374097064\n",
      "Epoch 2275, Loss: 0.008445255021797493, Final Batch Loss: 0.0012074169935658574\n",
      "Epoch 2276, Loss: 0.002588775081676431, Final Batch Loss: 6.860784196760505e-05\n",
      "Epoch 2277, Loss: 0.0026423090021125972, Final Batch Loss: 0.0012580560287460685\n",
      "Epoch 2278, Loss: 0.0009844714495557128, Final Batch Loss: 0.0001525615225546062\n",
      "Epoch 2279, Loss: 0.0016465291773783974, Final Batch Loss: 1.4903089322615415e-05\n",
      "Epoch 2280, Loss: 0.010663256100087892, Final Batch Loss: 8.33219601190649e-05\n",
      "Epoch 2281, Loss: 0.0002500721720934962, Final Batch Loss: 6.719944212818518e-05\n",
      "Epoch 2282, Loss: 0.004743740653793793, Final Batch Loss: 3.703164838952944e-05\n",
      "Epoch 2283, Loss: 0.0009001550206448883, Final Batch Loss: 0.00040797717520035803\n",
      "Epoch 2284, Loss: 0.006273712189795333, Final Batch Loss: 0.006060451734811068\n",
      "Epoch 2285, Loss: 0.000598510800045915, Final Batch Loss: 0.0002582061861176044\n",
      "Epoch 2286, Loss: 0.0027574368432397023, Final Batch Loss: 0.0007169415475800633\n",
      "Epoch 2287, Loss: 0.0013204565038904548, Final Batch Loss: 0.00013860277249477804\n",
      "Epoch 2288, Loss: 0.0006627614311582875, Final Batch Loss: 3.1545725505566224e-05\n",
      "Epoch 2289, Loss: 0.0026122994677280076, Final Batch Loss: 0.0020417687483131886\n",
      "Epoch 2290, Loss: 0.0013316887198016047, Final Batch Loss: 5.5530384997837245e-05\n",
      "Epoch 2291, Loss: 0.033683175171972835, Final Batch Loss: 0.03352653607726097\n",
      "Epoch 2292, Loss: 0.0005183123412280111, Final Batch Loss: 0.00010752104572020471\n",
      "Epoch 2293, Loss: 0.0014987665654189186, Final Batch Loss: 0.000750637729652226\n",
      "Epoch 2294, Loss: 0.0024354834968107753, Final Batch Loss: 6.258096982492134e-05\n",
      "Epoch 2295, Loss: 0.026566441901195503, Final Batch Loss: 8.182471901818644e-06\n",
      "Epoch 2296, Loss: 0.0005031621294619981, Final Batch Loss: 5.5037893616827205e-05\n",
      "Epoch 2297, Loss: 0.0006946931243874133, Final Batch Loss: 0.0001456309255445376\n",
      "Epoch 2298, Loss: 0.0015460863778571365, Final Batch Loss: 1.808783235901501e-05\n",
      "Epoch 2299, Loss: 0.0012509863699960988, Final Batch Loss: 0.0006208406412042677\n",
      "Epoch 2300, Loss: 0.0014015042397659272, Final Batch Loss: 0.0008007183205336332\n",
      "Epoch 2301, Loss: 0.0008364847308257595, Final Batch Loss: 0.00018096189887728542\n",
      "Epoch 2302, Loss: 0.0009531475079711527, Final Batch Loss: 0.0005543902516365051\n",
      "Epoch 2303, Loss: 0.000596187495830236, Final Batch Loss: 0.00048459626850672066\n",
      "Epoch 2304, Loss: 0.0009166623785858974, Final Batch Loss: 0.00011800446372944862\n",
      "Epoch 2305, Loss: 0.03844739428313915, Final Batch Loss: 0.0002774471649900079\n",
      "Epoch 2306, Loss: 0.0022663805648335256, Final Batch Loss: 9.094174311030656e-05\n",
      "Epoch 2307, Loss: 0.00031768004464538535, Final Batch Loss: 0.0001857198221841827\n",
      "Epoch 2308, Loss: 0.0009040204204211477, Final Batch Loss: 0.0005659740418195724\n",
      "Epoch 2309, Loss: 0.0025999347053584643, Final Batch Loss: 0.00013168489385861903\n",
      "Epoch 2310, Loss: 0.0029677679158339743, Final Batch Loss: 3.732508412213065e-05\n",
      "Epoch 2311, Loss: 0.014593341067666188, Final Batch Loss: 0.0002823861432261765\n",
      "Epoch 2312, Loss: 0.006907120117830345, Final Batch Loss: 5.8754532801685855e-05\n",
      "Epoch 2313, Loss: 0.023748564824927598, Final Batch Loss: 0.00036663725040853024\n",
      "Epoch 2314, Loss: 0.006666265820967965, Final Batch Loss: 0.00012778524251189083\n",
      "Epoch 2315, Loss: 0.002255152037832886, Final Batch Loss: 0.0006941817118786275\n",
      "Epoch 2316, Loss: 0.001627698919037357, Final Batch Loss: 0.00046121975174173713\n",
      "Epoch 2317, Loss: 0.0018732700118562207, Final Batch Loss: 0.0010887860553339124\n",
      "Epoch 2318, Loss: 0.041213722273823805, Final Batch Loss: 0.040779996663331985\n",
      "Epoch 2319, Loss: 0.001585217185493093, Final Batch Loss: 7.174193888204172e-05\n",
      "Epoch 2320, Loss: 0.0005857398464286234, Final Batch Loss: 0.00011441735114203766\n",
      "Epoch 2321, Loss: 0.0028463716571422992, Final Batch Loss: 0.001645188545808196\n",
      "Epoch 2322, Loss: 0.08336049792706035, Final Batch Loss: 0.04196145012974739\n",
      "Epoch 2323, Loss: 0.0005764721863670275, Final Batch Loss: 3.0420254915952682e-05\n",
      "Epoch 2324, Loss: 0.01573324502533069, Final Batch Loss: 0.00061192357679829\n",
      "Epoch 2325, Loss: 0.003911701525794342, Final Batch Loss: 0.0002085783053189516\n",
      "Epoch 2326, Loss: 0.0011496082406665664, Final Batch Loss: 0.0005756409373134375\n",
      "Epoch 2327, Loss: 0.0011159115529153496, Final Batch Loss: 0.00014043049304746091\n",
      "Epoch 2328, Loss: 0.0014059587410883978, Final Batch Loss: 0.00018096181156579405\n",
      "Epoch 2329, Loss: 0.001190693219541572, Final Batch Loss: 0.0003365954908076674\n",
      "Epoch 2330, Loss: 0.002049764516414143, Final Batch Loss: 0.0008339462801814079\n",
      "Epoch 2331, Loss: 0.006723218767547223, Final Batch Loss: 1.4880019989504945e-05\n",
      "Epoch 2332, Loss: 0.004395361087517813, Final Batch Loss: 0.0003182896471116692\n",
      "Epoch 2333, Loss: 0.0009931100357789546, Final Batch Loss: 8.084383443929255e-05\n",
      "Epoch 2334, Loss: 0.006973066774662584, Final Batch Loss: 0.0003579752519726753\n",
      "Epoch 2335, Loss: 0.006298662119661458, Final Batch Loss: 0.002919778460636735\n",
      "Epoch 2336, Loss: 0.0026363699944340624, Final Batch Loss: 0.0001706120528979227\n",
      "Epoch 2337, Loss: 0.0012698056743829511, Final Batch Loss: 0.00040533411083742976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2338, Loss: 0.002386720632785, Final Batch Loss: 0.00010147546709049493\n",
      "Epoch 2339, Loss: 0.0007519293649238534, Final Batch Loss: 0.00019753898959606886\n",
      "Epoch 2340, Loss: 0.001743761749821715, Final Batch Loss: 0.0008870373130775988\n",
      "Epoch 2341, Loss: 0.003989276974607492, Final Batch Loss: 6.390798807842657e-05\n",
      "Epoch 2342, Loss: 0.0010305391260772012, Final Batch Loss: 0.00011841876403195783\n",
      "Epoch 2343, Loss: 0.0016872132691787556, Final Batch Loss: 0.00013982717064209282\n",
      "Epoch 2344, Loss: 0.000850730124511756, Final Batch Loss: 0.0003578858159016818\n",
      "Epoch 2345, Loss: 0.0015555064746877179, Final Batch Loss: 0.00012942180910613388\n",
      "Epoch 2346, Loss: 0.000993536015812424, Final Batch Loss: 0.00017107493476942182\n",
      "Epoch 2347, Loss: 0.0031779458513483405, Final Batch Loss: 0.00016534625319764018\n",
      "Epoch 2348, Loss: 0.0006490490086434875, Final Batch Loss: 0.0002529285557102412\n",
      "Epoch 2349, Loss: 0.003673931452794932, Final Batch Loss: 0.0030301492661237717\n",
      "Epoch 2350, Loss: 0.0007322332094190642, Final Batch Loss: 0.000394883390981704\n",
      "Epoch 2351, Loss: 0.0020618070557247847, Final Batch Loss: 0.00039022264536470175\n",
      "Epoch 2352, Loss: 0.0014542470744345337, Final Batch Loss: 0.000538995023816824\n",
      "Epoch 2353, Loss: 0.0013307588014868088, Final Batch Loss: 6.236212357180193e-05\n",
      "Epoch 2354, Loss: 0.0014094657162786461, Final Batch Loss: 1.0160631063627079e-05\n",
      "Epoch 2355, Loss: 0.00036547410672937986, Final Batch Loss: 1.5788898963364772e-05\n",
      "Epoch 2356, Loss: 0.0030729352874914184, Final Batch Loss: 0.00014141072460915893\n",
      "Epoch 2357, Loss: 0.0005860419514647219, Final Batch Loss: 1.083968163584359e-05\n",
      "Epoch 2358, Loss: 0.0004277502230252139, Final Batch Loss: 3.4339838748564944e-05\n",
      "Epoch 2359, Loss: 0.008396061944949906, Final Batch Loss: 8.681340113980696e-05\n",
      "Epoch 2360, Loss: 0.0005419780100055505, Final Batch Loss: 8.602780144428834e-05\n",
      "Epoch 2361, Loss: 0.004957727898727171, Final Batch Loss: 0.0036994661204516888\n",
      "Epoch 2362, Loss: 0.0009204537491314113, Final Batch Loss: 0.0003306073194835335\n",
      "Epoch 2363, Loss: 0.000376393846636347, Final Batch Loss: 0.00013828340161126107\n",
      "Epoch 2364, Loss: 0.0009031949421114405, Final Batch Loss: 0.00019286367751192302\n",
      "Epoch 2365, Loss: 0.0006850819117971696, Final Batch Loss: 0.00045534709352068603\n",
      "Epoch 2366, Loss: 0.0005131283760420047, Final Batch Loss: 4.898594488622621e-05\n",
      "Epoch 2367, Loss: 0.0007902608485892415, Final Batch Loss: 7.373579865088686e-05\n",
      "Epoch 2368, Loss: 0.00031705265064374544, Final Batch Loss: 0.00016616885841358453\n",
      "Epoch 2369, Loss: 0.0009435752926947316, Final Batch Loss: 1.8297554561286233e-05\n",
      "Epoch 2370, Loss: 0.0009965378267224878, Final Batch Loss: 9.389513434143737e-05\n",
      "Epoch 2371, Loss: 0.000703235091350507, Final Batch Loss: 0.00015842073480598629\n",
      "Epoch 2372, Loss: 0.0010211355729552452, Final Batch Loss: 5.4929467296460643e-05\n",
      "Epoch 2373, Loss: 0.0005117739783599973, Final Batch Loss: 0.0002687173546291888\n",
      "Epoch 2374, Loss: 0.000578242168558063, Final Batch Loss: 0.00041342072654515505\n",
      "Epoch 2375, Loss: 0.00036507124241325073, Final Batch Loss: 0.00022811704548075795\n",
      "Epoch 2376, Loss: 0.000386475598133984, Final Batch Loss: 0.00022985132818575948\n",
      "Epoch 2377, Loss: 0.0006098834855947644, Final Batch Loss: 1.8619641195982695e-05\n",
      "Epoch 2378, Loss: 0.0004970854715793394, Final Batch Loss: 0.00013459411275107414\n",
      "Epoch 2379, Loss: 0.0005002455618523527, Final Batch Loss: 0.00019614468328654766\n",
      "Epoch 2380, Loss: 0.0012003483661828795, Final Batch Loss: 3.2366391678806394e-05\n",
      "Epoch 2381, Loss: 0.0024553565790483844, Final Batch Loss: 2.507954377506394e-05\n",
      "Epoch 2382, Loss: 0.00021958921570330858, Final Batch Loss: 5.31917430635076e-05\n",
      "Epoch 2383, Loss: 0.0009645287200328312, Final Batch Loss: 6.67774156681844e-06\n",
      "Epoch 2384, Loss: 0.0019437535192992073, Final Batch Loss: 0.0010586583521217108\n",
      "Epoch 2385, Loss: 0.0017213740866282023, Final Batch Loss: 9.632787259761244e-05\n",
      "Epoch 2386, Loss: 0.0011855727425427176, Final Batch Loss: 0.0002523004950489849\n",
      "Epoch 2387, Loss: 0.0004132074063818436, Final Batch Loss: 4.5757111365674064e-05\n",
      "Epoch 2388, Loss: 0.0006475627324107336, Final Batch Loss: 0.00023376112221740186\n",
      "Epoch 2389, Loss: 0.0007196815822680946, Final Batch Loss: 0.0001789457892300561\n",
      "Epoch 2390, Loss: 0.0010580462985672057, Final Batch Loss: 0.00013411248801276088\n",
      "Epoch 2391, Loss: 0.012323375700361794, Final Batch Loss: 1.5284134860849008e-05\n",
      "Epoch 2392, Loss: 0.003394716544789844, Final Batch Loss: 2.991755354742054e-05\n",
      "Epoch 2393, Loss: 0.00036703281875816174, Final Batch Loss: 6.060951636754908e-05\n",
      "Epoch 2394, Loss: 0.006568633543793112, Final Batch Loss: 8.295518637169152e-05\n",
      "Epoch 2395, Loss: 0.00022306690243567573, Final Batch Loss: 1.0671599738998339e-05\n",
      "Epoch 2396, Loss: 0.0015741516745038098, Final Batch Loss: 5.982622315059416e-05\n",
      "Epoch 2397, Loss: 0.0010037500419457501, Final Batch Loss: 0.0005883597186766565\n",
      "Epoch 2398, Loss: 0.0013639110875374172, Final Batch Loss: 0.0004859845503233373\n",
      "Epoch 2399, Loss: 0.0020624232492991723, Final Batch Loss: 0.0001469384296797216\n",
      "Epoch 2400, Loss: 0.00028928461142641027, Final Batch Loss: 5.888592932024039e-05\n",
      "Epoch 2401, Loss: 0.0009335264930996345, Final Batch Loss: 1.1546015230123885e-05\n",
      "Epoch 2402, Loss: 0.0011472545011201873, Final Batch Loss: 0.00042332796147093177\n",
      "Epoch 2403, Loss: 0.0009248366586689372, Final Batch Loss: 5.4133906814968213e-05\n",
      "Epoch 2404, Loss: 0.00033319737667625304, Final Batch Loss: 2.0222894818289205e-05\n",
      "Epoch 2405, Loss: 0.0007391838680632645, Final Batch Loss: 0.0004462232463993132\n",
      "Epoch 2406, Loss: 0.0005002033176424447, Final Batch Loss: 0.00022090841957833618\n",
      "Epoch 2407, Loss: 0.0011948730316362344, Final Batch Loss: 0.0002536463434807956\n",
      "Epoch 2408, Loss: 0.011125394454211346, Final Batch Loss: 9.15730488486588e-05\n",
      "Epoch 2409, Loss: 0.0005385166223277338, Final Batch Loss: 4.651839117286727e-05\n",
      "Epoch 2410, Loss: 0.0006115459473221563, Final Batch Loss: 9.028442582348362e-05\n",
      "Epoch 2411, Loss: 0.001092011352739064, Final Batch Loss: 0.0003252917085774243\n",
      "Epoch 2412, Loss: 0.000945119718380738, Final Batch Loss: 0.00011804383393609896\n",
      "Epoch 2413, Loss: 0.009493341014604084, Final Batch Loss: 0.00020381638023536652\n",
      "Epoch 2414, Loss: 0.0004307827912271023, Final Batch Loss: 4.469236228032969e-05\n",
      "Epoch 2415, Loss: 0.014699273480800912, Final Batch Loss: 0.01425832137465477\n",
      "Epoch 2416, Loss: 0.009160783694824204, Final Batch Loss: 0.0006327470182441175\n",
      "Epoch 2417, Loss: 0.00039951417329575634, Final Batch Loss: 6.330555152089801e-06\n",
      "Epoch 2418, Loss: 0.010541597453993745, Final Batch Loss: 0.0023672382812947035\n",
      "Epoch 2419, Loss: 0.0004289323496777797, Final Batch Loss: 1.7211717931786552e-05\n",
      "Epoch 2420, Loss: 0.0007875562587287277, Final Batch Loss: 0.00022630866442341357\n",
      "Epoch 2421, Loss: 0.0019641820108518004, Final Batch Loss: 0.0003142101049888879\n",
      "Epoch 2422, Loss: 0.0012848130281781778, Final Batch Loss: 0.0005051819607615471\n",
      "Epoch 2423, Loss: 0.007229739832837367, Final Batch Loss: 3.745840513147414e-05\n",
      "Epoch 2424, Loss: 0.0018665812167455442, Final Batch Loss: 8.424008410656825e-05\n",
      "Epoch 2425, Loss: 0.0008684534332132898, Final Batch Loss: 4.426783561939374e-06\n",
      "Epoch 2426, Loss: 0.001244647937710397, Final Batch Loss: 0.0008150771609507501\n",
      "Epoch 2427, Loss: 0.010072579116240377, Final Batch Loss: 0.0008103341679088771\n",
      "Epoch 2428, Loss: 0.002112197849783115, Final Batch Loss: 0.00015055856783874333\n",
      "Epoch 2429, Loss: 0.004086466382432263, Final Batch Loss: 4.31514490628615e-05\n",
      "Epoch 2430, Loss: 0.01437703464034712, Final Batch Loss: 0.0005062571144662797\n",
      "Epoch 2431, Loss: 0.0006547273824253352, Final Batch Loss: 0.00027233350556343794\n",
      "Epoch 2432, Loss: 0.014714285205627675, Final Batch Loss: 0.00034516584128141403\n",
      "Epoch 2433, Loss: 0.0016123382629302796, Final Batch Loss: 4.5906566811027005e-05\n",
      "Epoch 2434, Loss: 0.0011536121965036727, Final Batch Loss: 8.040155080379918e-05\n",
      "Epoch 2435, Loss: 0.008785008365521207, Final Batch Loss: 6.053084507584572e-05\n",
      "Epoch 2436, Loss: 0.0008054247873587883, Final Batch Loss: 0.00017614713578950614\n",
      "Epoch 2437, Loss: 0.003688801483804127, Final Batch Loss: 3.183825538144447e-05\n",
      "Epoch 2438, Loss: 0.0011112560459878296, Final Batch Loss: 0.00020500581013038754\n",
      "Epoch 2439, Loss: 0.014180588343151612, Final Batch Loss: 2.7341397071722895e-05\n",
      "Epoch 2440, Loss: 0.06303781777205586, Final Batch Loss: 0.0532020665705204\n",
      "Epoch 2441, Loss: 0.0007852696980990004, Final Batch Loss: 0.0001374850544380024\n",
      "Epoch 2442, Loss: 0.001190611845231615, Final Batch Loss: 0.0001552098838146776\n",
      "Epoch 2443, Loss: 0.002101720037899213, Final Batch Loss: 5.9742207668023184e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2444, Loss: 0.003434393331190222, Final Batch Loss: 8.37491279526148e-06\n",
      "Epoch 2445, Loss: 0.005733704718295485, Final Batch Loss: 1.4490338799078017e-05\n",
      "Epoch 2446, Loss: 0.0011921837140107527, Final Batch Loss: 0.00028797821141779423\n",
      "Epoch 2447, Loss: 0.002429600150207989, Final Batch Loss: 0.0006921841413713992\n",
      "Epoch 2448, Loss: 0.002275364753586473, Final Batch Loss: 3.50032169080805e-05\n",
      "Epoch 2449, Loss: 0.004816794615180697, Final Batch Loss: 0.002646677428856492\n",
      "Epoch 2450, Loss: 0.00392623742664, Final Batch Loss: 0.00034305782173760235\n",
      "Epoch 2451, Loss: 0.0015493182218051516, Final Batch Loss: 7.374057167908177e-05\n",
      "Epoch 2452, Loss: 0.0033851394618977793, Final Batch Loss: 0.00028718236717395484\n",
      "Epoch 2453, Loss: 0.00036141620876151137, Final Batch Loss: 3.2951913453871384e-05\n",
      "Epoch 2454, Loss: 0.0005661185023200233, Final Batch Loss: 0.00010003917122958228\n",
      "Epoch 2455, Loss: 0.000766929479141254, Final Batch Loss: 7.685650052735582e-05\n",
      "Epoch 2456, Loss: 0.0006650878822256345, Final Batch Loss: 0.00010867955279536545\n",
      "Epoch 2457, Loss: 0.003974210194428451, Final Batch Loss: 0.0001214432340930216\n",
      "Epoch 2458, Loss: 0.0018576815818960313, Final Batch Loss: 0.0013991151936352253\n",
      "Epoch 2459, Loss: 0.00031389156356453896, Final Batch Loss: 4.8903712013270706e-05\n",
      "Epoch 2460, Loss: 0.0008119666126731317, Final Batch Loss: 0.00031893234699964523\n",
      "Epoch 2461, Loss: 0.005133834471052978, Final Batch Loss: 0.0005198942380957305\n",
      "Epoch 2462, Loss: 0.0066912436741404235, Final Batch Loss: 0.0003855288669001311\n",
      "Epoch 2463, Loss: 0.000537213045390672, Final Batch Loss: 0.0003047379432246089\n",
      "Epoch 2464, Loss: 0.00044867093674838543, Final Batch Loss: 0.00011186439951416105\n",
      "Epoch 2465, Loss: 0.025643798646342475, Final Batch Loss: 6.869373464724049e-05\n",
      "Epoch 2466, Loss: 0.007921748863736866, Final Batch Loss: 9.970359678845853e-05\n",
      "Epoch 2467, Loss: 0.0013319689824129455, Final Batch Loss: 0.0007806488429196179\n",
      "Epoch 2468, Loss: 0.0019196546636521816, Final Batch Loss: 0.000752884428948164\n",
      "Epoch 2469, Loss: 0.004242079987307079, Final Batch Loss: 0.003948351833969355\n",
      "Epoch 2470, Loss: 0.001582172983489727, Final Batch Loss: 5.69901794733596e-06\n",
      "Epoch 2471, Loss: 0.0013937605690443888, Final Batch Loss: 0.0001585112331667915\n",
      "Epoch 2472, Loss: 0.0008471020810247865, Final Batch Loss: 0.00021589345124084502\n",
      "Epoch 2473, Loss: 0.0009984700300265104, Final Batch Loss: 5.507765308720991e-05\n",
      "Epoch 2474, Loss: 0.003769009985262528, Final Batch Loss: 9.273423347622156e-05\n",
      "Epoch 2475, Loss: 0.001253723492482095, Final Batch Loss: 2.56233961408725e-05\n",
      "Epoch 2476, Loss: 0.00020063068586750887, Final Batch Loss: 5.071350096841343e-05\n",
      "Epoch 2477, Loss: 0.004561382389510982, Final Batch Loss: 0.0002610406372696161\n",
      "Epoch 2478, Loss: 0.0018323498225072399, Final Batch Loss: 0.0011574217351153493\n",
      "Epoch 2479, Loss: 0.000755074797780253, Final Batch Loss: 0.00010524815297685564\n",
      "Epoch 2480, Loss: 0.0011922958765353542, Final Batch Loss: 0.00013147627760190517\n",
      "Epoch 2481, Loss: 0.01507720275549218, Final Batch Loss: 7.214325887616724e-05\n",
      "Epoch 2482, Loss: 0.0012281296221772209, Final Batch Loss: 0.00010987649875460193\n",
      "Epoch 2483, Loss: 0.008794173118076287, Final Batch Loss: 0.00794967170804739\n",
      "Epoch 2484, Loss: 0.00380554221192142, Final Batch Loss: 0.0007034162990748882\n",
      "Epoch 2485, Loss: 0.001167373004136607, Final Batch Loss: 0.00012784928549081087\n",
      "Epoch 2486, Loss: 0.0304215413343627, Final Batch Loss: 0.029580656439065933\n",
      "Epoch 2487, Loss: 0.0009973408359655878, Final Batch Loss: 2.1647725588991307e-05\n",
      "Epoch 2488, Loss: 0.0010828650374605786, Final Batch Loss: 0.0007945788092911243\n",
      "Epoch 2489, Loss: 0.0056816842770786025, Final Batch Loss: 0.00014868758444208652\n",
      "Epoch 2490, Loss: 0.024401633767411113, Final Batch Loss: 0.02304263971745968\n",
      "Epoch 2491, Loss: 0.002751535988863907, Final Batch Loss: 1.7555945305502973e-05\n",
      "Epoch 2492, Loss: 0.002109305663907435, Final Batch Loss: 0.00021819971152581275\n",
      "Epoch 2493, Loss: 0.0012258729402674362, Final Batch Loss: 0.000385860912501812\n",
      "Epoch 2494, Loss: 0.001409755386703182, Final Batch Loss: 6.623772060265765e-05\n",
      "Epoch 2495, Loss: 0.020140507105679717, Final Batch Loss: 0.00046727032167837024\n",
      "Epoch 2496, Loss: 0.000992087458143942, Final Batch Loss: 0.00012428044283296913\n",
      "Epoch 2497, Loss: 0.0077405595511663705, Final Batch Loss: 0.0023824251256883144\n",
      "Epoch 2498, Loss: 0.0034046911168843508, Final Batch Loss: 0.0003208871930837631\n",
      "Epoch 2499, Loss: 0.0022149906762933824, Final Batch Loss: 5.044535282650031e-05\n",
      "Epoch 2500, Loss: 0.0019205231219530106, Final Batch Loss: 0.00020725346985273063\n",
      "Epoch 2501, Loss: 0.0016137314960360527, Final Batch Loss: 0.00016194280760828406\n",
      "Epoch 2502, Loss: 0.0018017783877439797, Final Batch Loss: 0.0008227084763348103\n",
      "Epoch 2503, Loss: 0.0010557839159446303, Final Batch Loss: 5.2690465963678434e-05\n",
      "Epoch 2504, Loss: 0.002555244922405109, Final Batch Loss: 0.0003273561305832118\n",
      "Epoch 2505, Loss: 0.0011368927225703374, Final Batch Loss: 0.00022801908198744059\n",
      "Epoch 2506, Loss: 0.0006390907456079731, Final Batch Loss: 0.00013913691509515047\n",
      "Epoch 2507, Loss: 0.0010864456999115646, Final Batch Loss: 8.710450492799282e-05\n",
      "Epoch 2508, Loss: 0.007870984554756433, Final Batch Loss: 0.0003352653584443033\n",
      "Epoch 2509, Loss: 0.0014880173985147849, Final Batch Loss: 0.0003102837363258004\n",
      "Epoch 2510, Loss: 0.050181559873635706, Final Batch Loss: 0.00023590023920405656\n",
      "Epoch 2511, Loss: 0.0008309453951369505, Final Batch Loss: 0.00037571327993646264\n",
      "Epoch 2512, Loss: 0.0014958245301386341, Final Batch Loss: 0.0010252634529024363\n",
      "Epoch 2513, Loss: 0.0015861920546740294, Final Batch Loss: 0.0003818133263848722\n",
      "Epoch 2514, Loss: 0.0037327250465750694, Final Batch Loss: 7.29118037270382e-05\n",
      "Epoch 2515, Loss: 0.001394012309901882, Final Batch Loss: 3.33407151629217e-05\n",
      "Epoch 2516, Loss: 0.001479238240790437, Final Batch Loss: 0.00020176309044472873\n",
      "Epoch 2517, Loss: 0.00030277198766270885, Final Batch Loss: 4.5256772864377126e-05\n",
      "Epoch 2518, Loss: 0.0006155832525109872, Final Batch Loss: 9.412846702616662e-05\n",
      "Epoch 2519, Loss: 0.0018846999882953241, Final Batch Loss: 0.0006269998266361654\n",
      "Epoch 2520, Loss: 0.000537814041308593, Final Batch Loss: 0.0001475938770454377\n",
      "Epoch 2521, Loss: 0.001458646740502445, Final Batch Loss: 0.00020334201690275222\n",
      "Epoch 2522, Loss: 0.0007742485722701531, Final Batch Loss: 0.0004632062336895615\n",
      "Epoch 2523, Loss: 0.0029822682990925387, Final Batch Loss: 0.0024173699785023928\n",
      "Epoch 2524, Loss: 0.000850342410558369, Final Batch Loss: 8.160250581568107e-05\n",
      "Epoch 2525, Loss: 0.0007261850878421683, Final Batch Loss: 5.5192216677824035e-05\n",
      "Epoch 2526, Loss: 0.0011752825957955793, Final Batch Loss: 8.652618271298707e-05\n",
      "Epoch 2527, Loss: 0.0016736952602514066, Final Batch Loss: 0.00019375023839529604\n",
      "Epoch 2528, Loss: 0.0032373631256632507, Final Batch Loss: 0.002071625553071499\n",
      "Epoch 2529, Loss: 0.0007943210221128538, Final Batch Loss: 0.00024997591390274465\n",
      "Epoch 2530, Loss: 0.0037629568178090267, Final Batch Loss: 0.003312447341158986\n",
      "Epoch 2531, Loss: 0.0008680760984134395, Final Batch Loss: 0.000438685470726341\n",
      "Epoch 2532, Loss: 0.005257562908809632, Final Batch Loss: 0.001153816469013691\n",
      "Epoch 2533, Loss: 0.0006508542192023015, Final Batch Loss: 0.00016847364895511419\n",
      "Epoch 2534, Loss: 0.0007300263896468095, Final Batch Loss: 9.117701119976118e-05\n",
      "Epoch 2535, Loss: 0.009348566674816539, Final Batch Loss: 1.0724657840910368e-05\n",
      "Epoch 2536, Loss: 0.000926320117287105, Final Batch Loss: 0.0005528288311325014\n",
      "Epoch 2537, Loss: 0.005561313941143453, Final Batch Loss: 0.0002737147151492536\n",
      "Epoch 2538, Loss: 0.0005133877057232894, Final Batch Loss: 0.00010414102143840864\n",
      "Epoch 2539, Loss: 0.002500316291843774, Final Batch Loss: 0.00025009227101691067\n",
      "Epoch 2540, Loss: 0.02724167915584985, Final Batch Loss: 0.02671600878238678\n",
      "Epoch 2541, Loss: 0.004840846944716759, Final Batch Loss: 0.0001037552283378318\n",
      "Epoch 2542, Loss: 0.01679021056224883, Final Batch Loss: 1.7332678908132948e-05\n",
      "Epoch 2543, Loss: 0.0009242167288903147, Final Batch Loss: 7.596718205604702e-05\n",
      "Epoch 2544, Loss: 0.00457941803324502, Final Batch Loss: 0.0001619214890524745\n",
      "Epoch 2545, Loss: 0.017884057335322723, Final Batch Loss: 0.0018484662286937237\n",
      "Epoch 2546, Loss: 0.0007019202112132916, Final Batch Loss: 3.55111769749783e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2547, Loss: 0.003432464611250907, Final Batch Loss: 0.0020977207459509373\n",
      "Epoch 2548, Loss: 0.00036730784268002026, Final Batch Loss: 4.851223638979718e-05\n",
      "Epoch 2549, Loss: 0.0027435994052211754, Final Batch Loss: 6.559550820384175e-05\n",
      "Epoch 2550, Loss: 0.0011357396288076416, Final Batch Loss: 5.4541334975510836e-05\n",
      "Epoch 2551, Loss: 0.0023985841808098485, Final Batch Loss: 0.00023413625604007393\n",
      "Epoch 2552, Loss: 0.0005477672821143642, Final Batch Loss: 4.7109897423069924e-05\n",
      "Epoch 2553, Loss: 0.0008539098203073081, Final Batch Loss: 0.0005795187898911536\n",
      "Epoch 2554, Loss: 0.009506141985184513, Final Batch Loss: 0.008169510401785374\n",
      "Epoch 2555, Loss: 0.0007612028639414348, Final Batch Loss: 2.737438990152441e-05\n",
      "Epoch 2556, Loss: 0.001086081174435094, Final Batch Loss: 0.0003853437374345958\n",
      "Epoch 2557, Loss: 0.00453692716837395, Final Batch Loss: 0.0001417293242411688\n",
      "Epoch 2558, Loss: 0.0008314522347063757, Final Batch Loss: 6.138001481303945e-05\n",
      "Epoch 2559, Loss: 0.00039974378887563944, Final Batch Loss: 7.459129119524732e-05\n",
      "Epoch 2560, Loss: 0.0013445447548292577, Final Batch Loss: 0.000764965545386076\n",
      "Epoch 2561, Loss: 0.0003624149139795918, Final Batch Loss: 0.00020500452956184745\n",
      "Epoch 2562, Loss: 0.0006624925326832454, Final Batch Loss: 1.093512310035294e-05\n",
      "Epoch 2563, Loss: 0.0004548092038021423, Final Batch Loss: 0.00011876846838276833\n",
      "Epoch 2564, Loss: 0.0016226068401010707, Final Batch Loss: 0.00014037048094905913\n",
      "Epoch 2565, Loss: 0.0004472062428249046, Final Batch Loss: 1.7353202565573156e-05\n",
      "Epoch 2566, Loss: 0.03679539270524401, Final Batch Loss: 0.014618828892707825\n",
      "Epoch 2567, Loss: 0.0108325053624867, Final Batch Loss: 4.5210024836706e-05\n",
      "Epoch 2568, Loss: 0.0005098350957268849, Final Batch Loss: 3.7038105801912025e-05\n",
      "Epoch 2569, Loss: 0.0013604972409666516, Final Batch Loss: 0.00015917394193820655\n",
      "Epoch 2570, Loss: 0.0013183666305849329, Final Batch Loss: 4.322036693338305e-05\n",
      "Epoch 2571, Loss: 0.17257917796359834, Final Batch Loss: 0.17219606041908264\n",
      "Epoch 2572, Loss: 0.001785377062333282, Final Batch Loss: 9.968467202270404e-05\n",
      "Epoch 2573, Loss: 0.009872859736788087, Final Batch Loss: 0.0012962047476321459\n",
      "Epoch 2574, Loss: 0.0006622445471293759, Final Batch Loss: 0.0002713488647714257\n",
      "Epoch 2575, Loss: 0.0023050281452015042, Final Batch Loss: 0.00015644037921447307\n",
      "Epoch 2576, Loss: 0.01544545243086759, Final Batch Loss: 0.006284381728619337\n",
      "Epoch 2577, Loss: 0.004533053433988243, Final Batch Loss: 0.00046857306733727455\n",
      "Epoch 2578, Loss: 0.0020356446329969913, Final Batch Loss: 0.00027883370057679713\n",
      "Epoch 2579, Loss: 0.0020503665728028864, Final Batch Loss: 0.0007502853404730558\n",
      "Epoch 2580, Loss: 0.0013306697219377384, Final Batch Loss: 0.0001721177832223475\n",
      "Epoch 2581, Loss: 0.0018270474974997342, Final Batch Loss: 4.060010542161763e-05\n",
      "Epoch 2582, Loss: 0.00405311792565044, Final Batch Loss: 0.00041454515303485096\n",
      "Epoch 2583, Loss: 0.017305488858255558, Final Batch Loss: 0.0005135018145665526\n",
      "Epoch 2584, Loss: 0.0013492181024048477, Final Batch Loss: 0.00020582220167852938\n",
      "Epoch 2585, Loss: 0.01900570039288141, Final Batch Loss: 8.98382713785395e-05\n",
      "Epoch 2586, Loss: 0.001616193178051617, Final Batch Loss: 6.1326842114795e-05\n",
      "Epoch 2587, Loss: 0.0015414815134136006, Final Batch Loss: 0.0005147686460986733\n",
      "Epoch 2588, Loss: 0.007079310133121908, Final Batch Loss: 0.0014387385454028845\n",
      "Epoch 2589, Loss: 0.002189338738389779, Final Batch Loss: 9.522756590740755e-05\n",
      "Epoch 2590, Loss: 0.0008657138459966518, Final Batch Loss: 0.00018382671987637877\n",
      "Epoch 2591, Loss: 0.0009891825902741402, Final Batch Loss: 0.00022828731744084507\n",
      "Epoch 2592, Loss: 0.0013482991862474591, Final Batch Loss: 1.2032848644594196e-05\n",
      "Epoch 2593, Loss: 0.0008751834284339566, Final Batch Loss: 9.722021786728874e-05\n",
      "Epoch 2594, Loss: 0.0010996285564033315, Final Batch Loss: 0.0002930525515694171\n",
      "Epoch 2595, Loss: 0.005682982344296761, Final Batch Loss: 0.005210536532104015\n",
      "Epoch 2596, Loss: 0.011413492931751534, Final Batch Loss: 0.011014429852366447\n",
      "Epoch 2597, Loss: 0.0012404958652041387, Final Batch Loss: 0.0005994549719616771\n",
      "Epoch 2598, Loss: 0.0029923956317361444, Final Batch Loss: 0.0002466381120029837\n",
      "Epoch 2599, Loss: 0.0036351363523863256, Final Batch Loss: 0.001930885948240757\n",
      "Epoch 2600, Loss: 0.0034843110624933615, Final Batch Loss: 6.738254160154611e-05\n",
      "Epoch 2601, Loss: 0.0009849208436207846, Final Batch Loss: 0.00027724282699637115\n",
      "Epoch 2602, Loss: 0.0033224982325918972, Final Batch Loss: 0.0008563381270505488\n",
      "Epoch 2603, Loss: 0.0007198541425168514, Final Batch Loss: 0.0003089456295128912\n",
      "Epoch 2604, Loss: 0.0006247903656912968, Final Batch Loss: 0.00010714132076827809\n",
      "Epoch 2605, Loss: 0.0001636917095311219, Final Batch Loss: 2.2261901904130355e-05\n",
      "Epoch 2606, Loss: 0.0011949283434660174, Final Batch Loss: 4.381760663818568e-05\n",
      "Epoch 2607, Loss: 0.00057837810163619, Final Batch Loss: 3.431446384638548e-05\n",
      "Epoch 2608, Loss: 0.0007992879727680702, Final Batch Loss: 6.043169923941605e-05\n",
      "Epoch 2609, Loss: 0.002523933364500408, Final Batch Loss: 3.0166336728143506e-05\n",
      "Epoch 2610, Loss: 0.00047852852367213927, Final Batch Loss: 9.932514512911439e-05\n",
      "Epoch 2611, Loss: 0.0007551799426437356, Final Batch Loss: 2.574503014329821e-05\n",
      "Epoch 2612, Loss: 0.000525088413269259, Final Batch Loss: 4.4143132981844246e-05\n",
      "Epoch 2613, Loss: 0.0004900961394014303, Final Batch Loss: 0.00011313825234537944\n",
      "Epoch 2614, Loss: 0.055292587110670866, Final Batch Loss: 2.0064535419805907e-05\n",
      "Epoch 2615, Loss: 0.0008291523554362357, Final Batch Loss: 0.00017207054770551622\n",
      "Epoch 2616, Loss: 0.0021960536832921207, Final Batch Loss: 0.0017673349939286709\n",
      "Epoch 2617, Loss: 0.005203650078328792, Final Batch Loss: 0.00011544317385414615\n",
      "Epoch 2618, Loss: 0.0072101518453564495, Final Batch Loss: 0.006152173969894648\n",
      "Epoch 2619, Loss: 0.0018201972270617262, Final Batch Loss: 1.780989987310022e-05\n",
      "Epoch 2620, Loss: 0.0010313700895494549, Final Batch Loss: 0.00013556166959460825\n",
      "Epoch 2621, Loss: 0.0005838738143211231, Final Batch Loss: 0.0001897765469038859\n",
      "Epoch 2622, Loss: 0.0003153254365315661, Final Batch Loss: 3.5309072700329125e-05\n",
      "Epoch 2623, Loss: 0.0010711312970670406, Final Batch Loss: 5.704124487238005e-05\n",
      "Epoch 2624, Loss: 0.00040102145430864766, Final Batch Loss: 0.00015782924310769886\n",
      "Epoch 2625, Loss: 0.0013646982406498864, Final Batch Loss: 0.0005557864787988365\n",
      "Epoch 2626, Loss: 0.0009728394543344621, Final Batch Loss: 8.114951197057962e-05\n",
      "Epoch 2627, Loss: 0.0009740367822814733, Final Batch Loss: 3.230536822229624e-05\n",
      "Epoch 2628, Loss: 0.0017158143637061585, Final Batch Loss: 9.683564712759107e-05\n",
      "Epoch 2629, Loss: 0.0004675855452660471, Final Batch Loss: 2.640978345880285e-05\n",
      "Epoch 2630, Loss: 0.0015521811419603182, Final Batch Loss: 2.56565854215296e-05\n",
      "Epoch 2631, Loss: 0.00075549492976279, Final Batch Loss: 0.000548661220818758\n",
      "Epoch 2632, Loss: 0.0006206509078765521, Final Batch Loss: 0.00020131915516685694\n",
      "Epoch 2633, Loss: 0.0009860271602519788, Final Batch Loss: 6.448782369261608e-05\n",
      "Epoch 2634, Loss: 0.0008607370582467411, Final Batch Loss: 0.0005882952827960253\n",
      "Epoch 2635, Loss: 0.0003349501275806688, Final Batch Loss: 0.00011559348786249757\n",
      "Epoch 2636, Loss: 0.0011806388429249637, Final Batch Loss: 6.836503598606214e-05\n",
      "Epoch 2637, Loss: 0.020988954885979183, Final Batch Loss: 0.0006262603565119207\n",
      "Epoch 2638, Loss: 0.0008351837041118415, Final Batch Loss: 0.00011737234308384359\n",
      "Epoch 2639, Loss: 0.0004583950212690979, Final Batch Loss: 3.9723738154862076e-05\n",
      "Epoch 2640, Loss: 0.0005620316951535642, Final Batch Loss: 8.276665903395042e-05\n",
      "Epoch 2641, Loss: 0.0006468552019214258, Final Batch Loss: 0.0002640657767187804\n",
      "Epoch 2642, Loss: 0.0014993999247963075, Final Batch Loss: 0.0006677935598418117\n",
      "Epoch 2643, Loss: 0.002907639274781104, Final Batch Loss: 3.1565552490064874e-05\n",
      "Epoch 2644, Loss: 0.00043876869858650025, Final Batch Loss: 2.517157372494694e-05\n",
      "Epoch 2645, Loss: 0.0004824553097932949, Final Batch Loss: 0.0001804105268092826\n",
      "Epoch 2646, Loss: 0.0002860706242699962, Final Batch Loss: 3.7004444948252058e-06\n",
      "Epoch 2647, Loss: 0.00041161960371027817, Final Batch Loss: 0.00013659575779456645\n",
      "Epoch 2648, Loss: 0.0036327910111140227, Final Batch Loss: 1.6747859262977727e-05\n",
      "Epoch 2649, Loss: 0.005966321034975408, Final Batch Loss: 4.9858062993735075e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2650, Loss: 0.0007117411514627747, Final Batch Loss: 0.0001321412273682654\n",
      "Epoch 2651, Loss: 0.0010471244640939403, Final Batch Loss: 2.9698745493078604e-05\n",
      "Epoch 2652, Loss: 0.002261706908029737, Final Batch Loss: 4.6964731154730543e-05\n",
      "Epoch 2653, Loss: 0.001359578327537747, Final Batch Loss: 4.096083284821361e-05\n",
      "Epoch 2654, Loss: 0.000950916611145658, Final Batch Loss: 0.0006596249877475202\n",
      "Epoch 2655, Loss: 0.0010577203283901326, Final Batch Loss: 8.046417497098446e-05\n",
      "Epoch 2656, Loss: 0.0007080312898324337, Final Batch Loss: 4.559736044029705e-05\n",
      "Epoch 2657, Loss: 0.0005940459668636322, Final Batch Loss: 0.00023894666810519993\n",
      "Epoch 2658, Loss: 0.006145979910797905, Final Batch Loss: 6.254922482185066e-05\n",
      "Epoch 2659, Loss: 0.014222202513337834, Final Batch Loss: 0.013939415104687214\n",
      "Epoch 2660, Loss: 0.002081729780911701, Final Batch Loss: 4.483242446440272e-05\n",
      "Epoch 2661, Loss: 0.0004801271206815727, Final Batch Loss: 6.540682079503313e-05\n",
      "Epoch 2662, Loss: 0.017983066487431643, Final Batch Loss: 0.0007081510848365724\n",
      "Epoch 2663, Loss: 0.0010660417538019828, Final Batch Loss: 0.0008182752644643188\n",
      "Epoch 2664, Loss: 0.004635368815797847, Final Batch Loss: 0.00012941380555275828\n",
      "Epoch 2665, Loss: 0.0010289726706105284, Final Batch Loss: 5.682792834704742e-05\n",
      "Epoch 2666, Loss: 0.0008817373600322753, Final Batch Loss: 5.3611467592418194e-05\n",
      "Epoch 2667, Loss: 0.0011226110764255282, Final Batch Loss: 0.0004667842877097428\n",
      "Epoch 2668, Loss: 0.004254644067259505, Final Batch Loss: 0.0001272789086215198\n",
      "Epoch 2669, Loss: 0.002543276030337438, Final Batch Loss: 0.00040644456748850644\n",
      "Epoch 2670, Loss: 0.00034720453004410956, Final Batch Loss: 0.0001950534206116572\n",
      "Epoch 2671, Loss: 0.03982324993557995, Final Batch Loss: 0.013771913945674896\n",
      "Epoch 2672, Loss: 0.0020331359410192817, Final Batch Loss: 0.0010509321000427008\n",
      "Epoch 2673, Loss: 0.007193673147412483, Final Batch Loss: 4.566039569908753e-05\n",
      "Epoch 2674, Loss: 0.030115640664007515, Final Batch Loss: 0.0045417011715471745\n",
      "Epoch 2675, Loss: 0.0010743415041361004, Final Batch Loss: 0.00020281775505281985\n",
      "Epoch 2676, Loss: 0.010498581521460437, Final Batch Loss: 6.799471520935185e-06\n",
      "Epoch 2677, Loss: 0.0070794275889056735, Final Batch Loss: 0.006467657629400492\n",
      "Epoch 2678, Loss: 0.0009360140466014855, Final Batch Loss: 0.0002756839385256171\n",
      "Epoch 2679, Loss: 0.00236407587362919, Final Batch Loss: 0.00010880181071115658\n",
      "Epoch 2680, Loss: 0.0016358970060537104, Final Batch Loss: 0.00016660205437801778\n",
      "Epoch 2681, Loss: 0.0007700715977989603, Final Batch Loss: 0.00048397810314781964\n",
      "Epoch 2682, Loss: 0.00032686513441149145, Final Batch Loss: 1.4648871001554653e-05\n",
      "Epoch 2683, Loss: 0.004647741836379282, Final Batch Loss: 0.00010292287333868444\n",
      "Epoch 2684, Loss: 0.0009247541383956559, Final Batch Loss: 0.0005697961314581335\n",
      "Epoch 2685, Loss: 0.0005176154227228835, Final Batch Loss: 0.00022145375260151923\n",
      "Epoch 2686, Loss: 0.0004923295527987648, Final Batch Loss: 0.00016068443073891103\n",
      "Epoch 2687, Loss: 0.00039569516411575023, Final Batch Loss: 9.132972627412528e-05\n",
      "Epoch 2688, Loss: 0.01516114305559313, Final Batch Loss: 0.0002570301585365087\n",
      "Epoch 2689, Loss: 0.0005920519106439315, Final Batch Loss: 0.00022265386360231787\n",
      "Epoch 2690, Loss: 0.0023897139781183796, Final Batch Loss: 1.638438152440358e-05\n",
      "Epoch 2691, Loss: 0.01670508772804169, Final Batch Loss: 0.00022815956617705524\n",
      "Epoch 2692, Loss: 0.0009966942889150232, Final Batch Loss: 0.000367365893907845\n",
      "Epoch 2693, Loss: 0.0007607061597809661, Final Batch Loss: 0.00014926887524779886\n",
      "Epoch 2694, Loss: 0.004770087034557946, Final Batch Loss: 0.0003646964323706925\n",
      "Epoch 2695, Loss: 0.004851024394156411, Final Batch Loss: 0.0003742038970813155\n",
      "Epoch 2696, Loss: 0.0014032840845175087, Final Batch Loss: 0.0006005961913615465\n",
      "Epoch 2697, Loss: 0.006108232599217445, Final Batch Loss: 7.571824244223535e-05\n",
      "Epoch 2698, Loss: 0.00186729534107144, Final Batch Loss: 5.552285801968537e-05\n",
      "Epoch 2699, Loss: 0.0003410283497942146, Final Batch Loss: 2.9433627787511796e-05\n",
      "Epoch 2700, Loss: 0.001372775569507212, Final Batch Loss: 1.4808077139605302e-05\n",
      "Epoch 2701, Loss: 0.0026018608259619214, Final Batch Loss: 0.00022208047448657453\n",
      "Epoch 2702, Loss: 0.0017946818807104137, Final Batch Loss: 3.686801210278645e-05\n",
      "Epoch 2703, Loss: 0.000843852452817373, Final Batch Loss: 0.00014180505240801722\n",
      "Epoch 2704, Loss: 0.001105820114389644, Final Batch Loss: 7.190988981164992e-05\n",
      "Epoch 2705, Loss: 0.0021281285880832, Final Batch Loss: 0.0010202773846685886\n",
      "Epoch 2706, Loss: 0.0024725204712012783, Final Batch Loss: 2.6084468117915094e-05\n",
      "Epoch 2707, Loss: 0.007509715367632452, Final Batch Loss: 0.00703415647149086\n",
      "Epoch 2708, Loss: 0.0006251116719795391, Final Batch Loss: 6.0823858802905306e-05\n",
      "Epoch 2709, Loss: 0.0006749235617462546, Final Batch Loss: 0.00015102823090273887\n",
      "Epoch 2710, Loss: 0.00097153099886782, Final Batch Loss: 0.000805055140517652\n",
      "Epoch 2711, Loss: 0.0006597134415642358, Final Batch Loss: 8.145334868459031e-05\n",
      "Epoch 2712, Loss: 0.0004095253607374616, Final Batch Loss: 0.000167106234584935\n",
      "Epoch 2713, Loss: 0.002888800037908368, Final Batch Loss: 0.0003566865634638816\n",
      "Epoch 2714, Loss: 0.0004783039094036212, Final Batch Loss: 8.277337474282831e-05\n",
      "Epoch 2715, Loss: 0.001241479672899004, Final Batch Loss: 0.0006901961751282215\n",
      "Epoch 2716, Loss: 0.0006174269456096226, Final Batch Loss: 3.95019342249725e-05\n",
      "Epoch 2717, Loss: 0.0015235164028126746, Final Batch Loss: 0.0006195143214426935\n",
      "Epoch 2718, Loss: 0.00758479796058964, Final Batch Loss: 0.00011241046013310552\n",
      "Epoch 2719, Loss: 0.00043630471554934047, Final Batch Loss: 4.459542833501473e-05\n",
      "Epoch 2720, Loss: 0.0006719282955600647, Final Batch Loss: 0.00018392785568721592\n",
      "Epoch 2721, Loss: 0.001046616082021501, Final Batch Loss: 4.9792091886047274e-05\n",
      "Epoch 2722, Loss: 0.0003644952457761974, Final Batch Loss: 1.093901209969772e-05\n",
      "Epoch 2723, Loss: 0.00030420047005463857, Final Batch Loss: 0.00010782879689941183\n",
      "Epoch 2724, Loss: 0.00021420225129986648, Final Batch Loss: 3.5193701478419825e-05\n",
      "Epoch 2725, Loss: 0.0013882651837775484, Final Batch Loss: 0.0002169630752177909\n",
      "Epoch 2726, Loss: 0.003323192722746171, Final Batch Loss: 0.0006013452657498419\n",
      "Epoch 2727, Loss: 0.00028616202871489804, Final Batch Loss: 6.757123628631234e-05\n",
      "Epoch 2728, Loss: 0.012271088668057928, Final Batch Loss: 0.001694360631518066\n",
      "Epoch 2729, Loss: 0.00031251409018295817, Final Batch Loss: 5.9396144933998585e-05\n",
      "Epoch 2730, Loss: 0.0009426106007595081, Final Batch Loss: 0.0008637228747829795\n",
      "Epoch 2731, Loss: 0.006529611377118272, Final Batch Loss: 0.006223246455192566\n",
      "Epoch 2732, Loss: 0.00156975987192709, Final Batch Loss: 0.000171887906617485\n",
      "Epoch 2733, Loss: 0.0004139685624977574, Final Batch Loss: 6.477894203271717e-05\n",
      "Epoch 2734, Loss: 0.0006305052447714843, Final Batch Loss: 6.08279078733176e-05\n",
      "Epoch 2735, Loss: 0.0006848879784229212, Final Batch Loss: 3.439503052504733e-05\n",
      "Epoch 2736, Loss: 0.0005491717820405029, Final Batch Loss: 0.0001804068888304755\n",
      "Epoch 2737, Loss: 0.0014998306014604168, Final Batch Loss: 8.310141856782138e-05\n",
      "Epoch 2738, Loss: 0.0011544496028363938, Final Batch Loss: 0.000779759488068521\n",
      "Epoch 2739, Loss: 0.0019979780045105144, Final Batch Loss: 0.0003130038967356086\n",
      "Epoch 2740, Loss: 0.002505222742911428, Final Batch Loss: 7.00199234415777e-05\n",
      "Epoch 2741, Loss: 0.0025411961869394872, Final Batch Loss: 0.0010651483898982406\n",
      "Epoch 2742, Loss: 0.0015339551919169025, Final Batch Loss: 2.6744595743366517e-05\n",
      "Epoch 2743, Loss: 0.0009517744110780768, Final Batch Loss: 0.0003085172502323985\n",
      "Epoch 2744, Loss: 0.000614326294453349, Final Batch Loss: 4.1279861761722714e-05\n",
      "Epoch 2745, Loss: 0.0007237037425511517, Final Batch Loss: 0.00016918701294343919\n",
      "Epoch 2746, Loss: 0.0004449249154276913, Final Batch Loss: 8.154123497661203e-05\n",
      "Epoch 2747, Loss: 0.00045065667291055433, Final Batch Loss: 2.0200779545120895e-05\n",
      "Epoch 2748, Loss: 0.0006149130222183885, Final Batch Loss: 0.0004291357472538948\n",
      "Epoch 2749, Loss: 0.0004971958696842194, Final Batch Loss: 0.0001374025596305728\n",
      "Epoch 2750, Loss: 0.001105052295315545, Final Batch Loss: 0.00010772822133731097\n",
      "Epoch 2751, Loss: 0.0016807316278573126, Final Batch Loss: 7.027202809695154e-05\n",
      "Epoch 2752, Loss: 0.0008750364140723832, Final Batch Loss: 4.929940769216046e-05\n",
      "Epoch 2753, Loss: 0.008913069379559602, Final Batch Loss: 1.0181798643316142e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2754, Loss: 0.0007357621361734346, Final Batch Loss: 0.0001584793790243566\n",
      "Epoch 2755, Loss: 0.0007184764126577647, Final Batch Loss: 1.7791078789741732e-05\n",
      "Epoch 2756, Loss: 0.0007261918199219508, Final Batch Loss: 2.2211070245248266e-05\n",
      "Epoch 2757, Loss: 0.00046347732131835073, Final Batch Loss: 7.523747626692057e-05\n",
      "Epoch 2758, Loss: 0.0002172912791138515, Final Batch Loss: 2.605773988761939e-05\n",
      "Epoch 2759, Loss: 0.003373650775756687, Final Batch Loss: 0.0029362738132476807\n",
      "Epoch 2760, Loss: 0.00793343131954316, Final Batch Loss: 0.0002046611625701189\n",
      "Epoch 2761, Loss: 0.000514485414896626, Final Batch Loss: 8.242398325819522e-05\n",
      "Epoch 2762, Loss: 0.000515898998855846, Final Batch Loss: 7.43250348023139e-05\n",
      "Epoch 2763, Loss: 0.0012235101166879758, Final Batch Loss: 0.00021001249842811376\n",
      "Epoch 2764, Loss: 0.002044117702098447, Final Batch Loss: 0.0008075766963884234\n",
      "Epoch 2765, Loss: 0.00920713612686086, Final Batch Loss: 2.0023171600769274e-05\n",
      "Epoch 2766, Loss: 0.0007663057822355768, Final Batch Loss: 4.483254087972455e-06\n",
      "Epoch 2767, Loss: 0.0014202163035861304, Final Batch Loss: 0.0010521365329623222\n",
      "Epoch 2768, Loss: 0.00034086484447470866, Final Batch Loss: 4.852988786296919e-05\n",
      "Epoch 2769, Loss: 0.0003238395875087008, Final Batch Loss: 2.1267864212859422e-05\n",
      "Epoch 2770, Loss: 0.0009981189778045518, Final Batch Loss: 1.5024341337266378e-05\n",
      "Epoch 2771, Loss: 0.0003802134160650894, Final Batch Loss: 3.7225450796540827e-05\n",
      "Epoch 2772, Loss: 0.0005298701344145229, Final Batch Loss: 3.771107003558427e-05\n",
      "Epoch 2773, Loss: 0.016191562568565132, Final Batch Loss: 0.00018915302644018084\n",
      "Epoch 2774, Loss: 0.00024947575093392516, Final Batch Loss: 0.00012573217099998146\n",
      "Epoch 2775, Loss: 0.001112576781451935, Final Batch Loss: 3.863035453832708e-05\n",
      "Epoch 2776, Loss: 0.01138038174212852, Final Batch Loss: 0.0020207262132316828\n",
      "Epoch 2777, Loss: 0.0012606241762114223, Final Batch Loss: 5.787991176475771e-05\n",
      "Epoch 2778, Loss: 0.0072528933378634974, Final Batch Loss: 6.405583553714678e-05\n",
      "Epoch 2779, Loss: 0.0005484758912643883, Final Batch Loss: 0.0001498843339504674\n",
      "Epoch 2780, Loss: 0.0027860157715622336, Final Batch Loss: 0.000264957983745262\n",
      "Epoch 2781, Loss: 0.0037346298468037276, Final Batch Loss: 4.905949754174799e-05\n",
      "Epoch 2782, Loss: 0.004240851571012172, Final Batch Loss: 0.00015635568706784397\n",
      "Epoch 2783, Loss: 0.0004450399246707093, Final Batch Loss: 0.00012444435560610145\n",
      "Epoch 2784, Loss: 0.00023443961345037678, Final Batch Loss: 2.269643300678581e-05\n",
      "Epoch 2785, Loss: 0.0017099094966397388, Final Batch Loss: 2.901103835029062e-05\n",
      "Epoch 2786, Loss: 0.00040045556852419395, Final Batch Loss: 5.007716754334979e-05\n",
      "Epoch 2787, Loss: 0.00019292064553155797, Final Batch Loss: 5.288330066832714e-05\n",
      "Epoch 2788, Loss: 0.0004314038196753245, Final Batch Loss: 0.00014440418453887105\n",
      "Epoch 2789, Loss: 0.0011578790072235279, Final Batch Loss: 0.00029328669188544154\n",
      "Epoch 2790, Loss: 0.0006085441891627852, Final Batch Loss: 6.0692389524774626e-05\n",
      "Epoch 2791, Loss: 0.00031976349418982863, Final Batch Loss: 0.00020012051390949637\n",
      "Epoch 2792, Loss: 0.001287149567360757, Final Batch Loss: 0.0007617190130986273\n",
      "Epoch 2793, Loss: 0.0014274021923483815, Final Batch Loss: 2.50684934144374e-05\n",
      "Epoch 2794, Loss: 0.00017414339708921034, Final Batch Loss: 7.776857091812417e-05\n",
      "Epoch 2795, Loss: 0.0005193354227230884, Final Batch Loss: 0.00014001251838635653\n",
      "Epoch 2796, Loss: 0.0013998754529893631, Final Batch Loss: 0.00018605453078635037\n",
      "Epoch 2797, Loss: 0.000501463798173063, Final Batch Loss: 0.00016832997789606452\n",
      "Epoch 2798, Loss: 0.0038885762660356704, Final Batch Loss: 0.00015772135520819575\n",
      "Epoch 2799, Loss: 0.0001311166361119831, Final Batch Loss: 3.116271909675561e-05\n",
      "Epoch 2800, Loss: 0.00016457835408800747, Final Batch Loss: 3.807865869021043e-05\n",
      "Epoch 2801, Loss: 0.0002858093794202432, Final Batch Loss: 8.248174708569422e-05\n",
      "Epoch 2802, Loss: 0.0006488885173894232, Final Batch Loss: 3.229189314879477e-05\n",
      "Epoch 2803, Loss: 0.00022959362468100153, Final Batch Loss: 2.209612102888059e-05\n",
      "Epoch 2804, Loss: 0.0003893693979080126, Final Batch Loss: 4.959728357789572e-06\n",
      "Epoch 2805, Loss: 0.0005606596951110987, Final Batch Loss: 5.9095214965054765e-05\n",
      "Epoch 2806, Loss: 0.0014405997064841358, Final Batch Loss: 0.001338896225206554\n",
      "Epoch 2807, Loss: 0.000514399042003788, Final Batch Loss: 7.51972256693989e-05\n",
      "Epoch 2808, Loss: 0.0005048539132985752, Final Batch Loss: 5.6959554058266804e-05\n",
      "Epoch 2809, Loss: 5.9429935390653554e-05, Final Batch Loss: 9.860088539426215e-06\n",
      "Epoch 2810, Loss: 9.736333959153853e-05, Final Batch Loss: 4.3887612264370546e-06\n",
      "Epoch 2811, Loss: 0.0004403325415296422, Final Batch Loss: 7.010298577370122e-05\n",
      "Epoch 2812, Loss: 0.0074497951527519035, Final Batch Loss: 0.00031373335514217615\n",
      "Epoch 2813, Loss: 0.013185162495574332, Final Batch Loss: 6.996711817919277e-06\n",
      "Epoch 2814, Loss: 0.006822102684964193, Final Batch Loss: 1.7274149286095053e-05\n",
      "Epoch 2815, Loss: 0.0020461029662328656, Final Batch Loss: 0.001774228410795331\n",
      "Epoch 2816, Loss: 0.0002367869583395077, Final Batch Loss: 7.55836081225425e-05\n",
      "Epoch 2817, Loss: 0.0006211620220710756, Final Batch Loss: 6.662242230959237e-05\n",
      "Epoch 2818, Loss: 0.0007115358625924273, Final Batch Loss: 2.8715041480609216e-05\n",
      "Epoch 2819, Loss: 0.00327665500844887, Final Batch Loss: 7.254545198520645e-05\n",
      "Epoch 2820, Loss: 0.006017384843289619, Final Batch Loss: 0.005845493171364069\n",
      "Epoch 2821, Loss: 0.0006196839713084046, Final Batch Loss: 4.591581819113344e-05\n",
      "Epoch 2822, Loss: 0.00014299254689831287, Final Batch Loss: 4.544532930594869e-05\n",
      "Epoch 2823, Loss: 0.002842583719484537, Final Batch Loss: 5.032129138271557e-06\n",
      "Epoch 2824, Loss: 0.0007069597158988472, Final Batch Loss: 0.0001225602172780782\n",
      "Epoch 2825, Loss: 0.0037702363115386106, Final Batch Loss: 7.394554995698854e-05\n",
      "Epoch 2826, Loss: 0.0003223919447918888, Final Batch Loss: 5.77032842556946e-05\n",
      "Epoch 2827, Loss: 0.001266621366085019, Final Batch Loss: 0.00068155478220433\n",
      "Epoch 2828, Loss: 0.005271222149531241, Final Batch Loss: 1.0297311746398918e-05\n",
      "Epoch 2829, Loss: 0.0008593603015469853, Final Batch Loss: 0.00017389074491802603\n",
      "Epoch 2830, Loss: 0.005562113641644828, Final Batch Loss: 0.00028430737438611686\n",
      "Epoch 2831, Loss: 0.001000937401840929, Final Batch Loss: 4.957874625688419e-05\n",
      "Epoch 2832, Loss: 0.0001518364588264376, Final Batch Loss: 1.5029765563667752e-05\n",
      "Epoch 2833, Loss: 0.0010354187670600368, Final Batch Loss: 2.1796275177621283e-05\n",
      "Epoch 2834, Loss: 0.016455793997010915, Final Batch Loss: 8.405151311308146e-05\n",
      "Epoch 2835, Loss: 0.0004915148747386411, Final Batch Loss: 0.00019639568927232176\n",
      "Epoch 2836, Loss: 0.0007221698597277282, Final Batch Loss: 3.8403111830120906e-05\n",
      "Epoch 2837, Loss: 0.0005306867860781495, Final Batch Loss: 0.0002723179350141436\n",
      "Epoch 2838, Loss: 0.0002745029833022272, Final Batch Loss: 1.2449889254639857e-05\n",
      "Epoch 2839, Loss: 0.011066435497923521, Final Batch Loss: 4.728747808258049e-05\n",
      "Epoch 2840, Loss: 0.0011289433896308765, Final Batch Loss: 3.266398562118411e-05\n",
      "Epoch 2841, Loss: 0.0005775513709522784, Final Batch Loss: 7.510812429245561e-05\n",
      "Epoch 2842, Loss: 0.00030356897514138836, Final Batch Loss: 5.8813311625272036e-05\n",
      "Epoch 2843, Loss: 0.00013707191646972205, Final Batch Loss: 2.969639899674803e-05\n",
      "Epoch 2844, Loss: 8.408929829784029e-05, Final Batch Loss: 3.5211480735597434e-06\n",
      "Epoch 2845, Loss: 0.0001410859276802512, Final Batch Loss: 1.550392698845826e-05\n",
      "Epoch 2846, Loss: 0.0002391250754953944, Final Batch Loss: 0.00017943617422133684\n",
      "Epoch 2847, Loss: 0.025660752125077124, Final Batch Loss: 3.247338463552296e-05\n",
      "Epoch 2848, Loss: 0.00041721408160810824, Final Batch Loss: 8.727005479158834e-05\n",
      "Epoch 2849, Loss: 0.0009983579766412731, Final Batch Loss: 0.0003739990061149001\n",
      "Epoch 2850, Loss: 0.00018083285249304026, Final Batch Loss: 4.7754096158314496e-05\n",
      "Epoch 2851, Loss: 0.001336130922936718, Final Batch Loss: 5.764488014392555e-05\n",
      "Epoch 2852, Loss: 0.000554177509911824, Final Batch Loss: 0.00016735409735701978\n",
      "Epoch 2853, Loss: 0.0013516192630049773, Final Batch Loss: 0.0010207926388829947\n",
      "Epoch 2854, Loss: 0.0109433015995819, Final Batch Loss: 1.2105029782105703e-05\n",
      "Epoch 2855, Loss: 0.0019367206732567865, Final Batch Loss: 4.155776332481764e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2856, Loss: 0.032373413100685866, Final Batch Loss: 0.03214109688997269\n",
      "Epoch 2857, Loss: 0.0009686927223810926, Final Batch Loss: 0.0006112370174378157\n",
      "Epoch 2858, Loss: 0.0006880491127958521, Final Batch Loss: 7.385392382275313e-05\n",
      "Epoch 2859, Loss: 0.00011046167435324605, Final Batch Loss: 1.3539957762986887e-05\n",
      "Epoch 2860, Loss: 0.0005700128795069759, Final Batch Loss: 8.704195352038369e-06\n",
      "Epoch 2861, Loss: 0.03194954495847924, Final Batch Loss: 0.0010259439004585147\n",
      "Epoch 2862, Loss: 0.0010545513323449995, Final Batch Loss: 0.0002888264134526253\n",
      "Epoch 2863, Loss: 0.0005628820545098279, Final Batch Loss: 0.00013816393038723618\n",
      "Epoch 2864, Loss: 0.005512106187779864, Final Batch Loss: 8.241701834776904e-06\n",
      "Epoch 2865, Loss: 0.0005180745301913703, Final Batch Loss: 8.461699326289818e-05\n",
      "Epoch 2866, Loss: 0.008372107835384668, Final Batch Loss: 0.008175789378583431\n",
      "Epoch 2867, Loss: 0.0007771470664010849, Final Batch Loss: 8.706600783625618e-05\n",
      "Epoch 2868, Loss: 0.0009641975120757706, Final Batch Loss: 2.628255242598243e-05\n",
      "Epoch 2869, Loss: 0.004817172861294239, Final Batch Loss: 0.004735980648547411\n",
      "Epoch 2870, Loss: 0.0009030623768921942, Final Batch Loss: 0.0004935755277983844\n",
      "Epoch 2871, Loss: 0.004914660214126343, Final Batch Loss: 0.0001463164371671155\n",
      "Epoch 2872, Loss: 0.0004600395513989497, Final Batch Loss: 0.00025609866133891046\n",
      "Epoch 2873, Loss: 0.03029991961466294, Final Batch Loss: 1.2653455087274779e-05\n",
      "Epoch 2874, Loss: 0.02961890327060246, Final Batch Loss: 6.374280928866938e-05\n",
      "Epoch 2875, Loss: 0.004610824204064556, Final Batch Loss: 1.4942661437089555e-05\n",
      "Epoch 2876, Loss: 0.0008707745946594514, Final Batch Loss: 0.00010333974933018908\n",
      "Epoch 2877, Loss: 0.0005041016920586117, Final Batch Loss: 0.00018460737192071974\n",
      "Epoch 2878, Loss: 0.0005824871950608213, Final Batch Loss: 2.5150980945909396e-05\n",
      "Epoch 2879, Loss: 0.00039314901005127467, Final Batch Loss: 3.2143016142072156e-05\n",
      "Epoch 2880, Loss: 0.001426040045771515, Final Batch Loss: 0.0012899235589429736\n",
      "Epoch 2881, Loss: 0.0009969197526515927, Final Batch Loss: 4.6282813855214044e-05\n",
      "Epoch 2882, Loss: 0.00046214847679948434, Final Batch Loss: 3.291627217549831e-05\n",
      "Epoch 2883, Loss: 0.009151720092631876, Final Batch Loss: 0.0004131672321818769\n",
      "Epoch 2884, Loss: 0.009909648837492568, Final Batch Loss: 3.575165101210587e-05\n",
      "Epoch 2885, Loss: 0.002034247365372721, Final Batch Loss: 0.00017666263738647103\n",
      "Epoch 2886, Loss: 0.00041720700119185494, Final Batch Loss: 7.35349822207354e-05\n",
      "Epoch 2887, Loss: 0.00044591167534235865, Final Batch Loss: 6.931091047590598e-05\n",
      "Epoch 2888, Loss: 0.0005561638354265597, Final Batch Loss: 0.00024278221826534718\n",
      "Epoch 2889, Loss: 0.0008521344038854295, Final Batch Loss: 0.00029131511109881103\n",
      "Epoch 2890, Loss: 0.005702916885638842, Final Batch Loss: 5.75401027163025e-05\n",
      "Epoch 2891, Loss: 0.0002693603000807343, Final Batch Loss: 4.2505118472035974e-05\n",
      "Epoch 2892, Loss: 0.0005043359487899579, Final Batch Loss: 5.9133693866897374e-05\n",
      "Epoch 2893, Loss: 0.013816817896440625, Final Batch Loss: 6.806985766161233e-05\n",
      "Epoch 2894, Loss: 0.0006659138707618695, Final Batch Loss: 0.00033496884861961007\n",
      "Epoch 2895, Loss: 0.0024667232573847286, Final Batch Loss: 6.989133544266224e-05\n",
      "Epoch 2896, Loss: 0.01057545782532543, Final Batch Loss: 0.00013300809951033443\n",
      "Epoch 2897, Loss: 0.0030734266692888923, Final Batch Loss: 5.015280476072803e-05\n",
      "Epoch 2898, Loss: 0.002243706738227047, Final Batch Loss: 0.00010460647899890319\n",
      "Epoch 2899, Loss: 0.0008149178793246392, Final Batch Loss: 5.989520650473423e-05\n",
      "Epoch 2900, Loss: 0.012283486168598756, Final Batch Loss: 0.00010815411224029958\n",
      "Epoch 2901, Loss: 0.001608299129657098, Final Batch Loss: 0.0006448471103794873\n",
      "Epoch 2902, Loss: 0.0006679035868728533, Final Batch Loss: 7.974467007443309e-05\n",
      "Epoch 2903, Loss: 0.017876554551548907, Final Batch Loss: 2.0470735762501135e-05\n",
      "Epoch 2904, Loss: 0.0008091642612271244, Final Batch Loss: 0.0002650744572747499\n",
      "Epoch 2905, Loss: 0.00471930632556905, Final Batch Loss: 0.00016844797937665135\n",
      "Epoch 2906, Loss: 0.0008660143794259056, Final Batch Loss: 4.819648165721446e-05\n",
      "Epoch 2907, Loss: 0.000879287748830393, Final Batch Loss: 0.00030441884882748127\n",
      "Epoch 2908, Loss: 0.004093743598787114, Final Batch Loss: 0.003722732188180089\n",
      "Epoch 2909, Loss: 0.00036818499211221933, Final Batch Loss: 0.00014920119429007173\n",
      "Epoch 2910, Loss: 0.0006254938061829307, Final Batch Loss: 0.00021843174181412905\n",
      "Epoch 2911, Loss: 0.0005767322800238617, Final Batch Loss: 0.00013501039939001203\n",
      "Epoch 2912, Loss: 0.0024151579273166135, Final Batch Loss: 0.0006261865491978824\n",
      "Epoch 2913, Loss: 0.0006812944920966402, Final Batch Loss: 0.0003586291568353772\n",
      "Epoch 2914, Loss: 0.001222814458742505, Final Batch Loss: 5.932153362664394e-05\n",
      "Epoch 2915, Loss: 0.0020037746071466245, Final Batch Loss: 0.0002732879074756056\n",
      "Epoch 2916, Loss: 0.0006741365359630436, Final Batch Loss: 5.154356767889112e-05\n",
      "Epoch 2917, Loss: 0.0013204843935454846, Final Batch Loss: 1.1457735126896296e-05\n",
      "Epoch 2918, Loss: 0.001952462742337957, Final Batch Loss: 4.310927033657208e-05\n",
      "Epoch 2919, Loss: 0.003300090143966372, Final Batch Loss: 5.005082130082883e-05\n",
      "Epoch 2920, Loss: 0.0028333854174888984, Final Batch Loss: 4.997875748813385e-06\n",
      "Epoch 2921, Loss: 0.0007631457992829382, Final Batch Loss: 9.572692215442657e-05\n",
      "Epoch 2922, Loss: 0.003641159550170414, Final Batch Loss: 9.027184569276869e-05\n",
      "Epoch 2923, Loss: 0.0014322360220830888, Final Batch Loss: 9.663101809564978e-05\n",
      "Epoch 2924, Loss: 0.0005487860908033326, Final Batch Loss: 7.070740684866905e-05\n",
      "Epoch 2925, Loss: 0.0007077703485265374, Final Batch Loss: 0.00016593592590652406\n",
      "Epoch 2926, Loss: 0.0005775539066235069, Final Batch Loss: 5.344205419532955e-05\n",
      "Epoch 2927, Loss: 0.0006470171319961082, Final Batch Loss: 0.0001506381231592968\n",
      "Epoch 2928, Loss: 0.0005691520268555905, Final Batch Loss: 7.94198494986631e-05\n",
      "Epoch 2929, Loss: 0.0015722267335149809, Final Batch Loss: 9.249640243069734e-06\n",
      "Epoch 2930, Loss: 0.0026171973968303064, Final Batch Loss: 0.0008901493274606764\n",
      "Epoch 2931, Loss: 0.000895030307219713, Final Batch Loss: 4.594689016812481e-06\n",
      "Epoch 2932, Loss: 0.0002073528730761609, Final Batch Loss: 1.3977184607938398e-05\n",
      "Epoch 2933, Loss: 0.0011158483284816612, Final Batch Loss: 0.0003529786190483719\n",
      "Epoch 2934, Loss: 0.0003721965586009901, Final Batch Loss: 2.5850644306046888e-05\n",
      "Epoch 2935, Loss: 0.0008655699693917995, Final Batch Loss: 2.824148214131128e-05\n",
      "Epoch 2936, Loss: 0.0024741919769439846, Final Batch Loss: 0.00015522728790529072\n",
      "Epoch 2937, Loss: 0.005534658770557144, Final Batch Loss: 0.00522189075127244\n",
      "Epoch 2938, Loss: 0.0009224537043337477, Final Batch Loss: 0.0005185167538002133\n",
      "Epoch 2939, Loss: 0.012627432772205793, Final Batch Loss: 1.5538151274085976e-05\n",
      "Epoch 2940, Loss: 0.0007728520831733476, Final Batch Loss: 4.93650404678192e-05\n",
      "Epoch 2941, Loss: 0.0005952676419838099, Final Batch Loss: 3.927217039745301e-05\n",
      "Epoch 2942, Loss: 0.003211113044017111, Final Batch Loss: 0.00017643094179220498\n",
      "Epoch 2943, Loss: 0.0002708254014578415, Final Batch Loss: 2.52941590588307e-05\n",
      "Epoch 2944, Loss: 0.0003874771373375552, Final Batch Loss: 1.8212662325822748e-05\n",
      "Epoch 2945, Loss: 0.008704051333552343, Final Batch Loss: 0.0003832356887869537\n",
      "Epoch 2946, Loss: 0.0007533337120548822, Final Batch Loss: 0.00010648448369465768\n",
      "Epoch 2947, Loss: 0.0018040129616565537, Final Batch Loss: 0.000175397377461195\n",
      "Epoch 2948, Loss: 0.0016117957320602727, Final Batch Loss: 2.538271110097412e-05\n",
      "Epoch 2949, Loss: 0.0012815121681342134, Final Batch Loss: 3.0166100259521045e-05\n",
      "Epoch 2950, Loss: 0.000310395867927582, Final Batch Loss: 3.339891918585636e-05\n",
      "Epoch 2951, Loss: 0.00022068345970183145, Final Batch Loss: 3.540522448020056e-05\n",
      "Epoch 2952, Loss: 0.000561102469873731, Final Batch Loss: 0.00014951714547351003\n",
      "Epoch 2953, Loss: 0.004967697426764062, Final Batch Loss: 3.408350676181726e-05\n",
      "Epoch 2954, Loss: 0.0003054673579754308, Final Batch Loss: 0.00010756817937362939\n",
      "Epoch 2955, Loss: 0.0005046729056630284, Final Batch Loss: 8.71118318173103e-05\n",
      "Epoch 2956, Loss: 0.0009520684034214355, Final Batch Loss: 8.350579446414486e-05\n",
      "Epoch 2957, Loss: 0.00045736781248706393, Final Batch Loss: 4.751983942696825e-05\n",
      "Epoch 2958, Loss: 0.008028397409361787, Final Batch Loss: 3.382668364793062e-05\n",
      "Epoch 2959, Loss: 0.000485163189296145, Final Batch Loss: 0.0002498352841939777\n",
      "Epoch 2960, Loss: 0.0019776810513576493, Final Batch Loss: 0.0008965067681856453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2961, Loss: 0.013179125760871102, Final Batch Loss: 2.2664085918222554e-05\n",
      "Epoch 2962, Loss: 0.01580977339472156, Final Batch Loss: 0.0004898031475022435\n",
      "Epoch 2963, Loss: 0.02548177841526922, Final Batch Loss: 0.02059507928788662\n",
      "Epoch 2964, Loss: 0.0010893897233472671, Final Batch Loss: 1.0435385775053874e-05\n",
      "Epoch 2965, Loss: 0.00043813439151563216, Final Batch Loss: 2.647315886861179e-05\n",
      "Epoch 2966, Loss: 0.00028032754198648036, Final Batch Loss: 3.1233714253176004e-05\n",
      "Epoch 2967, Loss: 0.00831456421292387, Final Batch Loss: 0.0006831131759099662\n",
      "Epoch 2968, Loss: 0.001329626735241618, Final Batch Loss: 0.00011576110409805551\n",
      "Epoch 2969, Loss: 0.009940989984897897, Final Batch Loss: 0.000297763996059075\n",
      "Epoch 2970, Loss: 0.0013058637996437028, Final Batch Loss: 8.148894994519651e-05\n",
      "Epoch 2971, Loss: 0.0005339878716767998, Final Batch Loss: 0.00020764340297318995\n",
      "Epoch 2972, Loss: 0.019820992793938785, Final Batch Loss: 0.014214455150067806\n",
      "Epoch 2973, Loss: 0.008272261326055741, Final Batch Loss: 9.172604040941224e-05\n",
      "Epoch 2974, Loss: 0.0017492967817815952, Final Batch Loss: 0.0011263523483648896\n",
      "Epoch 2975, Loss: 0.0019613548283814453, Final Batch Loss: 0.00031973872683010995\n",
      "Epoch 2976, Loss: 0.0022790397706557997, Final Batch Loss: 0.00010819320596056059\n",
      "Epoch 2977, Loss: 0.243502856901614, Final Batch Loss: 0.2257317155599594\n",
      "Epoch 2978, Loss: 0.0013441847204376245, Final Batch Loss: 8.4547747974284e-05\n",
      "Epoch 2979, Loss: 0.02274127462078468, Final Batch Loss: 4.2821393435588107e-05\n",
      "Epoch 2980, Loss: 0.0046914502272557, Final Batch Loss: 4.6736891818000004e-05\n",
      "Epoch 2981, Loss: 0.019356962009624112, Final Batch Loss: 0.00020235181727912277\n",
      "Epoch 2982, Loss: 0.009623464691685513, Final Batch Loss: 0.0002751420543063432\n",
      "Epoch 2983, Loss: 0.02859365772746969, Final Batch Loss: 0.0001494445459684357\n",
      "Epoch 2984, Loss: 0.0008229669601860223, Final Batch Loss: 1.7359530829708092e-05\n",
      "Epoch 2985, Loss: 0.0017398931777279358, Final Batch Loss: 0.0002730322303250432\n",
      "Epoch 2986, Loss: 0.005935591994784772, Final Batch Loss: 0.0019936482422053814\n",
      "Epoch 2987, Loss: 0.023756284746923484, Final Batch Loss: 9.599006443750113e-05\n",
      "Epoch 2988, Loss: 0.0005850651141372509, Final Batch Loss: 6.40095749986358e-05\n",
      "Epoch 2989, Loss: 0.0007966064949869178, Final Batch Loss: 5.837404023623094e-05\n",
      "Epoch 2990, Loss: 0.0007795178753440268, Final Batch Loss: 0.00016514262824784964\n",
      "Epoch 2991, Loss: 0.002789884907542728, Final Batch Loss: 7.222672866191715e-05\n",
      "Epoch 2992, Loss: 0.004698219905549195, Final Batch Loss: 7.079686474753544e-05\n",
      "Epoch 2993, Loss: 0.0016062464928836562, Final Batch Loss: 0.00127091770991683\n",
      "Epoch 2994, Loss: 0.0027042688452638686, Final Batch Loss: 0.0006277913926169276\n",
      "Epoch 2995, Loss: 0.0014179881836753339, Final Batch Loss: 0.0004907339462079108\n",
      "Epoch 2996, Loss: 0.002709857315494446, Final Batch Loss: 5.1439314120216295e-05\n",
      "Epoch 2997, Loss: 0.0017348399996990338, Final Batch Loss: 4.09222993766889e-05\n",
      "Epoch 2998, Loss: 0.0012444443145795958, Final Batch Loss: 2.2137932319310494e-05\n",
      "Epoch 2999, Loss: 0.004826106771361083, Final Batch Loss: 0.0004887028480879962\n",
      "Epoch 3000, Loss: 0.0014093417121330276, Final Batch Loss: 0.000237023807130754\n",
      "Epoch 3001, Loss: 0.01586287959071342, Final Batch Loss: 0.0001280051510548219\n",
      "Epoch 3002, Loss: 0.0018482595405657776, Final Batch Loss: 0.0012362099951133132\n",
      "Epoch 3003, Loss: 0.002168643124605296, Final Batch Loss: 0.00018310999439563602\n",
      "Epoch 3004, Loss: 0.015947577994666062, Final Batch Loss: 0.0008508287719450891\n",
      "Epoch 3005, Loss: 0.0007427511554851662, Final Batch Loss: 5.7011366152437404e-05\n",
      "Epoch 3006, Loss: 0.00218941830098629, Final Batch Loss: 0.00028578381170518696\n",
      "Epoch 3007, Loss: 0.0013231182529125363, Final Batch Loss: 0.00031581197981722653\n",
      "Epoch 3008, Loss: 0.0016092460173240397, Final Batch Loss: 1.4374341844813898e-05\n",
      "Epoch 3009, Loss: 0.0032901370577747002, Final Batch Loss: 0.0017272474942728877\n",
      "Epoch 3010, Loss: 0.0007875563751440495, Final Batch Loss: 0.0002659764140844345\n",
      "Epoch 3011, Loss: 0.0012727226712740958, Final Batch Loss: 0.00023899346706457436\n",
      "Epoch 3012, Loss: 0.0008323076690430753, Final Batch Loss: 0.00010101951920660213\n",
      "Epoch 3013, Loss: 0.008710888258065097, Final Batch Loss: 0.00022061288473196328\n",
      "Epoch 3014, Loss: 0.0009671308434917592, Final Batch Loss: 0.00046363301225937903\n",
      "Epoch 3015, Loss: 0.0032660174183547497, Final Batch Loss: 0.002551864366978407\n",
      "Epoch 3016, Loss: 0.018313721986487508, Final Batch Loss: 0.0006419304991140962\n",
      "Epoch 3017, Loss: 0.0005867964118806412, Final Batch Loss: 2.0886958736809902e-05\n",
      "Epoch 3018, Loss: 0.014476850599749014, Final Batch Loss: 0.0004576187639031559\n",
      "Epoch 3019, Loss: 0.0010939961321128067, Final Batch Loss: 3.669179568532854e-05\n",
      "Epoch 3020, Loss: 0.008227387792430818, Final Batch Loss: 0.003977723885327578\n",
      "Epoch 3021, Loss: 0.0024430976081930567, Final Batch Loss: 0.0018121934263035655\n",
      "Epoch 3022, Loss: 0.001210090318636503, Final Batch Loss: 0.00019435393915046006\n",
      "Epoch 3023, Loss: 0.0004916058969683945, Final Batch Loss: 8.456618525087833e-05\n",
      "Epoch 3024, Loss: 0.0011123279837192968, Final Batch Loss: 7.554041803814471e-05\n",
      "Epoch 3025, Loss: 0.0007792787364451215, Final Batch Loss: 3.2411597203463316e-05\n",
      "Epoch 3026, Loss: 0.00472274641651893, Final Batch Loss: 4.024688678327948e-05\n",
      "Epoch 3027, Loss: 0.013411577830993338, Final Batch Loss: 0.00010904904047492892\n",
      "Epoch 3028, Loss: 0.003450470198004041, Final Batch Loss: 0.0006463602767325938\n",
      "Epoch 3029, Loss: 0.0008784754172665998, Final Batch Loss: 0.00017009887960739434\n",
      "Epoch 3030, Loss: 0.0016972646917565726, Final Batch Loss: 7.808552618371323e-05\n",
      "Epoch 3031, Loss: 0.0006154793791210977, Final Batch Loss: 1.7643860701355152e-05\n",
      "Epoch 3032, Loss: 0.0018759522099571768, Final Batch Loss: 9.357497037854046e-05\n",
      "Epoch 3033, Loss: 0.0008885699935490265, Final Batch Loss: 0.00010274456872139126\n",
      "Epoch 3034, Loss: 0.002463697466737358, Final Batch Loss: 0.00040384632302448153\n",
      "Epoch 3035, Loss: 0.0011586402615648694, Final Batch Loss: 0.000691942113917321\n",
      "Epoch 3036, Loss: 0.0013248738105176017, Final Batch Loss: 0.000788712059147656\n",
      "Epoch 3037, Loss: 0.037677580665331334, Final Batch Loss: 0.0017281821928918362\n",
      "Epoch 3038, Loss: 0.0007232424804897164, Final Batch Loss: 1.0158267286897171e-05\n",
      "Epoch 3039, Loss: 0.0005670328719133977, Final Batch Loss: 5.0640101108001545e-05\n",
      "Epoch 3040, Loss: 0.0012488094043874298, Final Batch Loss: 0.00023764125944580883\n",
      "Epoch 3041, Loss: 0.000587094655202236, Final Batch Loss: 0.00045258994214236736\n",
      "Epoch 3042, Loss: 0.0005836923573951935, Final Batch Loss: 2.7260228307568468e-05\n",
      "Epoch 3043, Loss: 0.03251540636847494, Final Batch Loss: 0.030897017568349838\n",
      "Epoch 3044, Loss: 0.0006778701645089313, Final Batch Loss: 7.665515295229852e-05\n",
      "Epoch 3045, Loss: 0.0015296614474209491, Final Batch Loss: 5.81640015298035e-05\n",
      "Epoch 3046, Loss: 0.0007460268207069021, Final Batch Loss: 6.015227336320095e-05\n",
      "Epoch 3047, Loss: 0.0007299754797713831, Final Batch Loss: 0.00039600106538273394\n",
      "Epoch 3048, Loss: 0.0011617212876444682, Final Batch Loss: 0.0002646131324581802\n",
      "Epoch 3049, Loss: 0.0011820571817224845, Final Batch Loss: 7.459690823452547e-05\n",
      "Epoch 3050, Loss: 0.0009683840034995228, Final Batch Loss: 0.00010605884745018557\n",
      "Epoch 3051, Loss: 0.0007634925605088938, Final Batch Loss: 6.479120202129707e-06\n",
      "Epoch 3052, Loss: 0.001455800505937077, Final Batch Loss: 0.0006477704737335443\n",
      "Epoch 3053, Loss: 0.0006222956435522065, Final Batch Loss: 0.00013729643251281232\n",
      "Epoch 3054, Loss: 0.0008250385399151128, Final Batch Loss: 0.0003112709673587233\n",
      "Epoch 3055, Loss: 0.0005618558061541989, Final Batch Loss: 0.00016615500499028713\n",
      "Epoch 3056, Loss: 0.00042144578037550673, Final Batch Loss: 5.7242592447437346e-05\n",
      "Epoch 3057, Loss: 0.000433119173067098, Final Batch Loss: 0.00015634260489605367\n",
      "Epoch 3058, Loss: 0.0005979147099424154, Final Batch Loss: 0.00010467914398759604\n",
      "Epoch 3059, Loss: 0.0010009161924244836, Final Batch Loss: 8.152052032528445e-05\n",
      "Epoch 3060, Loss: 0.0006876598345115781, Final Batch Loss: 0.0003371307975612581\n",
      "Epoch 3061, Loss: 0.0012052615893480834, Final Batch Loss: 0.00042531429789960384\n",
      "Epoch 3062, Loss: 0.002208944941230584, Final Batch Loss: 0.0013597131473943591\n",
      "Epoch 3063, Loss: 0.0010565542033873498, Final Batch Loss: 0.0004529908765107393\n",
      "Epoch 3064, Loss: 0.0004311207558203023, Final Batch Loss: 0.0002521222340874374\n",
      "Epoch 3065, Loss: 0.00012061372353855404, Final Batch Loss: 2.3201560907182284e-05\n",
      "Epoch 3066, Loss: 0.0007275199095602147, Final Batch Loss: 9.348283492727205e-05\n",
      "Epoch 3067, Loss: 0.002001146523980424, Final Batch Loss: 0.00012581728515215218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3068, Loss: 0.0012023075723845977, Final Batch Loss: 2.0309375031501986e-05\n",
      "Epoch 3069, Loss: 0.0012135052525081846, Final Batch Loss: 0.000980155193246901\n",
      "Epoch 3070, Loss: 0.0003867059058393352, Final Batch Loss: 8.944558067014441e-05\n",
      "Epoch 3071, Loss: 0.0005329029518179595, Final Batch Loss: 8.537551912013441e-05\n",
      "Epoch 3072, Loss: 0.002402926438662689, Final Batch Loss: 0.001730946241877973\n",
      "Epoch 3073, Loss: 0.00038937113549764035, Final Batch Loss: 0.0002677191805560142\n",
      "Epoch 3074, Loss: 0.0008131108552333899, Final Batch Loss: 0.0003515041898936033\n",
      "Epoch 3075, Loss: 0.0003652157392934896, Final Batch Loss: 9.275776392314583e-05\n",
      "Epoch 3076, Loss: 0.0006442055200750474, Final Batch Loss: 0.0005814617034047842\n",
      "Epoch 3077, Loss: 0.00044290386904322077, Final Batch Loss: 0.00019621853425633162\n",
      "Epoch 3078, Loss: 0.000508597517182352, Final Batch Loss: 0.00026198424166068435\n",
      "Epoch 3079, Loss: 0.0002466707010171376, Final Batch Loss: 6.631405994994566e-05\n",
      "Epoch 3080, Loss: 0.005358688865271688, Final Batch Loss: 1.0818189366545994e-05\n",
      "Epoch 3081, Loss: 0.001072703673344222, Final Batch Loss: 0.00023029207659419626\n",
      "Epoch 3082, Loss: 0.0007456660678144544, Final Batch Loss: 1.2825355952372774e-05\n",
      "Epoch 3083, Loss: 0.0009563702005834784, Final Batch Loss: 5.311323548085056e-05\n",
      "Epoch 3084, Loss: 0.0006397730157914339, Final Batch Loss: 0.00025847615324892104\n",
      "Epoch 3085, Loss: 0.0029911427513980016, Final Batch Loss: 0.0013800137676298618\n",
      "Epoch 3086, Loss: 0.001189824813081941, Final Batch Loss: 0.00011129778431495652\n",
      "Epoch 3087, Loss: 0.02340843482670607, Final Batch Loss: 0.01382453739643097\n",
      "Epoch 3088, Loss: 0.0006853478262200952, Final Batch Loss: 9.622862853575498e-05\n",
      "Epoch 3089, Loss: 0.02175993785931496, Final Batch Loss: 0.00047882081707939506\n",
      "Epoch 3090, Loss: 0.003323034494314925, Final Batch Loss: 1.1246958820265718e-05\n",
      "Epoch 3091, Loss: 0.0011093749481005943, Final Batch Loss: 0.0005874106427654624\n",
      "Epoch 3092, Loss: 0.023705488651103224, Final Batch Loss: 0.00025048639508895576\n",
      "Epoch 3093, Loss: 0.002461774456605781, Final Batch Loss: 0.002181106014177203\n",
      "Epoch 3094, Loss: 0.0005458189334603958, Final Batch Loss: 0.0001924690295709297\n",
      "Epoch 3095, Loss: 0.0007430743862641975, Final Batch Loss: 0.00036363996332511306\n",
      "Epoch 3096, Loss: 0.001169193841633387, Final Batch Loss: 0.0004146959981881082\n",
      "Epoch 3097, Loss: 0.001552168370835716, Final Batch Loss: 0.0005741672939620912\n",
      "Epoch 3098, Loss: 0.0017666244857537095, Final Batch Loss: 8.208212238969281e-05\n",
      "Epoch 3099, Loss: 0.013303041703693452, Final Batch Loss: 1.5945332052069716e-05\n",
      "Epoch 3100, Loss: 0.0004756203416036442, Final Batch Loss: 8.658413571538404e-05\n",
      "Epoch 3101, Loss: 0.0007972599578351947, Final Batch Loss: 0.00040060089668259025\n",
      "Epoch 3102, Loss: 0.019307833579659928, Final Batch Loss: 7.991679740371183e-05\n",
      "Epoch 3103, Loss: 0.00014095329606789164, Final Batch Loss: 1.933357816596981e-05\n",
      "Epoch 3104, Loss: 0.0016873259883141145, Final Batch Loss: 0.0002879458770621568\n",
      "Epoch 3105, Loss: 0.02920504011808589, Final Batch Loss: 0.00022098144108895212\n",
      "Epoch 3106, Loss: 0.0008574998792028055, Final Batch Loss: 0.00013624616258312017\n",
      "Epoch 3107, Loss: 0.06801511362573365, Final Batch Loss: 0.06520088762044907\n",
      "Epoch 3108, Loss: 0.0006522433468489908, Final Batch Loss: 0.00011723284114850685\n",
      "Epoch 3109, Loss: 0.001620977573111304, Final Batch Loss: 2.752030013652984e-05\n",
      "Epoch 3110, Loss: 0.008141288119077217, Final Batch Loss: 0.0014716373989358544\n",
      "Epoch 3111, Loss: 0.009993812673201319, Final Batch Loss: 6.675264012301341e-05\n",
      "Epoch 3112, Loss: 0.002244271875497361, Final Batch Loss: 9.275811862607952e-06\n",
      "Epoch 3113, Loss: 0.0024047280312515795, Final Batch Loss: 5.04068739246577e-05\n",
      "Epoch 3114, Loss: 0.0005024942947784439, Final Batch Loss: 3.3247873943764716e-05\n",
      "Epoch 3115, Loss: 0.004090903785254341, Final Batch Loss: 0.00010361511522205546\n",
      "Epoch 3116, Loss: 0.0013139731745468453, Final Batch Loss: 0.0001165655703516677\n",
      "Epoch 3117, Loss: 0.000951471511143609, Final Batch Loss: 0.0002787807025015354\n",
      "Epoch 3118, Loss: 0.001244465847776155, Final Batch Loss: 1.554336449771654e-05\n",
      "Epoch 3119, Loss: 0.0025955684322980233, Final Batch Loss: 0.0006295361672528088\n",
      "Epoch 3120, Loss: 0.0011252412314206595, Final Batch Loss: 2.151609987777192e-05\n",
      "Epoch 3121, Loss: 0.0037599375064019114, Final Batch Loss: 0.000922194798476994\n",
      "Epoch 3122, Loss: 0.025848860099358717, Final Batch Loss: 6.979983299970627e-05\n",
      "Epoch 3123, Loss: 0.001442607826902531, Final Batch Loss: 0.00028386511257849634\n",
      "Epoch 3124, Loss: 0.0037006008642492816, Final Batch Loss: 0.0002656257711350918\n",
      "Epoch 3125, Loss: 0.0014624416071455926, Final Batch Loss: 0.0002598590508569032\n",
      "Epoch 3126, Loss: 0.0031670497519371565, Final Batch Loss: 0.002436992945149541\n",
      "Epoch 3127, Loss: 0.0007052844430290861, Final Batch Loss: 0.0004547967982944101\n",
      "Epoch 3128, Loss: 0.0009060608772415435, Final Batch Loss: 2.959555604320485e-05\n",
      "Epoch 3129, Loss: 0.0005884776546736248, Final Batch Loss: 0.00011923514830414206\n",
      "Epoch 3130, Loss: 0.007761617976939306, Final Batch Loss: 0.00019210732716601342\n",
      "Epoch 3131, Loss: 0.002196492481743917, Final Batch Loss: 2.507933822926134e-05\n",
      "Epoch 3132, Loss: 0.0005959308946330566, Final Batch Loss: 3.728823867277242e-05\n",
      "Epoch 3133, Loss: 0.0025411259557586163, Final Batch Loss: 0.00031733408104628325\n",
      "Epoch 3134, Loss: 0.0003621289233706193, Final Batch Loss: 0.00019420405442360789\n",
      "Epoch 3135, Loss: 0.0003905091871274635, Final Batch Loss: 0.00010355392441852018\n",
      "Epoch 3136, Loss: 0.000656252585031325, Final Batch Loss: 0.00017031824972946197\n",
      "Epoch 3137, Loss: 0.002209539590694476, Final Batch Loss: 6.226544064702466e-05\n",
      "Epoch 3138, Loss: 0.002563563834883098, Final Batch Loss: 1.0980617844325025e-05\n",
      "Epoch 3139, Loss: 0.00038922904604987707, Final Batch Loss: 0.000101275640190579\n",
      "Epoch 3140, Loss: 0.0008409895090153441, Final Batch Loss: 0.00011584067397052422\n",
      "Epoch 3141, Loss: 0.0012716758910755743, Final Batch Loss: 1.5190821613941807e-05\n",
      "Epoch 3142, Loss: 0.000878486294823233, Final Batch Loss: 0.0002066729066427797\n",
      "Epoch 3143, Loss: 0.00075576741801342, Final Batch Loss: 0.00034138213959522545\n",
      "Epoch 3144, Loss: 0.00498496665568382, Final Batch Loss: 5.681511902366765e-05\n",
      "Epoch 3145, Loss: 0.0006177774776006117, Final Batch Loss: 0.0001380144531140104\n",
      "Epoch 3146, Loss: 0.0008040762622840703, Final Batch Loss: 0.00010820903116837144\n",
      "Epoch 3147, Loss: 0.00027271261387795676, Final Batch Loss: 2.8118685804656707e-05\n",
      "Epoch 3148, Loss: 0.0003613697554101236, Final Batch Loss: 8.986596367321908e-05\n",
      "Epoch 3149, Loss: 0.0009079050905711483, Final Batch Loss: 4.898749102721922e-05\n",
      "Epoch 3150, Loss: 0.0005435319726529997, Final Batch Loss: 6.584290531463921e-06\n",
      "Epoch 3151, Loss: 0.0007804418783052824, Final Batch Loss: 0.00011506840382935479\n",
      "Epoch 3152, Loss: 0.0004025647394882981, Final Batch Loss: 7.303086022147909e-05\n",
      "Epoch 3153, Loss: 0.0004178536109975539, Final Batch Loss: 0.00015483763127122074\n",
      "Epoch 3154, Loss: 0.006018083360686433, Final Batch Loss: 0.0012516130227595568\n",
      "Epoch 3155, Loss: 0.004338014259701595, Final Batch Loss: 0.001695915125310421\n",
      "Epoch 3156, Loss: 0.0011091125852544792, Final Batch Loss: 0.0002322101208847016\n",
      "Epoch 3157, Loss: 0.0004925435532641131, Final Batch Loss: 8.249904931290075e-05\n",
      "Epoch 3158, Loss: 0.024808553302136716, Final Batch Loss: 6.698619108647108e-05\n",
      "Epoch 3159, Loss: 0.010400502240372589, Final Batch Loss: 5.10580612171907e-05\n",
      "Epoch 3160, Loss: 0.000379531760700047, Final Batch Loss: 3.1493411370320246e-05\n",
      "Epoch 3161, Loss: 0.0016010000836104155, Final Batch Loss: 0.00039008582825772464\n",
      "Epoch 3162, Loss: 0.0069957611958670896, Final Batch Loss: 0.00010889038821915165\n",
      "Epoch 3163, Loss: 0.0015389801264973357, Final Batch Loss: 0.00041222202708013356\n",
      "Epoch 3164, Loss: 0.0030762794849579223, Final Batch Loss: 0.0006249335128813982\n",
      "Epoch 3165, Loss: 0.0015125392965273932, Final Batch Loss: 8.154557144735008e-05\n",
      "Epoch 3166, Loss: 0.0007162276961025782, Final Batch Loss: 0.0002754991874098778\n",
      "Epoch 3167, Loss: 0.00029665350120922085, Final Batch Loss: 4.6652905439259484e-05\n",
      "Epoch 3168, Loss: 0.0005366941841202788, Final Batch Loss: 0.00019730169151443988\n",
      "Epoch 3169, Loss: 0.0008940372572396882, Final Batch Loss: 0.0005372515879571438\n",
      "Epoch 3170, Loss: 0.0013936918949184474, Final Batch Loss: 1.1596403055591509e-05\n",
      "Epoch 3171, Loss: 0.0016865728493939969, Final Batch Loss: 3.070899401791394e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3172, Loss: 0.0013403830962488428, Final Batch Loss: 0.0007787052891217172\n",
      "Epoch 3173, Loss: 0.0011801505752373487, Final Batch Loss: 0.00016432350093964487\n",
      "Epoch 3174, Loss: 0.000413203702919418, Final Batch Loss: 2.1994987037032843e-05\n",
      "Epoch 3175, Loss: 0.0021348861118895, Final Batch Loss: 9.357975068269297e-05\n",
      "Epoch 3176, Loss: 0.00055793236970203, Final Batch Loss: 0.00018989188538398594\n",
      "Epoch 3177, Loss: 0.00026555017007012793, Final Batch Loss: 2.8799001938750735e-06\n",
      "Epoch 3178, Loss: 0.0010866010416066274, Final Batch Loss: 0.00024817598750814795\n",
      "Epoch 3179, Loss: 0.0010417501616757363, Final Batch Loss: 0.0006483004544861615\n",
      "Epoch 3180, Loss: 0.0007485496971639805, Final Batch Loss: 8.394048927584663e-05\n",
      "Epoch 3181, Loss: 0.0005916678528592456, Final Batch Loss: 0.0003076617431361228\n",
      "Epoch 3182, Loss: 0.000779583958319563, Final Batch Loss: 0.0006197766051627696\n",
      "Epoch 3183, Loss: 0.0012498146897996776, Final Batch Loss: 3.730121534317732e-05\n",
      "Epoch 3184, Loss: 0.0016640088742860826, Final Batch Loss: 4.265139068593271e-06\n",
      "Epoch 3185, Loss: 0.001013258295643027, Final Batch Loss: 0.000674889946822077\n",
      "Epoch 3186, Loss: 0.0003887981874868274, Final Batch Loss: 0.00018779331003315747\n",
      "Epoch 3187, Loss: 0.0007381919931503944, Final Batch Loss: 6.828307959949598e-05\n",
      "Epoch 3188, Loss: 0.00021483517411979847, Final Batch Loss: 9.053402027348056e-05\n",
      "Epoch 3189, Loss: 0.0008848471070450614, Final Batch Loss: 0.00042691940325312316\n",
      "Epoch 3190, Loss: 0.0009342519042547792, Final Batch Loss: 0.00011134981468785554\n",
      "Epoch 3191, Loss: 0.0010391266023361823, Final Batch Loss: 4.405143408803269e-05\n",
      "Epoch 3192, Loss: 0.0004078479960298864, Final Batch Loss: 3.480005398159847e-05\n",
      "Epoch 3193, Loss: 0.0013479202461894602, Final Batch Loss: 7.875285518821329e-05\n",
      "Epoch 3194, Loss: 0.0018936420106001606, Final Batch Loss: 2.000587664952036e-05\n",
      "Epoch 3195, Loss: 0.0008683141204528511, Final Batch Loss: 0.0005851376918144524\n",
      "Epoch 3196, Loss: 0.0005864581144123804, Final Batch Loss: 0.0003104718925897032\n",
      "Epoch 3197, Loss: 0.004097915598322288, Final Batch Loss: 9.916939234244637e-06\n",
      "Epoch 3198, Loss: 0.00022536392134497873, Final Batch Loss: 3.56914424628485e-05\n",
      "Epoch 3199, Loss: 0.0024306082668772433, Final Batch Loss: 1.4181041478877887e-05\n",
      "Epoch 3200, Loss: 0.0004076909626746783, Final Batch Loss: 8.885954230208881e-06\n",
      "Epoch 3201, Loss: 0.007848881825339049, Final Batch Loss: 0.006682868115603924\n",
      "Epoch 3202, Loss: 0.0003000809265358839, Final Batch Loss: 2.1037878468632698e-05\n",
      "Epoch 3203, Loss: 0.001440436759367003, Final Batch Loss: 0.0011466735741123557\n",
      "Epoch 3204, Loss: 0.000517062064318452, Final Batch Loss: 0.00013559023500420153\n",
      "Epoch 3205, Loss: 0.00126064693358785, Final Batch Loss: 7.36527144908905e-05\n",
      "Epoch 3206, Loss: 0.0003136290797556285, Final Batch Loss: 4.3097319576190785e-05\n",
      "Epoch 3207, Loss: 0.00014176911190588726, Final Batch Loss: 1.1612575690378435e-05\n",
      "Epoch 3208, Loss: 0.03034690866843448, Final Batch Loss: 0.0011279803002253175\n",
      "Epoch 3209, Loss: 0.002054037271591369, Final Batch Loss: 3.251725865993649e-05\n",
      "Epoch 3210, Loss: 0.00044431151400203817, Final Batch Loss: 7.7292941568885e-05\n",
      "Epoch 3211, Loss: 0.001113223668653518, Final Batch Loss: 0.0006653440068475902\n",
      "Epoch 3212, Loss: 0.0005580530923907645, Final Batch Loss: 0.00018718688806984574\n",
      "Epoch 3213, Loss: 0.0340467703063041, Final Batch Loss: 0.00028294292860664427\n",
      "Epoch 3214, Loss: 0.005987383570754901, Final Batch Loss: 0.00019908579997718334\n",
      "Epoch 3215, Loss: 0.0009917887800838798, Final Batch Loss: 3.750350879272446e-05\n",
      "Epoch 3216, Loss: 0.0011761300265789032, Final Batch Loss: 9.653306915424764e-05\n",
      "Epoch 3217, Loss: 0.01738597185612889, Final Batch Loss: 0.0001076437984011136\n",
      "Epoch 3218, Loss: 0.0011895668922079494, Final Batch Loss: 1.9467470337986015e-05\n",
      "Epoch 3219, Loss: 0.0005274719151202589, Final Batch Loss: 4.173405250185169e-05\n",
      "Epoch 3220, Loss: 0.0008903926529910677, Final Batch Loss: 1.8007747712545097e-05\n",
      "Epoch 3221, Loss: 0.00019769881419051671, Final Batch Loss: 1.1643272046057973e-05\n",
      "Epoch 3222, Loss: 0.00039197475416585803, Final Batch Loss: 4.5774948375765234e-05\n",
      "Epoch 3223, Loss: 0.02545100304632797, Final Batch Loss: 0.00032886076951399446\n",
      "Epoch 3224, Loss: 0.0008969865102699259, Final Batch Loss: 0.0007181719993241131\n",
      "Epoch 3225, Loss: 0.0008704602150828578, Final Batch Loss: 0.00015330839960370213\n",
      "Epoch 3226, Loss: 0.0008815374540063203, Final Batch Loss: 0.0005085219745524228\n",
      "Epoch 3227, Loss: 0.00024494198623870034, Final Batch Loss: 0.00014647246280219406\n",
      "Epoch 3228, Loss: 0.0014337760221678764, Final Batch Loss: 0.0004748770734295249\n",
      "Epoch 3229, Loss: 0.029992256611876655, Final Batch Loss: 0.00011731126141967252\n",
      "Epoch 3230, Loss: 0.0009837468460318632, Final Batch Loss: 9.520276944385841e-05\n",
      "Epoch 3231, Loss: 0.0013411625259323046, Final Batch Loss: 0.0003006414626725018\n",
      "Epoch 3232, Loss: 0.008507419455781928, Final Batch Loss: 2.390784902672749e-05\n",
      "Epoch 3233, Loss: 0.0016114500467665493, Final Batch Loss: 0.0002865584392566234\n",
      "Epoch 3234, Loss: 0.0006388475667336024, Final Batch Loss: 0.00023991674243006855\n",
      "Epoch 3235, Loss: 0.0006851884754723869, Final Batch Loss: 0.00020795068121515214\n",
      "Epoch 3236, Loss: 0.00031298658541345503, Final Batch Loss: 2.4575097995693795e-05\n",
      "Epoch 3237, Loss: 0.001030905645166058, Final Batch Loss: 0.0005205488414503634\n",
      "Epoch 3238, Loss: 0.0011787293927341125, Final Batch Loss: 5.60017099360266e-07\n",
      "Epoch 3239, Loss: 0.0004211614796076901, Final Batch Loss: 0.00014835513138677925\n",
      "Epoch 3240, Loss: 0.010570815680694068, Final Batch Loss: 0.010219106450676918\n",
      "Epoch 3241, Loss: 0.0002847445757652167, Final Batch Loss: 2.5108602130785584e-05\n",
      "Epoch 3242, Loss: 0.0015842176508158445, Final Batch Loss: 0.0007295761024579406\n",
      "Epoch 3243, Loss: 0.0012799442338291556, Final Batch Loss: 0.0005427252035588026\n",
      "Epoch 3244, Loss: 0.0380895173366298, Final Batch Loss: 0.0005882180412299931\n",
      "Epoch 3245, Loss: 0.0009541125182295218, Final Batch Loss: 0.00020908756414428353\n",
      "Epoch 3246, Loss: 0.0007668146899959538, Final Batch Loss: 4.840371911996044e-05\n",
      "Epoch 3247, Loss: 0.011902220678166486, Final Batch Loss: 0.00011059000826207921\n",
      "Epoch 3248, Loss: 0.010974781223922037, Final Batch Loss: 4.6840890718158334e-05\n",
      "Epoch 3249, Loss: 0.001306526261032559, Final Batch Loss: 6.111350376158953e-05\n",
      "Epoch 3250, Loss: 0.007316929007629369, Final Batch Loss: 4.6574782572861295e-06\n",
      "Epoch 3251, Loss: 0.0050268026675439614, Final Batch Loss: 0.003625177312642336\n",
      "Epoch 3252, Loss: 0.005301952580339275, Final Batch Loss: 0.00014846793783362955\n",
      "Epoch 3253, Loss: 0.025004721152072307, Final Batch Loss: 7.023593207122758e-05\n",
      "Epoch 3254, Loss: 0.045832835996407084, Final Batch Loss: 0.0006858910201117396\n",
      "Epoch 3255, Loss: 0.0006159361400932539, Final Batch Loss: 0.00033504021121189\n",
      "Epoch 3256, Loss: 0.0011046136496588588, Final Batch Loss: 0.00010961027874145657\n",
      "Epoch 3257, Loss: 0.0036182651601848193, Final Batch Loss: 0.0029087760485708714\n",
      "Epoch 3258, Loss: 0.00041405396041227505, Final Batch Loss: 5.0553800974739715e-05\n",
      "Epoch 3259, Loss: 0.0034056864060403313, Final Batch Loss: 3.0242012144299224e-05\n",
      "Epoch 3260, Loss: 0.000660529271044652, Final Batch Loss: 2.808670797094237e-05\n",
      "Epoch 3261, Loss: 0.0019672881171572953, Final Batch Loss: 0.0003130247932858765\n",
      "Epoch 3262, Loss: 0.0012155357035226189, Final Batch Loss: 0.00011422399984439835\n",
      "Epoch 3263, Loss: 0.0043407219236542005, Final Batch Loss: 4.4244781747693196e-05\n",
      "Epoch 3264, Loss: 0.003333478329295758, Final Batch Loss: 0.001983958063647151\n",
      "Epoch 3265, Loss: 0.0006818775982537773, Final Batch Loss: 7.288289634743705e-05\n",
      "Epoch 3266, Loss: 0.0009701148956082761, Final Batch Loss: 3.562097845133394e-06\n",
      "Epoch 3267, Loss: 0.0017862277018139139, Final Batch Loss: 0.00020986783783882856\n",
      "Epoch 3268, Loss: 0.001015965041005984, Final Batch Loss: 0.00019368920766282827\n",
      "Epoch 3269, Loss: 0.0008145032625179738, Final Batch Loss: 7.338328578043729e-05\n",
      "Epoch 3270, Loss: 0.0007513561504310928, Final Batch Loss: 0.00027359602972865105\n",
      "Epoch 3271, Loss: 0.0016825258790049702, Final Batch Loss: 0.000253815931500867\n",
      "Epoch 3272, Loss: 0.0028237161168362945, Final Batch Loss: 4.9517355364514515e-05\n",
      "Epoch 3273, Loss: 0.0003564220478438074, Final Batch Loss: 9.77388299361337e-06\n",
      "Epoch 3274, Loss: 0.000778023593738908, Final Batch Loss: 4.4165051804156974e-05\n",
      "Epoch 3275, Loss: 0.0008955394478107337, Final Batch Loss: 2.3105585569282994e-05\n",
      "Epoch 3276, Loss: 0.0007173850353865419, Final Batch Loss: 0.00021293069585226476\n",
      "Epoch 3277, Loss: 0.00353959815674898, Final Batch Loss: 1.3379200936469715e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3278, Loss: 0.0006740454564351239, Final Batch Loss: 0.00023418419004883617\n",
      "Epoch 3279, Loss: 0.0016224646169575863, Final Batch Loss: 0.0009247513953596354\n",
      "Epoch 3280, Loss: 0.0005928583013883326, Final Batch Loss: 0.00022820354206487536\n",
      "Epoch 3281, Loss: 0.0008056967199081555, Final Batch Loss: 0.0005044318968430161\n",
      "Epoch 3282, Loss: 0.0005648785518133081, Final Batch Loss: 0.0002206906210631132\n",
      "Epoch 3283, Loss: 0.0005061935808043927, Final Batch Loss: 0.0002625621564220637\n",
      "Epoch 3284, Loss: 0.0011026870197383687, Final Batch Loss: 0.0006419591372832656\n",
      "Epoch 3285, Loss: 0.000568158517125994, Final Batch Loss: 0.0002639350714161992\n",
      "Epoch 3286, Loss: 0.0007857402888475917, Final Batch Loss: 0.00010901802306761965\n",
      "Epoch 3287, Loss: 0.0043149128728146025, Final Batch Loss: 6.141123321867781e-06\n",
      "Epoch 3288, Loss: 0.002340453445640378, Final Batch Loss: 3.591799895730219e-06\n",
      "Epoch 3289, Loss: 0.00105879315015045, Final Batch Loss: 0.00011359471682226285\n",
      "Epoch 3290, Loss: 0.0003079477637584205, Final Batch Loss: 1.1816190635727253e-05\n",
      "Epoch 3291, Loss: 0.0011495352450765495, Final Batch Loss: 4.247151537128957e-06\n",
      "Epoch 3292, Loss: 0.0030959125360823236, Final Batch Loss: 0.00013460023910738528\n",
      "Epoch 3293, Loss: 0.007857172578951577, Final Batch Loss: 0.0039019817486405373\n",
      "Epoch 3294, Loss: 0.001264656675630249, Final Batch Loss: 0.0003846008621621877\n",
      "Epoch 3295, Loss: 0.0003205632347089704, Final Batch Loss: 8.51278891786933e-05\n",
      "Epoch 3296, Loss: 0.0009187701652990654, Final Batch Loss: 0.00024207062961068004\n",
      "Epoch 3297, Loss: 0.0008259933420049492, Final Batch Loss: 1.5484834875678644e-05\n",
      "Epoch 3298, Loss: 0.00059158876138099, Final Batch Loss: 0.00018844044825527817\n",
      "Epoch 3299, Loss: 0.0003305514983367175, Final Batch Loss: 9.934097761288285e-06\n",
      "Epoch 3300, Loss: 0.0011522934000822715, Final Batch Loss: 0.0006027373019605875\n",
      "Epoch 3301, Loss: 0.00045680892890231917, Final Batch Loss: 9.704069270810578e-06\n",
      "Epoch 3302, Loss: 0.0005764885227108607, Final Batch Loss: 1.8677275875234045e-05\n",
      "Epoch 3303, Loss: 0.00021800751574119204, Final Batch Loss: 2.1683157683582976e-05\n",
      "Epoch 3304, Loss: 0.00025392957923031645, Final Batch Loss: 5.774486999143846e-05\n",
      "Epoch 3305, Loss: 0.00023853911170590436, Final Batch Loss: 7.720354005869012e-06\n",
      "Epoch 3306, Loss: 0.00223789439041866, Final Batch Loss: 0.0006154864677228034\n",
      "Epoch 3307, Loss: 0.0004383489012980135, Final Batch Loss: 2.7258010959485546e-06\n",
      "Epoch 3308, Loss: 0.0002570215001469478, Final Batch Loss: 0.00021010164346080273\n",
      "Epoch 3309, Loss: 0.0004175476469754358, Final Batch Loss: 0.00022037407325115055\n",
      "Epoch 3310, Loss: 0.0033152644464280456, Final Batch Loss: 0.00014355160237755626\n",
      "Epoch 3311, Loss: 0.00042853233753703535, Final Batch Loss: 2.3301383407670073e-05\n",
      "Epoch 3312, Loss: 0.0006162650533951819, Final Batch Loss: 3.3872725907713175e-05\n",
      "Epoch 3313, Loss: 0.0023027806191748823, Final Batch Loss: 9.689271973911673e-05\n",
      "Epoch 3314, Loss: 0.012438709167327033, Final Batch Loss: 0.0001237895485246554\n",
      "Epoch 3315, Loss: 0.0006323220368358307, Final Batch Loss: 0.00021085349726490676\n",
      "Epoch 3316, Loss: 0.0008205766789615154, Final Batch Loss: 0.000488341087475419\n",
      "Epoch 3317, Loss: 0.00027566532298806123, Final Batch Loss: 3.17822523356881e-05\n",
      "Epoch 3318, Loss: 0.0011534676150404266, Final Batch Loss: 1.3700816452910658e-05\n",
      "Epoch 3319, Loss: 0.0003892580989486305, Final Batch Loss: 0.0001526329288026318\n",
      "Epoch 3320, Loss: 0.000673432337862323, Final Batch Loss: 0.0001149599120253697\n",
      "Epoch 3321, Loss: 0.0018087576536345296, Final Batch Loss: 8.077415259322152e-05\n",
      "Epoch 3322, Loss: 0.0003858692452922696, Final Batch Loss: 2.8817757993238047e-06\n",
      "Epoch 3323, Loss: 0.00036573383840732276, Final Batch Loss: 7.327658386202529e-05\n",
      "Epoch 3324, Loss: 0.00936099326099793, Final Batch Loss: 0.0009974587010219693\n",
      "Epoch 3325, Loss: 0.0003629921229730826, Final Batch Loss: 3.071859464398585e-05\n",
      "Epoch 3326, Loss: 0.009235166187863797, Final Batch Loss: 6.424133607652038e-05\n",
      "Epoch 3327, Loss: 0.0008615210899733938, Final Batch Loss: 0.00016399491869378835\n",
      "Epoch 3328, Loss: 0.0006794814805743954, Final Batch Loss: 2.3932341264298884e-06\n",
      "Epoch 3329, Loss: 0.0029785217775497586, Final Batch Loss: 0.00017113020294345915\n",
      "Epoch 3330, Loss: 0.0004474970937735634, Final Batch Loss: 2.6719166271504946e-05\n",
      "Epoch 3331, Loss: 0.011075988004449755, Final Batch Loss: 0.0005794113385491073\n",
      "Epoch 3332, Loss: 0.0008150019020831678, Final Batch Loss: 0.00014550771447829902\n",
      "Epoch 3333, Loss: 0.00034044402855215594, Final Batch Loss: 2.9226677725091577e-05\n",
      "Epoch 3334, Loss: 0.0036311932490207255, Final Batch Loss: 8.16389947431162e-05\n",
      "Epoch 3335, Loss: 0.00030236702787078684, Final Batch Loss: 0.00018373837519902736\n",
      "Epoch 3336, Loss: 0.0022898225906828884, Final Batch Loss: 3.6477387766353786e-05\n",
      "Epoch 3337, Loss: 0.00028949584884685464, Final Batch Loss: 5.265822255751118e-05\n",
      "Epoch 3338, Loss: 0.0005726768140448257, Final Batch Loss: 7.404619827866554e-05\n",
      "Epoch 3339, Loss: 0.002411280856904341, Final Batch Loss: 0.00011982148862443864\n",
      "Epoch 3340, Loss: 0.0037839510150661226, Final Batch Loss: 3.533262497512624e-05\n",
      "Epoch 3341, Loss: 0.00013651242898049532, Final Batch Loss: 2.5229592210962437e-06\n",
      "Epoch 3342, Loss: 0.0006889012656756677, Final Batch Loss: 0.00023217470152303576\n",
      "Epoch 3343, Loss: 0.0007950342078402173, Final Batch Loss: 4.807414370588958e-05\n",
      "Epoch 3344, Loss: 0.0011385956058802549, Final Batch Loss: 3.4996486647287384e-05\n",
      "Epoch 3345, Loss: 0.00758815482549835, Final Batch Loss: 7.269238267326728e-05\n",
      "Epoch 3346, Loss: 0.0002216061438957695, Final Batch Loss: 1.1420390364946797e-05\n",
      "Epoch 3347, Loss: 0.029694408252908033, Final Batch Loss: 2.6527866793912835e-05\n",
      "Epoch 3348, Loss: 0.00032462265335198026, Final Batch Loss: 0.00017650671361479908\n",
      "Epoch 3349, Loss: 0.0004116554482607171, Final Batch Loss: 0.00011503857240313664\n",
      "Epoch 3350, Loss: 0.0036066719876544084, Final Batch Loss: 0.0002073712385026738\n",
      "Epoch 3351, Loss: 0.000391717221646104, Final Batch Loss: 4.903296212432906e-05\n",
      "Epoch 3352, Loss: 0.0004266162941348739, Final Batch Loss: 0.0001447220565751195\n",
      "Epoch 3353, Loss: 0.0005278191893012263, Final Batch Loss: 0.00020348421821836382\n",
      "Epoch 3354, Loss: 0.001084963247194537, Final Batch Loss: 1.1520185580593534e-05\n",
      "Epoch 3355, Loss: 0.0006528866524604382, Final Batch Loss: 1.8874257875722833e-05\n",
      "Epoch 3356, Loss: 0.0013735757747781463, Final Batch Loss: 9.725676500238478e-05\n",
      "Epoch 3357, Loss: 0.0020994065907871118, Final Batch Loss: 0.0003831729118246585\n",
      "Epoch 3358, Loss: 0.0007020141638349742, Final Batch Loss: 6.840013520559296e-05\n",
      "Epoch 3359, Loss: 0.0005633673863485456, Final Batch Loss: 7.183868729043752e-05\n",
      "Epoch 3360, Loss: 0.006320396683804574, Final Batch Loss: 2.3616781618329696e-05\n",
      "Epoch 3361, Loss: 0.009211326607328374, Final Batch Loss: 0.008894822560250759\n",
      "Epoch 3362, Loss: 0.003624380344263045, Final Batch Loss: 4.050730058224872e-05\n",
      "Epoch 3363, Loss: 0.0008485956559525221, Final Batch Loss: 0.0001511800946900621\n",
      "Epoch 3364, Loss: 0.008095905621303245, Final Batch Loss: 0.00031477498123422265\n",
      "Epoch 3365, Loss: 0.009568460431182757, Final Batch Loss: 0.00041295334813185036\n",
      "Epoch 3366, Loss: 0.004582657649734756, Final Batch Loss: 0.003907211124897003\n",
      "Epoch 3367, Loss: 0.006157688618941393, Final Batch Loss: 3.310033889647457e-06\n",
      "Epoch 3368, Loss: 0.013312958566530142, Final Batch Loss: 3.1409676012117416e-05\n",
      "Epoch 3369, Loss: 0.013714900036575273, Final Batch Loss: 0.013101749122142792\n",
      "Epoch 3370, Loss: 0.0004104718937014695, Final Batch Loss: 0.0001194879223476164\n",
      "Epoch 3371, Loss: 0.02509880222260108, Final Batch Loss: 1.0260918315907475e-05\n",
      "Epoch 3372, Loss: 0.0017574137455085292, Final Batch Loss: 0.0008703585481271148\n",
      "Epoch 3373, Loss: 0.000877359212609008, Final Batch Loss: 0.0001651510683586821\n",
      "Epoch 3374, Loss: 0.0022059602379158605, Final Batch Loss: 0.00012579657777678221\n",
      "Epoch 3375, Loss: 0.004975671312422492, Final Batch Loss: 0.00020521142869256437\n",
      "Epoch 3376, Loss: 0.001106540541513823, Final Batch Loss: 0.00035125904832966626\n",
      "Epoch 3377, Loss: 0.017177870737214107, Final Batch Loss: 0.0014672839315608144\n",
      "Epoch 3378, Loss: 0.00016043431060097646, Final Batch Loss: 2.5120267309830524e-05\n",
      "Epoch 3379, Loss: 0.0025013471326928993, Final Batch Loss: 7.029518747003749e-05\n",
      "Epoch 3380, Loss: 0.0004957432465744205, Final Batch Loss: 8.14439590612892e-06\n",
      "Epoch 3381, Loss: 0.0007203381373983575, Final Batch Loss: 0.0002845772251021117\n",
      "Epoch 3382, Loss: 0.0030353118636412546, Final Batch Loss: 0.00045637457515113056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3383, Loss: 0.0005321711796568707, Final Batch Loss: 0.0001528531574876979\n",
      "Epoch 3384, Loss: 0.00052434639474086, Final Batch Loss: 2.348060479562264e-05\n",
      "Epoch 3385, Loss: 0.0003286429273430258, Final Batch Loss: 4.9626596592133865e-05\n",
      "Epoch 3386, Loss: 0.0015725169341749279, Final Batch Loss: 0.00018940577865578234\n",
      "Epoch 3387, Loss: 0.0006828636633144924, Final Batch Loss: 9.871143993223086e-05\n",
      "Epoch 3388, Loss: 0.03060523231033585, Final Batch Loss: 6.437247793655843e-05\n",
      "Epoch 3389, Loss: 0.0006411621670849854, Final Batch Loss: 2.8627313440665603e-05\n",
      "Epoch 3390, Loss: 0.0012803769495803863, Final Batch Loss: 0.00021458929404616356\n",
      "Epoch 3391, Loss: 0.0005683893759851344, Final Batch Loss: 0.00030884865554980934\n",
      "Epoch 3392, Loss: 0.0011554772281670012, Final Batch Loss: 0.0006582761998288333\n",
      "Epoch 3393, Loss: 0.0009959640483430121, Final Batch Loss: 4.247664401191287e-05\n",
      "Epoch 3394, Loss: 0.010376303311204538, Final Batch Loss: 1.687368785496801e-05\n",
      "Epoch 3395, Loss: 0.0009707649260235485, Final Batch Loss: 4.802851617569104e-05\n",
      "Epoch 3396, Loss: 0.0005969710728095379, Final Batch Loss: 0.00030083267483860254\n",
      "Epoch 3397, Loss: 0.0010956089536193758, Final Batch Loss: 0.00013739800488110632\n",
      "Epoch 3398, Loss: 0.0012982227599422913, Final Batch Loss: 4.515322871156968e-05\n",
      "Epoch 3399, Loss: 0.0015635404815839138, Final Batch Loss: 0.0007134907646104693\n",
      "Epoch 3400, Loss: 0.0007479506894014776, Final Batch Loss: 9.471775410929695e-05\n",
      "Epoch 3401, Loss: 0.0006182764991535805, Final Batch Loss: 0.00029197733965702355\n",
      "Epoch 3402, Loss: 0.00041991334001068026, Final Batch Loss: 9.797047096071765e-05\n",
      "Epoch 3403, Loss: 0.001222310896991985, Final Batch Loss: 4.6864570322213694e-05\n",
      "Epoch 3404, Loss: 0.0009247399721061811, Final Batch Loss: 0.00010574323823675513\n",
      "Epoch 3405, Loss: 0.00073837172385538, Final Batch Loss: 0.0001290537475142628\n",
      "Epoch 3406, Loss: 0.0013076767827442382, Final Batch Loss: 0.0006776478257961571\n",
      "Epoch 3407, Loss: 0.00036487487886915915, Final Batch Loss: 3.0353538022609428e-05\n",
      "Epoch 3408, Loss: 0.00041569343375158496, Final Batch Loss: 2.440845491946675e-05\n",
      "Epoch 3409, Loss: 0.000605793562499457, Final Batch Loss: 2.1681737052858807e-05\n",
      "Epoch 3410, Loss: 0.0005514340027730213, Final Batch Loss: 3.1407213100465015e-05\n",
      "Epoch 3411, Loss: 0.001059912312484812, Final Batch Loss: 2.5536948669468984e-05\n",
      "Epoch 3412, Loss: 0.0006972032670091721, Final Batch Loss: 0.00026670368970371783\n",
      "Epoch 3413, Loss: 0.0012108207156416029, Final Batch Loss: 0.00038407620741054416\n",
      "Epoch 3414, Loss: 0.0007519049831898883, Final Batch Loss: 2.0014311303384602e-05\n",
      "Epoch 3415, Loss: 0.0002307923678017687, Final Batch Loss: 2.3984948711586185e-05\n",
      "Epoch 3416, Loss: 0.00020298504932725336, Final Batch Loss: 4.300718501326628e-06\n",
      "Epoch 3417, Loss: 0.00121589894661156, Final Batch Loss: 0.0004955182084813714\n",
      "Epoch 3418, Loss: 0.0004452865778148407, Final Batch Loss: 0.00024050282081589103\n",
      "Epoch 3419, Loss: 0.00021388150435086573, Final Batch Loss: 0.00011612343951128423\n",
      "Epoch 3420, Loss: 0.0201822943672596, Final Batch Loss: 0.019894517958164215\n",
      "Epoch 3421, Loss: 0.003189214454323519, Final Batch Loss: 0.00017202002345584333\n",
      "Epoch 3422, Loss: 0.00021427990213851444, Final Batch Loss: 0.00011680234456434846\n",
      "Epoch 3423, Loss: 0.017985069054702763, Final Batch Loss: 0.00016535804024897516\n",
      "Epoch 3424, Loss: 0.0007483645886168233, Final Batch Loss: 9.086462341656443e-06\n",
      "Epoch 3425, Loss: 0.015084922693858971, Final Batch Loss: 0.00030643673380836844\n",
      "Epoch 3426, Loss: 0.0002683316051843576, Final Batch Loss: 5.477366357808933e-05\n",
      "Epoch 3427, Loss: 0.0007116466731531546, Final Batch Loss: 0.0002061502746073529\n",
      "Epoch 3428, Loss: 0.00041909271021722816, Final Batch Loss: 9.236590994987637e-05\n",
      "Epoch 3429, Loss: 0.0019336685018060962, Final Batch Loss: 6.918027065694332e-05\n",
      "Epoch 3430, Loss: 0.009331588404165814, Final Batch Loss: 0.009097040630877018\n",
      "Epoch 3431, Loss: 0.0015065466577652842, Final Batch Loss: 4.095069016329944e-05\n",
      "Epoch 3432, Loss: 0.00033700731819408247, Final Batch Loss: 6.692394526908174e-05\n",
      "Epoch 3433, Loss: 0.004735323534987401, Final Batch Loss: 0.004457664210349321\n",
      "Epoch 3434, Loss: 0.0001367858931189403, Final Batch Loss: 1.0002416274801362e-05\n",
      "Epoch 3435, Loss: 0.0010824353339558002, Final Batch Loss: 0.0002643591142259538\n",
      "Epoch 3436, Loss: 0.0004428990505402908, Final Batch Loss: 1.105038245441392e-05\n",
      "Epoch 3437, Loss: 0.001359360605420079, Final Batch Loss: 1.6917074390221387e-05\n",
      "Epoch 3438, Loss: 0.0007099279000613024, Final Batch Loss: 5.723391041101422e-06\n",
      "Epoch 3439, Loss: 0.0008516180128026463, Final Batch Loss: 0.000440652685938403\n",
      "Epoch 3440, Loss: 0.00043806697794934735, Final Batch Loss: 0.00014722824562340975\n",
      "Epoch 3441, Loss: 0.00021746887068729848, Final Batch Loss: 2.7289914214634337e-05\n",
      "Epoch 3442, Loss: 0.0012499874501372688, Final Batch Loss: 0.0010982647072523832\n",
      "Epoch 3443, Loss: 0.00046670054507558234, Final Batch Loss: 0.0003141254710499197\n",
      "Epoch 3444, Loss: 0.0009307526293014234, Final Batch Loss: 6.08890559306019e-06\n",
      "Epoch 3445, Loss: 0.00025762881341506727, Final Batch Loss: 3.1856234272709116e-05\n",
      "Epoch 3446, Loss: 0.0001976389439732884, Final Batch Loss: 0.00010119604849023744\n",
      "Epoch 3447, Loss: 0.0006697786930089933, Final Batch Loss: 0.0003148242540191859\n",
      "Epoch 3448, Loss: 0.0010255397155560786, Final Batch Loss: 0.00043008264037780464\n",
      "Epoch 3449, Loss: 0.00045282656719791703, Final Batch Loss: 3.476774872979149e-05\n",
      "Epoch 3450, Loss: 0.0009229830479853263, Final Batch Loss: 0.0007993945619091392\n",
      "Epoch 3451, Loss: 0.0009297600063291611, Final Batch Loss: 5.460586180561222e-06\n",
      "Epoch 3452, Loss: 0.000804607668214885, Final Batch Loss: 7.852532689867076e-06\n",
      "Epoch 3453, Loss: 0.00048564312601229176, Final Batch Loss: 0.00015050516230985522\n",
      "Epoch 3454, Loss: 0.00043269617162877694, Final Batch Loss: 0.00023095434880815446\n",
      "Epoch 3455, Loss: 0.0016380808701796923, Final Batch Loss: 0.000936457421630621\n",
      "Epoch 3456, Loss: 0.0006620293097512331, Final Batch Loss: 2.5524661396048032e-05\n",
      "Epoch 3457, Loss: 0.007870334397011902, Final Batch Loss: 0.0006653344607912004\n",
      "Epoch 3458, Loss: 0.0007589290271425853, Final Batch Loss: 0.00029829831328243017\n",
      "Epoch 3459, Loss: 0.00018721456399362069, Final Batch Loss: 2.8156491680420004e-05\n",
      "Epoch 3460, Loss: 0.00039696041494607925, Final Batch Loss: 0.00010174072667723522\n",
      "Epoch 3461, Loss: 0.0009649977455410408, Final Batch Loss: 1.9716100723599084e-05\n",
      "Epoch 3462, Loss: 0.0006004614861012669, Final Batch Loss: 2.9072651159367524e-05\n",
      "Epoch 3463, Loss: 0.00023539404901384842, Final Batch Loss: 7.359594746958464e-05\n",
      "Epoch 3464, Loss: 0.030175245212376467, Final Batch Loss: 0.00015601531777065247\n",
      "Epoch 3465, Loss: 0.01989168726322532, Final Batch Loss: 0.00023956522636581212\n",
      "Epoch 3466, Loss: 0.0009830148537730565, Final Batch Loss: 0.0006168872932903469\n",
      "Epoch 3467, Loss: 0.0018881678333855234, Final Batch Loss: 4.540209920378402e-05\n",
      "Epoch 3468, Loss: 0.004220320235617692, Final Batch Loss: 3.740688771358691e-05\n",
      "Epoch 3469, Loss: 0.0021343420871744456, Final Batch Loss: 6.880980890855426e-06\n",
      "Epoch 3470, Loss: 0.00048604376024741214, Final Batch Loss: 0.00023249577498063445\n",
      "Epoch 3471, Loss: 0.0008980481516118743, Final Batch Loss: 1.1808741874119733e-05\n",
      "Epoch 3472, Loss: 0.0010870098631130531, Final Batch Loss: 4.8805130063556135e-05\n",
      "Epoch 3473, Loss: 0.0006427948665077565, Final Batch Loss: 2.0739336832775734e-05\n",
      "Epoch 3474, Loss: 0.0010735160103649832, Final Batch Loss: 0.0009030210203491151\n",
      "Epoch 3475, Loss: 0.0010986442321154755, Final Batch Loss: 0.0003486418863758445\n",
      "Epoch 3476, Loss: 0.000388831045711413, Final Batch Loss: 0.00018563499907031655\n",
      "Epoch 3477, Loss: 0.0007666121182410279, Final Batch Loss: 1.4902669136063196e-05\n",
      "Epoch 3478, Loss: 0.0023037300270516425, Final Batch Loss: 5.306599268806167e-05\n",
      "Epoch 3479, Loss: 0.0012070909215253778, Final Batch Loss: 0.0003068968071602285\n",
      "Epoch 3480, Loss: 0.0004752778186229989, Final Batch Loss: 4.5814515033271164e-05\n",
      "Epoch 3481, Loss: 0.020745072323734348, Final Batch Loss: 0.00016519984637852758\n",
      "Epoch 3482, Loss: 0.0005478534426401893, Final Batch Loss: 2.947946995845996e-05\n",
      "Epoch 3483, Loss: 0.00045419051548378775, Final Batch Loss: 0.00025074806762859225\n",
      "Epoch 3484, Loss: 0.0017542532741572359, Final Batch Loss: 6.38886631350033e-05\n",
      "Epoch 3485, Loss: 0.0006454205758927856, Final Batch Loss: 4.170103420619853e-05\n",
      "Epoch 3486, Loss: 0.0001390736788380309, Final Batch Loss: 9.345412399852648e-05\n",
      "Epoch 3487, Loss: 0.0014343904549605213, Final Batch Loss: 0.00012835416418965906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3488, Loss: 0.0009252493755411706, Final Batch Loss: 1.430726933904225e-05\n",
      "Epoch 3489, Loss: 0.0020801440041395836, Final Batch Loss: 0.0005401998059824109\n",
      "Epoch 3490, Loss: 0.0008274710726254852, Final Batch Loss: 0.0001526116393506527\n",
      "Epoch 3491, Loss: 0.006892958879689104, Final Batch Loss: 2.5165127226500772e-05\n",
      "Epoch 3492, Loss: 0.002664165003807284, Final Batch Loss: 0.00037037217407487333\n",
      "Epoch 3493, Loss: 0.00038021723230485804, Final Batch Loss: 0.00011327502579661086\n",
      "Epoch 3494, Loss: 0.0005047821177868173, Final Batch Loss: 0.0002498135145287961\n",
      "Epoch 3495, Loss: 0.0036400063618202694, Final Batch Loss: 9.754951315699145e-05\n",
      "Epoch 3496, Loss: 0.0003636726687545888, Final Batch Loss: 5.5811586207710207e-05\n",
      "Epoch 3497, Loss: 0.000407238956540823, Final Batch Loss: 8.784996316535398e-05\n",
      "Epoch 3498, Loss: 0.0006273000144574326, Final Batch Loss: 0.0002033057389780879\n",
      "Epoch 3499, Loss: 0.000377066009605187, Final Batch Loss: 9.215587851940654e-06\n",
      "Epoch 3500, Loss: 0.000426793387532598, Final Batch Loss: 0.00010507451224839315\n",
      "Epoch 3501, Loss: 0.000251701581873931, Final Batch Loss: 0.00010099360952153802\n",
      "Epoch 3502, Loss: 0.00022260261175688356, Final Batch Loss: 2.7653690267470665e-05\n",
      "Epoch 3503, Loss: 0.0009617788418836426, Final Batch Loss: 0.00011760321649489924\n",
      "Epoch 3504, Loss: 0.0004788787628058344, Final Batch Loss: 0.0002604022156447172\n",
      "Epoch 3505, Loss: 0.0039034427502429025, Final Batch Loss: 2.184049890274764e-06\n",
      "Epoch 3506, Loss: 0.0004681723357862211, Final Batch Loss: 9.251943993149325e-05\n",
      "Epoch 3507, Loss: 0.0005530934158741729, Final Batch Loss: 4.357855868875049e-05\n",
      "Epoch 3508, Loss: 0.0005467660776048433, Final Batch Loss: 2.2849559172755107e-05\n",
      "Epoch 3509, Loss: 0.00022226159512683807, Final Batch Loss: 0.00010483816004125401\n",
      "Epoch 3510, Loss: 0.0004963480641890783, Final Batch Loss: 6.954173295525834e-05\n",
      "Epoch 3511, Loss: 0.0010390280476713087, Final Batch Loss: 1.401444387738593e-05\n",
      "Epoch 3512, Loss: 0.0002817785116349114, Final Batch Loss: 3.712874240591191e-05\n",
      "Epoch 3513, Loss: 0.0004953388242938672, Final Batch Loss: 0.00023336286540143192\n",
      "Epoch 3514, Loss: 0.0011335767121636309, Final Batch Loss: 0.00012910328223370016\n",
      "Epoch 3515, Loss: 0.0011767195701395394, Final Batch Loss: 0.0009130683029070497\n",
      "Epoch 3516, Loss: 0.00042022401248686947, Final Batch Loss: 4.53626926173456e-05\n",
      "Epoch 3517, Loss: 0.0004095341264473973, Final Batch Loss: 2.1546607968048193e-05\n",
      "Epoch 3518, Loss: 0.00035860172283719294, Final Batch Loss: 5.699583562090993e-05\n",
      "Epoch 3519, Loss: 0.0014258133232942782, Final Batch Loss: 0.0001183173299068585\n",
      "Epoch 3520, Loss: 0.016212938581702474, Final Batch Loss: 8.069318027992267e-06\n",
      "Epoch 3521, Loss: 0.0004010526422462135, Final Batch Loss: 0.00024663348449394107\n",
      "Epoch 3522, Loss: 0.0027954485985901556, Final Batch Loss: 0.0009217792539857328\n",
      "Epoch 3523, Loss: 0.00015188312022473838, Final Batch Loss: 9.68716221905197e-07\n",
      "Epoch 3524, Loss: 0.014749387990377727, Final Batch Loss: 1.7958729586098343e-05\n",
      "Epoch 3525, Loss: 0.00021486367859324673, Final Batch Loss: 1.428853011020692e-05\n",
      "Epoch 3526, Loss: 0.0011136745670228265, Final Batch Loss: 1.2320357200223953e-05\n",
      "Epoch 3527, Loss: 0.0004660240574594354, Final Batch Loss: 1.729178438836243e-05\n",
      "Epoch 3528, Loss: 0.0007507014502152742, Final Batch Loss: 4.329612056608312e-05\n",
      "Epoch 3529, Loss: 0.0017922821098181885, Final Batch Loss: 0.00036800827365368605\n",
      "Epoch 3530, Loss: 0.0002964776103908662, Final Batch Loss: 3.4401706216158345e-05\n",
      "Epoch 3531, Loss: 0.0008773431700319634, Final Batch Loss: 0.0008262998308055103\n",
      "Epoch 3532, Loss: 0.0011768897602451034, Final Batch Loss: 0.0004903849912807345\n",
      "Epoch 3533, Loss: 0.0008846877317409962, Final Batch Loss: 8.595845429226756e-06\n",
      "Epoch 3534, Loss: 0.00019606260048021795, Final Batch Loss: 8.933057870308403e-06\n",
      "Epoch 3535, Loss: 0.0004952463036715926, Final Batch Loss: 0.0002555197279434651\n",
      "Epoch 3536, Loss: 0.0007646186959391343, Final Batch Loss: 2.808333192660939e-06\n",
      "Epoch 3537, Loss: 0.00016047830649768002, Final Batch Loss: 0.00011945682490477338\n",
      "Epoch 3538, Loss: 0.021145163318578852, Final Batch Loss: 3.454720717854798e-05\n",
      "Epoch 3539, Loss: 0.0024785501009318978, Final Batch Loss: 0.0014517217641696334\n",
      "Epoch 3540, Loss: 0.0007887302526796702, Final Batch Loss: 2.9067459763609804e-06\n",
      "Epoch 3541, Loss: 0.003890904152285657, Final Batch Loss: 0.003797222627326846\n",
      "Epoch 3542, Loss: 0.00032763303170213476, Final Batch Loss: 0.00010400683095213026\n",
      "Epoch 3543, Loss: 0.0005350926585379057, Final Batch Loss: 9.657291957410052e-05\n",
      "Epoch 3544, Loss: 0.00020588814004440792, Final Batch Loss: 7.934709719847888e-05\n",
      "Epoch 3545, Loss: 0.0007331728884309996, Final Batch Loss: 0.0004469705745577812\n",
      "Epoch 3546, Loss: 0.003184045995340057, Final Batch Loss: 4.015688318759203e-05\n",
      "Epoch 3547, Loss: 0.0008710274432814913, Final Batch Loss: 6.187673716340214e-05\n",
      "Epoch 3548, Loss: 0.004152655213147227, Final Batch Loss: 0.0037893145345151424\n",
      "Epoch 3549, Loss: 0.00048006181032178574, Final Batch Loss: 2.405007035122253e-05\n",
      "Epoch 3550, Loss: 0.0008012245161808096, Final Batch Loss: 1.1700081813614815e-05\n",
      "Epoch 3551, Loss: 0.00016016699919418897, Final Batch Loss: 4.2786821722984314e-05\n",
      "Epoch 3552, Loss: 0.0001347766478829726, Final Batch Loss: 5.7273550737590995e-06\n",
      "Epoch 3553, Loss: 0.0008654318844492082, Final Batch Loss: 2.8291076887398958e-05\n",
      "Epoch 3554, Loss: 0.0008461606339551508, Final Batch Loss: 0.0003108966920990497\n",
      "Epoch 3555, Loss: 0.002180700201279251, Final Batch Loss: 0.0007509649731218815\n",
      "Epoch 3556, Loss: 0.0012638218931897427, Final Batch Loss: 6.758858035027515e-06\n",
      "Epoch 3557, Loss: 0.0005272854646136693, Final Batch Loss: 5.358799626264954e-06\n",
      "Epoch 3558, Loss: 0.0007625921844010008, Final Batch Loss: 8.77121856319718e-05\n",
      "Epoch 3559, Loss: 0.00033189372607012047, Final Batch Loss: 7.389207894448191e-06\n",
      "Epoch 3560, Loss: 0.0027832966297864914, Final Batch Loss: 0.0002594732795841992\n",
      "Epoch 3561, Loss: 0.02553263311710907, Final Batch Loss: 3.832571383100003e-05\n",
      "Epoch 3562, Loss: 0.00026360903757449705, Final Batch Loss: 2.6316944058635272e-05\n",
      "Epoch 3563, Loss: 0.008723039078176953, Final Batch Loss: 0.008082211017608643\n",
      "Epoch 3564, Loss: 0.00027635770493361633, Final Batch Loss: 9.682264135335572e-06\n",
      "Epoch 3565, Loss: 0.004769896808738849, Final Batch Loss: 4.983469352737302e-06\n",
      "Epoch 3566, Loss: 0.03433489934741374, Final Batch Loss: 0.03397437185049057\n",
      "Epoch 3567, Loss: 0.0006433511716750218, Final Batch Loss: 4.406608422868885e-05\n",
      "Epoch 3568, Loss: 0.00023920028979773633, Final Batch Loss: 3.540413672453724e-05\n",
      "Epoch 3569, Loss: 0.0007374123342742678, Final Batch Loss: 7.483760418836027e-05\n",
      "Epoch 3570, Loss: 0.00653856183271273, Final Batch Loss: 0.006195748690515757\n",
      "Epoch 3571, Loss: 0.0019276740058558062, Final Batch Loss: 0.00019391383102629334\n",
      "Epoch 3572, Loss: 0.0006797396217734786, Final Batch Loss: 1.2848982805735432e-05\n",
      "Epoch 3573, Loss: 0.01185632197666564, Final Batch Loss: 0.011029472574591637\n",
      "Epoch 3574, Loss: 0.0011120642557216343, Final Batch Loss: 0.0009881786536425352\n",
      "Epoch 3575, Loss: 0.050771555623214226, Final Batch Loss: 8.115064701996744e-05\n",
      "Epoch 3576, Loss: 0.013461333837767597, Final Batch Loss: 3.643512900453061e-05\n",
      "Epoch 3577, Loss: 0.0008587242737121414, Final Batch Loss: 2.2377756977220997e-05\n",
      "Epoch 3578, Loss: 0.03485619061393663, Final Batch Loss: 0.0034510502591729164\n",
      "Epoch 3579, Loss: 0.000546571802260587, Final Batch Loss: 0.0002156981936423108\n",
      "Epoch 3580, Loss: 0.0011904596904059872, Final Batch Loss: 0.00034711952321231365\n",
      "Epoch 3581, Loss: 0.0024676472712599207, Final Batch Loss: 0.0002544772869441658\n",
      "Epoch 3582, Loss: 0.0256551073071023, Final Batch Loss: 5.941712515777908e-05\n",
      "Epoch 3583, Loss: 0.0005062113705207594, Final Batch Loss: 0.0002807595010381192\n",
      "Epoch 3584, Loss: 0.0057045051544264425, Final Batch Loss: 6.831400241935626e-05\n",
      "Epoch 3585, Loss: 0.0052525157952914014, Final Batch Loss: 0.0001603468117536977\n",
      "Epoch 3586, Loss: 0.0021532355021918193, Final Batch Loss: 0.0011063233250752091\n",
      "Epoch 3587, Loss: 0.0006525036405946594, Final Batch Loss: 3.862258017761633e-05\n",
      "Epoch 3588, Loss: 0.0013329084977158345, Final Batch Loss: 2.821194902935531e-05\n",
      "Epoch 3589, Loss: 0.0016779823672550265, Final Batch Loss: 0.000470760598545894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3590, Loss: 0.0005107374836370582, Final Batch Loss: 0.00013282989675644785\n",
      "Epoch 3591, Loss: 0.0003142848336210591, Final Batch Loss: 1.0171647772949655e-05\n",
      "Epoch 3592, Loss: 0.0008334294761880301, Final Batch Loss: 0.0003557287564035505\n",
      "Epoch 3593, Loss: 0.0005771506039309315, Final Batch Loss: 0.00023596500977873802\n",
      "Epoch 3594, Loss: 0.000314837123369216, Final Batch Loss: 0.000211349266464822\n",
      "Epoch 3595, Loss: 0.00048380353473476134, Final Batch Loss: 5.3336469136411324e-05\n",
      "Epoch 3596, Loss: 0.017590184994332958, Final Batch Loss: 0.016535071656107903\n",
      "Epoch 3597, Loss: 0.0008417311837547459, Final Batch Loss: 0.00044613832142204046\n",
      "Epoch 3598, Loss: 0.011410313774831593, Final Batch Loss: 0.0011229431256651878\n",
      "Epoch 3599, Loss: 0.016034204578318167, Final Batch Loss: 2.7436013624537736e-05\n",
      "Epoch 3600, Loss: 0.0009266515626222827, Final Batch Loss: 0.00024644986842758954\n",
      "Epoch 3601, Loss: 0.004964641353581101, Final Batch Loss: 0.0008097274694591761\n",
      "Epoch 3602, Loss: 0.04196199795114808, Final Batch Loss: 0.003317014779895544\n",
      "Epoch 3603, Loss: 0.0011357313960616011, Final Batch Loss: 3.460042717051692e-05\n",
      "Epoch 3604, Loss: 0.0006071725620131474, Final Batch Loss: 0.00013378175208345056\n",
      "Epoch 3605, Loss: 0.0004418438911670819, Final Batch Loss: 8.42255903990008e-05\n",
      "Epoch 3606, Loss: 0.0017567987670190632, Final Batch Loss: 0.0008196348790079355\n",
      "Epoch 3607, Loss: 0.0015643358055967838, Final Batch Loss: 0.000888106762431562\n",
      "Epoch 3608, Loss: 0.001119425673095975, Final Batch Loss: 8.478463132632896e-05\n",
      "Epoch 3609, Loss: 0.0013665701844729483, Final Batch Loss: 9.623167716199532e-05\n",
      "Epoch 3610, Loss: 0.001242519065272063, Final Batch Loss: 0.0003355625958647579\n",
      "Epoch 3611, Loss: 0.001708046122075757, Final Batch Loss: 0.0009348572348244488\n",
      "Epoch 3612, Loss: 0.0033969889918807894, Final Batch Loss: 0.0002476399822626263\n",
      "Epoch 3613, Loss: 0.0005738842246501008, Final Batch Loss: 2.4583996491855942e-05\n",
      "Epoch 3614, Loss: 0.0015359062672359869, Final Batch Loss: 0.00022977795742917806\n",
      "Epoch 3615, Loss: 0.0006424052553484216, Final Batch Loss: 0.0002218545414507389\n",
      "Epoch 3616, Loss: 0.002025634988967795, Final Batch Loss: 0.0008890131139196455\n",
      "Epoch 3617, Loss: 0.0008055761991272448, Final Batch Loss: 5.147570846020244e-06\n",
      "Epoch 3618, Loss: 0.006547939599840902, Final Batch Loss: 8.470112516079098e-05\n",
      "Epoch 3619, Loss: 0.0010494855814613402, Final Batch Loss: 0.0007723905728198588\n",
      "Epoch 3620, Loss: 0.0006219610186235514, Final Batch Loss: 1.9306831745780073e-05\n",
      "Epoch 3621, Loss: 0.0021206006604188588, Final Batch Loss: 0.0011826131958514452\n",
      "Epoch 3622, Loss: 0.00043061609540018253, Final Batch Loss: 1.759495717124082e-05\n",
      "Epoch 3623, Loss: 0.0007016257950454019, Final Batch Loss: 0.00013229038449935615\n",
      "Epoch 3624, Loss: 0.00030936088205635315, Final Batch Loss: 0.00019717105897143483\n",
      "Epoch 3625, Loss: 0.0006863478520244826, Final Batch Loss: 0.0002483026182744652\n",
      "Epoch 3626, Loss: 0.000622733001364395, Final Batch Loss: 0.00027129481895826757\n",
      "Epoch 3627, Loss: 0.002492920382792363, Final Batch Loss: 2.0618419512175024e-05\n",
      "Epoch 3628, Loss: 0.0021351294744818006, Final Batch Loss: 2.7621674234978855e-05\n",
      "Epoch 3629, Loss: 0.0002924501895904541, Final Batch Loss: 6.538519664900377e-05\n",
      "Epoch 3630, Loss: 0.0008225203637266532, Final Batch Loss: 0.00011140344577142969\n",
      "Epoch 3631, Loss: 0.0005967975216663035, Final Batch Loss: 5.709329798264662e-06\n",
      "Epoch 3632, Loss: 0.0007573962379865407, Final Batch Loss: 6.445831331802765e-06\n",
      "Epoch 3633, Loss: 0.0014001277668285184, Final Batch Loss: 0.0010462978389114141\n",
      "Epoch 3634, Loss: 0.0018944720941362903, Final Batch Loss: 0.00033502388396300375\n",
      "Epoch 3635, Loss: 0.0005518709131138166, Final Batch Loss: 2.0803321604034863e-05\n",
      "Epoch 3636, Loss: 0.0004559882654575631, Final Batch Loss: 9.412036888534203e-05\n",
      "Epoch 3637, Loss: 0.0004345543406998331, Final Batch Loss: 4.617789090843871e-05\n",
      "Epoch 3638, Loss: 0.0009658635426603723, Final Batch Loss: 2.1412404748843983e-05\n",
      "Epoch 3639, Loss: 0.00042049127478094306, Final Batch Loss: 8.667496149428189e-05\n",
      "Epoch 3640, Loss: 0.0002576287170086289, Final Batch Loss: 0.00014510845358017832\n",
      "Epoch 3641, Loss: 0.0008612101810285822, Final Batch Loss: 0.00013713474618270993\n",
      "Epoch 3642, Loss: 0.0020950411380908918, Final Batch Loss: 1.4526751328958198e-05\n",
      "Epoch 3643, Loss: 0.00018470472787157632, Final Batch Loss: 2.9784307116642594e-05\n",
      "Epoch 3644, Loss: 0.002947387649328448, Final Batch Loss: 0.0003148214309476316\n",
      "Epoch 3645, Loss: 0.023922730673803017, Final Batch Loss: 0.000264682195847854\n",
      "Epoch 3646, Loss: 0.0005852767444594065, Final Batch Loss: 0.00045773101737722754\n",
      "Epoch 3647, Loss: 0.0016709663032088429, Final Batch Loss: 7.739085413049906e-05\n",
      "Epoch 3648, Loss: 0.0012272451967874076, Final Batch Loss: 0.0006598516483791173\n",
      "Epoch 3649, Loss: 0.0017220289319084259, Final Batch Loss: 0.0002268794341944158\n",
      "Epoch 3650, Loss: 0.0014486175691672543, Final Batch Loss: 0.0009338946547359228\n",
      "Epoch 3651, Loss: 0.0007434940803250356, Final Batch Loss: 1.3729273632634431e-05\n",
      "Epoch 3652, Loss: 0.002371341543039307, Final Batch Loss: 0.0009496344719082117\n",
      "Epoch 3653, Loss: 0.005858632899617078, Final Batch Loss: 6.551015758304857e-06\n",
      "Epoch 3654, Loss: 0.0035739626764552668, Final Batch Loss: 0.00011557778634596616\n",
      "Epoch 3655, Loss: 0.0009367097445647232, Final Batch Loss: 0.00034675688948482275\n",
      "Epoch 3656, Loss: 0.00028108260994486045, Final Batch Loss: 3.722958354046568e-05\n",
      "Epoch 3657, Loss: 0.002527551842831599, Final Batch Loss: 0.0020840256474912167\n",
      "Epoch 3658, Loss: 0.0008233374937844928, Final Batch Loss: 6.882400339236483e-05\n",
      "Epoch 3659, Loss: 0.0006088155423640274, Final Batch Loss: 0.00013915602175984532\n",
      "Epoch 3660, Loss: 0.000506479462274001, Final Batch Loss: 0.0002768997510429472\n",
      "Epoch 3661, Loss: 0.01288420168475568, Final Batch Loss: 8.782689110375941e-05\n",
      "Epoch 3662, Loss: 0.0032060596849987633, Final Batch Loss: 4.376500328362454e-06\n",
      "Epoch 3663, Loss: 0.0039374877269438, Final Batch Loss: 0.0034461207687854767\n",
      "Epoch 3664, Loss: 0.012161711487351567, Final Batch Loss: 0.00010105826368089765\n",
      "Epoch 3665, Loss: 0.003460954455931642, Final Batch Loss: 2.559583208494587e-06\n",
      "Epoch 3666, Loss: 0.0013340654568310129, Final Batch Loss: 9.785151632968336e-05\n",
      "Epoch 3667, Loss: 0.0007205086585599929, Final Batch Loss: 0.00018892301886808127\n",
      "Epoch 3668, Loss: 0.009006815007523983, Final Batch Loss: 0.00866181030869484\n",
      "Epoch 3669, Loss: 0.000493763660415425, Final Batch Loss: 2.021495129156392e-05\n",
      "Epoch 3670, Loss: 0.005085583328764187, Final Batch Loss: 0.003972657956182957\n",
      "Epoch 3671, Loss: 0.0006190190906636417, Final Batch Loss: 2.7247690013609827e-05\n",
      "Epoch 3672, Loss: 0.05087532163452124, Final Batch Loss: 0.039264604449272156\n",
      "Epoch 3673, Loss: 0.001318567341513699, Final Batch Loss: 0.0003947157529182732\n",
      "Epoch 3674, Loss: 0.00131730193788826, Final Batch Loss: 2.98370450764196e-05\n",
      "Epoch 3675, Loss: 0.0015935331030050293, Final Batch Loss: 0.00015218101907521486\n",
      "Epoch 3676, Loss: 0.0009950731273420388, Final Batch Loss: 0.0001296047994401306\n",
      "Epoch 3677, Loss: 0.0017813737231335836, Final Batch Loss: 2.3154478185460903e-05\n",
      "Epoch 3678, Loss: 0.0034020196471828967, Final Batch Loss: 0.0026607292238622904\n",
      "Epoch 3679, Loss: 0.00892920885962667, Final Batch Loss: 0.008359271101653576\n",
      "Epoch 3680, Loss: 0.0008336581813637167, Final Batch Loss: 3.57171957148239e-05\n",
      "Epoch 3681, Loss: 0.00015710257935097616, Final Batch Loss: 7.212987111415714e-05\n",
      "Epoch 3682, Loss: 0.0003734487036126666, Final Batch Loss: 5.152374797035009e-05\n",
      "Epoch 3683, Loss: 0.00039903048855194356, Final Batch Loss: 0.00019566966511774808\n",
      "Epoch 3684, Loss: 0.0013189398450776935, Final Batch Loss: 3.6506447941064835e-05\n",
      "Epoch 3685, Loss: 0.0006023737223586068, Final Batch Loss: 7.68088357290253e-05\n",
      "Epoch 3686, Loss: 0.0009638752817409113, Final Batch Loss: 0.00013947964180260897\n",
      "Epoch 3687, Loss: 0.0008474102723994292, Final Batch Loss: 0.0006716381176374853\n",
      "Epoch 3688, Loss: 0.0004634287743101595, Final Batch Loss: 5.472373231896199e-06\n",
      "Epoch 3689, Loss: 0.0024776362075726865, Final Batch Loss: 0.0022555405739694834\n",
      "Epoch 3690, Loss: 0.0007289994500752073, Final Batch Loss: 6.629333802266046e-05\n",
      "Epoch 3691, Loss: 0.000228898709792702, Final Batch Loss: 6.527299410663545e-05\n",
      "Epoch 3692, Loss: 0.0002078696525131818, Final Batch Loss: 4.705116953118704e-05\n",
      "Epoch 3693, Loss: 0.0005986123615002725, Final Batch Loss: 4.838959648623131e-05\n",
      "Epoch 3694, Loss: 0.000358677683834685, Final Batch Loss: 4.162672485108487e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3695, Loss: 0.0017270361913688248, Final Batch Loss: 5.049999526818283e-05\n",
      "Epoch 3696, Loss: 0.00026904214746537036, Final Batch Loss: 1.8193419236922637e-05\n",
      "Epoch 3697, Loss: 0.00016195049101952463, Final Batch Loss: 4.780511881108396e-05\n",
      "Epoch 3698, Loss: 0.0011946282847929979, Final Batch Loss: 0.0008278467576019466\n",
      "Epoch 3699, Loss: 0.00015813394793440239, Final Batch Loss: 8.133021037792787e-05\n",
      "Epoch 3700, Loss: 0.00029671852712453983, Final Batch Loss: 2.8882666356366826e-06\n",
      "Epoch 3701, Loss: 0.00023361657167697558, Final Batch Loss: 1.1606572115852032e-05\n",
      "Epoch 3702, Loss: 0.0011676760400405328, Final Batch Loss: 3.9621776522835717e-05\n",
      "Epoch 3703, Loss: 0.047255089963982755, Final Batch Loss: 0.00012673340097535402\n",
      "Epoch 3704, Loss: 0.00023946910368977115, Final Batch Loss: 1.3956108887214214e-05\n",
      "Epoch 3705, Loss: 0.01999747571790067, Final Batch Loss: 5.645779310725629e-05\n",
      "Epoch 3706, Loss: 2.1753253122369642e-05, Final Batch Loss: 3.6302822081779595e-06\n",
      "Epoch 3707, Loss: 0.04748388180269103, Final Batch Loss: 0.04723299294710159\n",
      "Epoch 3708, Loss: 0.0003404518138268031, Final Batch Loss: 2.5329263735329732e-05\n",
      "Epoch 3709, Loss: 0.0038506476339534856, Final Batch Loss: 0.0026740864850580692\n",
      "Epoch 3710, Loss: 8.234734059442417e-05, Final Batch Loss: 2.5816689230850898e-05\n",
      "Epoch 3711, Loss: 0.011733089748304337, Final Batch Loss: 0.011538849212229252\n",
      "Epoch 3712, Loss: 0.00029004994121351046, Final Batch Loss: 8.84641758602811e-06\n",
      "Epoch 3713, Loss: 0.008828214098684839, Final Batch Loss: 1.1740563422790729e-05\n",
      "Epoch 3714, Loss: 0.0010340923536205082, Final Batch Loss: 0.00018632203864399344\n",
      "Epoch 3715, Loss: 0.0031243749654095154, Final Batch Loss: 4.2770294385263696e-05\n",
      "Epoch 3716, Loss: 0.0044914990867255256, Final Batch Loss: 0.0036025000736117363\n",
      "Epoch 3717, Loss: 0.0021592287957901135, Final Batch Loss: 0.0008368176058866084\n",
      "Epoch 3718, Loss: 0.0003267972770117922, Final Batch Loss: 1.3459723049891181e-05\n",
      "Epoch 3719, Loss: 0.0004000674216513289, Final Batch Loss: 0.00024994686827994883\n",
      "Epoch 3720, Loss: 0.0009664571844041348, Final Batch Loss: 3.5074743209406734e-05\n",
      "Epoch 3721, Loss: 0.00029244951133478025, Final Batch Loss: 3.8247475458774716e-05\n",
      "Epoch 3722, Loss: 0.00037153211815166287, Final Batch Loss: 2.1851357814739458e-05\n",
      "Epoch 3723, Loss: 0.0021211880157352425, Final Batch Loss: 1.7124089936260134e-05\n",
      "Epoch 3724, Loss: 0.021846634575922508, Final Batch Loss: 0.0001119518929044716\n",
      "Epoch 3725, Loss: 0.0006135605872259475, Final Batch Loss: 0.00029127486050128937\n",
      "Epoch 3726, Loss: 0.0005780535429948941, Final Batch Loss: 3.6572946555679664e-05\n",
      "Epoch 3727, Loss: 0.010026147894677706, Final Batch Loss: 3.5182220017304644e-05\n",
      "Epoch 3728, Loss: 0.0009746876094141044, Final Batch Loss: 0.00013365125050768256\n",
      "Epoch 3729, Loss: 0.0002760182051133597, Final Batch Loss: 1.8126032955478877e-05\n",
      "Epoch 3730, Loss: 0.0011723448915290646, Final Batch Loss: 0.0002161913871532306\n",
      "Epoch 3731, Loss: 0.0005718764077755623, Final Batch Loss: 0.00010280334390699863\n",
      "Epoch 3732, Loss: 0.0016694883961463347, Final Batch Loss: 0.0012921844609081745\n",
      "Epoch 3733, Loss: 0.0008304683069582097, Final Batch Loss: 9.315487841377035e-05\n",
      "Epoch 3734, Loss: 0.0008098909866021131, Final Batch Loss: 0.0001547355786897242\n",
      "Epoch 3735, Loss: 0.0003323303487832163, Final Batch Loss: 8.808562415651977e-05\n",
      "Epoch 3736, Loss: 0.049199099613360886, Final Batch Loss: 1.0169797860726248e-05\n",
      "Epoch 3737, Loss: 0.002386566047789529, Final Batch Loss: 0.002188395941630006\n",
      "Epoch 3738, Loss: 0.0006231088677850494, Final Batch Loss: 0.00035753435804508626\n",
      "Epoch 3739, Loss: 0.0007954065586091019, Final Batch Loss: 9.146003139903769e-05\n",
      "Epoch 3740, Loss: 0.000623699164862046, Final Batch Loss: 3.1088969990378246e-05\n",
      "Epoch 3741, Loss: 0.00040439451186102815, Final Batch Loss: 0.00015206378884613514\n",
      "Epoch 3742, Loss: 0.0010398205813544337, Final Batch Loss: 0.00031694266363047063\n",
      "Epoch 3743, Loss: 0.0003631705912994221, Final Batch Loss: 3.7364439776865765e-05\n",
      "Epoch 3744, Loss: 0.0004005542868981138, Final Batch Loss: 7.003771315794438e-05\n",
      "Epoch 3745, Loss: 0.00040520742504668306, Final Batch Loss: 6.417587883333908e-06\n",
      "Epoch 3746, Loss: 0.0005627991904475493, Final Batch Loss: 7.920370262581855e-05\n",
      "Epoch 3747, Loss: 0.0011043027816413087, Final Batch Loss: 8.639191946713254e-06\n",
      "Epoch 3748, Loss: 0.0003343264925206313, Final Batch Loss: 0.000147843238664791\n",
      "Epoch 3749, Loss: 0.00030322443853947334, Final Batch Loss: 5.700367910321802e-05\n",
      "Epoch 3750, Loss: 0.0005937464138696669, Final Batch Loss: 3.302018012618646e-05\n",
      "Epoch 3751, Loss: 0.0007460244655703718, Final Batch Loss: 5.748554485762725e-06\n",
      "Epoch 3752, Loss: 0.011999213748822513, Final Batch Loss: 0.010551800020039082\n",
      "Epoch 3753, Loss: 0.0012309363146414398, Final Batch Loss: 1.3913427210354712e-05\n",
      "Epoch 3754, Loss: 0.005642834075842984, Final Batch Loss: 0.00030482318834401667\n",
      "Epoch 3755, Loss: 0.0005205168708926067, Final Batch Loss: 6.197948096087202e-05\n",
      "Epoch 3756, Loss: 0.0024498393904650584, Final Batch Loss: 0.0006900961743667722\n",
      "Epoch 3757, Loss: 0.005832780265336623, Final Batch Loss: 0.000747394107747823\n",
      "Epoch 3758, Loss: 0.0025229755983673385, Final Batch Loss: 5.1345477913855575e-06\n",
      "Epoch 3759, Loss: 0.001069159246981144, Final Batch Loss: 0.0001332401589024812\n",
      "Epoch 3760, Loss: 0.01273132781170716, Final Batch Loss: 0.000655975250992924\n",
      "Epoch 3761, Loss: 0.0009156663290923461, Final Batch Loss: 3.759265018743463e-05\n",
      "Epoch 3762, Loss: 0.002854338184988592, Final Batch Loss: 7.835462020011619e-05\n",
      "Epoch 3763, Loss: 0.0015769959427416325, Final Batch Loss: 0.00023910286836326122\n",
      "Epoch 3764, Loss: 0.0021747142418462317, Final Batch Loss: 0.00022125852410681546\n",
      "Epoch 3765, Loss: 0.002437073617329588, Final Batch Loss: 5.130012868903577e-05\n",
      "Epoch 3766, Loss: 0.0008509750005032402, Final Batch Loss: 2.870255775633268e-05\n",
      "Epoch 3767, Loss: 0.002087792305246694, Final Batch Loss: 0.0010661354754120111\n",
      "Epoch 3768, Loss: 0.00024362191834370606, Final Batch Loss: 4.396142321638763e-05\n",
      "Epoch 3769, Loss: 0.0004338601174822543, Final Batch Loss: 0.0001097114582080394\n",
      "Epoch 3770, Loss: 0.0019972363479610067, Final Batch Loss: 4.149844971834682e-05\n",
      "Epoch 3771, Loss: 0.0005386068514781073, Final Batch Loss: 0.00016796101408544928\n",
      "Epoch 3772, Loss: 0.0011478922169771977, Final Batch Loss: 4.7614295908715576e-05\n",
      "Epoch 3773, Loss: 0.0005227969795669196, Final Batch Loss: 0.00034142323420383036\n",
      "Epoch 3774, Loss: 0.0029425951943267137, Final Batch Loss: 0.0024236454628407955\n",
      "Epoch 3775, Loss: 0.0010237866063107504, Final Batch Loss: 0.0007393543492071331\n",
      "Epoch 3776, Loss: 0.0006219628157850821, Final Batch Loss: 3.3272855944233015e-05\n",
      "Epoch 3777, Loss: 0.0005953170420980314, Final Batch Loss: 6.132091584731825e-06\n",
      "Epoch 3778, Loss: 0.0008936099184211344, Final Batch Loss: 0.00013086407852824777\n",
      "Epoch 3779, Loss: 0.0003724075904756319, Final Batch Loss: 3.751572876353748e-05\n",
      "Epoch 3780, Loss: 0.00023255481937667355, Final Batch Loss: 0.00010291558282915503\n",
      "Epoch 3781, Loss: 0.00026365365556557663, Final Batch Loss: 0.00017585165915079415\n",
      "Epoch 3782, Loss: 0.0005180992102395976, Final Batch Loss: 0.00012130791583331302\n",
      "Epoch 3783, Loss: 0.0005696966472896747, Final Batch Loss: 0.00030989418155513704\n",
      "Epoch 3784, Loss: 0.0003100495414400939, Final Batch Loss: 9.555178985465318e-05\n",
      "Epoch 3785, Loss: 0.00023195989524538163, Final Batch Loss: 0.00010384302004240453\n",
      "Epoch 3786, Loss: 0.0003825212424999336, Final Batch Loss: 1.884280027297791e-05\n",
      "Epoch 3787, Loss: 0.00025420232668693643, Final Batch Loss: 1.0677358659449965e-05\n",
      "Epoch 3788, Loss: 0.0027302934977342375, Final Batch Loss: 0.00018894989625550807\n",
      "Epoch 3789, Loss: 0.016993475405797653, Final Batch Loss: 9.978762136597652e-06\n",
      "Epoch 3790, Loss: 0.001026578713208437, Final Batch Loss: 4.750034349854104e-05\n",
      "Epoch 3791, Loss: 0.0005461785503939609, Final Batch Loss: 6.528772064484656e-05\n",
      "Epoch 3792, Loss: 0.0009534207883916679, Final Batch Loss: 9.18374935281463e-05\n",
      "Epoch 3793, Loss: 0.0007785983762005344, Final Batch Loss: 0.00010326897609047592\n",
      "Epoch 3794, Loss: 0.000263320511294296, Final Batch Loss: 3.4443048207322136e-05\n",
      "Epoch 3795, Loss: 0.021582827423117124, Final Batch Loss: 0.000627535511739552\n",
      "Epoch 3796, Loss: 0.001078833525752998, Final Batch Loss: 8.256328328570817e-06\n",
      "Epoch 3797, Loss: 0.0003531619977366063, Final Batch Loss: 1.196612629428273e-05\n",
      "Epoch 3798, Loss: 0.000386247677852225, Final Batch Loss: 7.637040835106745e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3799, Loss: 0.0016030895912990673, Final Batch Loss: 0.0006794735672883689\n",
      "Epoch 3800, Loss: 0.0023142250065575354, Final Batch Loss: 0.00034061537007801235\n",
      "Epoch 3801, Loss: 0.0001934619936037052, Final Batch Loss: 4.904954766971059e-05\n",
      "Epoch 3802, Loss: 0.0011781454068113817, Final Batch Loss: 2.3285434508579783e-05\n",
      "Epoch 3803, Loss: 0.007339537594702961, Final Batch Loss: 0.00011804412497440353\n",
      "Epoch 3804, Loss: 0.0007940533432702068, Final Batch Loss: 4.827910379390232e-05\n",
      "Epoch 3805, Loss: 0.0034454492706572637, Final Batch Loss: 6.347255839500576e-05\n",
      "Epoch 3806, Loss: 0.0006049238836567383, Final Batch Loss: 0.0001834337308537215\n",
      "Epoch 3807, Loss: 0.027140586970290315, Final Batch Loss: 0.0003544884384609759\n",
      "Epoch 3808, Loss: 0.00019224640072934562, Final Batch Loss: 3.990088225691579e-05\n",
      "Epoch 3809, Loss: 0.0004222185943945078, Final Batch Loss: 2.3861948648118414e-05\n",
      "Epoch 3810, Loss: 0.0025404091211385094, Final Batch Loss: 2.8486900191637687e-05\n",
      "Epoch 3811, Loss: 0.0018100705456163269, Final Batch Loss: 1.9500464986776933e-05\n",
      "Epoch 3812, Loss: 0.0004611546837622882, Final Batch Loss: 4.574439117277507e-06\n",
      "Epoch 3813, Loss: 0.025908523801490446, Final Batch Loss: 1.930870212163427e-06\n",
      "Epoch 3814, Loss: 0.0002931219914898975, Final Batch Loss: 8.47430492285639e-05\n",
      "Epoch 3815, Loss: 0.00025820878909144085, Final Batch Loss: 5.2298808441264555e-05\n",
      "Epoch 3816, Loss: 0.000420643200413906, Final Batch Loss: 0.00018445031309965998\n",
      "Epoch 3817, Loss: 0.001173409054899821, Final Batch Loss: 9.801935811992735e-05\n",
      "Epoch 3818, Loss: 0.0006690804034406028, Final Batch Loss: 0.00017464674601797014\n",
      "Epoch 3819, Loss: 0.0002844957930392411, Final Batch Loss: 1.414414327882696e-05\n",
      "Epoch 3820, Loss: 0.0017411646113032475, Final Batch Loss: 0.00032405220554210246\n",
      "Epoch 3821, Loss: 0.0044518311879073735, Final Batch Loss: 1.797810909920372e-06\n",
      "Epoch 3822, Loss: 0.001069950871169567, Final Batch Loss: 9.997858433052897e-05\n",
      "Epoch 3823, Loss: 0.00042336698606959544, Final Batch Loss: 4.7130986786214635e-05\n",
      "Epoch 3824, Loss: 0.0010746641928562894, Final Batch Loss: 7.073639426380396e-05\n",
      "Epoch 3825, Loss: 0.002343348132853862, Final Batch Loss: 0.00046693836338818073\n",
      "Epoch 3826, Loss: 0.0002712657587835565, Final Batch Loss: 4.5085900637786835e-05\n",
      "Epoch 3827, Loss: 0.001278755909879692, Final Batch Loss: 0.00035318059963174164\n",
      "Epoch 3828, Loss: 0.00035923054747399874, Final Batch Loss: 0.00015783404523972422\n",
      "Epoch 3829, Loss: 0.00035109790405840613, Final Batch Loss: 0.00024525035405531526\n",
      "Epoch 3830, Loss: 0.001866434540716, Final Batch Loss: 9.754166967468336e-05\n",
      "Epoch 3831, Loss: 0.0005530978278329712, Final Batch Loss: 3.189974449924193e-05\n",
      "Epoch 3832, Loss: 0.0004994668026938598, Final Batch Loss: 3.208505631846492e-06\n",
      "Epoch 3833, Loss: 0.0007242184801725671, Final Batch Loss: 5.526596214622259e-05\n",
      "Epoch 3834, Loss: 0.00369422516450868, Final Batch Loss: 0.0001314586406806484\n",
      "Epoch 3835, Loss: 0.018182345607783645, Final Batch Loss: 0.01586798205971718\n",
      "Epoch 3836, Loss: 0.0006448956119129434, Final Batch Loss: 8.342444925801829e-05\n",
      "Epoch 3837, Loss: 0.0005145635441294871, Final Batch Loss: 4.576003993861377e-05\n",
      "Epoch 3838, Loss: 9.052449149749009e-05, Final Batch Loss: 1.7969647160498425e-05\n",
      "Epoch 3839, Loss: 0.001233610264307572, Final Batch Loss: 0.00038863386726006866\n",
      "Epoch 3840, Loss: 0.0010218990755674895, Final Batch Loss: 5.209036316955462e-06\n",
      "Epoch 3841, Loss: 0.0014103269968472887, Final Batch Loss: 0.0006182474317029119\n",
      "Epoch 3842, Loss: 0.00023418438286171295, Final Batch Loss: 3.5259661672171205e-05\n",
      "Epoch 3843, Loss: 0.00021008044859627262, Final Batch Loss: 4.60307091998402e-05\n",
      "Epoch 3844, Loss: 0.004903317698335741, Final Batch Loss: 3.1858937290962785e-05\n",
      "Epoch 3845, Loss: 7.412558920805168e-05, Final Batch Loss: 3.181258534823428e-06\n",
      "Epoch 3846, Loss: 0.0005415424377588351, Final Batch Loss: 1.089232000595075e-06\n",
      "Epoch 3847, Loss: 0.0007633403729414567, Final Batch Loss: 0.00061117421137169\n",
      "Epoch 3848, Loss: 0.0008359641360584646, Final Batch Loss: 0.00030382187105715275\n",
      "Epoch 3849, Loss: 0.00029036367777734995, Final Batch Loss: 4.770029045175761e-05\n",
      "Epoch 3850, Loss: 0.006571124744368717, Final Batch Loss: 0.0012341541005298495\n",
      "Epoch 3851, Loss: 0.0007019174812512574, Final Batch Loss: 1.259531131836411e-06\n",
      "Epoch 3852, Loss: 0.0005609036015812308, Final Batch Loss: 0.00016804476035758853\n",
      "Epoch 3853, Loss: 0.001087736636691261, Final Batch Loss: 0.00041431892896071076\n",
      "Epoch 3854, Loss: 0.0002849532866093796, Final Batch Loss: 9.368947212351486e-05\n",
      "Epoch 3855, Loss: 4.180310384072072e-05, Final Batch Loss: 3.0167168461048277e-06\n",
      "Epoch 3856, Loss: 0.03991048468560621, Final Batch Loss: 2.921115083154291e-05\n",
      "Epoch 3857, Loss: 8.169646253008978e-05, Final Batch Loss: 2.3164107005868573e-06\n",
      "Epoch 3858, Loss: 0.00040442375757265836, Final Batch Loss: 1.857648021541536e-05\n",
      "Epoch 3859, Loss: 0.0004785422897839453, Final Batch Loss: 1.7700167518341914e-05\n",
      "Epoch 3860, Loss: 0.004544886920484714, Final Batch Loss: 0.0038795594591647387\n",
      "Epoch 3861, Loss: 0.010924305592197925, Final Batch Loss: 0.000812678481452167\n",
      "Epoch 3862, Loss: 0.027781881635746686, Final Batch Loss: 5.1897204684792086e-05\n",
      "Epoch 3863, Loss: 0.022364237662259256, Final Batch Loss: 0.02169547975063324\n",
      "Epoch 3864, Loss: 0.0021404687358881347, Final Batch Loss: 0.001860553864389658\n",
      "Epoch 3865, Loss: 0.0005804242537124082, Final Batch Loss: 0.00023235476692207158\n",
      "Epoch 3866, Loss: 0.0019847394432872534, Final Batch Loss: 0.001163589651696384\n",
      "Epoch 3867, Loss: 0.0019839946544379927, Final Batch Loss: 0.0015324383275583386\n",
      "Epoch 3868, Loss: 0.0015139763854676858, Final Batch Loss: 0.0010744070168584585\n",
      "Epoch 3869, Loss: 0.0005871029206900857, Final Batch Loss: 0.00020068172307219356\n",
      "Epoch 3870, Loss: 0.003760789835723699, Final Batch Loss: 0.0028948509134352207\n",
      "Epoch 3871, Loss: 0.001038818882079795, Final Batch Loss: 0.0006030280492268503\n",
      "Epoch 3872, Loss: 0.004697989199485164, Final Batch Loss: 0.0018921422306448221\n",
      "Epoch 3873, Loss: 0.0005207538870308781, Final Batch Loss: 0.0002682918857317418\n",
      "Epoch 3874, Loss: 0.004242993047228083, Final Batch Loss: 0.0028988171834498644\n",
      "Epoch 3875, Loss: 0.0004314527668611845, Final Batch Loss: 0.00020748292445205152\n",
      "Epoch 3876, Loss: 0.00782267780687107, Final Batch Loss: 1.4394835488928948e-05\n",
      "Epoch 3877, Loss: 0.0006131512673164252, Final Batch Loss: 0.00011734925647033378\n",
      "Epoch 3878, Loss: 0.0006123990460764617, Final Batch Loss: 0.00015448679914698005\n",
      "Epoch 3879, Loss: 0.000685451137542259, Final Batch Loss: 0.0002348009729757905\n",
      "Epoch 3880, Loss: 0.004566944258840522, Final Batch Loss: 3.695193663588725e-05\n",
      "Epoch 3881, Loss: 0.0005055695219198242, Final Batch Loss: 5.924372817389667e-05\n",
      "Epoch 3882, Loss: 0.00041893284651450813, Final Batch Loss: 0.00025152741000056267\n",
      "Epoch 3883, Loss: 0.0006299851993389893, Final Batch Loss: 1.891627107397653e-05\n",
      "Epoch 3884, Loss: 0.0002892756510846084, Final Batch Loss: 0.00017900406965054572\n",
      "Epoch 3885, Loss: 0.00038879243584233336, Final Batch Loss: 2.057161327684298e-05\n",
      "Epoch 3886, Loss: 0.0014044212184671778, Final Batch Loss: 7.270203059306368e-05\n",
      "Epoch 3887, Loss: 0.0004098389408682124, Final Batch Loss: 6.143261271063238e-05\n",
      "Epoch 3888, Loss: 0.0002575162834546063, Final Batch Loss: 7.095285400282592e-05\n",
      "Epoch 3889, Loss: 0.0003648054607765516, Final Batch Loss: 0.00010851037950487807\n",
      "Epoch 3890, Loss: 0.0010732214395829942, Final Batch Loss: 0.00015656657342333347\n",
      "Epoch 3891, Loss: 0.0013402597505773883, Final Batch Loss: 2.2785663531976752e-05\n",
      "Epoch 3892, Loss: 0.00033010743936756626, Final Batch Loss: 0.0001894316083053127\n",
      "Epoch 3893, Loss: 0.00045995692562428303, Final Batch Loss: 0.00031048772507347167\n",
      "Epoch 3894, Loss: 0.00022956943848839728, Final Batch Loss: 0.0001493655436206609\n",
      "Epoch 3895, Loss: 0.000279357491308474, Final Batch Loss: 0.00012574718857649714\n",
      "Epoch 3896, Loss: 0.00887971984889191, Final Batch Loss: 0.0006718295626342297\n",
      "Epoch 3897, Loss: 0.00045098193663761776, Final Batch Loss: 2.371695927649853e-06\n",
      "Epoch 3898, Loss: 0.00035571016542235157, Final Batch Loss: 1.0011835001932923e-05\n",
      "Epoch 3899, Loss: 0.01361126267875079, Final Batch Loss: 0.0011588744819164276\n",
      "Epoch 3900, Loss: 0.007999185057997238, Final Batch Loss: 0.0005335866007953882\n",
      "Epoch 3901, Loss: 0.0552361238769663, Final Batch Loss: 0.05489461123943329\n",
      "Epoch 3902, Loss: 0.0007018257533673022, Final Batch Loss: 3.3285618883382995e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3903, Loss: 0.00019125897324556718, Final Batch Loss: 2.1037749320385046e-06\n",
      "Epoch 3904, Loss: 0.004871917062700959, Final Batch Loss: 6.817979738116264e-05\n",
      "Epoch 3905, Loss: 0.00037507123306568246, Final Batch Loss: 4.40087569586467e-05\n",
      "Epoch 3906, Loss: 0.0005216086155996891, Final Batch Loss: 7.574244955321774e-05\n",
      "Epoch 3907, Loss: 0.0012463871125873993, Final Batch Loss: 8.828313002595678e-05\n",
      "Epoch 3908, Loss: 0.0002485208342477563, Final Batch Loss: 1.1834442375402432e-05\n",
      "Epoch 3909, Loss: 0.000357745768269524, Final Batch Loss: 0.00010333771933801472\n",
      "Epoch 3910, Loss: 0.0006256769083847757, Final Batch Loss: 3.1704676075605676e-05\n",
      "Epoch 3911, Loss: 0.0002585532783996314, Final Batch Loss: 2.8178525099065155e-05\n",
      "Epoch 3912, Loss: 0.0006762170960428193, Final Batch Loss: 0.0002768735575955361\n",
      "Epoch 3913, Loss: 0.0005054210923844948, Final Batch Loss: 0.00022148860443849117\n",
      "Epoch 3914, Loss: 0.0011320419944240712, Final Batch Loss: 0.00012486567720770836\n",
      "Epoch 3915, Loss: 0.0005957156281510834, Final Batch Loss: 3.8184080040082335e-06\n",
      "Epoch 3916, Loss: 0.0009748310112627223, Final Batch Loss: 7.570988964289427e-05\n",
      "Epoch 3917, Loss: 0.0001924522002809681, Final Batch Loss: 1.2236811016919091e-05\n",
      "Epoch 3918, Loss: 0.001119552694945014, Final Batch Loss: 8.702167542651296e-05\n",
      "Epoch 3919, Loss: 0.00010929269319603918, Final Batch Loss: 6.224228854989633e-05\n",
      "Epoch 3920, Loss: 0.0003545403169482597, Final Batch Loss: 1.4634068975283299e-05\n",
      "Epoch 3921, Loss: 0.0008307928619615268, Final Batch Loss: 2.1914634999120608e-05\n",
      "Epoch 3922, Loss: 0.006704122672090307, Final Batch Loss: 0.0004267210606485605\n",
      "Epoch 3923, Loss: 0.0006370035298459698, Final Batch Loss: 0.00013647749437950552\n",
      "Epoch 3924, Loss: 0.0016691878299752716, Final Batch Loss: 0.0010962605010718107\n",
      "Epoch 3925, Loss: 0.00024490762734785676, Final Batch Loss: 2.0242880054865964e-05\n",
      "Epoch 3926, Loss: 0.000468082565930672, Final Batch Loss: 6.279442459344864e-06\n",
      "Epoch 3927, Loss: 0.00030351145323948003, Final Batch Loss: 0.00011430621088948101\n",
      "Epoch 3928, Loss: 0.00033394238926121034, Final Batch Loss: 0.00014501198893412948\n",
      "Epoch 3929, Loss: 0.0007248204324241669, Final Batch Loss: 4.44313591287937e-05\n",
      "Epoch 3930, Loss: 0.01328615985403303, Final Batch Loss: 0.0015272876480594277\n",
      "Epoch 3931, Loss: 0.0014097321109147742, Final Batch Loss: 6.464249599957839e-05\n",
      "Epoch 3932, Loss: 0.01428873968325206, Final Batch Loss: 0.00011648793588392437\n",
      "Epoch 3933, Loss: 0.00038292434328468516, Final Batch Loss: 0.00012588989920914173\n",
      "Epoch 3934, Loss: 0.00157147442769201, Final Batch Loss: 5.0363851187285036e-05\n",
      "Epoch 3935, Loss: 0.010023942311818246, Final Batch Loss: 0.006502336356788874\n",
      "Epoch 3936, Loss: 0.0003616912363213487, Final Batch Loss: 6.456116534536704e-05\n",
      "Epoch 3937, Loss: 0.0003630404426075984, Final Batch Loss: 1.0412000847281888e-05\n",
      "Epoch 3938, Loss: 0.012725469701763359, Final Batch Loss: 0.00010587370343273506\n",
      "Epoch 3939, Loss: 0.0007521619263570756, Final Batch Loss: 0.0003468486829660833\n",
      "Epoch 3940, Loss: 0.00016400332242483273, Final Batch Loss: 1.4704388377140276e-05\n",
      "Epoch 3941, Loss: 0.0007310640294235782, Final Batch Loss: 2.91400465357583e-05\n",
      "Epoch 3942, Loss: 0.000483523170260014, Final Batch Loss: 0.0003813614894170314\n",
      "Epoch 3943, Loss: 0.0007220293155114632, Final Batch Loss: 0.00022138157510198653\n",
      "Epoch 3944, Loss: 0.0003910387240466662, Final Batch Loss: 9.243580279871821e-05\n",
      "Epoch 3945, Loss: 0.0001708814306766726, Final Batch Loss: 1.965808041859418e-05\n",
      "Epoch 3946, Loss: 0.0010414637481517275, Final Batch Loss: 0.0008174541871994734\n",
      "Epoch 3947, Loss: 0.0003369931478118815, Final Batch Loss: 0.0001230805937666446\n",
      "Epoch 3948, Loss: 0.00037165045796427876, Final Batch Loss: 1.5105675629456528e-05\n",
      "Epoch 3949, Loss: 0.000790457459515892, Final Batch Loss: 1.665843592491001e-05\n",
      "Epoch 3950, Loss: 0.001077062202966772, Final Batch Loss: 0.00010729930363595486\n",
      "Epoch 3951, Loss: 0.00045900194709247444, Final Batch Loss: 1.2188249456812628e-05\n",
      "Epoch 3952, Loss: 0.00019531954694684828, Final Batch Loss: 4.4018752305419184e-06\n",
      "Epoch 3953, Loss: 0.00029827135358573287, Final Batch Loss: 8.145353058353066e-05\n",
      "Epoch 3954, Loss: 0.0005512099960469641, Final Batch Loss: 3.101853872067295e-05\n",
      "Epoch 3955, Loss: 0.0005915840638408554, Final Batch Loss: 0.0004382078186608851\n",
      "Epoch 3956, Loss: 0.0073055042867054, Final Batch Loss: 2.7745756597141735e-05\n",
      "Epoch 3957, Loss: 0.00033964582598855486, Final Batch Loss: 7.481835200451314e-05\n",
      "Epoch 3958, Loss: 0.002710779015615117, Final Batch Loss: 0.0016871485859155655\n",
      "Epoch 3959, Loss: 0.011282134742941707, Final Batch Loss: 0.0004559060325846076\n",
      "Epoch 3960, Loss: 0.000918100909984787, Final Batch Loss: 0.0001065111646312289\n",
      "Epoch 3961, Loss: 0.017673910027951933, Final Batch Loss: 0.0002388995053479448\n",
      "Epoch 3962, Loss: 0.00587073338101618, Final Batch Loss: 0.00502526992931962\n",
      "Epoch 3963, Loss: 0.001530276844277978, Final Batch Loss: 6.688810390187427e-05\n",
      "Epoch 3964, Loss: 0.0004961195813848462, Final Batch Loss: 4.789639660884859e-06\n",
      "Epoch 3965, Loss: 0.0008272715422208421, Final Batch Loss: 0.00027830226463265717\n",
      "Epoch 3966, Loss: 0.0018135007594537456, Final Batch Loss: 0.00040217203786596656\n",
      "Epoch 3967, Loss: 0.005000210971047636, Final Batch Loss: 6.901344022480771e-05\n",
      "Epoch 3968, Loss: 0.0006475996638073411, Final Batch Loss: 0.0002037410595221445\n",
      "Epoch 3969, Loss: 0.00038831555866636336, Final Batch Loss: 9.562226478010416e-05\n",
      "Epoch 3970, Loss: 0.00021507421206479194, Final Batch Loss: 3.3780870580812916e-05\n",
      "Epoch 3971, Loss: 0.00013440751172311138, Final Batch Loss: 4.26785736635793e-05\n",
      "Epoch 3972, Loss: 0.0003773871976591181, Final Batch Loss: 4.886551323579624e-06\n",
      "Epoch 3973, Loss: 0.0005156735205673613, Final Batch Loss: 4.738787902169861e-05\n",
      "Epoch 3974, Loss: 0.006727910924382741, Final Batch Loss: 0.0002816145133692771\n",
      "Epoch 3975, Loss: 0.0032344347055186518, Final Batch Loss: 7.51012921682559e-05\n",
      "Epoch 3976, Loss: 0.0002473870317771798, Final Batch Loss: 9.718103683553636e-05\n",
      "Epoch 3977, Loss: 0.00041350054016220383, Final Batch Loss: 3.785829176194966e-05\n",
      "Epoch 3978, Loss: 0.007355283363722265, Final Batch Loss: 0.006402680650353432\n",
      "Epoch 3979, Loss: 0.007517657053540461, Final Batch Loss: 7.440614717779681e-05\n",
      "Epoch 3980, Loss: 0.003723526791873155, Final Batch Loss: 4.719644130091183e-05\n",
      "Epoch 3981, Loss: 0.0015242796998791164, Final Batch Loss: 0.0002334361051907763\n",
      "Epoch 3982, Loss: 0.009660900952439988, Final Batch Loss: 2.4106051569106057e-05\n",
      "Epoch 3983, Loss: 0.00859820119876531, Final Batch Loss: 1.2131309631513432e-05\n",
      "Epoch 3984, Loss: 0.0010177432309319556, Final Batch Loss: 0.000922500854358077\n",
      "Epoch 3985, Loss: 0.0011504964833193299, Final Batch Loss: 9.169790473606554e-07\n",
      "Epoch 3986, Loss: 0.010889546876569511, Final Batch Loss: 5.7255067076766863e-05\n",
      "Epoch 3987, Loss: 0.0003965020296163857, Final Batch Loss: 0.00011539796832948923\n",
      "Epoch 3988, Loss: 0.03685433837745222, Final Batch Loss: 0.00012634233280550689\n",
      "Epoch 3989, Loss: 0.0003897404021699913, Final Batch Loss: 8.68892457219772e-05\n",
      "Epoch 3990, Loss: 0.006752126888386556, Final Batch Loss: 0.00012693896132986993\n",
      "Epoch 3991, Loss: 0.000540886314411182, Final Batch Loss: 0.00019171673920936882\n",
      "Epoch 3992, Loss: 0.006441257195547223, Final Batch Loss: 0.0003812609356828034\n",
      "Epoch 3993, Loss: 0.0014884773172525456, Final Batch Loss: 0.00023313051497098058\n",
      "Epoch 3994, Loss: 0.0032700487945476198, Final Batch Loss: 9.617338037060108e-06\n",
      "Epoch 3995, Loss: 0.0016473627038067207, Final Batch Loss: 0.00118736969307065\n",
      "Epoch 3996, Loss: 0.002941004073363729, Final Batch Loss: 0.0026162825524806976\n",
      "Epoch 3997, Loss: 0.0004830177058465779, Final Batch Loss: 2.3763896024320275e-05\n",
      "Epoch 3998, Loss: 0.0009757231227922603, Final Batch Loss: 7.298923264897894e-06\n",
      "Epoch 3999, Loss: 0.0008225457786465995, Final Batch Loss: 0.0003263135440647602\n",
      "Epoch 4000, Loss: 0.009374090710480232, Final Batch Loss: 0.007361193187534809\n",
      "Epoch 4001, Loss: 0.0017612077754165512, Final Batch Loss: 0.0003456840058788657\n",
      "Epoch 4002, Loss: 0.0008671077393955784, Final Batch Loss: 1.832023735914845e-05\n",
      "Epoch 4003, Loss: 0.0003313720335427206, Final Batch Loss: 6.057224891264923e-05\n",
      "Epoch 4004, Loss: 0.0007255882376284717, Final Batch Loss: 0.00011994239321211353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4005, Loss: 0.001345457749266643, Final Batch Loss: 0.0004396714211907238\n",
      "Epoch 4006, Loss: 0.0006738827687513549, Final Batch Loss: 0.00019610457820817828\n",
      "Epoch 4007, Loss: 0.0011474049642856698, Final Batch Loss: 4.8918162065092474e-05\n",
      "Epoch 4008, Loss: 0.00997981489126687, Final Batch Loss: 0.00957492832094431\n",
      "Epoch 4009, Loss: 0.0018503401915950235, Final Batch Loss: 0.00032006684341467917\n",
      "Epoch 4010, Loss: 0.0025267240416724235, Final Batch Loss: 0.0005807153065688908\n",
      "Epoch 4011, Loss: 0.0023222388081194367, Final Batch Loss: 0.00011007739522028714\n",
      "Epoch 4012, Loss: 0.0009624808808439411, Final Batch Loss: 2.7989626687485725e-05\n",
      "Epoch 4013, Loss: 0.004198275102680782, Final Batch Loss: 0.002447923645377159\n",
      "Epoch 4014, Loss: 0.0012473750830395147, Final Batch Loss: 5.748115654569119e-05\n",
      "Epoch 4015, Loss: 0.00028988475696678506, Final Batch Loss: 1.55162069859216e-06\n",
      "Epoch 4016, Loss: 0.0012000635906588286, Final Batch Loss: 7.436677697114646e-05\n",
      "Epoch 4017, Loss: 0.0003233904826629441, Final Batch Loss: 0.0001624825963517651\n",
      "Epoch 4018, Loss: 0.00031173910792858806, Final Batch Loss: 7.993589679244906e-05\n",
      "Epoch 4019, Loss: 0.00043622678640531376, Final Batch Loss: 0.00012232066364958882\n",
      "Epoch 4020, Loss: 0.0006433416638174094, Final Batch Loss: 4.991000605514273e-05\n",
      "Epoch 4021, Loss: 0.00027031141144107096, Final Batch Loss: 5.1230050303274766e-05\n",
      "Epoch 4022, Loss: 0.002509207548428094, Final Batch Loss: 0.0013134449254721403\n",
      "Epoch 4023, Loss: 0.0008424014285992598, Final Batch Loss: 2.490455881343223e-05\n",
      "Epoch 4024, Loss: 0.0007789030678395648, Final Batch Loss: 0.00013375723210629076\n",
      "Epoch 4025, Loss: 0.00022260964942688588, Final Batch Loss: 7.870011177146807e-05\n",
      "Epoch 4026, Loss: 0.00036904368334944593, Final Batch Loss: 1.4636209925811272e-05\n",
      "Epoch 4027, Loss: 0.0015375461225630715, Final Batch Loss: 0.00026955080102197826\n",
      "Epoch 4028, Loss: 0.0016799217783045606, Final Batch Loss: 2.6855297619476914e-05\n",
      "Epoch 4029, Loss: 0.0003133450177301711, Final Batch Loss: 4.346579316916177e-06\n",
      "Epoch 4030, Loss: 0.0002728249201027211, Final Batch Loss: 6.130011024652049e-05\n",
      "Epoch 4031, Loss: 0.0009617040013836231, Final Batch Loss: 0.0005463768029585481\n",
      "Epoch 4032, Loss: 0.0006304628827820125, Final Batch Loss: 2.707307976379525e-05\n",
      "Epoch 4033, Loss: 0.00012253440581844188, Final Batch Loss: 1.912120387714822e-05\n",
      "Epoch 4034, Loss: 0.0005630657137771777, Final Batch Loss: 0.00048393019824288785\n",
      "Epoch 4035, Loss: 0.002992081703268923, Final Batch Loss: 3.497445140965283e-05\n",
      "Epoch 4036, Loss: 0.0005016936256652116, Final Batch Loss: 0.0004160795942880213\n",
      "Epoch 4037, Loss: 0.000785183030529879, Final Batch Loss: 5.970669008092955e-05\n",
      "Epoch 4038, Loss: 0.0010307593547622673, Final Batch Loss: 0.0003782077692449093\n",
      "Epoch 4039, Loss: 0.00019223242679800023, Final Batch Loss: 7.539422313129762e-06\n",
      "Epoch 4040, Loss: 0.0018330991279071895, Final Batch Loss: 2.4443301299470477e-05\n",
      "Epoch 4041, Loss: 0.0022375567314156797, Final Batch Loss: 9.273453906644136e-05\n",
      "Epoch 4042, Loss: 0.000847833653097041, Final Batch Loss: 6.882756133563817e-05\n",
      "Epoch 4043, Loss: 0.0008308766737172846, Final Batch Loss: 0.0001781038154149428\n",
      "Epoch 4044, Loss: 0.00059639920709742, Final Batch Loss: 1.1472339792817365e-05\n",
      "Epoch 4045, Loss: 0.0003728670926648192, Final Batch Loss: 6.37096309219487e-05\n",
      "Epoch 4046, Loss: 0.0006912492542596738, Final Batch Loss: 2.6858472210733453e-06\n",
      "Epoch 4047, Loss: 0.00047611515128664905, Final Batch Loss: 0.0003353441716171801\n",
      "Epoch 4048, Loss: 0.00026158098171435995, Final Batch Loss: 4.4436219468479976e-05\n",
      "Epoch 4049, Loss: 0.00017818372134570382, Final Batch Loss: 4.193288259557448e-05\n",
      "Epoch 4050, Loss: 0.0007852956359784002, Final Batch Loss: 2.2320333300740458e-05\n",
      "Epoch 4051, Loss: 0.004821650552912615, Final Batch Loss: 9.386422607349232e-05\n",
      "Epoch 4052, Loss: 0.00021400200785137713, Final Batch Loss: 7.201799598988146e-05\n",
      "Epoch 4053, Loss: 0.0016142532549565658, Final Batch Loss: 6.770175241399556e-05\n",
      "Epoch 4054, Loss: 0.00014813549466907716, Final Batch Loss: 1.8208607798442245e-05\n",
      "Epoch 4055, Loss: 0.0004724617101601325, Final Batch Loss: 7.236430246848613e-05\n",
      "Epoch 4056, Loss: 0.00023616155067429645, Final Batch Loss: 8.575386345910374e-06\n",
      "Epoch 4057, Loss: 0.0011377195280601882, Final Batch Loss: 0.0001515783224022016\n",
      "Epoch 4058, Loss: 0.0001585093341418542, Final Batch Loss: 1.9990424334537238e-05\n",
      "Epoch 4059, Loss: 0.0012770368357450934, Final Batch Loss: 8.75582372827921e-06\n",
      "Epoch 4060, Loss: 6.353907826905925e-05, Final Batch Loss: 3.1015344575280324e-05\n",
      "Epoch 4061, Loss: 0.0002560147650001454, Final Batch Loss: 3.9613409171579406e-05\n",
      "Epoch 4062, Loss: 0.0004283619018679019, Final Batch Loss: 0.00010007733362726867\n",
      "Epoch 4063, Loss: 0.00037091128251631744, Final Batch Loss: 0.00015612800780218095\n",
      "Epoch 4064, Loss: 0.000717340046321624, Final Batch Loss: 1.4781571735511534e-05\n",
      "Epoch 4065, Loss: 0.0002993362613779027, Final Batch Loss: 9.886903717415407e-05\n",
      "Epoch 4066, Loss: 0.0003433852243688307, Final Batch Loss: 3.4614047763170674e-05\n",
      "Epoch 4067, Loss: 0.00028627971096284455, Final Batch Loss: 0.00021886336617171764\n",
      "Epoch 4068, Loss: 0.00032485508108948125, Final Batch Loss: 3.5712138924282044e-05\n",
      "Epoch 4069, Loss: 0.0003527116050463519, Final Batch Loss: 1.4938814274501055e-05\n",
      "Epoch 4070, Loss: 0.0005300116263242671, Final Batch Loss: 0.0001685466995695606\n",
      "Epoch 4071, Loss: 0.0004935874949296704, Final Batch Loss: 1.3813845725962892e-05\n",
      "Epoch 4072, Loss: 9.686673365649767e-05, Final Batch Loss: 3.0553946999134496e-06\n",
      "Epoch 4073, Loss: 0.00018054435031444882, Final Batch Loss: 0.00011641943274298683\n",
      "Epoch 4074, Loss: 0.0006840714377176482, Final Batch Loss: 6.27049885224551e-05\n",
      "Epoch 4075, Loss: 0.0002393833906353393, Final Batch Loss: 0.00016181021055672318\n",
      "Epoch 4076, Loss: 0.0066149330441476195, Final Batch Loss: 0.006406268570572138\n",
      "Epoch 4077, Loss: 0.00020930595383106265, Final Batch Loss: 2.534073246351909e-05\n",
      "Epoch 4078, Loss: 0.0005120933019497897, Final Batch Loss: 0.00016459292965009809\n",
      "Epoch 4079, Loss: 0.010629082054947503, Final Batch Loss: 0.0002872934564948082\n",
      "Epoch 4080, Loss: 0.00033210458741450566, Final Batch Loss: 5.273715487419395e-06\n",
      "Epoch 4081, Loss: 0.00013403595903582755, Final Batch Loss: 5.911762491450645e-05\n",
      "Epoch 4082, Loss: 0.00023784949371474795, Final Batch Loss: 0.00021175430447328836\n",
      "Epoch 4083, Loss: 0.00017729033424984664, Final Batch Loss: 1.6574645997025073e-05\n",
      "Epoch 4084, Loss: 0.00012484834678616608, Final Batch Loss: 3.1934680009726435e-05\n",
      "Epoch 4085, Loss: 0.0003107890825049253, Final Batch Loss: 3.949556230509188e-06\n",
      "Epoch 4086, Loss: 0.0007892345615800878, Final Batch Loss: 8.650108611618634e-06\n",
      "Epoch 4087, Loss: 0.0010428500945636188, Final Batch Loss: 1.4749371075595263e-05\n",
      "Epoch 4088, Loss: 0.0003606403772664635, Final Batch Loss: 1.8363828075962374e-06\n",
      "Epoch 4089, Loss: 0.00022582409292226657, Final Batch Loss: 1.7933693015947938e-05\n",
      "Epoch 4090, Loss: 0.0006817770035922877, Final Batch Loss: 6.252733328437898e-06\n",
      "Epoch 4091, Loss: 0.0002921818504546536, Final Batch Loss: 9.624162339605391e-05\n",
      "Epoch 4092, Loss: 5.5446880651288666e-05, Final Batch Loss: 1.0635907528921962e-05\n",
      "Epoch 4093, Loss: 0.0004912240719932015, Final Batch Loss: 1.0304934221494477e-05\n",
      "Epoch 4094, Loss: 0.000382182382963947, Final Batch Loss: 0.00018955007544718683\n",
      "Epoch 4095, Loss: 0.00013674860338142025, Final Batch Loss: 3.293857298558578e-05\n",
      "Epoch 4096, Loss: 0.0003913460632247734, Final Batch Loss: 1.4878241017868277e-05\n",
      "Epoch 4097, Loss: 9.978127309295814e-05, Final Batch Loss: 5.5140579206636176e-05\n",
      "Epoch 4098, Loss: 0.00012300423077249434, Final Batch Loss: 2.2523809093399905e-05\n",
      "Epoch 4099, Loss: 9.260969181923429e-05, Final Batch Loss: 1.0552273124631029e-05\n",
      "Epoch 4100, Loss: 0.0008031260567804566, Final Batch Loss: 8.344705565832555e-05\n",
      "Epoch 4101, Loss: 0.0005559707451538998, Final Batch Loss: 7.223620195873082e-05\n",
      "Epoch 4102, Loss: 0.005075463099615263, Final Batch Loss: 0.0001446479873266071\n",
      "Epoch 4103, Loss: 0.0001241931231561466, Final Batch Loss: 2.1604391804430634e-05\n",
      "Epoch 4104, Loss: 0.00011704828875735984, Final Batch Loss: 2.1531597667490132e-05\n",
      "Epoch 4105, Loss: 0.005805096876429161, Final Batch Loss: 0.00017042217950802296\n",
      "Epoch 4106, Loss: 0.0005731631608796306, Final Batch Loss: 0.0002221099566668272\n",
      "Epoch 4107, Loss: 0.00017894940538099036, Final Batch Loss: 9.638272604206577e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4108, Loss: 0.0001896085160524308, Final Batch Loss: 4.6280649257823825e-05\n",
      "Epoch 4109, Loss: 0.00018448608966536995, Final Batch Loss: 0.00011226283822907135\n",
      "Epoch 4110, Loss: 7.220227053039707e-05, Final Batch Loss: 9.571007467457093e-06\n",
      "Epoch 4111, Loss: 0.0002611841812267812, Final Batch Loss: 1.3240807675174437e-05\n",
      "Epoch 4112, Loss: 5.9152628182346234e-05, Final Batch Loss: 4.65592938780901e-06\n",
      "Epoch 4113, Loss: 0.0006641649001721817, Final Batch Loss: 5.435688217403367e-05\n",
      "Epoch 4114, Loss: 0.00029606820362459985, Final Batch Loss: 7.049493888189318e-06\n",
      "Epoch 4115, Loss: 0.0021236091897662845, Final Batch Loss: 0.0019717244431376457\n",
      "Epoch 4116, Loss: 0.00021074498909001704, Final Batch Loss: 7.619440293638036e-05\n",
      "Epoch 4117, Loss: 0.001330106280875043, Final Batch Loss: 1.926518052641768e-05\n",
      "Epoch 4118, Loss: 0.00017303969980275724, Final Batch Loss: 2.6335588700021617e-05\n",
      "Epoch 4119, Loss: 0.00015894551324890926, Final Batch Loss: 1.7883085092762485e-05\n",
      "Epoch 4120, Loss: 0.00015191709280770738, Final Batch Loss: 1.538402466394473e-05\n",
      "Epoch 4121, Loss: 0.006707814156470704, Final Batch Loss: 2.076847749776789e-06\n",
      "Epoch 4122, Loss: 0.001883946128145908, Final Batch Loss: 8.412849638261832e-06\n",
      "Epoch 4123, Loss: 0.00028737380739585205, Final Batch Loss: 8.026803698157892e-05\n",
      "Epoch 4124, Loss: 4.844744523779809e-05, Final Batch Loss: 4.165992322668899e-06\n",
      "Epoch 4125, Loss: 0.0007024401493254118, Final Batch Loss: 0.0006632721051573753\n",
      "Epoch 4126, Loss: 0.000188425586543417, Final Batch Loss: 9.377142851008102e-05\n",
      "Epoch 4127, Loss: 5.229425005381927e-05, Final Batch Loss: 3.063804342673393e-06\n",
      "Epoch 4128, Loss: 0.00020109196793782758, Final Batch Loss: 1.4543366887664888e-05\n",
      "Epoch 4129, Loss: 0.000163884321864316, Final Batch Loss: 1.9096569303655997e-05\n",
      "Epoch 4130, Loss: 0.0008164048631442711, Final Batch Loss: 3.196838952135295e-05\n",
      "Epoch 4131, Loss: 0.00011910112448276777, Final Batch Loss: 6.004135138937272e-05\n",
      "Epoch 4132, Loss: 0.008337140725416248, Final Batch Loss: 5.462568151415326e-05\n",
      "Epoch 4133, Loss: 0.0002677729626157088, Final Batch Loss: 5.396337292040698e-05\n",
      "Epoch 4134, Loss: 0.02662635437809513, Final Batch Loss: 6.9976675149519e-05\n",
      "Epoch 4135, Loss: 0.009922400536197529, Final Batch Loss: 0.00018500241276342422\n",
      "Epoch 4136, Loss: 0.003524672000821738, Final Batch Loss: 1.0498436495254282e-05\n",
      "Epoch 4137, Loss: 0.002090407850118936, Final Batch Loss: 0.0017899086233228445\n",
      "Epoch 4138, Loss: 0.00017799499983084388, Final Batch Loss: 2.4470822609146126e-05\n",
      "Epoch 4139, Loss: 0.0003653447538454202, Final Batch Loss: 9.125722135649994e-05\n",
      "Epoch 4140, Loss: 0.0006108299985498888, Final Batch Loss: 1.6750904251239263e-05\n",
      "Epoch 4141, Loss: 0.003298162220744416, Final Batch Loss: 0.0001415314618498087\n",
      "Epoch 4142, Loss: 0.01779474469003617, Final Batch Loss: 3.1626932468498126e-05\n",
      "Epoch 4143, Loss: 0.00027038600114792644, Final Batch Loss: 4.015240119770169e-05\n",
      "Epoch 4144, Loss: 0.00855233715446957, Final Batch Loss: 0.00020603527082130313\n",
      "Epoch 4145, Loss: 0.0007005240195212536, Final Batch Loss: 2.6385741875856183e-05\n",
      "Epoch 4146, Loss: 0.004053349490277469, Final Batch Loss: 0.0012715639313682914\n",
      "Epoch 4147, Loss: 0.00040109707151714247, Final Batch Loss: 2.068933281407226e-05\n",
      "Epoch 4148, Loss: 0.0006974215975787956, Final Batch Loss: 8.264505595434457e-05\n",
      "Epoch 4149, Loss: 0.00016890170263650361, Final Batch Loss: 7.765976988594048e-06\n",
      "Epoch 4150, Loss: 0.0033837543032859685, Final Batch Loss: 7.00726595823653e-05\n",
      "Epoch 4151, Loss: 0.000997146256850101, Final Batch Loss: 7.939335773698986e-05\n",
      "Epoch 4152, Loss: 0.0009299681878474075, Final Batch Loss: 9.814586519496515e-06\n",
      "Epoch 4153, Loss: 0.00039168642661024933, Final Batch Loss: 0.00032312667462974787\n",
      "Epoch 4154, Loss: 5.068697305432579e-05, Final Batch Loss: 3.572253945094417e-06\n",
      "Epoch 4155, Loss: 0.0012652609002543613, Final Batch Loss: 2.1024488887633197e-06\n",
      "Epoch 4156, Loss: 0.0698192769614252, Final Batch Loss: 0.04269220679998398\n",
      "Epoch 4157, Loss: 0.0009068879062397173, Final Batch Loss: 2.406641397101339e-05\n",
      "Epoch 4158, Loss: 0.0004726462218513916, Final Batch Loss: 5.9864130889764056e-05\n",
      "Epoch 4159, Loss: 0.0002721976397879189, Final Batch Loss: 0.00022586298291571438\n",
      "Epoch 4160, Loss: 0.003943353321119503, Final Batch Loss: 1.1875189557031263e-05\n",
      "Epoch 4161, Loss: 0.005044367355367285, Final Batch Loss: 5.336189133231528e-06\n",
      "Epoch 4162, Loss: 0.00023052969709169702, Final Batch Loss: 4.106384494662052e-06\n",
      "Epoch 4163, Loss: 0.032888506288145436, Final Batch Loss: 3.11378862534184e-05\n",
      "Epoch 4164, Loss: 0.009010213806504908, Final Batch Loss: 1.573917325004004e-05\n",
      "Epoch 4165, Loss: 0.00039530879439553246, Final Batch Loss: 0.00013656319060828537\n",
      "Epoch 4166, Loss: 0.0015966177770678769, Final Batch Loss: 0.0014093694044277072\n",
      "Epoch 4167, Loss: 0.004219612892484292, Final Batch Loss: 7.071993604768068e-05\n",
      "Epoch 4168, Loss: 0.0028054731228621677, Final Batch Loss: 0.0002956617099698633\n",
      "Epoch 4169, Loss: 0.005419752815214451, Final Batch Loss: 5.0741262384690344e-05\n",
      "Epoch 4170, Loss: 0.05042053099896293, Final Batch Loss: 0.00022468539827968925\n",
      "Epoch 4171, Loss: 0.03236624344572192, Final Batch Loss: 0.00031033388222567737\n",
      "Epoch 4172, Loss: 0.0011692902917275205, Final Batch Loss: 7.999209628906101e-05\n",
      "Epoch 4173, Loss: 0.0020248600048944354, Final Batch Loss: 0.001575270900502801\n",
      "Epoch 4174, Loss: 0.0019962506353294884, Final Batch Loss: 0.0006780917174182832\n",
      "Epoch 4175, Loss: 0.009511738098808564, Final Batch Loss: 0.00020690880774054676\n",
      "Epoch 4176, Loss: 0.001801052101654932, Final Batch Loss: 5.0667695177253336e-05\n",
      "Epoch 4177, Loss: 0.004974281575414352, Final Batch Loss: 7.647321035619825e-05\n",
      "Epoch 4178, Loss: 0.006694971903925762, Final Batch Loss: 8.435686322627589e-05\n",
      "Epoch 4179, Loss: 0.006958410852348607, Final Batch Loss: 2.1043952074251138e-06\n",
      "Epoch 4180, Loss: 0.014569713675882667, Final Batch Loss: 0.00021726079285144806\n",
      "Epoch 4181, Loss: 0.0010258622023684438, Final Batch Loss: 0.0002894228673540056\n",
      "Epoch 4182, Loss: 0.007956278781421133, Final Batch Loss: 2.049173963314388e-05\n",
      "Epoch 4183, Loss: 0.0003395956209715223, Final Batch Loss: 6.487612699856982e-05\n",
      "Epoch 4184, Loss: 0.00037068850178911816, Final Batch Loss: 0.00025116984033957124\n",
      "Epoch 4185, Loss: 0.00048297007924702484, Final Batch Loss: 3.41473423759453e-05\n",
      "Epoch 4186, Loss: 0.009603448997950181, Final Batch Loss: 0.0007259628036990762\n",
      "Epoch 4187, Loss: 0.0006246308748814045, Final Batch Loss: 1.3959319403511472e-05\n",
      "Epoch 4188, Loss: 0.0010074622605316108, Final Batch Loss: 0.0005385559052228928\n",
      "Epoch 4189, Loss: 0.03580687455905718, Final Batch Loss: 0.00036425553844310343\n",
      "Epoch 4190, Loss: 0.0005654750093526673, Final Batch Loss: 9.754934580996633e-05\n",
      "Epoch 4191, Loss: 0.02680056785538909, Final Batch Loss: 4.7915225877659395e-05\n",
      "Epoch 4192, Loss: 0.003983355272794142, Final Batch Loss: 0.00360197969712317\n",
      "Epoch 4193, Loss: 0.015604644431732595, Final Batch Loss: 0.0012692705495283008\n",
      "Epoch 4194, Loss: 0.000828711265057791, Final Batch Loss: 0.00019295480160508305\n",
      "Epoch 4195, Loss: 0.03545151285288739, Final Batch Loss: 9.469436190556735e-05\n",
      "Epoch 4196, Loss: 0.0008564918061892968, Final Batch Loss: 4.923162850900553e-05\n",
      "Epoch 4197, Loss: 0.013934550777776167, Final Batch Loss: 0.00010467696120031178\n",
      "Epoch 4198, Loss: 0.00043459568496473366, Final Batch Loss: 0.0003178527404088527\n",
      "Epoch 4199, Loss: 0.0004215497601762763, Final Batch Loss: 2.5262115741497837e-06\n",
      "Epoch 4200, Loss: 0.0015670198081352282, Final Batch Loss: 2.801019945763983e-05\n",
      "Epoch 4201, Loss: 0.027747386100600124, Final Batch Loss: 0.02741783857345581\n",
      "Epoch 4202, Loss: 0.0004957084961461078, Final Batch Loss: 0.0003978260501753539\n",
      "Epoch 4203, Loss: 0.0005029943422414362, Final Batch Loss: 0.00014627876225858927\n",
      "Epoch 4204, Loss: 0.0017885823908727616, Final Batch Loss: 3.141076012980193e-05\n",
      "Epoch 4205, Loss: 0.00040096414704748895, Final Batch Loss: 0.00010401081817690283\n",
      "Epoch 4206, Loss: 0.0040865647188184084, Final Batch Loss: 8.086726666078903e-06\n",
      "Epoch 4207, Loss: 0.025595929802875617, Final Batch Loss: 9.974015483749099e-06\n",
      "Epoch 4208, Loss: 0.0009452722842979711, Final Batch Loss: 4.333799734013155e-05\n",
      "Epoch 4209, Loss: 0.0004702268779510632, Final Batch Loss: 1.0504933015909046e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4210, Loss: 0.00038232795623116544, Final Batch Loss: 6.743897301930701e-06\n",
      "Epoch 4211, Loss: 0.00020063492684130324, Final Batch Loss: 0.00011075101065216586\n",
      "Epoch 4212, Loss: 0.001986639414099045, Final Batch Loss: 0.00022165018890518695\n",
      "Epoch 4213, Loss: 0.00074764370219782, Final Batch Loss: 0.0001307736529270187\n",
      "Epoch 4214, Loss: 0.00029303815608727746, Final Batch Loss: 9.596702147973701e-05\n",
      "Epoch 4215, Loss: 0.0016002681950340047, Final Batch Loss: 0.00010714938980527222\n",
      "Epoch 4216, Loss: 0.005401879810960963, Final Batch Loss: 0.00013785125338472426\n",
      "Epoch 4217, Loss: 0.000631721073659719, Final Batch Loss: 2.3657143174204975e-05\n",
      "Epoch 4218, Loss: 0.0027411828868935117, Final Batch Loss: 0.0023154260125011206\n",
      "Epoch 4219, Loss: 0.000375924663785554, Final Batch Loss: 1.1711158549587708e-05\n",
      "Epoch 4220, Loss: 0.0006099954443925526, Final Batch Loss: 0.0001263616286450997\n",
      "Epoch 4221, Loss: 0.005792058145743795, Final Batch Loss: 0.00019155119662173092\n",
      "Epoch 4222, Loss: 0.0003228175210097106, Final Batch Loss: 6.715621566399932e-05\n",
      "Epoch 4223, Loss: 0.0006740698372595944, Final Batch Loss: 0.00027686660178005695\n",
      "Epoch 4224, Loss: 0.0004397264383442234, Final Batch Loss: 7.878801989136264e-05\n",
      "Epoch 4225, Loss: 0.001421341105015017, Final Batch Loss: 0.0002385571860941127\n",
      "Epoch 4226, Loss: 0.0005223739353823476, Final Batch Loss: 5.270104156807065e-05\n",
      "Epoch 4227, Loss: 0.0009497719147475436, Final Batch Loss: 8.886111754691228e-05\n",
      "Epoch 4228, Loss: 0.0003574752863642061, Final Batch Loss: 1.860803058661986e-05\n",
      "Epoch 4229, Loss: 0.0025700462247186806, Final Batch Loss: 0.0018580808537080884\n",
      "Epoch 4230, Loss: 0.0015389186737593263, Final Batch Loss: 0.0011626177001744509\n",
      "Epoch 4231, Loss: 0.0007805804125382565, Final Batch Loss: 0.00039681902853772044\n",
      "Epoch 4232, Loss: 0.0004740113581647165, Final Batch Loss: 9.682255767984316e-05\n",
      "Epoch 4233, Loss: 0.00021132286201464012, Final Batch Loss: 7.811354589648545e-05\n",
      "Epoch 4234, Loss: 0.000351206415643901, Final Batch Loss: 3.802638957495219e-06\n",
      "Epoch 4235, Loss: 0.0009621898861951195, Final Batch Loss: 3.6601817555492744e-05\n",
      "Epoch 4236, Loss: 0.0012882559894933365, Final Batch Loss: 0.000492702703922987\n",
      "Epoch 4237, Loss: 0.000715584905265132, Final Batch Loss: 3.774981087190099e-05\n",
      "Epoch 4238, Loss: 0.0003134724756819196, Final Batch Loss: 2.419169686618261e-05\n",
      "Epoch 4239, Loss: 0.0008570427854692753, Final Batch Loss: 1.8345382386542042e-06\n",
      "Epoch 4240, Loss: 0.0002973440138021033, Final Batch Loss: 1.5299780216082581e-06\n",
      "Epoch 4241, Loss: 0.0014561655279976549, Final Batch Loss: 6.873061465739738e-06\n",
      "Epoch 4242, Loss: 0.003088523226324469, Final Batch Loss: 0.0025541246868669987\n",
      "Epoch 4243, Loss: 0.00029684581568290014, Final Batch Loss: 0.00011796865874202922\n",
      "Epoch 4244, Loss: 0.0003710558648890583, Final Batch Loss: 4.180402174824849e-05\n",
      "Epoch 4245, Loss: 0.0002254722382986074, Final Batch Loss: 3.3133908345917007e-06\n",
      "Epoch 4246, Loss: 0.0005934357141086366, Final Batch Loss: 3.797063618549146e-05\n",
      "Epoch 4247, Loss: 0.000630852761787537, Final Batch Loss: 6.433591806853656e-06\n",
      "Epoch 4248, Loss: 0.0007406369077216368, Final Batch Loss: 0.00021070809452794492\n",
      "Epoch 4249, Loss: 0.0004694546614700812, Final Batch Loss: 0.0003676429623737931\n",
      "Epoch 4250, Loss: 0.0004895613747066818, Final Batch Loss: 0.00013688243052456528\n",
      "Epoch 4251, Loss: 0.0035197522229282185, Final Batch Loss: 0.0034449908416718245\n",
      "Epoch 4252, Loss: 0.000937976688874187, Final Batch Loss: 8.106262612272985e-06\n",
      "Epoch 4253, Loss: 0.0009403457952430472, Final Batch Loss: 0.00040699337841942906\n",
      "Epoch 4254, Loss: 0.00015394729916806682, Final Batch Loss: 5.488951046572765e-06\n",
      "Epoch 4255, Loss: 0.0019954370238792762, Final Batch Loss: 0.0018544000340625644\n",
      "Epoch 4256, Loss: 0.00037841466428290005, Final Batch Loss: 0.0003458973369561136\n",
      "Epoch 4257, Loss: 0.0006201447977218777, Final Batch Loss: 0.000329149654135108\n",
      "Epoch 4258, Loss: 0.001119044873121311, Final Batch Loss: 1.701559995126445e-05\n",
      "Epoch 4259, Loss: 0.00011668024762911955, Final Batch Loss: 2.7063540983363055e-05\n",
      "Epoch 4260, Loss: 0.0033403961124349735, Final Batch Loss: 1.0876064152398612e-05\n",
      "Epoch 4261, Loss: 0.00037204445516181295, Final Batch Loss: 6.600580036320025e-06\n",
      "Epoch 4262, Loss: 0.0005533107942028437, Final Batch Loss: 9.517568105366081e-05\n",
      "Epoch 4263, Loss: 0.00022837701521893905, Final Batch Loss: 9.394148037245031e-06\n",
      "Epoch 4264, Loss: 9.385099565406563e-05, Final Batch Loss: 4.8220284952549264e-05\n",
      "Epoch 4265, Loss: 0.0010423421554150991, Final Batch Loss: 0.0008639109437353909\n",
      "Epoch 4266, Loss: 0.000505149262608029, Final Batch Loss: 6.204648525454104e-05\n",
      "Epoch 4267, Loss: 0.00043173257654416375, Final Batch Loss: 3.4738750400720164e-05\n",
      "Epoch 4268, Loss: 0.008034908318222733, Final Batch Loss: 3.618090340751223e-05\n",
      "Epoch 4269, Loss: 0.005817521395329095, Final Batch Loss: 3.478177313809283e-05\n",
      "Epoch 4270, Loss: 0.0004371892810013378, Final Batch Loss: 8.977843208413105e-06\n",
      "Epoch 4271, Loss: 0.0004695588941103779, Final Batch Loss: 0.0002663721679709852\n",
      "Epoch 4272, Loss: 0.00037833314058843825, Final Batch Loss: 2.809861825880944e-06\n",
      "Epoch 4273, Loss: 0.00010024372932093684, Final Batch Loss: 1.5227772564685438e-05\n",
      "Epoch 4274, Loss: 0.00013356946601561503, Final Batch Loss: 8.266961231129244e-05\n",
      "Epoch 4275, Loss: 0.012488287065934855, Final Batch Loss: 0.012391336262226105\n",
      "Epoch 4276, Loss: 0.0004264958424755605, Final Batch Loss: 8.285917829198297e-06\n",
      "Epoch 4277, Loss: 0.00025742703655851074, Final Batch Loss: 5.862155740032904e-05\n",
      "Epoch 4278, Loss: 0.00029639137892445433, Final Batch Loss: 4.907059337710962e-05\n",
      "Epoch 4279, Loss: 0.000735498701033066, Final Batch Loss: 0.00029887116397731006\n",
      "Epoch 4280, Loss: 0.00032915194060478825, Final Batch Loss: 4.532348611974157e-06\n",
      "Epoch 4281, Loss: 0.0008538041838619392, Final Batch Loss: 3.093621489824727e-05\n",
      "Epoch 4282, Loss: 0.0021960067097097635, Final Batch Loss: 0.00041231661452911794\n",
      "Epoch 4283, Loss: 0.0020693577753263526, Final Batch Loss: 0.00011350755085004494\n",
      "Epoch 4284, Loss: 0.00037894076649536146, Final Batch Loss: 9.083986515179276e-05\n",
      "Epoch 4285, Loss: 0.0006669435379080824, Final Batch Loss: 0.00013811886310577393\n",
      "Epoch 4286, Loss: 0.0011383952878532, Final Batch Loss: 3.904722325387411e-05\n",
      "Epoch 4287, Loss: 0.0008313235894092941, Final Batch Loss: 1.601435178599786e-05\n",
      "Epoch 4288, Loss: 0.0018716525055424427, Final Batch Loss: 3.7172150769038126e-05\n",
      "Epoch 4289, Loss: 0.0075101235233887564, Final Batch Loss: 9.50034154811874e-05\n",
      "Epoch 4290, Loss: 0.000368439829799172, Final Batch Loss: 0.00029784548678435385\n",
      "Epoch 4291, Loss: 0.0053329698130255565, Final Batch Loss: 0.0010625103022903204\n",
      "Epoch 4292, Loss: 0.0002997094088641461, Final Batch Loss: 7.074017958075274e-06\n",
      "Epoch 4293, Loss: 0.00170857442299166, Final Batch Loss: 7.398991328955162e-06\n",
      "Epoch 4294, Loss: 0.019640703730146924, Final Batch Loss: 8.75163750606589e-05\n",
      "Epoch 4295, Loss: 0.0004142462112213252, Final Batch Loss: 8.112893556244671e-05\n",
      "Epoch 4296, Loss: 0.0004526402462943224, Final Batch Loss: 0.0002790800353977829\n",
      "Epoch 4297, Loss: 0.0072153910350607475, Final Batch Loss: 2.0164463421679102e-05\n",
      "Epoch 4298, Loss: 0.00035913806641474366, Final Batch Loss: 9.517895523458719e-05\n",
      "Epoch 4299, Loss: 0.0011650645265035564, Final Batch Loss: 0.0005695208092220128\n",
      "Epoch 4300, Loss: 0.002389287245023297, Final Batch Loss: 3.878696952597238e-05\n",
      "Epoch 4301, Loss: 0.007333494097792936, Final Batch Loss: 1.19333049042325e-06\n",
      "Epoch 4302, Loss: 0.0012024183088215068, Final Batch Loss: 0.00011404744873289019\n",
      "Epoch 4303, Loss: 0.0007998122327990131, Final Batch Loss: 1.935571890498977e-05\n",
      "Epoch 4304, Loss: 0.0011994708984275348, Final Batch Loss: 0.0007590953609906137\n",
      "Epoch 4305, Loss: 0.0015736205750727095, Final Batch Loss: 9.530326497042552e-05\n",
      "Epoch 4306, Loss: 0.00038024085779397865, Final Batch Loss: 0.0003099445311818272\n",
      "Epoch 4307, Loss: 0.000699075753800571, Final Batch Loss: 1.3590153685072437e-05\n",
      "Epoch 4308, Loss: 0.0005580899451160803, Final Batch Loss: 9.697992936708033e-05\n",
      "Epoch 4309, Loss: 0.0031787539410288446, Final Batch Loss: 0.0004005066293757409\n",
      "Epoch 4310, Loss: 0.002958981192932697, Final Batch Loss: 0.00023709468950983137\n",
      "Epoch 4311, Loss: 0.008329968946782174, Final Batch Loss: 2.998351374117192e-05\n",
      "Epoch 4312, Loss: 0.0004793262487510219, Final Batch Loss: 0.00020511333423200995\n",
      "Epoch 4313, Loss: 0.0010517828927731898, Final Batch Loss: 0.0004980872035957873\n",
      "Epoch 4314, Loss: 0.004835375544644194, Final Batch Loss: 6.854894309071824e-05\n",
      "Epoch 4315, Loss: 0.0006374851263899473, Final Batch Loss: 0.00021797000954393297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4316, Loss: 0.00022910242705620476, Final Batch Loss: 2.040118124568835e-05\n",
      "Epoch 4317, Loss: 0.0021761853613497806, Final Batch Loss: 0.0019674545619636774\n",
      "Epoch 4318, Loss: 0.000854251986311283, Final Batch Loss: 0.00028110769926570356\n",
      "Epoch 4319, Loss: 0.0004973778013663832, Final Batch Loss: 1.817421980376821e-05\n",
      "Epoch 4320, Loss: 0.013686000595043879, Final Batch Loss: 7.271529466379434e-05\n",
      "Epoch 4321, Loss: 0.0008611979992565466, Final Batch Loss: 2.1256693798932247e-05\n",
      "Epoch 4322, Loss: 0.0029717007564613596, Final Batch Loss: 0.00020343970390968025\n",
      "Epoch 4323, Loss: 0.0030631042609456927, Final Batch Loss: 4.0899372834246606e-05\n",
      "Epoch 4324, Loss: 0.0006853790182503872, Final Batch Loss: 3.220604412490502e-05\n",
      "Epoch 4325, Loss: 0.0017527528034406714, Final Batch Loss: 1.3112374290358275e-05\n",
      "Epoch 4326, Loss: 0.0075896972321061185, Final Batch Loss: 4.864376751356758e-05\n",
      "Epoch 4327, Loss: 0.02594721513469267, Final Batch Loss: 0.000987645355053246\n",
      "Epoch 4328, Loss: 0.0003717200024766498, Final Batch Loss: 1.3335093171917833e-06\n",
      "Epoch 4329, Loss: 0.008693713029060746, Final Batch Loss: 4.977423304808326e-05\n",
      "Epoch 4330, Loss: 0.0005641429906972917, Final Batch Loss: 0.00015903839084785432\n",
      "Epoch 4331, Loss: 0.028160080830275547, Final Batch Loss: 0.00012105653149774298\n",
      "Epoch 4332, Loss: 0.03410081536276266, Final Batch Loss: 0.0009663414675742388\n",
      "Epoch 4333, Loss: 0.0001759297119861003, Final Batch Loss: 3.1178322387859225e-05\n",
      "Epoch 4334, Loss: 0.00315188652893994, Final Batch Loss: 0.000137908777105622\n",
      "Epoch 4335, Loss: 0.0007087875164870638, Final Batch Loss: 4.8621473979437724e-05\n",
      "Epoch 4336, Loss: 0.00018973573423863854, Final Batch Loss: 9.07315916265361e-05\n",
      "Epoch 4337, Loss: 0.001224294659550651, Final Batch Loss: 2.0263092665118165e-05\n",
      "Epoch 4338, Loss: 0.000679850671076565, Final Batch Loss: 2.508414581825491e-05\n",
      "Epoch 4339, Loss: 0.000736638406124257, Final Batch Loss: 9.327993211627472e-06\n",
      "Epoch 4340, Loss: 0.001041675384840346, Final Batch Loss: 1.3982053133076988e-05\n",
      "Epoch 4341, Loss: 0.0013055434319539927, Final Batch Loss: 0.00010186400322709233\n",
      "Epoch 4342, Loss: 0.0020829344048252096, Final Batch Loss: 0.0019152389140799642\n",
      "Epoch 4343, Loss: 0.020413430691405665, Final Batch Loss: 5.386301563703455e-05\n",
      "Epoch 4344, Loss: 0.000786215558036929, Final Batch Loss: 4.6127588575473055e-05\n",
      "Epoch 4345, Loss: 0.002795473479636712, Final Batch Loss: 0.0010212467750534415\n",
      "Epoch 4346, Loss: 0.0010586823664198164, Final Batch Loss: 6.056455094949342e-05\n",
      "Epoch 4347, Loss: 0.000299773171718698, Final Batch Loss: 0.0001516714401077479\n",
      "Epoch 4348, Loss: 0.0006638544382440159, Final Batch Loss: 4.2358373320894316e-05\n",
      "Epoch 4349, Loss: 0.0009479266009293497, Final Batch Loss: 0.0002770644787233323\n",
      "Epoch 4350, Loss: 0.0009184612117678626, Final Batch Loss: 7.288750566658564e-06\n",
      "Epoch 4351, Loss: 0.00029566932971647475, Final Batch Loss: 0.00013100597425363958\n",
      "Epoch 4352, Loss: 0.0002942485698440578, Final Batch Loss: 2.520933594496455e-05\n",
      "Epoch 4353, Loss: 0.0008540308681403985, Final Batch Loss: 1.6435564248240553e-05\n",
      "Epoch 4354, Loss: 0.0007476671635231469, Final Batch Loss: 2.7911919460166246e-06\n",
      "Epoch 4355, Loss: 0.0007721101374045247, Final Batch Loss: 0.00017284757632296532\n",
      "Epoch 4356, Loss: 0.0015613813657182618, Final Batch Loss: 1.401038662152132e-05\n",
      "Epoch 4357, Loss: 0.002572418045019731, Final Batch Loss: 1.4639532309956849e-05\n",
      "Epoch 4358, Loss: 0.00045071699969412293, Final Batch Loss: 6.491786916740239e-05\n",
      "Epoch 4359, Loss: 0.0011353174086252693, Final Batch Loss: 5.7748718973016366e-05\n",
      "Epoch 4360, Loss: 0.00042152930836891755, Final Batch Loss: 0.00012439826969057322\n",
      "Epoch 4361, Loss: 0.0004847776872338727, Final Batch Loss: 0.0002006498834816739\n",
      "Epoch 4362, Loss: 0.00025103685538852005, Final Batch Loss: 5.2714556659338996e-05\n",
      "Epoch 4363, Loss: 0.0004902987311652396, Final Batch Loss: 7.423933857353404e-05\n",
      "Epoch 4364, Loss: 0.0016456673038192093, Final Batch Loss: 0.0009720229427330196\n",
      "Epoch 4365, Loss: 0.0006851670325431769, Final Batch Loss: 5.088726084068185e-06\n",
      "Epoch 4366, Loss: 0.0002531252384869731, Final Batch Loss: 5.425150447990745e-05\n",
      "Epoch 4367, Loss: 0.0006597276696993504, Final Batch Loss: 3.9263493817998096e-05\n",
      "Epoch 4368, Loss: 0.0002741440257523209, Final Batch Loss: 0.00011243753397138789\n",
      "Epoch 4369, Loss: 0.00036838044616160914, Final Batch Loss: 9.529796807328239e-05\n",
      "Epoch 4370, Loss: 0.0002625894994707778, Final Batch Loss: 9.61705663939938e-05\n",
      "Epoch 4371, Loss: 0.0029869724512536777, Final Batch Loss: 2.14379087992711e-05\n",
      "Epoch 4372, Loss: 0.0017158988903247518, Final Batch Loss: 1.1857504432555288e-05\n",
      "Epoch 4373, Loss: 0.0008158188429661095, Final Batch Loss: 0.0003156011807732284\n",
      "Epoch 4374, Loss: 0.0013854114440619014, Final Batch Loss: 0.0002993601083289832\n",
      "Epoch 4375, Loss: 0.0006347426424326841, Final Batch Loss: 0.0005541335558518767\n",
      "Epoch 4376, Loss: 0.00043583726801443845, Final Batch Loss: 0.0001226665044669062\n",
      "Epoch 4377, Loss: 0.0011288825196515972, Final Batch Loss: 3.6651988466473995e-06\n",
      "Epoch 4378, Loss: 0.00013311230031831656, Final Batch Loss: 4.630773219105322e-06\n",
      "Epoch 4379, Loss: 0.00036148904109722935, Final Batch Loss: 4.889168849331327e-05\n",
      "Epoch 4380, Loss: 0.0002588573934190208, Final Batch Loss: 0.00012398454418871552\n",
      "Epoch 4381, Loss: 0.0002936785003839759, Final Batch Loss: 6.127476081019267e-05\n",
      "Epoch 4382, Loss: 0.0007759238942526281, Final Batch Loss: 0.00033692969009280205\n",
      "Epoch 4383, Loss: 0.00010954740764645976, Final Batch Loss: 5.505253739102045e-06\n",
      "Epoch 4384, Loss: 0.0002421637091174489, Final Batch Loss: 1.626097764528822e-05\n",
      "Epoch 4385, Loss: 0.0002926128181570675, Final Batch Loss: 9.760003013070673e-05\n",
      "Epoch 4386, Loss: 0.0007479186533601023, Final Batch Loss: 4.613044438883662e-05\n",
      "Epoch 4387, Loss: 0.0002987488487633527, Final Batch Loss: 0.00017634994583204389\n",
      "Epoch 4388, Loss: 0.0002095444383485301, Final Batch Loss: 2.709384170884732e-05\n",
      "Epoch 4389, Loss: 0.0007136429449019488, Final Batch Loss: 3.77563810616266e-05\n",
      "Epoch 4390, Loss: 0.0027483056792334537, Final Batch Loss: 0.00034461464383639395\n",
      "Epoch 4391, Loss: 0.00019657604389067274, Final Batch Loss: 1.7805470633902587e-05\n",
      "Epoch 4392, Loss: 0.005547447308344999, Final Batch Loss: 0.005467831622809172\n",
      "Epoch 4393, Loss: 0.0003321832627989352, Final Batch Loss: 4.9787573516368866e-05\n",
      "Epoch 4394, Loss: 0.00019171762414771365, Final Batch Loss: 4.4344116759020835e-05\n",
      "Epoch 4395, Loss: 0.00022584588805329986, Final Batch Loss: 1.7489855963503942e-05\n",
      "Epoch 4396, Loss: 0.0002809883462759899, Final Batch Loss: 9.833634248934686e-05\n",
      "Epoch 4397, Loss: 0.000578771222535579, Final Batch Loss: 1.1887816981470678e-05\n",
      "Epoch 4398, Loss: 0.0003603514105634531, Final Batch Loss: 3.368658144609071e-05\n",
      "Epoch 4399, Loss: 0.006024510114457371, Final Batch Loss: 6.352768195938552e-06\n",
      "Epoch 4400, Loss: 0.0017470872971898643, Final Batch Loss: 0.0014119140105322003\n",
      "Epoch 4401, Loss: 0.0003660330239654286, Final Batch Loss: 0.00019346941553521901\n",
      "Epoch 4402, Loss: 0.00030152658246151987, Final Batch Loss: 2.3129630790208466e-05\n",
      "Epoch 4403, Loss: 0.0012997904941585148, Final Batch Loss: 0.0006798026151955128\n",
      "Epoch 4404, Loss: 0.001844818689278327, Final Batch Loss: 0.0016990763833746314\n",
      "Epoch 4405, Loss: 0.00026036432791443076, Final Batch Loss: 2.6136189262615517e-05\n",
      "Epoch 4406, Loss: 0.0005008176558476407, Final Batch Loss: 3.9207367080962285e-05\n",
      "Epoch 4407, Loss: 0.00039871052831585985, Final Batch Loss: 0.00011155643733218312\n",
      "Epoch 4408, Loss: 0.00016914260004341486, Final Batch Loss: 8.857864304445684e-05\n",
      "Epoch 4409, Loss: 0.0002075268833436894, Final Batch Loss: 7.427500463563774e-07\n",
      "Epoch 4410, Loss: 0.0003227455688374903, Final Batch Loss: 2.7807489004771924e-06\n",
      "Epoch 4411, Loss: 0.0003443753566898522, Final Batch Loss: 6.768202729290351e-05\n",
      "Epoch 4412, Loss: 0.0005993479026074056, Final Batch Loss: 0.000235467086895369\n",
      "Epoch 4413, Loss: 0.0003028331739187706, Final Batch Loss: 2.3056558347889222e-05\n",
      "Epoch 4414, Loss: 0.00024222586034738924, Final Batch Loss: 1.5026380424387753e-05\n",
      "Epoch 4415, Loss: 0.0001289104766328819, Final Batch Loss: 1.4036551874596626e-05\n",
      "Epoch 4416, Loss: 0.0005093728177598678, Final Batch Loss: 5.124519157106988e-05\n",
      "Epoch 4417, Loss: 0.0002391684629401425, Final Batch Loss: 7.908800762379542e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4418, Loss: 0.00011372949154520029, Final Batch Loss: 9.909821301334887e-07\n",
      "Epoch 4419, Loss: 5.580688355166785e-05, Final Batch Loss: 2.7717167085938854e-06\n",
      "Epoch 4420, Loss: 0.0010878736640620446, Final Batch Loss: 5.613212010757707e-07\n",
      "Epoch 4421, Loss: 0.000327487139202276, Final Batch Loss: 1.9109897039015777e-05\n",
      "Epoch 4422, Loss: 0.0015710966767983336, Final Batch Loss: 5.581723144132411e-06\n",
      "Epoch 4423, Loss: 0.0009983142190321814, Final Batch Loss: 2.071735798381269e-05\n",
      "Epoch 4424, Loss: 0.00018105990739059052, Final Batch Loss: 2.9960843676235527e-05\n",
      "Epoch 4425, Loss: 5.6563934776932e-05, Final Batch Loss: 9.582819075149018e-06\n",
      "Epoch 4426, Loss: 0.00015106972568901256, Final Batch Loss: 1.994111153180711e-05\n",
      "Epoch 4427, Loss: 0.0001939144312927965, Final Batch Loss: 3.582925273803994e-05\n",
      "Epoch 4428, Loss: 0.0005314172492489888, Final Batch Loss: 8.147587777784793e-07\n",
      "Epoch 4429, Loss: 0.0005490780654326954, Final Batch Loss: 0.0004352090763859451\n",
      "Epoch 4430, Loss: 0.00012488040556490887, Final Batch Loss: 1.0768357242341153e-05\n",
      "Epoch 4431, Loss: 0.00032946004284895025, Final Batch Loss: 0.00018637508037500083\n",
      "Epoch 4432, Loss: 0.00022412038924812805, Final Batch Loss: 2.9134103897376917e-05\n",
      "Epoch 4433, Loss: 7.697402816120302e-05, Final Batch Loss: 2.0457684513530694e-05\n",
      "Epoch 4434, Loss: 0.0008458797233288351, Final Batch Loss: 0.0007971097948029637\n",
      "Epoch 4435, Loss: 9.672655141912401e-05, Final Batch Loss: 2.0104807845200412e-05\n",
      "Epoch 4436, Loss: 0.0021068322375867865, Final Batch Loss: 0.002037772908806801\n",
      "Epoch 4437, Loss: 0.00011380440599850772, Final Batch Loss: 8.573658192290168e-07\n",
      "Epoch 4438, Loss: 0.0003474453606031602, Final Batch Loss: 0.000232244172366336\n",
      "Epoch 4439, Loss: 0.0021384279971243814, Final Batch Loss: 0.0018170996336266398\n",
      "Epoch 4440, Loss: 8.3782319961756e-05, Final Batch Loss: 3.858656418742612e-05\n",
      "Epoch 4441, Loss: 0.000172543407984449, Final Batch Loss: 8.423628605669364e-05\n",
      "Epoch 4442, Loss: 5.455631117001758e-05, Final Batch Loss: 1.757926384016173e-06\n",
      "Epoch 4443, Loss: 0.0001358503236588149, Final Batch Loss: 1.083614188246429e-05\n",
      "Epoch 4444, Loss: 0.0001394151231579599, Final Batch Loss: 1.3770054465567227e-05\n",
      "Epoch 4445, Loss: 0.0002852641378012777, Final Batch Loss: 0.00012563234486151487\n",
      "Epoch 4446, Loss: 0.0001408009416081768, Final Batch Loss: 5.082920324639417e-06\n",
      "Epoch 4447, Loss: 0.000987822248134762, Final Batch Loss: 4.2532050429144874e-05\n",
      "Epoch 4448, Loss: 0.000784214637860714, Final Batch Loss: 3.756253863684833e-05\n",
      "Epoch 4449, Loss: 0.0004174980226707703, Final Batch Loss: 0.00023867878189776093\n",
      "Epoch 4450, Loss: 0.0018498496610845905, Final Batch Loss: 0.0017250539967790246\n",
      "Epoch 4451, Loss: 0.00023709804804639134, Final Batch Loss: 3.588502977436292e-06\n",
      "Epoch 4452, Loss: 9.200630069017279e-05, Final Batch Loss: 1.0152191862289328e-05\n",
      "Epoch 4453, Loss: 0.00014171990414979518, Final Batch Loss: 3.600471973186359e-05\n",
      "Epoch 4454, Loss: 0.011687350224747206, Final Batch Loss: 0.011622599326074123\n",
      "Epoch 4455, Loss: 0.0006200050193001516, Final Batch Loss: 9.850291098700836e-05\n",
      "Epoch 4456, Loss: 0.00013102441516821273, Final Batch Loss: 5.7328805269207805e-05\n",
      "Epoch 4457, Loss: 0.0002055334953183774, Final Batch Loss: 0.00011055920913349837\n",
      "Epoch 4458, Loss: 0.00023395532161885058, Final Batch Loss: 3.546104926499538e-05\n",
      "Epoch 4459, Loss: 0.0009315750148743973, Final Batch Loss: 1.0138072866539005e-05\n",
      "Epoch 4460, Loss: 6.293330943663022e-05, Final Batch Loss: 3.00040228466969e-05\n",
      "Epoch 4461, Loss: 9.969451636493432e-05, Final Batch Loss: 3.715307320817374e-05\n",
      "Epoch 4462, Loss: 0.0004397643665470241, Final Batch Loss: 9.506224159849808e-05\n",
      "Epoch 4463, Loss: 0.003480081162706483, Final Batch Loss: 0.002957303076982498\n",
      "Epoch 4464, Loss: 0.0076351348325260915, Final Batch Loss: 0.00017661666788626462\n",
      "Epoch 4465, Loss: 0.0001366452297588694, Final Batch Loss: 1.1335843737469986e-05\n",
      "Epoch 4466, Loss: 0.005011299410028869, Final Batch Loss: 0.0041986810974776745\n",
      "Epoch 4467, Loss: 6.5146988390552e-05, Final Batch Loss: 2.438830597384367e-05\n",
      "Epoch 4468, Loss: 0.0005090587919767131, Final Batch Loss: 0.00011199356958968565\n",
      "Epoch 4469, Loss: 9.246673215557166e-05, Final Batch Loss: 4.859932118961297e-07\n",
      "Epoch 4470, Loss: 0.00022112933584139682, Final Batch Loss: 3.29592076013796e-05\n",
      "Epoch 4471, Loss: 0.0002475171029345802, Final Batch Loss: 3.623966449595173e-06\n",
      "Epoch 4472, Loss: 0.0004028592184113222, Final Batch Loss: 2.1456430658872705e-06\n",
      "Epoch 4473, Loss: 0.00042893470481430995, Final Batch Loss: 8.868965232977644e-05\n",
      "Epoch 4474, Loss: 0.00029661344456144434, Final Batch Loss: 0.00012573431013152003\n",
      "Epoch 4475, Loss: 0.0013102153234285652, Final Batch Loss: 4.527406417764723e-06\n",
      "Epoch 4476, Loss: 0.0002485441061708116, Final Batch Loss: 2.4960270366136683e-06\n",
      "Epoch 4477, Loss: 0.00031797096380614676, Final Batch Loss: 5.169365249457769e-05\n",
      "Epoch 4478, Loss: 0.0007064212568366202, Final Batch Loss: 2.71685730695026e-05\n",
      "Epoch 4479, Loss: 0.00025739277953107376, Final Batch Loss: 0.00021990842651575804\n",
      "Epoch 4480, Loss: 0.0005668048179359175, Final Batch Loss: 6.8727444158867e-05\n",
      "Epoch 4481, Loss: 0.0001577936700414284, Final Batch Loss: 9.379850780533161e-06\n",
      "Epoch 4482, Loss: 0.00024704378984097275, Final Batch Loss: 7.259986432472942e-06\n",
      "Epoch 4483, Loss: 0.09542941787731252, Final Batch Loss: 0.04854188114404678\n",
      "Epoch 4484, Loss: 0.0009037756312864076, Final Batch Loss: 7.898971489339601e-06\n",
      "Epoch 4485, Loss: 0.0003168155235471204, Final Batch Loss: 4.4046490074833855e-05\n",
      "Epoch 4486, Loss: 0.0044190183170940145, Final Batch Loss: 1.0999356163665652e-05\n",
      "Epoch 4487, Loss: 0.0005995327373966575, Final Batch Loss: 5.760377098340541e-05\n",
      "Epoch 4488, Loss: 0.0007657609121451969, Final Batch Loss: 8.073750905168708e-06\n",
      "Epoch 4489, Loss: 0.000352564058630378, Final Batch Loss: 2.261550798721146e-05\n",
      "Epoch 4490, Loss: 0.0006500299487015582, Final Batch Loss: 0.0006123252678662539\n",
      "Epoch 4491, Loss: 0.0012678956445597578, Final Batch Loss: 7.117957284208387e-05\n",
      "Epoch 4492, Loss: 0.0001088958774744242, Final Batch Loss: 4.044080469611799e-06\n",
      "Epoch 4493, Loss: 0.0002785620563372504, Final Batch Loss: 2.2881420591147617e-05\n",
      "Epoch 4494, Loss: 0.0011310749941912945, Final Batch Loss: 9.561461047269404e-05\n",
      "Epoch 4495, Loss: 0.0042714063411040115, Final Batch Loss: 1.293648801947711e-05\n",
      "Epoch 4496, Loss: 0.034782422754688014, Final Batch Loss: 3.0036553653189912e-06\n",
      "Epoch 4497, Loss: 0.0009014785218823818, Final Batch Loss: 3.6315877878223546e-06\n",
      "Epoch 4498, Loss: 0.0012869015918113291, Final Batch Loss: 0.0002929455367848277\n",
      "Epoch 4499, Loss: 0.002568645868450403, Final Batch Loss: 0.0003721497778315097\n",
      "Epoch 4500, Loss: 0.02466357796220109, Final Batch Loss: 0.00019032091950066388\n",
      "Epoch 4501, Loss: 0.00041873638474498875, Final Batch Loss: 3.275022390880622e-05\n",
      "Epoch 4502, Loss: 0.00036726017606270034, Final Batch Loss: 3.6506489777821116e-06\n",
      "Epoch 4503, Loss: 0.0008478488853143062, Final Batch Loss: 1.9797815184574574e-05\n",
      "Epoch 4504, Loss: 0.0002105738785758149, Final Batch Loss: 5.727979441871867e-06\n",
      "Epoch 4505, Loss: 0.00041148182390315924, Final Batch Loss: 2.2542901206179522e-05\n",
      "Epoch 4506, Loss: 0.0001941930331668118, Final Batch Loss: 0.00010162317630602047\n",
      "Epoch 4507, Loss: 0.00048387990636911127, Final Batch Loss: 0.00036498147528618574\n",
      "Epoch 4508, Loss: 0.0002832558034242538, Final Batch Loss: 2.640762886585435e-06\n",
      "Epoch 4509, Loss: 0.0038819437177153304, Final Batch Loss: 2.4056822439888492e-05\n",
      "Epoch 4510, Loss: 0.0003081662198383128, Final Batch Loss: 1.1512036508065648e-05\n",
      "Epoch 4511, Loss: 0.000507328051753575, Final Batch Loss: 5.802479790872894e-06\n",
      "Epoch 4512, Loss: 0.0005485697274707491, Final Batch Loss: 1.4319304682430811e-05\n",
      "Epoch 4513, Loss: 0.00010275541558257828, Final Batch Loss: 9.189190677716397e-06\n",
      "Epoch 4514, Loss: 0.0006606749236652831, Final Batch Loss: 6.482383469119668e-05\n",
      "Epoch 4515, Loss: 0.00027916888939216733, Final Batch Loss: 8.741848432691768e-05\n",
      "Epoch 4516, Loss: 0.0013311488346516853, Final Batch Loss: 5.730384145863354e-05\n",
      "Epoch 4517, Loss: 0.00036179120434098877, Final Batch Loss: 4.547453499981202e-05\n",
      "Epoch 4518, Loss: 0.0439092075289409, Final Batch Loss: 4.573161731968867e-06\n",
      "Epoch 4519, Loss: 0.0065715667442418635, Final Batch Loss: 5.5868003983050585e-05\n",
      "Epoch 4520, Loss: 0.0013435774671961553, Final Batch Loss: 0.00042641200707294047\n",
      "Epoch 4521, Loss: 0.0006930762356205378, Final Batch Loss: 8.843033720040694e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4522, Loss: 0.0584985049572424, Final Batch Loss: 0.0006475560949184\n",
      "Epoch 4523, Loss: 0.0006627005013797316, Final Batch Loss: 6.9216848714859225e-06\n",
      "Epoch 4524, Loss: 0.00016320795839419588, Final Batch Loss: 1.8491176888346672e-05\n",
      "Epoch 4525, Loss: 0.0006526074653265823, Final Batch Loss: 3.6948990782548208e-06\n",
      "Epoch 4526, Loss: 0.0002582959205028601, Final Batch Loss: 7.734647806501016e-05\n",
      "Epoch 4527, Loss: 0.0003540393986440904, Final Batch Loss: 2.0642068193410523e-05\n",
      "Epoch 4528, Loss: 0.000245291314968199, Final Batch Loss: 7.340439333347604e-05\n",
      "Epoch 4529, Loss: 0.00024087454949039966, Final Batch Loss: 2.6477300707483664e-05\n",
      "Epoch 4530, Loss: 0.015767810953548178, Final Batch Loss: 3.265833220211789e-05\n",
      "Epoch 4531, Loss: 0.0004861859415541403, Final Batch Loss: 0.00031716295052319765\n",
      "Epoch 4532, Loss: 0.0004921659783576615, Final Batch Loss: 0.00023396802134811878\n",
      "Epoch 4533, Loss: 0.001098770480894018, Final Batch Loss: 0.0008031011675484478\n",
      "Epoch 4534, Loss: 0.016736608593419078, Final Batch Loss: 0.00443017715588212\n",
      "Epoch 4535, Loss: 0.02945259660100419, Final Batch Loss: 1.5915916264930274e-06\n",
      "Epoch 4536, Loss: 0.0006558722307090648, Final Batch Loss: 0.0003085143107455224\n",
      "Epoch 4537, Loss: 0.00862237362889573, Final Batch Loss: 0.0030344263650476933\n",
      "Epoch 4538, Loss: 0.0005974610103294253, Final Batch Loss: 0.00033124437322840095\n",
      "Epoch 4539, Loss: 0.00041236442120862193, Final Batch Loss: 0.00016995772602967918\n",
      "Epoch 4540, Loss: 0.010180325392866507, Final Batch Loss: 0.0005236436263658106\n",
      "Epoch 4541, Loss: 0.004329283401602879, Final Batch Loss: 6.964084604987875e-05\n",
      "Epoch 4542, Loss: 0.004409410190419294, Final Batch Loss: 0.0035033829044550657\n",
      "Epoch 4543, Loss: 0.002546137613535393, Final Batch Loss: 0.0012794237118214369\n",
      "Epoch 4544, Loss: 0.0018054596657748334, Final Batch Loss: 6.922541797393933e-05\n",
      "Epoch 4545, Loss: 0.0003561874800652731, Final Batch Loss: 6.579379987670109e-05\n",
      "Epoch 4546, Loss: 0.00038529675657628104, Final Batch Loss: 9.944944031303748e-05\n",
      "Epoch 4547, Loss: 0.00039160598680609837, Final Batch Loss: 0.0001826706138672307\n",
      "Epoch 4548, Loss: 0.0004623225722752977, Final Batch Loss: 4.982080281479284e-05\n",
      "Epoch 4549, Loss: 0.001082203583791852, Final Batch Loss: 0.000720339419785887\n",
      "Epoch 4550, Loss: 0.0036997850711486535, Final Batch Loss: 0.000198948138859123\n",
      "Epoch 4551, Loss: 0.0004951272292146314, Final Batch Loss: 1.1016834378096974e-06\n",
      "Epoch 4552, Loss: 0.0004199599461571779, Final Batch Loss: 5.214112388784997e-05\n",
      "Epoch 4553, Loss: 0.0013698568582185544, Final Batch Loss: 0.0008667632355354726\n",
      "Epoch 4554, Loss: 0.0005684617353836074, Final Batch Loss: 0.00015987336519174278\n",
      "Epoch 4555, Loss: 0.0006500152776425239, Final Batch Loss: 4.4689939386444166e-05\n",
      "Epoch 4556, Loss: 0.004507018255935691, Final Batch Loss: 9.412749022885691e-06\n",
      "Epoch 4557, Loss: 0.00017020577797666192, Final Batch Loss: 7.439051114488393e-05\n",
      "Epoch 4558, Loss: 0.000312344724079594, Final Batch Loss: 0.0002220802562078461\n",
      "Epoch 4559, Loss: 0.004812811485862767, Final Batch Loss: 3.216344703105278e-05\n",
      "Epoch 4560, Loss: 0.0007257570068759378, Final Batch Loss: 0.00036396048380993307\n",
      "Epoch 4561, Loss: 0.0012929737567901611, Final Batch Loss: 0.0010457541793584824\n",
      "Epoch 4562, Loss: 0.0031377170180348912, Final Batch Loss: 2.1479072529473342e-05\n",
      "Epoch 4563, Loss: 0.00037143213194212876, Final Batch Loss: 0.00013816759746987373\n",
      "Epoch 4564, Loss: 0.0005753836885560304, Final Batch Loss: 1.5030986105557531e-05\n",
      "Epoch 4565, Loss: 0.0007521391780755948, Final Batch Loss: 1.6057128959801048e-05\n",
      "Epoch 4566, Loss: 0.00016847125925778528, Final Batch Loss: 7.558230663562426e-06\n",
      "Epoch 4567, Loss: 0.0005509865368367173, Final Batch Loss: 0.00019731855718418956\n",
      "Epoch 4568, Loss: 0.0004211755544929474, Final Batch Loss: 0.00010872224083868787\n",
      "Epoch 4569, Loss: 0.0003310345318823238, Final Batch Loss: 1.1440778507676441e-05\n",
      "Epoch 4570, Loss: 0.00034473376035748515, Final Batch Loss: 8.951336349127814e-05\n",
      "Epoch 4571, Loss: 0.0007264306459546788, Final Batch Loss: 1.9288385374238715e-05\n",
      "Epoch 4572, Loss: 0.0006129651137598557, Final Batch Loss: 1.4240677046473138e-05\n",
      "Epoch 4573, Loss: 0.00044365068242768757, Final Batch Loss: 0.00010879498586291447\n",
      "Epoch 4574, Loss: 0.0004654375370591879, Final Batch Loss: 0.0003667172568384558\n",
      "Epoch 4575, Loss: 0.00019360036958460114, Final Batch Loss: 5.35033314008615e-06\n",
      "Epoch 4576, Loss: 0.0001791430599951127, Final Batch Loss: 4.496594920055941e-05\n",
      "Epoch 4577, Loss: 0.0003336679110361729, Final Batch Loss: 5.378438436309807e-05\n",
      "Epoch 4578, Loss: 0.0013221113749750657, Final Batch Loss: 6.902773020556197e-05\n",
      "Epoch 4579, Loss: 0.0002432330984447617, Final Batch Loss: 1.558019721414894e-05\n",
      "Epoch 4580, Loss: 0.002958859702630434, Final Batch Loss: 8.077126403804868e-05\n",
      "Epoch 4581, Loss: 0.0012451378715923056, Final Batch Loss: 1.5795600120327435e-05\n",
      "Epoch 4582, Loss: 0.0005799690134153934, Final Batch Loss: 1.5046191947476473e-05\n",
      "Epoch 4583, Loss: 0.0003097952539974358, Final Batch Loss: 2.0922014300595038e-05\n",
      "Epoch 4584, Loss: 0.00016205015799641842, Final Batch Loss: 0.00011923833517357707\n",
      "Epoch 4585, Loss: 0.0001879228750567563, Final Batch Loss: 3.567498652046197e-06\n",
      "Epoch 4586, Loss: 0.0003828740282187937, Final Batch Loss: 7.957300113048404e-05\n",
      "Epoch 4587, Loss: 0.01814211114015052, Final Batch Loss: 1.4521398952638265e-05\n",
      "Epoch 4588, Loss: 5.993457079966902e-05, Final Batch Loss: 5.075820354250027e-06\n",
      "Epoch 4589, Loss: 0.0004733691021101549, Final Batch Loss: 0.00018119541346095502\n",
      "Epoch 4590, Loss: 0.0005601851617029752, Final Batch Loss: 1.1758422260754742e-05\n",
      "Epoch 4591, Loss: 0.0010877288077608682, Final Batch Loss: 0.0002104095765389502\n",
      "Epoch 4592, Loss: 0.0005369873688323423, Final Batch Loss: 0.0001349069207208231\n",
      "Epoch 4593, Loss: 0.0005125484876771225, Final Batch Loss: 3.3263124350924045e-05\n",
      "Epoch 4594, Loss: 0.0007840490325179417, Final Batch Loss: 0.000592119584325701\n",
      "Epoch 4595, Loss: 0.00148914614237583, Final Batch Loss: 0.0013583332765847445\n",
      "Epoch 4596, Loss: 0.00042209931734760175, Final Batch Loss: 3.569085674826056e-05\n",
      "Epoch 4597, Loss: 0.0014557004396920092, Final Batch Loss: 8.711637201486155e-05\n",
      "Epoch 4598, Loss: 0.0009438619981665397, Final Batch Loss: 0.000421037373598665\n",
      "Epoch 4599, Loss: 0.00010851938804989913, Final Batch Loss: 6.493695400422439e-05\n",
      "Epoch 4600, Loss: 0.00022836929929326288, Final Batch Loss: 4.7367218940053135e-05\n",
      "Epoch 4601, Loss: 0.00042153433423663955, Final Batch Loss: 2.617652717162855e-05\n",
      "Epoch 4602, Loss: 0.00010414517419121694, Final Batch Loss: 3.324679346405901e-05\n",
      "Epoch 4603, Loss: 0.0007734548471489688, Final Batch Loss: 0.00038083625258877873\n",
      "Epoch 4604, Loss: 0.0005728310898120981, Final Batch Loss: 5.828514986205846e-05\n",
      "Epoch 4605, Loss: 0.0002977208041556878, Final Batch Loss: 2.912272793764714e-05\n",
      "Epoch 4606, Loss: 0.00035731252773985034, Final Batch Loss: 3.141598790534772e-05\n",
      "Epoch 4607, Loss: 0.00043468992043926846, Final Batch Loss: 0.00019497684843372554\n",
      "Epoch 4608, Loss: 0.004177869721388561, Final Batch Loss: 0.004010254982858896\n",
      "Epoch 4609, Loss: 0.00024627006860100664, Final Batch Loss: 3.8688620406901464e-05\n",
      "Epoch 4610, Loss: 0.00024267154367407784, Final Batch Loss: 5.2429379138629884e-05\n",
      "Epoch 4611, Loss: 0.000678680487908423, Final Batch Loss: 0.00036722570075653493\n",
      "Epoch 4612, Loss: 0.00018709072099909463, Final Batch Loss: 6.883830678816594e-07\n",
      "Epoch 4613, Loss: 0.00010621596902637975, Final Batch Loss: 8.953067663242109e-06\n",
      "Epoch 4614, Loss: 0.013786223345960025, Final Batch Loss: 0.00034902256447821856\n",
      "Epoch 4615, Loss: 0.00023801592033123598, Final Batch Loss: 5.378767673391849e-05\n",
      "Epoch 4616, Loss: 0.014277144575771672, Final Batch Loss: 0.014240278862416744\n",
      "Epoch 4617, Loss: 0.009191996621666476, Final Batch Loss: 0.00018676243780646473\n",
      "Epoch 4618, Loss: 0.0006790897177779698, Final Batch Loss: 6.93059428158449e-06\n",
      "Epoch 4619, Loss: 0.00027849753257669363, Final Batch Loss: 2.4098439098452218e-05\n",
      "Epoch 4620, Loss: 0.0002759050630629645, Final Batch Loss: 6.34522657492198e-05\n",
      "Epoch 4621, Loss: 0.00013079287691653008, Final Batch Loss: 7.075289613567293e-05\n",
      "Epoch 4622, Loss: 0.012894182009404176, Final Batch Loss: 0.0004627322778105736\n",
      "Epoch 4623, Loss: 0.0008635251651867293, Final Batch Loss: 1.851743581937626e-05\n",
      "Epoch 4624, Loss: 0.0005541286900552223, Final Batch Loss: 0.0001320170849794522\n",
      "Epoch 4625, Loss: 0.0008052925140873413, Final Batch Loss: 8.998270459414925e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4626, Loss: 0.0023882510322437156, Final Batch Loss: 0.002131805056706071\n",
      "Epoch 4627, Loss: 0.00023862840862420853, Final Batch Loss: 1.5534014892182313e-05\n",
      "Epoch 4628, Loss: 0.00031380080690723844, Final Batch Loss: 8.83192042238079e-05\n",
      "Epoch 4629, Loss: 0.0003419477852730779, Final Batch Loss: 1.1688460290315561e-05\n",
      "Epoch 4630, Loss: 0.000501397131529302, Final Batch Loss: 0.00029058445943519473\n",
      "Epoch 4631, Loss: 0.00020647871315304656, Final Batch Loss: 4.479976632865146e-05\n",
      "Epoch 4632, Loss: 0.0016406880895374343, Final Batch Loss: 0.00014968878531362861\n",
      "Epoch 4633, Loss: 0.00028282420316827483, Final Batch Loss: 3.098437809967436e-05\n",
      "Epoch 4634, Loss: 0.00030529327796102734, Final Batch Loss: 3.453767203609459e-05\n",
      "Epoch 4635, Loss: 0.001074491399776889, Final Batch Loss: 8.79697545315139e-05\n",
      "Epoch 4636, Loss: 0.0004417462064338906, Final Batch Loss: 6.526288871100405e-06\n",
      "Epoch 4637, Loss: 0.00010746923862825497, Final Batch Loss: 1.3953920642961748e-05\n",
      "Epoch 4638, Loss: 0.004573744947265368, Final Batch Loss: 0.004393213894218206\n",
      "Epoch 4639, Loss: 0.0004363342777651269, Final Batch Loss: 4.9633377784630284e-05\n",
      "Epoch 4640, Loss: 0.006361769053910393, Final Batch Loss: 8.42862282297574e-05\n",
      "Epoch 4641, Loss: 0.00048707800669944845, Final Batch Loss: 3.8641323044430465e-05\n",
      "Epoch 4642, Loss: 0.0005092340725241229, Final Batch Loss: 5.485591827891767e-05\n",
      "Epoch 4643, Loss: 0.0006485952762886882, Final Batch Loss: 0.00012774296919815242\n",
      "Epoch 4644, Loss: 0.0001620279417693382, Final Batch Loss: 1.8796026779455133e-05\n",
      "Epoch 4645, Loss: 0.0002590518770375638, Final Batch Loss: 7.266545708262129e-06\n",
      "Epoch 4646, Loss: 0.0002864009093173081, Final Batch Loss: 0.0001769410737324506\n",
      "Epoch 4647, Loss: 0.00029532593543990515, Final Batch Loss: 0.0001537521166028455\n",
      "Epoch 4648, Loss: 0.00037782033723487984, Final Batch Loss: 0.0002830796001944691\n",
      "Epoch 4649, Loss: 0.0007396288142444973, Final Batch Loss: 5.575462182605406e-06\n",
      "Epoch 4650, Loss: 0.014198774944361503, Final Batch Loss: 1.644363146624528e-05\n",
      "Epoch 4651, Loss: 0.0001496401278018311, Final Batch Loss: 2.9324975912459195e-05\n",
      "Epoch 4652, Loss: 0.0002897549456974957, Final Batch Loss: 8.587332558818161e-05\n",
      "Epoch 4653, Loss: 0.0003506565153656993, Final Batch Loss: 7.199601532192901e-05\n",
      "Epoch 4654, Loss: 0.0045532411295425845, Final Batch Loss: 7.845241270842962e-06\n",
      "Epoch 4655, Loss: 0.017164355847853585, Final Batch Loss: 0.016948137432336807\n",
      "Epoch 4656, Loss: 0.023831387203244958, Final Batch Loss: 6.283546099439263e-05\n",
      "Epoch 4657, Loss: 0.001644500225665979, Final Batch Loss: 0.00046485604252666235\n",
      "Epoch 4658, Loss: 0.004890344222076237, Final Batch Loss: 0.0045792581513524055\n",
      "Epoch 4659, Loss: 0.0008093451087916037, Final Batch Loss: 0.0005827433778904378\n",
      "Epoch 4660, Loss: 0.00040602940134704113, Final Batch Loss: 9.469303040532395e-05\n",
      "Epoch 4661, Loss: 0.0012769864570145728, Final Batch Loss: 0.00013579416554421186\n",
      "Epoch 4662, Loss: 0.0005292213561460812, Final Batch Loss: 0.0001597404043423012\n",
      "Epoch 4663, Loss: 0.004114805204153527, Final Batch Loss: 0.00012302504910621792\n",
      "Epoch 4664, Loss: 0.003240155443563708, Final Batch Loss: 2.1779860617243685e-05\n",
      "Epoch 4665, Loss: 0.0005623878769256407, Final Batch Loss: 2.355284414079506e-05\n",
      "Epoch 4666, Loss: 6.876817860757001e-05, Final Batch Loss: 1.982729918381665e-05\n",
      "Epoch 4667, Loss: 0.0002022561473040696, Final Batch Loss: 2.826671106959111e-06\n",
      "Epoch 4668, Loss: 0.00038085379674157593, Final Batch Loss: 8.312932186527178e-05\n",
      "Epoch 4669, Loss: 0.0009619997294976201, Final Batch Loss: 3.6454543987929355e-06\n",
      "Epoch 4670, Loss: 0.0007279592646227684, Final Batch Loss: 0.000568787450902164\n",
      "Epoch 4671, Loss: 0.0019091238718829118, Final Batch Loss: 4.7362223995151e-05\n",
      "Epoch 4672, Loss: 0.00026719313609646633, Final Batch Loss: 5.462686749524437e-05\n",
      "Epoch 4673, Loss: 0.0001590427364135394, Final Batch Loss: 7.572686445200816e-05\n",
      "Epoch 4674, Loss: 0.0008309196018672083, Final Batch Loss: 2.0251774913049303e-05\n",
      "Epoch 4675, Loss: 4.299712372812792e-05, Final Batch Loss: 6.757487881259294e-06\n",
      "Epoch 4676, Loss: 0.0004566771631289157, Final Batch Loss: 0.0003203028463758528\n",
      "Epoch 4677, Loss: 0.0010434138202981558, Final Batch Loss: 9.355304064229131e-05\n",
      "Epoch 4678, Loss: 0.0006490739979199134, Final Batch Loss: 0.00021089690562803298\n",
      "Epoch 4679, Loss: 0.0003518227949825814, Final Batch Loss: 1.9869175957865082e-05\n",
      "Epoch 4680, Loss: 0.0003862697185468278, Final Batch Loss: 5.846565727551933e-06\n",
      "Epoch 4681, Loss: 0.0002769025741145015, Final Batch Loss: 2.1800347894895822e-05\n",
      "Epoch 4682, Loss: 0.0005973888748940226, Final Batch Loss: 0.0005668644444085658\n",
      "Epoch 4683, Loss: 0.0003680723175421008, Final Batch Loss: 1.9165343474014662e-05\n",
      "Epoch 4684, Loss: 0.001715767857604078, Final Batch Loss: 0.00019151781452819705\n",
      "Epoch 4685, Loss: 0.00024045472900979803, Final Batch Loss: 2.779173337330576e-05\n",
      "Epoch 4686, Loss: 0.00034150752458117495, Final Batch Loss: 3.5205669064453105e-06\n",
      "Epoch 4687, Loss: 0.0003957757293164832, Final Batch Loss: 1.0673048564058263e-05\n",
      "Epoch 4688, Loss: 0.00015843991241126787, Final Batch Loss: 1.9228320525144227e-05\n",
      "Epoch 4689, Loss: 0.0002486988105374621, Final Batch Loss: 9.640660209697671e-06\n",
      "Epoch 4690, Loss: 0.0011739354436031135, Final Batch Loss: 1.89204620255623e-05\n",
      "Epoch 4691, Loss: 0.001753658250436274, Final Batch Loss: 4.488266768021276e-06\n",
      "Epoch 4692, Loss: 0.00020799971753149293, Final Batch Loss: 2.3968517780303955e-05\n",
      "Epoch 4693, Loss: 0.0001664921940118802, Final Batch Loss: 2.240541334685986e-06\n",
      "Epoch 4694, Loss: 0.00010716966426116414, Final Batch Loss: 2.532286998757627e-05\n",
      "Epoch 4695, Loss: 9.659785678195476e-05, Final Batch Loss: 3.575740265659988e-05\n",
      "Epoch 4696, Loss: 0.000480475904623745, Final Batch Loss: 0.00013251214113552123\n",
      "Epoch 4697, Loss: 0.00018858983366953908, Final Batch Loss: 4.4611933844862506e-05\n",
      "Epoch 4698, Loss: 0.0002896304508794856, Final Batch Loss: 2.3824609343137126e-06\n",
      "Epoch 4699, Loss: 0.00019210479376852163, Final Batch Loss: 2.015956397372065e-06\n",
      "Epoch 4700, Loss: 7.830454615032068e-05, Final Batch Loss: 3.743578417925164e-05\n",
      "Epoch 4701, Loss: 0.0003792181069002254, Final Batch Loss: 8.675631761434488e-06\n",
      "Epoch 4702, Loss: 0.004053044054899146, Final Batch Loss: 0.00390056474134326\n",
      "Epoch 4703, Loss: 0.00013845885419527804, Final Batch Loss: 4.4539243049257493e-07\n",
      "Epoch 4704, Loss: 0.0008713434617675375, Final Batch Loss: 3.405696406844072e-05\n",
      "Epoch 4705, Loss: 0.0007841056667530211, Final Batch Loss: 8.220782183343545e-05\n",
      "Epoch 4706, Loss: 0.000566264783628867, Final Batch Loss: 2.5838022338575684e-05\n",
      "Epoch 4707, Loss: 0.0003297087023383938, Final Batch Loss: 0.0002018085797317326\n",
      "Epoch 4708, Loss: 0.001115627666877117, Final Batch Loss: 3.172994911437854e-05\n",
      "Epoch 4709, Loss: 0.0007058032861095853, Final Batch Loss: 0.00010120204387931153\n",
      "Epoch 4710, Loss: 0.00023282668053070665, Final Batch Loss: 2.5360336621815804e-06\n",
      "Epoch 4711, Loss: 0.013019044828979531, Final Batch Loss: 0.012507375329732895\n",
      "Epoch 4712, Loss: 0.00029784743855998386, Final Batch Loss: 3.5956687497673556e-05\n",
      "Epoch 4713, Loss: 0.0003487628091534134, Final Batch Loss: 0.00017654162365943193\n",
      "Epoch 4714, Loss: 0.005264599119982449, Final Batch Loss: 4.0055292629403993e-05\n",
      "Epoch 4715, Loss: 0.05314750036313853, Final Batch Loss: 7.038971034489805e-06\n",
      "Epoch 4716, Loss: 0.0012100554858989199, Final Batch Loss: 0.0009697304922156036\n",
      "Epoch 4717, Loss: 0.00011363622763838066, Final Batch Loss: 9.843894304140122e-07\n",
      "Epoch 4718, Loss: 0.00046074462807155214, Final Batch Loss: 6.014243626850657e-05\n",
      "Epoch 4719, Loss: 0.00048659506092008087, Final Batch Loss: 5.334730667527765e-05\n",
      "Epoch 4720, Loss: 0.0001429055591870565, Final Batch Loss: 7.017445750534534e-05\n",
      "Epoch 4721, Loss: 0.00034691371092776535, Final Batch Loss: 7.806312169122975e-06\n",
      "Epoch 4722, Loss: 0.0001712041994323954, Final Batch Loss: 1.6713758668629453e-05\n",
      "Epoch 4723, Loss: 0.001024335467718629, Final Batch Loss: 7.91745424066903e-06\n",
      "Epoch 4724, Loss: 0.0028003169936710037, Final Batch Loss: 7.747044583084062e-05\n",
      "Epoch 4725, Loss: 0.0001251131139952122, Final Batch Loss: 5.023439371143468e-05\n",
      "Epoch 4726, Loss: 0.0009962386893676012, Final Batch Loss: 1.9297476683277637e-05\n",
      "Epoch 4727, Loss: 0.00017637628025113372, Final Batch Loss: 3.273649053880945e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4728, Loss: 0.000583954634521433, Final Batch Loss: 5.562156275118468e-06\n",
      "Epoch 4729, Loss: 0.00025817266396188643, Final Batch Loss: 1.527643144072499e-05\n",
      "Epoch 4730, Loss: 0.00016395142756664427, Final Batch Loss: 2.9677825295948423e-05\n",
      "Epoch 4731, Loss: 0.00014449443369812798, Final Batch Loss: 5.3238945838529617e-05\n",
      "Epoch 4732, Loss: 0.006983529015769818, Final Batch Loss: 0.000851341406814754\n",
      "Epoch 4733, Loss: 0.017069160523078608, Final Batch Loss: 0.00019282274297438562\n",
      "Epoch 4734, Loss: 9.227656846633181e-05, Final Batch Loss: 1.6008238162612543e-05\n",
      "Epoch 4735, Loss: 0.0063629366413806565, Final Batch Loss: 0.00044631335185840726\n",
      "Epoch 4736, Loss: 0.00023403852492265287, Final Batch Loss: 3.232924791518599e-05\n",
      "Epoch 4737, Loss: 0.00037594119930872694, Final Batch Loss: 0.00011936010560020804\n",
      "Epoch 4738, Loss: 0.0007814973459971952, Final Batch Loss: 0.0003137062885798514\n",
      "Epoch 4739, Loss: 0.003682667073007906, Final Batch Loss: 6.739477248629555e-05\n",
      "Epoch 4740, Loss: 0.0004020651155087762, Final Batch Loss: 0.00016719280392862856\n",
      "Epoch 4741, Loss: 0.0007328520218834456, Final Batch Loss: 0.0003034992259927094\n",
      "Epoch 4742, Loss: 0.0007230940518638818, Final Batch Loss: 0.0001245261519216001\n",
      "Epoch 4743, Loss: 0.00024382803348999005, Final Batch Loss: 2.107477848767303e-05\n",
      "Epoch 4744, Loss: 0.000392007785194437, Final Batch Loss: 1.66187764989445e-05\n",
      "Epoch 4745, Loss: 0.0008835579324113496, Final Batch Loss: 0.0005988824414089322\n",
      "Epoch 4746, Loss: 0.002486853532900568, Final Batch Loss: 0.002070364309474826\n",
      "Epoch 4747, Loss: 0.0007652538333786651, Final Batch Loss: 7.312717934837565e-05\n",
      "Epoch 4748, Loss: 0.0008205449285014765, Final Batch Loss: 0.00012757847434841096\n",
      "Epoch 4749, Loss: 0.0005068623904662672, Final Batch Loss: 0.00029238828574307263\n",
      "Epoch 4750, Loss: 0.00033262678698520176, Final Batch Loss: 6.995139119680971e-05\n",
      "Epoch 4751, Loss: 0.000810966837889282, Final Batch Loss: 2.7149068046128377e-05\n",
      "Epoch 4752, Loss: 0.0008508628052368294, Final Batch Loss: 0.0006111548282206059\n",
      "Epoch 4753, Loss: 0.00020229266192473006, Final Batch Loss: 8.647579670650885e-05\n",
      "Epoch 4754, Loss: 0.00024875150756997755, Final Batch Loss: 0.00020377874898258597\n",
      "Epoch 4755, Loss: 0.00040071037074085325, Final Batch Loss: 0.0001603665587026626\n",
      "Epoch 4756, Loss: 0.0011848724629999197, Final Batch Loss: 0.001004333607852459\n",
      "Epoch 4757, Loss: 0.00037071280712552834, Final Batch Loss: 2.858547304640524e-05\n",
      "Epoch 4758, Loss: 6.134727527751238e-05, Final Batch Loss: 1.2482611055020243e-05\n",
      "Epoch 4759, Loss: 0.00030203845108189853, Final Batch Loss: 1.295922356803203e-05\n",
      "Epoch 4760, Loss: 0.0004447736428119242, Final Batch Loss: 0.00013352670066524297\n",
      "Epoch 4761, Loss: 0.00025461536688453634, Final Batch Loss: 7.220071438496234e-06\n",
      "Epoch 4762, Loss: 0.000582177492901792, Final Batch Loss: 1.3944635384177673e-06\n",
      "Epoch 4763, Loss: 0.00024613069217593875, Final Batch Loss: 6.186073005665094e-05\n",
      "Epoch 4764, Loss: 0.0005218156006776553, Final Batch Loss: 1.911862000270048e-06\n",
      "Epoch 4765, Loss: 0.00027247503840044374, Final Batch Loss: 3.681932503241114e-05\n",
      "Epoch 4766, Loss: 0.0009041853190865368, Final Batch Loss: 7.35356006771326e-05\n",
      "Epoch 4767, Loss: 0.0010272908752995136, Final Batch Loss: 3.868239218718372e-05\n",
      "Epoch 4768, Loss: 0.00013868915061721054, Final Batch Loss: 7.696454122196883e-05\n",
      "Epoch 4769, Loss: 0.0013999027942190878, Final Batch Loss: 0.0006338489474728703\n",
      "Epoch 4770, Loss: 0.004372880361188436, Final Batch Loss: 3.606389873311855e-05\n",
      "Epoch 4771, Loss: 0.00011758807841033558, Final Batch Loss: 8.96706260391511e-05\n",
      "Epoch 4772, Loss: 0.0006767158572529297, Final Batch Loss: 2.7285220767225837e-06\n",
      "Epoch 4773, Loss: 0.0008903702673705993, Final Batch Loss: 0.00032300123712047935\n",
      "Epoch 4774, Loss: 0.0003077263545492315, Final Batch Loss: 0.00024398542882408947\n",
      "Epoch 4775, Loss: 4.783793747265008e-05, Final Batch Loss: 2.3022030291031115e-05\n",
      "Epoch 4776, Loss: 0.0006557850392709952, Final Batch Loss: 7.283674221980618e-06\n",
      "Epoch 4777, Loss: 0.00026450298014424334, Final Batch Loss: 3.1372623197967187e-05\n",
      "Epoch 4778, Loss: 0.0001410541854056646, Final Batch Loss: 1.3348481843422633e-05\n",
      "Epoch 4779, Loss: 0.0007026517305348534, Final Batch Loss: 0.0005781279178336263\n",
      "Epoch 4780, Loss: 0.0001931202114064945, Final Batch Loss: 4.988050204701722e-05\n",
      "Epoch 4781, Loss: 0.00026658362412490533, Final Batch Loss: 0.00019476799934636801\n",
      "Epoch 4782, Loss: 0.00035746799903790816, Final Batch Loss: 0.00010328346979804337\n",
      "Epoch 4783, Loss: 0.00017295391671723337, Final Batch Loss: 4.3083247874164954e-05\n",
      "Epoch 4784, Loss: 0.000740859669576821, Final Batch Loss: 6.855119863757864e-05\n",
      "Epoch 4785, Loss: 0.001213966092109331, Final Batch Loss: 1.6655503713991493e-06\n",
      "Epoch 4786, Loss: 0.0003426473631407134, Final Batch Loss: 2.585125002951827e-05\n",
      "Epoch 4787, Loss: 9.416434932063567e-05, Final Batch Loss: 4.331870968599105e-06\n",
      "Epoch 4788, Loss: 0.0001343456237918872, Final Batch Loss: 9.059815056389198e-05\n",
      "Epoch 4789, Loss: 0.0003247294798711664, Final Batch Loss: 2.11590995604638e-05\n",
      "Epoch 4790, Loss: 0.0003742117842193693, Final Batch Loss: 1.645201882638503e-05\n",
      "Epoch 4791, Loss: 6.685257812932832e-05, Final Batch Loss: 1.2707660062005743e-05\n",
      "Epoch 4792, Loss: 7.22803079042933e-05, Final Batch Loss: 1.9536837498890236e-05\n",
      "Epoch 4793, Loss: 0.0007293927874343353, Final Batch Loss: 0.00023293591220863163\n",
      "Epoch 4794, Loss: 0.0001424203765054699, Final Batch Loss: 7.57363231969066e-05\n",
      "Epoch 4795, Loss: 0.0001320492251579708, Final Batch Loss: 5.320149739418412e-06\n",
      "Epoch 4796, Loss: 0.00028325715226174, Final Batch Loss: 6.163414241200371e-07\n",
      "Epoch 4797, Loss: 0.0009208886585838627, Final Batch Loss: 2.3130112822400406e-05\n",
      "Epoch 4798, Loss: 5.5053959727047186e-05, Final Batch Loss: 5.488808483278262e-07\n",
      "Epoch 4799, Loss: 6.858281312815961e-05, Final Batch Loss: 1.2239043826411944e-05\n",
      "Epoch 4800, Loss: 0.00015367189314474672, Final Batch Loss: 9.100632451009005e-05\n",
      "Epoch 4801, Loss: 0.000354194670421748, Final Batch Loss: 1.3606584616354667e-05\n",
      "Epoch 4802, Loss: 0.0006239503613869601, Final Batch Loss: 2.8958464099559933e-05\n",
      "Epoch 4803, Loss: 0.00015164949491008883, Final Batch Loss: 1.31649685499724e-05\n",
      "Epoch 4804, Loss: 0.0004668719361689, Final Batch Loss: 0.0003912074025720358\n",
      "Epoch 4805, Loss: 4.3634625853883335e-05, Final Batch Loss: 7.863890459702816e-06\n",
      "Epoch 4806, Loss: 0.00018422885750624118, Final Batch Loss: 8.626605449535418e-06\n",
      "Epoch 4807, Loss: 0.0011618070930126123, Final Batch Loss: 0.00015665881801396608\n",
      "Epoch 4808, Loss: 0.0002793980202113744, Final Batch Loss: 8.18843036540784e-05\n",
      "Epoch 4809, Loss: 4.794885478531796e-05, Final Batch Loss: 1.3160603884898592e-05\n",
      "Epoch 4810, Loss: 0.0012139920359004464, Final Batch Loss: 1.96013525055605e-06\n",
      "Epoch 4811, Loss: 9.202596498880666e-05, Final Batch Loss: 1.4900729183864314e-06\n",
      "Epoch 4812, Loss: 0.00010338811352994526, Final Batch Loss: 5.5695403716526926e-05\n",
      "Epoch 4813, Loss: 0.029354709768995235, Final Batch Loss: 2.4761166059761308e-05\n",
      "Epoch 4814, Loss: 0.0008366967449546792, Final Batch Loss: 8.288859680760652e-05\n",
      "Epoch 4815, Loss: 5.243027385404275e-05, Final Batch Loss: 8.936918675317429e-06\n",
      "Epoch 4816, Loss: 0.0003090581190008379, Final Batch Loss: 0.00019986000552307814\n",
      "Epoch 4817, Loss: 0.0001701097121440398, Final Batch Loss: 1.6043404684751295e-05\n",
      "Epoch 4818, Loss: 0.00019136012997478247, Final Batch Loss: 6.712706181133399e-06\n",
      "Epoch 4819, Loss: 0.0002299086327184341, Final Batch Loss: 9.997738379752263e-05\n",
      "Epoch 4820, Loss: 0.00011879348983256932, Final Batch Loss: 9.761533874552697e-06\n",
      "Epoch 4821, Loss: 0.0013282301188155543, Final Batch Loss: 0.0012603547656908631\n",
      "Epoch 4822, Loss: 0.0004584119751598337, Final Batch Loss: 0.00038983605918474495\n",
      "Epoch 4823, Loss: 0.0001340680719295051, Final Batch Loss: 8.273797902802471e-06\n",
      "Epoch 4824, Loss: 0.0007229206792089826, Final Batch Loss: 1.9818223790935008e-06\n",
      "Epoch 4825, Loss: 5.7617828133516014e-05, Final Batch Loss: 9.794136531127151e-06\n",
      "Epoch 4826, Loss: 0.00011033662298132185, Final Batch Loss: 6.896897843944316e-07\n",
      "Epoch 4827, Loss: 0.00013138772555976175, Final Batch Loss: 4.237754183122888e-05\n",
      "Epoch 4828, Loss: 0.00010553982883720892, Final Batch Loss: 1.2334713574091438e-05\n",
      "Epoch 4829, Loss: 0.0002678220760117256, Final Batch Loss: 4.1043917008209974e-05\n",
      "Epoch 4830, Loss: 0.00010045724775409326, Final Batch Loss: 1.0572745850367937e-05\n",
      "Epoch 4831, Loss: 0.0005927867532591335, Final Batch Loss: 3.906566053046845e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4832, Loss: 0.0004346465302660363, Final Batch Loss: 1.3786941053695045e-05\n",
      "Epoch 4833, Loss: 0.00021836219877968688, Final Batch Loss: 2.5684386855573393e-05\n",
      "Epoch 4834, Loss: 0.02729050696507329, Final Batch Loss: 0.003223998239263892\n",
      "Epoch 4835, Loss: 0.00014248808020056458, Final Batch Loss: 5.254093775874935e-05\n",
      "Epoch 4836, Loss: 0.0002374534746536483, Final Batch Loss: 1.6879195754881948e-05\n",
      "Epoch 4837, Loss: 0.0029572602757070854, Final Batch Loss: 5.468303061206825e-05\n",
      "Epoch 4838, Loss: 0.00015274842741064276, Final Batch Loss: 5.587026521425287e-07\n",
      "Epoch 4839, Loss: 0.02458875841202257, Final Batch Loss: 0.02435358054935932\n",
      "Epoch 4840, Loss: 7.339461046740325e-05, Final Batch Loss: 1.2146720109740272e-05\n",
      "Epoch 4841, Loss: 0.0012582857380039059, Final Batch Loss: 0.00032797944732010365\n",
      "Epoch 4842, Loss: 0.000508589356286393, Final Batch Loss: 0.00045382822281681\n",
      "Epoch 4843, Loss: 0.0005113809311296791, Final Batch Loss: 6.765410944353789e-05\n",
      "Epoch 4844, Loss: 0.00017111404667957686, Final Batch Loss: 7.996671047294512e-05\n",
      "Epoch 4845, Loss: 0.00030387197102754726, Final Batch Loss: 6.532088718813611e-06\n",
      "Epoch 4846, Loss: 0.001821725067202351, Final Batch Loss: 0.0013823967892676592\n",
      "Epoch 4847, Loss: 0.0008832357889332343, Final Batch Loss: 4.2672523704823107e-05\n",
      "Epoch 4848, Loss: 0.00024460595295749954, Final Batch Loss: 0.00012525104102678597\n",
      "Epoch 4849, Loss: 0.0003090744017981706, Final Batch Loss: 1.1887981372638023e-06\n",
      "Epoch 4850, Loss: 0.000563981564482674, Final Batch Loss: 7.063852535793558e-06\n",
      "Epoch 4851, Loss: 0.00023295575738302432, Final Batch Loss: 3.3184769563376904e-06\n",
      "Epoch 4852, Loss: 0.0020295459144108463, Final Batch Loss: 0.00010988782742060721\n",
      "Epoch 4853, Loss: 0.0009723920193209779, Final Batch Loss: 2.1866166207473725e-05\n",
      "Epoch 4854, Loss: 0.0008709250651008915, Final Batch Loss: 0.0005380818038247526\n",
      "Epoch 4855, Loss: 0.0004098236076970352, Final Batch Loss: 0.0001570305903442204\n",
      "Epoch 4856, Loss: 0.009302809304244875, Final Batch Loss: 0.00024163597845472395\n",
      "Epoch 4857, Loss: 0.00018608533446240472, Final Batch Loss: 5.547744876821525e-07\n",
      "Epoch 4858, Loss: 0.00011399060940675554, Final Batch Loss: 8.686378350830637e-06\n",
      "Epoch 4859, Loss: 0.00028419595821560506, Final Batch Loss: 0.00010315658437320963\n",
      "Epoch 4860, Loss: 0.0002422521342850814, Final Batch Loss: 2.440336629661033e-06\n",
      "Epoch 4861, Loss: 0.00012824249097320717, Final Batch Loss: 2.0408171621966176e-05\n",
      "Epoch 4862, Loss: 7.761985671095317e-05, Final Batch Loss: 2.1628229660564102e-05\n",
      "Epoch 4863, Loss: 6.0330859469104325e-05, Final Batch Loss: 1.0294174899172504e-05\n",
      "Epoch 4864, Loss: 0.00011238328693252697, Final Batch Loss: 1.786766688383068e-06\n",
      "Epoch 4865, Loss: 0.0004543110298982356, Final Batch Loss: 1.8026543330051936e-05\n",
      "Epoch 4866, Loss: 0.012642860221603769, Final Batch Loss: 2.857726030924823e-05\n",
      "Epoch 4867, Loss: 0.0004932118226861348, Final Batch Loss: 0.00040891184471547604\n",
      "Epoch 4868, Loss: 0.00030169157616910525, Final Batch Loss: 0.00011325897503411397\n",
      "Epoch 4869, Loss: 0.002777345787762897, Final Batch Loss: 0.0026757875457406044\n",
      "Epoch 4870, Loss: 0.0003461938440523227, Final Batch Loss: 6.302332621999085e-05\n",
      "Epoch 4871, Loss: 0.00039745782413547204, Final Batch Loss: 0.00027425403823144734\n",
      "Epoch 4872, Loss: 0.0017415004203940043, Final Batch Loss: 0.00038818593020550907\n",
      "Epoch 4873, Loss: 0.0009503584151389077, Final Batch Loss: 0.0005243693594820797\n",
      "Epoch 4874, Loss: 0.0005698085897165583, Final Batch Loss: 1.1160327630932443e-05\n",
      "Epoch 4875, Loss: 0.001303548834130197, Final Batch Loss: 7.3851520028256346e-06\n",
      "Epoch 4876, Loss: 0.04584305541243339, Final Batch Loss: 3.087331151618855e-06\n",
      "Epoch 4877, Loss: 0.00023746362785459496, Final Batch Loss: 4.7258741687983274e-05\n",
      "Epoch 4878, Loss: 0.004671234923989687, Final Batch Loss: 8.096870260487776e-06\n",
      "Epoch 4879, Loss: 0.013041085718214163, Final Batch Loss: 0.012910865247249603\n",
      "Epoch 4880, Loss: 0.0005243684317974839, Final Batch Loss: 0.0003732862533070147\n",
      "Epoch 4881, Loss: 0.010908389192081813, Final Batch Loss: 1.7685722923488356e-05\n",
      "Epoch 4882, Loss: 0.014453164156293496, Final Batch Loss: 0.012505879625678062\n",
      "Epoch 4883, Loss: 0.00016396075784541608, Final Batch Loss: 7.637117960257456e-06\n",
      "Epoch 4884, Loss: 0.00019655531013995642, Final Batch Loss: 5.783188680652529e-05\n",
      "Epoch 4885, Loss: 0.0006793630673200823, Final Batch Loss: 1.7517821106594056e-05\n",
      "Epoch 4886, Loss: 0.0010694285520003177, Final Batch Loss: 8.091657218756154e-05\n",
      "Epoch 4887, Loss: 0.0010118254940607585, Final Batch Loss: 2.3423197490046732e-05\n",
      "Epoch 4888, Loss: 0.0027801212031590694, Final Batch Loss: 0.00012440356658771634\n",
      "Epoch 4889, Loss: 0.00015613907498845947, Final Batch Loss: 5.2723266890097875e-06\n",
      "Epoch 4890, Loss: 0.0007804823499100166, Final Batch Loss: 0.0003643638046924025\n",
      "Epoch 4891, Loss: 0.0004929876122332644, Final Batch Loss: 0.0002135851827915758\n",
      "Epoch 4892, Loss: 0.0009827145765086698, Final Batch Loss: 2.9409025614768325e-07\n",
      "Epoch 4893, Loss: 0.00012700095066975337, Final Batch Loss: 8.235034329118207e-05\n",
      "Epoch 4894, Loss: 0.0002300139443605076, Final Batch Loss: 0.000198591107618995\n",
      "Epoch 4895, Loss: 0.00017559985394655087, Final Batch Loss: 9.763975867826957e-06\n",
      "Epoch 4896, Loss: 0.022026353922086628, Final Batch Loss: 3.281446367964236e-07\n",
      "Epoch 4897, Loss: 0.02576693962328136, Final Batch Loss: 0.025447538122534752\n",
      "Epoch 4898, Loss: 0.0019987142293302895, Final Batch Loss: 2.905211431425414e-06\n",
      "Epoch 4899, Loss: 0.0005315880298439879, Final Batch Loss: 0.00020812977163586766\n",
      "Epoch 4900, Loss: 0.0002263143528580258, Final Batch Loss: 5.6331988162128255e-05\n",
      "Epoch 4901, Loss: 0.014275990550231654, Final Batch Loss: 8.962964784586802e-05\n",
      "Epoch 4902, Loss: 0.0009482225541432854, Final Batch Loss: 4.716525654657744e-05\n",
      "Epoch 4903, Loss: 0.012470244373616879, Final Batch Loss: 0.012323045171797276\n",
      "Epoch 4904, Loss: 0.006840115089289611, Final Batch Loss: 0.0001902194635476917\n",
      "Epoch 4905, Loss: 0.003214289661627845, Final Batch Loss: 0.0028447185177356005\n",
      "Epoch 4906, Loss: 0.004565268667647615, Final Batch Loss: 0.00414216797798872\n",
      "Epoch 4907, Loss: 0.00020144357927165402, Final Batch Loss: 5.197923201194499e-06\n",
      "Epoch 4908, Loss: 0.0010320982892153552, Final Batch Loss: 0.00012629959383048117\n",
      "Epoch 4909, Loss: 0.0012991421156129945, Final Batch Loss: 2.765043063845951e-05\n",
      "Epoch 4910, Loss: 0.00019065717924604542, Final Batch Loss: 4.952243762090802e-05\n",
      "Epoch 4911, Loss: 0.00023485390101996018, Final Batch Loss: 0.00020569833577610552\n",
      "Epoch 4912, Loss: 0.0002776745286610094, Final Batch Loss: 2.345341727050254e-06\n",
      "Epoch 4913, Loss: 0.0003825082239927724, Final Batch Loss: 1.6677302483003587e-05\n",
      "Epoch 4914, Loss: 0.00038799546621248737, Final Batch Loss: 1.6039754200392053e-06\n",
      "Epoch 4915, Loss: 0.0031194888229038042, Final Batch Loss: 0.003051905194297433\n",
      "Epoch 4916, Loss: 5.92398566823249e-05, Final Batch Loss: 4.427130988915451e-06\n",
      "Epoch 4917, Loss: 0.0021775369550596224, Final Batch Loss: 9.847545152297243e-05\n",
      "Epoch 4918, Loss: 0.00022156829982122872, Final Batch Loss: 3.223417297704145e-05\n",
      "Epoch 4919, Loss: 0.0006987387059780303, Final Batch Loss: 2.6072173568536527e-05\n",
      "Epoch 4920, Loss: 0.00023602208648298983, Final Batch Loss: 8.382149826502427e-05\n",
      "Epoch 4921, Loss: 0.0005812741540012212, Final Batch Loss: 1.4775658200960606e-05\n",
      "Epoch 4922, Loss: 0.0016411134211011813, Final Batch Loss: 0.00027269686688669026\n",
      "Epoch 4923, Loss: 0.0004301152512198314, Final Batch Loss: 9.295333438785747e-05\n",
      "Epoch 4924, Loss: 0.01512230478329002, Final Batch Loss: 0.014670304954051971\n",
      "Epoch 4925, Loss: 0.0034236423671245575, Final Batch Loss: 0.00012857140973210335\n",
      "Epoch 4926, Loss: 0.0011806153343059123, Final Batch Loss: 0.0001745690533425659\n",
      "Epoch 4927, Loss: 0.0007853366805647966, Final Batch Loss: 6.644010863965377e-05\n",
      "Epoch 4928, Loss: 0.0016723797353961345, Final Batch Loss: 1.0970808261845377e-06\n",
      "Epoch 4929, Loss: 0.0041097387602349045, Final Batch Loss: 1.6206109648919664e-05\n",
      "Epoch 4930, Loss: 0.0008188065453396121, Final Batch Loss: 0.0007133135804906487\n",
      "Epoch 4931, Loss: 0.0010173099362873472, Final Batch Loss: 0.0001718037819955498\n",
      "Epoch 4932, Loss: 0.0009954550591828593, Final Batch Loss: 3.588329127524048e-05\n",
      "Epoch 4933, Loss: 0.00016184395906293503, Final Batch Loss: 1.3525149142878945e-06\n",
      "Epoch 4934, Loss: 0.00013939073687652126, Final Batch Loss: 3.6046229070052505e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4935, Loss: 0.00022089779304224066, Final Batch Loss: 3.0632454581791535e-05\n",
      "Epoch 4936, Loss: 0.00020976813902962022, Final Batch Loss: 3.972054037149064e-05\n",
      "Epoch 4937, Loss: 0.0007656383695575641, Final Batch Loss: 0.0001882444485090673\n",
      "Epoch 4938, Loss: 0.00016853812576300697, Final Batch Loss: 9.017793672683183e-06\n",
      "Epoch 4939, Loss: 0.00024381863022426842, Final Batch Loss: 1.1561775863810908e-05\n",
      "Epoch 4940, Loss: 0.00013254252337446815, Final Batch Loss: 1.6268014633169514e-06\n",
      "Epoch 4941, Loss: 0.0006171792449549685, Final Batch Loss: 0.00034870492527261376\n",
      "Epoch 4942, Loss: 0.001028909888191265, Final Batch Loss: 2.694562317628879e-05\n",
      "Epoch 4943, Loss: 0.0003224497387463998, Final Batch Loss: 1.5948509144436684e-06\n",
      "Epoch 4944, Loss: 0.00026687148397286364, Final Batch Loss: 2.0015611426060786e-06\n",
      "Epoch 4945, Loss: 0.0004714519518529414, Final Batch Loss: 1.363006049359683e-06\n",
      "Epoch 4946, Loss: 0.011336364779708674, Final Batch Loss: 4.583314876072109e-05\n",
      "Epoch 4947, Loss: 0.00041809878530330025, Final Batch Loss: 0.00023406451509799808\n",
      "Epoch 4948, Loss: 0.0004958358770181803, Final Batch Loss: 1.3816063074045815e-05\n",
      "Epoch 4949, Loss: 0.006715125859045656, Final Batch Loss: 0.00019509118283167481\n",
      "Epoch 4950, Loss: 0.00040437450684294163, Final Batch Loss: 2.4862822556315223e-06\n",
      "Epoch 4951, Loss: 0.00254613085667188, Final Batch Loss: 0.00027642506756819785\n",
      "Epoch 4952, Loss: 0.0005570737571360951, Final Batch Loss: 2.58938962360844e-06\n",
      "Epoch 4953, Loss: 0.02730542788776802, Final Batch Loss: 0.026874536648392677\n",
      "Epoch 4954, Loss: 0.0005779255870947964, Final Batch Loss: 8.030830213101581e-05\n",
      "Epoch 4955, Loss: 0.0005974467321721022, Final Batch Loss: 5.585353392234538e-06\n",
      "Epoch 4956, Loss: 0.0006641836207563756, Final Batch Loss: 3.353745705680922e-05\n",
      "Epoch 4957, Loss: 0.00025933088227247936, Final Batch Loss: 1.8777868717734236e-06\n",
      "Epoch 4958, Loss: 0.0009584005993588107, Final Batch Loss: 9.424657605450193e-07\n",
      "Epoch 4959, Loss: 9.160687659459654e-05, Final Batch Loss: 8.927153430704493e-06\n",
      "Epoch 4960, Loss: 0.0002434043362882221, Final Batch Loss: 4.629312752513215e-05\n",
      "Epoch 4961, Loss: 0.0001840619916038122, Final Batch Loss: 3.495631244732067e-05\n",
      "Epoch 4962, Loss: 0.0002613097458379343, Final Batch Loss: 2.2619049559580162e-05\n",
      "Epoch 4963, Loss: 0.0012401604044498526, Final Batch Loss: 0.0006706405547447503\n",
      "Epoch 4964, Loss: 0.00024660073364657364, Final Batch Loss: 0.0002026191505137831\n",
      "Epoch 4965, Loss: 0.001294776546274079, Final Batch Loss: 2.0212526578688994e-05\n",
      "Epoch 4966, Loss: 0.000685773808072554, Final Batch Loss: 3.3964279282372445e-05\n",
      "Epoch 4967, Loss: 0.000402067213144619, Final Batch Loss: 6.615173333557323e-05\n",
      "Epoch 4968, Loss: 0.00011444196604770696, Final Batch Loss: 7.252983323269291e-06\n",
      "Epoch 4969, Loss: 0.0014714616772835143, Final Batch Loss: 0.0011332331923767924\n",
      "Epoch 4970, Loss: 0.00035555445447243983, Final Batch Loss: 3.8949732697801664e-05\n",
      "Epoch 4971, Loss: 0.0001514166378910886, Final Batch Loss: 1.9222354239900596e-05\n",
      "Epoch 4972, Loss: 0.00022128082719063968, Final Batch Loss: 3.629820184869459e-06\n",
      "Epoch 4973, Loss: 0.00017615145861782366, Final Batch Loss: 6.901423148519825e-06\n",
      "Epoch 4974, Loss: 0.008500783026420322, Final Batch Loss: 3.2111681775859324e-06\n",
      "Epoch 4975, Loss: 0.0003300010721432045, Final Batch Loss: 3.1368836062029004e-05\n",
      "Epoch 4976, Loss: 0.000740958565074834, Final Batch Loss: 1.8087079297401942e-05\n",
      "Epoch 4977, Loss: 0.00041295035771327093, Final Batch Loss: 5.567313201026991e-05\n",
      "Epoch 4978, Loss: 0.0005766264496287477, Final Batch Loss: 1.9439378320385003e-06\n",
      "Epoch 4979, Loss: 0.012540367285510001, Final Batch Loss: 2.5756366085261106e-05\n",
      "Epoch 4980, Loss: 0.0010975380555464653, Final Batch Loss: 2.7448133550933562e-05\n",
      "Epoch 4981, Loss: 0.001179137183498824, Final Batch Loss: 0.0007190314354375005\n",
      "Epoch 4982, Loss: 0.00022827802604297176, Final Batch Loss: 3.457344791968353e-05\n",
      "Epoch 4983, Loss: 0.0008320957058458589, Final Batch Loss: 0.0005426908610388637\n",
      "Epoch 4984, Loss: 0.000205161807116383, Final Batch Loss: 5.794980097562075e-05\n",
      "Epoch 4985, Loss: 0.0009867224534900743, Final Batch Loss: 2.5942841602955014e-05\n",
      "Epoch 4986, Loss: 0.0004196152094664285, Final Batch Loss: 8.974471711553633e-05\n",
      "Epoch 4987, Loss: 8.680041719344445e-05, Final Batch Loss: 4.8990252253133804e-05\n",
      "Epoch 4988, Loss: 0.0019645118882181123, Final Batch Loss: 0.0012497922871261835\n",
      "Epoch 4989, Loss: 0.0003858541494992096, Final Batch Loss: 9.466928895562887e-05\n",
      "Epoch 4990, Loss: 0.0001325442908637342, Final Batch Loss: 8.955137673183344e-06\n",
      "Epoch 4991, Loss: 0.00013145781667844858, Final Batch Loss: 4.1068746213568375e-05\n",
      "Epoch 4992, Loss: 0.0008944563269324135, Final Batch Loss: 0.0008774145971983671\n",
      "Epoch 4993, Loss: 0.0008889936543710064, Final Batch Loss: 4.418219032231718e-05\n",
      "Epoch 4994, Loss: 0.00011260463361395523, Final Batch Loss: 2.8316087991697714e-05\n",
      "Epoch 4995, Loss: 0.00030292429710243596, Final Batch Loss: 9.834976481215563e-06\n",
      "Epoch 4996, Loss: 0.0002273551217513159, Final Batch Loss: 4.7442197683267295e-05\n",
      "Epoch 4997, Loss: 0.00015364383762062062, Final Batch Loss: 4.8914156650425866e-05\n",
      "Epoch 4998, Loss: 0.0003885279456881108, Final Batch Loss: 0.00013200640387367457\n",
      "Epoch 4999, Loss: 0.0003197698970325291, Final Batch Loss: 1.910707760544028e-05\n",
      "Epoch 5000, Loss: 0.0015367344767582836, Final Batch Loss: 0.0013144169934093952\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[70  0  0]\n",
      " [ 1 41  0]\n",
      " [ 0  0 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     1.000     0.993        70\n",
      "           1      1.000     0.976     0.988        42\n",
      "           2      1.000     1.000     1.000        53\n",
      "\n",
      "    accuracy                          0.994       165\n",
      "   macro avg      0.995     0.992     0.994       165\n",
      "weighted avg      0.994     0.994     0.994       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../../saved_models/UCI 3 Label 7 Subject Classifier Ablation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
