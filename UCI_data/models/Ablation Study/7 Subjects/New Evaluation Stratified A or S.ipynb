{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 7)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.36576771736145, Final Batch Loss: 1.0899100303649902\n",
      "Epoch 2, Loss: 4.349387049674988, Final Batch Loss: 1.0702663660049438\n",
      "Epoch 3, Loss: 4.3491305112838745, Final Batch Loss: 1.0788629055023193\n",
      "Epoch 4, Loss: 4.344789981842041, Final Batch Loss: 1.0828319787979126\n",
      "Epoch 5, Loss: 4.346787810325623, Final Batch Loss: 1.094003438949585\n",
      "Epoch 6, Loss: 4.330332398414612, Final Batch Loss: 1.0834686756134033\n",
      "Epoch 7, Loss: 4.307819724082947, Final Batch Loss: 1.0590285062789917\n",
      "Epoch 8, Loss: 4.302067995071411, Final Batch Loss: 1.0753734111785889\n",
      "Epoch 9, Loss: 4.2786630392074585, Final Batch Loss: 1.074175477027893\n",
      "Epoch 10, Loss: 4.240744352340698, Final Batch Loss: 1.0460864305496216\n",
      "Epoch 11, Loss: 4.18159806728363, Final Batch Loss: 1.0245922803878784\n",
      "Epoch 12, Loss: 4.144050598144531, Final Batch Loss: 1.033598780632019\n",
      "Epoch 13, Loss: 4.056296944618225, Final Batch Loss: 1.0162899494171143\n",
      "Epoch 14, Loss: 3.9756470918655396, Final Batch Loss: 0.9833683967590332\n",
      "Epoch 15, Loss: 3.9036834836006165, Final Batch Loss: 0.997744083404541\n",
      "Epoch 16, Loss: 3.751462161540985, Final Batch Loss: 0.9301913976669312\n",
      "Epoch 17, Loss: 3.630721151828766, Final Batch Loss: 0.9211748838424683\n",
      "Epoch 18, Loss: 3.4526928663253784, Final Batch Loss: 0.8394899368286133\n",
      "Epoch 19, Loss: 3.2732651829719543, Final Batch Loss: 0.7916178703308105\n",
      "Epoch 20, Loss: 3.0384801626205444, Final Batch Loss: 0.748860239982605\n",
      "Epoch 21, Loss: 2.8609769344329834, Final Batch Loss: 0.7024354338645935\n",
      "Epoch 22, Loss: 2.537342071533203, Final Batch Loss: 0.5555920004844666\n",
      "Epoch 23, Loss: 2.258020520210266, Final Batch Loss: 0.5170593857765198\n",
      "Epoch 24, Loss: 1.9335935711860657, Final Batch Loss: 0.4932899475097656\n",
      "Epoch 25, Loss: 1.620668202638626, Final Batch Loss: 0.3910500407218933\n",
      "Epoch 26, Loss: 1.335030347108841, Final Batch Loss: 0.3208259046077728\n",
      "Epoch 27, Loss: 1.207769125699997, Final Batch Loss: 0.27114996314048767\n",
      "Epoch 28, Loss: 0.9514877200126648, Final Batch Loss: 0.19761626422405243\n",
      "Epoch 29, Loss: 0.8985665142536163, Final Batch Loss: 0.22195975482463837\n",
      "Epoch 30, Loss: 0.7656358182430267, Final Batch Loss: 0.17363567650318146\n",
      "Epoch 31, Loss: 0.7667684704065323, Final Batch Loss: 0.1878543496131897\n",
      "Epoch 32, Loss: 0.6291482299566269, Final Batch Loss: 0.15467886626720428\n",
      "Epoch 33, Loss: 0.49110518395900726, Final Batch Loss: 0.0856890082359314\n",
      "Epoch 34, Loss: 0.5617602691054344, Final Batch Loss: 0.11576856672763824\n",
      "Epoch 35, Loss: 0.5009273663163185, Final Batch Loss: 0.12152126431465149\n",
      "Epoch 36, Loss: 0.5210462510585785, Final Batch Loss: 0.11194545030593872\n",
      "Epoch 37, Loss: 0.4993700757622719, Final Batch Loss: 0.1080746054649353\n",
      "Epoch 38, Loss: 0.4436412453651428, Final Batch Loss: 0.14976000785827637\n",
      "Epoch 39, Loss: 0.42333461344242096, Final Batch Loss: 0.1007298082113266\n",
      "Epoch 40, Loss: 0.390471413731575, Final Batch Loss: 0.06757847219705582\n",
      "Epoch 41, Loss: 0.4470547214150429, Final Batch Loss: 0.08556222170591354\n",
      "Epoch 42, Loss: 0.366004291921854, Final Batch Loss: 0.08412456512451172\n",
      "Epoch 43, Loss: 0.37541724741458893, Final Batch Loss: 0.08958851546049118\n",
      "Epoch 44, Loss: 0.3686525970697403, Final Batch Loss: 0.1003870889544487\n",
      "Epoch 45, Loss: 0.376164011657238, Final Batch Loss: 0.0867048054933548\n",
      "Epoch 46, Loss: 0.3030441254377365, Final Batch Loss: 0.0727597028017044\n",
      "Epoch 47, Loss: 0.31551337987184525, Final Batch Loss: 0.09160539507865906\n",
      "Epoch 48, Loss: 0.26938629895448685, Final Batch Loss: 0.04121890291571617\n",
      "Epoch 49, Loss: 0.33794332295656204, Final Batch Loss: 0.059992894530296326\n",
      "Epoch 50, Loss: 0.2636687606573105, Final Batch Loss: 0.0765785276889801\n",
      "Epoch 51, Loss: 0.25670490972697735, Final Batch Loss: 0.028758881613612175\n",
      "Epoch 52, Loss: 0.31104398146271706, Final Batch Loss: 0.08070637285709381\n",
      "Epoch 53, Loss: 0.2924773246049881, Final Batch Loss: 0.08185597509145737\n",
      "Epoch 54, Loss: 0.29768774285912514, Final Batch Loss: 0.06742679327726364\n",
      "Epoch 55, Loss: 0.27822262048721313, Final Batch Loss: 0.07811585068702698\n",
      "Epoch 56, Loss: 0.3070908337831497, Final Batch Loss: 0.07353795319795609\n",
      "Epoch 57, Loss: 0.2722049653530121, Final Batch Loss: 0.04734908789396286\n",
      "Epoch 58, Loss: 0.2189345918595791, Final Batch Loss: 0.05663396045565605\n",
      "Epoch 59, Loss: 0.2511182799935341, Final Batch Loss: 0.04246540740132332\n",
      "Epoch 60, Loss: 0.30868589133024216, Final Batch Loss: 0.05388408899307251\n",
      "Epoch 61, Loss: 0.28483717143535614, Final Batch Loss: 0.04427303373813629\n",
      "Epoch 62, Loss: 0.26353732869029045, Final Batch Loss: 0.0911356657743454\n",
      "Epoch 63, Loss: 0.25080226361751556, Final Batch Loss: 0.03798310086131096\n",
      "Epoch 64, Loss: 0.24476497992873192, Final Batch Loss: 0.03833823278546333\n",
      "Epoch 65, Loss: 0.25574270635843277, Final Batch Loss: 0.046490855515003204\n",
      "Epoch 66, Loss: 0.2547866515815258, Final Batch Loss: 0.05631217733025551\n",
      "Epoch 67, Loss: 0.21962429583072662, Final Batch Loss: 0.04097754880785942\n",
      "Epoch 68, Loss: 0.2827115170657635, Final Batch Loss: 0.04748621955513954\n",
      "Epoch 69, Loss: 0.22066207602620125, Final Batch Loss: 0.07553788274526596\n",
      "Epoch 70, Loss: 0.24899468570947647, Final Batch Loss: 0.08872000873088837\n",
      "Epoch 71, Loss: 0.21208523586392403, Final Batch Loss: 0.0388861745595932\n",
      "Epoch 72, Loss: 0.18481762893497944, Final Batch Loss: 0.026457076892256737\n",
      "Epoch 73, Loss: 0.1853809989988804, Final Batch Loss: 0.031405434012413025\n",
      "Epoch 74, Loss: 0.20958642847836018, Final Batch Loss: 0.05871071293950081\n",
      "Epoch 75, Loss: 0.17181279882788658, Final Batch Loss: 0.02361820638179779\n",
      "Epoch 76, Loss: 0.20387281849980354, Final Batch Loss: 0.02555035427212715\n",
      "Epoch 77, Loss: 0.18419722840189934, Final Batch Loss: 0.02327542006969452\n",
      "Epoch 78, Loss: 0.19627194106578827, Final Batch Loss: 0.035999152809381485\n",
      "Epoch 79, Loss: 0.16915435157716274, Final Batch Loss: 0.06960802525281906\n",
      "Epoch 80, Loss: 0.19237201288342476, Final Batch Loss: 0.04238644242286682\n",
      "Epoch 81, Loss: 0.19985472783446312, Final Batch Loss: 0.06610774993896484\n",
      "Epoch 82, Loss: 0.1952390931546688, Final Batch Loss: 0.03438415378332138\n",
      "Epoch 83, Loss: 0.16753743030130863, Final Batch Loss: 0.031419601291418076\n",
      "Epoch 84, Loss: 0.19920551590621471, Final Batch Loss: 0.08681692183017731\n",
      "Epoch 85, Loss: 0.181222602725029, Final Batch Loss: 0.07331280410289764\n",
      "Epoch 86, Loss: 0.17537416145205498, Final Batch Loss: 0.06467799842357635\n",
      "Epoch 87, Loss: 0.20154688134789467, Final Batch Loss: 0.047956399619579315\n",
      "Epoch 88, Loss: 0.15607728250324726, Final Batch Loss: 0.021725399419665337\n",
      "Epoch 89, Loss: 0.18182453885674477, Final Batch Loss: 0.016614850610494614\n",
      "Epoch 90, Loss: 0.1538346465677023, Final Batch Loss: 0.02778148092329502\n",
      "Epoch 91, Loss: 0.18611066788434982, Final Batch Loss: 0.05106943100690842\n",
      "Epoch 92, Loss: 0.17247175052762032, Final Batch Loss: 0.04539550095796585\n",
      "Epoch 93, Loss: 0.14403467439115047, Final Batch Loss: 0.021886246278882027\n",
      "Epoch 94, Loss: 0.2539140935987234, Final Batch Loss: 0.1549151986837387\n",
      "Epoch 95, Loss: 0.2114306464791298, Final Batch Loss: 0.06742625683546066\n",
      "Epoch 96, Loss: 0.15900066494941711, Final Batch Loss: 0.024384774267673492\n",
      "Epoch 97, Loss: 0.1490110233426094, Final Batch Loss: 0.040906719863414764\n",
      "Epoch 98, Loss: 0.17753414437174797, Final Batch Loss: 0.07049613445997238\n",
      "Epoch 99, Loss: 0.1778198629617691, Final Batch Loss: 0.063922218978405\n",
      "Epoch 100, Loss: 0.1407415047287941, Final Batch Loss: 0.0414661280810833\n",
      "Epoch 101, Loss: 0.14242732524871826, Final Batch Loss: 0.03965742141008377\n",
      "Epoch 102, Loss: 0.11452778335660696, Final Batch Loss: 0.008406971581280231\n",
      "Epoch 103, Loss: 0.14092373847961426, Final Batch Loss: 0.03662095218896866\n",
      "Epoch 104, Loss: 0.1696699745953083, Final Batch Loss: 0.08358382433652878\n",
      "Epoch 105, Loss: 0.17872554250061512, Final Batch Loss: 0.07274783402681351\n",
      "Epoch 106, Loss: 0.1301440615206957, Final Batch Loss: 0.0170805174857378\n",
      "Epoch 107, Loss: 0.1909034363925457, Final Batch Loss: 0.055414702743291855\n",
      "Epoch 108, Loss: 0.13545100577175617, Final Batch Loss: 0.008635478094220161\n",
      "Epoch 109, Loss: 0.1658610263839364, Final Batch Loss: 0.08818938583135605\n",
      "Epoch 110, Loss: 0.15900934487581253, Final Batch Loss: 0.04734267666935921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, Loss: 0.14713040739297867, Final Batch Loss: 0.035206761211156845\n",
      "Epoch 112, Loss: 0.17698768433183432, Final Batch Loss: 0.07819787412881851\n",
      "Epoch 113, Loss: 0.12007927522063255, Final Batch Loss: 0.019010182470083237\n",
      "Epoch 114, Loss: 0.19699268229305744, Final Batch Loss: 0.05125173181295395\n",
      "Epoch 115, Loss: 0.1240863986313343, Final Batch Loss: 0.0161491259932518\n",
      "Epoch 116, Loss: 0.14403057098388672, Final Batch Loss: 0.03797454386949539\n",
      "Epoch 117, Loss: 0.14511089958250523, Final Batch Loss: 0.02481284737586975\n",
      "Epoch 118, Loss: 0.13968586549162865, Final Batch Loss: 0.03704892843961716\n",
      "Epoch 119, Loss: 0.1595332771539688, Final Batch Loss: 0.056136008352041245\n",
      "Epoch 120, Loss: 0.13390304520726204, Final Batch Loss: 0.021936168894171715\n",
      "Epoch 121, Loss: 0.13044004887342453, Final Batch Loss: 0.05395938456058502\n",
      "Epoch 122, Loss: 0.20574522577226162, Final Batch Loss: 0.119707390666008\n",
      "Epoch 123, Loss: 0.11935363803058863, Final Batch Loss: 0.008437984623014927\n",
      "Epoch 124, Loss: 0.18337507732212543, Final Batch Loss: 0.05185948312282562\n",
      "Epoch 125, Loss: 0.11230420041829348, Final Batch Loss: 0.0078487703576684\n",
      "Epoch 126, Loss: 0.11768103577196598, Final Batch Loss: 0.023487500846385956\n",
      "Epoch 127, Loss: 0.11230197735130787, Final Batch Loss: 0.05946609750390053\n",
      "Epoch 128, Loss: 0.15722515992820263, Final Batch Loss: 0.07951099425554276\n",
      "Epoch 129, Loss: 0.09991292282938957, Final Batch Loss: 0.029165193438529968\n",
      "Epoch 130, Loss: 0.12462530843913555, Final Batch Loss: 0.046045321971178055\n",
      "Epoch 131, Loss: 0.11895672790706158, Final Batch Loss: 0.04304378479719162\n",
      "Epoch 132, Loss: 0.14752279594540596, Final Batch Loss: 0.04686623066663742\n",
      "Epoch 133, Loss: 0.14401357248425484, Final Batch Loss: 0.04478899762034416\n",
      "Epoch 134, Loss: 0.1017841724678874, Final Batch Loss: 0.04806104302406311\n",
      "Epoch 135, Loss: 0.13022553361952305, Final Batch Loss: 0.041850194334983826\n",
      "Epoch 136, Loss: 0.14699921570718288, Final Batch Loss: 0.06989394873380661\n",
      "Epoch 137, Loss: 0.09951630979776382, Final Batch Loss: 0.024984681978821754\n",
      "Epoch 138, Loss: 0.13619317673146725, Final Batch Loss: 0.03725941479206085\n",
      "Epoch 139, Loss: 0.0789422383531928, Final Batch Loss: 0.01243675034493208\n",
      "Epoch 140, Loss: 0.12237854022532701, Final Batch Loss: 0.018123477697372437\n",
      "Epoch 141, Loss: 0.17031945567578077, Final Batch Loss: 0.09663284569978714\n",
      "Epoch 142, Loss: 0.13037792220711708, Final Batch Loss: 0.04910880699753761\n",
      "Epoch 143, Loss: 0.09746505878865719, Final Batch Loss: 0.016764355823397636\n",
      "Epoch 144, Loss: 0.09973185881972313, Final Batch Loss: 0.024018483236432076\n",
      "Epoch 145, Loss: 0.09906403301283717, Final Batch Loss: 0.01823095977306366\n",
      "Epoch 146, Loss: 0.1419640714302659, Final Batch Loss: 0.014820418320596218\n",
      "Epoch 147, Loss: 0.1079739648848772, Final Batch Loss: 0.020271245390176773\n",
      "Epoch 148, Loss: 0.09031437197700143, Final Batch Loss: 0.007288201246410608\n",
      "Epoch 149, Loss: 0.17402176838368177, Final Batch Loss: 0.07732804864645004\n",
      "Epoch 150, Loss: 0.13795101270079613, Final Batch Loss: 0.030952563509345055\n",
      "Epoch 151, Loss: 0.10377975553274155, Final Batch Loss: 0.011722056195139885\n",
      "Epoch 152, Loss: 0.10499929543584585, Final Batch Loss: 0.04737471416592598\n",
      "Epoch 153, Loss: 0.11490107700228691, Final Batch Loss: 0.03690962493419647\n",
      "Epoch 154, Loss: 0.12197687663137913, Final Batch Loss: 0.013427173718810081\n",
      "Epoch 155, Loss: 0.077588751912117, Final Batch Loss: 0.017794448882341385\n",
      "Epoch 156, Loss: 0.11002607084810734, Final Batch Loss: 0.010511213913559914\n",
      "Epoch 157, Loss: 0.11603519506752491, Final Batch Loss: 0.0673007145524025\n",
      "Epoch 158, Loss: 0.09981076559051871, Final Batch Loss: 0.005773363169282675\n",
      "Epoch 159, Loss: 0.17982052080333233, Final Batch Loss: 0.11466509103775024\n",
      "Epoch 160, Loss: 0.08749890048056841, Final Batch Loss: 0.030566683039069176\n",
      "Epoch 161, Loss: 0.10582033079117537, Final Batch Loss: 0.008437094278633595\n",
      "Epoch 162, Loss: 0.09856946021318436, Final Batch Loss: 0.014876196160912514\n",
      "Epoch 163, Loss: 0.10546479374170303, Final Batch Loss: 0.009776219725608826\n",
      "Epoch 164, Loss: 0.11273367796093225, Final Batch Loss: 0.014194696210324764\n",
      "Epoch 165, Loss: 0.12226507440209389, Final Batch Loss: 0.06280215084552765\n",
      "Epoch 166, Loss: 0.12939542904496193, Final Batch Loss: 0.053931400179862976\n",
      "Epoch 167, Loss: 0.10388226108625531, Final Batch Loss: 0.026792189106345177\n",
      "Epoch 168, Loss: 0.10160271730273962, Final Batch Loss: 0.0053997403010725975\n",
      "Epoch 169, Loss: 0.09100972209125757, Final Batch Loss: 0.017298145219683647\n",
      "Epoch 170, Loss: 0.09214127529412508, Final Batch Loss: 0.012583493255078793\n",
      "Epoch 171, Loss: 0.14156773127615452, Final Batch Loss: 0.0920838862657547\n",
      "Epoch 172, Loss: 0.11040235124528408, Final Batch Loss: 0.013973690569400787\n",
      "Epoch 173, Loss: 0.10595105402171612, Final Batch Loss: 0.04436193034052849\n",
      "Epoch 174, Loss: 0.09566584881395102, Final Batch Loss: 0.051976386457681656\n",
      "Epoch 175, Loss: 0.08972567785531282, Final Batch Loss: 0.013478037901222706\n",
      "Epoch 176, Loss: 0.05747193982824683, Final Batch Loss: 0.005804689601063728\n",
      "Epoch 177, Loss: 0.0812552273273468, Final Batch Loss: 0.01435932144522667\n",
      "Epoch 178, Loss: 0.08465654775500298, Final Batch Loss: 0.00863813515752554\n",
      "Epoch 179, Loss: 0.08518856484442949, Final Batch Loss: 0.022511430084705353\n",
      "Epoch 180, Loss: 0.09631104953587055, Final Batch Loss: 0.040066614747047424\n",
      "Epoch 181, Loss: 0.1086421487852931, Final Batch Loss: 0.04273028299212456\n",
      "Epoch 182, Loss: 0.12634305842220783, Final Batch Loss: 0.02006606198847294\n",
      "Epoch 183, Loss: 0.12322957068681717, Final Batch Loss: 0.02289743535220623\n",
      "Epoch 184, Loss: 0.08501933608204126, Final Batch Loss: 0.03598373010754585\n",
      "Epoch 185, Loss: 0.09028007509186864, Final Batch Loss: 0.010475228540599346\n",
      "Epoch 186, Loss: 0.13917789794504642, Final Batch Loss: 0.04003669694066048\n",
      "Epoch 187, Loss: 0.07677417900413275, Final Batch Loss: 0.01744498685002327\n",
      "Epoch 188, Loss: 0.09757283423095942, Final Batch Loss: 0.005830722860991955\n",
      "Epoch 189, Loss: 0.08060008240863681, Final Batch Loss: 0.007692431565374136\n",
      "Epoch 190, Loss: 0.09691772051155567, Final Batch Loss: 0.05194896459579468\n",
      "Epoch 191, Loss: 0.07291759131476283, Final Batch Loss: 0.00637656869366765\n",
      "Epoch 192, Loss: 0.09181741625070572, Final Batch Loss: 0.03075190633535385\n",
      "Epoch 193, Loss: 0.081780054140836, Final Batch Loss: 0.0035954960621893406\n",
      "Epoch 194, Loss: 0.07062764093279839, Final Batch Loss: 0.009306121617555618\n",
      "Epoch 195, Loss: 0.10081039369106293, Final Batch Loss: 0.046642400324344635\n",
      "Epoch 196, Loss: 0.12299940874800086, Final Batch Loss: 0.03804168850183487\n",
      "Epoch 197, Loss: 0.08164263749495149, Final Batch Loss: 0.005135571584105492\n",
      "Epoch 198, Loss: 0.12808467727154493, Final Batch Loss: 0.01531421858817339\n",
      "Epoch 199, Loss: 0.08383020386099815, Final Batch Loss: 0.01274446863681078\n",
      "Epoch 200, Loss: 0.07591513730585575, Final Batch Loss: 0.0074896737933158875\n",
      "Epoch 201, Loss: 0.08015219960361719, Final Batch Loss: 0.034869905561208725\n",
      "Epoch 202, Loss: 0.07052007270976901, Final Batch Loss: 0.003772101830691099\n",
      "Epoch 203, Loss: 0.11811550799757242, Final Batch Loss: 0.06090548262000084\n",
      "Epoch 204, Loss: 0.08277944615110755, Final Batch Loss: 0.006088450085371733\n",
      "Epoch 205, Loss: 0.12520648818463087, Final Batch Loss: 0.09175797551870346\n",
      "Epoch 206, Loss: 0.11038110964000225, Final Batch Loss: 0.06424690037965775\n",
      "Epoch 207, Loss: 0.07122864667326212, Final Batch Loss: 0.008114693686366081\n",
      "Epoch 208, Loss: 0.08808829169720411, Final Batch Loss: 0.03570173680782318\n",
      "Epoch 209, Loss: 0.07467016484588385, Final Batch Loss: 0.030282683670520782\n",
      "Epoch 210, Loss: 0.0984309334307909, Final Batch Loss: 0.031331516802310944\n",
      "Epoch 211, Loss: 0.08219883544370532, Final Batch Loss: 0.04653584957122803\n",
      "Epoch 212, Loss: 0.10177335143089294, Final Batch Loss: 0.0364355742931366\n",
      "Epoch 213, Loss: 0.09204855747520924, Final Batch Loss: 0.014601599425077438\n",
      "Epoch 214, Loss: 0.06393067492172122, Final Batch Loss: 0.00745544396340847\n",
      "Epoch 215, Loss: 0.1134399976581335, Final Batch Loss: 0.02631147764623165\n",
      "Epoch 216, Loss: 0.08554922416806221, Final Batch Loss: 0.012049931101500988\n",
      "Epoch 217, Loss: 0.06466568564064801, Final Batch Loss: 0.0027887329924851656\n",
      "Epoch 218, Loss: 0.0770618449896574, Final Batch Loss: 0.01767631806433201\n",
      "Epoch 219, Loss: 0.07043529534712434, Final Batch Loss: 0.0028177364729344845\n",
      "Epoch 220, Loss: 0.08878820668905973, Final Batch Loss: 0.011788731440901756\n",
      "Epoch 221, Loss: 0.11119447043165565, Final Batch Loss: 0.03761959448456764\n",
      "Epoch 222, Loss: 0.07188117457553744, Final Batch Loss: 0.005331546533852816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223, Loss: 0.0895784511230886, Final Batch Loss: 0.012076412327587605\n",
      "Epoch 224, Loss: 0.07614632742479444, Final Batch Loss: 0.03413989022374153\n",
      "Epoch 225, Loss: 0.09218046255409718, Final Batch Loss: 0.04906642064452171\n",
      "Epoch 226, Loss: 0.06960407923907042, Final Batch Loss: 0.016022169962525368\n",
      "Epoch 227, Loss: 0.07487126160413027, Final Batch Loss: 0.030558031052350998\n",
      "Epoch 228, Loss: 0.09152569901198149, Final Batch Loss: 0.03832918033003807\n",
      "Epoch 229, Loss: 0.0978116700425744, Final Batch Loss: 0.042822133749723434\n",
      "Epoch 230, Loss: 0.05182819114997983, Final Batch Loss: 0.004302126355469227\n",
      "Epoch 231, Loss: 0.09632308967411518, Final Batch Loss: 0.04830231890082359\n",
      "Epoch 232, Loss: 0.09505121316760778, Final Batch Loss: 0.024045808240771294\n",
      "Epoch 233, Loss: 0.09059954527765512, Final Batch Loss: 0.010164489038288593\n",
      "Epoch 234, Loss: 0.057677924167364836, Final Batch Loss: 0.005675687920302153\n",
      "Epoch 235, Loss: 0.11531026125885546, Final Batch Loss: 0.06804204732179642\n",
      "Epoch 236, Loss: 0.09736171830445528, Final Batch Loss: 0.057995956391096115\n",
      "Epoch 237, Loss: 0.08913205657154322, Final Batch Loss: 0.0067673372104763985\n",
      "Epoch 238, Loss: 0.10080099245533347, Final Batch Loss: 0.036857038736343384\n",
      "Epoch 239, Loss: 0.08847174048423767, Final Batch Loss: 0.015220243483781815\n",
      "Epoch 240, Loss: 0.05762765696272254, Final Batch Loss: 0.005960665177553892\n",
      "Epoch 241, Loss: 0.07024640450254083, Final Batch Loss: 0.005526665132492781\n",
      "Epoch 242, Loss: 0.06204484775662422, Final Batch Loss: 0.004752478562295437\n",
      "Epoch 243, Loss: 0.07269009295850992, Final Batch Loss: 0.006533598527312279\n",
      "Epoch 244, Loss: 0.06761633651331067, Final Batch Loss: 0.0049508060328662395\n",
      "Epoch 245, Loss: 0.05079843197017908, Final Batch Loss: 0.003969242796301842\n",
      "Epoch 246, Loss: 0.04772037314251065, Final Batch Loss: 0.0023160604760050774\n",
      "Epoch 247, Loss: 0.06279814895242453, Final Batch Loss: 0.022147972136735916\n",
      "Epoch 248, Loss: 0.05734030716121197, Final Batch Loss: 0.014681619592010975\n",
      "Epoch 249, Loss: 0.06660923967137933, Final Batch Loss: 0.0051493230275809765\n",
      "Epoch 250, Loss: 0.11495131719857454, Final Batch Loss: 0.043803367763757706\n",
      "Epoch 251, Loss: 0.07448327634483576, Final Batch Loss: 0.008113579824566841\n",
      "Epoch 252, Loss: 0.07983045559376478, Final Batch Loss: 0.016237465664744377\n",
      "Epoch 253, Loss: 0.11562846228480339, Final Batch Loss: 0.011989950202405453\n",
      "Epoch 254, Loss: 0.11936825374141335, Final Batch Loss: 0.09030884504318237\n",
      "Epoch 255, Loss: 0.07682869024574757, Final Batch Loss: 0.030511237680912018\n",
      "Epoch 256, Loss: 0.09375358419492841, Final Batch Loss: 0.005118415225297213\n",
      "Epoch 257, Loss: 0.11019776854664087, Final Batch Loss: 0.05575478449463844\n",
      "Epoch 258, Loss: 0.06967589794658124, Final Batch Loss: 0.020825274288654327\n",
      "Epoch 259, Loss: 0.06558467238210142, Final Batch Loss: 0.0038091533351689577\n",
      "Epoch 260, Loss: 0.07873464748263359, Final Batch Loss: 0.0425998829305172\n",
      "Epoch 261, Loss: 0.10407178103923798, Final Batch Loss: 0.03816584497690201\n",
      "Epoch 262, Loss: 0.07060179393738508, Final Batch Loss: 0.014045175164937973\n",
      "Epoch 263, Loss: 0.07402744144201279, Final Batch Loss: 0.003331869374960661\n",
      "Epoch 264, Loss: 0.06674467027187347, Final Batch Loss: 0.02322135865688324\n",
      "Epoch 265, Loss: 0.05441636499017477, Final Batch Loss: 0.005959619767963886\n",
      "Epoch 266, Loss: 0.08532491396181285, Final Batch Loss: 0.022506240755319595\n",
      "Epoch 267, Loss: 0.083042673766613, Final Batch Loss: 0.004995683208107948\n",
      "Epoch 268, Loss: 0.05140523333102465, Final Batch Loss: 0.007880735211074352\n",
      "Epoch 269, Loss: 0.07541230996139348, Final Batch Loss: 0.01157835591584444\n",
      "Epoch 270, Loss: 0.09423287538811564, Final Batch Loss: 0.0549655482172966\n",
      "Epoch 271, Loss: 0.060296652372926474, Final Batch Loss: 0.023459743708372116\n",
      "Epoch 272, Loss: 0.07155190268531442, Final Batch Loss: 0.0077190701849758625\n",
      "Epoch 273, Loss: 0.07431626971811056, Final Batch Loss: 0.021422816440463066\n",
      "Epoch 274, Loss: 0.07607585284858942, Final Batch Loss: 0.007177736610174179\n",
      "Epoch 275, Loss: 0.0686908948700875, Final Batch Loss: 0.007460497785359621\n",
      "Epoch 276, Loss: 0.05825539445504546, Final Batch Loss: 0.007292859721928835\n",
      "Epoch 277, Loss: 0.05709442077204585, Final Batch Loss: 0.004331283736974001\n",
      "Epoch 278, Loss: 0.08219602890312672, Final Batch Loss: 0.03462310880422592\n",
      "Epoch 279, Loss: 0.0821070137899369, Final Batch Loss: 0.03428270295262337\n",
      "Epoch 280, Loss: 0.06205532280728221, Final Batch Loss: 0.0055609713308513165\n",
      "Epoch 281, Loss: 0.07097957283258438, Final Batch Loss: 0.011155563406646252\n",
      "Epoch 282, Loss: 0.08241706481203437, Final Batch Loss: 0.03090607561171055\n",
      "Epoch 283, Loss: 0.08317963499575853, Final Batch Loss: 0.028648991137742996\n",
      "Epoch 284, Loss: 0.057821452617645264, Final Batch Loss: 0.00841554906219244\n",
      "Epoch 285, Loss: 0.07412567269057035, Final Batch Loss: 0.03547225520014763\n",
      "Epoch 286, Loss: 0.07004827167838812, Final Batch Loss: 0.0028771646320819855\n",
      "Epoch 287, Loss: 0.04929258627817035, Final Batch Loss: 0.0040586357936263084\n",
      "Epoch 288, Loss: 0.06756130885332823, Final Batch Loss: 0.007385010365396738\n",
      "Epoch 289, Loss: 0.07276874827221036, Final Batch Loss: 0.006266517098993063\n",
      "Epoch 290, Loss: 0.04784881370142102, Final Batch Loss: 0.004662806633859873\n",
      "Epoch 291, Loss: 0.051118834875524044, Final Batch Loss: 0.009511100128293037\n",
      "Epoch 292, Loss: 0.06357219186611474, Final Batch Loss: 0.0059922849759459496\n",
      "Epoch 293, Loss: 0.08958435989916325, Final Batch Loss: 0.005527770146727562\n",
      "Epoch 294, Loss: 0.08666042052209377, Final Batch Loss: 0.014425471425056458\n",
      "Epoch 295, Loss: 0.0922377067618072, Final Batch Loss: 0.04798215627670288\n",
      "Epoch 296, Loss: 0.06047985516488552, Final Batch Loss: 0.0052634640596807\n",
      "Epoch 297, Loss: 0.07215344067662954, Final Batch Loss: 0.026967044919729233\n",
      "Epoch 298, Loss: 0.0707904240116477, Final Batch Loss: 0.008712878450751305\n",
      "Epoch 299, Loss: 0.11310952855274081, Final Batch Loss: 0.058986663818359375\n",
      "Epoch 300, Loss: 0.05591163644567132, Final Batch Loss: 0.006851749960333109\n",
      "Epoch 301, Loss: 0.07617308478802443, Final Batch Loss: 0.026835618540644646\n",
      "Epoch 302, Loss: 0.05993944592773914, Final Batch Loss: 0.02126009576022625\n",
      "Epoch 303, Loss: 0.06747594103217125, Final Batch Loss: 0.019853200763463974\n",
      "Epoch 304, Loss: 0.11581323761492968, Final Batch Loss: 0.0864768922328949\n",
      "Epoch 305, Loss: 0.06695553613826632, Final Batch Loss: 0.005460141692310572\n",
      "Epoch 306, Loss: 0.07049702946096659, Final Batch Loss: 0.013811486773192883\n",
      "Epoch 307, Loss: 0.12421384733170271, Final Batch Loss: 0.060176510363817215\n",
      "Epoch 308, Loss: 0.08311497932299972, Final Batch Loss: 0.015988776460289955\n",
      "Epoch 309, Loss: 0.08648899383842945, Final Batch Loss: 0.055628761649131775\n",
      "Epoch 310, Loss: 0.05606568790972233, Final Batch Loss: 0.004691343754529953\n",
      "Epoch 311, Loss: 0.0911686671897769, Final Batch Loss: 0.04023471102118492\n",
      "Epoch 312, Loss: 0.06986579392105341, Final Batch Loss: 0.014008177444338799\n",
      "Epoch 313, Loss: 0.0612858310341835, Final Batch Loss: 0.01616295985877514\n",
      "Epoch 314, Loss: 0.06956370547413826, Final Batch Loss: 0.023012395948171616\n",
      "Epoch 315, Loss: 0.08920298609882593, Final Batch Loss: 0.02983297035098076\n",
      "Epoch 316, Loss: 0.05367673560976982, Final Batch Loss: 0.006082883104681969\n",
      "Epoch 317, Loss: 0.04847249248996377, Final Batch Loss: 0.006062185857445002\n",
      "Epoch 318, Loss: 0.05795137584209442, Final Batch Loss: 0.023750482127070427\n",
      "Epoch 319, Loss: 0.05504409596323967, Final Batch Loss: 0.015853144228458405\n",
      "Epoch 320, Loss: 0.09792135725729167, Final Batch Loss: 0.04872255027294159\n",
      "Epoch 321, Loss: 0.06194583233445883, Final Batch Loss: 0.005021745804697275\n",
      "Epoch 322, Loss: 0.07205698802135885, Final Batch Loss: 0.051682066172361374\n",
      "Epoch 323, Loss: 0.06428548460826278, Final Batch Loss: 0.011358017101883888\n",
      "Epoch 324, Loss: 0.06863942835479975, Final Batch Loss: 0.008032198064029217\n",
      "Epoch 325, Loss: 0.05442738300189376, Final Batch Loss: 0.004273674916476011\n",
      "Epoch 326, Loss: 0.04165886854752898, Final Batch Loss: 0.012291698716580868\n",
      "Epoch 327, Loss: 0.06654988322407007, Final Batch Loss: 0.00878714770078659\n",
      "Epoch 328, Loss: 0.06210561282932758, Final Batch Loss: 0.031260035932064056\n",
      "Epoch 329, Loss: 0.059965009801089764, Final Batch Loss: 0.002220523077994585\n",
      "Epoch 330, Loss: 0.05923316767439246, Final Batch Loss: 0.006084133870899677\n",
      "Epoch 331, Loss: 0.1132216127589345, Final Batch Loss: 0.07820509374141693\n",
      "Epoch 332, Loss: 0.06310139247216284, Final Batch Loss: 0.010821056552231312\n",
      "Epoch 333, Loss: 0.06308425683528185, Final Batch Loss: 0.004453487228602171\n",
      "Epoch 334, Loss: 0.05454941838979721, Final Batch Loss: 0.028360584750771523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335, Loss: 0.06754338881000876, Final Batch Loss: 0.014920834451913834\n",
      "Epoch 336, Loss: 0.05854008859023452, Final Batch Loss: 0.022867882624268532\n",
      "Epoch 337, Loss: 0.07169452076777816, Final Batch Loss: 0.006655833218246698\n",
      "Epoch 338, Loss: 0.05866815708577633, Final Batch Loss: 0.008490084670484066\n",
      "Epoch 339, Loss: 0.06398884207010269, Final Batch Loss: 0.008031053468585014\n",
      "Epoch 340, Loss: 0.053700946271419525, Final Batch Loss: 0.006824522279202938\n",
      "Epoch 341, Loss: 0.0681737051345408, Final Batch Loss: 0.011279371567070484\n",
      "Epoch 342, Loss: 0.06830414570868015, Final Batch Loss: 0.007857336662709713\n",
      "Epoch 343, Loss: 0.08374876203015447, Final Batch Loss: 0.054085370153188705\n",
      "Epoch 344, Loss: 0.04184260731562972, Final Batch Loss: 0.011018846184015274\n",
      "Epoch 345, Loss: 0.04890845390036702, Final Batch Loss: 0.0032080146484076977\n",
      "Epoch 346, Loss: 0.09297464275732636, Final Batch Loss: 0.03734266757965088\n",
      "Epoch 347, Loss: 0.061701598577201366, Final Batch Loss: 0.005115976557135582\n",
      "Epoch 348, Loss: 0.0672755679115653, Final Batch Loss: 0.007983727380633354\n",
      "Epoch 349, Loss: 0.058685858733952045, Final Batch Loss: 0.011965169571340084\n",
      "Epoch 350, Loss: 0.05491592129692435, Final Batch Loss: 0.025174353271722794\n",
      "Epoch 351, Loss: 0.07902288716286421, Final Batch Loss: 0.04380178824067116\n",
      "Epoch 352, Loss: 0.05138544086366892, Final Batch Loss: 0.0066343313083052635\n",
      "Epoch 353, Loss: 0.0418745840433985, Final Batch Loss: 0.0036546464543789625\n",
      "Epoch 354, Loss: 0.09392048325389624, Final Batch Loss: 0.06522493064403534\n",
      "Epoch 355, Loss: 0.046530206222087145, Final Batch Loss: 0.003843637416139245\n",
      "Epoch 356, Loss: 0.06623796047642827, Final Batch Loss: 0.004250032361596823\n",
      "Epoch 357, Loss: 0.0533554102294147, Final Batch Loss: 0.02571973018348217\n",
      "Epoch 358, Loss: 0.059502652613446116, Final Batch Loss: 0.003070161445066333\n",
      "Epoch 359, Loss: 0.03823096374981105, Final Batch Loss: 0.005983913782984018\n",
      "Epoch 360, Loss: 0.07151799369603395, Final Batch Loss: 0.009104212746024132\n",
      "Epoch 361, Loss: 0.04472489841282368, Final Batch Loss: 0.005065100267529488\n",
      "Epoch 362, Loss: 0.0728372250450775, Final Batch Loss: 0.05022350698709488\n",
      "Epoch 363, Loss: 0.0674881103914231, Final Batch Loss: 0.027624577283859253\n",
      "Epoch 364, Loss: 0.06652394169941545, Final Batch Loss: 0.00280795618891716\n",
      "Epoch 365, Loss: 0.060742187313735485, Final Batch Loss: 0.02281273901462555\n",
      "Epoch 366, Loss: 0.05974716693162918, Final Batch Loss: 0.010840622708201408\n",
      "Epoch 367, Loss: 0.06266946834512055, Final Batch Loss: 0.0031114721205085516\n",
      "Epoch 368, Loss: 0.050145164132118225, Final Batch Loss: 0.011052078567445278\n",
      "Epoch 369, Loss: 0.05635079857893288, Final Batch Loss: 0.034576449543237686\n",
      "Epoch 370, Loss: 0.04318306827917695, Final Batch Loss: 0.005322411190718412\n",
      "Epoch 371, Loss: 0.06848006835207343, Final Batch Loss: 0.03012729436159134\n",
      "Epoch 372, Loss: 0.0431289232801646, Final Batch Loss: 0.00218329974450171\n",
      "Epoch 373, Loss: 0.062680893111974, Final Batch Loss: 0.030487654730677605\n",
      "Epoch 374, Loss: 0.03732098871842027, Final Batch Loss: 0.0021046302281320095\n",
      "Epoch 375, Loss: 0.05089947069063783, Final Batch Loss: 0.013966874219477177\n",
      "Epoch 376, Loss: 0.051705299876630306, Final Batch Loss: 0.006315765902400017\n",
      "Epoch 377, Loss: 0.04534303187392652, Final Batch Loss: 0.0029209780041128397\n",
      "Epoch 378, Loss: 0.06540988991037011, Final Batch Loss: 0.011245490983128548\n",
      "Epoch 379, Loss: 0.045435791835188866, Final Batch Loss: 0.004764082375913858\n",
      "Epoch 380, Loss: 0.03370923246257007, Final Batch Loss: 0.0016625148709863424\n",
      "Epoch 381, Loss: 0.04948599822819233, Final Batch Loss: 0.007506748661398888\n",
      "Epoch 382, Loss: 0.053851507836952806, Final Batch Loss: 0.0247655026614666\n",
      "Epoch 383, Loss: 0.031960754306055605, Final Batch Loss: 0.0018933085957542062\n",
      "Epoch 384, Loss: 0.07410479395184666, Final Batch Loss: 0.04052653908729553\n",
      "Epoch 385, Loss: 0.05069929640740156, Final Batch Loss: 0.004482930526137352\n",
      "Epoch 386, Loss: 0.05228505306877196, Final Batch Loss: 0.00427571265026927\n",
      "Epoch 387, Loss: 0.04345842590555549, Final Batch Loss: 0.0032342183403670788\n",
      "Epoch 388, Loss: 0.0431081757415086, Final Batch Loss: 0.00263663730584085\n",
      "Epoch 389, Loss: 0.04862232552841306, Final Batch Loss: 0.002184564247727394\n",
      "Epoch 390, Loss: 0.06541974795982242, Final Batch Loss: 0.02376859448850155\n",
      "Epoch 391, Loss: 0.050153233110904694, Final Batch Loss: 0.004950751084834337\n",
      "Epoch 392, Loss: 0.06177417188882828, Final Batch Loss: 0.008223358541727066\n",
      "Epoch 393, Loss: 0.04115654481574893, Final Batch Loss: 0.007585275452584028\n",
      "Epoch 394, Loss: 0.049625345738604665, Final Batch Loss: 0.002121777506545186\n",
      "Epoch 395, Loss: 0.043934791814535856, Final Batch Loss: 0.006947616580873728\n",
      "Epoch 396, Loss: 0.04847256117500365, Final Batch Loss: 0.024309922009706497\n",
      "Epoch 397, Loss: 0.04562618606723845, Final Batch Loss: 0.023845085874199867\n",
      "Epoch 398, Loss: 0.04205102170817554, Final Batch Loss: 0.003050128696486354\n",
      "Epoch 399, Loss: 0.03568581980653107, Final Batch Loss: 0.00754649518057704\n",
      "Epoch 400, Loss: 0.07205084525048733, Final Batch Loss: 0.06048664450645447\n",
      "Epoch 401, Loss: 0.05732968088705093, Final Batch Loss: 0.0013266924070194364\n",
      "Epoch 402, Loss: 0.04391360469162464, Final Batch Loss: 0.01253293827176094\n",
      "Epoch 403, Loss: 0.035970061318948865, Final Batch Loss: 0.006663502659648657\n",
      "Epoch 404, Loss: 0.03176013310439885, Final Batch Loss: 0.0021124330814927816\n",
      "Epoch 405, Loss: 0.041880229488015175, Final Batch Loss: 0.006172751076519489\n",
      "Epoch 406, Loss: 0.04856149642728269, Final Batch Loss: 0.002741433447226882\n",
      "Epoch 407, Loss: 0.05071217846125364, Final Batch Loss: 0.015070403926074505\n",
      "Epoch 408, Loss: 0.04767418932169676, Final Batch Loss: 0.0063651311211287975\n",
      "Epoch 409, Loss: 0.039013045374304056, Final Batch Loss: 0.007404486183077097\n",
      "Epoch 410, Loss: 0.054352034348994493, Final Batch Loss: 0.01448865421116352\n",
      "Epoch 411, Loss: 0.04315594304352999, Final Batch Loss: 0.0028235241770744324\n",
      "Epoch 412, Loss: 0.06296180537901819, Final Batch Loss: 0.0015219335909932852\n",
      "Epoch 413, Loss: 0.06280233454890549, Final Batch Loss: 0.016195980831980705\n",
      "Epoch 414, Loss: 0.028399542905390263, Final Batch Loss: 0.001470457878895104\n",
      "Epoch 415, Loss: 0.03776531247422099, Final Batch Loss: 0.002345586195588112\n",
      "Epoch 416, Loss: 0.05711410939693451, Final Batch Loss: 0.0040960293263196945\n",
      "Epoch 417, Loss: 0.07128692069090903, Final Batch Loss: 0.047570180147886276\n",
      "Epoch 418, Loss: 0.055792289320379496, Final Batch Loss: 0.013256876729428768\n",
      "Epoch 419, Loss: 0.042809379170648754, Final Batch Loss: 0.021057553589344025\n",
      "Epoch 420, Loss: 0.048589225858449936, Final Batch Loss: 0.015107718296349049\n",
      "Epoch 421, Loss: 0.038999643293209374, Final Batch Loss: 0.001015011454001069\n",
      "Epoch 422, Loss: 0.034410268533974886, Final Batch Loss: 0.006859194952994585\n",
      "Epoch 423, Loss: 0.039638338959775865, Final Batch Loss: 0.0032928637228906155\n",
      "Epoch 424, Loss: 0.03835207689553499, Final Batch Loss: 0.003877787385135889\n",
      "Epoch 425, Loss: 0.046493437606841326, Final Batch Loss: 0.014669298194348812\n",
      "Epoch 426, Loss: 0.03842420200817287, Final Batch Loss: 0.002325356239452958\n",
      "Epoch 427, Loss: 0.04066263616550714, Final Batch Loss: 0.014829084277153015\n",
      "Epoch 428, Loss: 0.037449055816978216, Final Batch Loss: 0.003962645772844553\n",
      "Epoch 429, Loss: 0.04870116850361228, Final Batch Loss: 0.004969983361661434\n",
      "Epoch 430, Loss: 0.04564429260790348, Final Batch Loss: 0.002171645872294903\n",
      "Epoch 431, Loss: 0.04016473516821861, Final Batch Loss: 0.006401336286216974\n",
      "Epoch 432, Loss: 0.055129814660176635, Final Batch Loss: 0.0220846775919199\n",
      "Epoch 433, Loss: 0.043162457179278135, Final Batch Loss: 0.0023547648452222347\n",
      "Epoch 434, Loss: 0.04499840596690774, Final Batch Loss: 0.009324430488049984\n",
      "Epoch 435, Loss: 0.040114269591867924, Final Batch Loss: 0.01496342197060585\n",
      "Epoch 436, Loss: 0.038118030643090606, Final Batch Loss: 0.005051614250987768\n",
      "Epoch 437, Loss: 0.04689428047277033, Final Batch Loss: 0.003006936050951481\n",
      "Epoch 438, Loss: 0.05123534053564072, Final Batch Loss: 0.0062586055137217045\n",
      "Epoch 439, Loss: 0.045541200088337064, Final Batch Loss: 0.007276203017681837\n",
      "Epoch 440, Loss: 0.055063176434487104, Final Batch Loss: 0.004952719900757074\n",
      "Epoch 441, Loss: 0.03411202738061547, Final Batch Loss: 0.005628351122140884\n",
      "Epoch 442, Loss: 0.03443736769258976, Final Batch Loss: 0.001613212050870061\n",
      "Epoch 443, Loss: 0.04416586272418499, Final Batch Loss: 0.027723021805286407\n",
      "Epoch 444, Loss: 0.04598988906946033, Final Batch Loss: 0.024343213066458702\n",
      "Epoch 445, Loss: 0.07461977296043187, Final Batch Loss: 0.0509471632540226\n",
      "Epoch 446, Loss: 0.06562672439031303, Final Batch Loss: 0.044829972088336945\n",
      "Epoch 447, Loss: 0.05203999578952789, Final Batch Loss: 0.0064011369831860065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448, Loss: 0.02799196122214198, Final Batch Loss: 0.0036357976496219635\n",
      "Epoch 449, Loss: 0.05080106668174267, Final Batch Loss: 0.0039462074637413025\n",
      "Epoch 450, Loss: 0.07956235972233117, Final Batch Loss: 0.052728042006492615\n",
      "Epoch 451, Loss: 0.0623420481570065, Final Batch Loss: 0.021016238257288933\n",
      "Epoch 452, Loss: 0.04109061602503061, Final Batch Loss: 0.006870650220662355\n",
      "Epoch 453, Loss: 0.04427370894700289, Final Batch Loss: 0.005129598081111908\n",
      "Epoch 454, Loss: 0.04846584238111973, Final Batch Loss: 0.02506340481340885\n",
      "Epoch 455, Loss: 0.04317082790657878, Final Batch Loss: 0.0017700658645480871\n",
      "Epoch 456, Loss: 0.04321973444893956, Final Batch Loss: 0.009210807271301746\n",
      "Epoch 457, Loss: 0.060408377554267645, Final Batch Loss: 0.006337106693536043\n",
      "Epoch 458, Loss: 0.058547146851196885, Final Batch Loss: 0.03747839853167534\n",
      "Epoch 459, Loss: 0.04784586210735142, Final Batch Loss: 0.004620722029358149\n",
      "Epoch 460, Loss: 0.04884950316045433, Final Batch Loss: 0.003311386564746499\n",
      "Epoch 461, Loss: 0.04485900979489088, Final Batch Loss: 0.005522510502487421\n",
      "Epoch 462, Loss: 0.04801594675518572, Final Batch Loss: 0.002126553328707814\n",
      "Epoch 463, Loss: 0.07623619760852307, Final Batch Loss: 0.0006606407696381211\n",
      "Epoch 464, Loss: 0.05778400017879903, Final Batch Loss: 0.0018573340494185686\n",
      "Epoch 465, Loss: 0.054860498989000916, Final Batch Loss: 0.012639385648071766\n",
      "Epoch 466, Loss: 0.048977505415678024, Final Batch Loss: 0.010270797647535801\n",
      "Epoch 467, Loss: 0.031069090589880943, Final Batch Loss: 0.004691938869655132\n",
      "Epoch 468, Loss: 0.033777554985135794, Final Batch Loss: 0.005685580428689718\n",
      "Epoch 469, Loss: 0.05239171301946044, Final Batch Loss: 0.024197634309530258\n",
      "Epoch 470, Loss: 0.04546708078123629, Final Batch Loss: 0.004978676326572895\n",
      "Epoch 471, Loss: 0.047254522098228335, Final Batch Loss: 0.03584546223282814\n",
      "Epoch 472, Loss: 0.07385887042619288, Final Batch Loss: 0.04281603544950485\n",
      "Epoch 473, Loss: 0.03122986597009003, Final Batch Loss: 0.002582301152870059\n",
      "Epoch 474, Loss: 0.030707916244864464, Final Batch Loss: 0.0034459347371011972\n",
      "Epoch 475, Loss: 0.048632825491949916, Final Batch Loss: 0.0029763816855847836\n",
      "Epoch 476, Loss: 0.033880206756293774, Final Batch Loss: 0.022291479632258415\n",
      "Epoch 477, Loss: 0.05179697694256902, Final Batch Loss: 0.017394475638866425\n",
      "Epoch 478, Loss: 0.059337959391996264, Final Batch Loss: 0.02763189934194088\n",
      "Epoch 479, Loss: 0.033424124820157886, Final Batch Loss: 0.004381932783871889\n",
      "Epoch 480, Loss: 0.04551798081956804, Final Batch Loss: 0.002553342143073678\n",
      "Epoch 481, Loss: 0.02757398528046906, Final Batch Loss: 0.0019410543609410524\n",
      "Epoch 482, Loss: 0.05194889253471047, Final Batch Loss: 0.04263043776154518\n",
      "Epoch 483, Loss: 0.04497277271002531, Final Batch Loss: 0.002732211723923683\n",
      "Epoch 484, Loss: 0.024486824753694236, Final Batch Loss: 0.0015341428807005286\n",
      "Epoch 485, Loss: 0.039536340394988656, Final Batch Loss: 0.0023590391501784325\n",
      "Epoch 486, Loss: 0.03207432711496949, Final Batch Loss: 0.0034369411878287792\n",
      "Epoch 487, Loss: 0.04219659371301532, Final Batch Loss: 0.0011330246925354004\n",
      "Epoch 488, Loss: 0.052064243936911225, Final Batch Loss: 0.03073294088244438\n",
      "Epoch 489, Loss: 0.034886452136561275, Final Batch Loss: 0.014804442413151264\n",
      "Epoch 490, Loss: 0.04342127533163875, Final Batch Loss: 0.0015740528469905257\n",
      "Epoch 491, Loss: 0.03204285306856036, Final Batch Loss: 0.003358179936185479\n",
      "Epoch 492, Loss: 0.04423580598086119, Final Batch Loss: 0.0020486616995185614\n",
      "Epoch 493, Loss: 0.041404837276786566, Final Batch Loss: 0.012029941193759441\n",
      "Epoch 494, Loss: 0.03530863765627146, Final Batch Loss: 0.004077505320310593\n",
      "Epoch 495, Loss: 0.037811461137607694, Final Batch Loss: 0.0020871495362371206\n",
      "Epoch 496, Loss: 0.04064897866919637, Final Batch Loss: 0.010878991335630417\n",
      "Epoch 497, Loss: 0.04252974549308419, Final Batch Loss: 0.004785163328051567\n",
      "Epoch 498, Loss: 0.051336285658180714, Final Batch Loss: 0.026463139802217484\n",
      "Epoch 499, Loss: 0.03977278294041753, Final Batch Loss: 0.0075352853164076805\n",
      "Epoch 500, Loss: 0.02631289605051279, Final Batch Loss: 0.0045884745195508\n",
      "Epoch 501, Loss: 0.04969810810871422, Final Batch Loss: 0.024693557992577553\n",
      "Epoch 502, Loss: 0.03625935909803957, Final Batch Loss: 0.0011479387758299708\n",
      "Epoch 503, Loss: 0.024292994174174964, Final Batch Loss: 0.0017770084086805582\n",
      "Epoch 504, Loss: 0.02875510649755597, Final Batch Loss: 0.002424787264317274\n",
      "Epoch 505, Loss: 0.024243591935373843, Final Batch Loss: 0.0012260585790500045\n",
      "Epoch 506, Loss: 0.03105444833636284, Final Batch Loss: 0.002908038906753063\n",
      "Epoch 507, Loss: 0.026006109779700637, Final Batch Loss: 0.001486846711486578\n",
      "Epoch 508, Loss: 0.026000457350164652, Final Batch Loss: 0.0037044589407742023\n",
      "Epoch 509, Loss: 0.028247494134120643, Final Batch Loss: 0.004361170809715986\n",
      "Epoch 510, Loss: 0.018553634523414075, Final Batch Loss: 0.003375012893229723\n",
      "Epoch 511, Loss: 0.03747866576304659, Final Batch Loss: 0.01765579544007778\n",
      "Epoch 512, Loss: 0.04015414114110172, Final Batch Loss: 0.013244695961475372\n",
      "Epoch 513, Loss: 0.03863066993653774, Final Batch Loss: 0.013403062708675861\n",
      "Epoch 514, Loss: 0.03977190109435469, Final Batch Loss: 0.010578595101833344\n",
      "Epoch 515, Loss: 0.06318627926521003, Final Batch Loss: 0.008597766980528831\n",
      "Epoch 516, Loss: 0.031242314842529595, Final Batch Loss: 0.001447725691832602\n",
      "Epoch 517, Loss: 0.04124712711200118, Final Batch Loss: 0.0057603903114795685\n",
      "Epoch 518, Loss: 0.030191313941031694, Final Batch Loss: 0.011678500100970268\n",
      "Epoch 519, Loss: 0.03491193591617048, Final Batch Loss: 0.002044851193204522\n",
      "Epoch 520, Loss: 0.06403927272185683, Final Batch Loss: 0.03415878117084503\n",
      "Epoch 521, Loss: 0.04241762845776975, Final Batch Loss: 0.021045682951807976\n",
      "Epoch 522, Loss: 0.03507476206868887, Final Batch Loss: 0.0020051798783242702\n",
      "Epoch 523, Loss: 0.04395462875254452, Final Batch Loss: 0.004145896527916193\n",
      "Epoch 524, Loss: 0.03195120906457305, Final Batch Loss: 0.0056739808060228825\n",
      "Epoch 525, Loss: 0.02887518797069788, Final Batch Loss: 0.0048331646248698235\n",
      "Epoch 526, Loss: 0.06405123765580356, Final Batch Loss: 0.0039869872853159904\n",
      "Epoch 527, Loss: 0.03105288278311491, Final Batch Loss: 0.0024064548779278994\n",
      "Epoch 528, Loss: 0.0645299213938415, Final Batch Loss: 0.024537907913327217\n",
      "Epoch 529, Loss: 0.03715712937992066, Final Batch Loss: 0.0008918627863749862\n",
      "Epoch 530, Loss: 0.026551763992756605, Final Batch Loss: 0.004976029507815838\n",
      "Epoch 531, Loss: 0.046826262725517154, Final Batch Loss: 0.024740533903241158\n",
      "Epoch 532, Loss: 0.03451614920049906, Final Batch Loss: 0.0032434151507914066\n",
      "Epoch 533, Loss: 0.05282944440841675, Final Batch Loss: 0.029712574556469917\n",
      "Epoch 534, Loss: 0.03364456782583147, Final Batch Loss: 0.0014450285816565156\n",
      "Epoch 535, Loss: 0.027323595946654677, Final Batch Loss: 0.001452251453883946\n",
      "Epoch 536, Loss: 0.03568702912889421, Final Batch Loss: 0.0034195270854979753\n",
      "Epoch 537, Loss: 0.027314663282595575, Final Batch Loss: 0.0015717785572633147\n",
      "Epoch 538, Loss: 0.05512090597767383, Final Batch Loss: 0.001963328570127487\n",
      "Epoch 539, Loss: 0.03979757346678525, Final Batch Loss: 0.0006976128788664937\n",
      "Epoch 540, Loss: 0.03233921597711742, Final Batch Loss: 0.0032825488597154617\n",
      "Epoch 541, Loss: 0.028450301731936634, Final Batch Loss: 0.001507803681306541\n",
      "Epoch 542, Loss: 0.039756816579028964, Final Batch Loss: 0.025625014677643776\n",
      "Epoch 543, Loss: 0.036449176259338856, Final Batch Loss: 0.011076537892222404\n",
      "Epoch 544, Loss: 0.03970620222389698, Final Batch Loss: 0.0027096238918602467\n",
      "Epoch 545, Loss: 0.032325720647349954, Final Batch Loss: 0.0006031657103449106\n",
      "Epoch 546, Loss: 0.0263114997651428, Final Batch Loss: 0.002180723939090967\n",
      "Epoch 547, Loss: 0.03843869850970805, Final Batch Loss: 0.002917628502473235\n",
      "Epoch 548, Loss: 0.032941431971266866, Final Batch Loss: 0.018934382125735283\n",
      "Epoch 549, Loss: 0.029778913827612996, Final Batch Loss: 0.006995629519224167\n",
      "Epoch 550, Loss: 0.04510448774090037, Final Batch Loss: 0.0008377220365218818\n",
      "Epoch 551, Loss: 0.032354353461414576, Final Batch Loss: 0.006199214607477188\n",
      "Epoch 552, Loss: 0.02616283588577062, Final Batch Loss: 0.0011941614793613553\n",
      "Epoch 553, Loss: 0.029372927849180996, Final Batch Loss: 0.016593173146247864\n",
      "Epoch 554, Loss: 0.028512196033261716, Final Batch Loss: 0.0008568739285692573\n",
      "Epoch 555, Loss: 0.04624961223453283, Final Batch Loss: 0.0026003660168498755\n",
      "Epoch 556, Loss: 0.0514198507880792, Final Batch Loss: 0.0009975462453439832\n",
      "Epoch 557, Loss: 0.04383622435852885, Final Batch Loss: 0.0029943541157990694\n",
      "Epoch 558, Loss: 0.03738038684241474, Final Batch Loss: 0.00692547345533967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559, Loss: 0.03174817131366581, Final Batch Loss: 0.0015445820754393935\n",
      "Epoch 560, Loss: 0.03162698773667216, Final Batch Loss: 0.004394651856273413\n",
      "Epoch 561, Loss: 0.0221902976045385, Final Batch Loss: 0.001879745745100081\n",
      "Epoch 562, Loss: 0.02759353385772556, Final Batch Loss: 0.0033775069750845432\n",
      "Epoch 563, Loss: 0.034180907532572746, Final Batch Loss: 0.0064203497022390366\n",
      "Epoch 564, Loss: 0.03413330623880029, Final Batch Loss: 0.0022283641155809164\n",
      "Epoch 565, Loss: 0.02682131784968078, Final Batch Loss: 0.006496871821582317\n",
      "Epoch 566, Loss: 0.016134095028974116, Final Batch Loss: 0.0017326090019196272\n",
      "Epoch 567, Loss: 0.03587320470251143, Final Batch Loss: 0.0007676733657717705\n",
      "Epoch 568, Loss: 0.04690467659384012, Final Batch Loss: 0.004616227000951767\n",
      "Epoch 569, Loss: 0.034406164078973234, Final Batch Loss: 0.006007382180541754\n",
      "Epoch 570, Loss: 0.05769374524243176, Final Batch Loss: 0.026316387578845024\n",
      "Epoch 571, Loss: 0.04304579447489232, Final Batch Loss: 0.02010945789515972\n",
      "Epoch 572, Loss: 0.03107639728114009, Final Batch Loss: 0.00413329154253006\n",
      "Epoch 573, Loss: 0.023707531159743667, Final Batch Loss: 0.013396278955042362\n",
      "Epoch 574, Loss: 0.03094206447713077, Final Batch Loss: 0.003361298469826579\n",
      "Epoch 575, Loss: 0.027500028256326914, Final Batch Loss: 0.007045803125947714\n",
      "Epoch 576, Loss: 0.032252487260848284, Final Batch Loss: 0.01499693188816309\n",
      "Epoch 577, Loss: 0.04097059555351734, Final Batch Loss: 0.003556897398084402\n",
      "Epoch 578, Loss: 0.022095305612310767, Final Batch Loss: 0.00444285711273551\n",
      "Epoch 579, Loss: 0.023959623416885734, Final Batch Loss: 0.0035677209962159395\n",
      "Epoch 580, Loss: 0.041790681425482035, Final Batch Loss: 0.003348971251398325\n",
      "Epoch 581, Loss: 0.026598821859806776, Final Batch Loss: 0.0037328023463487625\n",
      "Epoch 582, Loss: 0.051781050744466484, Final Batch Loss: 0.0007545574335381389\n",
      "Epoch 583, Loss: 0.022661682683974504, Final Batch Loss: 0.0020744982175529003\n",
      "Epoch 584, Loss: 0.028152495389804244, Final Batch Loss: 0.012698905542492867\n",
      "Epoch 585, Loss: 0.025914364494383335, Final Batch Loss: 0.0028499183245003223\n",
      "Epoch 586, Loss: 0.010827269405126572, Final Batch Loss: 0.002866219263523817\n",
      "Epoch 587, Loss: 0.04151993338018656, Final Batch Loss: 0.033023178577423096\n",
      "Epoch 588, Loss: 0.03710169531404972, Final Batch Loss: 0.003938684705644846\n",
      "Epoch 589, Loss: 0.018828276777639985, Final Batch Loss: 0.005716218613088131\n",
      "Epoch 590, Loss: 0.05712224019225687, Final Batch Loss: 0.023514654487371445\n",
      "Epoch 591, Loss: 0.020248612971045077, Final Batch Loss: 0.009885539300739765\n",
      "Epoch 592, Loss: 0.0186422704719007, Final Batch Loss: 0.0026357388123869896\n",
      "Epoch 593, Loss: 0.019579795887693763, Final Batch Loss: 0.005384182557463646\n",
      "Epoch 594, Loss: 0.02647488529328257, Final Batch Loss: 0.0012087068753316998\n",
      "Epoch 595, Loss: 0.02222553000319749, Final Batch Loss: 0.0013303211890161037\n",
      "Epoch 596, Loss: 0.01871500350534916, Final Batch Loss: 0.0027804970741271973\n",
      "Epoch 597, Loss: 0.011874368647113442, Final Batch Loss: 0.002318205777555704\n",
      "Epoch 598, Loss: 0.025892215489875525, Final Batch Loss: 0.007086571305990219\n",
      "Epoch 599, Loss: 0.02206137008033693, Final Batch Loss: 0.001237130956724286\n",
      "Epoch 600, Loss: 0.04251242143800482, Final Batch Loss: 0.0007828573579899967\n",
      "Epoch 601, Loss: 0.018055000517051667, Final Batch Loss: 0.0009210295393131673\n",
      "Epoch 602, Loss: 0.0104966857470572, Final Batch Loss: 0.002312522614374757\n",
      "Epoch 603, Loss: 0.019969316897913814, Final Batch Loss: 0.00713680824264884\n",
      "Epoch 604, Loss: 0.01912408380303532, Final Batch Loss: 0.006789897568523884\n",
      "Epoch 605, Loss: 0.0163442709017545, Final Batch Loss: 0.005074616055935621\n",
      "Epoch 606, Loss: 0.016611421131528914, Final Batch Loss: 0.0011947577586397529\n",
      "Epoch 607, Loss: 0.016436111414805055, Final Batch Loss: 0.007966389879584312\n",
      "Epoch 608, Loss: 0.00963535055052489, Final Batch Loss: 0.0015241518849506974\n",
      "Epoch 609, Loss: 0.05418695125263184, Final Batch Loss: 0.012943805195391178\n",
      "Epoch 610, Loss: 0.02033781976206228, Final Batch Loss: 0.002411938039585948\n",
      "Epoch 611, Loss: 0.03401469485834241, Final Batch Loss: 0.017142362892627716\n",
      "Epoch 612, Loss: 0.00997779075987637, Final Batch Loss: 0.0009414817322976887\n",
      "Epoch 613, Loss: 0.01973149733385071, Final Batch Loss: 0.005414850078523159\n",
      "Epoch 614, Loss: 0.020265890285372734, Final Batch Loss: 0.0012336458312347531\n",
      "Epoch 615, Loss: 0.030355835740920156, Final Batch Loss: 0.00031495996518060565\n",
      "Epoch 616, Loss: 0.012865324621088803, Final Batch Loss: 0.005702100694179535\n",
      "Epoch 617, Loss: 0.03614825499244034, Final Batch Loss: 0.026962747797369957\n",
      "Epoch 618, Loss: 0.012346130446530879, Final Batch Loss: 0.0019304524175822735\n",
      "Epoch 619, Loss: 0.033607729244977236, Final Batch Loss: 0.015843702480196953\n",
      "Epoch 620, Loss: 0.025566560099832714, Final Batch Loss: 0.002171492436900735\n",
      "Epoch 621, Loss: 0.02079905173741281, Final Batch Loss: 0.006804403383284807\n",
      "Epoch 622, Loss: 0.044748765183612704, Final Batch Loss: 0.002358256606385112\n",
      "Epoch 623, Loss: 0.013302146689966321, Final Batch Loss: 0.0016968456329777837\n",
      "Epoch 624, Loss: 0.019647773588076234, Final Batch Loss: 0.002038052072748542\n",
      "Epoch 625, Loss: 0.04378925426863134, Final Batch Loss: 0.0011375859612599015\n",
      "Epoch 626, Loss: 0.014367977622896433, Final Batch Loss: 0.0023236116394400597\n",
      "Epoch 627, Loss: 0.02721361187286675, Final Batch Loss: 0.004304020199924707\n",
      "Epoch 628, Loss: 0.013246779795736074, Final Batch Loss: 0.003429321339353919\n",
      "Epoch 629, Loss: 0.041569409309886396, Final Batch Loss: 0.033176030963659286\n",
      "Epoch 630, Loss: 0.017653275397606194, Final Batch Loss: 0.0010149716399610043\n",
      "Epoch 631, Loss: 0.015027322573587298, Final Batch Loss: 0.009785095229744911\n",
      "Epoch 632, Loss: 0.017032056814059615, Final Batch Loss: 0.003000737866386771\n",
      "Epoch 633, Loss: 0.01532014791155234, Final Batch Loss: 0.002899216953665018\n",
      "Epoch 634, Loss: 0.02715043700300157, Final Batch Loss: 0.002670340007171035\n",
      "Epoch 635, Loss: 0.01933027250925079, Final Batch Loss: 0.0025917261373251677\n",
      "Epoch 636, Loss: 0.015461096889339387, Final Batch Loss: 0.0025375881232321262\n",
      "Epoch 637, Loss: 0.011520610307343304, Final Batch Loss: 0.0017979051917791367\n",
      "Epoch 638, Loss: 0.015644797356799245, Final Batch Loss: 0.001002781791612506\n",
      "Epoch 639, Loss: 0.017385850427672267, Final Batch Loss: 0.005001306999474764\n",
      "Epoch 640, Loss: 0.03620352526195347, Final Batch Loss: 0.031029658392071724\n",
      "Epoch 641, Loss: 0.019474396394798532, Final Batch Loss: 0.0002592160308267921\n",
      "Epoch 642, Loss: 0.008265429176390171, Final Batch Loss: 0.0007305201143026352\n",
      "Epoch 643, Loss: 0.005149410804733634, Final Batch Loss: 0.0023876624181866646\n",
      "Epoch 644, Loss: 0.006690788664855063, Final Batch Loss: 0.0019947101827710867\n",
      "Epoch 645, Loss: 0.012068011448718607, Final Batch Loss: 0.003575937356799841\n",
      "Epoch 646, Loss: 0.02170547062996775, Final Batch Loss: 0.004337262362241745\n",
      "Epoch 647, Loss: 0.010042378038633615, Final Batch Loss: 0.0009096656576730311\n",
      "Epoch 648, Loss: 0.0081714988918975, Final Batch Loss: 0.0014784211525693536\n",
      "Epoch 649, Loss: 0.013810015982016921, Final Batch Loss: 0.0043768566101789474\n",
      "Epoch 650, Loss: 0.019692579633556306, Final Batch Loss: 0.0072838254272937775\n",
      "Epoch 651, Loss: 0.03635120182298124, Final Batch Loss: 0.024551434442400932\n",
      "Epoch 652, Loss: 0.025392839044798166, Final Batch Loss: 0.0012254116591066122\n",
      "Epoch 653, Loss: 0.04936926136724651, Final Batch Loss: 0.0031184544786810875\n",
      "Epoch 654, Loss: 0.020480074628721923, Final Batch Loss: 0.0003742456319741905\n",
      "Epoch 655, Loss: 0.02072293177479878, Final Batch Loss: 0.01577475108206272\n",
      "Epoch 656, Loss: 0.01970449648797512, Final Batch Loss: 0.0011433064937591553\n",
      "Epoch 657, Loss: 0.01007865194696933, Final Batch Loss: 0.003790753660723567\n",
      "Epoch 658, Loss: 0.017797629116103053, Final Batch Loss: 0.0023013479076325893\n",
      "Epoch 659, Loss: 0.03498478187248111, Final Batch Loss: 0.0018983413465321064\n",
      "Epoch 660, Loss: 0.0165803381241858, Final Batch Loss: 0.0008664127672091126\n",
      "Epoch 661, Loss: 0.006905707879923284, Final Batch Loss: 0.0008298424072563648\n",
      "Epoch 662, Loss: 0.013455255655571818, Final Batch Loss: 0.008792025037109852\n",
      "Epoch 663, Loss: 0.010555926361121237, Final Batch Loss: 0.004875453654676676\n",
      "Epoch 664, Loss: 0.015255383041221648, Final Batch Loss: 0.0005988461780361831\n",
      "Epoch 665, Loss: 0.005888811079785228, Final Batch Loss: 0.0004660837003029883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666, Loss: 0.007201841159258038, Final Batch Loss: 0.0009538804297335446\n",
      "Epoch 667, Loss: 0.010320438828784972, Final Batch Loss: 0.000493622908834368\n",
      "Epoch 668, Loss: 0.007617057533934712, Final Batch Loss: 0.003441459499299526\n",
      "Epoch 669, Loss: 0.009594353701686487, Final Batch Loss: 0.0004706070467364043\n",
      "Epoch 670, Loss: 0.020178056962322444, Final Batch Loss: 0.0007525098626501858\n",
      "Epoch 671, Loss: 0.025023442460224032, Final Batch Loss: 0.014014957472682\n",
      "Epoch 672, Loss: 0.05231286003254354, Final Batch Loss: 0.018697485327720642\n",
      "Epoch 673, Loss: 0.010012160695623606, Final Batch Loss: 0.00022149522555992007\n",
      "Epoch 674, Loss: 0.011556918499991298, Final Batch Loss: 0.004837730899453163\n",
      "Epoch 675, Loss: 0.01371855498291552, Final Batch Loss: 0.0009733004262670875\n",
      "Epoch 676, Loss: 0.019697608629940078, Final Batch Loss: 0.000239738350501284\n",
      "Epoch 677, Loss: 0.008377993362955749, Final Batch Loss: 0.001250579603947699\n",
      "Epoch 678, Loss: 0.017768524819985032, Final Batch Loss: 0.0009980174945667386\n",
      "Epoch 679, Loss: 0.014703069362440147, Final Batch Loss: 0.0004831468395423144\n",
      "Epoch 680, Loss: 0.014635842526331544, Final Batch Loss: 0.0007361010066233575\n",
      "Epoch 681, Loss: 0.030510071956086904, Final Batch Loss: 0.0008190235239453614\n",
      "Epoch 682, Loss: 0.019961989572038874, Final Batch Loss: 0.0003131900157313794\n",
      "Epoch 683, Loss: 0.012080496409907937, Final Batch Loss: 0.0006597734754905105\n",
      "Epoch 684, Loss: 0.013675729627721012, Final Batch Loss: 0.0038096709176898003\n",
      "Epoch 685, Loss: 0.007054375484585762, Final Batch Loss: 0.001302579534240067\n",
      "Epoch 686, Loss: 0.008882123453076929, Final Batch Loss: 0.0035879837814718485\n",
      "Epoch 687, Loss: 0.005370145110646263, Final Batch Loss: 0.0008498133393004537\n",
      "Epoch 688, Loss: 0.003745730733498931, Final Batch Loss: 0.00029571144841611385\n",
      "Epoch 689, Loss: 0.07479586219415069, Final Batch Loss: 0.06071668118238449\n",
      "Epoch 690, Loss: 0.011256018071435392, Final Batch Loss: 0.008480039425194263\n",
      "Epoch 691, Loss: 0.008521363692125306, Final Batch Loss: 0.0003399300912860781\n",
      "Epoch 692, Loss: 0.020129108568653464, Final Batch Loss: 0.0004593443009071052\n",
      "Epoch 693, Loss: 0.02708907041233033, Final Batch Loss: 0.0002660430036485195\n",
      "Epoch 694, Loss: 0.014460484264418483, Final Batch Loss: 0.005992811173200607\n",
      "Epoch 695, Loss: 0.016227044980041683, Final Batch Loss: 0.0009488280629739165\n",
      "Epoch 696, Loss: 0.007177816238254309, Final Batch Loss: 0.0009129147510975599\n",
      "Epoch 697, Loss: 0.01680729165673256, Final Batch Loss: 0.0014909915626049042\n",
      "Epoch 698, Loss: 0.03077134641353041, Final Batch Loss: 0.01392905879765749\n",
      "Epoch 699, Loss: 0.007291883302968927, Final Batch Loss: 0.003066825680434704\n",
      "Epoch 700, Loss: 0.012129951675888151, Final Batch Loss: 0.0005147702759131789\n",
      "Epoch 701, Loss: 0.026306674059014767, Final Batch Loss: 0.0009217433980666101\n",
      "Epoch 702, Loss: 0.007872606336604804, Final Batch Loss: 0.0005114905070513487\n",
      "Epoch 703, Loss: 0.007748194795567542, Final Batch Loss: 0.0006209275452420115\n",
      "Epoch 704, Loss: 0.008613303769379854, Final Batch Loss: 0.0005416917847469449\n",
      "Epoch 705, Loss: 0.014330647565657273, Final Batch Loss: 0.0003042782482225448\n",
      "Epoch 706, Loss: 0.005458353611174971, Final Batch Loss: 0.0007208407623693347\n",
      "Epoch 707, Loss: 0.024135782034136355, Final Batch Loss: 0.0005546208703890443\n",
      "Epoch 708, Loss: 0.0051979138515889645, Final Batch Loss: 0.0015389787731692195\n",
      "Epoch 709, Loss: 0.004734640941023827, Final Batch Loss: 0.0008789635612629354\n",
      "Epoch 710, Loss: 0.009626077662687749, Final Batch Loss: 0.0006346923764795065\n",
      "Epoch 711, Loss: 0.010608449170831591, Final Batch Loss: 0.005773576442152262\n",
      "Epoch 712, Loss: 0.018119980581104755, Final Batch Loss: 0.0005291465204209089\n",
      "Epoch 713, Loss: 0.008717426506336778, Final Batch Loss: 0.000425070698838681\n",
      "Epoch 714, Loss: 0.0034046343062072992, Final Batch Loss: 0.0003096318687312305\n",
      "Epoch 715, Loss: 0.005215429526288062, Final Batch Loss: 0.0015067453496158123\n",
      "Epoch 716, Loss: 0.015215698163956404, Final Batch Loss: 0.0024134411942213774\n",
      "Epoch 717, Loss: 0.014842382282949984, Final Batch Loss: 0.003354001324623823\n",
      "Epoch 718, Loss: 0.02060024515958503, Final Batch Loss: 0.0006506667705252767\n",
      "Epoch 719, Loss: 0.018443915789248422, Final Batch Loss: 0.012655286118388176\n",
      "Epoch 720, Loss: 0.004650288668926805, Final Batch Loss: 0.003147510578855872\n",
      "Epoch 721, Loss: 0.013776471838355064, Final Batch Loss: 0.0005009423475712538\n",
      "Epoch 722, Loss: 0.01110898080514744, Final Batch Loss: 0.001445372006855905\n",
      "Epoch 723, Loss: 0.008257556241005659, Final Batch Loss: 0.0007420612964779139\n",
      "Epoch 724, Loss: 0.02042503433767706, Final Batch Loss: 0.0026535808574408293\n",
      "Epoch 725, Loss: 0.007643489574547857, Final Batch Loss: 0.002629803027957678\n",
      "Epoch 726, Loss: 0.01572680368553847, Final Batch Loss: 0.006383078638464212\n",
      "Epoch 727, Loss: 0.0044925705587957054, Final Batch Loss: 0.0016509640263393521\n",
      "Epoch 728, Loss: 0.01002668560249731, Final Batch Loss: 0.000833712110761553\n",
      "Epoch 729, Loss: 0.004678443481680006, Final Batch Loss: 0.000914710049983114\n",
      "Epoch 730, Loss: 0.010180410114116967, Final Batch Loss: 0.006166896317154169\n",
      "Epoch 731, Loss: 0.014707714639371261, Final Batch Loss: 0.0011850682785734534\n",
      "Epoch 732, Loss: 0.004040130181238055, Final Batch Loss: 0.0006392872310243547\n",
      "Epoch 733, Loss: 0.034476763554266654, Final Batch Loss: 0.02192811854183674\n",
      "Epoch 734, Loss: 0.036517069092951715, Final Batch Loss: 0.001399100641719997\n",
      "Epoch 735, Loss: 0.009236755926394835, Final Batch Loss: 0.0013842704938724637\n",
      "Epoch 736, Loss: 0.010185281629674137, Final Batch Loss: 0.0010842089541256428\n",
      "Epoch 737, Loss: 0.004336081532528624, Final Batch Loss: 0.00020198480342514813\n",
      "Epoch 738, Loss: 0.009872053080471233, Final Batch Loss: 8.328809053637087e-05\n",
      "Epoch 739, Loss: 0.023887898219982162, Final Batch Loss: 0.002290546428412199\n",
      "Epoch 740, Loss: 0.003585588696296327, Final Batch Loss: 0.0012242270167917013\n",
      "Epoch 741, Loss: 0.02540737263916526, Final Batch Loss: 0.019354304298758507\n",
      "Epoch 742, Loss: 0.003629270097007975, Final Batch Loss: 0.0003813891962636262\n",
      "Epoch 743, Loss: 0.01039817405398935, Final Batch Loss: 0.0010516532929614186\n",
      "Epoch 744, Loss: 0.022081332659581676, Final Batch Loss: 0.0003769415488932282\n",
      "Epoch 745, Loss: 0.004975462972652167, Final Batch Loss: 0.0004787609213963151\n",
      "Epoch 746, Loss: 0.012392292264848948, Final Batch Loss: 0.000834509904962033\n",
      "Epoch 747, Loss: 0.0026516771758906543, Final Batch Loss: 0.0003637644404079765\n",
      "Epoch 748, Loss: 0.01175419840728864, Final Batch Loss: 0.005414001643657684\n",
      "Epoch 749, Loss: 0.008587001939304173, Final Batch Loss: 0.002336566336452961\n",
      "Epoch 750, Loss: 0.00933879887452349, Final Batch Loss: 0.0028446645010262728\n",
      "Epoch 751, Loss: 0.010605554794892669, Final Batch Loss: 0.0012936124112457037\n",
      "Epoch 752, Loss: 0.009585485968273133, Final Batch Loss: 0.0005499436520040035\n",
      "Epoch 753, Loss: 0.01611450099153444, Final Batch Loss: 0.0006683629471808672\n",
      "Epoch 754, Loss: 0.0014671089957118966, Final Batch Loss: 0.0003371449129190296\n",
      "Epoch 755, Loss: 0.01608521188609302, Final Batch Loss: 0.0010445775697007775\n",
      "Epoch 756, Loss: 0.019559020060114563, Final Batch Loss: 0.0011218150611966848\n",
      "Epoch 757, Loss: 0.041212796000763774, Final Batch Loss: 0.00011194375110790133\n",
      "Epoch 758, Loss: 0.00983696017647162, Final Batch Loss: 0.0035022615920752287\n",
      "Epoch 759, Loss: 0.0042726973479148, Final Batch Loss: 0.0019569701980799437\n",
      "Epoch 760, Loss: 0.003331501175125595, Final Batch Loss: 0.00011981085845036432\n",
      "Epoch 761, Loss: 0.013189880701247603, Final Batch Loss: 0.002541588619351387\n",
      "Epoch 762, Loss: 0.017725062622048426, Final Batch Loss: 0.00012169167894171551\n",
      "Epoch 763, Loss: 0.01156149705639109, Final Batch Loss: 0.0005232733092270792\n",
      "Epoch 764, Loss: 0.008019141896511428, Final Batch Loss: 0.00016147263522725552\n",
      "Epoch 765, Loss: 0.005788837908767164, Final Batch Loss: 0.0008116854587569833\n",
      "Epoch 766, Loss: 0.01706386380828917, Final Batch Loss: 0.0005335459718480706\n",
      "Epoch 767, Loss: 0.018004959740210325, Final Batch Loss: 0.0008612180245108902\n",
      "Epoch 768, Loss: 0.009770140110049397, Final Batch Loss: 0.002493747742846608\n",
      "Epoch 769, Loss: 0.013972179032862186, Final Batch Loss: 0.0011068530147895217\n",
      "Epoch 770, Loss: 0.004977788426913321, Final Batch Loss: 0.0007218129467219114\n",
      "Epoch 771, Loss: 0.014071900164708495, Final Batch Loss: 0.002894774777814746\n",
      "Epoch 772, Loss: 0.005120677640661597, Final Batch Loss: 0.0005478914827108383\n",
      "Epoch 773, Loss: 0.026068354287417606, Final Batch Loss: 0.000859203515574336\n",
      "Epoch 774, Loss: 0.0031155100150499493, Final Batch Loss: 0.0002629856753628701\n",
      "Epoch 775, Loss: 0.03440584085183218, Final Batch Loss: 0.027709387242794037\n",
      "Epoch 776, Loss: 0.004447056242497638, Final Batch Loss: 0.00026653773966245353\n",
      "Epoch 777, Loss: 0.03524933391599916, Final Batch Loss: 0.022955380380153656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778, Loss: 0.017646548672928475, Final Batch Loss: 0.0001669745979597792\n",
      "Epoch 779, Loss: 0.0038456106558442116, Final Batch Loss: 0.0005287391250021756\n",
      "Epoch 780, Loss: 0.059756436734460294, Final Batch Loss: 0.035692352801561356\n",
      "Epoch 781, Loss: 0.017625933222007006, Final Batch Loss: 0.005633678287267685\n",
      "Epoch 782, Loss: 0.04102782753761858, Final Batch Loss: 0.007156455423682928\n",
      "Epoch 783, Loss: 0.014007556455908343, Final Batch Loss: 0.0040527936071157455\n",
      "Epoch 784, Loss: 0.01063654274912551, Final Batch Loss: 0.0008400835213251412\n",
      "Epoch 785, Loss: 0.02825681451940909, Final Batch Loss: 0.0007564240368083119\n",
      "Epoch 786, Loss: 0.008581296191550791, Final Batch Loss: 0.002801918424665928\n",
      "Epoch 787, Loss: 0.004954084288328886, Final Batch Loss: 0.0002847003343049437\n",
      "Epoch 788, Loss: 0.019905787165043876, Final Batch Loss: 0.00042872157064266503\n",
      "Epoch 789, Loss: 0.022173607198055834, Final Batch Loss: 0.0152380196377635\n",
      "Epoch 790, Loss: 0.05774759536143392, Final Batch Loss: 0.04953422024846077\n",
      "Epoch 791, Loss: 0.04087816353421658, Final Batch Loss: 0.03135105222463608\n",
      "Epoch 792, Loss: 0.02304083900526166, Final Batch Loss: 0.0019420936005190015\n",
      "Epoch 793, Loss: 0.008601488021668047, Final Batch Loss: 0.0032375166192650795\n",
      "Epoch 794, Loss: 0.024778486345894635, Final Batch Loss: 0.017940932884812355\n",
      "Epoch 795, Loss: 0.009535503457300365, Final Batch Loss: 0.00219622696749866\n",
      "Epoch 796, Loss: 0.0103137536207214, Final Batch Loss: 0.002985316561535001\n",
      "Epoch 797, Loss: 0.01147013227455318, Final Batch Loss: 0.0008122185245156288\n",
      "Epoch 798, Loss: 0.04730359138920903, Final Batch Loss: 0.005253429524600506\n",
      "Epoch 799, Loss: 0.006917759252246469, Final Batch Loss: 0.0005444053094834089\n",
      "Epoch 800, Loss: 0.010738798882812262, Final Batch Loss: 0.001629886799491942\n",
      "Epoch 801, Loss: 0.02277389564551413, Final Batch Loss: 0.011110545136034489\n",
      "Epoch 802, Loss: 0.007444478338584304, Final Batch Loss: 0.003072927938774228\n",
      "Epoch 803, Loss: 0.025487974169664085, Final Batch Loss: 0.021603934466838837\n",
      "Epoch 804, Loss: 0.004824621806619689, Final Batch Loss: 0.0004159612872172147\n",
      "Epoch 805, Loss: 0.004471420717891306, Final Batch Loss: 0.0007837866432964802\n",
      "Epoch 806, Loss: 0.0377755148219876, Final Batch Loss: 0.03537840023636818\n",
      "Epoch 807, Loss: 0.014052591897780076, Final Batch Loss: 0.00040449496009387076\n",
      "Epoch 808, Loss: 0.0073603467317298055, Final Batch Loss: 0.0014149388298392296\n",
      "Epoch 809, Loss: 0.0053222093265503645, Final Batch Loss: 0.0007998901419341564\n",
      "Epoch 810, Loss: 0.01784078445052728, Final Batch Loss: 0.0001261274446733296\n",
      "Epoch 811, Loss: 0.035490081703756005, Final Batch Loss: 0.0028213656041771173\n",
      "Epoch 812, Loss: 0.00860726519022137, Final Batch Loss: 0.005166519898921251\n",
      "Epoch 813, Loss: 0.009910076711094007, Final Batch Loss: 0.00034633930772542953\n",
      "Epoch 814, Loss: 0.020183685468509793, Final Batch Loss: 0.017392491921782494\n",
      "Epoch 815, Loss: 0.011365180369466543, Final Batch Loss: 0.0004929748829454184\n",
      "Epoch 816, Loss: 0.019428907136898488, Final Batch Loss: 0.0006514884880743921\n",
      "Epoch 817, Loss: 0.018776337266899645, Final Batch Loss: 0.007936965674161911\n",
      "Epoch 818, Loss: 0.006283755763433874, Final Batch Loss: 0.0007688516634516418\n",
      "Epoch 819, Loss: 0.003908627317287028, Final Batch Loss: 0.0016077733598649502\n",
      "Epoch 820, Loss: 0.03143935860134661, Final Batch Loss: 0.0057188174687325954\n",
      "Epoch 821, Loss: 0.019632150360848755, Final Batch Loss: 0.0010299264686182141\n",
      "Epoch 822, Loss: 0.008742877340409905, Final Batch Loss: 0.00045564776519313455\n",
      "Epoch 823, Loss: 0.00814542721491307, Final Batch Loss: 0.0008025054121389985\n",
      "Epoch 824, Loss: 0.0032688895516912453, Final Batch Loss: 8.084493310889229e-05\n",
      "Epoch 825, Loss: 0.005680344271240756, Final Batch Loss: 0.002059894846752286\n",
      "Epoch 826, Loss: 0.005382036630180664, Final Batch Loss: 0.00014535665104631335\n",
      "Epoch 827, Loss: 0.007361309282714501, Final Batch Loss: 0.003254322335124016\n",
      "Epoch 828, Loss: 0.010591589380055666, Final Batch Loss: 0.0015148246893659234\n",
      "Epoch 829, Loss: 0.00409124769794289, Final Batch Loss: 0.00015027546032797545\n",
      "Epoch 830, Loss: 0.005442145455162972, Final Batch Loss: 0.0008933111093938351\n",
      "Epoch 831, Loss: 0.016522496327525005, Final Batch Loss: 0.007930280640721321\n",
      "Epoch 832, Loss: 0.004179389216005802, Final Batch Loss: 0.0004792292311321944\n",
      "Epoch 833, Loss: 0.03389005064673256, Final Batch Loss: 0.0013347489293664694\n",
      "Epoch 834, Loss: 0.01621120795607567, Final Batch Loss: 0.004173704888671637\n",
      "Epoch 835, Loss: 0.06526990834390745, Final Batch Loss: 0.016181329265236855\n",
      "Epoch 836, Loss: 0.024249366717413068, Final Batch Loss: 0.0034987579565495253\n",
      "Epoch 837, Loss: 0.02903373318258673, Final Batch Loss: 0.002114448929205537\n",
      "Epoch 838, Loss: 0.02281727339141071, Final Batch Loss: 0.008134647272527218\n",
      "Epoch 839, Loss: 0.04455393675016239, Final Batch Loss: 0.0009384469594806433\n",
      "Epoch 840, Loss: 0.005314347974490374, Final Batch Loss: 0.0019228167366236448\n",
      "Epoch 841, Loss: 0.017240512010175735, Final Batch Loss: 0.0007716763648204505\n",
      "Epoch 842, Loss: 0.013796879153233021, Final Batch Loss: 0.001810551853850484\n",
      "Epoch 843, Loss: 0.017620033031562343, Final Batch Loss: 0.0007394426502287388\n",
      "Epoch 844, Loss: 0.008323325600940734, Final Batch Loss: 0.000647238630335778\n",
      "Epoch 845, Loss: 0.00884529176983051, Final Batch Loss: 0.000355534692062065\n",
      "Epoch 846, Loss: 0.005144384020240977, Final Batch Loss: 0.00039956383989192545\n",
      "Epoch 847, Loss: 0.017096554976888, Final Batch Loss: 0.000617475132457912\n",
      "Epoch 848, Loss: 0.0037758512189611793, Final Batch Loss: 0.0005159575957804918\n",
      "Epoch 849, Loss: 0.005708533775759861, Final Batch Loss: 0.0002748577680904418\n",
      "Epoch 850, Loss: 0.0037240081874188036, Final Batch Loss: 0.0001736691629048437\n",
      "Epoch 851, Loss: 0.0043238080106675625, Final Batch Loss: 0.0011594898533076048\n",
      "Epoch 852, Loss: 0.010273979456542293, Final Batch Loss: 4.822045229957439e-05\n",
      "Epoch 853, Loss: 0.005989111145026982, Final Batch Loss: 0.0011025051353499293\n",
      "Epoch 854, Loss: 0.002382724196650088, Final Batch Loss: 0.000932344060856849\n",
      "Epoch 855, Loss: 0.011497645173221827, Final Batch Loss: 0.00033497472759336233\n",
      "Epoch 856, Loss: 0.04594491410534829, Final Batch Loss: 0.00045804015826433897\n",
      "Epoch 857, Loss: 0.0119054174865596, Final Batch Loss: 0.00048087938921526074\n",
      "Epoch 858, Loss: 0.007772195531288162, Final Batch Loss: 0.00041258931742049754\n",
      "Epoch 859, Loss: 0.008831212529912591, Final Batch Loss: 0.0021473730448633432\n",
      "Epoch 860, Loss: 0.004727103325421922, Final Batch Loss: 0.0001928908604895696\n",
      "Epoch 861, Loss: 0.029277545982040465, Final Batch Loss: 0.0015418879920616746\n",
      "Epoch 862, Loss: 0.01092567975865677, Final Batch Loss: 0.0002351021976210177\n",
      "Epoch 863, Loss: 0.014531393346260302, Final Batch Loss: 0.0031057691667228937\n",
      "Epoch 864, Loss: 0.01656980998814106, Final Batch Loss: 0.001007737242616713\n",
      "Epoch 865, Loss: 0.009279205347411335, Final Batch Loss: 0.00406356155872345\n",
      "Epoch 866, Loss: 0.020312344262492843, Final Batch Loss: 0.00021812169870827347\n",
      "Epoch 867, Loss: 0.008386741814319976, Final Batch Loss: 0.0001675547828199342\n",
      "Epoch 868, Loss: 0.01851462060585618, Final Batch Loss: 0.0011540224077180028\n",
      "Epoch 869, Loss: 0.0065183385158888996, Final Batch Loss: 0.0008165621547959745\n",
      "Epoch 870, Loss: 0.005011830595321953, Final Batch Loss: 0.000726868980564177\n",
      "Epoch 871, Loss: 0.024279738368932158, Final Batch Loss: 0.018818628042936325\n",
      "Epoch 872, Loss: 0.006882627494633198, Final Batch Loss: 0.0005560287390835583\n",
      "Epoch 873, Loss: 0.009210584801621735, Final Batch Loss: 0.0006561435293406248\n",
      "Epoch 874, Loss: 0.00440364028327167, Final Batch Loss: 6.804446456953883e-05\n",
      "Epoch 875, Loss: 0.010987212852342054, Final Batch Loss: 0.0003660846850834787\n",
      "Epoch 876, Loss: 0.020460719184484333, Final Batch Loss: 0.018932200968265533\n",
      "Epoch 877, Loss: 0.01973486228962429, Final Batch Loss: 0.01577449031174183\n",
      "Epoch 878, Loss: 0.006244883028557524, Final Batch Loss: 0.0003073283878620714\n",
      "Epoch 879, Loss: 0.004408200504258275, Final Batch Loss: 0.0008312850259244442\n",
      "Epoch 880, Loss: 0.026643869816325605, Final Batch Loss: 0.0011911947512999177\n",
      "Epoch 881, Loss: 0.004212045663734898, Final Batch Loss: 0.0016441732877865434\n",
      "Epoch 882, Loss: 0.007013236288912594, Final Batch Loss: 0.004303140100091696\n",
      "Epoch 883, Loss: 0.013906402396969497, Final Batch Loss: 0.00477195717394352\n",
      "Epoch 884, Loss: 0.006458471529185772, Final Batch Loss: 0.001283171703107655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885, Loss: 0.010648755240254104, Final Batch Loss: 0.006854682695120573\n",
      "Epoch 886, Loss: 0.007235139550175518, Final Batch Loss: 0.0007318204152397811\n",
      "Epoch 887, Loss: 0.004186507489066571, Final Batch Loss: 0.001141798566095531\n",
      "Epoch 888, Loss: 0.021385685307905078, Final Batch Loss: 0.015369950793683529\n",
      "Epoch 889, Loss: 0.008957741141784936, Final Batch Loss: 0.0005821976228617132\n",
      "Epoch 890, Loss: 0.005268494365736842, Final Batch Loss: 0.0007066280813887715\n",
      "Epoch 891, Loss: 0.011004830594174564, Final Batch Loss: 0.002135438844561577\n",
      "Epoch 892, Loss: 0.0029473580652847886, Final Batch Loss: 0.0006004255264997482\n",
      "Epoch 893, Loss: 0.008368042297661304, Final Batch Loss: 0.00030188955133780837\n",
      "Epoch 894, Loss: 0.008545803852030076, Final Batch Loss: 0.00015815185906831175\n",
      "Epoch 895, Loss: 0.007366510282736272, Final Batch Loss: 0.0006203989032655954\n",
      "Epoch 896, Loss: 0.03666457056533545, Final Batch Loss: 0.00560101680457592\n",
      "Epoch 897, Loss: 0.007567969267256558, Final Batch Loss: 0.0041055940091609955\n",
      "Epoch 898, Loss: 0.002039496335783042, Final Batch Loss: 0.0001584885612828657\n",
      "Epoch 899, Loss: 0.0022568255153601058, Final Batch Loss: 2.8340677090454847e-05\n",
      "Epoch 900, Loss: 0.004961081227520481, Final Batch Loss: 0.00046294223284348845\n",
      "Epoch 901, Loss: 0.014326236152555794, Final Batch Loss: 0.000794751278590411\n",
      "Epoch 902, Loss: 0.010722077335231006, Final Batch Loss: 0.00147051562089473\n",
      "Epoch 903, Loss: 0.008950922114308923, Final Batch Loss: 0.0005914284847676754\n",
      "Epoch 904, Loss: 0.004388563596876338, Final Batch Loss: 0.000635743432212621\n",
      "Epoch 905, Loss: 0.007250753194966819, Final Batch Loss: 8.297655585920438e-05\n",
      "Epoch 906, Loss: 0.005197167280130088, Final Batch Loss: 0.0008695154101587832\n",
      "Epoch 907, Loss: 0.0021638348989654332, Final Batch Loss: 0.00028792148805223405\n",
      "Epoch 908, Loss: 0.003165630536386743, Final Batch Loss: 0.00022291913046501577\n",
      "Epoch 909, Loss: 0.011118478723801672, Final Batch Loss: 0.006947912275791168\n",
      "Epoch 910, Loss: 0.01908639782050159, Final Batch Loss: 0.002068367088213563\n",
      "Epoch 911, Loss: 0.0027774041882366873, Final Batch Loss: 0.0005120853893458843\n",
      "Epoch 912, Loss: 0.012024465730064549, Final Batch Loss: 0.0019566453993320465\n",
      "Epoch 913, Loss: 0.007966476608999074, Final Batch Loss: 0.0002583756868261844\n",
      "Epoch 914, Loss: 0.006799041701015085, Final Batch Loss: 0.0005152035155333579\n",
      "Epoch 915, Loss: 0.01126996532548219, Final Batch Loss: 0.008670416660606861\n",
      "Epoch 916, Loss: 0.003588824696635129, Final Batch Loss: 5.27906850038562e-05\n",
      "Epoch 917, Loss: 0.002730890642851591, Final Batch Loss: 0.000774573883973062\n",
      "Epoch 918, Loss: 0.005040179588831961, Final Batch Loss: 0.0002365119435125962\n",
      "Epoch 919, Loss: 0.004754329173010774, Final Batch Loss: 0.0012411412317305803\n",
      "Epoch 920, Loss: 0.013985040335683152, Final Batch Loss: 0.00033330442965961993\n",
      "Epoch 921, Loss: 0.003381930902833119, Final Batch Loss: 0.0019037853926420212\n",
      "Epoch 922, Loss: 0.019792222185060382, Final Batch Loss: 7.480906788259745e-05\n",
      "Epoch 923, Loss: 0.08117338686133735, Final Batch Loss: 0.07487917691469193\n",
      "Epoch 924, Loss: 0.0022438157320721075, Final Batch Loss: 0.0001815502910176292\n",
      "Epoch 925, Loss: 0.012259279930731282, Final Batch Loss: 0.0002825480478350073\n",
      "Epoch 926, Loss: 0.013470948688336648, Final Batch Loss: 0.01195191964507103\n",
      "Epoch 927, Loss: 0.001953261256858241, Final Batch Loss: 0.00011442274990258738\n",
      "Epoch 928, Loss: 0.002249371405923739, Final Batch Loss: 0.00011692181578837335\n",
      "Epoch 929, Loss: 0.003975094994530082, Final Batch Loss: 0.0013229220639914274\n",
      "Epoch 930, Loss: 0.002864093257812783, Final Batch Loss: 0.0003942194161936641\n",
      "Epoch 931, Loss: 0.004748209859826602, Final Batch Loss: 0.00020872698223683983\n",
      "Epoch 932, Loss: 0.0042054519726661965, Final Batch Loss: 0.00048054003855213523\n",
      "Epoch 933, Loss: 0.017669896944426, Final Batch Loss: 0.012584567070007324\n",
      "Epoch 934, Loss: 0.006301733636064455, Final Batch Loss: 0.00043726034346036613\n",
      "Epoch 935, Loss: 0.0012500781231210567, Final Batch Loss: 0.00010248299076920375\n",
      "Epoch 936, Loss: 0.003840769117232412, Final Batch Loss: 0.0023564710281789303\n",
      "Epoch 937, Loss: 0.01012844275101088, Final Batch Loss: 0.004512305371463299\n",
      "Epoch 938, Loss: 0.004797848087036982, Final Batch Loss: 0.0004287154006306082\n",
      "Epoch 939, Loss: 0.004752568711410277, Final Batch Loss: 0.0001631175837246701\n",
      "Epoch 940, Loss: 0.003804571519140154, Final Batch Loss: 0.002287834882736206\n",
      "Epoch 941, Loss: 0.0022927739046281204, Final Batch Loss: 0.0008833557949401438\n",
      "Epoch 942, Loss: 0.002719987358432263, Final Batch Loss: 0.0001699348504189402\n",
      "Epoch 943, Loss: 0.0075104252027813345, Final Batch Loss: 0.00032080672099255025\n",
      "Epoch 944, Loss: 0.009337386210972909, Final Batch Loss: 0.004186117090284824\n",
      "Epoch 945, Loss: 0.0026392758009023964, Final Batch Loss: 0.00025879385066218674\n",
      "Epoch 946, Loss: 0.0008821230730973184, Final Batch Loss: 0.00036783036193810403\n",
      "Epoch 947, Loss: 0.0029300309834070504, Final Batch Loss: 0.0005438574589788914\n",
      "Epoch 948, Loss: 0.012094915131456219, Final Batch Loss: 0.00015708328282926232\n",
      "Epoch 949, Loss: 0.002031446958426386, Final Batch Loss: 0.0003820617275778204\n",
      "Epoch 950, Loss: 0.0017676324714557268, Final Batch Loss: 0.0006872935337014496\n",
      "Epoch 951, Loss: 0.007055174763081595, Final Batch Loss: 0.000468921527499333\n",
      "Epoch 952, Loss: 0.0036559810614562593, Final Batch Loss: 4.59490911453031e-05\n",
      "Epoch 953, Loss: 0.0030805355054326355, Final Batch Loss: 0.002026183297857642\n",
      "Epoch 954, Loss: 0.004378139274194837, Final Batch Loss: 0.00016111612785607576\n",
      "Epoch 955, Loss: 0.0143993082238012, Final Batch Loss: 0.009901932440698147\n",
      "Epoch 956, Loss: 0.0028931067427038215, Final Batch Loss: 0.00040752431959845126\n",
      "Epoch 957, Loss: 0.0076789345548604615, Final Batch Loss: 0.0011516900267452002\n",
      "Epoch 958, Loss: 0.020128714240854606, Final Batch Loss: 0.017412599176168442\n",
      "Epoch 959, Loss: 0.011509371921420097, Final Batch Loss: 0.0007651053601875901\n",
      "Epoch 960, Loss: 0.017016134690493345, Final Batch Loss: 0.002619503065943718\n",
      "Epoch 961, Loss: 0.00186672288691625, Final Batch Loss: 0.00030035979580134153\n",
      "Epoch 962, Loss: 0.0028145007527200505, Final Batch Loss: 0.0010540754301473498\n",
      "Epoch 963, Loss: 0.018998987710801885, Final Batch Loss: 0.0006853781524114311\n",
      "Epoch 964, Loss: 0.005187505739741027, Final Batch Loss: 0.0032250466756522655\n",
      "Epoch 965, Loss: 0.05896554165519774, Final Batch Loss: 0.0426042415201664\n",
      "Epoch 966, Loss: 0.009999950823839754, Final Batch Loss: 0.0026164487935602665\n",
      "Epoch 967, Loss: 0.01090212757117115, Final Batch Loss: 0.0068202088586986065\n",
      "Epoch 968, Loss: 0.018184271437348798, Final Batch Loss: 0.014516935683786869\n",
      "Epoch 969, Loss: 0.004262895083229523, Final Batch Loss: 0.0013271996285766363\n",
      "Epoch 970, Loss: 0.008516893780324608, Final Batch Loss: 0.00028988978010602295\n",
      "Epoch 971, Loss: 0.019786846678471193, Final Batch Loss: 0.0010798758594319224\n",
      "Epoch 972, Loss: 0.015008570975624025, Final Batch Loss: 0.005315194372087717\n",
      "Epoch 973, Loss: 0.004946798500895966, Final Batch Loss: 9.756640793057159e-05\n",
      "Epoch 974, Loss: 0.0015684744284953922, Final Batch Loss: 0.0003391763602849096\n",
      "Epoch 975, Loss: 0.004215442037093453, Final Batch Loss: 0.0011114142835140228\n",
      "Epoch 976, Loss: 0.03534395626047626, Final Batch Loss: 0.03165287896990776\n",
      "Epoch 977, Loss: 0.002548484393628314, Final Batch Loss: 0.00032934820046648383\n",
      "Epoch 978, Loss: 0.004973099159542471, Final Batch Loss: 0.001464858534745872\n",
      "Epoch 979, Loss: 0.012636192637728527, Final Batch Loss: 0.006526189856231213\n",
      "Epoch 980, Loss: 0.043668691301718354, Final Batch Loss: 0.023236703127622604\n",
      "Epoch 981, Loss: 0.003833448121440597, Final Batch Loss: 0.0005976566462777555\n",
      "Epoch 982, Loss: 0.024915415327996016, Final Batch Loss: 0.004512638319283724\n",
      "Epoch 983, Loss: 0.007808722511981614, Final Batch Loss: 0.0008900875691324472\n",
      "Epoch 984, Loss: 0.0057534109801054, Final Batch Loss: 0.0031412336975336075\n",
      "Epoch 985, Loss: 0.01507568362285383, Final Batch Loss: 0.00035048488643951714\n",
      "Epoch 986, Loss: 0.004397822282044217, Final Batch Loss: 0.000498645007610321\n",
      "Epoch 987, Loss: 0.005161262568435632, Final Batch Loss: 0.003039273666217923\n",
      "Epoch 988, Loss: 0.008950660936534405, Final Batch Loss: 0.0005777580663561821\n",
      "Epoch 989, Loss: 0.009193760575726628, Final Batch Loss: 0.0006183617515489459\n",
      "Epoch 990, Loss: 0.00291173520963639, Final Batch Loss: 0.00023579562548547983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991, Loss: 0.007386911980574951, Final Batch Loss: 0.00025577988708391786\n",
      "Epoch 992, Loss: 0.025462206605880056, Final Batch Loss: 0.0005404510302469134\n",
      "Epoch 993, Loss: 0.010033570550149307, Final Batch Loss: 0.00013054892770014703\n",
      "Epoch 994, Loss: 0.0040713595517445356, Final Batch Loss: 0.0017936903750523925\n",
      "Epoch 995, Loss: 0.002291476572281681, Final Batch Loss: 0.0007134734187275171\n",
      "Epoch 996, Loss: 0.003686661904794164, Final Batch Loss: 0.0011262946063652635\n",
      "Epoch 997, Loss: 0.005026047554565594, Final Batch Loss: 0.0016841221367940307\n",
      "Epoch 998, Loss: 0.0030270287970779464, Final Batch Loss: 0.00022520909260492772\n",
      "Epoch 999, Loss: 0.003136296189040877, Final Batch Loss: 0.001688940916210413\n",
      "Epoch 1000, Loss: 0.004110147332539782, Final Batch Loss: 0.0002787979319691658\n",
      "Epoch 1001, Loss: 0.007330073683988303, Final Batch Loss: 0.00365455006249249\n",
      "Epoch 1002, Loss: 0.005933089094469324, Final Batch Loss: 0.0032033519819378853\n",
      "Epoch 1003, Loss: 0.0012368113675620407, Final Batch Loss: 0.00013286725152283907\n",
      "Epoch 1004, Loss: 0.014585720105969813, Final Batch Loss: 0.0003178978222422302\n",
      "Epoch 1005, Loss: 0.0038668162014801055, Final Batch Loss: 0.0020968562457710505\n",
      "Epoch 1006, Loss: 0.006723513419274241, Final Batch Loss: 0.00016159162623807788\n",
      "Epoch 1007, Loss: 0.012102974549634382, Final Batch Loss: 9.852179209701717e-05\n",
      "Epoch 1008, Loss: 0.003870759275741875, Final Batch Loss: 0.00014855375047773123\n",
      "Epoch 1009, Loss: 0.007230934163089842, Final Batch Loss: 0.003662193426862359\n",
      "Epoch 1010, Loss: 0.0015035050673759542, Final Batch Loss: 9.015737305162475e-05\n",
      "Epoch 1011, Loss: 0.016663314017932862, Final Batch Loss: 0.0007775907288305461\n",
      "Epoch 1012, Loss: 0.0026366009551566094, Final Batch Loss: 0.001822113641537726\n",
      "Epoch 1013, Loss: 0.0016903547511901706, Final Batch Loss: 0.00025220843963325024\n",
      "Epoch 1014, Loss: 0.00362026272341609, Final Batch Loss: 0.000495797663461417\n",
      "Epoch 1015, Loss: 0.010286907519912347, Final Batch Loss: 0.00830113422125578\n",
      "Epoch 1016, Loss: 0.0021236768443486653, Final Batch Loss: 8.188274659914896e-05\n",
      "Epoch 1017, Loss: 0.0009336412331322208, Final Batch Loss: 0.00012210782733745873\n",
      "Epoch 1018, Loss: 0.004648724454455078, Final Batch Loss: 6.699963705614209e-05\n",
      "Epoch 1019, Loss: 0.0017921902326634154, Final Batch Loss: 0.0003881925076711923\n",
      "Epoch 1020, Loss: 0.0027359021041775122, Final Batch Loss: 0.001455381978303194\n",
      "Epoch 1021, Loss: 0.0044471163128037006, Final Batch Loss: 0.00040437959250994027\n",
      "Epoch 1022, Loss: 0.01334412823052844, Final Batch Loss: 7.417095912387595e-05\n",
      "Epoch 1023, Loss: 0.021227060482488014, Final Batch Loss: 0.0014511824119836092\n",
      "Epoch 1024, Loss: 0.006491904321592301, Final Batch Loss: 0.0003091148391831666\n",
      "Epoch 1025, Loss: 0.001993329824472312, Final Batch Loss: 0.0003966905060224235\n",
      "Epoch 1026, Loss: 0.0030347845604410395, Final Batch Loss: 0.0004765466437675059\n",
      "Epoch 1027, Loss: 0.010355245554819703, Final Batch Loss: 6.826352910138667e-05\n",
      "Epoch 1028, Loss: 0.0016879636095836759, Final Batch Loss: 0.0001790909154806286\n",
      "Epoch 1029, Loss: 0.0028642179968301207, Final Batch Loss: 0.0007882213685661554\n",
      "Epoch 1030, Loss: 0.009777075676538516, Final Batch Loss: 8.443051046924666e-05\n",
      "Epoch 1031, Loss: 0.007204858120530844, Final Batch Loss: 0.0021895302925258875\n",
      "Epoch 1032, Loss: 0.003183078377333004, Final Batch Loss: 0.0015988677041605115\n",
      "Epoch 1033, Loss: 0.0013443200732581317, Final Batch Loss: 0.00016532673907931894\n",
      "Epoch 1034, Loss: 0.007471272605471313, Final Batch Loss: 0.002622901229187846\n",
      "Epoch 1035, Loss: 0.0021858111558685778, Final Batch Loss: 2.7051353754359297e-05\n",
      "Epoch 1036, Loss: 0.003657646448118612, Final Batch Loss: 0.00012086539209121838\n",
      "Epoch 1037, Loss: 0.002662747006979771, Final Batch Loss: 0.00016627974400762469\n",
      "Epoch 1038, Loss: 0.003124089736957103, Final Batch Loss: 0.00031881468021310866\n",
      "Epoch 1039, Loss: 0.0020248078944860026, Final Batch Loss: 0.00013184230192564428\n",
      "Epoch 1040, Loss: 0.012223373632878065, Final Batch Loss: 0.01167451124638319\n",
      "Epoch 1041, Loss: 0.004186146659776568, Final Batch Loss: 0.00017322570784017444\n",
      "Epoch 1042, Loss: 0.012356991675915197, Final Batch Loss: 0.000442797172581777\n",
      "Epoch 1043, Loss: 0.012033335231535602, Final Batch Loss: 0.009201910346746445\n",
      "Epoch 1044, Loss: 0.014292660358478315, Final Batch Loss: 0.0018470182549208403\n",
      "Epoch 1045, Loss: 0.001035802546539344, Final Batch Loss: 5.916495865676552e-05\n",
      "Epoch 1046, Loss: 0.006988289373111911, Final Batch Loss: 0.0011268724920228124\n",
      "Epoch 1047, Loss: 0.0012298012734390795, Final Batch Loss: 4.540722875390202e-05\n",
      "Epoch 1048, Loss: 0.03517861367436126, Final Batch Loss: 0.0010454620933160186\n",
      "Epoch 1049, Loss: 0.0033595082350075245, Final Batch Loss: 0.0009926056955009699\n",
      "Epoch 1050, Loss: 0.03275679552461952, Final Batch Loss: 0.017380502074956894\n",
      "Epoch 1051, Loss: 0.0015261101725627668, Final Batch Loss: 2.1706851839553565e-05\n",
      "Epoch 1052, Loss: 0.010627301671775058, Final Batch Loss: 0.001623737858608365\n",
      "Epoch 1053, Loss: 0.020455160454730503, Final Batch Loss: 0.0001567588042235002\n",
      "Epoch 1054, Loss: 0.001835475253756158, Final Batch Loss: 0.00026275290292687714\n",
      "Epoch 1055, Loss: 0.009342573895992246, Final Batch Loss: 0.00010458038741489872\n",
      "Epoch 1056, Loss: 0.01732350524980575, Final Batch Loss: 0.000759233022108674\n",
      "Epoch 1057, Loss: 0.0034253097546752542, Final Batch Loss: 0.0002639077138155699\n",
      "Epoch 1058, Loss: 0.004753660119604319, Final Batch Loss: 0.000549888820387423\n",
      "Epoch 1059, Loss: 0.011967839673161507, Final Batch Loss: 0.002920352155342698\n",
      "Epoch 1060, Loss: 0.0017394005408277735, Final Batch Loss: 0.00043866605847142637\n",
      "Epoch 1061, Loss: 0.003721595130627975, Final Batch Loss: 0.0006225096294656396\n",
      "Epoch 1062, Loss: 0.001890213054139167, Final Batch Loss: 0.0009786378359422088\n",
      "Epoch 1063, Loss: 0.0016484470252180472, Final Batch Loss: 0.0002498711983207613\n",
      "Epoch 1064, Loss: 0.0036870595286018215, Final Batch Loss: 0.00019220815738663077\n",
      "Epoch 1065, Loss: 0.005542639482882805, Final Batch Loss: 0.00020852329907938838\n",
      "Epoch 1066, Loss: 0.0020145460475760046, Final Batch Loss: 5.3121326345717534e-05\n",
      "Epoch 1067, Loss: 0.0013881372069590725, Final Batch Loss: 0.00011245814675930887\n",
      "Epoch 1068, Loss: 0.002723455494560767, Final Batch Loss: 0.0004594173515215516\n",
      "Epoch 1069, Loss: 0.0023920751846162602, Final Batch Loss: 0.000511143181938678\n",
      "Epoch 1070, Loss: 0.0021107618522364646, Final Batch Loss: 0.0011632641544565558\n",
      "Epoch 1071, Loss: 0.00877990128356032, Final Batch Loss: 0.0002218153967987746\n",
      "Epoch 1072, Loss: 0.0010435776930535212, Final Batch Loss: 0.00046127018867991865\n",
      "Epoch 1073, Loss: 0.0020202812302159145, Final Batch Loss: 0.00035460194339975715\n",
      "Epoch 1074, Loss: 0.004851926030823961, Final Batch Loss: 0.00037942250492051244\n",
      "Epoch 1075, Loss: 0.006337759172311053, Final Batch Loss: 0.0021474442910403013\n",
      "Epoch 1076, Loss: 0.013496442254108842, Final Batch Loss: 0.0032749378588050604\n",
      "Epoch 1077, Loss: 0.003318636358017102, Final Batch Loss: 5.443792906589806e-05\n",
      "Epoch 1078, Loss: 0.011417210436775349, Final Batch Loss: 0.00028596058837138116\n",
      "Epoch 1079, Loss: 0.008751266723265871, Final Batch Loss: 0.005739692598581314\n",
      "Epoch 1080, Loss: 0.0025075867015402764, Final Batch Loss: 0.0005264254286885262\n",
      "Epoch 1081, Loss: 0.00191688760969555, Final Batch Loss: 6.330885662464425e-05\n",
      "Epoch 1082, Loss: 0.006321543041849509, Final Batch Loss: 0.000532743870280683\n",
      "Epoch 1083, Loss: 0.013254547608084977, Final Batch Loss: 0.0006486058700829744\n",
      "Epoch 1084, Loss: 0.006125369742221665, Final Batch Loss: 0.003122442401945591\n",
      "Epoch 1085, Loss: 0.027301227826683316, Final Batch Loss: 0.00014152830408420414\n",
      "Epoch 1086, Loss: 0.0031885830248938873, Final Batch Loss: 0.0016879832837730646\n",
      "Epoch 1087, Loss: 0.010564219260231766, Final Batch Loss: 1.5156513654801529e-05\n",
      "Epoch 1088, Loss: 0.005384599142416846, Final Batch Loss: 0.002697552088648081\n",
      "Epoch 1089, Loss: 0.0012620617853826843, Final Batch Loss: 0.00012041271111229435\n",
      "Epoch 1090, Loss: 0.014432300748012494, Final Batch Loss: 0.00016122472879942507\n",
      "Epoch 1091, Loss: 0.004753628687467426, Final Batch Loss: 0.002836135681718588\n",
      "Epoch 1092, Loss: 0.003656539091025479, Final Batch Loss: 7.132913742680103e-05\n",
      "Epoch 1093, Loss: 0.0031041994807310402, Final Batch Loss: 0.0006874864338897169\n",
      "Epoch 1094, Loss: 0.018350133439525962, Final Batch Loss: 0.0057763089425861835\n",
      "Epoch 1095, Loss: 0.002166893427784089, Final Batch Loss: 0.00010126931738341227\n",
      "Epoch 1096, Loss: 0.0011339473276166245, Final Batch Loss: 0.00022600153170060366\n",
      "Epoch 1097, Loss: 0.019851569391903467, Final Batch Loss: 0.0005019202944822609\n",
      "Epoch 1098, Loss: 0.0009958338632714003, Final Batch Loss: 0.00017300457693636417\n",
      "Epoch 1099, Loss: 0.005851028938195668, Final Batch Loss: 8.245704520959407e-05\n",
      "Epoch 1100, Loss: 0.013734970445511863, Final Batch Loss: 7.067510159686208e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1101, Loss: 0.01881198526825756, Final Batch Loss: 0.0052273087203502655\n",
      "Epoch 1102, Loss: 0.00376698694890365, Final Batch Loss: 0.00031724615837447345\n",
      "Epoch 1103, Loss: 0.0018811634799931198, Final Batch Loss: 0.00018206305685453117\n",
      "Epoch 1104, Loss: 0.007231290557683678, Final Batch Loss: 5.3978543292032555e-05\n",
      "Epoch 1105, Loss: 0.025329259307909524, Final Batch Loss: 4.122365135117434e-05\n",
      "Epoch 1106, Loss: 0.003149625437799841, Final Batch Loss: 0.0006412116927094758\n",
      "Epoch 1107, Loss: 0.011093475099187344, Final Batch Loss: 0.006869868375360966\n",
      "Epoch 1108, Loss: 0.0011897738004336134, Final Batch Loss: 0.0005214894190430641\n",
      "Epoch 1109, Loss: 0.005155932856723666, Final Batch Loss: 7.690126949455589e-05\n",
      "Epoch 1110, Loss: 0.00474719179328531, Final Batch Loss: 0.00014001889212522656\n",
      "Epoch 1111, Loss: 0.0020224218314979225, Final Batch Loss: 0.0006777492817491293\n",
      "Epoch 1112, Loss: 0.0009878198470687494, Final Batch Loss: 9.800461702980101e-05\n",
      "Epoch 1113, Loss: 0.0011166475160280243, Final Batch Loss: 0.0002304904191987589\n",
      "Epoch 1114, Loss: 0.011103481985628605, Final Batch Loss: 0.0048214285634458065\n",
      "Epoch 1115, Loss: 0.016156555648194626, Final Batch Loss: 0.002471419284120202\n",
      "Epoch 1116, Loss: 0.029258120426675305, Final Batch Loss: 6.363356078509241e-05\n",
      "Epoch 1117, Loss: 0.0010422436898807064, Final Batch Loss: 0.0002842039102688432\n",
      "Epoch 1118, Loss: 0.03627462187432684, Final Batch Loss: 0.0036446815356612206\n",
      "Epoch 1119, Loss: 0.006166874285554513, Final Batch Loss: 0.00018116491264663637\n",
      "Epoch 1120, Loss: 0.000668189037241973, Final Batch Loss: 0.00016540502838324755\n",
      "Epoch 1121, Loss: 0.006266394499107264, Final Batch Loss: 8.870857709553093e-05\n",
      "Epoch 1122, Loss: 0.006694377734675072, Final Batch Loss: 0.0002978930715471506\n",
      "Epoch 1123, Loss: 0.005313336310791783, Final Batch Loss: 0.0007134417537599802\n",
      "Epoch 1124, Loss: 0.014928222059097607, Final Batch Loss: 0.010877352207899094\n",
      "Epoch 1125, Loss: 0.0010855715736397542, Final Batch Loss: 7.211199408629909e-05\n",
      "Epoch 1126, Loss: 0.007026275659882231, Final Batch Loss: 5.6266489991685376e-05\n",
      "Epoch 1127, Loss: 0.0009263011597795412, Final Batch Loss: 8.076863014139235e-05\n",
      "Epoch 1128, Loss: 0.00255938277405221, Final Batch Loss: 0.0008186040795408189\n",
      "Epoch 1129, Loss: 0.007162704539950937, Final Batch Loss: 0.0002027762238867581\n",
      "Epoch 1130, Loss: 0.0006505360925075365, Final Batch Loss: 1.7750882761902176e-05\n",
      "Epoch 1131, Loss: 0.020223957137204707, Final Batch Loss: 0.01846410147845745\n",
      "Epoch 1132, Loss: 0.0014851895248284563, Final Batch Loss: 0.00048135683755390346\n",
      "Epoch 1133, Loss: 0.0032266747293761, Final Batch Loss: 0.00011685742356348783\n",
      "Epoch 1134, Loss: 0.0018176878256781492, Final Batch Loss: 0.0003531890397425741\n",
      "Epoch 1135, Loss: 0.005449098563985899, Final Batch Loss: 0.00015390558110084385\n",
      "Epoch 1136, Loss: 0.0076243846997385845, Final Batch Loss: 0.00015070447989273816\n",
      "Epoch 1137, Loss: 0.013911421090597287, Final Batch Loss: 0.00033573494874872267\n",
      "Epoch 1138, Loss: 0.0011475628198240884, Final Batch Loss: 0.0002973468799609691\n",
      "Epoch 1139, Loss: 0.017270429598283954, Final Batch Loss: 0.003626882331445813\n",
      "Epoch 1140, Loss: 0.007248736350447871, Final Batch Loss: 0.0002191392268287018\n",
      "Epoch 1141, Loss: 0.005397660133894533, Final Batch Loss: 0.0009946258505806327\n",
      "Epoch 1142, Loss: 0.002585301197541412, Final Batch Loss: 0.0015842665452510118\n",
      "Epoch 1143, Loss: 0.002167579412343912, Final Batch Loss: 0.0002110183850163594\n",
      "Epoch 1144, Loss: 0.0038453952583950013, Final Batch Loss: 0.0021425301674753428\n",
      "Epoch 1145, Loss: 0.003493264113785699, Final Batch Loss: 0.0003382342983968556\n",
      "Epoch 1146, Loss: 0.0019865141075570136, Final Batch Loss: 0.0002587120688986033\n",
      "Epoch 1147, Loss: 0.0030406897276407108, Final Batch Loss: 0.0001750925584929064\n",
      "Epoch 1148, Loss: 0.032245182956103235, Final Batch Loss: 0.00028800457948818803\n",
      "Epoch 1149, Loss: 0.011063235564506613, Final Batch Loss: 0.0009959598537534475\n",
      "Epoch 1150, Loss: 0.003187544265529141, Final Batch Loss: 0.00019789305224549025\n",
      "Epoch 1151, Loss: 0.000801080655946862, Final Batch Loss: 0.0004001074412371963\n",
      "Epoch 1152, Loss: 0.010161851649172604, Final Batch Loss: 0.004394329618662596\n",
      "Epoch 1153, Loss: 0.011610251174715813, Final Batch Loss: 0.00010506502439966425\n",
      "Epoch 1154, Loss: 0.007288415741641074, Final Batch Loss: 0.00027941836742684245\n",
      "Epoch 1155, Loss: 0.0036592132164514624, Final Batch Loss: 0.0018777087097987533\n",
      "Epoch 1156, Loss: 0.0018443670269334689, Final Batch Loss: 0.00020409325952641666\n",
      "Epoch 1157, Loss: 0.00758558014058508, Final Batch Loss: 6.94158225087449e-05\n",
      "Epoch 1158, Loss: 0.006104735628468916, Final Batch Loss: 0.00029575263033621013\n",
      "Epoch 1159, Loss: 0.00590636940614786, Final Batch Loss: 0.00018069108773488551\n",
      "Epoch 1160, Loss: 0.006371099792886525, Final Batch Loss: 0.0004907879629172385\n",
      "Epoch 1161, Loss: 0.003911892890755553, Final Batch Loss: 9.884927567327395e-05\n",
      "Epoch 1162, Loss: 0.0013126317935530096, Final Batch Loss: 0.0004233886720612645\n",
      "Epoch 1163, Loss: 0.0033582268079044297, Final Batch Loss: 0.0006051570526324213\n",
      "Epoch 1164, Loss: 0.0004839377652388066, Final Batch Loss: 0.00014249225205276161\n",
      "Epoch 1165, Loss: 0.00682898098602891, Final Batch Loss: 0.002114578615874052\n",
      "Epoch 1166, Loss: 0.0016249128893832676, Final Batch Loss: 2.9361624910961837e-05\n",
      "Epoch 1167, Loss: 0.005813460549688898, Final Batch Loss: 0.0037705698050558567\n",
      "Epoch 1168, Loss: 0.0037468620867002755, Final Batch Loss: 0.00012643901573028415\n",
      "Epoch 1169, Loss: 0.002495199703844264, Final Batch Loss: 0.00012643163790926337\n",
      "Epoch 1170, Loss: 0.004663072802941315, Final Batch Loss: 0.0011952804634347558\n",
      "Epoch 1171, Loss: 0.0012035865074722096, Final Batch Loss: 0.00021211130660958588\n",
      "Epoch 1172, Loss: 0.0033008960308507085, Final Batch Loss: 0.0015796098159626126\n",
      "Epoch 1173, Loss: 0.0031148003836278804, Final Batch Loss: 6.581416528206319e-05\n",
      "Epoch 1174, Loss: 0.002155650559870992, Final Batch Loss: 6.235154432943091e-05\n",
      "Epoch 1175, Loss: 0.0007715533065493219, Final Batch Loss: 0.00010388800728833303\n",
      "Epoch 1176, Loss: 0.0013568616122938693, Final Batch Loss: 7.754583202768117e-05\n",
      "Epoch 1177, Loss: 0.003955398860853165, Final Batch Loss: 0.0019713423680514097\n",
      "Epoch 1178, Loss: 0.004596209357259795, Final Batch Loss: 0.0027401072438806295\n",
      "Epoch 1179, Loss: 0.0029218046402093023, Final Batch Loss: 0.0004404272767715156\n",
      "Epoch 1180, Loss: 0.0015792179510754067, Final Batch Loss: 3.831142748822458e-05\n",
      "Epoch 1181, Loss: 0.0006259431829676032, Final Batch Loss: 0.00022246513981372118\n",
      "Epoch 1182, Loss: 0.0018456497637089342, Final Batch Loss: 0.0008254658314399421\n",
      "Epoch 1183, Loss: 0.0012359032552922145, Final Batch Loss: 0.0002967843320220709\n",
      "Epoch 1184, Loss: 0.0006929466180736199, Final Batch Loss: 6.448128260672092e-05\n",
      "Epoch 1185, Loss: 0.0005269557150313631, Final Batch Loss: 0.00016575100016780198\n",
      "Epoch 1186, Loss: 0.0014274042550823651, Final Batch Loss: 8.863278344506398e-05\n",
      "Epoch 1187, Loss: 0.0008577313128625974, Final Batch Loss: 0.00033146829809993505\n",
      "Epoch 1188, Loss: 0.0021710900982725434, Final Batch Loss: 5.3951975132804364e-05\n",
      "Epoch 1189, Loss: 0.00358186302401009, Final Batch Loss: 4.1629999032011256e-05\n",
      "Epoch 1190, Loss: 0.0008926971422624774, Final Batch Loss: 0.00012582381896208972\n",
      "Epoch 1191, Loss: 0.001308773280470632, Final Batch Loss: 0.0005851109744980931\n",
      "Epoch 1192, Loss: 0.0035424893721938133, Final Batch Loss: 0.0008355627069249749\n",
      "Epoch 1193, Loss: 0.0018784600961225806, Final Batch Loss: 1.671649624768179e-05\n",
      "Epoch 1194, Loss: 0.0010159369603570667, Final Batch Loss: 9.137923370872159e-06\n",
      "Epoch 1195, Loss: 0.001240780584339518, Final Batch Loss: 9.317950025433674e-05\n",
      "Epoch 1196, Loss: 0.018023677810560912, Final Batch Loss: 0.00019018650345969945\n",
      "Epoch 1197, Loss: 0.0054929529869696125, Final Batch Loss: 0.0011988208862021565\n",
      "Epoch 1198, Loss: 0.00584563403390348, Final Batch Loss: 0.001195159973576665\n",
      "Epoch 1199, Loss: 0.006719516778503021, Final Batch Loss: 9.163347385765519e-06\n",
      "Epoch 1200, Loss: 0.008932561060646549, Final Batch Loss: 9.618239710107446e-05\n",
      "Epoch 1201, Loss: 0.026878363511059433, Final Batch Loss: 0.003664943389594555\n",
      "Epoch 1202, Loss: 0.002760413466603495, Final Batch Loss: 0.0017273185076192021\n",
      "Epoch 1203, Loss: 0.0021228308396530338, Final Batch Loss: 0.0002463592973072082\n",
      "Epoch 1204, Loss: 0.02950183365464909, Final Batch Loss: 9.159103501588106e-05\n",
      "Epoch 1205, Loss: 0.0012361576336843427, Final Batch Loss: 3.767985253944062e-05\n",
      "Epoch 1206, Loss: 0.0015500093868467957, Final Batch Loss: 5.621151649393141e-05\n",
      "Epoch 1207, Loss: 0.003535573268891312, Final Batch Loss: 6.836377724539489e-05\n",
      "Epoch 1208, Loss: 0.010288711811881512, Final Batch Loss: 0.001100151683203876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209, Loss: 0.0020906904101138934, Final Batch Loss: 0.0004113829636480659\n",
      "Epoch 1210, Loss: 0.00636094888614025, Final Batch Loss: 0.0019772942177951336\n",
      "Epoch 1211, Loss: 0.015176895743934438, Final Batch Loss: 0.0003937015135306865\n",
      "Epoch 1212, Loss: 0.014002513697050745, Final Batch Loss: 0.00012168920511612669\n",
      "Epoch 1213, Loss: 0.00570886091554712, Final Batch Loss: 2.0496945580816828e-05\n",
      "Epoch 1214, Loss: 0.003233703915611841, Final Batch Loss: 0.001026528887450695\n",
      "Epoch 1215, Loss: 0.0006230351064004935, Final Batch Loss: 0.0001045691387844272\n",
      "Epoch 1216, Loss: 0.002373693700064905, Final Batch Loss: 0.0001834904687711969\n",
      "Epoch 1217, Loss: 0.0038927369459997863, Final Batch Loss: 0.0002785227552521974\n",
      "Epoch 1218, Loss: 0.010805247613461688, Final Batch Loss: 0.003400106681510806\n",
      "Epoch 1219, Loss: 0.006461148601374589, Final Batch Loss: 0.00014983130677137524\n",
      "Epoch 1220, Loss: 0.002129691536538303, Final Batch Loss: 0.0006034845719113946\n",
      "Epoch 1221, Loss: 0.0012979312814422883, Final Batch Loss: 0.000179479960934259\n",
      "Epoch 1222, Loss: 0.0029237612761789933, Final Batch Loss: 0.00014424780965782702\n",
      "Epoch 1223, Loss: 0.0024222444772021845, Final Batch Loss: 0.0011616927804425359\n",
      "Epoch 1224, Loss: 0.0016599901355220936, Final Batch Loss: 0.00010281087452312931\n",
      "Epoch 1225, Loss: 0.011471943340438884, Final Batch Loss: 9.42043770919554e-05\n",
      "Epoch 1226, Loss: 0.0019272885147074703, Final Batch Loss: 5.226408757152967e-05\n",
      "Epoch 1227, Loss: 0.007044128367851954, Final Batch Loss: 0.0007155141211114824\n",
      "Epoch 1228, Loss: 0.0050928379787364975, Final Batch Loss: 0.0002858701627701521\n",
      "Epoch 1229, Loss: 0.0017132923239842057, Final Batch Loss: 2.1315179765224457e-05\n",
      "Epoch 1230, Loss: 0.0004982005921192467, Final Batch Loss: 0.00011868849105667323\n",
      "Epoch 1231, Loss: 0.0022450771502917632, Final Batch Loss: 0.0007746858173049986\n",
      "Epoch 1232, Loss: 0.0006403021179721691, Final Batch Loss: 0.00012178738688817248\n",
      "Epoch 1233, Loss: 0.0020647394194384106, Final Batch Loss: 0.0011725783115252852\n",
      "Epoch 1234, Loss: 0.0016853098095452879, Final Batch Loss: 0.0004016080347355455\n",
      "Epoch 1235, Loss: 0.002213635299995076, Final Batch Loss: 4.553741018753499e-05\n",
      "Epoch 1236, Loss: 0.020302557608374627, Final Batch Loss: 4.463365257834084e-05\n",
      "Epoch 1237, Loss: 0.0012290034355828539, Final Batch Loss: 0.00037590996362268925\n",
      "Epoch 1238, Loss: 0.028459373028454138, Final Batch Loss: 4.148222433286719e-05\n",
      "Epoch 1239, Loss: 0.005105475698655937, Final Batch Loss: 0.0001420207554474473\n",
      "Epoch 1240, Loss: 0.006049112562322989, Final Batch Loss: 0.004978482145816088\n",
      "Epoch 1241, Loss: 0.0010327473173674662, Final Batch Loss: 0.0004323504399508238\n",
      "Epoch 1242, Loss: 0.0129552656726446, Final Batch Loss: 0.0002510359336156398\n",
      "Epoch 1243, Loss: 0.004988803644664586, Final Batch Loss: 0.003305889666080475\n",
      "Epoch 1244, Loss: 0.001775806420482695, Final Batch Loss: 0.0006159499753266573\n",
      "Epoch 1245, Loss: 0.023836483887862414, Final Batch Loss: 0.0038944880943745375\n",
      "Epoch 1246, Loss: 0.004007269744761288, Final Batch Loss: 9.023427264764905e-05\n",
      "Epoch 1247, Loss: 0.0022349203791236505, Final Batch Loss: 0.0006646355614066124\n",
      "Epoch 1248, Loss: 0.0009177695974358357, Final Batch Loss: 5.7955468946602196e-05\n",
      "Epoch 1249, Loss: 0.001904689175717067, Final Batch Loss: 9.218122431775555e-05\n",
      "Epoch 1250, Loss: 0.01212124020094052, Final Batch Loss: 0.0005069577018730342\n",
      "Epoch 1251, Loss: 0.0008864221817930229, Final Batch Loss: 0.00028728917823173106\n",
      "Epoch 1252, Loss: 0.005448710280688829, Final Batch Loss: 2.0796365788555704e-05\n",
      "Epoch 1253, Loss: 0.024988985278469045, Final Batch Loss: 0.02047017775475979\n",
      "Epoch 1254, Loss: 0.0021360909540817374, Final Batch Loss: 0.00013923492224421352\n",
      "Epoch 1255, Loss: 0.06738356083224062, Final Batch Loss: 0.001174825825728476\n",
      "Epoch 1256, Loss: 0.027460652650916018, Final Batch Loss: 0.00040081804036162794\n",
      "Epoch 1257, Loss: 0.05846720840781927, Final Batch Loss: 0.0032984521239995956\n",
      "Epoch 1258, Loss: 0.013459060137392953, Final Batch Loss: 0.00048320379573851824\n",
      "Epoch 1259, Loss: 0.02209096317528747, Final Batch Loss: 5.328879342414439e-05\n",
      "Epoch 1260, Loss: 0.012421999272191897, Final Batch Loss: 0.00023223159951157868\n",
      "Epoch 1261, Loss: 0.005008706939406693, Final Batch Loss: 0.0008770100539550185\n",
      "Epoch 1262, Loss: 0.002815766667481512, Final Batch Loss: 0.0005922330892644823\n",
      "Epoch 1263, Loss: 0.011811604432296008, Final Batch Loss: 0.0018717956263571978\n",
      "Epoch 1264, Loss: 0.005269583125482313, Final Batch Loss: 6.89944572513923e-05\n",
      "Epoch 1265, Loss: 0.005892007990041748, Final Batch Loss: 0.00042629046947695315\n",
      "Epoch 1266, Loss: 0.004727425126475282, Final Batch Loss: 0.00038862149813212454\n",
      "Epoch 1267, Loss: 0.0013445586082525551, Final Batch Loss: 0.0002978374541271478\n",
      "Epoch 1268, Loss: 0.0014887626020936295, Final Batch Loss: 0.00021155773720238358\n",
      "Epoch 1269, Loss: 0.008101893297862262, Final Batch Loss: 0.0024218831676989794\n",
      "Epoch 1270, Loss: 0.005394216983404476, Final Batch Loss: 9.963766933651641e-05\n",
      "Epoch 1271, Loss: 0.0013638791497214697, Final Batch Loss: 6.0275451687630266e-05\n",
      "Epoch 1272, Loss: 0.006867735835839994, Final Batch Loss: 0.00022881334007252008\n",
      "Epoch 1273, Loss: 0.0013315118085301947, Final Batch Loss: 0.00025930273113772273\n",
      "Epoch 1274, Loss: 0.002133501082425937, Final Batch Loss: 0.0009261938976123929\n",
      "Epoch 1275, Loss: 0.002314225788722979, Final Batch Loss: 2.7869380573974922e-05\n",
      "Epoch 1276, Loss: 0.011394496250431985, Final Batch Loss: 0.0005561266443692148\n",
      "Epoch 1277, Loss: 0.002388599343248643, Final Batch Loss: 8.554766827728599e-05\n",
      "Epoch 1278, Loss: 0.01215250839595683, Final Batch Loss: 0.009580918587744236\n",
      "Epoch 1279, Loss: 0.0006198680639499798, Final Batch Loss: 0.00019889841496478766\n",
      "Epoch 1280, Loss: 0.0006760732430848293, Final Batch Loss: 2.3835018509998918e-05\n",
      "Epoch 1281, Loss: 0.0012138502352172509, Final Batch Loss: 6.412189395632595e-05\n",
      "Epoch 1282, Loss: 0.025213657165295444, Final Batch Loss: 0.00013140974624548107\n",
      "Epoch 1283, Loss: 0.0025269024772569537, Final Batch Loss: 0.0007967113051563501\n",
      "Epoch 1284, Loss: 0.0026715143758337945, Final Batch Loss: 0.0002544815361034125\n",
      "Epoch 1285, Loss: 0.003920484341506381, Final Batch Loss: 0.00040828148485161364\n",
      "Epoch 1286, Loss: 0.002440403142827563, Final Batch Loss: 0.0013658859534189105\n",
      "Epoch 1287, Loss: 0.0030958536081016064, Final Batch Loss: 0.00019169473671354353\n",
      "Epoch 1288, Loss: 0.008848768222378567, Final Batch Loss: 0.00046089894021861255\n",
      "Epoch 1289, Loss: 0.0144560229673516, Final Batch Loss: 0.0002100437559420243\n",
      "Epoch 1290, Loss: 0.0023986047599464655, Final Batch Loss: 0.0002355037140659988\n",
      "Epoch 1291, Loss: 0.004076843775692396, Final Batch Loss: 0.0018090081866830587\n",
      "Epoch 1292, Loss: 0.0014306250668596476, Final Batch Loss: 0.00015989910752978176\n",
      "Epoch 1293, Loss: 0.00402741068683099, Final Batch Loss: 0.0022049257531762123\n",
      "Epoch 1294, Loss: 0.00415260508452775, Final Batch Loss: 5.2073221013415605e-05\n",
      "Epoch 1295, Loss: 0.0028016065334668383, Final Batch Loss: 0.000481112307170406\n",
      "Epoch 1296, Loss: 0.021204490811214782, Final Batch Loss: 0.005300724878907204\n",
      "Epoch 1297, Loss: 0.009030819041072391, Final Batch Loss: 0.0040901885367929935\n",
      "Epoch 1298, Loss: 0.009111504565225914, Final Batch Loss: 6.423922604881227e-05\n",
      "Epoch 1299, Loss: 0.00419558615249116, Final Batch Loss: 0.0002402197424089536\n",
      "Epoch 1300, Loss: 0.007286406529601663, Final Batch Loss: 0.003428740194067359\n",
      "Epoch 1301, Loss: 0.0024193245844799094, Final Batch Loss: 0.00011811119475169107\n",
      "Epoch 1302, Loss: 0.006152920032036491, Final Batch Loss: 0.0048211198300123215\n",
      "Epoch 1303, Loss: 0.0049720722272468265, Final Batch Loss: 2.0245464838808402e-05\n",
      "Epoch 1304, Loss: 0.003492725169053301, Final Batch Loss: 0.0002624487678986043\n",
      "Epoch 1305, Loss: 0.0033771913294913247, Final Batch Loss: 0.001456103753298521\n",
      "Epoch 1306, Loss: 0.00410606199875474, Final Batch Loss: 0.00030645309016108513\n",
      "Epoch 1307, Loss: 0.003433156030951068, Final Batch Loss: 0.0004489132552407682\n",
      "Epoch 1308, Loss: 0.0037421052111312747, Final Batch Loss: 0.0026377085596323013\n",
      "Epoch 1309, Loss: 0.01674298029683996, Final Batch Loss: 0.0010713892988860607\n",
      "Epoch 1310, Loss: 0.00432979632387287, Final Batch Loss: 4.283545058569871e-05\n",
      "Epoch 1311, Loss: 0.004362175066489726, Final Batch Loss: 0.0010662811109796166\n",
      "Epoch 1312, Loss: 0.0013595987784356112, Final Batch Loss: 0.0006429165368899703\n",
      "Epoch 1313, Loss: 0.0003287402869318612, Final Batch Loss: 3.243179526180029e-05\n",
      "Epoch 1314, Loss: 0.0011203804024262354, Final Batch Loss: 5.590851651504636e-05\n",
      "Epoch 1315, Loss: 0.004601342472597025, Final Batch Loss: 0.00012965136556886137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1316, Loss: 0.0009872360024019144, Final Batch Loss: 0.00019069440895691514\n",
      "Epoch 1317, Loss: 0.0010289925339748152, Final Batch Loss: 0.00018607474339660257\n",
      "Epoch 1318, Loss: 0.002420261997031048, Final Batch Loss: 0.0005013699410483241\n",
      "Epoch 1319, Loss: 0.03690435879980214, Final Batch Loss: 0.00030690644052810967\n",
      "Epoch 1320, Loss: 0.020364335159683833, Final Batch Loss: 4.239389454596676e-05\n",
      "Epoch 1321, Loss: 0.004356134377303533, Final Batch Loss: 0.00018432641809340566\n",
      "Epoch 1322, Loss: 0.0013807669092784636, Final Batch Loss: 4.6163353545125574e-05\n",
      "Epoch 1323, Loss: 0.0015630815032636747, Final Batch Loss: 0.0010274829110130668\n",
      "Epoch 1324, Loss: 0.0095081920735538, Final Batch Loss: 0.0001644317526370287\n",
      "Epoch 1325, Loss: 0.009402748371940106, Final Batch Loss: 0.0014201159356161952\n",
      "Epoch 1326, Loss: 0.009462847279792186, Final Batch Loss: 0.0006282501271925867\n",
      "Epoch 1327, Loss: 0.0014014900953043252, Final Batch Loss: 0.00025453793932683766\n",
      "Epoch 1328, Loss: 0.002476063382346183, Final Batch Loss: 0.0011292049894109368\n",
      "Epoch 1329, Loss: 0.016822507510369178, Final Batch Loss: 0.004469636362046003\n",
      "Epoch 1330, Loss: 0.0041587202285882086, Final Batch Loss: 0.002773321233689785\n",
      "Epoch 1331, Loss: 0.0015458231209777296, Final Batch Loss: 0.000737054564524442\n",
      "Epoch 1332, Loss: 0.016277336224447936, Final Batch Loss: 0.014027289114892483\n",
      "Epoch 1333, Loss: 0.0007358224320341833, Final Batch Loss: 0.00011139624257339165\n",
      "Epoch 1334, Loss: 0.0009397785761393607, Final Batch Loss: 0.00017335648590233177\n",
      "Epoch 1335, Loss: 0.001373440016323002, Final Batch Loss: 8.2584643678274e-05\n",
      "Epoch 1336, Loss: 0.0006587925054191146, Final Batch Loss: 1.5383488062070683e-05\n",
      "Epoch 1337, Loss: 0.005296049144817516, Final Batch Loss: 0.00022817926947027445\n",
      "Epoch 1338, Loss: 0.0034470614918973297, Final Batch Loss: 0.0025101862847805023\n",
      "Epoch 1339, Loss: 0.00580928322597174, Final Batch Loss: 2.615182165754959e-05\n",
      "Epoch 1340, Loss: 0.013390521933615673, Final Batch Loss: 4.682350845541805e-05\n",
      "Epoch 1341, Loss: 0.00402537573245354, Final Batch Loss: 0.0010395311983302236\n",
      "Epoch 1342, Loss: 0.0006209873099578544, Final Batch Loss: 0.00011391532461857423\n",
      "Epoch 1343, Loss: 0.0017218882385350298, Final Batch Loss: 8.850902668200433e-05\n",
      "Epoch 1344, Loss: 0.0019119593744107988, Final Batch Loss: 5.2495550335152075e-05\n",
      "Epoch 1345, Loss: 0.000969404853094602, Final Batch Loss: 6.344950816128403e-05\n",
      "Epoch 1346, Loss: 0.0007324510806938633, Final Batch Loss: 3.3687669201754034e-05\n",
      "Epoch 1347, Loss: 0.0010713057454267982, Final Batch Loss: 0.00015293582691811025\n",
      "Epoch 1348, Loss: 0.0005764758243458346, Final Batch Loss: 0.00011125174933113158\n",
      "Epoch 1349, Loss: 0.0030741544178454205, Final Batch Loss: 0.0007318105199374259\n",
      "Epoch 1350, Loss: 0.027070181560702622, Final Batch Loss: 0.008408491499722004\n",
      "Epoch 1351, Loss: 0.0007598260490340181, Final Batch Loss: 2.272526762681082e-05\n",
      "Epoch 1352, Loss: 0.013502690999303013, Final Batch Loss: 4.5333152229432017e-05\n",
      "Epoch 1353, Loss: 0.030060671371757053, Final Batch Loss: 0.00014632583770435303\n",
      "Epoch 1354, Loss: 0.003839482851617504, Final Batch Loss: 0.0002668661472853273\n",
      "Epoch 1355, Loss: 0.000602575768425595, Final Batch Loss: 9.396438690600917e-05\n",
      "Epoch 1356, Loss: 0.007395195367280394, Final Batch Loss: 0.0002802786766551435\n",
      "Epoch 1357, Loss: 0.0011587205372052267, Final Batch Loss: 7.551457383669913e-05\n",
      "Epoch 1358, Loss: 0.012232404405949637, Final Batch Loss: 4.366040229797363e-05\n",
      "Epoch 1359, Loss: 0.0018044195967377163, Final Batch Loss: 0.001194412587210536\n",
      "Epoch 1360, Loss: 0.002430389024084434, Final Batch Loss: 0.00026885620900429785\n",
      "Epoch 1361, Loss: 0.005099349727970548, Final Batch Loss: 0.0006807056488469243\n",
      "Epoch 1362, Loss: 0.0011489097378216684, Final Batch Loss: 0.00013414619024842978\n",
      "Epoch 1363, Loss: 0.004567313037114218, Final Batch Loss: 0.0009477637358941138\n",
      "Epoch 1364, Loss: 0.0016599597875028849, Final Batch Loss: 0.00032341916812583804\n",
      "Epoch 1365, Loss: 0.007054013411107007, Final Batch Loss: 0.000407416868256405\n",
      "Epoch 1366, Loss: 0.0005704837403754937, Final Batch Loss: 2.7914980819332413e-05\n",
      "Epoch 1367, Loss: 0.002829138160450384, Final Batch Loss: 0.0013636929215863347\n",
      "Epoch 1368, Loss: 0.0031759643752593547, Final Batch Loss: 0.0009537499863654375\n",
      "Epoch 1369, Loss: 0.008914284389902605, Final Batch Loss: 0.00802644807845354\n",
      "Epoch 1370, Loss: 0.0007944576063891873, Final Batch Loss: 0.00013160445087123662\n",
      "Epoch 1371, Loss: 0.028296381102336454, Final Batch Loss: 1.5641655409126543e-05\n",
      "Epoch 1372, Loss: 0.0011237900653213728, Final Batch Loss: 0.0002478629758115858\n",
      "Epoch 1373, Loss: 0.003955485983169638, Final Batch Loss: 0.00024074518296401948\n",
      "Epoch 1374, Loss: 0.011291973321931437, Final Batch Loss: 7.510415889555588e-05\n",
      "Epoch 1375, Loss: 0.0015135761204874143, Final Batch Loss: 0.0003937059373129159\n",
      "Epoch 1376, Loss: 0.0026206180336885154, Final Batch Loss: 0.0005364124081097543\n",
      "Epoch 1377, Loss: 0.004549485562165501, Final Batch Loss: 5.812982635688968e-05\n",
      "Epoch 1378, Loss: 0.00026623487792676315, Final Batch Loss: 8.372463344130665e-05\n",
      "Epoch 1379, Loss: 0.0019485223601805046, Final Batch Loss: 0.0008509240578860044\n",
      "Epoch 1380, Loss: 0.0022292141075013205, Final Batch Loss: 0.0004939988721162081\n",
      "Epoch 1381, Loss: 0.001132975914515555, Final Batch Loss: 0.00035707783536054194\n",
      "Epoch 1382, Loss: 0.004148129533859901, Final Batch Loss: 3.00318788504228e-05\n",
      "Epoch 1383, Loss: 0.00048701306150178425, Final Batch Loss: 1.5109715604921803e-05\n",
      "Epoch 1384, Loss: 0.0021388183813542128, Final Batch Loss: 0.00012545865320134908\n",
      "Epoch 1385, Loss: 0.000715855883754557, Final Batch Loss: 0.00023991515627130866\n",
      "Epoch 1386, Loss: 0.003603339799155947, Final Batch Loss: 6.210365245351568e-05\n",
      "Epoch 1387, Loss: 0.0009490416741755325, Final Batch Loss: 8.510465704603121e-05\n",
      "Epoch 1388, Loss: 0.0015321531391236931, Final Batch Loss: 0.00012668760609813035\n",
      "Epoch 1389, Loss: 0.0003163584024150623, Final Batch Loss: 2.007226248679217e-05\n",
      "Epoch 1390, Loss: 0.002539765879191691, Final Batch Loss: 1.1717656889231876e-05\n",
      "Epoch 1391, Loss: 0.001808790853829123, Final Batch Loss: 0.0003100588801316917\n",
      "Epoch 1392, Loss: 0.0011540022878762102, Final Batch Loss: 1.0369452866143547e-05\n",
      "Epoch 1393, Loss: 0.0014653060788987204, Final Batch Loss: 0.0004658533143810928\n",
      "Epoch 1394, Loss: 0.00021809352256241255, Final Batch Loss: 3.274048140156083e-05\n",
      "Epoch 1395, Loss: 0.03070523703354411, Final Batch Loss: 0.0002575830148998648\n",
      "Epoch 1396, Loss: 0.000468674348667264, Final Batch Loss: 8.397801866522059e-05\n",
      "Epoch 1397, Loss: 0.003449648429523222, Final Batch Loss: 0.0025661499239504337\n",
      "Epoch 1398, Loss: 0.005225774675636785, Final Batch Loss: 0.0019710042979568243\n",
      "Epoch 1399, Loss: 0.003055546105315443, Final Batch Loss: 1.873844303190708e-05\n",
      "Epoch 1400, Loss: 0.002555502887844341, Final Batch Loss: 0.000582569045946002\n",
      "Epoch 1401, Loss: 0.0030330386180139612, Final Batch Loss: 0.00011181606532773003\n",
      "Epoch 1402, Loss: 0.0002944547613878967, Final Batch Loss: 6.778155511710793e-05\n",
      "Epoch 1403, Loss: 0.0017811192483350169, Final Batch Loss: 6.110745744081214e-05\n",
      "Epoch 1404, Loss: 0.0019311316791572608, Final Batch Loss: 0.0012755595380440354\n",
      "Epoch 1405, Loss: 0.0036196634609950706, Final Batch Loss: 0.0002461517578922212\n",
      "Epoch 1406, Loss: 0.0007120374666556017, Final Batch Loss: 2.164553734473884e-05\n",
      "Epoch 1407, Loss: 0.02003969921315729, Final Batch Loss: 2.0809597117477097e-05\n",
      "Epoch 1408, Loss: 0.010571851293207146, Final Batch Loss: 0.00021606810332741588\n",
      "Epoch 1409, Loss: 0.013979984079014685, Final Batch Loss: 1.1849285328935366e-05\n",
      "Epoch 1410, Loss: 0.002935684591648169, Final Batch Loss: 0.0002097390970448032\n",
      "Epoch 1411, Loss: 0.028029328721459024, Final Batch Loss: 0.01925639621913433\n",
      "Epoch 1412, Loss: 0.0125178215384949, Final Batch Loss: 0.0020491681061685085\n",
      "Epoch 1413, Loss: 0.013021104445215315, Final Batch Loss: 0.000879783125128597\n",
      "Epoch 1414, Loss: 0.0033959425782086328, Final Batch Loss: 0.0018561958568170667\n",
      "Epoch 1415, Loss: 0.00046127978566801175, Final Batch Loss: 0.00011273028212599456\n",
      "Epoch 1416, Loss: 0.010267441946780309, Final Batch Loss: 0.0009174436563625932\n",
      "Epoch 1417, Loss: 0.00642154534580186, Final Batch Loss: 0.001079685753211379\n",
      "Epoch 1418, Loss: 0.00047884452214930207, Final Batch Loss: 0.0001319206494372338\n",
      "Epoch 1419, Loss: 0.0013541076841647737, Final Batch Loss: 5.891905311727896e-05\n",
      "Epoch 1420, Loss: 0.006905907481268514, Final Batch Loss: 0.0004884150112047791\n",
      "Epoch 1421, Loss: 0.020365751537610777, Final Batch Loss: 0.0010693075601011515\n",
      "Epoch 1422, Loss: 0.0008133982846629806, Final Batch Loss: 0.0003153400612063706\n",
      "Epoch 1423, Loss: 0.0009836757599259727, Final Batch Loss: 0.0001447476097382605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1424, Loss: 0.0007931187428766862, Final Batch Loss: 0.00012009014608338475\n",
      "Epoch 1425, Loss: 0.009101291110710008, Final Batch Loss: 3.993671271018684e-05\n",
      "Epoch 1426, Loss: 0.0019212935403629672, Final Batch Loss: 0.0001087119453586638\n",
      "Epoch 1427, Loss: 0.0003793661126110237, Final Batch Loss: 1.729335417621769e-05\n",
      "Epoch 1428, Loss: 0.00041431676800129935, Final Batch Loss: 3.768835085793398e-05\n",
      "Epoch 1429, Loss: 0.001204472064273432, Final Batch Loss: 0.00016314700769726187\n",
      "Epoch 1430, Loss: 0.028467856063798536, Final Batch Loss: 0.0004461077041924\n",
      "Epoch 1431, Loss: 0.0017302016785833985, Final Batch Loss: 0.00024061549629550427\n",
      "Epoch 1432, Loss: 0.010284744756063446, Final Batch Loss: 0.00021227402612566948\n",
      "Epoch 1433, Loss: 0.001310845800617244, Final Batch Loss: 0.0004723437305074185\n",
      "Epoch 1434, Loss: 0.000872672040713951, Final Batch Loss: 0.00023976253578439355\n",
      "Epoch 1435, Loss: 0.0026782651111716405, Final Batch Loss: 0.0001900471979752183\n",
      "Epoch 1436, Loss: 0.011887488559295889, Final Batch Loss: 0.0001186079389299266\n",
      "Epoch 1437, Loss: 0.01736122148577124, Final Batch Loss: 0.00026765294023789465\n",
      "Epoch 1438, Loss: 0.014240795127989259, Final Batch Loss: 7.677025132579729e-05\n",
      "Epoch 1439, Loss: 0.0024024311351240613, Final Batch Loss: 0.0016785144107416272\n",
      "Epoch 1440, Loss: 0.000361618653187179, Final Batch Loss: 0.0002142095036106184\n",
      "Epoch 1441, Loss: 0.004461409054783871, Final Batch Loss: 0.00013966357801109552\n",
      "Epoch 1442, Loss: 0.0015284035289369058, Final Batch Loss: 0.00112686597276479\n",
      "Epoch 1443, Loss: 0.007579324657854158, Final Batch Loss: 4.385269494378008e-05\n",
      "Epoch 1444, Loss: 0.02093379657890182, Final Batch Loss: 0.00018828673637472093\n",
      "Epoch 1445, Loss: 0.0037828350396011956, Final Batch Loss: 0.0001555100898258388\n",
      "Epoch 1446, Loss: 0.0016681145652910345, Final Batch Loss: 9.350435902888421e-06\n",
      "Epoch 1447, Loss: 0.001306316724367207, Final Batch Loss: 0.0006932034739293158\n",
      "Epoch 1448, Loss: 0.006115345691796392, Final Batch Loss: 0.0004462187644094229\n",
      "Epoch 1449, Loss: 0.0030605010251747444, Final Batch Loss: 0.0004858057654928416\n",
      "Epoch 1450, Loss: 0.015110771764739184, Final Batch Loss: 0.014980443753302097\n",
      "Epoch 1451, Loss: 0.005238471436314285, Final Batch Loss: 0.0013649306492879987\n",
      "Epoch 1452, Loss: 0.05204092396888882, Final Batch Loss: 0.03903694450855255\n",
      "Epoch 1453, Loss: 0.030158731737174094, Final Batch Loss: 0.0019358586287125945\n",
      "Epoch 1454, Loss: 0.02994992224557791, Final Batch Loss: 0.027969665825366974\n",
      "Epoch 1455, Loss: 0.03951569115452003, Final Batch Loss: 0.0038459559436887503\n",
      "Epoch 1456, Loss: 0.0054543915030080825, Final Batch Loss: 0.00026063158293254673\n",
      "Epoch 1457, Loss: 0.06067152484320104, Final Batch Loss: 0.023369353264570236\n",
      "Epoch 1458, Loss: 0.0019484192453091964, Final Batch Loss: 0.0009251010487787426\n",
      "Epoch 1459, Loss: 0.04359100651345216, Final Batch Loss: 0.00020569081243593246\n",
      "Epoch 1460, Loss: 0.007327090948820114, Final Batch Loss: 0.0014539010589942336\n",
      "Epoch 1461, Loss: 0.019052580057177693, Final Batch Loss: 0.0005746008246205747\n",
      "Epoch 1462, Loss: 0.011356824019458145, Final Batch Loss: 0.0016723045846447349\n",
      "Epoch 1463, Loss: 0.011168071810971014, Final Batch Loss: 0.007967634126543999\n",
      "Epoch 1464, Loss: 0.0027035987441195175, Final Batch Loss: 0.00021052714146208018\n",
      "Epoch 1465, Loss: 0.019946257554693148, Final Batch Loss: 0.0002372024318901822\n",
      "Epoch 1466, Loss: 0.0479687105253106, Final Batch Loss: 0.016825875267386436\n",
      "Epoch 1467, Loss: 0.0017253591504413635, Final Batch Loss: 0.00028568741981871426\n",
      "Epoch 1468, Loss: 0.002021649155722116, Final Batch Loss: 6.561051122844219e-05\n",
      "Epoch 1469, Loss: 0.0026573764289423707, Final Batch Loss: 1.5041873666632455e-05\n",
      "Epoch 1470, Loss: 0.002257857318909373, Final Batch Loss: 6.468881474575028e-05\n",
      "Epoch 1471, Loss: 0.0009488231771683786, Final Batch Loss: 5.762334694736637e-05\n",
      "Epoch 1472, Loss: 0.004112812370294705, Final Batch Loss: 0.0030333707109093666\n",
      "Epoch 1473, Loss: 0.00298414308053907, Final Batch Loss: 0.0005712417187169194\n",
      "Epoch 1474, Loss: 0.006800783972721547, Final Batch Loss: 0.0011356218019500375\n",
      "Epoch 1475, Loss: 0.000812609912827611, Final Batch Loss: 5.731020064558834e-05\n",
      "Epoch 1476, Loss: 0.023930968338390812, Final Batch Loss: 0.0054085515439510345\n",
      "Epoch 1477, Loss: 0.0013342702441150323, Final Batch Loss: 0.0009095512214116752\n",
      "Epoch 1478, Loss: 0.01807379706588108, Final Batch Loss: 0.0008528095204383135\n",
      "Epoch 1479, Loss: 0.000927583037992008, Final Batch Loss: 0.0003299932577647269\n",
      "Epoch 1480, Loss: 0.005542579339817166, Final Batch Loss: 0.00019546953262761235\n",
      "Epoch 1481, Loss: 0.0036696510505862534, Final Batch Loss: 6.990437395870686e-05\n",
      "Epoch 1482, Loss: 0.0033455681659688707, Final Batch Loss: 3.760409526876174e-05\n",
      "Epoch 1483, Loss: 0.0014759604673599824, Final Batch Loss: 0.00033052265644073486\n",
      "Epoch 1484, Loss: 0.01463231477100635, Final Batch Loss: 8.967409667093307e-05\n",
      "Epoch 1485, Loss: 0.002465546363964677, Final Batch Loss: 0.0005298492033034563\n",
      "Epoch 1486, Loss: 0.001984382819500752, Final Batch Loss: 0.00022644098498858511\n",
      "Epoch 1487, Loss: 0.006248814883292653, Final Batch Loss: 0.005190106108784676\n",
      "Epoch 1488, Loss: 0.00957341089088004, Final Batch Loss: 0.007399430964142084\n",
      "Epoch 1489, Loss: 0.005037736147642136, Final Batch Loss: 0.0010016103042289615\n",
      "Epoch 1490, Loss: 0.001551490535348421, Final Batch Loss: 2.8995473257964477e-05\n",
      "Epoch 1491, Loss: 0.016135455516632646, Final Batch Loss: 0.00017294258577749133\n",
      "Epoch 1492, Loss: 0.003906661848304793, Final Batch Loss: 0.000380086392397061\n",
      "Epoch 1493, Loss: 0.00709586212906288, Final Batch Loss: 0.00016504505765624344\n",
      "Epoch 1494, Loss: 0.0015198572800727561, Final Batch Loss: 8.413810428464785e-05\n",
      "Epoch 1495, Loss: 0.005580020893830806, Final Batch Loss: 0.0005394308245740831\n",
      "Epoch 1496, Loss: 0.0009681887167971581, Final Batch Loss: 0.00023179657000582665\n",
      "Epoch 1497, Loss: 0.003098275716183707, Final Batch Loss: 0.0019389124354347587\n",
      "Epoch 1498, Loss: 0.003134441692964174, Final Batch Loss: 0.0011797609040513635\n",
      "Epoch 1499, Loss: 0.0019050269474973902, Final Batch Loss: 0.00021148067025933415\n",
      "Epoch 1500, Loss: 0.0013637078809551895, Final Batch Loss: 0.00018529802036937326\n",
      "Epoch 1501, Loss: 0.012999713217141107, Final Batch Loss: 2.1704036043956876e-05\n",
      "Epoch 1502, Loss: 0.005348799808416516, Final Batch Loss: 0.00018138322047889233\n",
      "Epoch 1503, Loss: 0.000841536711959634, Final Batch Loss: 0.0003867996856570244\n",
      "Epoch 1504, Loss: 0.03618779616954271, Final Batch Loss: 0.023990008980035782\n",
      "Epoch 1505, Loss: 0.00263158704910893, Final Batch Loss: 0.0004677482647821307\n",
      "Epoch 1506, Loss: 0.001699511987681035, Final Batch Loss: 0.0004960448713973165\n",
      "Epoch 1507, Loss: 0.02046082736342214, Final Batch Loss: 0.000224203773541376\n",
      "Epoch 1508, Loss: 0.0010479342163307592, Final Batch Loss: 0.0003040504816453904\n",
      "Epoch 1509, Loss: 0.004168305455095833, Final Batch Loss: 6.087835572543554e-05\n",
      "Epoch 1510, Loss: 0.0016124529229273321, Final Batch Loss: 7.844940409995615e-05\n",
      "Epoch 1511, Loss: 0.003211985051166266, Final Batch Loss: 0.0019126328406855464\n",
      "Epoch 1512, Loss: 0.0010918084371951409, Final Batch Loss: 3.6375102354213595e-05\n",
      "Epoch 1513, Loss: 0.0029439030186040327, Final Batch Loss: 0.00017769708938430995\n",
      "Epoch 1514, Loss: 0.0008480222277285066, Final Batch Loss: 0.000349236186593771\n",
      "Epoch 1515, Loss: 0.035396989158471115, Final Batch Loss: 0.00026429619174450636\n",
      "Epoch 1516, Loss: 0.008146726235281676, Final Batch Loss: 0.0007986113196238875\n",
      "Epoch 1517, Loss: 0.0022768952476326376, Final Batch Loss: 0.0001657089014770463\n",
      "Epoch 1518, Loss: 0.007566810723801609, Final Batch Loss: 0.006730562541633844\n",
      "Epoch 1519, Loss: 0.0027028253534808755, Final Batch Loss: 5.429207521956414e-05\n",
      "Epoch 1520, Loss: 0.00039089829806471244, Final Batch Loss: 8.949388575274497e-05\n",
      "Epoch 1521, Loss: 0.002862268971512094, Final Batch Loss: 4.707573680207133e-05\n",
      "Epoch 1522, Loss: 0.0026481501408852637, Final Batch Loss: 0.00018206372624263167\n",
      "Epoch 1523, Loss: 0.002777780347969383, Final Batch Loss: 0.0001053056403179653\n",
      "Epoch 1524, Loss: 0.0015988659870345145, Final Batch Loss: 0.00031966244569048285\n",
      "Epoch 1525, Loss: 0.0011600981088122353, Final Batch Loss: 0.0006558739114552736\n",
      "Epoch 1526, Loss: 0.0017746639205142856, Final Batch Loss: 0.0003730114840436727\n",
      "Epoch 1527, Loss: 0.0030789314841968007, Final Batch Loss: 0.0001154434066847898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1528, Loss: 0.002252916179713793, Final Batch Loss: 0.00022825715132057667\n",
      "Epoch 1529, Loss: 0.0007895749549788889, Final Batch Loss: 3.808396650128998e-05\n",
      "Epoch 1530, Loss: 0.0006502486539829988, Final Batch Loss: 3.505970016703941e-05\n",
      "Epoch 1531, Loss: 0.0056191715120803565, Final Batch Loss: 0.00029205103055574\n",
      "Epoch 1532, Loss: 0.0004981196962035028, Final Batch Loss: 4.914414239465259e-05\n",
      "Epoch 1533, Loss: 0.0006724477207171731, Final Batch Loss: 0.00017553243378642946\n",
      "Epoch 1534, Loss: 0.0021565502720477525, Final Batch Loss: 4.609665120369755e-05\n",
      "Epoch 1535, Loss: 0.0018742553947959095, Final Batch Loss: 0.00018674114835448563\n",
      "Epoch 1536, Loss: 0.0007294151728274301, Final Batch Loss: 9.667682024883106e-05\n",
      "Epoch 1537, Loss: 0.013139787828549743, Final Batch Loss: 0.0006526494398713112\n",
      "Epoch 1538, Loss: 0.0012074243641109206, Final Batch Loss: 0.0004539198998827487\n",
      "Epoch 1539, Loss: 0.0022691936464980245, Final Batch Loss: 0.0002388590364716947\n",
      "Epoch 1540, Loss: 0.0007743504784230026, Final Batch Loss: 6.311115612334106e-06\n",
      "Epoch 1541, Loss: 0.006702830112772062, Final Batch Loss: 7.459043990820646e-05\n",
      "Epoch 1542, Loss: 0.0013230869044491556, Final Batch Loss: 0.00019525550305843353\n",
      "Epoch 1543, Loss: 0.012345144932623953, Final Batch Loss: 0.011084482073783875\n",
      "Epoch 1544, Loss: 0.0008730532208574004, Final Batch Loss: 7.786558126099408e-05\n",
      "Epoch 1545, Loss: 0.04444075984065421, Final Batch Loss: 0.0014586282195523381\n",
      "Epoch 1546, Loss: 0.0067210186389274895, Final Batch Loss: 0.0006226846599020064\n",
      "Epoch 1547, Loss: 0.010707619599997997, Final Batch Loss: 0.0024266589898616076\n",
      "Epoch 1548, Loss: 0.00194980717060389, Final Batch Loss: 0.00023893217439763248\n",
      "Epoch 1549, Loss: 0.02996404396253638, Final Batch Loss: 0.022004608064889908\n",
      "Epoch 1550, Loss: 0.012360940119833685, Final Batch Loss: 0.00018337216170039028\n",
      "Epoch 1551, Loss: 0.022062942996853963, Final Batch Loss: 0.005807167384773493\n",
      "Epoch 1552, Loss: 0.0010897826286964118, Final Batch Loss: 0.00012803019490092993\n",
      "Epoch 1553, Loss: 0.0015226847608573735, Final Batch Loss: 0.00034513967693783343\n",
      "Epoch 1554, Loss: 0.000950743407884147, Final Batch Loss: 6.118439341662452e-05\n",
      "Epoch 1555, Loss: 0.002994778442371171, Final Batch Loss: 0.002192117739468813\n",
      "Epoch 1556, Loss: 0.005564278006204404, Final Batch Loss: 0.0007214554934762418\n",
      "Epoch 1557, Loss: 0.0014735297809238546, Final Batch Loss: 0.001057319575920701\n",
      "Epoch 1558, Loss: 0.0028249423412489705, Final Batch Loss: 0.0008932516793720424\n",
      "Epoch 1559, Loss: 0.005672265746397898, Final Batch Loss: 0.0019176492933183908\n",
      "Epoch 1560, Loss: 0.029704224143642932, Final Batch Loss: 0.0005141546716913581\n",
      "Epoch 1561, Loss: 0.0007871443158364855, Final Batch Loss: 0.0004289255593903363\n",
      "Epoch 1562, Loss: 0.007242142302857246, Final Batch Loss: 0.0004889001720584929\n",
      "Epoch 1563, Loss: 0.0021726709164795466, Final Batch Loss: 0.0004319974686950445\n",
      "Epoch 1564, Loss: 0.0012468761851778254, Final Batch Loss: 0.00015031188377179205\n",
      "Epoch 1565, Loss: 0.00575637370639015, Final Batch Loss: 0.0009495429112575948\n",
      "Epoch 1566, Loss: 0.019248133903602138, Final Batch Loss: 0.000252807280048728\n",
      "Epoch 1567, Loss: 0.0007275599709828384, Final Batch Loss: 0.0001790458190953359\n",
      "Epoch 1568, Loss: 0.005166306451428682, Final Batch Loss: 0.004318952094763517\n",
      "Epoch 1569, Loss: 0.01706509399082279, Final Batch Loss: 0.015609638765454292\n",
      "Epoch 1570, Loss: 0.002068905308988178, Final Batch Loss: 0.001096312771551311\n",
      "Epoch 1571, Loss: 0.0033442793355789036, Final Batch Loss: 0.00022280917619355023\n",
      "Epoch 1572, Loss: 0.003696149229654111, Final Batch Loss: 0.0013581038219854236\n",
      "Epoch 1573, Loss: 0.012566403813252691, Final Batch Loss: 5.732169665861875e-05\n",
      "Epoch 1574, Loss: 0.00260607831296511, Final Batch Loss: 0.00025070502306334674\n",
      "Epoch 1575, Loss: 0.0012507520950748585, Final Batch Loss: 6.875357212265953e-05\n",
      "Epoch 1576, Loss: 0.0030394951027119532, Final Batch Loss: 8.55714242788963e-05\n",
      "Epoch 1577, Loss: 0.0013662738128914498, Final Batch Loss: 9.538737504044548e-05\n",
      "Epoch 1578, Loss: 0.0013190828467486426, Final Batch Loss: 0.0003309869207441807\n",
      "Epoch 1579, Loss: 0.011431271937908605, Final Batch Loss: 8.266819349955767e-05\n",
      "Epoch 1580, Loss: 0.002131291010300629, Final Batch Loss: 0.0002020833344431594\n",
      "Epoch 1581, Loss: 0.0008091351901384769, Final Batch Loss: 2.7022235371987335e-05\n",
      "Epoch 1582, Loss: 0.004290223834686913, Final Batch Loss: 4.205256118439138e-05\n",
      "Epoch 1583, Loss: 0.0031853995751589537, Final Batch Loss: 0.000641115359030664\n",
      "Epoch 1584, Loss: 0.008861411246471107, Final Batch Loss: 0.00046593070146627724\n",
      "Epoch 1585, Loss: 0.0013772661550319754, Final Batch Loss: 9.084462362807244e-05\n",
      "Epoch 1586, Loss: 0.001605857425602153, Final Batch Loss: 0.0002284833462908864\n",
      "Epoch 1587, Loss: 0.03596812875912292, Final Batch Loss: 4.517636989476159e-05\n",
      "Epoch 1588, Loss: 0.0018016777030425146, Final Batch Loss: 0.0009112472180277109\n",
      "Epoch 1589, Loss: 0.0040096813281707, Final Batch Loss: 6.079140803194605e-05\n",
      "Epoch 1590, Loss: 0.005796584933705162, Final Batch Loss: 0.00013264564040582627\n",
      "Epoch 1591, Loss: 0.0030314156028907746, Final Batch Loss: 1.5910511137917638e-05\n",
      "Epoch 1592, Loss: 0.002310916348505998, Final Batch Loss: 0.00016270048217847943\n",
      "Epoch 1593, Loss: 0.002205124001193326, Final Batch Loss: 6.740347453160211e-05\n",
      "Epoch 1594, Loss: 0.00042064065564773045, Final Batch Loss: 0.00023030875308904797\n",
      "Epoch 1595, Loss: 0.0012334370248936466, Final Batch Loss: 1.2917119420308154e-05\n",
      "Epoch 1596, Loss: 0.0006168125873955432, Final Batch Loss: 1.3252025382826105e-05\n",
      "Epoch 1597, Loss: 0.0011694597324094502, Final Batch Loss: 1.576763497723732e-05\n",
      "Epoch 1598, Loss: 0.0007368062924797414, Final Batch Loss: 0.00016920515918172896\n",
      "Epoch 1599, Loss: 0.0007190770065790275, Final Batch Loss: 0.00013847328955307603\n",
      "Epoch 1600, Loss: 0.015109496172954096, Final Batch Loss: 4.4173542846692726e-05\n",
      "Epoch 1601, Loss: 0.0005900536580156768, Final Batch Loss: 2.4768591174506582e-05\n",
      "Epoch 1602, Loss: 0.0006753031557309441, Final Batch Loss: 8.160227298503742e-05\n",
      "Epoch 1603, Loss: 0.0005273191327432869, Final Batch Loss: 3.243353057769127e-05\n",
      "Epoch 1604, Loss: 0.0021620556653942913, Final Batch Loss: 0.0006723680999130011\n",
      "Epoch 1605, Loss: 0.0037255383940646425, Final Batch Loss: 0.0019049257971346378\n",
      "Epoch 1606, Loss: 0.0009896554984152317, Final Batch Loss: 7.477340113837272e-05\n",
      "Epoch 1607, Loss: 0.001635003078263253, Final Batch Loss: 0.001037578098475933\n",
      "Epoch 1608, Loss: 0.003494250194307824, Final Batch Loss: 7.165522220020648e-06\n",
      "Epoch 1609, Loss: 0.0011837500769615872, Final Batch Loss: 0.0004058903723489493\n",
      "Epoch 1610, Loss: 0.000680894052493386, Final Batch Loss: 7.356389687629417e-05\n",
      "Epoch 1611, Loss: 0.0014649459253632813, Final Batch Loss: 9.467569725529756e-06\n",
      "Epoch 1612, Loss: 0.0015425596357090399, Final Batch Loss: 2.0405830582603812e-05\n",
      "Epoch 1613, Loss: 0.0010017849090218078, Final Batch Loss: 0.0005990357603877783\n",
      "Epoch 1614, Loss: 0.0003978756212745793, Final Batch Loss: 2.9623341106344014e-05\n",
      "Epoch 1615, Loss: 0.0003868541780320811, Final Batch Loss: 1.7734369976096787e-05\n",
      "Epoch 1616, Loss: 0.004207951611533645, Final Batch Loss: 2.143633355444763e-05\n",
      "Epoch 1617, Loss: 0.0013183479240979068, Final Batch Loss: 0.0001993933110497892\n",
      "Epoch 1618, Loss: 0.0007482694927603006, Final Batch Loss: 9.931715612765402e-05\n",
      "Epoch 1619, Loss: 0.0036955880786990747, Final Batch Loss: 3.900340016116388e-05\n",
      "Epoch 1620, Loss: 0.0011026656120520784, Final Batch Loss: 0.0001374973653582856\n",
      "Epoch 1621, Loss: 0.00041510574010317214, Final Batch Loss: 0.00014384651149157435\n",
      "Epoch 1622, Loss: 0.0036285858595874743, Final Batch Loss: 1.2970004718226846e-05\n",
      "Epoch 1623, Loss: 0.0005577152332989499, Final Batch Loss: 0.00012528480147011578\n",
      "Epoch 1624, Loss: 0.0007265062049555127, Final Batch Loss: 9.96515154838562e-05\n",
      "Epoch 1625, Loss: 0.0006099347483541351, Final Batch Loss: 0.00023584970040246844\n",
      "Epoch 1626, Loss: 0.0008520641567884013, Final Batch Loss: 0.00032121845288202167\n",
      "Epoch 1627, Loss: 0.01603668663301505, Final Batch Loss: 0.002034137025475502\n",
      "Epoch 1628, Loss: 0.0004736312330351211, Final Batch Loss: 8.358864579349756e-05\n",
      "Epoch 1629, Loss: 0.001977674373847549, Final Batch Loss: 9.23930638236925e-05\n",
      "Epoch 1630, Loss: 0.003026308746484574, Final Batch Loss: 9.529113594908267e-05\n",
      "Epoch 1631, Loss: 0.0008601792724221013, Final Batch Loss: 6.248229328775778e-05\n",
      "Epoch 1632, Loss: 0.00030124579279799946, Final Batch Loss: 3.715203274623491e-05\n",
      "Epoch 1633, Loss: 0.0005141978763276711, Final Batch Loss: 0.00012046507617924362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1634, Loss: 0.0011234205539949471, Final Batch Loss: 0.0006341652479022741\n",
      "Epoch 1635, Loss: 0.004411393150803633, Final Batch Loss: 0.002670146059244871\n",
      "Epoch 1636, Loss: 0.000723376124369679, Final Batch Loss: 2.9911963792983443e-05\n",
      "Epoch 1637, Loss: 0.00031757457873027306, Final Batch Loss: 8.25551469461061e-05\n",
      "Epoch 1638, Loss: 0.0017406543338438496, Final Batch Loss: 0.000998992589302361\n",
      "Epoch 1639, Loss: 0.00021121275312907528, Final Batch Loss: 1.8266238839714788e-05\n",
      "Epoch 1640, Loss: 0.012926798892294755, Final Batch Loss: 0.00961294211447239\n",
      "Epoch 1641, Loss: 0.001410957753250841, Final Batch Loss: 0.0010393444681540132\n",
      "Epoch 1642, Loss: 0.013739480455114972, Final Batch Loss: 0.0001564434205647558\n",
      "Epoch 1643, Loss: 0.0009694321270217188, Final Batch Loss: 0.0006577812600880861\n",
      "Epoch 1644, Loss: 0.022202703359653242, Final Batch Loss: 0.021338075399398804\n",
      "Epoch 1645, Loss: 0.0006914090918144211, Final Batch Loss: 0.0001538065553177148\n",
      "Epoch 1646, Loss: 0.00038059479265939444, Final Batch Loss: 2.4811350158415735e-05\n",
      "Epoch 1647, Loss: 0.00015008549235062674, Final Batch Loss: 1.7242997273569927e-05\n",
      "Epoch 1648, Loss: 0.004687872220529243, Final Batch Loss: 6.821483839303255e-05\n",
      "Epoch 1649, Loss: 0.0013080259959679097, Final Batch Loss: 0.0001835935254348442\n",
      "Epoch 1650, Loss: 0.003211671646567993, Final Batch Loss: 0.00024949698126874864\n",
      "Epoch 1651, Loss: 0.00765037868404761, Final Batch Loss: 0.002082497114315629\n",
      "Epoch 1652, Loss: 0.005538996114410111, Final Batch Loss: 0.005360560491681099\n",
      "Epoch 1653, Loss: 0.010893999709878699, Final Batch Loss: 0.00012362920097075403\n",
      "Epoch 1654, Loss: 0.0005461544787976891, Final Batch Loss: 0.00016523414524272084\n",
      "Epoch 1655, Loss: 0.007120247146758629, Final Batch Loss: 2.1578184714599047e-06\n",
      "Epoch 1656, Loss: 0.011861801671329886, Final Batch Loss: 0.0005178627325221896\n",
      "Epoch 1657, Loss: 0.0023981152044143528, Final Batch Loss: 0.0006892284727655351\n",
      "Epoch 1658, Loss: 0.0005177691236895043, Final Batch Loss: 0.0001245939201908186\n",
      "Epoch 1659, Loss: 0.005642105477818404, Final Batch Loss: 2.2910653569852002e-05\n",
      "Epoch 1660, Loss: 0.008492818247759715, Final Batch Loss: 0.0008020937093533576\n",
      "Epoch 1661, Loss: 0.00026485308899282245, Final Batch Loss: 7.371850188064855e-06\n",
      "Epoch 1662, Loss: 0.0003566473533282988, Final Batch Loss: 3.39701546181459e-05\n",
      "Epoch 1663, Loss: 0.0024356629546673503, Final Batch Loss: 0.00016885837248992175\n",
      "Epoch 1664, Loss: 0.005988335808069678, Final Batch Loss: 1.7338101315544918e-05\n",
      "Epoch 1665, Loss: 0.021468893777637277, Final Batch Loss: 0.021108310669660568\n",
      "Epoch 1666, Loss: 0.008235447388869943, Final Batch Loss: 5.012302062823437e-05\n",
      "Epoch 1667, Loss: 0.0005236714496277273, Final Batch Loss: 9.033687820192426e-05\n",
      "Epoch 1668, Loss: 0.027236358087975532, Final Batch Loss: 0.005111976061016321\n",
      "Epoch 1669, Loss: 0.02352491993588046, Final Batch Loss: 4.4780030293622985e-05\n",
      "Epoch 1670, Loss: 0.008661541123728966, Final Batch Loss: 2.9196384275564924e-05\n",
      "Epoch 1671, Loss: 0.00306003812875133, Final Batch Loss: 0.0006579964538104832\n",
      "Epoch 1672, Loss: 0.04433152421552222, Final Batch Loss: 0.042649075388908386\n",
      "Epoch 1673, Loss: 0.0015759431553306058, Final Batch Loss: 0.0005660894676111639\n",
      "Epoch 1674, Loss: 0.0010829931998159736, Final Batch Loss: 0.00028800376458093524\n",
      "Epoch 1675, Loss: 0.0031541548669338226, Final Batch Loss: 0.0006360289989970624\n",
      "Epoch 1676, Loss: 0.001457748847315088, Final Batch Loss: 0.0009350774344056845\n",
      "Epoch 1677, Loss: 0.0007465878588845953, Final Batch Loss: 9.953892731573433e-05\n",
      "Epoch 1678, Loss: 0.006927910744707333, Final Batch Loss: 3.7583649827865884e-05\n",
      "Epoch 1679, Loss: 0.0016996488193399273, Final Batch Loss: 0.00014168696361593902\n",
      "Epoch 1680, Loss: 0.0009967648074962199, Final Batch Loss: 0.00016231169865932316\n",
      "Epoch 1681, Loss: 0.006600723361771088, Final Batch Loss: 0.00606647739186883\n",
      "Epoch 1682, Loss: 0.0007081164767441805, Final Batch Loss: 7.374457345576957e-05\n",
      "Epoch 1683, Loss: 0.0038159610812726896, Final Batch Loss: 0.0002384605904808268\n",
      "Epoch 1684, Loss: 0.0007275666212080978, Final Batch Loss: 0.00020953257626388222\n",
      "Epoch 1685, Loss: 0.010824456967384322, Final Batch Loss: 0.00012794231588486582\n",
      "Epoch 1686, Loss: 0.0023507885925937444, Final Batch Loss: 0.0003855236864183098\n",
      "Epoch 1687, Loss: 0.012249798899574671, Final Batch Loss: 0.00011446295684436336\n",
      "Epoch 1688, Loss: 0.01860286173177883, Final Batch Loss: 0.0018763032276183367\n",
      "Epoch 1689, Loss: 0.0014037529253982939, Final Batch Loss: 3.4547112591098994e-05\n",
      "Epoch 1690, Loss: 0.002926119210314937, Final Batch Loss: 0.00012622546637430787\n",
      "Epoch 1691, Loss: 0.007268471905263141, Final Batch Loss: 0.00669174874201417\n",
      "Epoch 1692, Loss: 0.00031546649915981106, Final Batch Loss: 5.040731412009336e-05\n",
      "Epoch 1693, Loss: 0.0084203791921027, Final Batch Loss: 0.00015845727466512471\n",
      "Epoch 1694, Loss: 0.0483666219515726, Final Batch Loss: 0.01866583526134491\n",
      "Epoch 1695, Loss: 0.002923394669778645, Final Batch Loss: 0.00015313748735934496\n",
      "Epoch 1696, Loss: 0.001847434206865728, Final Batch Loss: 0.00027980669983662665\n",
      "Epoch 1697, Loss: 0.0015416541427839547, Final Batch Loss: 0.0007093136082403362\n",
      "Epoch 1698, Loss: 0.011918355477973819, Final Batch Loss: 0.0016387049108743668\n",
      "Epoch 1699, Loss: 0.0037495449141715653, Final Batch Loss: 0.00011793926387326792\n",
      "Epoch 1700, Loss: 0.0013743520648858976, Final Batch Loss: 2.686258449102752e-05\n",
      "Epoch 1701, Loss: 0.0027542107709450647, Final Batch Loss: 0.0013442360796034336\n",
      "Epoch 1702, Loss: 0.005736130398872774, Final Batch Loss: 0.004877791274338961\n",
      "Epoch 1703, Loss: 0.005412743317720015, Final Batch Loss: 0.00018379035464022309\n",
      "Epoch 1704, Loss: 0.0009038908610818908, Final Batch Loss: 7.227585592772812e-05\n",
      "Epoch 1705, Loss: 0.001124938076827675, Final Batch Loss: 0.00018568048835732043\n",
      "Epoch 1706, Loss: 0.005714504513889551, Final Batch Loss: 0.004392970819026232\n",
      "Epoch 1707, Loss: 0.001246463303687051, Final Batch Loss: 0.000338645011652261\n",
      "Epoch 1708, Loss: 0.011103624434326775, Final Batch Loss: 0.00019668391905725002\n",
      "Epoch 1709, Loss: 0.002225400967290625, Final Batch Loss: 0.0003515860007610172\n",
      "Epoch 1710, Loss: 0.0027195217335247435, Final Batch Loss: 0.0012039764551445842\n",
      "Epoch 1711, Loss: 0.0018920037400675938, Final Batch Loss: 0.0001176219157059677\n",
      "Epoch 1712, Loss: 0.0004588145202433225, Final Batch Loss: 5.2149862312944606e-05\n",
      "Epoch 1713, Loss: 0.003075683278439101, Final Batch Loss: 0.0007989248842932284\n",
      "Epoch 1714, Loss: 0.00115297034062678, Final Batch Loss: 0.0006631360156461596\n",
      "Epoch 1715, Loss: 0.0015873418451519683, Final Batch Loss: 0.0003563005302567035\n",
      "Epoch 1716, Loss: 0.001608966525964206, Final Batch Loss: 3.1441948522115126e-05\n",
      "Epoch 1717, Loss: 0.0011100552364951, Final Batch Loss: 0.00021084737090859562\n",
      "Epoch 1718, Loss: 0.0009859262463578489, Final Batch Loss: 4.0688941226108e-05\n",
      "Epoch 1719, Loss: 0.005909742620133329, Final Batch Loss: 0.0009910449152812362\n",
      "Epoch 1720, Loss: 0.004154890266363509, Final Batch Loss: 0.002625365275889635\n",
      "Epoch 1721, Loss: 0.008872643029462779, Final Batch Loss: 1.6678928659530357e-05\n",
      "Epoch 1722, Loss: 0.0017341263082926162, Final Batch Loss: 6.667913112323731e-05\n",
      "Epoch 1723, Loss: 0.004359636466688244, Final Batch Loss: 0.00011684923811117187\n",
      "Epoch 1724, Loss: 0.005947304172877921, Final Batch Loss: 0.005647876765578985\n",
      "Epoch 1725, Loss: 0.0011138552363263443, Final Batch Loss: 0.0004028089460916817\n",
      "Epoch 1726, Loss: 0.00043083150922029745, Final Batch Loss: 4.545483534457162e-06\n",
      "Epoch 1727, Loss: 0.0007347580976784229, Final Batch Loss: 5.468268500408158e-05\n",
      "Epoch 1728, Loss: 0.0013182140173739754, Final Batch Loss: 0.00018246147374156862\n",
      "Epoch 1729, Loss: 0.0037387444208434317, Final Batch Loss: 6.0698108427459374e-05\n",
      "Epoch 1730, Loss: 0.0053938447090331465, Final Batch Loss: 0.00048547127516940236\n",
      "Epoch 1731, Loss: 0.0023767923412378877, Final Batch Loss: 0.0007746711489744484\n",
      "Epoch 1732, Loss: 0.0011101111667812802, Final Batch Loss: 0.00010168922744924203\n",
      "Epoch 1733, Loss: 0.0005884488400624832, Final Batch Loss: 6.479674993897788e-06\n",
      "Epoch 1734, Loss: 0.0019334508833708242, Final Batch Loss: 0.00032832284341566265\n",
      "Epoch 1735, Loss: 0.021844570292159915, Final Batch Loss: 0.00016221658734139055\n",
      "Epoch 1736, Loss: 0.0013267930844449438, Final Batch Loss: 4.677190008806065e-05\n",
      "Epoch 1737, Loss: 0.0011218069994356483, Final Batch Loss: 5.299225449562073e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1738, Loss: 0.008605131857621018, Final Batch Loss: 7.835865108063444e-05\n",
      "Epoch 1739, Loss: 0.05361846517189406, Final Batch Loss: 0.015596391633152962\n",
      "Epoch 1740, Loss: 0.0006425354913517367, Final Batch Loss: 8.167804480763152e-05\n",
      "Epoch 1741, Loss: 0.002353671814489644, Final Batch Loss: 0.0007598522934131324\n",
      "Epoch 1742, Loss: 0.02288140179007314, Final Batch Loss: 0.002436005510389805\n",
      "Epoch 1743, Loss: 0.021762975524325157, Final Batch Loss: 3.9946975448401645e-05\n",
      "Epoch 1744, Loss: 0.0018088115975842811, Final Batch Loss: 0.001053439686074853\n",
      "Epoch 1745, Loss: 0.003784915963478852, Final Batch Loss: 0.0034259227104485035\n",
      "Epoch 1746, Loss: 0.003289384585514199, Final Batch Loss: 0.0002810352307278663\n",
      "Epoch 1747, Loss: 0.001082902104826644, Final Batch Loss: 0.00023861565568950027\n",
      "Epoch 1748, Loss: 0.000858504881762201, Final Batch Loss: 4.569263182929717e-05\n",
      "Epoch 1749, Loss: 0.0018179366925323848, Final Batch Loss: 0.00019940442871302366\n",
      "Epoch 1750, Loss: 0.001651010647037765, Final Batch Loss: 2.4397526431130245e-05\n",
      "Epoch 1751, Loss: 0.008374958240892738, Final Batch Loss: 6.615566235268489e-05\n",
      "Epoch 1752, Loss: 0.0018130480821128003, Final Batch Loss: 0.00026063076802529395\n",
      "Epoch 1753, Loss: 0.0019915595810289233, Final Batch Loss: 2.726658522078651e-06\n",
      "Epoch 1754, Loss: 0.0009621774152037688, Final Batch Loss: 0.00038941350067034364\n",
      "Epoch 1755, Loss: 0.0029633389494847506, Final Batch Loss: 0.0009075715206563473\n",
      "Epoch 1756, Loss: 0.0005405612937465776, Final Batch Loss: 3.112890408374369e-05\n",
      "Epoch 1757, Loss: 0.0009701104236228275, Final Batch Loss: 8.190249900508206e-06\n",
      "Epoch 1758, Loss: 0.0002286526323587168, Final Batch Loss: 9.372372733196244e-05\n",
      "Epoch 1759, Loss: 0.000368143990272074, Final Batch Loss: 2.7056563340011053e-05\n",
      "Epoch 1760, Loss: 0.00041466764560027514, Final Batch Loss: 0.00010986973211402074\n",
      "Epoch 1761, Loss: 0.007023612022749148, Final Batch Loss: 0.0001100522349588573\n",
      "Epoch 1762, Loss: 0.0030756270462006796, Final Batch Loss: 0.0020778831094503403\n",
      "Epoch 1763, Loss: 0.0004374132531665964, Final Batch Loss: 6.304615817498416e-05\n",
      "Epoch 1764, Loss: 0.0010703063317123451, Final Batch Loss: 1.3919213415647391e-05\n",
      "Epoch 1765, Loss: 0.00045514810335589573, Final Batch Loss: 6.582060450455174e-05\n",
      "Epoch 1766, Loss: 0.0011119689916085918, Final Batch Loss: 0.0002613685792312026\n",
      "Epoch 1767, Loss: 0.001000693202513503, Final Batch Loss: 9.766148286871612e-05\n",
      "Epoch 1768, Loss: 0.0005550323839997873, Final Batch Loss: 0.0003619668132159859\n",
      "Epoch 1769, Loss: 0.0017246253773919307, Final Batch Loss: 9.722820686874911e-05\n",
      "Epoch 1770, Loss: 0.0006194080197019503, Final Batch Loss: 0.00017614765965845436\n",
      "Epoch 1771, Loss: 0.00043098628157167695, Final Batch Loss: 0.00013402396871242672\n",
      "Epoch 1772, Loss: 0.0005031615255575161, Final Batch Loss: 0.00015451648505404592\n",
      "Epoch 1773, Loss: 0.0011330369743518531, Final Batch Loss: 7.806316716596484e-05\n",
      "Epoch 1774, Loss: 0.000152817097841762, Final Batch Loss: 3.209535498172045e-05\n",
      "Epoch 1775, Loss: 0.0037128847470739856, Final Batch Loss: 0.00014750218542758375\n",
      "Epoch 1776, Loss: 0.0011481714354886208, Final Batch Loss: 0.0007762133609503508\n",
      "Epoch 1777, Loss: 0.0004896608552371617, Final Batch Loss: 7.74297586758621e-06\n",
      "Epoch 1778, Loss: 0.000395365510485135, Final Batch Loss: 1.9744536984944716e-05\n",
      "Epoch 1779, Loss: 0.0009851379581959918, Final Batch Loss: 0.000691438966896385\n",
      "Epoch 1780, Loss: 0.0001300046592405124, Final Batch Loss: 5.713011432817439e-06\n",
      "Epoch 1781, Loss: 0.0003160664055030793, Final Batch Loss: 9.179005428450182e-05\n",
      "Epoch 1782, Loss: 0.0006643237102252897, Final Batch Loss: 2.9936789360363036e-05\n",
      "Epoch 1783, Loss: 0.02673355702427216, Final Batch Loss: 4.200803232379258e-05\n",
      "Epoch 1784, Loss: 0.0008348270530404989, Final Batch Loss: 0.0001400651381118223\n",
      "Epoch 1785, Loss: 0.012591822006925213, Final Batch Loss: 6.5230556174356025e-06\n",
      "Epoch 1786, Loss: 0.003840204662992619, Final Batch Loss: 0.002627940382808447\n",
      "Epoch 1787, Loss: 0.0009023125385283493, Final Batch Loss: 6.269934237934649e-05\n",
      "Epoch 1788, Loss: 0.0005708764074370265, Final Batch Loss: 0.00014877635112497956\n",
      "Epoch 1789, Loss: 0.005389304129494121, Final Batch Loss: 1.67754442372825e-05\n",
      "Epoch 1790, Loss: 0.0331634438916808, Final Batch Loss: 0.00020301870245020837\n",
      "Epoch 1791, Loss: 0.010049087372408394, Final Batch Loss: 6.92928597345599e-06\n",
      "Epoch 1792, Loss: 0.010256421403028071, Final Batch Loss: 6.943114567548037e-05\n",
      "Epoch 1793, Loss: 0.018229439074275433, Final Batch Loss: 0.0006283824914135039\n",
      "Epoch 1794, Loss: 0.0027023767470382154, Final Batch Loss: 0.0007963578100316226\n",
      "Epoch 1795, Loss: 0.000807831203474052, Final Batch Loss: 1.341316874459153e-06\n",
      "Epoch 1796, Loss: 0.004962904218700714, Final Batch Loss: 0.00430966867133975\n",
      "Epoch 1797, Loss: 0.002874112091376446, Final Batch Loss: 8.602137677371502e-05\n",
      "Epoch 1798, Loss: 0.015619298370438628, Final Batch Loss: 0.014287879690527916\n",
      "Epoch 1799, Loss: 0.035036135639529675, Final Batch Loss: 8.26675386633724e-06\n",
      "Epoch 1800, Loss: 0.004285647984488605, Final Batch Loss: 4.754837846121518e-06\n",
      "Epoch 1801, Loss: 0.014168568632157985, Final Batch Loss: 0.0009651579312048852\n",
      "Epoch 1802, Loss: 0.011560049628315028, Final Batch Loss: 9.465926996199414e-05\n",
      "Epoch 1803, Loss: 0.0007783815963193774, Final Batch Loss: 0.00010834353452082723\n",
      "Epoch 1804, Loss: 0.0010656386730261147, Final Batch Loss: 0.00010625926370266825\n",
      "Epoch 1805, Loss: 0.004169067651673686, Final Batch Loss: 0.00015916838310658932\n",
      "Epoch 1806, Loss: 0.001279488977161236, Final Batch Loss: 0.00024034638772718608\n",
      "Epoch 1807, Loss: 0.0012424698870745488, Final Batch Loss: 5.3079282224643975e-05\n",
      "Epoch 1808, Loss: 0.000772251863963902, Final Batch Loss: 0.0002798620262183249\n",
      "Epoch 1809, Loss: 0.0008061750777415, Final Batch Loss: 0.00029439193895086646\n",
      "Epoch 1810, Loss: 0.0079385325389012, Final Batch Loss: 2.4300237782881595e-05\n",
      "Epoch 1811, Loss: 0.0009469680444453843, Final Batch Loss: 0.00011742175411200151\n",
      "Epoch 1812, Loss: 0.006998707722232211, Final Batch Loss: 0.005267841275781393\n",
      "Epoch 1813, Loss: 0.0009318889351561666, Final Batch Loss: 4.4441738282330334e-05\n",
      "Epoch 1814, Loss: 0.013675570371560752, Final Batch Loss: 0.0002927515597548336\n",
      "Epoch 1815, Loss: 0.002868945521186106, Final Batch Loss: 3.709007432917133e-05\n",
      "Epoch 1816, Loss: 0.0027101034647785127, Final Batch Loss: 0.0006134244031272829\n",
      "Epoch 1817, Loss: 0.001718096355034504, Final Batch Loss: 0.0005204745684750378\n",
      "Epoch 1818, Loss: 0.0031883656629361212, Final Batch Loss: 0.00044509817962534726\n",
      "Epoch 1819, Loss: 0.020825153580517508, Final Batch Loss: 4.319056461099535e-05\n",
      "Epoch 1820, Loss: 0.0014061695255804807, Final Batch Loss: 8.737010648474097e-05\n",
      "Epoch 1821, Loss: 0.01766535702336114, Final Batch Loss: 0.0006700369995087385\n",
      "Epoch 1822, Loss: 0.007856700347474543, Final Batch Loss: 0.00014383722736965865\n",
      "Epoch 1823, Loss: 0.0005824090167152463, Final Batch Loss: 2.310354284418281e-05\n",
      "Epoch 1824, Loss: 0.0008507507955073379, Final Batch Loss: 0.0002852794714272022\n",
      "Epoch 1825, Loss: 0.0015218645239656325, Final Batch Loss: 0.0007756543345749378\n",
      "Epoch 1826, Loss: 0.003853564281598665, Final Batch Loss: 0.00023863292881287634\n",
      "Epoch 1827, Loss: 0.00042060967462020926, Final Batch Loss: 6.906282214913517e-05\n",
      "Epoch 1828, Loss: 0.0034545169983175583, Final Batch Loss: 0.00019474708824418485\n",
      "Epoch 1829, Loss: 0.00566227882700332, Final Batch Loss: 9.514506382402033e-05\n",
      "Epoch 1830, Loss: 0.0007151364079618361, Final Batch Loss: 5.8297064242651686e-05\n",
      "Epoch 1831, Loss: 0.0006949349044589326, Final Batch Loss: 8.948300819611177e-05\n",
      "Epoch 1832, Loss: 0.0021996402938384563, Final Batch Loss: 0.0006375520024448633\n",
      "Epoch 1833, Loss: 0.003973687540565152, Final Batch Loss: 0.000239242595853284\n",
      "Epoch 1834, Loss: 0.0088129460636992, Final Batch Loss: 0.0015527562936767936\n",
      "Epoch 1835, Loss: 0.0018985060014529154, Final Batch Loss: 4.849415199714713e-05\n",
      "Epoch 1836, Loss: 0.0006462941128120292, Final Batch Loss: 0.00020647875498980284\n",
      "Epoch 1837, Loss: 0.0010233560569758993, Final Batch Loss: 7.236543751787394e-05\n",
      "Epoch 1838, Loss: 0.0018836329254554585, Final Batch Loss: 0.00030236339080147445\n",
      "Epoch 1839, Loss: 0.001538296175567666, Final Batch Loss: 0.0003667355631478131\n",
      "Epoch 1840, Loss: 0.004281866891687969, Final Batch Loss: 3.4349581255810335e-05\n",
      "Epoch 1841, Loss: 0.0007552045208285563, Final Batch Loss: 0.0004308322968427092\n",
      "Epoch 1842, Loss: 0.0010064676771435188, Final Batch Loss: 0.00031972405849955976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1843, Loss: 0.0025039993452082854, Final Batch Loss: 0.001945927506312728\n",
      "Epoch 1844, Loss: 0.0015438758564414456, Final Batch Loss: 6.367296737153083e-05\n",
      "Epoch 1845, Loss: 0.00027604904607869685, Final Batch Loss: 8.039246313273907e-05\n",
      "Epoch 1846, Loss: 0.0007430081477650674, Final Batch Loss: 2.543926348153036e-05\n",
      "Epoch 1847, Loss: 0.0007082429419824621, Final Batch Loss: 2.2080761482357047e-05\n",
      "Epoch 1848, Loss: 0.0005413523504103068, Final Batch Loss: 6.14501113886945e-05\n",
      "Epoch 1849, Loss: 0.00024239149934146553, Final Batch Loss: 1.712069206405431e-05\n",
      "Epoch 1850, Loss: 0.001041484130837489, Final Batch Loss: 0.0004558026266749948\n",
      "Epoch 1851, Loss: 0.000894999356205517, Final Batch Loss: 0.0005558885168284178\n",
      "Epoch 1852, Loss: 0.00015579738828819245, Final Batch Loss: 5.058395254309289e-05\n",
      "Epoch 1853, Loss: 0.0006006751682434697, Final Batch Loss: 0.00010814513370860368\n",
      "Epoch 1854, Loss: 0.0005595673555944813, Final Batch Loss: 1.144052112067584e-05\n",
      "Epoch 1855, Loss: 0.0009221616719514714, Final Batch Loss: 8.295141924463678e-06\n",
      "Epoch 1856, Loss: 0.005053909661000944, Final Batch Loss: 1.7057331206160598e-05\n",
      "Epoch 1857, Loss: 0.0003077552937611472, Final Batch Loss: 0.00010405643843114376\n",
      "Epoch 1858, Loss: 0.0022451776239904575, Final Batch Loss: 5.3146082791499794e-05\n",
      "Epoch 1859, Loss: 0.0012260564799362328, Final Batch Loss: 4.891175194643438e-05\n",
      "Epoch 1860, Loss: 0.0032339542085537687, Final Batch Loss: 5.506258821696974e-05\n",
      "Epoch 1861, Loss: 0.009176376886898652, Final Batch Loss: 0.008215521462261677\n",
      "Epoch 1862, Loss: 0.001056621225870913, Final Batch Loss: 3.346058292663656e-05\n",
      "Epoch 1863, Loss: 0.0006102229308453389, Final Batch Loss: 0.0002672990958672017\n",
      "Epoch 1864, Loss: 0.0007344042569457088, Final Batch Loss: 8.607037307228893e-05\n",
      "Epoch 1865, Loss: 0.0010958620987366885, Final Batch Loss: 4.790534148924053e-05\n",
      "Epoch 1866, Loss: 0.0004901797310594702, Final Batch Loss: 1.8377249944023788e-05\n",
      "Epoch 1867, Loss: 0.0008118934092635754, Final Batch Loss: 2.3347882233792916e-05\n",
      "Epoch 1868, Loss: 0.0014417440761462785, Final Batch Loss: 0.0001696039835223928\n",
      "Epoch 1869, Loss: 0.00026215810430585407, Final Batch Loss: 5.0642742280615494e-05\n",
      "Epoch 1870, Loss: 0.0005754769263148773, Final Batch Loss: 1.240852361661382e-05\n",
      "Epoch 1871, Loss: 0.009866892687568907, Final Batch Loss: 0.006727523170411587\n",
      "Epoch 1872, Loss: 0.0009971478311854298, Final Batch Loss: 9.266123925044667e-06\n",
      "Epoch 1873, Loss: 0.0009659327188273892, Final Batch Loss: 0.000355702853994444\n",
      "Epoch 1874, Loss: 0.0017423090030206367, Final Batch Loss: 0.0003520158934406936\n",
      "Epoch 1875, Loss: 0.023103731859009713, Final Batch Loss: 5.7926823501475155e-05\n",
      "Epoch 1876, Loss: 0.002534718019887805, Final Batch Loss: 0.0001966374256880954\n",
      "Epoch 1877, Loss: 0.018161453426728258, Final Batch Loss: 5.094470179756172e-05\n",
      "Epoch 1878, Loss: 0.0014839764771750197, Final Batch Loss: 8.090872142929584e-05\n",
      "Epoch 1879, Loss: 0.0030097870621830225, Final Batch Loss: 0.000928552180994302\n",
      "Epoch 1880, Loss: 0.012740867518004961, Final Batch Loss: 5.49918768228963e-05\n",
      "Epoch 1881, Loss: 0.03432182071628631, Final Batch Loss: 3.8633977965218946e-05\n",
      "Epoch 1882, Loss: 0.00848821798717836, Final Batch Loss: 0.0002308047260157764\n",
      "Epoch 1883, Loss: 0.0007098036676325137, Final Batch Loss: 3.1917392334435135e-05\n",
      "Epoch 1884, Loss: 0.001536673924420029, Final Batch Loss: 0.0002409511071164161\n",
      "Epoch 1885, Loss: 0.002724422956816852, Final Batch Loss: 0.0004570219898596406\n",
      "Epoch 1886, Loss: 0.0013895559532102197, Final Batch Loss: 0.0004360009916126728\n",
      "Epoch 1887, Loss: 0.027664995574923523, Final Batch Loss: 0.00044532050378620625\n",
      "Epoch 1888, Loss: 0.00043025276318076067, Final Batch Loss: 5.31276709807571e-05\n",
      "Epoch 1889, Loss: 0.0005021772485633846, Final Batch Loss: 0.00015116938448045403\n",
      "Epoch 1890, Loss: 0.002092635571898427, Final Batch Loss: 5.948687976342626e-05\n",
      "Epoch 1891, Loss: 0.0007810572569724172, Final Batch Loss: 0.00023540885013062507\n",
      "Epoch 1892, Loss: 0.001701712935755495, Final Batch Loss: 8.54223471833393e-05\n",
      "Epoch 1893, Loss: 0.0035906462144339457, Final Batch Loss: 0.00023223921016324311\n",
      "Epoch 1894, Loss: 0.0018901755611295812, Final Batch Loss: 0.0005667881341651082\n",
      "Epoch 1895, Loss: 0.00047170398829621263, Final Batch Loss: 4.037363760289736e-05\n",
      "Epoch 1896, Loss: 0.001969726203242317, Final Batch Loss: 5.357111513148993e-05\n",
      "Epoch 1897, Loss: 0.0006428232227335684, Final Batch Loss: 9.638374467613176e-05\n",
      "Epoch 1898, Loss: 0.0026039124713861383, Final Batch Loss: 0.00018931887461803854\n",
      "Epoch 1899, Loss: 0.0010098280181409791, Final Batch Loss: 0.00019606620480772108\n",
      "Epoch 1900, Loss: 0.0020015247428091243, Final Batch Loss: 0.00011039755190722644\n",
      "Epoch 1901, Loss: 0.0027970848059339914, Final Batch Loss: 0.0010070821736007929\n",
      "Epoch 1902, Loss: 0.0004360225793789141, Final Batch Loss: 0.00013204339484218508\n",
      "Epoch 1903, Loss: 0.000611379677138757, Final Batch Loss: 0.00010505828686291352\n",
      "Epoch 1904, Loss: 0.0013085893497191137, Final Batch Loss: 1.984318623726722e-05\n",
      "Epoch 1905, Loss: 0.014810047970968299, Final Batch Loss: 2.9117178200976923e-05\n",
      "Epoch 1906, Loss: 0.0050136159334215336, Final Batch Loss: 0.0034273387864232063\n",
      "Epoch 1907, Loss: 0.001782105304300785, Final Batch Loss: 0.00010282703442499042\n",
      "Epoch 1908, Loss: 0.007368415335804457, Final Batch Loss: 9.910736116580665e-05\n",
      "Epoch 1909, Loss: 0.0008687383306096308, Final Batch Loss: 0.0006050420925021172\n",
      "Epoch 1910, Loss: 0.03286010504234582, Final Batch Loss: 0.014111888594925404\n",
      "Epoch 1911, Loss: 0.009444718409213237, Final Batch Loss: 0.00022486061789095402\n",
      "Epoch 1912, Loss: 0.0011990490656899055, Final Batch Loss: 0.00023609604977536947\n",
      "Epoch 1913, Loss: 0.05324733675661264, Final Batch Loss: 7.755366823403165e-05\n",
      "Epoch 1914, Loss: 0.008814215441816486, Final Batch Loss: 0.0001091890298994258\n",
      "Epoch 1915, Loss: 0.026801001236890443, Final Batch Loss: 0.0257455762475729\n",
      "Epoch 1916, Loss: 0.022700637702655513, Final Batch Loss: 0.020437197759747505\n",
      "Epoch 1917, Loss: 0.002025178910116665, Final Batch Loss: 0.0004146165738347918\n",
      "Epoch 1918, Loss: 0.0008794519162620418, Final Batch Loss: 0.0001121610330301337\n",
      "Epoch 1919, Loss: 0.004261875961674377, Final Batch Loss: 0.0011433885665610433\n",
      "Epoch 1920, Loss: 0.033135968988062814, Final Batch Loss: 0.0005347536643967032\n",
      "Epoch 1921, Loss: 0.020352686769911088, Final Batch Loss: 0.0006195675232447684\n",
      "Epoch 1922, Loss: 0.001028992177452892, Final Batch Loss: 0.00029318241286091506\n",
      "Epoch 1923, Loss: 0.000772553827118827, Final Batch Loss: 0.0005915886140428483\n",
      "Epoch 1924, Loss: 0.004423775048053358, Final Batch Loss: 8.660057937959209e-05\n",
      "Epoch 1925, Loss: 0.002590927149867639, Final Batch Loss: 0.00015488281496800482\n",
      "Epoch 1926, Loss: 0.004051038478792179, Final Batch Loss: 5.621878517558798e-05\n",
      "Epoch 1927, Loss: 0.009454838967940304, Final Batch Loss: 0.0001707309711491689\n",
      "Epoch 1928, Loss: 0.0030445314187090844, Final Batch Loss: 0.00020472340111155063\n",
      "Epoch 1929, Loss: 0.0012592555358423851, Final Batch Loss: 0.00014351389836519957\n",
      "Epoch 1930, Loss: 0.003581681608920917, Final Batch Loss: 0.0002082569699268788\n",
      "Epoch 1931, Loss: 0.004361111976322718, Final Batch Loss: 5.4685588111169636e-05\n",
      "Epoch 1932, Loss: 0.001103788468753919, Final Batch Loss: 0.0005675897118635476\n",
      "Epoch 1933, Loss: 0.0037513547722483054, Final Batch Loss: 0.000212563929380849\n",
      "Epoch 1934, Loss: 0.000629030226264149, Final Batch Loss: 0.0004155609349254519\n",
      "Epoch 1935, Loss: 0.00570015956327552, Final Batch Loss: 6.908490468049422e-05\n",
      "Epoch 1936, Loss: 0.0005741677741752937, Final Batch Loss: 7.994693442014977e-05\n",
      "Epoch 1937, Loss: 0.0013640311990457121, Final Batch Loss: 2.5926719899871387e-05\n",
      "Epoch 1938, Loss: 0.0009863914710876998, Final Batch Loss: 3.32741292368155e-05\n",
      "Epoch 1939, Loss: 0.0004224406111461576, Final Batch Loss: 6.941280298633501e-05\n",
      "Epoch 1940, Loss: 0.0010080398060381413, Final Batch Loss: 0.0001052819425240159\n",
      "Epoch 1941, Loss: 0.0026029179825854953, Final Batch Loss: 4.1337840229971334e-05\n",
      "Epoch 1942, Loss: 0.009628497165977024, Final Batch Loss: 0.00015514282858930528\n",
      "Epoch 1943, Loss: 0.002871959310141392, Final Batch Loss: 0.00016019682516343892\n",
      "Epoch 1944, Loss: 0.000486414182887529, Final Batch Loss: 1.3149381629773416e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1945, Loss: 0.0006097321675042622, Final Batch Loss: 5.3331750677898526e-05\n",
      "Epoch 1946, Loss: 0.0004506484874582384, Final Batch Loss: 0.00025558387278579175\n",
      "Epoch 1947, Loss: 0.003216570163203869, Final Batch Loss: 0.0007889822009019554\n",
      "Epoch 1948, Loss: 0.0017572736010151857, Final Batch Loss: 4.92096069137915e-06\n",
      "Epoch 1949, Loss: 0.000873463781317696, Final Batch Loss: 0.00010300824942532927\n",
      "Epoch 1950, Loss: 0.0007035720518615562, Final Batch Loss: 9.221056825481355e-05\n",
      "Epoch 1951, Loss: 0.00457215593996807, Final Batch Loss: 2.712129571591504e-05\n",
      "Epoch 1952, Loss: 0.005088195990538225, Final Batch Loss: 0.00019388399960007519\n",
      "Epoch 1953, Loss: 0.0010168761509703472, Final Batch Loss: 9.368533210363239e-05\n",
      "Epoch 1954, Loss: 0.012089358809134865, Final Batch Loss: 8.937556231103372e-06\n",
      "Epoch 1955, Loss: 0.0015522134272032417, Final Batch Loss: 6.652017327724025e-05\n",
      "Epoch 1956, Loss: 0.001437864044419257, Final Batch Loss: 0.0002027454029303044\n",
      "Epoch 1957, Loss: 0.004092132143341587, Final Batch Loss: 1.6453277567052282e-05\n",
      "Epoch 1958, Loss: 0.0009393380823894404, Final Batch Loss: 3.843923332169652e-05\n",
      "Epoch 1959, Loss: 0.0005768449191236869, Final Batch Loss: 6.888167263241485e-05\n",
      "Epoch 1960, Loss: 0.0005169047126400983, Final Batch Loss: 6.044759356882423e-05\n",
      "Epoch 1961, Loss: 0.0006391066526703071, Final Batch Loss: 0.00015745876589789987\n",
      "Epoch 1962, Loss: 0.0008002439062693156, Final Batch Loss: 5.709974357159808e-05\n",
      "Epoch 1963, Loss: 0.0010696428507799283, Final Batch Loss: 0.00031638063956052065\n",
      "Epoch 1964, Loss: 0.0010420122680443455, Final Batch Loss: 1.3084337297186721e-05\n",
      "Epoch 1965, Loss: 0.001177511367131956, Final Batch Loss: 6.14364689681679e-05\n",
      "Epoch 1966, Loss: 0.001148134280811064, Final Batch Loss: 0.00018629238184075803\n",
      "Epoch 1967, Loss: 0.006802510983106913, Final Batch Loss: 5.001704630558379e-05\n",
      "Epoch 1968, Loss: 0.0013767101627308875, Final Batch Loss: 0.0005704081850126386\n",
      "Epoch 1969, Loss: 0.0006632178701693192, Final Batch Loss: 6.200160714797676e-05\n",
      "Epoch 1970, Loss: 0.0006516865360026713, Final Batch Loss: 6.1025191826047376e-05\n",
      "Epoch 1971, Loss: 0.0006710718625981826, Final Batch Loss: 3.097462104051374e-05\n",
      "Epoch 1972, Loss: 0.0010610197423375212, Final Batch Loss: 5.113082443131134e-05\n",
      "Epoch 1973, Loss: 0.00043822910947710625, Final Batch Loss: 4.116745458304649e-06\n",
      "Epoch 1974, Loss: 0.0003880667391058523, Final Batch Loss: 3.358583853696473e-05\n",
      "Epoch 1975, Loss: 0.0002283382664245437, Final Batch Loss: 1.24535536087933e-05\n",
      "Epoch 1976, Loss: 0.0003768419992411509, Final Batch Loss: 3.1324041628977284e-05\n",
      "Epoch 1977, Loss: 0.0006912976750754751, Final Batch Loss: 0.0001977476931642741\n",
      "Epoch 1978, Loss: 0.0012006080032733735, Final Batch Loss: 7.014958100626245e-06\n",
      "Epoch 1979, Loss: 0.017075005592232628, Final Batch Loss: 0.00018975403509102762\n",
      "Epoch 1980, Loss: 0.0011935364673263393, Final Batch Loss: 4.776549758389592e-05\n",
      "Epoch 1981, Loss: 0.0007091650004440453, Final Batch Loss: 4.5053315261611715e-05\n",
      "Epoch 1982, Loss: 0.00015084128426678944, Final Batch Loss: 1.639278889342677e-05\n",
      "Epoch 1983, Loss: 0.0011923811689484864, Final Batch Loss: 0.00011698644084390253\n",
      "Epoch 1984, Loss: 0.0008192575951397885, Final Batch Loss: 1.7319714970653877e-05\n",
      "Epoch 1985, Loss: 0.005319512885762379, Final Batch Loss: 6.184894300531596e-05\n",
      "Epoch 1986, Loss: 0.009718677021737676, Final Batch Loss: 7.173380436142907e-05\n",
      "Epoch 1987, Loss: 0.0006003652815707028, Final Batch Loss: 0.0001288197236135602\n",
      "Epoch 1988, Loss: 0.0019874309364240617, Final Batch Loss: 5.812630843138322e-05\n",
      "Epoch 1989, Loss: 0.0007854674040572718, Final Batch Loss: 2.4059118004515767e-05\n",
      "Epoch 1990, Loss: 0.001414919192029629, Final Batch Loss: 1.901948417071253e-05\n",
      "Epoch 1991, Loss: 0.0004000621429440798, Final Batch Loss: 1.747809255903121e-05\n",
      "Epoch 1992, Loss: 0.0006579928012797609, Final Batch Loss: 0.00019522469665389508\n",
      "Epoch 1993, Loss: 0.0009875636806100374, Final Batch Loss: 5.287865860736929e-06\n",
      "Epoch 1994, Loss: 0.005408342130976962, Final Batch Loss: 0.0002278773463331163\n",
      "Epoch 1995, Loss: 0.0015255670732585713, Final Batch Loss: 0.00013581411621998996\n",
      "Epoch 1996, Loss: 0.019344081250892486, Final Batch Loss: 0.019048504531383514\n",
      "Epoch 1997, Loss: 0.0019427037077548448, Final Batch Loss: 0.0014422746608033776\n",
      "Epoch 1998, Loss: 0.06733236229047179, Final Batch Loss: 0.0035328269004821777\n",
      "Epoch 1999, Loss: 0.007760175631119637, Final Batch Loss: 0.0002854900376405567\n",
      "Epoch 2000, Loss: 0.0058484862674959, Final Batch Loss: 0.0004976110067218542\n",
      "Epoch 2001, Loss: 0.02963920969341416, Final Batch Loss: 0.028877053409814835\n",
      "Epoch 2002, Loss: 0.00344918345217593, Final Batch Loss: 8.846223499858752e-05\n",
      "Epoch 2003, Loss: 0.008047290320973843, Final Batch Loss: 5.8514182455837727e-05\n",
      "Epoch 2004, Loss: 0.005787257643532939, Final Batch Loss: 0.00029512454057112336\n",
      "Epoch 2005, Loss: 0.0257891739893239, Final Batch Loss: 0.00011614451068453491\n",
      "Epoch 2006, Loss: 0.001263259480765555, Final Batch Loss: 0.0006414805538952351\n",
      "Epoch 2007, Loss: 0.004149355765548535, Final Batch Loss: 0.00012951347162015736\n",
      "Epoch 2008, Loss: 0.009041476529091597, Final Batch Loss: 5.15105202794075e-05\n",
      "Epoch 2009, Loss: 0.0036536281695589423, Final Batch Loss: 0.0001504259998910129\n",
      "Epoch 2010, Loss: 0.002665207917743828, Final Batch Loss: 0.0005568017368204892\n",
      "Epoch 2011, Loss: 0.003118048181931954, Final Batch Loss: 0.0015066361520439386\n",
      "Epoch 2012, Loss: 0.0016186539069167338, Final Batch Loss: 0.0002662102924659848\n",
      "Epoch 2013, Loss: 0.003892099375661928, Final Batch Loss: 4.3117506720591336e-05\n",
      "Epoch 2014, Loss: 0.0008888691372703761, Final Batch Loss: 5.9568432334344834e-05\n",
      "Epoch 2015, Loss: 0.00144794005973381, Final Batch Loss: 5.982756192679517e-05\n",
      "Epoch 2016, Loss: 0.0010714281670516357, Final Batch Loss: 0.00013148997095413506\n",
      "Epoch 2017, Loss: 0.0024713276652619243, Final Batch Loss: 6.703456165269017e-05\n",
      "Epoch 2018, Loss: 0.0024099181428027805, Final Batch Loss: 0.00011394153989385813\n",
      "Epoch 2019, Loss: 0.0009323707090516109, Final Batch Loss: 0.00026653031818568707\n",
      "Epoch 2020, Loss: 0.0018712338205659762, Final Batch Loss: 0.00040772705688141286\n",
      "Epoch 2021, Loss: 0.001128003656049259, Final Batch Loss: 0.00047679158160462976\n",
      "Epoch 2022, Loss: 0.0004924637951262412, Final Batch Loss: 5.2889126891386695e-06\n",
      "Epoch 2023, Loss: 0.005375735192501452, Final Batch Loss: 0.001516854390501976\n",
      "Epoch 2024, Loss: 0.010631367666064762, Final Batch Loss: 0.007028399966657162\n",
      "Epoch 2025, Loss: 0.03959532221779227, Final Batch Loss: 0.0002456724760122597\n",
      "Epoch 2026, Loss: 0.0005574697752308566, Final Batch Loss: 0.00019629814778454602\n",
      "Epoch 2027, Loss: 0.002935982105555013, Final Batch Loss: 0.0001995665516005829\n",
      "Epoch 2028, Loss: 0.0008181574557966087, Final Batch Loss: 4.9373225920135155e-05\n",
      "Epoch 2029, Loss: 0.003157385188387707, Final Batch Loss: 0.0024343652185052633\n",
      "Epoch 2030, Loss: 0.00203381144820014, Final Batch Loss: 0.0011584919411689043\n",
      "Epoch 2031, Loss: 0.0005305587092152564, Final Batch Loss: 2.8476597435656004e-05\n",
      "Epoch 2032, Loss: 0.010665530757250963, Final Batch Loss: 0.00996723398566246\n",
      "Epoch 2033, Loss: 0.001951778118382208, Final Batch Loss: 0.0003127706586383283\n",
      "Epoch 2034, Loss: 0.000949968809436541, Final Batch Loss: 7.401825132546946e-05\n",
      "Epoch 2035, Loss: 0.013848956470610574, Final Batch Loss: 0.0014470695750787854\n",
      "Epoch 2036, Loss: 0.0019332304837007541, Final Batch Loss: 0.001025386736728251\n",
      "Epoch 2037, Loss: 0.008396963616178255, Final Batch Loss: 0.0011684385826811194\n",
      "Epoch 2038, Loss: 0.001572260880493559, Final Batch Loss: 0.0006109083769842982\n",
      "Epoch 2039, Loss: 0.0021223947551334277, Final Batch Loss: 0.0006893283571116626\n",
      "Epoch 2040, Loss: 0.0445846231887117, Final Batch Loss: 0.0020477876532822847\n",
      "Epoch 2041, Loss: 0.0006350999174173921, Final Batch Loss: 0.00012750545283779502\n",
      "Epoch 2042, Loss: 0.008780866366578266, Final Batch Loss: 0.001697648549452424\n",
      "Epoch 2043, Loss: 0.003850637196592288, Final Batch Loss: 4.8675148718757555e-05\n",
      "Epoch 2044, Loss: 0.002590530682937242, Final Batch Loss: 0.0001268941123271361\n",
      "Epoch 2045, Loss: 0.0023237823697854765, Final Batch Loss: 6.432871305150911e-05\n",
      "Epoch 2046, Loss: 0.0005584571918006986, Final Batch Loss: 0.00019406937644816935\n",
      "Epoch 2047, Loss: 0.0012811634878744371, Final Batch Loss: 9.874504030449316e-05\n",
      "Epoch 2048, Loss: 0.0009777849918464199, Final Batch Loss: 0.00010100779036292806\n",
      "Epoch 2049, Loss: 0.0021438035255414434, Final Batch Loss: 0.0012689204886555672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2050, Loss: 0.0004114682124054525, Final Batch Loss: 1.2898402928840369e-05\n",
      "Epoch 2051, Loss: 0.03775363254771946, Final Batch Loss: 0.03704128786921501\n",
      "Epoch 2052, Loss: 0.0015722710959380493, Final Batch Loss: 0.0009243173408322036\n",
      "Epoch 2053, Loss: 0.011250032810494304, Final Batch Loss: 0.0014983053551986814\n",
      "Epoch 2054, Loss: 0.004781681152962847, Final Batch Loss: 2.0077637600479648e-05\n",
      "Epoch 2055, Loss: 0.0018913526837422978, Final Batch Loss: 0.000686880957800895\n",
      "Epoch 2056, Loss: 0.017026584202540107, Final Batch Loss: 0.00014105747686699033\n",
      "Epoch 2057, Loss: 0.00034714342473307624, Final Batch Loss: 2.446528378641233e-05\n",
      "Epoch 2058, Loss: 0.004043466797156725, Final Batch Loss: 0.00010411712719360366\n",
      "Epoch 2059, Loss: 0.03947552217687189, Final Batch Loss: 2.1843805370735936e-05\n",
      "Epoch 2060, Loss: 0.0006879122083773836, Final Batch Loss: 2.4690823920536786e-05\n",
      "Epoch 2061, Loss: 0.001157765495008789, Final Batch Loss: 3.377205575816333e-05\n",
      "Epoch 2062, Loss: 0.007083986303769052, Final Batch Loss: 0.001754237455315888\n",
      "Epoch 2063, Loss: 0.01751605383469723, Final Batch Loss: 7.28632730897516e-05\n",
      "Epoch 2064, Loss: 0.0017960982222575694, Final Batch Loss: 0.0007147079450078309\n",
      "Epoch 2065, Loss: 0.02691951881570276, Final Batch Loss: 0.026105154305696487\n",
      "Epoch 2066, Loss: 0.01361027897655731, Final Batch Loss: 0.0012578102760016918\n",
      "Epoch 2067, Loss: 0.0011873971488967072, Final Batch Loss: 2.7180369215784594e-05\n",
      "Epoch 2068, Loss: 0.005019794836698566, Final Batch Loss: 7.43465861887671e-05\n",
      "Epoch 2069, Loss: 0.011809965537395328, Final Batch Loss: 0.0034595360048115253\n",
      "Epoch 2070, Loss: 0.002420092532702256, Final Batch Loss: 0.0004653621290344745\n",
      "Epoch 2071, Loss: 0.0010496131508261897, Final Batch Loss: 0.00027787513681687415\n",
      "Epoch 2072, Loss: 0.0012927420284540858, Final Batch Loss: 5.8228029956808314e-05\n",
      "Epoch 2073, Loss: 0.019973823575128336, Final Batch Loss: 9.249455615645275e-05\n",
      "Epoch 2074, Loss: 0.008974378361017443, Final Batch Loss: 0.00018254829046782106\n",
      "Epoch 2075, Loss: 0.000783697889346513, Final Batch Loss: 2.4729144570301287e-05\n",
      "Epoch 2076, Loss: 0.002865122616640292, Final Batch Loss: 0.002316156169399619\n",
      "Epoch 2077, Loss: 0.0010071433644043282, Final Batch Loss: 0.00037917200825177133\n",
      "Epoch 2078, Loss: 0.00476831202104222, Final Batch Loss: 0.0022167761344462633\n",
      "Epoch 2079, Loss: 0.005276472875266336, Final Batch Loss: 7.498209015466273e-05\n",
      "Epoch 2080, Loss: 0.0023625294415978715, Final Batch Loss: 0.0005804807296954095\n",
      "Epoch 2081, Loss: 0.010927717128652148, Final Batch Loss: 0.00015552453987766057\n",
      "Epoch 2082, Loss: 0.01517756754765287, Final Batch Loss: 0.00014340202324092388\n",
      "Epoch 2083, Loss: 0.005805674603834632, Final Batch Loss: 0.00020600295101758093\n",
      "Epoch 2084, Loss: 0.0027173188645974733, Final Batch Loss: 0.00011601398728089407\n",
      "Epoch 2085, Loss: 0.0027877597603946924, Final Batch Loss: 0.0007517525227740407\n",
      "Epoch 2086, Loss: 0.0005976892898615915, Final Batch Loss: 0.00025338662089779973\n",
      "Epoch 2087, Loss: 0.0007397883491648827, Final Batch Loss: 0.00033063243608921766\n",
      "Epoch 2088, Loss: 0.002051808543910738, Final Batch Loss: 0.0017443472752347589\n",
      "Epoch 2089, Loss: 0.0006589062977582216, Final Batch Loss: 0.00015562385669909418\n",
      "Epoch 2090, Loss: 0.0008399052894674242, Final Batch Loss: 0.0002759275084827095\n",
      "Epoch 2091, Loss: 0.0010661950946087018, Final Batch Loss: 0.0004213571082800627\n",
      "Epoch 2092, Loss: 0.00929820816963911, Final Batch Loss: 0.006220467854291201\n",
      "Epoch 2093, Loss: 0.0009308985609095544, Final Batch Loss: 0.00018422288121655583\n",
      "Epoch 2094, Loss: 0.0006965378943277756, Final Batch Loss: 1.9734865418286063e-05\n",
      "Epoch 2095, Loss: 0.006304910566541366, Final Batch Loss: 0.00012745919229928404\n",
      "Epoch 2096, Loss: 0.007190791686298326, Final Batch Loss: 0.005554866045713425\n",
      "Epoch 2097, Loss: 0.0044186574523337185, Final Batch Loss: 0.0006000708672218025\n",
      "Epoch 2098, Loss: 0.0011528463310241932, Final Batch Loss: 6.30236609140411e-05\n",
      "Epoch 2099, Loss: 0.0005089228179713245, Final Batch Loss: 8.872670150594786e-06\n",
      "Epoch 2100, Loss: 0.010652775017661043, Final Batch Loss: 0.0013068561675027013\n",
      "Epoch 2101, Loss: 0.0015195581763691735, Final Batch Loss: 4.303849345888011e-05\n",
      "Epoch 2102, Loss: 0.0030386741273105145, Final Batch Loss: 0.00033989359508268535\n",
      "Epoch 2103, Loss: 0.0022762214139220305, Final Batch Loss: 0.00010213512723566964\n",
      "Epoch 2104, Loss: 0.013914356745090117, Final Batch Loss: 2.5380670649610693e-06\n",
      "Epoch 2105, Loss: 0.00045524762845161604, Final Batch Loss: 9.237738595402334e-06\n",
      "Epoch 2106, Loss: 0.000741529802326113, Final Batch Loss: 7.657531386939809e-05\n",
      "Epoch 2107, Loss: 0.0035038309506489895, Final Batch Loss: 7.219932012958452e-05\n",
      "Epoch 2108, Loss: 0.0007574652590847109, Final Batch Loss: 0.0003479577135294676\n",
      "Epoch 2109, Loss: 0.001301870357565349, Final Batch Loss: 0.0009017100092023611\n",
      "Epoch 2110, Loss: 0.0018631747789186193, Final Batch Loss: 6.000998109811917e-05\n",
      "Epoch 2111, Loss: 0.001789446389011573, Final Batch Loss: 8.635500125819817e-05\n",
      "Epoch 2112, Loss: 0.012871527462266386, Final Batch Loss: 0.00020177116675768048\n",
      "Epoch 2113, Loss: 0.003928411555534694, Final Batch Loss: 0.0023569094482809305\n",
      "Epoch 2114, Loss: 0.0007118005523807369, Final Batch Loss: 0.00020043151744175702\n",
      "Epoch 2115, Loss: 0.001461585135984933, Final Batch Loss: 1.941588197951205e-05\n",
      "Epoch 2116, Loss: 0.001811362197258859, Final Batch Loss: 0.00019065332890022546\n",
      "Epoch 2117, Loss: 0.01663298354469589, Final Batch Loss: 4.5461307308869436e-05\n",
      "Epoch 2118, Loss: 0.00018041356815956533, Final Batch Loss: 1.535188130219467e-05\n",
      "Epoch 2119, Loss: 0.0006031018201611005, Final Batch Loss: 2.7632740966510028e-05\n",
      "Epoch 2120, Loss: 0.0013517330517061055, Final Batch Loss: 0.00011099064431618899\n",
      "Epoch 2121, Loss: 0.0004907336242467863, Final Batch Loss: 3.093416671617888e-05\n",
      "Epoch 2122, Loss: 0.0010624949136399664, Final Batch Loss: 3.256455238442868e-05\n",
      "Epoch 2123, Loss: 0.0011621071462286636, Final Batch Loss: 0.00013345657498575747\n",
      "Epoch 2124, Loss: 0.0008944892724684905, Final Batch Loss: 0.00011835792247438803\n",
      "Epoch 2125, Loss: 0.0024737669591559097, Final Batch Loss: 9.559768659528345e-05\n",
      "Epoch 2126, Loss: 0.0035905374970752746, Final Batch Loss: 0.0033187654335051775\n",
      "Epoch 2127, Loss: 0.002980217195727164, Final Batch Loss: 3.3616128348512575e-05\n",
      "Epoch 2128, Loss: 0.0005526055210793857, Final Batch Loss: 0.0004152800829615444\n",
      "Epoch 2129, Loss: 0.004208307881754081, Final Batch Loss: 2.6206482743873494e-06\n",
      "Epoch 2130, Loss: 0.013950261512945872, Final Batch Loss: 0.00014607190678361803\n",
      "Epoch 2131, Loss: 0.0005981309623166453, Final Batch Loss: 3.7460722523974255e-05\n",
      "Epoch 2132, Loss: 0.00108784688563901, Final Batch Loss: 3.830365676549263e-05\n",
      "Epoch 2133, Loss: 0.000623575037025148, Final Batch Loss: 7.80300615588203e-06\n",
      "Epoch 2134, Loss: 0.001547505995404208, Final Batch Loss: 0.0005662314943037927\n",
      "Epoch 2135, Loss: 0.0009674284628999885, Final Batch Loss: 0.00021645663946401328\n",
      "Epoch 2136, Loss: 0.0006055383200873621, Final Batch Loss: 0.0002683918864931911\n",
      "Epoch 2137, Loss: 0.0029833031812813715, Final Batch Loss: 0.00019013838027603924\n",
      "Epoch 2138, Loss: 0.0005787147820228711, Final Batch Loss: 1.5848796465434134e-05\n",
      "Epoch 2139, Loss: 0.0007817870018698159, Final Batch Loss: 6.3097890233621e-05\n",
      "Epoch 2140, Loss: 0.00037721551780123264, Final Batch Loss: 3.2556690712226555e-05\n",
      "Epoch 2141, Loss: 0.04120088331728766, Final Batch Loss: 7.031697168713436e-05\n",
      "Epoch 2142, Loss: 0.0007633169325345079, Final Batch Loss: 7.677847315790132e-05\n",
      "Epoch 2143, Loss: 0.00036800801171921194, Final Batch Loss: 0.00017807487165555358\n",
      "Epoch 2144, Loss: 0.0010399628881714307, Final Batch Loss: 0.00013783949543721974\n",
      "Epoch 2145, Loss: 0.00016480615158798173, Final Batch Loss: 2.997651245095767e-05\n",
      "Epoch 2146, Loss: 0.003045457040570909, Final Batch Loss: 0.00043576298048719764\n",
      "Epoch 2147, Loss: 0.002150307689589681, Final Batch Loss: 0.0009937530849128962\n",
      "Epoch 2148, Loss: 0.0008059492975007743, Final Batch Loss: 3.205069515388459e-05\n",
      "Epoch 2149, Loss: 0.0003498000842228066, Final Batch Loss: 6.462648889282718e-05\n",
      "Epoch 2150, Loss: 0.0003918830807378981, Final Batch Loss: 3.755258148885332e-05\n",
      "Epoch 2151, Loss: 0.0006722858524881303, Final Batch Loss: 0.00018975631974171847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2152, Loss: 0.0010908326985372696, Final Batch Loss: 0.0002018410013988614\n",
      "Epoch 2153, Loss: 0.0005057228408986703, Final Batch Loss: 4.5325548853725195e-05\n",
      "Epoch 2154, Loss: 0.00325616423288011, Final Batch Loss: 0.0025915182195603848\n",
      "Epoch 2155, Loss: 0.002940367590781534, Final Batch Loss: 4.347312278696336e-05\n",
      "Epoch 2156, Loss: 0.012919014492581482, Final Batch Loss: 0.00021809469035360962\n",
      "Epoch 2157, Loss: 0.0013347251588129438, Final Batch Loss: 0.0009683191310614347\n",
      "Epoch 2158, Loss: 0.0009269047295674682, Final Batch Loss: 0.00040525628719478846\n",
      "Epoch 2159, Loss: 0.002889603360017645, Final Batch Loss: 2.4887949621188454e-05\n",
      "Epoch 2160, Loss: 0.0013519545100280084, Final Batch Loss: 0.000413080066209659\n",
      "Epoch 2161, Loss: 0.00046593619117629714, Final Batch Loss: 0.0002166987251257524\n",
      "Epoch 2162, Loss: 0.0027350866876076907, Final Batch Loss: 3.0867813620716333e-05\n",
      "Epoch 2163, Loss: 0.0007693906118220184, Final Batch Loss: 0.00013336412666831166\n",
      "Epoch 2164, Loss: 0.000580842221097555, Final Batch Loss: 9.749144373927265e-05\n",
      "Epoch 2165, Loss: 0.0030337612088260357, Final Batch Loss: 8.301966772705782e-06\n",
      "Epoch 2166, Loss: 0.0017100605655286927, Final Batch Loss: 6.598668551305309e-05\n",
      "Epoch 2167, Loss: 0.002555889226641739, Final Batch Loss: 1.0486899554962292e-05\n",
      "Epoch 2168, Loss: 0.00047343159712909255, Final Batch Loss: 8.164819519151933e-06\n",
      "Epoch 2169, Loss: 0.0003246413398301229, Final Batch Loss: 0.0001343355543212965\n",
      "Epoch 2170, Loss: 0.0013164683305149083, Final Batch Loss: 7.698644367337693e-06\n",
      "Epoch 2171, Loss: 0.0017109254208662605, Final Batch Loss: 0.00011968488979618996\n",
      "Epoch 2172, Loss: 0.0008417297358391806, Final Batch Loss: 0.0001024314115056768\n",
      "Epoch 2173, Loss: 0.0024154059901775327, Final Batch Loss: 0.0002592236560303718\n",
      "Epoch 2174, Loss: 0.0021384432384365937, Final Batch Loss: 0.0004473007284104824\n",
      "Epoch 2175, Loss: 0.0010080168622152996, Final Batch Loss: 0.0003106617950834334\n",
      "Epoch 2176, Loss: 0.00020689240136562148, Final Batch Loss: 4.53706961707212e-05\n",
      "Epoch 2177, Loss: 0.00017046597167791333, Final Batch Loss: 3.948098310502246e-05\n",
      "Epoch 2178, Loss: 0.0015240781194734154, Final Batch Loss: 0.0013743125600740314\n",
      "Epoch 2179, Loss: 0.0002576839106041007, Final Batch Loss: 4.972026727045886e-05\n",
      "Epoch 2180, Loss: 0.0006800845721954829, Final Batch Loss: 6.667745037702844e-05\n",
      "Epoch 2181, Loss: 0.0021405154639069224, Final Batch Loss: 0.0007294511888176203\n",
      "Epoch 2182, Loss: 0.00022936410641705152, Final Batch Loss: 2.344695349165704e-05\n",
      "Epoch 2183, Loss: 0.0012678366292675491, Final Batch Loss: 5.4000633099349216e-05\n",
      "Epoch 2184, Loss: 0.0002441500055283541, Final Batch Loss: 1.8222761354991235e-05\n",
      "Epoch 2185, Loss: 0.0009910774970194325, Final Batch Loss: 0.0003574932343326509\n",
      "Epoch 2186, Loss: 0.0010727482494985452, Final Batch Loss: 2.090841553581413e-05\n",
      "Epoch 2187, Loss: 0.0007848082204873208, Final Batch Loss: 3.656075932667591e-05\n",
      "Epoch 2188, Loss: 0.0002663627947185887, Final Batch Loss: 3.6100267607253045e-05\n",
      "Epoch 2189, Loss: 0.00025798964088608045, Final Batch Loss: 5.302647332428023e-05\n",
      "Epoch 2190, Loss: 0.0013829497402184643, Final Batch Loss: 0.0001343502663075924\n",
      "Epoch 2191, Loss: 0.00018830723001883598, Final Batch Loss: 6.3316811065305956e-06\n",
      "Epoch 2192, Loss: 0.02393285942162038, Final Batch Loss: 0.0011952061904594302\n",
      "Epoch 2193, Loss: 0.00090292192180641, Final Batch Loss: 0.0001957349304575473\n",
      "Epoch 2194, Loss: 0.011032216305466136, Final Batch Loss: 0.001205218257382512\n",
      "Epoch 2195, Loss: 0.00025715384481372894, Final Batch Loss: 4.207666734146187e-06\n",
      "Epoch 2196, Loss: 0.00015554875972156879, Final Batch Loss: 6.318817031569779e-05\n",
      "Epoch 2197, Loss: 0.0011481944420665968, Final Batch Loss: 0.00017475189815741032\n",
      "Epoch 2198, Loss: 0.0011680283587338636, Final Batch Loss: 0.0003352529602125287\n",
      "Epoch 2199, Loss: 0.0003006573642778676, Final Batch Loss: 0.00010127048153663054\n",
      "Epoch 2200, Loss: 0.0018415090016787872, Final Batch Loss: 0.00013310492795426399\n",
      "Epoch 2201, Loss: 0.0033600708138692426, Final Batch Loss: 8.298689863295294e-06\n",
      "Epoch 2202, Loss: 0.008955911476846268, Final Batch Loss: 3.9892449876788305e-07\n",
      "Epoch 2203, Loss: 0.0004409547182149254, Final Batch Loss: 8.306166273541749e-05\n",
      "Epoch 2204, Loss: 0.000588928648539877, Final Batch Loss: 8.588810487708542e-06\n",
      "Epoch 2205, Loss: 0.00015869715753069613, Final Batch Loss: 1.1638674550340511e-05\n",
      "Epoch 2206, Loss: 0.0011510230187923298, Final Batch Loss: 0.00016816619609016925\n",
      "Epoch 2207, Loss: 0.0006138656790426467, Final Batch Loss: 0.0002110814821207896\n",
      "Epoch 2208, Loss: 0.0002641224018589128, Final Batch Loss: 5.106030948809348e-05\n",
      "Epoch 2209, Loss: 0.006291892583249137, Final Batch Loss: 0.005887025035917759\n",
      "Epoch 2210, Loss: 0.0022008061641827226, Final Batch Loss: 0.0007868061657063663\n",
      "Epoch 2211, Loss: 0.0002870091584554757, Final Batch Loss: 1.4110427400737535e-05\n",
      "Epoch 2212, Loss: 0.0002677789634617511, Final Batch Loss: 1.8947130229207687e-05\n",
      "Epoch 2213, Loss: 0.0006647286681982223, Final Batch Loss: 7.952698069857433e-05\n",
      "Epoch 2214, Loss: 0.0008672177664266201, Final Batch Loss: 0.00031812279485166073\n",
      "Epoch 2215, Loss: 0.0008073598901319201, Final Batch Loss: 0.0004527932032942772\n",
      "Epoch 2216, Loss: 0.00037349259218899533, Final Batch Loss: 6.565803050762042e-05\n",
      "Epoch 2217, Loss: 0.0005099618661006389, Final Batch Loss: 0.00037379187415353954\n",
      "Epoch 2218, Loss: 0.00025427091713936534, Final Batch Loss: 0.00016083501395769417\n",
      "Epoch 2219, Loss: 0.00013275669698487036, Final Batch Loss: 2.3945098291733302e-05\n",
      "Epoch 2220, Loss: 0.0003802266601269366, Final Batch Loss: 2.1510299120564014e-05\n",
      "Epoch 2221, Loss: 0.002852865512295466, Final Batch Loss: 0.0007371855317614973\n",
      "Epoch 2222, Loss: 0.0014021161041455343, Final Batch Loss: 0.0011237170547246933\n",
      "Epoch 2223, Loss: 0.0026144480871153064, Final Batch Loss: 5.078770482214168e-05\n",
      "Epoch 2224, Loss: 0.00035822776317218086, Final Batch Loss: 6.40774942439748e-06\n",
      "Epoch 2225, Loss: 0.00045286018212209456, Final Batch Loss: 0.0001266031904378906\n",
      "Epoch 2226, Loss: 0.0001674994327913737, Final Batch Loss: 7.887572792242281e-06\n",
      "Epoch 2227, Loss: 0.0007736409434073721, Final Batch Loss: 9.532093827147037e-06\n",
      "Epoch 2228, Loss: 0.0002906860136135947, Final Batch Loss: 2.1954001567792147e-06\n",
      "Epoch 2229, Loss: 0.0005537926117540337, Final Batch Loss: 0.0001131222743424587\n",
      "Epoch 2230, Loss: 0.0025947594890567416, Final Batch Loss: 1.6766392946010455e-05\n",
      "Epoch 2231, Loss: 0.0003290788663434796, Final Batch Loss: 2.2492939024232328e-05\n",
      "Epoch 2232, Loss: 0.00015138884327825508, Final Batch Loss: 3.721669054357335e-05\n",
      "Epoch 2233, Loss: 0.0004458205521586933, Final Batch Loss: 1.449562932975823e-05\n",
      "Epoch 2234, Loss: 0.0004944584070472047, Final Batch Loss: 0.00010714857489801943\n",
      "Epoch 2235, Loss: 0.0004435596947587328, Final Batch Loss: 5.804071042803116e-05\n",
      "Epoch 2236, Loss: 0.0001410355131383767, Final Batch Loss: 3.482401780274813e-07\n",
      "Epoch 2237, Loss: 0.012033306659304799, Final Batch Loss: 9.799131657928228e-05\n",
      "Epoch 2238, Loss: 0.00011420174405429862, Final Batch Loss: 6.120360194472596e-05\n",
      "Epoch 2239, Loss: 0.0025280476693296805, Final Batch Loss: 0.002467117039486766\n",
      "Epoch 2240, Loss: 0.00012690687390204403, Final Batch Loss: 3.6881316191283986e-05\n",
      "Epoch 2241, Loss: 0.00018034556478596642, Final Batch Loss: 0.00013888167450204492\n",
      "Epoch 2242, Loss: 0.005860075430973666, Final Batch Loss: 0.00028659473173320293\n",
      "Epoch 2243, Loss: 0.00043069366074632853, Final Batch Loss: 9.947507351171225e-05\n",
      "Epoch 2244, Loss: 0.004965886510490236, Final Batch Loss: 0.00023021608649287373\n",
      "Epoch 2245, Loss: 0.0003444738940743264, Final Batch Loss: 1.5739005903014913e-05\n",
      "Epoch 2246, Loss: 0.006569616438355297, Final Batch Loss: 1.834347131079994e-05\n",
      "Epoch 2247, Loss: 0.0010657946513674688, Final Batch Loss: 5.883630001335405e-05\n",
      "Epoch 2248, Loss: 0.05071091117133619, Final Batch Loss: 5.661457544192672e-05\n",
      "Epoch 2249, Loss: 0.0001834419836086454, Final Batch Loss: 1.7384698367095552e-05\n",
      "Epoch 2250, Loss: 0.0006748665728082415, Final Batch Loss: 0.00010802742326632142\n",
      "Epoch 2251, Loss: 4.00455483031692e-05, Final Batch Loss: 8.300468834931962e-06\n",
      "Epoch 2252, Loss: 0.00042628590017557144, Final Batch Loss: 4.705015817307867e-05\n",
      "Epoch 2253, Loss: 0.001969388342331513, Final Batch Loss: 1.1981514944636729e-05\n",
      "Epoch 2254, Loss: 0.004933458345476538, Final Batch Loss: 3.7952762795612216e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2255, Loss: 0.0005581862992585229, Final Batch Loss: 0.0002332802105229348\n",
      "Epoch 2256, Loss: 0.0003532885566528421, Final Batch Loss: 7.160571840358898e-06\n",
      "Epoch 2257, Loss: 0.01055118757449236, Final Batch Loss: 8.85494318936253e-06\n",
      "Epoch 2258, Loss: 0.001935030857566744, Final Batch Loss: 3.7992678699083626e-05\n",
      "Epoch 2259, Loss: 0.0036822097608819604, Final Batch Loss: 8.047438313951716e-05\n",
      "Epoch 2260, Loss: 0.0006686826745863073, Final Batch Loss: 0.00011273702693870291\n",
      "Epoch 2261, Loss: 0.006214702503712033, Final Batch Loss: 0.00029436504701152444\n",
      "Epoch 2262, Loss: 0.0028221836837474257, Final Batch Loss: 5.701831105398014e-05\n",
      "Epoch 2263, Loss: 0.011082938042818569, Final Batch Loss: 0.010141762904822826\n",
      "Epoch 2264, Loss: 0.00225297468205099, Final Batch Loss: 0.0011716600274667144\n",
      "Epoch 2265, Loss: 0.0015978913506842218, Final Batch Loss: 0.0008073135977610946\n",
      "Epoch 2266, Loss: 0.07339044535547146, Final Batch Loss: 0.057284533977508545\n",
      "Epoch 2267, Loss: 0.00593235718406504, Final Batch Loss: 0.00019370140216778964\n",
      "Epoch 2268, Loss: 0.002861756227503065, Final Batch Loss: 4.3986849050270393e-05\n",
      "Epoch 2269, Loss: 0.046028812659642426, Final Batch Loss: 0.02570308931171894\n",
      "Epoch 2270, Loss: 0.011763228628296929, Final Batch Loss: 1.608879210834857e-05\n",
      "Epoch 2271, Loss: 0.029694850352825597, Final Batch Loss: 0.0007709372439421713\n",
      "Epoch 2272, Loss: 0.013615307088912232, Final Batch Loss: 1.7438240320188925e-05\n",
      "Epoch 2273, Loss: 0.0005958973979431903, Final Batch Loss: 4.8354355385527015e-05\n",
      "Epoch 2274, Loss: 0.002986057164889644, Final Batch Loss: 2.0925383068970405e-05\n",
      "Epoch 2275, Loss: 0.0004580120075843297, Final Batch Loss: 5.822408274980262e-05\n",
      "Epoch 2276, Loss: 0.0062259844489744864, Final Batch Loss: 0.00462342007085681\n",
      "Epoch 2277, Loss: 0.0010953700002573896, Final Batch Loss: 0.0005731817218475044\n",
      "Epoch 2278, Loss: 0.0012649938216782175, Final Batch Loss: 0.0008246423676609993\n",
      "Epoch 2279, Loss: 0.0005740949000028195, Final Batch Loss: 0.0003951973048970103\n",
      "Epoch 2280, Loss: 0.023246896902492153, Final Batch Loss: 0.00039122093585319817\n",
      "Epoch 2281, Loss: 0.015096442613867112, Final Batch Loss: 0.00015588510723318905\n",
      "Epoch 2282, Loss: 0.008656641581183067, Final Batch Loss: 3.680540612549521e-05\n",
      "Epoch 2283, Loss: 0.0012381609249132453, Final Batch Loss: 5.514024451258592e-06\n",
      "Epoch 2284, Loss: 0.0044815190631197765, Final Batch Loss: 0.00016213483468163759\n",
      "Epoch 2285, Loss: 0.01978923167735047, Final Batch Loss: 2.8359134375932626e-05\n",
      "Epoch 2286, Loss: 0.018369154957326828, Final Batch Loss: 3.363793439348228e-05\n",
      "Epoch 2287, Loss: 0.02855366225958278, Final Batch Loss: 0.027161190286278725\n",
      "Epoch 2288, Loss: 0.024442608610115713, Final Batch Loss: 3.4319611586397514e-05\n",
      "Epoch 2289, Loss: 0.01543232292533503, Final Batch Loss: 0.014906217344105244\n",
      "Epoch 2290, Loss: 0.0013344699545996264, Final Batch Loss: 0.0003903020406141877\n",
      "Epoch 2291, Loss: 0.0015332580951508135, Final Batch Loss: 0.00011436500062700361\n",
      "Epoch 2292, Loss: 0.006051236588973552, Final Batch Loss: 0.0024286294355988503\n",
      "Epoch 2293, Loss: 0.006241811701329425, Final Batch Loss: 0.005044258665293455\n",
      "Epoch 2294, Loss: 0.005388954799855128, Final Batch Loss: 0.0027422301936894655\n",
      "Epoch 2295, Loss: 0.0016401253669755533, Final Batch Loss: 0.00010994375043082982\n",
      "Epoch 2296, Loss: 0.0022478686514659785, Final Batch Loss: 1.9347287889104337e-05\n",
      "Epoch 2297, Loss: 0.0005456098697322886, Final Batch Loss: 4.0379625716013834e-05\n",
      "Epoch 2298, Loss: 0.00045419463094731327, Final Batch Loss: 0.00014557641407009214\n",
      "Epoch 2299, Loss: 0.0007991843594936654, Final Batch Loss: 0.000148327206261456\n",
      "Epoch 2300, Loss: 0.0014801320767219295, Final Batch Loss: 8.884931048669387e-06\n",
      "Epoch 2301, Loss: 0.015382835659693228, Final Batch Loss: 0.0008646263158880174\n",
      "Epoch 2302, Loss: 0.0004396300209918991, Final Batch Loss: 3.6867095332127064e-05\n",
      "Epoch 2303, Loss: 0.01538625168177532, Final Batch Loss: 0.0002640537277329713\n",
      "Epoch 2304, Loss: 0.003738700965186581, Final Batch Loss: 0.00018051592633128166\n",
      "Epoch 2305, Loss: 0.0007301191435544752, Final Batch Loss: 0.0004474561719689518\n",
      "Epoch 2306, Loss: 0.027778322037192993, Final Batch Loss: 0.00011246907524764538\n",
      "Epoch 2307, Loss: 0.0008472106746921781, Final Batch Loss: 2.803102324833162e-05\n",
      "Epoch 2308, Loss: 0.03792514095403021, Final Batch Loss: 0.006513476837426424\n",
      "Epoch 2309, Loss: 0.010962897868012078, Final Batch Loss: 0.0005763519438914955\n",
      "Epoch 2310, Loss: 0.0020698376756627113, Final Batch Loss: 0.0001639819674892351\n",
      "Epoch 2311, Loss: 0.001552347700453538, Final Batch Loss: 1.4311913218989503e-05\n",
      "Epoch 2312, Loss: 0.002314199265128991, Final Batch Loss: 1.0117067176906858e-05\n",
      "Epoch 2313, Loss: 0.0007090983399393735, Final Batch Loss: 0.0002112509246217087\n",
      "Epoch 2314, Loss: 0.0011843442225654144, Final Batch Loss: 3.8351765397237614e-05\n",
      "Epoch 2315, Loss: 0.0021558939188253134, Final Batch Loss: 0.00010229588224319741\n",
      "Epoch 2316, Loss: 0.0005658607115037739, Final Batch Loss: 5.927760503254831e-05\n",
      "Epoch 2317, Loss: 0.0013031010748818517, Final Batch Loss: 0.0002598442661110312\n",
      "Epoch 2318, Loss: 0.0009401682236784836, Final Batch Loss: 0.0001742405438562855\n",
      "Epoch 2319, Loss: 0.0016812014509923756, Final Batch Loss: 0.0005529084010049701\n",
      "Epoch 2320, Loss: 0.0009342047924292274, Final Batch Loss: 0.00014260299212764949\n",
      "Epoch 2321, Loss: 0.0006562795824720524, Final Batch Loss: 0.00029862846713513136\n",
      "Epoch 2322, Loss: 0.00039364306212519296, Final Batch Loss: 3.1931504054227844e-05\n",
      "Epoch 2323, Loss: 0.0008530403056283831, Final Batch Loss: 1.3759105968347285e-05\n",
      "Epoch 2324, Loss: 0.0003293023801234085, Final Batch Loss: 8.098702528513968e-05\n",
      "Epoch 2325, Loss: 0.0009216554390150122, Final Batch Loss: 7.026777893770486e-05\n",
      "Epoch 2326, Loss: 0.001511704882432241, Final Batch Loss: 8.663317566970363e-05\n",
      "Epoch 2327, Loss: 0.000929706307942979, Final Batch Loss: 0.0005941062700003386\n",
      "Epoch 2328, Loss: 0.0005827088698424632, Final Batch Loss: 0.00021558968001045287\n",
      "Epoch 2329, Loss: 0.002290378928591963, Final Batch Loss: 1.1951146007049829e-05\n",
      "Epoch 2330, Loss: 0.0009775968592293793, Final Batch Loss: 4.843010174226947e-06\n",
      "Epoch 2331, Loss: 0.0005338491396287282, Final Batch Loss: 5.775139015895547e-06\n",
      "Epoch 2332, Loss: 0.0015921524372970453, Final Batch Loss: 1.8583587007015012e-05\n",
      "Epoch 2333, Loss: 0.006179366595461033, Final Batch Loss: 0.00021652199211530387\n",
      "Epoch 2334, Loss: 0.0006626242284255568, Final Batch Loss: 0.0001536344934720546\n",
      "Epoch 2335, Loss: 0.00034296592866667197, Final Batch Loss: 7.520524832216324e-06\n",
      "Epoch 2336, Loss: 0.0011210342890990432, Final Batch Loss: 4.0007867937674746e-05\n",
      "Epoch 2337, Loss: 0.0006666699264314957, Final Batch Loss: 0.0003803841827902943\n",
      "Epoch 2338, Loss: 0.0004749176569021074, Final Batch Loss: 0.0003138596657663584\n",
      "Epoch 2339, Loss: 0.0011674748893710785, Final Batch Loss: 0.00015639656339772046\n",
      "Epoch 2340, Loss: 0.0009277512954213307, Final Batch Loss: 1.1903627637366299e-05\n",
      "Epoch 2341, Loss: 0.004634867247659713, Final Batch Loss: 6.672491144854575e-05\n",
      "Epoch 2342, Loss: 0.002787820385492523, Final Batch Loss: 1.3855511497240514e-05\n",
      "Epoch 2343, Loss: 0.00840855040041788, Final Batch Loss: 0.00791882537305355\n",
      "Epoch 2344, Loss: 0.0016329940481227823, Final Batch Loss: 9.152078564511612e-05\n",
      "Epoch 2345, Loss: 0.0013609987108793575, Final Batch Loss: 1.780140883056447e-05\n",
      "Epoch 2346, Loss: 0.00024168092386389617, Final Batch Loss: 0.00016844278434291482\n",
      "Epoch 2347, Loss: 0.00288886047565029, Final Batch Loss: 3.507722067297436e-05\n",
      "Epoch 2348, Loss: 0.00030322025600071356, Final Batch Loss: 2.360643748033908e-06\n",
      "Epoch 2349, Loss: 0.002189843446103623, Final Batch Loss: 4.519079448073171e-05\n",
      "Epoch 2350, Loss: 0.0011431175298639573, Final Batch Loss: 3.5299730370752513e-05\n",
      "Epoch 2351, Loss: 0.008950447289862495, Final Batch Loss: 0.00017446269339416176\n",
      "Epoch 2352, Loss: 0.0006609453084820416, Final Batch Loss: 0.0001870754931587726\n",
      "Epoch 2353, Loss: 0.0007308147705771262, Final Batch Loss: 1.2356076695141383e-05\n",
      "Epoch 2354, Loss: 0.0006620120329898782, Final Batch Loss: 0.00018392007041256875\n",
      "Epoch 2355, Loss: 0.00031219935044646263, Final Batch Loss: 3.520887912600301e-05\n",
      "Epoch 2356, Loss: 0.0010554728542047087, Final Batch Loss: 0.0007910400745458901\n",
      "Epoch 2357, Loss: 0.03274235621211119, Final Batch Loss: 0.0014832590240985155\n",
      "Epoch 2358, Loss: 0.00208622699665284, Final Batch Loss: 5.715413499274291e-05\n",
      "Epoch 2359, Loss: 0.002852658544725273, Final Batch Loss: 0.0001189381000585854\n",
      "Epoch 2360, Loss: 0.006553145008183492, Final Batch Loss: 1.111021174438065e-05\n",
      "Epoch 2361, Loss: 0.003765243396628648, Final Batch Loss: 0.0009056776762008667\n",
      "Epoch 2362, Loss: 0.0003273512775194831, Final Batch Loss: 0.0001760742161422968\n",
      "Epoch 2363, Loss: 0.0033260018135479186, Final Batch Loss: 8.11007630545646e-05\n",
      "Epoch 2364, Loss: 0.0008117089782899711, Final Batch Loss: 4.9381207645637915e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2365, Loss: 0.0017200948805111693, Final Batch Loss: 3.8099544326541945e-05\n",
      "Epoch 2366, Loss: 0.00032882907180464827, Final Batch Loss: 4.696802352555096e-05\n",
      "Epoch 2367, Loss: 0.00015134438217501156, Final Batch Loss: 6.330614269245416e-06\n",
      "Epoch 2368, Loss: 0.0007831977563910186, Final Batch Loss: 6.918496364960447e-05\n",
      "Epoch 2369, Loss: 0.004015412081571412, Final Batch Loss: 2.0087194570805877e-05\n",
      "Epoch 2370, Loss: 0.0003245525495003676, Final Batch Loss: 5.782005246146582e-06\n",
      "Epoch 2371, Loss: 0.008652758318930864, Final Batch Loss: 3.2098749215947464e-05\n",
      "Epoch 2372, Loss: 0.008719216253666673, Final Batch Loss: 0.007033623289316893\n",
      "Epoch 2373, Loss: 0.0006795585759391543, Final Batch Loss: 0.00038244648021645844\n",
      "Epoch 2374, Loss: 0.014418375802051742, Final Batch Loss: 0.0012206967221572995\n",
      "Epoch 2375, Loss: 0.000476906070161931, Final Batch Loss: 7.404539701383328e-06\n",
      "Epoch 2376, Loss: 0.01780502211477142, Final Batch Loss: 0.00019539477943908423\n",
      "Epoch 2377, Loss: 0.019000849319127155, Final Batch Loss: 5.411992242443375e-05\n",
      "Epoch 2378, Loss: 0.004558721047942527, Final Batch Loss: 0.00014503460261039436\n",
      "Epoch 2379, Loss: 0.0003866010520141572, Final Batch Loss: 3.2835465390235186e-05\n",
      "Epoch 2380, Loss: 0.0016825998500280548, Final Batch Loss: 0.00041156867519021034\n",
      "Epoch 2381, Loss: 0.007340980795561336, Final Batch Loss: 0.006820571608841419\n",
      "Epoch 2382, Loss: 0.0010121022933162749, Final Batch Loss: 0.0006128156092017889\n",
      "Epoch 2383, Loss: 0.0027836445333377924, Final Batch Loss: 0.00011258473386988044\n",
      "Epoch 2384, Loss: 0.0018724549681792269, Final Batch Loss: 2.751139436441008e-05\n",
      "Epoch 2385, Loss: 0.0021651361603289843, Final Batch Loss: 0.0013960986398160458\n",
      "Epoch 2386, Loss: 0.0006095651824580273, Final Batch Loss: 2.9631799407070503e-05\n",
      "Epoch 2387, Loss: 0.0025048507086467, Final Batch Loss: 0.0018603913486003876\n",
      "Epoch 2388, Loss: 0.0006388115507434122, Final Batch Loss: 0.00011335189628880471\n",
      "Epoch 2389, Loss: 0.0004889588317382731, Final Batch Loss: 9.696704364614561e-05\n",
      "Epoch 2390, Loss: 0.0007547708328274894, Final Batch Loss: 1.5179389265540522e-05\n",
      "Epoch 2391, Loss: 0.0016885153236216865, Final Batch Loss: 0.0012808976462110877\n",
      "Epoch 2392, Loss: 0.0007046012324281037, Final Batch Loss: 0.0002505109296180308\n",
      "Epoch 2393, Loss: 0.00207992553623626, Final Batch Loss: 5.728578980779275e-05\n",
      "Epoch 2394, Loss: 0.0007063115772325546, Final Batch Loss: 0.00024104186741169542\n",
      "Epoch 2395, Loss: 0.0002427605249977205, Final Batch Loss: 6.508797378046438e-05\n",
      "Epoch 2396, Loss: 0.0008334324302268215, Final Batch Loss: 0.0003005008620675653\n",
      "Epoch 2397, Loss: 0.0016230670298682526, Final Batch Loss: 0.00028820362058468163\n",
      "Epoch 2398, Loss: 0.0011668513543554582, Final Batch Loss: 0.00045136717380955815\n",
      "Epoch 2399, Loss: 0.0006163330326671712, Final Batch Loss: 0.0001051712388289161\n",
      "Epoch 2400, Loss: 0.0031370401702588424, Final Batch Loss: 1.6129397408803925e-05\n",
      "Epoch 2401, Loss: 0.00040333831930183806, Final Batch Loss: 4.9560847401153296e-05\n",
      "Epoch 2402, Loss: 0.0009728050245030317, Final Batch Loss: 0.0003516084689181298\n",
      "Epoch 2403, Loss: 0.0012020849680993706, Final Batch Loss: 4.0490340325050056e-05\n",
      "Epoch 2404, Loss: 0.0005466356160468422, Final Batch Loss: 0.00026352310669608414\n",
      "Epoch 2405, Loss: 0.0009583949067746289, Final Batch Loss: 0.00021928029309492558\n",
      "Epoch 2406, Loss: 0.0002396504205535166, Final Batch Loss: 3.920954623026773e-05\n",
      "Epoch 2407, Loss: 0.0010864689531899785, Final Batch Loss: 0.0007163636619225144\n",
      "Epoch 2408, Loss: 0.0008855125652189599, Final Batch Loss: 0.0007082842057570815\n",
      "Epoch 2409, Loss: 0.0011914690830963082, Final Batch Loss: 1.0667506103345659e-05\n",
      "Epoch 2410, Loss: 0.0004787498437508475, Final Batch Loss: 0.0002791188599076122\n",
      "Epoch 2411, Loss: 0.00042952405510732206, Final Batch Loss: 1.248717035196023e-05\n",
      "Epoch 2412, Loss: 0.001806464229048288, Final Batch Loss: 4.545313640846871e-05\n",
      "Epoch 2413, Loss: 0.0006465158148785122, Final Batch Loss: 0.00013066380051895976\n",
      "Epoch 2414, Loss: 0.00043289629684295505, Final Batch Loss: 7.220540283014998e-05\n",
      "Epoch 2415, Loss: 0.0012448699981177924, Final Batch Loss: 3.404495510039851e-05\n",
      "Epoch 2416, Loss: 0.0007274267227330711, Final Batch Loss: 4.974871626473032e-05\n",
      "Epoch 2417, Loss: 0.00030059710479690693, Final Batch Loss: 9.258594218408689e-06\n",
      "Epoch 2418, Loss: 0.0007483393019356299, Final Batch Loss: 0.0005480335094034672\n",
      "Epoch 2419, Loss: 0.0014833610848654644, Final Batch Loss: 4.14871556131402e-06\n",
      "Epoch 2420, Loss: 0.004606159684044542, Final Batch Loss: 0.00010389447561465204\n",
      "Epoch 2421, Loss: 0.0004894351841358002, Final Batch Loss: 0.00011125944729428738\n",
      "Epoch 2422, Loss: 0.0007949578257466783, Final Batch Loss: 1.3503679838322569e-05\n",
      "Epoch 2423, Loss: 0.0062763418773101876, Final Batch Loss: 8.47838309709914e-05\n",
      "Epoch 2424, Loss: 0.0003841623583866749, Final Batch Loss: 3.2522151741432026e-05\n",
      "Epoch 2425, Loss: 0.003246382041652396, Final Batch Loss: 6.211209256434813e-05\n",
      "Epoch 2426, Loss: 0.0004966083506587893, Final Batch Loss: 0.0002422036195639521\n",
      "Epoch 2427, Loss: 0.0023982998718565796, Final Batch Loss: 0.0015482741873711348\n",
      "Epoch 2428, Loss: 0.00023026138114801142, Final Batch Loss: 9.822534047998488e-05\n",
      "Epoch 2429, Loss: 0.00024225925642440416, Final Batch Loss: 1.1366877288310206e-06\n",
      "Epoch 2430, Loss: 0.0008667254546708136, Final Batch Loss: 0.00013465763186104596\n",
      "Epoch 2431, Loss: 0.012264376928214915, Final Batch Loss: 0.00018140020256396383\n",
      "Epoch 2432, Loss: 0.000366968637536047, Final Batch Loss: 0.00011340394848957658\n",
      "Epoch 2433, Loss: 0.0013185614661779255, Final Batch Loss: 0.00017387178377248347\n",
      "Epoch 2434, Loss: 0.0087510099147039, Final Batch Loss: 5.1789716962957755e-05\n",
      "Epoch 2435, Loss: 0.0002699344913708046, Final Batch Loss: 5.019088348490186e-05\n",
      "Epoch 2436, Loss: 0.0009469542528677266, Final Batch Loss: 0.0002544853778090328\n",
      "Epoch 2437, Loss: 0.0006517517867905553, Final Batch Loss: 8.400843944400549e-05\n",
      "Epoch 2438, Loss: 0.002815213934809435, Final Batch Loss: 0.00015797826927155256\n",
      "Epoch 2439, Loss: 0.0015995517496776301, Final Batch Loss: 0.00010284140444127843\n",
      "Epoch 2440, Loss: 0.000419184054408106, Final Batch Loss: 6.734173439326696e-06\n",
      "Epoch 2441, Loss: 0.002526742307964014, Final Batch Loss: 9.257271813112311e-06\n",
      "Epoch 2442, Loss: 0.0007391541421384318, Final Batch Loss: 0.0005520003032870591\n",
      "Epoch 2443, Loss: 0.003266005486693757, Final Batch Loss: 5.156961196917109e-05\n",
      "Epoch 2444, Loss: 0.000123451072795433, Final Batch Loss: 5.4163487220648676e-05\n",
      "Epoch 2445, Loss: 0.003914560026942127, Final Batch Loss: 0.0035953924525529146\n",
      "Epoch 2446, Loss: 0.000629019250482088, Final Batch Loss: 4.96631910209544e-05\n",
      "Epoch 2447, Loss: 0.017777944437966653, Final Batch Loss: 4.4219203118700534e-05\n",
      "Epoch 2448, Loss: 0.008668140802910784, Final Batch Loss: 0.008563840761780739\n",
      "Epoch 2449, Loss: 0.00015635984345863108, Final Batch Loss: 6.715056952089071e-05\n",
      "Epoch 2450, Loss: 0.006375640929036308, Final Batch Loss: 7.724465831415728e-05\n",
      "Epoch 2451, Loss: 0.00016273421169898938, Final Batch Loss: 2.9284767151693814e-05\n",
      "Epoch 2452, Loss: 0.014100850423346856, Final Batch Loss: 0.013898040167987347\n",
      "Epoch 2453, Loss: 0.04034591574782098, Final Batch Loss: 9.397834219271317e-05\n",
      "Epoch 2454, Loss: 0.0007823360319889616, Final Batch Loss: 0.0004954052856191993\n",
      "Epoch 2455, Loss: 0.0006623896260862239, Final Batch Loss: 0.0001793973642634228\n",
      "Epoch 2456, Loss: 0.0026445052644703537, Final Batch Loss: 0.0009976314613595605\n",
      "Epoch 2457, Loss: 0.0011775880557252094, Final Batch Loss: 0.00020033640612382442\n",
      "Epoch 2458, Loss: 0.007450525743479375, Final Batch Loss: 0.0015978242736309767\n",
      "Epoch 2459, Loss: 0.0071689005781081505, Final Batch Loss: 7.38214366720058e-05\n",
      "Epoch 2460, Loss: 0.036091087880777195, Final Batch Loss: 9.027126361615956e-05\n",
      "Epoch 2461, Loss: 0.0009423921746929409, Final Batch Loss: 0.0007262058206833899\n",
      "Epoch 2462, Loss: 0.0016022169002098963, Final Batch Loss: 9.182003850582987e-05\n",
      "Epoch 2463, Loss: 0.004126980988075957, Final Batch Loss: 0.0006629298441112041\n",
      "Epoch 2464, Loss: 0.0020166283939033747, Final Batch Loss: 0.00031202175887301564\n",
      "Epoch 2465, Loss: 0.026471957959074643, Final Batch Loss: 2.8974945962545462e-05\n",
      "Epoch 2466, Loss: 0.0019489134720060974, Final Batch Loss: 6.521087198052555e-05\n",
      "Epoch 2467, Loss: 0.0005015235310565913, Final Batch Loss: 2.6842915758606978e-05\n",
      "Epoch 2468, Loss: 0.001138421246650978, Final Batch Loss: 0.000783188792411238\n",
      "Epoch 2469, Loss: 0.0026648855564417318, Final Batch Loss: 0.00014558964176103473\n",
      "Epoch 2470, Loss: 0.002586092712590471, Final Batch Loss: 0.00012589804828166962\n",
      "Epoch 2471, Loss: 0.0005092801366117783, Final Batch Loss: 0.00011566874309210107\n",
      "Epoch 2472, Loss: 0.0022276646250247722, Final Batch Loss: 0.0007611102773807943\n",
      "Epoch 2473, Loss: 0.0015309432837966597, Final Batch Loss: 2.553041667852085e-05\n",
      "Epoch 2474, Loss: 0.0004791550018126145, Final Batch Loss: 0.00011834971519419923\n",
      "Epoch 2475, Loss: 0.001646904944209382, Final Batch Loss: 0.0002116317773470655\n",
      "Epoch 2476, Loss: 0.0006238163568923483, Final Batch Loss: 1.6537613191758282e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2477, Loss: 0.0008429691079072654, Final Batch Loss: 2.159704308724031e-05\n",
      "Epoch 2478, Loss: 0.00026613403315423056, Final Batch Loss: 9.76326919044368e-05\n",
      "Epoch 2479, Loss: 0.0009131623264693189, Final Batch Loss: 5.608153878711164e-05\n",
      "Epoch 2480, Loss: 0.0013652423440362327, Final Batch Loss: 0.0003853680973406881\n",
      "Epoch 2481, Loss: 0.0014605851101805456, Final Batch Loss: 0.0001100810113712214\n",
      "Epoch 2482, Loss: 0.00030639268152299337, Final Batch Loss: 8.026195428101346e-05\n",
      "Epoch 2483, Loss: 0.00034355269781372044, Final Batch Loss: 1.8504379113437608e-05\n",
      "Epoch 2484, Loss: 0.00787571667751763, Final Batch Loss: 8.990608330350369e-05\n",
      "Epoch 2485, Loss: 0.0006305239558059839, Final Batch Loss: 6.637280603172258e-05\n",
      "Epoch 2486, Loss: 0.000592405915085692, Final Batch Loss: 0.00011105331213911995\n",
      "Epoch 2487, Loss: 0.002377025783971476, Final Batch Loss: 0.000761830189730972\n",
      "Epoch 2488, Loss: 0.0005563637241721153, Final Batch Loss: 5.717734893551096e-05\n",
      "Epoch 2489, Loss: 0.0004084422453161096, Final Batch Loss: 6.012424637447111e-05\n",
      "Epoch 2490, Loss: 0.02359161104686791, Final Batch Loss: 4.819673631573096e-05\n",
      "Epoch 2491, Loss: 0.0009576372485753382, Final Batch Loss: 0.0007267770124599338\n",
      "Epoch 2492, Loss: 0.0007244371881824918, Final Batch Loss: 0.00010790635860757902\n",
      "Epoch 2493, Loss: 0.005861215002369136, Final Batch Loss: 0.0002295863232575357\n",
      "Epoch 2494, Loss: 0.0011840209590445738, Final Batch Loss: 0.00030858683749102056\n",
      "Epoch 2495, Loss: 0.01591360901511507, Final Batch Loss: 0.0001899528142530471\n",
      "Epoch 2496, Loss: 0.002926390247012023, Final Batch Loss: 2.9045138944638893e-05\n",
      "Epoch 2497, Loss: 0.000698670113706612, Final Batch Loss: 2.000873973884154e-05\n",
      "Epoch 2498, Loss: 0.0028400903756846674, Final Batch Loss: 0.0020574224181473255\n",
      "Epoch 2499, Loss: 0.0007542553648818284, Final Batch Loss: 0.0001263460871996358\n",
      "Epoch 2500, Loss: 0.0016988918177958112, Final Batch Loss: 6.171823042677715e-05\n",
      "Epoch 2501, Loss: 0.001241497535374947, Final Batch Loss: 0.0001705787144601345\n",
      "Epoch 2502, Loss: 0.0006640312240051571, Final Batch Loss: 3.593691872083582e-05\n",
      "Epoch 2503, Loss: 0.02859746844114852, Final Batch Loss: 9.335918730357662e-05\n",
      "Epoch 2504, Loss: 0.0010253069121972658, Final Batch Loss: 8.48747804411687e-05\n",
      "Epoch 2505, Loss: 0.0009087505677598529, Final Batch Loss: 0.00038869716809131205\n",
      "Epoch 2506, Loss: 0.002604066343337763, Final Batch Loss: 0.0015756296925246716\n",
      "Epoch 2507, Loss: 0.000615021515841363, Final Batch Loss: 2.2615506168222055e-05\n",
      "Epoch 2508, Loss: 0.0002623396176204551, Final Batch Loss: 4.021780478069559e-05\n",
      "Epoch 2509, Loss: 0.00039421741166734137, Final Batch Loss: 4.0501035982742906e-06\n",
      "Epoch 2510, Loss: 0.001511011621914804, Final Batch Loss: 9.264262916985899e-05\n",
      "Epoch 2511, Loss: 0.0015069963701535016, Final Batch Loss: 0.0004638844693545252\n",
      "Epoch 2512, Loss: 0.002984489743539598, Final Batch Loss: 0.001252594985999167\n",
      "Epoch 2513, Loss: 0.03311496155038185, Final Batch Loss: 0.023299556225538254\n",
      "Epoch 2514, Loss: 0.0007795075871399604, Final Batch Loss: 0.00015099416486918926\n",
      "Epoch 2515, Loss: 0.012148181867814856, Final Batch Loss: 5.534613228519447e-05\n",
      "Epoch 2516, Loss: 0.0008363345550606027, Final Batch Loss: 0.00017273920821025968\n",
      "Epoch 2517, Loss: 0.02453471657645423, Final Batch Loss: 0.0002215383865404874\n",
      "Epoch 2518, Loss: 0.0346680882939836, Final Batch Loss: 0.0003835411334875971\n",
      "Epoch 2519, Loss: 0.0005802703817607835, Final Batch Loss: 0.00023045946727506816\n",
      "Epoch 2520, Loss: 0.0016731303321648738, Final Batch Loss: 1.0211136213911232e-05\n",
      "Epoch 2521, Loss: 0.005655314300383907, Final Batch Loss: 0.004992115776985884\n",
      "Epoch 2522, Loss: 0.0002817265385601786, Final Batch Loss: 3.948437733924948e-05\n",
      "Epoch 2523, Loss: 0.001124391612393083, Final Batch Loss: 2.4849901819834486e-05\n",
      "Epoch 2524, Loss: 0.013503419628250413, Final Batch Loss: 6.305046554189175e-05\n",
      "Epoch 2525, Loss: 0.0014102879649726674, Final Batch Loss: 0.001084416639059782\n",
      "Epoch 2526, Loss: 0.0003706309726112522, Final Batch Loss: 0.00018933333922177553\n",
      "Epoch 2527, Loss: 0.010525152703849017, Final Batch Loss: 2.61217664956348e-05\n",
      "Epoch 2528, Loss: 0.00041876085379044525, Final Batch Loss: 9.261063496524002e-06\n",
      "Epoch 2529, Loss: 0.0010754659342637751, Final Batch Loss: 0.0001025696619763039\n",
      "Epoch 2530, Loss: 0.022100010499343625, Final Batch Loss: 2.4666544049978256e-05\n",
      "Epoch 2531, Loss: 0.0019356587581569329, Final Batch Loss: 5.5601849453523755e-05\n",
      "Epoch 2532, Loss: 0.0011250301304244203, Final Batch Loss: 0.0006978223100304604\n",
      "Epoch 2533, Loss: 0.003553707102582848, Final Batch Loss: 0.00011731306585716084\n",
      "Epoch 2534, Loss: 0.0017629295980441384, Final Batch Loss: 0.00018394345534034073\n",
      "Epoch 2535, Loss: 0.00015995656394807156, Final Batch Loss: 4.1972798499045894e-05\n",
      "Epoch 2536, Loss: 0.0008409126166952774, Final Batch Loss: 0.000575160258449614\n",
      "Epoch 2537, Loss: 0.0003329572682559956, Final Batch Loss: 6.552955892402679e-05\n",
      "Epoch 2538, Loss: 0.023603380032000132, Final Batch Loss: 0.022758588194847107\n",
      "Epoch 2539, Loss: 0.0007050085696391761, Final Batch Loss: 0.00010432434646645561\n",
      "Epoch 2540, Loss: 0.009276463992136996, Final Batch Loss: 0.009034724906086922\n",
      "Epoch 2541, Loss: 0.05088434353638149, Final Batch Loss: 2.8018819648423232e-05\n",
      "Epoch 2542, Loss: 0.0005653808329952881, Final Batch Loss: 0.0001831938570830971\n",
      "Epoch 2543, Loss: 0.0008070577487160335, Final Batch Loss: 0.00045564741594716907\n",
      "Epoch 2544, Loss: 0.013342091988306493, Final Batch Loss: 0.0037314454093575478\n",
      "Epoch 2545, Loss: 0.025754581816727296, Final Batch Loss: 0.00014762338832952082\n",
      "Epoch 2546, Loss: 0.0005651002720696852, Final Batch Loss: 5.8587713283486664e-05\n",
      "Epoch 2547, Loss: 0.0005260158286546357, Final Batch Loss: 0.00020100099209230393\n",
      "Epoch 2548, Loss: 0.0018974933336721733, Final Batch Loss: 0.0009029806242324412\n",
      "Epoch 2549, Loss: 0.0013448776371660642, Final Batch Loss: 4.0124541555996984e-05\n",
      "Epoch 2550, Loss: 0.049552218362805434, Final Batch Loss: 9.993756248150021e-05\n",
      "Epoch 2551, Loss: 0.0007388973044726299, Final Batch Loss: 8.482345583615825e-05\n",
      "Epoch 2552, Loss: 0.0008156541080097668, Final Batch Loss: 7.147189899114892e-05\n",
      "Epoch 2553, Loss: 0.003915626912203152, Final Batch Loss: 0.00014632861712016165\n",
      "Epoch 2554, Loss: 0.006939074846741278, Final Batch Loss: 4.0680351958144456e-05\n",
      "Epoch 2555, Loss: 0.0020816281828501815, Final Batch Loss: 3.555411012712284e-06\n",
      "Epoch 2556, Loss: 0.001625391909328755, Final Batch Loss: 0.00021255506726447493\n",
      "Epoch 2557, Loss: 0.0005731966557505075, Final Batch Loss: 0.00013560333172790706\n",
      "Epoch 2558, Loss: 0.0018167378038924653, Final Batch Loss: 0.0014498368836939335\n",
      "Epoch 2559, Loss: 0.0005040401392761851, Final Batch Loss: 8.737466851016507e-05\n",
      "Epoch 2560, Loss: 0.0008943223328969907, Final Batch Loss: 9.958996088244021e-06\n",
      "Epoch 2561, Loss: 0.0007729398130322807, Final Batch Loss: 0.00014874069893267006\n",
      "Epoch 2562, Loss: 0.00039666363954893313, Final Batch Loss: 0.00014464599371422082\n",
      "Epoch 2563, Loss: 0.0004807624973182101, Final Batch Loss: 0.00028499955078586936\n",
      "Epoch 2564, Loss: 0.00169450569228502, Final Batch Loss: 0.0002120264107361436\n",
      "Epoch 2565, Loss: 0.013619935114547843, Final Batch Loss: 0.0001532739115646109\n",
      "Epoch 2566, Loss: 0.0006012960984662641, Final Batch Loss: 3.124452268821187e-05\n",
      "Epoch 2567, Loss: 0.0003477995160210412, Final Batch Loss: 0.00019578341743908823\n",
      "Epoch 2568, Loss: 0.001393646205542609, Final Batch Loss: 0.0002937188546638936\n",
      "Epoch 2569, Loss: 0.00041321143544337247, Final Batch Loss: 2.4383623895118944e-05\n",
      "Epoch 2570, Loss: 0.01897404467672459, Final Batch Loss: 5.588384374277666e-05\n",
      "Epoch 2571, Loss: 0.0020071069429832278, Final Batch Loss: 0.0015864362940192223\n",
      "Epoch 2572, Loss: 0.0008417372664553113, Final Batch Loss: 0.0001777332799974829\n",
      "Epoch 2573, Loss: 0.0035462910163914785, Final Batch Loss: 0.0028497863095253706\n",
      "Epoch 2574, Loss: 0.0002961078098451253, Final Batch Loss: 8.996025280794129e-05\n",
      "Epoch 2575, Loss: 0.0007241543717100285, Final Batch Loss: 5.597151903202757e-05\n",
      "Epoch 2576, Loss: 0.012065877484928933, Final Batch Loss: 0.01181167270988226\n",
      "Epoch 2577, Loss: 0.0006055834273865912, Final Batch Loss: 0.0003329813771415502\n",
      "Epoch 2578, Loss: 0.0005409069344750606, Final Batch Loss: 0.0001803630293579772\n",
      "Epoch 2579, Loss: 0.0014000673036207445, Final Batch Loss: 0.0006715137860737741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2580, Loss: 0.0018448878763592802, Final Batch Loss: 4.0909682866185904e-05\n",
      "Epoch 2581, Loss: 0.0011472382211650256, Final Batch Loss: 5.554611925617792e-05\n",
      "Epoch 2582, Loss: 0.0013643042802868877, Final Batch Loss: 3.105518771917559e-05\n",
      "Epoch 2583, Loss: 0.006335076326649869, Final Batch Loss: 4.961622107657604e-05\n",
      "Epoch 2584, Loss: 0.00043705166172003374, Final Batch Loss: 6.311816105153412e-05\n",
      "Epoch 2585, Loss: 0.001944743806234328, Final Batch Loss: 5.3438005124917254e-05\n",
      "Epoch 2586, Loss: 0.0007523813956140657, Final Batch Loss: 9.821419553190935e-06\n",
      "Epoch 2587, Loss: 0.0006733854133926798, Final Batch Loss: 0.0004097043420188129\n",
      "Epoch 2588, Loss: 0.0012736351127387024, Final Batch Loss: 4.208782047498971e-05\n",
      "Epoch 2589, Loss: 0.0068489728946588, Final Batch Loss: 0.00017685274360701442\n",
      "Epoch 2590, Loss: 0.0003416695362830069, Final Batch Loss: 4.638859900296666e-05\n",
      "Epoch 2591, Loss: 0.0005657630899804644, Final Batch Loss: 3.1932264391798526e-05\n",
      "Epoch 2592, Loss: 0.00037527128642977914, Final Batch Loss: 0.0001544701081002131\n",
      "Epoch 2593, Loss: 0.0015670778630010318, Final Batch Loss: 0.00032646485487930477\n",
      "Epoch 2594, Loss: 0.0008666953472129535, Final Batch Loss: 0.0001170589093817398\n",
      "Epoch 2595, Loss: 0.002103622566210106, Final Batch Loss: 7.476095925085247e-05\n",
      "Epoch 2596, Loss: 0.0013284514898259658, Final Batch Loss: 3.129187098238617e-05\n",
      "Epoch 2597, Loss: 0.00037782988329126965, Final Batch Loss: 9.915680493577383e-06\n",
      "Epoch 2598, Loss: 0.007000703870289726, Final Batch Loss: 0.00605914369225502\n",
      "Epoch 2599, Loss: 0.0008974514121291577, Final Batch Loss: 0.0006567374803125858\n",
      "Epoch 2600, Loss: 0.004165644843851624, Final Batch Loss: 6.6657730712904595e-06\n",
      "Epoch 2601, Loss: 0.000377890912204748, Final Batch Loss: 0.00010998456855304539\n",
      "Epoch 2602, Loss: 0.0006108812522143126, Final Batch Loss: 0.00043442577589303255\n",
      "Epoch 2603, Loss: 0.0011721234004653525, Final Batch Loss: 2.2853308109915815e-05\n",
      "Epoch 2604, Loss: 0.00026112544310308294, Final Batch Loss: 6.516037501569372e-06\n",
      "Epoch 2605, Loss: 0.0003248545399401337, Final Batch Loss: 2.874010897357948e-05\n",
      "Epoch 2606, Loss: 0.00019678894295793725, Final Batch Loss: 1.3469328223436605e-05\n",
      "Epoch 2607, Loss: 0.0005120084824739024, Final Batch Loss: 2.169053186662495e-05\n",
      "Epoch 2608, Loss: 0.0006628583651036024, Final Batch Loss: 0.00014264453784562647\n",
      "Epoch 2609, Loss: 0.00479896826800541, Final Batch Loss: 0.0003593412402551621\n",
      "Epoch 2610, Loss: 0.00023900742053228896, Final Batch Loss: 8.674485434312373e-05\n",
      "Epoch 2611, Loss: 0.00014943949281587265, Final Batch Loss: 2.9884282412240282e-05\n",
      "Epoch 2612, Loss: 0.008001210109796375, Final Batch Loss: 0.0001037577458191663\n",
      "Epoch 2613, Loss: 0.0015998413364286534, Final Batch Loss: 0.00012969480303581804\n",
      "Epoch 2614, Loss: 0.000822603513370268, Final Batch Loss: 0.00034552361466921866\n",
      "Epoch 2615, Loss: 0.00046022168498893734, Final Batch Loss: 0.00011311566777294502\n",
      "Epoch 2616, Loss: 0.00022155247688715463, Final Batch Loss: 0.00013256834063213319\n",
      "Epoch 2617, Loss: 0.0004912687581963837, Final Batch Loss: 0.0001504359534010291\n",
      "Epoch 2618, Loss: 0.0016692850695108064, Final Batch Loss: 5.201225940254517e-05\n",
      "Epoch 2619, Loss: 0.00042102087536477484, Final Batch Loss: 1.6059868357842788e-05\n",
      "Epoch 2620, Loss: 0.0001732110463308345, Final Batch Loss: 7.849386020097882e-05\n",
      "Epoch 2621, Loss: 0.0014324500539260043, Final Batch Loss: 6.065655270504067e-06\n",
      "Epoch 2622, Loss: 0.0004276955150999129, Final Batch Loss: 5.0516624469310045e-05\n",
      "Epoch 2623, Loss: 0.00036574895602825563, Final Batch Loss: 0.00018801285477820784\n",
      "Epoch 2624, Loss: 0.000477558820421109, Final Batch Loss: 0.00015361577970907092\n",
      "Epoch 2625, Loss: 0.00037524042863879004, Final Batch Loss: 3.866888164338889e-06\n",
      "Epoch 2626, Loss: 0.0012132076662965119, Final Batch Loss: 0.0006304298294708133\n",
      "Epoch 2627, Loss: 0.00046982625281088986, Final Batch Loss: 0.00024014497466851026\n",
      "Epoch 2628, Loss: 0.00013121202573529445, Final Batch Loss: 1.929554491653107e-05\n",
      "Epoch 2629, Loss: 0.0015722399184596725, Final Batch Loss: 0.0010515397880226374\n",
      "Epoch 2630, Loss: 0.00013601900354842655, Final Batch Loss: 4.0686245483811945e-06\n",
      "Epoch 2631, Loss: 0.0002118982765750843, Final Batch Loss: 5.748472540290095e-05\n",
      "Epoch 2632, Loss: 0.00023037626942823408, Final Batch Loss: 1.1555265700735617e-05\n",
      "Epoch 2633, Loss: 0.00013749252411798807, Final Batch Loss: 1.8227792679681443e-06\n",
      "Epoch 2634, Loss: 0.00022122521090750524, Final Batch Loss: 2.670363528523012e-06\n",
      "Epoch 2635, Loss: 0.012407200101733906, Final Batch Loss: 0.00029136138618923724\n",
      "Epoch 2636, Loss: 0.0003650053604360437, Final Batch Loss: 3.873223249684088e-05\n",
      "Epoch 2637, Loss: 0.00032871620715013705, Final Batch Loss: 2.2294096197583713e-05\n",
      "Epoch 2638, Loss: 0.00014341123915073695, Final Batch Loss: 9.23998868529452e-06\n",
      "Epoch 2639, Loss: 0.0017919405254360754, Final Batch Loss: 1.0002881026593968e-05\n",
      "Epoch 2640, Loss: 0.00012741912451019743, Final Batch Loss: 9.656142538005952e-06\n",
      "Epoch 2641, Loss: 0.0014521890425385209, Final Batch Loss: 2.3446564227924682e-05\n",
      "Epoch 2642, Loss: 0.016991848926409148, Final Batch Loss: 7.45068900869228e-05\n",
      "Epoch 2643, Loss: 0.00022435171558754519, Final Batch Loss: 5.136571417097002e-06\n",
      "Epoch 2644, Loss: 0.0003491345964903303, Final Batch Loss: 3.7664472074538935e-06\n",
      "Epoch 2645, Loss: 0.00048251399493892677, Final Batch Loss: 9.392328502144665e-05\n",
      "Epoch 2646, Loss: 0.0003463193861534819, Final Batch Loss: 2.058404788840562e-06\n",
      "Epoch 2647, Loss: 0.000953495611611288, Final Batch Loss: 2.2817726858193055e-05\n",
      "Epoch 2648, Loss: 0.00025523107797198463, Final Batch Loss: 1.6989723008009605e-05\n",
      "Epoch 2649, Loss: 0.0003316726961202221, Final Batch Loss: 0.00018498035205993801\n",
      "Epoch 2650, Loss: 0.00037747012174804695, Final Batch Loss: 5.475817670230754e-05\n",
      "Epoch 2651, Loss: 0.0005766494177805725, Final Batch Loss: 1.0972613381454721e-05\n",
      "Epoch 2652, Loss: 0.00030537146085407585, Final Batch Loss: 0.00014430707960855216\n",
      "Epoch 2653, Loss: 0.052256795825087465, Final Batch Loss: 8.432178583461791e-05\n",
      "Epoch 2654, Loss: 0.0008444012419204228, Final Batch Loss: 2.1453117369674146e-05\n",
      "Epoch 2655, Loss: 0.0027953302351306775, Final Batch Loss: 0.00046471794485114515\n",
      "Epoch 2656, Loss: 0.010121102841367247, Final Batch Loss: 6.054837649571709e-05\n",
      "Epoch 2657, Loss: 0.0007707830300205387, Final Batch Loss: 0.0004981738748028874\n",
      "Epoch 2658, Loss: 0.001146139133197721, Final Batch Loss: 0.00015684209938626736\n",
      "Epoch 2659, Loss: 0.0006749534054506512, Final Batch Loss: 6.948449936317047e-06\n",
      "Epoch 2660, Loss: 0.0007863873634050833, Final Batch Loss: 8.02077011030633e-06\n",
      "Epoch 2661, Loss: 0.0007160661480156705, Final Batch Loss: 5.659709859173745e-05\n",
      "Epoch 2662, Loss: 0.0004545270021480974, Final Batch Loss: 0.00013041139754932374\n",
      "Epoch 2663, Loss: 0.0002137185156243504, Final Batch Loss: 4.8990448703989387e-05\n",
      "Epoch 2664, Loss: 0.005890013475436717, Final Batch Loss: 0.004936015233397484\n",
      "Epoch 2665, Loss: 0.0005950186923655565, Final Batch Loss: 7.628895218658727e-06\n",
      "Epoch 2666, Loss: 0.0010389778544777073, Final Batch Loss: 9.132571722147986e-05\n",
      "Epoch 2667, Loss: 0.00062166709540179, Final Batch Loss: 3.270642628194764e-05\n",
      "Epoch 2668, Loss: 0.00026650539075490087, Final Batch Loss: 6.752765330020338e-05\n",
      "Epoch 2669, Loss: 0.0015066288142406847, Final Batch Loss: 2.9641440050909296e-05\n",
      "Epoch 2670, Loss: 0.003765923698665574, Final Batch Loss: 0.0001380227186018601\n",
      "Epoch 2671, Loss: 0.0005586537154158577, Final Batch Loss: 1.3061564459349029e-05\n",
      "Epoch 2672, Loss: 0.0016391156314057298, Final Batch Loss: 9.046158083947375e-05\n",
      "Epoch 2673, Loss: 0.00035115587888867594, Final Batch Loss: 5.967214747215621e-05\n",
      "Epoch 2674, Loss: 0.0013675810077984352, Final Batch Loss: 0.00013157614739611745\n",
      "Epoch 2675, Loss: 0.0042678737263486255, Final Batch Loss: 1.0834166459972039e-05\n",
      "Epoch 2676, Loss: 0.0004722354315163102, Final Batch Loss: 0.00021843312424607575\n",
      "Epoch 2677, Loss: 0.0003027945313078817, Final Batch Loss: 1.2509974112617783e-05\n",
      "Epoch 2678, Loss: 0.0005293551694194321, Final Batch Loss: 0.00017321834457106888\n",
      "Epoch 2679, Loss: 0.0010043456422863528, Final Batch Loss: 2.4065597244771197e-05\n",
      "Epoch 2680, Loss: 0.0019857228398905136, Final Batch Loss: 4.658080797526054e-05\n",
      "Epoch 2681, Loss: 0.0004970944758042606, Final Batch Loss: 2.053584694294841e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2682, Loss: 0.00010858832411031472, Final Batch Loss: 4.091452501597814e-05\n",
      "Epoch 2683, Loss: 0.000776837405283004, Final Batch Loss: 0.00037139744381420314\n",
      "Epoch 2684, Loss: 0.00088869160390459, Final Batch Loss: 0.00015625522064510733\n",
      "Epoch 2685, Loss: 0.0002838923719536979, Final Batch Loss: 0.00010026903328252956\n",
      "Epoch 2686, Loss: 0.0014360988498083316, Final Batch Loss: 0.00034344138111919165\n",
      "Epoch 2687, Loss: 0.00035000197203771677, Final Batch Loss: 0.0001474567543482408\n",
      "Epoch 2688, Loss: 0.0003974832907260861, Final Batch Loss: 4.52984131698031e-05\n",
      "Epoch 2689, Loss: 0.0004633184762496967, Final Batch Loss: 3.310633837827481e-05\n",
      "Epoch 2690, Loss: 0.000324809893299971, Final Batch Loss: 4.9201430556422565e-06\n",
      "Epoch 2691, Loss: 0.0003331071111460915, Final Batch Loss: 6.732650945195928e-05\n",
      "Epoch 2692, Loss: 0.00026600147339195246, Final Batch Loss: 6.0060128816985525e-06\n",
      "Epoch 2693, Loss: 0.001338255482551176, Final Batch Loss: 0.0009043324971571565\n",
      "Epoch 2694, Loss: 9.813173710426781e-05, Final Batch Loss: 1.4971225027693436e-05\n",
      "Epoch 2695, Loss: 0.00017985724844038486, Final Batch Loss: 7.059013114485424e-06\n",
      "Epoch 2696, Loss: 0.0018769787056953646, Final Batch Loss: 5.2711118769366294e-05\n",
      "Epoch 2697, Loss: 0.003140877466648817, Final Batch Loss: 3.665075928438455e-05\n",
      "Epoch 2698, Loss: 0.0007611744003952481, Final Batch Loss: 2.7737456548493356e-05\n",
      "Epoch 2699, Loss: 0.00034025447871499637, Final Batch Loss: 3.0160917958710343e-05\n",
      "Epoch 2700, Loss: 0.0008837298983053188, Final Batch Loss: 1.7062528058886528e-05\n",
      "Epoch 2701, Loss: 0.008121668356579903, Final Batch Loss: 1.3489591765392106e-05\n",
      "Epoch 2702, Loss: 0.0012068544529029168, Final Batch Loss: 0.0007087899139150977\n",
      "Epoch 2703, Loss: 0.00021477360314747784, Final Batch Loss: 0.0001321688323514536\n",
      "Epoch 2704, Loss: 0.0001337684843747411, Final Batch Loss: 3.34035576088354e-05\n",
      "Epoch 2705, Loss: 0.011330054326208483, Final Batch Loss: 1.1686216566886287e-05\n",
      "Epoch 2706, Loss: 0.0005558814445976168, Final Batch Loss: 8.173068636097014e-06\n",
      "Epoch 2707, Loss: 9.99247608888254e-05, Final Batch Loss: 6.159581516840262e-06\n",
      "Epoch 2708, Loss: 0.0007470832206308842, Final Batch Loss: 0.00017454344197176397\n",
      "Epoch 2709, Loss: 0.00022822568462288473, Final Batch Loss: 1.5311885363189504e-05\n",
      "Epoch 2710, Loss: 0.0004437951010913821, Final Batch Loss: 1.4631521480623633e-05\n",
      "Epoch 2711, Loss: 0.0015245867925841594, Final Batch Loss: 7.69614489399828e-05\n",
      "Epoch 2712, Loss: 0.00026554864120953425, Final Batch Loss: 3.152824137941934e-05\n",
      "Epoch 2713, Loss: 0.0022864426955777617, Final Batch Loss: 3.698260400142317e-07\n",
      "Epoch 2714, Loss: 0.00029360059124883264, Final Batch Loss: 1.3789634977001697e-05\n",
      "Epoch 2715, Loss: 0.0022857465119159315, Final Batch Loss: 0.001799211255274713\n",
      "Epoch 2716, Loss: 0.00017111008673964534, Final Batch Loss: 4.632963828044012e-05\n",
      "Epoch 2717, Loss: 0.00018630979047884466, Final Batch Loss: 1.8846942111849785e-05\n",
      "Epoch 2718, Loss: 0.0073675213141086715, Final Batch Loss: 3.260981975472532e-05\n",
      "Epoch 2719, Loss: 0.0005603668460025801, Final Batch Loss: 1.8308544895262457e-05\n",
      "Epoch 2720, Loss: 0.0034699819043453317, Final Batch Loss: 8.091628842521459e-06\n",
      "Epoch 2721, Loss: 0.0009718976216390729, Final Batch Loss: 6.51381560601294e-05\n",
      "Epoch 2722, Loss: 0.0004587252435612754, Final Batch Loss: 3.362936013218132e-06\n",
      "Epoch 2723, Loss: 0.0008918299135984853, Final Batch Loss: 5.997070547891781e-05\n",
      "Epoch 2724, Loss: 0.000232733260418172, Final Batch Loss: 5.255258201941615e-06\n",
      "Epoch 2725, Loss: 0.0002532581547711743, Final Batch Loss: 2.319389022886753e-05\n",
      "Epoch 2726, Loss: 0.00011007719058397925, Final Batch Loss: 6.056892380001955e-05\n",
      "Epoch 2727, Loss: 0.0034964207229677413, Final Batch Loss: 5.224053165875375e-05\n",
      "Epoch 2728, Loss: 0.0001447383747290587, Final Batch Loss: 1.9590797819546424e-05\n",
      "Epoch 2729, Loss: 0.0023622764065294177, Final Batch Loss: 1.725712172628846e-05\n",
      "Epoch 2730, Loss: 0.0051660374156199396, Final Batch Loss: 5.198960570851341e-05\n",
      "Epoch 2731, Loss: 0.012717256222458673, Final Batch Loss: 2.656204924278427e-05\n",
      "Epoch 2732, Loss: 0.0008375147525612192, Final Batch Loss: 2.3813483494450338e-05\n",
      "Epoch 2733, Loss: 0.00024208815921156202, Final Batch Loss: 4.175948561169207e-05\n",
      "Epoch 2734, Loss: 0.01022232354443986, Final Batch Loss: 0.009368638508021832\n",
      "Epoch 2735, Loss: 0.0009380715964653064, Final Batch Loss: 1.9218730813008733e-05\n",
      "Epoch 2736, Loss: 0.000918258718229481, Final Batch Loss: 8.678866288391873e-05\n",
      "Epoch 2737, Loss: 0.0004407546621223446, Final Batch Loss: 3.6624544009100646e-05\n",
      "Epoch 2738, Loss: 0.0016790976360425702, Final Batch Loss: 7.678953807044309e-06\n",
      "Epoch 2739, Loss: 0.02996158970563556, Final Batch Loss: 0.008296369574964046\n",
      "Epoch 2740, Loss: 0.0012278397116460837, Final Batch Loss: 0.00034067744854837656\n",
      "Epoch 2741, Loss: 0.0008469344593322603, Final Batch Loss: 0.00018901638395618647\n",
      "Epoch 2742, Loss: 0.006699677138385596, Final Batch Loss: 0.0007646519807167351\n",
      "Epoch 2743, Loss: 0.000613010983215645, Final Batch Loss: 0.0001594628265593201\n",
      "Epoch 2744, Loss: 0.0014006717647134792, Final Batch Loss: 3.829459092230536e-05\n",
      "Epoch 2745, Loss: 0.002172351480112411, Final Batch Loss: 0.0017829200951382518\n",
      "Epoch 2746, Loss: 0.005694875495464657, Final Batch Loss: 0.0055587817914783955\n",
      "Epoch 2747, Loss: 0.0018211134811281227, Final Batch Loss: 0.0004151852917857468\n",
      "Epoch 2748, Loss: 0.00704777105966059, Final Batch Loss: 8.129251364152879e-05\n",
      "Epoch 2749, Loss: 0.0015419841056427686, Final Batch Loss: 2.8351443688734435e-05\n",
      "Epoch 2750, Loss: 0.008156582344781782, Final Batch Loss: 1.4135536730464082e-05\n",
      "Epoch 2751, Loss: 0.001422101428033784, Final Batch Loss: 0.0001467464171582833\n",
      "Epoch 2752, Loss: 0.00036755941619048826, Final Batch Loss: 6.858414417365566e-05\n",
      "Epoch 2753, Loss: 0.0021922065570834093, Final Batch Loss: 0.0002522700815461576\n",
      "Epoch 2754, Loss: 0.015668382417061366, Final Batch Loss: 0.00012427511683199555\n",
      "Epoch 2755, Loss: 0.001117533922297298, Final Batch Loss: 1.6754993339418434e-05\n",
      "Epoch 2756, Loss: 0.00011979947703366634, Final Batch Loss: 1.5622881619492546e-05\n",
      "Epoch 2757, Loss: 0.0009108411641136627, Final Batch Loss: 0.00020216897246427834\n",
      "Epoch 2758, Loss: 0.021000255068429396, Final Batch Loss: 5.1843318942701444e-05\n",
      "Epoch 2759, Loss: 0.000403034913688316, Final Batch Loss: 2.9102373446221463e-05\n",
      "Epoch 2760, Loss: 0.001317907026532339, Final Batch Loss: 9.269559086533263e-05\n",
      "Epoch 2761, Loss: 0.00012692624477494974, Final Batch Loss: 3.592689972720109e-05\n",
      "Epoch 2762, Loss: 0.0006878853810121655, Final Batch Loss: 1.4975804333516862e-05\n",
      "Epoch 2763, Loss: 0.00016459721700812224, Final Batch Loss: 1.7861691958387382e-05\n",
      "Epoch 2764, Loss: 0.0018346784927416593, Final Batch Loss: 6.554491847055033e-05\n",
      "Epoch 2765, Loss: 0.00014100952944318124, Final Batch Loss: 3.474807090242393e-05\n",
      "Epoch 2766, Loss: 0.00045273757314134855, Final Batch Loss: 4.735893526230939e-06\n",
      "Epoch 2767, Loss: 0.0010490724835108267, Final Batch Loss: 0.00024114087864290923\n",
      "Epoch 2768, Loss: 0.0009042969811616786, Final Batch Loss: 2.2535639345733216e-06\n",
      "Epoch 2769, Loss: 0.0009254570022676489, Final Batch Loss: 5.8444102251087315e-06\n",
      "Epoch 2770, Loss: 9.597313965059584e-05, Final Batch Loss: 4.143802470935043e-06\n",
      "Epoch 2771, Loss: 7.035709404590307e-05, Final Batch Loss: 5.787332156614866e-06\n",
      "Epoch 2772, Loss: 0.0002891063541028416, Final Batch Loss: 5.095691449241713e-05\n",
      "Epoch 2773, Loss: 0.0015106020273378817, Final Batch Loss: 0.0001611322077224031\n",
      "Epoch 2774, Loss: 0.0001506247735960642, Final Batch Loss: 5.147276897332631e-05\n",
      "Epoch 2775, Loss: 0.0008074340148596093, Final Batch Loss: 0.0003735653590410948\n",
      "Epoch 2776, Loss: 0.0011883415633064942, Final Batch Loss: 1.6707678014427074e-06\n",
      "Epoch 2777, Loss: 0.0014338054061227012, Final Batch Loss: 5.2505565690808e-05\n",
      "Epoch 2778, Loss: 0.00012195214912935626, Final Batch Loss: 4.435600567376241e-05\n",
      "Epoch 2779, Loss: 0.0005723709327867255, Final Batch Loss: 5.215148121351376e-05\n",
      "Epoch 2780, Loss: 0.0015690854997956194, Final Batch Loss: 0.00018803651619236916\n",
      "Epoch 2781, Loss: 0.001212249910167884, Final Batch Loss: 0.0005744544905610383\n",
      "Epoch 2782, Loss: 0.0002728954059421085, Final Batch Loss: 3.5107328585581854e-05\n",
      "Epoch 2783, Loss: 0.0001377999486749104, Final Batch Loss: 1.529052315163426e-05\n",
      "Epoch 2784, Loss: 0.00014314041800389532, Final Batch Loss: 1.0740694051492028e-05\n",
      "Epoch 2785, Loss: 0.00040460896661898005, Final Batch Loss: 8.787615115579683e-06\n",
      "Epoch 2786, Loss: 8.075628738879459e-05, Final Batch Loss: 5.671315193467308e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2787, Loss: 0.00016341302080036257, Final Batch Loss: 3.101301263086498e-05\n",
      "Epoch 2788, Loss: 0.0006121781261754222, Final Batch Loss: 9.48330489336513e-06\n",
      "Epoch 2789, Loss: 0.00017350666985294083, Final Batch Loss: 3.570389708329458e-06\n",
      "Epoch 2790, Loss: 0.0003219089521735441, Final Batch Loss: 5.042521297582425e-05\n",
      "Epoch 2791, Loss: 0.00015335710168074002, Final Batch Loss: 2.5345681933686137e-05\n",
      "Epoch 2792, Loss: 0.0011438895253377268, Final Batch Loss: 0.0001602489355718717\n",
      "Epoch 2793, Loss: 0.0004436476904174924, Final Batch Loss: 3.484036142253899e-06\n",
      "Epoch 2794, Loss: 0.0004744005823340558, Final Batch Loss: 7.332633686019108e-06\n",
      "Epoch 2795, Loss: 0.00011979292776231887, Final Batch Loss: 4.367205110611394e-05\n",
      "Epoch 2796, Loss: 0.00671688059992448, Final Batch Loss: 0.00018111825920641422\n",
      "Epoch 2797, Loss: 0.00043254433330730535, Final Batch Loss: 6.127802771516144e-05\n",
      "Epoch 2798, Loss: 0.0037289928113750648, Final Batch Loss: 4.680420897784643e-05\n",
      "Epoch 2799, Loss: 0.00014987662234489108, Final Batch Loss: 2.430330278002657e-05\n",
      "Epoch 2800, Loss: 0.0071370522236975376, Final Batch Loss: 4.638616519514471e-05\n",
      "Epoch 2801, Loss: 0.00017820783432398457, Final Batch Loss: 1.1717853340087458e-05\n",
      "Epoch 2802, Loss: 0.00010728861070674611, Final Batch Loss: 5.5032733143889345e-06\n",
      "Epoch 2803, Loss: 0.00011765560884668957, Final Batch Loss: 2.6662741220206954e-05\n",
      "Epoch 2804, Loss: 0.0005580575816566125, Final Batch Loss: 2.1584017304121517e-05\n",
      "Epoch 2805, Loss: 9.313345935879624e-05, Final Batch Loss: 9.81523498921888e-06\n",
      "Epoch 2806, Loss: 0.0015161282526605646, Final Batch Loss: 1.0438803656143136e-05\n",
      "Epoch 2807, Loss: 8.943064926825173e-05, Final Batch Loss: 2.9521117539843544e-05\n",
      "Epoch 2808, Loss: 0.0005637339063468971, Final Batch Loss: 0.000243239919655025\n",
      "Epoch 2809, Loss: 0.00025427851596759865, Final Batch Loss: 1.0456583368068095e-05\n",
      "Epoch 2810, Loss: 0.0007132502360036597, Final Batch Loss: 1.3828503142576665e-05\n",
      "Epoch 2811, Loss: 0.00023344092650745552, Final Batch Loss: 2.9848987992409093e-07\n",
      "Epoch 2812, Loss: 0.0002467392673679569, Final Batch Loss: 1.776661338226404e-05\n",
      "Epoch 2813, Loss: 0.00013180765563447494, Final Batch Loss: 1.4260265743359923e-05\n",
      "Epoch 2814, Loss: 0.00010872223629121436, Final Batch Loss: 4.111491944058798e-05\n",
      "Epoch 2815, Loss: 0.0010044087775895605, Final Batch Loss: 4.5860484533477575e-05\n",
      "Epoch 2816, Loss: 0.00025548536223141127, Final Batch Loss: 2.8863838451798074e-05\n",
      "Epoch 2817, Loss: 0.00016171776269402471, Final Batch Loss: 4.427495241543511e-06\n",
      "Epoch 2818, Loss: 0.00015169420066740713, Final Batch Loss: 1.9740782590815797e-05\n",
      "Epoch 2819, Loss: 0.00010603232067296631, Final Batch Loss: 3.062875839532353e-05\n",
      "Epoch 2820, Loss: 0.00021141984325367957, Final Batch Loss: 1.1738966350094415e-05\n",
      "Epoch 2821, Loss: 0.00021431283374795385, Final Batch Loss: 2.675157588782895e-07\n",
      "Epoch 2822, Loss: 0.000752448408093187, Final Batch Loss: 4.1581952245905995e-05\n",
      "Epoch 2823, Loss: 0.0022034382291167276, Final Batch Loss: 0.001278604264371097\n",
      "Epoch 2824, Loss: 0.00037395147955976427, Final Batch Loss: 1.646796408749651e-05\n",
      "Epoch 2825, Loss: 8.08722445526655e-05, Final Batch Loss: 4.1075938497669995e-05\n",
      "Epoch 2826, Loss: 0.00010085326630360214, Final Batch Loss: 4.5325999963097274e-05\n",
      "Epoch 2827, Loss: 0.0007245071428769734, Final Batch Loss: 5.5985099606914446e-05\n",
      "Epoch 2828, Loss: 0.0038484306260215817, Final Batch Loss: 0.0034281255211681128\n",
      "Epoch 2829, Loss: 0.00465257344649217, Final Batch Loss: 0.003619830822572112\n",
      "Epoch 2830, Loss: 0.00012734586925944313, Final Batch Loss: 5.435014099930413e-05\n",
      "Epoch 2831, Loss: 9.223193865182111e-05, Final Batch Loss: 2.6331370463594794e-05\n",
      "Epoch 2832, Loss: 0.00010083893221235485, Final Batch Loss: 4.0038462429947685e-06\n",
      "Epoch 2833, Loss: 0.00020871406559308525, Final Batch Loss: 9.170512385026086e-07\n",
      "Epoch 2834, Loss: 6.216650990609196e-05, Final Batch Loss: 4.51430287284893e-06\n",
      "Epoch 2835, Loss: 0.00019293942023068666, Final Batch Loss: 1.272796725970693e-05\n",
      "Epoch 2836, Loss: 0.00012967668226337992, Final Batch Loss: 4.3915006244787946e-05\n",
      "Epoch 2837, Loss: 0.00032350872584174795, Final Batch Loss: 3.054246235478786e-06\n",
      "Epoch 2838, Loss: 0.00040306118808075553, Final Batch Loss: 9.907061212288681e-06\n",
      "Epoch 2839, Loss: 5.026572102906357e-05, Final Batch Loss: 1.4098236533754971e-05\n",
      "Epoch 2840, Loss: 0.0010509740241104737, Final Batch Loss: 8.577175321988761e-06\n",
      "Epoch 2841, Loss: 0.001604472054850703, Final Batch Loss: 0.0010349182412028313\n",
      "Epoch 2842, Loss: 0.0022376858760253526, Final Batch Loss: 5.0769831432262436e-05\n",
      "Epoch 2843, Loss: 0.0002937563408522692, Final Batch Loss: 9.861280705081299e-05\n",
      "Epoch 2844, Loss: 0.0001052547549988958, Final Batch Loss: 1.4874461157887708e-05\n",
      "Epoch 2845, Loss: 0.00016046032533267862, Final Batch Loss: 2.6023770260508172e-05\n",
      "Epoch 2846, Loss: 0.0004442930530785816, Final Batch Loss: 0.00027809443417936563\n",
      "Epoch 2847, Loss: 0.00010625872096170497, Final Batch Loss: 6.370512710418552e-05\n",
      "Epoch 2848, Loss: 0.0005058439010099391, Final Batch Loss: 0.00016173841140698642\n",
      "Epoch 2849, Loss: 0.0006861340227715118, Final Batch Loss: 2.302367875017808e-06\n",
      "Epoch 2850, Loss: 0.00018148815934182494, Final Batch Loss: 0.00010134914919035509\n",
      "Epoch 2851, Loss: 0.0007833305207896046, Final Batch Loss: 6.016895713401027e-05\n",
      "Epoch 2852, Loss: 0.00036030849514645524, Final Batch Loss: 8.620899461675435e-05\n",
      "Epoch 2853, Loss: 0.00029285964228620287, Final Batch Loss: 0.00014775364252272993\n",
      "Epoch 2854, Loss: 0.00025191584427375346, Final Batch Loss: 1.1250982424826361e-05\n",
      "Epoch 2855, Loss: 0.0001626163893888588, Final Batch Loss: 7.888579602877144e-06\n",
      "Epoch 2856, Loss: 0.0003395069668385986, Final Batch Loss: 1.3365749964577844e-06\n",
      "Epoch 2857, Loss: 0.0014314315676529077, Final Batch Loss: 2.4128310542437248e-05\n",
      "Epoch 2858, Loss: 5.832668466609903e-05, Final Batch Loss: 2.6103243726538494e-06\n",
      "Epoch 2859, Loss: 0.000104957694247787, Final Batch Loss: 6.0554568335646763e-05\n",
      "Epoch 2860, Loss: 0.00012334896496213332, Final Batch Loss: 2.6121111659449525e-05\n",
      "Epoch 2861, Loss: 0.0004717375520613132, Final Batch Loss: 1.2971938758710166e-06\n",
      "Epoch 2862, Loss: 0.0008608619755250402, Final Batch Loss: 3.820742858806625e-05\n",
      "Epoch 2863, Loss: 0.00014903034298185958, Final Batch Loss: 8.640639862278476e-06\n",
      "Epoch 2864, Loss: 0.005676665856299223, Final Batch Loss: 9.920939191943035e-06\n",
      "Epoch 2865, Loss: 0.0001965237470358261, Final Batch Loss: 8.996999895316549e-06\n",
      "Epoch 2866, Loss: 0.001314305008691008, Final Batch Loss: 1.9011413314728998e-05\n",
      "Epoch 2867, Loss: 0.006820111714887389, Final Batch Loss: 6.354590004775673e-05\n",
      "Epoch 2868, Loss: 0.00015984541710167832, Final Batch Loss: 0.00012201759091112763\n",
      "Epoch 2869, Loss: 0.0008316789640048228, Final Batch Loss: 5.4249135246209335e-06\n",
      "Epoch 2870, Loss: 4.916334427207403e-05, Final Batch Loss: 4.2615098209353164e-05\n",
      "Epoch 2871, Loss: 5.358297136126566e-05, Final Batch Loss: 1.2025038813590072e-05\n",
      "Epoch 2872, Loss: 0.021010562104947894, Final Batch Loss: 1.5354060451500118e-05\n",
      "Epoch 2873, Loss: 9.1579098807415e-05, Final Batch Loss: 8.832923413137905e-06\n",
      "Epoch 2874, Loss: 0.00018647652359504718, Final Batch Loss: 1.8190526134276297e-06\n",
      "Epoch 2875, Loss: 0.013973902849556907, Final Batch Loss: 8.424034604104236e-06\n",
      "Epoch 2876, Loss: 0.0008746977828195668, Final Batch Loss: 0.00015946841449476779\n",
      "Epoch 2877, Loss: 0.0290834595762135, Final Batch Loss: 3.3027779863914475e-05\n",
      "Epoch 2878, Loss: 0.01066520217955258, Final Batch Loss: 1.1790927601396106e-05\n",
      "Epoch 2879, Loss: 0.0004017874307464808, Final Batch Loss: 1.841826451709494e-05\n",
      "Epoch 2880, Loss: 0.013338727510472381, Final Batch Loss: 7.2511461439717095e-06\n",
      "Epoch 2881, Loss: 0.0007625838525200379, Final Batch Loss: 1.0925537026196253e-05\n",
      "Epoch 2882, Loss: 0.004312926608690759, Final Batch Loss: 0.000665222411043942\n",
      "Epoch 2883, Loss: 0.004451490677638503, Final Batch Loss: 9.171943929686677e-06\n",
      "Epoch 2884, Loss: 0.00126244989951374, Final Batch Loss: 1.7293899873038754e-05\n",
      "Epoch 2885, Loss: 0.030365296868694713, Final Batch Loss: 0.030208442360162735\n",
      "Epoch 2886, Loss: 0.013483417238603579, Final Batch Loss: 4.7590354370186105e-05\n",
      "Epoch 2887, Loss: 0.00011221732847843668, Final Batch Loss: 1.7013751858030446e-05\n",
      "Epoch 2888, Loss: 0.01006744623555278, Final Batch Loss: 0.004236616659909487\n",
      "Epoch 2889, Loss: 0.0014886704084347002, Final Batch Loss: 3.248327266192064e-05\n",
      "Epoch 2890, Loss: 0.001894109242130071, Final Batch Loss: 0.0001693947851890698\n",
      "Epoch 2891, Loss: 0.00020140484548392124, Final Batch Loss: 4.4424050429370254e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2892, Loss: 0.00021337012276489986, Final Batch Loss: 3.587592073017731e-05\n",
      "Epoch 2893, Loss: 0.00019507767706272716, Final Batch Loss: 6.535078136948869e-05\n",
      "Epoch 2894, Loss: 0.0008012704056454822, Final Batch Loss: 4.312857345212251e-05\n",
      "Epoch 2895, Loss: 0.009245380389074853, Final Batch Loss: 1.2371391676424537e-05\n",
      "Epoch 2896, Loss: 0.00013238467454357306, Final Batch Loss: 4.470371095521841e-06\n",
      "Epoch 2897, Loss: 0.002210422997450223, Final Batch Loss: 1.1657539289444685e-06\n",
      "Epoch 2898, Loss: 0.00012926347744723898, Final Batch Loss: 4.1971511564042885e-06\n",
      "Epoch 2899, Loss: 0.0008547352390451124, Final Batch Loss: 0.00017380189092364162\n",
      "Epoch 2900, Loss: 9.231172680301825e-05, Final Batch Loss: 6.710017623845488e-05\n",
      "Epoch 2901, Loss: 0.0001257851245100028, Final Batch Loss: 8.902288755052723e-06\n",
      "Epoch 2902, Loss: 0.0012283886754573814, Final Batch Loss: 3.1726276006338594e-07\n",
      "Epoch 2903, Loss: 0.00012508341228567588, Final Batch Loss: 1.8619793991092592e-05\n",
      "Epoch 2904, Loss: 0.00015159204122028314, Final Batch Loss: 2.216976645286195e-05\n",
      "Epoch 2905, Loss: 0.00032371480938309105, Final Batch Loss: 1.75071218109224e-05\n",
      "Epoch 2906, Loss: 0.0038056625393210197, Final Batch Loss: 0.0023512335028499365\n",
      "Epoch 2907, Loss: 0.00010461558031238383, Final Batch Loss: 3.425784598221071e-05\n",
      "Epoch 2908, Loss: 7.359197024925379e-05, Final Batch Loss: 5.703553142666351e-06\n",
      "Epoch 2909, Loss: 0.00022152732435642974, Final Batch Loss: 3.4240047170897014e-06\n",
      "Epoch 2910, Loss: 5.987169970467221e-05, Final Batch Loss: 8.151514521159697e-06\n",
      "Epoch 2911, Loss: 0.0008104696801183309, Final Batch Loss: 3.1910324196360307e-06\n",
      "Epoch 2912, Loss: 6.657299218204571e-05, Final Batch Loss: 2.0128238247707486e-05\n",
      "Epoch 2913, Loss: 0.00020027925893373322, Final Batch Loss: 1.8197959434473887e-05\n",
      "Epoch 2914, Loss: 0.0003245833686378319, Final Batch Loss: 1.9695469745784067e-05\n",
      "Epoch 2915, Loss: 0.0001889726722197338, Final Batch Loss: 5.603728254754969e-07\n",
      "Epoch 2916, Loss: 0.0003001251752721146, Final Batch Loss: 5.5113749112933874e-05\n",
      "Epoch 2917, Loss: 0.0004658075031329645, Final Batch Loss: 1.7424785255570896e-05\n",
      "Epoch 2918, Loss: 0.00035382046371523757, Final Batch Loss: 9.246292029274628e-05\n",
      "Epoch 2919, Loss: 0.00012885082469438203, Final Batch Loss: 3.6958685086574405e-05\n",
      "Epoch 2920, Loss: 5.469801067192748e-05, Final Batch Loss: 3.0427993351622717e-06\n",
      "Epoch 2921, Loss: 0.022211992867596564, Final Batch Loss: 0.021705955266952515\n",
      "Epoch 2922, Loss: 0.0004887785489700036, Final Batch Loss: 0.0003721750108525157\n",
      "Epoch 2923, Loss: 0.03029681380940019, Final Batch Loss: 0.00017920558457262814\n",
      "Epoch 2924, Loss: 0.0031526340026175603, Final Batch Loss: 0.00015298252401407808\n",
      "Epoch 2925, Loss: 0.0012490168155636638, Final Batch Loss: 0.0003564445360098034\n",
      "Epoch 2926, Loss: 0.0082810294097726, Final Batch Loss: 4.107765926164575e-05\n",
      "Epoch 2927, Loss: 0.015474869805984781, Final Batch Loss: 7.284527964657173e-05\n",
      "Epoch 2928, Loss: 0.0008694910313806758, Final Batch Loss: 7.546580036432715e-07\n",
      "Epoch 2929, Loss: 0.012377216289678472, Final Batch Loss: 3.748782546608709e-06\n",
      "Epoch 2930, Loss: 0.05793047213592217, Final Batch Loss: 0.057146959006786346\n",
      "Epoch 2931, Loss: 0.010166918564209482, Final Batch Loss: 0.005436853505671024\n",
      "Epoch 2932, Loss: 0.002222128172434168, Final Batch Loss: 0.0018394415965303779\n",
      "Epoch 2933, Loss: 0.0013564593682531267, Final Batch Loss: 7.532686868216842e-05\n",
      "Epoch 2934, Loss: 0.0006714511255268008, Final Batch Loss: 0.00027677437174133956\n",
      "Epoch 2935, Loss: 0.0008126700590764813, Final Batch Loss: 7.202924734883709e-06\n",
      "Epoch 2936, Loss: 0.0005617101869574981, Final Batch Loss: 2.6986930606653914e-05\n",
      "Epoch 2937, Loss: 0.00026431157880324463, Final Batch Loss: 3.4427923765179003e-06\n",
      "Epoch 2938, Loss: 0.00027638311803457327, Final Batch Loss: 0.00012326754222158343\n",
      "Epoch 2939, Loss: 0.0007546881242888048, Final Batch Loss: 3.9531099901068956e-05\n",
      "Epoch 2940, Loss: 0.0014475733100880461, Final Batch Loss: 0.0002206766657764092\n",
      "Epoch 2941, Loss: 0.00021567497060459573, Final Batch Loss: 2.7674634111463092e-05\n",
      "Epoch 2942, Loss: 0.000869901072292123, Final Batch Loss: 7.249152258737013e-05\n",
      "Epoch 2943, Loss: 0.0002517659049772192, Final Batch Loss: 5.083078576717526e-05\n",
      "Epoch 2944, Loss: 8.900115926735452e-05, Final Batch Loss: 2.138987292710226e-05\n",
      "Epoch 2945, Loss: 0.0005671288527082652, Final Batch Loss: 0.00012214986782055348\n",
      "Epoch 2946, Loss: 0.0003244706804252928, Final Batch Loss: 0.0001946323609445244\n",
      "Epoch 2947, Loss: 0.0001720161071716575, Final Batch Loss: 1.6155687262653373e-05\n",
      "Epoch 2948, Loss: 0.00025710550380608765, Final Batch Loss: 3.9251499401871115e-05\n",
      "Epoch 2949, Loss: 0.00047715118125779554, Final Batch Loss: 1.4219973309081979e-05\n",
      "Epoch 2950, Loss: 0.010762952086224686, Final Batch Loss: 3.2817104511195794e-05\n",
      "Epoch 2951, Loss: 0.0006084881588321878, Final Batch Loss: 0.0004569251323118806\n",
      "Epoch 2952, Loss: 0.00041190269348589936, Final Batch Loss: 1.3066998690192122e-05\n",
      "Epoch 2953, Loss: 0.004328310191340279, Final Batch Loss: 0.0028710244223475456\n",
      "Epoch 2954, Loss: 0.0003455601545283571, Final Batch Loss: 3.491197639959864e-05\n",
      "Epoch 2955, Loss: 0.0031718920354251168, Final Batch Loss: 8.86459238245152e-05\n",
      "Epoch 2956, Loss: 0.0010665888439689297, Final Batch Loss: 0.0005524850566871464\n",
      "Epoch 2957, Loss: 0.00018551035100244917, Final Batch Loss: 2.6684610929805785e-06\n",
      "Epoch 2958, Loss: 0.00015257110976563126, Final Batch Loss: 8.393456482735928e-06\n",
      "Epoch 2959, Loss: 0.0002496052584319841, Final Batch Loss: 5.8156540035270154e-05\n",
      "Epoch 2960, Loss: 0.031811917362574604, Final Batch Loss: 0.031140850856900215\n",
      "Epoch 2961, Loss: 0.0003522206752677448, Final Batch Loss: 0.0001081846421584487\n",
      "Epoch 2962, Loss: 0.01637586342803843, Final Batch Loss: 0.0002845599374268204\n",
      "Epoch 2963, Loss: 0.0008632389665308438, Final Batch Loss: 3.1762003800395178e-06\n",
      "Epoch 2964, Loss: 0.0004152263281866908, Final Batch Loss: 7.14169509592466e-05\n",
      "Epoch 2965, Loss: 0.0005499283693097823, Final Batch Loss: 6.740725075360388e-05\n",
      "Epoch 2966, Loss: 0.009826471183259855, Final Batch Loss: 0.00011008510045940056\n",
      "Epoch 2967, Loss: 0.00025596339037292637, Final Batch Loss: 3.788414323935285e-05\n",
      "Epoch 2968, Loss: 0.0003644540884124581, Final Batch Loss: 1.7121677956311032e-05\n",
      "Epoch 2969, Loss: 0.0020527580286398006, Final Batch Loss: 0.0010690974304452538\n",
      "Epoch 2970, Loss: 0.004842735170313972, Final Batch Loss: 5.551488357014023e-06\n",
      "Epoch 2971, Loss: 0.0011045531682611909, Final Batch Loss: 0.00024394063802901655\n",
      "Epoch 2972, Loss: 0.0009448952187085524, Final Batch Loss: 0.0005030427128076553\n",
      "Epoch 2973, Loss: 0.0026918182102235733, Final Batch Loss: 2.820313056872692e-05\n",
      "Epoch 2974, Loss: 0.038019283096218714, Final Batch Loss: 7.992407336132601e-05\n",
      "Epoch 2975, Loss: 0.0007265250860655215, Final Batch Loss: 4.6697576181031764e-05\n",
      "Epoch 2976, Loss: 0.0050244108078914, Final Batch Loss: 0.003571242792531848\n",
      "Epoch 2977, Loss: 0.0006041520282451529, Final Batch Loss: 0.0003213777090422809\n",
      "Epoch 2978, Loss: 0.004674001360399416, Final Batch Loss: 7.22670229151845e-05\n",
      "Epoch 2979, Loss: 0.010249995219055563, Final Batch Loss: 0.000433473294833675\n",
      "Epoch 2980, Loss: 0.003705716102558654, Final Batch Loss: 8.999433339340612e-05\n",
      "Epoch 2981, Loss: 0.008600689782724658, Final Batch Loss: 9.721551577968057e-06\n",
      "Epoch 2982, Loss: 0.0005680122849298641, Final Batch Loss: 1.6394991689594463e-05\n",
      "Epoch 2983, Loss: 0.0057398905119043775, Final Batch Loss: 0.004940240643918514\n",
      "Epoch 2984, Loss: 0.002968011942357407, Final Batch Loss: 0.002378688892349601\n",
      "Epoch 2985, Loss: 0.000286854839487205, Final Batch Loss: 3.479267888906179e-06\n",
      "Epoch 2986, Loss: 0.0004554247407213552, Final Batch Loss: 1.6956588297034614e-05\n",
      "Epoch 2987, Loss: 0.0012044981522194576, Final Batch Loss: 9.485727787250653e-06\n",
      "Epoch 2988, Loss: 0.00021811209808220156, Final Batch Loss: 1.4533998182741925e-05\n",
      "Epoch 2989, Loss: 0.0009064818541446584, Final Batch Loss: 0.0005087499739602208\n",
      "Epoch 2990, Loss: 0.002375745043536881, Final Batch Loss: 2.139034404535778e-05\n",
      "Epoch 2991, Loss: 0.0008876295105437748, Final Batch Loss: 2.333273005206138e-05\n",
      "Epoch 2992, Loss: 0.0004107031272724271, Final Batch Loss: 8.123730367515236e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2993, Loss: 0.001183475149446167, Final Batch Loss: 0.00030935395625419915\n",
      "Epoch 2994, Loss: 0.0018289504678250523, Final Batch Loss: 2.5777428163564764e-05\n",
      "Epoch 2995, Loss: 0.0010491312859812751, Final Batch Loss: 0.00013898589531891048\n",
      "Epoch 2996, Loss: 0.004196946523734368, Final Batch Loss: 0.002720839576795697\n",
      "Epoch 2997, Loss: 0.0009934238842106424, Final Batch Loss: 7.283407467184588e-05\n",
      "Epoch 2998, Loss: 0.0014074219752728823, Final Batch Loss: 4.71885778097203e-06\n",
      "Epoch 2999, Loss: 0.000470574992505135, Final Batch Loss: 0.00021938075951766223\n",
      "Epoch 3000, Loss: 0.0018735153280431405, Final Batch Loss: 7.617546361871064e-05\n",
      "Epoch 3001, Loss: 0.029669121550796262, Final Batch Loss: 1.2923364010930527e-05\n",
      "Epoch 3002, Loss: 0.0007168879164964892, Final Batch Loss: 2.2591251763515174e-05\n",
      "Epoch 3003, Loss: 0.02245170803689689, Final Batch Loss: 1.966570744116325e-05\n",
      "Epoch 3004, Loss: 0.00902556022265344, Final Batch Loss: 0.00024728060816414654\n",
      "Epoch 3005, Loss: 0.00032447141711600125, Final Batch Loss: 3.673407627502456e-05\n",
      "Epoch 3006, Loss: 0.0006257059394556563, Final Batch Loss: 4.849522883887403e-05\n",
      "Epoch 3007, Loss: 0.0011793170160672162, Final Batch Loss: 0.0009331722394563258\n",
      "Epoch 3008, Loss: 0.0020758497557835653, Final Batch Loss: 0.0004291814402677119\n",
      "Epoch 3009, Loss: 0.0009288258643209701, Final Batch Loss: 2.3071805117069744e-05\n",
      "Epoch 3010, Loss: 0.0023387566361634526, Final Batch Loss: 0.00030561062158085406\n",
      "Epoch 3011, Loss: 0.008916460879845545, Final Batch Loss: 0.0014484977582469583\n",
      "Epoch 3012, Loss: 0.0048065894243336516, Final Batch Loss: 1.3840281098964624e-05\n",
      "Epoch 3013, Loss: 0.0035951624104200164, Final Batch Loss: 9.709699952509254e-05\n",
      "Epoch 3014, Loss: 0.0020072800671186997, Final Batch Loss: 0.0005304107908159494\n",
      "Epoch 3015, Loss: 0.0011592833761824295, Final Batch Loss: 7.047296094242483e-05\n",
      "Epoch 3016, Loss: 0.0013171803002478555, Final Batch Loss: 3.7490692193387076e-05\n",
      "Epoch 3017, Loss: 0.0008180670756701147, Final Batch Loss: 3.863721576635726e-05\n",
      "Epoch 3018, Loss: 0.0007379414382739924, Final Batch Loss: 0.00014038922381587327\n",
      "Epoch 3019, Loss: 0.0013208415803092066, Final Batch Loss: 0.0004133548936806619\n",
      "Epoch 3020, Loss: 0.0010356081675126916, Final Batch Loss: 0.0005919820396229625\n",
      "Epoch 3021, Loss: 0.005048775925388327, Final Batch Loss: 0.00029642044682987034\n",
      "Epoch 3022, Loss: 0.0018251439482810383, Final Batch Loss: 5.2964176575187594e-05\n",
      "Epoch 3023, Loss: 0.009336401016298623, Final Batch Loss: 0.008811650797724724\n",
      "Epoch 3024, Loss: 0.0002137245701305801, Final Batch Loss: 4.592622644850053e-05\n",
      "Epoch 3025, Loss: 0.0006355003970384132, Final Batch Loss: 0.0002663923951331526\n",
      "Epoch 3026, Loss: 0.003185340334312059, Final Batch Loss: 7.679843110963702e-05\n",
      "Epoch 3027, Loss: 0.0009554178650432732, Final Batch Loss: 0.0002661018806975335\n",
      "Epoch 3028, Loss: 0.0026317094516343786, Final Batch Loss: 4.460242053028196e-06\n",
      "Epoch 3029, Loss: 0.0035378120082896203, Final Batch Loss: 0.00016659054381307214\n",
      "Epoch 3030, Loss: 0.0009435949250473641, Final Batch Loss: 1.018973853206262e-05\n",
      "Epoch 3031, Loss: 0.0008200114336887054, Final Batch Loss: 2.4582129753980553e-06\n",
      "Epoch 3032, Loss: 0.0007030413216853049, Final Batch Loss: 0.00013945178943686187\n",
      "Epoch 3033, Loss: 0.0008139941946865292, Final Batch Loss: 0.0005209792871028185\n",
      "Epoch 3034, Loss: 0.0007481795310013695, Final Batch Loss: 0.0001407306845067069\n",
      "Epoch 3035, Loss: 0.002200373510731879, Final Batch Loss: 3.242525508539984e-06\n",
      "Epoch 3036, Loss: 0.0006296480532910209, Final Batch Loss: 7.038547482807189e-05\n",
      "Epoch 3037, Loss: 0.0002659708261489868, Final Batch Loss: 4.8314577725250274e-05\n",
      "Epoch 3038, Loss: 0.00039495308374171145, Final Batch Loss: 4.186591468169354e-05\n",
      "Epoch 3039, Loss: 0.0009728011482366128, Final Batch Loss: 0.0008796603651717305\n",
      "Epoch 3040, Loss: 0.0006415376337827183, Final Batch Loss: 8.671478281030431e-05\n",
      "Epoch 3041, Loss: 0.013611993833364977, Final Batch Loss: 7.290392204595264e-06\n",
      "Epoch 3042, Loss: 0.0030774571641813964, Final Batch Loss: 0.0013073614099994302\n",
      "Epoch 3043, Loss: 0.0002932632669399027, Final Batch Loss: 5.600288568530232e-05\n",
      "Epoch 3044, Loss: 0.0005093033043976902, Final Batch Loss: 3.18934439746954e-06\n",
      "Epoch 3045, Loss: 0.0005434288759715855, Final Batch Loss: 4.735777838504873e-05\n",
      "Epoch 3046, Loss: 0.00034150196370319463, Final Batch Loss: 1.904206510516815e-05\n",
      "Epoch 3047, Loss: 0.008578447399486322, Final Batch Loss: 8.21164358058013e-05\n",
      "Epoch 3048, Loss: 0.0038856690534885274, Final Batch Loss: 0.00024085243057925254\n",
      "Epoch 3049, Loss: 0.000426674319896847, Final Batch Loss: 3.422791633056477e-05\n",
      "Epoch 3050, Loss: 0.006833270290371729, Final Batch Loss: 0.00027461256831884384\n",
      "Epoch 3051, Loss: 0.003221725529328978, Final Batch Loss: 1.1770695891755167e-05\n",
      "Epoch 3052, Loss: 0.0012372979372230475, Final Batch Loss: 5.588947533397004e-05\n",
      "Epoch 3053, Loss: 0.00044225343845027965, Final Batch Loss: 1.8461831132299267e-05\n",
      "Epoch 3054, Loss: 0.00043543636638787575, Final Batch Loss: 5.333969966159202e-05\n",
      "Epoch 3055, Loss: 0.004375979013275355, Final Batch Loss: 0.0003864837053697556\n",
      "Epoch 3056, Loss: 0.0010161769678234123, Final Batch Loss: 0.0006221854127943516\n",
      "Epoch 3057, Loss: 0.003407575946766883, Final Batch Loss: 3.1023075280245394e-05\n",
      "Epoch 3058, Loss: 0.0010309718072676333, Final Batch Loss: 0.00011519261897774413\n",
      "Epoch 3059, Loss: 0.0004748374399241584, Final Batch Loss: 5.8198215810989495e-06\n",
      "Epoch 3060, Loss: 0.00029312734068298596, Final Batch Loss: 5.464274636324262e-06\n",
      "Epoch 3061, Loss: 0.0001415157621522667, Final Batch Loss: 7.497460319427773e-05\n",
      "Epoch 3062, Loss: 0.0044696361692331266, Final Batch Loss: 0.004380977246910334\n",
      "Epoch 3063, Loss: 0.0010529704304644838, Final Batch Loss: 2.6116387743968517e-05\n",
      "Epoch 3064, Loss: 0.0003818285263150756, Final Batch Loss: 7.434096005454194e-07\n",
      "Epoch 3065, Loss: 0.012699892240561894, Final Batch Loss: 3.018571987922769e-05\n",
      "Epoch 3066, Loss: 0.0007310117034649011, Final Batch Loss: 6.099747770349495e-05\n",
      "Epoch 3067, Loss: 0.012832744066145096, Final Batch Loss: 9.201369721267838e-06\n",
      "Epoch 3068, Loss: 0.00024859771019691834, Final Batch Loss: 0.00014140830899123102\n",
      "Epoch 3069, Loss: 0.0003401750095690659, Final Batch Loss: 5.825668722536648e-06\n",
      "Epoch 3070, Loss: 0.0006583579051948618, Final Batch Loss: 1.5134946806938387e-05\n",
      "Epoch 3071, Loss: 0.0003347401125211036, Final Batch Loss: 9.379780385643244e-05\n",
      "Epoch 3072, Loss: 0.0004959959894677013, Final Batch Loss: 1.9355757103767246e-05\n",
      "Epoch 3073, Loss: 0.00013650199571202393, Final Batch Loss: 2.703089649003232e-06\n",
      "Epoch 3074, Loss: 0.021611007875435462, Final Batch Loss: 0.0004995429189875722\n",
      "Epoch 3075, Loss: 0.0038472734881906945, Final Batch Loss: 1.9634967429738026e-06\n",
      "Epoch 3076, Loss: 7.510015575462603e-05, Final Batch Loss: 3.93261834688019e-05\n",
      "Epoch 3077, Loss: 0.0021621979494739207, Final Batch Loss: 0.001978005049750209\n",
      "Epoch 3078, Loss: 0.0011795910213550087, Final Batch Loss: 0.0001039330818457529\n",
      "Epoch 3079, Loss: 0.0001321536983596161, Final Batch Loss: 1.3863098502042703e-05\n",
      "Epoch 3080, Loss: 0.0010356375096307602, Final Batch Loss: 1.2031563528580591e-05\n",
      "Epoch 3081, Loss: 0.00044071940010326216, Final Batch Loss: 1.1549219379958231e-05\n",
      "Epoch 3082, Loss: 0.003098205095739104, Final Batch Loss: 6.721002864651382e-05\n",
      "Epoch 3083, Loss: 0.0016585676257818704, Final Batch Loss: 1.2635928214876913e-05\n",
      "Epoch 3084, Loss: 0.00032768730670795776, Final Batch Loss: 0.00013621890684589744\n",
      "Epoch 3085, Loss: 0.00010630459564708872, Final Batch Loss: 2.1672558432328515e-06\n",
      "Epoch 3086, Loss: 0.00010444946656207321, Final Batch Loss: 3.3210584660992026e-05\n",
      "Epoch 3087, Loss: 0.015170744954957627, Final Batch Loss: 0.002022240310907364\n",
      "Epoch 3088, Loss: 0.0003409114378882805, Final Batch Loss: 0.00012422646977938712\n",
      "Epoch 3089, Loss: 0.00020557385778374737, Final Batch Loss: 4.5118536945665255e-05\n",
      "Epoch 3090, Loss: 0.00010304793431714643, Final Batch Loss: 1.1857991012220737e-05\n",
      "Epoch 3091, Loss: 0.0006149533382995287, Final Batch Loss: 8.570732461521402e-05\n",
      "Epoch 3092, Loss: 0.0040912279564508935, Final Batch Loss: 0.00048217136645689607\n",
      "Epoch 3093, Loss: 0.0007343423130805604, Final Batch Loss: 7.662527059437707e-05\n",
      "Epoch 3094, Loss: 0.00020778632642759476, Final Batch Loss: 4.319759682402946e-06\n",
      "Epoch 3095, Loss: 0.03311710804064205, Final Batch Loss: 0.008475533686578274\n",
      "Epoch 3096, Loss: 0.0005305401355144568, Final Batch Loss: 3.995237420895137e-05\n",
      "Epoch 3097, Loss: 0.0014283721557148965, Final Batch Loss: 5.8492907555773854e-05\n",
      "Epoch 3098, Loss: 0.0047040378412930295, Final Batch Loss: 0.00035480709630064666\n",
      "Epoch 3099, Loss: 0.008987439672637265, Final Batch Loss: 8.105354936560616e-06\n",
      "Epoch 3100, Loss: 0.0004112674832867924, Final Batch Loss: 4.121355959796347e-05\n",
      "Epoch 3101, Loss: 0.0007033169044916576, Final Batch Loss: 3.438168732827762e-06\n",
      "Epoch 3102, Loss: 0.0022390621779777575, Final Batch Loss: 0.0007940283394418657\n",
      "Epoch 3103, Loss: 0.005177896528039128, Final Batch Loss: 0.0003964663192164153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3104, Loss: 0.00018309158349438803, Final Batch Loss: 5.621981108561158e-05\n",
      "Epoch 3105, Loss: 0.001531553795302898, Final Batch Loss: 8.03279981482774e-05\n",
      "Epoch 3106, Loss: 0.0002410334695923666, Final Batch Loss: 1.9119966054859105e-06\n",
      "Epoch 3107, Loss: 0.00013228189664005185, Final Batch Loss: 6.808326816098997e-06\n",
      "Epoch 3108, Loss: 0.0002014557394431904, Final Batch Loss: 2.199839218519628e-05\n",
      "Epoch 3109, Loss: 0.0003294156340416521, Final Batch Loss: 7.542746607214212e-05\n",
      "Epoch 3110, Loss: 0.00028656811900873436, Final Batch Loss: 0.00021456292597576976\n",
      "Epoch 3111, Loss: 0.0011868348342432, Final Batch Loss: 3.920413746527629e-06\n",
      "Epoch 3112, Loss: 0.0006086330395191908, Final Batch Loss: 0.00022723111032973975\n",
      "Epoch 3113, Loss: 0.000135739730012574, Final Batch Loss: 7.464607278961921e-06\n",
      "Epoch 3114, Loss: 0.0006882604429847561, Final Batch Loss: 4.675928357755765e-05\n",
      "Epoch 3115, Loss: 0.0002987289390148362, Final Batch Loss: 4.828573946724646e-05\n",
      "Epoch 3116, Loss: 0.0019300782155369234, Final Batch Loss: 0.0001561506069265306\n",
      "Epoch 3117, Loss: 0.00010588619988993742, Final Batch Loss: 3.5132619814248756e-05\n",
      "Epoch 3118, Loss: 0.00017209931809247792, Final Batch Loss: 9.770968745215214e-07\n",
      "Epoch 3119, Loss: 9.735602361615747e-05, Final Batch Loss: 2.7604719434748404e-05\n",
      "Epoch 3120, Loss: 0.01063604126466089, Final Batch Loss: 7.995688065420836e-05\n",
      "Epoch 3121, Loss: 0.0002528480581531767, Final Batch Loss: 5.205549314268865e-05\n",
      "Epoch 3122, Loss: 0.0005226460762060015, Final Batch Loss: 2.3855607651057653e-05\n",
      "Epoch 3123, Loss: 0.0012208025218569674, Final Batch Loss: 0.00022203303524293005\n",
      "Epoch 3124, Loss: 0.0027932148893796693, Final Batch Loss: 1.4820477645116625e-06\n",
      "Epoch 3125, Loss: 0.002115756844432326, Final Batch Loss: 5.972074359306134e-05\n",
      "Epoch 3126, Loss: 0.000402918254621909, Final Batch Loss: 2.126118852174841e-05\n",
      "Epoch 3127, Loss: 0.00043660453593474813, Final Batch Loss: 1.488541420258116e-05\n",
      "Epoch 3128, Loss: 0.0003919110631613876, Final Batch Loss: 4.8274319851771e-05\n",
      "Epoch 3129, Loss: 0.0013542700762627646, Final Batch Loss: 0.00016400168533436954\n",
      "Epoch 3130, Loss: 0.00011204514521523379, Final Batch Loss: 2.0343164578662254e-05\n",
      "Epoch 3131, Loss: 0.0006975248054459371, Final Batch Loss: 0.0003993306017946452\n",
      "Epoch 3132, Loss: 0.00034513389073254075, Final Batch Loss: 5.582819721894339e-05\n",
      "Epoch 3133, Loss: 0.0015970937674865127, Final Batch Loss: 2.1900357751292177e-05\n",
      "Epoch 3134, Loss: 0.00026224407065456035, Final Batch Loss: 0.0001059638088918291\n",
      "Epoch 3135, Loss: 0.00025726260855662986, Final Batch Loss: 6.697000117128482e-06\n",
      "Epoch 3136, Loss: 0.00017633331799515872, Final Batch Loss: 4.045111563755199e-05\n",
      "Epoch 3137, Loss: 0.000663400593566621, Final Batch Loss: 8.332559082191437e-05\n",
      "Epoch 3138, Loss: 0.0003326244755044172, Final Batch Loss: 1.984614755201619e-05\n",
      "Epoch 3139, Loss: 0.0011776896553783445, Final Batch Loss: 0.0005182677996344864\n",
      "Epoch 3140, Loss: 0.0005229455455264542, Final Batch Loss: 0.00028653934714384377\n",
      "Epoch 3141, Loss: 0.000212619274861936, Final Batch Loss: 6.9247207648004405e-06\n",
      "Epoch 3142, Loss: 0.004836886717043853, Final Batch Loss: 7.227532705655904e-07\n",
      "Epoch 3143, Loss: 0.00029033536247879965, Final Batch Loss: 1.2097531907784287e-05\n",
      "Epoch 3144, Loss: 0.00043152892430953216, Final Batch Loss: 5.961208444205113e-06\n",
      "Epoch 3145, Loss: 0.0003243506889702985, Final Batch Loss: 2.566816510807257e-05\n",
      "Epoch 3146, Loss: 0.005088183727366413, Final Batch Loss: 5.618915565719362e-06\n",
      "Epoch 3147, Loss: 0.00017179364658659324, Final Batch Loss: 8.73377503012307e-05\n",
      "Epoch 3148, Loss: 0.0005307428666583291, Final Batch Loss: 3.7337656522140605e-06\n",
      "Epoch 3149, Loss: 6.721921556618327e-05, Final Batch Loss: 1.7148805682154489e-06\n",
      "Epoch 3150, Loss: 0.004275951978343073, Final Batch Loss: 0.003908121958374977\n",
      "Epoch 3151, Loss: 0.00010702240524551598, Final Batch Loss: 2.5023409762070514e-06\n",
      "Epoch 3152, Loss: 0.00013783637041342445, Final Batch Loss: 2.209541889897082e-05\n",
      "Epoch 3153, Loss: 0.00019644500616777805, Final Batch Loss: 8.056789374677464e-05\n",
      "Epoch 3154, Loss: 6.34086859463423e-05, Final Batch Loss: 6.280908110056771e-06\n",
      "Epoch 3155, Loss: 6.746519829903264e-05, Final Batch Loss: 1.1610170986386947e-05\n",
      "Epoch 3156, Loss: 0.000936614180432116, Final Batch Loss: 1.1986113577222568e-06\n",
      "Epoch 3157, Loss: 0.0028737118568642472, Final Batch Loss: 4.680712208937621e-06\n",
      "Epoch 3158, Loss: 0.0002187573286391853, Final Batch Loss: 3.039065450138878e-05\n",
      "Epoch 3159, Loss: 0.0006269799954452537, Final Batch Loss: 1.6304069276884547e-06\n",
      "Epoch 3160, Loss: 0.04237533232662827, Final Batch Loss: 0.030287619680166245\n",
      "Epoch 3161, Loss: 0.01634826117515331, Final Batch Loss: 0.00026084514684043825\n",
      "Epoch 3162, Loss: 0.03378836208139546, Final Batch Loss: 0.000649453024379909\n",
      "Epoch 3163, Loss: 0.03335468493492044, Final Batch Loss: 2.6252735096932156e-06\n",
      "Epoch 3164, Loss: 0.04147838916105684, Final Batch Loss: 0.0411381870508194\n",
      "Epoch 3165, Loss: 0.011518149913172238, Final Batch Loss: 0.0001956284249899909\n",
      "Epoch 3166, Loss: 0.0076943876629229635, Final Batch Loss: 0.0026961173862218857\n",
      "Epoch 3167, Loss: 0.007448625547112897, Final Batch Loss: 5.9744255850091577e-05\n",
      "Epoch 3168, Loss: 0.024157186635420658, Final Batch Loss: 7.000927871558815e-05\n",
      "Epoch 3169, Loss: 0.010746753207058646, Final Batch Loss: 0.009781863540410995\n",
      "Epoch 3170, Loss: 0.0006870499046272016, Final Batch Loss: 4.015463673567865e-06\n",
      "Epoch 3171, Loss: 0.0018947938224300742, Final Batch Loss: 0.001156339538283646\n",
      "Epoch 3172, Loss: 0.001269955499083153, Final Batch Loss: 2.7330379452905618e-05\n",
      "Epoch 3173, Loss: 0.026431513455463573, Final Batch Loss: 0.009556228294968605\n",
      "Epoch 3174, Loss: 0.0019785295662586577, Final Batch Loss: 1.828709355322644e-05\n",
      "Epoch 3175, Loss: 0.0008485299858875806, Final Batch Loss: 0.00012831870117224753\n",
      "Epoch 3176, Loss: 0.0003787754430959467, Final Batch Loss: 2.6021622034022585e-05\n",
      "Epoch 3177, Loss: 0.003954264462663559, Final Batch Loss: 4.796050416189246e-05\n",
      "Epoch 3178, Loss: 0.0008322403627971653, Final Batch Loss: 2.784117532428354e-05\n",
      "Epoch 3179, Loss: 0.00029420277223835, Final Batch Loss: 2.0565556042129174e-05\n",
      "Epoch 3180, Loss: 0.00048307313772966154, Final Batch Loss: 0.00019264972070232034\n",
      "Epoch 3181, Loss: 0.0009454468072362943, Final Batch Loss: 4.7875120799290016e-05\n",
      "Epoch 3182, Loss: 0.0007591871617478319, Final Batch Loss: 5.415709892986342e-05\n",
      "Epoch 3183, Loss: 0.0016791781963547692, Final Batch Loss: 0.00027925337781198323\n",
      "Epoch 3184, Loss: 0.0006471470733231399, Final Batch Loss: 0.0002392971218796447\n",
      "Epoch 3185, Loss: 0.0005025794598623179, Final Batch Loss: 0.00010166680294787511\n",
      "Epoch 3186, Loss: 0.0004899554219264246, Final Batch Loss: 0.00013329970533959568\n",
      "Epoch 3187, Loss: 0.0009588003122189548, Final Batch Loss: 9.233329183189198e-05\n",
      "Epoch 3188, Loss: 0.012135100270825205, Final Batch Loss: 4.5078657421981916e-05\n",
      "Epoch 3189, Loss: 0.0027774332847911865, Final Batch Loss: 0.0007867747917771339\n",
      "Epoch 3190, Loss: 0.0011310120244161226, Final Batch Loss: 3.535702853696421e-05\n",
      "Epoch 3191, Loss: 0.001782748053301475, Final Batch Loss: 1.289887040911708e-05\n",
      "Epoch 3192, Loss: 0.0004454298059499706, Final Batch Loss: 0.0002581643348094076\n",
      "Epoch 3193, Loss: 0.005989397388475481, Final Batch Loss: 6.271646270761266e-05\n",
      "Epoch 3194, Loss: 0.00030210479235392995, Final Batch Loss: 2.649261659826152e-05\n",
      "Epoch 3195, Loss: 0.00022208888913155533, Final Batch Loss: 8.883514965418726e-06\n",
      "Epoch 3196, Loss: 0.01228304447067785, Final Batch Loss: 0.00020812745788134634\n",
      "Epoch 3197, Loss: 0.0006377565250659245, Final Batch Loss: 3.5870776628144085e-05\n",
      "Epoch 3198, Loss: 0.0005483587228809483, Final Batch Loss: 3.099211971857585e-05\n",
      "Epoch 3199, Loss: 0.00029891235590184806, Final Batch Loss: 0.0001368177472613752\n",
      "Epoch 3200, Loss: 0.0004124519164179219, Final Batch Loss: 2.526996649976354e-05\n",
      "Epoch 3201, Loss: 0.004719158700027037, Final Batch Loss: 0.001539176912046969\n",
      "Epoch 3202, Loss: 0.00022748556511942297, Final Batch Loss: 3.906796337105334e-05\n",
      "Epoch 3203, Loss: 0.001905853147036396, Final Batch Loss: 9.457744454266503e-06\n",
      "Epoch 3204, Loss: 0.000794761555880541, Final Batch Loss: 0.0002976285759359598\n",
      "Epoch 3205, Loss: 0.00044336827704682946, Final Batch Loss: 0.0001344016782240942\n",
      "Epoch 3206, Loss: 0.0012367624294711277, Final Batch Loss: 0.00011240041203564033\n",
      "Epoch 3207, Loss: 0.0005353173878575035, Final Batch Loss: 4.9642458179732785e-05\n",
      "Epoch 3208, Loss: 0.00033363695365551393, Final Batch Loss: 3.8406316889449954e-05\n",
      "Epoch 3209, Loss: 0.00010747464693849906, Final Batch Loss: 1.63371969392756e-05\n",
      "Epoch 3210, Loss: 0.0012760745012201369, Final Batch Loss: 0.00017631972150411457\n",
      "Epoch 3211, Loss: 0.0001443150736122334, Final Batch Loss: 6.142442998680053e-06\n",
      "Epoch 3212, Loss: 0.0003062081304960884, Final Batch Loss: 8.11170248198323e-05\n",
      "Epoch 3213, Loss: 0.0022274746438597504, Final Batch Loss: 2.6778502615343314e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3214, Loss: 0.0012772603186022025, Final Batch Loss: 0.00019538271590135992\n",
      "Epoch 3215, Loss: 0.00022048584696676699, Final Batch Loss: 3.779498365474865e-05\n",
      "Epoch 3216, Loss: 0.00017687750278128078, Final Batch Loss: 1.672108737693634e-05\n",
      "Epoch 3217, Loss: 0.0003942920970985142, Final Batch Loss: 4.066110250278143e-06\n",
      "Epoch 3218, Loss: 0.0007768483192194253, Final Batch Loss: 0.00020757634774781764\n",
      "Epoch 3219, Loss: 0.0003663731745291443, Final Batch Loss: 0.00028417256544344127\n",
      "Epoch 3220, Loss: 0.0001030256303238275, Final Batch Loss: 4.090792117494857e-06\n",
      "Epoch 3221, Loss: 0.00028029419991071336, Final Batch Loss: 8.05255476734601e-05\n",
      "Epoch 3222, Loss: 0.00032565202127443627, Final Batch Loss: 0.00010498447954887524\n",
      "Epoch 3223, Loss: 0.000791700749687152, Final Batch Loss: 2.1426534658530727e-05\n",
      "Epoch 3224, Loss: 0.00012937977089677588, Final Batch Loss: 6.986307653278345e-06\n",
      "Epoch 3225, Loss: 0.0001640274772967132, Final Batch Loss: 8.128614013003244e-07\n",
      "Epoch 3226, Loss: 0.0001112395020754775, Final Batch Loss: 1.616172812646255e-05\n",
      "Epoch 3227, Loss: 0.00013520601896743756, Final Batch Loss: 3.276673669461161e-05\n",
      "Epoch 3228, Loss: 0.00013922348853157018, Final Batch Loss: 3.8153870264068246e-05\n",
      "Epoch 3229, Loss: 8.940021689340938e-05, Final Batch Loss: 1.6373363905586302e-05\n",
      "Epoch 3230, Loss: 0.004955579629836393, Final Batch Loss: 1.0109009735970176e-06\n",
      "Epoch 3231, Loss: 0.0006828637815488037, Final Batch Loss: 4.885478119831532e-06\n",
      "Epoch 3232, Loss: 0.00015531685221503722, Final Batch Loss: 0.00011324749357299879\n",
      "Epoch 3233, Loss: 0.001038257990103375, Final Batch Loss: 1.9109818367724074e-06\n",
      "Epoch 3234, Loss: 0.00026190212838628213, Final Batch Loss: 5.7306310736748856e-06\n",
      "Epoch 3235, Loss: 0.006609042196032533, Final Batch Loss: 0.001413545454852283\n",
      "Epoch 3236, Loss: 0.00018916816406999715, Final Batch Loss: 5.084581425762735e-05\n",
      "Epoch 3237, Loss: 0.00014580928700524964, Final Batch Loss: 0.0001080184883903712\n",
      "Epoch 3238, Loss: 0.0015769887686474249, Final Batch Loss: 1.1100892152171582e-05\n",
      "Epoch 3239, Loss: 0.0001920503477776947, Final Batch Loss: 9.258421778213233e-05\n",
      "Epoch 3240, Loss: 0.0004177968094154494, Final Batch Loss: 2.8131436920375563e-05\n",
      "Epoch 3241, Loss: 0.0010354349069530144, Final Batch Loss: 0.0005338717019185424\n",
      "Epoch 3242, Loss: 0.00041361396051797783, Final Batch Loss: 0.0002654699783306569\n",
      "Epoch 3243, Loss: 0.00025509756414976437, Final Batch Loss: 0.00011081412230851129\n",
      "Epoch 3244, Loss: 0.00017408285987130512, Final Batch Loss: 9.057863508132868e-07\n",
      "Epoch 3245, Loss: 0.0010617066945997067, Final Batch Loss: 6.298658990999684e-05\n",
      "Epoch 3246, Loss: 0.00027359286605133093, Final Batch Loss: 2.4094420041365083e-06\n",
      "Epoch 3247, Loss: 0.00021116186076142185, Final Batch Loss: 2.7604103252087953e-06\n",
      "Epoch 3248, Loss: 0.0005423439943115227, Final Batch Loss: 0.00038881151704117656\n",
      "Epoch 3249, Loss: 0.00024331007102773583, Final Batch Loss: 2.6384116154076764e-06\n",
      "Epoch 3250, Loss: 0.00041277317450294504, Final Batch Loss: 5.258697456156369e-06\n",
      "Epoch 3251, Loss: 0.00017056044953278615, Final Batch Loss: 5.3215655498206615e-05\n",
      "Epoch 3252, Loss: 0.0001476806310165557, Final Batch Loss: 6.629664858337492e-05\n",
      "Epoch 3253, Loss: 0.0003257088301324984, Final Batch Loss: 2.1038480554125272e-05\n",
      "Epoch 3254, Loss: 0.00011699307287926786, Final Batch Loss: 2.0247829525033012e-05\n",
      "Epoch 3255, Loss: 0.0003090957525273552, Final Batch Loss: 3.1996987672755495e-06\n",
      "Epoch 3256, Loss: 7.17777356840088e-05, Final Batch Loss: 9.208330993715208e-06\n",
      "Epoch 3257, Loss: 0.0002919531580118928, Final Batch Loss: 5.5777651141397655e-05\n",
      "Epoch 3258, Loss: 0.0002387680342508247, Final Batch Loss: 3.151275450363755e-05\n",
      "Epoch 3259, Loss: 0.0009075583802768961, Final Batch Loss: 0.00026064334088005126\n",
      "Epoch 3260, Loss: 0.0006497944300463132, Final Batch Loss: 7.706417818553746e-05\n",
      "Epoch 3261, Loss: 4.558806222121348e-05, Final Batch Loss: 1.4922938134986907e-05\n",
      "Epoch 3262, Loss: 0.0016958321093625273, Final Batch Loss: 9.18911518965615e-06\n",
      "Epoch 3263, Loss: 0.00032725050778026343, Final Batch Loss: 6.92700859872275e-06\n",
      "Epoch 3264, Loss: 0.0002492199982953025, Final Batch Loss: 1.2575879736687057e-05\n",
      "Epoch 3265, Loss: 0.00036884250312141376, Final Batch Loss: 0.0001395929721184075\n",
      "Epoch 3266, Loss: 0.00036113002306592534, Final Batch Loss: 0.0003286213323008269\n",
      "Epoch 3267, Loss: 0.00023657771043872344, Final Batch Loss: 4.691832600656198e-06\n",
      "Epoch 3268, Loss: 0.00043894962527701864, Final Batch Loss: 1.4941271729185246e-05\n",
      "Epoch 3269, Loss: 0.0001539269533168408, Final Batch Loss: 1.262475961993914e-06\n",
      "Epoch 3270, Loss: 0.0004470694775591255, Final Batch Loss: 9.545512148179114e-05\n",
      "Epoch 3271, Loss: 0.00011693496935549774, Final Batch Loss: 6.902615132275969e-05\n",
      "Epoch 3272, Loss: 0.0016822579973450047, Final Batch Loss: 0.00012194859300507233\n",
      "Epoch 3273, Loss: 0.00013440263819575193, Final Batch Loss: 2.4300293262058403e-06\n",
      "Epoch 3274, Loss: 6.14951188708801e-05, Final Batch Loss: 1.6515874449396506e-05\n",
      "Epoch 3275, Loss: 0.00016786053106443433, Final Batch Loss: 2.8935498903592816e-06\n",
      "Epoch 3276, Loss: 0.0002372850221945555, Final Batch Loss: 6.977207704039756e-06\n",
      "Epoch 3277, Loss: 0.00015395081663882593, Final Batch Loss: 1.3924724953540135e-05\n",
      "Epoch 3278, Loss: 0.00014319510398763668, Final Batch Loss: 1.0587772294456954e-06\n",
      "Epoch 3279, Loss: 0.010227649130683858, Final Batch Loss: 0.010115042328834534\n",
      "Epoch 3280, Loss: 0.00038199909613467753, Final Batch Loss: 1.599320057721343e-05\n",
      "Epoch 3281, Loss: 8.151835277203645e-05, Final Batch Loss: 1.423440971848322e-05\n",
      "Epoch 3282, Loss: 0.00012332275582593866, Final Batch Loss: 3.0396628062590025e-05\n",
      "Epoch 3283, Loss: 0.0001249297229151125, Final Batch Loss: 5.446372597361915e-06\n",
      "Epoch 3284, Loss: 0.000962518070537044, Final Batch Loss: 6.455995844589779e-06\n",
      "Epoch 3285, Loss: 0.0005529544105229434, Final Batch Loss: 0.000367966276826337\n",
      "Epoch 3286, Loss: 0.0002494561747425905, Final Batch Loss: 3.54494909515779e-06\n",
      "Epoch 3287, Loss: 0.0001676991553267726, Final Batch Loss: 8.584647730458528e-06\n",
      "Epoch 3288, Loss: 0.00038116889027151046, Final Batch Loss: 6.048193426977377e-06\n",
      "Epoch 3289, Loss: 0.00021026346860253398, Final Batch Loss: 0.0001737642742227763\n",
      "Epoch 3290, Loss: 0.0007734346695542627, Final Batch Loss: 3.44548288921942e-06\n",
      "Epoch 3291, Loss: 7.26011840015417e-05, Final Batch Loss: 1.539658842375502e-05\n",
      "Epoch 3292, Loss: 1.7255954958272923e-05, Final Batch Loss: 1.7382814121447154e-06\n",
      "Epoch 3293, Loss: 0.00011715170046500134, Final Batch Loss: 1.863167085502937e-06\n",
      "Epoch 3294, Loss: 0.00015541250041906096, Final Batch Loss: 8.945219747147348e-07\n",
      "Epoch 3295, Loss: 0.00020857683489339252, Final Batch Loss: 2.6600014280120376e-06\n",
      "Epoch 3296, Loss: 0.00019580090793169802, Final Batch Loss: 3.27482121065259e-05\n",
      "Epoch 3297, Loss: 0.0004206276579452606, Final Batch Loss: 6.514190999951097e-07\n",
      "Epoch 3298, Loss: 0.0007613581400391922, Final Batch Loss: 7.317691142816329e-06\n",
      "Epoch 3299, Loss: 0.00043549864585656906, Final Batch Loss: 0.00039088205085135996\n",
      "Epoch 3300, Loss: 0.009219553121965873, Final Batch Loss: 1.574788439029362e-05\n",
      "Epoch 3301, Loss: 0.00517472852152423, Final Batch Loss: 1.2718874131678604e-05\n",
      "Epoch 3302, Loss: 0.0005840643843839644, Final Batch Loss: 3.05608227790799e-06\n",
      "Epoch 3303, Loss: 0.00038636907652289665, Final Batch Loss: 1.6876458630576963e-06\n",
      "Epoch 3304, Loss: 0.0010411731205977048, Final Batch Loss: 6.692522447337979e-07\n",
      "Epoch 3305, Loss: 0.019377394143702986, Final Batch Loss: 5.43439182365546e-06\n",
      "Epoch 3306, Loss: 0.00035414958620094694, Final Batch Loss: 5.091339335194789e-05\n",
      "Epoch 3307, Loss: 0.0010343734734306054, Final Batch Loss: 0.00047709327191114426\n",
      "Epoch 3308, Loss: 0.008602164036346949, Final Batch Loss: 0.006370631977915764\n",
      "Epoch 3309, Loss: 0.0010497228449821705, Final Batch Loss: 0.00012381419946905226\n",
      "Epoch 3310, Loss: 0.00014577225601897226, Final Batch Loss: 3.115656727459282e-05\n",
      "Epoch 3311, Loss: 0.0003013551213371102, Final Batch Loss: 5.890125976293348e-05\n",
      "Epoch 3312, Loss: 0.00011930188793485286, Final Batch Loss: 1.1045894098060671e-05\n",
      "Epoch 3313, Loss: 0.0008510375919286162, Final Batch Loss: 0.0004327072238083929\n",
      "Epoch 3314, Loss: 9.532672720524715e-05, Final Batch Loss: 4.192213964415714e-06\n",
      "Epoch 3315, Loss: 0.0008298231405206025, Final Batch Loss: 1.8497055862098932e-05\n",
      "Epoch 3316, Loss: 0.0007045163874863647, Final Batch Loss: 8.461549441562966e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3317, Loss: 0.007723025718178178, Final Batch Loss: 3.0870712635078235e-06\n",
      "Epoch 3318, Loss: 0.0038053948874221533, Final Batch Loss: 0.0037439418956637383\n",
      "Epoch 3319, Loss: 0.0025363808827023604, Final Batch Loss: 0.00016450323164463043\n",
      "Epoch 3320, Loss: 0.02480180149359512, Final Batch Loss: 2.060945007542614e-05\n",
      "Epoch 3321, Loss: 0.00014247435933611996, Final Batch Loss: 2.8786541861336445e-06\n",
      "Epoch 3322, Loss: 0.002718425777857192, Final Batch Loss: 6.180821219459176e-05\n",
      "Epoch 3323, Loss: 0.00017645507523411652, Final Batch Loss: 5.6541750382166356e-05\n",
      "Epoch 3324, Loss: 0.00011228723241174521, Final Batch Loss: 7.603018161717046e-07\n",
      "Epoch 3325, Loss: 5.141892847859708e-05, Final Batch Loss: 6.7603868956211954e-06\n",
      "Epoch 3326, Loss: 0.00018266787083121017, Final Batch Loss: 3.822878352366388e-05\n",
      "Epoch 3327, Loss: 0.0002313119675818598, Final Batch Loss: 1.5639352568541653e-05\n",
      "Epoch 3328, Loss: 0.0067755818517980515, Final Batch Loss: 9.076217793335672e-06\n",
      "Epoch 3329, Loss: 7.953252497827634e-05, Final Batch Loss: 1.5049112334963866e-05\n",
      "Epoch 3330, Loss: 0.0005433389014797285, Final Batch Loss: 5.69012263440527e-05\n",
      "Epoch 3331, Loss: 0.002928263111243723, Final Batch Loss: 0.00023583241272717714\n",
      "Epoch 3332, Loss: 0.000395924771510181, Final Batch Loss: 2.067061905108858e-05\n",
      "Epoch 3333, Loss: 0.0003683224476844771, Final Batch Loss: 0.00029610845376737416\n",
      "Epoch 3334, Loss: 0.000894094160230452, Final Batch Loss: 3.526189630065346e-06\n",
      "Epoch 3335, Loss: 0.0007735623266853509, Final Batch Loss: 1.0990487680828664e-05\n",
      "Epoch 3336, Loss: 0.0003845170813292498, Final Batch Loss: 3.9018930692691356e-05\n",
      "Epoch 3337, Loss: 0.00039441129183614976, Final Batch Loss: 5.998469077894697e-06\n",
      "Epoch 3338, Loss: 0.008045534446864622, Final Batch Loss: 4.4882854126626626e-06\n",
      "Epoch 3339, Loss: 0.0003321639323985437, Final Batch Loss: 3.604298399295658e-06\n",
      "Epoch 3340, Loss: 0.001824751449021278, Final Batch Loss: 2.1612970158457756e-05\n",
      "Epoch 3341, Loss: 0.0003440185846557142, Final Batch Loss: 6.985143045312725e-06\n",
      "Epoch 3342, Loss: 0.0013325775680641527, Final Batch Loss: 0.001139175845310092\n",
      "Epoch 3343, Loss: 0.0004551537222141633, Final Batch Loss: 1.0538597052800469e-05\n",
      "Epoch 3344, Loss: 0.0002477390080457553, Final Batch Loss: 3.286296487203799e-05\n",
      "Epoch 3345, Loss: 0.001148524821473984, Final Batch Loss: 5.3748328355140984e-05\n",
      "Epoch 3346, Loss: 0.0005794975731987506, Final Batch Loss: 0.00044430498383007944\n",
      "Epoch 3347, Loss: 5.9969131370962714e-05, Final Batch Loss: 1.3132400454196613e-05\n",
      "Epoch 3348, Loss: 0.00037812479968124535, Final Batch Loss: 0.0002212508552474901\n",
      "Epoch 3349, Loss: 0.00045040022314424277, Final Batch Loss: 5.922875516262138e-06\n",
      "Epoch 3350, Loss: 0.002391496064774401, Final Batch Loss: 3.716356150107458e-05\n",
      "Epoch 3351, Loss: 0.0004899121195194311, Final Batch Loss: 7.796348654665053e-05\n",
      "Epoch 3352, Loss: 0.00036933346791556687, Final Batch Loss: 5.604803391179303e-06\n",
      "Epoch 3353, Loss: 0.003220399987185374, Final Batch Loss: 3.672542152344249e-05\n",
      "Epoch 3354, Loss: 0.0002114536345061424, Final Batch Loss: 1.3422221627479303e-06\n",
      "Epoch 3355, Loss: 0.00015131270038182265, Final Batch Loss: 3.923525218851864e-05\n",
      "Epoch 3356, Loss: 4.84901615891431e-05, Final Batch Loss: 8.344890375155956e-06\n",
      "Epoch 3357, Loss: 0.0007562924552075856, Final Batch Loss: 4.052777967444854e-06\n",
      "Epoch 3358, Loss: 0.0017967017497539928, Final Batch Loss: 1.9992253328382503e-06\n",
      "Epoch 3359, Loss: 8.497048202116275e-05, Final Batch Loss: 3.639588612713851e-05\n",
      "Epoch 3360, Loss: 0.0005407180251495447, Final Batch Loss: 5.910481922910549e-05\n",
      "Epoch 3361, Loss: 0.00018371620171819814, Final Batch Loss: 5.232450348557904e-06\n",
      "Epoch 3362, Loss: 8.054680893110344e-05, Final Batch Loss: 3.0157934816088527e-05\n",
      "Epoch 3363, Loss: 0.0003714255417435197, Final Batch Loss: 1.5117233488126658e-05\n",
      "Epoch 3364, Loss: 0.00018733669094217476, Final Batch Loss: 2.5233437554561533e-05\n",
      "Epoch 3365, Loss: 0.00030645229458059475, Final Batch Loss: 1.1019596058758907e-05\n",
      "Epoch 3366, Loss: 0.006353644826958771, Final Batch Loss: 7.1431832111557014e-06\n",
      "Epoch 3367, Loss: 0.0006748828591298661, Final Batch Loss: 0.00015385611914098263\n",
      "Epoch 3368, Loss: 0.00013427251997200074, Final Batch Loss: 5.970646452624351e-05\n",
      "Epoch 3369, Loss: 0.023431601680840686, Final Batch Loss: 0.02295578457415104\n",
      "Epoch 3370, Loss: 0.0024685510634299135, Final Batch Loss: 0.002062044106423855\n",
      "Epoch 3371, Loss: 0.0004457528175407788, Final Batch Loss: 2.1246427422738634e-05\n",
      "Epoch 3372, Loss: 0.0004905946116195992, Final Batch Loss: 1.2213648005854338e-05\n",
      "Epoch 3373, Loss: 0.0013185112566134194, Final Batch Loss: 1.7505390133010224e-06\n",
      "Epoch 3374, Loss: 0.0011449219164205715, Final Batch Loss: 0.0008308598771691322\n",
      "Epoch 3375, Loss: 0.002133761950972257, Final Batch Loss: 3.140904300380498e-05\n",
      "Epoch 3376, Loss: 0.00507347709753958, Final Batch Loss: 1.6218427845160477e-05\n",
      "Epoch 3377, Loss: 0.00018063251263811253, Final Batch Loss: 2.631296229083091e-05\n",
      "Epoch 3378, Loss: 0.00014187550732458476, Final Batch Loss: 1.7503589333500713e-05\n",
      "Epoch 3379, Loss: 6.866104922664817e-05, Final Batch Loss: 2.6569825422484428e-05\n",
      "Epoch 3380, Loss: 0.00015650865316274576, Final Batch Loss: 2.9070200980640948e-05\n",
      "Epoch 3381, Loss: 0.00010320383444195613, Final Batch Loss: 3.12457159452606e-05\n",
      "Epoch 3382, Loss: 0.003600652500608703, Final Batch Loss: 4.7240315325325355e-05\n",
      "Epoch 3383, Loss: 0.00017240127090190072, Final Batch Loss: 0.00010829795792233199\n",
      "Epoch 3384, Loss: 0.00028355871290841606, Final Batch Loss: 0.00013319171557668597\n",
      "Epoch 3385, Loss: 0.0042328746585553745, Final Batch Loss: 6.0441747336881235e-05\n",
      "Epoch 3386, Loss: 0.0003282718407717766, Final Batch Loss: 0.00020674016559496522\n",
      "Epoch 3387, Loss: 0.00022878671370563097, Final Batch Loss: 2.2565325707546435e-05\n",
      "Epoch 3388, Loss: 0.0030649589189124526, Final Batch Loss: 0.002943386323750019\n",
      "Epoch 3389, Loss: 0.00037936076591904566, Final Batch Loss: 3.1375432172353612e-06\n",
      "Epoch 3390, Loss: 9.736929587234044e-05, Final Batch Loss: 1.1148791600135155e-05\n",
      "Epoch 3391, Loss: 0.00019776193948928267, Final Batch Loss: 1.730911390041001e-05\n",
      "Epoch 3392, Loss: 0.000993408813883434, Final Batch Loss: 0.00019591859017964453\n",
      "Epoch 3393, Loss: 0.0004610360483638942, Final Batch Loss: 6.795074295951054e-05\n",
      "Epoch 3394, Loss: 0.002527311785343045, Final Batch Loss: 1.087640703190118e-05\n",
      "Epoch 3395, Loss: 0.0005265993777356925, Final Batch Loss: 9.739336746861227e-06\n",
      "Epoch 3396, Loss: 0.0002335536910322844, Final Batch Loss: 3.079099769820459e-05\n",
      "Epoch 3397, Loss: 0.00023059701879901695, Final Batch Loss: 9.41450252867071e-07\n",
      "Epoch 3398, Loss: 0.00020874868641840294, Final Batch Loss: 1.7395817849319428e-05\n",
      "Epoch 3399, Loss: 0.0017365759231324773, Final Batch Loss: 1.3609427696792409e-05\n",
      "Epoch 3400, Loss: 0.00037033047556178644, Final Batch Loss: 3.0299190257210284e-05\n",
      "Epoch 3401, Loss: 0.0004963907904311782, Final Batch Loss: 5.666541255777702e-05\n",
      "Epoch 3402, Loss: 0.0003322966560972418, Final Batch Loss: 0.000169860984897241\n",
      "Epoch 3403, Loss: 0.0023037109203869477, Final Batch Loss: 2.30935329454951e-05\n",
      "Epoch 3404, Loss: 5.4006378832127666e-05, Final Batch Loss: 5.55928954781848e-06\n",
      "Epoch 3405, Loss: 0.0001919339829328237, Final Batch Loss: 1.566729770274833e-05\n",
      "Epoch 3406, Loss: 0.05190154453157447, Final Batch Loss: 9.61207042564638e-05\n",
      "Epoch 3407, Loss: 0.0012371439206617652, Final Batch Loss: 0.0007729986682534218\n",
      "Epoch 3408, Loss: 0.007957686024383293, Final Batch Loss: 2.7299038265482523e-05\n",
      "Epoch 3409, Loss: 0.0001618256073925295, Final Batch Loss: 1.0913968253589701e-05\n",
      "Epoch 3410, Loss: 0.0003090603513555834, Final Batch Loss: 4.904174056719057e-05\n",
      "Epoch 3411, Loss: 7.026598757420288e-05, Final Batch Loss: 1.6904726862776442e-06\n",
      "Epoch 3412, Loss: 0.003278436915934435, Final Batch Loss: 0.0030416990630328655\n",
      "Epoch 3413, Loss: 0.0029971986878081225, Final Batch Loss: 0.0012111697578802705\n",
      "Epoch 3414, Loss: 8.253418309323024e-05, Final Batch Loss: 1.367568074783776e-05\n",
      "Epoch 3415, Loss: 0.00018786423970595933, Final Batch Loss: 7.681954593863338e-05\n",
      "Epoch 3416, Loss: 0.00045109144684829516, Final Batch Loss: 0.00028041659970767796\n",
      "Epoch 3417, Loss: 0.001108352380128963, Final Batch Loss: 6.364003866110579e-07\n",
      "Epoch 3418, Loss: 8.639600150672777e-05, Final Batch Loss: 1.578044430061709e-05\n",
      "Epoch 3419, Loss: 0.00012985975854462595, Final Batch Loss: 1.476987381465733e-05\n",
      "Epoch 3420, Loss: 0.0010286905180691974, Final Batch Loss: 9.306244464823976e-06\n",
      "Epoch 3421, Loss: 8.38701018892607e-05, Final Batch Loss: 4.7929261199897155e-05\n",
      "Epoch 3422, Loss: 6.213314725300734e-05, Final Batch Loss: 1.757078166519932e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3423, Loss: 0.00010941957407339942, Final Batch Loss: 3.0725022952537984e-05\n",
      "Epoch 3424, Loss: 0.00013878735205707926, Final Batch Loss: 9.464810864301398e-05\n",
      "Epoch 3425, Loss: 0.0006243650368560338, Final Batch Loss: 1.8016560716205277e-05\n",
      "Epoch 3426, Loss: 0.0002619728290937928, Final Batch Loss: 0.00022809977235738188\n",
      "Epoch 3427, Loss: 0.00019821838424149973, Final Batch Loss: 6.649442366324365e-05\n",
      "Epoch 3428, Loss: 0.00029967668024255545, Final Batch Loss: 0.00013062242942396551\n",
      "Epoch 3429, Loss: 6.473895086855919e-05, Final Batch Loss: 2.129670428985264e-05\n",
      "Epoch 3430, Loss: 0.0007708526313763286, Final Batch Loss: 5.043786131864181e-06\n",
      "Epoch 3431, Loss: 0.0002074591398013581, Final Batch Loss: 1.1129292943223845e-05\n",
      "Epoch 3432, Loss: 0.0014107780671110959, Final Batch Loss: 7.723327144049108e-06\n",
      "Epoch 3433, Loss: 0.00020575344024109654, Final Batch Loss: 2.6798448743647896e-05\n",
      "Epoch 3434, Loss: 0.0003154227595132397, Final Batch Loss: 0.00021191475389059633\n",
      "Epoch 3435, Loss: 5.540684537663765e-05, Final Batch Loss: 1.3644225873576943e-05\n",
      "Epoch 3436, Loss: 0.0012504287960837246, Final Batch Loss: 0.001124962349422276\n",
      "Epoch 3437, Loss: 0.01619085965199929, Final Batch Loss: 2.645834456416196e-06\n",
      "Epoch 3438, Loss: 0.0016314533968397882, Final Batch Loss: 8.477208757540211e-05\n",
      "Epoch 3439, Loss: 0.0005657265551235469, Final Batch Loss: 5.2712082833750173e-05\n",
      "Epoch 3440, Loss: 0.00018981475477630738, Final Batch Loss: 6.249741272768006e-05\n",
      "Epoch 3441, Loss: 0.0009633768318053626, Final Batch Loss: 2.727743412833661e-05\n",
      "Epoch 3442, Loss: 0.00015581047773594037, Final Batch Loss: 5.49174401385244e-05\n",
      "Epoch 3443, Loss: 0.033221137717191596, Final Batch Loss: 3.1914016290102154e-05\n",
      "Epoch 3444, Loss: 0.00040371534646510554, Final Batch Loss: 1.9719825559150195e-06\n",
      "Epoch 3445, Loss: 0.002068281298306829, Final Batch Loss: 1.981899913516827e-05\n",
      "Epoch 3446, Loss: 0.0009614152331778314, Final Batch Loss: 1.6147725546034053e-05\n",
      "Epoch 3447, Loss: 0.00018549459036876215, Final Batch Loss: 0.00010537999332882464\n",
      "Epoch 3448, Loss: 0.008783603771917114, Final Batch Loss: 9.132143532042392e-06\n",
      "Epoch 3449, Loss: 0.04435455839484348, Final Batch Loss: 1.4867622667225078e-05\n",
      "Epoch 3450, Loss: 0.012914097213979403, Final Batch Loss: 5.473976671055425e-06\n",
      "Epoch 3451, Loss: 0.0038992787895040237, Final Batch Loss: 4.002161404059734e-06\n",
      "Epoch 3452, Loss: 0.0001449184810553561, Final Batch Loss: 1.4154620657791384e-06\n",
      "Epoch 3453, Loss: 0.008917113475035876, Final Batch Loss: 0.0003614508605096489\n",
      "Epoch 3454, Loss: 0.00037065970627736533, Final Batch Loss: 1.1739201909222174e-05\n",
      "Epoch 3455, Loss: 0.00010242824237138848, Final Batch Loss: 5.330622570909327e-06\n",
      "Epoch 3456, Loss: 0.015080830957231228, Final Batch Loss: 2.4534178010071628e-05\n",
      "Epoch 3457, Loss: 0.0024245470642654254, Final Batch Loss: 2.182304569942062e-06\n",
      "Epoch 3458, Loss: 0.011653893718175823, Final Batch Loss: 1.7035152268363163e-05\n",
      "Epoch 3459, Loss: 0.006744600344973151, Final Batch Loss: 5.476515070768073e-05\n",
      "Epoch 3460, Loss: 0.005503061343688387, Final Batch Loss: 2.7792555101768812e-06\n",
      "Epoch 3461, Loss: 0.0007670679806324188, Final Batch Loss: 1.4517709132633172e-05\n",
      "Epoch 3462, Loss: 0.0015205304584924306, Final Batch Loss: 5.237747973296791e-05\n",
      "Epoch 3463, Loss: 0.011643330451988732, Final Batch Loss: 0.0031337037216871977\n",
      "Epoch 3464, Loss: 0.0002433399558867677, Final Batch Loss: 8.315601917274762e-06\n",
      "Epoch 3465, Loss: 0.00027314849262438656, Final Batch Loss: 2.2883175461174687e-06\n",
      "Epoch 3466, Loss: 0.0005840924495714717, Final Batch Loss: 0.00011654462286969647\n",
      "Epoch 3467, Loss: 0.002436269891404663, Final Batch Loss: 6.9126341259107e-05\n",
      "Epoch 3468, Loss: 0.0008108669680950698, Final Batch Loss: 8.870491728885099e-05\n",
      "Epoch 3469, Loss: 0.00033591910869290587, Final Batch Loss: 8.827263081911951e-05\n",
      "Epoch 3470, Loss: 0.0009755103128554765, Final Batch Loss: 0.0002909761678893119\n",
      "Epoch 3471, Loss: 0.00020981159900657076, Final Batch Loss: 5.3574876801576465e-05\n",
      "Epoch 3472, Loss: 0.00025780168380151736, Final Batch Loss: 5.93971271882765e-05\n",
      "Epoch 3473, Loss: 0.000446207351387784, Final Batch Loss: 3.2585987810307415e-06\n",
      "Epoch 3474, Loss: 0.0006130042092991062, Final Batch Loss: 0.0001437430182704702\n",
      "Epoch 3475, Loss: 0.0006498333074773655, Final Batch Loss: 5.012386168345984e-07\n",
      "Epoch 3476, Loss: 0.0188066680780139, Final Batch Loss: 2.6805605557456147e-06\n",
      "Epoch 3477, Loss: 0.0013290620263433084, Final Batch Loss: 0.0003793516953010112\n",
      "Epoch 3478, Loss: 0.029751122940979258, Final Batch Loss: 0.0005582990706898272\n",
      "Epoch 3479, Loss: 0.00017327727618976496, Final Batch Loss: 5.891923501621932e-05\n",
      "Epoch 3480, Loss: 0.0010417290620807762, Final Batch Loss: 3.0427479487116216e-06\n",
      "Epoch 3481, Loss: 0.0002698930215956352, Final Batch Loss: 3.6311557778390124e-05\n",
      "Epoch 3482, Loss: 0.000415017851992161, Final Batch Loss: 1.7110707631218247e-05\n",
      "Epoch 3483, Loss: 0.0015271579650288913, Final Batch Loss: 3.645367905846797e-05\n",
      "Epoch 3484, Loss: 0.002123001584550366, Final Batch Loss: 0.000586149690207094\n",
      "Epoch 3485, Loss: 0.0004220176560920663, Final Batch Loss: 3.4186025004601106e-05\n",
      "Epoch 3486, Loss: 0.011480168536763813, Final Batch Loss: 0.0006508235819637775\n",
      "Epoch 3487, Loss: 0.00010391583236923907, Final Batch Loss: 3.420924622332677e-05\n",
      "Epoch 3488, Loss: 0.0019426855269557564, Final Batch Loss: 0.0012131612747907639\n",
      "Epoch 3489, Loss: 0.01134196295242873, Final Batch Loss: 0.0011665154015645385\n",
      "Epoch 3490, Loss: 0.0018368337841820903, Final Batch Loss: 8.087377864285372e-06\n",
      "Epoch 3491, Loss: 0.020842768415377577, Final Batch Loss: 3.191220230291947e-06\n",
      "Epoch 3492, Loss: 0.0003364906879141927, Final Batch Loss: 8.015579805942252e-05\n",
      "Epoch 3493, Loss: 0.0006772605192963965, Final Batch Loss: 0.00019076940952800214\n",
      "Epoch 3494, Loss: 0.007879413926275447, Final Batch Loss: 3.627335172495805e-05\n",
      "Epoch 3495, Loss: 0.002287009574502008, Final Batch Loss: 4.6070046664681286e-05\n",
      "Epoch 3496, Loss: 0.0003306504122519982, Final Batch Loss: 8.156314834195655e-06\n",
      "Epoch 3497, Loss: 0.0020680037268903106, Final Batch Loss: 0.0002532151702325791\n",
      "Epoch 3498, Loss: 0.003227868925932853, Final Batch Loss: 8.083805369096808e-06\n",
      "Epoch 3499, Loss: 0.000669448319968069, Final Batch Loss: 1.736558260745369e-05\n",
      "Epoch 3500, Loss: 0.0002695022894840804, Final Batch Loss: 2.4062976081040688e-05\n",
      "Epoch 3501, Loss: 0.0009290545040130382, Final Batch Loss: 2.712297828111332e-05\n",
      "Epoch 3502, Loss: 0.00046238313848334656, Final Batch Loss: 1.9251358480687486e-06\n",
      "Epoch 3503, Loss: 0.0014613357520829595, Final Batch Loss: 2.134381702489918e-06\n",
      "Epoch 3504, Loss: 0.0003894205245842386, Final Batch Loss: 1.4858404711048934e-06\n",
      "Epoch 3505, Loss: 0.0008991950080599054, Final Batch Loss: 0.00035668580676428974\n",
      "Epoch 3506, Loss: 0.002779179367735196, Final Batch Loss: 2.5252249542973004e-05\n",
      "Epoch 3507, Loss: 0.0004943679996358696, Final Batch Loss: 1.7096994270104915e-05\n",
      "Epoch 3508, Loss: 0.0004858201209572144, Final Batch Loss: 0.0003899075381923467\n",
      "Epoch 3509, Loss: 0.0006215825196704827, Final Batch Loss: 1.9948120097978972e-05\n",
      "Epoch 3510, Loss: 0.00018152132906834595, Final Batch Loss: 4.808250378118828e-05\n",
      "Epoch 3511, Loss: 0.00019801245616690721, Final Batch Loss: 2.0670877347583883e-05\n",
      "Epoch 3512, Loss: 0.00015518319742113817, Final Batch Loss: 2.3968588720890693e-05\n",
      "Epoch 3513, Loss: 0.0022663718918920495, Final Batch Loss: 0.0009048175415955484\n",
      "Epoch 3514, Loss: 0.003827595071925316, Final Batch Loss: 0.00019080081256106496\n",
      "Epoch 3515, Loss: 0.004023368179332465, Final Batch Loss: 6.0788415794377215e-06\n",
      "Epoch 3516, Loss: 0.0005266885569881197, Final Batch Loss: 4.374093123260536e-07\n",
      "Epoch 3517, Loss: 0.0003189878470948315, Final Batch Loss: 0.0001612001797184348\n",
      "Epoch 3518, Loss: 0.03379669736750657, Final Batch Loss: 5.4996249673422426e-05\n",
      "Epoch 3519, Loss: 0.00011841379728139145, Final Batch Loss: 7.400365575449541e-06\n",
      "Epoch 3520, Loss: 0.0011265072698734002, Final Batch Loss: 2.0052068066434003e-05\n",
      "Epoch 3521, Loss: 0.00018833682952390518, Final Batch Loss: 9.093609696719795e-05\n",
      "Epoch 3522, Loss: 0.0006610572181671159, Final Batch Loss: 0.00045648569357581437\n",
      "Epoch 3523, Loss: 0.00019046471334149828, Final Batch Loss: 7.887842912168708e-06\n",
      "Epoch 3524, Loss: 0.0002626419609441655, Final Batch Loss: 9.015002433443442e-05\n",
      "Epoch 3525, Loss: 0.0010431326136313146, Final Batch Loss: 1.617096677364316e-05\n",
      "Epoch 3526, Loss: 0.0002792020241031423, Final Batch Loss: 7.625900616403669e-05\n",
      "Epoch 3527, Loss: 0.00017227817443199456, Final Batch Loss: 0.00011133335647173226\n",
      "Epoch 3528, Loss: 0.00018049645632345346, Final Batch Loss: 7.157074833230581e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3529, Loss: 0.00027971606141363736, Final Batch Loss: 2.093870352837257e-05\n",
      "Epoch 3530, Loss: 0.0007005658699199557, Final Batch Loss: 0.00041684872121550143\n",
      "Epoch 3531, Loss: 0.03312592141128334, Final Batch Loss: 0.03286490961909294\n",
      "Epoch 3532, Loss: 0.0011504876038088696, Final Batch Loss: 0.0007184383575804532\n",
      "Epoch 3533, Loss: 0.0025447073380746588, Final Batch Loss: 5.977212822472211e-06\n",
      "Epoch 3534, Loss: 0.00031596686403645435, Final Batch Loss: 0.00014600019494537264\n",
      "Epoch 3535, Loss: 8.920683467295021e-05, Final Batch Loss: 3.1903546187095344e-06\n",
      "Epoch 3536, Loss: 0.0002080406329696416, Final Batch Loss: 1.2383096873236354e-05\n",
      "Epoch 3537, Loss: 0.0006978709316172171, Final Batch Loss: 1.5738882211735472e-05\n",
      "Epoch 3538, Loss: 0.0026549358417469193, Final Batch Loss: 3.937006476917304e-05\n",
      "Epoch 3539, Loss: 0.0004190598360764852, Final Batch Loss: 7.587388154206565e-06\n",
      "Epoch 3540, Loss: 0.00012519594793047872, Final Batch Loss: 2.7950105504714884e-05\n",
      "Epoch 3541, Loss: 0.002138611973350635, Final Batch Loss: 2.1453033696161583e-05\n",
      "Epoch 3542, Loss: 0.00022981302299740491, Final Batch Loss: 9.205963579006493e-05\n",
      "Epoch 3543, Loss: 0.04540848548322174, Final Batch Loss: 0.04531453549861908\n",
      "Epoch 3544, Loss: 0.0017308765272900928, Final Batch Loss: 0.0002588771458249539\n",
      "Epoch 3545, Loss: 0.018090302130076452, Final Batch Loss: 3.733203993760981e-05\n",
      "Epoch 3546, Loss: 0.0004924302620565868, Final Batch Loss: 0.00011947569146286696\n",
      "Epoch 3547, Loss: 0.0002741275156949996, Final Batch Loss: 0.00010698202095227316\n",
      "Epoch 3548, Loss: 0.0006348056358547183, Final Batch Loss: 3.7124729715287685e-05\n",
      "Epoch 3549, Loss: 0.001479496471802122, Final Batch Loss: 2.973418122564908e-05\n",
      "Epoch 3550, Loss: 0.0030208909993234556, Final Batch Loss: 2.7885798772331327e-06\n",
      "Epoch 3551, Loss: 0.04542642625165172, Final Batch Loss: 0.04270245134830475\n",
      "Epoch 3552, Loss: 9.95318860077532e-05, Final Batch Loss: 1.809095192584209e-05\n",
      "Epoch 3553, Loss: 0.0009161432026303373, Final Batch Loss: 0.00048165256157517433\n",
      "Epoch 3554, Loss: 0.036031631632795325, Final Batch Loss: 4.1050658182939515e-05\n",
      "Epoch 3555, Loss: 0.024035151713178493, Final Batch Loss: 2.688785025384277e-05\n",
      "Epoch 3556, Loss: 0.001756042598572094, Final Batch Loss: 6.94101327098906e-05\n",
      "Epoch 3557, Loss: 0.0010635712133080233, Final Batch Loss: 3.2470903533976525e-05\n",
      "Epoch 3558, Loss: 0.0005889387739443919, Final Batch Loss: 1.5504369002883323e-05\n",
      "Epoch 3559, Loss: 0.000987891515251249, Final Batch Loss: 0.00032022278173826635\n",
      "Epoch 3560, Loss: 0.0011568935610739572, Final Batch Loss: 4.432064542925218e-06\n",
      "Epoch 3561, Loss: 0.0003330580693727825, Final Batch Loss: 5.6244898587465286e-05\n",
      "Epoch 3562, Loss: 0.00016590919040027075, Final Batch Loss: 9.508044968242757e-06\n",
      "Epoch 3563, Loss: 0.0004932106403430225, Final Batch Loss: 1.0438978279125877e-05\n",
      "Epoch 3564, Loss: 0.0035531676203390816, Final Batch Loss: 3.0508117561112158e-05\n",
      "Epoch 3565, Loss: 0.0005870436325494666, Final Batch Loss: 0.00010413728887215257\n",
      "Epoch 3566, Loss: 0.0008299298860947601, Final Batch Loss: 1.5704250472481363e-05\n",
      "Epoch 3567, Loss: 0.0034704047574223296, Final Batch Loss: 1.0559696193013224e-06\n",
      "Epoch 3568, Loss: 0.0009880522461571672, Final Batch Loss: 7.3458318183838855e-06\n",
      "Epoch 3569, Loss: 0.0031153479794738814, Final Batch Loss: 1.6950663848547265e-05\n",
      "Epoch 3570, Loss: 0.0003966943577324855, Final Batch Loss: 0.00022559335047844797\n",
      "Epoch 3571, Loss: 0.002209823103839881, Final Batch Loss: 0.001869615982286632\n",
      "Epoch 3572, Loss: 0.0003414439879634301, Final Batch Loss: 0.00014120506239123642\n",
      "Epoch 3573, Loss: 0.0002807433884299826, Final Batch Loss: 8.088384493021294e-05\n",
      "Epoch 3574, Loss: 0.0008790560823399574, Final Batch Loss: 0.00014912591723259538\n",
      "Epoch 3575, Loss: 0.001159502633527154, Final Batch Loss: 1.7780086636776105e-05\n",
      "Epoch 3576, Loss: 0.0386362604704118, Final Batch Loss: 0.03848668932914734\n",
      "Epoch 3577, Loss: 0.00023721044635749422, Final Batch Loss: 3.833387017948553e-05\n",
      "Epoch 3578, Loss: 0.006255620102820103, Final Batch Loss: 1.088213139155414e-05\n",
      "Epoch 3579, Loss: 0.0004033541786157002, Final Batch Loss: 1.7828380805440247e-05\n",
      "Epoch 3580, Loss: 0.00027782002644016757, Final Batch Loss: 5.2212467380741145e-06\n",
      "Epoch 3581, Loss: 0.0014782506841584109, Final Batch Loss: 7.932410517241806e-05\n",
      "Epoch 3582, Loss: 0.005557622365813586, Final Batch Loss: 2.087914435833227e-05\n",
      "Epoch 3583, Loss: 0.00016261188420685357, Final Batch Loss: 1.6483350918861106e-05\n",
      "Epoch 3584, Loss: 0.0007678061065234942, Final Batch Loss: 4.672428985941224e-06\n",
      "Epoch 3585, Loss: 0.0012964335219294298, Final Batch Loss: 8.493861059832852e-06\n",
      "Epoch 3586, Loss: 0.003920881412341259, Final Batch Loss: 0.0016176484059542418\n",
      "Epoch 3587, Loss: 0.0012777586689480813, Final Batch Loss: 0.00010753688547993079\n",
      "Epoch 3588, Loss: 0.00011450262735479555, Final Batch Loss: 7.09616585936601e-07\n",
      "Epoch 3589, Loss: 0.0004635489622160094, Final Batch Loss: 2.5922572604031302e-05\n",
      "Epoch 3590, Loss: 0.00041715242718964873, Final Batch Loss: 1.810614094210905e-06\n",
      "Epoch 3591, Loss: 8.849359164742054e-05, Final Batch Loss: 9.888298336591106e-06\n",
      "Epoch 3592, Loss: 0.00037711687764385715, Final Batch Loss: 2.59386797551997e-05\n",
      "Epoch 3593, Loss: 0.0016495127929374576, Final Batch Loss: 0.000221818161662668\n",
      "Epoch 3594, Loss: 0.00022301392345980275, Final Batch Loss: 1.3489292541635223e-05\n",
      "Epoch 3595, Loss: 0.0015366717989309109, Final Batch Loss: 0.001035426277667284\n",
      "Epoch 3596, Loss: 0.0005190719457459636, Final Batch Loss: 9.721770766191185e-05\n",
      "Epoch 3597, Loss: 0.004848858121476951, Final Batch Loss: 2.710619810386561e-06\n",
      "Epoch 3598, Loss: 0.0011961192794842646, Final Batch Loss: 0.0004658593097701669\n",
      "Epoch 3599, Loss: 0.06342931783001404, Final Batch Loss: 0.0003089184465352446\n",
      "Epoch 3600, Loss: 0.0009727594683681673, Final Batch Loss: 0.0007030304986983538\n",
      "Epoch 3601, Loss: 0.01572187456622487, Final Batch Loss: 0.00037607771810144186\n",
      "Epoch 3602, Loss: 0.0010657002349034883, Final Batch Loss: 8.658974547870457e-05\n",
      "Epoch 3603, Loss: 0.0014439667647820897, Final Batch Loss: 0.0004367840301711112\n",
      "Epoch 3604, Loss: 0.0037831286417713272, Final Batch Loss: 9.606624189473223e-06\n",
      "Epoch 3605, Loss: 0.0006636532671109308, Final Batch Loss: 2.2298416297417134e-05\n",
      "Epoch 3606, Loss: 0.00313129096684861, Final Batch Loss: 3.724417547346093e-05\n",
      "Epoch 3607, Loss: 0.0007490779498766642, Final Batch Loss: 1.0241474228678271e-05\n",
      "Epoch 3608, Loss: 0.0005857088763150387, Final Batch Loss: 0.00029984425054863095\n",
      "Epoch 3609, Loss: 0.002517746461307979, Final Batch Loss: 7.825690772733651e-06\n",
      "Epoch 3610, Loss: 0.000837181985616553, Final Batch Loss: 3.534783672876074e-06\n",
      "Epoch 3611, Loss: 0.0030372215505849454, Final Batch Loss: 1.2564642929646652e-05\n",
      "Epoch 3612, Loss: 0.0004893713885394391, Final Batch Loss: 5.5687622079858556e-05\n",
      "Epoch 3613, Loss: 0.0002844068058038829, Final Batch Loss: 0.0001648611796554178\n",
      "Epoch 3614, Loss: 0.0009100213337660534, Final Batch Loss: 6.306607247097418e-05\n",
      "Epoch 3615, Loss: 0.0033680342548905173, Final Batch Loss: 2.7947819035034627e-05\n",
      "Epoch 3616, Loss: 0.014091947705310304, Final Batch Loss: 0.001190235954709351\n",
      "Epoch 3617, Loss: 0.0011058568256885337, Final Batch Loss: 2.7328731448506005e-05\n",
      "Epoch 3618, Loss: 0.000336177391432102, Final Batch Loss: 1.1761047744585085e-06\n",
      "Epoch 3619, Loss: 0.0012762428004862159, Final Batch Loss: 9.770209544512909e-06\n",
      "Epoch 3620, Loss: 0.00016077482905529905, Final Batch Loss: 1.1650125998130534e-05\n",
      "Epoch 3621, Loss: 0.00015906189400993753, Final Batch Loss: 4.821339825866744e-05\n",
      "Epoch 3622, Loss: 0.00017415770525985863, Final Batch Loss: 3.831615322269499e-05\n",
      "Epoch 3623, Loss: 7.136333192647726e-05, Final Batch Loss: 2.8372949145705206e-06\n",
      "Epoch 3624, Loss: 0.0015827767106202373, Final Batch Loss: 3.884418674715562e-06\n",
      "Epoch 3625, Loss: 9.448824948776746e-05, Final Batch Loss: 1.0699433914851397e-05\n",
      "Epoch 3626, Loss: 0.0005280271761876065, Final Batch Loss: 0.00019506442185956985\n",
      "Epoch 3627, Loss: 0.0007052789624140132, Final Batch Loss: 9.17049401323311e-05\n",
      "Epoch 3628, Loss: 0.00024154227344297396, Final Batch Loss: 2.178407385144965e-06\n",
      "Epoch 3629, Loss: 0.00022635677896687412, Final Batch Loss: 3.145127720927121e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3630, Loss: 0.00011528416280270903, Final Batch Loss: 3.744002970051952e-05\n",
      "Epoch 3631, Loss: 0.000320586773341347, Final Batch Loss: 2.2940617782296613e-05\n",
      "Epoch 3632, Loss: 0.0002887589430429216, Final Batch Loss: 1.4954019206925295e-05\n",
      "Epoch 3633, Loss: 4.822297455575608e-05, Final Batch Loss: 1.901271753013134e-05\n",
      "Epoch 3634, Loss: 0.002159027251536827, Final Batch Loss: 0.0002073975483654067\n",
      "Epoch 3635, Loss: 0.0005324886278685881, Final Batch Loss: 1.467087167839054e-05\n",
      "Epoch 3636, Loss: 0.00020469734590733424, Final Batch Loss: 2.9011051083216444e-05\n",
      "Epoch 3637, Loss: 0.00047163152521534357, Final Batch Loss: 0.0003599455230869353\n",
      "Epoch 3638, Loss: 0.0002863065033125167, Final Batch Loss: 0.00020596198737621307\n",
      "Epoch 3639, Loss: 0.000290414137452899, Final Batch Loss: 0.00014627104974351823\n",
      "Epoch 3640, Loss: 0.0001838168354879599, Final Batch Loss: 4.4095173507230356e-05\n",
      "Epoch 3641, Loss: 0.026786952531892894, Final Batch Loss: 6.219362603587797e-06\n",
      "Epoch 3642, Loss: 0.0001235689910572546, Final Batch Loss: 3.823530278168619e-05\n",
      "Epoch 3643, Loss: 0.0002692245598154841, Final Batch Loss: 1.8686116163735278e-05\n",
      "Epoch 3644, Loss: 0.007500570926822547, Final Batch Loss: 6.60623072690214e-06\n",
      "Epoch 3645, Loss: 9.508163429927663e-05, Final Batch Loss: 6.94339314577519e-06\n",
      "Epoch 3646, Loss: 8.167801934177987e-05, Final Batch Loss: 3.7094647268531844e-05\n",
      "Epoch 3647, Loss: 7.869953878980596e-05, Final Batch Loss: 1.52818229253171e-05\n",
      "Epoch 3648, Loss: 0.20427394288344658, Final Batch Loss: 0.010654624551534653\n",
      "Epoch 3649, Loss: 0.006550709120347165, Final Batch Loss: 0.006366959307342768\n",
      "Epoch 3650, Loss: 0.0017123781981354114, Final Batch Loss: 1.1610864021349698e-06\n",
      "Epoch 3651, Loss: 0.00027359674550098134, Final Batch Loss: 0.0002208786318078637\n",
      "Epoch 3652, Loss: 0.00037892711407039315, Final Batch Loss: 0.00015866124886088073\n",
      "Epoch 3653, Loss: 0.0002652924458743655, Final Batch Loss: 1.124508253269596e-05\n",
      "Epoch 3654, Loss: 0.003070916199931162, Final Batch Loss: 2.3587006126035703e-06\n",
      "Epoch 3655, Loss: 0.0008875508974597324, Final Batch Loss: 3.112025297014043e-05\n",
      "Epoch 3656, Loss: 0.000322468686135835, Final Batch Loss: 1.5951891327858903e-05\n",
      "Epoch 3657, Loss: 0.034379223459836794, Final Batch Loss: 0.03316029533743858\n",
      "Epoch 3658, Loss: 0.009457571223265404, Final Batch Loss: 6.508972091978649e-06\n",
      "Epoch 3659, Loss: 0.007983757564943517, Final Batch Loss: 0.00010530611325521022\n",
      "Epoch 3660, Loss: 0.0003289650098849961, Final Batch Loss: 1.5948189684422687e-05\n",
      "Epoch 3661, Loss: 0.0004439678268681746, Final Batch Loss: 2.1283660316839814e-05\n",
      "Epoch 3662, Loss: 0.005261741687718313, Final Batch Loss: 0.004294097423553467\n",
      "Epoch 3663, Loss: 0.08668117006891407, Final Batch Loss: 0.00036255287704989314\n",
      "Epoch 3664, Loss: 0.0002407807387498906, Final Batch Loss: 2.457071423123125e-05\n",
      "Epoch 3665, Loss: 0.0030441053113463568, Final Batch Loss: 0.00011553021613508463\n",
      "Epoch 3666, Loss: 0.00781702043605037, Final Batch Loss: 0.0003705549461301416\n",
      "Epoch 3667, Loss: 0.00022690496120958414, Final Batch Loss: 4.85261480207555e-05\n",
      "Epoch 3668, Loss: 0.0001800013651518384, Final Batch Loss: 1.642367169552017e-05\n",
      "Epoch 3669, Loss: 0.007940901958136237, Final Batch Loss: 2.209513695561327e-06\n",
      "Epoch 3670, Loss: 0.0001794751137822459, Final Batch Loss: 4.893492587143555e-05\n",
      "Epoch 3671, Loss: 0.0028447460081224563, Final Batch Loss: 3.195130921085365e-05\n",
      "Epoch 3672, Loss: 0.001603387084287533, Final Batch Loss: 9.019492608786095e-06\n",
      "Epoch 3673, Loss: 0.016556601483898703, Final Batch Loss: 0.013809564523398876\n",
      "Epoch 3674, Loss: 0.0008309887853101827, Final Batch Loss: 3.888093488058075e-05\n",
      "Epoch 3675, Loss: 0.00032262850800179876, Final Batch Loss: 5.778037302661687e-05\n",
      "Epoch 3676, Loss: 0.003639636679963587, Final Batch Loss: 6.533208306791494e-06\n",
      "Epoch 3677, Loss: 0.004111002886929782, Final Batch Loss: 3.3996788260992616e-05\n",
      "Epoch 3678, Loss: 0.0007223889169836184, Final Batch Loss: 0.0001091681988327764\n",
      "Epoch 3679, Loss: 0.0002262832313135732, Final Batch Loss: 8.828048157738522e-05\n",
      "Epoch 3680, Loss: 0.0044455790375650395, Final Batch Loss: 3.154916703351773e-05\n",
      "Epoch 3681, Loss: 0.0001629433645575773, Final Batch Loss: 8.268034434877336e-06\n",
      "Epoch 3682, Loss: 0.0005714085236832034, Final Batch Loss: 7.27961742086336e-05\n",
      "Epoch 3683, Loss: 0.000571865701203933, Final Batch Loss: 6.903225585119799e-05\n",
      "Epoch 3684, Loss: 0.008716325650311774, Final Batch Loss: 1.3312335795490071e-05\n",
      "Epoch 3685, Loss: 0.002993958381921402, Final Batch Loss: 2.842222420440521e-05\n",
      "Epoch 3686, Loss: 0.002064266365778167, Final Batch Loss: 8.130270725814626e-05\n",
      "Epoch 3687, Loss: 0.0004512305258685956, Final Batch Loss: 4.7781704779481515e-06\n",
      "Epoch 3688, Loss: 0.008346223340595316, Final Batch Loss: 0.00019664443971123546\n",
      "Epoch 3689, Loss: 0.003443848076130962, Final Batch Loss: 3.5078930523013696e-05\n",
      "Epoch 3690, Loss: 0.0004720756203369092, Final Batch Loss: 1.0249766546621686e-06\n",
      "Epoch 3691, Loss: 0.00012306214421187178, Final Batch Loss: 6.712442427669885e-06\n",
      "Epoch 3692, Loss: 0.00016255578520940617, Final Batch Loss: 7.496659236494452e-05\n",
      "Epoch 3693, Loss: 0.0005412352511484642, Final Batch Loss: 0.00018749346781987697\n",
      "Epoch 3694, Loss: 0.0006495721318060532, Final Batch Loss: 5.692171544069424e-05\n",
      "Epoch 3695, Loss: 0.0016139531135195284, Final Batch Loss: 9.292608410760295e-06\n",
      "Epoch 3696, Loss: 0.00043619324060273357, Final Batch Loss: 0.00020536997180897743\n",
      "Epoch 3697, Loss: 0.001884953489820873, Final Batch Loss: 3.4464906093489844e-06\n",
      "Epoch 3698, Loss: 0.0005431323279481148, Final Batch Loss: 1.2965612768311985e-05\n",
      "Epoch 3699, Loss: 0.000255579319627941, Final Batch Loss: 2.9275195174705004e-06\n",
      "Epoch 3700, Loss: 0.00015503643408010248, Final Batch Loss: 9.848423360381275e-05\n",
      "Epoch 3701, Loss: 0.00010195659137934854, Final Batch Loss: 1.9748310933209723e-06\n",
      "Epoch 3702, Loss: 0.0028023880527143774, Final Batch Loss: 3.6847900446446147e-06\n",
      "Epoch 3703, Loss: 0.049986281544533995, Final Batch Loss: 1.6964806491159834e-05\n",
      "Epoch 3704, Loss: 0.00022412391808757093, Final Batch Loss: 4.600730335369008e-06\n",
      "Epoch 3705, Loss: 0.0058065619496119325, Final Batch Loss: 0.005532803479582071\n",
      "Epoch 3706, Loss: 0.0008532578697213467, Final Batch Loss: 2.8438491881388472e-06\n",
      "Epoch 3707, Loss: 0.00047622591046092566, Final Batch Loss: 9.454794781049713e-05\n",
      "Epoch 3708, Loss: 0.006860623718239367, Final Batch Loss: 3.065545024583116e-05\n",
      "Epoch 3709, Loss: 0.00023397602217301028, Final Batch Loss: 5.046628211857751e-05\n",
      "Epoch 3710, Loss: 0.00023137475000112318, Final Batch Loss: 5.781449726782739e-05\n",
      "Epoch 3711, Loss: 0.0003030010484508239, Final Batch Loss: 0.00013374231639318168\n",
      "Epoch 3712, Loss: 0.0001462225259274419, Final Batch Loss: 4.298458861740073e-06\n",
      "Epoch 3713, Loss: 0.00047900102345010964, Final Batch Loss: 4.619755600288045e-06\n",
      "Epoch 3714, Loss: 0.00017593356960787787, Final Batch Loss: 4.291739242034964e-05\n",
      "Epoch 3715, Loss: 0.00010003016268456122, Final Batch Loss: 7.267467299243435e-05\n",
      "Epoch 3716, Loss: 0.00035937547909270506, Final Batch Loss: 5.767406037193723e-06\n",
      "Epoch 3717, Loss: 0.0002980528468015109, Final Batch Loss: 1.4755357824469684e-06\n",
      "Epoch 3718, Loss: 0.0003118091062788153, Final Batch Loss: 4.9238278734264895e-06\n",
      "Epoch 3719, Loss: 0.00011423800606280565, Final Batch Loss: 8.315384548041038e-06\n",
      "Epoch 3720, Loss: 6.76902902796428e-05, Final Batch Loss: 3.6143585475656437e-06\n",
      "Epoch 3721, Loss: 0.0003252903297834564, Final Batch Loss: 8.229722880059853e-06\n",
      "Epoch 3722, Loss: 8.671836849316605e-05, Final Batch Loss: 3.318372546345927e-05\n",
      "Epoch 3723, Loss: 0.00023362363208434545, Final Batch Loss: 1.5069939763634466e-05\n",
      "Epoch 3724, Loss: 0.0002076360387945897, Final Batch Loss: 1.423780031473143e-05\n",
      "Epoch 3725, Loss: 9.815902600962545e-05, Final Batch Loss: 3.763989013805258e-07\n",
      "Epoch 3726, Loss: 0.0001293912072242165, Final Batch Loss: 1.7646046899244539e-06\n",
      "Epoch 3727, Loss: 0.0008454896342300344, Final Batch Loss: 0.0005617529968731105\n",
      "Epoch 3728, Loss: 0.00011109601155112614, Final Batch Loss: 5.597757535724668e-06\n",
      "Epoch 3729, Loss: 0.00040842127509677084, Final Batch Loss: 0.0001365350908599794\n",
      "Epoch 3730, Loss: 8.322395024151774e-05, Final Batch Loss: 2.687630694708787e-05\n",
      "Epoch 3731, Loss: 0.00011724737305485178, Final Batch Loss: 3.1440660677617416e-05\n",
      "Epoch 3732, Loss: 0.0001388831578879035, Final Batch Loss: 9.11112056201091e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3733, Loss: 0.0001891798938231659, Final Batch Loss: 0.00011371927394066006\n",
      "Epoch 3734, Loss: 0.0004193077802483458, Final Batch Loss: 2.0367235265439376e-05\n",
      "Epoch 3735, Loss: 0.0002800674656100455, Final Batch Loss: 3.3879168768180534e-05\n",
      "Epoch 3736, Loss: 0.0001458086892398569, Final Batch Loss: 5.395833341026446e-06\n",
      "Epoch 3737, Loss: 0.00010469558037584648, Final Batch Loss: 6.513467815238982e-05\n",
      "Epoch 3738, Loss: 0.0005607112343568588, Final Batch Loss: 0.00016930705169215798\n",
      "Epoch 3739, Loss: 0.00038385684456443414, Final Batch Loss: 8.091043127933517e-06\n",
      "Epoch 3740, Loss: 0.0005498850728145044, Final Batch Loss: 0.0004809223173651844\n",
      "Epoch 3741, Loss: 5.630442115034384e-05, Final Batch Loss: 1.8231481590191834e-05\n",
      "Epoch 3742, Loss: 0.0037665809177269693, Final Batch Loss: 0.0001245708845090121\n",
      "Epoch 3743, Loss: 9.41512844292447e-05, Final Batch Loss: 1.8840251868823543e-05\n",
      "Epoch 3744, Loss: 0.00033757620627739016, Final Batch Loss: 3.2195754329222837e-07\n",
      "Epoch 3745, Loss: 0.00047293706393247703, Final Batch Loss: 1.770548442436848e-05\n",
      "Epoch 3746, Loss: 0.0001327320755990513, Final Batch Loss: 7.242443643917795e-06\n",
      "Epoch 3747, Loss: 0.00012140673902649723, Final Batch Loss: 2.0124118691455806e-06\n",
      "Epoch 3748, Loss: 0.010017178473390231, Final Batch Loss: 0.0033411141484975815\n",
      "Epoch 3749, Loss: 0.0002605914257856057, Final Batch Loss: 0.00022935678134672344\n",
      "Epoch 3750, Loss: 0.0007390899481833912, Final Batch Loss: 0.0005547323380596936\n",
      "Epoch 3751, Loss: 0.00022568125299926578, Final Batch Loss: 7.722826558165252e-05\n",
      "Epoch 3752, Loss: 0.0003877539056702517, Final Batch Loss: 7.438188185915351e-05\n",
      "Epoch 3753, Loss: 0.0007283716040547006, Final Batch Loss: 0.0003461854066699743\n",
      "Epoch 3754, Loss: 0.0008160461811712594, Final Batch Loss: 0.0005834928015246987\n",
      "Epoch 3755, Loss: 0.0033380564127583057, Final Batch Loss: 0.0031752032227814198\n",
      "Epoch 3756, Loss: 0.001009556468716255, Final Batch Loss: 1.9842434539896203e-06\n",
      "Epoch 3757, Loss: 0.0003996635314251762, Final Batch Loss: 4.2652212869143113e-05\n",
      "Epoch 3758, Loss: 0.0004253635215718532, Final Batch Loss: 0.0003268844448029995\n",
      "Epoch 3759, Loss: 0.0003404876383683586, Final Batch Loss: 4.403921138873557e-06\n",
      "Epoch 3760, Loss: 0.001103768536268035, Final Batch Loss: 8.460947719868273e-05\n",
      "Epoch 3761, Loss: 0.0006277500183387019, Final Batch Loss: 0.00011779637861764058\n",
      "Epoch 3762, Loss: 0.007531155211836449, Final Batch Loss: 8.472879926557653e-06\n",
      "Epoch 3763, Loss: 0.00015648874250473455, Final Batch Loss: 5.916746522416361e-05\n",
      "Epoch 3764, Loss: 0.000587258669838775, Final Batch Loss: 0.00021550968813244253\n",
      "Epoch 3765, Loss: 0.0003148219079776027, Final Batch Loss: 4.908757546218112e-05\n",
      "Epoch 3766, Loss: 0.0005084286030978546, Final Batch Loss: 2.683400634850841e-05\n",
      "Epoch 3767, Loss: 0.0008132029352054815, Final Batch Loss: 2.5258041205233894e-06\n",
      "Epoch 3768, Loss: 0.005108562127134064, Final Batch Loss: 8.037699444685131e-06\n",
      "Epoch 3769, Loss: 0.0038968488479440566, Final Batch Loss: 3.7992529541952536e-05\n",
      "Epoch 3770, Loss: 0.0057861095763200865, Final Batch Loss: 2.861698476408492e-06\n",
      "Epoch 3771, Loss: 0.0004438891382960719, Final Batch Loss: 0.00010377659054938704\n",
      "Epoch 3772, Loss: 0.022645270970315323, Final Batch Loss: 4.890604941465426e-06\n",
      "Epoch 3773, Loss: 0.0022737843819413683, Final Batch Loss: 0.0003841326688416302\n",
      "Epoch 3774, Loss: 0.00026985055455952534, Final Batch Loss: 0.00023329522809945047\n",
      "Epoch 3775, Loss: 0.013305729427884216, Final Batch Loss: 0.0006994723808020353\n",
      "Epoch 3776, Loss: 0.007355351651767705, Final Batch Loss: 2.8073850444343407e-06\n",
      "Epoch 3777, Loss: 0.0004571621275317739, Final Batch Loss: 5.622400749416556e-06\n",
      "Epoch 3778, Loss: 0.0005991840885144484, Final Batch Loss: 3.5149409995938186e-06\n",
      "Epoch 3779, Loss: 0.001514385393647899, Final Batch Loss: 1.8237162748846458e-06\n",
      "Epoch 3780, Loss: 0.0170298223674763, Final Batch Loss: 0.004712284076958895\n",
      "Epoch 3781, Loss: 0.00020200509152346058, Final Batch Loss: 6.135383046057541e-06\n",
      "Epoch 3782, Loss: 0.00014529114196193404, Final Batch Loss: 3.433895471971482e-05\n",
      "Epoch 3783, Loss: 0.00010327326617698418, Final Batch Loss: 5.514587974175811e-05\n",
      "Epoch 3784, Loss: 0.004927904828946339, Final Batch Loss: 3.805409141932614e-05\n",
      "Epoch 3785, Loss: 0.0006339663327707967, Final Batch Loss: 6.531232884299243e-06\n",
      "Epoch 3786, Loss: 5.3083745569892926e-05, Final Batch Loss: 3.617339189077029e-06\n",
      "Epoch 3787, Loss: 0.0006285233148446423, Final Batch Loss: 5.295201845001429e-05\n",
      "Epoch 3788, Loss: 0.008823806972941384, Final Batch Loss: 0.00010654578363755718\n",
      "Epoch 3789, Loss: 0.00030750356017961167, Final Batch Loss: 9.517452417640015e-05\n",
      "Epoch 3790, Loss: 0.0014119783827482024, Final Batch Loss: 0.0008883604896254838\n",
      "Epoch 3791, Loss: 0.008999248494546919, Final Batch Loss: 3.5437151382211596e-05\n",
      "Epoch 3792, Loss: 0.0022938233696550014, Final Batch Loss: 5.2879240683978423e-05\n",
      "Epoch 3793, Loss: 0.0022778607526561245, Final Batch Loss: 0.0020137804094702005\n",
      "Epoch 3794, Loss: 0.0004226594760439184, Final Batch Loss: 3.5787943488685414e-06\n",
      "Epoch 3795, Loss: 0.0003175281181029277, Final Batch Loss: 4.6004926844034344e-05\n",
      "Epoch 3796, Loss: 0.0006418804490522234, Final Batch Loss: 1.3585718988906592e-05\n",
      "Epoch 3797, Loss: 0.00038908164822260005, Final Batch Loss: 0.00023130522458814085\n",
      "Epoch 3798, Loss: 0.002495979380910285, Final Batch Loss: 4.4898017222294584e-05\n",
      "Epoch 3799, Loss: 0.00011246521808061516, Final Batch Loss: 1.201057148136897e-05\n",
      "Epoch 3800, Loss: 8.522568805346964e-05, Final Batch Loss: 4.126729618292302e-05\n",
      "Epoch 3801, Loss: 6.542048595292727e-05, Final Batch Loss: 6.3276320361183025e-06\n",
      "Epoch 3802, Loss: 0.0064205227072307025, Final Batch Loss: 0.0002595562837086618\n",
      "Epoch 3803, Loss: 0.00014776956777495798, Final Batch Loss: 9.569496614858508e-05\n",
      "Epoch 3804, Loss: 0.006706317630232661, Final Batch Loss: 1.0765523256850429e-05\n",
      "Epoch 3805, Loss: 0.031741968546157295, Final Batch Loss: 2.2700734916725196e-05\n",
      "Epoch 3806, Loss: 0.00024259855035779765, Final Batch Loss: 7.172728510340676e-05\n",
      "Epoch 3807, Loss: 0.0006158369069453329, Final Batch Loss: 1.250430432264693e-05\n",
      "Epoch 3808, Loss: 0.0038331835548888193, Final Batch Loss: 0.003793890355154872\n",
      "Epoch 3809, Loss: 0.021565749263345424, Final Batch Loss: 2.9152549814170925e-06\n",
      "Epoch 3810, Loss: 0.030541502491360006, Final Batch Loss: 0.00033911142963916063\n",
      "Epoch 3811, Loss: 0.011591438815230504, Final Batch Loss: 0.011350365355610847\n",
      "Epoch 3812, Loss: 0.00010669304265320534, Final Batch Loss: 1.2351818440947682e-05\n",
      "Epoch 3813, Loss: 0.0004906965041300282, Final Batch Loss: 0.00017988729814533144\n",
      "Epoch 3814, Loss: 0.00881773231412808, Final Batch Loss: 0.0004955197218805552\n",
      "Epoch 3815, Loss: 0.0005885920509172138, Final Batch Loss: 0.00019892708223778754\n",
      "Epoch 3816, Loss: 0.003961258757044561, Final Batch Loss: 0.0034931376576423645\n",
      "Epoch 3817, Loss: 0.001056146148357584, Final Batch Loss: 5.0294351240154356e-05\n",
      "Epoch 3818, Loss: 0.000201316237962601, Final Batch Loss: 9.420972492080182e-05\n",
      "Epoch 3819, Loss: 0.00023663571300858166, Final Batch Loss: 4.262353468220681e-05\n",
      "Epoch 3820, Loss: 0.004053429209307069, Final Batch Loss: 6.0858110373374075e-05\n",
      "Epoch 3821, Loss: 0.0004580327913572546, Final Batch Loss: 2.9908009310020134e-05\n",
      "Epoch 3822, Loss: 0.000779985162353114, Final Batch Loss: 2.6140728550672065e-06\n",
      "Epoch 3823, Loss: 0.0038458430437913194, Final Batch Loss: 2.7951584797847318e-06\n",
      "Epoch 3824, Loss: 0.0009638200972403865, Final Batch Loss: 0.0009045553160831332\n",
      "Epoch 3825, Loss: 0.000499581921758363, Final Batch Loss: 2.9887496566516347e-05\n",
      "Epoch 3826, Loss: 0.0002636617937241681, Final Batch Loss: 8.013852493604645e-06\n",
      "Epoch 3827, Loss: 0.00011848581516460399, Final Batch Loss: 2.3405809770338237e-05\n",
      "Epoch 3828, Loss: 0.0012618149448826443, Final Batch Loss: 3.061371899093501e-05\n",
      "Epoch 3829, Loss: 0.0006141899657450267, Final Batch Loss: 4.830397665500641e-05\n",
      "Epoch 3830, Loss: 4.618087541530258e-05, Final Batch Loss: 1.4059805835131556e-05\n",
      "Epoch 3831, Loss: 0.0002153280775019084, Final Batch Loss: 2.9750872272416018e-05\n",
      "Epoch 3832, Loss: 0.0015839324316857528, Final Batch Loss: 3.557308673407533e-06\n",
      "Epoch 3833, Loss: 0.0004631400770449545, Final Batch Loss: 2.0928384401486255e-05\n",
      "Epoch 3834, Loss: 0.0004029300980619155, Final Batch Loss: 7.885580998845398e-05\n",
      "Epoch 3835, Loss: 9.936689457390457e-05, Final Batch Loss: 3.235116309951991e-05\n",
      "Epoch 3836, Loss: 0.00040942077407635225, Final Batch Loss: 8.372715001314646e-07\n",
      "Epoch 3837, Loss: 0.000995043030798115, Final Batch Loss: 5.188273007661337e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3838, Loss: 0.0001094848944376281, Final Batch Loss: 6.753759862476727e-06\n",
      "Epoch 3839, Loss: 0.00015721692307124613, Final Batch Loss: 4.540567715594079e-06\n",
      "Epoch 3840, Loss: 0.0009364456025195977, Final Batch Loss: 3.2944815302471397e-06\n",
      "Epoch 3841, Loss: 0.00015686456026742235, Final Batch Loss: 1.0680553714337293e-05\n",
      "Epoch 3842, Loss: 0.00020592966211552266, Final Batch Loss: 0.00012733142648357898\n",
      "Epoch 3843, Loss: 0.0004912022450298537, Final Batch Loss: 0.00011211043602088466\n",
      "Epoch 3844, Loss: 0.00016393269834225066, Final Batch Loss: 3.484958870103583e-05\n",
      "Epoch 3845, Loss: 0.0006093807096476667, Final Batch Loss: 3.192698932252824e-05\n",
      "Epoch 3846, Loss: 0.00019788904501183424, Final Batch Loss: 3.637523695942946e-05\n",
      "Epoch 3847, Loss: 0.00021152049021111452, Final Batch Loss: 7.604218353662873e-06\n",
      "Epoch 3848, Loss: 0.001238528691828833, Final Batch Loss: 1.821152363845613e-05\n",
      "Epoch 3849, Loss: 7.47761132515734e-05, Final Batch Loss: 6.199556082719937e-06\n",
      "Epoch 3850, Loss: 0.0003288338980382832, Final Batch Loss: 3.8860025597386993e-07\n",
      "Epoch 3851, Loss: 0.008442627367912792, Final Batch Loss: 6.765512080164626e-05\n",
      "Epoch 3852, Loss: 6.781736556149554e-05, Final Batch Loss: 4.8591500672046095e-05\n",
      "Epoch 3853, Loss: 0.0005549774722908296, Final Batch Loss: 6.279551030274888e-07\n",
      "Epoch 3854, Loss: 0.0002960873862321023, Final Batch Loss: 4.430451008374803e-05\n",
      "Epoch 3855, Loss: 0.018117835770681268, Final Batch Loss: 3.0251385396695696e-06\n",
      "Epoch 3856, Loss: 0.0001820602788029646, Final Batch Loss: 3.6738889320986345e-05\n",
      "Epoch 3857, Loss: 0.0006357291923677622, Final Batch Loss: 5.0821796321542934e-05\n",
      "Epoch 3858, Loss: 0.00041693938874232117, Final Batch Loss: 1.4763440049136989e-05\n",
      "Epoch 3859, Loss: 0.000571927447708731, Final Batch Loss: 0.00027486926410347223\n",
      "Epoch 3860, Loss: 0.00019631307759482297, Final Batch Loss: 1.1216429811611306e-06\n",
      "Epoch 3861, Loss: 0.0001454823050153209, Final Batch Loss: 3.419909262447618e-06\n",
      "Epoch 3862, Loss: 0.00012679640894930344, Final Batch Loss: 9.810100891627371e-05\n",
      "Epoch 3863, Loss: 0.0003324792714920477, Final Batch Loss: 0.00021658399782609195\n",
      "Epoch 3864, Loss: 0.0019349681024323218, Final Batch Loss: 0.0015225560637190938\n",
      "Epoch 3865, Loss: 7.741586205156636e-05, Final Batch Loss: 4.143278783885762e-05\n",
      "Epoch 3866, Loss: 0.0001807692078727996, Final Batch Loss: 7.079670467646793e-05\n",
      "Epoch 3867, Loss: 0.009121341565332841, Final Batch Loss: 2.4760929591138847e-06\n",
      "Epoch 3868, Loss: 0.00011950616726608132, Final Batch Loss: 7.5166431088291574e-06\n",
      "Epoch 3869, Loss: 0.0002996645616804017, Final Batch Loss: 9.197237523039803e-05\n",
      "Epoch 3870, Loss: 0.0004571907361423655, Final Batch Loss: 5.806958597531775e-06\n",
      "Epoch 3871, Loss: 0.0012538741063963244, Final Batch Loss: 1.1122608611913165e-06\n",
      "Epoch 3872, Loss: 0.00013518471087081707, Final Batch Loss: 1.7112486602854915e-05\n",
      "Epoch 3873, Loss: 0.00013912549343331193, Final Batch Loss: 3.4840593343687942e-06\n",
      "Epoch 3874, Loss: 0.0004711727269750554, Final Batch Loss: 0.00012005392636638135\n",
      "Epoch 3875, Loss: 0.00026885755960393, Final Batch Loss: 0.00020776565361302346\n",
      "Epoch 3876, Loss: 0.00032241910412267316, Final Batch Loss: 0.00030352515750564635\n",
      "Epoch 3877, Loss: 0.00023737948140478693, Final Batch Loss: 1.385277573717758e-05\n",
      "Epoch 3878, Loss: 0.002822688266462592, Final Batch Loss: 9.423961842003337e-07\n",
      "Epoch 3879, Loss: 0.00020280109720260953, Final Batch Loss: 4.999048542231321e-05\n",
      "Epoch 3880, Loss: 0.00024643782398925396, Final Batch Loss: 4.674998490372673e-05\n",
      "Epoch 3881, Loss: 0.00026496001783016254, Final Batch Loss: 1.5412292668770533e-06\n",
      "Epoch 3882, Loss: 6.354828292387538e-05, Final Batch Loss: 1.5408564649987966e-05\n",
      "Epoch 3883, Loss: 7.875732126194634e-05, Final Batch Loss: 3.1227296858560294e-05\n",
      "Epoch 3884, Loss: 0.0066674977992988715, Final Batch Loss: 3.1387012313643936e-06\n",
      "Epoch 3885, Loss: 0.0006229553837329149, Final Batch Loss: 0.000287923525320366\n",
      "Epoch 3886, Loss: 0.0015175133194134105, Final Batch Loss: 0.0003010422515217215\n",
      "Epoch 3887, Loss: 0.00030627357909907005, Final Batch Loss: 6.1423943407135084e-06\n",
      "Epoch 3888, Loss: 0.0011352855835866649, Final Batch Loss: 0.0008502291166223586\n",
      "Epoch 3889, Loss: 0.0010941111213469412, Final Batch Loss: 3.212650335626677e-05\n",
      "Epoch 3890, Loss: 0.00535138770874255, Final Batch Loss: 6.212840617081383e-06\n",
      "Epoch 3891, Loss: 0.00010990566647706146, Final Batch Loss: 7.374871074716793e-06\n",
      "Epoch 3892, Loss: 0.00033791744317568373, Final Batch Loss: 0.0002519032859709114\n",
      "Epoch 3893, Loss: 0.00011228960943299171, Final Batch Loss: 3.317835080451914e-06\n",
      "Epoch 3894, Loss: 0.0012037901888106717, Final Batch Loss: 0.0006544720381498337\n",
      "Epoch 3895, Loss: 0.018070073367198347, Final Batch Loss: 1.9657403754536062e-05\n",
      "Epoch 3896, Loss: 0.00019198027530364925, Final Batch Loss: 0.0001331191451754421\n",
      "Epoch 3897, Loss: 0.0007296462354133837, Final Batch Loss: 0.00015942921163514256\n",
      "Epoch 3898, Loss: 0.01236353226704523, Final Batch Loss: 5.07832010043785e-05\n",
      "Epoch 3899, Loss: 0.00047751378394877975, Final Batch Loss: 7.396455430352944e-07\n",
      "Epoch 3900, Loss: 0.11713700134532701, Final Batch Loss: 0.11688867211341858\n",
      "Epoch 3901, Loss: 0.0011448542281868868, Final Batch Loss: 0.0001484490931034088\n",
      "Epoch 3902, Loss: 0.0069358943055704, Final Batch Loss: 0.003862192155793309\n",
      "Epoch 3903, Loss: 0.01310382497831597, Final Batch Loss: 4.681073551182635e-05\n",
      "Epoch 3904, Loss: 0.0007380968527286313, Final Batch Loss: 6.292931357165799e-05\n",
      "Epoch 3905, Loss: 0.0015619797450199258, Final Batch Loss: 0.001041719107888639\n",
      "Epoch 3906, Loss: 0.01159258852385392, Final Batch Loss: 0.00244681304320693\n",
      "Epoch 3907, Loss: 0.0006229398131836206, Final Batch Loss: 9.170496923616156e-05\n",
      "Epoch 3908, Loss: 0.0005313270394253777, Final Batch Loss: 0.000382443075068295\n",
      "Epoch 3909, Loss: 0.009674389177234843, Final Batch Loss: 0.008624378591775894\n",
      "Epoch 3910, Loss: 0.0002013079974858556, Final Batch Loss: 3.902229218510911e-05\n",
      "Epoch 3911, Loss: 0.014438503538258374, Final Batch Loss: 0.0007240584818646312\n",
      "Epoch 3912, Loss: 0.000910977962121251, Final Batch Loss: 9.164935181615874e-05\n",
      "Epoch 3913, Loss: 0.00036149371589999646, Final Batch Loss: 2.8277674573473632e-05\n",
      "Epoch 3914, Loss: 0.0040327535944015835, Final Batch Loss: 0.002878488041460514\n",
      "Epoch 3915, Loss: 0.0040433903741359245, Final Batch Loss: 5.951348430244252e-05\n",
      "Epoch 3916, Loss: 0.00043272603852528846, Final Batch Loss: 5.0376787839923054e-05\n",
      "Epoch 3917, Loss: 0.004675459393183701, Final Batch Loss: 6.011633377056569e-05\n",
      "Epoch 3918, Loss: 0.05131158905169286, Final Batch Loss: 0.049373432993888855\n",
      "Epoch 3919, Loss: 0.001806260230296175, Final Batch Loss: 2.0176359612378292e-05\n",
      "Epoch 3920, Loss: 0.013387828206759878, Final Batch Loss: 0.00010251546336803585\n",
      "Epoch 3921, Loss: 0.0022232900810195133, Final Batch Loss: 0.001523638959042728\n",
      "Epoch 3922, Loss: 0.0039025352671160363, Final Batch Loss: 0.002376818796619773\n",
      "Epoch 3923, Loss: 0.0015870555907895323, Final Batch Loss: 0.0005263325292617083\n",
      "Epoch 3924, Loss: 0.0005194855821173405, Final Batch Loss: 0.00012175001756986603\n",
      "Epoch 3925, Loss: 0.0022795603435952216, Final Batch Loss: 0.00022782130690757185\n",
      "Epoch 3926, Loss: 0.0011534918085089885, Final Batch Loss: 0.0002070576447295025\n",
      "Epoch 3927, Loss: 0.01648400789417792, Final Batch Loss: 0.0007556519121862948\n",
      "Epoch 3928, Loss: 0.0033763889368856326, Final Batch Loss: 0.0002867064322344959\n",
      "Epoch 3929, Loss: 0.0017968812553590396, Final Batch Loss: 0.00014789545093663037\n",
      "Epoch 3930, Loss: 0.0025033243309735553, Final Batch Loss: 2.948470319097396e-05\n",
      "Epoch 3931, Loss: 0.0017820185130403843, Final Batch Loss: 0.0005467170849442482\n",
      "Epoch 3932, Loss: 0.0009255647819372825, Final Batch Loss: 0.0003466929483693093\n",
      "Epoch 3933, Loss: 0.002972511349071283, Final Batch Loss: 0.0021356609649956226\n",
      "Epoch 3934, Loss: 0.0008245435237768106, Final Batch Loss: 7.110844308044761e-05\n",
      "Epoch 3935, Loss: 0.0010224709376416286, Final Batch Loss: 7.239192927954718e-05\n",
      "Epoch 3936, Loss: 0.0003388113191249431, Final Batch Loss: 5.382117706176359e-06\n",
      "Epoch 3937, Loss: 0.00048455030992045067, Final Batch Loss: 3.0150160455377772e-05\n",
      "Epoch 3938, Loss: 0.0009780869222595356, Final Batch Loss: 3.373699291842058e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3939, Loss: 0.0005045706348028034, Final Batch Loss: 6.412631046259776e-05\n",
      "Epoch 3940, Loss: 0.000646174486973905, Final Batch Loss: 0.00024487797054462135\n",
      "Epoch 3941, Loss: 0.00123268247989472, Final Batch Loss: 0.0004034629091620445\n",
      "Epoch 3942, Loss: 0.0004949558096996043, Final Batch Loss: 4.4728229113388807e-05\n",
      "Epoch 3943, Loss: 0.00032865655612113187, Final Batch Loss: 1.1403412827348802e-05\n",
      "Epoch 3944, Loss: 0.011631253641098738, Final Batch Loss: 0.00019350508227944374\n",
      "Epoch 3945, Loss: 0.00032719308728701435, Final Batch Loss: 0.00011875960626639426\n",
      "Epoch 3946, Loss: 0.000482732146338094, Final Batch Loss: 8.785138925304636e-05\n",
      "Epoch 3947, Loss: 0.02538268051284831, Final Batch Loss: 0.024499230086803436\n",
      "Epoch 3948, Loss: 0.0006199415984156076, Final Batch Loss: 0.00040085468208417296\n",
      "Epoch 3949, Loss: 0.0006976226777624106, Final Batch Loss: 5.9548539866227657e-05\n",
      "Epoch 3950, Loss: 0.0015536436058027903, Final Batch Loss: 0.0010489330161362886\n",
      "Epoch 3951, Loss: 0.0006177397244755412, Final Batch Loss: 7.127079152269289e-05\n",
      "Epoch 3952, Loss: 0.0006858892156742513, Final Batch Loss: 5.31190526089631e-05\n",
      "Epoch 3953, Loss: 0.0008455200295429677, Final Batch Loss: 0.0003527970111463219\n",
      "Epoch 3954, Loss: 0.0008107788198685739, Final Batch Loss: 1.8500109945307486e-05\n",
      "Epoch 3955, Loss: 0.0015845269535930129, Final Batch Loss: 9.052169843926094e-06\n",
      "Epoch 3956, Loss: 0.0005028833329561166, Final Batch Loss: 0.00016532096196897328\n",
      "Epoch 3957, Loss: 0.001853719830251066, Final Batch Loss: 0.0016643275739625096\n",
      "Epoch 3958, Loss: 0.00034612195668159984, Final Batch Loss: 6.822863360866904e-05\n",
      "Epoch 3959, Loss: 0.00017924888925335836, Final Batch Loss: 1.1705526048899628e-05\n",
      "Epoch 3960, Loss: 0.0005156179540790617, Final Batch Loss: 7.142846152419224e-05\n",
      "Epoch 3961, Loss: 0.0007657473843210028, Final Batch Loss: 3.091008693445474e-05\n",
      "Epoch 3962, Loss: 0.00041091661478276365, Final Batch Loss: 5.154291648068465e-05\n",
      "Epoch 3963, Loss: 0.00034546594451967394, Final Batch Loss: 1.202155453938758e-05\n",
      "Epoch 3964, Loss: 0.00044977248398936354, Final Batch Loss: 4.264785457053222e-05\n",
      "Epoch 3965, Loss: 0.0005660190327034798, Final Batch Loss: 8.001614332897589e-06\n",
      "Epoch 3966, Loss: 0.0006687723434879445, Final Batch Loss: 7.091009319992736e-05\n",
      "Epoch 3967, Loss: 0.004186800697425497, Final Batch Loss: 0.0032973827328532934\n",
      "Epoch 3968, Loss: 0.00023649920876778197, Final Batch Loss: 0.00010952961747534573\n",
      "Epoch 3969, Loss: 0.0007767120514472481, Final Batch Loss: 0.0001772669784259051\n",
      "Epoch 3970, Loss: 0.0007534839714935515, Final Batch Loss: 2.8236707294126973e-05\n",
      "Epoch 3971, Loss: 0.006781569747545291, Final Batch Loss: 0.0019052691059187055\n",
      "Epoch 3972, Loss: 0.0017989087209571153, Final Batch Loss: 0.0002579333959147334\n",
      "Epoch 3973, Loss: 0.0005698274289898109, Final Batch Loss: 0.000142955468618311\n",
      "Epoch 3974, Loss: 0.0007692037252127193, Final Batch Loss: 0.0005265238578431308\n",
      "Epoch 3975, Loss: 0.0002756320718617644, Final Batch Loss: 6.125853542471305e-05\n",
      "Epoch 3976, Loss: 0.0005980495870971936, Final Batch Loss: 0.0002534622326493263\n",
      "Epoch 3977, Loss: 0.00031700352155894507, Final Batch Loss: 4.344521585153416e-06\n",
      "Epoch 3978, Loss: 0.0003879611685988493, Final Batch Loss: 1.554141636006534e-05\n",
      "Epoch 3979, Loss: 0.0006910821648489218, Final Batch Loss: 0.00034003995824605227\n",
      "Epoch 3980, Loss: 0.0002502459756215103, Final Batch Loss: 3.457921411609277e-05\n",
      "Epoch 3981, Loss: 0.000376411437173374, Final Batch Loss: 1.531761336082127e-05\n",
      "Epoch 3982, Loss: 0.0008270280923170503, Final Batch Loss: 5.9617002989398316e-05\n",
      "Epoch 3983, Loss: 0.0005577071642619558, Final Batch Loss: 4.369828093331307e-05\n",
      "Epoch 3984, Loss: 0.0002855453514598594, Final Batch Loss: 5.416006274572283e-07\n",
      "Epoch 3985, Loss: 0.0002486300516011397, Final Batch Loss: 2.380230171183939e-06\n",
      "Epoch 3986, Loss: 0.0008210683045035694, Final Batch Loss: 0.00012738896475639194\n",
      "Epoch 3987, Loss: 0.00023483474433305673, Final Batch Loss: 9.642181976232678e-05\n",
      "Epoch 3988, Loss: 0.0007835989381419495, Final Batch Loss: 1.2917508684040513e-05\n",
      "Epoch 3989, Loss: 0.00019047625573875848, Final Batch Loss: 2.4899141862988472e-05\n",
      "Epoch 3990, Loss: 0.00018919426292995922, Final Batch Loss: 4.741792508866638e-06\n",
      "Epoch 3991, Loss: 0.021587173483567312, Final Batch Loss: 2.3941338440636173e-05\n",
      "Epoch 3992, Loss: 0.00027929556381423026, Final Batch Loss: 3.363827272551134e-05\n",
      "Epoch 3993, Loss: 0.0028215503916726448, Final Batch Loss: 3.764840221265331e-05\n",
      "Epoch 3994, Loss: 0.0001248233729711501, Final Batch Loss: 1.1698263733705971e-05\n",
      "Epoch 3995, Loss: 0.0006614282701775664, Final Batch Loss: 0.00023577988031320274\n",
      "Epoch 3996, Loss: 0.00032458366877108347, Final Batch Loss: 1.5633033399353735e-05\n",
      "Epoch 3997, Loss: 0.00019366554624866694, Final Batch Loss: 3.843258673441596e-05\n",
      "Epoch 3998, Loss: 0.0003867573705065297, Final Batch Loss: 2.0617046175175346e-05\n",
      "Epoch 3999, Loss: 0.0006632897457166109, Final Batch Loss: 0.00028432844555936754\n",
      "Epoch 4000, Loss: 0.001900733838283486, Final Batch Loss: 7.3472697295073885e-06\n",
      "Epoch 4001, Loss: 0.0011871162269017077, Final Batch Loss: 2.9574282962130383e-05\n",
      "Epoch 4002, Loss: 0.0001697048392088618, Final Batch Loss: 2.7994688934995793e-05\n",
      "Epoch 4003, Loss: 0.00016553635578020476, Final Batch Loss: 3.856745388475247e-05\n",
      "Epoch 4004, Loss: 0.0006080396015022416, Final Batch Loss: 4.6974837459856644e-05\n",
      "Epoch 4005, Loss: 0.0003149501962980139, Final Batch Loss: 1.0119015314558055e-05\n",
      "Epoch 4006, Loss: 0.008655106772494037, Final Batch Loss: 2.797358320094645e-05\n",
      "Epoch 4007, Loss: 0.00043114463733218145, Final Batch Loss: 0.000322625768603757\n",
      "Epoch 4008, Loss: 0.00029354452453844715, Final Batch Loss: 0.00011642805475275964\n",
      "Epoch 4009, Loss: 0.00019043626070924802, Final Batch Loss: 9.874945135379676e-06\n",
      "Epoch 4010, Loss: 0.0026313236944588425, Final Batch Loss: 3.913041382475058e-06\n",
      "Epoch 4011, Loss: 0.0001092225265892921, Final Batch Loss: 7.944496246636845e-06\n",
      "Epoch 4012, Loss: 0.0002644218538989662, Final Batch Loss: 9.892103662423324e-06\n",
      "Epoch 4013, Loss: 0.00018041777730104513, Final Batch Loss: 0.00011833493044832721\n",
      "Epoch 4014, Loss: 0.00023628755843674298, Final Batch Loss: 5.320810305420309e-05\n",
      "Epoch 4015, Loss: 0.0005244768617558293, Final Batch Loss: 0.00022631947649642825\n",
      "Epoch 4016, Loss: 0.00027561916795093566, Final Batch Loss: 1.7334041331196204e-05\n",
      "Epoch 4017, Loss: 0.0010217301605734974, Final Batch Loss: 0.0006737795774824917\n",
      "Epoch 4018, Loss: 0.00023167690051195677, Final Batch Loss: 2.3976552256499417e-05\n",
      "Epoch 4019, Loss: 0.000576873783757037, Final Batch Loss: 0.00022374549007508904\n",
      "Epoch 4020, Loss: 0.0002342448960916954, Final Batch Loss: 1.0359678526583593e-05\n",
      "Epoch 4021, Loss: 0.0001544607935102249, Final Batch Loss: 6.054059213056462e-06\n",
      "Epoch 4022, Loss: 0.00014564450998477696, Final Batch Loss: 3.37608821610047e-06\n",
      "Epoch 4023, Loss: 0.00021109404315211577, Final Batch Loss: 6.893452336953487e-06\n",
      "Epoch 4024, Loss: 0.0010460226412760676, Final Batch Loss: 0.0009800601983442903\n",
      "Epoch 4025, Loss: 0.00011048640044464264, Final Batch Loss: 4.6405424654949456e-05\n",
      "Epoch 4026, Loss: 0.0004021947943328996, Final Batch Loss: 4.271958096069284e-05\n",
      "Epoch 4027, Loss: 0.00048392947428510524, Final Batch Loss: 8.568615885451436e-05\n",
      "Epoch 4028, Loss: 0.0003772026248043403, Final Batch Loss: 0.00021138935699127614\n",
      "Epoch 4029, Loss: 0.000156124909153732, Final Batch Loss: 2.436893555568531e-05\n",
      "Epoch 4030, Loss: 0.0007789580664621099, Final Batch Loss: 1.5074198245201842e-06\n",
      "Epoch 4031, Loss: 0.0007581343907077098, Final Batch Loss: 0.0006599638727493584\n",
      "Epoch 4032, Loss: 0.00019962968553954852, Final Batch Loss: 2.543666141718859e-06\n",
      "Epoch 4033, Loss: 0.005014259571908042, Final Batch Loss: 0.004887356422841549\n",
      "Epoch 4034, Loss: 0.0006325975000436301, Final Batch Loss: 1.1909341992577538e-05\n",
      "Epoch 4035, Loss: 0.0009473000891375705, Final Batch Loss: 7.792334145051427e-06\n",
      "Epoch 4036, Loss: 0.00018935265234176768, Final Batch Loss: 4.694662038673414e-06\n",
      "Epoch 4037, Loss: 0.00014113315683061955, Final Batch Loss: 9.186022907670122e-06\n",
      "Epoch 4038, Loss: 0.0002043651165877236, Final Batch Loss: 1.7049062080332078e-05\n",
      "Epoch 4039, Loss: 0.00046444615963991964, Final Batch Loss: 1.189710837934399e-05\n",
      "Epoch 4040, Loss: 0.0008873769220372196, Final Batch Loss: 3.361340714036487e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4041, Loss: 0.0007788019224790332, Final Batch Loss: 0.00011019256635336205\n",
      "Epoch 4042, Loss: 0.002743057933912496, Final Batch Loss: 3.813899093074724e-05\n",
      "Epoch 4043, Loss: 7.890413598943269e-05, Final Batch Loss: 8.072232049016748e-06\n",
      "Epoch 4044, Loss: 0.00035328459398442646, Final Batch Loss: 9.642472832638305e-06\n",
      "Epoch 4045, Loss: 0.00021948120411252603, Final Batch Loss: 2.281334309373051e-05\n",
      "Epoch 4046, Loss: 0.0004044802499265643, Final Batch Loss: 4.8514870286453515e-05\n",
      "Epoch 4047, Loss: 0.000761400780902477, Final Batch Loss: 0.0006450613145716488\n",
      "Epoch 4048, Loss: 0.0002163433837267803, Final Batch Loss: 0.00010066208051284775\n",
      "Epoch 4049, Loss: 0.0024192737878365733, Final Batch Loss: 0.0019444721983745694\n",
      "Epoch 4050, Loss: 0.00015608598368999083, Final Batch Loss: 4.499844362726435e-05\n",
      "Epoch 4051, Loss: 0.00014484243388324103, Final Batch Loss: 1.2371873708616477e-05\n",
      "Epoch 4052, Loss: 0.00018723515904639498, Final Batch Loss: 6.634345481870696e-05\n",
      "Epoch 4053, Loss: 0.002651482491273782, Final Batch Loss: 1.1358783012838103e-05\n",
      "Epoch 4054, Loss: 0.0005747963500652986, Final Batch Loss: 0.00049876410048455\n",
      "Epoch 4055, Loss: 0.00025361776238241873, Final Batch Loss: 1.930705593622406e-06\n",
      "Epoch 4056, Loss: 0.000518378101332928, Final Batch Loss: 0.00026863618404604495\n",
      "Epoch 4057, Loss: 0.00010484459198778495, Final Batch Loss: 6.231363659026101e-05\n",
      "Epoch 4058, Loss: 2.9744082326033094e-05, Final Batch Loss: 2.1230889615253545e-06\n",
      "Epoch 4059, Loss: 8.795078599632689e-05, Final Batch Loss: 1.5346439568020287e-06\n",
      "Epoch 4060, Loss: 0.0016586476704105735, Final Batch Loss: 7.349831139435992e-05\n",
      "Epoch 4061, Loss: 0.000150383813092958, Final Batch Loss: 1.6690746633685194e-05\n",
      "Epoch 4062, Loss: 0.0010776539952530584, Final Batch Loss: 2.350002250750549e-05\n",
      "Epoch 4063, Loss: 5.3331675871959305e-05, Final Batch Loss: 5.173008503334131e-06\n",
      "Epoch 4064, Loss: 0.00015442145377164707, Final Batch Loss: 5.969291305518709e-05\n",
      "Epoch 4065, Loss: 0.00038150674936332507, Final Batch Loss: 4.3390245991759e-06\n",
      "Epoch 4066, Loss: 0.0003450203430475085, Final Batch Loss: 0.0002923957654275\n",
      "Epoch 4067, Loss: 8.636564780317713e-05, Final Batch Loss: 7.690061465837061e-06\n",
      "Epoch 4068, Loss: 1.6293869634864677e-05, Final Batch Loss: 6.94762547936989e-06\n",
      "Epoch 4069, Loss: 0.0005158314097570837, Final Batch Loss: 1.6271402273559943e-05\n",
      "Epoch 4070, Loss: 0.00014107021434028866, Final Batch Loss: 1.383261496812338e-05\n",
      "Epoch 4071, Loss: 6.804948998251348e-05, Final Batch Loss: 4.151393568463391e-06\n",
      "Epoch 4072, Loss: 0.00013789094407457014, Final Batch Loss: 7.87510884947551e-07\n",
      "Epoch 4073, Loss: 0.00015447309488081373, Final Batch Loss: 5.7051107432926074e-05\n",
      "Epoch 4074, Loss: 0.00013022655161876173, Final Batch Loss: 1.0581645256024785e-05\n",
      "Epoch 4075, Loss: 4.6864133764756843e-05, Final Batch Loss: 1.5434387023560703e-05\n",
      "Epoch 4076, Loss: 0.00019726682603504742, Final Batch Loss: 5.342256190488115e-05\n",
      "Epoch 4077, Loss: 0.00026003976381616667, Final Batch Loss: 1.2884731404483318e-05\n",
      "Epoch 4078, Loss: 9.126985014518141e-05, Final Batch Loss: 1.1490262295410503e-05\n",
      "Epoch 4079, Loss: 8.060323852987494e-05, Final Batch Loss: 2.065826083708089e-05\n",
      "Epoch 4080, Loss: 5.8064992117579095e-05, Final Batch Loss: 2.0346313249319792e-05\n",
      "Epoch 4081, Loss: 7.049148371152114e-05, Final Batch Loss: 2.729976586124394e-05\n",
      "Epoch 4082, Loss: 8.329492817438222e-05, Final Batch Loss: 6.504797624984349e-07\n",
      "Epoch 4083, Loss: 0.00010617165207804646, Final Batch Loss: 1.1325470950396266e-05\n",
      "Epoch 4084, Loss: 0.00010192662239205674, Final Batch Loss: 4.747063940158114e-06\n",
      "Epoch 4085, Loss: 0.006214704757667278, Final Batch Loss: 3.5995110465592006e-06\n",
      "Epoch 4086, Loss: 0.001323932364812208, Final Batch Loss: 2.8053359528712463e-06\n",
      "Epoch 4087, Loss: 0.00014008384914632188, Final Batch Loss: 4.288420768716605e-06\n",
      "Epoch 4088, Loss: 0.00012648567417272716, Final Batch Loss: 7.11007887730375e-05\n",
      "Epoch 4089, Loss: 0.0012898731049517664, Final Batch Loss: 1.911031404233654e-06\n",
      "Epoch 4090, Loss: 0.00018015424166151206, Final Batch Loss: 3.944662967114709e-05\n",
      "Epoch 4091, Loss: 7.553543110816463e-05, Final Batch Loss: 4.787114562532224e-07\n",
      "Epoch 4092, Loss: 0.00017961845878744498, Final Batch Loss: 5.085036900709383e-05\n",
      "Epoch 4093, Loss: 0.0004805033959200955, Final Batch Loss: 1.1155797437822912e-05\n",
      "Epoch 4094, Loss: 0.004353083836804217, Final Batch Loss: 7.796545105520636e-05\n",
      "Epoch 4095, Loss: 4.7348684802273056e-05, Final Batch Loss: 7.193134933913825e-06\n",
      "Epoch 4096, Loss: 0.0004190600881770479, Final Batch Loss: 0.0003559575416147709\n",
      "Epoch 4097, Loss: 0.0004004115762654692, Final Batch Loss: 0.0001032407017191872\n",
      "Epoch 4098, Loss: 8.507600614393596e-05, Final Batch Loss: 7.62868148740381e-06\n",
      "Epoch 4099, Loss: 0.0003290930853836471, Final Batch Loss: 9.718356523080729e-06\n",
      "Epoch 4100, Loss: 0.00019359140105734696, Final Batch Loss: 2.062159865090507e-06\n",
      "Epoch 4101, Loss: 0.000263651385466801, Final Batch Loss: 7.334398105740547e-06\n",
      "Epoch 4102, Loss: 0.0008059777926519018, Final Batch Loss: 0.0005678831366822124\n",
      "Epoch 4103, Loss: 0.00013321952610567678, Final Batch Loss: 4.359259401098825e-05\n",
      "Epoch 4104, Loss: 0.0006430541128565892, Final Batch Loss: 0.00045927136670798063\n",
      "Epoch 4105, Loss: 0.0003651254592114128, Final Batch Loss: 4.245867603458464e-05\n",
      "Epoch 4106, Loss: 0.0002816631572386541, Final Batch Loss: 3.5240736906416714e-05\n",
      "Epoch 4107, Loss: 0.00015249263083205733, Final Batch Loss: 3.5234777442383347e-06\n",
      "Epoch 4108, Loss: 7.529125628025213e-05, Final Batch Loss: 4.937886478728615e-05\n",
      "Epoch 4109, Loss: 0.0004330618203312042, Final Batch Loss: 8.646991773275658e-05\n",
      "Epoch 4110, Loss: 0.00015135845114855329, Final Batch Loss: 0.00010558425128692761\n",
      "Epoch 4111, Loss: 0.003597426908527268, Final Batch Loss: 5.99678278376814e-05\n",
      "Epoch 4112, Loss: 0.0005338323662726907, Final Batch Loss: 0.0001976597122848034\n",
      "Epoch 4113, Loss: 0.0001587380979799491, Final Batch Loss: 1.677025829849299e-05\n",
      "Epoch 4114, Loss: 6.382839717389288e-05, Final Batch Loss: 4.427001385920448e-06\n",
      "Epoch 4115, Loss: 0.00012175132633274188, Final Batch Loss: 1.1170813195349183e-05\n",
      "Epoch 4116, Loss: 9.232312322637881e-05, Final Batch Loss: 1.9710150809260085e-06\n",
      "Epoch 4117, Loss: 0.00010171902658839826, Final Batch Loss: 5.3624899010173976e-05\n",
      "Epoch 4118, Loss: 0.0002641056172478784, Final Batch Loss: 1.586268922437739e-06\n",
      "Epoch 4119, Loss: 0.0001250623856776656, Final Batch Loss: 8.79700601217337e-05\n",
      "Epoch 4120, Loss: 0.002560226958109979, Final Batch Loss: 5.265750928629132e-07\n",
      "Epoch 4121, Loss: 0.00047950076395864016, Final Batch Loss: 1.0810281310114078e-05\n",
      "Epoch 4122, Loss: 0.00030809377682317063, Final Batch Loss: 8.241268574238347e-07\n",
      "Epoch 4123, Loss: 0.00028370654104037385, Final Batch Loss: 2.7754383609135402e-06\n",
      "Epoch 4124, Loss: 0.0006237334873731015, Final Batch Loss: 0.00013659197429660708\n",
      "Epoch 4125, Loss: 0.023795480961780413, Final Batch Loss: 3.679238034237642e-06\n",
      "Epoch 4126, Loss: 0.0010479089755222049, Final Batch Loss: 6.373369956236274e-07\n",
      "Epoch 4127, Loss: 0.00021892784343435778, Final Batch Loss: 2.7979581318504643e-06\n",
      "Epoch 4128, Loss: 0.0014356658402903122, Final Batch Loss: 0.00014376688341144472\n",
      "Epoch 4129, Loss: 0.0010043763216458501, Final Batch Loss: 8.973241278908972e-07\n",
      "Epoch 4130, Loss: 0.00010551151444815332, Final Batch Loss: 2.934913572971709e-05\n",
      "Epoch 4131, Loss: 0.00010628010477375938, Final Batch Loss: 2.3511500330641866e-05\n",
      "Epoch 4132, Loss: 0.00010737394609350304, Final Batch Loss: 2.6590380457491847e-06\n",
      "Epoch 4133, Loss: 0.000215806852793321, Final Batch Loss: 0.0001226843596668914\n",
      "Epoch 4134, Loss: 0.00035001596256734047, Final Batch Loss: 0.00026756321312859654\n",
      "Epoch 4135, Loss: 8.394472911277262e-05, Final Batch Loss: 2.5257149900426157e-06\n",
      "Epoch 4136, Loss: 0.00013501402327165124, Final Batch Loss: 1.2539953786472324e-06\n",
      "Epoch 4137, Loss: 0.0001439027628293843, Final Batch Loss: 4.894463017990347e-06\n",
      "Epoch 4138, Loss: 0.0001208369692449196, Final Batch Loss: 4.06297931476729e-06\n",
      "Epoch 4139, Loss: 0.0005265793313355971, Final Batch Loss: 3.5289288007334108e-06\n",
      "Epoch 4140, Loss: 0.00026504933384785545, Final Batch Loss: 3.6706005630549043e-05\n",
      "Epoch 4141, Loss: 0.00026671017940316233, Final Batch Loss: 4.352146333985729e-06\n",
      "Epoch 4142, Loss: 0.0018377769411017653, Final Batch Loss: 1.6011916159186512e-05\n",
      "Epoch 4143, Loss: 0.0001148512324107287, Final Batch Loss: 1.4857741916785017e-05\n",
      "Epoch 4144, Loss: 0.0003861136876821547, Final Batch Loss: 1.4716170881001744e-05\n",
      "Epoch 4145, Loss: 0.000586139906772587, Final Batch Loss: 0.0003950898826587945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4146, Loss: 0.0003226951066608308, Final Batch Loss: 1.8952401660499163e-05\n",
      "Epoch 4147, Loss: 0.0002109684891138386, Final Batch Loss: 3.970273246522993e-05\n",
      "Epoch 4148, Loss: 0.00014023260928297532, Final Batch Loss: 1.2049929864588194e-05\n",
      "Epoch 4149, Loss: 0.0042990876825115265, Final Batch Loss: 2.2113524664746365e-06\n",
      "Epoch 4150, Loss: 0.0006573962687070889, Final Batch Loss: 0.00056605035206303\n",
      "Epoch 4151, Loss: 0.0019905439709759776, Final Batch Loss: 9.010915960061538e-07\n",
      "Epoch 4152, Loss: 0.0008783557559581823, Final Batch Loss: 7.57423276809277e-06\n",
      "Epoch 4153, Loss: 0.00039656950838207194, Final Batch Loss: 8.719850370653148e-07\n",
      "Epoch 4154, Loss: 4.626688428288617e-05, Final Batch Loss: 2.2396025087800808e-05\n",
      "Epoch 4155, Loss: 6.396350204340706e-05, Final Batch Loss: 2.4843997380230576e-05\n",
      "Epoch 4156, Loss: 0.008135828269473677, Final Batch Loss: 0.008114236406981945\n",
      "Epoch 4157, Loss: 0.00015903476867151767, Final Batch Loss: 1.4229616454031202e-06\n",
      "Epoch 4158, Loss: 0.0011383128330635373, Final Batch Loss: 1.916210567287635e-05\n",
      "Epoch 4159, Loss: 0.0007454458054780844, Final Batch Loss: 1.3350264453038108e-05\n",
      "Epoch 4160, Loss: 4.6316701627802104e-05, Final Batch Loss: 3.1458994271815754e-06\n",
      "Epoch 4161, Loss: 0.00020124775164731545, Final Batch Loss: 7.864237886678893e-06\n",
      "Epoch 4162, Loss: 7.06812508042276e-05, Final Batch Loss: 1.5112266282812925e-07\n",
      "Epoch 4163, Loss: 3.9650918552069925e-05, Final Batch Loss: 1.5279738363460638e-05\n",
      "Epoch 4164, Loss: 4.577908771352668e-05, Final Batch Loss: 1.1158632332808338e-05\n",
      "Epoch 4165, Loss: 2.8341469942461117e-05, Final Batch Loss: 5.899168172618374e-06\n",
      "Epoch 4166, Loss: 0.00015971590028129867, Final Batch Loss: 4.19438174503739e-06\n",
      "Epoch 4167, Loss: 0.00047170159567144765, Final Batch Loss: 0.00014911215112078935\n",
      "Epoch 4168, Loss: 9.721248619598555e-05, Final Batch Loss: 6.0174956161063164e-05\n",
      "Epoch 4169, Loss: 5.0710959840216674e-05, Final Batch Loss: 4.281813289708225e-06\n",
      "Epoch 4170, Loss: 0.0014205592519829224, Final Batch Loss: 4.3800059756904375e-06\n",
      "Epoch 4171, Loss: 8.130348032864276e-05, Final Batch Loss: 6.0122893046354875e-05\n",
      "Epoch 4172, Loss: 9.670928557170555e-05, Final Batch Loss: 6.040917469363194e-06\n",
      "Epoch 4173, Loss: 0.002294442100833294, Final Batch Loss: 1.7092216921810177e-06\n",
      "Epoch 4174, Loss: 6.642759240094165e-05, Final Batch Loss: 3.304710162410629e-06\n",
      "Epoch 4175, Loss: 0.00817204562167717, Final Batch Loss: 8.21509092929773e-06\n",
      "Epoch 4176, Loss: 0.04787198984558927, Final Batch Loss: 0.04724736884236336\n",
      "Epoch 4177, Loss: 3.0243208129832055e-05, Final Batch Loss: 4.780707058671396e-06\n",
      "Epoch 4178, Loss: 0.050380818790472404, Final Batch Loss: 1.0719933015934657e-05\n",
      "Epoch 4179, Loss: 0.00672081223456189, Final Batch Loss: 0.00019502974464558065\n",
      "Epoch 4180, Loss: 0.09528188152762596, Final Batch Loss: 0.043930549174547195\n",
      "Epoch 4181, Loss: 0.010948374466806854, Final Batch Loss: 3.247728272981476e-07\n",
      "Epoch 4182, Loss: 0.03624774624017846, Final Batch Loss: 1.918553380164667e-06\n",
      "Epoch 4183, Loss: 0.11486488234368153, Final Batch Loss: 0.074728824198246\n",
      "Epoch 4184, Loss: 0.0007960777329572011, Final Batch Loss: 6.389915506588295e-05\n",
      "Epoch 4185, Loss: 0.03548817173577845, Final Batch Loss: 0.014969035983085632\n",
      "Epoch 4186, Loss: 0.0022658591960862395, Final Batch Loss: 1.3585701708507258e-05\n",
      "Epoch 4187, Loss: 0.0005068514401500579, Final Batch Loss: 0.00011814853496616706\n",
      "Epoch 4188, Loss: 0.000975006703811232, Final Batch Loss: 0.0002859178639482707\n",
      "Epoch 4189, Loss: 0.0015018230787973152, Final Batch Loss: 1.6668580428813584e-05\n",
      "Epoch 4190, Loss: 0.0028770874196197838, Final Batch Loss: 0.001296305563300848\n",
      "Epoch 4191, Loss: 0.0015807414602022618, Final Batch Loss: 0.00011479102249722928\n",
      "Epoch 4192, Loss: 0.0037123356596566737, Final Batch Loss: 0.0015572005650028586\n",
      "Epoch 4193, Loss: 0.0008269553618447389, Final Batch Loss: 1.6035213775467128e-05\n",
      "Epoch 4194, Loss: 0.0006489781517302617, Final Batch Loss: 0.00011388826533220708\n",
      "Epoch 4195, Loss: 0.0011496618526507518, Final Batch Loss: 7.504560016968753e-06\n",
      "Epoch 4196, Loss: 0.009731161691888701, Final Batch Loss: 0.00019175211491528898\n",
      "Epoch 4197, Loss: 0.001247715023055207, Final Batch Loss: 7.115344487829134e-05\n",
      "Epoch 4198, Loss: 0.0011569169291760772, Final Batch Loss: 0.0001371685357298702\n",
      "Epoch 4199, Loss: 0.0004922549269394949, Final Batch Loss: 5.383660754887387e-05\n",
      "Epoch 4200, Loss: 0.00030559008882846683, Final Batch Loss: 3.3114156394731253e-06\n",
      "Epoch 4201, Loss: 0.0010942666348228158, Final Batch Loss: 1.6510101659150678e-06\n",
      "Epoch 4202, Loss: 0.00023679192145209527, Final Batch Loss: 6.260357622522861e-06\n",
      "Epoch 4203, Loss: 0.00142207060457622, Final Batch Loss: 3.334765324325417e-06\n",
      "Epoch 4204, Loss: 0.0011344924132572487, Final Batch Loss: 8.855956548359245e-05\n",
      "Epoch 4205, Loss: 0.006724800325173419, Final Batch Loss: 0.00032355630537495017\n",
      "Epoch 4206, Loss: 0.00045702371426159516, Final Batch Loss: 4.2632866097847e-05\n",
      "Epoch 4207, Loss: 0.00046033079524931964, Final Batch Loss: 1.3554161341744475e-05\n",
      "Epoch 4208, Loss: 0.0010323066762794042, Final Batch Loss: 0.0005855521885678172\n",
      "Epoch 4209, Loss: 0.0013423124237306183, Final Batch Loss: 2.8888482120237313e-05\n",
      "Epoch 4210, Loss: 0.011613675276748836, Final Batch Loss: 0.01042347401380539\n",
      "Epoch 4211, Loss: 0.00019787131532211788, Final Batch Loss: 6.53871611575596e-05\n",
      "Epoch 4212, Loss: 0.001016124828311149, Final Batch Loss: 0.0007000453188084066\n",
      "Epoch 4213, Loss: 0.000271543838607613, Final Batch Loss: 1.4697174265165813e-05\n",
      "Epoch 4214, Loss: 0.024903049428758095, Final Batch Loss: 4.173188062850386e-05\n",
      "Epoch 4215, Loss: 0.001073343860298337, Final Batch Loss: 4.92921972181648e-05\n",
      "Epoch 4216, Loss: 0.000390776895073941, Final Batch Loss: 0.00015679598436690867\n",
      "Epoch 4217, Loss: 0.0004575967868731823, Final Batch Loss: 0.00027509842766448855\n",
      "Epoch 4218, Loss: 0.000587149741477333, Final Batch Loss: 8.077590609900653e-05\n",
      "Epoch 4219, Loss: 0.002270036562549649, Final Batch Loss: 0.001972627593204379\n",
      "Epoch 4220, Loss: 0.0008236498788392055, Final Batch Loss: 1.3589068657893222e-05\n",
      "Epoch 4221, Loss: 0.0007148071235860698, Final Batch Loss: 0.0003902350727003068\n",
      "Epoch 4222, Loss: 0.00037882509423070587, Final Batch Loss: 3.0808067094767466e-05\n",
      "Epoch 4223, Loss: 0.0002850186465366278, Final Batch Loss: 0.00010586099961074069\n",
      "Epoch 4224, Loss: 0.00024027961671890807, Final Batch Loss: 6.943426797079155e-06\n",
      "Epoch 4225, Loss: 0.0008354122737728176, Final Batch Loss: 0.0006148272659629583\n",
      "Epoch 4226, Loss: 0.00028506664239102975, Final Batch Loss: 2.2671749320579693e-05\n",
      "Epoch 4227, Loss: 0.00023952798437676392, Final Batch Loss: 3.70539964933414e-05\n",
      "Epoch 4228, Loss: 0.00013191232574172318, Final Batch Loss: 1.2039645298500545e-05\n",
      "Epoch 4229, Loss: 0.00014629090219386853, Final Batch Loss: 3.0575753044104204e-05\n",
      "Epoch 4230, Loss: 0.0005410772500908934, Final Batch Loss: 0.00011949716281378642\n",
      "Epoch 4231, Loss: 0.006676987562968861, Final Batch Loss: 0.00029973190976306796\n",
      "Epoch 4232, Loss: 0.0005239841684669955, Final Batch Loss: 2.083579784084577e-05\n",
      "Epoch 4233, Loss: 0.0004636619742086623, Final Batch Loss: 6.351907359203324e-05\n",
      "Epoch 4234, Loss: 0.0007057736511342227, Final Batch Loss: 0.00011709691898431629\n",
      "Epoch 4235, Loss: 0.0007232930674945237, Final Batch Loss: 2.436831891827751e-05\n",
      "Epoch 4236, Loss: 0.008648639546663617, Final Batch Loss: 0.0004485995741561055\n",
      "Epoch 4237, Loss: 0.0005038871204305906, Final Batch Loss: 3.018505231011659e-05\n",
      "Epoch 4238, Loss: 0.0006767605555069167, Final Batch Loss: 5.622638127533719e-06\n",
      "Epoch 4239, Loss: 0.004786392211826751, Final Batch Loss: 0.004657731391489506\n",
      "Epoch 4240, Loss: 0.0004759670118801296, Final Batch Loss: 0.00015987339429557323\n",
      "Epoch 4241, Loss: 0.00029080695458105765, Final Batch Loss: 2.184214099543169e-05\n",
      "Epoch 4242, Loss: 0.0007463865856607299, Final Batch Loss: 2.851533054126776e-06\n",
      "Epoch 4243, Loss: 0.003997066305032604, Final Batch Loss: 6.429721679523936e-07\n",
      "Epoch 4244, Loss: 0.027038021509724786, Final Batch Loss: 0.02628747560083866\n",
      "Epoch 4245, Loss: 0.0005003656951885205, Final Batch Loss: 5.335032255970873e-05\n",
      "Epoch 4246, Loss: 0.004647869205655297, Final Batch Loss: 0.0029168622568249702\n",
      "Epoch 4247, Loss: 0.0018823134014382958, Final Batch Loss: 0.0012080667074769735\n",
      "Epoch 4248, Loss: 0.0325856464833123, Final Batch Loss: 9.99035455606645e-06\n",
      "Epoch 4249, Loss: 0.019918827155379404, Final Batch Loss: 1.1680772331601474e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4250, Loss: 0.002051876579571399, Final Batch Loss: 7.26495636627078e-05\n",
      "Epoch 4251, Loss: 0.00022371917930286145, Final Batch Loss: 1.3794599908578675e-05\n",
      "Epoch 4252, Loss: 0.009812452117330395, Final Batch Loss: 0.006283581722527742\n",
      "Epoch 4253, Loss: 0.010038974873168627, Final Batch Loss: 0.009194763377308846\n",
      "Epoch 4254, Loss: 0.0006826777243986726, Final Batch Loss: 8.738975157029927e-05\n",
      "Epoch 4255, Loss: 0.0016592664433119353, Final Batch Loss: 5.248543675406836e-05\n",
      "Epoch 4256, Loss: 0.0005509502212817097, Final Batch Loss: 1.1038415550501668e-06\n",
      "Epoch 4257, Loss: 0.0007624685968039557, Final Batch Loss: 1.068576966645196e-05\n",
      "Epoch 4258, Loss: 0.0021750443847849965, Final Batch Loss: 3.8930003938730806e-05\n",
      "Epoch 4259, Loss: 0.0014276326310209697, Final Batch Loss: 0.0002937949320767075\n",
      "Epoch 4260, Loss: 9.869045879895566e-05, Final Batch Loss: 1.8554517737356946e-05\n",
      "Epoch 4261, Loss: 0.0010070391053886851, Final Batch Loss: 2.9924185582785867e-05\n",
      "Epoch 4262, Loss: 0.001699129250482656, Final Batch Loss: 4.372447438072413e-05\n",
      "Epoch 4263, Loss: 0.00015902713676041458, Final Batch Loss: 1.8491706214263104e-05\n",
      "Epoch 4264, Loss: 0.00021923677559243515, Final Batch Loss: 2.9879363864893094e-05\n",
      "Epoch 4265, Loss: 0.0012398526559991296, Final Batch Loss: 3.8522437534993514e-05\n",
      "Epoch 4266, Loss: 0.0005653612752212211, Final Batch Loss: 8.329033153131604e-05\n",
      "Epoch 4267, Loss: 0.00016123829936987022, Final Batch Loss: 8.3271124822204e-06\n",
      "Epoch 4268, Loss: 0.00013719281105295522, Final Batch Loss: 4.803388947038911e-05\n",
      "Epoch 4269, Loss: 0.0003824321411229903, Final Batch Loss: 2.620145278342534e-05\n",
      "Epoch 4270, Loss: 0.001455329583677667, Final Batch Loss: 1.5215223356790375e-06\n",
      "Epoch 4271, Loss: 0.0008958974244706042, Final Batch Loss: 3.2999037102854345e-06\n",
      "Epoch 4272, Loss: 0.000507670411025174, Final Batch Loss: 0.000190687263966538\n",
      "Epoch 4273, Loss: 0.00023118784702091943, Final Batch Loss: 4.0793784137349576e-05\n",
      "Epoch 4274, Loss: 0.0003926289937226102, Final Batch Loss: 9.072704415302724e-05\n",
      "Epoch 4275, Loss: 5.51849652765668e-05, Final Batch Loss: 4.986630301573314e-06\n",
      "Epoch 4276, Loss: 0.00015109337437024806, Final Batch Loss: 5.700394103769213e-05\n",
      "Epoch 4277, Loss: 0.0006405682702279591, Final Batch Loss: 7.129082860046765e-06\n",
      "Epoch 4278, Loss: 0.0009692989842733368, Final Batch Loss: 3.6852223274763674e-05\n",
      "Epoch 4279, Loss: 0.0003501238643366378, Final Batch Loss: 0.0002390720328548923\n",
      "Epoch 4280, Loss: 0.0001972153631868423, Final Batch Loss: 1.5083968719409313e-05\n",
      "Epoch 4281, Loss: 0.0011100728952442296, Final Batch Loss: 0.0009760743705555797\n",
      "Epoch 4282, Loss: 0.0005516415835700172, Final Batch Loss: 0.000283997185761109\n",
      "Epoch 4283, Loss: 0.0011158421211803216, Final Batch Loss: 1.4685488167742733e-05\n",
      "Epoch 4284, Loss: 0.0011998549653071677, Final Batch Loss: 0.00021214343723841012\n",
      "Epoch 4285, Loss: 6.045824937928046e-05, Final Batch Loss: 8.776225399742543e-07\n",
      "Epoch 4286, Loss: 0.00023910647848879307, Final Batch Loss: 5.218875003265566e-07\n",
      "Epoch 4287, Loss: 0.00027867474636877887, Final Batch Loss: 7.17782968422398e-05\n",
      "Epoch 4288, Loss: 0.00019842204164888244, Final Batch Loss: 4.4487933337222785e-06\n",
      "Epoch 4289, Loss: 0.0002809805027936818, Final Batch Loss: 0.0001233428920386359\n",
      "Epoch 4290, Loss: 0.0006036263221176341, Final Batch Loss: 2.139751632057596e-05\n",
      "Epoch 4291, Loss: 0.0002951744645542931, Final Batch Loss: 5.215856435825117e-05\n",
      "Epoch 4292, Loss: 0.0008939696399465902, Final Batch Loss: 0.000572194519918412\n",
      "Epoch 4293, Loss: 0.0001630876098488443, Final Batch Loss: 1.6491597989443108e-06\n",
      "Epoch 4294, Loss: 0.00046560502914871904, Final Batch Loss: 5.084210442873882e-06\n",
      "Epoch 4295, Loss: 0.0015202770846372005, Final Batch Loss: 0.0011942159617319703\n",
      "Epoch 4296, Loss: 0.00019616379722720012, Final Batch Loss: 1.4604087482439354e-05\n",
      "Epoch 4297, Loss: 0.0003007963277923409, Final Batch Loss: 4.962524326401763e-05\n",
      "Epoch 4298, Loss: 0.00036197787812852766, Final Batch Loss: 0.00019143280223943293\n",
      "Epoch 4299, Loss: 0.0004678248069467372, Final Batch Loss: 1.4308942809293512e-05\n",
      "Epoch 4300, Loss: 0.00308577183500347, Final Batch Loss: 2.426203764116508e-06\n",
      "Epoch 4301, Loss: 0.00017806762025429634, Final Batch Loss: 0.00011118641850771382\n",
      "Epoch 4302, Loss: 0.0005259099016257096, Final Batch Loss: 1.0436542652314529e-05\n",
      "Epoch 4303, Loss: 0.00018033887772617163, Final Batch Loss: 0.00011844652908621356\n",
      "Epoch 4304, Loss: 0.00041003954942198106, Final Batch Loss: 0.00024019813281483948\n",
      "Epoch 4305, Loss: 0.0003211364428352681, Final Batch Loss: 1.2236062502779532e-05\n",
      "Epoch 4306, Loss: 6.746888220732217e-05, Final Batch Loss: 2.1133397240191698e-05\n",
      "Epoch 4307, Loss: 0.00029888409699196927, Final Batch Loss: 7.738611020613462e-05\n",
      "Epoch 4308, Loss: 0.00015427033395098988, Final Batch Loss: 2.957194192276802e-05\n",
      "Epoch 4309, Loss: 0.0008178565858543152, Final Batch Loss: 1.3286922694533132e-05\n",
      "Epoch 4310, Loss: 0.0011917344218090875, Final Batch Loss: 0.00017292756820097566\n",
      "Epoch 4311, Loss: 0.00010381773063272703, Final Batch Loss: 5.204088665777817e-06\n",
      "Epoch 4312, Loss: 0.0006348473434627522, Final Batch Loss: 0.00035028616548515856\n",
      "Epoch 4313, Loss: 0.00013501749617716996, Final Batch Loss: 1.8203287254436873e-05\n",
      "Epoch 4314, Loss: 0.00011418527628848096, Final Batch Loss: 7.754914804536384e-06\n",
      "Epoch 4315, Loss: 0.00015081018909768318, Final Batch Loss: 2.5351241674798075e-06\n",
      "Epoch 4316, Loss: 0.0005569378909058287, Final Batch Loss: 0.0004830296093132347\n",
      "Epoch 4317, Loss: 0.0003368338002474047, Final Batch Loss: 0.00018295540940016508\n",
      "Epoch 4318, Loss: 9.584224108039052e-05, Final Batch Loss: 3.870442469633417e-06\n",
      "Epoch 4319, Loss: 0.0004202884647384053, Final Batch Loss: 1.4560144336428493e-05\n",
      "Epoch 4320, Loss: 0.00074430105587453, Final Batch Loss: 0.0006321491673588753\n",
      "Epoch 4321, Loss: 0.00011531341033332865, Final Batch Loss: 4.121889651287347e-05\n",
      "Epoch 4322, Loss: 0.00016749522683312534, Final Batch Loss: 1.9547029296518303e-05\n",
      "Epoch 4323, Loss: 0.0001896866835977562, Final Batch Loss: 1.4989652754593408e-06\n",
      "Epoch 4324, Loss: 0.00025735491576028835, Final Batch Loss: 2.046257066012913e-07\n",
      "Epoch 4325, Loss: 0.000533082783476857, Final Batch Loss: 0.0001795479329302907\n",
      "Epoch 4326, Loss: 6.537103058690263e-05, Final Batch Loss: 2.3953455183800543e-06\n",
      "Epoch 4327, Loss: 0.00028093316814192804, Final Batch Loss: 0.0001977639039978385\n",
      "Epoch 4328, Loss: 8.563706421682582e-05, Final Batch Loss: 1.7786686612453195e-06\n",
      "Epoch 4329, Loss: 0.00011392036049073795, Final Batch Loss: 9.429616511624772e-06\n",
      "Epoch 4330, Loss: 0.00026886473369813757, Final Batch Loss: 0.0001489128335379064\n",
      "Epoch 4331, Loss: 0.00047707081603221013, Final Batch Loss: 6.61443345961743e-06\n",
      "Epoch 4332, Loss: 0.00016329539903381374, Final Batch Loss: 2.2714082660968415e-05\n",
      "Epoch 4333, Loss: 0.00011435537635406945, Final Batch Loss: 2.843038055289071e-05\n",
      "Epoch 4334, Loss: 0.00024235779164882842, Final Batch Loss: 3.6837947845924646e-05\n",
      "Epoch 4335, Loss: 0.0002798507803163375, Final Batch Loss: 0.0002253705752082169\n",
      "Epoch 4336, Loss: 0.0029529006978918915, Final Batch Loss: 2.4224236767622642e-05\n",
      "Epoch 4337, Loss: 0.0003168337516399333, Final Batch Loss: 3.872192246490158e-05\n",
      "Epoch 4338, Loss: 0.00033046752605514484, Final Batch Loss: 4.927041572955204e-06\n",
      "Epoch 4339, Loss: 0.0001990658793147304, Final Batch Loss: 9.771542863745708e-06\n",
      "Epoch 4340, Loss: 0.0007117824925444438, Final Batch Loss: 7.878724318288732e-06\n",
      "Epoch 4341, Loss: 0.0016143307587981326, Final Batch Loss: 1.1958221648455947e-06\n",
      "Epoch 4342, Loss: 0.00035588642640504986, Final Batch Loss: 0.0002026404981734231\n",
      "Epoch 4343, Loss: 0.021793650845211232, Final Batch Loss: 2.2204498236533254e-05\n",
      "Epoch 4344, Loss: 5.631253111459955e-05, Final Batch Loss: 1.2098837487428682e-06\n",
      "Epoch 4345, Loss: 0.00012915751676700893, Final Batch Loss: 5.224682900006883e-05\n",
      "Epoch 4346, Loss: 0.0054992483819660265, Final Batch Loss: 0.00013344072795007378\n",
      "Epoch 4347, Loss: 0.0007628988792021119, Final Batch Loss: 0.00021346088033169508\n",
      "Epoch 4348, Loss: 0.00025487270340818213, Final Batch Loss: 2.115433380822651e-05\n",
      "Epoch 4349, Loss: 0.0007834387190541747, Final Batch Loss: 6.829922494944185e-05\n",
      "Epoch 4350, Loss: 0.00016908746556509868, Final Batch Loss: 4.055349563714117e-05\n",
      "Epoch 4351, Loss: 0.002841505290234636, Final Batch Loss: 6.985565960349049e-06\n",
      "Epoch 4352, Loss: 0.0002889395373131265, Final Batch Loss: 1.3257021237222943e-05\n",
      "Epoch 4353, Loss: 0.0002547242902437574, Final Batch Loss: 9.166787094727624e-06\n",
      "Epoch 4354, Loss: 0.00010947007922368357, Final Batch Loss: 2.4423423383268528e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4355, Loss: 0.00017474750166002195, Final Batch Loss: 2.8922007913934067e-05\n",
      "Epoch 4356, Loss: 0.0010614635393721983, Final Batch Loss: 4.726854967884719e-06\n",
      "Epoch 4357, Loss: 0.0002066829631530709, Final Batch Loss: 4.527701094048098e-06\n",
      "Epoch 4358, Loss: 0.0004236351051076781, Final Batch Loss: 3.0091505323071033e-06\n",
      "Epoch 4359, Loss: 0.0002972902639157837, Final Batch Loss: 1.64921202667756e-05\n",
      "Epoch 4360, Loss: 0.00031046073218021775, Final Batch Loss: 5.8951500250259414e-06\n",
      "Epoch 4361, Loss: 0.00021734514825766382, Final Batch Loss: 2.80076960734732e-06\n",
      "Epoch 4362, Loss: 0.017251966934054508, Final Batch Loss: 7.0874530138098635e-06\n",
      "Epoch 4363, Loss: 0.0022042584996597725, Final Batch Loss: 3.3732500014593825e-05\n",
      "Epoch 4364, Loss: 0.00010680426885301131, Final Batch Loss: 2.5482981982349884e-06\n",
      "Epoch 4365, Loss: 0.00027499864063429413, Final Batch Loss: 0.00024814571952447295\n",
      "Epoch 4366, Loss: 0.006893623805808602, Final Batch Loss: 1.979008811758831e-05\n",
      "Epoch 4367, Loss: 0.0002957378769679053, Final Batch Loss: 1.6425588000856806e-06\n",
      "Epoch 4368, Loss: 0.00014837469871054054, Final Batch Loss: 4.075191463925876e-05\n",
      "Epoch 4369, Loss: 0.0007907567578513408, Final Batch Loss: 0.00025717815151438117\n",
      "Epoch 4370, Loss: 0.0006793949287384748, Final Batch Loss: 1.573064218973741e-05\n",
      "Epoch 4371, Loss: 0.00020946476797689684, Final Batch Loss: 3.619271592469886e-05\n",
      "Epoch 4372, Loss: 0.0002495711523806676, Final Batch Loss: 2.4373999622184783e-05\n",
      "Epoch 4373, Loss: 0.00044910186625202186, Final Batch Loss: 7.07163562765345e-05\n",
      "Epoch 4374, Loss: 0.0002054605083685601, Final Batch Loss: 6.732361362082884e-05\n",
      "Epoch 4375, Loss: 0.001151642235527106, Final Batch Loss: 0.00031931587727740407\n",
      "Epoch 4376, Loss: 0.0008277523547803867, Final Batch Loss: 6.445411599997897e-06\n",
      "Epoch 4377, Loss: 0.00017340801969112363, Final Batch Loss: 2.3672009774600156e-06\n",
      "Epoch 4378, Loss: 0.0002034283461398445, Final Batch Loss: 3.735698919626884e-05\n",
      "Epoch 4379, Loss: 0.0007712324004387483, Final Batch Loss: 0.0006582344067282975\n",
      "Epoch 4380, Loss: 0.0008141838843584992, Final Batch Loss: 5.436270294012502e-05\n",
      "Epoch 4381, Loss: 0.00020594780562532833, Final Batch Loss: 8.465366590826306e-06\n",
      "Epoch 4382, Loss: 0.0025824801759881666, Final Batch Loss: 1.832145244407002e-05\n",
      "Epoch 4383, Loss: 0.00011390272811695468, Final Batch Loss: 1.662239810684696e-05\n",
      "Epoch 4384, Loss: 0.0002210381195482114, Final Batch Loss: 3.6254179576644674e-05\n",
      "Epoch 4385, Loss: 0.00018485319435512793, Final Batch Loss: 1.4717339809067198e-06\n",
      "Epoch 4386, Loss: 0.000841621288600436, Final Batch Loss: 3.359978109074291e-06\n",
      "Epoch 4387, Loss: 0.0016616805000921886, Final Batch Loss: 0.0015973647823557258\n",
      "Epoch 4388, Loss: 7.111400805115409e-05, Final Batch Loss: 9.64930904956418e-07\n",
      "Epoch 4389, Loss: 0.00029898340625322817, Final Batch Loss: 5.716307782677177e-07\n",
      "Epoch 4390, Loss: 7.958722380863037e-05, Final Batch Loss: 1.6682237401255406e-05\n",
      "Epoch 4391, Loss: 0.00012081355797022297, Final Batch Loss: 3.003677022661577e-07\n",
      "Epoch 4392, Loss: 0.00013654241274707601, Final Batch Loss: 1.6645002688164823e-05\n",
      "Epoch 4393, Loss: 0.009925228357815286, Final Batch Loss: 3.115082336080377e-06\n",
      "Epoch 4394, Loss: 0.0003165106199958245, Final Batch Loss: 7.5161178756388836e-06\n",
      "Epoch 4395, Loss: 0.005827950843922736, Final Batch Loss: 4.80032067571301e-05\n",
      "Epoch 4396, Loss: 0.0014010425211381516, Final Batch Loss: 0.0012167838867753744\n",
      "Epoch 4397, Loss: 0.013347561882255832, Final Batch Loss: 0.012815220281481743\n",
      "Epoch 4398, Loss: 0.0006339159708659281, Final Batch Loss: 1.7179616406792775e-05\n",
      "Epoch 4399, Loss: 0.030827478378341766, Final Batch Loss: 0.00011360613279975951\n",
      "Epoch 4400, Loss: 0.07444487824250245, Final Batch Loss: 9.633379522711039e-05\n",
      "Epoch 4401, Loss: 0.034988741433153336, Final Batch Loss: 0.0023449368309229612\n",
      "Epoch 4402, Loss: 0.03067758360521111, Final Batch Loss: 1.2054761100444011e-05\n",
      "Epoch 4403, Loss: 0.014981951782829128, Final Batch Loss: 4.354228440206498e-05\n",
      "Epoch 4404, Loss: 0.03660132498589519, Final Batch Loss: 3.0373497793334536e-05\n",
      "Epoch 4405, Loss: 0.01522076462424593, Final Batch Loss: 6.815790402470157e-05\n",
      "Epoch 4406, Loss: 0.01588314236505539, Final Batch Loss: 0.00021457826369442046\n",
      "Epoch 4407, Loss: 0.0019216924483771436, Final Batch Loss: 0.00012810123735107481\n",
      "Epoch 4408, Loss: 0.002741676213190658, Final Batch Loss: 0.0011986182071268559\n",
      "Epoch 4409, Loss: 0.003368575169588439, Final Batch Loss: 0.0003327307931613177\n",
      "Epoch 4410, Loss: 0.0009466992341913283, Final Batch Loss: 6.995366129558533e-05\n",
      "Epoch 4411, Loss: 0.004464754951186478, Final Batch Loss: 0.0003013307577930391\n",
      "Epoch 4412, Loss: 0.005169241212570341, Final Batch Loss: 6.078403748688288e-05\n",
      "Epoch 4413, Loss: 0.0023470701125916094, Final Batch Loss: 0.0008343445369973779\n",
      "Epoch 4414, Loss: 0.0007004993531154469, Final Batch Loss: 9.429919009562582e-05\n",
      "Epoch 4415, Loss: 0.0012409049741108902, Final Batch Loss: 3.6909063055645674e-05\n",
      "Epoch 4416, Loss: 0.0018052896339213476, Final Batch Loss: 0.0010671892669051886\n",
      "Epoch 4417, Loss: 0.002351531045860611, Final Batch Loss: 0.0015653554582968354\n",
      "Epoch 4418, Loss: 0.0013022532657487318, Final Batch Loss: 0.0004745303303934634\n",
      "Epoch 4419, Loss: 0.0015302272295230068, Final Batch Loss: 0.00013537719496525824\n",
      "Epoch 4420, Loss: 0.001049523925757967, Final Batch Loss: 7.308173371711746e-05\n",
      "Epoch 4421, Loss: 0.0012845544042647816, Final Batch Loss: 0.00043881009332835674\n",
      "Epoch 4422, Loss: 0.0010025675910583232, Final Batch Loss: 8.957088721217588e-05\n",
      "Epoch 4423, Loss: 0.0010872156417462975, Final Batch Loss: 8.145991887431592e-05\n",
      "Epoch 4424, Loss: 0.00048436937686346937, Final Batch Loss: 3.962242408306338e-05\n",
      "Epoch 4425, Loss: 0.0020675757023127517, Final Batch Loss: 0.00013491668505594134\n",
      "Epoch 4426, Loss: 0.0012410709168761969, Final Batch Loss: 0.00040617058402858675\n",
      "Epoch 4427, Loss: 0.0008586574131186353, Final Batch Loss: 2.1248089979053475e-05\n",
      "Epoch 4428, Loss: 0.0019057807548961136, Final Batch Loss: 5.7499692047713324e-05\n",
      "Epoch 4429, Loss: 0.0015890450995357241, Final Batch Loss: 0.00028497891617007554\n",
      "Epoch 4430, Loss: 0.0013002417390453047, Final Batch Loss: 8.78159607964335e-06\n",
      "Epoch 4431, Loss: 0.0007726873087676722, Final Batch Loss: 1.4511266499539488e-06\n",
      "Epoch 4432, Loss: 0.0016060831767390482, Final Batch Loss: 0.0008739354088902473\n",
      "Epoch 4433, Loss: 0.00030350852830451913, Final Batch Loss: 2.7039026463171467e-05\n",
      "Epoch 4434, Loss: 0.0006081715850996261, Final Batch Loss: 6.80182847645483e-06\n",
      "Epoch 4435, Loss: 0.0009409214144397993, Final Batch Loss: 4.6010442019905895e-05\n",
      "Epoch 4436, Loss: 0.0005293969261401799, Final Batch Loss: 0.00013595717609860003\n",
      "Epoch 4437, Loss: 0.00026654334487830056, Final Batch Loss: 1.847224666562397e-06\n",
      "Epoch 4438, Loss: 0.0008635778631287394, Final Batch Loss: 5.715465158573352e-05\n",
      "Epoch 4439, Loss: 0.0001762362467161438, Final Batch Loss: 6.188009592733579e-06\n",
      "Epoch 4440, Loss: 0.00046902110989321955, Final Batch Loss: 3.1671141186961904e-05\n",
      "Epoch 4441, Loss: 0.0002212542358392966, Final Batch Loss: 5.75581088924082e-06\n",
      "Epoch 4442, Loss: 0.000754858795517066, Final Batch Loss: 2.738880539254751e-06\n",
      "Epoch 4443, Loss: 0.0005280375571601326, Final Batch Loss: 5.2406834583962336e-05\n",
      "Epoch 4444, Loss: 0.000910104217382468, Final Batch Loss: 6.774754638172453e-06\n",
      "Epoch 4445, Loss: 0.0004373510291770799, Final Batch Loss: 3.104090137640014e-05\n",
      "Epoch 4446, Loss: 0.0011546629048098112, Final Batch Loss: 0.00016823149053379893\n",
      "Epoch 4447, Loss: 0.0010485367456567474, Final Batch Loss: 0.0002223687624791637\n",
      "Epoch 4448, Loss: 0.0008612447090854403, Final Batch Loss: 3.55618103640154e-05\n",
      "Epoch 4449, Loss: 0.0002391788884779089, Final Batch Loss: 4.685295607487205e-06\n",
      "Epoch 4450, Loss: 0.0016202880469791126, Final Batch Loss: 0.0009075362468138337\n",
      "Epoch 4451, Loss: 0.00016257867264357628, Final Batch Loss: 1.32261166072567e-05\n",
      "Epoch 4452, Loss: 0.000638865378277842, Final Batch Loss: 0.00032026239205151796\n",
      "Epoch 4453, Loss: 0.001015356472635176, Final Batch Loss: 3.859631033265032e-05\n",
      "Epoch 4454, Loss: 0.0002991604401358927, Final Batch Loss: 4.810612608707743e-06\n",
      "Epoch 4455, Loss: 0.00025001382527989335, Final Batch Loss: 0.0001233021612279117\n",
      "Epoch 4456, Loss: 0.0008490464060741942, Final Batch Loss: 0.00040643996908329427\n",
      "Epoch 4457, Loss: 0.00038057534948165994, Final Batch Loss: 6.631218639086001e-06\n",
      "Epoch 4458, Loss: 0.00035809238943329547, Final Batch Loss: 8.489684842061251e-05\n",
      "Epoch 4459, Loss: 0.0004671243050324847, Final Batch Loss: 2.564395617810078e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4460, Loss: 0.00125057899094827, Final Batch Loss: 0.0008543010335415602\n",
      "Epoch 4461, Loss: 0.00024575061888754135, Final Batch Loss: 0.00010949232819257304\n",
      "Epoch 4462, Loss: 0.003095259351994173, Final Batch Loss: 0.002722075441852212\n",
      "Epoch 4463, Loss: 0.002937042347184615, Final Batch Loss: 2.6158704713452607e-06\n",
      "Epoch 4464, Loss: 0.0035076402515414884, Final Batch Loss: 1.6068612467279308e-06\n",
      "Epoch 4465, Loss: 0.0008443818442174233, Final Batch Loss: 0.0002682176709640771\n",
      "Epoch 4466, Loss: 0.0004271269745004247, Final Batch Loss: 1.4967450624681078e-05\n",
      "Epoch 4467, Loss: 0.0008899908498278819, Final Batch Loss: 2.1326828573364764e-05\n",
      "Epoch 4468, Loss: 0.0010689351402106695, Final Batch Loss: 0.0007631583721376956\n",
      "Epoch 4469, Loss: 0.00030197643354767933, Final Batch Loss: 4.088933201273903e-05\n",
      "Epoch 4470, Loss: 0.0004978982092325168, Final Batch Loss: 8.86952784640016e-06\n",
      "Epoch 4471, Loss: 0.0892831546434536, Final Batch Loss: 0.0010011729318648577\n",
      "Epoch 4472, Loss: 0.003156207167194225, Final Batch Loss: 4.7750407247804105e-05\n",
      "Epoch 4473, Loss: 0.002617345993712661, Final Batch Loss: 0.000450414459919557\n",
      "Epoch 4474, Loss: 0.00335358468873892, Final Batch Loss: 3.301461401861161e-05\n",
      "Epoch 4475, Loss: 0.0005031754044466652, Final Batch Loss: 4.857834574067965e-05\n",
      "Epoch 4476, Loss: 0.0007153515689424239, Final Batch Loss: 0.0004222966672386974\n",
      "Epoch 4477, Loss: 0.0007252466448335326, Final Batch Loss: 1.4476724572887179e-05\n",
      "Epoch 4478, Loss: 0.0003352783014634042, Final Batch Loss: 0.0002114217495545745\n",
      "Epoch 4479, Loss: 0.0009666938349255361, Final Batch Loss: 9.475807746639475e-05\n",
      "Epoch 4480, Loss: 0.0009558486945024924, Final Batch Loss: 8.303964932565577e-06\n",
      "Epoch 4481, Loss: 0.0007626367842021864, Final Batch Loss: 3.973109778598882e-05\n",
      "Epoch 4482, Loss: 0.00044091725794714876, Final Batch Loss: 4.31779189966619e-05\n",
      "Epoch 4483, Loss: 0.0011165147298015654, Final Batch Loss: 0.0007750314543955028\n",
      "Epoch 4484, Loss: 0.0004589503259921912, Final Batch Loss: 0.00011573700612643734\n",
      "Epoch 4485, Loss: 0.00028858068526460556, Final Batch Loss: 1.2192070244054776e-05\n",
      "Epoch 4486, Loss: 0.0017733196436893195, Final Batch Loss: 0.00021284697868395597\n",
      "Epoch 4487, Loss: 0.0007961202500155196, Final Batch Loss: 7.860562618589029e-06\n",
      "Epoch 4488, Loss: 0.0004741752018162515, Final Batch Loss: 4.17252340412233e-05\n",
      "Epoch 4489, Loss: 0.0010909389484368148, Final Batch Loss: 8.914351383282337e-06\n",
      "Epoch 4490, Loss: 0.00013526049770007376, Final Batch Loss: 7.924678357085213e-06\n",
      "Epoch 4491, Loss: 0.0002798441128106788, Final Batch Loss: 8.210456871893257e-05\n",
      "Epoch 4492, Loss: 0.0006250914884731174, Final Batch Loss: 0.0001255887618754059\n",
      "Epoch 4493, Loss: 0.0001573938343426562, Final Batch Loss: 6.008444870531093e-06\n",
      "Epoch 4494, Loss: 0.00010575900404319327, Final Batch Loss: 8.926469377001922e-07\n",
      "Epoch 4495, Loss: 0.001042244581185514, Final Batch Loss: 3.8485672121169046e-05\n",
      "Epoch 4496, Loss: 0.00014801753968640696, Final Batch Loss: 3.964499228459317e-06\n",
      "Epoch 4497, Loss: 0.0009811050695134327, Final Batch Loss: 0.0004557423817459494\n",
      "Epoch 4498, Loss: 0.003543498415638169, Final Batch Loss: 9.021492587635294e-06\n",
      "Epoch 4499, Loss: 0.0002724547612160677, Final Batch Loss: 5.887985389563255e-05\n",
      "Epoch 4500, Loss: 0.00031128301270655356, Final Batch Loss: 3.8066184060880914e-05\n",
      "Epoch 4501, Loss: 0.0007737103487670538, Final Batch Loss: 6.7764076447929256e-06\n",
      "Epoch 4502, Loss: 0.00014793951231695246, Final Batch Loss: 6.780609692214057e-05\n",
      "Epoch 4503, Loss: 0.0005803286030641175, Final Batch Loss: 2.5633771656430326e-06\n",
      "Epoch 4504, Loss: 0.0005013375875932979, Final Batch Loss: 4.402253580337856e-06\n",
      "Epoch 4505, Loss: 0.0009507846189080738, Final Batch Loss: 8.90972078195773e-05\n",
      "Epoch 4506, Loss: 0.0004266926198397414, Final Batch Loss: 0.00034110265551134944\n",
      "Epoch 4507, Loss: 0.0002476530798958265, Final Batch Loss: 0.0001438805047655478\n",
      "Epoch 4508, Loss: 0.00020562832287396304, Final Batch Loss: 1.7325295630143955e-05\n",
      "Epoch 4509, Loss: 0.0006749570329702692, Final Batch Loss: 5.225164568400942e-05\n",
      "Epoch 4510, Loss: 5.2017974439877435e-05, Final Batch Loss: 1.5331928807427175e-05\n",
      "Epoch 4511, Loss: 0.0002085159267153358, Final Batch Loss: 2.7946074624196626e-05\n",
      "Epoch 4512, Loss: 0.0002755326968326699, Final Batch Loss: 7.520972576458007e-05\n",
      "Epoch 4513, Loss: 0.0010941262053165701, Final Batch Loss: 3.192174517607782e-06\n",
      "Epoch 4514, Loss: 0.00012826667716581142, Final Batch Loss: 3.4883403714047745e-05\n",
      "Epoch 4515, Loss: 0.0002001706052396912, Final Batch Loss: 8.308092947117984e-05\n",
      "Epoch 4516, Loss: 0.00010452631249791011, Final Batch Loss: 1.4581069990526885e-05\n",
      "Epoch 4517, Loss: 0.00035163060238119215, Final Batch Loss: 6.704101542709395e-05\n",
      "Epoch 4518, Loss: 0.00014531453416566364, Final Batch Loss: 4.4209318730281666e-05\n",
      "Epoch 4519, Loss: 0.0007946052246552426, Final Batch Loss: 2.539183697081171e-05\n",
      "Epoch 4520, Loss: 0.00022063742312639079, Final Batch Loss: 3.010991576957167e-06\n",
      "Epoch 4521, Loss: 0.0017964255912374938, Final Batch Loss: 1.1141639333800413e-05\n",
      "Epoch 4522, Loss: 0.0004098811659787316, Final Batch Loss: 3.237592682125978e-05\n",
      "Epoch 4523, Loss: 0.00014598318034586555, Final Batch Loss: 3.809693453149521e-06\n",
      "Epoch 4524, Loss: 0.0001459155355405528, Final Batch Loss: 1.832189445849508e-05\n",
      "Epoch 4525, Loss: 0.0009698206426946854, Final Batch Loss: 0.00078022968955338\n",
      "Epoch 4526, Loss: 8.552819190299488e-05, Final Batch Loss: 2.599981144157937e-06\n",
      "Epoch 4527, Loss: 0.0005850820870136886, Final Batch Loss: 3.2946434203040553e-07\n",
      "Epoch 4528, Loss: 3.070027673857112e-05, Final Batch Loss: 1.924993512147921e-06\n",
      "Epoch 4529, Loss: 0.00020479097088355047, Final Batch Loss: 4.634235301637091e-05\n",
      "Epoch 4530, Loss: 0.0007988575580384349, Final Batch Loss: 1.7289412426180206e-05\n",
      "Epoch 4531, Loss: 0.0003064665872898331, Final Batch Loss: 4.186351816315437e-07\n",
      "Epoch 4532, Loss: 0.00022744031048205215, Final Batch Loss: 0.00013120575749780983\n",
      "Epoch 4533, Loss: 0.001665479171606421, Final Batch Loss: 0.0016248816391453147\n",
      "Epoch 4534, Loss: 0.0004724928720065691, Final Batch Loss: 5.19070738391747e-07\n",
      "Epoch 4535, Loss: 0.0001381006914016325, Final Batch Loss: 6.69286964694038e-06\n",
      "Epoch 4536, Loss: 3.9978863696887856e-05, Final Batch Loss: 8.935924597608391e-06\n",
      "Epoch 4537, Loss: 0.0019302466653243755, Final Batch Loss: 0.0018026666948571801\n",
      "Epoch 4538, Loss: 0.0004471992506296374, Final Batch Loss: 4.990559318684973e-05\n",
      "Epoch 4539, Loss: 0.000797238629502317, Final Batch Loss: 1.3187684544391232e-06\n",
      "Epoch 4540, Loss: 8.047644587350078e-05, Final Batch Loss: 4.785258715855889e-05\n",
      "Epoch 4541, Loss: 0.0001484815011281171, Final Batch Loss: 1.3932939509686548e-05\n",
      "Epoch 4542, Loss: 0.0001384862788427199, Final Batch Loss: 9.39729216042906e-05\n",
      "Epoch 4543, Loss: 0.0020229422789270757, Final Batch Loss: 3.8698763091815636e-06\n",
      "Epoch 4544, Loss: 0.0002790501603158191, Final Batch Loss: 1.4853651009616442e-05\n",
      "Epoch 4545, Loss: 0.00039659486628806917, Final Batch Loss: 5.9608773881336674e-05\n",
      "Epoch 4546, Loss: 8.718536446394864e-05, Final Batch Loss: 2.4424976800219156e-05\n",
      "Epoch 4547, Loss: 0.0002351662169530755, Final Batch Loss: 7.330609514610842e-05\n",
      "Epoch 4548, Loss: 0.0003153639081574511, Final Batch Loss: 2.6116560547961853e-05\n",
      "Epoch 4549, Loss: 0.00016614680134807713, Final Batch Loss: 1.668747609073762e-05\n",
      "Epoch 4550, Loss: 0.0004589110203596647, Final Batch Loss: 3.434934114920907e-05\n",
      "Epoch 4551, Loss: 0.00045281384791451273, Final Batch Loss: 3.701016612467356e-05\n",
      "Epoch 4552, Loss: 0.002294706150678394, Final Batch Loss: 1.7433341781725176e-05\n",
      "Epoch 4553, Loss: 0.0002854440140254155, Final Batch Loss: 1.3025489352003206e-05\n",
      "Epoch 4554, Loss: 0.0002899691905895452, Final Batch Loss: 0.0002024767454713583\n",
      "Epoch 4555, Loss: 0.0004410590727275121, Final Batch Loss: 0.0003903330652974546\n",
      "Epoch 4556, Loss: 0.00021217355470071197, Final Batch Loss: 0.00016103885718621314\n",
      "Epoch 4557, Loss: 3.9545692061437876e-05, Final Batch Loss: 1.2357780178717803e-05\n",
      "Epoch 4558, Loss: 6.725867115164874e-05, Final Batch Loss: 9.367081474920269e-06\n",
      "Epoch 4559, Loss: 0.00022122799683188532, Final Batch Loss: 2.440491755351104e-07\n",
      "Epoch 4560, Loss: 3.0229803087422624e-05, Final Batch Loss: 6.870818651805166e-07\n",
      "Epoch 4561, Loss: 0.0003200837833787773, Final Batch Loss: 5.941598715253349e-07\n",
      "Epoch 4562, Loss: 0.00019278691024737782, Final Batch Loss: 4.928760063194204e-06\n",
      "Epoch 4563, Loss: 0.00018679268168853014, Final Batch Loss: 6.113685230957344e-05\n",
      "Epoch 4564, Loss: 0.003803019568238142, Final Batch Loss: 5.950993795522663e-07\n",
      "Epoch 4565, Loss: 0.00036039550496980155, Final Batch Loss: 5.125005486661394e-07\n",
      "Epoch 4566, Loss: 0.0005453170163036702, Final Batch Loss: 4.807269579032436e-05\n",
      "Epoch 4567, Loss: 0.000709882820274288, Final Batch Loss: 1.861996679508593e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4568, Loss: 0.001582436665557907, Final Batch Loss: 0.0001316197303822264\n",
      "Epoch 4569, Loss: 0.0001760991397077305, Final Batch Loss: 1.6409814634243958e-05\n",
      "Epoch 4570, Loss: 0.0001459654736208904, Final Batch Loss: 1.7963620848604478e-05\n",
      "Epoch 4571, Loss: 0.0003640953700596583, Final Batch Loss: 2.3687496650381945e-05\n",
      "Epoch 4572, Loss: 0.0006515815512102563, Final Batch Loss: 6.765776925021783e-05\n",
      "Epoch 4573, Loss: 0.0005719371538361884, Final Batch Loss: 0.0005389233119785786\n",
      "Epoch 4574, Loss: 0.0002444758501951583, Final Batch Loss: 0.00010963201930280775\n",
      "Epoch 4575, Loss: 0.0007117802952052443, Final Batch Loss: 8.033618541958276e-06\n",
      "Epoch 4576, Loss: 0.0003502172858134145, Final Batch Loss: 0.00010652669152477756\n",
      "Epoch 4577, Loss: 0.0001161310692623374, Final Batch Loss: 1.6851379768922925e-05\n",
      "Epoch 4578, Loss: 0.0021047541598591124, Final Batch Loss: 2.5555909815011546e-06\n",
      "Epoch 4579, Loss: 0.000825177363367402, Final Batch Loss: 1.0234949513687752e-05\n",
      "Epoch 4580, Loss: 5.7406741007071105e-05, Final Batch Loss: 3.913787077181041e-05\n",
      "Epoch 4581, Loss: 0.00046454220887426345, Final Batch Loss: 0.00039246573578566313\n",
      "Epoch 4582, Loss: 0.00011268401249253657, Final Batch Loss: 1.2158716344856657e-05\n",
      "Epoch 4583, Loss: 0.0011009890049535898, Final Batch Loss: 0.0010447175009176135\n",
      "Epoch 4584, Loss: 0.00037338911238293804, Final Batch Loss: 3.3673859434202313e-05\n",
      "Epoch 4585, Loss: 0.00015296892200566958, Final Batch Loss: 3.660755609757871e-08\n",
      "Epoch 4586, Loss: 0.0002881350550296702, Final Batch Loss: 7.845148502383381e-05\n",
      "Epoch 4587, Loss: 0.00011015159493865667, Final Batch Loss: 9.949731349934154e-08\n",
      "Epoch 4588, Loss: 0.00010562451939222228, Final Batch Loss: 1.728008328427677e-06\n",
      "Epoch 4589, Loss: 3.635615348684951e-05, Final Batch Loss: 4.049788913107477e-06\n",
      "Epoch 4590, Loss: 9.030413184518693e-05, Final Batch Loss: 9.669575774751138e-06\n",
      "Epoch 4591, Loss: 6.584576908608142e-05, Final Batch Loss: 1.4756693417439237e-05\n",
      "Epoch 4592, Loss: 8.531253286037099e-05, Final Batch Loss: 4.984218548997887e-07\n",
      "Epoch 4593, Loss: 9.940658583218465e-05, Final Batch Loss: 2.8401660529198125e-05\n",
      "Epoch 4594, Loss: 0.0006845440457254881, Final Batch Loss: 1.1007325156242587e-05\n",
      "Epoch 4595, Loss: 4.774437418575417e-05, Final Batch Loss: 1.595706891066584e-07\n",
      "Epoch 4596, Loss: 0.00018212636609860056, Final Batch Loss: 2.6627524221112253e-06\n",
      "Epoch 4597, Loss: 0.00034292686984827014, Final Batch Loss: 8.006610414668103e-07\n",
      "Epoch 4598, Loss: 0.00039732420623295184, Final Batch Loss: 9.59459339355817e-06\n",
      "Epoch 4599, Loss: 0.00014574044939763553, Final Batch Loss: 2.070583150270977e-06\n",
      "Epoch 4600, Loss: 7.98891902604737e-05, Final Batch Loss: 3.4818633139366284e-05\n",
      "Epoch 4601, Loss: 0.0037786976706684072, Final Batch Loss: 4.043103672302095e-06\n",
      "Epoch 4602, Loss: 7.413714774884284e-05, Final Batch Loss: 8.898068699636497e-07\n",
      "Epoch 4603, Loss: 0.0004881798154201533, Final Batch Loss: 0.0004386358486954123\n",
      "Epoch 4604, Loss: 0.0001732967912175809, Final Batch Loss: 4.5216071157483384e-05\n",
      "Epoch 4605, Loss: 5.974490727567172e-05, Final Batch Loss: 3.4456036246410804e-06\n",
      "Epoch 4606, Loss: 0.000207763526304916, Final Batch Loss: 1.4609534446208272e-05\n",
      "Epoch 4607, Loss: 8.840191412673448e-05, Final Batch Loss: 4.6554272557841614e-05\n",
      "Epoch 4608, Loss: 0.0004022797479592555, Final Batch Loss: 3.487466983642662e-06\n",
      "Epoch 4609, Loss: 0.0011787192916017375, Final Batch Loss: 7.631069820490666e-07\n",
      "Epoch 4610, Loss: 0.00020311943990236614, Final Batch Loss: 3.717789877555333e-05\n",
      "Epoch 4611, Loss: 0.0001743390098454256, Final Batch Loss: 1.2305431482673157e-06\n",
      "Epoch 4612, Loss: 0.00022069217266107444, Final Batch Loss: 0.00016432668780907989\n",
      "Epoch 4613, Loss: 0.00013035050892540312, Final Batch Loss: 2.9715827167819953e-06\n",
      "Epoch 4614, Loss: 6.698919196423958e-05, Final Batch Loss: 5.2042591960344e-06\n",
      "Epoch 4615, Loss: 0.0004885859707428608, Final Batch Loss: 2.3052249161992222e-05\n",
      "Epoch 4616, Loss: 9.555380063375196e-05, Final Batch Loss: 1.2033116263410193e-06\n",
      "Epoch 4617, Loss: 0.002303906607949102, Final Batch Loss: 2.3737800347589655e-06\n",
      "Epoch 4618, Loss: 1.2146771950938273e-05, Final Batch Loss: 1.5787386473675724e-06\n",
      "Epoch 4619, Loss: 0.0002755445984803373, Final Batch Loss: 2.721828650464886e-06\n",
      "Epoch 4620, Loss: 0.001255471454896906, Final Batch Loss: 3.581180499168113e-05\n",
      "Epoch 4621, Loss: 4.3838950773533725e-05, Final Batch Loss: 1.0484590120540815e-06\n",
      "Epoch 4622, Loss: 8.759647880651755e-05, Final Batch Loss: 2.8059828764526173e-05\n",
      "Epoch 4623, Loss: 0.00021872136221645633, Final Batch Loss: 6.843974551884457e-05\n",
      "Epoch 4624, Loss: 0.0001360905046112748, Final Batch Loss: 3.7784741380164633e-06\n",
      "Epoch 4625, Loss: 6.0156988411108614e-05, Final Batch Loss: 2.0546087853290373e-06\n",
      "Epoch 4626, Loss: 6.780048897780944e-05, Final Batch Loss: 8.993124538392294e-06\n",
      "Epoch 4627, Loss: 0.00017464354661456127, Final Batch Loss: 1.9617820612438663e-07\n",
      "Epoch 4628, Loss: 0.00012600604713952634, Final Batch Loss: 6.322206900222227e-06\n",
      "Epoch 4629, Loss: 3.000430621113992e-05, Final Batch Loss: 7.462134021807287e-07\n",
      "Epoch 4630, Loss: 1.0687793860597594e-05, Final Batch Loss: 1.107574462366756e-06\n",
      "Epoch 4631, Loss: 8.389854798451779e-05, Final Batch Loss: 9.377018272971327e-07\n",
      "Epoch 4632, Loss: 0.00018101230762113119, Final Batch Loss: 0.00011728434765245765\n",
      "Epoch 4633, Loss: 0.0004904323300252145, Final Batch Loss: 1.7691250832285732e-05\n",
      "Epoch 4634, Loss: 0.00045113589521861286, Final Batch Loss: 4.03616013500141e-07\n",
      "Epoch 4635, Loss: 0.00011872501272591762, Final Batch Loss: 6.8134531829855405e-06\n",
      "Epoch 4636, Loss: 0.0005625073376904766, Final Batch Loss: 7.830662980268244e-06\n",
      "Epoch 4637, Loss: 0.0001268467914314897, Final Batch Loss: 0.00010561844101175666\n",
      "Epoch 4638, Loss: 0.00023259796944330446, Final Batch Loss: 6.256203050725162e-05\n",
      "Epoch 4639, Loss: 4.947197800220238e-05, Final Batch Loss: 9.576699085300788e-06\n",
      "Epoch 4640, Loss: 0.00010039739595413266, Final Batch Loss: 1.4801428278587991e-06\n",
      "Epoch 4641, Loss: 0.0008598380769626601, Final Batch Loss: 1.1225885145904613e-06\n",
      "Epoch 4642, Loss: 0.00023932378599056392, Final Batch Loss: 1.124690334108891e-05\n",
      "Epoch 4643, Loss: 9.800091800116206e-05, Final Batch Loss: 1.0688469046726823e-05\n",
      "Epoch 4644, Loss: 0.00025816031870817824, Final Batch Loss: 3.69322115147952e-05\n",
      "Epoch 4645, Loss: 2.1264471115500783e-05, Final Batch Loss: 1.128814801631961e-05\n",
      "Epoch 4646, Loss: 9.143948500422994e-05, Final Batch Loss: 2.3511765903094783e-06\n",
      "Epoch 4647, Loss: 0.00045923433458483487, Final Batch Loss: 0.0004400234029162675\n",
      "Epoch 4648, Loss: 9.667226549936458e-05, Final Batch Loss: 8.783766679698601e-05\n",
      "Epoch 4649, Loss: 6.64258086544578e-05, Final Batch Loss: 1.0214893336524256e-05\n",
      "Epoch 4650, Loss: 2.3108234472601907e-05, Final Batch Loss: 2.5885731247399235e-06\n",
      "Epoch 4651, Loss: 1.642963457015867e-05, Final Batch Loss: 4.210868610243779e-06\n",
      "Epoch 4652, Loss: 0.00037145312808206654, Final Batch Loss: 1.9744094970519654e-05\n",
      "Epoch 4653, Loss: 4.430415629030904e-05, Final Batch Loss: 2.4392133127548732e-05\n",
      "Epoch 4654, Loss: 0.0019383870875344655, Final Batch Loss: 6.410822379621095e-07\n",
      "Epoch 4655, Loss: 3.461986102593073e-05, Final Batch Loss: 1.0146400200028438e-06\n",
      "Epoch 4656, Loss: 2.467038643771957e-05, Final Batch Loss: 1.4885716836943175e-06\n",
      "Epoch 4657, Loss: 0.0015295517403046688, Final Batch Loss: 1.58717352860549e-06\n",
      "Epoch 4658, Loss: 6.832909207332705e-06, Final Batch Loss: 2.684244464035146e-06\n",
      "Epoch 4659, Loss: 3.264031738581252e-05, Final Batch Loss: 5.167093604541151e-06\n",
      "Epoch 4660, Loss: 3.9403030768880853e-05, Final Batch Loss: 3.7106856325408444e-06\n",
      "Epoch 4661, Loss: 4.087283969056443e-05, Final Batch Loss: 7.582605576317292e-06\n",
      "Epoch 4662, Loss: 9.527457984859211e-05, Final Batch Loss: 7.846627704566345e-05\n",
      "Epoch 4663, Loss: 0.0001545846230897041, Final Batch Loss: 5.331463057700603e-07\n",
      "Epoch 4664, Loss: 0.00024189210671465844, Final Batch Loss: 3.271067726018373e-06\n",
      "Epoch 4665, Loss: 0.0001850537732934754, Final Batch Loss: 4.035362962895306e-06\n",
      "Epoch 4666, Loss: 0.00014108436159254722, Final Batch Loss: 1.5957146715095405e-08\n",
      "Epoch 4667, Loss: 6.299865708569996e-05, Final Batch Loss: 4.555849045573268e-06\n",
      "Epoch 4668, Loss: 0.0010214177224270315, Final Batch Loss: 1.553329298076278e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4669, Loss: 7.655204814227545e-05, Final Batch Loss: 3.482387569420098e-07\n",
      "Epoch 4670, Loss: 0.0017188554047606885, Final Batch Loss: 0.0016594082117080688\n",
      "Epoch 4671, Loss: 2.557225320742873e-05, Final Batch Loss: 1.1845600056403782e-06\n",
      "Epoch 4672, Loss: 0.0007656118120848987, Final Batch Loss: 2.875653990486171e-05\n",
      "Epoch 4673, Loss: 0.0004813518382889015, Final Batch Loss: 2.7885371309821494e-06\n",
      "Epoch 4674, Loss: 0.00010114249380421825, Final Batch Loss: 1.195775439555291e-06\n",
      "Epoch 4675, Loss: 0.00022760849651604076, Final Batch Loss: 0.00013193563790991902\n",
      "Epoch 4676, Loss: 4.305782638880373e-05, Final Batch Loss: 4.160408934694715e-06\n",
      "Epoch 4677, Loss: 0.00011218858651318442, Final Batch Loss: 9.265132575819734e-06\n",
      "Epoch 4678, Loss: 4.8280058194904996e-05, Final Batch Loss: 3.677824861370027e-05\n",
      "Epoch 4679, Loss: 6.264105195441516e-05, Final Batch Loss: 3.137055318802595e-05\n",
      "Epoch 4680, Loss: 0.0004137520018048235, Final Batch Loss: 0.00040026966598816216\n",
      "Epoch 4681, Loss: 7.92760403101056e-06, Final Batch Loss: 6.1105907889214e-07\n",
      "Epoch 4682, Loss: 0.0002205533132837445, Final Batch Loss: 2.393537670286605e-07\n",
      "Epoch 4683, Loss: 2.3455359041690826e-05, Final Batch Loss: 2.7651103664538823e-06\n",
      "Epoch 4684, Loss: 6.374409296938666e-05, Final Batch Loss: 2.3372440693947283e-07\n",
      "Epoch 4685, Loss: 0.005693194448781469, Final Batch Loss: 6.232518217075267e-07\n",
      "Epoch 4686, Loss: 0.00016322988831518614, Final Batch Loss: 1.9148428975768184e-07\n",
      "Epoch 4687, Loss: 0.00012175132860647864, Final Batch Loss: 4.634513061319012e-06\n",
      "Epoch 4688, Loss: 5.4587114391324576e-05, Final Batch Loss: 2.1079968064441346e-06\n",
      "Epoch 4689, Loss: 0.0023752362403115512, Final Batch Loss: 7.95971288880537e-07\n",
      "Epoch 4690, Loss: 0.0023728018531983253, Final Batch Loss: 0.002201349474489689\n",
      "Epoch 4691, Loss: 0.00010788200421529837, Final Batch Loss: 1.6265719295915915e-06\n",
      "Epoch 4692, Loss: 1.7525281833741246e-05, Final Batch Loss: 3.831214598903898e-06\n",
      "Epoch 4693, Loss: 0.00039352556223093416, Final Batch Loss: 1.786099801392993e-06\n",
      "Epoch 4694, Loss: 0.0004419332249199215, Final Batch Loss: 4.399498266138835e-06\n",
      "Epoch 4695, Loss: 0.001448965069357655, Final Batch Loss: 0.00012206354585941881\n",
      "Epoch 4696, Loss: 8.341931868471875e-05, Final Batch Loss: 1.0784886399051175e-05\n",
      "Epoch 4697, Loss: 0.00013447863102555857, Final Batch Loss: 5.910922118346207e-05\n",
      "Epoch 4698, Loss: 0.006595207430791561, Final Batch Loss: 9.532862350170035e-06\n",
      "Epoch 4699, Loss: 7.704006975473021e-05, Final Batch Loss: 1.665250601945445e-05\n",
      "Epoch 4700, Loss: 0.006945720357180107, Final Batch Loss: 0.0010174718918278813\n",
      "Epoch 4701, Loss: 0.0003003071535658819, Final Batch Loss: 2.6721498215920292e-05\n",
      "Epoch 4702, Loss: 0.0016422793726604823, Final Batch Loss: 6.570580524112302e-08\n",
      "Epoch 4703, Loss: 0.0018056046159244943, Final Batch Loss: 3.0916266950953286e-06\n",
      "Epoch 4704, Loss: 0.018309732643956522, Final Batch Loss: 0.0023904945701360703\n",
      "Epoch 4705, Loss: 0.019773217628653583, Final Batch Loss: 0.00011465680290712044\n",
      "Epoch 4706, Loss: 0.0020403555517987115, Final Batch Loss: 1.9794874788203742e-06\n",
      "Epoch 4707, Loss: 0.00039472997286793543, Final Batch Loss: 0.00018924481992144138\n",
      "Epoch 4708, Loss: 0.001851624409937358, Final Batch Loss: 1.4655183804279659e-05\n",
      "Epoch 4709, Loss: 0.00639249241902462, Final Batch Loss: 7.781283670738048e-07\n",
      "Epoch 4710, Loss: 0.0014189841294864891, Final Batch Loss: 2.3948045054567046e-05\n",
      "Epoch 4711, Loss: 0.0014050930519147187, Final Batch Loss: 5.669323286383587e-07\n",
      "Epoch 4712, Loss: 0.016702924335106673, Final Batch Loss: 3.657482375274412e-05\n",
      "Epoch 4713, Loss: 0.0008438865270363749, Final Batch Loss: 9.523097105557099e-06\n",
      "Epoch 4714, Loss: 0.008764667561990791, Final Batch Loss: 3.474417462712154e-05\n",
      "Epoch 4715, Loss: 0.0003122659218206536, Final Batch Loss: 0.0001456214376958087\n",
      "Epoch 4716, Loss: 0.00030506535313179484, Final Batch Loss: 7.746962182864081e-06\n",
      "Epoch 4717, Loss: 0.0011272602341705351, Final Batch Loss: 4.322632776165847e-06\n",
      "Epoch 4718, Loss: 0.000336378571773821, Final Batch Loss: 6.264969670155551e-06\n",
      "Epoch 4719, Loss: 0.0003907545408310398, Final Batch Loss: 1.952585625986103e-05\n",
      "Epoch 4720, Loss: 0.002515391841370729, Final Batch Loss: 0.0023674878757447004\n",
      "Epoch 4721, Loss: 0.014457781972964767, Final Batch Loss: 0.01435286458581686\n",
      "Epoch 4722, Loss: 0.04064174488030403, Final Batch Loss: 0.04022512212395668\n",
      "Epoch 4723, Loss: 0.00729173327999888, Final Batch Loss: 6.944307097001001e-05\n",
      "Epoch 4724, Loss: 0.0008365355361092952, Final Batch Loss: 1.430550491932081e-05\n",
      "Epoch 4725, Loss: 0.02560831881339709, Final Batch Loss: 1.2737247061522794e-06\n",
      "Epoch 4726, Loss: 0.02057459628849756, Final Batch Loss: 0.00013582679093815386\n",
      "Epoch 4727, Loss: 0.004278866445929452, Final Batch Loss: 1.039137987390859e-05\n",
      "Epoch 4728, Loss: 0.01260732254377217, Final Batch Loss: 0.00034213080652989447\n",
      "Epoch 4729, Loss: 0.0013802436587866396, Final Batch Loss: 0.00016671261982992291\n",
      "Epoch 4730, Loss: 0.006627980830671731, Final Batch Loss: 0.0006378727266564965\n",
      "Epoch 4731, Loss: 0.0010319371012883494, Final Batch Loss: 1.1864258340210654e-05\n",
      "Epoch 4732, Loss: 0.014423356524275732, Final Batch Loss: 1.9008848539669998e-05\n",
      "Epoch 4733, Loss: 0.0009093252374441363, Final Batch Loss: 0.00042138321441598237\n",
      "Epoch 4734, Loss: 0.011939094292756636, Final Batch Loss: 0.00012494140537455678\n",
      "Epoch 4735, Loss: 0.00479228500444151, Final Batch Loss: 0.00014720269246026874\n",
      "Epoch 4736, Loss: 0.01080284287536415, Final Batch Loss: 6.5631124925857875e-06\n",
      "Epoch 4737, Loss: 0.012107077287510037, Final Batch Loss: 5.3032312280265614e-05\n",
      "Epoch 4738, Loss: 0.009131577297011972, Final Batch Loss: 1.6061114365584217e-05\n",
      "Epoch 4739, Loss: 0.0018815852527040988, Final Batch Loss: 0.00015499047003686428\n",
      "Epoch 4740, Loss: 0.0033002732893692155, Final Batch Loss: 6.306982413661899e-06\n",
      "Epoch 4741, Loss: 0.011995577864581719, Final Batch Loss: 0.0007391191320493817\n",
      "Epoch 4742, Loss: 0.003941458202461945, Final Batch Loss: 3.4615386539371684e-05\n",
      "Epoch 4743, Loss: 0.010435933989356272, Final Batch Loss: 0.00010857757297344506\n",
      "Epoch 4744, Loss: 0.0016260865395452129, Final Batch Loss: 1.715862708806526e-05\n",
      "Epoch 4745, Loss: 0.0012443850937415846, Final Batch Loss: 0.00012314956984482706\n",
      "Epoch 4746, Loss: 0.0006324591176962713, Final Batch Loss: 2.5664508939371444e-05\n",
      "Epoch 4747, Loss: 0.00028523022592708003, Final Batch Loss: 3.9664595533395186e-05\n",
      "Epoch 4748, Loss: 0.003127965095700347, Final Batch Loss: 0.002947866916656494\n",
      "Epoch 4749, Loss: 0.0011306841624900699, Final Batch Loss: 0.00030656784656457603\n",
      "Epoch 4750, Loss: 0.008345448732143268, Final Batch Loss: 0.00015100713062565774\n",
      "Epoch 4751, Loss: 0.001821501422455185, Final Batch Loss: 2.024155401159078e-05\n",
      "Epoch 4752, Loss: 0.0003831443864328321, Final Batch Loss: 0.00014947715681046247\n",
      "Epoch 4753, Loss: 0.00010440770984132541, Final Batch Loss: 4.639370672521181e-06\n",
      "Epoch 4754, Loss: 0.0008227809375966899, Final Batch Loss: 7.445843948516995e-05\n",
      "Epoch 4755, Loss: 0.002003889393108693, Final Batch Loss: 1.9161208911100402e-05\n",
      "Epoch 4756, Loss: 0.003856450441162451, Final Batch Loss: 1.2006839824607596e-05\n",
      "Epoch 4757, Loss: 0.00010313048016996618, Final Batch Loss: 1.5139941069719498e-06\n",
      "Epoch 4758, Loss: 0.002488150850240345, Final Batch Loss: 0.00013942016812507063\n",
      "Epoch 4759, Loss: 0.0002666751893229957, Final Batch Loss: 2.5764702513697557e-06\n",
      "Epoch 4760, Loss: 0.0003199419988959562, Final Batch Loss: 0.00013497246254701167\n",
      "Epoch 4761, Loss: 0.0021256560175970662, Final Batch Loss: 6.0458871303126216e-05\n",
      "Epoch 4762, Loss: 0.0005768324321593354, Final Batch Loss: 8.560440960536653e-07\n",
      "Epoch 4763, Loss: 0.0001550575243527419, Final Batch Loss: 2.345675056858454e-05\n",
      "Epoch 4764, Loss: 0.009568519631557137, Final Batch Loss: 0.00755259720608592\n",
      "Epoch 4765, Loss: 0.000798154507720028, Final Batch Loss: 8.15950807009358e-06\n",
      "Epoch 4766, Loss: 0.006257898098738224, Final Batch Loss: 0.0032965783029794693\n",
      "Epoch 4767, Loss: 0.0005263372124773014, Final Batch Loss: 0.0001832819398259744\n",
      "Epoch 4768, Loss: 0.01771374878808274, Final Batch Loss: 4.879704647464678e-06\n",
      "Epoch 4769, Loss: 0.0001933082508003281, Final Batch Loss: 4.088460627826862e-06\n",
      "Epoch 4770, Loss: 0.0015219206006804598, Final Batch Loss: 3.804969310294837e-05\n",
      "Epoch 4771, Loss: 0.001201820861467695, Final Batch Loss: 2.2888800231157802e-05\n",
      "Epoch 4772, Loss: 0.00032857074575076695, Final Batch Loss: 2.000192125706235e-06\n",
      "Epoch 4773, Loss: 0.0006943335865798872, Final Batch Loss: 7.903569348854944e-05\n",
      "Epoch 4774, Loss: 0.005816006360873871, Final Batch Loss: 0.005764924921095371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4775, Loss: 0.0001726123296066362, Final Batch Loss: 6.6643829086387996e-06\n",
      "Epoch 4776, Loss: 0.0001684342041698983, Final Batch Loss: 5.836717173224315e-05\n",
      "Epoch 4777, Loss: 0.002548639185988577, Final Batch Loss: 1.7041682440321892e-05\n",
      "Epoch 4778, Loss: 0.003986247045077107, Final Batch Loss: 0.0034687663428485394\n",
      "Epoch 4779, Loss: 0.0002034736648965918, Final Batch Loss: 9.573785064276308e-05\n",
      "Epoch 4780, Loss: 8.721433914615773e-05, Final Batch Loss: 1.1551746865734458e-05\n",
      "Epoch 4781, Loss: 7.667553450119158e-05, Final Batch Loss: 2.5500546598777873e-06\n",
      "Epoch 4782, Loss: 0.00020155291304035927, Final Batch Loss: 5.401147518568905e-06\n",
      "Epoch 4783, Loss: 0.0003672337752504973, Final Batch Loss: 0.00012784886348526925\n",
      "Epoch 4784, Loss: 0.13328667181122, Final Batch Loss: 0.1323057860136032\n",
      "Epoch 4785, Loss: 0.0008107808098429814, Final Batch Loss: 2.9995855584274977e-05\n",
      "Epoch 4786, Loss: 0.0007171868774094037, Final Batch Loss: 0.0003034147375728935\n",
      "Epoch 4787, Loss: 0.03236017573181016, Final Batch Loss: 0.00025715443189255893\n",
      "Epoch 4788, Loss: 0.020400267276272643, Final Batch Loss: 5.3530508012045175e-05\n",
      "Epoch 4789, Loss: 0.058187314542010427, Final Batch Loss: 0.005229292903095484\n",
      "Epoch 4790, Loss: 0.008813394655589946, Final Batch Loss: 4.6528188249794766e-05\n",
      "Epoch 4791, Loss: 0.012774079174050712, Final Batch Loss: 0.0001993701298488304\n",
      "Epoch 4792, Loss: 0.0007990008730871523, Final Batch Loss: 5.228271788837446e-07\n",
      "Epoch 4793, Loss: 0.0004961911763530225, Final Batch Loss: 2.8992923034820706e-05\n",
      "Epoch 4794, Loss: 0.0001102859014281421, Final Batch Loss: 2.952115573862102e-05\n",
      "Epoch 4795, Loss: 0.00035919547008234076, Final Batch Loss: 5.215002965996973e-05\n",
      "Epoch 4796, Loss: 0.020254679353456595, Final Batch Loss: 1.3066942301520612e-05\n",
      "Epoch 4797, Loss: 0.007814159262125031, Final Batch Loss: 9.141094778897241e-05\n",
      "Epoch 4798, Loss: 0.0023956636041475576, Final Batch Loss: 1.4813479538133834e-05\n",
      "Epoch 4799, Loss: 0.005362292595236795, Final Batch Loss: 0.00511662382632494\n",
      "Epoch 4800, Loss: 0.009090343019124703, Final Batch Loss: 0.00013566396955866367\n",
      "Epoch 4801, Loss: 0.00539928766193043, Final Batch Loss: 8.409579459112138e-05\n",
      "Epoch 4802, Loss: 0.032543430228543, Final Batch Loss: 0.03152946010231972\n",
      "Epoch 4803, Loss: 0.0011785804026658298, Final Batch Loss: 1.0706797183956951e-05\n",
      "Epoch 4804, Loss: 0.02212402759869292, Final Batch Loss: 1.59388091560686e-05\n",
      "Epoch 4805, Loss: 0.014650846118911431, Final Batch Loss: 4.730406089947792e-06\n",
      "Epoch 4806, Loss: 0.0009049580330611207, Final Batch Loss: 3.123391070403159e-05\n",
      "Epoch 4807, Loss: 0.029054031192572438, Final Batch Loss: 5.108774348627776e-05\n",
      "Epoch 4808, Loss: 0.0007090719727784744, Final Batch Loss: 0.0006292967591434717\n",
      "Epoch 4809, Loss: 0.0026343170611653477, Final Batch Loss: 4.6749599277973175e-05\n",
      "Epoch 4810, Loss: 0.0013324671945156297, Final Batch Loss: 0.00022490551054943353\n",
      "Epoch 4811, Loss: 0.0006319218528005877, Final Batch Loss: 1.0374206794949714e-05\n",
      "Epoch 4812, Loss: 0.0003011243961736909, Final Batch Loss: 6.256661436054856e-05\n",
      "Epoch 4813, Loss: 0.0004511667630140437, Final Batch Loss: 0.0002404626429779455\n",
      "Epoch 4814, Loss: 0.00026855173746298533, Final Batch Loss: 7.467785326298326e-05\n",
      "Epoch 4815, Loss: 0.006840550742936102, Final Batch Loss: 3.121822601315216e-06\n",
      "Epoch 4816, Loss: 0.0006413825922209071, Final Batch Loss: 0.00017817059415392578\n",
      "Epoch 4817, Loss: 0.00013628969463752583, Final Batch Loss: 1.7106694940594025e-05\n",
      "Epoch 4818, Loss: 0.0006998931057751179, Final Batch Loss: 0.00021239827037788928\n",
      "Epoch 4819, Loss: 0.0014509798911603866, Final Batch Loss: 5.316934039001353e-05\n",
      "Epoch 4820, Loss: 0.0012499698946157878, Final Batch Loss: 4.567268842947669e-05\n",
      "Epoch 4821, Loss: 0.0017723730597936083, Final Batch Loss: 8.069966861512512e-05\n",
      "Epoch 4822, Loss: 0.0017868650957097998, Final Batch Loss: 2.9176990210544318e-05\n",
      "Epoch 4823, Loss: 0.0058636126914279885, Final Batch Loss: 0.0008323081419803202\n",
      "Epoch 4824, Loss: 0.00035898528676625574, Final Batch Loss: 0.0001648556353757158\n",
      "Epoch 4825, Loss: 0.003960891841416014, Final Batch Loss: 0.0037443581968545914\n",
      "Epoch 4826, Loss: 0.0008583996504967217, Final Batch Loss: 3.749839379452169e-05\n",
      "Epoch 4827, Loss: 0.0036485338896454778, Final Batch Loss: 0.00019007055379915982\n",
      "Epoch 4828, Loss: 0.0023958382043929305, Final Batch Loss: 2.4724802642595023e-05\n",
      "Epoch 4829, Loss: 0.0005846848034707364, Final Batch Loss: 8.628125942777842e-05\n",
      "Epoch 4830, Loss: 0.0016818738513393328, Final Batch Loss: 8.672848343849182e-05\n",
      "Epoch 4831, Loss: 0.0003016388072865084, Final Batch Loss: 0.00015416054520756006\n",
      "Epoch 4832, Loss: 0.0006628739574807696, Final Batch Loss: 0.0002496392116881907\n",
      "Epoch 4833, Loss: 0.00020498235244303942, Final Batch Loss: 9.177177707897499e-05\n",
      "Epoch 4834, Loss: 0.00035075674077234, Final Batch Loss: 0.0002447925216984004\n",
      "Epoch 4835, Loss: 0.0003168855118929059, Final Batch Loss: 0.0002638347214087844\n",
      "Epoch 4836, Loss: 0.00013526280963560566, Final Batch Loss: 1.0427385859657079e-05\n",
      "Epoch 4837, Loss: 0.00032065327195596183, Final Batch Loss: 1.309902381763095e-05\n",
      "Epoch 4838, Loss: 0.0006070674880902516, Final Batch Loss: 0.0005398016655817628\n",
      "Epoch 4839, Loss: 0.0004950693200953538, Final Batch Loss: 1.7258638763451017e-05\n",
      "Epoch 4840, Loss: 0.000536634534910263, Final Batch Loss: 1.4371401448443066e-05\n",
      "Epoch 4841, Loss: 0.0023488645574616385, Final Batch Loss: 7.17427974450402e-05\n",
      "Epoch 4842, Loss: 0.0002119158152709133, Final Batch Loss: 2.9726102184213232e-06\n",
      "Epoch 4843, Loss: 8.52497501000471e-05, Final Batch Loss: 2.2701529815094545e-05\n",
      "Epoch 4844, Loss: 0.0013032409842708148, Final Batch Loss: 0.000970848894212395\n",
      "Epoch 4845, Loss: 6.319726617221022e-05, Final Batch Loss: 8.697238627064507e-06\n",
      "Epoch 4846, Loss: 0.00031834235596761573, Final Batch Loss: 4.326088856032584e-06\n",
      "Epoch 4847, Loss: 4.245160857863084e-05, Final Batch Loss: 3.7469155813596444e-06\n",
      "Epoch 4848, Loss: 9.65701660788909e-05, Final Batch Loss: 4.2236475565005094e-05\n",
      "Epoch 4849, Loss: 0.0003970462239522021, Final Batch Loss: 2.113977461704053e-05\n",
      "Epoch 4850, Loss: 8.587018282923964e-05, Final Batch Loss: 2.455336925777374e-06\n",
      "Epoch 4851, Loss: 0.0006065917150408495, Final Batch Loss: 2.9909093427704647e-05\n",
      "Epoch 4852, Loss: 0.0008041424152906984, Final Batch Loss: 1.0559237125562504e-05\n",
      "Epoch 4853, Loss: 0.0006024395631811785, Final Batch Loss: 2.2555111627298174e-06\n",
      "Epoch 4854, Loss: 0.0005021681072321371, Final Batch Loss: 1.356808115815511e-05\n",
      "Epoch 4855, Loss: 0.00013767720747637213, Final Batch Loss: 5.2273491746746004e-05\n",
      "Epoch 4856, Loss: 0.00035674993341672234, Final Batch Loss: 7.907279359642416e-05\n",
      "Epoch 4857, Loss: 8.241342948167585e-05, Final Batch Loss: 2.299066909472458e-05\n",
      "Epoch 4858, Loss: 0.00013661256434716051, Final Batch Loss: 1.920258000609465e-05\n",
      "Epoch 4859, Loss: 0.0002403385969955707, Final Batch Loss: 4.2131072405027226e-05\n",
      "Epoch 4860, Loss: 0.00010436326056151302, Final Batch Loss: 3.4126337595807854e-06\n",
      "Epoch 4861, Loss: 0.005109442077809945, Final Batch Loss: 0.00014739937614649534\n",
      "Epoch 4862, Loss: 0.00040692813627174473, Final Batch Loss: 3.6974070098949596e-05\n",
      "Epoch 4863, Loss: 0.018973485110109323, Final Batch Loss: 0.0004782321339007467\n",
      "Epoch 4864, Loss: 0.0005104537403894938, Final Batch Loss: 5.893116394872777e-05\n",
      "Epoch 4865, Loss: 0.0006925611896804185, Final Batch Loss: 0.0003712112666107714\n",
      "Epoch 4866, Loss: 0.0023535512955277227, Final Batch Loss: 0.002018911298364401\n",
      "Epoch 4867, Loss: 0.00020537664750008844, Final Batch Loss: 3.110900797764771e-05\n",
      "Epoch 4868, Loss: 0.001015060673125845, Final Batch Loss: 0.0008394877077080309\n",
      "Epoch 4869, Loss: 0.0010850119542737957, Final Batch Loss: 0.0006416040705516934\n",
      "Epoch 4870, Loss: 0.0011757253796531586, Final Batch Loss: 0.0009451914229430258\n",
      "Epoch 4871, Loss: 0.00014752504830539692, Final Batch Loss: 5.099012923892587e-06\n",
      "Epoch 4872, Loss: 0.00021203378491918556, Final Batch Loss: 0.00011074544454459101\n",
      "Epoch 4873, Loss: 0.00011786330378527055, Final Batch Loss: 3.81547179131303e-05\n",
      "Epoch 4874, Loss: 0.00012489415212257882, Final Batch Loss: 4.762720345752314e-05\n",
      "Epoch 4875, Loss: 0.0001520139298918366, Final Batch Loss: 5.435164894151967e-06\n",
      "Epoch 4876, Loss: 0.0004182654072337755, Final Batch Loss: 3.8453399611171335e-06\n",
      "Epoch 4877, Loss: 8.552627423341619e-05, Final Batch Loss: 1.2118407539674081e-05\n",
      "Epoch 4878, Loss: 0.004507361411015154, Final Batch Loss: 2.6734171115094796e-05\n",
      "Epoch 4879, Loss: 0.0005647426442010328, Final Batch Loss: 0.00017351868154946715\n",
      "Epoch 4880, Loss: 0.010463994223755435, Final Batch Loss: 1.2067199349985458e-05\n",
      "Epoch 4881, Loss: 0.000380946994482656, Final Batch Loss: 7.700818969169632e-06\n",
      "Epoch 4882, Loss: 0.0003015355505340267, Final Batch Loss: 0.00017411996668670326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4883, Loss: 5.656746702698001e-05, Final Batch Loss: 5.36825700692134e-06\n",
      "Epoch 4884, Loss: 5.1376810461079e-05, Final Batch Loss: 1.650564809096977e-05\n",
      "Epoch 4885, Loss: 5.454553502204362e-05, Final Batch Loss: 1.8976550563820638e-05\n",
      "Epoch 4886, Loss: 9.528966006655537e-05, Final Batch Loss: 1.2165988664492033e-05\n",
      "Epoch 4887, Loss: 0.0002673004910320742, Final Batch Loss: 1.7876040146802552e-05\n",
      "Epoch 4888, Loss: 0.00013095297981635667, Final Batch Loss: 4.1351362597197294e-05\n",
      "Epoch 4889, Loss: 0.0026204435380350333, Final Batch Loss: 1.8618206013343297e-05\n",
      "Epoch 4890, Loss: 0.004752474219458236, Final Batch Loss: 0.0003209979913663119\n",
      "Epoch 4891, Loss: 0.000765075952585903, Final Batch Loss: 0.0006522221374325454\n",
      "Epoch 4892, Loss: 0.00021656762692146003, Final Batch Loss: 4.456871829461306e-05\n",
      "Epoch 4893, Loss: 0.00020620104487534263, Final Batch Loss: 3.731018750841031e-06\n",
      "Epoch 4894, Loss: 0.003006481816555606, Final Batch Loss: 0.0016936881002038717\n",
      "Epoch 4895, Loss: 0.0001421299766661832, Final Batch Loss: 6.129398389020935e-05\n",
      "Epoch 4896, Loss: 9.106386278290302e-05, Final Batch Loss: 1.2151254850323312e-05\n",
      "Epoch 4897, Loss: 0.0001261291890841676, Final Batch Loss: 4.0291059121955186e-05\n",
      "Epoch 4898, Loss: 9.682172822067514e-05, Final Batch Loss: 3.65655796485953e-05\n",
      "Epoch 4899, Loss: 7.562005066574784e-05, Final Batch Loss: 2.579993633844424e-05\n",
      "Epoch 4900, Loss: 0.006903448986122385, Final Batch Loss: 1.5512130630668253e-05\n",
      "Epoch 4901, Loss: 0.00040214980958808155, Final Batch Loss: 2.81576444649545e-06\n",
      "Epoch 4902, Loss: 0.0002594991974547156, Final Batch Loss: 0.00021485584147740155\n",
      "Epoch 4903, Loss: 0.0001704579970009945, Final Batch Loss: 9.925636732077692e-06\n",
      "Epoch 4904, Loss: 0.0004135091264743096, Final Batch Loss: 2.2075953438616125e-06\n",
      "Epoch 4905, Loss: 0.005506777692062315, Final Batch Loss: 0.004205230623483658\n",
      "Epoch 4906, Loss: 0.001488591983616061, Final Batch Loss: 6.6788661570171826e-06\n",
      "Epoch 4907, Loss: 0.0002654295658430783, Final Batch Loss: 0.00017599017883185297\n",
      "Epoch 4908, Loss: 0.0016994697289192118, Final Batch Loss: 1.8159022147301584e-05\n",
      "Epoch 4909, Loss: 0.008100206698600232, Final Batch Loss: 0.00013979604409541935\n",
      "Epoch 4910, Loss: 0.0003268415657657897, Final Batch Loss: 2.2592987079406157e-05\n",
      "Epoch 4911, Loss: 0.008419750045959518, Final Batch Loss: 0.008264538832008839\n",
      "Epoch 4912, Loss: 0.017210587701811164, Final Batch Loss: 9.150481491815299e-05\n",
      "Epoch 4913, Loss: 0.0011875532209160156, Final Batch Loss: 3.384771480341442e-05\n",
      "Epoch 4914, Loss: 0.00039983787519304315, Final Batch Loss: 5.429134762380272e-05\n",
      "Epoch 4915, Loss: 0.0007149618481889775, Final Batch Loss: 0.00016320917347911745\n",
      "Epoch 4916, Loss: 0.000418414593241323, Final Batch Loss: 6.072991709515918e-07\n",
      "Epoch 4917, Loss: 0.00026214239642285975, Final Batch Loss: 1.093835544452304e-05\n",
      "Epoch 4918, Loss: 0.00927719297396834, Final Batch Loss: 1.2767221051035449e-05\n",
      "Epoch 4919, Loss: 0.00036763753269042354, Final Batch Loss: 1.631809391255956e-05\n",
      "Epoch 4920, Loss: 0.00018418156241750694, Final Batch Loss: 1.290618001803523e-06\n",
      "Epoch 4921, Loss: 0.00010978607679135166, Final Batch Loss: 4.394310599309392e-05\n",
      "Epoch 4922, Loss: 0.0006256148917600513, Final Batch Loss: 0.00046265291166491807\n",
      "Epoch 4923, Loss: 0.000661654468785855, Final Batch Loss: 8.151446672854945e-05\n",
      "Epoch 4924, Loss: 0.0002837016461967323, Final Batch Loss: 5.48169566627621e-07\n",
      "Epoch 4925, Loss: 0.00043298416039760923, Final Batch Loss: 4.486179932428058e-06\n",
      "Epoch 4926, Loss: 0.0005493930430020555, Final Batch Loss: 7.760021981084719e-05\n",
      "Epoch 4927, Loss: 0.0002707428438952775, Final Batch Loss: 4.1046067053684965e-05\n",
      "Epoch 4928, Loss: 0.011849315386825765, Final Batch Loss: 0.011486293748021126\n",
      "Epoch 4929, Loss: 0.00040791983337840065, Final Batch Loss: 0.00024114074767567217\n",
      "Epoch 4930, Loss: 0.00040307073544454397, Final Batch Loss: 6.36397487596696e-07\n",
      "Epoch 4931, Loss: 0.0002668631586857373, Final Batch Loss: 1.102057740354212e-05\n",
      "Epoch 4932, Loss: 0.0010041864270533551, Final Batch Loss: 1.4237372852221597e-05\n",
      "Epoch 4933, Loss: 0.0004803938609256875, Final Batch Loss: 0.0002633655967656523\n",
      "Epoch 4934, Loss: 0.0004990540760445583, Final Batch Loss: 0.0003197892219759524\n",
      "Epoch 4935, Loss: 0.0003157426190227852, Final Batch Loss: 0.00027983353356830776\n",
      "Epoch 4936, Loss: 0.00015478152988634974, Final Batch Loss: 4.405895742820576e-05\n",
      "Epoch 4937, Loss: 0.005028041134210071, Final Batch Loss: 0.004467991646379232\n",
      "Epoch 4938, Loss: 0.00015781298861838877, Final Batch Loss: 1.292471461056266e-05\n",
      "Epoch 4939, Loss: 0.00012650167104766297, Final Batch Loss: 2.7838934784085723e-06\n",
      "Epoch 4940, Loss: 0.00025390878704456554, Final Batch Loss: 1.353515244773007e-06\n",
      "Epoch 4941, Loss: 0.0008530382492608624, Final Batch Loss: 1.640724622120615e-05\n",
      "Epoch 4942, Loss: 0.0007635012416358222, Final Batch Loss: 6.2207300288719125e-06\n",
      "Epoch 4943, Loss: 0.0006865601144454558, Final Batch Loss: 0.00021088508947286755\n",
      "Epoch 4944, Loss: 0.00017980630582314916, Final Batch Loss: 7.221552368719131e-05\n",
      "Epoch 4945, Loss: 0.00038811200556665426, Final Batch Loss: 0.00010496370668988675\n",
      "Epoch 4946, Loss: 0.00013972496822134417, Final Batch Loss: 2.1626121906592743e-06\n",
      "Epoch 4947, Loss: 0.00013484483702086436, Final Batch Loss: 1.8162028936785646e-05\n",
      "Epoch 4948, Loss: 3.886661329488561e-05, Final Batch Loss: 1.576528484292794e-05\n",
      "Epoch 4949, Loss: 0.0046704052078894165, Final Batch Loss: 5.171496468392434e-06\n",
      "Epoch 4950, Loss: 0.0003059572395613941, Final Batch Loss: 3.5869365092366934e-05\n",
      "Epoch 4951, Loss: 0.00017893585277306556, Final Batch Loss: 8.710569545655744e-07\n",
      "Epoch 4952, Loss: 0.005608528202628804, Final Batch Loss: 5.4139283747645095e-05\n",
      "Epoch 4953, Loss: 9.393386608280707e-05, Final Batch Loss: 1.4781267964281142e-05\n",
      "Epoch 4954, Loss: 0.013062709198493394, Final Batch Loss: 1.1207296665816102e-05\n",
      "Epoch 4955, Loss: 0.00022519522281072568, Final Batch Loss: 8.975897799246013e-05\n",
      "Epoch 4956, Loss: 0.014670962242234964, Final Batch Loss: 0.0001691653742454946\n",
      "Epoch 4957, Loss: 0.00041310237247671466, Final Batch Loss: 0.0003738579689525068\n",
      "Epoch 4958, Loss: 4.36486250237067e-05, Final Batch Loss: 1.9711401364475023e-06\n",
      "Epoch 4959, Loss: 0.0006020863527282927, Final Batch Loss: 3.6124163216300076e-06\n",
      "Epoch 4960, Loss: 0.0008785839108895743, Final Batch Loss: 0.00048575535765849054\n",
      "Epoch 4961, Loss: 0.0005103716002849978, Final Batch Loss: 1.1214972801099066e-05\n",
      "Epoch 4962, Loss: 0.0001307636466663098, Final Batch Loss: 5.571209840127267e-06\n",
      "Epoch 4963, Loss: 0.004120766017877031, Final Batch Loss: 0.00019043592328671366\n",
      "Epoch 4964, Loss: 0.000395270647459256, Final Batch Loss: 0.00022636092035099864\n",
      "Epoch 4965, Loss: 0.0010486830324225593, Final Batch Loss: 8.334669473697431e-06\n",
      "Epoch 4966, Loss: 0.0001356987213512184, Final Batch Loss: 2.0205134205752984e-05\n",
      "Epoch 4967, Loss: 0.00029488767540897243, Final Batch Loss: 4.5024116843706e-05\n",
      "Epoch 4968, Loss: 0.00010794670151881292, Final Batch Loss: 5.716752184525831e-06\n",
      "Epoch 4969, Loss: 0.00032223592597802053, Final Batch Loss: 2.277126895933179e-06\n",
      "Epoch 4970, Loss: 9.466643905398087e-05, Final Batch Loss: 1.4653448488388676e-05\n",
      "Epoch 4971, Loss: 0.00014818833363960948, Final Batch Loss: 7.077368877617118e-07\n",
      "Epoch 4972, Loss: 0.00021691392771572282, Final Batch Loss: 3.0305761811177945e-06\n",
      "Epoch 4973, Loss: 0.00019639119136627414, Final Batch Loss: 4.5573990064440295e-05\n",
      "Epoch 4974, Loss: 0.0002988242558785714, Final Batch Loss: 2.6536939913057722e-05\n",
      "Epoch 4975, Loss: 0.00013301889475769713, Final Batch Loss: 4.127413558308035e-05\n",
      "Epoch 4976, Loss: 0.00011357434414094314, Final Batch Loss: 8.036490180529654e-05\n",
      "Epoch 4977, Loss: 0.001210830158470344, Final Batch Loss: 0.0008696591248735785\n",
      "Epoch 4978, Loss: 0.00010926447657766403, Final Batch Loss: 1.961186353582889e-05\n",
      "Epoch 4979, Loss: 7.71994496062689e-05, Final Batch Loss: 2.6567413442535326e-05\n",
      "Epoch 4980, Loss: 0.000858109837736265, Final Batch Loss: 6.423726972570876e-06\n",
      "Epoch 4981, Loss: 0.005424000199127477, Final Batch Loss: 2.734109693847131e-05\n",
      "Epoch 4982, Loss: 0.0002715836612878775, Final Batch Loss: 4.4145159336039796e-05\n",
      "Epoch 4983, Loss: 0.00017330732680420624, Final Batch Loss: 2.4472894438076764e-05\n",
      "Epoch 4984, Loss: 0.00032744040800025687, Final Batch Loss: 0.00017757838941179216\n",
      "Epoch 4985, Loss: 0.00038140276228659786, Final Batch Loss: 0.00012826768215745687\n",
      "Epoch 4986, Loss: 0.003528303202983807, Final Batch Loss: 6.624371962971054e-06\n",
      "Epoch 4987, Loss: 8.52477287480724e-05, Final Batch Loss: 1.5068165339471307e-05\n",
      "Epoch 4988, Loss: 9.477813000557944e-05, Final Batch Loss: 3.527888111420907e-05\n",
      "Epoch 4989, Loss: 0.0011323792414259515, Final Batch Loss: 0.0003146934031974524\n",
      "Epoch 4990, Loss: 0.00011320583462293143, Final Batch Loss: 5.61543629373773e-06\n",
      "Epoch 4991, Loss: 5.5650903732384904e-05, Final Batch Loss: 1.1474365237518214e-05\n",
      "Epoch 4992, Loss: 0.0007955828702961298, Final Batch Loss: 0.0007689991616643965\n",
      "Epoch 4993, Loss: 0.00015004718170530396, Final Batch Loss: 1.344674910797039e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4994, Loss: 0.00014373666704159405, Final Batch Loss: 3.2134637422132073e-06\n",
      "Epoch 4995, Loss: 0.00016183656589419115, Final Batch Loss: 2.3274871637113392e-05\n",
      "Epoch 4996, Loss: 0.0025961208029912086, Final Batch Loss: 6.535270949825644e-05\n",
      "Epoch 4997, Loss: 0.001687968860210276, Final Batch Loss: 0.0014792144065722823\n",
      "Epoch 4998, Loss: 0.00010432118506287225, Final Batch Loss: 6.915877020219341e-05\n",
      "Epoch 4999, Loss: 0.00023480498566641472, Final Batch Loss: 6.011160621710587e-06\n",
      "Epoch 5000, Loss: 0.00014946948476790567, Final Batch Loss: 4.522071776591474e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  3  1]\n",
      " [ 0 63  0]\n",
      " [ 0  0 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.95402   0.97647        87\n",
      "           1    0.95455   1.00000   0.97674        63\n",
      "           2    0.98592   1.00000   0.99291        70\n",
      "\n",
      "    accuracy                        0.98182       220\n",
      "   macro avg    0.98015   0.98467   0.98204       220\n",
      "weighted avg    0.98250   0.98182   0.98178       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 7)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_13 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_14 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 7)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_15 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_16 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_17 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_18 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_19 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U5A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_20 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U6A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_21 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 7) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12,\n",
    "                               fake_features_13, fake_features_14, fake_features_15, fake_features_16, fake_features_17, fake_features_18,\n",
    "                               fake_features_19, fake_features_20, fake_features_21))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68  2  0]\n",
      " [ 0 70  0]\n",
      " [ 0  0 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    1.00000   0.97143   0.98551        70\n",
      "         1.0    0.97222   1.00000   0.98592        70\n",
      "         2.0    1.00000   1.00000   1.00000        70\n",
      "\n",
      "    accuracy                        0.99048       210\n",
      "   macro avg    0.99074   0.99048   0.99047       210\n",
      "weighted avg    0.99074   0.99048   0.99047       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8, 11, 14]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    elif y[k] == 8:\n",
    "        y[k] = 4\n",
    "    elif y[k] == 11:\n",
    "        y[k] = 5\n",
    "    else:\n",
    "        y[k] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.829120397567749, Final Batch Loss: 1.9629391431808472\n",
      "Epoch 2, Loss: 7.806324481964111, Final Batch Loss: 1.9320296049118042\n",
      "Epoch 3, Loss: 7.799121022224426, Final Batch Loss: 1.9395220279693604\n",
      "Epoch 4, Loss: 7.78170371055603, Final Batch Loss: 1.9449036121368408\n",
      "Epoch 5, Loss: 7.778874039649963, Final Batch Loss: 1.9326989650726318\n",
      "Epoch 6, Loss: 7.762550473213196, Final Batch Loss: 1.9288957118988037\n",
      "Epoch 7, Loss: 7.769577980041504, Final Batch Loss: 1.9299522638320923\n",
      "Epoch 8, Loss: 7.76414680480957, Final Batch Loss: 1.9429709911346436\n",
      "Epoch 9, Loss: 7.751281023025513, Final Batch Loss: 1.9246987104415894\n",
      "Epoch 10, Loss: 7.754444599151611, Final Batch Loss: 1.9341353178024292\n",
      "Epoch 11, Loss: 7.73308002948761, Final Batch Loss: 1.9240518808364868\n",
      "Epoch 12, Loss: 7.729907155036926, Final Batch Loss: 1.9358093738555908\n",
      "Epoch 13, Loss: 7.705235481262207, Final Batch Loss: 1.9148224592208862\n",
      "Epoch 14, Loss: 7.7063000202178955, Final Batch Loss: 1.945185661315918\n",
      "Epoch 15, Loss: 7.678402781486511, Final Batch Loss: 1.9099390506744385\n",
      "Epoch 16, Loss: 7.654995679855347, Final Batch Loss: 1.9141713380813599\n",
      "Epoch 17, Loss: 7.625222563743591, Final Batch Loss: 1.8957929611206055\n",
      "Epoch 18, Loss: 7.5830124616622925, Final Batch Loss: 1.8870004415512085\n",
      "Epoch 19, Loss: 7.524341940879822, Final Batch Loss: 1.8544243574142456\n",
      "Epoch 20, Loss: 7.507080078125, Final Batch Loss: 1.8921937942504883\n",
      "Epoch 21, Loss: 7.412806868553162, Final Batch Loss: 1.8429737091064453\n",
      "Epoch 22, Loss: 7.34149706363678, Final Batch Loss: 1.8242919445037842\n",
      "Epoch 23, Loss: 7.205945014953613, Final Batch Loss: 1.7397125959396362\n",
      "Epoch 24, Loss: 7.184212684631348, Final Batch Loss: 1.8084869384765625\n",
      "Epoch 25, Loss: 7.031012773513794, Final Batch Loss: 1.7651554346084595\n",
      "Epoch 26, Loss: 6.98555862903595, Final Batch Loss: 1.790725588798523\n",
      "Epoch 27, Loss: 6.8977214097976685, Final Batch Loss: 1.7262146472930908\n",
      "Epoch 28, Loss: 6.739658236503601, Final Batch Loss: 1.659683108329773\n",
      "Epoch 29, Loss: 6.679089426994324, Final Batch Loss: 1.6111252307891846\n",
      "Epoch 30, Loss: 6.563344120979309, Final Batch Loss: 1.6364891529083252\n",
      "Epoch 31, Loss: 6.511836290359497, Final Batch Loss: 1.625065565109253\n",
      "Epoch 32, Loss: 6.39372181892395, Final Batch Loss: 1.5316969156265259\n",
      "Epoch 33, Loss: 6.354098320007324, Final Batch Loss: 1.5471165180206299\n",
      "Epoch 34, Loss: 6.374151349067688, Final Batch Loss: 1.6109853982925415\n",
      "Epoch 35, Loss: 6.203503847122192, Final Batch Loss: 1.4813239574432373\n",
      "Epoch 36, Loss: 6.133325099945068, Final Batch Loss: 1.4715911149978638\n",
      "Epoch 37, Loss: 6.097523331642151, Final Batch Loss: 1.5305436849594116\n",
      "Epoch 38, Loss: 5.97652804851532, Final Batch Loss: 1.4733511209487915\n",
      "Epoch 39, Loss: 5.960398435592651, Final Batch Loss: 1.4699535369873047\n",
      "Epoch 40, Loss: 5.952174782752991, Final Batch Loss: 1.4945768117904663\n",
      "Epoch 41, Loss: 5.88219678401947, Final Batch Loss: 1.40981924533844\n",
      "Epoch 42, Loss: 5.8149988651275635, Final Batch Loss: 1.4713969230651855\n",
      "Epoch 43, Loss: 5.733928442001343, Final Batch Loss: 1.4136412143707275\n",
      "Epoch 44, Loss: 5.679547429084778, Final Batch Loss: 1.40384840965271\n",
      "Epoch 45, Loss: 5.572708487510681, Final Batch Loss: 1.2635267972946167\n",
      "Epoch 46, Loss: 5.602806329727173, Final Batch Loss: 1.423287272453308\n",
      "Epoch 47, Loss: 5.6020307540893555, Final Batch Loss: 1.3359497785568237\n",
      "Epoch 48, Loss: 5.631451368331909, Final Batch Loss: 1.3778306245803833\n",
      "Epoch 49, Loss: 5.486646056175232, Final Batch Loss: 1.3158938884735107\n",
      "Epoch 50, Loss: 5.593757510185242, Final Batch Loss: 1.4305495023727417\n",
      "Epoch 51, Loss: 5.529979109764099, Final Batch Loss: 1.376707911491394\n",
      "Epoch 52, Loss: 5.3697381019592285, Final Batch Loss: 1.3503167629241943\n",
      "Epoch 53, Loss: 5.4978286027908325, Final Batch Loss: 1.4472119808197021\n",
      "Epoch 54, Loss: 5.289152383804321, Final Batch Loss: 1.2628941535949707\n",
      "Epoch 55, Loss: 5.295441031455994, Final Batch Loss: 1.3736366033554077\n",
      "Epoch 56, Loss: 5.187540054321289, Final Batch Loss: 1.2560203075408936\n",
      "Epoch 57, Loss: 5.1836079359054565, Final Batch Loss: 1.2679426670074463\n",
      "Epoch 58, Loss: 5.341288805007935, Final Batch Loss: 1.3345797061920166\n",
      "Epoch 59, Loss: 5.135808229446411, Final Batch Loss: 1.3006047010421753\n",
      "Epoch 60, Loss: 5.088641166687012, Final Batch Loss: 1.203186273574829\n",
      "Epoch 61, Loss: 5.200235486030579, Final Batch Loss: 1.2634555101394653\n",
      "Epoch 62, Loss: 5.056902289390564, Final Batch Loss: 1.2462998628616333\n",
      "Epoch 63, Loss: 5.0008838176727295, Final Batch Loss: 1.161531925201416\n",
      "Epoch 64, Loss: 4.950474143028259, Final Batch Loss: 1.2225764989852905\n",
      "Epoch 65, Loss: 4.963532567024231, Final Batch Loss: 1.2490837574005127\n",
      "Epoch 66, Loss: 4.989418625831604, Final Batch Loss: 1.2427796125411987\n",
      "Epoch 67, Loss: 4.9843831062316895, Final Batch Loss: 1.2606149911880493\n",
      "Epoch 68, Loss: 4.904041409492493, Final Batch Loss: 1.2253693342208862\n",
      "Epoch 69, Loss: 4.962598562240601, Final Batch Loss: 1.2619602680206299\n",
      "Epoch 70, Loss: 4.9167702198028564, Final Batch Loss: 1.2027281522750854\n",
      "Epoch 71, Loss: 4.812631964683533, Final Batch Loss: 1.1729003190994263\n",
      "Epoch 72, Loss: 4.834979057312012, Final Batch Loss: 1.2422294616699219\n",
      "Epoch 73, Loss: 4.788185119628906, Final Batch Loss: 1.1809626817703247\n",
      "Epoch 74, Loss: 4.851635575294495, Final Batch Loss: 1.2046147584915161\n",
      "Epoch 75, Loss: 4.688868403434753, Final Batch Loss: 1.1075000762939453\n",
      "Epoch 76, Loss: 4.814624071121216, Final Batch Loss: 1.2003648281097412\n",
      "Epoch 77, Loss: 4.709240794181824, Final Batch Loss: 1.1537617444992065\n",
      "Epoch 78, Loss: 4.6680203676223755, Final Batch Loss: 1.1435835361480713\n",
      "Epoch 79, Loss: 4.825012683868408, Final Batch Loss: 1.2022911310195923\n",
      "Epoch 80, Loss: 4.60958468914032, Final Batch Loss: 1.1402084827423096\n",
      "Epoch 81, Loss: 4.644189119338989, Final Batch Loss: 1.1165424585342407\n",
      "Epoch 82, Loss: 4.8135986328125, Final Batch Loss: 1.2382155656814575\n",
      "Epoch 83, Loss: 4.666981935501099, Final Batch Loss: 1.2423958778381348\n",
      "Epoch 84, Loss: 4.641392946243286, Final Batch Loss: 1.134603500366211\n",
      "Epoch 85, Loss: 4.63667094707489, Final Batch Loss: 1.1021047830581665\n",
      "Epoch 86, Loss: 4.587182283401489, Final Batch Loss: 1.115782618522644\n",
      "Epoch 87, Loss: 4.5736329555511475, Final Batch Loss: 1.1587555408477783\n",
      "Epoch 88, Loss: 4.581514477729797, Final Batch Loss: 1.0725566148757935\n",
      "Epoch 89, Loss: 4.660421371459961, Final Batch Loss: 1.1376633644104004\n",
      "Epoch 90, Loss: 4.61588180065155, Final Batch Loss: 1.1625475883483887\n",
      "Epoch 91, Loss: 4.430943012237549, Final Batch Loss: 1.112094759941101\n",
      "Epoch 92, Loss: 4.582764506340027, Final Batch Loss: 1.0999693870544434\n",
      "Epoch 93, Loss: 4.408330678939819, Final Batch Loss: 1.1381165981292725\n",
      "Epoch 94, Loss: 4.345252990722656, Final Batch Loss: 1.0189168453216553\n",
      "Epoch 95, Loss: 4.4527469873428345, Final Batch Loss: 1.1287343502044678\n",
      "Epoch 96, Loss: 4.470509886741638, Final Batch Loss: 1.165618658065796\n",
      "Epoch 97, Loss: 4.457316279411316, Final Batch Loss: 1.1723603010177612\n",
      "Epoch 98, Loss: 4.256415128707886, Final Batch Loss: 1.017217755317688\n",
      "Epoch 99, Loss: 4.422955632209778, Final Batch Loss: 1.1374775171279907\n",
      "Epoch 100, Loss: 4.331515789031982, Final Batch Loss: 1.0958340167999268\n",
      "Epoch 101, Loss: 4.320392370223999, Final Batch Loss: 1.1110156774520874\n",
      "Epoch 102, Loss: 4.257029294967651, Final Batch Loss: 1.0078986883163452\n",
      "Epoch 103, Loss: 4.320255160331726, Final Batch Loss: 1.1173450946807861\n",
      "Epoch 104, Loss: 4.287095308303833, Final Batch Loss: 1.1193065643310547\n",
      "Epoch 105, Loss: 4.232796788215637, Final Batch Loss: 1.0709577798843384\n",
      "Epoch 106, Loss: 4.150351285934448, Final Batch Loss: 0.9278851747512817\n",
      "Epoch 107, Loss: 4.175594210624695, Final Batch Loss: 1.006397008895874\n",
      "Epoch 108, Loss: 4.169887125492096, Final Batch Loss: 0.9588529467582703\n",
      "Epoch 109, Loss: 4.33354127407074, Final Batch Loss: 1.0722520351409912\n",
      "Epoch 110, Loss: 4.224552929401398, Final Batch Loss: 1.1642298698425293\n",
      "Epoch 111, Loss: 4.231801748275757, Final Batch Loss: 1.1872007846832275\n",
      "Epoch 112, Loss: 4.222229421138763, Final Batch Loss: 1.1020658016204834\n",
      "Epoch 113, Loss: 4.07318502664566, Final Batch Loss: 1.0150209665298462\n",
      "Epoch 114, Loss: 4.020305335521698, Final Batch Loss: 0.9992570281028748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Loss: 4.072989761829376, Final Batch Loss: 1.0495809316635132\n",
      "Epoch 116, Loss: 4.043751001358032, Final Batch Loss: 1.066024899482727\n",
      "Epoch 117, Loss: 4.034191310405731, Final Batch Loss: 0.9591153264045715\n",
      "Epoch 118, Loss: 4.095159947872162, Final Batch Loss: 1.1093199253082275\n",
      "Epoch 119, Loss: 4.036996603012085, Final Batch Loss: 0.9527297616004944\n",
      "Epoch 120, Loss: 4.078827440738678, Final Batch Loss: 1.0388680696487427\n",
      "Epoch 121, Loss: 3.941320776939392, Final Batch Loss: 1.065710425376892\n",
      "Epoch 122, Loss: 4.038117349147797, Final Batch Loss: 1.0025553703308105\n",
      "Epoch 123, Loss: 4.146547794342041, Final Batch Loss: 1.125451922416687\n",
      "Epoch 124, Loss: 3.916926145553589, Final Batch Loss: 0.8838779926300049\n",
      "Epoch 125, Loss: 3.977644979953766, Final Batch Loss: 0.9953639507293701\n",
      "Epoch 126, Loss: 3.8860031962394714, Final Batch Loss: 0.8882778882980347\n",
      "Epoch 127, Loss: 3.903688609600067, Final Batch Loss: 0.8915362358093262\n",
      "Epoch 128, Loss: 3.900764286518097, Final Batch Loss: 0.9797073602676392\n",
      "Epoch 129, Loss: 3.7489832639694214, Final Batch Loss: 0.9522116780281067\n",
      "Epoch 130, Loss: 3.7573395371437073, Final Batch Loss: 0.9477616548538208\n",
      "Epoch 131, Loss: 3.7443268299102783, Final Batch Loss: 0.9428582191467285\n",
      "Epoch 132, Loss: 3.9152576327323914, Final Batch Loss: 0.9541322588920593\n",
      "Epoch 133, Loss: 3.836626887321472, Final Batch Loss: 0.9445080757141113\n",
      "Epoch 134, Loss: 3.825523316860199, Final Batch Loss: 1.0199428796768188\n",
      "Epoch 135, Loss: 3.675402879714966, Final Batch Loss: 0.86223965883255\n",
      "Epoch 136, Loss: 3.7288399934768677, Final Batch Loss: 0.8320445418357849\n",
      "Epoch 137, Loss: 3.7049930691719055, Final Batch Loss: 0.9811961650848389\n",
      "Epoch 138, Loss: 3.9031540155410767, Final Batch Loss: 1.1065285205841064\n",
      "Epoch 139, Loss: 3.789751708507538, Final Batch Loss: 0.9363482594490051\n",
      "Epoch 140, Loss: 3.6605897545814514, Final Batch Loss: 0.9360981583595276\n",
      "Epoch 141, Loss: 3.730457603931427, Final Batch Loss: 0.8802601099014282\n",
      "Epoch 142, Loss: 3.7204267978668213, Final Batch Loss: 0.927565336227417\n",
      "Epoch 143, Loss: 3.8735081553459167, Final Batch Loss: 1.0736738443374634\n",
      "Epoch 144, Loss: 3.5768603086471558, Final Batch Loss: 0.9218935966491699\n",
      "Epoch 145, Loss: 3.823264002799988, Final Batch Loss: 1.141019582748413\n",
      "Epoch 146, Loss: 3.727659225463867, Final Batch Loss: 1.0056782960891724\n",
      "Epoch 147, Loss: 3.5450865030288696, Final Batch Loss: 0.9610736966133118\n",
      "Epoch 148, Loss: 3.6179128289222717, Final Batch Loss: 0.9802084565162659\n",
      "Epoch 149, Loss: 3.5810590386390686, Final Batch Loss: 0.9541192650794983\n",
      "Epoch 150, Loss: 3.650872528553009, Final Batch Loss: 0.9326995015144348\n",
      "Epoch 151, Loss: 3.7230767607688904, Final Batch Loss: 1.0460233688354492\n",
      "Epoch 152, Loss: 3.5160646438598633, Final Batch Loss: 0.8243808150291443\n",
      "Epoch 153, Loss: 3.5838319063186646, Final Batch Loss: 0.8345364332199097\n",
      "Epoch 154, Loss: 3.604138731956482, Final Batch Loss: 0.8926280736923218\n",
      "Epoch 155, Loss: 3.6078917384147644, Final Batch Loss: 0.9308692812919617\n",
      "Epoch 156, Loss: 3.5338475704193115, Final Batch Loss: 0.879319429397583\n",
      "Epoch 157, Loss: 3.541053533554077, Final Batch Loss: 0.8547510504722595\n",
      "Epoch 158, Loss: 3.4672999382019043, Final Batch Loss: 0.880669355392456\n",
      "Epoch 159, Loss: 3.335376560688019, Final Batch Loss: 0.7538886666297913\n",
      "Epoch 160, Loss: 3.481638729572296, Final Batch Loss: 0.8364326357841492\n",
      "Epoch 161, Loss: 3.497388184070587, Final Batch Loss: 0.9025117754936218\n",
      "Epoch 162, Loss: 3.410742700099945, Final Batch Loss: 0.9165541529655457\n",
      "Epoch 163, Loss: 3.3132172226905823, Final Batch Loss: 0.776603639125824\n",
      "Epoch 164, Loss: 3.6302286982536316, Final Batch Loss: 0.9385172128677368\n",
      "Epoch 165, Loss: 3.3664767146110535, Final Batch Loss: 0.8242596983909607\n",
      "Epoch 166, Loss: 3.4595102667808533, Final Batch Loss: 0.8870493173599243\n",
      "Epoch 167, Loss: 3.2582806944847107, Final Batch Loss: 0.825572669506073\n",
      "Epoch 168, Loss: 3.5181217789649963, Final Batch Loss: 0.8903681039810181\n",
      "Epoch 169, Loss: 3.3144615292549133, Final Batch Loss: 0.828216552734375\n",
      "Epoch 170, Loss: 3.3576566576957703, Final Batch Loss: 0.857022762298584\n",
      "Epoch 171, Loss: 3.4839842319488525, Final Batch Loss: 0.9255884289741516\n",
      "Epoch 172, Loss: 3.382856011390686, Final Batch Loss: 0.9003024697303772\n",
      "Epoch 173, Loss: 3.4094871878623962, Final Batch Loss: 0.918095052242279\n",
      "Epoch 174, Loss: 3.3013339042663574, Final Batch Loss: 0.8103864192962646\n",
      "Epoch 175, Loss: 3.4453335404396057, Final Batch Loss: 0.8678432106971741\n",
      "Epoch 176, Loss: 3.1650694608688354, Final Batch Loss: 0.7165194153785706\n",
      "Epoch 177, Loss: 3.265778660774231, Final Batch Loss: 0.7952625751495361\n",
      "Epoch 178, Loss: 3.219223439693451, Final Batch Loss: 0.7872816324234009\n",
      "Epoch 179, Loss: 3.157006084918976, Final Batch Loss: 0.7978783249855042\n",
      "Epoch 180, Loss: 3.2083582282066345, Final Batch Loss: 0.8226350545883179\n",
      "Epoch 181, Loss: 3.1479695439338684, Final Batch Loss: 0.7472614645957947\n",
      "Epoch 182, Loss: 3.241505801677704, Final Batch Loss: 0.7741437554359436\n",
      "Epoch 183, Loss: 3.238891363143921, Final Batch Loss: 0.8398956060409546\n",
      "Epoch 184, Loss: 3.214354395866394, Final Batch Loss: 0.8299395442008972\n",
      "Epoch 185, Loss: 3.136455535888672, Final Batch Loss: 0.7263630032539368\n",
      "Epoch 186, Loss: 3.1841923594474792, Final Batch Loss: 0.6821472644805908\n",
      "Epoch 187, Loss: 3.1965067982673645, Final Batch Loss: 0.8343757390975952\n",
      "Epoch 188, Loss: 3.2098037600517273, Final Batch Loss: 0.7480238080024719\n",
      "Epoch 189, Loss: 3.009048283100128, Final Batch Loss: 0.8124735355377197\n",
      "Epoch 190, Loss: 3.1035719513893127, Final Batch Loss: 0.703866183757782\n",
      "Epoch 191, Loss: 3.1524933576583862, Final Batch Loss: 0.7261993885040283\n",
      "Epoch 192, Loss: 3.136715829372406, Final Batch Loss: 0.7485790252685547\n",
      "Epoch 193, Loss: 3.1860331296920776, Final Batch Loss: 0.8686110973358154\n",
      "Epoch 194, Loss: 3.125466227531433, Final Batch Loss: 0.8149945735931396\n",
      "Epoch 195, Loss: 3.070092499256134, Final Batch Loss: 0.8177260756492615\n",
      "Epoch 196, Loss: 3.090591847896576, Final Batch Loss: 0.6995956301689148\n",
      "Epoch 197, Loss: 3.0881584882736206, Final Batch Loss: 0.7658652067184448\n",
      "Epoch 198, Loss: 3.238656520843506, Final Batch Loss: 0.8652026653289795\n",
      "Epoch 199, Loss: 3.153512477874756, Final Batch Loss: 0.818816065788269\n",
      "Epoch 200, Loss: 3.1441690325737, Final Batch Loss: 0.8119667768478394\n",
      "Epoch 201, Loss: 3.254813551902771, Final Batch Loss: 0.902655839920044\n",
      "Epoch 202, Loss: 3.067040264606476, Final Batch Loss: 0.8254137635231018\n",
      "Epoch 203, Loss: 2.9965304732322693, Final Batch Loss: 0.8777881264686584\n",
      "Epoch 204, Loss: 3.06289279460907, Final Batch Loss: 0.7626625299453735\n",
      "Epoch 205, Loss: 3.0267127752304077, Final Batch Loss: 0.7395811080932617\n",
      "Epoch 206, Loss: 3.1090469360351562, Final Batch Loss: 0.7804142236709595\n",
      "Epoch 207, Loss: 3.0732328295707703, Final Batch Loss: 0.8744634985923767\n",
      "Epoch 208, Loss: 3.1002824306488037, Final Batch Loss: 0.7765448689460754\n",
      "Epoch 209, Loss: 3.003600597381592, Final Batch Loss: 0.7419445514678955\n",
      "Epoch 210, Loss: 2.91424024105072, Final Batch Loss: 0.7947769165039062\n",
      "Epoch 211, Loss: 2.9265172481536865, Final Batch Loss: 0.698017954826355\n",
      "Epoch 212, Loss: 3.1034420132637024, Final Batch Loss: 0.709409773349762\n",
      "Epoch 213, Loss: 3.072448432445526, Final Batch Loss: 0.8622182607650757\n",
      "Epoch 214, Loss: 2.943619728088379, Final Batch Loss: 0.6986799240112305\n",
      "Epoch 215, Loss: 3.012307107448578, Final Batch Loss: 0.7593602538108826\n",
      "Epoch 216, Loss: 3.0207878947257996, Final Batch Loss: 0.801270604133606\n",
      "Epoch 217, Loss: 2.9000682830810547, Final Batch Loss: 0.7652732729911804\n",
      "Epoch 218, Loss: 3.1055991649627686, Final Batch Loss: 0.8842573165893555\n",
      "Epoch 219, Loss: 2.961780369281769, Final Batch Loss: 0.7792719602584839\n",
      "Epoch 220, Loss: 2.988143563270569, Final Batch Loss: 0.6724384427070618\n",
      "Epoch 221, Loss: 2.999718129634857, Final Batch Loss: 0.719210684299469\n",
      "Epoch 222, Loss: 2.957756459712982, Final Batch Loss: 0.7559948563575745\n",
      "Epoch 223, Loss: 2.86371511220932, Final Batch Loss: 0.5677815675735474\n",
      "Epoch 224, Loss: 2.919432282447815, Final Batch Loss: 0.6711941957473755\n",
      "Epoch 225, Loss: 2.827930510044098, Final Batch Loss: 0.6721039414405823\n",
      "Epoch 226, Loss: 2.972849488258362, Final Batch Loss: 0.7601025104522705\n",
      "Epoch 227, Loss: 2.8828142285346985, Final Batch Loss: 0.744516909122467\n",
      "Epoch 228, Loss: 2.883572518825531, Final Batch Loss: 0.7144087553024292\n",
      "Epoch 229, Loss: 2.9909743070602417, Final Batch Loss: 0.7001951336860657\n",
      "Epoch 230, Loss: 2.881961762905121, Final Batch Loss: 0.7055226564407349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231, Loss: 3.002963602542877, Final Batch Loss: 0.8006185293197632\n",
      "Epoch 232, Loss: 2.7694727778434753, Final Batch Loss: 0.7013657093048096\n",
      "Epoch 233, Loss: 2.9162025451660156, Final Batch Loss: 0.6161056160926819\n",
      "Epoch 234, Loss: 2.9618998765945435, Final Batch Loss: 0.8408477902412415\n",
      "Epoch 235, Loss: 2.9469281435012817, Final Batch Loss: 0.7802278399467468\n",
      "Epoch 236, Loss: 2.7670750617980957, Final Batch Loss: 0.6542277336120605\n",
      "Epoch 237, Loss: 2.920811176300049, Final Batch Loss: 0.6909490823745728\n",
      "Epoch 238, Loss: 2.9888681173324585, Final Batch Loss: 0.7519965767860413\n",
      "Epoch 239, Loss: 2.7348233461380005, Final Batch Loss: 0.7362764477729797\n",
      "Epoch 240, Loss: 2.9096741676330566, Final Batch Loss: 0.7161902189254761\n",
      "Epoch 241, Loss: 2.8940380215644836, Final Batch Loss: 0.6571955680847168\n",
      "Epoch 242, Loss: 2.8276575803756714, Final Batch Loss: 0.7089771628379822\n",
      "Epoch 243, Loss: 2.7883923053741455, Final Batch Loss: 0.6893912553787231\n",
      "Epoch 244, Loss: 3.010918080806732, Final Batch Loss: 0.8856901526451111\n",
      "Epoch 245, Loss: 2.8319013118743896, Final Batch Loss: 0.7428687214851379\n",
      "Epoch 246, Loss: 2.8396750688552856, Final Batch Loss: 0.7205585837364197\n",
      "Epoch 247, Loss: 2.9336894154548645, Final Batch Loss: 0.7286889553070068\n",
      "Epoch 248, Loss: 2.782549738883972, Final Batch Loss: 0.7433527708053589\n",
      "Epoch 249, Loss: 2.825634717941284, Final Batch Loss: 0.6775652766227722\n",
      "Epoch 250, Loss: 2.796807825565338, Final Batch Loss: 0.7055947184562683\n",
      "Epoch 251, Loss: 2.761241614818573, Final Batch Loss: 0.626374363899231\n",
      "Epoch 252, Loss: 2.7475237250328064, Final Batch Loss: 0.5855012536048889\n",
      "Epoch 253, Loss: 2.862321197986603, Final Batch Loss: 0.7687498331069946\n",
      "Epoch 254, Loss: 2.783756732940674, Final Batch Loss: 0.6988041400909424\n",
      "Epoch 255, Loss: 2.9365509152412415, Final Batch Loss: 0.747295618057251\n",
      "Epoch 256, Loss: 2.843587815761566, Final Batch Loss: 0.823349118232727\n",
      "Epoch 257, Loss: 2.7782278656959534, Final Batch Loss: 0.7034652233123779\n",
      "Epoch 258, Loss: 2.797053813934326, Final Batch Loss: 0.6810235381126404\n",
      "Epoch 259, Loss: 2.8051127791404724, Final Batch Loss: 0.6446292400360107\n",
      "Epoch 260, Loss: 2.6403881907463074, Final Batch Loss: 0.5769320726394653\n",
      "Epoch 261, Loss: 2.887110650539398, Final Batch Loss: 0.705907940864563\n",
      "Epoch 262, Loss: 2.690636992454529, Final Batch Loss: 0.6460229158401489\n",
      "Epoch 263, Loss: 2.8055299520492554, Final Batch Loss: 0.578712522983551\n",
      "Epoch 264, Loss: 2.694277584552765, Final Batch Loss: 0.5281006693840027\n",
      "Epoch 265, Loss: 2.8757911324501038, Final Batch Loss: 0.8679425716400146\n",
      "Epoch 266, Loss: 2.816283166408539, Final Batch Loss: 0.7020374536514282\n",
      "Epoch 267, Loss: 2.767225503921509, Final Batch Loss: 0.6618767976760864\n",
      "Epoch 268, Loss: 2.5923845767974854, Final Batch Loss: 0.6078127026557922\n",
      "Epoch 269, Loss: 2.8352773785591125, Final Batch Loss: 0.7701485753059387\n",
      "Epoch 270, Loss: 2.632868230342865, Final Batch Loss: 0.6173107624053955\n",
      "Epoch 271, Loss: 2.8812854886054993, Final Batch Loss: 0.6006239056587219\n",
      "Epoch 272, Loss: 2.7986486554145813, Final Batch Loss: 0.6903670430183411\n",
      "Epoch 273, Loss: 2.6400054693222046, Final Batch Loss: 0.6163796186447144\n",
      "Epoch 274, Loss: 2.72381454706192, Final Batch Loss: 0.662090539932251\n",
      "Epoch 275, Loss: 2.718451738357544, Final Batch Loss: 0.7457389235496521\n",
      "Epoch 276, Loss: 2.8841148018836975, Final Batch Loss: 0.7924423217773438\n",
      "Epoch 277, Loss: 2.731162130832672, Final Batch Loss: 0.6770939230918884\n",
      "Epoch 278, Loss: 2.8405033349990845, Final Batch Loss: 0.7780057191848755\n",
      "Epoch 279, Loss: 2.8121447563171387, Final Batch Loss: 0.6242153644561768\n",
      "Epoch 280, Loss: 2.775950789451599, Final Batch Loss: 0.7025711536407471\n",
      "Epoch 281, Loss: 2.758511483669281, Final Batch Loss: 0.6520580649375916\n",
      "Epoch 282, Loss: 2.818435490131378, Final Batch Loss: 0.780774712562561\n",
      "Epoch 283, Loss: 2.67898952960968, Final Batch Loss: 0.6597423553466797\n",
      "Epoch 284, Loss: 2.6871254444122314, Final Batch Loss: 0.5850492119789124\n",
      "Epoch 285, Loss: 2.6168388724327087, Final Batch Loss: 0.680246114730835\n",
      "Epoch 286, Loss: 2.8076555728912354, Final Batch Loss: 0.7623003721237183\n",
      "Epoch 287, Loss: 2.6888453364372253, Final Batch Loss: 0.6466497778892517\n",
      "Epoch 288, Loss: 2.647540271282196, Final Batch Loss: 0.6281970739364624\n",
      "Epoch 289, Loss: 2.6458266973495483, Final Batch Loss: 0.5747105479240417\n",
      "Epoch 290, Loss: 2.6848575472831726, Final Batch Loss: 0.7243860960006714\n",
      "Epoch 291, Loss: 2.6096010208129883, Final Batch Loss: 0.631905734539032\n",
      "Epoch 292, Loss: 2.615442156791687, Final Batch Loss: 0.7047623991966248\n",
      "Epoch 293, Loss: 2.5997577905654907, Final Batch Loss: 0.6881117820739746\n",
      "Epoch 294, Loss: 2.7266247272491455, Final Batch Loss: 0.7717896699905396\n",
      "Epoch 295, Loss: 2.6803808212280273, Final Batch Loss: 0.7336230874061584\n",
      "Epoch 296, Loss: 2.5094624757766724, Final Batch Loss: 0.5698807239532471\n",
      "Epoch 297, Loss: 2.7604631185531616, Final Batch Loss: 0.7269485592842102\n",
      "Epoch 298, Loss: 2.6321550011634827, Final Batch Loss: 0.7435810565948486\n",
      "Epoch 299, Loss: 2.6629449129104614, Final Batch Loss: 0.5661405920982361\n",
      "Epoch 300, Loss: 2.508119761943817, Final Batch Loss: 0.5854365229606628\n",
      "Epoch 301, Loss: 2.643967032432556, Final Batch Loss: 0.6256334185600281\n",
      "Epoch 302, Loss: 2.544103264808655, Final Batch Loss: 0.6379918456077576\n",
      "Epoch 303, Loss: 2.493833005428314, Final Batch Loss: 0.5477726459503174\n",
      "Epoch 304, Loss: 2.606565833091736, Final Batch Loss: 0.6331711411476135\n",
      "Epoch 305, Loss: 2.551545798778534, Final Batch Loss: 0.6427406072616577\n",
      "Epoch 306, Loss: 2.521873652935028, Final Batch Loss: 0.5746402740478516\n",
      "Epoch 307, Loss: 2.5619831681251526, Final Batch Loss: 0.6320154070854187\n",
      "Epoch 308, Loss: 2.64846408367157, Final Batch Loss: 0.7476637363433838\n",
      "Epoch 309, Loss: 2.6013988256454468, Final Batch Loss: 0.7222020030021667\n",
      "Epoch 310, Loss: 2.662214457988739, Final Batch Loss: 0.6813220977783203\n",
      "Epoch 311, Loss: 2.453894853591919, Final Batch Loss: 0.5483454465866089\n",
      "Epoch 312, Loss: 2.5655016899108887, Final Batch Loss: 0.6301712393760681\n",
      "Epoch 313, Loss: 2.5856480598449707, Final Batch Loss: 0.6740723252296448\n",
      "Epoch 314, Loss: 2.6406449675559998, Final Batch Loss: 0.593916654586792\n",
      "Epoch 315, Loss: 2.6933231353759766, Final Batch Loss: 0.7057583928108215\n",
      "Epoch 316, Loss: 2.638150691986084, Final Batch Loss: 0.6142208576202393\n",
      "Epoch 317, Loss: 2.5786210894584656, Final Batch Loss: 0.6379498839378357\n",
      "Epoch 318, Loss: 2.605384051799774, Final Batch Loss: 0.6600465178489685\n",
      "Epoch 319, Loss: 2.5961713194847107, Final Batch Loss: 0.6630447506904602\n",
      "Epoch 320, Loss: 2.5889262557029724, Final Batch Loss: 0.7917061448097229\n",
      "Epoch 321, Loss: 2.677070140838623, Final Batch Loss: 0.6928629875183105\n",
      "Epoch 322, Loss: 2.531827211380005, Final Batch Loss: 0.5901741981506348\n",
      "Epoch 323, Loss: 2.565459430217743, Final Batch Loss: 0.7673895359039307\n",
      "Epoch 324, Loss: 2.599971354007721, Final Batch Loss: 0.6664837598800659\n",
      "Epoch 325, Loss: 2.4142280220985413, Final Batch Loss: 0.5992841720581055\n",
      "Epoch 326, Loss: 2.569421172142029, Final Batch Loss: 0.7255019545555115\n",
      "Epoch 327, Loss: 2.6309605836868286, Final Batch Loss: 0.7517983317375183\n",
      "Epoch 328, Loss: 2.506336808204651, Final Batch Loss: 0.6485220789909363\n",
      "Epoch 329, Loss: 2.4812570214271545, Final Batch Loss: 0.5865709185600281\n",
      "Epoch 330, Loss: 2.5418628454208374, Final Batch Loss: 0.6127526760101318\n",
      "Epoch 331, Loss: 2.629447042942047, Final Batch Loss: 0.6388859748840332\n",
      "Epoch 332, Loss: 2.4861708283424377, Final Batch Loss: 0.5707087516784668\n",
      "Epoch 333, Loss: 2.395510971546173, Final Batch Loss: 0.5866284966468811\n",
      "Epoch 334, Loss: 2.6346529722213745, Final Batch Loss: 0.6671762466430664\n",
      "Epoch 335, Loss: 2.3946680426597595, Final Batch Loss: 0.5656405687332153\n",
      "Epoch 336, Loss: 2.4863797426223755, Final Batch Loss: 0.6269831657409668\n",
      "Epoch 337, Loss: 2.4568339586257935, Final Batch Loss: 0.5746385455131531\n",
      "Epoch 338, Loss: 2.5282989144325256, Final Batch Loss: 0.609042227268219\n",
      "Epoch 339, Loss: 2.4525551199913025, Final Batch Loss: 0.5950264930725098\n",
      "Epoch 340, Loss: 2.4635393619537354, Final Batch Loss: 0.5599017143249512\n",
      "Epoch 341, Loss: 2.472382605075836, Final Batch Loss: 0.6339429020881653\n",
      "Epoch 342, Loss: 2.4300562143325806, Final Batch Loss: 0.5319420099258423\n",
      "Epoch 343, Loss: 2.466034412384033, Final Batch Loss: 0.48723268508911133\n",
      "Epoch 344, Loss: 2.4917678236961365, Final Batch Loss: 0.6894827485084534\n",
      "Epoch 345, Loss: 2.6017683148384094, Final Batch Loss: 0.7891404628753662\n",
      "Epoch 346, Loss: 2.442187249660492, Final Batch Loss: 0.5580527186393738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347, Loss: 2.458435356616974, Final Batch Loss: 0.6047745943069458\n",
      "Epoch 348, Loss: 2.4628159403800964, Final Batch Loss: 0.5999388694763184\n",
      "Epoch 349, Loss: 2.4457753896713257, Final Batch Loss: 0.5753253102302551\n",
      "Epoch 350, Loss: 2.5367594361305237, Final Batch Loss: 0.6192055344581604\n",
      "Epoch 351, Loss: 2.4964385628700256, Final Batch Loss: 0.5948818325996399\n",
      "Epoch 352, Loss: 2.527197480201721, Final Batch Loss: 0.6169732809066772\n",
      "Epoch 353, Loss: 2.491900324821472, Final Batch Loss: 0.7192424535751343\n",
      "Epoch 354, Loss: 2.572737395763397, Final Batch Loss: 0.6426435708999634\n",
      "Epoch 355, Loss: 2.4468822479248047, Final Batch Loss: 0.57635498046875\n",
      "Epoch 356, Loss: 2.3472448587417603, Final Batch Loss: 0.6551461815834045\n",
      "Epoch 357, Loss: 2.519586205482483, Final Batch Loss: 0.6201153993606567\n",
      "Epoch 358, Loss: 2.409421384334564, Final Batch Loss: 0.6453325152397156\n",
      "Epoch 359, Loss: 2.4960864186286926, Final Batch Loss: 0.6171118021011353\n",
      "Epoch 360, Loss: 2.4876797199249268, Final Batch Loss: 0.5497689843177795\n",
      "Epoch 361, Loss: 2.608067274093628, Final Batch Loss: 0.7348413467407227\n",
      "Epoch 362, Loss: 2.480836272239685, Final Batch Loss: 0.5935379266738892\n",
      "Epoch 363, Loss: 2.649351716041565, Final Batch Loss: 0.7902455925941467\n",
      "Epoch 364, Loss: 2.5005186796188354, Final Batch Loss: 0.6544741988182068\n",
      "Epoch 365, Loss: 2.3636361956596375, Final Batch Loss: 0.5066150426864624\n",
      "Epoch 366, Loss: 2.4066591262817383, Final Batch Loss: 0.6584978103637695\n",
      "Epoch 367, Loss: 2.3560832142829895, Final Batch Loss: 0.5686925649642944\n",
      "Epoch 368, Loss: 2.437828004360199, Final Batch Loss: 0.6459214687347412\n",
      "Epoch 369, Loss: 2.4436625838279724, Final Batch Loss: 0.6554005146026611\n",
      "Epoch 370, Loss: 2.4515169262886047, Final Batch Loss: 0.5597086548805237\n",
      "Epoch 371, Loss: 2.4594271779060364, Final Batch Loss: 0.7564579844474792\n",
      "Epoch 372, Loss: 2.3658950328826904, Final Batch Loss: 0.551220178604126\n",
      "Epoch 373, Loss: 2.4060357213020325, Final Batch Loss: 0.5562271475791931\n",
      "Epoch 374, Loss: 2.410754680633545, Final Batch Loss: 0.504091739654541\n",
      "Epoch 375, Loss: 2.448568046092987, Final Batch Loss: 0.6235173344612122\n",
      "Epoch 376, Loss: 2.324149787425995, Final Batch Loss: 0.5686650276184082\n",
      "Epoch 377, Loss: 2.301779627799988, Final Batch Loss: 0.6022163033485413\n",
      "Epoch 378, Loss: 2.454551875591278, Final Batch Loss: 0.5847106575965881\n",
      "Epoch 379, Loss: 2.394041061401367, Final Batch Loss: 0.6769106984138489\n",
      "Epoch 380, Loss: 2.345139294862747, Final Batch Loss: 0.5891404151916504\n",
      "Epoch 381, Loss: 2.5129887461662292, Final Batch Loss: 0.6777827739715576\n",
      "Epoch 382, Loss: 2.3214763402938843, Final Batch Loss: 0.5777199864387512\n",
      "Epoch 383, Loss: 2.3936939239501953, Final Batch Loss: 0.7655807733535767\n",
      "Epoch 384, Loss: 2.400636851787567, Final Batch Loss: 0.6479058265686035\n",
      "Epoch 385, Loss: 2.3551878333091736, Final Batch Loss: 0.5727869868278503\n",
      "Epoch 386, Loss: 2.3174418807029724, Final Batch Loss: 0.6099391579627991\n",
      "Epoch 387, Loss: 2.3718379735946655, Final Batch Loss: 0.5477311611175537\n",
      "Epoch 388, Loss: 2.387862980365753, Final Batch Loss: 0.5256515741348267\n",
      "Epoch 389, Loss: 2.544542133808136, Final Batch Loss: 0.7210006713867188\n",
      "Epoch 390, Loss: 2.3846027851104736, Final Batch Loss: 0.6810386776924133\n",
      "Epoch 391, Loss: 2.3872631192207336, Final Batch Loss: 0.6223915219306946\n",
      "Epoch 392, Loss: 2.335666596889496, Final Batch Loss: 0.5477921366691589\n",
      "Epoch 393, Loss: 2.323275327682495, Final Batch Loss: 0.5613552927970886\n",
      "Epoch 394, Loss: 2.316561698913574, Final Batch Loss: 0.6129069924354553\n",
      "Epoch 395, Loss: 2.248404026031494, Final Batch Loss: 0.5327134132385254\n",
      "Epoch 396, Loss: 2.4338725209236145, Final Batch Loss: 0.7133119702339172\n",
      "Epoch 397, Loss: 2.313143312931061, Final Batch Loss: 0.6535547971725464\n",
      "Epoch 398, Loss: 2.2556969225406647, Final Batch Loss: 0.49679645895957947\n",
      "Epoch 399, Loss: 2.3595376014709473, Final Batch Loss: 0.512334942817688\n",
      "Epoch 400, Loss: 2.3937880396842957, Final Batch Loss: 0.603044331073761\n",
      "Epoch 401, Loss: 2.4469013810157776, Final Batch Loss: 0.6549792885780334\n",
      "Epoch 402, Loss: 2.31269770860672, Final Batch Loss: 0.5549651980400085\n",
      "Epoch 403, Loss: 2.303280532360077, Final Batch Loss: 0.4732939600944519\n",
      "Epoch 404, Loss: 2.2957398891448975, Final Batch Loss: 0.5249826908111572\n",
      "Epoch 405, Loss: 2.436645984649658, Final Batch Loss: 0.636478066444397\n",
      "Epoch 406, Loss: 2.2184693217277527, Final Batch Loss: 0.5017216801643372\n",
      "Epoch 407, Loss: 2.4012316465377808, Final Batch Loss: 0.6040043830871582\n",
      "Epoch 408, Loss: 2.4642882347106934, Final Batch Loss: 0.6270389556884766\n",
      "Epoch 409, Loss: 2.3700667023658752, Final Batch Loss: 0.5998471975326538\n",
      "Epoch 410, Loss: 2.3017134070396423, Final Batch Loss: 0.572545051574707\n",
      "Epoch 411, Loss: 2.30710232257843, Final Batch Loss: 0.6204919815063477\n",
      "Epoch 412, Loss: 2.3256703913211823, Final Batch Loss: 0.5426355600357056\n",
      "Epoch 413, Loss: 2.230093628168106, Final Batch Loss: 0.5730875134468079\n",
      "Epoch 414, Loss: 2.2169472575187683, Final Batch Loss: 0.5446518063545227\n",
      "Epoch 415, Loss: 2.306902825832367, Final Batch Loss: 0.5934932231903076\n",
      "Epoch 416, Loss: 2.3144257068634033, Final Batch Loss: 0.5539220571517944\n",
      "Epoch 417, Loss: 2.339302122592926, Final Batch Loss: 0.5192751884460449\n",
      "Epoch 418, Loss: 2.3290607631206512, Final Batch Loss: 0.5908557772636414\n",
      "Epoch 419, Loss: 2.314091384410858, Final Batch Loss: 0.5761002898216248\n",
      "Epoch 420, Loss: 2.2592427134513855, Final Batch Loss: 0.569165825843811\n",
      "Epoch 421, Loss: 2.262967050075531, Final Batch Loss: 0.5540691614151001\n",
      "Epoch 422, Loss: 2.2811012268066406, Final Batch Loss: 0.6323821544647217\n",
      "Epoch 423, Loss: 2.324377119541168, Final Batch Loss: 0.6737367510795593\n",
      "Epoch 424, Loss: 2.3693960905075073, Final Batch Loss: 0.6763665676116943\n",
      "Epoch 425, Loss: 2.3470661640167236, Final Batch Loss: 0.5670583248138428\n",
      "Epoch 426, Loss: 2.395102858543396, Final Batch Loss: 0.5747860074043274\n",
      "Epoch 427, Loss: 2.3834095001220703, Final Batch Loss: 0.6579965353012085\n",
      "Epoch 428, Loss: 2.4074090719223022, Final Batch Loss: 0.6144471168518066\n",
      "Epoch 429, Loss: 2.337165057659149, Final Batch Loss: 0.4881746172904968\n",
      "Epoch 430, Loss: 2.208264410495758, Final Batch Loss: 0.5573030710220337\n",
      "Epoch 431, Loss: 2.3662478923797607, Final Batch Loss: 0.5895797610282898\n",
      "Epoch 432, Loss: 2.4179227352142334, Final Batch Loss: 0.6355505585670471\n",
      "Epoch 433, Loss: 2.284528374671936, Final Batch Loss: 0.5804877281188965\n",
      "Epoch 434, Loss: 2.1811586916446686, Final Batch Loss: 0.4715002477169037\n",
      "Epoch 435, Loss: 2.399852693080902, Final Batch Loss: 0.6017172932624817\n",
      "Epoch 436, Loss: 2.3170048594474792, Final Batch Loss: 0.5751177072525024\n",
      "Epoch 437, Loss: 2.4495508074760437, Final Batch Loss: 0.7073439359664917\n",
      "Epoch 438, Loss: 2.2991210222244263, Final Batch Loss: 0.6265749335289001\n",
      "Epoch 439, Loss: 2.328315854072571, Final Batch Loss: 0.6595837473869324\n",
      "Epoch 440, Loss: 2.3222392797470093, Final Batch Loss: 0.635749340057373\n",
      "Epoch 441, Loss: 2.183670938014984, Final Batch Loss: 0.512149453163147\n",
      "Epoch 442, Loss: 2.2777697145938873, Final Batch Loss: 0.571009635925293\n",
      "Epoch 443, Loss: 2.2537951469421387, Final Batch Loss: 0.5558301210403442\n",
      "Epoch 444, Loss: 2.219284623861313, Final Batch Loss: 0.49902376532554626\n",
      "Epoch 445, Loss: 2.254681348800659, Final Batch Loss: 0.4661814570426941\n",
      "Epoch 446, Loss: 2.2265652418136597, Final Batch Loss: 0.49632036685943604\n",
      "Epoch 447, Loss: 2.1970196962356567, Final Batch Loss: 0.5690937042236328\n",
      "Epoch 448, Loss: 2.2574734687805176, Final Batch Loss: 0.5916011333465576\n",
      "Epoch 449, Loss: 2.2818780541419983, Final Batch Loss: 0.5681421160697937\n",
      "Epoch 450, Loss: 2.2170216143131256, Final Batch Loss: 0.5275624394416809\n",
      "Epoch 451, Loss: 2.2956265807151794, Final Batch Loss: 0.6018359661102295\n",
      "Epoch 452, Loss: 2.2413434982299805, Final Batch Loss: 0.5435595512390137\n",
      "Epoch 453, Loss: 2.237555980682373, Final Batch Loss: 0.5907725095748901\n",
      "Epoch 454, Loss: 2.1458203196525574, Final Batch Loss: 0.5185648202896118\n",
      "Epoch 455, Loss: 2.147497594356537, Final Batch Loss: 0.5249877572059631\n",
      "Epoch 456, Loss: 2.2021287083625793, Final Batch Loss: 0.52337247133255\n",
      "Epoch 457, Loss: 2.356608808040619, Final Batch Loss: 0.7192321419715881\n",
      "Epoch 458, Loss: 2.30727881193161, Final Batch Loss: 0.5188508033752441\n",
      "Epoch 459, Loss: 2.3253636956214905, Final Batch Loss: 0.5364336371421814\n",
      "Epoch 460, Loss: 2.280272603034973, Final Batch Loss: 0.6038907170295715\n",
      "Epoch 461, Loss: 2.2294942140579224, Final Batch Loss: 0.5295683145523071\n",
      "Epoch 462, Loss: 2.346245288848877, Final Batch Loss: 0.59462970495224\n",
      "Epoch 463, Loss: 2.285585582256317, Final Batch Loss: 0.5894485116004944\n",
      "Epoch 464, Loss: 2.249202400445938, Final Batch Loss: 0.6442753076553345\n",
      "Epoch 465, Loss: 2.125249594449997, Final Batch Loss: 0.4685100018978119\n",
      "Epoch 466, Loss: 2.2022871375083923, Final Batch Loss: 0.5555005669593811\n",
      "Epoch 467, Loss: 2.1460097432136536, Final Batch Loss: 0.5051299929618835\n",
      "Epoch 468, Loss: 2.167203962802887, Final Batch Loss: 0.5680038928985596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469, Loss: 2.307913064956665, Final Batch Loss: 0.5811082720756531\n",
      "Epoch 470, Loss: 2.157164990901947, Final Batch Loss: 0.5467043519020081\n",
      "Epoch 471, Loss: 2.2013357877731323, Final Batch Loss: 0.5021005868911743\n",
      "Epoch 472, Loss: 2.265878677368164, Final Batch Loss: 0.5734277963638306\n",
      "Epoch 473, Loss: 2.2826411724090576, Final Batch Loss: 0.6142022609710693\n",
      "Epoch 474, Loss: 2.185527205467224, Final Batch Loss: 0.526756763458252\n",
      "Epoch 475, Loss: 2.393193006515503, Final Batch Loss: 0.7754323482513428\n",
      "Epoch 476, Loss: 2.267684817314148, Final Batch Loss: 0.6578729748725891\n",
      "Epoch 477, Loss: 2.2593387961387634, Final Batch Loss: 0.5988275408744812\n",
      "Epoch 478, Loss: 2.1560438871383667, Final Batch Loss: 0.46074652671813965\n",
      "Epoch 479, Loss: 2.302128553390503, Final Batch Loss: 0.540520191192627\n",
      "Epoch 480, Loss: 2.177589327096939, Final Batch Loss: 0.48236533999443054\n",
      "Epoch 481, Loss: 2.2503591179847717, Final Batch Loss: 0.5488118529319763\n",
      "Epoch 482, Loss: 2.2300037145614624, Final Batch Loss: 0.6139663457870483\n",
      "Epoch 483, Loss: 2.1690905392169952, Final Batch Loss: 0.6233618855476379\n",
      "Epoch 484, Loss: 2.317320019006729, Final Batch Loss: 0.6262078285217285\n",
      "Epoch 485, Loss: 2.2064173221588135, Final Batch Loss: 0.5628624558448792\n",
      "Epoch 486, Loss: 2.1473326683044434, Final Batch Loss: 0.47096431255340576\n",
      "Epoch 487, Loss: 2.126986026763916, Final Batch Loss: 0.5119725465774536\n",
      "Epoch 488, Loss: 2.1283313035964966, Final Batch Loss: 0.45561540126800537\n",
      "Epoch 489, Loss: 2.2261186242103577, Final Batch Loss: 0.6630875468254089\n",
      "Epoch 490, Loss: 2.200719863176346, Final Batch Loss: 0.5839655995368958\n",
      "Epoch 491, Loss: 2.049551248550415, Final Batch Loss: 0.4605425000190735\n",
      "Epoch 492, Loss: 1.987378865480423, Final Batch Loss: 0.421579509973526\n",
      "Epoch 493, Loss: 2.1001044511795044, Final Batch Loss: 0.5318554043769836\n",
      "Epoch 494, Loss: 2.1226765513420105, Final Batch Loss: 0.5090806484222412\n",
      "Epoch 495, Loss: 2.3115740716457367, Final Batch Loss: 0.7145695090293884\n",
      "Epoch 496, Loss: 2.138172000646591, Final Batch Loss: 0.6049408912658691\n",
      "Epoch 497, Loss: 2.060497760772705, Final Batch Loss: 0.4625321626663208\n",
      "Epoch 498, Loss: 2.1980115175247192, Final Batch Loss: 0.5169613361358643\n",
      "Epoch 499, Loss: 2.0443479418754578, Final Batch Loss: 0.36634570360183716\n",
      "Epoch 500, Loss: 2.1972509920597076, Final Batch Loss: 0.6093541979789734\n",
      "Epoch 501, Loss: 2.211007058620453, Final Batch Loss: 0.5434131026268005\n",
      "Epoch 502, Loss: 2.272051125764847, Final Batch Loss: 0.517076313495636\n",
      "Epoch 503, Loss: 2.129273384809494, Final Batch Loss: 0.5471919775009155\n",
      "Epoch 504, Loss: 2.1975709199905396, Final Batch Loss: 0.5734981894493103\n",
      "Epoch 505, Loss: 2.243616759777069, Final Batch Loss: 0.6142801642417908\n",
      "Epoch 506, Loss: 2.257155656814575, Final Batch Loss: 0.5976729989051819\n",
      "Epoch 507, Loss: 2.2106540203094482, Final Batch Loss: 0.6174154281616211\n",
      "Epoch 508, Loss: 2.1646728217601776, Final Batch Loss: 0.6471707820892334\n",
      "Epoch 509, Loss: 2.2253794074058533, Final Batch Loss: 0.5576950311660767\n",
      "Epoch 510, Loss: 2.0630082488059998, Final Batch Loss: 0.513794481754303\n",
      "Epoch 511, Loss: 2.286290228366852, Final Batch Loss: 0.6205675005912781\n",
      "Epoch 512, Loss: 2.1620469987392426, Final Batch Loss: 0.49989572167396545\n",
      "Epoch 513, Loss: 2.194087266921997, Final Batch Loss: 0.5643909573554993\n",
      "Epoch 514, Loss: 2.092621624469757, Final Batch Loss: 0.520702064037323\n",
      "Epoch 515, Loss: 2.079049974679947, Final Batch Loss: 0.4586051404476166\n",
      "Epoch 516, Loss: 2.106754720211029, Final Batch Loss: 0.5474498867988586\n",
      "Epoch 517, Loss: 2.1237416863441467, Final Batch Loss: 0.482063353061676\n",
      "Epoch 518, Loss: 2.205672264099121, Final Batch Loss: 0.5787112712860107\n",
      "Epoch 519, Loss: 2.138091117143631, Final Batch Loss: 0.46374115347862244\n",
      "Epoch 520, Loss: 2.164889335632324, Final Batch Loss: 0.604094922542572\n",
      "Epoch 521, Loss: 2.1934186816215515, Final Batch Loss: 0.5840939879417419\n",
      "Epoch 522, Loss: 2.257235109806061, Final Batch Loss: 0.6257299184799194\n",
      "Epoch 523, Loss: 2.143536686897278, Final Batch Loss: 0.5286152362823486\n",
      "Epoch 524, Loss: 2.2349236607551575, Final Batch Loss: 0.5944889187812805\n",
      "Epoch 525, Loss: 2.0870623886585236, Final Batch Loss: 0.5258981585502625\n",
      "Epoch 526, Loss: 2.0355493128299713, Final Batch Loss: 0.516562283039093\n",
      "Epoch 527, Loss: 2.046153485774994, Final Batch Loss: 0.5265672206878662\n",
      "Epoch 528, Loss: 2.1419104039669037, Final Batch Loss: 0.6126354932785034\n",
      "Epoch 529, Loss: 2.0550079941749573, Final Batch Loss: 0.5437695384025574\n",
      "Epoch 530, Loss: 2.0671771466732025, Final Batch Loss: 0.461929589509964\n",
      "Epoch 531, Loss: 2.1509053111076355, Final Batch Loss: 0.5597213506698608\n",
      "Epoch 532, Loss: 2.2009255588054657, Final Batch Loss: 0.5938517451286316\n",
      "Epoch 533, Loss: 2.1668953001499176, Final Batch Loss: 0.5755411982536316\n",
      "Epoch 534, Loss: 2.023772358894348, Final Batch Loss: 0.5103177428245544\n",
      "Epoch 535, Loss: 2.154661387205124, Final Batch Loss: 0.5609631538391113\n",
      "Epoch 536, Loss: 2.110872596502304, Final Batch Loss: 0.5597158670425415\n",
      "Epoch 537, Loss: 2.2071890830993652, Final Batch Loss: 0.6486775279045105\n",
      "Epoch 538, Loss: 2.0400015711784363, Final Batch Loss: 0.39695075154304504\n",
      "Epoch 539, Loss: 2.3616585731506348, Final Batch Loss: 0.6446752548217773\n",
      "Epoch 540, Loss: 2.215935170650482, Final Batch Loss: 0.5809099078178406\n",
      "Epoch 541, Loss: 2.2513836324214935, Final Batch Loss: 0.7430866360664368\n",
      "Epoch 542, Loss: 1.960065335035324, Final Batch Loss: 0.4549165964126587\n",
      "Epoch 543, Loss: 2.1186895966529846, Final Batch Loss: 0.5420541763305664\n",
      "Epoch 544, Loss: 2.039790004491806, Final Batch Loss: 0.40276774764060974\n",
      "Epoch 545, Loss: 2.012353867292404, Final Batch Loss: 0.4114823639392853\n",
      "Epoch 546, Loss: 2.10517355799675, Final Batch Loss: 0.49186837673187256\n",
      "Epoch 547, Loss: 2.147155523300171, Final Batch Loss: 0.5118265151977539\n",
      "Epoch 548, Loss: 2.037718653678894, Final Batch Loss: 0.4450809359550476\n",
      "Epoch 549, Loss: 2.2190839052200317, Final Batch Loss: 0.6697726845741272\n",
      "Epoch 550, Loss: 2.0202128291130066, Final Batch Loss: 0.410535991191864\n",
      "Epoch 551, Loss: 2.057019054889679, Final Batch Loss: 0.5159102082252502\n",
      "Epoch 552, Loss: 2.0590247213840485, Final Batch Loss: 0.442060261964798\n",
      "Epoch 553, Loss: 1.9889220595359802, Final Batch Loss: 0.45392894744873047\n",
      "Epoch 554, Loss: 2.0113443434238434, Final Batch Loss: 0.5407782793045044\n",
      "Epoch 555, Loss: 1.9565441608428955, Final Batch Loss: 0.5301393270492554\n",
      "Epoch 556, Loss: 2.091701090335846, Final Batch Loss: 0.5697068572044373\n",
      "Epoch 557, Loss: 2.12263822555542, Final Batch Loss: 0.5482991933822632\n",
      "Epoch 558, Loss: 2.1024752855300903, Final Batch Loss: 0.5484600067138672\n",
      "Epoch 559, Loss: 2.0831885039806366, Final Batch Loss: 0.5186061263084412\n",
      "Epoch 560, Loss: 2.195879817008972, Final Batch Loss: 0.5763869881629944\n",
      "Epoch 561, Loss: 2.0772194862365723, Final Batch Loss: 0.4758329391479492\n",
      "Epoch 562, Loss: 2.0515618920326233, Final Batch Loss: 0.5100824236869812\n",
      "Epoch 563, Loss: 2.139986962080002, Final Batch Loss: 0.5693221688270569\n",
      "Epoch 564, Loss: 2.1294110119342804, Final Batch Loss: 0.6325941681861877\n",
      "Epoch 565, Loss: 2.076273024082184, Final Batch Loss: 0.6022776961326599\n",
      "Epoch 566, Loss: 2.043171852827072, Final Batch Loss: 0.5020633339881897\n",
      "Epoch 567, Loss: 2.2534191012382507, Final Batch Loss: 0.5257993340492249\n",
      "Epoch 568, Loss: 2.0093251168727875, Final Batch Loss: 0.42449280619621277\n",
      "Epoch 569, Loss: 2.0965255796909332, Final Batch Loss: 0.5139145255088806\n",
      "Epoch 570, Loss: 2.0684962272644043, Final Batch Loss: 0.5825031995773315\n",
      "Epoch 571, Loss: 2.2144236862659454, Final Batch Loss: 0.6623092889785767\n",
      "Epoch 572, Loss: 2.158114433288574, Final Batch Loss: 0.6083637475967407\n",
      "Epoch 573, Loss: 2.0513231456279755, Final Batch Loss: 0.514980673789978\n",
      "Epoch 574, Loss: 2.2853819727897644, Final Batch Loss: 0.5205561518669128\n",
      "Epoch 575, Loss: 2.098211318254471, Final Batch Loss: 0.48113057017326355\n",
      "Epoch 576, Loss: 2.0475337207317352, Final Batch Loss: 0.44315144419670105\n",
      "Epoch 577, Loss: 2.0973378121852875, Final Batch Loss: 0.47234299778938293\n",
      "Epoch 578, Loss: 2.039866268634796, Final Batch Loss: 0.47698336839675903\n",
      "Epoch 579, Loss: 2.024606317281723, Final Batch Loss: 0.5294724702835083\n",
      "Epoch 580, Loss: 2.0123420655727386, Final Batch Loss: 0.4899676442146301\n",
      "Epoch 581, Loss: 2.133948504924774, Final Batch Loss: 0.5196229219436646\n",
      "Epoch 582, Loss: 2.0508525371551514, Final Batch Loss: 0.443669855594635\n",
      "Epoch 583, Loss: 1.999297022819519, Final Batch Loss: 0.5052027106285095\n",
      "Epoch 584, Loss: 2.038712203502655, Final Batch Loss: 0.5164703130722046\n",
      "Epoch 585, Loss: 1.9785779416561127, Final Batch Loss: 0.5136955976486206\n",
      "Epoch 586, Loss: 2.075829893350601, Final Batch Loss: 0.48008182644844055\n",
      "Epoch 587, Loss: 2.10776424407959, Final Batch Loss: 0.5501216053962708\n",
      "Epoch 588, Loss: 1.900707721710205, Final Batch Loss: 0.37561696767807007\n",
      "Epoch 589, Loss: 2.084484040737152, Final Batch Loss: 0.49398258328437805\n",
      "Epoch 590, Loss: 2.0445447862148285, Final Batch Loss: 0.4802800714969635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591, Loss: 2.0760125815868378, Final Batch Loss: 0.5419114232063293\n",
      "Epoch 592, Loss: 2.0042575299739838, Final Batch Loss: 0.542093813419342\n",
      "Epoch 593, Loss: 2.0634841918945312, Final Batch Loss: 0.5153782963752747\n",
      "Epoch 594, Loss: 2.037073403596878, Final Batch Loss: 0.449339359998703\n",
      "Epoch 595, Loss: 1.96570885181427, Final Batch Loss: 0.4510478377342224\n",
      "Epoch 596, Loss: 1.9601030051708221, Final Batch Loss: 0.5185869336128235\n",
      "Epoch 597, Loss: 2.158210337162018, Final Batch Loss: 0.47053730487823486\n",
      "Epoch 598, Loss: 2.0694518089294434, Final Batch Loss: 0.532278835773468\n",
      "Epoch 599, Loss: 2.081801474094391, Final Batch Loss: 0.5055240988731384\n",
      "Epoch 600, Loss: 2.0530432760715485, Final Batch Loss: 0.5436161160469055\n",
      "Epoch 601, Loss: 2.0402953922748566, Final Batch Loss: 0.3956318199634552\n",
      "Epoch 602, Loss: 2.0870012640953064, Final Batch Loss: 0.47878390550613403\n",
      "Epoch 603, Loss: 2.0886334776878357, Final Batch Loss: 0.5649558901786804\n",
      "Epoch 604, Loss: 2.064969092607498, Final Batch Loss: 0.5942519307136536\n",
      "Epoch 605, Loss: 2.010851740837097, Final Batch Loss: 0.45254820585250854\n",
      "Epoch 606, Loss: 2.0111604630947113, Final Batch Loss: 0.5319527387619019\n",
      "Epoch 607, Loss: 2.0209779739379883, Final Batch Loss: 0.453758180141449\n",
      "Epoch 608, Loss: 2.0934999883174896, Final Batch Loss: 0.5257952213287354\n",
      "Epoch 609, Loss: 1.9431248903274536, Final Batch Loss: 0.3994414210319519\n",
      "Epoch 610, Loss: 1.934288501739502, Final Batch Loss: 0.5019065141677856\n",
      "Epoch 611, Loss: 1.994441270828247, Final Batch Loss: 0.5451708436012268\n",
      "Epoch 612, Loss: 1.9683793783187866, Final Batch Loss: 0.4743056893348694\n",
      "Epoch 613, Loss: 2.015656918287277, Final Batch Loss: 0.5246261954307556\n",
      "Epoch 614, Loss: 2.0365082919597626, Final Batch Loss: 0.4790332019329071\n",
      "Epoch 615, Loss: 2.0736468732357025, Final Batch Loss: 0.5196127891540527\n",
      "Epoch 616, Loss: 2.0319379568099976, Final Batch Loss: 0.5137183666229248\n",
      "Epoch 617, Loss: 2.020861178636551, Final Batch Loss: 0.5022403001785278\n",
      "Epoch 618, Loss: 2.0061022341251373, Final Batch Loss: 0.47165849804878235\n",
      "Epoch 619, Loss: 1.9764723181724548, Final Batch Loss: 0.5832282900810242\n",
      "Epoch 620, Loss: 1.948680728673935, Final Batch Loss: 0.4917995035648346\n",
      "Epoch 621, Loss: 1.9571811854839325, Final Batch Loss: 0.528953492641449\n",
      "Epoch 622, Loss: 2.043689638376236, Final Batch Loss: 0.5454710125923157\n",
      "Epoch 623, Loss: 2.0477150976657867, Final Batch Loss: 0.5226354002952576\n",
      "Epoch 624, Loss: 2.005924791097641, Final Batch Loss: 0.48471513390541077\n",
      "Epoch 625, Loss: 2.000122219324112, Final Batch Loss: 0.4758494794368744\n",
      "Epoch 626, Loss: 1.91852006316185, Final Batch Loss: 0.511206865310669\n",
      "Epoch 627, Loss: 1.9433335363864899, Final Batch Loss: 0.43289604783058167\n",
      "Epoch 628, Loss: 1.8493185639381409, Final Batch Loss: 0.4192291796207428\n",
      "Epoch 629, Loss: 1.9244219958782196, Final Batch Loss: 0.41232091188430786\n",
      "Epoch 630, Loss: 1.9426797330379486, Final Batch Loss: 0.3958015739917755\n",
      "Epoch 631, Loss: 2.090583473443985, Final Batch Loss: 0.6210945844650269\n",
      "Epoch 632, Loss: 2.3002872467041016, Final Batch Loss: 0.736357569694519\n",
      "Epoch 633, Loss: 2.0359452962875366, Final Batch Loss: 0.46432560682296753\n",
      "Epoch 634, Loss: 1.8867727518081665, Final Batch Loss: 0.32077425718307495\n",
      "Epoch 635, Loss: 1.9922324120998383, Final Batch Loss: 0.47751349210739136\n",
      "Epoch 636, Loss: 2.094809412956238, Final Batch Loss: 0.4745258688926697\n",
      "Epoch 637, Loss: 2.0252825319767, Final Batch Loss: 0.4557012617588043\n",
      "Epoch 638, Loss: 2.0032864809036255, Final Batch Loss: 0.5396502017974854\n",
      "Epoch 639, Loss: 2.021520435810089, Final Batch Loss: 0.5590884685516357\n",
      "Epoch 640, Loss: 1.9379677772521973, Final Batch Loss: 0.4548074007034302\n",
      "Epoch 641, Loss: 1.9911424815654755, Final Batch Loss: 0.4962851107120514\n",
      "Epoch 642, Loss: 2.0420194268226624, Final Batch Loss: 0.508023738861084\n",
      "Epoch 643, Loss: 2.078548014163971, Final Batch Loss: 0.45986589789390564\n",
      "Epoch 644, Loss: 2.0693622529506683, Final Batch Loss: 0.5337501764297485\n",
      "Epoch 645, Loss: 1.8514714241027832, Final Batch Loss: 0.4156474769115448\n",
      "Epoch 646, Loss: 2.0013489425182343, Final Batch Loss: 0.5641295313835144\n",
      "Epoch 647, Loss: 1.9957032203674316, Final Batch Loss: 0.4679485559463501\n",
      "Epoch 648, Loss: 1.9739949405193329, Final Batch Loss: 0.48285743594169617\n",
      "Epoch 649, Loss: 1.9756344556808472, Final Batch Loss: 0.49271950125694275\n",
      "Epoch 650, Loss: 2.1417942345142365, Final Batch Loss: 0.6210073828697205\n",
      "Epoch 651, Loss: 1.9194706678390503, Final Batch Loss: 0.43171021342277527\n",
      "Epoch 652, Loss: 1.8213067948818207, Final Batch Loss: 0.3695427179336548\n",
      "Epoch 653, Loss: 2.0379092693328857, Final Batch Loss: 0.5315653681755066\n",
      "Epoch 654, Loss: 2.0790224969387054, Final Batch Loss: 0.5588365793228149\n",
      "Epoch 655, Loss: 1.9514901340007782, Final Batch Loss: 0.44568300247192383\n",
      "Epoch 656, Loss: 1.942681223154068, Final Batch Loss: 0.5741251111030579\n",
      "Epoch 657, Loss: 2.0609034597873688, Final Batch Loss: 0.5873371362686157\n",
      "Epoch 658, Loss: 1.941674381494522, Final Batch Loss: 0.539192259311676\n",
      "Epoch 659, Loss: 1.9012827575206757, Final Batch Loss: 0.5237843990325928\n",
      "Epoch 660, Loss: 2.014314144849777, Final Batch Loss: 0.5347810387611389\n",
      "Epoch 661, Loss: 2.1875307857990265, Final Batch Loss: 0.6917033791542053\n",
      "Epoch 662, Loss: 2.09819033741951, Final Batch Loss: 0.5754054188728333\n",
      "Epoch 663, Loss: 1.8954467177391052, Final Batch Loss: 0.43453362584114075\n",
      "Epoch 664, Loss: 2.009184330701828, Final Batch Loss: 0.48635056614875793\n",
      "Epoch 665, Loss: 1.9608975052833557, Final Batch Loss: 0.5196382999420166\n",
      "Epoch 666, Loss: 1.8843035995960236, Final Batch Loss: 0.36097824573516846\n",
      "Epoch 667, Loss: 1.9465948343276978, Final Batch Loss: 0.4810667932033539\n",
      "Epoch 668, Loss: 1.873628705739975, Final Batch Loss: 0.49793991446495056\n",
      "Epoch 669, Loss: 2.0420421063899994, Final Batch Loss: 0.5720431208610535\n",
      "Epoch 670, Loss: 1.9664950966835022, Final Batch Loss: 0.5357690453529358\n",
      "Epoch 671, Loss: 1.9660986065864563, Final Batch Loss: 0.42550963163375854\n",
      "Epoch 672, Loss: 1.8896056413650513, Final Batch Loss: 0.5373483896255493\n",
      "Epoch 673, Loss: 1.90216463804245, Final Batch Loss: 0.433586448431015\n",
      "Epoch 674, Loss: 1.9908659160137177, Final Batch Loss: 0.5394883751869202\n",
      "Epoch 675, Loss: 1.9801787436008453, Final Batch Loss: 0.5009192228317261\n",
      "Epoch 676, Loss: 1.9047322273254395, Final Batch Loss: 0.45368894934654236\n",
      "Epoch 677, Loss: 2.0314636528491974, Final Batch Loss: 0.5947228670120239\n",
      "Epoch 678, Loss: 1.9467583000659943, Final Batch Loss: 0.3885687291622162\n",
      "Epoch 679, Loss: 1.882310688495636, Final Batch Loss: 0.4434168040752411\n",
      "Epoch 680, Loss: 2.0433735847473145, Final Batch Loss: 0.5823168158531189\n",
      "Epoch 681, Loss: 1.9171750843524933, Final Batch Loss: 0.46806591749191284\n",
      "Epoch 682, Loss: 1.9144011437892914, Final Batch Loss: 0.3874155282974243\n",
      "Epoch 683, Loss: 2.050373613834381, Final Batch Loss: 0.5232555866241455\n",
      "Epoch 684, Loss: 2.0188287794589996, Final Batch Loss: 0.5405287742614746\n",
      "Epoch 685, Loss: 1.9458256363868713, Final Batch Loss: 0.5561751127243042\n",
      "Epoch 686, Loss: 1.9623929560184479, Final Batch Loss: 0.5256345868110657\n",
      "Epoch 687, Loss: 1.9051029086112976, Final Batch Loss: 0.4646049439907074\n",
      "Epoch 688, Loss: 1.8942219018936157, Final Batch Loss: 0.35989758372306824\n",
      "Epoch 689, Loss: 1.8744542598724365, Final Batch Loss: 0.40098193287849426\n",
      "Epoch 690, Loss: 1.8849721550941467, Final Batch Loss: 0.42705586552619934\n",
      "Epoch 691, Loss: 2.0111089944839478, Final Batch Loss: 0.5223608613014221\n",
      "Epoch 692, Loss: 1.9134620428085327, Final Batch Loss: 0.46558353304862976\n",
      "Epoch 693, Loss: 1.8672677874565125, Final Batch Loss: 0.44061562418937683\n",
      "Epoch 694, Loss: 1.9052790403366089, Final Batch Loss: 0.45276230573654175\n",
      "Epoch 695, Loss: 1.876865178346634, Final Batch Loss: 0.4759717881679535\n",
      "Epoch 696, Loss: 1.89574533700943, Final Batch Loss: 0.4644838273525238\n",
      "Epoch 697, Loss: 1.8891803920269012, Final Batch Loss: 0.37998971343040466\n",
      "Epoch 698, Loss: 2.082562655210495, Final Batch Loss: 0.5414978861808777\n",
      "Epoch 699, Loss: 1.931314468383789, Final Batch Loss: 0.46967214345932007\n",
      "Epoch 700, Loss: 1.7473539412021637, Final Batch Loss: 0.34928640723228455\n",
      "Epoch 701, Loss: 1.9496633112430573, Final Batch Loss: 0.47280192375183105\n",
      "Epoch 702, Loss: 1.9869932532310486, Final Batch Loss: 0.5026951432228088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703, Loss: 1.954971820116043, Final Batch Loss: 0.46404170989990234\n",
      "Epoch 704, Loss: 1.924489676952362, Final Batch Loss: 0.4585195779800415\n",
      "Epoch 705, Loss: 1.9100567698478699, Final Batch Loss: 0.47395163774490356\n",
      "Epoch 706, Loss: 1.8814439475536346, Final Batch Loss: 0.41683951020240784\n",
      "Epoch 707, Loss: 1.90530127286911, Final Batch Loss: 0.4978880286216736\n",
      "Epoch 708, Loss: 1.794597178697586, Final Batch Loss: 0.3322173058986664\n",
      "Epoch 709, Loss: 1.9413480758666992, Final Batch Loss: 0.46121010184288025\n",
      "Epoch 710, Loss: 1.9152583479881287, Final Batch Loss: 0.4519135653972626\n",
      "Epoch 711, Loss: 1.8762815594673157, Final Batch Loss: 0.46181824803352356\n",
      "Epoch 712, Loss: 1.9801037013530731, Final Batch Loss: 0.48475778102874756\n",
      "Epoch 713, Loss: 1.9431714117527008, Final Batch Loss: 0.43824711441993713\n",
      "Epoch 714, Loss: 1.9116683304309845, Final Batch Loss: 0.3982229232788086\n",
      "Epoch 715, Loss: 1.8375982642173767, Final Batch Loss: 0.37721866369247437\n",
      "Epoch 716, Loss: 1.940794050693512, Final Batch Loss: 0.5010244250297546\n",
      "Epoch 717, Loss: 1.9858329892158508, Final Batch Loss: 0.5093318223953247\n",
      "Epoch 718, Loss: 1.9952000379562378, Final Batch Loss: 0.5308462977409363\n",
      "Epoch 719, Loss: 1.971746951341629, Final Batch Loss: 0.46239912509918213\n",
      "Epoch 720, Loss: 1.8751042187213898, Final Batch Loss: 0.45553722977638245\n",
      "Epoch 721, Loss: 1.8715137839317322, Final Batch Loss: 0.44370782375335693\n",
      "Epoch 722, Loss: 1.924790620803833, Final Batch Loss: 0.5441187620162964\n",
      "Epoch 723, Loss: 1.906207263469696, Final Batch Loss: 0.5822781324386597\n",
      "Epoch 724, Loss: 1.8919794261455536, Final Batch Loss: 0.48359760642051697\n",
      "Epoch 725, Loss: 1.895743042230606, Final Batch Loss: 0.44513943791389465\n",
      "Epoch 726, Loss: 1.9409562647342682, Final Batch Loss: 0.5022673606872559\n",
      "Epoch 727, Loss: 1.9254669547080994, Final Batch Loss: 0.4737175703048706\n",
      "Epoch 728, Loss: 2.0081808865070343, Final Batch Loss: 0.5475652813911438\n",
      "Epoch 729, Loss: 1.8755152523517609, Final Batch Loss: 0.4206693172454834\n",
      "Epoch 730, Loss: 1.8994636833667755, Final Batch Loss: 0.44283294677734375\n",
      "Epoch 731, Loss: 2.0521120131015778, Final Batch Loss: 0.6285315752029419\n",
      "Epoch 732, Loss: 1.889044165611267, Final Batch Loss: 0.5229136347770691\n",
      "Epoch 733, Loss: 1.997356116771698, Final Batch Loss: 0.5492380857467651\n",
      "Epoch 734, Loss: 1.846001923084259, Final Batch Loss: 0.39107614755630493\n",
      "Epoch 735, Loss: 1.8164407014846802, Final Batch Loss: 0.4178169071674347\n",
      "Epoch 736, Loss: 1.9862459003925323, Final Batch Loss: 0.567541241645813\n",
      "Epoch 737, Loss: 2.01865354180336, Final Batch Loss: 0.5661044120788574\n",
      "Epoch 738, Loss: 2.0214502215385437, Final Batch Loss: 0.40681666135787964\n",
      "Epoch 739, Loss: 1.8760830760002136, Final Batch Loss: 0.4214380979537964\n",
      "Epoch 740, Loss: 1.9068845808506012, Final Batch Loss: 0.45204687118530273\n",
      "Epoch 741, Loss: 1.8430883884429932, Final Batch Loss: 0.4150257408618927\n",
      "Epoch 742, Loss: 1.94050133228302, Final Batch Loss: 0.5255553126335144\n",
      "Epoch 743, Loss: 1.975803405046463, Final Batch Loss: 0.45422136783599854\n",
      "Epoch 744, Loss: 1.8121946156024933, Final Batch Loss: 0.42228013277053833\n",
      "Epoch 745, Loss: 1.8945260345935822, Final Batch Loss: 0.41050875186920166\n",
      "Epoch 746, Loss: 1.9319579303264618, Final Batch Loss: 0.5019076466560364\n",
      "Epoch 747, Loss: 1.929284244775772, Final Batch Loss: 0.5420287251472473\n",
      "Epoch 748, Loss: 1.8621965050697327, Final Batch Loss: 0.3962475657463074\n",
      "Epoch 749, Loss: 1.8644118010997772, Final Batch Loss: 0.4231085479259491\n",
      "Epoch 750, Loss: 2.0551628172397614, Final Batch Loss: 0.6051229238510132\n",
      "Epoch 751, Loss: 1.9576485753059387, Final Batch Loss: 0.4818059206008911\n",
      "Epoch 752, Loss: 2.0115594267845154, Final Batch Loss: 0.5236509442329407\n",
      "Epoch 753, Loss: 1.870935320854187, Final Batch Loss: 0.4696792662143707\n",
      "Epoch 754, Loss: 1.9731087684631348, Final Batch Loss: 0.4634164869785309\n",
      "Epoch 755, Loss: 1.864868700504303, Final Batch Loss: 0.5322282910346985\n",
      "Epoch 756, Loss: 1.879227191209793, Final Batch Loss: 0.371209979057312\n",
      "Epoch 757, Loss: 1.88146510720253, Final Batch Loss: 0.4700744152069092\n",
      "Epoch 758, Loss: 1.982200562953949, Final Batch Loss: 0.5639856457710266\n",
      "Epoch 759, Loss: 1.8789490461349487, Final Batch Loss: 0.5001639127731323\n",
      "Epoch 760, Loss: 1.8542006313800812, Final Batch Loss: 0.4777147173881531\n",
      "Epoch 761, Loss: 1.9140529036521912, Final Batch Loss: 0.4322067201137543\n",
      "Epoch 762, Loss: 1.881056785583496, Final Batch Loss: 0.4252104163169861\n",
      "Epoch 763, Loss: 1.9239719808101654, Final Batch Loss: 0.4656428396701813\n",
      "Epoch 764, Loss: 1.774825394153595, Final Batch Loss: 0.38962239027023315\n",
      "Epoch 765, Loss: 1.8445086181163788, Final Batch Loss: 0.5040136575698853\n",
      "Epoch 766, Loss: 1.9119491577148438, Final Batch Loss: 0.471226304769516\n",
      "Epoch 767, Loss: 1.7971616983413696, Final Batch Loss: 0.46319401264190674\n",
      "Epoch 768, Loss: 1.940427839756012, Final Batch Loss: 0.5126016736030579\n",
      "Epoch 769, Loss: 1.7903368771076202, Final Batch Loss: 0.5060315132141113\n",
      "Epoch 770, Loss: 1.8655457496643066, Final Batch Loss: 0.4578344523906708\n",
      "Epoch 771, Loss: 1.838284820318222, Final Batch Loss: 0.3526187837123871\n",
      "Epoch 772, Loss: 1.9047485291957855, Final Batch Loss: 0.4686031639575958\n",
      "Epoch 773, Loss: 1.8846586346626282, Final Batch Loss: 0.439167320728302\n",
      "Epoch 774, Loss: 1.9385524988174438, Final Batch Loss: 0.5481864213943481\n",
      "Epoch 775, Loss: 1.8863458037376404, Final Batch Loss: 0.4865705370903015\n",
      "Epoch 776, Loss: 1.8390984237194061, Final Batch Loss: 0.4513654112815857\n",
      "Epoch 777, Loss: 1.825857698917389, Final Batch Loss: 0.37108373641967773\n",
      "Epoch 778, Loss: 2.0038610994815826, Final Batch Loss: 0.4846350848674774\n",
      "Epoch 779, Loss: 2.0546742379665375, Final Batch Loss: 0.5092394351959229\n",
      "Epoch 780, Loss: 1.837692528963089, Final Batch Loss: 0.41562268137931824\n",
      "Epoch 781, Loss: 1.9248355031013489, Final Batch Loss: 0.46386411786079407\n",
      "Epoch 782, Loss: 1.772390753030777, Final Batch Loss: 0.4944108724594116\n",
      "Epoch 783, Loss: 1.8457346856594086, Final Batch Loss: 0.4708554446697235\n",
      "Epoch 784, Loss: 1.848461002111435, Final Batch Loss: 0.42429018020629883\n",
      "Epoch 785, Loss: 1.7818224132061005, Final Batch Loss: 0.42250168323516846\n",
      "Epoch 786, Loss: 1.9038573801517487, Final Batch Loss: 0.4401089549064636\n",
      "Epoch 787, Loss: 1.7335247099399567, Final Batch Loss: 0.4167028069496155\n",
      "Epoch 788, Loss: 2.0660479068756104, Final Batch Loss: 0.7557641267776489\n",
      "Epoch 789, Loss: 1.9600932896137238, Final Batch Loss: 0.5232258439064026\n",
      "Epoch 790, Loss: 1.949742168188095, Final Batch Loss: 0.5799814462661743\n",
      "Epoch 791, Loss: 2.0553797483444214, Final Batch Loss: 0.47832342982292175\n",
      "Epoch 792, Loss: 1.9738229513168335, Final Batch Loss: 0.5885726809501648\n",
      "Epoch 793, Loss: 1.919274628162384, Final Batch Loss: 0.5666379332542419\n",
      "Epoch 794, Loss: 1.8210654854774475, Final Batch Loss: 0.4705567955970764\n",
      "Epoch 795, Loss: 1.9058780670166016, Final Batch Loss: 0.45577266812324524\n",
      "Epoch 796, Loss: 1.9104375541210175, Final Batch Loss: 0.44744041562080383\n",
      "Epoch 797, Loss: 1.7235368192195892, Final Batch Loss: 0.3500424921512604\n",
      "Epoch 798, Loss: 1.9353740513324738, Final Batch Loss: 0.540755033493042\n",
      "Epoch 799, Loss: 1.8615979552268982, Final Batch Loss: 0.4707905948162079\n",
      "Epoch 800, Loss: 1.771684169769287, Final Batch Loss: 0.31733301281929016\n",
      "Epoch 801, Loss: 1.8557314574718475, Final Batch Loss: 0.47745755314826965\n",
      "Epoch 802, Loss: 1.8933018445968628, Final Batch Loss: 0.5202155113220215\n",
      "Epoch 803, Loss: 1.990831196308136, Final Batch Loss: 0.5469349026679993\n",
      "Epoch 804, Loss: 1.9411418735980988, Final Batch Loss: 0.5487017035484314\n",
      "Epoch 805, Loss: 1.8328849971294403, Final Batch Loss: 0.45064952969551086\n",
      "Epoch 806, Loss: 1.826373428106308, Final Batch Loss: 0.43953654170036316\n",
      "Epoch 807, Loss: 2.085162729024887, Final Batch Loss: 0.5030050277709961\n",
      "Epoch 808, Loss: 1.8817231059074402, Final Batch Loss: 0.5498902201652527\n",
      "Epoch 809, Loss: 1.8704167306423187, Final Batch Loss: 0.4918072521686554\n",
      "Epoch 810, Loss: 1.8643344938755035, Final Batch Loss: 0.522152841091156\n",
      "Epoch 811, Loss: 1.9160062670707703, Final Batch Loss: 0.48954683542251587\n",
      "Epoch 812, Loss: 1.8264682590961456, Final Batch Loss: 0.4328094720840454\n",
      "Epoch 813, Loss: 1.8357148468494415, Final Batch Loss: 0.47743135690689087\n",
      "Epoch 814, Loss: 1.797514021396637, Final Batch Loss: 0.43050506711006165\n",
      "Epoch 815, Loss: 1.7489081025123596, Final Batch Loss: 0.3801861107349396\n",
      "Epoch 816, Loss: 1.7976248860359192, Final Batch Loss: 0.4421321153640747\n",
      "Epoch 817, Loss: 1.839629590511322, Final Batch Loss: 0.5448362827301025\n",
      "Epoch 818, Loss: 1.8446416556835175, Final Batch Loss: 0.5191653966903687\n",
      "Epoch 819, Loss: 1.7856812477111816, Final Batch Loss: 0.4133058786392212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820, Loss: 1.8001234233379364, Final Batch Loss: 0.4118734300136566\n",
      "Epoch 821, Loss: 1.8301637172698975, Final Batch Loss: 0.4745897650718689\n",
      "Epoch 822, Loss: 1.8322865068912506, Final Batch Loss: 0.3300808370113373\n",
      "Epoch 823, Loss: 1.7988631129264832, Final Batch Loss: 0.4504636228084564\n",
      "Epoch 824, Loss: 1.9513631463050842, Final Batch Loss: 0.4920733869075775\n",
      "Epoch 825, Loss: 1.8154438138008118, Final Batch Loss: 0.43510961532592773\n",
      "Epoch 826, Loss: 1.878010630607605, Final Batch Loss: 0.5332915186882019\n",
      "Epoch 827, Loss: 1.7668682038784027, Final Batch Loss: 0.42810386419296265\n",
      "Epoch 828, Loss: 1.7738088965415955, Final Batch Loss: 0.40338459610939026\n",
      "Epoch 829, Loss: 1.8067576587200165, Final Batch Loss: 0.42772412300109863\n",
      "Epoch 830, Loss: 1.925240010023117, Final Batch Loss: 0.3664857745170593\n",
      "Epoch 831, Loss: 1.840368777513504, Final Batch Loss: 0.45137423276901245\n",
      "Epoch 832, Loss: 1.8454084396362305, Final Batch Loss: 0.4386621415615082\n",
      "Epoch 833, Loss: 1.814858615398407, Final Batch Loss: 0.5432602763175964\n",
      "Epoch 834, Loss: 1.8508325517177582, Final Batch Loss: 0.47565093636512756\n",
      "Epoch 835, Loss: 1.7656736969947815, Final Batch Loss: 0.4171578586101532\n",
      "Epoch 836, Loss: 1.9372502267360687, Final Batch Loss: 0.5283545255661011\n",
      "Epoch 837, Loss: 1.8825467824935913, Final Batch Loss: 0.5115078091621399\n",
      "Epoch 838, Loss: 1.915915459394455, Final Batch Loss: 0.594628095626831\n",
      "Epoch 839, Loss: 1.979605346918106, Final Batch Loss: 0.5964056849479675\n",
      "Epoch 840, Loss: 1.9114825129508972, Final Batch Loss: 0.40804919600486755\n",
      "Epoch 841, Loss: 1.7874704599380493, Final Batch Loss: 0.4818382263183594\n",
      "Epoch 842, Loss: 1.972695678472519, Final Batch Loss: 0.5675963163375854\n",
      "Epoch 843, Loss: 1.9131283164024353, Final Batch Loss: 0.5179457068443298\n",
      "Epoch 844, Loss: 1.8389863967895508, Final Batch Loss: 0.44727662205696106\n",
      "Epoch 845, Loss: 1.8028452396392822, Final Batch Loss: 0.49964919686317444\n",
      "Epoch 846, Loss: 1.7909983694553375, Final Batch Loss: 0.4774617850780487\n",
      "Epoch 847, Loss: 1.8368145525455475, Final Batch Loss: 0.3775809407234192\n",
      "Epoch 848, Loss: 1.783367097377777, Final Batch Loss: 0.42336469888687134\n",
      "Epoch 849, Loss: 1.9260291457176208, Final Batch Loss: 0.46620529890060425\n",
      "Epoch 850, Loss: 1.7491861879825592, Final Batch Loss: 0.4063686728477478\n",
      "Epoch 851, Loss: 1.8258993029594421, Final Batch Loss: 0.4683188199996948\n",
      "Epoch 852, Loss: 1.9139385521411896, Final Batch Loss: 0.43559765815734863\n",
      "Epoch 853, Loss: 1.9195128977298737, Final Batch Loss: 0.4866940677165985\n",
      "Epoch 854, Loss: 1.787327378988266, Final Batch Loss: 0.4030091464519501\n",
      "Epoch 855, Loss: 1.7568148970603943, Final Batch Loss: 0.39762362837791443\n",
      "Epoch 856, Loss: 1.7733841836452484, Final Batch Loss: 0.39195969700813293\n",
      "Epoch 857, Loss: 1.9102741181850433, Final Batch Loss: 0.5564345121383667\n",
      "Epoch 858, Loss: 1.7826789319515228, Final Batch Loss: 0.4660223424434662\n",
      "Epoch 859, Loss: 1.6646399199962616, Final Batch Loss: 0.3645210862159729\n",
      "Epoch 860, Loss: 1.8102522492408752, Final Batch Loss: 0.428310364484787\n",
      "Epoch 861, Loss: 1.7144761979579926, Final Batch Loss: 0.42804810404777527\n",
      "Epoch 862, Loss: 1.675281971693039, Final Batch Loss: 0.4074248671531677\n",
      "Epoch 863, Loss: 1.8083742558956146, Final Batch Loss: 0.47857773303985596\n",
      "Epoch 864, Loss: 1.9307017624378204, Final Batch Loss: 0.5097760558128357\n",
      "Epoch 865, Loss: 1.8951716125011444, Final Batch Loss: 0.4370228052139282\n",
      "Epoch 866, Loss: 1.9074771106243134, Final Batch Loss: 0.5112833380699158\n",
      "Epoch 867, Loss: 1.6978475451469421, Final Batch Loss: 0.42380785942077637\n",
      "Epoch 868, Loss: 1.8796437084674835, Final Batch Loss: 0.5427026748657227\n",
      "Epoch 869, Loss: 1.8637756705284119, Final Batch Loss: 0.5060155987739563\n",
      "Epoch 870, Loss: 1.7472254037857056, Final Batch Loss: 0.410382479429245\n",
      "Epoch 871, Loss: 1.6737495362758636, Final Batch Loss: 0.3924335539340973\n",
      "Epoch 872, Loss: 1.8461028933525085, Final Batch Loss: 0.43092888593673706\n",
      "Epoch 873, Loss: 1.7701549530029297, Final Batch Loss: 0.4702449142932892\n",
      "Epoch 874, Loss: 1.7589107155799866, Final Batch Loss: 0.38670969009399414\n",
      "Epoch 875, Loss: 1.6920407116413116, Final Batch Loss: 0.34313035011291504\n",
      "Epoch 876, Loss: 1.680087685585022, Final Batch Loss: 0.3707800805568695\n",
      "Epoch 877, Loss: 1.7489729523658752, Final Batch Loss: 0.4182312786579132\n",
      "Epoch 878, Loss: 1.8411140441894531, Final Batch Loss: 0.45147016644477844\n",
      "Epoch 879, Loss: 1.7420697212219238, Final Batch Loss: 0.43275681138038635\n",
      "Epoch 880, Loss: 1.6406380534172058, Final Batch Loss: 0.3813099265098572\n",
      "Epoch 881, Loss: 1.7309353649616241, Final Batch Loss: 0.48236408829689026\n",
      "Epoch 882, Loss: 1.9084136486053467, Final Batch Loss: 0.4776684641838074\n",
      "Epoch 883, Loss: 1.8810158669948578, Final Batch Loss: 0.5398263335227966\n",
      "Epoch 884, Loss: 1.7568511664867401, Final Batch Loss: 0.35549768805503845\n",
      "Epoch 885, Loss: 1.7702676057815552, Final Batch Loss: 0.37369072437286377\n",
      "Epoch 886, Loss: 1.8608358204364777, Final Batch Loss: 0.532035768032074\n",
      "Epoch 887, Loss: 1.9041089117527008, Final Batch Loss: 0.5153859257698059\n",
      "Epoch 888, Loss: 1.6461847126483917, Final Batch Loss: 0.41055840253829956\n",
      "Epoch 889, Loss: 1.7673314213752747, Final Batch Loss: 0.4925910234451294\n",
      "Epoch 890, Loss: 1.8200852274894714, Final Batch Loss: 0.42465129494667053\n",
      "Epoch 891, Loss: 1.7563499510288239, Final Batch Loss: 0.40395236015319824\n",
      "Epoch 892, Loss: 1.7738795280456543, Final Batch Loss: 0.47106248140335083\n",
      "Epoch 893, Loss: 2.0030623376369476, Final Batch Loss: 0.6456745266914368\n",
      "Epoch 894, Loss: 1.8157671988010406, Final Batch Loss: 0.44284921884536743\n",
      "Epoch 895, Loss: 1.8666635155677795, Final Batch Loss: 0.6223081946372986\n",
      "Epoch 896, Loss: 1.7436705827713013, Final Batch Loss: 0.3890131115913391\n",
      "Epoch 897, Loss: 1.7894136309623718, Final Batch Loss: 0.3969719111919403\n",
      "Epoch 898, Loss: 1.7742739617824554, Final Batch Loss: 0.3902260363101959\n",
      "Epoch 899, Loss: 1.8864429593086243, Final Batch Loss: 0.6181674003601074\n",
      "Epoch 900, Loss: 1.7966980934143066, Final Batch Loss: 0.5715680122375488\n",
      "Epoch 901, Loss: 1.939639925956726, Final Batch Loss: 0.5342785120010376\n",
      "Epoch 902, Loss: 1.7660572528839111, Final Batch Loss: 0.36073291301727295\n",
      "Epoch 903, Loss: 1.731230616569519, Final Batch Loss: 0.4751593768596649\n",
      "Epoch 904, Loss: 1.9067840874195099, Final Batch Loss: 0.521239697933197\n",
      "Epoch 905, Loss: 1.9231979846954346, Final Batch Loss: 0.3531093895435333\n",
      "Epoch 906, Loss: 1.7920747101306915, Final Batch Loss: 0.47686153650283813\n",
      "Epoch 907, Loss: 1.7894121408462524, Final Batch Loss: 0.50384122133255\n",
      "Epoch 908, Loss: 1.9225869178771973, Final Batch Loss: 0.6070114970207214\n",
      "Epoch 909, Loss: 1.7241307497024536, Final Batch Loss: 0.44282129406929016\n",
      "Epoch 910, Loss: 1.8040818274021149, Final Batch Loss: 0.41567838191986084\n",
      "Epoch 911, Loss: 1.8909737169742584, Final Batch Loss: 0.5171040892601013\n",
      "Epoch 912, Loss: 1.8463955223560333, Final Batch Loss: 0.5018617510795593\n",
      "Epoch 913, Loss: 1.8236965537071228, Final Batch Loss: 0.5118922591209412\n",
      "Epoch 914, Loss: 1.7360329926013947, Final Batch Loss: 0.3946659564971924\n",
      "Epoch 915, Loss: 1.7508737444877625, Final Batch Loss: 0.469926655292511\n",
      "Epoch 916, Loss: 1.7985898554325104, Final Batch Loss: 0.31522780656814575\n",
      "Epoch 917, Loss: 1.680492877960205, Final Batch Loss: 0.4158257842063904\n",
      "Epoch 918, Loss: 1.9142135083675385, Final Batch Loss: 0.5662276148796082\n",
      "Epoch 919, Loss: 1.9144919216632843, Final Batch Loss: 0.49589645862579346\n",
      "Epoch 920, Loss: 1.732358992099762, Final Batch Loss: 0.3852050304412842\n",
      "Epoch 921, Loss: 1.7837098240852356, Final Batch Loss: 0.49810469150543213\n",
      "Epoch 922, Loss: 1.7408026456832886, Final Batch Loss: 0.4066877067089081\n",
      "Epoch 923, Loss: 1.868911325931549, Final Batch Loss: 0.4119342565536499\n",
      "Epoch 924, Loss: 1.6963801085948944, Final Batch Loss: 0.33395642042160034\n",
      "Epoch 925, Loss: 1.7150024771690369, Final Batch Loss: 0.4203437566757202\n",
      "Epoch 926, Loss: 1.8158142566680908, Final Batch Loss: 0.5629298686981201\n",
      "Epoch 927, Loss: 1.7860398888587952, Final Batch Loss: 0.34841445088386536\n",
      "Epoch 928, Loss: 1.889760434627533, Final Batch Loss: 0.5562758445739746\n",
      "Epoch 929, Loss: 1.8688335716724396, Final Batch Loss: 0.3944658041000366\n",
      "Epoch 930, Loss: 1.8370218575000763, Final Batch Loss: 0.49493563175201416\n",
      "Epoch 931, Loss: 1.8377844989299774, Final Batch Loss: 0.5353116989135742\n",
      "Epoch 932, Loss: 1.8351146578788757, Final Batch Loss: 0.46467524766921997\n",
      "Epoch 933, Loss: 1.862438827753067, Final Batch Loss: 0.4529893398284912\n",
      "Epoch 934, Loss: 1.8349125385284424, Final Batch Loss: 0.5186617374420166\n",
      "Epoch 935, Loss: 1.6891590356826782, Final Batch Loss: 0.47137272357940674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936, Loss: 1.6825544834136963, Final Batch Loss: 0.40119338035583496\n",
      "Epoch 937, Loss: 1.691065102815628, Final Batch Loss: 0.3817356824874878\n",
      "Epoch 938, Loss: 1.9092731475830078, Final Batch Loss: 0.5458049774169922\n",
      "Epoch 939, Loss: 1.9705336093902588, Final Batch Loss: 0.6637508869171143\n",
      "Epoch 940, Loss: 1.840563416481018, Final Batch Loss: 0.38761910796165466\n",
      "Epoch 941, Loss: 1.6706677973270416, Final Batch Loss: 0.41289228200912476\n",
      "Epoch 942, Loss: 1.835110753774643, Final Batch Loss: 0.49430781602859497\n",
      "Epoch 943, Loss: 1.7095154821872711, Final Batch Loss: 0.3804014325141907\n",
      "Epoch 944, Loss: 1.7990098595619202, Final Batch Loss: 0.4422135353088379\n",
      "Epoch 945, Loss: 1.7812634110450745, Final Batch Loss: 0.4397538900375366\n",
      "Epoch 946, Loss: 1.7341043949127197, Final Batch Loss: 0.38458967208862305\n",
      "Epoch 947, Loss: 1.6624499261379242, Final Batch Loss: 0.3693293035030365\n",
      "Epoch 948, Loss: 1.667848825454712, Final Batch Loss: 0.4150036573410034\n",
      "Epoch 949, Loss: 1.7764009833335876, Final Batch Loss: 0.4331357777118683\n",
      "Epoch 950, Loss: 2.0412758588790894, Final Batch Loss: 0.6263752579689026\n",
      "Epoch 951, Loss: 1.6066583096981049, Final Batch Loss: 0.33927860856056213\n",
      "Epoch 952, Loss: 1.9024608135223389, Final Batch Loss: 0.5441489219665527\n",
      "Epoch 953, Loss: 1.7523866593837738, Final Batch Loss: 0.3944067060947418\n",
      "Epoch 954, Loss: 1.7989273965358734, Final Batch Loss: 0.40535596013069153\n",
      "Epoch 955, Loss: 1.8039597272872925, Final Batch Loss: 0.39210668206214905\n",
      "Epoch 956, Loss: 1.7696716487407684, Final Batch Loss: 0.4762824773788452\n",
      "Epoch 957, Loss: 1.8373193144798279, Final Batch Loss: 0.5691150426864624\n",
      "Epoch 958, Loss: 1.7839997708797455, Final Batch Loss: 0.38190317153930664\n",
      "Epoch 959, Loss: 1.7903308272361755, Final Batch Loss: 0.5778821110725403\n",
      "Epoch 960, Loss: 1.780680537223816, Final Batch Loss: 0.48390546441078186\n",
      "Epoch 961, Loss: 1.7689854204654694, Final Batch Loss: 0.4576204717159271\n",
      "Epoch 962, Loss: 1.8303149044513702, Final Batch Loss: 0.48852261900901794\n",
      "Epoch 963, Loss: 1.7243272960186005, Final Batch Loss: 0.41100013256073\n",
      "Epoch 964, Loss: 1.7534420490264893, Final Batch Loss: 0.3914726972579956\n",
      "Epoch 965, Loss: 1.8442996740341187, Final Batch Loss: 0.4233890771865845\n",
      "Epoch 966, Loss: 1.7483360171318054, Final Batch Loss: 0.3576531410217285\n",
      "Epoch 967, Loss: 1.684910148382187, Final Batch Loss: 0.4230969548225403\n",
      "Epoch 968, Loss: 1.8173848390579224, Final Batch Loss: 0.41694149374961853\n",
      "Epoch 969, Loss: 1.707038700580597, Final Batch Loss: 0.35598695278167725\n",
      "Epoch 970, Loss: 1.6473740339279175, Final Batch Loss: 0.357430100440979\n",
      "Epoch 971, Loss: 1.6851620376110077, Final Batch Loss: 0.3989608883857727\n",
      "Epoch 972, Loss: 1.653537392616272, Final Batch Loss: 0.33862975239753723\n",
      "Epoch 973, Loss: 1.6786428689956665, Final Batch Loss: 0.4656331539154053\n",
      "Epoch 974, Loss: 1.7822155952453613, Final Batch Loss: 0.44164639711380005\n",
      "Epoch 975, Loss: 1.6964218020439148, Final Batch Loss: 0.4128004312515259\n",
      "Epoch 976, Loss: 1.6759759187698364, Final Batch Loss: 0.3363249897956848\n",
      "Epoch 977, Loss: 1.7968103885650635, Final Batch Loss: 0.4394371509552002\n",
      "Epoch 978, Loss: 1.8956907093524933, Final Batch Loss: 0.47522297501564026\n",
      "Epoch 979, Loss: 1.7379634082317352, Final Batch Loss: 0.49823078513145447\n",
      "Epoch 980, Loss: 1.8315791189670563, Final Batch Loss: 0.5525984168052673\n",
      "Epoch 981, Loss: 1.6993889212608337, Final Batch Loss: 0.40959978103637695\n",
      "Epoch 982, Loss: 1.7041148245334625, Final Batch Loss: 0.4111080765724182\n",
      "Epoch 983, Loss: 1.6823588609695435, Final Batch Loss: 0.40809914469718933\n",
      "Epoch 984, Loss: 1.6859539151191711, Final Batch Loss: 0.4045836925506592\n",
      "Epoch 985, Loss: 1.7364746034145355, Final Batch Loss: 0.46710753440856934\n",
      "Epoch 986, Loss: 1.658455729484558, Final Batch Loss: 0.39408984780311584\n",
      "Epoch 987, Loss: 1.7285121381282806, Final Batch Loss: 0.41425931453704834\n",
      "Epoch 988, Loss: 1.677069902420044, Final Batch Loss: 0.3781448006629944\n",
      "Epoch 989, Loss: 1.6790124773979187, Final Batch Loss: 0.4196670651435852\n",
      "Epoch 990, Loss: 1.781126230955124, Final Batch Loss: 0.4093427360057831\n",
      "Epoch 991, Loss: 1.5266508162021637, Final Batch Loss: 0.34226879477500916\n",
      "Epoch 992, Loss: 1.6852953135967255, Final Batch Loss: 0.4188868999481201\n",
      "Epoch 993, Loss: 1.7169720828533173, Final Batch Loss: 0.4443148374557495\n",
      "Epoch 994, Loss: 1.691342830657959, Final Batch Loss: 0.5127899050712585\n",
      "Epoch 995, Loss: 1.6358124911785126, Final Batch Loss: 0.39637336134910583\n",
      "Epoch 996, Loss: 1.6606581807136536, Final Batch Loss: 0.36558768153190613\n",
      "Epoch 997, Loss: 1.7608617544174194, Final Batch Loss: 0.4727182984352112\n",
      "Epoch 998, Loss: 1.5667684376239777, Final Batch Loss: 0.370464950799942\n",
      "Epoch 999, Loss: 1.6845976114273071, Final Batch Loss: 0.41011473536491394\n",
      "Epoch 1000, Loss: 1.7574060559272766, Final Batch Loss: 0.33884480595588684\n",
      "Epoch 1001, Loss: 1.7596955001354218, Final Batch Loss: 0.3783809244632721\n",
      "Epoch 1002, Loss: 1.7601423859596252, Final Batch Loss: 0.415402889251709\n",
      "Epoch 1003, Loss: 1.825561672449112, Final Batch Loss: 0.46944740414619446\n",
      "Epoch 1004, Loss: 1.7851892709732056, Final Batch Loss: 0.4819955825805664\n",
      "Epoch 1005, Loss: 1.6822108626365662, Final Batch Loss: 0.3129681944847107\n",
      "Epoch 1006, Loss: 1.6965281963348389, Final Batch Loss: 0.3994638919830322\n",
      "Epoch 1007, Loss: 1.6992888748645782, Final Batch Loss: 0.37066972255706787\n",
      "Epoch 1008, Loss: 1.8724735081195831, Final Batch Loss: 0.5398072600364685\n",
      "Epoch 1009, Loss: 1.8266549110412598, Final Batch Loss: 0.4833213984966278\n",
      "Epoch 1010, Loss: 1.6543112099170685, Final Batch Loss: 0.3977571129798889\n",
      "Epoch 1011, Loss: 1.7774266302585602, Final Batch Loss: 0.5590230226516724\n",
      "Epoch 1012, Loss: 1.7253300249576569, Final Batch Loss: 0.44388142228126526\n",
      "Epoch 1013, Loss: 1.6432025730609894, Final Batch Loss: 0.3510971665382385\n",
      "Epoch 1014, Loss: 1.727982997894287, Final Batch Loss: 0.4332374930381775\n",
      "Epoch 1015, Loss: 1.7971958220005035, Final Batch Loss: 0.4988170266151428\n",
      "Epoch 1016, Loss: 1.6478267014026642, Final Batch Loss: 0.4143793284893036\n",
      "Epoch 1017, Loss: 1.8708207309246063, Final Batch Loss: 0.5206732153892517\n",
      "Epoch 1018, Loss: 1.7155984044075012, Final Batch Loss: 0.40181079506874084\n",
      "Epoch 1019, Loss: 1.696456402540207, Final Batch Loss: 0.3510671555995941\n",
      "Epoch 1020, Loss: 1.6080495119094849, Final Batch Loss: 0.33197221159935\n",
      "Epoch 1021, Loss: 1.6753489077091217, Final Batch Loss: 0.3290722072124481\n",
      "Epoch 1022, Loss: 1.7252707779407501, Final Batch Loss: 0.4264128804206848\n",
      "Epoch 1023, Loss: 1.6773306131362915, Final Batch Loss: 0.3640731871128082\n",
      "Epoch 1024, Loss: 1.8213653266429901, Final Batch Loss: 0.5333568453788757\n",
      "Epoch 1025, Loss: 1.7675322890281677, Final Batch Loss: 0.409728080034256\n",
      "Epoch 1026, Loss: 1.7317306697368622, Final Batch Loss: 0.43851959705352783\n",
      "Epoch 1027, Loss: 1.761362999677658, Final Batch Loss: 0.4051515460014343\n",
      "Epoch 1028, Loss: 1.7123048901557922, Final Batch Loss: 0.4338032305240631\n",
      "Epoch 1029, Loss: 1.615667313337326, Final Batch Loss: 0.38629135489463806\n",
      "Epoch 1030, Loss: 1.7648501098155975, Final Batch Loss: 0.4497455656528473\n",
      "Epoch 1031, Loss: 1.7332874238491058, Final Batch Loss: 0.3290475308895111\n",
      "Epoch 1032, Loss: 1.8376765251159668, Final Batch Loss: 0.5272014141082764\n",
      "Epoch 1033, Loss: 1.7642555832862854, Final Batch Loss: 0.4332581162452698\n",
      "Epoch 1034, Loss: 1.7164095044136047, Final Batch Loss: 0.4753470718860626\n",
      "Epoch 1035, Loss: 1.7290595471858978, Final Batch Loss: 0.4331989884376526\n",
      "Epoch 1036, Loss: 1.7883816361427307, Final Batch Loss: 0.3799891471862793\n",
      "Epoch 1037, Loss: 1.8027679920196533, Final Batch Loss: 0.4694548547267914\n",
      "Epoch 1038, Loss: 1.8324086964130402, Final Batch Loss: 0.4965311884880066\n",
      "Epoch 1039, Loss: 1.7350869476795197, Final Batch Loss: 0.5291803479194641\n",
      "Epoch 1040, Loss: 1.6917957961559296, Final Batch Loss: 0.42638227343559265\n",
      "Epoch 1041, Loss: 1.6293849050998688, Final Batch Loss: 0.39653775095939636\n",
      "Epoch 1042, Loss: 1.674808293581009, Final Batch Loss: 0.4568307399749756\n",
      "Epoch 1043, Loss: 1.7710317969322205, Final Batch Loss: 0.4112958014011383\n",
      "Epoch 1044, Loss: 1.822547286748886, Final Batch Loss: 0.457398921251297\n",
      "Epoch 1045, Loss: 1.8264619708061218, Final Batch Loss: 0.5048767924308777\n",
      "Epoch 1046, Loss: 1.7252267897129059, Final Batch Loss: 0.4058417081832886\n",
      "Epoch 1047, Loss: 1.734182894229889, Final Batch Loss: 0.37042292952537537\n",
      "Epoch 1048, Loss: 1.6071730554103851, Final Batch Loss: 0.3647988438606262\n",
      "Epoch 1049, Loss: 1.7229257225990295, Final Batch Loss: 0.4206749498844147\n",
      "Epoch 1050, Loss: 1.7326465845108032, Final Batch Loss: 0.49055084586143494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1051, Loss: 1.7755873799324036, Final Batch Loss: 0.4670334756374359\n",
      "Epoch 1052, Loss: 1.6459151208400726, Final Batch Loss: 0.35445472598075867\n",
      "Epoch 1053, Loss: 1.8465221226215363, Final Batch Loss: 0.545886754989624\n",
      "Epoch 1054, Loss: 1.763620138168335, Final Batch Loss: 0.3819432854652405\n",
      "Epoch 1055, Loss: 1.781209647655487, Final Batch Loss: 0.42975786328315735\n",
      "Epoch 1056, Loss: 1.7351745665073395, Final Batch Loss: 0.4721956253051758\n",
      "Epoch 1057, Loss: 1.7642689645290375, Final Batch Loss: 0.47516316175460815\n",
      "Epoch 1058, Loss: 1.719033807516098, Final Batch Loss: 0.4523251950740814\n",
      "Epoch 1059, Loss: 1.6856915950775146, Final Batch Loss: 0.44312629103660583\n",
      "Epoch 1060, Loss: 1.6250863075256348, Final Batch Loss: 0.3464289903640747\n",
      "Epoch 1061, Loss: 1.6863432228565216, Final Batch Loss: 0.3039388954639435\n",
      "Epoch 1062, Loss: 1.8033462762832642, Final Batch Loss: 0.5533080101013184\n",
      "Epoch 1063, Loss: 1.6896095871925354, Final Batch Loss: 0.39080920815467834\n",
      "Epoch 1064, Loss: 1.804138571023941, Final Batch Loss: 0.5676393508911133\n",
      "Epoch 1065, Loss: 1.6073214411735535, Final Batch Loss: 0.3422870337963104\n",
      "Epoch 1066, Loss: 1.7022357881069183, Final Batch Loss: 0.4124107360839844\n",
      "Epoch 1067, Loss: 1.671173870563507, Final Batch Loss: 0.4769832193851471\n",
      "Epoch 1068, Loss: 1.6041288077831268, Final Batch Loss: 0.3563583195209503\n",
      "Epoch 1069, Loss: 1.6740233898162842, Final Batch Loss: 0.46418893337249756\n",
      "Epoch 1070, Loss: 1.7172077894210815, Final Batch Loss: 0.4893292784690857\n",
      "Epoch 1071, Loss: 1.6253767609596252, Final Batch Loss: 0.4053119122982025\n",
      "Epoch 1072, Loss: 1.7833254635334015, Final Batch Loss: 0.5517219305038452\n",
      "Epoch 1073, Loss: 1.7247789204120636, Final Batch Loss: 0.3822287619113922\n",
      "Epoch 1074, Loss: 1.780585765838623, Final Batch Loss: 0.45681506395339966\n",
      "Epoch 1075, Loss: 1.6276724934577942, Final Batch Loss: 0.3898581266403198\n",
      "Epoch 1076, Loss: 1.7927559316158295, Final Batch Loss: 0.5691519379615784\n",
      "Epoch 1077, Loss: 1.6661573946475983, Final Batch Loss: 0.5048763155937195\n",
      "Epoch 1078, Loss: 1.6356893479824066, Final Batch Loss: 0.39272841811180115\n",
      "Epoch 1079, Loss: 1.7301194965839386, Final Batch Loss: 0.48484352231025696\n",
      "Epoch 1080, Loss: 1.608289659023285, Final Batch Loss: 0.38897886872291565\n",
      "Epoch 1081, Loss: 1.6414936184883118, Final Batch Loss: 0.3735811710357666\n",
      "Epoch 1082, Loss: 1.8211729824543, Final Batch Loss: 0.4254664182662964\n",
      "Epoch 1083, Loss: 1.6374756395816803, Final Batch Loss: 0.4301597476005554\n",
      "Epoch 1084, Loss: 1.7305266857147217, Final Batch Loss: 0.3949112892150879\n",
      "Epoch 1085, Loss: 1.7803447544574738, Final Batch Loss: 0.4561406970024109\n",
      "Epoch 1086, Loss: 1.6239535510540009, Final Batch Loss: 0.34138065576553345\n",
      "Epoch 1087, Loss: 1.8672747611999512, Final Batch Loss: 0.5337291359901428\n",
      "Epoch 1088, Loss: 1.7571050822734833, Final Batch Loss: 0.4754135012626648\n",
      "Epoch 1089, Loss: 1.7237517833709717, Final Batch Loss: 0.4622728228569031\n",
      "Epoch 1090, Loss: 1.7243201434612274, Final Batch Loss: 0.4444127082824707\n",
      "Epoch 1091, Loss: 1.722026765346527, Final Batch Loss: 0.43352288007736206\n",
      "Epoch 1092, Loss: 1.7869925498962402, Final Batch Loss: 0.5317936539649963\n",
      "Epoch 1093, Loss: 1.590232491493225, Final Batch Loss: 0.4627890884876251\n",
      "Epoch 1094, Loss: 1.7156022191047668, Final Batch Loss: 0.35536813735961914\n",
      "Epoch 1095, Loss: 1.6065368354320526, Final Batch Loss: 0.4245191216468811\n",
      "Epoch 1096, Loss: 1.6829546391963959, Final Batch Loss: 0.48005831241607666\n",
      "Epoch 1097, Loss: 1.7200611531734467, Final Batch Loss: 0.33144378662109375\n",
      "Epoch 1098, Loss: 1.5440903902053833, Final Batch Loss: 0.39844080805778503\n",
      "Epoch 1099, Loss: 1.6939946115016937, Final Batch Loss: 0.4831746518611908\n",
      "Epoch 1100, Loss: 1.6869586408138275, Final Batch Loss: 0.4342920184135437\n",
      "Epoch 1101, Loss: 1.6614799499511719, Final Batch Loss: 0.3945530652999878\n",
      "Epoch 1102, Loss: 1.7292977273464203, Final Batch Loss: 0.46703627705574036\n",
      "Epoch 1103, Loss: 1.7926093935966492, Final Batch Loss: 0.44150102138519287\n",
      "Epoch 1104, Loss: 1.7107316553592682, Final Batch Loss: 0.4275301396846771\n",
      "Epoch 1105, Loss: 1.6283657550811768, Final Batch Loss: 0.4120997488498688\n",
      "Epoch 1106, Loss: 1.83947092294693, Final Batch Loss: 0.49136868119239807\n",
      "Epoch 1107, Loss: 1.6461698710918427, Final Batch Loss: 0.4390311539173126\n",
      "Epoch 1108, Loss: 1.7324783205986023, Final Batch Loss: 0.4897269308567047\n",
      "Epoch 1109, Loss: 1.7390193939208984, Final Batch Loss: 0.4604928195476532\n",
      "Epoch 1110, Loss: 1.601101130247116, Final Batch Loss: 0.3866771161556244\n",
      "Epoch 1111, Loss: 1.7158258855342865, Final Batch Loss: 0.46010738611221313\n",
      "Epoch 1112, Loss: 1.6863370537757874, Final Batch Loss: 0.40188103914260864\n",
      "Epoch 1113, Loss: 1.7697475254535675, Final Batch Loss: 0.4155518412590027\n",
      "Epoch 1114, Loss: 1.671765297651291, Final Batch Loss: 0.3739824891090393\n",
      "Epoch 1115, Loss: 1.6536977887153625, Final Batch Loss: 0.3687801957130432\n",
      "Epoch 1116, Loss: 1.613982617855072, Final Batch Loss: 0.42833635210990906\n",
      "Epoch 1117, Loss: 1.8279926776885986, Final Batch Loss: 0.5431933403015137\n",
      "Epoch 1118, Loss: 1.6405020654201508, Final Batch Loss: 0.40294164419174194\n",
      "Epoch 1119, Loss: 1.63421431183815, Final Batch Loss: 0.38006171584129333\n",
      "Epoch 1120, Loss: 1.6275643110275269, Final Batch Loss: 0.35999658703804016\n",
      "Epoch 1121, Loss: 1.6452998518943787, Final Batch Loss: 0.42609456181526184\n",
      "Epoch 1122, Loss: 1.730985313653946, Final Batch Loss: 0.45349687337875366\n",
      "Epoch 1123, Loss: 1.7568533718585968, Final Batch Loss: 0.4349576532840729\n",
      "Epoch 1124, Loss: 1.737978309392929, Final Batch Loss: 0.45575976371765137\n",
      "Epoch 1125, Loss: 1.6958513855934143, Final Batch Loss: 0.48129895329475403\n",
      "Epoch 1126, Loss: 1.6140707433223724, Final Batch Loss: 0.48939087986946106\n",
      "Epoch 1127, Loss: 1.667152851819992, Final Batch Loss: 0.45002302527427673\n",
      "Epoch 1128, Loss: 1.6351079642772675, Final Batch Loss: 0.41649457812309265\n",
      "Epoch 1129, Loss: 1.6113197207450867, Final Batch Loss: 0.42150750756263733\n",
      "Epoch 1130, Loss: 1.7728911638259888, Final Batch Loss: 0.4209117293357849\n",
      "Epoch 1131, Loss: 1.633715182542801, Final Batch Loss: 0.36564645171165466\n",
      "Epoch 1132, Loss: 1.671111285686493, Final Batch Loss: 0.489492267370224\n",
      "Epoch 1133, Loss: 1.6764731109142303, Final Batch Loss: 0.3890715539455414\n",
      "Epoch 1134, Loss: 1.560753881931305, Final Batch Loss: 0.31917622685432434\n",
      "Epoch 1135, Loss: 1.5673770010471344, Final Batch Loss: 0.37844517827033997\n",
      "Epoch 1136, Loss: 1.6515753865242004, Final Batch Loss: 0.3947696089744568\n",
      "Epoch 1137, Loss: 1.7333390712738037, Final Batch Loss: 0.5368279218673706\n",
      "Epoch 1138, Loss: 1.6654777526855469, Final Batch Loss: 0.4076302945613861\n",
      "Epoch 1139, Loss: 1.7458069324493408, Final Batch Loss: 0.4971349835395813\n",
      "Epoch 1140, Loss: 1.7085216641426086, Final Batch Loss: 0.49796053767204285\n",
      "Epoch 1141, Loss: 1.6246168911457062, Final Batch Loss: 0.37791433930397034\n",
      "Epoch 1142, Loss: 1.7711647152900696, Final Batch Loss: 0.35706213116645813\n",
      "Epoch 1143, Loss: 1.6776451766490936, Final Batch Loss: 0.45088523626327515\n",
      "Epoch 1144, Loss: 1.7315821945667267, Final Batch Loss: 0.37921321392059326\n",
      "Epoch 1145, Loss: 1.6808367371559143, Final Batch Loss: 0.5031972527503967\n",
      "Epoch 1146, Loss: 1.6475643813610077, Final Batch Loss: 0.45624101161956787\n",
      "Epoch 1147, Loss: 1.7141245007514954, Final Batch Loss: 0.5069454312324524\n",
      "Epoch 1148, Loss: 1.7307024896144867, Final Batch Loss: 0.37415197491645813\n",
      "Epoch 1149, Loss: 1.7207625210285187, Final Batch Loss: 0.4406181275844574\n",
      "Epoch 1150, Loss: 1.6412163972854614, Final Batch Loss: 0.44067463278770447\n",
      "Epoch 1151, Loss: 1.639262169599533, Final Batch Loss: 0.4354979395866394\n",
      "Epoch 1152, Loss: 1.7656945586204529, Final Batch Loss: 0.5093749165534973\n",
      "Epoch 1153, Loss: 1.7025490403175354, Final Batch Loss: 0.5273770689964294\n",
      "Epoch 1154, Loss: 1.7318108081817627, Final Batch Loss: 0.41096004843711853\n",
      "Epoch 1155, Loss: 1.6337153017520905, Final Batch Loss: 0.44670507311820984\n",
      "Epoch 1156, Loss: 1.7980547845363617, Final Batch Loss: 0.4148651957511902\n",
      "Epoch 1157, Loss: 1.6939657628536224, Final Batch Loss: 0.361027330160141\n",
      "Epoch 1158, Loss: 1.5740433633327484, Final Batch Loss: 0.3968260884284973\n",
      "Epoch 1159, Loss: 1.6745789349079132, Final Batch Loss: 0.5016226172447205\n",
      "Epoch 1160, Loss: 1.536267340183258, Final Batch Loss: 0.3464595079421997\n",
      "Epoch 1161, Loss: 1.608147382736206, Final Batch Loss: 0.3600660264492035\n",
      "Epoch 1162, Loss: 1.5830525159835815, Final Batch Loss: 0.37274178862571716\n",
      "Epoch 1163, Loss: 1.7148238122463226, Final Batch Loss: 0.5114270448684692\n",
      "Epoch 1164, Loss: 1.7199721336364746, Final Batch Loss: 0.5504052042961121\n",
      "Epoch 1165, Loss: 1.5881183445453644, Final Batch Loss: 0.32153162360191345\n",
      "Epoch 1166, Loss: 1.7163767516613007, Final Batch Loss: 0.4806349575519562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1167, Loss: 1.5307744145393372, Final Batch Loss: 0.31629475951194763\n",
      "Epoch 1168, Loss: 1.6978034377098083, Final Batch Loss: 0.449458509683609\n",
      "Epoch 1169, Loss: 1.715951144695282, Final Batch Loss: 0.4279741644859314\n",
      "Epoch 1170, Loss: 1.6856738328933716, Final Batch Loss: 0.5317227840423584\n",
      "Epoch 1171, Loss: 1.6185859143733978, Final Batch Loss: 0.3866351544857025\n",
      "Epoch 1172, Loss: 1.734956532716751, Final Batch Loss: 0.45749524235725403\n",
      "Epoch 1173, Loss: 1.6002873182296753, Final Batch Loss: 0.382436066865921\n",
      "Epoch 1174, Loss: 1.600605309009552, Final Batch Loss: 0.37526455521583557\n",
      "Epoch 1175, Loss: 1.6967340409755707, Final Batch Loss: 0.3654991686344147\n",
      "Epoch 1176, Loss: 1.6885610818862915, Final Batch Loss: 0.4806894361972809\n",
      "Epoch 1177, Loss: 1.7423401176929474, Final Batch Loss: 0.5555347204208374\n",
      "Epoch 1178, Loss: 1.5907925367355347, Final Batch Loss: 0.36837905645370483\n",
      "Epoch 1179, Loss: 1.5441137850284576, Final Batch Loss: 0.3159875273704529\n",
      "Epoch 1180, Loss: 1.4908093512058258, Final Batch Loss: 0.3135986328125\n",
      "Epoch 1181, Loss: 1.638331651687622, Final Batch Loss: 0.3355291783809662\n",
      "Epoch 1182, Loss: 1.5870702266693115, Final Batch Loss: 0.35634782910346985\n",
      "Epoch 1183, Loss: 1.6891277432441711, Final Batch Loss: 0.43309491872787476\n",
      "Epoch 1184, Loss: 1.549348622560501, Final Batch Loss: 0.3722050189971924\n",
      "Epoch 1185, Loss: 1.7003743350505829, Final Batch Loss: 0.44426748156547546\n",
      "Epoch 1186, Loss: 1.710566908121109, Final Batch Loss: 0.3071799874305725\n",
      "Epoch 1187, Loss: 1.6676703095436096, Final Batch Loss: 0.46550363302230835\n",
      "Epoch 1188, Loss: 1.5862275063991547, Final Batch Loss: 0.3539983034133911\n",
      "Epoch 1189, Loss: 1.6206671595573425, Final Batch Loss: 0.35359135270118713\n",
      "Epoch 1190, Loss: 1.5620176494121552, Final Batch Loss: 0.3346959352493286\n",
      "Epoch 1191, Loss: 1.6880156993865967, Final Batch Loss: 0.4485931694507599\n",
      "Epoch 1192, Loss: 1.7522285282611847, Final Batch Loss: 0.45415595173835754\n",
      "Epoch 1193, Loss: 1.6781062185764313, Final Batch Loss: 0.5249813199043274\n",
      "Epoch 1194, Loss: 1.6477353870868683, Final Batch Loss: 0.3983860909938812\n",
      "Epoch 1195, Loss: 1.5963698625564575, Final Batch Loss: 0.42663487792015076\n",
      "Epoch 1196, Loss: 1.6944459676742554, Final Batch Loss: 0.4230635166168213\n",
      "Epoch 1197, Loss: 1.5764574110507965, Final Batch Loss: 0.3250749409198761\n",
      "Epoch 1198, Loss: 1.7222121059894562, Final Batch Loss: 0.44357267022132874\n",
      "Epoch 1199, Loss: 1.6371781826019287, Final Batch Loss: 0.47543051838874817\n",
      "Epoch 1200, Loss: 1.585063874721527, Final Batch Loss: 0.39572787284851074\n",
      "Epoch 1201, Loss: 1.5876314640045166, Final Batch Loss: 0.43139731884002686\n",
      "Epoch 1202, Loss: 1.6078959107398987, Final Batch Loss: 0.3794662058353424\n",
      "Epoch 1203, Loss: 1.6094397902488708, Final Batch Loss: 0.37535741925239563\n",
      "Epoch 1204, Loss: 1.6772429645061493, Final Batch Loss: 0.4020328223705292\n",
      "Epoch 1205, Loss: 1.7859874367713928, Final Batch Loss: 0.5160519480705261\n",
      "Epoch 1206, Loss: 1.5346936285495758, Final Batch Loss: 0.4412032663822174\n",
      "Epoch 1207, Loss: 1.5972761809825897, Final Batch Loss: 0.46394169330596924\n",
      "Epoch 1208, Loss: 1.663930505514145, Final Batch Loss: 0.4383222460746765\n",
      "Epoch 1209, Loss: 1.640552818775177, Final Batch Loss: 0.5058526992797852\n",
      "Epoch 1210, Loss: 1.748192012310028, Final Batch Loss: 0.41230952739715576\n",
      "Epoch 1211, Loss: 1.690846174955368, Final Batch Loss: 0.4544287919998169\n",
      "Epoch 1212, Loss: 1.8047662377357483, Final Batch Loss: 0.5142083764076233\n",
      "Epoch 1213, Loss: 1.5361133813858032, Final Batch Loss: 0.3325521647930145\n",
      "Epoch 1214, Loss: 1.6972213983535767, Final Batch Loss: 0.4881395995616913\n",
      "Epoch 1215, Loss: 1.779101401567459, Final Batch Loss: 0.4571188688278198\n",
      "Epoch 1216, Loss: 1.6255938708782196, Final Batch Loss: 0.4746420085430145\n",
      "Epoch 1217, Loss: 1.6290531158447266, Final Batch Loss: 0.4201572835445404\n",
      "Epoch 1218, Loss: 1.6777907013893127, Final Batch Loss: 0.444363534450531\n",
      "Epoch 1219, Loss: 1.568037062883377, Final Batch Loss: 0.37938472628593445\n",
      "Epoch 1220, Loss: 1.6529081761837006, Final Batch Loss: 0.43150943517684937\n",
      "Epoch 1221, Loss: 1.6295773386955261, Final Batch Loss: 0.4344944655895233\n",
      "Epoch 1222, Loss: 1.6098507940769196, Final Batch Loss: 0.3860245645046234\n",
      "Epoch 1223, Loss: 1.6526302099227905, Final Batch Loss: 0.48124945163726807\n",
      "Epoch 1224, Loss: 1.6706329882144928, Final Batch Loss: 0.4040718078613281\n",
      "Epoch 1225, Loss: 1.6363784670829773, Final Batch Loss: 0.41353365778923035\n",
      "Epoch 1226, Loss: 1.6734052002429962, Final Batch Loss: 0.46312960982322693\n",
      "Epoch 1227, Loss: 1.6666338741779327, Final Batch Loss: 0.4486635625362396\n",
      "Epoch 1228, Loss: 1.6291383504867554, Final Batch Loss: 0.4086812436580658\n",
      "Epoch 1229, Loss: 1.5690544247627258, Final Batch Loss: 0.3860670328140259\n",
      "Epoch 1230, Loss: 1.6885966062545776, Final Batch Loss: 0.418043851852417\n",
      "Epoch 1231, Loss: 1.7096339166164398, Final Batch Loss: 0.44190049171447754\n",
      "Epoch 1232, Loss: 1.655312567949295, Final Batch Loss: 0.444898784160614\n",
      "Epoch 1233, Loss: 1.5743385553359985, Final Batch Loss: 0.4048723876476288\n",
      "Epoch 1234, Loss: 1.5915825068950653, Final Batch Loss: 0.4069841206073761\n",
      "Epoch 1235, Loss: 1.6959109604358673, Final Batch Loss: 0.4278382956981659\n",
      "Epoch 1236, Loss: 1.6127109229564667, Final Batch Loss: 0.38479048013687134\n",
      "Epoch 1237, Loss: 1.5748986303806305, Final Batch Loss: 0.331897109746933\n",
      "Epoch 1238, Loss: 1.7311167418956757, Final Batch Loss: 0.47719791531562805\n",
      "Epoch 1239, Loss: 1.6875974535942078, Final Batch Loss: 0.46663740277290344\n",
      "Epoch 1240, Loss: 1.5705595016479492, Final Batch Loss: 0.3494824767112732\n",
      "Epoch 1241, Loss: 1.6777871549129486, Final Batch Loss: 0.42136669158935547\n",
      "Epoch 1242, Loss: 1.7068048417568207, Final Batch Loss: 0.5344322323799133\n",
      "Epoch 1243, Loss: 1.6382498741149902, Final Batch Loss: 0.44268471002578735\n",
      "Epoch 1244, Loss: 1.6416656374931335, Final Batch Loss: 0.41532111167907715\n",
      "Epoch 1245, Loss: 1.6587741076946259, Final Batch Loss: 0.43747085332870483\n",
      "Epoch 1246, Loss: 1.5581539869308472, Final Batch Loss: 0.33491361141204834\n",
      "Epoch 1247, Loss: 1.8074019253253937, Final Batch Loss: 0.6051624417304993\n",
      "Epoch 1248, Loss: 1.5587259829044342, Final Batch Loss: 0.3859483301639557\n",
      "Epoch 1249, Loss: 1.6261094212532043, Final Batch Loss: 0.4182264804840088\n",
      "Epoch 1250, Loss: 1.629522830247879, Final Batch Loss: 0.4272631108760834\n",
      "Epoch 1251, Loss: 1.5473520457744598, Final Batch Loss: 0.2967948615550995\n",
      "Epoch 1252, Loss: 1.5894575715065002, Final Batch Loss: 0.36274003982543945\n",
      "Epoch 1253, Loss: 1.5837674140930176, Final Batch Loss: 0.3227771520614624\n",
      "Epoch 1254, Loss: 1.6527747213840485, Final Batch Loss: 0.39246517419815063\n",
      "Epoch 1255, Loss: 1.642792284488678, Final Batch Loss: 0.44767630100250244\n",
      "Epoch 1256, Loss: 1.6597252488136292, Final Batch Loss: 0.41712284088134766\n",
      "Epoch 1257, Loss: 1.5956585705280304, Final Batch Loss: 0.3952052593231201\n",
      "Epoch 1258, Loss: 1.6989537179470062, Final Batch Loss: 0.5297262668609619\n",
      "Epoch 1259, Loss: 1.6255143582820892, Final Batch Loss: 0.38045695424079895\n",
      "Epoch 1260, Loss: 1.6714836359024048, Final Batch Loss: 0.45453470945358276\n",
      "Epoch 1261, Loss: 1.754141241312027, Final Batch Loss: 0.46110889315605164\n",
      "Epoch 1262, Loss: 1.5502300262451172, Final Batch Loss: 0.3621305227279663\n",
      "Epoch 1263, Loss: 1.7259337604045868, Final Batch Loss: 0.458716481924057\n",
      "Epoch 1264, Loss: 1.6878877878189087, Final Batch Loss: 0.47330671548843384\n",
      "Epoch 1265, Loss: 1.5436657965183258, Final Batch Loss: 0.3964192867279053\n",
      "Epoch 1266, Loss: 1.5793454349040985, Final Batch Loss: 0.38718608021736145\n",
      "Epoch 1267, Loss: 1.5546579360961914, Final Batch Loss: 0.3707302212715149\n",
      "Epoch 1268, Loss: 1.5378256440162659, Final Batch Loss: 0.3857696056365967\n",
      "Epoch 1269, Loss: 1.6410898566246033, Final Batch Loss: 0.3534855246543884\n",
      "Epoch 1270, Loss: 1.4673020541667938, Final Batch Loss: 0.3073953092098236\n",
      "Epoch 1271, Loss: 1.592738300561905, Final Batch Loss: 0.4137304425239563\n",
      "Epoch 1272, Loss: 1.612876296043396, Final Batch Loss: 0.4401240050792694\n",
      "Epoch 1273, Loss: 1.5500578582286835, Final Batch Loss: 0.43031710386276245\n",
      "Epoch 1274, Loss: 1.6977942287921906, Final Batch Loss: 0.3713941276073456\n",
      "Epoch 1275, Loss: 1.5978783071041107, Final Batch Loss: 0.4452526271343231\n",
      "Epoch 1276, Loss: 1.5075962245464325, Final Batch Loss: 0.37628859281539917\n",
      "Epoch 1277, Loss: 1.6596544981002808, Final Batch Loss: 0.48971694707870483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1278, Loss: 1.5396954417228699, Final Batch Loss: 0.27217310667037964\n",
      "Epoch 1279, Loss: 1.6867730915546417, Final Batch Loss: 0.3816637396812439\n",
      "Epoch 1280, Loss: 1.5420408248901367, Final Batch Loss: 0.4171692430973053\n",
      "Epoch 1281, Loss: 1.576769471168518, Final Batch Loss: 0.4206840991973877\n",
      "Epoch 1282, Loss: 1.7668988108634949, Final Batch Loss: 0.5482255816459656\n",
      "Epoch 1283, Loss: 1.6878449320793152, Final Batch Loss: 0.46936851739883423\n",
      "Epoch 1284, Loss: 1.5016061961650848, Final Batch Loss: 0.3517858684062958\n",
      "Epoch 1285, Loss: 1.526853233575821, Final Batch Loss: 0.3146791458129883\n",
      "Epoch 1286, Loss: 1.6015259325504303, Final Batch Loss: 0.4051046073436737\n",
      "Epoch 1287, Loss: 1.5455151796340942, Final Batch Loss: 0.32737046480178833\n",
      "Epoch 1288, Loss: 1.6259692013263702, Final Batch Loss: 0.41651687026023865\n",
      "Epoch 1289, Loss: 1.5641327500343323, Final Batch Loss: 0.4390820264816284\n",
      "Epoch 1290, Loss: 1.5916843116283417, Final Batch Loss: 0.3714296221733093\n",
      "Epoch 1291, Loss: 1.537818282842636, Final Batch Loss: 0.33875852823257446\n",
      "Epoch 1292, Loss: 1.5008968710899353, Final Batch Loss: 0.32509344816207886\n",
      "Epoch 1293, Loss: 1.6237013936042786, Final Batch Loss: 0.4496280550956726\n",
      "Epoch 1294, Loss: 1.6130021512508392, Final Batch Loss: 0.33250635862350464\n",
      "Epoch 1295, Loss: 1.6431763768196106, Final Batch Loss: 0.395757794380188\n",
      "Epoch 1296, Loss: 1.6508065462112427, Final Batch Loss: 0.3893905282020569\n",
      "Epoch 1297, Loss: 1.4976544976234436, Final Batch Loss: 0.33309319615364075\n",
      "Epoch 1298, Loss: 1.5083822309970856, Final Batch Loss: 0.3709077835083008\n",
      "Epoch 1299, Loss: 1.5222301185131073, Final Batch Loss: 0.3741818070411682\n",
      "Epoch 1300, Loss: 1.624660611152649, Final Batch Loss: 0.4044070541858673\n",
      "Epoch 1301, Loss: 1.6446693539619446, Final Batch Loss: 0.4053225815296173\n",
      "Epoch 1302, Loss: 1.506925642490387, Final Batch Loss: 0.29928192496299744\n",
      "Epoch 1303, Loss: 1.6066651940345764, Final Batch Loss: 0.4252763092517853\n",
      "Epoch 1304, Loss: 1.7048755586147308, Final Batch Loss: 0.3767749071121216\n",
      "Epoch 1305, Loss: 1.5497700572013855, Final Batch Loss: 0.37634435296058655\n",
      "Epoch 1306, Loss: 1.706500083208084, Final Batch Loss: 0.483767569065094\n",
      "Epoch 1307, Loss: 1.6643604636192322, Final Batch Loss: 0.48118430376052856\n",
      "Epoch 1308, Loss: 1.6913531720638275, Final Batch Loss: 0.4526885151863098\n",
      "Epoch 1309, Loss: 1.7517415881156921, Final Batch Loss: 0.563422441482544\n",
      "Epoch 1310, Loss: 1.6600406169891357, Final Batch Loss: 0.4698360562324524\n",
      "Epoch 1311, Loss: 1.6014138460159302, Final Batch Loss: 0.47137242555618286\n",
      "Epoch 1312, Loss: 1.6117843985557556, Final Batch Loss: 0.39502474665641785\n",
      "Epoch 1313, Loss: 1.6142857372760773, Final Batch Loss: 0.4519025683403015\n",
      "Epoch 1314, Loss: 1.7322978675365448, Final Batch Loss: 0.4639511704444885\n",
      "Epoch 1315, Loss: 1.6609834134578705, Final Batch Loss: 0.2952054440975189\n",
      "Epoch 1316, Loss: 1.5474284887313843, Final Batch Loss: 0.34589269757270813\n",
      "Epoch 1317, Loss: 1.4894779026508331, Final Batch Loss: 0.34222644567489624\n",
      "Epoch 1318, Loss: 1.570834368467331, Final Batch Loss: 0.33173149824142456\n",
      "Epoch 1319, Loss: 1.5775344669818878, Final Batch Loss: 0.36717715859413147\n",
      "Epoch 1320, Loss: 1.6788671016693115, Final Batch Loss: 0.41910409927368164\n",
      "Epoch 1321, Loss: 1.5628964006900787, Final Batch Loss: 0.39973247051239014\n",
      "Epoch 1322, Loss: 1.5588423907756805, Final Batch Loss: 0.41518542170524597\n",
      "Epoch 1323, Loss: 1.5700387060642242, Final Batch Loss: 0.3693552017211914\n",
      "Epoch 1324, Loss: 1.674767017364502, Final Batch Loss: 0.4957237243652344\n",
      "Epoch 1325, Loss: 1.486390471458435, Final Batch Loss: 0.33891287446022034\n",
      "Epoch 1326, Loss: 1.6590004861354828, Final Batch Loss: 0.3838789165019989\n",
      "Epoch 1327, Loss: 1.743978589773178, Final Batch Loss: 0.36510780453681946\n",
      "Epoch 1328, Loss: 1.689347743988037, Final Batch Loss: 0.41055360436439514\n",
      "Epoch 1329, Loss: 1.6174014508724213, Final Batch Loss: 0.4558960795402527\n",
      "Epoch 1330, Loss: 1.7099892795085907, Final Batch Loss: 0.42230111360549927\n",
      "Epoch 1331, Loss: 1.518239289522171, Final Batch Loss: 0.37757307291030884\n",
      "Epoch 1332, Loss: 1.535124033689499, Final Batch Loss: 0.3376518487930298\n",
      "Epoch 1333, Loss: 1.626453697681427, Final Batch Loss: 0.41663581132888794\n",
      "Epoch 1334, Loss: 1.5434341132640839, Final Batch Loss: 0.4025089740753174\n",
      "Epoch 1335, Loss: 1.667413204908371, Final Batch Loss: 0.41461291909217834\n",
      "Epoch 1336, Loss: 1.5361426770687103, Final Batch Loss: 0.435980886220932\n",
      "Epoch 1337, Loss: 1.4672476053237915, Final Batch Loss: 0.3508792817592621\n",
      "Epoch 1338, Loss: 1.5373627543449402, Final Batch Loss: 0.37735822796821594\n",
      "Epoch 1339, Loss: 1.5705362260341644, Final Batch Loss: 0.3555586040019989\n",
      "Epoch 1340, Loss: 1.5793161690235138, Final Batch Loss: 0.3723585903644562\n",
      "Epoch 1341, Loss: 1.6223739981651306, Final Batch Loss: 0.4488791823387146\n",
      "Epoch 1342, Loss: 1.4674910604953766, Final Batch Loss: 0.4198835790157318\n",
      "Epoch 1343, Loss: 1.5954398810863495, Final Batch Loss: 0.2831161320209503\n",
      "Epoch 1344, Loss: 1.5874505937099457, Final Batch Loss: 0.3335443139076233\n",
      "Epoch 1345, Loss: 1.5029145181179047, Final Batch Loss: 0.3356196880340576\n",
      "Epoch 1346, Loss: 1.4890974164009094, Final Batch Loss: 0.3491482436656952\n",
      "Epoch 1347, Loss: 1.5438818633556366, Final Batch Loss: 0.43007344007492065\n",
      "Epoch 1348, Loss: 1.5818171799182892, Final Batch Loss: 0.4337957203388214\n",
      "Epoch 1349, Loss: 1.4173109233379364, Final Batch Loss: 0.3633865714073181\n",
      "Epoch 1350, Loss: 1.6291308104991913, Final Batch Loss: 0.40259289741516113\n",
      "Epoch 1351, Loss: 1.6599754095077515, Final Batch Loss: 0.3962689936161041\n",
      "Epoch 1352, Loss: 1.5893850326538086, Final Batch Loss: 0.4256446957588196\n",
      "Epoch 1353, Loss: 1.5605971217155457, Final Batch Loss: 0.36872589588165283\n",
      "Epoch 1354, Loss: 1.5463469922542572, Final Batch Loss: 0.36436259746551514\n",
      "Epoch 1355, Loss: 1.5932793021202087, Final Batch Loss: 0.3124181032180786\n",
      "Epoch 1356, Loss: 1.484755665063858, Final Batch Loss: 0.3566988706588745\n",
      "Epoch 1357, Loss: 1.6391701996326447, Final Batch Loss: 0.5405586361885071\n",
      "Epoch 1358, Loss: 1.5957953929901123, Final Batch Loss: 0.517577052116394\n",
      "Epoch 1359, Loss: 1.496722787618637, Final Batch Loss: 0.381969690322876\n",
      "Epoch 1360, Loss: 1.5512694418430328, Final Batch Loss: 0.32335636019706726\n",
      "Epoch 1361, Loss: 1.5499157011508942, Final Batch Loss: 0.3697769045829773\n",
      "Epoch 1362, Loss: 1.4434386789798737, Final Batch Loss: 0.3129103481769562\n",
      "Epoch 1363, Loss: 1.6083184480667114, Final Batch Loss: 0.408602774143219\n",
      "Epoch 1364, Loss: 1.5074129700660706, Final Batch Loss: 0.2761862874031067\n",
      "Epoch 1365, Loss: 1.5007199048995972, Final Batch Loss: 0.3089616894721985\n",
      "Epoch 1366, Loss: 1.5317870676517487, Final Batch Loss: 0.33876195549964905\n",
      "Epoch 1367, Loss: 1.571976125240326, Final Batch Loss: 0.452335923910141\n",
      "Epoch 1368, Loss: 1.5708999931812286, Final Batch Loss: 0.33546361327171326\n",
      "Epoch 1369, Loss: 1.5057925283908844, Final Batch Loss: 0.3631162643432617\n",
      "Epoch 1370, Loss: 1.5896461606025696, Final Batch Loss: 0.4083481431007385\n",
      "Epoch 1371, Loss: 1.5195184648036957, Final Batch Loss: 0.40131425857543945\n",
      "Epoch 1372, Loss: 1.5244315266609192, Final Batch Loss: 0.3907240331172943\n",
      "Epoch 1373, Loss: 1.4432333409786224, Final Batch Loss: 0.26803287863731384\n",
      "Epoch 1374, Loss: 1.5717780888080597, Final Batch Loss: 0.40137186646461487\n",
      "Epoch 1375, Loss: 1.5957554876804352, Final Batch Loss: 0.46291783452033997\n",
      "Epoch 1376, Loss: 1.6181366741657257, Final Batch Loss: 0.44180795550346375\n",
      "Epoch 1377, Loss: 1.4743618667125702, Final Batch Loss: 0.3853575885295868\n",
      "Epoch 1378, Loss: 1.4377950429916382, Final Batch Loss: 0.31338411569595337\n",
      "Epoch 1379, Loss: 1.556082844734192, Final Batch Loss: 0.41053783893585205\n",
      "Epoch 1380, Loss: 1.6209735870361328, Final Batch Loss: 0.4315283000469208\n",
      "Epoch 1381, Loss: 1.4926422238349915, Final Batch Loss: 0.416958212852478\n",
      "Epoch 1382, Loss: 1.506753921508789, Final Batch Loss: 0.37277060747146606\n",
      "Epoch 1383, Loss: 1.5352419912815094, Final Batch Loss: 0.4266203045845032\n",
      "Epoch 1384, Loss: 1.694039762020111, Final Batch Loss: 0.4219704568386078\n",
      "Epoch 1385, Loss: 1.5026846826076508, Final Batch Loss: 0.34620434045791626\n",
      "Epoch 1386, Loss: 1.5917696058750153, Final Batch Loss: 0.3861088156700134\n",
      "Epoch 1387, Loss: 1.5356839895248413, Final Batch Loss: 0.41918036341667175\n",
      "Epoch 1388, Loss: 1.536386787891388, Final Batch Loss: 0.3864680826663971\n",
      "Epoch 1389, Loss: 1.4668652415275574, Final Batch Loss: 0.37643828988075256\n",
      "Epoch 1390, Loss: 1.449079006910324, Final Batch Loss: 0.2748553454875946\n",
      "Epoch 1391, Loss: 1.6043681800365448, Final Batch Loss: 0.5203068852424622\n",
      "Epoch 1392, Loss: 1.4797149300575256, Final Batch Loss: 0.36012423038482666\n",
      "Epoch 1393, Loss: 1.4814178049564362, Final Batch Loss: 0.4098414480686188\n",
      "Epoch 1394, Loss: 1.560566008090973, Final Batch Loss: 0.4262017607688904\n",
      "Epoch 1395, Loss: 1.6289515793323517, Final Batch Loss: 0.43476444482803345\n",
      "Epoch 1396, Loss: 1.5395205914974213, Final Batch Loss: 0.2975881099700928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1397, Loss: 1.6219376921653748, Final Batch Loss: 0.5046823024749756\n",
      "Epoch 1398, Loss: 1.56747704744339, Final Batch Loss: 0.3820834755897522\n",
      "Epoch 1399, Loss: 1.5770739614963531, Final Batch Loss: 0.35897383093833923\n",
      "Epoch 1400, Loss: 1.7098398804664612, Final Batch Loss: 0.5109145641326904\n",
      "Epoch 1401, Loss: 1.5230271816253662, Final Batch Loss: 0.3415571451187134\n",
      "Epoch 1402, Loss: 1.5216785073280334, Final Batch Loss: 0.4136768579483032\n",
      "Epoch 1403, Loss: 1.5362061560153961, Final Batch Loss: 0.4337085783481598\n",
      "Epoch 1404, Loss: 1.487089604139328, Final Batch Loss: 0.3528870642185211\n",
      "Epoch 1405, Loss: 1.5749385356903076, Final Batch Loss: 0.41729384660720825\n",
      "Epoch 1406, Loss: 1.5227873921394348, Final Batch Loss: 0.411287784576416\n",
      "Epoch 1407, Loss: 1.5588051676750183, Final Batch Loss: 0.4128958582878113\n",
      "Epoch 1408, Loss: 1.548931062221527, Final Batch Loss: 0.3450544476509094\n",
      "Epoch 1409, Loss: 1.6465607583522797, Final Batch Loss: 0.4028489887714386\n",
      "Epoch 1410, Loss: 1.759797841310501, Final Batch Loss: 0.5255588293075562\n",
      "Epoch 1411, Loss: 1.577848494052887, Final Batch Loss: 0.47099125385284424\n",
      "Epoch 1412, Loss: 1.441449373960495, Final Batch Loss: 0.27389034628868103\n",
      "Epoch 1413, Loss: 1.6496883928775787, Final Batch Loss: 0.37542322278022766\n",
      "Epoch 1414, Loss: 1.4356380105018616, Final Batch Loss: 0.3265409469604492\n",
      "Epoch 1415, Loss: 1.5490534603595734, Final Batch Loss: 0.3280104100704193\n",
      "Epoch 1416, Loss: 1.6524008214473724, Final Batch Loss: 0.38187089562416077\n",
      "Epoch 1417, Loss: 1.755020260810852, Final Batch Loss: 0.43271395564079285\n",
      "Epoch 1418, Loss: 1.752113550901413, Final Batch Loss: 0.4296826124191284\n",
      "Epoch 1419, Loss: 1.6233021914958954, Final Batch Loss: 0.3423043489456177\n",
      "Epoch 1420, Loss: 1.5179433822631836, Final Batch Loss: 0.3446751534938812\n",
      "Epoch 1421, Loss: 1.6194198429584503, Final Batch Loss: 0.47217169404029846\n",
      "Epoch 1422, Loss: 1.4472354054450989, Final Batch Loss: 0.29785943031311035\n",
      "Epoch 1423, Loss: 1.5481486022472382, Final Batch Loss: 0.29837384819984436\n",
      "Epoch 1424, Loss: 1.5158686637878418, Final Batch Loss: 0.3691766858100891\n",
      "Epoch 1425, Loss: 1.6341612637043, Final Batch Loss: 0.4269998371601105\n",
      "Epoch 1426, Loss: 1.5712862014770508, Final Batch Loss: 0.36084815859794617\n",
      "Epoch 1427, Loss: 1.3940437734127045, Final Batch Loss: 0.22238650918006897\n",
      "Epoch 1428, Loss: 1.4555890560150146, Final Batch Loss: 0.3406729996204376\n",
      "Epoch 1429, Loss: 1.5175201892852783, Final Batch Loss: 0.3860558569431305\n",
      "Epoch 1430, Loss: 1.7784621715545654, Final Batch Loss: 0.5514891147613525\n",
      "Epoch 1431, Loss: 1.4894946217536926, Final Batch Loss: 0.2565930187702179\n",
      "Epoch 1432, Loss: 1.589467853307724, Final Batch Loss: 0.3609597980976105\n",
      "Epoch 1433, Loss: 1.615603119134903, Final Batch Loss: 0.3513207733631134\n",
      "Epoch 1434, Loss: 1.5012215971946716, Final Batch Loss: 0.3527351915836334\n",
      "Epoch 1435, Loss: 1.57339745759964, Final Batch Loss: 0.47208160161972046\n",
      "Epoch 1436, Loss: 1.4979247450828552, Final Batch Loss: 0.4115082621574402\n",
      "Epoch 1437, Loss: 1.65859916806221, Final Batch Loss: 0.32378605008125305\n",
      "Epoch 1438, Loss: 1.5210114419460297, Final Batch Loss: 0.41956427693367004\n",
      "Epoch 1439, Loss: 1.5005647242069244, Final Batch Loss: 0.36442503333091736\n",
      "Epoch 1440, Loss: 1.5770595371723175, Final Batch Loss: 0.35839396715164185\n",
      "Epoch 1441, Loss: 1.6269462406635284, Final Batch Loss: 0.3768365979194641\n",
      "Epoch 1442, Loss: 1.5484641790390015, Final Batch Loss: 0.3887869119644165\n",
      "Epoch 1443, Loss: 1.5107089281082153, Final Batch Loss: 0.3690643012523651\n",
      "Epoch 1444, Loss: 1.6209067106246948, Final Batch Loss: 0.3558620810508728\n",
      "Epoch 1445, Loss: 1.5833217799663544, Final Batch Loss: 0.346369206905365\n",
      "Epoch 1446, Loss: 1.4974444806575775, Final Batch Loss: 0.362771600484848\n",
      "Epoch 1447, Loss: 1.5579820275306702, Final Batch Loss: 0.4225166440010071\n",
      "Epoch 1448, Loss: 1.6194229125976562, Final Batch Loss: 0.4742877781391144\n",
      "Epoch 1449, Loss: 1.6738415658473969, Final Batch Loss: 0.4402325749397278\n",
      "Epoch 1450, Loss: 1.5207155048847198, Final Batch Loss: 0.3974877893924713\n",
      "Epoch 1451, Loss: 1.591433584690094, Final Batch Loss: 0.40822604298591614\n",
      "Epoch 1452, Loss: 1.5654204785823822, Final Batch Loss: 0.33563390374183655\n",
      "Epoch 1453, Loss: 1.58957439661026, Final Batch Loss: 0.49900707602500916\n",
      "Epoch 1454, Loss: 1.548255294561386, Final Batch Loss: 0.3684632182121277\n",
      "Epoch 1455, Loss: 1.5709715783596039, Final Batch Loss: 0.42573994398117065\n",
      "Epoch 1456, Loss: 1.4976341128349304, Final Batch Loss: 0.4159580171108246\n",
      "Epoch 1457, Loss: 1.540587067604065, Final Batch Loss: 0.4382030665874481\n",
      "Epoch 1458, Loss: 1.5620991885662079, Final Batch Loss: 0.41850781440734863\n",
      "Epoch 1459, Loss: 1.5894412398338318, Final Batch Loss: 0.2998775541782379\n",
      "Epoch 1460, Loss: 1.645027607679367, Final Batch Loss: 0.4545835256576538\n",
      "Epoch 1461, Loss: 1.456702560186386, Final Batch Loss: 0.347408264875412\n",
      "Epoch 1462, Loss: 1.4243095219135284, Final Batch Loss: 0.30523017048835754\n",
      "Epoch 1463, Loss: 1.5035191476345062, Final Batch Loss: 0.3625352084636688\n",
      "Epoch 1464, Loss: 1.6083131432533264, Final Batch Loss: 0.505979597568512\n",
      "Epoch 1465, Loss: 1.562860906124115, Final Batch Loss: 0.4395595192909241\n",
      "Epoch 1466, Loss: 1.7131883800029755, Final Batch Loss: 0.4931252896785736\n",
      "Epoch 1467, Loss: 1.4733876585960388, Final Batch Loss: 0.337130069732666\n",
      "Epoch 1468, Loss: 1.5535613596439362, Final Batch Loss: 0.41570669412612915\n",
      "Epoch 1469, Loss: 1.632979929447174, Final Batch Loss: 0.5195099115371704\n",
      "Epoch 1470, Loss: 1.6029052734375, Final Batch Loss: 0.42105889320373535\n",
      "Epoch 1471, Loss: 1.4689562916755676, Final Batch Loss: 0.31012022495269775\n",
      "Epoch 1472, Loss: 1.6483010649681091, Final Batch Loss: 0.37758806347846985\n",
      "Epoch 1473, Loss: 1.487443208694458, Final Batch Loss: 0.2948359549045563\n",
      "Epoch 1474, Loss: 1.4042811393737793, Final Batch Loss: 0.3450707197189331\n",
      "Epoch 1475, Loss: 1.4730377793312073, Final Batch Loss: 0.3811294734477997\n",
      "Epoch 1476, Loss: 1.614959955215454, Final Batch Loss: 0.36709970235824585\n",
      "Epoch 1477, Loss: 1.5892203450202942, Final Batch Loss: 0.4635069668292999\n",
      "Epoch 1478, Loss: 1.537718266248703, Final Batch Loss: 0.3905876874923706\n",
      "Epoch 1479, Loss: 1.552658587694168, Final Batch Loss: 0.365286260843277\n",
      "Epoch 1480, Loss: 1.5276597440242767, Final Batch Loss: 0.3988714814186096\n",
      "Epoch 1481, Loss: 1.508120983839035, Final Batch Loss: 0.342736154794693\n",
      "Epoch 1482, Loss: 1.5602706968784332, Final Batch Loss: 0.3757222592830658\n",
      "Epoch 1483, Loss: 1.5741448104381561, Final Batch Loss: 0.4073154926300049\n",
      "Epoch 1484, Loss: 1.6326858401298523, Final Batch Loss: 0.4197312891483307\n",
      "Epoch 1485, Loss: 1.4505253732204437, Final Batch Loss: 0.320866197347641\n",
      "Epoch 1486, Loss: 1.5677088797092438, Final Batch Loss: 0.44872957468032837\n",
      "Epoch 1487, Loss: 1.540927231311798, Final Batch Loss: 0.48365065455436707\n",
      "Epoch 1488, Loss: 1.4883400201797485, Final Batch Loss: 0.3952130377292633\n",
      "Epoch 1489, Loss: 1.5223564505577087, Final Batch Loss: 0.35945504903793335\n",
      "Epoch 1490, Loss: 1.5645309686660767, Final Batch Loss: 0.4236961901187897\n",
      "Epoch 1491, Loss: 1.616160660982132, Final Batch Loss: 0.3513965308666229\n",
      "Epoch 1492, Loss: 1.5731861889362335, Final Batch Loss: 0.470462828874588\n",
      "Epoch 1493, Loss: 1.5959185361862183, Final Batch Loss: 0.4697035253047943\n",
      "Epoch 1494, Loss: 1.6200783848762512, Final Batch Loss: 0.4183136522769928\n",
      "Epoch 1495, Loss: 1.4630625545978546, Final Batch Loss: 0.3292432427406311\n",
      "Epoch 1496, Loss: 1.4881269335746765, Final Batch Loss: 0.3939272463321686\n",
      "Epoch 1497, Loss: 1.5933398604393005, Final Batch Loss: 0.44006335735321045\n",
      "Epoch 1498, Loss: 1.5524955987930298, Final Batch Loss: 0.3728834390640259\n",
      "Epoch 1499, Loss: 1.5169611871242523, Final Batch Loss: 0.3536919355392456\n",
      "Epoch 1500, Loss: 1.3436391651630402, Final Batch Loss: 0.2680037319660187\n",
      "Epoch 1501, Loss: 1.4947271347045898, Final Batch Loss: 0.37930846214294434\n",
      "Epoch 1502, Loss: 1.6572064757347107, Final Batch Loss: 0.4138939380645752\n",
      "Epoch 1503, Loss: 1.5142090618610382, Final Batch Loss: 0.4524328112602234\n",
      "Epoch 1504, Loss: 1.5425908267498016, Final Batch Loss: 0.4185604751110077\n",
      "Epoch 1505, Loss: 1.3655675947666168, Final Batch Loss: 0.2783306837081909\n",
      "Epoch 1506, Loss: 1.5167887210845947, Final Batch Loss: 0.4473804831504822\n",
      "Epoch 1507, Loss: 1.4397072792053223, Final Batch Loss: 0.30594176054000854\n",
      "Epoch 1508, Loss: 1.5836752355098724, Final Batch Loss: 0.37275955080986023\n",
      "Epoch 1509, Loss: 1.583803653717041, Final Batch Loss: 0.4193822145462036\n",
      "Epoch 1510, Loss: 1.5562858879566193, Final Batch Loss: 0.33723539113998413\n",
      "Epoch 1511, Loss: 1.5436639785766602, Final Batch Loss: 0.30655619502067566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1512, Loss: 1.5165565609931946, Final Batch Loss: 0.43933868408203125\n",
      "Epoch 1513, Loss: 1.4922991394996643, Final Batch Loss: 0.3209405243396759\n",
      "Epoch 1514, Loss: 1.385851874947548, Final Batch Loss: 0.2179204374551773\n",
      "Epoch 1515, Loss: 1.6534926295280457, Final Batch Loss: 0.46475446224212646\n",
      "Epoch 1516, Loss: 1.5645067691802979, Final Batch Loss: 0.31554755568504333\n",
      "Epoch 1517, Loss: 1.539076805114746, Final Batch Loss: 0.3502560257911682\n",
      "Epoch 1518, Loss: 1.525498390197754, Final Batch Loss: 0.365357369184494\n",
      "Epoch 1519, Loss: 1.4061219990253448, Final Batch Loss: 0.3126879334449768\n",
      "Epoch 1520, Loss: 1.7645466923713684, Final Batch Loss: 0.5101577043533325\n",
      "Epoch 1521, Loss: 1.6050918996334076, Final Batch Loss: 0.40061935782432556\n",
      "Epoch 1522, Loss: 1.5743182301521301, Final Batch Loss: 0.4294213056564331\n",
      "Epoch 1523, Loss: 1.616339534521103, Final Batch Loss: 0.36102086305618286\n",
      "Epoch 1524, Loss: 1.4650487005710602, Final Batch Loss: 0.4457678496837616\n",
      "Epoch 1525, Loss: 1.6828603744506836, Final Batch Loss: 0.5601124167442322\n",
      "Epoch 1526, Loss: 1.714786410331726, Final Batch Loss: 0.45456114411354065\n",
      "Epoch 1527, Loss: 1.5118963420391083, Final Batch Loss: 0.3392408490180969\n",
      "Epoch 1528, Loss: 1.5082418024539948, Final Batch Loss: 0.2840591371059418\n",
      "Epoch 1529, Loss: 1.4572441577911377, Final Batch Loss: 0.3874746859073639\n",
      "Epoch 1530, Loss: 1.5579819679260254, Final Batch Loss: 0.38012203574180603\n",
      "Epoch 1531, Loss: 1.6106463372707367, Final Batch Loss: 0.49697116017341614\n",
      "Epoch 1532, Loss: 1.4499237537384033, Final Batch Loss: 0.4517449140548706\n",
      "Epoch 1533, Loss: 1.512814998626709, Final Batch Loss: 0.43853360414505005\n",
      "Epoch 1534, Loss: 1.4647618234157562, Final Batch Loss: 0.39848923683166504\n",
      "Epoch 1535, Loss: 1.4840722978115082, Final Batch Loss: 0.33265647292137146\n",
      "Epoch 1536, Loss: 1.4381941854953766, Final Batch Loss: 0.36356428265571594\n",
      "Epoch 1537, Loss: 1.4981135129928589, Final Batch Loss: 0.4547188878059387\n",
      "Epoch 1538, Loss: 1.4645206332206726, Final Batch Loss: 0.42742061614990234\n",
      "Epoch 1539, Loss: 1.4772962629795074, Final Batch Loss: 0.35962727665901184\n",
      "Epoch 1540, Loss: 1.467253416776657, Final Batch Loss: 0.3125293254852295\n",
      "Epoch 1541, Loss: 1.5712100863456726, Final Batch Loss: 0.3666232228279114\n",
      "Epoch 1542, Loss: 1.5541193783283234, Final Batch Loss: 0.4509705901145935\n",
      "Epoch 1543, Loss: 1.5806460082530975, Final Batch Loss: 0.3823971152305603\n",
      "Epoch 1544, Loss: 1.4505716264247894, Final Batch Loss: 0.3338868021965027\n",
      "Epoch 1545, Loss: 1.6621726155281067, Final Batch Loss: 0.5323437452316284\n",
      "Epoch 1546, Loss: 1.460996836423874, Final Batch Loss: 0.30282193422317505\n",
      "Epoch 1547, Loss: 1.542895793914795, Final Batch Loss: 0.39326924085617065\n",
      "Epoch 1548, Loss: 1.53398796916008, Final Batch Loss: 0.39327767491340637\n",
      "Epoch 1549, Loss: 1.533013105392456, Final Batch Loss: 0.40819379687309265\n",
      "Epoch 1550, Loss: 1.5114182829856873, Final Batch Loss: 0.40646830201148987\n",
      "Epoch 1551, Loss: 1.4752881824970245, Final Batch Loss: 0.47888797521591187\n",
      "Epoch 1552, Loss: 1.5137380063533783, Final Batch Loss: 0.38728800415992737\n",
      "Epoch 1553, Loss: 1.629548966884613, Final Batch Loss: 0.48403698205947876\n",
      "Epoch 1554, Loss: 1.3942041993141174, Final Batch Loss: 0.354812890291214\n",
      "Epoch 1555, Loss: 1.525181919336319, Final Batch Loss: 0.4005706310272217\n",
      "Epoch 1556, Loss: 1.475378692150116, Final Batch Loss: 0.3536689579486847\n",
      "Epoch 1557, Loss: 1.570586919784546, Final Batch Loss: 0.41027364134788513\n",
      "Epoch 1558, Loss: 1.5671390295028687, Final Batch Loss: 0.40288588404655457\n",
      "Epoch 1559, Loss: 1.4912680983543396, Final Batch Loss: 0.34951111674308777\n",
      "Epoch 1560, Loss: 1.4425150752067566, Final Batch Loss: 0.35104140639305115\n",
      "Epoch 1561, Loss: 1.4598592221736908, Final Batch Loss: 0.3304746150970459\n",
      "Epoch 1562, Loss: 1.6183602511882782, Final Batch Loss: 0.45633113384246826\n",
      "Epoch 1563, Loss: 1.3118390440940857, Final Batch Loss: 0.32940828800201416\n",
      "Epoch 1564, Loss: 1.562613993883133, Final Batch Loss: 0.41389790177345276\n",
      "Epoch 1565, Loss: 1.6323191821575165, Final Batch Loss: 0.5455724596977234\n",
      "Epoch 1566, Loss: 1.4882973730564117, Final Batch Loss: 0.43968918919563293\n",
      "Epoch 1567, Loss: 1.4974963963031769, Final Batch Loss: 0.43897175788879395\n",
      "Epoch 1568, Loss: 1.4940145611763, Final Batch Loss: 0.4043344259262085\n",
      "Epoch 1569, Loss: 1.411033421754837, Final Batch Loss: 0.3763176500797272\n",
      "Epoch 1570, Loss: 1.5502530932426453, Final Batch Loss: 0.4640733599662781\n",
      "Epoch 1571, Loss: 1.5106782019138336, Final Batch Loss: 0.3841392993927002\n",
      "Epoch 1572, Loss: 1.5012617409229279, Final Batch Loss: 0.3426833748817444\n",
      "Epoch 1573, Loss: 1.5420779287815094, Final Batch Loss: 0.3138374388217926\n",
      "Epoch 1574, Loss: 1.5193705558776855, Final Batch Loss: 0.38737502694129944\n",
      "Epoch 1575, Loss: 1.593828022480011, Final Batch Loss: 0.3772250711917877\n",
      "Epoch 1576, Loss: 1.4807497560977936, Final Batch Loss: 0.3589188754558563\n",
      "Epoch 1577, Loss: 1.4360535740852356, Final Batch Loss: 0.31943222880363464\n",
      "Epoch 1578, Loss: 1.5988803803920746, Final Batch Loss: 0.4864093065261841\n",
      "Epoch 1579, Loss: 1.5336811542510986, Final Batch Loss: 0.3748451769351959\n",
      "Epoch 1580, Loss: 1.3484766483306885, Final Batch Loss: 0.2772505283355713\n",
      "Epoch 1581, Loss: 1.5384014248847961, Final Batch Loss: 0.3931508958339691\n",
      "Epoch 1582, Loss: 1.603535383939743, Final Batch Loss: 0.5178439617156982\n",
      "Epoch 1583, Loss: 1.4268783926963806, Final Batch Loss: 0.28435441851615906\n",
      "Epoch 1584, Loss: 1.5730961561203003, Final Batch Loss: 0.4596139192581177\n",
      "Epoch 1585, Loss: 1.4608436822891235, Final Batch Loss: 0.37761756777763367\n",
      "Epoch 1586, Loss: 1.479193776845932, Final Batch Loss: 0.4026477038860321\n",
      "Epoch 1587, Loss: 1.5592588186264038, Final Batch Loss: 0.4088931083679199\n",
      "Epoch 1588, Loss: 1.4898451566696167, Final Batch Loss: 0.26541867852211\n",
      "Epoch 1589, Loss: 1.3943104147911072, Final Batch Loss: 0.30633288621902466\n",
      "Epoch 1590, Loss: 1.4292559921741486, Final Batch Loss: 0.40395495295524597\n",
      "Epoch 1591, Loss: 1.4490399062633514, Final Batch Loss: 0.2621772289276123\n",
      "Epoch 1592, Loss: 1.6200705766677856, Final Batch Loss: 0.38812246918678284\n",
      "Epoch 1593, Loss: 1.5362790822982788, Final Batch Loss: 0.47722291946411133\n",
      "Epoch 1594, Loss: 1.583677887916565, Final Batch Loss: 0.41673707962036133\n",
      "Epoch 1595, Loss: 1.461748093366623, Final Batch Loss: 0.3609561324119568\n",
      "Epoch 1596, Loss: 1.5403338074684143, Final Batch Loss: 0.4647688567638397\n",
      "Epoch 1597, Loss: 1.558726191520691, Final Batch Loss: 0.42872247099876404\n",
      "Epoch 1598, Loss: 1.5849571526050568, Final Batch Loss: 0.38621261715888977\n",
      "Epoch 1599, Loss: 1.4854143261909485, Final Batch Loss: 0.4111257791519165\n",
      "Epoch 1600, Loss: 1.6206493377685547, Final Batch Loss: 0.4064021706581116\n",
      "Epoch 1601, Loss: 1.6229159235954285, Final Batch Loss: 0.38609129190444946\n",
      "Epoch 1602, Loss: 1.3369945883750916, Final Batch Loss: 0.357279509305954\n",
      "Epoch 1603, Loss: 1.359730303287506, Final Batch Loss: 0.2412186861038208\n",
      "Epoch 1604, Loss: 1.4108097851276398, Final Batch Loss: 0.32899749279022217\n",
      "Epoch 1605, Loss: 1.4640068113803864, Final Batch Loss: 0.2981507182121277\n",
      "Epoch 1606, Loss: 1.3821178674697876, Final Batch Loss: 0.37232473492622375\n",
      "Epoch 1607, Loss: 1.4990084767341614, Final Batch Loss: 0.3985505998134613\n",
      "Epoch 1608, Loss: 1.4007675051689148, Final Batch Loss: 0.2852494418621063\n",
      "Epoch 1609, Loss: 1.482641875743866, Final Batch Loss: 0.30907389521598816\n",
      "Epoch 1610, Loss: 1.4241365492343903, Final Batch Loss: 0.2953616976737976\n",
      "Epoch 1611, Loss: 1.6219769418239594, Final Batch Loss: 0.5064505934715271\n",
      "Epoch 1612, Loss: 1.5174565315246582, Final Batch Loss: 0.42715325951576233\n",
      "Epoch 1613, Loss: 1.5903866291046143, Final Batch Loss: 0.4583466649055481\n",
      "Epoch 1614, Loss: 1.511066049337387, Final Batch Loss: 0.3949054777622223\n",
      "Epoch 1615, Loss: 1.569141536951065, Final Batch Loss: 0.3999811112880707\n",
      "Epoch 1616, Loss: 1.353370487689972, Final Batch Loss: 0.25606250762939453\n",
      "Epoch 1617, Loss: 1.5703583657741547, Final Batch Loss: 0.4324909448623657\n",
      "Epoch 1618, Loss: 1.4026510119438171, Final Batch Loss: 0.37101078033447266\n",
      "Epoch 1619, Loss: 1.5443860292434692, Final Batch Loss: 0.40235182642936707\n",
      "Epoch 1620, Loss: 1.4559669494628906, Final Batch Loss: 0.2906934320926666\n",
      "Epoch 1621, Loss: 1.430189162492752, Final Batch Loss: 0.33568906784057617\n",
      "Epoch 1622, Loss: 1.4065974950790405, Final Batch Loss: 0.30866554379463196\n",
      "Epoch 1623, Loss: 1.4082812666893005, Final Batch Loss: 0.36473044753074646\n",
      "Epoch 1624, Loss: 1.3684857785701752, Final Batch Loss: 0.3698646128177643\n",
      "Epoch 1625, Loss: 1.568538099527359, Final Batch Loss: 0.45536842942237854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1626, Loss: 1.5440522134304047, Final Batch Loss: 0.40560659766197205\n",
      "Epoch 1627, Loss: 1.5796931684017181, Final Batch Loss: 0.5698493123054504\n",
      "Epoch 1628, Loss: 1.409803330898285, Final Batch Loss: 0.28311625123023987\n",
      "Epoch 1629, Loss: 1.5653572380542755, Final Batch Loss: 0.4373921751976013\n",
      "Epoch 1630, Loss: 1.4698327481746674, Final Batch Loss: 0.28238996863365173\n",
      "Epoch 1631, Loss: 1.414198100566864, Final Batch Loss: 0.31622716784477234\n",
      "Epoch 1632, Loss: 1.4845542013645172, Final Batch Loss: 0.37197813391685486\n",
      "Epoch 1633, Loss: 1.4625470638275146, Final Batch Loss: 0.37117618322372437\n",
      "Epoch 1634, Loss: 1.601197600364685, Final Batch Loss: 0.5646363496780396\n",
      "Epoch 1635, Loss: 1.4905580580234528, Final Batch Loss: 0.4290992319583893\n",
      "Epoch 1636, Loss: 1.5053077936172485, Final Batch Loss: 0.40383994579315186\n",
      "Epoch 1637, Loss: 1.5478916764259338, Final Batch Loss: 0.3981506824493408\n",
      "Epoch 1638, Loss: 1.474813550710678, Final Batch Loss: 0.40867847204208374\n",
      "Epoch 1639, Loss: 1.4109643399715424, Final Batch Loss: 0.35211336612701416\n",
      "Epoch 1640, Loss: 1.370210587978363, Final Batch Loss: 0.2717825174331665\n",
      "Epoch 1641, Loss: 1.4504387378692627, Final Batch Loss: 0.37454867362976074\n",
      "Epoch 1642, Loss: 1.3645880818367004, Final Batch Loss: 0.32480332255363464\n",
      "Epoch 1643, Loss: 1.4147981107234955, Final Batch Loss: 0.3616516888141632\n",
      "Epoch 1644, Loss: 1.395512580871582, Final Batch Loss: 0.36654987931251526\n",
      "Epoch 1645, Loss: 1.4936129450798035, Final Batch Loss: 0.28205606341362\n",
      "Epoch 1646, Loss: 1.4441885948181152, Final Batch Loss: 0.39504510164260864\n",
      "Epoch 1647, Loss: 1.3442904651165009, Final Batch Loss: 0.3222963809967041\n",
      "Epoch 1648, Loss: 1.602582037448883, Final Batch Loss: 0.35710451006889343\n",
      "Epoch 1649, Loss: 1.66630819439888, Final Batch Loss: 0.3509322702884674\n",
      "Epoch 1650, Loss: 1.493417203426361, Final Batch Loss: 0.36303234100341797\n",
      "Epoch 1651, Loss: 1.451042890548706, Final Batch Loss: 0.3750443458557129\n",
      "Epoch 1652, Loss: 1.5413038432598114, Final Batch Loss: 0.45209598541259766\n",
      "Epoch 1653, Loss: 1.4808787405490875, Final Batch Loss: 0.28735244274139404\n",
      "Epoch 1654, Loss: 1.5690963864326477, Final Batch Loss: 0.36189666390419006\n",
      "Epoch 1655, Loss: 1.422804206609726, Final Batch Loss: 0.337708979845047\n",
      "Epoch 1656, Loss: 1.4700302481651306, Final Batch Loss: 0.37314513325691223\n",
      "Epoch 1657, Loss: 1.6966960728168488, Final Batch Loss: 0.6228095293045044\n",
      "Epoch 1658, Loss: 1.347973644733429, Final Batch Loss: 0.35383301973342896\n",
      "Epoch 1659, Loss: 1.4536469280719757, Final Batch Loss: 0.2803345322608948\n",
      "Epoch 1660, Loss: 1.4763424098491669, Final Batch Loss: 0.44828933477401733\n",
      "Epoch 1661, Loss: 1.4007052779197693, Final Batch Loss: 0.21474623680114746\n",
      "Epoch 1662, Loss: 1.4003470540046692, Final Batch Loss: 0.31429558992385864\n",
      "Epoch 1663, Loss: 1.380094289779663, Final Batch Loss: 0.2978510856628418\n",
      "Epoch 1664, Loss: 1.4246718883514404, Final Batch Loss: 0.3403773605823517\n",
      "Epoch 1665, Loss: 1.5658245086669922, Final Batch Loss: 0.5074198842048645\n",
      "Epoch 1666, Loss: 1.4792885184288025, Final Batch Loss: 0.3400745689868927\n",
      "Epoch 1667, Loss: 1.4656108915805817, Final Batch Loss: 0.40975895524024963\n",
      "Epoch 1668, Loss: 1.3598509728908539, Final Batch Loss: 0.30461376905441284\n",
      "Epoch 1669, Loss: 1.4887852370738983, Final Batch Loss: 0.37229931354522705\n",
      "Epoch 1670, Loss: 1.3355700969696045, Final Batch Loss: 0.2483026087284088\n",
      "Epoch 1671, Loss: 1.535863310098648, Final Batch Loss: 0.44992706179618835\n",
      "Epoch 1672, Loss: 1.3781821429729462, Final Batch Loss: 0.3038727641105652\n",
      "Epoch 1673, Loss: 1.5387313961982727, Final Batch Loss: 0.413912296295166\n",
      "Epoch 1674, Loss: 1.4266745150089264, Final Batch Loss: 0.28417253494262695\n",
      "Epoch 1675, Loss: 1.339787244796753, Final Batch Loss: 0.27725785970687866\n",
      "Epoch 1676, Loss: 1.357999324798584, Final Batch Loss: 0.318864643573761\n",
      "Epoch 1677, Loss: 1.3752376735210419, Final Batch Loss: 0.28515028953552246\n",
      "Epoch 1678, Loss: 1.4959993958473206, Final Batch Loss: 0.42230603098869324\n",
      "Epoch 1679, Loss: 1.5247430801391602, Final Batch Loss: 0.37345069646835327\n",
      "Epoch 1680, Loss: 1.4704473614692688, Final Batch Loss: 0.3909386992454529\n",
      "Epoch 1681, Loss: 1.415826678276062, Final Batch Loss: 0.27534836530685425\n",
      "Epoch 1682, Loss: 1.4699995815753937, Final Batch Loss: 0.2927396595478058\n",
      "Epoch 1683, Loss: 1.4771054685115814, Final Batch Loss: 0.3870801031589508\n",
      "Epoch 1684, Loss: 1.5230126678943634, Final Batch Loss: 0.45843538641929626\n",
      "Epoch 1685, Loss: 1.3843069672584534, Final Batch Loss: 0.3411196172237396\n",
      "Epoch 1686, Loss: 1.4051736295223236, Final Batch Loss: 0.38271626830101013\n",
      "Epoch 1687, Loss: 1.4039528369903564, Final Batch Loss: 0.3208516836166382\n",
      "Epoch 1688, Loss: 1.3680302798748016, Final Batch Loss: 0.3066866993904114\n",
      "Epoch 1689, Loss: 1.3834896236658096, Final Batch Loss: 0.24021513760089874\n",
      "Epoch 1690, Loss: 1.4945886731147766, Final Batch Loss: 0.3939497768878937\n",
      "Epoch 1691, Loss: 1.429303377866745, Final Batch Loss: 0.3619588613510132\n",
      "Epoch 1692, Loss: 1.4546846449375153, Final Batch Loss: 0.41421425342559814\n",
      "Epoch 1693, Loss: 1.4623434841632843, Final Batch Loss: 0.333869069814682\n",
      "Epoch 1694, Loss: 1.4625815451145172, Final Batch Loss: 0.43302246928215027\n",
      "Epoch 1695, Loss: 1.4421892166137695, Final Batch Loss: 0.3174351453781128\n",
      "Epoch 1696, Loss: 1.3051459193229675, Final Batch Loss: 0.2670113742351532\n",
      "Epoch 1697, Loss: 1.5531724095344543, Final Batch Loss: 0.44107934832572937\n",
      "Epoch 1698, Loss: 1.429579883813858, Final Batch Loss: 0.33887341618537903\n",
      "Epoch 1699, Loss: 1.4808411002159119, Final Batch Loss: 0.4746573269367218\n",
      "Epoch 1700, Loss: 1.3718777894973755, Final Batch Loss: 0.3239584267139435\n",
      "Epoch 1701, Loss: 1.547796905040741, Final Batch Loss: 0.43605905771255493\n",
      "Epoch 1702, Loss: 1.531743973493576, Final Batch Loss: 0.36180949211120605\n",
      "Epoch 1703, Loss: 1.4388604760169983, Final Batch Loss: 0.37133538722991943\n",
      "Epoch 1704, Loss: 1.3931290805339813, Final Batch Loss: 0.34130173921585083\n",
      "Epoch 1705, Loss: 1.465658724308014, Final Batch Loss: 0.38801491260528564\n",
      "Epoch 1706, Loss: 1.4196751117706299, Final Batch Loss: 0.3955685496330261\n",
      "Epoch 1707, Loss: 1.4961374998092651, Final Batch Loss: 0.42266806960105896\n",
      "Epoch 1708, Loss: 1.6135138869285583, Final Batch Loss: 0.4824729859828949\n",
      "Epoch 1709, Loss: 1.4701688587665558, Final Batch Loss: 0.3934521973133087\n",
      "Epoch 1710, Loss: 1.448024958372116, Final Batch Loss: 0.32689058780670166\n",
      "Epoch 1711, Loss: 1.4801470339298248, Final Batch Loss: 0.34255272150039673\n",
      "Epoch 1712, Loss: 1.5199906826019287, Final Batch Loss: 0.3782493472099304\n",
      "Epoch 1713, Loss: 1.5358697772026062, Final Batch Loss: 0.37380823493003845\n",
      "Epoch 1714, Loss: 1.4232105612754822, Final Batch Loss: 0.3749578297138214\n",
      "Epoch 1715, Loss: 1.4399689137935638, Final Batch Loss: 0.35966840386390686\n",
      "Epoch 1716, Loss: 1.3791361302137375, Final Batch Loss: 0.23357154428958893\n",
      "Epoch 1717, Loss: 1.4215036630630493, Final Batch Loss: 0.36210301518440247\n",
      "Epoch 1718, Loss: 1.5084044635295868, Final Batch Loss: 0.30486196279525757\n",
      "Epoch 1719, Loss: 1.5082236528396606, Final Batch Loss: 0.3542180061340332\n",
      "Epoch 1720, Loss: 1.4848977625370026, Final Batch Loss: 0.3770783543586731\n",
      "Epoch 1721, Loss: 1.3898654282093048, Final Batch Loss: 0.33677420020103455\n",
      "Epoch 1722, Loss: 1.4432669579982758, Final Batch Loss: 0.4199029803276062\n",
      "Epoch 1723, Loss: 1.4853402078151703, Final Batch Loss: 0.4067600965499878\n",
      "Epoch 1724, Loss: 1.411313235759735, Final Batch Loss: 0.31362512707710266\n",
      "Epoch 1725, Loss: 1.290222316980362, Final Batch Loss: 0.24564197659492493\n",
      "Epoch 1726, Loss: 1.414849042892456, Final Batch Loss: 0.3665052354335785\n",
      "Epoch 1727, Loss: 1.3853947818279266, Final Batch Loss: 0.3392851948738098\n",
      "Epoch 1728, Loss: 1.2066334038972855, Final Batch Loss: 0.19473905861377716\n",
      "Epoch 1729, Loss: 1.4971666932106018, Final Batch Loss: 0.3942866325378418\n",
      "Epoch 1730, Loss: 1.464144080877304, Final Batch Loss: 0.3550240993499756\n",
      "Epoch 1731, Loss: 1.410333901643753, Final Batch Loss: 0.3233063220977783\n",
      "Epoch 1732, Loss: 1.3984254896640778, Final Batch Loss: 0.3399198353290558\n",
      "Epoch 1733, Loss: 1.4159249365329742, Final Batch Loss: 0.39795926213264465\n",
      "Epoch 1734, Loss: 1.416792094707489, Final Batch Loss: 0.36497220396995544\n",
      "Epoch 1735, Loss: 1.3300872147083282, Final Batch Loss: 0.28253400325775146\n",
      "Epoch 1736, Loss: 1.3740968108177185, Final Batch Loss: 0.37246280908584595\n",
      "Epoch 1737, Loss: 1.385723352432251, Final Batch Loss: 0.3490214943885803\n",
      "Epoch 1738, Loss: 1.4533109962940216, Final Batch Loss: 0.436242014169693\n",
      "Epoch 1739, Loss: 1.4452922642230988, Final Batch Loss: 0.38801658153533936\n",
      "Epoch 1740, Loss: 1.547398865222931, Final Batch Loss: 0.3537401854991913\n",
      "Epoch 1741, Loss: 1.6324359476566315, Final Batch Loss: 0.5027056336402893\n",
      "Epoch 1742, Loss: 1.3672866523265839, Final Batch Loss: 0.3017009198665619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1743, Loss: 1.475999116897583, Final Batch Loss: 0.38144734501838684\n",
      "Epoch 1744, Loss: 1.4365366995334625, Final Batch Loss: 0.4579629898071289\n",
      "Epoch 1745, Loss: 1.396066814661026, Final Batch Loss: 0.3031950294971466\n",
      "Epoch 1746, Loss: 1.4457812011241913, Final Batch Loss: 0.31753161549568176\n",
      "Epoch 1747, Loss: 1.3888772130012512, Final Batch Loss: 0.39874711632728577\n",
      "Epoch 1748, Loss: 1.3564474880695343, Final Batch Loss: 0.3162757158279419\n",
      "Epoch 1749, Loss: 1.3545880019664764, Final Batch Loss: 0.34338143467903137\n",
      "Epoch 1750, Loss: 1.4333745539188385, Final Batch Loss: 0.4220263957977295\n",
      "Epoch 1751, Loss: 1.4734951257705688, Final Batch Loss: 0.3914603590965271\n",
      "Epoch 1752, Loss: 1.4178564101457596, Final Batch Loss: 0.22904808819293976\n",
      "Epoch 1753, Loss: 1.4212101697921753, Final Batch Loss: 0.2941104769706726\n",
      "Epoch 1754, Loss: 1.3923149704933167, Final Batch Loss: 0.3007987141609192\n",
      "Epoch 1755, Loss: 1.620471715927124, Final Batch Loss: 0.5003891587257385\n",
      "Epoch 1756, Loss: 1.4759277701377869, Final Batch Loss: 0.3540908992290497\n",
      "Epoch 1757, Loss: 1.4339002072811127, Final Batch Loss: 0.36089086532592773\n",
      "Epoch 1758, Loss: 1.3822413086891174, Final Batch Loss: 0.36122560501098633\n",
      "Epoch 1759, Loss: 1.4215454459190369, Final Batch Loss: 0.41942793130874634\n",
      "Epoch 1760, Loss: 1.4336491823196411, Final Batch Loss: 0.33485111594200134\n",
      "Epoch 1761, Loss: 1.3977226316928864, Final Batch Loss: 0.2864086925983429\n",
      "Epoch 1762, Loss: 1.3161679208278656, Final Batch Loss: 0.3076109290122986\n",
      "Epoch 1763, Loss: 1.5100688636302948, Final Batch Loss: 0.3010886609554291\n",
      "Epoch 1764, Loss: 1.484914094209671, Final Batch Loss: 0.4070090651512146\n",
      "Epoch 1765, Loss: 1.4374691843986511, Final Batch Loss: 0.349939227104187\n",
      "Epoch 1766, Loss: 1.4042138755321503, Final Batch Loss: 0.3721455931663513\n",
      "Epoch 1767, Loss: 1.3908914625644684, Final Batch Loss: 0.2824261486530304\n",
      "Epoch 1768, Loss: 1.2575425207614899, Final Batch Loss: 0.30629006028175354\n",
      "Epoch 1769, Loss: 1.534694880247116, Final Batch Loss: 0.39764800667762756\n",
      "Epoch 1770, Loss: 1.3975552022457123, Final Batch Loss: 0.334922730922699\n",
      "Epoch 1771, Loss: 1.5415000319480896, Final Batch Loss: 0.3379766643047333\n",
      "Epoch 1772, Loss: 1.452987402677536, Final Batch Loss: 0.36933496594429016\n",
      "Epoch 1773, Loss: 1.4456811845302582, Final Batch Loss: 0.35579556226730347\n",
      "Epoch 1774, Loss: 1.4295081794261932, Final Batch Loss: 0.3236795961856842\n",
      "Epoch 1775, Loss: 1.391087532043457, Final Batch Loss: 0.3339223861694336\n",
      "Epoch 1776, Loss: 1.4001112878322601, Final Batch Loss: 0.33903488516807556\n",
      "Epoch 1777, Loss: 1.3333424925804138, Final Batch Loss: 0.24797028303146362\n",
      "Epoch 1778, Loss: 1.5064036548137665, Final Batch Loss: 0.3769821226596832\n",
      "Epoch 1779, Loss: 1.4854786098003387, Final Batch Loss: 0.40271642804145813\n",
      "Epoch 1780, Loss: 1.612565815448761, Final Batch Loss: 0.4273616075515747\n",
      "Epoch 1781, Loss: 1.444800704717636, Final Batch Loss: 0.3179457187652588\n",
      "Epoch 1782, Loss: 1.3756836950778961, Final Batch Loss: 0.355610728263855\n",
      "Epoch 1783, Loss: 1.3204324841499329, Final Batch Loss: 0.2645856738090515\n",
      "Epoch 1784, Loss: 1.413611263036728, Final Batch Loss: 0.30897703766822815\n",
      "Epoch 1785, Loss: 1.4364556968212128, Final Batch Loss: 0.3421771824359894\n",
      "Epoch 1786, Loss: 1.354045420885086, Final Batch Loss: 0.2892141044139862\n",
      "Epoch 1787, Loss: 1.3778158724308014, Final Batch Loss: 0.2713582217693329\n",
      "Epoch 1788, Loss: 1.4404262602329254, Final Batch Loss: 0.2874247133731842\n",
      "Epoch 1789, Loss: 1.4699856638908386, Final Batch Loss: 0.41284236311912537\n",
      "Epoch 1790, Loss: 1.2930294275283813, Final Batch Loss: 0.25446683168411255\n",
      "Epoch 1791, Loss: 1.4735525846481323, Final Batch Loss: 0.3112129867076874\n",
      "Epoch 1792, Loss: 1.5048027336597443, Final Batch Loss: 0.5055001378059387\n",
      "Epoch 1793, Loss: 1.5180992186069489, Final Batch Loss: 0.39400017261505127\n",
      "Epoch 1794, Loss: 1.3947397470474243, Final Batch Loss: 0.3790190517902374\n",
      "Epoch 1795, Loss: 1.4461307525634766, Final Batch Loss: 0.4036865532398224\n",
      "Epoch 1796, Loss: 1.416302502155304, Final Batch Loss: 0.3310459852218628\n",
      "Epoch 1797, Loss: 1.4087011218070984, Final Batch Loss: 0.29937076568603516\n",
      "Epoch 1798, Loss: 1.4425115883350372, Final Batch Loss: 0.33404675126075745\n",
      "Epoch 1799, Loss: 1.4685222208499908, Final Batch Loss: 0.405155211687088\n",
      "Epoch 1800, Loss: 1.3228376805782318, Final Batch Loss: 0.28992214798927307\n",
      "Epoch 1801, Loss: 1.3745456635951996, Final Batch Loss: 0.2829284071922302\n",
      "Epoch 1802, Loss: 1.3774371445178986, Final Batch Loss: 0.37468385696411133\n",
      "Epoch 1803, Loss: 1.4512777030467987, Final Batch Loss: 0.3619874119758606\n",
      "Epoch 1804, Loss: 1.3412118256092072, Final Batch Loss: 0.3536912500858307\n",
      "Epoch 1805, Loss: 1.3133533000946045, Final Batch Loss: 0.2988375127315521\n",
      "Epoch 1806, Loss: 1.5071074068546295, Final Batch Loss: 0.3754746615886688\n",
      "Epoch 1807, Loss: 1.3605731427669525, Final Batch Loss: 0.37574949860572815\n",
      "Epoch 1808, Loss: 1.254706233739853, Final Batch Loss: 0.33959832787513733\n",
      "Epoch 1809, Loss: 1.3549834787845612, Final Batch Loss: 0.30223384499549866\n",
      "Epoch 1810, Loss: 1.5652001798152924, Final Batch Loss: 0.4086737036705017\n",
      "Epoch 1811, Loss: 1.4422797858715057, Final Batch Loss: 0.3203958570957184\n",
      "Epoch 1812, Loss: 1.532704085111618, Final Batch Loss: 0.4225192070007324\n",
      "Epoch 1813, Loss: 1.421339362859726, Final Batch Loss: 0.3299698233604431\n",
      "Epoch 1814, Loss: 1.3403216898441315, Final Batch Loss: 0.32672959566116333\n",
      "Epoch 1815, Loss: 1.4221568703651428, Final Batch Loss: 0.3239315450191498\n",
      "Epoch 1816, Loss: 1.3663137257099152, Final Batch Loss: 0.31282633543014526\n",
      "Epoch 1817, Loss: 1.5536766648292542, Final Batch Loss: 0.31937268376350403\n",
      "Epoch 1818, Loss: 1.3705487251281738, Final Batch Loss: 0.3425913453102112\n",
      "Epoch 1819, Loss: 1.435765951871872, Final Batch Loss: 0.3764633536338806\n",
      "Epoch 1820, Loss: 1.3003797233104706, Final Batch Loss: 0.3161504566669464\n",
      "Epoch 1821, Loss: 1.3461659848690033, Final Batch Loss: 0.30409911274909973\n",
      "Epoch 1822, Loss: 1.407391756772995, Final Batch Loss: 0.36499345302581787\n",
      "Epoch 1823, Loss: 1.3286923170089722, Final Batch Loss: 0.3413020074367523\n",
      "Epoch 1824, Loss: 1.3240925073623657, Final Batch Loss: 0.2856791317462921\n",
      "Epoch 1825, Loss: 1.2696141004562378, Final Batch Loss: 0.3042271137237549\n",
      "Epoch 1826, Loss: 1.466616153717041, Final Batch Loss: 0.31595465540885925\n",
      "Epoch 1827, Loss: 1.393224149942398, Final Batch Loss: 0.435224711894989\n",
      "Epoch 1828, Loss: 1.3073481917381287, Final Batch Loss: 0.30007264018058777\n",
      "Epoch 1829, Loss: 1.4417315423488617, Final Batch Loss: 0.4207579493522644\n",
      "Epoch 1830, Loss: 1.4054201543331146, Final Batch Loss: 0.3229078948497772\n",
      "Epoch 1831, Loss: 1.4665398299694061, Final Batch Loss: 0.4235245883464813\n",
      "Epoch 1832, Loss: 1.5540765821933746, Final Batch Loss: 0.4033821225166321\n",
      "Epoch 1833, Loss: 1.6392214000225067, Final Batch Loss: 0.4132091701030731\n",
      "Epoch 1834, Loss: 1.4308010637760162, Final Batch Loss: 0.4288221299648285\n",
      "Epoch 1835, Loss: 1.3397828936576843, Final Batch Loss: 0.27697110176086426\n",
      "Epoch 1836, Loss: 1.4287468194961548, Final Batch Loss: 0.37747085094451904\n",
      "Epoch 1837, Loss: 1.3925310969352722, Final Batch Loss: 0.3569641411304474\n",
      "Epoch 1838, Loss: 1.306884527206421, Final Batch Loss: 0.2668493390083313\n",
      "Epoch 1839, Loss: 1.2748397588729858, Final Batch Loss: 0.2848571836948395\n",
      "Epoch 1840, Loss: 1.4262107908725739, Final Batch Loss: 0.3036089539527893\n",
      "Epoch 1841, Loss: 1.3324052393436432, Final Batch Loss: 0.35217416286468506\n",
      "Epoch 1842, Loss: 1.4760608971118927, Final Batch Loss: 0.37950512766838074\n",
      "Epoch 1843, Loss: 1.4323116540908813, Final Batch Loss: 0.42949578166007996\n",
      "Epoch 1844, Loss: 1.4368974268436432, Final Batch Loss: 0.32428884506225586\n",
      "Epoch 1845, Loss: 1.3413182199001312, Final Batch Loss: 0.3317956328392029\n",
      "Epoch 1846, Loss: 1.4674611985683441, Final Batch Loss: 0.4051434099674225\n",
      "Epoch 1847, Loss: 1.3851913213729858, Final Batch Loss: 0.3750120997428894\n",
      "Epoch 1848, Loss: 1.4163779020309448, Final Batch Loss: 0.335951030254364\n",
      "Epoch 1849, Loss: 1.4145218431949615, Final Batch Loss: 0.3627023994922638\n",
      "Epoch 1850, Loss: 1.347206950187683, Final Batch Loss: 0.3232761323451996\n",
      "Epoch 1851, Loss: 1.3536107242107391, Final Batch Loss: 0.31833046674728394\n",
      "Epoch 1852, Loss: 1.305035725235939, Final Batch Loss: 0.21595807373523712\n",
      "Epoch 1853, Loss: 1.3904052078723907, Final Batch Loss: 0.3661902844905853\n",
      "Epoch 1854, Loss: 1.5000743865966797, Final Batch Loss: 0.42991605401039124\n",
      "Epoch 1855, Loss: 1.3352898061275482, Final Batch Loss: 0.39567041397094727\n",
      "Epoch 1856, Loss: 1.4596502184867859, Final Batch Loss: 0.429446816444397\n",
      "Epoch 1857, Loss: 1.2918933182954788, Final Batch Loss: 0.2405119389295578\n",
      "Epoch 1858, Loss: 1.3772939145565033, Final Batch Loss: 0.30234354734420776\n",
      "Epoch 1859, Loss: 1.4841426014900208, Final Batch Loss: 0.36618587374687195\n",
      "Epoch 1860, Loss: 1.374588519334793, Final Batch Loss: 0.34466949105262756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1861, Loss: 1.3752063661813736, Final Batch Loss: 0.48470690846443176\n",
      "Epoch 1862, Loss: 1.4058326482772827, Final Batch Loss: 0.36873847246170044\n",
      "Epoch 1863, Loss: 1.4218013286590576, Final Batch Loss: 0.39826127886772156\n",
      "Epoch 1864, Loss: 1.334562748670578, Final Batch Loss: 0.23530268669128418\n",
      "Epoch 1865, Loss: 1.3785228729248047, Final Batch Loss: 0.3008343279361725\n",
      "Epoch 1866, Loss: 1.3880750238895416, Final Batch Loss: 0.2741880714893341\n",
      "Epoch 1867, Loss: 1.3857005536556244, Final Batch Loss: 0.42501938343048096\n",
      "Epoch 1868, Loss: 1.4284064769744873, Final Batch Loss: 0.376404732465744\n",
      "Epoch 1869, Loss: 1.4863207936286926, Final Batch Loss: 0.48916158080101013\n",
      "Epoch 1870, Loss: 1.3969060480594635, Final Batch Loss: 0.30624938011169434\n",
      "Epoch 1871, Loss: 1.5319503545761108, Final Batch Loss: 0.44800135493278503\n",
      "Epoch 1872, Loss: 1.4896505177021027, Final Batch Loss: 0.3842187821865082\n",
      "Epoch 1873, Loss: 1.2737209796905518, Final Batch Loss: 0.3079638183116913\n",
      "Epoch 1874, Loss: 1.3321318924427032, Final Batch Loss: 0.2513870298862457\n",
      "Epoch 1875, Loss: 1.4935551285743713, Final Batch Loss: 0.43616005778312683\n",
      "Epoch 1876, Loss: 1.446339800953865, Final Batch Loss: 0.4479924142360687\n",
      "Epoch 1877, Loss: 1.2992012798786163, Final Batch Loss: 0.2566103935241699\n",
      "Epoch 1878, Loss: 1.3297093212604523, Final Batch Loss: 0.40714749693870544\n",
      "Epoch 1879, Loss: 1.3970457315444946, Final Batch Loss: 0.2535976767539978\n",
      "Epoch 1880, Loss: 1.3507460355758667, Final Batch Loss: 0.33448752760887146\n",
      "Epoch 1881, Loss: 1.2695687115192413, Final Batch Loss: 0.2742301821708679\n",
      "Epoch 1882, Loss: 1.344104290008545, Final Batch Loss: 0.26643115282058716\n",
      "Epoch 1883, Loss: 1.3953563570976257, Final Batch Loss: 0.36072227358818054\n",
      "Epoch 1884, Loss: 1.3208833932876587, Final Batch Loss: 0.3222595155239105\n",
      "Epoch 1885, Loss: 1.4441512525081635, Final Batch Loss: 0.4095786213874817\n",
      "Epoch 1886, Loss: 1.3345344364643097, Final Batch Loss: 0.3584570288658142\n",
      "Epoch 1887, Loss: 1.4185721576213837, Final Batch Loss: 0.319912314414978\n",
      "Epoch 1888, Loss: 1.4553681910037994, Final Batch Loss: 0.33290359377861023\n",
      "Epoch 1889, Loss: 1.3392578065395355, Final Batch Loss: 0.28068816661834717\n",
      "Epoch 1890, Loss: 1.2826724350452423, Final Batch Loss: 0.2793402075767517\n",
      "Epoch 1891, Loss: 1.4426556825637817, Final Batch Loss: 0.30063876509666443\n",
      "Epoch 1892, Loss: 1.4202340245246887, Final Batch Loss: 0.34495365619659424\n",
      "Epoch 1893, Loss: 1.3217633068561554, Final Batch Loss: 0.3466138243675232\n",
      "Epoch 1894, Loss: 1.4701929837465286, Final Batch Loss: 0.505142331123352\n",
      "Epoch 1895, Loss: 1.3993332386016846, Final Batch Loss: 0.42777952551841736\n",
      "Epoch 1896, Loss: 1.3569411039352417, Final Batch Loss: 0.27555787563323975\n",
      "Epoch 1897, Loss: 1.5183792114257812, Final Batch Loss: 0.4254373013973236\n",
      "Epoch 1898, Loss: 1.4617858827114105, Final Batch Loss: 0.43966415524482727\n",
      "Epoch 1899, Loss: 1.2977957129478455, Final Batch Loss: 0.29958856105804443\n",
      "Epoch 1900, Loss: 1.4811314642429352, Final Batch Loss: 0.41224661469459534\n",
      "Epoch 1901, Loss: 1.2799146473407745, Final Batch Loss: 0.35101228952407837\n",
      "Epoch 1902, Loss: 1.355044275522232, Final Batch Loss: 0.3332602083683014\n",
      "Epoch 1903, Loss: 1.3427408635616302, Final Batch Loss: 0.29601168632507324\n",
      "Epoch 1904, Loss: 1.3069061040878296, Final Batch Loss: 0.30999964475631714\n",
      "Epoch 1905, Loss: 1.3068598806858063, Final Batch Loss: 0.3387092053890228\n",
      "Epoch 1906, Loss: 1.3546515107154846, Final Batch Loss: 0.37579914927482605\n",
      "Epoch 1907, Loss: 1.3533046543598175, Final Batch Loss: 0.41021186113357544\n",
      "Epoch 1908, Loss: 1.347851723432541, Final Batch Loss: 0.31232762336730957\n",
      "Epoch 1909, Loss: 1.4688007235527039, Final Batch Loss: 0.3519882559776306\n",
      "Epoch 1910, Loss: 1.4276845455169678, Final Batch Loss: 0.4061063826084137\n",
      "Epoch 1911, Loss: 1.4475726783275604, Final Batch Loss: 0.4096527397632599\n",
      "Epoch 1912, Loss: 1.4026652574539185, Final Batch Loss: 0.35530000925064087\n",
      "Epoch 1913, Loss: 1.3299487829208374, Final Batch Loss: 0.25687098503112793\n",
      "Epoch 1914, Loss: 1.2815706431865692, Final Batch Loss: 0.21004819869995117\n",
      "Epoch 1915, Loss: 1.427977979183197, Final Batch Loss: 0.3290526270866394\n",
      "Epoch 1916, Loss: 1.3085151016712189, Final Batch Loss: 0.37315574288368225\n",
      "Epoch 1917, Loss: 1.3308172523975372, Final Batch Loss: 0.3978331685066223\n",
      "Epoch 1918, Loss: 1.3017455637454987, Final Batch Loss: 0.3282279372215271\n",
      "Epoch 1919, Loss: 1.3268037736415863, Final Batch Loss: 0.36449307203292847\n",
      "Epoch 1920, Loss: 1.3801371157169342, Final Batch Loss: 0.3550508916378021\n",
      "Epoch 1921, Loss: 1.3157673478126526, Final Batch Loss: 0.35248425602912903\n",
      "Epoch 1922, Loss: 1.324799656867981, Final Batch Loss: 0.28320837020874023\n",
      "Epoch 1923, Loss: 1.3382468819618225, Final Batch Loss: 0.31116366386413574\n",
      "Epoch 1924, Loss: 1.3735539019107819, Final Batch Loss: 0.3384370803833008\n",
      "Epoch 1925, Loss: 1.3372228741645813, Final Batch Loss: 0.33977800607681274\n",
      "Epoch 1926, Loss: 1.25412118434906, Final Batch Loss: 0.29578614234924316\n",
      "Epoch 1927, Loss: 1.334488183259964, Final Batch Loss: 0.3701813817024231\n",
      "Epoch 1928, Loss: 1.317367047071457, Final Batch Loss: 0.28363651037216187\n",
      "Epoch 1929, Loss: 1.3080059736967087, Final Batch Loss: 0.23036138713359833\n",
      "Epoch 1930, Loss: 1.2318304181098938, Final Batch Loss: 0.3364396393299103\n",
      "Epoch 1931, Loss: 1.4480797946453094, Final Batch Loss: 0.3234579861164093\n",
      "Epoch 1932, Loss: 1.4394145607948303, Final Batch Loss: 0.27669820189476013\n",
      "Epoch 1933, Loss: 1.36085444688797, Final Batch Loss: 0.3489167392253876\n",
      "Epoch 1934, Loss: 1.2120376825332642, Final Batch Loss: 0.20819246768951416\n",
      "Epoch 1935, Loss: 1.2863067090511322, Final Batch Loss: 0.2585841417312622\n",
      "Epoch 1936, Loss: 1.4245754480361938, Final Batch Loss: 0.39168766140937805\n",
      "Epoch 1937, Loss: 1.2205851674079895, Final Batch Loss: 0.30456969141960144\n",
      "Epoch 1938, Loss: 1.452833116054535, Final Batch Loss: 0.2993030846118927\n",
      "Epoch 1939, Loss: 1.317067712545395, Final Batch Loss: 0.33218032121658325\n",
      "Epoch 1940, Loss: 1.3116912692785263, Final Batch Loss: 0.3728596568107605\n",
      "Epoch 1941, Loss: 1.220941498875618, Final Batch Loss: 0.1960633248090744\n",
      "Epoch 1942, Loss: 1.2488223612308502, Final Batch Loss: 0.25592249631881714\n",
      "Epoch 1943, Loss: 1.421122819185257, Final Batch Loss: 0.37171420454978943\n",
      "Epoch 1944, Loss: 1.3634720742702484, Final Batch Loss: 0.3905704617500305\n",
      "Epoch 1945, Loss: 1.3006196916103363, Final Batch Loss: 0.3553285300731659\n",
      "Epoch 1946, Loss: 1.4308024644851685, Final Batch Loss: 0.34760379791259766\n",
      "Epoch 1947, Loss: 1.335332304239273, Final Batch Loss: 0.2210063338279724\n",
      "Epoch 1948, Loss: 1.2421953976154327, Final Batch Loss: 0.26939624547958374\n",
      "Epoch 1949, Loss: 1.4679498374462128, Final Batch Loss: 0.4290296733379364\n",
      "Epoch 1950, Loss: 1.4245046377182007, Final Batch Loss: 0.34907370805740356\n",
      "Epoch 1951, Loss: 1.4362110495567322, Final Batch Loss: 0.4464752674102783\n",
      "Epoch 1952, Loss: 1.3678154647350311, Final Batch Loss: 0.4698651432991028\n",
      "Epoch 1953, Loss: 1.4189517199993134, Final Batch Loss: 0.31795966625213623\n",
      "Epoch 1954, Loss: 1.157410591840744, Final Batch Loss: 0.2354738712310791\n",
      "Epoch 1955, Loss: 1.2035547494888306, Final Batch Loss: 0.2997453510761261\n",
      "Epoch 1956, Loss: 1.3233920335769653, Final Batch Loss: 0.38453006744384766\n",
      "Epoch 1957, Loss: 1.3848260343074799, Final Batch Loss: 0.3573978841304779\n",
      "Epoch 1958, Loss: 1.3240166008472443, Final Batch Loss: 0.3143804967403412\n",
      "Epoch 1959, Loss: 1.2997924983501434, Final Batch Loss: 0.33344173431396484\n",
      "Epoch 1960, Loss: 1.4500691890716553, Final Batch Loss: 0.34912776947021484\n",
      "Epoch 1961, Loss: 1.2472179681062698, Final Batch Loss: 0.1847124546766281\n",
      "Epoch 1962, Loss: 1.3146262168884277, Final Batch Loss: 0.3618330955505371\n",
      "Epoch 1963, Loss: 1.1788473725318909, Final Batch Loss: 0.28972572088241577\n",
      "Epoch 1964, Loss: 1.3283554017543793, Final Batch Loss: 0.2963502109050751\n",
      "Epoch 1965, Loss: 1.355224996805191, Final Batch Loss: 0.3326367735862732\n",
      "Epoch 1966, Loss: 1.236547514796257, Final Batch Loss: 0.30099570751190186\n",
      "Epoch 1967, Loss: 1.4154478013515472, Final Batch Loss: 0.3754029870033264\n",
      "Epoch 1968, Loss: 1.4079555571079254, Final Batch Loss: 0.34471791982650757\n",
      "Epoch 1969, Loss: 1.3933526277542114, Final Batch Loss: 0.45814526081085205\n",
      "Epoch 1970, Loss: 1.1812949627637863, Final Batch Loss: 0.24756889045238495\n",
      "Epoch 1971, Loss: 1.3080297112464905, Final Batch Loss: 0.38781481981277466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1972, Loss: 1.248842865228653, Final Batch Loss: 0.32446497678756714\n",
      "Epoch 1973, Loss: 1.4015508592128754, Final Batch Loss: 0.3947836756706238\n",
      "Epoch 1974, Loss: 1.4696629047393799, Final Batch Loss: 0.3383338451385498\n",
      "Epoch 1975, Loss: 1.275730460882187, Final Batch Loss: 0.2617141306400299\n",
      "Epoch 1976, Loss: 1.5460872650146484, Final Batch Loss: 0.37845250964164734\n",
      "Epoch 1977, Loss: 1.3221063315868378, Final Batch Loss: 0.3090464174747467\n",
      "Epoch 1978, Loss: 1.455842286348343, Final Batch Loss: 0.3837745487689972\n",
      "Epoch 1979, Loss: 1.2755526006221771, Final Batch Loss: 0.4099946618080139\n",
      "Epoch 1980, Loss: 1.3775614500045776, Final Batch Loss: 0.23644715547561646\n",
      "Epoch 1981, Loss: 1.343698263168335, Final Batch Loss: 0.3659327030181885\n",
      "Epoch 1982, Loss: 1.2387109249830246, Final Batch Loss: 0.21283148229122162\n",
      "Epoch 1983, Loss: 1.4368309378623962, Final Batch Loss: 0.36489543318748474\n",
      "Epoch 1984, Loss: 1.3521516919136047, Final Batch Loss: 0.3724246621131897\n",
      "Epoch 1985, Loss: 1.1736880093812943, Final Batch Loss: 0.29364264011383057\n",
      "Epoch 1986, Loss: 1.3555723130702972, Final Batch Loss: 0.3352152109146118\n",
      "Epoch 1987, Loss: 1.3858212232589722, Final Batch Loss: 0.38982489705085754\n",
      "Epoch 1988, Loss: 1.2881699204444885, Final Batch Loss: 0.2924070656299591\n",
      "Epoch 1989, Loss: 1.419317364692688, Final Batch Loss: 0.48968183994293213\n",
      "Epoch 1990, Loss: 1.2303153425455093, Final Batch Loss: 0.22908930480480194\n",
      "Epoch 1991, Loss: 1.4833024740219116, Final Batch Loss: 0.43314361572265625\n",
      "Epoch 1992, Loss: 1.354595273733139, Final Batch Loss: 0.3612634241580963\n",
      "Epoch 1993, Loss: 1.330808401107788, Final Batch Loss: 0.2975558936595917\n",
      "Epoch 1994, Loss: 1.24190354347229, Final Batch Loss: 0.3232353925704956\n",
      "Epoch 1995, Loss: 1.3651387095451355, Final Batch Loss: 0.34064123034477234\n",
      "Epoch 1996, Loss: 1.366533249616623, Final Batch Loss: 0.3659657835960388\n",
      "Epoch 1997, Loss: 1.3542064726352692, Final Batch Loss: 0.31051331758499146\n",
      "Epoch 1998, Loss: 1.4314814805984497, Final Batch Loss: 0.359911173582077\n",
      "Epoch 1999, Loss: 1.3938632011413574, Final Batch Loss: 0.38966426253318787\n",
      "Epoch 2000, Loss: 1.3350073397159576, Final Batch Loss: 0.31663778424263\n",
      "Epoch 2001, Loss: 1.3166663199663162, Final Batch Loss: 0.22256232798099518\n",
      "Epoch 2002, Loss: 1.520613193511963, Final Batch Loss: 0.34022122621536255\n",
      "Epoch 2003, Loss: 1.2288420647382736, Final Batch Loss: 0.1957024782896042\n",
      "Epoch 2004, Loss: 1.1202589124441147, Final Batch Loss: 0.21088527143001556\n",
      "Epoch 2005, Loss: 1.3833743631839752, Final Batch Loss: 0.2958392798900604\n",
      "Epoch 2006, Loss: 1.4190453588962555, Final Batch Loss: 0.37685367465019226\n",
      "Epoch 2007, Loss: 1.342118114233017, Final Batch Loss: 0.31428080797195435\n",
      "Epoch 2008, Loss: 1.24572192132473, Final Batch Loss: 0.22657768428325653\n",
      "Epoch 2009, Loss: 1.2622712552547455, Final Batch Loss: 0.34182894229888916\n",
      "Epoch 2010, Loss: 1.334815800189972, Final Batch Loss: 0.3625292479991913\n",
      "Epoch 2011, Loss: 1.360635906457901, Final Batch Loss: 0.34475550055503845\n",
      "Epoch 2012, Loss: 1.308607280254364, Final Batch Loss: 0.33706244826316833\n",
      "Epoch 2013, Loss: 1.4899962842464447, Final Batch Loss: 0.44378188252449036\n",
      "Epoch 2014, Loss: 1.4336261749267578, Final Batch Loss: 0.3796181082725525\n",
      "Epoch 2015, Loss: 1.3499241173267365, Final Batch Loss: 0.4722687005996704\n",
      "Epoch 2016, Loss: 1.3252576887607574, Final Batch Loss: 0.35365214943885803\n",
      "Epoch 2017, Loss: 1.294103592634201, Final Batch Loss: 0.3183700144290924\n",
      "Epoch 2018, Loss: 1.458291620016098, Final Batch Loss: 0.39758142828941345\n",
      "Epoch 2019, Loss: 1.4273643791675568, Final Batch Loss: 0.32446399331092834\n",
      "Epoch 2020, Loss: 1.3757146000862122, Final Batch Loss: 0.2986942529678345\n",
      "Epoch 2021, Loss: 1.5356066823005676, Final Batch Loss: 0.4188125431537628\n",
      "Epoch 2022, Loss: 1.250929057598114, Final Batch Loss: 0.29524853825569153\n",
      "Epoch 2023, Loss: 1.314556360244751, Final Batch Loss: 0.32146981358528137\n",
      "Epoch 2024, Loss: 1.4316537827253342, Final Batch Loss: 0.23847584426403046\n",
      "Epoch 2025, Loss: 1.2019980698823929, Final Batch Loss: 0.19772939383983612\n",
      "Epoch 2026, Loss: 1.2492491751909256, Final Batch Loss: 0.347735732793808\n",
      "Epoch 2027, Loss: 1.2765771746635437, Final Batch Loss: 0.34241989254951477\n",
      "Epoch 2028, Loss: 1.346222460269928, Final Batch Loss: 0.3045370578765869\n",
      "Epoch 2029, Loss: 1.2705640494823456, Final Batch Loss: 0.30215418338775635\n",
      "Epoch 2030, Loss: 1.3739530146121979, Final Batch Loss: 0.42776715755462646\n",
      "Epoch 2031, Loss: 1.3445538580417633, Final Batch Loss: 0.30320361256599426\n",
      "Epoch 2032, Loss: 1.207712322473526, Final Batch Loss: 0.29331502318382263\n",
      "Epoch 2033, Loss: 1.3628528714179993, Final Batch Loss: 0.3706708252429962\n",
      "Epoch 2034, Loss: 1.4570849537849426, Final Batch Loss: 0.4153832495212555\n",
      "Epoch 2035, Loss: 1.300248146057129, Final Batch Loss: 0.3187870383262634\n",
      "Epoch 2036, Loss: 1.302938312292099, Final Batch Loss: 0.3149832487106323\n",
      "Epoch 2037, Loss: 1.248559832572937, Final Batch Loss: 0.3408707082271576\n",
      "Epoch 2038, Loss: 1.353807508945465, Final Batch Loss: 0.39995986223220825\n",
      "Epoch 2039, Loss: 1.2606241703033447, Final Batch Loss: 0.2618711590766907\n",
      "Epoch 2040, Loss: 1.339005321264267, Final Batch Loss: 0.32231101393699646\n",
      "Epoch 2041, Loss: 1.2547249495983124, Final Batch Loss: 0.2783743441104889\n",
      "Epoch 2042, Loss: 1.3812153935432434, Final Batch Loss: 0.45612379908561707\n",
      "Epoch 2043, Loss: 1.3063227534294128, Final Batch Loss: 0.2749410569667816\n",
      "Epoch 2044, Loss: 1.2364286482334137, Final Batch Loss: 0.3767330050468445\n",
      "Epoch 2045, Loss: 1.2158485352993011, Final Batch Loss: 0.31522336602211\n",
      "Epoch 2046, Loss: 1.3105051815509796, Final Batch Loss: 0.307840496301651\n",
      "Epoch 2047, Loss: 1.3874792754650116, Final Batch Loss: 0.2873207628726959\n",
      "Epoch 2048, Loss: 1.3474498093128204, Final Batch Loss: 0.3536956012248993\n",
      "Epoch 2049, Loss: 1.299387663602829, Final Batch Loss: 0.430881142616272\n",
      "Epoch 2050, Loss: 1.2268090844154358, Final Batch Loss: 0.33585023880004883\n",
      "Epoch 2051, Loss: 1.3355769515037537, Final Batch Loss: 0.3730987012386322\n",
      "Epoch 2052, Loss: 1.2122960835695267, Final Batch Loss: 0.21610374748706818\n",
      "Epoch 2053, Loss: 1.3170829117298126, Final Batch Loss: 0.3040650486946106\n",
      "Epoch 2054, Loss: 1.2179196178913116, Final Batch Loss: 0.3512154221534729\n",
      "Epoch 2055, Loss: 1.5105329155921936, Final Batch Loss: 0.445645272731781\n",
      "Epoch 2056, Loss: 1.2049699574708939, Final Batch Loss: 0.24741025269031525\n",
      "Epoch 2057, Loss: 1.3509053885936737, Final Batch Loss: 0.3787069618701935\n",
      "Epoch 2058, Loss: 1.2925929129123688, Final Batch Loss: 0.2525622248649597\n",
      "Epoch 2059, Loss: 1.415183186531067, Final Batch Loss: 0.31919950246810913\n",
      "Epoch 2060, Loss: 1.400493711233139, Final Batch Loss: 0.35601603984832764\n",
      "Epoch 2061, Loss: 1.3806095719337463, Final Batch Loss: 0.33387768268585205\n",
      "Epoch 2062, Loss: 1.2746295630931854, Final Batch Loss: 0.2404496967792511\n",
      "Epoch 2063, Loss: 1.284951001405716, Final Batch Loss: 0.30976417660713196\n",
      "Epoch 2064, Loss: 1.1932989954948425, Final Batch Loss: 0.20733454823493958\n",
      "Epoch 2065, Loss: 1.3886785209178925, Final Batch Loss: 0.4214766025543213\n",
      "Epoch 2066, Loss: 1.1209340989589691, Final Batch Loss: 0.25224342942237854\n",
      "Epoch 2067, Loss: 1.3703486919403076, Final Batch Loss: 0.2718868851661682\n",
      "Epoch 2068, Loss: 1.446357101202011, Final Batch Loss: 0.27513158321380615\n",
      "Epoch 2069, Loss: 1.3775847554206848, Final Batch Loss: 0.4167008101940155\n",
      "Epoch 2070, Loss: 1.3406722247600555, Final Batch Loss: 0.3266144096851349\n",
      "Epoch 2071, Loss: 1.339707463979721, Final Batch Loss: 0.2503455877304077\n",
      "Epoch 2072, Loss: 1.2938467264175415, Final Batch Loss: 0.31197991967201233\n",
      "Epoch 2073, Loss: 1.3198430836200714, Final Batch Loss: 0.2691403329372406\n",
      "Epoch 2074, Loss: 1.4364561438560486, Final Batch Loss: 0.3968356251716614\n",
      "Epoch 2075, Loss: 1.2944681346416473, Final Batch Loss: 0.34498685598373413\n",
      "Epoch 2076, Loss: 1.3077417016029358, Final Batch Loss: 0.3572108745574951\n",
      "Epoch 2077, Loss: 1.2885357737541199, Final Batch Loss: 0.31448718905448914\n",
      "Epoch 2078, Loss: 1.3888884782791138, Final Batch Loss: 0.252097487449646\n",
      "Epoch 2079, Loss: 1.2788396179676056, Final Batch Loss: 0.2345598042011261\n",
      "Epoch 2080, Loss: 1.272032916545868, Final Batch Loss: 0.2855367958545685\n",
      "Epoch 2081, Loss: 1.4493703544139862, Final Batch Loss: 0.36647552251815796\n",
      "Epoch 2082, Loss: 1.2161330878734589, Final Batch Loss: 0.26945701241493225\n",
      "Epoch 2083, Loss: 1.3864519596099854, Final Batch Loss: 0.36291268467903137\n",
      "Epoch 2084, Loss: 1.4605575501918793, Final Batch Loss: 0.41941335797309875\n",
      "Epoch 2085, Loss: 1.2930991351604462, Final Batch Loss: 0.3456774055957794\n",
      "Epoch 2086, Loss: 1.4551903903484344, Final Batch Loss: 0.452158659696579\n",
      "Epoch 2087, Loss: 1.5059925615787506, Final Batch Loss: 0.5492728352546692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2088, Loss: 1.2154387831687927, Final Batch Loss: 0.33528926968574524\n",
      "Epoch 2089, Loss: 1.371577650308609, Final Batch Loss: 0.3946577310562134\n",
      "Epoch 2090, Loss: 1.255042552947998, Final Batch Loss: 0.2905634641647339\n",
      "Epoch 2091, Loss: 1.2538548111915588, Final Batch Loss: 0.33242738246917725\n",
      "Epoch 2092, Loss: 1.2218105345964432, Final Batch Loss: 0.3038877546787262\n",
      "Epoch 2093, Loss: 1.2334913909435272, Final Batch Loss: 0.30673477053642273\n",
      "Epoch 2094, Loss: 1.6391476690769196, Final Batch Loss: 0.34793534874916077\n",
      "Epoch 2095, Loss: 1.411407083272934, Final Batch Loss: 0.496277779340744\n",
      "Epoch 2096, Loss: 1.2010649144649506, Final Batch Loss: 0.23863551020622253\n",
      "Epoch 2097, Loss: 1.2691401839256287, Final Batch Loss: 0.31956881284713745\n",
      "Epoch 2098, Loss: 1.2364217042922974, Final Batch Loss: 0.2952217161655426\n",
      "Epoch 2099, Loss: 1.3128517866134644, Final Batch Loss: 0.32382330298423767\n",
      "Epoch 2100, Loss: 1.3756807446479797, Final Batch Loss: 0.43084776401519775\n",
      "Epoch 2101, Loss: 1.3598686158657074, Final Batch Loss: 0.3121250867843628\n",
      "Epoch 2102, Loss: 1.2591527700424194, Final Batch Loss: 0.30356326699256897\n",
      "Epoch 2103, Loss: 1.2188752591609955, Final Batch Loss: 0.28610140085220337\n",
      "Epoch 2104, Loss: 1.3387152552604675, Final Batch Loss: 0.3108128607273102\n",
      "Epoch 2105, Loss: 1.327677607536316, Final Batch Loss: 0.29254060983657837\n",
      "Epoch 2106, Loss: 1.19154292345047, Final Batch Loss: 0.28686976432800293\n",
      "Epoch 2107, Loss: 1.3297493755817413, Final Batch Loss: 0.3953644335269928\n",
      "Epoch 2108, Loss: 1.1636853516101837, Final Batch Loss: 0.267246276140213\n",
      "Epoch 2109, Loss: 1.255139023065567, Final Batch Loss: 0.3794799745082855\n",
      "Epoch 2110, Loss: 1.1681135296821594, Final Batch Loss: 0.3152428865432739\n",
      "Epoch 2111, Loss: 1.3413337171077728, Final Batch Loss: 0.45288804173469543\n",
      "Epoch 2112, Loss: 1.3344132900238037, Final Batch Loss: 0.27966517210006714\n",
      "Epoch 2113, Loss: 1.365007609128952, Final Batch Loss: 0.31159287691116333\n",
      "Epoch 2114, Loss: 1.277763307094574, Final Batch Loss: 0.31345751881599426\n",
      "Epoch 2115, Loss: 1.2194010317325592, Final Batch Loss: 0.2859634459018707\n",
      "Epoch 2116, Loss: 1.351246863603592, Final Batch Loss: 0.42736127972602844\n",
      "Epoch 2117, Loss: 1.2852526903152466, Final Batch Loss: 0.32513919472694397\n",
      "Epoch 2118, Loss: 1.3717057406902313, Final Batch Loss: 0.4292876422405243\n",
      "Epoch 2119, Loss: 1.1443658024072647, Final Batch Loss: 0.245966836810112\n",
      "Epoch 2120, Loss: 1.2457815408706665, Final Batch Loss: 0.2636139690876007\n",
      "Epoch 2121, Loss: 1.218404233455658, Final Batch Loss: 0.2500317692756653\n",
      "Epoch 2122, Loss: 1.2291527092456818, Final Batch Loss: 0.27110007405281067\n",
      "Epoch 2123, Loss: 1.3307025134563446, Final Batch Loss: 0.21736636757850647\n",
      "Epoch 2124, Loss: 1.3135513365268707, Final Batch Loss: 0.2807786166667938\n",
      "Epoch 2125, Loss: 1.2019077837467194, Final Batch Loss: 0.3256826102733612\n",
      "Epoch 2126, Loss: 1.2518856823444366, Final Batch Loss: 0.28421497344970703\n",
      "Epoch 2127, Loss: 1.2316349744796753, Final Batch Loss: 0.29241225123405457\n",
      "Epoch 2128, Loss: 1.12687486410141, Final Batch Loss: 0.24372020363807678\n",
      "Epoch 2129, Loss: 1.237170159816742, Final Batch Loss: 0.2581757605075836\n",
      "Epoch 2130, Loss: 1.549560159444809, Final Batch Loss: 0.48618006706237793\n",
      "Epoch 2131, Loss: 1.2946938276290894, Final Batch Loss: 0.3273167014122009\n",
      "Epoch 2132, Loss: 1.2454651296138763, Final Batch Loss: 0.27208226919174194\n",
      "Epoch 2133, Loss: 1.3914531767368317, Final Batch Loss: 0.2819414436817169\n",
      "Epoch 2134, Loss: 1.211154580116272, Final Batch Loss: 0.2386360764503479\n",
      "Epoch 2135, Loss: 1.2401667535305023, Final Batch Loss: 0.33463969826698303\n",
      "Epoch 2136, Loss: 1.2859914302825928, Final Batch Loss: 0.37994104623794556\n",
      "Epoch 2137, Loss: 1.3466495871543884, Final Batch Loss: 0.3496425449848175\n",
      "Epoch 2138, Loss: 1.3183070719242096, Final Batch Loss: 0.27095484733581543\n",
      "Epoch 2139, Loss: 1.194543033838272, Final Batch Loss: 0.35360267758369446\n",
      "Epoch 2140, Loss: 1.3217162191867828, Final Batch Loss: 0.34998124837875366\n",
      "Epoch 2141, Loss: 1.1197414547204971, Final Batch Loss: 0.2325366884469986\n",
      "Epoch 2142, Loss: 1.1850631833076477, Final Batch Loss: 0.282084584236145\n",
      "Epoch 2143, Loss: 1.4458051919937134, Final Batch Loss: 0.30110445618629456\n",
      "Epoch 2144, Loss: 1.365887612104416, Final Batch Loss: 0.36896130442619324\n",
      "Epoch 2145, Loss: 1.2628377676010132, Final Batch Loss: 0.27223148941993713\n",
      "Epoch 2146, Loss: 1.2518542110919952, Final Batch Loss: 0.3471558690071106\n",
      "Epoch 2147, Loss: 1.302176058292389, Final Batch Loss: 0.3893577456474304\n",
      "Epoch 2148, Loss: 1.3285168707370758, Final Batch Loss: 0.34258437156677246\n",
      "Epoch 2149, Loss: 1.3875742256641388, Final Batch Loss: 0.3017365634441376\n",
      "Epoch 2150, Loss: 1.1982585787773132, Final Batch Loss: 0.22252243757247925\n",
      "Epoch 2151, Loss: 1.1898153126239777, Final Batch Loss: 0.22789201140403748\n",
      "Epoch 2152, Loss: 1.4135326743125916, Final Batch Loss: 0.2968198359012604\n",
      "Epoch 2153, Loss: 1.203313559293747, Final Batch Loss: 0.3331563472747803\n",
      "Epoch 2154, Loss: 1.2427195608615875, Final Batch Loss: 0.2128981053829193\n",
      "Epoch 2155, Loss: 1.4000512659549713, Final Batch Loss: 0.31683263182640076\n",
      "Epoch 2156, Loss: 1.3576824963092804, Final Batch Loss: 0.3522689938545227\n",
      "Epoch 2157, Loss: 1.3946095407009125, Final Batch Loss: 0.35746949911117554\n",
      "Epoch 2158, Loss: 1.4480305314064026, Final Batch Loss: 0.5295155644416809\n",
      "Epoch 2159, Loss: 1.2889050543308258, Final Batch Loss: 0.3107541501522064\n",
      "Epoch 2160, Loss: 1.3072603940963745, Final Batch Loss: 0.36037495732307434\n",
      "Epoch 2161, Loss: 1.3544296324253082, Final Batch Loss: 0.3068944811820984\n",
      "Epoch 2162, Loss: 1.390834480524063, Final Batch Loss: 0.3576745390892029\n",
      "Epoch 2163, Loss: 1.258701503276825, Final Batch Loss: 0.251301109790802\n",
      "Epoch 2164, Loss: 1.4092552959918976, Final Batch Loss: 0.49289095401763916\n",
      "Epoch 2165, Loss: 1.2110824435949326, Final Batch Loss: 0.33005109429359436\n",
      "Epoch 2166, Loss: 1.2398752868175507, Final Batch Loss: 0.29243624210357666\n",
      "Epoch 2167, Loss: 1.2509389817714691, Final Batch Loss: 0.34718185663223267\n",
      "Epoch 2168, Loss: 1.2263231575489044, Final Batch Loss: 0.2831827402114868\n",
      "Epoch 2169, Loss: 1.3256308138370514, Final Batch Loss: 0.303462952375412\n",
      "Epoch 2170, Loss: 1.4193722307682037, Final Batch Loss: 0.37845662236213684\n",
      "Epoch 2171, Loss: 1.3249220848083496, Final Batch Loss: 0.22035753726959229\n",
      "Epoch 2172, Loss: 1.2619990706443787, Final Batch Loss: 0.36285603046417236\n",
      "Epoch 2173, Loss: 1.3943935632705688, Final Batch Loss: 0.3790286183357239\n",
      "Epoch 2174, Loss: 1.2817870676517487, Final Batch Loss: 0.314445436000824\n",
      "Epoch 2175, Loss: 1.3119959831237793, Final Batch Loss: 0.30676865577697754\n",
      "Epoch 2176, Loss: 1.2955821454524994, Final Batch Loss: 0.3270006775856018\n",
      "Epoch 2177, Loss: 1.2460291981697083, Final Batch Loss: 0.26769864559173584\n",
      "Epoch 2178, Loss: 1.2337133586406708, Final Batch Loss: 0.35702261328697205\n",
      "Epoch 2179, Loss: 1.277952492237091, Final Batch Loss: 0.29263409972190857\n",
      "Epoch 2180, Loss: 1.267719030380249, Final Batch Loss: 0.33682674169540405\n",
      "Epoch 2181, Loss: 1.243890568614006, Final Batch Loss: 0.3035711348056793\n",
      "Epoch 2182, Loss: 1.4508484899997711, Final Batch Loss: 0.4885547161102295\n",
      "Epoch 2183, Loss: 1.3126474916934967, Final Batch Loss: 0.36582088470458984\n",
      "Epoch 2184, Loss: 1.2937402725219727, Final Batch Loss: 0.3094441592693329\n",
      "Epoch 2185, Loss: 1.279531180858612, Final Batch Loss: 0.2766602635383606\n",
      "Epoch 2186, Loss: 1.2500693202018738, Final Batch Loss: 0.3359752297401428\n",
      "Epoch 2187, Loss: 1.2714500278234482, Final Batch Loss: 0.2019641250371933\n",
      "Epoch 2188, Loss: 1.3217975497245789, Final Batch Loss: 0.40297648310661316\n",
      "Epoch 2189, Loss: 1.2628850936889648, Final Batch Loss: 0.34640049934387207\n",
      "Epoch 2190, Loss: 1.3096821010112762, Final Batch Loss: 0.3685802221298218\n",
      "Epoch 2191, Loss: 1.456654131412506, Final Batch Loss: 0.42995113134384155\n",
      "Epoch 2192, Loss: 1.274474710226059, Final Batch Loss: 0.3287777602672577\n",
      "Epoch 2193, Loss: 1.2863124310970306, Final Batch Loss: 0.29511937499046326\n",
      "Epoch 2194, Loss: 1.354167401790619, Final Batch Loss: 0.39621680974960327\n",
      "Epoch 2195, Loss: 1.2202417701482773, Final Batch Loss: 0.24165217578411102\n",
      "Epoch 2196, Loss: 1.3921756446361542, Final Batch Loss: 0.41464701294898987\n",
      "Epoch 2197, Loss: 1.2490605413913727, Final Batch Loss: 0.2909530699253082\n",
      "Epoch 2198, Loss: 1.3001414984464645, Final Batch Loss: 0.32215070724487305\n",
      "Epoch 2199, Loss: 1.2515163719654083, Final Batch Loss: 0.30665457248687744\n",
      "Epoch 2200, Loss: 1.2318443655967712, Final Batch Loss: 0.2907634973526001\n",
      "Epoch 2201, Loss: 1.2511304914951324, Final Batch Loss: 0.3481774628162384\n",
      "Epoch 2202, Loss: 1.140596330165863, Final Batch Loss: 0.26901525259017944\n",
      "Epoch 2203, Loss: 1.3682433068752289, Final Batch Loss: 0.34631383419036865\n",
      "Epoch 2204, Loss: 1.3279131948947906, Final Batch Loss: 0.351505309343338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2205, Loss: 1.364758014678955, Final Batch Loss: 0.3559766113758087\n",
      "Epoch 2206, Loss: 1.2742131352424622, Final Batch Loss: 0.35166504979133606\n",
      "Epoch 2207, Loss: 1.3315371572971344, Final Batch Loss: 0.3371833860874176\n",
      "Epoch 2208, Loss: 1.257792353630066, Final Batch Loss: 0.29367396235466003\n",
      "Epoch 2209, Loss: 1.2188489437103271, Final Batch Loss: 0.2882367968559265\n",
      "Epoch 2210, Loss: 1.2189839482307434, Final Batch Loss: 0.25751009583473206\n",
      "Epoch 2211, Loss: 1.1966612935066223, Final Batch Loss: 0.2659859359264374\n",
      "Epoch 2212, Loss: 1.4125854074954987, Final Batch Loss: 0.3476029634475708\n",
      "Epoch 2213, Loss: 1.2759073674678802, Final Batch Loss: 0.31874004006385803\n",
      "Epoch 2214, Loss: 1.2225207686424255, Final Batch Loss: 0.3107617199420929\n",
      "Epoch 2215, Loss: 1.2731561064720154, Final Batch Loss: 0.3736337721347809\n",
      "Epoch 2216, Loss: 1.2423686683177948, Final Batch Loss: 0.3150119483470917\n",
      "Epoch 2217, Loss: 1.2847366631031036, Final Batch Loss: 0.30331215262413025\n",
      "Epoch 2218, Loss: 1.2182149291038513, Final Batch Loss: 0.29049697518348694\n",
      "Epoch 2219, Loss: 1.1883957386016846, Final Batch Loss: 0.31152039766311646\n",
      "Epoch 2220, Loss: 1.1730717718601227, Final Batch Loss: 0.26782411336898804\n",
      "Epoch 2221, Loss: 1.2469168603420258, Final Batch Loss: 0.21471473574638367\n",
      "Epoch 2222, Loss: 1.2903462648391724, Final Batch Loss: 0.28578418493270874\n",
      "Epoch 2223, Loss: 1.2146618515253067, Final Batch Loss: 0.3622889518737793\n",
      "Epoch 2224, Loss: 1.1887763291597366, Final Batch Loss: 0.24504204094409943\n",
      "Epoch 2225, Loss: 1.2735434174537659, Final Batch Loss: 0.3537565767765045\n",
      "Epoch 2226, Loss: 1.439485102891922, Final Batch Loss: 0.36955907940864563\n",
      "Epoch 2227, Loss: 1.3750376403331757, Final Batch Loss: 0.404840886592865\n",
      "Epoch 2228, Loss: 1.2181103825569153, Final Batch Loss: 0.2555231750011444\n",
      "Epoch 2229, Loss: 1.2198602557182312, Final Batch Loss: 0.3424655795097351\n",
      "Epoch 2230, Loss: 1.2254412025213242, Final Batch Loss: 0.24533222615718842\n",
      "Epoch 2231, Loss: 1.1663537323474884, Final Batch Loss: 0.28157278895378113\n",
      "Epoch 2232, Loss: 1.2740821838378906, Final Batch Loss: 0.2426835000514984\n",
      "Epoch 2233, Loss: 1.2422064244747162, Final Batch Loss: 0.25004732608795166\n",
      "Epoch 2234, Loss: 1.2102155685424805, Final Batch Loss: 0.2731717824935913\n",
      "Epoch 2235, Loss: 1.3918058276176453, Final Batch Loss: 0.4178300201892853\n",
      "Epoch 2236, Loss: 1.3339735865592957, Final Batch Loss: 0.3216211497783661\n",
      "Epoch 2237, Loss: 1.292189121246338, Final Batch Loss: 0.37237146496772766\n",
      "Epoch 2238, Loss: 1.2369166612625122, Final Batch Loss: 0.25647327303886414\n",
      "Epoch 2239, Loss: 1.2611580789089203, Final Batch Loss: 0.3431393802165985\n",
      "Epoch 2240, Loss: 1.2909873723983765, Final Batch Loss: 0.36048564314842224\n",
      "Epoch 2241, Loss: 1.2195293605327606, Final Batch Loss: 0.350850909948349\n",
      "Epoch 2242, Loss: 1.244787409901619, Final Batch Loss: 0.33672627806663513\n",
      "Epoch 2243, Loss: 1.211856096982956, Final Batch Loss: 0.2810099720954895\n",
      "Epoch 2244, Loss: 1.166477918624878, Final Batch Loss: 0.256275475025177\n",
      "Epoch 2245, Loss: 1.2958312332630157, Final Batch Loss: 0.25304216146469116\n",
      "Epoch 2246, Loss: 1.2240495085716248, Final Batch Loss: 0.30953073501586914\n",
      "Epoch 2247, Loss: 1.4963018596172333, Final Batch Loss: 0.5187848210334778\n",
      "Epoch 2248, Loss: 1.3251200020313263, Final Batch Loss: 0.28386613726615906\n",
      "Epoch 2249, Loss: 1.259667158126831, Final Batch Loss: 0.27076810598373413\n",
      "Epoch 2250, Loss: 1.5080761015415192, Final Batch Loss: 0.3629061281681061\n",
      "Epoch 2251, Loss: 1.2462199032306671, Final Batch Loss: 0.27778565883636475\n",
      "Epoch 2252, Loss: 1.2090101540088654, Final Batch Loss: 0.33561044931411743\n",
      "Epoch 2253, Loss: 1.1517189145088196, Final Batch Loss: 0.18390652537345886\n",
      "Epoch 2254, Loss: 1.2762621641159058, Final Batch Loss: 0.3061727285385132\n",
      "Epoch 2255, Loss: 1.3539637625217438, Final Batch Loss: 0.3269599974155426\n",
      "Epoch 2256, Loss: 1.2046841084957123, Final Batch Loss: 0.31203800439834595\n",
      "Epoch 2257, Loss: 1.3244866728782654, Final Batch Loss: 0.3818300664424896\n",
      "Epoch 2258, Loss: 1.2414429485797882, Final Batch Loss: 0.3365897238254547\n",
      "Epoch 2259, Loss: 1.294083833694458, Final Batch Loss: 0.3649636507034302\n",
      "Epoch 2260, Loss: 1.224799484014511, Final Batch Loss: 0.35705897212028503\n",
      "Epoch 2261, Loss: 1.2950927317142487, Final Batch Loss: 0.3266980051994324\n",
      "Epoch 2262, Loss: 1.3020432591438293, Final Batch Loss: 0.364486426115036\n",
      "Epoch 2263, Loss: 1.2306382954120636, Final Batch Loss: 0.3272351324558258\n",
      "Epoch 2264, Loss: 1.3101830780506134, Final Batch Loss: 0.3555464446544647\n",
      "Epoch 2265, Loss: 1.3030393719673157, Final Batch Loss: 0.31108370423316956\n",
      "Epoch 2266, Loss: 1.2831552922725677, Final Batch Loss: 0.3859389126300812\n",
      "Epoch 2267, Loss: 1.2986015379428864, Final Batch Loss: 0.30999499559402466\n",
      "Epoch 2268, Loss: 1.1326491832733154, Final Batch Loss: 0.25785234570503235\n",
      "Epoch 2269, Loss: 1.1363501697778702, Final Batch Loss: 0.23856283724308014\n",
      "Epoch 2270, Loss: 1.3422669470310211, Final Batch Loss: 0.29525026679039\n",
      "Epoch 2271, Loss: 1.3232244402170181, Final Batch Loss: 0.3341650068759918\n",
      "Epoch 2272, Loss: 1.1741521656513214, Final Batch Loss: 0.31266117095947266\n",
      "Epoch 2273, Loss: 1.2689606547355652, Final Batch Loss: 0.3220624029636383\n",
      "Epoch 2274, Loss: 1.2242603600025177, Final Batch Loss: 0.3079083263874054\n",
      "Epoch 2275, Loss: 1.2057583928108215, Final Batch Loss: 0.3034898638725281\n",
      "Epoch 2276, Loss: 1.3004408180713654, Final Batch Loss: 0.33821243047714233\n",
      "Epoch 2277, Loss: 1.2807415127754211, Final Batch Loss: 0.25775113701820374\n",
      "Epoch 2278, Loss: 1.1361896097660065, Final Batch Loss: 0.2689571976661682\n",
      "Epoch 2279, Loss: 1.0984494388103485, Final Batch Loss: 0.2909604609012604\n",
      "Epoch 2280, Loss: 1.362851321697235, Final Batch Loss: 0.3944930136203766\n",
      "Epoch 2281, Loss: 1.2724156975746155, Final Batch Loss: 0.30785486102104187\n",
      "Epoch 2282, Loss: 1.2860198318958282, Final Batch Loss: 0.3181777000427246\n",
      "Epoch 2283, Loss: 1.2788766622543335, Final Batch Loss: 0.34758245944976807\n",
      "Epoch 2284, Loss: 1.2906249910593033, Final Batch Loss: 0.3668791651725769\n",
      "Epoch 2285, Loss: 1.3303382098674774, Final Batch Loss: 0.33259260654449463\n",
      "Epoch 2286, Loss: 1.366142451763153, Final Batch Loss: 0.37408825755119324\n",
      "Epoch 2287, Loss: 1.18617545068264, Final Batch Loss: 0.2542726695537567\n",
      "Epoch 2288, Loss: 1.1718194335699081, Final Batch Loss: 0.2403145283460617\n",
      "Epoch 2289, Loss: 1.1907886266708374, Final Batch Loss: 0.3195645213127136\n",
      "Epoch 2290, Loss: 1.3264650702476501, Final Batch Loss: 0.3145844340324402\n",
      "Epoch 2291, Loss: 1.3631788194179535, Final Batch Loss: 0.37795570492744446\n",
      "Epoch 2292, Loss: 1.1158632040023804, Final Batch Loss: 0.23415091633796692\n",
      "Epoch 2293, Loss: 1.1812068223953247, Final Batch Loss: 0.26330992579460144\n",
      "Epoch 2294, Loss: 1.3022390305995941, Final Batch Loss: 0.3681600093841553\n",
      "Epoch 2295, Loss: 1.3815940618515015, Final Batch Loss: 0.36602795124053955\n",
      "Epoch 2296, Loss: 1.1563555002212524, Final Batch Loss: 0.29363587498664856\n",
      "Epoch 2297, Loss: 1.2850199937820435, Final Batch Loss: 0.3582271635532379\n",
      "Epoch 2298, Loss: 1.2143306732177734, Final Batch Loss: 0.19627320766448975\n",
      "Epoch 2299, Loss: 1.1521997600793839, Final Batch Loss: 0.24136628210544586\n",
      "Epoch 2300, Loss: 1.2620553970336914, Final Batch Loss: 0.35490986704826355\n",
      "Epoch 2301, Loss: 1.1908930540084839, Final Batch Loss: 0.2974083125591278\n",
      "Epoch 2302, Loss: 1.2980542480945587, Final Batch Loss: 0.34798410534858704\n",
      "Epoch 2303, Loss: 1.1228985637426376, Final Batch Loss: 0.1997806578874588\n",
      "Epoch 2304, Loss: 1.2093700766563416, Final Batch Loss: 0.3124595880508423\n",
      "Epoch 2305, Loss: 1.386678159236908, Final Batch Loss: 0.3150467872619629\n",
      "Epoch 2306, Loss: 1.333878219127655, Final Batch Loss: 0.40467342734336853\n",
      "Epoch 2307, Loss: 1.2202360033988953, Final Batch Loss: 0.3126683831214905\n",
      "Epoch 2308, Loss: 1.1565217971801758, Final Batch Loss: 0.289592444896698\n",
      "Epoch 2309, Loss: 1.2510088682174683, Final Batch Loss: 0.31421753764152527\n",
      "Epoch 2310, Loss: 1.1355255097150803, Final Batch Loss: 0.2339649647474289\n",
      "Epoch 2311, Loss: 1.2517285346984863, Final Batch Loss: 0.3261115252971649\n",
      "Epoch 2312, Loss: 1.2419704794883728, Final Batch Loss: 0.264800101518631\n",
      "Epoch 2313, Loss: 1.263733983039856, Final Batch Loss: 0.3128907382488251\n",
      "Epoch 2314, Loss: 1.2307444214820862, Final Batch Loss: 0.2632158398628235\n",
      "Epoch 2315, Loss: 1.2732994258403778, Final Batch Loss: 0.33415958285331726\n",
      "Epoch 2316, Loss: 1.1932117640972137, Final Batch Loss: 0.3437161147594452\n",
      "Epoch 2317, Loss: 1.3003941774368286, Final Batch Loss: 0.4024240970611572\n",
      "Epoch 2318, Loss: 1.1104815155267715, Final Batch Loss: 0.2415914684534073\n",
      "Epoch 2319, Loss: 1.284794807434082, Final Batch Loss: 0.3371753990650177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2320, Loss: 1.19186532497406, Final Batch Loss: 0.3281751871109009\n",
      "Epoch 2321, Loss: 1.1998512744903564, Final Batch Loss: 0.3037577271461487\n",
      "Epoch 2322, Loss: 1.0817896872758865, Final Batch Loss: 0.24703349173069\n",
      "Epoch 2323, Loss: 1.2255081832408905, Final Batch Loss: 0.32744285464286804\n",
      "Epoch 2324, Loss: 1.1481996923685074, Final Batch Loss: 0.3221547603607178\n",
      "Epoch 2325, Loss: 1.1304473578929901, Final Batch Loss: 0.19831934571266174\n",
      "Epoch 2326, Loss: 1.2135700285434723, Final Batch Loss: 0.2909401059150696\n",
      "Epoch 2327, Loss: 1.2829120755195618, Final Batch Loss: 0.29535314440727234\n",
      "Epoch 2328, Loss: 1.2124524265527725, Final Batch Loss: 0.33146098256111145\n",
      "Epoch 2329, Loss: 1.3467698395252228, Final Batch Loss: 0.41199275851249695\n",
      "Epoch 2330, Loss: 1.2418591678142548, Final Batch Loss: 0.28794944286346436\n",
      "Epoch 2331, Loss: 1.2633573412895203, Final Batch Loss: 0.3789936304092407\n",
      "Epoch 2332, Loss: 1.125041425228119, Final Batch Loss: 0.2942950129508972\n",
      "Epoch 2333, Loss: 1.2350287735462189, Final Batch Loss: 0.4253471791744232\n",
      "Epoch 2334, Loss: 1.192015290260315, Final Batch Loss: 0.30898189544677734\n",
      "Epoch 2335, Loss: 1.3321644365787506, Final Batch Loss: 0.3733676075935364\n",
      "Epoch 2336, Loss: 1.126166671514511, Final Batch Loss: 0.22276747226715088\n",
      "Epoch 2337, Loss: 1.3038248419761658, Final Batch Loss: 0.29408159852027893\n",
      "Epoch 2338, Loss: 1.2106381952762604, Final Batch Loss: 0.29440054297447205\n",
      "Epoch 2339, Loss: 1.1854758560657501, Final Batch Loss: 0.28060901165008545\n",
      "Epoch 2340, Loss: 1.2383557260036469, Final Batch Loss: 0.30694591999053955\n",
      "Epoch 2341, Loss: 1.2383879125118256, Final Batch Loss: 0.403260201215744\n",
      "Epoch 2342, Loss: 1.1931657642126083, Final Batch Loss: 0.368971049785614\n",
      "Epoch 2343, Loss: 1.0716467052698135, Final Batch Loss: 0.1889633983373642\n",
      "Epoch 2344, Loss: 1.2197010815143585, Final Batch Loss: 0.28121712803840637\n",
      "Epoch 2345, Loss: 1.263934150338173, Final Batch Loss: 0.23201924562454224\n",
      "Epoch 2346, Loss: 1.1894098669290543, Final Batch Loss: 0.2215692698955536\n",
      "Epoch 2347, Loss: 1.1176031231880188, Final Batch Loss: 0.2360169142484665\n",
      "Epoch 2348, Loss: 1.1654787510633469, Final Batch Loss: 0.3075324296951294\n",
      "Epoch 2349, Loss: 1.2680610120296478, Final Batch Loss: 0.3095926344394684\n",
      "Epoch 2350, Loss: 1.3644206523895264, Final Batch Loss: 0.43833282589912415\n",
      "Epoch 2351, Loss: 1.2510962784290314, Final Batch Loss: 0.36825045943260193\n",
      "Epoch 2352, Loss: 1.1948804557323456, Final Batch Loss: 0.383346825838089\n",
      "Epoch 2353, Loss: 1.2053140997886658, Final Batch Loss: 0.32442378997802734\n",
      "Epoch 2354, Loss: 1.163758784532547, Final Batch Loss: 0.2638876438140869\n",
      "Epoch 2355, Loss: 1.2466960847377777, Final Batch Loss: 0.30290380120277405\n",
      "Epoch 2356, Loss: 1.2696199119091034, Final Batch Loss: 0.3135719299316406\n",
      "Epoch 2357, Loss: 1.131315991282463, Final Batch Loss: 0.28887325525283813\n",
      "Epoch 2358, Loss: 1.2117505967617035, Final Batch Loss: 0.27649492025375366\n",
      "Epoch 2359, Loss: 1.391308069229126, Final Batch Loss: 0.3538006842136383\n",
      "Epoch 2360, Loss: 1.2459417581558228, Final Batch Loss: 0.2995615303516388\n",
      "Epoch 2361, Loss: 1.282876193523407, Final Batch Loss: 0.3285726010799408\n",
      "Epoch 2362, Loss: 1.1609875559806824, Final Batch Loss: 0.1620124876499176\n",
      "Epoch 2363, Loss: 1.372362494468689, Final Batch Loss: 0.41479232907295227\n",
      "Epoch 2364, Loss: 1.2967139184474945, Final Batch Loss: 0.3509135842323303\n",
      "Epoch 2365, Loss: 1.2661845088005066, Final Batch Loss: 0.33682939410209656\n",
      "Epoch 2366, Loss: 1.2417148053646088, Final Batch Loss: 0.3985801041126251\n",
      "Epoch 2367, Loss: 1.1920697093009949, Final Batch Loss: 0.3397676646709442\n",
      "Epoch 2368, Loss: 1.0573782622814178, Final Batch Loss: 0.25480377674102783\n",
      "Epoch 2369, Loss: 1.2497817277908325, Final Batch Loss: 0.2832832634449005\n",
      "Epoch 2370, Loss: 1.1314748972654343, Final Batch Loss: 0.2549326419830322\n",
      "Epoch 2371, Loss: 1.2484973222017288, Final Batch Loss: 0.24307791888713837\n",
      "Epoch 2372, Loss: 1.228860080242157, Final Batch Loss: 0.3145786225795746\n",
      "Epoch 2373, Loss: 1.1814111918210983, Final Batch Loss: 0.2087523192167282\n",
      "Epoch 2374, Loss: 1.2474767863750458, Final Batch Loss: 0.3545750081539154\n",
      "Epoch 2375, Loss: 1.2163673043251038, Final Batch Loss: 0.2722450792789459\n",
      "Epoch 2376, Loss: 1.262428104877472, Final Batch Loss: 0.280317097902298\n",
      "Epoch 2377, Loss: 1.2311812490224838, Final Batch Loss: 0.3285977244377136\n",
      "Epoch 2378, Loss: 1.336374819278717, Final Batch Loss: 0.24667587876319885\n",
      "Epoch 2379, Loss: 1.2656342089176178, Final Batch Loss: 0.3510288596153259\n",
      "Epoch 2380, Loss: 1.3158877193927765, Final Batch Loss: 0.4021735191345215\n",
      "Epoch 2381, Loss: 1.3104175627231598, Final Batch Loss: 0.3093326687812805\n",
      "Epoch 2382, Loss: 1.1010886281728745, Final Batch Loss: 0.24781884253025055\n",
      "Epoch 2383, Loss: 1.228377342224121, Final Batch Loss: 0.29941436648368835\n",
      "Epoch 2384, Loss: 1.1445744037628174, Final Batch Loss: 0.3125319480895996\n",
      "Epoch 2385, Loss: 1.352245569229126, Final Batch Loss: 0.25870639085769653\n",
      "Epoch 2386, Loss: 1.3481343388557434, Final Batch Loss: 0.3006356358528137\n",
      "Epoch 2387, Loss: 1.2339225858449936, Final Batch Loss: 0.38449323177337646\n",
      "Epoch 2388, Loss: 1.3083166480064392, Final Batch Loss: 0.41026175022125244\n",
      "Epoch 2389, Loss: 1.3014840185642242, Final Batch Loss: 0.34197860956192017\n",
      "Epoch 2390, Loss: 1.3344103395938873, Final Batch Loss: 0.38992583751678467\n",
      "Epoch 2391, Loss: 1.2643293738365173, Final Batch Loss: 0.38398316502571106\n",
      "Epoch 2392, Loss: 1.4241088926792145, Final Batch Loss: 0.4369715452194214\n",
      "Epoch 2393, Loss: 1.2702012658119202, Final Batch Loss: 0.3589634895324707\n",
      "Epoch 2394, Loss: 1.3096133470535278, Final Batch Loss: 0.3159482479095459\n",
      "Epoch 2395, Loss: 1.1764505207538605, Final Batch Loss: 0.2872016131877899\n",
      "Epoch 2396, Loss: 1.256886675953865, Final Batch Loss: 0.38871830701828003\n",
      "Epoch 2397, Loss: 1.3898392617702484, Final Batch Loss: 0.39014869928359985\n",
      "Epoch 2398, Loss: 1.4431571066379547, Final Batch Loss: 0.34558817744255066\n",
      "Epoch 2399, Loss: 1.1851194202899933, Final Batch Loss: 0.2572551965713501\n",
      "Epoch 2400, Loss: 1.1746018528938293, Final Batch Loss: 0.2617467939853668\n",
      "Epoch 2401, Loss: 1.277598798274994, Final Batch Loss: 0.3442537486553192\n",
      "Epoch 2402, Loss: 1.216331124305725, Final Batch Loss: 0.2530461549758911\n",
      "Epoch 2403, Loss: 1.2369432002305984, Final Batch Loss: 0.27646711468696594\n",
      "Epoch 2404, Loss: 1.2630269229412079, Final Batch Loss: 0.31949010491371155\n",
      "Epoch 2405, Loss: 1.1571040451526642, Final Batch Loss: 0.23889082670211792\n",
      "Epoch 2406, Loss: 1.3608184158802032, Final Batch Loss: 0.4198590815067291\n",
      "Epoch 2407, Loss: 1.3190524876117706, Final Batch Loss: 0.3033384382724762\n",
      "Epoch 2408, Loss: 1.1948949694633484, Final Batch Loss: 0.3344085216522217\n",
      "Epoch 2409, Loss: 1.1778428852558136, Final Batch Loss: 0.31010016798973083\n",
      "Epoch 2410, Loss: 1.3891225755214691, Final Batch Loss: 0.40423086285591125\n",
      "Epoch 2411, Loss: 1.4403823614120483, Final Batch Loss: 0.32864856719970703\n",
      "Epoch 2412, Loss: 1.2575028240680695, Final Batch Loss: 0.2306363731622696\n",
      "Epoch 2413, Loss: 1.2610406875610352, Final Batch Loss: 0.3204151690006256\n",
      "Epoch 2414, Loss: 1.2870768904685974, Final Batch Loss: 0.3485656678676605\n",
      "Epoch 2415, Loss: 1.3400755822658539, Final Batch Loss: 0.3212611973285675\n",
      "Epoch 2416, Loss: 1.2219631671905518, Final Batch Loss: 0.32590147852897644\n",
      "Epoch 2417, Loss: 1.2383230924606323, Final Batch Loss: 0.2881700396537781\n",
      "Epoch 2418, Loss: 1.1852019727230072, Final Batch Loss: 0.2783862352371216\n",
      "Epoch 2419, Loss: 1.2696901559829712, Final Batch Loss: 0.30778613686561584\n",
      "Epoch 2420, Loss: 1.28567573428154, Final Batch Loss: 0.3940196931362152\n",
      "Epoch 2421, Loss: 1.2040109783411026, Final Batch Loss: 0.30802011489868164\n",
      "Epoch 2422, Loss: 1.4373601377010345, Final Batch Loss: 0.3457142114639282\n",
      "Epoch 2423, Loss: 1.1157014071941376, Final Batch Loss: 0.13346171379089355\n",
      "Epoch 2424, Loss: 1.1918305158615112, Final Batch Loss: 0.25885188579559326\n",
      "Epoch 2425, Loss: 1.281796634197235, Final Batch Loss: 0.4169796407222748\n",
      "Epoch 2426, Loss: 1.2066474854946136, Final Batch Loss: 0.24854961037635803\n",
      "Epoch 2427, Loss: 1.0613048076629639, Final Batch Loss: 0.15863248705863953\n",
      "Epoch 2428, Loss: 1.2561942785978317, Final Batch Loss: 0.244397833943367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2429, Loss: 1.1457368433475494, Final Batch Loss: 0.3211565911769867\n",
      "Epoch 2430, Loss: 1.2526257634162903, Final Batch Loss: 0.3798195719718933\n",
      "Epoch 2431, Loss: 1.465555101633072, Final Batch Loss: 0.4081602990627289\n",
      "Epoch 2432, Loss: 1.3019693493843079, Final Batch Loss: 0.36142241954803467\n",
      "Epoch 2433, Loss: 1.2186968624591827, Final Batch Loss: 0.2622763216495514\n",
      "Epoch 2434, Loss: 1.1489258259534836, Final Batch Loss: 0.22762461006641388\n",
      "Epoch 2435, Loss: 1.3676794171333313, Final Batch Loss: 0.3579099178314209\n",
      "Epoch 2436, Loss: 1.1993954479694366, Final Batch Loss: 0.2606545090675354\n",
      "Epoch 2437, Loss: 1.2213091552257538, Final Batch Loss: 0.2962971031665802\n",
      "Epoch 2438, Loss: 1.152157261967659, Final Batch Loss: 0.2280462235212326\n",
      "Epoch 2439, Loss: 1.2753753662109375, Final Batch Loss: 0.25845658779144287\n",
      "Epoch 2440, Loss: 1.3244815468788147, Final Batch Loss: 0.396936297416687\n",
      "Epoch 2441, Loss: 1.2399402558803558, Final Batch Loss: 0.30975085496902466\n",
      "Epoch 2442, Loss: 1.2307890802621841, Final Batch Loss: 0.3725743293762207\n",
      "Epoch 2443, Loss: 1.3193420469760895, Final Batch Loss: 0.3457795977592468\n",
      "Epoch 2444, Loss: 1.266186237335205, Final Batch Loss: 0.2984200119972229\n",
      "Epoch 2445, Loss: 1.2836402356624603, Final Batch Loss: 0.4332839548587799\n",
      "Epoch 2446, Loss: 1.3100223243236542, Final Batch Loss: 0.40405547618865967\n",
      "Epoch 2447, Loss: 1.1375393867492676, Final Batch Loss: 0.2395021617412567\n",
      "Epoch 2448, Loss: 1.1933974921703339, Final Batch Loss: 0.2566237449645996\n",
      "Epoch 2449, Loss: 1.2219067513942719, Final Batch Loss: 0.2645653188228607\n",
      "Epoch 2450, Loss: 1.0807591825723648, Final Batch Loss: 0.28448760509490967\n",
      "Epoch 2451, Loss: 1.3121747374534607, Final Batch Loss: 0.3157142996788025\n",
      "Epoch 2452, Loss: 1.2256280481815338, Final Batch Loss: 0.31646016240119934\n",
      "Epoch 2453, Loss: 1.2941637635231018, Final Batch Loss: 0.3533109724521637\n",
      "Epoch 2454, Loss: 1.2830350995063782, Final Batch Loss: 0.3721994459629059\n",
      "Epoch 2455, Loss: 1.295387640595436, Final Batch Loss: 0.3889581561088562\n",
      "Epoch 2456, Loss: 1.3391444683074951, Final Batch Loss: 0.2621593773365021\n",
      "Epoch 2457, Loss: 1.3811316192150116, Final Batch Loss: 0.33659449219703674\n",
      "Epoch 2458, Loss: 1.367039829492569, Final Batch Loss: 0.4038158655166626\n",
      "Epoch 2459, Loss: 1.3446632325649261, Final Batch Loss: 0.4296525716781616\n",
      "Epoch 2460, Loss: 1.1242015659809113, Final Batch Loss: 0.2606843411922455\n",
      "Epoch 2461, Loss: 1.1419889628887177, Final Batch Loss: 0.2978607416152954\n",
      "Epoch 2462, Loss: 1.2793393433094025, Final Batch Loss: 0.4074755907058716\n",
      "Epoch 2463, Loss: 1.364237904548645, Final Batch Loss: 0.40083032846450806\n",
      "Epoch 2464, Loss: 1.2161319851875305, Final Batch Loss: 0.2601342499256134\n",
      "Epoch 2465, Loss: 1.238602101802826, Final Batch Loss: 0.3679635226726532\n",
      "Epoch 2466, Loss: 1.1545931845903397, Final Batch Loss: 0.33807095885276794\n",
      "Epoch 2467, Loss: 1.339939922094345, Final Batch Loss: 0.3665292263031006\n",
      "Epoch 2468, Loss: 1.1680922657251358, Final Batch Loss: 0.29384738206863403\n",
      "Epoch 2469, Loss: 1.1811830401420593, Final Batch Loss: 0.2679581940174103\n",
      "Epoch 2470, Loss: 1.3687477707862854, Final Batch Loss: 0.28073835372924805\n",
      "Epoch 2471, Loss: 1.2351163029670715, Final Batch Loss: 0.3291461765766144\n",
      "Epoch 2472, Loss: 1.2517817318439484, Final Batch Loss: 0.327533483505249\n",
      "Epoch 2473, Loss: 1.0360625684261322, Final Batch Loss: 0.1874183565378189\n",
      "Epoch 2474, Loss: 1.160096824169159, Final Batch Loss: 0.3583112359046936\n",
      "Epoch 2475, Loss: 1.3634223341941833, Final Batch Loss: 0.36183488368988037\n",
      "Epoch 2476, Loss: 1.1561880111694336, Final Batch Loss: 0.2273063361644745\n",
      "Epoch 2477, Loss: 1.3112601041793823, Final Batch Loss: 0.39725959300994873\n",
      "Epoch 2478, Loss: 1.2759805619716644, Final Batch Loss: 0.2913970351219177\n",
      "Epoch 2479, Loss: 1.2266729325056076, Final Batch Loss: 0.24278058111667633\n",
      "Epoch 2480, Loss: 1.1682597994804382, Final Batch Loss: 0.23895388841629028\n",
      "Epoch 2481, Loss: 1.0709422677755356, Final Batch Loss: 0.2279134839773178\n",
      "Epoch 2482, Loss: 1.1418940722942352, Final Batch Loss: 0.21493849158287048\n",
      "Epoch 2483, Loss: 1.1220141649246216, Final Batch Loss: 0.27281656861305237\n",
      "Epoch 2484, Loss: 1.110459640622139, Final Batch Loss: 0.312626451253891\n",
      "Epoch 2485, Loss: 1.0740614086389542, Final Batch Loss: 0.18007279932498932\n",
      "Epoch 2486, Loss: 1.1821527928113937, Final Batch Loss: 0.24156419932842255\n",
      "Epoch 2487, Loss: 1.2062589824199677, Final Batch Loss: 0.373378187417984\n",
      "Epoch 2488, Loss: 1.2073542028665543, Final Batch Loss: 0.3436579406261444\n",
      "Epoch 2489, Loss: 1.2541887909173965, Final Batch Loss: 0.3865945041179657\n",
      "Epoch 2490, Loss: 1.2209359407424927, Final Batch Loss: 0.23578274250030518\n",
      "Epoch 2491, Loss: 1.164507657289505, Final Batch Loss: 0.22254449129104614\n",
      "Epoch 2492, Loss: 1.1217705756425858, Final Batch Loss: 0.2856261730194092\n",
      "Epoch 2493, Loss: 1.1340559422969818, Final Batch Loss: 0.20016491413116455\n",
      "Epoch 2494, Loss: 1.1592709422111511, Final Batch Loss: 0.3530006408691406\n",
      "Epoch 2495, Loss: 1.285851627588272, Final Batch Loss: 0.3468325436115265\n",
      "Epoch 2496, Loss: 1.2192736119031906, Final Batch Loss: 0.35811367630958557\n",
      "Epoch 2497, Loss: 1.2555780112743378, Final Batch Loss: 0.3031696379184723\n",
      "Epoch 2498, Loss: 1.1888846158981323, Final Batch Loss: 0.25949200987815857\n",
      "Epoch 2499, Loss: 1.2832534909248352, Final Batch Loss: 0.26030197739601135\n",
      "Epoch 2500, Loss: 1.2281364798545837, Final Batch Loss: 0.28917959332466125\n",
      "Epoch 2501, Loss: 1.1840555965900421, Final Batch Loss: 0.24979037046432495\n",
      "Epoch 2502, Loss: 1.1908923089504242, Final Batch Loss: 0.2755815088748932\n",
      "Epoch 2503, Loss: 1.3183010518550873, Final Batch Loss: 0.31904470920562744\n",
      "Epoch 2504, Loss: 1.0633681118488312, Final Batch Loss: 0.2568973898887634\n",
      "Epoch 2505, Loss: 1.1732256710529327, Final Batch Loss: 0.2582668662071228\n",
      "Epoch 2506, Loss: 1.364157885313034, Final Batch Loss: 0.3999806046485901\n",
      "Epoch 2507, Loss: 1.2218468189239502, Final Batch Loss: 0.36329585313796997\n",
      "Epoch 2508, Loss: 1.033139705657959, Final Batch Loss: 0.22332975268363953\n",
      "Epoch 2509, Loss: 1.2584488093852997, Final Batch Loss: 0.3705354928970337\n",
      "Epoch 2510, Loss: 1.1620640754699707, Final Batch Loss: 0.3223901689052582\n",
      "Epoch 2511, Loss: 1.5084442794322968, Final Batch Loss: 0.5104807615280151\n",
      "Epoch 2512, Loss: 1.1605236381292343, Final Batch Loss: 0.24784217774868011\n",
      "Epoch 2513, Loss: 1.382683888077736, Final Batch Loss: 0.41204023361206055\n",
      "Epoch 2514, Loss: 1.3400365114212036, Final Batch Loss: 0.4273335337638855\n",
      "Epoch 2515, Loss: 1.1613166779279709, Final Batch Loss: 0.23098327219486237\n",
      "Epoch 2516, Loss: 1.1507029980421066, Final Batch Loss: 0.27812427282333374\n",
      "Epoch 2517, Loss: 1.3091674149036407, Final Batch Loss: 0.35379114747047424\n",
      "Epoch 2518, Loss: 1.293480098247528, Final Batch Loss: 0.36418867111206055\n",
      "Epoch 2519, Loss: 1.136639580130577, Final Batch Loss: 0.20764519274234772\n",
      "Epoch 2520, Loss: 1.2528928816318512, Final Batch Loss: 0.3841632306575775\n",
      "Epoch 2521, Loss: 1.2206422239542007, Final Batch Loss: 0.3384726941585541\n",
      "Epoch 2522, Loss: 1.1915264129638672, Final Batch Loss: 0.2535974383354187\n",
      "Epoch 2523, Loss: 1.2964236438274384, Final Batch Loss: 0.29706010222435\n",
      "Epoch 2524, Loss: 1.2312772572040558, Final Batch Loss: 0.297903835773468\n",
      "Epoch 2525, Loss: 1.244188904762268, Final Batch Loss: 0.25453895330429077\n",
      "Epoch 2526, Loss: 1.2342788577079773, Final Batch Loss: 0.3108605742454529\n",
      "Epoch 2527, Loss: 1.2632827758789062, Final Batch Loss: 0.2889658212661743\n",
      "Epoch 2528, Loss: 1.1974334716796875, Final Batch Loss: 0.31460216641426086\n",
      "Epoch 2529, Loss: 1.2417607605457306, Final Batch Loss: 0.34296366572380066\n",
      "Epoch 2530, Loss: 1.1034149527549744, Final Batch Loss: 0.28432294726371765\n",
      "Epoch 2531, Loss: 1.2197735607624054, Final Batch Loss: 0.29217079281806946\n",
      "Epoch 2532, Loss: 1.1695417165756226, Final Batch Loss: 0.30284854769706726\n",
      "Epoch 2533, Loss: 1.3793386816978455, Final Batch Loss: 0.44534069299697876\n",
      "Epoch 2534, Loss: 1.1263709962368011, Final Batch Loss: 0.3007650673389435\n",
      "Epoch 2535, Loss: 1.4772633612155914, Final Batch Loss: 0.5362333655357361\n",
      "Epoch 2536, Loss: 1.2503381967544556, Final Batch Loss: 0.3275807797908783\n",
      "Epoch 2537, Loss: 1.1054243743419647, Final Batch Loss: 0.27110379934310913\n",
      "Epoch 2538, Loss: 1.257972702383995, Final Batch Loss: 0.22812844812870026\n",
      "Epoch 2539, Loss: 1.1476350128650665, Final Batch Loss: 0.26896440982818604\n",
      "Epoch 2540, Loss: 1.1815958321094513, Final Batch Loss: 0.3134450316429138\n",
      "Epoch 2541, Loss: 1.1915411353111267, Final Batch Loss: 0.39047929644584656\n",
      "Epoch 2542, Loss: 1.1491329669952393, Final Batch Loss: 0.2545042037963867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2543, Loss: 1.0779153257608414, Final Batch Loss: 0.2819134593009949\n",
      "Epoch 2544, Loss: 1.2785584926605225, Final Batch Loss: 0.36781206727027893\n",
      "Epoch 2545, Loss: 1.3115954995155334, Final Batch Loss: 0.49663862586021423\n",
      "Epoch 2546, Loss: 1.1874756813049316, Final Batch Loss: 0.3024258613586426\n",
      "Epoch 2547, Loss: 1.1300782263278961, Final Batch Loss: 0.2979969382286072\n",
      "Epoch 2548, Loss: 1.1863570809364319, Final Batch Loss: 0.25003060698509216\n",
      "Epoch 2549, Loss: 1.070838376879692, Final Batch Loss: 0.20772133767604828\n",
      "Epoch 2550, Loss: 1.1897418797016144, Final Batch Loss: 0.2948853373527527\n",
      "Epoch 2551, Loss: 1.2131593078374863, Final Batch Loss: 0.3198269009590149\n",
      "Epoch 2552, Loss: 1.1600398123264313, Final Batch Loss: 0.2796744704246521\n",
      "Epoch 2553, Loss: 1.1552830636501312, Final Batch Loss: 0.22057676315307617\n",
      "Epoch 2554, Loss: 1.2034145444631577, Final Batch Loss: 0.2109895795583725\n",
      "Epoch 2555, Loss: 1.236859530210495, Final Batch Loss: 0.31562134623527527\n",
      "Epoch 2556, Loss: 1.255364090204239, Final Batch Loss: 0.35359466075897217\n",
      "Epoch 2557, Loss: 1.1634887754917145, Final Batch Loss: 0.21696403622627258\n",
      "Epoch 2558, Loss: 1.371719092130661, Final Batch Loss: 0.4495188295841217\n",
      "Epoch 2559, Loss: 1.2740783095359802, Final Batch Loss: 0.353060781955719\n",
      "Epoch 2560, Loss: 1.1819575130939484, Final Batch Loss: 0.23526862263679504\n",
      "Epoch 2561, Loss: 1.2992950677871704, Final Batch Loss: 0.32975712418556213\n",
      "Epoch 2562, Loss: 1.2393250167369843, Final Batch Loss: 0.3425903916358948\n",
      "Epoch 2563, Loss: 1.3236095905303955, Final Batch Loss: 0.42073720693588257\n",
      "Epoch 2564, Loss: 1.1778539717197418, Final Batch Loss: 0.25913065671920776\n",
      "Epoch 2565, Loss: 1.1339001506567001, Final Batch Loss: 0.3324723243713379\n",
      "Epoch 2566, Loss: 1.2453610301017761, Final Batch Loss: 0.2903648316860199\n",
      "Epoch 2567, Loss: 1.1468114256858826, Final Batch Loss: 0.253081738948822\n",
      "Epoch 2568, Loss: 1.1310206055641174, Final Batch Loss: 0.2676562964916229\n",
      "Epoch 2569, Loss: 1.3105053305625916, Final Batch Loss: 0.40360796451568604\n",
      "Epoch 2570, Loss: 1.2596212029457092, Final Batch Loss: 0.3628906309604645\n",
      "Epoch 2571, Loss: 1.2993425130844116, Final Batch Loss: 0.35183045268058777\n",
      "Epoch 2572, Loss: 1.1683081537485123, Final Batch Loss: 0.22602461278438568\n",
      "Epoch 2573, Loss: 1.1893026232719421, Final Batch Loss: 0.32351425290107727\n",
      "Epoch 2574, Loss: 1.0933113098144531, Final Batch Loss: 0.24953559041023254\n",
      "Epoch 2575, Loss: 1.1493733823299408, Final Batch Loss: 0.27660220861434937\n",
      "Epoch 2576, Loss: 1.393805593252182, Final Batch Loss: 0.49805471301078796\n",
      "Epoch 2577, Loss: 1.265742301940918, Final Batch Loss: 0.27517956495285034\n",
      "Epoch 2578, Loss: 1.1195782721042633, Final Batch Loss: 0.2703332304954529\n",
      "Epoch 2579, Loss: 1.1577500700950623, Final Batch Loss: 0.2667357921600342\n",
      "Epoch 2580, Loss: 1.3145386576652527, Final Batch Loss: 0.2641215920448303\n",
      "Epoch 2581, Loss: 1.1253779530525208, Final Batch Loss: 0.29691198468208313\n",
      "Epoch 2582, Loss: 1.413608878850937, Final Batch Loss: 0.41928377747535706\n",
      "Epoch 2583, Loss: 1.1237006485462189, Final Batch Loss: 0.2778489887714386\n",
      "Epoch 2584, Loss: 1.2512188404798508, Final Batch Loss: 0.3174191117286682\n",
      "Epoch 2585, Loss: 1.1377127766609192, Final Batch Loss: 0.2913438081741333\n",
      "Epoch 2586, Loss: 1.262256234884262, Final Batch Loss: 0.27180981636047363\n",
      "Epoch 2587, Loss: 1.1628078520298004, Final Batch Loss: 0.2837267518043518\n",
      "Epoch 2588, Loss: 1.193133533000946, Final Batch Loss: 0.2531067132949829\n",
      "Epoch 2589, Loss: 1.1770547181367874, Final Batch Loss: 0.28455600142478943\n",
      "Epoch 2590, Loss: 1.090383917093277, Final Batch Loss: 0.23878857493400574\n",
      "Epoch 2591, Loss: 1.2241783142089844, Final Batch Loss: 0.2816380262374878\n",
      "Epoch 2592, Loss: 1.1869190335273743, Final Batch Loss: 0.28363844752311707\n",
      "Epoch 2593, Loss: 1.2466067969799042, Final Batch Loss: 0.3218519985675812\n",
      "Epoch 2594, Loss: 1.1217795610427856, Final Batch Loss: 0.20137035846710205\n",
      "Epoch 2595, Loss: 1.1737549602985382, Final Batch Loss: 0.30935215950012207\n",
      "Epoch 2596, Loss: 1.1364586353302002, Final Batch Loss: 0.33290618658065796\n",
      "Epoch 2597, Loss: 1.282941222190857, Final Batch Loss: 0.3409077227115631\n",
      "Epoch 2598, Loss: 1.252831131219864, Final Batch Loss: 0.3319600224494934\n",
      "Epoch 2599, Loss: 1.2502292096614838, Final Batch Loss: 0.2509889304637909\n",
      "Epoch 2600, Loss: 1.2897921353578568, Final Batch Loss: 0.40174946188926697\n",
      "Epoch 2601, Loss: 1.2167364954948425, Final Batch Loss: 0.2558402121067047\n",
      "Epoch 2602, Loss: 1.061283454298973, Final Batch Loss: 0.2718634307384491\n",
      "Epoch 2603, Loss: 1.1236930042505264, Final Batch Loss: 0.1768476366996765\n",
      "Epoch 2604, Loss: 1.1509422659873962, Final Batch Loss: 0.29529595375061035\n",
      "Epoch 2605, Loss: 1.243231862783432, Final Batch Loss: 0.2875438630580902\n",
      "Epoch 2606, Loss: 1.1358233392238617, Final Batch Loss: 0.2803749144077301\n",
      "Epoch 2607, Loss: 1.3462187945842743, Final Batch Loss: 0.38114312291145325\n",
      "Epoch 2608, Loss: 1.01128751039505, Final Batch Loss: 0.17963586747646332\n",
      "Epoch 2609, Loss: 1.1307367533445358, Final Batch Loss: 0.2099909633398056\n",
      "Epoch 2610, Loss: 1.0621987283229828, Final Batch Loss: 0.27175959944725037\n",
      "Epoch 2611, Loss: 1.1509222984313965, Final Batch Loss: 0.2762753963470459\n",
      "Epoch 2612, Loss: 1.1442401707172394, Final Batch Loss: 0.23125532269477844\n",
      "Epoch 2613, Loss: 1.1702899038791656, Final Batch Loss: 0.2766929864883423\n",
      "Epoch 2614, Loss: 1.110047236084938, Final Batch Loss: 0.2775992453098297\n",
      "Epoch 2615, Loss: 1.204861119389534, Final Batch Loss: 0.314880907535553\n",
      "Epoch 2616, Loss: 1.3051193952560425, Final Batch Loss: 0.2874327301979065\n",
      "Epoch 2617, Loss: 1.1099838465452194, Final Batch Loss: 0.2625214159488678\n",
      "Epoch 2618, Loss: 1.1926023066043854, Final Batch Loss: 0.2783650755882263\n",
      "Epoch 2619, Loss: 1.129131868481636, Final Batch Loss: 0.2855971157550812\n",
      "Epoch 2620, Loss: 1.1805101931095123, Final Batch Loss: 0.3250552713871002\n",
      "Epoch 2621, Loss: 1.1549776494503021, Final Batch Loss: 0.2724285423755646\n",
      "Epoch 2622, Loss: 1.1706575453281403, Final Batch Loss: 0.33055511116981506\n",
      "Epoch 2623, Loss: 1.1710658520460129, Final Batch Loss: 0.30298054218292236\n",
      "Epoch 2624, Loss: 1.2498435080051422, Final Batch Loss: 0.3370492160320282\n",
      "Epoch 2625, Loss: 1.2112779021263123, Final Batch Loss: 0.30779188871383667\n",
      "Epoch 2626, Loss: 1.1176391690969467, Final Batch Loss: 0.31354957818984985\n",
      "Epoch 2627, Loss: 1.1140366792678833, Final Batch Loss: 0.26310059428215027\n",
      "Epoch 2628, Loss: 1.1433531939983368, Final Batch Loss: 0.29280713200569153\n",
      "Epoch 2629, Loss: 1.356466293334961, Final Batch Loss: 0.3361726701259613\n",
      "Epoch 2630, Loss: 1.2117643058300018, Final Batch Loss: 0.33222049474716187\n",
      "Epoch 2631, Loss: 1.2701517939567566, Final Batch Loss: 0.326823890209198\n",
      "Epoch 2632, Loss: 1.2177253067493439, Final Batch Loss: 0.2933092415332794\n",
      "Epoch 2633, Loss: 1.257726788520813, Final Batch Loss: 0.33748966455459595\n",
      "Epoch 2634, Loss: 1.242292732000351, Final Batch Loss: 0.2561761140823364\n",
      "Epoch 2635, Loss: 1.2074808925390244, Final Batch Loss: 0.2680515646934509\n",
      "Epoch 2636, Loss: 1.2275195121765137, Final Batch Loss: 0.28607282042503357\n",
      "Epoch 2637, Loss: 1.2355588972568512, Final Batch Loss: 0.2641673684120178\n",
      "Epoch 2638, Loss: 1.178899735212326, Final Batch Loss: 0.39132818579673767\n",
      "Epoch 2639, Loss: 1.145229995250702, Final Batch Loss: 0.3452557325363159\n",
      "Epoch 2640, Loss: 1.1078943014144897, Final Batch Loss: 0.27262964844703674\n",
      "Epoch 2641, Loss: 1.1314708292484283, Final Batch Loss: 0.2762349247932434\n",
      "Epoch 2642, Loss: 1.0916921496391296, Final Batch Loss: 0.26526182889938354\n",
      "Epoch 2643, Loss: 1.1953407526016235, Final Batch Loss: 0.29740461707115173\n",
      "Epoch 2644, Loss: 1.1343891322612762, Final Batch Loss: 0.2917788326740265\n",
      "Epoch 2645, Loss: 1.098127320408821, Final Batch Loss: 0.2900696098804474\n",
      "Epoch 2646, Loss: 1.3171294629573822, Final Batch Loss: 0.3811999261379242\n",
      "Epoch 2647, Loss: 1.1418568789958954, Final Batch Loss: 0.35144659876823425\n",
      "Epoch 2648, Loss: 1.289787471294403, Final Batch Loss: 0.3015884459018707\n",
      "Epoch 2649, Loss: 1.129682868719101, Final Batch Loss: 0.32870566844940186\n",
      "Epoch 2650, Loss: 1.02602519094944, Final Batch Loss: 0.20643368363380432\n",
      "Epoch 2651, Loss: 1.216591477394104, Final Batch Loss: 0.337939590215683\n",
      "Epoch 2652, Loss: 1.273291438817978, Final Batch Loss: 0.35949501395225525\n",
      "Epoch 2653, Loss: 1.1898480951786041, Final Batch Loss: 0.2968350350856781\n",
      "Epoch 2654, Loss: 1.233385369181633, Final Batch Loss: 0.24857474863529205\n",
      "Epoch 2655, Loss: 1.3771664500236511, Final Batch Loss: 0.3376838266849518\n",
      "Epoch 2656, Loss: 1.1925728470087051, Final Batch Loss: 0.20305953919887543\n",
      "Epoch 2657, Loss: 1.1454360485076904, Final Batch Loss: 0.25435203313827515\n",
      "Epoch 2658, Loss: 1.2044172883033752, Final Batch Loss: 0.2597472369670868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2659, Loss: 1.1238219141960144, Final Batch Loss: 0.2979750633239746\n",
      "Epoch 2660, Loss: 1.2568802684545517, Final Batch Loss: 0.3171080946922302\n",
      "Epoch 2661, Loss: 1.1685497760772705, Final Batch Loss: 0.25314095616340637\n",
      "Epoch 2662, Loss: 1.1715310215950012, Final Batch Loss: 0.28436657786369324\n",
      "Epoch 2663, Loss: 1.273185282945633, Final Batch Loss: 0.45465680956840515\n",
      "Epoch 2664, Loss: 1.1333149075508118, Final Batch Loss: 0.2803817689418793\n",
      "Epoch 2665, Loss: 1.2109452188014984, Final Batch Loss: 0.25869569182395935\n",
      "Epoch 2666, Loss: 1.1370074450969696, Final Batch Loss: 0.2619091868400574\n",
      "Epoch 2667, Loss: 1.2282821834087372, Final Batch Loss: 0.27154508233070374\n",
      "Epoch 2668, Loss: 1.0736036151647568, Final Batch Loss: 0.36045992374420166\n",
      "Epoch 2669, Loss: 1.3174383044242859, Final Batch Loss: 0.3789607286453247\n",
      "Epoch 2670, Loss: 1.2133957743644714, Final Batch Loss: 0.3531075417995453\n",
      "Epoch 2671, Loss: 1.1564756333827972, Final Batch Loss: 0.29849618673324585\n",
      "Epoch 2672, Loss: 1.2242542803287506, Final Batch Loss: 0.3712038993835449\n",
      "Epoch 2673, Loss: 1.127785474061966, Final Batch Loss: 0.2792901396751404\n",
      "Epoch 2674, Loss: 1.1629655063152313, Final Batch Loss: 0.3176099359989166\n",
      "Epoch 2675, Loss: 1.1956916898488998, Final Batch Loss: 0.378426730632782\n",
      "Epoch 2676, Loss: 1.172767013311386, Final Batch Loss: 0.2828451097011566\n",
      "Epoch 2677, Loss: 1.1377269923686981, Final Batch Loss: 0.2814418375492096\n",
      "Epoch 2678, Loss: 1.1052914410829544, Final Batch Loss: 0.23492638766765594\n",
      "Epoch 2679, Loss: 1.165438026189804, Final Batch Loss: 0.2781130373477936\n",
      "Epoch 2680, Loss: 1.272077202796936, Final Batch Loss: 0.3210604786872864\n",
      "Epoch 2681, Loss: 1.0313926935195923, Final Batch Loss: 0.17861402034759521\n",
      "Epoch 2682, Loss: 1.0803586840629578, Final Batch Loss: 0.23690997064113617\n",
      "Epoch 2683, Loss: 1.0426517874002457, Final Batch Loss: 0.19565844535827637\n",
      "Epoch 2684, Loss: 1.276694506406784, Final Batch Loss: 0.3394497334957123\n",
      "Epoch 2685, Loss: 1.1208823919296265, Final Batch Loss: 0.32092997431755066\n",
      "Epoch 2686, Loss: 1.1840483844280243, Final Batch Loss: 0.2837525010108948\n",
      "Epoch 2687, Loss: 1.0484286844730377, Final Batch Loss: 0.2764380872249603\n",
      "Epoch 2688, Loss: 1.0843002796173096, Final Batch Loss: 0.2768150568008423\n",
      "Epoch 2689, Loss: 1.188025325536728, Final Batch Loss: 0.2826704680919647\n",
      "Epoch 2690, Loss: 1.1154195964336395, Final Batch Loss: 0.2744620442390442\n",
      "Epoch 2691, Loss: 1.3641229271888733, Final Batch Loss: 0.33776554465293884\n",
      "Epoch 2692, Loss: 1.028407245874405, Final Batch Loss: 0.15671777725219727\n",
      "Epoch 2693, Loss: 1.1956826746463776, Final Batch Loss: 0.3217933177947998\n",
      "Epoch 2694, Loss: 1.2434864342212677, Final Batch Loss: 0.32538723945617676\n",
      "Epoch 2695, Loss: 1.1638224422931671, Final Batch Loss: 0.25647270679473877\n",
      "Epoch 2696, Loss: 1.1195094883441925, Final Batch Loss: 0.29272696375846863\n",
      "Epoch 2697, Loss: 1.102112352848053, Final Batch Loss: 0.21841377019882202\n",
      "Epoch 2698, Loss: 1.2804304957389832, Final Batch Loss: 0.3965606391429901\n",
      "Epoch 2699, Loss: 1.144158035516739, Final Batch Loss: 0.2967766523361206\n",
      "Epoch 2700, Loss: 1.3059460073709488, Final Batch Loss: 0.32021963596343994\n",
      "Epoch 2701, Loss: 1.0506342351436615, Final Batch Loss: 0.3378620743751526\n",
      "Epoch 2702, Loss: 1.1087304949760437, Final Batch Loss: 0.2733384966850281\n",
      "Epoch 2703, Loss: 1.2091084420681, Final Batch Loss: 0.38451993465423584\n",
      "Epoch 2704, Loss: 1.1995876133441925, Final Batch Loss: 0.293706476688385\n",
      "Epoch 2705, Loss: 1.1055065542459488, Final Batch Loss: 0.26092082262039185\n",
      "Epoch 2706, Loss: 1.1282888352870941, Final Batch Loss: 0.2993205487728119\n",
      "Epoch 2707, Loss: 1.2260472178459167, Final Batch Loss: 0.32552894949913025\n",
      "Epoch 2708, Loss: 1.260183423757553, Final Batch Loss: 0.24991029500961304\n",
      "Epoch 2709, Loss: 1.1205534040927887, Final Batch Loss: 0.2245372235774994\n",
      "Epoch 2710, Loss: 1.0373209565877914, Final Batch Loss: 0.2359512746334076\n",
      "Epoch 2711, Loss: 1.2646819055080414, Final Batch Loss: 0.28965747356414795\n",
      "Epoch 2712, Loss: 1.1240485906600952, Final Batch Loss: 0.3140527307987213\n",
      "Epoch 2713, Loss: 1.0860538184642792, Final Batch Loss: 0.2628970742225647\n",
      "Epoch 2714, Loss: 1.1139146089553833, Final Batch Loss: 0.31882405281066895\n",
      "Epoch 2715, Loss: 1.0806376039981842, Final Batch Loss: 0.23463448882102966\n",
      "Epoch 2716, Loss: 1.2691194117069244, Final Batch Loss: 0.3457459509372711\n",
      "Epoch 2717, Loss: 1.118294209241867, Final Batch Loss: 0.2925400733947754\n",
      "Epoch 2718, Loss: 1.1627416908740997, Final Batch Loss: 0.3116242289543152\n",
      "Epoch 2719, Loss: 1.3132227063179016, Final Batch Loss: 0.3624334931373596\n",
      "Epoch 2720, Loss: 1.1067119538784027, Final Batch Loss: 0.3079528212547302\n",
      "Epoch 2721, Loss: 1.0497457087039948, Final Batch Loss: 0.2478775680065155\n",
      "Epoch 2722, Loss: 1.0830655097961426, Final Batch Loss: 0.2074001431465149\n",
      "Epoch 2723, Loss: 1.1579477936029434, Final Batch Loss: 0.2770765721797943\n",
      "Epoch 2724, Loss: 1.2290394306182861, Final Batch Loss: 0.32007694244384766\n",
      "Epoch 2725, Loss: 1.145834505558014, Final Batch Loss: 0.24801093339920044\n",
      "Epoch 2726, Loss: 1.1765994131565094, Final Batch Loss: 0.27529868483543396\n",
      "Epoch 2727, Loss: 1.2810592651367188, Final Batch Loss: 0.36052587628364563\n",
      "Epoch 2728, Loss: 1.251870483160019, Final Batch Loss: 0.31425946950912476\n",
      "Epoch 2729, Loss: 1.0556836128234863, Final Batch Loss: 0.20091545581817627\n",
      "Epoch 2730, Loss: 1.1941077709197998, Final Batch Loss: 0.3495219647884369\n",
      "Epoch 2731, Loss: 1.1766103357076645, Final Batch Loss: 0.2298101931810379\n",
      "Epoch 2732, Loss: 1.2062985301017761, Final Batch Loss: 0.2640565037727356\n",
      "Epoch 2733, Loss: 1.2131128311157227, Final Batch Loss: 0.2274961769580841\n",
      "Epoch 2734, Loss: 1.207837074995041, Final Batch Loss: 0.33836236596107483\n",
      "Epoch 2735, Loss: 1.2124378979206085, Final Batch Loss: 0.3692426383495331\n",
      "Epoch 2736, Loss: 1.2721843421459198, Final Batch Loss: 0.4270976185798645\n",
      "Epoch 2737, Loss: 1.1653172969818115, Final Batch Loss: 0.31330734491348267\n",
      "Epoch 2738, Loss: 1.276512771844864, Final Batch Loss: 0.26944637298583984\n",
      "Epoch 2739, Loss: 1.3096783757209778, Final Batch Loss: 0.38607585430145264\n",
      "Epoch 2740, Loss: 1.250711351633072, Final Batch Loss: 0.3315010964870453\n",
      "Epoch 2741, Loss: 1.1239557564258575, Final Batch Loss: 0.23475947976112366\n",
      "Epoch 2742, Loss: 1.0705354809761047, Final Batch Loss: 0.2685311436653137\n",
      "Epoch 2743, Loss: 1.2173166573047638, Final Batch Loss: 0.28555411100387573\n",
      "Epoch 2744, Loss: 1.1396544575691223, Final Batch Loss: 0.31602317094802856\n",
      "Epoch 2745, Loss: 1.1324134171009064, Final Batch Loss: 0.294540137052536\n",
      "Epoch 2746, Loss: 1.1724666506052017, Final Batch Loss: 0.35106539726257324\n",
      "Epoch 2747, Loss: 1.11818128824234, Final Batch Loss: 0.2634664475917816\n",
      "Epoch 2748, Loss: 1.1195108592510223, Final Batch Loss: 0.256991982460022\n",
      "Epoch 2749, Loss: 1.2877641469240189, Final Batch Loss: 0.3340817093849182\n",
      "Epoch 2750, Loss: 1.0944900810718536, Final Batch Loss: 0.2485332489013672\n",
      "Epoch 2751, Loss: 1.150928109884262, Final Batch Loss: 0.2682132422924042\n",
      "Epoch 2752, Loss: 1.1445115804672241, Final Batch Loss: 0.27413269877433777\n",
      "Epoch 2753, Loss: 1.1965064704418182, Final Batch Loss: 0.29401278495788574\n",
      "Epoch 2754, Loss: 0.9637618809938431, Final Batch Loss: 0.16888192296028137\n",
      "Epoch 2755, Loss: 1.0900287479162216, Final Batch Loss: 0.309378981590271\n",
      "Epoch 2756, Loss: 1.1290095299482346, Final Batch Loss: 0.24071194231510162\n",
      "Epoch 2757, Loss: 1.120206281542778, Final Batch Loss: 0.23545442521572113\n",
      "Epoch 2758, Loss: 1.2406927943229675, Final Batch Loss: 0.2735291123390198\n",
      "Epoch 2759, Loss: 1.4066355228424072, Final Batch Loss: 0.5230004787445068\n",
      "Epoch 2760, Loss: 1.234567642211914, Final Batch Loss: 0.3051062822341919\n",
      "Epoch 2761, Loss: 1.1465209424495697, Final Batch Loss: 0.3058033585548401\n",
      "Epoch 2762, Loss: 1.1691043823957443, Final Batch Loss: 0.23776875436306\n",
      "Epoch 2763, Loss: 1.1923312544822693, Final Batch Loss: 0.30793386697769165\n",
      "Epoch 2764, Loss: 1.0273040384054184, Final Batch Loss: 0.26036474108695984\n",
      "Epoch 2765, Loss: 1.2662509083747864, Final Batch Loss: 0.31691640615463257\n",
      "Epoch 2766, Loss: 1.313290685415268, Final Batch Loss: 0.3840169906616211\n",
      "Epoch 2767, Loss: 1.2416347861289978, Final Batch Loss: 0.3477891981601715\n",
      "Epoch 2768, Loss: 1.2489518821239471, Final Batch Loss: 0.3263622522354126\n",
      "Epoch 2769, Loss: 1.1394516229629517, Final Batch Loss: 0.25956422090530396\n",
      "Epoch 2770, Loss: 1.2652715742588043, Final Batch Loss: 0.33507952094078064\n",
      "Epoch 2771, Loss: 1.2112739384174347, Final Batch Loss: 0.34525421261787415\n",
      "Epoch 2772, Loss: 1.1115669012069702, Final Batch Loss: 0.1628354787826538\n",
      "Epoch 2773, Loss: 1.229146808385849, Final Batch Loss: 0.3099561929702759\n",
      "Epoch 2774, Loss: 1.1496365666389465, Final Batch Loss: 0.2527585029602051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2775, Loss: 1.1447960883378983, Final Batch Loss: 0.22150297462940216\n",
      "Epoch 2776, Loss: 1.167131096124649, Final Batch Loss: 0.2605830729007721\n",
      "Epoch 2777, Loss: 1.0322838127613068, Final Batch Loss: 0.2223026156425476\n",
      "Epoch 2778, Loss: 1.050236001610756, Final Batch Loss: 0.22976098954677582\n",
      "Epoch 2779, Loss: 0.9611508399248123, Final Batch Loss: 0.17180366814136505\n",
      "Epoch 2780, Loss: 1.1946137249469757, Final Batch Loss: 0.2554593086242676\n",
      "Epoch 2781, Loss: 1.1489688456058502, Final Batch Loss: 0.2862008810043335\n",
      "Epoch 2782, Loss: 1.2398886233568192, Final Batch Loss: 0.4144606292247772\n",
      "Epoch 2783, Loss: 1.250119298696518, Final Batch Loss: 0.2767082452774048\n",
      "Epoch 2784, Loss: 1.338685780763626, Final Batch Loss: 0.35091274976730347\n",
      "Epoch 2785, Loss: 1.1105816066265106, Final Batch Loss: 0.2674354016780853\n",
      "Epoch 2786, Loss: 1.1915299594402313, Final Batch Loss: 0.25363174080848694\n",
      "Epoch 2787, Loss: 1.2611278891563416, Final Batch Loss: 0.40570226311683655\n",
      "Epoch 2788, Loss: 1.135388821363449, Final Batch Loss: 0.22836518287658691\n",
      "Epoch 2789, Loss: 1.0828221291303635, Final Batch Loss: 0.20210663974285126\n",
      "Epoch 2790, Loss: 1.105813354253769, Final Batch Loss: 0.2406136691570282\n",
      "Epoch 2791, Loss: 1.095873385667801, Final Batch Loss: 0.2617650628089905\n",
      "Epoch 2792, Loss: 1.2300085723400116, Final Batch Loss: 0.27055028080940247\n",
      "Epoch 2793, Loss: 1.3160159289836884, Final Batch Loss: 0.3654150068759918\n",
      "Epoch 2794, Loss: 1.0782792568206787, Final Batch Loss: 0.28340527415275574\n",
      "Epoch 2795, Loss: 1.1836544275283813, Final Batch Loss: 0.26306864619255066\n",
      "Epoch 2796, Loss: 1.2974736094474792, Final Batch Loss: 0.3068734109401703\n",
      "Epoch 2797, Loss: 1.2260390520095825, Final Batch Loss: 0.30235645174980164\n",
      "Epoch 2798, Loss: 1.1791273057460785, Final Batch Loss: 0.3656846284866333\n",
      "Epoch 2799, Loss: 1.1692777425050735, Final Batch Loss: 0.23997990787029266\n",
      "Epoch 2800, Loss: 1.0933260172605515, Final Batch Loss: 0.3281829059123993\n",
      "Epoch 2801, Loss: 1.194949060678482, Final Batch Loss: 0.26176509261131287\n",
      "Epoch 2802, Loss: 1.1730739325284958, Final Batch Loss: 0.25227874517440796\n",
      "Epoch 2803, Loss: 1.2154803276062012, Final Batch Loss: 0.31689366698265076\n",
      "Epoch 2804, Loss: 1.2499675452709198, Final Batch Loss: 0.301125705242157\n",
      "Epoch 2805, Loss: 1.1088216453790665, Final Batch Loss: 0.2961967885494232\n",
      "Epoch 2806, Loss: 0.9551616013050079, Final Batch Loss: 0.2939623296260834\n",
      "Epoch 2807, Loss: 1.234409213066101, Final Batch Loss: 0.3135530650615692\n",
      "Epoch 2808, Loss: 1.1266351789236069, Final Batch Loss: 0.23953647911548615\n",
      "Epoch 2809, Loss: 1.104506939649582, Final Batch Loss: 0.26948872208595276\n",
      "Epoch 2810, Loss: 1.1568481773138046, Final Batch Loss: 0.27320683002471924\n",
      "Epoch 2811, Loss: 1.206611692905426, Final Batch Loss: 0.28664833307266235\n",
      "Epoch 2812, Loss: 1.2599784135818481, Final Batch Loss: 0.3727666139602661\n",
      "Epoch 2813, Loss: 1.0454066693782806, Final Batch Loss: 0.24590784311294556\n",
      "Epoch 2814, Loss: 1.1232144236564636, Final Batch Loss: 0.26018479466438293\n",
      "Epoch 2815, Loss: 1.0419700592756271, Final Batch Loss: 0.2334376871585846\n",
      "Epoch 2816, Loss: 1.188081294298172, Final Batch Loss: 0.2870173752307892\n",
      "Epoch 2817, Loss: 1.168366402387619, Final Batch Loss: 0.36832231283187866\n",
      "Epoch 2818, Loss: 1.2070974111557007, Final Batch Loss: 0.24433410167694092\n",
      "Epoch 2819, Loss: 1.1613620221614838, Final Batch Loss: 0.33934155106544495\n",
      "Epoch 2820, Loss: 1.070816695690155, Final Batch Loss: 0.2580642104148865\n",
      "Epoch 2821, Loss: 1.105400875210762, Final Batch Loss: 0.22223792970180511\n",
      "Epoch 2822, Loss: 1.0840785801410675, Final Batch Loss: 0.24562904238700867\n",
      "Epoch 2823, Loss: 1.112703561782837, Final Batch Loss: 0.23177772760391235\n",
      "Epoch 2824, Loss: 1.2306349575519562, Final Batch Loss: 0.2966589331626892\n",
      "Epoch 2825, Loss: 1.1777527630329132, Final Batch Loss: 0.3412014842033386\n",
      "Epoch 2826, Loss: 1.1501200795173645, Final Batch Loss: 0.2857701778411865\n",
      "Epoch 2827, Loss: 1.2015594840049744, Final Batch Loss: 0.33386993408203125\n",
      "Epoch 2828, Loss: 0.9418862909078598, Final Batch Loss: 0.2279098480939865\n",
      "Epoch 2829, Loss: 1.3211694955825806, Final Batch Loss: 0.43173569440841675\n",
      "Epoch 2830, Loss: 1.0515467524528503, Final Batch Loss: 0.22191640734672546\n",
      "Epoch 2831, Loss: 1.0760123133659363, Final Batch Loss: 0.23270463943481445\n",
      "Epoch 2832, Loss: 1.1001903414726257, Final Batch Loss: 0.26988574862480164\n",
      "Epoch 2833, Loss: 1.1349251121282578, Final Batch Loss: 0.22264115512371063\n",
      "Epoch 2834, Loss: 1.1788249909877777, Final Batch Loss: 0.2674279510974884\n",
      "Epoch 2835, Loss: 1.1695251613855362, Final Batch Loss: 0.28726527094841003\n",
      "Epoch 2836, Loss: 1.2449171394109726, Final Batch Loss: 0.31445595622062683\n",
      "Epoch 2837, Loss: 1.1834419965744019, Final Batch Loss: 0.2986520528793335\n",
      "Epoch 2838, Loss: 1.1436395049095154, Final Batch Loss: 0.2988464832305908\n",
      "Epoch 2839, Loss: 1.0923393964767456, Final Batch Loss: 0.18711072206497192\n",
      "Epoch 2840, Loss: 1.1617730855941772, Final Batch Loss: 0.2720361649990082\n",
      "Epoch 2841, Loss: 1.0996315032243729, Final Batch Loss: 0.23928870260715485\n",
      "Epoch 2842, Loss: 0.9973066449165344, Final Batch Loss: 0.204659104347229\n",
      "Epoch 2843, Loss: 1.1705803722143173, Final Batch Loss: 0.23590438067913055\n",
      "Epoch 2844, Loss: 1.1301606744527817, Final Batch Loss: 0.25267642736434937\n",
      "Epoch 2845, Loss: 1.176010623574257, Final Batch Loss: 0.14661715924739838\n",
      "Epoch 2846, Loss: 1.2324420362710953, Final Batch Loss: 0.3145361542701721\n",
      "Epoch 2847, Loss: 1.2820908725261688, Final Batch Loss: 0.29801738262176514\n",
      "Epoch 2848, Loss: 1.0708038657903671, Final Batch Loss: 0.2685230076313019\n",
      "Epoch 2849, Loss: 1.1220165342092514, Final Batch Loss: 0.25109055638313293\n",
      "Epoch 2850, Loss: 1.2015823721885681, Final Batch Loss: 0.36985448002815247\n",
      "Epoch 2851, Loss: 1.1052947789430618, Final Batch Loss: 0.2995908558368683\n",
      "Epoch 2852, Loss: 1.01787568628788, Final Batch Loss: 0.2536986768245697\n",
      "Epoch 2853, Loss: 1.075008749961853, Final Batch Loss: 0.3090018033981323\n",
      "Epoch 2854, Loss: 1.0871776193380356, Final Batch Loss: 0.29777687788009644\n",
      "Epoch 2855, Loss: 1.228281393647194, Final Batch Loss: 0.4529634118080139\n",
      "Epoch 2856, Loss: 1.204799473285675, Final Batch Loss: 0.3609476089477539\n",
      "Epoch 2857, Loss: 1.174532264471054, Final Batch Loss: 0.32320839166641235\n",
      "Epoch 2858, Loss: 1.2017408311367035, Final Batch Loss: 0.3157815635204315\n",
      "Epoch 2859, Loss: 1.157368689775467, Final Batch Loss: 0.2916347086429596\n",
      "Epoch 2860, Loss: 1.2499358355998993, Final Batch Loss: 0.33727821707725525\n",
      "Epoch 2861, Loss: 1.1181319504976273, Final Batch Loss: 0.3440167307853699\n",
      "Epoch 2862, Loss: 1.0486388802528381, Final Batch Loss: 0.17525151371955872\n",
      "Epoch 2863, Loss: 1.212355598807335, Final Batch Loss: 0.3164852261543274\n",
      "Epoch 2864, Loss: 1.137632504105568, Final Batch Loss: 0.2222752720117569\n",
      "Epoch 2865, Loss: 1.1158588528633118, Final Batch Loss: 0.365133136510849\n",
      "Epoch 2866, Loss: 1.2401503026485443, Final Batch Loss: 0.35115352272987366\n",
      "Epoch 2867, Loss: 1.0703753232955933, Final Batch Loss: 0.27616870403289795\n",
      "Epoch 2868, Loss: 1.0763508081436157, Final Batch Loss: 0.2581257224082947\n",
      "Epoch 2869, Loss: 1.2046579122543335, Final Batch Loss: 0.3284120559692383\n",
      "Epoch 2870, Loss: 1.2333350479602814, Final Batch Loss: 0.340980589389801\n",
      "Epoch 2871, Loss: 1.1192271411418915, Final Batch Loss: 0.2843034565448761\n",
      "Epoch 2872, Loss: 1.0146571099758148, Final Batch Loss: 0.20214322209358215\n",
      "Epoch 2873, Loss: 1.064526528120041, Final Batch Loss: 0.2719954550266266\n",
      "Epoch 2874, Loss: 1.2301989495754242, Final Batch Loss: 0.43880438804626465\n",
      "Epoch 2875, Loss: 1.1093033850193024, Final Batch Loss: 0.27244821190834045\n",
      "Epoch 2876, Loss: 1.0715742260217667, Final Batch Loss: 0.26907971501350403\n",
      "Epoch 2877, Loss: 1.062149167060852, Final Batch Loss: 0.24710002541542053\n",
      "Epoch 2878, Loss: 1.1568272113800049, Final Batch Loss: 0.25789791345596313\n",
      "Epoch 2879, Loss: 1.2240165024995804, Final Batch Loss: 0.24710793793201447\n",
      "Epoch 2880, Loss: 1.1753765642642975, Final Batch Loss: 0.28835511207580566\n",
      "Epoch 2881, Loss: 1.2090274691581726, Final Batch Loss: 0.3568068742752075\n",
      "Epoch 2882, Loss: 1.2373642027378082, Final Batch Loss: 0.3059545159339905\n",
      "Epoch 2883, Loss: 1.060465857386589, Final Batch Loss: 0.2726011872291565\n",
      "Epoch 2884, Loss: 1.0692593455314636, Final Batch Loss: 0.23671090602874756\n",
      "Epoch 2885, Loss: 1.0605343282222748, Final Batch Loss: 0.23821702599525452\n",
      "Epoch 2886, Loss: 1.2106778919696808, Final Batch Loss: 0.277971088886261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2887, Loss: 1.174377292394638, Final Batch Loss: 0.22269850969314575\n",
      "Epoch 2888, Loss: 1.0598584115505219, Final Batch Loss: 0.2996107041835785\n",
      "Epoch 2889, Loss: 1.1376468688249588, Final Batch Loss: 0.2483811229467392\n",
      "Epoch 2890, Loss: 1.119325891137123, Final Batch Loss: 0.22847308218479156\n",
      "Epoch 2891, Loss: 1.1436658054590225, Final Batch Loss: 0.21078099310398102\n",
      "Epoch 2892, Loss: 1.0307065546512604, Final Batch Loss: 0.19837306439876556\n",
      "Epoch 2893, Loss: 1.135464921593666, Final Batch Loss: 0.3467690050601959\n",
      "Epoch 2894, Loss: 1.177794948220253, Final Batch Loss: 0.296916663646698\n",
      "Epoch 2895, Loss: 1.104119747877121, Final Batch Loss: 0.29060178995132446\n",
      "Epoch 2896, Loss: 1.0194411724805832, Final Batch Loss: 0.22550000250339508\n",
      "Epoch 2897, Loss: 1.2137086987495422, Final Batch Loss: 0.30519434809684753\n",
      "Epoch 2898, Loss: 1.1189674586057663, Final Batch Loss: 0.3014431595802307\n",
      "Epoch 2899, Loss: 1.018336996436119, Final Batch Loss: 0.21074318885803223\n",
      "Epoch 2900, Loss: 1.0693448930978775, Final Batch Loss: 0.25817108154296875\n",
      "Epoch 2901, Loss: 1.0856146663427353, Final Batch Loss: 0.2660438120365143\n",
      "Epoch 2902, Loss: 1.3031388223171234, Final Batch Loss: 0.3767491281032562\n",
      "Epoch 2903, Loss: 1.3040017932653427, Final Batch Loss: 0.4961789846420288\n",
      "Epoch 2904, Loss: 1.1911748349666595, Final Batch Loss: 0.24986320734024048\n",
      "Epoch 2905, Loss: 1.0385797172784805, Final Batch Loss: 0.20639336109161377\n",
      "Epoch 2906, Loss: 1.0246884673833847, Final Batch Loss: 0.19973225891590118\n",
      "Epoch 2907, Loss: 1.2401500344276428, Final Batch Loss: 0.3956630229949951\n",
      "Epoch 2908, Loss: 1.0365219116210938, Final Batch Loss: 0.2756541967391968\n",
      "Epoch 2909, Loss: 1.1081999242305756, Final Batch Loss: 0.28996190428733826\n",
      "Epoch 2910, Loss: 1.0788105726242065, Final Batch Loss: 0.29848551750183105\n",
      "Epoch 2911, Loss: 1.020369365811348, Final Batch Loss: 0.22014595568180084\n",
      "Epoch 2912, Loss: 1.1216575801372528, Final Batch Loss: 0.3851621150970459\n",
      "Epoch 2913, Loss: 1.0802201479673386, Final Batch Loss: 0.21227246522903442\n",
      "Epoch 2914, Loss: 1.1239396631717682, Final Batch Loss: 0.3024512827396393\n",
      "Epoch 2915, Loss: 1.0722522884607315, Final Batch Loss: 0.24615377187728882\n",
      "Epoch 2916, Loss: 1.17840176820755, Final Batch Loss: 0.24720484018325806\n",
      "Epoch 2917, Loss: 1.0838421732187271, Final Batch Loss: 0.3168196380138397\n",
      "Epoch 2918, Loss: 1.03282929956913, Final Batch Loss: 0.14975543320178986\n",
      "Epoch 2919, Loss: 1.098485752940178, Final Batch Loss: 0.27187681198120117\n",
      "Epoch 2920, Loss: 1.1791865080595016, Final Batch Loss: 0.24783955514431\n",
      "Epoch 2921, Loss: 1.0623307526111603, Final Batch Loss: 0.200008362531662\n",
      "Epoch 2922, Loss: 1.004277914762497, Final Batch Loss: 0.2613770365715027\n",
      "Epoch 2923, Loss: 1.3025240898132324, Final Batch Loss: 0.38777974247932434\n",
      "Epoch 2924, Loss: 1.0456844419240952, Final Batch Loss: 0.29967552423477173\n",
      "Epoch 2925, Loss: 1.0581316351890564, Final Batch Loss: 0.3568764328956604\n",
      "Epoch 2926, Loss: 1.109652653336525, Final Batch Loss: 0.31618720293045044\n",
      "Epoch 2927, Loss: 1.1254681050777435, Final Batch Loss: 0.3095434606075287\n",
      "Epoch 2928, Loss: 1.1628944873809814, Final Batch Loss: 0.34607645869255066\n",
      "Epoch 2929, Loss: 1.0679581612348557, Final Batch Loss: 0.2563171684741974\n",
      "Epoch 2930, Loss: 1.1951731145381927, Final Batch Loss: 0.3248077630996704\n",
      "Epoch 2931, Loss: 1.1579826176166534, Final Batch Loss: 0.3622296154499054\n",
      "Epoch 2932, Loss: 1.0586464554071426, Final Batch Loss: 0.2801326513290405\n",
      "Epoch 2933, Loss: 1.0429406315088272, Final Batch Loss: 0.2928014397621155\n",
      "Epoch 2934, Loss: 1.039732038974762, Final Batch Loss: 0.2426859438419342\n",
      "Epoch 2935, Loss: 1.0723943561315536, Final Batch Loss: 0.24449454247951508\n",
      "Epoch 2936, Loss: 1.0775265395641327, Final Batch Loss: 0.19795411825180054\n",
      "Epoch 2937, Loss: 1.2263509631156921, Final Batch Loss: 0.2982262074947357\n",
      "Epoch 2938, Loss: 1.2111850827932358, Final Batch Loss: 0.38144221901893616\n",
      "Epoch 2939, Loss: 1.2471637725830078, Final Batch Loss: 0.30814042687416077\n",
      "Epoch 2940, Loss: 1.0566385090351105, Final Batch Loss: 0.2692752182483673\n",
      "Epoch 2941, Loss: 1.0309254378080368, Final Batch Loss: 0.22497506439685822\n",
      "Epoch 2942, Loss: 1.1444286555051804, Final Batch Loss: 0.30161747336387634\n",
      "Epoch 2943, Loss: 1.030263751745224, Final Batch Loss: 0.2737842798233032\n",
      "Epoch 2944, Loss: 1.1690763980150223, Final Batch Loss: 0.3730319142341614\n",
      "Epoch 2945, Loss: 1.1256017237901688, Final Batch Loss: 0.23299233615398407\n",
      "Epoch 2946, Loss: 1.1287221312522888, Final Batch Loss: 0.27490347623825073\n",
      "Epoch 2947, Loss: 1.3349341750144958, Final Batch Loss: 0.44873949885368347\n",
      "Epoch 2948, Loss: 1.137419953942299, Final Batch Loss: 0.29981186985969543\n",
      "Epoch 2949, Loss: 1.0486471503973007, Final Batch Loss: 0.21268562972545624\n",
      "Epoch 2950, Loss: 1.0060810446739197, Final Batch Loss: 0.205523282289505\n",
      "Epoch 2951, Loss: 1.050118312239647, Final Batch Loss: 0.27514249086380005\n",
      "Epoch 2952, Loss: 1.1594484150409698, Final Batch Loss: 0.3961452543735504\n",
      "Epoch 2953, Loss: 1.111979454755783, Final Batch Loss: 0.2532607316970825\n",
      "Epoch 2954, Loss: 1.146762728691101, Final Batch Loss: 0.24472248554229736\n",
      "Epoch 2955, Loss: 1.2649911046028137, Final Batch Loss: 0.31075623631477356\n",
      "Epoch 2956, Loss: 1.1418204009532928, Final Batch Loss: 0.2766511142253876\n",
      "Epoch 2957, Loss: 1.0765768736600876, Final Batch Loss: 0.287159264087677\n",
      "Epoch 2958, Loss: 1.1512953639030457, Final Batch Loss: 0.28058016300201416\n",
      "Epoch 2959, Loss: 1.0351150035858154, Final Batch Loss: 0.20811089873313904\n",
      "Epoch 2960, Loss: 1.0269580632448196, Final Batch Loss: 0.22092552483081818\n",
      "Epoch 2961, Loss: 1.170027568936348, Final Batch Loss: 0.32800400257110596\n",
      "Epoch 2962, Loss: 1.1077168732881546, Final Batch Loss: 0.2607917785644531\n",
      "Epoch 2963, Loss: 1.2648876756429672, Final Batch Loss: 0.36024636030197144\n",
      "Epoch 2964, Loss: 0.9897550195455551, Final Batch Loss: 0.3351500630378723\n",
      "Epoch 2965, Loss: 1.1388332396745682, Final Batch Loss: 0.19909070432186127\n",
      "Epoch 2966, Loss: 1.3401087522506714, Final Batch Loss: 0.40463197231292725\n",
      "Epoch 2967, Loss: 0.96470145881176, Final Batch Loss: 0.1390833705663681\n",
      "Epoch 2968, Loss: 1.100280910730362, Final Batch Loss: 0.30585432052612305\n",
      "Epoch 2969, Loss: 1.0102059990167618, Final Batch Loss: 0.25610682368278503\n",
      "Epoch 2970, Loss: 1.1254608929157257, Final Batch Loss: 0.30033251643180847\n",
      "Epoch 2971, Loss: 1.232103854417801, Final Batch Loss: 0.3922472894191742\n",
      "Epoch 2972, Loss: 1.1271799355745316, Final Batch Loss: 0.31345799565315247\n",
      "Epoch 2973, Loss: 1.1896821856498718, Final Batch Loss: 0.2741800844669342\n",
      "Epoch 2974, Loss: 0.9673048406839371, Final Batch Loss: 0.21792805194854736\n",
      "Epoch 2975, Loss: 1.1531473398208618, Final Batch Loss: 0.23160916566848755\n",
      "Epoch 2976, Loss: 1.0616829693317413, Final Batch Loss: 0.28415510058403015\n",
      "Epoch 2977, Loss: 1.2020287662744522, Final Batch Loss: 0.3516412079334259\n",
      "Epoch 2978, Loss: 1.2293216288089752, Final Batch Loss: 0.4121639132499695\n",
      "Epoch 2979, Loss: 1.1787076592445374, Final Batch Loss: 0.2564835846424103\n",
      "Epoch 2980, Loss: 1.102567046880722, Final Batch Loss: 0.3356468379497528\n",
      "Epoch 2981, Loss: 1.0242904871702194, Final Batch Loss: 0.25044456124305725\n",
      "Epoch 2982, Loss: 1.0659365504980087, Final Batch Loss: 0.19357728958129883\n",
      "Epoch 2983, Loss: 1.2266277372837067, Final Batch Loss: 0.3465946912765503\n",
      "Epoch 2984, Loss: 1.1306068152189255, Final Batch Loss: 0.1748064011335373\n",
      "Epoch 2985, Loss: 1.2274166494607925, Final Batch Loss: 0.4334409534931183\n",
      "Epoch 2986, Loss: 1.2367900907993317, Final Batch Loss: 0.28933799266815186\n",
      "Epoch 2987, Loss: 1.181711345911026, Final Batch Loss: 0.27112722396850586\n",
      "Epoch 2988, Loss: 1.2201518714427948, Final Batch Loss: 0.25593286752700806\n",
      "Epoch 2989, Loss: 1.1738065332174301, Final Batch Loss: 0.3601577579975128\n",
      "Epoch 2990, Loss: 1.1357807517051697, Final Batch Loss: 0.26594385504722595\n",
      "Epoch 2991, Loss: 1.2915555834770203, Final Batch Loss: 0.42425230145454407\n",
      "Epoch 2992, Loss: 1.1290810257196426, Final Batch Loss: 0.2568694055080414\n",
      "Epoch 2993, Loss: 1.223955750465393, Final Batch Loss: 0.3263213634490967\n",
      "Epoch 2994, Loss: 1.1196993738412857, Final Batch Loss: 0.1946948915719986\n",
      "Epoch 2995, Loss: 1.219659224152565, Final Batch Loss: 0.3545886278152466\n",
      "Epoch 2996, Loss: 1.1035482585430145, Final Batch Loss: 0.26096758246421814\n",
      "Epoch 2997, Loss: 1.024079367518425, Final Batch Loss: 0.20940381288528442\n",
      "Epoch 2998, Loss: 1.1516677141189575, Final Batch Loss: 0.22979280352592468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2999, Loss: 1.159523367881775, Final Batch Loss: 0.2621549963951111\n",
      "Epoch 3000, Loss: 1.0479562431573868, Final Batch Loss: 0.18522988259792328\n",
      "Epoch 3001, Loss: 1.1095911115407944, Final Batch Loss: 0.30409666895866394\n",
      "Epoch 3002, Loss: 1.1727180480957031, Final Batch Loss: 0.26906639337539673\n",
      "Epoch 3003, Loss: 1.2235379368066788, Final Batch Loss: 0.20254339277744293\n",
      "Epoch 3004, Loss: 1.0471994876861572, Final Batch Loss: 0.22334617376327515\n",
      "Epoch 3005, Loss: 1.183687001466751, Final Batch Loss: 0.3764597177505493\n",
      "Epoch 3006, Loss: 1.1422161161899567, Final Batch Loss: 0.284706175327301\n",
      "Epoch 3007, Loss: 1.262190043926239, Final Batch Loss: 0.3754066228866577\n",
      "Epoch 3008, Loss: 1.2613948583602905, Final Batch Loss: 0.33208614587783813\n",
      "Epoch 3009, Loss: 1.0822861343622208, Final Batch Loss: 0.293753445148468\n",
      "Epoch 3010, Loss: 1.158934473991394, Final Batch Loss: 0.24103784561157227\n",
      "Epoch 3011, Loss: 1.1907652020454407, Final Batch Loss: 0.40793344378471375\n",
      "Epoch 3012, Loss: 0.9601207822561264, Final Batch Loss: 0.2080262005329132\n",
      "Epoch 3013, Loss: 1.11361625790596, Final Batch Loss: 0.2239718735218048\n",
      "Epoch 3014, Loss: 1.0859468579292297, Final Batch Loss: 0.29964712262153625\n",
      "Epoch 3015, Loss: 1.3011234998703003, Final Batch Loss: 0.4483312964439392\n",
      "Epoch 3016, Loss: 1.1826296299695969, Final Batch Loss: 0.3097708821296692\n",
      "Epoch 3017, Loss: 1.1888766437768936, Final Batch Loss: 0.24458922445774078\n",
      "Epoch 3018, Loss: 1.1149346977472305, Final Batch Loss: 0.2675565183162689\n",
      "Epoch 3019, Loss: 1.0234413743019104, Final Batch Loss: 0.2169358730316162\n",
      "Epoch 3020, Loss: 1.225953608751297, Final Batch Loss: 0.2313145399093628\n",
      "Epoch 3021, Loss: 1.1148279160261154, Final Batch Loss: 0.23790785670280457\n",
      "Epoch 3022, Loss: 1.2657314240932465, Final Batch Loss: 0.34704703092575073\n",
      "Epoch 3023, Loss: 1.286927193403244, Final Batch Loss: 0.42046254873275757\n",
      "Epoch 3024, Loss: 1.1407139897346497, Final Batch Loss: 0.29134461283683777\n",
      "Epoch 3025, Loss: 1.159533143043518, Final Batch Loss: 0.24853286147117615\n",
      "Epoch 3026, Loss: 1.1992312669754028, Final Batch Loss: 0.34050557017326355\n",
      "Epoch 3027, Loss: 1.090837001800537, Final Batch Loss: 0.284146785736084\n",
      "Epoch 3028, Loss: 1.195192277431488, Final Batch Loss: 0.3462115526199341\n",
      "Epoch 3029, Loss: 1.0728687345981598, Final Batch Loss: 0.20266452431678772\n",
      "Epoch 3030, Loss: 1.1183696240186691, Final Batch Loss: 0.25517284870147705\n",
      "Epoch 3031, Loss: 1.1517974734306335, Final Batch Loss: 0.24373134970664978\n",
      "Epoch 3032, Loss: 1.221617728471756, Final Batch Loss: 0.3246108293533325\n",
      "Epoch 3033, Loss: 1.1614553481340408, Final Batch Loss: 0.14825759828090668\n",
      "Epoch 3034, Loss: 1.124599203467369, Final Batch Loss: 0.28034162521362305\n",
      "Epoch 3035, Loss: 1.1041866838932037, Final Batch Loss: 0.280656099319458\n",
      "Epoch 3036, Loss: 1.0396625846624374, Final Batch Loss: 0.1704799085855484\n",
      "Epoch 3037, Loss: 1.235306203365326, Final Batch Loss: 0.3366914689540863\n",
      "Epoch 3038, Loss: 1.037146806716919, Final Batch Loss: 0.21467344462871552\n",
      "Epoch 3039, Loss: 1.1546774506568909, Final Batch Loss: 0.20861279964447021\n",
      "Epoch 3040, Loss: 1.0595235079526901, Final Batch Loss: 0.2743047773838043\n",
      "Epoch 3041, Loss: 1.073785811662674, Final Batch Loss: 0.16489921510219574\n",
      "Epoch 3042, Loss: 1.12164668738842, Final Batch Loss: 0.3545777499675751\n",
      "Epoch 3043, Loss: 1.072147622704506, Final Batch Loss: 0.20543532073497772\n",
      "Epoch 3044, Loss: 1.012941598892212, Final Batch Loss: 0.1992197334766388\n",
      "Epoch 3045, Loss: 1.0616076290607452, Final Batch Loss: 0.22808043658733368\n",
      "Epoch 3046, Loss: 1.1401892304420471, Final Batch Loss: 0.23933476209640503\n",
      "Epoch 3047, Loss: 1.0887673050165176, Final Batch Loss: 0.2345287948846817\n",
      "Epoch 3048, Loss: 1.2060211896896362, Final Batch Loss: 0.35900184512138367\n",
      "Epoch 3049, Loss: 1.1459740698337555, Final Batch Loss: 0.2831290662288666\n",
      "Epoch 3050, Loss: 1.3461454510688782, Final Batch Loss: 0.29624053835868835\n",
      "Epoch 3051, Loss: 1.0245687812566757, Final Batch Loss: 0.2960119843482971\n",
      "Epoch 3052, Loss: 1.0442965477705002, Final Batch Loss: 0.2156715989112854\n",
      "Epoch 3053, Loss: 1.2441884875297546, Final Batch Loss: 0.32422083616256714\n",
      "Epoch 3054, Loss: 1.0031683444976807, Final Batch Loss: 0.18292734026908875\n",
      "Epoch 3055, Loss: 1.0398476719856262, Final Batch Loss: 0.23660071194171906\n",
      "Epoch 3056, Loss: 1.1642809808254242, Final Batch Loss: 0.27335628867149353\n",
      "Epoch 3057, Loss: 1.2126782685518265, Final Batch Loss: 0.29136350750923157\n",
      "Epoch 3058, Loss: 1.081733301281929, Final Batch Loss: 0.1529945284128189\n",
      "Epoch 3059, Loss: 1.086963802576065, Final Batch Loss: 0.26241135597229004\n",
      "Epoch 3060, Loss: 0.9763642847537994, Final Batch Loss: 0.23546668887138367\n",
      "Epoch 3061, Loss: 1.239930346608162, Final Batch Loss: 0.3454650342464447\n",
      "Epoch 3062, Loss: 1.285490870475769, Final Batch Loss: 0.34777653217315674\n",
      "Epoch 3063, Loss: 1.0470027327537537, Final Batch Loss: 0.27637502551078796\n",
      "Epoch 3064, Loss: 1.2004484832286835, Final Batch Loss: 0.3678538203239441\n",
      "Epoch 3065, Loss: 1.0570878386497498, Final Batch Loss: 0.293609082698822\n",
      "Epoch 3066, Loss: 0.9751696437597275, Final Batch Loss: 0.17287595570087433\n",
      "Epoch 3067, Loss: 0.9949906766414642, Final Batch Loss: 0.22398528456687927\n",
      "Epoch 3068, Loss: 1.1669109612703323, Final Batch Loss: 0.3282261788845062\n",
      "Epoch 3069, Loss: 1.0673485100269318, Final Batch Loss: 0.3196670114994049\n",
      "Epoch 3070, Loss: 1.2392165064811707, Final Batch Loss: 0.36177223920822144\n",
      "Epoch 3071, Loss: 1.2192339599132538, Final Batch Loss: 0.291041761636734\n",
      "Epoch 3072, Loss: 1.0973671078681946, Final Batch Loss: 0.2605455219745636\n",
      "Epoch 3073, Loss: 1.1596842259168625, Final Batch Loss: 0.22750909626483917\n",
      "Epoch 3074, Loss: 1.0659451633691788, Final Batch Loss: 0.25635743141174316\n",
      "Epoch 3075, Loss: 1.0857830494642258, Final Batch Loss: 0.21990029513835907\n",
      "Epoch 3076, Loss: 1.2794499695301056, Final Batch Loss: 0.3142440617084503\n",
      "Epoch 3077, Loss: 1.142991989850998, Final Batch Loss: 0.3511348366737366\n",
      "Epoch 3078, Loss: 1.1485285311937332, Final Batch Loss: 0.36512431502342224\n",
      "Epoch 3079, Loss: 1.210298404097557, Final Batch Loss: 0.3395322561264038\n",
      "Epoch 3080, Loss: 1.2266597747802734, Final Batch Loss: 0.3159097731113434\n",
      "Epoch 3081, Loss: 1.1131533682346344, Final Batch Loss: 0.31050896644592285\n",
      "Epoch 3082, Loss: 1.0991269648075104, Final Batch Loss: 0.24293851852416992\n",
      "Epoch 3083, Loss: 1.1436718553304672, Final Batch Loss: 0.17465998232364655\n",
      "Epoch 3084, Loss: 1.170210525393486, Final Batch Loss: 0.21986739337444305\n",
      "Epoch 3085, Loss: 1.1150268614292145, Final Batch Loss: 0.2806529402732849\n",
      "Epoch 3086, Loss: 1.1087030470371246, Final Batch Loss: 0.3078606426715851\n",
      "Epoch 3087, Loss: 1.0639177858829498, Final Batch Loss: 0.21182337403297424\n",
      "Epoch 3088, Loss: 1.10732302069664, Final Batch Loss: 0.23725497722625732\n",
      "Epoch 3089, Loss: 0.9836598336696625, Final Batch Loss: 0.25455304980278015\n",
      "Epoch 3090, Loss: 1.053181305527687, Final Batch Loss: 0.1969950944185257\n",
      "Epoch 3091, Loss: 1.0787985175848007, Final Batch Loss: 0.25481924414634705\n",
      "Epoch 3092, Loss: 1.098351314663887, Final Batch Loss: 0.3445415794849396\n",
      "Epoch 3093, Loss: 1.10561141371727, Final Batch Loss: 0.28368496894836426\n",
      "Epoch 3094, Loss: 1.1030655205249786, Final Batch Loss: 0.3268084228038788\n",
      "Epoch 3095, Loss: 1.2036375999450684, Final Batch Loss: 0.2532103955745697\n",
      "Epoch 3096, Loss: 1.0299628376960754, Final Batch Loss: 0.17243333160877228\n",
      "Epoch 3097, Loss: 1.1093012541532516, Final Batch Loss: 0.339354932308197\n",
      "Epoch 3098, Loss: 1.052044816315174, Final Batch Loss: 0.10684395581483841\n",
      "Epoch 3099, Loss: 1.0111708045005798, Final Batch Loss: 0.261974573135376\n",
      "Epoch 3100, Loss: 1.050014391541481, Final Batch Loss: 0.20968465507030487\n",
      "Epoch 3101, Loss: 0.9933929741382599, Final Batch Loss: 0.1386396586894989\n",
      "Epoch 3102, Loss: 1.1117632687091827, Final Batch Loss: 0.2928161323070526\n",
      "Epoch 3103, Loss: 1.0434318333864212, Final Batch Loss: 0.27912628650665283\n",
      "Epoch 3104, Loss: 0.9865805357694626, Final Batch Loss: 0.15438300371170044\n",
      "Epoch 3105, Loss: 1.0627414733171463, Final Batch Loss: 0.24317888915538788\n",
      "Epoch 3106, Loss: 1.0787706673145294, Final Batch Loss: 0.29772451519966125\n",
      "Epoch 3107, Loss: 1.028758928179741, Final Batch Loss: 0.20952360332012177\n",
      "Epoch 3108, Loss: 1.1157380193471909, Final Batch Loss: 0.23978115618228912\n",
      "Epoch 3109, Loss: 0.9516159743070602, Final Batch Loss: 0.1738610714673996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3110, Loss: 1.0811837166547775, Final Batch Loss: 0.2959587275981903\n",
      "Epoch 3111, Loss: 1.118956670165062, Final Batch Loss: 0.3117487132549286\n",
      "Epoch 3112, Loss: 1.1271730661392212, Final Batch Loss: 0.30659887194633484\n",
      "Epoch 3113, Loss: 1.049407258629799, Final Batch Loss: 0.2651001214981079\n",
      "Epoch 3114, Loss: 1.0469010174274445, Final Batch Loss: 0.1812451183795929\n",
      "Epoch 3115, Loss: 0.9898478984832764, Final Batch Loss: 0.22440670430660248\n",
      "Epoch 3116, Loss: 1.0060373693704605, Final Batch Loss: 0.24543873965740204\n",
      "Epoch 3117, Loss: 1.0764173716306686, Final Batch Loss: 0.218808114528656\n",
      "Epoch 3118, Loss: 0.9895377457141876, Final Batch Loss: 0.2581665515899658\n",
      "Epoch 3119, Loss: 1.0842403769493103, Final Batch Loss: 0.2200324535369873\n",
      "Epoch 3120, Loss: 1.2591079771518707, Final Batch Loss: 0.31719645857810974\n",
      "Epoch 3121, Loss: 1.1364743262529373, Final Batch Loss: 0.2589525580406189\n",
      "Epoch 3122, Loss: 1.2216328978538513, Final Batch Loss: 0.3387303650379181\n",
      "Epoch 3123, Loss: 0.8773107975721359, Final Batch Loss: 0.19005773961544037\n",
      "Epoch 3124, Loss: 0.9518636763095856, Final Batch Loss: 0.20187698304653168\n",
      "Epoch 3125, Loss: 1.0154570490121841, Final Batch Loss: 0.22321490943431854\n",
      "Epoch 3126, Loss: 1.1614788174629211, Final Batch Loss: 0.3476870357990265\n",
      "Epoch 3127, Loss: 1.0987305492162704, Final Batch Loss: 0.1740937978029251\n",
      "Epoch 3128, Loss: 1.2218502014875412, Final Batch Loss: 0.38853561878204346\n",
      "Epoch 3129, Loss: 1.1694433838129044, Final Batch Loss: 0.3561211824417114\n",
      "Epoch 3130, Loss: 1.0029636174440384, Final Batch Loss: 0.213654562830925\n",
      "Epoch 3131, Loss: 0.9676560312509537, Final Batch Loss: 0.2341412454843521\n",
      "Epoch 3132, Loss: 0.9222659021615982, Final Batch Loss: 0.18006299436092377\n",
      "Epoch 3133, Loss: 1.1236382275819778, Final Batch Loss: 0.3781118392944336\n",
      "Epoch 3134, Loss: 1.0379771441221237, Final Batch Loss: 0.2144644409418106\n",
      "Epoch 3135, Loss: 1.220367044210434, Final Batch Loss: 0.3397976756095886\n",
      "Epoch 3136, Loss: 1.0630200505256653, Final Batch Loss: 0.2217341810464859\n",
      "Epoch 3137, Loss: 1.1707285791635513, Final Batch Loss: 0.22264547646045685\n",
      "Epoch 3138, Loss: 1.1333007663488388, Final Batch Loss: 0.3096853196620941\n",
      "Epoch 3139, Loss: 1.1318520903587341, Final Batch Loss: 0.36589115858078003\n",
      "Epoch 3140, Loss: 1.068543255329132, Final Batch Loss: 0.23256155848503113\n",
      "Epoch 3141, Loss: 1.0492272973060608, Final Batch Loss: 0.26533544063568115\n",
      "Epoch 3142, Loss: 1.0058004707098007, Final Batch Loss: 0.2680871784687042\n",
      "Epoch 3143, Loss: 1.107730433344841, Final Batch Loss: 0.3013874888420105\n",
      "Epoch 3144, Loss: 1.1913692206144333, Final Batch Loss: 0.43209001421928406\n",
      "Epoch 3145, Loss: 1.032195657491684, Final Batch Loss: 0.22386306524276733\n",
      "Epoch 3146, Loss: 1.20394966006279, Final Batch Loss: 0.3051793575286865\n",
      "Epoch 3147, Loss: 1.1287131905555725, Final Batch Loss: 0.26513996720314026\n",
      "Epoch 3148, Loss: 1.0658319294452667, Final Batch Loss: 0.26578065752983093\n",
      "Epoch 3149, Loss: 1.1608964055776596, Final Batch Loss: 0.23802001774311066\n",
      "Epoch 3150, Loss: 1.0660937428474426, Final Batch Loss: 0.251383900642395\n",
      "Epoch 3151, Loss: 1.106702983379364, Final Batch Loss: 0.26797667145729065\n",
      "Epoch 3152, Loss: 1.033443346619606, Final Batch Loss: 0.31432852149009705\n",
      "Epoch 3153, Loss: 1.0930380076169968, Final Batch Loss: 0.2789137661457062\n",
      "Epoch 3154, Loss: 1.1597219109535217, Final Batch Loss: 0.3168788552284241\n",
      "Epoch 3155, Loss: 1.1476026326417923, Final Batch Loss: 0.29844045639038086\n",
      "Epoch 3156, Loss: 1.168301373720169, Final Batch Loss: 0.33573853969573975\n",
      "Epoch 3157, Loss: 1.2235965132713318, Final Batch Loss: 0.27202680706977844\n",
      "Epoch 3158, Loss: 1.1978054642677307, Final Batch Loss: 0.29205504059791565\n",
      "Epoch 3159, Loss: 1.1063562035560608, Final Batch Loss: 0.2930905818939209\n",
      "Epoch 3160, Loss: 1.087504580616951, Final Batch Loss: 0.2325141578912735\n",
      "Epoch 3161, Loss: 1.1053176820278168, Final Batch Loss: 0.24929937720298767\n",
      "Epoch 3162, Loss: 1.144839346408844, Final Batch Loss: 0.1938559114933014\n",
      "Epoch 3163, Loss: 0.9899007827043533, Final Batch Loss: 0.2102082073688507\n",
      "Epoch 3164, Loss: 0.9404564052820206, Final Batch Loss: 0.1405572146177292\n",
      "Epoch 3165, Loss: 1.1306357085704803, Final Batch Loss: 0.2928604483604431\n",
      "Epoch 3166, Loss: 1.2733579277992249, Final Batch Loss: 0.35940465331077576\n",
      "Epoch 3167, Loss: 1.051044523715973, Final Batch Loss: 0.3094358742237091\n",
      "Epoch 3168, Loss: 1.02287158370018, Final Batch Loss: 0.2539677321910858\n",
      "Epoch 3169, Loss: 1.005111500620842, Final Batch Loss: 0.2904147803783417\n",
      "Epoch 3170, Loss: 1.2511721551418304, Final Batch Loss: 0.32337507605552673\n",
      "Epoch 3171, Loss: 1.1846583187580109, Final Batch Loss: 0.2586123049259186\n",
      "Epoch 3172, Loss: 1.1402369737625122, Final Batch Loss: 0.32479390501976013\n",
      "Epoch 3173, Loss: 1.091475173830986, Final Batch Loss: 0.27691471576690674\n",
      "Epoch 3174, Loss: 1.1366077661514282, Final Batch Loss: 0.2298230230808258\n",
      "Epoch 3175, Loss: 0.9538261592388153, Final Batch Loss: 0.24340659379959106\n",
      "Epoch 3176, Loss: 0.9677155464887619, Final Batch Loss: 0.24113725125789642\n",
      "Epoch 3177, Loss: 1.1300698071718216, Final Batch Loss: 0.3691360056400299\n",
      "Epoch 3178, Loss: 1.0218959897756577, Final Batch Loss: 0.2301975041627884\n",
      "Epoch 3179, Loss: 1.1950329095125198, Final Batch Loss: 0.41405755281448364\n",
      "Epoch 3180, Loss: 1.2058199644088745, Final Batch Loss: 0.3190370202064514\n",
      "Epoch 3181, Loss: 1.0427560657262802, Final Batch Loss: 0.25237563252449036\n",
      "Epoch 3182, Loss: 1.0540592521429062, Final Batch Loss: 0.3595409691333771\n",
      "Epoch 3183, Loss: 1.1300466656684875, Final Batch Loss: 0.30860981345176697\n",
      "Epoch 3184, Loss: 1.1538542211055756, Final Batch Loss: 0.4078180491924286\n",
      "Epoch 3185, Loss: 1.106890857219696, Final Batch Loss: 0.23082563281059265\n",
      "Epoch 3186, Loss: 1.1340802907943726, Final Batch Loss: 0.36762261390686035\n",
      "Epoch 3187, Loss: 1.257705181837082, Final Batch Loss: 0.31031015515327454\n",
      "Epoch 3188, Loss: 1.0296372026205063, Final Batch Loss: 0.2918887734413147\n",
      "Epoch 3189, Loss: 1.1131178587675095, Final Batch Loss: 0.2768727242946625\n",
      "Epoch 3190, Loss: 1.1461634039878845, Final Batch Loss: 0.23349615931510925\n",
      "Epoch 3191, Loss: 1.0007107853889465, Final Batch Loss: 0.2445959448814392\n",
      "Epoch 3192, Loss: 1.1543621718883514, Final Batch Loss: 0.31554949283599854\n",
      "Epoch 3193, Loss: 1.1069313436746597, Final Batch Loss: 0.27188485860824585\n",
      "Epoch 3194, Loss: 1.190432533621788, Final Batch Loss: 0.246976837515831\n",
      "Epoch 3195, Loss: 1.2065088748931885, Final Batch Loss: 0.34718284010887146\n",
      "Epoch 3196, Loss: 1.0911475867033005, Final Batch Loss: 0.3231382668018341\n",
      "Epoch 3197, Loss: 1.1385181099176407, Final Batch Loss: 0.36283260583877563\n",
      "Epoch 3198, Loss: 1.121293306350708, Final Batch Loss: 0.3226690888404846\n",
      "Epoch 3199, Loss: 1.2120171785354614, Final Batch Loss: 0.3393052816390991\n",
      "Epoch 3200, Loss: 1.011583372950554, Final Batch Loss: 0.24991145730018616\n",
      "Epoch 3201, Loss: 1.0943487137556076, Final Batch Loss: 0.30251890420913696\n",
      "Epoch 3202, Loss: 1.1124293506145477, Final Batch Loss: 0.2653837502002716\n",
      "Epoch 3203, Loss: 1.103072464466095, Final Batch Loss: 0.23000547289848328\n",
      "Epoch 3204, Loss: 1.0841945707798004, Final Batch Loss: 0.271217942237854\n",
      "Epoch 3205, Loss: 1.131944715976715, Final Batch Loss: 0.27310657501220703\n",
      "Epoch 3206, Loss: 1.0796669572591782, Final Batch Loss: 0.28628113865852356\n",
      "Epoch 3207, Loss: 1.2087988257408142, Final Batch Loss: 0.33956393599510193\n",
      "Epoch 3208, Loss: 1.0912002176046371, Final Batch Loss: 0.24980096518993378\n",
      "Epoch 3209, Loss: 1.0754945427179337, Final Batch Loss: 0.28544315695762634\n",
      "Epoch 3210, Loss: 1.1495488733053207, Final Batch Loss: 0.2528044581413269\n",
      "Epoch 3211, Loss: 1.1847190856933594, Final Batch Loss: 0.3675917088985443\n",
      "Epoch 3212, Loss: 1.1252641528844833, Final Batch Loss: 0.29245367646217346\n",
      "Epoch 3213, Loss: 0.985119417309761, Final Batch Loss: 0.22119389474391937\n",
      "Epoch 3214, Loss: 1.0433399528265, Final Batch Loss: 0.289538711309433\n",
      "Epoch 3215, Loss: 1.1573224514722824, Final Batch Loss: 0.3439243733882904\n",
      "Epoch 3216, Loss: 1.1946692168712616, Final Batch Loss: 0.3282596170902252\n",
      "Epoch 3217, Loss: 1.041170746088028, Final Batch Loss: 0.2741691470146179\n",
      "Epoch 3218, Loss: 1.0312906950712204, Final Batch Loss: 0.19291196763515472\n",
      "Epoch 3219, Loss: 1.0690216422080994, Final Batch Loss: 0.2745344936847687\n",
      "Epoch 3220, Loss: 1.0683979094028473, Final Batch Loss: 0.19728624820709229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3221, Loss: 1.111537367105484, Final Batch Loss: 0.30130115151405334\n",
      "Epoch 3222, Loss: 0.9775988757610321, Final Batch Loss: 0.19921351969242096\n",
      "Epoch 3223, Loss: 1.1895298510789871, Final Batch Loss: 0.22353507578372955\n",
      "Epoch 3224, Loss: 1.2443883568048477, Final Batch Loss: 0.35247164964675903\n",
      "Epoch 3225, Loss: 1.091391146183014, Final Batch Loss: 0.2190255969762802\n",
      "Epoch 3226, Loss: 1.1097998470067978, Final Batch Loss: 0.27097001671791077\n",
      "Epoch 3227, Loss: 1.1369581073522568, Final Batch Loss: 0.24986346065998077\n",
      "Epoch 3228, Loss: 1.0602528601884842, Final Batch Loss: 0.2659122943878174\n",
      "Epoch 3229, Loss: 1.0684048533439636, Final Batch Loss: 0.2889581322669983\n",
      "Epoch 3230, Loss: 1.0974237620830536, Final Batch Loss: 0.2530255913734436\n",
      "Epoch 3231, Loss: 1.0362514853477478, Final Batch Loss: 0.20939835906028748\n",
      "Epoch 3232, Loss: 1.1402107030153275, Final Batch Loss: 0.2485436052083969\n",
      "Epoch 3233, Loss: 1.2001719772815704, Final Batch Loss: 0.29142338037490845\n",
      "Epoch 3234, Loss: 1.178940087556839, Final Batch Loss: 0.2286086082458496\n",
      "Epoch 3235, Loss: 1.0725590586662292, Final Batch Loss: 0.25211814045906067\n",
      "Epoch 3236, Loss: 1.029385507106781, Final Batch Loss: 0.2927318215370178\n",
      "Epoch 3237, Loss: 1.1066414713859558, Final Batch Loss: 0.26312193274497986\n",
      "Epoch 3238, Loss: 1.2042228877544403, Final Batch Loss: 0.27074873447418213\n",
      "Epoch 3239, Loss: 0.9939185082912445, Final Batch Loss: 0.21382322907447815\n",
      "Epoch 3240, Loss: 1.0764987617731094, Final Batch Loss: 0.2833554148674011\n",
      "Epoch 3241, Loss: 1.1381158381700516, Final Batch Loss: 0.3547709584236145\n",
      "Epoch 3242, Loss: 1.1286962777376175, Final Batch Loss: 0.3169157803058624\n",
      "Epoch 3243, Loss: 1.1072378754615784, Final Batch Loss: 0.26968634128570557\n",
      "Epoch 3244, Loss: 1.1701486706733704, Final Batch Loss: 0.25575852394104004\n",
      "Epoch 3245, Loss: 1.0315423607826233, Final Batch Loss: 0.2696571946144104\n",
      "Epoch 3246, Loss: 1.022264301776886, Final Batch Loss: 0.23907415568828583\n",
      "Epoch 3247, Loss: 1.0613663345575333, Final Batch Loss: 0.23571588099002838\n",
      "Epoch 3248, Loss: 1.0746411681175232, Final Batch Loss: 0.3243958652019501\n",
      "Epoch 3249, Loss: 1.0921810865402222, Final Batch Loss: 0.2589232921600342\n",
      "Epoch 3250, Loss: 1.291105955839157, Final Batch Loss: 0.27939373254776\n",
      "Epoch 3251, Loss: 1.0524693429470062, Final Batch Loss: 0.2782292366027832\n",
      "Epoch 3252, Loss: 1.1743547022342682, Final Batch Loss: 0.203603595495224\n",
      "Epoch 3253, Loss: 1.0405562818050385, Final Batch Loss: 0.3251332938671112\n",
      "Epoch 3254, Loss: 1.0514811128377914, Final Batch Loss: 0.33787739276885986\n",
      "Epoch 3255, Loss: 1.1069238632917404, Final Batch Loss: 0.24401633441448212\n",
      "Epoch 3256, Loss: 1.0887294113636017, Final Batch Loss: 0.2766631245613098\n",
      "Epoch 3257, Loss: 0.9889024049043655, Final Batch Loss: 0.27319347858428955\n",
      "Epoch 3258, Loss: 1.139640748500824, Final Batch Loss: 0.2740824520587921\n",
      "Epoch 3259, Loss: 1.1031465381383896, Final Batch Loss: 0.2787037193775177\n",
      "Epoch 3260, Loss: 1.0608659833669662, Final Batch Loss: 0.3572043776512146\n",
      "Epoch 3261, Loss: 1.035354420542717, Final Batch Loss: 0.25825658440589905\n",
      "Epoch 3262, Loss: 1.146447166800499, Final Batch Loss: 0.32642674446105957\n",
      "Epoch 3263, Loss: 1.1404475420713425, Final Batch Loss: 0.3124789595603943\n",
      "Epoch 3264, Loss: 1.049518421292305, Final Batch Loss: 0.2732006907463074\n",
      "Epoch 3265, Loss: 1.1280719190835953, Final Batch Loss: 0.372285932302475\n",
      "Epoch 3266, Loss: 1.1312332600355148, Final Batch Loss: 0.280747652053833\n",
      "Epoch 3267, Loss: 1.2309216558933258, Final Batch Loss: 0.3564998209476471\n",
      "Epoch 3268, Loss: 0.9987823218107224, Final Batch Loss: 0.2344272881746292\n",
      "Epoch 3269, Loss: 1.0701715350151062, Final Batch Loss: 0.20736423134803772\n",
      "Epoch 3270, Loss: 1.2318415343761444, Final Batch Loss: 0.4044281840324402\n",
      "Epoch 3271, Loss: 1.0434496700763702, Final Batch Loss: 0.35584011673927307\n",
      "Epoch 3272, Loss: 0.961200475692749, Final Batch Loss: 0.20654258131980896\n",
      "Epoch 3273, Loss: 1.0878479480743408, Final Batch Loss: 0.2995624840259552\n",
      "Epoch 3274, Loss: 1.1581945568323135, Final Batch Loss: 0.32799771428108215\n",
      "Epoch 3275, Loss: 1.222595915198326, Final Batch Loss: 0.360940545797348\n",
      "Epoch 3276, Loss: 1.2638086676597595, Final Batch Loss: 0.3018586039543152\n",
      "Epoch 3277, Loss: 1.0975226163864136, Final Batch Loss: 0.2838854491710663\n",
      "Epoch 3278, Loss: 0.9336763024330139, Final Batch Loss: 0.2350510060787201\n",
      "Epoch 3279, Loss: 1.0135626941919327, Final Batch Loss: 0.2555551528930664\n",
      "Epoch 3280, Loss: 1.1781914830207825, Final Batch Loss: 0.3576448857784271\n",
      "Epoch 3281, Loss: 1.069028452038765, Final Batch Loss: 0.22554340958595276\n",
      "Epoch 3282, Loss: 1.156884491443634, Final Batch Loss: 0.36944207549095154\n",
      "Epoch 3283, Loss: 1.0307898670434952, Final Batch Loss: 0.2299814671278\n",
      "Epoch 3284, Loss: 1.1593234539031982, Final Batch Loss: 0.32750388979911804\n",
      "Epoch 3285, Loss: 0.9953553229570389, Final Batch Loss: 0.3002758324146271\n",
      "Epoch 3286, Loss: 1.0637766122817993, Final Batch Loss: 0.2507593631744385\n",
      "Epoch 3287, Loss: 1.1338030248880386, Final Batch Loss: 0.3303002417087555\n",
      "Epoch 3288, Loss: 1.0614436268806458, Final Batch Loss: 0.243917316198349\n",
      "Epoch 3289, Loss: 1.114278495311737, Final Batch Loss: 0.34774094820022583\n",
      "Epoch 3290, Loss: 1.012903243303299, Final Batch Loss: 0.2938518226146698\n",
      "Epoch 3291, Loss: 1.1232382953166962, Final Batch Loss: 0.27296778559684753\n",
      "Epoch 3292, Loss: 1.1650367379188538, Final Batch Loss: 0.2337774932384491\n",
      "Epoch 3293, Loss: 1.0224545001983643, Final Batch Loss: 0.20273327827453613\n",
      "Epoch 3294, Loss: 1.0461235344409943, Final Batch Loss: 0.2526945173740387\n",
      "Epoch 3295, Loss: 1.0632937550544739, Final Batch Loss: 0.2608080804347992\n",
      "Epoch 3296, Loss: 1.0055218935012817, Final Batch Loss: 0.22158893942832947\n",
      "Epoch 3297, Loss: 1.022937372326851, Final Batch Loss: 0.20583851635456085\n",
      "Epoch 3298, Loss: 1.1381738036870956, Final Batch Loss: 0.29553231596946716\n",
      "Epoch 3299, Loss: 1.2645940780639648, Final Batch Loss: 0.33042895793914795\n",
      "Epoch 3300, Loss: 0.9574085623025894, Final Batch Loss: 0.21939411759376526\n",
      "Epoch 3301, Loss: 1.1190969944000244, Final Batch Loss: 0.33574074506759644\n",
      "Epoch 3302, Loss: 1.1167998015880585, Final Batch Loss: 0.282504141330719\n",
      "Epoch 3303, Loss: 1.0673579275608063, Final Batch Loss: 0.2714864909648895\n",
      "Epoch 3304, Loss: 1.0448195934295654, Final Batch Loss: 0.24156925082206726\n",
      "Epoch 3305, Loss: 1.057167038321495, Final Batch Loss: 0.3014672100543976\n",
      "Epoch 3306, Loss: 1.1662455797195435, Final Batch Loss: 0.33112701773643494\n",
      "Epoch 3307, Loss: 0.8989309370517731, Final Batch Loss: 0.1856689304113388\n",
      "Epoch 3308, Loss: 1.1393064558506012, Final Batch Loss: 0.2512474060058594\n",
      "Epoch 3309, Loss: 1.2353149056434631, Final Batch Loss: 0.4327179491519928\n",
      "Epoch 3310, Loss: 1.040433093905449, Final Batch Loss: 0.2466997355222702\n",
      "Epoch 3311, Loss: 1.0422346889972687, Final Batch Loss: 0.3398696482181549\n",
      "Epoch 3312, Loss: 1.0220917910337448, Final Batch Loss: 0.269890695810318\n",
      "Epoch 3313, Loss: 0.9409695863723755, Final Batch Loss: 0.1585180163383484\n",
      "Epoch 3314, Loss: 1.0303415358066559, Final Batch Loss: 0.24988333880901337\n",
      "Epoch 3315, Loss: 1.217313289642334, Final Batch Loss: 0.3222111761569977\n",
      "Epoch 3316, Loss: 1.0607648342847824, Final Batch Loss: 0.1933608502149582\n",
      "Epoch 3317, Loss: 1.0820469558238983, Final Batch Loss: 0.2679024934768677\n",
      "Epoch 3318, Loss: 1.0146814435720444, Final Batch Loss: 0.19035880267620087\n",
      "Epoch 3319, Loss: 1.0632695257663727, Final Batch Loss: 0.22235503792762756\n",
      "Epoch 3320, Loss: 1.036489948630333, Final Batch Loss: 0.2350914031267166\n",
      "Epoch 3321, Loss: 0.9389372020959854, Final Batch Loss: 0.1897910088300705\n",
      "Epoch 3322, Loss: 1.0721354931592941, Final Batch Loss: 0.3155953586101532\n",
      "Epoch 3323, Loss: 1.0030891597270966, Final Batch Loss: 0.17721500992774963\n",
      "Epoch 3324, Loss: 1.1652929782867432, Final Batch Loss: 0.256620854139328\n",
      "Epoch 3325, Loss: 1.2055884897708893, Final Batch Loss: 0.3854004740715027\n",
      "Epoch 3326, Loss: 1.0692083835601807, Final Batch Loss: 0.3215283155441284\n",
      "Epoch 3327, Loss: 1.0748675614595413, Final Batch Loss: 0.23341085016727448\n",
      "Epoch 3328, Loss: 1.0021606087684631, Final Batch Loss: 0.15380319952964783\n",
      "Epoch 3329, Loss: 1.2095243632793427, Final Batch Loss: 0.2778208553791046\n",
      "Epoch 3330, Loss: 1.0785171389579773, Final Batch Loss: 0.20070603489875793\n",
      "Epoch 3331, Loss: 1.16834557056427, Final Batch Loss: 0.28366556763648987\n",
      "Epoch 3332, Loss: 1.0147017240524292, Final Batch Loss: 0.21929818391799927\n",
      "Epoch 3333, Loss: 1.0541485100984573, Final Batch Loss: 0.3436746597290039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3334, Loss: 1.1779350340366364, Final Batch Loss: 0.38459399342536926\n",
      "Epoch 3335, Loss: 1.1818965077400208, Final Batch Loss: 0.27200907468795776\n",
      "Epoch 3336, Loss: 1.2620670199394226, Final Batch Loss: 0.3508322238922119\n",
      "Epoch 3337, Loss: 1.1178057491779327, Final Batch Loss: 0.24903365969657898\n",
      "Epoch 3338, Loss: 1.1129017174243927, Final Batch Loss: 0.2905799448490143\n",
      "Epoch 3339, Loss: 1.1302050054073334, Final Batch Loss: 0.26494139432907104\n",
      "Epoch 3340, Loss: 1.0583632290363312, Final Batch Loss: 0.2006603479385376\n",
      "Epoch 3341, Loss: 1.0880535393953323, Final Batch Loss: 0.18380342423915863\n",
      "Epoch 3342, Loss: 1.0133379250764847, Final Batch Loss: 0.2754809260368347\n",
      "Epoch 3343, Loss: 1.088381975889206, Final Batch Loss: 0.28166109323501587\n",
      "Epoch 3344, Loss: 1.1051708906888962, Final Batch Loss: 0.25131040811538696\n",
      "Epoch 3345, Loss: 0.9530604332685471, Final Batch Loss: 0.22753529250621796\n",
      "Epoch 3346, Loss: 1.0641116201877594, Final Batch Loss: 0.23917493224143982\n",
      "Epoch 3347, Loss: 1.0107972621917725, Final Batch Loss: 0.30572059750556946\n",
      "Epoch 3348, Loss: 1.0588320642709732, Final Batch Loss: 0.30279541015625\n",
      "Epoch 3349, Loss: 1.0726497322320938, Final Batch Loss: 0.29623791575431824\n",
      "Epoch 3350, Loss: 1.038223683834076, Final Batch Loss: 0.262688547372818\n",
      "Epoch 3351, Loss: 1.2090802192687988, Final Batch Loss: 0.31237557530403137\n",
      "Epoch 3352, Loss: 1.141385555267334, Final Batch Loss: 0.3147619068622589\n",
      "Epoch 3353, Loss: 0.9828538745641708, Final Batch Loss: 0.22303947806358337\n",
      "Epoch 3354, Loss: 1.195616364479065, Final Batch Loss: 0.3022129237651825\n",
      "Epoch 3355, Loss: 1.022024467587471, Final Batch Loss: 0.2599855959415436\n",
      "Epoch 3356, Loss: 1.170113354921341, Final Batch Loss: 0.3428065776824951\n",
      "Epoch 3357, Loss: 0.9950020909309387, Final Batch Loss: 0.21415077149868011\n",
      "Epoch 3358, Loss: 1.0196192562580109, Final Batch Loss: 0.21398088335990906\n",
      "Epoch 3359, Loss: 0.993837907910347, Final Batch Loss: 0.3221658170223236\n",
      "Epoch 3360, Loss: 1.0018360167741776, Final Batch Loss: 0.29897865653038025\n",
      "Epoch 3361, Loss: 1.1172081232070923, Final Batch Loss: 0.2758793234825134\n",
      "Epoch 3362, Loss: 1.0749257504940033, Final Batch Loss: 0.24419912695884705\n",
      "Epoch 3363, Loss: 1.0054929852485657, Final Batch Loss: 0.30770304799079895\n",
      "Epoch 3364, Loss: 1.0637761801481247, Final Batch Loss: 0.2444961816072464\n",
      "Epoch 3365, Loss: 1.0383444130420685, Final Batch Loss: 0.21752366423606873\n",
      "Epoch 3366, Loss: 1.226473718881607, Final Batch Loss: 0.3275749087333679\n",
      "Epoch 3367, Loss: 1.0155067294836044, Final Batch Loss: 0.24922025203704834\n",
      "Epoch 3368, Loss: 0.9979919344186783, Final Batch Loss: 0.25338444113731384\n",
      "Epoch 3369, Loss: 1.0396843999624252, Final Batch Loss: 0.21784628927707672\n",
      "Epoch 3370, Loss: 1.1118919551372528, Final Batch Loss: 0.22150522470474243\n",
      "Epoch 3371, Loss: 1.0691160410642624, Final Batch Loss: 0.20392762124538422\n",
      "Epoch 3372, Loss: 0.8903715908527374, Final Batch Loss: 0.16226956248283386\n",
      "Epoch 3373, Loss: 1.1034830212593079, Final Batch Loss: 0.2493492215871811\n",
      "Epoch 3374, Loss: 0.9744155555963516, Final Batch Loss: 0.21230514347553253\n",
      "Epoch 3375, Loss: 1.220065876841545, Final Batch Loss: 0.32861781120300293\n",
      "Epoch 3376, Loss: 1.0427619218826294, Final Batch Loss: 0.245082288980484\n",
      "Epoch 3377, Loss: 1.0809615701436996, Final Batch Loss: 0.2088809460401535\n",
      "Epoch 3378, Loss: 1.0291502624750137, Final Batch Loss: 0.224198117852211\n",
      "Epoch 3379, Loss: 1.082476794719696, Final Batch Loss: 0.22778679430484772\n",
      "Epoch 3380, Loss: 1.235055387020111, Final Batch Loss: 0.3515344560146332\n",
      "Epoch 3381, Loss: 1.0487087070941925, Final Batch Loss: 0.18998318910598755\n",
      "Epoch 3382, Loss: 1.0161807090044022, Final Batch Loss: 0.221095472574234\n",
      "Epoch 3383, Loss: 1.1242179721593857, Final Batch Loss: 0.335947722196579\n",
      "Epoch 3384, Loss: 1.0845468789339066, Final Batch Loss: 0.2305067777633667\n",
      "Epoch 3385, Loss: 1.0716615617275238, Final Batch Loss: 0.278105229139328\n",
      "Epoch 3386, Loss: 0.9569759368896484, Final Batch Loss: 0.2771340012550354\n",
      "Epoch 3387, Loss: 1.1198717653751373, Final Batch Loss: 0.19110509753227234\n",
      "Epoch 3388, Loss: 1.0938019454479218, Final Batch Loss: 0.3364601135253906\n",
      "Epoch 3389, Loss: 1.0673104524612427, Final Batch Loss: 0.2317276895046234\n",
      "Epoch 3390, Loss: 0.9642224013805389, Final Batch Loss: 0.2386838048696518\n",
      "Epoch 3391, Loss: 1.0561982691287994, Final Batch Loss: 0.3031080961227417\n",
      "Epoch 3392, Loss: 1.035925716161728, Final Batch Loss: 0.25469499826431274\n",
      "Epoch 3393, Loss: 1.2048896551132202, Final Batch Loss: 0.23225238919258118\n",
      "Epoch 3394, Loss: 1.0852759182453156, Final Batch Loss: 0.2495088279247284\n",
      "Epoch 3395, Loss: 1.105614334344864, Final Batch Loss: 0.370920330286026\n",
      "Epoch 3396, Loss: 1.2056339979171753, Final Batch Loss: 0.2895016372203827\n",
      "Epoch 3397, Loss: 1.168757975101471, Final Batch Loss: 0.3593598008155823\n",
      "Epoch 3398, Loss: 1.0173895806074142, Final Batch Loss: 0.22383859753608704\n",
      "Epoch 3399, Loss: 1.099100574851036, Final Batch Loss: 0.313558429479599\n",
      "Epoch 3400, Loss: 1.0604050010442734, Final Batch Loss: 0.2797431945800781\n",
      "Epoch 3401, Loss: 1.184206783771515, Final Batch Loss: 0.3728582561016083\n",
      "Epoch 3402, Loss: 1.1316153407096863, Final Batch Loss: 0.26572707295417786\n",
      "Epoch 3403, Loss: 1.1273583322763443, Final Batch Loss: 0.34452804923057556\n",
      "Epoch 3404, Loss: 1.2458289861679077, Final Batch Loss: 0.3697679340839386\n",
      "Epoch 3405, Loss: 1.1050828993320465, Final Batch Loss: 0.2614791989326477\n",
      "Epoch 3406, Loss: 1.0958762466907501, Final Batch Loss: 0.25476107001304626\n",
      "Epoch 3407, Loss: 1.1545442640781403, Final Batch Loss: 0.3006070554256439\n",
      "Epoch 3408, Loss: 1.17606982588768, Final Batch Loss: 0.36629518866539\n",
      "Epoch 3409, Loss: 1.14809750020504, Final Batch Loss: 0.3386470079421997\n",
      "Epoch 3410, Loss: 1.1114546805620193, Final Batch Loss: 0.2836246192455292\n",
      "Epoch 3411, Loss: 1.123678594827652, Final Batch Loss: 0.2629116475582123\n",
      "Epoch 3412, Loss: 1.0569746643304825, Final Batch Loss: 0.2943311333656311\n",
      "Epoch 3413, Loss: 0.987642452120781, Final Batch Loss: 0.19381193816661835\n",
      "Epoch 3414, Loss: 1.1875679939985275, Final Batch Loss: 0.26770707964897156\n",
      "Epoch 3415, Loss: 1.1144611984491348, Final Batch Loss: 0.20592381060123444\n",
      "Epoch 3416, Loss: 1.077718362212181, Final Batch Loss: 0.25927773118019104\n",
      "Epoch 3417, Loss: 1.19558946788311, Final Batch Loss: 0.31372418999671936\n",
      "Epoch 3418, Loss: 1.07406784594059, Final Batch Loss: 0.22628283500671387\n",
      "Epoch 3419, Loss: 1.1643557697534561, Final Batch Loss: 0.21471278369426727\n",
      "Epoch 3420, Loss: 1.1180326044559479, Final Batch Loss: 0.3017410933971405\n",
      "Epoch 3421, Loss: 1.0860738456249237, Final Batch Loss: 0.32503485679626465\n",
      "Epoch 3422, Loss: 0.9891684204339981, Final Batch Loss: 0.242701455950737\n",
      "Epoch 3423, Loss: 1.0128304213285446, Final Batch Loss: 0.20266279578208923\n",
      "Epoch 3424, Loss: 1.016848310828209, Final Batch Loss: 0.14726348221302032\n",
      "Epoch 3425, Loss: 1.0020619928836823, Final Batch Loss: 0.2144046127796173\n",
      "Epoch 3426, Loss: 1.1920815706253052, Final Batch Loss: 0.3591352701187134\n",
      "Epoch 3427, Loss: 1.1283176839351654, Final Batch Loss: 0.25809600949287415\n",
      "Epoch 3428, Loss: 1.0999601632356644, Final Batch Loss: 0.3343580365180969\n",
      "Epoch 3429, Loss: 1.0247534960508347, Final Batch Loss: 0.23105601966381073\n",
      "Epoch 3430, Loss: 1.0976444780826569, Final Batch Loss: 0.26863470673561096\n",
      "Epoch 3431, Loss: 1.0807798206806183, Final Batch Loss: 0.25298455357551575\n",
      "Epoch 3432, Loss: 1.0231386423110962, Final Batch Loss: 0.2462884783744812\n",
      "Epoch 3433, Loss: 1.1743039786815643, Final Batch Loss: 0.31041809916496277\n",
      "Epoch 3434, Loss: 1.0242563635110855, Final Batch Loss: 0.25936180353164673\n",
      "Epoch 3435, Loss: 1.20082488656044, Final Batch Loss: 0.33023980259895325\n",
      "Epoch 3436, Loss: 1.0496302098035812, Final Batch Loss: 0.21919257938861847\n",
      "Epoch 3437, Loss: 1.093395173549652, Final Batch Loss: 0.3215335011482239\n",
      "Epoch 3438, Loss: 1.0397602915763855, Final Batch Loss: 0.21257565915584564\n",
      "Epoch 3439, Loss: 1.0174516290426254, Final Batch Loss: 0.259568989276886\n",
      "Epoch 3440, Loss: 0.9252877533435822, Final Batch Loss: 0.15949295461177826\n",
      "Epoch 3441, Loss: 1.0775552988052368, Final Batch Loss: 0.23569652438163757\n",
      "Epoch 3442, Loss: 1.098891094326973, Final Batch Loss: 0.33188554644584656\n",
      "Epoch 3443, Loss: 1.1679034233093262, Final Batch Loss: 0.30187082290649414\n",
      "Epoch 3444, Loss: 1.0686764270067215, Final Batch Loss: 0.1988522857427597\n",
      "Epoch 3445, Loss: 1.0479534566402435, Final Batch Loss: 0.29510241746902466\n",
      "Epoch 3446, Loss: 1.16962131857872, Final Batch Loss: 0.21303051710128784\n",
      "Epoch 3447, Loss: 1.1122139245271683, Final Batch Loss: 0.30817368626594543\n",
      "Epoch 3448, Loss: 1.1239182502031326, Final Batch Loss: 0.2833184003829956\n",
      "Epoch 3449, Loss: 0.9941057711839676, Final Batch Loss: 0.23836363852024078\n",
      "Epoch 3450, Loss: 1.0474345535039902, Final Batch Loss: 0.19507244229316711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3451, Loss: 1.1721470355987549, Final Batch Loss: 0.32132354378700256\n",
      "Epoch 3452, Loss: 1.1188537776470184, Final Batch Loss: 0.3274762034416199\n",
      "Epoch 3453, Loss: 0.9747375845909119, Final Batch Loss: 0.24404878914356232\n",
      "Epoch 3454, Loss: 1.2368693053722382, Final Batch Loss: 0.3369899392127991\n",
      "Epoch 3455, Loss: 1.0928012430667877, Final Batch Loss: 0.2937893569469452\n",
      "Epoch 3456, Loss: 0.9607641100883484, Final Batch Loss: 0.19776363670825958\n",
      "Epoch 3457, Loss: 0.9911129623651505, Final Batch Loss: 0.30088886618614197\n",
      "Epoch 3458, Loss: 1.2540198862552643, Final Batch Loss: 0.4129513204097748\n",
      "Epoch 3459, Loss: 0.94658562541008, Final Batch Loss: 0.20283836126327515\n",
      "Epoch 3460, Loss: 1.0197023749351501, Final Batch Loss: 0.1844107061624527\n",
      "Epoch 3461, Loss: 1.2285424172878265, Final Batch Loss: 0.32333213090896606\n",
      "Epoch 3462, Loss: 1.0219074338674545, Final Batch Loss: 0.22482164204120636\n",
      "Epoch 3463, Loss: 1.0762450248003006, Final Batch Loss: 0.30422642827033997\n",
      "Epoch 3464, Loss: 1.1178456097841263, Final Batch Loss: 0.32123106718063354\n",
      "Epoch 3465, Loss: 1.1621384918689728, Final Batch Loss: 0.31761375069618225\n",
      "Epoch 3466, Loss: 0.9643764346837997, Final Batch Loss: 0.15758006274700165\n",
      "Epoch 3467, Loss: 1.0403886884450912, Final Batch Loss: 0.20034585893154144\n",
      "Epoch 3468, Loss: 0.8591223508119583, Final Batch Loss: 0.17607803642749786\n",
      "Epoch 3469, Loss: 1.019492506980896, Final Batch Loss: 0.25346723198890686\n",
      "Epoch 3470, Loss: 1.1950941979885101, Final Batch Loss: 0.26960861682891846\n",
      "Epoch 3471, Loss: 1.0578675866127014, Final Batch Loss: 0.21035698056221008\n",
      "Epoch 3472, Loss: 1.1066456884145737, Final Batch Loss: 0.2520393431186676\n",
      "Epoch 3473, Loss: 0.9311761260032654, Final Batch Loss: 0.17323347926139832\n",
      "Epoch 3474, Loss: 1.155598595738411, Final Batch Loss: 0.2927092909812927\n",
      "Epoch 3475, Loss: 1.0634531527757645, Final Batch Loss: 0.2931665778160095\n",
      "Epoch 3476, Loss: 1.3085274696350098, Final Batch Loss: 0.34528475999832153\n",
      "Epoch 3477, Loss: 1.1285606622695923, Final Batch Loss: 0.20716014504432678\n",
      "Epoch 3478, Loss: 0.996541440486908, Final Batch Loss: 0.1815699189901352\n",
      "Epoch 3479, Loss: 1.3032171726226807, Final Batch Loss: 0.4120042622089386\n",
      "Epoch 3480, Loss: 1.1634348630905151, Final Batch Loss: 0.3572588264942169\n",
      "Epoch 3481, Loss: 1.051381915807724, Final Batch Loss: 0.28615808486938477\n",
      "Epoch 3482, Loss: 1.0266945213079453, Final Batch Loss: 0.26680460572242737\n",
      "Epoch 3483, Loss: 0.9366652071475983, Final Batch Loss: 0.2534347176551819\n",
      "Epoch 3484, Loss: 0.9704299569129944, Final Batch Loss: 0.2534417510032654\n",
      "Epoch 3485, Loss: 1.2409355342388153, Final Batch Loss: 0.27978548407554626\n",
      "Epoch 3486, Loss: 1.2436012923717499, Final Batch Loss: 0.34846606850624084\n",
      "Epoch 3487, Loss: 1.0493720918893814, Final Batch Loss: 0.2521618604660034\n",
      "Epoch 3488, Loss: 1.021836131811142, Final Batch Loss: 0.25802820920944214\n",
      "Epoch 3489, Loss: 1.027753323316574, Final Batch Loss: 0.24443082511425018\n",
      "Epoch 3490, Loss: 1.0221389681100845, Final Batch Loss: 0.18711715936660767\n",
      "Epoch 3491, Loss: 1.0561925768852234, Final Batch Loss: 0.24061764776706696\n",
      "Epoch 3492, Loss: 1.1171286404132843, Final Batch Loss: 0.26359108090400696\n",
      "Epoch 3493, Loss: 1.0321611016988754, Final Batch Loss: 0.30992063879966736\n",
      "Epoch 3494, Loss: 1.1878823935985565, Final Batch Loss: 0.3654656410217285\n",
      "Epoch 3495, Loss: 1.0647872239351273, Final Batch Loss: 0.20754830539226532\n",
      "Epoch 3496, Loss: 1.1319260597229004, Final Batch Loss: 0.2926240861415863\n",
      "Epoch 3497, Loss: 1.0897067785263062, Final Batch Loss: 0.24714350700378418\n",
      "Epoch 3498, Loss: 1.1822690814733505, Final Batch Loss: 0.3368314206600189\n",
      "Epoch 3499, Loss: 1.02157624065876, Final Batch Loss: 0.2729700803756714\n",
      "Epoch 3500, Loss: 1.0428495407104492, Final Batch Loss: 0.20197418332099915\n",
      "Epoch 3501, Loss: 1.2029263377189636, Final Batch Loss: 0.3889840543270111\n",
      "Epoch 3502, Loss: 0.9369121491909027, Final Batch Loss: 0.2026185840368271\n",
      "Epoch 3503, Loss: 0.9643088281154633, Final Batch Loss: 0.24998727440834045\n",
      "Epoch 3504, Loss: 0.989538237452507, Final Batch Loss: 0.2082446664571762\n",
      "Epoch 3505, Loss: 1.0372454077005386, Final Batch Loss: 0.21115772426128387\n",
      "Epoch 3506, Loss: 1.1225550025701523, Final Batch Loss: 0.3504609167575836\n",
      "Epoch 3507, Loss: 1.0393525213003159, Final Batch Loss: 0.20687136054039001\n",
      "Epoch 3508, Loss: 1.0465451627969742, Final Batch Loss: 0.2815203368663788\n",
      "Epoch 3509, Loss: 1.1391143202781677, Final Batch Loss: 0.3005692958831787\n",
      "Epoch 3510, Loss: 0.9960864931344986, Final Batch Loss: 0.1989494115114212\n",
      "Epoch 3511, Loss: 1.0435957610607147, Final Batch Loss: 0.23677203059196472\n",
      "Epoch 3512, Loss: 1.006168246269226, Final Batch Loss: 0.193634495139122\n",
      "Epoch 3513, Loss: 1.056253120303154, Final Batch Loss: 0.2269120067358017\n",
      "Epoch 3514, Loss: 0.9864754378795624, Final Batch Loss: 0.20637963712215424\n",
      "Epoch 3515, Loss: 1.0458973497152328, Final Batch Loss: 0.27069711685180664\n",
      "Epoch 3516, Loss: 1.052294299006462, Final Batch Loss: 0.31964266300201416\n",
      "Epoch 3517, Loss: 0.9478147774934769, Final Batch Loss: 0.14349626004695892\n",
      "Epoch 3518, Loss: 1.0481352508068085, Final Batch Loss: 0.31649690866470337\n",
      "Epoch 3519, Loss: 1.0984948575496674, Final Batch Loss: 0.2779079079627991\n",
      "Epoch 3520, Loss: 1.090607464313507, Final Batch Loss: 0.2398768961429596\n",
      "Epoch 3521, Loss: 1.1163983047008514, Final Batch Loss: 0.24476313591003418\n",
      "Epoch 3522, Loss: 1.0734591335058212, Final Batch Loss: 0.31337302923202515\n",
      "Epoch 3523, Loss: 1.0580767095088959, Final Batch Loss: 0.2842938005924225\n",
      "Epoch 3524, Loss: 0.991079106926918, Final Batch Loss: 0.24488744139671326\n",
      "Epoch 3525, Loss: 1.0443630665540695, Final Batch Loss: 0.22496397793293\n",
      "Epoch 3526, Loss: 1.030398190021515, Final Batch Loss: 0.2054593861103058\n",
      "Epoch 3527, Loss: 0.9466128796339035, Final Batch Loss: 0.19888357818126678\n",
      "Epoch 3528, Loss: 1.004946380853653, Final Batch Loss: 0.293113648891449\n",
      "Epoch 3529, Loss: 1.0460248440504074, Final Batch Loss: 0.22863540053367615\n",
      "Epoch 3530, Loss: 1.0886387676000595, Final Batch Loss: 0.3257623016834259\n",
      "Epoch 3531, Loss: 1.1232018321752548, Final Batch Loss: 0.23523031175136566\n",
      "Epoch 3532, Loss: 1.0594141781330109, Final Batch Loss: 0.28035688400268555\n",
      "Epoch 3533, Loss: 1.1024945825338364, Final Batch Loss: 0.37708693742752075\n",
      "Epoch 3534, Loss: 1.0140364468097687, Final Batch Loss: 0.32139459252357483\n",
      "Epoch 3535, Loss: 0.983845442533493, Final Batch Loss: 0.24124732613563538\n",
      "Epoch 3536, Loss: 1.0208745747804642, Final Batch Loss: 0.262239933013916\n",
      "Epoch 3537, Loss: 1.1776885986328125, Final Batch Loss: 0.4171103537082672\n",
      "Epoch 3538, Loss: 1.0358993113040924, Final Batch Loss: 0.2867699861526489\n",
      "Epoch 3539, Loss: 1.1332857757806778, Final Batch Loss: 0.33173108100891113\n",
      "Epoch 3540, Loss: 1.0687064230442047, Final Batch Loss: 0.28141266107559204\n",
      "Epoch 3541, Loss: 1.1609510034322739, Final Batch Loss: 0.41886675357818604\n",
      "Epoch 3542, Loss: 1.2136251628398895, Final Batch Loss: 0.3804166615009308\n",
      "Epoch 3543, Loss: 0.9431653171777725, Final Batch Loss: 0.2273637354373932\n",
      "Epoch 3544, Loss: 1.0888195931911469, Final Batch Loss: 0.34172871708869934\n",
      "Epoch 3545, Loss: 0.9990845918655396, Final Batch Loss: 0.2312031090259552\n",
      "Epoch 3546, Loss: 1.0853597521781921, Final Batch Loss: 0.1833009123802185\n",
      "Epoch 3547, Loss: 1.1626178324222565, Final Batch Loss: 0.3185529410839081\n",
      "Epoch 3548, Loss: 1.0820022374391556, Final Batch Loss: 0.26658767461776733\n",
      "Epoch 3549, Loss: 1.0400509387254715, Final Batch Loss: 0.25989362597465515\n",
      "Epoch 3550, Loss: 1.0695525407791138, Final Batch Loss: 0.26837265491485596\n",
      "Epoch 3551, Loss: 1.0676137208938599, Final Batch Loss: 0.23668621480464935\n",
      "Epoch 3552, Loss: 0.9896934777498245, Final Batch Loss: 0.21526938676834106\n",
      "Epoch 3553, Loss: 1.1311203688383102, Final Batch Loss: 0.3089887499809265\n",
      "Epoch 3554, Loss: 1.1081826835870743, Final Batch Loss: 0.2228250354528427\n",
      "Epoch 3555, Loss: 1.0075851082801819, Final Batch Loss: 0.1711009442806244\n",
      "Epoch 3556, Loss: 1.0657623261213303, Final Batch Loss: 0.2582937479019165\n",
      "Epoch 3557, Loss: 1.0354913175106049, Final Batch Loss: 0.28331252932548523\n",
      "Epoch 3558, Loss: 1.0926503837108612, Final Batch Loss: 0.23305702209472656\n",
      "Epoch 3559, Loss: 1.0467001795768738, Final Batch Loss: 0.2505228817462921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3560, Loss: 1.0932493805885315, Final Batch Loss: 0.305397093296051\n",
      "Epoch 3561, Loss: 0.9672710448503494, Final Batch Loss: 0.15920615196228027\n",
      "Epoch 3562, Loss: 1.0230982154607773, Final Batch Loss: 0.20819394290447235\n",
      "Epoch 3563, Loss: 1.1465346664190292, Final Batch Loss: 0.2479497343301773\n",
      "Epoch 3564, Loss: 1.0824971348047256, Final Batch Loss: 0.21323584020137787\n",
      "Epoch 3565, Loss: 1.0592252016067505, Final Batch Loss: 0.2099093347787857\n",
      "Epoch 3566, Loss: 1.0818875879049301, Final Batch Loss: 0.2878597676753998\n",
      "Epoch 3567, Loss: 1.0508118718862534, Final Batch Loss: 0.23441274464130402\n",
      "Epoch 3568, Loss: 1.0581706017255783, Final Batch Loss: 0.23559246957302094\n",
      "Epoch 3569, Loss: 1.0787683874368668, Final Batch Loss: 0.26757824420928955\n",
      "Epoch 3570, Loss: 1.078780859708786, Final Batch Loss: 0.2543114125728607\n",
      "Epoch 3571, Loss: 1.0695604979991913, Final Batch Loss: 0.2722955644130707\n",
      "Epoch 3572, Loss: 1.016381859779358, Final Batch Loss: 0.23754312098026276\n",
      "Epoch 3573, Loss: 1.0638998448848724, Final Batch Loss: 0.2556159198284149\n",
      "Epoch 3574, Loss: 0.9305475205183029, Final Batch Loss: 0.20990601181983948\n",
      "Epoch 3575, Loss: 1.1249699741601944, Final Batch Loss: 0.2296096533536911\n",
      "Epoch 3576, Loss: 0.9856263548135757, Final Batch Loss: 0.19797328114509583\n",
      "Epoch 3577, Loss: 0.9878803044557571, Final Batch Loss: 0.2403082549571991\n",
      "Epoch 3578, Loss: 1.1867767572402954, Final Batch Loss: 0.27519479393959045\n",
      "Epoch 3579, Loss: 1.166413128376007, Final Batch Loss: 0.27818718552589417\n",
      "Epoch 3580, Loss: 1.1045475900173187, Final Batch Loss: 0.21484023332595825\n",
      "Epoch 3581, Loss: 1.2991182804107666, Final Batch Loss: 0.4455936551094055\n",
      "Epoch 3582, Loss: 1.0677403062582016, Final Batch Loss: 0.24967938661575317\n",
      "Epoch 3583, Loss: 1.047985628247261, Final Batch Loss: 0.3421768546104431\n",
      "Epoch 3584, Loss: 1.0947937071323395, Final Batch Loss: 0.21845823526382446\n",
      "Epoch 3585, Loss: 1.207127332687378, Final Batch Loss: 0.34258562326431274\n",
      "Epoch 3586, Loss: 1.109775722026825, Final Batch Loss: 0.2705368101596832\n",
      "Epoch 3587, Loss: 1.0704736113548279, Final Batch Loss: 0.34723445773124695\n",
      "Epoch 3588, Loss: 1.06399305164814, Final Batch Loss: 0.2730962932109833\n",
      "Epoch 3589, Loss: 1.034765511751175, Final Batch Loss: 0.2800476849079132\n",
      "Epoch 3590, Loss: 1.0989130735397339, Final Batch Loss: 0.29453399777412415\n",
      "Epoch 3591, Loss: 1.0959990173578262, Final Batch Loss: 0.31818369030952454\n",
      "Epoch 3592, Loss: 0.9174081981182098, Final Batch Loss: 0.18577809631824493\n",
      "Epoch 3593, Loss: 0.9218349009752274, Final Batch Loss: 0.22633133828639984\n",
      "Epoch 3594, Loss: 1.187773421406746, Final Batch Loss: 0.3920879065990448\n",
      "Epoch 3595, Loss: 1.1855569779872894, Final Batch Loss: 0.2243618667125702\n",
      "Epoch 3596, Loss: 0.975875049829483, Final Batch Loss: 0.17406952381134033\n",
      "Epoch 3597, Loss: 1.0649245083332062, Final Batch Loss: 0.2678897976875305\n",
      "Epoch 3598, Loss: 1.146464079618454, Final Batch Loss: 0.3467402756214142\n",
      "Epoch 3599, Loss: 1.241223394870758, Final Batch Loss: 0.3594399392604828\n",
      "Epoch 3600, Loss: 1.03063203394413, Final Batch Loss: 0.24853847920894623\n",
      "Epoch 3601, Loss: 1.0620813965797424, Final Batch Loss: 0.24457062780857086\n",
      "Epoch 3602, Loss: 1.1216144561767578, Final Batch Loss: 0.2740147113800049\n",
      "Epoch 3603, Loss: 1.1033526957035065, Final Batch Loss: 0.29817599058151245\n",
      "Epoch 3604, Loss: 1.1679567992687225, Final Batch Loss: 0.2971048951148987\n",
      "Epoch 3605, Loss: 1.1366290748119354, Final Batch Loss: 0.3108474910259247\n",
      "Epoch 3606, Loss: 1.1321271508932114, Final Batch Loss: 0.2937496602535248\n",
      "Epoch 3607, Loss: 1.0546385049819946, Final Batch Loss: 0.28430888056755066\n",
      "Epoch 3608, Loss: 1.065263792872429, Final Batch Loss: 0.32517772912979126\n",
      "Epoch 3609, Loss: 1.1032617539167404, Final Batch Loss: 0.2163863629102707\n",
      "Epoch 3610, Loss: 1.068535789847374, Final Batch Loss: 0.2605932950973511\n",
      "Epoch 3611, Loss: 1.0308660715818405, Final Batch Loss: 0.12733642756938934\n",
      "Epoch 3612, Loss: 0.9830435812473297, Final Batch Loss: 0.23169176280498505\n",
      "Epoch 3613, Loss: 0.9498439580202103, Final Batch Loss: 0.25282949209213257\n",
      "Epoch 3614, Loss: 1.0015764683485031, Final Batch Loss: 0.2674741744995117\n",
      "Epoch 3615, Loss: 1.2176693379878998, Final Batch Loss: 0.3448655903339386\n",
      "Epoch 3616, Loss: 1.0535122007131577, Final Batch Loss: 0.3885022699832916\n",
      "Epoch 3617, Loss: 1.0489289462566376, Final Batch Loss: 0.18201571702957153\n",
      "Epoch 3618, Loss: 0.9536908715963364, Final Batch Loss: 0.21941082179546356\n",
      "Epoch 3619, Loss: 1.2881457209587097, Final Batch Loss: 0.5171354413032532\n",
      "Epoch 3620, Loss: 1.1247817873954773, Final Batch Loss: 0.39636147022247314\n",
      "Epoch 3621, Loss: 1.2177537381649017, Final Batch Loss: 0.35114791989326477\n",
      "Epoch 3622, Loss: 0.9004211872816086, Final Batch Loss: 0.21659409999847412\n",
      "Epoch 3623, Loss: 0.9667572230100632, Final Batch Loss: 0.22681468725204468\n",
      "Epoch 3624, Loss: 0.9832109063863754, Final Batch Loss: 0.2476770430803299\n",
      "Epoch 3625, Loss: 1.0296755284070969, Final Batch Loss: 0.30797505378723145\n",
      "Epoch 3626, Loss: 1.0273151397705078, Final Batch Loss: 0.31700587272644043\n",
      "Epoch 3627, Loss: 0.9491621404886246, Final Batch Loss: 0.19203244149684906\n",
      "Epoch 3628, Loss: 1.1384193897247314, Final Batch Loss: 0.29455065727233887\n",
      "Epoch 3629, Loss: 0.9886924922466278, Final Batch Loss: 0.3098728656768799\n",
      "Epoch 3630, Loss: 1.0877714604139328, Final Batch Loss: 0.22113624215126038\n",
      "Epoch 3631, Loss: 0.940799817442894, Final Batch Loss: 0.23593832552433014\n",
      "Epoch 3632, Loss: 0.9950395226478577, Final Batch Loss: 0.2480001151561737\n",
      "Epoch 3633, Loss: 0.9557623714208603, Final Batch Loss: 0.19959527254104614\n",
      "Epoch 3634, Loss: 1.0933652818202972, Final Batch Loss: 0.22279202938079834\n",
      "Epoch 3635, Loss: 1.0625255554914474, Final Batch Loss: 0.310780793428421\n",
      "Epoch 3636, Loss: 1.0362416207790375, Final Batch Loss: 0.19794929027557373\n",
      "Epoch 3637, Loss: 0.9336165934801102, Final Batch Loss: 0.2271403819322586\n",
      "Epoch 3638, Loss: 1.0059661865234375, Final Batch Loss: 0.24126474559307098\n",
      "Epoch 3639, Loss: 1.023278295993805, Final Batch Loss: 0.21667872369289398\n",
      "Epoch 3640, Loss: 0.9200944900512695, Final Batch Loss: 0.2478974312543869\n",
      "Epoch 3641, Loss: 1.0327608436346054, Final Batch Loss: 0.1693219393491745\n",
      "Epoch 3642, Loss: 1.111359864473343, Final Batch Loss: 0.29817667603492737\n",
      "Epoch 3643, Loss: 1.0124215930700302, Final Batch Loss: 0.28485551476478577\n",
      "Epoch 3644, Loss: 1.1017931997776031, Final Batch Loss: 0.2509971261024475\n",
      "Epoch 3645, Loss: 1.1014322489500046, Final Batch Loss: 0.2983592450618744\n",
      "Epoch 3646, Loss: 1.0657529085874557, Final Batch Loss: 0.2149004191160202\n",
      "Epoch 3647, Loss: 0.9527931362390518, Final Batch Loss: 0.20270049571990967\n",
      "Epoch 3648, Loss: 1.1427299678325653, Final Batch Loss: 0.3339356482028961\n",
      "Epoch 3649, Loss: 1.1562988609075546, Final Batch Loss: 0.3478754460811615\n",
      "Epoch 3650, Loss: 0.9435366839170456, Final Batch Loss: 0.3129217028617859\n",
      "Epoch 3651, Loss: 1.1089129745960236, Final Batch Loss: 0.2128942906856537\n",
      "Epoch 3652, Loss: 0.9863820225000381, Final Batch Loss: 0.22936122119426727\n",
      "Epoch 3653, Loss: 0.9755526632070541, Final Batch Loss: 0.19152124226093292\n",
      "Epoch 3654, Loss: 1.0521695166826248, Final Batch Loss: 0.2850993871688843\n",
      "Epoch 3655, Loss: 1.0867843329906464, Final Batch Loss: 0.22912828624248505\n",
      "Epoch 3656, Loss: 1.037634238600731, Final Batch Loss: 0.2816813290119171\n",
      "Epoch 3657, Loss: 1.1140550076961517, Final Batch Loss: 0.3917670249938965\n",
      "Epoch 3658, Loss: 1.1036927103996277, Final Batch Loss: 0.24558404088020325\n",
      "Epoch 3659, Loss: 1.09715536236763, Final Batch Loss: 0.33277639746665955\n",
      "Epoch 3660, Loss: 1.1054132878780365, Final Batch Loss: 0.27707183361053467\n",
      "Epoch 3661, Loss: 0.9890950918197632, Final Batch Loss: 0.21481230854988098\n",
      "Epoch 3662, Loss: 0.9834048300981522, Final Batch Loss: 0.20265592634677887\n",
      "Epoch 3663, Loss: 1.0765565782785416, Final Batch Loss: 0.16993926465511322\n",
      "Epoch 3664, Loss: 1.094425231218338, Final Batch Loss: 0.30666178464889526\n",
      "Epoch 3665, Loss: 1.0782788842916489, Final Batch Loss: 0.3231773376464844\n",
      "Epoch 3666, Loss: 1.0988806188106537, Final Batch Loss: 0.29062893986701965\n",
      "Epoch 3667, Loss: 0.925804004073143, Final Batch Loss: 0.19372931122779846\n",
      "Epoch 3668, Loss: 1.1531071662902832, Final Batch Loss: 0.3743247389793396\n",
      "Epoch 3669, Loss: 0.9234809726476669, Final Batch Loss: 0.16252656280994415\n",
      "Epoch 3670, Loss: 1.0142541229724884, Final Batch Loss: 0.20312336087226868\n",
      "Epoch 3671, Loss: 1.1020074784755707, Final Batch Loss: 0.36034226417541504\n",
      "Epoch 3672, Loss: 1.0785888135433197, Final Batch Loss: 0.26426637172698975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3673, Loss: 0.9721559286117554, Final Batch Loss: 0.2425927072763443\n",
      "Epoch 3674, Loss: 0.995006263256073, Final Batch Loss: 0.2410595715045929\n",
      "Epoch 3675, Loss: 0.9990342259407043, Final Batch Loss: 0.26068273186683655\n",
      "Epoch 3676, Loss: 0.9043736010789871, Final Batch Loss: 0.15122734010219574\n",
      "Epoch 3677, Loss: 0.9402002245187759, Final Batch Loss: 0.20134367048740387\n",
      "Epoch 3678, Loss: 1.1088621765375137, Final Batch Loss: 0.3640266954898834\n",
      "Epoch 3679, Loss: 1.0709277987480164, Final Batch Loss: 0.25679609179496765\n",
      "Epoch 3680, Loss: 0.9531033635139465, Final Batch Loss: 0.2945571541786194\n",
      "Epoch 3681, Loss: 1.2037306427955627, Final Batch Loss: 0.31760674715042114\n",
      "Epoch 3682, Loss: 1.0510547906160355, Final Batch Loss: 0.2516631782054901\n",
      "Epoch 3683, Loss: 1.0176421105861664, Final Batch Loss: 0.2276206612586975\n",
      "Epoch 3684, Loss: 1.2199379205703735, Final Batch Loss: 0.3361228406429291\n",
      "Epoch 3685, Loss: 0.9644552916288376, Final Batch Loss: 0.23141059279441833\n",
      "Epoch 3686, Loss: 1.0730519741773605, Final Batch Loss: 0.2854878306388855\n",
      "Epoch 3687, Loss: 1.1000332832336426, Final Batch Loss: 0.18752019107341766\n",
      "Epoch 3688, Loss: 1.0368709713220596, Final Batch Loss: 0.24097348749637604\n",
      "Epoch 3689, Loss: 0.9065345674753189, Final Batch Loss: 0.17644669115543365\n",
      "Epoch 3690, Loss: 1.3379202485084534, Final Batch Loss: 0.34109246730804443\n",
      "Epoch 3691, Loss: 1.124384120106697, Final Batch Loss: 0.37235894799232483\n",
      "Epoch 3692, Loss: 1.1296608448028564, Final Batch Loss: 0.2977578639984131\n",
      "Epoch 3693, Loss: 1.0918431878089905, Final Batch Loss: 0.28078994154930115\n",
      "Epoch 3694, Loss: 1.1944210231304169, Final Batch Loss: 0.3633412718772888\n",
      "Epoch 3695, Loss: 1.0169359296560287, Final Batch Loss: 0.3063699007034302\n",
      "Epoch 3696, Loss: 1.0555448532104492, Final Batch Loss: 0.21672990918159485\n",
      "Epoch 3697, Loss: 1.0517428368330002, Final Batch Loss: 0.2928450405597687\n",
      "Epoch 3698, Loss: 0.9216223061084747, Final Batch Loss: 0.1337374597787857\n",
      "Epoch 3699, Loss: 1.0718843936920166, Final Batch Loss: 0.24633672833442688\n",
      "Epoch 3700, Loss: 1.0990744233131409, Final Batch Loss: 0.2780304253101349\n",
      "Epoch 3701, Loss: 0.922101154923439, Final Batch Loss: 0.21087540686130524\n",
      "Epoch 3702, Loss: 0.9692691415548325, Final Batch Loss: 0.22505126893520355\n",
      "Epoch 3703, Loss: 1.0786435455083847, Final Batch Loss: 0.21372908353805542\n",
      "Epoch 3704, Loss: 1.3005642741918564, Final Batch Loss: 0.4981386065483093\n",
      "Epoch 3705, Loss: 1.1258548200130463, Final Batch Loss: 0.30659809708595276\n",
      "Epoch 3706, Loss: 0.9275375157594681, Final Batch Loss: 0.1796909123659134\n",
      "Epoch 3707, Loss: 1.0446067452430725, Final Batch Loss: 0.35821104049682617\n",
      "Epoch 3708, Loss: 1.0575768798589706, Final Batch Loss: 0.26842018961906433\n",
      "Epoch 3709, Loss: 0.9731779843568802, Final Batch Loss: 0.26254525780677795\n",
      "Epoch 3710, Loss: 0.9784984141588211, Final Batch Loss: 0.1952574998140335\n",
      "Epoch 3711, Loss: 1.0520718842744827, Final Batch Loss: 0.25861862301826477\n",
      "Epoch 3712, Loss: 1.050451248884201, Final Batch Loss: 0.2589940130710602\n",
      "Epoch 3713, Loss: 1.2427737414836884, Final Batch Loss: 0.3104357421398163\n",
      "Epoch 3714, Loss: 1.0288043916225433, Final Batch Loss: 0.27587515115737915\n",
      "Epoch 3715, Loss: 1.0832261741161346, Final Batch Loss: 0.3301254212856293\n",
      "Epoch 3716, Loss: 0.9381304234266281, Final Batch Loss: 0.21399231255054474\n",
      "Epoch 3717, Loss: 0.9888306111097336, Final Batch Loss: 0.30626288056373596\n",
      "Epoch 3718, Loss: 1.0500425845384598, Final Batch Loss: 0.26297351717948914\n",
      "Epoch 3719, Loss: 0.9413601607084274, Final Batch Loss: 0.19375886023044586\n",
      "Epoch 3720, Loss: 1.0871984511613846, Final Batch Loss: 0.2769743502140045\n",
      "Epoch 3721, Loss: 1.0554962754249573, Final Batch Loss: 0.21310272812843323\n",
      "Epoch 3722, Loss: 1.1080766767263412, Final Batch Loss: 0.28688549995422363\n",
      "Epoch 3723, Loss: 1.005251869559288, Final Batch Loss: 0.24122698605060577\n",
      "Epoch 3724, Loss: 1.1685808598995209, Final Batch Loss: 0.280422180891037\n",
      "Epoch 3725, Loss: 1.0563018172979355, Final Batch Loss: 0.31463563442230225\n",
      "Epoch 3726, Loss: 0.9729978144168854, Final Batch Loss: 0.31850993633270264\n",
      "Epoch 3727, Loss: 1.0752524435520172, Final Batch Loss: 0.36946117877960205\n",
      "Epoch 3728, Loss: 1.1664889752864838, Final Batch Loss: 0.2678932547569275\n",
      "Epoch 3729, Loss: 0.9354177862405777, Final Batch Loss: 0.22771234810352325\n",
      "Epoch 3730, Loss: 1.1044469326734543, Final Batch Loss: 0.2600099444389343\n",
      "Epoch 3731, Loss: 1.1421997249126434, Final Batch Loss: 0.2881288230419159\n",
      "Epoch 3732, Loss: 1.2409952580928802, Final Batch Loss: 0.3186214566230774\n",
      "Epoch 3733, Loss: 1.3845373094081879, Final Batch Loss: 0.34939098358154297\n",
      "Epoch 3734, Loss: 1.0816768407821655, Final Batch Loss: 0.26858165860176086\n",
      "Epoch 3735, Loss: 1.078259289264679, Final Batch Loss: 0.22708384692668915\n",
      "Epoch 3736, Loss: 1.064538598060608, Final Batch Loss: 0.24403122067451477\n",
      "Epoch 3737, Loss: 1.1163313835859299, Final Batch Loss: 0.26293012499809265\n",
      "Epoch 3738, Loss: 1.0443435609340668, Final Batch Loss: 0.2697799801826477\n",
      "Epoch 3739, Loss: 1.3390458822250366, Final Batch Loss: 0.4521006941795349\n",
      "Epoch 3740, Loss: 0.9891410619020462, Final Batch Loss: 0.296564519405365\n",
      "Epoch 3741, Loss: 1.035512238740921, Final Batch Loss: 0.20343756675720215\n",
      "Epoch 3742, Loss: 1.1539714485406876, Final Batch Loss: 0.33902212977409363\n",
      "Epoch 3743, Loss: 0.9450523108243942, Final Batch Loss: 0.13946114480495453\n",
      "Epoch 3744, Loss: 1.0133741199970245, Final Batch Loss: 0.27739107608795166\n",
      "Epoch 3745, Loss: 0.9924722462892532, Final Batch Loss: 0.2258886992931366\n",
      "Epoch 3746, Loss: 1.0905346870422363, Final Batch Loss: 0.22723355889320374\n",
      "Epoch 3747, Loss: 0.8385828584432602, Final Batch Loss: 0.18637005984783173\n",
      "Epoch 3748, Loss: 1.0366868078708649, Final Batch Loss: 0.2558729946613312\n",
      "Epoch 3749, Loss: 1.0234276354312897, Final Batch Loss: 0.264021098613739\n",
      "Epoch 3750, Loss: 1.0508185029029846, Final Batch Loss: 0.25634458661079407\n",
      "Epoch 3751, Loss: 0.9598800987005234, Final Batch Loss: 0.22237998247146606\n",
      "Epoch 3752, Loss: 1.111412063241005, Final Batch Loss: 0.2903609573841095\n",
      "Epoch 3753, Loss: 1.031836673617363, Final Batch Loss: 0.24893999099731445\n",
      "Epoch 3754, Loss: 1.0682755708694458, Final Batch Loss: 0.3101171851158142\n",
      "Epoch 3755, Loss: 1.029597133398056, Final Batch Loss: 0.27861735224723816\n",
      "Epoch 3756, Loss: 1.0739044696092606, Final Batch Loss: 0.31805872917175293\n",
      "Epoch 3757, Loss: 0.8853328824043274, Final Batch Loss: 0.2172461301088333\n",
      "Epoch 3758, Loss: 1.060300201177597, Final Batch Loss: 0.23084603250026703\n",
      "Epoch 3759, Loss: 1.00760979950428, Final Batch Loss: 0.19137246906757355\n",
      "Epoch 3760, Loss: 1.016382411122322, Final Batch Loss: 0.26568135619163513\n",
      "Epoch 3761, Loss: 1.0254302471876144, Final Batch Loss: 0.22032569348812103\n",
      "Epoch 3762, Loss: 1.1309315711259842, Final Batch Loss: 0.4328479468822479\n",
      "Epoch 3763, Loss: 1.04544797539711, Final Batch Loss: 0.32018524408340454\n",
      "Epoch 3764, Loss: 1.0683783441781998, Final Batch Loss: 0.2560027241706848\n",
      "Epoch 3765, Loss: 1.0419931560754776, Final Batch Loss: 0.178887739777565\n",
      "Epoch 3766, Loss: 1.0691289156675339, Final Batch Loss: 0.3427037298679352\n",
      "Epoch 3767, Loss: 0.9857305437326431, Final Batch Loss: 0.22370456159114838\n",
      "Epoch 3768, Loss: 0.9017758071422577, Final Batch Loss: 0.17513251304626465\n",
      "Epoch 3769, Loss: 1.1538852900266647, Final Batch Loss: 0.4081861674785614\n",
      "Epoch 3770, Loss: 0.9645429402589798, Final Batch Loss: 0.26773473620414734\n",
      "Epoch 3771, Loss: 1.1465541571378708, Final Batch Loss: 0.20801283419132233\n",
      "Epoch 3772, Loss: 1.033678099513054, Final Batch Loss: 0.2662011682987213\n",
      "Epoch 3773, Loss: 0.9947915077209473, Final Batch Loss: 0.2022002786397934\n",
      "Epoch 3774, Loss: 1.148415058851242, Final Batch Loss: 0.25943028926849365\n",
      "Epoch 3775, Loss: 1.0197685360908508, Final Batch Loss: 0.27273067831993103\n",
      "Epoch 3776, Loss: 1.1241686791181564, Final Batch Loss: 0.31348660588264465\n",
      "Epoch 3777, Loss: 1.0802246034145355, Final Batch Loss: 0.21589691936969757\n",
      "Epoch 3778, Loss: 1.0150071829557419, Final Batch Loss: 0.2138683944940567\n",
      "Epoch 3779, Loss: 1.106095552444458, Final Batch Loss: 0.24417996406555176\n",
      "Epoch 3780, Loss: 1.1720065474510193, Final Batch Loss: 0.40743571519851685\n",
      "Epoch 3781, Loss: 1.0469720661640167, Final Batch Loss: 0.20500008761882782\n",
      "Epoch 3782, Loss: 1.017410233616829, Final Batch Loss: 0.263764351606369\n",
      "Epoch 3783, Loss: 1.0093484222888947, Final Batch Loss: 0.2820642590522766\n",
      "Epoch 3784, Loss: 1.0067602843046188, Final Batch Loss: 0.2646433115005493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3785, Loss: 1.0843129456043243, Final Batch Loss: 0.2982158958911896\n",
      "Epoch 3786, Loss: 1.1338021159172058, Final Batch Loss: 0.27767786383628845\n",
      "Epoch 3787, Loss: 0.9401679784059525, Final Batch Loss: 0.27238890528678894\n",
      "Epoch 3788, Loss: 1.0929047912359238, Final Batch Loss: 0.21356377005577087\n",
      "Epoch 3789, Loss: 1.0444775819778442, Final Batch Loss: 0.28791338205337524\n",
      "Epoch 3790, Loss: 1.0728162080049515, Final Batch Loss: 0.25949910283088684\n",
      "Epoch 3791, Loss: 0.9837144017219543, Final Batch Loss: 0.23345130681991577\n",
      "Epoch 3792, Loss: 0.9013966619968414, Final Batch Loss: 0.17023970186710358\n",
      "Epoch 3793, Loss: 1.0177673399448395, Final Batch Loss: 0.226774662733078\n",
      "Epoch 3794, Loss: 1.051490530371666, Final Batch Loss: 0.19049088656902313\n",
      "Epoch 3795, Loss: 0.9991645216941833, Final Batch Loss: 0.3480815291404724\n",
      "Epoch 3796, Loss: 0.8919079303741455, Final Batch Loss: 0.15190774202346802\n",
      "Epoch 3797, Loss: 1.0069739520549774, Final Batch Loss: 0.28058111667633057\n",
      "Epoch 3798, Loss: 0.9808874726295471, Final Batch Loss: 0.2809330224990845\n",
      "Epoch 3799, Loss: 1.0589169561862946, Final Batch Loss: 0.2326643168926239\n",
      "Epoch 3800, Loss: 0.988864466547966, Final Batch Loss: 0.16517402231693268\n",
      "Epoch 3801, Loss: 1.014634981751442, Final Batch Loss: 0.23590263724327087\n",
      "Epoch 3802, Loss: 1.0438723713159561, Final Batch Loss: 0.25258147716522217\n",
      "Epoch 3803, Loss: 1.077215924859047, Final Batch Loss: 0.3607427477836609\n",
      "Epoch 3804, Loss: 1.409149020910263, Final Batch Loss: 0.47900858521461487\n",
      "Epoch 3805, Loss: 0.9865398854017258, Final Batch Loss: 0.23481135070323944\n",
      "Epoch 3806, Loss: 1.025589108467102, Final Batch Loss: 0.23375679552555084\n",
      "Epoch 3807, Loss: 0.9616793245077133, Final Batch Loss: 0.22379297018051147\n",
      "Epoch 3808, Loss: 1.0613602995872498, Final Batch Loss: 0.23939210176467896\n",
      "Epoch 3809, Loss: 0.9569429606199265, Final Batch Loss: 0.1716585010290146\n",
      "Epoch 3810, Loss: 0.9877296686172485, Final Batch Loss: 0.2827296555042267\n",
      "Epoch 3811, Loss: 1.029511347413063, Final Batch Loss: 0.2070665806531906\n",
      "Epoch 3812, Loss: 1.0322328358888626, Final Batch Loss: 0.2419859617948532\n",
      "Epoch 3813, Loss: 1.060915395617485, Final Batch Loss: 0.2872684895992279\n",
      "Epoch 3814, Loss: 0.939304456114769, Final Batch Loss: 0.16955602169036865\n",
      "Epoch 3815, Loss: 1.090704932808876, Final Batch Loss: 0.2820267975330353\n",
      "Epoch 3816, Loss: 1.130796492099762, Final Batch Loss: 0.2416667342185974\n",
      "Epoch 3817, Loss: 1.0402561575174332, Final Batch Loss: 0.31061774492263794\n",
      "Epoch 3818, Loss: 1.0728436410427094, Final Batch Loss: 0.2658369541168213\n",
      "Epoch 3819, Loss: 1.0061140060424805, Final Batch Loss: 0.28068098425865173\n",
      "Epoch 3820, Loss: 1.0343706905841827, Final Batch Loss: 0.23363618552684784\n",
      "Epoch 3821, Loss: 1.0720340758562088, Final Batch Loss: 0.3011898696422577\n",
      "Epoch 3822, Loss: 1.2237026393413544, Final Batch Loss: 0.48111802339553833\n",
      "Epoch 3823, Loss: 1.0549693256616592, Final Batch Loss: 0.274469256401062\n",
      "Epoch 3824, Loss: 0.9828057885169983, Final Batch Loss: 0.25145620107650757\n",
      "Epoch 3825, Loss: 1.0611094236373901, Final Batch Loss: 0.27010011672973633\n",
      "Epoch 3826, Loss: 1.0928595960140228, Final Batch Loss: 0.2778595983982086\n",
      "Epoch 3827, Loss: 1.0611641108989716, Final Batch Loss: 0.2335631251335144\n",
      "Epoch 3828, Loss: 1.2374923825263977, Final Batch Loss: 0.34093979001045227\n",
      "Epoch 3829, Loss: 1.1427500993013382, Final Batch Loss: 0.30988961458206177\n",
      "Epoch 3830, Loss: 0.9468391239643097, Final Batch Loss: 0.19256499409675598\n",
      "Epoch 3831, Loss: 1.1225274056196213, Final Batch Loss: 0.1835441142320633\n",
      "Epoch 3832, Loss: 1.013282522559166, Final Batch Loss: 0.12921816110610962\n",
      "Epoch 3833, Loss: 1.032107651233673, Final Batch Loss: 0.23446227610111237\n",
      "Epoch 3834, Loss: 1.1176080405712128, Final Batch Loss: 0.3393034338951111\n",
      "Epoch 3835, Loss: 1.1453561782836914, Final Batch Loss: 0.3551824986934662\n",
      "Epoch 3836, Loss: 1.0946347266435623, Final Batch Loss: 0.3140314221382141\n",
      "Epoch 3837, Loss: 1.0175311118364334, Final Batch Loss: 0.23260800540447235\n",
      "Epoch 3838, Loss: 0.9534559994935989, Final Batch Loss: 0.22569550573825836\n",
      "Epoch 3839, Loss: 1.0301223993301392, Final Batch Loss: 0.22444148361682892\n",
      "Epoch 3840, Loss: 1.0529365837574005, Final Batch Loss: 0.2944921851158142\n",
      "Epoch 3841, Loss: 0.9278611540794373, Final Batch Loss: 0.2644021213054657\n",
      "Epoch 3842, Loss: 1.0290422588586807, Final Batch Loss: 0.1973644345998764\n",
      "Epoch 3843, Loss: 0.950886607170105, Final Batch Loss: 0.24339717626571655\n",
      "Epoch 3844, Loss: 1.0225530415773392, Final Batch Loss: 0.21699117124080658\n",
      "Epoch 3845, Loss: 0.948129266500473, Final Batch Loss: 0.14206375181674957\n",
      "Epoch 3846, Loss: 1.1780976951122284, Final Batch Loss: 0.3717026710510254\n",
      "Epoch 3847, Loss: 0.9944134652614594, Final Batch Loss: 0.15279996395111084\n",
      "Epoch 3848, Loss: 1.0458574295043945, Final Batch Loss: 0.26905158162117004\n",
      "Epoch 3849, Loss: 1.0210652351379395, Final Batch Loss: 0.21492673456668854\n",
      "Epoch 3850, Loss: 1.087090790271759, Final Batch Loss: 0.3495664596557617\n",
      "Epoch 3851, Loss: 1.089633584022522, Final Batch Loss: 0.29258057475090027\n",
      "Epoch 3852, Loss: 1.1845614910125732, Final Batch Loss: 0.38775333762168884\n",
      "Epoch 3853, Loss: 0.9787821471691132, Final Batch Loss: 0.19368751347064972\n",
      "Epoch 3854, Loss: 1.058891475200653, Final Batch Loss: 0.2383333295583725\n",
      "Epoch 3855, Loss: 1.00664921104908, Final Batch Loss: 0.2523631453514099\n",
      "Epoch 3856, Loss: 0.950716182589531, Final Batch Loss: 0.23990468680858612\n",
      "Epoch 3857, Loss: 1.0199327319860458, Final Batch Loss: 0.2558114230632782\n",
      "Epoch 3858, Loss: 1.074599876999855, Final Batch Loss: 0.3039390742778778\n",
      "Epoch 3859, Loss: 1.0876140892505646, Final Batch Loss: 0.353679895401001\n",
      "Epoch 3860, Loss: 0.9737822413444519, Final Batch Loss: 0.2361173778772354\n",
      "Epoch 3861, Loss: 0.9302407503128052, Final Batch Loss: 0.24797993898391724\n",
      "Epoch 3862, Loss: 1.1416971981525421, Final Batch Loss: 0.3419888913631439\n",
      "Epoch 3863, Loss: 0.9491670280694962, Final Batch Loss: 0.23726493120193481\n",
      "Epoch 3864, Loss: 1.0073774009943008, Final Batch Loss: 0.3224869668483734\n",
      "Epoch 3865, Loss: 0.9581865072250366, Final Batch Loss: 0.21925699710845947\n",
      "Epoch 3866, Loss: 0.9237478971481323, Final Batch Loss: 0.15754631161689758\n",
      "Epoch 3867, Loss: 1.0387896001338959, Final Batch Loss: 0.22597157955169678\n",
      "Epoch 3868, Loss: 0.8683737963438034, Final Batch Loss: 0.15235187113285065\n",
      "Epoch 3869, Loss: 1.1710387915372849, Final Batch Loss: 0.36204272508621216\n",
      "Epoch 3870, Loss: 1.1802201569080353, Final Batch Loss: 0.21631324291229248\n",
      "Epoch 3871, Loss: 0.96810182929039, Final Batch Loss: 0.1890435665845871\n",
      "Epoch 3872, Loss: 0.9677795916795731, Final Batch Loss: 0.2602179944515228\n",
      "Epoch 3873, Loss: 0.9886230826377869, Final Batch Loss: 0.25563913583755493\n",
      "Epoch 3874, Loss: 1.051454558968544, Final Batch Loss: 0.27968698740005493\n",
      "Epoch 3875, Loss: 0.8939222991466522, Final Batch Loss: 0.25521108508110046\n",
      "Epoch 3876, Loss: 0.9602664709091187, Final Batch Loss: 0.22223679721355438\n",
      "Epoch 3877, Loss: 1.0098236799240112, Final Batch Loss: 0.20635339617729187\n",
      "Epoch 3878, Loss: 1.1150788068771362, Final Batch Loss: 0.3106933534145355\n",
      "Epoch 3879, Loss: 1.0030964612960815, Final Batch Loss: 0.2933052182197571\n",
      "Epoch 3880, Loss: 0.9754042327404022, Final Batch Loss: 0.2443612664937973\n",
      "Epoch 3881, Loss: 1.0682566910982132, Final Batch Loss: 0.2675308883190155\n",
      "Epoch 3882, Loss: 1.033717781305313, Final Batch Loss: 0.293180376291275\n",
      "Epoch 3883, Loss: 1.0553997159004211, Final Batch Loss: 0.30992960929870605\n",
      "Epoch 3884, Loss: 0.9733699858188629, Final Batch Loss: 0.2363186478614807\n",
      "Epoch 3885, Loss: 1.0816302001476288, Final Batch Loss: 0.3033565878868103\n",
      "Epoch 3886, Loss: 0.779715046286583, Final Batch Loss: 0.20882216095924377\n",
      "Epoch 3887, Loss: 1.131041094660759, Final Batch Loss: 0.35669273138046265\n",
      "Epoch 3888, Loss: 1.187841147184372, Final Batch Loss: 0.31456413865089417\n",
      "Epoch 3889, Loss: 1.0847098529338837, Final Batch Loss: 0.2718333303928375\n",
      "Epoch 3890, Loss: 1.022938460111618, Final Batch Loss: 0.25785160064697266\n",
      "Epoch 3891, Loss: 1.0684729218482971, Final Batch Loss: 0.2920880615711212\n",
      "Epoch 3892, Loss: 1.214963048696518, Final Batch Loss: 0.3910558521747589\n",
      "Epoch 3893, Loss: 1.0720098614692688, Final Batch Loss: 0.22523370385169983\n",
      "Epoch 3894, Loss: 0.9977656304836273, Final Batch Loss: 0.2617793679237366\n",
      "Epoch 3895, Loss: 1.0370668023824692, Final Batch Loss: 0.3027961552143097\n",
      "Epoch 3896, Loss: 1.0741917788982391, Final Batch Loss: 0.34428834915161133\n",
      "Epoch 3897, Loss: 1.096292793750763, Final Batch Loss: 0.2300969362258911\n",
      "Epoch 3898, Loss: 1.0671665668487549, Final Batch Loss: 0.30785447359085083\n",
      "Epoch 3899, Loss: 1.1775968819856644, Final Batch Loss: 0.4553574025630951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3900, Loss: 0.9047069698572159, Final Batch Loss: 0.1908036321401596\n",
      "Epoch 3901, Loss: 1.0269959270954132, Final Batch Loss: 0.2610940635204315\n",
      "Epoch 3902, Loss: 1.1211538314819336, Final Batch Loss: 0.30994144082069397\n",
      "Epoch 3903, Loss: 0.9350406676530838, Final Batch Loss: 0.2289559245109558\n",
      "Epoch 3904, Loss: 0.9684502184391022, Final Batch Loss: 0.2441890835762024\n",
      "Epoch 3905, Loss: 1.1119626760482788, Final Batch Loss: 0.29346519708633423\n",
      "Epoch 3906, Loss: 0.9522215873003006, Final Batch Loss: 0.20226475596427917\n",
      "Epoch 3907, Loss: 0.9455576688051224, Final Batch Loss: 0.286818265914917\n",
      "Epoch 3908, Loss: 0.9542382061481476, Final Batch Loss: 0.28732308745384216\n",
      "Epoch 3909, Loss: 0.9738376885652542, Final Batch Loss: 0.2340129017829895\n",
      "Epoch 3910, Loss: 1.0193857252597809, Final Batch Loss: 0.2729327082633972\n",
      "Epoch 3911, Loss: 1.0261420011520386, Final Batch Loss: 0.2929532825946808\n",
      "Epoch 3912, Loss: 1.0401622205972672, Final Batch Loss: 0.25592106580734253\n",
      "Epoch 3913, Loss: 1.0481128543615341, Final Batch Loss: 0.2893797755241394\n",
      "Epoch 3914, Loss: 1.106993705034256, Final Batch Loss: 0.3927112817764282\n",
      "Epoch 3915, Loss: 1.181471824645996, Final Batch Loss: 0.3588566184043884\n",
      "Epoch 3916, Loss: 1.1064218580722809, Final Batch Loss: 0.33528006076812744\n",
      "Epoch 3917, Loss: 1.055499017238617, Final Batch Loss: 0.34979891777038574\n",
      "Epoch 3918, Loss: 1.1434729099273682, Final Batch Loss: 0.32759663462638855\n",
      "Epoch 3919, Loss: 1.0817275792360306, Final Batch Loss: 0.3563254475593567\n",
      "Epoch 3920, Loss: 0.9825474470853806, Final Batch Loss: 0.2631772458553314\n",
      "Epoch 3921, Loss: 1.1317230314016342, Final Batch Loss: 0.22858493030071259\n",
      "Epoch 3922, Loss: 1.0137214362621307, Final Batch Loss: 0.20284013450145721\n",
      "Epoch 3923, Loss: 1.0350905656814575, Final Batch Loss: 0.2221851348876953\n",
      "Epoch 3924, Loss: 1.034837618470192, Final Batch Loss: 0.21989382803440094\n",
      "Epoch 3925, Loss: 1.164842426776886, Final Batch Loss: 0.32305315136909485\n",
      "Epoch 3926, Loss: 0.867668941617012, Final Batch Loss: 0.15776485204696655\n",
      "Epoch 3927, Loss: 1.0543027967214584, Final Batch Loss: 0.1965503841638565\n",
      "Epoch 3928, Loss: 1.1850851774215698, Final Batch Loss: 0.30141201615333557\n",
      "Epoch 3929, Loss: 1.1482483893632889, Final Batch Loss: 0.3538109064102173\n",
      "Epoch 3930, Loss: 1.0198491960763931, Final Batch Loss: 0.2672674059867859\n",
      "Epoch 3931, Loss: 1.0134776085615158, Final Batch Loss: 0.24757647514343262\n",
      "Epoch 3932, Loss: 1.0683501809835434, Final Batch Loss: 0.20963145792484283\n",
      "Epoch 3933, Loss: 1.010451003909111, Final Batch Loss: 0.26562434434890747\n",
      "Epoch 3934, Loss: 1.1602972447872162, Final Batch Loss: 0.35675957798957825\n",
      "Epoch 3935, Loss: 1.0865853428840637, Final Batch Loss: 0.23929521441459656\n",
      "Epoch 3936, Loss: 1.0093674808740616, Final Batch Loss: 0.22911196947097778\n",
      "Epoch 3937, Loss: 0.9875203669071198, Final Batch Loss: 0.18596932291984558\n",
      "Epoch 3938, Loss: 1.0923387110233307, Final Batch Loss: 0.27300429344177246\n",
      "Epoch 3939, Loss: 0.9925470054149628, Final Batch Loss: 0.2546791732311249\n",
      "Epoch 3940, Loss: 1.0367587059736252, Final Batch Loss: 0.293381005525589\n",
      "Epoch 3941, Loss: 1.0724235773086548, Final Batch Loss: 0.22938627004623413\n",
      "Epoch 3942, Loss: 1.0057321190834045, Final Batch Loss: 0.32652977108955383\n",
      "Epoch 3943, Loss: 1.02369125187397, Final Batch Loss: 0.23346325755119324\n",
      "Epoch 3944, Loss: 1.005642294883728, Final Batch Loss: 0.27635839581489563\n",
      "Epoch 3945, Loss: 1.047434151172638, Final Batch Loss: 0.17840871214866638\n",
      "Epoch 3946, Loss: 1.0122671276330948, Final Batch Loss: 0.26353150606155396\n",
      "Epoch 3947, Loss: 1.0095079243183136, Final Batch Loss: 0.2468552589416504\n",
      "Epoch 3948, Loss: 0.9510975480079651, Final Batch Loss: 0.24923646450042725\n",
      "Epoch 3949, Loss: 1.1285601258277893, Final Batch Loss: 0.3202308416366577\n",
      "Epoch 3950, Loss: 1.0372952073812485, Final Batch Loss: 0.2186291664838791\n",
      "Epoch 3951, Loss: 1.0467457473278046, Final Batch Loss: 0.2610403001308441\n",
      "Epoch 3952, Loss: 0.9462036639451981, Final Batch Loss: 0.23558522760868073\n",
      "Epoch 3953, Loss: 1.1343106031417847, Final Batch Loss: 0.28129228949546814\n",
      "Epoch 3954, Loss: 0.9636112153530121, Final Batch Loss: 0.2646455764770508\n",
      "Epoch 3955, Loss: 1.0199651718139648, Final Batch Loss: 0.26104167103767395\n",
      "Epoch 3956, Loss: 1.2161299735307693, Final Batch Loss: 0.22108764946460724\n",
      "Epoch 3957, Loss: 1.1976257860660553, Final Batch Loss: 0.3594917356967926\n",
      "Epoch 3958, Loss: 1.0643566846847534, Final Batch Loss: 0.2429860234260559\n",
      "Epoch 3959, Loss: 1.1120449900627136, Final Batch Loss: 0.2781568467617035\n",
      "Epoch 3960, Loss: 1.1269512474536896, Final Batch Loss: 0.2567664682865143\n",
      "Epoch 3961, Loss: 1.2098519653081894, Final Batch Loss: 0.32716992497444153\n",
      "Epoch 3962, Loss: 0.949482336640358, Final Batch Loss: 0.303337961435318\n",
      "Epoch 3963, Loss: 0.8807798624038696, Final Batch Loss: 0.1748926043510437\n",
      "Epoch 3964, Loss: 0.9797176122665405, Final Batch Loss: 0.19763872027397156\n",
      "Epoch 3965, Loss: 1.2354711890220642, Final Batch Loss: 0.41157904267311096\n",
      "Epoch 3966, Loss: 1.041012093424797, Final Batch Loss: 0.14877283573150635\n",
      "Epoch 3967, Loss: 0.9963666647672653, Final Batch Loss: 0.2380259484052658\n",
      "Epoch 3968, Loss: 0.9043477922677994, Final Batch Loss: 0.21281269192695618\n",
      "Epoch 3969, Loss: 0.9782374799251556, Final Batch Loss: 0.2339981645345688\n",
      "Epoch 3970, Loss: 0.998453363776207, Final Batch Loss: 0.2568950951099396\n",
      "Epoch 3971, Loss: 0.9740910977125168, Final Batch Loss: 0.21908117830753326\n",
      "Epoch 3972, Loss: 0.9840385168790817, Final Batch Loss: 0.22723188996315002\n",
      "Epoch 3973, Loss: 0.9634698331356049, Final Batch Loss: 0.24129968881607056\n",
      "Epoch 3974, Loss: 1.0642222464084625, Final Batch Loss: 0.3434317708015442\n",
      "Epoch 3975, Loss: 0.9494761526584625, Final Batch Loss: 0.22972562909126282\n",
      "Epoch 3976, Loss: 1.0679753571748734, Final Batch Loss: 0.2850799858570099\n",
      "Epoch 3977, Loss: 0.9452818334102631, Final Batch Loss: 0.20000497996807098\n",
      "Epoch 3978, Loss: 1.150095909833908, Final Batch Loss: 0.3282621502876282\n",
      "Epoch 3979, Loss: 0.9947153031826019, Final Batch Loss: 0.2437324821949005\n",
      "Epoch 3980, Loss: 1.029381349682808, Final Batch Loss: 0.17656053602695465\n",
      "Epoch 3981, Loss: 1.0941317975521088, Final Batch Loss: 0.2756321430206299\n",
      "Epoch 3982, Loss: 1.1007925271987915, Final Batch Loss: 0.2800799310207367\n",
      "Epoch 3983, Loss: 1.1569464206695557, Final Batch Loss: 0.3000534772872925\n",
      "Epoch 3984, Loss: 1.1186968833208084, Final Batch Loss: 0.2596331536769867\n",
      "Epoch 3985, Loss: 0.9038808643817902, Final Batch Loss: 0.23061618208885193\n",
      "Epoch 3986, Loss: 0.9643955528736115, Final Batch Loss: 0.21464507281780243\n",
      "Epoch 3987, Loss: 0.9950054883956909, Final Batch Loss: 0.18209540843963623\n",
      "Epoch 3988, Loss: 1.053261011838913, Final Batch Loss: 0.33637985587120056\n",
      "Epoch 3989, Loss: 1.0582496672868729, Final Batch Loss: 0.340591162443161\n",
      "Epoch 3990, Loss: 0.9484628736972809, Final Batch Loss: 0.22489161789417267\n",
      "Epoch 3991, Loss: 1.1664162874221802, Final Batch Loss: 0.32064104080200195\n",
      "Epoch 3992, Loss: 1.0401217192411423, Final Batch Loss: 0.32843104004859924\n",
      "Epoch 3993, Loss: 0.9439269304275513, Final Batch Loss: 0.22083823382854462\n",
      "Epoch 3994, Loss: 0.9175436943769455, Final Batch Loss: 0.2376522719860077\n",
      "Epoch 3995, Loss: 1.0131555795669556, Final Batch Loss: 0.19224074482917786\n",
      "Epoch 3996, Loss: 0.9701252281665802, Final Batch Loss: 0.1913759410381317\n",
      "Epoch 3997, Loss: 1.0819920003414154, Final Batch Loss: 0.4327898323535919\n",
      "Epoch 3998, Loss: 0.9787773191928864, Final Batch Loss: 0.32061606645584106\n",
      "Epoch 3999, Loss: 0.8810373246669769, Final Batch Loss: 0.21625296771526337\n",
      "Epoch 4000, Loss: 0.9624706953763962, Final Batch Loss: 0.2245834469795227\n",
      "Epoch 4001, Loss: 0.9384432733058929, Final Batch Loss: 0.2568686902523041\n",
      "Epoch 4002, Loss: 1.0491456240415573, Final Batch Loss: 0.24622465670108795\n",
      "Epoch 4003, Loss: 0.9845121055841446, Final Batch Loss: 0.27285489439964294\n",
      "Epoch 4004, Loss: 1.073618695139885, Final Batch Loss: 0.24920500814914703\n",
      "Epoch 4005, Loss: 1.0304684042930603, Final Batch Loss: 0.28383296728134155\n",
      "Epoch 4006, Loss: 0.9596141427755356, Final Batch Loss: 0.16383503377437592\n",
      "Epoch 4007, Loss: 1.0821341127157211, Final Batch Loss: 0.20028413832187653\n",
      "Epoch 4008, Loss: 1.0674669593572617, Final Batch Loss: 0.20218466222286224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4009, Loss: 1.025391049683094, Final Batch Loss: 0.11994338780641556\n",
      "Epoch 4010, Loss: 0.9825608283281326, Final Batch Loss: 0.2578393816947937\n",
      "Epoch 4011, Loss: 1.0553883761167526, Final Batch Loss: 0.23396354913711548\n",
      "Epoch 4012, Loss: 0.9959955364465714, Final Batch Loss: 0.20116373896598816\n",
      "Epoch 4013, Loss: 1.0218593627214432, Final Batch Loss: 0.2115696519613266\n",
      "Epoch 4014, Loss: 1.0326040834188461, Final Batch Loss: 0.23856358230113983\n",
      "Epoch 4015, Loss: 1.1265768110752106, Final Batch Loss: 0.24378645420074463\n",
      "Epoch 4016, Loss: 1.0411470234394073, Final Batch Loss: 0.2680564522743225\n",
      "Epoch 4017, Loss: 1.1115389615297318, Final Batch Loss: 0.23788759112358093\n",
      "Epoch 4018, Loss: 1.0231702774763107, Final Batch Loss: 0.26590412855148315\n",
      "Epoch 4019, Loss: 1.0833821594715118, Final Batch Loss: 0.3721448481082916\n",
      "Epoch 4020, Loss: 0.9099925011396408, Final Batch Loss: 0.18746277689933777\n",
      "Epoch 4021, Loss: 0.9988668709993362, Final Batch Loss: 0.20509189367294312\n",
      "Epoch 4022, Loss: 1.0276259034872055, Final Batch Loss: 0.20005597174167633\n",
      "Epoch 4023, Loss: 1.107874557375908, Final Batch Loss: 0.28847652673721313\n",
      "Epoch 4024, Loss: 0.9121622294187546, Final Batch Loss: 0.18726703524589539\n",
      "Epoch 4025, Loss: 1.0482397824525833, Final Batch Loss: 0.39459723234176636\n",
      "Epoch 4026, Loss: 0.9632383733987808, Final Batch Loss: 0.2954365909099579\n",
      "Epoch 4027, Loss: 0.92762790620327, Final Batch Loss: 0.2622617781162262\n",
      "Epoch 4028, Loss: 1.1784986853599548, Final Batch Loss: 0.20841047167778015\n",
      "Epoch 4029, Loss: 1.0170562416315079, Final Batch Loss: 0.26957401633262634\n",
      "Epoch 4030, Loss: 1.0960946083068848, Final Batch Loss: 0.30641788244247437\n",
      "Epoch 4031, Loss: 1.0023708939552307, Final Batch Loss: 0.2769135534763336\n",
      "Epoch 4032, Loss: 0.9263847768306732, Final Batch Loss: 0.12286446988582611\n",
      "Epoch 4033, Loss: 0.9193629026412964, Final Batch Loss: 0.23468460142612457\n",
      "Epoch 4034, Loss: 1.0430116206407547, Final Batch Loss: 0.19309289753437042\n",
      "Epoch 4035, Loss: 0.9694739580154419, Final Batch Loss: 0.2384977638721466\n",
      "Epoch 4036, Loss: 0.97175632417202, Final Batch Loss: 0.2159712314605713\n",
      "Epoch 4037, Loss: 1.2492473125457764, Final Batch Loss: 0.22297164797782898\n",
      "Epoch 4038, Loss: 1.016487181186676, Final Batch Loss: 0.22253113985061646\n",
      "Epoch 4039, Loss: 1.124575436115265, Final Batch Loss: 0.25674039125442505\n",
      "Epoch 4040, Loss: 0.9391122907400131, Final Batch Loss: 0.1857917755842209\n",
      "Epoch 4041, Loss: 0.9596002101898193, Final Batch Loss: 0.2746276557445526\n",
      "Epoch 4042, Loss: 0.9780484288930893, Final Batch Loss: 0.2578698396682739\n",
      "Epoch 4043, Loss: 0.9739902913570404, Final Batch Loss: 0.22437240183353424\n",
      "Epoch 4044, Loss: 0.9678501188755035, Final Batch Loss: 0.26018965244293213\n",
      "Epoch 4045, Loss: 0.9855871349573135, Final Batch Loss: 0.264539510011673\n",
      "Epoch 4046, Loss: 1.0734576433897018, Final Batch Loss: 0.36812832951545715\n",
      "Epoch 4047, Loss: 1.163699209690094, Final Batch Loss: 0.2133786976337433\n",
      "Epoch 4048, Loss: 0.8428616523742676, Final Batch Loss: 0.18340905010700226\n",
      "Epoch 4049, Loss: 1.137559413909912, Final Batch Loss: 0.21431289613246918\n",
      "Epoch 4050, Loss: 1.0415039211511612, Final Batch Loss: 0.3139566481113434\n",
      "Epoch 4051, Loss: 1.0791940242052078, Final Batch Loss: 0.20832811295986176\n",
      "Epoch 4052, Loss: 1.142962098121643, Final Batch Loss: 0.2615356743335724\n",
      "Epoch 4053, Loss: 0.8370979577302933, Final Batch Loss: 0.1625298112630844\n",
      "Epoch 4054, Loss: 1.0290853530168533, Final Batch Loss: 0.15835314989089966\n",
      "Epoch 4055, Loss: 1.0983933955430984, Final Batch Loss: 0.2278500646352768\n",
      "Epoch 4056, Loss: 1.1034251004457474, Final Batch Loss: 0.3043114244937897\n",
      "Epoch 4057, Loss: 0.9878823012113571, Final Batch Loss: 0.31289178133010864\n",
      "Epoch 4058, Loss: 1.057408407330513, Final Batch Loss: 0.278408408164978\n",
      "Epoch 4059, Loss: 1.0778531432151794, Final Batch Loss: 0.38849303126335144\n",
      "Epoch 4060, Loss: 0.9344261884689331, Final Batch Loss: 0.2534410357475281\n",
      "Epoch 4061, Loss: 1.0530432909727097, Final Batch Loss: 0.23613357543945312\n",
      "Epoch 4062, Loss: 0.9942566007375717, Final Batch Loss: 0.26316577196121216\n",
      "Epoch 4063, Loss: 0.9664342999458313, Final Batch Loss: 0.17954111099243164\n",
      "Epoch 4064, Loss: 0.8809003531932831, Final Batch Loss: 0.1888648122549057\n",
      "Epoch 4065, Loss: 0.9154340177774429, Final Batch Loss: 0.2572253942489624\n",
      "Epoch 4066, Loss: 1.051987424492836, Final Batch Loss: 0.257766991853714\n",
      "Epoch 4067, Loss: 0.9138428866863251, Final Batch Loss: 0.17078830301761627\n",
      "Epoch 4068, Loss: 1.0509459972381592, Final Batch Loss: 0.33849984407424927\n",
      "Epoch 4069, Loss: 1.067388117313385, Final Batch Loss: 0.25557342171669006\n",
      "Epoch 4070, Loss: 0.8857880085706711, Final Batch Loss: 0.19513733685016632\n",
      "Epoch 4071, Loss: 1.0105960071086884, Final Batch Loss: 0.2967466115951538\n",
      "Epoch 4072, Loss: 1.1268397122621536, Final Batch Loss: 0.3985610008239746\n",
      "Epoch 4073, Loss: 1.002463310956955, Final Batch Loss: 0.25486043095588684\n",
      "Epoch 4074, Loss: 1.1716091483831406, Final Batch Loss: 0.33509403467178345\n",
      "Epoch 4075, Loss: 1.1709534227848053, Final Batch Loss: 0.3381718695163727\n",
      "Epoch 4076, Loss: 1.0906764268875122, Final Batch Loss: 0.301845908164978\n",
      "Epoch 4077, Loss: 0.8494395911693573, Final Batch Loss: 0.148042693734169\n",
      "Epoch 4078, Loss: 0.9532653093338013, Final Batch Loss: 0.21252667903900146\n",
      "Epoch 4079, Loss: 1.0011298656463623, Final Batch Loss: 0.21284602582454681\n",
      "Epoch 4080, Loss: 0.8727914690971375, Final Batch Loss: 0.20562557876110077\n",
      "Epoch 4081, Loss: 0.9779177159070969, Final Batch Loss: 0.22418023645877838\n",
      "Epoch 4082, Loss: 0.9171591550111771, Final Batch Loss: 0.20422278344631195\n",
      "Epoch 4083, Loss: 1.033137559890747, Final Batch Loss: 0.17727968096733093\n",
      "Epoch 4084, Loss: 1.019124612212181, Final Batch Loss: 0.27921047806739807\n",
      "Epoch 4085, Loss: 0.9158485680818558, Final Batch Loss: 0.17313708364963531\n",
      "Epoch 4086, Loss: 0.9611296206712723, Final Batch Loss: 0.2545156478881836\n",
      "Epoch 4087, Loss: 0.9190757572650909, Final Batch Loss: 0.16557231545448303\n",
      "Epoch 4088, Loss: 0.9607200026512146, Final Batch Loss: 0.2404172271490097\n",
      "Epoch 4089, Loss: 1.1433491706848145, Final Batch Loss: 0.3060203790664673\n",
      "Epoch 4090, Loss: 0.9902184903621674, Final Batch Loss: 0.15521040558815002\n",
      "Epoch 4091, Loss: 1.1364598274230957, Final Batch Loss: 0.35542306303977966\n",
      "Epoch 4092, Loss: 0.9943699985742569, Final Batch Loss: 0.22978118062019348\n",
      "Epoch 4093, Loss: 1.0455685406923294, Final Batch Loss: 0.3187132179737091\n",
      "Epoch 4094, Loss: 1.010940819978714, Final Batch Loss: 0.24206267297267914\n",
      "Epoch 4095, Loss: 1.0978767424821854, Final Batch Loss: 0.2783147990703583\n",
      "Epoch 4096, Loss: 0.9274132400751114, Final Batch Loss: 0.16127558052539825\n",
      "Epoch 4097, Loss: 0.9088334888219833, Final Batch Loss: 0.20101720094680786\n",
      "Epoch 4098, Loss: 0.9091701060533524, Final Batch Loss: 0.22652024030685425\n",
      "Epoch 4099, Loss: 0.9994705319404602, Final Batch Loss: 0.240319162607193\n",
      "Epoch 4100, Loss: 1.0062816441059113, Final Batch Loss: 0.21096369624137878\n",
      "Epoch 4101, Loss: 0.8401414304971695, Final Batch Loss: 0.14158007502555847\n",
      "Epoch 4102, Loss: 1.0083777010440826, Final Batch Loss: 0.21404269337654114\n",
      "Epoch 4103, Loss: 1.0330296456813812, Final Batch Loss: 0.19328565895557404\n",
      "Epoch 4104, Loss: 1.0331380516290665, Final Batch Loss: 0.19673658907413483\n",
      "Epoch 4105, Loss: 0.909186840057373, Final Batch Loss: 0.2448805570602417\n",
      "Epoch 4106, Loss: 1.1033666282892227, Final Batch Loss: 0.23241572082042694\n",
      "Epoch 4107, Loss: 1.052125632762909, Final Batch Loss: 0.21115835011005402\n",
      "Epoch 4108, Loss: 0.9605952203273773, Final Batch Loss: 0.2569720447063446\n",
      "Epoch 4109, Loss: 1.1818940192461014, Final Batch Loss: 0.28789374232292175\n",
      "Epoch 4110, Loss: 0.9916208684444427, Final Batch Loss: 0.31399261951446533\n",
      "Epoch 4111, Loss: 0.957048162817955, Final Batch Loss: 0.20150412619113922\n",
      "Epoch 4112, Loss: 0.9436694234609604, Final Batch Loss: 0.22667838633060455\n",
      "Epoch 4113, Loss: 1.020025447010994, Final Batch Loss: 0.22401820123195648\n",
      "Epoch 4114, Loss: 0.9966573417186737, Final Batch Loss: 0.15986980497837067\n",
      "Epoch 4115, Loss: 0.9189018160104752, Final Batch Loss: 0.194748654961586\n",
      "Epoch 4116, Loss: 1.0282594859600067, Final Batch Loss: 0.3094397485256195\n",
      "Epoch 4117, Loss: 0.8830002695322037, Final Batch Loss: 0.22384695708751678\n",
      "Epoch 4118, Loss: 0.8766875267028809, Final Batch Loss: 0.176117941737175\n",
      "Epoch 4119, Loss: 0.968530997633934, Final Batch Loss: 0.22889351844787598\n",
      "Epoch 4120, Loss: 0.9959485828876495, Final Batch Loss: 0.2055407464504242\n",
      "Epoch 4121, Loss: 1.033850833773613, Final Batch Loss: 0.29161131381988525\n",
      "Epoch 4122, Loss: 1.0796616077423096, Final Batch Loss: 0.3666534423828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4123, Loss: 1.122521534562111, Final Batch Loss: 0.4161459803581238\n",
      "Epoch 4124, Loss: 1.010108932852745, Final Batch Loss: 0.24522079527378082\n",
      "Epoch 4125, Loss: 0.9933147430419922, Final Batch Loss: 0.17395184934139252\n",
      "Epoch 4126, Loss: 1.1726720333099365, Final Batch Loss: 0.28868117928504944\n",
      "Epoch 4127, Loss: 1.2472181767225266, Final Batch Loss: 0.1760818511247635\n",
      "Epoch 4128, Loss: 1.0663668513298035, Final Batch Loss: 0.3292771875858307\n",
      "Epoch 4129, Loss: 1.1083357483148575, Final Batch Loss: 0.3006954491138458\n",
      "Epoch 4130, Loss: 0.8442431092262268, Final Batch Loss: 0.17700354754924774\n",
      "Epoch 4131, Loss: 1.2065216600894928, Final Batch Loss: 0.393314003944397\n",
      "Epoch 4132, Loss: 0.8989918231964111, Final Batch Loss: 0.15343910455703735\n",
      "Epoch 4133, Loss: 0.9629737585783005, Final Batch Loss: 0.1987399160861969\n",
      "Epoch 4134, Loss: 0.9747719019651413, Final Batch Loss: 0.25089919567108154\n",
      "Epoch 4135, Loss: 1.1419512182474136, Final Batch Loss: 0.2814672887325287\n",
      "Epoch 4136, Loss: 0.9824241250753403, Final Batch Loss: 0.21358661353588104\n",
      "Epoch 4137, Loss: 1.085764855146408, Final Batch Loss: 0.23140159249305725\n",
      "Epoch 4138, Loss: 1.050562009215355, Final Batch Loss: 0.3057539463043213\n",
      "Epoch 4139, Loss: 1.0725041031837463, Final Batch Loss: 0.31595808267593384\n",
      "Epoch 4140, Loss: 1.0131138116121292, Final Batch Loss: 0.21770869195461273\n",
      "Epoch 4141, Loss: 1.0370837301015854, Final Batch Loss: 0.21447309851646423\n",
      "Epoch 4142, Loss: 0.9115041643381119, Final Batch Loss: 0.2522388696670532\n",
      "Epoch 4143, Loss: 1.1126582473516464, Final Batch Loss: 0.24910737574100494\n",
      "Epoch 4144, Loss: 1.2068628519773483, Final Batch Loss: 0.39732950925827026\n",
      "Epoch 4145, Loss: 0.9650221765041351, Final Batch Loss: 0.28141218423843384\n",
      "Epoch 4146, Loss: 0.9449124485254288, Final Batch Loss: 0.22629143297672272\n",
      "Epoch 4147, Loss: 1.0707428306341171, Final Batch Loss: 0.2891281545162201\n",
      "Epoch 4148, Loss: 0.8969330340623856, Final Batch Loss: 0.18164458870887756\n",
      "Epoch 4149, Loss: 1.1107671409845352, Final Batch Loss: 0.37769636511802673\n",
      "Epoch 4150, Loss: 1.0371670126914978, Final Batch Loss: 0.26076552271842957\n",
      "Epoch 4151, Loss: 1.0442926436662674, Final Batch Loss: 0.20104345679283142\n",
      "Epoch 4152, Loss: 1.1190605759620667, Final Batch Loss: 0.34121400117874146\n",
      "Epoch 4153, Loss: 1.0090779513120651, Final Batch Loss: 0.19464614987373352\n",
      "Epoch 4154, Loss: 0.9151095151901245, Final Batch Loss: 0.1909313052892685\n",
      "Epoch 4155, Loss: 1.0469056367874146, Final Batch Loss: 0.2872560918331146\n",
      "Epoch 4156, Loss: 0.9164798855781555, Final Batch Loss: 0.18580974638462067\n",
      "Epoch 4157, Loss: 1.0043848156929016, Final Batch Loss: 0.23561663925647736\n",
      "Epoch 4158, Loss: 0.9038497358560562, Final Batch Loss: 0.22992949187755585\n",
      "Epoch 4159, Loss: 0.8680897653102875, Final Batch Loss: 0.24841228127479553\n",
      "Epoch 4160, Loss: 0.9616464972496033, Final Batch Loss: 0.2538999021053314\n",
      "Epoch 4161, Loss: 1.0301832109689713, Final Batch Loss: 0.27913597226142883\n",
      "Epoch 4162, Loss: 1.1045427322387695, Final Batch Loss: 0.2921055555343628\n",
      "Epoch 4163, Loss: 1.0303063988685608, Final Batch Loss: 0.1912429928779602\n",
      "Epoch 4164, Loss: 1.0587508380413055, Final Batch Loss: 0.25702813267707825\n",
      "Epoch 4165, Loss: 1.0194272100925446, Final Batch Loss: 0.2512722313404083\n",
      "Epoch 4166, Loss: 1.0974021703004837, Final Batch Loss: 0.2874841094017029\n",
      "Epoch 4167, Loss: 0.9305292516946793, Final Batch Loss: 0.20479558408260345\n",
      "Epoch 4168, Loss: 1.121972844004631, Final Batch Loss: 0.4014553725719452\n",
      "Epoch 4169, Loss: 0.9263171404600143, Final Batch Loss: 0.240424245595932\n",
      "Epoch 4170, Loss: 1.0244834572076797, Final Batch Loss: 0.2853267192840576\n",
      "Epoch 4171, Loss: 0.8150774240493774, Final Batch Loss: 0.16184909641742706\n",
      "Epoch 4172, Loss: 1.1164621859788895, Final Batch Loss: 0.23770032823085785\n",
      "Epoch 4173, Loss: 1.0734239667654037, Final Batch Loss: 0.38577356934547424\n",
      "Epoch 4174, Loss: 0.8339446038007736, Final Batch Loss: 0.15397191047668457\n",
      "Epoch 4175, Loss: 1.0672104805707932, Final Batch Loss: 0.23613117635250092\n",
      "Epoch 4176, Loss: 1.03345288336277, Final Batch Loss: 0.27319565415382385\n",
      "Epoch 4177, Loss: 0.8595678061246872, Final Batch Loss: 0.1826905608177185\n",
      "Epoch 4178, Loss: 1.108498826622963, Final Batch Loss: 0.25468116998672485\n",
      "Epoch 4179, Loss: 0.939383327960968, Final Batch Loss: 0.19743652641773224\n",
      "Epoch 4180, Loss: 1.0557482987642288, Final Batch Loss: 0.22025717794895172\n",
      "Epoch 4181, Loss: 1.0308284610509872, Final Batch Loss: 0.23821064829826355\n",
      "Epoch 4182, Loss: 0.9255447536706924, Final Batch Loss: 0.2024848908185959\n",
      "Epoch 4183, Loss: 1.3381820172071457, Final Batch Loss: 0.540493905544281\n",
      "Epoch 4184, Loss: 0.9970352500677109, Final Batch Loss: 0.22872291505336761\n",
      "Epoch 4185, Loss: 1.1537907868623734, Final Batch Loss: 0.3482900559902191\n",
      "Epoch 4186, Loss: 1.2101646065711975, Final Batch Loss: 0.4281518757343292\n",
      "Epoch 4187, Loss: 1.0013923943042755, Final Batch Loss: 0.2333734780550003\n",
      "Epoch 4188, Loss: 0.951106071472168, Final Batch Loss: 0.23571382462978363\n",
      "Epoch 4189, Loss: 1.1860603988170624, Final Batch Loss: 0.2805118262767792\n",
      "Epoch 4190, Loss: 0.9893991053104401, Final Batch Loss: 0.20131245255470276\n",
      "Epoch 4191, Loss: 0.9631132632493973, Final Batch Loss: 0.23049035668373108\n",
      "Epoch 4192, Loss: 0.9946619123220444, Final Batch Loss: 0.2558663785457611\n",
      "Epoch 4193, Loss: 0.985226109623909, Final Batch Loss: 0.30464932322502136\n",
      "Epoch 4194, Loss: 1.0563597232103348, Final Batch Loss: 0.3482075035572052\n",
      "Epoch 4195, Loss: 1.0540175586938858, Final Batch Loss: 0.1587165892124176\n",
      "Epoch 4196, Loss: 0.9989456981420517, Final Batch Loss: 0.17755484580993652\n",
      "Epoch 4197, Loss: 1.131399318575859, Final Batch Loss: 0.21437133848667145\n",
      "Epoch 4198, Loss: 1.0166012048721313, Final Batch Loss: 0.270582377910614\n",
      "Epoch 4199, Loss: 1.0598058700561523, Final Batch Loss: 0.32928305864334106\n",
      "Epoch 4200, Loss: 1.0439434796571732, Final Batch Loss: 0.2805616855621338\n",
      "Epoch 4201, Loss: 0.9393260478973389, Final Batch Loss: 0.23917904496192932\n",
      "Epoch 4202, Loss: 0.984181672334671, Final Batch Loss: 0.20120233297348022\n",
      "Epoch 4203, Loss: 1.147227019071579, Final Batch Loss: 0.2426375448703766\n",
      "Epoch 4204, Loss: 1.1233559399843216, Final Batch Loss: 0.1461256593465805\n",
      "Epoch 4205, Loss: 1.1142760217189789, Final Batch Loss: 0.2835504114627838\n",
      "Epoch 4206, Loss: 0.8837648332118988, Final Batch Loss: 0.18296003341674805\n",
      "Epoch 4207, Loss: 0.9935605823993683, Final Batch Loss: 0.1937527358531952\n",
      "Epoch 4208, Loss: 1.0630381405353546, Final Batch Loss: 0.2508014440536499\n",
      "Epoch 4209, Loss: 1.0641108006238937, Final Batch Loss: 0.250458300113678\n",
      "Epoch 4210, Loss: 0.9716598689556122, Final Batch Loss: 0.1968943476676941\n",
      "Epoch 4211, Loss: 1.065342515707016, Final Batch Loss: 0.2263857126235962\n",
      "Epoch 4212, Loss: 1.0272902250289917, Final Batch Loss: 0.31261298060417175\n",
      "Epoch 4213, Loss: 0.993272140622139, Final Batch Loss: 0.20803320407867432\n",
      "Epoch 4214, Loss: 1.1611174792051315, Final Batch Loss: 0.3466167151927948\n",
      "Epoch 4215, Loss: 0.9323862046003342, Final Batch Loss: 0.24890150129795074\n",
      "Epoch 4216, Loss: 0.7884712368249893, Final Batch Loss: 0.1894027292728424\n",
      "Epoch 4217, Loss: 1.0733614265918732, Final Batch Loss: 0.2290600687265396\n",
      "Epoch 4218, Loss: 0.978109285235405, Final Batch Loss: 0.20626035332679749\n",
      "Epoch 4219, Loss: 1.0374977886676788, Final Batch Loss: 0.2624509036540985\n",
      "Epoch 4220, Loss: 0.9195543974637985, Final Batch Loss: 0.23013341426849365\n",
      "Epoch 4221, Loss: 0.9881929159164429, Final Batch Loss: 0.23655010759830475\n",
      "Epoch 4222, Loss: 1.1193953454494476, Final Batch Loss: 0.27707570791244507\n",
      "Epoch 4223, Loss: 0.9519395977258682, Final Batch Loss: 0.23913933336734772\n",
      "Epoch 4224, Loss: 1.1674567461013794, Final Batch Loss: 0.30236849188804626\n",
      "Epoch 4225, Loss: 1.0265377908945084, Final Batch Loss: 0.2652905583381653\n",
      "Epoch 4226, Loss: 1.0357969105243683, Final Batch Loss: 0.21896646916866302\n",
      "Epoch 4227, Loss: 1.0531068742275238, Final Batch Loss: 0.21435780823230743\n",
      "Epoch 4228, Loss: 1.1467694342136383, Final Batch Loss: 0.28609612584114075\n",
      "Epoch 4229, Loss: 1.2646416425704956, Final Batch Loss: 0.4850645363330841\n",
      "Epoch 4230, Loss: 0.9464850723743439, Final Batch Loss: 0.3086394667625427\n",
      "Epoch 4231, Loss: 1.1435446590185165, Final Batch Loss: 0.28735628724098206\n",
      "Epoch 4232, Loss: 1.0919839143753052, Final Batch Loss: 0.32262206077575684\n",
      "Epoch 4233, Loss: 1.0069739073514938, Final Batch Loss: 0.2170039266347885\n",
      "Epoch 4234, Loss: 1.0342838019132614, Final Batch Loss: 0.2498427778482437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4235, Loss: 1.007820188999176, Final Batch Loss: 0.22221150994300842\n",
      "Epoch 4236, Loss: 0.9929035902023315, Final Batch Loss: 0.20523260533809662\n",
      "Epoch 4237, Loss: 1.0054176598787308, Final Batch Loss: 0.21613390743732452\n",
      "Epoch 4238, Loss: 0.8910714536905289, Final Batch Loss: 0.20049543678760529\n",
      "Epoch 4239, Loss: 0.8832796961069107, Final Batch Loss: 0.22916236519813538\n",
      "Epoch 4240, Loss: 1.0454995036125183, Final Batch Loss: 0.2505684494972229\n",
      "Epoch 4241, Loss: 1.0724831968545914, Final Batch Loss: 0.28633058071136475\n",
      "Epoch 4242, Loss: 0.9573487490415573, Final Batch Loss: 0.2511480450630188\n",
      "Epoch 4243, Loss: 0.9238635748624802, Final Batch Loss: 0.148788720369339\n",
      "Epoch 4244, Loss: 0.998514249920845, Final Batch Loss: 0.25694435834884644\n",
      "Epoch 4245, Loss: 1.0700238943099976, Final Batch Loss: 0.24086228013038635\n",
      "Epoch 4246, Loss: 0.9269959628582001, Final Batch Loss: 0.22300498187541962\n",
      "Epoch 4247, Loss: 1.0096350312232971, Final Batch Loss: 0.22798903286457062\n",
      "Epoch 4248, Loss: 1.0718469023704529, Final Batch Loss: 0.3300486207008362\n",
      "Epoch 4249, Loss: 1.0629762411117554, Final Batch Loss: 0.31040605902671814\n",
      "Epoch 4250, Loss: 0.9358148872852325, Final Batch Loss: 0.25530922412872314\n",
      "Epoch 4251, Loss: 1.0074506998062134, Final Batch Loss: 0.21796660125255585\n",
      "Epoch 4252, Loss: 1.1174925863742828, Final Batch Loss: 0.27087146043777466\n",
      "Epoch 4253, Loss: 1.1087424755096436, Final Batch Loss: 0.3595659136772156\n",
      "Epoch 4254, Loss: 1.2282438725233078, Final Batch Loss: 0.3773205578327179\n",
      "Epoch 4255, Loss: 1.1285319030284882, Final Batch Loss: 0.2576824724674225\n",
      "Epoch 4256, Loss: 1.0968604981899261, Final Batch Loss: 0.28771838545799255\n",
      "Epoch 4257, Loss: 0.8648167252540588, Final Batch Loss: 0.14548641443252563\n",
      "Epoch 4258, Loss: 1.0241346955299377, Final Batch Loss: 0.21416448056697845\n",
      "Epoch 4259, Loss: 1.0373032838106155, Final Batch Loss: 0.3233501613140106\n",
      "Epoch 4260, Loss: 1.0119062662124634, Final Batch Loss: 0.2428131252527237\n",
      "Epoch 4261, Loss: 0.9913662523031235, Final Batch Loss: 0.23222030699253082\n",
      "Epoch 4262, Loss: 1.0947940796613693, Final Batch Loss: 0.3302731513977051\n",
      "Epoch 4263, Loss: 1.1141254156827927, Final Batch Loss: 0.23975087702274323\n",
      "Epoch 4264, Loss: 1.1513128727674484, Final Batch Loss: 0.3689199388027191\n",
      "Epoch 4265, Loss: 1.1085692644119263, Final Batch Loss: 0.26737913489341736\n",
      "Epoch 4266, Loss: 1.072458192706108, Final Batch Loss: 0.2247082144021988\n",
      "Epoch 4267, Loss: 1.1052796244621277, Final Batch Loss: 0.33676302433013916\n",
      "Epoch 4268, Loss: 0.9711916744709015, Final Batch Loss: 0.2580711841583252\n",
      "Epoch 4269, Loss: 1.1998088210821152, Final Batch Loss: 0.375641405582428\n",
      "Epoch 4270, Loss: 0.9902965575456619, Final Batch Loss: 0.18071532249450684\n",
      "Epoch 4271, Loss: 1.0273651480674744, Final Batch Loss: 0.3427847921848297\n",
      "Epoch 4272, Loss: 0.9874186962842941, Final Batch Loss: 0.18791259825229645\n",
      "Epoch 4273, Loss: 1.2740506082773209, Final Batch Loss: 0.4021785259246826\n",
      "Epoch 4274, Loss: 0.8667111098766327, Final Batch Loss: 0.19650156795978546\n",
      "Epoch 4275, Loss: 1.007294774055481, Final Batch Loss: 0.25228962302207947\n",
      "Epoch 4276, Loss: 1.0542045682668686, Final Batch Loss: 0.22291521728038788\n",
      "Epoch 4277, Loss: 1.0639750212430954, Final Batch Loss: 0.30552002787590027\n",
      "Epoch 4278, Loss: 1.0151487588882446, Final Batch Loss: 0.2692811191082001\n",
      "Epoch 4279, Loss: 1.1904283463954926, Final Batch Loss: 0.3807622790336609\n",
      "Epoch 4280, Loss: 0.9210020005702972, Final Batch Loss: 0.2195926457643509\n",
      "Epoch 4281, Loss: 1.0390793234109879, Final Batch Loss: 0.24635151028633118\n",
      "Epoch 4282, Loss: 0.9528026878833771, Final Batch Loss: 0.28673985600471497\n",
      "Epoch 4283, Loss: 1.0011094957590103, Final Batch Loss: 0.24633122980594635\n",
      "Epoch 4284, Loss: 1.0929616838693619, Final Batch Loss: 0.26426053047180176\n",
      "Epoch 4285, Loss: 1.2665285468101501, Final Batch Loss: 0.4787067770957947\n",
      "Epoch 4286, Loss: 0.9436570554971695, Final Batch Loss: 0.24962873756885529\n",
      "Epoch 4287, Loss: 0.9781228750944138, Final Batch Loss: 0.2361232191324234\n",
      "Epoch 4288, Loss: 1.0384591221809387, Final Batch Loss: 0.1907268464565277\n",
      "Epoch 4289, Loss: 0.8119165897369385, Final Batch Loss: 0.17417769134044647\n",
      "Epoch 4290, Loss: 1.124273031949997, Final Batch Loss: 0.42032110691070557\n",
      "Epoch 4291, Loss: 1.1204843074083328, Final Batch Loss: 0.2355843186378479\n",
      "Epoch 4292, Loss: 1.0591432750225067, Final Batch Loss: 0.2592076063156128\n",
      "Epoch 4293, Loss: 0.9997320622205734, Final Batch Loss: 0.24674692749977112\n",
      "Epoch 4294, Loss: 1.0801727175712585, Final Batch Loss: 0.2687318027019501\n",
      "Epoch 4295, Loss: 1.0270139276981354, Final Batch Loss: 0.20883634686470032\n",
      "Epoch 4296, Loss: 1.0300709307193756, Final Batch Loss: 0.20324699580669403\n",
      "Epoch 4297, Loss: 1.061903327703476, Final Batch Loss: 0.26518532633781433\n",
      "Epoch 4298, Loss: 1.0314442962408066, Final Batch Loss: 0.19500912725925446\n",
      "Epoch 4299, Loss: 1.0622039884328842, Final Batch Loss: 0.17591606080532074\n",
      "Epoch 4300, Loss: 1.1245248317718506, Final Batch Loss: 0.31359341740608215\n",
      "Epoch 4301, Loss: 1.2037653028964996, Final Batch Loss: 0.3670557737350464\n",
      "Epoch 4302, Loss: 0.9680743515491486, Final Batch Loss: 0.2187773436307907\n",
      "Epoch 4303, Loss: 0.927418053150177, Final Batch Loss: 0.16934418678283691\n",
      "Epoch 4304, Loss: 0.9362182170152664, Final Batch Loss: 0.2191416323184967\n",
      "Epoch 4305, Loss: 0.9815529882907867, Final Batch Loss: 0.30819177627563477\n",
      "Epoch 4306, Loss: 0.9959898442029953, Final Batch Loss: 0.2744338810443878\n",
      "Epoch 4307, Loss: 0.9529969692230225, Final Batch Loss: 0.24400486052036285\n",
      "Epoch 4308, Loss: 0.9151641279459, Final Batch Loss: 0.17524264752864838\n",
      "Epoch 4309, Loss: 1.1142140924930573, Final Batch Loss: 0.29186317324638367\n",
      "Epoch 4310, Loss: 1.2150917947292328, Final Batch Loss: 0.37200620770454407\n",
      "Epoch 4311, Loss: 0.9842810034751892, Final Batch Loss: 0.21071498095989227\n",
      "Epoch 4312, Loss: 1.0355305671691895, Final Batch Loss: 0.2606033384799957\n",
      "Epoch 4313, Loss: 1.0192433148622513, Final Batch Loss: 0.26451703906059265\n",
      "Epoch 4314, Loss: 1.1954556554555893, Final Batch Loss: 0.3054603934288025\n",
      "Epoch 4315, Loss: 1.0737645775079727, Final Batch Loss: 0.3370554447174072\n",
      "Epoch 4316, Loss: 1.0729409754276276, Final Batch Loss: 0.20635269582271576\n",
      "Epoch 4317, Loss: 0.9822764992713928, Final Batch Loss: 0.21285751461982727\n",
      "Epoch 4318, Loss: 1.0091931819915771, Final Batch Loss: 0.19493405520915985\n",
      "Epoch 4319, Loss: 0.9772283881902695, Final Batch Loss: 0.2254273146390915\n",
      "Epoch 4320, Loss: 1.0428136885166168, Final Batch Loss: 0.26151955127716064\n",
      "Epoch 4321, Loss: 0.9101992547512054, Final Batch Loss: 0.18102742731571198\n",
      "Epoch 4322, Loss: 0.9675340056419373, Final Batch Loss: 0.2690977156162262\n",
      "Epoch 4323, Loss: 0.8417460918426514, Final Batch Loss: 0.14416155219078064\n",
      "Epoch 4324, Loss: 0.8933740705251694, Final Batch Loss: 0.1593385487794876\n",
      "Epoch 4325, Loss: 0.9467128068208694, Final Batch Loss: 0.26140207052230835\n",
      "Epoch 4326, Loss: 0.8607011586427689, Final Batch Loss: 0.19965630769729614\n",
      "Epoch 4327, Loss: 0.9178437292575836, Final Batch Loss: 0.20101645588874817\n",
      "Epoch 4328, Loss: 1.0265312641859055, Final Batch Loss: 0.3685861825942993\n",
      "Epoch 4329, Loss: 1.0187644213438034, Final Batch Loss: 0.3385396897792816\n",
      "Epoch 4330, Loss: 1.072963461279869, Final Batch Loss: 0.2869889736175537\n",
      "Epoch 4331, Loss: 0.9202661067247391, Final Batch Loss: 0.26771289110183716\n",
      "Epoch 4332, Loss: 0.9038012474775314, Final Batch Loss: 0.18465375900268555\n",
      "Epoch 4333, Loss: 1.0802253037691116, Final Batch Loss: 0.21820518374443054\n",
      "Epoch 4334, Loss: 0.9813477993011475, Final Batch Loss: 0.246474951505661\n",
      "Epoch 4335, Loss: 1.0559888184070587, Final Batch Loss: 0.26571381092071533\n",
      "Epoch 4336, Loss: 1.2351530343294144, Final Batch Loss: 0.30610141158103943\n",
      "Epoch 4337, Loss: 1.1417987495660782, Final Batch Loss: 0.2960556745529175\n",
      "Epoch 4338, Loss: 1.1019056290388107, Final Batch Loss: 0.31534668803215027\n",
      "Epoch 4339, Loss: 1.0186491757631302, Final Batch Loss: 0.2622022032737732\n",
      "Epoch 4340, Loss: 0.9888754040002823, Final Batch Loss: 0.21743826568126678\n",
      "Epoch 4341, Loss: 1.0430286973714828, Final Batch Loss: 0.2865374684333801\n",
      "Epoch 4342, Loss: 0.9221750795841217, Final Batch Loss: 0.2987007200717926\n",
      "Epoch 4343, Loss: 0.9791145920753479, Final Batch Loss: 0.18700961768627167\n",
      "Epoch 4344, Loss: 1.2647291123867035, Final Batch Loss: 0.3520149886608124\n",
      "Epoch 4345, Loss: 1.069368988275528, Final Batch Loss: 0.3096221089363098\n",
      "Epoch 4346, Loss: 0.9532736837863922, Final Batch Loss: 0.24431069195270538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4347, Loss: 1.1002860069274902, Final Batch Loss: 0.34683793783187866\n",
      "Epoch 4348, Loss: 0.9907602369785309, Final Batch Loss: 0.2741285562515259\n",
      "Epoch 4349, Loss: 0.9724290370941162, Final Batch Loss: 0.2898266017436981\n",
      "Epoch 4350, Loss: 1.0364887118339539, Final Batch Loss: 0.2914141118526459\n",
      "Epoch 4351, Loss: 1.0193660706281662, Final Batch Loss: 0.35478347539901733\n",
      "Epoch 4352, Loss: 1.0678273290395737, Final Batch Loss: 0.2894076704978943\n",
      "Epoch 4353, Loss: 0.9470248073339462, Final Batch Loss: 0.2606496214866638\n",
      "Epoch 4354, Loss: 1.034235417842865, Final Batch Loss: 0.2866658568382263\n",
      "Epoch 4355, Loss: 0.8693493753671646, Final Batch Loss: 0.20888249576091766\n",
      "Epoch 4356, Loss: 0.9786735624074936, Final Batch Loss: 0.26317301392555237\n",
      "Epoch 4357, Loss: 0.8685349375009537, Final Batch Loss: 0.23202992975711823\n",
      "Epoch 4358, Loss: 0.9998577684164047, Final Batch Loss: 0.31623929738998413\n",
      "Epoch 4359, Loss: 0.9535883814096451, Final Batch Loss: 0.24320833384990692\n",
      "Epoch 4360, Loss: 0.9394750446081161, Final Batch Loss: 0.1845843344926834\n",
      "Epoch 4361, Loss: 1.0431901812553406, Final Batch Loss: 0.32011938095092773\n",
      "Epoch 4362, Loss: 1.0526253134012222, Final Batch Loss: 0.339783251285553\n",
      "Epoch 4363, Loss: 0.9158196151256561, Final Batch Loss: 0.23024067282676697\n",
      "Epoch 4364, Loss: 1.0403096079826355, Final Batch Loss: 0.25797709822654724\n",
      "Epoch 4365, Loss: 0.9511339366436005, Final Batch Loss: 0.21808430552482605\n",
      "Epoch 4366, Loss: 1.1363483220338821, Final Batch Loss: 0.336276650428772\n",
      "Epoch 4367, Loss: 0.9802278280258179, Final Batch Loss: 0.2865371108055115\n",
      "Epoch 4368, Loss: 1.0149853229522705, Final Batch Loss: 0.2823267877101898\n",
      "Epoch 4369, Loss: 0.904214397072792, Final Batch Loss: 0.2651757001876831\n",
      "Epoch 4370, Loss: 1.0005814284086227, Final Batch Loss: 0.2774251401424408\n",
      "Epoch 4371, Loss: 1.0077000260353088, Final Batch Loss: 0.28617918491363525\n",
      "Epoch 4372, Loss: 1.0456907749176025, Final Batch Loss: 0.25555887818336487\n",
      "Epoch 4373, Loss: 0.9546657204627991, Final Batch Loss: 0.17590780556201935\n",
      "Epoch 4374, Loss: 0.8841198980808258, Final Batch Loss: 0.16418008506298065\n",
      "Epoch 4375, Loss: 1.0837002992630005, Final Batch Loss: 0.30461385846138\n",
      "Epoch 4376, Loss: 1.219195693731308, Final Batch Loss: 0.3918149471282959\n",
      "Epoch 4377, Loss: 1.0514661818742752, Final Batch Loss: 0.2505267262458801\n",
      "Epoch 4378, Loss: 1.0106851905584335, Final Batch Loss: 0.264885812997818\n",
      "Epoch 4379, Loss: 1.0471271872520447, Final Batch Loss: 0.38220155239105225\n",
      "Epoch 4380, Loss: 1.0554224401712418, Final Batch Loss: 0.2875151038169861\n",
      "Epoch 4381, Loss: 0.8823055773973465, Final Batch Loss: 0.1829424798488617\n",
      "Epoch 4382, Loss: 1.1171875, Final Batch Loss: 0.37355858087539673\n",
      "Epoch 4383, Loss: 0.9358396679162979, Final Batch Loss: 0.1670701503753662\n",
      "Epoch 4384, Loss: 1.1444593667984009, Final Batch Loss: 0.3625056743621826\n",
      "Epoch 4385, Loss: 0.9851448684930801, Final Batch Loss: 0.335375040769577\n",
      "Epoch 4386, Loss: 1.1180517375469208, Final Batch Loss: 0.24840767681598663\n",
      "Epoch 4387, Loss: 0.8745524436235428, Final Batch Loss: 0.20002013444900513\n",
      "Epoch 4388, Loss: 1.120889127254486, Final Batch Loss: 0.24371519684791565\n",
      "Epoch 4389, Loss: 1.0486498028039932, Final Batch Loss: 0.2708246409893036\n",
      "Epoch 4390, Loss: 1.096108764410019, Final Batch Loss: 0.2308013141155243\n",
      "Epoch 4391, Loss: 1.0387562662363052, Final Batch Loss: 0.3125072419643402\n",
      "Epoch 4392, Loss: 1.0236625969409943, Final Batch Loss: 0.24411934614181519\n",
      "Epoch 4393, Loss: 0.886303722858429, Final Batch Loss: 0.22166205942630768\n",
      "Epoch 4394, Loss: 0.9648802429437637, Final Batch Loss: 0.23128536343574524\n",
      "Epoch 4395, Loss: 0.9867976307868958, Final Batch Loss: 0.24974972009658813\n",
      "Epoch 4396, Loss: 0.9932759255170822, Final Batch Loss: 0.19593046605587006\n",
      "Epoch 4397, Loss: 1.0440558195114136, Final Batch Loss: 0.33739954233169556\n",
      "Epoch 4398, Loss: 1.0371508747339249, Final Batch Loss: 0.27641433477401733\n",
      "Epoch 4399, Loss: 1.0092593133449554, Final Batch Loss: 0.27833688259124756\n",
      "Epoch 4400, Loss: 0.9440588057041168, Final Batch Loss: 0.2144341766834259\n",
      "Epoch 4401, Loss: 0.8637610077857971, Final Batch Loss: 0.2204550951719284\n",
      "Epoch 4402, Loss: 0.9841369539499283, Final Batch Loss: 0.2199862152338028\n",
      "Epoch 4403, Loss: 1.1452590972185135, Final Batch Loss: 0.2541271448135376\n",
      "Epoch 4404, Loss: 0.9368064403533936, Final Batch Loss: 0.17503683269023895\n",
      "Epoch 4405, Loss: 1.184727504849434, Final Batch Loss: 0.3646717965602875\n",
      "Epoch 4406, Loss: 0.9680162221193314, Final Batch Loss: 0.20046845078468323\n",
      "Epoch 4407, Loss: 0.9754506647586823, Final Batch Loss: 0.24712295830249786\n",
      "Epoch 4408, Loss: 1.1404817253351212, Final Batch Loss: 0.3747161030769348\n",
      "Epoch 4409, Loss: 1.019288569688797, Final Batch Loss: 0.19873465597629547\n",
      "Epoch 4410, Loss: 1.0560667961835861, Final Batch Loss: 0.17326201498508453\n",
      "Epoch 4411, Loss: 0.98549385368824, Final Batch Loss: 0.22053839266300201\n",
      "Epoch 4412, Loss: 1.0381286889314651, Final Batch Loss: 0.1904028207063675\n",
      "Epoch 4413, Loss: 1.105622872710228, Final Batch Loss: 0.34956929087638855\n",
      "Epoch 4414, Loss: 1.0899064093828201, Final Batch Loss: 0.43690651655197144\n",
      "Epoch 4415, Loss: 1.085494801402092, Final Batch Loss: 0.2548242211341858\n",
      "Epoch 4416, Loss: 0.9057740122079849, Final Batch Loss: 0.21545523405075073\n",
      "Epoch 4417, Loss: 1.0556301176548004, Final Batch Loss: 0.2607978284358978\n",
      "Epoch 4418, Loss: 0.9542337357997894, Final Batch Loss: 0.25302815437316895\n",
      "Epoch 4419, Loss: 0.983054593205452, Final Batch Loss: 0.25780221819877625\n",
      "Epoch 4420, Loss: 1.027921661734581, Final Batch Loss: 0.28087863326072693\n",
      "Epoch 4421, Loss: 1.041308045387268, Final Batch Loss: 0.24736100435256958\n",
      "Epoch 4422, Loss: 1.0527077466249466, Final Batch Loss: 0.24797791242599487\n",
      "Epoch 4423, Loss: 0.9742935448884964, Final Batch Loss: 0.2574343681335449\n",
      "Epoch 4424, Loss: 0.9956490248441696, Final Batch Loss: 0.2533847987651825\n",
      "Epoch 4425, Loss: 1.0040683299303055, Final Batch Loss: 0.2538847029209137\n",
      "Epoch 4426, Loss: 0.9440510421991348, Final Batch Loss: 0.2162604182958603\n",
      "Epoch 4427, Loss: 1.0893684476613998, Final Batch Loss: 0.22156129777431488\n",
      "Epoch 4428, Loss: 0.9605990648269653, Final Batch Loss: 0.2382039874792099\n",
      "Epoch 4429, Loss: 0.9996698051691055, Final Batch Loss: 0.3079606890678406\n",
      "Epoch 4430, Loss: 0.8781551420688629, Final Batch Loss: 0.1860698014497757\n",
      "Epoch 4431, Loss: 0.8621211498975754, Final Batch Loss: 0.18548229336738586\n",
      "Epoch 4432, Loss: 1.0418400764465332, Final Batch Loss: 0.23020552098751068\n",
      "Epoch 4433, Loss: 0.9956912249326706, Final Batch Loss: 0.17242345213890076\n",
      "Epoch 4434, Loss: 1.0325758159160614, Final Batch Loss: 0.22350600361824036\n",
      "Epoch 4435, Loss: 0.9575473368167877, Final Batch Loss: 0.2582301199436188\n",
      "Epoch 4436, Loss: 0.9410664439201355, Final Batch Loss: 0.23832523822784424\n",
      "Epoch 4437, Loss: 1.0339151173830032, Final Batch Loss: 0.1995033472776413\n",
      "Epoch 4438, Loss: 0.9567841738462448, Final Batch Loss: 0.2327730357646942\n",
      "Epoch 4439, Loss: 0.9693249464035034, Final Batch Loss: 0.24182727932929993\n",
      "Epoch 4440, Loss: 0.8648237884044647, Final Batch Loss: 0.24219106137752533\n",
      "Epoch 4441, Loss: 1.0323887467384338, Final Batch Loss: 0.2053220570087433\n",
      "Epoch 4442, Loss: 0.985655203461647, Final Batch Loss: 0.20932577550411224\n",
      "Epoch 4443, Loss: 0.9261988401412964, Final Batch Loss: 0.3071242570877075\n",
      "Epoch 4444, Loss: 1.0573585629463196, Final Batch Loss: 0.2588210105895996\n",
      "Epoch 4445, Loss: 1.1136770248413086, Final Batch Loss: 0.33575448393821716\n",
      "Epoch 4446, Loss: 1.0491261780261993, Final Batch Loss: 0.2922775149345398\n",
      "Epoch 4447, Loss: 1.1176136583089828, Final Batch Loss: 0.2678597569465637\n",
      "Epoch 4448, Loss: 0.9699359089136124, Final Batch Loss: 0.1543320268392563\n",
      "Epoch 4449, Loss: 1.0331154316663742, Final Batch Loss: 0.229895681142807\n",
      "Epoch 4450, Loss: 1.081944316625595, Final Batch Loss: 0.3386717438697815\n",
      "Epoch 4451, Loss: 0.9378639459609985, Final Batch Loss: 0.16260430216789246\n",
      "Epoch 4452, Loss: 1.1569079160690308, Final Batch Loss: 0.34304094314575195\n",
      "Epoch 4453, Loss: 0.9898160099983215, Final Batch Loss: 0.2994966208934784\n",
      "Epoch 4454, Loss: 1.072577953338623, Final Batch Loss: 0.24805301427841187\n",
      "Epoch 4455, Loss: 0.9076070040464401, Final Batch Loss: 0.18264468014240265\n",
      "Epoch 4456, Loss: 1.0917314141988754, Final Batch Loss: 0.43981027603149414\n",
      "Epoch 4457, Loss: 0.9072279036045074, Final Batch Loss: 0.2308340221643448\n",
      "Epoch 4458, Loss: 1.0708881169557571, Final Batch Loss: 0.2397078424692154\n",
      "Epoch 4459, Loss: 0.9823321402072906, Final Batch Loss: 0.1886374056339264\n",
      "Epoch 4460, Loss: 0.9523741602897644, Final Batch Loss: 0.29858314990997314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4461, Loss: 0.9198978692293167, Final Batch Loss: 0.2627718448638916\n",
      "Epoch 4462, Loss: 0.9411504566669464, Final Batch Loss: 0.2656466066837311\n",
      "Epoch 4463, Loss: 0.9544029533863068, Final Batch Loss: 0.22422342002391815\n",
      "Epoch 4464, Loss: 1.023260846734047, Final Batch Loss: 0.239740788936615\n",
      "Epoch 4465, Loss: 0.9649959057569504, Final Batch Loss: 0.2620237469673157\n",
      "Epoch 4466, Loss: 1.0557481795549393, Final Batch Loss: 0.27951183915138245\n",
      "Epoch 4467, Loss: 0.9061347246170044, Final Batch Loss: 0.26471421122550964\n",
      "Epoch 4468, Loss: 0.9815859645605087, Final Batch Loss: 0.21729245781898499\n",
      "Epoch 4469, Loss: 1.087326243519783, Final Batch Loss: 0.2307257205247879\n",
      "Epoch 4470, Loss: 0.9766454696655273, Final Batch Loss: 0.20744003355503082\n",
      "Epoch 4471, Loss: 1.0343541502952576, Final Batch Loss: 0.2528461217880249\n",
      "Epoch 4472, Loss: 1.0736842602491379, Final Batch Loss: 0.2332950085401535\n",
      "Epoch 4473, Loss: 0.9690720736980438, Final Batch Loss: 0.22153174877166748\n",
      "Epoch 4474, Loss: 0.9726753085851669, Final Batch Loss: 0.25560277700424194\n",
      "Epoch 4475, Loss: 0.9865800887346268, Final Batch Loss: 0.23011082410812378\n",
      "Epoch 4476, Loss: 0.9745945185422897, Final Batch Loss: 0.25794339179992676\n",
      "Epoch 4477, Loss: 1.0703124552965164, Final Batch Loss: 0.28091174364089966\n",
      "Epoch 4478, Loss: 1.002544179558754, Final Batch Loss: 0.27507731318473816\n",
      "Epoch 4479, Loss: 0.9256700575351715, Final Batch Loss: 0.23481899499893188\n",
      "Epoch 4480, Loss: 1.0595281273126602, Final Batch Loss: 0.32662707567214966\n",
      "Epoch 4481, Loss: 0.9410977810621262, Final Batch Loss: 0.28933578729629517\n",
      "Epoch 4482, Loss: 1.0523051768541336, Final Batch Loss: 0.273682177066803\n",
      "Epoch 4483, Loss: 0.86360964179039, Final Batch Loss: 0.15483242273330688\n",
      "Epoch 4484, Loss: 0.9559750705957413, Final Batch Loss: 0.20645974576473236\n",
      "Epoch 4485, Loss: 1.0477885901927948, Final Batch Loss: 0.3790017068386078\n",
      "Epoch 4486, Loss: 0.9881018102169037, Final Batch Loss: 0.1693444848060608\n",
      "Epoch 4487, Loss: 0.9462864696979523, Final Batch Loss: 0.20902606844902039\n",
      "Epoch 4488, Loss: 1.024558201432228, Final Batch Loss: 0.28813058137893677\n",
      "Epoch 4489, Loss: 1.033960074186325, Final Batch Loss: 0.2666317820549011\n",
      "Epoch 4490, Loss: 0.8724215775728226, Final Batch Loss: 0.15248988568782806\n",
      "Epoch 4491, Loss: 1.0317621231079102, Final Batch Loss: 0.2855106294155121\n",
      "Epoch 4492, Loss: 1.0082053989171982, Final Batch Loss: 0.16266892850399017\n",
      "Epoch 4493, Loss: 0.9922486990690231, Final Batch Loss: 0.26569172739982605\n",
      "Epoch 4494, Loss: 0.9155602008104324, Final Batch Loss: 0.225600928068161\n",
      "Epoch 4495, Loss: 0.8504922240972519, Final Batch Loss: 0.17091450095176697\n",
      "Epoch 4496, Loss: 0.9369091987609863, Final Batch Loss: 0.2146780639886856\n",
      "Epoch 4497, Loss: 1.0818906128406525, Final Batch Loss: 0.2051999270915985\n",
      "Epoch 4498, Loss: 0.9596023261547089, Final Batch Loss: 0.23386238515377045\n",
      "Epoch 4499, Loss: 1.0297776013612747, Final Batch Loss: 0.30554550886154175\n",
      "Epoch 4500, Loss: 0.9709553271532059, Final Batch Loss: 0.19598448276519775\n",
      "Epoch 4501, Loss: 0.9452594220638275, Final Batch Loss: 0.20108026266098022\n",
      "Epoch 4502, Loss: 1.0138190984725952, Final Batch Loss: 0.19626149535179138\n",
      "Epoch 4503, Loss: 0.8566609919071198, Final Batch Loss: 0.2362935096025467\n",
      "Epoch 4504, Loss: 0.8828418403863907, Final Batch Loss: 0.20033420622348785\n",
      "Epoch 4505, Loss: 0.8897758573293686, Final Batch Loss: 0.2500627934932709\n",
      "Epoch 4506, Loss: 1.0527877062559128, Final Batch Loss: 0.3476700484752655\n",
      "Epoch 4507, Loss: 0.971006914973259, Final Batch Loss: 0.24268792569637299\n",
      "Epoch 4508, Loss: 0.9176084995269775, Final Batch Loss: 0.20384187996387482\n",
      "Epoch 4509, Loss: 1.007793366909027, Final Batch Loss: 0.24521504342556\n",
      "Epoch 4510, Loss: 1.0657075494527817, Final Batch Loss: 0.28908708691596985\n",
      "Epoch 4511, Loss: 0.9829349219799042, Final Batch Loss: 0.2775571048259735\n",
      "Epoch 4512, Loss: 0.840412512421608, Final Batch Loss: 0.16656942665576935\n",
      "Epoch 4513, Loss: 0.8975434452295303, Final Batch Loss: 0.22303685545921326\n",
      "Epoch 4514, Loss: 0.9344567656517029, Final Batch Loss: 0.18476535379886627\n",
      "Epoch 4515, Loss: 1.008934646844864, Final Batch Loss: 0.29717835783958435\n",
      "Epoch 4516, Loss: 0.9453399628400803, Final Batch Loss: 0.30485451221466064\n",
      "Epoch 4517, Loss: 1.0942699015140533, Final Batch Loss: 0.35712987184524536\n",
      "Epoch 4518, Loss: 0.9098916500806808, Final Batch Loss: 0.18997618556022644\n",
      "Epoch 4519, Loss: 0.9320835173130035, Final Batch Loss: 0.12519977986812592\n",
      "Epoch 4520, Loss: 1.0685684233903885, Final Batch Loss: 0.2812380790710449\n",
      "Epoch 4521, Loss: 1.366954743862152, Final Batch Loss: 0.4210035502910614\n",
      "Epoch 4522, Loss: 1.0253603160381317, Final Batch Loss: 0.22033557295799255\n",
      "Epoch 4523, Loss: 1.101374864578247, Final Batch Loss: 0.32629328966140747\n",
      "Epoch 4524, Loss: 1.100328117609024, Final Batch Loss: 0.2806420624256134\n",
      "Epoch 4525, Loss: 0.9768993258476257, Final Batch Loss: 0.1940581202507019\n",
      "Epoch 4526, Loss: 0.9288363456726074, Final Batch Loss: 0.21176984906196594\n",
      "Epoch 4527, Loss: 0.8965341150760651, Final Batch Loss: 0.1703433245420456\n",
      "Epoch 4528, Loss: 0.8707173764705658, Final Batch Loss: 0.16510745882987976\n",
      "Epoch 4529, Loss: 0.9698788374662399, Final Batch Loss: 0.31151485443115234\n",
      "Epoch 4530, Loss: 1.0346407294273376, Final Batch Loss: 0.2833053469657898\n",
      "Epoch 4531, Loss: 1.0798370838165283, Final Batch Loss: 0.3046557903289795\n",
      "Epoch 4532, Loss: 0.9338110536336899, Final Batch Loss: 0.2772951126098633\n",
      "Epoch 4533, Loss: 0.8935594409704208, Final Batch Loss: 0.157260462641716\n",
      "Epoch 4534, Loss: 0.9304655939340591, Final Batch Loss: 0.2581162452697754\n",
      "Epoch 4535, Loss: 0.9232559353113174, Final Batch Loss: 0.28302058577537537\n",
      "Epoch 4536, Loss: 1.0032357722520828, Final Batch Loss: 0.31025874614715576\n",
      "Epoch 4537, Loss: 0.9155184328556061, Final Batch Loss: 0.2089613974094391\n",
      "Epoch 4538, Loss: 1.0554869621992111, Final Batch Loss: 0.3309863805770874\n",
      "Epoch 4539, Loss: 1.0234447121620178, Final Batch Loss: 0.20517097413539886\n",
      "Epoch 4540, Loss: 0.8653982281684875, Final Batch Loss: 0.20507532358169556\n",
      "Epoch 4541, Loss: 1.0468306988477707, Final Batch Loss: 0.305044561624527\n",
      "Epoch 4542, Loss: 0.9358837902545929, Final Batch Loss: 0.19743308424949646\n",
      "Epoch 4543, Loss: 1.0086533427238464, Final Batch Loss: 0.2035333514213562\n",
      "Epoch 4544, Loss: 0.8992713540792465, Final Batch Loss: 0.15921512246131897\n",
      "Epoch 4545, Loss: 1.0091751664876938, Final Batch Loss: 0.21804796159267426\n",
      "Epoch 4546, Loss: 1.1326877027750015, Final Batch Loss: 0.3669813871383667\n",
      "Epoch 4547, Loss: 1.08132304251194, Final Batch Loss: 0.34417009353637695\n",
      "Epoch 4548, Loss: 0.9904283732175827, Final Batch Loss: 0.26101192831993103\n",
      "Epoch 4549, Loss: 0.9630644619464874, Final Batch Loss: 0.21366338431835175\n",
      "Epoch 4550, Loss: 0.9087154269218445, Final Batch Loss: 0.25756484270095825\n",
      "Epoch 4551, Loss: 1.0606392472982407, Final Batch Loss: 0.24513037502765656\n",
      "Epoch 4552, Loss: 0.9216292351484299, Final Batch Loss: 0.2503718137741089\n",
      "Epoch 4553, Loss: 1.0899954438209534, Final Batch Loss: 0.16095373034477234\n",
      "Epoch 4554, Loss: 1.0195974260568619, Final Batch Loss: 0.27794012427330017\n",
      "Epoch 4555, Loss: 1.0468692779541016, Final Batch Loss: 0.32990673184394836\n",
      "Epoch 4556, Loss: 0.9894408583641052, Final Batch Loss: 0.20335650444030762\n",
      "Epoch 4557, Loss: 1.2872649878263474, Final Batch Loss: 0.20620368421077728\n",
      "Epoch 4558, Loss: 1.0639833360910416, Final Batch Loss: 0.23816965520381927\n",
      "Epoch 4559, Loss: 1.0358324497938156, Final Batch Loss: 0.17530502378940582\n",
      "Epoch 4560, Loss: 0.9441879391670227, Final Batch Loss: 0.2553909420967102\n",
      "Epoch 4561, Loss: 0.8546164780855179, Final Batch Loss: 0.20029139518737793\n",
      "Epoch 4562, Loss: 0.9859960526227951, Final Batch Loss: 0.160335972905159\n",
      "Epoch 4563, Loss: 1.0063074082136154, Final Batch Loss: 0.21072319149971008\n",
      "Epoch 4564, Loss: 0.92019322514534, Final Batch Loss: 0.22622008621692657\n",
      "Epoch 4565, Loss: 1.0451751202344894, Final Batch Loss: 0.4002070128917694\n",
      "Epoch 4566, Loss: 0.8456049561500549, Final Batch Loss: 0.19107939302921295\n",
      "Epoch 4567, Loss: 1.012029692530632, Final Batch Loss: 0.30203577876091003\n",
      "Epoch 4568, Loss: 1.120738908648491, Final Batch Loss: 0.4195345342159271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4569, Loss: 1.0850637257099152, Final Batch Loss: 0.17979195713996887\n",
      "Epoch 4570, Loss: 0.9096919149160385, Final Batch Loss: 0.2131901979446411\n",
      "Epoch 4571, Loss: 1.0218788385391235, Final Batch Loss: 0.20143365859985352\n",
      "Epoch 4572, Loss: 0.9190466105937958, Final Batch Loss: 0.28285548090934753\n",
      "Epoch 4573, Loss: 0.7977585941553116, Final Batch Loss: 0.17601478099822998\n",
      "Epoch 4574, Loss: 0.9776347726583481, Final Batch Loss: 0.2853783369064331\n",
      "Epoch 4575, Loss: 0.8507059812545776, Final Batch Loss: 0.18016308546066284\n",
      "Epoch 4576, Loss: 0.9820450097322464, Final Batch Loss: 0.1654045730829239\n",
      "Epoch 4577, Loss: 1.10960054397583, Final Batch Loss: 0.2969166934490204\n",
      "Epoch 4578, Loss: 0.9253563433885574, Final Batch Loss: 0.2517324388027191\n",
      "Epoch 4579, Loss: 1.0076048076152802, Final Batch Loss: 0.19598506391048431\n",
      "Epoch 4580, Loss: 0.9059172123670578, Final Batch Loss: 0.2832389771938324\n",
      "Epoch 4581, Loss: 0.9178643375635147, Final Batch Loss: 0.1797615885734558\n",
      "Epoch 4582, Loss: 1.0807192474603653, Final Batch Loss: 0.2270987182855606\n",
      "Epoch 4583, Loss: 1.16022689640522, Final Batch Loss: 0.20044223964214325\n",
      "Epoch 4584, Loss: 1.2326382100582123, Final Batch Loss: 0.3211480677127838\n",
      "Epoch 4585, Loss: 1.074741467833519, Final Batch Loss: 0.21297575533390045\n",
      "Epoch 4586, Loss: 0.96583691239357, Final Batch Loss: 0.2384912222623825\n",
      "Epoch 4587, Loss: 1.104257509112358, Final Batch Loss: 0.3550463616847992\n",
      "Epoch 4588, Loss: 1.0734987556934357, Final Batch Loss: 0.34418344497680664\n",
      "Epoch 4589, Loss: 1.117057055234909, Final Batch Loss: 0.3454825282096863\n",
      "Epoch 4590, Loss: 1.0043719708919525, Final Batch Loss: 0.24676848948001862\n",
      "Epoch 4591, Loss: 0.9919878244400024, Final Batch Loss: 0.24020473659038544\n",
      "Epoch 4592, Loss: 1.0141100585460663, Final Batch Loss: 0.26241421699523926\n",
      "Epoch 4593, Loss: 1.0352400839328766, Final Batch Loss: 0.34741437435150146\n",
      "Epoch 4594, Loss: 0.8450719267129898, Final Batch Loss: 0.1373003125190735\n",
      "Epoch 4595, Loss: 1.0436545312404633, Final Batch Loss: 0.27192455530166626\n",
      "Epoch 4596, Loss: 1.0010641515254974, Final Batch Loss: 0.20586730539798737\n",
      "Epoch 4597, Loss: 1.0615870654582977, Final Batch Loss: 0.29748815298080444\n",
      "Epoch 4598, Loss: 0.8424642235040665, Final Batch Loss: 0.2198350578546524\n",
      "Epoch 4599, Loss: 0.974298432469368, Final Batch Loss: 0.3244539499282837\n",
      "Epoch 4600, Loss: 0.977513924241066, Final Batch Loss: 0.2862454652786255\n",
      "Epoch 4601, Loss: 0.7587998062372208, Final Batch Loss: 0.14368829131126404\n",
      "Epoch 4602, Loss: 0.8431955873966217, Final Batch Loss: 0.16197998821735382\n",
      "Epoch 4603, Loss: 1.0807996988296509, Final Batch Loss: 0.2602013349533081\n",
      "Epoch 4604, Loss: 1.029255747795105, Final Batch Loss: 0.27639445662498474\n",
      "Epoch 4605, Loss: 1.0328325927257538, Final Batch Loss: 0.2810249924659729\n",
      "Epoch 4606, Loss: 0.8569694012403488, Final Batch Loss: 0.19643908739089966\n",
      "Epoch 4607, Loss: 1.0411238819360733, Final Batch Loss: 0.21762004494667053\n",
      "Epoch 4608, Loss: 1.0304293185472488, Final Batch Loss: 0.347159206867218\n",
      "Epoch 4609, Loss: 0.892707422375679, Final Batch Loss: 0.1497526466846466\n",
      "Epoch 4610, Loss: 1.0118405520915985, Final Batch Loss: 0.14309751987457275\n",
      "Epoch 4611, Loss: 1.0315855592489243, Final Batch Loss: 0.2845269739627838\n",
      "Epoch 4612, Loss: 1.0179903954267502, Final Batch Loss: 0.3241391181945801\n",
      "Epoch 4613, Loss: 1.0754861533641815, Final Batch Loss: 0.23136931657791138\n",
      "Epoch 4614, Loss: 1.006715014576912, Final Batch Loss: 0.2549208998680115\n",
      "Epoch 4615, Loss: 1.1905539631843567, Final Batch Loss: 0.4185859262943268\n",
      "Epoch 4616, Loss: 1.0346888899803162, Final Batch Loss: 0.23325712978839874\n",
      "Epoch 4617, Loss: 1.0409908890724182, Final Batch Loss: 0.26227444410324097\n",
      "Epoch 4618, Loss: 1.0300005972385406, Final Batch Loss: 0.2087046056985855\n",
      "Epoch 4619, Loss: 0.9632442891597748, Final Batch Loss: 0.29056426882743835\n",
      "Epoch 4620, Loss: 0.9626950323581696, Final Batch Loss: 0.25534531474113464\n",
      "Epoch 4621, Loss: 0.93622986972332, Final Batch Loss: 0.22941748797893524\n",
      "Epoch 4622, Loss: 1.134120225906372, Final Batch Loss: 0.20185866951942444\n",
      "Epoch 4623, Loss: 0.9300592541694641, Final Batch Loss: 0.267258882522583\n",
      "Epoch 4624, Loss: 1.0242087990045547, Final Batch Loss: 0.31781384348869324\n",
      "Epoch 4625, Loss: 1.014282450079918, Final Batch Loss: 0.2738109230995178\n",
      "Epoch 4626, Loss: 0.9749319404363632, Final Batch Loss: 0.24338456988334656\n",
      "Epoch 4627, Loss: 0.8218498975038528, Final Batch Loss: 0.156601682305336\n",
      "Epoch 4628, Loss: 1.0276909470558167, Final Batch Loss: 0.3212870657444\n",
      "Epoch 4629, Loss: 0.9675045758485794, Final Batch Loss: 0.16881507635116577\n",
      "Epoch 4630, Loss: 0.9333639889955521, Final Batch Loss: 0.19286832213401794\n",
      "Epoch 4631, Loss: 0.9126106798648834, Final Batch Loss: 0.22116848826408386\n",
      "Epoch 4632, Loss: 0.9305525720119476, Final Batch Loss: 0.19145318865776062\n",
      "Epoch 4633, Loss: 0.9438047409057617, Final Batch Loss: 0.24201582372188568\n",
      "Epoch 4634, Loss: 0.8806518912315369, Final Batch Loss: 0.209604412317276\n",
      "Epoch 4635, Loss: 0.9441919326782227, Final Batch Loss: 0.3219130337238312\n",
      "Epoch 4636, Loss: 0.9301286935806274, Final Batch Loss: 0.17544028162956238\n",
      "Epoch 4637, Loss: 0.9501896351575851, Final Batch Loss: 0.18846657872200012\n",
      "Epoch 4638, Loss: 1.1052682548761368, Final Batch Loss: 0.3966512680053711\n",
      "Epoch 4639, Loss: 1.1004284024238586, Final Batch Loss: 0.2876946032047272\n",
      "Epoch 4640, Loss: 1.034112498164177, Final Batch Loss: 0.2924236059188843\n",
      "Epoch 4641, Loss: 1.001728743314743, Final Batch Loss: 0.27876612544059753\n",
      "Epoch 4642, Loss: 0.9770147949457169, Final Batch Loss: 0.19343826174736023\n",
      "Epoch 4643, Loss: 0.9723375141620636, Final Batch Loss: 0.2825518846511841\n",
      "Epoch 4644, Loss: 0.985378161072731, Final Batch Loss: 0.2399447113275528\n",
      "Epoch 4645, Loss: 0.9495363235473633, Final Batch Loss: 0.23086941242218018\n",
      "Epoch 4646, Loss: 1.0437521934509277, Final Batch Loss: 0.33552342653274536\n",
      "Epoch 4647, Loss: 1.0665672272443771, Final Batch Loss: 0.3642958104610443\n",
      "Epoch 4648, Loss: 1.0246969014406204, Final Batch Loss: 0.19447369873523712\n",
      "Epoch 4649, Loss: 1.0512484163045883, Final Batch Loss: 0.2464943826198578\n",
      "Epoch 4650, Loss: 0.9914611130952835, Final Batch Loss: 0.22151872515678406\n",
      "Epoch 4651, Loss: 1.0444167703390121, Final Batch Loss: 0.28874197602272034\n",
      "Epoch 4652, Loss: 1.0678033083677292, Final Batch Loss: 0.2761991322040558\n",
      "Epoch 4653, Loss: 0.9481059461832047, Final Batch Loss: 0.21367080509662628\n",
      "Epoch 4654, Loss: 1.0193926244974136, Final Batch Loss: 0.25752127170562744\n",
      "Epoch 4655, Loss: 0.9076039791107178, Final Batch Loss: 0.2039322555065155\n",
      "Epoch 4656, Loss: 1.0138561874628067, Final Batch Loss: 0.2227625995874405\n",
      "Epoch 4657, Loss: 1.0225080847740173, Final Batch Loss: 0.25487080216407776\n",
      "Epoch 4658, Loss: 0.9529331028461456, Final Batch Loss: 0.15237747132778168\n",
      "Epoch 4659, Loss: 0.908417358994484, Final Batch Loss: 0.2228662222623825\n",
      "Epoch 4660, Loss: 0.8717144280672073, Final Batch Loss: 0.2355939745903015\n",
      "Epoch 4661, Loss: 1.0900751799345016, Final Batch Loss: 0.3371344804763794\n",
      "Epoch 4662, Loss: 1.0439418256282806, Final Batch Loss: 0.3089503049850464\n",
      "Epoch 4663, Loss: 1.1195325255393982, Final Batch Loss: 0.2584373652935028\n",
      "Epoch 4664, Loss: 1.0081516057252884, Final Batch Loss: 0.1926494836807251\n",
      "Epoch 4665, Loss: 0.9008330553770065, Final Batch Loss: 0.15722718834877014\n",
      "Epoch 4666, Loss: 0.9781689196825027, Final Batch Loss: 0.25832849740982056\n",
      "Epoch 4667, Loss: 1.000843122601509, Final Batch Loss: 0.2725294530391693\n",
      "Epoch 4668, Loss: 1.0313498675823212, Final Batch Loss: 0.29945600032806396\n",
      "Epoch 4669, Loss: 1.0893353074789047, Final Batch Loss: 0.1890871822834015\n",
      "Epoch 4670, Loss: 1.2630860209465027, Final Batch Loss: 0.32663974165916443\n",
      "Epoch 4671, Loss: 0.997626319527626, Final Batch Loss: 0.1951143443584442\n",
      "Epoch 4672, Loss: 0.898438423871994, Final Batch Loss: 0.15272697806358337\n",
      "Epoch 4673, Loss: 1.101761668920517, Final Batch Loss: 0.2871728241443634\n",
      "Epoch 4674, Loss: 0.9945039600133896, Final Batch Loss: 0.24863988161087036\n",
      "Epoch 4675, Loss: 1.0472211390733719, Final Batch Loss: 0.21079565584659576\n",
      "Epoch 4676, Loss: 0.9782189875841141, Final Batch Loss: 0.2501874268054962\n",
      "Epoch 4677, Loss: 0.8620324432849884, Final Batch Loss: 0.19006460905075073\n",
      "Epoch 4678, Loss: 1.0456953048706055, Final Batch Loss: 0.2628691494464874\n",
      "Epoch 4679, Loss: 1.0099438279867172, Final Batch Loss: 0.22058618068695068\n",
      "Epoch 4680, Loss: 0.9764932096004486, Final Batch Loss: 0.23811385035514832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4681, Loss: 0.9710310697555542, Final Batch Loss: 0.22493164241313934\n",
      "Epoch 4682, Loss: 0.9161009937524796, Final Batch Loss: 0.2572633922100067\n",
      "Epoch 4683, Loss: 0.9982617795467377, Final Batch Loss: 0.26724639534950256\n",
      "Epoch 4684, Loss: 0.9847741574048996, Final Batch Loss: 0.16889674961566925\n",
      "Epoch 4685, Loss: 1.1034162044525146, Final Batch Loss: 0.13707862794399261\n",
      "Epoch 4686, Loss: 0.961030513048172, Final Batch Loss: 0.27303630113601685\n",
      "Epoch 4687, Loss: 0.9084748476743698, Final Batch Loss: 0.24312934279441833\n",
      "Epoch 4688, Loss: 0.9229920655488968, Final Batch Loss: 0.2489493489265442\n",
      "Epoch 4689, Loss: 0.9777169227600098, Final Batch Loss: 0.29107582569122314\n",
      "Epoch 4690, Loss: 1.022699236869812, Final Batch Loss: 0.27206552028656006\n",
      "Epoch 4691, Loss: 0.8564888089895248, Final Batch Loss: 0.19914217293262482\n",
      "Epoch 4692, Loss: 0.9932166337966919, Final Batch Loss: 0.20506072044372559\n",
      "Epoch 4693, Loss: 0.9552560299634933, Final Batch Loss: 0.1893412172794342\n",
      "Epoch 4694, Loss: 0.8330130577087402, Final Batch Loss: 0.1885344684123993\n",
      "Epoch 4695, Loss: 0.9072268903255463, Final Batch Loss: 0.2408466786146164\n",
      "Epoch 4696, Loss: 0.9429480135440826, Final Batch Loss: 0.22296692430973053\n",
      "Epoch 4697, Loss: 0.8072199672460556, Final Batch Loss: 0.21013596653938293\n",
      "Epoch 4698, Loss: 0.9068153351545334, Final Batch Loss: 0.19736552238464355\n",
      "Epoch 4699, Loss: 1.1179630756378174, Final Batch Loss: 0.3476305603981018\n",
      "Epoch 4700, Loss: 1.054591566324234, Final Batch Loss: 0.2605084478855133\n",
      "Epoch 4701, Loss: 0.9629574865102768, Final Batch Loss: 0.28744179010391235\n",
      "Epoch 4702, Loss: 0.9804616868495941, Final Batch Loss: 0.23082302510738373\n",
      "Epoch 4703, Loss: 0.9727752208709717, Final Batch Loss: 0.2681198716163635\n",
      "Epoch 4704, Loss: 0.9566413462162018, Final Batch Loss: 0.15511448681354523\n",
      "Epoch 4705, Loss: 1.1853975355625153, Final Batch Loss: 0.457355797290802\n",
      "Epoch 4706, Loss: 1.0330858826637268, Final Batch Loss: 0.22562211751937866\n",
      "Epoch 4707, Loss: 1.1359371542930603, Final Batch Loss: 0.38688066601753235\n",
      "Epoch 4708, Loss: 1.0616070628166199, Final Batch Loss: 0.24725931882858276\n",
      "Epoch 4709, Loss: 1.2038704454898834, Final Batch Loss: 0.3478473722934723\n",
      "Epoch 4710, Loss: 1.0971237421035767, Final Batch Loss: 0.25061896443367004\n",
      "Epoch 4711, Loss: 1.0793298035860062, Final Batch Loss: 0.2073892205953598\n",
      "Epoch 4712, Loss: 1.0621413439512253, Final Batch Loss: 0.2993928790092468\n",
      "Epoch 4713, Loss: 1.0153740793466568, Final Batch Loss: 0.2993127703666687\n",
      "Epoch 4714, Loss: 1.0230063199996948, Final Batch Loss: 0.28541260957717896\n",
      "Epoch 4715, Loss: 1.0196530520915985, Final Batch Loss: 0.2707787752151489\n",
      "Epoch 4716, Loss: 0.9179486781358719, Final Batch Loss: 0.165171280503273\n",
      "Epoch 4717, Loss: 0.9943330436944962, Final Batch Loss: 0.1536390334367752\n",
      "Epoch 4718, Loss: 1.0387518405914307, Final Batch Loss: 0.167119100689888\n",
      "Epoch 4719, Loss: 1.0065755993127823, Final Batch Loss: 0.27607041597366333\n",
      "Epoch 4720, Loss: 0.9515481740236282, Final Batch Loss: 0.2855655550956726\n",
      "Epoch 4721, Loss: 0.7709506899118423, Final Batch Loss: 0.1828518658876419\n",
      "Epoch 4722, Loss: 0.9596454203128815, Final Batch Loss: 0.20592841506004333\n",
      "Epoch 4723, Loss: 0.9949063956737518, Final Batch Loss: 0.3104751706123352\n",
      "Epoch 4724, Loss: 0.9837094694375992, Final Batch Loss: 0.2535635232925415\n",
      "Epoch 4725, Loss: 0.9676905274391174, Final Batch Loss: 0.23863926529884338\n",
      "Epoch 4726, Loss: 0.9595329314470291, Final Batch Loss: 0.23795245587825775\n",
      "Epoch 4727, Loss: 0.8860324770212173, Final Batch Loss: 0.18772375583648682\n",
      "Epoch 4728, Loss: 0.9123430997133255, Final Batch Loss: 0.21154654026031494\n",
      "Epoch 4729, Loss: 1.0376312136650085, Final Batch Loss: 0.2767576575279236\n",
      "Epoch 4730, Loss: 0.9714535921812057, Final Batch Loss: 0.2859303951263428\n",
      "Epoch 4731, Loss: 0.8646528571844101, Final Batch Loss: 0.22642263770103455\n",
      "Epoch 4732, Loss: 0.9451605528593063, Final Batch Loss: 0.19353453814983368\n",
      "Epoch 4733, Loss: 0.9581339359283447, Final Batch Loss: 0.2461571991443634\n",
      "Epoch 4734, Loss: 1.0668370425701141, Final Batch Loss: 0.282253623008728\n",
      "Epoch 4735, Loss: 0.9239692687988281, Final Batch Loss: 0.20195096731185913\n",
      "Epoch 4736, Loss: 1.0100456327199936, Final Batch Loss: 0.1949252486228943\n",
      "Epoch 4737, Loss: 0.9194292277097702, Final Batch Loss: 0.1968051791191101\n",
      "Epoch 4738, Loss: 1.074330449104309, Final Batch Loss: 0.3579171895980835\n",
      "Epoch 4739, Loss: 0.939789891242981, Final Batch Loss: 0.2181505262851715\n",
      "Epoch 4740, Loss: 0.8904424011707306, Final Batch Loss: 0.3112252652645111\n",
      "Epoch 4741, Loss: 0.9419534504413605, Final Batch Loss: 0.2796867787837982\n",
      "Epoch 4742, Loss: 1.1139833480119705, Final Batch Loss: 0.3841959238052368\n",
      "Epoch 4743, Loss: 1.0921720415353775, Final Batch Loss: 0.29108113050460815\n",
      "Epoch 4744, Loss: 1.1240824908018112, Final Batch Loss: 0.25233548879623413\n",
      "Epoch 4745, Loss: 1.053715318441391, Final Batch Loss: 0.338817298412323\n",
      "Epoch 4746, Loss: 0.9937884658575058, Final Batch Loss: 0.24140124022960663\n",
      "Epoch 4747, Loss: 1.0445300191640854, Final Batch Loss: 0.2839016914367676\n",
      "Epoch 4748, Loss: 1.1275205314159393, Final Batch Loss: 0.32491201162338257\n",
      "Epoch 4749, Loss: 0.9818691462278366, Final Batch Loss: 0.24036996066570282\n",
      "Epoch 4750, Loss: 0.970599353313446, Final Batch Loss: 0.2989141345024109\n",
      "Epoch 4751, Loss: 0.8634243905544281, Final Batch Loss: 0.21581552922725677\n",
      "Epoch 4752, Loss: 0.9972811490297318, Final Batch Loss: 0.2186712920665741\n",
      "Epoch 4753, Loss: 0.9772950261831284, Final Batch Loss: 0.28154370188713074\n",
      "Epoch 4754, Loss: 0.9813492298126221, Final Batch Loss: 0.20838138461112976\n",
      "Epoch 4755, Loss: 0.96962670981884, Final Batch Loss: 0.253346711397171\n",
      "Epoch 4756, Loss: 0.9927040338516235, Final Batch Loss: 0.28264275193214417\n",
      "Epoch 4757, Loss: 0.9825339913368225, Final Batch Loss: 0.325461745262146\n",
      "Epoch 4758, Loss: 0.971374973654747, Final Batch Loss: 0.21925900876522064\n",
      "Epoch 4759, Loss: 1.087594896554947, Final Batch Loss: 0.3376612365245819\n",
      "Epoch 4760, Loss: 1.0201254934072495, Final Batch Loss: 0.2623521089553833\n",
      "Epoch 4761, Loss: 0.8762903064489365, Final Batch Loss: 0.21193327009677887\n",
      "Epoch 4762, Loss: 0.9939866214990616, Final Batch Loss: 0.24684177339076996\n",
      "Epoch 4763, Loss: 1.027142971754074, Final Batch Loss: 0.3068448305130005\n",
      "Epoch 4764, Loss: 1.111630618572235, Final Batch Loss: 0.15556544065475464\n",
      "Epoch 4765, Loss: 1.0286686569452286, Final Batch Loss: 0.24059021472930908\n",
      "Epoch 4766, Loss: 1.1232100427150726, Final Batch Loss: 0.38916754722595215\n",
      "Epoch 4767, Loss: 1.064284786581993, Final Batch Loss: 0.38071343302726746\n",
      "Epoch 4768, Loss: 1.1751407533884048, Final Batch Loss: 0.31621062755584717\n",
      "Epoch 4769, Loss: 0.8788692057132721, Final Batch Loss: 0.1834527999162674\n",
      "Epoch 4770, Loss: 0.9819300770759583, Final Batch Loss: 0.23683279752731323\n",
      "Epoch 4771, Loss: 0.8777583688497543, Final Batch Loss: 0.16121117770671844\n",
      "Epoch 4772, Loss: 0.9427805542945862, Final Batch Loss: 0.2606864273548126\n",
      "Epoch 4773, Loss: 0.9588653743267059, Final Batch Loss: 0.24218381941318512\n",
      "Epoch 4774, Loss: 0.9389765113592148, Final Batch Loss: 0.2571767568588257\n",
      "Epoch 4775, Loss: 1.0068235844373703, Final Batch Loss: 0.32615283131599426\n",
      "Epoch 4776, Loss: 0.9420269876718521, Final Batch Loss: 0.14008042216300964\n",
      "Epoch 4777, Loss: 1.0983705818653107, Final Batch Loss: 0.30388668179512024\n",
      "Epoch 4778, Loss: 1.1184736341238022, Final Batch Loss: 0.39289212226867676\n",
      "Epoch 4779, Loss: 1.043107345700264, Final Batch Loss: 0.21811304986476898\n",
      "Epoch 4780, Loss: 0.9248752295970917, Final Batch Loss: 0.1902664303779602\n",
      "Epoch 4781, Loss: 1.0687913447618484, Final Batch Loss: 0.2985541820526123\n",
      "Epoch 4782, Loss: 1.069405272603035, Final Batch Loss: 0.3173346519470215\n",
      "Epoch 4783, Loss: 0.9627571851015091, Final Batch Loss: 0.1491527259349823\n",
      "Epoch 4784, Loss: 1.0075432062149048, Final Batch Loss: 0.237363800406456\n",
      "Epoch 4785, Loss: 0.9609135836362839, Final Batch Loss: 0.1815650463104248\n",
      "Epoch 4786, Loss: 1.0173935890197754, Final Batch Loss: 0.28464198112487793\n",
      "Epoch 4787, Loss: 0.9293434619903564, Final Batch Loss: 0.18531306087970734\n",
      "Epoch 4788, Loss: 1.0033932477235794, Final Batch Loss: 0.24976037442684174\n",
      "Epoch 4789, Loss: 0.939154326915741, Final Batch Loss: 0.20198220014572144\n",
      "Epoch 4790, Loss: 0.918733760714531, Final Batch Loss: 0.21951372921466827\n",
      "Epoch 4791, Loss: 0.8887638449668884, Final Batch Loss: 0.19438286125659943\n",
      "Epoch 4792, Loss: 1.0184813737869263, Final Batch Loss: 0.274978369474411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4793, Loss: 0.9145811498165131, Final Batch Loss: 0.27652856707572937\n",
      "Epoch 4794, Loss: 0.9974191784858704, Final Batch Loss: 0.2418251484632492\n",
      "Epoch 4795, Loss: 0.9934609234333038, Final Batch Loss: 0.2053476721048355\n",
      "Epoch 4796, Loss: 1.0912388563156128, Final Batch Loss: 0.23391297459602356\n",
      "Epoch 4797, Loss: 1.101365089416504, Final Batch Loss: 0.2705492377281189\n",
      "Epoch 4798, Loss: 1.028943806886673, Final Batch Loss: 0.34359312057495117\n",
      "Epoch 4799, Loss: 1.0073984861373901, Final Batch Loss: 0.25200146436691284\n",
      "Epoch 4800, Loss: 0.8570845127105713, Final Batch Loss: 0.12896399199962616\n",
      "Epoch 4801, Loss: 1.049721121788025, Final Batch Loss: 0.28839626908302307\n",
      "Epoch 4802, Loss: 0.9110043942928314, Final Batch Loss: 0.21841445565223694\n",
      "Epoch 4803, Loss: 0.9383976012468338, Final Batch Loss: 0.16618885099887848\n",
      "Epoch 4804, Loss: 1.007545605301857, Final Batch Loss: 0.23693132400512695\n",
      "Epoch 4805, Loss: 1.0063494592905045, Final Batch Loss: 0.2088492065668106\n",
      "Epoch 4806, Loss: 0.9134938418865204, Final Batch Loss: 0.2523673474788666\n",
      "Epoch 4807, Loss: 0.9609186351299286, Final Batch Loss: 0.2358224242925644\n",
      "Epoch 4808, Loss: 1.0077907890081406, Final Batch Loss: 0.3129994571208954\n",
      "Epoch 4809, Loss: 0.9402380287647247, Final Batch Loss: 0.23787620663642883\n",
      "Epoch 4810, Loss: 0.939262181520462, Final Batch Loss: 0.24862655997276306\n",
      "Epoch 4811, Loss: 0.9342353343963623, Final Batch Loss: 0.2226954996585846\n",
      "Epoch 4812, Loss: 0.8694731146097183, Final Batch Loss: 0.14241857826709747\n",
      "Epoch 4813, Loss: 1.0967251062393188, Final Batch Loss: 0.28956201672554016\n",
      "Epoch 4814, Loss: 0.9954933524131775, Final Batch Loss: 0.19734330475330353\n",
      "Epoch 4815, Loss: 1.0944736450910568, Final Batch Loss: 0.2133292704820633\n",
      "Epoch 4816, Loss: 0.9328282326459885, Final Batch Loss: 0.2311905473470688\n",
      "Epoch 4817, Loss: 1.0011464208364487, Final Batch Loss: 0.19163556396961212\n",
      "Epoch 4818, Loss: 0.9617954790592194, Final Batch Loss: 0.2709623873233795\n",
      "Epoch 4819, Loss: 1.009614273905754, Final Batch Loss: 0.24578645825386047\n",
      "Epoch 4820, Loss: 1.0303728729486465, Final Batch Loss: 0.33634576201438904\n",
      "Epoch 4821, Loss: 0.9613260477781296, Final Batch Loss: 0.2933649718761444\n",
      "Epoch 4822, Loss: 0.9629548490047455, Final Batch Loss: 0.22144654393196106\n",
      "Epoch 4823, Loss: 1.02816940844059, Final Batch Loss: 0.3516082763671875\n",
      "Epoch 4824, Loss: 1.1082021445035934, Final Batch Loss: 0.36235862970352173\n",
      "Epoch 4825, Loss: 1.1898235827684402, Final Batch Loss: 0.4154199957847595\n",
      "Epoch 4826, Loss: 0.894725576043129, Final Batch Loss: 0.2526070773601532\n",
      "Epoch 4827, Loss: 0.9148036241531372, Final Batch Loss: 0.1840306967496872\n",
      "Epoch 4828, Loss: 1.2169024646282196, Final Batch Loss: 0.404030442237854\n",
      "Epoch 4829, Loss: 1.0907208025455475, Final Batch Loss: 0.2120642215013504\n",
      "Epoch 4830, Loss: 1.076446384191513, Final Batch Loss: 0.2861928641796112\n",
      "Epoch 4831, Loss: 1.2080958634614944, Final Batch Loss: 0.3623518645763397\n",
      "Epoch 4832, Loss: 0.9815824031829834, Final Batch Loss: 0.20519869029521942\n",
      "Epoch 4833, Loss: 0.867448702454567, Final Batch Loss: 0.2289203405380249\n",
      "Epoch 4834, Loss: 1.1194286346435547, Final Batch Loss: 0.3406195044517517\n",
      "Epoch 4835, Loss: 0.9158190786838531, Final Batch Loss: 0.2148570567369461\n",
      "Epoch 4836, Loss: 0.9742278605699539, Final Batch Loss: 0.2613951563835144\n",
      "Epoch 4837, Loss: 0.9272665977478027, Final Batch Loss: 0.1761762946844101\n",
      "Epoch 4838, Loss: 1.000984713435173, Final Batch Loss: 0.2425948828458786\n",
      "Epoch 4839, Loss: 0.965048611164093, Final Batch Loss: 0.30308565497398376\n",
      "Epoch 4840, Loss: 0.9521075189113617, Final Batch Loss: 0.20904378592967987\n",
      "Epoch 4841, Loss: 0.8277987539768219, Final Batch Loss: 0.23421430587768555\n",
      "Epoch 4842, Loss: 0.9667584151029587, Final Batch Loss: 0.20940682291984558\n",
      "Epoch 4843, Loss: 1.0614947527647018, Final Batch Loss: 0.3155597448348999\n",
      "Epoch 4844, Loss: 0.9836195707321167, Final Batch Loss: 0.1868896484375\n",
      "Epoch 4845, Loss: 0.9654709249734879, Final Batch Loss: 0.2492857575416565\n",
      "Epoch 4846, Loss: 1.0950450897216797, Final Batch Loss: 0.2903340756893158\n",
      "Epoch 4847, Loss: 0.9557684361934662, Final Batch Loss: 0.19440872967243195\n",
      "Epoch 4848, Loss: 1.101879969239235, Final Batch Loss: 0.3362220823764801\n",
      "Epoch 4849, Loss: 0.955443724989891, Final Batch Loss: 0.24637943506240845\n",
      "Epoch 4850, Loss: 0.9911234527826309, Final Batch Loss: 0.25433292984962463\n",
      "Epoch 4851, Loss: 1.0612271875143051, Final Batch Loss: 0.2646406888961792\n",
      "Epoch 4852, Loss: 1.0451879501342773, Final Batch Loss: 0.29876700043678284\n",
      "Epoch 4853, Loss: 1.096023216843605, Final Batch Loss: 0.28166526556015015\n",
      "Epoch 4854, Loss: 1.020349696278572, Final Batch Loss: 0.2732861638069153\n",
      "Epoch 4855, Loss: 1.180385559797287, Final Batch Loss: 0.3665624260902405\n",
      "Epoch 4856, Loss: 1.0982834249734879, Final Batch Loss: 0.30317625403404236\n",
      "Epoch 4857, Loss: 0.9785944670438766, Final Batch Loss: 0.22429461777210236\n",
      "Epoch 4858, Loss: 0.9691084176301956, Final Batch Loss: 0.2118319422006607\n",
      "Epoch 4859, Loss: 0.8767851442098618, Final Batch Loss: 0.24999670684337616\n",
      "Epoch 4860, Loss: 0.9426163583993912, Final Batch Loss: 0.29478147625923157\n",
      "Epoch 4861, Loss: 0.9165906459093094, Final Batch Loss: 0.3091261684894562\n",
      "Epoch 4862, Loss: 0.9970749467611313, Final Batch Loss: 0.23036785423755646\n",
      "Epoch 4863, Loss: 0.9440550059080124, Final Batch Loss: 0.11618760228157043\n",
      "Epoch 4864, Loss: 0.9883404821157455, Final Batch Loss: 0.27554839849472046\n",
      "Epoch 4865, Loss: 1.0428478717803955, Final Batch Loss: 0.26650214195251465\n",
      "Epoch 4866, Loss: 0.8743814378976822, Final Batch Loss: 0.21747691929340363\n",
      "Epoch 4867, Loss: 1.0856954753398895, Final Batch Loss: 0.36408695578575134\n",
      "Epoch 4868, Loss: 0.8836659342050552, Final Batch Loss: 0.15088918805122375\n",
      "Epoch 4869, Loss: 0.9013198018074036, Final Batch Loss: 0.14702923595905304\n",
      "Epoch 4870, Loss: 0.8178128451108932, Final Batch Loss: 0.1367901712656021\n",
      "Epoch 4871, Loss: 0.9991598874330521, Final Batch Loss: 0.2670609951019287\n",
      "Epoch 4872, Loss: 1.0334733873605728, Final Batch Loss: 0.25653496384620667\n",
      "Epoch 4873, Loss: 1.0698440074920654, Final Batch Loss: 0.2885056138038635\n",
      "Epoch 4874, Loss: 1.111432060599327, Final Batch Loss: 0.3167343735694885\n",
      "Epoch 4875, Loss: 0.8410434275865555, Final Batch Loss: 0.20941558480262756\n",
      "Epoch 4876, Loss: 1.0466507226228714, Final Batch Loss: 0.3099250793457031\n",
      "Epoch 4877, Loss: 1.044960230588913, Final Batch Loss: 0.2726762890815735\n",
      "Epoch 4878, Loss: 1.0203883200883865, Final Batch Loss: 0.32434511184692383\n",
      "Epoch 4879, Loss: 0.9347781985998154, Final Batch Loss: 0.18686792254447937\n",
      "Epoch 4880, Loss: 0.9724802076816559, Final Batch Loss: 0.24448315799236298\n",
      "Epoch 4881, Loss: 0.9359709769487381, Final Batch Loss: 0.22581127285957336\n",
      "Epoch 4882, Loss: 1.0700819790363312, Final Batch Loss: 0.30244189500808716\n",
      "Epoch 4883, Loss: 0.9782716631889343, Final Batch Loss: 0.22799421846866608\n",
      "Epoch 4884, Loss: 0.9267174899578094, Final Batch Loss: 0.22726333141326904\n",
      "Epoch 4885, Loss: 0.9717978537082672, Final Batch Loss: 0.27541929483413696\n",
      "Epoch 4886, Loss: 1.0711796432733536, Final Batch Loss: 0.17754177749156952\n",
      "Epoch 4887, Loss: 1.0251652747392654, Final Batch Loss: 0.27274200320243835\n",
      "Epoch 4888, Loss: 0.9199394285678864, Final Batch Loss: 0.20648783445358276\n",
      "Epoch 4889, Loss: 0.939650371670723, Final Batch Loss: 0.22011248767375946\n",
      "Epoch 4890, Loss: 0.9871368110179901, Final Batch Loss: 0.21160459518432617\n",
      "Epoch 4891, Loss: 1.0102912187576294, Final Batch Loss: 0.3006895184516907\n",
      "Epoch 4892, Loss: 0.9404691904783249, Final Batch Loss: 0.27268949151039124\n",
      "Epoch 4893, Loss: 1.0793668180704117, Final Batch Loss: 0.29627522826194763\n",
      "Epoch 4894, Loss: 0.9493640810251236, Final Batch Loss: 0.23579801619052887\n",
      "Epoch 4895, Loss: 0.8671730011701584, Final Batch Loss: 0.18216198682785034\n",
      "Epoch 4896, Loss: 0.9661102890968323, Final Batch Loss: 0.17963795363903046\n",
      "Epoch 4897, Loss: 1.0298920571804047, Final Batch Loss: 0.3101004958152771\n",
      "Epoch 4898, Loss: 1.0219699293375015, Final Batch Loss: 0.21734856069087982\n",
      "Epoch 4899, Loss: 1.2202284336090088, Final Batch Loss: 0.3971565365791321\n",
      "Epoch 4900, Loss: 0.8578522652387619, Final Batch Loss: 0.2504936456680298\n",
      "Epoch 4901, Loss: 0.842478558421135, Final Batch Loss: 0.1530824452638626\n",
      "Epoch 4902, Loss: 1.0288573503494263, Final Batch Loss: 0.21073360741138458\n",
      "Epoch 4903, Loss: 0.8748435974121094, Final Batch Loss: 0.2190442532300949\n",
      "Epoch 4904, Loss: 1.0027382671833038, Final Batch Loss: 0.2961932122707367\n",
      "Epoch 4905, Loss: 0.8423502147197723, Final Batch Loss: 0.161952406167984\n",
      "Epoch 4906, Loss: 0.9983967691659927, Final Batch Loss: 0.24702541530132294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4907, Loss: 0.9518777877092361, Final Batch Loss: 0.31831297278404236\n",
      "Epoch 4908, Loss: 0.9273402988910675, Final Batch Loss: 0.25718656182289124\n",
      "Epoch 4909, Loss: 0.8750833570957184, Final Batch Loss: 0.23946848511695862\n",
      "Epoch 4910, Loss: 0.9917814284563065, Final Batch Loss: 0.21335434913635254\n",
      "Epoch 4911, Loss: 0.968689814209938, Final Batch Loss: 0.2629547119140625\n",
      "Epoch 4912, Loss: 1.048228606581688, Final Batch Loss: 0.2739087641239166\n",
      "Epoch 4913, Loss: 0.9948750138282776, Final Batch Loss: 0.26643067598342896\n",
      "Epoch 4914, Loss: 0.9924626499414444, Final Batch Loss: 0.17496155202388763\n",
      "Epoch 4915, Loss: 0.9443012177944183, Final Batch Loss: 0.2562863826751709\n",
      "Epoch 4916, Loss: 0.9876133501529694, Final Batch Loss: 0.26670366525650024\n",
      "Epoch 4917, Loss: 1.0746541917324066, Final Batch Loss: 0.2245214879512787\n",
      "Epoch 4918, Loss: 0.987550288438797, Final Batch Loss: 0.2409908026456833\n",
      "Epoch 4919, Loss: 0.9435631632804871, Final Batch Loss: 0.26446813344955444\n",
      "Epoch 4920, Loss: 0.9766305685043335, Final Batch Loss: 0.25989463925361633\n",
      "Epoch 4921, Loss: 0.8713090717792511, Final Batch Loss: 0.22557784616947174\n",
      "Epoch 4922, Loss: 0.942159965634346, Final Batch Loss: 0.2117869257926941\n",
      "Epoch 4923, Loss: 0.9631470143795013, Final Batch Loss: 0.2582490146160126\n",
      "Epoch 4924, Loss: 0.8286584317684174, Final Batch Loss: 0.1782381534576416\n",
      "Epoch 4925, Loss: 0.8910411149263382, Final Batch Loss: 0.18868926167488098\n",
      "Epoch 4926, Loss: 0.9661704450845718, Final Batch Loss: 0.21904505789279938\n",
      "Epoch 4927, Loss: 1.0075261294841766, Final Batch Loss: 0.2572987973690033\n",
      "Epoch 4928, Loss: 0.931852713227272, Final Batch Loss: 0.22997716069221497\n",
      "Epoch 4929, Loss: 0.9482324868440628, Final Batch Loss: 0.26056185364723206\n",
      "Epoch 4930, Loss: 0.8839390277862549, Final Batch Loss: 0.1609003245830536\n",
      "Epoch 4931, Loss: 0.9282867461442947, Final Batch Loss: 0.2606537640094757\n",
      "Epoch 4932, Loss: 0.9622507393360138, Final Batch Loss: 0.2352677583694458\n",
      "Epoch 4933, Loss: 0.9684891998767853, Final Batch Loss: 0.32055971026420593\n",
      "Epoch 4934, Loss: 0.8879768922924995, Final Batch Loss: 0.2557651698589325\n",
      "Epoch 4935, Loss: 0.9812273234128952, Final Batch Loss: 0.2468215972185135\n",
      "Epoch 4936, Loss: 0.8494597971439362, Final Batch Loss: 0.1965974122285843\n",
      "Epoch 4937, Loss: 0.9956098794937134, Final Batch Loss: 0.28243786096572876\n",
      "Epoch 4938, Loss: 0.9253372400999069, Final Batch Loss: 0.21819275617599487\n",
      "Epoch 4939, Loss: 0.9304617643356323, Final Batch Loss: 0.21096408367156982\n",
      "Epoch 4940, Loss: 0.8112354427576065, Final Batch Loss: 0.18924099206924438\n",
      "Epoch 4941, Loss: 0.9289031773805618, Final Batch Loss: 0.1721176952123642\n",
      "Epoch 4942, Loss: 1.0384165048599243, Final Batch Loss: 0.23740962147712708\n",
      "Epoch 4943, Loss: 1.0678951740264893, Final Batch Loss: 0.3921493589878082\n",
      "Epoch 4944, Loss: 1.067048892378807, Final Batch Loss: 0.2954557240009308\n",
      "Epoch 4945, Loss: 0.9540144354104996, Final Batch Loss: 0.17886795103549957\n",
      "Epoch 4946, Loss: 0.9795065522193909, Final Batch Loss: 0.3607543408870697\n",
      "Epoch 4947, Loss: 0.9341344684362411, Final Batch Loss: 0.2884298861026764\n",
      "Epoch 4948, Loss: 0.8874954879283905, Final Batch Loss: 0.2244085818529129\n",
      "Epoch 4949, Loss: 0.9957916587591171, Final Batch Loss: 0.18017159402370453\n",
      "Epoch 4950, Loss: 1.138843595981598, Final Batch Loss: 0.37555646896362305\n",
      "Epoch 4951, Loss: 0.9182492196559906, Final Batch Loss: 0.18081578612327576\n",
      "Epoch 4952, Loss: 0.9002715200185776, Final Batch Loss: 0.2451668232679367\n",
      "Epoch 4953, Loss: 0.8929320722818375, Final Batch Loss: 0.2528665363788605\n",
      "Epoch 4954, Loss: 1.0921304374933243, Final Batch Loss: 0.3193312883377075\n",
      "Epoch 4955, Loss: 0.8862746059894562, Final Batch Loss: 0.2327229380607605\n",
      "Epoch 4956, Loss: 1.1232100129127502, Final Batch Loss: 0.2516099512577057\n",
      "Epoch 4957, Loss: 1.0342568755149841, Final Batch Loss: 0.27494728565216064\n",
      "Epoch 4958, Loss: 1.071403294801712, Final Batch Loss: 0.22203414142131805\n",
      "Epoch 4959, Loss: 0.9420713633298874, Final Batch Loss: 0.2319103479385376\n",
      "Epoch 4960, Loss: 0.9735920578241348, Final Batch Loss: 0.32227790355682373\n",
      "Epoch 4961, Loss: 1.083938106894493, Final Batch Loss: 0.23297365009784698\n",
      "Epoch 4962, Loss: 1.0368758738040924, Final Batch Loss: 0.22671663761138916\n",
      "Epoch 4963, Loss: 0.884151041507721, Final Batch Loss: 0.13502401113510132\n",
      "Epoch 4964, Loss: 0.9904885143041611, Final Batch Loss: 0.28370246291160583\n",
      "Epoch 4965, Loss: 1.0325309783220291, Final Batch Loss: 0.37703239917755127\n",
      "Epoch 4966, Loss: 0.8479120284318924, Final Batch Loss: 0.1901613026857376\n",
      "Epoch 4967, Loss: 1.1486286222934723, Final Batch Loss: 0.33289921283721924\n",
      "Epoch 4968, Loss: 0.9845177233219147, Final Batch Loss: 0.28174537420272827\n",
      "Epoch 4969, Loss: 1.0960715562105179, Final Batch Loss: 0.25870296359062195\n",
      "Epoch 4970, Loss: 0.8730844557285309, Final Batch Loss: 0.14537706971168518\n",
      "Epoch 4971, Loss: 1.0894888043403625, Final Batch Loss: 0.28549909591674805\n",
      "Epoch 4972, Loss: 0.8839856833219528, Final Batch Loss: 0.17954371869564056\n",
      "Epoch 4973, Loss: 0.867984876036644, Final Batch Loss: 0.19646470248699188\n",
      "Epoch 4974, Loss: 0.9128768444061279, Final Batch Loss: 0.24460574984550476\n",
      "Epoch 4975, Loss: 1.184016153216362, Final Batch Loss: 0.47758978605270386\n",
      "Epoch 4976, Loss: 0.9271036237478256, Final Batch Loss: 0.332431823015213\n",
      "Epoch 4977, Loss: 1.0424004197120667, Final Batch Loss: 0.19244179129600525\n",
      "Epoch 4978, Loss: 0.9917946010828018, Final Batch Loss: 0.22247347235679626\n",
      "Epoch 4979, Loss: 1.1811629384756088, Final Batch Loss: 0.36562082171440125\n",
      "Epoch 4980, Loss: 0.76502425968647, Final Batch Loss: 0.18396370112895966\n",
      "Epoch 4981, Loss: 0.9084452092647552, Final Batch Loss: 0.20981542766094208\n",
      "Epoch 4982, Loss: 0.8603542298078537, Final Batch Loss: 0.13064365088939667\n",
      "Epoch 4983, Loss: 0.9480100870132446, Final Batch Loss: 0.2017413079738617\n",
      "Epoch 4984, Loss: 0.9823096692562103, Final Batch Loss: 0.2608499526977539\n",
      "Epoch 4985, Loss: 0.9432646781206131, Final Batch Loss: 0.2434317171573639\n",
      "Epoch 4986, Loss: 0.9781735986471176, Final Batch Loss: 0.1514064073562622\n",
      "Epoch 4987, Loss: 1.0650369077920914, Final Batch Loss: 0.29924634099006653\n",
      "Epoch 4988, Loss: 1.0185340642929077, Final Batch Loss: 0.25623592734336853\n",
      "Epoch 4989, Loss: 1.1350702196359634, Final Batch Loss: 0.2813800275325775\n",
      "Epoch 4990, Loss: 0.8285420536994934, Final Batch Loss: 0.19770732522010803\n",
      "Epoch 4991, Loss: 0.866356834769249, Final Batch Loss: 0.2025623619556427\n",
      "Epoch 4992, Loss: 0.8706214874982834, Final Batch Loss: 0.2087177336215973\n",
      "Epoch 4993, Loss: 0.919145479798317, Final Batch Loss: 0.19366218149662018\n",
      "Epoch 4994, Loss: 1.0378441214561462, Final Batch Loss: 0.16496773064136505\n",
      "Epoch 4995, Loss: 1.003595843911171, Final Batch Loss: 0.2715959846973419\n",
      "Epoch 4996, Loss: 1.0981099158525467, Final Batch Loss: 0.3430856168270111\n",
      "Epoch 4997, Loss: 1.087469071149826, Final Batch Loss: 0.24059776961803436\n",
      "Epoch 4998, Loss: 0.9232507348060608, Final Batch Loss: 0.22380639612674713\n",
      "Epoch 4999, Loss: 0.89166559278965, Final Batch Loss: 0.23930169641971588\n",
      "Epoch 5000, Loss: 1.0798614770174026, Final Batch Loss: 0.2519858777523041\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  0  0  0  0  0]\n",
      " [ 0 24  0  1  4  2  1]\n",
      " [ 0  0 23  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  1]\n",
      " [ 1  1  0  0 22  0  0]\n",
      " [ 1  0  0  0  1 32  0]\n",
      " [ 0  0  0  2  0  0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95652   1.00000   0.97778        44\n",
      "           1    0.96000   0.75000   0.84211        32\n",
      "           2    1.00000   1.00000   1.00000        23\n",
      "           3    0.92308   0.97297   0.94737        37\n",
      "           4    0.81481   0.91667   0.86275        24\n",
      "           5    0.94118   0.94118   0.94118        34\n",
      "           6    0.92308   0.92308   0.92308        26\n",
      "\n",
      "    accuracy                        0.93182       220\n",
      "   macro avg    0.93124   0.92913   0.92775       220\n",
      "weighted avg    0.93417   0.93182   0.93058       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [5] * n_samples + [6] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  2  0  3  1  3]\n",
      " [ 2 18  2  4  2  1  1]\n",
      " [ 0  0 18 11  1  0  0]\n",
      " [ 0  5  0 20  4  0  1]\n",
      " [ 3  1  2  1 20  3  0]\n",
      " [ 6  0  8  0  0 16  0]\n",
      " [ 0  0  0  0  0  2 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.65625   0.70000   0.67742        30\n",
      "           1    0.75000   0.60000   0.66667        30\n",
      "           2    0.56250   0.60000   0.58065        30\n",
      "           3    0.55556   0.66667   0.60606        30\n",
      "           4    0.66667   0.66667   0.66667        30\n",
      "           5    0.69565   0.53333   0.60377        30\n",
      "           6    0.84848   0.93333   0.88889        30\n",
      "\n",
      "    accuracy                        0.67143       210\n",
      "   macro avg    0.67644   0.67143   0.67002       210\n",
      "weighted avg    0.67644   0.67143   0.67002       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
