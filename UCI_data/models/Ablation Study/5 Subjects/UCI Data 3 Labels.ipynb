{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '90 tBodyAccJerk-max()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '272 fBodyAcc-mad()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42 tGravityAcc-mean()-Y</th>\n",
       "      <th>43 tGravityAcc-mean()-Z</th>\n",
       "      <th>51 tGravityAcc-max()-Y</th>\n",
       "      <th>52 tGravityAcc-max()-Z</th>\n",
       "      <th>54 tGravityAcc-min()-Y</th>\n",
       "      <th>55 tGravityAcc-min()-Z</th>\n",
       "      <th>56 tGravityAcc-sma()</th>\n",
       "      <th>58 tGravityAcc-energy()-Y</th>\n",
       "      <th>475 fBodyGyro-bandsEnergy()-1,8</th>\n",
       "      <th>483 fBodyGyro-bandsEnergy()-1,16</th>\n",
       "      <th>...</th>\n",
       "      <th>272 fBodyAcc-mad()-X</th>\n",
       "      <th>282 fBodyAcc-energy()-X</th>\n",
       "      <th>303 fBodyAcc-bandsEnergy()-1,8</th>\n",
       "      <th>311 fBodyAcc-bandsEnergy()-1,16</th>\n",
       "      <th>315 fBodyAcc-bandsEnergy()-1,24</th>\n",
       "      <th>504 fBodyAccMag-std()</th>\n",
       "      <th>505 fBodyAccMag-mad()</th>\n",
       "      <th>509 fBodyAccMag-energy()</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140840</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>-0.161265</td>\n",
       "      <td>0.124660</td>\n",
       "      <td>-0.123213</td>\n",
       "      <td>0.056483</td>\n",
       "      <td>-0.375426</td>\n",
       "      <td>-0.970905</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>-0.999619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.996889</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.999963</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999971</td>\n",
       "      <td>-0.956134</td>\n",
       "      <td>-0.948870</td>\n",
       "      <td>-0.998285</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.141551</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>-0.161343</td>\n",
       "      <td>0.122586</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.383430</td>\n",
       "      <td>-0.970583</td>\n",
       "      <td>-0.999856</td>\n",
       "      <td>-0.999897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997890</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.975866</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>-0.999472</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.142010</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.094566</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>0.102764</td>\n",
       "      <td>-0.401602</td>\n",
       "      <td>-0.970368</td>\n",
       "      <td>-0.999954</td>\n",
       "      <td>-0.999962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.994097</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999983</td>\n",
       "      <td>-0.999972</td>\n",
       "      <td>-0.989015</td>\n",
       "      <td>-0.985594</td>\n",
       "      <td>-0.999807</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.143976</td>\n",
       "      <td>0.099850</td>\n",
       "      <td>-0.163711</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>-0.121336</td>\n",
       "      <td>0.095753</td>\n",
       "      <td>-0.400278</td>\n",
       "      <td>-0.969400</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>-0.999947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.994547</td>\n",
       "      <td>-0.999975</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.999986</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.986742</td>\n",
       "      <td>-0.983524</td>\n",
       "      <td>-0.999770</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.148750</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.166786</td>\n",
       "      <td>0.091682</td>\n",
       "      <td>-0.121834</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>-0.400477</td>\n",
       "      <td>-0.967051</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>-0.999946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997725</td>\n",
       "      <td>-0.999990</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.990063</td>\n",
       "      <td>-0.992324</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>-0.222004</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.214233</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.071977</td>\n",
       "      <td>-0.405132</td>\n",
       "      <td>-0.918375</td>\n",
       "      <td>-0.053258</td>\n",
       "      <td>-0.307101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050748</td>\n",
       "      <td>-0.674230</td>\n",
       "      <td>-0.684177</td>\n",
       "      <td>-0.666429</td>\n",
       "      <td>-0.668164</td>\n",
       "      <td>-0.232600</td>\n",
       "      <td>-0.007392</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>-0.242054</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.234998</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.358934</td>\n",
       "      <td>-0.902880</td>\n",
       "      <td>-0.029411</td>\n",
       "      <td>-0.286728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177661</td>\n",
       "      <td>-0.705580</td>\n",
       "      <td>-0.726986</td>\n",
       "      <td>-0.704444</td>\n",
       "      <td>-0.705435</td>\n",
       "      <td>-0.275373</td>\n",
       "      <td>-0.172448</td>\n",
       "      <td>-0.632536</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>-0.236950</td>\n",
       "      <td>-0.026805</td>\n",
       "      <td>-0.249134</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.216004</td>\n",
       "      <td>-0.068919</td>\n",
       "      <td>-0.377025</td>\n",
       "      <td>-0.907561</td>\n",
       "      <td>0.161404</td>\n",
       "      <td>-0.164197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249486</td>\n",
       "      <td>-0.692379</td>\n",
       "      <td>-0.655263</td>\n",
       "      <td>-0.674515</td>\n",
       "      <td>-0.684729</td>\n",
       "      <td>-0.220288</td>\n",
       "      <td>-0.216074</td>\n",
       "      <td>-0.641170</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>-0.233230</td>\n",
       "      <td>-0.004984</td>\n",
       "      <td>-0.244267</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>-0.210542</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-0.440050</td>\n",
       "      <td>-0.910648</td>\n",
       "      <td>0.193585</td>\n",
       "      <td>-0.155644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247028</td>\n",
       "      <td>-0.693098</td>\n",
       "      <td>-0.643425</td>\n",
       "      <td>-0.677215</td>\n",
       "      <td>-0.685088</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>-0.220443</td>\n",
       "      <td>-0.663579</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7351</th>\n",
       "      <td>-0.233292</td>\n",
       "      <td>-0.020954</td>\n",
       "      <td>-0.240956</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.212149</td>\n",
       "      <td>-0.047491</td>\n",
       "      <td>-0.432003</td>\n",
       "      <td>-0.910579</td>\n",
       "      <td>-0.129277</td>\n",
       "      <td>-0.384693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114475</td>\n",
       "      <td>-0.731037</td>\n",
       "      <td>-0.709495</td>\n",
       "      <td>-0.728519</td>\n",
       "      <td>-0.727441</td>\n",
       "      <td>-0.342670</td>\n",
       "      <td>-0.146649</td>\n",
       "      <td>-0.698087</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7352 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      42 tGravityAcc-mean()-Y  43 tGravityAcc-mean()-Z  \\\n",
       "0                   -0.140840                 0.115375   \n",
       "1                   -0.141551                 0.109379   \n",
       "2                   -0.142010                 0.101884   \n",
       "3                   -0.143976                 0.099850   \n",
       "4                   -0.148750                 0.094486   \n",
       "...                       ...                      ...   \n",
       "7347                -0.222004                -0.039492   \n",
       "7348                -0.242054                -0.039863   \n",
       "7349                -0.236950                -0.026805   \n",
       "7350                -0.233230                -0.004984   \n",
       "7351                -0.233292                -0.020954   \n",
       "\n",
       "      51 tGravityAcc-max()-Y  52 tGravityAcc-max()-Z  54 tGravityAcc-min()-Y  \\\n",
       "0                  -0.161265                0.124660               -0.123213   \n",
       "1                  -0.161343                0.122586               -0.114893   \n",
       "2                  -0.163711                0.094566               -0.114893   \n",
       "3                  -0.163711                0.093425               -0.121336   \n",
       "4                  -0.166786                0.091682               -0.121834   \n",
       "...                      ...                     ...                     ...   \n",
       "7347               -0.214233               -0.016391               -0.234998   \n",
       "7348               -0.231477               -0.016391               -0.234998   \n",
       "7349               -0.249134                0.024684               -0.216004   \n",
       "7350               -0.244267                0.024684               -0.210542   \n",
       "7351               -0.240956                0.003031               -0.212149   \n",
       "\n",
       "      55 tGravityAcc-min()-Z  56 tGravityAcc-sma()  58 tGravityAcc-energy()-Y  \\\n",
       "0                   0.056483             -0.375426                  -0.970905   \n",
       "1                   0.102764             -0.383430                  -0.970583   \n",
       "2                   0.102764             -0.401602                  -0.970368   \n",
       "3                   0.095753             -0.400278                  -0.969400   \n",
       "4                   0.094059             -0.400477                  -0.967051   \n",
       "...                      ...                   ...                        ...   \n",
       "7347               -0.071977             -0.405132                  -0.918375   \n",
       "7348               -0.068919             -0.358934                  -0.902880   \n",
       "7349               -0.068919             -0.377025                  -0.907561   \n",
       "7350               -0.040009             -0.440050                  -0.910648   \n",
       "7351               -0.047491             -0.432003                  -0.910579   \n",
       "\n",
       "      475 fBodyGyro-bandsEnergy()-1,8  483 fBodyGyro-bandsEnergy()-1,16  ...  \\\n",
       "0                           -0.999454                         -0.999619  ...   \n",
       "1                           -0.999856                         -0.999897  ...   \n",
       "2                           -0.999954                         -0.999962  ...   \n",
       "3                           -0.999931                         -0.999947  ...   \n",
       "4                           -0.999926                         -0.999946  ...   \n",
       "...                               ...                               ...  ...   \n",
       "7347                        -0.053258                         -0.307101  ...   \n",
       "7348                        -0.029411                         -0.286728  ...   \n",
       "7349                         0.161404                         -0.164197  ...   \n",
       "7350                         0.193585                         -0.155644  ...   \n",
       "7351                        -0.129277                         -0.384693  ...   \n",
       "\n",
       "      272 fBodyAcc-mad()-X  282 fBodyAcc-energy()-X  \\\n",
       "0                -0.996889                -0.999968   \n",
       "1                -0.997890                -0.999991   \n",
       "2                -0.994097                -0.999969   \n",
       "3                -0.994547                -0.999975   \n",
       "4                -0.997725                -0.999990   \n",
       "...                    ...                      ...   \n",
       "7347             -0.050748                -0.674230   \n",
       "7348             -0.177661                -0.705580   \n",
       "7349             -0.249486                -0.692379   \n",
       "7350             -0.247028                -0.693098   \n",
       "7351             -0.114475                -0.731037   \n",
       "\n",
       "      303 fBodyAcc-bandsEnergy()-1,8  311 fBodyAcc-bandsEnergy()-1,16  \\\n",
       "0                          -0.999963                        -0.999969   \n",
       "1                          -0.999996                        -0.999994   \n",
       "2                          -0.999989                        -0.999983   \n",
       "3                          -0.999989                        -0.999986   \n",
       "4                          -0.999994                        -0.999993   \n",
       "...                              ...                              ...   \n",
       "7347                       -0.684177                        -0.666429   \n",
       "7348                       -0.726986                        -0.704444   \n",
       "7349                       -0.655263                        -0.674515   \n",
       "7350                       -0.643425                        -0.677215   \n",
       "7351                       -0.709495                        -0.728519   \n",
       "\n",
       "      315 fBodyAcc-bandsEnergy()-1,24  504 fBodyAccMag-std()  \\\n",
       "0                           -0.999971              -0.956134   \n",
       "1                           -0.999992              -0.975866   \n",
       "2                           -0.999972              -0.989015   \n",
       "3                           -0.999977              -0.986742   \n",
       "4                           -0.999991              -0.990063   \n",
       "...                               ...                    ...   \n",
       "7347                        -0.668164              -0.232600   \n",
       "7348                        -0.705435              -0.275373   \n",
       "7349                        -0.684729              -0.220288   \n",
       "7350                        -0.685088              -0.234539   \n",
       "7351                        -0.727441              -0.342670   \n",
       "\n",
       "      505 fBodyAccMag-mad()  509 fBodyAccMag-energy()  Activity  Subject  \n",
       "0                 -0.948870                 -0.998285         5        1  \n",
       "1                 -0.975777                 -0.999472         5        1  \n",
       "2                 -0.985594                 -0.999807         5        1  \n",
       "3                 -0.983524                 -0.999770         5        1  \n",
       "4                 -0.992324                 -0.999873         5        1  \n",
       "...                     ...                       ...       ...      ...  \n",
       "7347              -0.007392                 -0.584282         2       30  \n",
       "7348              -0.172448                 -0.632536         2       30  \n",
       "7349              -0.216074                 -0.641170         2       30  \n",
       "7350              -0.220443                 -0.663579         2       30  \n",
       "7351              -0.146649                 -0.698087         2       30  \n",
       "\n",
       "[7352 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_names = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "train_column_names = train_names.values.tolist()\n",
    "train_column_names = [k for row in train_column_names for k in row]\n",
    "\n",
    "train_data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None)\n",
    "train_data.columns = train_column_names\n",
    "\n",
    "### Single dataframe column\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "y_train.columns = ['Activity']\n",
    "\n",
    "y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "y_train_subject.columns = ['Subject']\n",
    "\n",
    "X_train_1 = train_data[sub_features]\n",
    "X_train_2 = train_data[act_features]\n",
    "X_train_data = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "\n",
    "X_train_data = pd.concat([X_train_data, y_train, y_train_subject], axis = 1)\n",
    "X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,:-2].values\n",
    "y_train = X_train_data[(X_train_data['Subject'].isin([1, 3, 5, 7, 8])) & (X_train_data['Activity'].isin([1, 3, 4]))].iloc[:,-2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y_train)):\n",
    "    if y_train[k] == 1:\n",
    "        y_train[k] = 0\n",
    "    elif y_train[k] == 3:\n",
    "        y_train[k] = 1\n",
    "    else:\n",
    "        y_train[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 30),\n",
    "            classifier_block(30, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.3818461894989014, Final Batch Loss: 1.1199910640716553\n",
      "Epoch 2, Loss: 3.360764741897583, Final Batch Loss: 1.1248975992202759\n",
      "Epoch 3, Loss: 3.345532536506653, Final Batch Loss: 1.108768105506897\n",
      "Epoch 4, Loss: 3.321077346801758, Final Batch Loss: 1.1103602647781372\n",
      "Epoch 5, Loss: 3.304026961326599, Final Batch Loss: 1.0953086614608765\n",
      "Epoch 6, Loss: 3.2789058685302734, Final Batch Loss: 1.0852421522140503\n",
      "Epoch 7, Loss: 3.2608437538146973, Final Batch Loss: 1.0772026777267456\n",
      "Epoch 8, Loss: 3.2395211458206177, Final Batch Loss: 1.0718973875045776\n",
      "Epoch 9, Loss: 3.2058804035186768, Final Batch Loss: 1.0648943185806274\n",
      "Epoch 10, Loss: 3.1618908643722534, Final Batch Loss: 1.0490577220916748\n",
      "Epoch 11, Loss: 3.1340503692626953, Final Batch Loss: 1.0386773347854614\n",
      "Epoch 12, Loss: 3.08295476436615, Final Batch Loss: 1.0163066387176514\n",
      "Epoch 13, Loss: 3.0603578090667725, Final Batch Loss: 1.0187907218933105\n",
      "Epoch 14, Loss: 3.0092798471450806, Final Batch Loss: 0.9964610934257507\n",
      "Epoch 15, Loss: 2.938363552093506, Final Batch Loss: 0.9670467376708984\n",
      "Epoch 16, Loss: 2.895654857158661, Final Batch Loss: 0.9599564671516418\n",
      "Epoch 17, Loss: 2.8121359944343567, Final Batch Loss: 0.947246253490448\n",
      "Epoch 18, Loss: 2.7082966566085815, Final Batch Loss: 0.8854697942733765\n",
      "Epoch 19, Loss: 2.608367621898651, Final Batch Loss: 0.8494979739189148\n",
      "Epoch 20, Loss: 2.4970187544822693, Final Batch Loss: 0.8117977976799011\n",
      "Epoch 21, Loss: 2.3800012469291687, Final Batch Loss: 0.7699708342552185\n",
      "Epoch 22, Loss: 2.2114976048469543, Final Batch Loss: 0.7152990698814392\n",
      "Epoch 23, Loss: 2.087614417076111, Final Batch Loss: 0.6656762361526489\n",
      "Epoch 24, Loss: 1.9825533628463745, Final Batch Loss: 0.6475714445114136\n",
      "Epoch 25, Loss: 1.7366234064102173, Final Batch Loss: 0.5572368502616882\n",
      "Epoch 26, Loss: 1.6824623942375183, Final Batch Loss: 0.5580902695655823\n",
      "Epoch 27, Loss: 1.585775911808014, Final Batch Loss: 0.5267760157585144\n",
      "Epoch 28, Loss: 1.3693268299102783, Final Batch Loss: 0.4649936258792877\n",
      "Epoch 29, Loss: 1.2348613739013672, Final Batch Loss: 0.4226304888725281\n",
      "Epoch 30, Loss: 1.2336877286434174, Final Batch Loss: 0.3879396617412567\n",
      "Epoch 31, Loss: 1.1348636746406555, Final Batch Loss: 0.37290650606155396\n",
      "Epoch 32, Loss: 0.9852083623409271, Final Batch Loss: 0.3256583511829376\n",
      "Epoch 33, Loss: 0.9155406355857849, Final Batch Loss: 0.2859824299812317\n",
      "Epoch 34, Loss: 0.8703437447547913, Final Batch Loss: 0.31712040305137634\n",
      "Epoch 35, Loss: 0.894404411315918, Final Batch Loss: 0.2660365402698517\n",
      "Epoch 36, Loss: 0.7539394199848175, Final Batch Loss: 0.21717679500579834\n",
      "Epoch 37, Loss: 0.8458670377731323, Final Batch Loss: 0.281603068113327\n",
      "Epoch 38, Loss: 0.719679519534111, Final Batch Loss: 0.23106704652309418\n",
      "Epoch 39, Loss: 0.6957602351903915, Final Batch Loss: 0.15873666107654572\n",
      "Epoch 40, Loss: 0.684871643781662, Final Batch Loss: 0.22485491633415222\n",
      "Epoch 41, Loss: 0.6141643822193146, Final Batch Loss: 0.20846833288669586\n",
      "Epoch 42, Loss: 0.6907824128866196, Final Batch Loss: 0.24432386457920074\n",
      "Epoch 43, Loss: 0.6052483320236206, Final Batch Loss: 0.22084581851959229\n",
      "Epoch 44, Loss: 0.5848280787467957, Final Batch Loss: 0.15458907186985016\n",
      "Epoch 45, Loss: 0.5615896433591843, Final Batch Loss: 0.22725559771060944\n",
      "Epoch 46, Loss: 0.5627796053886414, Final Batch Loss: 0.1594676673412323\n",
      "Epoch 47, Loss: 0.42127327620983124, Final Batch Loss: 0.09513135254383087\n",
      "Epoch 48, Loss: 0.46319450438022614, Final Batch Loss: 0.15685459971427917\n",
      "Epoch 49, Loss: 0.4521665722131729, Final Batch Loss: 0.12747593224048615\n",
      "Epoch 50, Loss: 0.5030525028705597, Final Batch Loss: 0.1802932769060135\n",
      "Epoch 51, Loss: 0.5393045246601105, Final Batch Loss: 0.19843287765979767\n",
      "Epoch 52, Loss: 0.4772624373435974, Final Batch Loss: 0.18350379168987274\n",
      "Epoch 53, Loss: 0.5015590488910675, Final Batch Loss: 0.1927613914012909\n",
      "Epoch 54, Loss: 0.439078189432621, Final Batch Loss: 0.13484595715999603\n",
      "Epoch 55, Loss: 0.3973194733262062, Final Batch Loss: 0.13170263171195984\n",
      "Epoch 56, Loss: 0.41069868206977844, Final Batch Loss: 0.12581397593021393\n",
      "Epoch 57, Loss: 0.38843492418527603, Final Batch Loss: 0.1364811211824417\n",
      "Epoch 58, Loss: 0.3490333631634712, Final Batch Loss: 0.07145101577043533\n",
      "Epoch 59, Loss: 0.37299272418022156, Final Batch Loss: 0.10529238730669022\n",
      "Epoch 60, Loss: 0.37903808057308197, Final Batch Loss: 0.1082686334848404\n",
      "Epoch 61, Loss: 0.37910959124565125, Final Batch Loss: 0.11359646916389465\n",
      "Epoch 62, Loss: 0.3564530536532402, Final Batch Loss: 0.09361954778432846\n",
      "Epoch 63, Loss: 0.3811573386192322, Final Batch Loss: 0.15058356523513794\n",
      "Epoch 64, Loss: 0.3879758268594742, Final Batch Loss: 0.14889828860759735\n",
      "Epoch 65, Loss: 0.44063030928373337, Final Batch Loss: 0.22545136511325836\n",
      "Epoch 66, Loss: 0.38242653757333755, Final Batch Loss: 0.15843676030635834\n",
      "Epoch 67, Loss: 0.34341762959957123, Final Batch Loss: 0.09409681707620621\n",
      "Epoch 68, Loss: 0.3430163189768791, Final Batch Loss: 0.10204204171895981\n",
      "Epoch 69, Loss: 0.3810245767235756, Final Batch Loss: 0.17929592728614807\n",
      "Epoch 70, Loss: 0.29239609092473984, Final Batch Loss: 0.09002639353275299\n",
      "Epoch 71, Loss: 0.33798258751630783, Final Batch Loss: 0.06963077932596207\n",
      "Epoch 72, Loss: 0.3352997899055481, Final Batch Loss: 0.07932654023170471\n",
      "Epoch 73, Loss: 0.32004478573799133, Final Batch Loss: 0.09934873878955841\n",
      "Epoch 74, Loss: 0.39249366521835327, Final Batch Loss: 0.1855998933315277\n",
      "Epoch 75, Loss: 0.33274729549884796, Final Batch Loss: 0.13640813529491425\n",
      "Epoch 76, Loss: 0.3486013412475586, Final Batch Loss: 0.12604546546936035\n",
      "Epoch 77, Loss: 0.3134492337703705, Final Batch Loss: 0.1127510517835617\n",
      "Epoch 78, Loss: 0.28796474635601044, Final Batch Loss: 0.07556483149528503\n",
      "Epoch 79, Loss: 0.33766354620456696, Final Batch Loss: 0.11596706509590149\n",
      "Epoch 80, Loss: 0.3443165794014931, Final Batch Loss: 0.09716923534870148\n",
      "Epoch 81, Loss: 0.335900716483593, Final Batch Loss: 0.09599841386079788\n",
      "Epoch 82, Loss: 0.34165362268686295, Final Batch Loss: 0.12436368316411972\n",
      "Epoch 83, Loss: 0.33074989914894104, Final Batch Loss: 0.11141844838857651\n",
      "Epoch 84, Loss: 0.3673627972602844, Final Batch Loss: 0.15531210601329803\n",
      "Epoch 85, Loss: 0.3001936748623848, Final Batch Loss: 0.08442424982786179\n",
      "Epoch 86, Loss: 0.342572957277298, Final Batch Loss: 0.1414036750793457\n",
      "Epoch 87, Loss: 0.31559907644987106, Final Batch Loss: 0.14113469421863556\n",
      "Epoch 88, Loss: 0.29695725440979004, Final Batch Loss: 0.10603153705596924\n",
      "Epoch 89, Loss: 0.2529098130762577, Final Batch Loss: 0.09381292015314102\n",
      "Epoch 90, Loss: 0.273397833108902, Final Batch Loss: 0.1112179234623909\n",
      "Epoch 91, Loss: 0.27226559072732925, Final Batch Loss: 0.10848642140626907\n",
      "Epoch 92, Loss: 0.2932019382715225, Final Batch Loss: 0.10318397730588913\n",
      "Epoch 93, Loss: 0.3133595362305641, Final Batch Loss: 0.13756953179836273\n",
      "Epoch 94, Loss: 0.30210649222135544, Final Batch Loss: 0.07473933696746826\n",
      "Epoch 95, Loss: 0.3330470323562622, Final Batch Loss: 0.14886415004730225\n",
      "Epoch 96, Loss: 0.25304390490055084, Final Batch Loss: 0.10148503631353378\n",
      "Epoch 97, Loss: 0.26812694221735, Final Batch Loss: 0.09912947565317154\n",
      "Epoch 98, Loss: 0.2791789323091507, Final Batch Loss: 0.09252970665693283\n",
      "Epoch 99, Loss: 0.26431332528591156, Final Batch Loss: 0.0929119810461998\n",
      "Epoch 100, Loss: 0.30378465726971626, Final Batch Loss: 0.1370037943124771\n",
      "Epoch 101, Loss: 0.2812027335166931, Final Batch Loss: 0.10267733782529831\n",
      "Epoch 102, Loss: 0.33758223056793213, Final Batch Loss: 0.12710294127464294\n",
      "Epoch 103, Loss: 0.28226104378700256, Final Batch Loss: 0.09793490171432495\n",
      "Epoch 104, Loss: 0.2976296618580818, Final Batch Loss: 0.12391750514507294\n",
      "Epoch 105, Loss: 0.26714327931404114, Final Batch Loss: 0.07644908875226974\n",
      "Epoch 106, Loss: 0.2896837070584297, Final Batch Loss: 0.08429320156574249\n",
      "Epoch 107, Loss: 0.30738282203674316, Final Batch Loss: 0.12018429487943649\n",
      "Epoch 108, Loss: 0.2377399280667305, Final Batch Loss: 0.033623963594436646\n",
      "Epoch 109, Loss: 0.2559695839881897, Final Batch Loss: 0.08715887367725372\n",
      "Epoch 110, Loss: 0.2370774820446968, Final Batch Loss: 0.07986798882484436\n",
      "Epoch 111, Loss: 0.2888018488883972, Final Batch Loss: 0.06256008893251419\n",
      "Epoch 112, Loss: 0.2715977802872658, Final Batch Loss: 0.07613128423690796\n",
      "Epoch 113, Loss: 0.2607821896672249, Final Batch Loss: 0.13586001098155975\n",
      "Epoch 114, Loss: 0.2508561313152313, Final Batch Loss: 0.08348657190799713\n",
      "Epoch 115, Loss: 0.2749742269515991, Final Batch Loss: 0.07539312541484833\n",
      "Epoch 116, Loss: 0.24287425726652145, Final Batch Loss: 0.08711080998182297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, Loss: 0.25040021538734436, Final Batch Loss: 0.11111901700496674\n",
      "Epoch 118, Loss: 0.2344067320227623, Final Batch Loss: 0.07544846832752228\n",
      "Epoch 119, Loss: 0.2423417717218399, Final Batch Loss: 0.030393123626708984\n",
      "Epoch 120, Loss: 0.21522139385342598, Final Batch Loss: 0.075160451233387\n",
      "Epoch 121, Loss: 0.23867261409759521, Final Batch Loss: 0.09622912108898163\n",
      "Epoch 122, Loss: 0.2704731896519661, Final Batch Loss: 0.09525503218173981\n",
      "Epoch 123, Loss: 0.24924403429031372, Final Batch Loss: 0.07612251490354538\n",
      "Epoch 124, Loss: 0.2517349123954773, Final Batch Loss: 0.10492121428251266\n",
      "Epoch 125, Loss: 0.23464252799749374, Final Batch Loss: 0.11213649809360504\n",
      "Epoch 126, Loss: 0.2842940539121628, Final Batch Loss: 0.11813196539878845\n",
      "Epoch 127, Loss: 0.23642971366643906, Final Batch Loss: 0.09036292880773544\n",
      "Epoch 128, Loss: 0.28207990154623985, Final Batch Loss: 0.12288022041320801\n",
      "Epoch 129, Loss: 0.23341692239046097, Final Batch Loss: 0.08130935579538345\n",
      "Epoch 130, Loss: 0.22838741540908813, Final Batch Loss: 0.06958109140396118\n",
      "Epoch 131, Loss: 0.23655762895941734, Final Batch Loss: 0.07758449018001556\n",
      "Epoch 132, Loss: 0.22641927376389503, Final Batch Loss: 0.07321838289499283\n",
      "Epoch 133, Loss: 0.19909603521227837, Final Batch Loss: 0.0788419172167778\n",
      "Epoch 134, Loss: 0.2357005551457405, Final Batch Loss: 0.09213893115520477\n",
      "Epoch 135, Loss: 0.20368407666683197, Final Batch Loss: 0.09426461160182953\n",
      "Epoch 136, Loss: 0.21637488156557083, Final Batch Loss: 0.0534915030002594\n",
      "Epoch 137, Loss: 0.2288488820195198, Final Batch Loss: 0.08419997990131378\n",
      "Epoch 138, Loss: 0.2036106213927269, Final Batch Loss: 0.03817383199930191\n",
      "Epoch 139, Loss: 0.23617032170295715, Final Batch Loss: 0.06708309799432755\n",
      "Epoch 140, Loss: 0.21874737739562988, Final Batch Loss: 0.0766192302107811\n",
      "Epoch 141, Loss: 0.22249199450016022, Final Batch Loss: 0.07361626625061035\n",
      "Epoch 142, Loss: 0.24283500388264656, Final Batch Loss: 0.0599791593849659\n",
      "Epoch 143, Loss: 0.22237835824489594, Final Batch Loss: 0.045820895582437515\n",
      "Epoch 144, Loss: 0.2040817029774189, Final Batch Loss: 0.04119854047894478\n",
      "Epoch 145, Loss: 0.2483733706176281, Final Batch Loss: 0.06507237255573273\n",
      "Epoch 146, Loss: 0.23458390682935715, Final Batch Loss: 0.08194706588983536\n",
      "Epoch 147, Loss: 0.27187227457761765, Final Batch Loss: 0.04172314703464508\n",
      "Epoch 148, Loss: 0.23268013074994087, Final Batch Loss: 0.10702059417963028\n",
      "Epoch 149, Loss: 0.2463293969631195, Final Batch Loss: 0.08960752189159393\n",
      "Epoch 150, Loss: 0.19655299931764603, Final Batch Loss: 0.05429890379309654\n",
      "Epoch 151, Loss: 0.2313552312552929, Final Batch Loss: 0.059023674577474594\n",
      "Epoch 152, Loss: 0.18369218334555626, Final Batch Loss: 0.07508590072393417\n",
      "Epoch 153, Loss: 0.22540020942687988, Final Batch Loss: 0.08299720287322998\n",
      "Epoch 154, Loss: 0.21061449870467186, Final Batch Loss: 0.05813666060566902\n",
      "Epoch 155, Loss: 0.20129411295056343, Final Batch Loss: 0.04378792271018028\n",
      "Epoch 156, Loss: 0.21977081522345543, Final Batch Loss: 0.09699024260044098\n",
      "Epoch 157, Loss: 0.1806047484278679, Final Batch Loss: 0.04161375015974045\n",
      "Epoch 158, Loss: 0.17984740063548088, Final Batch Loss: 0.04757028445601463\n",
      "Epoch 159, Loss: 0.22513851895928383, Final Batch Loss: 0.08381370455026627\n",
      "Epoch 160, Loss: 0.20483581349253654, Final Batch Loss: 0.07652963697910309\n",
      "Epoch 161, Loss: 0.2679811827838421, Final Batch Loss: 0.11227025836706161\n",
      "Epoch 162, Loss: 0.2291504144668579, Final Batch Loss: 0.09711826592683792\n",
      "Epoch 163, Loss: 0.2002946101129055, Final Batch Loss: 0.059853728860616684\n",
      "Epoch 164, Loss: 0.20056824013590813, Final Batch Loss: 0.07960385829210281\n",
      "Epoch 165, Loss: 0.19486461952328682, Final Batch Loss: 0.048557180911302567\n",
      "Epoch 166, Loss: 0.16347327828407288, Final Batch Loss: 0.05331447720527649\n",
      "Epoch 167, Loss: 0.2137291207909584, Final Batch Loss: 0.0666513442993164\n",
      "Epoch 168, Loss: 0.1846875324845314, Final Batch Loss: 0.03577841818332672\n",
      "Epoch 169, Loss: 0.19757601246237755, Final Batch Loss: 0.0660037249326706\n",
      "Epoch 170, Loss: 0.2202186994254589, Final Batch Loss: 0.06857840716838837\n",
      "Epoch 171, Loss: 0.18862132728099823, Final Batch Loss: 0.07669790089130402\n",
      "Epoch 172, Loss: 0.18471619486808777, Final Batch Loss: 0.032852232456207275\n",
      "Epoch 173, Loss: 0.17073583975434303, Final Batch Loss: 0.04391852021217346\n",
      "Epoch 174, Loss: 0.1841486543416977, Final Batch Loss: 0.06606308370828629\n",
      "Epoch 175, Loss: 0.2099077571183443, Final Batch Loss: 0.10567386448383331\n",
      "Epoch 176, Loss: 0.19401192292571068, Final Batch Loss: 0.04991660639643669\n",
      "Epoch 177, Loss: 0.21953754499554634, Final Batch Loss: 0.1179550513625145\n",
      "Epoch 178, Loss: 0.20403143763542175, Final Batch Loss: 0.0756034180521965\n",
      "Epoch 179, Loss: 0.1911890059709549, Final Batch Loss: 0.054141197353601456\n",
      "Epoch 180, Loss: 0.19645249471068382, Final Batch Loss: 0.042955175042152405\n",
      "Epoch 181, Loss: 0.20066146552562714, Final Batch Loss: 0.044939011335372925\n",
      "Epoch 182, Loss: 0.2189997136592865, Final Batch Loss: 0.08951763063669205\n",
      "Epoch 183, Loss: 0.22591694816946983, Final Batch Loss: 0.12806829810142517\n",
      "Epoch 184, Loss: 0.17643520794808865, Final Batch Loss: 0.10506628453731537\n",
      "Epoch 185, Loss: 0.1871051788330078, Final Batch Loss: 0.09115820378065109\n",
      "Epoch 186, Loss: 0.18388625793159008, Final Batch Loss: 0.07314302772283554\n",
      "Epoch 187, Loss: 0.15737568587064743, Final Batch Loss: 0.03001602366566658\n",
      "Epoch 188, Loss: 0.18847889080643654, Final Batch Loss: 0.0836559310555458\n",
      "Epoch 189, Loss: 0.1698036789894104, Final Batch Loss: 0.041817136108875275\n",
      "Epoch 190, Loss: 0.22181756794452667, Final Batch Loss: 0.08282426744699478\n",
      "Epoch 191, Loss: 0.1888258457183838, Final Batch Loss: 0.050487272441387177\n",
      "Epoch 192, Loss: 0.16974153369665146, Final Batch Loss: 0.055303942412137985\n",
      "Epoch 193, Loss: 0.16031639277935028, Final Batch Loss: 0.023149482905864716\n",
      "Epoch 194, Loss: 0.18717289716005325, Final Batch Loss: 0.07272402942180634\n",
      "Epoch 195, Loss: 0.17583873495459557, Final Batch Loss: 0.045731060206890106\n",
      "Epoch 196, Loss: 0.20011691376566887, Final Batch Loss: 0.10218235105276108\n",
      "Epoch 197, Loss: 0.18310533091425896, Final Batch Loss: 0.06079315021634102\n",
      "Epoch 198, Loss: 0.12200706079602242, Final Batch Loss: 0.0163433775305748\n",
      "Epoch 199, Loss: 0.15751097351312637, Final Batch Loss: 0.028022177517414093\n",
      "Epoch 200, Loss: 0.18262812122702599, Final Batch Loss: 0.07413177192211151\n",
      "Epoch 201, Loss: 0.14018003642559052, Final Batch Loss: 0.020083297044038773\n",
      "Epoch 202, Loss: 0.18860408291220665, Final Batch Loss: 0.06472860276699066\n",
      "Epoch 203, Loss: 0.15333078242838383, Final Batch Loss: 0.015877777710556984\n",
      "Epoch 204, Loss: 0.1938561126589775, Final Batch Loss: 0.06555488705635071\n",
      "Epoch 205, Loss: 0.15647951886057854, Final Batch Loss: 0.052282948046922684\n",
      "Epoch 206, Loss: 0.16329682245850563, Final Batch Loss: 0.03455765172839165\n",
      "Epoch 207, Loss: 0.1813940405845642, Final Batch Loss: 0.05950350686907768\n",
      "Epoch 208, Loss: 0.21765683963894844, Final Batch Loss: 0.10531513392925262\n",
      "Epoch 209, Loss: 0.16884363070130348, Final Batch Loss: 0.07415749877691269\n",
      "Epoch 210, Loss: 0.199707243591547, Final Batch Loss: 0.08741547167301178\n",
      "Epoch 211, Loss: 0.1486690379679203, Final Batch Loss: 0.037946667522192\n",
      "Epoch 212, Loss: 0.17563385516405106, Final Batch Loss: 0.021556876599788666\n",
      "Epoch 213, Loss: 0.163433488458395, Final Batch Loss: 0.03957471624016762\n",
      "Epoch 214, Loss: 0.12362901493906975, Final Batch Loss: 0.01212257519364357\n",
      "Epoch 215, Loss: 0.14868498966097832, Final Batch Loss: 0.042275723069906235\n",
      "Epoch 216, Loss: 0.17099640890955925, Final Batch Loss: 0.060648925602436066\n",
      "Epoch 217, Loss: 0.15827000886201859, Final Batch Loss: 0.0492253452539444\n",
      "Epoch 218, Loss: 0.1631070412695408, Final Batch Loss: 0.05637102201581001\n",
      "Epoch 219, Loss: 0.18496345728635788, Final Batch Loss: 0.08295270055532455\n",
      "Epoch 220, Loss: 0.17562227323651314, Final Batch Loss: 0.04355067387223244\n",
      "Epoch 221, Loss: 0.16084164008498192, Final Batch Loss: 0.06660737842321396\n",
      "Epoch 222, Loss: 0.14528506994247437, Final Batch Loss: 0.059924423694610596\n",
      "Epoch 223, Loss: 0.20857065171003342, Final Batch Loss: 0.1163502112030983\n",
      "Epoch 224, Loss: 0.12879158928990364, Final Batch Loss: 0.034164443612098694\n",
      "Epoch 225, Loss: 0.14963427931070328, Final Batch Loss: 0.06838032603263855\n",
      "Epoch 226, Loss: 0.16307848691940308, Final Batch Loss: 0.04323596879839897\n",
      "Epoch 227, Loss: 0.15174543298780918, Final Batch Loss: 0.07523609697818756\n",
      "Epoch 228, Loss: 0.13614623993635178, Final Batch Loss: 0.05127715319395065\n",
      "Epoch 229, Loss: 0.12344316393136978, Final Batch Loss: 0.018748119473457336\n",
      "Epoch 230, Loss: 0.14476164802908897, Final Batch Loss: 0.036735888570547104\n",
      "Epoch 231, Loss: 0.13117041066288948, Final Batch Loss: 0.0423867292702198\n",
      "Epoch 232, Loss: 0.16440927982330322, Final Batch Loss: 0.07196907699108124\n",
      "Epoch 233, Loss: 0.20250243321061134, Final Batch Loss: 0.09656167030334473\n",
      "Epoch 234, Loss: 0.17551040276885033, Final Batch Loss: 0.058118708431720734\n",
      "Epoch 235, Loss: 0.1248262133449316, Final Batch Loss: 0.021319130435585976\n",
      "Epoch 236, Loss: 0.15823474898934364, Final Batch Loss: 0.05208664387464523\n",
      "Epoch 237, Loss: 0.20808673277497292, Final Batch Loss: 0.1469520628452301\n",
      "Epoch 238, Loss: 0.13627640157938004, Final Batch Loss: 0.034687768667936325\n",
      "Epoch 239, Loss: 0.13889530673623085, Final Batch Loss: 0.045513588935136795\n",
      "Epoch 240, Loss: 0.12597208097577095, Final Batch Loss: 0.04841851443052292\n",
      "Epoch 241, Loss: 0.12358889635652304, Final Batch Loss: 0.012912779115140438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242, Loss: 0.20115768164396286, Final Batch Loss: 0.051896125078201294\n",
      "Epoch 243, Loss: 0.15602407790720463, Final Batch Loss: 0.07615938782691956\n",
      "Epoch 244, Loss: 0.12757301330566406, Final Batch Loss: 0.04269765317440033\n",
      "Epoch 245, Loss: 0.17528080567717552, Final Batch Loss: 0.07691202312707901\n",
      "Epoch 246, Loss: 0.1610003001987934, Final Batch Loss: 0.07317358255386353\n",
      "Epoch 247, Loss: 0.12936552055180073, Final Batch Loss: 0.05861755833029747\n",
      "Epoch 248, Loss: 0.14543847739696503, Final Batch Loss: 0.03927426040172577\n",
      "Epoch 249, Loss: 0.1412695050239563, Final Batch Loss: 0.04589027166366577\n",
      "Epoch 250, Loss: 0.1597229279577732, Final Batch Loss: 0.06416907906532288\n",
      "Epoch 251, Loss: 0.15381716191768646, Final Batch Loss: 0.05352433770895004\n",
      "Epoch 252, Loss: 0.15877271071076393, Final Batch Loss: 0.06000500172376633\n",
      "Epoch 253, Loss: 0.1517645362764597, Final Batch Loss: 0.01764580048620701\n",
      "Epoch 254, Loss: 0.13566698506474495, Final Batch Loss: 0.09244856238365173\n",
      "Epoch 255, Loss: 0.17931783571839333, Final Batch Loss: 0.08160880208015442\n",
      "Epoch 256, Loss: 0.16660544835031033, Final Batch Loss: 0.08012264221906662\n",
      "Epoch 257, Loss: 0.12671995349228382, Final Batch Loss: 0.020928597077727318\n",
      "Epoch 258, Loss: 0.164521848782897, Final Batch Loss: 0.09326407313346863\n",
      "Epoch 259, Loss: 0.13059404119849205, Final Batch Loss: 0.05280948057770729\n",
      "Epoch 260, Loss: 0.11463580653071404, Final Batch Loss: 0.040207430720329285\n",
      "Epoch 261, Loss: 0.12385624274611473, Final Batch Loss: 0.024012528359889984\n",
      "Epoch 262, Loss: 0.1283293291926384, Final Batch Loss: 0.03989194333553314\n",
      "Epoch 263, Loss: 0.14352321065962315, Final Batch Loss: 0.0544675812125206\n",
      "Epoch 264, Loss: 0.12480328790843487, Final Batch Loss: 0.060381438583135605\n",
      "Epoch 265, Loss: 0.12631186470389366, Final Batch Loss: 0.04901949316263199\n",
      "Epoch 266, Loss: 0.18658321350812912, Final Batch Loss: 0.09881413727998734\n",
      "Epoch 267, Loss: 0.14666848070919514, Final Batch Loss: 0.06741990149021149\n",
      "Epoch 268, Loss: 0.11786641739308834, Final Batch Loss: 0.018670348450541496\n",
      "Epoch 269, Loss: 0.12176148593425751, Final Batch Loss: 0.04212843254208565\n",
      "Epoch 270, Loss: 0.12495524808764458, Final Batch Loss: 0.05815279483795166\n",
      "Epoch 271, Loss: 0.1356790978461504, Final Batch Loss: 0.0867176502943039\n",
      "Epoch 272, Loss: 0.10812990739941597, Final Batch Loss: 0.013543788343667984\n",
      "Epoch 273, Loss: 0.11660905368626118, Final Batch Loss: 0.03088158555328846\n",
      "Epoch 274, Loss: 0.11795365624129772, Final Batch Loss: 0.030216213315725327\n",
      "Epoch 275, Loss: 0.12379514053463936, Final Batch Loss: 0.04457112029194832\n",
      "Epoch 276, Loss: 0.13769967295229435, Final Batch Loss: 0.05279144272208214\n",
      "Epoch 277, Loss: 0.14826948195695877, Final Batch Loss: 0.0555063858628273\n",
      "Epoch 278, Loss: 0.12112259492278099, Final Batch Loss: 0.03958265483379364\n",
      "Epoch 279, Loss: 0.1146012656390667, Final Batch Loss: 0.02220860868692398\n",
      "Epoch 280, Loss: 0.12598557583987713, Final Batch Loss: 0.0551372654736042\n",
      "Epoch 281, Loss: 0.14548305422067642, Final Batch Loss: 0.06037699803709984\n",
      "Epoch 282, Loss: 0.1278246808797121, Final Batch Loss: 0.016916053369641304\n",
      "Epoch 283, Loss: 0.12362218461930752, Final Batch Loss: 0.07888617366552353\n",
      "Epoch 284, Loss: 0.13676635921001434, Final Batch Loss: 0.03510652109980583\n",
      "Epoch 285, Loss: 0.10375557839870453, Final Batch Loss: 0.04504098370671272\n",
      "Epoch 286, Loss: 0.1156263118609786, Final Batch Loss: 0.05561688914895058\n",
      "Epoch 287, Loss: 0.1016058437526226, Final Batch Loss: 0.030408034101128578\n",
      "Epoch 288, Loss: 0.11108293570578098, Final Batch Loss: 0.02276063710451126\n",
      "Epoch 289, Loss: 0.10492485016584396, Final Batch Loss: 0.05291767790913582\n",
      "Epoch 290, Loss: 0.10772683843970299, Final Batch Loss: 0.03624014928936958\n",
      "Epoch 291, Loss: 0.1302895937114954, Final Batch Loss: 0.057662371546030045\n",
      "Epoch 292, Loss: 0.13380014896392822, Final Batch Loss: 0.08111698925495148\n",
      "Epoch 293, Loss: 0.12642676383256912, Final Batch Loss: 0.06056298315525055\n",
      "Epoch 294, Loss: 0.07987924665212631, Final Batch Loss: 0.01979990489780903\n",
      "Epoch 295, Loss: 0.08682692050933838, Final Batch Loss: 0.016474466770887375\n",
      "Epoch 296, Loss: 0.09429613687098026, Final Batch Loss: 0.02108878456056118\n",
      "Epoch 297, Loss: 0.10116774961352348, Final Batch Loss: 0.02027995139360428\n",
      "Epoch 298, Loss: 0.09958441369235516, Final Batch Loss: 0.03222135081887245\n",
      "Epoch 299, Loss: 0.10013118013739586, Final Batch Loss: 0.025962479412555695\n",
      "Epoch 300, Loss: 0.09839965961873531, Final Batch Loss: 0.03443984314799309\n",
      "Epoch 301, Loss: 0.09072841983288527, Final Batch Loss: 0.011539052240550518\n",
      "Epoch 302, Loss: 0.122566107660532, Final Batch Loss: 0.016244571655988693\n",
      "Epoch 303, Loss: 0.0906804297119379, Final Batch Loss: 0.009210074320435524\n",
      "Epoch 304, Loss: 0.12592089176177979, Final Batch Loss: 0.054983630776405334\n",
      "Epoch 305, Loss: 0.12459712475538254, Final Batch Loss: 0.05229946970939636\n",
      "Epoch 306, Loss: 0.09225041419267654, Final Batch Loss: 0.04767875373363495\n",
      "Epoch 307, Loss: 0.08068756945431232, Final Batch Loss: 0.02527036890387535\n",
      "Epoch 308, Loss: 0.10496525280177593, Final Batch Loss: 0.05353933945298195\n",
      "Epoch 309, Loss: 0.08374418877065182, Final Batch Loss: 0.022164126858115196\n",
      "Epoch 310, Loss: 0.12034210562705994, Final Batch Loss: 0.02600812539458275\n",
      "Epoch 311, Loss: 0.1163043174892664, Final Batch Loss: 0.0431831032037735\n",
      "Epoch 312, Loss: 0.12078352831304073, Final Batch Loss: 0.04580344632267952\n",
      "Epoch 313, Loss: 0.08366149384528399, Final Batch Loss: 0.008577997796237469\n",
      "Epoch 314, Loss: 0.0942497793585062, Final Batch Loss: 0.02182135172188282\n",
      "Epoch 315, Loss: 0.0862215394154191, Final Batch Loss: 0.03164980560541153\n",
      "Epoch 316, Loss: 0.09785505197942257, Final Batch Loss: 0.06248427927494049\n",
      "Epoch 317, Loss: 0.0842751506716013, Final Batch Loss: 0.019625339657068253\n",
      "Epoch 318, Loss: 0.08904711343348026, Final Batch Loss: 0.03978342562913895\n",
      "Epoch 319, Loss: 0.14690263383090496, Final Batch Loss: 0.09588538110256195\n",
      "Epoch 320, Loss: 0.09760528616607189, Final Batch Loss: 0.01390952430665493\n",
      "Epoch 321, Loss: 0.11743205040693283, Final Batch Loss: 0.03562793508172035\n",
      "Epoch 322, Loss: 0.09854063577950001, Final Batch Loss: 0.03719479963183403\n",
      "Epoch 323, Loss: 0.07655966375023127, Final Batch Loss: 0.03742397949099541\n",
      "Epoch 324, Loss: 0.10561262629926205, Final Batch Loss: 0.039703868329524994\n",
      "Epoch 325, Loss: 0.11521397903561592, Final Batch Loss: 0.06010299548506737\n",
      "Epoch 326, Loss: 0.11232333164662123, Final Batch Loss: 0.04833979159593582\n",
      "Epoch 327, Loss: 0.11744533106684685, Final Batch Loss: 0.03785379230976105\n",
      "Epoch 328, Loss: 0.10312595590949059, Final Batch Loss: 0.04453378543257713\n",
      "Epoch 329, Loss: 0.0919377189129591, Final Batch Loss: 0.027909787371754646\n",
      "Epoch 330, Loss: 0.08759478852152824, Final Batch Loss: 0.012465154752135277\n",
      "Epoch 331, Loss: 0.07362397853285074, Final Batch Loss: 0.013095409609377384\n",
      "Epoch 332, Loss: 0.08329121954739094, Final Batch Loss: 0.029064126312732697\n",
      "Epoch 333, Loss: 0.07699903286993504, Final Batch Loss: 0.012246310710906982\n",
      "Epoch 334, Loss: 0.09229946509003639, Final Batch Loss: 0.03840009123086929\n",
      "Epoch 335, Loss: 0.07653180323541164, Final Batch Loss: 0.0207595843821764\n",
      "Epoch 336, Loss: 0.04931530077010393, Final Batch Loss: 0.008236869238317013\n",
      "Epoch 337, Loss: 0.059179989621043205, Final Batch Loss: 0.019655916839838028\n",
      "Epoch 338, Loss: 0.05860406532883644, Final Batch Loss: 0.014822191558778286\n",
      "Epoch 339, Loss: 0.08811776712536812, Final Batch Loss: 0.04644794762134552\n",
      "Epoch 340, Loss: 0.08660024590790272, Final Batch Loss: 0.03597646951675415\n",
      "Epoch 341, Loss: 0.09040623344480991, Final Batch Loss: 0.02533349208533764\n",
      "Epoch 342, Loss: 0.07572285272181034, Final Batch Loss: 0.008829239755868912\n",
      "Epoch 343, Loss: 0.06714783981442451, Final Batch Loss: 0.008909263648092747\n",
      "Epoch 344, Loss: 0.06785256788134575, Final Batch Loss: 0.016414105892181396\n",
      "Epoch 345, Loss: 0.06686044856905937, Final Batch Loss: 0.011516129598021507\n",
      "Epoch 346, Loss: 0.06559439934790134, Final Batch Loss: 0.025398187339305878\n",
      "Epoch 347, Loss: 0.07116361428052187, Final Batch Loss: 0.0365426279604435\n",
      "Epoch 348, Loss: 0.07084256550297141, Final Batch Loss: 0.007738265674561262\n",
      "Epoch 349, Loss: 0.08127492293715477, Final Batch Loss: 0.020411966368556023\n",
      "Epoch 350, Loss: 0.06498187128454447, Final Batch Loss: 0.035338144749403\n",
      "Epoch 351, Loss: 0.05729817599058151, Final Batch Loss: 0.02089816704392433\n",
      "Epoch 352, Loss: 0.08398219384253025, Final Batch Loss: 0.03589034453034401\n",
      "Epoch 353, Loss: 0.07132698781788349, Final Batch Loss: 0.028122229501605034\n",
      "Epoch 354, Loss: 0.0713899303227663, Final Batch Loss: 0.00974183902144432\n",
      "Epoch 355, Loss: 0.05777462385594845, Final Batch Loss: 0.013018926605582237\n",
      "Epoch 356, Loss: 0.07483033556491137, Final Batch Loss: 0.04707134887576103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357, Loss: 0.06246847286820412, Final Batch Loss: 0.029894530773162842\n",
      "Epoch 358, Loss: 0.10733397863805294, Final Batch Loss: 0.04758930578827858\n",
      "Epoch 359, Loss: 0.10496817342936993, Final Batch Loss: 0.02172013185918331\n",
      "Epoch 360, Loss: 0.07544938288629055, Final Batch Loss: 0.030894987285137177\n",
      "Epoch 361, Loss: 0.04752069711685181, Final Batch Loss: 0.014808394014835358\n",
      "Epoch 362, Loss: 0.059573578648269176, Final Batch Loss: 0.008364670909941196\n",
      "Epoch 363, Loss: 0.08780544623732567, Final Batch Loss: 0.04610219970345497\n",
      "Epoch 364, Loss: 0.07970481179654598, Final Batch Loss: 0.020525842905044556\n",
      "Epoch 365, Loss: 0.05276361992582679, Final Batch Loss: 0.005575676914304495\n",
      "Epoch 366, Loss: 0.07088604010641575, Final Batch Loss: 0.023305796086788177\n",
      "Epoch 367, Loss: 0.04808627860620618, Final Batch Loss: 0.006745961029082537\n",
      "Epoch 368, Loss: 0.0912005640566349, Final Batch Loss: 0.04101990535855293\n",
      "Epoch 369, Loss: 0.06199787091463804, Final Batch Loss: 0.025225330144166946\n",
      "Epoch 370, Loss: 0.05377156473696232, Final Batch Loss: 0.010199332609772682\n",
      "Epoch 371, Loss: 0.07203585375100374, Final Batch Loss: 0.04155643656849861\n",
      "Epoch 372, Loss: 0.041623145807534456, Final Batch Loss: 0.02714085392653942\n",
      "Epoch 373, Loss: 0.04618187714368105, Final Batch Loss: 0.009605051018297672\n",
      "Epoch 374, Loss: 0.09402191080152988, Final Batch Loss: 0.0345059372484684\n",
      "Epoch 375, Loss: 0.05121383909136057, Final Batch Loss: 0.01244413387030363\n",
      "Epoch 376, Loss: 0.07854648679494858, Final Batch Loss: 0.01785164140164852\n",
      "Epoch 377, Loss: 0.051169952377676964, Final Batch Loss: 0.005724283866584301\n",
      "Epoch 378, Loss: 0.05953194014728069, Final Batch Loss: 0.015226082876324654\n",
      "Epoch 379, Loss: 0.05469307862222195, Final Batch Loss: 0.016124719753861427\n",
      "Epoch 380, Loss: 0.04910261556506157, Final Batch Loss: 0.008872083388268948\n",
      "Epoch 381, Loss: 0.07505538687109947, Final Batch Loss: 0.025659186765551567\n",
      "Epoch 382, Loss: 0.05452797980979085, Final Batch Loss: 0.02879655547440052\n",
      "Epoch 383, Loss: 0.056908137165009975, Final Batch Loss: 0.009445847012102604\n",
      "Epoch 384, Loss: 0.04985752236098051, Final Batch Loss: 0.024066217243671417\n",
      "Epoch 385, Loss: 0.059989751316607, Final Batch Loss: 0.0247743409126997\n",
      "Epoch 386, Loss: 0.04544853791594505, Final Batch Loss: 0.022316841408610344\n",
      "Epoch 387, Loss: 0.06773439049720764, Final Batch Loss: 0.0229348074644804\n",
      "Epoch 388, Loss: 0.07187156938016415, Final Batch Loss: 0.011798897758126259\n",
      "Epoch 389, Loss: 0.05217583570629358, Final Batch Loss: 0.014944497495889664\n",
      "Epoch 390, Loss: 0.06039645383134484, Final Batch Loss: 0.005287420470267534\n",
      "Epoch 391, Loss: 0.026325433049350977, Final Batch Loss: 0.0054971324279904366\n",
      "Epoch 392, Loss: 0.03548071626573801, Final Batch Loss: 0.018821559846401215\n",
      "Epoch 393, Loss: 0.06914757937192917, Final Batch Loss: 0.012071575969457626\n",
      "Epoch 394, Loss: 0.05105633847415447, Final Batch Loss: 0.020254287868738174\n",
      "Epoch 395, Loss: 0.0565906073898077, Final Batch Loss: 0.037242405116558075\n",
      "Epoch 396, Loss: 0.03409543912857771, Final Batch Loss: 0.012474006973206997\n",
      "Epoch 397, Loss: 0.05103390850126743, Final Batch Loss: 0.015025671571493149\n",
      "Epoch 398, Loss: 0.042832471895962954, Final Batch Loss: 0.005339881870895624\n",
      "Epoch 399, Loss: 0.04014300648123026, Final Batch Loss: 0.008802018128335476\n",
      "Epoch 400, Loss: 0.05003354884684086, Final Batch Loss: 0.03161327540874481\n",
      "Epoch 401, Loss: 0.0538890091702342, Final Batch Loss: 0.008191264234483242\n",
      "Epoch 402, Loss: 0.06084055686369538, Final Batch Loss: 0.0019699125550687313\n",
      "Epoch 403, Loss: 0.04828211897984147, Final Batch Loss: 0.027556287124753\n",
      "Epoch 404, Loss: 0.049772906582802534, Final Batch Loss: 0.007041919510811567\n",
      "Epoch 405, Loss: 0.03027322795242071, Final Batch Loss: 0.006821826100349426\n",
      "Epoch 406, Loss: 0.07494988944381475, Final Batch Loss: 0.008557763881981373\n",
      "Epoch 407, Loss: 0.05486484430730343, Final Batch Loss: 0.017513372004032135\n",
      "Epoch 408, Loss: 0.04322429373860359, Final Batch Loss: 0.006753240711987019\n",
      "Epoch 409, Loss: 0.03928739042021334, Final Batch Loss: 0.022346941754221916\n",
      "Epoch 410, Loss: 0.036461846670135856, Final Batch Loss: 0.024761339649558067\n",
      "Epoch 411, Loss: 0.055393841583281755, Final Batch Loss: 0.003132591489702463\n",
      "Epoch 412, Loss: 0.0381472110748291, Final Batch Loss: 0.00969561655074358\n",
      "Epoch 413, Loss: 0.06313663348555565, Final Batch Loss: 0.017866164445877075\n",
      "Epoch 414, Loss: 0.0435575507581234, Final Batch Loss: 0.016494715586304665\n",
      "Epoch 415, Loss: 0.07644306868314743, Final Batch Loss: 0.05034814774990082\n",
      "Epoch 416, Loss: 0.05154700018465519, Final Batch Loss: 0.008930929005146027\n",
      "Epoch 417, Loss: 0.07867597974836826, Final Batch Loss: 0.01651209592819214\n",
      "Epoch 418, Loss: 0.02679808810353279, Final Batch Loss: 0.005111889448016882\n",
      "Epoch 419, Loss: 0.0228065000846982, Final Batch Loss: 0.005937062669545412\n",
      "Epoch 420, Loss: 0.03940285788848996, Final Batch Loss: 0.0049021877348423\n",
      "Epoch 421, Loss: 0.049967809580266476, Final Batch Loss: 0.0115419402718544\n",
      "Epoch 422, Loss: 0.06433374155312777, Final Batch Loss: 0.012133079580962658\n",
      "Epoch 423, Loss: 0.04590035695582628, Final Batch Loss: 0.030993321910500526\n",
      "Epoch 424, Loss: 0.05241106357425451, Final Batch Loss: 0.00967012532055378\n",
      "Epoch 425, Loss: 0.017172198044136167, Final Batch Loss: 0.0034964813385158777\n",
      "Epoch 426, Loss: 0.030534204095602036, Final Batch Loss: 0.0090463412925601\n",
      "Epoch 427, Loss: 0.042710548266768456, Final Batch Loss: 0.018817458301782608\n",
      "Epoch 428, Loss: 0.06933470815420151, Final Batch Loss: 0.019703000783920288\n",
      "Epoch 429, Loss: 0.04197158617898822, Final Batch Loss: 0.003435899969190359\n",
      "Epoch 430, Loss: 0.03167259320616722, Final Batch Loss: 0.010707130655646324\n",
      "Epoch 431, Loss: 0.05588438035920262, Final Batch Loss: 0.026236625388264656\n",
      "Epoch 432, Loss: 0.03956944029778242, Final Batch Loss: 0.015330667607486248\n",
      "Epoch 433, Loss: 0.04577270895242691, Final Batch Loss: 0.0213425662368536\n",
      "Epoch 434, Loss: 0.05191595572978258, Final Batch Loss: 0.010288706049323082\n",
      "Epoch 435, Loss: 0.05774165689945221, Final Batch Loss: 0.03262903168797493\n",
      "Epoch 436, Loss: 0.07085540611296892, Final Batch Loss: 0.006794351153075695\n",
      "Epoch 437, Loss: 0.055972445756196976, Final Batch Loss: 0.03388809785246849\n",
      "Epoch 438, Loss: 0.025865123607218266, Final Batch Loss: 0.007341769523918629\n",
      "Epoch 439, Loss: 0.028550179675221443, Final Batch Loss: 0.013554646633565426\n",
      "Epoch 440, Loss: 0.03736528055742383, Final Batch Loss: 0.003117610700428486\n",
      "Epoch 441, Loss: 0.040347268572077155, Final Batch Loss: 0.01062589231878519\n",
      "Epoch 442, Loss: 0.03767800284549594, Final Batch Loss: 0.015588962472975254\n",
      "Epoch 443, Loss: 0.0401170807890594, Final Batch Loss: 0.027080396190285683\n",
      "Epoch 444, Loss: 0.027508219238370657, Final Batch Loss: 0.008257006295025349\n",
      "Epoch 445, Loss: 0.035091109573841095, Final Batch Loss: 0.012158744968473911\n",
      "Epoch 446, Loss: 0.08976083947345614, Final Batch Loss: 0.07216797769069672\n",
      "Epoch 447, Loss: 0.0490451748482883, Final Batch Loss: 0.035344064235687256\n",
      "Epoch 448, Loss: 0.053733466658741236, Final Batch Loss: 0.005182082299143076\n",
      "Epoch 449, Loss: 0.018984749913215637, Final Batch Loss: 0.004501555114984512\n",
      "Epoch 450, Loss: 0.04309072089381516, Final Batch Loss: 0.00488082692027092\n",
      "Epoch 451, Loss: 0.04500441160053015, Final Batch Loss: 0.006318884436041117\n",
      "Epoch 452, Loss: 0.02339896559715271, Final Batch Loss: 0.0023285080678761005\n",
      "Epoch 453, Loss: 0.030561339110136032, Final Batch Loss: 0.010604364797472954\n",
      "Epoch 454, Loss: 0.026531039271503687, Final Batch Loss: 0.0068722376599907875\n",
      "Epoch 455, Loss: 0.030956116039305925, Final Batch Loss: 0.018750378862023354\n",
      "Epoch 456, Loss: 0.03441713750362396, Final Batch Loss: 0.010999493300914764\n",
      "Epoch 457, Loss: 0.0645841071382165, Final Batch Loss: 0.01505211926996708\n",
      "Epoch 458, Loss: 0.034051415510475636, Final Batch Loss: 0.009753399528563023\n",
      "Epoch 459, Loss: 0.04530749097466469, Final Batch Loss: 0.005014634225517511\n",
      "Epoch 460, Loss: 0.0698601109907031, Final Batch Loss: 0.01295898575335741\n",
      "Epoch 461, Loss: 0.06382113322615623, Final Batch Loss: 0.030156981199979782\n",
      "Epoch 462, Loss: 0.06373534863814712, Final Batch Loss: 0.017026256769895554\n",
      "Epoch 463, Loss: 0.03874277323484421, Final Batch Loss: 0.01708463579416275\n",
      "Epoch 464, Loss: 0.03611187171190977, Final Batch Loss: 0.017679300159215927\n",
      "Epoch 465, Loss: 0.016479538287967443, Final Batch Loss: 0.00803214032202959\n",
      "Epoch 466, Loss: 0.09466604329645634, Final Batch Loss: 0.07230961322784424\n",
      "Epoch 467, Loss: 0.02164524281397462, Final Batch Loss: 0.01009418349713087\n",
      "Epoch 468, Loss: 0.024117323337122798, Final Batch Loss: 0.0020685431081801653\n",
      "Epoch 469, Loss: 0.05104515189304948, Final Batch Loss: 0.0038978182710707188\n",
      "Epoch 470, Loss: 0.031144459266215563, Final Batch Loss: 0.013098321855068207\n",
      "Epoch 471, Loss: 0.06553410738706589, Final Batch Loss: 0.02660479210317135\n",
      "Epoch 472, Loss: 0.0440518562681973, Final Batch Loss: 0.015153049491345882\n",
      "Epoch 473, Loss: 0.03941482352092862, Final Batch Loss: 0.020204847678542137\n",
      "Epoch 474, Loss: 0.02081681229174137, Final Batch Loss: 0.007085106801241636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, Loss: 0.017920534126460552, Final Batch Loss: 0.004894621204584837\n",
      "Epoch 476, Loss: 0.05655945232138038, Final Batch Loss: 0.040944408625364304\n",
      "Epoch 477, Loss: 0.03479501698166132, Final Batch Loss: 0.019138945266604424\n",
      "Epoch 478, Loss: 0.060238220263272524, Final Batch Loss: 0.016673361882567406\n",
      "Epoch 479, Loss: 0.017656707670539618, Final Batch Loss: 0.005308769177645445\n",
      "Epoch 480, Loss: 0.023847939912229776, Final Batch Loss: 0.0067277029156684875\n",
      "Epoch 481, Loss: 0.043150078039616346, Final Batch Loss: 0.008668327704071999\n",
      "Epoch 482, Loss: 0.019635091302916408, Final Batch Loss: 0.0037860574666410685\n",
      "Epoch 483, Loss: 0.03883454203605652, Final Batch Loss: 0.019814349710941315\n",
      "Epoch 484, Loss: 0.06289478065446019, Final Batch Loss: 0.03691159561276436\n",
      "Epoch 485, Loss: 0.06033238861709833, Final Batch Loss: 0.031446851789951324\n",
      "Epoch 486, Loss: 0.04254938894882798, Final Batch Loss: 0.011533272452652454\n",
      "Epoch 487, Loss: 0.03957619518041611, Final Batch Loss: 0.014175666496157646\n",
      "Epoch 488, Loss: 0.04519790876656771, Final Batch Loss: 0.003910134546458721\n",
      "Epoch 489, Loss: 0.03225693665444851, Final Batch Loss: 0.018562333658337593\n",
      "Epoch 490, Loss: 0.026702753733843565, Final Batch Loss: 0.006438912823796272\n",
      "Epoch 491, Loss: 0.03140673553571105, Final Batch Loss: 0.0031788931228220463\n",
      "Epoch 492, Loss: 0.018212735187262297, Final Batch Loss: 0.00436070840805769\n",
      "Epoch 493, Loss: 0.015505010960623622, Final Batch Loss: 0.007907327264547348\n",
      "Epoch 494, Loss: 0.04941320698708296, Final Batch Loss: 0.03658367320895195\n",
      "Epoch 495, Loss: 0.02316618338227272, Final Batch Loss: 0.005629195831716061\n",
      "Epoch 496, Loss: 0.030581898521631956, Final Batch Loss: 0.010185922496020794\n",
      "Epoch 497, Loss: 0.021320923697203398, Final Batch Loss: 0.005732308607548475\n",
      "Epoch 498, Loss: 0.0260940867010504, Final Batch Loss: 0.001496307784691453\n",
      "Epoch 499, Loss: 0.033257632283493876, Final Batch Loss: 0.013842721469700336\n",
      "Epoch 500, Loss: 0.017332169110886753, Final Batch Loss: 0.0014009576989337802\n",
      "Epoch 501, Loss: 0.021018662489950657, Final Batch Loss: 0.006717302370816469\n",
      "Epoch 502, Loss: 0.022614229237660766, Final Batch Loss: 0.006639435421675444\n",
      "Epoch 503, Loss: 0.04193481965921819, Final Batch Loss: 0.0019740841817110777\n",
      "Epoch 504, Loss: 0.023108102846890688, Final Batch Loss: 0.006871391553431749\n",
      "Epoch 505, Loss: 0.06004940439015627, Final Batch Loss: 0.0323282852768898\n",
      "Epoch 506, Loss: 0.021114115603268147, Final Batch Loss: 0.006470275577157736\n",
      "Epoch 507, Loss: 0.039012708235532045, Final Batch Loss: 0.012147023342549801\n",
      "Epoch 508, Loss: 0.02418978838250041, Final Batch Loss: 0.017287254333496094\n",
      "Epoch 509, Loss: 0.042169414926320314, Final Batch Loss: 0.0075248838402330875\n",
      "Epoch 510, Loss: 0.01314291451126337, Final Batch Loss: 0.004356962163001299\n",
      "Epoch 511, Loss: 0.008389178663492203, Final Batch Loss: 0.0024273651652038097\n",
      "Epoch 512, Loss: 0.019966804422438145, Final Batch Loss: 0.003857140429317951\n",
      "Epoch 513, Loss: 0.026068773586302996, Final Batch Loss: 0.004798260051757097\n",
      "Epoch 514, Loss: 0.01581029687076807, Final Batch Loss: 0.003748413873836398\n",
      "Epoch 515, Loss: 0.022647362435236573, Final Batch Loss: 0.0052994959987699986\n",
      "Epoch 516, Loss: 0.013741405447944999, Final Batch Loss: 0.0056964196264743805\n",
      "Epoch 517, Loss: 0.052204239182174206, Final Batch Loss: 0.03189089894294739\n",
      "Epoch 518, Loss: 0.023126088548451662, Final Batch Loss: 0.012241524644196033\n",
      "Epoch 519, Loss: 0.023607741226442158, Final Batch Loss: 0.0014824726385995746\n",
      "Epoch 520, Loss: 0.020351161248981953, Final Batch Loss: 0.0072075361385941505\n",
      "Epoch 521, Loss: 0.024077282985672355, Final Batch Loss: 0.0031521504279226065\n",
      "Epoch 522, Loss: 0.028074215166270733, Final Batch Loss: 0.019960053265094757\n",
      "Epoch 523, Loss: 0.047526114620268345, Final Batch Loss: 0.008972286246716976\n",
      "Epoch 524, Loss: 0.012436301447451115, Final Batch Loss: 0.005733807571232319\n",
      "Epoch 525, Loss: 0.024316387251019478, Final Batch Loss: 0.008856859989464283\n",
      "Epoch 526, Loss: 0.010253283428028226, Final Batch Loss: 0.0037674380000680685\n",
      "Epoch 527, Loss: 0.018665263429284096, Final Batch Loss: 0.007238751742988825\n",
      "Epoch 528, Loss: 0.010783926350995898, Final Batch Loss: 0.0015024831518530846\n",
      "Epoch 529, Loss: 0.032593119773082435, Final Batch Loss: 0.008373565971851349\n",
      "Epoch 530, Loss: 0.02894658618606627, Final Batch Loss: 0.018943285569548607\n",
      "Epoch 531, Loss: 0.02584202610887587, Final Batch Loss: 0.006070508621633053\n",
      "Epoch 532, Loss: 0.047361836303025484, Final Batch Loss: 0.04091417044401169\n",
      "Epoch 533, Loss: 0.022580737248063087, Final Batch Loss: 0.01573079451918602\n",
      "Epoch 534, Loss: 0.05673103593289852, Final Batch Loss: 0.007950833067297935\n",
      "Epoch 535, Loss: 0.025347651913762093, Final Batch Loss: 0.008544917218387127\n",
      "Epoch 536, Loss: 0.018550564534962177, Final Batch Loss: 0.004902084358036518\n",
      "Epoch 537, Loss: 0.05111285485327244, Final Batch Loss: 0.03180220350623131\n",
      "Epoch 538, Loss: 0.017055097152478993, Final Batch Loss: 0.0011560494313016534\n",
      "Epoch 539, Loss: 0.021523028844967484, Final Batch Loss: 0.003805100219324231\n",
      "Epoch 540, Loss: 0.034878104692324996, Final Batch Loss: 0.001242821803316474\n",
      "Epoch 541, Loss: 0.027533761458471417, Final Batch Loss: 0.006031119264662266\n",
      "Epoch 542, Loss: 0.026637296890839934, Final Batch Loss: 0.002124967286363244\n",
      "Epoch 543, Loss: 0.04462952585890889, Final Batch Loss: 0.0031699244864284992\n",
      "Epoch 544, Loss: 0.016900330549106002, Final Batch Loss: 0.0014751350972801447\n",
      "Epoch 545, Loss: 0.024581915233284235, Final Batch Loss: 0.004449151922017336\n",
      "Epoch 546, Loss: 0.05350431823171675, Final Batch Loss: 0.0028151413425803185\n",
      "Epoch 547, Loss: 0.021320929052308202, Final Batch Loss: 0.016166148707270622\n",
      "Epoch 548, Loss: 0.016882543917745352, Final Batch Loss: 0.0016332454979419708\n",
      "Epoch 549, Loss: 0.057169318199157715, Final Batch Loss: 0.008588680066168308\n",
      "Epoch 550, Loss: 0.039561748038977385, Final Batch Loss: 0.00666444655507803\n",
      "Epoch 551, Loss: 0.021735190181061625, Final Batch Loss: 0.008563430048525333\n",
      "Epoch 552, Loss: 0.022139130043797195, Final Batch Loss: 0.001344833872281015\n",
      "Epoch 553, Loss: 0.013862415915355086, Final Batch Loss: 0.0022421185858547688\n",
      "Epoch 554, Loss: 0.01823669415898621, Final Batch Loss: 0.0021961380261927843\n",
      "Epoch 555, Loss: 0.008281917544081807, Final Batch Loss: 0.0020368658006191254\n",
      "Epoch 556, Loss: 0.008647512295283377, Final Batch Loss: 0.0015371933113783598\n",
      "Epoch 557, Loss: 0.030585062690079212, Final Batch Loss: 0.017958110198378563\n",
      "Epoch 558, Loss: 0.024051647749729455, Final Batch Loss: 0.017025576904416084\n",
      "Epoch 559, Loss: 0.036362381651997566, Final Batch Loss: 0.0043722279369831085\n",
      "Epoch 560, Loss: 0.020663426257669926, Final Batch Loss: 0.005665174685418606\n",
      "Epoch 561, Loss: 0.023168935906141996, Final Batch Loss: 0.0072008464485406876\n",
      "Epoch 562, Loss: 0.019819625420495868, Final Batch Loss: 0.0021105334162712097\n",
      "Epoch 563, Loss: 0.06953267531935126, Final Batch Loss: 0.04155829921364784\n",
      "Epoch 564, Loss: 0.01704946905374527, Final Batch Loss: 0.0023071374744176865\n",
      "Epoch 565, Loss: 0.030664831632748246, Final Batch Loss: 0.0014920781832188368\n",
      "Epoch 566, Loss: 0.03440074110403657, Final Batch Loss: 0.0054021249525249004\n",
      "Epoch 567, Loss: 0.08038857765495777, Final Batch Loss: 0.05835036560893059\n",
      "Epoch 568, Loss: 0.013072464149445295, Final Batch Loss: 0.005650329869240522\n",
      "Epoch 569, Loss: 0.023065312299877405, Final Batch Loss: 0.006611338350921869\n",
      "Epoch 570, Loss: 0.010889144497923553, Final Batch Loss: 0.0060225375927984715\n",
      "Epoch 571, Loss: 0.03625944280065596, Final Batch Loss: 0.0015746850986033678\n",
      "Epoch 572, Loss: 0.0300212730653584, Final Batch Loss: 0.0070914397947490215\n",
      "Epoch 573, Loss: 0.007974144304171205, Final Batch Loss: 0.0013403577031567693\n",
      "Epoch 574, Loss: 0.011027009692043066, Final Batch Loss: 0.006617010571062565\n",
      "Epoch 575, Loss: 0.02595813968218863, Final Batch Loss: 0.0030198446474969387\n",
      "Epoch 576, Loss: 0.035723740234971046, Final Batch Loss: 0.0032085950952023268\n",
      "Epoch 577, Loss: 0.020900143310427666, Final Batch Loss: 0.007439990062266588\n",
      "Epoch 578, Loss: 0.011049670167267323, Final Batch Loss: 0.001672922633588314\n",
      "Epoch 579, Loss: 0.014310456113889813, Final Batch Loss: 0.004602278117090464\n",
      "Epoch 580, Loss: 0.05312351533211768, Final Batch Loss: 0.0017533183563500643\n",
      "Epoch 581, Loss: 0.01503857341594994, Final Batch Loss: 0.0029810236301273108\n",
      "Epoch 582, Loss: 0.028775819577276707, Final Batch Loss: 0.003122813068330288\n",
      "Epoch 583, Loss: 0.011096069123595953, Final Batch Loss: 0.0023310480173677206\n",
      "Epoch 584, Loss: 0.01611547451466322, Final Batch Loss: 0.004878568463027477\n",
      "Epoch 585, Loss: 0.02120348857715726, Final Batch Loss: 0.010661504231393337\n",
      "Epoch 586, Loss: 0.011064336635172367, Final Batch Loss: 0.004183550365269184\n",
      "Epoch 587, Loss: 0.014755265437997878, Final Batch Loss: 0.008759111166000366\n",
      "Epoch 588, Loss: 0.021646613720804453, Final Batch Loss: 0.00977422297000885\n",
      "Epoch 589, Loss: 0.06620106170885265, Final Batch Loss: 0.046418942511081696\n",
      "Epoch 590, Loss: 0.006606434006243944, Final Batch Loss: 0.0017386190593242645\n",
      "Epoch 591, Loss: 0.03872979327570647, Final Batch Loss: 0.0010995407355949283\n",
      "Epoch 592, Loss: 0.02140583749860525, Final Batch Loss: 0.004325455985963345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593, Loss: 0.020236805081367493, Final Batch Loss: 0.008925200439989567\n",
      "Epoch 594, Loss: 0.017249959520995617, Final Batch Loss: 0.004455955699086189\n",
      "Epoch 595, Loss: 0.04020056826993823, Final Batch Loss: 0.015405277721583843\n",
      "Epoch 596, Loss: 0.02263396978378296, Final Batch Loss: 0.009310651570558548\n",
      "Epoch 597, Loss: 0.013548358110710979, Final Batch Loss: 0.0030751319136470556\n",
      "Epoch 598, Loss: 0.014949377859011292, Final Batch Loss: 0.0030190355610102415\n",
      "Epoch 599, Loss: 0.008798227761872113, Final Batch Loss: 0.003038529772311449\n",
      "Epoch 600, Loss: 0.012119033373892307, Final Batch Loss: 0.0068086255341768265\n",
      "Epoch 601, Loss: 0.014114332385361195, Final Batch Loss: 0.00328272208571434\n",
      "Epoch 602, Loss: 0.03231754153966904, Final Batch Loss: 0.005030967760831118\n",
      "Epoch 603, Loss: 0.014521254226565361, Final Batch Loss: 0.004907040856778622\n",
      "Epoch 604, Loss: 0.04734093649312854, Final Batch Loss: 0.0007134838961064816\n",
      "Epoch 605, Loss: 0.02167692082002759, Final Batch Loss: 0.008935846388339996\n",
      "Epoch 606, Loss: 0.021011994103901088, Final Batch Loss: 0.016033779829740524\n",
      "Epoch 607, Loss: 0.013308492489159107, Final Batch Loss: 0.007747416850179434\n",
      "Epoch 608, Loss: 0.015176554443314672, Final Batch Loss: 0.0020434928592294455\n",
      "Epoch 609, Loss: 0.028423914220184088, Final Batch Loss: 0.007950027473270893\n",
      "Epoch 610, Loss: 0.022067884681746364, Final Batch Loss: 0.013277723453938961\n",
      "Epoch 611, Loss: 0.00987848057411611, Final Batch Loss: 0.003560882294550538\n",
      "Epoch 612, Loss: 0.011429298669099808, Final Batch Loss: 0.00503395264968276\n",
      "Epoch 613, Loss: 0.02338950871489942, Final Batch Loss: 0.002636489225551486\n",
      "Epoch 614, Loss: 0.033031347673386335, Final Batch Loss: 0.0020488756708800793\n",
      "Epoch 615, Loss: 0.01236766204237938, Final Batch Loss: 0.003031250787898898\n",
      "Epoch 616, Loss: 0.009097838657908142, Final Batch Loss: 0.0067890360951423645\n",
      "Epoch 617, Loss: 0.08051212504506111, Final Batch Loss: 0.052512284368276596\n",
      "Epoch 618, Loss: 0.01944310258841142, Final Batch Loss: 0.0015888120979070663\n",
      "Epoch 619, Loss: 0.011235054582357407, Final Batch Loss: 0.0054040709510445595\n",
      "Epoch 620, Loss: 0.02323758217971772, Final Batch Loss: 0.007532249204814434\n",
      "Epoch 621, Loss: 0.012072484707459807, Final Batch Loss: 0.0031188682187348604\n",
      "Epoch 622, Loss: 0.01869595469906926, Final Batch Loss: 0.000985402031801641\n",
      "Epoch 623, Loss: 0.01433584769256413, Final Batch Loss: 0.0026553950738161802\n",
      "Epoch 624, Loss: 0.006680803839117289, Final Batch Loss: 0.0019651264883577824\n",
      "Epoch 625, Loss: 0.015581084415316582, Final Batch Loss: 0.003559399163350463\n",
      "Epoch 626, Loss: 0.02712024189531803, Final Batch Loss: 0.005612730048596859\n",
      "Epoch 627, Loss: 0.03299638209864497, Final Batch Loss: 0.02218368835747242\n",
      "Epoch 628, Loss: 0.01850247464608401, Final Batch Loss: 0.010773489251732826\n",
      "Epoch 629, Loss: 0.012525014113634825, Final Batch Loss: 0.003393561812117696\n",
      "Epoch 630, Loss: 0.055351374205201864, Final Batch Loss: 0.006719901692122221\n",
      "Epoch 631, Loss: 0.027436079923063517, Final Batch Loss: 0.002695096656680107\n",
      "Epoch 632, Loss: 0.014297223184257746, Final Batch Loss: 0.006464990321546793\n",
      "Epoch 633, Loss: 0.02732074074447155, Final Batch Loss: 0.006441929377615452\n",
      "Epoch 634, Loss: 0.008160103694535792, Final Batch Loss: 0.0010006658267229795\n",
      "Epoch 635, Loss: 0.07153154420666397, Final Batch Loss: 0.04678068682551384\n",
      "Epoch 636, Loss: 0.03725204383954406, Final Batch Loss: 0.003947029355913401\n",
      "Epoch 637, Loss: 0.020663278875872493, Final Batch Loss: 0.0036689883563667536\n",
      "Epoch 638, Loss: 0.011774152982980013, Final Batch Loss: 0.005105406045913696\n",
      "Epoch 639, Loss: 0.04659788031131029, Final Batch Loss: 0.023823808878660202\n",
      "Epoch 640, Loss: 0.030215442995540798, Final Batch Loss: 0.023222139105200768\n",
      "Epoch 641, Loss: 0.013448738609440625, Final Batch Loss: 0.010410018265247345\n",
      "Epoch 642, Loss: 0.018007184960879385, Final Batch Loss: 0.003277913201600313\n",
      "Epoch 643, Loss: 0.03989892569370568, Final Batch Loss: 0.033771298825740814\n",
      "Epoch 644, Loss: 0.014109679032117128, Final Batch Loss: 0.007851734757423401\n",
      "Epoch 645, Loss: 0.018501704558730125, Final Batch Loss: 0.00699102645739913\n",
      "Epoch 646, Loss: 0.02504653576761484, Final Batch Loss: 0.021071698516607285\n",
      "Epoch 647, Loss: 0.010716309188865125, Final Batch Loss: 0.0011214768746867776\n",
      "Epoch 648, Loss: 0.004936856799758971, Final Batch Loss: 0.0013549317372962832\n",
      "Epoch 649, Loss: 0.019413363304920495, Final Batch Loss: 0.0012939161388203502\n",
      "Epoch 650, Loss: 0.022873513167724013, Final Batch Loss: 0.0004529526922851801\n",
      "Epoch 651, Loss: 0.02138433838263154, Final Batch Loss: 0.0025103199295699596\n",
      "Epoch 652, Loss: 0.014749020803719759, Final Batch Loss: 0.004517158959060907\n",
      "Epoch 653, Loss: 0.017351131653413177, Final Batch Loss: 0.0129432063549757\n",
      "Epoch 654, Loss: 0.014099101070314646, Final Batch Loss: 0.00532672181725502\n",
      "Epoch 655, Loss: 0.012484095292165875, Final Batch Loss: 0.0030144397169351578\n",
      "Epoch 656, Loss: 0.010608116164803505, Final Batch Loss: 0.00245481263846159\n",
      "Epoch 657, Loss: 0.022821554797701538, Final Batch Loss: 0.0007602801779285073\n",
      "Epoch 658, Loss: 0.035888044629245996, Final Batch Loss: 0.002099525649100542\n",
      "Epoch 659, Loss: 0.024074300657957792, Final Batch Loss: 0.005233726464211941\n",
      "Epoch 660, Loss: 0.03177539655007422, Final Batch Loss: 0.0075430539436638355\n",
      "Epoch 661, Loss: 0.02654836676083505, Final Batch Loss: 0.0046581244096159935\n",
      "Epoch 662, Loss: 0.006381924380548298, Final Batch Loss: 0.002752098487690091\n",
      "Epoch 663, Loss: 0.010241430660244077, Final Batch Loss: 0.0007595836068503559\n",
      "Epoch 664, Loss: 0.007272997405380011, Final Batch Loss: 0.004005603492259979\n",
      "Epoch 665, Loss: 0.019363372353836894, Final Batch Loss: 0.0026423276867717505\n",
      "Epoch 666, Loss: 0.004450108157470822, Final Batch Loss: 0.001070977421477437\n",
      "Epoch 667, Loss: 0.029559939168393612, Final Batch Loss: 0.002897442551329732\n",
      "Epoch 668, Loss: 0.020881069591268897, Final Batch Loss: 0.0018731660675257444\n",
      "Epoch 669, Loss: 0.00634796591475606, Final Batch Loss: 0.0008008650038391352\n",
      "Epoch 670, Loss: 0.010735139017924666, Final Batch Loss: 0.0023430436849594116\n",
      "Epoch 671, Loss: 0.01567749259993434, Final Batch Loss: 0.0019068893743678927\n",
      "Epoch 672, Loss: 0.01881453162059188, Final Batch Loss: 0.009936154820024967\n",
      "Epoch 673, Loss: 0.013883127365261316, Final Batch Loss: 0.009815146215260029\n",
      "Epoch 674, Loss: 0.009551069291774184, Final Batch Loss: 0.0007224572473205626\n",
      "Epoch 675, Loss: 0.035657136293593794, Final Batch Loss: 0.0008737450116313994\n",
      "Epoch 676, Loss: 0.0397210456430912, Final Batch Loss: 0.03645658865571022\n",
      "Epoch 677, Loss: 0.013902560458518565, Final Batch Loss: 0.0011570497881621122\n",
      "Epoch 678, Loss: 0.019012969569303095, Final Batch Loss: 0.009712783619761467\n",
      "Epoch 679, Loss: 0.012244565645232797, Final Batch Loss: 0.002356673590838909\n",
      "Epoch 680, Loss: 0.024511789670214057, Final Batch Loss: 0.012192366644740105\n",
      "Epoch 681, Loss: 0.03795956901740283, Final Batch Loss: 0.0012223952217027545\n",
      "Epoch 682, Loss: 0.005702380440197885, Final Batch Loss: 0.0009843019070103765\n",
      "Epoch 683, Loss: 0.014197350945323706, Final Batch Loss: 0.005329078529030085\n",
      "Epoch 684, Loss: 0.01848040404729545, Final Batch Loss: 0.00130232865922153\n",
      "Epoch 685, Loss: 0.010738767217844725, Final Batch Loss: 0.001131546450778842\n",
      "Epoch 686, Loss: 0.011522955959662795, Final Batch Loss: 0.004914629273116589\n",
      "Epoch 687, Loss: 0.01707372779492289, Final Batch Loss: 0.014568377286195755\n",
      "Epoch 688, Loss: 0.031208585249260068, Final Batch Loss: 0.024737300351262093\n",
      "Epoch 689, Loss: 0.004327204078435898, Final Batch Loss: 0.000582805834710598\n",
      "Epoch 690, Loss: 0.018792005255818367, Final Batch Loss: 0.01417318545281887\n",
      "Epoch 691, Loss: 0.023745493730530143, Final Batch Loss: 0.017917385324835777\n",
      "Epoch 692, Loss: 0.007105079130269587, Final Batch Loss: 0.0017120052361860871\n",
      "Epoch 693, Loss: 0.014558761147782207, Final Batch Loss: 0.002826669020578265\n",
      "Epoch 694, Loss: 0.03098801785381511, Final Batch Loss: 0.023378752171993256\n",
      "Epoch 695, Loss: 0.012949858792126179, Final Batch Loss: 0.005833931267261505\n",
      "Epoch 696, Loss: 0.021311949007213116, Final Batch Loss: 0.005614158697426319\n",
      "Epoch 697, Loss: 0.00722739368211478, Final Batch Loss: 0.001266524544917047\n",
      "Epoch 698, Loss: 0.027128151152282953, Final Batch Loss: 0.0012269788421690464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699, Loss: 0.030099830823019147, Final Batch Loss: 0.02409510128200054\n",
      "Epoch 700, Loss: 0.0041897931369021535, Final Batch Loss: 0.0010142795508727431\n",
      "Epoch 701, Loss: 0.023063123458996415, Final Batch Loss: 0.003652592422440648\n",
      "Epoch 702, Loss: 0.022844851249828935, Final Batch Loss: 0.01119818165898323\n",
      "Epoch 703, Loss: 0.006678254692815244, Final Batch Loss: 0.0015379373217001557\n",
      "Epoch 704, Loss: 0.014034405234269798, Final Batch Loss: 0.0016408500960096717\n",
      "Epoch 705, Loss: 0.00494216731749475, Final Batch Loss: 0.0016583588439971209\n",
      "Epoch 706, Loss: 0.015566869406029582, Final Batch Loss: 0.0011468518059700727\n",
      "Epoch 707, Loss: 0.006202515563927591, Final Batch Loss: 0.0029005634132772684\n",
      "Epoch 708, Loss: 0.047871899558231235, Final Batch Loss: 0.042272720485925674\n",
      "Epoch 709, Loss: 0.005233151896391064, Final Batch Loss: 0.0027069058269262314\n",
      "Epoch 710, Loss: 0.029879438458010554, Final Batch Loss: 0.0013052874710410833\n",
      "Epoch 711, Loss: 0.02862643334083259, Final Batch Loss: 0.005159107968211174\n",
      "Epoch 712, Loss: 0.007497652084566653, Final Batch Loss: 0.0011719422182068229\n",
      "Epoch 713, Loss: 0.01072497246786952, Final Batch Loss: 0.0024349282030016184\n",
      "Epoch 714, Loss: 0.01265078759752214, Final Batch Loss: 0.0011543773580342531\n",
      "Epoch 715, Loss: 0.027545466320589185, Final Batch Loss: 0.002850057790055871\n",
      "Epoch 716, Loss: 0.008974649594165385, Final Batch Loss: 0.0016674678772687912\n",
      "Epoch 717, Loss: 0.008631526725366712, Final Batch Loss: 0.0017223088070750237\n",
      "Epoch 718, Loss: 0.008423990453593433, Final Batch Loss: 0.0017291015246883035\n",
      "Epoch 719, Loss: 0.006633640616200864, Final Batch Loss: 0.002916156081482768\n",
      "Epoch 720, Loss: 0.034740855859126896, Final Batch Loss: 0.0007380316383205354\n",
      "Epoch 721, Loss: 0.009739150991663337, Final Batch Loss: 0.003338932292535901\n",
      "Epoch 722, Loss: 0.00465174182318151, Final Batch Loss: 0.001598867354914546\n",
      "Epoch 723, Loss: 0.01163605519104749, Final Batch Loss: 0.0012605435913428664\n",
      "Epoch 724, Loss: 0.038368071895092726, Final Batch Loss: 0.002633357420563698\n",
      "Epoch 725, Loss: 0.009693618048913777, Final Batch Loss: 0.0017411125591024756\n",
      "Epoch 726, Loss: 0.022148082847706974, Final Batch Loss: 0.001919030793942511\n",
      "Epoch 727, Loss: 0.010939908941509202, Final Batch Loss: 0.00027946525369770825\n",
      "Epoch 728, Loss: 0.005456335609778762, Final Batch Loss: 0.00160448148380965\n",
      "Epoch 729, Loss: 0.013566772686317563, Final Batch Loss: 0.004386890679597855\n",
      "Epoch 730, Loss: 0.003916301531717181, Final Batch Loss: 0.0007784009212628007\n",
      "Epoch 731, Loss: 0.004568404925521463, Final Batch Loss: 0.0011158348061144352\n",
      "Epoch 732, Loss: 0.03114974359050393, Final Batch Loss: 0.018281977623701096\n",
      "Epoch 733, Loss: 0.019970676628872752, Final Batch Loss: 0.0037622693926095963\n",
      "Epoch 734, Loss: 0.011752980761229992, Final Batch Loss: 0.0018667969852685928\n",
      "Epoch 735, Loss: 0.01922719250433147, Final Batch Loss: 0.007433154620230198\n",
      "Epoch 736, Loss: 0.003931278537493199, Final Batch Loss: 0.0008340372587554157\n",
      "Epoch 737, Loss: 0.023291943944059312, Final Batch Loss: 0.005808102432638407\n",
      "Epoch 738, Loss: 0.005023792095016688, Final Batch Loss: 0.001668183715082705\n",
      "Epoch 739, Loss: 0.007194877718575299, Final Batch Loss: 0.0040587871335446835\n",
      "Epoch 740, Loss: 0.00986745220143348, Final Batch Loss: 0.0016688077012076974\n",
      "Epoch 741, Loss: 0.0035358158638700843, Final Batch Loss: 0.0011811063159257174\n",
      "Epoch 742, Loss: 0.0038386827800422907, Final Batch Loss: 0.0014346372336149216\n",
      "Epoch 743, Loss: 0.007965619908645749, Final Batch Loss: 0.0034673020709306\n",
      "Epoch 744, Loss: 0.009750362543854862, Final Batch Loss: 0.00032202532747760415\n",
      "Epoch 745, Loss: 0.05207337415777147, Final Batch Loss: 0.00232659257017076\n",
      "Epoch 746, Loss: 0.007552579045295715, Final Batch Loss: 0.005008504260331392\n",
      "Epoch 747, Loss: 0.005377636756747961, Final Batch Loss: 0.002068006433546543\n",
      "Epoch 748, Loss: 0.004009495722129941, Final Batch Loss: 0.001016673631966114\n",
      "Epoch 749, Loss: 0.005045483412686735, Final Batch Loss: 0.0004564077244140208\n",
      "Epoch 750, Loss: 0.05141575203742832, Final Batch Loss: 0.04793263226747513\n",
      "Epoch 751, Loss: 0.009512339252978563, Final Batch Loss: 0.004463091492652893\n",
      "Epoch 752, Loss: 0.017819702508859336, Final Batch Loss: 0.013686087913811207\n",
      "Epoch 753, Loss: 0.021154537331312895, Final Batch Loss: 0.00878717377781868\n",
      "Epoch 754, Loss: 0.005283338250592351, Final Batch Loss: 0.0032356504816561937\n",
      "Epoch 755, Loss: 0.0371527747483924, Final Batch Loss: 0.02940143458545208\n",
      "Epoch 756, Loss: 0.010186484432779253, Final Batch Loss: 0.002291536657139659\n",
      "Epoch 757, Loss: 0.018235325696878135, Final Batch Loss: 0.0021949035581201315\n",
      "Epoch 758, Loss: 0.007968107121996582, Final Batch Loss: 0.0010458399774506688\n",
      "Epoch 759, Loss: 0.007168278563767672, Final Batch Loss: 0.0011085914447903633\n",
      "Epoch 760, Loss: 0.020963858580216765, Final Batch Loss: 0.009766995906829834\n",
      "Epoch 761, Loss: 0.008506494923494756, Final Batch Loss: 0.001619187998585403\n",
      "Epoch 762, Loss: 0.023068785667419434, Final Batch Loss: 0.0010447632521390915\n",
      "Epoch 763, Loss: 0.05036415718495846, Final Batch Loss: 0.0012781154364347458\n",
      "Epoch 764, Loss: 0.016679726424627006, Final Batch Loss: 0.00367593951523304\n",
      "Epoch 765, Loss: 0.010557679110206664, Final Batch Loss: 0.005959808360785246\n",
      "Epoch 766, Loss: 0.008777990471571684, Final Batch Loss: 0.0027198761235922575\n",
      "Epoch 767, Loss: 0.00735583808273077, Final Batch Loss: 0.0024064460303634405\n",
      "Epoch 768, Loss: 0.006312783225439489, Final Batch Loss: 0.0015741019742563367\n",
      "Epoch 769, Loss: 0.023905436974018812, Final Batch Loss: 0.018841983750462532\n",
      "Epoch 770, Loss: 0.014630697667598724, Final Batch Loss: 0.010616477578878403\n",
      "Epoch 771, Loss: 0.03772307827603072, Final Batch Loss: 0.02527531608939171\n",
      "Epoch 772, Loss: 0.007924245903268456, Final Batch Loss: 0.001087457058019936\n",
      "Epoch 773, Loss: 0.0118025541305542, Final Batch Loss: 0.0003191339783370495\n",
      "Epoch 774, Loss: 0.013115872628986835, Final Batch Loss: 0.0032182573340833187\n",
      "Epoch 775, Loss: 0.006278547341935337, Final Batch Loss: 0.0022157756611704826\n",
      "Epoch 776, Loss: 0.010426208842545748, Final Batch Loss: 0.0033496494870632887\n",
      "Epoch 777, Loss: 0.005818394536618143, Final Batch Loss: 0.00042087369365617633\n",
      "Epoch 778, Loss: 0.01001165620982647, Final Batch Loss: 0.0038066571578383446\n",
      "Epoch 779, Loss: 0.030723751056939363, Final Batch Loss: 0.0010138526558876038\n",
      "Epoch 780, Loss: 0.036974456743337214, Final Batch Loss: 0.000901558087207377\n",
      "Epoch 781, Loss: 0.02425283833872527, Final Batch Loss: 0.0010490812128409743\n",
      "Epoch 782, Loss: 0.00742919510230422, Final Batch Loss: 0.0013524291571229696\n",
      "Epoch 783, Loss: 0.03570651914924383, Final Batch Loss: 0.0043998537585139275\n",
      "Epoch 784, Loss: 0.012777335243299603, Final Batch Loss: 0.005697521381080151\n",
      "Epoch 785, Loss: 0.006290234159678221, Final Batch Loss: 0.001560752745717764\n",
      "Epoch 786, Loss: 0.004840563866309822, Final Batch Loss: 0.0006768916500732303\n",
      "Epoch 787, Loss: 0.011645593564026058, Final Batch Loss: 0.005043064709752798\n",
      "Epoch 788, Loss: 0.004674468655139208, Final Batch Loss: 0.0010384834604337811\n",
      "Epoch 789, Loss: 0.00591502251336351, Final Batch Loss: 0.0015504405600950122\n",
      "Epoch 790, Loss: 0.026410047197714448, Final Batch Loss: 0.0022604793775826693\n",
      "Epoch 791, Loss: 0.03603789862245321, Final Batch Loss: 0.006864222232252359\n",
      "Epoch 792, Loss: 0.026799878804013133, Final Batch Loss: 0.021438684314489365\n",
      "Epoch 793, Loss: 0.02795864047948271, Final Batch Loss: 0.0007705433527007699\n",
      "Epoch 794, Loss: 0.02221017051488161, Final Batch Loss: 0.001983080990612507\n",
      "Epoch 795, Loss: 0.019483509298879653, Final Batch Loss: 0.0008122004219330847\n",
      "Epoch 796, Loss: 0.00812339421827346, Final Batch Loss: 0.0015063293976709247\n",
      "Epoch 797, Loss: 0.021322193555533886, Final Batch Loss: 0.016095777973532677\n",
      "Epoch 798, Loss: 0.0027100812585558742, Final Batch Loss: 0.0008793547167442739\n",
      "Epoch 799, Loss: 0.025516366644296795, Final Batch Loss: 0.0005208608345128596\n",
      "Epoch 800, Loss: 0.009917984367348254, Final Batch Loss: 0.0013806357746943831\n",
      "Epoch 801, Loss: 0.008204780984669924, Final Batch Loss: 0.002585558919236064\n",
      "Epoch 802, Loss: 0.011443760828115046, Final Batch Loss: 0.00765732629224658\n",
      "Epoch 803, Loss: 0.009173729282338172, Final Batch Loss: 0.004751620814204216\n",
      "Epoch 804, Loss: 0.014330119360238314, Final Batch Loss: 0.004852295387536287\n",
      "Epoch 805, Loss: 0.011347746825776994, Final Batch Loss: 0.0010548547143116593\n",
      "Epoch 806, Loss: 0.02159250609111041, Final Batch Loss: 0.004652674775570631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807, Loss: 0.0070050026988610625, Final Batch Loss: 0.0023959169629961252\n",
      "Epoch 808, Loss: 0.015992513246601447, Final Batch Loss: 0.0031439533922821283\n",
      "Epoch 809, Loss: 0.012349176919087768, Final Batch Loss: 0.004986153915524483\n",
      "Epoch 810, Loss: 0.027998036588542163, Final Batch Loss: 0.024451082572340965\n",
      "Epoch 811, Loss: 0.0023639956198167056, Final Batch Loss: 0.0002912977652158588\n",
      "Epoch 812, Loss: 0.021030998788774014, Final Batch Loss: 0.005981974769383669\n",
      "Epoch 813, Loss: 0.019428877625614405, Final Batch Loss: 0.008342339657247066\n",
      "Epoch 814, Loss: 0.008776925504207611, Final Batch Loss: 0.0035842459183186293\n",
      "Epoch 815, Loss: 0.012942249595653266, Final Batch Loss: 0.006181448698043823\n",
      "Epoch 816, Loss: 0.0043940143077634275, Final Batch Loss: 0.0009227919508703053\n",
      "Epoch 817, Loss: 0.01743442239239812, Final Batch Loss: 0.005964971613138914\n",
      "Epoch 818, Loss: 0.009385809476953, Final Batch Loss: 0.0004960037185810506\n",
      "Epoch 819, Loss: 0.018119414686225355, Final Batch Loss: 0.014722824096679688\n",
      "Epoch 820, Loss: 0.050718836137093604, Final Batch Loss: 0.04598933085799217\n",
      "Epoch 821, Loss: 0.007069082697853446, Final Batch Loss: 0.0010360454907640815\n",
      "Epoch 822, Loss: 0.0070421245181933045, Final Batch Loss: 0.0011776912724599242\n",
      "Epoch 823, Loss: 0.0422597405849956, Final Batch Loss: 0.0005677210865542293\n",
      "Epoch 824, Loss: 0.007560504134744406, Final Batch Loss: 0.0014430605806410313\n",
      "Epoch 825, Loss: 0.004884825786575675, Final Batch Loss: 0.002219831570982933\n",
      "Epoch 826, Loss: 0.006189811625517905, Final Batch Loss: 0.0012720308732241392\n",
      "Epoch 827, Loss: 0.003982374852057546, Final Batch Loss: 0.0007276478572748601\n",
      "Epoch 828, Loss: 0.007132374565117061, Final Batch Loss: 0.0015221447683870792\n",
      "Epoch 829, Loss: 0.005885634571313858, Final Batch Loss: 0.0010584330884739757\n",
      "Epoch 830, Loss: 0.007236045319586992, Final Batch Loss: 0.0030875494703650475\n",
      "Epoch 831, Loss: 0.0016958606720436364, Final Batch Loss: 0.000699653523042798\n",
      "Epoch 832, Loss: 0.010992258321493864, Final Batch Loss: 0.0014805267564952374\n",
      "Epoch 833, Loss: 0.008419466321356595, Final Batch Loss: 0.003754623932763934\n",
      "Epoch 834, Loss: 0.014313203049823642, Final Batch Loss: 0.0008644997142255306\n",
      "Epoch 835, Loss: 0.02272430737502873, Final Batch Loss: 0.020526448264718056\n",
      "Epoch 836, Loss: 0.015303878812119365, Final Batch Loss: 0.0020660064183175564\n",
      "Epoch 837, Loss: 0.005117839085869491, Final Batch Loss: 0.0014794789021834731\n",
      "Epoch 838, Loss: 0.0034532446297816932, Final Batch Loss: 0.0010281131835654378\n",
      "Epoch 839, Loss: 0.004422180820256472, Final Batch Loss: 0.0014343572547659278\n",
      "Epoch 840, Loss: 0.011051395355025306, Final Batch Loss: 0.0004636448866222054\n",
      "Epoch 841, Loss: 0.007559939112979919, Final Batch Loss: 0.004827573895454407\n",
      "Epoch 842, Loss: 0.003902166849002242, Final Batch Loss: 0.00045291660353541374\n",
      "Epoch 843, Loss: 0.008680866565555334, Final Batch Loss: 0.0036436698865145445\n",
      "Epoch 844, Loss: 0.004619032260961831, Final Batch Loss: 0.0009565092623233795\n",
      "Epoch 845, Loss: 0.007496231759432703, Final Batch Loss: 0.0009320988901890814\n",
      "Epoch 846, Loss: 0.01212824584217742, Final Batch Loss: 0.009306123480200768\n",
      "Epoch 847, Loss: 0.017670990200713277, Final Batch Loss: 0.002587192924693227\n",
      "Epoch 848, Loss: 0.010432515176944435, Final Batch Loss: 0.000537226558662951\n",
      "Epoch 849, Loss: 0.02041786629706621, Final Batch Loss: 0.009393984451889992\n",
      "Epoch 850, Loss: 0.008124023137497716, Final Batch Loss: 0.00016825801867526025\n",
      "Epoch 851, Loss: 0.0065151359885931015, Final Batch Loss: 0.0016995792975649238\n",
      "Epoch 852, Loss: 0.011995897279120982, Final Batch Loss: 0.0009578714380040765\n",
      "Epoch 853, Loss: 0.007024226943030953, Final Batch Loss: 0.0011776299215853214\n",
      "Epoch 854, Loss: 0.03510296461172402, Final Batch Loss: 0.0014641593443229795\n",
      "Epoch 855, Loss: 0.02299581142142415, Final Batch Loss: 0.0031484428327530622\n",
      "Epoch 856, Loss: 0.007986605982296169, Final Batch Loss: 0.0015415657544508576\n",
      "Epoch 857, Loss: 0.002720617048908025, Final Batch Loss: 0.0010466178646311164\n",
      "Epoch 858, Loss: 0.006181067321449518, Final Batch Loss: 0.0014013313921168447\n",
      "Epoch 859, Loss: 0.012897098204120994, Final Batch Loss: 0.0035389892291277647\n",
      "Epoch 860, Loss: 0.0015303678810596466, Final Batch Loss: 0.00043774148798547685\n",
      "Epoch 861, Loss: 0.03398276772350073, Final Batch Loss: 0.019108755514025688\n",
      "Epoch 862, Loss: 0.007198029255960137, Final Batch Loss: 0.0006111808470450342\n",
      "Epoch 863, Loss: 0.00843536271713674, Final Batch Loss: 0.004805330187082291\n",
      "Epoch 864, Loss: 0.0028463020571507514, Final Batch Loss: 0.0013422257034108043\n",
      "Epoch 865, Loss: 0.012897900713142008, Final Batch Loss: 0.0004695802344940603\n",
      "Epoch 866, Loss: 0.003756543854251504, Final Batch Loss: 0.0007412104168906808\n",
      "Epoch 867, Loss: 0.008095056400634348, Final Batch Loss: 0.004959369543939829\n",
      "Epoch 868, Loss: 0.012595603009685874, Final Batch Loss: 0.010589937679469585\n",
      "Epoch 869, Loss: 0.0034610291477292776, Final Batch Loss: 0.0014094511279836297\n",
      "Epoch 870, Loss: 0.021231901249848306, Final Batch Loss: 0.015014461241662502\n",
      "Epoch 871, Loss: 0.015280328807421029, Final Batch Loss: 0.001362543203867972\n",
      "Epoch 872, Loss: 0.014517267816700041, Final Batch Loss: 0.004618112929165363\n",
      "Epoch 873, Loss: 0.021277253923472017, Final Batch Loss: 0.0007554971962235868\n",
      "Epoch 874, Loss: 0.005894081434234977, Final Batch Loss: 0.0009212261065840721\n",
      "Epoch 875, Loss: 0.006987192551605403, Final Batch Loss: 0.0047352551482617855\n",
      "Epoch 876, Loss: 0.0046476305287797, Final Batch Loss: 0.0007757098646834493\n",
      "Epoch 877, Loss: 0.003890554769895971, Final Batch Loss: 0.0005608120700344443\n",
      "Epoch 878, Loss: 0.007886428153142333, Final Batch Loss: 0.002999255433678627\n",
      "Epoch 879, Loss: 0.01585595984943211, Final Batch Loss: 0.011381343938410282\n",
      "Epoch 880, Loss: 0.0043873407412320375, Final Batch Loss: 0.0016143113607540727\n",
      "Epoch 881, Loss: 0.0051665668725036085, Final Batch Loss: 0.0020416437182575464\n",
      "Epoch 882, Loss: 0.0059945916291326284, Final Batch Loss: 0.0034702338743954897\n",
      "Epoch 883, Loss: 0.00920534087345004, Final Batch Loss: 0.0016132693272083998\n",
      "Epoch 884, Loss: 0.00960310292430222, Final Batch Loss: 0.0042735738679766655\n",
      "Epoch 885, Loss: 0.03445809369441122, Final Batch Loss: 0.0017347150715067983\n",
      "Epoch 886, Loss: 0.0025286449817940593, Final Batch Loss: 0.0005359654896892607\n",
      "Epoch 887, Loss: 0.005636476504150778, Final Batch Loss: 0.0031647414434701204\n",
      "Epoch 888, Loss: 0.005497441161423922, Final Batch Loss: 0.0007095659384503961\n",
      "Epoch 889, Loss: 0.008158023745636456, Final Batch Loss: 0.00020840803335886449\n",
      "Epoch 890, Loss: 0.006159040582133457, Final Batch Loss: 0.0050305589102208614\n",
      "Epoch 891, Loss: 0.0023711471585556865, Final Batch Loss: 0.00041454832535237074\n",
      "Epoch 892, Loss: 0.005877559655345976, Final Batch Loss: 0.004491758998483419\n",
      "Epoch 893, Loss: 0.00991126272128895, Final Batch Loss: 0.0003982321941293776\n",
      "Epoch 894, Loss: 0.0030057873227633536, Final Batch Loss: 0.001203010557219386\n",
      "Epoch 895, Loss: 0.012750313733704388, Final Batch Loss: 0.009014129638671875\n",
      "Epoch 896, Loss: 0.00710556551348418, Final Batch Loss: 0.001983834197744727\n",
      "Epoch 897, Loss: 0.0033448776812292635, Final Batch Loss: 0.0014764367369934916\n",
      "Epoch 898, Loss: 0.008566733915358782, Final Batch Loss: 0.00133227976039052\n",
      "Epoch 899, Loss: 0.007207079965155572, Final Batch Loss: 0.0008737327880226076\n",
      "Epoch 900, Loss: 0.0016578380018472672, Final Batch Loss: 0.0005383872776292264\n",
      "Epoch 901, Loss: 0.004420362412929535, Final Batch Loss: 0.0012178635224699974\n",
      "Epoch 902, Loss: 0.007230757037177682, Final Batch Loss: 0.002025531604886055\n",
      "Epoch 903, Loss: 0.0404258948401548, Final Batch Loss: 0.0006772513152100146\n",
      "Epoch 904, Loss: 0.010643040266586468, Final Batch Loss: 0.00035862333606928587\n",
      "Epoch 905, Loss: 0.005409838049672544, Final Batch Loss: 0.0011644818587228656\n",
      "Epoch 906, Loss: 0.010755868046544492, Final Batch Loss: 0.005441954825073481\n",
      "Epoch 907, Loss: 0.004273115424439311, Final Batch Loss: 0.0005829996662214398\n",
      "Epoch 908, Loss: 0.008297077612951398, Final Batch Loss: 0.004253359977155924\n",
      "Epoch 909, Loss: 0.002864884678274393, Final Batch Loss: 0.0015307682333514094\n",
      "Epoch 910, Loss: 0.005867551197297871, Final Batch Loss: 0.001207714551128447\n",
      "Epoch 911, Loss: 0.01005667119170539, Final Batch Loss: 0.0003747581213247031\n",
      "Epoch 912, Loss: 0.0120552449952811, Final Batch Loss: 0.00576271116733551\n",
      "Epoch 913, Loss: 0.0038268794014584273, Final Batch Loss: 0.002347989473491907\n",
      "Epoch 914, Loss: 0.010119586950168014, Final Batch Loss: 0.0017950570909306407\n",
      "Epoch 915, Loss: 0.015516855055466294, Final Batch Loss: 0.004388031084090471\n",
      "Epoch 916, Loss: 0.005344304023310542, Final Batch Loss: 0.001019811606965959\n",
      "Epoch 917, Loss: 0.005466497445013374, Final Batch Loss: 0.0009492964600212872\n",
      "Epoch 918, Loss: 0.021290210890583694, Final Batch Loss: 0.016273658722639084\n",
      "Epoch 919, Loss: 0.004269161727279425, Final Batch Loss: 0.0022866700310260057\n",
      "Epoch 920, Loss: 0.008921807631850243, Final Batch Loss: 0.00486671132966876\n",
      "Epoch 921, Loss: 0.0045333473244681954, Final Batch Loss: 0.0011010832386091352\n",
      "Epoch 922, Loss: 0.013075431401375681, Final Batch Loss: 0.004280813969671726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923, Loss: 0.011585903819650412, Final Batch Loss: 0.0016472337301820517\n",
      "Epoch 924, Loss: 0.012219822208862752, Final Batch Loss: 0.00902590248733759\n",
      "Epoch 925, Loss: 0.0058430476929061115, Final Batch Loss: 0.0002550582285039127\n",
      "Epoch 926, Loss: 0.013732285995502025, Final Batch Loss: 0.0001556052011437714\n",
      "Epoch 927, Loss: 0.004842238122364506, Final Batch Loss: 0.0031819832511246204\n",
      "Epoch 928, Loss: 0.0072869425639510155, Final Batch Loss: 0.001092444290407002\n",
      "Epoch 929, Loss: 0.006182993238326162, Final Batch Loss: 0.001040097326040268\n",
      "Epoch 930, Loss: 0.001794475712813437, Final Batch Loss: 0.0008089893381111324\n",
      "Epoch 931, Loss: 0.009413040126673877, Final Batch Loss: 0.001485897577367723\n",
      "Epoch 932, Loss: 0.008628306852187961, Final Batch Loss: 0.004583505913615227\n",
      "Epoch 933, Loss: 0.039672527273069136, Final Batch Loss: 0.03901384025812149\n",
      "Epoch 934, Loss: 0.07706844434142113, Final Batch Loss: 0.020390378311276436\n",
      "Epoch 935, Loss: 0.026462871173862368, Final Batch Loss: 0.0007800120511092246\n",
      "Epoch 936, Loss: 0.02060723381873686, Final Batch Loss: 0.012479729019105434\n",
      "Epoch 937, Loss: 0.03776605101302266, Final Batch Loss: 0.0027447124011814594\n",
      "Epoch 938, Loss: 0.0173433501040563, Final Batch Loss: 0.008827396668493748\n",
      "Epoch 939, Loss: 0.00484015146503225, Final Batch Loss: 0.0009704944095574319\n",
      "Epoch 940, Loss: 0.011280711740255356, Final Batch Loss: 0.002159818774089217\n",
      "Epoch 941, Loss: 0.007430129451677203, Final Batch Loss: 0.0016647017328068614\n",
      "Epoch 942, Loss: 0.014557056245394051, Final Batch Loss: 0.0056311748921871185\n",
      "Epoch 943, Loss: 0.00577923737000674, Final Batch Loss: 0.0024772793985903263\n",
      "Epoch 944, Loss: 0.012613293598406017, Final Batch Loss: 0.0007960455259308219\n",
      "Epoch 945, Loss: 0.010982470528688282, Final Batch Loss: 0.0008073716890066862\n",
      "Epoch 946, Loss: 0.009706935496069491, Final Batch Loss: 0.0008589638164266944\n",
      "Epoch 947, Loss: 0.03736285527702421, Final Batch Loss: 0.01880047284066677\n",
      "Epoch 948, Loss: 0.004497476562391967, Final Batch Loss: 0.0005571629735641181\n",
      "Epoch 949, Loss: 0.02398981642909348, Final Batch Loss: 0.002355879871174693\n",
      "Epoch 950, Loss: 0.005263990955427289, Final Batch Loss: 0.0015331675531342626\n",
      "Epoch 951, Loss: 0.013001734798308462, Final Batch Loss: 0.002460433403030038\n",
      "Epoch 952, Loss: 0.004362773965112865, Final Batch Loss: 0.0014010254526510835\n",
      "Epoch 953, Loss: 0.0020754068391397595, Final Batch Loss: 0.0009040241711772978\n",
      "Epoch 954, Loss: 0.011710695747751743, Final Batch Loss: 0.0005695627187378705\n",
      "Epoch 955, Loss: 0.008625965099781752, Final Batch Loss: 0.0012486798223108053\n",
      "Epoch 956, Loss: 0.00327658950118348, Final Batch Loss: 0.0007275669486261904\n",
      "Epoch 957, Loss: 0.004006610077340156, Final Batch Loss: 0.00040707242442294955\n",
      "Epoch 958, Loss: 0.008605851442553103, Final Batch Loss: 0.0010158093646168709\n",
      "Epoch 959, Loss: 0.013215144397690892, Final Batch Loss: 0.0061898501589894295\n",
      "Epoch 960, Loss: 0.00946094433311373, Final Batch Loss: 0.00683167576789856\n",
      "Epoch 961, Loss: 0.006434668553993106, Final Batch Loss: 0.0017767163226380944\n",
      "Epoch 962, Loss: 0.015759682864882052, Final Batch Loss: 0.012150720693171024\n",
      "Epoch 963, Loss: 0.014482434722594917, Final Batch Loss: 0.00794773455709219\n",
      "Epoch 964, Loss: 0.008907066250685602, Final Batch Loss: 0.001074985251761973\n",
      "Epoch 965, Loss: 0.015058269491419196, Final Batch Loss: 0.00679126987233758\n",
      "Epoch 966, Loss: 0.012975915102288127, Final Batch Loss: 0.009006933309137821\n",
      "Epoch 967, Loss: 0.004205703386105597, Final Batch Loss: 0.0009805503068491817\n",
      "Epoch 968, Loss: 0.0131604615598917, Final Batch Loss: 0.006465923506766558\n",
      "Epoch 969, Loss: 0.005485531990416348, Final Batch Loss: 0.0026937539223581553\n",
      "Epoch 970, Loss: 0.01274383335839957, Final Batch Loss: 0.007686919067054987\n",
      "Epoch 971, Loss: 0.0031276903464458883, Final Batch Loss: 0.0009438733686693013\n",
      "Epoch 972, Loss: 0.0045606239582411945, Final Batch Loss: 0.0019001505570486188\n",
      "Epoch 973, Loss: 0.007500815438106656, Final Batch Loss: 0.002235514111816883\n",
      "Epoch 974, Loss: 0.00773897988256067, Final Batch Loss: 0.0031252061016857624\n",
      "Epoch 975, Loss: 0.011817931255791336, Final Batch Loss: 0.00047416106099262834\n",
      "Epoch 976, Loss: 0.004494417829846498, Final Batch Loss: 0.0036425923462957144\n",
      "Epoch 977, Loss: 0.0052430733921937644, Final Batch Loss: 0.0004103439277969301\n",
      "Epoch 978, Loss: 0.010247191181406379, Final Batch Loss: 0.003259947756305337\n",
      "Epoch 979, Loss: 0.009406518773175776, Final Batch Loss: 0.0047617810778319836\n",
      "Epoch 980, Loss: 0.0026864588435273618, Final Batch Loss: 0.0006190921412780881\n",
      "Epoch 981, Loss: 0.0017139535339083523, Final Batch Loss: 0.0009690215811133385\n",
      "Epoch 982, Loss: 0.004140145727433264, Final Batch Loss: 0.0007842234335839748\n",
      "Epoch 983, Loss: 0.012491349771153182, Final Batch Loss: 0.0003459698345977813\n",
      "Epoch 984, Loss: 0.003301032178569585, Final Batch Loss: 0.0008201887249015272\n",
      "Epoch 985, Loss: 0.004792025501956232, Final Batch Loss: 0.00018506271590013057\n",
      "Epoch 986, Loss: 0.006685470027150586, Final Batch Loss: 0.0004146217543166131\n",
      "Epoch 987, Loss: 0.0065092356817331165, Final Batch Loss: 0.0008436632342636585\n",
      "Epoch 988, Loss: 0.0016438454040326178, Final Batch Loss: 0.0007280202116817236\n",
      "Epoch 989, Loss: 0.004732125380542129, Final Batch Loss: 0.00036961835576221347\n",
      "Epoch 990, Loss: 0.0029231395456008613, Final Batch Loss: 0.0003442410961724818\n",
      "Epoch 991, Loss: 0.016870602674316615, Final Batch Loss: 0.0008844590629450977\n",
      "Epoch 992, Loss: 0.002862624707631767, Final Batch Loss: 0.0004177491646260023\n",
      "Epoch 993, Loss: 0.0026231780066154897, Final Batch Loss: 0.0013369127409532666\n",
      "Epoch 994, Loss: 0.004872473131399602, Final Batch Loss: 0.00027490907814353704\n",
      "Epoch 995, Loss: 0.05977713712491095, Final Batch Loss: 0.05548449605703354\n",
      "Epoch 996, Loss: 0.008204199257306755, Final Batch Loss: 0.0009757158113643527\n",
      "Epoch 997, Loss: 0.0047156318032648414, Final Batch Loss: 0.00041729313670657575\n",
      "Epoch 998, Loss: 0.004565632727462798, Final Batch Loss: 0.0006079804734326899\n",
      "Epoch 999, Loss: 0.0024355878704227507, Final Batch Loss: 0.00038615427911281586\n",
      "Epoch 1000, Loss: 0.0033480519050499424, Final Batch Loss: 0.0027375887148082256\n",
      "Epoch 1001, Loss: 0.003579816941055469, Final Batch Loss: 0.00023006326227914542\n",
      "Epoch 1002, Loss: 0.0020541165067697875, Final Batch Loss: 9.989918180508539e-05\n",
      "Epoch 1003, Loss: 0.0024988720688270405, Final Batch Loss: 0.00010643027781043202\n",
      "Epoch 1004, Loss: 0.0047461507201660424, Final Batch Loss: 0.0031690942123532295\n",
      "Epoch 1005, Loss: 0.007645004545338452, Final Batch Loss: 0.0011614032555371523\n",
      "Epoch 1006, Loss: 0.0023031493183225393, Final Batch Loss: 0.0012861546128988266\n",
      "Epoch 1007, Loss: 0.0023505318094976246, Final Batch Loss: 0.000715973146725446\n",
      "Epoch 1008, Loss: 0.014590403181500733, Final Batch Loss: 0.0008962725987657905\n",
      "Epoch 1009, Loss: 0.012924647482577711, Final Batch Loss: 0.0002731574058998376\n",
      "Epoch 1010, Loss: 0.0008091105701168999, Final Batch Loss: 0.00021516780543606728\n",
      "Epoch 1011, Loss: 0.03613483236404136, Final Batch Loss: 0.0003148422110825777\n",
      "Epoch 1012, Loss: 0.0029363353678490967, Final Batch Loss: 0.0002727274550125003\n",
      "Epoch 1013, Loss: 0.022315906928270124, Final Batch Loss: 0.02163124457001686\n",
      "Epoch 1014, Loss: 0.00964096817187965, Final Batch Loss: 0.004068910144269466\n",
      "Epoch 1015, Loss: 0.00316011936229188, Final Batch Loss: 0.0001950175064848736\n",
      "Epoch 1016, Loss: 0.002690457651624456, Final Batch Loss: 0.00040866664494387805\n",
      "Epoch 1017, Loss: 0.0065064780646935105, Final Batch Loss: 0.004068792797625065\n",
      "Epoch 1018, Loss: 0.003186234476743266, Final Batch Loss: 0.0009227294358424842\n",
      "Epoch 1019, Loss: 0.003202109190169722, Final Batch Loss: 0.0022110282443463802\n",
      "Epoch 1020, Loss: 0.0018231321882922202, Final Batch Loss: 0.0007095696637406945\n",
      "Epoch 1021, Loss: 0.00978858067537658, Final Batch Loss: 0.008785847574472427\n",
      "Epoch 1022, Loss: 0.0058253726456314325, Final Batch Loss: 0.0010015098378062248\n",
      "Epoch 1023, Loss: 0.04596623654651921, Final Batch Loss: 0.044152773916721344\n",
      "Epoch 1024, Loss: 0.0028470857068896294, Final Batch Loss: 0.0012813577195629478\n",
      "Epoch 1025, Loss: 0.005385653887060471, Final Batch Loss: 0.00018746046407613903\n",
      "Epoch 1026, Loss: 0.004285742645151913, Final Batch Loss: 0.0002929078182205558\n",
      "Epoch 1027, Loss: 0.003929310085368343, Final Batch Loss: 0.0006388452602550387\n",
      "Epoch 1028, Loss: 0.003646677767392248, Final Batch Loss: 0.0005134374951012433\n",
      "Epoch 1029, Loss: 0.026251689763739705, Final Batch Loss: 0.002390125999227166\n",
      "Epoch 1030, Loss: 0.0032913964241743088, Final Batch Loss: 0.0013583684340119362\n",
      "Epoch 1031, Loss: 0.013916133088059723, Final Batch Loss: 0.0019779610447585583\n",
      "Epoch 1032, Loss: 0.006238961534108967, Final Batch Loss: 0.00035976123763248324\n",
      "Epoch 1033, Loss: 0.0027974418771918863, Final Batch Loss: 0.00013467646203935146\n",
      "Epoch 1034, Loss: 0.028016917291097343, Final Batch Loss: 0.000835833721794188\n",
      "Epoch 1035, Loss: 0.005466791393700987, Final Batch Loss: 0.00248937145806849\n",
      "Epoch 1036, Loss: 0.01258119905833155, Final Batch Loss: 0.0015011044451966882\n",
      "Epoch 1037, Loss: 0.0036337502242531627, Final Batch Loss: 0.00021432593348436058\n",
      "Epoch 1038, Loss: 0.025990697984525468, Final Batch Loss: 0.0009144283831119537\n",
      "Epoch 1039, Loss: 0.019791778759099543, Final Batch Loss: 0.015482576563954353\n",
      "Epoch 1040, Loss: 0.0027563385374378413, Final Batch Loss: 0.001080513116903603\n",
      "Epoch 1041, Loss: 0.00429630238795653, Final Batch Loss: 0.00167194998357445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1042, Loss: 0.004533433821052313, Final Batch Loss: 0.0031777569092810154\n",
      "Epoch 1043, Loss: 0.00542679920908995, Final Batch Loss: 0.0009118634043261409\n",
      "Epoch 1044, Loss: 0.010304785362677649, Final Batch Loss: 0.0048381974920630455\n",
      "Epoch 1045, Loss: 0.004683358478359878, Final Batch Loss: 0.0006862904410809278\n",
      "Epoch 1046, Loss: 0.002316504978807643, Final Batch Loss: 0.0009492449462413788\n",
      "Epoch 1047, Loss: 0.003152594857965596, Final Batch Loss: 0.0004775951965712011\n",
      "Epoch 1048, Loss: 0.004690663306973875, Final Batch Loss: 0.0004963401006534696\n",
      "Epoch 1049, Loss: 0.008097990648820996, Final Batch Loss: 0.003423015819862485\n",
      "Epoch 1050, Loss: 0.003666710894322023, Final Batch Loss: 0.0004080505750607699\n",
      "Epoch 1051, Loss: 0.03741114889271557, Final Batch Loss: 0.0007133738836273551\n",
      "Epoch 1052, Loss: 0.0031377149862237275, Final Batch Loss: 0.0005862581892870367\n",
      "Epoch 1053, Loss: 0.004321131156757474, Final Batch Loss: 0.0012421152787283063\n",
      "Epoch 1054, Loss: 0.00549957063049078, Final Batch Loss: 0.0002622117754071951\n",
      "Epoch 1055, Loss: 0.001837725896621123, Final Batch Loss: 0.0006955932476557791\n",
      "Epoch 1056, Loss: 0.0026675424014683813, Final Batch Loss: 0.0009026003535836935\n",
      "Epoch 1057, Loss: 0.0036984009202569723, Final Batch Loss: 0.0011689492966979742\n",
      "Epoch 1058, Loss: 0.021555745508521795, Final Batch Loss: 0.0019874514546245337\n",
      "Epoch 1059, Loss: 0.007243496394949034, Final Batch Loss: 0.00037109493860043585\n",
      "Epoch 1060, Loss: 0.002690162684302777, Final Batch Loss: 0.00044786330545321107\n",
      "Epoch 1061, Loss: 0.005454730067867786, Final Batch Loss: 0.0007957933121360838\n",
      "Epoch 1062, Loss: 0.001709212432615459, Final Batch Loss: 0.0004823383060283959\n",
      "Epoch 1063, Loss: 0.005471945274621248, Final Batch Loss: 0.0007779952138662338\n",
      "Epoch 1064, Loss: 0.003551164292730391, Final Batch Loss: 0.0010271896608173847\n",
      "Epoch 1065, Loss: 0.001254711241926998, Final Batch Loss: 0.0001466037647332996\n",
      "Epoch 1066, Loss: 0.0025357960257679224, Final Batch Loss: 0.0010901479981839657\n",
      "Epoch 1067, Loss: 0.002399003249593079, Final Batch Loss: 0.0006744634010829031\n",
      "Epoch 1068, Loss: 0.0034401589073240757, Final Batch Loss: 0.0018354201456531882\n",
      "Epoch 1069, Loss: 0.0031523263023700565, Final Batch Loss: 0.0006869066855870187\n",
      "Epoch 1070, Loss: 0.004825583630008623, Final Batch Loss: 0.0004477535549085587\n",
      "Epoch 1071, Loss: 0.006789565668441355, Final Batch Loss: 0.003090422134846449\n",
      "Epoch 1072, Loss: 0.004036793136037886, Final Batch Loss: 0.0011005110573023558\n",
      "Epoch 1073, Loss: 0.008705799584276974, Final Batch Loss: 0.004275151994079351\n",
      "Epoch 1074, Loss: 0.013244082394521683, Final Batch Loss: 0.011349737644195557\n",
      "Epoch 1075, Loss: 0.007110564270988107, Final Batch Loss: 0.0036606192588806152\n",
      "Epoch 1076, Loss: 0.008209986961446702, Final Batch Loss: 0.005918807815760374\n",
      "Epoch 1077, Loss: 0.0034906479413621128, Final Batch Loss: 0.0003624385572038591\n",
      "Epoch 1078, Loss: 0.002516167485737242, Final Batch Loss: 0.00019084148516412824\n",
      "Epoch 1079, Loss: 0.004945721477270126, Final Batch Loss: 0.0015416622627526522\n",
      "Epoch 1080, Loss: 0.003514511918183416, Final Batch Loss: 0.0010275628883391619\n",
      "Epoch 1081, Loss: 0.0010973067619488575, Final Batch Loss: 8.733265713090077e-05\n",
      "Epoch 1082, Loss: 0.0023409778805216774, Final Batch Loss: 0.0012050188379362226\n",
      "Epoch 1083, Loss: 0.003034456691239029, Final Batch Loss: 0.00019661919213831425\n",
      "Epoch 1084, Loss: 0.008851658436469734, Final Batch Loss: 0.004006306640803814\n",
      "Epoch 1085, Loss: 0.005201281339395791, Final Batch Loss: 0.0006242786184884608\n",
      "Epoch 1086, Loss: 0.008370161216589622, Final Batch Loss: 0.0071463328786194324\n",
      "Epoch 1087, Loss: 0.014697488746605814, Final Batch Loss: 0.0007733518723398447\n",
      "Epoch 1088, Loss: 0.005846563377417624, Final Batch Loss: 0.001014802255667746\n",
      "Epoch 1089, Loss: 0.0011847983114421368, Final Batch Loss: 0.0003293017507530749\n",
      "Epoch 1090, Loss: 0.016680724220350385, Final Batch Loss: 0.00717503298074007\n",
      "Epoch 1091, Loss: 0.005063273725681938, Final Batch Loss: 0.0026886695995926857\n",
      "Epoch 1092, Loss: 0.0018703328314586543, Final Batch Loss: 0.0005412073223851621\n",
      "Epoch 1093, Loss: 0.008454771596007049, Final Batch Loss: 0.004810309037566185\n",
      "Epoch 1094, Loss: 0.0027305122930556536, Final Batch Loss: 0.0001872920256573707\n",
      "Epoch 1095, Loss: 0.006790861982153729, Final Batch Loss: 0.0056426143273711205\n",
      "Epoch 1096, Loss: 0.0043979783076792955, Final Batch Loss: 0.0007260735728777945\n",
      "Epoch 1097, Loss: 0.0023925936257001013, Final Batch Loss: 0.0010068337433040142\n",
      "Epoch 1098, Loss: 0.0025995021569542587, Final Batch Loss: 0.0009857295081019402\n",
      "Epoch 1099, Loss: 0.001492986615630798, Final Batch Loss: 0.00010035249579232186\n",
      "Epoch 1100, Loss: 0.02084257363458164, Final Batch Loss: 0.01976923644542694\n",
      "Epoch 1101, Loss: 0.004640202852897346, Final Batch Loss: 0.0017546771559864283\n",
      "Epoch 1102, Loss: 0.013864357606507838, Final Batch Loss: 0.0009855381213128567\n",
      "Epoch 1103, Loss: 0.0032643023296259344, Final Batch Loss: 0.00025443354388698936\n",
      "Epoch 1104, Loss: 0.0037755109660793096, Final Batch Loss: 0.0009119267342612147\n",
      "Epoch 1105, Loss: 0.0019588907998695504, Final Batch Loss: 4.727018313133158e-05\n",
      "Epoch 1106, Loss: 0.002419867741991766, Final Batch Loss: 0.0009959593880921602\n",
      "Epoch 1107, Loss: 0.011223934692679904, Final Batch Loss: 0.00016308162594214082\n",
      "Epoch 1108, Loss: 0.007006125582847744, Final Batch Loss: 0.005303878802806139\n",
      "Epoch 1109, Loss: 0.02721231270697899, Final Batch Loss: 0.0024546415079385042\n",
      "Epoch 1110, Loss: 0.002647153160069138, Final Batch Loss: 0.0007382584153674543\n",
      "Epoch 1111, Loss: 0.01267745514633134, Final Batch Loss: 0.0008615457336418331\n",
      "Epoch 1112, Loss: 0.0012207887484692037, Final Batch Loss: 0.0002670347457751632\n",
      "Epoch 1113, Loss: 0.004031627671793103, Final Batch Loss: 0.00034513825085014105\n",
      "Epoch 1114, Loss: 0.0032600039266981184, Final Batch Loss: 0.00037789769703522325\n",
      "Epoch 1115, Loss: 0.0014722902269568294, Final Batch Loss: 0.00030882321880199015\n",
      "Epoch 1116, Loss: 0.005961885675787926, Final Batch Loss: 0.0003008494386449456\n",
      "Epoch 1117, Loss: 0.008746639359742403, Final Batch Loss: 0.00042009796015918255\n",
      "Epoch 1118, Loss: 0.01852238504216075, Final Batch Loss: 0.006022867280989885\n",
      "Epoch 1119, Loss: 0.002739695191849023, Final Batch Loss: 0.00120088504627347\n",
      "Epoch 1120, Loss: 0.001300479198107496, Final Batch Loss: 0.00013062695506960154\n",
      "Epoch 1121, Loss: 0.0009875107498373836, Final Batch Loss: 0.000843313115183264\n",
      "Epoch 1122, Loss: 0.005272613780107349, Final Batch Loss: 0.0015230500139296055\n",
      "Epoch 1123, Loss: 0.010661449254257604, Final Batch Loss: 0.004590973258018494\n",
      "Epoch 1124, Loss: 0.005394576248363592, Final Batch Loss: 0.00018711887241806835\n",
      "Epoch 1125, Loss: 0.0013753238890785724, Final Batch Loss: 0.000491235638037324\n",
      "Epoch 1126, Loss: 0.002782808616757393, Final Batch Loss: 0.0008582405280321836\n",
      "Epoch 1127, Loss: 0.006027903553331271, Final Batch Loss: 0.00014596679829992354\n",
      "Epoch 1128, Loss: 0.0011470694589661434, Final Batch Loss: 0.00016285952006001025\n",
      "Epoch 1129, Loss: 0.00599036557105137, Final Batch Loss: 0.00010380049207014963\n",
      "Epoch 1130, Loss: 0.0017029728624038398, Final Batch Loss: 0.001146885217167437\n",
      "Epoch 1131, Loss: 0.0026398448972031474, Final Batch Loss: 0.000369258807040751\n",
      "Epoch 1132, Loss: 0.002031749696470797, Final Batch Loss: 0.0005449627060443163\n",
      "Epoch 1133, Loss: 0.004330676485551521, Final Batch Loss: 0.003501160303130746\n",
      "Epoch 1134, Loss: 0.021544522373005748, Final Batch Loss: 0.0015176613815128803\n",
      "Epoch 1135, Loss: 0.0037858420982956886, Final Batch Loss: 0.00029729941161349416\n",
      "Epoch 1136, Loss: 0.006117128417827189, Final Batch Loss: 0.0038164500147104263\n",
      "Epoch 1137, Loss: 0.0045058119867462665, Final Batch Loss: 0.003506359178572893\n",
      "Epoch 1138, Loss: 0.01266653323546052, Final Batch Loss: 0.003572006244212389\n",
      "Epoch 1139, Loss: 0.0018215601157862693, Final Batch Loss: 0.0002846676215995103\n",
      "Epoch 1140, Loss: 0.026261224469635636, Final Batch Loss: 0.000753027678001672\n",
      "Epoch 1141, Loss: 0.03401450784440385, Final Batch Loss: 0.0011536646634340286\n",
      "Epoch 1142, Loss: 0.0028569443384185433, Final Batch Loss: 0.0006366407033056021\n",
      "Epoch 1143, Loss: 0.001306692443904467, Final Batch Loss: 0.00028572752489708364\n",
      "Epoch 1144, Loss: 0.0046658114733872935, Final Batch Loss: 0.0016403313493356109\n",
      "Epoch 1145, Loss: 0.03446154932316858, Final Batch Loss: 0.006424623541533947\n",
      "Epoch 1146, Loss: 0.002334289893042296, Final Batch Loss: 0.0003922805772162974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1147, Loss: 0.002148324128938839, Final Batch Loss: 0.00015307925059460104\n",
      "Epoch 1148, Loss: 0.0055853844387456775, Final Batch Loss: 0.0027120662853121758\n",
      "Epoch 1149, Loss: 0.007670998224057257, Final Batch Loss: 0.0011340916389599442\n",
      "Epoch 1150, Loss: 0.012108763825381175, Final Batch Loss: 0.0007646021549589932\n",
      "Epoch 1151, Loss: 0.002837909836671315, Final Batch Loss: 0.0012635785387828946\n",
      "Epoch 1152, Loss: 0.002698845404665917, Final Batch Loss: 0.0008272675913758576\n",
      "Epoch 1153, Loss: 0.004000886430731043, Final Batch Loss: 0.00040437153074890375\n",
      "Epoch 1154, Loss: 0.006449448934290558, Final Batch Loss: 0.00506608234718442\n",
      "Epoch 1155, Loss: 0.010536048299400136, Final Batch Loss: 0.00993343349546194\n",
      "Epoch 1156, Loss: 0.01033882360206917, Final Batch Loss: 0.009002765640616417\n",
      "Epoch 1157, Loss: 0.0021477488917298615, Final Batch Loss: 0.0009003520244732499\n",
      "Epoch 1158, Loss: 0.002103786937368568, Final Batch Loss: 0.00011688612721627578\n",
      "Epoch 1159, Loss: 0.0024704149400349706, Final Batch Loss: 0.000263660418568179\n",
      "Epoch 1160, Loss: 0.01305753260385245, Final Batch Loss: 0.008733284659683704\n",
      "Epoch 1161, Loss: 0.005227036876021884, Final Batch Loss: 0.0001698911510175094\n",
      "Epoch 1162, Loss: 0.003481669817119837, Final Batch Loss: 0.0013116815825924277\n",
      "Epoch 1163, Loss: 0.005278927506878972, Final Batch Loss: 0.0011496816296130419\n",
      "Epoch 1164, Loss: 0.0019181217066943645, Final Batch Loss: 0.0002785692340694368\n",
      "Epoch 1165, Loss: 0.004035572725115344, Final Batch Loss: 0.0012519105803221464\n",
      "Epoch 1166, Loss: 0.0038003211666364223, Final Batch Loss: 0.0003159960324410349\n",
      "Epoch 1167, Loss: 0.0042743784142658114, Final Batch Loss: 0.0027107952628284693\n",
      "Epoch 1168, Loss: 0.028653347515501082, Final Batch Loss: 0.001250861561857164\n",
      "Epoch 1169, Loss: 0.0029248224454931915, Final Batch Loss: 0.002321577863767743\n",
      "Epoch 1170, Loss: 0.0066200983710587025, Final Batch Loss: 0.002801587339490652\n",
      "Epoch 1171, Loss: 0.002330805640667677, Final Batch Loss: 0.0010016676969826221\n",
      "Epoch 1172, Loss: 0.0019404721824685112, Final Batch Loss: 0.001342501607723534\n",
      "Epoch 1173, Loss: 0.0022629866434726864, Final Batch Loss: 0.0003767163143493235\n",
      "Epoch 1174, Loss: 0.0016970729629974812, Final Batch Loss: 0.00047020462807267904\n",
      "Epoch 1175, Loss: 0.005659940274199471, Final Batch Loss: 0.0006888682255521417\n",
      "Epoch 1176, Loss: 0.008843765943311155, Final Batch Loss: 0.0010424032807350159\n",
      "Epoch 1177, Loss: 0.02735859784297645, Final Batch Loss: 0.024895215407013893\n",
      "Epoch 1178, Loss: 0.0019366875203559175, Final Batch Loss: 0.0002257166925119236\n",
      "Epoch 1179, Loss: 0.0016690540360286832, Final Batch Loss: 0.0006708669243380427\n",
      "Epoch 1180, Loss: 0.013212187332101166, Final Batch Loss: 0.00044840702321380377\n",
      "Epoch 1181, Loss: 0.004155902395723388, Final Batch Loss: 0.00047518042265437543\n",
      "Epoch 1182, Loss: 0.006530244063469581, Final Batch Loss: 0.00014777288015466183\n",
      "Epoch 1183, Loss: 0.0024922524899011478, Final Batch Loss: 0.00023393564333673567\n",
      "Epoch 1184, Loss: 0.001073191742761992, Final Batch Loss: 0.0003253029426559806\n",
      "Epoch 1185, Loss: 0.0013743463350692764, Final Batch Loss: 0.000356179109076038\n",
      "Epoch 1186, Loss: 0.0029298904119059443, Final Batch Loss: 0.0006120636826381087\n",
      "Epoch 1187, Loss: 0.0022057432506699115, Final Batch Loss: 0.00033334680483676493\n",
      "Epoch 1188, Loss: 0.010216168870101683, Final Batch Loss: 0.0002311442804057151\n",
      "Epoch 1189, Loss: 0.005659806658513844, Final Batch Loss: 0.0009726519929245114\n",
      "Epoch 1190, Loss: 0.006827915436588228, Final Batch Loss: 0.004273531027138233\n",
      "Epoch 1191, Loss: 0.007049100939184427, Final Batch Loss: 0.0017663612961769104\n",
      "Epoch 1192, Loss: 0.0024898153642425314, Final Batch Loss: 0.00013854239659849554\n",
      "Epoch 1193, Loss: 0.017539173568366095, Final Batch Loss: 0.01484338752925396\n",
      "Epoch 1194, Loss: 0.0014929316967027262, Final Batch Loss: 0.0007598074735142291\n",
      "Epoch 1195, Loss: 0.0035021445073653013, Final Batch Loss: 0.00013613307964988053\n",
      "Epoch 1196, Loss: 0.0613436836283654, Final Batch Loss: 0.06022057682275772\n",
      "Epoch 1197, Loss: 0.010441129328683019, Final Batch Loss: 0.0045771971344947815\n",
      "Epoch 1198, Loss: 0.020849550986895338, Final Batch Loss: 0.004607406910508871\n",
      "Epoch 1199, Loss: 0.003796807475737296, Final Batch Loss: 0.0001449564442737028\n",
      "Epoch 1200, Loss: 0.012805566715542227, Final Batch Loss: 0.0029898383654654026\n",
      "Epoch 1201, Loss: 0.0018153952260036021, Final Batch Loss: 0.0008072813507169485\n",
      "Epoch 1202, Loss: 0.0025128464330919087, Final Batch Loss: 0.000544069625902921\n",
      "Epoch 1203, Loss: 0.0071606512065045536, Final Batch Loss: 0.00028838583966717124\n",
      "Epoch 1204, Loss: 0.0007061865981086157, Final Batch Loss: 0.00011068287858506665\n",
      "Epoch 1205, Loss: 0.0025601405068300664, Final Batch Loss: 0.0012565914075821638\n",
      "Epoch 1206, Loss: 0.0219484271510737, Final Batch Loss: 0.00025703676510602236\n",
      "Epoch 1207, Loss: 0.011726803350029513, Final Batch Loss: 0.006776520982384682\n",
      "Epoch 1208, Loss: 0.0017705908103380352, Final Batch Loss: 0.0003826681640930474\n",
      "Epoch 1209, Loss: 0.0037238495715428144, Final Batch Loss: 0.00029532695771194994\n",
      "Epoch 1210, Loss: 0.021084177133161575, Final Batch Loss: 0.01892663910984993\n",
      "Epoch 1211, Loss: 0.00553143146680668, Final Batch Loss: 0.004494488704949617\n",
      "Epoch 1212, Loss: 0.005345241661416367, Final Batch Loss: 0.0007454481674358249\n",
      "Epoch 1213, Loss: 0.008087327762041241, Final Batch Loss: 0.005724199581891298\n",
      "Epoch 1214, Loss: 0.016412170371040702, Final Batch Loss: 0.0020556922536343336\n",
      "Epoch 1215, Loss: 0.017184653173899278, Final Batch Loss: 0.0160671379417181\n",
      "Epoch 1216, Loss: 0.020226179098244756, Final Batch Loss: 0.016729939728975296\n",
      "Epoch 1217, Loss: 0.007832390139810741, Final Batch Loss: 0.00037686305586248636\n",
      "Epoch 1218, Loss: 0.00296401436207816, Final Batch Loss: 0.0015113562112674117\n",
      "Epoch 1219, Loss: 0.0036553413956426084, Final Batch Loss: 0.001049141981638968\n",
      "Epoch 1220, Loss: 0.00353948819974903, Final Batch Loss: 0.00017944870342034847\n",
      "Epoch 1221, Loss: 0.009260395338060334, Final Batch Loss: 0.0004676142998505384\n",
      "Epoch 1222, Loss: 0.005040448799263686, Final Batch Loss: 0.000695192429702729\n",
      "Epoch 1223, Loss: 0.002951827016659081, Final Batch Loss: 0.00071860128082335\n",
      "Epoch 1224, Loss: 0.006129280664026737, Final Batch Loss: 0.0005007245345041156\n",
      "Epoch 1225, Loss: 0.0029817786416970193, Final Batch Loss: 0.0015641194768249989\n",
      "Epoch 1226, Loss: 0.0184478594455868, Final Batch Loss: 0.00925765186548233\n",
      "Epoch 1227, Loss: 0.0022775924371671863, Final Batch Loss: 7.243350410135463e-05\n",
      "Epoch 1228, Loss: 0.004429808002896607, Final Batch Loss: 0.0026830004062503576\n",
      "Epoch 1229, Loss: 0.0035964480484835804, Final Batch Loss: 0.0029738738667219877\n",
      "Epoch 1230, Loss: 0.0018654834129847586, Final Batch Loss: 0.00037312298081815243\n",
      "Epoch 1231, Loss: 0.06881166172388475, Final Batch Loss: 0.06835100054740906\n",
      "Epoch 1232, Loss: 0.06751150684431195, Final Batch Loss: 0.0655561238527298\n",
      "Epoch 1233, Loss: 0.0017130336200352758, Final Batch Loss: 0.0007544414256699383\n",
      "Epoch 1234, Loss: 0.00481528858654201, Final Batch Loss: 0.0006238899077288806\n",
      "Epoch 1235, Loss: 0.03512143588159233, Final Batch Loss: 0.0003463831963017583\n",
      "Epoch 1236, Loss: 0.03850474726641551, Final Batch Loss: 0.03649480640888214\n",
      "Epoch 1237, Loss: 0.03241724777035415, Final Batch Loss: 0.007647667080163956\n",
      "Epoch 1238, Loss: 0.012047022115439177, Final Batch Loss: 0.002725983038544655\n",
      "Epoch 1239, Loss: 0.025660680374130607, Final Batch Loss: 0.000686936778947711\n",
      "Epoch 1240, Loss: 0.014109198120422661, Final Batch Loss: 0.0005550275091081858\n",
      "Epoch 1241, Loss: 0.007447129464708269, Final Batch Loss: 0.003136442042887211\n",
      "Epoch 1242, Loss: 0.002323620952665806, Final Batch Loss: 0.001480747596360743\n",
      "Epoch 1243, Loss: 0.006523732095956802, Final Batch Loss: 0.0017652756068855524\n",
      "Epoch 1244, Loss: 0.0034963033394888043, Final Batch Loss: 0.001000101095996797\n",
      "Epoch 1245, Loss: 0.003325406985823065, Final Batch Loss: 0.0012254593893885612\n",
      "Epoch 1246, Loss: 0.004013077937997878, Final Batch Loss: 0.0014590799110010266\n",
      "Epoch 1247, Loss: 0.007417236687615514, Final Batch Loss: 0.0006494878907687962\n",
      "Epoch 1248, Loss: 0.0036150375963188708, Final Batch Loss: 0.0005758358747698367\n",
      "Epoch 1249, Loss: 0.0044332718243822455, Final Batch Loss: 0.001229992019943893\n",
      "Epoch 1250, Loss: 0.002453134424285963, Final Batch Loss: 0.00029159808764234185\n",
      "Epoch 1251, Loss: 0.005402394279371947, Final Batch Loss: 0.0029142803978174925\n",
      "Epoch 1252, Loss: 0.002047707181191072, Final Batch Loss: 0.0002465362485963851\n",
      "Epoch 1253, Loss: 0.008996213262435049, Final Batch Loss: 0.0004426180967129767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1254, Loss: 0.012821297626942396, Final Batch Loss: 0.00292484974488616\n",
      "Epoch 1255, Loss: 0.004533393774181604, Final Batch Loss: 0.001133575802668929\n",
      "Epoch 1256, Loss: 0.0018721722590271384, Final Batch Loss: 0.0012349530588835478\n",
      "Epoch 1257, Loss: 0.03432215968496166, Final Batch Loss: 0.030363328754901886\n",
      "Epoch 1258, Loss: 0.004974490380845964, Final Batch Loss: 0.003987655509263277\n",
      "Epoch 1259, Loss: 0.002126972234691493, Final Batch Loss: 9.792031778488308e-05\n",
      "Epoch 1260, Loss: 0.0043052346154581755, Final Batch Loss: 0.0031188379507511854\n",
      "Epoch 1261, Loss: 0.0029660485161002725, Final Batch Loss: 0.0011080362601205707\n",
      "Epoch 1262, Loss: 0.002680897421669215, Final Batch Loss: 0.00025277610984630883\n",
      "Epoch 1263, Loss: 0.0043146662501385435, Final Batch Loss: 0.0001992783072637394\n",
      "Epoch 1264, Loss: 0.0026177063991781324, Final Batch Loss: 0.0003858956915792078\n",
      "Epoch 1265, Loss: 0.00725074514048174, Final Batch Loss: 0.0002614965196698904\n",
      "Epoch 1266, Loss: 0.0043829048809129745, Final Batch Loss: 0.0004680601123254746\n",
      "Epoch 1267, Loss: 0.012561721610836685, Final Batch Loss: 0.01046701055020094\n",
      "Epoch 1268, Loss: 0.004648353497032076, Final Batch Loss: 0.0013659411342814565\n",
      "Epoch 1269, Loss: 0.0025195792550221086, Final Batch Loss: 0.0006489317747764289\n",
      "Epoch 1270, Loss: 0.0011930173204746097, Final Batch Loss: 0.0005410864250734448\n",
      "Epoch 1271, Loss: 0.00275033651269041, Final Batch Loss: 0.00028603614191524684\n",
      "Epoch 1272, Loss: 0.01861526425636839, Final Batch Loss: 8.385586261283606e-05\n",
      "Epoch 1273, Loss: 0.00918995391111821, Final Batch Loss: 0.0073318444192409515\n",
      "Epoch 1274, Loss: 0.006065241163014434, Final Batch Loss: 0.005479039158672094\n",
      "Epoch 1275, Loss: 0.000749084007111378, Final Batch Loss: 0.0002572137163951993\n",
      "Epoch 1276, Loss: 0.0065658254898153245, Final Batch Loss: 0.0011675237910822034\n",
      "Epoch 1277, Loss: 0.0037269670283421874, Final Batch Loss: 0.000371509522665292\n",
      "Epoch 1278, Loss: 0.0021516448468901217, Final Batch Loss: 9.61877522058785e-05\n",
      "Epoch 1279, Loss: 0.02228683332214132, Final Batch Loss: 0.00016992009477689862\n",
      "Epoch 1280, Loss: 0.004450738895684481, Final Batch Loss: 0.00021155201829969883\n",
      "Epoch 1281, Loss: 0.006851422629551962, Final Batch Loss: 0.0005739751504734159\n",
      "Epoch 1282, Loss: 0.004574901191517711, Final Batch Loss: 0.001379910740070045\n",
      "Epoch 1283, Loss: 0.004984286380931735, Final Batch Loss: 0.000548100215382874\n",
      "Epoch 1284, Loss: 0.0052398798579815775, Final Batch Loss: 0.000308840797515586\n",
      "Epoch 1285, Loss: 0.004301158362068236, Final Batch Loss: 0.00041637232061475515\n",
      "Epoch 1286, Loss: 0.00107299312367104, Final Batch Loss: 0.0002784930693451315\n",
      "Epoch 1287, Loss: 0.0025455172290094197, Final Batch Loss: 0.0002453313791193068\n",
      "Epoch 1288, Loss: 0.0023317192390095443, Final Batch Loss: 0.00084819330368191\n",
      "Epoch 1289, Loss: 0.002833374368492514, Final Batch Loss: 0.0011302060447633266\n",
      "Epoch 1290, Loss: 0.008747758663957939, Final Batch Loss: 0.003411795012652874\n",
      "Epoch 1291, Loss: 0.007854721741750836, Final Batch Loss: 0.0009563661878928542\n",
      "Epoch 1292, Loss: 0.0022176978673087433, Final Batch Loss: 0.0001345790078630671\n",
      "Epoch 1293, Loss: 0.005361903924494982, Final Batch Loss: 0.0007845534710213542\n",
      "Epoch 1294, Loss: 0.00493692621239461, Final Batch Loss: 0.000190673308679834\n",
      "Epoch 1295, Loss: 0.0034910886097350158, Final Batch Loss: 0.0017875544726848602\n",
      "Epoch 1296, Loss: 0.003788824047660455, Final Batch Loss: 0.003038116032257676\n",
      "Epoch 1297, Loss: 0.0064432150684297085, Final Batch Loss: 0.0010048446711152792\n",
      "Epoch 1298, Loss: 0.0019929481350118294, Final Batch Loss: 0.000312034651869908\n",
      "Epoch 1299, Loss: 0.008329979609698057, Final Batch Loss: 0.00011719902977347374\n",
      "Epoch 1300, Loss: 0.0054730674892198294, Final Batch Loss: 0.00034170373692177236\n",
      "Epoch 1301, Loss: 0.007329825544729829, Final Batch Loss: 0.006754955742508173\n",
      "Epoch 1302, Loss: 0.0021815107902511954, Final Batch Loss: 0.000462498574052006\n",
      "Epoch 1303, Loss: 0.009037029929459095, Final Batch Loss: 0.005626180674880743\n",
      "Epoch 1304, Loss: 0.012348540185485035, Final Batch Loss: 0.0009133095154538751\n",
      "Epoch 1305, Loss: 0.010004310810472816, Final Batch Loss: 0.005630230996757746\n",
      "Epoch 1306, Loss: 0.009376561734825373, Final Batch Loss: 0.005397930275648832\n",
      "Epoch 1307, Loss: 0.007352717249887064, Final Batch Loss: 0.0003199070051778108\n",
      "Epoch 1308, Loss: 0.00395771797047928, Final Batch Loss: 0.002085359999909997\n",
      "Epoch 1309, Loss: 0.003669087163871154, Final Batch Loss: 0.00019228534074500203\n",
      "Epoch 1310, Loss: 0.005534948402782902, Final Batch Loss: 0.0005101841525174677\n",
      "Epoch 1311, Loss: 0.014726431691087782, Final Batch Loss: 0.005242445506155491\n",
      "Epoch 1312, Loss: 0.00876576837617904, Final Batch Loss: 0.0014537821989506483\n",
      "Epoch 1313, Loss: 0.0030882821301929653, Final Batch Loss: 0.00041715786210261285\n",
      "Epoch 1314, Loss: 0.004935976001434028, Final Batch Loss: 0.002742987358942628\n",
      "Epoch 1315, Loss: 0.0026006827247329056, Final Batch Loss: 0.00013683456927537918\n",
      "Epoch 1316, Loss: 0.0035808568354696035, Final Batch Loss: 0.0011368399718776345\n",
      "Epoch 1317, Loss: 0.004993830865714699, Final Batch Loss: 0.0044224997982382774\n",
      "Epoch 1318, Loss: 0.0042394864722155035, Final Batch Loss: 0.001135673257522285\n",
      "Epoch 1319, Loss: 0.002172384825826157, Final Batch Loss: 6.751454930054024e-05\n",
      "Epoch 1320, Loss: 0.0017306864028796554, Final Batch Loss: 0.0009519716259092093\n",
      "Epoch 1321, Loss: 0.005907175043830648, Final Batch Loss: 0.0002597852435428649\n",
      "Epoch 1322, Loss: 0.0009618155636417214, Final Batch Loss: 0.0002697140153031796\n",
      "Epoch 1323, Loss: 0.000736509362468496, Final Batch Loss: 0.0001532245660200715\n",
      "Epoch 1324, Loss: 0.0009486263224971481, Final Batch Loss: 0.00010974524775519967\n",
      "Epoch 1325, Loss: 0.001159481587819755, Final Batch Loss: 0.0005283564678393304\n",
      "Epoch 1326, Loss: 0.004066675406647846, Final Batch Loss: 0.0002454322238918394\n",
      "Epoch 1327, Loss: 0.0004795532258867752, Final Batch Loss: 0.0002677639713510871\n",
      "Epoch 1328, Loss: 0.0007281457801582292, Final Batch Loss: 0.00038283178582787514\n",
      "Epoch 1329, Loss: 0.01542622629494872, Final Batch Loss: 0.00012414703087415546\n",
      "Epoch 1330, Loss: 0.0012400842970237136, Final Batch Loss: 0.0001304402103414759\n",
      "Epoch 1331, Loss: 0.005188562092371285, Final Batch Loss: 0.0021510247606784105\n",
      "Epoch 1332, Loss: 0.01774219170329161, Final Batch Loss: 0.00011716983863152564\n",
      "Epoch 1333, Loss: 0.002865548391127959, Final Batch Loss: 0.0017529802862554789\n",
      "Epoch 1334, Loss: 0.0035107389267068356, Final Batch Loss: 0.000277407409157604\n",
      "Epoch 1335, Loss: 0.0016787884524092078, Final Batch Loss: 0.0004023860674351454\n",
      "Epoch 1336, Loss: 0.0013817624567309394, Final Batch Loss: 0.0008286774973385036\n",
      "Epoch 1337, Loss: 0.005965196556644514, Final Batch Loss: 0.0004626270674634725\n",
      "Epoch 1338, Loss: 0.0385822233511135, Final Batch Loss: 0.024144237861037254\n",
      "Epoch 1339, Loss: 0.0033844300196506083, Final Batch Loss: 0.001471371972002089\n",
      "Epoch 1340, Loss: 0.006265965595957823, Final Batch Loss: 0.0023576475214213133\n",
      "Epoch 1341, Loss: 0.012762131118506659, Final Batch Loss: 0.012007830664515495\n",
      "Epoch 1342, Loss: 0.00463473005220294, Final Batch Loss: 0.002049301750957966\n",
      "Epoch 1343, Loss: 0.0018302845128346235, Final Batch Loss: 0.0009102598996832967\n",
      "Epoch 1344, Loss: 0.0023440394434146583, Final Batch Loss: 0.0004934719181619585\n",
      "Epoch 1345, Loss: 0.0018707695417106152, Final Batch Loss: 0.000877333281096071\n",
      "Epoch 1346, Loss: 0.002357102290261537, Final Batch Loss: 0.0011520750122144818\n",
      "Epoch 1347, Loss: 0.00782391568645835, Final Batch Loss: 0.0007362897740676999\n",
      "Epoch 1348, Loss: 0.005916190566495061, Final Batch Loss: 0.0042211380787193775\n",
      "Epoch 1349, Loss: 0.015054846706334502, Final Batch Loss: 0.00015103680198080838\n",
      "Epoch 1350, Loss: 0.02560533891664818, Final Batch Loss: 0.004102830309420824\n",
      "Epoch 1351, Loss: 0.010016493266448379, Final Batch Loss: 0.0025368889328092337\n",
      "Epoch 1352, Loss: 0.008312203746754676, Final Batch Loss: 7.582601392641664e-05\n",
      "Epoch 1353, Loss: 0.0014524512480420526, Final Batch Loss: 4.172726403339766e-05\n",
      "Epoch 1354, Loss: 0.04250410382519476, Final Batch Loss: 0.00048709483235143125\n",
      "Epoch 1355, Loss: 0.017287235968979076, Final Batch Loss: 0.00017548658070154488\n",
      "Epoch 1356, Loss: 0.002832777099683881, Final Batch Loss: 0.0005151283694431186\n",
      "Epoch 1357, Loss: 0.0006563353526871651, Final Batch Loss: 0.00014902355906087905\n",
      "Epoch 1358, Loss: 0.013535347621655092, Final Batch Loss: 0.007157018408179283\n",
      "Epoch 1359, Loss: 0.01734075936838053, Final Batch Loss: 0.00025550249847583473\n",
      "Epoch 1360, Loss: 0.010610276032821275, Final Batch Loss: 0.00038084349944256246\n",
      "Epoch 1361, Loss: 0.0015481861482840031, Final Batch Loss: 0.0003338103706482798\n",
      "Epoch 1362, Loss: 0.0016889730177354068, Final Batch Loss: 0.000614679476711899\n",
      "Epoch 1363, Loss: 0.006506796402391046, Final Batch Loss: 0.0006450034561567008\n",
      "Epoch 1364, Loss: 0.016777345881564543, Final Batch Loss: 0.015262833796441555\n",
      "Epoch 1365, Loss: 0.0038113713380880654, Final Batch Loss: 0.0009596715099178255\n",
      "Epoch 1366, Loss: 0.0022143016394693404, Final Batch Loss: 0.00036763129173778\n",
      "Epoch 1367, Loss: 0.005115727719385177, Final Batch Loss: 0.0003638010239228606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1368, Loss: 0.004726847109850496, Final Batch Loss: 0.0006826057215221226\n",
      "Epoch 1369, Loss: 0.0023353618453256786, Final Batch Loss: 0.0006279060617089272\n",
      "Epoch 1370, Loss: 0.017878814483992755, Final Batch Loss: 0.014700289815664291\n",
      "Epoch 1371, Loss: 0.005088652775157243, Final Batch Loss: 0.0030393400229513645\n",
      "Epoch 1372, Loss: 0.004807992314454168, Final Batch Loss: 0.0005315603339113295\n",
      "Epoch 1373, Loss: 0.0013076214236207306, Final Batch Loss: 0.0007059559575282037\n",
      "Epoch 1374, Loss: 0.0005696349253412336, Final Batch Loss: 0.00017310601833742112\n",
      "Epoch 1375, Loss: 0.0007624768259120174, Final Batch Loss: 8.024217822821811e-05\n",
      "Epoch 1376, Loss: 0.004144386446569115, Final Batch Loss: 0.00035236874828115106\n",
      "Epoch 1377, Loss: 0.023156692448537797, Final Batch Loss: 0.0001522541861049831\n",
      "Epoch 1378, Loss: 0.010411056311568245, Final Batch Loss: 0.0003976261068601161\n",
      "Epoch 1379, Loss: 0.005259161029243842, Final Batch Loss: 0.004080845508724451\n",
      "Epoch 1380, Loss: 0.002821814894559793, Final Batch Loss: 0.00019129882275592536\n",
      "Epoch 1381, Loss: 0.0016777883283793926, Final Batch Loss: 0.001390382763929665\n",
      "Epoch 1382, Loss: 0.004253358521964401, Final Batch Loss: 0.0026995395310223103\n",
      "Epoch 1383, Loss: 0.004666228735004552, Final Batch Loss: 0.00440113665536046\n",
      "Epoch 1384, Loss: 0.003648154146503657, Final Batch Loss: 0.002441378775984049\n",
      "Epoch 1385, Loss: 0.001310526829911396, Final Batch Loss: 0.0001122459361795336\n",
      "Epoch 1386, Loss: 0.003964900330174714, Final Batch Loss: 0.0004796270513907075\n",
      "Epoch 1387, Loss: 0.0011944133657380007, Final Batch Loss: 0.0002290101838298142\n",
      "Epoch 1388, Loss: 0.002191791543737054, Final Batch Loss: 0.00032909633591771126\n",
      "Epoch 1389, Loss: 0.0057750571286305785, Final Batch Loss: 0.00035174909862689674\n",
      "Epoch 1390, Loss: 0.0012504519472713582, Final Batch Loss: 0.0001100747540476732\n",
      "Epoch 1391, Loss: 0.0011665739184536505, Final Batch Loss: 5.872226392966695e-05\n",
      "Epoch 1392, Loss: 0.006641655694693327, Final Batch Loss: 0.00011741927301045507\n",
      "Epoch 1393, Loss: 0.0029270032537169755, Final Batch Loss: 0.0005337543552741408\n",
      "Epoch 1394, Loss: 0.005508644913788885, Final Batch Loss: 0.004153480753302574\n",
      "Epoch 1395, Loss: 0.0016582033567829058, Final Batch Loss: 6.473709072452039e-05\n",
      "Epoch 1396, Loss: 0.0016682823770679533, Final Batch Loss: 0.00017264668713323772\n",
      "Epoch 1397, Loss: 0.0015142249685595743, Final Batch Loss: 0.00020540252444334328\n",
      "Epoch 1398, Loss: 0.004013213387224823, Final Batch Loss: 0.0002820992667693645\n",
      "Epoch 1399, Loss: 0.0031836197449592873, Final Batch Loss: 0.0006900674197822809\n",
      "Epoch 1400, Loss: 0.0006641190120717511, Final Batch Loss: 0.00016814013360999525\n",
      "Epoch 1401, Loss: 0.0017479850794188678, Final Batch Loss: 8.264719508588314e-05\n",
      "Epoch 1402, Loss: 0.001142700610216707, Final Batch Loss: 0.0003145662194583565\n",
      "Epoch 1403, Loss: 0.0058855961106019095, Final Batch Loss: 0.005539366509765387\n",
      "Epoch 1404, Loss: 0.0024740195585764013, Final Batch Loss: 4.0293198253493756e-05\n",
      "Epoch 1405, Loss: 0.0035862675576936454, Final Batch Loss: 0.0023651004303246737\n",
      "Epoch 1406, Loss: 0.005287473148200661, Final Batch Loss: 0.0008921851986087859\n",
      "Epoch 1407, Loss: 0.010155554067750927, Final Batch Loss: 0.0001452705473639071\n",
      "Epoch 1408, Loss: 0.015392853194498457, Final Batch Loss: 0.00017067744920495898\n",
      "Epoch 1409, Loss: 0.0019141882366966456, Final Batch Loss: 0.0008577505359426141\n",
      "Epoch 1410, Loss: 0.006687099521514028, Final Batch Loss: 0.000475805951282382\n",
      "Epoch 1411, Loss: 0.007249357644468546, Final Batch Loss: 0.0047673676162958145\n",
      "Epoch 1412, Loss: 0.0066939155221916735, Final Batch Loss: 0.00032332545379176736\n",
      "Epoch 1413, Loss: 0.0021565705828834325, Final Batch Loss: 0.00016878002497833222\n",
      "Epoch 1414, Loss: 0.003259234596043825, Final Batch Loss: 0.00013781074085272849\n",
      "Epoch 1415, Loss: 0.0016261541459243745, Final Batch Loss: 0.000259060732787475\n",
      "Epoch 1416, Loss: 0.001771464361809194, Final Batch Loss: 0.000286527763819322\n",
      "Epoch 1417, Loss: 0.026868199565797113, Final Batch Loss: 0.00012664437235798687\n",
      "Epoch 1418, Loss: 0.0034152331500081345, Final Batch Loss: 0.0006296412320807576\n",
      "Epoch 1419, Loss: 0.003404412418603897, Final Batch Loss: 0.0026739132590591908\n",
      "Epoch 1420, Loss: 0.0023256531276274472, Final Batch Loss: 0.0012782589765265584\n",
      "Epoch 1421, Loss: 0.007077616959577426, Final Batch Loss: 0.006326638627797365\n",
      "Epoch 1422, Loss: 0.0021532689133891836, Final Batch Loss: 0.0017618645215407014\n",
      "Epoch 1423, Loss: 0.0008285628064186312, Final Batch Loss: 0.00011148663907079026\n",
      "Epoch 1424, Loss: 0.0024653431901242584, Final Batch Loss: 0.0015822449931874871\n",
      "Epoch 1425, Loss: 0.0009611791174393147, Final Batch Loss: 0.0006112559349276125\n",
      "Epoch 1426, Loss: 0.0011311195412417874, Final Batch Loss: 0.00012227024126332253\n",
      "Epoch 1427, Loss: 0.0005650185776175931, Final Batch Loss: 0.00023132482601795346\n",
      "Epoch 1428, Loss: 0.0019081674690824002, Final Batch Loss: 0.00038082050741650164\n",
      "Epoch 1429, Loss: 0.012410316150635481, Final Batch Loss: 0.011030538938939571\n",
      "Epoch 1430, Loss: 0.0020382086659083143, Final Batch Loss: 0.00018373092461843044\n",
      "Epoch 1431, Loss: 0.0007962743984535336, Final Batch Loss: 3.6003446439281106e-05\n",
      "Epoch 1432, Loss: 0.001190376133308746, Final Batch Loss: 0.0003988464595749974\n",
      "Epoch 1433, Loss: 0.004974234179826453, Final Batch Loss: 0.003741306019946933\n",
      "Epoch 1434, Loss: 0.013182754599256441, Final Batch Loss: 0.0003031606029253453\n",
      "Epoch 1435, Loss: 0.008211151929572225, Final Batch Loss: 0.006604456342756748\n",
      "Epoch 1436, Loss: 0.03161857546365354, Final Batch Loss: 0.0002230808458989486\n",
      "Epoch 1437, Loss: 0.0024001564597710967, Final Batch Loss: 0.0008667283109389246\n",
      "Epoch 1438, Loss: 0.014581968251150101, Final Batch Loss: 0.012368363328278065\n",
      "Epoch 1439, Loss: 0.0015363219717983156, Final Batch Loss: 0.0003482890024315566\n",
      "Epoch 1440, Loss: 0.008188845531549305, Final Batch Loss: 0.006891158409416676\n",
      "Epoch 1441, Loss: 0.0012579478789120913, Final Batch Loss: 0.00028672843473032117\n",
      "Epoch 1442, Loss: 0.0016111380537040532, Final Batch Loss: 0.00024189456598833203\n",
      "Epoch 1443, Loss: 0.006966932051000185, Final Batch Loss: 0.006531205028295517\n",
      "Epoch 1444, Loss: 0.001168611372122541, Final Batch Loss: 0.0005389199359342456\n",
      "Epoch 1445, Loss: 0.03939152808743529, Final Batch Loss: 0.01857256516814232\n",
      "Epoch 1446, Loss: 0.002231821999885142, Final Batch Loss: 0.00013432494597509503\n",
      "Epoch 1447, Loss: 0.0038991622568573803, Final Batch Loss: 0.0026534884236752987\n",
      "Epoch 1448, Loss: 0.010333572165109217, Final Batch Loss: 0.008362243883311749\n",
      "Epoch 1449, Loss: 0.006317671592114493, Final Batch Loss: 0.00040526463999412954\n",
      "Epoch 1450, Loss: 0.0016840901516843587, Final Batch Loss: 0.00039752284646965563\n",
      "Epoch 1451, Loss: 0.01110867339593824, Final Batch Loss: 0.00014360206841956824\n",
      "Epoch 1452, Loss: 0.004499414673773572, Final Batch Loss: 0.001429355819709599\n",
      "Epoch 1453, Loss: 0.014199920056853443, Final Batch Loss: 0.0005900722462683916\n",
      "Epoch 1454, Loss: 0.001953741528268438, Final Batch Loss: 0.00011136379180243239\n",
      "Epoch 1455, Loss: 0.004299421940231696, Final Batch Loss: 0.00020974970539100468\n",
      "Epoch 1456, Loss: 0.0012274344771867618, Final Batch Loss: 0.0007379075395874679\n",
      "Epoch 1457, Loss: 0.0021316653583198786, Final Batch Loss: 0.0007267050095833838\n",
      "Epoch 1458, Loss: 0.0018233413866255432, Final Batch Loss: 0.0012897924752905965\n",
      "Epoch 1459, Loss: 0.0012541307369247079, Final Batch Loss: 0.00017493843915872276\n",
      "Epoch 1460, Loss: 0.004913895390927792, Final Batch Loss: 0.0036669725086539984\n",
      "Epoch 1461, Loss: 0.0021600551262963563, Final Batch Loss: 0.001504685147665441\n",
      "Epoch 1462, Loss: 0.00350986878038384, Final Batch Loss: 0.002784788142889738\n",
      "Epoch 1463, Loss: 0.0025566444091964513, Final Batch Loss: 0.0005859117954969406\n",
      "Epoch 1464, Loss: 0.003341006704431493, Final Batch Loss: 0.0010000357870012522\n",
      "Epoch 1465, Loss: 0.0021579580061370507, Final Batch Loss: 8.136210090015084e-05\n",
      "Epoch 1466, Loss: 0.007712490274570882, Final Batch Loss: 0.0023645267356187105\n",
      "Epoch 1467, Loss: 0.0006396972894435748, Final Batch Loss: 0.0002713747089728713\n",
      "Epoch 1468, Loss: 0.0031092230055946857, Final Batch Loss: 0.00027408040477894247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1469, Loss: 0.000628972498816438, Final Batch Loss: 0.00026610473287291825\n",
      "Epoch 1470, Loss: 0.0023219644499477, Final Batch Loss: 0.0017644561594352126\n",
      "Epoch 1471, Loss: 0.0010322191919840407, Final Batch Loss: 3.2101099350256845e-05\n",
      "Epoch 1472, Loss: 0.0011007653665728867, Final Batch Loss: 0.00019126833649352193\n",
      "Epoch 1473, Loss: 0.0010176150099141523, Final Batch Loss: 0.0004730341024696827\n",
      "Epoch 1474, Loss: 0.007798974329489283, Final Batch Loss: 0.0013577527133747935\n",
      "Epoch 1475, Loss: 0.0007904521335149184, Final Batch Loss: 0.00012318420340307057\n",
      "Epoch 1476, Loss: 0.06482144707115367, Final Batch Loss: 0.06106729432940483\n",
      "Epoch 1477, Loss: 0.0009235433972207829, Final Batch Loss: 0.00048739215708337724\n",
      "Epoch 1478, Loss: 0.008296472136862576, Final Batch Loss: 0.002894901903346181\n",
      "Epoch 1479, Loss: 0.0012442640218068846, Final Batch Loss: 6.579273758688942e-05\n",
      "Epoch 1480, Loss: 0.0006710604866384529, Final Batch Loss: 0.0001917524787131697\n",
      "Epoch 1481, Loss: 0.008430674119153991, Final Batch Loss: 0.00026686288765631616\n",
      "Epoch 1482, Loss: 0.0032658392447046936, Final Batch Loss: 0.0017067171866074204\n",
      "Epoch 1483, Loss: 0.0070457387482747436, Final Batch Loss: 0.004967637825757265\n",
      "Epoch 1484, Loss: 0.001711461241939105, Final Batch Loss: 0.0012858777772635221\n",
      "Epoch 1485, Loss: 0.03967618232127279, Final Batch Loss: 0.038830630481243134\n",
      "Epoch 1486, Loss: 0.003081739618210122, Final Batch Loss: 0.00022143209935165942\n",
      "Epoch 1487, Loss: 0.0011066110091633163, Final Batch Loss: 0.00011749302939279005\n",
      "Epoch 1488, Loss: 0.0014829263964202255, Final Batch Loss: 0.000209822814213112\n",
      "Epoch 1489, Loss: 0.004258456930983812, Final Batch Loss: 0.002744498895481229\n",
      "Epoch 1490, Loss: 0.0022552091686520725, Final Batch Loss: 0.00031581593793816864\n",
      "Epoch 1491, Loss: 0.026225287932902575, Final Batch Loss: 0.00215759314596653\n",
      "Epoch 1492, Loss: 0.0020008593855891377, Final Batch Loss: 0.0012786522274836898\n",
      "Epoch 1493, Loss: 0.0021458437404362485, Final Batch Loss: 0.0005939041147939861\n",
      "Epoch 1494, Loss: 0.07052130825468339, Final Batch Loss: 0.06931290030479431\n",
      "Epoch 1495, Loss: 0.009475696715526283, Final Batch Loss: 0.00124811427667737\n",
      "Epoch 1496, Loss: 0.0134898882752168, Final Batch Loss: 0.012515195645391941\n",
      "Epoch 1497, Loss: 0.00687403701886069, Final Batch Loss: 8.832391176838428e-05\n",
      "Epoch 1498, Loss: 0.013228243915364146, Final Batch Loss: 0.00262056034989655\n",
      "Epoch 1499, Loss: 0.018641604983713478, Final Batch Loss: 0.0006258749053813517\n",
      "Epoch 1500, Loss: 0.010135921693290584, Final Batch Loss: 0.0001589549210621044\n",
      "Epoch 1501, Loss: 0.05734539586410392, Final Batch Loss: 0.055397577583789825\n",
      "Epoch 1502, Loss: 0.004608232586178929, Final Batch Loss: 0.0009452122030779719\n",
      "Epoch 1503, Loss: 0.0017854220495792106, Final Batch Loss: 0.0011771200224757195\n",
      "Epoch 1504, Loss: 0.02108370972564444, Final Batch Loss: 0.019861044362187386\n",
      "Epoch 1505, Loss: 0.0020923675037920475, Final Batch Loss: 0.0003044113691430539\n",
      "Epoch 1506, Loss: 0.005240751546807587, Final Batch Loss: 0.003058568574488163\n",
      "Epoch 1507, Loss: 0.009338609204860404, Final Batch Loss: 0.00030524100293405354\n",
      "Epoch 1508, Loss: 0.004785934230312705, Final Batch Loss: 0.003112821839749813\n",
      "Epoch 1509, Loss: 0.005039549170760438, Final Batch Loss: 0.000388423417462036\n",
      "Epoch 1510, Loss: 0.003907529127900489, Final Batch Loss: 0.0005623685428872705\n",
      "Epoch 1511, Loss: 0.0017942040867637843, Final Batch Loss: 0.00018124966300092638\n",
      "Epoch 1512, Loss: 0.0010324806644348428, Final Batch Loss: 0.0003845705941785127\n",
      "Epoch 1513, Loss: 0.013675181449798401, Final Batch Loss: 0.00011299389734631404\n",
      "Epoch 1514, Loss: 0.042445594852324575, Final Batch Loss: 0.04014970734715462\n",
      "Epoch 1515, Loss: 0.0018886536709032953, Final Batch Loss: 0.0013080841163173318\n",
      "Epoch 1516, Loss: 0.002192673389799893, Final Batch Loss: 0.0011544745648279786\n",
      "Epoch 1517, Loss: 0.057000492728548124, Final Batch Loss: 0.049211207777261734\n",
      "Epoch 1518, Loss: 0.036340750026283786, Final Batch Loss: 0.03443813696503639\n",
      "Epoch 1519, Loss: 0.0017452611937187612, Final Batch Loss: 0.0004935927572660148\n",
      "Epoch 1520, Loss: 0.0017547766910865903, Final Batch Loss: 0.00024088853388093412\n",
      "Epoch 1521, Loss: 0.014039999397937208, Final Batch Loss: 0.0016525074606761336\n",
      "Epoch 1522, Loss: 0.0015544717607554048, Final Batch Loss: 0.0005795207689516246\n",
      "Epoch 1523, Loss: 0.0014218153519323096, Final Batch Loss: 0.00010084559471579269\n",
      "Epoch 1524, Loss: 0.001546430285088718, Final Batch Loss: 0.00047572844778187573\n",
      "Epoch 1525, Loss: 0.006030109594576061, Final Batch Loss: 0.0005718733882531524\n",
      "Epoch 1526, Loss: 0.005186984257306904, Final Batch Loss: 0.0006501561147160828\n",
      "Epoch 1527, Loss: 0.028079231444280595, Final Batch Loss: 0.0010519020725041628\n",
      "Epoch 1528, Loss: 0.015845372108742595, Final Batch Loss: 0.0020156654063612223\n",
      "Epoch 1529, Loss: 0.00197041236970108, Final Batch Loss: 0.001100177294574678\n",
      "Epoch 1530, Loss: 0.010136310069356114, Final Batch Loss: 0.00810230616480112\n",
      "Epoch 1531, Loss: 0.0024589446984464303, Final Batch Loss: 0.0016235609073191881\n",
      "Epoch 1532, Loss: 0.0017696060240268707, Final Batch Loss: 0.0002812109887599945\n",
      "Epoch 1533, Loss: 0.0013077594921924174, Final Batch Loss: 0.000148362189065665\n",
      "Epoch 1534, Loss: 0.03135725307947723, Final Batch Loss: 0.00011593818635446951\n",
      "Epoch 1535, Loss: 0.002202245988883078, Final Batch Loss: 0.00043827714398503304\n",
      "Epoch 1536, Loss: 0.002106812287820503, Final Batch Loss: 0.00040878940490074456\n",
      "Epoch 1537, Loss: 0.0075808830733876675, Final Batch Loss: 0.004130836110562086\n",
      "Epoch 1538, Loss: 0.002388404624070972, Final Batch Loss: 0.0010821542236953974\n",
      "Epoch 1539, Loss: 0.0022588489737245254, Final Batch Loss: 0.0015077796997502446\n",
      "Epoch 1540, Loss: 0.004872558929491788, Final Batch Loss: 0.0003934722044505179\n",
      "Epoch 1541, Loss: 0.0012140133185312152, Final Batch Loss: 0.00030414373031817377\n",
      "Epoch 1542, Loss: 0.04226380190812051, Final Batch Loss: 0.03598576784133911\n",
      "Epoch 1543, Loss: 0.0017023683176375926, Final Batch Loss: 0.0003356620145495981\n",
      "Epoch 1544, Loss: 0.0015247575647663325, Final Batch Loss: 0.0006894615944474936\n",
      "Epoch 1545, Loss: 0.005117019871249795, Final Batch Loss: 0.00022219825768843293\n",
      "Epoch 1546, Loss: 0.0019480829942040145, Final Batch Loss: 0.000639919308014214\n",
      "Epoch 1547, Loss: 0.0016464310319861397, Final Batch Loss: 0.00015797953528817743\n",
      "Epoch 1548, Loss: 0.004049480805406347, Final Batch Loss: 0.00024537890567444265\n",
      "Epoch 1549, Loss: 0.002146881219232455, Final Batch Loss: 0.00020708327065221965\n",
      "Epoch 1550, Loss: 0.00449530070181936, Final Batch Loss: 0.000523631926625967\n",
      "Epoch 1551, Loss: 0.001348214573226869, Final Batch Loss: 0.0002561190922278911\n",
      "Epoch 1552, Loss: 0.0039244221115950495, Final Batch Loss: 0.002310910727828741\n",
      "Epoch 1553, Loss: 0.010050675482489169, Final Batch Loss: 0.0024370395112782717\n",
      "Epoch 1554, Loss: 0.0014092017809161916, Final Batch Loss: 0.00013542776287067682\n",
      "Epoch 1555, Loss: 0.0010823126940522343, Final Batch Loss: 0.00016966028488241136\n",
      "Epoch 1556, Loss: 0.0010883787253987975, Final Batch Loss: 8.3328784967307e-05\n",
      "Epoch 1557, Loss: 0.008366716196178459, Final Batch Loss: 0.007762374822050333\n",
      "Epoch 1558, Loss: 0.0012393099023029208, Final Batch Loss: 0.0003743193519767374\n",
      "Epoch 1559, Loss: 0.02236879343399778, Final Batch Loss: 0.0002714075963012874\n",
      "Epoch 1560, Loss: 0.005289567925501615, Final Batch Loss: 0.0005609181826002896\n",
      "Epoch 1561, Loss: 0.0020825044630328193, Final Batch Loss: 0.00032324757194146514\n",
      "Epoch 1562, Loss: 0.003161546104820445, Final Batch Loss: 0.0024066329933702946\n",
      "Epoch 1563, Loss: 0.004460413125343621, Final Batch Loss: 0.0007861937629058957\n",
      "Epoch 1564, Loss: 0.004215214095893316, Final Batch Loss: 0.00016936594329308718\n",
      "Epoch 1565, Loss: 0.005293951602652669, Final Batch Loss: 0.0025907610543072224\n",
      "Epoch 1566, Loss: 0.0037174057797528803, Final Batch Loss: 0.002070581540465355\n",
      "Epoch 1567, Loss: 0.0018361815018579364, Final Batch Loss: 0.0001470642746426165\n",
      "Epoch 1568, Loss: 0.0020340504415798932, Final Batch Loss: 0.0006137800519354641\n",
      "Epoch 1569, Loss: 0.0015922737147775479, Final Batch Loss: 0.0001126908537116833\n",
      "Epoch 1570, Loss: 0.004843119531869888, Final Batch Loss: 0.0015510781668126583\n",
      "Epoch 1571, Loss: 0.0011218003128306009, Final Batch Loss: 8.850228186929598e-05\n",
      "Epoch 1572, Loss: 0.015008872287580743, Final Batch Loss: 0.00026199486455880105\n",
      "Epoch 1573, Loss: 0.0014911475955159403, Final Batch Loss: 0.00013870379189029336\n",
      "Epoch 1574, Loss: 0.006154906470328569, Final Batch Loss: 0.003700864501297474\n",
      "Epoch 1575, Loss: 0.01899975468404591, Final Batch Loss: 0.002437726827338338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1576, Loss: 0.007322971345274709, Final Batch Loss: 0.005693580489605665\n",
      "Epoch 1577, Loss: 0.001093313068849966, Final Batch Loss: 0.00016986113041639328\n",
      "Epoch 1578, Loss: 0.002209074707934633, Final Batch Loss: 0.0002906626323238015\n",
      "Epoch 1579, Loss: 0.0018884090968640521, Final Batch Loss: 0.0002104535378748551\n",
      "Epoch 1580, Loss: 0.00538579893327551, Final Batch Loss: 0.00010543782991589978\n",
      "Epoch 1581, Loss: 0.005213764845393598, Final Batch Loss: 0.001360979862511158\n",
      "Epoch 1582, Loss: 0.008002232003491372, Final Batch Loss: 0.00611981563270092\n",
      "Epoch 1583, Loss: 0.0011285218934062868, Final Batch Loss: 0.00025391290546394885\n",
      "Epoch 1584, Loss: 0.0069793673465028405, Final Batch Loss: 0.005437107756733894\n",
      "Epoch 1585, Loss: 0.0006139302204246633, Final Batch Loss: 0.00022716066450811923\n",
      "Epoch 1586, Loss: 0.00532516889506951, Final Batch Loss: 0.0004944288521073759\n",
      "Epoch 1587, Loss: 0.0013830225798301399, Final Batch Loss: 0.00037598947528749704\n",
      "Epoch 1588, Loss: 0.0018138780869776383, Final Batch Loss: 0.00037028605584055185\n",
      "Epoch 1589, Loss: 0.002793502528220415, Final Batch Loss: 0.0007417153683491051\n",
      "Epoch 1590, Loss: 0.012522691584308632, Final Batch Loss: 0.002396957017481327\n",
      "Epoch 1591, Loss: 0.008789150655502453, Final Batch Loss: 0.00012970951502211392\n",
      "Epoch 1592, Loss: 0.02926181688235374, Final Batch Loss: 0.00202349410392344\n",
      "Epoch 1593, Loss: 0.0015019078564364463, Final Batch Loss: 0.0003151573764625937\n",
      "Epoch 1594, Loss: 0.0028044206264894456, Final Batch Loss: 0.0011652110842987895\n",
      "Epoch 1595, Loss: 0.002743245946476236, Final Batch Loss: 0.0022717188112437725\n",
      "Epoch 1596, Loss: 0.002807485856465064, Final Batch Loss: 0.001584694953635335\n",
      "Epoch 1597, Loss: 0.0017979801050387323, Final Batch Loss: 0.0011814930476248264\n",
      "Epoch 1598, Loss: 0.0011505298461997882, Final Batch Loss: 0.0004297252162359655\n",
      "Epoch 1599, Loss: 0.002036184858297929, Final Batch Loss: 0.0006137688178569078\n",
      "Epoch 1600, Loss: 0.004502734373090789, Final Batch Loss: 0.0008956211386248469\n",
      "Epoch 1601, Loss: 0.027621808825642802, Final Batch Loss: 0.02674112468957901\n",
      "Epoch 1602, Loss: 0.001921058661537245, Final Batch Loss: 0.0006744607235305011\n",
      "Epoch 1603, Loss: 0.0011970911946264096, Final Batch Loss: 0.00018833497597370297\n",
      "Epoch 1604, Loss: 0.0019709087209776044, Final Batch Loss: 0.00013999195653013885\n",
      "Epoch 1605, Loss: 0.008276952692540362, Final Batch Loss: 0.007816282100975513\n",
      "Epoch 1606, Loss: 0.002075626573059708, Final Batch Loss: 0.0004307679191697389\n",
      "Epoch 1607, Loss: 0.00189109705388546, Final Batch Loss: 0.001277807867154479\n",
      "Epoch 1608, Loss: 0.0020929417805746198, Final Batch Loss: 0.0011117078829556704\n",
      "Epoch 1609, Loss: 0.003594195586629212, Final Batch Loss: 4.208250902593136e-05\n",
      "Epoch 1610, Loss: 0.00578723888611421, Final Batch Loss: 0.0012369150063022971\n",
      "Epoch 1611, Loss: 0.009626106650102884, Final Batch Loss: 0.00048620166489854455\n",
      "Epoch 1612, Loss: 0.0014224316400941461, Final Batch Loss: 0.00040209852159023285\n",
      "Epoch 1613, Loss: 0.000594855286180973, Final Batch Loss: 9.599156328476965e-05\n",
      "Epoch 1614, Loss: 0.002195411827415228, Final Batch Loss: 0.0002195450506405905\n",
      "Epoch 1615, Loss: 0.003243577724788338, Final Batch Loss: 0.0017685283673927188\n",
      "Epoch 1616, Loss: 0.0025167737039737403, Final Batch Loss: 0.0004434372531250119\n",
      "Epoch 1617, Loss: 0.006789305887650698, Final Batch Loss: 0.005987437907606363\n",
      "Epoch 1618, Loss: 0.0013030683185206726, Final Batch Loss: 0.00012447054905351251\n",
      "Epoch 1619, Loss: 0.008663259366585407, Final Batch Loss: 0.00011452651961008087\n",
      "Epoch 1620, Loss: 0.011952884204220027, Final Batch Loss: 0.009354389272630215\n",
      "Epoch 1621, Loss: 0.0010265379096381366, Final Batch Loss: 0.00038647017208859324\n",
      "Epoch 1622, Loss: 0.002980591234518215, Final Batch Loss: 0.001356431283056736\n",
      "Epoch 1623, Loss: 0.007234335931570968, Final Batch Loss: 4.8084471927722916e-05\n",
      "Epoch 1624, Loss: 0.0010622570043778978, Final Batch Loss: 6.767367449356243e-05\n",
      "Epoch 1625, Loss: 0.006344669876853004, Final Batch Loss: 0.005610206164419651\n",
      "Epoch 1626, Loss: 0.0013836144571541809, Final Batch Loss: 0.00013162550749257207\n",
      "Epoch 1627, Loss: 0.0014005823759362102, Final Batch Loss: 0.00028142015798948705\n",
      "Epoch 1628, Loss: 0.0005462837689265143, Final Batch Loss: 0.00014466483844444156\n",
      "Epoch 1629, Loss: 0.011731506878277287, Final Batch Loss: 0.009631638415157795\n",
      "Epoch 1630, Loss: 0.00842135231141583, Final Batch Loss: 0.0076087056659162045\n",
      "Epoch 1631, Loss: 0.0005059265895397402, Final Batch Loss: 0.0001397819141857326\n",
      "Epoch 1632, Loss: 0.002385713334660977, Final Batch Loss: 0.0007266697939485312\n",
      "Epoch 1633, Loss: 0.0032318418379873037, Final Batch Loss: 0.00045591930393129587\n",
      "Epoch 1634, Loss: 0.0013449291873257607, Final Batch Loss: 0.0007500345818698406\n",
      "Epoch 1635, Loss: 0.0008449411834590137, Final Batch Loss: 4.5548047637566924e-05\n",
      "Epoch 1636, Loss: 0.005407901626313105, Final Batch Loss: 0.00012877481640316546\n",
      "Epoch 1637, Loss: 0.00784316600766033, Final Batch Loss: 0.0009791523916646838\n",
      "Epoch 1638, Loss: 0.007351074047619477, Final Batch Loss: 0.0008720112964510918\n",
      "Epoch 1639, Loss: 0.0011706686454999726, Final Batch Loss: 3.7107831303728744e-05\n",
      "Epoch 1640, Loss: 0.0012158803583588451, Final Batch Loss: 0.00023027913994155824\n",
      "Epoch 1641, Loss: 0.004693118724389933, Final Batch Loss: 7.55783257773146e-05\n",
      "Epoch 1642, Loss: 0.0007873120266594924, Final Batch Loss: 0.000582733191549778\n",
      "Epoch 1643, Loss: 0.0010679649276426062, Final Batch Loss: 0.00026443065144121647\n",
      "Epoch 1644, Loss: 0.010403888780274428, Final Batch Loss: 0.0002270292752655223\n",
      "Epoch 1645, Loss: 0.003888858773279935, Final Batch Loss: 0.0018740223022177815\n",
      "Epoch 1646, Loss: 0.00048123156375368126, Final Batch Loss: 4.962966704624705e-05\n",
      "Epoch 1647, Loss: 0.02025331323966384, Final Batch Loss: 0.0002971966750919819\n",
      "Epoch 1648, Loss: 0.0010452189453644678, Final Batch Loss: 0.0003397762484382838\n",
      "Epoch 1649, Loss: 0.0007597834337502718, Final Batch Loss: 0.00019013159908354282\n",
      "Epoch 1650, Loss: 0.0009164598886854947, Final Batch Loss: 0.000291482952889055\n",
      "Epoch 1651, Loss: 0.029671659125597216, Final Batch Loss: 7.083396485541016e-05\n",
      "Epoch 1652, Loss: 0.0017927518929354846, Final Batch Loss: 0.0004939379286952317\n",
      "Epoch 1653, Loss: 0.00038524068077094853, Final Batch Loss: 0.00010365395428379998\n",
      "Epoch 1654, Loss: 0.008103082305751741, Final Batch Loss: 0.0003017603885382414\n",
      "Epoch 1655, Loss: 0.0019192463078070432, Final Batch Loss: 0.0007809051312506199\n",
      "Epoch 1656, Loss: 0.003458807186689228, Final Batch Loss: 0.0003229719295632094\n",
      "Epoch 1657, Loss: 0.0013408720988081768, Final Batch Loss: 0.00024766448768787086\n",
      "Epoch 1658, Loss: 0.0009336848015664145, Final Batch Loss: 0.00012757530203089118\n",
      "Epoch 1659, Loss: 0.001921361283166334, Final Batch Loss: 0.0003083316842094064\n",
      "Epoch 1660, Loss: 0.001095136976800859, Final Batch Loss: 0.00044187044841237366\n",
      "Epoch 1661, Loss: 0.0018874037778005004, Final Batch Loss: 0.0007862004567869008\n",
      "Epoch 1662, Loss: 0.00039732073855702765, Final Batch Loss: 0.0002563393209129572\n",
      "Epoch 1663, Loss: 0.0012640698769246228, Final Batch Loss: 9.078923176275566e-05\n",
      "Epoch 1664, Loss: 0.0020542405545711517, Final Batch Loss: 0.0003959009191021323\n",
      "Epoch 1665, Loss: 0.0025662840344011784, Final Batch Loss: 0.00104078883305192\n",
      "Epoch 1666, Loss: 0.0031874103588052094, Final Batch Loss: 0.0003440078580752015\n",
      "Epoch 1667, Loss: 0.005314437847118825, Final Batch Loss: 0.004669219255447388\n",
      "Epoch 1668, Loss: 0.0014557221438735723, Final Batch Loss: 0.0002564975875429809\n",
      "Epoch 1669, Loss: 0.0024792382901068777, Final Batch Loss: 0.0020628494676202536\n",
      "Epoch 1670, Loss: 0.0014678303414257243, Final Batch Loss: 0.00032236092374660075\n",
      "Epoch 1671, Loss: 0.02963210642337799, Final Batch Loss: 0.02483118139207363\n",
      "Epoch 1672, Loss: 0.0030902609578333795, Final Batch Loss: 0.001039551687426865\n",
      "Epoch 1673, Loss: 0.0011985903838649392, Final Batch Loss: 0.00012638617772608995\n",
      "Epoch 1674, Loss: 0.0020398160195327364, Final Batch Loss: 0.0014022792456671596\n",
      "Epoch 1675, Loss: 0.001216500750160776, Final Batch Loss: 0.0006357478559948504\n",
      "Epoch 1676, Loss: 0.04612924827961251, Final Batch Loss: 0.0006804343429394066\n",
      "Epoch 1677, Loss: 0.007934844834380783, Final Batch Loss: 0.002878214931115508\n",
      "Epoch 1678, Loss: 0.002221484020992648, Final Batch Loss: 7.47836529626511e-05\n",
      "Epoch 1679, Loss: 0.005757738021202385, Final Batch Loss: 0.0009549201349727809\n",
      "Epoch 1680, Loss: 0.003221021397621371, Final Batch Loss: 0.002501095412299037\n",
      "Epoch 1681, Loss: 0.0008854670450091362, Final Batch Loss: 0.00024378483067266643\n",
      "Epoch 1682, Loss: 0.001416185921698343, Final Batch Loss: 0.0007963529787957668\n",
      "Epoch 1683, Loss: 0.00350400127354078, Final Batch Loss: 0.0004544733965303749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1684, Loss: 0.005834736977703869, Final Batch Loss: 0.0017368259141221642\n",
      "Epoch 1685, Loss: 0.005032658373238519, Final Batch Loss: 0.0037444494664669037\n",
      "Epoch 1686, Loss: 0.002911872390541248, Final Batch Loss: 0.00219396292231977\n",
      "Epoch 1687, Loss: 0.0012597515305969864, Final Batch Loss: 0.0009606060339137912\n",
      "Epoch 1688, Loss: 0.0019845422721118666, Final Batch Loss: 0.00023129826877266169\n",
      "Epoch 1689, Loss: 0.002706398598093074, Final Batch Loss: 0.0024226370733231306\n",
      "Epoch 1690, Loss: 0.0005166587070561945, Final Batch Loss: 5.699334724340588e-05\n",
      "Epoch 1691, Loss: 0.0032913813774939626, Final Batch Loss: 0.0003099144378211349\n",
      "Epoch 1692, Loss: 0.0007043396035442129, Final Batch Loss: 0.0001388978707836941\n",
      "Epoch 1693, Loss: 0.0008389228314626962, Final Batch Loss: 0.00014089126489125192\n",
      "Epoch 1694, Loss: 0.009171519486699253, Final Batch Loss: 0.0030718946363776922\n",
      "Epoch 1695, Loss: 0.0009764531423570588, Final Batch Loss: 3.258208744227886e-05\n",
      "Epoch 1696, Loss: 0.019992501358501613, Final Batch Loss: 0.0056424010545015335\n",
      "Epoch 1697, Loss: 0.0007890713823144324, Final Batch Loss: 6.788259634049609e-05\n",
      "Epoch 1698, Loss: 0.0009511565003776923, Final Batch Loss: 0.0003934054693672806\n",
      "Epoch 1699, Loss: 0.001809597626561299, Final Batch Loss: 0.0012736259959638119\n",
      "Epoch 1700, Loss: 0.0017160224815597758, Final Batch Loss: 0.0009153661667369306\n",
      "Epoch 1701, Loss: 0.005822040227940306, Final Batch Loss: 0.00017270990065298975\n",
      "Epoch 1702, Loss: 0.01296573068248108, Final Batch Loss: 0.012494671158492565\n",
      "Epoch 1703, Loss: 0.001639447917114012, Final Batch Loss: 0.0010845530778169632\n",
      "Epoch 1704, Loss: 0.0008233731059590355, Final Batch Loss: 7.57132947910577e-05\n",
      "Epoch 1705, Loss: 0.0002277195526403375, Final Batch Loss: 6.399324774974957e-05\n",
      "Epoch 1706, Loss: 0.0005245591019047424, Final Batch Loss: 0.00014756839664187282\n",
      "Epoch 1707, Loss: 0.01588640475529246, Final Batch Loss: 0.0001464013330405578\n",
      "Epoch 1708, Loss: 0.001704412221442908, Final Batch Loss: 0.0004944026586599648\n",
      "Epoch 1709, Loss: 0.042504033248405904, Final Batch Loss: 0.040251798927783966\n",
      "Epoch 1710, Loss: 0.001033399603329599, Final Batch Loss: 0.0002700300537981093\n",
      "Epoch 1711, Loss: 0.002437017232296057, Final Batch Loss: 0.002114543691277504\n",
      "Epoch 1712, Loss: 0.0011476357612991706, Final Batch Loss: 0.00019042441272176802\n",
      "Epoch 1713, Loss: 0.0046356966777238995, Final Batch Loss: 0.0002388713473919779\n",
      "Epoch 1714, Loss: 0.0028851829265477136, Final Batch Loss: 0.002252923557534814\n",
      "Epoch 1715, Loss: 0.007437434571329504, Final Batch Loss: 0.006071567069739103\n",
      "Epoch 1716, Loss: 0.018128861207515, Final Batch Loss: 0.00047398300375789404\n",
      "Epoch 1717, Loss: 0.0009502500251983292, Final Batch Loss: 0.0002468713209964335\n",
      "Epoch 1718, Loss: 0.003712444973643869, Final Batch Loss: 0.00029576392262242734\n",
      "Epoch 1719, Loss: 0.007104926044121385, Final Batch Loss: 0.004651801194995642\n",
      "Epoch 1720, Loss: 0.006869192933663726, Final Batch Loss: 0.0008147967746481299\n",
      "Epoch 1721, Loss: 0.0006632016520597972, Final Batch Loss: 8.856577187543735e-05\n",
      "Epoch 1722, Loss: 0.0014351466379594058, Final Batch Loss: 0.000563354988116771\n",
      "Epoch 1723, Loss: 0.002726789432927035, Final Batch Loss: 0.0018674538005143404\n",
      "Epoch 1724, Loss: 0.005277218791889027, Final Batch Loss: 0.0012046432821080089\n",
      "Epoch 1725, Loss: 0.008985853266494814, Final Batch Loss: 0.008762984536588192\n",
      "Epoch 1726, Loss: 0.01910362089984119, Final Batch Loss: 0.01442115567624569\n",
      "Epoch 1727, Loss: 0.0027795014902949333, Final Batch Loss: 0.001343800569884479\n",
      "Epoch 1728, Loss: 0.007331246277317405, Final Batch Loss: 0.00015435132081620395\n",
      "Epoch 1729, Loss: 0.00667516840621829, Final Batch Loss: 0.0022007750812917948\n",
      "Epoch 1730, Loss: 0.013361124438233674, Final Batch Loss: 0.009912282228469849\n",
      "Epoch 1731, Loss: 0.017917003540787846, Final Batch Loss: 0.0011337825562804937\n",
      "Epoch 1732, Loss: 0.0010757364798337221, Final Batch Loss: 0.0008444954291917384\n",
      "Epoch 1733, Loss: 0.004306412884034216, Final Batch Loss: 0.00327413366176188\n",
      "Epoch 1734, Loss: 0.0006214285749592818, Final Batch Loss: 0.00011188450298504904\n",
      "Epoch 1735, Loss: 0.000919606420211494, Final Batch Loss: 0.0004541893722489476\n",
      "Epoch 1736, Loss: 0.00541028383304365, Final Batch Loss: 0.00029717147117480636\n",
      "Epoch 1737, Loss: 0.0077983302471693605, Final Batch Loss: 0.0003535495779942721\n",
      "Epoch 1738, Loss: 0.0008656817954033613, Final Batch Loss: 0.0004494476306717843\n",
      "Epoch 1739, Loss: 0.0016186264983844012, Final Batch Loss: 0.0004376106371637434\n",
      "Epoch 1740, Loss: 0.0019060242630075663, Final Batch Loss: 0.00020685215713456273\n",
      "Epoch 1741, Loss: 0.001369703037198633, Final Batch Loss: 0.0004986331914551556\n",
      "Epoch 1742, Loss: 0.0020496421711868607, Final Batch Loss: 5.285505176289007e-05\n",
      "Epoch 1743, Loss: 0.0012616999738384038, Final Batch Loss: 8.652123506180942e-05\n",
      "Epoch 1744, Loss: 0.0005176543127163313, Final Batch Loss: 6.803000724175945e-05\n",
      "Epoch 1745, Loss: 0.002559782107709907, Final Batch Loss: 0.0017339964397251606\n",
      "Epoch 1746, Loss: 0.00206558546051383, Final Batch Loss: 0.0013586546992883086\n",
      "Epoch 1747, Loss: 0.001275036862352863, Final Batch Loss: 0.00025177240604534745\n",
      "Epoch 1748, Loss: 0.0010186546496697702, Final Batch Loss: 0.000678909127600491\n",
      "Epoch 1749, Loss: 0.009250298717233818, Final Batch Loss: 0.00011728630488505587\n",
      "Epoch 1750, Loss: 0.002175531961256638, Final Batch Loss: 0.0005926448502577841\n",
      "Epoch 1751, Loss: 0.002410676905128639, Final Batch Loss: 0.002186042722314596\n",
      "Epoch 1752, Loss: 0.0017812920559663326, Final Batch Loss: 0.0003408797492738813\n",
      "Epoch 1753, Loss: 0.00899193313671276, Final Batch Loss: 0.003592883236706257\n",
      "Epoch 1754, Loss: 0.00157024001237005, Final Batch Loss: 0.001030145213007927\n",
      "Epoch 1755, Loss: 0.0019344285028637387, Final Batch Loss: 0.0015283802058547735\n",
      "Epoch 1756, Loss: 0.0060864015358674806, Final Batch Loss: 0.005940863862633705\n",
      "Epoch 1757, Loss: 0.0009090151688724291, Final Batch Loss: 5.211023017182015e-05\n",
      "Epoch 1758, Loss: 0.005290496701491065, Final Batch Loss: 0.0007754916441626847\n",
      "Epoch 1759, Loss: 0.0007801553729223087, Final Batch Loss: 0.00015119761519599706\n",
      "Epoch 1760, Loss: 0.0028728118049912155, Final Batch Loss: 0.002093678340315819\n",
      "Epoch 1761, Loss: 0.0037460228777490556, Final Batch Loss: 0.0028188640717417\n",
      "Epoch 1762, Loss: 0.006326154056296218, Final Batch Loss: 0.0033432713244110346\n",
      "Epoch 1763, Loss: 0.0013202432419348042, Final Batch Loss: 2.6714882551459596e-05\n",
      "Epoch 1764, Loss: 0.005389505775383441, Final Batch Loss: 0.003655768930912018\n",
      "Epoch 1765, Loss: 0.006306907627731562, Final Batch Loss: 0.0019018175080418587\n",
      "Epoch 1766, Loss: 0.003985578950960189, Final Batch Loss: 0.0012715107295662165\n",
      "Epoch 1767, Loss: 0.000604436281719245, Final Batch Loss: 0.00035461116931401193\n",
      "Epoch 1768, Loss: 0.0007450538105331361, Final Batch Loss: 0.00010011857375502586\n",
      "Epoch 1769, Loss: 0.001524711391539313, Final Batch Loss: 0.0010507629485800862\n",
      "Epoch 1770, Loss: 0.0021014460071455687, Final Batch Loss: 0.0006128474487923086\n",
      "Epoch 1771, Loss: 0.00047146848373813555, Final Batch Loss: 5.8334619097877294e-05\n",
      "Epoch 1772, Loss: 0.027361456479411572, Final Batch Loss: 0.02380823716521263\n",
      "Epoch 1773, Loss: 0.013423076248727739, Final Batch Loss: 0.000649534456897527\n",
      "Epoch 1774, Loss: 0.012173859729955439, Final Batch Loss: 7.374681445071474e-05\n",
      "Epoch 1775, Loss: 0.013473527145833941, Final Batch Loss: 4.408914901432581e-05\n",
      "Epoch 1776, Loss: 0.0006228854908840731, Final Batch Loss: 0.00026112626073881984\n",
      "Epoch 1777, Loss: 0.0008382962696487084, Final Batch Loss: 0.0004324762267060578\n",
      "Epoch 1778, Loss: 0.00026810784765984863, Final Batch Loss: 9.815792873268947e-05\n",
      "Epoch 1779, Loss: 0.004552706828690134, Final Batch Loss: 0.0004667301836889237\n",
      "Epoch 1780, Loss: 0.018369536875979975, Final Batch Loss: 0.005199079867452383\n",
      "Epoch 1781, Loss: 0.003301141405245289, Final Batch Loss: 0.0020929418969899416\n",
      "Epoch 1782, Loss: 0.003703175148984883, Final Batch Loss: 0.00010815702989930287\n",
      "Epoch 1783, Loss: 0.029870556783862412, Final Batch Loss: 0.0009783236309885979\n",
      "Epoch 1784, Loss: 0.0045508314069593325, Final Batch Loss: 0.00010992427996825427\n",
      "Epoch 1785, Loss: 0.001076461310731247, Final Batch Loss: 0.00017665457562543452\n",
      "Epoch 1786, Loss: 0.0017194632710015867, Final Batch Loss: 0.00016660238907206804\n",
      "Epoch 1787, Loss: 0.000377267013391247, Final Batch Loss: 3.713444675668143e-05\n",
      "Epoch 1788, Loss: 0.0010622881090966985, Final Batch Loss: 0.0004069434944540262\n",
      "Epoch 1789, Loss: 0.0013483829607139342, Final Batch Loss: 0.0003464468172751367\n",
      "Epoch 1790, Loss: 0.0001861323617049493, Final Batch Loss: 3.3729236747603863e-05\n",
      "Epoch 1791, Loss: 0.001651429891353473, Final Batch Loss: 0.0008740852936170995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1792, Loss: 0.018786161148454994, Final Batch Loss: 8.2687649410218e-05\n",
      "Epoch 1793, Loss: 0.004939552949508652, Final Batch Loss: 0.0004463738005142659\n",
      "Epoch 1794, Loss: 0.0025465572689427063, Final Batch Loss: 0.0016225195722654462\n",
      "Epoch 1795, Loss: 0.009910952678183094, Final Batch Loss: 0.0002208991500083357\n",
      "Epoch 1796, Loss: 0.0017039961676346138, Final Batch Loss: 0.001118874759413302\n",
      "Epoch 1797, Loss: 0.0033686289098113775, Final Batch Loss: 0.00045050951302982867\n",
      "Epoch 1798, Loss: 0.03527233447675826, Final Batch Loss: 7.502001972170547e-05\n",
      "Epoch 1799, Loss: 0.0013658186653628945, Final Batch Loss: 9.89684704109095e-05\n",
      "Epoch 1800, Loss: 0.0010772022797027603, Final Batch Loss: 0.0008445680141448975\n",
      "Epoch 1801, Loss: 0.0019840117020066828, Final Batch Loss: 0.0009441862348467112\n",
      "Epoch 1802, Loss: 0.0011133243679068983, Final Batch Loss: 0.00047073696623556316\n",
      "Epoch 1803, Loss: 0.005845103209139779, Final Batch Loss: 0.004847467876970768\n",
      "Epoch 1804, Loss: 0.00333713750296738, Final Batch Loss: 0.00255045504309237\n",
      "Epoch 1805, Loss: 0.0005641713505610824, Final Batch Loss: 0.00014326482778415084\n",
      "Epoch 1806, Loss: 0.0011584667299757712, Final Batch Loss: 0.0005969693884253502\n",
      "Epoch 1807, Loss: 0.0030058487318456173, Final Batch Loss: 0.0007364662014879286\n",
      "Epoch 1808, Loss: 0.010528819810133427, Final Batch Loss: 0.0007186249131336808\n",
      "Epoch 1809, Loss: 0.0031734220901853405, Final Batch Loss: 0.0003451043739914894\n",
      "Epoch 1810, Loss: 0.001134384481702, Final Batch Loss: 0.00046743371058255434\n",
      "Epoch 1811, Loss: 0.003258868760894984, Final Batch Loss: 7.719715358689427e-05\n",
      "Epoch 1812, Loss: 0.0069536599912680686, Final Batch Loss: 0.006006841082125902\n",
      "Epoch 1813, Loss: 0.00047738506691530347, Final Batch Loss: 0.00012567844532895833\n",
      "Epoch 1814, Loss: 0.0016191464674193412, Final Batch Loss: 0.00013843257329426706\n",
      "Epoch 1815, Loss: 0.0008540814378648065, Final Batch Loss: 0.00040273560443893075\n",
      "Epoch 1816, Loss: 0.04142703163961414, Final Batch Loss: 0.0001229446061188355\n",
      "Epoch 1817, Loss: 0.0004996152783860452, Final Batch Loss: 0.00023289328964892775\n",
      "Epoch 1818, Loss: 0.0022850327368360013, Final Batch Loss: 0.0003237568598706275\n",
      "Epoch 1819, Loss: 0.002636253251694143, Final Batch Loss: 0.00017169793136417866\n",
      "Epoch 1820, Loss: 0.0007490543721360154, Final Batch Loss: 0.00019675533985719085\n",
      "Epoch 1821, Loss: 0.0029775585717288777, Final Batch Loss: 0.002171845408156514\n",
      "Epoch 1822, Loss: 0.008142444945406169, Final Batch Loss: 0.0001005928497761488\n",
      "Epoch 1823, Loss: 0.0023391195572912693, Final Batch Loss: 0.000895245058927685\n",
      "Epoch 1824, Loss: 0.0010252757856505923, Final Batch Loss: 0.00045585454790852964\n",
      "Epoch 1825, Loss: 0.008423224615398794, Final Batch Loss: 0.0027937437407672405\n",
      "Epoch 1826, Loss: 0.00115153580554761, Final Batch Loss: 0.00032921924139373004\n",
      "Epoch 1827, Loss: 0.0024495436809957027, Final Batch Loss: 0.0013449457474052906\n",
      "Epoch 1828, Loss: 0.0045626949140569195, Final Batch Loss: 0.00017743658099789172\n",
      "Epoch 1829, Loss: 0.002788627170957625, Final Batch Loss: 0.0001492695591878146\n",
      "Epoch 1830, Loss: 0.0011391030056984164, Final Batch Loss: 7.015688606770709e-05\n",
      "Epoch 1831, Loss: 0.0013529976386053022, Final Batch Loss: 0.0008761718054302037\n",
      "Epoch 1832, Loss: 0.0005434311024146155, Final Batch Loss: 0.0001062322553480044\n",
      "Epoch 1833, Loss: 0.0019193938860553317, Final Batch Loss: 6.363723514368758e-05\n",
      "Epoch 1834, Loss: 0.004582309382385574, Final Batch Loss: 0.0034962224308401346\n",
      "Epoch 1835, Loss: 0.0032302994513884187, Final Batch Loss: 0.0012106524081900716\n",
      "Epoch 1836, Loss: 0.0007078134221956134, Final Batch Loss: 0.0003709803568199277\n",
      "Epoch 1837, Loss: 0.004472615182748996, Final Batch Loss: 0.0038932848256081343\n",
      "Epoch 1838, Loss: 0.0007586353167425841, Final Batch Loss: 0.00017521718109492213\n",
      "Epoch 1839, Loss: 0.0015981844626367092, Final Batch Loss: 0.0006322581321001053\n",
      "Epoch 1840, Loss: 0.001382187256240286, Final Batch Loss: 0.00028926751110702753\n",
      "Epoch 1841, Loss: 0.000975747374468483, Final Batch Loss: 0.00036074622767046094\n",
      "Epoch 1842, Loss: 0.004067517787916586, Final Batch Loss: 0.00017944724822882563\n",
      "Epoch 1843, Loss: 0.0056948489509522915, Final Batch Loss: 0.0014189784415066242\n",
      "Epoch 1844, Loss: 0.004193073487840593, Final Batch Loss: 0.00034059188328683376\n",
      "Epoch 1845, Loss: 0.007619665295351297, Final Batch Loss: 0.0041295671835541725\n",
      "Epoch 1846, Loss: 0.0008486419537803158, Final Batch Loss: 0.00029628039919771254\n",
      "Epoch 1847, Loss: 0.003723681249539368, Final Batch Loss: 0.00012809407780878246\n",
      "Epoch 1848, Loss: 0.002621954132337123, Final Batch Loss: 0.0009311242029070854\n",
      "Epoch 1849, Loss: 0.00039338877832051367, Final Batch Loss: 0.0002935921947937459\n",
      "Epoch 1850, Loss: 0.0020319802570156753, Final Batch Loss: 0.0007656228262931108\n",
      "Epoch 1851, Loss: 0.0235817517968826, Final Batch Loss: 0.0006171812419779599\n",
      "Epoch 1852, Loss: 0.0005473199344123714, Final Batch Loss: 8.645795605843887e-05\n",
      "Epoch 1853, Loss: 0.00038631485222140327, Final Batch Loss: 0.0001568168809171766\n",
      "Epoch 1854, Loss: 0.0012120894971303642, Final Batch Loss: 0.0004076877376064658\n",
      "Epoch 1855, Loss: 0.0007835527358110994, Final Batch Loss: 0.00023453526955563575\n",
      "Epoch 1856, Loss: 0.0006218486196303274, Final Batch Loss: 0.0001605112774996087\n",
      "Epoch 1857, Loss: 0.003795146731135901, Final Batch Loss: 0.0025891344994306564\n",
      "Epoch 1858, Loss: 0.003993739563156851, Final Batch Loss: 0.0030224809888750315\n",
      "Epoch 1859, Loss: 0.003333823347929865, Final Batch Loss: 0.00010920133354375139\n",
      "Epoch 1860, Loss: 0.0002508427860448137, Final Batch Loss: 0.00012795317161362618\n",
      "Epoch 1861, Loss: 0.0006560687397723086, Final Batch Loss: 7.867368549341336e-05\n",
      "Epoch 1862, Loss: 0.0003074054948228877, Final Batch Loss: 7.571730384370312e-05\n",
      "Epoch 1863, Loss: 0.0015739001210022252, Final Batch Loss: 0.0014124332228675485\n",
      "Epoch 1864, Loss: 0.0003554319828253938, Final Batch Loss: 2.123490958183538e-05\n",
      "Epoch 1865, Loss: 0.0004690470923378598, Final Batch Loss: 5.710064942832105e-05\n",
      "Epoch 1866, Loss: 0.0127368830035266, Final Batch Loss: 5.761561988038011e-05\n",
      "Epoch 1867, Loss: 0.0007815593125997111, Final Batch Loss: 0.0002519724948797375\n",
      "Epoch 1868, Loss: 0.025439404766075313, Final Batch Loss: 0.0033696212340146303\n",
      "Epoch 1869, Loss: 0.0023849990029702894, Final Batch Loss: 5.203206819714978e-05\n",
      "Epoch 1870, Loss: 0.0011458055378170684, Final Batch Loss: 0.0002118862612405792\n",
      "Epoch 1871, Loss: 0.0010287010518368334, Final Batch Loss: 0.0003716509963851422\n",
      "Epoch 1872, Loss: 0.006927322261617519, Final Batch Loss: 0.004876141902059317\n",
      "Epoch 1873, Loss: 0.004066143766976893, Final Batch Loss: 0.0025931380223482847\n",
      "Epoch 1874, Loss: 0.0038129307504277676, Final Batch Loss: 0.0034867385402321815\n",
      "Epoch 1875, Loss: 0.0007213613716885448, Final Batch Loss: 0.00028503965586423874\n",
      "Epoch 1876, Loss: 0.0008074261495494284, Final Batch Loss: 0.0003281068638898432\n",
      "Epoch 1877, Loss: 0.00047038074990268797, Final Batch Loss: 7.714929233770818e-05\n",
      "Epoch 1878, Loss: 0.01042975825839676, Final Batch Loss: 0.009999282658100128\n",
      "Epoch 1879, Loss: 0.0440414039985626, Final Batch Loss: 0.0004321072483435273\n",
      "Epoch 1880, Loss: 0.0036826381692662835, Final Batch Loss: 0.00019278321997262537\n",
      "Epoch 1881, Loss: 0.005271338559396099, Final Batch Loss: 7.775091944495216e-05\n",
      "Epoch 1882, Loss: 0.0011711486804415472, Final Batch Loss: 7.14643465471454e-05\n",
      "Epoch 1883, Loss: 0.0014761966958758421, Final Batch Loss: 0.0013146304991096258\n",
      "Epoch 1884, Loss: 0.0015213934530038387, Final Batch Loss: 9.908432548400015e-05\n",
      "Epoch 1885, Loss: 0.0024754587648203596, Final Batch Loss: 0.0015487225027754903\n",
      "Epoch 1886, Loss: 0.0007502041116822511, Final Batch Loss: 0.00017343515355605632\n",
      "Epoch 1887, Loss: 0.023891083597845864, Final Batch Loss: 0.0003195461758878082\n",
      "Epoch 1888, Loss: 0.0021895025856792927, Final Batch Loss: 0.0002632505784276873\n",
      "Epoch 1889, Loss: 0.035351179241843056, Final Batch Loss: 0.03496088832616806\n",
      "Epoch 1890, Loss: 0.0005144895221746992, Final Batch Loss: 0.00038958751247264445\n",
      "Epoch 1891, Loss: 0.0118725543434266, Final Batch Loss: 0.01121334545314312\n",
      "Epoch 1892, Loss: 0.003725183880305849, Final Batch Loss: 0.003027196042239666\n",
      "Epoch 1893, Loss: 0.0005868710049981019, Final Batch Loss: 0.0004137038195040077\n",
      "Epoch 1894, Loss: 0.00020089476311113685, Final Batch Loss: 3.675145853776485e-05\n",
      "Epoch 1895, Loss: 0.006340445048408583, Final Batch Loss: 0.004345451015979052\n",
      "Epoch 1896, Loss: 0.0016491246497025713, Final Batch Loss: 0.0005515696830116212\n",
      "Epoch 1897, Loss: 0.0015988386853678094, Final Batch Loss: 7.226798970805248e-06\n",
      "Epoch 1898, Loss: 0.0020145310709267505, Final Batch Loss: 1.2286343007872347e-05\n",
      "Epoch 1899, Loss: 0.0021284899266902357, Final Batch Loss: 0.0004587812873069197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1900, Loss: 0.00022071096009312896, Final Batch Loss: 4.139946213399526e-06\n",
      "Epoch 1901, Loss: 0.0004438585056050215, Final Batch Loss: 3.615684909163974e-05\n",
      "Epoch 1902, Loss: 0.013621195976156741, Final Batch Loss: 0.009860135614871979\n",
      "Epoch 1903, Loss: 0.0003075686690863222, Final Batch Loss: 0.00021616141020786017\n",
      "Epoch 1904, Loss: 0.03846850425179582, Final Batch Loss: 0.02080380916595459\n",
      "Epoch 1905, Loss: 0.006217517613549717, Final Batch Loss: 0.0010213128989562392\n",
      "Epoch 1906, Loss: 0.0011427143617765978, Final Batch Loss: 0.0005037434748373926\n",
      "Epoch 1907, Loss: 0.004164996324107051, Final Batch Loss: 0.0002453040797263384\n",
      "Epoch 1908, Loss: 0.006398478581104428, Final Batch Loss: 0.00018046138575300574\n",
      "Epoch 1909, Loss: 0.043363274657167494, Final Batch Loss: 0.0013048878172412515\n",
      "Epoch 1910, Loss: 0.002014341880567372, Final Batch Loss: 0.0005324883968569338\n",
      "Epoch 1911, Loss: 0.0010291881844750606, Final Batch Loss: 0.00010247376485494897\n",
      "Epoch 1912, Loss: 0.0034230755118187517, Final Batch Loss: 0.0004043755179736763\n",
      "Epoch 1913, Loss: 0.00992223696084693, Final Batch Loss: 0.0002833368198480457\n",
      "Epoch 1914, Loss: 0.0007326219929382205, Final Batch Loss: 0.00023095723008736968\n",
      "Epoch 1915, Loss: 0.0009708709039841779, Final Batch Loss: 7.632464257767424e-05\n",
      "Epoch 1916, Loss: 0.0011978012917097658, Final Batch Loss: 0.0001460365892853588\n",
      "Epoch 1917, Loss: 0.00956536628655158, Final Batch Loss: 0.00011749981786124408\n",
      "Epoch 1918, Loss: 0.006043087156285765, Final Batch Loss: 0.005461766850203276\n",
      "Epoch 1919, Loss: 0.0017313723292318173, Final Batch Loss: 0.000507117307279259\n",
      "Epoch 1920, Loss: 0.0020092281483812258, Final Batch Loss: 0.0014271093532443047\n",
      "Epoch 1921, Loss: 0.0086671884637326, Final Batch Loss: 0.0022880479227751493\n",
      "Epoch 1922, Loss: 0.0012297369830776006, Final Batch Loss: 0.0008916562073864043\n",
      "Epoch 1923, Loss: 0.008537484420230612, Final Batch Loss: 0.0013960335636511445\n",
      "Epoch 1924, Loss: 0.001389609184116125, Final Batch Loss: 0.0005674121202901006\n",
      "Epoch 1925, Loss: 0.0009500276719336398, Final Batch Loss: 3.758949605980888e-05\n",
      "Epoch 1926, Loss: 0.003655809981864877, Final Batch Loss: 0.0005101758288219571\n",
      "Epoch 1927, Loss: 0.0012212322471896186, Final Batch Loss: 6.501974712591618e-05\n",
      "Epoch 1928, Loss: 0.0012317108339630067, Final Batch Loss: 0.00044035239261575043\n",
      "Epoch 1929, Loss: 0.044619258667808026, Final Batch Loss: 0.0005764422821812332\n",
      "Epoch 1930, Loss: 0.0008511074338457547, Final Batch Loss: 0.000600125000346452\n",
      "Epoch 1931, Loss: 0.0029193111113272607, Final Batch Loss: 0.0015249233692884445\n",
      "Epoch 1932, Loss: 0.009299669764004648, Final Batch Loss: 0.00043018560972996056\n",
      "Epoch 1933, Loss: 0.0015755713830003515, Final Batch Loss: 0.0005700213368982077\n",
      "Epoch 1934, Loss: 0.00039233600909938104, Final Batch Loss: 3.077944347751327e-05\n",
      "Epoch 1935, Loss: 0.0010692139767343178, Final Batch Loss: 0.0004298044659662992\n",
      "Epoch 1936, Loss: 0.0014224634724087082, Final Batch Loss: 7.993846520548686e-05\n",
      "Epoch 1937, Loss: 0.0018852450302802026, Final Batch Loss: 0.000780089758336544\n",
      "Epoch 1938, Loss: 0.0003472153766779229, Final Batch Loss: 0.00010428271343698725\n",
      "Epoch 1939, Loss: 0.0007445876485689951, Final Batch Loss: 0.0004960318328812718\n",
      "Epoch 1940, Loss: 0.026420369493280305, Final Batch Loss: 0.0010178074007853866\n",
      "Epoch 1941, Loss: 0.0016358580178348348, Final Batch Loss: 0.0001100086810765788\n",
      "Epoch 1942, Loss: 0.06400850348290987, Final Batch Loss: 0.06329136341810226\n",
      "Epoch 1943, Loss: 0.008094323158729821, Final Batch Loss: 0.00019034347496926785\n",
      "Epoch 1944, Loss: 0.004357568745035678, Final Batch Loss: 0.003650539554655552\n",
      "Epoch 1945, Loss: 0.0011432105529820547, Final Batch Loss: 0.00046024960465729237\n",
      "Epoch 1946, Loss: 0.0005384017713367939, Final Batch Loss: 0.00020472652977332473\n",
      "Epoch 1947, Loss: 0.001039779555867426, Final Batch Loss: 0.00020676250278484076\n",
      "Epoch 1948, Loss: 0.0011645981285255402, Final Batch Loss: 0.00044602970592677593\n",
      "Epoch 1949, Loss: 0.003235109936213121, Final Batch Loss: 0.0003220162761863321\n",
      "Epoch 1950, Loss: 0.0012825680860260036, Final Batch Loss: 5.2680272347060964e-05\n",
      "Epoch 1951, Loss: 0.0006557154993060976, Final Batch Loss: 0.0002848162839654833\n",
      "Epoch 1952, Loss: 0.0009505238231213298, Final Batch Loss: 5.4970430937828496e-05\n",
      "Epoch 1953, Loss: 0.0032204673916567117, Final Batch Loss: 0.00040033613913692534\n",
      "Epoch 1954, Loss: 0.0019985685794381425, Final Batch Loss: 0.0002334923337912187\n",
      "Epoch 1955, Loss: 0.0035157397796865553, Final Batch Loss: 0.00040640970109961927\n",
      "Epoch 1956, Loss: 0.001109530006942805, Final Batch Loss: 0.00012113735283492133\n",
      "Epoch 1957, Loss: 0.00037721086846431717, Final Batch Loss: 2.2311891370918602e-05\n",
      "Epoch 1958, Loss: 0.0009750232929945923, Final Batch Loss: 7.498496415792033e-05\n",
      "Epoch 1959, Loss: 0.001612123391169007, Final Batch Loss: 2.3781014533597045e-05\n",
      "Epoch 1960, Loss: 0.0018424086010782048, Final Batch Loss: 0.00046529053361155093\n",
      "Epoch 1961, Loss: 0.06009878986515105, Final Batch Loss: 0.0038474334869533777\n",
      "Epoch 1962, Loss: 0.0025280828413087875, Final Batch Loss: 0.0002560374850872904\n",
      "Epoch 1963, Loss: 0.0008005090676306281, Final Batch Loss: 0.0004249989870004356\n",
      "Epoch 1964, Loss: 0.001576853435835801, Final Batch Loss: 0.00014494969218503684\n",
      "Epoch 1965, Loss: 0.0015564789646305144, Final Batch Loss: 0.00033956265542656183\n",
      "Epoch 1966, Loss: 0.000949259614571929, Final Batch Loss: 0.0002819121873471886\n",
      "Epoch 1967, Loss: 0.0011768924159696326, Final Batch Loss: 0.00019923275976907462\n",
      "Epoch 1968, Loss: 0.0027613961647148244, Final Batch Loss: 0.002550631994381547\n",
      "Epoch 1969, Loss: 0.014801591234572697, Final Batch Loss: 0.011339240707457066\n",
      "Epoch 1970, Loss: 0.003635692148236558, Final Batch Loss: 0.00022419815650209785\n",
      "Epoch 1971, Loss: 0.00410631246631965, Final Batch Loss: 0.0018416504608467221\n",
      "Epoch 1972, Loss: 0.017221291964233387, Final Batch Loss: 0.00010492321598576382\n",
      "Epoch 1973, Loss: 0.004856274368648883, Final Batch Loss: 0.00010349424701416865\n",
      "Epoch 1974, Loss: 0.0015267402632161975, Final Batch Loss: 0.0012302182149142027\n",
      "Epoch 1975, Loss: 0.05854891147464514, Final Batch Loss: 0.03735044226050377\n",
      "Epoch 1976, Loss: 0.007854192575905472, Final Batch Loss: 0.0002256865263916552\n",
      "Epoch 1977, Loss: 0.010948466879199259, Final Batch Loss: 8.990387141238898e-05\n",
      "Epoch 1978, Loss: 0.0011292198687442578, Final Batch Loss: 9.20427919481881e-05\n",
      "Epoch 1979, Loss: 0.001138317456934601, Final Batch Loss: 9.235696052201092e-05\n",
      "Epoch 1980, Loss: 0.03079315333161503, Final Batch Loss: 0.0008998798439279199\n",
      "Epoch 1981, Loss: 0.001853346315328963, Final Batch Loss: 0.0001685567112872377\n",
      "Epoch 1982, Loss: 0.0009272518072975799, Final Batch Loss: 0.00022185304260347039\n",
      "Epoch 1983, Loss: 0.002737013914156705, Final Batch Loss: 0.0020612752996385098\n",
      "Epoch 1984, Loss: 0.002328145084902644, Final Batch Loss: 0.0003257286734879017\n",
      "Epoch 1985, Loss: 0.005039784235123079, Final Batch Loss: 0.00011375167377991602\n",
      "Epoch 1986, Loss: 0.0011433926702011377, Final Batch Loss: 0.00035074466723017395\n",
      "Epoch 1987, Loss: 0.0033327291894238442, Final Batch Loss: 0.0006191555294208229\n",
      "Epoch 1988, Loss: 0.0013797726423945278, Final Batch Loss: 0.0004537191998679191\n",
      "Epoch 1989, Loss: 0.0005045730140409432, Final Batch Loss: 7.672030187677592e-05\n",
      "Epoch 1990, Loss: 0.009684472766821273, Final Batch Loss: 0.0006441184668801725\n",
      "Epoch 1991, Loss: 0.006115536161814816, Final Batch Loss: 0.00023317702289205045\n",
      "Epoch 1992, Loss: 0.0011586386535782367, Final Batch Loss: 0.00028707736055366695\n",
      "Epoch 1993, Loss: 0.0012229259009473026, Final Batch Loss: 0.000690615561325103\n",
      "Epoch 1994, Loss: 0.001279432988667395, Final Batch Loss: 9.242106898454949e-05\n",
      "Epoch 1995, Loss: 0.0015274817124009132, Final Batch Loss: 0.0005177910206839442\n",
      "Epoch 1996, Loss: 0.005786898575024679, Final Batch Loss: 0.0023254419211298227\n",
      "Epoch 1997, Loss: 0.0020698931912193075, Final Batch Loss: 0.0005062302225269377\n",
      "Epoch 1998, Loss: 0.0008901245164452121, Final Batch Loss: 0.00033018243266269565\n",
      "Epoch 1999, Loss: 0.004343791399151087, Final Batch Loss: 0.00037428765790537\n",
      "Epoch 2000, Loss: 0.006115501833846793, Final Batch Loss: 0.0015557219740003347\n",
      "Epoch 2001, Loss: 0.011302115508442512, Final Batch Loss: 3.907002610503696e-05\n",
      "Epoch 2002, Loss: 0.00044844722287962213, Final Batch Loss: 6.709351146128029e-05\n",
      "Epoch 2003, Loss: 0.0008049846801441163, Final Batch Loss: 0.00020464745466597378\n",
      "Epoch 2004, Loss: 0.0005675057218468282, Final Batch Loss: 0.00022152739984449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2005, Loss: 0.0019881938096659724, Final Batch Loss: 3.2890169677557424e-05\n",
      "Epoch 2006, Loss: 0.001327708399912808, Final Batch Loss: 8.4420942584984e-05\n",
      "Epoch 2007, Loss: 0.0015705054174759425, Final Batch Loss: 0.0001085818003048189\n",
      "Epoch 2008, Loss: 0.0031058919266797602, Final Batch Loss: 0.0016673338832333684\n",
      "Epoch 2009, Loss: 0.0008630336524220183, Final Batch Loss: 0.00031113679870031774\n",
      "Epoch 2010, Loss: 0.0006853924969618674, Final Batch Loss: 6.135081639513373e-05\n",
      "Epoch 2011, Loss: 0.0014508071908494458, Final Batch Loss: 0.0004912044387310743\n",
      "Epoch 2012, Loss: 0.009108028294576798, Final Batch Loss: 6.601325731026009e-05\n",
      "Epoch 2013, Loss: 0.011722698302037315, Final Batch Loss: 0.0011979296104982495\n",
      "Epoch 2014, Loss: 0.007294574112165719, Final Batch Loss: 0.0007816330762580037\n",
      "Epoch 2015, Loss: 0.0017994312074733898, Final Batch Loss: 0.0005838842480443418\n",
      "Epoch 2016, Loss: 0.0008186676204786636, Final Batch Loss: 3.9789600123185664e-05\n",
      "Epoch 2017, Loss: 0.007012491405475885, Final Batch Loss: 0.0003245177213102579\n",
      "Epoch 2018, Loss: 0.0015180777409113944, Final Batch Loss: 0.0002748577971942723\n",
      "Epoch 2019, Loss: 0.0025064146611839533, Final Batch Loss: 0.0007946991245262325\n",
      "Epoch 2020, Loss: 0.0022263264036155306, Final Batch Loss: 0.0005124828894622624\n",
      "Epoch 2021, Loss: 0.0005289339314913377, Final Batch Loss: 0.0001881198986666277\n",
      "Epoch 2022, Loss: 0.0010758081334643066, Final Batch Loss: 0.00012082586181350052\n",
      "Epoch 2023, Loss: 0.0007086383266141638, Final Batch Loss: 0.0002181550080422312\n",
      "Epoch 2024, Loss: 0.005790790484752506, Final Batch Loss: 0.005117158405482769\n",
      "Epoch 2025, Loss: 0.0013061643876426388, Final Batch Loss: 5.334076195140369e-05\n",
      "Epoch 2026, Loss: 0.0046535933870472945, Final Batch Loss: 8.519378752680495e-05\n",
      "Epoch 2027, Loss: 0.0006607624709431548, Final Batch Loss: 0.00035733028198592365\n",
      "Epoch 2028, Loss: 0.0013608086519525386, Final Batch Loss: 6.421401485567912e-05\n",
      "Epoch 2029, Loss: 0.0004178568487986922, Final Batch Loss: 0.0001858378091128543\n",
      "Epoch 2030, Loss: 0.0005488685419550166, Final Batch Loss: 0.0002542076981626451\n",
      "Epoch 2031, Loss: 0.017509660130599514, Final Batch Loss: 0.001108167227357626\n",
      "Epoch 2032, Loss: 0.0006300585810095072, Final Batch Loss: 0.0002419360534986481\n",
      "Epoch 2033, Loss: 0.000538480126124341, Final Batch Loss: 0.00032368680695071816\n",
      "Epoch 2034, Loss: 0.005046944803325459, Final Batch Loss: 0.0036615224089473486\n",
      "Epoch 2035, Loss: 0.0038938143552513793, Final Batch Loss: 3.111596743110567e-05\n",
      "Epoch 2036, Loss: 0.0010491507564438507, Final Batch Loss: 0.0002275948936585337\n",
      "Epoch 2037, Loss: 0.0004607997980201617, Final Batch Loss: 7.24380515748635e-05\n",
      "Epoch 2038, Loss: 0.0013375825037655886, Final Batch Loss: 0.0012002495350316167\n",
      "Epoch 2039, Loss: 0.0038822609349153936, Final Batch Loss: 0.00023075874196365476\n",
      "Epoch 2040, Loss: 0.006146183943201322, Final Batch Loss: 0.005663483403623104\n",
      "Epoch 2041, Loss: 0.000722988166671712, Final Batch Loss: 0.00016472044808324426\n",
      "Epoch 2042, Loss: 0.0036358483193907887, Final Batch Loss: 2.5272107450291514e-05\n",
      "Epoch 2043, Loss: 0.0025600523185858037, Final Batch Loss: 0.0017817049520090222\n",
      "Epoch 2044, Loss: 0.0012303037365199998, Final Batch Loss: 0.00017862986715044826\n",
      "Epoch 2045, Loss: 0.003282420126197394, Final Batch Loss: 0.0026009944267570972\n",
      "Epoch 2046, Loss: 0.003608800092479214, Final Batch Loss: 0.00048518108087591827\n",
      "Epoch 2047, Loss: 0.0011259633683948778, Final Batch Loss: 0.0003417586849536747\n",
      "Epoch 2048, Loss: 0.0026374025910627097, Final Batch Loss: 9.686319390311837e-05\n",
      "Epoch 2049, Loss: 0.003682227252284065, Final Batch Loss: 0.0010524932295084\n",
      "Epoch 2050, Loss: 0.003659601410618052, Final Batch Loss: 0.0004154098278377205\n",
      "Epoch 2051, Loss: 0.0007955050095915794, Final Batch Loss: 0.0001683575683273375\n",
      "Epoch 2052, Loss: 0.0021442229553940706, Final Batch Loss: 5.042662814958021e-05\n",
      "Epoch 2053, Loss: 0.000461702817119658, Final Batch Loss: 0.00022568705026060343\n",
      "Epoch 2054, Loss: 0.008347304188646376, Final Batch Loss: 0.0004960201913490891\n",
      "Epoch 2055, Loss: 0.004197783477138728, Final Batch Loss: 0.002805118216201663\n",
      "Epoch 2056, Loss: 0.0007870357767387759, Final Batch Loss: 0.0001368034863844514\n",
      "Epoch 2057, Loss: 0.0034623764076968655, Final Batch Loss: 0.00021627506066579372\n",
      "Epoch 2058, Loss: 0.0003404042490728898, Final Batch Loss: 2.293813849973958e-05\n",
      "Epoch 2059, Loss: 0.015364706137916073, Final Batch Loss: 0.0008522866992279887\n",
      "Epoch 2060, Loss: 0.001165091889561154, Final Batch Loss: 0.0001500155485700816\n",
      "Epoch 2061, Loss: 0.0009084691046155058, Final Batch Loss: 3.9315309550147504e-05\n",
      "Epoch 2062, Loss: 0.005853896487678867, Final Batch Loss: 0.00020546081941574812\n",
      "Epoch 2063, Loss: 0.032014955238992115, Final Batch Loss: 2.6870355213759467e-05\n",
      "Epoch 2064, Loss: 0.02881955576594919, Final Batch Loss: 0.0011832324089482427\n",
      "Epoch 2065, Loss: 0.021029544295743108, Final Batch Loss: 0.006202204618602991\n",
      "Epoch 2066, Loss: 0.0007301671957975486, Final Batch Loss: 0.00026357342721894383\n",
      "Epoch 2067, Loss: 0.0007793113472871482, Final Batch Loss: 0.00045485683949664235\n",
      "Epoch 2068, Loss: 0.000546293638763018, Final Batch Loss: 0.0001829585962696001\n",
      "Epoch 2069, Loss: 0.0010841600451385602, Final Batch Loss: 0.0004908521077595651\n",
      "Epoch 2070, Loss: 0.011748086151783355, Final Batch Loss: 0.01135716587305069\n",
      "Epoch 2071, Loss: 0.003600818399718264, Final Batch Loss: 0.002833781996741891\n",
      "Epoch 2072, Loss: 0.0024701849615667015, Final Batch Loss: 0.002076390665024519\n",
      "Epoch 2073, Loss: 0.0024376967921853065, Final Batch Loss: 0.0006177169852890074\n",
      "Epoch 2074, Loss: 0.00798448285786435, Final Batch Loss: 0.00014213394024409354\n",
      "Epoch 2075, Loss: 0.00029307930162758566, Final Batch Loss: 5.9640344261424616e-05\n",
      "Epoch 2076, Loss: 0.0008295793413708452, Final Batch Loss: 4.6903362090233713e-05\n",
      "Epoch 2077, Loss: 0.0003211259754607454, Final Batch Loss: 0.0001315620174864307\n",
      "Epoch 2078, Loss: 0.0057594423269620165, Final Batch Loss: 0.00013799172302242368\n",
      "Epoch 2079, Loss: 0.03456360712880269, Final Batch Loss: 0.0001054357853718102\n",
      "Epoch 2080, Loss: 0.0014551317945006303, Final Batch Loss: 4.972310125594959e-05\n",
      "Epoch 2081, Loss: 0.0006494999979622662, Final Batch Loss: 0.00024815768119879067\n",
      "Epoch 2082, Loss: 0.0010030508710769936, Final Batch Loss: 0.0005411208840087056\n",
      "Epoch 2083, Loss: 0.005355362663976848, Final Batch Loss: 0.0010508589912205935\n",
      "Epoch 2084, Loss: 0.0013404579658526927, Final Batch Loss: 0.00019257079111412168\n",
      "Epoch 2085, Loss: 0.0027918232372030616, Final Batch Loss: 0.0002839989319909364\n",
      "Epoch 2086, Loss: 0.001362033810437424, Final Batch Loss: 5.6076427426887676e-05\n",
      "Epoch 2087, Loss: 0.000435035144619178, Final Batch Loss: 0.00015565207286272198\n",
      "Epoch 2088, Loss: 0.000754828899516724, Final Batch Loss: 0.0003115376166533679\n",
      "Epoch 2089, Loss: 0.0007288095366675407, Final Batch Loss: 0.00015773232735227793\n",
      "Epoch 2090, Loss: 0.007219798470032401, Final Batch Loss: 0.0002561419678386301\n",
      "Epoch 2091, Loss: 0.004328612703830004, Final Batch Loss: 0.0016239772085100412\n",
      "Epoch 2092, Loss: 0.0011091891792602837, Final Batch Loss: 7.476260361727327e-05\n",
      "Epoch 2093, Loss: 0.0006335110956570134, Final Batch Loss: 0.00015117702423594892\n",
      "Epoch 2094, Loss: 0.0010252108550048433, Final Batch Loss: 0.00029246247140690684\n",
      "Epoch 2095, Loss: 0.0007999841654964257, Final Batch Loss: 0.00012185734522063285\n",
      "Epoch 2096, Loss: 0.0016764854663051665, Final Batch Loss: 0.00030680361669510603\n",
      "Epoch 2097, Loss: 0.0011206055933143944, Final Batch Loss: 0.0003909535298589617\n",
      "Epoch 2098, Loss: 0.00042095592652913183, Final Batch Loss: 0.0001070976722985506\n",
      "Epoch 2099, Loss: 0.001226920823683031, Final Batch Loss: 0.0005685602081939578\n",
      "Epoch 2100, Loss: 0.001031172891089227, Final Batch Loss: 0.0004024092049803585\n",
      "Epoch 2101, Loss: 0.0009050485386978835, Final Batch Loss: 0.00012756395153701305\n",
      "Epoch 2102, Loss: 0.0007035643102426548, Final Batch Loss: 5.229736052569933e-05\n",
      "Epoch 2103, Loss: 0.0005038340086684912, Final Batch Loss: 1.3900032172387e-05\n",
      "Epoch 2104, Loss: 0.00031300686896429397, Final Batch Loss: 0.00010263146396027878\n",
      "Epoch 2105, Loss: 0.0013502165529644117, Final Batch Loss: 0.0006810590857639909\n",
      "Epoch 2106, Loss: 0.0008238724258262664, Final Batch Loss: 0.00010325909534003586\n",
      "Epoch 2107, Loss: 0.0005746698589064181, Final Batch Loss: 0.0001675493986112997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2108, Loss: 0.0011093259090557694, Final Batch Loss: 9.406518074683845e-05\n",
      "Epoch 2109, Loss: 0.0008615053520770743, Final Batch Loss: 0.00012250673898961395\n",
      "Epoch 2110, Loss: 0.005692823826393578, Final Batch Loss: 0.005336086265742779\n",
      "Epoch 2111, Loss: 0.00064421899151057, Final Batch Loss: 0.00040215300396084785\n",
      "Epoch 2112, Loss: 0.0015832541248528287, Final Batch Loss: 0.0010816374560818076\n",
      "Epoch 2113, Loss: 0.001017822723952122, Final Batch Loss: 0.0007812060648575425\n",
      "Epoch 2114, Loss: 0.00029767783780698664, Final Batch Loss: 0.00020370015408843756\n",
      "Epoch 2115, Loss: 0.0002781655784929171, Final Batch Loss: 6.122377089923248e-05\n",
      "Epoch 2116, Loss: 0.019228580844355747, Final Batch Loss: 0.013411595486104488\n",
      "Epoch 2117, Loss: 0.0012051898447680287, Final Batch Loss: 0.0005631831591017544\n",
      "Epoch 2118, Loss: 0.00302416697377339, Final Batch Loss: 0.0006710532470606267\n",
      "Epoch 2119, Loss: 0.00042607286741258577, Final Batch Loss: 3.213278978364542e-05\n",
      "Epoch 2120, Loss: 0.00043796474710688926, Final Batch Loss: 0.00019968101696576923\n",
      "Epoch 2121, Loss: 0.0012626691022887826, Final Batch Loss: 0.0010822821641340852\n",
      "Epoch 2122, Loss: 0.0004387522458273452, Final Batch Loss: 0.00031050280085764825\n",
      "Epoch 2123, Loss: 0.0003068989681196399, Final Batch Loss: 0.0001113164980779402\n",
      "Epoch 2124, Loss: 0.0007938403687148821, Final Batch Loss: 0.000498841458465904\n",
      "Epoch 2125, Loss: 0.0015665551072743256, Final Batch Loss: 4.5789045543642715e-05\n",
      "Epoch 2126, Loss: 0.00020453574143175501, Final Batch Loss: 8.115266973618418e-05\n",
      "Epoch 2127, Loss: 0.0004013184880022891, Final Batch Loss: 0.00026240586885251105\n",
      "Epoch 2128, Loss: 0.0004560265915642958, Final Batch Loss: 0.00036910627386532724\n",
      "Epoch 2129, Loss: 0.0008092929638223723, Final Batch Loss: 0.00039907218888401985\n",
      "Epoch 2130, Loss: 0.0011856220589834265, Final Batch Loss: 8.082111889962107e-06\n",
      "Epoch 2131, Loss: 0.0006023861715220846, Final Batch Loss: 0.00018788434681482613\n",
      "Epoch 2132, Loss: 0.01043437997577712, Final Batch Loss: 0.0009564557112753391\n",
      "Epoch 2133, Loss: 0.0009490062511758879, Final Batch Loss: 3.3599979360587895e-05\n",
      "Epoch 2134, Loss: 0.0008747585598030128, Final Batch Loss: 2.836951898643747e-05\n",
      "Epoch 2135, Loss: 0.0015983605553628877, Final Batch Loss: 0.00012906371557619423\n",
      "Epoch 2136, Loss: 0.002717960625886917, Final Batch Loss: 0.000857795006595552\n",
      "Epoch 2137, Loss: 0.002323131117009325, Final Batch Loss: 0.0016614983323961496\n",
      "Epoch 2138, Loss: 0.000650887333904393, Final Batch Loss: 0.0002215213025920093\n",
      "Epoch 2139, Loss: 0.0008248470439866651, Final Batch Loss: 0.0004730225191451609\n",
      "Epoch 2140, Loss: 0.0016430730174761266, Final Batch Loss: 0.00016161947860382497\n",
      "Epoch 2141, Loss: 0.002239049950730987, Final Batch Loss: 0.00020048856094945222\n",
      "Epoch 2142, Loss: 0.0015695706533733755, Final Batch Loss: 0.0009548497619107366\n",
      "Epoch 2143, Loss: 0.005257762917608488, Final Batch Loss: 4.203938442515209e-05\n",
      "Epoch 2144, Loss: 0.0010926310933427885, Final Batch Loss: 0.00020255685376469046\n",
      "Epoch 2145, Loss: 0.0013532932862290181, Final Batch Loss: 2.4520391889382154e-05\n",
      "Epoch 2146, Loss: 0.0029409126145765185, Final Batch Loss: 0.00011974322842434049\n",
      "Epoch 2147, Loss: 0.00019798745051957667, Final Batch Loss: 3.966056465287693e-05\n",
      "Epoch 2148, Loss: 0.004023591329314513, Final Batch Loss: 0.0038916838821023703\n",
      "Epoch 2149, Loss: 0.0021270173601806164, Final Batch Loss: 0.001225227490067482\n",
      "Epoch 2150, Loss: 0.0008238463487941772, Final Batch Loss: 0.000436740112490952\n",
      "Epoch 2151, Loss: 0.0002716894341574516, Final Batch Loss: 2.780172690108884e-05\n",
      "Epoch 2152, Loss: 0.0009238248203473631, Final Batch Loss: 0.0005686021759174764\n",
      "Epoch 2153, Loss: 0.00018770264250633772, Final Batch Loss: 2.490076622052584e-05\n",
      "Epoch 2154, Loss: 0.0006109801870479714, Final Batch Loss: 0.0004899827181361616\n",
      "Epoch 2155, Loss: 0.0016751994444348384, Final Batch Loss: 4.5054028305457905e-05\n",
      "Epoch 2156, Loss: 0.0011993216830887832, Final Batch Loss: 0.00040632093441672623\n",
      "Epoch 2157, Loss: 0.0007790662225488632, Final Batch Loss: 6.794218734285096e-06\n",
      "Epoch 2158, Loss: 0.0029223957171780057, Final Batch Loss: 8.342623186763376e-05\n",
      "Epoch 2159, Loss: 0.00038877965380379464, Final Batch Loss: 1.3683767974725924e-05\n",
      "Epoch 2160, Loss: 0.0010595133462629747, Final Batch Loss: 3.374290463398211e-05\n",
      "Epoch 2161, Loss: 0.0005404929470387287, Final Batch Loss: 0.00020497040532063693\n",
      "Epoch 2162, Loss: 0.00031371340628538746, Final Batch Loss: 1.8736691345111467e-05\n",
      "Epoch 2163, Loss: 0.027287672110105632, Final Batch Loss: 0.00019739191338885576\n",
      "Epoch 2164, Loss: 0.0024763473047642037, Final Batch Loss: 0.00019995680486317724\n",
      "Epoch 2165, Loss: 0.00900001492118463, Final Batch Loss: 0.0012879952555522323\n",
      "Epoch 2166, Loss: 0.0152218990115216, Final Batch Loss: 0.014752816408872604\n",
      "Epoch 2167, Loss: 0.0022892851311553386, Final Batch Loss: 1.2424065971572418e-05\n",
      "Epoch 2168, Loss: 0.00040702235855860636, Final Batch Loss: 0.00020289653912186623\n",
      "Epoch 2169, Loss: 0.0022493141295854002, Final Batch Loss: 0.0003526301879901439\n",
      "Epoch 2170, Loss: 0.0014996606114436872, Final Batch Loss: 0.0006422784645110369\n",
      "Epoch 2171, Loss: 0.0024449219927191734, Final Batch Loss: 0.000324561377055943\n",
      "Epoch 2172, Loss: 0.0008918500134313945, Final Batch Loss: 8.901233377400786e-05\n",
      "Epoch 2173, Loss: 0.00033679795888019726, Final Batch Loss: 5.210843664826825e-05\n",
      "Epoch 2174, Loss: 0.0009847709443420172, Final Batch Loss: 0.00036048097535967827\n",
      "Epoch 2175, Loss: 0.0009496687562204897, Final Batch Loss: 0.00039224501233547926\n",
      "Epoch 2176, Loss: 0.0007515041488659335, Final Batch Loss: 2.1338868464226834e-05\n",
      "Epoch 2177, Loss: 0.007207988062873483, Final Batch Loss: 0.005155744031071663\n",
      "Epoch 2178, Loss: 0.00724595676001627, Final Batch Loss: 0.0026579946279525757\n",
      "Epoch 2179, Loss: 0.000254892691373243, Final Batch Loss: 2.0006582417408936e-05\n",
      "Epoch 2180, Loss: 0.0005948955367784947, Final Batch Loss: 0.00023270369274541736\n",
      "Epoch 2181, Loss: 0.0005664546406478621, Final Batch Loss: 9.446724288864061e-05\n",
      "Epoch 2182, Loss: 0.002574235732026864, Final Batch Loss: 0.00010463453509146348\n",
      "Epoch 2183, Loss: 0.0015328152512665838, Final Batch Loss: 0.0007669468759559095\n",
      "Epoch 2184, Loss: 0.0026910263841273263, Final Batch Loss: 0.0021829872857779264\n",
      "Epoch 2185, Loss: 0.0016403087065555155, Final Batch Loss: 0.00023052183678373694\n",
      "Epoch 2186, Loss: 0.00045250503171700984, Final Batch Loss: 9.295002382714301e-05\n",
      "Epoch 2187, Loss: 0.026120459544472396, Final Batch Loss: 0.02554544433951378\n",
      "Epoch 2188, Loss: 0.0008042356566875242, Final Batch Loss: 4.0898572478909045e-05\n",
      "Epoch 2189, Loss: 0.005260386773443315, Final Batch Loss: 5.909699393669143e-05\n",
      "Epoch 2190, Loss: 0.000686045521433698, Final Batch Loss: 5.3681153076468036e-05\n",
      "Epoch 2191, Loss: 0.0007896958413766697, Final Batch Loss: 0.00020092204795219004\n",
      "Epoch 2192, Loss: 0.002657744502357673, Final Batch Loss: 0.00010939832282019779\n",
      "Epoch 2193, Loss: 0.0007971732520672958, Final Batch Loss: 0.0005066714365966618\n",
      "Epoch 2194, Loss: 0.0019190675011486746, Final Batch Loss: 0.0008892545592971146\n",
      "Epoch 2195, Loss: 0.0006037729253876023, Final Batch Loss: 0.00018239498604089022\n",
      "Epoch 2196, Loss: 0.0002280945009260904, Final Batch Loss: 7.264834857778624e-05\n",
      "Epoch 2197, Loss: 0.0005629023689834867, Final Batch Loss: 6.123803905211389e-05\n",
      "Epoch 2198, Loss: 0.001882540287624579, Final Batch Loss: 7.456877210643142e-05\n",
      "Epoch 2199, Loss: 0.005223361295065843, Final Batch Loss: 0.00027950669755227864\n",
      "Epoch 2200, Loss: 0.0015882572915870696, Final Batch Loss: 0.00010805806959979236\n",
      "Epoch 2201, Loss: 0.006399681442417204, Final Batch Loss: 0.005503607913851738\n",
      "Epoch 2202, Loss: 0.006585009559785249, Final Batch Loss: 6.044136534910649e-05\n",
      "Epoch 2203, Loss: 0.0023585839953739196, Final Batch Loss: 0.0008326961542479694\n",
      "Epoch 2204, Loss: 0.0013665844307979569, Final Batch Loss: 3.880394797306508e-05\n",
      "Epoch 2205, Loss: 0.004970708047039807, Final Batch Loss: 0.0007416931912302971\n",
      "Epoch 2206, Loss: 0.0020194258831907064, Final Batch Loss: 0.0005224037449806929\n",
      "Epoch 2207, Loss: 0.0005235068711044732, Final Batch Loss: 6.067912181606516e-05\n",
      "Epoch 2208, Loss: 0.0005985062016407028, Final Batch Loss: 0.00032623196602799\n",
      "Epoch 2209, Loss: 0.0016065565359895118, Final Batch Loss: 0.00011146160250063986\n",
      "Epoch 2210, Loss: 0.001736176993290428, Final Batch Loss: 0.0011507202871143818\n",
      "Epoch 2211, Loss: 0.000266006842139177, Final Batch Loss: 0.00018491705122869462\n",
      "Epoch 2212, Loss: 0.0005668697049259208, Final Batch Loss: 6.480362935690209e-05\n",
      "Epoch 2213, Loss: 0.001026809353788849, Final Batch Loss: 0.00010786522034322843\n",
      "Epoch 2214, Loss: 0.0005174915168026928, Final Batch Loss: 4.9159298214362934e-05\n",
      "Epoch 2215, Loss: 0.0003050551895285025, Final Batch Loss: 0.00014906992146279663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2216, Loss: 0.0009483058456680737, Final Batch Loss: 0.0006413562805391848\n",
      "Epoch 2217, Loss: 0.0009002738443086855, Final Batch Loss: 0.0002465945144649595\n",
      "Epoch 2218, Loss: 0.0005514079366548685, Final Batch Loss: 0.000442720134742558\n",
      "Epoch 2219, Loss: 0.002471361411153339, Final Batch Loss: 0.001830887165851891\n",
      "Epoch 2220, Loss: 0.0006351271458697738, Final Batch Loss: 0.0004668339970521629\n",
      "Epoch 2221, Loss: 0.00040855621045921, Final Batch Loss: 0.0001019996270770207\n",
      "Epoch 2222, Loss: 0.0019177691719960421, Final Batch Loss: 0.0005767124239355326\n",
      "Epoch 2223, Loss: 0.0021973204566165805, Final Batch Loss: 0.0006853483500890434\n",
      "Epoch 2224, Loss: 0.0009676435583969578, Final Batch Loss: 0.0005556326359510422\n",
      "Epoch 2225, Loss: 0.000428497267421335, Final Batch Loss: 3.614158777054399e-05\n",
      "Epoch 2226, Loss: 0.0009397355133842211, Final Batch Loss: 0.00017373824084643275\n",
      "Epoch 2227, Loss: 0.0002729299994825851, Final Batch Loss: 7.64474316383712e-05\n",
      "Epoch 2228, Loss: 0.0001795262323867064, Final Batch Loss: 0.00010091222065966576\n",
      "Epoch 2229, Loss: 0.0019345582404639572, Final Batch Loss: 0.0009759041713550687\n",
      "Epoch 2230, Loss: 0.001128241332480684, Final Batch Loss: 2.1179293980821967e-05\n",
      "Epoch 2231, Loss: 0.0003357875539222732, Final Batch Loss: 9.169867553282529e-05\n",
      "Epoch 2232, Loss: 0.0009101386676775292, Final Batch Loss: 0.00019586557755246758\n",
      "Epoch 2233, Loss: 0.013911460196140979, Final Batch Loss: 2.8625396225834265e-05\n",
      "Epoch 2234, Loss: 0.00013228792886366136, Final Batch Loss: 2.2816162527306005e-05\n",
      "Epoch 2235, Loss: 0.0012802805449609878, Final Batch Loss: 4.192640699329786e-05\n",
      "Epoch 2236, Loss: 0.00041586087172618136, Final Batch Loss: 0.00022941167117096484\n",
      "Epoch 2237, Loss: 0.0003813727162196301, Final Batch Loss: 0.00011165263276780024\n",
      "Epoch 2238, Loss: 0.0005201270832912996, Final Batch Loss: 1.9100138160865754e-05\n",
      "Epoch 2239, Loss: 0.00024301798475789838, Final Batch Loss: 0.00010599075176287442\n",
      "Epoch 2240, Loss: 0.0009333060079370625, Final Batch Loss: 0.00034778780536726117\n",
      "Epoch 2241, Loss: 0.000239772918575909, Final Batch Loss: 4.250315760145895e-05\n",
      "Epoch 2242, Loss: 0.00020323630815255456, Final Batch Loss: 8.625061309430748e-05\n",
      "Epoch 2243, Loss: 0.015980669602868147, Final Batch Loss: 0.00022984280076343566\n",
      "Epoch 2244, Loss: 0.0002672732953215018, Final Batch Loss: 9.133174899034202e-05\n",
      "Epoch 2245, Loss: 0.0023789013848727336, Final Batch Loss: 0.002267442876473069\n",
      "Epoch 2246, Loss: 9.558219244354405e-05, Final Batch Loss: 4.1480278014205396e-05\n",
      "Epoch 2247, Loss: 0.002451940454193391, Final Batch Loss: 0.0001337368885288015\n",
      "Epoch 2248, Loss: 0.004679737146943808, Final Batch Loss: 0.0003540275793056935\n",
      "Epoch 2249, Loss: 0.0003028784622074454, Final Batch Loss: 0.00024329726875294\n",
      "Epoch 2250, Loss: 0.0019291908320155926, Final Batch Loss: 3.910031955456361e-05\n",
      "Epoch 2251, Loss: 0.011404400298488326, Final Batch Loss: 3.073799598496407e-05\n",
      "Epoch 2252, Loss: 0.0009524549459456466, Final Batch Loss: 0.0006928130751475692\n",
      "Epoch 2253, Loss: 0.0015311714669223875, Final Batch Loss: 0.00026149905170314014\n",
      "Epoch 2254, Loss: 0.001510879876150284, Final Batch Loss: 8.656550926389173e-05\n",
      "Epoch 2255, Loss: 0.0019268399937573122, Final Batch Loss: 0.001521683530882001\n",
      "Epoch 2256, Loss: 0.0021185513433010783, Final Batch Loss: 5.175458863959648e-05\n",
      "Epoch 2257, Loss: 0.0005910549662075937, Final Batch Loss: 0.00013959265197627246\n",
      "Epoch 2258, Loss: 0.0005949718106421642, Final Batch Loss: 0.00014431227464228868\n",
      "Epoch 2259, Loss: 0.0003847678535748855, Final Batch Loss: 8.193238500098232e-06\n",
      "Epoch 2260, Loss: 0.0005325396759872092, Final Batch Loss: 2.8916749215568416e-05\n",
      "Epoch 2261, Loss: 0.00018076930427923799, Final Batch Loss: 4.296035331208259e-05\n",
      "Epoch 2262, Loss: 0.002519157307688147, Final Batch Loss: 0.0002940469130408019\n",
      "Epoch 2263, Loss: 0.00022327466649585404, Final Batch Loss: 4.676424214267172e-05\n",
      "Epoch 2264, Loss: 0.012405326546286233, Final Batch Loss: 0.00014138493861537427\n",
      "Epoch 2265, Loss: 0.005589235574007034, Final Batch Loss: 0.0017065409338101745\n",
      "Epoch 2266, Loss: 0.0071938805558602326, Final Batch Loss: 0.005896697286516428\n",
      "Epoch 2267, Loss: 0.0010552945896051824, Final Batch Loss: 0.00018388376338407397\n",
      "Epoch 2268, Loss: 0.005957212095381692, Final Batch Loss: 0.0057409401051700115\n",
      "Epoch 2269, Loss: 0.001687806041445583, Final Batch Loss: 0.00028384802863001823\n",
      "Epoch 2270, Loss: 0.0022196150093805045, Final Batch Loss: 0.00046913750702515244\n",
      "Epoch 2271, Loss: 0.0006983642670093104, Final Batch Loss: 3.745634967344813e-05\n",
      "Epoch 2272, Loss: 0.0007996752538019791, Final Batch Loss: 0.0002431157190585509\n",
      "Epoch 2273, Loss: 0.00033688891016936395, Final Batch Loss: 1.2352562407613732e-05\n",
      "Epoch 2274, Loss: 0.003084175812546164, Final Batch Loss: 0.0026886840350925922\n",
      "Epoch 2275, Loss: 0.0006175193630042486, Final Batch Loss: 0.00034459488233551383\n",
      "Epoch 2276, Loss: 0.00039911543353809975, Final Batch Loss: 0.0003190381685271859\n",
      "Epoch 2277, Loss: 0.00036221816117176786, Final Batch Loss: 0.00014332309365272522\n",
      "Epoch 2278, Loss: 0.0007010952849668683, Final Batch Loss: 1.0905301678576507e-05\n",
      "Epoch 2279, Loss: 0.0012007584155071527, Final Batch Loss: 0.0006696954951621592\n",
      "Epoch 2280, Loss: 0.00818322564009577, Final Batch Loss: 0.004700247198343277\n",
      "Epoch 2281, Loss: 0.003939531135983998, Final Batch Loss: 0.0008815189357846975\n",
      "Epoch 2282, Loss: 0.00026184044963883935, Final Batch Loss: 1.2908912140119355e-05\n",
      "Epoch 2283, Loss: 0.0003860214965243358, Final Batch Loss: 0.00023220870934892446\n",
      "Epoch 2284, Loss: 0.00031089524236449506, Final Batch Loss: 2.266107730974909e-05\n",
      "Epoch 2285, Loss: 0.005658730311552063, Final Batch Loss: 0.00013747633784078062\n",
      "Epoch 2286, Loss: 0.0009889352804748341, Final Batch Loss: 0.0007218538084998727\n",
      "Epoch 2287, Loss: 0.0006918997823959216, Final Batch Loss: 4.433467984199524e-05\n",
      "Epoch 2288, Loss: 0.01307912101765396, Final Batch Loss: 0.01280257198959589\n",
      "Epoch 2289, Loss: 0.013788019365165383, Final Batch Loss: 0.006831166334450245\n",
      "Epoch 2290, Loss: 0.035859961091773584, Final Batch Loss: 0.0004281159781385213\n",
      "Epoch 2291, Loss: 0.002461533864334342, Final Batch Loss: 1.1782527508330531e-05\n",
      "Epoch 2292, Loss: 0.0007672830251976848, Final Batch Loss: 0.00026454668841324747\n",
      "Epoch 2293, Loss: 0.000210211564990459, Final Batch Loss: 0.0001273804809898138\n",
      "Epoch 2294, Loss: 0.0002802672333928058, Final Batch Loss: 0.0002138478448614478\n",
      "Epoch 2295, Loss: 0.005833261267980561, Final Batch Loss: 0.004928992595523596\n",
      "Epoch 2296, Loss: 0.002693443777388893, Final Batch Loss: 0.00024092085368465632\n",
      "Epoch 2297, Loss: 0.000842823734274134, Final Batch Loss: 0.00024416393716819584\n",
      "Epoch 2298, Loss: 0.0029807728715240955, Final Batch Loss: 0.0007087284466251731\n",
      "Epoch 2299, Loss: 0.0011822841697721742, Final Batch Loss: 0.00042829959420487285\n",
      "Epoch 2300, Loss: 0.008063671935815364, Final Batch Loss: 0.0005394066101871431\n",
      "Epoch 2301, Loss: 0.0014999537670519203, Final Batch Loss: 0.00044241483556106687\n",
      "Epoch 2302, Loss: 0.012370642096357187, Final Batch Loss: 0.010558055713772774\n",
      "Epoch 2303, Loss: 0.0003699549979501171, Final Batch Loss: 2.5441475372645073e-05\n",
      "Epoch 2304, Loss: 0.0015837759856367484, Final Batch Loss: 0.0003790672344621271\n",
      "Epoch 2305, Loss: 0.0003113446364295669, Final Batch Loss: 0.00011424676631577313\n",
      "Epoch 2306, Loss: 0.001316837573540397, Final Batch Loss: 0.0008065625443123281\n",
      "Epoch 2307, Loss: 0.0013853666096110828, Final Batch Loss: 0.00010455842857481912\n",
      "Epoch 2308, Loss: 0.0005475022335303947, Final Batch Loss: 0.00010830564133357257\n",
      "Epoch 2309, Loss: 0.002766781115496997, Final Batch Loss: 4.1927101847250015e-05\n",
      "Epoch 2310, Loss: 0.002704215672565624, Final Batch Loss: 0.00011394030298106372\n",
      "Epoch 2311, Loss: 0.0042933992663165554, Final Batch Loss: 0.0039490885101258755\n",
      "Epoch 2312, Loss: 0.05924331363348756, Final Batch Loss: 0.05850965529680252\n",
      "Epoch 2313, Loss: 0.00012028460514557082, Final Batch Loss: 4.6952256525401026e-05\n",
      "Epoch 2314, Loss: 0.0007676706518395804, Final Batch Loss: 0.00041632712236605585\n",
      "Epoch 2315, Loss: 0.00273903357447125, Final Batch Loss: 0.001729502808302641\n",
      "Epoch 2316, Loss: 0.00033607449222472496, Final Batch Loss: 4.0039642044575885e-05\n",
      "Epoch 2317, Loss: 0.020676194690167904, Final Batch Loss: 0.004138017538934946\n",
      "Epoch 2318, Loss: 0.0014357001091411803, Final Batch Loss: 0.0006987871020101011\n",
      "Epoch 2319, Loss: 0.006911551907251123, Final Batch Loss: 7.468819239875302e-05\n",
      "Epoch 2320, Loss: 0.001060634182067588, Final Batch Loss: 0.00028016898431815207\n",
      "Epoch 2321, Loss: 0.01645328188624262, Final Batch Loss: 0.0008136393153108656\n",
      "Epoch 2322, Loss: 0.0006960345963307191, Final Batch Loss: 2.309777119080536e-05\n",
      "Epoch 2323, Loss: 0.0037812017908436246, Final Batch Loss: 0.00011822574742836878\n",
      "Epoch 2324, Loss: 0.0010435424774186686, Final Batch Loss: 0.0003255134215578437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2325, Loss: 0.0016835884598549455, Final Batch Loss: 0.00036361339152790606\n",
      "Epoch 2326, Loss: 0.0005801809165859595, Final Batch Loss: 0.0003514330310281366\n",
      "Epoch 2327, Loss: 0.0003959679015679285, Final Batch Loss: 0.00010573847976047546\n",
      "Epoch 2328, Loss: 0.0007450905759469606, Final Batch Loss: 0.000187039389857091\n",
      "Epoch 2329, Loss: 0.0006056781767256325, Final Batch Loss: 9.265328117180616e-05\n",
      "Epoch 2330, Loss: 0.019517800086759962, Final Batch Loss: 0.018949249759316444\n",
      "Epoch 2331, Loss: 0.00046303245471790433, Final Batch Loss: 0.0001662270224187523\n",
      "Epoch 2332, Loss: 0.0005586110200965777, Final Batch Loss: 0.00011189121869392693\n",
      "Epoch 2333, Loss: 0.01002683183469344, Final Batch Loss: 0.00952078029513359\n",
      "Epoch 2334, Loss: 0.0019357847995706834, Final Batch Loss: 0.0017382650403305888\n",
      "Epoch 2335, Loss: 0.0005177993953111582, Final Batch Loss: 0.0001477851765230298\n",
      "Epoch 2336, Loss: 0.0007350960731855594, Final Batch Loss: 0.00044751650420948863\n",
      "Epoch 2337, Loss: 0.001425295602530241, Final Batch Loss: 0.00044111369061283767\n",
      "Epoch 2338, Loss: 0.0009904220860335045, Final Batch Loss: 5.4587530030403286e-05\n",
      "Epoch 2339, Loss: 0.0009748945449246094, Final Batch Loss: 0.0002654211421031505\n",
      "Epoch 2340, Loss: 0.000473099215014372, Final Batch Loss: 0.00014280894538387656\n",
      "Epoch 2341, Loss: 0.003667517514259089, Final Batch Loss: 0.0012954717967659235\n",
      "Epoch 2342, Loss: 0.0022706357412971556, Final Batch Loss: 0.0006461298326030374\n",
      "Epoch 2343, Loss: 0.009255814555217512, Final Batch Loss: 8.25163588160649e-05\n",
      "Epoch 2344, Loss: 0.002829223551088944, Final Batch Loss: 4.283009911887348e-05\n",
      "Epoch 2345, Loss: 0.0013763577298959717, Final Batch Loss: 4.862232890445739e-05\n",
      "Epoch 2346, Loss: 0.007157232990721241, Final Batch Loss: 0.0002110407513100654\n",
      "Epoch 2347, Loss: 0.0024662168361828662, Final Batch Loss: 2.8983115043956786e-05\n",
      "Epoch 2348, Loss: 0.004459587129531428, Final Batch Loss: 0.00015384375001303852\n",
      "Epoch 2349, Loss: 0.0007482188229914755, Final Batch Loss: 0.00046164452214725316\n",
      "Epoch 2350, Loss: 0.0010096526093548164, Final Batch Loss: 0.00013994019536767155\n",
      "Epoch 2351, Loss: 0.0034867193789978046, Final Batch Loss: 0.0031897726003080606\n",
      "Epoch 2352, Loss: 0.00046483515689033084, Final Batch Loss: 0.00011778292537201196\n",
      "Epoch 2353, Loss: 0.0010996543533110525, Final Batch Loss: 0.00039122087764553726\n",
      "Epoch 2354, Loss: 0.0012268163700355217, Final Batch Loss: 0.0002432800829410553\n",
      "Epoch 2355, Loss: 0.0012513482215581462, Final Batch Loss: 0.00024199490144383162\n",
      "Epoch 2356, Loss: 0.00027540207520360127, Final Batch Loss: 1.9712562789209187e-05\n",
      "Epoch 2357, Loss: 0.002144041547580855, Final Batch Loss: 0.0020300359465181828\n",
      "Epoch 2358, Loss: 0.002708854717639042, Final Batch Loss: 0.002485334174707532\n",
      "Epoch 2359, Loss: 0.0016788107168395072, Final Batch Loss: 0.0007591564790345728\n",
      "Epoch 2360, Loss: 0.0007627362210769206, Final Batch Loss: 8.236918074544519e-05\n",
      "Epoch 2361, Loss: 0.0007051775683066808, Final Batch Loss: 0.00039567420026287436\n",
      "Epoch 2362, Loss: 0.00042356670019216835, Final Batch Loss: 2.2604348487220705e-05\n",
      "Epoch 2363, Loss: 0.0022932149513508193, Final Batch Loss: 8.279323083115742e-05\n",
      "Epoch 2364, Loss: 0.0010247585450997576, Final Batch Loss: 0.000124734579003416\n",
      "Epoch 2365, Loss: 0.00021890531752433162, Final Batch Loss: 1.8023578377324156e-05\n",
      "Epoch 2366, Loss: 0.000339432961482089, Final Batch Loss: 0.0001135547790909186\n",
      "Epoch 2367, Loss: 0.0027364711422706023, Final Batch Loss: 0.0001354016421828419\n",
      "Epoch 2368, Loss: 0.0004737043163913768, Final Batch Loss: 3.626619218266569e-05\n",
      "Epoch 2369, Loss: 0.03359460982755991, Final Batch Loss: 0.033331990242004395\n",
      "Epoch 2370, Loss: 0.03670957665599417, Final Batch Loss: 0.00011712194827850908\n",
      "Epoch 2371, Loss: 0.0009945066267391667, Final Batch Loss: 0.0001792312104953453\n",
      "Epoch 2372, Loss: 0.0006147910971776582, Final Batch Loss: 4.723529127659276e-05\n",
      "Epoch 2373, Loss: 0.0006190068670548499, Final Batch Loss: 0.00020268134539946914\n",
      "Epoch 2374, Loss: 0.006301190034719184, Final Batch Loss: 0.0002489820180926472\n",
      "Epoch 2375, Loss: 0.00354190036887303, Final Batch Loss: 0.002170577412471175\n",
      "Epoch 2376, Loss: 0.0008564794698031619, Final Batch Loss: 0.00016620437963865697\n",
      "Epoch 2377, Loss: 0.0009483781177550554, Final Batch Loss: 0.00015744735719636083\n",
      "Epoch 2378, Loss: 0.0003830221394309774, Final Batch Loss: 0.00021227625256869942\n",
      "Epoch 2379, Loss: 0.000413392270274926, Final Batch Loss: 3.380289126653224e-05\n",
      "Epoch 2380, Loss: 0.0006721074860251974, Final Batch Loss: 0.00012055248225806281\n",
      "Epoch 2381, Loss: 0.0009502793400315568, Final Batch Loss: 0.000513916602358222\n",
      "Epoch 2382, Loss: 0.0006446380211855285, Final Batch Loss: 0.0004736617556773126\n",
      "Epoch 2383, Loss: 0.0011365136306267232, Final Batch Loss: 0.0001120996312238276\n",
      "Epoch 2384, Loss: 0.002203964671934955, Final Batch Loss: 8.534383232472464e-05\n",
      "Epoch 2385, Loss: 0.018725702131632715, Final Batch Loss: 0.0013843142660334706\n",
      "Epoch 2386, Loss: 0.0033182979896082543, Final Batch Loss: 0.0002111973735736683\n",
      "Epoch 2387, Loss: 0.002669572873855941, Final Batch Loss: 0.00016321794828400016\n",
      "Epoch 2388, Loss: 0.022859961420181207, Final Batch Loss: 0.00019114046881441027\n",
      "Epoch 2389, Loss: 0.011807202947238693, Final Batch Loss: 0.010203627869486809\n",
      "Epoch 2390, Loss: 0.0008886312989488943, Final Batch Loss: 1.1813010132755153e-05\n",
      "Epoch 2391, Loss: 0.0031492707566940226, Final Batch Loss: 0.0016274297377094626\n",
      "Epoch 2392, Loss: 0.05521030770614743, Final Batch Loss: 0.00097909034229815\n",
      "Epoch 2393, Loss: 0.0036203181953169405, Final Batch Loss: 0.00010846106306416914\n",
      "Epoch 2394, Loss: 0.0005478834100358654, Final Batch Loss: 0.0002940189733635634\n",
      "Epoch 2395, Loss: 0.0007854418709030142, Final Batch Loss: 2.9369666663114913e-05\n",
      "Epoch 2396, Loss: 0.005804247950436547, Final Batch Loss: 0.000126961269415915\n",
      "Epoch 2397, Loss: 0.0008222322794608772, Final Batch Loss: 0.0003794367366936058\n",
      "Epoch 2398, Loss: 0.03408885048702359, Final Batch Loss: 6.487713835667819e-05\n",
      "Epoch 2399, Loss: 0.0008945917506935075, Final Batch Loss: 9.240632061846554e-05\n",
      "Epoch 2400, Loss: 0.017304611450526863, Final Batch Loss: 0.016475602984428406\n",
      "Epoch 2401, Loss: 0.0013112789602018893, Final Batch Loss: 0.0004106161359231919\n",
      "Epoch 2402, Loss: 0.001600583374965936, Final Batch Loss: 0.0009184447699226439\n",
      "Epoch 2403, Loss: 0.0007591796020278707, Final Batch Loss: 0.00016933924052864313\n",
      "Epoch 2404, Loss: 0.0005948550679022446, Final Batch Loss: 0.00019676907686516643\n",
      "Epoch 2405, Loss: 0.0388712483108975, Final Batch Loss: 0.0004631711053662002\n",
      "Epoch 2406, Loss: 0.0017770594567991793, Final Batch Loss: 0.0005840843659825623\n",
      "Epoch 2407, Loss: 0.0013064991508144885, Final Batch Loss: 0.0001423962094122544\n",
      "Epoch 2408, Loss: 0.0047445223171962425, Final Batch Loss: 0.00420575775206089\n",
      "Epoch 2409, Loss: 0.0006164245278341696, Final Batch Loss: 8.489919127896428e-05\n",
      "Epoch 2410, Loss: 0.002671389462193474, Final Batch Loss: 0.0021373589988797903\n",
      "Epoch 2411, Loss: 0.001125200215028599, Final Batch Loss: 0.00016285375750157982\n",
      "Epoch 2412, Loss: 0.010681950836442411, Final Batch Loss: 0.0062117320485413074\n",
      "Epoch 2413, Loss: 0.0016244969592662528, Final Batch Loss: 0.00022021525364834815\n",
      "Epoch 2414, Loss: 0.004617180340574123, Final Batch Loss: 0.00161566655151546\n",
      "Epoch 2415, Loss: 0.0011624608596321195, Final Batch Loss: 0.0007779767620377243\n",
      "Epoch 2416, Loss: 0.0005062998825451359, Final Batch Loss: 0.0001112730533350259\n",
      "Epoch 2417, Loss: 0.005613071582047269, Final Batch Loss: 0.00042246346129104495\n",
      "Epoch 2418, Loss: 0.0018043830059468746, Final Batch Loss: 0.000717703893315047\n",
      "Epoch 2419, Loss: 0.024523964035324752, Final Batch Loss: 0.0004012741846963763\n",
      "Epoch 2420, Loss: 0.0006315403297776356, Final Batch Loss: 0.00016990944277495146\n",
      "Epoch 2421, Loss: 0.0009085938218049705, Final Batch Loss: 0.0003477541031315923\n",
      "Epoch 2422, Loss: 0.0006621448119403794, Final Batch Loss: 0.00028432143153622746\n",
      "Epoch 2423, Loss: 0.0005144113893038593, Final Batch Loss: 0.00025664284476079047\n",
      "Epoch 2424, Loss: 0.0021853801154065877, Final Batch Loss: 0.00024509275681339204\n",
      "Epoch 2425, Loss: 0.0025909006071742624, Final Batch Loss: 0.0002828609140124172\n",
      "Epoch 2426, Loss: 0.0035821335768559948, Final Batch Loss: 0.002998020499944687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2427, Loss: 0.0006085157656343654, Final Batch Loss: 0.0003515519783832133\n",
      "Epoch 2428, Loss: 0.0009548864181851968, Final Batch Loss: 0.00030285847606137395\n",
      "Epoch 2429, Loss: 0.0007679491536691785, Final Batch Loss: 0.00020847233827225864\n",
      "Epoch 2430, Loss: 0.005616171714791562, Final Batch Loss: 0.005205061286687851\n",
      "Epoch 2431, Loss: 0.0013202937407186255, Final Batch Loss: 0.0004913532757200301\n",
      "Epoch 2432, Loss: 0.0004708305605163332, Final Batch Loss: 5.0857470341725275e-05\n",
      "Epoch 2433, Loss: 0.000679557015246246, Final Batch Loss: 7.550729060312733e-05\n",
      "Epoch 2434, Loss: 0.0007972752464411315, Final Batch Loss: 4.8477169912075624e-05\n",
      "Epoch 2435, Loss: 0.000451137479103636, Final Batch Loss: 9.00965605978854e-05\n",
      "Epoch 2436, Loss: 0.0008993360024760477, Final Batch Loss: 4.20836076955311e-05\n",
      "Epoch 2437, Loss: 0.00027442599093774334, Final Batch Loss: 0.00015611360140610486\n",
      "Epoch 2438, Loss: 0.0011730779660865664, Final Batch Loss: 0.00023618513660039753\n",
      "Epoch 2439, Loss: 0.0005026258477300871, Final Batch Loss: 5.638091897708364e-05\n",
      "Epoch 2440, Loss: 0.004335643443482695, Final Batch Loss: 1.7539521650178358e-05\n",
      "Epoch 2441, Loss: 0.0011066537990700454, Final Batch Loss: 0.0002495425578672439\n",
      "Epoch 2442, Loss: 0.0032765403884695843, Final Batch Loss: 0.0001261261204490438\n",
      "Epoch 2443, Loss: 0.002875359874451533, Final Batch Loss: 0.0019665935542434454\n",
      "Epoch 2444, Loss: 0.011226578475543647, Final Batch Loss: 2.599691470095422e-05\n",
      "Epoch 2445, Loss: 0.012566940189572051, Final Batch Loss: 0.00026549005997367203\n",
      "Epoch 2446, Loss: 0.0005760380554420408, Final Batch Loss: 0.00018710362201090902\n",
      "Epoch 2447, Loss: 0.004564291419228539, Final Batch Loss: 0.0019941027276217937\n",
      "Epoch 2448, Loss: 0.000543175181519473, Final Batch Loss: 5.5853666708571836e-05\n",
      "Epoch 2449, Loss: 0.008930474752560258, Final Batch Loss: 0.00823068618774414\n",
      "Epoch 2450, Loss: 0.0028357760747894645, Final Batch Loss: 0.0011334611335769296\n",
      "Epoch 2451, Loss: 0.0015360157558461651, Final Batch Loss: 0.0007863669306971133\n",
      "Epoch 2452, Loss: 0.007191339012933895, Final Batch Loss: 0.0002922327839769423\n",
      "Epoch 2453, Loss: 0.0006597809260711074, Final Batch Loss: 0.00015653209993615746\n",
      "Epoch 2454, Loss: 0.004173810666543432, Final Batch Loss: 0.0036886942107230425\n",
      "Epoch 2455, Loss: 0.008733034832403064, Final Batch Loss: 0.00027279037749394774\n",
      "Epoch 2456, Loss: 0.0015612452407367527, Final Batch Loss: 0.0007360974559560418\n",
      "Epoch 2457, Loss: 0.0015841874555917457, Final Batch Loss: 0.0013212603516876698\n",
      "Epoch 2458, Loss: 0.0012538817536551505, Final Batch Loss: 0.0002080037083942443\n",
      "Epoch 2459, Loss: 0.006500614545075223, Final Batch Loss: 0.005910709034651518\n",
      "Epoch 2460, Loss: 0.0025228898448403925, Final Batch Loss: 0.00024029365158639848\n",
      "Epoch 2461, Loss: 0.019234954903367907, Final Batch Loss: 0.016609836369752884\n",
      "Epoch 2462, Loss: 0.0007197170634754002, Final Batch Loss: 0.00020252745889592916\n",
      "Epoch 2463, Loss: 0.0014656450257461984, Final Batch Loss: 0.00011509736941661686\n",
      "Epoch 2464, Loss: 0.04753196887031663, Final Batch Loss: 0.0001530956942588091\n",
      "Epoch 2465, Loss: 0.0036333685638965108, Final Batch Loss: 0.0006399250123649836\n",
      "Epoch 2466, Loss: 0.0016797616044641472, Final Batch Loss: 0.0004966406850144267\n",
      "Epoch 2467, Loss: 0.028284483807510696, Final Batch Loss: 0.00011631730740191415\n",
      "Epoch 2468, Loss: 0.00718017722829245, Final Batch Loss: 0.005216101184487343\n",
      "Epoch 2469, Loss: 0.04304526471241843, Final Batch Loss: 0.04233720526099205\n",
      "Epoch 2470, Loss: 0.014202051344909705, Final Batch Loss: 0.013859331607818604\n",
      "Epoch 2471, Loss: 0.0017344834341201931, Final Batch Loss: 0.00034181741648353636\n",
      "Epoch 2472, Loss: 0.0003393022889213171, Final Batch Loss: 3.4928609238704666e-05\n",
      "Epoch 2473, Loss: 0.0015690555082983337, Final Batch Loss: 0.00011633146641543135\n",
      "Epoch 2474, Loss: 0.0028286729066167027, Final Batch Loss: 0.0021139923483133316\n",
      "Epoch 2475, Loss: 0.00411661270482, Final Batch Loss: 0.00015676846669521183\n",
      "Epoch 2476, Loss: 0.0010357515275245532, Final Batch Loss: 0.000589074450545013\n",
      "Epoch 2477, Loss: 0.003046901634661481, Final Batch Loss: 0.0007136346539482474\n",
      "Epoch 2478, Loss: 0.00044412822171580046, Final Batch Loss: 0.00017520702385809273\n",
      "Epoch 2479, Loss: 0.00423701512045227, Final Batch Loss: 0.0038956536445766687\n",
      "Epoch 2480, Loss: 0.0011255604040343314, Final Batch Loss: 0.00045953888911753893\n",
      "Epoch 2481, Loss: 0.0022824418265372515, Final Batch Loss: 0.0010470598936080933\n",
      "Epoch 2482, Loss: 0.0020407521806191653, Final Batch Loss: 0.0003847012703772634\n",
      "Epoch 2483, Loss: 0.0010644890717230737, Final Batch Loss: 0.00028748559998348355\n",
      "Epoch 2484, Loss: 0.0010918556072283536, Final Batch Loss: 0.00045642643817700446\n",
      "Epoch 2485, Loss: 0.0007333428802667186, Final Batch Loss: 0.00014671444660052657\n",
      "Epoch 2486, Loss: 0.001196450786665082, Final Batch Loss: 0.000590203853789717\n",
      "Epoch 2487, Loss: 0.0004285617105779238, Final Batch Loss: 0.00017355284944642335\n",
      "Epoch 2488, Loss: 0.0006322310218820348, Final Batch Loss: 0.00013001871411688626\n",
      "Epoch 2489, Loss: 0.0015604620930389501, Final Batch Loss: 0.0006502935430034995\n",
      "Epoch 2490, Loss: 0.00026390139828436077, Final Batch Loss: 0.00010925308743026108\n",
      "Epoch 2491, Loss: 0.00537431518023368, Final Batch Loss: 0.00010698156256694347\n",
      "Epoch 2492, Loss: 0.0005893779816688038, Final Batch Loss: 0.00030997497378848493\n",
      "Epoch 2493, Loss: 0.0008157911361195147, Final Batch Loss: 5.155961844138801e-05\n",
      "Epoch 2494, Loss: 0.000943471779464744, Final Batch Loss: 0.00025451634428463876\n",
      "Epoch 2495, Loss: 0.0027575940257520415, Final Batch Loss: 6.384141306625679e-05\n",
      "Epoch 2496, Loss: 0.04391901011695154, Final Batch Loss: 0.043172188103199005\n",
      "Epoch 2497, Loss: 0.0013372250250540674, Final Batch Loss: 0.0008525176672264934\n",
      "Epoch 2498, Loss: 0.002424012120172847, Final Batch Loss: 9.80464174062945e-05\n",
      "Epoch 2499, Loss: 0.00156900388901704, Final Batch Loss: 0.0006583586218766868\n",
      "Epoch 2500, Loss: 0.004855640756431967, Final Batch Loss: 0.00013097713235765696\n",
      "Epoch 2501, Loss: 0.0013550910443882458, Final Batch Loss: 7.777392602292821e-05\n",
      "Epoch 2502, Loss: 0.0017612064257264137, Final Batch Loss: 0.0005646315403282642\n",
      "Epoch 2503, Loss: 0.013851345298462547, Final Batch Loss: 0.01190978940576315\n",
      "Epoch 2504, Loss: 0.0005322783872543368, Final Batch Loss: 4.983939652447589e-05\n",
      "Epoch 2505, Loss: 0.006464222497015726, Final Batch Loss: 0.00011638696742011234\n",
      "Epoch 2506, Loss: 0.0014904152340022847, Final Batch Loss: 0.00020077571389265358\n",
      "Epoch 2507, Loss: 0.05084355277358554, Final Batch Loss: 3.238939098082483e-05\n",
      "Epoch 2508, Loss: 0.0027200821205042303, Final Batch Loss: 0.0001326067722402513\n",
      "Epoch 2509, Loss: 0.006438904732931405, Final Batch Loss: 0.0002067392342723906\n",
      "Epoch 2510, Loss: 0.004744611112982966, Final Batch Loss: 0.0002341451618121937\n",
      "Epoch 2511, Loss: 0.010738198790932074, Final Batch Loss: 0.0007448832038789988\n",
      "Epoch 2512, Loss: 0.0019132866145810112, Final Batch Loss: 6.548686360474676e-05\n",
      "Epoch 2513, Loss: 0.002007981907809153, Final Batch Loss: 0.0007756858831271529\n",
      "Epoch 2514, Loss: 0.0015200019552139565, Final Batch Loss: 0.0009371782070957124\n",
      "Epoch 2515, Loss: 0.0042172358225798234, Final Batch Loss: 0.0001883280638139695\n",
      "Epoch 2516, Loss: 0.0018012957370956428, Final Batch Loss: 0.0008754180744290352\n",
      "Epoch 2517, Loss: 0.0011657898285193369, Final Batch Loss: 0.00012724539556074888\n",
      "Epoch 2518, Loss: 0.003690753917908296, Final Batch Loss: 0.00018043539603240788\n",
      "Epoch 2519, Loss: 0.0005850739034940489, Final Batch Loss: 0.0003024198522325605\n",
      "Epoch 2520, Loss: 0.0007397390218102373, Final Batch Loss: 0.0002529960183892399\n",
      "Epoch 2521, Loss: 0.0008734035000088625, Final Batch Loss: 0.0003974402497988194\n",
      "Epoch 2522, Loss: 0.0009754744241945446, Final Batch Loss: 0.0005650644889101386\n",
      "Epoch 2523, Loss: 0.00459495397444698, Final Batch Loss: 5.027443330618553e-05\n",
      "Epoch 2524, Loss: 0.001789212808944285, Final Batch Loss: 0.00013283995212987065\n",
      "Epoch 2525, Loss: 0.0009220209531122237, Final Batch Loss: 1.298503684665775e-05\n",
      "Epoch 2526, Loss: 0.0035395653394516557, Final Batch Loss: 0.0028106255922466516\n",
      "Epoch 2527, Loss: 0.0031363652524305508, Final Batch Loss: 4.706990148406476e-05\n",
      "Epoch 2528, Loss: 0.0046909797238186, Final Batch Loss: 0.0037801440339535475\n",
      "Epoch 2529, Loss: 0.0008065375877777115, Final Batch Loss: 0.00044431840069592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2530, Loss: 0.0008917407976696268, Final Batch Loss: 0.00032602137071080506\n",
      "Epoch 2531, Loss: 0.0009669280261732638, Final Batch Loss: 0.0002708295069169253\n",
      "Epoch 2532, Loss: 0.00015176696251728572, Final Batch Loss: 4.5360524381976575e-05\n",
      "Epoch 2533, Loss: 0.006413056908058934, Final Batch Loss: 0.0002395368937868625\n",
      "Epoch 2534, Loss: 0.0007857825985411182, Final Batch Loss: 0.00031893071718513966\n",
      "Epoch 2535, Loss: 0.0013373817746469285, Final Batch Loss: 4.255167368683033e-05\n",
      "Epoch 2536, Loss: 0.0026703520270530134, Final Batch Loss: 0.0003381235001143068\n",
      "Epoch 2537, Loss: 0.0011430184731580084, Final Batch Loss: 6.855919491499662e-05\n",
      "Epoch 2538, Loss: 0.0036348428911878727, Final Batch Loss: 3.254258626839146e-05\n",
      "Epoch 2539, Loss: 0.0007478767583961599, Final Batch Loss: 3.4709202736848965e-05\n",
      "Epoch 2540, Loss: 0.0006950806775876117, Final Batch Loss: 3.6052435916644754e-06\n",
      "Epoch 2541, Loss: 0.0005653261223415029, Final Batch Loss: 1.1220986380067188e-05\n",
      "Epoch 2542, Loss: 0.0007132310565793887, Final Batch Loss: 0.0002741340722423047\n",
      "Epoch 2543, Loss: 0.0021644097578246146, Final Batch Loss: 0.00043603384983725846\n",
      "Epoch 2544, Loss: 0.00032544559689995367, Final Batch Loss: 2.7414042051532306e-05\n",
      "Epoch 2545, Loss: 0.0006863341623102315, Final Batch Loss: 0.0004936287296004593\n",
      "Epoch 2546, Loss: 0.0004560122688417323, Final Batch Loss: 0.0002156101108994335\n",
      "Epoch 2547, Loss: 0.0017556728053023107, Final Batch Loss: 5.623867764370516e-05\n",
      "Epoch 2548, Loss: 0.0005808114583487622, Final Batch Loss: 0.00010248746548313648\n",
      "Epoch 2549, Loss: 0.001802213111659512, Final Batch Loss: 0.00044526663259603083\n",
      "Epoch 2550, Loss: 0.0008622707682661712, Final Batch Loss: 0.00028350314823910594\n",
      "Epoch 2551, Loss: 0.0004972884908056585, Final Batch Loss: 8.291115227621049e-05\n",
      "Epoch 2552, Loss: 0.000719622643373441, Final Batch Loss: 0.0005991981597617269\n",
      "Epoch 2553, Loss: 0.00020426557239261456, Final Batch Loss: 7.34922505216673e-05\n",
      "Epoch 2554, Loss: 0.000680373290379066, Final Batch Loss: 5.752361175836995e-05\n",
      "Epoch 2555, Loss: 0.00037996530954842456, Final Batch Loss: 0.00023160153068602085\n",
      "Epoch 2556, Loss: 0.0007385290809907019, Final Batch Loss: 0.0001657423417782411\n",
      "Epoch 2557, Loss: 0.00023022177811071742, Final Batch Loss: 7.235015073092654e-05\n",
      "Epoch 2558, Loss: 0.017121544624387752, Final Batch Loss: 0.015021000988781452\n",
      "Epoch 2559, Loss: 0.0008435869585809996, Final Batch Loss: 0.0001338945294264704\n",
      "Epoch 2560, Loss: 0.00042156060226261616, Final Batch Loss: 3.8045429391786456e-05\n",
      "Epoch 2561, Loss: 0.004340809606219409, Final Batch Loss: 0.0003870236687362194\n",
      "Epoch 2562, Loss: 0.002662481258084881, Final Batch Loss: 0.0021110984962433577\n",
      "Epoch 2563, Loss: 0.001317342135735089, Final Batch Loss: 3.8021862565074116e-05\n",
      "Epoch 2564, Loss: 0.0005353964370442554, Final Batch Loss: 0.00019030751718673855\n",
      "Epoch 2565, Loss: 0.0026416341279400513, Final Batch Loss: 0.00011819997598649934\n",
      "Epoch 2566, Loss: 0.0011731853810488246, Final Batch Loss: 0.0009476065170019865\n",
      "Epoch 2567, Loss: 0.00209556074696593, Final Batch Loss: 0.0002612815296743065\n",
      "Epoch 2568, Loss: 0.0023506828729296103, Final Batch Loss: 0.00010340472363168374\n",
      "Epoch 2569, Loss: 0.0007401924813166261, Final Batch Loss: 0.00029874310712330043\n",
      "Epoch 2570, Loss: 0.0035744201795750996, Final Batch Loss: 2.211494393122848e-05\n",
      "Epoch 2571, Loss: 0.0006074401608202606, Final Batch Loss: 0.0001543394901091233\n",
      "Epoch 2572, Loss: 0.00021907953305344563, Final Batch Loss: 1.9171360690961592e-05\n",
      "Epoch 2573, Loss: 0.0009812802745727822, Final Batch Loss: 0.0005419028457254171\n",
      "Epoch 2574, Loss: 0.0009020797660923563, Final Batch Loss: 4.7073895984794945e-05\n",
      "Epoch 2575, Loss: 0.0003651232909760438, Final Batch Loss: 9.653564484324306e-05\n",
      "Epoch 2576, Loss: 0.02240399515721947, Final Batch Loss: 0.00013094372116029263\n",
      "Epoch 2577, Loss: 0.00021164606187085155, Final Batch Loss: 3.611869033193216e-05\n",
      "Epoch 2578, Loss: 0.0002381407994107576, Final Batch Loss: 1.375933970848564e-05\n",
      "Epoch 2579, Loss: 0.0007195869839051738, Final Batch Loss: 0.00037327042082324624\n",
      "Epoch 2580, Loss: 0.0010343759640818462, Final Batch Loss: 0.0005745009402744472\n",
      "Epoch 2581, Loss: 0.00018133346020476893, Final Batch Loss: 5.807656634715386e-05\n",
      "Epoch 2582, Loss: 0.0021042365551693365, Final Batch Loss: 0.0016690598567947745\n",
      "Epoch 2583, Loss: 0.00023083953419700265, Final Batch Loss: 7.746808842057362e-05\n",
      "Epoch 2584, Loss: 0.0014422801323235035, Final Batch Loss: 0.0002872860059142113\n",
      "Epoch 2585, Loss: 0.00015491026715608314, Final Batch Loss: 1.9261495253886096e-05\n",
      "Epoch 2586, Loss: 0.0027502433840709273, Final Batch Loss: 0.00017001161177176982\n",
      "Epoch 2587, Loss: 0.0008400659571634606, Final Batch Loss: 0.00018847528554033488\n",
      "Epoch 2588, Loss: 0.0010150506022910122, Final Batch Loss: 0.000753165630158037\n",
      "Epoch 2589, Loss: 0.00040368283589486964, Final Batch Loss: 0.00016276439419016242\n",
      "Epoch 2590, Loss: 0.0010384343768237159, Final Batch Loss: 0.00018996205471921712\n",
      "Epoch 2591, Loss: 0.0004995785893697757, Final Batch Loss: 4.990061643184163e-05\n",
      "Epoch 2592, Loss: 0.006838112807599828, Final Batch Loss: 0.005900136660784483\n",
      "Epoch 2593, Loss: 0.00041861527279252186, Final Batch Loss: 6.390696944436058e-05\n",
      "Epoch 2594, Loss: 0.0008980669445008971, Final Batch Loss: 0.0005957955145277083\n",
      "Epoch 2595, Loss: 0.002398404169071, Final Batch Loss: 5.804700049338862e-05\n",
      "Epoch 2596, Loss: 0.0031165055697783828, Final Batch Loss: 0.001476653036661446\n",
      "Epoch 2597, Loss: 0.0005177000566618517, Final Batch Loss: 0.00029461190570145845\n",
      "Epoch 2598, Loss: 0.0012860170245403424, Final Batch Loss: 0.0006377899553626776\n",
      "Epoch 2599, Loss: 0.004775938265083823, Final Batch Loss: 3.900724550476298e-05\n",
      "Epoch 2600, Loss: 0.0005184875881241169, Final Batch Loss: 0.0004420408804435283\n",
      "Epoch 2601, Loss: 0.00021424631268018857, Final Batch Loss: 3.614145680330694e-05\n",
      "Epoch 2602, Loss: 0.001118493455578573, Final Batch Loss: 0.0010393501725047827\n",
      "Epoch 2603, Loss: 0.00020002945529995486, Final Batch Loss: 2.78795268968679e-05\n",
      "Epoch 2604, Loss: 0.00048309986414096784, Final Batch Loss: 1.8693470337893814e-05\n",
      "Epoch 2605, Loss: 0.0012357592931948602, Final Batch Loss: 0.000195554195670411\n",
      "Epoch 2606, Loss: 0.0026429293648106977, Final Batch Loss: 0.0002402241516392678\n",
      "Epoch 2607, Loss: 0.07351905420364346, Final Batch Loss: 0.07322269678115845\n",
      "Epoch 2608, Loss: 0.0009230755058524664, Final Batch Loss: 0.0001840178738348186\n",
      "Epoch 2609, Loss: 0.0004947658562741708, Final Batch Loss: 9.204475645674393e-06\n",
      "Epoch 2610, Loss: 0.0006254363979678601, Final Batch Loss: 0.00014681293396279216\n",
      "Epoch 2611, Loss: 0.000928728753933683, Final Batch Loss: 0.0001632600324228406\n",
      "Epoch 2612, Loss: 0.0007653463471797295, Final Batch Loss: 0.00027278283960185945\n",
      "Epoch 2613, Loss: 0.0011827601920231245, Final Batch Loss: 0.001004165387712419\n",
      "Epoch 2614, Loss: 0.0010028847282228526, Final Batch Loss: 0.0007417541346512735\n",
      "Epoch 2615, Loss: 0.0006543758991028881, Final Batch Loss: 2.208831392636057e-05\n",
      "Epoch 2616, Loss: 0.020144404523307458, Final Batch Loss: 0.0003076401480939239\n",
      "Epoch 2617, Loss: 0.00022411342797568068, Final Batch Loss: 4.660498962039128e-05\n",
      "Epoch 2618, Loss: 0.00023916403370094486, Final Batch Loss: 3.962190021411516e-05\n",
      "Epoch 2619, Loss: 0.00223659574839985, Final Batch Loss: 0.0015981089090928435\n",
      "Epoch 2620, Loss: 0.028765021390427137, Final Batch Loss: 4.073318632435985e-05\n",
      "Epoch 2621, Loss: 0.0010446651140227914, Final Batch Loss: 0.00011539750266820192\n",
      "Epoch 2622, Loss: 0.0008138185658026487, Final Batch Loss: 9.493395918980241e-05\n",
      "Epoch 2623, Loss: 0.00025769030617084354, Final Batch Loss: 7.8088793088682e-05\n",
      "Epoch 2624, Loss: 0.0001618877868168056, Final Batch Loss: 1.7256712453672662e-05\n",
      "Epoch 2625, Loss: 0.0016784939161880175, Final Batch Loss: 2.7523836251930334e-05\n",
      "Epoch 2626, Loss: 0.0007990380108822137, Final Batch Loss: 0.00010200279939454049\n",
      "Epoch 2627, Loss: 0.0012264587712706998, Final Batch Loss: 0.0009113427950069308\n",
      "Epoch 2628, Loss: 0.0007894474983913824, Final Batch Loss: 0.0003765705041587353\n",
      "Epoch 2629, Loss: 0.0055861518612800865, Final Batch Loss: 0.00540976133197546\n",
      "Epoch 2630, Loss: 0.00031224398844642565, Final Batch Loss: 9.141590271610767e-05\n",
      "Epoch 2631, Loss: 0.000897785292181652, Final Batch Loss: 0.00011440581147326156\n",
      "Epoch 2632, Loss: 0.0011209965086891316, Final Batch Loss: 0.00015163740317802876\n",
      "Epoch 2633, Loss: 0.0007263651423272677, Final Batch Loss: 5.098323890706524e-05\n",
      "Epoch 2634, Loss: 0.004653915646485984, Final Batch Loss: 0.004375922959297895\n",
      "Epoch 2635, Loss: 0.002774670982034877, Final Batch Loss: 0.0024695468600839376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2636, Loss: 0.0004488451450015418, Final Batch Loss: 0.00020965241128578782\n",
      "Epoch 2637, Loss: 0.0012491626548580825, Final Batch Loss: 0.00012582639465108514\n",
      "Epoch 2638, Loss: 0.0004637890451704152, Final Batch Loss: 4.585936403600499e-05\n",
      "Epoch 2639, Loss: 0.0002409979952062713, Final Batch Loss: 1.1322170394123532e-05\n",
      "Epoch 2640, Loss: 0.002095646908855997, Final Batch Loss: 0.001144189154729247\n",
      "Epoch 2641, Loss: 0.0004511622537393123, Final Batch Loss: 0.00016911671264097095\n",
      "Epoch 2642, Loss: 0.0004602362896548584, Final Batch Loss: 0.0002967797627206892\n",
      "Epoch 2643, Loss: 0.000188001503374835, Final Batch Loss: 0.00011237062426516786\n",
      "Epoch 2644, Loss: 0.00021040864339738619, Final Batch Loss: 4.9592857976676896e-05\n",
      "Epoch 2645, Loss: 0.0013881339109502733, Final Batch Loss: 0.0006383492145687342\n",
      "Epoch 2646, Loss: 0.0006237349662114866, Final Batch Loss: 0.0003238216449972242\n",
      "Epoch 2647, Loss: 0.0025979695201385766, Final Batch Loss: 0.0023643739987164736\n",
      "Epoch 2648, Loss: 0.001214965115650557, Final Batch Loss: 5.699009489035234e-05\n",
      "Epoch 2649, Loss: 0.00044925118709215894, Final Batch Loss: 8.077372331172228e-05\n",
      "Epoch 2650, Loss: 0.0004390139220049605, Final Batch Loss: 0.00011207589705009013\n",
      "Epoch 2651, Loss: 0.00021946031847619452, Final Batch Loss: 1.7503971321275458e-05\n",
      "Epoch 2652, Loss: 0.00021365149586927146, Final Batch Loss: 2.3906482965685427e-05\n",
      "Epoch 2653, Loss: 0.0003763366548810154, Final Batch Loss: 6.225338438525796e-05\n",
      "Epoch 2654, Loss: 0.0008242167532444, Final Batch Loss: 0.00017287800437770784\n",
      "Epoch 2655, Loss: 0.0005053252098150551, Final Batch Loss: 0.0002709781692828983\n",
      "Epoch 2656, Loss: 0.0023804910597391427, Final Batch Loss: 7.899707998149097e-05\n",
      "Epoch 2657, Loss: 0.0009571066038915887, Final Batch Loss: 0.00014502914564218372\n",
      "Epoch 2658, Loss: 0.00180593338154722, Final Batch Loss: 6.948020018171519e-05\n",
      "Epoch 2659, Loss: 0.0007304896571440622, Final Batch Loss: 0.00032097447547130287\n",
      "Epoch 2660, Loss: 0.008009977813344449, Final Batch Loss: 0.005071424413472414\n",
      "Epoch 2661, Loss: 0.0003400789009901928, Final Batch Loss: 2.86103841062868e-05\n",
      "Epoch 2662, Loss: 0.00021738625582656823, Final Batch Loss: 7.660545088583604e-05\n",
      "Epoch 2663, Loss: 0.0008485703001497313, Final Batch Loss: 0.0004801943141501397\n",
      "Epoch 2664, Loss: 0.00034306326233490836, Final Batch Loss: 0.0002920037950389087\n",
      "Epoch 2665, Loss: 0.0021272735257298336, Final Batch Loss: 1.4448168258240912e-05\n",
      "Epoch 2666, Loss: 0.008787155209574848, Final Batch Loss: 0.0003066417993977666\n",
      "Epoch 2667, Loss: 0.000390019618862425, Final Batch Loss: 0.0002868815208785236\n",
      "Epoch 2668, Loss: 6.755337199138012e-05, Final Batch Loss: 1.1712855666701216e-05\n",
      "Epoch 2669, Loss: 0.0016429079732915852, Final Batch Loss: 0.0009450560319237411\n",
      "Epoch 2670, Loss: 0.00023328752649831586, Final Batch Loss: 6.894595571793616e-05\n",
      "Epoch 2671, Loss: 0.00018335024924454046, Final Batch Loss: 9.558901183481794e-06\n",
      "Epoch 2672, Loss: 0.0030209504839149304, Final Batch Loss: 7.289346103789285e-05\n",
      "Epoch 2673, Loss: 0.00038093552939244546, Final Batch Loss: 0.0001509585854364559\n",
      "Epoch 2674, Loss: 0.044035465480192215, Final Batch Loss: 0.04398822784423828\n",
      "Epoch 2675, Loss: 0.0003066122953896411, Final Batch Loss: 6.204617238836363e-05\n",
      "Epoch 2676, Loss: 0.009726685757414089, Final Batch Loss: 0.0004881868080701679\n",
      "Epoch 2677, Loss: 0.003965159310610034, Final Batch Loss: 7.898824696894735e-05\n",
      "Epoch 2678, Loss: 0.0019836390201817267, Final Batch Loss: 3.875133552355692e-05\n",
      "Epoch 2679, Loss: 0.016024560660298448, Final Batch Loss: 0.014843223616480827\n",
      "Epoch 2680, Loss: 0.00026988501122104935, Final Batch Loss: 4.124972110730596e-05\n",
      "Epoch 2681, Loss: 0.008882091869963915, Final Batch Loss: 1.8267646737513132e-05\n",
      "Epoch 2682, Loss: 0.00463454941927921, Final Batch Loss: 0.00014140531129669398\n",
      "Epoch 2683, Loss: 0.002321782012586482, Final Batch Loss: 0.0012040507281199098\n",
      "Epoch 2684, Loss: 0.07086509351574932, Final Batch Loss: 0.0706329271197319\n",
      "Epoch 2685, Loss: 0.0007124653984647011, Final Batch Loss: 1.9368146240594797e-05\n",
      "Epoch 2686, Loss: 0.010233919849270023, Final Batch Loss: 8.271009573945776e-05\n",
      "Epoch 2687, Loss: 0.0004540792178886477, Final Batch Loss: 0.00016022854833863676\n",
      "Epoch 2688, Loss: 0.0003223433450330049, Final Batch Loss: 6.378099351422861e-05\n",
      "Epoch 2689, Loss: 0.01196216886091861, Final Batch Loss: 1.6774352843640372e-05\n",
      "Epoch 2690, Loss: 0.0002529306511860341, Final Batch Loss: 1.89398524526041e-05\n",
      "Epoch 2691, Loss: 0.0007985689226188697, Final Batch Loss: 0.000330666167428717\n",
      "Epoch 2692, Loss: 0.0015902925879345275, Final Batch Loss: 0.0010108513524755836\n",
      "Epoch 2693, Loss: 0.0017541262204758823, Final Batch Loss: 0.00011941770208068192\n",
      "Epoch 2694, Loss: 0.0008041962464631069, Final Batch Loss: 1.5369001630460843e-05\n",
      "Epoch 2695, Loss: 0.0009497775026829913, Final Batch Loss: 0.0003312396293040365\n",
      "Epoch 2696, Loss: 0.0002663118630152894, Final Batch Loss: 1.6570846128161065e-05\n",
      "Epoch 2697, Loss: 0.0004836720981984399, Final Batch Loss: 0.0002283319045091048\n",
      "Epoch 2698, Loss: 0.024051180211245082, Final Batch Loss: 0.00010057399049401283\n",
      "Epoch 2699, Loss: 0.0011690053943311796, Final Batch Loss: 0.00026889555738307536\n",
      "Epoch 2700, Loss: 0.012785407830961049, Final Batch Loss: 0.011472822166979313\n",
      "Epoch 2701, Loss: 0.007664416174520738, Final Batch Loss: 2.7508154744282365e-05\n",
      "Epoch 2702, Loss: 0.0012263231474207714, Final Batch Loss: 0.0005776081816293299\n",
      "Epoch 2703, Loss: 0.00054595652181888, Final Batch Loss: 0.00015170923143159598\n",
      "Epoch 2704, Loss: 0.009368827737489482, Final Batch Loss: 0.00022099622583482414\n",
      "Epoch 2705, Loss: 0.0006784513680031523, Final Batch Loss: 7.208534225355834e-05\n",
      "Epoch 2706, Loss: 0.0001912962306960253, Final Batch Loss: 2.105129351548385e-05\n",
      "Epoch 2707, Loss: 0.0017443779688619543, Final Batch Loss: 5.645493001793511e-05\n",
      "Epoch 2708, Loss: 0.0005534094962058589, Final Batch Loss: 0.0001299819559790194\n",
      "Epoch 2709, Loss: 0.0006710621091770008, Final Batch Loss: 0.0004360031452961266\n",
      "Epoch 2710, Loss: 0.013089586256683106, Final Batch Loss: 0.012831231579184532\n",
      "Epoch 2711, Loss: 0.0010260465642204508, Final Batch Loss: 0.0004275594255886972\n",
      "Epoch 2712, Loss: 0.0011192054225830361, Final Batch Loss: 0.0004680764686781913\n",
      "Epoch 2713, Loss: 0.005876128692761995, Final Batch Loss: 0.0001396330917486921\n",
      "Epoch 2714, Loss: 0.0011161238508066162, Final Batch Loss: 0.0004495686152949929\n",
      "Epoch 2715, Loss: 0.0012999119571759365, Final Batch Loss: 0.0005603600875474513\n",
      "Epoch 2716, Loss: 0.0010751252993941307, Final Batch Loss: 0.000386894796974957\n",
      "Epoch 2717, Loss: 0.001654215855523944, Final Batch Loss: 0.000505569449160248\n",
      "Epoch 2718, Loss: 0.0013004585925955325, Final Batch Loss: 0.0001507000415585935\n",
      "Epoch 2719, Loss: 0.00168437889078632, Final Batch Loss: 3.9065576856955886e-05\n",
      "Epoch 2720, Loss: 0.0009568193345330656, Final Batch Loss: 0.0001023368677124381\n",
      "Epoch 2721, Loss: 0.0011904430139111355, Final Batch Loss: 0.0009022603626362979\n",
      "Epoch 2722, Loss: 0.04829706893360708, Final Batch Loss: 0.048093538731336594\n",
      "Epoch 2723, Loss: 0.0018966200295835733, Final Batch Loss: 8.36121616885066e-05\n",
      "Epoch 2724, Loss: 0.0004949901122017764, Final Batch Loss: 6.570241384906694e-05\n",
      "Epoch 2725, Loss: 0.0010314644569007214, Final Batch Loss: 7.647921302122995e-05\n",
      "Epoch 2726, Loss: 0.0019465002551442012, Final Batch Loss: 0.0012148454552516341\n",
      "Epoch 2727, Loss: 0.001539277916890569, Final Batch Loss: 0.0002419779048068449\n",
      "Epoch 2728, Loss: 0.0007297819829545915, Final Batch Loss: 0.0004453809524420649\n",
      "Epoch 2729, Loss: 0.0006407648179447278, Final Batch Loss: 0.00010060459317173809\n",
      "Epoch 2730, Loss: 0.000432349115726538, Final Batch Loss: 0.0001487856061430648\n",
      "Epoch 2731, Loss: 0.0008656556019559503, Final Batch Loss: 0.0001285482430830598\n",
      "Epoch 2732, Loss: 0.00033195436299138237, Final Batch Loss: 0.00023558983230032027\n",
      "Epoch 2733, Loss: 0.0006941331812413409, Final Batch Loss: 6.25581742497161e-05\n",
      "Epoch 2734, Loss: 0.000825576062197797, Final Batch Loss: 0.000264097674516961\n",
      "Epoch 2735, Loss: 0.0018440714702592231, Final Batch Loss: 0.001381085254251957\n",
      "Epoch 2736, Loss: 0.004389425288536586, Final Batch Loss: 0.00018923207244370133\n",
      "Epoch 2737, Loss: 0.0008707240485819057, Final Batch Loss: 0.0004014165897388011\n",
      "Epoch 2738, Loss: 0.0015622493374394253, Final Batch Loss: 0.00014055742940399796\n",
      "Epoch 2739, Loss: 0.00041840346239041537, Final Batch Loss: 8.300336776301265e-05\n",
      "Epoch 2740, Loss: 0.00017434779510949738, Final Batch Loss: 2.3122342099668458e-05\n",
      "Epoch 2741, Loss: 0.0008524876393494196, Final Batch Loss: 0.00047280697617679834\n",
      "Epoch 2742, Loss: 0.0007655612716916949, Final Batch Loss: 0.00016854806744959205\n",
      "Epoch 2743, Loss: 0.0008433985130977817, Final Batch Loss: 0.000689737789798528\n",
      "Epoch 2744, Loss: 0.001699558604741469, Final Batch Loss: 0.0006064861081540585\n",
      "Epoch 2745, Loss: 0.007836138887796551, Final Batch Loss: 0.00413384847342968\n",
      "Epoch 2746, Loss: 0.0020989791373722255, Final Batch Loss: 0.0012677646009251475\n",
      "Epoch 2747, Loss: 0.008932749369705562, Final Batch Loss: 9.136671724263579e-05\n",
      "Epoch 2748, Loss: 0.0006132323105703108, Final Batch Loss: 6.71587695251219e-05\n",
      "Epoch 2749, Loss: 0.0008806797413853928, Final Batch Loss: 0.0006934720440767705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2750, Loss: 0.00026425951000419445, Final Batch Loss: 2.5958637706935406e-05\n",
      "Epoch 2751, Loss: 0.00044129219531896524, Final Batch Loss: 5.167627750779502e-05\n",
      "Epoch 2752, Loss: 0.0019078889454249293, Final Batch Loss: 0.0004872341814916581\n",
      "Epoch 2753, Loss: 0.0005863004298589658, Final Batch Loss: 0.00017735447909217328\n",
      "Epoch 2754, Loss: 0.0010936184044112451, Final Batch Loss: 0.0006868663476780057\n",
      "Epoch 2755, Loss: 0.0017153511653305031, Final Batch Loss: 0.00026431583683006465\n",
      "Epoch 2756, Loss: 0.0011726502616511425, Final Batch Loss: 0.0003853129455819726\n",
      "Epoch 2757, Loss: 0.0014235812013794202, Final Batch Loss: 0.00014279130846261978\n",
      "Epoch 2758, Loss: 0.0013790220618830062, Final Batch Loss: 0.0002694182621780783\n",
      "Epoch 2759, Loss: 0.0032490204903297126, Final Batch Loss: 0.0023611660581082106\n",
      "Epoch 2760, Loss: 0.006436796204070561, Final Batch Loss: 0.0003908687795046717\n",
      "Epoch 2761, Loss: 0.004350280942162499, Final Batch Loss: 0.0026052563916891813\n",
      "Epoch 2762, Loss: 0.0013882130588172004, Final Batch Loss: 6.744275742676109e-05\n",
      "Epoch 2763, Loss: 0.0003297134753665887, Final Batch Loss: 7.954298780532554e-05\n",
      "Epoch 2764, Loss: 0.0005998181004542857, Final Batch Loss: 5.2548624807968736e-05\n",
      "Epoch 2765, Loss: 0.001786929031368345, Final Batch Loss: 0.0004070500726811588\n",
      "Epoch 2766, Loss: 0.003137151616101619, Final Batch Loss: 0.0013925792882218957\n",
      "Epoch 2767, Loss: 0.0004942980303894728, Final Batch Loss: 0.0002557758998591453\n",
      "Epoch 2768, Loss: 0.0007549294241471216, Final Batch Loss: 0.00018407274910714477\n",
      "Epoch 2769, Loss: 0.00283839426265331, Final Batch Loss: 0.0018325848504900932\n",
      "Epoch 2770, Loss: 0.004941933060763404, Final Batch Loss: 0.000168438971741125\n",
      "Epoch 2771, Loss: 0.001363060437142849, Final Batch Loss: 0.00034778888220898807\n",
      "Epoch 2772, Loss: 0.0008304784823849332, Final Batch Loss: 0.00013529082934837788\n",
      "Epoch 2773, Loss: 0.0007324780453927815, Final Batch Loss: 0.0002302895882166922\n",
      "Epoch 2774, Loss: 0.0025621361601224635, Final Batch Loss: 5.3563217079499736e-05\n",
      "Epoch 2775, Loss: 0.0003308488376205787, Final Batch Loss: 0.0001686716132098809\n",
      "Epoch 2776, Loss: 0.00018340836504648905, Final Batch Loss: 2.5724226361489855e-05\n",
      "Epoch 2777, Loss: 0.0003502568815747509, Final Batch Loss: 1.5589890608680435e-05\n",
      "Epoch 2778, Loss: 0.0004101470622117631, Final Batch Loss: 0.00010838551679626107\n",
      "Epoch 2779, Loss: 0.001516000964329578, Final Batch Loss: 0.0010866790544241667\n",
      "Epoch 2780, Loss: 0.0036643942239606986, Final Batch Loss: 0.003520504804328084\n",
      "Epoch 2781, Loss: 0.0007190944334070082, Final Batch Loss: 1.0476552233740222e-05\n",
      "Epoch 2782, Loss: 0.00030441867420449853, Final Batch Loss: 8.31290235510096e-05\n",
      "Epoch 2783, Loss: 0.0006686063370580086, Final Batch Loss: 2.3483933546231128e-05\n",
      "Epoch 2784, Loss: 0.0009453862821828807, Final Batch Loss: 4.1684415919007733e-05\n",
      "Epoch 2785, Loss: 0.03653802315238863, Final Batch Loss: 9.194354061037302e-05\n",
      "Epoch 2786, Loss: 0.0009623684964026324, Final Batch Loss: 0.0003456244885455817\n",
      "Epoch 2787, Loss: 0.002947073633549735, Final Batch Loss: 0.0019945381209254265\n",
      "Epoch 2788, Loss: 0.0022664516109216493, Final Batch Loss: 0.0017187678022310138\n",
      "Epoch 2789, Loss: 0.002883313864003867, Final Batch Loss: 0.00029268715297803283\n",
      "Epoch 2790, Loss: 0.0011248365190112963, Final Batch Loss: 0.00023022726236376911\n",
      "Epoch 2791, Loss: 0.00123782895389013, Final Batch Loss: 0.0004835203289985657\n",
      "Epoch 2792, Loss: 0.01957843604759546, Final Batch Loss: 0.016770733520388603\n",
      "Epoch 2793, Loss: 0.0005646790950777358, Final Batch Loss: 9.4746201284579e-06\n",
      "Epoch 2794, Loss: 0.000826767849503085, Final Batch Loss: 0.0006193304434418678\n",
      "Epoch 2795, Loss: 0.000738688221645134, Final Batch Loss: 0.0003320715914014727\n",
      "Epoch 2796, Loss: 0.0006635228082814137, Final Batch Loss: 1.4033113075129222e-05\n",
      "Epoch 2797, Loss: 0.035295864385261666, Final Batch Loss: 0.03513575717806816\n",
      "Epoch 2798, Loss: 0.005888844360015355, Final Batch Loss: 0.005214743781834841\n",
      "Epoch 2799, Loss: 0.0027284742682240903, Final Batch Loss: 2.1393760107457638e-05\n",
      "Epoch 2800, Loss: 0.0012041069567203522, Final Batch Loss: 0.00022244441788643599\n",
      "Epoch 2801, Loss: 0.007499255996663123, Final Batch Loss: 0.00026639836141839623\n",
      "Epoch 2802, Loss: 0.004597228253260255, Final Batch Loss: 0.00425148569047451\n",
      "Epoch 2803, Loss: 0.01821113156620413, Final Batch Loss: 0.017893711104989052\n",
      "Epoch 2804, Loss: 0.0016042912211560179, Final Batch Loss: 1.5175395674305037e-05\n",
      "Epoch 2805, Loss: 0.002153316727344645, Final Batch Loss: 0.0002328990085516125\n",
      "Epoch 2806, Loss: 0.02259806623624172, Final Batch Loss: 0.00038973777554929256\n",
      "Epoch 2807, Loss: 0.00036365977211971767, Final Batch Loss: 3.9850969187682495e-05\n",
      "Epoch 2808, Loss: 0.0003518184894346632, Final Batch Loss: 6.530057726195082e-05\n",
      "Epoch 2809, Loss: 0.0008983727966551669, Final Batch Loss: 9.491029777564108e-05\n",
      "Epoch 2810, Loss: 0.001892407330160495, Final Batch Loss: 0.0016333925304934382\n",
      "Epoch 2811, Loss: 0.001807343571272213, Final Batch Loss: 0.00022808994981460273\n",
      "Epoch 2812, Loss: 0.0028074389410903677, Final Batch Loss: 0.0007261554128490388\n",
      "Epoch 2813, Loss: 0.0008332426405104343, Final Batch Loss: 0.0003186594694852829\n",
      "Epoch 2814, Loss: 0.0012555383145809174, Final Batch Loss: 0.00012531131505966187\n",
      "Epoch 2815, Loss: 0.0012311982864048332, Final Batch Loss: 3.597367322072387e-05\n",
      "Epoch 2816, Loss: 0.0007624667778145522, Final Batch Loss: 0.00035430394927971065\n",
      "Epoch 2817, Loss: 0.004017965042294236, Final Batch Loss: 1.4609482605010271e-05\n",
      "Epoch 2818, Loss: 0.0015011434225016274, Final Batch Loss: 0.00031189079163596034\n",
      "Epoch 2819, Loss: 0.0015146889491006732, Final Batch Loss: 0.00042105873581022024\n",
      "Epoch 2820, Loss: 0.000907933121197857, Final Batch Loss: 0.00023160711862146854\n",
      "Epoch 2821, Loss: 0.0007344074820139213, Final Batch Loss: 2.418993790342938e-05\n",
      "Epoch 2822, Loss: 0.0006661941260972526, Final Batch Loss: 2.929340917035006e-05\n",
      "Epoch 2823, Loss: 0.0008314683218486607, Final Batch Loss: 6.980190664762631e-05\n",
      "Epoch 2824, Loss: 0.0005809328868053854, Final Batch Loss: 0.00018012845248449594\n",
      "Epoch 2825, Loss: 0.014315983826236334, Final Batch Loss: 0.0002514048828743398\n",
      "Epoch 2826, Loss: 0.0004411307236296125, Final Batch Loss: 0.00011304555664537475\n",
      "Epoch 2827, Loss: 0.002920107690442819, Final Batch Loss: 0.00019608807633630931\n",
      "Epoch 2828, Loss: 0.002152355602447642, Final Batch Loss: 4.850669574807398e-05\n",
      "Epoch 2829, Loss: 0.0012455595860956237, Final Batch Loss: 0.00018838582036551088\n",
      "Epoch 2830, Loss: 0.0008269023091997951, Final Batch Loss: 0.0003932148974854499\n",
      "Epoch 2831, Loss: 0.0013209423123043962, Final Batch Loss: 6.647838017670438e-05\n",
      "Epoch 2832, Loss: 0.0008394899268751033, Final Batch Loss: 8.361691288882867e-05\n",
      "Epoch 2833, Loss: 0.007101566756318789, Final Batch Loss: 0.004809952806681395\n",
      "Epoch 2834, Loss: 0.0006653635355178267, Final Batch Loss: 0.00012968963710591197\n",
      "Epoch 2835, Loss: 0.0006613774166908115, Final Batch Loss: 0.00013205788854975253\n",
      "Epoch 2836, Loss: 0.00088486447930336, Final Batch Loss: 0.00010866529191844165\n",
      "Epoch 2837, Loss: 0.0006235152104636654, Final Batch Loss: 0.00020087113080080599\n",
      "Epoch 2838, Loss: 0.0007588376029161736, Final Batch Loss: 0.00018549160449765623\n",
      "Epoch 2839, Loss: 0.0006818502733949572, Final Batch Loss: 7.01497629052028e-05\n",
      "Epoch 2840, Loss: 0.0009052871318999678, Final Batch Loss: 0.0006845443858765066\n",
      "Epoch 2841, Loss: 0.0003734772799361963, Final Batch Loss: 3.384766023373231e-05\n",
      "Epoch 2842, Loss: 0.0014319129986688495, Final Batch Loss: 0.0005435029161162674\n",
      "Epoch 2843, Loss: 0.021759871058748104, Final Batch Loss: 0.0020821073558181524\n",
      "Epoch 2844, Loss: 0.00040015248305280693, Final Batch Loss: 0.00014439091319218278\n",
      "Epoch 2845, Loss: 0.002205877766755293, Final Batch Loss: 1.9870172764058225e-05\n",
      "Epoch 2846, Loss: 0.000535084334842395, Final Batch Loss: 0.00033186038490384817\n",
      "Epoch 2847, Loss: 0.0004335242228989955, Final Batch Loss: 4.092740346095525e-05\n",
      "Epoch 2848, Loss: 0.000527863077877555, Final Batch Loss: 0.0001144415364251472\n",
      "Epoch 2849, Loss: 0.006292228119491483, Final Batch Loss: 2.9916829589637928e-05\n",
      "Epoch 2850, Loss: 0.0006164880833239295, Final Batch Loss: 3.580813790904358e-05\n",
      "Epoch 2851, Loss: 0.0005188833310967311, Final Batch Loss: 0.0001357055443804711\n",
      "Epoch 2852, Loss: 0.00129321184795117, Final Batch Loss: 8.367015834664926e-05\n",
      "Epoch 2853, Loss: 0.00015270275980583392, Final Batch Loss: 5.162903107702732e-05\n",
      "Epoch 2854, Loss: 0.00016030596452765167, Final Batch Loss: 4.0550134144723415e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2855, Loss: 0.00035744273554882966, Final Batch Loss: 0.00022604876721743494\n",
      "Epoch 2856, Loss: 0.00048824598343344405, Final Batch Loss: 0.00014827951963525265\n",
      "Epoch 2857, Loss: 0.0005376822227844968, Final Batch Loss: 0.00025368278147652745\n",
      "Epoch 2858, Loss: 0.00048121412692125887, Final Batch Loss: 0.00033137795981019735\n",
      "Epoch 2859, Loss: 0.0005598372522399586, Final Batch Loss: 3.864217887894483e-06\n",
      "Epoch 2860, Loss: 0.00038127972948132083, Final Batch Loss: 9.375314402859658e-05\n",
      "Epoch 2861, Loss: 0.00032010675386118237, Final Batch Loss: 2.62814082816476e-05\n",
      "Epoch 2862, Loss: 0.00019087990222033113, Final Batch Loss: 0.00012398195394780487\n",
      "Epoch 2863, Loss: 0.0005885021892026998, Final Batch Loss: 8.027740841498598e-05\n",
      "Epoch 2864, Loss: 0.000975664377619978, Final Batch Loss: 0.0007021647179499269\n",
      "Epoch 2865, Loss: 0.0005069580729468726, Final Batch Loss: 6.197769107529894e-05\n",
      "Epoch 2866, Loss: 0.0006938638325664215, Final Batch Loss: 4.351565439719707e-05\n",
      "Epoch 2867, Loss: 0.0019106009640381671, Final Batch Loss: 0.0011169015197083354\n",
      "Epoch 2868, Loss: 0.0002748461120063439, Final Batch Loss: 6.776325608370826e-05\n",
      "Epoch 2869, Loss: 0.00046817687689326704, Final Batch Loss: 8.26169052743353e-05\n",
      "Epoch 2870, Loss: 0.0002613567367006908, Final Batch Loss: 1.3189092896936927e-05\n",
      "Epoch 2871, Loss: 0.00018906855530076427, Final Batch Loss: 8.449350389128085e-06\n",
      "Epoch 2872, Loss: 0.0007762713103147689, Final Batch Loss: 0.000587797723710537\n",
      "Epoch 2873, Loss: 0.02064090436033439, Final Batch Loss: 6.68997090542689e-05\n",
      "Epoch 2874, Loss: 0.0011803049565060064, Final Batch Loss: 0.0008453677291981876\n",
      "Epoch 2875, Loss: 0.0026859772769967094, Final Batch Loss: 0.00034531790879555047\n",
      "Epoch 2876, Loss: 0.0011028045555576682, Final Batch Loss: 0.0006259837537072599\n",
      "Epoch 2877, Loss: 0.015788937802426517, Final Batch Loss: 0.011933134868741035\n",
      "Epoch 2878, Loss: 0.0001932287195813842, Final Batch Loss: 0.00013075367314741015\n",
      "Epoch 2879, Loss: 0.00032665571961842943, Final Batch Loss: 0.0001573946647113189\n",
      "Epoch 2880, Loss: 0.0006938373880984727, Final Batch Loss: 5.675469947163947e-05\n",
      "Epoch 2881, Loss: 0.03127204330303357, Final Batch Loss: 0.030801787972450256\n",
      "Epoch 2882, Loss: 0.0005161934168427251, Final Batch Loss: 1.4433033356908709e-05\n",
      "Epoch 2883, Loss: 6.674187352473382e-05, Final Batch Loss: 1.1529625226103235e-05\n",
      "Epoch 2884, Loss: 0.0006821746646892279, Final Batch Loss: 0.00022950007405597717\n",
      "Epoch 2885, Loss: 0.0008799745846772566, Final Batch Loss: 0.00015791649639140815\n",
      "Epoch 2886, Loss: 0.0002844702175934799, Final Batch Loss: 1.980737579287961e-05\n",
      "Epoch 2887, Loss: 0.00013758820568909869, Final Batch Loss: 3.381027272553183e-05\n",
      "Epoch 2888, Loss: 0.0025314503654954024, Final Batch Loss: 0.002273476915434003\n",
      "Epoch 2889, Loss: 0.00320322866900824, Final Batch Loss: 5.4662785260006785e-05\n",
      "Epoch 2890, Loss: 0.025800503888604, Final Batch Loss: 0.0003486339992377907\n",
      "Epoch 2891, Loss: 0.0003704788614413701, Final Batch Loss: 0.00022718908439856023\n",
      "Epoch 2892, Loss: 0.00018494465257390402, Final Batch Loss: 3.1430954550160095e-05\n",
      "Epoch 2893, Loss: 0.0008250753444372094, Final Batch Loss: 1.0369548363087233e-05\n",
      "Epoch 2894, Loss: 0.00021928206115262583, Final Batch Loss: 5.997171683702618e-05\n",
      "Epoch 2895, Loss: 0.001055657776305452, Final Batch Loss: 0.00019311040523461998\n",
      "Epoch 2896, Loss: 0.0002752287946350407, Final Batch Loss: 5.595261973212473e-05\n",
      "Epoch 2897, Loss: 0.00048816599701240193, Final Batch Loss: 1.8475284377927892e-05\n",
      "Epoch 2898, Loss: 0.005598898365860805, Final Batch Loss: 5.616530324914493e-05\n",
      "Epoch 2899, Loss: 0.036259210834032274, Final Batch Loss: 2.9051958335912786e-05\n",
      "Epoch 2900, Loss: 0.0010246186284348369, Final Batch Loss: 0.0003554837603587657\n",
      "Epoch 2901, Loss: 0.0063601498695788905, Final Batch Loss: 0.0045930854976177216\n",
      "Epoch 2902, Loss: 0.000177851884473057, Final Batch Loss: 1.1828406968561467e-05\n",
      "Epoch 2903, Loss: 0.023681268270593137, Final Batch Loss: 0.003945472184568644\n",
      "Epoch 2904, Loss: 0.0011653700494207442, Final Batch Loss: 0.000608414935413748\n",
      "Epoch 2905, Loss: 0.0003094862713624025, Final Batch Loss: 0.00017744017532095313\n",
      "Epoch 2906, Loss: 0.00023304234855459072, Final Batch Loss: 0.00010264450975228101\n",
      "Epoch 2907, Loss: 0.00034673386107897386, Final Batch Loss: 7.529069989686832e-05\n",
      "Epoch 2908, Loss: 0.001081376161891967, Final Batch Loss: 0.000976894749328494\n",
      "Epoch 2909, Loss: 0.005946706703980453, Final Batch Loss: 0.00022302586876321584\n",
      "Epoch 2910, Loss: 0.0009239508744940395, Final Batch Loss: 0.000786818447522819\n",
      "Epoch 2911, Loss: 0.0009301632089773193, Final Batch Loss: 0.0002556078543420881\n",
      "Epoch 2912, Loss: 0.001474191463785246, Final Batch Loss: 0.00020159356063231826\n",
      "Epoch 2913, Loss: 0.00048687076377973426, Final Batch Loss: 0.00022639297822024673\n",
      "Epoch 2914, Loss: 0.0010997096105711535, Final Batch Loss: 0.00018797423399519175\n",
      "Epoch 2915, Loss: 0.00025562310838722624, Final Batch Loss: 2.0682640752056614e-05\n",
      "Epoch 2916, Loss: 0.0005394003019318916, Final Batch Loss: 0.0003128168173134327\n",
      "Epoch 2917, Loss: 0.0010372177475801436, Final Batch Loss: 2.910062721639406e-05\n",
      "Epoch 2918, Loss: 0.0006596167768293526, Final Batch Loss: 0.0005751397693529725\n",
      "Epoch 2919, Loss: 0.004147904634010047, Final Batch Loss: 0.0033978468272835016\n",
      "Epoch 2920, Loss: 0.0015738689398858696, Final Batch Loss: 0.0001254788803635165\n",
      "Epoch 2921, Loss: 0.0002629468035593163, Final Batch Loss: 0.00013231039338279516\n",
      "Epoch 2922, Loss: 0.00034956144736497663, Final Batch Loss: 1.8059867215924896e-05\n",
      "Epoch 2923, Loss: 0.0018221360660390928, Final Batch Loss: 4.5440407120622694e-05\n",
      "Epoch 2924, Loss: 0.0013962695811642334, Final Batch Loss: 0.00010522364755161107\n",
      "Epoch 2925, Loss: 0.0009255251570721157, Final Batch Loss: 7.662346615688875e-05\n",
      "Epoch 2926, Loss: 0.0005085498851258308, Final Batch Loss: 3.580380871426314e-05\n",
      "Epoch 2927, Loss: 0.001004420242679771, Final Batch Loss: 4.0135324525181204e-05\n",
      "Epoch 2928, Loss: 0.011012667942850385, Final Batch Loss: 0.00012602133210748434\n",
      "Epoch 2929, Loss: 0.0007699866037000902, Final Batch Loss: 6.387098255800083e-05\n",
      "Epoch 2930, Loss: 0.001517111057182774, Final Batch Loss: 0.0006298419320955873\n",
      "Epoch 2931, Loss: 0.0006385875021805987, Final Batch Loss: 0.0003129068936686963\n",
      "Epoch 2932, Loss: 0.039987791489693336, Final Batch Loss: 0.038456838577985764\n",
      "Epoch 2933, Loss: 0.001667631986492779, Final Batch Loss: 0.0014038296649232507\n",
      "Epoch 2934, Loss: 0.029540333955083042, Final Batch Loss: 0.00017767157987691462\n",
      "Epoch 2935, Loss: 0.0004941812294418924, Final Batch Loss: 0.00022320510470308363\n",
      "Epoch 2936, Loss: 0.00023563330796605442, Final Batch Loss: 1.7046100765583105e-05\n",
      "Epoch 2937, Loss: 0.0006644330933340825, Final Batch Loss: 0.00018620600167196244\n",
      "Epoch 2938, Loss: 0.00021254003149806522, Final Batch Loss: 1.0130785085493699e-05\n",
      "Epoch 2939, Loss: 0.0005822024686494842, Final Batch Loss: 0.00014013817417435348\n",
      "Epoch 2940, Loss: 0.0029204583406681195, Final Batch Loss: 0.002589184558019042\n",
      "Epoch 2941, Loss: 0.005888627638341859, Final Batch Loss: 0.0004113338072784245\n",
      "Epoch 2942, Loss: 0.0017514574974484276, Final Batch Loss: 0.0007186834118328989\n",
      "Epoch 2943, Loss: 0.0005846487474627793, Final Batch Loss: 7.238826947286725e-05\n",
      "Epoch 2944, Loss: 0.0015024037602415774, Final Batch Loss: 0.0004108303692191839\n",
      "Epoch 2945, Loss: 0.0003563256614143029, Final Batch Loss: 1.0334086255170405e-05\n",
      "Epoch 2946, Loss: 0.011665535348583944, Final Batch Loss: 0.011095674708485603\n",
      "Epoch 2947, Loss: 0.0025651981704868376, Final Batch Loss: 0.0003199551720172167\n",
      "Epoch 2948, Loss: 0.0010444137151353061, Final Batch Loss: 0.0008284750510938466\n",
      "Epoch 2949, Loss: 0.0019113636517431587, Final Batch Loss: 0.0011649392545223236\n",
      "Epoch 2950, Loss: 0.001935790067363996, Final Batch Loss: 0.0014487027656286955\n",
      "Epoch 2951, Loss: 0.0009611053828848526, Final Batch Loss: 0.00013944397505838424\n",
      "Epoch 2952, Loss: 0.0008397355995839462, Final Batch Loss: 4.792357503902167e-05\n",
      "Epoch 2953, Loss: 0.00024125594427459873, Final Batch Loss: 4.4412026909412816e-05\n",
      "Epoch 2954, Loss: 0.020940341346431524, Final Batch Loss: 0.0003112730919383466\n",
      "Epoch 2955, Loss: 0.0006051715390640311, Final Batch Loss: 0.00032115785870701075\n",
      "Epoch 2956, Loss: 0.0036147053469903767, Final Batch Loss: 3.5703356843441725e-05\n",
      "Epoch 2957, Loss: 0.0040462390024913475, Final Batch Loss: 0.0001044421733240597\n",
      "Epoch 2958, Loss: 0.0007542334642494097, Final Batch Loss: 0.00017694711277727038\n",
      "Epoch 2959, Loss: 0.0003653015592135489, Final Batch Loss: 0.00016286340542137623\n",
      "Epoch 2960, Loss: 0.0006609719603147823, Final Batch Loss: 3.1530802516499534e-05\n",
      "Epoch 2961, Loss: 0.00042702867358457297, Final Batch Loss: 0.00025483561330474913\n",
      "Epoch 2962, Loss: 0.0012327645963523537, Final Batch Loss: 0.0007662146235816181\n",
      "Epoch 2963, Loss: 0.0021613162934954744, Final Batch Loss: 1.1833773896796629e-05\n",
      "Epoch 2964, Loss: 0.0031550763142149663, Final Batch Loss: 0.002772674895823002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2965, Loss: 0.0005690072503057308, Final Batch Loss: 0.00010508595005376264\n",
      "Epoch 2966, Loss: 0.00038509921614604536, Final Batch Loss: 0.00018358339730184525\n",
      "Epoch 2967, Loss: 0.01373778865672648, Final Batch Loss: 0.0022323934826999903\n",
      "Epoch 2968, Loss: 0.0006854930543340743, Final Batch Loss: 0.00039333131280727684\n",
      "Epoch 2969, Loss: 0.0008819210561341606, Final Batch Loss: 0.0001256341638509184\n",
      "Epoch 2970, Loss: 0.0012602138449437916, Final Batch Loss: 0.0002479382383171469\n",
      "Epoch 2971, Loss: 0.0018497556484362576, Final Batch Loss: 0.0003055738052353263\n",
      "Epoch 2972, Loss: 0.0031952936406014487, Final Batch Loss: 8.809739665593952e-05\n",
      "Epoch 2973, Loss: 0.0005611316446447745, Final Batch Loss: 0.00030273673473857343\n",
      "Epoch 2974, Loss: 0.0008661257452331483, Final Batch Loss: 0.00018772506155073643\n",
      "Epoch 2975, Loss: 0.00027946185946348123, Final Batch Loss: 6.811798084527254e-05\n",
      "Epoch 2976, Loss: 0.0012050908262608573, Final Batch Loss: 0.0007127609569579363\n",
      "Epoch 2977, Loss: 0.0011980595118075144, Final Batch Loss: 3.699080480146222e-05\n",
      "Epoch 2978, Loss: 0.0007018504402367398, Final Batch Loss: 0.0005264173960313201\n",
      "Epoch 2979, Loss: 0.0005097592802485451, Final Batch Loss: 9.429827332496643e-05\n",
      "Epoch 2980, Loss: 0.0007712092556175776, Final Batch Loss: 0.0003592980501707643\n",
      "Epoch 2981, Loss: 0.004843763075768948, Final Batch Loss: 0.003104917472228408\n",
      "Epoch 2982, Loss: 0.0004042489927087445, Final Batch Loss: 0.00027238711481913924\n",
      "Epoch 2983, Loss: 0.005773042566943332, Final Batch Loss: 0.005699676461517811\n",
      "Epoch 2984, Loss: 0.0004693194277933799, Final Batch Loss: 0.00021401364938355982\n",
      "Epoch 2985, Loss: 0.0002749521445366554, Final Batch Loss: 6.746657891198993e-05\n",
      "Epoch 2986, Loss: 0.0010212120978394523, Final Batch Loss: 0.00013521098298951983\n",
      "Epoch 2987, Loss: 0.0004129734197704238, Final Batch Loss: 9.637534276407678e-06\n",
      "Epoch 2988, Loss: 0.0018216010357718915, Final Batch Loss: 6.56617630738765e-05\n",
      "Epoch 2989, Loss: 0.0006435860050260089, Final Batch Loss: 5.4198775615077466e-05\n",
      "Epoch 2990, Loss: 0.0005446859486255562, Final Batch Loss: 1.4337247193907388e-05\n",
      "Epoch 2991, Loss: 0.0005471588010550477, Final Batch Loss: 6.152051355456933e-05\n",
      "Epoch 2992, Loss: 0.0026189525960944593, Final Batch Loss: 0.0019572009332478046\n",
      "Epoch 2993, Loss: 0.00034470714308554307, Final Batch Loss: 0.00025197656941600144\n",
      "Epoch 2994, Loss: 0.0003866124025080353, Final Batch Loss: 6.680105434497818e-05\n",
      "Epoch 2995, Loss: 0.0004392857199491118, Final Batch Loss: 3.549032953742426e-06\n",
      "Epoch 2996, Loss: 0.004057195546920411, Final Batch Loss: 0.0007136808708310127\n",
      "Epoch 2997, Loss: 0.00045112601219443604, Final Batch Loss: 0.0001152626282419078\n",
      "Epoch 2998, Loss: 0.000722741533536464, Final Batch Loss: 0.00034140623756684363\n",
      "Epoch 2999, Loss: 0.00038308373041218147, Final Batch Loss: 9.655964822741225e-05\n",
      "Epoch 3000, Loss: 0.0004256582978996448, Final Batch Loss: 0.00023811050050426275\n",
      "Epoch 3001, Loss: 0.0018767111032502726, Final Batch Loss: 1.6045887605287135e-05\n",
      "Epoch 3002, Loss: 0.002395560499280691, Final Batch Loss: 0.00026109733153134584\n",
      "Epoch 3003, Loss: 0.01783106694347225, Final Batch Loss: 1.5404169971589e-05\n",
      "Epoch 3004, Loss: 0.000223432343773311, Final Batch Loss: 0.00012023903400404379\n",
      "Epoch 3005, Loss: 0.0005474122153827921, Final Batch Loss: 0.00020120482076890767\n",
      "Epoch 3006, Loss: 0.0005465788999572396, Final Batch Loss: 0.0002099229022860527\n",
      "Epoch 3007, Loss: 0.002417691166556324, Final Batch Loss: 5.327501639840193e-05\n",
      "Epoch 3008, Loss: 0.028951984975719824, Final Batch Loss: 0.00015061747399158776\n",
      "Epoch 3009, Loss: 0.00019058277939620893, Final Batch Loss: 2.1908852431806736e-05\n",
      "Epoch 3010, Loss: 0.002756724767095875, Final Batch Loss: 9.945853526005521e-05\n",
      "Epoch 3011, Loss: 0.0002744400371739175, Final Batch Loss: 6.615462916670367e-05\n",
      "Epoch 3012, Loss: 0.08623451410676353, Final Batch Loss: 0.08277114480733871\n",
      "Epoch 3013, Loss: 0.0002645509139256319, Final Batch Loss: 2.7985157430521213e-05\n",
      "Epoch 3014, Loss: 0.001235662683029659, Final Batch Loss: 0.0005238425801508129\n",
      "Epoch 3015, Loss: 0.004412272770423442, Final Batch Loss: 0.0005014179623685777\n",
      "Epoch 3016, Loss: 0.0007349409279413521, Final Batch Loss: 0.00013668200699612498\n",
      "Epoch 3017, Loss: 0.02764897036831826, Final Batch Loss: 0.0006224875105544925\n",
      "Epoch 3018, Loss: 0.00042398058576509356, Final Batch Loss: 0.00012582605995703489\n",
      "Epoch 3019, Loss: 0.00033828634332166985, Final Batch Loss: 8.668910595588386e-05\n",
      "Epoch 3020, Loss: 0.0010124510881723836, Final Batch Loss: 0.0001307820639340207\n",
      "Epoch 3021, Loss: 0.0008066230620897841, Final Batch Loss: 4.761422678711824e-05\n",
      "Epoch 3022, Loss: 0.0003505027707433328, Final Batch Loss: 0.00010388909868197516\n",
      "Epoch 3023, Loss: 0.0003721769608091563, Final Batch Loss: 1.935089676408097e-05\n",
      "Epoch 3024, Loss: 0.0008282087655970827, Final Batch Loss: 0.0005288840620778501\n",
      "Epoch 3025, Loss: 0.0007044107042020187, Final Batch Loss: 0.0005910026957280934\n",
      "Epoch 3026, Loss: 0.0007815583230694756, Final Batch Loss: 6.506236968562007e-05\n",
      "Epoch 3027, Loss: 0.006588663440197706, Final Batch Loss: 0.004451001528650522\n",
      "Epoch 3028, Loss: 0.00029696503770537674, Final Batch Loss: 8.906694711185992e-05\n",
      "Epoch 3029, Loss: 0.0005027740699006245, Final Batch Loss: 9.412673534825444e-05\n",
      "Epoch 3030, Loss: 0.00033587533107493073, Final Batch Loss: 0.00016736684483475983\n",
      "Epoch 3031, Loss: 0.0005793770933451015, Final Batch Loss: 1.249472097697435e-05\n",
      "Epoch 3032, Loss: 0.00015552413424302358, Final Batch Loss: 2.9705624911002815e-05\n",
      "Epoch 3033, Loss: 0.0002965269159176387, Final Batch Loss: 7.336946873692796e-05\n",
      "Epoch 3034, Loss: 0.00017133244409706094, Final Batch Loss: 2.759296421572799e-06\n",
      "Epoch 3035, Loss: 7.555183219665196e-05, Final Batch Loss: 2.503153336874675e-05\n",
      "Epoch 3036, Loss: 0.0001968369324458763, Final Batch Loss: 6.367768219206482e-05\n",
      "Epoch 3037, Loss: 0.0016966426628641784, Final Batch Loss: 0.0004974714247509837\n",
      "Epoch 3038, Loss: 0.0003123486194454017, Final Batch Loss: 1.2105067980883177e-05\n",
      "Epoch 3039, Loss: 0.002122878569934983, Final Batch Loss: 0.0001718494459055364\n",
      "Epoch 3040, Loss: 0.00034929163484775927, Final Batch Loss: 1.9102923033642583e-05\n",
      "Epoch 3041, Loss: 0.00042175249836873263, Final Batch Loss: 0.00017095851944759488\n",
      "Epoch 3042, Loss: 0.0013615317802759819, Final Batch Loss: 0.0008882945403456688\n",
      "Epoch 3043, Loss: 0.0003764105640584603, Final Batch Loss: 0.00014594168169423938\n",
      "Epoch 3044, Loss: 0.00014413106327992864, Final Batch Loss: 5.6543976825196296e-05\n",
      "Epoch 3045, Loss: 0.000532018664671341, Final Batch Loss: 0.0001920971553772688\n",
      "Epoch 3046, Loss: 0.03289224751461006, Final Batch Loss: 6.295354251051322e-05\n",
      "Epoch 3047, Loss: 0.0002877637848541781, Final Batch Loss: 4.364484630059451e-05\n",
      "Epoch 3048, Loss: 0.00024234791453636717, Final Batch Loss: 0.00011164448369527236\n",
      "Epoch 3049, Loss: 0.0004290034348741756, Final Batch Loss: 1.3105819562042598e-05\n",
      "Epoch 3050, Loss: 0.00034648845030460507, Final Batch Loss: 0.00020845604012720287\n",
      "Epoch 3051, Loss: 0.000322660923757212, Final Batch Loss: 4.066981546202442e-06\n",
      "Epoch 3052, Loss: 0.0009059706644620746, Final Batch Loss: 0.00013880972983315587\n",
      "Epoch 3053, Loss: 0.0011754112988455745, Final Batch Loss: 3.124083832517499e-06\n",
      "Epoch 3054, Loss: 0.00018437012658978347, Final Batch Loss: 2.6370618797955103e-05\n",
      "Epoch 3055, Loss: 0.000367055632523261, Final Batch Loss: 0.0001147469665738754\n",
      "Epoch 3056, Loss: 0.0016880967232282273, Final Batch Loss: 0.00106402940582484\n",
      "Epoch 3057, Loss: 0.0016511438561792602, Final Batch Loss: 1.4414993529499043e-05\n",
      "Epoch 3058, Loss: 0.003414432088902686, Final Batch Loss: 0.0001843753270804882\n",
      "Epoch 3059, Loss: 9.468198913964443e-05, Final Batch Loss: 3.59084879164584e-05\n",
      "Epoch 3060, Loss: 0.02777235981920967, Final Batch Loss: 0.02762911282479763\n",
      "Epoch 3061, Loss: 0.015398848845507018, Final Batch Loss: 6.227914127521217e-05\n",
      "Epoch 3062, Loss: 0.0008741574893065263, Final Batch Loss: 2.759691051323898e-05\n",
      "Epoch 3063, Loss: 0.000235260566114448, Final Batch Loss: 8.166191400960088e-05\n",
      "Epoch 3064, Loss: 0.002049414048087783, Final Batch Loss: 0.001783723826520145\n",
      "Epoch 3065, Loss: 0.0004982347527402453, Final Batch Loss: 8.095642260741442e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3066, Loss: 0.0008526417568646139, Final Batch Loss: 0.00016945693641901016\n",
      "Epoch 3067, Loss: 0.001087237280444242, Final Batch Loss: 0.00011921422265004367\n",
      "Epoch 3068, Loss: 0.0005136726031196304, Final Batch Loss: 0.00011336334864608943\n",
      "Epoch 3069, Loss: 0.0014214283000910655, Final Batch Loss: 0.0009142693597823381\n",
      "Epoch 3070, Loss: 0.0004883803012489807, Final Batch Loss: 1.706421244307421e-05\n",
      "Epoch 3071, Loss: 0.00041208496259059757, Final Batch Loss: 5.314238660503179e-05\n",
      "Epoch 3072, Loss: 0.005669463025697041, Final Batch Loss: 6.249832949833944e-05\n",
      "Epoch 3073, Loss: 0.0006601124314329354, Final Batch Loss: 0.0004820545727852732\n",
      "Epoch 3074, Loss: 0.0002977590720547596, Final Batch Loss: 0.00015953024558257312\n",
      "Epoch 3075, Loss: 0.00043037906107201707, Final Batch Loss: 2.2025427824701183e-05\n",
      "Epoch 3076, Loss: 0.0006374292142936611, Final Batch Loss: 1.2373945537547115e-05\n",
      "Epoch 3077, Loss: 0.0005194286713958718, Final Batch Loss: 0.00015540893946308643\n",
      "Epoch 3078, Loss: 0.00021359559468692169, Final Batch Loss: 1.714888639980927e-05\n",
      "Epoch 3079, Loss: 0.0004137311734666582, Final Batch Loss: 6.795908120693639e-06\n",
      "Epoch 3080, Loss: 0.0002689403081603814, Final Batch Loss: 8.039025124162436e-05\n",
      "Epoch 3081, Loss: 0.0003600136042223312, Final Batch Loss: 0.0001941683003678918\n",
      "Epoch 3082, Loss: 0.0003517828226904385, Final Batch Loss: 0.00011648898362182081\n",
      "Epoch 3083, Loss: 0.0006497322938230354, Final Batch Loss: 0.00013350346125662327\n",
      "Epoch 3084, Loss: 0.0006201854575920152, Final Batch Loss: 2.8324038794380613e-05\n",
      "Epoch 3085, Loss: 0.00020821650468860753, Final Batch Loss: 0.00010901449422817677\n",
      "Epoch 3086, Loss: 0.00013473269063979387, Final Batch Loss: 3.526638465700671e-05\n",
      "Epoch 3087, Loss: 0.00024772081087576225, Final Batch Loss: 1.0731338988989592e-05\n",
      "Epoch 3088, Loss: 0.0005682765404344536, Final Batch Loss: 0.00043723234557546675\n",
      "Epoch 3089, Loss: 0.0009168010551547923, Final Batch Loss: 5.5079476624086965e-06\n",
      "Epoch 3090, Loss: 0.00036831195393460803, Final Batch Loss: 4.313524914323352e-05\n",
      "Epoch 3091, Loss: 0.0004590994503814727, Final Batch Loss: 0.00027444984880276024\n",
      "Epoch 3092, Loss: 0.0006528612357215025, Final Batch Loss: 0.00012282519310247153\n",
      "Epoch 3093, Loss: 0.0002441642318444792, Final Batch Loss: 7.161741086747497e-05\n",
      "Epoch 3094, Loss: 0.051245557493530214, Final Batch Loss: 0.04786518216133118\n",
      "Epoch 3095, Loss: 0.0003808749170275405, Final Batch Loss: 0.00018460025603417307\n",
      "Epoch 3096, Loss: 0.00014445282431552187, Final Batch Loss: 8.449758752249181e-06\n",
      "Epoch 3097, Loss: 0.0005917141825193539, Final Batch Loss: 0.00033847641316242516\n",
      "Epoch 3098, Loss: 0.003839165292447433, Final Batch Loss: 9.607672109268606e-05\n",
      "Epoch 3099, Loss: 0.024735010349104414, Final Batch Loss: 3.0724306270712987e-05\n",
      "Epoch 3100, Loss: 0.0029016380067332648, Final Batch Loss: 0.0006189103005453944\n",
      "Epoch 3101, Loss: 0.003448706782364752, Final Batch Loss: 7.477640610886738e-05\n",
      "Epoch 3102, Loss: 0.0010439931211294606, Final Batch Loss: 0.00016033432621043175\n",
      "Epoch 3103, Loss: 0.0005404376279329881, Final Batch Loss: 0.00017490699246991426\n",
      "Epoch 3104, Loss: 0.000534563121618703, Final Batch Loss: 0.0003457167185842991\n",
      "Epoch 3105, Loss: 0.00489900116372155, Final Batch Loss: 0.0007798868464305997\n",
      "Epoch 3106, Loss: 0.00020361011047498323, Final Batch Loss: 2.3898817744338885e-05\n",
      "Epoch 3107, Loss: 0.0004494860731938388, Final Batch Loss: 2.529596895328723e-05\n",
      "Epoch 3108, Loss: 0.0003410168537811842, Final Batch Loss: 0.00023260760644916445\n",
      "Epoch 3109, Loss: 0.0012092076503904536, Final Batch Loss: 0.0008497338858433068\n",
      "Epoch 3110, Loss: 0.0014344133087433875, Final Batch Loss: 0.0003175611491315067\n",
      "Epoch 3111, Loss: 0.00042798883077921346, Final Batch Loss: 3.788932372117415e-05\n",
      "Epoch 3112, Loss: 0.0015708642631580005, Final Batch Loss: 0.0011199982836842537\n",
      "Epoch 3113, Loss: 0.0009599216464266647, Final Batch Loss: 2.5947654648916796e-05\n",
      "Epoch 3114, Loss: 0.02043909927670029, Final Batch Loss: 0.02024993859231472\n",
      "Epoch 3115, Loss: 0.0006890569311508443, Final Batch Loss: 4.300395448808558e-05\n",
      "Epoch 3116, Loss: 0.000504878131323494, Final Batch Loss: 0.0002412577741779387\n",
      "Epoch 3117, Loss: 0.08491711589158513, Final Batch Loss: 0.07217614352703094\n",
      "Epoch 3118, Loss: 0.0018198397392552579, Final Batch Loss: 2.6392934159957804e-05\n",
      "Epoch 3119, Loss: 0.020964673327398486, Final Batch Loss: 0.0009248468559235334\n",
      "Epoch 3120, Loss: 0.021007068367907777, Final Batch Loss: 0.00021268051932565868\n",
      "Epoch 3121, Loss: 0.11942505650222301, Final Batch Loss: 0.04231029376387596\n",
      "Epoch 3122, Loss: 0.03434286290575983, Final Batch Loss: 7.008272950770333e-05\n",
      "Epoch 3123, Loss: 0.001162467320682481, Final Batch Loss: 0.00014758679026272148\n",
      "Epoch 3124, Loss: 0.010353656485676765, Final Batch Loss: 0.00572834350168705\n",
      "Epoch 3125, Loss: 0.014860423747450113, Final Batch Loss: 0.0023648440837860107\n",
      "Epoch 3126, Loss: 0.003462585445959121, Final Batch Loss: 0.0020901609677821398\n",
      "Epoch 3127, Loss: 0.0011357207549735904, Final Batch Loss: 0.00025225733406841755\n",
      "Epoch 3128, Loss: 0.0028349108652037103, Final Batch Loss: 5.029379462939687e-05\n",
      "Epoch 3129, Loss: 0.001823020531446673, Final Batch Loss: 0.00015919511497486383\n",
      "Epoch 3130, Loss: 0.002422272867988795, Final Batch Loss: 0.00024289987049996853\n",
      "Epoch 3131, Loss: 0.0015600537008140236, Final Batch Loss: 0.0006777825765311718\n",
      "Epoch 3132, Loss: 0.00153252825839445, Final Batch Loss: 0.0002899503742810339\n",
      "Epoch 3133, Loss: 0.0014914618514012545, Final Batch Loss: 0.00026419214555062354\n",
      "Epoch 3134, Loss: 0.003037561269593425, Final Batch Loss: 0.00019611734023783356\n",
      "Epoch 3135, Loss: 0.012411021336447448, Final Batch Loss: 0.00010508246487006545\n",
      "Epoch 3136, Loss: 0.0007952173327794299, Final Batch Loss: 0.0002020294195972383\n",
      "Epoch 3137, Loss: 0.002759000810328871, Final Batch Loss: 0.0007660064147785306\n",
      "Epoch 3138, Loss: 0.0008831035520415753, Final Batch Loss: 0.00021853121870663017\n",
      "Epoch 3139, Loss: 0.0016200512764044106, Final Batch Loss: 0.0012388991890475154\n",
      "Epoch 3140, Loss: 0.004497625108342618, Final Batch Loss: 0.0005671640974469483\n",
      "Epoch 3141, Loss: 0.003684802824864164, Final Batch Loss: 0.00012831864296458662\n",
      "Epoch 3142, Loss: 0.0035434669771348126, Final Batch Loss: 9.73470087046735e-05\n",
      "Epoch 3143, Loss: 0.00045903929640189745, Final Batch Loss: 4.7913013986544684e-05\n",
      "Epoch 3144, Loss: 0.0007266964094014838, Final Batch Loss: 0.0003839585406240076\n",
      "Epoch 3145, Loss: 0.00041558333759894595, Final Batch Loss: 0.00010851017577806488\n",
      "Epoch 3146, Loss: 0.0015992102198651992, Final Batch Loss: 0.0014223885955289006\n",
      "Epoch 3147, Loss: 0.009563431580318138, Final Batch Loss: 0.009212658740580082\n",
      "Epoch 3148, Loss: 0.00045480165135813877, Final Batch Loss: 0.0001786010543582961\n",
      "Epoch 3149, Loss: 0.003323051321785897, Final Batch Loss: 0.0002252160629723221\n",
      "Epoch 3150, Loss: 0.0009616634779376909, Final Batch Loss: 0.0004230736813042313\n",
      "Epoch 3151, Loss: 0.01930236810585484, Final Batch Loss: 0.01899964176118374\n",
      "Epoch 3152, Loss: 0.000505122519825818, Final Batch Loss: 0.0003729464369826019\n",
      "Epoch 3153, Loss: 0.000817359279608354, Final Batch Loss: 9.06111381482333e-05\n",
      "Epoch 3154, Loss: 0.015005518915131688, Final Batch Loss: 5.707493983209133e-05\n",
      "Epoch 3155, Loss: 0.01971396862063557, Final Batch Loss: 0.0035058511421084404\n",
      "Epoch 3156, Loss: 0.0018960359157063067, Final Batch Loss: 0.00017818313790485263\n",
      "Epoch 3157, Loss: 0.011533147044247016, Final Batch Loss: 0.0007423698552884161\n",
      "Epoch 3158, Loss: 0.002748656421317719, Final Batch Loss: 0.0002485016011632979\n",
      "Epoch 3159, Loss: 0.00037125725066289306, Final Batch Loss: 8.738890755921602e-05\n",
      "Epoch 3160, Loss: 0.002586442045867443, Final Batch Loss: 0.0001243778388015926\n",
      "Epoch 3161, Loss: 0.0012472358794184402, Final Batch Loss: 0.00019039744802284986\n",
      "Epoch 3162, Loss: 0.0018332636609557085, Final Batch Loss: 8.66964619490318e-05\n",
      "Epoch 3163, Loss: 0.0007005283987382427, Final Batch Loss: 0.0003585568047128618\n",
      "Epoch 3164, Loss: 0.0009258471545763314, Final Batch Loss: 0.0004168350133113563\n",
      "Epoch 3165, Loss: 0.0008185045153368264, Final Batch Loss: 0.00019355262338649482\n",
      "Epoch 3166, Loss: 0.0026994272193405777, Final Batch Loss: 0.002048908732831478\n",
      "Epoch 3167, Loss: 0.0009780592663446441, Final Batch Loss: 0.0005534359370358288\n",
      "Epoch 3168, Loss: 0.0005385895929066464, Final Batch Loss: 9.222276275977492e-05\n",
      "Epoch 3169, Loss: 0.02867632322886493, Final Batch Loss: 0.028397735208272934\n",
      "Epoch 3170, Loss: 0.0012038060085615143, Final Batch Loss: 0.0004029644187539816\n",
      "Epoch 3171, Loss: 0.001414789177943021, Final Batch Loss: 0.0007960021030157804\n",
      "Epoch 3172, Loss: 0.006349373696139082, Final Batch Loss: 0.003768555587157607\n",
      "Epoch 3173, Loss: 0.000544234637345653, Final Batch Loss: 5.485668225446716e-05\n",
      "Epoch 3174, Loss: 0.000689492288074689, Final Batch Loss: 8.244893251685426e-05\n",
      "Epoch 3175, Loss: 0.018009352555964142, Final Batch Loss: 0.00023014468024484813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3176, Loss: 0.0006868613854749128, Final Batch Loss: 0.0004664165317080915\n",
      "Epoch 3177, Loss: 0.0007228719332488254, Final Batch Loss: 0.0001527357380837202\n",
      "Epoch 3178, Loss: 0.0002691094050533138, Final Batch Loss: 9.249250433640555e-05\n",
      "Epoch 3179, Loss: 0.0006446094266721047, Final Batch Loss: 8.826007979223505e-05\n",
      "Epoch 3180, Loss: 0.0040204223623732105, Final Batch Loss: 0.0002264903305331245\n",
      "Epoch 3181, Loss: 0.0013897318567615002, Final Batch Loss: 0.0007142142858356237\n",
      "Epoch 3182, Loss: 0.0008882873189577367, Final Batch Loss: 1.9373223040020093e-05\n",
      "Epoch 3183, Loss: 0.00032353443020838313, Final Batch Loss: 1.612347477930598e-05\n",
      "Epoch 3184, Loss: 0.0024369495222344995, Final Batch Loss: 0.0002714248257689178\n",
      "Epoch 3185, Loss: 0.001127212162828073, Final Batch Loss: 0.00024046303587965667\n",
      "Epoch 3186, Loss: 0.004986580752301961, Final Batch Loss: 0.0037938649766147137\n",
      "Epoch 3187, Loss: 0.0036155707930447534, Final Batch Loss: 0.002762954216450453\n",
      "Epoch 3188, Loss: 0.0012485456827562302, Final Batch Loss: 0.0008894609054550529\n",
      "Epoch 3189, Loss: 0.0005055529727542307, Final Batch Loss: 0.00019660328689496964\n",
      "Epoch 3190, Loss: 0.001818863966036588, Final Batch Loss: 0.0007029170519672334\n",
      "Epoch 3191, Loss: 0.000713281289790757, Final Batch Loss: 0.000243837246671319\n",
      "Epoch 3192, Loss: 0.0002750800776993856, Final Batch Loss: 6.310778553597629e-05\n",
      "Epoch 3193, Loss: 0.0033421917833038606, Final Batch Loss: 0.003043256001546979\n",
      "Epoch 3194, Loss: 0.0013672969653271139, Final Batch Loss: 0.00019568933930713683\n",
      "Epoch 3195, Loss: 0.0006343084969557822, Final Batch Loss: 0.00045698496978729963\n",
      "Epoch 3196, Loss: 0.0013890908739995211, Final Batch Loss: 0.00012494868133217096\n",
      "Epoch 3197, Loss: 0.002403225196758285, Final Batch Loss: 0.0010272254003211856\n",
      "Epoch 3198, Loss: 0.0001621835290279705, Final Batch Loss: 4.8330424760933965e-05\n",
      "Epoch 3199, Loss: 0.003764580877032131, Final Batch Loss: 0.00025014946004375815\n",
      "Epoch 3200, Loss: 0.0014414880351978354, Final Batch Loss: 7.865002407925203e-05\n",
      "Epoch 3201, Loss: 0.000596420060901437, Final Batch Loss: 2.1597610611934215e-05\n",
      "Epoch 3202, Loss: 0.00020420481450855732, Final Batch Loss: 0.00011782892397604883\n",
      "Epoch 3203, Loss: 0.0006948305308469571, Final Batch Loss: 3.8732650864403695e-05\n",
      "Epoch 3204, Loss: 0.002215629138845543, Final Batch Loss: 0.0017996777314692736\n",
      "Epoch 3205, Loss: 0.0001778913865564391, Final Batch Loss: 3.1537081667920575e-05\n",
      "Epoch 3206, Loss: 0.0005181790329515934, Final Batch Loss: 0.00021418152027763426\n",
      "Epoch 3207, Loss: 0.0008681148174218833, Final Batch Loss: 6.748133455403149e-05\n",
      "Epoch 3208, Loss: 0.0009333253183285706, Final Batch Loss: 0.00016206305008381605\n",
      "Epoch 3209, Loss: 0.00039933652442414314, Final Batch Loss: 0.00017919910897035152\n",
      "Epoch 3210, Loss: 0.00037001678720116615, Final Batch Loss: 0.00020751012198161334\n",
      "Epoch 3211, Loss: 0.00037948376848362386, Final Batch Loss: 0.00017065026622731239\n",
      "Epoch 3212, Loss: 0.001752549986122176, Final Batch Loss: 0.0008604672038927674\n",
      "Epoch 3213, Loss: 0.007204155903309584, Final Batch Loss: 0.0065001738257706165\n",
      "Epoch 3214, Loss: 0.0013241020496934652, Final Batch Loss: 0.00037577658076770604\n",
      "Epoch 3215, Loss: 0.0009184916925732978, Final Batch Loss: 0.0006539255264215171\n",
      "Epoch 3216, Loss: 0.00016995389705698472, Final Batch Loss: 1.478878220950719e-05\n",
      "Epoch 3217, Loss: 0.0012676562328124419, Final Batch Loss: 0.00025607962743379176\n",
      "Epoch 3218, Loss: 0.0003438342100707814, Final Batch Loss: 0.00010164066043216735\n",
      "Epoch 3219, Loss: 0.0012348664022283629, Final Batch Loss: 5.769521521870047e-05\n",
      "Epoch 3220, Loss: 0.0010257293906761333, Final Batch Loss: 0.0005879721720702946\n",
      "Epoch 3221, Loss: 0.004582302950439043, Final Batch Loss: 0.003412284655496478\n",
      "Epoch 3222, Loss: 0.0004019598272861913, Final Batch Loss: 9.103277989197522e-05\n",
      "Epoch 3223, Loss: 0.0006412138100131415, Final Batch Loss: 9.576921729603782e-05\n",
      "Epoch 3224, Loss: 0.000519938359502703, Final Batch Loss: 0.00016178168880287558\n",
      "Epoch 3225, Loss: 0.0025714658258948475, Final Batch Loss: 0.0015674816677346826\n",
      "Epoch 3226, Loss: 0.005905357116716914, Final Batch Loss: 0.005493183620274067\n",
      "Epoch 3227, Loss: 0.0011245713139942382, Final Batch Loss: 3.867077248287387e-05\n",
      "Epoch 3228, Loss: 0.00044579660607269034, Final Batch Loss: 2.4929773644544184e-05\n",
      "Epoch 3229, Loss: 0.0004077433331985958, Final Batch Loss: 0.0001274603564525023\n",
      "Epoch 3230, Loss: 0.0018545206148701254, Final Batch Loss: 0.00012788332242053002\n",
      "Epoch 3231, Loss: 0.0003294315029052086, Final Batch Loss: 9.416935790795833e-05\n",
      "Epoch 3232, Loss: 0.03359905043907929, Final Batch Loss: 0.00021891431242693216\n",
      "Epoch 3233, Loss: 0.002283574838656932, Final Batch Loss: 0.0011178511194884777\n",
      "Epoch 3234, Loss: 0.002303335946635343, Final Batch Loss: 0.0001339360314887017\n",
      "Epoch 3235, Loss: 0.0007124218827812001, Final Batch Loss: 0.0001922035007737577\n",
      "Epoch 3236, Loss: 0.00015188885754469084, Final Batch Loss: 4.3499021558091044e-05\n",
      "Epoch 3237, Loss: 0.0004131553796469234, Final Batch Loss: 6.639658386120573e-05\n",
      "Epoch 3238, Loss: 0.0008628901814518031, Final Batch Loss: 3.8603608118137345e-05\n",
      "Epoch 3239, Loss: 0.0004167080551269464, Final Batch Loss: 0.0002581589506007731\n",
      "Epoch 3240, Loss: 0.003932897467166185, Final Batch Loss: 0.0035425249952822924\n",
      "Epoch 3241, Loss: 0.0016858930539456196, Final Batch Loss: 0.00029089456074871123\n",
      "Epoch 3242, Loss: 0.00032577031379332766, Final Batch Loss: 7.275598181877285e-05\n",
      "Epoch 3243, Loss: 0.0007002091806498356, Final Batch Loss: 0.00010136128548765555\n",
      "Epoch 3244, Loss: 8.33238582345075e-05, Final Batch Loss: 2.1107109205331653e-05\n",
      "Epoch 3245, Loss: 0.0005422150279628113, Final Batch Loss: 0.00027026538737118244\n",
      "Epoch 3246, Loss: 0.07245155856799101, Final Batch Loss: 0.07177502661943436\n",
      "Epoch 3247, Loss: 0.005876351831830107, Final Batch Loss: 0.005668216850608587\n",
      "Epoch 3248, Loss: 0.0003513315677992068, Final Batch Loss: 0.00011009469017153606\n",
      "Epoch 3249, Loss: 0.011932157918636221, Final Batch Loss: 8.693707786733285e-05\n",
      "Epoch 3250, Loss: 0.0032492855316377245, Final Batch Loss: 9.108773519983515e-05\n",
      "Epoch 3251, Loss: 0.0015332851326093078, Final Batch Loss: 0.0006417102413251996\n",
      "Epoch 3252, Loss: 0.0075472390235518105, Final Batch Loss: 9.997169399866834e-05\n",
      "Epoch 3253, Loss: 0.0015565859648631886, Final Batch Loss: 0.0006409559864550829\n",
      "Epoch 3254, Loss: 0.002051837531325873, Final Batch Loss: 0.00017806545656640083\n",
      "Epoch 3255, Loss: 0.00014122707216301933, Final Batch Loss: 6.453519745264202e-05\n",
      "Epoch 3256, Loss: 0.0012959633022546768, Final Batch Loss: 0.000833395344670862\n",
      "Epoch 3257, Loss: 0.002994028561261075, Final Batch Loss: 1.0133692740055267e-05\n",
      "Epoch 3258, Loss: 0.00030001349114172626, Final Batch Loss: 2.3423332095262595e-05\n",
      "Epoch 3259, Loss: 0.00042252944331266917, Final Batch Loss: 0.00028005288913846016\n",
      "Epoch 3260, Loss: 0.0003505057065922301, Final Batch Loss: 7.45341822039336e-05\n",
      "Epoch 3261, Loss: 0.0008018231201276649, Final Batch Loss: 3.541440310073085e-05\n",
      "Epoch 3262, Loss: 0.00019249901879447862, Final Batch Loss: 3.166949318256229e-05\n",
      "Epoch 3263, Loss: 0.0006288728254730813, Final Batch Loss: 1.7696926079224795e-05\n",
      "Epoch 3264, Loss: 0.0003237931268813554, Final Batch Loss: 5.960764974588528e-05\n",
      "Epoch 3265, Loss: 0.0012195551953482209, Final Batch Loss: 0.0010749937500804663\n",
      "Epoch 3266, Loss: 0.00021988958906149492, Final Batch Loss: 5.8242338127456605e-05\n",
      "Epoch 3267, Loss: 0.0004019702973891981, Final Batch Loss: 2.6048255676869303e-05\n",
      "Epoch 3268, Loss: 0.00039322585143963806, Final Batch Loss: 1.909106140374206e-05\n",
      "Epoch 3269, Loss: 0.0005789045899291523, Final Batch Loss: 0.0005367654957808554\n",
      "Epoch 3270, Loss: 0.0006946941293790587, Final Batch Loss: 1.1767305295506958e-05\n",
      "Epoch 3271, Loss: 0.0047194214075716445, Final Batch Loss: 0.004417955409735441\n",
      "Epoch 3272, Loss: 0.0005199856132094283, Final Batch Loss: 0.00031795556424185634\n",
      "Epoch 3273, Loss: 0.0007283769737114199, Final Batch Loss: 5.6106298870872706e-05\n",
      "Epoch 3274, Loss: 0.000356253807694884, Final Batch Loss: 0.0001480042265029624\n",
      "Epoch 3275, Loss: 0.0002916703515438712, Final Batch Loss: 1.0602888323774096e-05\n",
      "Epoch 3276, Loss: 0.014508564618154196, Final Batch Loss: 1.4621891750721261e-05\n",
      "Epoch 3277, Loss: 0.0018473841519153211, Final Batch Loss: 0.0009506961796432734\n",
      "Epoch 3278, Loss: 0.0006233759886526968, Final Batch Loss: 5.017179864807986e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3279, Loss: 0.002075656995884856, Final Batch Loss: 2.6034924758278066e-06\n",
      "Epoch 3280, Loss: 0.030921813508030027, Final Batch Loss: 0.002059404505416751\n",
      "Epoch 3281, Loss: 0.0011820224317489192, Final Batch Loss: 0.0007699686684645712\n",
      "Epoch 3282, Loss: 0.000358741595846368, Final Batch Loss: 0.00010211098560830578\n",
      "Epoch 3283, Loss: 0.0003098179331573192, Final Batch Loss: 7.49450409784913e-05\n",
      "Epoch 3284, Loss: 0.00041712666279636323, Final Batch Loss: 0.00018538020958658308\n",
      "Epoch 3285, Loss: 0.0005511035251402063, Final Batch Loss: 0.000477956811664626\n",
      "Epoch 3286, Loss: 0.000612197403825121, Final Batch Loss: 3.7043359043309465e-05\n",
      "Epoch 3287, Loss: 0.00014622393064200878, Final Batch Loss: 2.323564694961533e-05\n",
      "Epoch 3288, Loss: 0.0006014844984747469, Final Batch Loss: 0.00014812193694524467\n",
      "Epoch 3289, Loss: 0.00018309841652808245, Final Batch Loss: 9.000540740089491e-05\n",
      "Epoch 3290, Loss: 0.0030278958120106836, Final Batch Loss: 0.0007029774715192616\n",
      "Epoch 3291, Loss: 0.0024401252667303197, Final Batch Loss: 0.0018119062297046185\n",
      "Epoch 3292, Loss: 0.0016323711242876016, Final Batch Loss: 0.00011341394565533847\n",
      "Epoch 3293, Loss: 0.0002947914654214401, Final Batch Loss: 9.006441541714594e-05\n",
      "Epoch 3294, Loss: 0.0030002484472788638, Final Batch Loss: 0.0016627468867227435\n",
      "Epoch 3295, Loss: 0.00021436676615849137, Final Batch Loss: 1.749489820213057e-05\n",
      "Epoch 3296, Loss: 0.0007490403586416505, Final Batch Loss: 0.00016602655523456633\n",
      "Epoch 3297, Loss: 0.026369354862254113, Final Batch Loss: 0.0004956613411195576\n",
      "Epoch 3298, Loss: 0.0009679964878159808, Final Batch Loss: 5.53220343135763e-06\n",
      "Epoch 3299, Loss: 0.0008539591472072061, Final Batch Loss: 0.000171783976838924\n",
      "Epoch 3300, Loss: 0.009282926504965872, Final Batch Loss: 0.00039505003951489925\n",
      "Epoch 3301, Loss: 0.0006244023243198171, Final Batch Loss: 7.924008968984708e-05\n",
      "Epoch 3302, Loss: 0.00033960615564865293, Final Batch Loss: 8.685606189828832e-06\n",
      "Epoch 3303, Loss: 0.0002906733370764414, Final Batch Loss: 2.4147588192136027e-05\n",
      "Epoch 3304, Loss: 0.0002188408288930077, Final Batch Loss: 0.00012572990090120584\n",
      "Epoch 3305, Loss: 0.00033261124917771667, Final Batch Loss: 4.316713966545649e-05\n",
      "Epoch 3306, Loss: 0.0007265240419656038, Final Batch Loss: 0.00012450625945348293\n",
      "Epoch 3307, Loss: 0.0016257370880339295, Final Batch Loss: 0.00024542384198866785\n",
      "Epoch 3308, Loss: 0.0002481431292835623, Final Batch Loss: 3.215418109903112e-05\n",
      "Epoch 3309, Loss: 0.00031197856878861785, Final Batch Loss: 7.123363320715725e-05\n",
      "Epoch 3310, Loss: 0.0011403832904761657, Final Batch Loss: 0.0005104764713905752\n",
      "Epoch 3311, Loss: 8.284822069981601e-05, Final Batch Loss: 3.0216771847335622e-05\n",
      "Epoch 3312, Loss: 0.0008357023161806865, Final Batch Loss: 0.0005957569228485227\n",
      "Epoch 3313, Loss: 0.0005272818889352493, Final Batch Loss: 5.46341179870069e-05\n",
      "Epoch 3314, Loss: 0.0002963555962196551, Final Batch Loss: 4.66065393993631e-05\n",
      "Epoch 3315, Loss: 0.0011033430637326092, Final Batch Loss: 0.00022357753186952323\n",
      "Epoch 3316, Loss: 0.0005899469942960422, Final Batch Loss: 5.313391375239007e-05\n",
      "Epoch 3317, Loss: 0.0029141690756659955, Final Batch Loss: 0.0018940165173262358\n",
      "Epoch 3318, Loss: 0.0003596403093979461, Final Batch Loss: 0.0001628750324016437\n",
      "Epoch 3319, Loss: 0.00022948963669477962, Final Batch Loss: 0.00017351869610138237\n",
      "Epoch 3320, Loss: 0.0007698819099459797, Final Batch Loss: 0.0003400291607249528\n",
      "Epoch 3321, Loss: 0.00021838878819835372, Final Batch Loss: 4.855842053075321e-05\n",
      "Epoch 3322, Loss: 0.016067534129433625, Final Batch Loss: 8.72103282745229e-06\n",
      "Epoch 3323, Loss: 0.00013881607810617425, Final Batch Loss: 2.3431372028426267e-05\n",
      "Epoch 3324, Loss: 0.0003926876288460335, Final Batch Loss: 0.0003096041618846357\n",
      "Epoch 3325, Loss: 0.0004982469072274398, Final Batch Loss: 0.0003843483573291451\n",
      "Epoch 3326, Loss: 0.0005339384624676313, Final Batch Loss: 0.00041723233880475163\n",
      "Epoch 3327, Loss: 0.0005260926918708719, Final Batch Loss: 0.00030376031645573676\n",
      "Epoch 3328, Loss: 0.00014210920380719472, Final Batch Loss: 3.507111978251487e-05\n",
      "Epoch 3329, Loss: 0.00018160062609240413, Final Batch Loss: 7.014958828222007e-05\n",
      "Epoch 3330, Loss: 0.0006307423755060881, Final Batch Loss: 0.00028195494087412953\n",
      "Epoch 3331, Loss: 0.0005237881559878588, Final Batch Loss: 0.00021303548419382423\n",
      "Epoch 3332, Loss: 0.00039323446253547445, Final Batch Loss: 0.00012830844207201153\n",
      "Epoch 3333, Loss: 0.0008880731002136599, Final Batch Loss: 3.074046617257409e-05\n",
      "Epoch 3334, Loss: 0.00022202160107553937, Final Batch Loss: 0.00010375125566497445\n",
      "Epoch 3335, Loss: 0.00045242464329930954, Final Batch Loss: 0.00033076986437663436\n",
      "Epoch 3336, Loss: 0.0007915045589470537, Final Batch Loss: 1.74295073520625e-05\n",
      "Epoch 3337, Loss: 0.011961846394115128, Final Batch Loss: 0.00019778947171289474\n",
      "Epoch 3338, Loss: 0.0008851566963130608, Final Batch Loss: 0.00021221300994511694\n",
      "Epoch 3339, Loss: 0.00045123096424504183, Final Batch Loss: 0.000108043008367531\n",
      "Epoch 3340, Loss: 0.0003028936807822902, Final Batch Loss: 5.2884981414536014e-05\n",
      "Epoch 3341, Loss: 0.011802143228123896, Final Batch Loss: 0.0007928319973871112\n",
      "Epoch 3342, Loss: 0.0006245583290365175, Final Batch Loss: 4.49635354016209e-06\n",
      "Epoch 3343, Loss: 0.0019094541785307229, Final Batch Loss: 0.0002974984818138182\n",
      "Epoch 3344, Loss: 0.00022833732509752735, Final Batch Loss: 0.00013102436787448823\n",
      "Epoch 3345, Loss: 0.00013167571887606755, Final Batch Loss: 3.912927058991045e-05\n",
      "Epoch 3346, Loss: 0.00020939634850947186, Final Batch Loss: 7.722916052443907e-05\n",
      "Epoch 3347, Loss: 0.0014909192505001556, Final Batch Loss: 3.108979217358865e-05\n",
      "Epoch 3348, Loss: 0.00022464224821305834, Final Batch Loss: 8.965082815848291e-05\n",
      "Epoch 3349, Loss: 0.0005679067689925432, Final Batch Loss: 0.00021936907432973385\n",
      "Epoch 3350, Loss: 0.0014745618445886066, Final Batch Loss: 2.3600621716468595e-05\n",
      "Epoch 3351, Loss: 0.00024972814935608767, Final Batch Loss: 3.662374001578428e-05\n",
      "Epoch 3352, Loss: 0.0004791931569343433, Final Batch Loss: 0.0003363458963576704\n",
      "Epoch 3353, Loss: 0.00013611450776807033, Final Batch Loss: 4.0496670408174396e-05\n",
      "Epoch 3354, Loss: 0.00028676638430624735, Final Batch Loss: 1.7987485989579e-05\n",
      "Epoch 3355, Loss: 0.0002110570389959321, Final Batch Loss: 7.703150185989216e-05\n",
      "Epoch 3356, Loss: 0.036646112936068675, Final Batch Loss: 4.973893737769686e-06\n",
      "Epoch 3357, Loss: 0.0005354125514713814, Final Batch Loss: 0.0004273828526493162\n",
      "Epoch 3358, Loss: 0.0016588239959673956, Final Batch Loss: 0.0014646571362391114\n",
      "Epoch 3359, Loss: 0.0014629803263233043, Final Batch Loss: 0.0013220621040090919\n",
      "Epoch 3360, Loss: 0.0021226849348749965, Final Batch Loss: 0.0009821366984397173\n",
      "Epoch 3361, Loss: 0.0012942197026859503, Final Batch Loss: 3.617837865022011e-05\n",
      "Epoch 3362, Loss: 0.002139577420166461, Final Batch Loss: 0.001327558304183185\n",
      "Epoch 3363, Loss: 0.00010053025289380457, Final Batch Loss: 5.049653191235848e-05\n",
      "Epoch 3364, Loss: 0.0019193704138160683, Final Batch Loss: 8.667350630275905e-05\n",
      "Epoch 3365, Loss: 0.00040283107227878645, Final Batch Loss: 0.00024131829559337348\n",
      "Epoch 3366, Loss: 0.0011098932736786082, Final Batch Loss: 0.0006321012624539435\n",
      "Epoch 3367, Loss: 0.0005453024132293649, Final Batch Loss: 0.00013381654571276158\n",
      "Epoch 3368, Loss: 0.0008738367032492533, Final Batch Loss: 0.00019293598597869277\n",
      "Epoch 3369, Loss: 0.00019737436377909034, Final Batch Loss: 5.132903243065812e-05\n",
      "Epoch 3370, Loss: 0.0013272761575535696, Final Batch Loss: 7.392591669486137e-06\n",
      "Epoch 3371, Loss: 0.00017936939912033267, Final Batch Loss: 8.632184471935034e-05\n",
      "Epoch 3372, Loss: 0.0014271621039370075, Final Batch Loss: 0.0008183318423107266\n",
      "Epoch 3373, Loss: 0.0022564720129594207, Final Batch Loss: 0.0001806081854738295\n",
      "Epoch 3374, Loss: 0.000679330165439751, Final Batch Loss: 0.00011044766142731532\n",
      "Epoch 3375, Loss: 0.0009472055680816993, Final Batch Loss: 0.0006714554619975388\n",
      "Epoch 3376, Loss: 0.0008891451507224701, Final Batch Loss: 1.5210440324153751e-05\n",
      "Epoch 3377, Loss: 0.0001941322880156804, Final Batch Loss: 9.9657365353778e-05\n",
      "Epoch 3378, Loss: 0.0007170030712586595, Final Batch Loss: 2.8395223125698976e-05\n",
      "Epoch 3379, Loss: 0.0002433949921396561, Final Batch Loss: 8.517579408362508e-05\n",
      "Epoch 3380, Loss: 0.00016911365491978358, Final Batch Loss: 7.500862557208166e-05\n",
      "Epoch 3381, Loss: 0.0002599668814582401, Final Batch Loss: 4.306632945372257e-06\n",
      "Epoch 3382, Loss: 0.00046726181790290866, Final Batch Loss: 1.6264939404209144e-05\n",
      "Epoch 3383, Loss: 0.0001333989293925697, Final Batch Loss: 2.1343725165934302e-05\n",
      "Epoch 3384, Loss: 0.0006322820318018785, Final Batch Loss: 2.3871656594565138e-05\n",
      "Epoch 3385, Loss: 0.0030904908271622844, Final Batch Loss: 8.548870391678065e-05\n",
      "Epoch 3386, Loss: 0.0006443778074753936, Final Batch Loss: 4.991251262254082e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3387, Loss: 0.00040933572472567903, Final Batch Loss: 6.315573409665376e-05\n",
      "Epoch 3388, Loss: 0.0015526458155363798, Final Batch Loss: 0.0011106111342087388\n",
      "Epoch 3389, Loss: 0.04235773480604621, Final Batch Loss: 0.04231391102075577\n",
      "Epoch 3390, Loss: 0.001769170179613866, Final Batch Loss: 0.0008181466837413609\n",
      "Epoch 3391, Loss: 0.0005889851418032777, Final Batch Loss: 3.6657682358054444e-05\n",
      "Epoch 3392, Loss: 0.0005070226616226137, Final Batch Loss: 0.00028289208421483636\n",
      "Epoch 3393, Loss: 0.001343273559541558, Final Batch Loss: 0.0003602045471780002\n",
      "Epoch 3394, Loss: 0.0007079335264279507, Final Batch Loss: 0.0005432633333839476\n",
      "Epoch 3395, Loss: 0.0012747094115184154, Final Batch Loss: 3.2495383493369445e-05\n",
      "Epoch 3396, Loss: 0.0018646123498911038, Final Batch Loss: 6.18004851276055e-05\n",
      "Epoch 3397, Loss: 0.0019388915420677222, Final Batch Loss: 6.727520940330578e-06\n",
      "Epoch 3398, Loss: 0.00046975956502137706, Final Batch Loss: 0.00013078161282464862\n",
      "Epoch 3399, Loss: 0.0010112249583471566, Final Batch Loss: 0.0002096248499583453\n",
      "Epoch 3400, Loss: 0.00029109767638146877, Final Batch Loss: 8.408181747654453e-05\n",
      "Epoch 3401, Loss: 0.0024835474314386374, Final Batch Loss: 1.1540459126990754e-05\n",
      "Epoch 3402, Loss: 0.000531888242221612, Final Batch Loss: 0.0003866088518407196\n",
      "Epoch 3403, Loss: 0.001742552085488569, Final Batch Loss: 0.00012070284719811752\n",
      "Epoch 3404, Loss: 0.00011204223301319871, Final Batch Loss: 2.7869036784977652e-05\n",
      "Epoch 3405, Loss: 0.0003880393323925091, Final Batch Loss: 2.701081939449068e-05\n",
      "Epoch 3406, Loss: 0.0008517463102180045, Final Batch Loss: 0.0005631567910313606\n",
      "Epoch 3407, Loss: 0.0034534693218120083, Final Batch Loss: 5.837118351337267e-06\n",
      "Epoch 3408, Loss: 0.0005734443329856731, Final Batch Loss: 0.0003255181945860386\n",
      "Epoch 3409, Loss: 0.0005930867082497571, Final Batch Loss: 0.00016123097157105803\n",
      "Epoch 3410, Loss: 0.00027287629927741364, Final Batch Loss: 8.629661169834435e-05\n",
      "Epoch 3411, Loss: 0.017921057784406003, Final Batch Loss: 1.3353164831642061e-05\n",
      "Epoch 3412, Loss: 0.00021857532192370854, Final Batch Loss: 6.422091973945498e-05\n",
      "Epoch 3413, Loss: 0.0010721057478804141, Final Batch Loss: 7.035210728645325e-05\n",
      "Epoch 3414, Loss: 0.0008705293457751395, Final Batch Loss: 0.0006907691713422537\n",
      "Epoch 3415, Loss: 0.0005770043608208653, Final Batch Loss: 4.537998393061571e-05\n",
      "Epoch 3416, Loss: 0.001253986280062236, Final Batch Loss: 8.480421092826873e-05\n",
      "Epoch 3417, Loss: 0.0004914664314128458, Final Batch Loss: 8.415811316808686e-05\n",
      "Epoch 3418, Loss: 0.0003710187966134981, Final Batch Loss: 0.0003005583130288869\n",
      "Epoch 3419, Loss: 0.0030764894327148795, Final Batch Loss: 0.0002717403694987297\n",
      "Epoch 3420, Loss: 0.0005517037498066202, Final Batch Loss: 0.00020290323300287127\n",
      "Epoch 3421, Loss: 0.009483786780037917, Final Batch Loss: 0.00012483612226787955\n",
      "Epoch 3422, Loss: 0.000609034403169062, Final Batch Loss: 0.00018824155267793685\n",
      "Epoch 3423, Loss: 0.0017179759106511483, Final Batch Loss: 1.7602485968382098e-05\n",
      "Epoch 3424, Loss: 0.0003651385923149064, Final Batch Loss: 0.00023797551693860441\n",
      "Epoch 3425, Loss: 0.00039119927077990724, Final Batch Loss: 6.605788803426549e-05\n",
      "Epoch 3426, Loss: 0.001660439171246253, Final Batch Loss: 0.0010164896957576275\n",
      "Epoch 3427, Loss: 0.0007454515289282426, Final Batch Loss: 3.4339012927375734e-05\n",
      "Epoch 3428, Loss: 0.0012547442729555769, Final Batch Loss: 1.5955212802509777e-05\n",
      "Epoch 3429, Loss: 0.0009452185331610963, Final Batch Loss: 0.0005160310538485646\n",
      "Epoch 3430, Loss: 0.0013621793477796018, Final Batch Loss: 0.0009509954252280295\n",
      "Epoch 3431, Loss: 0.00029028771496086847, Final Batch Loss: 2.1025420210207812e-05\n",
      "Epoch 3432, Loss: 0.0035214636172895553, Final Batch Loss: 1.1694233762682416e-05\n",
      "Epoch 3433, Loss: 0.00045218006016511936, Final Batch Loss: 0.0002653824049048126\n",
      "Epoch 3434, Loss: 0.0006760302603652235, Final Batch Loss: 0.00026018134667538106\n",
      "Epoch 3435, Loss: 0.0005458815649035387, Final Batch Loss: 0.000468117359559983\n",
      "Epoch 3436, Loss: 0.0007247563044074923, Final Batch Loss: 0.00011068812455050647\n",
      "Epoch 3437, Loss: 0.0005800482103950344, Final Batch Loss: 0.00011837368219858035\n",
      "Epoch 3438, Loss: 0.000924415944609791, Final Batch Loss: 1.6711856005713344e-05\n",
      "Epoch 3439, Loss: 0.0005128595366841182, Final Batch Loss: 0.00027017417596653104\n",
      "Epoch 3440, Loss: 0.00021397223190433579, Final Batch Loss: 6.620693602599204e-05\n",
      "Epoch 3441, Loss: 0.05530274540069513, Final Batch Loss: 0.0549306757748127\n",
      "Epoch 3442, Loss: 0.0002720399388635997, Final Batch Loss: 0.00017996497626882046\n",
      "Epoch 3443, Loss: 0.0011819792598544154, Final Batch Loss: 0.0006814779480919242\n",
      "Epoch 3444, Loss: 0.0031400911448145052, Final Batch Loss: 0.0003566158120520413\n",
      "Epoch 3445, Loss: 0.001349839280010201, Final Batch Loss: 0.0008935856749303639\n",
      "Epoch 3446, Loss: 0.0015573195269098505, Final Batch Loss: 0.0009345305152237415\n",
      "Epoch 3447, Loss: 0.009881499101538793, Final Batch Loss: 2.7270923965261318e-05\n",
      "Epoch 3448, Loss: 0.0005926638259552419, Final Batch Loss: 0.00038406107341870666\n",
      "Epoch 3449, Loss: 0.005011437780922279, Final Batch Loss: 0.0004921871586702764\n",
      "Epoch 3450, Loss: 0.0003570798025975819, Final Batch Loss: 0.0001828320964705199\n",
      "Epoch 3451, Loss: 0.007122448497284495, Final Batch Loss: 2.1364789063227363e-05\n",
      "Epoch 3452, Loss: 0.0001572153232700657, Final Batch Loss: 6.423806917155161e-05\n",
      "Epoch 3453, Loss: 0.001788470646715723, Final Batch Loss: 0.0005317227332852781\n",
      "Epoch 3454, Loss: 0.00024370760002057068, Final Batch Loss: 7.896812167018652e-05\n",
      "Epoch 3455, Loss: 0.002547402516938746, Final Batch Loss: 0.0012166860979050398\n",
      "Epoch 3456, Loss: 0.0022510852286359295, Final Batch Loss: 0.00019984671962447464\n",
      "Epoch 3457, Loss: 0.0012849615013692528, Final Batch Loss: 0.00019537252956070006\n",
      "Epoch 3458, Loss: 0.0012600529007613659, Final Batch Loss: 0.00012673516175709665\n",
      "Epoch 3459, Loss: 0.0008445869607385248, Final Batch Loss: 0.0005710209952667356\n",
      "Epoch 3460, Loss: 0.004960763089911779, Final Batch Loss: 3.779830512939952e-05\n",
      "Epoch 3461, Loss: 0.0033111465236288495, Final Batch Loss: 8.094660734059289e-05\n",
      "Epoch 3462, Loss: 0.0005309743282850832, Final Batch Loss: 5.322825745679438e-05\n",
      "Epoch 3463, Loss: 0.006507661608338822, Final Batch Loss: 0.005605342797935009\n",
      "Epoch 3464, Loss: 0.0022862443365738727, Final Batch Loss: 9.225685062119737e-05\n",
      "Epoch 3465, Loss: 0.0006247074124985375, Final Batch Loss: 7.248332985909656e-05\n",
      "Epoch 3466, Loss: 0.009805683726881398, Final Batch Loss: 5.415684063336812e-05\n",
      "Epoch 3467, Loss: 0.0004373518968350254, Final Batch Loss: 0.00010007123637478799\n",
      "Epoch 3468, Loss: 0.00022666389850201085, Final Batch Loss: 6.328224117169157e-05\n",
      "Epoch 3469, Loss: 0.00033727011486917036, Final Batch Loss: 0.00012837088434025645\n",
      "Epoch 3470, Loss: 0.001379614433972165, Final Batch Loss: 0.0004472015716601163\n",
      "Epoch 3471, Loss: 0.004242457041982561, Final Batch Loss: 0.0004789265803992748\n",
      "Epoch 3472, Loss: 0.0014870814775349572, Final Batch Loss: 0.00010405637294752523\n",
      "Epoch 3473, Loss: 0.0006094140953791793, Final Batch Loss: 0.0004511398437898606\n",
      "Epoch 3474, Loss: 0.0005473766286741011, Final Batch Loss: 0.0002267019299324602\n",
      "Epoch 3475, Loss: 0.00043771625496447086, Final Batch Loss: 0.00013159691297914833\n",
      "Epoch 3476, Loss: 0.00013190691970521584, Final Batch Loss: 2.7665326342685148e-05\n",
      "Epoch 3477, Loss: 0.0005124737965616077, Final Batch Loss: 2.6240034003421897e-06\n",
      "Epoch 3478, Loss: 0.00011880871716130059, Final Batch Loss: 3.0811359465587884e-05\n",
      "Epoch 3479, Loss: 0.00025497331444057636, Final Batch Loss: 0.00013419023889582604\n",
      "Epoch 3480, Loss: 0.009181191446259618, Final Batch Loss: 0.0009568918030709028\n",
      "Epoch 3481, Loss: 0.002527131857277709, Final Batch Loss: 9.80045115284156e-06\n",
      "Epoch 3482, Loss: 0.0013181133199395845, Final Batch Loss: 7.627863669767976e-05\n",
      "Epoch 3483, Loss: 0.0014265544596128166, Final Batch Loss: 9.425805183127522e-05\n",
      "Epoch 3484, Loss: 0.002153870313122752, Final Batch Loss: 0.00024460224085487425\n",
      "Epoch 3485, Loss: 0.0004736740520456806, Final Batch Loss: 0.0002405868872301653\n",
      "Epoch 3486, Loss: 0.0007707381191721652, Final Batch Loss: 4.663048093789257e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3487, Loss: 0.0005011145876778755, Final Batch Loss: 0.0003601662174332887\n",
      "Epoch 3488, Loss: 0.0006680865117232315, Final Batch Loss: 6.677605415461585e-05\n",
      "Epoch 3489, Loss: 0.0008309331751661375, Final Batch Loss: 0.00010416976874694228\n",
      "Epoch 3490, Loss: 0.0009131982624239754, Final Batch Loss: 0.00011318244651192799\n",
      "Epoch 3491, Loss: 0.0009293617586081382, Final Batch Loss: 0.0007015207665972412\n",
      "Epoch 3492, Loss: 0.02353376481551095, Final Batch Loss: 0.023378465324640274\n",
      "Epoch 3493, Loss: 0.0009690823499113321, Final Batch Loss: 8.186549530364573e-05\n",
      "Epoch 3494, Loss: 0.008066857961239293, Final Batch Loss: 0.0071574184112250805\n",
      "Epoch 3495, Loss: 0.009405157594301272, Final Batch Loss: 0.009178020991384983\n",
      "Epoch 3496, Loss: 0.000824239491521439, Final Batch Loss: 4.8252932174364105e-05\n",
      "Epoch 3497, Loss: 0.001197475308799767, Final Batch Loss: 2.141245386155788e-05\n",
      "Epoch 3498, Loss: 0.0003482740357867442, Final Batch Loss: 0.00019511196296662092\n",
      "Epoch 3499, Loss: 0.035711209413420875, Final Batch Loss: 0.029269803315401077\n",
      "Epoch 3500, Loss: 0.0017320875249424716, Final Batch Loss: 2.7492405934026465e-05\n",
      "Epoch 3501, Loss: 0.0012554043059935793, Final Batch Loss: 0.0007789035444147885\n",
      "Epoch 3502, Loss: 0.0005100801063235849, Final Batch Loss: 0.0004342706233728677\n",
      "Epoch 3503, Loss: 0.004709502165496815, Final Batch Loss: 0.00024530020891688764\n",
      "Epoch 3504, Loss: 0.00027212994609726593, Final Batch Loss: 9.573681018082425e-05\n",
      "Epoch 3505, Loss: 0.01061961484447238, Final Batch Loss: 3.6211033147992566e-05\n",
      "Epoch 3506, Loss: 0.0015970065651345067, Final Batch Loss: 0.0005730431876145303\n",
      "Epoch 3507, Loss: 0.000181900348252384, Final Batch Loss: 6.860707071609795e-05\n",
      "Epoch 3508, Loss: 0.0007601928846270312, Final Batch Loss: 0.0004871206183452159\n",
      "Epoch 3509, Loss: 0.00043339009425835684, Final Batch Loss: 9.272064926335588e-05\n",
      "Epoch 3510, Loss: 0.0029158246179576963, Final Batch Loss: 0.000570479198358953\n",
      "Epoch 3511, Loss: 0.0018867282869905466, Final Batch Loss: 0.0017779800109565258\n",
      "Epoch 3512, Loss: 0.0003959282985306345, Final Batch Loss: 0.0001021452117129229\n",
      "Epoch 3513, Loss: 0.00030634372524218634, Final Batch Loss: 0.00018541565805207938\n",
      "Epoch 3514, Loss: 0.0006046579383109929, Final Batch Loss: 1.578671253810171e-05\n",
      "Epoch 3515, Loss: 0.0006431698002415942, Final Batch Loss: 1.4130871932138689e-05\n",
      "Epoch 3516, Loss: 0.004734514754090924, Final Batch Loss: 0.004503391217440367\n",
      "Epoch 3517, Loss: 0.0008005196723388508, Final Batch Loss: 0.00026497102226130664\n",
      "Epoch 3518, Loss: 0.00038283066351141315, Final Batch Loss: 1.4261835531215183e-05\n",
      "Epoch 3519, Loss: 0.0014183850944391452, Final Batch Loss: 0.00010386289795860648\n",
      "Epoch 3520, Loss: 0.00028450778700062074, Final Batch Loss: 3.90408058592584e-05\n",
      "Epoch 3521, Loss: 0.03325487341498956, Final Batch Loss: 5.165273978491314e-05\n",
      "Epoch 3522, Loss: 0.00037906845682300627, Final Batch Loss: 8.125074964482337e-05\n",
      "Epoch 3523, Loss: 0.0004915595782222226, Final Batch Loss: 0.0002246247895527631\n",
      "Epoch 3524, Loss: 0.00041427956603001803, Final Batch Loss: 0.00019071970018558204\n",
      "Epoch 3525, Loss: 0.0004829449208045844, Final Batch Loss: 9.414803935214877e-05\n",
      "Epoch 3526, Loss: 0.0006640285282628611, Final Batch Loss: 0.0002278270258102566\n",
      "Epoch 3527, Loss: 0.0015617768658557907, Final Batch Loss: 0.00034650249290280044\n",
      "Epoch 3528, Loss: 0.0032017196863307618, Final Batch Loss: 3.7765443266835064e-05\n",
      "Epoch 3529, Loss: 0.00019776577755692415, Final Batch Loss: 0.0001044658274622634\n",
      "Epoch 3530, Loss: 0.00015868916671024635, Final Batch Loss: 4.623748827725649e-05\n",
      "Epoch 3531, Loss: 0.0002649623893375974, Final Batch Loss: 4.044969318783842e-05\n",
      "Epoch 3532, Loss: 0.001592904853168875, Final Batch Loss: 0.00010992246097885072\n",
      "Epoch 3533, Loss: 0.002078496469039237, Final Batch Loss: 0.0001747146452544257\n",
      "Epoch 3534, Loss: 0.00024155981554940809, Final Batch Loss: 3.853616362903267e-05\n",
      "Epoch 3535, Loss: 0.0004977730932296254, Final Batch Loss: 0.00024402013514190912\n",
      "Epoch 3536, Loss: 0.00044036933832103387, Final Batch Loss: 0.0001377281587338075\n",
      "Epoch 3537, Loss: 0.01788521076377947, Final Batch Loss: 4.0436090785078704e-05\n",
      "Epoch 3538, Loss: 0.00011472374535514973, Final Batch Loss: 2.4860910343704745e-05\n",
      "Epoch 3539, Loss: 0.00034326468812651, Final Batch Loss: 6.0251124523347244e-05\n",
      "Epoch 3540, Loss: 0.0014395171820069663, Final Batch Loss: 1.923890522448346e-05\n",
      "Epoch 3541, Loss: 0.0038657379482174292, Final Batch Loss: 0.0032259104773402214\n",
      "Epoch 3542, Loss: 0.0005321191347320564, Final Batch Loss: 0.0001760680606821552\n",
      "Epoch 3543, Loss: 0.0002631926108733751, Final Batch Loss: 5.433654587250203e-05\n",
      "Epoch 3544, Loss: 0.0014601986549678259, Final Batch Loss: 0.0008340351050719619\n",
      "Epoch 3545, Loss: 0.0004112188980798237, Final Batch Loss: 0.00014025410928297788\n",
      "Epoch 3546, Loss: 0.003576819653972052, Final Batch Loss: 0.0008892275509424508\n",
      "Epoch 3547, Loss: 0.0019142167875543237, Final Batch Loss: 0.0008819284266792238\n",
      "Epoch 3548, Loss: 0.00022960014393902384, Final Batch Loss: 4.2011361074401066e-05\n",
      "Epoch 3549, Loss: 0.0002580357722763438, Final Batch Loss: 0.00010515170288272202\n",
      "Epoch 3550, Loss: 0.0005558565244427882, Final Batch Loss: 8.210732630686834e-05\n",
      "Epoch 3551, Loss: 0.0014611566730309278, Final Batch Loss: 0.001396815525367856\n",
      "Epoch 3552, Loss: 0.0005440681061372743, Final Batch Loss: 3.293286863481626e-05\n",
      "Epoch 3553, Loss: 0.0009379192779306322, Final Batch Loss: 0.0007572419126518071\n",
      "Epoch 3554, Loss: 0.0003196386642230209, Final Batch Loss: 0.00011115321103716269\n",
      "Epoch 3555, Loss: 0.00039106932672439143, Final Batch Loss: 0.00010144506086362526\n",
      "Epoch 3556, Loss: 0.0008069814284681343, Final Batch Loss: 7.422029011650011e-05\n",
      "Epoch 3557, Loss: 0.040613670644233935, Final Batch Loss: 0.0390201173722744\n",
      "Epoch 3558, Loss: 0.00018387170166533906, Final Batch Loss: 2.695461989787873e-05\n",
      "Epoch 3559, Loss: 0.0005308826803229749, Final Batch Loss: 0.00012987168156541884\n",
      "Epoch 3560, Loss: 0.024113276464049704, Final Batch Loss: 0.023604804649949074\n",
      "Epoch 3561, Loss: 0.0024839071156748105, Final Batch Loss: 0.002392287366092205\n",
      "Epoch 3562, Loss: 0.0024236550962086767, Final Batch Loss: 0.00014850599109195173\n",
      "Epoch 3563, Loss: 0.005084649819764309, Final Batch Loss: 0.004883406218141317\n",
      "Epoch 3564, Loss: 0.0014199049619492143, Final Batch Loss: 0.0006952491239644587\n",
      "Epoch 3565, Loss: 0.0006019763095537201, Final Batch Loss: 0.0002752052969299257\n",
      "Epoch 3566, Loss: 0.0052161667990731075, Final Batch Loss: 0.00011343506776029244\n",
      "Epoch 3567, Loss: 0.004893899822491221, Final Batch Loss: 0.0013363895704969764\n",
      "Epoch 3568, Loss: 0.0010839557799044997, Final Batch Loss: 0.0006709606386721134\n",
      "Epoch 3569, Loss: 0.002074814838124439, Final Batch Loss: 0.0006750382017344236\n",
      "Epoch 3570, Loss: 0.0034338193363510072, Final Batch Loss: 0.0007699474808759987\n",
      "Epoch 3571, Loss: 0.004606178186804755, Final Batch Loss: 1.808716478990391e-05\n",
      "Epoch 3572, Loss: 0.0003698578493640525, Final Batch Loss: 5.449050149763934e-06\n",
      "Epoch 3573, Loss: 0.0012688084389083087, Final Batch Loss: 0.00023386126849800348\n",
      "Epoch 3574, Loss: 0.027294373334370903, Final Batch Loss: 5.2761664846912026e-05\n",
      "Epoch 3575, Loss: 0.008116295008221641, Final Batch Loss: 0.0006422674050554633\n",
      "Epoch 3576, Loss: 0.005148181073309388, Final Batch Loss: 0.004949425812810659\n",
      "Epoch 3577, Loss: 0.0007604819293192122, Final Batch Loss: 4.414032810018398e-05\n",
      "Epoch 3578, Loss: 0.00035908793870476075, Final Batch Loss: 0.00018004847515840083\n",
      "Epoch 3579, Loss: 0.0009138149616774172, Final Batch Loss: 0.0004778248257935047\n",
      "Epoch 3580, Loss: 0.0021242320362944156, Final Batch Loss: 0.00030611312831752\n",
      "Epoch 3581, Loss: 0.0008131808954203734, Final Batch Loss: 0.0007094522588886321\n",
      "Epoch 3582, Loss: 0.002466608479153365, Final Batch Loss: 0.0011737988097593188\n",
      "Epoch 3583, Loss: 0.00031000047601992264, Final Batch Loss: 8.904125570552424e-05\n",
      "Epoch 3584, Loss: 0.005084572774649132, Final Batch Loss: 0.0037188350688666105\n",
      "Epoch 3585, Loss: 0.0006604161171708256, Final Batch Loss: 0.000254727405263111\n",
      "Epoch 3586, Loss: 0.0006868338714411948, Final Batch Loss: 5.04269301018212e-05\n",
      "Epoch 3587, Loss: 0.0017046096181729808, Final Batch Loss: 0.00014720880426466465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3588, Loss: 0.0004903526278212667, Final Batch Loss: 0.00015707231068518013\n",
      "Epoch 3589, Loss: 0.0002488934151188005, Final Batch Loss: 5.976297688903287e-05\n",
      "Epoch 3590, Loss: 0.0004812458937522024, Final Batch Loss: 0.00018436268146615475\n",
      "Epoch 3591, Loss: 0.00019501401402521878, Final Batch Loss: 9.431398939341307e-05\n",
      "Epoch 3592, Loss: 0.0012113556113035884, Final Batch Loss: 5.958491601631977e-05\n",
      "Epoch 3593, Loss: 0.013449402529658983, Final Batch Loss: 0.013247618451714516\n",
      "Epoch 3594, Loss: 0.0008649126230011461, Final Batch Loss: 0.0001302276796195656\n",
      "Epoch 3595, Loss: 0.002808385164826177, Final Batch Loss: 0.00048214371781796217\n",
      "Epoch 3596, Loss: 0.0069131405325606465, Final Batch Loss: 0.0005836999043822289\n",
      "Epoch 3597, Loss: 0.0003593299552449025, Final Batch Loss: 0.00013292529911268502\n",
      "Epoch 3598, Loss: 0.006819789899964235, Final Batch Loss: 0.0066395970061421394\n",
      "Epoch 3599, Loss: 0.0007335119153140113, Final Batch Loss: 0.00014779243792872876\n",
      "Epoch 3600, Loss: 0.0007574510782433208, Final Batch Loss: 5.9339927247492597e-05\n",
      "Epoch 3601, Loss: 0.04098830878501758, Final Batch Loss: 0.0067141070030629635\n",
      "Epoch 3602, Loss: 0.002990373184729833, Final Batch Loss: 0.0013731312938034534\n",
      "Epoch 3603, Loss: 0.001743824323057197, Final Batch Loss: 7.207184535218403e-05\n",
      "Epoch 3604, Loss: 0.0004974862022208981, Final Batch Loss: 6.192202999955043e-05\n",
      "Epoch 3605, Loss: 0.0380261919926852, Final Batch Loss: 0.026900984346866608\n",
      "Epoch 3606, Loss: 0.0002161200209229719, Final Batch Loss: 4.001886190962978e-05\n",
      "Epoch 3607, Loss: 0.00029778777661704225, Final Batch Loss: 0.00011874004849232733\n",
      "Epoch 3608, Loss: 0.00732215799507685, Final Batch Loss: 0.0056785778142511845\n",
      "Epoch 3609, Loss: 0.009152754792012274, Final Batch Loss: 0.0004261551657691598\n",
      "Epoch 3610, Loss: 0.0015709816798334941, Final Batch Loss: 7.29048770153895e-05\n",
      "Epoch 3611, Loss: 0.04119731787068304, Final Batch Loss: 0.040402401238679886\n",
      "Epoch 3612, Loss: 0.0005178155479370616, Final Batch Loss: 0.00018985725182574242\n",
      "Epoch 3613, Loss: 0.001207832210639026, Final Batch Loss: 0.0008608557982370257\n",
      "Epoch 3614, Loss: 0.003838756510958774, Final Batch Loss: 0.0001287650957237929\n",
      "Epoch 3615, Loss: 0.001015247187751811, Final Batch Loss: 0.00023354955192189664\n",
      "Epoch 3616, Loss: 0.0003627179285103921, Final Batch Loss: 3.9116250263759866e-05\n",
      "Epoch 3617, Loss: 0.0006088647423894145, Final Batch Loss: 0.0002568843774497509\n",
      "Epoch 3618, Loss: 0.0006501298030343605, Final Batch Loss: 0.00019360761507414281\n",
      "Epoch 3619, Loss: 0.0005542256549233571, Final Batch Loss: 0.00014045827265363187\n",
      "Epoch 3620, Loss: 0.0004482880794967059, Final Batch Loss: 0.00014215597184374928\n",
      "Epoch 3621, Loss: 0.0015323897096095607, Final Batch Loss: 0.0001676352258073166\n",
      "Epoch 3622, Loss: 0.002663362363819033, Final Batch Loss: 0.0010157336946576834\n",
      "Epoch 3623, Loss: 0.001197739882627502, Final Batch Loss: 0.0008116462267935276\n",
      "Epoch 3624, Loss: 0.000199167699975078, Final Batch Loss: 1.352513390884269e-05\n",
      "Epoch 3625, Loss: 0.0005291655324981548, Final Batch Loss: 0.0001025321107590571\n",
      "Epoch 3626, Loss: 0.0008784360543359071, Final Batch Loss: 0.00019886111840605736\n",
      "Epoch 3627, Loss: 0.00015130091833270853, Final Batch Loss: 0.00010418591409688815\n",
      "Epoch 3628, Loss: 0.0007264063460752368, Final Batch Loss: 0.00010795982962008566\n",
      "Epoch 3629, Loss: 0.0004463655059225857, Final Batch Loss: 0.00014762817590963095\n",
      "Epoch 3630, Loss: 0.0002683472994249314, Final Batch Loss: 7.922614167910069e-05\n",
      "Epoch 3631, Loss: 0.0029913128819316626, Final Batch Loss: 0.0024002320133149624\n",
      "Epoch 3632, Loss: 0.0005699328157788841, Final Batch Loss: 2.953856710519176e-05\n",
      "Epoch 3633, Loss: 0.0015932739261188544, Final Batch Loss: 1.811396941775456e-05\n",
      "Epoch 3634, Loss: 0.0016738431440899149, Final Batch Loss: 0.0001229059707839042\n",
      "Epoch 3635, Loss: 0.0013764642644673586, Final Batch Loss: 0.0012915456900373101\n",
      "Epoch 3636, Loss: 0.0004164160018262919, Final Batch Loss: 4.7504679969279096e-05\n",
      "Epoch 3637, Loss: 0.019553876591089647, Final Batch Loss: 9.116397268371657e-05\n",
      "Epoch 3638, Loss: 0.0005352198495529592, Final Batch Loss: 0.00013227439194452018\n",
      "Epoch 3639, Loss: 0.0005755751699325629, Final Batch Loss: 7.912696310086176e-05\n",
      "Epoch 3640, Loss: 0.004948231464368291, Final Batch Loss: 0.004583548754453659\n",
      "Epoch 3641, Loss: 0.008280718262540177, Final Batch Loss: 0.008009782992303371\n",
      "Epoch 3642, Loss: 0.0020069060992682353, Final Batch Loss: 0.00034841164597310126\n",
      "Epoch 3643, Loss: 0.0005161648568901001, Final Batch Loss: 3.005633880093228e-05\n",
      "Epoch 3644, Loss: 0.00038631013012491167, Final Batch Loss: 0.0001345103810308501\n",
      "Epoch 3645, Loss: 0.0007125206648197491, Final Batch Loss: 4.847726449952461e-05\n",
      "Epoch 3646, Loss: 0.0006610718774027191, Final Batch Loss: 0.00039614265551790595\n",
      "Epoch 3647, Loss: 0.00054939764959272, Final Batch Loss: 0.00023868192511145025\n",
      "Epoch 3648, Loss: 0.0020835143950534984, Final Batch Loss: 7.01242097420618e-05\n",
      "Epoch 3649, Loss: 0.007165243674535304, Final Batch Loss: 0.006421200931072235\n",
      "Epoch 3650, Loss: 0.00035694974212674424, Final Batch Loss: 6.316281360341236e-05\n",
      "Epoch 3651, Loss: 0.0007334256224567071, Final Batch Loss: 7.885020750109106e-05\n",
      "Epoch 3652, Loss: 0.0011091338747064583, Final Batch Loss: 6.581327761523426e-05\n",
      "Epoch 3653, Loss: 0.00038577856685151346, Final Batch Loss: 3.0181170586729422e-05\n",
      "Epoch 3654, Loss: 0.0013720194983761758, Final Batch Loss: 0.00044627152965404093\n",
      "Epoch 3655, Loss: 0.005594515989287174, Final Batch Loss: 9.150691039394587e-05\n",
      "Epoch 3656, Loss: 0.000544199334399309, Final Batch Loss: 9.491319360677153e-05\n",
      "Epoch 3657, Loss: 0.0004207756428513676, Final Batch Loss: 0.00022067654936108738\n",
      "Epoch 3658, Loss: 0.01851777372212382, Final Batch Loss: 0.005106523633003235\n",
      "Epoch 3659, Loss: 0.000553803525690455, Final Batch Loss: 0.00038633766234852374\n",
      "Epoch 3660, Loss: 0.003525170737702865, Final Batch Loss: 9.730124293128029e-05\n",
      "Epoch 3661, Loss: 0.0005565141800616402, Final Batch Loss: 3.4203152608824894e-05\n",
      "Epoch 3662, Loss: 0.0004978282704541925, Final Batch Loss: 2.9228878702269867e-05\n",
      "Epoch 3663, Loss: 0.00032881624065339565, Final Batch Loss: 6.728467997163534e-05\n",
      "Epoch 3664, Loss: 0.00043566244858084247, Final Batch Loss: 0.00011504028952913359\n",
      "Epoch 3665, Loss: 0.00021895510599279078, Final Batch Loss: 6.897292769281194e-05\n",
      "Epoch 3666, Loss: 0.00033887202880578116, Final Batch Loss: 6.93312831572257e-05\n",
      "Epoch 3667, Loss: 0.0006364326000039, Final Batch Loss: 0.00013783620670437813\n",
      "Epoch 3668, Loss: 0.01599884017559816, Final Batch Loss: 0.015530873090028763\n",
      "Epoch 3669, Loss: 0.00015050214642542414, Final Batch Loss: 6.0601589211728424e-05\n",
      "Epoch 3670, Loss: 0.0006713410402880982, Final Batch Loss: 0.00027999086887575686\n",
      "Epoch 3671, Loss: 0.0008906632156140404, Final Batch Loss: 0.0006930491072125733\n",
      "Epoch 3672, Loss: 0.0003234719843021594, Final Batch Loss: 3.1681549444328994e-05\n",
      "Epoch 3673, Loss: 0.0004537821987469215, Final Batch Loss: 2.9788647225359455e-05\n",
      "Epoch 3674, Loss: 0.001008849503705278, Final Batch Loss: 0.0002517430402804166\n",
      "Epoch 3675, Loss: 0.0005051751977589447, Final Batch Loss: 5.089789192425087e-05\n",
      "Epoch 3676, Loss: 0.0006843802075309213, Final Batch Loss: 2.1829147954122163e-05\n",
      "Epoch 3677, Loss: 0.000668852160742972, Final Batch Loss: 0.0001740582229103893\n",
      "Epoch 3678, Loss: 0.002666559194040019, Final Batch Loss: 4.9844915338326246e-05\n",
      "Epoch 3679, Loss: 0.0006588277319679037, Final Batch Loss: 0.00015305864508263767\n",
      "Epoch 3680, Loss: 0.0002492039020580705, Final Batch Loss: 4.966070628142916e-05\n",
      "Epoch 3681, Loss: 0.0008034812090045307, Final Batch Loss: 4.79146656289231e-05\n",
      "Epoch 3682, Loss: 0.0007735441467957571, Final Batch Loss: 0.0005902947741560638\n",
      "Epoch 3683, Loss: 0.0015220163622871041, Final Batch Loss: 0.0003596486640162766\n",
      "Epoch 3684, Loss: 0.000331498133164132, Final Batch Loss: 3.481837848084979e-05\n",
      "Epoch 3685, Loss: 0.0003568913016351871, Final Batch Loss: 4.185401485301554e-05\n",
      "Epoch 3686, Loss: 0.00018312762040295638, Final Batch Loss: 7.624373392900452e-05\n",
      "Epoch 3687, Loss: 0.0011568430199986324, Final Batch Loss: 0.0009209715062752366\n",
      "Epoch 3688, Loss: 0.0004784530774486484, Final Batch Loss: 2.4676783141330816e-05\n",
      "Epoch 3689, Loss: 0.00020625372599170078, Final Batch Loss: 3.9428825402865186e-05\n",
      "Epoch 3690, Loss: 0.0012741310783894733, Final Batch Loss: 6.634926103288308e-05\n",
      "Epoch 3691, Loss: 0.003441079199546948, Final Batch Loss: 0.00038369218236766756\n",
      "Epoch 3692, Loss: 0.0003281282843090594, Final Batch Loss: 0.00012621592031791806\n",
      "Epoch 3693, Loss: 0.00047991389146773145, Final Batch Loss: 0.00033497021649964154\n",
      "Epoch 3694, Loss: 0.0035378878164920025, Final Batch Loss: 0.0033250462729483843\n",
      "Epoch 3695, Loss: 0.002822408479914884, Final Batch Loss: 7.093932799762115e-05\n",
      "Epoch 3696, Loss: 0.0012896867920062505, Final Batch Loss: 6.220057548489422e-05\n",
      "Epoch 3697, Loss: 0.0001611505686014425, Final Batch Loss: 4.496703331824392e-05\n",
      "Epoch 3698, Loss: 0.0010042993162642233, Final Batch Loss: 0.0003867378400173038\n",
      "Epoch 3699, Loss: 0.00046324288996402174, Final Batch Loss: 4.127515421714634e-05\n",
      "Epoch 3700, Loss: 0.0005480558229464805, Final Batch Loss: 2.8146028853370808e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3701, Loss: 0.008748776162974536, Final Batch Loss: 0.00020476743520703167\n",
      "Epoch 3702, Loss: 0.0005290657463774551, Final Batch Loss: 6.029275027685799e-05\n",
      "Epoch 3703, Loss: 0.00016374596089008264, Final Batch Loss: 1.8459562852513045e-05\n",
      "Epoch 3704, Loss: 0.00015879387365203002, Final Batch Loss: 6.0168524214532226e-05\n",
      "Epoch 3705, Loss: 0.000171460339515761, Final Batch Loss: 1.171406347566517e-05\n",
      "Epoch 3706, Loss: 0.0009919320691551547, Final Batch Loss: 6.426680192817003e-05\n",
      "Epoch 3707, Loss: 0.005643082313326886, Final Batch Loss: 0.005448660813271999\n",
      "Epoch 3708, Loss: 0.0006899854997755028, Final Batch Loss: 0.00041324851918034256\n",
      "Epoch 3709, Loss: 0.0007486990070901811, Final Batch Loss: 0.00012809009058400989\n",
      "Epoch 3710, Loss: 0.002708801672270056, Final Batch Loss: 6.528665107907727e-05\n",
      "Epoch 3711, Loss: 0.004792603394889738, Final Batch Loss: 0.0001476199395256117\n",
      "Epoch 3712, Loss: 0.002894689685490448, Final Batch Loss: 0.0027516838163137436\n",
      "Epoch 3713, Loss: 0.0004423544633027632, Final Batch Loss: 0.0002021733089350164\n",
      "Epoch 3714, Loss: 0.0004931301373289898, Final Batch Loss: 6.978152669034898e-05\n",
      "Epoch 3715, Loss: 0.0024647554564580787, Final Batch Loss: 0.00014522772107739002\n",
      "Epoch 3716, Loss: 0.0005409820078057237, Final Batch Loss: 0.0003271211462561041\n",
      "Epoch 3717, Loss: 0.0002967503678519279, Final Batch Loss: 0.00012163004430476576\n",
      "Epoch 3718, Loss: 0.0010942533754132455, Final Batch Loss: 2.1320933228707872e-05\n",
      "Epoch 3719, Loss: 0.0017944000737770693, Final Batch Loss: 0.00039931442006491125\n",
      "Epoch 3720, Loss: 0.040824299214364146, Final Batch Loss: 0.04032240808010101\n",
      "Epoch 3721, Loss: 0.0028617258140002377, Final Batch Loss: 9.210813004756346e-05\n",
      "Epoch 3722, Loss: 0.0010897566899075173, Final Batch Loss: 0.00091952970251441\n",
      "Epoch 3723, Loss: 0.0005156985789653845, Final Batch Loss: 9.124250937020406e-05\n",
      "Epoch 3724, Loss: 0.0018502746534068137, Final Batch Loss: 3.647812991403043e-05\n",
      "Epoch 3725, Loss: 0.0016289467021124437, Final Batch Loss: 0.0003391530772205442\n",
      "Epoch 3726, Loss: 0.0011447736469563097, Final Batch Loss: 0.00033911122591234744\n",
      "Epoch 3727, Loss: 0.00040431011530017713, Final Batch Loss: 6.094921627664007e-05\n",
      "Epoch 3728, Loss: 0.0005125439274706878, Final Batch Loss: 0.0002787743869703263\n",
      "Epoch 3729, Loss: 0.000907078694581287, Final Batch Loss: 4.394179632072337e-05\n",
      "Epoch 3730, Loss: 0.0016109067146317102, Final Batch Loss: 6.172274152049795e-05\n",
      "Epoch 3731, Loss: 0.0009667096892371774, Final Batch Loss: 0.00026646378682926297\n",
      "Epoch 3732, Loss: 0.0007894562422734452, Final Batch Loss: 0.0004311530210543424\n",
      "Epoch 3733, Loss: 0.0006052791504771449, Final Batch Loss: 4.851407356909476e-05\n",
      "Epoch 3734, Loss: 0.0005849996960023418, Final Batch Loss: 2.220527494500857e-05\n",
      "Epoch 3735, Loss: 0.00043466047281981446, Final Batch Loss: 0.0002979757555294782\n",
      "Epoch 3736, Loss: 0.00015255610378517304, Final Batch Loss: 2.2914657165529206e-05\n",
      "Epoch 3737, Loss: 0.00033405694375687744, Final Batch Loss: 4.0361112041864544e-05\n",
      "Epoch 3738, Loss: 0.0004328847558099369, Final Batch Loss: 0.00033684037043713033\n",
      "Epoch 3739, Loss: 0.0021358755730034318, Final Batch Loss: 0.0016501110512763262\n",
      "Epoch 3740, Loss: 0.00022820092817710247, Final Batch Loss: 0.00020033297187183052\n",
      "Epoch 3741, Loss: 0.0010307496540917782, Final Batch Loss: 9.097134170588106e-05\n",
      "Epoch 3742, Loss: 0.0018531880778027698, Final Batch Loss: 0.00013901556667406112\n",
      "Epoch 3743, Loss: 0.00014132025080471067, Final Batch Loss: 8.461495781375561e-06\n",
      "Epoch 3744, Loss: 0.0002287414245074615, Final Batch Loss: 7.51048864913173e-05\n",
      "Epoch 3745, Loss: 0.0002778895795927383, Final Batch Loss: 8.390437869820744e-05\n",
      "Epoch 3746, Loss: 0.00011200610424566548, Final Batch Loss: 5.636299101752229e-05\n",
      "Epoch 3747, Loss: 0.00024049676994764013, Final Batch Loss: 0.00010348336218157783\n",
      "Epoch 3748, Loss: 0.0007215193909360096, Final Batch Loss: 0.00040367268957197666\n",
      "Epoch 3749, Loss: 0.0005520120212167967, Final Batch Loss: 0.0003515778516884893\n",
      "Epoch 3750, Loss: 0.00039407653821399435, Final Batch Loss: 0.00025217109941877425\n",
      "Epoch 3751, Loss: 0.0001355071617581416, Final Batch Loss: 2.7349624360795133e-05\n",
      "Epoch 3752, Loss: 0.00026938745941151865, Final Batch Loss: 5.3184459829935804e-05\n",
      "Epoch 3753, Loss: 0.0009005504853121238, Final Batch Loss: 4.6642835513921455e-06\n",
      "Epoch 3754, Loss: 8.95825478437473e-05, Final Batch Loss: 1.4526534869219176e-05\n",
      "Epoch 3755, Loss: 0.0002687663145479746, Final Batch Loss: 4.471451393328607e-05\n",
      "Epoch 3756, Loss: 0.003417458585317945, Final Batch Loss: 4.832655758946203e-05\n",
      "Epoch 3757, Loss: 0.0027025933377444744, Final Batch Loss: 0.00017285539070144296\n",
      "Epoch 3758, Loss: 0.00019617921498138458, Final Batch Loss: 7.63902862672694e-05\n",
      "Epoch 3759, Loss: 0.00019200698807253502, Final Batch Loss: 5.268428867566399e-05\n",
      "Epoch 3760, Loss: 0.00037811314541613683, Final Batch Loss: 0.00010456195013830438\n",
      "Epoch 3761, Loss: 0.0005842144682901562, Final Batch Loss: 1.1883364095410798e-05\n",
      "Epoch 3762, Loss: 0.0002544044291425962, Final Batch Loss: 0.00014334818115457892\n",
      "Epoch 3763, Loss: 0.0001696013605396729, Final Batch Loss: 6.53769020573236e-05\n",
      "Epoch 3764, Loss: 0.000500255984661635, Final Batch Loss: 0.00011244251800235361\n",
      "Epoch 3765, Loss: 0.00010603045393509092, Final Batch Loss: 2.5888568416121416e-05\n",
      "Epoch 3766, Loss: 0.00011897491276613437, Final Batch Loss: 4.419223478180356e-05\n",
      "Epoch 3767, Loss: 0.00048645025162841193, Final Batch Loss: 0.0003510274982545525\n",
      "Epoch 3768, Loss: 0.00022458019748228253, Final Batch Loss: 6.851718808320584e-06\n",
      "Epoch 3769, Loss: 0.0021010201089666225, Final Batch Loss: 0.0015180018963292241\n",
      "Epoch 3770, Loss: 0.00019342536779731745, Final Batch Loss: 3.927477519027889e-05\n",
      "Epoch 3771, Loss: 0.0011356722461641766, Final Batch Loss: 2.6570327463559806e-05\n",
      "Epoch 3772, Loss: 0.001196749582504708, Final Batch Loss: 4.669143436331069e-06\n",
      "Epoch 3773, Loss: 8.872795024217339e-05, Final Batch Loss: 3.2144456781679764e-05\n",
      "Epoch 3774, Loss: 0.00022921454183233436, Final Batch Loss: 2.457964546920266e-05\n",
      "Epoch 3775, Loss: 0.00024275964096887037, Final Batch Loss: 5.1641483878483996e-05\n",
      "Epoch 3776, Loss: 0.00043368825936340727, Final Batch Loss: 2.02496703423094e-05\n",
      "Epoch 3777, Loss: 0.00012916473247059912, Final Batch Loss: 3.3155859000544297e-06\n",
      "Epoch 3778, Loss: 0.00017519975608593086, Final Batch Loss: 4.780058588949032e-05\n",
      "Epoch 3779, Loss: 0.00015565970898023807, Final Batch Loss: 2.4746786948526278e-05\n",
      "Epoch 3780, Loss: 0.00042489122643019073, Final Batch Loss: 3.9350747101707384e-05\n",
      "Epoch 3781, Loss: 0.0008548631412850227, Final Batch Loss: 1.8965449271490797e-05\n",
      "Epoch 3782, Loss: 0.0001604947574378457, Final Batch Loss: 1.701545261312276e-05\n",
      "Epoch 3783, Loss: 0.0002415701874269871, Final Batch Loss: 3.891755113727413e-05\n",
      "Epoch 3784, Loss: 0.0027668360708048567, Final Batch Loss: 0.0022197600919753313\n",
      "Epoch 3785, Loss: 0.0004385848537822312, Final Batch Loss: 4.302174147596816e-06\n",
      "Epoch 3786, Loss: 0.00021734774782089517, Final Batch Loss: 1.9044811779167503e-05\n",
      "Epoch 3787, Loss: 0.0005156009169695608, Final Batch Loss: 6.065583420422627e-06\n",
      "Epoch 3788, Loss: 0.00013466844939102884, Final Batch Loss: 3.2692038075765595e-05\n",
      "Epoch 3789, Loss: 0.0009990212893171702, Final Batch Loss: 1.6702924767741933e-05\n",
      "Epoch 3790, Loss: 0.00024948872305685654, Final Batch Loss: 9.710255835670978e-05\n",
      "Epoch 3791, Loss: 0.0012728173369396245, Final Batch Loss: 2.6928420993499458e-05\n",
      "Epoch 3792, Loss: 0.00128305604448542, Final Batch Loss: 1.8198974430561066e-05\n",
      "Epoch 3793, Loss: 0.0006088495883886935, Final Batch Loss: 0.00023848171986173838\n",
      "Epoch 3794, Loss: 0.000370965830370551, Final Batch Loss: 9.995023719966412e-05\n",
      "Epoch 3795, Loss: 0.0005156460538273677, Final Batch Loss: 0.00019134221656713635\n",
      "Epoch 3796, Loss: 0.0002884155619540252, Final Batch Loss: 6.985608342802152e-05\n",
      "Epoch 3797, Loss: 0.0002438005176372826, Final Batch Loss: 6.673279131064191e-05\n",
      "Epoch 3798, Loss: 0.0001739919407555135, Final Batch Loss: 2.5595249098842032e-05\n",
      "Epoch 3799, Loss: 0.0004703371541836532, Final Batch Loss: 3.091089820372872e-05\n",
      "Epoch 3800, Loss: 0.00010410865888843546, Final Batch Loss: 5.457354200189002e-05\n",
      "Epoch 3801, Loss: 7.666756664548302e-05, Final Batch Loss: 1.0810320418386254e-05\n",
      "Epoch 3802, Loss: 0.0001895177920232527, Final Batch Loss: 7.517134508816525e-05\n",
      "Epoch 3803, Loss: 0.00025053173158084974, Final Batch Loss: 2.2736647224519402e-05\n",
      "Epoch 3804, Loss: 0.03612444008467719, Final Batch Loss: 0.033512379974126816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Loss: 6.582223795703612e-05, Final Batch Loss: 1.6074061932158656e-05\n",
      "Epoch 3806, Loss: 0.0015048146451590583, Final Batch Loss: 0.0010555419139564037\n",
      "Epoch 3807, Loss: 0.00028833074611611664, Final Batch Loss: 7.167623698478565e-05\n",
      "Epoch 3808, Loss: 0.0005600032582151471, Final Batch Loss: 0.00048665565554983914\n",
      "Epoch 3809, Loss: 0.0003586013426684076, Final Batch Loss: 1.444871122657787e-05\n",
      "Epoch 3810, Loss: 0.0003422722984396387, Final Batch Loss: 9.083699842449278e-05\n",
      "Epoch 3811, Loss: 0.0013722459552809596, Final Batch Loss: 0.000835235056001693\n",
      "Epoch 3812, Loss: 0.0006985979634919204, Final Batch Loss: 0.00028715661028400064\n",
      "Epoch 3813, Loss: 0.0008664639099151827, Final Batch Loss: 8.513264037901536e-05\n",
      "Epoch 3814, Loss: 0.017492064934231166, Final Batch Loss: 8.054023965087254e-06\n",
      "Epoch 3815, Loss: 0.001768652320606634, Final Batch Loss: 0.0003100987523794174\n",
      "Epoch 3816, Loss: 0.0013488581043930026, Final Batch Loss: 0.0011559741105884314\n",
      "Epoch 3817, Loss: 0.0021523841242014896, Final Batch Loss: 2.9579387046396732e-05\n",
      "Epoch 3818, Loss: 0.0005857927608303726, Final Batch Loss: 4.525147960521281e-05\n",
      "Epoch 3819, Loss: 0.0009354547146358527, Final Batch Loss: 0.0003835100505966693\n",
      "Epoch 3820, Loss: 0.0013652232610184, Final Batch Loss: 1.526774030935485e-05\n",
      "Epoch 3821, Loss: 0.00037918110865575727, Final Batch Loss: 0.00012361757399048656\n",
      "Epoch 3822, Loss: 0.0008271082078863401, Final Batch Loss: 0.0006320055108517408\n",
      "Epoch 3823, Loss: 0.0005266438238322735, Final Batch Loss: 5.722200148738921e-05\n",
      "Epoch 3824, Loss: 0.024480460459017195, Final Batch Loss: 0.0023742232006043196\n",
      "Epoch 3825, Loss: 0.0004458833918761229, Final Batch Loss: 1.0789712177938782e-05\n",
      "Epoch 3826, Loss: 0.0005700092733604833, Final Batch Loss: 0.0001168135495390743\n",
      "Epoch 3827, Loss: 0.00045800264979334315, Final Batch Loss: 0.0002348515554331243\n",
      "Epoch 3828, Loss: 0.0026492613651498687, Final Batch Loss: 0.0024305791594088078\n",
      "Epoch 3829, Loss: 0.00024700789799680933, Final Batch Loss: 8.054177305893973e-05\n",
      "Epoch 3830, Loss: 0.0002504518979549175, Final Batch Loss: 0.0001297755225095898\n",
      "Epoch 3831, Loss: 0.0001448079892725218, Final Batch Loss: 2.5517962058074772e-05\n",
      "Epoch 3832, Loss: 0.0012862525254604407, Final Batch Loss: 2.395577757852152e-05\n",
      "Epoch 3833, Loss: 0.00024409052821283694, Final Batch Loss: 2.7998516088700853e-05\n",
      "Epoch 3834, Loss: 0.0012286395722185262, Final Batch Loss: 5.2474708354566246e-05\n",
      "Epoch 3835, Loss: 0.0005018377414671704, Final Batch Loss: 0.0003158571198582649\n",
      "Epoch 3836, Loss: 0.00019468105529085733, Final Batch Loss: 1.7865484551293775e-05\n",
      "Epoch 3837, Loss: 0.000374918534362223, Final Batch Loss: 5.070151019026525e-05\n",
      "Epoch 3838, Loss: 0.0007266674438142218, Final Batch Loss: 3.788219692069106e-05\n",
      "Epoch 3839, Loss: 0.010014975610829424, Final Batch Loss: 0.009975571185350418\n",
      "Epoch 3840, Loss: 0.0010421698170830496, Final Batch Loss: 6.454071990447119e-05\n",
      "Epoch 3841, Loss: 0.01871937447140226, Final Batch Loss: 0.014043743722140789\n",
      "Epoch 3842, Loss: 0.0022944056399865076, Final Batch Loss: 0.001598481903783977\n",
      "Epoch 3843, Loss: 0.0008546198678232031, Final Batch Loss: 1.562337638461031e-05\n",
      "Epoch 3844, Loss: 0.00023974729811016005, Final Batch Loss: 0.0001714034005999565\n",
      "Epoch 3845, Loss: 0.0007315525072044693, Final Batch Loss: 0.00014449843729380518\n",
      "Epoch 3846, Loss: 0.00035342360206414014, Final Batch Loss: 3.671057493193075e-05\n",
      "Epoch 3847, Loss: 0.04174745969066862, Final Batch Loss: 0.041410088539123535\n",
      "Epoch 3848, Loss: 0.041933203174266964, Final Batch Loss: 0.04147952049970627\n",
      "Epoch 3849, Loss: 0.000778702727984637, Final Batch Loss: 0.0002584632020443678\n",
      "Epoch 3850, Loss: 0.0008800312352832407, Final Batch Loss: 0.0003053569816984236\n",
      "Epoch 3851, Loss: 0.000730318321075174, Final Batch Loss: 1.544364022265654e-05\n",
      "Epoch 3852, Loss: 0.006114526785722774, Final Batch Loss: 3.2192504022532376e-06\n",
      "Epoch 3853, Loss: 0.0003553549795469735, Final Batch Loss: 0.0001686461764620617\n",
      "Epoch 3854, Loss: 0.0012816968228435144, Final Batch Loss: 0.00028755521634593606\n",
      "Epoch 3855, Loss: 0.0005078179383417591, Final Batch Loss: 8.404298569075763e-05\n",
      "Epoch 3856, Loss: 0.0032199280758504756, Final Batch Loss: 0.00018298329086974263\n",
      "Epoch 3857, Loss: 0.00010157032556890044, Final Batch Loss: 1.6950565623119473e-05\n",
      "Epoch 3858, Loss: 0.0009415899767191149, Final Batch Loss: 8.376249024877325e-05\n",
      "Epoch 3859, Loss: 0.00022487644855573308, Final Batch Loss: 1.1496804290800355e-05\n",
      "Epoch 3860, Loss: 0.0011707042413036106, Final Batch Loss: 0.0006536486907862127\n",
      "Epoch 3861, Loss: 0.0012271353480173275, Final Batch Loss: 0.000911151000764221\n",
      "Epoch 3862, Loss: 0.027150973852258176, Final Batch Loss: 0.00027151836548000574\n",
      "Epoch 3863, Loss: 0.0010208391322521493, Final Batch Loss: 0.00047119217924773693\n",
      "Epoch 3864, Loss: 0.0005708025273634121, Final Batch Loss: 0.00013059757475275546\n",
      "Epoch 3865, Loss: 0.0008545526143279858, Final Batch Loss: 0.0001145182250184007\n",
      "Epoch 3866, Loss: 0.0009214705496560782, Final Batch Loss: 0.0004218388057779521\n",
      "Epoch 3867, Loss: 0.0005151697987457737, Final Batch Loss: 8.059889660216868e-05\n",
      "Epoch 3868, Loss: 0.0025075792509596795, Final Batch Loss: 0.00027122022584080696\n",
      "Epoch 3869, Loss: 0.0003708896620082669, Final Batch Loss: 6.773171480745077e-05\n",
      "Epoch 3870, Loss: 0.0004390110698295757, Final Batch Loss: 0.00010948393901344389\n",
      "Epoch 3871, Loss: 0.00042926002060994506, Final Batch Loss: 7.501130312448367e-05\n",
      "Epoch 3872, Loss: 0.0002598873143142555, Final Batch Loss: 2.321199281141162e-05\n",
      "Epoch 3873, Loss: 0.0012589286852744408, Final Batch Loss: 0.0005144085153006017\n",
      "Epoch 3874, Loss: 0.0006823663134127855, Final Batch Loss: 8.452235488221049e-05\n",
      "Epoch 3875, Loss: 0.0006587696511815011, Final Batch Loss: 6.077108537283493e-06\n",
      "Epoch 3876, Loss: 0.00019402999942030874, Final Batch Loss: 7.347804512392031e-06\n",
      "Epoch 3877, Loss: 0.0005847661304869689, Final Batch Loss: 2.1022860892117023e-05\n",
      "Epoch 3878, Loss: 0.0014095053484197706, Final Batch Loss: 3.368307079654187e-05\n",
      "Epoch 3879, Loss: 0.0003809951485891361, Final Batch Loss: 3.66252897947561e-05\n",
      "Epoch 3880, Loss: 0.00016693729048711248, Final Batch Loss: 1.974689439521171e-05\n",
      "Epoch 3881, Loss: 0.0018176227604271844, Final Batch Loss: 0.00015795163926668465\n",
      "Epoch 3882, Loss: 0.0005255922151263803, Final Batch Loss: 0.0001449375704396516\n",
      "Epoch 3883, Loss: 0.00026824194355867803, Final Batch Loss: 3.48190005752258e-05\n",
      "Epoch 3884, Loss: 0.00014228666077542584, Final Batch Loss: 9.654742461862043e-05\n",
      "Epoch 3885, Loss: 0.0003961270849686116, Final Batch Loss: 1.4978846593294293e-05\n",
      "Epoch 3886, Loss: 0.0005078200010757428, Final Batch Loss: 3.4604214306455106e-05\n",
      "Epoch 3887, Loss: 0.00043519475548237097, Final Batch Loss: 1.585815152793657e-05\n",
      "Epoch 3888, Loss: 0.0004724034952232614, Final Batch Loss: 6.805832526879385e-05\n",
      "Epoch 3889, Loss: 0.00036685153463622555, Final Batch Loss: 4.88116274937056e-05\n",
      "Epoch 3890, Loss: 0.0010092650045407936, Final Batch Loss: 0.0006646438268944621\n",
      "Epoch 3891, Loss: 0.0008138244920701254, Final Batch Loss: 0.0006264398689381778\n",
      "Epoch 3892, Loss: 0.0038110879831947386, Final Batch Loss: 0.0036887063179165125\n",
      "Epoch 3893, Loss: 0.0035381969646550715, Final Batch Loss: 0.0006415269454009831\n",
      "Epoch 3894, Loss: 0.00025783230921661016, Final Batch Loss: 8.088102913461626e-05\n",
      "Epoch 3895, Loss: 0.00038988924279692583, Final Batch Loss: 4.859725231654011e-05\n",
      "Epoch 3896, Loss: 0.00020879148269159487, Final Batch Loss: 7.288893357326742e-06\n",
      "Epoch 3897, Loss: 0.001404658833052963, Final Batch Loss: 0.0013362971367314458\n",
      "Epoch 3898, Loss: 0.0008446896390523762, Final Batch Loss: 2.9137900128262118e-05\n",
      "Epoch 3899, Loss: 0.00019642466395453084, Final Batch Loss: 4.699248165707104e-06\n",
      "Epoch 3900, Loss: 0.0008563365117879584, Final Batch Loss: 0.0006309806485660374\n",
      "Epoch 3901, Loss: 0.0005038474591856357, Final Batch Loss: 0.00033435042132623494\n",
      "Epoch 3902, Loss: 0.0010369154224463273, Final Batch Loss: 0.0008606111514382064\n",
      "Epoch 3903, Loss: 0.0003513121746436809, Final Batch Loss: 5.925675395701546e-06\n",
      "Epoch 3904, Loss: 0.013135498659721634, Final Batch Loss: 0.004109233617782593\n",
      "Epoch 3905, Loss: 0.0004901390275335871, Final Batch Loss: 0.0004376788274385035\n",
      "Epoch 3906, Loss: 0.008370727373403497, Final Batch Loss: 0.008042851462960243\n",
      "Epoch 3907, Loss: 0.00022214126329345163, Final Batch Loss: 5.3358573495643213e-05\n",
      "Epoch 3908, Loss: 0.005322963203070685, Final Batch Loss: 0.0003788472677115351\n",
      "Epoch 3909, Loss: 0.0021204455824772594, Final Batch Loss: 2.1391444533946924e-05\n",
      "Epoch 3910, Loss: 0.005696935491869226, Final Batch Loss: 0.0002714775619097054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3911, Loss: 0.008470979504636489, Final Batch Loss: 8.057862578425556e-05\n",
      "Epoch 3912, Loss: 0.0024613341920485254, Final Batch Loss: 2.379963916609995e-05\n",
      "Epoch 3913, Loss: 0.0011543126165634021, Final Batch Loss: 9.017869888339192e-05\n",
      "Epoch 3914, Loss: 0.00045421057438943535, Final Batch Loss: 5.796043842565268e-05\n",
      "Epoch 3915, Loss: 0.0006807203244534321, Final Batch Loss: 0.00021047839254606515\n",
      "Epoch 3916, Loss: 0.0003647216117315111, Final Batch Loss: 0.00014198017015587538\n",
      "Epoch 3917, Loss: 0.0018786405998980626, Final Batch Loss: 2.771224535536021e-05\n",
      "Epoch 3918, Loss: 0.0022675569781540617, Final Batch Loss: 1.007749347081699e-06\n",
      "Epoch 3919, Loss: 0.00043210254443692975, Final Batch Loss: 9.929144289344549e-05\n",
      "Epoch 3920, Loss: 0.0003109820536337793, Final Batch Loss: 4.0377686673309654e-05\n",
      "Epoch 3921, Loss: 0.13922503432331723, Final Batch Loss: 0.13899026811122894\n",
      "Epoch 3922, Loss: 0.0005540814099731506, Final Batch Loss: 1.1864519365190063e-05\n",
      "Epoch 3923, Loss: 0.0011189966899110004, Final Batch Loss: 6.225995457498357e-05\n",
      "Epoch 3924, Loss: 0.0003954535804950865, Final Batch Loss: 2.4443843358312733e-05\n",
      "Epoch 3925, Loss: 0.00981091872381512, Final Batch Loss: 8.290229015983641e-05\n",
      "Epoch 3926, Loss: 0.000952070582570741, Final Batch Loss: 4.114950934308581e-05\n",
      "Epoch 3927, Loss: 0.0003481304593151435, Final Batch Loss: 0.00012171301932539791\n",
      "Epoch 3928, Loss: 0.001714680140139535, Final Batch Loss: 0.00032944499980658293\n",
      "Epoch 3929, Loss: 0.0007709744240855798, Final Batch Loss: 9.131027036346495e-05\n",
      "Epoch 3930, Loss: 0.0012667479750234634, Final Batch Loss: 0.0001339810260105878\n",
      "Epoch 3931, Loss: 0.020587682869518176, Final Batch Loss: 0.00014752941206097603\n",
      "Epoch 3932, Loss: 0.005854733455635142, Final Batch Loss: 4.846280353376642e-05\n",
      "Epoch 3933, Loss: 0.0004747923885588534, Final Batch Loss: 0.00021745634148828685\n",
      "Epoch 3934, Loss: 0.0006757257215213031, Final Batch Loss: 0.00011350792919984087\n",
      "Epoch 3935, Loss: 0.0005905032958253287, Final Batch Loss: 0.00011303846986265853\n",
      "Epoch 3936, Loss: 0.0009958725204342045, Final Batch Loss: 8.734160655876622e-05\n",
      "Epoch 3937, Loss: 0.0003713801452249754, Final Batch Loss: 1.6398913430748507e-05\n",
      "Epoch 3938, Loss: 0.0002911865458372631, Final Batch Loss: 0.00014506570005323738\n",
      "Epoch 3939, Loss: 0.0005939529455645243, Final Batch Loss: 0.0002558896958362311\n",
      "Epoch 3940, Loss: 0.00012611459987965645, Final Batch Loss: 1.5233182239171583e-05\n",
      "Epoch 3941, Loss: 0.0006013427992002107, Final Batch Loss: 0.00022397069551516324\n",
      "Epoch 3942, Loss: 0.00048044308277894743, Final Batch Loss: 0.00013221030530985445\n",
      "Epoch 3943, Loss: 0.00014197589371178765, Final Batch Loss: 4.773515684064478e-05\n",
      "Epoch 3944, Loss: 0.0001234602641488891, Final Batch Loss: 1.7609778296900913e-05\n",
      "Epoch 3945, Loss: 0.000334518403178663, Final Batch Loss: 1.962591522897128e-05\n",
      "Epoch 3946, Loss: 0.000660072939353995, Final Batch Loss: 0.00021783050033263862\n",
      "Epoch 3947, Loss: 0.0009800855150388088, Final Batch Loss: 0.0008573147933930159\n",
      "Epoch 3948, Loss: 0.0009166219642793294, Final Batch Loss: 0.0005463979905471206\n",
      "Epoch 3949, Loss: 0.00031046391814015806, Final Batch Loss: 6.365108856698498e-05\n",
      "Epoch 3950, Loss: 0.0002717593051784206, Final Batch Loss: 0.00011231514508835971\n",
      "Epoch 3951, Loss: 0.012180220252048457, Final Batch Loss: 0.0004294730315450579\n",
      "Epoch 3952, Loss: 0.0005879774398636073, Final Batch Loss: 5.9707992477342486e-05\n",
      "Epoch 3953, Loss: 0.0010592969883873593, Final Batch Loss: 0.0004481288488022983\n",
      "Epoch 3954, Loss: 0.00984360843358445, Final Batch Loss: 0.003864761209115386\n",
      "Epoch 3955, Loss: 0.0007544481650256785, Final Batch Loss: 2.5299408662249334e-05\n",
      "Epoch 3956, Loss: 0.0013323856746865204, Final Batch Loss: 1.0538735295995139e-05\n",
      "Epoch 3957, Loss: 0.0003000482320203446, Final Batch Loss: 6.206822581589222e-05\n",
      "Epoch 3958, Loss: 0.00027873346334672533, Final Batch Loss: 0.00017641522572375834\n",
      "Epoch 3959, Loss: 0.0018159512037527747, Final Batch Loss: 0.0015614167787134647\n",
      "Epoch 3960, Loss: 0.000346173696925689, Final Batch Loss: 1.2319041161390487e-05\n",
      "Epoch 3961, Loss: 0.002197248955781106, Final Batch Loss: 4.229124897392467e-05\n",
      "Epoch 3962, Loss: 0.00023000544933893252, Final Batch Loss: 1.554558730276767e-05\n",
      "Epoch 3963, Loss: 0.00020148162002442405, Final Batch Loss: 0.00014087400631979108\n",
      "Epoch 3964, Loss: 0.0009172872523777187, Final Batch Loss: 9.330359171144664e-05\n",
      "Epoch 3965, Loss: 0.0007981247326824814, Final Batch Loss: 0.0004085951077286154\n",
      "Epoch 3966, Loss: 0.0015711493069829885, Final Batch Loss: 2.3163451260188594e-05\n",
      "Epoch 3967, Loss: 7.5331115112931e-05, Final Batch Loss: 3.438841304159723e-05\n",
      "Epoch 3968, Loss: 0.00116495868792299, Final Batch Loss: 3.783722831940395e-06\n",
      "Epoch 3969, Loss: 0.00016859701827343088, Final Batch Loss: 2.6437313863425516e-05\n",
      "Epoch 3970, Loss: 0.00014959558939153794, Final Batch Loss: 1.802528822736349e-05\n",
      "Epoch 3971, Loss: 0.003136309667070236, Final Batch Loss: 3.753109240278718e-06\n",
      "Epoch 3972, Loss: 6.517208748846315e-05, Final Batch Loss: 1.542866630188655e-05\n",
      "Epoch 3973, Loss: 0.001276539609534666, Final Batch Loss: 0.0007325136102735996\n",
      "Epoch 3974, Loss: 0.0017470551756559871, Final Batch Loss: 0.00013944429520051926\n",
      "Epoch 3975, Loss: 0.001207570341648534, Final Batch Loss: 0.00014143070438876748\n",
      "Epoch 3976, Loss: 0.0002714220536290668, Final Batch Loss: 0.0002057017554761842\n",
      "Epoch 3977, Loss: 0.008013457016204484, Final Batch Loss: 9.44924249779433e-05\n",
      "Epoch 3978, Loss: 0.00014899661528033903, Final Batch Loss: 1.3925689017924014e-05\n",
      "Epoch 3979, Loss: 8.037809402594576e-05, Final Batch Loss: 4.871727651334368e-05\n",
      "Epoch 3980, Loss: 0.0045843636835343204, Final Batch Loss: 4.543008253676817e-05\n",
      "Epoch 3981, Loss: 0.001254423861610121, Final Batch Loss: 0.0008286377415060997\n",
      "Epoch 3982, Loss: 0.0008469829554087482, Final Batch Loss: 0.0006861947476863861\n",
      "Epoch 3983, Loss: 0.0001478675603721058, Final Batch Loss: 9.099014278035611e-05\n",
      "Epoch 3984, Loss: 0.0001695443752396386, Final Batch Loss: 8.159014396369457e-05\n",
      "Epoch 3985, Loss: 0.0008908174131647684, Final Batch Loss: 2.371317896177061e-05\n",
      "Epoch 3986, Loss: 0.0018631521124916617, Final Batch Loss: 4.225130032864399e-05\n",
      "Epoch 3987, Loss: 0.00036265224480303004, Final Batch Loss: 0.00013928720727562904\n",
      "Epoch 3988, Loss: 0.0004433351641637273, Final Batch Loss: 0.00019041828636545688\n",
      "Epoch 3989, Loss: 0.0003143063886454911, Final Batch Loss: 1.3688281796930823e-05\n",
      "Epoch 3990, Loss: 0.0005226695957389893, Final Batch Loss: 0.00046874277177266777\n",
      "Epoch 3991, Loss: 0.0025722289210534655, Final Batch Loss: 2.0485822460614145e-05\n",
      "Epoch 3992, Loss: 0.0017716871807351708, Final Batch Loss: 0.0006496353889815509\n",
      "Epoch 3993, Loss: 0.0007377217962130089, Final Batch Loss: 9.540000064589549e-06\n",
      "Epoch 3994, Loss: 0.0004592266059262329, Final Batch Loss: 6.641182153543923e-06\n",
      "Epoch 3995, Loss: 0.00022465034635388292, Final Batch Loss: 6.531347753480077e-05\n",
      "Epoch 3996, Loss: 8.41142468743783e-05, Final Batch Loss: 4.589987383951666e-06\n",
      "Epoch 3997, Loss: 0.00020051802130183205, Final Batch Loss: 3.232581366319209e-05\n",
      "Epoch 3998, Loss: 0.0002775268512777984, Final Batch Loss: 8.280781912617385e-05\n",
      "Epoch 3999, Loss: 0.005087890025606612, Final Batch Loss: 1.2710868759313598e-05\n",
      "Epoch 4000, Loss: 0.00021605277356684383, Final Batch Loss: 2.8864094474556623e-06\n",
      "Epoch 4001, Loss: 0.0025188747104039066, Final Batch Loss: 3.1751778806210496e-06\n",
      "Epoch 4002, Loss: 0.0023213302501972066, Final Batch Loss: 0.0001034174274536781\n",
      "Epoch 4003, Loss: 0.0001321448289672844, Final Batch Loss: 3.317483060527593e-05\n",
      "Epoch 4004, Loss: 0.020097620523301885, Final Batch Loss: 0.00010207858576904982\n",
      "Epoch 4005, Loss: 0.00039893561915960163, Final Batch Loss: 5.646450517815538e-05\n",
      "Epoch 4006, Loss: 0.00027995059645036235, Final Batch Loss: 2.139159187208861e-05\n",
      "Epoch 4007, Loss: 0.002722550962062087, Final Batch Loss: 0.0004820415051653981\n",
      "Epoch 4008, Loss: 0.0005969820576865459, Final Batch Loss: 1.4971841665101238e-05\n",
      "Epoch 4009, Loss: 0.00030615839932579547, Final Batch Loss: 5.280360346660018e-05\n",
      "Epoch 4010, Loss: 0.00013573121941590216, Final Batch Loss: 8.392001473112032e-05\n",
      "Epoch 4011, Loss: 0.0005655423174175667, Final Batch Loss: 1.3763363313046284e-05\n",
      "Epoch 4012, Loss: 0.0015520433480560314, Final Batch Loss: 0.0002999001007992774\n",
      "Epoch 4013, Loss: 5.7916660807677545e-05, Final Batch Loss: 4.097152122994885e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4014, Loss: 0.00029377736063906923, Final Batch Loss: 7.196698425104842e-05\n",
      "Epoch 4015, Loss: 0.0002952090399048757, Final Batch Loss: 1.6119225620059296e-05\n",
      "Epoch 4016, Loss: 0.00011466864634712692, Final Batch Loss: 4.989923399989493e-05\n",
      "Epoch 4017, Loss: 0.0010979668732034042, Final Batch Loss: 0.0001864258520072326\n",
      "Epoch 4018, Loss: 0.00028385394762153737, Final Batch Loss: 3.689829827635549e-05\n",
      "Epoch 4019, Loss: 0.00039368276884488296, Final Batch Loss: 1.0113797543453984e-05\n",
      "Epoch 4020, Loss: 0.0003459362269495614, Final Batch Loss: 0.0002586371556390077\n",
      "Epoch 4021, Loss: 0.0001469573107897304, Final Batch Loss: 4.577719664666802e-05\n",
      "Epoch 4022, Loss: 0.0002622909842102672, Final Batch Loss: 9.613788279239088e-05\n",
      "Epoch 4023, Loss: 0.0011350955119269202, Final Batch Loss: 0.0005280650802887976\n",
      "Epoch 4024, Loss: 0.0008206285783671774, Final Batch Loss: 0.0001055775283020921\n",
      "Epoch 4025, Loss: 0.0003525186639308231, Final Batch Loss: 0.0002464009739924222\n",
      "Epoch 4026, Loss: 0.0006034559301042464, Final Batch Loss: 6.044309338903986e-05\n",
      "Epoch 4027, Loss: 0.0009193075670737016, Final Batch Loss: 0.00028801296139135957\n",
      "Epoch 4028, Loss: 0.00012817440710932715, Final Batch Loss: 8.159177377820015e-05\n",
      "Epoch 4029, Loss: 7.81373764766613e-05, Final Batch Loss: 5.4489748436026275e-05\n",
      "Epoch 4030, Loss: 0.00015089469889062457, Final Batch Loss: 1.4662660760222934e-05\n",
      "Epoch 4031, Loss: 8.443654405709822e-05, Final Batch Loss: 2.4272003429359756e-05\n",
      "Epoch 4032, Loss: 0.0009706724786155974, Final Batch Loss: 0.0009396105306223035\n",
      "Epoch 4033, Loss: 0.00016903632149478653, Final Batch Loss: 0.00014869373990222812\n",
      "Epoch 4034, Loss: 0.00035921429662266746, Final Batch Loss: 0.0002563947346061468\n",
      "Epoch 4035, Loss: 0.0004662665742216632, Final Batch Loss: 0.00023547658929601312\n",
      "Epoch 4036, Loss: 0.00011867715761582076, Final Batch Loss: 1.9597816844907356e-06\n",
      "Epoch 4037, Loss: 0.00044230216735741124, Final Batch Loss: 0.00012032063386868685\n",
      "Epoch 4038, Loss: 6.196160211402457e-05, Final Batch Loss: 1.5861292922636494e-05\n",
      "Epoch 4039, Loss: 0.0023871448956924723, Final Batch Loss: 2.571789809735492e-05\n",
      "Epoch 4040, Loss: 0.00016191886243177578, Final Batch Loss: 4.647968307835981e-05\n",
      "Epoch 4041, Loss: 0.0019613108970588655, Final Batch Loss: 1.2106204849260394e-05\n",
      "Epoch 4042, Loss: 0.0005156263505341485, Final Batch Loss: 9.796513768378645e-05\n",
      "Epoch 4043, Loss: 7.209234445326729e-05, Final Batch Loss: 5.7590757933212444e-05\n",
      "Epoch 4044, Loss: 0.00046429498524958035, Final Batch Loss: 1.2927383977512363e-05\n",
      "Epoch 4045, Loss: 0.00014347475371323526, Final Batch Loss: 5.796616824227385e-05\n",
      "Epoch 4046, Loss: 9.199403655202332e-05, Final Batch Loss: 1.1898699767698417e-06\n",
      "Epoch 4047, Loss: 4.101613558304962e-05, Final Batch Loss: 1.667367178015411e-05\n",
      "Epoch 4048, Loss: 0.00043590673521975987, Final Batch Loss: 5.07365184603259e-05\n",
      "Epoch 4049, Loss: 0.0011407513220547116, Final Batch Loss: 0.0009571387781761587\n",
      "Epoch 4050, Loss: 0.00018984144844580442, Final Batch Loss: 0.00012314932246226817\n",
      "Epoch 4051, Loss: 0.0027832597688757232, Final Batch Loss: 2.107980617438443e-05\n",
      "Epoch 4052, Loss: 0.0003455923251749482, Final Batch Loss: 3.8803704228485e-05\n",
      "Epoch 4053, Loss: 9.224235009241966e-05, Final Batch Loss: 7.248479505506111e-06\n",
      "Epoch 4054, Loss: 0.0002900470731219684, Final Batch Loss: 0.00025767626357264817\n",
      "Epoch 4055, Loss: 0.00040399990348305437, Final Batch Loss: 5.236633569438709e-06\n",
      "Epoch 4056, Loss: 0.00523865577270044, Final Batch Loss: 0.000251074496190995\n",
      "Epoch 4057, Loss: 0.00042754580863402225, Final Batch Loss: 4.687348337029107e-05\n",
      "Epoch 4058, Loss: 5.132109254191164e-05, Final Batch Loss: 5.3221447160467505e-06\n",
      "Epoch 4059, Loss: 2.246324265797739e-05, Final Batch Loss: 7.752533747407142e-06\n",
      "Epoch 4060, Loss: 0.00035316475259605795, Final Batch Loss: 0.00010604139242786914\n",
      "Epoch 4061, Loss: 0.00010086301017508958, Final Batch Loss: 2.8849249247286934e-06\n",
      "Epoch 4062, Loss: 0.03777509125939105, Final Batch Loss: 7.5527947046794e-05\n",
      "Epoch 4063, Loss: 0.00018891791660280433, Final Batch Loss: 4.964448089594953e-05\n",
      "Epoch 4064, Loss: 0.0002538285015134534, Final Batch Loss: 6.41384644950449e-07\n",
      "Epoch 4065, Loss: 0.000515243380505126, Final Batch Loss: 5.3919749916531146e-05\n",
      "Epoch 4066, Loss: 0.0024175639955501538, Final Batch Loss: 3.646006007329561e-05\n",
      "Epoch 4067, Loss: 0.0005307326446200022, Final Batch Loss: 0.0004891332355327904\n",
      "Epoch 4068, Loss: 0.0001200838632939849, Final Batch Loss: 2.3904893168946728e-05\n",
      "Epoch 4069, Loss: 0.0006005921859468799, Final Batch Loss: 4.127151260036044e-05\n",
      "Epoch 4070, Loss: 0.00010548861791903619, Final Batch Loss: 3.5022552765440196e-05\n",
      "Epoch 4071, Loss: 0.0007185226759247598, Final Batch Loss: 6.705970918119419e-06\n",
      "Epoch 4072, Loss: 0.0005458466002892237, Final Batch Loss: 0.000449027749709785\n",
      "Epoch 4073, Loss: 0.00022741203065379523, Final Batch Loss: 6.596295861527324e-05\n",
      "Epoch 4074, Loss: 0.0009566822918714024, Final Batch Loss: 0.00011613798415055498\n",
      "Epoch 4075, Loss: 0.00020506216105786734, Final Batch Loss: 5.788102953374619e-06\n",
      "Epoch 4076, Loss: 0.0020825148749281652, Final Batch Loss: 0.0016144703840836883\n",
      "Epoch 4077, Loss: 0.0001229813788086176, Final Batch Loss: 5.430771125247702e-05\n",
      "Epoch 4078, Loss: 0.00010478036892891396, Final Batch Loss: 6.331949407467619e-05\n",
      "Epoch 4079, Loss: 0.0005156421393621713, Final Batch Loss: 0.00010895198647631332\n",
      "Epoch 4080, Loss: 0.0037364828185673105, Final Batch Loss: 1.6497298929607496e-05\n",
      "Epoch 4081, Loss: 8.680376686243108e-05, Final Batch Loss: 1.0841739822353702e-05\n",
      "Epoch 4082, Loss: 0.0001945344847626984, Final Batch Loss: 3.4783217415679246e-05\n",
      "Epoch 4083, Loss: 7.33992983441567e-05, Final Batch Loss: 4.006277595181018e-05\n",
      "Epoch 4084, Loss: 0.004219781672873069, Final Batch Loss: 0.0037387891206890345\n",
      "Epoch 4085, Loss: 0.00038242787195486017, Final Batch Loss: 0.00010488777479622513\n",
      "Epoch 4086, Loss: 0.005165503487660317, Final Batch Loss: 4.634639117284678e-05\n",
      "Epoch 4087, Loss: 0.00020691125973826274, Final Batch Loss: 1.726780283206608e-05\n",
      "Epoch 4088, Loss: 0.0012982952157472027, Final Batch Loss: 0.001155117410235107\n",
      "Epoch 4089, Loss: 0.00010354181586080813, Final Batch Loss: 5.959330883342773e-05\n",
      "Epoch 4090, Loss: 0.00013762188791588414, Final Batch Loss: 7.203580753412098e-05\n",
      "Epoch 4091, Loss: 0.0002341274630452972, Final Batch Loss: 8.268186502391472e-05\n",
      "Epoch 4092, Loss: 0.0002359493000767543, Final Batch Loss: 9.34706531552365e-06\n",
      "Epoch 4093, Loss: 0.0016733511383790756, Final Batch Loss: 9.685240001999773e-06\n",
      "Epoch 4094, Loss: 0.000718815343134338, Final Batch Loss: 0.0006425492465496063\n",
      "Epoch 4095, Loss: 0.00014009118058311287, Final Batch Loss: 2.5746914616320282e-05\n",
      "Epoch 4096, Loss: 0.0006437451038436848, Final Batch Loss: 1.2585805052367505e-05\n",
      "Epoch 4097, Loss: 0.0002431572174828034, Final Batch Loss: 3.2345076760975644e-05\n",
      "Epoch 4098, Loss: 0.00021375388246269722, Final Batch Loss: 7.590075256302953e-05\n",
      "Epoch 4099, Loss: 0.0005614388064714149, Final Batch Loss: 7.320691656786948e-05\n",
      "Epoch 4100, Loss: 5.632013017020654e-05, Final Batch Loss: 1.0577295142866205e-05\n",
      "Epoch 4101, Loss: 0.0006447086507250788, Final Batch Loss: 1.1257887308602221e-05\n",
      "Epoch 4102, Loss: 0.00018532067201704194, Final Batch Loss: 0.00012407000758685172\n",
      "Epoch 4103, Loss: 0.00020225835396558978, Final Batch Loss: 4.4264983444008976e-05\n",
      "Epoch 4104, Loss: 0.00017607723930268548, Final Batch Loss: 3.441316221142188e-05\n",
      "Epoch 4105, Loss: 0.0001669102730375016, Final Batch Loss: 2.7916274120798334e-05\n",
      "Epoch 4106, Loss: 0.0003178367478540167, Final Batch Loss: 3.848081541946158e-05\n",
      "Epoch 4107, Loss: 0.00018171240117226262, Final Batch Loss: 1.1994025044259615e-05\n",
      "Epoch 4108, Loss: 0.0006471515735029243, Final Batch Loss: 0.00019077416800428182\n",
      "Epoch 4109, Loss: 0.0001516946176707279, Final Batch Loss: 2.509185651433654e-05\n",
      "Epoch 4110, Loss: 0.00017405834478267934, Final Batch Loss: 2.1281153749441728e-05\n",
      "Epoch 4111, Loss: 0.0005976590364298318, Final Batch Loss: 0.00013032174319960177\n",
      "Epoch 4112, Loss: 0.00011478515534690814, Final Batch Loss: 2.811629201460164e-05\n",
      "Epoch 4113, Loss: 9.556008444633335e-05, Final Batch Loss: 4.4287400669418275e-05\n",
      "Epoch 4114, Loss: 0.00012204924132674932, Final Batch Loss: 1.597643677087035e-05\n",
      "Epoch 4115, Loss: 0.0004916607576888055, Final Batch Loss: 0.0001854019210441038\n",
      "Epoch 4116, Loss: 0.00037043657357571647, Final Batch Loss: 0.0002241565234726295\n",
      "Epoch 4117, Loss: 0.0003986435694969259, Final Batch Loss: 0.00030660867923870683\n",
      "Epoch 4118, Loss: 0.0018319075725230505, Final Batch Loss: 1.5207388969429303e-05\n",
      "Epoch 4119, Loss: 0.0010151664027944207, Final Batch Loss: 8.647662616567686e-05\n",
      "Epoch 4120, Loss: 0.00034353738601566874, Final Batch Loss: 5.3324423788581043e-05\n",
      "Epoch 4121, Loss: 0.00032772809026937466, Final Batch Loss: 0.00011359810014255345\n",
      "Epoch 4122, Loss: 0.0009123260242631659, Final Batch Loss: 0.00019539895583875477\n",
      "Epoch 4123, Loss: 8.577031735512719e-05, Final Batch Loss: 3.719267851920449e-06\n",
      "Epoch 4124, Loss: 0.0004718037321254087, Final Batch Loss: 0.00026604090817272663\n",
      "Epoch 4125, Loss: 3.122809994238196e-05, Final Batch Loss: 9.725781637826003e-06\n",
      "Epoch 4126, Loss: 0.00019595631692936877, Final Batch Loss: 8.832518687995616e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4127, Loss: 0.00034376338135189144, Final Batch Loss: 1.4679603737022262e-05\n",
      "Epoch 4128, Loss: 0.00014399663098174642, Final Batch Loss: 1.8992597006217693e-06\n",
      "Epoch 4129, Loss: 3.7750332012365106e-05, Final Batch Loss: 3.1320496418629773e-06\n",
      "Epoch 4130, Loss: 0.0009350186955998652, Final Batch Loss: 0.0007386626675724983\n",
      "Epoch 4131, Loss: 0.0006718194290442625, Final Batch Loss: 0.0006061316234990954\n",
      "Epoch 4132, Loss: 0.0001502020786574576, Final Batch Loss: 3.257671050960198e-05\n",
      "Epoch 4133, Loss: 0.00013681551808986114, Final Batch Loss: 6.615090569539461e-06\n",
      "Epoch 4134, Loss: 0.001672957113441953, Final Batch Loss: 1.9436838556430303e-06\n",
      "Epoch 4135, Loss: 0.0003407806798350066, Final Batch Loss: 5.501176929101348e-06\n",
      "Epoch 4136, Loss: 0.0006142539077700349, Final Batch Loss: 3.840584759018384e-05\n",
      "Epoch 4137, Loss: 0.0005792053834738908, Final Batch Loss: 0.0004601020482368767\n",
      "Epoch 4138, Loss: 0.0001140774675150169, Final Batch Loss: 3.682211536215618e-05\n",
      "Epoch 4139, Loss: 3.5771576449405984e-05, Final Batch Loss: 8.949668881541584e-06\n",
      "Epoch 4140, Loss: 0.0007312065936275758, Final Batch Loss: 5.4210624512052163e-05\n",
      "Epoch 4141, Loss: 0.0004984722663721186, Final Batch Loss: 8.597652595199179e-06\n",
      "Epoch 4142, Loss: 3.8368114928744035e-05, Final Batch Loss: 1.695203536655754e-05\n",
      "Epoch 4143, Loss: 8.56739152368391e-05, Final Batch Loss: 4.619804894900881e-05\n",
      "Epoch 4144, Loss: 0.0001560176388011314, Final Batch Loss: 8.01098212832585e-06\n",
      "Epoch 4145, Loss: 0.0001779680037543585, Final Batch Loss: 4.321731012169039e-06\n",
      "Epoch 4146, Loss: 0.0002282467521581566, Final Batch Loss: 9.7880263638217e-05\n",
      "Epoch 4147, Loss: 0.0008557077981095063, Final Batch Loss: 2.0802157450816594e-05\n",
      "Epoch 4148, Loss: 0.0009278653224100708, Final Batch Loss: 3.34619871864561e-05\n",
      "Epoch 4149, Loss: 0.0001176408968603937, Final Batch Loss: 8.934173820307478e-05\n",
      "Epoch 4150, Loss: 0.0004958911813446321, Final Batch Loss: 0.00041232569492422044\n",
      "Epoch 4151, Loss: 7.183420348155778e-05, Final Batch Loss: 4.335183348302962e-06\n",
      "Epoch 4152, Loss: 0.00018189407546742586, Final Batch Loss: 3.360338268976193e-06\n",
      "Epoch 4153, Loss: 0.00044441327918320894, Final Batch Loss: 7.849800022086129e-05\n",
      "Epoch 4154, Loss: 9.544514512072055e-05, Final Batch Loss: 5.14168459631037e-05\n",
      "Epoch 4155, Loss: 9.810825940803625e-05, Final Batch Loss: 1.6283298464259133e-05\n",
      "Epoch 4156, Loss: 0.00033674210135359317, Final Batch Loss: 0.00012334120401646942\n",
      "Epoch 4157, Loss: 9.695111430119141e-05, Final Batch Loss: 2.1808132260048296e-06\n",
      "Epoch 4158, Loss: 4.2125541312998394e-05, Final Batch Loss: 5.099206191516714e-06\n",
      "Epoch 4159, Loss: 0.0003489991959213512, Final Batch Loss: 2.1085432308609597e-05\n",
      "Epoch 4160, Loss: 0.0002502392071619397, Final Batch Loss: 1.290753971261438e-05\n",
      "Epoch 4161, Loss: 5.793388299935032e-05, Final Batch Loss: 7.398863544949563e-06\n",
      "Epoch 4162, Loss: 0.00011396986883482896, Final Batch Loss: 1.5740211892989464e-05\n",
      "Epoch 4163, Loss: 0.0002565416980360169, Final Batch Loss: 6.25097964075394e-05\n",
      "Epoch 4164, Loss: 4.4560188143805135e-05, Final Batch Loss: 7.287818334589247e-06\n",
      "Epoch 4165, Loss: 0.0005953212466920377, Final Batch Loss: 0.00011256202560616657\n",
      "Epoch 4166, Loss: 0.0002464497956680134, Final Batch Loss: 5.1261096814414486e-05\n",
      "Epoch 4167, Loss: 0.00018093108519678935, Final Batch Loss: 2.6567593522486277e-05\n",
      "Epoch 4168, Loss: 9.021433515954413e-05, Final Batch Loss: 1.0256107088935096e-05\n",
      "Epoch 4169, Loss: 0.00012917519700295088, Final Batch Loss: 1.663752414060582e-06\n",
      "Epoch 4170, Loss: 2.8387823704179027e-05, Final Batch Loss: 2.9492150588339427e-06\n",
      "Epoch 4171, Loss: 4.765883613799815e-05, Final Batch Loss: 2.177830992877716e-06\n",
      "Epoch 4172, Loss: 0.000112094036921917, Final Batch Loss: 1.3052856047579553e-05\n",
      "Epoch 4173, Loss: 7.986587354480434e-05, Final Batch Loss: 1.0816335134222754e-06\n",
      "Epoch 4174, Loss: 0.00012952511497132946, Final Batch Loss: 3.7753507058368996e-05\n",
      "Epoch 4175, Loss: 9.98456835077377e-05, Final Batch Loss: 1.4290388207882643e-05\n",
      "Epoch 4176, Loss: 0.0002264070753881242, Final Batch Loss: 2.5654240744188428e-05\n",
      "Epoch 4177, Loss: 0.0004939998580084648, Final Batch Loss: 0.0004466157406568527\n",
      "Epoch 4178, Loss: 0.0003303692501503974, Final Batch Loss: 2.21504014916718e-05\n",
      "Epoch 4179, Loss: 8.867269662005128e-05, Final Batch Loss: 9.597652933734935e-06\n",
      "Epoch 4180, Loss: 0.0003626599441304279, Final Batch Loss: 0.00013764319010078907\n",
      "Epoch 4181, Loss: 0.04279836575938134, Final Batch Loss: 4.409163011587225e-06\n",
      "Epoch 4182, Loss: 0.0012811896822313429, Final Batch Loss: 4.167611223238055e-06\n",
      "Epoch 4183, Loss: 0.00019066117602051236, Final Batch Loss: 7.607031875522807e-06\n",
      "Epoch 4184, Loss: 0.00027356493956176564, Final Batch Loss: 3.49847978213802e-05\n",
      "Epoch 4185, Loss: 0.0021229634880910453, Final Batch Loss: 4.743073441204615e-05\n",
      "Epoch 4186, Loss: 0.002464757508278126, Final Batch Loss: 0.00010014247527578846\n",
      "Epoch 4187, Loss: 0.0005431075387605233, Final Batch Loss: 0.0004356552381068468\n",
      "Epoch 4188, Loss: 0.0008024179587664548, Final Batch Loss: 0.00017491031030658633\n",
      "Epoch 4189, Loss: 0.0003511142094794195, Final Batch Loss: 3.127246236545034e-05\n",
      "Epoch 4190, Loss: 0.00012598100693139713, Final Batch Loss: 1.664864430495072e-05\n",
      "Epoch 4191, Loss: 0.00019227294887969038, Final Batch Loss: 3.29840331687592e-05\n",
      "Epoch 4192, Loss: 0.0002553621952756657, Final Batch Loss: 1.240289111592574e-05\n",
      "Epoch 4193, Loss: 0.0021079582802485675, Final Batch Loss: 0.00024625324294902384\n",
      "Epoch 4194, Loss: 3.427551882850821e-05, Final Batch Loss: 1.9693365175044164e-05\n",
      "Epoch 4195, Loss: 0.0005285168936097762, Final Batch Loss: 0.00029423178057186306\n",
      "Epoch 4196, Loss: 0.00019025884466827847, Final Batch Loss: 3.8526715798070654e-05\n",
      "Epoch 4197, Loss: 0.00046221927732403856, Final Batch Loss: 4.1380520997336134e-05\n",
      "Epoch 4198, Loss: 0.0003604208222895977, Final Batch Loss: 4.0831560909282416e-05\n",
      "Epoch 4199, Loss: 0.00018462875459590578, Final Batch Loss: 7.315304628718877e-06\n",
      "Epoch 4200, Loss: 0.00029965311659907456, Final Batch Loss: 2.5803792595979758e-05\n",
      "Epoch 4201, Loss: 0.00016482524370076135, Final Batch Loss: 7.948298298288137e-05\n",
      "Epoch 4202, Loss: 0.0006891654750234011, Final Batch Loss: 2.3806524040992372e-05\n",
      "Epoch 4203, Loss: 0.00016565750411245972, Final Batch Loss: 4.5712153223576024e-05\n",
      "Epoch 4204, Loss: 5.703294209524756e-05, Final Batch Loss: 1.3101785953040235e-05\n",
      "Epoch 4205, Loss: 0.00026421842449053656, Final Batch Loss: 1.018023249343969e-05\n",
      "Epoch 4206, Loss: 0.00012336333384155296, Final Batch Loss: 1.5819678083062172e-05\n",
      "Epoch 4207, Loss: 0.0004352915202616714, Final Batch Loss: 0.00010916392056969926\n",
      "Epoch 4208, Loss: 0.00020238919569237623, Final Batch Loss: 8.159997378243133e-05\n",
      "Epoch 4209, Loss: 3.488162656140048e-05, Final Batch Loss: 2.132124973286409e-05\n",
      "Epoch 4210, Loss: 0.00016430522123300761, Final Batch Loss: 1.8246621493744897e-06\n",
      "Epoch 4211, Loss: 0.00026014318154921057, Final Batch Loss: 2.1299656509654596e-05\n",
      "Epoch 4212, Loss: 0.02932739386415051, Final Batch Loss: 4.751291635329835e-05\n",
      "Epoch 4213, Loss: 0.0002032979900832288, Final Batch Loss: 9.174896695185453e-05\n",
      "Epoch 4214, Loss: 0.0005715527113352437, Final Batch Loss: 0.0005315098678693175\n",
      "Epoch 4215, Loss: 0.0004478300324990414, Final Batch Loss: 9.277618664782494e-05\n",
      "Epoch 4216, Loss: 0.00034114816298824735, Final Batch Loss: 0.00015476089902222157\n",
      "Epoch 4217, Loss: 0.0009817957834457047, Final Batch Loss: 6.230594590306282e-05\n",
      "Epoch 4218, Loss: 0.0013368677856533395, Final Batch Loss: 0.0012672798475250602\n",
      "Epoch 4219, Loss: 0.00015559095118078403, Final Batch Loss: 7.469160482287407e-05\n",
      "Epoch 4220, Loss: 0.0005692219783668406, Final Batch Loss: 0.0001946770935319364\n",
      "Epoch 4221, Loss: 0.0002189563679166895, Final Batch Loss: 4.641290161089273e-06\n",
      "Epoch 4222, Loss: 0.0005483104778249981, Final Batch Loss: 2.6436036932864226e-05\n",
      "Epoch 4223, Loss: 8.016109859454446e-05, Final Batch Loss: 3.289981032139622e-05\n",
      "Epoch 4224, Loss: 0.00011137228921143105, Final Batch Loss: 4.683931911131367e-05\n",
      "Epoch 4225, Loss: 0.00037949018042127136, Final Batch Loss: 1.7445863704779185e-05\n",
      "Epoch 4226, Loss: 0.00037613311724271625, Final Batch Loss: 3.2179770641960204e-05\n",
      "Epoch 4227, Loss: 0.0006491585736512206, Final Batch Loss: 8.29256241559051e-05\n",
      "Epoch 4228, Loss: 7.82702427386539e-05, Final Batch Loss: 7.776571692375e-06\n",
      "Epoch 4229, Loss: 5.835386309627211e-05, Final Batch Loss: 1.0016577107307967e-05\n",
      "Epoch 4230, Loss: 0.0003330485915284953, Final Batch Loss: 9.608635991753545e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4231, Loss: 0.00011398529977668659, Final Batch Loss: 3.1730946830066387e-06\n",
      "Epoch 4232, Loss: 0.00023068867085385136, Final Batch Loss: 5.708366370527074e-05\n",
      "Epoch 4233, Loss: 0.00046661114083690336, Final Batch Loss: 3.2926418498391286e-05\n",
      "Epoch 4234, Loss: 0.00011243807102800929, Final Batch Loss: 6.514510914712446e-06\n",
      "Epoch 4235, Loss: 0.009208526009842899, Final Batch Loss: 1.5259187421179377e-05\n",
      "Epoch 4236, Loss: 0.00041365003562532365, Final Batch Loss: 0.00013552705058827996\n",
      "Epoch 4237, Loss: 0.00048331619836972095, Final Batch Loss: 3.971280966652557e-05\n",
      "Epoch 4238, Loss: 0.004291934637876693, Final Batch Loss: 6.990780093474314e-05\n",
      "Epoch 4239, Loss: 0.00066513626370579, Final Batch Loss: 0.00011857066419906914\n",
      "Epoch 4240, Loss: 0.0003596958667912986, Final Batch Loss: 5.29149838257581e-05\n",
      "Epoch 4241, Loss: 0.0002492987803179858, Final Batch Loss: 0.000147236482007429\n",
      "Epoch 4242, Loss: 0.0004917768189898197, Final Batch Loss: 3.4106603834516136e-06\n",
      "Epoch 4243, Loss: 0.0004417478612595005, Final Batch Loss: 3.676198684843257e-05\n",
      "Epoch 4244, Loss: 0.00039711349381832406, Final Batch Loss: 0.00010444311919854954\n",
      "Epoch 4245, Loss: 0.0002585830370662734, Final Batch Loss: 8.709164831088856e-05\n",
      "Epoch 4246, Loss: 0.00019517810233082855, Final Batch Loss: 8.38433606986655e-06\n",
      "Epoch 4247, Loss: 0.0010819899071066175, Final Batch Loss: 1.8112325051333755e-05\n",
      "Epoch 4248, Loss: 0.002210725873737829, Final Batch Loss: 5.085602242616005e-05\n",
      "Epoch 4249, Loss: 0.00015482974595215637, Final Batch Loss: 0.00010306169860996306\n",
      "Epoch 4250, Loss: 0.0017145611154774087, Final Batch Loss: 1.4649714103143197e-05\n",
      "Epoch 4251, Loss: 0.00015919384713924956, Final Batch Loss: 1.0539502909523435e-05\n",
      "Epoch 4252, Loss: 0.0003179713476129109, Final Batch Loss: 1.1207050192751922e-05\n",
      "Epoch 4253, Loss: 0.018883476270275423, Final Batch Loss: 3.4137166949221864e-05\n",
      "Epoch 4254, Loss: 0.0006502995947812451, Final Batch Loss: 4.091385562787764e-06\n",
      "Epoch 4255, Loss: 0.00036599114810087485, Final Batch Loss: 0.00033874096698127687\n",
      "Epoch 4256, Loss: 0.0001107493872041232, Final Batch Loss: 2.1547470169025473e-05\n",
      "Epoch 4257, Loss: 0.00023297138159250608, Final Batch Loss: 1.394779701513471e-05\n",
      "Epoch 4258, Loss: 0.0001472149851906579, Final Batch Loss: 7.936849578982219e-05\n",
      "Epoch 4259, Loss: 0.010377356535173021, Final Batch Loss: 7.8001176007092e-05\n",
      "Epoch 4260, Loss: 0.00047653211004217155, Final Batch Loss: 5.284750659484416e-05\n",
      "Epoch 4261, Loss: 0.009046558640875446, Final Batch Loss: 0.0089698676019907\n",
      "Epoch 4262, Loss: 0.0009918572104652412, Final Batch Loss: 9.446098556509241e-05\n",
      "Epoch 4263, Loss: 0.00022522445215145126, Final Batch Loss: 6.546607619384304e-05\n",
      "Epoch 4264, Loss: 0.006454131886130199, Final Batch Loss: 0.0002744419907685369\n",
      "Epoch 4265, Loss: 0.0007773061674924975, Final Batch Loss: 5.477356808114564e-06\n",
      "Epoch 4266, Loss: 0.0004102701204828918, Final Batch Loss: 0.00026396859902888536\n",
      "Epoch 4267, Loss: 0.0010744254013843602, Final Batch Loss: 0.0009840503334999084\n",
      "Epoch 4268, Loss: 9.505246907792753e-05, Final Batch Loss: 1.1092217391706072e-05\n",
      "Epoch 4269, Loss: 4.7107127500112256e-05, Final Batch Loss: 6.713657398904616e-07\n",
      "Epoch 4270, Loss: 0.00019567809522413881, Final Batch Loss: 1.3910824236518238e-05\n",
      "Epoch 4271, Loss: 0.00022346658624883275, Final Batch Loss: 1.9582024833653122e-05\n",
      "Epoch 4272, Loss: 0.0007961783849168569, Final Batch Loss: 2.6505209461902268e-05\n",
      "Epoch 4273, Loss: 0.001498209618148394, Final Batch Loss: 7.083594391588122e-05\n",
      "Epoch 4274, Loss: 9.050701828527963e-05, Final Batch Loss: 5.0557489885250106e-05\n",
      "Epoch 4275, Loss: 0.00013739708310822607, Final Batch Loss: 5.345704721548827e-06\n",
      "Epoch 4276, Loss: 8.768833458816516e-05, Final Batch Loss: 5.3595026656694245e-06\n",
      "Epoch 4277, Loss: 0.0005901535405428149, Final Batch Loss: 0.00012777026859112084\n",
      "Epoch 4278, Loss: 6.411045342247235e-05, Final Batch Loss: 4.123354301555082e-05\n",
      "Epoch 4279, Loss: 0.0004987558368156897, Final Batch Loss: 0.000237775340792723\n",
      "Epoch 4280, Loss: 0.00014898041445121635, Final Batch Loss: 2.3561979105579667e-05\n",
      "Epoch 4281, Loss: 0.022547924902937666, Final Batch Loss: 8.855196028889623e-06\n",
      "Epoch 4282, Loss: 0.00018994987112819217, Final Batch Loss: 0.00015305653505492955\n",
      "Epoch 4283, Loss: 0.0002148607131857716, Final Batch Loss: 3.0992964639153797e-06\n",
      "Epoch 4284, Loss: 0.002907764763222076, Final Batch Loss: 0.0021438985131680965\n",
      "Epoch 4285, Loss: 0.000832094912766479, Final Batch Loss: 1.906209217850119e-05\n",
      "Epoch 4286, Loss: 0.000991283403664056, Final Batch Loss: 1.6761885035521118e-06\n",
      "Epoch 4287, Loss: 7.142122194636613e-05, Final Batch Loss: 2.1863805159227923e-05\n",
      "Epoch 4288, Loss: 0.0002537257423682604, Final Batch Loss: 0.0001219391924678348\n",
      "Epoch 4289, Loss: 0.00017839460815594066, Final Batch Loss: 5.5258100474020466e-05\n",
      "Epoch 4290, Loss: 8.870721831044648e-05, Final Batch Loss: 2.8168562494101934e-05\n",
      "Epoch 4291, Loss: 0.0002046822955890093, Final Batch Loss: 0.0001049372658599168\n",
      "Epoch 4292, Loss: 0.002211274667388352, Final Batch Loss: 4.3929594539804384e-05\n",
      "Epoch 4293, Loss: 0.0005588606200035429, Final Batch Loss: 8.908303243515547e-06\n",
      "Epoch 4294, Loss: 0.0006455247676058207, Final Batch Loss: 2.1943971660220996e-05\n",
      "Epoch 4295, Loss: 0.000246697360125836, Final Batch Loss: 8.197381248464808e-05\n",
      "Epoch 4296, Loss: 0.0004315961523388978, Final Batch Loss: 0.0003101785259786993\n",
      "Epoch 4297, Loss: 0.0001602706222456618, Final Batch Loss: 2.9640311822731746e-06\n",
      "Epoch 4298, Loss: 9.565000709699234e-05, Final Batch Loss: 1.1853159776364919e-05\n",
      "Epoch 4299, Loss: 0.0002986176077683922, Final Batch Loss: 6.073153417673893e-05\n",
      "Epoch 4300, Loss: 4.134816390433116e-05, Final Batch Loss: 1.0790997293952387e-05\n",
      "Epoch 4301, Loss: 0.0003948516459786333, Final Batch Loss: 8.912151315598749e-06\n",
      "Epoch 4302, Loss: 8.148978349709068e-05, Final Batch Loss: 5.915233941777842e-06\n",
      "Epoch 4303, Loss: 0.00019493860736474744, Final Batch Loss: 3.6300811188993976e-05\n",
      "Epoch 4304, Loss: 3.6009761060995515e-05, Final Batch Loss: 8.04597311798716e-06\n",
      "Epoch 4305, Loss: 0.00048357908008256345, Final Batch Loss: 0.00045898574171587825\n",
      "Epoch 4306, Loss: 9.488701084592321e-05, Final Batch Loss: 8.345766400452703e-05\n",
      "Epoch 4307, Loss: 0.00031688106719229836, Final Batch Loss: 1.1017854376405012e-05\n",
      "Epoch 4308, Loss: 7.787347794874222e-05, Final Batch Loss: 6.244325049920008e-05\n",
      "Epoch 4309, Loss: 0.00023343761949945474, Final Batch Loss: 0.00012003968731733039\n",
      "Epoch 4310, Loss: 0.0001638148905840353, Final Batch Loss: 1.3070458408037666e-05\n",
      "Epoch 4311, Loss: 0.0002949596087091777, Final Batch Loss: 5.507131845661206e-06\n",
      "Epoch 4312, Loss: 0.00011814109529950656, Final Batch Loss: 1.939628054969944e-05\n",
      "Epoch 4313, Loss: 2.6749089329314302e-05, Final Batch Loss: 2.781779357974301e-06\n",
      "Epoch 4314, Loss: 0.0012812411914637778, Final Batch Loss: 0.0003478701983112842\n",
      "Epoch 4315, Loss: 0.00017533482059661765, Final Batch Loss: 2.686690459086094e-05\n",
      "Epoch 4316, Loss: 0.0002858041425497504, Final Batch Loss: 1.9737581169465557e-06\n",
      "Epoch 4317, Loss: 0.0006555922836923855, Final Batch Loss: 0.0006344584398902953\n",
      "Epoch 4318, Loss: 0.0007484995003324002, Final Batch Loss: 0.0007016739691607654\n",
      "Epoch 4319, Loss: 0.00031428670627065003, Final Batch Loss: 0.00018259459466207772\n",
      "Epoch 4320, Loss: 0.00029052066111034947, Final Batch Loss: 5.940248956903815e-05\n",
      "Epoch 4321, Loss: 0.0009700510709080845, Final Batch Loss: 0.0002450054744258523\n",
      "Epoch 4322, Loss: 0.00035788755121757276, Final Batch Loss: 1.5490011719521135e-05\n",
      "Epoch 4323, Loss: 3.8196960304048844e-05, Final Batch Loss: 1.2194417649880052e-05\n",
      "Epoch 4324, Loss: 0.0024629072004245245, Final Batch Loss: 0.0024330297019332647\n",
      "Epoch 4325, Loss: 4.359804643172538e-05, Final Batch Loss: 1.6678590327501297e-05\n",
      "Epoch 4326, Loss: 0.00014341859423439018, Final Batch Loss: 1.3878607205697335e-05\n",
      "Epoch 4327, Loss: 9.552354708830535e-05, Final Batch Loss: 2.7057528768636985e-06\n",
      "Epoch 4328, Loss: 0.0002587092340036179, Final Batch Loss: 0.00020790212147403508\n",
      "Epoch 4329, Loss: 5.4225937674345914e-05, Final Batch Loss: 2.257442793052178e-05\n",
      "Epoch 4330, Loss: 0.000690200711687794, Final Batch Loss: 0.00014324088988360018\n",
      "Epoch 4331, Loss: 0.00015311465278955438, Final Batch Loss: 6.296787660176051e-07\n",
      "Epoch 4332, Loss: 0.00014337923289531318, Final Batch Loss: 1.8736079709924525e-06\n",
      "Epoch 4333, Loss: 6.278434557316359e-05, Final Batch Loss: 8.217277354560792e-06\n",
      "Epoch 4334, Loss: 0.00016084235539892688, Final Batch Loss: 4.5752080040983856e-05\n",
      "Epoch 4335, Loss: 0.002300678566825809, Final Batch Loss: 6.660180952167138e-05\n",
      "Epoch 4336, Loss: 0.00011437302237027325, Final Batch Loss: 1.2067222087353002e-05\n",
      "Epoch 4337, Loss: 2.717656514050759e-05, Final Batch Loss: 4.033696313854307e-06\n",
      "Epoch 4338, Loss: 0.00010275118984282017, Final Batch Loss: 1.891166357381735e-05\n",
      "Epoch 4339, Loss: 0.012697397446800096, Final Batch Loss: 1.186168674394139e-06\n",
      "Epoch 4340, Loss: 0.00015787164420544286, Final Batch Loss: 4.337660811870592e-06\n",
      "Epoch 4341, Loss: 0.04641310662555043, Final Batch Loss: 0.04583069682121277\n",
      "Epoch 4342, Loss: 0.00021265756458888063, Final Batch Loss: 9.503725777904037e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4343, Loss: 0.00193225396105845, Final Batch Loss: 0.0005359318456612527\n",
      "Epoch 4344, Loss: 0.06843014865080477, Final Batch Loss: 0.06829003989696503\n",
      "Epoch 4345, Loss: 0.00021119605480635073, Final Batch Loss: 1.1602664017118514e-05\n",
      "Epoch 4346, Loss: 0.00016814504397189012, Final Batch Loss: 8.111891474982258e-06\n",
      "Epoch 4347, Loss: 0.00012536879876279272, Final Batch Loss: 4.207086021779105e-05\n",
      "Epoch 4348, Loss: 0.0005250275780781521, Final Batch Loss: 0.00014532540808431804\n",
      "Epoch 4349, Loss: 0.00999245309503749, Final Batch Loss: 7.807771908119321e-05\n",
      "Epoch 4350, Loss: 0.0004893150289717596, Final Batch Loss: 0.0002292590943397954\n",
      "Epoch 4351, Loss: 0.01905809048912488, Final Batch Loss: 0.000251397374086082\n",
      "Epoch 4352, Loss: 0.0034953264039359055, Final Batch Loss: 0.0006444767932407558\n",
      "Epoch 4353, Loss: 0.0019473646680125967, Final Batch Loss: 4.162790719419718e-05\n",
      "Epoch 4354, Loss: 0.01620288646336121, Final Batch Loss: 2.7291220249026082e-05\n",
      "Epoch 4355, Loss: 0.0012359009924693964, Final Batch Loss: 0.0002786512195598334\n",
      "Epoch 4356, Loss: 0.010342675930587575, Final Batch Loss: 0.009040826000273228\n",
      "Epoch 4357, Loss: 0.014705902445712127, Final Batch Loss: 0.0013389951782301068\n",
      "Epoch 4358, Loss: 0.000550436663615983, Final Batch Loss: 0.00016444870561826974\n",
      "Epoch 4359, Loss: 0.00029935486600152217, Final Batch Loss: 0.00012813122884836048\n",
      "Epoch 4360, Loss: 0.00022007288862369023, Final Batch Loss: 5.807278648717329e-05\n",
      "Epoch 4361, Loss: 0.01512790019842214, Final Batch Loss: 4.714511669590138e-05\n",
      "Epoch 4362, Loss: 0.0003827041873591952, Final Batch Loss: 0.00019728404004126787\n",
      "Epoch 4363, Loss: 0.00043971768172923476, Final Batch Loss: 0.0001944487012224272\n",
      "Epoch 4364, Loss: 0.0009904228136292659, Final Batch Loss: 0.0005117601831443608\n",
      "Epoch 4365, Loss: 0.007858410346671008, Final Batch Loss: 7.176025246735662e-05\n",
      "Epoch 4366, Loss: 0.00861125851952238, Final Batch Loss: 0.008206198923289776\n",
      "Epoch 4367, Loss: 0.0008880918103386648, Final Batch Loss: 7.263503357535228e-05\n",
      "Epoch 4368, Loss: 0.010780440585222095, Final Batch Loss: 0.0001321338932029903\n",
      "Epoch 4369, Loss: 0.001918924375786446, Final Batch Loss: 0.0016630124300718307\n",
      "Epoch 4370, Loss: 0.0015224878079607151, Final Batch Loss: 0.00011364390229573473\n",
      "Epoch 4371, Loss: 0.0008170734145096503, Final Batch Loss: 7.386788638541475e-05\n",
      "Epoch 4372, Loss: 0.006714535637001973, Final Batch Loss: 4.0377512050326914e-05\n",
      "Epoch 4373, Loss: 0.0008530546692782082, Final Batch Loss: 8.966535824583843e-05\n",
      "Epoch 4374, Loss: 0.004180597214144655, Final Batch Loss: 7.582849502796307e-05\n",
      "Epoch 4375, Loss: 0.011683384180287248, Final Batch Loss: 1.7261181710637175e-05\n",
      "Epoch 4376, Loss: 0.0004731146900667227, Final Batch Loss: 1.4464719242823776e-05\n",
      "Epoch 4377, Loss: 0.00032430798819405027, Final Batch Loss: 0.0002049663889920339\n",
      "Epoch 4378, Loss: 0.027502411845489405, Final Batch Loss: 0.0013770963996648788\n",
      "Epoch 4379, Loss: 0.000265543298155535, Final Batch Loss: 0.00014659295266028494\n",
      "Epoch 4380, Loss: 0.006705494575726334, Final Batch Loss: 0.006478785537183285\n",
      "Epoch 4381, Loss: 0.0025265219737775624, Final Batch Loss: 0.00011272983101662248\n",
      "Epoch 4382, Loss: 0.0006452211309806444, Final Batch Loss: 5.953747677267529e-05\n",
      "Epoch 4383, Loss: 0.0010019639157690108, Final Batch Loss: 0.0008740822086110711\n",
      "Epoch 4384, Loss: 0.00093700688375975, Final Batch Loss: 3.616112007875927e-05\n",
      "Epoch 4385, Loss: 0.0001326123619946884, Final Batch Loss: 4.733730020234361e-05\n",
      "Epoch 4386, Loss: 0.0006030097720213234, Final Batch Loss: 0.0001958629145519808\n",
      "Epoch 4387, Loss: 0.0009699577931314707, Final Batch Loss: 3.5590688639786094e-05\n",
      "Epoch 4388, Loss: 0.00018635039668879472, Final Batch Loss: 8.779141353443265e-05\n",
      "Epoch 4389, Loss: 0.0011112298197986092, Final Batch Loss: 6.158313772175461e-05\n",
      "Epoch 4390, Loss: 0.003219630947569385, Final Batch Loss: 0.00017510514589957893\n",
      "Epoch 4391, Loss: 0.0002465165889589116, Final Batch Loss: 4.044546585646458e-05\n",
      "Epoch 4392, Loss: 0.00022456455189967528, Final Batch Loss: 7.239649858092889e-05\n",
      "Epoch 4393, Loss: 0.0006426886102417484, Final Batch Loss: 5.1667302614077926e-05\n",
      "Epoch 4394, Loss: 0.0006402823710232042, Final Batch Loss: 5.200142913963646e-05\n",
      "Epoch 4395, Loss: 0.0004932550073135644, Final Batch Loss: 7.264753367053345e-05\n",
      "Epoch 4396, Loss: 0.000392818506952608, Final Batch Loss: 0.0002669387904461473\n",
      "Epoch 4397, Loss: 0.00028824707624153234, Final Batch Loss: 3.0928742489777505e-05\n",
      "Epoch 4398, Loss: 0.000715202113497071, Final Batch Loss: 0.0003649916616268456\n",
      "Epoch 4399, Loss: 0.0003411216239328496, Final Batch Loss: 0.00011371976870577782\n",
      "Epoch 4400, Loss: 0.0031094272853806615, Final Batch Loss: 0.0008963975706137717\n",
      "Epoch 4401, Loss: 0.0002641517639858648, Final Batch Loss: 0.00011438450019340962\n",
      "Epoch 4402, Loss: 0.00016849896746862214, Final Batch Loss: 2.8645643396885134e-05\n",
      "Epoch 4403, Loss: 0.000363958806701703, Final Batch Loss: 1.960925874300301e-05\n",
      "Epoch 4404, Loss: 0.00048722321207606, Final Batch Loss: 7.23551565897651e-05\n",
      "Epoch 4405, Loss: 0.0005010130012124137, Final Batch Loss: 8.190748303604778e-06\n",
      "Epoch 4406, Loss: 0.002954777305603784, Final Batch Loss: 1.037528727465542e-05\n",
      "Epoch 4407, Loss: 0.08271751302891062, Final Batch Loss: 0.08265689760446548\n",
      "Epoch 4408, Loss: 0.007227670692373067, Final Batch Loss: 0.004872771445661783\n",
      "Epoch 4409, Loss: 0.0032347316373488866, Final Batch Loss: 3.1619791116099805e-05\n",
      "Epoch 4410, Loss: 0.00029953321427456103, Final Batch Loss: 8.817872731015086e-05\n",
      "Epoch 4411, Loss: 0.0005397985187300947, Final Batch Loss: 0.0004808486846741289\n",
      "Epoch 4412, Loss: 0.00024551890783186536, Final Batch Loss: 8.098822945612483e-06\n",
      "Epoch 4413, Loss: 0.02027346470276825, Final Batch Loss: 0.0001333037216681987\n",
      "Epoch 4414, Loss: 0.00013205287359596696, Final Batch Loss: 3.2715015549911186e-05\n",
      "Epoch 4415, Loss: 9.845482873060973e-05, Final Batch Loss: 6.659785140072927e-05\n",
      "Epoch 4416, Loss: 0.0003073091538681183, Final Batch Loss: 0.00020725764625240117\n",
      "Epoch 4417, Loss: 0.008934050005336758, Final Batch Loss: 0.00010317817941540852\n",
      "Epoch 4418, Loss: 0.0033887962126755156, Final Batch Loss: 0.003201128914952278\n",
      "Epoch 4419, Loss: 0.0008496536211168859, Final Batch Loss: 7.486816321033984e-05\n",
      "Epoch 4420, Loss: 0.000335298564095865, Final Batch Loss: 2.4897932235035114e-05\n",
      "Epoch 4421, Loss: 0.00046927479343139566, Final Batch Loss: 0.00011515338701428846\n",
      "Epoch 4422, Loss: 0.0002606012567412108, Final Batch Loss: 9.903952741296962e-05\n",
      "Epoch 4423, Loss: 0.004697997021139599, Final Batch Loss: 0.0008193398243747652\n",
      "Epoch 4424, Loss: 0.0002923164392996114, Final Batch Loss: 8.339688065461814e-06\n",
      "Epoch 4425, Loss: 0.001631846622331068, Final Batch Loss: 4.11936198361218e-05\n",
      "Epoch 4426, Loss: 0.00024292282614624128, Final Batch Loss: 6.488592043751851e-05\n",
      "Epoch 4427, Loss: 0.0019306715039419942, Final Batch Loss: 0.001639335067011416\n",
      "Epoch 4428, Loss: 0.0006349080940708518, Final Batch Loss: 0.0003914595872629434\n",
      "Epoch 4429, Loss: 0.0004740235599456355, Final Batch Loss: 0.0001482003863202408\n",
      "Epoch 4430, Loss: 0.0029884273535571992, Final Batch Loss: 0.0011122514260932803\n",
      "Epoch 4431, Loss: 0.0002702505880733952, Final Batch Loss: 9.313926420873031e-05\n",
      "Epoch 4432, Loss: 0.00047692150837974623, Final Batch Loss: 9.339486859971657e-05\n",
      "Epoch 4433, Loss: 0.0003196921243215911, Final Batch Loss: 9.416536340722814e-05\n",
      "Epoch 4434, Loss: 0.006342632628729916, Final Batch Loss: 1.175789839180652e-05\n",
      "Epoch 4435, Loss: 0.0019243206061219098, Final Batch Loss: 2.772660991468001e-05\n",
      "Epoch 4436, Loss: 0.0019653823255794123, Final Batch Loss: 0.0014172899536788464\n",
      "Epoch 4437, Loss: 0.00027091299307357986, Final Batch Loss: 2.2532238290295936e-05\n",
      "Epoch 4438, Loss: 0.0021424683509394526, Final Batch Loss: 0.0004901588545180857\n",
      "Epoch 4439, Loss: 0.0005324452440618188, Final Batch Loss: 1.193030857393751e-05\n",
      "Epoch 4440, Loss: 0.0004162271252425853, Final Batch Loss: 0.0002297982864547521\n",
      "Epoch 4441, Loss: 0.00036593097320292145, Final Batch Loss: 0.00017696652503218502\n",
      "Epoch 4442, Loss: 0.00012388715549604967, Final Batch Loss: 3.511439717840403e-05\n",
      "Epoch 4443, Loss: 0.0003485541292320704, Final Batch Loss: 3.0953309760661796e-05\n",
      "Epoch 4444, Loss: 0.0007025467130006291, Final Batch Loss: 0.0005921907140873373\n",
      "Epoch 4445, Loss: 0.00012511035947682103, Final Batch Loss: 8.404555956076365e-06\n",
      "Epoch 4446, Loss: 0.0005585413455264643, Final Batch Loss: 0.00017177961126435548\n",
      "Epoch 4447, Loss: 0.00013450715414364822, Final Batch Loss: 6.631076394114643e-05\n",
      "Epoch 4448, Loss: 0.0007354369172389852, Final Batch Loss: 2.77808776445454e-05\n",
      "Epoch 4449, Loss: 0.00011938569514313713, Final Batch Loss: 2.12151171581354e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4450, Loss: 0.000134067361614143, Final Batch Loss: 9.299976227339357e-05\n",
      "Epoch 4451, Loss: 0.003955030791985337, Final Batch Loss: 0.003857787698507309\n",
      "Epoch 4452, Loss: 0.003905396159098018, Final Batch Loss: 8.733577124075964e-05\n",
      "Epoch 4453, Loss: 0.000301535394100938, Final Batch Loss: 3.2581468985881656e-05\n",
      "Epoch 4454, Loss: 6.60773857816821e-05, Final Batch Loss: 1.614202483324334e-05\n",
      "Epoch 4455, Loss: 0.0003002769353770418, Final Batch Loss: 0.00019234430510550737\n",
      "Epoch 4456, Loss: 0.0006308305946731707, Final Batch Loss: 4.353277836344205e-05\n",
      "Epoch 4457, Loss: 0.0001456099471397465, Final Batch Loss: 1.790646456356626e-05\n",
      "Epoch 4458, Loss: 0.00018837220795830945, Final Batch Loss: 2.503199539205525e-06\n",
      "Epoch 4459, Loss: 0.009764838076080196, Final Batch Loss: 0.009607953019440174\n",
      "Epoch 4460, Loss: 0.0007654019573237747, Final Batch Loss: 5.415353371063247e-05\n",
      "Epoch 4461, Loss: 0.0007977795867191162, Final Batch Loss: 0.0004886632668785751\n",
      "Epoch 4462, Loss: 0.001392247184412554, Final Batch Loss: 0.00010074302554130554\n",
      "Epoch 4463, Loss: 0.008355741039849818, Final Batch Loss: 0.00013846566434949636\n",
      "Epoch 4464, Loss: 0.009099576007429278, Final Batch Loss: 1.708989657345228e-05\n",
      "Epoch 4465, Loss: 0.00035054091131314635, Final Batch Loss: 0.00015758060908410698\n",
      "Epoch 4466, Loss: 0.00030025018713786267, Final Batch Loss: 0.0001878966431831941\n",
      "Epoch 4467, Loss: 0.0012309820303926244, Final Batch Loss: 0.00013397923612501472\n",
      "Epoch 4468, Loss: 0.00013291757386468817, Final Batch Loss: 5.4851858294568956e-05\n",
      "Epoch 4469, Loss: 0.000332959212755668, Final Batch Loss: 6.770304025849327e-05\n",
      "Epoch 4470, Loss: 0.00011648303916445002, Final Batch Loss: 2.466774094500579e-05\n",
      "Epoch 4471, Loss: 0.0006348874885588884, Final Batch Loss: 0.0002685891231521964\n",
      "Epoch 4472, Loss: 0.0008730618201298057, Final Batch Loss: 0.00014763833314646035\n",
      "Epoch 4473, Loss: 0.00020754326305905124, Final Batch Loss: 0.0001856409216998145\n",
      "Epoch 4474, Loss: 0.0042523505399003625, Final Batch Loss: 0.004125288221985102\n",
      "Epoch 4475, Loss: 0.0010302786504325923, Final Batch Loss: 1.3255015801405534e-05\n",
      "Epoch 4476, Loss: 0.001817495001887437, Final Batch Loss: 1.693900048849173e-05\n",
      "Epoch 4477, Loss: 5.9685527958208695e-05, Final Batch Loss: 2.4882461730157956e-05\n",
      "Epoch 4478, Loss: 0.0003128498574369587, Final Batch Loss: 0.00015061719750519842\n",
      "Epoch 4479, Loss: 0.00019501788392517483, Final Batch Loss: 7.181198270700406e-06\n",
      "Epoch 4480, Loss: 0.00020993441557948245, Final Batch Loss: 0.00011975705274380744\n",
      "Epoch 4481, Loss: 3.733119410753716e-05, Final Batch Loss: 1.1126874596811831e-05\n",
      "Epoch 4482, Loss: 0.0002022326098085614, Final Batch Loss: 1.8285778423887677e-05\n",
      "Epoch 4483, Loss: 0.0001527467684354633, Final Batch Loss: 4.67635654786136e-05\n",
      "Epoch 4484, Loss: 0.00018850157721317373, Final Batch Loss: 0.00010993274190695956\n",
      "Epoch 4485, Loss: 0.00013637585243486683, Final Batch Loss: 7.105916211003205e-06\n",
      "Epoch 4486, Loss: 0.0002811649351315282, Final Batch Loss: 0.00020126953313592821\n",
      "Epoch 4487, Loss: 0.00012423823295648617, Final Batch Loss: 6.920890882611275e-05\n",
      "Epoch 4488, Loss: 0.0003590265732782427, Final Batch Loss: 0.00019131872977595776\n",
      "Epoch 4489, Loss: 0.006042930170224281, Final Batch Loss: 0.0007919597555883229\n",
      "Epoch 4490, Loss: 0.00039028855826472864, Final Batch Loss: 0.00014831218868494034\n",
      "Epoch 4491, Loss: 0.0003233305469620973, Final Batch Loss: 6.195517926244065e-05\n",
      "Epoch 4492, Loss: 0.0008151494866979192, Final Batch Loss: 2.5732522772159427e-05\n",
      "Epoch 4493, Loss: 0.00034437379508744925, Final Batch Loss: 0.00012610787234734744\n",
      "Epoch 4494, Loss: 0.007779667525028344, Final Batch Loss: 0.0076622203923761845\n",
      "Epoch 4495, Loss: 0.0006493428008980118, Final Batch Loss: 0.00034888589289039373\n",
      "Epoch 4496, Loss: 8.030709886952536e-05, Final Batch Loss: 8.681451618031133e-06\n",
      "Epoch 4497, Loss: 0.00013749837307841517, Final Batch Loss: 2.2949543563299812e-05\n",
      "Epoch 4498, Loss: 0.0008605089096818119, Final Batch Loss: 0.0006933081313036382\n",
      "Epoch 4499, Loss: 3.917390483820782e-05, Final Batch Loss: 1.443633550479717e-06\n",
      "Epoch 4500, Loss: 0.0005884058045921847, Final Batch Loss: 0.0005475129000842571\n",
      "Epoch 4501, Loss: 0.000356906185970729, Final Batch Loss: 6.970588856347604e-06\n",
      "Epoch 4502, Loss: 0.0004066701390001981, Final Batch Loss: 5.003387286706129e-06\n",
      "Epoch 4503, Loss: 0.0005549877860175911, Final Batch Loss: 0.00040880191954784095\n",
      "Epoch 4504, Loss: 0.0006932835749466904, Final Batch Loss: 2.2682103008264676e-05\n",
      "Epoch 4505, Loss: 0.0011789651816798141, Final Batch Loss: 4.8496869567316025e-05\n",
      "Epoch 4506, Loss: 0.0016303271440847311, Final Batch Loss: 4.336242636782117e-05\n",
      "Epoch 4507, Loss: 0.00016127843991853297, Final Batch Loss: 2.9728082154178992e-05\n",
      "Epoch 4508, Loss: 0.00041706419506226666, Final Batch Loss: 1.6020341718103737e-05\n",
      "Epoch 4509, Loss: 0.0005466690236062277, Final Batch Loss: 0.0001444457157049328\n",
      "Epoch 4510, Loss: 0.0005347637943486916, Final Batch Loss: 0.000426068581873551\n",
      "Epoch 4511, Loss: 2.5941540116036776e-05, Final Batch Loss: 2.950777798105264e-06\n",
      "Epoch 4512, Loss: 0.00013021519316680497, Final Batch Loss: 0.00010165974526898935\n",
      "Epoch 4513, Loss: 0.00028092004777136026, Final Batch Loss: 0.00014057975204195827\n",
      "Epoch 4514, Loss: 0.00047902693108881067, Final Batch Loss: 2.0469013179535978e-05\n",
      "Epoch 4515, Loss: 0.0020575622106662195, Final Batch Loss: 3.4063373277604114e-06\n",
      "Epoch 4516, Loss: 0.0001160976020742055, Final Batch Loss: 9.163517802335264e-07\n",
      "Epoch 4517, Loss: 0.0004786898707607179, Final Batch Loss: 1.7822303561843e-06\n",
      "Epoch 4518, Loss: 0.0005834602776531028, Final Batch Loss: 1.3960521982880891e-06\n",
      "Epoch 4519, Loss: 5.895594495086698e-05, Final Batch Loss: 3.0481493013212457e-05\n",
      "Epoch 4520, Loss: 0.0001499414775025798, Final Batch Loss: 9.173903890768997e-06\n",
      "Epoch 4521, Loss: 9.22294350402808e-05, Final Batch Loss: 5.256095391814597e-05\n",
      "Epoch 4522, Loss: 0.00021248421899144887, Final Batch Loss: 2.3530357793788426e-05\n",
      "Epoch 4523, Loss: 0.0009102268777496647, Final Batch Loss: 6.653825403191149e-05\n",
      "Epoch 4524, Loss: 0.0025338915183965582, Final Batch Loss: 3.1825202313484624e-05\n",
      "Epoch 4525, Loss: 0.0010584778756310698, Final Batch Loss: 0.0009087090147659183\n",
      "Epoch 4526, Loss: 0.00140373387694126, Final Batch Loss: 0.00010246465535601601\n",
      "Epoch 4527, Loss: 0.0003309713429189287, Final Batch Loss: 0.00014389572606887668\n",
      "Epoch 4528, Loss: 0.00015450363935087807, Final Batch Loss: 3.3696269383654e-05\n",
      "Epoch 4529, Loss: 0.00015837475802982226, Final Batch Loss: 6.529970414703712e-05\n",
      "Epoch 4530, Loss: 0.00019533693739504088, Final Batch Loss: 8.77304482855834e-05\n",
      "Epoch 4531, Loss: 0.00040039440864347853, Final Batch Loss: 5.8238274505129084e-05\n",
      "Epoch 4532, Loss: 0.0005264586779958336, Final Batch Loss: 0.000335683929733932\n",
      "Epoch 4533, Loss: 0.022587859253690112, Final Batch Loss: 8.346663526026532e-05\n",
      "Epoch 4534, Loss: 0.0005419503104349133, Final Batch Loss: 0.0003945393254980445\n",
      "Epoch 4535, Loss: 0.0005796782606921624, Final Batch Loss: 0.0005350589053705335\n",
      "Epoch 4536, Loss: 0.00019618926671682857, Final Batch Loss: 6.405502062989399e-05\n",
      "Epoch 4537, Loss: 0.0014732738511611387, Final Batch Loss: 0.0005811626324430108\n",
      "Epoch 4538, Loss: 0.0003668928147817496, Final Batch Loss: 1.6162437532329932e-05\n",
      "Epoch 4539, Loss: 0.0002279496757182642, Final Batch Loss: 1.0406059118395206e-05\n",
      "Epoch 4540, Loss: 0.0015311429488065187, Final Batch Loss: 0.0002104102895827964\n",
      "Epoch 4541, Loss: 0.00033670115408312995, Final Batch Loss: 0.00014289385580923408\n",
      "Epoch 4542, Loss: 0.0004490637611525017, Final Batch Loss: 0.00030425313161686063\n",
      "Epoch 4543, Loss: 0.0004248831064614933, Final Batch Loss: 0.00034625738044269383\n",
      "Epoch 4544, Loss: 0.007529693773904, Final Batch Loss: 0.006626549642533064\n",
      "Epoch 4545, Loss: 0.0015701094453106634, Final Batch Loss: 7.977593486430123e-05\n",
      "Epoch 4546, Loss: 0.0008580822150179301, Final Batch Loss: 6.511571700684726e-05\n",
      "Epoch 4547, Loss: 0.0009288782946441643, Final Batch Loss: 3.2133300464920467e-06\n",
      "Epoch 4548, Loss: 0.0005439269152702764, Final Batch Loss: 4.702659498434514e-05\n",
      "Epoch 4549, Loss: 0.002946905193311977, Final Batch Loss: 2.326255889784079e-05\n",
      "Epoch 4550, Loss: 0.0016539903590455651, Final Batch Loss: 0.00034837599378079176\n",
      "Epoch 4551, Loss: 0.0007135500927688554, Final Batch Loss: 1.274047463084571e-05\n",
      "Epoch 4552, Loss: 0.00024621615375508554, Final Batch Loss: 0.00013457062595989555\n",
      "Epoch 4553, Loss: 0.00038637640227534575, Final Batch Loss: 1.0440659934829455e-05\n",
      "Epoch 4554, Loss: 0.00021657226170646027, Final Batch Loss: 3.6469056794885546e-05\n",
      "Epoch 4555, Loss: 0.00126503715000581, Final Batch Loss: 0.0008711936534382403\n",
      "Epoch 4556, Loss: 0.0009783678106032312, Final Batch Loss: 0.00018135301070287824\n",
      "Epoch 4557, Loss: 0.032205621973844245, Final Batch Loss: 0.0004233986255712807\n",
      "Epoch 4558, Loss: 0.0005080605624243617, Final Batch Loss: 1.5661256838939153e-05\n",
      "Epoch 4559, Loss: 7.970361730258446e-05, Final Batch Loss: 2.0648256395361386e-05\n",
      "Epoch 4560, Loss: 0.0003037614696950186, Final Batch Loss: 0.000192240797332488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4561, Loss: 0.0003183029170941154, Final Batch Loss: 4.128122327529127e-06\n",
      "Epoch 4562, Loss: 0.0003183557728334563, Final Batch Loss: 0.00017873778415378183\n",
      "Epoch 4563, Loss: 0.0001490422037022654, Final Batch Loss: 4.219988841214217e-05\n",
      "Epoch 4564, Loss: 0.0002358189522055909, Final Batch Loss: 2.0017658243887126e-05\n",
      "Epoch 4565, Loss: 0.00024916585425671656, Final Batch Loss: 0.00018929250654764473\n",
      "Epoch 4566, Loss: 0.0013271396710479166, Final Batch Loss: 0.00010291762737324461\n",
      "Epoch 4567, Loss: 0.00020646588018280454, Final Batch Loss: 0.00010193500202149153\n",
      "Epoch 4568, Loss: 0.00020832897644140758, Final Batch Loss: 1.679013075772673e-05\n",
      "Epoch 4569, Loss: 0.0028163027309346944, Final Batch Loss: 0.0004473463341128081\n",
      "Epoch 4570, Loss: 0.0003007754003192531, Final Batch Loss: 1.701621113170404e-05\n",
      "Epoch 4571, Loss: 0.00027683930966304615, Final Batch Loss: 1.2072439858457074e-05\n",
      "Epoch 4572, Loss: 0.00035468355054035783, Final Batch Loss: 1.920722752402071e-05\n",
      "Epoch 4573, Loss: 0.0001977601104954374, Final Batch Loss: 4.773760338139255e-06\n",
      "Epoch 4574, Loss: 0.0004675841018979554, Final Batch Loss: 0.0003217518387828022\n",
      "Epoch 4575, Loss: 0.0006262462484301068, Final Batch Loss: 5.200810483074747e-05\n",
      "Epoch 4576, Loss: 0.0004000217049906496, Final Batch Loss: 0.000305991037748754\n",
      "Epoch 4577, Loss: 0.0002053723219432868, Final Batch Loss: 0.00016516730829607695\n",
      "Epoch 4578, Loss: 0.0005944896274741041, Final Batch Loss: 0.00045754958409816027\n",
      "Epoch 4579, Loss: 3.8318011775118066e-05, Final Batch Loss: 1.4859273505862802e-05\n",
      "Epoch 4580, Loss: 0.0007598314432470943, Final Batch Loss: 7.178877240221482e-06\n",
      "Epoch 4581, Loss: 0.0013293918000272242, Final Batch Loss: 1.5750132661196403e-05\n",
      "Epoch 4582, Loss: 0.0001237464521182119, Final Batch Loss: 2.4280096113216132e-05\n",
      "Epoch 4583, Loss: 0.03182499650210957, Final Batch Loss: 0.00045139199937693775\n",
      "Epoch 4584, Loss: 0.0015237925654218998, Final Batch Loss: 0.0014205818297341466\n",
      "Epoch 4585, Loss: 0.00014157108353174408, Final Batch Loss: 5.563976174016716e-06\n",
      "Epoch 4586, Loss: 0.0016259952390100807, Final Batch Loss: 7.756377453915775e-05\n",
      "Epoch 4587, Loss: 0.00015691652697569225, Final Batch Loss: 1.5153196727624163e-05\n",
      "Epoch 4588, Loss: 0.00022046001322451048, Final Batch Loss: 3.129831384285353e-05\n",
      "Epoch 4589, Loss: 7.94787911218009e-05, Final Batch Loss: 7.665742487006355e-06\n",
      "Epoch 4590, Loss: 0.005009967731893994, Final Batch Loss: 0.00012041964509990066\n",
      "Epoch 4591, Loss: 0.00018543764599598944, Final Batch Loss: 0.00010202344128629193\n",
      "Epoch 4592, Loss: 0.0001561055669299094, Final Batch Loss: 9.377032256452367e-05\n",
      "Epoch 4593, Loss: 0.00021333391305233818, Final Batch Loss: 2.9840537536074407e-05\n",
      "Epoch 4594, Loss: 0.00037276128932717256, Final Batch Loss: 3.516143260640092e-05\n",
      "Epoch 4595, Loss: 0.00040424780036119046, Final Batch Loss: 5.6884611694840714e-05\n",
      "Epoch 4596, Loss: 0.00043453882972244173, Final Batch Loss: 9.600209887139499e-05\n",
      "Epoch 4597, Loss: 0.00023732434874546016, Final Batch Loss: 1.1352983165124897e-05\n",
      "Epoch 4598, Loss: 0.0005717161202483112, Final Batch Loss: 0.0004500091599766165\n",
      "Epoch 4599, Loss: 0.0003231536175007932, Final Batch Loss: 9.92965287878178e-05\n",
      "Epoch 4600, Loss: 0.00038805901931482367, Final Batch Loss: 0.00010055679740617052\n",
      "Epoch 4601, Loss: 0.000617290770605905, Final Batch Loss: 5.7181510783266276e-05\n",
      "Epoch 4602, Loss: 0.00043663295582518913, Final Batch Loss: 0.00028374019893817604\n",
      "Epoch 4603, Loss: 0.00011614861796260811, Final Batch Loss: 5.053293352830224e-05\n",
      "Epoch 4604, Loss: 0.00015391025863209506, Final Batch Loss: 3.625122189987451e-05\n",
      "Epoch 4605, Loss: 0.00014527301800626446, Final Batch Loss: 5.978909393888898e-05\n",
      "Epoch 4606, Loss: 0.0032905421644500166, Final Batch Loss: 3.548618406057358e-05\n",
      "Epoch 4607, Loss: 0.00025862012944344315, Final Batch Loss: 2.9806246857333463e-06\n",
      "Epoch 4608, Loss: 0.001981566398171708, Final Batch Loss: 0.0011747241951525211\n",
      "Epoch 4609, Loss: 0.00038586165464948863, Final Batch Loss: 1.669158518780023e-05\n",
      "Epoch 4610, Loss: 0.00038896672822374967, Final Batch Loss: 5.141570454725297e-06\n",
      "Epoch 4611, Loss: 0.0011722291092155501, Final Batch Loss: 0.00019811224774457514\n",
      "Epoch 4612, Loss: 0.00032689580439182464, Final Batch Loss: 2.9035372790531255e-05\n",
      "Epoch 4613, Loss: 0.0015408702529384755, Final Batch Loss: 0.000823248119559139\n",
      "Epoch 4614, Loss: 0.002557794585300144, Final Batch Loss: 0.00044901567162014544\n",
      "Epoch 4615, Loss: 0.0005322774923115503, Final Batch Loss: 0.00037888935185037553\n",
      "Epoch 4616, Loss: 0.00022366891425917856, Final Batch Loss: 0.00019182964751962572\n",
      "Epoch 4617, Loss: 0.0007069419225445017, Final Batch Loss: 1.9964420062024146e-05\n",
      "Epoch 4618, Loss: 0.00037823739603481954, Final Batch Loss: 4.9413443775847554e-05\n",
      "Epoch 4619, Loss: 0.00040910216921474785, Final Batch Loss: 5.233035335550085e-05\n",
      "Epoch 4620, Loss: 0.0004078693393694266, Final Batch Loss: 1.175967327071703e-06\n",
      "Epoch 4621, Loss: 0.0005329935083864257, Final Batch Loss: 0.00024085356562864035\n",
      "Epoch 4622, Loss: 0.00035422864402789855, Final Batch Loss: 2.7370208044885658e-05\n",
      "Epoch 4623, Loss: 0.01754326174250309, Final Batch Loss: 3.504064443404786e-05\n",
      "Epoch 4624, Loss: 0.0003453986673775944, Final Batch Loss: 0.00030075773247517645\n",
      "Epoch 4625, Loss: 0.00409910920279799, Final Batch Loss: 5.467748997034505e-05\n",
      "Epoch 4626, Loss: 0.020263932852685684, Final Batch Loss: 0.02014150284230709\n",
      "Epoch 4627, Loss: 0.001039155453327112, Final Batch Loss: 0.0005457306397147477\n",
      "Epoch 4628, Loss: 0.0014924229617463425, Final Batch Loss: 0.0008892093319445848\n",
      "Epoch 4629, Loss: 0.0010049128613900393, Final Batch Loss: 4.0559229091741145e-05\n",
      "Epoch 4630, Loss: 9.841221071837936e-05, Final Batch Loss: 4.480619463720359e-05\n",
      "Epoch 4631, Loss: 0.00010983659103658283, Final Batch Loss: 3.9856899093138054e-05\n",
      "Epoch 4632, Loss: 0.00020257018059055554, Final Batch Loss: 1.0038887012342457e-05\n",
      "Epoch 4633, Loss: 0.0007665557641303167, Final Batch Loss: 0.0005724405054934323\n",
      "Epoch 4634, Loss: 0.00011005566557287239, Final Batch Loss: 1.750171577441506e-05\n",
      "Epoch 4635, Loss: 0.00876293358487601, Final Batch Loss: 0.00870124064385891\n",
      "Epoch 4636, Loss: 0.0019151816034082003, Final Batch Loss: 0.00045469289761967957\n",
      "Epoch 4637, Loss: 0.02008164296603354, Final Batch Loss: 0.020026909187436104\n",
      "Epoch 4638, Loss: 0.05052657815394923, Final Batch Loss: 4.74925764137879e-05\n",
      "Epoch 4639, Loss: 0.001360810041660443, Final Batch Loss: 0.0007211155025288463\n",
      "Epoch 4640, Loss: 8.872692205841304e-05, Final Batch Loss: 5.512230472959345e-06\n",
      "Epoch 4641, Loss: 0.00012997206522413762, Final Batch Loss: 8.674869604874402e-05\n",
      "Epoch 4642, Loss: 0.010040663492873136, Final Batch Loss: 0.010005840100347996\n",
      "Epoch 4643, Loss: 0.00014783746883040294, Final Batch Loss: 6.459803262259811e-05\n",
      "Epoch 4644, Loss: 0.0005839336881763302, Final Batch Loss: 0.00030288321431726217\n",
      "Epoch 4645, Loss: 0.0009566727057972457, Final Batch Loss: 0.000721521326340735\n",
      "Epoch 4646, Loss: 0.02014363514172146, Final Batch Loss: 5.0271410145796835e-05\n",
      "Epoch 4647, Loss: 9.236121150024701e-05, Final Batch Loss: 3.917518552043475e-05\n",
      "Epoch 4648, Loss: 0.0019660675470731803, Final Batch Loss: 0.0016835920978337526\n",
      "Epoch 4649, Loss: 0.0009972994994313922, Final Batch Loss: 0.0004815282009076327\n",
      "Epoch 4650, Loss: 0.0016880695402505808, Final Batch Loss: 7.218619430204853e-05\n",
      "Epoch 4651, Loss: 0.00046155111431289697, Final Batch Loss: 0.00036009735777042806\n",
      "Epoch 4652, Loss: 0.0005323976820363896, Final Batch Loss: 2.4332899556611665e-05\n",
      "Epoch 4653, Loss: 0.002725183472648496, Final Batch Loss: 5.853257971466519e-05\n",
      "Epoch 4654, Loss: 0.007886232633609325, Final Batch Loss: 0.0002599233412183821\n",
      "Epoch 4655, Loss: 0.001669820246661402, Final Batch Loss: 5.282746769808e-06\n",
      "Epoch 4656, Loss: 0.0003002820740221068, Final Batch Loss: 0.0002127149055013433\n",
      "Epoch 4657, Loss: 0.00023654607866774313, Final Batch Loss: 5.0863298383774236e-05\n",
      "Epoch 4658, Loss: 0.001632154278922826, Final Batch Loss: 8.654271368868649e-05\n",
      "Epoch 4659, Loss: 0.005455537611851469, Final Batch Loss: 0.00020544303697533906\n",
      "Epoch 4660, Loss: 0.00031827397469896823, Final Batch Loss: 7.550651207566261e-05\n",
      "Epoch 4661, Loss: 0.0009514291341474745, Final Batch Loss: 0.00011273642303422093\n",
      "Epoch 4662, Loss: 0.004572286939946935, Final Batch Loss: 0.00033945776522159576\n",
      "Epoch 4663, Loss: 0.0003071433129662182, Final Batch Loss: 0.0001332590909441933\n",
      "Epoch 4664, Loss: 0.0002442463573970599, Final Batch Loss: 0.00017212062084581703\n",
      "Epoch 4665, Loss: 0.00039200615719892085, Final Batch Loss: 0.00011457489017629996\n",
      "Epoch 4666, Loss: 0.0019343942185514607, Final Batch Loss: 0.0017167370533570647\n",
      "Epoch 4667, Loss: 0.0019837210056721233, Final Batch Loss: 1.0421514161862433e-05\n",
      "Epoch 4668, Loss: 0.00045679594040848315, Final Batch Loss: 9.234372555511072e-05\n",
      "Epoch 4669, Loss: 0.0003307343313281308, Final Batch Loss: 1.024652101477841e-05\n",
      "Epoch 4670, Loss: 0.0004397417505970225, Final Batch Loss: 0.00018790479225572199\n",
      "Epoch 4671, Loss: 0.026688633230833148, Final Batch Loss: 2.441904825900565e-06\n",
      "Epoch 4672, Loss: 0.00019953637092839926, Final Batch Loss: 5.874417183804326e-05\n",
      "Epoch 4673, Loss: 0.0016823929836391471, Final Batch Loss: 3.8367950764950365e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4674, Loss: 0.002226391836302355, Final Batch Loss: 0.00111620023380965\n",
      "Epoch 4675, Loss: 0.00034923615930892993, Final Batch Loss: 1.977724787138868e-05\n",
      "Epoch 4676, Loss: 0.0004329071825850406, Final Batch Loss: 1.0520628165977541e-05\n",
      "Epoch 4677, Loss: 0.0021057477169961203, Final Batch Loss: 3.903092510881834e-05\n",
      "Epoch 4678, Loss: 0.0005899128445889801, Final Batch Loss: 0.00027353924815542996\n",
      "Epoch 4679, Loss: 0.0006038811116013676, Final Batch Loss: 0.00022372904641088098\n",
      "Epoch 4680, Loss: 0.0007940700634208042, Final Batch Loss: 5.1626662752823904e-05\n",
      "Epoch 4681, Loss: 0.00046960580948507413, Final Batch Loss: 4.9927701184060425e-05\n",
      "Epoch 4682, Loss: 0.0004850999794143718, Final Batch Loss: 3.174114317516796e-05\n",
      "Epoch 4683, Loss: 0.0003397623586351983, Final Batch Loss: 6.090482202125713e-05\n",
      "Epoch 4684, Loss: 0.0001752715488692047, Final Batch Loss: 6.164949809317477e-06\n",
      "Epoch 4685, Loss: 0.000596554578805808, Final Batch Loss: 0.00022262831043917686\n",
      "Epoch 4686, Loss: 0.0005773858429165557, Final Batch Loss: 0.0002240643952973187\n",
      "Epoch 4687, Loss: 0.00048684911598684266, Final Batch Loss: 0.0002867764269467443\n",
      "Epoch 4688, Loss: 0.00341295884027204, Final Batch Loss: 0.0007386714569292963\n",
      "Epoch 4689, Loss: 0.0007417873857775703, Final Batch Loss: 8.804601384326816e-05\n",
      "Epoch 4690, Loss: 0.00013056675493317016, Final Batch Loss: 3.750706355276634e-06\n",
      "Epoch 4691, Loss: 0.000834292070067022, Final Batch Loss: 5.500877887243405e-05\n",
      "Epoch 4692, Loss: 0.00011926858587685274, Final Batch Loss: 2.4879562261048704e-05\n",
      "Epoch 4693, Loss: 0.0002260974324599374, Final Batch Loss: 3.763699351111427e-05\n",
      "Epoch 4694, Loss: 0.0005455413374875207, Final Batch Loss: 3.9253125578397885e-05\n",
      "Epoch 4695, Loss: 0.0002913904536399059, Final Batch Loss: 7.818415178917348e-05\n",
      "Epoch 4696, Loss: 0.00016607519864919595, Final Batch Loss: 3.6885168810840696e-05\n",
      "Epoch 4697, Loss: 0.00016230631081270985, Final Batch Loss: 1.8785172869684175e-05\n",
      "Epoch 4698, Loss: 0.00012059432356181787, Final Batch Loss: 3.0135253837215714e-05\n",
      "Epoch 4699, Loss: 0.0004829141435038764, Final Batch Loss: 1.473626252845861e-05\n",
      "Epoch 4700, Loss: 0.0005669418478646548, Final Batch Loss: 0.00018999079475179315\n",
      "Epoch 4701, Loss: 0.00014364697199198417, Final Batch Loss: 5.0489692512201145e-05\n",
      "Epoch 4702, Loss: 0.003935769491363317, Final Batch Loss: 0.0005822622333653271\n",
      "Epoch 4703, Loss: 0.00017449962979299016, Final Batch Loss: 6.255904008867219e-05\n",
      "Epoch 4704, Loss: 0.0003767477064684499, Final Batch Loss: 0.00026414214516989887\n",
      "Epoch 4705, Loss: 0.004597262313836836, Final Batch Loss: 0.0045159501023590565\n",
      "Epoch 4706, Loss: 0.0014709624811075628, Final Batch Loss: 0.0007327793282456696\n",
      "Epoch 4707, Loss: 0.00023326642440224532, Final Batch Loss: 0.00018455018289387226\n",
      "Epoch 4708, Loss: 0.0006625382320635254, Final Batch Loss: 0.00011331293353578076\n",
      "Epoch 4709, Loss: 0.0002911522133217659, Final Batch Loss: 0.00014031071623321623\n",
      "Epoch 4710, Loss: 0.0004092039671377279, Final Batch Loss: 0.0003385277232155204\n",
      "Epoch 4711, Loss: 0.004451721244549844, Final Batch Loss: 0.00010735242540249601\n",
      "Epoch 4712, Loss: 0.00036784037547477055, Final Batch Loss: 0.00018474235548637807\n",
      "Epoch 4713, Loss: 0.0002551941815909231, Final Batch Loss: 0.00017895303608383983\n",
      "Epoch 4714, Loss: 0.0006344518114929087, Final Batch Loss: 2.722559293033555e-05\n",
      "Epoch 4715, Loss: 0.004534526256975369, Final Batch Loss: 2.107254294969607e-05\n",
      "Epoch 4716, Loss: 0.0003119287293884554, Final Batch Loss: 0.0002562756126280874\n",
      "Epoch 4717, Loss: 0.0021834153635609255, Final Batch Loss: 3.4830632102966774e-06\n",
      "Epoch 4718, Loss: 0.00010671592644939665, Final Batch Loss: 1.7952805137610994e-05\n",
      "Epoch 4719, Loss: 0.002288643016072456, Final Batch Loss: 0.0016392392572015524\n",
      "Epoch 4720, Loss: 0.03311376312876746, Final Batch Loss: 1.9972499103459995e-06\n",
      "Epoch 4721, Loss: 0.0005239609890850261, Final Batch Loss: 0.0003434474056120962\n",
      "Epoch 4722, Loss: 0.0005224039546192216, Final Batch Loss: 5.467524260893697e-06\n",
      "Epoch 4723, Loss: 0.00028914386848555296, Final Batch Loss: 3.982718681072583e-06\n",
      "Epoch 4724, Loss: 0.0001110384610001347, Final Batch Loss: 7.224950422823895e-06\n",
      "Epoch 4725, Loss: 0.00021984965496812947, Final Batch Loss: 2.1058724087197334e-05\n",
      "Epoch 4726, Loss: 0.00011856383935082704, Final Batch Loss: 6.86265921103768e-05\n",
      "Epoch 4727, Loss: 0.00015074575640028343, Final Batch Loss: 5.747181785409339e-05\n",
      "Epoch 4728, Loss: 0.0002829167860909365, Final Batch Loss: 0.0001406928786309436\n",
      "Epoch 4729, Loss: 0.00028570578069775365, Final Batch Loss: 5.730143311666325e-05\n",
      "Epoch 4730, Loss: 5.4638453548250254e-05, Final Batch Loss: 2.8785874746972695e-05\n",
      "Epoch 4731, Loss: 0.00017417731396562885, Final Batch Loss: 1.1492518751765601e-05\n",
      "Epoch 4732, Loss: 0.00112558663568052, Final Batch Loss: 3.0245771995396353e-05\n",
      "Epoch 4733, Loss: 0.0008358876730198972, Final Batch Loss: 0.0005633712862618268\n",
      "Epoch 4734, Loss: 0.0005898209346923977, Final Batch Loss: 0.00040011669625528157\n",
      "Epoch 4735, Loss: 0.004608357960933063, Final Batch Loss: 0.00458554457873106\n",
      "Epoch 4736, Loss: 0.00011549976261449046, Final Batch Loss: 2.3045236957841553e-05\n",
      "Epoch 4737, Loss: 0.0014455410537266289, Final Batch Loss: 0.0012947365175932646\n",
      "Epoch 4738, Loss: 0.0002685238669073442, Final Batch Loss: 2.1055184333818033e-05\n",
      "Epoch 4739, Loss: 4.3041809476562776e-05, Final Batch Loss: 1.3156922250345815e-05\n",
      "Epoch 4740, Loss: 0.00046284082827696693, Final Batch Loss: 2.9216103030194063e-06\n",
      "Epoch 4741, Loss: 0.00011090085354226176, Final Batch Loss: 1.834307477110997e-05\n",
      "Epoch 4742, Loss: 0.00019889639588654973, Final Batch Loss: 7.205595466075465e-05\n",
      "Epoch 4743, Loss: 0.00021502362324099522, Final Batch Loss: 0.0001615744549781084\n",
      "Epoch 4744, Loss: 8.544402771804016e-05, Final Batch Loss: 4.6521872718585655e-05\n",
      "Epoch 4745, Loss: 0.0004506816458160756, Final Batch Loss: 0.00040856286068446934\n",
      "Epoch 4746, Loss: 0.0001380440617140266, Final Batch Loss: 3.092439510510303e-05\n",
      "Epoch 4747, Loss: 0.0035644175650304533, Final Batch Loss: 8.451744179183152e-06\n",
      "Epoch 4748, Loss: 0.0014971621276345104, Final Batch Loss: 0.000720260024536401\n",
      "Epoch 4749, Loss: 0.0005165502843738068, Final Batch Loss: 0.000320393533911556\n",
      "Epoch 4750, Loss: 0.0004521339233178878, Final Batch Loss: 4.726442421087995e-05\n",
      "Epoch 4751, Loss: 0.0066408488200977445, Final Batch Loss: 0.0055582644417881966\n",
      "Epoch 4752, Loss: 0.0001915244010888273, Final Batch Loss: 2.237310582131613e-05\n",
      "Epoch 4753, Loss: 6.874810378576512e-05, Final Batch Loss: 2.703696554817725e-05\n",
      "Epoch 4754, Loss: 0.00027128372221341124, Final Batch Loss: 1.370382869936293e-05\n",
      "Epoch 4755, Loss: 0.0002919156104326248, Final Batch Loss: 8.643043838674203e-05\n",
      "Epoch 4756, Loss: 0.0009529889248369727, Final Batch Loss: 0.0007147983415052295\n",
      "Epoch 4757, Loss: 0.0003308048690087162, Final Batch Loss: 6.97746581863612e-05\n",
      "Epoch 4758, Loss: 0.0006509525483124889, Final Batch Loss: 0.0004676354583352804\n",
      "Epoch 4759, Loss: 0.000246220992266899, Final Batch Loss: 4.493284723139368e-05\n",
      "Epoch 4760, Loss: 0.035197951961890794, Final Batch Loss: 0.034903232008218765\n",
      "Epoch 4761, Loss: 0.004865727685682941, Final Batch Loss: 0.004508667159825563\n",
      "Epoch 4762, Loss: 0.0018194083495473024, Final Batch Loss: 1.216170858242549e-05\n",
      "Epoch 4763, Loss: 0.0003358893736731261, Final Batch Loss: 8.746492676436901e-05\n",
      "Epoch 4764, Loss: 0.013786952156806365, Final Batch Loss: 0.013109021820127964\n",
      "Epoch 4765, Loss: 0.01196622452698648, Final Batch Loss: 1.633737701922655e-05\n",
      "Epoch 4766, Loss: 0.0002343539999856148, Final Batch Loss: 7.1731410571374e-05\n",
      "Epoch 4767, Loss: 0.000704771991877351, Final Batch Loss: 0.0005417160573415458\n",
      "Epoch 4768, Loss: 0.0002357821176701691, Final Batch Loss: 1.6834927009767853e-05\n",
      "Epoch 4769, Loss: 0.00022053258544474375, Final Batch Loss: 2.6044455808005296e-05\n",
      "Epoch 4770, Loss: 0.0001972578465938568, Final Batch Loss: 3.380986163392663e-05\n",
      "Epoch 4771, Loss: 0.0010419973987154663, Final Batch Loss: 0.00023738409799989313\n",
      "Epoch 4772, Loss: 0.0007169857271946967, Final Batch Loss: 0.0003724679700098932\n",
      "Epoch 4773, Loss: 0.0003967837765230797, Final Batch Loss: 0.000336935103405267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4774, Loss: 0.004544177238130942, Final Batch Loss: 7.831119000911713e-05\n",
      "Epoch 4775, Loss: 0.0003983257192885503, Final Batch Loss: 0.00011879115481860936\n",
      "Epoch 4776, Loss: 0.0006412799484678544, Final Batch Loss: 0.00037207829882390797\n",
      "Epoch 4777, Loss: 0.0006404415762517601, Final Batch Loss: 0.00022474907746072859\n",
      "Epoch 4778, Loss: 0.028213199380843434, Final Batch Loss: 0.027795016765594482\n",
      "Epoch 4779, Loss: 0.00045106645848136395, Final Batch Loss: 1.8458347767591476e-05\n",
      "Epoch 4780, Loss: 0.00016216370568145066, Final Batch Loss: 2.2762200387660414e-05\n",
      "Epoch 4781, Loss: 0.0013574085605796427, Final Batch Loss: 0.0006376233068294823\n",
      "Epoch 4782, Loss: 0.006821170638431795, Final Batch Loss: 0.0057029323652386665\n",
      "Epoch 4783, Loss: 0.0002219624657300301, Final Batch Loss: 4.132100002607331e-05\n",
      "Epoch 4784, Loss: 0.0028657676484726835, Final Batch Loss: 6.949942326173186e-05\n",
      "Epoch 4785, Loss: 0.0006605923244933365, Final Batch Loss: 0.00015887897461652756\n",
      "Epoch 4786, Loss: 0.0002053602183877956, Final Batch Loss: 1.8199974874733016e-05\n",
      "Epoch 4787, Loss: 0.0005602384844678454, Final Batch Loss: 0.00018449137860443443\n",
      "Epoch 4788, Loss: 0.00015311225979530718, Final Batch Loss: 1.78121972567169e-05\n",
      "Epoch 4789, Loss: 0.00026200149113719817, Final Batch Loss: 3.458801074884832e-05\n",
      "Epoch 4790, Loss: 0.0006553606908710208, Final Batch Loss: 6.031259908922948e-05\n",
      "Epoch 4791, Loss: 0.0001669888079049997, Final Batch Loss: 6.611944263568148e-05\n",
      "Epoch 4792, Loss: 0.0002175160807382781, Final Batch Loss: 7.304976315936074e-05\n",
      "Epoch 4793, Loss: 0.025744908924025367, Final Batch Loss: 1.772944779077079e-05\n",
      "Epoch 4794, Loss: 0.00974172295536846, Final Batch Loss: 7.180775719461963e-05\n",
      "Epoch 4795, Loss: 0.0002617697809910169, Final Batch Loss: 1.1280490070930682e-05\n",
      "Epoch 4796, Loss: 0.000519985769642517, Final Batch Loss: 0.00017442615353502333\n",
      "Epoch 4797, Loss: 0.00047292855015257373, Final Batch Loss: 0.00011674225243041292\n",
      "Epoch 4798, Loss: 0.0010729230125434697, Final Batch Loss: 9.761723049450666e-05\n",
      "Epoch 4799, Loss: 0.005691273509000894, Final Batch Loss: 0.00010849665704881772\n",
      "Epoch 4800, Loss: 0.0003471782420092495, Final Batch Loss: 2.5235125576728024e-05\n",
      "Epoch 4801, Loss: 0.0012926293711643666, Final Batch Loss: 0.0009390297927893698\n",
      "Epoch 4802, Loss: 0.0010311605728929862, Final Batch Loss: 0.00017878848302643746\n",
      "Epoch 4803, Loss: 0.00018255869144923054, Final Batch Loss: 3.471337186056189e-05\n",
      "Epoch 4804, Loss: 0.00035319921516929753, Final Batch Loss: 6.846938777016476e-05\n",
      "Epoch 4805, Loss: 0.00028765458046109416, Final Batch Loss: 4.477996481000446e-05\n",
      "Epoch 4806, Loss: 0.00024284418759634718, Final Batch Loss: 3.645216202130541e-05\n",
      "Epoch 4807, Loss: 0.0007990976373548619, Final Batch Loss: 4.070739305461757e-05\n",
      "Epoch 4808, Loss: 0.0005695537402061746, Final Batch Loss: 0.00018924215692095459\n",
      "Epoch 4809, Loss: 0.00019514422820066102, Final Batch Loss: 2.388299981248565e-05\n",
      "Epoch 4810, Loss: 0.00046877375280018896, Final Batch Loss: 6.964361818972975e-05\n",
      "Epoch 4811, Loss: 0.0006356648227665573, Final Batch Loss: 0.00048098675324581563\n",
      "Epoch 4812, Loss: 0.00023325700021814555, Final Batch Loss: 6.807601312175393e-05\n",
      "Epoch 4813, Loss: 0.0005251795591902919, Final Batch Loss: 0.00010229575127596036\n",
      "Epoch 4814, Loss: 0.00011588859524636064, Final Batch Loss: 1.3807648429065011e-06\n",
      "Epoch 4815, Loss: 0.0009146918200713117, Final Batch Loss: 0.0008100529084913433\n",
      "Epoch 4816, Loss: 0.0021196433990553487, Final Batch Loss: 1.4614717656513676e-05\n",
      "Epoch 4817, Loss: 0.00045056711314828135, Final Batch Loss: 3.5939501685788855e-05\n",
      "Epoch 4818, Loss: 6.806601504649734e-05, Final Batch Loss: 7.100131369952578e-06\n",
      "Epoch 4819, Loss: 0.000390639925171854, Final Batch Loss: 0.00031046682852320373\n",
      "Epoch 4820, Loss: 0.00020755890363943763, Final Batch Loss: 8.938758401200175e-05\n",
      "Epoch 4821, Loss: 0.00043401594302849844, Final Batch Loss: 0.0002192702959291637\n",
      "Epoch 4822, Loss: 0.00021070530056022108, Final Batch Loss: 4.478586924960837e-05\n",
      "Epoch 4823, Loss: 0.00045148823846830055, Final Batch Loss: 0.0001898000482469797\n",
      "Epoch 4824, Loss: 0.00021066916360723553, Final Batch Loss: 9.53897961153416e-06\n",
      "Epoch 4825, Loss: 0.0004174162750132382, Final Batch Loss: 0.00027086923364549875\n",
      "Epoch 4826, Loss: 0.0017436836214983487, Final Batch Loss: 1.001788132271031e-05\n",
      "Epoch 4827, Loss: 0.00039438980820705183, Final Batch Loss: 0.00026741871261037886\n",
      "Epoch 4828, Loss: 0.0005273632232274394, Final Batch Loss: 4.435173104866408e-05\n",
      "Epoch 4829, Loss: 0.0009508258735877462, Final Batch Loss: 0.00010531466250540689\n",
      "Epoch 4830, Loss: 0.0006222620304470183, Final Batch Loss: 0.00032384294900111854\n",
      "Epoch 4831, Loss: 0.00035022531301365234, Final Batch Loss: 0.00021601244225166738\n",
      "Epoch 4832, Loss: 0.00031895718711894006, Final Batch Loss: 1.741225969453808e-05\n",
      "Epoch 4833, Loss: 0.0004328705308580538, Final Batch Loss: 0.0001040298375301063\n",
      "Epoch 4834, Loss: 0.003912016845788457, Final Batch Loss: 4.3646839912980795e-05\n",
      "Epoch 4835, Loss: 0.0003931724722860963, Final Batch Loss: 4.332443495513871e-05\n",
      "Epoch 4836, Loss: 0.0002452744356560288, Final Batch Loss: 1.9292083379696123e-05\n",
      "Epoch 4837, Loss: 0.0003288247808086453, Final Batch Loss: 1.0748082786449231e-05\n",
      "Epoch 4838, Loss: 0.0029206922263256274, Final Batch Loss: 0.00022760334832128137\n",
      "Epoch 4839, Loss: 0.00022223234191187657, Final Batch Loss: 9.412151121068746e-05\n",
      "Epoch 4840, Loss: 0.0001242702164745424, Final Batch Loss: 3.2620788260828704e-05\n",
      "Epoch 4841, Loss: 0.0003706948809849564, Final Batch Loss: 7.436832675011829e-05\n",
      "Epoch 4842, Loss: 0.0003619621456891764, Final Batch Loss: 0.0001509587891632691\n",
      "Epoch 4843, Loss: 0.0006118009041529149, Final Batch Loss: 0.00042455235961824656\n",
      "Epoch 4844, Loss: 0.0005660750102833845, Final Batch Loss: 0.00011651224485831335\n",
      "Epoch 4845, Loss: 0.0006799234324716963, Final Batch Loss: 6.387418397935107e-05\n",
      "Epoch 4846, Loss: 0.00044999508463661186, Final Batch Loss: 0.00023038870131131262\n",
      "Epoch 4847, Loss: 8.964386597654084e-05, Final Batch Loss: 8.545071068510879e-06\n",
      "Epoch 4848, Loss: 0.020825237006647512, Final Batch Loss: 0.02072274684906006\n",
      "Epoch 4849, Loss: 0.0002646288412506692, Final Batch Loss: 8.887353033060208e-05\n",
      "Epoch 4850, Loss: 0.0009602750214980915, Final Batch Loss: 0.00032162395655177534\n",
      "Epoch 4851, Loss: 0.00694474448391702, Final Batch Loss: 0.006150157190859318\n",
      "Epoch 4852, Loss: 0.00034462191615602933, Final Batch Loss: 0.00014563294826075435\n",
      "Epoch 4853, Loss: 0.0016770292131695896, Final Batch Loss: 0.00018775201169773936\n",
      "Epoch 4854, Loss: 0.0006932666583452374, Final Batch Loss: 0.0003342395939398557\n",
      "Epoch 4855, Loss: 0.0004339004954090342, Final Batch Loss: 0.000161501404363662\n",
      "Epoch 4856, Loss: 0.00016671852245053742, Final Batch Loss: 5.3115098125999793e-05\n",
      "Epoch 4857, Loss: 0.00021187947277212515, Final Batch Loss: 0.000138621122459881\n",
      "Epoch 4858, Loss: 0.0025854807599898777, Final Batch Loss: 1.2554824024846312e-05\n",
      "Epoch 4859, Loss: 0.0013869532631360926, Final Batch Loss: 0.0007616067887283862\n",
      "Epoch 4860, Loss: 0.00028749492412316613, Final Batch Loss: 2.7864170988323167e-05\n",
      "Epoch 4861, Loss: 0.030243339952903625, Final Batch Loss: 0.00010250827472191304\n",
      "Epoch 4862, Loss: 0.001878474718068901, Final Batch Loss: 1.1483082744234707e-05\n",
      "Epoch 4863, Loss: 0.00021699276840081438, Final Batch Loss: 2.118982229148969e-05\n",
      "Epoch 4864, Loss: 0.002023761639975419, Final Batch Loss: 0.00017681527242530137\n",
      "Epoch 4865, Loss: 0.0001927277826325735, Final Batch Loss: 0.00011300181358819827\n",
      "Epoch 4866, Loss: 0.0005944947342868545, Final Batch Loss: 4.820351932721678e-06\n",
      "Epoch 4867, Loss: 0.001190809503896162, Final Batch Loss: 0.00015441016876138747\n",
      "Epoch 4868, Loss: 0.00030504556707455777, Final Batch Loss: 0.00014562136493623257\n",
      "Epoch 4869, Loss: 0.0004571693752950523, Final Batch Loss: 4.9554582801647484e-05\n",
      "Epoch 4870, Loss: 0.0004219594338792376, Final Batch Loss: 0.0002528226177673787\n",
      "Epoch 4871, Loss: 0.0006099213242123369, Final Batch Loss: 2.1560004825005308e-05\n",
      "Epoch 4872, Loss: 0.0001684663757259841, Final Batch Loss: 2.2479616745840758e-05\n",
      "Epoch 4873, Loss: 0.00022998729582468513, Final Batch Loss: 2.3621310901944526e-05\n",
      "Epoch 4874, Loss: 0.0005737383726227563, Final Batch Loss: 2.2141473891679198e-05\n",
      "Epoch 4875, Loss: 0.0004076285840710625, Final Batch Loss: 0.00018408472533337772\n",
      "Epoch 4876, Loss: 0.014022377461515134, Final Batch Loss: 1.7866008420241997e-05\n",
      "Epoch 4877, Loss: 0.00022521043865708634, Final Batch Loss: 0.0001601341791683808\n",
      "Epoch 4878, Loss: 0.0009156507348961895, Final Batch Loss: 1.9894729121006094e-05\n",
      "Epoch 4879, Loss: 0.0005525537344510667, Final Batch Loss: 7.168436422944069e-05\n",
      "Epoch 4880, Loss: 0.0003650930302683264, Final Batch Loss: 4.1964776755776256e-05\n",
      "Epoch 4881, Loss: 0.0008668840018799528, Final Batch Loss: 7.901338540250435e-05\n",
      "Epoch 4882, Loss: 0.0003785930821322836, Final Batch Loss: 6.340544496197253e-05\n",
      "Epoch 4883, Loss: 0.00024131816462613642, Final Batch Loss: 7.392455154331401e-05\n",
      "Epoch 4884, Loss: 0.0004098819481441751, Final Batch Loss: 0.00026138481916859746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4885, Loss: 0.0003979267494287342, Final Batch Loss: 4.05868049710989e-05\n",
      "Epoch 4886, Loss: 0.000493622625072021, Final Batch Loss: 4.886401438852772e-05\n",
      "Epoch 4887, Loss: 0.00024934621251304634, Final Batch Loss: 3.4229382436024025e-05\n",
      "Epoch 4888, Loss: 0.0003038380054931622, Final Batch Loss: 5.5696353228995577e-05\n",
      "Epoch 4889, Loss: 0.003228513272915734, Final Batch Loss: 0.003089768346399069\n",
      "Epoch 4890, Loss: 0.00024004638544283807, Final Batch Loss: 7.032167923171073e-05\n",
      "Epoch 4891, Loss: 0.00018975671264342964, Final Batch Loss: 6.33976305834949e-05\n",
      "Epoch 4892, Loss: 0.0012136803543398855, Final Batch Loss: 4.5654360292246565e-06\n",
      "Epoch 4893, Loss: 0.00229896730161272, Final Batch Loss: 0.00011115866072941571\n",
      "Epoch 4894, Loss: 0.00015905759391898755, Final Batch Loss: 2.1553782062255777e-05\n",
      "Epoch 4895, Loss: 0.0024989431985886768, Final Batch Loss: 0.0016141294036060572\n",
      "Epoch 4896, Loss: 0.00014668733638245612, Final Batch Loss: 7.911566353868693e-05\n",
      "Epoch 4897, Loss: 0.0002588454226497561, Final Batch Loss: 0.00012335428618825972\n",
      "Epoch 4898, Loss: 0.00018810187611961737, Final Batch Loss: 5.404517287388444e-05\n",
      "Epoch 4899, Loss: 0.00010204504906141665, Final Batch Loss: 2.223337287432514e-05\n",
      "Epoch 4900, Loss: 0.0012585141594172455, Final Batch Loss: 0.00016532685549464077\n",
      "Epoch 4901, Loss: 0.00031269757346308324, Final Batch Loss: 0.0002376308257225901\n",
      "Epoch 4902, Loss: 0.0005205303423281293, Final Batch Loss: 0.0004090690636076033\n",
      "Epoch 4903, Loss: 0.00024682954426680226, Final Batch Loss: 2.3690723537583835e-05\n",
      "Epoch 4904, Loss: 0.0018863907016566372, Final Batch Loss: 5.9102243540110067e-05\n",
      "Epoch 4905, Loss: 0.00010951727381325327, Final Batch Loss: 1.70288622030057e-05\n",
      "Epoch 4906, Loss: 0.00043010865556425415, Final Batch Loss: 6.029472569935024e-05\n",
      "Epoch 4907, Loss: 0.0008983009829535149, Final Batch Loss: 0.0001381306501571089\n",
      "Epoch 4908, Loss: 0.0005685393552994356, Final Batch Loss: 3.0084222089499235e-05\n",
      "Epoch 4909, Loss: 0.0008479658381475019, Final Batch Loss: 2.4622304408694617e-06\n",
      "Epoch 4910, Loss: 0.000265886270426563, Final Batch Loss: 0.00021530655794776976\n",
      "Epoch 4911, Loss: 0.00046877013915036514, Final Batch Loss: 0.00043229726725257933\n",
      "Epoch 4912, Loss: 0.00016959836557361996, Final Batch Loss: 1.0099675819219556e-05\n",
      "Epoch 4913, Loss: 9.665967445471324e-05, Final Batch Loss: 1.93507567018969e-05\n",
      "Epoch 4914, Loss: 0.0005035646609030664, Final Batch Loss: 0.0001648792822379619\n",
      "Epoch 4915, Loss: 0.00021235364329186268, Final Batch Loss: 3.487697176751681e-05\n",
      "Epoch 4916, Loss: 0.00028132228180766106, Final Batch Loss: 4.44025281467475e-05\n",
      "Epoch 4917, Loss: 0.00013224259055277798, Final Batch Loss: 1.1675523637677543e-05\n",
      "Epoch 4918, Loss: 0.0009213620942318812, Final Batch Loss: 0.0005768797709606588\n",
      "Epoch 4919, Loss: 0.00019363398678251542, Final Batch Loss: 6.514717097161338e-05\n",
      "Epoch 4920, Loss: 0.00017862447930383496, Final Batch Loss: 1.8136834114557132e-06\n",
      "Epoch 4921, Loss: 0.0013441587525448995, Final Batch Loss: 9.23061634239275e-06\n",
      "Epoch 4922, Loss: 0.00018334018022869714, Final Batch Loss: 1.2568089914566372e-05\n",
      "Epoch 4923, Loss: 0.0002396351301285904, Final Batch Loss: 0.0001387436204822734\n",
      "Epoch 4924, Loss: 0.00019638746016426012, Final Batch Loss: 0.00013122921518515795\n",
      "Epoch 4925, Loss: 0.00016653805778332753, Final Batch Loss: 0.00013046004460193217\n",
      "Epoch 4926, Loss: 6.58201483929588e-05, Final Batch Loss: 6.643248980253702e-06\n",
      "Epoch 4927, Loss: 0.00015567666923743673, Final Batch Loss: 7.655914669157937e-05\n",
      "Epoch 4928, Loss: 0.0010372522556281183, Final Batch Loss: 0.00015888421330600977\n",
      "Epoch 4929, Loss: 4.7426618039025925e-05, Final Batch Loss: 1.1160211215610616e-05\n",
      "Epoch 4930, Loss: 4.678305231209379e-05, Final Batch Loss: 2.05102696781978e-05\n",
      "Epoch 4931, Loss: 0.0012443416635505855, Final Batch Loss: 0.0011525388108566403\n",
      "Epoch 4932, Loss: 0.00029386227470240556, Final Batch Loss: 5.2801220590481535e-05\n",
      "Epoch 4933, Loss: 0.00038737624845452956, Final Batch Loss: 5.829063866258366e-06\n",
      "Epoch 4934, Loss: 0.0010142036978777469, Final Batch Loss: 3.8106798001535935e-06\n",
      "Epoch 4935, Loss: 0.00019397461619519163, Final Batch Loss: 1.5454357708222233e-05\n",
      "Epoch 4936, Loss: 0.00017583615726834978, Final Batch Loss: 4.536179767455906e-05\n",
      "Epoch 4937, Loss: 0.0010089036732097156, Final Batch Loss: 9.914806287270039e-05\n",
      "Epoch 4938, Loss: 0.0011537528664575802, Final Batch Loss: 2.317010694241617e-05\n",
      "Epoch 4939, Loss: 0.00014599209748666908, Final Batch Loss: 2.1997548174113035e-05\n",
      "Epoch 4940, Loss: 0.00019386794156162068, Final Batch Loss: 1.3785205737804063e-05\n",
      "Epoch 4941, Loss: 0.00031167231281870045, Final Batch Loss: 3.159161133226007e-05\n",
      "Epoch 4942, Loss: 0.00015175016596913338, Final Batch Loss: 4.697116673924029e-05\n",
      "Epoch 4943, Loss: 0.00031891565822661505, Final Batch Loss: 6.856470918137347e-06\n",
      "Epoch 4944, Loss: 0.0005621820891974494, Final Batch Loss: 0.00020821027283091098\n",
      "Epoch 4945, Loss: 0.01438987567962613, Final Batch Loss: 0.0003561566409189254\n",
      "Epoch 4946, Loss: 0.0006748795331077417, Final Batch Loss: 2.400419907644391e-05\n",
      "Epoch 4947, Loss: 0.0007761425003991462, Final Batch Loss: 0.000651420617941767\n",
      "Epoch 4948, Loss: 0.00042593779949129384, Final Batch Loss: 3.3353528579027625e-06\n",
      "Epoch 4949, Loss: 0.00015890801296336576, Final Batch Loss: 8.208042709156871e-05\n",
      "Epoch 4950, Loss: 0.001530294270196464, Final Batch Loss: 0.0008691265829838812\n",
      "Epoch 4951, Loss: 0.00013311270231497474, Final Batch Loss: 5.115904059493914e-06\n",
      "Epoch 4952, Loss: 0.0007844995641335117, Final Batch Loss: 6.370874416461447e-06\n",
      "Epoch 4953, Loss: 0.00023737113588140346, Final Batch Loss: 0.00014848416321910918\n",
      "Epoch 4954, Loss: 0.0004129092931179912, Final Batch Loss: 4.191015977994539e-05\n",
      "Epoch 4955, Loss: 0.00018370008456258802, Final Batch Loss: 1.4823387573414948e-05\n",
      "Epoch 4956, Loss: 4.651520521292696e-05, Final Batch Loss: 1.3476227650244255e-05\n",
      "Epoch 4957, Loss: 0.00011786352888520923, Final Batch Loss: 1.7889178707264364e-05\n",
      "Epoch 4958, Loss: 0.00011332360008964315, Final Batch Loss: 7.720709982095286e-05\n",
      "Epoch 4959, Loss: 0.0002144362870240002, Final Batch Loss: 0.00017108691099565476\n",
      "Epoch 4960, Loss: 4.583578856909298e-05, Final Batch Loss: 2.532805774535518e-05\n",
      "Epoch 4961, Loss: 0.0007942136726342142, Final Batch Loss: 6.51940208626911e-05\n",
      "Epoch 4962, Loss: 0.0002945110263681272, Final Batch Loss: 0.00015394145157188177\n",
      "Epoch 4963, Loss: 0.00019250628702138783, Final Batch Loss: 1.0664244655345101e-05\n",
      "Epoch 4964, Loss: 0.0001558980120535125, Final Batch Loss: 3.2517498766537756e-05\n",
      "Epoch 4965, Loss: 0.0009962286894733552, Final Batch Loss: 4.3027583160437644e-05\n",
      "Epoch 4966, Loss: 0.0009655585381551646, Final Batch Loss: 4.962070670444518e-05\n",
      "Epoch 4967, Loss: 0.00022034017001715256, Final Batch Loss: 1.1229992196604144e-05\n",
      "Epoch 4968, Loss: 0.00012460715879569761, Final Batch Loss: 2.75979982689023e-06\n",
      "Epoch 4969, Loss: 5.004111517337151e-05, Final Batch Loss: 1.0446766282257158e-05\n",
      "Epoch 4970, Loss: 0.0004373468109406531, Final Batch Loss: 8.45309768919833e-05\n",
      "Epoch 4971, Loss: 5.924699235038133e-05, Final Batch Loss: 1.6339805370080285e-05\n",
      "Epoch 4972, Loss: 0.00013749732806900283, Final Batch Loss: 1.4998689948697574e-05\n",
      "Epoch 4973, Loss: 0.00016469187858092482, Final Batch Loss: 0.00012211076682433486\n",
      "Epoch 4974, Loss: 6.698362994939089e-05, Final Batch Loss: 1.8286675185663626e-05\n",
      "Epoch 4975, Loss: 0.0001977744705072837, Final Batch Loss: 4.291126242605969e-05\n",
      "Epoch 4976, Loss: 0.000279730405054579, Final Batch Loss: 3.3352276659570634e-05\n",
      "Epoch 4977, Loss: 0.0002255859826618689, Final Batch Loss: 2.9705070119234733e-06\n",
      "Epoch 4978, Loss: 0.00023536466869700234, Final Batch Loss: 0.00018223699589725584\n",
      "Epoch 4979, Loss: 0.00014431631188926985, Final Batch Loss: 1.1200879271200392e-05\n",
      "Epoch 4980, Loss: 0.00013365106204332733, Final Batch Loss: 3.612811099173996e-07\n",
      "Epoch 4981, Loss: 6.346509144350421e-05, Final Batch Loss: 2.5865430870908312e-05\n",
      "Epoch 4982, Loss: 0.000128436779959884, Final Batch Loss: 1.39083940666751e-05\n",
      "Epoch 4983, Loss: 0.0003513780393404886, Final Batch Loss: 0.0001792117691366002\n",
      "Epoch 4984, Loss: 0.00010967050866383943, Final Batch Loss: 1.458445876778569e-05\n",
      "Epoch 4985, Loss: 7.713588274782524e-05, Final Batch Loss: 8.178036296158098e-06\n",
      "Epoch 4986, Loss: 0.00013454964846459916, Final Batch Loss: 3.62749160558451e-05\n",
      "Epoch 4987, Loss: 8.846138916851487e-05, Final Batch Loss: 3.057705544051714e-05\n",
      "Epoch 4988, Loss: 0.0006247943711059634, Final Batch Loss: 6.76555009704316e-06\n",
      "Epoch 4989, Loss: 0.0002997267583850771, Final Batch Loss: 9.352929191663861e-05\n",
      "Epoch 4990, Loss: 0.0005233763586147688, Final Batch Loss: 9.525159111944959e-05\n",
      "Epoch 4991, Loss: 0.00010783052448459785, Final Batch Loss: 3.5901586670661345e-05\n",
      "Epoch 4992, Loss: 0.0033518623786221724, Final Batch Loss: 5.522525680135004e-05\n",
      "Epoch 4993, Loss: 0.00011309596925457299, Final Batch Loss: 3.1393376502819592e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4994, Loss: 0.00019834755676129134, Final Batch Loss: 3.659012872958556e-05\n",
      "Epoch 4995, Loss: 0.00019573155259422492, Final Batch Loss: 4.9530815886100754e-05\n",
      "Epoch 4996, Loss: 0.0002720732391026104, Final Batch Loss: 1.9299690393381752e-05\n",
      "Epoch 4997, Loss: 0.00010085843041451881, Final Batch Loss: 2.018439772655256e-06\n",
      "Epoch 4998, Loss: 0.00018138886116503272, Final Batch Loss: 9.330959073849954e-06\n",
      "Epoch 4999, Loss: 0.0003606430400395766, Final Batch Loss: 1.576160138938576e-05\n",
      "Epoch 5000, Loss: 0.00039702176218270324, Final Batch Loss: 3.1234099878929555e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  2]\n",
      " [ 0 34  0]\n",
      " [ 0  0 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.957     0.978        46\n",
      "           1      1.000     1.000     1.000        34\n",
      "           2      0.950     1.000     0.974        38\n",
      "\n",
      "    accuracy                          0.983       118\n",
      "   macro avg      0.983     0.986     0.984       118\n",
      "weighted avg      0.984     0.983     0.983       118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../../../saved_models/UCI 3 Label 5 Subject Classifier Ablation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
