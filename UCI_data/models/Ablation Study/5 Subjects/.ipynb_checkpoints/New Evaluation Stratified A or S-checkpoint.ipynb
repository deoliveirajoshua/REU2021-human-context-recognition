{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_features = ['42 tGravityAcc-mean()-Y',\n",
    " '43 tGravityAcc-mean()-Z',\n",
    " '51 tGravityAcc-max()-Y',\n",
    " '52 tGravityAcc-max()-Z',\n",
    " '54 tGravityAcc-min()-Y',\n",
    " '55 tGravityAcc-min()-Z',\n",
    " '56 tGravityAcc-sma()',\n",
    " '58 tGravityAcc-energy()-Y',\n",
    " '59 tGravityAcc-energy()-Z',\n",
    " '128 tBodyGyro-mad()-Y',\n",
    " '141 tBodyGyro-iqr()-Y',\n",
    " '428 fBodyGyro-std()-Y',\n",
    " '434 fBodyGyro-max()-Y',\n",
    " '475 fBodyGyro-bandsEnergy()-1,8',\n",
    " '483 fBodyGyro-bandsEnergy()-1,16',\n",
    " '487 fBodyGyro-bandsEnergy()-1,24',\n",
    " '559 angle(X,gravityMean)',\n",
    " '560 angle(Y,gravityMean)',\n",
    " '561 angle(Z,gravityMean)']\n",
    "\n",
    "act_features = ['4 tBodyAcc-std()-X',\n",
    " '7 tBodyAcc-mad()-X',\n",
    " '10 tBodyAcc-max()-X',\n",
    " '17 tBodyAcc-energy()-X',\n",
    " '202 tBodyAccMag-std()',\n",
    " '203 tBodyAccMag-mad()',\n",
    " '215 tGravityAccMag-std()',\n",
    " '216 tGravityAccMag-mad()',\n",
    " '266 fBodyAcc-mean()-X',\n",
    " '269 fBodyAcc-std()-X',\n",
    " '282 fBodyAcc-energy()-X',\n",
    " '303 fBodyAcc-bandsEnergy()-1,8',\n",
    " '311 fBodyAcc-bandsEnergy()-1,16',\n",
    " '315 fBodyAcc-bandsEnergy()-1,24',\n",
    " '382 fBodyAccJerk-bandsEnergy()-1,8',\n",
    " '504 fBodyAccMag-std()',\n",
    " '505 fBodyAccMag-mad()',\n",
    " '509 fBodyAccMag-energy()']\n",
    "\n",
    "input_shape = len(sub_features) + len(act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.LeakyReLU(0.05)\n",
    "    )\n",
    "\n",
    "class Activity_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Activity_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "class Subject_Classifier(nn.Module):\n",
    "    def __init__(self, feature_dim = input_shape):\n",
    "        super(Subject_Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            classifier_block(feature_dim, 25),\n",
    "            classifier_block(25, 20),\n",
    "            classifier_block(20, 15),\n",
    "            classifier_block(15, 10),\n",
    "            nn.Linear(10, 5)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines each generator layer\n",
    "#input and output dimensions needed\n",
    "def generator_block(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace = True)\n",
    "    )\n",
    "\n",
    "#returns n_samples of z_dim (number of dimensions of latent space) noise\n",
    "def get_noise(n_samples, z_dim):\n",
    "    return torch.randn(n_samples, z_dim)\n",
    "\n",
    "#defines generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 10, feature_dim = input_shape, hidden_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            generator_block(z_dim, 80),\n",
    "            generator_block(80, 60),\n",
    "            generator_block(60, 50),\n",
    "            nn.Linear(50, feature_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, noise):\n",
    "        return self.gen(noise)\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    model.load_state_dict(torch.load(f'../../../saved_models/{model_name}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label is a list of integers specifying which labels to filter by\n",
    "#users is a list of integers specifying which users to filter by\n",
    "#y_label is a string, either \"Activity\" or \"Subject\" depending on what y output needs to be returned\n",
    "def start_data(label, users, y_label, sub_features, act_features):\n",
    "    #get the dataframe column names\n",
    "    name_dataframe = pd.read_csv('../../../data/features.txt', delimiter = '\\n', header = None)\n",
    "    names = name_dataframe.values.tolist()\n",
    "    names = [k for row in names for k in row] #List of column names\n",
    "\n",
    "    data = pd.read_csv('../../../data/X_train.txt', delim_whitespace = True, header = None) #Read in dataframe\n",
    "    data.columns = names #Setting column names\n",
    "    \n",
    "    X_train_1 = data[sub_features]\n",
    "    X_train_2 = data[act_features]\n",
    "    X_train = pd.concat([X_train_1, X_train_2], axis = 1)\n",
    "    \n",
    "    y_train_activity = pd.read_csv('../../../data/y_train.txt', header = None)\n",
    "    y_train_activity.columns = ['Activity']\n",
    "    \n",
    "    y_train_subject = pd.read_csv('../../../data/subject_train.txt', header = None)\n",
    "    y_train_subject.columns = ['Subject']\n",
    "    \n",
    "    GAN_data = pd.concat([X_train, y_train_activity, y_train_subject], axis = 1)\n",
    "    GAN_data = GAN_data[GAN_data['Activity'].isin(label)]\n",
    "    GAN_data = GAN_data[GAN_data['Subject'].isin(users)]\n",
    "    \n",
    "    X_train = GAN_data.iloc[:,:-2].values\n",
    "    y_train = GAN_data[[y_label]].values\n",
    "    \n",
    "    return X_train, y_train.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8]\n",
    "\n",
    "X, y = start_data(activities, users, \"Activity\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    else:\n",
    "        y[k] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model = Activity_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.273602604866028, Final Batch Loss: 1.0973317623138428\n",
      "Epoch 2, Loss: 3.2591891288757324, Final Batch Loss: 1.0855427980422974\n",
      "Epoch 3, Loss: 3.2668423652648926, Final Batch Loss: 1.1006696224212646\n",
      "Epoch 4, Loss: 3.2474950551986694, Final Batch Loss: 1.072757363319397\n",
      "Epoch 5, Loss: 3.2402745485305786, Final Batch Loss: 1.070950984954834\n",
      "Epoch 6, Loss: 3.2520869970321655, Final Batch Loss: 1.1045938730239868\n",
      "Epoch 7, Loss: 3.234590172767639, Final Batch Loss: 1.0795608758926392\n",
      "Epoch 8, Loss: 3.2186944484710693, Final Batch Loss: 1.0694972276687622\n",
      "Epoch 9, Loss: 3.206766963005066, Final Batch Loss: 1.0504335165023804\n",
      "Epoch 10, Loss: 3.1965088844299316, Final Batch Loss: 1.0593514442443848\n",
      "Epoch 11, Loss: 3.1868953704833984, Final Batch Loss: 1.0628448724746704\n",
      "Epoch 12, Loss: 3.162538766860962, Final Batch Loss: 1.0416103601455688\n",
      "Epoch 13, Loss: 3.1544206142425537, Final Batch Loss: 1.0482701063156128\n",
      "Epoch 14, Loss: 3.135264277458191, Final Batch Loss: 1.058513879776001\n",
      "Epoch 15, Loss: 3.1112217903137207, Final Batch Loss: 1.0440956354141235\n",
      "Epoch 16, Loss: 3.06432044506073, Final Batch Loss: 1.0059860944747925\n",
      "Epoch 17, Loss: 3.03352153301239, Final Batch Loss: 1.0210644006729126\n",
      "Epoch 18, Loss: 2.9832030534744263, Final Batch Loss: 0.980944037437439\n",
      "Epoch 19, Loss: 2.9082778692245483, Final Batch Loss: 0.9521469473838806\n",
      "Epoch 20, Loss: 2.840897560119629, Final Batch Loss: 0.934698224067688\n",
      "Epoch 21, Loss: 2.765719473361969, Final Batch Loss: 0.8919525742530823\n",
      "Epoch 22, Loss: 2.6923967003822327, Final Batch Loss: 0.8996817469596863\n",
      "Epoch 23, Loss: 2.5999760031700134, Final Batch Loss: 0.8511742949485779\n",
      "Epoch 24, Loss: 2.4550469517707825, Final Batch Loss: 0.7865896821022034\n",
      "Epoch 25, Loss: 2.366979479789734, Final Batch Loss: 0.7854493260383606\n",
      "Epoch 26, Loss: 2.253049612045288, Final Batch Loss: 0.7239207625389099\n",
      "Epoch 27, Loss: 2.1039722561836243, Final Batch Loss: 0.7034478187561035\n",
      "Epoch 28, Loss: 1.9802653789520264, Final Batch Loss: 0.6947628259658813\n",
      "Epoch 29, Loss: 1.8464671969413757, Final Batch Loss: 0.5601126551628113\n",
      "Epoch 30, Loss: 1.745648741722107, Final Batch Loss: 0.5730546116828918\n",
      "Epoch 31, Loss: 1.636837124824524, Final Batch Loss: 0.5290126204490662\n",
      "Epoch 32, Loss: 1.4664711654186249, Final Batch Loss: 0.4664864242076874\n",
      "Epoch 33, Loss: 1.381447196006775, Final Batch Loss: 0.4581523537635803\n",
      "Epoch 34, Loss: 1.3200895190238953, Final Batch Loss: 0.4399965703487396\n",
      "Epoch 35, Loss: 1.281421273946762, Final Batch Loss: 0.45754846930503845\n",
      "Epoch 36, Loss: 1.1862723529338837, Final Batch Loss: 0.361223965883255\n",
      "Epoch 37, Loss: 1.026554822921753, Final Batch Loss: 0.3586968183517456\n",
      "Epoch 38, Loss: 1.0224265158176422, Final Batch Loss: 0.3690812885761261\n",
      "Epoch 39, Loss: 0.9463261961936951, Final Batch Loss: 0.28254878520965576\n",
      "Epoch 40, Loss: 0.8756898194551468, Final Batch Loss: 0.2229396551847458\n",
      "Epoch 41, Loss: 0.8285301476716995, Final Batch Loss: 0.2335667461156845\n",
      "Epoch 42, Loss: 0.8764743506908417, Final Batch Loss: 0.3192225694656372\n",
      "Epoch 43, Loss: 0.7558336108922958, Final Batch Loss: 0.26133260130882263\n",
      "Epoch 44, Loss: 0.7217442244291306, Final Batch Loss: 0.2368760108947754\n",
      "Epoch 45, Loss: 0.6448608040809631, Final Batch Loss: 0.1997145712375641\n",
      "Epoch 46, Loss: 0.6135703772306442, Final Batch Loss: 0.16627289354801178\n",
      "Epoch 47, Loss: 0.604771226644516, Final Batch Loss: 0.206868514418602\n",
      "Epoch 48, Loss: 0.5660161823034286, Final Batch Loss: 0.1975909024477005\n",
      "Epoch 49, Loss: 0.5373103767633438, Final Batch Loss: 0.131181538105011\n",
      "Epoch 50, Loss: 0.5098588541150093, Final Batch Loss: 0.11994960159063339\n",
      "Epoch 51, Loss: 0.47295190393924713, Final Batch Loss: 0.13709929585456848\n",
      "Epoch 52, Loss: 0.5338465571403503, Final Batch Loss: 0.17437835037708282\n",
      "Epoch 53, Loss: 0.49585914611816406, Final Batch Loss: 0.17887744307518005\n",
      "Epoch 54, Loss: 0.5066614300012589, Final Batch Loss: 0.18160104751586914\n",
      "Epoch 55, Loss: 0.48518405854701996, Final Batch Loss: 0.13924071192741394\n",
      "Epoch 56, Loss: 0.4965285509824753, Final Batch Loss: 0.15079046785831451\n",
      "Epoch 57, Loss: 0.5068913698196411, Final Batch Loss: 0.20628488063812256\n",
      "Epoch 58, Loss: 0.4308789372444153, Final Batch Loss: 0.1558334082365036\n",
      "Epoch 59, Loss: 0.3936862424015999, Final Batch Loss: 0.10138768702745438\n",
      "Epoch 60, Loss: 0.4382094517350197, Final Batch Loss: 0.15002281963825226\n",
      "Epoch 61, Loss: 0.4765111058950424, Final Batch Loss: 0.20518943667411804\n",
      "Epoch 62, Loss: 0.4175291582942009, Final Batch Loss: 0.11810288578271866\n",
      "Epoch 63, Loss: 0.38056912273168564, Final Batch Loss: 0.07291693240404129\n",
      "Epoch 64, Loss: 0.3786174803972244, Final Batch Loss: 0.12398543953895569\n",
      "Epoch 65, Loss: 0.3082500770688057, Final Batch Loss: 0.10240916907787323\n",
      "Epoch 66, Loss: 0.3854657709598541, Final Batch Loss: 0.11481114476919174\n",
      "Epoch 67, Loss: 0.36472858488559723, Final Batch Loss: 0.09433571994304657\n",
      "Epoch 68, Loss: 0.35330143570899963, Final Batch Loss: 0.12778489291667938\n",
      "Epoch 69, Loss: 0.33510608971118927, Final Batch Loss: 0.09030255675315857\n",
      "Epoch 70, Loss: 0.331573449075222, Final Batch Loss: 0.10587254166603088\n",
      "Epoch 71, Loss: 0.3154004290699959, Final Batch Loss: 0.09060469269752502\n",
      "Epoch 72, Loss: 0.33563897013664246, Final Batch Loss: 0.14336451888084412\n",
      "Epoch 73, Loss: 0.3235785439610481, Final Batch Loss: 0.13775764405727386\n",
      "Epoch 74, Loss: 0.326882004737854, Final Batch Loss: 0.13240373134613037\n",
      "Epoch 75, Loss: 0.266303651034832, Final Batch Loss: 0.07054590433835983\n",
      "Epoch 76, Loss: 0.2511662244796753, Final Batch Loss: 0.048330940306186676\n",
      "Epoch 77, Loss: 0.3032776564359665, Final Batch Loss: 0.08410552889108658\n",
      "Epoch 78, Loss: 0.2982759326696396, Final Batch Loss: 0.12886367738246918\n",
      "Epoch 79, Loss: 0.2769140675663948, Final Batch Loss: 0.057310596108436584\n",
      "Epoch 80, Loss: 0.27881936728954315, Final Batch Loss: 0.09621886909008026\n",
      "Epoch 81, Loss: 0.28533733636140823, Final Batch Loss: 0.11883512884378433\n",
      "Epoch 82, Loss: 0.29837706685066223, Final Batch Loss: 0.09514707326889038\n",
      "Epoch 83, Loss: 0.2510344758629799, Final Batch Loss: 0.06125715374946594\n",
      "Epoch 84, Loss: 0.27531246095895767, Final Batch Loss: 0.071031354367733\n",
      "Epoch 85, Loss: 0.2481146603822708, Final Batch Loss: 0.05451642721891403\n",
      "Epoch 86, Loss: 0.24696419946849346, Final Batch Loss: 0.029811633750796318\n",
      "Epoch 87, Loss: 0.24893726408481598, Final Batch Loss: 0.04823664575815201\n",
      "Epoch 88, Loss: 0.22980591654777527, Final Batch Loss: 0.060033634305000305\n",
      "Epoch 89, Loss: 0.2652898579835892, Final Batch Loss: 0.11059476435184479\n",
      "Epoch 90, Loss: 0.22712596133351326, Final Batch Loss: 0.06115060672163963\n",
      "Epoch 91, Loss: 0.20197833701968193, Final Batch Loss: 0.07708920538425446\n",
      "Epoch 92, Loss: 0.2084244303405285, Final Batch Loss: 0.0350462906062603\n",
      "Epoch 93, Loss: 0.26844948530197144, Final Batch Loss: 0.07850547134876251\n",
      "Epoch 94, Loss: 0.2703818269073963, Final Batch Loss: 0.13465885818004608\n",
      "Epoch 95, Loss: 0.23567907512187958, Final Batch Loss: 0.04485756903886795\n",
      "Epoch 96, Loss: 0.24645953997969627, Final Batch Loss: 0.05343548581004143\n",
      "Epoch 97, Loss: 0.2032812498509884, Final Batch Loss: 0.06839410215616226\n",
      "Epoch 98, Loss: 0.17777928709983826, Final Batch Loss: 0.04888581112027168\n",
      "Epoch 99, Loss: 0.1995762698352337, Final Batch Loss: 0.07129795849323273\n",
      "Epoch 100, Loss: 0.23033436387777328, Final Batch Loss: 0.07408799231052399\n",
      "Epoch 101, Loss: 0.25109509378671646, Final Batch Loss: 0.04658418148756027\n",
      "Epoch 102, Loss: 0.22718451172113419, Final Batch Loss: 0.0819716602563858\n",
      "Epoch 103, Loss: 0.2374182529747486, Final Batch Loss: 0.09228292107582092\n",
      "Epoch 104, Loss: 0.2009866014122963, Final Batch Loss: 0.08353500068187714\n",
      "Epoch 105, Loss: 0.20730453915894032, Final Batch Loss: 0.024229707196354866\n",
      "Epoch 106, Loss: 0.2490006908774376, Final Batch Loss: 0.08187499642372131\n",
      "Epoch 107, Loss: 0.22773698344826698, Final Batch Loss: 0.09917662292718887\n",
      "Epoch 108, Loss: 0.20939674228429794, Final Batch Loss: 0.07061333954334259\n",
      "Epoch 109, Loss: 0.1990126110613346, Final Batch Loss: 0.08297652751207352\n",
      "Epoch 110, Loss: 0.23631273210048676, Final Batch Loss: 0.10974907875061035\n",
      "Epoch 111, Loss: 0.22477874159812927, Final Batch Loss: 0.0936075821518898\n",
      "Epoch 112, Loss: 0.24865816161036491, Final Batch Loss: 0.12842139601707458\n",
      "Epoch 113, Loss: 0.2666187286376953, Final Batch Loss: 0.10129979252815247\n",
      "Epoch 114, Loss: 0.2113768756389618, Final Batch Loss: 0.07637238502502441\n",
      "Epoch 115, Loss: 0.224678173661232, Final Batch Loss: 0.06300197541713715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Loss: 0.1925605647265911, Final Batch Loss: 0.03511438146233559\n",
      "Epoch 117, Loss: 0.16491127014160156, Final Batch Loss: 0.06668539345264435\n",
      "Epoch 118, Loss: 0.1934518963098526, Final Batch Loss: 0.058235447853803635\n",
      "Epoch 119, Loss: 0.18646077439188957, Final Batch Loss: 0.07962494343519211\n",
      "Epoch 120, Loss: 0.21188142150640488, Final Batch Loss: 0.12904998660087585\n",
      "Epoch 121, Loss: 0.15938770398497581, Final Batch Loss: 0.032909493893384933\n",
      "Epoch 122, Loss: 0.18163393065333366, Final Batch Loss: 0.058160945773124695\n",
      "Epoch 123, Loss: 0.18931641802191734, Final Batch Loss: 0.06396974623203278\n",
      "Epoch 124, Loss: 0.1383473426103592, Final Batch Loss: 0.040840424597263336\n",
      "Epoch 125, Loss: 0.20334388129413128, Final Batch Loss: 0.028939275071024895\n",
      "Epoch 126, Loss: 0.13805591687560081, Final Batch Loss: 0.06108696758747101\n",
      "Epoch 127, Loss: 0.1559332236647606, Final Batch Loss: 0.046549342572689056\n",
      "Epoch 128, Loss: 0.22111482545733452, Final Batch Loss: 0.11887584626674652\n",
      "Epoch 129, Loss: 0.18995852395892143, Final Batch Loss: 0.09280276298522949\n",
      "Epoch 130, Loss: 0.20587031915783882, Final Batch Loss: 0.0735577791929245\n",
      "Epoch 131, Loss: 0.2068301998078823, Final Batch Loss: 0.05605050548911095\n",
      "Epoch 132, Loss: 0.19820361956954002, Final Batch Loss: 0.07210764288902283\n",
      "Epoch 133, Loss: 0.17646533995866776, Final Batch Loss: 0.07117537409067154\n",
      "Epoch 134, Loss: 0.20974509045481682, Final Batch Loss: 0.06531039625406265\n",
      "Epoch 135, Loss: 0.16999848559498787, Final Batch Loss: 0.04822656139731407\n",
      "Epoch 136, Loss: 0.1702187918126583, Final Batch Loss: 0.045740947127342224\n",
      "Epoch 137, Loss: 0.17047032341361046, Final Batch Loss: 0.054006967693567276\n",
      "Epoch 138, Loss: 0.18618015199899673, Final Batch Loss: 0.12036184221506119\n",
      "Epoch 139, Loss: 0.16248567402362823, Final Batch Loss: 0.043358590453863144\n",
      "Epoch 140, Loss: 0.15113642811775208, Final Batch Loss: 0.05699868127703667\n",
      "Epoch 141, Loss: 0.18742797523736954, Final Batch Loss: 0.06819484382867813\n",
      "Epoch 142, Loss: 0.10554363578557968, Final Batch Loss: 0.01795148104429245\n",
      "Epoch 143, Loss: 0.2196488231420517, Final Batch Loss: 0.10419527441263199\n",
      "Epoch 144, Loss: 0.16271059960126877, Final Batch Loss: 0.05729685351252556\n",
      "Epoch 145, Loss: 0.1775742657482624, Final Batch Loss: 0.05608466640114784\n",
      "Epoch 146, Loss: 0.11803767457604408, Final Batch Loss: 0.038116205483675\n",
      "Epoch 147, Loss: 0.14087526500225067, Final Batch Loss: 0.03889194503426552\n",
      "Epoch 148, Loss: 0.14487802982330322, Final Batch Loss: 0.09335604310035706\n",
      "Epoch 149, Loss: 0.12941639684140682, Final Batch Loss: 0.02380274422466755\n",
      "Epoch 150, Loss: 0.13440044596791267, Final Batch Loss: 0.0363711379468441\n",
      "Epoch 151, Loss: 0.11693803779780865, Final Batch Loss: 0.030630530789494514\n",
      "Epoch 152, Loss: 0.18015097454190254, Final Batch Loss: 0.06141146272420883\n",
      "Epoch 153, Loss: 0.16040249541401863, Final Batch Loss: 0.06442742794752121\n",
      "Epoch 154, Loss: 0.11333263665437698, Final Batch Loss: 0.027288688346743584\n",
      "Epoch 155, Loss: 0.13643220253288746, Final Batch Loss: 0.07277809828519821\n",
      "Epoch 156, Loss: 0.15326864272356033, Final Batch Loss: 0.05393214151263237\n",
      "Epoch 157, Loss: 0.15632161125540733, Final Batch Loss: 0.07315987348556519\n",
      "Epoch 158, Loss: 0.17476819083094597, Final Batch Loss: 0.059031616896390915\n",
      "Epoch 159, Loss: 0.13026547990739346, Final Batch Loss: 0.023106390610337257\n",
      "Epoch 160, Loss: 0.16436364129185677, Final Batch Loss: 0.07401777803897858\n",
      "Epoch 161, Loss: 0.14770784229040146, Final Batch Loss: 0.050162237137556076\n",
      "Epoch 162, Loss: 0.14517329633235931, Final Batch Loss: 0.037999384105205536\n",
      "Epoch 163, Loss: 0.1834736354649067, Final Batch Loss: 0.09657153487205505\n",
      "Epoch 164, Loss: 0.13837023451924324, Final Batch Loss: 0.015776704996824265\n",
      "Epoch 165, Loss: 0.11162553541362286, Final Batch Loss: 0.026317698881030083\n",
      "Epoch 166, Loss: 0.1424511056393385, Final Batch Loss: 0.062340591102838516\n",
      "Epoch 167, Loss: 0.13511907868087292, Final Batch Loss: 0.022615155205130577\n",
      "Epoch 168, Loss: 0.14644328691065311, Final Batch Loss: 0.0661047101020813\n",
      "Epoch 169, Loss: 0.12068627588450909, Final Batch Loss: 0.05939268320798874\n",
      "Epoch 170, Loss: 0.11999012529850006, Final Batch Loss: 0.02780163660645485\n",
      "Epoch 171, Loss: 0.13472329452633858, Final Batch Loss: 0.04022010788321495\n",
      "Epoch 172, Loss: 0.1278560794889927, Final Batch Loss: 0.020675178617239\n",
      "Epoch 173, Loss: 0.13420845195651054, Final Batch Loss: 0.04819568246603012\n",
      "Epoch 174, Loss: 0.11674389243125916, Final Batch Loss: 0.03844701871275902\n",
      "Epoch 175, Loss: 0.0872657336294651, Final Batch Loss: 0.025246065109968185\n",
      "Epoch 176, Loss: 0.14265051856637, Final Batch Loss: 0.049185968935489655\n",
      "Epoch 177, Loss: 0.18107296526432037, Final Batch Loss: 0.08083082735538483\n",
      "Epoch 178, Loss: 0.12685240432620049, Final Batch Loss: 0.031754691153764725\n",
      "Epoch 179, Loss: 0.12389267049729824, Final Batch Loss: 0.043853577226400375\n",
      "Epoch 180, Loss: 0.08875607885420322, Final Batch Loss: 0.018690580502152443\n",
      "Epoch 181, Loss: 0.09831054322421551, Final Batch Loss: 0.04483306035399437\n",
      "Epoch 182, Loss: 0.12652470916509628, Final Batch Loss: 0.032496824860572815\n",
      "Epoch 183, Loss: 0.10882243886590004, Final Batch Loss: 0.04348518326878548\n",
      "Epoch 184, Loss: 0.14682044833898544, Final Batch Loss: 0.03710482269525528\n",
      "Epoch 185, Loss: 0.11392213776707649, Final Batch Loss: 0.050667956471443176\n",
      "Epoch 186, Loss: 0.13027600571513176, Final Batch Loss: 0.04307648167014122\n",
      "Epoch 187, Loss: 0.12082671001553535, Final Batch Loss: 0.038122981786727905\n",
      "Epoch 188, Loss: 0.1119442731142044, Final Batch Loss: 0.05849073454737663\n",
      "Epoch 189, Loss: 0.10281046479940414, Final Batch Loss: 0.022953543812036514\n",
      "Epoch 190, Loss: 0.11542000994086266, Final Batch Loss: 0.03735216334462166\n",
      "Epoch 191, Loss: 0.12690471857786179, Final Batch Loss: 0.05451427400112152\n",
      "Epoch 192, Loss: 0.11701546236872673, Final Batch Loss: 0.017110103741288185\n",
      "Epoch 193, Loss: 0.12382441945374012, Final Batch Loss: 0.032532356679439545\n",
      "Epoch 194, Loss: 0.13109600730240345, Final Batch Loss: 0.055597271770238876\n",
      "Epoch 195, Loss: 0.07727283425629139, Final Batch Loss: 0.011434441432356834\n",
      "Epoch 196, Loss: 0.11180686391890049, Final Batch Loss: 0.04772152751684189\n",
      "Epoch 197, Loss: 0.11542197316884995, Final Batch Loss: 0.035953592509031296\n",
      "Epoch 198, Loss: 0.0945593174546957, Final Batch Loss: 0.022548150271177292\n",
      "Epoch 199, Loss: 0.12055917084217072, Final Batch Loss: 0.06969109922647476\n",
      "Epoch 200, Loss: 0.08062632754445076, Final Batch Loss: 0.03603976592421532\n",
      "Epoch 201, Loss: 0.11870698817074299, Final Batch Loss: 0.048799026757478714\n",
      "Epoch 202, Loss: 0.10049946419894695, Final Batch Loss: 0.058819480240345\n",
      "Epoch 203, Loss: 0.10266652796417475, Final Batch Loss: 0.011835024692118168\n",
      "Epoch 204, Loss: 0.09389672428369522, Final Batch Loss: 0.046679846942424774\n",
      "Epoch 205, Loss: 0.06856688857078552, Final Batch Loss: 0.009358640760183334\n",
      "Epoch 206, Loss: 0.1144799031317234, Final Batch Loss: 0.037149906158447266\n",
      "Epoch 207, Loss: 0.09783177636563778, Final Batch Loss: 0.015591630712151527\n",
      "Epoch 208, Loss: 0.09519577212631702, Final Batch Loss: 0.03565560281276703\n",
      "Epoch 209, Loss: 0.12431501224637032, Final Batch Loss: 0.03160189092159271\n",
      "Epoch 210, Loss: 0.09408036060631275, Final Batch Loss: 0.03181285411119461\n",
      "Epoch 211, Loss: 0.07844861224293709, Final Batch Loss: 0.024431012570858\n",
      "Epoch 212, Loss: 0.118282500654459, Final Batch Loss: 0.0375446155667305\n",
      "Epoch 213, Loss: 0.11429649777710438, Final Batch Loss: 0.057025883346796036\n",
      "Epoch 214, Loss: 0.09488449525088072, Final Batch Loss: 0.05015742778778076\n",
      "Epoch 215, Loss: 0.10503874532878399, Final Batch Loss: 0.04768551141023636\n",
      "Epoch 216, Loss: 0.10381998121738434, Final Batch Loss: 0.03474476560950279\n",
      "Epoch 217, Loss: 0.10212540067732334, Final Batch Loss: 0.06445086747407913\n",
      "Epoch 218, Loss: 0.11565618868917227, Final Batch Loss: 0.05484146997332573\n",
      "Epoch 219, Loss: 0.11012744344770908, Final Batch Loss: 0.05924228951334953\n",
      "Epoch 220, Loss: 0.10203609988093376, Final Batch Loss: 0.04590538516640663\n",
      "Epoch 221, Loss: 0.12706471886485815, Final Batch Loss: 0.07096286863088608\n",
      "Epoch 222, Loss: 0.1011576484888792, Final Batch Loss: 0.05408488214015961\n",
      "Epoch 223, Loss: 0.08267335500568151, Final Batch Loss: 0.012222765944898129\n",
      "Epoch 224, Loss: 0.10152969090268016, Final Batch Loss: 0.005556586664170027\n",
      "Epoch 225, Loss: 0.08475900627672672, Final Batch Loss: 0.0185234397649765\n",
      "Epoch 226, Loss: 0.0954552460461855, Final Batch Loss: 0.020362799987196922\n",
      "Epoch 227, Loss: 0.07395487651228905, Final Batch Loss: 0.012755848467350006\n",
      "Epoch 228, Loss: 0.10557379759848118, Final Batch Loss: 0.040402960032224655\n",
      "Epoch 229, Loss: 0.1033113244920969, Final Batch Loss: 0.016500169411301613\n",
      "Epoch 230, Loss: 0.09141069278120995, Final Batch Loss: 0.014900105074048042\n",
      "Epoch 231, Loss: 0.1065835221670568, Final Batch Loss: 0.0062462701462209225\n",
      "Epoch 232, Loss: 0.09224950335919857, Final Batch Loss: 0.01691979356110096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233, Loss: 0.11902426555752754, Final Batch Loss: 0.03559228777885437\n",
      "Epoch 234, Loss: 0.05988907255232334, Final Batch Loss: 0.020376810804009438\n",
      "Epoch 235, Loss: 0.061312668956816196, Final Batch Loss: 0.009508353658020496\n",
      "Epoch 236, Loss: 0.05790054425597191, Final Batch Loss: 0.010287338867783546\n",
      "Epoch 237, Loss: 0.10141701344400644, Final Batch Loss: 0.009012934751808643\n",
      "Epoch 238, Loss: 0.10098731983453035, Final Batch Loss: 0.04806597903370857\n",
      "Epoch 239, Loss: 0.07492252299562097, Final Batch Loss: 0.005450645927339792\n",
      "Epoch 240, Loss: 0.06280092243105173, Final Batch Loss: 0.020789803937077522\n",
      "Epoch 241, Loss: 0.061296334490180016, Final Batch Loss: 0.015611207112669945\n",
      "Epoch 242, Loss: 0.08135801879689097, Final Batch Loss: 0.007470607291907072\n",
      "Epoch 243, Loss: 0.0874966960400343, Final Batch Loss: 0.00944504700601101\n",
      "Epoch 244, Loss: 0.0977434441447258, Final Batch Loss: 0.01755780167877674\n",
      "Epoch 245, Loss: 0.07342781499028206, Final Batch Loss: 0.024539636448025703\n",
      "Epoch 246, Loss: 0.09145781304687262, Final Batch Loss: 0.009925353340804577\n",
      "Epoch 247, Loss: 0.06801715027540922, Final Batch Loss: 0.01014556922018528\n",
      "Epoch 248, Loss: 0.06895984895527363, Final Batch Loss: 0.01790972240269184\n",
      "Epoch 249, Loss: 0.0759429931640625, Final Batch Loss: 0.023047026246786118\n",
      "Epoch 250, Loss: 0.09511514008045197, Final Batch Loss: 0.025587020441889763\n",
      "Epoch 251, Loss: 0.08541055954992771, Final Batch Loss: 0.025632712990045547\n",
      "Epoch 252, Loss: 0.09738530032336712, Final Batch Loss: 0.054573461413383484\n",
      "Epoch 253, Loss: 0.07641908805817366, Final Batch Loss: 0.036193858832120895\n",
      "Epoch 254, Loss: 0.07374386209994555, Final Batch Loss: 0.006338267587125301\n",
      "Epoch 255, Loss: 0.07390101067721844, Final Batch Loss: 0.012530867010354996\n",
      "Epoch 256, Loss: 0.06690361071377993, Final Batch Loss: 0.011407035402953625\n",
      "Epoch 257, Loss: 0.08271204959601164, Final Batch Loss: 0.01007386390119791\n",
      "Epoch 258, Loss: 0.06038331473246217, Final Batch Loss: 0.003560472745448351\n",
      "Epoch 259, Loss: 0.06284320121631026, Final Batch Loss: 0.047838617116212845\n",
      "Epoch 260, Loss: 0.0661598308943212, Final Batch Loss: 0.00680552190169692\n",
      "Epoch 261, Loss: 0.06625272240489721, Final Batch Loss: 0.035056017339229584\n",
      "Epoch 262, Loss: 0.06429537059739232, Final Batch Loss: 0.006280860397964716\n",
      "Epoch 263, Loss: 0.08436301443725824, Final Batch Loss: 0.06108124554157257\n",
      "Epoch 264, Loss: 0.0676787681877613, Final Batch Loss: 0.0426570288836956\n",
      "Epoch 265, Loss: 0.08129753777757287, Final Batch Loss: 0.00652893865481019\n",
      "Epoch 266, Loss: 0.04928217176347971, Final Batch Loss: 0.009405379183590412\n",
      "Epoch 267, Loss: 0.07485784869641066, Final Batch Loss: 0.024398677051067352\n",
      "Epoch 268, Loss: 0.05666187359020114, Final Batch Loss: 0.006772277411073446\n",
      "Epoch 269, Loss: 0.07696620002388954, Final Batch Loss: 0.005438968539237976\n",
      "Epoch 270, Loss: 0.13831606321036816, Final Batch Loss: 0.10055886954069138\n",
      "Epoch 271, Loss: 0.07450575428083539, Final Batch Loss: 0.004767626989632845\n",
      "Epoch 272, Loss: 0.08248020149767399, Final Batch Loss: 0.03867439180612564\n",
      "Epoch 273, Loss: 0.08577776327729225, Final Batch Loss: 0.023982305079698563\n",
      "Epoch 274, Loss: 0.09277957119047642, Final Batch Loss: 0.03576795011758804\n",
      "Epoch 275, Loss: 0.06840531714260578, Final Batch Loss: 0.02549842931330204\n",
      "Epoch 276, Loss: 0.055553863756358624, Final Batch Loss: 0.02592029795050621\n",
      "Epoch 277, Loss: 0.0562553433701396, Final Batch Loss: 0.010951540432870388\n",
      "Epoch 278, Loss: 0.05108811240643263, Final Batch Loss: 0.028986692428588867\n",
      "Epoch 279, Loss: 0.05528838559985161, Final Batch Loss: 0.01152035966515541\n",
      "Epoch 280, Loss: 0.04556343238800764, Final Batch Loss: 0.008503103628754616\n",
      "Epoch 281, Loss: 0.07429953524842858, Final Batch Loss: 0.0437113381922245\n",
      "Epoch 282, Loss: 0.06660560192540288, Final Batch Loss: 0.003155393060296774\n",
      "Epoch 283, Loss: 0.09765477012842894, Final Batch Loss: 0.06675155460834503\n",
      "Epoch 284, Loss: 0.058922807686030865, Final Batch Loss: 0.013693117536604404\n",
      "Epoch 285, Loss: 0.06537447310984135, Final Batch Loss: 0.022037243470549583\n",
      "Epoch 286, Loss: 0.06164839491248131, Final Batch Loss: 0.02117534913122654\n",
      "Epoch 287, Loss: 0.07592355413362384, Final Batch Loss: 0.05636756122112274\n",
      "Epoch 288, Loss: 0.09942389093339443, Final Batch Loss: 0.03755366802215576\n",
      "Epoch 289, Loss: 0.04785230942070484, Final Batch Loss: 0.005969109013676643\n",
      "Epoch 290, Loss: 0.0593309635296464, Final Batch Loss: 0.010642948560416698\n",
      "Epoch 291, Loss: 0.04627618519589305, Final Batch Loss: 0.01879870519042015\n",
      "Epoch 292, Loss: 0.05162744829431176, Final Batch Loss: 0.023834271356463432\n",
      "Epoch 293, Loss: 0.04933221032842994, Final Batch Loss: 0.006956194061785936\n",
      "Epoch 294, Loss: 0.07252181507647038, Final Batch Loss: 0.01323474757373333\n",
      "Epoch 295, Loss: 0.07182882074266672, Final Batch Loss: 0.03636125102639198\n",
      "Epoch 296, Loss: 0.061533672735095024, Final Batch Loss: 0.029533827677369118\n",
      "Epoch 297, Loss: 0.0826995950192213, Final Batch Loss: 0.04405835270881653\n",
      "Epoch 298, Loss: 0.05881387274712324, Final Batch Loss: 0.010058301500976086\n",
      "Epoch 299, Loss: 0.06804268062114716, Final Batch Loss: 0.005384061485528946\n",
      "Epoch 300, Loss: 0.04662156105041504, Final Batch Loss: 0.00685103889554739\n",
      "Epoch 301, Loss: 0.07189074531197548, Final Batch Loss: 0.028068244457244873\n",
      "Epoch 302, Loss: 0.047102384734898806, Final Batch Loss: 0.003591418731957674\n",
      "Epoch 303, Loss: 0.04949095007032156, Final Batch Loss: 0.012908192351460457\n",
      "Epoch 304, Loss: 0.07016557175666094, Final Batch Loss: 0.036820974200963974\n",
      "Epoch 305, Loss: 0.05539901368319988, Final Batch Loss: 0.012344632297754288\n",
      "Epoch 306, Loss: 0.033299158327281475, Final Batch Loss: 0.009861616417765617\n",
      "Epoch 307, Loss: 0.05441612750291824, Final Batch Loss: 0.012113923206925392\n",
      "Epoch 308, Loss: 0.0564253618940711, Final Batch Loss: 0.01962219551205635\n",
      "Epoch 309, Loss: 0.05424293130636215, Final Batch Loss: 0.018763041123747826\n",
      "Epoch 310, Loss: 0.05470311129465699, Final Batch Loss: 0.005426548887044191\n",
      "Epoch 311, Loss: 0.07129482924938202, Final Batch Loss: 0.021566782146692276\n",
      "Epoch 312, Loss: 0.04340224131010473, Final Batch Loss: 0.01273613702505827\n",
      "Epoch 313, Loss: 0.048804701305925846, Final Batch Loss: 0.006064120680093765\n",
      "Epoch 314, Loss: 0.06497046165168285, Final Batch Loss: 0.04588752239942551\n",
      "Epoch 315, Loss: 0.05493168346583843, Final Batch Loss: 0.03242882713675499\n",
      "Epoch 316, Loss: 0.03739537438377738, Final Batch Loss: 0.004785746801644564\n",
      "Epoch 317, Loss: 0.0666255378164351, Final Batch Loss: 0.0038538617081940174\n",
      "Epoch 318, Loss: 0.04518907004967332, Final Batch Loss: 0.008940714411437511\n",
      "Epoch 319, Loss: 0.04694888927042484, Final Batch Loss: 0.009692469611763954\n",
      "Epoch 320, Loss: 0.049122968688607216, Final Batch Loss: 0.0038963714614510536\n",
      "Epoch 321, Loss: 0.05595321673899889, Final Batch Loss: 0.014657744206488132\n",
      "Epoch 322, Loss: 0.04772069817408919, Final Batch Loss: 0.011181299574673176\n",
      "Epoch 323, Loss: 0.06288236565887928, Final Batch Loss: 0.007150799036026001\n",
      "Epoch 324, Loss: 0.04610518645495176, Final Batch Loss: 0.017199421301484108\n",
      "Epoch 325, Loss: 0.07181181106716394, Final Batch Loss: 0.03659261390566826\n",
      "Epoch 326, Loss: 0.05371422227472067, Final Batch Loss: 0.005176985636353493\n",
      "Epoch 327, Loss: 0.0363193959929049, Final Batch Loss: 0.014612616039812565\n",
      "Epoch 328, Loss: 0.06942579243332148, Final Batch Loss: 0.014304685406386852\n",
      "Epoch 329, Loss: 0.045463649556040764, Final Batch Loss: 0.008004410192370415\n",
      "Epoch 330, Loss: 0.041547710075974464, Final Batch Loss: 0.009144986979663372\n",
      "Epoch 331, Loss: 0.04450795007869601, Final Batch Loss: 0.007237792480736971\n",
      "Epoch 332, Loss: 0.03356954641640186, Final Batch Loss: 0.010178139433264732\n",
      "Epoch 333, Loss: 0.049173510167747736, Final Batch Loss: 0.02231365256011486\n",
      "Epoch 334, Loss: 0.05465508531779051, Final Batch Loss: 0.030223118141293526\n",
      "Epoch 335, Loss: 0.05001881532371044, Final Batch Loss: 0.016977611929178238\n",
      "Epoch 336, Loss: 0.05146745592355728, Final Batch Loss: 0.010155532509088516\n",
      "Epoch 337, Loss: 0.07311555277556181, Final Batch Loss: 0.03262962028384209\n",
      "Epoch 338, Loss: 0.03536209696903825, Final Batch Loss: 0.004002695437520742\n",
      "Epoch 339, Loss: 0.09177071368321776, Final Batch Loss: 0.06741619110107422\n",
      "Epoch 340, Loss: 0.029482140438631177, Final Batch Loss: 0.003685535630211234\n",
      "Epoch 341, Loss: 0.03746072109788656, Final Batch Loss: 0.006136263720691204\n",
      "Epoch 342, Loss: 0.04378264816477895, Final Batch Loss: 0.004616674035787582\n",
      "Epoch 343, Loss: 0.05399513337761164, Final Batch Loss: 0.01575593277812004\n",
      "Epoch 344, Loss: 0.07360688783228397, Final Batch Loss: 0.008875338360667229\n",
      "Epoch 345, Loss: 0.07294910866767168, Final Batch Loss: 0.012671035714447498\n",
      "Epoch 346, Loss: 0.029952442971989512, Final Batch Loss: 0.0029888262506574392\n",
      "Epoch 347, Loss: 0.039617953822016716, Final Batch Loss: 0.007269138470292091\n",
      "Epoch 348, Loss: 0.03674266720190644, Final Batch Loss: 0.005700994748622179\n",
      "Epoch 349, Loss: 0.03481303248554468, Final Batch Loss: 0.013713759370148182\n",
      "Epoch 350, Loss: 0.034085340332239866, Final Batch Loss: 0.017587710171937943\n",
      "Epoch 351, Loss: 0.03910955786705017, Final Batch Loss: 0.00772903673350811\n",
      "Epoch 352, Loss: 0.07361796870827675, Final Batch Loss: 0.056776564568281174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353, Loss: 0.04172943066805601, Final Batch Loss: 0.011520630680024624\n",
      "Epoch 354, Loss: 0.07999766850844026, Final Batch Loss: 0.03833454102277756\n",
      "Epoch 355, Loss: 0.08983867522329092, Final Batch Loss: 0.06580700725317001\n",
      "Epoch 356, Loss: 0.029732541646808386, Final Batch Loss: 0.006111005786806345\n",
      "Epoch 357, Loss: 0.05542023712769151, Final Batch Loss: 0.0043483939953148365\n",
      "Epoch 358, Loss: 0.05631935130804777, Final Batch Loss: 0.02519305609166622\n",
      "Epoch 359, Loss: 0.060047279112041, Final Batch Loss: 0.03818345069885254\n",
      "Epoch 360, Loss: 0.1204922879114747, Final Batch Loss: 0.09524167329072952\n",
      "Epoch 361, Loss: 0.03783165640197694, Final Batch Loss: 0.005361140239983797\n",
      "Epoch 362, Loss: 0.0637251827865839, Final Batch Loss: 0.01776045560836792\n",
      "Epoch 363, Loss: 0.02543999534100294, Final Batch Loss: 0.010795324109494686\n",
      "Epoch 364, Loss: 0.04429658246226609, Final Batch Loss: 0.003415716113522649\n",
      "Epoch 365, Loss: 0.04839428002014756, Final Batch Loss: 0.0020453506149351597\n",
      "Epoch 366, Loss: 0.04004806652665138, Final Batch Loss: 0.014741470105946064\n",
      "Epoch 367, Loss: 0.033152957912534475, Final Batch Loss: 0.01818586140871048\n",
      "Epoch 368, Loss: 0.03175966767594218, Final Batch Loss: 0.009514454752206802\n",
      "Epoch 369, Loss: 0.047739626839756966, Final Batch Loss: 0.009679562412202358\n",
      "Epoch 370, Loss: 0.05270168394781649, Final Batch Loss: 0.003213974880054593\n",
      "Epoch 371, Loss: 0.029960219748318195, Final Batch Loss: 0.0026766462251544\n",
      "Epoch 372, Loss: 0.031245913356542587, Final Batch Loss: 0.0029822317883372307\n",
      "Epoch 373, Loss: 0.03588743321597576, Final Batch Loss: 0.010369814932346344\n",
      "Epoch 374, Loss: 0.029856625944375992, Final Batch Loss: 0.006075331009924412\n",
      "Epoch 375, Loss: 0.060246629640460014, Final Batch Loss: 0.03086201474070549\n",
      "Epoch 376, Loss: 0.025547532364726067, Final Batch Loss: 0.006358262151479721\n",
      "Epoch 377, Loss: 0.041276585310697556, Final Batch Loss: 0.004207640886306763\n",
      "Epoch 378, Loss: 0.03800265118479729, Final Batch Loss: 0.006917518563568592\n",
      "Epoch 379, Loss: 0.06160708353854716, Final Batch Loss: 0.002887623617425561\n",
      "Epoch 380, Loss: 0.0420365072786808, Final Batch Loss: 0.01025337167084217\n",
      "Epoch 381, Loss: 0.02258066600188613, Final Batch Loss: 0.006012421101331711\n",
      "Epoch 382, Loss: 0.02601934364065528, Final Batch Loss: 0.0057508330792188644\n",
      "Epoch 383, Loss: 0.018811117159202695, Final Batch Loss: 0.003133178921416402\n",
      "Epoch 384, Loss: 0.04868775559589267, Final Batch Loss: 0.0062216962687671185\n",
      "Epoch 385, Loss: 0.04418100789189339, Final Batch Loss: 0.01230209693312645\n",
      "Epoch 386, Loss: 0.07288886653259397, Final Batch Loss: 0.04861124977469444\n",
      "Epoch 387, Loss: 0.036774386651813984, Final Batch Loss: 0.027609527111053467\n",
      "Epoch 388, Loss: 0.032581353560090065, Final Batch Loss: 0.003562391735613346\n",
      "Epoch 389, Loss: 0.03241105726920068, Final Batch Loss: 0.002871809294447303\n",
      "Epoch 390, Loss: 0.025155713316053152, Final Batch Loss: 0.013666338287293911\n",
      "Epoch 391, Loss: 0.024509320966899395, Final Batch Loss: 0.003207635832950473\n",
      "Epoch 392, Loss: 0.027742482256144285, Final Batch Loss: 0.018061870709061623\n",
      "Epoch 393, Loss: 0.019430858548730612, Final Batch Loss: 0.006491298787295818\n",
      "Epoch 394, Loss: 0.03429482504725456, Final Batch Loss: 0.020757252350449562\n",
      "Epoch 395, Loss: 0.014904930023476481, Final Batch Loss: 0.00359517615288496\n",
      "Epoch 396, Loss: 0.020304832607507706, Final Batch Loss: 0.0045760637149214745\n",
      "Epoch 397, Loss: 0.026129160076379776, Final Batch Loss: 0.007901931181550026\n",
      "Epoch 398, Loss: 0.042195850517600775, Final Batch Loss: 0.02693147398531437\n",
      "Epoch 399, Loss: 0.03565845172852278, Final Batch Loss: 0.0034926487132906914\n",
      "Epoch 400, Loss: 0.047635843977332115, Final Batch Loss: 0.02073720470070839\n",
      "Epoch 401, Loss: 0.052963996306061745, Final Batch Loss: 0.015861276537179947\n",
      "Epoch 402, Loss: 0.019431341905146837, Final Batch Loss: 0.006155123934149742\n",
      "Epoch 403, Loss: 0.05166115704923868, Final Batch Loss: 0.02816028520464897\n",
      "Epoch 404, Loss: 0.03396684629842639, Final Batch Loss: 0.006875945720821619\n",
      "Epoch 405, Loss: 0.018602661788463593, Final Batch Loss: 0.006107072811573744\n",
      "Epoch 406, Loss: 0.024919234216213226, Final Batch Loss: 0.005181104876101017\n",
      "Epoch 407, Loss: 0.013125787489116192, Final Batch Loss: 0.004016292281448841\n",
      "Epoch 408, Loss: 0.035918602254241705, Final Batch Loss: 0.006744595244526863\n",
      "Epoch 409, Loss: 0.01967513421550393, Final Batch Loss: 0.007240480277687311\n",
      "Epoch 410, Loss: 0.01574669172987342, Final Batch Loss: 0.005968098528683186\n",
      "Epoch 411, Loss: 0.04406151454895735, Final Batch Loss: 0.027540724724531174\n",
      "Epoch 412, Loss: 0.01778371469117701, Final Batch Loss: 0.0031553455628454685\n",
      "Epoch 413, Loss: 0.05658490629866719, Final Batch Loss: 0.02773832343518734\n",
      "Epoch 414, Loss: 0.027450816123746336, Final Batch Loss: 0.0017782304203137755\n",
      "Epoch 415, Loss: 0.013955369824543595, Final Batch Loss: 0.004011542070657015\n",
      "Epoch 416, Loss: 0.018119659507647157, Final Batch Loss: 0.012201153673231602\n",
      "Epoch 417, Loss: 0.027734300121665, Final Batch Loss: 0.005378900561481714\n",
      "Epoch 418, Loss: 0.03274534782394767, Final Batch Loss: 0.017210887745022774\n",
      "Epoch 419, Loss: 0.015513609629124403, Final Batch Loss: 0.004743640776723623\n",
      "Epoch 420, Loss: 0.016512154485099018, Final Batch Loss: 0.007717327680438757\n",
      "Epoch 421, Loss: 0.036248326767235994, Final Batch Loss: 0.020555440336465836\n",
      "Epoch 422, Loss: 0.0179728080984205, Final Batch Loss: 0.0026260511949658394\n",
      "Epoch 423, Loss: 0.05578441917896271, Final Batch Loss: 0.022397177293896675\n",
      "Epoch 424, Loss: 0.016426665475592017, Final Batch Loss: 0.002298276172950864\n",
      "Epoch 425, Loss: 0.03828463330864906, Final Batch Loss: 0.002352079376578331\n",
      "Epoch 426, Loss: 0.026898813666775823, Final Batch Loss: 0.003054579719901085\n",
      "Epoch 427, Loss: 0.03036990063264966, Final Batch Loss: 0.003345942823216319\n",
      "Epoch 428, Loss: 0.05801339051686227, Final Batch Loss: 0.040847424417734146\n",
      "Epoch 429, Loss: 0.016134741017594934, Final Batch Loss: 0.0006714027840644121\n",
      "Epoch 430, Loss: 0.02792837319429964, Final Batch Loss: 0.0011290012625977397\n",
      "Epoch 431, Loss: 0.018369708908721805, Final Batch Loss: 0.0036075308453291655\n",
      "Epoch 432, Loss: 0.03078601392917335, Final Batch Loss: 0.023273391649127007\n",
      "Epoch 433, Loss: 0.021624975837767124, Final Batch Loss: 0.0018629998667165637\n",
      "Epoch 434, Loss: 0.030464131385087967, Final Batch Loss: 0.010783646255731583\n",
      "Epoch 435, Loss: 0.028630836866796017, Final Batch Loss: 0.0038783634081482887\n",
      "Epoch 436, Loss: 0.03763437271118164, Final Batch Loss: 0.007892719469964504\n",
      "Epoch 437, Loss: 0.017480381880886853, Final Batch Loss: 0.008157051168382168\n",
      "Epoch 438, Loss: 0.02474259037990123, Final Batch Loss: 0.0011336604366078973\n",
      "Epoch 439, Loss: 0.021498666377738118, Final Batch Loss: 0.002432995242998004\n",
      "Epoch 440, Loss: 0.014071786543354392, Final Batch Loss: 0.0038149661850184202\n",
      "Epoch 441, Loss: 0.017547365743666887, Final Batch Loss: 0.0008815932087600231\n",
      "Epoch 442, Loss: 0.014706171583384275, Final Batch Loss: 0.002413123846054077\n",
      "Epoch 443, Loss: 0.02686764602549374, Final Batch Loss: 0.002435172675177455\n",
      "Epoch 444, Loss: 0.057143108220770955, Final Batch Loss: 0.026117147877812386\n",
      "Epoch 445, Loss: 0.015134927700273693, Final Batch Loss: 0.0014309686375781894\n",
      "Epoch 446, Loss: 0.006672747200354934, Final Batch Loss: 0.0019128075800836086\n",
      "Epoch 447, Loss: 0.029425384011119604, Final Batch Loss: 0.002898681443184614\n",
      "Epoch 448, Loss: 0.028374993707984686, Final Batch Loss: 0.004548695404082537\n",
      "Epoch 449, Loss: 0.017998573079239577, Final Batch Loss: 0.000963489233981818\n",
      "Epoch 450, Loss: 0.019671530462801456, Final Batch Loss: 0.007949784398078918\n",
      "Epoch 451, Loss: 0.029973083408549428, Final Batch Loss: 0.0015639334451407194\n",
      "Epoch 452, Loss: 0.042991444119252264, Final Batch Loss: 0.001387661905027926\n",
      "Epoch 453, Loss: 0.028012151829898357, Final Batch Loss: 0.00506925955414772\n",
      "Epoch 454, Loss: 0.020444697642233223, Final Batch Loss: 0.0008386566187255085\n",
      "Epoch 455, Loss: 0.04061133903451264, Final Batch Loss: 0.003077944042161107\n",
      "Epoch 456, Loss: 0.007404090079944581, Final Batch Loss: 0.0007213414064608514\n",
      "Epoch 457, Loss: 0.024947160854935646, Final Batch Loss: 0.006129797548055649\n",
      "Epoch 458, Loss: 0.0055896020494401455, Final Batch Loss: 0.0015269896248355508\n",
      "Epoch 459, Loss: 0.014953155303373933, Final Batch Loss: 0.002201617928221822\n",
      "Epoch 460, Loss: 0.017077854834496975, Final Batch Loss: 0.003140537068247795\n",
      "Epoch 461, Loss: 0.020563543308526278, Final Batch Loss: 0.017553051933646202\n",
      "Epoch 462, Loss: 0.016171153751201928, Final Batch Loss: 0.0014287327649071813\n",
      "Epoch 463, Loss: 0.05542969889938831, Final Batch Loss: 0.005387218669056892\n",
      "Epoch 464, Loss: 0.018216857104562223, Final Batch Loss: 0.0015806298470124602\n",
      "Epoch 465, Loss: 0.02321820124052465, Final Batch Loss: 0.006279646418988705\n",
      "Epoch 466, Loss: 0.028645613696426153, Final Batch Loss: 0.02364707924425602\n",
      "Epoch 467, Loss: 0.03957513556815684, Final Batch Loss: 0.00329878949560225\n",
      "Epoch 468, Loss: 0.024069720413535833, Final Batch Loss: 0.008131733164191246\n",
      "Epoch 469, Loss: 0.02373932907357812, Final Batch Loss: 0.001692499965429306\n",
      "Epoch 470, Loss: 0.012823314289562404, Final Batch Loss: 0.006683281157165766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471, Loss: 0.03461610805243254, Final Batch Loss: 0.010352828539907932\n",
      "Epoch 472, Loss: 0.03314841887913644, Final Batch Loss: 0.011439623311161995\n",
      "Epoch 473, Loss: 0.0195812996244058, Final Batch Loss: 0.0028583102393895388\n",
      "Epoch 474, Loss: 0.02770837559364736, Final Batch Loss: 0.002925923326984048\n",
      "Epoch 475, Loss: 0.014798010932281613, Final Batch Loss: 0.006805047392845154\n",
      "Epoch 476, Loss: 0.026306360494345427, Final Batch Loss: 0.00976055022329092\n",
      "Epoch 477, Loss: 0.009546041488647461, Final Batch Loss: 0.004230639897286892\n",
      "Epoch 478, Loss: 0.03618665714748204, Final Batch Loss: 0.0090542733669281\n",
      "Epoch 479, Loss: 0.016112295212224126, Final Batch Loss: 0.011698158457875252\n",
      "Epoch 480, Loss: 0.007614632602781057, Final Batch Loss: 0.001744431909173727\n",
      "Epoch 481, Loss: 0.017679677112028003, Final Batch Loss: 0.002170545281842351\n",
      "Epoch 482, Loss: 0.020669336314313114, Final Batch Loss: 0.0012746063293889165\n",
      "Epoch 483, Loss: 0.022489840164780617, Final Batch Loss: 0.011339335702359676\n",
      "Epoch 484, Loss: 0.02606938569806516, Final Batch Loss: 0.008910861797630787\n",
      "Epoch 485, Loss: 0.04056715406477451, Final Batch Loss: 0.008684809319674969\n",
      "Epoch 486, Loss: 0.018590462394058704, Final Batch Loss: 0.0022490425035357475\n",
      "Epoch 487, Loss: 0.023483351222239435, Final Batch Loss: 0.009512624703347683\n",
      "Epoch 488, Loss: 0.011408817954361439, Final Batch Loss: 0.003513805102556944\n",
      "Epoch 489, Loss: 0.022700976114720106, Final Batch Loss: 0.006190093234181404\n",
      "Epoch 490, Loss: 0.042953770724125206, Final Batch Loss: 0.033223770558834076\n",
      "Epoch 491, Loss: 0.014400402433238924, Final Batch Loss: 0.007877333089709282\n",
      "Epoch 492, Loss: 0.02242193929851055, Final Batch Loss: 0.002532835816964507\n",
      "Epoch 493, Loss: 0.013943528174422681, Final Batch Loss: 0.0016031983541324735\n",
      "Epoch 494, Loss: 0.013706202851608396, Final Batch Loss: 0.005600026808679104\n",
      "Epoch 495, Loss: 0.017089179484173656, Final Batch Loss: 0.008867213502526283\n",
      "Epoch 496, Loss: 0.009461589914280921, Final Batch Loss: 0.0006498750881291926\n",
      "Epoch 497, Loss: 0.023194291978143156, Final Batch Loss: 0.0011418600333854556\n",
      "Epoch 498, Loss: 0.03471193159930408, Final Batch Loss: 0.016099685803055763\n",
      "Epoch 499, Loss: 0.04540911945514381, Final Batch Loss: 0.03597867861390114\n",
      "Epoch 500, Loss: 0.02661836997140199, Final Batch Loss: 0.018801836296916008\n",
      "Epoch 501, Loss: 0.017273483565077186, Final Batch Loss: 0.0030148341320455074\n",
      "Epoch 502, Loss: 0.005825016763992608, Final Batch Loss: 0.0023936103098094463\n",
      "Epoch 503, Loss: 0.024297798285260797, Final Batch Loss: 0.0028724849689751863\n",
      "Epoch 504, Loss: 0.024711212143301964, Final Batch Loss: 0.01562773436307907\n",
      "Epoch 505, Loss: 0.011509368661791086, Final Batch Loss: 0.006219749338924885\n",
      "Epoch 506, Loss: 0.0166433536214754, Final Batch Loss: 0.0018702425295487046\n",
      "Epoch 507, Loss: 0.022344033932313323, Final Batch Loss: 0.0029640852008014917\n",
      "Epoch 508, Loss: 0.0386253948090598, Final Batch Loss: 0.0013115395558997989\n",
      "Epoch 509, Loss: 0.0071820057346485555, Final Batch Loss: 0.0007602578843943775\n",
      "Epoch 510, Loss: 0.019815934589132667, Final Batch Loss: 0.012178494594991207\n",
      "Epoch 511, Loss: 0.007800114108249545, Final Batch Loss: 0.002016659127548337\n",
      "Epoch 512, Loss: 0.018542025587521493, Final Batch Loss: 0.001498664147220552\n",
      "Epoch 513, Loss: 0.008126355824060738, Final Batch Loss: 0.0018279155483469367\n",
      "Epoch 514, Loss: 0.009501723805442452, Final Batch Loss: 0.0031454479321837425\n",
      "Epoch 515, Loss: 0.0046136597520671785, Final Batch Loss: 0.0005429722368717194\n",
      "Epoch 516, Loss: 0.013560695573687553, Final Batch Loss: 0.008954550139605999\n",
      "Epoch 517, Loss: 0.02062564145307988, Final Batch Loss: 0.00211471994407475\n",
      "Epoch 518, Loss: 0.009414088330231607, Final Batch Loss: 0.0012773772468790412\n",
      "Epoch 519, Loss: 0.019902706379070878, Final Batch Loss: 0.004566343501210213\n",
      "Epoch 520, Loss: 0.02066298248246312, Final Batch Loss: 0.004329083487391472\n",
      "Epoch 521, Loss: 0.03187969978898764, Final Batch Loss: 0.0018398005049675703\n",
      "Epoch 522, Loss: 0.008618495892733335, Final Batch Loss: 0.0014331017155200243\n",
      "Epoch 523, Loss: 0.020397086424054578, Final Batch Loss: 0.00045690572005696595\n",
      "Epoch 524, Loss: 0.062427223776467144, Final Batch Loss: 0.0387784019112587\n",
      "Epoch 525, Loss: 0.023740721167996526, Final Batch Loss: 0.01667494885623455\n",
      "Epoch 526, Loss: 0.006580484216101468, Final Batch Loss: 0.00163834763225168\n",
      "Epoch 527, Loss: 0.011137917288579047, Final Batch Loss: 0.007532426156103611\n",
      "Epoch 528, Loss: 0.005856800475157797, Final Batch Loss: 0.0029445220716297626\n",
      "Epoch 529, Loss: 0.03165001864545047, Final Batch Loss: 0.0013377119321376085\n",
      "Epoch 530, Loss: 0.02624563197605312, Final Batch Loss: 0.020173123106360435\n",
      "Epoch 531, Loss: 0.060031563974916935, Final Batch Loss: 0.02721121534705162\n",
      "Epoch 532, Loss: 0.024978406028822064, Final Batch Loss: 0.0035471348091959953\n",
      "Epoch 533, Loss: 0.012106969952583313, Final Batch Loss: 0.002938863355666399\n",
      "Epoch 534, Loss: 0.00951178022660315, Final Batch Loss: 0.0012629216071218252\n",
      "Epoch 535, Loss: 0.023804298834875226, Final Batch Loss: 0.020496424287557602\n",
      "Epoch 536, Loss: 0.01005305617582053, Final Batch Loss: 0.0013589883456006646\n",
      "Epoch 537, Loss: 0.01052929984871298, Final Batch Loss: 0.0009855489479377866\n",
      "Epoch 538, Loss: 0.00880786805646494, Final Batch Loss: 0.0008399836369790137\n",
      "Epoch 539, Loss: 0.019090486224740744, Final Batch Loss: 0.004981459584087133\n",
      "Epoch 540, Loss: 0.03180061426246539, Final Batch Loss: 0.0005743827787227929\n",
      "Epoch 541, Loss: 0.015873455617111176, Final Batch Loss: 0.0007044914527796209\n",
      "Epoch 542, Loss: 0.0075726795475929976, Final Batch Loss: 0.0008061870466917753\n",
      "Epoch 543, Loss: 0.006355079123750329, Final Batch Loss: 0.0012884004972875118\n",
      "Epoch 544, Loss: 0.006005731993354857, Final Batch Loss: 0.002836050232872367\n",
      "Epoch 545, Loss: 0.01612342067528516, Final Batch Loss: 0.010809715837240219\n",
      "Epoch 546, Loss: 0.008722350932657719, Final Batch Loss: 0.001919241389259696\n",
      "Epoch 547, Loss: 0.01161989860702306, Final Batch Loss: 0.002831686520949006\n",
      "Epoch 548, Loss: 0.010976161225698888, Final Batch Loss: 0.0008403643732890487\n",
      "Epoch 549, Loss: 0.019148038234561682, Final Batch Loss: 0.0011061017867177725\n",
      "Epoch 550, Loss: 0.008659889383125119, Final Batch Loss: 0.00023599380801897496\n",
      "Epoch 551, Loss: 0.013153582520317286, Final Batch Loss: 0.0006513562402687967\n",
      "Epoch 552, Loss: 0.011887648492120206, Final Batch Loss: 0.003129915101453662\n",
      "Epoch 553, Loss: 0.025035066762939095, Final Batch Loss: 0.021692808717489243\n",
      "Epoch 554, Loss: 0.025346225884277374, Final Batch Loss: 0.021964434534311295\n",
      "Epoch 555, Loss: 0.0037331637577153742, Final Batch Loss: 0.000534693943336606\n",
      "Epoch 556, Loss: 0.014058575150556862, Final Batch Loss: 0.0009364212164655328\n",
      "Epoch 557, Loss: 0.021391869755461812, Final Batch Loss: 0.002637089230120182\n",
      "Epoch 558, Loss: 0.02736645028926432, Final Batch Loss: 0.0029141169507056475\n",
      "Epoch 559, Loss: 0.027589619741775095, Final Batch Loss: 0.0009600945049896836\n",
      "Epoch 560, Loss: 0.005970254977000877, Final Batch Loss: 0.004683748818933964\n",
      "Epoch 561, Loss: 0.007912501518148929, Final Batch Loss: 0.00035650195786729455\n",
      "Epoch 562, Loss: 0.006620732514420524, Final Batch Loss: 0.0003698616346810013\n",
      "Epoch 563, Loss: 0.04020300041884184, Final Batch Loss: 0.03029261715710163\n",
      "Epoch 564, Loss: 0.016075060237199068, Final Batch Loss: 0.0021356146316975355\n",
      "Epoch 565, Loss: 0.03402724943589419, Final Batch Loss: 0.014677056111395359\n",
      "Epoch 566, Loss: 0.036353544099256396, Final Batch Loss: 0.002229616278782487\n",
      "Epoch 567, Loss: 0.05850422161165625, Final Batch Loss: 0.04627952724695206\n",
      "Epoch 568, Loss: 0.018670388963073492, Final Batch Loss: 0.0011028561275452375\n",
      "Epoch 569, Loss: 0.013565146829932928, Final Batch Loss: 0.004901891574263573\n",
      "Epoch 570, Loss: 0.012859576614573598, Final Batch Loss: 0.0034653740003705025\n",
      "Epoch 571, Loss: 0.008073084172792733, Final Batch Loss: 0.004149294923990965\n",
      "Epoch 572, Loss: 0.01574126281775534, Final Batch Loss: 0.0036368584260344505\n",
      "Epoch 573, Loss: 0.01814918522723019, Final Batch Loss: 0.0019582754466682673\n",
      "Epoch 574, Loss: 0.006451667984947562, Final Batch Loss: 0.001895297784358263\n",
      "Epoch 575, Loss: 0.01174654217902571, Final Batch Loss: 0.0015536543214693666\n",
      "Epoch 576, Loss: 0.030135470093227923, Final Batch Loss: 0.0026297152508050203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577, Loss: 0.026388695696368814, Final Batch Loss: 0.012197651900351048\n",
      "Epoch 578, Loss: 0.03220206731930375, Final Batch Loss: 0.027761731296777725\n",
      "Epoch 579, Loss: 0.020453936595004052, Final Batch Loss: 0.0003527977387420833\n",
      "Epoch 580, Loss: 0.011955439113080502, Final Batch Loss: 0.0032580960541963577\n",
      "Epoch 581, Loss: 0.006151934619992971, Final Batch Loss: 0.0008275398286059499\n",
      "Epoch 582, Loss: 0.017833341378718615, Final Batch Loss: 0.002082556951791048\n",
      "Epoch 583, Loss: 0.008990562055259943, Final Batch Loss: 0.0034728210885077715\n",
      "Epoch 584, Loss: 0.011487839045003057, Final Batch Loss: 0.0019215340726077557\n",
      "Epoch 585, Loss: 0.02741388970753178, Final Batch Loss: 0.024503815919160843\n",
      "Epoch 586, Loss: 0.01495173026341945, Final Batch Loss: 0.011981230229139328\n",
      "Epoch 587, Loss: 0.006239133479539305, Final Batch Loss: 0.0015619678888469934\n",
      "Epoch 588, Loss: 0.01734652853338048, Final Batch Loss: 0.012852786108851433\n",
      "Epoch 589, Loss: 0.033767250715754926, Final Batch Loss: 0.028709374368190765\n",
      "Epoch 590, Loss: 0.020831044763326645, Final Batch Loss: 0.012618505395948887\n",
      "Epoch 591, Loss: 0.007232288829982281, Final Batch Loss: 0.002205407479777932\n",
      "Epoch 592, Loss: 0.015266868402250111, Final Batch Loss: 0.0012248362181708217\n",
      "Epoch 593, Loss: 0.03986386815086007, Final Batch Loss: 0.019389387220144272\n",
      "Epoch 594, Loss: 0.008909520111046731, Final Batch Loss: 0.003629569197073579\n",
      "Epoch 595, Loss: 0.024363792268559337, Final Batch Loss: 0.0014374495949596167\n",
      "Epoch 596, Loss: 0.04957401368301362, Final Batch Loss: 0.0015221786452457309\n",
      "Epoch 597, Loss: 0.009306386345997453, Final Batch Loss: 0.005394951440393925\n",
      "Epoch 598, Loss: 0.048825820442289114, Final Batch Loss: 0.0013922726502642035\n",
      "Epoch 599, Loss: 0.01663353038020432, Final Batch Loss: 0.005494352430105209\n",
      "Epoch 600, Loss: 0.03136636543786153, Final Batch Loss: 0.015944162383675575\n",
      "Epoch 601, Loss: 0.016479295678436756, Final Batch Loss: 0.00131292047444731\n",
      "Epoch 602, Loss: 0.007925715064629912, Final Batch Loss: 0.001275411224924028\n",
      "Epoch 603, Loss: 0.016973715974017978, Final Batch Loss: 0.00560208922252059\n",
      "Epoch 604, Loss: 0.005689746263669804, Final Batch Loss: 0.00037377772969193757\n",
      "Epoch 605, Loss: 0.007766785798594356, Final Batch Loss: 0.0018869786290451884\n",
      "Epoch 606, Loss: 0.009299126104451716, Final Batch Loss: 0.001831305562518537\n",
      "Epoch 607, Loss: 0.006469661369919777, Final Batch Loss: 0.0015569004463031888\n",
      "Epoch 608, Loss: 0.00569456082303077, Final Batch Loss: 0.0005424319533631206\n",
      "Epoch 609, Loss: 0.010008754557929933, Final Batch Loss: 0.000855041784234345\n",
      "Epoch 610, Loss: 0.022724617621861398, Final Batch Loss: 0.0006920449668541551\n",
      "Epoch 611, Loss: 0.0054337853798642755, Final Batch Loss: 0.003034795168787241\n",
      "Epoch 612, Loss: 0.007718886772636324, Final Batch Loss: 0.0008508111932314932\n",
      "Epoch 613, Loss: 0.021636205492541194, Final Batch Loss: 0.004191431682556868\n",
      "Epoch 614, Loss: 0.019480129063595086, Final Batch Loss: 0.005917441099882126\n",
      "Epoch 615, Loss: 0.015796270687133074, Final Batch Loss: 0.0009868736378848553\n",
      "Epoch 616, Loss: 0.005603614845313132, Final Batch Loss: 0.0020919470116496086\n",
      "Epoch 617, Loss: 0.021735704271122813, Final Batch Loss: 0.0022278681863099337\n",
      "Epoch 618, Loss: 0.014040963724255562, Final Batch Loss: 0.0025456075090914965\n",
      "Epoch 619, Loss: 0.015972436405718327, Final Batch Loss: 0.004818961024284363\n",
      "Epoch 620, Loss: 0.008312859223224223, Final Batch Loss: 0.0028519530314952135\n",
      "Epoch 621, Loss: 0.022141601075418293, Final Batch Loss: 0.011724666692316532\n",
      "Epoch 622, Loss: 0.008671236922964454, Final Batch Loss: 0.003452790668234229\n",
      "Epoch 623, Loss: 0.015724826836958528, Final Batch Loss: 0.009735234081745148\n",
      "Epoch 624, Loss: 0.02681927871890366, Final Batch Loss: 0.012398763559758663\n",
      "Epoch 625, Loss: 0.005464278190629557, Final Batch Loss: 0.0003016617556568235\n",
      "Epoch 626, Loss: 0.007422410883009434, Final Batch Loss: 0.0004686934407800436\n",
      "Epoch 627, Loss: 0.010062210378237069, Final Batch Loss: 0.0067144338972866535\n",
      "Epoch 628, Loss: 0.004007807379821315, Final Batch Loss: 0.0003744226705748588\n",
      "Epoch 629, Loss: 0.005024424259318039, Final Batch Loss: 0.00044014197192154825\n",
      "Epoch 630, Loss: 0.02004363649757579, Final Batch Loss: 0.0005704599316231906\n",
      "Epoch 631, Loss: 0.0034866995410993695, Final Batch Loss: 0.0011932410998269916\n",
      "Epoch 632, Loss: 0.011565032531507313, Final Batch Loss: 0.001739837578497827\n",
      "Epoch 633, Loss: 0.010106368688866496, Final Batch Loss: 0.004200587514787912\n",
      "Epoch 634, Loss: 0.01610179978888482, Final Batch Loss: 0.0009457356063649058\n",
      "Epoch 635, Loss: 0.02114242920652032, Final Batch Loss: 0.010226882062852383\n",
      "Epoch 636, Loss: 0.016577563248574734, Final Batch Loss: 0.004461888689547777\n",
      "Epoch 637, Loss: 0.007005098159424961, Final Batch Loss: 0.0019217567751184106\n",
      "Epoch 638, Loss: 0.006902890745550394, Final Batch Loss: 0.0005992770893499255\n",
      "Epoch 639, Loss: 0.03333295718766749, Final Batch Loss: 0.0274965837597847\n",
      "Epoch 640, Loss: 0.03326686786022037, Final Batch Loss: 0.0014667840441688895\n",
      "Epoch 641, Loss: 0.01677187019959092, Final Batch Loss: 0.0031716555822640657\n",
      "Epoch 642, Loss: 0.02621500543318689, Final Batch Loss: 0.00348970596678555\n",
      "Epoch 643, Loss: 0.029857039800845087, Final Batch Loss: 0.0011449636658653617\n",
      "Epoch 644, Loss: 0.011858296114951372, Final Batch Loss: 0.0019926787354052067\n",
      "Epoch 645, Loss: 0.02004788164049387, Final Batch Loss: 0.01196297723799944\n",
      "Epoch 646, Loss: 0.015196322929114103, Final Batch Loss: 0.00993405468761921\n",
      "Epoch 647, Loss: 0.04482207680121064, Final Batch Loss: 0.04085836187005043\n",
      "Epoch 648, Loss: 0.00593254913110286, Final Batch Loss: 0.002341556828469038\n",
      "Epoch 649, Loss: 0.007625632802955806, Final Batch Loss: 0.0008811833104118705\n",
      "Epoch 650, Loss: 0.004299218417145312, Final Batch Loss: 0.0005542462458834052\n",
      "Epoch 651, Loss: 0.04046538280090317, Final Batch Loss: 0.0005495920195244253\n",
      "Epoch 652, Loss: 0.007673278101719916, Final Batch Loss: 0.003665330819785595\n",
      "Epoch 653, Loss: 0.01724288589321077, Final Batch Loss: 0.003410294884815812\n",
      "Epoch 654, Loss: 0.018142596469260752, Final Batch Loss: 0.00132849405054003\n",
      "Epoch 655, Loss: 0.016718005761504173, Final Batch Loss: 0.0034619553480297327\n",
      "Epoch 656, Loss: 0.016419331775978208, Final Batch Loss: 0.00133659434504807\n",
      "Epoch 657, Loss: 0.022456591250374913, Final Batch Loss: 0.0020592957735061646\n",
      "Epoch 658, Loss: 0.021307891176547855, Final Batch Loss: 0.0012909522047266364\n",
      "Epoch 659, Loss: 0.005286254920065403, Final Batch Loss: 0.001785064348950982\n",
      "Epoch 660, Loss: 0.0050753881223499775, Final Batch Loss: 0.00211121141910553\n",
      "Epoch 661, Loss: 0.032310937880538404, Final Batch Loss: 0.001564436941407621\n",
      "Epoch 662, Loss: 0.004013315308839083, Final Batch Loss: 0.0012095606653019786\n",
      "Epoch 663, Loss: 0.036578627419658005, Final Batch Loss: 0.0007472328143194318\n",
      "Epoch 664, Loss: 0.011679848481435329, Final Batch Loss: 0.0032891822047531605\n",
      "Epoch 665, Loss: 0.011045295046642423, Final Batch Loss: 0.0016519587952643633\n",
      "Epoch 666, Loss: 0.004946808097884059, Final Batch Loss: 0.0026455954648554325\n",
      "Epoch 667, Loss: 0.006705417879857123, Final Batch Loss: 0.0025372342206537724\n",
      "Epoch 668, Loss: 0.006064494431484491, Final Batch Loss: 0.0030735209584236145\n",
      "Epoch 669, Loss: 0.0023957600933499634, Final Batch Loss: 0.0010653311619535089\n",
      "Epoch 670, Loss: 0.032154581567738205, Final Batch Loss: 0.0006957449368201196\n",
      "Epoch 671, Loss: 0.0066734375432133675, Final Batch Loss: 0.0021031429059803486\n",
      "Epoch 672, Loss: 0.021679277764633298, Final Batch Loss: 0.007479577790945768\n",
      "Epoch 673, Loss: 0.007989221485331655, Final Batch Loss: 0.0008075602818280458\n",
      "Epoch 674, Loss: 0.003489241295028478, Final Batch Loss: 0.0006148286047391593\n",
      "Epoch 675, Loss: 0.00994781288318336, Final Batch Loss: 0.0024626811500638723\n",
      "Epoch 676, Loss: 0.009899287426378578, Final Batch Loss: 0.0009519950835965574\n",
      "Epoch 677, Loss: 0.02031354163773358, Final Batch Loss: 0.0037368545308709145\n",
      "Epoch 678, Loss: 0.0060414159670472145, Final Batch Loss: 0.0022614344488829374\n",
      "Epoch 679, Loss: 0.032300296472385526, Final Batch Loss: 0.017535023391246796\n",
      "Epoch 680, Loss: 0.046508612285833806, Final Batch Loss: 0.03537815064191818\n",
      "Epoch 681, Loss: 0.010950746713206172, Final Batch Loss: 0.00506200734525919\n",
      "Epoch 682, Loss: 0.008327123650815338, Final Batch Loss: 0.000637036981061101\n",
      "Epoch 683, Loss: 0.011966633494012058, Final Batch Loss: 0.001345740514807403\n",
      "Epoch 684, Loss: 0.00642375263851136, Final Batch Loss: 0.0008097955724224448\n",
      "Epoch 685, Loss: 0.022173759061843157, Final Batch Loss: 0.0012005456956103444\n",
      "Epoch 686, Loss: 0.0061260093934834, Final Batch Loss: 0.0010929872514680028\n",
      "Epoch 687, Loss: 0.022884482517838478, Final Batch Loss: 0.02050420455634594\n",
      "Epoch 688, Loss: 0.0018243075755890459, Final Batch Loss: 0.00040268790326081216\n",
      "Epoch 689, Loss: 0.007597043993882835, Final Batch Loss: 0.0049344501458108425\n",
      "Epoch 690, Loss: 0.04098527261521667, Final Batch Loss: 0.013566827401518822\n",
      "Epoch 691, Loss: 0.03662324763718061, Final Batch Loss: 0.00048514289665035903\n",
      "Epoch 692, Loss: 0.006425277213566005, Final Batch Loss: 0.004671748261898756\n",
      "Epoch 693, Loss: 0.009487319504842162, Final Batch Loss: 0.0042093535885214806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694, Loss: 0.005469644034747034, Final Batch Loss: 0.0006736144423484802\n",
      "Epoch 695, Loss: 0.022784094529924914, Final Batch Loss: 0.0004605647118296474\n",
      "Epoch 696, Loss: 0.02406708849593997, Final Batch Loss: 0.019485589116811752\n",
      "Epoch 697, Loss: 0.007680142647586763, Final Batch Loss: 0.0016970948781818151\n",
      "Epoch 698, Loss: 0.015143606578931212, Final Batch Loss: 0.007504051085561514\n",
      "Epoch 699, Loss: 0.0039809177978895605, Final Batch Loss: 0.0022072489373385906\n",
      "Epoch 700, Loss: 0.01731112354900688, Final Batch Loss: 0.0010598424123600125\n",
      "Epoch 701, Loss: 0.013262948137708008, Final Batch Loss: 0.007712306920439005\n",
      "Epoch 702, Loss: 0.008300452609546483, Final Batch Loss: 0.0037548004183918238\n",
      "Epoch 703, Loss: 0.018760588951408863, Final Batch Loss: 0.007093052379786968\n",
      "Epoch 704, Loss: 0.017890854098368436, Final Batch Loss: 0.0008624964975751936\n",
      "Epoch 705, Loss: 0.005197138409130275, Final Batch Loss: 0.0009780304972082376\n",
      "Epoch 706, Loss: 0.003833967144601047, Final Batch Loss: 0.0014806847320869565\n",
      "Epoch 707, Loss: 0.005384624295402318, Final Batch Loss: 0.0009509637602604926\n",
      "Epoch 708, Loss: 0.015385776408948004, Final Batch Loss: 0.0002853312762454152\n",
      "Epoch 709, Loss: 0.029886282398365438, Final Batch Loss: 0.0020842377562075853\n",
      "Epoch 710, Loss: 0.004366148146800697, Final Batch Loss: 0.0007994271581992507\n",
      "Epoch 711, Loss: 0.0036559781874530017, Final Batch Loss: 0.0005474846693687141\n",
      "Epoch 712, Loss: 0.00791195745114237, Final Batch Loss: 0.004359858576208353\n",
      "Epoch 713, Loss: 0.026437913242261857, Final Batch Loss: 0.011630411259829998\n",
      "Epoch 714, Loss: 0.01291521464008838, Final Batch Loss: 0.007939377799630165\n",
      "Epoch 715, Loss: 0.005443894595373422, Final Batch Loss: 0.0017774708103388548\n",
      "Epoch 716, Loss: 0.004462887009140104, Final Batch Loss: 0.0005821562954224646\n",
      "Epoch 717, Loss: 0.0052630287245847285, Final Batch Loss: 0.0003661772352643311\n",
      "Epoch 718, Loss: 0.007668377715162933, Final Batch Loss: 0.00394474808126688\n",
      "Epoch 719, Loss: 0.02287584364239592, Final Batch Loss: 0.0001779292506398633\n",
      "Epoch 720, Loss: 0.003251587215345353, Final Batch Loss: 0.0014220061711966991\n",
      "Epoch 721, Loss: 0.01495525153586641, Final Batch Loss: 0.00039672484854236245\n",
      "Epoch 722, Loss: 0.004507303470745683, Final Batch Loss: 0.0017609947826713324\n",
      "Epoch 723, Loss: 0.0028318141703493893, Final Batch Loss: 0.0016268419567495584\n",
      "Epoch 724, Loss: 0.020021016942337155, Final Batch Loss: 0.0023584903683513403\n",
      "Epoch 725, Loss: 0.006939536950085312, Final Batch Loss: 0.003562984522432089\n",
      "Epoch 726, Loss: 0.01147754886187613, Final Batch Loss: 0.0006033636163920164\n",
      "Epoch 727, Loss: 0.011446901015006006, Final Batch Loss: 0.0008593676029704511\n",
      "Epoch 728, Loss: 0.005143102025613189, Final Batch Loss: 0.0022439213935285807\n",
      "Epoch 729, Loss: 0.005570155452005565, Final Batch Loss: 0.0009931322420015931\n",
      "Epoch 730, Loss: 0.0070323043037205935, Final Batch Loss: 0.0006620048079639673\n",
      "Epoch 731, Loss: 0.007272544899024069, Final Batch Loss: 0.0012059725122526288\n",
      "Epoch 732, Loss: 0.006573105056304485, Final Batch Loss: 0.001314015593379736\n",
      "Epoch 733, Loss: 0.004990214336430654, Final Batch Loss: 0.0003373518993612379\n",
      "Epoch 734, Loss: 0.018020640243776143, Final Batch Loss: 0.0038492518942803144\n",
      "Epoch 735, Loss: 0.003020245465449989, Final Batch Loss: 0.0014065796276554465\n",
      "Epoch 736, Loss: 0.0028319686971371993, Final Batch Loss: 0.00024122207832988352\n",
      "Epoch 737, Loss: 0.006867220159620047, Final Batch Loss: 0.004009865690022707\n",
      "Epoch 738, Loss: 0.0020708578813355416, Final Batch Loss: 0.00035600594128482044\n",
      "Epoch 739, Loss: 0.005307876941515133, Final Batch Loss: 0.001115483115427196\n",
      "Epoch 740, Loss: 0.00457587544224225, Final Batch Loss: 0.00033647791133262217\n",
      "Epoch 741, Loss: 0.003692031546961516, Final Batch Loss: 0.0014998032711446285\n",
      "Epoch 742, Loss: 0.0039025055011734366, Final Batch Loss: 0.00043180095963180065\n",
      "Epoch 743, Loss: 0.002222235023509711, Final Batch Loss: 0.00015382299898192286\n",
      "Epoch 744, Loss: 0.004174443689407781, Final Batch Loss: 0.0002743795921560377\n",
      "Epoch 745, Loss: 0.009278595738578588, Final Batch Loss: 0.003352843225002289\n",
      "Epoch 746, Loss: 0.01070714695379138, Final Batch Loss: 0.006977437995374203\n",
      "Epoch 747, Loss: 0.020622832758817822, Final Batch Loss: 0.01977412961423397\n",
      "Epoch 748, Loss: 0.002100724814226851, Final Batch Loss: 0.0004619065730366856\n",
      "Epoch 749, Loss: 0.002948550565633923, Final Batch Loss: 0.0005843128892593086\n",
      "Epoch 750, Loss: 0.010973044903948903, Final Batch Loss: 0.008235237561166286\n",
      "Epoch 751, Loss: 0.0033792570466175675, Final Batch Loss: 0.0012220852077007294\n",
      "Epoch 752, Loss: 0.015965819009579718, Final Batch Loss: 0.0017176010878756642\n",
      "Epoch 753, Loss: 0.003101492300629616, Final Batch Loss: 0.0011495263315737247\n",
      "Epoch 754, Loss: 0.02164454315789044, Final Batch Loss: 0.006286612246185541\n",
      "Epoch 755, Loss: 0.017572510696481913, Final Batch Loss: 0.00037179054925218225\n",
      "Epoch 756, Loss: 0.011610908433794975, Final Batch Loss: 0.00464176619425416\n",
      "Epoch 757, Loss: 0.00987618045473937, Final Batch Loss: 0.00014372386795002967\n",
      "Epoch 758, Loss: 0.006301043671555817, Final Batch Loss: 0.003837605705484748\n",
      "Epoch 759, Loss: 0.0025308317854069173, Final Batch Loss: 0.00021982734324410558\n",
      "Epoch 760, Loss: 0.01487445883685723, Final Batch Loss: 0.01193608995527029\n",
      "Epoch 761, Loss: 0.044288220815360546, Final Batch Loss: 0.005003352649509907\n",
      "Epoch 762, Loss: 0.024405492935329676, Final Batch Loss: 0.02066744491457939\n",
      "Epoch 763, Loss: 0.019797011525952257, Final Batch Loss: 0.0001771948445821181\n",
      "Epoch 764, Loss: 0.004230213613482192, Final Batch Loss: 0.00046711144386790693\n",
      "Epoch 765, Loss: 0.004053812241181731, Final Batch Loss: 0.000602785381488502\n",
      "Epoch 766, Loss: 0.008031606208533049, Final Batch Loss: 0.006170578766614199\n",
      "Epoch 767, Loss: 0.008450443448964506, Final Batch Loss: 0.0019415892893448472\n",
      "Epoch 768, Loss: 0.013626961503177881, Final Batch Loss: 0.003260416444391012\n",
      "Epoch 769, Loss: 0.011383553530322388, Final Batch Loss: 0.0003453125827945769\n",
      "Epoch 770, Loss: 0.003630113147664815, Final Batch Loss: 0.00029259693110361695\n",
      "Epoch 771, Loss: 0.0036505427851807326, Final Batch Loss: 0.0003942322509828955\n",
      "Epoch 772, Loss: 0.012688667513430119, Final Batch Loss: 0.0006988173117861152\n",
      "Epoch 773, Loss: 0.001495865872129798, Final Batch Loss: 0.0005960792768746614\n",
      "Epoch 774, Loss: 0.0024977534485515207, Final Batch Loss: 0.0004446623206604272\n",
      "Epoch 775, Loss: 0.005102006602101028, Final Batch Loss: 0.0006526311626657844\n",
      "Epoch 776, Loss: 0.008630383556010202, Final Batch Loss: 0.00033471008646301925\n",
      "Epoch 777, Loss: 0.011649157560896128, Final Batch Loss: 0.00027460575802251697\n",
      "Epoch 778, Loss: 0.008722346974536777, Final Batch Loss: 0.001042418647557497\n",
      "Epoch 779, Loss: 0.024837664619553834, Final Batch Loss: 0.000579447892960161\n",
      "Epoch 780, Loss: 0.011952764994930476, Final Batch Loss: 0.009333410300314426\n",
      "Epoch 781, Loss: 0.0023706444771960378, Final Batch Loss: 0.0008555303211323917\n",
      "Epoch 782, Loss: 0.007580068428069353, Final Batch Loss: 0.0020232752431184053\n",
      "Epoch 783, Loss: 0.002399238495854661, Final Batch Loss: 0.00038207959732972085\n",
      "Epoch 784, Loss: 0.030294903204776347, Final Batch Loss: 0.027906229719519615\n",
      "Epoch 785, Loss: 0.04850720672402531, Final Batch Loss: 0.04486262425780296\n",
      "Epoch 786, Loss: 0.004155837174039334, Final Batch Loss: 0.001746293157339096\n",
      "Epoch 787, Loss: 0.009185493807308376, Final Batch Loss: 0.004278452135622501\n",
      "Epoch 788, Loss: 0.050262656062841415, Final Batch Loss: 0.027973126620054245\n",
      "Epoch 789, Loss: 0.01027349999640137, Final Batch Loss: 0.006291800644248724\n",
      "Epoch 790, Loss: 0.002294220816111192, Final Batch Loss: 0.00015349462046287954\n",
      "Epoch 791, Loss: 0.00912273908033967, Final Batch Loss: 0.004957406781613827\n",
      "Epoch 792, Loss: 0.049272448086412624, Final Batch Loss: 0.0004591993347276002\n",
      "Epoch 793, Loss: 0.03291922475909814, Final Batch Loss: 0.012206044048070908\n",
      "Epoch 794, Loss: 0.0023662133316975087, Final Batch Loss: 0.00021375162759795785\n",
      "Epoch 795, Loss: 0.007095166976796463, Final Batch Loss: 0.0003699112276080996\n",
      "Epoch 796, Loss: 0.044383751577697694, Final Batch Loss: 0.0007719650166109204\n",
      "Epoch 797, Loss: 0.01028602328733541, Final Batch Loss: 0.0003917470166925341\n",
      "Epoch 798, Loss: 0.0040551977581344545, Final Batch Loss: 0.0031406565103679895\n",
      "Epoch 799, Loss: 0.005556832882575691, Final Batch Loss: 0.001810891437344253\n",
      "Epoch 800, Loss: 0.002354409487452358, Final Batch Loss: 0.0005174935213290155\n",
      "Epoch 801, Loss: 0.017512341728433967, Final Batch Loss: 0.002111325738951564\n",
      "Epoch 802, Loss: 0.003550935274688527, Final Batch Loss: 0.0017290309770032763\n",
      "Epoch 803, Loss: 0.006465726182796061, Final Batch Loss: 0.0021446826867759228\n",
      "Epoch 804, Loss: 0.0036242551868781447, Final Batch Loss: 0.0013661155244335532\n",
      "Epoch 805, Loss: 0.005531779839657247, Final Batch Loss: 0.0015735523775219917\n",
      "Epoch 806, Loss: 0.023312597768381238, Final Batch Loss: 0.007378888316452503\n",
      "Epoch 807, Loss: 0.004082980041857809, Final Batch Loss: 0.0007813370903022587\n",
      "Epoch 808, Loss: 0.008524696750100702, Final Batch Loss: 0.00028159754583612084\n",
      "Epoch 809, Loss: 0.006205503537785262, Final Batch Loss: 0.0028287305030971766\n",
      "Epoch 810, Loss: 0.001990680262679234, Final Batch Loss: 0.0003223719832021743\n",
      "Epoch 811, Loss: 0.0030594596173614264, Final Batch Loss: 0.0006256236811168492\n",
      "Epoch 812, Loss: 0.004794256470631808, Final Batch Loss: 0.0008837963105179369\n",
      "Epoch 813, Loss: 0.004635255900211632, Final Batch Loss: 0.0016827475046738982\n",
      "Epoch 814, Loss: 0.03527989520080155, Final Batch Loss: 9.410143684362993e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 815, Loss: 0.01685646126861684, Final Batch Loss: 0.0004073620948474854\n",
      "Epoch 816, Loss: 0.003269633511081338, Final Batch Loss: 0.0005698055028915405\n",
      "Epoch 817, Loss: 0.00648699383600615, Final Batch Loss: 0.0006590175908058882\n",
      "Epoch 818, Loss: 0.005346893041860312, Final Batch Loss: 0.0015215363819152117\n",
      "Epoch 819, Loss: 0.003709698445163667, Final Batch Loss: 0.0007944896351546049\n",
      "Epoch 820, Loss: 0.0041737866995390505, Final Batch Loss: 0.00025782090961001813\n",
      "Epoch 821, Loss: 0.01037864459794946, Final Batch Loss: 0.00043748694588430226\n",
      "Epoch 822, Loss: 0.006537721128552221, Final Batch Loss: 7.656308298464864e-05\n",
      "Epoch 823, Loss: 0.00599440596124623, Final Batch Loss: 0.00023768162645865232\n",
      "Epoch 824, Loss: 0.004742928569612559, Final Batch Loss: 0.00012043528113281354\n",
      "Epoch 825, Loss: 0.004462373210117221, Final Batch Loss: 0.002595139667391777\n",
      "Epoch 826, Loss: 0.0029909436125308275, Final Batch Loss: 0.0016004922799766064\n",
      "Epoch 827, Loss: 0.001402403722750023, Final Batch Loss: 0.00021774994092993438\n",
      "Epoch 828, Loss: 0.0033118274877779186, Final Batch Loss: 0.00043435400584712625\n",
      "Epoch 829, Loss: 0.006586734787560999, Final Batch Loss: 0.004833281971514225\n",
      "Epoch 830, Loss: 0.003496410441584885, Final Batch Loss: 0.0017006247071549296\n",
      "Epoch 831, Loss: 0.00655992137035355, Final Batch Loss: 0.0005980145069770515\n",
      "Epoch 832, Loss: 0.011330901776091196, Final Batch Loss: 0.00020614256209228188\n",
      "Epoch 833, Loss: 0.008853096624079626, Final Batch Loss: 0.00010260260751238093\n",
      "Epoch 834, Loss: 0.0019976414478151128, Final Batch Loss: 0.0006246403208933771\n",
      "Epoch 835, Loss: 0.006467470957431942, Final Batch Loss: 0.005562894511967897\n",
      "Epoch 836, Loss: 0.017904993146657944, Final Batch Loss: 0.0033283191733062267\n",
      "Epoch 837, Loss: 0.006230940227396786, Final Batch Loss: 0.0006783327553421259\n",
      "Epoch 838, Loss: 0.0038683628663420677, Final Batch Loss: 0.0007943742675706744\n",
      "Epoch 839, Loss: 0.007517553691286594, Final Batch Loss: 0.000128457963000983\n",
      "Epoch 840, Loss: 0.040944573760498315, Final Batch Loss: 0.03367607668042183\n",
      "Epoch 841, Loss: 0.017414627713151276, Final Batch Loss: 0.008618354797363281\n",
      "Epoch 842, Loss: 0.032511540688574314, Final Batch Loss: 0.02015012875199318\n",
      "Epoch 843, Loss: 0.01431308314204216, Final Batch Loss: 0.00825855415314436\n",
      "Epoch 844, Loss: 0.011597953853197396, Final Batch Loss: 0.009550402872264385\n",
      "Epoch 845, Loss: 0.008329176518600434, Final Batch Loss: 0.00035731546813622117\n",
      "Epoch 846, Loss: 0.005342351563740522, Final Batch Loss: 0.0004905182286165655\n",
      "Epoch 847, Loss: 0.01686367191723548, Final Batch Loss: 0.00045274425065144897\n",
      "Epoch 848, Loss: 0.014179575722664595, Final Batch Loss: 0.0037895948626101017\n",
      "Epoch 849, Loss: 0.06046824622899294, Final Batch Loss: 0.014648031443357468\n",
      "Epoch 850, Loss: 0.005616513546556234, Final Batch Loss: 0.0016897330060601234\n",
      "Epoch 851, Loss: 0.019965031766332686, Final Batch Loss: 0.002006229944527149\n",
      "Epoch 852, Loss: 0.0016366572817787528, Final Batch Loss: 0.0005653724074363708\n",
      "Epoch 853, Loss: 0.0035735610290430486, Final Batch Loss: 0.0006369585753418505\n",
      "Epoch 854, Loss: 0.005078998277895153, Final Batch Loss: 0.0007145404815673828\n",
      "Epoch 855, Loss: 0.051937316078692675, Final Batch Loss: 0.03897581249475479\n",
      "Epoch 856, Loss: 0.009062071330845356, Final Batch Loss: 0.005658891052007675\n",
      "Epoch 857, Loss: 0.01140519161708653, Final Batch Loss: 0.0007696566171944141\n",
      "Epoch 858, Loss: 0.011345046805217862, Final Batch Loss: 0.0011046312283724546\n",
      "Epoch 859, Loss: 0.016869423765456304, Final Batch Loss: 0.0009573048446327448\n",
      "Epoch 860, Loss: 0.012280167720746249, Final Batch Loss: 0.0009498947183601558\n",
      "Epoch 861, Loss: 0.011251406744122505, Final Batch Loss: 0.0035847260151058435\n",
      "Epoch 862, Loss: 0.008023037109524012, Final Batch Loss: 0.002577150473371148\n",
      "Epoch 863, Loss: 0.003843085200060159, Final Batch Loss: 0.0010002698982134461\n",
      "Epoch 864, Loss: 0.007458754349499941, Final Batch Loss: 0.0004876117454841733\n",
      "Epoch 865, Loss: 0.0037672121543437243, Final Batch Loss: 0.0019365729531273246\n",
      "Epoch 866, Loss: 0.005495195247931406, Final Batch Loss: 0.0022403302136808634\n",
      "Epoch 867, Loss: 0.013225857983343303, Final Batch Loss: 0.008440482430160046\n",
      "Epoch 868, Loss: 0.00269921230210457, Final Batch Loss: 0.0005181082524359226\n",
      "Epoch 869, Loss: 0.01906382173183374, Final Batch Loss: 0.0028477127198129892\n",
      "Epoch 870, Loss: 0.01355643873102963, Final Batch Loss: 0.0047964071854949\n",
      "Epoch 871, Loss: 0.00327991577796638, Final Batch Loss: 0.0012177159078419209\n",
      "Epoch 872, Loss: 0.009520818653982133, Final Batch Loss: 0.00047642114805057645\n",
      "Epoch 873, Loss: 0.0021461794094648212, Final Batch Loss: 0.0011674248380586505\n",
      "Epoch 874, Loss: 0.011722374765668064, Final Batch Loss: 0.0007443652139045298\n",
      "Epoch 875, Loss: 0.002837606123648584, Final Batch Loss: 0.0009937867289409041\n",
      "Epoch 876, Loss: 0.002721238066442311, Final Batch Loss: 0.001785498228855431\n",
      "Epoch 877, Loss: 0.004460553784156218, Final Batch Loss: 0.0013007043162360787\n",
      "Epoch 878, Loss: 0.006970678048674017, Final Batch Loss: 0.0008534297230653465\n",
      "Epoch 879, Loss: 0.004125399951590225, Final Batch Loss: 0.0003420872089918703\n",
      "Epoch 880, Loss: 0.0035258429124951363, Final Batch Loss: 0.0012405328452587128\n",
      "Epoch 881, Loss: 0.0020890869200229645, Final Batch Loss: 0.0001757833524607122\n",
      "Epoch 882, Loss: 0.0017211990198120475, Final Batch Loss: 0.0007659476832486689\n",
      "Epoch 883, Loss: 0.0012750304595101625, Final Batch Loss: 0.00010085056419484317\n",
      "Epoch 884, Loss: 0.019400470016989857, Final Batch Loss: 0.01682330295443535\n",
      "Epoch 885, Loss: 0.00452583353035152, Final Batch Loss: 0.0019735100213438272\n",
      "Epoch 886, Loss: 0.0021425087470561266, Final Batch Loss: 0.0011090182233601809\n",
      "Epoch 887, Loss: 0.0026890400622505695, Final Batch Loss: 0.0017497516237199306\n",
      "Epoch 888, Loss: 0.008597649401053786, Final Batch Loss: 0.004768310114741325\n",
      "Epoch 889, Loss: 0.026397269626613706, Final Batch Loss: 0.0007509407005272806\n",
      "Epoch 890, Loss: 0.005071917199529707, Final Batch Loss: 0.0025767346378415823\n",
      "Epoch 891, Loss: 0.0011993969965260476, Final Batch Loss: 0.0003761975676752627\n",
      "Epoch 892, Loss: 0.020628026104532182, Final Batch Loss: 0.0024234887678176165\n",
      "Epoch 893, Loss: 0.0021004469599574804, Final Batch Loss: 0.0005759902414865792\n",
      "Epoch 894, Loss: 0.0021455500391311944, Final Batch Loss: 0.000544880167581141\n",
      "Epoch 895, Loss: 0.011858038720674813, Final Batch Loss: 0.00023293029516935349\n",
      "Epoch 896, Loss: 0.006448561704019085, Final Batch Loss: 0.00034801699803210795\n",
      "Epoch 897, Loss: 0.016611932427622378, Final Batch Loss: 0.0009836103999987245\n",
      "Epoch 898, Loss: 0.0101238515926525, Final Batch Loss: 0.008525167591869831\n",
      "Epoch 899, Loss: 0.0015875478857196867, Final Batch Loss: 0.0007344623445533216\n",
      "Epoch 900, Loss: 0.021585090464213863, Final Batch Loss: 0.00039311093860305846\n",
      "Epoch 901, Loss: 0.002176431065890938, Final Batch Loss: 0.0007568504079245031\n",
      "Epoch 902, Loss: 0.003721748071257025, Final Batch Loss: 0.0014879670925438404\n",
      "Epoch 903, Loss: 0.0013757336710114032, Final Batch Loss: 0.0001494196185376495\n",
      "Epoch 904, Loss: 0.0031126104877330363, Final Batch Loss: 0.0018460191786289215\n",
      "Epoch 905, Loss: 0.006731264526024461, Final Batch Loss: 0.001897252514027059\n",
      "Epoch 906, Loss: 0.0211872395593673, Final Batch Loss: 0.013305526226758957\n",
      "Epoch 907, Loss: 0.004102920240256935, Final Batch Loss: 0.0021177048329263926\n",
      "Epoch 908, Loss: 0.0019091842841589823, Final Batch Loss: 0.00012802799756173044\n",
      "Epoch 909, Loss: 0.00082597546861507, Final Batch Loss: 0.00019993280875496566\n",
      "Epoch 910, Loss: 0.001195655160699971, Final Batch Loss: 0.0006916251732036471\n",
      "Epoch 911, Loss: 0.0013020781334489584, Final Batch Loss: 0.00018162337073590606\n",
      "Epoch 912, Loss: 0.002450072846841067, Final Batch Loss: 0.000867509632371366\n",
      "Epoch 913, Loss: 0.0025934049335774034, Final Batch Loss: 0.0002963242877740413\n",
      "Epoch 914, Loss: 0.0032586231536697596, Final Batch Loss: 0.0007049650303088129\n",
      "Epoch 915, Loss: 0.011676739173708484, Final Batch Loss: 0.0031749755144119263\n",
      "Epoch 916, Loss: 0.05199879752763081, Final Batch Loss: 0.038945067673921585\n",
      "Epoch 917, Loss: 0.006948524285689928, Final Batch Loss: 0.00017927367298398167\n",
      "Epoch 918, Loss: 0.006948786380235106, Final Batch Loss: 0.0017380358185619116\n",
      "Epoch 919, Loss: 0.004271398182027042, Final Batch Loss: 0.001833736547268927\n",
      "Epoch 920, Loss: 0.003635639586718753, Final Batch Loss: 0.0018114240374416113\n",
      "Epoch 921, Loss: 0.006371401323121972, Final Batch Loss: 0.005978306755423546\n",
      "Epoch 922, Loss: 0.0006951530813239515, Final Batch Loss: 0.0001497686025686562\n",
      "Epoch 923, Loss: 0.005736429826356471, Final Batch Loss: 0.0006650504656136036\n",
      "Epoch 924, Loss: 0.016127741750096902, Final Batch Loss: 0.0003626107645686716\n",
      "Epoch 925, Loss: 0.0016690314951119944, Final Batch Loss: 0.00016777469136286527\n",
      "Epoch 926, Loss: 0.002636582823470235, Final Batch Loss: 0.000797454034909606\n",
      "Epoch 927, Loss: 0.005403188290074468, Final Batch Loss: 0.0004463810473680496\n",
      "Epoch 928, Loss: 0.008997706143418327, Final Batch Loss: 0.0001310130173806101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929, Loss: 0.0019197938381694257, Final Batch Loss: 0.0007155963685363531\n",
      "Epoch 930, Loss: 0.029705112043302506, Final Batch Loss: 0.0006733812042512\n",
      "Epoch 931, Loss: 0.012320938883931376, Final Batch Loss: 0.00012548304221127182\n",
      "Epoch 932, Loss: 0.0034083418431691825, Final Batch Loss: 0.0015280431834980845\n",
      "Epoch 933, Loss: 0.005632958112983033, Final Batch Loss: 0.0004269648634362966\n",
      "Epoch 934, Loss: 0.0030552527168765664, Final Batch Loss: 0.0005232308758422732\n",
      "Epoch 935, Loss: 0.06089192582294345, Final Batch Loss: 0.01062711887061596\n",
      "Epoch 936, Loss: 0.01580310898134485, Final Batch Loss: 0.0005367068224586546\n",
      "Epoch 937, Loss: 0.0024478551058564335, Final Batch Loss: 0.00030994132976047695\n",
      "Epoch 938, Loss: 0.011086445971159264, Final Batch Loss: 0.0002814967592712492\n",
      "Epoch 939, Loss: 0.0026527925801929086, Final Batch Loss: 0.0008812289452180266\n",
      "Epoch 940, Loss: 0.0021095806441735476, Final Batch Loss: 0.00022094303858466446\n",
      "Epoch 941, Loss: 0.002091393485898152, Final Batch Loss: 0.00017362521612085402\n",
      "Epoch 942, Loss: 0.004711968125775456, Final Batch Loss: 0.001961423084139824\n",
      "Epoch 943, Loss: 0.010047489602584392, Final Batch Loss: 0.00017621851293370128\n",
      "Epoch 944, Loss: 0.002575288526713848, Final Batch Loss: 0.0008116149692796171\n",
      "Epoch 945, Loss: 0.009304618142778054, Final Batch Loss: 0.00024888323969207704\n",
      "Epoch 946, Loss: 0.0031810411164769903, Final Batch Loss: 0.00016830414824653417\n",
      "Epoch 947, Loss: 0.005637218215269968, Final Batch Loss: 0.00023799968766979873\n",
      "Epoch 948, Loss: 0.004297011939343065, Final Batch Loss: 0.0006384461303241551\n",
      "Epoch 949, Loss: 0.004957488854415715, Final Batch Loss: 0.0007731216610409319\n",
      "Epoch 950, Loss: 0.007646736514288932, Final Batch Loss: 0.006525288335978985\n",
      "Epoch 951, Loss: 0.02569356317690108, Final Batch Loss: 0.0012771801557391882\n",
      "Epoch 952, Loss: 0.00515243667177856, Final Batch Loss: 0.003270188346505165\n",
      "Epoch 953, Loss: 0.03359647444449365, Final Batch Loss: 0.0015307519352063537\n",
      "Epoch 954, Loss: 0.0026627957122400403, Final Batch Loss: 0.000501545611768961\n",
      "Epoch 955, Loss: 0.027533695683814585, Final Batch Loss: 0.005894568748772144\n",
      "Epoch 956, Loss: 0.0034538678301032633, Final Batch Loss: 0.0009353950736112893\n",
      "Epoch 957, Loss: 0.005076287314295769, Final Batch Loss: 0.0022974838502705097\n",
      "Epoch 958, Loss: 0.05281119191204198, Final Batch Loss: 0.0372881144285202\n",
      "Epoch 959, Loss: 0.0077566534746438265, Final Batch Loss: 0.0009336368530057371\n",
      "Epoch 960, Loss: 0.005285287392325699, Final Batch Loss: 0.0007576661882922053\n",
      "Epoch 961, Loss: 0.011320152669213712, Final Batch Loss: 0.009696370922029018\n",
      "Epoch 962, Loss: 0.01701575468177907, Final Batch Loss: 0.015847641974687576\n",
      "Epoch 963, Loss: 0.010510141917620786, Final Batch Loss: 0.00016897784371394664\n",
      "Epoch 964, Loss: 0.0021074009127914906, Final Batch Loss: 0.0007431444828398526\n",
      "Epoch 965, Loss: 0.001436603080946952, Final Batch Loss: 0.0007044692756608129\n",
      "Epoch 966, Loss: 0.00119083518802654, Final Batch Loss: 0.00017709452367853373\n",
      "Epoch 967, Loss: 0.014617227192502469, Final Batch Loss: 0.0008404433610849082\n",
      "Epoch 968, Loss: 0.001998190869926475, Final Batch Loss: 0.00042734132148325443\n",
      "Epoch 969, Loss: 0.004084200190845877, Final Batch Loss: 0.001142015098594129\n",
      "Epoch 970, Loss: 0.011739582289010286, Final Batch Loss: 0.002549330936744809\n",
      "Epoch 971, Loss: 0.008011883328435943, Final Batch Loss: 0.007105193566530943\n",
      "Epoch 972, Loss: 0.0033987142523983493, Final Batch Loss: 0.00015055180119816214\n",
      "Epoch 973, Loss: 0.0021738096547778696, Final Batch Loss: 0.00033715812605805695\n",
      "Epoch 974, Loss: 0.002333587530301884, Final Batch Loss: 0.000479400681797415\n",
      "Epoch 975, Loss: 0.00808715823222883, Final Batch Loss: 0.0001732062955852598\n",
      "Epoch 976, Loss: 0.01304766401881352, Final Batch Loss: 0.011146587319672108\n",
      "Epoch 977, Loss: 0.005713639809982851, Final Batch Loss: 0.0002986650506500155\n",
      "Epoch 978, Loss: 0.002301141925272532, Final Batch Loss: 0.00023422592494171113\n",
      "Epoch 979, Loss: 0.00756672999705188, Final Batch Loss: 0.00018197399913333356\n",
      "Epoch 980, Loss: 0.015499621746130288, Final Batch Loss: 0.014259814284741879\n",
      "Epoch 981, Loss: 0.003260667552240193, Final Batch Loss: 0.0014108580071479082\n",
      "Epoch 982, Loss: 0.01005141664063558, Final Batch Loss: 0.0003268542932346463\n",
      "Epoch 983, Loss: 0.002806705917464569, Final Batch Loss: 0.0008586501353420317\n",
      "Epoch 984, Loss: 0.0013804919726680964, Final Batch Loss: 0.0005012129549868405\n",
      "Epoch 985, Loss: 0.014778804092202336, Final Batch Loss: 0.0013816809514537454\n",
      "Epoch 986, Loss: 0.01983321609441191, Final Batch Loss: 0.01834883540868759\n",
      "Epoch 987, Loss: 0.005243851686827838, Final Batch Loss: 0.0029083797708153725\n",
      "Epoch 988, Loss: 0.002202135365223512, Final Batch Loss: 0.001227094791829586\n",
      "Epoch 989, Loss: 0.0059964688116451725, Final Batch Loss: 0.00015437403635587543\n",
      "Epoch 990, Loss: 0.0038792350387666374, Final Batch Loss: 0.00035521891550160944\n",
      "Epoch 991, Loss: 0.0070485101896338165, Final Batch Loss: 0.004931656178086996\n",
      "Epoch 992, Loss: 0.011507862363941967, Final Batch Loss: 0.0016785552725195885\n",
      "Epoch 993, Loss: 0.0026112927007488906, Final Batch Loss: 0.0006237514899112284\n",
      "Epoch 994, Loss: 0.02773864532355219, Final Batch Loss: 0.000615520984865725\n",
      "Epoch 995, Loss: 0.002942536724731326, Final Batch Loss: 0.0011820157524198294\n",
      "Epoch 996, Loss: 0.04226817999733612, Final Batch Loss: 0.039458923041820526\n",
      "Epoch 997, Loss: 0.002519764209864661, Final Batch Loss: 0.00033231652923859656\n",
      "Epoch 998, Loss: 0.011689055012539029, Final Batch Loss: 0.010646742768585682\n",
      "Epoch 999, Loss: 0.0010955998877761886, Final Batch Loss: 0.00015972585242707282\n",
      "Epoch 1000, Loss: 0.006515426095575094, Final Batch Loss: 0.0009897445561364293\n",
      "Epoch 1001, Loss: 0.011058057541958988, Final Batch Loss: 0.0013404597993940115\n",
      "Epoch 1002, Loss: 0.0039521736616734415, Final Batch Loss: 0.0002746657410170883\n",
      "Epoch 1003, Loss: 0.0013438548485282809, Final Batch Loss: 0.00026946855359710753\n",
      "Epoch 1004, Loss: 0.0033382124092895538, Final Batch Loss: 0.0003464561013970524\n",
      "Epoch 1005, Loss: 0.020602896169293672, Final Batch Loss: 0.0006645465036854148\n",
      "Epoch 1006, Loss: 0.002940397331258282, Final Batch Loss: 0.00039848111919127405\n",
      "Epoch 1007, Loss: 0.005222676205448806, Final Batch Loss: 0.0006296273204497993\n",
      "Epoch 1008, Loss: 0.006954621057957411, Final Batch Loss: 0.004609731025993824\n",
      "Epoch 1009, Loss: 0.021391205256804824, Final Batch Loss: 0.01740921474993229\n",
      "Epoch 1010, Loss: 0.0027670376002788544, Final Batch Loss: 0.000563159235753119\n",
      "Epoch 1011, Loss: 0.0021122345933690667, Final Batch Loss: 0.00031883837073110044\n",
      "Epoch 1012, Loss: 0.009036986652063206, Final Batch Loss: 0.0003346070006955415\n",
      "Epoch 1013, Loss: 0.009175800805678591, Final Batch Loss: 0.006885088514536619\n",
      "Epoch 1014, Loss: 0.004203774326015264, Final Batch Loss: 0.0017065212596207857\n",
      "Epoch 1015, Loss: 0.0026274783012922853, Final Batch Loss: 0.000364167703082785\n",
      "Epoch 1016, Loss: 0.0018277563503943384, Final Batch Loss: 0.0009037073468789458\n",
      "Epoch 1017, Loss: 0.015613471739925444, Final Batch Loss: 0.005942757241427898\n",
      "Epoch 1018, Loss: 0.0012911261146655306, Final Batch Loss: 0.0001465231616748497\n",
      "Epoch 1019, Loss: 0.005593953974312171, Final Batch Loss: 0.00030403034179471433\n",
      "Epoch 1020, Loss: 0.0011993747029919177, Final Batch Loss: 0.0004300015280023217\n",
      "Epoch 1021, Loss: 0.0019501528731780127, Final Batch Loss: 5.023299308959395e-05\n",
      "Epoch 1022, Loss: 0.007969807891640812, Final Batch Loss: 0.0004236320382915437\n",
      "Epoch 1023, Loss: 0.011552166077308357, Final Batch Loss: 0.006649143528193235\n",
      "Epoch 1024, Loss: 0.003988632699474692, Final Batch Loss: 0.0013892098795622587\n",
      "Epoch 1025, Loss: 0.0017368252156302333, Final Batch Loss: 0.000326693058013916\n",
      "Epoch 1026, Loss: 0.004709332133643329, Final Batch Loss: 0.001278644660487771\n",
      "Epoch 1027, Loss: 0.0019363272876944393, Final Batch Loss: 0.0002608186623547226\n",
      "Epoch 1028, Loss: 0.002051236617262475, Final Batch Loss: 0.00023866620904300362\n",
      "Epoch 1029, Loss: 0.0016040616028476506, Final Batch Loss: 0.0002983363519888371\n",
      "Epoch 1030, Loss: 0.0014580238639609888, Final Batch Loss: 0.00010450703848619014\n",
      "Epoch 1031, Loss: 0.0014972681819926947, Final Batch Loss: 0.0008262302726507187\n",
      "Epoch 1032, Loss: 0.001888083788799122, Final Batch Loss: 0.0010647677117958665\n",
      "Epoch 1033, Loss: 0.016746281151426956, Final Batch Loss: 0.0016466942615807056\n",
      "Epoch 1034, Loss: 0.002129803120624274, Final Batch Loss: 0.0006290118326433003\n",
      "Epoch 1035, Loss: 0.0061579880566569045, Final Batch Loss: 0.00022463944333139807\n",
      "Epoch 1036, Loss: 0.003208343798178248, Final Batch Loss: 0.0026175612583756447\n",
      "Epoch 1037, Loss: 0.0012539834569906816, Final Batch Loss: 0.00019328064809087664\n",
      "Epoch 1038, Loss: 0.0019050256814807653, Final Batch Loss: 0.0004452813300304115\n",
      "Epoch 1039, Loss: 0.002496049302862957, Final Batch Loss: 0.0005322766373865306\n",
      "Epoch 1040, Loss: 0.014013757812790573, Final Batch Loss: 0.0007124750409275293\n",
      "Epoch 1041, Loss: 0.00396633826312609, Final Batch Loss: 0.0004781261377502233\n",
      "Epoch 1042, Loss: 0.005077771609649062, Final Batch Loss: 0.003372888546437025\n",
      "Epoch 1043, Loss: 0.003677602857351303, Final Batch Loss: 0.0016978816129267216\n",
      "Epoch 1044, Loss: 0.004815940570551902, Final Batch Loss: 0.0017212086822837591\n",
      "Epoch 1045, Loss: 0.0031318635446950793, Final Batch Loss: 0.00028296365053392947\n",
      "Epoch 1046, Loss: 0.00197874748846516, Final Batch Loss: 0.0008554410887882113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1047, Loss: 0.0036047878675162792, Final Batch Loss: 0.0005175688420422375\n",
      "Epoch 1048, Loss: 0.0025632460092310794, Final Batch Loss: 6.805425073252991e-05\n",
      "Epoch 1049, Loss: 0.002221797069068998, Final Batch Loss: 0.000507791992276907\n",
      "Epoch 1050, Loss: 0.001035278633935377, Final Batch Loss: 0.00023159541888162494\n",
      "Epoch 1051, Loss: 0.0012119708262616768, Final Batch Loss: 0.0002267754025524482\n",
      "Epoch 1052, Loss: 0.017719929688610137, Final Batch Loss: 0.016574790701270103\n",
      "Epoch 1053, Loss: 0.001980815315619111, Final Batch Loss: 0.0004843705100938678\n",
      "Epoch 1054, Loss: 0.0012863992888014764, Final Batch Loss: 0.00013506054528988898\n",
      "Epoch 1055, Loss: 0.0016916621098062024, Final Batch Loss: 0.0001517503260402009\n",
      "Epoch 1056, Loss: 0.023088726273272187, Final Batch Loss: 0.002217891626060009\n",
      "Epoch 1057, Loss: 0.011539740022271872, Final Batch Loss: 0.0017861967207863927\n",
      "Epoch 1058, Loss: 0.0013805252965539694, Final Batch Loss: 0.0003766708541661501\n",
      "Epoch 1059, Loss: 0.001826709572924301, Final Batch Loss: 0.0005839018267579377\n",
      "Epoch 1060, Loss: 0.0009324122365796939, Final Batch Loss: 0.00016664912982378155\n",
      "Epoch 1061, Loss: 0.0024970954546006396, Final Batch Loss: 0.0012954554986208677\n",
      "Epoch 1062, Loss: 0.003708191274199635, Final Batch Loss: 0.0010966333793476224\n",
      "Epoch 1063, Loss: 0.0012696029953076504, Final Batch Loss: 6.214278255356476e-05\n",
      "Epoch 1064, Loss: 0.0042352789314463735, Final Batch Loss: 0.0021236855536699295\n",
      "Epoch 1065, Loss: 0.002005056507186964, Final Batch Loss: 0.00027167334337718785\n",
      "Epoch 1066, Loss: 0.002929760368715506, Final Batch Loss: 8.46434777486138e-05\n",
      "Epoch 1067, Loss: 0.00223467119212728, Final Batch Loss: 0.00040121551137417555\n",
      "Epoch 1068, Loss: 0.0018647796241566539, Final Batch Loss: 0.0005885807913728058\n",
      "Epoch 1069, Loss: 0.0008883324626367539, Final Batch Loss: 0.00029454901232384145\n",
      "Epoch 1070, Loss: 0.0035136193764628842, Final Batch Loss: 0.00048271173727698624\n",
      "Epoch 1071, Loss: 0.012422670959495008, Final Batch Loss: 0.007304549682885408\n",
      "Epoch 1072, Loss: 0.016710151452571154, Final Batch Loss: 0.01598956622183323\n",
      "Epoch 1073, Loss: 0.0011337039322825149, Final Batch Loss: 0.00018059123249258846\n",
      "Epoch 1074, Loss: 0.0029365040973061696, Final Batch Loss: 0.002471466548740864\n",
      "Epoch 1075, Loss: 0.0021757329523097724, Final Batch Loss: 0.0004640840052161366\n",
      "Epoch 1076, Loss: 0.004399897494295146, Final Batch Loss: 0.00011373784946044907\n",
      "Epoch 1077, Loss: 0.0008061702192208031, Final Batch Loss: 1.9242283087805845e-05\n",
      "Epoch 1078, Loss: 0.004625932080671191, Final Batch Loss: 0.0032851039431989193\n",
      "Epoch 1079, Loss: 0.0074943563231499866, Final Batch Loss: 0.00015585149230901152\n",
      "Epoch 1080, Loss: 0.004448908191989176, Final Batch Loss: 0.0031246868893504143\n",
      "Epoch 1081, Loss: 0.010873018967686221, Final Batch Loss: 0.006918379105627537\n",
      "Epoch 1082, Loss: 0.009163032518699765, Final Batch Loss: 0.00019979415810666978\n",
      "Epoch 1083, Loss: 0.0013089438725728542, Final Batch Loss: 7.72568309912458e-05\n",
      "Epoch 1084, Loss: 0.006600233711651526, Final Batch Loss: 0.00012946697825100273\n",
      "Epoch 1085, Loss: 0.0038784298521932214, Final Batch Loss: 0.001970943994820118\n",
      "Epoch 1086, Loss: 0.0015265037509379908, Final Batch Loss: 0.00023515259090345353\n",
      "Epoch 1087, Loss: 0.007025332015473396, Final Batch Loss: 0.0007483037770725787\n",
      "Epoch 1088, Loss: 0.003625006997026503, Final Batch Loss: 0.00016973906895145774\n",
      "Epoch 1089, Loss: 0.0027617932355497032, Final Batch Loss: 0.0017941227415576577\n",
      "Epoch 1090, Loss: 0.0065002849441953, Final Batch Loss: 0.0048386091366410255\n",
      "Epoch 1091, Loss: 0.0018483118037693202, Final Batch Loss: 0.0007133526960387826\n",
      "Epoch 1092, Loss: 0.00043017484131269157, Final Batch Loss: 0.0001520481746410951\n",
      "Epoch 1093, Loss: 0.012489632739743683, Final Batch Loss: 0.002777515212073922\n",
      "Epoch 1094, Loss: 0.0017922565821208991, Final Batch Loss: 0.00010325364564778283\n",
      "Epoch 1095, Loss: 0.021406859974376857, Final Batch Loss: 0.019576234742999077\n",
      "Epoch 1096, Loss: 0.0004717454794445075, Final Batch Loss: 7.891791756264865e-05\n",
      "Epoch 1097, Loss: 0.0017838932108134031, Final Batch Loss: 0.0005703136557713151\n",
      "Epoch 1098, Loss: 0.0027118349098600447, Final Batch Loss: 0.00031219556694850326\n",
      "Epoch 1099, Loss: 0.0011331938876537606, Final Batch Loss: 0.00011631609231699258\n",
      "Epoch 1100, Loss: 0.0005540388010558672, Final Batch Loss: 3.7298003007890657e-05\n",
      "Epoch 1101, Loss: 0.0016964721435215324, Final Batch Loss: 0.0003573131689336151\n",
      "Epoch 1102, Loss: 0.0023879288200987503, Final Batch Loss: 0.00012098341539967805\n",
      "Epoch 1103, Loss: 0.0021024255111115053, Final Batch Loss: 0.0001530433801235631\n",
      "Epoch 1104, Loss: 0.002225814445409924, Final Batch Loss: 0.0008876455249264836\n",
      "Epoch 1105, Loss: 0.0026921566168311983, Final Batch Loss: 0.00019105561659671366\n",
      "Epoch 1106, Loss: 0.0017107096209656447, Final Batch Loss: 0.0008489181636832654\n",
      "Epoch 1107, Loss: 0.006502289877971634, Final Batch Loss: 0.006062688305974007\n",
      "Epoch 1108, Loss: 0.001398187319864519, Final Batch Loss: 0.00019970025459770113\n",
      "Epoch 1109, Loss: 0.0013939135678810999, Final Batch Loss: 0.0009708440629765391\n",
      "Epoch 1110, Loss: 0.00950519568141317, Final Batch Loss: 0.007680473383516073\n",
      "Epoch 1111, Loss: 0.0036873517092317343, Final Batch Loss: 0.0008155109826475382\n",
      "Epoch 1112, Loss: 0.0006776016525691375, Final Batch Loss: 0.0001873295841505751\n",
      "Epoch 1113, Loss: 0.02997966096154414, Final Batch Loss: 0.0004391942056827247\n",
      "Epoch 1114, Loss: 0.005977001579594798, Final Batch Loss: 0.00016567517013754696\n",
      "Epoch 1115, Loss: 0.0022648169833701104, Final Batch Loss: 0.0013265558518469334\n",
      "Epoch 1116, Loss: 0.027352761302608997, Final Batch Loss: 0.026848915964365005\n",
      "Epoch 1117, Loss: 0.0018096420972142369, Final Batch Loss: 0.001451005693525076\n",
      "Epoch 1118, Loss: 0.013734562788158655, Final Batch Loss: 0.0002520932466723025\n",
      "Epoch 1119, Loss: 0.004560760717140511, Final Batch Loss: 0.0022256539668887854\n",
      "Epoch 1120, Loss: 0.006684026564471424, Final Batch Loss: 0.002321079606190324\n",
      "Epoch 1121, Loss: 0.0015082955651450902, Final Batch Loss: 0.00028428598307073116\n",
      "Epoch 1122, Loss: 0.0006385027663782239, Final Batch Loss: 0.00017346456297673285\n",
      "Epoch 1123, Loss: 0.015165889519266784, Final Batch Loss: 0.0028457173611968756\n",
      "Epoch 1124, Loss: 0.004380155500257388, Final Batch Loss: 0.003345274366438389\n",
      "Epoch 1125, Loss: 0.0024574724957346916, Final Batch Loss: 0.000930286361835897\n",
      "Epoch 1126, Loss: 0.0034092547721229494, Final Batch Loss: 0.0016006564255803823\n",
      "Epoch 1127, Loss: 0.01267663127509877, Final Batch Loss: 0.009380219504237175\n",
      "Epoch 1128, Loss: 0.035974835758679546, Final Batch Loss: 0.00015007257752586156\n",
      "Epoch 1129, Loss: 0.0049846503243315965, Final Batch Loss: 0.0002817877393681556\n",
      "Epoch 1130, Loss: 0.004006310249678791, Final Batch Loss: 0.0024671044666320086\n",
      "Epoch 1131, Loss: 0.006580538989510387, Final Batch Loss: 0.0025958523619920015\n",
      "Epoch 1132, Loss: 0.01938447868451476, Final Batch Loss: 0.0003808119799941778\n",
      "Epoch 1133, Loss: 0.002540478089940734, Final Batch Loss: 0.0002386600972386077\n",
      "Epoch 1134, Loss: 0.011322386941174045, Final Batch Loss: 0.0005270022084005177\n",
      "Epoch 1135, Loss: 0.0026332221750635654, Final Batch Loss: 0.0004667197645176202\n",
      "Epoch 1136, Loss: 0.010041792411357164, Final Batch Loss: 0.0012650198768824339\n",
      "Epoch 1137, Loss: 0.0045163042814238, Final Batch Loss: 0.001959418412297964\n",
      "Epoch 1138, Loss: 0.006413874070858583, Final Batch Loss: 0.00022109950077719986\n",
      "Epoch 1139, Loss: 0.037692080601118505, Final Batch Loss: 0.03617081418633461\n",
      "Epoch 1140, Loss: 0.00509581615915522, Final Batch Loss: 0.0007275902316905558\n",
      "Epoch 1141, Loss: 0.0017895600904012099, Final Batch Loss: 0.0003121415211353451\n",
      "Epoch 1142, Loss: 0.0021203698124736547, Final Batch Loss: 0.0005101262358948588\n",
      "Epoch 1143, Loss: 0.013487312942743301, Final Batch Loss: 0.011197797954082489\n",
      "Epoch 1144, Loss: 0.0011131590144941583, Final Batch Loss: 0.00016426957154180855\n",
      "Epoch 1145, Loss: 0.006736051989719272, Final Batch Loss: 0.003851720131933689\n",
      "Epoch 1146, Loss: 0.01193522135145031, Final Batch Loss: 0.010870597325265408\n",
      "Epoch 1147, Loss: 0.008193867863155901, Final Batch Loss: 0.000620288890786469\n",
      "Epoch 1148, Loss: 0.0026636470574885607, Final Batch Loss: 0.0011490832548588514\n",
      "Epoch 1149, Loss: 0.05565036623738706, Final Batch Loss: 0.053921591490507126\n",
      "Epoch 1150, Loss: 0.0055940321035450324, Final Batch Loss: 0.00021290119912009686\n",
      "Epoch 1151, Loss: 0.0033940040157176554, Final Batch Loss: 0.00022766500478610396\n",
      "Epoch 1152, Loss: 0.02693921785976272, Final Batch Loss: 0.00022667220036964864\n",
      "Epoch 1153, Loss: 0.0017121624550782144, Final Batch Loss: 0.00047962419921532273\n",
      "Epoch 1154, Loss: 0.0016028742829803377, Final Batch Loss: 0.00018607274978421628\n",
      "Epoch 1155, Loss: 0.010745233827037737, Final Batch Loss: 0.0002641125756781548\n",
      "Epoch 1156, Loss: 0.0027045840688515455, Final Batch Loss: 0.0009394337539561093\n",
      "Epoch 1157, Loss: 0.004436170915141702, Final Batch Loss: 0.002308744238689542\n",
      "Epoch 1158, Loss: 0.006707533742883243, Final Batch Loss: 0.00021827944146934897\n",
      "Epoch 1159, Loss: 0.0030795615166425705, Final Batch Loss: 0.002180727431550622\n",
      "Epoch 1160, Loss: 0.0011887801811099052, Final Batch Loss: 0.0003870188957080245\n",
      "Epoch 1161, Loss: 0.002799177513225004, Final Batch Loss: 0.0012631387216970325\n",
      "Epoch 1162, Loss: 0.004152245484874584, Final Batch Loss: 0.0031566848047077656\n",
      "Epoch 1163, Loss: 0.003748079907381907, Final Batch Loss: 0.00026527399313636124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1164, Loss: 0.0011105559533461928, Final Batch Loss: 0.00035195384407415986\n",
      "Epoch 1165, Loss: 0.0007617996598128229, Final Batch Loss: 0.00039686798118054867\n",
      "Epoch 1166, Loss: 0.0008885170755092986, Final Batch Loss: 6.638128979830071e-05\n",
      "Epoch 1167, Loss: 0.0024168333475245163, Final Batch Loss: 0.00021073028619866818\n",
      "Epoch 1168, Loss: 0.0028653527260757983, Final Batch Loss: 0.00032365386141464114\n",
      "Epoch 1169, Loss: 0.008319616739754565, Final Batch Loss: 0.0006041586748324335\n",
      "Epoch 1170, Loss: 0.002012214608839713, Final Batch Loss: 0.00017882038082461804\n",
      "Epoch 1171, Loss: 0.0015206405332719442, Final Batch Loss: 3.6344255931908265e-05\n",
      "Epoch 1172, Loss: 0.0016338163040927611, Final Batch Loss: 0.00011803654342656955\n",
      "Epoch 1173, Loss: 0.0024535021802876145, Final Batch Loss: 0.00030172860715538263\n",
      "Epoch 1174, Loss: 0.004314094199799001, Final Batch Loss: 0.0005308004911057651\n",
      "Epoch 1175, Loss: 0.002377077005803585, Final Batch Loss: 0.0016774983378127217\n",
      "Epoch 1176, Loss: 0.0019175591733073816, Final Batch Loss: 7.352609827648848e-05\n",
      "Epoch 1177, Loss: 0.026223123422823846, Final Batch Loss: 0.00037966843228787184\n",
      "Epoch 1178, Loss: 0.01922389742685482, Final Batch Loss: 0.00030058593256399035\n",
      "Epoch 1179, Loss: 0.0024561139289289713, Final Batch Loss: 0.0001968074357137084\n",
      "Epoch 1180, Loss: 0.002556279127020389, Final Batch Loss: 0.0013422854244709015\n",
      "Epoch 1181, Loss: 0.002513284081942402, Final Batch Loss: 0.0005002745892852545\n",
      "Epoch 1182, Loss: 0.0026367121026851237, Final Batch Loss: 0.0020112476777285337\n",
      "Epoch 1183, Loss: 0.020659785077441484, Final Batch Loss: 0.002669123001396656\n",
      "Epoch 1184, Loss: 0.001003273697278928, Final Batch Loss: 7.722450391156599e-05\n",
      "Epoch 1185, Loss: 0.0007180731045082211, Final Batch Loss: 0.00031645881244912744\n",
      "Epoch 1186, Loss: 0.0006679454527329654, Final Batch Loss: 3.836792893707752e-05\n",
      "Epoch 1187, Loss: 0.0010696444660425186, Final Batch Loss: 5.2264658734202385e-05\n",
      "Epoch 1188, Loss: 0.0011363634112058207, Final Batch Loss: 0.000513316597789526\n",
      "Epoch 1189, Loss: 0.0020497968944255263, Final Batch Loss: 0.0005004844861105084\n",
      "Epoch 1190, Loss: 0.006684266903903335, Final Batch Loss: 0.0007411264814436436\n",
      "Epoch 1191, Loss: 0.004321774991694838, Final Batch Loss: 0.0010291555663570762\n",
      "Epoch 1192, Loss: 0.0013227782619651407, Final Batch Loss: 0.00013324987958185375\n",
      "Epoch 1193, Loss: 0.0051126944454154, Final Batch Loss: 0.003253566101193428\n",
      "Epoch 1194, Loss: 0.00712614186340943, Final Batch Loss: 0.005700769834220409\n",
      "Epoch 1195, Loss: 0.0019352005328983068, Final Batch Loss: 0.0003806523163802922\n",
      "Epoch 1196, Loss: 0.0006293150945566595, Final Batch Loss: 0.00016475228767376393\n",
      "Epoch 1197, Loss: 0.03493809647625312, Final Batch Loss: 0.03350318595767021\n",
      "Epoch 1198, Loss: 0.00952425372088328, Final Batch Loss: 0.008497947826981544\n",
      "Epoch 1199, Loss: 0.0056328037098865025, Final Batch Loss: 0.00012184509978396818\n",
      "Epoch 1200, Loss: 0.002459091425407678, Final Batch Loss: 0.0007723289309069514\n",
      "Epoch 1201, Loss: 0.004054584365803748, Final Batch Loss: 0.0013069510459899902\n",
      "Epoch 1202, Loss: 0.0021624017390422523, Final Batch Loss: 0.0003314071800559759\n",
      "Epoch 1203, Loss: 0.004356926190666854, Final Batch Loss: 0.0017355444142594934\n",
      "Epoch 1204, Loss: 0.01194360840599984, Final Batch Loss: 0.0005721867782995105\n",
      "Epoch 1205, Loss: 0.0020367664837976918, Final Batch Loss: 0.0001576444919919595\n",
      "Epoch 1206, Loss: 0.001190478535136208, Final Batch Loss: 0.0003415579558350146\n",
      "Epoch 1207, Loss: 0.0005361552175600082, Final Batch Loss: 7.725469185970724e-05\n",
      "Epoch 1208, Loss: 0.008762201156059746, Final Batch Loss: 0.00012039495777571574\n",
      "Epoch 1209, Loss: 0.0019318771519465372, Final Batch Loss: 0.00023203117598313838\n",
      "Epoch 1210, Loss: 0.004174818575847894, Final Batch Loss: 0.00016563554527238011\n",
      "Epoch 1211, Loss: 0.0006987962842686102, Final Batch Loss: 0.0001751591044012457\n",
      "Epoch 1212, Loss: 0.002694193972274661, Final Batch Loss: 0.0017766932724043727\n",
      "Epoch 1213, Loss: 0.0013961864387965761, Final Batch Loss: 0.0004154580819886178\n",
      "Epoch 1214, Loss: 0.0007741380904917605, Final Batch Loss: 6.0842823586426675e-05\n",
      "Epoch 1215, Loss: 0.0008541386487195268, Final Batch Loss: 0.00037042112671770155\n",
      "Epoch 1216, Loss: 0.0011834092147182673, Final Batch Loss: 0.000222888367716223\n",
      "Epoch 1217, Loss: 0.003590889878978487, Final Batch Loss: 9.02211686479859e-05\n",
      "Epoch 1218, Loss: 0.00200852207490243, Final Batch Loss: 0.0008188896463252604\n",
      "Epoch 1219, Loss: 0.0005556045507546514, Final Batch Loss: 9.616257739253342e-05\n",
      "Epoch 1220, Loss: 0.01206435399944894, Final Batch Loss: 0.00042056894744746387\n",
      "Epoch 1221, Loss: 0.0013439757349260617, Final Batch Loss: 4.280913344700821e-05\n",
      "Epoch 1222, Loss: 0.0007961792252899613, Final Batch Loss: 0.00037069711834192276\n",
      "Epoch 1223, Loss: 0.0025987975241150707, Final Batch Loss: 0.0008026841096580029\n",
      "Epoch 1224, Loss: 0.0029706644563702866, Final Batch Loss: 0.001711090444587171\n",
      "Epoch 1225, Loss: 0.0015349669265560806, Final Batch Loss: 0.0009157563908956945\n",
      "Epoch 1226, Loss: 0.0007492528893635608, Final Batch Loss: 0.0001203359934152104\n",
      "Epoch 1227, Loss: 0.001227727836521808, Final Batch Loss: 0.0001420870830770582\n",
      "Epoch 1228, Loss: 0.001579789211973548, Final Batch Loss: 0.0003758691600523889\n",
      "Epoch 1229, Loss: 0.010496365139260888, Final Batch Loss: 0.007659048307687044\n",
      "Epoch 1230, Loss: 0.0010231022024527192, Final Batch Loss: 0.00017461540119256824\n",
      "Epoch 1231, Loss: 0.023133188304200303, Final Batch Loss: 0.009518434293568134\n",
      "Epoch 1232, Loss: 0.00163571911980398, Final Batch Loss: 0.00016204683925025165\n",
      "Epoch 1233, Loss: 0.003672263352200389, Final Batch Loss: 0.0005321624339558184\n",
      "Epoch 1234, Loss: 0.03966875247715507, Final Batch Loss: 0.00013071032299194485\n",
      "Epoch 1235, Loss: 0.0015126303769648075, Final Batch Loss: 0.0006237422931008041\n",
      "Epoch 1236, Loss: 0.04961168087902479, Final Batch Loss: 0.042688217014074326\n",
      "Epoch 1237, Loss: 0.007079963295836933, Final Batch Loss: 9.944020712282509e-05\n",
      "Epoch 1238, Loss: 0.0025241825060220435, Final Batch Loss: 0.00010814257257152349\n",
      "Epoch 1239, Loss: 0.0005421717360150069, Final Batch Loss: 0.0001569269661558792\n",
      "Epoch 1240, Loss: 0.02532432123553008, Final Batch Loss: 0.016729407012462616\n",
      "Epoch 1241, Loss: 0.023677471792325377, Final Batch Loss: 0.00043341354466974735\n",
      "Epoch 1242, Loss: 0.0023170040076365694, Final Batch Loss: 0.001595192588865757\n",
      "Epoch 1243, Loss: 0.007794636650942266, Final Batch Loss: 0.00047784263733774424\n",
      "Epoch 1244, Loss: 0.0032591011258773506, Final Batch Loss: 0.0011864261468872428\n",
      "Epoch 1245, Loss: 0.0025176644448947627, Final Batch Loss: 4.8028483433881775e-05\n",
      "Epoch 1246, Loss: 0.00810328300576657, Final Batch Loss: 0.0005679386085830629\n",
      "Epoch 1247, Loss: 0.0029305971693247557, Final Batch Loss: 0.0010672855423763394\n",
      "Epoch 1248, Loss: 0.0017108106330852024, Final Batch Loss: 6.466070044552907e-05\n",
      "Epoch 1249, Loss: 0.0009315554852946661, Final Batch Loss: 0.0003258181968703866\n",
      "Epoch 1250, Loss: 0.0020550931367324665, Final Batch Loss: 0.00017776219465304166\n",
      "Epoch 1251, Loss: 0.000864459179865662, Final Batch Loss: 3.364701842656359e-05\n",
      "Epoch 1252, Loss: 0.001948770965100266, Final Batch Loss: 0.0005976677057333291\n",
      "Epoch 1253, Loss: 0.0008928154420573264, Final Batch Loss: 0.0003007175400853157\n",
      "Epoch 1254, Loss: 0.02312296663876623, Final Batch Loss: 0.0008881450048647821\n",
      "Epoch 1255, Loss: 0.001826745101425331, Final Batch Loss: 0.00017541262786835432\n",
      "Epoch 1256, Loss: 0.0026984522555721924, Final Batch Loss: 0.00020632184168789536\n",
      "Epoch 1257, Loss: 0.0035694497637450695, Final Batch Loss: 0.0018352459883317351\n",
      "Epoch 1258, Loss: 0.0009404621996509377, Final Batch Loss: 4.7396115405717865e-05\n",
      "Epoch 1259, Loss: 0.0013173931802157313, Final Batch Loss: 0.00016309457714669406\n",
      "Epoch 1260, Loss: 0.0013988109130878001, Final Batch Loss: 0.00045733596198260784\n",
      "Epoch 1261, Loss: 0.003335067318403162, Final Batch Loss: 0.0002599630388431251\n",
      "Epoch 1262, Loss: 0.0008578854758525267, Final Batch Loss: 0.00019280766719020903\n",
      "Epoch 1263, Loss: 0.0004843530186917633, Final Batch Loss: 0.0001346889475826174\n",
      "Epoch 1264, Loss: 0.007193106226623058, Final Batch Loss: 0.0026153649669140577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1265, Loss: 0.0007292249792953953, Final Batch Loss: 0.00023667597270105034\n",
      "Epoch 1266, Loss: 0.0005557644435612019, Final Batch Loss: 4.734922185889445e-05\n",
      "Epoch 1267, Loss: 0.0433736232080264, Final Batch Loss: 8.619714935775846e-05\n",
      "Epoch 1268, Loss: 0.001263530670257751, Final Batch Loss: 0.00044251963845454156\n",
      "Epoch 1269, Loss: 0.0039026076556183398, Final Batch Loss: 0.0009126967051997781\n",
      "Epoch 1270, Loss: 0.00131344617693685, Final Batch Loss: 0.00018470900249667466\n",
      "Epoch 1271, Loss: 0.0023706571155344136, Final Batch Loss: 0.00011247886141063645\n",
      "Epoch 1272, Loss: 0.0008819396753096953, Final Batch Loss: 0.0001778055593604222\n",
      "Epoch 1273, Loss: 0.004805981967365369, Final Batch Loss: 0.00027751768357120454\n",
      "Epoch 1274, Loss: 0.003846108156722039, Final Batch Loss: 0.002555101178586483\n",
      "Epoch 1275, Loss: 0.0014243374462239444, Final Batch Loss: 0.00032181176356971264\n",
      "Epoch 1276, Loss: 0.001002985820377944, Final Batch Loss: 4.86718890897464e-05\n",
      "Epoch 1277, Loss: 0.0010099191567860544, Final Batch Loss: 0.0003351409104652703\n",
      "Epoch 1278, Loss: 0.0017282981425523758, Final Batch Loss: 0.0006029822397977114\n",
      "Epoch 1279, Loss: 0.0033294714958174154, Final Batch Loss: 0.0018322673859074712\n",
      "Epoch 1280, Loss: 0.0017720991163514555, Final Batch Loss: 0.00035844219382852316\n",
      "Epoch 1281, Loss: 0.001599152063135989, Final Batch Loss: 0.0005007506115362048\n",
      "Epoch 1282, Loss: 0.0022908094397280365, Final Batch Loss: 0.00024578990996815264\n",
      "Epoch 1283, Loss: 0.005487414833623916, Final Batch Loss: 0.0011572702787816525\n",
      "Epoch 1284, Loss: 0.000559154199436307, Final Batch Loss: 0.00013438487076200545\n",
      "Epoch 1285, Loss: 0.0006926202913746238, Final Batch Loss: 0.00022733124205842614\n",
      "Epoch 1286, Loss: 0.0008414119511144236, Final Batch Loss: 0.00031897329608909786\n",
      "Epoch 1287, Loss: 0.001609109400305897, Final Batch Loss: 0.0003710876335389912\n",
      "Epoch 1288, Loss: 0.009036182244017255, Final Batch Loss: 9.092226537177339e-05\n",
      "Epoch 1289, Loss: 0.007917972419818398, Final Batch Loss: 0.00010061068314826116\n",
      "Epoch 1290, Loss: 0.0013925577732152306, Final Batch Loss: 0.0005315649323165417\n",
      "Epoch 1291, Loss: 0.001502788858488202, Final Batch Loss: 0.0003550810506567359\n",
      "Epoch 1292, Loss: 0.0005582971061812714, Final Batch Loss: 0.00012774871720466763\n",
      "Epoch 1293, Loss: 0.0013574570511991624, Final Batch Loss: 0.0009174152510240674\n",
      "Epoch 1294, Loss: 0.00047187404561555013, Final Batch Loss: 9.439913992537186e-05\n",
      "Epoch 1295, Loss: 0.0015120144234970212, Final Batch Loss: 8.008758595678955e-05\n",
      "Epoch 1296, Loss: 0.0007329342042794451, Final Batch Loss: 0.0002677027368918061\n",
      "Epoch 1297, Loss: 0.0007271102149388753, Final Batch Loss: 0.0003722703258972615\n",
      "Epoch 1298, Loss: 0.00093418026517611, Final Batch Loss: 0.00015973493282217532\n",
      "Epoch 1299, Loss: 0.009377765527460724, Final Batch Loss: 0.0001788896624930203\n",
      "Epoch 1300, Loss: 0.023490620747907087, Final Batch Loss: 0.02237599343061447\n",
      "Epoch 1301, Loss: 0.0006499110313598067, Final Batch Loss: 0.00015009423077572137\n",
      "Epoch 1302, Loss: 0.0007410431062453426, Final Batch Loss: 0.00011115031520603225\n",
      "Epoch 1303, Loss: 0.00041394783329451457, Final Batch Loss: 0.0001707099872874096\n",
      "Epoch 1304, Loss: 0.07867437265667832, Final Batch Loss: 0.07633085548877716\n",
      "Epoch 1305, Loss: 0.0006822008872404695, Final Batch Loss: 0.0001250933128176257\n",
      "Epoch 1306, Loss: 0.0007916923059383407, Final Batch Loss: 8.420776430284604e-05\n",
      "Epoch 1307, Loss: 0.0004676890021073632, Final Batch Loss: 9.191402205033228e-05\n",
      "Epoch 1308, Loss: 0.006838877707195934, Final Batch Loss: 0.006493603810667992\n",
      "Epoch 1309, Loss: 0.0203880915978516, Final Batch Loss: 0.019775042310357094\n",
      "Epoch 1310, Loss: 0.005942390955169685, Final Batch Loss: 0.00015800092660356313\n",
      "Epoch 1311, Loss: 0.0036112990783294663, Final Batch Loss: 0.00023284302733372897\n",
      "Epoch 1312, Loss: 0.022295512433629483, Final Batch Loss: 0.020980020985007286\n",
      "Epoch 1313, Loss: 0.024564844512497075, Final Batch Loss: 0.00022712924692314118\n",
      "Epoch 1314, Loss: 0.001582915720064193, Final Batch Loss: 0.000259047606959939\n",
      "Epoch 1315, Loss: 0.0031941341585479677, Final Batch Loss: 0.0024966138880699873\n",
      "Epoch 1316, Loss: 0.0015187884418992326, Final Batch Loss: 9.269399743061513e-05\n",
      "Epoch 1317, Loss: 0.002611614065244794, Final Batch Loss: 0.0008792151929810643\n",
      "Epoch 1318, Loss: 0.03351873060455546, Final Batch Loss: 0.0320696085691452\n",
      "Epoch 1319, Loss: 0.0019440262694843113, Final Batch Loss: 0.0005378997884690762\n",
      "Epoch 1320, Loss: 0.0015893143136054277, Final Batch Loss: 0.00046585540985688567\n",
      "Epoch 1321, Loss: 0.0037789529596921057, Final Batch Loss: 0.0029509656596928835\n",
      "Epoch 1322, Loss: 0.006916358615853824, Final Batch Loss: 0.0010765043552964926\n",
      "Epoch 1323, Loss: 0.007052082757581957, Final Batch Loss: 0.00019539509958121926\n",
      "Epoch 1324, Loss: 0.012242846103617921, Final Batch Loss: 0.011008060537278652\n",
      "Epoch 1325, Loss: 0.0007704177551204339, Final Batch Loss: 0.00018329350859858096\n",
      "Epoch 1326, Loss: 0.019245609757490456, Final Batch Loss: 0.01723002828657627\n",
      "Epoch 1327, Loss: 0.0017493056366220117, Final Batch Loss: 0.0010503465309739113\n",
      "Epoch 1328, Loss: 0.0009071589156519622, Final Batch Loss: 0.0004387884109746665\n",
      "Epoch 1329, Loss: 0.001239013989106752, Final Batch Loss: 0.0005426965653896332\n",
      "Epoch 1330, Loss: 0.0013990383085911162, Final Batch Loss: 0.000426690821768716\n",
      "Epoch 1331, Loss: 0.008845786112942733, Final Batch Loss: 0.0002379981888225302\n",
      "Epoch 1332, Loss: 0.004100175283383578, Final Batch Loss: 0.0013005132786929607\n",
      "Epoch 1333, Loss: 0.0037847882485948503, Final Batch Loss: 0.0015767310978844762\n",
      "Epoch 1334, Loss: 0.0015714285400463268, Final Batch Loss: 0.0001897942420328036\n",
      "Epoch 1335, Loss: 0.007141377485822886, Final Batch Loss: 0.0010782977333292365\n",
      "Epoch 1336, Loss: 0.0017848971765488386, Final Batch Loss: 0.000996576389297843\n",
      "Epoch 1337, Loss: 0.0019483714713715017, Final Batch Loss: 0.0005326977116055787\n",
      "Epoch 1338, Loss: 0.015849850547965616, Final Batch Loss: 0.0006368529866449535\n",
      "Epoch 1339, Loss: 0.004558615146379452, Final Batch Loss: 0.0034997165203094482\n",
      "Epoch 1340, Loss: 0.002574700891273096, Final Batch Loss: 0.00012420734856277704\n",
      "Epoch 1341, Loss: 0.045807454524037894, Final Batch Loss: 9.576754382578656e-05\n",
      "Epoch 1342, Loss: 0.0045866686559747905, Final Batch Loss: 0.00039007182931527495\n",
      "Epoch 1343, Loss: 0.001509653746325057, Final Batch Loss: 0.0006733272457495332\n",
      "Epoch 1344, Loss: 0.0005019948584958911, Final Batch Loss: 0.00011786648246925324\n",
      "Epoch 1345, Loss: 0.0012030791549477726, Final Batch Loss: 0.0004946264671161771\n",
      "Epoch 1346, Loss: 0.002708523563342169, Final Batch Loss: 8.905430149752647e-05\n",
      "Epoch 1347, Loss: 0.008746631901885848, Final Batch Loss: 0.0032056975178420544\n",
      "Epoch 1348, Loss: 0.0006089700182201341, Final Batch Loss: 8.760315540712327e-05\n",
      "Epoch 1349, Loss: 0.006119282217696309, Final Batch Loss: 0.00032038206700235605\n",
      "Epoch 1350, Loss: 0.0554725450638216, Final Batch Loss: 0.00029047366115264595\n",
      "Epoch 1351, Loss: 0.006170615495648235, Final Batch Loss: 0.00031020137248560786\n",
      "Epoch 1352, Loss: 0.0021394521463662386, Final Batch Loss: 0.0010908532422035933\n",
      "Epoch 1353, Loss: 0.003382984781637788, Final Batch Loss: 0.0021602341439574957\n",
      "Epoch 1354, Loss: 0.0030569702794309705, Final Batch Loss: 0.0018094986444339156\n",
      "Epoch 1355, Loss: 0.0012134659482399002, Final Batch Loss: 0.00020852815941907465\n",
      "Epoch 1356, Loss: 0.0019575153419282287, Final Batch Loss: 0.0003593722067307681\n",
      "Epoch 1357, Loss: 0.004725820937892422, Final Batch Loss: 0.00038166725425980985\n",
      "Epoch 1358, Loss: 0.004727133724372834, Final Batch Loss: 0.0032070453744381666\n",
      "Epoch 1359, Loss: 0.0015360735997091979, Final Batch Loss: 0.0003073178813792765\n",
      "Epoch 1360, Loss: 0.0010178888915106654, Final Batch Loss: 0.0001376250002067536\n",
      "Epoch 1361, Loss: 0.002958242257591337, Final Batch Loss: 0.000651077541988343\n",
      "Epoch 1362, Loss: 0.00084884294483345, Final Batch Loss: 0.00016843566845636815\n",
      "Epoch 1363, Loss: 0.05572214047424495, Final Batch Loss: 0.0009618618059903383\n",
      "Epoch 1364, Loss: 0.0014388426207005978, Final Batch Loss: 0.00031436834251508117\n",
      "Epoch 1365, Loss: 0.001671219157287851, Final Batch Loss: 0.0009346302831545472\n",
      "Epoch 1366, Loss: 0.0032086981227621436, Final Batch Loss: 0.0012576335575431585\n",
      "Epoch 1367, Loss: 0.002564390073530376, Final Batch Loss: 0.001512980437837541\n",
      "Epoch 1368, Loss: 0.001775351440301165, Final Batch Loss: 0.0014814423630014062\n",
      "Epoch 1369, Loss: 0.002015197154833004, Final Batch Loss: 0.001107237534597516\n",
      "Epoch 1370, Loss: 0.0029546499717980623, Final Batch Loss: 0.0006474318797700107\n",
      "Epoch 1371, Loss: 0.003803938830969855, Final Batch Loss: 0.0008722881320863962\n",
      "Epoch 1372, Loss: 0.001674646497122012, Final Batch Loss: 0.0007859793258830905\n",
      "Epoch 1373, Loss: 0.0017180155991809443, Final Batch Loss: 8.873782644513994e-05\n",
      "Epoch 1374, Loss: 0.0022586752893403172, Final Batch Loss: 0.0008835986373014748\n",
      "Epoch 1375, Loss: 0.0021618854443659075, Final Batch Loss: 0.0011313981376588345\n",
      "Epoch 1376, Loss: 0.002827300748322159, Final Batch Loss: 0.0001385989598929882\n",
      "Epoch 1377, Loss: 0.0017191627121064812, Final Batch Loss: 0.00026105897268280387\n",
      "Epoch 1378, Loss: 0.00418276953860186, Final Batch Loss: 0.0014570601051673293\n",
      "Epoch 1379, Loss: 0.0023286096402443945, Final Batch Loss: 0.0012952544493600726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1380, Loss: 0.0013380810705712065, Final Batch Loss: 0.00024974343250505626\n",
      "Epoch 1381, Loss: 0.0015968454827088863, Final Batch Loss: 0.00015377273666672409\n",
      "Epoch 1382, Loss: 0.007662382748094387, Final Batch Loss: 0.00022937233734410256\n",
      "Epoch 1383, Loss: 0.0022925926677999087, Final Batch Loss: 6.176246824907139e-05\n",
      "Epoch 1384, Loss: 0.0023272536491276696, Final Batch Loss: 0.0001242569269379601\n",
      "Epoch 1385, Loss: 0.0029358426108956337, Final Batch Loss: 0.0008624340407550335\n",
      "Epoch 1386, Loss: 0.0012171826529083773, Final Batch Loss: 0.00013724052405450493\n",
      "Epoch 1387, Loss: 0.016859064460732043, Final Batch Loss: 0.00047222001012414694\n",
      "Epoch 1388, Loss: 0.0005357339978218079, Final Batch Loss: 0.0001896670728456229\n",
      "Epoch 1389, Loss: 0.004604495130479336, Final Batch Loss: 0.0003439389984123409\n",
      "Epoch 1390, Loss: 0.06409265675756615, Final Batch Loss: 0.06297118961811066\n",
      "Epoch 1391, Loss: 0.0022994723985902965, Final Batch Loss: 0.00025544813252054155\n",
      "Epoch 1392, Loss: 0.0009415718595846556, Final Batch Loss: 0.0002151847875211388\n",
      "Epoch 1393, Loss: 0.009328685046057217, Final Batch Loss: 0.0001519404904684052\n",
      "Epoch 1394, Loss: 0.0019604476110544056, Final Batch Loss: 0.001134424819611013\n",
      "Epoch 1395, Loss: 0.002733615110628307, Final Batch Loss: 0.0019810993690043688\n",
      "Epoch 1396, Loss: 0.008077276666881517, Final Batch Loss: 0.0011263228952884674\n",
      "Epoch 1397, Loss: 0.0030004281434230506, Final Batch Loss: 0.0010314687388017774\n",
      "Epoch 1398, Loss: 0.0006956154829822481, Final Batch Loss: 0.00014244907652027905\n",
      "Epoch 1399, Loss: 0.0028253333875909448, Final Batch Loss: 0.000624815293122083\n",
      "Epoch 1400, Loss: 0.0028847904250142165, Final Batch Loss: 0.0025448771193623543\n",
      "Epoch 1401, Loss: 0.003010763553902507, Final Batch Loss: 0.0024319130461663008\n",
      "Epoch 1402, Loss: 0.006413084978703409, Final Batch Loss: 0.00025264755822718143\n",
      "Epoch 1403, Loss: 0.0018099059234373271, Final Batch Loss: 0.00044032029109075665\n",
      "Epoch 1404, Loss: 0.00351502702687867, Final Batch Loss: 0.00025806264602579176\n",
      "Epoch 1405, Loss: 0.01307330495910719, Final Batch Loss: 0.0008901053224690259\n",
      "Epoch 1406, Loss: 0.003936043329304084, Final Batch Loss: 0.000255286373430863\n",
      "Epoch 1407, Loss: 0.005874543479876593, Final Batch Loss: 0.004538289271295071\n",
      "Epoch 1408, Loss: 0.0007640362673555501, Final Batch Loss: 9.418855916010216e-05\n",
      "Epoch 1409, Loss: 0.001062973948137369, Final Batch Loss: 9.609827975509688e-05\n",
      "Epoch 1410, Loss: 0.001048689166054828, Final Batch Loss: 5.9245398006169125e-05\n",
      "Epoch 1411, Loss: 0.0011838101199828088, Final Batch Loss: 0.0005184268811717629\n",
      "Epoch 1412, Loss: 0.0012028089840896428, Final Batch Loss: 0.0004034912271890789\n",
      "Epoch 1413, Loss: 0.003169088944559917, Final Batch Loss: 0.002716519869863987\n",
      "Epoch 1414, Loss: 0.0011870517628267407, Final Batch Loss: 0.0009061679011210799\n",
      "Epoch 1415, Loss: 0.0011584055100684054, Final Batch Loss: 8.351277938345447e-05\n",
      "Epoch 1416, Loss: 0.0018452607473591343, Final Batch Loss: 0.00022749679919797927\n",
      "Epoch 1417, Loss: 0.006996100149990525, Final Batch Loss: 0.0004958307254128158\n",
      "Epoch 1418, Loss: 0.006326109927613288, Final Batch Loss: 0.00015753443585708737\n",
      "Epoch 1419, Loss: 0.0027537965797819197, Final Batch Loss: 0.0015775043284520507\n",
      "Epoch 1420, Loss: 0.0011103481883765198, Final Batch Loss: 5.603562021860853e-05\n",
      "Epoch 1421, Loss: 0.0007191374143076246, Final Batch Loss: 1.2888643141195644e-05\n",
      "Epoch 1422, Loss: 0.01802793680690229, Final Batch Loss: 0.017260216176509857\n",
      "Epoch 1423, Loss: 0.00038475925975944847, Final Batch Loss: 0.0001955891348188743\n",
      "Epoch 1424, Loss: 0.01511278727411991, Final Batch Loss: 0.0011418411741033196\n",
      "Epoch 1425, Loss: 0.025280471047153696, Final Batch Loss: 0.00012421802966855466\n",
      "Epoch 1426, Loss: 0.0005131321668159217, Final Batch Loss: 0.0001979365333681926\n",
      "Epoch 1427, Loss: 0.0006539627502206713, Final Batch Loss: 0.00022012942645233124\n",
      "Epoch 1428, Loss: 0.0009051660599652678, Final Batch Loss: 0.00010418012971058488\n",
      "Epoch 1429, Loss: 0.016875783854629844, Final Batch Loss: 0.0019731756765395403\n",
      "Epoch 1430, Loss: 0.00307139809592627, Final Batch Loss: 0.0006293584010563791\n",
      "Epoch 1431, Loss: 0.0008330883429152891, Final Batch Loss: 0.00015796277148183435\n",
      "Epoch 1432, Loss: 0.0015287701098714024, Final Batch Loss: 0.00031626963755115867\n",
      "Epoch 1433, Loss: 0.004646130939363502, Final Batch Loss: 0.00016892787243705243\n",
      "Epoch 1434, Loss: 0.0009100567986024544, Final Batch Loss: 0.00019424405763857067\n",
      "Epoch 1435, Loss: 0.0006326241928036325, Final Batch Loss: 0.00018301383533980697\n",
      "Epoch 1436, Loss: 0.012919100263388827, Final Batch Loss: 0.00044463263475336134\n",
      "Epoch 1437, Loss: 0.005893497684155591, Final Batch Loss: 0.00018185180670116097\n",
      "Epoch 1438, Loss: 0.0069186100154183805, Final Batch Loss: 0.00012185161904199049\n",
      "Epoch 1439, Loss: 0.0006693748000543565, Final Batch Loss: 0.00013641518307849765\n",
      "Epoch 1440, Loss: 0.0009169714176096022, Final Batch Loss: 0.0004250070487614721\n",
      "Epoch 1441, Loss: 0.0007283954182639718, Final Batch Loss: 0.00012489871005527675\n",
      "Epoch 1442, Loss: 0.0009159752080449834, Final Batch Loss: 0.00013294510426931083\n",
      "Epoch 1443, Loss: 0.003278400283306837, Final Batch Loss: 0.0004761406744364649\n",
      "Epoch 1444, Loss: 0.00042703205326688476, Final Batch Loss: 5.063327625975944e-05\n",
      "Epoch 1445, Loss: 0.0012148871610406786, Final Batch Loss: 0.0010315246181562543\n",
      "Epoch 1446, Loss: 0.0019182254909537733, Final Batch Loss: 0.0005100315902382135\n",
      "Epoch 1447, Loss: 0.002063315740088001, Final Batch Loss: 0.0011310467962175608\n",
      "Epoch 1448, Loss: 0.001445810601580888, Final Batch Loss: 0.0006555616855621338\n",
      "Epoch 1449, Loss: 0.01460634428076446, Final Batch Loss: 0.001235593343153596\n",
      "Epoch 1450, Loss: 0.004337106664024759, Final Batch Loss: 7.858605385990813e-05\n",
      "Epoch 1451, Loss: 0.003680618727230467, Final Batch Loss: 0.0001595537323737517\n",
      "Epoch 1452, Loss: 0.044285709685937036, Final Batch Loss: 0.04403255879878998\n",
      "Epoch 1453, Loss: 0.0008754851151024923, Final Batch Loss: 0.000459642440546304\n",
      "Epoch 1454, Loss: 0.0023736947478028014, Final Batch Loss: 0.0005638794391416013\n",
      "Epoch 1455, Loss: 0.0006089967318985146, Final Batch Loss: 0.0004301816807128489\n",
      "Epoch 1456, Loss: 0.03617165132163791, Final Batch Loss: 0.0001090759105863981\n",
      "Epoch 1457, Loss: 0.0009729669254738837, Final Batch Loss: 0.00035366619704291224\n",
      "Epoch 1458, Loss: 0.001962817885214463, Final Batch Loss: 0.0013443288626149297\n",
      "Epoch 1459, Loss: 0.007614942034706473, Final Batch Loss: 0.0002222091134171933\n",
      "Epoch 1460, Loss: 0.007257736622705124, Final Batch Loss: 0.0008005820563994348\n",
      "Epoch 1461, Loss: 0.0029093935736455023, Final Batch Loss: 0.001615480869077146\n",
      "Epoch 1462, Loss: 0.001129132928326726, Final Batch Loss: 0.0004308528732508421\n",
      "Epoch 1463, Loss: 0.0012848586775362492, Final Batch Loss: 0.000852053752169013\n",
      "Epoch 1464, Loss: 0.0011589525383897126, Final Batch Loss: 0.0005389902507886291\n",
      "Epoch 1465, Loss: 0.011398406182706822, Final Batch Loss: 0.00011726382217602804\n",
      "Epoch 1466, Loss: 0.002262809910462238, Final Batch Loss: 0.0003396704269107431\n",
      "Epoch 1467, Loss: 0.0006712552421959117, Final Batch Loss: 0.00012439012061804533\n",
      "Epoch 1468, Loss: 0.0013482767681125551, Final Batch Loss: 0.0002470486506354064\n",
      "Epoch 1469, Loss: 0.00568757472501602, Final Batch Loss: 0.00028013362316414714\n",
      "Epoch 1470, Loss: 0.001455810521292733, Final Batch Loss: 0.0008146244217641652\n",
      "Epoch 1471, Loss: 0.004618663806468248, Final Batch Loss: 0.003219126258045435\n",
      "Epoch 1472, Loss: 0.008538196154404432, Final Batch Loss: 0.0007877130410633981\n",
      "Epoch 1473, Loss: 0.004260247980710119, Final Batch Loss: 0.0007278237608261406\n",
      "Epoch 1474, Loss: 0.0009327262741862796, Final Batch Loss: 0.0004637633101083338\n",
      "Epoch 1475, Loss: 0.0012022961745969951, Final Batch Loss: 0.0005312416469678283\n",
      "Epoch 1476, Loss: 0.01953382214924204, Final Batch Loss: 1.7989903426496312e-05\n",
      "Epoch 1477, Loss: 0.001272201247047633, Final Batch Loss: 0.00046747049782425165\n",
      "Epoch 1478, Loss: 0.0012071034725522622, Final Batch Loss: 0.00037263601552695036\n",
      "Epoch 1479, Loss: 0.0029068892472423613, Final Batch Loss: 0.0004932534648105502\n",
      "Epoch 1480, Loss: 0.0011709740938385949, Final Batch Loss: 0.00020935859356541187\n",
      "Epoch 1481, Loss: 0.004766349113197066, Final Batch Loss: 0.00419629504904151\n",
      "Epoch 1482, Loss: 0.0014954157668398693, Final Batch Loss: 0.000995689071714878\n",
      "Epoch 1483, Loss: 0.0015305809465644415, Final Batch Loss: 0.001156538724899292\n",
      "Epoch 1484, Loss: 0.007250257767736912, Final Batch Loss: 0.0006828006589785218\n",
      "Epoch 1485, Loss: 0.00970894230704289, Final Batch Loss: 0.0036744088865816593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1486, Loss: 0.0014786962783546187, Final Batch Loss: 0.0005729250842705369\n",
      "Epoch 1487, Loss: 0.003713080892339349, Final Batch Loss: 0.002485573524609208\n",
      "Epoch 1488, Loss: 0.0012277356727281585, Final Batch Loss: 0.0008471286273561418\n",
      "Epoch 1489, Loss: 0.0006379859405569732, Final Batch Loss: 0.00014298706082627177\n",
      "Epoch 1490, Loss: 0.01150044152745977, Final Batch Loss: 0.008265610784292221\n",
      "Epoch 1491, Loss: 0.0011695167049765587, Final Batch Loss: 8.650030940771103e-05\n",
      "Epoch 1492, Loss: 0.017591741852811538, Final Batch Loss: 0.017190802842378616\n",
      "Epoch 1493, Loss: 0.0005652711406582966, Final Batch Loss: 0.0001241450954694301\n",
      "Epoch 1494, Loss: 0.0005274995128274895, Final Batch Loss: 6.45613981760107e-05\n",
      "Epoch 1495, Loss: 0.0024823206185828894, Final Batch Loss: 0.0020350192207843065\n",
      "Epoch 1496, Loss: 0.0014071716577745974, Final Batch Loss: 0.00025390335940755904\n",
      "Epoch 1497, Loss: 0.017295821919105947, Final Batch Loss: 0.0004487511469051242\n",
      "Epoch 1498, Loss: 0.021576602739514783, Final Batch Loss: 0.00015236911713145673\n",
      "Epoch 1499, Loss: 0.0008122481376631185, Final Batch Loss: 0.00029510929016396403\n",
      "Epoch 1500, Loss: 0.009851888702542055, Final Batch Loss: 0.009431038051843643\n",
      "Epoch 1501, Loss: 0.001265647093532607, Final Batch Loss: 0.0001334701373707503\n",
      "Epoch 1502, Loss: 0.0018871286156354472, Final Batch Loss: 0.0004098618228454143\n",
      "Epoch 1503, Loss: 0.0033042052818927914, Final Batch Loss: 0.00048803703975863755\n",
      "Epoch 1504, Loss: 0.006545167081640102, Final Batch Loss: 0.0001511102163931355\n",
      "Epoch 1505, Loss: 0.0020245013874955475, Final Batch Loss: 0.00030371983302757144\n",
      "Epoch 1506, Loss: 0.00201891889446415, Final Batch Loss: 0.0002820064255502075\n",
      "Epoch 1507, Loss: 0.0006650860887020826, Final Batch Loss: 0.00014969492622185498\n",
      "Epoch 1508, Loss: 0.0015927915374049917, Final Batch Loss: 0.000290266121737659\n",
      "Epoch 1509, Loss: 0.0019113379166810773, Final Batch Loss: 0.0011212513782083988\n",
      "Epoch 1510, Loss: 0.005501751234987751, Final Batch Loss: 0.0003976835578214377\n",
      "Epoch 1511, Loss: 0.002554810547735542, Final Batch Loss: 0.0014167018234729767\n",
      "Epoch 1512, Loss: 0.0009331688925158232, Final Batch Loss: 0.000603316817432642\n",
      "Epoch 1513, Loss: 0.0010520578071009368, Final Batch Loss: 0.0002504723670426756\n",
      "Epoch 1514, Loss: 0.000891560543095693, Final Batch Loss: 0.00042342045344412327\n",
      "Epoch 1515, Loss: 0.0008976163080660626, Final Batch Loss: 0.00019769409846048802\n",
      "Epoch 1516, Loss: 0.0019679563920362853, Final Batch Loss: 0.0014678285224363208\n",
      "Epoch 1517, Loss: 0.026638477269443683, Final Batch Loss: 0.026059724390506744\n",
      "Epoch 1518, Loss: 0.0010758241842268035, Final Batch Loss: 0.0004264080780558288\n",
      "Epoch 1519, Loss: 0.001172271979157813, Final Batch Loss: 0.0001285465114051476\n",
      "Epoch 1520, Loss: 0.002561475121183321, Final Batch Loss: 0.0009833688382059336\n",
      "Epoch 1521, Loss: 0.020649025565944612, Final Batch Loss: 0.0024296166375279427\n",
      "Epoch 1522, Loss: 0.0027588176453718916, Final Batch Loss: 3.698783984873444e-05\n",
      "Epoch 1523, Loss: 0.0023005737457424402, Final Batch Loss: 0.0004974861512891948\n",
      "Epoch 1524, Loss: 0.0019277837709523737, Final Batch Loss: 0.0001487429835833609\n",
      "Epoch 1525, Loss: 0.006295050727203488, Final Batch Loss: 0.00020181603031232953\n",
      "Epoch 1526, Loss: 0.0011542775318957865, Final Batch Loss: 0.00015818775864318013\n",
      "Epoch 1527, Loss: 0.002315087942406535, Final Batch Loss: 0.0005038455128669739\n",
      "Epoch 1528, Loss: 0.0018855062662623823, Final Batch Loss: 0.0003444857429713011\n",
      "Epoch 1529, Loss: 0.0007639714604010805, Final Batch Loss: 0.00028436753200367093\n",
      "Epoch 1530, Loss: 0.0010845113065443002, Final Batch Loss: 0.0003552474663592875\n",
      "Epoch 1531, Loss: 0.002845373048330657, Final Batch Loss: 0.0026029229629784822\n",
      "Epoch 1532, Loss: 0.0014924452480045147, Final Batch Loss: 8.035888458834961e-05\n",
      "Epoch 1533, Loss: 0.0015766188589623198, Final Batch Loss: 0.00014132422802504152\n",
      "Epoch 1534, Loss: 0.003115388855803758, Final Batch Loss: 0.0004992880276404321\n",
      "Epoch 1535, Loss: 0.008918934719986282, Final Batch Loss: 0.0003739820094779134\n",
      "Epoch 1536, Loss: 0.007491466007195413, Final Batch Loss: 0.005760934203863144\n",
      "Epoch 1537, Loss: 0.0006719624943798408, Final Batch Loss: 0.00016353311366401613\n",
      "Epoch 1538, Loss: 0.008993574607302435, Final Batch Loss: 0.00019820888701360673\n",
      "Epoch 1539, Loss: 0.0063526727726639365, Final Batch Loss: 1.4927308257028926e-05\n",
      "Epoch 1540, Loss: 0.0007008141692494974, Final Batch Loss: 0.0002149782667402178\n",
      "Epoch 1541, Loss: 0.0010750935980468057, Final Batch Loss: 0.0008876643842086196\n",
      "Epoch 1542, Loss: 0.0021218134788796306, Final Batch Loss: 0.00033788610016927123\n",
      "Epoch 1543, Loss: 0.00048388007417088374, Final Batch Loss: 0.0003452491364441812\n",
      "Epoch 1544, Loss: 0.0008660468083689921, Final Batch Loss: 2.939046680694446e-05\n",
      "Epoch 1545, Loss: 0.017342977836960927, Final Batch Loss: 0.0002934597141575068\n",
      "Epoch 1546, Loss: 0.0009322696205344982, Final Batch Loss: 0.00011625319166341797\n",
      "Epoch 1547, Loss: 0.00042068836046382785, Final Batch Loss: 0.00017659473815001547\n",
      "Epoch 1548, Loss: 0.004932254880259279, Final Batch Loss: 0.0006358321406878531\n",
      "Epoch 1549, Loss: 0.0013485145900631323, Final Batch Loss: 0.0009959082817658782\n",
      "Epoch 1550, Loss: 0.0016690564370946959, Final Batch Loss: 0.0001314686523983255\n",
      "Epoch 1551, Loss: 0.0008396288176300004, Final Batch Loss: 0.0003862727608066052\n",
      "Epoch 1552, Loss: 0.03131640169885941, Final Batch Loss: 0.00010857744928216562\n",
      "Epoch 1553, Loss: 0.01861858493066393, Final Batch Loss: 0.0012174110161140561\n",
      "Epoch 1554, Loss: 0.0003344088327139616, Final Batch Loss: 8.9454602857586e-05\n",
      "Epoch 1555, Loss: 0.00043105064833071083, Final Batch Loss: 0.00012511831300798804\n",
      "Epoch 1556, Loss: 0.01587942741025472, Final Batch Loss: 9.352374036097899e-05\n",
      "Epoch 1557, Loss: 0.024586203977378318, Final Batch Loss: 4.2575706174829975e-05\n",
      "Epoch 1558, Loss: 0.0017977492680074647, Final Batch Loss: 0.00022346187324728817\n",
      "Epoch 1559, Loss: 0.0015674094029236585, Final Batch Loss: 0.0010336301056668162\n",
      "Epoch 1560, Loss: 0.0035068993165623397, Final Batch Loss: 0.002442317781969905\n",
      "Epoch 1561, Loss: 0.0025139430072158575, Final Batch Loss: 0.0003228912246413529\n",
      "Epoch 1562, Loss: 0.014858421112876385, Final Batch Loss: 0.011157592758536339\n",
      "Epoch 1563, Loss: 0.0038675050454912707, Final Batch Loss: 0.00017351230781059712\n",
      "Epoch 1564, Loss: 0.0011391356820240617, Final Batch Loss: 0.00030788284493610263\n",
      "Epoch 1565, Loss: 0.0006577201129402965, Final Batch Loss: 0.0002250677061965689\n",
      "Epoch 1566, Loss: 0.0017048997324309312, Final Batch Loss: 0.00010144951374968514\n",
      "Epoch 1567, Loss: 0.0006408714179997332, Final Batch Loss: 0.0002918298414442688\n",
      "Epoch 1568, Loss: 0.0011304326744721038, Final Batch Loss: 1.4057708540349267e-05\n",
      "Epoch 1569, Loss: 0.0019959493292844854, Final Batch Loss: 3.581321652745828e-05\n",
      "Epoch 1570, Loss: 0.0006388678011717275, Final Batch Loss: 0.00032537136576138437\n",
      "Epoch 1571, Loss: 0.00018333514435653342, Final Batch Loss: 1.1030623682017904e-05\n",
      "Epoch 1572, Loss: 0.00033524318132549524, Final Batch Loss: 1.3303098967298865e-05\n",
      "Epoch 1573, Loss: 0.004411992078530602, Final Batch Loss: 0.00019409818924032152\n",
      "Epoch 1574, Loss: 0.0009702398310764693, Final Batch Loss: 0.0005652139079757035\n",
      "Epoch 1575, Loss: 0.0006181372591527179, Final Batch Loss: 0.00039749883580952883\n",
      "Epoch 1576, Loss: 0.0009759516688063741, Final Batch Loss: 0.00041360591421835124\n",
      "Epoch 1577, Loss: 0.0571426821697969, Final Batch Loss: 0.056152213364839554\n",
      "Epoch 1578, Loss: 0.0011404433053030516, Final Batch Loss: 7.262674444064032e-06\n",
      "Epoch 1579, Loss: 0.006841050199000165, Final Batch Loss: 0.00018941625603474677\n",
      "Epoch 1580, Loss: 0.0007017361203907058, Final Batch Loss: 0.00015109356900211424\n",
      "Epoch 1581, Loss: 0.0011517402963363566, Final Batch Loss: 0.0003583999059628695\n",
      "Epoch 1582, Loss: 0.0004626432273653336, Final Batch Loss: 0.00010042163921752945\n",
      "Epoch 1583, Loss: 0.006385360826243414, Final Batch Loss: 3.104690040345304e-05\n",
      "Epoch 1584, Loss: 0.000485054224554915, Final Batch Loss: 6.297353684203699e-05\n",
      "Epoch 1585, Loss: 0.02387517520401161, Final Batch Loss: 0.00014479800302069634\n",
      "Epoch 1586, Loss: 0.0012148329769843258, Final Batch Loss: 9.531566320220008e-05\n",
      "Epoch 1587, Loss: 0.001049062906531617, Final Batch Loss: 0.00021906569600105286\n",
      "Epoch 1588, Loss: 0.00043382264266256243, Final Batch Loss: 0.00016108991985674948\n",
      "Epoch 1589, Loss: 0.007839063298888505, Final Batch Loss: 0.007525959517806768\n",
      "Epoch 1590, Loss: 0.00094870816974435, Final Batch Loss: 9.379636321682483e-05\n",
      "Epoch 1591, Loss: 0.0008826153789414093, Final Batch Loss: 0.0004352316027507186\n",
      "Epoch 1592, Loss: 0.0019060365430050297, Final Batch Loss: 1.6581381714786403e-05\n",
      "Epoch 1593, Loss: 0.0018922067829407752, Final Batch Loss: 0.00046953308628872037\n",
      "Epoch 1594, Loss: 0.004312326695071533, Final Batch Loss: 0.0002932370698545128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1595, Loss: 0.0011337721371091902, Final Batch Loss: 0.00013190422032494098\n",
      "Epoch 1596, Loss: 0.0006095035641919822, Final Batch Loss: 0.0003627218247856945\n",
      "Epoch 1597, Loss: 0.02351974364137277, Final Batch Loss: 0.00017607578774914145\n",
      "Epoch 1598, Loss: 0.0008791585423750803, Final Batch Loss: 0.0006323766428977251\n",
      "Epoch 1599, Loss: 0.0015499221626669168, Final Batch Loss: 0.00032592995557934046\n",
      "Epoch 1600, Loss: 0.0032191443315241486, Final Batch Loss: 0.00029938764055259526\n",
      "Epoch 1601, Loss: 0.0010241541531286202, Final Batch Loss: 6.193792069097981e-05\n",
      "Epoch 1602, Loss: 0.0033325664117000997, Final Batch Loss: 0.0006378821562975645\n",
      "Epoch 1603, Loss: 0.0006446793668146711, Final Batch Loss: 4.085067121195607e-05\n",
      "Epoch 1604, Loss: 0.0031471466354560107, Final Batch Loss: 0.0015591897536069155\n",
      "Epoch 1605, Loss: 0.022349642851622775, Final Batch Loss: 0.0003073708212468773\n",
      "Epoch 1606, Loss: 0.001451096948585473, Final Batch Loss: 0.0007957582711242139\n",
      "Epoch 1607, Loss: 0.0019543286034604535, Final Batch Loss: 0.001644632313400507\n",
      "Epoch 1608, Loss: 0.0008513341017533094, Final Batch Loss: 0.00038519661757163703\n",
      "Epoch 1609, Loss: 0.0010436036609462462, Final Batch Loss: 7.370905223069713e-05\n",
      "Epoch 1610, Loss: 0.001614693333976902, Final Batch Loss: 0.0002191211242461577\n",
      "Epoch 1611, Loss: 0.0009844789892667904, Final Batch Loss: 0.0004330050724092871\n",
      "Epoch 1612, Loss: 0.0010448083776282147, Final Batch Loss: 0.0003346061857882887\n",
      "Epoch 1613, Loss: 0.0005416431376943365, Final Batch Loss: 0.00021758867660537362\n",
      "Epoch 1614, Loss: 0.012113115255488083, Final Batch Loss: 0.011393238790333271\n",
      "Epoch 1615, Loss: 0.001435563142877072, Final Batch Loss: 0.0008402187959291041\n",
      "Epoch 1616, Loss: 0.0014217583593563177, Final Batch Loss: 0.00011390489089535549\n",
      "Epoch 1617, Loss: 0.001806936168577522, Final Batch Loss: 0.0011263852939009666\n",
      "Epoch 1618, Loss: 0.0008413241448579356, Final Batch Loss: 5.383060488384217e-05\n",
      "Epoch 1619, Loss: 0.0006687167769996449, Final Batch Loss: 0.00014241828466765583\n",
      "Epoch 1620, Loss: 0.0013527421106118709, Final Batch Loss: 0.0006733597838319838\n",
      "Epoch 1621, Loss: 0.00026623970916261896, Final Batch Loss: 3.593612927943468e-05\n",
      "Epoch 1622, Loss: 0.0012588856188813224, Final Batch Loss: 7.302350422833115e-05\n",
      "Epoch 1623, Loss: 0.0015854534576646984, Final Batch Loss: 0.0009370941552333534\n",
      "Epoch 1624, Loss: 0.0016582620155531913, Final Batch Loss: 0.0006582341738976538\n",
      "Epoch 1625, Loss: 0.003785380074987188, Final Batch Loss: 9.571130794938654e-05\n",
      "Epoch 1626, Loss: 0.01256828213809058, Final Batch Loss: 0.0004523051902651787\n",
      "Epoch 1627, Loss: 0.0007948208804009482, Final Batch Loss: 0.00017945784202311188\n",
      "Epoch 1628, Loss: 0.001741001702612266, Final Batch Loss: 0.0008846984128467739\n",
      "Epoch 1629, Loss: 0.0003505025160848163, Final Batch Loss: 9.460921137360856e-05\n",
      "Epoch 1630, Loss: 0.00867656446644105, Final Batch Loss: 0.0001944909308804199\n",
      "Epoch 1631, Loss: 0.0029238998831715435, Final Batch Loss: 0.0006228650454431772\n",
      "Epoch 1632, Loss: 0.009898343749227934, Final Batch Loss: 0.00954379327595234\n",
      "Epoch 1633, Loss: 0.001037701360473875, Final Batch Loss: 6.280474190134555e-05\n",
      "Epoch 1634, Loss: 0.0027104081527795643, Final Batch Loss: 0.00023297881125472486\n",
      "Epoch 1635, Loss: 0.001870988155133091, Final Batch Loss: 0.00021609895338770002\n",
      "Epoch 1636, Loss: 0.0009238268539775163, Final Batch Loss: 0.00030027146567590535\n",
      "Epoch 1637, Loss: 0.031036445288918912, Final Batch Loss: 0.00021826043666806072\n",
      "Epoch 1638, Loss: 0.0006350512849166989, Final Batch Loss: 0.0003665516269393265\n",
      "Epoch 1639, Loss: 0.001472936746722553, Final Batch Loss: 8.021292160265148e-05\n",
      "Epoch 1640, Loss: 0.0008179881551768631, Final Batch Loss: 0.00010418076999485493\n",
      "Epoch 1641, Loss: 0.00398907841736218, Final Batch Loss: 0.0031617511995136738\n",
      "Epoch 1642, Loss: 0.0005895596023037797, Final Batch Loss: 2.804425275826361e-05\n",
      "Epoch 1643, Loss: 0.0005715215738746338, Final Batch Loss: 8.731593698030338e-05\n",
      "Epoch 1644, Loss: 0.0005217620200710371, Final Batch Loss: 5.179652362130582e-06\n",
      "Epoch 1645, Loss: 0.0036070367350475863, Final Batch Loss: 0.0028486656956374645\n",
      "Epoch 1646, Loss: 0.004744862691950402, Final Batch Loss: 2.9915658160462044e-05\n",
      "Epoch 1647, Loss: 0.0004979041041224264, Final Batch Loss: 0.00031885565840639174\n",
      "Epoch 1648, Loss: 0.0005288684442348313, Final Batch Loss: 0.00018677480693440884\n",
      "Epoch 1649, Loss: 0.01928342731844168, Final Batch Loss: 0.018890896812081337\n",
      "Epoch 1650, Loss: 0.0014436655728786718, Final Batch Loss: 4.7927573177730665e-05\n",
      "Epoch 1651, Loss: 0.00036321638617664576, Final Batch Loss: 0.00017501425463706255\n",
      "Epoch 1652, Loss: 0.0006590359225810971, Final Batch Loss: 2.2021562472218648e-05\n",
      "Epoch 1653, Loss: 0.0022150377626530826, Final Batch Loss: 0.00018761874525807798\n",
      "Epoch 1654, Loss: 0.00027148009394295514, Final Batch Loss: 7.771178206894547e-05\n",
      "Epoch 1655, Loss: 0.011204046197235584, Final Batch Loss: 0.0016576875932514668\n",
      "Epoch 1656, Loss: 0.006033049943653168, Final Batch Loss: 3.331494008307345e-05\n",
      "Epoch 1657, Loss: 0.023196621899842285, Final Batch Loss: 0.00021057431877125055\n",
      "Epoch 1658, Loss: 0.0067037526168860495, Final Batch Loss: 0.005807482637465\n",
      "Epoch 1659, Loss: 0.0006931064199307002, Final Batch Loss: 5.8892292145174e-05\n",
      "Epoch 1660, Loss: 0.0006790541556256358, Final Batch Loss: 3.112743070232682e-05\n",
      "Epoch 1661, Loss: 0.002278921863762662, Final Batch Loss: 0.0005485864239744842\n",
      "Epoch 1662, Loss: 0.002453874360071495, Final Batch Loss: 0.00048478200915269554\n",
      "Epoch 1663, Loss: 0.00857730963616632, Final Batch Loss: 0.0003180614148732275\n",
      "Epoch 1664, Loss: 0.012866685168773984, Final Batch Loss: 1.7906773791764863e-05\n",
      "Epoch 1665, Loss: 0.0013161897732061334, Final Batch Loss: 5.0518639909569174e-05\n",
      "Epoch 1666, Loss: 0.030583381827455014, Final Batch Loss: 0.030070923268795013\n",
      "Epoch 1667, Loss: 0.008447221167443786, Final Batch Loss: 0.00018541360623203218\n",
      "Epoch 1668, Loss: 0.0048447084409417585, Final Batch Loss: 9.209239215124398e-05\n",
      "Epoch 1669, Loss: 0.0033296663459623232, Final Batch Loss: 0.000206583077670075\n",
      "Epoch 1670, Loss: 0.0008562452785554342, Final Batch Loss: 0.00066942791454494\n",
      "Epoch 1671, Loss: 0.009590718444087543, Final Batch Loss: 0.0001624780270503834\n",
      "Epoch 1672, Loss: 0.0008499775576638058, Final Batch Loss: 5.212779069552198e-05\n",
      "Epoch 1673, Loss: 0.003322526936244685, Final Batch Loss: 0.0028892874252051115\n",
      "Epoch 1674, Loss: 0.0020224323125148658, Final Batch Loss: 3.0525177862728015e-05\n",
      "Epoch 1675, Loss: 0.0019039783510379493, Final Batch Loss: 0.00019200140377506614\n",
      "Epoch 1676, Loss: 0.007444890565238893, Final Batch Loss: 0.006664693355560303\n",
      "Epoch 1677, Loss: 0.012886693599284627, Final Batch Loss: 0.011634798720479012\n",
      "Epoch 1678, Loss: 0.001382545604428742, Final Batch Loss: 0.00010029535769717768\n",
      "Epoch 1679, Loss: 0.002135478294803761, Final Batch Loss: 0.0005650376551784575\n",
      "Epoch 1680, Loss: 0.0023395525058731437, Final Batch Loss: 0.0003352179774083197\n",
      "Epoch 1681, Loss: 0.0006988468230701983, Final Batch Loss: 0.0001382599730277434\n",
      "Epoch 1682, Loss: 0.024774111050646752, Final Batch Loss: 0.0002532017242629081\n",
      "Epoch 1683, Loss: 0.0011001761668012477, Final Batch Loss: 8.453845657641068e-05\n",
      "Epoch 1684, Loss: 0.0013750878279097378, Final Batch Loss: 0.00020066311117261648\n",
      "Epoch 1685, Loss: 0.0010775768023449928, Final Batch Loss: 0.0001331134990323335\n",
      "Epoch 1686, Loss: 0.0013826116282871226, Final Batch Loss: 2.4906878024921753e-05\n",
      "Epoch 1687, Loss: 0.006005315051879734, Final Batch Loss: 0.0038875178433954716\n",
      "Epoch 1688, Loss: 0.0030669821426272392, Final Batch Loss: 0.0014577617403119802\n",
      "Epoch 1689, Loss: 0.0005753993318649009, Final Batch Loss: 0.00016775800031609833\n",
      "Epoch 1690, Loss: 0.028043593803886324, Final Batch Loss: 0.026784203946590424\n",
      "Epoch 1691, Loss: 0.0011420153023209423, Final Batch Loss: 0.0003308746963739395\n",
      "Epoch 1692, Loss: 0.0006517452275147662, Final Batch Loss: 4.8867499572224915e-05\n",
      "Epoch 1693, Loss: 0.0008579746063333005, Final Batch Loss: 0.00022986243129707873\n",
      "Epoch 1694, Loss: 0.004425810620887205, Final Batch Loss: 0.0013372439425438643\n",
      "Epoch 1695, Loss: 0.0011961835552938282, Final Batch Loss: 0.0004053500888403505\n",
      "Epoch 1696, Loss: 0.0013033548748353496, Final Batch Loss: 0.00030816750950179994\n",
      "Epoch 1697, Loss: 0.0007651339983567595, Final Batch Loss: 0.00020146320457570255\n",
      "Epoch 1698, Loss: 0.004313548197387718, Final Batch Loss: 0.00011687293590512127\n",
      "Epoch 1699, Loss: 0.001109237280616071, Final Batch Loss: 0.00011604345490923151\n",
      "Epoch 1700, Loss: 0.0020433639001566917, Final Batch Loss: 0.0012128424132242799\n",
      "Epoch 1701, Loss: 0.0005451405704661738, Final Batch Loss: 1.7989801563089713e-05\n",
      "Epoch 1702, Loss: 0.0007479975029127672, Final Batch Loss: 0.00018327555153518915\n",
      "Epoch 1703, Loss: 0.0011257063451921567, Final Batch Loss: 0.0005330226849764585\n",
      "Epoch 1704, Loss: 0.0020544738799799234, Final Batch Loss: 0.00131559232249856\n",
      "Epoch 1705, Loss: 0.0008348871051566675, Final Batch Loss: 0.00019630351744126529\n",
      "Epoch 1706, Loss: 0.02167985003325157, Final Batch Loss: 0.002269062679260969\n",
      "Epoch 1707, Loss: 0.004382618717500009, Final Batch Loss: 0.0001402060006512329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1708, Loss: 0.0007885994564276189, Final Batch Loss: 0.00032032286981120706\n",
      "Epoch 1709, Loss: 0.0010290104983141646, Final Batch Loss: 0.00019742549920920283\n",
      "Epoch 1710, Loss: 0.0030141945753712207, Final Batch Loss: 0.0003393868391867727\n",
      "Epoch 1711, Loss: 0.002581530890893191, Final Batch Loss: 0.0003008682979270816\n",
      "Epoch 1712, Loss: 0.0008000981179066002, Final Batch Loss: 0.00019307729962747544\n",
      "Epoch 1713, Loss: 0.0015165452496148646, Final Batch Loss: 0.0005147428018972278\n",
      "Epoch 1714, Loss: 0.0006771692005713703, Final Batch Loss: 2.4314083930221386e-05\n",
      "Epoch 1715, Loss: 0.0050028675905196, Final Batch Loss: 0.004485142417252064\n",
      "Epoch 1716, Loss: 0.0009687568817753345, Final Batch Loss: 0.00019772090308833867\n",
      "Epoch 1717, Loss: 0.0004200294497422874, Final Batch Loss: 0.00022939736663829535\n",
      "Epoch 1718, Loss: 0.0006710060442856047, Final Batch Loss: 5.319348201737739e-05\n",
      "Epoch 1719, Loss: 0.0013759507128270343, Final Batch Loss: 0.0002462397387716919\n",
      "Epoch 1720, Loss: 0.00039611802276340313, Final Batch Loss: 2.9970229661557823e-05\n",
      "Epoch 1721, Loss: 0.02083629317348823, Final Batch Loss: 0.019713522866368294\n",
      "Epoch 1722, Loss: 0.002142596582416445, Final Batch Loss: 0.0007590993773192167\n",
      "Epoch 1723, Loss: 0.0006445684703066945, Final Batch Loss: 4.1540508391335607e-05\n",
      "Epoch 1724, Loss: 0.023316936949413503, Final Batch Loss: 5.453397534438409e-05\n",
      "Epoch 1725, Loss: 0.002353932519326918, Final Batch Loss: 0.00015346908185165375\n",
      "Epoch 1726, Loss: 0.0010040360284619965, Final Batch Loss: 0.00032197294058278203\n",
      "Epoch 1727, Loss: 0.004523175768554211, Final Batch Loss: 0.0009243916720151901\n",
      "Epoch 1728, Loss: 0.0023017332568997517, Final Batch Loss: 0.00036654583527706563\n",
      "Epoch 1729, Loss: 0.0032512069155927747, Final Batch Loss: 0.0006575954612344503\n",
      "Epoch 1730, Loss: 0.0009266746928915381, Final Batch Loss: 0.00016661913832649589\n",
      "Epoch 1731, Loss: 0.055159550058306195, Final Batch Loss: 0.03923283517360687\n",
      "Epoch 1732, Loss: 0.0016103455564007163, Final Batch Loss: 0.0003303450648672879\n",
      "Epoch 1733, Loss: 0.0018014754023170099, Final Batch Loss: 0.0013703095028176904\n",
      "Epoch 1734, Loss: 0.0025085385859711096, Final Batch Loss: 0.0017572179203853011\n",
      "Epoch 1735, Loss: 0.0005259565587039106, Final Batch Loss: 0.0001063955933204852\n",
      "Epoch 1736, Loss: 0.0026593790971674025, Final Batch Loss: 0.0005110598285682499\n",
      "Epoch 1737, Loss: 0.0011946116428589448, Final Batch Loss: 0.00015887264453340322\n",
      "Epoch 1738, Loss: 0.003810147834883537, Final Batch Loss: 8.695446740603074e-05\n",
      "Epoch 1739, Loss: 0.000734625784389209, Final Batch Loss: 6.302819383563474e-05\n",
      "Epoch 1740, Loss: 0.007401892391499132, Final Batch Loss: 0.003106300486251712\n",
      "Epoch 1741, Loss: 0.0081892157177208, Final Batch Loss: 0.007974468171596527\n",
      "Epoch 1742, Loss: 0.0029560116672655568, Final Batch Loss: 0.0015076330164447427\n",
      "Epoch 1743, Loss: 0.0012376719387248158, Final Batch Loss: 0.0003351770283188671\n",
      "Epoch 1744, Loss: 0.0008548129771952517, Final Batch Loss: 0.000544591573998332\n",
      "Epoch 1745, Loss: 0.0015448286576429382, Final Batch Loss: 0.0005804919055663049\n",
      "Epoch 1746, Loss: 0.0032659308635629714, Final Batch Loss: 0.0003559788747224957\n",
      "Epoch 1747, Loss: 0.004497149733651895, Final Batch Loss: 0.0006813023937866092\n",
      "Epoch 1748, Loss: 0.0015824282891117036, Final Batch Loss: 0.00066832744050771\n",
      "Epoch 1749, Loss: 0.0010837192239705473, Final Batch Loss: 0.0007346026250161231\n",
      "Epoch 1750, Loss: 0.0019271798082627356, Final Batch Loss: 0.0011455519124865532\n",
      "Epoch 1751, Loss: 0.0020584482117556036, Final Batch Loss: 0.0003902634489350021\n",
      "Epoch 1752, Loss: 0.0013275772507768124, Final Batch Loss: 0.0011529000476002693\n",
      "Epoch 1753, Loss: 0.0014776336029171944, Final Batch Loss: 0.0009247533744201064\n",
      "Epoch 1754, Loss: 0.0012963821936864406, Final Batch Loss: 0.00034539971966296434\n",
      "Epoch 1755, Loss: 0.0011765826056944206, Final Batch Loss: 0.00016037726891227067\n",
      "Epoch 1756, Loss: 0.006621328575420193, Final Batch Loss: 0.002873844001442194\n",
      "Epoch 1757, Loss: 0.0014761043566977605, Final Batch Loss: 8.284240902867168e-05\n",
      "Epoch 1758, Loss: 0.0008065182046266273, Final Batch Loss: 0.000593656615819782\n",
      "Epoch 1759, Loss: 0.003709256838192232, Final Batch Loss: 0.0001233487419085577\n",
      "Epoch 1760, Loss: 0.0028051083208993077, Final Batch Loss: 0.0012385600712150335\n",
      "Epoch 1761, Loss: 0.0005672966653946787, Final Batch Loss: 0.000297906604828313\n",
      "Epoch 1762, Loss: 0.0006421616271836683, Final Batch Loss: 0.0001276917028008029\n",
      "Epoch 1763, Loss: 0.002462790420395322, Final Batch Loss: 0.0002099591220030561\n",
      "Epoch 1764, Loss: 0.001821971916797338, Final Batch Loss: 2.7227255486650392e-05\n",
      "Epoch 1765, Loss: 0.0012481032899813727, Final Batch Loss: 0.0008218384464271367\n",
      "Epoch 1766, Loss: 0.03232506744097918, Final Batch Loss: 0.0005918170791119337\n",
      "Epoch 1767, Loss: 0.001012975350022316, Final Batch Loss: 0.0007988843717612326\n",
      "Epoch 1768, Loss: 0.009562382198055275, Final Batch Loss: 0.006120542995631695\n",
      "Epoch 1769, Loss: 0.0007941718067741022, Final Batch Loss: 0.00013138186477590352\n",
      "Epoch 1770, Loss: 0.01287877511640545, Final Batch Loss: 0.00044991017784923315\n",
      "Epoch 1771, Loss: 0.0027922396548092365, Final Batch Loss: 0.0009464070899412036\n",
      "Epoch 1772, Loss: 0.0015068329812493175, Final Batch Loss: 0.0009070655214600265\n",
      "Epoch 1773, Loss: 0.0010156801872653887, Final Batch Loss: 0.0007759626023471355\n",
      "Epoch 1774, Loss: 0.005090811529953498, Final Batch Loss: 0.004506698809564114\n",
      "Epoch 1775, Loss: 0.0005444449780043215, Final Batch Loss: 0.00022935470042284578\n",
      "Epoch 1776, Loss: 0.0011604471656028181, Final Batch Loss: 0.0005110508645884693\n",
      "Epoch 1777, Loss: 0.006376091740094125, Final Batch Loss: 0.0003692471073009074\n",
      "Epoch 1778, Loss: 0.0013284373781061731, Final Batch Loss: 8.465264545520768e-05\n",
      "Epoch 1779, Loss: 0.0012969454255653545, Final Batch Loss: 0.0002093973889714107\n",
      "Epoch 1780, Loss: 0.002277366482303478, Final Batch Loss: 0.00015468864876311272\n",
      "Epoch 1781, Loss: 0.0011024061968782917, Final Batch Loss: 0.0001353157713310793\n",
      "Epoch 1782, Loss: 0.005142760594026186, Final Batch Loss: 0.004679643549025059\n",
      "Epoch 1783, Loss: 0.002950106885691639, Final Batch Loss: 0.0026415714528411627\n",
      "Epoch 1784, Loss: 0.0009356383525300771, Final Batch Loss: 0.00035137878148816526\n",
      "Epoch 1785, Loss: 0.0014136029785731807, Final Batch Loss: 0.00017069910245481879\n",
      "Epoch 1786, Loss: 0.0013683698634849861, Final Batch Loss: 0.00014812707377132028\n",
      "Epoch 1787, Loss: 0.0005377478155423887, Final Batch Loss: 7.901353092165664e-05\n",
      "Epoch 1788, Loss: 0.00460658289375715, Final Batch Loss: 0.00025849801022559404\n",
      "Epoch 1789, Loss: 0.0017851082375273108, Final Batch Loss: 0.0007828487432561815\n",
      "Epoch 1790, Loss: 0.008990272381197428, Final Batch Loss: 6.0403919633245096e-05\n",
      "Epoch 1791, Loss: 0.0007469598349416628, Final Batch Loss: 0.00011667465150821954\n",
      "Epoch 1792, Loss: 0.005986553325783461, Final Batch Loss: 0.00010751650552265346\n",
      "Epoch 1793, Loss: 0.0033506117179058492, Final Batch Loss: 0.0021326260175555944\n",
      "Epoch 1794, Loss: 0.0018838859687093645, Final Batch Loss: 0.0005505975568667054\n",
      "Epoch 1795, Loss: 0.0013236760787549429, Final Batch Loss: 9.487408533459529e-05\n",
      "Epoch 1796, Loss: 0.0010932492659776472, Final Batch Loss: 9.439477435080335e-05\n",
      "Epoch 1797, Loss: 0.0022845197599963285, Final Batch Loss: 0.0013215860817581415\n",
      "Epoch 1798, Loss: 0.001157511753262952, Final Batch Loss: 0.0009407153120264411\n",
      "Epoch 1799, Loss: 0.001389097422361374, Final Batch Loss: 0.000256126222666353\n",
      "Epoch 1800, Loss: 0.0002878036320907995, Final Batch Loss: 3.775677760131657e-05\n",
      "Epoch 1801, Loss: 0.0007030788983684033, Final Batch Loss: 0.00025709884357638657\n",
      "Epoch 1802, Loss: 0.003175419522449374, Final Batch Loss: 0.0005989138735458255\n",
      "Epoch 1803, Loss: 0.0018038444250123575, Final Batch Loss: 0.00028453022241592407\n",
      "Epoch 1804, Loss: 0.0006181018543429673, Final Batch Loss: 8.051839540712535e-05\n",
      "Epoch 1805, Loss: 0.001462399923184421, Final Batch Loss: 0.0010612175101414323\n",
      "Epoch 1806, Loss: 0.005291999768815003, Final Batch Loss: 0.0018593285931274295\n",
      "Epoch 1807, Loss: 0.000413477322581457, Final Batch Loss: 0.00023241605958901346\n",
      "Epoch 1808, Loss: 0.0011066404404118657, Final Batch Loss: 0.0007219284307211637\n",
      "Epoch 1809, Loss: 0.0006192888722580392, Final Batch Loss: 3.173265213263221e-05\n",
      "Epoch 1810, Loss: 0.004702912716311403, Final Batch Loss: 0.00036886954330839217\n",
      "Epoch 1811, Loss: 0.0015061673111631535, Final Batch Loss: 9.251765732187778e-05\n",
      "Epoch 1812, Loss: 0.00019516277097864076, Final Batch Loss: 5.510108167072758e-05\n",
      "Epoch 1813, Loss: 0.0034002245229203254, Final Batch Loss: 0.0004470605053938925\n",
      "Epoch 1814, Loss: 0.0005765568494098261, Final Batch Loss: 0.0002578754210844636\n",
      "Epoch 1815, Loss: 0.0008226003556046635, Final Batch Loss: 0.00013983910321258008\n",
      "Epoch 1816, Loss: 0.001477061174227856, Final Batch Loss: 0.0003148906980641186\n",
      "Epoch 1817, Loss: 0.0020155131933279335, Final Batch Loss: 0.0006368677131831646\n",
      "Epoch 1818, Loss: 0.001067319797584787, Final Batch Loss: 7.211670163087547e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1819, Loss: 0.04568023528554477, Final Batch Loss: 0.0444464311003685\n",
      "Epoch 1820, Loss: 0.00064463222224731, Final Batch Loss: 0.00019220841932110488\n",
      "Epoch 1821, Loss: 0.0017137682880274951, Final Batch Loss: 6.149039836600423e-05\n",
      "Epoch 1822, Loss: 0.0028490305885497946, Final Batch Loss: 2.1877178369322792e-05\n",
      "Epoch 1823, Loss: 0.0020648776117013767, Final Batch Loss: 0.00016611347382422537\n",
      "Epoch 1824, Loss: 0.0005633846812997945, Final Batch Loss: 0.00014031918544787914\n",
      "Epoch 1825, Loss: 0.0017365570092806593, Final Batch Loss: 0.00024198043684009463\n",
      "Epoch 1826, Loss: 0.0006693262330372818, Final Batch Loss: 0.0004890609998255968\n",
      "Epoch 1827, Loss: 0.0009510450690868311, Final Batch Loss: 0.0007404712378047407\n",
      "Epoch 1828, Loss: 0.006801496347179636, Final Batch Loss: 0.00013140271767042577\n",
      "Epoch 1829, Loss: 0.0024115174310281873, Final Batch Loss: 0.0012035378022119403\n",
      "Epoch 1830, Loss: 0.0009857741915766383, Final Batch Loss: 7.866032319725491e-06\n",
      "Epoch 1831, Loss: 0.0012092470933566801, Final Batch Loss: 0.0008520230185240507\n",
      "Epoch 1832, Loss: 0.011528458475368097, Final Batch Loss: 0.010469770058989525\n",
      "Epoch 1833, Loss: 0.000732389173208503, Final Batch Loss: 0.00013758869317825884\n",
      "Epoch 1834, Loss: 0.0028460248868213966, Final Batch Loss: 0.00010420611943118274\n",
      "Epoch 1835, Loss: 0.0004246337484801188, Final Batch Loss: 7.142250979086384e-05\n",
      "Epoch 1836, Loss: 0.0005870598761248402, Final Batch Loss: 3.618835035013035e-05\n",
      "Epoch 1837, Loss: 0.014186565233103465, Final Batch Loss: 0.0006284028058871627\n",
      "Epoch 1838, Loss: 0.0008797402988420799, Final Batch Loss: 0.0002972752845380455\n",
      "Epoch 1839, Loss: 0.002725808066315949, Final Batch Loss: 0.002023369772359729\n",
      "Epoch 1840, Loss: 0.0007522305204474833, Final Batch Loss: 0.0006336430669762194\n",
      "Epoch 1841, Loss: 0.016136613965500146, Final Batch Loss: 0.00047971290769055486\n",
      "Epoch 1842, Loss: 0.0037667876458726823, Final Batch Loss: 0.001427341834641993\n",
      "Epoch 1843, Loss: 0.0024633365392219275, Final Batch Loss: 0.0005648115766234696\n",
      "Epoch 1844, Loss: 0.007384876167634502, Final Batch Loss: 0.00011384839308448136\n",
      "Epoch 1845, Loss: 0.0013066912506474182, Final Batch Loss: 0.0009503926848992705\n",
      "Epoch 1846, Loss: 0.0008234242923208512, Final Batch Loss: 0.00014638992433901876\n",
      "Epoch 1847, Loss: 0.002292796183610335, Final Batch Loss: 0.00017252573161385953\n",
      "Epoch 1848, Loss: 0.0005670265236403793, Final Batch Loss: 0.0002581356093287468\n",
      "Epoch 1849, Loss: 0.0007445138107868843, Final Batch Loss: 7.071088475640863e-05\n",
      "Epoch 1850, Loss: 0.0012998307720408775, Final Batch Loss: 4.3689484300557524e-05\n",
      "Epoch 1851, Loss: 0.0019939433404942974, Final Batch Loss: 0.0008594846585765481\n",
      "Epoch 1852, Loss: 0.062240779094281606, Final Batch Loss: 0.06194593384861946\n",
      "Epoch 1853, Loss: 0.005852951973793097, Final Batch Loss: 8.371139119844884e-05\n",
      "Epoch 1854, Loss: 0.0006354447250487283, Final Batch Loss: 4.217780951876193e-05\n",
      "Epoch 1855, Loss: 0.0012188745822641067, Final Batch Loss: 0.00011290981638012454\n",
      "Epoch 1856, Loss: 0.00048272677304339595, Final Batch Loss: 0.0002718196192290634\n",
      "Epoch 1857, Loss: 0.00178584543755278, Final Batch Loss: 0.0007885611848905683\n",
      "Epoch 1858, Loss: 0.017623748077312484, Final Batch Loss: 0.01624867506325245\n",
      "Epoch 1859, Loss: 0.014250459615141153, Final Batch Loss: 0.012180956080555916\n",
      "Epoch 1860, Loss: 0.0014024851006979588, Final Batch Loss: 5.738967229262926e-05\n",
      "Epoch 1861, Loss: 0.009025982108141761, Final Batch Loss: 0.00011189304495928809\n",
      "Epoch 1862, Loss: 0.0005036333386669867, Final Batch Loss: 8.916129445424303e-05\n",
      "Epoch 1863, Loss: 0.0007424533105222508, Final Batch Loss: 0.00015682721277698874\n",
      "Epoch 1864, Loss: 0.0026670156585169025, Final Batch Loss: 0.0014788146363571286\n",
      "Epoch 1865, Loss: 0.0009105880744755268, Final Batch Loss: 0.0002942662686109543\n",
      "Epoch 1866, Loss: 0.0006934131233720109, Final Batch Loss: 0.00033675754093565047\n",
      "Epoch 1867, Loss: 0.0006645004541496746, Final Batch Loss: 0.00043900831951759756\n",
      "Epoch 1868, Loss: 0.0016546939295949414, Final Batch Loss: 0.00010866836237255484\n",
      "Epoch 1869, Loss: 0.0006604011723538861, Final Batch Loss: 0.00019642927509266883\n",
      "Epoch 1870, Loss: 0.0035820396660710685, Final Batch Loss: 3.309223029646091e-05\n",
      "Epoch 1871, Loss: 0.0009641236974857748, Final Batch Loss: 0.0003850968205370009\n",
      "Epoch 1872, Loss: 0.0013467017743096221, Final Batch Loss: 0.00015823285502847284\n",
      "Epoch 1873, Loss: 0.0007883756479714066, Final Batch Loss: 4.497585177887231e-05\n",
      "Epoch 1874, Loss: 0.0012838265975005925, Final Batch Loss: 0.000679357151966542\n",
      "Epoch 1875, Loss: 0.018867796461563557, Final Batch Loss: 0.01786818541586399\n",
      "Epoch 1876, Loss: 0.0023442342499038205, Final Batch Loss: 0.001242165919393301\n",
      "Epoch 1877, Loss: 0.0011796283833973575, Final Batch Loss: 0.0008819761569611728\n",
      "Epoch 1878, Loss: 0.002086504449835047, Final Batch Loss: 0.0016240598633885384\n",
      "Epoch 1879, Loss: 0.0011195288170711137, Final Batch Loss: 0.0008782439981587231\n",
      "Epoch 1880, Loss: 0.001428531072633632, Final Batch Loss: 1.3611727808893193e-05\n",
      "Epoch 1881, Loss: 0.0006131623667897657, Final Batch Loss: 5.426745337899774e-05\n",
      "Epoch 1882, Loss: 0.000776421875343658, Final Batch Loss: 1.7906480934470892e-05\n",
      "Epoch 1883, Loss: 0.0005022308832849376, Final Batch Loss: 5.942138523096219e-05\n",
      "Epoch 1884, Loss: 0.004199463946861215, Final Batch Loss: 0.00020646961638703942\n",
      "Epoch 1885, Loss: 0.0009652384542278014, Final Batch Loss: 0.0003939350717701018\n",
      "Epoch 1886, Loss: 0.0005964808078715578, Final Batch Loss: 0.0002130362845491618\n",
      "Epoch 1887, Loss: 0.0005010729510104284, Final Batch Loss: 0.0003313806082587689\n",
      "Epoch 1888, Loss: 0.0012994123244425282, Final Batch Loss: 0.0004692969669122249\n",
      "Epoch 1889, Loss: 0.001777075813151896, Final Batch Loss: 0.0006151289562694728\n",
      "Epoch 1890, Loss: 0.04227666259976104, Final Batch Loss: 0.0006599211483262479\n",
      "Epoch 1891, Loss: 0.0017001550004351884, Final Batch Loss: 0.00020851829322054982\n",
      "Epoch 1892, Loss: 0.006112458810093813, Final Batch Loss: 0.00553018506616354\n",
      "Epoch 1893, Loss: 0.0003932785984943621, Final Batch Loss: 4.614781209966168e-05\n",
      "Epoch 1894, Loss: 0.0026955404464388266, Final Batch Loss: 0.0005147447227500379\n",
      "Epoch 1895, Loss: 0.05172298896650318, Final Batch Loss: 0.019882677122950554\n",
      "Epoch 1896, Loss: 0.0009844908927334473, Final Batch Loss: 0.000747538753785193\n",
      "Epoch 1897, Loss: 0.0004055921017425135, Final Batch Loss: 0.00014651780657004565\n",
      "Epoch 1898, Loss: 0.0006371002455125563, Final Batch Loss: 0.00016551352746319026\n",
      "Epoch 1899, Loss: 0.0025659889652160928, Final Batch Loss: 0.0010194688802585006\n",
      "Epoch 1900, Loss: 0.0014199760335031897, Final Batch Loss: 0.0002488869067747146\n",
      "Epoch 1901, Loss: 0.0011622371421253774, Final Batch Loss: 0.0003508283116389066\n",
      "Epoch 1902, Loss: 0.000657688950013835, Final Batch Loss: 9.916965063894168e-05\n",
      "Epoch 1903, Loss: 0.027119926831801422, Final Batch Loss: 0.026536280289292336\n",
      "Epoch 1904, Loss: 0.002148456551367417, Final Batch Loss: 0.001107230898924172\n",
      "Epoch 1905, Loss: 0.016228332809987478, Final Batch Loss: 0.00013469990517478436\n",
      "Epoch 1906, Loss: 0.0010447654203744605, Final Batch Loss: 0.00034962152130901814\n",
      "Epoch 1907, Loss: 0.02009621424076613, Final Batch Loss: 0.0010977665660902858\n",
      "Epoch 1908, Loss: 0.005389796424424276, Final Batch Loss: 0.004241371061652899\n",
      "Epoch 1909, Loss: 0.020960429741535336, Final Batch Loss: 0.00020747602684423327\n",
      "Epoch 1910, Loss: 0.046795391288469546, Final Batch Loss: 0.0017858791397884488\n",
      "Epoch 1911, Loss: 0.0010853207495529205, Final Batch Loss: 0.00039471685886383057\n",
      "Epoch 1912, Loss: 0.0004065793727932032, Final Batch Loss: 0.0003292352776043117\n",
      "Epoch 1913, Loss: 0.007716746840742417, Final Batch Loss: 6.219329952728003e-05\n",
      "Epoch 1914, Loss: 0.0019242739290348254, Final Batch Loss: 6.460033910116181e-05\n",
      "Epoch 1915, Loss: 0.0020452348107937723, Final Batch Loss: 0.0010022014612331986\n",
      "Epoch 1916, Loss: 0.0019890708645107225, Final Batch Loss: 0.00036334304604679346\n",
      "Epoch 1917, Loss: 0.0005210848612478003, Final Batch Loss: 0.00022933476429898292\n",
      "Epoch 1918, Loss: 0.004220209732011426, Final Batch Loss: 0.004043173044919968\n",
      "Epoch 1919, Loss: 0.003689993522129953, Final Batch Loss: 0.003303159959614277\n",
      "Epoch 1920, Loss: 0.0014350926721817814, Final Batch Loss: 0.0008605093462392688\n",
      "Epoch 1921, Loss: 0.0010832191910594702, Final Batch Loss: 0.0003702515678014606\n",
      "Epoch 1922, Loss: 0.0021653844451066107, Final Batch Loss: 0.0011361624347046018\n",
      "Epoch 1923, Loss: 0.0006753693305654451, Final Batch Loss: 0.000310809031361714\n",
      "Epoch 1924, Loss: 0.014986828857217915, Final Batch Loss: 0.00011964088480453938\n",
      "Epoch 1925, Loss: 0.0014944466820452362, Final Batch Loss: 0.0005598089192062616\n",
      "Epoch 1926, Loss: 0.0008669879171065986, Final Batch Loss: 0.00032806998933665454\n",
      "Epoch 1927, Loss: 0.002343091502552852, Final Batch Loss: 0.0006651128060184419\n",
      "Epoch 1928, Loss: 0.0009497734718024731, Final Batch Loss: 0.0007657140376977623\n",
      "Epoch 1929, Loss: 0.001244914106791839, Final Batch Loss: 0.0005208845250308514\n",
      "Epoch 1930, Loss: 0.0012153701463830657, Final Batch Loss: 9.138050518231466e-05\n",
      "Epoch 1931, Loss: 0.0006345750625769142, Final Batch Loss: 5.930709085077979e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1932, Loss: 0.0010364685767854098, Final Batch Loss: 1.9403178157517686e-05\n",
      "Epoch 1933, Loss: 0.0013423582786344923, Final Batch Loss: 9.798259270610288e-05\n",
      "Epoch 1934, Loss: 0.00015273967437678948, Final Batch Loss: 3.0436225642915815e-05\n",
      "Epoch 1935, Loss: 0.002542503585573286, Final Batch Loss: 0.0004779942682944238\n",
      "Epoch 1936, Loss: 0.0011456653337518219, Final Batch Loss: 5.102175418869592e-05\n",
      "Epoch 1937, Loss: 0.00032817966712173074, Final Batch Loss: 0.00010546324483584613\n",
      "Epoch 1938, Loss: 0.016685533621057402, Final Batch Loss: 0.0005829863948747516\n",
      "Epoch 1939, Loss: 0.000810178738902323, Final Batch Loss: 0.00014302587078418583\n",
      "Epoch 1940, Loss: 0.00040535719017498195, Final Batch Loss: 0.000151371379615739\n",
      "Epoch 1941, Loss: 0.0009852388975559734, Final Batch Loss: 0.00040052662370726466\n",
      "Epoch 1942, Loss: 0.001315064091613749, Final Batch Loss: 3.165466841892339e-05\n",
      "Epoch 1943, Loss: 0.001512949340394698, Final Batch Loss: 0.0010395677527412772\n",
      "Epoch 1944, Loss: 0.0008742992795305327, Final Batch Loss: 0.00037089918623678386\n",
      "Epoch 1945, Loss: 0.0017090948604163714, Final Batch Loss: 0.00012171513662906364\n",
      "Epoch 1946, Loss: 0.0007005565421422943, Final Batch Loss: 7.87707103881985e-05\n",
      "Epoch 1947, Loss: 0.0015044463070807979, Final Batch Loss: 0.0011263698106631637\n",
      "Epoch 1948, Loss: 0.000925590364204254, Final Batch Loss: 0.00022565023391507566\n",
      "Epoch 1949, Loss: 0.005387436773162335, Final Batch Loss: 0.003563118167221546\n",
      "Epoch 1950, Loss: 0.000791014485002961, Final Batch Loss: 0.00023843013332225382\n",
      "Epoch 1951, Loss: 0.002879461186239496, Final Batch Loss: 0.0022057327441871166\n",
      "Epoch 1952, Loss: 0.00042330866199336015, Final Batch Loss: 4.214201544527896e-05\n",
      "Epoch 1953, Loss: 0.001550535875139758, Final Batch Loss: 0.0010036929743364453\n",
      "Epoch 1954, Loss: 0.001197365181724308, Final Batch Loss: 0.0007989263394847512\n",
      "Epoch 1955, Loss: 0.001723834575386718, Final Batch Loss: 0.0008828574209474027\n",
      "Epoch 1956, Loss: 0.00022001559773343615, Final Batch Loss: 9.875498653855175e-05\n",
      "Epoch 1957, Loss: 0.0004217969180899672, Final Batch Loss: 3.0351417080964893e-05\n",
      "Epoch 1958, Loss: 0.0006973474737606011, Final Batch Loss: 0.0002817186468746513\n",
      "Epoch 1959, Loss: 0.0003046141609956976, Final Batch Loss: 9.166141535388306e-05\n",
      "Epoch 1960, Loss: 0.00036632273349823663, Final Batch Loss: 1.5031714610813651e-05\n",
      "Epoch 1961, Loss: 0.000620500257355161, Final Batch Loss: 0.0001703845919109881\n",
      "Epoch 1962, Loss: 0.0009437287881155498, Final Batch Loss: 7.626925798831508e-05\n",
      "Epoch 1963, Loss: 0.0003511425657052314, Final Batch Loss: 8.994869858724996e-05\n",
      "Epoch 1964, Loss: 0.0006181475837365724, Final Batch Loss: 9.481723100179806e-05\n",
      "Epoch 1965, Loss: 0.0003548418826540001, Final Batch Loss: 5.352677180781029e-05\n",
      "Epoch 1966, Loss: 0.0005494478173204698, Final Batch Loss: 8.147308108163998e-05\n",
      "Epoch 1967, Loss: 0.00011082131641160231, Final Batch Loss: 6.8491244746837765e-06\n",
      "Epoch 1968, Loss: 0.0010597768232400995, Final Batch Loss: 0.0008302853093482554\n",
      "Epoch 1969, Loss: 0.00035875885805580765, Final Batch Loss: 4.4260668801143765e-05\n",
      "Epoch 1970, Loss: 0.0012663000088650733, Final Batch Loss: 0.00018283107783645391\n",
      "Epoch 1971, Loss: 0.007666166799026541, Final Batch Loss: 0.00010457976895850152\n",
      "Epoch 1972, Loss: 0.0002674463903531432, Final Batch Loss: 0.00012605245865415782\n",
      "Epoch 1973, Loss: 0.0008447064756182954, Final Batch Loss: 0.000448659440735355\n",
      "Epoch 1974, Loss: 0.0008852840419422137, Final Batch Loss: 0.0005129397613927722\n",
      "Epoch 1975, Loss: 0.00037950935802655295, Final Batch Loss: 9.921148739522323e-05\n",
      "Epoch 1976, Loss: 0.003949125726649072, Final Batch Loss: 0.003660043003037572\n",
      "Epoch 1977, Loss: 0.003449492738582194, Final Batch Loss: 0.0013202594127506018\n",
      "Epoch 1978, Loss: 0.0007015922601567581, Final Batch Loss: 0.00012469242210499942\n",
      "Epoch 1979, Loss: 0.0008735052397241816, Final Batch Loss: 0.0004506419936660677\n",
      "Epoch 1980, Loss: 0.0008019319002414704, Final Batch Loss: 7.972536877787206e-06\n",
      "Epoch 1981, Loss: 0.001997742692765314, Final Batch Loss: 0.0017480081878602505\n",
      "Epoch 1982, Loss: 0.0008080865518422797, Final Batch Loss: 0.00050859380280599\n",
      "Epoch 1983, Loss: 0.0008253723281086423, Final Batch Loss: 5.283801147015765e-05\n",
      "Epoch 1984, Loss: 0.001979441207367927, Final Batch Loss: 0.001309580053202808\n",
      "Epoch 1985, Loss: 0.0010159498851862736, Final Batch Loss: 0.00014979626575950533\n",
      "Epoch 1986, Loss: 0.00031291599589167163, Final Batch Loss: 3.2201060093939304e-05\n",
      "Epoch 1987, Loss: 0.0009019358694786206, Final Batch Loss: 9.257016063202173e-05\n",
      "Epoch 1988, Loss: 0.002088405264657922, Final Batch Loss: 0.00018670795543584973\n",
      "Epoch 1989, Loss: 0.0001425402551831212, Final Batch Loss: 1.8881215510191396e-05\n",
      "Epoch 1990, Loss: 0.0004880791966570541, Final Batch Loss: 0.0003393707738723606\n",
      "Epoch 1991, Loss: 0.0006331528566079214, Final Batch Loss: 0.00010346504859626293\n",
      "Epoch 1992, Loss: 0.0005360991563065909, Final Batch Loss: 0.00021529747755266726\n",
      "Epoch 1993, Loss: 0.00038356423829100095, Final Batch Loss: 4.480931966099888e-05\n",
      "Epoch 1994, Loss: 0.0017338021971227136, Final Batch Loss: 3.078379450016655e-05\n",
      "Epoch 1995, Loss: 0.010298648478055838, Final Batch Loss: 4.501766670728102e-05\n",
      "Epoch 1996, Loss: 0.00043276096403133124, Final Batch Loss: 0.00013853491691406816\n",
      "Epoch 1997, Loss: 0.000903965125871764, Final Batch Loss: 9.213871635438409e-06\n",
      "Epoch 1998, Loss: 0.0003398199551156722, Final Batch Loss: 0.00016733039228711277\n",
      "Epoch 1999, Loss: 0.006048918095984845, Final Batch Loss: 0.00032689422369003296\n",
      "Epoch 2000, Loss: 0.00018791043476085179, Final Batch Loss: 3.204470340278931e-05\n",
      "Epoch 2001, Loss: 0.000371156160326791, Final Batch Loss: 1.8318432921660133e-05\n",
      "Epoch 2002, Loss: 0.002811997299431823, Final Batch Loss: 0.00011726307275239378\n",
      "Epoch 2003, Loss: 0.0005418559740064666, Final Batch Loss: 8.828371937852353e-05\n",
      "Epoch 2004, Loss: 0.00025049763371498557, Final Batch Loss: 0.00013342087913770229\n",
      "Epoch 2005, Loss: 0.002188342568842927, Final Batch Loss: 0.0005502408021129668\n",
      "Epoch 2006, Loss: 0.0009867821499938145, Final Batch Loss: 6.103744090069085e-05\n",
      "Epoch 2007, Loss: 0.00014056746294954792, Final Batch Loss: 3.2594030926702544e-05\n",
      "Epoch 2008, Loss: 0.00013065108396403957, Final Batch Loss: 6.545273936353624e-05\n",
      "Epoch 2009, Loss: 0.00016656073785270564, Final Batch Loss: 3.274706978118047e-05\n",
      "Epoch 2010, Loss: 0.002772658903268166, Final Batch Loss: 0.0004688895132858306\n",
      "Epoch 2011, Loss: 0.01247578693619289, Final Batch Loss: 0.012411627918481827\n",
      "Epoch 2012, Loss: 0.0029621375433634967, Final Batch Loss: 0.0005738210747949779\n",
      "Epoch 2013, Loss: 0.0002695228649827186, Final Batch Loss: 0.00021157899755053222\n",
      "Epoch 2014, Loss: 0.0006928584116394632, Final Batch Loss: 5.6502562074456364e-05\n",
      "Epoch 2015, Loss: 0.0053743435855722055, Final Batch Loss: 0.005079404916614294\n",
      "Epoch 2016, Loss: 0.00040452034954796545, Final Batch Loss: 2.645433232828509e-05\n",
      "Epoch 2017, Loss: 0.0005015608567191521, Final Batch Loss: 2.0074958229088224e-05\n",
      "Epoch 2018, Loss: 0.001016936730593443, Final Batch Loss: 0.0001343718613497913\n",
      "Epoch 2019, Loss: 0.00023667479217692744, Final Batch Loss: 8.302219794131815e-05\n",
      "Epoch 2020, Loss: 0.01106144035293255, Final Batch Loss: 0.010794772766530514\n",
      "Epoch 2021, Loss: 0.0007287755324796308, Final Batch Loss: 0.00036517754779197276\n",
      "Epoch 2022, Loss: 0.0005714135768357664, Final Batch Loss: 0.00025942843058146536\n",
      "Epoch 2023, Loss: 0.005178120729397051, Final Batch Loss: 0.0018365789437666535\n",
      "Epoch 2024, Loss: 0.0017589314084034413, Final Batch Loss: 0.00015855010133236647\n",
      "Epoch 2025, Loss: 0.0007255007512867451, Final Batch Loss: 4.58707072539255e-05\n",
      "Epoch 2026, Loss: 0.002767850994132459, Final Batch Loss: 0.0003000554861500859\n",
      "Epoch 2027, Loss: 0.0014978271938161924, Final Batch Loss: 0.0005937322275713086\n",
      "Epoch 2028, Loss: 0.000472825870019733, Final Batch Loss: 2.8416301574907266e-05\n",
      "Epoch 2029, Loss: 0.0007859186043788213, Final Batch Loss: 0.00042754813330248\n",
      "Epoch 2030, Loss: 0.0005331431002559839, Final Batch Loss: 0.0003972836711909622\n",
      "Epoch 2031, Loss: 0.0004379120291559957, Final Batch Loss: 0.00026213316596113145\n",
      "Epoch 2032, Loss: 0.0030901848804205656, Final Batch Loss: 0.00020266190404072404\n",
      "Epoch 2033, Loss: 0.005702700436813757, Final Batch Loss: 6.575864972546697e-05\n",
      "Epoch 2034, Loss: 0.0010709559537644964, Final Batch Loss: 0.00027054492966271937\n",
      "Epoch 2035, Loss: 0.0005527589710254688, Final Batch Loss: 0.00046267674770206213\n",
      "Epoch 2036, Loss: 0.0003394883533474058, Final Batch Loss: 6.304029375314713e-05\n",
      "Epoch 2037, Loss: 0.007882325997343287, Final Batch Loss: 0.0016619840171188116\n",
      "Epoch 2038, Loss: 0.0010153665862162597, Final Batch Loss: 8.365850226255134e-05\n",
      "Epoch 2039, Loss: 0.0015248471063387115, Final Batch Loss: 3.822848157142289e-05\n",
      "Epoch 2040, Loss: 0.0012356875668046996, Final Batch Loss: 0.00018031924264505506\n",
      "Epoch 2041, Loss: 0.0003361569615663029, Final Batch Loss: 8.09018310974352e-05\n",
      "Epoch 2042, Loss: 0.00021273612946970388, Final Batch Loss: 1.641806011321023e-05\n",
      "Epoch 2043, Loss: 0.011227933624468278, Final Batch Loss: 7.299417484318838e-05\n",
      "Epoch 2044, Loss: 0.031035490123031195, Final Batch Loss: 0.030726421624422073\n",
      "Epoch 2045, Loss: 0.002235209569334984, Final Batch Loss: 0.000855612161103636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2046, Loss: 0.0014173469971865416, Final Batch Loss: 0.0004341415478847921\n",
      "Epoch 2047, Loss: 0.0002140493998012971, Final Batch Loss: 0.00010037246102001518\n",
      "Epoch 2048, Loss: 0.017937318443728145, Final Batch Loss: 7.163632835727185e-05\n",
      "Epoch 2049, Loss: 0.000520412369951373, Final Batch Loss: 0.00023737174342386425\n",
      "Epoch 2050, Loss: 0.0008282100716314744, Final Batch Loss: 4.63267024315428e-05\n",
      "Epoch 2051, Loss: 0.002630555347423069, Final Batch Loss: 0.002318484243005514\n",
      "Epoch 2052, Loss: 0.009447527132579125, Final Batch Loss: 0.008636261336505413\n",
      "Epoch 2053, Loss: 0.0005933744496360305, Final Batch Loss: 1.5007691217761021e-05\n",
      "Epoch 2054, Loss: 0.013331764595932327, Final Batch Loss: 0.00021017783728893846\n",
      "Epoch 2055, Loss: 0.0018855200833058916, Final Batch Loss: 8.153574162861332e-05\n",
      "Epoch 2056, Loss: 0.0010938988561974838, Final Batch Loss: 0.00016131192387547344\n",
      "Epoch 2057, Loss: 0.0029529554885812104, Final Batch Loss: 0.00269564357586205\n",
      "Epoch 2058, Loss: 0.0017145239944511559, Final Batch Loss: 4.308262941776775e-05\n",
      "Epoch 2059, Loss: 0.001191611729154829, Final Batch Loss: 0.00038791593397036195\n",
      "Epoch 2060, Loss: 0.005865220999112353, Final Batch Loss: 0.005308372899889946\n",
      "Epoch 2061, Loss: 0.004437329975189641, Final Batch Loss: 0.0032437231857329607\n",
      "Epoch 2062, Loss: 0.002359134603466373, Final Batch Loss: 0.0022214208729565144\n",
      "Epoch 2063, Loss: 0.0015028456400614232, Final Batch Loss: 0.0003546875377651304\n",
      "Epoch 2064, Loss: 0.0017323803767794743, Final Batch Loss: 0.00014403021486941725\n",
      "Epoch 2065, Loss: 0.0007728059972578194, Final Batch Loss: 4.3649280996760353e-05\n",
      "Epoch 2066, Loss: 0.0012417118268785998, Final Batch Loss: 0.0003493921831250191\n",
      "Epoch 2067, Loss: 0.0022992727754171938, Final Batch Loss: 0.0002594129473436624\n",
      "Epoch 2068, Loss: 0.0009218542109010741, Final Batch Loss: 0.0002025775465881452\n",
      "Epoch 2069, Loss: 0.004266635558451526, Final Batch Loss: 0.0001563484111102298\n",
      "Epoch 2070, Loss: 0.00679153687087819, Final Batch Loss: 0.00017983824363909662\n",
      "Epoch 2071, Loss: 0.003968521559727378, Final Batch Loss: 0.0001598493690835312\n",
      "Epoch 2072, Loss: 0.000934151939873118, Final Batch Loss: 1.9270060874987394e-05\n",
      "Epoch 2073, Loss: 0.00047124769662332255, Final Batch Loss: 2.0037428839714266e-05\n",
      "Epoch 2074, Loss: 0.006266689713811502, Final Batch Loss: 7.97164102550596e-05\n",
      "Epoch 2075, Loss: 0.0036558237989083864, Final Batch Loss: 4.416729643708095e-05\n",
      "Epoch 2076, Loss: 0.001989983098610537, Final Batch Loss: 4.122128666494973e-05\n",
      "Epoch 2077, Loss: 0.0006264102703426033, Final Batch Loss: 0.0001594693458173424\n",
      "Epoch 2078, Loss: 0.000389337154047098, Final Batch Loss: 0.00010182108235312626\n",
      "Epoch 2079, Loss: 0.0005492509953910485, Final Batch Loss: 0.00021807783923577517\n",
      "Epoch 2080, Loss: 0.0002558232008595951, Final Batch Loss: 7.556706259492785e-05\n",
      "Epoch 2081, Loss: 0.0010226541053270921, Final Batch Loss: 0.00024256813048850745\n",
      "Epoch 2082, Loss: 0.00025631749667809345, Final Batch Loss: 0.0001002352437353693\n",
      "Epoch 2083, Loss: 0.00048059672553790733, Final Batch Loss: 0.00018005647871177644\n",
      "Epoch 2084, Loss: 0.0004355121564003639, Final Batch Loss: 0.00028311728965491056\n",
      "Epoch 2085, Loss: 0.00046920947079343023, Final Batch Loss: 1.0471911991771776e-05\n",
      "Epoch 2086, Loss: 0.0006759910938853864, Final Batch Loss: 9.864698222372681e-05\n",
      "Epoch 2087, Loss: 0.0016407838556915522, Final Batch Loss: 0.0007570140296593308\n",
      "Epoch 2088, Loss: 0.0008599816574133001, Final Batch Loss: 1.8710641597863287e-05\n",
      "Epoch 2089, Loss: 0.0011145083954033908, Final Batch Loss: 4.4455748138716444e-05\n",
      "Epoch 2090, Loss: 0.0023302980844164267, Final Batch Loss: 0.00190383056178689\n",
      "Epoch 2091, Loss: 0.0003669269644888118, Final Batch Loss: 7.806163921486586e-05\n",
      "Epoch 2092, Loss: 0.0005487313828780316, Final Batch Loss: 0.00014400255167856812\n",
      "Epoch 2093, Loss: 0.0002236523678220692, Final Batch Loss: 1.1950362932111602e-05\n",
      "Epoch 2094, Loss: 0.0005000816454412416, Final Batch Loss: 7.10173771949485e-05\n",
      "Epoch 2095, Loss: 0.00020323598619143013, Final Batch Loss: 2.5263119823648594e-05\n",
      "Epoch 2096, Loss: 8.347302355105057e-05, Final Batch Loss: 2.3014838006929494e-05\n",
      "Epoch 2097, Loss: 0.0005596914597845171, Final Batch Loss: 5.062025229563005e-05\n",
      "Epoch 2098, Loss: 0.001255980932910461, Final Batch Loss: 0.0008993826922960579\n",
      "Epoch 2099, Loss: 0.0005530277921934612, Final Batch Loss: 0.00029386216192506254\n",
      "Epoch 2100, Loss: 0.023058094346197322, Final Batch Loss: 0.0104261739179492\n",
      "Epoch 2101, Loss: 0.0003012722736457363, Final Batch Loss: 4.6460190787911415e-05\n",
      "Epoch 2102, Loss: 0.032897971861530095, Final Batch Loss: 3.5622811992652714e-05\n",
      "Epoch 2103, Loss: 0.016624275624053553, Final Batch Loss: 6.927941285539418e-05\n",
      "Epoch 2104, Loss: 0.00015929104756651213, Final Batch Loss: 1.3825024325342383e-05\n",
      "Epoch 2105, Loss: 0.00018589661704027094, Final Batch Loss: 3.154423393425532e-05\n",
      "Epoch 2106, Loss: 0.014474592382612173, Final Batch Loss: 1.724553294479847e-05\n",
      "Epoch 2107, Loss: 0.032824503075971734, Final Batch Loss: 7.588118751300499e-05\n",
      "Epoch 2108, Loss: 0.0297957326984033, Final Batch Loss: 0.029320336878299713\n",
      "Epoch 2109, Loss: 0.009061905060661957, Final Batch Loss: 3.7789897760376334e-05\n",
      "Epoch 2110, Loss: 0.0009423483861610293, Final Batch Loss: 0.00013529957504943013\n",
      "Epoch 2111, Loss: 0.0008182302917703055, Final Batch Loss: 5.543200677493587e-05\n",
      "Epoch 2112, Loss: 0.0010324986460545915, Final Batch Loss: 1.1287203051324468e-05\n",
      "Epoch 2113, Loss: 0.0018841650162357837, Final Batch Loss: 0.0004622925480362028\n",
      "Epoch 2114, Loss: 0.0016695310187060386, Final Batch Loss: 0.0007967025740072131\n",
      "Epoch 2115, Loss: 0.0006706770072923973, Final Batch Loss: 0.00020443473476916552\n",
      "Epoch 2116, Loss: 0.006728471984388307, Final Batch Loss: 0.00014528093743138015\n",
      "Epoch 2117, Loss: 0.006036128004780039, Final Batch Loss: 0.0001499360951129347\n",
      "Epoch 2118, Loss: 0.0021240661153569818, Final Batch Loss: 7.055210880935192e-05\n",
      "Epoch 2119, Loss: 0.018997355247847736, Final Batch Loss: 4.838968743570149e-05\n",
      "Epoch 2120, Loss: 0.000469581937068142, Final Batch Loss: 0.00010616044164635241\n",
      "Epoch 2121, Loss: 0.001009829924441874, Final Batch Loss: 0.0001860023767221719\n",
      "Epoch 2122, Loss: 0.0004904911402263679, Final Batch Loss: 8.63498353282921e-05\n",
      "Epoch 2123, Loss: 0.0013608043955173343, Final Batch Loss: 0.00045661264448426664\n",
      "Epoch 2124, Loss: 0.0004212676649331115, Final Batch Loss: 0.0001567726576467976\n",
      "Epoch 2125, Loss: 0.004434101439983351, Final Batch Loss: 4.992725371266715e-05\n",
      "Epoch 2126, Loss: 0.00020570025299093686, Final Batch Loss: 6.145491352071986e-05\n",
      "Epoch 2127, Loss: 0.0012026465265080333, Final Batch Loss: 0.0007007803069427609\n",
      "Epoch 2128, Loss: 0.000474940625281306, Final Batch Loss: 7.48312086216174e-05\n",
      "Epoch 2129, Loss: 0.01124562000768492, Final Batch Loss: 0.00010033048602053896\n",
      "Epoch 2130, Loss: 0.007729172590188682, Final Batch Loss: 0.0009853426599875093\n",
      "Epoch 2131, Loss: 0.0013463769209920429, Final Batch Loss: 0.000434883899288252\n",
      "Epoch 2132, Loss: 0.0005695825238944963, Final Batch Loss: 0.00024722778471186757\n",
      "Epoch 2133, Loss: 0.0009857428958639503, Final Batch Loss: 0.0003836205287370831\n",
      "Epoch 2134, Loss: 0.004981977283023298, Final Batch Loss: 0.0029256250709295273\n",
      "Epoch 2135, Loss: 0.0017295233847107738, Final Batch Loss: 0.0003271066816523671\n",
      "Epoch 2136, Loss: 0.003096604545135051, Final Batch Loss: 0.001426412840373814\n",
      "Epoch 2137, Loss: 0.003613707798649557, Final Batch Loss: 0.003224711399525404\n",
      "Epoch 2138, Loss: 0.001524432736914605, Final Batch Loss: 0.0009216644684784114\n",
      "Epoch 2139, Loss: 0.0008083709690254182, Final Batch Loss: 0.0003034860419575125\n",
      "Epoch 2140, Loss: 0.000621009863607469, Final Batch Loss: 4.6598241169704124e-05\n",
      "Epoch 2141, Loss: 0.0007533755269832909, Final Batch Loss: 0.0005667285877279937\n",
      "Epoch 2142, Loss: 0.0006122778286226094, Final Batch Loss: 0.00014146839384920895\n",
      "Epoch 2143, Loss: 0.00017594071687199175, Final Batch Loss: 2.678702730918303e-05\n",
      "Epoch 2144, Loss: 0.024753929741564207, Final Batch Loss: 0.00021829518664162606\n",
      "Epoch 2145, Loss: 0.00027316337764204945, Final Batch Loss: 1.4822062439634465e-05\n",
      "Epoch 2146, Loss: 0.0004994404662284069, Final Batch Loss: 4.188116145087406e-05\n",
      "Epoch 2147, Loss: 0.003959752793889493, Final Batch Loss: 0.0014708556700497866\n",
      "Epoch 2148, Loss: 0.0011001177481375635, Final Batch Loss: 0.0005143257440067828\n",
      "Epoch 2149, Loss: 0.05064344924176112, Final Batch Loss: 0.04947996512055397\n",
      "Epoch 2150, Loss: 0.00045276911987457424, Final Batch Loss: 0.00014352810103446245\n",
      "Epoch 2151, Loss: 0.00253094729851, Final Batch Loss: 0.0011392912128940225\n",
      "Epoch 2152, Loss: 0.002032149197475519, Final Batch Loss: 0.0008766189566813409\n",
      "Epoch 2153, Loss: 0.0008978580808616243, Final Batch Loss: 3.6822973925154656e-05\n",
      "Epoch 2154, Loss: 0.002482264710124582, Final Batch Loss: 0.00018808385357260704\n",
      "Epoch 2155, Loss: 0.000956902775214985, Final Batch Loss: 0.00025625553098507226\n",
      "Epoch 2156, Loss: 0.011291464266832918, Final Batch Loss: 0.010688182897865772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2157, Loss: 0.0008486738297506236, Final Batch Loss: 0.0005337238544598222\n",
      "Epoch 2158, Loss: 0.0010135538032045588, Final Batch Loss: 0.0003768002789001912\n",
      "Epoch 2159, Loss: 0.001123422698583454, Final Batch Loss: 0.0001231734931934625\n",
      "Epoch 2160, Loss: 0.0023792748506821226, Final Batch Loss: 0.0017922258703038096\n",
      "Epoch 2161, Loss: 0.0009173256694339216, Final Batch Loss: 0.00014464883133769035\n",
      "Epoch 2162, Loss: 0.000890347444510553, Final Batch Loss: 0.00021310849115252495\n",
      "Epoch 2163, Loss: 0.000691230503434781, Final Batch Loss: 8.23590307845734e-05\n",
      "Epoch 2164, Loss: 0.001938104018336162, Final Batch Loss: 0.0015176247106865048\n",
      "Epoch 2165, Loss: 0.0016783588216640055, Final Batch Loss: 0.0011779468040913343\n",
      "Epoch 2166, Loss: 0.0005226055363891646, Final Batch Loss: 0.00010170389577979222\n",
      "Epoch 2167, Loss: 0.0006971300099394284, Final Batch Loss: 0.0001186703666462563\n",
      "Epoch 2168, Loss: 0.0032349247485399246, Final Batch Loss: 0.0002683121128939092\n",
      "Epoch 2169, Loss: 0.0007835476790205576, Final Batch Loss: 4.3321444536559284e-05\n",
      "Epoch 2170, Loss: 0.0014709654096805025, Final Batch Loss: 0.0013448897516354918\n",
      "Epoch 2171, Loss: 0.0006177870800456731, Final Batch Loss: 2.2842910766485147e-05\n",
      "Epoch 2172, Loss: 0.0009169298605229415, Final Batch Loss: 7.000951427471591e-06\n",
      "Epoch 2173, Loss: 0.002334834214707371, Final Batch Loss: 0.0014554148074239492\n",
      "Epoch 2174, Loss: 0.002097754870192148, Final Batch Loss: 0.0017464251723140478\n",
      "Epoch 2175, Loss: 0.01575393552047899, Final Batch Loss: 5.4787400586064905e-05\n",
      "Epoch 2176, Loss: 0.0012076586062903516, Final Batch Loss: 0.0004327525675762445\n",
      "Epoch 2177, Loss: 0.0010037981010100339, Final Batch Loss: 0.0006793004577048123\n",
      "Epoch 2178, Loss: 0.0013650290020450484, Final Batch Loss: 0.001111087272875011\n",
      "Epoch 2179, Loss: 0.000976876091954182, Final Batch Loss: 0.0008316839230246842\n",
      "Epoch 2180, Loss: 0.0010304395254934207, Final Batch Loss: 8.295469160657376e-05\n",
      "Epoch 2181, Loss: 0.0007959242939250544, Final Batch Loss: 0.0001902561343740672\n",
      "Epoch 2182, Loss: 0.0014448933361563832, Final Batch Loss: 0.00012055056868121028\n",
      "Epoch 2183, Loss: 0.0008187578059732914, Final Batch Loss: 0.0003602362994570285\n",
      "Epoch 2184, Loss: 0.0002967406835523434, Final Batch Loss: 7.247045141411945e-05\n",
      "Epoch 2185, Loss: 0.0009164067232632078, Final Batch Loss: 7.12529945303686e-05\n",
      "Epoch 2186, Loss: 0.014764406339963898, Final Batch Loss: 0.0062084803357720375\n",
      "Epoch 2187, Loss: 0.0004254740633768961, Final Batch Loss: 5.3792973631061614e-05\n",
      "Epoch 2188, Loss: 0.0006447232553909998, Final Batch Loss: 4.593318226397969e-05\n",
      "Epoch 2189, Loss: 0.00018931186787085608, Final Batch Loss: 6.168457184685394e-05\n",
      "Epoch 2190, Loss: 0.0024477216065861285, Final Batch Loss: 0.0009408165351487696\n",
      "Epoch 2191, Loss: 0.0009874868410406634, Final Batch Loss: 0.0003661794471554458\n",
      "Epoch 2192, Loss: 0.0016836477734614164, Final Batch Loss: 0.0010825193021446466\n",
      "Epoch 2193, Loss: 0.000868881368660368, Final Batch Loss: 0.0004466989485081285\n",
      "Epoch 2194, Loss: 0.0002685884974198416, Final Batch Loss: 7.03446421539411e-05\n",
      "Epoch 2195, Loss: 0.006013208068907261, Final Batch Loss: 0.0004967681597918272\n",
      "Epoch 2196, Loss: 0.0002754019969870569, Final Batch Loss: 1.4337108950712718e-05\n",
      "Epoch 2197, Loss: 0.0003227588749723509, Final Batch Loss: 7.563408144051209e-05\n",
      "Epoch 2198, Loss: 0.0005890475113119464, Final Batch Loss: 4.067452027811669e-05\n",
      "Epoch 2199, Loss: 0.0002904053581005428, Final Batch Loss: 0.00018288890714757144\n",
      "Epoch 2200, Loss: 0.0006627040820603725, Final Batch Loss: 0.0001465208042645827\n",
      "Epoch 2201, Loss: 0.0010151336464332417, Final Batch Loss: 0.000262157031102106\n",
      "Epoch 2202, Loss: 0.00025218130031134933, Final Batch Loss: 5.67935494473204e-05\n",
      "Epoch 2203, Loss: 0.001165802103059832, Final Batch Loss: 0.00013069534907117486\n",
      "Epoch 2204, Loss: 0.00023732373119855765, Final Batch Loss: 2.8390555598889478e-05\n",
      "Epoch 2205, Loss: 0.004858796797634568, Final Batch Loss: 0.0047230832278728485\n",
      "Epoch 2206, Loss: 0.001788674431736581, Final Batch Loss: 0.0017040446400642395\n",
      "Epoch 2207, Loss: 0.00020804472296731547, Final Batch Loss: 8.284002979053184e-05\n",
      "Epoch 2208, Loss: 0.000910485574422637, Final Batch Loss: 0.000737468886654824\n",
      "Epoch 2209, Loss: 0.0003283990981799434, Final Batch Loss: 9.277969184040558e-06\n",
      "Epoch 2210, Loss: 0.000592710952332709, Final Batch Loss: 9.242236410500482e-05\n",
      "Epoch 2211, Loss: 0.00023730752764095087, Final Batch Loss: 2.943599429272581e-05\n",
      "Epoch 2212, Loss: 0.0002821166090143379, Final Batch Loss: 0.0001313319953624159\n",
      "Epoch 2213, Loss: 0.00012162976781837642, Final Batch Loss: 3.1306513847084716e-05\n",
      "Epoch 2214, Loss: 0.00559044411056675, Final Batch Loss: 0.0052357870154082775\n",
      "Epoch 2215, Loss: 0.0004738875668408582, Final Batch Loss: 7.029224798316136e-05\n",
      "Epoch 2216, Loss: 0.0005736383100156672, Final Batch Loss: 0.00011441195238148794\n",
      "Epoch 2217, Loss: 0.00016135269470396452, Final Batch Loss: 8.253530540969223e-05\n",
      "Epoch 2218, Loss: 0.009958636052033398, Final Batch Loss: 7.920110510895029e-05\n",
      "Epoch 2219, Loss: 0.0006171388668008149, Final Batch Loss: 3.854787792079151e-05\n",
      "Epoch 2220, Loss: 0.003958090390369762, Final Batch Loss: 9.322044934378937e-05\n",
      "Epoch 2221, Loss: 0.001471771152864676, Final Batch Loss: 0.0010272964136675\n",
      "Epoch 2222, Loss: 0.009230239593307488, Final Batch Loss: 0.008570029400289059\n",
      "Epoch 2223, Loss: 0.0007238302641781047, Final Batch Loss: 0.00011426374840084463\n",
      "Epoch 2224, Loss: 0.0015100156160769984, Final Batch Loss: 0.0004945949767716229\n",
      "Epoch 2225, Loss: 0.0021378539531724527, Final Batch Loss: 0.0012493494432419538\n",
      "Epoch 2226, Loss: 0.0005606973427347839, Final Batch Loss: 0.00011396445916034281\n",
      "Epoch 2227, Loss: 0.0010343536487198435, Final Batch Loss: 0.00027513864915817976\n",
      "Epoch 2228, Loss: 0.00036824266862822697, Final Batch Loss: 4.032116703456268e-05\n",
      "Epoch 2229, Loss: 0.0011612572488957085, Final Batch Loss: 0.00044410303235054016\n",
      "Epoch 2230, Loss: 0.0009665341349318624, Final Batch Loss: 0.0006550446851179004\n",
      "Epoch 2231, Loss: 0.00042162010868196376, Final Batch Loss: 3.61710881406907e-05\n",
      "Epoch 2232, Loss: 0.0008033912599785253, Final Batch Loss: 0.00048244043136946857\n",
      "Epoch 2233, Loss: 0.000474121086881496, Final Batch Loss: 6.390652561094612e-05\n",
      "Epoch 2234, Loss: 0.0030648883748654043, Final Batch Loss: 1.8496843040338717e-05\n",
      "Epoch 2235, Loss: 0.00030054150101932464, Final Batch Loss: 1.364089530397905e-05\n",
      "Epoch 2236, Loss: 0.00032581822779320646, Final Batch Loss: 2.057532583421562e-05\n",
      "Epoch 2237, Loss: 0.0006836993125034496, Final Batch Loss: 0.0002054529613815248\n",
      "Epoch 2238, Loss: 0.0006544015086547006, Final Batch Loss: 0.00044860393973067403\n",
      "Epoch 2239, Loss: 0.00379260974295903, Final Batch Loss: 0.00017121444398071617\n",
      "Epoch 2240, Loss: 0.0004252109720255248, Final Batch Loss: 0.00016144075198099017\n",
      "Epoch 2241, Loss: 0.0005489850236699567, Final Batch Loss: 1.4124446352070663e-05\n",
      "Epoch 2242, Loss: 0.0003664887190097943, Final Batch Loss: 0.00016930220590438694\n",
      "Epoch 2243, Loss: 0.0004475278328754939, Final Batch Loss: 7.116932101780549e-05\n",
      "Epoch 2244, Loss: 0.04177581331168767, Final Batch Loss: 0.04142475500702858\n",
      "Epoch 2245, Loss: 0.0010123120882781222, Final Batch Loss: 0.0006491278763860464\n",
      "Epoch 2246, Loss: 0.0006533677551487926, Final Batch Loss: 1.640490154386498e-05\n",
      "Epoch 2247, Loss: 0.00019279092157376, Final Batch Loss: 2.853232217603363e-05\n",
      "Epoch 2248, Loss: 0.0016501853096997365, Final Batch Loss: 0.0009395114611834288\n",
      "Epoch 2249, Loss: 0.06371891919116024, Final Batch Loss: 0.06240994855761528\n",
      "Epoch 2250, Loss: 0.00028798838047805475, Final Batch Loss: 1.3544308785640169e-05\n",
      "Epoch 2251, Loss: 0.0019300075800856575, Final Batch Loss: 7.06506980350241e-05\n",
      "Epoch 2252, Loss: 0.0012267185666132718, Final Batch Loss: 0.0004652545612771064\n",
      "Epoch 2253, Loss: 0.0017669624357949942, Final Batch Loss: 0.00026442817761562765\n",
      "Epoch 2254, Loss: 0.0019170498162566219, Final Batch Loss: 0.0011310032568871975\n",
      "Epoch 2255, Loss: 0.002414008049527183, Final Batch Loss: 0.0002729460538830608\n",
      "Epoch 2256, Loss: 0.028028049404383637, Final Batch Loss: 0.013134942390024662\n",
      "Epoch 2257, Loss: 0.0002536611664254451, Final Batch Loss: 2.6015995899797417e-05\n",
      "Epoch 2258, Loss: 0.02391722792526707, Final Batch Loss: 0.02021535113453865\n",
      "Epoch 2259, Loss: 0.019304100307635963, Final Batch Loss: 0.016580680385231972\n",
      "Epoch 2260, Loss: 0.0004909513882012106, Final Batch Loss: 8.42084118630737e-05\n",
      "Epoch 2261, Loss: 0.003365348733495921, Final Batch Loss: 0.0015036974800750613\n",
      "Epoch 2262, Loss: 0.004239947069436312, Final Batch Loss: 0.0024530524387955666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2263, Loss: 0.004615064361132681, Final Batch Loss: 0.002202789532020688\n",
      "Epoch 2264, Loss: 0.010006487311329693, Final Batch Loss: 0.0020349498372524977\n",
      "Epoch 2265, Loss: 0.001342775794910267, Final Batch Loss: 0.0007424763171002269\n",
      "Epoch 2266, Loss: 0.0015331238791986834, Final Batch Loss: 0.001171598327346146\n",
      "Epoch 2267, Loss: 0.0015752986073493958, Final Batch Loss: 7.893567089922726e-05\n",
      "Epoch 2268, Loss: 0.005513830343261361, Final Batch Loss: 0.00012499335571192205\n",
      "Epoch 2269, Loss: 0.0009439775458304211, Final Batch Loss: 0.00032722012838348746\n",
      "Epoch 2270, Loss: 0.0006081571918912232, Final Batch Loss: 1.662607246544212e-05\n",
      "Epoch 2271, Loss: 0.000527348238392733, Final Batch Loss: 9.997664164984599e-05\n",
      "Epoch 2272, Loss: 0.00044552231702255085, Final Batch Loss: 6.542648043250665e-05\n",
      "Epoch 2273, Loss: 0.0010877313252422027, Final Batch Loss: 0.00011896454816451296\n",
      "Epoch 2274, Loss: 0.003594324953155592, Final Batch Loss: 0.0029013033490628004\n",
      "Epoch 2275, Loss: 0.001366603930364363, Final Batch Loss: 0.0007282837759703398\n",
      "Epoch 2276, Loss: 0.0003305292484583333, Final Batch Loss: 8.021377288969234e-05\n",
      "Epoch 2277, Loss: 0.007369948216364719, Final Batch Loss: 0.006479471456259489\n",
      "Epoch 2278, Loss: 0.000705160025972873, Final Batch Loss: 0.00023054801567923278\n",
      "Epoch 2279, Loss: 0.00040800842543831095, Final Batch Loss: 8.294510917039588e-05\n",
      "Epoch 2280, Loss: 0.0004904802626697347, Final Batch Loss: 0.0002733409928623587\n",
      "Epoch 2281, Loss: 0.0010647878953022882, Final Batch Loss: 9.162809874396771e-05\n",
      "Epoch 2282, Loss: 0.0004892089218628826, Final Batch Loss: 1.660674206505064e-05\n",
      "Epoch 2283, Loss: 0.0005915344736422412, Final Batch Loss: 0.00011831513984361663\n",
      "Epoch 2284, Loss: 0.001791755472368095, Final Batch Loss: 0.00011228587391087785\n",
      "Epoch 2285, Loss: 0.05120287359022768, Final Batch Loss: 0.0005309773841872811\n",
      "Epoch 2286, Loss: 0.0005257148077362217, Final Batch Loss: 0.00014772964641451836\n",
      "Epoch 2287, Loss: 0.0025214558409061283, Final Batch Loss: 0.0016159561928361654\n",
      "Epoch 2288, Loss: 0.002399092714767903, Final Batch Loss: 0.001991517376154661\n",
      "Epoch 2289, Loss: 0.0006518444861285388, Final Batch Loss: 7.65124277677387e-05\n",
      "Epoch 2290, Loss: 0.0021674501222150866, Final Batch Loss: 5.940534538240172e-05\n",
      "Epoch 2291, Loss: 0.0003778706795856124, Final Batch Loss: 3.015204674738925e-05\n",
      "Epoch 2292, Loss: 0.0006345423171296716, Final Batch Loss: 8.56244150782004e-05\n",
      "Epoch 2293, Loss: 0.0006699125951854512, Final Batch Loss: 0.0002324007946299389\n",
      "Epoch 2294, Loss: 0.0002949811714643147, Final Batch Loss: 6.13545926171355e-05\n",
      "Epoch 2295, Loss: 0.0018860933705582283, Final Batch Loss: 9.08865113160573e-05\n",
      "Epoch 2296, Loss: 0.0003086362703470513, Final Batch Loss: 0.0001446492096874863\n",
      "Epoch 2297, Loss: 0.0009824145727179712, Final Batch Loss: 0.00041487853741273284\n",
      "Epoch 2298, Loss: 0.0005686699460056843, Final Batch Loss: 2.659671190485824e-05\n",
      "Epoch 2299, Loss: 0.0008872462785802782, Final Batch Loss: 5.22973423358053e-05\n",
      "Epoch 2300, Loss: 0.0006476350899902172, Final Batch Loss: 0.00034003061591647565\n",
      "Epoch 2301, Loss: 0.0005099892914586235, Final Batch Loss: 0.00018788193119689822\n",
      "Epoch 2302, Loss: 0.00014511337940348312, Final Batch Loss: 3.001008190040011e-05\n",
      "Epoch 2303, Loss: 0.0006403928018698934, Final Batch Loss: 1.2522945326054469e-05\n",
      "Epoch 2304, Loss: 0.017205727883265354, Final Batch Loss: 0.00013951085566077381\n",
      "Epoch 2305, Loss: 0.00438269905771449, Final Batch Loss: 1.316689213126665e-05\n",
      "Epoch 2306, Loss: 0.0005947420722804964, Final Batch Loss: 0.00011172435188200325\n",
      "Epoch 2307, Loss: 0.0003761242041946389, Final Batch Loss: 4.38373172073625e-05\n",
      "Epoch 2308, Loss: 0.00029987753441673703, Final Batch Loss: 4.4004311348544434e-05\n",
      "Epoch 2309, Loss: 0.00038189861516002566, Final Batch Loss: 0.00017930079775396734\n",
      "Epoch 2310, Loss: 0.07293446293624584, Final Batch Loss: 0.0001279623684240505\n",
      "Epoch 2311, Loss: 0.0008755917297094129, Final Batch Loss: 0.00012109339149901643\n",
      "Epoch 2312, Loss: 0.025250090307963546, Final Batch Loss: 0.024031449109315872\n",
      "Epoch 2313, Loss: 0.02428163605509326, Final Batch Loss: 0.023138126358389854\n",
      "Epoch 2314, Loss: 0.0018189117690781131, Final Batch Loss: 0.0005687015363946557\n",
      "Epoch 2315, Loss: 0.00020565975864883512, Final Batch Loss: 4.596469443640672e-05\n",
      "Epoch 2316, Loss: 0.00037981870264047757, Final Batch Loss: 0.0002853098267223686\n",
      "Epoch 2317, Loss: 0.0008741794772504363, Final Batch Loss: 0.0007160160457715392\n",
      "Epoch 2318, Loss: 0.002199273218138842, Final Batch Loss: 3.601029675337486e-05\n",
      "Epoch 2319, Loss: 0.0012919553264509887, Final Batch Loss: 0.000269032345386222\n",
      "Epoch 2320, Loss: 0.028115225013607414, Final Batch Loss: 5.760501153417863e-05\n",
      "Epoch 2321, Loss: 0.0004920839855913073, Final Batch Loss: 0.00013714002852793783\n",
      "Epoch 2322, Loss: 0.0003666518459795043, Final Batch Loss: 0.00016760775179136544\n",
      "Epoch 2323, Loss: 0.00039827059663366526, Final Batch Loss: 0.0001644734147703275\n",
      "Epoch 2324, Loss: 0.004425245613674633, Final Batch Loss: 0.0011818831553682685\n",
      "Epoch 2325, Loss: 0.0011741011257981881, Final Batch Loss: 0.0001156231010099873\n",
      "Epoch 2326, Loss: 0.05545329337473959, Final Batch Loss: 0.00026527285808697343\n",
      "Epoch 2327, Loss: 0.00036081342477700673, Final Batch Loss: 3.0469233024632558e-05\n",
      "Epoch 2328, Loss: 0.0005084267213533167, Final Batch Loss: 0.0003335651708766818\n",
      "Epoch 2329, Loss: 0.0003985761468356941, Final Batch Loss: 0.0002595017140265554\n",
      "Epoch 2330, Loss: 0.0015136923975660466, Final Batch Loss: 8.053029159782454e-05\n",
      "Epoch 2331, Loss: 0.000526196822647762, Final Batch Loss: 1.0665656191122252e-05\n",
      "Epoch 2332, Loss: 0.002842905312718358, Final Batch Loss: 0.002408913103863597\n",
      "Epoch 2333, Loss: 0.0007810593961039558, Final Batch Loss: 0.000319509650580585\n",
      "Epoch 2334, Loss: 0.00456448729528347, Final Batch Loss: 4.642336716642603e-05\n",
      "Epoch 2335, Loss: 0.001450662370189093, Final Batch Loss: 0.0009774132631719112\n",
      "Epoch 2336, Loss: 0.001014886194752762, Final Batch Loss: 4.6742719860048965e-05\n",
      "Epoch 2337, Loss: 0.00033200524194398895, Final Batch Loss: 3.1851996027398854e-05\n",
      "Epoch 2338, Loss: 0.0009657465707277879, Final Batch Loss: 0.0004589392920024693\n",
      "Epoch 2339, Loss: 0.00047501744847977534, Final Batch Loss: 0.0001227339234901592\n",
      "Epoch 2340, Loss: 0.00022586425620829687, Final Batch Loss: 0.00010368032235419378\n",
      "Epoch 2341, Loss: 0.00037009052948633325, Final Batch Loss: 7.239119895530166e-06\n",
      "Epoch 2342, Loss: 0.014284677719842875, Final Batch Loss: 1.1806874681496993e-05\n",
      "Epoch 2343, Loss: 0.0005113117149448954, Final Batch Loss: 0.0002630735980346799\n",
      "Epoch 2344, Loss: 0.0006291004610829987, Final Batch Loss: 0.0003274662303738296\n",
      "Epoch 2345, Loss: 0.00032771330006653443, Final Batch Loss: 0.0001568268780829385\n",
      "Epoch 2346, Loss: 0.002149308147636475, Final Batch Loss: 4.3145952076883987e-05\n",
      "Epoch 2347, Loss: 0.030824325396679342, Final Batch Loss: 0.030091719701886177\n",
      "Epoch 2348, Loss: 0.09297609777422622, Final Batch Loss: 0.09161745756864548\n",
      "Epoch 2349, Loss: 0.002323141205124557, Final Batch Loss: 0.0006628514965996146\n",
      "Epoch 2350, Loss: 0.019515788939315826, Final Batch Loss: 0.00015283015090972185\n",
      "Epoch 2351, Loss: 0.003972072168835439, Final Batch Loss: 6.240468064788729e-05\n",
      "Epoch 2352, Loss: 0.021603090572170913, Final Batch Loss: 0.00040137849282473326\n",
      "Epoch 2353, Loss: 0.0006766956066712737, Final Batch Loss: 0.0002953887451440096\n",
      "Epoch 2354, Loss: 0.003432234050706029, Final Batch Loss: 0.00199615559540689\n",
      "Epoch 2355, Loss: 0.0020501625549513847, Final Batch Loss: 0.0012851884821429849\n",
      "Epoch 2356, Loss: 0.02599259185080882, Final Batch Loss: 0.00015336739306803793\n",
      "Epoch 2357, Loss: 0.008333380275871605, Final Batch Loss: 0.0011165131581947207\n",
      "Epoch 2358, Loss: 0.012190748282591812, Final Batch Loss: 0.0002301686763530597\n",
      "Epoch 2359, Loss: 0.0009595941955922171, Final Batch Loss: 0.00013409349776338786\n",
      "Epoch 2360, Loss: 0.0011623871396295726, Final Batch Loss: 0.0006166754174046218\n",
      "Epoch 2361, Loss: 0.007709113022428937, Final Batch Loss: 0.00013520302309188992\n",
      "Epoch 2362, Loss: 0.0013751110527664423, Final Batch Loss: 0.00019549293210729957\n",
      "Epoch 2363, Loss: 0.004126754036406055, Final Batch Loss: 0.00020049107843078673\n",
      "Epoch 2364, Loss: 0.008474679838400334, Final Batch Loss: 0.0005963895819149911\n",
      "Epoch 2365, Loss: 0.0007341560412896797, Final Batch Loss: 0.00031217283685691655\n",
      "Epoch 2366, Loss: 0.0018693722086027265, Final Batch Loss: 0.00019911985145881772\n",
      "Epoch 2367, Loss: 0.0009566387525410391, Final Batch Loss: 6.449683132814243e-05\n",
      "Epoch 2368, Loss: 0.0010096871119458228, Final Batch Loss: 0.00018812299822457135\n",
      "Epoch 2369, Loss: 0.002010172334848903, Final Batch Loss: 0.0014303495408967137\n",
      "Epoch 2370, Loss: 0.0013641898694913834, Final Batch Loss: 0.00042901511187665164\n",
      "Epoch 2371, Loss: 0.0009998606401495636, Final Batch Loss: 0.000428523140726611\n",
      "Epoch 2372, Loss: 0.00042706784915935714, Final Batch Loss: 2.4516784833394922e-05\n",
      "Epoch 2373, Loss: 0.0008885877614375204, Final Batch Loss: 0.000498084060382098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2374, Loss: 0.004903304754407145, Final Batch Loss: 0.00015010028437245637\n",
      "Epoch 2375, Loss: 0.0018786544969771057, Final Batch Loss: 0.0009050819789990783\n",
      "Epoch 2376, Loss: 0.0050516165647422895, Final Batch Loss: 0.00017048482550308108\n",
      "Epoch 2377, Loss: 0.0015734209882793948, Final Batch Loss: 0.0009272693423554301\n",
      "Epoch 2378, Loss: 0.0012973704433534294, Final Batch Loss: 0.000627624976914376\n",
      "Epoch 2379, Loss: 0.0003902991593349725, Final Batch Loss: 8.578773849876598e-05\n",
      "Epoch 2380, Loss: 0.000908361173060257, Final Batch Loss: 0.00045521516585722566\n",
      "Epoch 2381, Loss: 0.010824315992067568, Final Batch Loss: 0.008584252558648586\n",
      "Epoch 2382, Loss: 0.03202251983748283, Final Batch Loss: 0.03164801746606827\n",
      "Epoch 2383, Loss: 0.0010178382362937555, Final Batch Loss: 0.0001850930420914665\n",
      "Epoch 2384, Loss: 0.0013214641658123583, Final Batch Loss: 0.0003698715299833566\n",
      "Epoch 2385, Loss: 0.0006833574807387777, Final Batch Loss: 7.354051194852218e-05\n",
      "Epoch 2386, Loss: 0.0010167281870963052, Final Batch Loss: 0.0002694804279599339\n",
      "Epoch 2387, Loss: 0.0004847303825954441, Final Batch Loss: 0.00020142915309406817\n",
      "Epoch 2388, Loss: 0.015377592499135062, Final Batch Loss: 0.0007657090318389237\n",
      "Epoch 2389, Loss: 0.001688200340140611, Final Batch Loss: 0.0004876475431956351\n",
      "Epoch 2390, Loss: 0.0009860919672064483, Final Batch Loss: 0.00034814851824194193\n",
      "Epoch 2391, Loss: 0.0005789130082121119, Final Batch Loss: 0.0002102277212543413\n",
      "Epoch 2392, Loss: 0.003568908427041606, Final Batch Loss: 2.6719479137682356e-05\n",
      "Epoch 2393, Loss: 0.003885472448018845, Final Batch Loss: 0.00011652157991193235\n",
      "Epoch 2394, Loss: 0.0008961348939919844, Final Batch Loss: 0.0003601429343689233\n",
      "Epoch 2395, Loss: 0.007870071931392886, Final Batch Loss: 0.007078663446009159\n",
      "Epoch 2396, Loss: 0.00024434224906144664, Final Batch Loss: 7.084936805767938e-05\n",
      "Epoch 2397, Loss: 0.0007446773670380935, Final Batch Loss: 5.250691174296662e-05\n",
      "Epoch 2398, Loss: 0.008829263082589023, Final Batch Loss: 0.008337168022990227\n",
      "Epoch 2399, Loss: 0.0017421984084649011, Final Batch Loss: 0.00029232955421321094\n",
      "Epoch 2400, Loss: 0.0020240334342815913, Final Batch Loss: 0.0016858363524079323\n",
      "Epoch 2401, Loss: 0.00011285623259027489, Final Batch Loss: 3.163839573971927e-05\n",
      "Epoch 2402, Loss: 0.0009275569864257704, Final Batch Loss: 2.7339334337739274e-05\n",
      "Epoch 2403, Loss: 0.005643750559102045, Final Batch Loss: 0.00010774182737804949\n",
      "Epoch 2404, Loss: 0.0008042300905799493, Final Batch Loss: 6.0443897382356226e-05\n",
      "Epoch 2405, Loss: 0.0005526094610104337, Final Batch Loss: 9.405099262949079e-05\n",
      "Epoch 2406, Loss: 0.001756742232828401, Final Batch Loss: 0.0002037064841715619\n",
      "Epoch 2407, Loss: 0.0003989899778389372, Final Batch Loss: 0.00012125082866987213\n",
      "Epoch 2408, Loss: 0.0019918122270610183, Final Batch Loss: 0.00029053675825707614\n",
      "Epoch 2409, Loss: 0.0005515523662324995, Final Batch Loss: 0.000296616432024166\n",
      "Epoch 2410, Loss: 0.0008413241012021899, Final Batch Loss: 0.00017902164836414158\n",
      "Epoch 2411, Loss: 0.00026438194799993653, Final Batch Loss: 1.6160987797775306e-05\n",
      "Epoch 2412, Loss: 0.01732923097006278, Final Batch Loss: 5.842373502673581e-05\n",
      "Epoch 2413, Loss: 0.0007594194721605163, Final Batch Loss: 4.6122546336846426e-05\n",
      "Epoch 2414, Loss: 0.0005349611201381776, Final Batch Loss: 0.00011181068111909553\n",
      "Epoch 2415, Loss: 0.00024485724134137854, Final Batch Loss: 0.00013294111704453826\n",
      "Epoch 2416, Loss: 0.003926687903003767, Final Batch Loss: 0.00022204426932148635\n",
      "Epoch 2417, Loss: 0.0008458294323645532, Final Batch Loss: 0.00010611893958412111\n",
      "Epoch 2418, Loss: 0.004898273735307157, Final Batch Loss: 6.195465539349243e-05\n",
      "Epoch 2419, Loss: 0.04079596252995543, Final Batch Loss: 0.04025660455226898\n",
      "Epoch 2420, Loss: 0.0016391155950259417, Final Batch Loss: 0.0009664506651461124\n",
      "Epoch 2421, Loss: 0.0010242678254144266, Final Batch Loss: 0.00048496044473722577\n",
      "Epoch 2422, Loss: 0.0018754148040898144, Final Batch Loss: 0.0001324425102211535\n",
      "Epoch 2423, Loss: 0.0036198485613567755, Final Batch Loss: 0.00017646471678745002\n",
      "Epoch 2424, Loss: 0.010797611728776246, Final Batch Loss: 0.0003558435128070414\n",
      "Epoch 2425, Loss: 0.0014850197694613598, Final Batch Loss: 0.00042327685514464974\n",
      "Epoch 2426, Loss: 0.0006017084306222387, Final Batch Loss: 0.0001057715926435776\n",
      "Epoch 2427, Loss: 0.0017207998607773334, Final Batch Loss: 0.000759770511649549\n",
      "Epoch 2428, Loss: 0.003365974291227758, Final Batch Loss: 0.00039634216227568686\n",
      "Epoch 2429, Loss: 0.0003424342467042152, Final Batch Loss: 7.48395177652128e-05\n",
      "Epoch 2430, Loss: 0.004295394857763313, Final Batch Loss: 0.0004420431505423039\n",
      "Epoch 2431, Loss: 0.02528721404087264, Final Batch Loss: 0.00011938657553400844\n",
      "Epoch 2432, Loss: 0.00042643405322451144, Final Batch Loss: 0.00011609693319769576\n",
      "Epoch 2433, Loss: 0.0010248012258671224, Final Batch Loss: 0.00029365476802922785\n",
      "Epoch 2434, Loss: 0.004283134781871922, Final Batch Loss: 0.004028833471238613\n",
      "Epoch 2435, Loss: 0.0021385587424447294, Final Batch Loss: 4.6552533603971824e-05\n",
      "Epoch 2436, Loss: 0.001513153314590454, Final Batch Loss: 6.304823909886181e-05\n",
      "Epoch 2437, Loss: 0.0011646675447991583, Final Batch Loss: 4.337108475738205e-05\n",
      "Epoch 2438, Loss: 0.002164226745662745, Final Batch Loss: 0.0004141477693337947\n",
      "Epoch 2439, Loss: 0.0011705842043738812, Final Batch Loss: 0.0003875315887853503\n",
      "Epoch 2440, Loss: 0.0007659156835870817, Final Batch Loss: 7.02074175933376e-05\n",
      "Epoch 2441, Loss: 0.0007324981270357966, Final Batch Loss: 6.39084173599258e-05\n",
      "Epoch 2442, Loss: 0.0008970228373073041, Final Batch Loss: 0.00014311878476291895\n",
      "Epoch 2443, Loss: 0.002327064299606718, Final Batch Loss: 7.122122042346746e-05\n",
      "Epoch 2444, Loss: 0.0031855538982199505, Final Batch Loss: 0.0028124582022428513\n",
      "Epoch 2445, Loss: 0.002004108508117497, Final Batch Loss: 0.0008359710918739438\n",
      "Epoch 2446, Loss: 0.0011072317138314247, Final Batch Loss: 0.0001151642354670912\n",
      "Epoch 2447, Loss: 0.0004993448019376956, Final Batch Loss: 0.00016206534928642213\n",
      "Epoch 2448, Loss: 0.00036190552782500163, Final Batch Loss: 0.00014667396317236125\n",
      "Epoch 2449, Loss: 0.001872993738288642, Final Batch Loss: 3.0253309887484647e-05\n",
      "Epoch 2450, Loss: 0.001375401159748435, Final Batch Loss: 0.0008308441611006856\n",
      "Epoch 2451, Loss: 0.0004792904437636025, Final Batch Loss: 0.0001792285911506042\n",
      "Epoch 2452, Loss: 0.0007957178531796671, Final Batch Loss: 3.568034298950806e-05\n",
      "Epoch 2453, Loss: 0.000415972313930979, Final Batch Loss: 4.393125345814042e-05\n",
      "Epoch 2454, Loss: 0.0012864723757957108, Final Batch Loss: 3.845172614092007e-05\n",
      "Epoch 2455, Loss: 0.04150042143010069, Final Batch Loss: 0.0002005721617024392\n",
      "Epoch 2456, Loss: 0.0010573162799119018, Final Batch Loss: 9.838461119215935e-05\n",
      "Epoch 2457, Loss: 0.0008050136066231062, Final Batch Loss: 7.1905496952240355e-06\n",
      "Epoch 2458, Loss: 0.0005268259410513565, Final Batch Loss: 0.00010807740909513086\n",
      "Epoch 2459, Loss: 0.00032358276075683534, Final Batch Loss: 7.443254435202107e-05\n",
      "Epoch 2460, Loss: 0.0013193545019021258, Final Batch Loss: 0.00018479906430002302\n",
      "Epoch 2461, Loss: 0.0009564860556565691, Final Batch Loss: 4.3027630454162136e-05\n",
      "Epoch 2462, Loss: 0.0008978204205050133, Final Batch Loss: 2.6261892344336957e-05\n",
      "Epoch 2463, Loss: 0.0004702690930571407, Final Batch Loss: 0.00031913997372612357\n",
      "Epoch 2464, Loss: 0.0005473556020660908, Final Batch Loss: 1.142401833931217e-05\n",
      "Epoch 2465, Loss: 0.00047436446766369045, Final Batch Loss: 0.00014012226893100888\n",
      "Epoch 2466, Loss: 0.001643477226025425, Final Batch Loss: 0.0008186553022824228\n",
      "Epoch 2467, Loss: 0.00038237108674366027, Final Batch Loss: 0.000189439146197401\n",
      "Epoch 2468, Loss: 0.00010730910526035586, Final Batch Loss: 1.4200669284036849e-05\n",
      "Epoch 2469, Loss: 0.0010812141044880264, Final Batch Loss: 0.00039390119491145015\n",
      "Epoch 2470, Loss: 0.0004563676193356514, Final Batch Loss: 0.00014124199515208602\n",
      "Epoch 2471, Loss: 0.002932912320829928, Final Batch Loss: 0.0001971930032595992\n",
      "Epoch 2472, Loss: 0.0007505413523176685, Final Batch Loss: 0.0002672801783774048\n",
      "Epoch 2473, Loss: 0.0019529250712366775, Final Batch Loss: 0.0014434409094974399\n",
      "Epoch 2474, Loss: 0.0003663890347525012, Final Batch Loss: 7.588700827909634e-05\n",
      "Epoch 2475, Loss: 0.00564541325729806, Final Batch Loss: 0.00013113465684000403\n",
      "Epoch 2476, Loss: 0.0012788873864337802, Final Batch Loss: 0.000152747321408242\n",
      "Epoch 2477, Loss: 0.0003418956694076769, Final Batch Loss: 0.00012540216266643256\n",
      "Epoch 2478, Loss: 0.0006008502059557941, Final Batch Loss: 3.455926707829349e-05\n",
      "Epoch 2479, Loss: 0.0021944545151200145, Final Batch Loss: 0.0013446112861856818\n",
      "Epoch 2480, Loss: 0.0001690406606940087, Final Batch Loss: 1.6836052964208648e-05\n",
      "Epoch 2481, Loss: 0.00014513831411022693, Final Batch Loss: 4.066140900249593e-05\n",
      "Epoch 2482, Loss: 0.0008060213949647732, Final Batch Loss: 6.879700958961621e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2483, Loss: 0.00042833103725570254, Final Batch Loss: 5.707838499802165e-05\n",
      "Epoch 2484, Loss: 0.001095122002880089, Final Batch Loss: 0.0005791512667201459\n",
      "Epoch 2485, Loss: 0.0003069105059694266, Final Batch Loss: 1.8410484699415974e-05\n",
      "Epoch 2486, Loss: 0.00021016263781348243, Final Batch Loss: 5.488637543749064e-05\n",
      "Epoch 2487, Loss: 0.0011749473196687177, Final Batch Loss: 0.00011291868577245623\n",
      "Epoch 2488, Loss: 0.00023633658929611556, Final Batch Loss: 3.342831041663885e-05\n",
      "Epoch 2489, Loss: 0.0004929432179778814, Final Batch Loss: 0.0002487059682607651\n",
      "Epoch 2490, Loss: 0.0008651870957692154, Final Batch Loss: 8.644648914923891e-05\n",
      "Epoch 2491, Loss: 0.0014093377958488418, Final Batch Loss: 0.0012926541967317462\n",
      "Epoch 2492, Loss: 0.00043419266876298934, Final Batch Loss: 0.00012791043263860047\n",
      "Epoch 2493, Loss: 0.0015660004573874176, Final Batch Loss: 7.50915496610105e-05\n",
      "Epoch 2494, Loss: 0.00015012931180535816, Final Batch Loss: 4.2198786104563624e-05\n",
      "Epoch 2495, Loss: 0.016154089877090883, Final Batch Loss: 0.01591053046286106\n",
      "Epoch 2496, Loss: 0.028665618741797516, Final Batch Loss: 3.1573468731949106e-05\n",
      "Epoch 2497, Loss: 0.004265430608938914, Final Batch Loss: 0.00012018546840408817\n",
      "Epoch 2498, Loss: 0.0014914905768819153, Final Batch Loss: 0.0007343158358708024\n",
      "Epoch 2499, Loss: 0.03260335687082261, Final Batch Loss: 0.031944241374731064\n",
      "Epoch 2500, Loss: 0.0006133853748906404, Final Batch Loss: 0.0002308426337549463\n",
      "Epoch 2501, Loss: 0.0009599575423635542, Final Batch Loss: 0.00028641673270612955\n",
      "Epoch 2502, Loss: 0.0033843084747786634, Final Batch Loss: 0.002994867041707039\n",
      "Epoch 2503, Loss: 0.0007054514244373422, Final Batch Loss: 4.91606151626911e-05\n",
      "Epoch 2504, Loss: 0.02031867590631009, Final Batch Loss: 2.6655852707335725e-05\n",
      "Epoch 2505, Loss: 0.000859752886753995, Final Batch Loss: 0.0005416193744167686\n",
      "Epoch 2506, Loss: 0.0010967872804030776, Final Batch Loss: 6.144533108454198e-05\n",
      "Epoch 2507, Loss: 0.00108452737913467, Final Batch Loss: 0.0001602572447154671\n",
      "Epoch 2508, Loss: 0.0005691115875379182, Final Batch Loss: 0.00016114870959427208\n",
      "Epoch 2509, Loss: 0.0017303403874393553, Final Batch Loss: 6.597083120141178e-05\n",
      "Epoch 2510, Loss: 0.0016155968260136433, Final Batch Loss: 8.900932152755558e-05\n",
      "Epoch 2511, Loss: 0.02623132419466856, Final Batch Loss: 1.3918044714955613e-05\n",
      "Epoch 2512, Loss: 0.00023127097665565088, Final Batch Loss: 8.366062684217468e-05\n",
      "Epoch 2513, Loss: 0.003529127010551747, Final Batch Loss: 8.679381426190957e-05\n",
      "Epoch 2514, Loss: 0.00021281971567077562, Final Batch Loss: 0.00010862110502785072\n",
      "Epoch 2515, Loss: 0.006432242473238148, Final Batch Loss: 0.006068513263016939\n",
      "Epoch 2516, Loss: 0.001476555087720044, Final Batch Loss: 0.001022550743073225\n",
      "Epoch 2517, Loss: 0.0012307327124290168, Final Batch Loss: 0.0007862740312702954\n",
      "Epoch 2518, Loss: 0.00040011539385886863, Final Batch Loss: 0.00011580094724195078\n",
      "Epoch 2519, Loss: 0.00045222268090583384, Final Batch Loss: 0.0002982307050842792\n",
      "Epoch 2520, Loss: 0.0006179577903822064, Final Batch Loss: 0.00020565577142406255\n",
      "Epoch 2521, Loss: 0.0025863952469080687, Final Batch Loss: 0.0011545392917469144\n",
      "Epoch 2522, Loss: 0.00025107759938691743, Final Batch Loss: 0.0001080117144738324\n",
      "Epoch 2523, Loss: 0.0003041606296392274, Final Batch Loss: 1.3461512025969569e-05\n",
      "Epoch 2524, Loss: 0.0013826643262291327, Final Batch Loss: 0.0006788806058466434\n",
      "Epoch 2525, Loss: 0.0004392878763610497, Final Batch Loss: 0.00014626716438215226\n",
      "Epoch 2526, Loss: 0.0009500728519924451, Final Batch Loss: 0.00011128625192213804\n",
      "Epoch 2527, Loss: 0.0014895126150804572, Final Batch Loss: 0.00020944789866916835\n",
      "Epoch 2528, Loss: 0.0006861711335659493, Final Batch Loss: 4.278941560187377e-05\n",
      "Epoch 2529, Loss: 0.0014201914054865483, Final Batch Loss: 4.508329220698215e-05\n",
      "Epoch 2530, Loss: 0.0005555830284720287, Final Batch Loss: 0.0002323012740816921\n",
      "Epoch 2531, Loss: 0.0015961776080075651, Final Batch Loss: 0.0001874638837762177\n",
      "Epoch 2532, Loss: 0.0004484212986426428, Final Batch Loss: 0.0002122618316207081\n",
      "Epoch 2533, Loss: 0.004405177664011717, Final Batch Loss: 0.002426246413961053\n",
      "Epoch 2534, Loss: 0.0002369949761487078, Final Batch Loss: 5.851571404491551e-05\n",
      "Epoch 2535, Loss: 0.0030541701707988977, Final Batch Loss: 0.00017992696666624397\n",
      "Epoch 2536, Loss: 0.005007588304579258, Final Batch Loss: 0.004237407818436623\n",
      "Epoch 2537, Loss: 0.00014776524039916694, Final Batch Loss: 4.073267336934805e-05\n",
      "Epoch 2538, Loss: 0.0002030592422670452, Final Batch Loss: 4.370729948277585e-05\n",
      "Epoch 2539, Loss: 0.0025856511492747813, Final Batch Loss: 0.001175832818262279\n",
      "Epoch 2540, Loss: 0.000292748798528919, Final Batch Loss: 3.7014764529885724e-05\n",
      "Epoch 2541, Loss: 0.0037759466213174164, Final Batch Loss: 1.8413978978060186e-05\n",
      "Epoch 2542, Loss: 0.003213844232959673, Final Batch Loss: 0.0030158909503370523\n",
      "Epoch 2543, Loss: 0.0006323232446447946, Final Batch Loss: 7.883961370680481e-05\n",
      "Epoch 2544, Loss: 0.0003812923387158662, Final Batch Loss: 0.00012086654169252142\n",
      "Epoch 2545, Loss: 0.0007153152264436358, Final Batch Loss: 8.887408512237016e-06\n",
      "Epoch 2546, Loss: 0.00451428350788774, Final Batch Loss: 3.466779162408784e-05\n",
      "Epoch 2547, Loss: 0.0006106148575781845, Final Batch Loss: 0.0003115053696092218\n",
      "Epoch 2548, Loss: 0.0008915166763472371, Final Batch Loss: 7.155411731218919e-05\n",
      "Epoch 2549, Loss: 0.0008676961588207632, Final Batch Loss: 7.947595440782607e-05\n",
      "Epoch 2550, Loss: 0.0010147715656785294, Final Batch Loss: 0.0006921787862665951\n",
      "Epoch 2551, Loss: 0.0015130652027437463, Final Batch Loss: 0.00020153298100922257\n",
      "Epoch 2552, Loss: 0.00013161021342966706, Final Batch Loss: 4.494432869250886e-05\n",
      "Epoch 2553, Loss: 0.0011308851680951193, Final Batch Loss: 0.0009463981841690838\n",
      "Epoch 2554, Loss: 0.006101092293647525, Final Batch Loss: 4.163527046330273e-05\n",
      "Epoch 2555, Loss: 0.007062019984005019, Final Batch Loss: 0.006854939740151167\n",
      "Epoch 2556, Loss: 0.0005546163920371328, Final Batch Loss: 1.633621650398709e-05\n",
      "Epoch 2557, Loss: 0.0014765183441340923, Final Batch Loss: 0.00020823627710342407\n",
      "Epoch 2558, Loss: 0.0009009801378851989, Final Batch Loss: 2.7827851226902567e-05\n",
      "Epoch 2559, Loss: 9.883893108053599e-05, Final Batch Loss: 1.3751576261711307e-05\n",
      "Epoch 2560, Loss: 0.0005615065238089301, Final Batch Loss: 0.00027311628218740225\n",
      "Epoch 2561, Loss: 0.00022143058959045447, Final Batch Loss: 5.720211993320845e-05\n",
      "Epoch 2562, Loss: 0.00046569421283493284, Final Batch Loss: 3.908726284862496e-06\n",
      "Epoch 2563, Loss: 0.0004214034997858107, Final Batch Loss: 0.0002226895885542035\n",
      "Epoch 2564, Loss: 0.00030108777718851343, Final Batch Loss: 0.00015490507939830422\n",
      "Epoch 2565, Loss: 0.00024213474171119742, Final Batch Loss: 5.593089008470997e-05\n",
      "Epoch 2566, Loss: 0.00033340822119498625, Final Batch Loss: 9.608512482373044e-05\n",
      "Epoch 2567, Loss: 0.0005031558175687678, Final Batch Loss: 6.554328138008714e-05\n",
      "Epoch 2568, Loss: 0.00010932078521364019, Final Batch Loss: 3.4858226172218565e-06\n",
      "Epoch 2569, Loss: 0.0008453029931843048, Final Batch Loss: 1.8403303329250775e-05\n",
      "Epoch 2570, Loss: 0.0004677673709920782, Final Batch Loss: 5.6158310144382995e-06\n",
      "Epoch 2571, Loss: 0.0012260636085557053, Final Batch Loss: 2.8322774596745148e-05\n",
      "Epoch 2572, Loss: 0.00014300822385848733, Final Batch Loss: 1.8680568246054463e-05\n",
      "Epoch 2573, Loss: 0.0007992874998308253, Final Batch Loss: 8.921739208744839e-06\n",
      "Epoch 2574, Loss: 0.001095540103960957, Final Batch Loss: 1.0776891031127889e-05\n",
      "Epoch 2575, Loss: 0.00017570693125890102, Final Batch Loss: 2.295147169206757e-05\n",
      "Epoch 2576, Loss: 0.000997626077150926, Final Batch Loss: 0.00012935500126332045\n",
      "Epoch 2577, Loss: 0.0006641985746682622, Final Batch Loss: 0.0003951299877371639\n",
      "Epoch 2578, Loss: 0.00021473841297847684, Final Batch Loss: 0.00016313401283696294\n",
      "Epoch 2579, Loss: 5.784180348200607e-05, Final Batch Loss: 6.358089649438625e-06\n",
      "Epoch 2580, Loss: 0.0001803645063773729, Final Batch Loss: 5.280324330669828e-05\n",
      "Epoch 2581, Loss: 0.0012880377062174375, Final Batch Loss: 1.3676911294169258e-05\n",
      "Epoch 2582, Loss: 0.00015572474330838304, Final Batch Loss: 2.0589728592312895e-05\n",
      "Epoch 2583, Loss: 0.000579638006456662, Final Batch Loss: 0.00011904037819476798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2584, Loss: 0.0015433538210345432, Final Batch Loss: 6.163498619571328e-05\n",
      "Epoch 2585, Loss: 0.0001837752788560465, Final Batch Loss: 0.00013898500765208155\n",
      "Epoch 2586, Loss: 0.0010614732000249205, Final Batch Loss: 8.418884681304917e-05\n",
      "Epoch 2587, Loss: 0.0002708642277866602, Final Batch Loss: 0.00018819814431481063\n",
      "Epoch 2588, Loss: 0.012945106673214468, Final Batch Loss: 1.9622053514467552e-05\n",
      "Epoch 2589, Loss: 0.0006413448654711829, Final Batch Loss: 0.0005624989862553775\n",
      "Epoch 2590, Loss: 0.0006979283934924752, Final Batch Loss: 0.00020337708701845258\n",
      "Epoch 2591, Loss: 0.0003178208389726933, Final Batch Loss: 0.00016313124797306955\n",
      "Epoch 2592, Loss: 0.004629720206139609, Final Batch Loss: 0.000674525392241776\n",
      "Epoch 2593, Loss: 0.000999477633740753, Final Batch Loss: 0.00013790976663585752\n",
      "Epoch 2594, Loss: 0.0008586199546698481, Final Batch Loss: 0.000206584416446276\n",
      "Epoch 2595, Loss: 0.0003795632983383257, Final Batch Loss: 0.00013217548257671297\n",
      "Epoch 2596, Loss: 0.0010664809815352783, Final Batch Loss: 7.007196836639196e-05\n",
      "Epoch 2597, Loss: 0.0004215973208374635, Final Batch Loss: 0.00011008097499143332\n",
      "Epoch 2598, Loss: 9.222364769811975e-05, Final Batch Loss: 1.1813933269877452e-05\n",
      "Epoch 2599, Loss: 0.0004432705318322405, Final Batch Loss: 7.101151277311146e-05\n",
      "Epoch 2600, Loss: 0.0009695319258753443, Final Batch Loss: 0.0006997112650424242\n",
      "Epoch 2601, Loss: 0.0006446104307542555, Final Batch Loss: 7.942858064780012e-05\n",
      "Epoch 2602, Loss: 0.0011988295846094843, Final Batch Loss: 4.336406345828436e-05\n",
      "Epoch 2603, Loss: 0.00040383411032962613, Final Batch Loss: 2.9351922421483323e-05\n",
      "Epoch 2604, Loss: 8.594201972300652e-05, Final Batch Loss: 3.797600948018953e-05\n",
      "Epoch 2605, Loss: 0.001630424298127764, Final Batch Loss: 0.0012321401154622436\n",
      "Epoch 2606, Loss: 0.0007337319302678225, Final Batch Loss: 3.135442238999531e-05\n",
      "Epoch 2607, Loss: 0.00016415415393566946, Final Batch Loss: 9.04780699784169e-06\n",
      "Epoch 2608, Loss: 0.009658872239015182, Final Batch Loss: 1.2102269465685822e-05\n",
      "Epoch 2609, Loss: 0.016389817555591435, Final Batch Loss: 3.5943626244261395e-06\n",
      "Epoch 2610, Loss: 0.00018963647744385526, Final Batch Loss: 5.952819992671721e-05\n",
      "Epoch 2611, Loss: 0.00013677556034963345, Final Batch Loss: 4.291351615393069e-06\n",
      "Epoch 2612, Loss: 0.0002389798919466557, Final Batch Loss: 1.9608787624747492e-05\n",
      "Epoch 2613, Loss: 0.010686146553780418, Final Batch Loss: 0.00012212179717607796\n",
      "Epoch 2614, Loss: 0.0002357554876653012, Final Batch Loss: 3.520278914947994e-05\n",
      "Epoch 2615, Loss: 0.001026283904138836, Final Batch Loss: 0.00014870369341224432\n",
      "Epoch 2616, Loss: 0.0013086451981507707, Final Batch Loss: 1.5447109035449103e-05\n",
      "Epoch 2617, Loss: 0.0005682861919922289, Final Batch Loss: 6.058180224499665e-05\n",
      "Epoch 2618, Loss: 0.00048302528739441186, Final Batch Loss: 8.249986422015354e-05\n",
      "Epoch 2619, Loss: 0.004328784969402477, Final Batch Loss: 0.00043689095764420927\n",
      "Epoch 2620, Loss: 0.0008313511934829876, Final Batch Loss: 0.00011422524403315037\n",
      "Epoch 2621, Loss: 0.0006139820243333816, Final Batch Loss: 9.550206414132845e-06\n",
      "Epoch 2622, Loss: 0.0018044869575533085, Final Batch Loss: 3.2823496439959854e-05\n",
      "Epoch 2623, Loss: 0.0005092757273814641, Final Batch Loss: 5.4050695325713605e-05\n",
      "Epoch 2624, Loss: 0.0004281653345969971, Final Batch Loss: 0.00029970414470881224\n",
      "Epoch 2625, Loss: 0.00030450988560914993, Final Batch Loss: 2.4419176043011248e-05\n",
      "Epoch 2626, Loss: 0.000980122851615306, Final Batch Loss: 0.00011840133083751425\n",
      "Epoch 2627, Loss: 0.0005761434367741458, Final Batch Loss: 0.00013972310989629477\n",
      "Epoch 2628, Loss: 0.001492081384640187, Final Batch Loss: 0.0008390843868255615\n",
      "Epoch 2629, Loss: 0.0004082437535544159, Final Batch Loss: 2.0484165361267515e-05\n",
      "Epoch 2630, Loss: 0.0002934642643594998, Final Batch Loss: 6.729332380928099e-05\n",
      "Epoch 2631, Loss: 0.0004944231368426699, Final Batch Loss: 0.00032529476447962224\n",
      "Epoch 2632, Loss: 0.00043505373469088227, Final Batch Loss: 9.152069833362475e-05\n",
      "Epoch 2633, Loss: 0.00041751460230443627, Final Batch Loss: 0.0001552659523440525\n",
      "Epoch 2634, Loss: 0.0005684097377525177, Final Batch Loss: 2.5939658371498808e-05\n",
      "Epoch 2635, Loss: 0.0005324453304638155, Final Batch Loss: 0.00024247626424767077\n",
      "Epoch 2636, Loss: 0.00039605102938367054, Final Batch Loss: 6.867040792712942e-05\n",
      "Epoch 2637, Loss: 0.005339168348655221, Final Batch Loss: 9.410512575414032e-05\n",
      "Epoch 2638, Loss: 0.0018832446112355683, Final Batch Loss: 0.00020850819419138134\n",
      "Epoch 2639, Loss: 0.02322408118561725, Final Batch Loss: 2.789384961943142e-05\n",
      "Epoch 2640, Loss: 0.00027850042170030065, Final Batch Loss: 8.067237649811432e-05\n",
      "Epoch 2641, Loss: 0.0004613622004399076, Final Batch Loss: 8.272039121948183e-05\n",
      "Epoch 2642, Loss: 0.0005582950107054785, Final Batch Loss: 8.64483808982186e-05\n",
      "Epoch 2643, Loss: 0.0013004764296056237, Final Batch Loss: 0.00010673440556274727\n",
      "Epoch 2644, Loss: 0.0015719041475676931, Final Batch Loss: 3.615480090957135e-05\n",
      "Epoch 2645, Loss: 0.0006719131124555133, Final Batch Loss: 0.00047633491340093315\n",
      "Epoch 2646, Loss: 0.012611833488335833, Final Batch Loss: 0.0016638432862237096\n",
      "Epoch 2647, Loss: 0.0003432290093314805, Final Batch Loss: 1.694844058874878e-06\n",
      "Epoch 2648, Loss: 0.007332750712521374, Final Batch Loss: 0.006428358610719442\n",
      "Epoch 2649, Loss: 0.0004351908137323335, Final Batch Loss: 0.0002039235841948539\n",
      "Epoch 2650, Loss: 0.0018387676873317105, Final Batch Loss: 1.379557670588838e-05\n",
      "Epoch 2651, Loss: 0.0033428444439778104, Final Batch Loss: 0.00018863037985283881\n",
      "Epoch 2652, Loss: 0.00045951699212309904, Final Batch Loss: 2.536150350351818e-05\n",
      "Epoch 2653, Loss: 0.0005200156374485232, Final Batch Loss: 0.0001273892557946965\n",
      "Epoch 2654, Loss: 0.0026733626073109917, Final Batch Loss: 0.0025482673663645983\n",
      "Epoch 2655, Loss: 0.00622122676577419, Final Batch Loss: 0.004495775792747736\n",
      "Epoch 2656, Loss: 0.0012377915682009188, Final Batch Loss: 1.2397313184919767e-05\n",
      "Epoch 2657, Loss: 0.00012072880053892732, Final Batch Loss: 3.302041659480892e-05\n",
      "Epoch 2658, Loss: 0.007062736743137066, Final Batch Loss: 3.5317701986059546e-05\n",
      "Epoch 2659, Loss: 0.00016882791351235937, Final Batch Loss: 2.560185566835571e-05\n",
      "Epoch 2660, Loss: 0.041269662255217554, Final Batch Loss: 0.0005002566031180322\n",
      "Epoch 2661, Loss: 0.002686121177248424, Final Batch Loss: 0.00246429699473083\n",
      "Epoch 2662, Loss: 0.0025811934283410665, Final Batch Loss: 3.868687417707406e-05\n",
      "Epoch 2663, Loss: 0.0058405087038408965, Final Batch Loss: 0.0002805441617965698\n",
      "Epoch 2664, Loss: 0.0007602464611409232, Final Batch Loss: 6.693881732644513e-05\n",
      "Epoch 2665, Loss: 0.0005184663241379894, Final Batch Loss: 7.264772284543142e-05\n",
      "Epoch 2666, Loss: 0.002866420240025036, Final Batch Loss: 0.0005347481346689165\n",
      "Epoch 2667, Loss: 0.0008618857100373134, Final Batch Loss: 0.00047099587391130626\n",
      "Epoch 2668, Loss: 0.0013161719543859363, Final Batch Loss: 0.0009159036562778056\n",
      "Epoch 2669, Loss: 0.003764897307519277, Final Batch Loss: 1.2245184734638315e-05\n",
      "Epoch 2670, Loss: 0.00047697113404865377, Final Batch Loss: 1.1425345292082056e-05\n",
      "Epoch 2671, Loss: 0.00015024611388980702, Final Batch Loss: 3.1338761345978128e-06\n",
      "Epoch 2672, Loss: 0.0003664221876533702, Final Batch Loss: 4.426403029356152e-05\n",
      "Epoch 2673, Loss: 0.001215261479956098, Final Batch Loss: 0.00032126501901075244\n",
      "Epoch 2674, Loss: 0.006640334744588472, Final Batch Loss: 0.005526240915060043\n",
      "Epoch 2675, Loss: 0.0006238773457880598, Final Batch Loss: 0.0004969905712641776\n",
      "Epoch 2676, Loss: 0.0003009589418070391, Final Batch Loss: 8.757990144658834e-06\n",
      "Epoch 2677, Loss: 0.00010489345913811121, Final Batch Loss: 1.8141048713005148e-05\n",
      "Epoch 2678, Loss: 0.0033303633390460163, Final Batch Loss: 0.00015972669643815607\n",
      "Epoch 2679, Loss: 0.001071688617230393, Final Batch Loss: 0.0005925226141698658\n",
      "Epoch 2680, Loss: 0.008801426331046969, Final Batch Loss: 0.007693661842495203\n",
      "Epoch 2681, Loss: 0.0006111874208727386, Final Batch Loss: 0.00041109780431725085\n",
      "Epoch 2682, Loss: 0.0003280266610090621, Final Batch Loss: 0.00020280612807255238\n",
      "Epoch 2683, Loss: 0.0060642145908786915, Final Batch Loss: 0.00034673369373194873\n",
      "Epoch 2684, Loss: 0.006303094050963409, Final Batch Loss: 0.00013152598694432527\n",
      "Epoch 2685, Loss: 0.0005142173686181195, Final Batch Loss: 5.712928395951167e-05\n",
      "Epoch 2686, Loss: 0.0003410409808566328, Final Batch Loss: 7.078679482219741e-05\n",
      "Epoch 2687, Loss: 0.0003548659042280633, Final Batch Loss: 0.00015694525791332126\n",
      "Epoch 2688, Loss: 0.0005160099135537166, Final Batch Loss: 3.4968488762388006e-05\n",
      "Epoch 2689, Loss: 0.0006367278292600531, Final Batch Loss: 5.7623419706942514e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2690, Loss: 0.00024149830278474838, Final Batch Loss: 8.467864245176315e-05\n",
      "Epoch 2691, Loss: 0.0001083910683519207, Final Batch Loss: 6.999174365773797e-05\n",
      "Epoch 2692, Loss: 0.00022801447994424962, Final Batch Loss: 0.00012734792835544795\n",
      "Epoch 2693, Loss: 0.00030769346813031007, Final Batch Loss: 3.431302320677787e-05\n",
      "Epoch 2694, Loss: 0.007001921214396134, Final Batch Loss: 4.037938197143376e-05\n",
      "Epoch 2695, Loss: 0.0008021239154913928, Final Batch Loss: 3.4014741686405614e-05\n",
      "Epoch 2696, Loss: 0.001834237291404861, Final Batch Loss: 7.820182872819714e-06\n",
      "Epoch 2697, Loss: 0.014801413446548395, Final Batch Loss: 9.643936937209219e-05\n",
      "Epoch 2698, Loss: 0.004105859465198591, Final Batch Loss: 0.00012323631381150335\n",
      "Epoch 2699, Loss: 0.0002464295248501003, Final Batch Loss: 4.638056270778179e-05\n",
      "Epoch 2700, Loss: 0.00034037923251162283, Final Batch Loss: 8.759043703321368e-05\n",
      "Epoch 2701, Loss: 0.0006673552470601862, Final Batch Loss: 1.3143673641025089e-05\n",
      "Epoch 2702, Loss: 0.0003613433727878146, Final Batch Loss: 0.00021878656116314232\n",
      "Epoch 2703, Loss: 0.0006475862464867532, Final Batch Loss: 0.0005726273520849645\n",
      "Epoch 2704, Loss: 0.00020810977002838627, Final Batch Loss: 0.0001336371642537415\n",
      "Epoch 2705, Loss: 0.03560962692426983, Final Batch Loss: 0.035338666290044785\n",
      "Epoch 2706, Loss: 0.0005005973725928925, Final Batch Loss: 0.00019021780462935567\n",
      "Epoch 2707, Loss: 0.0010528980819799472, Final Batch Loss: 0.0008723273640498519\n",
      "Epoch 2708, Loss: 0.00010493206536921207, Final Batch Loss: 1.8785516658681445e-05\n",
      "Epoch 2709, Loss: 0.0010646798073139507, Final Batch Loss: 6.015239705448039e-05\n",
      "Epoch 2710, Loss: 0.0004265066818334162, Final Batch Loss: 0.00011727479432011023\n",
      "Epoch 2711, Loss: 0.00011571532013476826, Final Batch Loss: 3.333300628582947e-05\n",
      "Epoch 2712, Loss: 0.0004613300698110834, Final Batch Loss: 5.209958180785179e-05\n",
      "Epoch 2713, Loss: 0.0008543072544853203, Final Batch Loss: 4.264819290256128e-05\n",
      "Epoch 2714, Loss: 0.0013394402631092817, Final Batch Loss: 0.0006221830262802541\n",
      "Epoch 2715, Loss: 0.0008942816602939274, Final Batch Loss: 0.00033295576577074826\n",
      "Epoch 2716, Loss: 0.0012495727423811331, Final Batch Loss: 0.00058078917209059\n",
      "Epoch 2717, Loss: 0.0007658125832676888, Final Batch Loss: 0.0005842262180522084\n",
      "Epoch 2718, Loss: 0.001058497749909293, Final Batch Loss: 9.019001299748197e-05\n",
      "Epoch 2719, Loss: 0.0007282346850843169, Final Batch Loss: 6.75343326292932e-05\n",
      "Epoch 2720, Loss: 0.004131166484512505, Final Batch Loss: 2.6087438527611084e-05\n",
      "Epoch 2721, Loss: 0.0009149621109827422, Final Batch Loss: 0.00022259891557041556\n",
      "Epoch 2722, Loss: 0.0011877103970618919, Final Batch Loss: 0.0007430643890984356\n",
      "Epoch 2723, Loss: 0.0008793279412202537, Final Batch Loss: 0.00010307001502951607\n",
      "Epoch 2724, Loss: 0.0003279415946053632, Final Batch Loss: 5.8358750720799435e-06\n",
      "Epoch 2725, Loss: 0.00013735292304772884, Final Batch Loss: 2.502025745343417e-05\n",
      "Epoch 2726, Loss: 0.0024704768729861826, Final Batch Loss: 0.0004754744004458189\n",
      "Epoch 2727, Loss: 0.0008618993451818824, Final Batch Loss: 0.0006805669399909675\n",
      "Epoch 2728, Loss: 0.00037447728755068965, Final Batch Loss: 0.00021387332526501268\n",
      "Epoch 2729, Loss: 0.00817255958372698, Final Batch Loss: 1.4739230209670495e-05\n",
      "Epoch 2730, Loss: 0.0009963230113498867, Final Batch Loss: 0.0008872827747836709\n",
      "Epoch 2731, Loss: 0.0007426075553667033, Final Batch Loss: 7.113460742402822e-05\n",
      "Epoch 2732, Loss: 0.000949271212448366, Final Batch Loss: 0.00032997337984852493\n",
      "Epoch 2733, Loss: 0.0007940882860566489, Final Batch Loss: 5.845521081937477e-05\n",
      "Epoch 2734, Loss: 0.01227800885681063, Final Batch Loss: 0.00019453710410743952\n",
      "Epoch 2735, Loss: 0.00036982231176807545, Final Batch Loss: 0.00010176117211813107\n",
      "Epoch 2736, Loss: 0.0006058660801500082, Final Batch Loss: 9.238143684342504e-05\n",
      "Epoch 2737, Loss: 0.0017278095401707105, Final Batch Loss: 5.834810872329399e-05\n",
      "Epoch 2738, Loss: 0.00018294958499609493, Final Batch Loss: 5.612457243842073e-05\n",
      "Epoch 2739, Loss: 0.0016105304966913536, Final Batch Loss: 0.00017782258510123938\n",
      "Epoch 2740, Loss: 0.00038207760007935576, Final Batch Loss: 0.00022702151909470558\n",
      "Epoch 2741, Loss: 0.0019183022959623486, Final Batch Loss: 0.000855814665555954\n",
      "Epoch 2742, Loss: 0.0006562043017765973, Final Batch Loss: 0.0005614251713268459\n",
      "Epoch 2743, Loss: 0.0011834633769467473, Final Batch Loss: 0.00026398926274850965\n",
      "Epoch 2744, Loss: 0.00020955074433004484, Final Batch Loss: 4.7811801778152585e-05\n",
      "Epoch 2745, Loss: 0.00047013219409564044, Final Batch Loss: 2.1291087250574492e-05\n",
      "Epoch 2746, Loss: 0.00046052562902332284, Final Batch Loss: 4.040552084916271e-05\n",
      "Epoch 2747, Loss: 0.0017769897708603821, Final Batch Loss: 0.00010527396807447076\n",
      "Epoch 2748, Loss: 0.0034685063146753237, Final Batch Loss: 0.00011395290493965149\n",
      "Epoch 2749, Loss: 0.000422745415562531, Final Batch Loss: 3.873995228786953e-05\n",
      "Epoch 2750, Loss: 0.00012953919940628111, Final Batch Loss: 7.384214404737577e-05\n",
      "Epoch 2751, Loss: 0.0002396533436694881, Final Batch Loss: 9.103727279580198e-06\n",
      "Epoch 2752, Loss: 0.0005150985261934693, Final Batch Loss: 7.66224093240453e-06\n",
      "Epoch 2753, Loss: 0.000422675657318905, Final Batch Loss: 0.000187293830094859\n",
      "Epoch 2754, Loss: 0.00034423604847688694, Final Batch Loss: 2.2125694158603437e-05\n",
      "Epoch 2755, Loss: 0.03706999907444697, Final Batch Loss: 3.380612179171294e-05\n",
      "Epoch 2756, Loss: 0.00022539173369295895, Final Batch Loss: 6.205699173733592e-05\n",
      "Epoch 2757, Loss: 0.00023915188285172917, Final Batch Loss: 3.786808520089835e-05\n",
      "Epoch 2758, Loss: 0.00016109298667288385, Final Batch Loss: 3.79478806280531e-05\n",
      "Epoch 2759, Loss: 0.0005236816286924295, Final Batch Loss: 0.00032287146314047277\n",
      "Epoch 2760, Loss: 0.0007348832969000796, Final Batch Loss: 8.256271030404605e-06\n",
      "Epoch 2761, Loss: 0.00044836659253633115, Final Batch Loss: 0.00017930717149283737\n",
      "Epoch 2762, Loss: 0.00287837930227397, Final Batch Loss: 7.18744850018993e-05\n",
      "Epoch 2763, Loss: 0.0003616440908444929, Final Batch Loss: 7.094170541677158e-06\n",
      "Epoch 2764, Loss: 0.0016438491857115878, Final Batch Loss: 4.6977038437034935e-05\n",
      "Epoch 2765, Loss: 5.9466599395818776e-05, Final Batch Loss: 1.9553340280253906e-06\n",
      "Epoch 2766, Loss: 0.0004215114895487204, Final Batch Loss: 7.70885162637569e-05\n",
      "Epoch 2767, Loss: 0.00020813835180888418, Final Batch Loss: 2.6642695956979878e-05\n",
      "Epoch 2768, Loss: 0.00012607363396455185, Final Batch Loss: 3.103205017396249e-06\n",
      "Epoch 2769, Loss: 0.004845097173529211, Final Batch Loss: 4.060779610881582e-05\n",
      "Epoch 2770, Loss: 8.521852760168258e-05, Final Batch Loss: 2.1198908143560402e-05\n",
      "Epoch 2771, Loss: 0.00012918955144414213, Final Batch Loss: 2.1539262888836674e-05\n",
      "Epoch 2772, Loss: 0.00012603779316577857, Final Batch Loss: 1.47081584600528e-06\n",
      "Epoch 2773, Loss: 0.001307489896134939, Final Batch Loss: 0.001174983917735517\n",
      "Epoch 2774, Loss: 0.0002840607885445934, Final Batch Loss: 0.00013263589062262326\n",
      "Epoch 2775, Loss: 0.0012650411445065401, Final Batch Loss: 1.621740375412628e-05\n",
      "Epoch 2776, Loss: 0.00023419508761435281, Final Batch Loss: 1.659155350353103e-05\n",
      "Epoch 2777, Loss: 0.00013416917499853298, Final Batch Loss: 2.56053390330635e-05\n",
      "Epoch 2778, Loss: 0.0008214362969738431, Final Batch Loss: 0.0007532514864578843\n",
      "Epoch 2779, Loss: 0.0010893451294577972, Final Batch Loss: 5.021615379519062e-06\n",
      "Epoch 2780, Loss: 8.954094482760411e-05, Final Batch Loss: 4.589354830386583e-06\n",
      "Epoch 2781, Loss: 0.00028268533606023993, Final Batch Loss: 5.006024002796039e-05\n",
      "Epoch 2782, Loss: 7.020346066610728e-05, Final Batch Loss: 7.017891334726301e-07\n",
      "Epoch 2783, Loss: 0.0006857662483525928, Final Batch Loss: 1.0275583917973563e-05\n",
      "Epoch 2784, Loss: 0.00022374294167093467, Final Batch Loss: 9.61868317972403e-06\n",
      "Epoch 2785, Loss: 0.00014002320040162886, Final Batch Loss: 6.0794582168455236e-06\n",
      "Epoch 2786, Loss: 0.0008471924720652169, Final Batch Loss: 2.1609163013636135e-05\n",
      "Epoch 2787, Loss: 0.00038841440255055204, Final Batch Loss: 0.00014597047993447632\n",
      "Epoch 2788, Loss: 0.009244648928870447, Final Batch Loss: 0.008048254996538162\n",
      "Epoch 2789, Loss: 0.0029328067175811157, Final Batch Loss: 5.133112063049339e-05\n",
      "Epoch 2790, Loss: 0.004200213646981865, Final Batch Loss: 0.0002794976462610066\n",
      "Epoch 2791, Loss: 0.004974474286427721, Final Batch Loss: 0.0035724714398384094\n",
      "Epoch 2792, Loss: 0.0025094126467593014, Final Batch Loss: 0.0005343072698451579\n",
      "Epoch 2793, Loss: 0.0043834077077917755, Final Batch Loss: 0.0024567849468439817\n",
      "Epoch 2794, Loss: 0.00024872267022146843, Final Batch Loss: 8.076913945842534e-05\n",
      "Epoch 2795, Loss: 0.0006457579875132069, Final Batch Loss: 0.0002918860118370503\n",
      "Epoch 2796, Loss: 0.0005825756670674309, Final Batch Loss: 0.00042847334407269955\n",
      "Epoch 2797, Loss: 0.005813829746330157, Final Batch Loss: 0.005566790699958801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2798, Loss: 0.0005648942023981363, Final Batch Loss: 4.2627492803148925e-05\n",
      "Epoch 2799, Loss: 0.0005707258642360102, Final Batch Loss: 8.890374010661617e-05\n",
      "Epoch 2800, Loss: 0.006677083860267885, Final Batch Loss: 0.0020585255697369576\n",
      "Epoch 2801, Loss: 0.00013253114434519375, Final Batch Loss: 3.355077069500112e-06\n",
      "Epoch 2802, Loss: 0.0002776425317279063, Final Batch Loss: 7.746375194983557e-05\n",
      "Epoch 2803, Loss: 0.0010587913420749828, Final Batch Loss: 4.8744972446002066e-05\n",
      "Epoch 2804, Loss: 7.046841528790537e-05, Final Batch Loss: 2.4963163014035672e-05\n",
      "Epoch 2805, Loss: 0.0012011848994006868, Final Batch Loss: 2.132585723302327e-05\n",
      "Epoch 2806, Loss: 0.00016418437735410407, Final Batch Loss: 3.2778913009678945e-05\n",
      "Epoch 2807, Loss: 0.00039114705214160495, Final Batch Loss: 2.0922536350553855e-05\n",
      "Epoch 2808, Loss: 0.0004080217804585118, Final Batch Loss: 1.121676541515626e-05\n",
      "Epoch 2809, Loss: 0.0004007091056337231, Final Batch Loss: 1.324492859566817e-05\n",
      "Epoch 2810, Loss: 0.0007565595878986642, Final Batch Loss: 0.00013407670485321432\n",
      "Epoch 2811, Loss: 9.751555080583785e-05, Final Batch Loss: 3.469200964900665e-05\n",
      "Epoch 2812, Loss: 0.0006501080279122107, Final Batch Loss: 6.97885625413619e-05\n",
      "Epoch 2813, Loss: 0.037023942741370774, Final Batch Loss: 1.2247712675161893e-06\n",
      "Epoch 2814, Loss: 4.487007493025885e-05, Final Batch Loss: 1.5285469316950184e-06\n",
      "Epoch 2815, Loss: 0.00029976191399327945, Final Batch Loss: 3.396957981749438e-05\n",
      "Epoch 2816, Loss: 0.0009141297541646054, Final Batch Loss: 1.7312215277343057e-05\n",
      "Epoch 2817, Loss: 0.0007012450114416424, Final Batch Loss: 3.47908389812801e-05\n",
      "Epoch 2818, Loss: 0.0003025866135430988, Final Batch Loss: 4.429171167430468e-05\n",
      "Epoch 2819, Loss: 0.0011003454710589722, Final Batch Loss: 0.000921841652598232\n",
      "Epoch 2820, Loss: 0.0003907376667484641, Final Batch Loss: 3.693171311169863e-05\n",
      "Epoch 2821, Loss: 0.0011945657861360814, Final Batch Loss: 0.0005794796743430197\n",
      "Epoch 2822, Loss: 0.0005305100276018493, Final Batch Loss: 0.00026420276844874024\n",
      "Epoch 2823, Loss: 0.04714954630617285, Final Batch Loss: 0.046853043138980865\n",
      "Epoch 2824, Loss: 0.00028273489442653954, Final Batch Loss: 7.928812556201592e-05\n",
      "Epoch 2825, Loss: 0.00020678553846664727, Final Batch Loss: 5.191427771933377e-05\n",
      "Epoch 2826, Loss: 0.0003466579109954182, Final Batch Loss: 0.0001935769832925871\n",
      "Epoch 2827, Loss: 0.0005436772626126185, Final Batch Loss: 0.00017711530381347984\n",
      "Epoch 2828, Loss: 0.026213754899799824, Final Batch Loss: 0.009081559255719185\n",
      "Epoch 2829, Loss: 0.000484969379613176, Final Batch Loss: 0.00016242671699728817\n",
      "Epoch 2830, Loss: 0.001114733560825698, Final Batch Loss: 0.0001559005759190768\n",
      "Epoch 2831, Loss: 0.00036920790262229275, Final Batch Loss: 0.0001759956358000636\n",
      "Epoch 2832, Loss: 0.00025329746495117433, Final Batch Loss: 2.1959192963549867e-05\n",
      "Epoch 2833, Loss: 0.0003847471616609255, Final Batch Loss: 0.00017188285710290074\n",
      "Epoch 2834, Loss: 0.00030218687243177556, Final Batch Loss: 9.594653965905309e-05\n",
      "Epoch 2835, Loss: 0.000732773190975422, Final Batch Loss: 3.0526691261911765e-05\n",
      "Epoch 2836, Loss: 0.0003979964603786357, Final Batch Loss: 2.680584293557331e-05\n",
      "Epoch 2837, Loss: 0.0006051793279766571, Final Batch Loss: 0.00027070421492680907\n",
      "Epoch 2838, Loss: 0.00041359227543580346, Final Batch Loss: 6.717533688060939e-05\n",
      "Epoch 2839, Loss: 0.00035436247071629623, Final Batch Loss: 2.9873752282583155e-05\n",
      "Epoch 2840, Loss: 0.0002042934538621921, Final Batch Loss: 6.168232357595116e-05\n",
      "Epoch 2841, Loss: 9.4336267466133e-05, Final Batch Loss: 3.87908767152112e-05\n",
      "Epoch 2842, Loss: 0.029620890214573592, Final Batch Loss: 0.028769077733159065\n",
      "Epoch 2843, Loss: 0.001603088399861008, Final Batch Loss: 0.0005284583894535899\n",
      "Epoch 2844, Loss: 0.0006784788602089975, Final Batch Loss: 0.00046844291500747204\n",
      "Epoch 2845, Loss: 0.0012787538871634752, Final Batch Loss: 0.000538275926373899\n",
      "Epoch 2846, Loss: 0.0022698603352182545, Final Batch Loss: 0.00011909820750588551\n",
      "Epoch 2847, Loss: 0.0018802131053234916, Final Batch Loss: 3.900543015333824e-05\n",
      "Epoch 2848, Loss: 0.0007999138324521482, Final Batch Loss: 0.0001694623933872208\n",
      "Epoch 2849, Loss: 0.0006766521401004866, Final Batch Loss: 0.00037266366416588426\n",
      "Epoch 2850, Loss: 0.002090636728098616, Final Batch Loss: 0.00027560294256545603\n",
      "Epoch 2851, Loss: 0.001732671371428296, Final Batch Loss: 0.0010119704529643059\n",
      "Epoch 2852, Loss: 0.0007436132946168073, Final Batch Loss: 0.0004430746485013515\n",
      "Epoch 2853, Loss: 0.0007654380751773715, Final Batch Loss: 4.4518681534100324e-05\n",
      "Epoch 2854, Loss: 0.0008016220162971877, Final Batch Loss: 0.00017469852173235267\n",
      "Epoch 2855, Loss: 0.0006888056468596915, Final Batch Loss: 1.8552726032794453e-05\n",
      "Epoch 2856, Loss: 0.0008066528389463201, Final Batch Loss: 0.0002564355672802776\n",
      "Epoch 2857, Loss: 0.0010550984625297133, Final Batch Loss: 0.0008991748909465969\n",
      "Epoch 2858, Loss: 0.08682988950022263, Final Batch Loss: 0.08665474504232407\n",
      "Epoch 2859, Loss: 0.0004377960503916256, Final Batch Loss: 3.074215055676177e-05\n",
      "Epoch 2860, Loss: 0.0015029677597340196, Final Batch Loss: 9.530753595754504e-05\n",
      "Epoch 2861, Loss: 0.0002111523335770471, Final Batch Loss: 2.4269682398880832e-05\n",
      "Epoch 2862, Loss: 0.0009082910255528986, Final Batch Loss: 0.0005925592849962413\n",
      "Epoch 2863, Loss: 0.0005083583309897222, Final Batch Loss: 5.5416167015209794e-05\n",
      "Epoch 2864, Loss: 0.0008137383556459099, Final Batch Loss: 0.0002516591630410403\n",
      "Epoch 2865, Loss: 0.0011607529741013423, Final Batch Loss: 0.0002038410893874243\n",
      "Epoch 2866, Loss: 0.00028405445846146904, Final Batch Loss: 3.430614378885366e-05\n",
      "Epoch 2867, Loss: 0.0010995267075486481, Final Batch Loss: 0.0003550273540895432\n",
      "Epoch 2868, Loss: 0.015391763328807428, Final Batch Loss: 0.0004937219200655818\n",
      "Epoch 2869, Loss: 0.0004267806143616326, Final Batch Loss: 0.00019018507737200707\n",
      "Epoch 2870, Loss: 0.0011027178261429071, Final Batch Loss: 0.00019220028480049223\n",
      "Epoch 2871, Loss: 0.002314097830094397, Final Batch Loss: 0.0008234455017372966\n",
      "Epoch 2872, Loss: 0.0004873597572441213, Final Batch Loss: 0.00010840802133316174\n",
      "Epoch 2873, Loss: 0.0008102483916445635, Final Batch Loss: 9.552125266054645e-05\n",
      "Epoch 2874, Loss: 0.0003982338894275017, Final Batch Loss: 9.676141053205356e-05\n",
      "Epoch 2875, Loss: 0.0020292503031669185, Final Batch Loss: 0.000489625264890492\n",
      "Epoch 2876, Loss: 0.00242520694155246, Final Batch Loss: 0.0015081004239618778\n",
      "Epoch 2877, Loss: 0.00516912697639782, Final Batch Loss: 0.00038733810652047396\n",
      "Epoch 2878, Loss: 0.0007976307897479273, Final Batch Loss: 0.0003145596128888428\n",
      "Epoch 2879, Loss: 0.0008431864916929044, Final Batch Loss: 6.905371992615983e-05\n",
      "Epoch 2880, Loss: 0.0003475959674688056, Final Batch Loss: 9.198304906021804e-05\n",
      "Epoch 2881, Loss: 0.00021763892436865717, Final Batch Loss: 5.4890188039280474e-05\n",
      "Epoch 2882, Loss: 0.008304113216581754, Final Batch Loss: 0.00017348348046652973\n",
      "Epoch 2883, Loss: 0.004212463582007331, Final Batch Loss: 2.4601076802355237e-05\n",
      "Epoch 2884, Loss: 0.00033956364131881855, Final Batch Loss: 1.6988265997497365e-05\n",
      "Epoch 2885, Loss: 0.00047731528684380464, Final Batch Loss: 5.550681089516729e-05\n",
      "Epoch 2886, Loss: 0.0007671968196518719, Final Batch Loss: 0.0002317543694516644\n",
      "Epoch 2887, Loss: 0.0009742864858708344, Final Batch Loss: 0.00010541021038079634\n",
      "Epoch 2888, Loss: 0.00028319124976405874, Final Batch Loss: 0.00011519937834236771\n",
      "Epoch 2889, Loss: 0.005166655173525214, Final Batch Loss: 0.00012930369121022522\n",
      "Epoch 2890, Loss: 0.0007589743199787335, Final Batch Loss: 1.7758460671757348e-05\n",
      "Epoch 2891, Loss: 0.00021511252998607233, Final Batch Loss: 0.00011101567361038178\n",
      "Epoch 2892, Loss: 0.00037266562139848247, Final Batch Loss: 0.00017796477186493576\n",
      "Epoch 2893, Loss: 0.0009480980825173901, Final Batch Loss: 0.00013295092503540218\n",
      "Epoch 2894, Loss: 0.0008427152861258946, Final Batch Loss: 0.0007119487854652107\n",
      "Epoch 2895, Loss: 0.00014022715913597494, Final Batch Loss: 5.720054105040617e-05\n",
      "Epoch 2896, Loss: 0.0014638460706919432, Final Batch Loss: 7.84203439252451e-06\n",
      "Epoch 2897, Loss: 0.00042770124127855524, Final Batch Loss: 0.00011816745245596394\n",
      "Epoch 2898, Loss: 0.000713076184183592, Final Batch Loss: 0.0005419038352556527\n",
      "Epoch 2899, Loss: 0.00030055904426262714, Final Batch Loss: 0.00016809474618639797\n",
      "Epoch 2900, Loss: 0.0005078323479210667, Final Batch Loss: 5.077690275356872e-06\n",
      "Epoch 2901, Loss: 0.000574591540498659, Final Batch Loss: 0.0002506219025235623\n",
      "Epoch 2902, Loss: 0.023776747491183414, Final Batch Loss: 1.5689195151935564e-06\n",
      "Epoch 2903, Loss: 0.009527070303192886, Final Batch Loss: 0.009274648502469063\n",
      "Epoch 2904, Loss: 0.0008536038749298314, Final Batch Loss: 9.819124898058362e-06\n",
      "Epoch 2905, Loss: 0.00043109566786370124, Final Batch Loss: 4.272580099495826e-06\n",
      "Epoch 2906, Loss: 0.0016465325243189, Final Batch Loss: 0.0012090037344023585\n",
      "Epoch 2907, Loss: 0.0005521339262486435, Final Batch Loss: 9.051539382198825e-05\n",
      "Epoch 2908, Loss: 0.00041616625821916386, Final Batch Loss: 0.00012800375407095999\n",
      "Epoch 2909, Loss: 0.0004799261732841842, Final Batch Loss: 0.00016599833907093853\n",
      "Epoch 2910, Loss: 0.0007780025480315089, Final Batch Loss: 0.00013866291556041688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2911, Loss: 0.00042085081804543734, Final Batch Loss: 0.0001569463056512177\n",
      "Epoch 2912, Loss: 0.00269323649990838, Final Batch Loss: 9.521744505036622e-05\n",
      "Epoch 2913, Loss: 0.00014349616549225175, Final Batch Loss: 5.812113613501424e-06\n",
      "Epoch 2914, Loss: 0.0010349355525249848, Final Batch Loss: 0.00031455972930416465\n",
      "Epoch 2915, Loss: 0.0004698619741247967, Final Batch Loss: 2.1779487724415958e-05\n",
      "Epoch 2916, Loss: 0.003277582669397816, Final Batch Loss: 0.0012744658160954714\n",
      "Epoch 2917, Loss: 0.0004120316334592644, Final Batch Loss: 3.502145045786165e-05\n",
      "Epoch 2918, Loss: 0.001089375179617491, Final Batch Loss: 6.838007720944006e-06\n",
      "Epoch 2919, Loss: 0.0004967286186001729, Final Batch Loss: 4.120778976357542e-05\n",
      "Epoch 2920, Loss: 0.0015731506500742398, Final Batch Loss: 0.0001612674241187051\n",
      "Epoch 2921, Loss: 0.001172345533632324, Final Batch Loss: 1.1251047908444889e-05\n",
      "Epoch 2922, Loss: 0.02617001993348822, Final Batch Loss: 0.02564256452023983\n",
      "Epoch 2923, Loss: 0.0003350360129843466, Final Batch Loss: 0.00013145252887625247\n",
      "Epoch 2924, Loss: 0.002454830755596049, Final Batch Loss: 0.0005221898318268359\n",
      "Epoch 2925, Loss: 0.014863678661640733, Final Batch Loss: 0.01392464991658926\n",
      "Epoch 2926, Loss: 0.052023158728843555, Final Batch Loss: 0.00040425857878290117\n",
      "Epoch 2927, Loss: 0.0038336591387633234, Final Batch Loss: 0.0007526596891693771\n",
      "Epoch 2928, Loss: 0.000668538694299059, Final Batch Loss: 1.9392875401536003e-05\n",
      "Epoch 2929, Loss: 0.02097367128590122, Final Batch Loss: 0.02038680948317051\n",
      "Epoch 2930, Loss: 0.0015198837681964505, Final Batch Loss: 3.69536028301809e-05\n",
      "Epoch 2931, Loss: 0.0023546245456600445, Final Batch Loss: 1.142876408266602e-05\n",
      "Epoch 2932, Loss: 0.007525311757490272, Final Batch Loss: 0.00018528917280491441\n",
      "Epoch 2933, Loss: 0.00039462860968342284, Final Batch Loss: 0.0002975545939989388\n",
      "Epoch 2934, Loss: 0.0004464187804842368, Final Batch Loss: 0.0002107237232849002\n",
      "Epoch 2935, Loss: 0.0015639442863175645, Final Batch Loss: 0.0001339801528956741\n",
      "Epoch 2936, Loss: 0.00499598199439788, Final Batch Loss: 7.661073141207453e-06\n",
      "Epoch 2937, Loss: 0.007700225025473628, Final Batch Loss: 9.213624434778467e-05\n",
      "Epoch 2938, Loss: 0.0014725745568284765, Final Batch Loss: 0.00010207925515715033\n",
      "Epoch 2939, Loss: 0.007612163655721815, Final Batch Loss: 4.516246553976089e-05\n",
      "Epoch 2940, Loss: 0.0011792189325205982, Final Batch Loss: 0.0004273296217434108\n",
      "Epoch 2941, Loss: 0.008514416949765291, Final Batch Loss: 0.00820158515125513\n",
      "Epoch 2942, Loss: 0.0012376197410048917, Final Batch Loss: 0.0004156899231020361\n",
      "Epoch 2943, Loss: 0.0009999730391427875, Final Batch Loss: 0.0007189703756012022\n",
      "Epoch 2944, Loss: 0.0011613463793764822, Final Batch Loss: 6.0431113524828106e-05\n",
      "Epoch 2945, Loss: 0.004319640527683077, Final Batch Loss: 5.921006595599465e-05\n",
      "Epoch 2946, Loss: 0.0009731871941767167, Final Batch Loss: 0.0007260853890329599\n",
      "Epoch 2947, Loss: 0.0008466311701340601, Final Batch Loss: 0.00038414658047258854\n",
      "Epoch 2948, Loss: 0.0003431848490436096, Final Batch Loss: 5.9935209719697013e-05\n",
      "Epoch 2949, Loss: 0.00036290777643444017, Final Batch Loss: 6.864871102152392e-05\n",
      "Epoch 2950, Loss: 0.0012975490681128576, Final Batch Loss: 4.6136483433656394e-05\n",
      "Epoch 2951, Loss: 0.0002537175314500928, Final Batch Loss: 5.4341202485375106e-05\n",
      "Epoch 2952, Loss: 0.004967166103597265, Final Batch Loss: 0.00012497637362685055\n",
      "Epoch 2953, Loss: 0.0019713430519914255, Final Batch Loss: 0.00010961525549646467\n",
      "Epoch 2954, Loss: 0.001343453062872868, Final Batch Loss: 0.0011345518287271261\n",
      "Epoch 2955, Loss: 0.0008368898343178444, Final Batch Loss: 0.0005775612662546337\n",
      "Epoch 2956, Loss: 0.012069302784766478, Final Batch Loss: 1.1955990885326173e-05\n",
      "Epoch 2957, Loss: 0.0005215399778535357, Final Batch Loss: 0.0004082855302840471\n",
      "Epoch 2958, Loss: 0.06066677166381851, Final Batch Loss: 0.06041345000267029\n",
      "Epoch 2959, Loss: 0.0012315289786783978, Final Batch Loss: 0.00046659543295390904\n",
      "Epoch 2960, Loss: 0.0031721661434858106, Final Batch Loss: 0.0029851291328668594\n",
      "Epoch 2961, Loss: 0.0085439973991015, Final Batch Loss: 0.008352316915988922\n",
      "Epoch 2962, Loss: 0.0011060580000048503, Final Batch Loss: 0.000768067198805511\n",
      "Epoch 2963, Loss: 0.0005608391911664512, Final Batch Loss: 3.086989090661518e-05\n",
      "Epoch 2964, Loss: 0.0009298170916736126, Final Batch Loss: 0.0003435984253883362\n",
      "Epoch 2965, Loss: 0.000459951268567238, Final Batch Loss: 0.00010337970888940617\n",
      "Epoch 2966, Loss: 0.00042999389188480563, Final Batch Loss: 5.558465272770263e-05\n",
      "Epoch 2967, Loss: 0.0007513037853641436, Final Batch Loss: 6.20003993390128e-05\n",
      "Epoch 2968, Loss: 0.002728307095821947, Final Batch Loss: 0.0014691613614559174\n",
      "Epoch 2969, Loss: 0.005494780612934846, Final Batch Loss: 0.00012084016634617001\n",
      "Epoch 2970, Loss: 0.0003391685204405803, Final Batch Loss: 0.0001178183956653811\n",
      "Epoch 2971, Loss: 0.0002112373895215569, Final Batch Loss: 2.483449316059705e-05\n",
      "Epoch 2972, Loss: 0.00020183623564662412, Final Batch Loss: 3.6003020795760676e-05\n",
      "Epoch 2973, Loss: 0.0005996169566060416, Final Batch Loss: 7.877017196733505e-05\n",
      "Epoch 2974, Loss: 0.0002362227696721675, Final Batch Loss: 2.5695664589875378e-05\n",
      "Epoch 2975, Loss: 0.0005445554270409048, Final Batch Loss: 0.00012879830319434404\n",
      "Epoch 2976, Loss: 0.0031972792803571792, Final Batch Loss: 2.913945536420215e-05\n",
      "Epoch 2977, Loss: 0.0007440582921844907, Final Batch Loss: 4.123766120756045e-05\n",
      "Epoch 2978, Loss: 0.00021446311075123958, Final Batch Loss: 2.42961359617766e-05\n",
      "Epoch 2979, Loss: 0.0012842884680139832, Final Batch Loss: 0.0005535662639886141\n",
      "Epoch 2980, Loss: 0.00034458077425369993, Final Batch Loss: 1.0420924809295684e-05\n",
      "Epoch 2981, Loss: 0.0004014900478068739, Final Batch Loss: 4.419105243869126e-05\n",
      "Epoch 2982, Loss: 0.009871233589365147, Final Batch Loss: 0.00018063519382849336\n",
      "Epoch 2983, Loss: 0.0005830033987876959, Final Batch Loss: 0.00026874704053625464\n",
      "Epoch 2984, Loss: 0.0006611835633520968, Final Batch Loss: 0.0004958329955115914\n",
      "Epoch 2985, Loss: 0.000664261593556148, Final Batch Loss: 0.00044117405195720494\n",
      "Epoch 2986, Loss: 0.0005511283670784906, Final Batch Loss: 0.00023111561313271523\n",
      "Epoch 2987, Loss: 0.0028004332634736784, Final Batch Loss: 6.784071592846885e-05\n",
      "Epoch 2988, Loss: 0.0008000634697964415, Final Batch Loss: 0.00037692085606977344\n",
      "Epoch 2989, Loss: 0.0014298931491794065, Final Batch Loss: 0.00019627354049589485\n",
      "Epoch 2990, Loss: 0.03666545988016878, Final Batch Loss: 0.03118330053985119\n",
      "Epoch 2991, Loss: 0.0005947262252448127, Final Batch Loss: 0.0002116667601512745\n",
      "Epoch 2992, Loss: 0.0022688682365696877, Final Batch Loss: 0.0015506611671298742\n",
      "Epoch 2993, Loss: 0.04576810522121377, Final Batch Loss: 0.0005894375499337912\n",
      "Epoch 2994, Loss: 0.013085142665659077, Final Batch Loss: 0.00022906037338543683\n",
      "Epoch 2995, Loss: 0.003129201097181067, Final Batch Loss: 0.002409399952739477\n",
      "Epoch 2996, Loss: 0.004691249516326934, Final Batch Loss: 0.0008693758281879127\n",
      "Epoch 2997, Loss: 0.0025438949232921004, Final Batch Loss: 0.00035124539863318205\n",
      "Epoch 2998, Loss: 0.003326519305119291, Final Batch Loss: 0.00042382304673083127\n",
      "Epoch 2999, Loss: 0.0008114254742395133, Final Batch Loss: 0.00013168316218070686\n",
      "Epoch 3000, Loss: 0.005419422865088563, Final Batch Loss: 0.0014726831577718258\n",
      "Epoch 3001, Loss: 0.0010037489046226256, Final Batch Loss: 9.769306780071929e-05\n",
      "Epoch 3002, Loss: 0.0008977251382020768, Final Batch Loss: 2.0313262211857364e-05\n",
      "Epoch 3003, Loss: 0.0013448590543703176, Final Batch Loss: 0.00013689014303963631\n",
      "Epoch 3004, Loss: 0.0025316175597254187, Final Batch Loss: 0.001979260006919503\n",
      "Epoch 3005, Loss: 0.0004160815733484924, Final Batch Loss: 0.00023516823421232402\n",
      "Epoch 3006, Loss: 0.008824408170767128, Final Batch Loss: 0.0036736938636749983\n",
      "Epoch 3007, Loss: 0.003345192366396077, Final Batch Loss: 0.00022889241517987102\n",
      "Epoch 3008, Loss: 0.0009865036263363436, Final Batch Loss: 0.0002559518034104258\n",
      "Epoch 3009, Loss: 0.0006591839810425881, Final Batch Loss: 6.61756785120815e-05\n",
      "Epoch 3010, Loss: 0.0011563763255253434, Final Batch Loss: 0.0002693833957891911\n",
      "Epoch 3011, Loss: 0.0007529611793870572, Final Batch Loss: 0.0005385286058299243\n",
      "Epoch 3012, Loss: 0.0013344161634449847, Final Batch Loss: 0.00010048400872619823\n",
      "Epoch 3013, Loss: 0.00033856488880701363, Final Batch Loss: 8.779048221185803e-05\n",
      "Epoch 3014, Loss: 0.00043680297676473856, Final Batch Loss: 0.00013101397780701518\n",
      "Epoch 3015, Loss: 0.025278737397457007, Final Batch Loss: 0.0005071818013675511\n",
      "Epoch 3016, Loss: 0.0016079717825050466, Final Batch Loss: 0.00016100543143693358\n",
      "Epoch 3017, Loss: 0.0011787789699155837, Final Batch Loss: 0.00043948262464255095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3018, Loss: 0.0001821222213038709, Final Batch Loss: 8.088308095466346e-05\n",
      "Epoch 3019, Loss: 0.0005729902077291626, Final Batch Loss: 0.00040790013736113906\n",
      "Epoch 3020, Loss: 0.0015080889425007626, Final Batch Loss: 0.0004671862698160112\n",
      "Epoch 3021, Loss: 0.0004156605718890205, Final Batch Loss: 0.00015204281953629106\n",
      "Epoch 3022, Loss: 0.031043687497003702, Final Batch Loss: 3.0111590604064986e-05\n",
      "Epoch 3023, Loss: 0.0009103036572923884, Final Batch Loss: 4.2317093175370246e-05\n",
      "Epoch 3024, Loss: 0.0008120496713672765, Final Batch Loss: 2.7015346859116107e-05\n",
      "Epoch 3025, Loss: 0.0014179308636812493, Final Batch Loss: 6.269312871154398e-05\n",
      "Epoch 3026, Loss: 0.004710788605734706, Final Batch Loss: 0.00035405828384682536\n",
      "Epoch 3027, Loss: 0.0007330294683924876, Final Batch Loss: 0.00033757835626602173\n",
      "Epoch 3028, Loss: 0.0018237583863083273, Final Batch Loss: 0.0013327262131497264\n",
      "Epoch 3029, Loss: 0.0013975749170640483, Final Batch Loss: 0.0005221582832746208\n",
      "Epoch 3030, Loss: 0.0004901553911622614, Final Batch Loss: 0.00012434329255484045\n",
      "Epoch 3031, Loss: 0.0015569257084280252, Final Batch Loss: 0.0012255144538357854\n",
      "Epoch 3032, Loss: 0.0006952684998395853, Final Batch Loss: 0.0001865561935119331\n",
      "Epoch 3033, Loss: 0.00029441270999086555, Final Batch Loss: 9.495105769019574e-05\n",
      "Epoch 3034, Loss: 0.0012117299338569865, Final Batch Loss: 0.0009309673914685845\n",
      "Epoch 3035, Loss: 0.0008278806126327254, Final Batch Loss: 0.00011664679914247245\n",
      "Epoch 3036, Loss: 0.0011357145849615335, Final Batch Loss: 2.352909359615296e-05\n",
      "Epoch 3037, Loss: 0.0012833396904170513, Final Batch Loss: 0.00014670862583443522\n",
      "Epoch 3038, Loss: 0.0008573979230277473, Final Batch Loss: 1.6790168956504203e-05\n",
      "Epoch 3039, Loss: 0.00043993482904625125, Final Batch Loss: 0.00030446250457316637\n",
      "Epoch 3040, Loss: 0.0026894511829596013, Final Batch Loss: 0.0002787224657367915\n",
      "Epoch 3041, Loss: 0.0004270648641977459, Final Batch Loss: 6.965977081563324e-05\n",
      "Epoch 3042, Loss: 0.0005210969829931855, Final Batch Loss: 0.00024957506684586406\n",
      "Epoch 3043, Loss: 0.000357930001882778, Final Batch Loss: 1.3775198567600455e-05\n",
      "Epoch 3044, Loss: 0.00023425359177053906, Final Batch Loss: 6.20552891632542e-05\n",
      "Epoch 3045, Loss: 0.010592501323117176, Final Batch Loss: 1.4847675629425794e-05\n",
      "Epoch 3046, Loss: 0.008153173315804452, Final Batch Loss: 0.007106029894202948\n",
      "Epoch 3047, Loss: 0.001241312813363038, Final Batch Loss: 0.00012580344628077\n",
      "Epoch 3048, Loss: 0.004971439411747269, Final Batch Loss: 0.0008826360572129488\n",
      "Epoch 3049, Loss: 0.00029639649073942564, Final Batch Loss: 4.156554496148601e-05\n",
      "Epoch 3050, Loss: 0.0004075610086147208, Final Batch Loss: 3.804896550718695e-05\n",
      "Epoch 3051, Loss: 0.00041145330033032224, Final Batch Loss: 3.6107259802520275e-05\n",
      "Epoch 3052, Loss: 0.003704808885231614, Final Batch Loss: 0.0003031188389286399\n",
      "Epoch 3053, Loss: 0.0007416417502099648, Final Batch Loss: 0.0003319832030683756\n",
      "Epoch 3054, Loss: 0.011796188373409677, Final Batch Loss: 0.00010914245649473742\n",
      "Epoch 3055, Loss: 0.00014516409464704338, Final Batch Loss: 7.342764729401097e-05\n",
      "Epoch 3056, Loss: 0.00024213045981014147, Final Batch Loss: 2.8511845812317915e-05\n",
      "Epoch 3057, Loss: 0.0002557538418841432, Final Batch Loss: 0.00016898606554605067\n",
      "Epoch 3058, Loss: 0.00037763857835670933, Final Batch Loss: 0.0002570975630078465\n",
      "Epoch 3059, Loss: 0.0007765721056784969, Final Batch Loss: 3.756927253562026e-05\n",
      "Epoch 3060, Loss: 0.0010952573647955433, Final Batch Loss: 0.00017157163529191166\n",
      "Epoch 3061, Loss: 0.0003501456158119254, Final Batch Loss: 0.0001845746737672016\n",
      "Epoch 3062, Loss: 0.0006191663633217104, Final Batch Loss: 8.837472705636173e-06\n",
      "Epoch 3063, Loss: 0.001736424514092505, Final Batch Loss: 0.0012053374666720629\n",
      "Epoch 3064, Loss: 0.009845682747254614, Final Batch Loss: 0.0093415891751647\n",
      "Epoch 3065, Loss: 0.035184382475563325, Final Batch Loss: 0.03395048528909683\n",
      "Epoch 3066, Loss: 0.0009068888903129846, Final Batch Loss: 6.689281144645065e-05\n",
      "Epoch 3067, Loss: 0.0001428170253348071, Final Batch Loss: 3.148029645672068e-05\n",
      "Epoch 3068, Loss: 0.000631237755442271, Final Batch Loss: 0.0005435959901660681\n",
      "Epoch 3069, Loss: 0.0004102777693333337, Final Batch Loss: 1.6455038348794915e-05\n",
      "Epoch 3070, Loss: 0.0002533965634938795, Final Batch Loss: 2.614976438053418e-05\n",
      "Epoch 3071, Loss: 0.0003209632122889161, Final Batch Loss: 0.00016850755491759628\n",
      "Epoch 3072, Loss: 0.0006768083767383359, Final Batch Loss: 0.00029633636586368084\n",
      "Epoch 3073, Loss: 0.011174910398040083, Final Batch Loss: 0.011112423613667488\n",
      "Epoch 3074, Loss: 0.0005066738413006533, Final Batch Loss: 0.0002066055021714419\n",
      "Epoch 3075, Loss: 0.000391437850339571, Final Batch Loss: 0.00011901312245754525\n",
      "Epoch 3076, Loss: 0.00047359524796775077, Final Batch Loss: 0.0003525930515024811\n",
      "Epoch 3077, Loss: 0.0007008442626101896, Final Batch Loss: 0.00012327941658440977\n",
      "Epoch 3078, Loss: 0.00010386625763203483, Final Batch Loss: 1.323084688920062e-05\n",
      "Epoch 3079, Loss: 0.0006352155505737755, Final Batch Loss: 3.605047822929919e-05\n",
      "Epoch 3080, Loss: 0.00477257686725352, Final Batch Loss: 6.413157097995281e-05\n",
      "Epoch 3081, Loss: 0.00027928308008995373, Final Batch Loss: 1.9677112504723482e-05\n",
      "Epoch 3082, Loss: 0.0006490758460131474, Final Batch Loss: 0.0002766737306956202\n",
      "Epoch 3083, Loss: 0.007017989591986407, Final Batch Loss: 0.003414793638512492\n",
      "Epoch 3084, Loss: 0.00026507244547246955, Final Batch Loss: 0.0001925354590639472\n",
      "Epoch 3085, Loss: 0.000857688417454483, Final Batch Loss: 3.331904372316785e-05\n",
      "Epoch 3086, Loss: 0.0008780873340583639, Final Batch Loss: 1.924387652252335e-05\n",
      "Epoch 3087, Loss: 0.0003651768129202537, Final Batch Loss: 0.00025996781187132\n",
      "Epoch 3088, Loss: 0.00023375993623631075, Final Batch Loss: 2.5081018975470215e-05\n",
      "Epoch 3089, Loss: 0.0005356238316380768, Final Batch Loss: 2.323568878637161e-06\n",
      "Epoch 3090, Loss: 0.000729344832507195, Final Batch Loss: 2.1246709366096184e-05\n",
      "Epoch 3091, Loss: 0.0007910800450190436, Final Batch Loss: 0.00037448934745043516\n",
      "Epoch 3092, Loss: 0.00019369966321391985, Final Batch Loss: 3.8814934669062495e-05\n",
      "Epoch 3093, Loss: 0.00011434420594014227, Final Batch Loss: 3.70769266737625e-05\n",
      "Epoch 3094, Loss: 0.0007424718885431503, Final Batch Loss: 2.0784307253052248e-06\n",
      "Epoch 3095, Loss: 0.0006265818556130398, Final Batch Loss: 4.371046816231683e-05\n",
      "Epoch 3096, Loss: 0.000301455565931974, Final Batch Loss: 0.00015997265290934592\n",
      "Epoch 3097, Loss: 0.0006328399394988082, Final Batch Loss: 0.0001113079342758283\n",
      "Epoch 3098, Loss: 0.00031317536922870204, Final Batch Loss: 7.623682904522866e-05\n",
      "Epoch 3099, Loss: 0.0012103716790079488, Final Batch Loss: 8.125504791678395e-06\n",
      "Epoch 3100, Loss: 0.000360842551344831, Final Batch Loss: 9.750028402777389e-05\n",
      "Epoch 3101, Loss: 0.003753457946004346, Final Batch Loss: 0.0028139285277575254\n",
      "Epoch 3102, Loss: 0.0006347910689328273, Final Batch Loss: 1.5854802768444642e-05\n",
      "Epoch 3103, Loss: 0.0009076671994989738, Final Batch Loss: 0.000406152248615399\n",
      "Epoch 3104, Loss: 0.0005847030461154645, Final Batch Loss: 2.0580422642524354e-05\n",
      "Epoch 3105, Loss: 0.0038047722227929626, Final Batch Loss: 0.0003247920249123126\n",
      "Epoch 3106, Loss: 0.0008810693125269609, Final Batch Loss: 0.0004888902767561376\n",
      "Epoch 3107, Loss: 0.0007431293342960998, Final Batch Loss: 0.0003554528811946511\n",
      "Epoch 3108, Loss: 0.00034064492865581997, Final Batch Loss: 1.9592331227613613e-05\n",
      "Epoch 3109, Loss: 0.00012051966669446301, Final Batch Loss: 3.7300824828889745e-07\n",
      "Epoch 3110, Loss: 0.0006565014773514122, Final Batch Loss: 6.531670078402385e-05\n",
      "Epoch 3111, Loss: 0.00048467643318872433, Final Batch Loss: 2.5093248041230254e-05\n",
      "Epoch 3112, Loss: 0.0012825277062802343, Final Batch Loss: 3.7913410778855905e-05\n",
      "Epoch 3113, Loss: 0.0004459172005226719, Final Batch Loss: 9.781974767975044e-06\n",
      "Epoch 3114, Loss: 0.00031900277917884523, Final Batch Loss: 1.2177509233879391e-05\n",
      "Epoch 3115, Loss: 0.00014629953511757776, Final Batch Loss: 4.2745301470858976e-05\n",
      "Epoch 3116, Loss: 0.0017211437789228512, Final Batch Loss: 0.0014010153245180845\n",
      "Epoch 3117, Loss: 0.0036735525936819613, Final Batch Loss: 0.0001724398462101817\n",
      "Epoch 3118, Loss: 0.0007439540386258159, Final Batch Loss: 1.668407639954239e-05\n",
      "Epoch 3119, Loss: 0.0003527222670527408, Final Batch Loss: 0.00027131609385833144\n",
      "Epoch 3120, Loss: 0.0004764167024404742, Final Batch Loss: 0.00023472045722883195\n",
      "Epoch 3121, Loss: 0.00042889722681138664, Final Batch Loss: 0.0003260169760324061\n",
      "Epoch 3122, Loss: 0.0002783500422083307, Final Batch Loss: 2.1849473341717385e-05\n",
      "Epoch 3123, Loss: 0.0003918277616321575, Final Batch Loss: 7.224223372759297e-05\n",
      "Epoch 3124, Loss: 0.00012634478707695962, Final Batch Loss: 6.00482644586009e-06\n",
      "Epoch 3125, Loss: 0.00025172125970129855, Final Batch Loss: 5.811536175315268e-05\n",
      "Epoch 3126, Loss: 0.0003837318108708132, Final Batch Loss: 9.52204572968185e-05\n",
      "Epoch 3127, Loss: 0.02326824893225421, Final Batch Loss: 1.4793530681345146e-05\n",
      "Epoch 3128, Loss: 0.0007167645744630136, Final Batch Loss: 0.00034968589898198843\n",
      "Epoch 3129, Loss: 0.00036513858140097, Final Batch Loss: 0.00010403667693026364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3130, Loss: 0.00013433700951281935, Final Batch Loss: 1.8754839402390644e-05\n",
      "Epoch 3131, Loss: 0.000244442103394249, Final Batch Loss: 1.4615706277254503e-05\n",
      "Epoch 3132, Loss: 0.0007573715920443647, Final Batch Loss: 0.0007016841555014253\n",
      "Epoch 3133, Loss: 0.004878799180005444, Final Batch Loss: 3.208780981367454e-05\n",
      "Epoch 3134, Loss: 0.0061655733225052245, Final Batch Loss: 0.003964870236814022\n",
      "Epoch 3135, Loss: 0.00044473256548371864, Final Batch Loss: 9.178448635793757e-06\n",
      "Epoch 3136, Loss: 0.0006327788196358597, Final Batch Loss: 2.4964350814116187e-05\n",
      "Epoch 3137, Loss: 0.0006404039013432339, Final Batch Loss: 5.390033038565889e-05\n",
      "Epoch 3138, Loss: 0.001785748841939494, Final Batch Loss: 0.00013888262037653476\n",
      "Epoch 3139, Loss: 9.375090849061962e-05, Final Batch Loss: 3.1250663596438244e-05\n",
      "Epoch 3140, Loss: 0.00023415979376295581, Final Batch Loss: 3.0126149795250967e-05\n",
      "Epoch 3141, Loss: 0.00011381556942069437, Final Batch Loss: 2.3162903744378127e-05\n",
      "Epoch 3142, Loss: 0.0026089017546837567, Final Batch Loss: 1.2146315384597983e-05\n",
      "Epoch 3143, Loss: 0.0009866099535429385, Final Batch Loss: 1.8874521629186347e-05\n",
      "Epoch 3144, Loss: 0.00022586163140658755, Final Batch Loss: 0.00016093539306893945\n",
      "Epoch 3145, Loss: 0.00013245685840956867, Final Batch Loss: 3.78204022126738e-05\n",
      "Epoch 3146, Loss: 7.116708457033383e-05, Final Batch Loss: 1.1109007573395502e-05\n",
      "Epoch 3147, Loss: 0.00046375263491427177, Final Batch Loss: 4.424792223289842e-06\n",
      "Epoch 3148, Loss: 0.00038734297231712844, Final Batch Loss: 8.72390519361943e-05\n",
      "Epoch 3149, Loss: 0.004163858277024701, Final Batch Loss: 1.3468881661538035e-05\n",
      "Epoch 3150, Loss: 0.0002776857036224101, Final Batch Loss: 6.478258728748187e-05\n",
      "Epoch 3151, Loss: 0.00014586925135517959, Final Batch Loss: 6.379783371812664e-06\n",
      "Epoch 3152, Loss: 0.000335326258209534, Final Batch Loss: 3.870049840770662e-05\n",
      "Epoch 3153, Loss: 0.0006552381173605681, Final Batch Loss: 1.3500547538569663e-05\n",
      "Epoch 3154, Loss: 0.0005069805120001547, Final Batch Loss: 3.548502718331292e-05\n",
      "Epoch 3155, Loss: 0.00017819604181568138, Final Batch Loss: 9.413582301931456e-05\n",
      "Epoch 3156, Loss: 0.00021433213169075316, Final Batch Loss: 0.00016955337196122855\n",
      "Epoch 3157, Loss: 0.00017512014255771646, Final Batch Loss: 1.3346395462576766e-05\n",
      "Epoch 3158, Loss: 0.00073828761378536, Final Batch Loss: 0.0004562977992463857\n",
      "Epoch 3159, Loss: 0.0003791852705035126, Final Batch Loss: 2.6719853849499486e-05\n",
      "Epoch 3160, Loss: 0.00034130985841329675, Final Batch Loss: 1.755467201292049e-05\n",
      "Epoch 3161, Loss: 0.00015736113164166454, Final Batch Loss: 1.548088221170474e-05\n",
      "Epoch 3162, Loss: 0.00020139611115155276, Final Batch Loss: 4.6065208152867854e-05\n",
      "Epoch 3163, Loss: 8.56934102557716e-05, Final Batch Loss: 8.36420713312691e-06\n",
      "Epoch 3164, Loss: 0.00011753257331292843, Final Batch Loss: 6.910437514306977e-05\n",
      "Epoch 3165, Loss: 0.00030892688573658234, Final Batch Loss: 0.00011777001054724678\n",
      "Epoch 3166, Loss: 0.00015843942856008653, Final Batch Loss: 5.278590106172487e-05\n",
      "Epoch 3167, Loss: 0.00014743965721208951, Final Batch Loss: 7.133794042601949e-06\n",
      "Epoch 3168, Loss: 0.0004531415361270774, Final Batch Loss: 0.00023736203729640692\n",
      "Epoch 3169, Loss: 0.00011289313260931522, Final Batch Loss: 2.928723733930383e-05\n",
      "Epoch 3170, Loss: 4.873718808084959e-05, Final Batch Loss: 1.5089457519934513e-05\n",
      "Epoch 3171, Loss: 8.01237256382592e-05, Final Batch Loss: 1.0309508070349693e-05\n",
      "Epoch 3172, Loss: 0.0001699599415587727, Final Batch Loss: 2.4202368877013214e-05\n",
      "Epoch 3173, Loss: 0.00011178219938301481, Final Batch Loss: 5.15307328896597e-05\n",
      "Epoch 3174, Loss: 5.2809305998380296e-05, Final Batch Loss: 9.733670594869182e-06\n",
      "Epoch 3175, Loss: 0.00012618976143130567, Final Batch Loss: 3.7029836676083505e-05\n",
      "Epoch 3176, Loss: 0.009380298361065798, Final Batch Loss: 9.791387856239453e-05\n",
      "Epoch 3177, Loss: 0.0002598717783257598, Final Batch Loss: 3.0015604352229275e-05\n",
      "Epoch 3178, Loss: 0.0003033260982192587, Final Batch Loss: 0.00020086037693545222\n",
      "Epoch 3179, Loss: 0.002941481045127148, Final Batch Loss: 3.413616286707111e-05\n",
      "Epoch 3180, Loss: 0.0005828110615766491, Final Batch Loss: 0.0003946627548430115\n",
      "Epoch 3181, Loss: 0.00024166800267266808, Final Batch Loss: 1.4973210454627406e-05\n",
      "Epoch 3182, Loss: 0.00019590808915381785, Final Batch Loss: 6.327642768155783e-05\n",
      "Epoch 3183, Loss: 0.00023852024605730549, Final Batch Loss: 1.2037080523441546e-05\n",
      "Epoch 3184, Loss: 0.0004501651601458434, Final Batch Loss: 0.0003686625277623534\n",
      "Epoch 3185, Loss: 0.0017882130414363928, Final Batch Loss: 5.9345205954741687e-05\n",
      "Epoch 3186, Loss: 0.0005061659758212045, Final Batch Loss: 0.00020375361782498658\n",
      "Epoch 3187, Loss: 0.0007719668137724511, Final Batch Loss: 0.00016277145186904818\n",
      "Epoch 3188, Loss: 0.00013786098770651734, Final Batch Loss: 9.876005060505122e-05\n",
      "Epoch 3189, Loss: 0.00022058364083932247, Final Batch Loss: 2.4155868231900968e-05\n",
      "Epoch 3190, Loss: 0.0013180859423300717, Final Batch Loss: 0.0012896469561383128\n",
      "Epoch 3191, Loss: 0.01827282605495384, Final Batch Loss: 0.00014973117504268885\n",
      "Epoch 3192, Loss: 0.0011916913574623322, Final Batch Loss: 7.652345175301889e-07\n",
      "Epoch 3193, Loss: 0.0001737810260920014, Final Batch Loss: 1.5102658608157071e-06\n",
      "Epoch 3194, Loss: 0.00027127403882332146, Final Batch Loss: 5.780658102594316e-05\n",
      "Epoch 3195, Loss: 0.005460603955725674, Final Batch Loss: 0.00012082912871846929\n",
      "Epoch 3196, Loss: 0.00437224569668615, Final Batch Loss: 1.420891840098193e-05\n",
      "Epoch 3197, Loss: 0.0006009139497109572, Final Batch Loss: 0.000576708756852895\n",
      "Epoch 3198, Loss: 0.00019996006312794634, Final Batch Loss: 5.839573987032054e-06\n",
      "Epoch 3199, Loss: 0.00010450522677274421, Final Batch Loss: 3.603097502491437e-05\n",
      "Epoch 3200, Loss: 0.00020517005805231747, Final Batch Loss: 2.425200909783598e-05\n",
      "Epoch 3201, Loss: 0.0001476322458984214, Final Batch Loss: 9.601971214578953e-06\n",
      "Epoch 3202, Loss: 0.0010965827968902886, Final Batch Loss: 0.00020569107437040657\n",
      "Epoch 3203, Loss: 0.00018764164724416332, Final Batch Loss: 8.759458978602197e-06\n",
      "Epoch 3204, Loss: 0.00035230514185968786, Final Batch Loss: 9.864219464361668e-06\n",
      "Epoch 3205, Loss: 0.00032306237699231133, Final Batch Loss: 4.085503314854577e-05\n",
      "Epoch 3206, Loss: 0.004061947568970936, Final Batch Loss: 6.093257525208173e-06\n",
      "Epoch 3207, Loss: 5.40221199116786e-05, Final Batch Loss: 5.98253700445639e-06\n",
      "Epoch 3208, Loss: 9.44606958910299e-05, Final Batch Loss: 1.4615876352763735e-05\n",
      "Epoch 3209, Loss: 0.0014698059785587247, Final Batch Loss: 4.687255568569526e-06\n",
      "Epoch 3210, Loss: 0.0060921008712284674, Final Batch Loss: 0.0005781766376458108\n",
      "Epoch 3211, Loss: 0.01245953625311813, Final Batch Loss: 0.012406827881932259\n",
      "Epoch 3212, Loss: 0.04545637560659088, Final Batch Loss: 0.0004697602998930961\n",
      "Epoch 3213, Loss: 0.00038400556513806805, Final Batch Loss: 0.00010379004379501566\n",
      "Epoch 3214, Loss: 6.296047195064602e-05, Final Batch Loss: 2.9390950658125803e-05\n",
      "Epoch 3215, Loss: 9.374818728247192e-05, Final Batch Loss: 6.211284198798239e-05\n",
      "Epoch 3216, Loss: 0.0002567893438936153, Final Batch Loss: 0.0001754037948558107\n",
      "Epoch 3217, Loss: 6.356749463520828e-05, Final Batch Loss: 6.461504653998418e-06\n",
      "Epoch 3218, Loss: 0.003065195800445508, Final Batch Loss: 4.117846765439026e-05\n",
      "Epoch 3219, Loss: 6.95508933858946e-05, Final Batch Loss: 1.1663453733490314e-05\n",
      "Epoch 3220, Loss: 0.0004014753734509213, Final Batch Loss: 7.440916078849114e-07\n",
      "Epoch 3221, Loss: 0.007273847741089412, Final Batch Loss: 0.0069534131325781345\n",
      "Epoch 3222, Loss: 0.00019720788259292021, Final Batch Loss: 4.6432945964625105e-05\n",
      "Epoch 3223, Loss: 0.0004911072901450098, Final Batch Loss: 0.00019623461412265897\n",
      "Epoch 3224, Loss: 0.0011805063295469154, Final Batch Loss: 0.000988406129181385\n",
      "Epoch 3225, Loss: 0.00010721272337832488, Final Batch Loss: 1.6722686268622056e-05\n",
      "Epoch 3226, Loss: 0.00031994747041608207, Final Batch Loss: 9.76045339484699e-06\n",
      "Epoch 3227, Loss: 0.014496265293132637, Final Batch Loss: 1.615023506928992e-06\n",
      "Epoch 3228, Loss: 0.00022137382802611683, Final Batch Loss: 1.1056983566959389e-05\n",
      "Epoch 3229, Loss: 0.00018639723930391483, Final Batch Loss: 8.223289478337392e-05\n",
      "Epoch 3230, Loss: 0.0009069822917808779, Final Batch Loss: 0.00037828891072422266\n",
      "Epoch 3231, Loss: 0.03242491156015603, Final Batch Loss: 0.032331936061382294\n",
      "Epoch 3232, Loss: 0.0003696463372762082, Final Batch Loss: 8.953576616477221e-05\n",
      "Epoch 3233, Loss: 0.0007417331944452599, Final Batch Loss: 0.00041565936408005655\n",
      "Epoch 3234, Loss: 0.011232674965867773, Final Batch Loss: 0.006069580093026161\n",
      "Epoch 3235, Loss: 0.0014519830265271594, Final Batch Loss: 0.0005506512825377285\n",
      "Epoch 3236, Loss: 0.0010563577670836821, Final Batch Loss: 0.00038704610778950155\n",
      "Epoch 3237, Loss: 0.0008991901040644734, Final Batch Loss: 7.289351742656436e-06\n",
      "Epoch 3238, Loss: 0.0001494668576924596, Final Batch Loss: 4.755020563607104e-05\n",
      "Epoch 3239, Loss: 7.336228964049951e-05, Final Batch Loss: 7.5710668170358986e-06\n",
      "Epoch 3240, Loss: 0.00022833665934740566, Final Batch Loss: 0.00014227291103452444\n",
      "Epoch 3241, Loss: 0.00030349057578860084, Final Batch Loss: 0.0002052511990768835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3242, Loss: 0.0016436181122116977, Final Batch Loss: 0.0014641021843999624\n",
      "Epoch 3243, Loss: 0.00026020556697403663, Final Batch Loss: 5.42076168130734e-06\n",
      "Epoch 3244, Loss: 0.0006869039934827015, Final Batch Loss: 0.000617561861872673\n",
      "Epoch 3245, Loss: 0.0006182853212521877, Final Batch Loss: 8.259644528152421e-05\n",
      "Epoch 3246, Loss: 6.402834151231218e-05, Final Batch Loss: 2.4893261070246808e-05\n",
      "Epoch 3247, Loss: 0.03892197733512148, Final Batch Loss: 0.03873166814446449\n",
      "Epoch 3248, Loss: 0.00019391595105844317, Final Batch Loss: 1.3722509720537346e-05\n",
      "Epoch 3249, Loss: 0.00030695792884216644, Final Batch Loss: 8.206659549614415e-05\n",
      "Epoch 3250, Loss: 0.00030628749664174393, Final Batch Loss: 7.140167872421443e-05\n",
      "Epoch 3251, Loss: 0.00019887184680555947, Final Batch Loss: 4.4278243876760826e-05\n",
      "Epoch 3252, Loss: 0.00038601336109422846, Final Batch Loss: 1.120967044698773e-05\n",
      "Epoch 3253, Loss: 0.0005132774349476676, Final Batch Loss: 3.48630674125161e-05\n",
      "Epoch 3254, Loss: 0.0024197755237764795, Final Batch Loss: 1.5240498214552645e-05\n",
      "Epoch 3255, Loss: 0.000713324174284935, Final Batch Loss: 0.00040346739115193486\n",
      "Epoch 3256, Loss: 0.00011365085265424568, Final Batch Loss: 5.5492306273663417e-05\n",
      "Epoch 3257, Loss: 0.001229653452128332, Final Batch Loss: 3.6069220641365973e-06\n",
      "Epoch 3258, Loss: 0.00024883661717467476, Final Batch Loss: 2.753080661932472e-05\n",
      "Epoch 3259, Loss: 0.0013476718595484272, Final Batch Loss: 0.00021431838104035705\n",
      "Epoch 3260, Loss: 0.0001829695738706505, Final Batch Loss: 1.8954404367832467e-05\n",
      "Epoch 3261, Loss: 0.002997818504809402, Final Batch Loss: 3.760574327316135e-05\n",
      "Epoch 3262, Loss: 0.0007426394877256826, Final Batch Loss: 0.00043232415919192135\n",
      "Epoch 3263, Loss: 0.00016561323172936682, Final Batch Loss: 2.427987965347711e-05\n",
      "Epoch 3264, Loss: 0.00045958269765833393, Final Batch Loss: 4.5788092393195257e-05\n",
      "Epoch 3265, Loss: 0.0002583663417681237, Final Batch Loss: 5.663893716700841e-06\n",
      "Epoch 3266, Loss: 0.00041017407056642696, Final Batch Loss: 5.6584456615382805e-05\n",
      "Epoch 3267, Loss: 0.00010473738802829757, Final Batch Loss: 1.724916000966914e-05\n",
      "Epoch 3268, Loss: 0.0003109683020738885, Final Batch Loss: 0.00013330044748727232\n",
      "Epoch 3269, Loss: 0.00011727110359061044, Final Batch Loss: 1.7679873053566553e-05\n",
      "Epoch 3270, Loss: 7.789165238136775e-05, Final Batch Loss: 2.6003558559750672e-06\n",
      "Epoch 3271, Loss: 0.00027290206708130427, Final Batch Loss: 0.00011311218258924782\n",
      "Epoch 3272, Loss: 0.00012594119652931113, Final Batch Loss: 5.4262884077616036e-05\n",
      "Epoch 3273, Loss: 0.00011415830158512108, Final Batch Loss: 3.906275742338039e-05\n",
      "Epoch 3274, Loss: 0.00032309133075614227, Final Batch Loss: 0.0002684241335373372\n",
      "Epoch 3275, Loss: 0.0006409233174053952, Final Batch Loss: 0.00018605646619107574\n",
      "Epoch 3276, Loss: 0.00024286619554914068, Final Batch Loss: 2.2093174266046844e-05\n",
      "Epoch 3277, Loss: 0.0039322898319369415, Final Batch Loss: 7.386871584458277e-05\n",
      "Epoch 3278, Loss: 0.00018603437092679087, Final Batch Loss: 7.927958358777687e-05\n",
      "Epoch 3279, Loss: 0.00030398592934943736, Final Batch Loss: 0.00010271943028783426\n",
      "Epoch 3280, Loss: 0.00016912998285079084, Final Batch Loss: 2.6282930321031017e-06\n",
      "Epoch 3281, Loss: 0.00029148501744202804, Final Batch Loss: 0.00015730978338979185\n",
      "Epoch 3282, Loss: 0.00016006581790861674, Final Batch Loss: 3.350438055349514e-05\n",
      "Epoch 3283, Loss: 0.0034445968231011648, Final Batch Loss: 4.2584888433339074e-05\n",
      "Epoch 3284, Loss: 9.898153075482696e-05, Final Batch Loss: 4.4988606532569975e-05\n",
      "Epoch 3285, Loss: 0.001065007509168936, Final Batch Loss: 4.564693517750129e-05\n",
      "Epoch 3286, Loss: 0.0005576189978455659, Final Batch Loss: 0.00010746359475888312\n",
      "Epoch 3287, Loss: 0.0008718017888895702, Final Batch Loss: 8.094598888419569e-05\n",
      "Epoch 3288, Loss: 0.00024405408066741074, Final Batch Loss: 9.837460675043985e-05\n",
      "Epoch 3289, Loss: 0.0003209871028957423, Final Batch Loss: 4.316915146773681e-05\n",
      "Epoch 3290, Loss: 0.007865913055866258, Final Batch Loss: 8.012483158381656e-05\n",
      "Epoch 3291, Loss: 0.0002823068862198852, Final Batch Loss: 5.867015715921298e-05\n",
      "Epoch 3292, Loss: 0.0007456621865458146, Final Batch Loss: 0.0005533471121452749\n",
      "Epoch 3293, Loss: 0.0002722071726566355, Final Batch Loss: 0.0002520199050195515\n",
      "Epoch 3294, Loss: 0.017947845066373702, Final Batch Loss: 0.017628829926252365\n",
      "Epoch 3295, Loss: 0.0008689887235959759, Final Batch Loss: 1.6825133570819162e-05\n",
      "Epoch 3296, Loss: 0.00020481540923356079, Final Batch Loss: 0.00011942997662117705\n",
      "Epoch 3297, Loss: 0.00030739208705199417, Final Batch Loss: 0.00019071975839324296\n",
      "Epoch 3298, Loss: 0.02213213179493323, Final Batch Loss: 0.016214627772569656\n",
      "Epoch 3299, Loss: 0.0004741026104966295, Final Batch Loss: 0.00037392901140265167\n",
      "Epoch 3300, Loss: 0.002231073420261964, Final Batch Loss: 0.000297707156278193\n",
      "Epoch 3301, Loss: 0.005746772701968439, Final Batch Loss: 0.002788313664495945\n",
      "Epoch 3302, Loss: 0.0006459031283156946, Final Batch Loss: 0.00015827399329282343\n",
      "Epoch 3303, Loss: 0.00023202802367450204, Final Batch Loss: 2.550147291913163e-05\n",
      "Epoch 3304, Loss: 0.003172128948790487, Final Batch Loss: 0.002161457436159253\n",
      "Epoch 3305, Loss: 0.0016891361738089472, Final Batch Loss: 0.000473084015538916\n",
      "Epoch 3306, Loss: 0.0004907613110844977, Final Batch Loss: 1.6906520613702014e-05\n",
      "Epoch 3307, Loss: 0.0002426693904453714, Final Batch Loss: 0.00018602886120788753\n",
      "Epoch 3308, Loss: 0.00029395995079539716, Final Batch Loss: 1.6898091416805983e-05\n",
      "Epoch 3309, Loss: 0.039915114703035215, Final Batch Loss: 0.039707913994789124\n",
      "Epoch 3310, Loss: 0.00026791040181706194, Final Batch Loss: 1.622525269340258e-05\n",
      "Epoch 3311, Loss: 0.013278364553116262, Final Batch Loss: 0.009029628708958626\n",
      "Epoch 3312, Loss: 0.006860570609205752, Final Batch Loss: 2.9028020435362123e-05\n",
      "Epoch 3313, Loss: 0.01858476119741681, Final Batch Loss: 4.809307210962288e-05\n",
      "Epoch 3314, Loss: 0.0030125092453090474, Final Batch Loss: 0.002383382059633732\n",
      "Epoch 3315, Loss: 0.0006984516148804687, Final Batch Loss: 0.000525698356796056\n",
      "Epoch 3316, Loss: 0.008443132028332911, Final Batch Loss: 0.00016119850624818355\n",
      "Epoch 3317, Loss: 0.0004456250462681055, Final Batch Loss: 0.00022050215920899063\n",
      "Epoch 3318, Loss: 0.0002782199480861891, Final Batch Loss: 5.279227116261609e-05\n",
      "Epoch 3319, Loss: 0.0006008341224514879, Final Batch Loss: 0.0001342026807833463\n",
      "Epoch 3320, Loss: 0.0004856992709392216, Final Batch Loss: 2.048090027528815e-05\n",
      "Epoch 3321, Loss: 0.0004161355841461045, Final Batch Loss: 4.587179773807293e-06\n",
      "Epoch 3322, Loss: 0.009603945713024586, Final Batch Loss: 0.0077189491130411625\n",
      "Epoch 3323, Loss: 0.0005357135232770815, Final Batch Loss: 6.862223381176591e-05\n",
      "Epoch 3324, Loss: 0.00037614948814734817, Final Batch Loss: 6.321712135104463e-05\n",
      "Epoch 3325, Loss: 0.0005641719762934372, Final Batch Loss: 0.00020669485093094409\n",
      "Epoch 3326, Loss: 0.0009262236271752045, Final Batch Loss: 3.184782690368593e-05\n",
      "Epoch 3327, Loss: 0.0016327658431691816, Final Batch Loss: 1.1509311661939137e-05\n",
      "Epoch 3328, Loss: 0.0008533321670256555, Final Batch Loss: 0.00010421364277135581\n",
      "Epoch 3329, Loss: 0.001219782541738823, Final Batch Loss: 0.0007858712924644351\n",
      "Epoch 3330, Loss: 0.0015950075758155435, Final Batch Loss: 0.00054998102132231\n",
      "Epoch 3331, Loss: 0.0006458880889113061, Final Batch Loss: 7.479017222067341e-05\n",
      "Epoch 3332, Loss: 0.0009642617078498006, Final Batch Loss: 0.0005857094074599445\n",
      "Epoch 3333, Loss: 0.003592778681195341, Final Batch Loss: 0.00011683731281664222\n",
      "Epoch 3334, Loss: 0.000560073412998463, Final Batch Loss: 0.0003117975720670074\n",
      "Epoch 3335, Loss: 0.0005224104588705814, Final Batch Loss: 0.00035733115510083735\n",
      "Epoch 3336, Loss: 0.00023426148254657164, Final Batch Loss: 5.2867380873067304e-05\n",
      "Epoch 3337, Loss: 0.00020014745314256288, Final Batch Loss: 3.844138336717151e-05\n",
      "Epoch 3338, Loss: 0.00011333436668792274, Final Batch Loss: 5.3009131079306826e-05\n",
      "Epoch 3339, Loss: 0.00013626191594084958, Final Batch Loss: 6.621333341172431e-06\n",
      "Epoch 3340, Loss: 0.0005208837537793443, Final Batch Loss: 0.0002942601277027279\n",
      "Epoch 3341, Loss: 0.0005193965916987509, Final Batch Loss: 0.00010941598884528503\n",
      "Epoch 3342, Loss: 0.00039874567301012576, Final Batch Loss: 0.00023471425811294466\n",
      "Epoch 3343, Loss: 0.0037544325914495857, Final Batch Loss: 2.9360542612266727e-05\n",
      "Epoch 3344, Loss: 0.0003506025459500961, Final Batch Loss: 0.00010667476453818381\n",
      "Epoch 3345, Loss: 0.0006851820944575593, Final Batch Loss: 0.00035354922874830663\n",
      "Epoch 3346, Loss: 0.00033363331021973863, Final Batch Loss: 0.00014417640340980142\n",
      "Epoch 3347, Loss: 0.0002893124437832739, Final Batch Loss: 2.990172288264148e-05\n",
      "Epoch 3348, Loss: 0.0002801208866003435, Final Batch Loss: 0.0001541604578960687\n",
      "Epoch 3349, Loss: 0.0005050784056948032, Final Batch Loss: 1.6362300812033936e-05\n",
      "Epoch 3350, Loss: 0.0002917063648055773, Final Batch Loss: 0.00016542735102120787\n",
      "Epoch 3351, Loss: 0.0008768725156187429, Final Batch Loss: 3.069540071010124e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3352, Loss: 0.002835055682226084, Final Batch Loss: 0.0027191713452339172\n",
      "Epoch 3353, Loss: 0.0019936937187594594, Final Batch Loss: 2.0549383407342248e-05\n",
      "Epoch 3354, Loss: 0.00025455418835917953, Final Batch Loss: 9.322919140686281e-06\n",
      "Epoch 3355, Loss: 0.0004820127069251612, Final Batch Loss: 0.0001385494542773813\n",
      "Epoch 3356, Loss: 0.031294117667130195, Final Batch Loss: 4.484121018322185e-05\n",
      "Epoch 3357, Loss: 0.0003489824593998492, Final Batch Loss: 0.00011292640556348488\n",
      "Epoch 3358, Loss: 0.00024475849386362825, Final Batch Loss: 5.323759978637099e-06\n",
      "Epoch 3359, Loss: 0.00016752330702729523, Final Batch Loss: 3.304069468867965e-05\n",
      "Epoch 3360, Loss: 0.00043186666152905673, Final Batch Loss: 0.0003200600331183523\n",
      "Epoch 3361, Loss: 0.00031004834090708755, Final Batch Loss: 1.7538284737383947e-05\n",
      "Epoch 3362, Loss: 0.0011771603021770716, Final Batch Loss: 0.0003741395485121757\n",
      "Epoch 3363, Loss: 0.0002354120988456998, Final Batch Loss: 0.00011945656297029927\n",
      "Epoch 3364, Loss: 0.00019643806808744557, Final Batch Loss: 4.204466313240118e-05\n",
      "Epoch 3365, Loss: 0.00029610265482915565, Final Batch Loss: 0.0001636774541111663\n",
      "Epoch 3366, Loss: 0.0001504924739492708, Final Batch Loss: 1.991229146369733e-05\n",
      "Epoch 3367, Loss: 0.0003847279219826305, Final Batch Loss: 2.259165512441541e-06\n",
      "Epoch 3368, Loss: 0.0003729862510226667, Final Batch Loss: 6.247771671041846e-05\n",
      "Epoch 3369, Loss: 0.001265981078176992, Final Batch Loss: 0.00019123224774375558\n",
      "Epoch 3370, Loss: 0.00017808842312661, Final Batch Loss: 5.549356137635186e-05\n",
      "Epoch 3371, Loss: 0.0004384410276543349, Final Batch Loss: 5.171167867956683e-05\n",
      "Epoch 3372, Loss: 0.0004544804251054302, Final Batch Loss: 0.00011225851631024852\n",
      "Epoch 3373, Loss: 0.00031973093427950516, Final Batch Loss: 3.2029271096689627e-05\n",
      "Epoch 3374, Loss: 0.0005723999493056908, Final Batch Loss: 9.299627890868578e-06\n",
      "Epoch 3375, Loss: 0.00016366403360734694, Final Batch Loss: 8.079713734332472e-05\n",
      "Epoch 3376, Loss: 0.0003064270870254404, Final Batch Loss: 3.6276844639360206e-06\n",
      "Epoch 3377, Loss: 0.00020618510825443082, Final Batch Loss: 8.212037209887058e-05\n",
      "Epoch 3378, Loss: 0.00016952821715676691, Final Batch Loss: 2.3628004782949574e-05\n",
      "Epoch 3379, Loss: 0.00040318520041182637, Final Batch Loss: 4.532096500042826e-05\n",
      "Epoch 3380, Loss: 0.00029960751453472767, Final Batch Loss: 1.3419359675026499e-05\n",
      "Epoch 3381, Loss: 0.00039787600690033287, Final Batch Loss: 0.00013679539551958442\n",
      "Epoch 3382, Loss: 0.0002915168461186113, Final Batch Loss: 1.5893097952357493e-05\n",
      "Epoch 3383, Loss: 0.000267447705482482, Final Batch Loss: 6.235206092242151e-05\n",
      "Epoch 3384, Loss: 0.00028099079372623237, Final Batch Loss: 1.0013504834205378e-05\n",
      "Epoch 3385, Loss: 0.00028951656895515043, Final Batch Loss: 6.031019438523799e-05\n",
      "Epoch 3386, Loss: 0.00015361924670287408, Final Batch Loss: 2.606857378850691e-05\n",
      "Epoch 3387, Loss: 5.630246369037195e-05, Final Batch Loss: 5.107394372316776e-06\n",
      "Epoch 3388, Loss: 0.0008889535520211211, Final Batch Loss: 1.2522256838565227e-05\n",
      "Epoch 3389, Loss: 0.0002918299796874635, Final Batch Loss: 0.0001628478494239971\n",
      "Epoch 3390, Loss: 0.0003779393155127764, Final Batch Loss: 0.0002915430814027786\n",
      "Epoch 3391, Loss: 0.00043704712174985616, Final Batch Loss: 3.6624917356675724e-06\n",
      "Epoch 3392, Loss: 0.016119291976792738, Final Batch Loss: 9.287700959248468e-05\n",
      "Epoch 3393, Loss: 0.00021605876099783927, Final Batch Loss: 2.2281426936388016e-05\n",
      "Epoch 3394, Loss: 0.00026844905551115517, Final Batch Loss: 2.4217444661189802e-05\n",
      "Epoch 3395, Loss: 0.0006065608322387561, Final Batch Loss: 8.020522363949567e-05\n",
      "Epoch 3396, Loss: 0.00025572026515874313, Final Batch Loss: 0.00021793287305627018\n",
      "Epoch 3397, Loss: 0.00046184314123820513, Final Batch Loss: 6.220555223990232e-05\n",
      "Epoch 3398, Loss: 0.00031622745154891163, Final Batch Loss: 9.609323024051264e-05\n",
      "Epoch 3399, Loss: 0.010799291114381049, Final Batch Loss: 0.010539090260863304\n",
      "Epoch 3400, Loss: 0.00011446036478446331, Final Batch Loss: 1.6269665138679557e-05\n",
      "Epoch 3401, Loss: 0.0006475819973275065, Final Batch Loss: 3.179931081831455e-05\n",
      "Epoch 3402, Loss: 0.0012948171060997993, Final Batch Loss: 0.0004309004871174693\n",
      "Epoch 3403, Loss: 0.001592881693795789, Final Batch Loss: 3.7972589780110866e-05\n",
      "Epoch 3404, Loss: 0.0005432842044683639, Final Batch Loss: 0.00035236129770055413\n",
      "Epoch 3405, Loss: 0.0012273673710296862, Final Batch Loss: 0.0005204313201829791\n",
      "Epoch 3406, Loss: 0.01116667791211512, Final Batch Loss: 0.00014899240341037512\n",
      "Epoch 3407, Loss: 0.005823857864015736, Final Batch Loss: 6.841692083980888e-05\n",
      "Epoch 3408, Loss: 0.00263938850548584, Final Batch Loss: 0.0002763483498711139\n",
      "Epoch 3409, Loss: 0.0005380213333410211, Final Batch Loss: 0.0002339092898182571\n",
      "Epoch 3410, Loss: 0.0018062590243062004, Final Batch Loss: 0.00019423149933572859\n",
      "Epoch 3411, Loss: 0.0006274938641581684, Final Batch Loss: 0.00011571775394259021\n",
      "Epoch 3412, Loss: 0.00446667230426101, Final Batch Loss: 0.0043532452546060085\n",
      "Epoch 3413, Loss: 0.00025271600861742627, Final Batch Loss: 1.941307527886238e-05\n",
      "Epoch 3414, Loss: 0.00040677728384252987, Final Batch Loss: 5.451359811559087e-06\n",
      "Epoch 3415, Loss: 0.003118756372714415, Final Batch Loss: 2.4824417778290808e-05\n",
      "Epoch 3416, Loss: 0.0034977105060534086, Final Batch Loss: 0.0032089909072965384\n",
      "Epoch 3417, Loss: 0.00022906618869455997, Final Batch Loss: 1.2750630048685707e-05\n",
      "Epoch 3418, Loss: 0.00015058028839121107, Final Batch Loss: 4.3242736865067855e-05\n",
      "Epoch 3419, Loss: 0.00025142023150692694, Final Batch Loss: 0.00015752551553305238\n",
      "Epoch 3420, Loss: 0.00011808486237896432, Final Batch Loss: 2.066818751700339e-06\n",
      "Epoch 3421, Loss: 0.0001493233971814334, Final Batch Loss: 5.693425464414759e-06\n",
      "Epoch 3422, Loss: 0.0003093280211032834, Final Batch Loss: 0.00011902498954441398\n",
      "Epoch 3423, Loss: 0.0002757951824605698, Final Batch Loss: 1.9422566765570082e-05\n",
      "Epoch 3424, Loss: 0.0002618253020045813, Final Batch Loss: 0.00017285220383200794\n",
      "Epoch 3425, Loss: 0.00039083874798961915, Final Batch Loss: 0.0001967089920071885\n",
      "Epoch 3426, Loss: 0.0032975573103612987, Final Batch Loss: 0.0009166329982690513\n",
      "Epoch 3427, Loss: 0.00010439589277666528, Final Batch Loss: 6.886888149892911e-05\n",
      "Epoch 3428, Loss: 0.00019997180788777769, Final Batch Loss: 5.697580490959808e-05\n",
      "Epoch 3429, Loss: 0.0004085105611011386, Final Batch Loss: 0.00012571403931360692\n",
      "Epoch 3430, Loss: 0.0002497522109479178, Final Batch Loss: 0.00015478514251299202\n",
      "Epoch 3431, Loss: 0.0011262906336924061, Final Batch Loss: 0.0009009557543322444\n",
      "Epoch 3432, Loss: 0.0035027477078983793, Final Batch Loss: 0.0034046093933284283\n",
      "Epoch 3433, Loss: 0.0004677639626606833, Final Batch Loss: 7.507800910389051e-05\n",
      "Epoch 3434, Loss: 0.0003425120648898883, Final Batch Loss: 2.0676341591752134e-05\n",
      "Epoch 3435, Loss: 0.000277360846666852, Final Batch Loss: 4.6752513298997656e-05\n",
      "Epoch 3436, Loss: 0.0003596884771468467, Final Batch Loss: 5.650247112498619e-05\n",
      "Epoch 3437, Loss: 0.00037354224878072273, Final Batch Loss: 0.0002594748802948743\n",
      "Epoch 3438, Loss: 0.00031787569969310425, Final Batch Loss: 5.167746348888613e-05\n",
      "Epoch 3439, Loss: 0.0001537688385724323, Final Batch Loss: 2.0024848708999343e-05\n",
      "Epoch 3440, Loss: 0.00017175888569909148, Final Batch Loss: 7.542184175690636e-05\n",
      "Epoch 3441, Loss: 0.0001335934557573637, Final Batch Loss: 1.655486448726151e-05\n",
      "Epoch 3442, Loss: 0.0010309466888429597, Final Batch Loss: 0.00019526464166119695\n",
      "Epoch 3443, Loss: 0.0012962339678779244, Final Batch Loss: 0.0011936055961996317\n",
      "Epoch 3444, Loss: 0.0007719300847384147, Final Batch Loss: 0.0004927749978378415\n",
      "Epoch 3445, Loss: 0.00016649152530590072, Final Batch Loss: 5.17930238856934e-05\n",
      "Epoch 3446, Loss: 0.0017641474660194945, Final Batch Loss: 9.512306860415265e-06\n",
      "Epoch 3447, Loss: 0.002052880336123053, Final Batch Loss: 3.5290748201077804e-05\n",
      "Epoch 3448, Loss: 4.7580376303812955e-05, Final Batch Loss: 1.3253240467747673e-05\n",
      "Epoch 3449, Loss: 0.0002754580455075484, Final Batch Loss: 0.00014340755296871066\n",
      "Epoch 3450, Loss: 0.00024487191694788635, Final Batch Loss: 1.1099493349320255e-05\n",
      "Epoch 3451, Loss: 0.00010533132444834337, Final Batch Loss: 1.5198536857496947e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3452, Loss: 0.0002873900484701153, Final Batch Loss: 1.735078330966644e-05\n",
      "Epoch 3453, Loss: 0.0005548396511585452, Final Batch Loss: 0.0003646111872512847\n",
      "Epoch 3454, Loss: 0.00018540251767262816, Final Batch Loss: 0.0001409968244843185\n",
      "Epoch 3455, Loss: 0.0006257329951040447, Final Batch Loss: 0.0001558605581521988\n",
      "Epoch 3456, Loss: 0.00027192290235689143, Final Batch Loss: 3.787720561376773e-05\n",
      "Epoch 3457, Loss: 6.395761738531291e-05, Final Batch Loss: 7.83098948886618e-06\n",
      "Epoch 3458, Loss: 0.0004464812664082274, Final Batch Loss: 0.0002382261009188369\n",
      "Epoch 3459, Loss: 0.0001955050065589603, Final Batch Loss: 8.71823649504222e-05\n",
      "Epoch 3460, Loss: 7.704646156980743e-05, Final Batch Loss: 1.5131466852835729e-06\n",
      "Epoch 3461, Loss: 0.0015974470397850382, Final Batch Loss: 0.0013237179955467582\n",
      "Epoch 3462, Loss: 0.0003104174084000988, Final Batch Loss: 5.521092680282891e-05\n",
      "Epoch 3463, Loss: 0.00039769933300703997, Final Batch Loss: 0.00010044010559795424\n",
      "Epoch 3464, Loss: 0.0003510921014822088, Final Batch Loss: 7.823875785106793e-05\n",
      "Epoch 3465, Loss: 0.0036472150268309633, Final Batch Loss: 5.5667394917691126e-05\n",
      "Epoch 3466, Loss: 9.725839208840625e-05, Final Batch Loss: 9.013435374072287e-06\n",
      "Epoch 3467, Loss: 0.000359314631396046, Final Batch Loss: 2.1380030830187025e-06\n",
      "Epoch 3468, Loss: 0.001051672221365152, Final Batch Loss: 0.00022736116079613566\n",
      "Epoch 3469, Loss: 0.000564176072657574, Final Batch Loss: 0.000346337299561128\n",
      "Epoch 3470, Loss: 0.00023934544719850237, Final Batch Loss: 2.0466925434448058e-06\n",
      "Epoch 3471, Loss: 0.0004505546221480472, Final Batch Loss: 9.246088666259311e-06\n",
      "Epoch 3472, Loss: 0.0016600438534624118, Final Batch Loss: 2.18619461520575e-05\n",
      "Epoch 3473, Loss: 0.0008519869543306413, Final Batch Loss: 0.0005961177521385252\n",
      "Epoch 3474, Loss: 9.302834405389149e-05, Final Batch Loss: 2.309959745616652e-05\n",
      "Epoch 3475, Loss: 8.134656104630267e-05, Final Batch Loss: 3.009866986758425e-06\n",
      "Epoch 3476, Loss: 0.0018335721260882565, Final Batch Loss: 0.0016292072832584381\n",
      "Epoch 3477, Loss: 0.013530133501262753, Final Batch Loss: 0.01251312717795372\n",
      "Epoch 3478, Loss: 0.0006978749152040109, Final Batch Loss: 0.00014007014397066087\n",
      "Epoch 3479, Loss: 0.004472086351597682, Final Batch Loss: 0.00025466197985224426\n",
      "Epoch 3480, Loss: 0.02342432612203993, Final Batch Loss: 0.0001918453781399876\n",
      "Epoch 3481, Loss: 0.0006283676066232147, Final Batch Loss: 1.617551788513083e-05\n",
      "Epoch 3482, Loss: 0.0018680281173146795, Final Batch Loss: 0.0001412168930983171\n",
      "Epoch 3483, Loss: 0.0001860581442088005, Final Batch Loss: 1.3414520253718365e-05\n",
      "Epoch 3484, Loss: 0.0003188800155839999, Final Batch Loss: 8.463921403745189e-05\n",
      "Epoch 3485, Loss: 0.00012369781188681372, Final Batch Loss: 2.399842196609825e-05\n",
      "Epoch 3486, Loss: 0.000429700859967852, Final Batch Loss: 0.0002939010155387223\n",
      "Epoch 3487, Loss: 0.0002963623410323635, Final Batch Loss: 0.0001926191325765103\n",
      "Epoch 3488, Loss: 0.0004753845269078738, Final Batch Loss: 1.4135154742689338e-05\n",
      "Epoch 3489, Loss: 0.0004624190696631558, Final Batch Loss: 3.7547721149167046e-05\n",
      "Epoch 3490, Loss: 0.008564268312511558, Final Batch Loss: 1.024709581542993e-05\n",
      "Epoch 3491, Loss: 9.101181785808876e-05, Final Batch Loss: 2.1367135559557937e-05\n",
      "Epoch 3492, Loss: 0.00045175992818258237, Final Batch Loss: 1.0656234735506587e-05\n",
      "Epoch 3493, Loss: 0.000724781419194187, Final Batch Loss: 0.0005632078391499817\n",
      "Epoch 3494, Loss: 0.0002338968224648852, Final Batch Loss: 0.00011778041516663507\n",
      "Epoch 3495, Loss: 0.0003961001921197749, Final Batch Loss: 0.00034874759148806334\n",
      "Epoch 3496, Loss: 0.0005674440417351434, Final Batch Loss: 0.0005174020770937204\n",
      "Epoch 3497, Loss: 0.0005328152074071113, Final Batch Loss: 3.2012660085456446e-05\n",
      "Epoch 3498, Loss: 0.00032927815618677414, Final Batch Loss: 4.947787147102645e-06\n",
      "Epoch 3499, Loss: 0.00017690246204438154, Final Batch Loss: 1.832832276704721e-05\n",
      "Epoch 3500, Loss: 6.247298597372719e-05, Final Batch Loss: 2.7424481231719255e-05\n",
      "Epoch 3501, Loss: 0.0003682577589643188, Final Batch Loss: 5.548242916120216e-05\n",
      "Epoch 3502, Loss: 0.00011585103843003708, Final Batch Loss: 4.6625777372355515e-07\n",
      "Epoch 3503, Loss: 0.0003115746585535817, Final Batch Loss: 0.0001369468227494508\n",
      "Epoch 3504, Loss: 0.0005462434419314377, Final Batch Loss: 0.0003418222477193922\n",
      "Epoch 3505, Loss: 0.00014728570749866776, Final Batch Loss: 5.4920659749768674e-05\n",
      "Epoch 3506, Loss: 4.8530649110034574e-05, Final Batch Loss: 1.7338663383270614e-05\n",
      "Epoch 3507, Loss: 0.00032991137413773686, Final Batch Loss: 9.132380364462733e-05\n",
      "Epoch 3508, Loss: 0.0011655180278467014, Final Batch Loss: 0.00018354794883634895\n",
      "Epoch 3509, Loss: 0.00025923143402906135, Final Batch Loss: 0.00011622205056482926\n",
      "Epoch 3510, Loss: 9.570837210048921e-05, Final Batch Loss: 2.7466683604870923e-05\n",
      "Epoch 3511, Loss: 0.00010868415938602993, Final Batch Loss: 1.3987263628223445e-05\n",
      "Epoch 3512, Loss: 0.003233573901525233, Final Batch Loss: 0.00023668039648327976\n",
      "Epoch 3513, Loss: 0.0001645785714572412, Final Batch Loss: 2.529516859794967e-05\n",
      "Epoch 3514, Loss: 6.750051488779718e-05, Final Batch Loss: 1.8718663341132924e-05\n",
      "Epoch 3515, Loss: 0.00023581343884870876, Final Batch Loss: 0.0001539590593893081\n",
      "Epoch 3516, Loss: 0.0110290331822398, Final Batch Loss: 9.411918290425092e-05\n",
      "Epoch 3517, Loss: 6.85587228872464e-05, Final Batch Loss: 9.486002454650588e-06\n",
      "Epoch 3518, Loss: 0.000920789891097229, Final Batch Loss: 0.000617528276052326\n",
      "Epoch 3519, Loss: 0.0002031047533819219, Final Batch Loss: 0.0001556331553729251\n",
      "Epoch 3520, Loss: 0.00028760025725205196, Final Batch Loss: 0.00021158772869966924\n",
      "Epoch 3521, Loss: 0.00021238693079794757, Final Batch Loss: 0.00015395852096844465\n",
      "Epoch 3522, Loss: 0.0004559069529932458, Final Batch Loss: 2.0898911316180602e-05\n",
      "Epoch 3523, Loss: 8.372470438189339e-05, Final Batch Loss: 2.6207138944300823e-05\n",
      "Epoch 3524, Loss: 0.0008918856547097676, Final Batch Loss: 0.0004884334630332887\n",
      "Epoch 3525, Loss: 0.0009349274823762244, Final Batch Loss: 1.994122976611834e-05\n",
      "Epoch 3526, Loss: 0.0001707757037365809, Final Batch Loss: 5.4254127462627366e-05\n",
      "Epoch 3527, Loss: 0.00024162639965652488, Final Batch Loss: 0.00011758162872865796\n",
      "Epoch 3528, Loss: 5.603318300018145e-05, Final Batch Loss: 7.921573796920711e-07\n",
      "Epoch 3529, Loss: 0.00020609765488188714, Final Batch Loss: 1.5611833077855408e-05\n",
      "Epoch 3530, Loss: 0.00011887984419445274, Final Batch Loss: 1.2724441148748156e-05\n",
      "Epoch 3531, Loss: 0.00014554327026417013, Final Batch Loss: 3.0821367545286193e-05\n",
      "Epoch 3532, Loss: 0.00010229220788460225, Final Batch Loss: 2.7031996069126762e-05\n",
      "Epoch 3533, Loss: 0.0003122789412373095, Final Batch Loss: 1.3903262697567698e-05\n",
      "Epoch 3534, Loss: 0.00012042411981383339, Final Batch Loss: 3.3148353395517915e-05\n",
      "Epoch 3535, Loss: 0.0005031025793869048, Final Batch Loss: 8.732817514101043e-05\n",
      "Epoch 3536, Loss: 9.884156997941318e-05, Final Batch Loss: 3.375539745320566e-05\n",
      "Epoch 3537, Loss: 0.0029099627490722924, Final Batch Loss: 0.0008650114177726209\n",
      "Epoch 3538, Loss: 0.000296035643259529, Final Batch Loss: 6.378161197062582e-05\n",
      "Epoch 3539, Loss: 0.0001944617433764506, Final Batch Loss: 1.9108152628177777e-05\n",
      "Epoch 3540, Loss: 0.00026040926240966655, Final Batch Loss: 0.00010953907622024417\n",
      "Epoch 3541, Loss: 0.00017400059368810616, Final Batch Loss: 1.3860288163414225e-05\n",
      "Epoch 3542, Loss: 0.008087217737738683, Final Batch Loss: 0.007667401805520058\n",
      "Epoch 3543, Loss: 5.976550937702996e-05, Final Batch Loss: 4.237188113620505e-05\n",
      "Epoch 3544, Loss: 0.0020144046720815822, Final Batch Loss: 0.0018530481029301882\n",
      "Epoch 3545, Loss: 0.00048681581756682135, Final Batch Loss: 0.00038983728154562414\n",
      "Epoch 3546, Loss: 0.0008488559624311165, Final Batch Loss: 6.77967273077229e-06\n",
      "Epoch 3547, Loss: 0.00018069420184474438, Final Batch Loss: 4.622013511834666e-05\n",
      "Epoch 3548, Loss: 0.0005802455270895734, Final Batch Loss: 4.1709718061611056e-05\n",
      "Epoch 3549, Loss: 0.0006638674167334102, Final Batch Loss: 0.0005073557258583605\n",
      "Epoch 3550, Loss: 0.0022666912846034393, Final Batch Loss: 5.3435025620274246e-05\n",
      "Epoch 3551, Loss: 0.0353342132934813, Final Batch Loss: 0.03516276180744171\n",
      "Epoch 3552, Loss: 0.0005495169316418469, Final Batch Loss: 0.00020591248176060617\n",
      "Epoch 3553, Loss: 0.00020223393221385777, Final Batch Loss: 1.628782592888456e-05\n",
      "Epoch 3554, Loss: 0.0012163081555627286, Final Batch Loss: 6.936019053682685e-05\n",
      "Epoch 3555, Loss: 0.03718208096688613, Final Batch Loss: 0.036036256700754166\n",
      "Epoch 3556, Loss: 0.0004319105073591345, Final Batch Loss: 0.00035252419183962047\n",
      "Epoch 3557, Loss: 0.0026918207440758124, Final Batch Loss: 0.0019061879720538855\n",
      "Epoch 3558, Loss: 3.459248694070993e-05, Final Batch Loss: 1.7073185745175579e-06\n",
      "Epoch 3559, Loss: 0.039805093056656915, Final Batch Loss: 0.03977713733911514\n",
      "Epoch 3560, Loss: 0.03144670574693009, Final Batch Loss: 0.03132319077849388\n",
      "Epoch 3561, Loss: 0.00011107008867838886, Final Batch Loss: 4.772159445565194e-05\n",
      "Epoch 3562, Loss: 0.004806553712114692, Final Batch Loss: 0.001107907621189952\n",
      "Epoch 3563, Loss: 0.017639212892390788, Final Batch Loss: 0.015408032573759556\n",
      "Epoch 3564, Loss: 0.00640975047417669, Final Batch Loss: 2.8079753064957913e-06\n",
      "Epoch 3565, Loss: 0.0005356048754947551, Final Batch Loss: 0.00028927347739227116\n",
      "Epoch 3566, Loss: 0.018518001612392254, Final Batch Loss: 0.015220359899103642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3567, Loss: 0.0003448914703767514, Final Batch Loss: 0.00023521365073975176\n",
      "Epoch 3568, Loss: 0.09096169430085865, Final Batch Loss: 7.863388418627437e-06\n",
      "Epoch 3569, Loss: 0.0011991407809546217, Final Batch Loss: 0.00027741602389141917\n",
      "Epoch 3570, Loss: 0.10294650043942966, Final Batch Loss: 0.09024495631456375\n",
      "Epoch 3571, Loss: 0.009244546741683735, Final Batch Loss: 3.714309059432708e-05\n",
      "Epoch 3572, Loss: 0.0006118556084402371, Final Batch Loss: 0.0003797856334131211\n",
      "Epoch 3573, Loss: 0.00011751139754778706, Final Batch Loss: 2.5237441150238737e-05\n",
      "Epoch 3574, Loss: 0.013496167215635069, Final Batch Loss: 0.009528037160634995\n",
      "Epoch 3575, Loss: 0.004674570845963899, Final Batch Loss: 0.00447056395933032\n",
      "Epoch 3576, Loss: 0.006948802707483992, Final Batch Loss: 0.00017567646864335984\n",
      "Epoch 3577, Loss: 0.0011759233093471266, Final Batch Loss: 0.0003834118542727083\n",
      "Epoch 3578, Loss: 0.04424774693325162, Final Batch Loss: 9.553181007504463e-05\n",
      "Epoch 3579, Loss: 0.0041395085863769054, Final Batch Loss: 0.0018693155143409967\n",
      "Epoch 3580, Loss: 0.00551590567920357, Final Batch Loss: 0.0015551759861409664\n",
      "Epoch 3581, Loss: 0.002950071051600389, Final Batch Loss: 0.0025005051866173744\n",
      "Epoch 3582, Loss: 0.004126906035708089, Final Batch Loss: 1.2814035471819807e-05\n",
      "Epoch 3583, Loss: 0.0002087975080939941, Final Batch Loss: 8.848879224387929e-05\n",
      "Epoch 3584, Loss: 0.0003468751165200956, Final Batch Loss: 4.678285768022761e-05\n",
      "Epoch 3585, Loss: 5.983115443086717e-05, Final Batch Loss: 5.807075467600953e-06\n",
      "Epoch 3586, Loss: 0.0014140106482045667, Final Batch Loss: 6.139054221421247e-06\n",
      "Epoch 3587, Loss: 0.00045797781240253244, Final Batch Loss: 1.2995480574318208e-05\n",
      "Epoch 3588, Loss: 0.00020010204025311396, Final Batch Loss: 0.00011037665535695851\n",
      "Epoch 3589, Loss: 0.0002246544827357866, Final Batch Loss: 0.00010199580719927326\n",
      "Epoch 3590, Loss: 0.0002156950613425579, Final Batch Loss: 6.152905552880839e-05\n",
      "Epoch 3591, Loss: 0.0002561439850978786, Final Batch Loss: 1.6770851289038546e-05\n",
      "Epoch 3592, Loss: 0.00032920290436777577, Final Batch Loss: 3.0724238513357705e-06\n",
      "Epoch 3593, Loss: 0.004007452062523953, Final Batch Loss: 5.917236649111146e-06\n",
      "Epoch 3594, Loss: 0.00022628249939771194, Final Batch Loss: 1.369929350403254e-06\n",
      "Epoch 3595, Loss: 0.00032815684335218975, Final Batch Loss: 0.0002536578685976565\n",
      "Epoch 3596, Loss: 0.0001735443047437002, Final Batch Loss: 8.336853352375329e-05\n",
      "Epoch 3597, Loss: 0.00023737185256322846, Final Batch Loss: 6.6831024014391e-05\n",
      "Epoch 3598, Loss: 0.0012731800597975962, Final Batch Loss: 0.00033920444548130035\n",
      "Epoch 3599, Loss: 0.00023215337205328979, Final Batch Loss: 5.798916026833467e-05\n",
      "Epoch 3600, Loss: 0.0031443270563613623, Final Batch Loss: 3.090200334554538e-05\n",
      "Epoch 3601, Loss: 0.006828218183727586, Final Batch Loss: 0.006802849937230349\n",
      "Epoch 3602, Loss: 0.0006642656153417192, Final Batch Loss: 6.724696868332103e-05\n",
      "Epoch 3603, Loss: 0.001393754746459308, Final Batch Loss: 0.00011841279047075659\n",
      "Epoch 3604, Loss: 0.001356830856821034, Final Batch Loss: 0.00011630569497356191\n",
      "Epoch 3605, Loss: 0.00024852590195223456, Final Batch Loss: 9.775313628779259e-06\n",
      "Epoch 3606, Loss: 0.0003323103846923914, Final Batch Loss: 0.0001804158091545105\n",
      "Epoch 3607, Loss: 0.00021239832676656079, Final Batch Loss: 0.0001175569705083035\n",
      "Epoch 3608, Loss: 0.000622926207142882, Final Batch Loss: 0.00011043981066904962\n",
      "Epoch 3609, Loss: 0.00013114312059769873, Final Batch Loss: 9.990719991037622e-05\n",
      "Epoch 3610, Loss: 0.0002087057746393839, Final Batch Loss: 0.0001589712774148211\n",
      "Epoch 3611, Loss: 0.0005960744165349752, Final Batch Loss: 0.00014349663979373872\n",
      "Epoch 3612, Loss: 0.0012294401567487512, Final Batch Loss: 5.1855036872439086e-05\n",
      "Epoch 3613, Loss: 0.00010351789296692004, Final Batch Loss: 1.4731586816196796e-05\n",
      "Epoch 3614, Loss: 0.001235846859344747, Final Batch Loss: 0.0010599254164844751\n",
      "Epoch 3615, Loss: 0.00044713111242344894, Final Batch Loss: 2.147638269889285e-06\n",
      "Epoch 3616, Loss: 0.00013851143103238428, Final Batch Loss: 1.0813567314471584e-05\n",
      "Epoch 3617, Loss: 4.13181760450243e-05, Final Batch Loss: 1.0246704732708167e-05\n",
      "Epoch 3618, Loss: 0.0009990868002205389, Final Batch Loss: 2.0130684788455255e-05\n",
      "Epoch 3619, Loss: 0.00012796491864719428, Final Batch Loss: 2.6231758965877816e-05\n",
      "Epoch 3620, Loss: 0.0008035384307731874, Final Batch Loss: 0.00018968326912727207\n",
      "Epoch 3621, Loss: 0.005218271586272749, Final Batch Loss: 1.6546879123779945e-05\n",
      "Epoch 3622, Loss: 0.00012229519234097097, Final Batch Loss: 1.849177533586044e-05\n",
      "Epoch 3623, Loss: 0.0005478651510202326, Final Batch Loss: 7.791318785166368e-05\n",
      "Epoch 3624, Loss: 0.0003961538550356636, Final Batch Loss: 1.2862026778748259e-05\n",
      "Epoch 3625, Loss: 0.0017087087726395112, Final Batch Loss: 0.00149788788985461\n",
      "Epoch 3626, Loss: 0.00047420622286153957, Final Batch Loss: 2.5547858967911452e-05\n",
      "Epoch 3627, Loss: 0.0007089405044098385, Final Batch Loss: 0.00013877729361411184\n",
      "Epoch 3628, Loss: 0.0010884381663345266, Final Batch Loss: 9.261992090614513e-06\n",
      "Epoch 3629, Loss: 0.0018475412798579782, Final Batch Loss: 0.0005188013892620802\n",
      "Epoch 3630, Loss: 0.0005549372945097275, Final Batch Loss: 2.2100612113717943e-05\n",
      "Epoch 3631, Loss: 0.00033725965113262646, Final Batch Loss: 8.320501365233213e-05\n",
      "Epoch 3632, Loss: 0.0007972948624228593, Final Batch Loss: 6.920268788235262e-06\n",
      "Epoch 3633, Loss: 0.000137591961902217, Final Batch Loss: 8.88851354829967e-05\n",
      "Epoch 3634, Loss: 0.00016065540694398805, Final Batch Loss: 6.0910173488082364e-05\n",
      "Epoch 3635, Loss: 0.000327277224187128, Final Batch Loss: 6.727708296239143e-06\n",
      "Epoch 3636, Loss: 0.0005817482087877579, Final Batch Loss: 4.970487498212606e-05\n",
      "Epoch 3637, Loss: 0.00044443015940487385, Final Batch Loss: 0.00016292041982524097\n",
      "Epoch 3638, Loss: 0.00011446265489212237, Final Batch Loss: 2.674482857401017e-05\n",
      "Epoch 3639, Loss: 0.00011024104435364279, Final Batch Loss: 1.5179231240836089e-06\n",
      "Epoch 3640, Loss: 0.0014497799011223833, Final Batch Loss: 2.7377891456126235e-06\n",
      "Epoch 3641, Loss: 0.0009106782235903665, Final Batch Loss: 1.4481545804301277e-05\n",
      "Epoch 3642, Loss: 0.00025733905658853473, Final Batch Loss: 1.0051936442323495e-05\n",
      "Epoch 3643, Loss: 0.0002794899983200594, Final Batch Loss: 8.337785402545705e-06\n",
      "Epoch 3644, Loss: 7.754495163680986e-05, Final Batch Loss: 4.076206460013054e-05\n",
      "Epoch 3645, Loss: 0.0005009189044358209, Final Batch Loss: 5.2337200031615794e-05\n",
      "Epoch 3646, Loss: 0.0016289946797769517, Final Batch Loss: 0.0012929004151374102\n",
      "Epoch 3647, Loss: 0.00015509153126913588, Final Batch Loss: 2.2118563720141537e-05\n",
      "Epoch 3648, Loss: 0.042117611366847996, Final Batch Loss: 7.350644409598317e-06\n",
      "Epoch 3649, Loss: 0.00010383623930465546, Final Batch Loss: 6.871231744298711e-05\n",
      "Epoch 3650, Loss: 0.0005143050020706141, Final Batch Loss: 1.0877733075176366e-05\n",
      "Epoch 3651, Loss: 0.004103615173335129, Final Batch Loss: 1.249999968422344e-05\n",
      "Epoch 3652, Loss: 0.00036625795655709226, Final Batch Loss: 7.99875269876793e-05\n",
      "Epoch 3653, Loss: 0.0005588887461271952, Final Batch Loss: 0.00011727419041562825\n",
      "Epoch 3654, Loss: 0.0002539198167141876, Final Batch Loss: 4.922482730762567e-06\n",
      "Epoch 3655, Loss: 0.0002667905209818855, Final Batch Loss: 4.277895641280338e-05\n",
      "Epoch 3656, Loss: 0.0004044499892188469, Final Batch Loss: 2.7261086870566942e-05\n",
      "Epoch 3657, Loss: 7.923324483272154e-05, Final Batch Loss: 1.1215648555662483e-05\n",
      "Epoch 3658, Loss: 0.00035291645326651633, Final Batch Loss: 6.31556031294167e-05\n",
      "Epoch 3659, Loss: 0.00014107976676314138, Final Batch Loss: 7.544276013504714e-05\n",
      "Epoch 3660, Loss: 7.461778113793116e-05, Final Batch Loss: 8.260003596660681e-06\n",
      "Epoch 3661, Loss: 0.0003574049078451935, Final Batch Loss: 0.0002946974418591708\n",
      "Epoch 3662, Loss: 0.00043016840936616063, Final Batch Loss: 0.00011686933430610225\n",
      "Epoch 3663, Loss: 0.00010314794690202689, Final Batch Loss: 2.6585510568111204e-05\n",
      "Epoch 3664, Loss: 0.00016733551092329435, Final Batch Loss: 6.089335511205718e-05\n",
      "Epoch 3665, Loss: 0.00010518077033339068, Final Batch Loss: 1.7799278793972917e-05\n",
      "Epoch 3666, Loss: 0.0007398679226753302, Final Batch Loss: 0.0006747631705366075\n",
      "Epoch 3667, Loss: 0.00013844185832567746, Final Batch Loss: 2.649162161105778e-05\n",
      "Epoch 3668, Loss: 0.003915212524589151, Final Batch Loss: 0.0018813521601259708\n",
      "Epoch 3669, Loss: 0.009030244888890593, Final Batch Loss: 0.005577671807259321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3670, Loss: 0.00012424711530911736, Final Batch Loss: 5.376057742978446e-05\n",
      "Epoch 3671, Loss: 0.010453152539412258, Final Batch Loss: 7.102491508703679e-05\n",
      "Epoch 3672, Loss: 0.0004486631223699078, Final Batch Loss: 5.673702253261581e-05\n",
      "Epoch 3673, Loss: 0.018425713741635263, Final Batch Loss: 1.2916608284285758e-05\n",
      "Epoch 3674, Loss: 0.00011292576891719364, Final Batch Loss: 1.440984669898171e-05\n",
      "Epoch 3675, Loss: 0.0005481345870066434, Final Batch Loss: 0.00013371027307584882\n",
      "Epoch 3676, Loss: 8.214841727749445e-05, Final Batch Loss: 8.424116458627395e-06\n",
      "Epoch 3677, Loss: 0.029173657196224667, Final Batch Loss: 5.048735692980699e-05\n",
      "Epoch 3678, Loss: 0.0021113083712407388, Final Batch Loss: 0.001923193340189755\n",
      "Epoch 3679, Loss: 0.00039576671900931615, Final Batch Loss: 9.065547033060284e-07\n",
      "Epoch 3680, Loss: 0.0012901025074825156, Final Batch Loss: 0.0004572986508719623\n",
      "Epoch 3681, Loss: 0.003367542740306817, Final Batch Loss: 0.000175445296918042\n",
      "Epoch 3682, Loss: 0.0009721507376525551, Final Batch Loss: 7.408190140267834e-05\n",
      "Epoch 3683, Loss: 0.0059741071418102365, Final Batch Loss: 0.00025440656463615596\n",
      "Epoch 3684, Loss: 0.0008567637869418832, Final Batch Loss: 0.000800070003606379\n",
      "Epoch 3685, Loss: 0.0006625759961025324, Final Batch Loss: 3.939291855203919e-05\n",
      "Epoch 3686, Loss: 0.0013904565639677458, Final Batch Loss: 5.787382542621344e-05\n",
      "Epoch 3687, Loss: 0.0009326913386757951, Final Batch Loss: 4.3147756514372304e-05\n",
      "Epoch 3688, Loss: 0.008479295851429924, Final Batch Loss: 0.00812298059463501\n",
      "Epoch 3689, Loss: 0.001230187808687333, Final Batch Loss: 8.223686745623127e-05\n",
      "Epoch 3690, Loss: 0.0001670536930760136, Final Batch Loss: 1.8593518689158373e-05\n",
      "Epoch 3691, Loss: 0.0008001947498996742, Final Batch Loss: 6.354685319820419e-05\n",
      "Epoch 3692, Loss: 0.00033112299570348114, Final Batch Loss: 4.254234227119014e-05\n",
      "Epoch 3693, Loss: 0.0006090793394832872, Final Batch Loss: 0.0004086148110218346\n",
      "Epoch 3694, Loss: 0.0005012418841943145, Final Batch Loss: 0.00026076455833390355\n",
      "Epoch 3695, Loss: 0.001008704537525773, Final Batch Loss: 0.0007250812486745417\n",
      "Epoch 3696, Loss: 0.0004546993732219562, Final Batch Loss: 7.435362203978002e-05\n",
      "Epoch 3697, Loss: 0.0001502329105278477, Final Batch Loss: 0.00010468724212842062\n",
      "Epoch 3698, Loss: 0.00047959654693841003, Final Batch Loss: 5.700266774510965e-05\n",
      "Epoch 3699, Loss: 0.00016382409194193315, Final Batch Loss: 3.017534254468046e-06\n",
      "Epoch 3700, Loss: 0.00010035797140517388, Final Batch Loss: 1.097866061172681e-06\n",
      "Epoch 3701, Loss: 0.0007410587859340012, Final Batch Loss: 0.0002685400831978768\n",
      "Epoch 3702, Loss: 0.0009134901183642796, Final Batch Loss: 0.0008491267799399793\n",
      "Epoch 3703, Loss: 0.003149794130877126, Final Batch Loss: 0.002965611405670643\n",
      "Epoch 3704, Loss: 0.00010322129855921958, Final Batch Loss: 3.8200403650989756e-05\n",
      "Epoch 3705, Loss: 7.265975909831468e-05, Final Batch Loss: 3.737639417522587e-06\n",
      "Epoch 3706, Loss: 0.00453955072316603, Final Batch Loss: 2.3787128156982362e-05\n",
      "Epoch 3707, Loss: 0.0006018068597768433, Final Batch Loss: 3.55495503754355e-05\n",
      "Epoch 3708, Loss: 0.0011099320636276389, Final Batch Loss: 5.622381650027819e-05\n",
      "Epoch 3709, Loss: 0.00022566030202142429, Final Batch Loss: 1.022542710416019e-05\n",
      "Epoch 3710, Loss: 0.003303234923805576, Final Batch Loss: 6.463721365435049e-05\n",
      "Epoch 3711, Loss: 0.0008348075607500505, Final Batch Loss: 9.426032193005085e-06\n",
      "Epoch 3712, Loss: 0.0015227364638121799, Final Batch Loss: 0.0012563541531562805\n",
      "Epoch 3713, Loss: 0.00031587832927471027, Final Batch Loss: 3.6726320104207844e-05\n",
      "Epoch 3714, Loss: 0.0034708696789493843, Final Batch Loss: 4.265270490577677e-06\n",
      "Epoch 3715, Loss: 0.001809201329251664, Final Batch Loss: 6.3531138039252255e-06\n",
      "Epoch 3716, Loss: 0.0010742840895545669, Final Batch Loss: 0.0006291214376688004\n",
      "Epoch 3717, Loss: 0.00012085998787370045, Final Batch Loss: 7.843324056011625e-06\n",
      "Epoch 3718, Loss: 0.00012880771191703388, Final Batch Loss: 1.1426310265960637e-05\n",
      "Epoch 3719, Loss: 0.0005183798675716389, Final Batch Loss: 0.00026678864378482103\n",
      "Epoch 3720, Loss: 0.0005480076906678732, Final Batch Loss: 3.36898592649959e-05\n",
      "Epoch 3721, Loss: 8.088335243883193e-05, Final Batch Loss: 6.689077508781338e-06\n",
      "Epoch 3722, Loss: 0.00039590657979715616, Final Batch Loss: 0.00022246695880312473\n",
      "Epoch 3723, Loss: 0.011333709828249994, Final Batch Loss: 0.011264344677329063\n",
      "Epoch 3724, Loss: 0.0004083745225216262, Final Batch Loss: 0.00024350412422791123\n",
      "Epoch 3725, Loss: 0.0003691238434839761, Final Batch Loss: 2.5501240088487975e-05\n",
      "Epoch 3726, Loss: 0.0008930929616326466, Final Batch Loss: 0.00010568487050477415\n",
      "Epoch 3727, Loss: 0.0010950021496682893, Final Batch Loss: 1.8541421013651416e-05\n",
      "Epoch 3728, Loss: 0.0017256650626222836, Final Batch Loss: 3.101231777691282e-05\n",
      "Epoch 3729, Loss: 0.00040863129106583074, Final Batch Loss: 4.609450843418017e-05\n",
      "Epoch 3730, Loss: 0.0008753461806918494, Final Batch Loss: 2.7902286092285067e-05\n",
      "Epoch 3731, Loss: 0.00030262319069152, Final Batch Loss: 9.155451152764726e-06\n",
      "Epoch 3732, Loss: 0.0007673729651287431, Final Batch Loss: 7.050961357890628e-06\n",
      "Epoch 3733, Loss: 0.0003127269937976962, Final Batch Loss: 0.00021549861412495375\n",
      "Epoch 3734, Loss: 0.00022560653633263428, Final Batch Loss: 1.7518565073260106e-05\n",
      "Epoch 3735, Loss: 0.0003883882200170774, Final Batch Loss: 0.00028136902255937457\n",
      "Epoch 3736, Loss: 0.00017465952896600356, Final Batch Loss: 4.686286956712138e-06\n",
      "Epoch 3737, Loss: 5.3140370937398984e-05, Final Batch Loss: 3.375837695784867e-05\n",
      "Epoch 3738, Loss: 0.0002608942559163552, Final Batch Loss: 5.6053551816148683e-05\n",
      "Epoch 3739, Loss: 0.000416035094531253, Final Batch Loss: 0.00025113378069363534\n",
      "Epoch 3740, Loss: 7.448320684488863e-05, Final Batch Loss: 3.254122566431761e-05\n",
      "Epoch 3741, Loss: 0.0008178959415090503, Final Batch Loss: 7.426382580888458e-06\n",
      "Epoch 3742, Loss: 0.0001693510785116814, Final Batch Loss: 8.635000085632782e-06\n",
      "Epoch 3743, Loss: 0.0004545335650618654, Final Batch Loss: 0.00023499566304963082\n",
      "Epoch 3744, Loss: 0.0006019843276590109, Final Batch Loss: 0.0004246947937645018\n",
      "Epoch 3745, Loss: 0.001201825958560221, Final Batch Loss: 0.000193687024875544\n",
      "Epoch 3746, Loss: 0.00023916681675473228, Final Batch Loss: 5.7208344514947385e-05\n",
      "Epoch 3747, Loss: 0.0003633383039414184, Final Batch Loss: 5.668031735694967e-05\n",
      "Epoch 3748, Loss: 0.0007000528967182618, Final Batch Loss: 1.7259551896131597e-05\n",
      "Epoch 3749, Loss: 0.0001229889794558403, Final Batch Loss: 8.468793566862587e-06\n",
      "Epoch 3750, Loss: 0.00013921590289101005, Final Batch Loss: 1.3396616850513965e-05\n",
      "Epoch 3751, Loss: 0.00016480645899719093, Final Batch Loss: 5.149545177118853e-05\n",
      "Epoch 3752, Loss: 0.00015425236870214576, Final Batch Loss: 1.0203516467299778e-05\n",
      "Epoch 3753, Loss: 0.0015128515697142575, Final Batch Loss: 5.691749174729921e-05\n",
      "Epoch 3754, Loss: 0.00031118839297050727, Final Batch Loss: 3.4934932955366094e-06\n",
      "Epoch 3755, Loss: 2.8540224320749985e-05, Final Batch Loss: 1.1840480510727502e-05\n",
      "Epoch 3756, Loss: 0.0003828708431683481, Final Batch Loss: 5.197070640861057e-05\n",
      "Epoch 3757, Loss: 0.00026219922801828943, Final Batch Loss: 4.5346951083047315e-05\n",
      "Epoch 3758, Loss: 0.00016893045540200546, Final Batch Loss: 7.021740020718426e-05\n",
      "Epoch 3759, Loss: 0.00010876997794184717, Final Batch Loss: 6.906525868544122e-06\n",
      "Epoch 3760, Loss: 0.00030405861616600305, Final Batch Loss: 7.364594785030931e-05\n",
      "Epoch 3761, Loss: 0.00011620116129051894, Final Batch Loss: 1.7758211470209062e-05\n",
      "Epoch 3762, Loss: 4.93110246679862e-05, Final Batch Loss: 5.052044343756279e-06\n",
      "Epoch 3763, Loss: 0.0002891682961490005, Final Batch Loss: 0.0001914200111059472\n",
      "Epoch 3764, Loss: 0.0004833611201320309, Final Batch Loss: 3.079804082517512e-05\n",
      "Epoch 3765, Loss: 0.0011392612932468182, Final Batch Loss: 0.0010963985696434975\n",
      "Epoch 3766, Loss: 0.0008083970642474014, Final Batch Loss: 5.671307008014992e-06\n",
      "Epoch 3767, Loss: 0.0001488604530095472, Final Batch Loss: 7.481517059204634e-06\n",
      "Epoch 3768, Loss: 0.00031704941466159653, Final Batch Loss: 1.4961085980758071e-05\n",
      "Epoch 3769, Loss: 0.0006515269747069397, Final Batch Loss: 6.75268938721274e-06\n",
      "Epoch 3770, Loss: 0.0015905311738606542, Final Batch Loss: 0.0013545663096010685\n",
      "Epoch 3771, Loss: 0.00011913650814676657, Final Batch Loss: 1.9415610950090922e-05\n",
      "Epoch 3772, Loss: 0.011462325166576193, Final Batch Loss: 0.011391418054699898\n",
      "Epoch 3773, Loss: 0.00013373491401580395, Final Batch Loss: 3.5028544516535476e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3774, Loss: 0.00025848174300335813, Final Batch Loss: 4.0907329093897715e-05\n",
      "Epoch 3775, Loss: 0.0002962235412269365, Final Batch Loss: 0.0002340112696401775\n",
      "Epoch 3776, Loss: 0.00033609176534810103, Final Batch Loss: 0.00011673813423840329\n",
      "Epoch 3777, Loss: 0.010952964741591131, Final Batch Loss: 0.00047306515625678003\n",
      "Epoch 3778, Loss: 0.0001572376313561108, Final Batch Loss: 4.6953558921813965e-05\n",
      "Epoch 3779, Loss: 0.00020393710565258516, Final Batch Loss: 3.0200140827219002e-05\n",
      "Epoch 3780, Loss: 0.00034430520281603094, Final Batch Loss: 2.685040635697078e-05\n",
      "Epoch 3781, Loss: 0.0003921972802345408, Final Batch Loss: 5.315379530657083e-05\n",
      "Epoch 3782, Loss: 0.004256888512827572, Final Batch Loss: 3.0641975172329694e-05\n",
      "Epoch 3783, Loss: 0.00015529454503848683, Final Batch Loss: 8.14458035165444e-05\n",
      "Epoch 3784, Loss: 0.0071752387902961345, Final Batch Loss: 2.776655492198188e-05\n",
      "Epoch 3785, Loss: 0.0003297321090940386, Final Batch Loss: 0.00010277832188876346\n",
      "Epoch 3786, Loss: 7.350368878178415e-05, Final Batch Loss: 2.067594869004097e-05\n",
      "Epoch 3787, Loss: 0.00043170220669708215, Final Batch Loss: 0.0003547191445250064\n",
      "Epoch 3788, Loss: 0.0016197027471207548, Final Batch Loss: 0.0006702753598801792\n",
      "Epoch 3789, Loss: 0.001260446777450852, Final Batch Loss: 0.0008452910697087646\n",
      "Epoch 3790, Loss: 0.0002973227110487642, Final Batch Loss: 3.947909499402158e-05\n",
      "Epoch 3791, Loss: 0.004085334123374196, Final Batch Loss: 8.30110875540413e-05\n",
      "Epoch 3792, Loss: 0.0002868997253244743, Final Batch Loss: 4.486571197048761e-05\n",
      "Epoch 3793, Loss: 0.0002699797432796913, Final Batch Loss: 1.1267750778642949e-05\n",
      "Epoch 3794, Loss: 0.0008288033968710806, Final Batch Loss: 4.5355784095590934e-05\n",
      "Epoch 3795, Loss: 0.0007384204218396917, Final Batch Loss: 0.00012403815344441682\n",
      "Epoch 3796, Loss: 0.012691089097643271, Final Batch Loss: 0.000451630272436887\n",
      "Epoch 3797, Loss: 0.009009579991470673, Final Batch Loss: 1.772098221408669e-05\n",
      "Epoch 3798, Loss: 0.00032306341381627135, Final Batch Loss: 5.9518246416701004e-05\n",
      "Epoch 3799, Loss: 0.038154684167238884, Final Batch Loss: 5.5545169743709266e-05\n",
      "Epoch 3800, Loss: 0.0009312770316682872, Final Batch Loss: 4.221187737130094e-06\n",
      "Epoch 3801, Loss: 0.001523673865449382, Final Batch Loss: 4.390343019622378e-05\n",
      "Epoch 3802, Loss: 0.00017164508608402684, Final Batch Loss: 1.0046314855571836e-05\n",
      "Epoch 3803, Loss: 0.0004040351941512199, Final Batch Loss: 2.7205804144614376e-05\n",
      "Epoch 3804, Loss: 0.00039972716695046984, Final Batch Loss: 0.0001899555354611948\n",
      "Epoch 3805, Loss: 0.00011430732229200657, Final Batch Loss: 2.565913564467337e-05\n",
      "Epoch 3806, Loss: 0.008348728821147233, Final Batch Loss: 0.00781429372727871\n",
      "Epoch 3807, Loss: 0.00012225254431541543, Final Batch Loss: 5.19217319379095e-05\n",
      "Epoch 3808, Loss: 0.0004287328797545342, Final Batch Loss: 3.3185374377353583e-06\n",
      "Epoch 3809, Loss: 0.0004159829259151593, Final Batch Loss: 1.8791237380355597e-05\n",
      "Epoch 3810, Loss: 0.0021658761288563255, Final Batch Loss: 0.0020610790234059095\n",
      "Epoch 3811, Loss: 0.0003988733369624242, Final Batch Loss: 0.00019516788597684354\n",
      "Epoch 3812, Loss: 0.00030697357487952104, Final Batch Loss: 1.0432278031657916e-05\n",
      "Epoch 3813, Loss: 0.0002977113745146198, Final Batch Loss: 0.00014218866999726743\n",
      "Epoch 3814, Loss: 0.0003148465275444323, Final Batch Loss: 9.324504208052531e-05\n",
      "Epoch 3815, Loss: 0.00035129147181578446, Final Batch Loss: 1.0737285265349783e-05\n",
      "Epoch 3816, Loss: 0.000188184276339598, Final Batch Loss: 2.682518788788002e-05\n",
      "Epoch 3817, Loss: 9.39799456318724e-05, Final Batch Loss: 1.3669444342667703e-05\n",
      "Epoch 3818, Loss: 0.0003303492339910008, Final Batch Loss: 0.00013884002692066133\n",
      "Epoch 3819, Loss: 0.0007385637873085216, Final Batch Loss: 0.00012782771955244243\n",
      "Epoch 3820, Loss: 0.0005155490362085402, Final Batch Loss: 0.00012580773909576237\n",
      "Epoch 3821, Loss: 0.0001039564749589772, Final Batch Loss: 1.3945828868600074e-05\n",
      "Epoch 3822, Loss: 0.0002756659341685008, Final Batch Loss: 0.00013912044232711196\n",
      "Epoch 3823, Loss: 0.00040315696969628334, Final Batch Loss: 2.2605534468311816e-05\n",
      "Epoch 3824, Loss: 0.0003425355098443106, Final Batch Loss: 2.3801650968380272e-05\n",
      "Epoch 3825, Loss: 0.00012480113218771294, Final Batch Loss: 2.1980920791975223e-05\n",
      "Epoch 3826, Loss: 0.00042517168185440823, Final Batch Loss: 0.0003045876801479608\n",
      "Epoch 3827, Loss: 8.543158674001461e-05, Final Batch Loss: 1.0462611498951446e-05\n",
      "Epoch 3828, Loss: 0.00039450094300264027, Final Batch Loss: 7.297288539120927e-05\n",
      "Epoch 3829, Loss: 0.00015768876085076045, Final Batch Loss: 1.3074405842417036e-06\n",
      "Epoch 3830, Loss: 0.000826970353955403, Final Batch Loss: 0.0004446017846930772\n",
      "Epoch 3831, Loss: 0.00018509675282984972, Final Batch Loss: 2.618339567561634e-05\n",
      "Epoch 3832, Loss: 0.0005405212923506042, Final Batch Loss: 2.880707870644983e-05\n",
      "Epoch 3833, Loss: 0.00028703046882583294, Final Batch Loss: 1.8894041204475798e-05\n",
      "Epoch 3834, Loss: 0.00025917715538525954, Final Batch Loss: 0.00016570158186368644\n",
      "Epoch 3835, Loss: 0.008935464764363132, Final Batch Loss: 7.369989180006087e-05\n",
      "Epoch 3836, Loss: 0.0004257802211213857, Final Batch Loss: 1.7681741155683994e-05\n",
      "Epoch 3837, Loss: 0.001705642840533983, Final Batch Loss: 3.556400042725727e-05\n",
      "Epoch 3838, Loss: 0.00039643259606236825, Final Batch Loss: 8.024735143408179e-05\n",
      "Epoch 3839, Loss: 0.0006885515249450691, Final Batch Loss: 4.592153709381819e-05\n",
      "Epoch 3840, Loss: 0.00027426784799899906, Final Batch Loss: 1.89433922059834e-05\n",
      "Epoch 3841, Loss: 0.0014804901693423744, Final Batch Loss: 0.001105196075513959\n",
      "Epoch 3842, Loss: 0.002130376895365771, Final Batch Loss: 0.0014453463954851031\n",
      "Epoch 3843, Loss: 0.000375807547243312, Final Batch Loss: 6.229000427993014e-05\n",
      "Epoch 3844, Loss: 0.0017365097446599975, Final Batch Loss: 0.0015480107394978404\n",
      "Epoch 3845, Loss: 0.0009278919769712957, Final Batch Loss: 6.517264409922063e-05\n",
      "Epoch 3846, Loss: 0.0005164837421034463, Final Batch Loss: 3.308123996248469e-05\n",
      "Epoch 3847, Loss: 0.0003224910469725728, Final Batch Loss: 4.801150498678908e-05\n",
      "Epoch 3848, Loss: 0.00019539932145562489, Final Batch Loss: 8.251363396993838e-06\n",
      "Epoch 3849, Loss: 0.00030957696435507387, Final Batch Loss: 7.418141467496753e-05\n",
      "Epoch 3850, Loss: 6.671058054052992e-05, Final Batch Loss: 3.244759500375949e-05\n",
      "Epoch 3851, Loss: 0.00029542770516854944, Final Batch Loss: 7.701676076976582e-05\n",
      "Epoch 3852, Loss: 0.00028869875177406357, Final Batch Loss: 3.815372565441066e-06\n",
      "Epoch 3853, Loss: 0.00024532389352316386, Final Batch Loss: 4.303730293031549e-06\n",
      "Epoch 3854, Loss: 0.0012073887446604203, Final Batch Loss: 0.0007588259177282453\n",
      "Epoch 3855, Loss: 0.0003309057783553726, Final Batch Loss: 0.00022955193708185107\n",
      "Epoch 3856, Loss: 0.0002340434893994825, Final Batch Loss: 7.553493560408242e-06\n",
      "Epoch 3857, Loss: 0.0001739777344482718, Final Batch Loss: 5.3679552365792915e-05\n",
      "Epoch 3858, Loss: 0.00032583372376393527, Final Batch Loss: 0.00012695598707068712\n",
      "Epoch 3859, Loss: 0.0011658479415928014, Final Batch Loss: 0.0010636303341016173\n",
      "Epoch 3860, Loss: 0.00011586894834181294, Final Batch Loss: 1.0769737855298445e-05\n",
      "Epoch 3861, Loss: 0.00016998919727484463, Final Batch Loss: 7.993282451934647e-06\n",
      "Epoch 3862, Loss: 0.001143634752224898, Final Batch Loss: 0.0006222923402674496\n",
      "Epoch 3863, Loss: 0.0011642435565590858, Final Batch Loss: 0.0001382415066473186\n",
      "Epoch 3864, Loss: 0.00019954878189309966, Final Batch Loss: 0.00014829818974249065\n",
      "Epoch 3865, Loss: 0.00013658421903528506, Final Batch Loss: 2.9272368919919245e-06\n",
      "Epoch 3866, Loss: 7.165726674429607e-05, Final Batch Loss: 2.405474879196845e-05\n",
      "Epoch 3867, Loss: 0.0029049427527070293, Final Batch Loss: 1.5938845763230347e-06\n",
      "Epoch 3868, Loss: 0.0002875322643376421, Final Batch Loss: 0.00019916926976293325\n",
      "Epoch 3869, Loss: 0.00024069997652986785, Final Batch Loss: 0.00022542737133335322\n",
      "Epoch 3870, Loss: 0.0002303698111063568, Final Batch Loss: 9.966399375116453e-05\n",
      "Epoch 3871, Loss: 0.0009035787516040727, Final Batch Loss: 0.00024143797054421157\n",
      "Epoch 3872, Loss: 0.0002681193618627731, Final Batch Loss: 2.5590485165594146e-05\n",
      "Epoch 3873, Loss: 0.0004034980524920684, Final Batch Loss: 0.00027483596932142973\n",
      "Epoch 3874, Loss: 0.0002823217480454332, Final Batch Loss: 2.5062151962629287e-06\n",
      "Epoch 3875, Loss: 5.8390462982060853e-05, Final Batch Loss: 5.733652869821526e-06\n",
      "Epoch 3876, Loss: 6.541197490150807e-05, Final Batch Loss: 2.7756959752878174e-05\n",
      "Epoch 3877, Loss: 0.0007190568776422879, Final Batch Loss: 1.8791970433085226e-05\n",
      "Epoch 3878, Loss: 0.00010533401746215532, Final Batch Loss: 7.1902695708558895e-06\n",
      "Epoch 3879, Loss: 0.00020950171710865106, Final Batch Loss: 0.00015330534370150417\n",
      "Epoch 3880, Loss: 7.210546573332977e-05, Final Batch Loss: 1.897852234833408e-05\n",
      "Epoch 3881, Loss: 0.0001389209655826562, Final Batch Loss: 7.793830263835844e-06\n",
      "Epoch 3882, Loss: 0.002117270046255726, Final Batch Loss: 1.2511548447946552e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3883, Loss: 0.0002782487208605744, Final Batch Loss: 9.040857548825443e-05\n",
      "Epoch 3884, Loss: 0.0001106092681766313, Final Batch Loss: 3.756751993932994e-06\n",
      "Epoch 3885, Loss: 0.00695857572281966, Final Batch Loss: 0.0067146578803658485\n",
      "Epoch 3886, Loss: 5.49161698017997e-05, Final Batch Loss: 2.1831740468769567e-06\n",
      "Epoch 3887, Loss: 7.936268866615137e-05, Final Batch Loss: 2.715059781621676e-05\n",
      "Epoch 3888, Loss: 2.399657569185365e-05, Final Batch Loss: 9.268742360291071e-06\n",
      "Epoch 3889, Loss: 0.00042009236494777724, Final Batch Loss: 2.6022935344371945e-05\n",
      "Epoch 3890, Loss: 0.00016306081670336425, Final Batch Loss: 1.8083126633428037e-05\n",
      "Epoch 3891, Loss: 9.364239986098255e-05, Final Batch Loss: 2.4052565095189493e-06\n",
      "Epoch 3892, Loss: 0.000593295333601418, Final Batch Loss: 1.4017020475876052e-05\n",
      "Epoch 3893, Loss: 0.004249190053087659, Final Batch Loss: 0.00011491412442410365\n",
      "Epoch 3894, Loss: 0.001662028800637927, Final Batch Loss: 4.9213987949769944e-05\n",
      "Epoch 3895, Loss: 0.00012999464524909854, Final Batch Loss: 0.000108632943010889\n",
      "Epoch 3896, Loss: 0.00011086315089414711, Final Batch Loss: 3.2997744710883126e-05\n",
      "Epoch 3897, Loss: 4.0459909996570786e-05, Final Batch Loss: 1.622792478883639e-05\n",
      "Epoch 3898, Loss: 0.01154543025586463, Final Batch Loss: 0.00010637213563313708\n",
      "Epoch 3899, Loss: 0.00036185537828714587, Final Batch Loss: 0.00013242130808066577\n",
      "Epoch 3900, Loss: 0.00018953478684125002, Final Batch Loss: 1.2958080333191901e-05\n",
      "Epoch 3901, Loss: 0.0002160543141371818, Final Batch Loss: 1.5871761434027576e-06\n",
      "Epoch 3902, Loss: 7.977965515237884e-05, Final Batch Loss: 2.976478026539553e-05\n",
      "Epoch 3903, Loss: 0.0028177004296594532, Final Batch Loss: 5.234781201579608e-05\n",
      "Epoch 3904, Loss: 0.0003866659913001058, Final Batch Loss: 4.47751654064632e-06\n",
      "Epoch 3905, Loss: 0.0006217580958036706, Final Batch Loss: 0.00030366310966201127\n",
      "Epoch 3906, Loss: 0.0006934838338565896, Final Batch Loss: 0.0005660708411596715\n",
      "Epoch 3907, Loss: 0.001138250295070975, Final Batch Loss: 6.540989033965161e-06\n",
      "Epoch 3908, Loss: 0.000410241126701294, Final Batch Loss: 0.0001768010261002928\n",
      "Epoch 3909, Loss: 0.0011931106346310116, Final Batch Loss: 0.0009952274849638343\n",
      "Epoch 3910, Loss: 0.0003876113059959607, Final Batch Loss: 6.76767886034213e-05\n",
      "Epoch 3911, Loss: 0.00016792902169981971, Final Batch Loss: 9.216195758199319e-05\n",
      "Epoch 3912, Loss: 0.0001825678064051317, Final Batch Loss: 1.3663202480529435e-05\n",
      "Epoch 3913, Loss: 0.00028183430003991816, Final Batch Loss: 2.3925664208945818e-05\n",
      "Epoch 3914, Loss: 0.0007170279022830073, Final Batch Loss: 0.0003219566715415567\n",
      "Epoch 3915, Loss: 0.0044854189745819895, Final Batch Loss: 6.530525752168614e-06\n",
      "Epoch 3916, Loss: 0.00025805524273891933, Final Batch Loss: 4.029525371151976e-05\n",
      "Epoch 3917, Loss: 0.00019405951024964452, Final Batch Loss: 0.00017795711755752563\n",
      "Epoch 3918, Loss: 0.0002909232807724038, Final Batch Loss: 0.000219015491893515\n",
      "Epoch 3919, Loss: 0.00010017078147939174, Final Batch Loss: 6.625153764616698e-05\n",
      "Epoch 3920, Loss: 0.00013095912618155126, Final Batch Loss: 2.4532400857424363e-06\n",
      "Epoch 3921, Loss: 0.00014244610611058306, Final Batch Loss: 6.253102583286818e-06\n",
      "Epoch 3922, Loss: 0.0017062860738406016, Final Batch Loss: 0.001364771742373705\n",
      "Epoch 3923, Loss: 0.0005576136031777423, Final Batch Loss: 1.0488297448318917e-06\n",
      "Epoch 3924, Loss: 0.0006096229626564309, Final Batch Loss: 3.271405876148492e-05\n",
      "Epoch 3925, Loss: 0.00014734784767256315, Final Batch Loss: 4.105007462840149e-07\n",
      "Epoch 3926, Loss: 7.070282663335092e-05, Final Batch Loss: 1.4370394637808204e-05\n",
      "Epoch 3927, Loss: 0.0006603180409001652, Final Batch Loss: 0.00012195316230645403\n",
      "Epoch 3928, Loss: 8.943160173657816e-05, Final Batch Loss: 5.090477498015389e-05\n",
      "Epoch 3929, Loss: 0.00011761598398152273, Final Batch Loss: 2.672528898983728e-05\n",
      "Epoch 3930, Loss: 0.00022428420879805344, Final Batch Loss: 6.14224654782447e-06\n",
      "Epoch 3931, Loss: 6.60097784930258e-05, Final Batch Loss: 1.025793517328566e-05\n",
      "Epoch 3932, Loss: 7.735943199804751e-05, Final Batch Loss: 3.3174628697452135e-06\n",
      "Epoch 3933, Loss: 0.0008758967533140094, Final Batch Loss: 0.0004126666462980211\n",
      "Epoch 3934, Loss: 5.4924148116697324e-05, Final Batch Loss: 1.4237048162613064e-06\n",
      "Epoch 3935, Loss: 0.00042298691460018745, Final Batch Loss: 0.0002839963708538562\n",
      "Epoch 3936, Loss: 0.0008320824961174367, Final Batch Loss: 7.587108029838419e-06\n",
      "Epoch 3937, Loss: 4.308712277634186e-05, Final Batch Loss: 1.0491989996808115e-05\n",
      "Epoch 3938, Loss: 3.488832680886844e-05, Final Batch Loss: 2.7569062694965396e-06\n",
      "Epoch 3939, Loss: 3.839747478195932e-05, Final Batch Loss: 9.414624400960747e-06\n",
      "Epoch 3940, Loss: 7.498702598240925e-05, Final Batch Loss: 1.8718747014645487e-05\n",
      "Epoch 3941, Loss: 0.0038670787362207193, Final Batch Loss: 5.5556254665134475e-05\n",
      "Epoch 3942, Loss: 8.86465440999018e-05, Final Batch Loss: 3.909448059857823e-05\n",
      "Epoch 3943, Loss: 0.0002866533077394706, Final Batch Loss: 6.65089683025144e-05\n",
      "Epoch 3944, Loss: 0.014895924159645801, Final Batch Loss: 0.012464449740946293\n",
      "Epoch 3945, Loss: 0.0007527270390710328, Final Batch Loss: 7.976783308549784e-06\n",
      "Epoch 3946, Loss: 0.0001668587378844677, Final Batch Loss: 4.721713139588246e-06\n",
      "Epoch 3947, Loss: 0.014963131418880948, Final Batch Loss: 0.014899828471243382\n",
      "Epoch 3948, Loss: 0.00215966254563682, Final Batch Loss: 8.211237582145259e-05\n",
      "Epoch 3949, Loss: 0.016943784055001743, Final Batch Loss: 8.827068086247891e-05\n",
      "Epoch 3950, Loss: 0.0014611527440138161, Final Batch Loss: 0.0003657136403489858\n",
      "Epoch 3951, Loss: 0.06316412059823051, Final Batch Loss: 0.0031617910135537386\n",
      "Epoch 3952, Loss: 0.0006366899015119998, Final Batch Loss: 2.398596188868396e-05\n",
      "Epoch 3953, Loss: 0.0012002530620520702, Final Batch Loss: 0.001057784422300756\n",
      "Epoch 3954, Loss: 0.014244598014329313, Final Batch Loss: 2.506157898096717e-06\n",
      "Epoch 3955, Loss: 0.007636417813046137, Final Batch Loss: 0.007501430343836546\n",
      "Epoch 3956, Loss: 0.010008881963585736, Final Batch Loss: 0.009765684604644775\n",
      "Epoch 3957, Loss: 0.00323205054655773, Final Batch Loss: 5.657120254909387e-06\n",
      "Epoch 3958, Loss: 0.006825353077147156, Final Batch Loss: 0.0003117017913609743\n",
      "Epoch 3959, Loss: 0.0006740590033587068, Final Batch Loss: 0.000268725270871073\n",
      "Epoch 3960, Loss: 0.002933175074758765, Final Batch Loss: 8.294166946143378e-06\n",
      "Epoch 3961, Loss: 0.0014486525396932848, Final Batch Loss: 9.439737914362922e-05\n",
      "Epoch 3962, Loss: 0.0005844044444529573, Final Batch Loss: 3.520565587677993e-05\n",
      "Epoch 3963, Loss: 0.00035339355235919356, Final Batch Loss: 0.00014413158351089805\n",
      "Epoch 3964, Loss: 0.00025540977094351547, Final Batch Loss: 1.8717519196798094e-06\n",
      "Epoch 3965, Loss: 0.0020724866262753494, Final Batch Loss: 0.0019914337899535894\n",
      "Epoch 3966, Loss: 0.002495963424735237, Final Batch Loss: 9.31954855332151e-06\n",
      "Epoch 3967, Loss: 0.0004883474139205646, Final Batch Loss: 0.00031439910526387393\n",
      "Epoch 3968, Loss: 0.00011909638851648197, Final Batch Loss: 3.269909575465135e-05\n",
      "Epoch 3969, Loss: 8.085716035566293e-05, Final Batch Loss: 1.1835532859549858e-05\n",
      "Epoch 3970, Loss: 0.005309936284902506, Final Batch Loss: 5.3415038564708084e-05\n",
      "Epoch 3971, Loss: 0.00014624898176407441, Final Batch Loss: 2.7626574592432007e-05\n",
      "Epoch 3972, Loss: 0.00017381245561409742, Final Batch Loss: 9.103445336222649e-06\n",
      "Epoch 3973, Loss: 0.002194721617797768, Final Batch Loss: 0.00214473158121109\n",
      "Epoch 3974, Loss: 0.0002155806669179583, Final Batch Loss: 1.2893275197711773e-05\n",
      "Epoch 3975, Loss: 4.38618353655329e-05, Final Batch Loss: 1.21589946502354e-05\n",
      "Epoch 3976, Loss: 0.0001727472263155505, Final Batch Loss: 7.687840843573213e-05\n",
      "Epoch 3977, Loss: 0.0009372047461511102, Final Batch Loss: 9.128425881499425e-05\n",
      "Epoch 3978, Loss: 0.00024232765827036928, Final Batch Loss: 1.4577677575289272e-05\n",
      "Epoch 3979, Loss: 0.0002125467999576358, Final Batch Loss: 8.424914994975552e-05\n",
      "Epoch 3980, Loss: 7.745927177893464e-05, Final Batch Loss: 2.5885981813189574e-05\n",
      "Epoch 3981, Loss: 0.0004216841953166295, Final Batch Loss: 0.00030668446561321616\n",
      "Epoch 3982, Loss: 0.00014057604130357504, Final Batch Loss: 3.765971268876456e-05\n",
      "Epoch 3983, Loss: 0.0008323047150042839, Final Batch Loss: 7.829463720554486e-05\n",
      "Epoch 3984, Loss: 0.00024715661311347503, Final Batch Loss: 2.9689394068554975e-05\n",
      "Epoch 3985, Loss: 9.292913364333799e-05, Final Batch Loss: 1.3787827811029274e-05\n",
      "Epoch 3986, Loss: 3.261643178120721e-05, Final Batch Loss: 1.8766919311019592e-05\n",
      "Epoch 3987, Loss: 0.00040117742491929675, Final Batch Loss: 6.006029707350535e-06\n",
      "Epoch 3988, Loss: 0.00015053113384055905, Final Batch Loss: 1.778826117515564e-05\n",
      "Epoch 3989, Loss: 0.00011051688488805667, Final Batch Loss: 2.0088864403078333e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3990, Loss: 0.010077798320708098, Final Batch Loss: 4.7595909563824534e-05\n",
      "Epoch 3991, Loss: 0.0001609595810805331, Final Batch Loss: 8.143068953359034e-06\n",
      "Epoch 3992, Loss: 0.0005870742788829375, Final Batch Loss: 0.00024109246442094445\n",
      "Epoch 3993, Loss: 0.003654076563179842, Final Batch Loss: 1.6800540834083222e-05\n",
      "Epoch 3994, Loss: 0.0005102609811729053, Final Batch Loss: 2.129645690729376e-05\n",
      "Epoch 3995, Loss: 0.0012417231882864144, Final Batch Loss: 3.5989938623970374e-05\n",
      "Epoch 3996, Loss: 7.468665080523351e-05, Final Batch Loss: 2.246134499728214e-05\n",
      "Epoch 3997, Loss: 0.00018762736544886138, Final Batch Loss: 1.0644491339917295e-05\n",
      "Epoch 3998, Loss: 0.007493305657590099, Final Batch Loss: 1.504881674918579e-05\n",
      "Epoch 3999, Loss: 0.0003022728124051355, Final Batch Loss: 0.0001250932109542191\n",
      "Epoch 4000, Loss: 0.00031027840850583743, Final Batch Loss: 0.0002685842046048492\n",
      "Epoch 4001, Loss: 0.0002704793405428063, Final Batch Loss: 5.1727383834077045e-05\n",
      "Epoch 4002, Loss: 0.00041166845767293125, Final Batch Loss: 8.086013986030594e-05\n",
      "Epoch 4003, Loss: 0.006686721222649794, Final Batch Loss: 0.0024848124012351036\n",
      "Epoch 4004, Loss: 0.00010872989059862448, Final Batch Loss: 5.553833761950955e-05\n",
      "Epoch 4005, Loss: 0.0009287023985962151, Final Batch Loss: 0.00027440665871836245\n",
      "Epoch 4006, Loss: 0.004176084041318973, Final Batch Loss: 2.9273682230268605e-05\n",
      "Epoch 4007, Loss: 0.0003572582209017128, Final Batch Loss: 7.851904956623912e-05\n",
      "Epoch 4008, Loss: 0.0009329402164439671, Final Batch Loss: 0.00011054594506276771\n",
      "Epoch 4009, Loss: 8.437253291049274e-05, Final Batch Loss: 1.5076876479724888e-05\n",
      "Epoch 4010, Loss: 0.0006773538298148196, Final Batch Loss: 0.00018759262457024306\n",
      "Epoch 4011, Loss: 0.0031337261225417024, Final Batch Loss: 0.0005648323567584157\n",
      "Epoch 4012, Loss: 0.0010065470110021124, Final Batch Loss: 3.891326286975527e-06\n",
      "Epoch 4013, Loss: 0.00016602021059952676, Final Batch Loss: 6.092446346883662e-05\n",
      "Epoch 4014, Loss: 0.00014874394037178718, Final Batch Loss: 4.536509368335828e-05\n",
      "Epoch 4015, Loss: 0.00011841384366562124, Final Batch Loss: 6.64753679302521e-05\n",
      "Epoch 4016, Loss: 0.001020591789711034, Final Batch Loss: 0.0009260408696718514\n",
      "Epoch 4017, Loss: 0.0002740417021414032, Final Batch Loss: 1.3701172065339051e-05\n",
      "Epoch 4018, Loss: 0.0002789390407542669, Final Batch Loss: 3.598047214836697e-06\n",
      "Epoch 4019, Loss: 0.0004983418693882413, Final Batch Loss: 8.462314872303978e-05\n",
      "Epoch 4020, Loss: 0.00012920726385345915, Final Batch Loss: 9.407213656231761e-05\n",
      "Epoch 4021, Loss: 5.6650314036232885e-05, Final Batch Loss: 3.097315493505448e-05\n",
      "Epoch 4022, Loss: 0.00048727787634561537, Final Batch Loss: 1.4448593901761342e-05\n",
      "Epoch 4023, Loss: 0.00022638099835603498, Final Batch Loss: 0.00013760932779405266\n",
      "Epoch 4024, Loss: 6.932062751729973e-05, Final Batch Loss: 8.906758921511937e-06\n",
      "Epoch 4025, Loss: 0.0008260340782726416, Final Batch Loss: 8.611140219727531e-05\n",
      "Epoch 4026, Loss: 0.0002962775320156652, Final Batch Loss: 6.472743280028226e-06\n",
      "Epoch 4027, Loss: 0.03871238159081258, Final Batch Loss: 0.03865302354097366\n",
      "Epoch 4028, Loss: 0.006611874322516087, Final Batch Loss: 0.0065818605944514275\n",
      "Epoch 4029, Loss: 0.00045497134215111146, Final Batch Loss: 6.123446837591473e-06\n",
      "Epoch 4030, Loss: 0.0011922923013116815, Final Batch Loss: 7.943137461552396e-05\n",
      "Epoch 4031, Loss: 0.012258951413969044, Final Batch Loss: 4.810289465240203e-05\n",
      "Epoch 4032, Loss: 0.00028938849391124677, Final Batch Loss: 3.554263093974441e-05\n",
      "Epoch 4033, Loss: 0.0003219038180759526, Final Batch Loss: 8.56288806971861e-06\n",
      "Epoch 4034, Loss: 0.0002294266814715229, Final Batch Loss: 9.926716302288696e-05\n",
      "Epoch 4035, Loss: 0.00019618775695562363, Final Batch Loss: 0.00016198278171941638\n",
      "Epoch 4036, Loss: 8.599975899414858e-05, Final Batch Loss: 4.020165761176031e-06\n",
      "Epoch 4037, Loss: 0.05957704574939271, Final Batch Loss: 0.05674722418189049\n",
      "Epoch 4038, Loss: 0.022997034262516536, Final Batch Loss: 0.0001245669845957309\n",
      "Epoch 4039, Loss: 0.0005236948127276264, Final Batch Loss: 0.00011760385677916929\n",
      "Epoch 4040, Loss: 0.0003514671934681246, Final Batch Loss: 0.0001630621263757348\n",
      "Epoch 4041, Loss: 0.0006535428256029263, Final Batch Loss: 0.00025828660000115633\n",
      "Epoch 4042, Loss: 0.0010332004876545398, Final Batch Loss: 8.076125959632918e-05\n",
      "Epoch 4043, Loss: 0.002038608814473264, Final Batch Loss: 7.436487067025155e-05\n",
      "Epoch 4044, Loss: 0.0006854980529169552, Final Batch Loss: 3.344029391882941e-05\n",
      "Epoch 4045, Loss: 0.01613243159954436, Final Batch Loss: 0.00026400972274132073\n",
      "Epoch 4046, Loss: 0.0003699568987940438, Final Batch Loss: 0.00012619313201867044\n",
      "Epoch 4047, Loss: 0.00024073638633126393, Final Batch Loss: 4.724635437014513e-05\n",
      "Epoch 4048, Loss: 0.0009576367156114429, Final Batch Loss: 0.0006466623744927347\n",
      "Epoch 4049, Loss: 0.00046061719694989733, Final Batch Loss: 2.584671528893523e-05\n",
      "Epoch 4050, Loss: 7.367777652689256e-05, Final Batch Loss: 9.52866321313195e-06\n",
      "Epoch 4051, Loss: 0.00020222169769112952, Final Batch Loss: 6.614984158659354e-06\n",
      "Epoch 4052, Loss: 0.0001932134218805004, Final Batch Loss: 3.061091774725355e-05\n",
      "Epoch 4053, Loss: 0.003936675668228418, Final Batch Loss: 0.00015751237515360117\n",
      "Epoch 4054, Loss: 0.0012002894109173212, Final Batch Loss: 7.837199518689886e-06\n",
      "Epoch 4055, Loss: 0.001776293975126464, Final Batch Loss: 0.0001593853230588138\n",
      "Epoch 4056, Loss: 0.0002390448389633093, Final Batch Loss: 0.0001170112009276636\n",
      "Epoch 4057, Loss: 0.00011408485988795292, Final Batch Loss: 2.1254765670164488e-05\n",
      "Epoch 4058, Loss: 0.0002905096953327302, Final Batch Loss: 0.00016189843881875277\n",
      "Epoch 4059, Loss: 0.0019372747337911278, Final Batch Loss: 9.422928269486874e-05\n",
      "Epoch 4060, Loss: 0.0018403114881948568, Final Batch Loss: 5.857728683622554e-05\n",
      "Epoch 4061, Loss: 0.0006274860934354365, Final Batch Loss: 1.728085771901533e-05\n",
      "Epoch 4062, Loss: 0.0006216427282197401, Final Batch Loss: 8.784142119111493e-05\n",
      "Epoch 4063, Loss: 0.0003953051827920717, Final Batch Loss: 0.00035311735700815916\n",
      "Epoch 4064, Loss: 0.0007261627470143139, Final Batch Loss: 8.601686567999423e-05\n",
      "Epoch 4065, Loss: 0.00019795459411398042, Final Batch Loss: 1.917882400448434e-06\n",
      "Epoch 4066, Loss: 0.0004472477285162313, Final Batch Loss: 3.688918150146492e-05\n",
      "Epoch 4067, Loss: 0.00022267168969847262, Final Batch Loss: 0.00011841773812193424\n",
      "Epoch 4068, Loss: 0.00017433607354178093, Final Batch Loss: 5.935065928497352e-05\n",
      "Epoch 4069, Loss: 0.0006395669479388744, Final Batch Loss: 0.0003868283238261938\n",
      "Epoch 4070, Loss: 0.0005669973652402405, Final Batch Loss: 0.00016725876776035875\n",
      "Epoch 4071, Loss: 0.0007841150581953116, Final Batch Loss: 0.0005870829918421805\n",
      "Epoch 4072, Loss: 0.0012461785336199682, Final Batch Loss: 2.5932495191227645e-05\n",
      "Epoch 4073, Loss: 8.682145744387526e-05, Final Batch Loss: 1.7385453247698024e-05\n",
      "Epoch 4074, Loss: 0.000247689854404598, Final Batch Loss: 1.639818583498709e-05\n",
      "Epoch 4075, Loss: 0.011013904550054576, Final Batch Loss: 2.0521089027170092e-05\n",
      "Epoch 4076, Loss: 0.0007866505861215956, Final Batch Loss: 0.0007700020796619356\n",
      "Epoch 4077, Loss: 7.181009777923464e-05, Final Batch Loss: 4.034193989355117e-05\n",
      "Epoch 4078, Loss: 0.0012678769326157635, Final Batch Loss: 0.0012114821001887321\n",
      "Epoch 4079, Loss: 0.00019311620167172805, Final Batch Loss: 1.1940003332711058e-06\n",
      "Epoch 4080, Loss: 0.0005120746100146789, Final Batch Loss: 5.050226900493726e-05\n",
      "Epoch 4081, Loss: 0.0005526004679268226, Final Batch Loss: 0.0002028659509960562\n",
      "Epoch 4082, Loss: 0.00022517603201777092, Final Batch Loss: 5.499563030753052e-06\n",
      "Epoch 4083, Loss: 0.000662286693113856, Final Batch Loss: 0.00012779905227944255\n",
      "Epoch 4084, Loss: 0.0002744806552072987, Final Batch Loss: 4.344327317085117e-05\n",
      "Epoch 4085, Loss: 0.00048355961916968226, Final Batch Loss: 0.00030155447893776\n",
      "Epoch 4086, Loss: 0.00010399311486253282, Final Batch Loss: 4.381729922897648e-06\n",
      "Epoch 4087, Loss: 0.00018043589079752564, Final Batch Loss: 3.4100976336048916e-05\n",
      "Epoch 4088, Loss: 0.00014264737046687515, Final Batch Loss: 4.503740001382539e-06\n",
      "Epoch 4089, Loss: 8.978156347438926e-05, Final Batch Loss: 3.144663787679747e-05\n",
      "Epoch 4090, Loss: 0.00020847115501965163, Final Batch Loss: 3.8972350012045354e-05\n",
      "Epoch 4091, Loss: 0.001367107848636806, Final Batch Loss: 4.7143319534370676e-05\n",
      "Epoch 4092, Loss: 0.0004351023453637026, Final Batch Loss: 8.823480311548337e-05\n",
      "Epoch 4093, Loss: 5.0298946916882414e-05, Final Batch Loss: 4.0237127905129455e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4094, Loss: 0.0005025429327361053, Final Batch Loss: 0.0004132594622205943\n",
      "Epoch 4095, Loss: 7.3608029197203e-05, Final Batch Loss: 1.3873994248569943e-05\n",
      "Epoch 4096, Loss: 0.00011757940455936478, Final Batch Loss: 4.6711847971891984e-05\n",
      "Epoch 4097, Loss: 0.00014906044816598296, Final Batch Loss: 2.937190220109187e-05\n",
      "Epoch 4098, Loss: 0.00018802571867126971, Final Batch Loss: 4.749959407490678e-05\n",
      "Epoch 4099, Loss: 0.0001675204184721224, Final Batch Loss: 4.336949496064335e-05\n",
      "Epoch 4100, Loss: 7.745279390292126e-05, Final Batch Loss: 6.5897361309907865e-06\n",
      "Epoch 4101, Loss: 0.00018473849286237964, Final Batch Loss: 1.2376783161016647e-05\n",
      "Epoch 4102, Loss: 8.395594159082975e-05, Final Batch Loss: 1.1913683920283802e-05\n",
      "Epoch 4103, Loss: 0.0002697517129490734, Final Batch Loss: 1.5509818695136346e-05\n",
      "Epoch 4104, Loss: 0.0001295185702474555, Final Batch Loss: 9.456321276957169e-05\n",
      "Epoch 4105, Loss: 0.00028182413245758653, Final Batch Loss: 1.796752826521697e-06\n",
      "Epoch 4106, Loss: 0.0005364309618016705, Final Batch Loss: 0.0002806124684866518\n",
      "Epoch 4107, Loss: 0.00034457740002835635, Final Batch Loss: 1.4273753549787216e-05\n",
      "Epoch 4108, Loss: 0.0007885270370024955, Final Batch Loss: 3.046759775315877e-05\n",
      "Epoch 4109, Loss: 0.00021177834423724562, Final Batch Loss: 6.207291880855337e-05\n",
      "Epoch 4110, Loss: 0.00010513821735003148, Final Batch Loss: 8.520893607055768e-05\n",
      "Epoch 4111, Loss: 0.00028124477466917597, Final Batch Loss: 5.734367368859239e-05\n",
      "Epoch 4112, Loss: 0.003646322254098777, Final Batch Loss: 1.6632420738460496e-05\n",
      "Epoch 4113, Loss: 0.004598522860760568, Final Batch Loss: 0.00455948943272233\n",
      "Epoch 4114, Loss: 0.0006490411615232006, Final Batch Loss: 0.00018813114729709923\n",
      "Epoch 4115, Loss: 0.0009177652700600447, Final Batch Loss: 7.64954456826672e-05\n",
      "Epoch 4116, Loss: 0.00013668572682945523, Final Batch Loss: 6.988189852563664e-06\n",
      "Epoch 4117, Loss: 0.0001389005947203259, Final Batch Loss: 6.536486034747213e-05\n",
      "Epoch 4118, Loss: 0.0035172710157667098, Final Batch Loss: 1.760214104251645e-06\n",
      "Epoch 4119, Loss: 0.00011017958240699954, Final Batch Loss: 3.967826705775224e-05\n",
      "Epoch 4120, Loss: 9.171254887974101e-05, Final Batch Loss: 3.951189739836991e-07\n",
      "Epoch 4121, Loss: 0.00047206326803461707, Final Batch Loss: 0.0004513268650043756\n",
      "Epoch 4122, Loss: 5.265949357635691e-05, Final Batch Loss: 1.977230749616865e-05\n",
      "Epoch 4123, Loss: 0.00022544945932168048, Final Batch Loss: 1.5637282558600418e-05\n",
      "Epoch 4124, Loss: 0.0001315221320510318, Final Batch Loss: 4.7312801143561956e-06\n",
      "Epoch 4125, Loss: 0.000568637165997643, Final Batch Loss: 0.00028160089277662337\n",
      "Epoch 4126, Loss: 0.0004833398779737763, Final Batch Loss: 2.796424087136984e-05\n",
      "Epoch 4127, Loss: 0.00045826483255950734, Final Batch Loss: 0.0002589877985883504\n",
      "Epoch 4128, Loss: 0.00027162789046997204, Final Batch Loss: 0.00014156007091514766\n",
      "Epoch 4129, Loss: 6.529404072352918e-05, Final Batch Loss: 1.737664751999546e-05\n",
      "Epoch 4130, Loss: 9.067825021702447e-05, Final Batch Loss: 2.0100983419979457e-06\n",
      "Epoch 4131, Loss: 6.964156091271434e-05, Final Batch Loss: 1.135356978920754e-05\n",
      "Epoch 4132, Loss: 8.863513016876823e-05, Final Batch Loss: 1.767901494531543e-06\n",
      "Epoch 4133, Loss: 0.0004277170737623237, Final Batch Loss: 0.00020078882516827434\n",
      "Epoch 4134, Loss: 5.655854533870297e-05, Final Batch Loss: 9.613529527996434e-07\n",
      "Epoch 4135, Loss: 0.01122409234449151, Final Batch Loss: 0.011075726710259914\n",
      "Epoch 4136, Loss: 0.0025656808084022487, Final Batch Loss: 1.2770868124789558e-05\n",
      "Epoch 4137, Loss: 0.0001867454866442131, Final Batch Loss: 0.00011833674216177315\n",
      "Epoch 4138, Loss: 0.0002857322974705312, Final Batch Loss: 4.366209850559244e-06\n",
      "Epoch 4139, Loss: 0.003918396982498962, Final Batch Loss: 5.000778855901444e-06\n",
      "Epoch 4140, Loss: 0.0003853483312923345, Final Batch Loss: 2.1840563931618817e-05\n",
      "Epoch 4141, Loss: 8.850114772940287e-05, Final Batch Loss: 2.3344598957919516e-05\n",
      "Epoch 4142, Loss: 0.0003364212786891585, Final Batch Loss: 1.8265452581545105e-06\n",
      "Epoch 4143, Loss: 0.00017862128515844233, Final Batch Loss: 3.3836149668786675e-05\n",
      "Epoch 4144, Loss: 0.0003324226836411981, Final Batch Loss: 2.480752118572127e-05\n",
      "Epoch 4145, Loss: 7.13909394107759e-05, Final Batch Loss: 1.903325210150797e-05\n",
      "Epoch 4146, Loss: 0.00035663775361172156, Final Batch Loss: 0.00015676469774916768\n",
      "Epoch 4147, Loss: 3.5076907238362764e-05, Final Batch Loss: 1.7582964346729568e-06\n",
      "Epoch 4148, Loss: 3.586492948670639e-05, Final Batch Loss: 1.2307288670854177e-05\n",
      "Epoch 4149, Loss: 7.288451479325886e-05, Final Batch Loss: 5.7024058151000645e-06\n",
      "Epoch 4150, Loss: 9.7537048986851e-05, Final Batch Loss: 4.1076123125094455e-06\n",
      "Epoch 4151, Loss: 0.0002743873410508968, Final Batch Loss: 4.198049282422289e-05\n",
      "Epoch 4152, Loss: 0.0004527354903984815, Final Batch Loss: 0.000395108392694965\n",
      "Epoch 4153, Loss: 0.00018558662486611865, Final Batch Loss: 9.076675632968545e-05\n",
      "Epoch 4154, Loss: 0.0003616236135712825, Final Batch Loss: 0.00011212314711883664\n",
      "Epoch 4155, Loss: 0.0006258473761135974, Final Batch Loss: 3.735541440619272e-06\n",
      "Epoch 4156, Loss: 0.00011594017496463493, Final Batch Loss: 1.1956062735407613e-05\n",
      "Epoch 4157, Loss: 0.0008140998588714865, Final Batch Loss: 0.0007833547424525023\n",
      "Epoch 4158, Loss: 0.0001679119856135003, Final Batch Loss: 8.546404615117353e-07\n",
      "Epoch 4159, Loss: 0.015977458832821867, Final Batch Loss: 1.0275086424371693e-05\n",
      "Epoch 4160, Loss: 0.00029430315225909, Final Batch Loss: 3.4602275263750926e-05\n",
      "Epoch 4161, Loss: 0.00017913618648890406, Final Batch Loss: 0.00012307291035540402\n",
      "Epoch 4162, Loss: 0.00012671196373048588, Final Batch Loss: 7.372812888206681e-06\n",
      "Epoch 4163, Loss: 0.01892160062197945, Final Batch Loss: 4.9650363507680595e-05\n",
      "Epoch 4164, Loss: 0.0001912417010316858, Final Batch Loss: 2.3922419131849892e-05\n",
      "Epoch 4165, Loss: 0.0007660328592464793, Final Batch Loss: 4.635308505385183e-05\n",
      "Epoch 4166, Loss: 0.00014799509881413542, Final Batch Loss: 1.5303477994166315e-05\n",
      "Epoch 4167, Loss: 0.0007280099289346253, Final Batch Loss: 0.00046679977094754577\n",
      "Epoch 4168, Loss: 0.00016749626774981152, Final Batch Loss: 3.3103995519923046e-05\n",
      "Epoch 4169, Loss: 0.0002474195098329801, Final Batch Loss: 0.00012586091179400682\n",
      "Epoch 4170, Loss: 0.00038017463202777435, Final Batch Loss: 5.874386715731816e-06\n",
      "Epoch 4171, Loss: 0.0002614164253600393, Final Batch Loss: 1.1901423704330227e-06\n",
      "Epoch 4172, Loss: 0.0026077088004967663, Final Batch Loss: 0.002442969474941492\n",
      "Epoch 4173, Loss: 9.245901765098097e-05, Final Batch Loss: 1.3363982361624949e-05\n",
      "Epoch 4174, Loss: 0.0003062677242269274, Final Batch Loss: 0.00011986213939962909\n",
      "Epoch 4175, Loss: 0.0002485127952240873, Final Batch Loss: 4.839653774979524e-05\n",
      "Epoch 4176, Loss: 0.00036095229461352574, Final Batch Loss: 1.1831679330498446e-05\n",
      "Epoch 4177, Loss: 0.0002831963220160105, Final Batch Loss: 4.642049680114724e-05\n",
      "Epoch 4178, Loss: 0.0002494670875421434, Final Batch Loss: 4.023109340778319e-06\n",
      "Epoch 4179, Loss: 0.00012655331556743477, Final Batch Loss: 3.601576463552192e-05\n",
      "Epoch 4180, Loss: 0.00027164464103179853, Final Batch Loss: 7.931170671326981e-07\n",
      "Epoch 4181, Loss: 0.00015987766710168216, Final Batch Loss: 4.040426210849546e-05\n",
      "Epoch 4182, Loss: 0.00011485555842227768, Final Batch Loss: 1.5298783182515763e-05\n",
      "Epoch 4183, Loss: 0.00021383282705755846, Final Batch Loss: 3.041604713871493e-06\n",
      "Epoch 4184, Loss: 0.0002860178751689091, Final Batch Loss: 5.070985480415402e-06\n",
      "Epoch 4185, Loss: 0.000690857366862474, Final Batch Loss: 8.033186531974934e-06\n",
      "Epoch 4186, Loss: 0.0008848380275594536, Final Batch Loss: 3.516071228659712e-05\n",
      "Epoch 4187, Loss: 0.00017531654884805903, Final Batch Loss: 2.5916750018950552e-05\n",
      "Epoch 4188, Loss: 0.0003075503700529225, Final Batch Loss: 0.00013720622519031167\n",
      "Epoch 4189, Loss: 0.0002685430954443291, Final Batch Loss: 6.89463340677321e-05\n",
      "Epoch 4190, Loss: 5.1864182751160115e-05, Final Batch Loss: 1.8596314475871623e-05\n",
      "Epoch 4191, Loss: 0.00043074872337456327, Final Batch Loss: 0.0003833681112155318\n",
      "Epoch 4192, Loss: 0.0004443277698555903, Final Batch Loss: 0.00013683023280464113\n",
      "Epoch 4193, Loss: 7.945641209516907e-05, Final Batch Loss: 2.5176321287290193e-05\n",
      "Epoch 4194, Loss: 0.00016996931935864268, Final Batch Loss: 1.2071733181073796e-05\n",
      "Epoch 4195, Loss: 0.00023726692597847432, Final Batch Loss: 0.00012180623161839321\n",
      "Epoch 4196, Loss: 9.23596662687487e-05, Final Batch Loss: 5.1397828428889625e-06\n",
      "Epoch 4197, Loss: 0.00014627111841036822, Final Batch Loss: 5.683057224814547e-06\n",
      "Epoch 4198, Loss: 0.00021207604004302993, Final Batch Loss: 8.208990038838238e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4199, Loss: 0.00020869133913947735, Final Batch Loss: 0.00015650314162485301\n",
      "Epoch 4200, Loss: 0.0007630998543390888, Final Batch Loss: 1.5230219105433207e-05\n",
      "Epoch 4201, Loss: 0.0009947775179171003, Final Batch Loss: 0.00011226596689084545\n",
      "Epoch 4202, Loss: 0.00043288608139846474, Final Batch Loss: 3.248748544137925e-05\n",
      "Epoch 4203, Loss: 0.00014308961317510693, Final Batch Loss: 4.4211242311575916e-06\n",
      "Epoch 4204, Loss: 0.000427715880505275, Final Batch Loss: 7.263667794177309e-05\n",
      "Epoch 4205, Loss: 0.0001180220497190021, Final Batch Loss: 4.446532329893671e-05\n",
      "Epoch 4206, Loss: 7.702446055191103e-05, Final Batch Loss: 8.494687790516764e-06\n",
      "Epoch 4207, Loss: 7.78820844971051e-05, Final Batch Loss: 5.785717348771868e-06\n",
      "Epoch 4208, Loss: 5.07627069055161e-05, Final Batch Loss: 4.3142867980350275e-06\n",
      "Epoch 4209, Loss: 8.004460687516257e-05, Final Batch Loss: 1.0176891919400077e-05\n",
      "Epoch 4210, Loss: 8.320673441630788e-05, Final Batch Loss: 5.916659938520752e-05\n",
      "Epoch 4211, Loss: 0.0003892469251240982, Final Batch Loss: 2.6167547275690595e-06\n",
      "Epoch 4212, Loss: 0.00013180576388549525, Final Batch Loss: 1.150449134001974e-05\n",
      "Epoch 4213, Loss: 0.0003882797282130923, Final Batch Loss: 0.00019000450265593827\n",
      "Epoch 4214, Loss: 0.00012361593962850748, Final Batch Loss: 6.697117896692362e-06\n",
      "Epoch 4215, Loss: 0.00018443577391735744, Final Batch Loss: 0.00011086430458817631\n",
      "Epoch 4216, Loss: 0.0004260770274413517, Final Batch Loss: 0.000338047684635967\n",
      "Epoch 4217, Loss: 7.803333664924139e-05, Final Batch Loss: 5.554308700084221e-06\n",
      "Epoch 4218, Loss: 7.405485439448967e-05, Final Batch Loss: 1.5621849343006033e-06\n",
      "Epoch 4219, Loss: 5.232274088484701e-05, Final Batch Loss: 5.670650352840312e-06\n",
      "Epoch 4220, Loss: 0.00010181538345932495, Final Batch Loss: 6.440297147491947e-05\n",
      "Epoch 4221, Loss: 6.894927719258703e-05, Final Batch Loss: 1.1085970072599594e-05\n",
      "Epoch 4222, Loss: 0.000300539118143206, Final Batch Loss: 0.0002540855493862182\n",
      "Epoch 4223, Loss: 0.000550066997675458, Final Batch Loss: 0.00013715865497943014\n",
      "Epoch 4224, Loss: 3.491345569273108e-05, Final Batch Loss: 6.913877314218553e-06\n",
      "Epoch 4225, Loss: 0.0002658238207686736, Final Batch Loss: 1.1959181165366317e-06\n",
      "Epoch 4226, Loss: 0.00028652789205807494, Final Batch Loss: 0.00018254108726978302\n",
      "Epoch 4227, Loss: 0.00013638812242788845, Final Batch Loss: 9.486797353019938e-05\n",
      "Epoch 4228, Loss: 0.0001486657693021698, Final Batch Loss: 1.3336100892047398e-05\n",
      "Epoch 4229, Loss: 0.0005752040988227236, Final Batch Loss: 1.2550302017189097e-05\n",
      "Epoch 4230, Loss: 0.0007178603145803208, Final Batch Loss: 0.0006740287644788623\n",
      "Epoch 4231, Loss: 0.0002264856593683362, Final Batch Loss: 3.180960629833862e-05\n",
      "Epoch 4232, Loss: 0.0001252616359579406, Final Batch Loss: 2.2417800664698007e-06\n",
      "Epoch 4233, Loss: 6.736724208167288e-05, Final Batch Loss: 6.087608198868111e-06\n",
      "Epoch 4234, Loss: 0.0055721629250911064, Final Batch Loss: 2.57493866229197e-05\n",
      "Epoch 4235, Loss: 4.441503506313893e-05, Final Batch Loss: 1.1258409358561039e-05\n",
      "Epoch 4236, Loss: 0.0007068133345455863, Final Batch Loss: 8.837185305310413e-06\n",
      "Epoch 4237, Loss: 0.00013006320295971818, Final Batch Loss: 3.2007155823521316e-05\n",
      "Epoch 4238, Loss: 0.00010436604415531292, Final Batch Loss: 3.1148019274951366e-07\n",
      "Epoch 4239, Loss: 0.00026856227304961067, Final Batch Loss: 4.719830758403987e-05\n",
      "Epoch 4240, Loss: 0.000987694897048641, Final Batch Loss: 0.00010433828720124438\n",
      "Epoch 4241, Loss: 0.00015028285497464822, Final Batch Loss: 4.271829766366864e-06\n",
      "Epoch 4242, Loss: 0.0002067226560029667, Final Batch Loss: 3.836887844954617e-05\n",
      "Epoch 4243, Loss: 0.0006827620231888432, Final Batch Loss: 1.1074494068452623e-06\n",
      "Epoch 4244, Loss: 0.0006645616194873583, Final Batch Loss: 3.9487495087087154e-06\n",
      "Epoch 4245, Loss: 4.749239190005028e-05, Final Batch Loss: 6.018082103764755e-07\n",
      "Epoch 4246, Loss: 0.00039067543048076914, Final Batch Loss: 6.356053290801356e-06\n",
      "Epoch 4247, Loss: 0.00010493040736037074, Final Batch Loss: 3.2049783840193413e-06\n",
      "Epoch 4248, Loss: 0.00021576624931185506, Final Batch Loss: 4.9582788051338866e-05\n",
      "Epoch 4249, Loss: 3.896892212651437e-05, Final Batch Loss: 7.19721583664068e-06\n",
      "Epoch 4250, Loss: 4.6636951083200984e-05, Final Batch Loss: 2.866162139980588e-05\n",
      "Epoch 4251, Loss: 0.00027704297849595605, Final Batch Loss: 2.619094811961986e-05\n",
      "Epoch 4252, Loss: 0.00021895832082918787, Final Batch Loss: 2.0658442281273892e-06\n",
      "Epoch 4253, Loss: 7.639035175088793e-05, Final Batch Loss: 1.8524347979109734e-05\n",
      "Epoch 4254, Loss: 0.0007123633295123, Final Batch Loss: 1.1513346180436201e-05\n",
      "Epoch 4255, Loss: 0.000335975822963519, Final Batch Loss: 0.0001338863221462816\n",
      "Epoch 4256, Loss: 0.0007024138540145941, Final Batch Loss: 1.0416953955427743e-05\n",
      "Epoch 4257, Loss: 0.0002932400589088502, Final Batch Loss: 4.6634581849502865e-06\n",
      "Epoch 4258, Loss: 0.00013776538253296167, Final Batch Loss: 5.383122697821818e-05\n",
      "Epoch 4259, Loss: 0.00010184877760366362, Final Batch Loss: 3.229093863410526e-06\n",
      "Epoch 4260, Loss: 0.0002889504221457173, Final Batch Loss: 1.3047193533566315e-05\n",
      "Epoch 4261, Loss: 0.00010536835907259956, Final Batch Loss: 1.4989123883424327e-05\n",
      "Epoch 4262, Loss: 6.768066759832436e-05, Final Batch Loss: 3.7187965062912554e-05\n",
      "Epoch 4263, Loss: 0.00026489843003218994, Final Batch Loss: 0.00011032471957150847\n",
      "Epoch 4264, Loss: 5.308019626681926e-05, Final Batch Loss: 4.688989974965807e-06\n",
      "Epoch 4265, Loss: 0.0004207577994748135, Final Batch Loss: 1.2534471352410037e-05\n",
      "Epoch 4266, Loss: 0.0038953317398409126, Final Batch Loss: 8.108687325147912e-06\n",
      "Epoch 4267, Loss: 0.00011178004206158221, Final Batch Loss: 1.7496131476946175e-06\n",
      "Epoch 4268, Loss: 0.0006150863264338113, Final Batch Loss: 4.359085869509727e-05\n",
      "Epoch 4269, Loss: 0.0008984946498458157, Final Batch Loss: 0.00022071172134019434\n",
      "Epoch 4270, Loss: 0.0032301367455147556, Final Batch Loss: 0.0029522108379751444\n",
      "Epoch 4271, Loss: 5.884683241674793e-05, Final Batch Loss: 3.5379111068323255e-05\n",
      "Epoch 4272, Loss: 0.0002003735316975508, Final Batch Loss: 8.66425943968352e-06\n",
      "Epoch 4273, Loss: 5.75275862502167e-05, Final Batch Loss: 2.693924034247175e-05\n",
      "Epoch 4274, Loss: 8.198246177926194e-05, Final Batch Loss: 3.188832852174528e-05\n",
      "Epoch 4275, Loss: 0.0012292504634388024, Final Batch Loss: 4.502589945332147e-06\n",
      "Epoch 4276, Loss: 0.0001682882816567144, Final Batch Loss: 4.770026498590596e-05\n",
      "Epoch 4277, Loss: 1.9043401607632404e-05, Final Batch Loss: 6.0321035562083125e-06\n",
      "Epoch 4278, Loss: 0.030774397768254858, Final Batch Loss: 2.3167427571024746e-05\n",
      "Epoch 4279, Loss: 0.021048895869171247, Final Batch Loss: 0.00010807344369823113\n",
      "Epoch 4280, Loss: 0.0038042865726310993, Final Batch Loss: 4.504476601141505e-05\n",
      "Epoch 4281, Loss: 0.00014531684701069025, Final Batch Loss: 1.0151964488613885e-05\n",
      "Epoch 4282, Loss: 0.00013873619900550693, Final Batch Loss: 7.642556738574058e-06\n",
      "Epoch 4283, Loss: 0.0005845656851306558, Final Batch Loss: 0.00022308077313937247\n",
      "Epoch 4284, Loss: 0.03161614862619899, Final Batch Loss: 0.00037734542274847627\n",
      "Epoch 4285, Loss: 0.00014986272003625345, Final Batch Loss: 2.3216155113914283e-06\n",
      "Epoch 4286, Loss: 0.0002226314136350993, Final Batch Loss: 0.00012553363922052085\n",
      "Epoch 4287, Loss: 0.005201668849622365, Final Batch Loss: 9.668673010310158e-05\n",
      "Epoch 4288, Loss: 0.0008525115554220974, Final Batch Loss: 8.669956878293306e-05\n",
      "Epoch 4289, Loss: 0.002052649164397735, Final Batch Loss: 4.536647611530498e-05\n",
      "Epoch 4290, Loss: 0.0005659372327500023, Final Batch Loss: 6.597534957109019e-05\n",
      "Epoch 4291, Loss: 0.005585635155512136, Final Batch Loss: 1.098524262488354e-05\n",
      "Epoch 4292, Loss: 0.00037369908022810705, Final Batch Loss: 5.9039248299086466e-05\n",
      "Epoch 4293, Loss: 0.00020061959730810486, Final Batch Loss: 0.00010985603876179084\n",
      "Epoch 4294, Loss: 0.00035500858575687744, Final Batch Loss: 0.0001376723375869915\n",
      "Epoch 4295, Loss: 0.0005351551371859387, Final Batch Loss: 0.0002289570984430611\n",
      "Epoch 4296, Loss: 0.0019028525894100312, Final Batch Loss: 4.31073312938679e-05\n",
      "Epoch 4297, Loss: 0.00030723752570338547, Final Batch Loss: 0.0002111702342517674\n",
      "Epoch 4298, Loss: 0.00022221988183446229, Final Batch Loss: 5.3870528063271195e-05\n",
      "Epoch 4299, Loss: 0.00019778583373408765, Final Batch Loss: 3.637250483734533e-05\n",
      "Epoch 4300, Loss: 0.00010515546273381915, Final Batch Loss: 1.938550303748343e-05\n",
      "Epoch 4301, Loss: 0.00040883802648750134, Final Batch Loss: 0.0002358714264119044\n",
      "Epoch 4302, Loss: 0.0018034021122730337, Final Batch Loss: 0.0011567616602405906\n",
      "Epoch 4303, Loss: 0.00010590391866571736, Final Batch Loss: 1.5418429029523395e-05\n",
      "Epoch 4304, Loss: 0.0001670679539529374, Final Batch Loss: 2.2318088667816482e-05\n",
      "Epoch 4305, Loss: 0.00012306656844884856, Final Batch Loss: 1.3389259947871324e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4306, Loss: 0.0015165004660957493, Final Batch Loss: 0.0013106040423735976\n",
      "Epoch 4307, Loss: 0.00012213698573759757, Final Batch Loss: 3.760640538530424e-05\n",
      "Epoch 4308, Loss: 0.0001229581430379767, Final Batch Loss: 2.763998054433614e-05\n",
      "Epoch 4309, Loss: 0.00041387846067664213, Final Batch Loss: 5.3570438467431813e-05\n",
      "Epoch 4310, Loss: 0.00039157666719802364, Final Batch Loss: 2.414889195279102e-06\n",
      "Epoch 4311, Loss: 0.00041855776362353936, Final Batch Loss: 0.00026119418907910585\n",
      "Epoch 4312, Loss: 0.00466673416121921, Final Batch Loss: 0.004430538974702358\n",
      "Epoch 4313, Loss: 0.00015930986273815506, Final Batch Loss: 3.157104947604239e-05\n",
      "Epoch 4314, Loss: 0.0003320532796351472, Final Batch Loss: 0.00012055137631250545\n",
      "Epoch 4315, Loss: 0.004945592499097984, Final Batch Loss: 1.2121045983803924e-05\n",
      "Epoch 4316, Loss: 0.0014729727554367855, Final Batch Loss: 0.00018841061682906002\n",
      "Epoch 4317, Loss: 0.0511090590753156, Final Batch Loss: 0.050597093999385834\n",
      "Epoch 4318, Loss: 0.00014408996503334492, Final Batch Loss: 9.857827535597607e-05\n",
      "Epoch 4319, Loss: 0.0002127936154465715, Final Batch Loss: 0.00019996415358036757\n",
      "Epoch 4320, Loss: 0.0013997338974149898, Final Batch Loss: 2.588756615296006e-06\n",
      "Epoch 4321, Loss: 0.00047494287537119817, Final Batch Loss: 0.00039429619209840894\n",
      "Epoch 4322, Loss: 0.00037353088191593997, Final Batch Loss: 0.00028982461662963033\n",
      "Epoch 4323, Loss: 6.645153143836069e-05, Final Batch Loss: 2.622479405545164e-05\n",
      "Epoch 4324, Loss: 0.03448921959170548, Final Batch Loss: 0.03443637490272522\n",
      "Epoch 4325, Loss: 0.028838546644692542, Final Batch Loss: 6.752974877599627e-05\n",
      "Epoch 4326, Loss: 0.007927160696453939, Final Batch Loss: 0.00781878549605608\n",
      "Epoch 4327, Loss: 0.01471537412271573, Final Batch Loss: 0.01406318973749876\n",
      "Epoch 4328, Loss: 0.001017330007016426, Final Batch Loss: 0.0005266252555884421\n",
      "Epoch 4329, Loss: 0.0024829107373989245, Final Batch Loss: 3.974108494730899e-06\n",
      "Epoch 4330, Loss: 0.00012491446250351146, Final Batch Loss: 7.857378659537062e-05\n",
      "Epoch 4331, Loss: 0.00028838898469984997, Final Batch Loss: 4.994642949895933e-05\n",
      "Epoch 4332, Loss: 0.00043239834394626087, Final Batch Loss: 1.5226730283757206e-05\n",
      "Epoch 4333, Loss: 0.00037582321238005534, Final Batch Loss: 0.00019969134882558137\n",
      "Epoch 4334, Loss: 0.0002831434685504064, Final Batch Loss: 7.647347956662998e-05\n",
      "Epoch 4335, Loss: 0.0004865024538958096, Final Batch Loss: 0.00015376968076452613\n",
      "Epoch 4336, Loss: 0.001276081195101142, Final Batch Loss: 0.001163260661996901\n",
      "Epoch 4337, Loss: 0.00023235310618474614, Final Batch Loss: 1.4646428098785691e-05\n",
      "Epoch 4338, Loss: 0.0003530700660121511, Final Batch Loss: 3.0617766242357902e-06\n",
      "Epoch 4339, Loss: 0.0003683159031879768, Final Batch Loss: 3.352974317749613e-06\n",
      "Epoch 4340, Loss: 0.0004570934174807917, Final Batch Loss: 6.24084304945427e-06\n",
      "Epoch 4341, Loss: 0.005285651932354085, Final Batch Loss: 7.71833147155121e-05\n",
      "Epoch 4342, Loss: 0.0037469271446752828, Final Batch Loss: 1.0640997061273083e-05\n",
      "Epoch 4343, Loss: 0.003909132014086936, Final Batch Loss: 0.0001992790785152465\n",
      "Epoch 4344, Loss: 0.0010770335429697298, Final Batch Loss: 0.0002766969264484942\n",
      "Epoch 4345, Loss: 0.0006705828454869334, Final Batch Loss: 0.0006347374292090535\n",
      "Epoch 4346, Loss: 0.000668994034640491, Final Batch Loss: 0.00016401842003688216\n",
      "Epoch 4347, Loss: 0.00036806764001084957, Final Batch Loss: 1.63361200975487e-05\n",
      "Epoch 4348, Loss: 0.0015721099844085984, Final Batch Loss: 0.0014107772149145603\n",
      "Epoch 4349, Loss: 0.0016655760409776121, Final Batch Loss: 9.587197564542294e-05\n",
      "Epoch 4350, Loss: 0.00017070227886506473, Final Batch Loss: 7.455386821675347e-06\n",
      "Epoch 4351, Loss: 0.0009527138900011778, Final Batch Loss: 7.811188697814941e-05\n",
      "Epoch 4352, Loss: 0.0006297604090832465, Final Batch Loss: 3.579957137844758e-06\n",
      "Epoch 4353, Loss: 0.0002722091412579175, Final Batch Loss: 1.5745639757369645e-05\n",
      "Epoch 4354, Loss: 0.00016713673539925367, Final Batch Loss: 7.745832408545539e-05\n",
      "Epoch 4355, Loss: 0.00033138836806756444, Final Batch Loss: 8.443909609923139e-05\n",
      "Epoch 4356, Loss: 7.613278739881935e-05, Final Batch Loss: 2.9936552891740575e-05\n",
      "Epoch 4357, Loss: 5.666524839398335e-05, Final Batch Loss: 7.335686859732959e-06\n",
      "Epoch 4358, Loss: 0.00015719847215223126, Final Batch Loss: 3.809264308074489e-05\n",
      "Epoch 4359, Loss: 0.0003911038820660906, Final Batch Loss: 1.6084411981864832e-05\n",
      "Epoch 4360, Loss: 9.027741180034354e-05, Final Batch Loss: 3.149265830870718e-05\n",
      "Epoch 4361, Loss: 0.0025909863661581767, Final Batch Loss: 0.0025652728509157896\n",
      "Epoch 4362, Loss: 0.0009357122144137975, Final Batch Loss: 0.0008788086124695837\n",
      "Epoch 4363, Loss: 0.000793766179413069, Final Batch Loss: 0.0005301405326463282\n",
      "Epoch 4364, Loss: 0.0004956917682648054, Final Batch Loss: 1.1746739801310468e-05\n",
      "Epoch 4365, Loss: 0.00010774253132694867, Final Batch Loss: 1.6706557289580815e-05\n",
      "Epoch 4366, Loss: 0.0013427085359580815, Final Batch Loss: 5.3609939641319215e-05\n",
      "Epoch 4367, Loss: 0.0004896170157735469, Final Batch Loss: 0.00040722492849454284\n",
      "Epoch 4368, Loss: 0.00021953913164907135, Final Batch Loss: 0.00010171598114538938\n",
      "Epoch 4369, Loss: 0.00019346149929333478, Final Batch Loss: 0.00011708556121448055\n",
      "Epoch 4370, Loss: 6.785425398447842e-05, Final Batch Loss: 1.7448394373786869e-06\n",
      "Epoch 4371, Loss: 5.710613504561479e-05, Final Batch Loss: 6.715277322655311e-06\n",
      "Epoch 4372, Loss: 0.00020422395027708262, Final Batch Loss: 8.95593038876541e-05\n",
      "Epoch 4373, Loss: 0.00018037204790744, Final Batch Loss: 2.8164376999484375e-05\n",
      "Epoch 4374, Loss: 6.009969911247026e-05, Final Batch Loss: 1.5667617844883353e-05\n",
      "Epoch 4375, Loss: 0.00017923607492775773, Final Batch Loss: 1.898640675790375e-06\n",
      "Epoch 4376, Loss: 6.661723182332935e-05, Final Batch Loss: 1.4516877854475752e-05\n",
      "Epoch 4377, Loss: 3.4684338061197195e-05, Final Batch Loss: 1.4091836419538595e-05\n",
      "Epoch 4378, Loss: 0.00026273940966348164, Final Batch Loss: 4.853264181292616e-05\n",
      "Epoch 4379, Loss: 0.00014213025315257255, Final Batch Loss: 5.587375198956579e-05\n",
      "Epoch 4380, Loss: 0.00019569048981793458, Final Batch Loss: 0.00014362411457113922\n",
      "Epoch 4381, Loss: 0.00014414614224733668, Final Batch Loss: 4.50544348495896e-06\n",
      "Epoch 4382, Loss: 0.00036435157016967423, Final Batch Loss: 3.308840314275585e-05\n",
      "Epoch 4383, Loss: 2.4508281967428047e-05, Final Batch Loss: 9.82330948318122e-06\n",
      "Epoch 4384, Loss: 7.148096483433619e-05, Final Batch Loss: 1.8231388821732253e-05\n",
      "Epoch 4385, Loss: 4.369046109786723e-05, Final Batch Loss: 8.529586921213195e-06\n",
      "Epoch 4386, Loss: 7.32937742213835e-05, Final Batch Loss: 3.174293669871986e-05\n",
      "Epoch 4387, Loss: 0.00014780714172957232, Final Batch Loss: 2.930869050032925e-05\n",
      "Epoch 4388, Loss: 9.566238077240996e-05, Final Batch Loss: 7.113058381946757e-05\n",
      "Epoch 4389, Loss: 7.624335535183491e-05, Final Batch Loss: 3.302437107777223e-05\n",
      "Epoch 4390, Loss: 0.00014485802148556104, Final Batch Loss: 9.123164636548609e-05\n",
      "Epoch 4391, Loss: 0.0001016292471831548, Final Batch Loss: 8.882992005965207e-06\n",
      "Epoch 4392, Loss: 0.0002863093609448697, Final Batch Loss: 5.7405482039030176e-06\n",
      "Epoch 4393, Loss: 0.00011781628018070478, Final Batch Loss: 2.4572424081270583e-05\n",
      "Epoch 4394, Loss: 7.283424565684982e-05, Final Batch Loss: 3.614953675423749e-05\n",
      "Epoch 4395, Loss: 5.098985366203124e-05, Final Batch Loss: 4.280503162590321e-06\n",
      "Epoch 4396, Loss: 0.0004704594139184337, Final Batch Loss: 0.0003402531147003174\n",
      "Epoch 4397, Loss: 4.625990277418168e-05, Final Batch Loss: 1.5053089555294719e-05\n",
      "Epoch 4398, Loss: 0.0001238921458934783, Final Batch Loss: 8.885280294634867e-06\n",
      "Epoch 4399, Loss: 0.0003250843083151267, Final Batch Loss: 3.3522948797326535e-05\n",
      "Epoch 4400, Loss: 0.0012583742354763672, Final Batch Loss: 9.519453669781797e-06\n",
      "Epoch 4401, Loss: 0.00045113233136362396, Final Batch Loss: 0.0003040687879547477\n",
      "Epoch 4402, Loss: 0.00040410862038697815, Final Batch Loss: 3.101237780356314e-06\n",
      "Epoch 4403, Loss: 0.00023157861141953617, Final Batch Loss: 7.269583875313401e-06\n",
      "Epoch 4404, Loss: 0.0014850320994810318, Final Batch Loss: 1.5041802726045717e-05\n",
      "Epoch 4405, Loss: 6.34979696769733e-05, Final Batch Loss: 2.2431026081903838e-05\n",
      "Epoch 4406, Loss: 8.568296379962703e-05, Final Batch Loss: 3.6947902117390186e-05\n",
      "Epoch 4407, Loss: 7.435002339661878e-05, Final Batch Loss: 2.590682242953335e-06\n",
      "Epoch 4408, Loss: 0.0004948580972268246, Final Batch Loss: 3.957681474275887e-05\n",
      "Epoch 4409, Loss: 3.9447870108233474e-05, Final Batch Loss: 1.2679987548835925e-06\n",
      "Epoch 4410, Loss: 0.00023985784650903952, Final Batch Loss: 3.6507965432974743e-06\n",
      "Epoch 4411, Loss: 0.0006912219801051833, Final Batch Loss: 7.496743364754366e-06\n",
      "Epoch 4412, Loss: 0.0001576322524670104, Final Batch Loss: 6.077175839891424e-06\n",
      "Epoch 4413, Loss: 0.0003426383264013566, Final Batch Loss: 0.00021104155166540295\n",
      "Epoch 4414, Loss: 0.0005911592052143533, Final Batch Loss: 0.00031748870969749987\n",
      "Epoch 4415, Loss: 0.0003311421751277521, Final Batch Loss: 0.00014258806186262518\n",
      "Epoch 4416, Loss: 6.869388471386628e-05, Final Batch Loss: 1.8647106116986834e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4417, Loss: 3.4253796002303716e-05, Final Batch Loss: 4.012200406577904e-06\n",
      "Epoch 4418, Loss: 6.914349580711132e-05, Final Batch Loss: 1.4054727444090531e-06\n",
      "Epoch 4419, Loss: 0.0021232511062407866, Final Batch Loss: 0.002050903160125017\n",
      "Epoch 4420, Loss: 0.004489145921979798, Final Batch Loss: 5.033611159888096e-05\n",
      "Epoch 4421, Loss: 0.0011397413622944441, Final Batch Loss: 4.09077847507433e-06\n",
      "Epoch 4422, Loss: 6.937577154531027e-05, Final Batch Loss: 2.7174423848919105e-06\n",
      "Epoch 4423, Loss: 0.0001658346873227856, Final Batch Loss: 0.00011288104724371806\n",
      "Epoch 4424, Loss: 3.158060530950024e-05, Final Batch Loss: 1.2080873602826614e-05\n",
      "Epoch 4425, Loss: 0.000710978052666178, Final Batch Loss: 1.3280598068377003e-05\n",
      "Epoch 4426, Loss: 0.00010979516173392767, Final Batch Loss: 5.4623706091661006e-05\n",
      "Epoch 4427, Loss: 9.777701598068234e-05, Final Batch Loss: 4.649867696571164e-05\n",
      "Epoch 4428, Loss: 0.0003610725252656266, Final Batch Loss: 0.00029447421547956765\n",
      "Epoch 4429, Loss: 0.0005045979323767824, Final Batch Loss: 1.692895239102654e-05\n",
      "Epoch 4430, Loss: 0.00016847485312609933, Final Batch Loss: 9.190528362523764e-05\n",
      "Epoch 4431, Loss: 2.7799419058283092e-05, Final Batch Loss: 8.599008651799522e-06\n",
      "Epoch 4432, Loss: 0.0006036905842847773, Final Batch Loss: 2.2812244424130768e-05\n",
      "Epoch 4433, Loss: 2.594822535684216e-05, Final Batch Loss: 8.047555638768245e-06\n",
      "Epoch 4434, Loss: 6.27640157517817e-05, Final Batch Loss: 1.5929336996123311e-06\n",
      "Epoch 4435, Loss: 7.791133339196676e-05, Final Batch Loss: 8.256077308033127e-06\n",
      "Epoch 4436, Loss: 4.0696312453292194e-05, Final Batch Loss: 1.0315281997463899e-06\n",
      "Epoch 4437, Loss: 0.00010961717225654866, Final Batch Loss: 8.525550219928846e-05\n",
      "Epoch 4438, Loss: 0.0009974009117286187, Final Batch Loss: 0.000990794855169952\n",
      "Epoch 4439, Loss: 0.00020491040231718216, Final Batch Loss: 7.181311229942366e-05\n",
      "Epoch 4440, Loss: 7.764933343423763e-05, Final Batch Loss: 6.44250485493103e-06\n",
      "Epoch 4441, Loss: 0.00041385560052731307, Final Batch Loss: 6.293551450653467e-06\n",
      "Epoch 4442, Loss: 0.0002422237857899745, Final Batch Loss: 5.269609573588241e-06\n",
      "Epoch 4443, Loss: 5.3162636959314113e-05, Final Batch Loss: 2.292518547619693e-05\n",
      "Epoch 4444, Loss: 0.0005777546874696782, Final Batch Loss: 1.0151860578844207e-06\n",
      "Epoch 4445, Loss: 8.813356407699757e-05, Final Batch Loss: 3.5953275983047206e-06\n",
      "Epoch 4446, Loss: 5.73162661794413e-05, Final Batch Loss: 3.2118093713506823e-06\n",
      "Epoch 4447, Loss: 0.0005311682980391197, Final Batch Loss: 1.3611417671199888e-05\n",
      "Epoch 4448, Loss: 0.0001815981838717562, Final Batch Loss: 3.2741797895141644e-06\n",
      "Epoch 4449, Loss: 0.0006102507038576732, Final Batch Loss: 1.7938625660463003e-06\n",
      "Epoch 4450, Loss: 0.00010025680603575893, Final Batch Loss: 3.09882962028496e-05\n",
      "Epoch 4451, Loss: 0.002559241962444503, Final Batch Loss: 0.00020676107669714838\n",
      "Epoch 4452, Loss: 7.228340655274224e-05, Final Batch Loss: 3.757689046324231e-05\n",
      "Epoch 4453, Loss: 0.000247464334279357, Final Batch Loss: 9.820653758652043e-06\n",
      "Epoch 4454, Loss: 0.0007003219761827495, Final Batch Loss: 6.065317938919179e-05\n",
      "Epoch 4455, Loss: 0.00021935505719739012, Final Batch Loss: 6.63520404486917e-06\n",
      "Epoch 4456, Loss: 5.06269443576457e-05, Final Batch Loss: 3.0924002203391865e-05\n",
      "Epoch 4457, Loss: 6.859416316729039e-05, Final Batch Loss: 7.966662451508455e-06\n",
      "Epoch 4458, Loss: 5.3264676353137475e-05, Final Batch Loss: 2.5814035325311124e-05\n",
      "Epoch 4459, Loss: 2.4198003757192055e-05, Final Batch Loss: 6.021605258865748e-06\n",
      "Epoch 4460, Loss: 7.622364546477911e-05, Final Batch Loss: 6.459946689574281e-06\n",
      "Epoch 4461, Loss: 8.014766171982046e-05, Final Batch Loss: 1.5655552488169633e-05\n",
      "Epoch 4462, Loss: 9.901850808091694e-05, Final Batch Loss: 7.20278185326606e-05\n",
      "Epoch 4463, Loss: 0.00016518883167293552, Final Batch Loss: 2.028475165616328e-07\n",
      "Epoch 4464, Loss: 0.0002802963099384215, Final Batch Loss: 8.874481136444956e-05\n",
      "Epoch 4465, Loss: 3.224556751035834e-05, Final Batch Loss: 1.740067290256775e-07\n",
      "Epoch 4466, Loss: 0.00037572056862700265, Final Batch Loss: 0.00033420053659938276\n",
      "Epoch 4467, Loss: 0.00019898853497579694, Final Batch Loss: 7.405198994092643e-05\n",
      "Epoch 4468, Loss: 0.00010204013551629032, Final Batch Loss: 6.363542343024164e-05\n",
      "Epoch 4469, Loss: 9.342829343950143e-05, Final Batch Loss: 2.8644941266975366e-05\n",
      "Epoch 4470, Loss: 0.003550989464315535, Final Batch Loss: 2.384045728831552e-06\n",
      "Epoch 4471, Loss: 0.00010660186990207876, Final Batch Loss: 4.7987336984078865e-06\n",
      "Epoch 4472, Loss: 0.0020183624037599657, Final Batch Loss: 9.470056829741225e-05\n",
      "Epoch 4473, Loss: 0.0001595417306816671, Final Batch Loss: 2.882477201637812e-05\n",
      "Epoch 4474, Loss: 8.238154396167374e-05, Final Batch Loss: 4.3821487452078145e-06\n",
      "Epoch 4475, Loss: 0.0064930862208711915, Final Batch Loss: 1.084841278498061e-05\n",
      "Epoch 4476, Loss: 0.00778705520724543, Final Batch Loss: 4.242962404532591e-06\n",
      "Epoch 4477, Loss: 0.0001422668347004219, Final Batch Loss: 3.857722185784951e-05\n",
      "Epoch 4478, Loss: 0.0003598639577830909, Final Batch Loss: 0.00018564511265140027\n",
      "Epoch 4479, Loss: 0.0002132203712790215, Final Batch Loss: 0.00019558305211830884\n",
      "Epoch 4480, Loss: 0.0004327870092311059, Final Batch Loss: 1.0081673281092662e-05\n",
      "Epoch 4481, Loss: 0.00023536059813977772, Final Batch Loss: 7.689838093938306e-05\n",
      "Epoch 4482, Loss: 5.407262324297335e-05, Final Batch Loss: 1.806801083148457e-05\n",
      "Epoch 4483, Loss: 0.0032130227154993918, Final Batch Loss: 1.694456113909837e-05\n",
      "Epoch 4484, Loss: 0.0004144849117437843, Final Batch Loss: 3.060468952753581e-05\n",
      "Epoch 4485, Loss: 0.0020088307828700636, Final Batch Loss: 0.00028422210016287863\n",
      "Epoch 4486, Loss: 0.00014018651927472092, Final Batch Loss: 1.843553764047101e-05\n",
      "Epoch 4487, Loss: 0.00011166206149937352, Final Batch Loss: 2.745118399616331e-05\n",
      "Epoch 4488, Loss: 0.00037976830037678155, Final Batch Loss: 1.6563709550609929e-06\n",
      "Epoch 4489, Loss: 0.00044358935883792583, Final Batch Loss: 2.910723014792893e-05\n",
      "Epoch 4490, Loss: 0.0008280010188173037, Final Batch Loss: 1.426990274921991e-05\n",
      "Epoch 4491, Loss: 0.00012521245662355796, Final Batch Loss: 5.365836386772571e-06\n",
      "Epoch 4492, Loss: 0.00010585340282887046, Final Batch Loss: 2.7176090497960104e-06\n",
      "Epoch 4493, Loss: 0.00017096317333198385, Final Batch Loss: 3.863127494696528e-05\n",
      "Epoch 4494, Loss: 4.033205914311111e-05, Final Batch Loss: 2.8752274374710396e-06\n",
      "Epoch 4495, Loss: 0.0002080173453578027, Final Batch Loss: 2.207459692726843e-05\n",
      "Epoch 4496, Loss: 7.637432463525329e-05, Final Batch Loss: 7.902181096142158e-06\n",
      "Epoch 4497, Loss: 6.687053155474132e-05, Final Batch Loss: 2.1720221411669627e-05\n",
      "Epoch 4498, Loss: 0.0031901871370791923, Final Batch Loss: 3.4530507946328726e-06\n",
      "Epoch 4499, Loss: 0.0017939728786586784, Final Batch Loss: 0.001683816546574235\n",
      "Epoch 4500, Loss: 2.2335173525789287e-05, Final Batch Loss: 1.3987437341711484e-06\n",
      "Epoch 4501, Loss: 0.00010899192238866817, Final Batch Loss: 4.187915692455135e-05\n",
      "Epoch 4502, Loss: 9.565907112119021e-05, Final Batch Loss: 9.772394150786567e-06\n",
      "Epoch 4503, Loss: 4.765363428305136e-05, Final Batch Loss: 2.0485294953687117e-06\n",
      "Epoch 4504, Loss: 0.00013325759118743008, Final Batch Loss: 1.1901715879503172e-05\n",
      "Epoch 4505, Loss: 0.07037796056829393, Final Batch Loss: 0.06903418898582458\n",
      "Epoch 4506, Loss: 0.0006813106338086072, Final Batch Loss: 8.679871825734153e-06\n",
      "Epoch 4507, Loss: 0.003974105071392842, Final Batch Loss: 0.0033823042176663876\n",
      "Epoch 4508, Loss: 0.0016733311640564352, Final Batch Loss: 0.0014773631701245904\n",
      "Epoch 4509, Loss: 0.00020742024935316294, Final Batch Loss: 1.556649658596143e-05\n",
      "Epoch 4510, Loss: 0.001358584762783721, Final Batch Loss: 1.368466837448068e-05\n",
      "Epoch 4511, Loss: 0.0021675408079318004, Final Batch Loss: 1.466641879233066e-05\n",
      "Epoch 4512, Loss: 0.0014916837944838335, Final Batch Loss: 7.982730494404677e-06\n",
      "Epoch 4513, Loss: 0.0005371443985495716, Final Batch Loss: 0.00015423116565216333\n",
      "Epoch 4514, Loss: 0.008261502829554956, Final Batch Loss: 7.414040010189638e-05\n",
      "Epoch 4515, Loss: 0.0005183825041967793, Final Batch Loss: 0.0004352594551164657\n",
      "Epoch 4516, Loss: 0.02050459457677789, Final Batch Loss: 0.0001315952104050666\n",
      "Epoch 4517, Loss: 0.02364407427739934, Final Batch Loss: 0.02347773313522339\n",
      "Epoch 4518, Loss: 0.0010507054303161567, Final Batch Loss: 3.3876112865982577e-06\n",
      "Epoch 4519, Loss: 0.014166526263579726, Final Batch Loss: 0.003808378940448165\n",
      "Epoch 4520, Loss: 0.006189433559484314, Final Batch Loss: 5.4664611525367945e-05\n",
      "Epoch 4521, Loss: 0.00032839145706020645, Final Batch Loss: 7.317220934055513e-06\n",
      "Epoch 4522, Loss: 0.00037640185246345936, Final Batch Loss: 7.4948379733541515e-06\n",
      "Epoch 4523, Loss: 0.0008084159271675162, Final Batch Loss: 8.850928134052083e-05\n",
      "Epoch 4524, Loss: 0.00036254913720767945, Final Batch Loss: 0.00013350335939321667\n",
      "Epoch 4525, Loss: 0.0003120273340755375, Final Batch Loss: 5.870199674973264e-05\n",
      "Epoch 4526, Loss: 0.011006069638824556, Final Batch Loss: 1.822681224439293e-05\n",
      "Epoch 4527, Loss: 0.000760805103709572, Final Batch Loss: 0.00022601710224989802\n",
      "Epoch 4528, Loss: 0.0050351032869002665, Final Batch Loss: 9.212645636580419e-06\n",
      "Epoch 4529, Loss: 0.027206730701436754, Final Batch Loss: 6.176459282869473e-05\n",
      "Epoch 4530, Loss: 0.004853700229432434, Final Batch Loss: 0.0004939969512633979\n",
      "Epoch 4531, Loss: 0.018037168541923165, Final Batch Loss: 0.01780659891664982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4532, Loss: 0.0002401984020252712, Final Batch Loss: 7.084798562573269e-05\n",
      "Epoch 4533, Loss: 0.00012393274391797604, Final Batch Loss: 8.053660712903365e-05\n",
      "Epoch 4534, Loss: 0.002917110308771953, Final Batch Loss: 0.0026414599269628525\n",
      "Epoch 4535, Loss: 0.018636283046362223, Final Batch Loss: 3.1824325560592115e-05\n",
      "Epoch 4536, Loss: 0.002677246244275011, Final Batch Loss: 5.6319055147469044e-05\n",
      "Epoch 4537, Loss: 0.000143221204780275, Final Batch Loss: 4.561085734167136e-05\n",
      "Epoch 4538, Loss: 0.0003980901346949395, Final Batch Loss: 0.00029753250419162214\n",
      "Epoch 4539, Loss: 0.00017842737725004554, Final Batch Loss: 9.086622594622895e-05\n",
      "Epoch 4540, Loss: 0.00030122693215162144, Final Batch Loss: 4.716059720522026e-06\n",
      "Epoch 4541, Loss: 0.004015049253212055, Final Batch Loss: 0.00014457147335633636\n",
      "Epoch 4542, Loss: 0.0013342053971427958, Final Batch Loss: 0.0009095488348975778\n",
      "Epoch 4543, Loss: 0.000763748241297435, Final Batch Loss: 7.137995271477848e-05\n",
      "Epoch 4544, Loss: 0.0032329420191672398, Final Batch Loss: 2.3222170057124458e-05\n",
      "Epoch 4545, Loss: 0.0004191518319203169, Final Batch Loss: 8.045427421166096e-06\n",
      "Epoch 4546, Loss: 0.0002242040864075534, Final Batch Loss: 5.300283010001294e-05\n",
      "Epoch 4547, Loss: 0.00018758502665150445, Final Batch Loss: 0.00012141490879002959\n",
      "Epoch 4548, Loss: 0.0008917552477214485, Final Batch Loss: 0.00013763493916485459\n",
      "Epoch 4549, Loss: 0.000941614322073292, Final Batch Loss: 5.105978198116645e-05\n",
      "Epoch 4550, Loss: 0.00016513457921973895, Final Batch Loss: 2.52596346399514e-05\n",
      "Epoch 4551, Loss: 0.005892220098758116, Final Batch Loss: 0.00522645004093647\n",
      "Epoch 4552, Loss: 0.00021058627316961065, Final Batch Loss: 2.7285455871606246e-05\n",
      "Epoch 4553, Loss: 0.00020977396525267977, Final Batch Loss: 1.642134338908363e-05\n",
      "Epoch 4554, Loss: 0.00010995607772201765, Final Batch Loss: 3.14258286380209e-05\n",
      "Epoch 4555, Loss: 0.007785897149005905, Final Batch Loss: 0.00014747167006134987\n",
      "Epoch 4556, Loss: 0.000523504602824687, Final Batch Loss: 1.4832190572633408e-05\n",
      "Epoch 4557, Loss: 5.6319537634408334e-05, Final Batch Loss: 5.616674116026843e-06\n",
      "Epoch 4558, Loss: 0.0010844080898095854, Final Batch Loss: 6.351557385642081e-05\n",
      "Epoch 4559, Loss: 0.00212131004082039, Final Batch Loss: 0.00034498851164244115\n",
      "Epoch 4560, Loss: 0.00011947342682105955, Final Batch Loss: 4.450643973541446e-05\n",
      "Epoch 4561, Loss: 0.00022442466161010088, Final Batch Loss: 8.46557395561831e-06\n",
      "Epoch 4562, Loss: 0.000122917848329962, Final Batch Loss: 5.222437175689265e-05\n",
      "Epoch 4563, Loss: 0.0011776567343986244, Final Batch Loss: 0.0011391306761652231\n",
      "Epoch 4564, Loss: 0.00032394976824434707, Final Batch Loss: 8.158737182384357e-05\n",
      "Epoch 4565, Loss: 0.00018444192937749904, Final Batch Loss: 1.9140716176480055e-05\n",
      "Epoch 4566, Loss: 0.0001510703186795581, Final Batch Loss: 5.3985309932613745e-05\n",
      "Epoch 4567, Loss: 2.7820027298730565e-05, Final Batch Loss: 1.0964479770336766e-05\n",
      "Epoch 4568, Loss: 7.486224603781011e-05, Final Batch Loss: 3.469561124802567e-05\n",
      "Epoch 4569, Loss: 0.0004205860013826168, Final Batch Loss: 0.00014499176177196205\n",
      "Epoch 4570, Loss: 0.0007428890503433649, Final Batch Loss: 0.0006554091232828796\n",
      "Epoch 4571, Loss: 0.00023047055310598807, Final Batch Loss: 0.00017647483036853373\n",
      "Epoch 4572, Loss: 5.849075955666194e-05, Final Batch Loss: 3.648830215752241e-06\n",
      "Epoch 4573, Loss: 9.244441139344417e-05, Final Batch Loss: 7.345688936766237e-05\n",
      "Epoch 4574, Loss: 0.0009965050567188882, Final Batch Loss: 7.754621947242413e-06\n",
      "Epoch 4575, Loss: 0.016932318660110468, Final Batch Loss: 0.016808969900012016\n",
      "Epoch 4576, Loss: 0.00035626003773359116, Final Batch Loss: 1.9327102563693188e-05\n",
      "Epoch 4577, Loss: 0.0004117182388654328, Final Batch Loss: 1.029299801302841e-05\n",
      "Epoch 4578, Loss: 0.0003493953227007296, Final Batch Loss: 3.6242283385945484e-05\n",
      "Epoch 4579, Loss: 0.0008512404706380039, Final Batch Loss: 2.962758571811719e-06\n",
      "Epoch 4580, Loss: 0.0003161591693014998, Final Batch Loss: 0.00019513230654411018\n",
      "Epoch 4581, Loss: 0.0005760320273111574, Final Batch Loss: 0.0001645524171181023\n",
      "Epoch 4582, Loss: 0.002703360093619267, Final Batch Loss: 7.2408884079777636e-06\n",
      "Epoch 4583, Loss: 0.0002955979980470147, Final Batch Loss: 5.141436122357845e-05\n",
      "Epoch 4584, Loss: 0.00033135302874143235, Final Batch Loss: 0.00023031787713989615\n",
      "Epoch 4585, Loss: 0.0001505528960024094, Final Batch Loss: 1.7054096588253742e-06\n",
      "Epoch 4586, Loss: 0.0003202818634235882, Final Batch Loss: 0.00020900042727589607\n",
      "Epoch 4587, Loss: 0.0001734566340019228, Final Batch Loss: 1.9385113773751073e-05\n",
      "Epoch 4588, Loss: 0.00013337997552298475, Final Batch Loss: 2.7054824386141263e-05\n",
      "Epoch 4589, Loss: 0.0003589195111999288, Final Batch Loss: 6.87724823364988e-05\n",
      "Epoch 4590, Loss: 0.0038833766302559525, Final Batch Loss: 7.009992259554565e-05\n",
      "Epoch 4591, Loss: 0.0001698883243079763, Final Batch Loss: 6.498511356767267e-05\n",
      "Epoch 4592, Loss: 0.0009026945799632813, Final Batch Loss: 0.000879360013641417\n",
      "Epoch 4593, Loss: 0.0014576608755305642, Final Batch Loss: 0.00019958970369771123\n",
      "Epoch 4594, Loss: 0.00012164462259534048, Final Batch Loss: 2.520415000617504e-05\n",
      "Epoch 4595, Loss: 0.0005126021260366542, Final Batch Loss: 1.7152675354736857e-05\n",
      "Epoch 4596, Loss: 0.000564392709236472, Final Batch Loss: 2.480314265085326e-07\n",
      "Epoch 4597, Loss: 0.03483482135561644, Final Batch Loss: 0.00027510622749105096\n",
      "Epoch 4598, Loss: 0.0008338773041032255, Final Batch Loss: 4.2404368286952376e-05\n",
      "Epoch 4599, Loss: 0.0005225171335041523, Final Batch Loss: 5.231146496953443e-05\n",
      "Epoch 4600, Loss: 0.0011485258000902832, Final Batch Loss: 0.0008028052398003638\n",
      "Epoch 4601, Loss: 0.0005597592680715024, Final Batch Loss: 9.265048720408231e-05\n",
      "Epoch 4602, Loss: 0.000895697834494058, Final Batch Loss: 0.00010808037040987983\n",
      "Epoch 4603, Loss: 0.00045759914064547047, Final Batch Loss: 0.0001874002191470936\n",
      "Epoch 4604, Loss: 0.0012209717133373488, Final Batch Loss: 3.439282954786904e-05\n",
      "Epoch 4605, Loss: 0.00891766090717283, Final Batch Loss: 3.60075973731e-05\n",
      "Epoch 4606, Loss: 0.00012532376149465563, Final Batch Loss: 1.041853192873532e-05\n",
      "Epoch 4607, Loss: 0.0009317154181189835, Final Batch Loss: 0.0005287000094540417\n",
      "Epoch 4608, Loss: 0.00011131758401461411, Final Batch Loss: 9.686302291811444e-06\n",
      "Epoch 4609, Loss: 0.0005264497758616926, Final Batch Loss: 1.2387174137984402e-05\n",
      "Epoch 4610, Loss: 0.0011617326745181344, Final Batch Loss: 0.00014682207256555557\n",
      "Epoch 4611, Loss: 0.0015156858498812653, Final Batch Loss: 0.0007840467733331025\n",
      "Epoch 4612, Loss: 0.0003642318633865216, Final Batch Loss: 1.9262019122834317e-05\n",
      "Epoch 4613, Loss: 0.010150091169634834, Final Batch Loss: 0.0011401672381907701\n",
      "Epoch 4614, Loss: 0.0003616613071244501, Final Batch Loss: 6.365179160638945e-06\n",
      "Epoch 4615, Loss: 0.0014370734061230905, Final Batch Loss: 0.00048365286784246564\n",
      "Epoch 4616, Loss: 0.00676900540565839, Final Batch Loss: 3.7167559639783576e-05\n",
      "Epoch 4617, Loss: 0.01395762998436112, Final Batch Loss: 0.00010510373249417171\n",
      "Epoch 4618, Loss: 6.116970325820148e-05, Final Batch Loss: 8.033772246562876e-06\n",
      "Epoch 4619, Loss: 0.0028721597336698323, Final Batch Loss: 0.001775215147063136\n",
      "Epoch 4620, Loss: 0.02882726832467597, Final Batch Loss: 2.1023661247454584e-05\n",
      "Epoch 4621, Loss: 0.002674768344149925, Final Batch Loss: 0.00016741656872909516\n",
      "Epoch 4622, Loss: 0.00017914103955263272, Final Batch Loss: 5.0373608246445656e-05\n",
      "Epoch 4623, Loss: 0.00026493028417462483, Final Batch Loss: 7.310215005418286e-05\n",
      "Epoch 4624, Loss: 0.00032934343107626773, Final Batch Loss: 3.092248516622931e-05\n",
      "Epoch 4625, Loss: 0.00020031338499393314, Final Batch Loss: 0.0001172304546344094\n",
      "Epoch 4626, Loss: 0.0007269074885698501, Final Batch Loss: 0.00021975356503389776\n",
      "Epoch 4627, Loss: 0.0015023136547824834, Final Batch Loss: 4.6438686695182696e-05\n",
      "Epoch 4628, Loss: 0.0005727636798837921, Final Batch Loss: 0.0005014071939513087\n",
      "Epoch 4629, Loss: 0.0002502464485587552, Final Batch Loss: 3.2884163374546915e-05\n",
      "Epoch 4630, Loss: 0.00340988763855421, Final Batch Loss: 5.9460151533130556e-05\n",
      "Epoch 4631, Loss: 0.00014285725774243474, Final Batch Loss: 4.371686009108089e-05\n",
      "Epoch 4632, Loss: 0.0004003021986136446, Final Batch Loss: 0.00034092116402462125\n",
      "Epoch 4633, Loss: 0.0018628873867783113, Final Batch Loss: 5.938264621363487e-06\n",
      "Epoch 4634, Loss: 0.020807250402867794, Final Batch Loss: 0.00044122961116954684\n",
      "Epoch 4635, Loss: 0.0010351971686759498, Final Batch Loss: 4.4127675209892914e-05\n",
      "Epoch 4636, Loss: 0.00038550903082068544, Final Batch Loss: 9.372828571940772e-06\n",
      "Epoch 4637, Loss: 0.0015213901351671666, Final Batch Loss: 7.406403892673552e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4638, Loss: 0.0002535334606363904, Final Batch Loss: 4.3345749872969463e-05\n",
      "Epoch 4639, Loss: 0.0001609183400432812, Final Batch Loss: 2.1561525500146672e-05\n",
      "Epoch 4640, Loss: 0.0004198746978545387, Final Batch Loss: 0.00019942614017054439\n",
      "Epoch 4641, Loss: 9.366564518131781e-05, Final Batch Loss: 4.7716184781165794e-05\n",
      "Epoch 4642, Loss: 0.0004593930407281732, Final Batch Loss: 1.987115501833614e-05\n",
      "Epoch 4643, Loss: 0.00024094566106214188, Final Batch Loss: 3.12474076054059e-05\n",
      "Epoch 4644, Loss: 0.00019509706953613204, Final Batch Loss: 1.5476540283998474e-05\n",
      "Epoch 4645, Loss: 0.00016053413673944306, Final Batch Loss: 7.288642518687993e-05\n",
      "Epoch 4646, Loss: 0.0007273242053997819, Final Batch Loss: 7.825225475244224e-05\n",
      "Epoch 4647, Loss: 0.0007392753004751285, Final Batch Loss: 3.7157878978177905e-05\n",
      "Epoch 4648, Loss: 0.005924013395997463, Final Batch Loss: 3.109639146714471e-05\n",
      "Epoch 4649, Loss: 0.00011826313311757986, Final Batch Loss: 3.4440570743754506e-05\n",
      "Epoch 4650, Loss: 0.004455787209735718, Final Batch Loss: 3.7532248825300485e-05\n",
      "Epoch 4651, Loss: 0.00010596430820442038, Final Batch Loss: 4.859632099396549e-05\n",
      "Epoch 4652, Loss: 7.765356167510618e-05, Final Batch Loss: 3.3278771297773346e-05\n",
      "Epoch 4653, Loss: 9.454335850023199e-05, Final Batch Loss: 5.775850513600744e-05\n",
      "Epoch 4654, Loss: 0.0003117649721389171, Final Batch Loss: 4.0509392420062795e-05\n",
      "Epoch 4655, Loss: 9.34686495384085e-05, Final Batch Loss: 1.368954144709278e-06\n",
      "Epoch 4656, Loss: 0.00014475780051270704, Final Batch Loss: 1.5246304201355088e-06\n",
      "Epoch 4657, Loss: 0.0028030156281602103, Final Batch Loss: 0.00028928296524100006\n",
      "Epoch 4658, Loss: 0.00014981679123593494, Final Batch Loss: 5.605286787613295e-05\n",
      "Epoch 4659, Loss: 6.577594103873707e-05, Final Batch Loss: 2.2454269128502347e-05\n",
      "Epoch 4660, Loss: 0.000503026763908565, Final Batch Loss: 0.0003849065979011357\n",
      "Epoch 4661, Loss: 0.00011691539839375764, Final Batch Loss: 4.4761480239685625e-05\n",
      "Epoch 4662, Loss: 0.0010161802815673582, Final Batch Loss: 0.0009088708320632577\n",
      "Epoch 4663, Loss: 0.0008748305554036051, Final Batch Loss: 1.4735300283064134e-05\n",
      "Epoch 4664, Loss: 0.00016823110991026624, Final Batch Loss: 3.987491709267488e-06\n",
      "Epoch 4665, Loss: 3.3538487514306325e-05, Final Batch Loss: 6.442193352995673e-06\n",
      "Epoch 4666, Loss: 0.00012181723923276877, Final Batch Loss: 2.501856033632066e-05\n",
      "Epoch 4667, Loss: 0.0009362992332171416, Final Batch Loss: 6.250124715734273e-05\n",
      "Epoch 4668, Loss: 0.0006426336367439944, Final Batch Loss: 4.5478172978619114e-05\n",
      "Epoch 4669, Loss: 0.0006630579773627687, Final Batch Loss: 1.0769796062959358e-05\n",
      "Epoch 4670, Loss: 0.0002231975172435341, Final Batch Loss: 4.030714535474544e-06\n",
      "Epoch 4671, Loss: 0.00010638114326866344, Final Batch Loss: 2.1315405319910496e-05\n",
      "Epoch 4672, Loss: 0.0003249300698371371, Final Batch Loss: 3.7534926377702504e-05\n",
      "Epoch 4673, Loss: 0.0010986169218085706, Final Batch Loss: 0.0008976160315796733\n",
      "Epoch 4674, Loss: 0.0005223641851443972, Final Batch Loss: 0.0004982981481589377\n",
      "Epoch 4675, Loss: 0.0004098526951565873, Final Batch Loss: 4.6104232751531526e-05\n",
      "Epoch 4676, Loss: 2.382134391609725e-05, Final Batch Loss: 1.5035390106277191e-06\n",
      "Epoch 4677, Loss: 0.0001727024086903839, Final Batch Loss: 3.913485215889523e-06\n",
      "Epoch 4678, Loss: 0.00012956437160482892, Final Batch Loss: 3.534431380103342e-05\n",
      "Epoch 4679, Loss: 8.971106433364184e-05, Final Batch Loss: 4.03444682888221e-05\n",
      "Epoch 4680, Loss: 0.0001138194838858908, Final Batch Loss: 4.877672836300917e-05\n",
      "Epoch 4681, Loss: 0.00012349741155048832, Final Batch Loss: 5.199995939619839e-06\n",
      "Epoch 4682, Loss: 0.00013900159501645248, Final Batch Loss: 2.8334221497061662e-05\n",
      "Epoch 4683, Loss: 0.00012510273791122017, Final Batch Loss: 9.321079414803535e-05\n",
      "Epoch 4684, Loss: 0.00013818462502968032, Final Batch Loss: 5.1555562095018104e-05\n",
      "Epoch 4685, Loss: 5.224506696777098e-05, Final Batch Loss: 1.5294759805328795e-06\n",
      "Epoch 4686, Loss: 0.00015425316405526246, Final Batch Loss: 4.327976057538763e-05\n",
      "Epoch 4687, Loss: 0.00010869862126128282, Final Batch Loss: 3.385360832908191e-05\n",
      "Epoch 4688, Loss: 0.00021237922010186594, Final Batch Loss: 4.552732207230292e-06\n",
      "Epoch 4689, Loss: 0.0001399119796587911, Final Batch Loss: 4.025836005894234e-06\n",
      "Epoch 4690, Loss: 8.030627191146777e-05, Final Batch Loss: 3.106948270215071e-06\n",
      "Epoch 4691, Loss: 0.00010104991497428273, Final Batch Loss: 6.325694812403526e-07\n",
      "Epoch 4692, Loss: 0.0032742300973040983, Final Batch Loss: 0.00014317598834168166\n",
      "Epoch 4693, Loss: 8.412287525061402e-05, Final Batch Loss: 5.825238622492179e-05\n",
      "Epoch 4694, Loss: 0.008247418898463366, Final Batch Loss: 0.008182681165635586\n",
      "Epoch 4695, Loss: 8.84185988070385e-05, Final Batch Loss: 6.377340014296351e-06\n",
      "Epoch 4696, Loss: 0.00018834870570572093, Final Batch Loss: 4.299127613194287e-05\n",
      "Epoch 4697, Loss: 0.0003537809207045939, Final Batch Loss: 2.979201599373482e-05\n",
      "Epoch 4698, Loss: 0.00028798813582398, Final Batch Loss: 0.00014526210725307465\n",
      "Epoch 4699, Loss: 0.00011613135256993701, Final Batch Loss: 9.817937825573608e-05\n",
      "Epoch 4700, Loss: 0.000297423173833522, Final Batch Loss: 1.572233122715261e-05\n",
      "Epoch 4701, Loss: 0.00010273916450387333, Final Batch Loss: 1.2769431123160757e-05\n",
      "Epoch 4702, Loss: 0.02611047106984188, Final Batch Loss: 2.2819574951427057e-05\n",
      "Epoch 4703, Loss: 0.0001385539515013079, Final Batch Loss: 8.23410227894783e-05\n",
      "Epoch 4704, Loss: 0.0004610368705471046, Final Batch Loss: 0.00023702131875324994\n",
      "Epoch 4705, Loss: 0.0002761054893198889, Final Batch Loss: 0.00010078174091177061\n",
      "Epoch 4706, Loss: 0.0007576869829790667, Final Batch Loss: 0.0006483918405137956\n",
      "Epoch 4707, Loss: 0.0003724311500263866, Final Batch Loss: 0.0002951144415419549\n",
      "Epoch 4708, Loss: 0.0006689011397611466, Final Batch Loss: 4.0795466702547856e-06\n",
      "Epoch 4709, Loss: 0.0002487112251401413, Final Batch Loss: 4.621020707418211e-05\n",
      "Epoch 4710, Loss: 0.0007624468526046257, Final Batch Loss: 2.9394472221611068e-05\n",
      "Epoch 4711, Loss: 0.00014726103711382166, Final Batch Loss: 1.3621780681205564e-06\n",
      "Epoch 4712, Loss: 7.15374007995706e-05, Final Batch Loss: 3.3362346584908664e-05\n",
      "Epoch 4713, Loss: 0.00016530298762518214, Final Batch Loss: 1.2669851457758341e-05\n",
      "Epoch 4714, Loss: 0.00039810596354072914, Final Batch Loss: 7.405837095575407e-05\n",
      "Epoch 4715, Loss: 0.0004853711507166736, Final Batch Loss: 6.123586354078725e-05\n",
      "Epoch 4716, Loss: 0.0006807941463193856, Final Batch Loss: 2.152162414859049e-05\n",
      "Epoch 4717, Loss: 0.00020247411339369137, Final Batch Loss: 1.6008389138733037e-05\n",
      "Epoch 4718, Loss: 0.0003280991095380159, Final Batch Loss: 2.5499810362816788e-05\n",
      "Epoch 4719, Loss: 0.00011696273941197433, Final Batch Loss: 4.921901927446015e-05\n",
      "Epoch 4720, Loss: 0.00016419504936493468, Final Batch Loss: 9.782985216588713e-06\n",
      "Epoch 4721, Loss: 0.0005880038042960223, Final Batch Loss: 2.505893280613236e-05\n",
      "Epoch 4722, Loss: 0.00012831506228394574, Final Batch Loss: 1.6453832358820364e-05\n",
      "Epoch 4723, Loss: 0.0006947795191081241, Final Batch Loss: 0.00014941692643333226\n",
      "Epoch 4724, Loss: 9.838423102337401e-05, Final Batch Loss: 7.787193680997007e-06\n",
      "Epoch 4725, Loss: 0.0005754474059358472, Final Batch Loss: 1.707478986645583e-05\n",
      "Epoch 4726, Loss: 0.001055625073149713, Final Batch Loss: 2.6273069124727044e-06\n",
      "Epoch 4727, Loss: 0.001057454621331999, Final Batch Loss: 0.000952325644902885\n",
      "Epoch 4728, Loss: 7.369820559688378e-05, Final Batch Loss: 1.3761444279225543e-05\n",
      "Epoch 4729, Loss: 0.00032018098499975167, Final Batch Loss: 7.580536475870758e-05\n",
      "Epoch 4730, Loss: 0.00031169940848485567, Final Batch Loss: 6.442731682909653e-05\n",
      "Epoch 4731, Loss: 9.256925477529876e-05, Final Batch Loss: 5.217595025897026e-05\n",
      "Epoch 4732, Loss: 0.00011878828081535175, Final Batch Loss: 4.9377667892258614e-06\n",
      "Epoch 4733, Loss: 0.0008635521153337322, Final Batch Loss: 8.723757491679862e-05\n",
      "Epoch 4734, Loss: 6.073117219784763e-05, Final Batch Loss: 8.406588676734827e-06\n",
      "Epoch 4735, Loss: 3.865199960273458e-05, Final Batch Loss: 2.2245303625823e-06\n",
      "Epoch 4736, Loss: 0.00018828547808880103, Final Batch Loss: 4.821755737793865e-06\n",
      "Epoch 4737, Loss: 0.00017753303654899355, Final Batch Loss: 1.868341860244982e-05\n",
      "Epoch 4738, Loss: 0.00043797099078801693, Final Batch Loss: 7.714178536843974e-06\n",
      "Epoch 4739, Loss: 5.994928096697549e-05, Final Batch Loss: 1.0462237696629018e-05\n",
      "Epoch 4740, Loss: 7.722874761384446e-05, Final Batch Loss: 4.323269968153909e-05\n",
      "Epoch 4741, Loss: 0.0001721473752240854, Final Batch Loss: 3.0819715902907774e-05\n",
      "Epoch 4742, Loss: 0.00011374463656466105, Final Batch Loss: 6.963189207453979e-06\n",
      "Epoch 4743, Loss: 8.208223880501464e-05, Final Batch Loss: 3.017973904206883e-05\n",
      "Epoch 4744, Loss: 0.001385864085477806, Final Batch Loss: 0.0013035698793828487\n",
      "Epoch 4745, Loss: 0.00022248402683544555, Final Batch Loss: 3.345298409840325e-06\n",
      "Epoch 4746, Loss: 0.0006905006439410499, Final Batch Loss: 9.465306902711745e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4747, Loss: 0.00041574636543373344, Final Batch Loss: 1.109710046875989e-05\n",
      "Epoch 4748, Loss: 0.00047599998652003706, Final Batch Loss: 3.784511500271037e-05\n",
      "Epoch 4749, Loss: 9.270150280826783e-05, Final Batch Loss: 1.4626773008785676e-05\n",
      "Epoch 4750, Loss: 0.00013804187892674236, Final Batch Loss: 1.3221969311416615e-05\n",
      "Epoch 4751, Loss: 0.00020926055913150776, Final Batch Loss: 7.055053720250726e-05\n",
      "Epoch 4752, Loss: 0.00032655960751526436, Final Batch Loss: 1.1507341923788772e-06\n",
      "Epoch 4753, Loss: 0.00012084412264812272, Final Batch Loss: 3.312172702862881e-05\n",
      "Epoch 4754, Loss: 8.087160131253768e-05, Final Batch Loss: 1.3997825590195134e-05\n",
      "Epoch 4755, Loss: 0.0005408252204688324, Final Batch Loss: 5.208656602917472e-06\n",
      "Epoch 4756, Loss: 0.0002469463179295417, Final Batch Loss: 0.00021477956033777446\n",
      "Epoch 4757, Loss: 8.196605631383136e-05, Final Batch Loss: 2.948331712104846e-06\n",
      "Epoch 4758, Loss: 0.0002708219672058476, Final Batch Loss: 2.3038137442199513e-05\n",
      "Epoch 4759, Loss: 0.0002500540631444892, Final Batch Loss: 5.7949826441472396e-05\n",
      "Epoch 4760, Loss: 0.00024200963434850564, Final Batch Loss: 0.0002215811691712588\n",
      "Epoch 4761, Loss: 0.00011945276969527185, Final Batch Loss: 1.826539346438949e-06\n",
      "Epoch 4762, Loss: 9.628969883124228e-05, Final Batch Loss: 4.317978437029524e-06\n",
      "Epoch 4763, Loss: 0.0009331883011327591, Final Batch Loss: 0.0005974035011604428\n",
      "Epoch 4764, Loss: 0.001173107470094692, Final Batch Loss: 7.022869976935908e-05\n",
      "Epoch 4765, Loss: 0.020635790094274853, Final Batch Loss: 6.5423528212704696e-06\n",
      "Epoch 4766, Loss: 6.572130678250687e-05, Final Batch Loss: 1.387834254273912e-05\n",
      "Epoch 4767, Loss: 5.746896113123512e-05, Final Batch Loss: 1.790198621165473e-05\n",
      "Epoch 4768, Loss: 0.0002032280262938002, Final Batch Loss: 3.0231476557673886e-06\n",
      "Epoch 4769, Loss: 0.00018075309071718948, Final Batch Loss: 6.0997253967798315e-06\n",
      "Epoch 4770, Loss: 0.0002194672870245995, Final Batch Loss: 1.8080811059917323e-05\n",
      "Epoch 4771, Loss: 0.007656972617041902, Final Batch Loss: 2.7105697881779633e-05\n",
      "Epoch 4772, Loss: 0.005045917932875454, Final Batch Loss: 0.001084282179363072\n",
      "Epoch 4773, Loss: 0.0008334671620104928, Final Batch Loss: 4.5721757487626746e-05\n",
      "Epoch 4774, Loss: 0.004772677406435832, Final Batch Loss: 6.191382999531925e-05\n",
      "Epoch 4775, Loss: 0.00011811296258201764, Final Batch Loss: 2.0072855022590375e-06\n",
      "Epoch 4776, Loss: 0.0004899982377537526, Final Batch Loss: 0.00027684145607054234\n",
      "Epoch 4777, Loss: 0.00016675870028848294, Final Batch Loss: 2.4074097382253967e-05\n",
      "Epoch 4778, Loss: 0.0001492406754550757, Final Batch Loss: 4.7787245421204716e-05\n",
      "Epoch 4779, Loss: 0.0002688260592549341, Final Batch Loss: 7.465005910489708e-05\n",
      "Epoch 4780, Loss: 0.01197091995345545, Final Batch Loss: 0.011823202483355999\n",
      "Epoch 4781, Loss: 0.00019298614643048495, Final Batch Loss: 0.00010305454634362832\n",
      "Epoch 4782, Loss: 0.00030125711964501534, Final Batch Loss: 0.00018737989012151957\n",
      "Epoch 4783, Loss: 0.0011198110432815156, Final Batch Loss: 1.965457522601355e-05\n",
      "Epoch 4784, Loss: 6.679828038613778e-05, Final Batch Loss: 1.5832545614102855e-05\n",
      "Epoch 4785, Loss: 0.0028656875983870123, Final Batch Loss: 0.00013077605399303138\n",
      "Epoch 4786, Loss: 0.005301690209307708, Final Batch Loss: 8.873023034539074e-06\n",
      "Epoch 4787, Loss: 0.00027649510616356565, Final Batch Loss: 1.6487752873217687e-05\n",
      "Epoch 4788, Loss: 0.00042714176925073843, Final Batch Loss: 0.00022860824537929147\n",
      "Epoch 4789, Loss: 0.0006507560392492451, Final Batch Loss: 1.157298538601026e-05\n",
      "Epoch 4790, Loss: 0.0008539269747416256, Final Batch Loss: 1.6477742974529974e-05\n",
      "Epoch 4791, Loss: 0.0022378381290764082, Final Batch Loss: 2.4577620933996513e-05\n",
      "Epoch 4792, Loss: 0.0009712647370179184, Final Batch Loss: 0.0005999220302328467\n",
      "Epoch 4793, Loss: 0.00017274991114391014, Final Batch Loss: 5.256577787804417e-05\n",
      "Epoch 4794, Loss: 0.00021439196689243545, Final Batch Loss: 0.00017871898307930678\n",
      "Epoch 4795, Loss: 0.00018419345178699587, Final Batch Loss: 3.0301791412057355e-05\n",
      "Epoch 4796, Loss: 0.0001840855393311358, Final Batch Loss: 6.279408989939839e-05\n",
      "Epoch 4797, Loss: 0.00023721148863842245, Final Batch Loss: 0.00017475495405960828\n",
      "Epoch 4798, Loss: 0.00012960538879269734, Final Batch Loss: 5.692114427802153e-05\n",
      "Epoch 4799, Loss: 0.0034534538768866696, Final Batch Loss: 1.3228142279331223e-06\n",
      "Epoch 4800, Loss: 0.00012002080711681629, Final Batch Loss: 1.1371595064701978e-05\n",
      "Epoch 4801, Loss: 0.0007809501212250325, Final Batch Loss: 1.1669030755001586e-05\n",
      "Epoch 4802, Loss: 7.442373180310824e-05, Final Batch Loss: 6.018146450514905e-05\n",
      "Epoch 4803, Loss: 1.895389232231537e-05, Final Batch Loss: 2.475362634868361e-06\n",
      "Epoch 4804, Loss: 0.0028498773572209757, Final Batch Loss: 0.002712245099246502\n",
      "Epoch 4805, Loss: 8.959665728980326e-05, Final Batch Loss: 1.4775308045500424e-05\n",
      "Epoch 4806, Loss: 0.00032759495206846623, Final Batch Loss: 2.3792988940840587e-05\n",
      "Epoch 4807, Loss: 0.0003963939082041179, Final Batch Loss: 2.489783764758613e-05\n",
      "Epoch 4808, Loss: 9.005929587146966e-05, Final Batch Loss: 1.2539995623228606e-05\n",
      "Epoch 4809, Loss: 2.6548751748123323e-05, Final Batch Loss: 3.3761500617401907e-06\n",
      "Epoch 4810, Loss: 5.177592447580537e-05, Final Batch Loss: 2.9776572773698717e-05\n",
      "Epoch 4811, Loss: 0.00024172834810087807, Final Batch Loss: 7.243209893204039e-06\n",
      "Epoch 4812, Loss: 4.904036086372798e-05, Final Batch Loss: 4.351722964202054e-06\n",
      "Epoch 4813, Loss: 4.840767201130802e-05, Final Batch Loss: 2.823435579557554e-06\n",
      "Epoch 4814, Loss: 7.26692828720843e-05, Final Batch Loss: 1.585033351148013e-05\n",
      "Epoch 4815, Loss: 8.471299588563852e-05, Final Batch Loss: 1.3630016837851144e-05\n",
      "Epoch 4816, Loss: 0.00010444824738442549, Final Batch Loss: 8.993968367576599e-05\n",
      "Epoch 4817, Loss: 9.444669012736995e-05, Final Batch Loss: 1.6560637959628366e-05\n",
      "Epoch 4818, Loss: 0.00021011301714679576, Final Batch Loss: 5.396952838054858e-05\n",
      "Epoch 4819, Loss: 1.057472013599181e-05, Final Batch Loss: 1.9341741790412925e-06\n",
      "Epoch 4820, Loss: 0.00016611649061815115, Final Batch Loss: 3.5401688364800066e-05\n",
      "Epoch 4821, Loss: 0.001606052815077419, Final Batch Loss: 8.32015120977303e-06\n",
      "Epoch 4822, Loss: 0.0001407030904374551, Final Batch Loss: 9.681250958237797e-05\n",
      "Epoch 4823, Loss: 3.9048120015650056e-05, Final Batch Loss: 8.39819767861627e-06\n",
      "Epoch 4824, Loss: 6.438650052587036e-05, Final Batch Loss: 1.774256998032797e-05\n",
      "Epoch 4825, Loss: 0.0005653745274685207, Final Batch Loss: 3.2915477277128957e-06\n",
      "Epoch 4826, Loss: 3.867167424687068e-05, Final Batch Loss: 1.0104851753567345e-05\n",
      "Epoch 4827, Loss: 0.00019358079407538753, Final Batch Loss: 1.8589067622087896e-05\n",
      "Epoch 4828, Loss: 6.889283758937381e-05, Final Batch Loss: 2.5516794266877696e-05\n",
      "Epoch 4829, Loss: 3.0335820383697865e-05, Final Batch Loss: 1.4045128864381695e-06\n",
      "Epoch 4830, Loss: 8.010453302631504e-05, Final Batch Loss: 8.020561836019624e-06\n",
      "Epoch 4831, Loss: 4.98681320095784e-05, Final Batch Loss: 8.714744581084233e-06\n",
      "Epoch 4832, Loss: 0.0008582199111515365, Final Batch Loss: 7.19057743481244e-06\n",
      "Epoch 4833, Loss: 0.00019553638583147404, Final Batch Loss: 1.898630102914467e-06\n",
      "Epoch 4834, Loss: 0.00013919000730311382, Final Batch Loss: 7.951657607918605e-05\n",
      "Epoch 4835, Loss: 0.00019035719287785469, Final Batch Loss: 1.133263413066743e-05\n",
      "Epoch 4836, Loss: 0.00019502428767737, Final Batch Loss: 6.0967162426095456e-05\n",
      "Epoch 4837, Loss: 0.0005297719453665195, Final Batch Loss: 6.175069756864104e-06\n",
      "Epoch 4838, Loss: 4.2115199903491884e-05, Final Batch Loss: 1.0823247066582553e-05\n",
      "Epoch 4839, Loss: 5.4537717915081885e-05, Final Batch Loss: 2.180492265324574e-05\n",
      "Epoch 4840, Loss: 0.00016098474861792056, Final Batch Loss: 1.4112529242993332e-06\n",
      "Epoch 4841, Loss: 0.0003607494254538324, Final Batch Loss: 0.00010824740456882864\n",
      "Epoch 4842, Loss: 0.00014594233198295115, Final Batch Loss: 0.00011663870100164786\n",
      "Epoch 4843, Loss: 8.676440756971715e-05, Final Batch Loss: 2.248353121103719e-05\n",
      "Epoch 4844, Loss: 0.00018945447982332553, Final Batch Loss: 9.170755947707221e-05\n",
      "Epoch 4845, Loss: 0.00031540627605863847, Final Batch Loss: 0.00020920578390359879\n",
      "Epoch 4846, Loss: 0.00011297797823317524, Final Batch Loss: 1.5304669886972988e-06\n",
      "Epoch 4847, Loss: 0.0018518969427532284, Final Batch Loss: 4.557224383461289e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4848, Loss: 0.00013462985953083262, Final Batch Loss: 6.219387432793155e-05\n",
      "Epoch 4849, Loss: 0.011204798458493315, Final Batch Loss: 0.0001787596702342853\n",
      "Epoch 4850, Loss: 5.9384625501479604e-05, Final Batch Loss: 5.831621820107102e-06\n",
      "Epoch 4851, Loss: 6.66325709062221e-05, Final Batch Loss: 2.80602534985519e-06\n",
      "Epoch 4852, Loss: 0.0001048982517204422, Final Batch Loss: 5.30197894477169e-06\n",
      "Epoch 4853, Loss: 0.0035103036352666095, Final Batch Loss: 0.0001859363983385265\n",
      "Epoch 4854, Loss: 0.010930599607490876, Final Batch Loss: 9.08635320229223e-06\n",
      "Epoch 4855, Loss: 8.246825473179342e-05, Final Batch Loss: 5.345251702237874e-05\n",
      "Epoch 4856, Loss: 7.391153758362634e-05, Final Batch Loss: 2.060449514829088e-05\n",
      "Epoch 4857, Loss: 0.00010737769753177417, Final Batch Loss: 7.707690201641526e-06\n",
      "Epoch 4858, Loss: 0.012818944491300499, Final Batch Loss: 0.012614917941391468\n",
      "Epoch 4859, Loss: 0.0012182376144664886, Final Batch Loss: 4.623832410288742e-06\n",
      "Epoch 4860, Loss: 5.1414573135843966e-05, Final Batch Loss: 1.6467303794343024e-05\n",
      "Epoch 4861, Loss: 0.0004077119624525949, Final Batch Loss: 0.0003551915579009801\n",
      "Epoch 4862, Loss: 0.00023031545879348414, Final Batch Loss: 2.278245119669009e-06\n",
      "Epoch 4863, Loss: 0.0006026173487043707, Final Batch Loss: 6.240186849026941e-06\n",
      "Epoch 4864, Loss: 0.00027259306034466135, Final Batch Loss: 0.00012318816152401268\n",
      "Epoch 4865, Loss: 2.73191483302071e-05, Final Batch Loss: 3.4790184599842178e-06\n",
      "Epoch 4866, Loss: 3.12421270791674e-05, Final Batch Loss: 7.632731467310805e-06\n",
      "Epoch 4867, Loss: 0.00021156042635084304, Final Batch Loss: 1.8130783701053588e-06\n",
      "Epoch 4868, Loss: 2.959628818643978e-05, Final Batch Loss: 9.615970157028642e-06\n",
      "Epoch 4869, Loss: 0.0001823877428250853, Final Batch Loss: 4.629475370165892e-06\n",
      "Epoch 4870, Loss: 8.888901174941566e-05, Final Batch Loss: 1.3342600141186267e-05\n",
      "Epoch 4871, Loss: 0.00038083784875198035, Final Batch Loss: 5.363875061448198e-06\n",
      "Epoch 4872, Loss: 0.0014714837016072124, Final Batch Loss: 4.9203365051653236e-05\n",
      "Epoch 4873, Loss: 0.00045297503675101325, Final Batch Loss: 0.0003106315853074193\n",
      "Epoch 4874, Loss: 0.0007627008535564528, Final Batch Loss: 1.3870910152036231e-05\n",
      "Epoch 4875, Loss: 2.6212930606561713e-05, Final Batch Loss: 9.021047844726127e-06\n",
      "Epoch 4876, Loss: 0.0008294170429508085, Final Batch Loss: 0.0007881591445766389\n",
      "Epoch 4877, Loss: 5.303381055909995e-05, Final Batch Loss: 1.3670254475073307e-06\n",
      "Epoch 4878, Loss: 5.5430804081879614e-05, Final Batch Loss: 4.8821668315213174e-05\n",
      "Epoch 4879, Loss: 6.295696391589445e-05, Final Batch Loss: 9.584508688931237e-07\n",
      "Epoch 4880, Loss: 0.00010085281519423006, Final Batch Loss: 2.6901821911451407e-05\n",
      "Epoch 4881, Loss: 0.0010164392115257215, Final Batch Loss: 0.00016035058069974184\n",
      "Epoch 4882, Loss: 0.022582426965527702, Final Batch Loss: 2.8783419111277908e-05\n",
      "Epoch 4883, Loss: 7.517686594837869e-05, Final Batch Loss: 4.2806361307157204e-05\n",
      "Epoch 4884, Loss: 7.912003638921306e-05, Final Batch Loss: 3.324222780065611e-05\n",
      "Epoch 4885, Loss: 0.00027680230004989426, Final Batch Loss: 0.00017414636386092752\n",
      "Epoch 4886, Loss: 0.0004915892022836488, Final Batch Loss: 0.0001493310701334849\n",
      "Epoch 4887, Loss: 0.003382041493750876, Final Batch Loss: 0.003340422408655286\n",
      "Epoch 4888, Loss: 9.1367905952211e-05, Final Batch Loss: 5.825563130201772e-05\n",
      "Epoch 4889, Loss: 0.0019493597692417097, Final Batch Loss: 9.05713841348188e-06\n",
      "Epoch 4890, Loss: 8.674244054418523e-05, Final Batch Loss: 6.0737547755707055e-05\n",
      "Epoch 4891, Loss: 0.00023461385171685833, Final Batch Loss: 4.8277936002705246e-05\n",
      "Epoch 4892, Loss: 0.0013595475220427033, Final Batch Loss: 1.4087800991546828e-05\n",
      "Epoch 4893, Loss: 0.00036422691300685983, Final Batch Loss: 5.061081537860446e-06\n",
      "Epoch 4894, Loss: 8.233656626543961e-05, Final Batch Loss: 3.737258157343604e-05\n",
      "Epoch 4895, Loss: 0.004065728335262975, Final Batch Loss: 0.004008632153272629\n",
      "Epoch 4896, Loss: 0.0007191362913090416, Final Batch Loss: 6.942107575014234e-06\n",
      "Epoch 4897, Loss: 6.333446742701199e-05, Final Batch Loss: 1.9227252323616995e-07\n",
      "Epoch 4898, Loss: 4.616924979927717e-05, Final Batch Loss: 2.9456512493197806e-05\n",
      "Epoch 4899, Loss: 0.00013936505797573773, Final Batch Loss: 1.1391691714379704e-06\n",
      "Epoch 4900, Loss: 0.02704758573509025, Final Batch Loss: 3.912017746188212e-06\n",
      "Epoch 4901, Loss: 0.0002370627953496296, Final Batch Loss: 9.285755368182436e-06\n",
      "Epoch 4902, Loss: 4.514763168117497e-05, Final Batch Loss: 3.901763193425722e-06\n",
      "Epoch 4903, Loss: 7.516242612837232e-05, Final Batch Loss: 6.622972705372376e-06\n",
      "Epoch 4904, Loss: 0.00019328306370880455, Final Batch Loss: 0.00012617856555152684\n",
      "Epoch 4905, Loss: 0.0014358041535160737, Final Batch Loss: 0.0013790061930194497\n",
      "Epoch 4906, Loss: 0.0010710839001148997, Final Batch Loss: 4.411502686707536e-06\n",
      "Epoch 4907, Loss: 3.537085558491526e-05, Final Batch Loss: 1.2647665244003292e-05\n",
      "Epoch 4908, Loss: 0.0005300074535625754, Final Batch Loss: 3.939373709727079e-05\n",
      "Epoch 4909, Loss: 0.000187279106285132, Final Batch Loss: 0.00016399247397202998\n",
      "Epoch 4910, Loss: 0.0001618807555132662, Final Batch Loss: 8.391057053813711e-05\n",
      "Epoch 4911, Loss: 1.992302804865176e-05, Final Batch Loss: 5.1617275858006906e-06\n",
      "Epoch 4912, Loss: 0.006929045703145675, Final Batch Loss: 3.897307033184916e-05\n",
      "Epoch 4913, Loss: 0.0003823689476121217, Final Batch Loss: 6.5729736888897605e-06\n",
      "Epoch 4914, Loss: 0.000180636954610236, Final Batch Loss: 8.114999218378216e-06\n",
      "Epoch 4915, Loss: 9.86771124189545e-05, Final Batch Loss: 5.5981113291636575e-06\n",
      "Epoch 4916, Loss: 0.004652884994357009, Final Batch Loss: 2.2726593670086004e-05\n",
      "Epoch 4917, Loss: 5.071718896942912e-05, Final Batch Loss: 2.5227052901755087e-05\n",
      "Epoch 4918, Loss: 8.911776967579499e-05, Final Batch Loss: 1.6275553207378834e-06\n",
      "Epoch 4919, Loss: 0.00021284769354679156, Final Batch Loss: 2.943095751106739e-05\n",
      "Epoch 4920, Loss: 0.0002529905502797192, Final Batch Loss: 2.85025794255489e-06\n",
      "Epoch 4921, Loss: 8.906855873647146e-05, Final Batch Loss: 7.306702173082158e-06\n",
      "Epoch 4922, Loss: 0.00029511888351407833, Final Batch Loss: 4.958112185704522e-05\n",
      "Epoch 4923, Loss: 0.00012708241365544382, Final Batch Loss: 0.00011256991274422035\n",
      "Epoch 4924, Loss: 0.00023826436699891929, Final Batch Loss: 0.00015358267410192639\n",
      "Epoch 4925, Loss: 7.334068141062744e-05, Final Batch Loss: 1.6251256965915672e-05\n",
      "Epoch 4926, Loss: 0.00014197841778695874, Final Batch Loss: 3.1444553769688355e-06\n",
      "Epoch 4927, Loss: 0.03389426084186198, Final Batch Loss: 2.7590053832682315e-06\n",
      "Epoch 4928, Loss: 0.00017411869066563668, Final Batch Loss: 1.0142092833120842e-05\n",
      "Epoch 4929, Loss: 0.0004533945775619941, Final Batch Loss: 5.087731551611796e-05\n",
      "Epoch 4930, Loss: 0.00035839165866491385, Final Batch Loss: 5.8228968555340543e-05\n",
      "Epoch 4931, Loss: 0.0010512849548831582, Final Batch Loss: 0.0001334594562649727\n",
      "Epoch 4932, Loss: 0.0010892354766838253, Final Batch Loss: 0.0007052774308249354\n",
      "Epoch 4933, Loss: 0.0011072213237639517, Final Batch Loss: 3.209701390005648e-05\n",
      "Epoch 4934, Loss: 0.021606813766993582, Final Batch Loss: 0.0004202352138236165\n",
      "Epoch 4935, Loss: 0.0023837087278479885, Final Batch Loss: 0.0014536139788106084\n",
      "Epoch 4936, Loss: 0.020852640018063084, Final Batch Loss: 6.614151857320394e-07\n",
      "Epoch 4937, Loss: 0.0006268596989684738, Final Batch Loss: 0.00013021370978094637\n",
      "Epoch 4938, Loss: 9.892898242469528e-05, Final Batch Loss: 6.534816293424228e-06\n",
      "Epoch 4939, Loss: 0.0002756451774530433, Final Batch Loss: 1.3712116015085485e-05\n",
      "Epoch 4940, Loss: 0.0003268078435212374, Final Batch Loss: 3.4983349905814976e-05\n",
      "Epoch 4941, Loss: 3.186901631124783e-05, Final Batch Loss: 1.5819488908164203e-05\n",
      "Epoch 4942, Loss: 0.005277164595099748, Final Batch Loss: 7.6200783951208e-05\n",
      "Epoch 4943, Loss: 0.0008430749594481313, Final Batch Loss: 5.452172990771942e-05\n",
      "Epoch 4944, Loss: 5.240963560027012e-05, Final Batch Loss: 3.26615440826572e-06\n",
      "Epoch 4945, Loss: 0.00019074790543527342, Final Batch Loss: 2.641328683239408e-05\n",
      "Epoch 4946, Loss: 0.004072458067867046, Final Batch Loss: 3.063737722186488e-06\n",
      "Epoch 4947, Loss: 0.0003900227569886283, Final Batch Loss: 1.1632474183898012e-07\n",
      "Epoch 4948, Loss: 2.242014761577593e-05, Final Batch Loss: 5.211058123677503e-06\n",
      "Epoch 4949, Loss: 0.006820792453254398, Final Batch Loss: 1.4238566109270323e-05\n",
      "Epoch 4950, Loss: 0.00011259603297730791, Final Batch Loss: 4.524099040281726e-06\n",
      "Epoch 4951, Loss: 0.0010842977771972073, Final Batch Loss: 1.9367986169527285e-05\n",
      "Epoch 4952, Loss: 0.009540733701214776, Final Batch Loss: 9.988216334022582e-07\n",
      "Epoch 4953, Loss: 0.00030796518694842234, Final Batch Loss: 5.544921805267222e-05\n",
      "Epoch 4954, Loss: 0.0012408391698954802, Final Batch Loss: 6.518682766909478e-06\n",
      "Epoch 4955, Loss: 1.703279281173309e-05, Final Batch Loss: 1.9802744191110833e-06\n",
      "Epoch 4956, Loss: 0.0007739276243228232, Final Batch Loss: 1.3650265827891417e-05\n",
      "Epoch 4957, Loss: 0.00026459054788574576, Final Batch Loss: 6.236063200049102e-05\n",
      "Epoch 4958, Loss: 0.00040150092308977037, Final Batch Loss: 2.2966028154769447e-06\n",
      "Epoch 4959, Loss: 0.0001580556518092635, Final Batch Loss: 0.00011264364729868248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4960, Loss: 0.0025310521050414536, Final Batch Loss: 1.5147616068134084e-05\n",
      "Epoch 4961, Loss: 0.0011323230482958024, Final Batch Loss: 0.0010007860837504268\n",
      "Epoch 4962, Loss: 0.0007829868318367517, Final Batch Loss: 1.1591995644266717e-05\n",
      "Epoch 4963, Loss: 0.00019909186084987596, Final Batch Loss: 2.435763417452108e-05\n",
      "Epoch 4964, Loss: 0.00011966903684879071, Final Batch Loss: 7.3393399361521e-05\n",
      "Epoch 4965, Loss: 6.724739967012283e-05, Final Batch Loss: 4.841541522182524e-05\n",
      "Epoch 4966, Loss: 0.0005188809400351602, Final Batch Loss: 8.179121505236253e-05\n",
      "Epoch 4967, Loss: 3.546815287336358e-05, Final Batch Loss: 1.847618113970384e-05\n",
      "Epoch 4968, Loss: 2.8607332524188678e-05, Final Batch Loss: 1.8735376215772703e-05\n",
      "Epoch 4969, Loss: 0.00011937878002754587, Final Batch Loss: 4.470812200452201e-05\n",
      "Epoch 4970, Loss: 5.134458388056373e-05, Final Batch Loss: 3.0265588065958582e-05\n",
      "Epoch 4971, Loss: 4.824957522941986e-05, Final Batch Loss: 1.0993689102178905e-05\n",
      "Epoch 4972, Loss: 0.0001578397850607871, Final Batch Loss: 0.0001089003708329983\n",
      "Epoch 4973, Loss: 8.364680797967594e-05, Final Batch Loss: 3.206345718353987e-05\n",
      "Epoch 4974, Loss: 0.0013761305517334677, Final Batch Loss: 3.451250165653619e-07\n",
      "Epoch 4975, Loss: 9.305606317866477e-05, Final Batch Loss: 1.0824683158716653e-06\n",
      "Epoch 4976, Loss: 6.009952903696103e-05, Final Batch Loss: 2.7107951609650627e-05\n",
      "Epoch 4977, Loss: 0.00037683837217628025, Final Batch Loss: 0.00015244187670759857\n",
      "Epoch 4978, Loss: 0.00011207038016891602, Final Batch Loss: 3.1078807296580635e-06\n",
      "Epoch 4979, Loss: 0.0001301422653341433, Final Batch Loss: 0.00011496727529447526\n",
      "Epoch 4980, Loss: 0.000275146971034701, Final Batch Loss: 4.576473656925373e-06\n",
      "Epoch 4981, Loss: 9.663392029324314e-05, Final Batch Loss: 1.1260211067565251e-05\n",
      "Epoch 4982, Loss: 0.00010582849790807813, Final Batch Loss: 7.396761066047475e-05\n",
      "Epoch 4983, Loss: 0.00023061596402840223, Final Batch Loss: 0.00012691415031440556\n",
      "Epoch 4984, Loss: 0.0015402936442114878, Final Batch Loss: 0.0015063193859532475\n",
      "Epoch 4985, Loss: 0.00044520482333609834, Final Batch Loss: 0.00012589884863700718\n",
      "Epoch 4986, Loss: 0.00015584744511443205, Final Batch Loss: 6.469927598118375e-07\n",
      "Epoch 4987, Loss: 6.973852714509121e-05, Final Batch Loss: 5.936989964538952e-06\n",
      "Epoch 4988, Loss: 8.956405804383394e-05, Final Batch Loss: 3.734571237146156e-06\n",
      "Epoch 4989, Loss: 0.06368009762809379, Final Batch Loss: 0.0636608898639679\n",
      "Epoch 4990, Loss: 0.0013220719840774109, Final Batch Loss: 0.0013065265957266092\n",
      "Epoch 4991, Loss: 0.0004951730006723665, Final Batch Loss: 0.00044233424705453217\n",
      "Epoch 4992, Loss: 0.055013064284139546, Final Batch Loss: 0.05060875415802002\n",
      "Epoch 4993, Loss: 0.04353079969223472, Final Batch Loss: 1.2313725164858624e-05\n",
      "Epoch 4994, Loss: 0.0010985954650095664, Final Batch Loss: 0.00010456468589836732\n",
      "Epoch 4995, Loss: 0.0010316985608369578, Final Batch Loss: 3.242926686652936e-05\n",
      "Epoch 4996, Loss: 0.0065561046394577716, Final Batch Loss: 7.002195343375206e-05\n",
      "Epoch 4997, Loss: 0.013693699300347362, Final Batch Loss: 0.013553778640925884\n",
      "Epoch 4998, Loss: 0.004920525330817327, Final Batch Loss: 0.0032579791732132435\n",
      "Epoch 4999, Loss: 0.0001775818445821642, Final Batch Loss: 7.426525371556636e-06\n",
      "Epoch 5000, Loss: 0.0013226929550000932, Final Batch Loss: 0.0012306174030527472\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62  2  0]\n",
      " [ 1 40  0]\n",
      " [ 0  0 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.98413   0.96875   0.97638        64\n",
      "           1    0.95238   0.97561   0.96386        41\n",
      "           2    1.00000   1.00000   1.00000        52\n",
      "\n",
      "    accuracy                        0.98089       157\n",
      "   macro avg    0.97884   0.98145   0.98008       157\n",
      "weighted avg    0.98109   0.98089   0.98093       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_1 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_2 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_3 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_4 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A0 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_5 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_1 = np.zeros(n_samples * 5)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_6 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_7 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_8 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_9 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A1 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_10 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_2 = np.ones(n_samples * 5)\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U0A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_11 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U1A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_12 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U2A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_13 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U3A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_14 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "gen = Generator(z_dim = 100)\n",
    "gen.eval()\n",
    "load_model(gen, \"U4A2 Solo GAN Ablation_gen.param\")\n",
    "latent_vectors = get_noise(n_samples, 100)\n",
    "fake_features_15 = gen(latent_vectors).detach().numpy()\n",
    "\n",
    "y_3 = np.ones(n_samples * 5) + 1\n",
    "\n",
    "fake_features = np.concatenate((fake_features_1, fake_features_2, fake_features_3, fake_features_4, fake_features_5, fake_features_6,\n",
    "                         fake_features_7, fake_features_8, fake_features_9, fake_features_10, fake_features_11, fake_features_12,\n",
    "                               fake_features_13, fake_features_14, fake_features_15))\n",
    "fake_labels = np.concatenate((y_1, y_2, y_3))\n",
    "\n",
    "fake_features = torch.Tensor(fake_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  3  0]\n",
      " [ 3 47  0]\n",
      " [ 0  0 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0    0.94000   0.94000   0.94000        50\n",
      "         1.0    0.94000   0.94000   0.94000        50\n",
      "         2.0    1.00000   1.00000   1.00000        50\n",
      "\n",
      "    accuracy                        0.96000       150\n",
      "   macro avg    0.96000   0.96000   0.96000       150\n",
      "weighted avg    0.96000   0.96000   0.96000       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix((fake_labels), preds.cpu()))\n",
    "print(metrics.classification_report((fake_labels), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = [1, 3, 4]\n",
    "users = [1, 3, 5, 7, 8]\n",
    "\n",
    "X, y = start_data(activities, users, \"Subject\", sub_features, act_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(y)):\n",
    "    if y[k] == 1:\n",
    "        y[k] = 0\n",
    "    elif y[k] == 3:\n",
    "        y[k] = 1\n",
    "    elif y[k] == 5:\n",
    "        y[k] = 2\n",
    "    elif y[k] == 7:\n",
    "        y[k] = 3\n",
    "    else:\n",
    "        y[k] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True)\n",
    "\n",
    "model_subject = Subject_Classifier()\n",
    "lr = 0.001\n",
    "n_epochs = 5000\n",
    "batch_size = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_subject.parameters(), lr = lr)\n",
    "\n",
    "train_features = torch.tensor(X_train)\n",
    "train_labels = torch.tensor(y_train)\n",
    "test_features = torch.tensor(X_test)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = len(test_labels), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.834184408187866, Final Batch Loss: 1.6053729057312012\n",
      "Epoch 2, Loss: 4.839436054229736, Final Batch Loss: 1.6326180696487427\n",
      "Epoch 3, Loss: 4.817689538002014, Final Batch Loss: 1.5912237167358398\n",
      "Epoch 4, Loss: 4.836143374443054, Final Batch Loss: 1.6288800239562988\n",
      "Epoch 5, Loss: 4.814775824546814, Final Batch Loss: 1.593578815460205\n",
      "Epoch 6, Loss: 4.809311270713806, Final Batch Loss: 1.5917668342590332\n",
      "Epoch 7, Loss: 4.815356373786926, Final Batch Loss: 1.6131302118301392\n",
      "Epoch 8, Loss: 4.8078086376190186, Final Batch Loss: 1.599535346031189\n",
      "Epoch 9, Loss: 4.80619752407074, Final Batch Loss: 1.5999796390533447\n",
      "Epoch 10, Loss: 4.8101547956466675, Final Batch Loss: 1.6124038696289062\n",
      "Epoch 11, Loss: 4.8039703369140625, Final Batch Loss: 1.6111074686050415\n",
      "Epoch 12, Loss: 4.802978277206421, Final Batch Loss: 1.6167726516723633\n",
      "Epoch 13, Loss: 4.7988070249557495, Final Batch Loss: 1.608424186706543\n",
      "Epoch 14, Loss: 4.78652036190033, Final Batch Loss: 1.604487657546997\n",
      "Epoch 15, Loss: 4.764805555343628, Final Batch Loss: 1.5751463174819946\n",
      "Epoch 16, Loss: 4.790214896202087, Final Batch Loss: 1.6111751794815063\n",
      "Epoch 17, Loss: 4.784841060638428, Final Batch Loss: 1.6200761795043945\n",
      "Epoch 18, Loss: 4.754531025886536, Final Batch Loss: 1.5659241676330566\n",
      "Epoch 19, Loss: 4.756540536880493, Final Batch Loss: 1.5909409523010254\n",
      "Epoch 20, Loss: 4.7451411485672, Final Batch Loss: 1.571530818939209\n",
      "Epoch 21, Loss: 4.744275450706482, Final Batch Loss: 1.5832693576812744\n",
      "Epoch 22, Loss: 4.726311922073364, Final Batch Loss: 1.569157361984253\n",
      "Epoch 23, Loss: 4.72138512134552, Final Batch Loss: 1.5632987022399902\n",
      "Epoch 24, Loss: 4.702820181846619, Final Batch Loss: 1.555908441543579\n",
      "Epoch 25, Loss: 4.709875583648682, Final Batch Loss: 1.5864347219467163\n",
      "Epoch 26, Loss: 4.65665602684021, Final Batch Loss: 1.53502357006073\n",
      "Epoch 27, Loss: 4.6607983112335205, Final Batch Loss: 1.5638208389282227\n",
      "Epoch 28, Loss: 4.608234882354736, Final Batch Loss: 1.5312230587005615\n",
      "Epoch 29, Loss: 4.618230223655701, Final Batch Loss: 1.5585036277770996\n",
      "Epoch 30, Loss: 4.549194574356079, Final Batch Loss: 1.4955739974975586\n",
      "Epoch 31, Loss: 4.553733468055725, Final Batch Loss: 1.529140591621399\n",
      "Epoch 32, Loss: 4.511134147644043, Final Batch Loss: 1.5055571794509888\n",
      "Epoch 33, Loss: 4.449694275856018, Final Batch Loss: 1.4644922018051147\n",
      "Epoch 34, Loss: 4.435728192329407, Final Batch Loss: 1.483400821685791\n",
      "Epoch 35, Loss: 4.33475923538208, Final Batch Loss: 1.403572916984558\n",
      "Epoch 36, Loss: 4.30764627456665, Final Batch Loss: 1.4561489820480347\n",
      "Epoch 37, Loss: 4.251590609550476, Final Batch Loss: 1.4115679264068604\n",
      "Epoch 38, Loss: 4.199578881263733, Final Batch Loss: 1.3794218301773071\n",
      "Epoch 39, Loss: 4.148327469825745, Final Batch Loss: 1.3098907470703125\n",
      "Epoch 40, Loss: 4.079339623451233, Final Batch Loss: 1.3143926858901978\n",
      "Epoch 41, Loss: 4.017316102981567, Final Batch Loss: 1.274532437324524\n",
      "Epoch 42, Loss: 3.989059090614319, Final Batch Loss: 1.3386207818984985\n",
      "Epoch 43, Loss: 3.9218595027923584, Final Batch Loss: 1.2537537813186646\n",
      "Epoch 44, Loss: 3.9336382150650024, Final Batch Loss: 1.2718236446380615\n",
      "Epoch 45, Loss: 3.790736436843872, Final Batch Loss: 1.2055792808532715\n",
      "Epoch 46, Loss: 3.7273095846176147, Final Batch Loss: 1.25816810131073\n",
      "Epoch 47, Loss: 3.696462869644165, Final Batch Loss: 1.2488023042678833\n",
      "Epoch 48, Loss: 3.674099564552307, Final Batch Loss: 1.225072979927063\n",
      "Epoch 49, Loss: 3.658139228820801, Final Batch Loss: 1.2619706392288208\n",
      "Epoch 50, Loss: 3.647668719291687, Final Batch Loss: 1.2444393634796143\n",
      "Epoch 51, Loss: 3.5301090478897095, Final Batch Loss: 1.1741557121276855\n",
      "Epoch 52, Loss: 3.4395971298217773, Final Batch Loss: 1.100803017616272\n",
      "Epoch 53, Loss: 3.475427508354187, Final Batch Loss: 1.1060930490493774\n",
      "Epoch 54, Loss: 3.462697386741638, Final Batch Loss: 1.1819233894348145\n",
      "Epoch 55, Loss: 3.4528058767318726, Final Batch Loss: 1.1273720264434814\n",
      "Epoch 56, Loss: 3.4485756158828735, Final Batch Loss: 1.158578634262085\n",
      "Epoch 57, Loss: 3.4515148401260376, Final Batch Loss: 1.186366081237793\n",
      "Epoch 58, Loss: 3.2672128081321716, Final Batch Loss: 0.9811472296714783\n",
      "Epoch 59, Loss: 3.305129647254944, Final Batch Loss: 1.1097301244735718\n",
      "Epoch 60, Loss: 3.315647006034851, Final Batch Loss: 1.160295844078064\n",
      "Epoch 61, Loss: 3.2366360425949097, Final Batch Loss: 1.0281856060028076\n",
      "Epoch 62, Loss: 3.2433820962905884, Final Batch Loss: 1.118606448173523\n",
      "Epoch 63, Loss: 3.1994097232818604, Final Batch Loss: 1.0394624471664429\n",
      "Epoch 64, Loss: 3.141284942626953, Final Batch Loss: 1.0094316005706787\n",
      "Epoch 65, Loss: 3.1756831407546997, Final Batch Loss: 1.0482264757156372\n",
      "Epoch 66, Loss: 3.1315335035324097, Final Batch Loss: 1.09816312789917\n",
      "Epoch 67, Loss: 3.1074284315109253, Final Batch Loss: 1.0377894639968872\n",
      "Epoch 68, Loss: 3.0738474130630493, Final Batch Loss: 1.0303866863250732\n",
      "Epoch 69, Loss: 3.1003592014312744, Final Batch Loss: 0.9882951974868774\n",
      "Epoch 70, Loss: 3.1278780698776245, Final Batch Loss: 1.1039440631866455\n",
      "Epoch 71, Loss: 3.145588457584381, Final Batch Loss: 1.144115924835205\n",
      "Epoch 72, Loss: 3.048423111438751, Final Batch Loss: 1.0781712532043457\n",
      "Epoch 73, Loss: 3.096465051174164, Final Batch Loss: 1.0716328620910645\n",
      "Epoch 74, Loss: 3.0528435707092285, Final Batch Loss: 1.0856176614761353\n",
      "Epoch 75, Loss: 2.9859349131584167, Final Batch Loss: 1.009487271308899\n",
      "Epoch 76, Loss: 2.986720323562622, Final Batch Loss: 0.9735010266304016\n",
      "Epoch 77, Loss: 2.9086835980415344, Final Batch Loss: 0.9058814644813538\n",
      "Epoch 78, Loss: 2.9779971837997437, Final Batch Loss: 1.0209743976593018\n",
      "Epoch 79, Loss: 2.954704761505127, Final Batch Loss: 1.0391225814819336\n",
      "Epoch 80, Loss: 2.830601155757904, Final Batch Loss: 0.8879318833351135\n",
      "Epoch 81, Loss: 2.864638924598694, Final Batch Loss: 0.9098753333091736\n",
      "Epoch 82, Loss: 2.8022027015686035, Final Batch Loss: 0.956916868686676\n",
      "Epoch 83, Loss: 2.903539001941681, Final Batch Loss: 0.9699089527130127\n",
      "Epoch 84, Loss: 2.8435972332954407, Final Batch Loss: 0.8709709644317627\n",
      "Epoch 85, Loss: 2.846169590950012, Final Batch Loss: 1.0210150480270386\n",
      "Epoch 86, Loss: 2.859316349029541, Final Batch Loss: 0.9899108409881592\n",
      "Epoch 87, Loss: 2.8836302757263184, Final Batch Loss: 0.9160468578338623\n",
      "Epoch 88, Loss: 2.7907270789146423, Final Batch Loss: 0.9140650629997253\n",
      "Epoch 89, Loss: 2.808888614177704, Final Batch Loss: 0.9143929481506348\n",
      "Epoch 90, Loss: 2.7443116903305054, Final Batch Loss: 0.8786816596984863\n",
      "Epoch 91, Loss: 2.7928024530410767, Final Batch Loss: 0.9655023217201233\n",
      "Epoch 92, Loss: 2.7615888714790344, Final Batch Loss: 0.8830406069755554\n",
      "Epoch 93, Loss: 2.756716549396515, Final Batch Loss: 0.9654978513717651\n",
      "Epoch 94, Loss: 2.697171628475189, Final Batch Loss: 0.887115478515625\n",
      "Epoch 95, Loss: 2.732507824897766, Final Batch Loss: 0.9467437267303467\n",
      "Epoch 96, Loss: 2.7182716131210327, Final Batch Loss: 0.9035515785217285\n",
      "Epoch 97, Loss: 2.663154184818268, Final Batch Loss: 0.866270899772644\n",
      "Epoch 98, Loss: 2.6335880160331726, Final Batch Loss: 0.8294893503189087\n",
      "Epoch 99, Loss: 2.7486602067947388, Final Batch Loss: 0.9105886816978455\n",
      "Epoch 100, Loss: 2.663662016391754, Final Batch Loss: 0.853448212146759\n",
      "Epoch 101, Loss: 2.6614941358566284, Final Batch Loss: 0.9832062721252441\n",
      "Epoch 102, Loss: 2.641381561756134, Final Batch Loss: 0.828875720500946\n",
      "Epoch 103, Loss: 2.6260083317756653, Final Batch Loss: 0.76078200340271\n",
      "Epoch 104, Loss: 2.67750746011734, Final Batch Loss: 0.9157416224479675\n",
      "Epoch 105, Loss: 2.618753969669342, Final Batch Loss: 0.8121746182441711\n",
      "Epoch 106, Loss: 2.6103671193122864, Final Batch Loss: 0.8409867882728577\n",
      "Epoch 107, Loss: 2.657662570476532, Final Batch Loss: 0.8606910109519958\n",
      "Epoch 108, Loss: 2.574092447757721, Final Batch Loss: 0.8166091442108154\n",
      "Epoch 109, Loss: 2.7743369936943054, Final Batch Loss: 1.020629644393921\n",
      "Epoch 110, Loss: 2.51157945394516, Final Batch Loss: 0.7758618593215942\n",
      "Epoch 111, Loss: 2.5461995005607605, Final Batch Loss: 0.8618508577346802\n",
      "Epoch 112, Loss: 2.4642133116722107, Final Batch Loss: 0.8021270036697388\n",
      "Epoch 113, Loss: 2.546986162662506, Final Batch Loss: 0.8468794226646423\n",
      "Epoch 114, Loss: 2.5587799549102783, Final Batch Loss: 0.8699008226394653\n",
      "Epoch 115, Loss: 2.5233518481254578, Final Batch Loss: 0.7764708399772644\n",
      "Epoch 116, Loss: 2.5080615878105164, Final Batch Loss: 0.7838793396949768\n",
      "Epoch 117, Loss: 2.479597568511963, Final Batch Loss: 0.7621431946754456\n",
      "Epoch 118, Loss: 2.5139618515968323, Final Batch Loss: 0.8554164171218872\n",
      "Epoch 119, Loss: 2.431235373020172, Final Batch Loss: 0.7336428761482239\n",
      "Epoch 120, Loss: 2.525784969329834, Final Batch Loss: 0.8962380290031433\n",
      "Epoch 121, Loss: 2.5617685317993164, Final Batch Loss: 0.8645037412643433\n",
      "Epoch 122, Loss: 2.6018404364585876, Final Batch Loss: 0.9414385557174683\n",
      "Epoch 123, Loss: 2.441673696041107, Final Batch Loss: 0.7712385058403015\n",
      "Epoch 124, Loss: 2.503474712371826, Final Batch Loss: 0.84058678150177\n",
      "Epoch 125, Loss: 2.5249494314193726, Final Batch Loss: 0.8552848696708679\n",
      "Epoch 126, Loss: 2.4234412908554077, Final Batch Loss: 0.7570908665657043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127, Loss: 2.459258019924164, Final Batch Loss: 0.8427100777626038\n",
      "Epoch 128, Loss: 2.408574104309082, Final Batch Loss: 0.7349541187286377\n",
      "Epoch 129, Loss: 2.4088306427001953, Final Batch Loss: 0.8089219331741333\n",
      "Epoch 130, Loss: 2.463410794734955, Final Batch Loss: 0.8505508303642273\n",
      "Epoch 131, Loss: 2.375169575214386, Final Batch Loss: 0.751697301864624\n",
      "Epoch 132, Loss: 2.3996938467025757, Final Batch Loss: 0.7617265582084656\n",
      "Epoch 133, Loss: 2.4642420411109924, Final Batch Loss: 0.8779067993164062\n",
      "Epoch 134, Loss: 2.408451795578003, Final Batch Loss: 0.7613816261291504\n",
      "Epoch 135, Loss: 2.400020480155945, Final Batch Loss: 0.8255825638771057\n",
      "Epoch 136, Loss: 2.322398364543915, Final Batch Loss: 0.7710760831832886\n",
      "Epoch 137, Loss: 2.4244235157966614, Final Batch Loss: 0.7490779757499695\n",
      "Epoch 138, Loss: 2.3357197642326355, Final Batch Loss: 0.8076683282852173\n",
      "Epoch 139, Loss: 2.4365898966789246, Final Batch Loss: 0.8571483492851257\n",
      "Epoch 140, Loss: 2.3424432277679443, Final Batch Loss: 0.730547308921814\n",
      "Epoch 141, Loss: 2.419106423854828, Final Batch Loss: 0.7983673810958862\n",
      "Epoch 142, Loss: 2.3625741600990295, Final Batch Loss: 0.770979106426239\n",
      "Epoch 143, Loss: 2.374292731285095, Final Batch Loss: 0.7922847867012024\n",
      "Epoch 144, Loss: 2.339626729488373, Final Batch Loss: 0.7795697450637817\n",
      "Epoch 145, Loss: 2.4263031482696533, Final Batch Loss: 0.9107558727264404\n",
      "Epoch 146, Loss: 2.3173453211784363, Final Batch Loss: 0.7670455574989319\n",
      "Epoch 147, Loss: 2.383536994457245, Final Batch Loss: 0.731178879737854\n",
      "Epoch 148, Loss: 2.2905664443969727, Final Batch Loss: 0.6964871883392334\n",
      "Epoch 149, Loss: 2.433982729911804, Final Batch Loss: 0.8893355131149292\n",
      "Epoch 150, Loss: 2.3670191168785095, Final Batch Loss: 0.8074191212654114\n",
      "Epoch 151, Loss: 2.4363434314727783, Final Batch Loss: 0.8852316737174988\n",
      "Epoch 152, Loss: 2.3839704394340515, Final Batch Loss: 0.8067991733551025\n",
      "Epoch 153, Loss: 2.3927900791168213, Final Batch Loss: 0.8999844789505005\n",
      "Epoch 154, Loss: 2.344910204410553, Final Batch Loss: 0.8107303380966187\n",
      "Epoch 155, Loss: 2.3655000925064087, Final Batch Loss: 0.8472829461097717\n",
      "Epoch 156, Loss: 2.3153072595596313, Final Batch Loss: 0.7536903023719788\n",
      "Epoch 157, Loss: 2.400897741317749, Final Batch Loss: 0.8641337752342224\n",
      "Epoch 158, Loss: 2.3941988945007324, Final Batch Loss: 0.8785347938537598\n",
      "Epoch 159, Loss: 2.338243842124939, Final Batch Loss: 0.8272747993469238\n",
      "Epoch 160, Loss: 2.352994918823242, Final Batch Loss: 0.8198444247245789\n",
      "Epoch 161, Loss: 2.273007035255432, Final Batch Loss: 0.82524174451828\n",
      "Epoch 162, Loss: 2.269795000553131, Final Batch Loss: 0.7669323682785034\n",
      "Epoch 163, Loss: 2.155934751033783, Final Batch Loss: 0.6692357063293457\n",
      "Epoch 164, Loss: 2.235155165195465, Final Batch Loss: 0.7555224299430847\n",
      "Epoch 165, Loss: 2.221254527568817, Final Batch Loss: 0.6975919008255005\n",
      "Epoch 166, Loss: 2.3284714221954346, Final Batch Loss: 0.8088092803955078\n",
      "Epoch 167, Loss: 2.2890005707740784, Final Batch Loss: 0.7938971519470215\n",
      "Epoch 168, Loss: 2.3403119444847107, Final Batch Loss: 0.7404883503913879\n",
      "Epoch 169, Loss: 2.230535626411438, Final Batch Loss: 0.7097977995872498\n",
      "Epoch 170, Loss: 2.335641384124756, Final Batch Loss: 0.7723777890205383\n",
      "Epoch 171, Loss: 2.285295009613037, Final Batch Loss: 0.7434555888175964\n",
      "Epoch 172, Loss: 2.2420743107795715, Final Batch Loss: 0.7567139863967896\n",
      "Epoch 173, Loss: 2.321168899536133, Final Batch Loss: 0.9129730463027954\n",
      "Epoch 174, Loss: 2.1959599256515503, Final Batch Loss: 0.7145760655403137\n",
      "Epoch 175, Loss: 2.1571404933929443, Final Batch Loss: 0.7111996412277222\n",
      "Epoch 176, Loss: 2.280484616756439, Final Batch Loss: 0.7884424924850464\n",
      "Epoch 177, Loss: 2.246643602848053, Final Batch Loss: 0.7831816077232361\n",
      "Epoch 178, Loss: 2.3208699226379395, Final Batch Loss: 0.8016334176063538\n",
      "Epoch 179, Loss: 2.316877007484436, Final Batch Loss: 0.7777179479598999\n",
      "Epoch 180, Loss: 2.253704845905304, Final Batch Loss: 0.7716351747512817\n",
      "Epoch 181, Loss: 2.2558260560035706, Final Batch Loss: 0.7981675863265991\n",
      "Epoch 182, Loss: 2.333435893058777, Final Batch Loss: 0.8599118590354919\n",
      "Epoch 183, Loss: 2.219600737094879, Final Batch Loss: 0.7392441630363464\n",
      "Epoch 184, Loss: 2.280624568462372, Final Batch Loss: 0.7910484671592712\n",
      "Epoch 185, Loss: 2.2428544759750366, Final Batch Loss: 0.8193023204803467\n",
      "Epoch 186, Loss: 2.185741126537323, Final Batch Loss: 0.7373558878898621\n",
      "Epoch 187, Loss: 2.1640411615371704, Final Batch Loss: 0.6595517992973328\n",
      "Epoch 188, Loss: 2.1585654616355896, Final Batch Loss: 0.779629111289978\n",
      "Epoch 189, Loss: 2.248462736606598, Final Batch Loss: 0.7535282373428345\n",
      "Epoch 190, Loss: 2.1106849312782288, Final Batch Loss: 0.6525314450263977\n",
      "Epoch 191, Loss: 2.3306058049201965, Final Batch Loss: 0.8870604634284973\n",
      "Epoch 192, Loss: 2.1811065077781677, Final Batch Loss: 0.7382094860076904\n",
      "Epoch 193, Loss: 2.2517637610435486, Final Batch Loss: 0.7931391000747681\n",
      "Epoch 194, Loss: 2.207113027572632, Final Batch Loss: 0.7771731615066528\n",
      "Epoch 195, Loss: 2.2131109833717346, Final Batch Loss: 0.791034996509552\n",
      "Epoch 196, Loss: 2.0949618220329285, Final Batch Loss: 0.6127556562423706\n",
      "Epoch 197, Loss: 2.22337943315506, Final Batch Loss: 0.775409996509552\n",
      "Epoch 198, Loss: 2.1169991493225098, Final Batch Loss: 0.6624253392219543\n",
      "Epoch 199, Loss: 2.1221364736557007, Final Batch Loss: 0.7042596936225891\n",
      "Epoch 200, Loss: 2.142934024333954, Final Batch Loss: 0.7231802940368652\n",
      "Epoch 201, Loss: 2.1154521703720093, Final Batch Loss: 0.7063477039337158\n",
      "Epoch 202, Loss: 2.1213943362236023, Final Batch Loss: 0.7091997265815735\n",
      "Epoch 203, Loss: 2.15508371591568, Final Batch Loss: 0.7233219146728516\n",
      "Epoch 204, Loss: 2.0596410632133484, Final Batch Loss: 0.6320424675941467\n",
      "Epoch 205, Loss: 2.046342968940735, Final Batch Loss: 0.5768446922302246\n",
      "Epoch 206, Loss: 2.16873300075531, Final Batch Loss: 0.7902018427848816\n",
      "Epoch 207, Loss: 2.07129967212677, Final Batch Loss: 0.6849340796470642\n",
      "Epoch 208, Loss: 2.0419522523880005, Final Batch Loss: 0.595775306224823\n",
      "Epoch 209, Loss: 2.04098641872406, Final Batch Loss: 0.653360903263092\n",
      "Epoch 210, Loss: 2.0509217977523804, Final Batch Loss: 0.6428871750831604\n",
      "Epoch 211, Loss: 2.128022253513336, Final Batch Loss: 0.7214219570159912\n",
      "Epoch 212, Loss: 2.1491037607192993, Final Batch Loss: 0.7380553483963013\n",
      "Epoch 213, Loss: 2.2407142519950867, Final Batch Loss: 0.8064267635345459\n",
      "Epoch 214, Loss: 2.1178765892982483, Final Batch Loss: 0.7146562337875366\n",
      "Epoch 215, Loss: 2.1594528555870056, Final Batch Loss: 0.699871301651001\n",
      "Epoch 216, Loss: 2.0993741154670715, Final Batch Loss: 0.6870138049125671\n",
      "Epoch 217, Loss: 2.0485334992408752, Final Batch Loss: 0.6825628876686096\n",
      "Epoch 218, Loss: 2.160142421722412, Final Batch Loss: 0.7593936324119568\n",
      "Epoch 219, Loss: 2.130904495716095, Final Batch Loss: 0.7461140751838684\n",
      "Epoch 220, Loss: 2.072017729282379, Final Batch Loss: 0.6920019388198853\n",
      "Epoch 221, Loss: 2.094189167022705, Final Batch Loss: 0.6867925524711609\n",
      "Epoch 222, Loss: 2.1274887919425964, Final Batch Loss: 0.6824014782905579\n",
      "Epoch 223, Loss: 2.202461004257202, Final Batch Loss: 0.8350598812103271\n",
      "Epoch 224, Loss: 2.0832417607307434, Final Batch Loss: 0.6498313546180725\n",
      "Epoch 225, Loss: 2.1252113580703735, Final Batch Loss: 0.6651060581207275\n",
      "Epoch 226, Loss: 2.122325599193573, Final Batch Loss: 0.6770280599594116\n",
      "Epoch 227, Loss: 2.021903872489929, Final Batch Loss: 0.6070106625556946\n",
      "Epoch 228, Loss: 2.012913167476654, Final Batch Loss: 0.6681975722312927\n",
      "Epoch 229, Loss: 2.00099641084671, Final Batch Loss: 0.7275166511535645\n",
      "Epoch 230, Loss: 2.098484218120575, Final Batch Loss: 0.6942270398139954\n",
      "Epoch 231, Loss: 2.078877806663513, Final Batch Loss: 0.7381455898284912\n",
      "Epoch 232, Loss: 1.9980496764183044, Final Batch Loss: 0.6826452612876892\n",
      "Epoch 233, Loss: 2.0333985686302185, Final Batch Loss: 0.6693518757820129\n",
      "Epoch 234, Loss: 2.100779116153717, Final Batch Loss: 0.6885873675346375\n",
      "Epoch 235, Loss: 2.0523857474327087, Final Batch Loss: 0.7056816220283508\n",
      "Epoch 236, Loss: 2.0002359747886658, Final Batch Loss: 0.7185519337654114\n",
      "Epoch 237, Loss: 1.9894081354141235, Final Batch Loss: 0.7623046040534973\n",
      "Epoch 238, Loss: 1.9727613925933838, Final Batch Loss: 0.5840469598770142\n",
      "Epoch 239, Loss: 2.0516311526298523, Final Batch Loss: 0.7003611922264099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss: 1.9851248860359192, Final Batch Loss: 0.6056119799613953\n",
      "Epoch 241, Loss: 1.8924556374549866, Final Batch Loss: 0.599976122379303\n",
      "Epoch 242, Loss: 1.9373915791511536, Final Batch Loss: 0.5833808183670044\n",
      "Epoch 243, Loss: 1.9067396521568298, Final Batch Loss: 0.6418732404708862\n",
      "Epoch 244, Loss: 2.0281132459640503, Final Batch Loss: 0.6786220669746399\n",
      "Epoch 245, Loss: 1.9237732291221619, Final Batch Loss: 0.5211618542671204\n",
      "Epoch 246, Loss: 2.069043457508087, Final Batch Loss: 0.7428763508796692\n",
      "Epoch 247, Loss: 1.9563947319984436, Final Batch Loss: 0.5984055399894714\n",
      "Epoch 248, Loss: 2.0257202982902527, Final Batch Loss: 0.7485061287879944\n",
      "Epoch 249, Loss: 1.947800636291504, Final Batch Loss: 0.6853135824203491\n",
      "Epoch 250, Loss: 1.987294316291809, Final Batch Loss: 0.6791892647743225\n",
      "Epoch 251, Loss: 1.9689267873764038, Final Batch Loss: 0.7449610829353333\n",
      "Epoch 252, Loss: 1.9890769720077515, Final Batch Loss: 0.7946107983589172\n",
      "Epoch 253, Loss: 1.9182765483856201, Final Batch Loss: 0.6069175601005554\n",
      "Epoch 254, Loss: 1.9852170944213867, Final Batch Loss: 0.6814406514167786\n",
      "Epoch 255, Loss: 1.8856510519981384, Final Batch Loss: 0.5928651094436646\n",
      "Epoch 256, Loss: 1.8675838112831116, Final Batch Loss: 0.6306034922599792\n",
      "Epoch 257, Loss: 1.8945539593696594, Final Batch Loss: 0.5778993964195251\n",
      "Epoch 258, Loss: 2.1230183243751526, Final Batch Loss: 0.8018165230751038\n",
      "Epoch 259, Loss: 1.8935765027999878, Final Batch Loss: 0.6154220104217529\n",
      "Epoch 260, Loss: 1.8817219138145447, Final Batch Loss: 0.6597711443901062\n",
      "Epoch 261, Loss: 1.8004727959632874, Final Batch Loss: 0.5597736239433289\n",
      "Epoch 262, Loss: 2.008262515068054, Final Batch Loss: 0.7731883525848389\n",
      "Epoch 263, Loss: 1.8185322284698486, Final Batch Loss: 0.5406051278114319\n",
      "Epoch 264, Loss: 1.9467809200286865, Final Batch Loss: 0.7026063203811646\n",
      "Epoch 265, Loss: 1.9171867966651917, Final Batch Loss: 0.6330661773681641\n",
      "Epoch 266, Loss: 1.9924479126930237, Final Batch Loss: 0.7107367515563965\n",
      "Epoch 267, Loss: 1.797367811203003, Final Batch Loss: 0.5668792724609375\n",
      "Epoch 268, Loss: 1.8706565499305725, Final Batch Loss: 0.6426738500595093\n",
      "Epoch 269, Loss: 1.8894368410110474, Final Batch Loss: 0.5912432074546814\n",
      "Epoch 270, Loss: 1.8104095458984375, Final Batch Loss: 0.578327476978302\n",
      "Epoch 271, Loss: 1.8116869926452637, Final Batch Loss: 0.585346519947052\n",
      "Epoch 272, Loss: 1.877872884273529, Final Batch Loss: 0.685341477394104\n",
      "Epoch 273, Loss: 1.9035120010375977, Final Batch Loss: 0.6691290140151978\n",
      "Epoch 274, Loss: 1.93550443649292, Final Batch Loss: 0.6969016194343567\n",
      "Epoch 275, Loss: 1.8516770005226135, Final Batch Loss: 0.62624591588974\n",
      "Epoch 276, Loss: 1.918693721294403, Final Batch Loss: 0.5967087149620056\n",
      "Epoch 277, Loss: 1.947916328907013, Final Batch Loss: 0.7087634205818176\n",
      "Epoch 278, Loss: 1.8423577547073364, Final Batch Loss: 0.7012009024620056\n",
      "Epoch 279, Loss: 1.8834083676338196, Final Batch Loss: 0.6201596856117249\n",
      "Epoch 280, Loss: 1.8367769718170166, Final Batch Loss: 0.6110642552375793\n",
      "Epoch 281, Loss: 1.811950147151947, Final Batch Loss: 0.5893703103065491\n",
      "Epoch 282, Loss: 1.7236766815185547, Final Batch Loss: 0.5143620371818542\n",
      "Epoch 283, Loss: 1.819935381412506, Final Batch Loss: 0.6351268291473389\n",
      "Epoch 284, Loss: 1.8255446553230286, Final Batch Loss: 0.60614013671875\n",
      "Epoch 285, Loss: 1.7498602271080017, Final Batch Loss: 0.5423722267150879\n",
      "Epoch 286, Loss: 1.7275445461273193, Final Batch Loss: 0.496551513671875\n",
      "Epoch 287, Loss: 1.920213222503662, Final Batch Loss: 0.7247775793075562\n",
      "Epoch 288, Loss: 1.7644997239112854, Final Batch Loss: 0.5281702876091003\n",
      "Epoch 289, Loss: 1.7170095443725586, Final Batch Loss: 0.5591894388198853\n",
      "Epoch 290, Loss: 1.7832165956497192, Final Batch Loss: 0.574504017829895\n",
      "Epoch 291, Loss: 1.777858316898346, Final Batch Loss: 0.5654968023300171\n",
      "Epoch 292, Loss: 1.7298066020011902, Final Batch Loss: 0.532886803150177\n",
      "Epoch 293, Loss: 1.7659571766853333, Final Batch Loss: 0.5714147686958313\n",
      "Epoch 294, Loss: 1.8686675429344177, Final Batch Loss: 0.5851303339004517\n",
      "Epoch 295, Loss: 1.8588805198669434, Final Batch Loss: 0.663205623626709\n",
      "Epoch 296, Loss: 1.84646737575531, Final Batch Loss: 0.6854272484779358\n",
      "Epoch 297, Loss: 1.7227095365524292, Final Batch Loss: 0.5161120295524597\n",
      "Epoch 298, Loss: 1.7211698293685913, Final Batch Loss: 0.5454484224319458\n",
      "Epoch 299, Loss: 1.769850492477417, Final Batch Loss: 0.5545443892478943\n",
      "Epoch 300, Loss: 1.651277780532837, Final Batch Loss: 0.40542709827423096\n",
      "Epoch 301, Loss: 1.770190715789795, Final Batch Loss: 0.5809396505355835\n",
      "Epoch 302, Loss: 1.7430300116539001, Final Batch Loss: 0.5894468426704407\n",
      "Epoch 303, Loss: 1.7374786138534546, Final Batch Loss: 0.52230304479599\n",
      "Epoch 304, Loss: 1.7546903491020203, Final Batch Loss: 0.6346687078475952\n",
      "Epoch 305, Loss: 1.8150554895401, Final Batch Loss: 0.5832493305206299\n",
      "Epoch 306, Loss: 1.8217917084693909, Final Batch Loss: 0.6273432374000549\n",
      "Epoch 307, Loss: 1.766323983669281, Final Batch Loss: 0.6123872399330139\n",
      "Epoch 308, Loss: 1.8647834658622742, Final Batch Loss: 0.6565334796905518\n",
      "Epoch 309, Loss: 1.7646561861038208, Final Batch Loss: 0.615613579750061\n",
      "Epoch 310, Loss: 1.8010991215705872, Final Batch Loss: 0.6215469837188721\n",
      "Epoch 311, Loss: 1.7932822704315186, Final Batch Loss: 0.6012812256813049\n",
      "Epoch 312, Loss: 1.841629981994629, Final Batch Loss: 0.6971434354782104\n",
      "Epoch 313, Loss: 1.785643219947815, Final Batch Loss: 0.5991405248641968\n",
      "Epoch 314, Loss: 1.6589139103889465, Final Batch Loss: 0.4634590744972229\n",
      "Epoch 315, Loss: 1.805977463722229, Final Batch Loss: 0.6492481231689453\n",
      "Epoch 316, Loss: 1.7129839658737183, Final Batch Loss: 0.574205219745636\n",
      "Epoch 317, Loss: 1.7628288269042969, Final Batch Loss: 0.6379824876785278\n",
      "Epoch 318, Loss: 1.8017640113830566, Final Batch Loss: 0.6269144415855408\n",
      "Epoch 319, Loss: 1.7073557376861572, Final Batch Loss: 0.5102176666259766\n",
      "Epoch 320, Loss: 1.6706929206848145, Final Batch Loss: 0.5705123543739319\n",
      "Epoch 321, Loss: 1.8319056630134583, Final Batch Loss: 0.6594929099082947\n",
      "Epoch 322, Loss: 1.7489750981330872, Final Batch Loss: 0.5844274759292603\n",
      "Epoch 323, Loss: 1.7262188792228699, Final Batch Loss: 0.5903018116950989\n",
      "Epoch 324, Loss: 1.6465577483177185, Final Batch Loss: 0.5203198194503784\n",
      "Epoch 325, Loss: 1.6209673285484314, Final Batch Loss: 0.5202158093452454\n",
      "Epoch 326, Loss: 1.712186336517334, Final Batch Loss: 0.5180709958076477\n",
      "Epoch 327, Loss: 1.5793388187885284, Final Batch Loss: 0.4396105706691742\n",
      "Epoch 328, Loss: 1.647512286901474, Final Batch Loss: 0.5892565846443176\n",
      "Epoch 329, Loss: 1.7162988185882568, Final Batch Loss: 0.5941563248634338\n",
      "Epoch 330, Loss: 1.7062437534332275, Final Batch Loss: 0.526285707950592\n",
      "Epoch 331, Loss: 1.6340832114219666, Final Batch Loss: 0.5292438268661499\n",
      "Epoch 332, Loss: 1.6725894808769226, Final Batch Loss: 0.5119345784187317\n",
      "Epoch 333, Loss: 1.6671472191810608, Final Batch Loss: 0.5652368068695068\n",
      "Epoch 334, Loss: 1.6495811343193054, Final Batch Loss: 0.5575489401817322\n",
      "Epoch 335, Loss: 1.695939153432846, Final Batch Loss: 0.6551092863082886\n",
      "Epoch 336, Loss: 1.599388837814331, Final Batch Loss: 0.5341053605079651\n",
      "Epoch 337, Loss: 1.6525113582611084, Final Batch Loss: 0.5506755709648132\n",
      "Epoch 338, Loss: 1.6772045195102692, Final Batch Loss: 0.6305293440818787\n",
      "Epoch 339, Loss: 1.7103030681610107, Final Batch Loss: 0.5888375043869019\n",
      "Epoch 340, Loss: 1.7297990918159485, Final Batch Loss: 0.607063889503479\n",
      "Epoch 341, Loss: 1.7625678181648254, Final Batch Loss: 0.6761695146560669\n",
      "Epoch 342, Loss: 1.7059494853019714, Final Batch Loss: 0.5854384303092957\n",
      "Epoch 343, Loss: 1.60902938246727, Final Batch Loss: 0.5484862327575684\n",
      "Epoch 344, Loss: 1.6799843907356262, Final Batch Loss: 0.5867642164230347\n",
      "Epoch 345, Loss: 1.6379335522651672, Final Batch Loss: 0.5611101388931274\n",
      "Epoch 346, Loss: 1.6251321732997894, Final Batch Loss: 0.5937859416007996\n",
      "Epoch 347, Loss: 1.569857805967331, Final Batch Loss: 0.4835934340953827\n",
      "Epoch 348, Loss: 1.5531691312789917, Final Batch Loss: 0.4369999170303345\n",
      "Epoch 349, Loss: 1.5737925171852112, Final Batch Loss: 0.4969192147254944\n",
      "Epoch 350, Loss: 1.621665894985199, Final Batch Loss: 0.4871889352798462\n",
      "Epoch 351, Loss: 1.561227798461914, Final Batch Loss: 0.49338817596435547\n",
      "Epoch 352, Loss: 1.653874933719635, Final Batch Loss: 0.49263089895248413\n",
      "Epoch 353, Loss: 1.5900850892066956, Final Batch Loss: 0.5559273362159729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354, Loss: 1.5973060131072998, Final Batch Loss: 0.6247422099113464\n",
      "Epoch 355, Loss: 1.6408727169036865, Final Batch Loss: 0.5872305035591125\n",
      "Epoch 356, Loss: 1.5601516664028168, Final Batch Loss: 0.44505199790000916\n",
      "Epoch 357, Loss: 1.6409980356693268, Final Batch Loss: 0.6524536609649658\n",
      "Epoch 358, Loss: 1.6892577409744263, Final Batch Loss: 0.5321382880210876\n",
      "Epoch 359, Loss: 1.585007220506668, Final Batch Loss: 0.5548485517501831\n",
      "Epoch 360, Loss: 1.612597405910492, Final Batch Loss: 0.5330271124839783\n",
      "Epoch 361, Loss: 1.4839994013309479, Final Batch Loss: 0.454484760761261\n",
      "Epoch 362, Loss: 1.5644255578517914, Final Batch Loss: 0.5506051778793335\n",
      "Epoch 363, Loss: 1.569868952035904, Final Batch Loss: 0.4896050989627838\n",
      "Epoch 364, Loss: 1.6309658288955688, Final Batch Loss: 0.5208932161331177\n",
      "Epoch 365, Loss: 1.6908063888549805, Final Batch Loss: 0.6559338569641113\n",
      "Epoch 366, Loss: 1.6108065843582153, Final Batch Loss: 0.5982579588890076\n",
      "Epoch 367, Loss: 1.6264131963253021, Final Batch Loss: 0.5375494360923767\n",
      "Epoch 368, Loss: 1.5806800723075867, Final Batch Loss: 0.521169126033783\n",
      "Epoch 369, Loss: 1.6525595784187317, Final Batch Loss: 0.5598329305648804\n",
      "Epoch 370, Loss: 1.654125452041626, Final Batch Loss: 0.5606600642204285\n",
      "Epoch 371, Loss: 1.5682824850082397, Final Batch Loss: 0.538491427898407\n",
      "Epoch 372, Loss: 1.581723690032959, Final Batch Loss: 0.5255014300346375\n",
      "Epoch 373, Loss: 1.6829577088356018, Final Batch Loss: 0.5437554717063904\n",
      "Epoch 374, Loss: 1.5801458060741425, Final Batch Loss: 0.539689838886261\n",
      "Epoch 375, Loss: 1.5340908467769623, Final Batch Loss: 0.5489324331283569\n",
      "Epoch 376, Loss: 1.5582548379898071, Final Batch Loss: 0.5140693187713623\n",
      "Epoch 377, Loss: 1.5878150165081024, Final Batch Loss: 0.49900904297828674\n",
      "Epoch 378, Loss: 1.553311675786972, Final Batch Loss: 0.5435604453086853\n",
      "Epoch 379, Loss: 1.5748652219772339, Final Batch Loss: 0.5524817109107971\n",
      "Epoch 380, Loss: 1.5290766656398773, Final Batch Loss: 0.5666211843490601\n",
      "Epoch 381, Loss: 1.5995262563228607, Final Batch Loss: 0.5855104327201843\n",
      "Epoch 382, Loss: 1.5682618618011475, Final Batch Loss: 0.5096712708473206\n",
      "Epoch 383, Loss: 1.5988830924034119, Final Batch Loss: 0.5358296632766724\n",
      "Epoch 384, Loss: 1.5547233819961548, Final Batch Loss: 0.5087963938713074\n",
      "Epoch 385, Loss: 1.5690035820007324, Final Batch Loss: 0.5247439742088318\n",
      "Epoch 386, Loss: 1.4491294622421265, Final Batch Loss: 0.434021532535553\n",
      "Epoch 387, Loss: 1.5746109783649445, Final Batch Loss: 0.4874744713306427\n",
      "Epoch 388, Loss: 1.5727997124195099, Final Batch Loss: 0.5154818296432495\n",
      "Epoch 389, Loss: 1.4925355911254883, Final Batch Loss: 0.41401422023773193\n",
      "Epoch 390, Loss: 1.591679722070694, Final Batch Loss: 0.5800074338912964\n",
      "Epoch 391, Loss: 1.5415836572647095, Final Batch Loss: 0.5188875794410706\n",
      "Epoch 392, Loss: 1.5334128737449646, Final Batch Loss: 0.5968854427337646\n",
      "Epoch 393, Loss: 1.4871267676353455, Final Batch Loss: 0.48148614168167114\n",
      "Epoch 394, Loss: 1.5094507932662964, Final Batch Loss: 0.5434093475341797\n",
      "Epoch 395, Loss: 1.5656217634677887, Final Batch Loss: 0.4759739935398102\n",
      "Epoch 396, Loss: 1.5263149738311768, Final Batch Loss: 0.4830375015735626\n",
      "Epoch 397, Loss: 1.494599461555481, Final Batch Loss: 0.4655703604221344\n",
      "Epoch 398, Loss: 1.535778433084488, Final Batch Loss: 0.5330318808555603\n",
      "Epoch 399, Loss: 1.6199417114257812, Final Batch Loss: 0.5857852697372437\n",
      "Epoch 400, Loss: 1.4843038320541382, Final Batch Loss: 0.5513961315155029\n",
      "Epoch 401, Loss: 1.440614104270935, Final Batch Loss: 0.4348854720592499\n",
      "Epoch 402, Loss: 1.5498503148555756, Final Batch Loss: 0.62162184715271\n",
      "Epoch 403, Loss: 1.5099082589149475, Final Batch Loss: 0.43851691484451294\n",
      "Epoch 404, Loss: 1.5026360750198364, Final Batch Loss: 0.5642393827438354\n",
      "Epoch 405, Loss: 1.4341146647930145, Final Batch Loss: 0.5282101035118103\n",
      "Epoch 406, Loss: 1.5911359786987305, Final Batch Loss: 0.5876941680908203\n",
      "Epoch 407, Loss: 1.4411927163600922, Final Batch Loss: 0.47578468918800354\n",
      "Epoch 408, Loss: 1.4785511195659637, Final Batch Loss: 0.4656320810317993\n",
      "Epoch 409, Loss: 1.504540890455246, Final Batch Loss: 0.4288950264453888\n",
      "Epoch 410, Loss: 1.4813558161258698, Final Batch Loss: 0.4575119614601135\n",
      "Epoch 411, Loss: 1.5849285423755646, Final Batch Loss: 0.6675312519073486\n",
      "Epoch 412, Loss: 1.5195244550704956, Final Batch Loss: 0.5207882523536682\n",
      "Epoch 413, Loss: 1.4707183539867401, Final Batch Loss: 0.47237828373908997\n",
      "Epoch 414, Loss: 1.5677694082260132, Final Batch Loss: 0.6056028604507446\n",
      "Epoch 415, Loss: 1.5417886972427368, Final Batch Loss: 0.4751994013786316\n",
      "Epoch 416, Loss: 1.4581896364688873, Final Batch Loss: 0.5143133997917175\n",
      "Epoch 417, Loss: 1.4781823456287384, Final Batch Loss: 0.4207858145236969\n",
      "Epoch 418, Loss: 1.4000239670276642, Final Batch Loss: 0.4206486940383911\n",
      "Epoch 419, Loss: 1.4482636749744415, Final Batch Loss: 0.4748004376888275\n",
      "Epoch 420, Loss: 1.511807143688202, Final Batch Loss: 0.48376619815826416\n",
      "Epoch 421, Loss: 1.5033581852912903, Final Batch Loss: 0.5313112139701843\n",
      "Epoch 422, Loss: 1.5021646320819855, Final Batch Loss: 0.5654405951499939\n",
      "Epoch 423, Loss: 1.5217632055282593, Final Batch Loss: 0.4881262183189392\n",
      "Epoch 424, Loss: 1.4441095292568207, Final Batch Loss: 0.4704959988594055\n",
      "Epoch 425, Loss: 1.4658296704292297, Final Batch Loss: 0.5023928284645081\n",
      "Epoch 426, Loss: 1.4448700845241547, Final Batch Loss: 0.4447267949581146\n",
      "Epoch 427, Loss: 1.4597400426864624, Final Batch Loss: 0.49984392523765564\n",
      "Epoch 428, Loss: 1.519916146993637, Final Batch Loss: 0.5820825099945068\n",
      "Epoch 429, Loss: 1.4568993747234344, Final Batch Loss: 0.5048669576644897\n",
      "Epoch 430, Loss: 1.4003792107105255, Final Batch Loss: 0.4645636975765228\n",
      "Epoch 431, Loss: 1.494734764099121, Final Batch Loss: 0.5334416031837463\n",
      "Epoch 432, Loss: 1.426288902759552, Final Batch Loss: 0.4965471625328064\n",
      "Epoch 433, Loss: 1.4716764092445374, Final Batch Loss: 0.567790150642395\n",
      "Epoch 434, Loss: 1.396866649389267, Final Batch Loss: 0.3997558653354645\n",
      "Epoch 435, Loss: 1.2995989322662354, Final Batch Loss: 0.4380384683609009\n",
      "Epoch 436, Loss: 1.371694266796112, Final Batch Loss: 0.4289870858192444\n",
      "Epoch 437, Loss: 1.4548881649971008, Final Batch Loss: 0.430864155292511\n",
      "Epoch 438, Loss: 1.4013611376285553, Final Batch Loss: 0.40551766753196716\n",
      "Epoch 439, Loss: 1.3772837221622467, Final Batch Loss: 0.4629506766796112\n",
      "Epoch 440, Loss: 1.411521077156067, Final Batch Loss: 0.49014198780059814\n",
      "Epoch 441, Loss: 1.4756763875484467, Final Batch Loss: 0.5388216972351074\n",
      "Epoch 442, Loss: 1.390702724456787, Final Batch Loss: 0.3968088924884796\n",
      "Epoch 443, Loss: 1.3738043010234833, Final Batch Loss: 0.45250949263572693\n",
      "Epoch 444, Loss: 1.4282503426074982, Final Batch Loss: 0.5110516548156738\n",
      "Epoch 445, Loss: 1.404231697320938, Final Batch Loss: 0.49097904562950134\n",
      "Epoch 446, Loss: 1.4995708763599396, Final Batch Loss: 0.5321913957595825\n",
      "Epoch 447, Loss: 1.4366690516471863, Final Batch Loss: 0.46995386481285095\n",
      "Epoch 448, Loss: 1.3628391325473785, Final Batch Loss: 0.4545946419239044\n",
      "Epoch 449, Loss: 1.3473711907863617, Final Batch Loss: 0.5058294534683228\n",
      "Epoch 450, Loss: 1.2914063930511475, Final Batch Loss: 0.4110409915447235\n",
      "Epoch 451, Loss: 1.3705292046070099, Final Batch Loss: 0.4376632571220398\n",
      "Epoch 452, Loss: 1.3696268796920776, Final Batch Loss: 0.4182478189468384\n",
      "Epoch 453, Loss: 1.398106187582016, Final Batch Loss: 0.4464007318019867\n",
      "Epoch 454, Loss: 1.4061561822891235, Final Batch Loss: 0.394632488489151\n",
      "Epoch 455, Loss: 1.4132336676120758, Final Batch Loss: 0.5666549205780029\n",
      "Epoch 456, Loss: 1.3892781138420105, Final Batch Loss: 0.4720497727394104\n",
      "Epoch 457, Loss: 1.4043760001659393, Final Batch Loss: 0.4956989884376526\n",
      "Epoch 458, Loss: 1.3818896412849426, Final Batch Loss: 0.4261503517627716\n",
      "Epoch 459, Loss: 1.3940627574920654, Final Batch Loss: 0.47993943095207214\n",
      "Epoch 460, Loss: 1.525502473115921, Final Batch Loss: 0.5261828899383545\n",
      "Epoch 461, Loss: 1.406561255455017, Final Batch Loss: 0.4365597367286682\n",
      "Epoch 462, Loss: 1.3861849904060364, Final Batch Loss: 0.39352428913116455\n",
      "Epoch 463, Loss: 1.3163290917873383, Final Batch Loss: 0.46104487776756287\n",
      "Epoch 464, Loss: 1.4070623815059662, Final Batch Loss: 0.47210589051246643\n",
      "Epoch 465, Loss: 1.4129574298858643, Final Batch Loss: 0.4800237715244293\n",
      "Epoch 466, Loss: 1.3340299725532532, Final Batch Loss: 0.42272883653640747\n",
      "Epoch 467, Loss: 1.4135078489780426, Final Batch Loss: 0.531325101852417\n",
      "Epoch 468, Loss: 1.3017377853393555, Final Batch Loss: 0.38156816363334656\n",
      "Epoch 469, Loss: 1.3937268555164337, Final Batch Loss: 0.5952091217041016\n",
      "Epoch 470, Loss: 1.3934552669525146, Final Batch Loss: 0.4307004511356354\n",
      "Epoch 471, Loss: 1.3325242102146149, Final Batch Loss: 0.38120487332344055\n",
      "Epoch 472, Loss: 1.3114262223243713, Final Batch Loss: 0.3827584385871887\n",
      "Epoch 473, Loss: 1.3548105657100677, Final Batch Loss: 0.4330962300300598\n",
      "Epoch 474, Loss: 1.219083845615387, Final Batch Loss: 0.34700486063957214\n",
      "Epoch 475, Loss: 1.3887134790420532, Final Batch Loss: 0.49785780906677246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476, Loss: 1.3854524791240692, Final Batch Loss: 0.45031315088272095\n",
      "Epoch 477, Loss: 1.4441445469856262, Final Batch Loss: 0.4933953881263733\n",
      "Epoch 478, Loss: 1.359555870294571, Final Batch Loss: 0.38606950640678406\n",
      "Epoch 479, Loss: 1.3899399638175964, Final Batch Loss: 0.43685615062713623\n",
      "Epoch 480, Loss: 1.2784131467342377, Final Batch Loss: 0.3841024935245514\n",
      "Epoch 481, Loss: 1.3884690403938293, Final Batch Loss: 0.47645801305770874\n",
      "Epoch 482, Loss: 1.4242711663246155, Final Batch Loss: 0.4957754611968994\n",
      "Epoch 483, Loss: 1.3487030565738678, Final Batch Loss: 0.46261492371559143\n",
      "Epoch 484, Loss: 1.2783931195735931, Final Batch Loss: 0.43475577235221863\n",
      "Epoch 485, Loss: 1.4119891226291656, Final Batch Loss: 0.5268942713737488\n",
      "Epoch 486, Loss: 1.3051831126213074, Final Batch Loss: 0.44414862990379333\n",
      "Epoch 487, Loss: 1.2940952777862549, Final Batch Loss: 0.35766857862472534\n",
      "Epoch 488, Loss: 1.2998786270618439, Final Batch Loss: 0.44869115948677063\n",
      "Epoch 489, Loss: 1.3357571959495544, Final Batch Loss: 0.5189071893692017\n",
      "Epoch 490, Loss: 1.3095479607582092, Final Batch Loss: 0.4350630044937134\n",
      "Epoch 491, Loss: 1.3147925734519958, Final Batch Loss: 0.41780492663383484\n",
      "Epoch 492, Loss: 1.3691628575325012, Final Batch Loss: 0.5231367945671082\n",
      "Epoch 493, Loss: 1.2910555005073547, Final Batch Loss: 0.5079888701438904\n",
      "Epoch 494, Loss: 1.2405761182308197, Final Batch Loss: 0.4164264500141144\n",
      "Epoch 495, Loss: 1.2537344992160797, Final Batch Loss: 0.3837980628013611\n",
      "Epoch 496, Loss: 1.3460845649242401, Final Batch Loss: 0.5274804830551147\n",
      "Epoch 497, Loss: 1.3644604980945587, Final Batch Loss: 0.43385395407676697\n",
      "Epoch 498, Loss: 1.3254552781581879, Final Batch Loss: 0.39002102613449097\n",
      "Epoch 499, Loss: 1.3102729618549347, Final Batch Loss: 0.4426366686820984\n",
      "Epoch 500, Loss: 1.282480001449585, Final Batch Loss: 0.45481446385383606\n",
      "Epoch 501, Loss: 1.2616179585456848, Final Batch Loss: 0.3645925223827362\n",
      "Epoch 502, Loss: 1.2711022794246674, Final Batch Loss: 0.35263150930404663\n",
      "Epoch 503, Loss: 1.3612046241760254, Final Batch Loss: 0.4832766056060791\n",
      "Epoch 504, Loss: 1.4948020577430725, Final Batch Loss: 0.6439986824989319\n",
      "Epoch 505, Loss: 1.312971979379654, Final Batch Loss: 0.3423580527305603\n",
      "Epoch 506, Loss: 1.3848059177398682, Final Batch Loss: 0.4692844748497009\n",
      "Epoch 507, Loss: 1.3461671471595764, Final Batch Loss: 0.4328281581401825\n",
      "Epoch 508, Loss: 1.3792617321014404, Final Batch Loss: 0.4522090554237366\n",
      "Epoch 509, Loss: 1.3161264657974243, Final Batch Loss: 0.4363303780555725\n",
      "Epoch 510, Loss: 1.407249093055725, Final Batch Loss: 0.540398359298706\n",
      "Epoch 511, Loss: 1.3451429605484009, Final Batch Loss: 0.3711244761943817\n",
      "Epoch 512, Loss: 1.3479534983634949, Final Batch Loss: 0.46386656165122986\n",
      "Epoch 513, Loss: 1.2368912398815155, Final Batch Loss: 0.452924519777298\n",
      "Epoch 514, Loss: 1.3233284056186676, Final Batch Loss: 0.4668368399143219\n",
      "Epoch 515, Loss: 1.3032868802547455, Final Batch Loss: 0.3397609293460846\n",
      "Epoch 516, Loss: 1.3020330369472504, Final Batch Loss: 0.4564685821533203\n",
      "Epoch 517, Loss: 1.249559611082077, Final Batch Loss: 0.42616015672683716\n",
      "Epoch 518, Loss: 1.328054428100586, Final Batch Loss: 0.4162134528160095\n",
      "Epoch 519, Loss: 1.2415911853313446, Final Batch Loss: 0.43285155296325684\n",
      "Epoch 520, Loss: 1.3143415451049805, Final Batch Loss: 0.4476233720779419\n",
      "Epoch 521, Loss: 1.3511810600757599, Final Batch Loss: 0.40953537821769714\n",
      "Epoch 522, Loss: 1.27947998046875, Final Batch Loss: 0.4011617600917816\n",
      "Epoch 523, Loss: 1.292586863040924, Final Batch Loss: 0.4713211953639984\n",
      "Epoch 524, Loss: 1.290241539478302, Final Batch Loss: 0.49039900302886963\n",
      "Epoch 525, Loss: 1.2577743828296661, Final Batch Loss: 0.4295446276664734\n",
      "Epoch 526, Loss: 1.3407444953918457, Final Batch Loss: 0.49792274832725525\n",
      "Epoch 527, Loss: 1.3050817847251892, Final Batch Loss: 0.454380601644516\n",
      "Epoch 528, Loss: 1.3467598259449005, Final Batch Loss: 0.4214150309562683\n",
      "Epoch 529, Loss: 1.2667196691036224, Final Batch Loss: 0.35093235969543457\n",
      "Epoch 530, Loss: 1.276003748178482, Final Batch Loss: 0.44761762022972107\n",
      "Epoch 531, Loss: 1.346973866224289, Final Batch Loss: 0.5171900391578674\n",
      "Epoch 532, Loss: 1.3899914026260376, Final Batch Loss: 0.4803885817527771\n",
      "Epoch 533, Loss: 1.3044441044330597, Final Batch Loss: 0.4346126616001129\n",
      "Epoch 534, Loss: 1.1375852525234222, Final Batch Loss: 0.26488080620765686\n",
      "Epoch 535, Loss: 1.364389032125473, Final Batch Loss: 0.44399577379226685\n",
      "Epoch 536, Loss: 1.2705682516098022, Final Batch Loss: 0.40138810873031616\n",
      "Epoch 537, Loss: 1.286865383386612, Final Batch Loss: 0.39218825101852417\n",
      "Epoch 538, Loss: 1.247280478477478, Final Batch Loss: 0.4007115066051483\n",
      "Epoch 539, Loss: 1.3719235360622406, Final Batch Loss: 0.46042174100875854\n",
      "Epoch 540, Loss: 1.3954704999923706, Final Batch Loss: 0.5148648619651794\n",
      "Epoch 541, Loss: 1.259393721818924, Final Batch Loss: 0.4269638657569885\n",
      "Epoch 542, Loss: 1.2393541932106018, Final Batch Loss: 0.3271479904651642\n",
      "Epoch 543, Loss: 1.4034328162670135, Final Batch Loss: 0.47916316986083984\n",
      "Epoch 544, Loss: 1.2219551503658295, Final Batch Loss: 0.41492488980293274\n",
      "Epoch 545, Loss: 1.3213506042957306, Final Batch Loss: 0.48847779631614685\n",
      "Epoch 546, Loss: 1.2786737978458405, Final Batch Loss: 0.4707199037075043\n",
      "Epoch 547, Loss: 1.273547500371933, Final Batch Loss: 0.38632699847221375\n",
      "Epoch 548, Loss: 1.2142962217330933, Final Batch Loss: 0.314421683549881\n",
      "Epoch 549, Loss: 1.2022361159324646, Final Batch Loss: 0.4005788564682007\n",
      "Epoch 550, Loss: 1.2310212850570679, Final Batch Loss: 0.3806000053882599\n",
      "Epoch 551, Loss: 1.2642894685268402, Final Batch Loss: 0.45749175548553467\n",
      "Epoch 552, Loss: 1.2949965596199036, Final Batch Loss: 0.49240729212760925\n",
      "Epoch 553, Loss: 1.3342860341072083, Final Batch Loss: 0.4714294373989105\n",
      "Epoch 554, Loss: 1.326030820608139, Final Batch Loss: 0.4748777747154236\n",
      "Epoch 555, Loss: 1.1856860220432281, Final Batch Loss: 0.4162784814834595\n",
      "Epoch 556, Loss: 1.2525965571403503, Final Batch Loss: 0.40599367022514343\n",
      "Epoch 557, Loss: 1.3232101202011108, Final Batch Loss: 0.4198005795478821\n",
      "Epoch 558, Loss: 1.2652631103992462, Final Batch Loss: 0.3706872761249542\n",
      "Epoch 559, Loss: 1.282257318496704, Final Batch Loss: 0.37182897329330444\n",
      "Epoch 560, Loss: 1.265894502401352, Final Batch Loss: 0.4490012228488922\n",
      "Epoch 561, Loss: 1.2446975409984589, Final Batch Loss: 0.3885555863380432\n",
      "Epoch 562, Loss: 1.2586513459682465, Final Batch Loss: 0.4066157042980194\n",
      "Epoch 563, Loss: 1.3205135464668274, Final Batch Loss: 0.4490277171134949\n",
      "Epoch 564, Loss: 1.2219023704528809, Final Batch Loss: 0.33114853501319885\n",
      "Epoch 565, Loss: 1.227152407169342, Final Batch Loss: 0.3844834268093109\n",
      "Epoch 566, Loss: 1.261273205280304, Final Batch Loss: 0.44036516547203064\n",
      "Epoch 567, Loss: 1.2520293593406677, Final Batch Loss: 0.3596259355545044\n",
      "Epoch 568, Loss: 1.2254623770713806, Final Batch Loss: 0.428459495306015\n",
      "Epoch 569, Loss: 1.2287004888057709, Final Batch Loss: 0.37392839789390564\n",
      "Epoch 570, Loss: 1.261837750673294, Final Batch Loss: 0.5149040818214417\n",
      "Epoch 571, Loss: 1.1869209706783295, Final Batch Loss: 0.34082967042922974\n",
      "Epoch 572, Loss: 1.2743925154209137, Final Batch Loss: 0.44017788767814636\n",
      "Epoch 573, Loss: 1.250908613204956, Final Batch Loss: 0.4090403616428375\n",
      "Epoch 574, Loss: 1.3388327956199646, Final Batch Loss: 0.4019409120082855\n",
      "Epoch 575, Loss: 1.202230989933014, Final Batch Loss: 0.35437607765197754\n",
      "Epoch 576, Loss: 1.1568596959114075, Final Batch Loss: 0.3943438231945038\n",
      "Epoch 577, Loss: 1.2422472834587097, Final Batch Loss: 0.4152144193649292\n",
      "Epoch 578, Loss: 1.2349859774112701, Final Batch Loss: 0.4311058521270752\n",
      "Epoch 579, Loss: 1.192372590303421, Final Batch Loss: 0.38560187816619873\n",
      "Epoch 580, Loss: 1.206983894109726, Final Batch Loss: 0.38733533024787903\n",
      "Epoch 581, Loss: 1.1942255198955536, Final Batch Loss: 0.34947192668914795\n",
      "Epoch 582, Loss: 1.2265274226665497, Final Batch Loss: 0.4259040653705597\n",
      "Epoch 583, Loss: 1.2454535365104675, Final Batch Loss: 0.46858322620391846\n",
      "Epoch 584, Loss: 1.2569587528705597, Final Batch Loss: 0.4129827618598938\n",
      "Epoch 585, Loss: 1.2375839054584503, Final Batch Loss: 0.41963300108909607\n",
      "Epoch 586, Loss: 1.2251826524734497, Final Batch Loss: 0.40489286184310913\n",
      "Epoch 587, Loss: 1.1899370849132538, Final Batch Loss: 0.32888343930244446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 588, Loss: 1.2556271255016327, Final Batch Loss: 0.34607645869255066\n",
      "Epoch 589, Loss: 1.1052657067775726, Final Batch Loss: 0.36298617720603943\n",
      "Epoch 590, Loss: 1.2261410653591156, Final Batch Loss: 0.447213739156723\n",
      "Epoch 591, Loss: 1.1419183015823364, Final Batch Loss: 0.35854631662368774\n",
      "Epoch 592, Loss: 1.2799192368984222, Final Batch Loss: 0.4195574223995209\n",
      "Epoch 593, Loss: 1.1746200323104858, Final Batch Loss: 0.35415539145469666\n",
      "Epoch 594, Loss: 1.2763481736183167, Final Batch Loss: 0.5165524482727051\n",
      "Epoch 595, Loss: 1.1929389238357544, Final Batch Loss: 0.3491106927394867\n",
      "Epoch 596, Loss: 1.141497790813446, Final Batch Loss: 0.4025024175643921\n",
      "Epoch 597, Loss: 1.2034918069839478, Final Batch Loss: 0.4018791615962982\n",
      "Epoch 598, Loss: 1.2132371366024017, Final Batch Loss: 0.35910433530807495\n",
      "Epoch 599, Loss: 1.2473497986793518, Final Batch Loss: 0.4623444080352783\n",
      "Epoch 600, Loss: 1.2210701704025269, Final Batch Loss: 0.39026933908462524\n",
      "Epoch 601, Loss: 1.2416536808013916, Final Batch Loss: 0.4078109562397003\n",
      "Epoch 602, Loss: 1.222616821527481, Final Batch Loss: 0.3947522044181824\n",
      "Epoch 603, Loss: 1.2931040525436401, Final Batch Loss: 0.45779919624328613\n",
      "Epoch 604, Loss: 1.1098495125770569, Final Batch Loss: 0.3056221306324005\n",
      "Epoch 605, Loss: 1.165055900812149, Final Batch Loss: 0.386430948972702\n",
      "Epoch 606, Loss: 1.2249199151992798, Final Batch Loss: 0.33962851762771606\n",
      "Epoch 607, Loss: 1.213133543729782, Final Batch Loss: 0.3946191370487213\n",
      "Epoch 608, Loss: 1.1387304961681366, Final Batch Loss: 0.33830225467681885\n",
      "Epoch 609, Loss: 1.1662622690200806, Final Batch Loss: 0.3509906232357025\n",
      "Epoch 610, Loss: 1.1861448884010315, Final Batch Loss: 0.44300082325935364\n",
      "Epoch 611, Loss: 1.1441960036754608, Final Batch Loss: 0.30467307567596436\n",
      "Epoch 612, Loss: 1.310899943113327, Final Batch Loss: 0.44999003410339355\n",
      "Epoch 613, Loss: 1.210332602262497, Final Batch Loss: 0.37249451875686646\n",
      "Epoch 614, Loss: 1.1787169277668, Final Batch Loss: 0.4302682876586914\n",
      "Epoch 615, Loss: 1.170253962278366, Final Batch Loss: 0.36358407139778137\n",
      "Epoch 616, Loss: 1.1583822667598724, Final Batch Loss: 0.4445924460887909\n",
      "Epoch 617, Loss: 1.2570825517177582, Final Batch Loss: 0.3563360273838043\n",
      "Epoch 618, Loss: 1.2632459700107574, Final Batch Loss: 0.47124674916267395\n",
      "Epoch 619, Loss: 1.2316221594810486, Final Batch Loss: 0.4251460134983063\n",
      "Epoch 620, Loss: 1.2341080009937286, Final Batch Loss: 0.42840248346328735\n",
      "Epoch 621, Loss: 1.1623265445232391, Final Batch Loss: 0.39441820979118347\n",
      "Epoch 622, Loss: 1.3231438398361206, Final Batch Loss: 0.44607222080230713\n",
      "Epoch 623, Loss: 1.2228814363479614, Final Batch Loss: 0.3664706349372864\n",
      "Epoch 624, Loss: 1.1253886222839355, Final Batch Loss: 0.26754915714263916\n",
      "Epoch 625, Loss: 1.1909182965755463, Final Batch Loss: 0.4021328091621399\n",
      "Epoch 626, Loss: 1.2297334671020508, Final Batch Loss: 0.3974681496620178\n",
      "Epoch 627, Loss: 1.2117967009544373, Final Batch Loss: 0.3890399932861328\n",
      "Epoch 628, Loss: 1.206864207983017, Final Batch Loss: 0.4112378656864166\n",
      "Epoch 629, Loss: 1.2013545334339142, Final Batch Loss: 0.35921478271484375\n",
      "Epoch 630, Loss: 1.2063927054405212, Final Batch Loss: 0.442429780960083\n",
      "Epoch 631, Loss: 1.1273427903652191, Final Batch Loss: 0.42604732513427734\n",
      "Epoch 632, Loss: 1.1785244941711426, Final Batch Loss: 0.3580735921859741\n",
      "Epoch 633, Loss: 1.2280076146125793, Final Batch Loss: 0.4191325902938843\n",
      "Epoch 634, Loss: 1.2687265276908875, Final Batch Loss: 0.5157589316368103\n",
      "Epoch 635, Loss: 1.248938411474228, Final Batch Loss: 0.4761650860309601\n",
      "Epoch 636, Loss: 1.1643376648426056, Final Batch Loss: 0.3522551655769348\n",
      "Epoch 637, Loss: 1.2403908669948578, Final Batch Loss: 0.43425142765045166\n",
      "Epoch 638, Loss: 1.1707133650779724, Final Batch Loss: 0.4217291474342346\n",
      "Epoch 639, Loss: 1.1482645273208618, Final Batch Loss: 0.32556238770484924\n",
      "Epoch 640, Loss: 1.162078857421875, Final Batch Loss: 0.44871681928634644\n",
      "Epoch 641, Loss: 1.2162013053894043, Final Batch Loss: 0.4608462452888489\n",
      "Epoch 642, Loss: 1.2003643214702606, Final Batch Loss: 0.37181583046913147\n",
      "Epoch 643, Loss: 1.1630225777626038, Final Batch Loss: 0.41252046823501587\n",
      "Epoch 644, Loss: 1.169548511505127, Final Batch Loss: 0.33037295937538147\n",
      "Epoch 645, Loss: 1.132142573595047, Final Batch Loss: 0.38273486495018005\n",
      "Epoch 646, Loss: 1.1211684942245483, Final Batch Loss: 0.31079813838005066\n",
      "Epoch 647, Loss: 1.2361075580120087, Final Batch Loss: 0.4077359437942505\n",
      "Epoch 648, Loss: 1.1647688448429108, Final Batch Loss: 0.34553152322769165\n",
      "Epoch 649, Loss: 1.156907558441162, Final Batch Loss: 0.29182168841362\n",
      "Epoch 650, Loss: 1.1322020590305328, Final Batch Loss: 0.3698768615722656\n",
      "Epoch 651, Loss: 1.13186115026474, Final Batch Loss: 0.34988561272621155\n",
      "Epoch 652, Loss: 1.180334359407425, Final Batch Loss: 0.3674412965774536\n",
      "Epoch 653, Loss: 1.2281653583049774, Final Batch Loss: 0.41305747628211975\n",
      "Epoch 654, Loss: 1.1434999704360962, Final Batch Loss: 0.3340160548686981\n",
      "Epoch 655, Loss: 1.2082721889019012, Final Batch Loss: 0.3918686509132385\n",
      "Epoch 656, Loss: 1.2104580104351044, Final Batch Loss: 0.4282219409942627\n",
      "Epoch 657, Loss: 1.258481115102768, Final Batch Loss: 0.42342743277549744\n",
      "Epoch 658, Loss: 1.1424190700054169, Final Batch Loss: 0.34097620844841003\n",
      "Epoch 659, Loss: 1.1328116357326508, Final Batch Loss: 0.30640992522239685\n",
      "Epoch 660, Loss: 1.1378313899040222, Final Batch Loss: 0.3842620253562927\n",
      "Epoch 661, Loss: 1.1730035543441772, Final Batch Loss: 0.3798069357872009\n",
      "Epoch 662, Loss: 1.1726504564285278, Final Batch Loss: 0.4014069736003876\n",
      "Epoch 663, Loss: 1.1532039642333984, Final Batch Loss: 0.37102389335632324\n",
      "Epoch 664, Loss: 1.2242165803909302, Final Batch Loss: 0.3997822701931\n",
      "Epoch 665, Loss: 1.1311724781990051, Final Batch Loss: 0.43869084119796753\n",
      "Epoch 666, Loss: 1.2666767835617065, Final Batch Loss: 0.4420669972896576\n",
      "Epoch 667, Loss: 1.100365787744522, Final Batch Loss: 0.34016841650009155\n",
      "Epoch 668, Loss: 1.2177647352218628, Final Batch Loss: 0.4335935711860657\n",
      "Epoch 669, Loss: 1.1775821447372437, Final Batch Loss: 0.3939751088619232\n",
      "Epoch 670, Loss: 1.1166193783283234, Final Batch Loss: 0.37068650126457214\n",
      "Epoch 671, Loss: 1.1840734779834747, Final Batch Loss: 0.3744787573814392\n",
      "Epoch 672, Loss: 1.1393116116523743, Final Batch Loss: 0.3317300081253052\n",
      "Epoch 673, Loss: 1.1213062107563019, Final Batch Loss: 0.36802515387535095\n",
      "Epoch 674, Loss: 1.1480099260807037, Final Batch Loss: 0.338975727558136\n",
      "Epoch 675, Loss: 1.0844407975673676, Final Batch Loss: 0.35212716460227966\n",
      "Epoch 676, Loss: 1.2048461139202118, Final Batch Loss: 0.455920934677124\n",
      "Epoch 677, Loss: 1.1877313256263733, Final Batch Loss: 0.41067034006118774\n",
      "Epoch 678, Loss: 1.2193583548069, Final Batch Loss: 0.42796361446380615\n",
      "Epoch 679, Loss: 1.108424574136734, Final Batch Loss: 0.36692506074905396\n",
      "Epoch 680, Loss: 1.2090405225753784, Final Batch Loss: 0.4708612263202667\n",
      "Epoch 681, Loss: 1.1859142780303955, Final Batch Loss: 0.4135526418685913\n",
      "Epoch 682, Loss: 1.1268470883369446, Final Batch Loss: 0.4218699634075165\n",
      "Epoch 683, Loss: 1.1083985567092896, Final Batch Loss: 0.3006727993488312\n",
      "Epoch 684, Loss: 1.1110504269599915, Final Batch Loss: 0.3251684606075287\n",
      "Epoch 685, Loss: 1.2278386652469635, Final Batch Loss: 0.38724827766418457\n",
      "Epoch 686, Loss: 1.13325896859169, Final Batch Loss: 0.3757733404636383\n",
      "Epoch 687, Loss: 1.0701547265052795, Final Batch Loss: 0.35657498240470886\n",
      "Epoch 688, Loss: 1.155780851840973, Final Batch Loss: 0.40721583366394043\n",
      "Epoch 689, Loss: 1.1114487051963806, Final Batch Loss: 0.35692650079727173\n",
      "Epoch 690, Loss: 1.26556858420372, Final Batch Loss: 0.4178162217140198\n",
      "Epoch 691, Loss: 1.1542294323444366, Final Batch Loss: 0.4388769567012787\n",
      "Epoch 692, Loss: 1.1361343264579773, Final Batch Loss: 0.4027976095676422\n",
      "Epoch 693, Loss: 1.1100666224956512, Final Batch Loss: 0.35267871618270874\n",
      "Epoch 694, Loss: 1.0933637022972107, Final Batch Loss: 0.35996636748313904\n",
      "Epoch 695, Loss: 1.1295305788516998, Final Batch Loss: 0.3821040093898773\n",
      "Epoch 696, Loss: 1.191417783498764, Final Batch Loss: 0.42487600445747375\n",
      "Epoch 697, Loss: 1.1152613759040833, Final Batch Loss: 0.4231407344341278\n",
      "Epoch 698, Loss: 1.1391246020793915, Final Batch Loss: 0.3544458746910095\n",
      "Epoch 699, Loss: 1.1712394952774048, Final Batch Loss: 0.41437411308288574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700, Loss: 1.1250557601451874, Final Batch Loss: 0.34641286730766296\n",
      "Epoch 701, Loss: 1.1756485104560852, Final Batch Loss: 0.43220430612564087\n",
      "Epoch 702, Loss: 1.1069560647010803, Final Batch Loss: 0.3367079198360443\n",
      "Epoch 703, Loss: 1.1756373941898346, Final Batch Loss: 0.3726084232330322\n",
      "Epoch 704, Loss: 1.1705487072467804, Final Batch Loss: 0.40350818634033203\n",
      "Epoch 705, Loss: 1.1152255237102509, Final Batch Loss: 0.3094225227832794\n",
      "Epoch 706, Loss: 1.1230574548244476, Final Batch Loss: 0.3584405183792114\n",
      "Epoch 707, Loss: 1.1362694799900055, Final Batch Loss: 0.36086076498031616\n",
      "Epoch 708, Loss: 1.3014873564243317, Final Batch Loss: 0.47671133279800415\n",
      "Epoch 709, Loss: 1.083837628364563, Final Batch Loss: 0.33414390683174133\n",
      "Epoch 710, Loss: 1.1005876064300537, Final Batch Loss: 0.32124343514442444\n",
      "Epoch 711, Loss: 1.2152746617794037, Final Batch Loss: 0.4205949306488037\n",
      "Epoch 712, Loss: 1.24399533867836, Final Batch Loss: 0.5454646944999695\n",
      "Epoch 713, Loss: 1.1170774698257446, Final Batch Loss: 0.3826984763145447\n",
      "Epoch 714, Loss: 1.1123927235603333, Final Batch Loss: 0.4081685543060303\n",
      "Epoch 715, Loss: 1.21503084897995, Final Batch Loss: 0.3121345043182373\n",
      "Epoch 716, Loss: 1.1189187169075012, Final Batch Loss: 0.3413497805595398\n",
      "Epoch 717, Loss: 1.0440796911716461, Final Batch Loss: 0.32295337319374084\n",
      "Epoch 718, Loss: 1.1488861441612244, Final Batch Loss: 0.3530351221561432\n",
      "Epoch 719, Loss: 1.1701177656650543, Final Batch Loss: 0.378985196352005\n",
      "Epoch 720, Loss: 1.1638235747814178, Final Batch Loss: 0.3866502046585083\n",
      "Epoch 721, Loss: 1.1386624574661255, Final Batch Loss: 0.3865032196044922\n",
      "Epoch 722, Loss: 1.1200239658355713, Final Batch Loss: 0.4649038314819336\n",
      "Epoch 723, Loss: 1.1648107469081879, Final Batch Loss: 0.4103299081325531\n",
      "Epoch 724, Loss: 1.1694490015506744, Final Batch Loss: 0.4170190393924713\n",
      "Epoch 725, Loss: 1.1614402830600739, Final Batch Loss: 0.42464080452919006\n",
      "Epoch 726, Loss: 1.0845264494419098, Final Batch Loss: 0.341655433177948\n",
      "Epoch 727, Loss: 1.1196419298648834, Final Batch Loss: 0.3836781680583954\n",
      "Epoch 728, Loss: 1.0882992148399353, Final Batch Loss: 0.3385288715362549\n",
      "Epoch 729, Loss: 1.1240154504776, Final Batch Loss: 0.32416343688964844\n",
      "Epoch 730, Loss: 1.0301900804042816, Final Batch Loss: 0.2780097723007202\n",
      "Epoch 731, Loss: 1.0700534284114838, Final Batch Loss: 0.3290238678455353\n",
      "Epoch 732, Loss: 1.2511882185935974, Final Batch Loss: 0.4486759305000305\n",
      "Epoch 733, Loss: 1.0291979014873505, Final Batch Loss: 0.29089441895484924\n",
      "Epoch 734, Loss: 1.1706079542636871, Final Batch Loss: 0.409503310918808\n",
      "Epoch 735, Loss: 1.1002967655658722, Final Batch Loss: 0.3739270865917206\n",
      "Epoch 736, Loss: 1.082499623298645, Final Batch Loss: 0.345774382352829\n",
      "Epoch 737, Loss: 1.1013271808624268, Final Batch Loss: 0.3196476101875305\n",
      "Epoch 738, Loss: 1.0723840594291687, Final Batch Loss: 0.3205709457397461\n",
      "Epoch 739, Loss: 1.049104005098343, Final Batch Loss: 0.3553406596183777\n",
      "Epoch 740, Loss: 1.101126492023468, Final Batch Loss: 0.34569355845451355\n",
      "Epoch 741, Loss: 1.1058135628700256, Final Batch Loss: 0.3340419828891754\n",
      "Epoch 742, Loss: 1.2262035608291626, Final Batch Loss: 0.5264825224876404\n",
      "Epoch 743, Loss: 1.1554908156394958, Final Batch Loss: 0.3637350797653198\n",
      "Epoch 744, Loss: 1.0969752073287964, Final Batch Loss: 0.32110798358917236\n",
      "Epoch 745, Loss: 1.158730149269104, Final Batch Loss: 0.3659835755825043\n",
      "Epoch 746, Loss: 1.1979480981826782, Final Batch Loss: 0.43511611223220825\n",
      "Epoch 747, Loss: 1.094559758901596, Final Batch Loss: 0.3653271496295929\n",
      "Epoch 748, Loss: 1.078547179698944, Final Batch Loss: 0.3652738928794861\n",
      "Epoch 749, Loss: 1.152642399072647, Final Batch Loss: 0.36839115619659424\n",
      "Epoch 750, Loss: 1.0817259550094604, Final Batch Loss: 0.31631070375442505\n",
      "Epoch 751, Loss: 1.1499849557876587, Final Batch Loss: 0.38607364892959595\n",
      "Epoch 752, Loss: 1.2333198487758636, Final Batch Loss: 0.4994531571865082\n",
      "Epoch 753, Loss: 1.1444585621356964, Final Batch Loss: 0.41770797967910767\n",
      "Epoch 754, Loss: 1.228230744600296, Final Batch Loss: 0.4885498583316803\n",
      "Epoch 755, Loss: 1.201677829027176, Final Batch Loss: 0.3924643397331238\n",
      "Epoch 756, Loss: 1.1169913411140442, Final Batch Loss: 0.33343711495399475\n",
      "Epoch 757, Loss: 1.212874948978424, Final Batch Loss: 0.40040963888168335\n",
      "Epoch 758, Loss: 1.0652982890605927, Final Batch Loss: 0.3392695188522339\n",
      "Epoch 759, Loss: 1.059685230255127, Final Batch Loss: 0.2931254506111145\n",
      "Epoch 760, Loss: 1.0883288383483887, Final Batch Loss: 0.40492138266563416\n",
      "Epoch 761, Loss: 1.1314226686954498, Final Batch Loss: 0.38005703687667847\n",
      "Epoch 762, Loss: 1.1907991170883179, Final Batch Loss: 0.49426960945129395\n",
      "Epoch 763, Loss: 1.1472084820270538, Final Batch Loss: 0.39392703771591187\n",
      "Epoch 764, Loss: 1.1607040464878082, Final Batch Loss: 0.36501747369766235\n",
      "Epoch 765, Loss: 1.1683861017227173, Final Batch Loss: 0.4363436996936798\n",
      "Epoch 766, Loss: 1.150711178779602, Final Batch Loss: 0.45444434881210327\n",
      "Epoch 767, Loss: 0.9908238649368286, Final Batch Loss: 0.3052925169467926\n",
      "Epoch 768, Loss: 1.1760365068912506, Final Batch Loss: 0.49451154470443726\n",
      "Epoch 769, Loss: 1.0688038766384125, Final Batch Loss: 0.34662431478500366\n",
      "Epoch 770, Loss: 1.1998492181301117, Final Batch Loss: 0.4712466895580292\n",
      "Epoch 771, Loss: 1.1046839356422424, Final Batch Loss: 0.3190048933029175\n",
      "Epoch 772, Loss: 1.1642272174358368, Final Batch Loss: 0.4340432286262512\n",
      "Epoch 773, Loss: 1.0555292665958405, Final Batch Loss: 0.38006889820098877\n",
      "Epoch 774, Loss: 1.038940966129303, Final Batch Loss: 0.3353818655014038\n",
      "Epoch 775, Loss: 1.1409793496131897, Final Batch Loss: 0.3774225115776062\n",
      "Epoch 776, Loss: 1.1302205920219421, Final Batch Loss: 0.35584744811058044\n",
      "Epoch 777, Loss: 1.1434056460857391, Final Batch Loss: 0.3201500177383423\n",
      "Epoch 778, Loss: 1.178032249212265, Final Batch Loss: 0.4085097014904022\n",
      "Epoch 779, Loss: 1.156107634305954, Final Batch Loss: 0.3937775790691376\n",
      "Epoch 780, Loss: 1.1240082383155823, Final Batch Loss: 0.3875998854637146\n",
      "Epoch 781, Loss: 1.1026209592819214, Final Batch Loss: 0.3232911229133606\n",
      "Epoch 782, Loss: 1.0535584688186646, Final Batch Loss: 0.32174786925315857\n",
      "Epoch 783, Loss: 1.0943733751773834, Final Batch Loss: 0.36473047733306885\n",
      "Epoch 784, Loss: 1.0686785578727722, Final Batch Loss: 0.3464643657207489\n",
      "Epoch 785, Loss: 1.1505429446697235, Final Batch Loss: 0.45915356278419495\n",
      "Epoch 786, Loss: 1.1030892133712769, Final Batch Loss: 0.3519284129142761\n",
      "Epoch 787, Loss: 1.0946004986763, Final Batch Loss: 0.3725318908691406\n",
      "Epoch 788, Loss: 1.1675994992256165, Final Batch Loss: 0.41082027554512024\n",
      "Epoch 789, Loss: 1.0394781827926636, Final Batch Loss: 0.3710704743862152\n",
      "Epoch 790, Loss: 1.1390248835086823, Final Batch Loss: 0.41590186953544617\n",
      "Epoch 791, Loss: 1.0798843801021576, Final Batch Loss: 0.30090948939323425\n",
      "Epoch 792, Loss: 1.1056948006153107, Final Batch Loss: 0.37470170855522156\n",
      "Epoch 793, Loss: 1.1307710409164429, Final Batch Loss: 0.379904568195343\n",
      "Epoch 794, Loss: 1.0857704281806946, Final Batch Loss: 0.3506964147090912\n",
      "Epoch 795, Loss: 1.0709484815597534, Final Batch Loss: 0.31297603249549866\n",
      "Epoch 796, Loss: 1.143699586391449, Final Batch Loss: 0.29166221618652344\n",
      "Epoch 797, Loss: 1.1087642908096313, Final Batch Loss: 0.33343297243118286\n",
      "Epoch 798, Loss: 1.081641435623169, Final Batch Loss: 0.37808728218078613\n",
      "Epoch 799, Loss: 1.0429043173789978, Final Batch Loss: 0.3390881419181824\n",
      "Epoch 800, Loss: 1.0853311717510223, Final Batch Loss: 0.36017295718193054\n",
      "Epoch 801, Loss: 1.0222949087619781, Final Batch Loss: 0.32820138335227966\n",
      "Epoch 802, Loss: 1.098592758178711, Final Batch Loss: 0.40441620349884033\n",
      "Epoch 803, Loss: 1.1231522262096405, Final Batch Loss: 0.39619937539100647\n",
      "Epoch 804, Loss: 1.1359402537345886, Final Batch Loss: 0.30956026911735535\n",
      "Epoch 805, Loss: 1.1416459381580353, Final Batch Loss: 0.4574994742870331\n",
      "Epoch 806, Loss: 1.0496850907802582, Final Batch Loss: 0.3821398913860321\n",
      "Epoch 807, Loss: 1.020737648010254, Final Batch Loss: 0.277363657951355\n",
      "Epoch 808, Loss: 1.193017989397049, Final Batch Loss: 0.49845343828201294\n",
      "Epoch 809, Loss: 1.1744869649410248, Final Batch Loss: 0.4140794277191162\n",
      "Epoch 810, Loss: 1.1326259076595306, Final Batch Loss: 0.35109320282936096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811, Loss: 1.1079289615154266, Final Batch Loss: 0.3457632064819336\n",
      "Epoch 812, Loss: 0.9875401556491852, Final Batch Loss: 0.278986394405365\n",
      "Epoch 813, Loss: 1.1641716957092285, Final Batch Loss: 0.42667528986930847\n",
      "Epoch 814, Loss: 1.0572403073310852, Final Batch Loss: 0.3818196952342987\n",
      "Epoch 815, Loss: 1.0430241227149963, Final Batch Loss: 0.28328412771224976\n",
      "Epoch 816, Loss: 1.0635840892791748, Final Batch Loss: 0.33995917439460754\n",
      "Epoch 817, Loss: 1.0919900238513947, Final Batch Loss: 0.3499296307563782\n",
      "Epoch 818, Loss: 1.0911938548088074, Final Batch Loss: 0.37077465653419495\n",
      "Epoch 819, Loss: 1.0247945487499237, Final Batch Loss: 0.36766377091407776\n",
      "Epoch 820, Loss: 1.1008528470993042, Final Batch Loss: 0.41401350498199463\n",
      "Epoch 821, Loss: 1.0513845384120941, Final Batch Loss: 0.3021732568740845\n",
      "Epoch 822, Loss: 1.0261527001857758, Final Batch Loss: 0.28999781608581543\n",
      "Epoch 823, Loss: 1.0643915832042694, Final Batch Loss: 0.2925304174423218\n",
      "Epoch 824, Loss: 0.9487662613391876, Final Batch Loss: 0.2825726568698883\n",
      "Epoch 825, Loss: 1.0329892039299011, Final Batch Loss: 0.32881852984428406\n",
      "Epoch 826, Loss: 1.080953299999237, Final Batch Loss: 0.3629513382911682\n",
      "Epoch 827, Loss: 1.118337243795395, Final Batch Loss: 0.4065384268760681\n",
      "Epoch 828, Loss: 1.0039816498756409, Final Batch Loss: 0.3079875111579895\n",
      "Epoch 829, Loss: 1.180736631155014, Final Batch Loss: 0.4649595320224762\n",
      "Epoch 830, Loss: 1.0608534812927246, Final Batch Loss: 0.3100475072860718\n",
      "Epoch 831, Loss: 1.0454995334148407, Final Batch Loss: 0.30695223808288574\n",
      "Epoch 832, Loss: 1.0930805802345276, Final Batch Loss: 0.37858718633651733\n",
      "Epoch 833, Loss: 1.0300045609474182, Final Batch Loss: 0.3264251947402954\n",
      "Epoch 834, Loss: 1.1698881089687347, Final Batch Loss: 0.415816068649292\n",
      "Epoch 835, Loss: 1.0629567801952362, Final Batch Loss: 0.36063647270202637\n",
      "Epoch 836, Loss: 1.1241551637649536, Final Batch Loss: 0.403128057718277\n",
      "Epoch 837, Loss: 1.1389563977718353, Final Batch Loss: 0.4216974973678589\n",
      "Epoch 838, Loss: 1.0136292278766632, Final Batch Loss: 0.2926328778266907\n",
      "Epoch 839, Loss: 1.0102424323558807, Final Batch Loss: 0.2757902443408966\n",
      "Epoch 840, Loss: 1.1052340865135193, Final Batch Loss: 0.4242664575576782\n",
      "Epoch 841, Loss: 1.1260409355163574, Final Batch Loss: 0.34245508909225464\n",
      "Epoch 842, Loss: 1.0863584280014038, Final Batch Loss: 0.37220892310142517\n",
      "Epoch 843, Loss: 1.1276147067546844, Final Batch Loss: 0.4024054706096649\n",
      "Epoch 844, Loss: 1.1197235584259033, Final Batch Loss: 0.37321749329566956\n",
      "Epoch 845, Loss: 1.06024831533432, Final Batch Loss: 0.4622785747051239\n",
      "Epoch 846, Loss: 1.110838621854782, Final Batch Loss: 0.3324703574180603\n",
      "Epoch 847, Loss: 1.0113648772239685, Final Batch Loss: 0.3220861852169037\n",
      "Epoch 848, Loss: 1.0621628165245056, Final Batch Loss: 0.32390862703323364\n",
      "Epoch 849, Loss: 1.0287490487098694, Final Batch Loss: 0.20826682448387146\n",
      "Epoch 850, Loss: 1.1251388788223267, Final Batch Loss: 0.37752869725227356\n",
      "Epoch 851, Loss: 1.0724803805351257, Final Batch Loss: 0.3449508249759674\n",
      "Epoch 852, Loss: 0.9734213650226593, Final Batch Loss: 0.30714160203933716\n",
      "Epoch 853, Loss: 1.1161699295043945, Final Batch Loss: 0.3162296414375305\n",
      "Epoch 854, Loss: 1.0827734470367432, Final Batch Loss: 0.3509768843650818\n",
      "Epoch 855, Loss: 1.0490435063838959, Final Batch Loss: 0.32894662022590637\n",
      "Epoch 856, Loss: 1.0321372151374817, Final Batch Loss: 0.29569336771965027\n",
      "Epoch 857, Loss: 0.9907960593700409, Final Batch Loss: 0.35486990213394165\n",
      "Epoch 858, Loss: 1.1132823526859283, Final Batch Loss: 0.4452245831489563\n",
      "Epoch 859, Loss: 1.0373118817806244, Final Batch Loss: 0.36974772810935974\n",
      "Epoch 860, Loss: 1.0810736417770386, Final Batch Loss: 0.34896883368492126\n",
      "Epoch 861, Loss: 1.0432795882225037, Final Batch Loss: 0.33842241764068604\n",
      "Epoch 862, Loss: 1.0334969460964203, Final Batch Loss: 0.3251800239086151\n",
      "Epoch 863, Loss: 1.161753922700882, Final Batch Loss: 0.44809621572494507\n",
      "Epoch 864, Loss: 1.056190550327301, Final Batch Loss: 0.3330419063568115\n",
      "Epoch 865, Loss: 1.0592533946037292, Final Batch Loss: 0.31407642364501953\n",
      "Epoch 866, Loss: 1.1014072895050049, Final Batch Loss: 0.39251938462257385\n",
      "Epoch 867, Loss: 1.0097686648368835, Final Batch Loss: 0.2921377420425415\n",
      "Epoch 868, Loss: 1.1551388204097748, Final Batch Loss: 0.4104432165622711\n",
      "Epoch 869, Loss: 1.070758044719696, Final Batch Loss: 0.3733707368373871\n",
      "Epoch 870, Loss: 1.06770658493042, Final Batch Loss: 0.29850253462791443\n",
      "Epoch 871, Loss: 1.0228015184402466, Final Batch Loss: 0.3063928186893463\n",
      "Epoch 872, Loss: 0.9967116117477417, Final Batch Loss: 0.2546771466732025\n",
      "Epoch 873, Loss: 1.0372796952724457, Final Batch Loss: 0.3422376811504364\n",
      "Epoch 874, Loss: 0.9994537234306335, Final Batch Loss: 0.3457666039466858\n",
      "Epoch 875, Loss: 1.0825264751911163, Final Batch Loss: 0.29257985949516296\n",
      "Epoch 876, Loss: 1.185997635126114, Final Batch Loss: 0.4065885841846466\n",
      "Epoch 877, Loss: 1.1125909686088562, Final Batch Loss: 0.35690075159072876\n",
      "Epoch 878, Loss: 1.1092188954353333, Final Batch Loss: 0.3658444285392761\n",
      "Epoch 879, Loss: 0.9776747524738312, Final Batch Loss: 0.34538060426712036\n",
      "Epoch 880, Loss: 1.077772170305252, Final Batch Loss: 0.30010443925857544\n",
      "Epoch 881, Loss: 1.0309865474700928, Final Batch Loss: 0.29356110095977783\n",
      "Epoch 882, Loss: 1.1029726564884186, Final Batch Loss: 0.3272343873977661\n",
      "Epoch 883, Loss: 1.1664413809776306, Final Batch Loss: 0.3997298777103424\n",
      "Epoch 884, Loss: 1.0814057886600494, Final Batch Loss: 0.44364655017852783\n",
      "Epoch 885, Loss: 1.0639291107654572, Final Batch Loss: 0.2991442382335663\n",
      "Epoch 886, Loss: 1.0364251136779785, Final Batch Loss: 0.28347480297088623\n",
      "Epoch 887, Loss: 1.111746996641159, Final Batch Loss: 0.3615472912788391\n",
      "Epoch 888, Loss: 1.022418588399887, Final Batch Loss: 0.27535346150398254\n",
      "Epoch 889, Loss: 1.1499777138233185, Final Batch Loss: 0.44975581765174866\n",
      "Epoch 890, Loss: 1.1231938600540161, Final Batch Loss: 0.3711988925933838\n",
      "Epoch 891, Loss: 1.0646542310714722, Final Batch Loss: 0.33871158957481384\n",
      "Epoch 892, Loss: 1.0097639858722687, Final Batch Loss: 0.30017903447151184\n",
      "Epoch 893, Loss: 1.0634013414382935, Final Batch Loss: 0.3274911344051361\n",
      "Epoch 894, Loss: 0.9879675507545471, Final Batch Loss: 0.34035417437553406\n",
      "Epoch 895, Loss: 1.0231044590473175, Final Batch Loss: 0.3525407910346985\n",
      "Epoch 896, Loss: 1.0795779526233673, Final Batch Loss: 0.397900253534317\n",
      "Epoch 897, Loss: 1.0408334136009216, Final Batch Loss: 0.3642728328704834\n",
      "Epoch 898, Loss: 1.068055421113968, Final Batch Loss: 0.3746049404144287\n",
      "Epoch 899, Loss: 1.0707309246063232, Final Batch Loss: 0.3544899523258209\n",
      "Epoch 900, Loss: 1.0740548074245453, Final Batch Loss: 0.30325672030448914\n",
      "Epoch 901, Loss: 1.003884732723236, Final Batch Loss: 0.3655107319355011\n",
      "Epoch 902, Loss: 0.9961934983730316, Final Batch Loss: 0.3778183162212372\n",
      "Epoch 903, Loss: 1.0019932389259338, Final Batch Loss: 0.26362475752830505\n",
      "Epoch 904, Loss: 1.1179096102714539, Final Batch Loss: 0.38067129254341125\n",
      "Epoch 905, Loss: 1.079577475786209, Final Batch Loss: 0.3952363133430481\n",
      "Epoch 906, Loss: 1.0542458891868591, Final Batch Loss: 0.3626047670841217\n",
      "Epoch 907, Loss: 1.0580467283725739, Final Batch Loss: 0.3452013432979584\n",
      "Epoch 908, Loss: 1.0888367891311646, Final Batch Loss: 0.40097853541374207\n",
      "Epoch 909, Loss: 1.1974700689315796, Final Batch Loss: 0.4816381335258484\n",
      "Epoch 910, Loss: 1.0609983503818512, Final Batch Loss: 0.421668142080307\n",
      "Epoch 911, Loss: 1.0561431050300598, Final Batch Loss: 0.3706410527229309\n",
      "Epoch 912, Loss: 1.076709270477295, Final Batch Loss: 0.4208891689777374\n",
      "Epoch 913, Loss: 1.0809917449951172, Final Batch Loss: 0.42561665177345276\n",
      "Epoch 914, Loss: 1.122039020061493, Final Batch Loss: 0.3474603593349457\n",
      "Epoch 915, Loss: 1.1813537776470184, Final Batch Loss: 0.46411368250846863\n",
      "Epoch 916, Loss: 1.0322450995445251, Final Batch Loss: 0.30542412400245667\n",
      "Epoch 917, Loss: 1.07462739944458, Final Batch Loss: 0.34608790278434753\n",
      "Epoch 918, Loss: 1.055342584848404, Final Batch Loss: 0.4062022566795349\n",
      "Epoch 919, Loss: 1.133207768201828, Final Batch Loss: 0.3591972887516022\n",
      "Epoch 920, Loss: 1.0496030151844025, Final Batch Loss: 0.3191102147102356\n",
      "Epoch 921, Loss: 1.0766906142234802, Final Batch Loss: 0.4035176634788513\n",
      "Epoch 922, Loss: 1.009799599647522, Final Batch Loss: 0.358036607503891\n",
      "Epoch 923, Loss: 1.036312609910965, Final Batch Loss: 0.3077576160430908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924, Loss: 1.1275475323200226, Final Batch Loss: 0.31989309191703796\n",
      "Epoch 925, Loss: 1.0725973546504974, Final Batch Loss: 0.3068983852863312\n",
      "Epoch 926, Loss: 1.115589290857315, Final Batch Loss: 0.3948024809360504\n",
      "Epoch 927, Loss: 0.980898305773735, Final Batch Loss: 0.23868726193904877\n",
      "Epoch 928, Loss: 0.9726359844207764, Final Batch Loss: 0.30634504556655884\n",
      "Epoch 929, Loss: 1.0146529078483582, Final Batch Loss: 0.3093847930431366\n",
      "Epoch 930, Loss: 1.1782537698745728, Final Batch Loss: 0.3961770534515381\n",
      "Epoch 931, Loss: 1.1034170091152191, Final Batch Loss: 0.34337538480758667\n",
      "Epoch 932, Loss: 1.0839096903800964, Final Batch Loss: 0.4217011332511902\n",
      "Epoch 933, Loss: 1.1014487445354462, Final Batch Loss: 0.3997153341770172\n",
      "Epoch 934, Loss: 1.008150577545166, Final Batch Loss: 0.35604017972946167\n",
      "Epoch 935, Loss: 0.9770469963550568, Final Batch Loss: 0.29999640583992004\n",
      "Epoch 936, Loss: 1.1413544416427612, Final Batch Loss: 0.41414332389831543\n",
      "Epoch 937, Loss: 1.0889071226119995, Final Batch Loss: 0.3619219660758972\n",
      "Epoch 938, Loss: 1.0444574356079102, Final Batch Loss: 0.31860417127609253\n",
      "Epoch 939, Loss: 0.910642609000206, Final Batch Loss: 0.21931733191013336\n",
      "Epoch 940, Loss: 1.0089505314826965, Final Batch Loss: 0.2791939079761505\n",
      "Epoch 941, Loss: 1.0126414597034454, Final Batch Loss: 0.32909852266311646\n",
      "Epoch 942, Loss: 1.047109603881836, Final Batch Loss: 0.37730497121810913\n",
      "Epoch 943, Loss: 1.1142273843288422, Final Batch Loss: 0.44045647978782654\n",
      "Epoch 944, Loss: 1.0288325250148773, Final Batch Loss: 0.378391832113266\n",
      "Epoch 945, Loss: 0.9676325023174286, Final Batch Loss: 0.3216351866722107\n",
      "Epoch 946, Loss: 1.0464021861553192, Final Batch Loss: 0.3797066807746887\n",
      "Epoch 947, Loss: 0.9488917589187622, Final Batch Loss: 0.3190903961658478\n",
      "Epoch 948, Loss: 1.1037797927856445, Final Batch Loss: 0.3792804181575775\n",
      "Epoch 949, Loss: 0.9943339228630066, Final Batch Loss: 0.28006330132484436\n",
      "Epoch 950, Loss: 0.95580193400383, Final Batch Loss: 0.2887252867221832\n",
      "Epoch 951, Loss: 1.1278230249881744, Final Batch Loss: 0.3558519780635834\n",
      "Epoch 952, Loss: 1.031993418931961, Final Batch Loss: 0.30140942335128784\n",
      "Epoch 953, Loss: 1.009332925081253, Final Batch Loss: 0.27090340852737427\n",
      "Epoch 954, Loss: 1.0296604931354523, Final Batch Loss: 0.2942204177379608\n",
      "Epoch 955, Loss: 1.0705999732017517, Final Batch Loss: 0.364206999540329\n",
      "Epoch 956, Loss: 0.9222233593463898, Final Batch Loss: 0.23672473430633545\n",
      "Epoch 957, Loss: 0.9995832145214081, Final Batch Loss: 0.29686376452445984\n",
      "Epoch 958, Loss: 0.9878808259963989, Final Batch Loss: 0.27425941824913025\n",
      "Epoch 959, Loss: 1.059618055820465, Final Batch Loss: 0.3268112540245056\n",
      "Epoch 960, Loss: 1.0194298326969147, Final Batch Loss: 0.3592991232872009\n",
      "Epoch 961, Loss: 1.0580297410488129, Final Batch Loss: 0.3962239623069763\n",
      "Epoch 962, Loss: 1.0488788783550262, Final Batch Loss: 0.33504557609558105\n",
      "Epoch 963, Loss: 1.1659726798534393, Final Batch Loss: 0.4413415491580963\n",
      "Epoch 964, Loss: 1.1127353310585022, Final Batch Loss: 0.40491145849227905\n",
      "Epoch 965, Loss: 1.1955495476722717, Final Batch Loss: 0.48993757367134094\n",
      "Epoch 966, Loss: 1.0154184997081757, Final Batch Loss: 0.31091445684432983\n",
      "Epoch 967, Loss: 1.1220675110816956, Final Batch Loss: 0.4383029043674469\n",
      "Epoch 968, Loss: 0.9528127014636993, Final Batch Loss: 0.19951024651527405\n",
      "Epoch 969, Loss: 1.0650137066841125, Final Batch Loss: 0.36594483256340027\n",
      "Epoch 970, Loss: 1.0587316155433655, Final Batch Loss: 0.38298630714416504\n",
      "Epoch 971, Loss: 1.0530798435211182, Final Batch Loss: 0.3064770996570587\n",
      "Epoch 972, Loss: 1.0848382711410522, Final Batch Loss: 0.3248159885406494\n",
      "Epoch 973, Loss: 1.0622981786727905, Final Batch Loss: 0.38927578926086426\n",
      "Epoch 974, Loss: 1.1113294064998627, Final Batch Loss: 0.4323723316192627\n",
      "Epoch 975, Loss: 1.0715863108634949, Final Batch Loss: 0.3701726794242859\n",
      "Epoch 976, Loss: 1.031356394290924, Final Batch Loss: 0.3676803708076477\n",
      "Epoch 977, Loss: 1.1657104194164276, Final Batch Loss: 0.42908939719200134\n",
      "Epoch 978, Loss: 1.0108246207237244, Final Batch Loss: 0.289750337600708\n",
      "Epoch 979, Loss: 1.0269306600093842, Final Batch Loss: 0.3560582995414734\n",
      "Epoch 980, Loss: 1.0016747117042542, Final Batch Loss: 0.33765101432800293\n",
      "Epoch 981, Loss: 0.953612208366394, Final Batch Loss: 0.29880383610725403\n",
      "Epoch 982, Loss: 0.9484735727310181, Final Batch Loss: 0.2527364194393158\n",
      "Epoch 983, Loss: 1.0566978752613068, Final Batch Loss: 0.37661680579185486\n",
      "Epoch 984, Loss: 0.9890100359916687, Final Batch Loss: 0.294124037027359\n",
      "Epoch 985, Loss: 1.1224178671836853, Final Batch Loss: 0.33222851157188416\n",
      "Epoch 986, Loss: 1.015220284461975, Final Batch Loss: 0.35140711069107056\n",
      "Epoch 987, Loss: 0.9769358932971954, Final Batch Loss: 0.2934524714946747\n",
      "Epoch 988, Loss: 0.9769477546215057, Final Batch Loss: 0.3195098340511322\n",
      "Epoch 989, Loss: 1.1650389730930328, Final Batch Loss: 0.5019508600234985\n",
      "Epoch 990, Loss: 0.9432503879070282, Final Batch Loss: 0.2757599949836731\n",
      "Epoch 991, Loss: 1.051252692937851, Final Batch Loss: 0.3427031636238098\n",
      "Epoch 992, Loss: 0.9881391525268555, Final Batch Loss: 0.2861345708370209\n",
      "Epoch 993, Loss: 0.9847924113273621, Final Batch Loss: 0.3461396396160126\n",
      "Epoch 994, Loss: 0.9752936065196991, Final Batch Loss: 0.3286800980567932\n",
      "Epoch 995, Loss: 1.1196467578411102, Final Batch Loss: 0.396506130695343\n",
      "Epoch 996, Loss: 1.0246641337871552, Final Batch Loss: 0.3982217609882355\n",
      "Epoch 997, Loss: 1.0571379959583282, Final Batch Loss: 0.3375730514526367\n",
      "Epoch 998, Loss: 1.0304990410804749, Final Batch Loss: 0.3641462028026581\n",
      "Epoch 999, Loss: 0.9762840270996094, Final Batch Loss: 0.3287462592124939\n",
      "Epoch 1000, Loss: 0.9617780148983002, Final Batch Loss: 0.28036007285118103\n",
      "Epoch 1001, Loss: 1.0785298645496368, Final Batch Loss: 0.37789154052734375\n",
      "Epoch 1002, Loss: 1.014872819185257, Final Batch Loss: 0.3664572834968567\n",
      "Epoch 1003, Loss: 1.0701568126678467, Final Batch Loss: 0.4166485071182251\n",
      "Epoch 1004, Loss: 1.0718113780021667, Final Batch Loss: 0.35138994455337524\n",
      "Epoch 1005, Loss: 1.0441320836544037, Final Batch Loss: 0.34334275126457214\n",
      "Epoch 1006, Loss: 1.0678593516349792, Final Batch Loss: 0.42934727668762207\n",
      "Epoch 1007, Loss: 0.9622337520122528, Final Batch Loss: 0.3313335180282593\n",
      "Epoch 1008, Loss: 0.9349980056285858, Final Batch Loss: 0.27564236521720886\n",
      "Epoch 1009, Loss: 1.0216094255447388, Final Batch Loss: 0.36086559295654297\n",
      "Epoch 1010, Loss: 0.9533770680427551, Final Batch Loss: 0.2788500487804413\n",
      "Epoch 1011, Loss: 1.071438491344452, Final Batch Loss: 0.34231728315353394\n",
      "Epoch 1012, Loss: 0.9684825837612152, Final Batch Loss: 0.3461601138114929\n",
      "Epoch 1013, Loss: 0.9365231394767761, Final Batch Loss: 0.29754459857940674\n",
      "Epoch 1014, Loss: 1.0377148985862732, Final Batch Loss: 0.37300485372543335\n",
      "Epoch 1015, Loss: 0.8889144062995911, Final Batch Loss: 0.260470986366272\n",
      "Epoch 1016, Loss: 1.0834178626537323, Final Batch Loss: 0.489022433757782\n",
      "Epoch 1017, Loss: 1.0571069121360779, Final Batch Loss: 0.4022381007671356\n",
      "Epoch 1018, Loss: 0.9666576385498047, Final Batch Loss: 0.3713918924331665\n",
      "Epoch 1019, Loss: 1.0136874616146088, Final Batch Loss: 0.31220051646232605\n",
      "Epoch 1020, Loss: 1.0422589182853699, Final Batch Loss: 0.3958459794521332\n",
      "Epoch 1021, Loss: 0.9973367750644684, Final Batch Loss: 0.32890579104423523\n",
      "Epoch 1022, Loss: 1.0511121451854706, Final Batch Loss: 0.4106995761394501\n",
      "Epoch 1023, Loss: 0.9685828983783722, Final Batch Loss: 0.2731662690639496\n",
      "Epoch 1024, Loss: 0.9780522882938385, Final Batch Loss: 0.324180006980896\n",
      "Epoch 1025, Loss: 1.0138519406318665, Final Batch Loss: 0.3619662821292877\n",
      "Epoch 1026, Loss: 1.0672302842140198, Final Batch Loss: 0.3315546214580536\n",
      "Epoch 1027, Loss: 1.0187631249427795, Final Batch Loss: 0.31625229120254517\n",
      "Epoch 1028, Loss: 1.0677132606506348, Final Batch Loss: 0.31057071685791016\n",
      "Epoch 1029, Loss: 1.0495353639125824, Final Batch Loss: 0.3943725824356079\n",
      "Epoch 1030, Loss: 1.087807685136795, Final Batch Loss: 0.3696475327014923\n",
      "Epoch 1031, Loss: 0.9926720261573792, Final Batch Loss: 0.2596603333950043\n",
      "Epoch 1032, Loss: 0.9953289330005646, Final Batch Loss: 0.2883831560611725\n",
      "Epoch 1033, Loss: 1.0614213049411774, Final Batch Loss: 0.351218044757843\n",
      "Epoch 1034, Loss: 0.9854990541934967, Final Batch Loss: 0.34505680203437805\n",
      "Epoch 1035, Loss: 1.0444495677947998, Final Batch Loss: 0.39097467064857483\n",
      "Epoch 1036, Loss: 1.0670722126960754, Final Batch Loss: 0.3309015929698944\n",
      "Epoch 1037, Loss: 0.9822010695934296, Final Batch Loss: 0.31695592403411865\n",
      "Epoch 1038, Loss: 1.039972573518753, Final Batch Loss: 0.4002005159854889\n",
      "Epoch 1039, Loss: 0.9630002975463867, Final Batch Loss: 0.3440680205821991\n",
      "Epoch 1040, Loss: 1.0203423500061035, Final Batch Loss: 0.2880387008190155\n",
      "Epoch 1041, Loss: 1.1272991597652435, Final Batch Loss: 0.445425420999527\n",
      "Epoch 1042, Loss: 1.0604175329208374, Final Batch Loss: 0.31324291229248047\n",
      "Epoch 1043, Loss: 1.0023569166660309, Final Batch Loss: 0.27633562684059143\n",
      "Epoch 1044, Loss: 0.9426766037940979, Final Batch Loss: 0.28297626972198486\n",
      "Epoch 1045, Loss: 0.9718942046165466, Final Batch Loss: 0.291111558675766\n",
      "Epoch 1046, Loss: 1.1699161529541016, Final Batch Loss: 0.4834756553173065\n",
      "Epoch 1047, Loss: 1.0472926497459412, Final Batch Loss: 0.3481409549713135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1048, Loss: 0.9914362728595734, Final Batch Loss: 0.3218287229537964\n",
      "Epoch 1049, Loss: 1.0504031777381897, Final Batch Loss: 0.28825339674949646\n",
      "Epoch 1050, Loss: 0.9873623847961426, Final Batch Loss: 0.3012676239013672\n",
      "Epoch 1051, Loss: 0.8795745372772217, Final Batch Loss: 0.20488280057907104\n",
      "Epoch 1052, Loss: 0.9134325087070465, Final Batch Loss: 0.28666049242019653\n",
      "Epoch 1053, Loss: 0.9312483668327332, Final Batch Loss: 0.27887415885925293\n",
      "Epoch 1054, Loss: 0.9881533086299896, Final Batch Loss: 0.37150850892066956\n",
      "Epoch 1055, Loss: 0.9395782202482224, Final Batch Loss: 0.24244444072246552\n",
      "Epoch 1056, Loss: 1.022012621164322, Final Batch Loss: 0.3044798970222473\n",
      "Epoch 1057, Loss: 1.0525693595409393, Final Batch Loss: 0.3140685558319092\n",
      "Epoch 1058, Loss: 1.0010958909988403, Final Batch Loss: 0.3159808814525604\n",
      "Epoch 1059, Loss: 1.0054132342338562, Final Batch Loss: 0.3456593453884125\n",
      "Epoch 1060, Loss: 0.9288179874420166, Final Batch Loss: 0.31726518273353577\n",
      "Epoch 1061, Loss: 1.0189641118049622, Final Batch Loss: 0.35713934898376465\n",
      "Epoch 1062, Loss: 0.9877630770206451, Final Batch Loss: 0.3808867633342743\n",
      "Epoch 1063, Loss: 0.9132663905620575, Final Batch Loss: 0.27726998925209045\n",
      "Epoch 1064, Loss: 1.0295994877815247, Final Batch Loss: 0.34609535336494446\n",
      "Epoch 1065, Loss: 0.9439682960510254, Final Batch Loss: 0.2752971351146698\n",
      "Epoch 1066, Loss: 1.024360179901123, Final Batch Loss: 0.3287922441959381\n",
      "Epoch 1067, Loss: 1.0656764209270477, Final Batch Loss: 0.3260542154312134\n",
      "Epoch 1068, Loss: 0.9765268266201019, Final Batch Loss: 0.31677648425102234\n",
      "Epoch 1069, Loss: 1.025107979774475, Final Batch Loss: 0.36673587560653687\n",
      "Epoch 1070, Loss: 0.9823657870292664, Final Batch Loss: 0.2961385250091553\n",
      "Epoch 1071, Loss: 0.9026045203208923, Final Batch Loss: 0.26158595085144043\n",
      "Epoch 1072, Loss: 0.9909035414457321, Final Batch Loss: 0.24028466641902924\n",
      "Epoch 1073, Loss: 0.9253378808498383, Final Batch Loss: 0.2781771421432495\n",
      "Epoch 1074, Loss: 0.9349617213010788, Final Batch Loss: 0.22709839046001434\n",
      "Epoch 1075, Loss: 1.0961873829364777, Final Batch Loss: 0.44140946865081787\n",
      "Epoch 1076, Loss: 1.0502013266086578, Final Batch Loss: 0.4000583291053772\n",
      "Epoch 1077, Loss: 0.9450345635414124, Final Batch Loss: 0.33863386511802673\n",
      "Epoch 1078, Loss: 0.977509617805481, Final Batch Loss: 0.36769339442253113\n",
      "Epoch 1079, Loss: 1.0510672628879547, Final Batch Loss: 0.34032317996025085\n",
      "Epoch 1080, Loss: 0.9867709279060364, Final Batch Loss: 0.3615495562553406\n",
      "Epoch 1081, Loss: 0.9027819335460663, Final Batch Loss: 0.29272139072418213\n",
      "Epoch 1082, Loss: 0.8959810584783554, Final Batch Loss: 0.22824011743068695\n",
      "Epoch 1083, Loss: 1.053753286600113, Final Batch Loss: 0.4074776768684387\n",
      "Epoch 1084, Loss: 1.0115102529525757, Final Batch Loss: 0.31392011046409607\n",
      "Epoch 1085, Loss: 0.8709015846252441, Final Batch Loss: 0.23957663774490356\n",
      "Epoch 1086, Loss: 0.9648378193378448, Final Batch Loss: 0.29252567887306213\n",
      "Epoch 1087, Loss: 0.9810331463813782, Final Batch Loss: 0.25054067373275757\n",
      "Epoch 1088, Loss: 1.0434035509824753, Final Batch Loss: 0.4448511004447937\n",
      "Epoch 1089, Loss: 1.0017321705818176, Final Batch Loss: 0.3746868669986725\n",
      "Epoch 1090, Loss: 1.035369098186493, Final Batch Loss: 0.3394888639450073\n",
      "Epoch 1091, Loss: 1.0146943032741547, Final Batch Loss: 0.3213483393192291\n",
      "Epoch 1092, Loss: 0.9460472464561462, Final Batch Loss: 0.2888261675834656\n",
      "Epoch 1093, Loss: 0.974822998046875, Final Batch Loss: 0.31094861030578613\n",
      "Epoch 1094, Loss: 0.9454439878463745, Final Batch Loss: 0.34469521045684814\n",
      "Epoch 1095, Loss: 1.02405247092247, Final Batch Loss: 0.3362365663051605\n",
      "Epoch 1096, Loss: 0.8965186774730682, Final Batch Loss: 0.28847408294677734\n",
      "Epoch 1097, Loss: 1.0087149739265442, Final Batch Loss: 0.28635087609291077\n",
      "Epoch 1098, Loss: 0.9945994913578033, Final Batch Loss: 0.34621354937553406\n",
      "Epoch 1099, Loss: 0.9284268021583557, Final Batch Loss: 0.2771133482456207\n",
      "Epoch 1100, Loss: 1.0252627432346344, Final Batch Loss: 0.35575929284095764\n",
      "Epoch 1101, Loss: 0.9859803915023804, Final Batch Loss: 0.35331130027770996\n",
      "Epoch 1102, Loss: 1.0002953112125397, Final Batch Loss: 0.36830177903175354\n",
      "Epoch 1103, Loss: 0.935036227107048, Final Batch Loss: 0.23333315551280975\n",
      "Epoch 1104, Loss: 1.0086723566055298, Final Batch Loss: 0.31285709142684937\n",
      "Epoch 1105, Loss: 0.9598912000656128, Final Batch Loss: 0.2979990839958191\n",
      "Epoch 1106, Loss: 1.027414083480835, Final Batch Loss: 0.3576950430870056\n",
      "Epoch 1107, Loss: 1.0186236202716827, Final Batch Loss: 0.3482728898525238\n",
      "Epoch 1108, Loss: 1.0413669645786285, Final Batch Loss: 0.3338184654712677\n",
      "Epoch 1109, Loss: 0.9924383163452148, Final Batch Loss: 0.3760039806365967\n",
      "Epoch 1110, Loss: 0.9437938034534454, Final Batch Loss: 0.25716254115104675\n",
      "Epoch 1111, Loss: 0.9903228878974915, Final Batch Loss: 0.32023152709007263\n",
      "Epoch 1112, Loss: 0.9636992514133453, Final Batch Loss: 0.37593573331832886\n",
      "Epoch 1113, Loss: 0.8854572474956512, Final Batch Loss: 0.2650042772293091\n",
      "Epoch 1114, Loss: 0.9378329813480377, Final Batch Loss: 0.24819982051849365\n",
      "Epoch 1115, Loss: 0.9637256860733032, Final Batch Loss: 0.37325578927993774\n",
      "Epoch 1116, Loss: 0.9315990805625916, Final Batch Loss: 0.271124929189682\n",
      "Epoch 1117, Loss: 1.0144288837909698, Final Batch Loss: 0.40208905935287476\n",
      "Epoch 1118, Loss: 0.995159775018692, Final Batch Loss: 0.3144511580467224\n",
      "Epoch 1119, Loss: 1.024519830942154, Final Batch Loss: 0.2912430167198181\n",
      "Epoch 1120, Loss: 0.9821089506149292, Final Batch Loss: 0.2827880382537842\n",
      "Epoch 1121, Loss: 0.9380833506584167, Final Batch Loss: 0.3471938371658325\n",
      "Epoch 1122, Loss: 1.0412270724773407, Final Batch Loss: 0.3607349395751953\n",
      "Epoch 1123, Loss: 0.9431992769241333, Final Batch Loss: 0.3250276744365692\n",
      "Epoch 1124, Loss: 0.9560599029064178, Final Batch Loss: 0.3366519510746002\n",
      "Epoch 1125, Loss: 1.032739371061325, Final Batch Loss: 0.3972236216068268\n",
      "Epoch 1126, Loss: 0.9399271905422211, Final Batch Loss: 0.2623595893383026\n",
      "Epoch 1127, Loss: 0.9816360473632812, Final Batch Loss: 0.3320610821247101\n",
      "Epoch 1128, Loss: 0.9703643023967743, Final Batch Loss: 0.2950255572795868\n",
      "Epoch 1129, Loss: 0.9462386071681976, Final Batch Loss: 0.3202328383922577\n",
      "Epoch 1130, Loss: 0.8874042481184006, Final Batch Loss: 0.24729053676128387\n",
      "Epoch 1131, Loss: 0.9609260261058807, Final Batch Loss: 0.3363976776599884\n",
      "Epoch 1132, Loss: 0.9329103827476501, Final Batch Loss: 0.27566447854042053\n",
      "Epoch 1133, Loss: 1.0289758443832397, Final Batch Loss: 0.3723953366279602\n",
      "Epoch 1134, Loss: 1.020158052444458, Final Batch Loss: 0.3712035119533539\n",
      "Epoch 1135, Loss: 0.997536689043045, Final Batch Loss: 0.31673094630241394\n",
      "Epoch 1136, Loss: 0.9246162474155426, Final Batch Loss: 0.2996354401111603\n",
      "Epoch 1137, Loss: 0.9728190004825592, Final Batch Loss: 0.3036203682422638\n",
      "Epoch 1138, Loss: 0.9090084433555603, Final Batch Loss: 0.26274678111076355\n",
      "Epoch 1139, Loss: 0.9674733281135559, Final Batch Loss: 0.33863478899002075\n",
      "Epoch 1140, Loss: 0.9976325035095215, Final Batch Loss: 0.36056894063949585\n",
      "Epoch 1141, Loss: 0.9903227984905243, Final Batch Loss: 0.3471268117427826\n",
      "Epoch 1142, Loss: 0.9920348823070526, Final Batch Loss: 0.29172593355178833\n",
      "Epoch 1143, Loss: 1.0280207693576813, Final Batch Loss: 0.40137678384780884\n",
      "Epoch 1144, Loss: 1.0038862228393555, Final Batch Loss: 0.38603267073631287\n",
      "Epoch 1145, Loss: 0.9808861911296844, Final Batch Loss: 0.29505112767219543\n",
      "Epoch 1146, Loss: 0.8668971955776215, Final Batch Loss: 0.26449793577194214\n",
      "Epoch 1147, Loss: 0.9113547503948212, Final Batch Loss: 0.28307628631591797\n",
      "Epoch 1148, Loss: 0.9583327174186707, Final Batch Loss: 0.3354168236255646\n",
      "Epoch 1149, Loss: 0.9182917177677155, Final Batch Loss: 0.30961358547210693\n",
      "Epoch 1150, Loss: 0.8395265191793442, Final Batch Loss: 0.22483398020267487\n",
      "Epoch 1151, Loss: 0.9633730053901672, Final Batch Loss: 0.32025280594825745\n",
      "Epoch 1152, Loss: 0.8819722682237625, Final Batch Loss: 0.23928792774677277\n",
      "Epoch 1153, Loss: 0.9941880404949188, Final Batch Loss: 0.3573266267776489\n",
      "Epoch 1154, Loss: 0.9536003768444061, Final Batch Loss: 0.34060755372047424\n",
      "Epoch 1155, Loss: 1.0510671734809875, Final Batch Loss: 0.43638432025909424\n",
      "Epoch 1156, Loss: 0.8954585492610931, Final Batch Loss: 0.2704986035823822\n",
      "Epoch 1157, Loss: 0.9241781234741211, Final Batch Loss: 0.2954346239566803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1158, Loss: 0.9052744507789612, Final Batch Loss: 0.34632980823516846\n",
      "Epoch 1159, Loss: 1.0505536794662476, Final Batch Loss: 0.37706056237220764\n",
      "Epoch 1160, Loss: 0.9603275060653687, Final Batch Loss: 0.35899025201797485\n",
      "Epoch 1161, Loss: 0.9045165777206421, Final Batch Loss: 0.26998287439346313\n",
      "Epoch 1162, Loss: 0.943748414516449, Final Batch Loss: 0.30466681718826294\n",
      "Epoch 1163, Loss: 1.0981235802173615, Final Batch Loss: 0.38930022716522217\n",
      "Epoch 1164, Loss: 0.9775055646896362, Final Batch Loss: 0.3223888576030731\n",
      "Epoch 1165, Loss: 0.9738701581954956, Final Batch Loss: 0.3180387616157532\n",
      "Epoch 1166, Loss: 0.9259519875049591, Final Batch Loss: 0.31036826968193054\n",
      "Epoch 1167, Loss: 0.9401390254497528, Final Batch Loss: 0.3176872730255127\n",
      "Epoch 1168, Loss: 0.9936319291591644, Final Batch Loss: 0.389225572347641\n",
      "Epoch 1169, Loss: 0.979511022567749, Final Batch Loss: 0.2926861643791199\n",
      "Epoch 1170, Loss: 0.9380795955657959, Final Batch Loss: 0.29386448860168457\n",
      "Epoch 1171, Loss: 0.9513462483882904, Final Batch Loss: 0.2863658666610718\n",
      "Epoch 1172, Loss: 0.9563522338867188, Final Batch Loss: 0.3374350965023041\n",
      "Epoch 1173, Loss: 0.8867150843143463, Final Batch Loss: 0.2602870464324951\n",
      "Epoch 1174, Loss: 0.9802534878253937, Final Batch Loss: 0.31015798449516296\n",
      "Epoch 1175, Loss: 0.9909057319164276, Final Batch Loss: 0.3624286651611328\n",
      "Epoch 1176, Loss: 0.9980010688304901, Final Batch Loss: 0.3547077775001526\n",
      "Epoch 1177, Loss: 1.0613877475261688, Final Batch Loss: 0.3251676559448242\n",
      "Epoch 1178, Loss: 0.9197817444801331, Final Batch Loss: 0.2514881491661072\n",
      "Epoch 1179, Loss: 0.9961291998624802, Final Batch Loss: 0.23158307373523712\n",
      "Epoch 1180, Loss: 0.9248910546302795, Final Batch Loss: 0.3329213261604309\n",
      "Epoch 1181, Loss: 0.916925698518753, Final Batch Loss: 0.2633764147758484\n",
      "Epoch 1182, Loss: 0.9593100249767303, Final Batch Loss: 0.32339781522750854\n",
      "Epoch 1183, Loss: 1.0487408638000488, Final Batch Loss: 0.3218774199485779\n",
      "Epoch 1184, Loss: 0.9304195046424866, Final Batch Loss: 0.2737651467323303\n",
      "Epoch 1185, Loss: 1.0486195385456085, Final Batch Loss: 0.3541291654109955\n",
      "Epoch 1186, Loss: 1.1090295910835266, Final Batch Loss: 0.440285325050354\n",
      "Epoch 1187, Loss: 0.8974047899246216, Final Batch Loss: 0.2790377736091614\n",
      "Epoch 1188, Loss: 0.9446129202842712, Final Batch Loss: 0.26988714933395386\n",
      "Epoch 1189, Loss: 0.9587171971797943, Final Batch Loss: 0.29013314843177795\n",
      "Epoch 1190, Loss: 0.9174821376800537, Final Batch Loss: 0.27005672454833984\n",
      "Epoch 1191, Loss: 1.0124442875385284, Final Batch Loss: 0.3532262444496155\n",
      "Epoch 1192, Loss: 0.991245836019516, Final Batch Loss: 0.37207382917404175\n",
      "Epoch 1193, Loss: 0.9542543888092041, Final Batch Loss: 0.3456937074661255\n",
      "Epoch 1194, Loss: 1.0192341208457947, Final Batch Loss: 0.37064263224601746\n",
      "Epoch 1195, Loss: 0.9078115522861481, Final Batch Loss: 0.27943354845046997\n",
      "Epoch 1196, Loss: 0.9718158841133118, Final Batch Loss: 0.30164510011672974\n",
      "Epoch 1197, Loss: 0.9762724339962006, Final Batch Loss: 0.40739408135414124\n",
      "Epoch 1198, Loss: 1.0533170402050018, Final Batch Loss: 0.4073501527309418\n",
      "Epoch 1199, Loss: 0.9274134337902069, Final Batch Loss: 0.3193207085132599\n",
      "Epoch 1200, Loss: 0.9558099210262299, Final Batch Loss: 0.31454554200172424\n",
      "Epoch 1201, Loss: 0.9311304986476898, Final Batch Loss: 0.30803975462913513\n",
      "Epoch 1202, Loss: 0.9820879399776459, Final Batch Loss: 0.3225107491016388\n",
      "Epoch 1203, Loss: 0.9841619431972504, Final Batch Loss: 0.2683265209197998\n",
      "Epoch 1204, Loss: 0.9108217656612396, Final Batch Loss: 0.3332469165325165\n",
      "Epoch 1205, Loss: 0.9990823566913605, Final Batch Loss: 0.3907660245895386\n",
      "Epoch 1206, Loss: 0.9277396202087402, Final Batch Loss: 0.3353969156742096\n",
      "Epoch 1207, Loss: 1.0026452541351318, Final Batch Loss: 0.27909183502197266\n",
      "Epoch 1208, Loss: 0.9369199872016907, Final Batch Loss: 0.3390044867992401\n",
      "Epoch 1209, Loss: 0.9702982902526855, Final Batch Loss: 0.3180714547634125\n",
      "Epoch 1210, Loss: 0.9233850538730621, Final Batch Loss: 0.2828120291233063\n",
      "Epoch 1211, Loss: 0.8917155563831329, Final Batch Loss: 0.23428577184677124\n",
      "Epoch 1212, Loss: 0.8802900612354279, Final Batch Loss: 0.26447948813438416\n",
      "Epoch 1213, Loss: 0.9095617830753326, Final Batch Loss: 0.31977906823158264\n",
      "Epoch 1214, Loss: 0.9428180754184723, Final Batch Loss: 0.2566739022731781\n",
      "Epoch 1215, Loss: 0.8986789882183075, Final Batch Loss: 0.270557701587677\n",
      "Epoch 1216, Loss: 0.9223156571388245, Final Batch Loss: 0.3518635630607605\n",
      "Epoch 1217, Loss: 0.9738869071006775, Final Batch Loss: 0.3481660485267639\n",
      "Epoch 1218, Loss: 0.9217708110809326, Final Batch Loss: 0.26232999563217163\n",
      "Epoch 1219, Loss: 1.066957712173462, Final Batch Loss: 0.36777999997138977\n",
      "Epoch 1220, Loss: 0.8755070269107819, Final Batch Loss: 0.22251886129379272\n",
      "Epoch 1221, Loss: 0.8847291767597198, Final Batch Loss: 0.27489525079727173\n",
      "Epoch 1222, Loss: 1.008339285850525, Final Batch Loss: 0.2921110987663269\n",
      "Epoch 1223, Loss: 0.9691322147846222, Final Batch Loss: 0.2591486871242523\n",
      "Epoch 1224, Loss: 0.9700187146663666, Final Batch Loss: 0.35306069254875183\n",
      "Epoch 1225, Loss: 0.9750029146671295, Final Batch Loss: 0.33662188053131104\n",
      "Epoch 1226, Loss: 1.051008403301239, Final Batch Loss: 0.35225000977516174\n",
      "Epoch 1227, Loss: 0.9315572082996368, Final Batch Loss: 0.27574124932289124\n",
      "Epoch 1228, Loss: 0.926112487912178, Final Batch Loss: 0.24952112138271332\n",
      "Epoch 1229, Loss: 0.9399949163198471, Final Batch Loss: 0.22497324645519257\n",
      "Epoch 1230, Loss: 0.890000581741333, Final Batch Loss: 0.27297288179397583\n",
      "Epoch 1231, Loss: 1.002798467874527, Final Batch Loss: 0.4073084890842438\n",
      "Epoch 1232, Loss: 0.9018712639808655, Final Batch Loss: 0.3063408434391022\n",
      "Epoch 1233, Loss: 0.9927242696285248, Final Batch Loss: 0.38981902599334717\n",
      "Epoch 1234, Loss: 0.9455063045024872, Final Batch Loss: 0.31336498260498047\n",
      "Epoch 1235, Loss: 1.035763829946518, Final Batch Loss: 0.3991430997848511\n",
      "Epoch 1236, Loss: 1.008822739124298, Final Batch Loss: 0.309239000082016\n",
      "Epoch 1237, Loss: 0.8960863947868347, Final Batch Loss: 0.2664470970630646\n",
      "Epoch 1238, Loss: 1.016930639743805, Final Batch Loss: 0.3472535312175751\n",
      "Epoch 1239, Loss: 0.946466475725174, Final Batch Loss: 0.40374651551246643\n",
      "Epoch 1240, Loss: 1.0259085595607758, Final Batch Loss: 0.4715918302536011\n",
      "Epoch 1241, Loss: 0.9078434109687805, Final Batch Loss: 0.318583220243454\n",
      "Epoch 1242, Loss: 0.9197598099708557, Final Batch Loss: 0.34812647104263306\n",
      "Epoch 1243, Loss: 0.9153377711772919, Final Batch Loss: 0.2565685212612152\n",
      "Epoch 1244, Loss: 0.8544639348983765, Final Batch Loss: 0.26947882771492004\n",
      "Epoch 1245, Loss: 0.9329179525375366, Final Batch Loss: 0.3279450535774231\n",
      "Epoch 1246, Loss: 0.9826034009456635, Final Batch Loss: 0.38923943042755127\n",
      "Epoch 1247, Loss: 0.9949376583099365, Final Batch Loss: 0.36561301350593567\n",
      "Epoch 1248, Loss: 0.8829590082168579, Final Batch Loss: 0.30212530493736267\n",
      "Epoch 1249, Loss: 0.9537699520587921, Final Batch Loss: 0.3164450228214264\n",
      "Epoch 1250, Loss: 0.9268022179603577, Final Batch Loss: 0.3007332384586334\n",
      "Epoch 1251, Loss: 0.9964660406112671, Final Batch Loss: 0.38550716638565063\n",
      "Epoch 1252, Loss: 0.9165041446685791, Final Batch Loss: 0.26955997943878174\n",
      "Epoch 1253, Loss: 0.8930058032274246, Final Batch Loss: 0.22678731381893158\n",
      "Epoch 1254, Loss: 0.9407226145267487, Final Batch Loss: 0.3461850583553314\n",
      "Epoch 1255, Loss: 0.9536019563674927, Final Batch Loss: 0.2993997633457184\n",
      "Epoch 1256, Loss: 0.9940968155860901, Final Batch Loss: 0.37716686725616455\n",
      "Epoch 1257, Loss: 0.9773497581481934, Final Batch Loss: 0.26633667945861816\n",
      "Epoch 1258, Loss: 0.921417161822319, Final Batch Loss: 0.23596163094043732\n",
      "Epoch 1259, Loss: 0.9886725842952728, Final Batch Loss: 0.334048330783844\n",
      "Epoch 1260, Loss: 0.9305228888988495, Final Batch Loss: 0.29844358563423157\n",
      "Epoch 1261, Loss: 0.9247083961963654, Final Batch Loss: 0.2885423004627228\n",
      "Epoch 1262, Loss: 0.9312103688716888, Final Batch Loss: 0.32999473810195923\n",
      "Epoch 1263, Loss: 0.9420770704746246, Final Batch Loss: 0.3331286311149597\n",
      "Epoch 1264, Loss: 1.0096507370471954, Final Batch Loss: 0.3438092768192291\n",
      "Epoch 1265, Loss: 0.9835980832576752, Final Batch Loss: 0.31742703914642334\n",
      "Epoch 1266, Loss: 0.9821552038192749, Final Batch Loss: 0.4218772351741791\n",
      "Epoch 1267, Loss: 0.9198723435401917, Final Batch Loss: 0.3395804762840271\n",
      "Epoch 1268, Loss: 0.9976856410503387, Final Batch Loss: 0.4148522615432739\n",
      "Epoch 1269, Loss: 0.9975571632385254, Final Batch Loss: 0.32420361042022705\n",
      "Epoch 1270, Loss: 1.0292882025241852, Final Batch Loss: 0.39790430665016174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1271, Loss: 0.9845946133136749, Final Batch Loss: 0.3574635088443756\n",
      "Epoch 1272, Loss: 0.9791743457317352, Final Batch Loss: 0.3608854413032532\n",
      "Epoch 1273, Loss: 0.9211848378181458, Final Batch Loss: 0.3162391483783722\n",
      "Epoch 1274, Loss: 0.9405007213354111, Final Batch Loss: 0.31693175435066223\n",
      "Epoch 1275, Loss: 0.9345501363277435, Final Batch Loss: 0.3699476420879364\n",
      "Epoch 1276, Loss: 0.8876067847013474, Final Batch Loss: 0.21443499624729156\n",
      "Epoch 1277, Loss: 1.0429436564445496, Final Batch Loss: 0.3286093473434448\n",
      "Epoch 1278, Loss: 1.008410781621933, Final Batch Loss: 0.33666959404945374\n",
      "Epoch 1279, Loss: 0.8463196158409119, Final Batch Loss: 0.25819236040115356\n",
      "Epoch 1280, Loss: 0.9125896990299225, Final Batch Loss: 0.2533368170261383\n",
      "Epoch 1281, Loss: 0.9678978025913239, Final Batch Loss: 0.32610058784484863\n",
      "Epoch 1282, Loss: 0.9804823100566864, Final Batch Loss: 0.2518581748008728\n",
      "Epoch 1283, Loss: 0.9775931239128113, Final Batch Loss: 0.3674953877925873\n",
      "Epoch 1284, Loss: 0.9922101497650146, Final Batch Loss: 0.422380268573761\n",
      "Epoch 1285, Loss: 0.9540048539638519, Final Batch Loss: 0.28747937083244324\n",
      "Epoch 1286, Loss: 0.9378688037395477, Final Batch Loss: 0.2775314748287201\n",
      "Epoch 1287, Loss: 0.9335751533508301, Final Batch Loss: 0.3146533966064453\n",
      "Epoch 1288, Loss: 0.9237890839576721, Final Batch Loss: 0.29423972964286804\n",
      "Epoch 1289, Loss: 0.9282398521900177, Final Batch Loss: 0.32027751207351685\n",
      "Epoch 1290, Loss: 0.9502120614051819, Final Batch Loss: 0.26722925901412964\n",
      "Epoch 1291, Loss: 1.0311304330825806, Final Batch Loss: 0.3616483211517334\n",
      "Epoch 1292, Loss: 0.8856973052024841, Final Batch Loss: 0.3004370331764221\n",
      "Epoch 1293, Loss: 0.9718196988105774, Final Batch Loss: 0.3227297365665436\n",
      "Epoch 1294, Loss: 1.0811822712421417, Final Batch Loss: 0.2932124733924866\n",
      "Epoch 1295, Loss: 0.909031331539154, Final Batch Loss: 0.2892896831035614\n",
      "Epoch 1296, Loss: 0.9432194530963898, Final Batch Loss: 0.3104378581047058\n",
      "Epoch 1297, Loss: 0.9712336957454681, Final Batch Loss: 0.3464184105396271\n",
      "Epoch 1298, Loss: 0.9262018203735352, Final Batch Loss: 0.3135867714881897\n",
      "Epoch 1299, Loss: 0.9248526096343994, Final Batch Loss: 0.3189162611961365\n",
      "Epoch 1300, Loss: 0.8967061340808868, Final Batch Loss: 0.2808597981929779\n",
      "Epoch 1301, Loss: 0.9701120257377625, Final Batch Loss: 0.34890198707580566\n",
      "Epoch 1302, Loss: 0.9684096872806549, Final Batch Loss: 0.314267098903656\n",
      "Epoch 1303, Loss: 0.9765187203884125, Final Batch Loss: 0.3513750731945038\n",
      "Epoch 1304, Loss: 1.003811925649643, Final Batch Loss: 0.3335016369819641\n",
      "Epoch 1305, Loss: 0.9247263669967651, Final Batch Loss: 0.2794286608695984\n",
      "Epoch 1306, Loss: 0.9105544090270996, Final Batch Loss: 0.27436238527297974\n",
      "Epoch 1307, Loss: 0.9924322664737701, Final Batch Loss: 0.36569035053253174\n",
      "Epoch 1308, Loss: 0.9916353225708008, Final Batch Loss: 0.381561279296875\n",
      "Epoch 1309, Loss: 0.8554950952529907, Final Batch Loss: 0.28543761372566223\n",
      "Epoch 1310, Loss: 0.9909776747226715, Final Batch Loss: 0.2652319371700287\n",
      "Epoch 1311, Loss: 1.0100017488002777, Final Batch Loss: 0.34473052620887756\n",
      "Epoch 1312, Loss: 0.9343720078468323, Final Batch Loss: 0.2943631112575531\n",
      "Epoch 1313, Loss: 0.880647599697113, Final Batch Loss: 0.3074739873409271\n",
      "Epoch 1314, Loss: 0.9838350117206573, Final Batch Loss: 0.3504779040813446\n",
      "Epoch 1315, Loss: 0.848589688539505, Final Batch Loss: 0.30028513073921204\n",
      "Epoch 1316, Loss: 0.9258470237255096, Final Batch Loss: 0.2965392768383026\n",
      "Epoch 1317, Loss: 0.9393628239631653, Final Batch Loss: 0.2982034683227539\n",
      "Epoch 1318, Loss: 0.8756169974803925, Final Batch Loss: 0.2953735291957855\n",
      "Epoch 1319, Loss: 0.8889806270599365, Final Batch Loss: 0.30297088623046875\n",
      "Epoch 1320, Loss: 0.9489205777645111, Final Batch Loss: 0.3464546501636505\n",
      "Epoch 1321, Loss: 0.8659228980541229, Final Batch Loss: 0.26483821868896484\n",
      "Epoch 1322, Loss: 1.0327548384666443, Final Batch Loss: 0.4541293680667877\n",
      "Epoch 1323, Loss: 0.8404034972190857, Final Batch Loss: 0.25249841809272766\n",
      "Epoch 1324, Loss: 0.9387680888175964, Final Batch Loss: 0.374237596988678\n",
      "Epoch 1325, Loss: 1.0432615876197815, Final Batch Loss: 0.41091105341911316\n",
      "Epoch 1326, Loss: 1.0424128770828247, Final Batch Loss: 0.4460832476615906\n",
      "Epoch 1327, Loss: 0.9460163116455078, Final Batch Loss: 0.28521087765693665\n",
      "Epoch 1328, Loss: 1.073493629693985, Final Batch Loss: 0.396956205368042\n",
      "Epoch 1329, Loss: 1.0192299783229828, Final Batch Loss: 0.3480033874511719\n",
      "Epoch 1330, Loss: 1.05597722530365, Final Batch Loss: 0.37933871150016785\n",
      "Epoch 1331, Loss: 0.9029181003570557, Final Batch Loss: 0.3404162526130676\n",
      "Epoch 1332, Loss: 0.9656364619731903, Final Batch Loss: 0.312997967004776\n",
      "Epoch 1333, Loss: 0.8293784707784653, Final Batch Loss: 0.23756207525730133\n",
      "Epoch 1334, Loss: 0.8772853016853333, Final Batch Loss: 0.27382346987724304\n",
      "Epoch 1335, Loss: 0.8413922339677811, Final Batch Loss: 0.2382814735174179\n",
      "Epoch 1336, Loss: 0.9884614646434784, Final Batch Loss: 0.3417423963546753\n",
      "Epoch 1337, Loss: 0.9544290006160736, Final Batch Loss: 0.30286720395088196\n",
      "Epoch 1338, Loss: 1.0658900141716003, Final Batch Loss: 0.39409658312797546\n",
      "Epoch 1339, Loss: 0.9085444658994675, Final Batch Loss: 0.2308761030435562\n",
      "Epoch 1340, Loss: 0.956367164850235, Final Batch Loss: 0.3565763533115387\n",
      "Epoch 1341, Loss: 0.9068388938903809, Final Batch Loss: 0.3245590925216675\n",
      "Epoch 1342, Loss: 1.0695036053657532, Final Batch Loss: 0.3424511253833771\n",
      "Epoch 1343, Loss: 0.9978443086147308, Final Batch Loss: 0.36056721210479736\n",
      "Epoch 1344, Loss: 1.0404101014137268, Final Batch Loss: 0.42406752705574036\n",
      "Epoch 1345, Loss: 0.9941348731517792, Final Batch Loss: 0.40150129795074463\n",
      "Epoch 1346, Loss: 0.9013178944587708, Final Batch Loss: 0.2952868640422821\n",
      "Epoch 1347, Loss: 0.9539204835891724, Final Batch Loss: 0.31909245252609253\n",
      "Epoch 1348, Loss: 0.9419248700141907, Final Batch Loss: 0.2542040944099426\n",
      "Epoch 1349, Loss: 0.9676281213760376, Final Batch Loss: 0.3405066132545471\n",
      "Epoch 1350, Loss: 0.9746087789535522, Final Batch Loss: 0.3475125730037689\n",
      "Epoch 1351, Loss: 0.9224375188350677, Final Batch Loss: 0.2888883650302887\n",
      "Epoch 1352, Loss: 0.9534932672977448, Final Batch Loss: 0.3472089469432831\n",
      "Epoch 1353, Loss: 0.9020460844039917, Final Batch Loss: 0.30644720792770386\n",
      "Epoch 1354, Loss: 1.0286512970924377, Final Batch Loss: 0.4151839017868042\n",
      "Epoch 1355, Loss: 0.9266660511493683, Final Batch Loss: 0.27893131971359253\n",
      "Epoch 1356, Loss: 0.9547564089298248, Final Batch Loss: 0.3197069466114044\n",
      "Epoch 1357, Loss: 0.9339486062526703, Final Batch Loss: 0.2726321518421173\n",
      "Epoch 1358, Loss: 0.8873876929283142, Final Batch Loss: 0.25227680802345276\n",
      "Epoch 1359, Loss: 0.9646533727645874, Final Batch Loss: 0.30393683910369873\n",
      "Epoch 1360, Loss: 0.9382609724998474, Final Batch Loss: 0.3322841227054596\n",
      "Epoch 1361, Loss: 1.0437389612197876, Final Batch Loss: 0.3867453634738922\n",
      "Epoch 1362, Loss: 1.0556248724460602, Final Batch Loss: 0.2924541234970093\n",
      "Epoch 1363, Loss: 0.8906618356704712, Final Batch Loss: 0.28790509700775146\n",
      "Epoch 1364, Loss: 0.9217291176319122, Final Batch Loss: 0.36369413137435913\n",
      "Epoch 1365, Loss: 0.8926776051521301, Final Batch Loss: 0.3122892379760742\n",
      "Epoch 1366, Loss: 1.0441051423549652, Final Batch Loss: 0.3414246439933777\n",
      "Epoch 1367, Loss: 0.8811001181602478, Final Batch Loss: 0.3403308093547821\n",
      "Epoch 1368, Loss: 0.9378005564212799, Final Batch Loss: 0.28078293800354004\n",
      "Epoch 1369, Loss: 0.9182704389095306, Final Batch Loss: 0.343789666891098\n",
      "Epoch 1370, Loss: 0.8945014476776123, Final Batch Loss: 0.3112820088863373\n",
      "Epoch 1371, Loss: 0.8933687508106232, Final Batch Loss: 0.253742516040802\n",
      "Epoch 1372, Loss: 0.9220732152462006, Final Batch Loss: 0.27879950404167175\n",
      "Epoch 1373, Loss: 0.8601655662059784, Final Batch Loss: 0.2610423266887665\n",
      "Epoch 1374, Loss: 0.8992069363594055, Final Batch Loss: 0.2709518373012543\n",
      "Epoch 1375, Loss: 0.9432734847068787, Final Batch Loss: 0.31463074684143066\n",
      "Epoch 1376, Loss: 0.8268440067768097, Final Batch Loss: 0.18978217244148254\n",
      "Epoch 1377, Loss: 0.9687354862689972, Final Batch Loss: 0.36580613255500793\n",
      "Epoch 1378, Loss: 0.8991460502147675, Final Batch Loss: 0.35533344745635986\n",
      "Epoch 1379, Loss: 0.9013341665267944, Final Batch Loss: 0.3091259300708771\n",
      "Epoch 1380, Loss: 0.8164863288402557, Final Batch Loss: 0.2480747103691101\n",
      "Epoch 1381, Loss: 0.8921086192131042, Final Batch Loss: 0.3164918124675751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382, Loss: 1.0256763100624084, Final Batch Loss: 0.3757036328315735\n",
      "Epoch 1383, Loss: 0.9346413612365723, Final Batch Loss: 0.3091816306114197\n",
      "Epoch 1384, Loss: 0.868630051612854, Final Batch Loss: 0.28040969371795654\n",
      "Epoch 1385, Loss: 0.8461094349622726, Final Batch Loss: 0.23834170401096344\n",
      "Epoch 1386, Loss: 0.9404706358909607, Final Batch Loss: 0.3160246014595032\n",
      "Epoch 1387, Loss: 0.8829623460769653, Final Batch Loss: 0.25593703985214233\n",
      "Epoch 1388, Loss: 0.9046353101730347, Final Batch Loss: 0.30407577753067017\n",
      "Epoch 1389, Loss: 0.9336951375007629, Final Batch Loss: 0.3190056383609772\n",
      "Epoch 1390, Loss: 0.8892597258090973, Final Batch Loss: 0.31827405095100403\n",
      "Epoch 1391, Loss: 0.865601509809494, Final Batch Loss: 0.24859017133712769\n",
      "Epoch 1392, Loss: 0.8530643582344055, Final Batch Loss: 0.25190940499305725\n",
      "Epoch 1393, Loss: 0.8815605938434601, Final Batch Loss: 0.3080410659313202\n",
      "Epoch 1394, Loss: 0.9143166244029999, Final Batch Loss: 0.3604852259159088\n",
      "Epoch 1395, Loss: 0.8593763113021851, Final Batch Loss: 0.2616661489009857\n",
      "Epoch 1396, Loss: 0.8884961307048798, Final Batch Loss: 0.28591465950012207\n",
      "Epoch 1397, Loss: 0.9497160315513611, Final Batch Loss: 0.3338416814804077\n",
      "Epoch 1398, Loss: 0.8109563440084457, Final Batch Loss: 0.1938702017068863\n",
      "Epoch 1399, Loss: 0.865986704826355, Final Batch Loss: 0.3429494798183441\n",
      "Epoch 1400, Loss: 0.8649961352348328, Final Batch Loss: 0.2740449905395508\n",
      "Epoch 1401, Loss: 0.8546794205904007, Final Batch Loss: 0.20137669146060944\n",
      "Epoch 1402, Loss: 0.9550105929374695, Final Batch Loss: 0.35817891359329224\n",
      "Epoch 1403, Loss: 0.8989458382129669, Final Batch Loss: 0.3501228988170624\n",
      "Epoch 1404, Loss: 0.9929291307926178, Final Batch Loss: 0.2967967092990875\n",
      "Epoch 1405, Loss: 0.8615913987159729, Final Batch Loss: 0.29068490862846375\n",
      "Epoch 1406, Loss: 0.8795200288295746, Final Batch Loss: 0.27863916754722595\n",
      "Epoch 1407, Loss: 0.9908856153488159, Final Batch Loss: 0.2929070293903351\n",
      "Epoch 1408, Loss: 0.8501645177602768, Final Batch Loss: 0.1923416405916214\n",
      "Epoch 1409, Loss: 0.8980893194675446, Final Batch Loss: 0.32990819215774536\n",
      "Epoch 1410, Loss: 0.9214864373207092, Final Batch Loss: 0.3059464991092682\n",
      "Epoch 1411, Loss: 0.9094400405883789, Final Batch Loss: 0.28430628776550293\n",
      "Epoch 1412, Loss: 0.9533232152462006, Final Batch Loss: 0.4258001446723938\n",
      "Epoch 1413, Loss: 0.9377571940422058, Final Batch Loss: 0.30938857793807983\n",
      "Epoch 1414, Loss: 0.8473610877990723, Final Batch Loss: 0.2778632342815399\n",
      "Epoch 1415, Loss: 0.9244723618030548, Final Batch Loss: 0.2963936924934387\n",
      "Epoch 1416, Loss: 0.8466969132423401, Final Batch Loss: 0.24529728293418884\n",
      "Epoch 1417, Loss: 0.8918468058109283, Final Batch Loss: 0.2883020043373108\n",
      "Epoch 1418, Loss: 0.8415157198905945, Final Batch Loss: 0.3142165243625641\n",
      "Epoch 1419, Loss: 0.8621330559253693, Final Batch Loss: 0.2820110619068146\n",
      "Epoch 1420, Loss: 0.929457813501358, Final Batch Loss: 0.34869593381881714\n",
      "Epoch 1421, Loss: 0.8978048861026764, Final Batch Loss: 0.3113920986652374\n",
      "Epoch 1422, Loss: 0.8963212370872498, Final Batch Loss: 0.2913607060909271\n",
      "Epoch 1423, Loss: 0.8927390575408936, Final Batch Loss: 0.3075333833694458\n",
      "Epoch 1424, Loss: 0.8150499761104584, Final Batch Loss: 0.21139419078826904\n",
      "Epoch 1425, Loss: 0.8972997963428497, Final Batch Loss: 0.2428026795387268\n",
      "Epoch 1426, Loss: 0.9325050711631775, Final Batch Loss: 0.27166974544525146\n",
      "Epoch 1427, Loss: 0.8536935448646545, Final Batch Loss: 0.30974316596984863\n",
      "Epoch 1428, Loss: 0.896713376045227, Final Batch Loss: 0.2890821397304535\n",
      "Epoch 1429, Loss: 0.8817285895347595, Final Batch Loss: 0.25338053703308105\n",
      "Epoch 1430, Loss: 0.9069622159004211, Final Batch Loss: 0.2952369451522827\n",
      "Epoch 1431, Loss: 0.856155514717102, Final Batch Loss: 0.3286066949367523\n",
      "Epoch 1432, Loss: 0.9073532968759537, Final Batch Loss: 0.39230212569236755\n",
      "Epoch 1433, Loss: 0.925385057926178, Final Batch Loss: 0.3157210648059845\n",
      "Epoch 1434, Loss: 0.9739457666873932, Final Batch Loss: 0.3306672275066376\n",
      "Epoch 1435, Loss: 0.8568811863660812, Final Batch Loss: 0.22971771657466888\n",
      "Epoch 1436, Loss: 0.9305693209171295, Final Batch Loss: 0.2914687693119049\n",
      "Epoch 1437, Loss: 0.9152734875679016, Final Batch Loss: 0.27366116642951965\n",
      "Epoch 1438, Loss: 0.8581493347883224, Final Batch Loss: 0.34221333265304565\n",
      "Epoch 1439, Loss: 0.8991490304470062, Final Batch Loss: 0.31983116269111633\n",
      "Epoch 1440, Loss: 0.9420492053031921, Final Batch Loss: 0.3717997968196869\n",
      "Epoch 1441, Loss: 0.9038721323013306, Final Batch Loss: 0.3416118919849396\n",
      "Epoch 1442, Loss: 0.868768721818924, Final Batch Loss: 0.30211421847343445\n",
      "Epoch 1443, Loss: 1.0024369657039642, Final Batch Loss: 0.4402869641780853\n",
      "Epoch 1444, Loss: 0.8874736726284027, Final Batch Loss: 0.3306896984577179\n",
      "Epoch 1445, Loss: 0.8937257528305054, Final Batch Loss: 0.30437925457954407\n",
      "Epoch 1446, Loss: 0.9398708641529083, Final Batch Loss: 0.35119786858558655\n",
      "Epoch 1447, Loss: 0.9082666337490082, Final Batch Loss: 0.3469281792640686\n",
      "Epoch 1448, Loss: 1.017009973526001, Final Batch Loss: 0.4371556043624878\n",
      "Epoch 1449, Loss: 0.898076668381691, Final Batch Loss: 0.21698229014873505\n",
      "Epoch 1450, Loss: 0.8852726817131042, Final Batch Loss: 0.3183270990848541\n",
      "Epoch 1451, Loss: 0.9196102321147919, Final Batch Loss: 0.3277985155582428\n",
      "Epoch 1452, Loss: 0.9020189344882965, Final Batch Loss: 0.31669336557388306\n",
      "Epoch 1453, Loss: 0.9056034982204437, Final Batch Loss: 0.24483013153076172\n",
      "Epoch 1454, Loss: 0.9679061770439148, Final Batch Loss: 0.3278898596763611\n",
      "Epoch 1455, Loss: 0.8066247552633286, Final Batch Loss: 0.23382501304149628\n",
      "Epoch 1456, Loss: 0.9884770810604095, Final Batch Loss: 0.334238201379776\n",
      "Epoch 1457, Loss: 0.934924989938736, Final Batch Loss: 0.2919786870479584\n",
      "Epoch 1458, Loss: 0.9182224869728088, Final Batch Loss: 0.3160819411277771\n",
      "Epoch 1459, Loss: 0.9456614553928375, Final Batch Loss: 0.35255125164985657\n",
      "Epoch 1460, Loss: 0.8877416849136353, Final Batch Loss: 0.32263219356536865\n",
      "Epoch 1461, Loss: 0.8582785427570343, Final Batch Loss: 0.28231626749038696\n",
      "Epoch 1462, Loss: 0.9831523895263672, Final Batch Loss: 0.31799766421318054\n",
      "Epoch 1463, Loss: 0.8749462962150574, Final Batch Loss: 0.2566726803779602\n",
      "Epoch 1464, Loss: 0.9330292642116547, Final Batch Loss: 0.3742828667163849\n",
      "Epoch 1465, Loss: 0.8725406229496002, Final Batch Loss: 0.2864372432231903\n",
      "Epoch 1466, Loss: 0.883613258600235, Final Batch Loss: 0.270513653755188\n",
      "Epoch 1467, Loss: 0.910048246383667, Final Batch Loss: 0.3785533308982849\n",
      "Epoch 1468, Loss: 0.8733845353126526, Final Batch Loss: 0.17414399981498718\n",
      "Epoch 1469, Loss: 1.0190706253051758, Final Batch Loss: 0.3638390004634857\n",
      "Epoch 1470, Loss: 0.878345251083374, Final Batch Loss: 0.24808353185653687\n",
      "Epoch 1471, Loss: 0.8685972690582275, Final Batch Loss: 0.2801472246646881\n",
      "Epoch 1472, Loss: 0.8668708801269531, Final Batch Loss: 0.28801319003105164\n",
      "Epoch 1473, Loss: 0.8739216327667236, Final Batch Loss: 0.3077264726161957\n",
      "Epoch 1474, Loss: 0.9136584103107452, Final Batch Loss: 0.31132814288139343\n",
      "Epoch 1475, Loss: 0.8268346339464188, Final Batch Loss: 0.21384967863559723\n",
      "Epoch 1476, Loss: 0.8790276944637299, Final Batch Loss: 0.3391452729701996\n",
      "Epoch 1477, Loss: 0.8566914796829224, Final Batch Loss: 0.2637450397014618\n",
      "Epoch 1478, Loss: 0.8453454226255417, Final Batch Loss: 0.2247428148984909\n",
      "Epoch 1479, Loss: 0.9686633348464966, Final Batch Loss: 0.32678309082984924\n",
      "Epoch 1480, Loss: 0.8830500841140747, Final Batch Loss: 0.3035222589969635\n",
      "Epoch 1481, Loss: 0.9155110120773315, Final Batch Loss: 0.3416512608528137\n",
      "Epoch 1482, Loss: 0.8176336139440536, Final Batch Loss: 0.21356718242168427\n",
      "Epoch 1483, Loss: 1.002845138311386, Final Batch Loss: 0.2842928171157837\n",
      "Epoch 1484, Loss: 0.8871504962444305, Final Batch Loss: 0.33665940165519714\n",
      "Epoch 1485, Loss: 0.8594009280204773, Final Batch Loss: 0.30062463879585266\n",
      "Epoch 1486, Loss: 0.8794509172439575, Final Batch Loss: 0.3169700503349304\n",
      "Epoch 1487, Loss: 0.8897692114114761, Final Batch Loss: 0.33643949031829834\n",
      "Epoch 1488, Loss: 0.8842544555664062, Final Batch Loss: 0.3057805299758911\n",
      "Epoch 1489, Loss: 0.8846935629844666, Final Batch Loss: 0.3010985851287842\n",
      "Epoch 1490, Loss: 0.9279535412788391, Final Batch Loss: 0.37766581773757935\n",
      "Epoch 1491, Loss: 0.8886051326990128, Final Batch Loss: 0.2544810175895691\n",
      "Epoch 1492, Loss: 0.8647847175598145, Final Batch Loss: 0.28199973702430725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1493, Loss: 0.9651705920696259, Final Batch Loss: 0.3381677567958832\n",
      "Epoch 1494, Loss: 0.9289434552192688, Final Batch Loss: 0.31707507371902466\n",
      "Epoch 1495, Loss: 0.8755171298980713, Final Batch Loss: 0.3262332081794739\n",
      "Epoch 1496, Loss: 0.8380348980426788, Final Batch Loss: 0.3044588267803192\n",
      "Epoch 1497, Loss: 0.8877940475940704, Final Batch Loss: 0.27841809391975403\n",
      "Epoch 1498, Loss: 0.9181118011474609, Final Batch Loss: 0.32224008440971375\n",
      "Epoch 1499, Loss: 0.9124487638473511, Final Batch Loss: 0.31305116415023804\n",
      "Epoch 1500, Loss: 1.0158004462718964, Final Batch Loss: 0.4296524226665497\n",
      "Epoch 1501, Loss: 0.8605552613735199, Final Batch Loss: 0.24417167901992798\n",
      "Epoch 1502, Loss: 0.903188943862915, Final Batch Loss: 0.33746039867401123\n",
      "Epoch 1503, Loss: 0.8713664263486862, Final Batch Loss: 0.20937933027744293\n",
      "Epoch 1504, Loss: 0.9616210162639618, Final Batch Loss: 0.3525451719760895\n",
      "Epoch 1505, Loss: 0.8653586953878403, Final Batch Loss: 0.22170771658420563\n",
      "Epoch 1506, Loss: 0.9590097367763519, Final Batch Loss: 0.36690932512283325\n",
      "Epoch 1507, Loss: 0.9159711003303528, Final Batch Loss: 0.354729562997818\n",
      "Epoch 1508, Loss: 0.9458195865154266, Final Batch Loss: 0.3404819965362549\n",
      "Epoch 1509, Loss: 0.866045668721199, Final Batch Loss: 0.3210565745830536\n",
      "Epoch 1510, Loss: 0.8291260600090027, Final Batch Loss: 0.24845698475837708\n",
      "Epoch 1511, Loss: 0.9644454121589661, Final Batch Loss: 0.33872535824775696\n",
      "Epoch 1512, Loss: 0.9081735014915466, Final Batch Loss: 0.2721567749977112\n",
      "Epoch 1513, Loss: 0.8978552520275116, Final Batch Loss: 0.4037620723247528\n",
      "Epoch 1514, Loss: 0.9013692140579224, Final Batch Loss: 0.3048665523529053\n",
      "Epoch 1515, Loss: 0.9641343653202057, Final Batch Loss: 0.3394889533519745\n",
      "Epoch 1516, Loss: 0.9283426403999329, Final Batch Loss: 0.34051308035850525\n",
      "Epoch 1517, Loss: 0.9488572776317596, Final Batch Loss: 0.3489095866680145\n",
      "Epoch 1518, Loss: 0.8645029962062836, Final Batch Loss: 0.27244511246681213\n",
      "Epoch 1519, Loss: 0.8792377263307571, Final Batch Loss: 0.3223806619644165\n",
      "Epoch 1520, Loss: 0.908981129527092, Final Batch Loss: 0.36206164956092834\n",
      "Epoch 1521, Loss: 0.9185479879379272, Final Batch Loss: 0.257154643535614\n",
      "Epoch 1522, Loss: 0.9609498977661133, Final Batch Loss: 0.2959479093551636\n",
      "Epoch 1523, Loss: 0.9119773209095001, Final Batch Loss: 0.35714057087898254\n",
      "Epoch 1524, Loss: 0.7926537692546844, Final Batch Loss: 0.2504398822784424\n",
      "Epoch 1525, Loss: 0.8328816890716553, Final Batch Loss: 0.27045193314552307\n",
      "Epoch 1526, Loss: 0.8282014280557632, Final Batch Loss: 0.2622603178024292\n",
      "Epoch 1527, Loss: 0.9846924245357513, Final Batch Loss: 0.40295204520225525\n",
      "Epoch 1528, Loss: 0.8135833591222763, Final Batch Loss: 0.22047172486782074\n",
      "Epoch 1529, Loss: 0.7714348286390305, Final Batch Loss: 0.26502734422683716\n",
      "Epoch 1530, Loss: 0.8715556859970093, Final Batch Loss: 0.2678493559360504\n",
      "Epoch 1531, Loss: 0.8523156046867371, Final Batch Loss: 0.30711132287979126\n",
      "Epoch 1532, Loss: 0.8708303272724152, Final Batch Loss: 0.2922908663749695\n",
      "Epoch 1533, Loss: 0.8691572397947311, Final Batch Loss: 0.35173770785331726\n",
      "Epoch 1534, Loss: 0.8575350940227509, Final Batch Loss: 0.27560049295425415\n",
      "Epoch 1535, Loss: 0.9120900630950928, Final Batch Loss: 0.36285191774368286\n",
      "Epoch 1536, Loss: 0.8764668852090836, Final Batch Loss: 0.32838723063468933\n",
      "Epoch 1537, Loss: 0.9253782629966736, Final Batch Loss: 0.34787464141845703\n",
      "Epoch 1538, Loss: 0.7850497215986252, Final Batch Loss: 0.21536202728748322\n",
      "Epoch 1539, Loss: 0.8060706555843353, Final Batch Loss: 0.2596398591995239\n",
      "Epoch 1540, Loss: 0.9171252250671387, Final Batch Loss: 0.3068428635597229\n",
      "Epoch 1541, Loss: 0.8411281406879425, Final Batch Loss: 0.21857187151908875\n",
      "Epoch 1542, Loss: 0.9411426186561584, Final Batch Loss: 0.2627205550670624\n",
      "Epoch 1543, Loss: 0.9542413949966431, Final Batch Loss: 0.38137343525886536\n",
      "Epoch 1544, Loss: 0.7791176289319992, Final Batch Loss: 0.2724457085132599\n",
      "Epoch 1545, Loss: 0.9156381636857986, Final Batch Loss: 0.36141249537467957\n",
      "Epoch 1546, Loss: 0.8202813267707825, Final Batch Loss: 0.28693485260009766\n",
      "Epoch 1547, Loss: 0.8736318647861481, Final Batch Loss: 0.3467088043689728\n",
      "Epoch 1548, Loss: 0.886684000492096, Final Batch Loss: 0.2979418635368347\n",
      "Epoch 1549, Loss: 0.8181422203779221, Final Batch Loss: 0.302694171667099\n",
      "Epoch 1550, Loss: 0.7962370216846466, Final Batch Loss: 0.21514004468917847\n",
      "Epoch 1551, Loss: 0.9510279595851898, Final Batch Loss: 0.30174365639686584\n",
      "Epoch 1552, Loss: 0.8805964887142181, Final Batch Loss: 0.26929664611816406\n",
      "Epoch 1553, Loss: 0.8406220376491547, Final Batch Loss: 0.2545817792415619\n",
      "Epoch 1554, Loss: 0.8628115355968475, Final Batch Loss: 0.242994487285614\n",
      "Epoch 1555, Loss: 0.8281536251306534, Final Batch Loss: 0.241581991314888\n",
      "Epoch 1556, Loss: 0.8279512077569962, Final Batch Loss: 0.22849975526332855\n",
      "Epoch 1557, Loss: 0.9051952064037323, Final Batch Loss: 0.2816276252269745\n",
      "Epoch 1558, Loss: 0.8650546818971634, Final Batch Loss: 0.20213980972766876\n",
      "Epoch 1559, Loss: 0.8348153233528137, Final Batch Loss: 0.25712472200393677\n",
      "Epoch 1560, Loss: 0.8404965400695801, Final Batch Loss: 0.20343035459518433\n",
      "Epoch 1561, Loss: 0.87525475025177, Final Batch Loss: 0.3221285343170166\n",
      "Epoch 1562, Loss: 0.8659245520830154, Final Batch Loss: 0.23789580166339874\n",
      "Epoch 1563, Loss: 0.857679545879364, Final Batch Loss: 0.2526971399784088\n",
      "Epoch 1564, Loss: 0.8384499251842499, Final Batch Loss: 0.2976043224334717\n",
      "Epoch 1565, Loss: 0.8091746419668198, Final Batch Loss: 0.2402295023202896\n",
      "Epoch 1566, Loss: 0.9376223385334015, Final Batch Loss: 0.31129834055900574\n",
      "Epoch 1567, Loss: 0.8160198479890823, Final Batch Loss: 0.2307828813791275\n",
      "Epoch 1568, Loss: 0.9322517514228821, Final Batch Loss: 0.378595769405365\n",
      "Epoch 1569, Loss: 0.8124735057353973, Final Batch Loss: 0.21977469325065613\n",
      "Epoch 1570, Loss: 0.9222525358200073, Final Batch Loss: 0.35047367215156555\n",
      "Epoch 1571, Loss: 0.8995310068130493, Final Batch Loss: 0.27813372015953064\n",
      "Epoch 1572, Loss: 0.8105571866035461, Final Batch Loss: 0.2821339964866638\n",
      "Epoch 1573, Loss: 0.9753110706806183, Final Batch Loss: 0.2982558012008667\n",
      "Epoch 1574, Loss: 0.9334462881088257, Final Batch Loss: 0.3423106074333191\n",
      "Epoch 1575, Loss: 0.9140644669532776, Final Batch Loss: 0.34442293643951416\n",
      "Epoch 1576, Loss: 0.8803217113018036, Final Batch Loss: 0.28341931104660034\n",
      "Epoch 1577, Loss: 0.9339285790920258, Final Batch Loss: 0.308051735162735\n",
      "Epoch 1578, Loss: 0.849261462688446, Final Batch Loss: 0.25633975863456726\n",
      "Epoch 1579, Loss: 0.8603591024875641, Final Batch Loss: 0.2835272550582886\n",
      "Epoch 1580, Loss: 0.8160315454006195, Final Batch Loss: 0.26405882835388184\n",
      "Epoch 1581, Loss: 0.786571204662323, Final Batch Loss: 0.24229015409946442\n",
      "Epoch 1582, Loss: 0.9081997275352478, Final Batch Loss: 0.33240005373954773\n",
      "Epoch 1583, Loss: 0.7863495200872421, Final Batch Loss: 0.2251325398683548\n",
      "Epoch 1584, Loss: 0.8041562438011169, Final Batch Loss: 0.2507804036140442\n",
      "Epoch 1585, Loss: 0.9353789687156677, Final Batch Loss: 0.3704036474227905\n",
      "Epoch 1586, Loss: 0.7425156682729721, Final Batch Loss: 0.22848986089229584\n",
      "Epoch 1587, Loss: 0.7867546379566193, Final Batch Loss: 0.23758207261562347\n",
      "Epoch 1588, Loss: 0.8498034775257111, Final Batch Loss: 0.38429659605026245\n",
      "Epoch 1589, Loss: 0.8162481039762497, Final Batch Loss: 0.24305574595928192\n",
      "Epoch 1590, Loss: 0.9305503070354462, Final Batch Loss: 0.34351128339767456\n",
      "Epoch 1591, Loss: 0.8421172797679901, Final Batch Loss: 0.29442062973976135\n",
      "Epoch 1592, Loss: 0.8455716520547867, Final Batch Loss: 0.21914543211460114\n",
      "Epoch 1593, Loss: 0.7603172659873962, Final Batch Loss: 0.18612071871757507\n",
      "Epoch 1594, Loss: 0.894827201962471, Final Batch Loss: 0.3581275939941406\n",
      "Epoch 1595, Loss: 0.8886878788471222, Final Batch Loss: 0.2884266972541809\n",
      "Epoch 1596, Loss: 0.8644357621669769, Final Batch Loss: 0.2706941068172455\n",
      "Epoch 1597, Loss: 0.9424889087677002, Final Batch Loss: 0.32183638215065\n",
      "Epoch 1598, Loss: 0.7898624539375305, Final Batch Loss: 0.22215965390205383\n",
      "Epoch 1599, Loss: 0.8942404985427856, Final Batch Loss: 0.37181082367897034\n",
      "Epoch 1600, Loss: 0.8363930433988571, Final Batch Loss: 0.32754987478256226\n",
      "Epoch 1601, Loss: 0.9506596922874451, Final Batch Loss: 0.36888307332992554\n",
      "Epoch 1602, Loss: 0.8242801427841187, Final Batch Loss: 0.24453404545783997\n",
      "Epoch 1603, Loss: 0.8590021431446075, Final Batch Loss: 0.2832562029361725\n",
      "Epoch 1604, Loss: 0.8869881480932236, Final Batch Loss: 0.23806671798229218\n",
      "Epoch 1605, Loss: 0.9415695667266846, Final Batch Loss: 0.2626008093357086\n",
      "Epoch 1606, Loss: 1.00545933842659, Final Batch Loss: 0.39988425374031067\n",
      "Epoch 1607, Loss: 0.9311144351959229, Final Batch Loss: 0.2827928364276886\n",
      "Epoch 1608, Loss: 0.8335444331169128, Final Batch Loss: 0.2780151069164276\n",
      "Epoch 1609, Loss: 0.7962490767240524, Final Batch Loss: 0.2829209268093109\n",
      "Epoch 1610, Loss: 0.8597298860549927, Final Batch Loss: 0.30970075726509094\n",
      "Epoch 1611, Loss: 0.8152259588241577, Final Batch Loss: 0.27391406893730164\n",
      "Epoch 1612, Loss: 0.8432762026786804, Final Batch Loss: 0.33151569962501526\n",
      "Epoch 1613, Loss: 0.8630181849002838, Final Batch Loss: 0.262061208486557\n",
      "Epoch 1614, Loss: 0.8503078073263168, Final Batch Loss: 0.28026071190834045\n",
      "Epoch 1615, Loss: 0.9262290447950363, Final Batch Loss: 0.40420883893966675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1616, Loss: 0.9200700223445892, Final Batch Loss: 0.3566415011882782\n",
      "Epoch 1617, Loss: 0.773553654551506, Final Batch Loss: 0.24942778050899506\n",
      "Epoch 1618, Loss: 0.9061754047870636, Final Batch Loss: 0.31469395756721497\n",
      "Epoch 1619, Loss: 0.8101947605609894, Final Batch Loss: 0.3055167496204376\n",
      "Epoch 1620, Loss: 0.9113140404224396, Final Batch Loss: 0.27441859245300293\n",
      "Epoch 1621, Loss: 0.8400560319423676, Final Batch Loss: 0.32456210255622864\n",
      "Epoch 1622, Loss: 0.9013044834136963, Final Batch Loss: 0.2747851312160492\n",
      "Epoch 1623, Loss: 0.9331790506839752, Final Batch Loss: 0.39601969718933105\n",
      "Epoch 1624, Loss: 0.8315657526254654, Final Batch Loss: 0.28077414631843567\n",
      "Epoch 1625, Loss: 0.958554595708847, Final Batch Loss: 0.36553001403808594\n",
      "Epoch 1626, Loss: 0.8424296677112579, Final Batch Loss: 0.27403199672698975\n",
      "Epoch 1627, Loss: 0.9570911526679993, Final Batch Loss: 0.3222694396972656\n",
      "Epoch 1628, Loss: 0.8158950209617615, Final Batch Loss: 0.26550883054733276\n",
      "Epoch 1629, Loss: 0.931727796792984, Final Batch Loss: 0.33795228600502014\n",
      "Epoch 1630, Loss: 0.8753543198108673, Final Batch Loss: 0.233041912317276\n",
      "Epoch 1631, Loss: 0.9598182141780853, Final Batch Loss: 0.313897967338562\n",
      "Epoch 1632, Loss: 0.8301311731338501, Final Batch Loss: 0.30897054076194763\n",
      "Epoch 1633, Loss: 0.8359773010015488, Final Batch Loss: 0.3048112392425537\n",
      "Epoch 1634, Loss: 0.8647747933864594, Final Batch Loss: 0.2777169644832611\n",
      "Epoch 1635, Loss: 0.8327120989561081, Final Batch Loss: 0.31863588094711304\n",
      "Epoch 1636, Loss: 0.8441105484962463, Final Batch Loss: 0.2433205544948578\n",
      "Epoch 1637, Loss: 0.8282705545425415, Final Batch Loss: 0.2535080909729004\n",
      "Epoch 1638, Loss: 0.8129386901855469, Final Batch Loss: 0.25722670555114746\n",
      "Epoch 1639, Loss: 0.8924228549003601, Final Batch Loss: 0.3190273344516754\n",
      "Epoch 1640, Loss: 0.8134939670562744, Final Batch Loss: 0.174008309841156\n",
      "Epoch 1641, Loss: 0.9119422435760498, Final Batch Loss: 0.3049972951412201\n",
      "Epoch 1642, Loss: 0.8889941573143005, Final Batch Loss: 0.3391997516155243\n",
      "Epoch 1643, Loss: 0.9068402349948883, Final Batch Loss: 0.3765714168548584\n",
      "Epoch 1644, Loss: 0.83677938580513, Final Batch Loss: 0.24767601490020752\n",
      "Epoch 1645, Loss: 0.8263643234968185, Final Batch Loss: 0.2409972995519638\n",
      "Epoch 1646, Loss: 0.8594684898853302, Final Batch Loss: 0.23299840092658997\n",
      "Epoch 1647, Loss: 0.8314340710639954, Final Batch Loss: 0.2424900233745575\n",
      "Epoch 1648, Loss: 0.9647913873195648, Final Batch Loss: 0.35547128319740295\n",
      "Epoch 1649, Loss: 0.8328762054443359, Final Batch Loss: 0.2731436491012573\n",
      "Epoch 1650, Loss: 0.986015260219574, Final Batch Loss: 0.42363211512565613\n",
      "Epoch 1651, Loss: 0.9380459487438202, Final Batch Loss: 0.40305402874946594\n",
      "Epoch 1652, Loss: 0.8342253863811493, Final Batch Loss: 0.3516763746738434\n",
      "Epoch 1653, Loss: 0.8017555773258209, Final Batch Loss: 0.2186642736196518\n",
      "Epoch 1654, Loss: 0.9290013313293457, Final Batch Loss: 0.31244245171546936\n",
      "Epoch 1655, Loss: 0.8155863285064697, Final Batch Loss: 0.2730814516544342\n",
      "Epoch 1656, Loss: 0.8061797618865967, Final Batch Loss: 0.22617754340171814\n",
      "Epoch 1657, Loss: 0.7673202902078629, Final Batch Loss: 0.26538604497909546\n",
      "Epoch 1658, Loss: 0.7796811759471893, Final Batch Loss: 0.19133269786834717\n",
      "Epoch 1659, Loss: 0.8969079256057739, Final Batch Loss: 0.34882375597953796\n",
      "Epoch 1660, Loss: 0.9165085256099701, Final Batch Loss: 0.29942426085472107\n",
      "Epoch 1661, Loss: 0.9090506732463837, Final Batch Loss: 0.31459176540374756\n",
      "Epoch 1662, Loss: 0.8886635005474091, Final Batch Loss: 0.27192655205726624\n",
      "Epoch 1663, Loss: 0.864464521408081, Final Batch Loss: 0.34288713335990906\n",
      "Epoch 1664, Loss: 0.876927986741066, Final Batch Loss: 0.3470349609851837\n",
      "Epoch 1665, Loss: 0.8661614656448364, Final Batch Loss: 0.3019443154335022\n",
      "Epoch 1666, Loss: 0.9898773431777954, Final Batch Loss: 0.3723839819431305\n",
      "Epoch 1667, Loss: 0.7927054911851883, Final Batch Loss: 0.22461412847042084\n",
      "Epoch 1668, Loss: 0.8858533203601837, Final Batch Loss: 0.3363040089607239\n",
      "Epoch 1669, Loss: 0.8986253440380096, Final Batch Loss: 0.36543065309524536\n",
      "Epoch 1670, Loss: 0.8693795204162598, Final Batch Loss: 0.20827147364616394\n",
      "Epoch 1671, Loss: 0.7841469049453735, Final Batch Loss: 0.19416603446006775\n",
      "Epoch 1672, Loss: 0.7566836923360825, Final Batch Loss: 0.2067570984363556\n",
      "Epoch 1673, Loss: 0.9050728380680084, Final Batch Loss: 0.3188953101634979\n",
      "Epoch 1674, Loss: 0.9131961464881897, Final Batch Loss: 0.3232758045196533\n",
      "Epoch 1675, Loss: 0.8150541186332703, Final Batch Loss: 0.28511279821395874\n",
      "Epoch 1676, Loss: 0.8181127607822418, Final Batch Loss: 0.3002595901489258\n",
      "Epoch 1677, Loss: 0.9092359840869904, Final Batch Loss: 0.3495098054409027\n",
      "Epoch 1678, Loss: 0.8191529512405396, Final Batch Loss: 0.22426387667655945\n",
      "Epoch 1679, Loss: 0.965019479393959, Final Batch Loss: 0.41110891103744507\n",
      "Epoch 1680, Loss: 0.8081921935081482, Final Batch Loss: 0.24053990840911865\n",
      "Epoch 1681, Loss: 0.8591313064098358, Final Batch Loss: 0.26176273822784424\n",
      "Epoch 1682, Loss: 0.8835535049438477, Final Batch Loss: 0.34035342931747437\n",
      "Epoch 1683, Loss: 0.8334992229938507, Final Batch Loss: 0.28216516971588135\n",
      "Epoch 1684, Loss: 0.8022318929433823, Final Batch Loss: 0.23778791725635529\n",
      "Epoch 1685, Loss: 0.8444473147392273, Final Batch Loss: 0.2226008176803589\n",
      "Epoch 1686, Loss: 0.8549056351184845, Final Batch Loss: 0.29852816462516785\n",
      "Epoch 1687, Loss: 0.8334958553314209, Final Batch Loss: 0.3025425374507904\n",
      "Epoch 1688, Loss: 0.8023917227983475, Final Batch Loss: 0.22699563205242157\n",
      "Epoch 1689, Loss: 0.8673910200595856, Final Batch Loss: 0.3170665204524994\n",
      "Epoch 1690, Loss: 0.830380380153656, Final Batch Loss: 0.2582155764102936\n",
      "Epoch 1691, Loss: 0.8368765115737915, Final Batch Loss: 0.2744850516319275\n",
      "Epoch 1692, Loss: 0.9038252532482147, Final Batch Loss: 0.2903438210487366\n",
      "Epoch 1693, Loss: 0.809286504983902, Final Batch Loss: 0.22696489095687866\n",
      "Epoch 1694, Loss: 0.9054044485092163, Final Batch Loss: 0.3426063358783722\n",
      "Epoch 1695, Loss: 0.8697560280561447, Final Batch Loss: 0.37260377407073975\n",
      "Epoch 1696, Loss: 0.8598861992359161, Final Batch Loss: 0.2546252906322479\n",
      "Epoch 1697, Loss: 0.882615327835083, Final Batch Loss: 0.26756298542022705\n",
      "Epoch 1698, Loss: 0.8566205054521561, Final Batch Loss: 0.30468809604644775\n",
      "Epoch 1699, Loss: 0.8832521438598633, Final Batch Loss: 0.2896997928619385\n",
      "Epoch 1700, Loss: 0.845466822385788, Final Batch Loss: 0.23197969794273376\n",
      "Epoch 1701, Loss: 0.807257816195488, Final Batch Loss: 0.27705442905426025\n",
      "Epoch 1702, Loss: 0.9385173916816711, Final Batch Loss: 0.43690237402915955\n",
      "Epoch 1703, Loss: 0.8033999055624008, Final Batch Loss: 0.20577098429203033\n",
      "Epoch 1704, Loss: 0.9331387430429459, Final Batch Loss: 0.3913350999355316\n",
      "Epoch 1705, Loss: 0.8419326394796371, Final Batch Loss: 0.298160582780838\n",
      "Epoch 1706, Loss: 0.9131673574447632, Final Batch Loss: 0.2972119152545929\n",
      "Epoch 1707, Loss: 0.8869212567806244, Final Batch Loss: 0.2992447316646576\n",
      "Epoch 1708, Loss: 0.882877767086029, Final Batch Loss: 0.2825809419155121\n",
      "Epoch 1709, Loss: 0.8014811277389526, Final Batch Loss: 0.26684996485710144\n",
      "Epoch 1710, Loss: 0.9015480279922485, Final Batch Loss: 0.33764705061912537\n",
      "Epoch 1711, Loss: 0.8334541618824005, Final Batch Loss: 0.23226693272590637\n",
      "Epoch 1712, Loss: 0.8702711760997772, Final Batch Loss: 0.26206672191619873\n",
      "Epoch 1713, Loss: 0.8474691808223724, Final Batch Loss: 0.3009951412677765\n",
      "Epoch 1714, Loss: 0.9109330177307129, Final Batch Loss: 0.2369237244129181\n",
      "Epoch 1715, Loss: 0.8305657058954239, Final Batch Loss: 0.33966052532196045\n",
      "Epoch 1716, Loss: 0.8657012283802032, Final Batch Loss: 0.3628464341163635\n",
      "Epoch 1717, Loss: 0.7618355005979538, Final Batch Loss: 0.20468951761722565\n",
      "Epoch 1718, Loss: 0.7796493768692017, Final Batch Loss: 0.2643398344516754\n",
      "Epoch 1719, Loss: 0.8250767886638641, Final Batch Loss: 0.2797066569328308\n",
      "Epoch 1720, Loss: 0.8397147357463837, Final Batch Loss: 0.25224143266677856\n",
      "Epoch 1721, Loss: 0.8650232553482056, Final Batch Loss: 0.3451487123966217\n",
      "Epoch 1722, Loss: 0.8233856856822968, Final Batch Loss: 0.3130818009376526\n",
      "Epoch 1723, Loss: 0.7714944630861282, Final Batch Loss: 0.2242889255285263\n",
      "Epoch 1724, Loss: 0.9161063730716705, Final Batch Loss: 0.3376891016960144\n",
      "Epoch 1725, Loss: 0.7939044088125229, Final Batch Loss: 0.24515752494335175\n",
      "Epoch 1726, Loss: 0.8071706593036652, Final Batch Loss: 0.3234501779079437\n",
      "Epoch 1727, Loss: 0.8769664466381073, Final Batch Loss: 0.2678597569465637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1728, Loss: 0.8547137379646301, Final Batch Loss: 0.28690728545188904\n",
      "Epoch 1729, Loss: 0.8194732069969177, Final Batch Loss: 0.28536030650138855\n",
      "Epoch 1730, Loss: 0.9174782931804657, Final Batch Loss: 0.2832332253456116\n",
      "Epoch 1731, Loss: 0.8331072479486465, Final Batch Loss: 0.3284494876861572\n",
      "Epoch 1732, Loss: 0.767647385597229, Final Batch Loss: 0.23617812991142273\n",
      "Epoch 1733, Loss: 0.9674709141254425, Final Batch Loss: 0.381841242313385\n",
      "Epoch 1734, Loss: 0.7752038091421127, Final Batch Loss: 0.23762769997119904\n",
      "Epoch 1735, Loss: 0.8832122087478638, Final Batch Loss: 0.32051363587379456\n",
      "Epoch 1736, Loss: 0.9284347891807556, Final Batch Loss: 0.339125394821167\n",
      "Epoch 1737, Loss: 0.8210296183824539, Final Batch Loss: 0.24790574610233307\n",
      "Epoch 1738, Loss: 0.7871283143758774, Final Batch Loss: 0.21212781965732574\n",
      "Epoch 1739, Loss: 0.8617382347583771, Final Batch Loss: 0.27217742800712585\n",
      "Epoch 1740, Loss: 0.8515226989984512, Final Batch Loss: 0.3027685880661011\n",
      "Epoch 1741, Loss: 0.9437166154384613, Final Batch Loss: 0.3132537305355072\n",
      "Epoch 1742, Loss: 0.8516014367341995, Final Batch Loss: 0.24749988317489624\n",
      "Epoch 1743, Loss: 0.784910187125206, Final Batch Loss: 0.28080305457115173\n",
      "Epoch 1744, Loss: 0.8929904401302338, Final Batch Loss: 0.27724993228912354\n",
      "Epoch 1745, Loss: 0.8255128115415573, Final Batch Loss: 0.33242592215538025\n",
      "Epoch 1746, Loss: 0.8337336182594299, Final Batch Loss: 0.2773699462413788\n",
      "Epoch 1747, Loss: 0.9061766266822815, Final Batch Loss: 0.3615753650665283\n",
      "Epoch 1748, Loss: 0.9140078872442245, Final Batch Loss: 0.3814329206943512\n",
      "Epoch 1749, Loss: 0.6989532560110092, Final Batch Loss: 0.16920320689678192\n",
      "Epoch 1750, Loss: 0.82513228058815, Final Batch Loss: 0.2676858901977539\n",
      "Epoch 1751, Loss: 0.8370327800512314, Final Batch Loss: 0.2391170710325241\n",
      "Epoch 1752, Loss: 0.9255439639091492, Final Batch Loss: 0.45697808265686035\n",
      "Epoch 1753, Loss: 0.7600619345903397, Final Batch Loss: 0.22642956674098969\n",
      "Epoch 1754, Loss: 0.8961625695228577, Final Batch Loss: 0.2929880917072296\n",
      "Epoch 1755, Loss: 0.8447019457817078, Final Batch Loss: 0.3355218470096588\n",
      "Epoch 1756, Loss: 0.8706120699644089, Final Batch Loss: 0.33324378728866577\n",
      "Epoch 1757, Loss: 0.8401563763618469, Final Batch Loss: 0.2835686206817627\n",
      "Epoch 1758, Loss: 0.8319169580936432, Final Batch Loss: 0.2575932443141937\n",
      "Epoch 1759, Loss: 0.9082835614681244, Final Batch Loss: 0.3724501132965088\n",
      "Epoch 1760, Loss: 1.078545093536377, Final Batch Loss: 0.5231540203094482\n",
      "Epoch 1761, Loss: 0.8456517457962036, Final Batch Loss: 0.281086802482605\n",
      "Epoch 1762, Loss: 0.8679147511720657, Final Batch Loss: 0.3020899295806885\n",
      "Epoch 1763, Loss: 0.7995118647813797, Final Batch Loss: 0.20032013952732086\n",
      "Epoch 1764, Loss: 0.7876434028148651, Final Batch Loss: 0.24400222301483154\n",
      "Epoch 1765, Loss: 0.9231337308883667, Final Batch Loss: 0.35828980803489685\n",
      "Epoch 1766, Loss: 0.8297337889671326, Final Batch Loss: 0.2592485845088959\n",
      "Epoch 1767, Loss: 0.82754185795784, Final Batch Loss: 0.24742081761360168\n",
      "Epoch 1768, Loss: 0.8827525824308395, Final Batch Loss: 0.23705948889255524\n",
      "Epoch 1769, Loss: 0.7932632267475128, Final Batch Loss: 0.22005558013916016\n",
      "Epoch 1770, Loss: 0.8143874406814575, Final Batch Loss: 0.312604695558548\n",
      "Epoch 1771, Loss: 0.9261178970336914, Final Batch Loss: 0.31421273946762085\n",
      "Epoch 1772, Loss: 0.7860898375511169, Final Batch Loss: 0.19063076376914978\n",
      "Epoch 1773, Loss: 1.02474045753479, Final Batch Loss: 0.4292415976524353\n",
      "Epoch 1774, Loss: 0.9088355302810669, Final Batch Loss: 0.31553012132644653\n",
      "Epoch 1775, Loss: 0.890701949596405, Final Batch Loss: 0.3451503813266754\n",
      "Epoch 1776, Loss: 0.8829311430454254, Final Batch Loss: 0.3354291617870331\n",
      "Epoch 1777, Loss: 0.8626570403575897, Final Batch Loss: 0.25053271651268005\n",
      "Epoch 1778, Loss: 0.8054286539554596, Final Batch Loss: 0.308450311422348\n",
      "Epoch 1779, Loss: 0.7790428698062897, Final Batch Loss: 0.29547080397605896\n",
      "Epoch 1780, Loss: 0.8794434368610382, Final Batch Loss: 0.3293629288673401\n",
      "Epoch 1781, Loss: 0.7702268213033676, Final Batch Loss: 0.27532267570495605\n",
      "Epoch 1782, Loss: 0.8285161256790161, Final Batch Loss: 0.3046216070652008\n",
      "Epoch 1783, Loss: 0.837160587310791, Final Batch Loss: 0.3056461811065674\n",
      "Epoch 1784, Loss: 0.8578817546367645, Final Batch Loss: 0.32204359769821167\n",
      "Epoch 1785, Loss: 0.784581184387207, Final Batch Loss: 0.2823457717895508\n",
      "Epoch 1786, Loss: 0.9182519316673279, Final Batch Loss: 0.3565533459186554\n",
      "Epoch 1787, Loss: 0.9032988548278809, Final Batch Loss: 0.2809987962245941\n",
      "Epoch 1788, Loss: 0.860339343547821, Final Batch Loss: 0.21746990084648132\n",
      "Epoch 1789, Loss: 0.879045382142067, Final Batch Loss: 0.21656106412410736\n",
      "Epoch 1790, Loss: 0.8423691093921661, Final Batch Loss: 0.28324565291404724\n",
      "Epoch 1791, Loss: 0.7166534066200256, Final Batch Loss: 0.1841818243265152\n",
      "Epoch 1792, Loss: 0.8063224405050278, Final Batch Loss: 0.26940590143203735\n",
      "Epoch 1793, Loss: 0.7776182889938354, Final Batch Loss: 0.2776881456375122\n",
      "Epoch 1794, Loss: 0.8700405359268188, Final Batch Loss: 0.3856246769428253\n",
      "Epoch 1795, Loss: 0.7331808358430862, Final Batch Loss: 0.21368587017059326\n",
      "Epoch 1796, Loss: 0.7701292783021927, Final Batch Loss: 0.2261330634355545\n",
      "Epoch 1797, Loss: 0.7999367713928223, Final Batch Loss: 0.25879842042922974\n",
      "Epoch 1798, Loss: 0.812634289264679, Final Batch Loss: 0.2915589511394501\n",
      "Epoch 1799, Loss: 0.7401485741138458, Final Batch Loss: 0.22588792443275452\n",
      "Epoch 1800, Loss: 0.7754278182983398, Final Batch Loss: 0.2335403859615326\n",
      "Epoch 1801, Loss: 0.7697615772485733, Final Batch Loss: 0.2616376578807831\n",
      "Epoch 1802, Loss: 0.8064727187156677, Final Batch Loss: 0.25652313232421875\n",
      "Epoch 1803, Loss: 0.8366830348968506, Final Batch Loss: 0.2839445471763611\n",
      "Epoch 1804, Loss: 0.8563829064369202, Final Batch Loss: 0.3440927267074585\n",
      "Epoch 1805, Loss: 0.8195753991603851, Final Batch Loss: 0.23716557025909424\n",
      "Epoch 1806, Loss: 0.7575220614671707, Final Batch Loss: 0.21014873683452606\n",
      "Epoch 1807, Loss: 0.8121958374977112, Final Batch Loss: 0.2615997791290283\n",
      "Epoch 1808, Loss: 0.8056747615337372, Final Batch Loss: 0.2847733199596405\n",
      "Epoch 1809, Loss: 0.7474010288715363, Final Batch Loss: 0.18524253368377686\n",
      "Epoch 1810, Loss: 0.8065160512924194, Final Batch Loss: 0.2316156029701233\n",
      "Epoch 1811, Loss: 0.7627796977758408, Final Batch Loss: 0.22633622586727142\n",
      "Epoch 1812, Loss: 0.7704233527183533, Final Batch Loss: 0.2523278594017029\n",
      "Epoch 1813, Loss: 0.9105552434921265, Final Batch Loss: 0.37821894884109497\n",
      "Epoch 1814, Loss: 0.8110974431037903, Final Batch Loss: 0.267653226852417\n",
      "Epoch 1815, Loss: 0.7079360485076904, Final Batch Loss: 0.22520270943641663\n",
      "Epoch 1816, Loss: 0.7344289124011993, Final Batch Loss: 0.20237401127815247\n",
      "Epoch 1817, Loss: 0.7724327743053436, Final Batch Loss: 0.2592625319957733\n",
      "Epoch 1818, Loss: 0.901737630367279, Final Batch Loss: 0.2768680453300476\n",
      "Epoch 1819, Loss: 0.8044656813144684, Final Batch Loss: 0.2834465503692627\n",
      "Epoch 1820, Loss: 0.8507881015539169, Final Batch Loss: 0.3084389567375183\n",
      "Epoch 1821, Loss: 0.9367744326591492, Final Batch Loss: 0.35109660029411316\n",
      "Epoch 1822, Loss: 0.8581030666828156, Final Batch Loss: 0.2579873502254486\n",
      "Epoch 1823, Loss: 0.8301232904195786, Final Batch Loss: 0.2257230430841446\n",
      "Epoch 1824, Loss: 0.8059904426336288, Final Batch Loss: 0.23311294615268707\n",
      "Epoch 1825, Loss: 0.8667209446430206, Final Batch Loss: 0.2651768624782562\n",
      "Epoch 1826, Loss: 0.8944257497787476, Final Batch Loss: 0.3316839933395386\n",
      "Epoch 1827, Loss: 0.7735831141471863, Final Batch Loss: 0.24439997971057892\n",
      "Epoch 1828, Loss: 0.7979680448770523, Final Batch Loss: 0.19810660183429718\n",
      "Epoch 1829, Loss: 0.8837670981884003, Final Batch Loss: 0.3002476394176483\n",
      "Epoch 1830, Loss: 0.7645746618509293, Final Batch Loss: 0.22758357226848602\n",
      "Epoch 1831, Loss: 0.7255754470825195, Final Batch Loss: 0.20990478992462158\n",
      "Epoch 1832, Loss: 0.8487455397844315, Final Batch Loss: 0.19008709490299225\n",
      "Epoch 1833, Loss: 0.8561055809259415, Final Batch Loss: 0.2892427444458008\n",
      "Epoch 1834, Loss: 0.9108605980873108, Final Batch Loss: 0.3309377133846283\n",
      "Epoch 1835, Loss: 0.7724660933017731, Final Batch Loss: 0.182095006108284\n",
      "Epoch 1836, Loss: 0.8448254466056824, Final Batch Loss: 0.3004090487957001\n",
      "Epoch 1837, Loss: 0.8080869764089584, Final Batch Loss: 0.20172201097011566\n",
      "Epoch 1838, Loss: 0.8686569631099701, Final Batch Loss: 0.2603520154953003\n",
      "Epoch 1839, Loss: 0.9272142797708511, Final Batch Loss: 0.4165704548358917\n",
      "Epoch 1840, Loss: 0.7984700053930283, Final Batch Loss: 0.24668274819850922\n",
      "Epoch 1841, Loss: 0.74687859416008, Final Batch Loss: 0.24505715072155\n",
      "Epoch 1842, Loss: 0.6982487142086029, Final Batch Loss: 0.1792439967393875\n",
      "Epoch 1843, Loss: 0.9742064476013184, Final Batch Loss: 0.4583318829536438\n",
      "Epoch 1844, Loss: 0.8297015577554703, Final Batch Loss: 0.30797284841537476\n",
      "Epoch 1845, Loss: 0.8573751300573349, Final Batch Loss: 0.3693513870239258\n",
      "Epoch 1846, Loss: 0.8124314695596695, Final Batch Loss: 0.24761466681957245\n",
      "Epoch 1847, Loss: 0.8695809841156006, Final Batch Loss: 0.322416752576828\n",
      "Epoch 1848, Loss: 0.8128078579902649, Final Batch Loss: 0.22807294130325317\n",
      "Epoch 1849, Loss: 0.8495504707098007, Final Batch Loss: 0.3127732574939728\n",
      "Epoch 1850, Loss: 0.8833561092615128, Final Batch Loss: 0.21076472103595734\n",
      "Epoch 1851, Loss: 0.798613891005516, Final Batch Loss: 0.2257317155599594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1852, Loss: 0.8046276271343231, Final Batch Loss: 0.2545093595981598\n",
      "Epoch 1853, Loss: 0.9209142327308655, Final Batch Loss: 0.3762170672416687\n",
      "Epoch 1854, Loss: 0.8042680025100708, Final Batch Loss: 0.21524181962013245\n",
      "Epoch 1855, Loss: 0.8898917436599731, Final Batch Loss: 0.3516828715801239\n",
      "Epoch 1856, Loss: 0.8524929881095886, Final Batch Loss: 0.26410791277885437\n",
      "Epoch 1857, Loss: 0.9674277305603027, Final Batch Loss: 0.4123404324054718\n",
      "Epoch 1858, Loss: 0.7609239369630814, Final Batch Loss: 0.1684669703245163\n",
      "Epoch 1859, Loss: 0.8005980253219604, Final Batch Loss: 0.2835679352283478\n",
      "Epoch 1860, Loss: 0.7494428306818008, Final Batch Loss: 0.2508716285228729\n",
      "Epoch 1861, Loss: 0.8504340499639511, Final Batch Loss: 0.28240177035331726\n",
      "Epoch 1862, Loss: 0.7842910587787628, Final Batch Loss: 0.23302727937698364\n",
      "Epoch 1863, Loss: 0.8173962980508804, Final Batch Loss: 0.2858882546424866\n",
      "Epoch 1864, Loss: 0.7349459081888199, Final Batch Loss: 0.189610555768013\n",
      "Epoch 1865, Loss: 0.8880933225154877, Final Batch Loss: 0.29534777998924255\n",
      "Epoch 1866, Loss: 0.7764360904693604, Final Batch Loss: 0.2670947313308716\n",
      "Epoch 1867, Loss: 0.7765279412269592, Final Batch Loss: 0.25401589274406433\n",
      "Epoch 1868, Loss: 0.7578659504652023, Final Batch Loss: 0.22193749248981476\n",
      "Epoch 1869, Loss: 0.7360582202672958, Final Batch Loss: 0.2554579973220825\n",
      "Epoch 1870, Loss: 0.7538412064313889, Final Batch Loss: 0.19108568131923676\n",
      "Epoch 1871, Loss: 0.791596919298172, Final Batch Loss: 0.27117720246315\n",
      "Epoch 1872, Loss: 0.813702717423439, Final Batch Loss: 0.22332055866718292\n",
      "Epoch 1873, Loss: 0.7874780744314194, Final Batch Loss: 0.24568216502666473\n",
      "Epoch 1874, Loss: 0.8246742933988571, Final Batch Loss: 0.29546257853507996\n",
      "Epoch 1875, Loss: 0.7820902913808823, Final Batch Loss: 0.19579006731510162\n",
      "Epoch 1876, Loss: 0.8006328344345093, Final Batch Loss: 0.2243739366531372\n",
      "Epoch 1877, Loss: 0.7440392822027206, Final Batch Loss: 0.21632136404514313\n",
      "Epoch 1878, Loss: 0.8354434669017792, Final Batch Loss: 0.2962780296802521\n",
      "Epoch 1879, Loss: 0.8471862822771072, Final Batch Loss: 0.27095872163772583\n",
      "Epoch 1880, Loss: 0.8176859766244888, Final Batch Loss: 0.2258114069700241\n",
      "Epoch 1881, Loss: 0.7490024566650391, Final Batch Loss: 0.251271516084671\n",
      "Epoch 1882, Loss: 0.777506485581398, Final Batch Loss: 0.23070776462554932\n",
      "Epoch 1883, Loss: 0.7881739288568497, Final Batch Loss: 0.20295806229114532\n",
      "Epoch 1884, Loss: 0.7975345849990845, Final Batch Loss: 0.23882290720939636\n",
      "Epoch 1885, Loss: 0.8339954316616058, Final Batch Loss: 0.3302825391292572\n",
      "Epoch 1886, Loss: 0.7695034146308899, Final Batch Loss: 0.24788394570350647\n",
      "Epoch 1887, Loss: 0.7830634415149689, Final Batch Loss: 0.2545793652534485\n",
      "Epoch 1888, Loss: 0.7913345545530319, Final Batch Loss: 0.28694766759872437\n",
      "Epoch 1889, Loss: 0.791474848985672, Final Batch Loss: 0.2590915858745575\n",
      "Epoch 1890, Loss: 0.8177676051855087, Final Batch Loss: 0.2576834261417389\n",
      "Epoch 1891, Loss: 0.8020724207162857, Final Batch Loss: 0.30990222096443176\n",
      "Epoch 1892, Loss: 0.7972949743270874, Final Batch Loss: 0.2799133360385895\n",
      "Epoch 1893, Loss: 0.7961520552635193, Final Batch Loss: 0.20997324585914612\n",
      "Epoch 1894, Loss: 0.8480899930000305, Final Batch Loss: 0.35413140058517456\n",
      "Epoch 1895, Loss: 0.7765205651521683, Final Batch Loss: 0.27573028206825256\n",
      "Epoch 1896, Loss: 0.9459259212017059, Final Batch Loss: 0.3792151212692261\n",
      "Epoch 1897, Loss: 0.808235689997673, Final Batch Loss: 0.22380860149860382\n",
      "Epoch 1898, Loss: 0.8596920222043991, Final Batch Loss: 0.3322771191596985\n",
      "Epoch 1899, Loss: 0.794418603181839, Final Batch Loss: 0.2862246632575989\n",
      "Epoch 1900, Loss: 0.8096986711025238, Final Batch Loss: 0.2779862880706787\n",
      "Epoch 1901, Loss: 0.7358127385377884, Final Batch Loss: 0.1787320375442505\n",
      "Epoch 1902, Loss: 0.8119037002325058, Final Batch Loss: 0.24577978253364563\n",
      "Epoch 1903, Loss: 0.8173972815275192, Final Batch Loss: 0.22940517961978912\n",
      "Epoch 1904, Loss: 0.7899092137813568, Final Batch Loss: 0.22621166706085205\n",
      "Epoch 1905, Loss: 0.8473815619945526, Final Batch Loss: 0.28051477670669556\n",
      "Epoch 1906, Loss: 0.8151511251926422, Final Batch Loss: 0.3305734097957611\n",
      "Epoch 1907, Loss: 0.7753658592700958, Final Batch Loss: 0.25980067253112793\n",
      "Epoch 1908, Loss: 0.7659194767475128, Final Batch Loss: 0.23348590731620789\n",
      "Epoch 1909, Loss: 0.828624963760376, Final Batch Loss: 0.2543185353279114\n",
      "Epoch 1910, Loss: 0.8424348533153534, Final Batch Loss: 0.2994168698787689\n",
      "Epoch 1911, Loss: 0.8137441426515579, Final Batch Loss: 0.329782634973526\n",
      "Epoch 1912, Loss: 0.8237989395856857, Final Batch Loss: 0.2396816462278366\n",
      "Epoch 1913, Loss: 0.8106113821268082, Final Batch Loss: 0.21526502072811127\n",
      "Epoch 1914, Loss: 0.7674356698989868, Final Batch Loss: 0.25250059366226196\n",
      "Epoch 1915, Loss: 0.9197553098201752, Final Batch Loss: 0.3072240948677063\n",
      "Epoch 1916, Loss: 0.8643750846385956, Final Batch Loss: 0.3204590380191803\n",
      "Epoch 1917, Loss: 0.8261536806821823, Final Batch Loss: 0.2741500437259674\n",
      "Epoch 1918, Loss: 0.7811309248209, Final Batch Loss: 0.23405174911022186\n",
      "Epoch 1919, Loss: 0.8621441423892975, Final Batch Loss: 0.28337615728378296\n",
      "Epoch 1920, Loss: 0.9131024777889252, Final Batch Loss: 0.3423207104206085\n",
      "Epoch 1921, Loss: 0.8088662177324295, Final Batch Loss: 0.2936250567436218\n",
      "Epoch 1922, Loss: 0.7405566871166229, Final Batch Loss: 0.1805974543094635\n",
      "Epoch 1923, Loss: 0.7527489811182022, Final Batch Loss: 0.2162742018699646\n",
      "Epoch 1924, Loss: 0.8213673233985901, Final Batch Loss: 0.3313150405883789\n",
      "Epoch 1925, Loss: 0.7629294991493225, Final Batch Loss: 0.2791346609592438\n",
      "Epoch 1926, Loss: 0.828733280301094, Final Batch Loss: 0.2298067957162857\n",
      "Epoch 1927, Loss: 0.882568359375, Final Batch Loss: 0.3275781571865082\n",
      "Epoch 1928, Loss: 0.8177004456520081, Final Batch Loss: 0.274342805147171\n",
      "Epoch 1929, Loss: 0.7590071111917496, Final Batch Loss: 0.209290012717247\n",
      "Epoch 1930, Loss: 0.7461815029382706, Final Batch Loss: 0.24782216548919678\n",
      "Epoch 1931, Loss: 0.7837105989456177, Final Batch Loss: 0.2845662832260132\n",
      "Epoch 1932, Loss: 0.7431919723749161, Final Batch Loss: 0.24121879041194916\n",
      "Epoch 1933, Loss: 0.7779331207275391, Final Batch Loss: 0.2355785071849823\n",
      "Epoch 1934, Loss: 0.796620562672615, Final Batch Loss: 0.20776338875293732\n",
      "Epoch 1935, Loss: 0.7508755028247833, Final Batch Loss: 0.17201516032218933\n",
      "Epoch 1936, Loss: 0.7918795049190521, Final Batch Loss: 0.2982690632343292\n",
      "Epoch 1937, Loss: 0.7556570023298264, Final Batch Loss: 0.2670467495918274\n",
      "Epoch 1938, Loss: 0.8055578917264938, Final Batch Loss: 0.30701327323913574\n",
      "Epoch 1939, Loss: 0.7890951633453369, Final Batch Loss: 0.29756370186805725\n",
      "Epoch 1940, Loss: 0.7307361960411072, Final Batch Loss: 0.203687846660614\n",
      "Epoch 1941, Loss: 0.8247213363647461, Final Batch Loss: 0.3290709853172302\n",
      "Epoch 1942, Loss: 0.8415241837501526, Final Batch Loss: 0.30413928627967834\n",
      "Epoch 1943, Loss: 0.8447765409946442, Final Batch Loss: 0.35564467310905457\n",
      "Epoch 1944, Loss: 0.8364814519882202, Final Batch Loss: 0.29260343313217163\n",
      "Epoch 1945, Loss: 0.7488501071929932, Final Batch Loss: 0.2671656012535095\n",
      "Epoch 1946, Loss: 0.7075219452381134, Final Batch Loss: 0.23095984756946564\n",
      "Epoch 1947, Loss: 0.8323260247707367, Final Batch Loss: 0.259541392326355\n",
      "Epoch 1948, Loss: 0.7784716933965683, Final Batch Loss: 0.24484547972679138\n",
      "Epoch 1949, Loss: 0.7351046353578568, Final Batch Loss: 0.1883496791124344\n",
      "Epoch 1950, Loss: 0.800484910607338, Final Batch Loss: 0.2921657860279083\n",
      "Epoch 1951, Loss: 0.7504027336835861, Final Batch Loss: 0.24052204191684723\n",
      "Epoch 1952, Loss: 0.7433185577392578, Final Batch Loss: 0.2457154393196106\n",
      "Epoch 1953, Loss: 0.7483300715684891, Final Batch Loss: 0.21381297707557678\n",
      "Epoch 1954, Loss: 0.8560414463281631, Final Batch Loss: 0.30525797605514526\n",
      "Epoch 1955, Loss: 0.7499359101057053, Final Batch Loss: 0.2214140146970749\n",
      "Epoch 1956, Loss: 0.7870723605155945, Final Batch Loss: 0.25927796959877014\n",
      "Epoch 1957, Loss: 0.8309513479471207, Final Batch Loss: 0.26667478680610657\n",
      "Epoch 1958, Loss: 0.7485631257295609, Final Batch Loss: 0.2699415683746338\n",
      "Epoch 1959, Loss: 0.7438391894102097, Final Batch Loss: 0.2630999684333801\n",
      "Epoch 1960, Loss: 0.7742185443639755, Final Batch Loss: 0.2254699468612671\n",
      "Epoch 1961, Loss: 0.8370515704154968, Final Batch Loss: 0.27362361550331116\n",
      "Epoch 1962, Loss: 0.8483896404504776, Final Batch Loss: 0.3195458948612213\n",
      "Epoch 1963, Loss: 0.7296502739191055, Final Batch Loss: 0.21896450221538544\n",
      "Epoch 1964, Loss: 0.7964654713869095, Final Batch Loss: 0.2705759108066559\n",
      "Epoch 1965, Loss: 0.679003119468689, Final Batch Loss: 0.20973160862922668\n",
      "Epoch 1966, Loss: 0.8276614844799042, Final Batch Loss: 0.311553031206131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1967, Loss: 0.8210448622703552, Final Batch Loss: 0.31608277559280396\n",
      "Epoch 1968, Loss: 0.8083923757076263, Final Batch Loss: 0.3003757894039154\n",
      "Epoch 1969, Loss: 0.7733816206455231, Final Batch Loss: 0.2530807554721832\n",
      "Epoch 1970, Loss: 0.8336642533540726, Final Batch Loss: 0.3116118609905243\n",
      "Epoch 1971, Loss: 0.8801259100437164, Final Batch Loss: 0.3026465177536011\n",
      "Epoch 1972, Loss: 0.7647731900215149, Final Batch Loss: 0.21395736932754517\n",
      "Epoch 1973, Loss: 0.7143750488758087, Final Batch Loss: 0.25170648097991943\n",
      "Epoch 1974, Loss: 0.8932847380638123, Final Batch Loss: 0.2513333559036255\n",
      "Epoch 1975, Loss: 0.649015873670578, Final Batch Loss: 0.1766592562198639\n",
      "Epoch 1976, Loss: 0.7229889333248138, Final Batch Loss: 0.23168295621871948\n",
      "Epoch 1977, Loss: 0.8333090394735336, Final Batch Loss: 0.3176797330379486\n",
      "Epoch 1978, Loss: 0.7664558440446854, Final Batch Loss: 0.2650389075279236\n",
      "Epoch 1979, Loss: 0.8694742769002914, Final Batch Loss: 0.3719826936721802\n",
      "Epoch 1980, Loss: 0.7746460288763046, Final Batch Loss: 0.2773663103580475\n",
      "Epoch 1981, Loss: 0.7754705846309662, Final Batch Loss: 0.268128901720047\n",
      "Epoch 1982, Loss: 0.7775974273681641, Final Batch Loss: 0.25109219551086426\n",
      "Epoch 1983, Loss: 0.7610385566949844, Final Batch Loss: 0.2210605889558792\n",
      "Epoch 1984, Loss: 0.8537104427814484, Final Batch Loss: 0.25804632902145386\n",
      "Epoch 1985, Loss: 0.7849627137184143, Final Batch Loss: 0.2303105592727661\n",
      "Epoch 1986, Loss: 0.7198967486619949, Final Batch Loss: 0.22903141379356384\n",
      "Epoch 1987, Loss: 0.7637255936861038, Final Batch Loss: 0.3005654215812683\n",
      "Epoch 1988, Loss: 0.8263505846261978, Final Batch Loss: 0.22247613966464996\n",
      "Epoch 1989, Loss: 0.8075699508190155, Final Batch Loss: 0.2165718674659729\n",
      "Epoch 1990, Loss: 0.6949239373207092, Final Batch Loss: 0.19365428388118744\n",
      "Epoch 1991, Loss: 0.7893216609954834, Final Batch Loss: 0.28661271929740906\n",
      "Epoch 1992, Loss: 0.8414131999015808, Final Batch Loss: 0.31724730134010315\n",
      "Epoch 1993, Loss: 0.8282015174627304, Final Batch Loss: 0.3610447645187378\n",
      "Epoch 1994, Loss: 0.7538313567638397, Final Batch Loss: 0.21551311016082764\n",
      "Epoch 1995, Loss: 0.7073668241500854, Final Batch Loss: 0.1664295196533203\n",
      "Epoch 1996, Loss: 0.7386117279529572, Final Batch Loss: 0.2723624110221863\n",
      "Epoch 1997, Loss: 0.7285878658294678, Final Batch Loss: 0.21750898659229279\n",
      "Epoch 1998, Loss: 0.7161264717578888, Final Batch Loss: 0.1996179223060608\n",
      "Epoch 1999, Loss: 0.6681848764419556, Final Batch Loss: 0.2206990122795105\n",
      "Epoch 2000, Loss: 0.7636622488498688, Final Batch Loss: 0.2369113266468048\n",
      "Epoch 2001, Loss: 0.7711749076843262, Final Batch Loss: 0.24437105655670166\n",
      "Epoch 2002, Loss: 0.8098886013031006, Final Batch Loss: 0.3250034749507904\n",
      "Epoch 2003, Loss: 0.7658518552780151, Final Batch Loss: 0.29435279965400696\n",
      "Epoch 2004, Loss: 0.7445955276489258, Final Batch Loss: 0.2545177638530731\n",
      "Epoch 2005, Loss: 0.7134745419025421, Final Batch Loss: 0.19575612246990204\n",
      "Epoch 2006, Loss: 0.7830336689949036, Final Batch Loss: 0.2560482323169708\n",
      "Epoch 2007, Loss: 0.7432379573583603, Final Batch Loss: 0.2673839032649994\n",
      "Epoch 2008, Loss: 0.7545118480920792, Final Batch Loss: 0.23371562361717224\n",
      "Epoch 2009, Loss: 0.6967184990644455, Final Batch Loss: 0.1911320686340332\n",
      "Epoch 2010, Loss: 0.7721344381570816, Final Batch Loss: 0.25712254643440247\n",
      "Epoch 2011, Loss: 0.8939077407121658, Final Batch Loss: 0.372742623090744\n",
      "Epoch 2012, Loss: 0.7700550109148026, Final Batch Loss: 0.24368104338645935\n",
      "Epoch 2013, Loss: 0.7774657160043716, Final Batch Loss: 0.26180100440979004\n",
      "Epoch 2014, Loss: 0.7554289698600769, Final Batch Loss: 0.23724353313446045\n",
      "Epoch 2015, Loss: 0.7594620138406754, Final Batch Loss: 0.3660007417201996\n",
      "Epoch 2016, Loss: 0.8091885894536972, Final Batch Loss: 0.21503601968288422\n",
      "Epoch 2017, Loss: 0.7958544939756393, Final Batch Loss: 0.24104303121566772\n",
      "Epoch 2018, Loss: 0.6821340024471283, Final Batch Loss: 0.17917992174625397\n",
      "Epoch 2019, Loss: 0.9038546830415726, Final Batch Loss: 0.40320834517478943\n",
      "Epoch 2020, Loss: 0.8382847607135773, Final Batch Loss: 0.2899932265281677\n",
      "Epoch 2021, Loss: 0.8450783789157867, Final Batch Loss: 0.29137247800827026\n",
      "Epoch 2022, Loss: 0.744870975613594, Final Batch Loss: 0.31180763244628906\n",
      "Epoch 2023, Loss: 0.7710413336753845, Final Batch Loss: 0.19455471634864807\n",
      "Epoch 2024, Loss: 0.772944837808609, Final Batch Loss: 0.25559404492378235\n",
      "Epoch 2025, Loss: 0.8242045640945435, Final Batch Loss: 0.283118337392807\n",
      "Epoch 2026, Loss: 0.8762971609830856, Final Batch Loss: 0.35778868198394775\n",
      "Epoch 2027, Loss: 0.671518549323082, Final Batch Loss: 0.15695396065711975\n",
      "Epoch 2028, Loss: 0.7243582010269165, Final Batch Loss: 0.2540765106678009\n",
      "Epoch 2029, Loss: 0.7417861074209213, Final Batch Loss: 0.1942519098520279\n",
      "Epoch 2030, Loss: 0.7389441132545471, Final Batch Loss: 0.18972618877887726\n",
      "Epoch 2031, Loss: 0.8153094798326492, Final Batch Loss: 0.31489109992980957\n",
      "Epoch 2032, Loss: 1.0670961290597916, Final Batch Loss: 0.4490221440792084\n",
      "Epoch 2033, Loss: 0.7323846518993378, Final Batch Loss: 0.24538373947143555\n",
      "Epoch 2034, Loss: 0.7305994033813477, Final Batch Loss: 0.18162423372268677\n",
      "Epoch 2035, Loss: 0.7839570194482803, Final Batch Loss: 0.21490918099880219\n",
      "Epoch 2036, Loss: 0.8864911794662476, Final Batch Loss: 0.37752342224121094\n",
      "Epoch 2037, Loss: 0.6795235127210617, Final Batch Loss: 0.1758728176355362\n",
      "Epoch 2038, Loss: 0.8522571325302124, Final Batch Loss: 0.2997124493122101\n",
      "Epoch 2039, Loss: 0.7493646293878555, Final Batch Loss: 0.23974528908729553\n",
      "Epoch 2040, Loss: 0.7717443257570267, Final Batch Loss: 0.24596896767616272\n",
      "Epoch 2041, Loss: 0.7610635906457901, Final Batch Loss: 0.20335368812084198\n",
      "Epoch 2042, Loss: 0.7503822147846222, Final Batch Loss: 0.24281829595565796\n",
      "Epoch 2043, Loss: 0.8232322633266449, Final Batch Loss: 0.2728135585784912\n",
      "Epoch 2044, Loss: 0.745807483792305, Final Batch Loss: 0.2808224558830261\n",
      "Epoch 2045, Loss: 0.7912632077932358, Final Batch Loss: 0.23339329659938812\n",
      "Epoch 2046, Loss: 0.7145856320858002, Final Batch Loss: 0.1902237981557846\n",
      "Epoch 2047, Loss: 0.8220185339450836, Final Batch Loss: 0.207294762134552\n",
      "Epoch 2048, Loss: 0.8081987798213959, Final Batch Loss: 0.30918142199516296\n",
      "Epoch 2049, Loss: 0.8502374738454819, Final Batch Loss: 0.3337266743183136\n",
      "Epoch 2050, Loss: 0.6884919703006744, Final Batch Loss: 0.2076398730278015\n",
      "Epoch 2051, Loss: 0.8571948856115341, Final Batch Loss: 0.2201165407896042\n",
      "Epoch 2052, Loss: 0.7449613362550735, Final Batch Loss: 0.26182541251182556\n",
      "Epoch 2053, Loss: 0.7792325913906097, Final Batch Loss: 0.20692923665046692\n",
      "Epoch 2054, Loss: 0.7808008939027786, Final Batch Loss: 0.30060872435569763\n",
      "Epoch 2055, Loss: 0.7537533640861511, Final Batch Loss: 0.233114555478096\n",
      "Epoch 2056, Loss: 0.7461636811494827, Final Batch Loss: 0.24582190811634064\n",
      "Epoch 2057, Loss: 0.7377228140830994, Final Batch Loss: 0.2721827030181885\n",
      "Epoch 2058, Loss: 0.7465539276599884, Final Batch Loss: 0.24639753997325897\n",
      "Epoch 2059, Loss: 0.7478806376457214, Final Batch Loss: 0.24413613975048065\n",
      "Epoch 2060, Loss: 0.8008307069540024, Final Batch Loss: 0.29659074544906616\n",
      "Epoch 2061, Loss: 0.7834399342536926, Final Batch Loss: 0.26637935638427734\n",
      "Epoch 2062, Loss: 0.6935891956090927, Final Batch Loss: 0.1773148775100708\n",
      "Epoch 2063, Loss: 0.7141902148723602, Final Batch Loss: 0.2734946608543396\n",
      "Epoch 2064, Loss: 0.8041502684354782, Final Batch Loss: 0.2753569781780243\n",
      "Epoch 2065, Loss: 0.8344196081161499, Final Batch Loss: 0.2521847188472748\n",
      "Epoch 2066, Loss: 0.8209852427244186, Final Batch Loss: 0.334459513425827\n",
      "Epoch 2067, Loss: 0.8223407566547394, Final Batch Loss: 0.324068158864975\n",
      "Epoch 2068, Loss: 0.7850203812122345, Final Batch Loss: 0.21422597765922546\n",
      "Epoch 2069, Loss: 0.7178031653165817, Final Batch Loss: 0.24772626161575317\n",
      "Epoch 2070, Loss: 0.7704701870679855, Final Batch Loss: 0.30376964807510376\n",
      "Epoch 2071, Loss: 0.7693290114402771, Final Batch Loss: 0.2722128927707672\n",
      "Epoch 2072, Loss: 0.6530730873346329, Final Batch Loss: 0.20756709575653076\n",
      "Epoch 2073, Loss: 0.7069130837917328, Final Batch Loss: 0.2631036043167114\n",
      "Epoch 2074, Loss: 0.8619698882102966, Final Batch Loss: 0.2801666557788849\n",
      "Epoch 2075, Loss: 0.8194627016782761, Final Batch Loss: 0.34921276569366455\n",
      "Epoch 2076, Loss: 0.7702350467443466, Final Batch Loss: 0.2254319041967392\n",
      "Epoch 2077, Loss: 0.7926907241344452, Final Batch Loss: 0.2609127461910248\n",
      "Epoch 2078, Loss: 0.7308454215526581, Final Batch Loss: 0.25422075390815735\n",
      "Epoch 2079, Loss: 0.7644073516130447, Final Batch Loss: 0.20845651626586914\n",
      "Epoch 2080, Loss: 0.736412838101387, Final Batch Loss: 0.20273880660533905\n",
      "Epoch 2081, Loss: 0.7697445601224899, Final Batch Loss: 0.23601852357387543\n",
      "Epoch 2082, Loss: 0.7986942231655121, Final Batch Loss: 0.24971459805965424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2083, Loss: 0.8302990198135376, Final Batch Loss: 0.26163554191589355\n",
      "Epoch 2084, Loss: 0.7315503358840942, Final Batch Loss: 0.2704726457595825\n",
      "Epoch 2085, Loss: 0.707633912563324, Final Batch Loss: 0.22054900228977203\n",
      "Epoch 2086, Loss: 0.7430793046951294, Final Batch Loss: 0.2609253525733948\n",
      "Epoch 2087, Loss: 0.7840082198381424, Final Batch Loss: 0.22161544859409332\n",
      "Epoch 2088, Loss: 0.7940107733011246, Final Batch Loss: 0.33854061365127563\n",
      "Epoch 2089, Loss: 0.7287557274103165, Final Batch Loss: 0.20385530591011047\n",
      "Epoch 2090, Loss: 0.7305198311805725, Final Batch Loss: 0.3000818192958832\n",
      "Epoch 2091, Loss: 0.9112513661384583, Final Batch Loss: 0.31771981716156006\n",
      "Epoch 2092, Loss: 0.7354505211114883, Final Batch Loss: 0.19967348873615265\n",
      "Epoch 2093, Loss: 0.7127201706171036, Final Batch Loss: 0.21002313494682312\n",
      "Epoch 2094, Loss: 0.6863985508680344, Final Batch Loss: 0.21957655251026154\n",
      "Epoch 2095, Loss: 0.7442865073680878, Final Batch Loss: 0.21555128693580627\n",
      "Epoch 2096, Loss: 0.709323450922966, Final Batch Loss: 0.18076004087924957\n",
      "Epoch 2097, Loss: 0.757789820432663, Final Batch Loss: 0.225674569606781\n",
      "Epoch 2098, Loss: 0.7413752526044846, Final Batch Loss: 0.25506898760795593\n",
      "Epoch 2099, Loss: 0.7547168135643005, Final Batch Loss: 0.21872609853744507\n",
      "Epoch 2100, Loss: 0.7322446256875992, Final Batch Loss: 0.28394070267677307\n",
      "Epoch 2101, Loss: 0.7634294778108597, Final Batch Loss: 0.2913096845149994\n",
      "Epoch 2102, Loss: 0.6861271411180496, Final Batch Loss: 0.20660720765590668\n",
      "Epoch 2103, Loss: 0.6542658805847168, Final Batch Loss: 0.21252436935901642\n",
      "Epoch 2104, Loss: 0.6777594983577728, Final Batch Loss: 0.1691020131111145\n",
      "Epoch 2105, Loss: 0.6899943053722382, Final Batch Loss: 0.19113141298294067\n",
      "Epoch 2106, Loss: 0.7593255341053009, Final Batch Loss: 0.18185260891914368\n",
      "Epoch 2107, Loss: 0.728741317987442, Final Batch Loss: 0.24761269986629486\n",
      "Epoch 2108, Loss: 0.7479266822338104, Final Batch Loss: 0.31518974900245667\n",
      "Epoch 2109, Loss: 0.7467232942581177, Final Batch Loss: 0.241590678691864\n",
      "Epoch 2110, Loss: 0.7461223155260086, Final Batch Loss: 0.20644985139369965\n",
      "Epoch 2111, Loss: 0.9239586293697357, Final Batch Loss: 0.419597864151001\n",
      "Epoch 2112, Loss: 0.8013624846935272, Final Batch Loss: 0.27568191289901733\n",
      "Epoch 2113, Loss: 0.7140473276376724, Final Batch Loss: 0.2478286176919937\n",
      "Epoch 2114, Loss: 0.6838491410017014, Final Batch Loss: 0.18854716420173645\n",
      "Epoch 2115, Loss: 0.7389691919088364, Final Batch Loss: 0.2741032540798187\n",
      "Epoch 2116, Loss: 0.7151774615049362, Final Batch Loss: 0.23260913789272308\n",
      "Epoch 2117, Loss: 0.7542474120855331, Final Batch Loss: 0.2639666199684143\n",
      "Epoch 2118, Loss: 0.743003711104393, Final Batch Loss: 0.22376272082328796\n",
      "Epoch 2119, Loss: 0.7718229740858078, Final Batch Loss: 0.22486768662929535\n",
      "Epoch 2120, Loss: 0.6870825588703156, Final Batch Loss: 0.18335863947868347\n",
      "Epoch 2121, Loss: 0.7881436347961426, Final Batch Loss: 0.21734991669654846\n",
      "Epoch 2122, Loss: 0.6728764474391937, Final Batch Loss: 0.2286825329065323\n",
      "Epoch 2123, Loss: 0.8336353898048401, Final Batch Loss: 0.215351402759552\n",
      "Epoch 2124, Loss: 0.7553204894065857, Final Batch Loss: 0.2369045466184616\n",
      "Epoch 2125, Loss: 0.7808292359113693, Final Batch Loss: 0.2906723618507385\n",
      "Epoch 2126, Loss: 0.7245422452688217, Final Batch Loss: 0.27372753620147705\n",
      "Epoch 2127, Loss: 0.7470938563346863, Final Batch Loss: 0.17533168196678162\n",
      "Epoch 2128, Loss: 0.69727922976017, Final Batch Loss: 0.21057622134685516\n",
      "Epoch 2129, Loss: 0.7131683826446533, Final Batch Loss: 0.21360372006893158\n",
      "Epoch 2130, Loss: 0.6926210075616837, Final Batch Loss: 0.21564704179763794\n",
      "Epoch 2131, Loss: 0.7710738182067871, Final Batch Loss: 0.22976729273796082\n",
      "Epoch 2132, Loss: 0.7299655675888062, Final Batch Loss: 0.22649937868118286\n",
      "Epoch 2133, Loss: 0.7260265350341797, Final Batch Loss: 0.2118576467037201\n",
      "Epoch 2134, Loss: 0.719441294670105, Final Batch Loss: 0.24198026955127716\n",
      "Epoch 2135, Loss: 0.8150365352630615, Final Batch Loss: 0.31277939677238464\n",
      "Epoch 2136, Loss: 0.8640893846750259, Final Batch Loss: 0.3173682689666748\n",
      "Epoch 2137, Loss: 0.7115593701601028, Final Batch Loss: 0.2008475512266159\n",
      "Epoch 2138, Loss: 0.8411955386400223, Final Batch Loss: 0.2960764169692993\n",
      "Epoch 2139, Loss: 0.7491504848003387, Final Batch Loss: 0.2865743339061737\n",
      "Epoch 2140, Loss: 0.834194079041481, Final Batch Loss: 0.3362331986427307\n",
      "Epoch 2141, Loss: 0.7085438519716263, Final Batch Loss: 0.2792641520500183\n",
      "Epoch 2142, Loss: 0.6961328387260437, Final Batch Loss: 0.20764091610908508\n",
      "Epoch 2143, Loss: 0.793192058801651, Final Batch Loss: 0.2737535238265991\n",
      "Epoch 2144, Loss: 0.7688542902469635, Final Batch Loss: 0.2800549268722534\n",
      "Epoch 2145, Loss: 0.7062465101480484, Final Batch Loss: 0.20287665724754333\n",
      "Epoch 2146, Loss: 0.702808067202568, Final Batch Loss: 0.1915365755558014\n",
      "Epoch 2147, Loss: 0.7206142991781235, Final Batch Loss: 0.1980566531419754\n",
      "Epoch 2148, Loss: 0.719001978635788, Final Batch Loss: 0.27238062024116516\n",
      "Epoch 2149, Loss: 0.7736023515462875, Final Batch Loss: 0.2934926152229309\n",
      "Epoch 2150, Loss: 0.8057773858308792, Final Batch Loss: 0.254292756319046\n",
      "Epoch 2151, Loss: 0.6967760920524597, Final Batch Loss: 0.15396347641944885\n",
      "Epoch 2152, Loss: 0.7619056701660156, Final Batch Loss: 0.2273796796798706\n",
      "Epoch 2153, Loss: 0.7083218991756439, Final Batch Loss: 0.24107396602630615\n",
      "Epoch 2154, Loss: 0.8045292645692825, Final Batch Loss: 0.2871181070804596\n",
      "Epoch 2155, Loss: 0.730750173330307, Final Batch Loss: 0.2296891212463379\n",
      "Epoch 2156, Loss: 0.882745698094368, Final Batch Loss: 0.4416137635707855\n",
      "Epoch 2157, Loss: 0.7032444775104523, Final Batch Loss: 0.1893598437309265\n",
      "Epoch 2158, Loss: 0.7404701560735703, Final Batch Loss: 0.27550071477890015\n",
      "Epoch 2159, Loss: 0.6950912475585938, Final Batch Loss: 0.18261660635471344\n",
      "Epoch 2160, Loss: 0.7119244188070297, Final Batch Loss: 0.1981940120458603\n",
      "Epoch 2161, Loss: 0.7109355628490448, Final Batch Loss: 0.1911771148443222\n",
      "Epoch 2162, Loss: 0.7676116079092026, Final Batch Loss: 0.27082332968711853\n",
      "Epoch 2163, Loss: 0.7092191874980927, Final Batch Loss: 0.2408505529165268\n",
      "Epoch 2164, Loss: 0.731882631778717, Final Batch Loss: 0.2500801086425781\n",
      "Epoch 2165, Loss: 0.8060785830020905, Final Batch Loss: 0.3177109956741333\n",
      "Epoch 2166, Loss: 0.8004628419876099, Final Batch Loss: 0.3111749291419983\n",
      "Epoch 2167, Loss: 0.7055316269397736, Final Batch Loss: 0.2092222422361374\n",
      "Epoch 2168, Loss: 0.8340268135070801, Final Batch Loss: 0.26381397247314453\n",
      "Epoch 2169, Loss: 0.6750914752483368, Final Batch Loss: 0.21655422449111938\n",
      "Epoch 2170, Loss: 0.6784511506557465, Final Batch Loss: 0.2770128548145294\n",
      "Epoch 2171, Loss: 0.6657581776380539, Final Batch Loss: 0.24746719002723694\n",
      "Epoch 2172, Loss: 0.8345992267131805, Final Batch Loss: 0.2944702208042145\n",
      "Epoch 2173, Loss: 0.7642194777727127, Final Batch Loss: 0.2901284396648407\n",
      "Epoch 2174, Loss: 0.9110157489776611, Final Batch Loss: 0.3910944163799286\n",
      "Epoch 2175, Loss: 0.7012742310762405, Final Batch Loss: 0.21013866364955902\n",
      "Epoch 2176, Loss: 0.7691859900951385, Final Batch Loss: 0.24287879467010498\n",
      "Epoch 2177, Loss: 0.7911173701286316, Final Batch Loss: 0.2661382257938385\n",
      "Epoch 2178, Loss: 0.7644268274307251, Final Batch Loss: 0.2851347029209137\n",
      "Epoch 2179, Loss: 0.7421565800905228, Final Batch Loss: 0.19373367726802826\n",
      "Epoch 2180, Loss: 0.7181492000818253, Final Batch Loss: 0.2394069880247116\n",
      "Epoch 2181, Loss: 0.700542539358139, Final Batch Loss: 0.1991955190896988\n",
      "Epoch 2182, Loss: 0.7247359454631805, Final Batch Loss: 0.23469632863998413\n",
      "Epoch 2183, Loss: 0.7214343547821045, Final Batch Loss: 0.20941764116287231\n",
      "Epoch 2184, Loss: 0.7366824448108673, Final Batch Loss: 0.28262433409690857\n",
      "Epoch 2185, Loss: 0.7767559289932251, Final Batch Loss: 0.2595052123069763\n",
      "Epoch 2186, Loss: 0.6983786225318909, Final Batch Loss: 0.2696608603000641\n",
      "Epoch 2187, Loss: 0.6812239438295364, Final Batch Loss: 0.22767390310764313\n",
      "Epoch 2188, Loss: 0.7406393587589264, Final Batch Loss: 0.23970703780651093\n",
      "Epoch 2189, Loss: 0.8559137582778931, Final Batch Loss: 0.3605826795101166\n",
      "Epoch 2190, Loss: 0.7767285108566284, Final Batch Loss: 0.23304802179336548\n",
      "Epoch 2191, Loss: 0.7940918207168579, Final Batch Loss: 0.23118728399276733\n",
      "Epoch 2192, Loss: 0.7310651391744614, Final Batch Loss: 0.22746716439723969\n",
      "Epoch 2193, Loss: 0.812273383140564, Final Batch Loss: 0.21556967496871948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2194, Loss: 0.7758088409900665, Final Batch Loss: 0.27481845021247864\n",
      "Epoch 2195, Loss: 0.7278528064489365, Final Batch Loss: 0.24650444090366364\n",
      "Epoch 2196, Loss: 0.840755969285965, Final Batch Loss: 0.27914440631866455\n",
      "Epoch 2197, Loss: 0.656616747379303, Final Batch Loss: 0.22888977825641632\n",
      "Epoch 2198, Loss: 0.7221760600805283, Final Batch Loss: 0.2711673378944397\n",
      "Epoch 2199, Loss: 0.7802468240261078, Final Batch Loss: 0.2345224767923355\n",
      "Epoch 2200, Loss: 0.686157301068306, Final Batch Loss: 0.20052236318588257\n",
      "Epoch 2201, Loss: 0.7531417161226273, Final Batch Loss: 0.2609349489212036\n",
      "Epoch 2202, Loss: 0.7060563862323761, Final Batch Loss: 0.20572024583816528\n",
      "Epoch 2203, Loss: 0.7050419002771378, Final Batch Loss: 0.20339471101760864\n",
      "Epoch 2204, Loss: 0.8028680980205536, Final Batch Loss: 0.304404079914093\n",
      "Epoch 2205, Loss: 0.8035387843847275, Final Batch Loss: 0.27668091654777527\n",
      "Epoch 2206, Loss: 0.6684207618236542, Final Batch Loss: 0.18502770364284515\n",
      "Epoch 2207, Loss: 0.7456624954938889, Final Batch Loss: 0.2804306447505951\n",
      "Epoch 2208, Loss: 0.7329166978597641, Final Batch Loss: 0.21740294992923737\n",
      "Epoch 2209, Loss: 0.7619974166154861, Final Batch Loss: 0.24007825553417206\n",
      "Epoch 2210, Loss: 0.7740994542837143, Final Batch Loss: 0.2938406765460968\n",
      "Epoch 2211, Loss: 0.657161146402359, Final Batch Loss: 0.15035393834114075\n",
      "Epoch 2212, Loss: 0.8026925325393677, Final Batch Loss: 0.23341640830039978\n",
      "Epoch 2213, Loss: 0.7250930517911911, Final Batch Loss: 0.26707446575164795\n",
      "Epoch 2214, Loss: 0.7785263359546661, Final Batch Loss: 0.3126891851425171\n",
      "Epoch 2215, Loss: 0.8055940419435501, Final Batch Loss: 0.2790287137031555\n",
      "Epoch 2216, Loss: 0.7759458422660828, Final Batch Loss: 0.27432119846343994\n",
      "Epoch 2217, Loss: 0.7327695488929749, Final Batch Loss: 0.24186719954013824\n",
      "Epoch 2218, Loss: 0.6774405092000961, Final Batch Loss: 0.16527603566646576\n",
      "Epoch 2219, Loss: 0.7368144392967224, Final Batch Loss: 0.23198238015174866\n",
      "Epoch 2220, Loss: 0.7773652970790863, Final Batch Loss: 0.22800013422966003\n",
      "Epoch 2221, Loss: 0.7957309931516647, Final Batch Loss: 0.335184246301651\n",
      "Epoch 2222, Loss: 0.8301853537559509, Final Batch Loss: 0.3791634142398834\n",
      "Epoch 2223, Loss: 0.6867354214191437, Final Batch Loss: 0.1386832743883133\n",
      "Epoch 2224, Loss: 0.7161391824483871, Final Batch Loss: 0.2168450951576233\n",
      "Epoch 2225, Loss: 0.7501982599496841, Final Batch Loss: 0.17655129730701447\n",
      "Epoch 2226, Loss: 0.7805721461772919, Final Batch Loss: 0.21276596188545227\n",
      "Epoch 2227, Loss: 0.7780583798885345, Final Batch Loss: 0.20484334230422974\n",
      "Epoch 2228, Loss: 0.7837408781051636, Final Batch Loss: 0.22972933948040009\n",
      "Epoch 2229, Loss: 0.7976119667291641, Final Batch Loss: 0.23317193984985352\n",
      "Epoch 2230, Loss: 0.7452186495065689, Final Batch Loss: 0.19817011058330536\n",
      "Epoch 2231, Loss: 0.6968079507350922, Final Batch Loss: 0.16493237018585205\n",
      "Epoch 2232, Loss: 0.8341082334518433, Final Batch Loss: 0.3305526375770569\n",
      "Epoch 2233, Loss: 0.6714548617601395, Final Batch Loss: 0.18435761332511902\n",
      "Epoch 2234, Loss: 0.655186802148819, Final Batch Loss: 0.23483359813690186\n",
      "Epoch 2235, Loss: 0.7737480700016022, Final Batch Loss: 0.2520194947719574\n",
      "Epoch 2236, Loss: 0.7156762182712555, Final Batch Loss: 0.21066713333129883\n",
      "Epoch 2237, Loss: 0.7577445954084396, Final Batch Loss: 0.21857134997844696\n",
      "Epoch 2238, Loss: 0.7256720960140228, Final Batch Loss: 0.2595459818840027\n",
      "Epoch 2239, Loss: 0.6867785453796387, Final Batch Loss: 0.19873858988285065\n",
      "Epoch 2240, Loss: 0.70484359562397, Final Batch Loss: 0.23734065890312195\n",
      "Epoch 2241, Loss: 0.7292177975177765, Final Batch Loss: 0.22023166716098785\n",
      "Epoch 2242, Loss: 0.7827135175466537, Final Batch Loss: 0.2407161444425583\n",
      "Epoch 2243, Loss: 0.6761864870786667, Final Batch Loss: 0.19793610274791718\n",
      "Epoch 2244, Loss: 0.7567826509475708, Final Batch Loss: 0.32160988450050354\n",
      "Epoch 2245, Loss: 0.7571467161178589, Final Batch Loss: 0.29537904262542725\n",
      "Epoch 2246, Loss: 0.8007112890481949, Final Batch Loss: 0.290790319442749\n",
      "Epoch 2247, Loss: 0.7614862471818924, Final Batch Loss: 0.31062111258506775\n",
      "Epoch 2248, Loss: 0.6867743730545044, Final Batch Loss: 0.24978962540626526\n",
      "Epoch 2249, Loss: 0.818227082490921, Final Batch Loss: 0.24520130455493927\n",
      "Epoch 2250, Loss: 0.7363659739494324, Final Batch Loss: 0.22876109182834625\n",
      "Epoch 2251, Loss: 0.8137443661689758, Final Batch Loss: 0.29975131154060364\n",
      "Epoch 2252, Loss: 0.6763587445020676, Final Batch Loss: 0.2161344438791275\n",
      "Epoch 2253, Loss: 0.7458969503641129, Final Batch Loss: 0.2526845932006836\n",
      "Epoch 2254, Loss: 0.7509364783763885, Final Batch Loss: 0.30128973722457886\n",
      "Epoch 2255, Loss: 0.7089923620223999, Final Batch Loss: 0.21445710957050323\n",
      "Epoch 2256, Loss: 0.7413778752088547, Final Batch Loss: 0.2646505832672119\n",
      "Epoch 2257, Loss: 0.7368505299091339, Final Batch Loss: 0.29279211163520813\n",
      "Epoch 2258, Loss: 0.6750261336565018, Final Batch Loss: 0.19537921249866486\n",
      "Epoch 2259, Loss: 0.7541934698820114, Final Batch Loss: 0.2458348125219345\n",
      "Epoch 2260, Loss: 0.6842095851898193, Final Batch Loss: 0.1797378808259964\n",
      "Epoch 2261, Loss: 0.7386775314807892, Final Batch Loss: 0.2214857041835785\n",
      "Epoch 2262, Loss: 0.6687294095754623, Final Batch Loss: 0.2536061704158783\n",
      "Epoch 2263, Loss: 0.6711804121732712, Final Batch Loss: 0.19722138345241547\n",
      "Epoch 2264, Loss: 0.7148659229278564, Final Batch Loss: 0.2032318115234375\n",
      "Epoch 2265, Loss: 0.7586077302694321, Final Batch Loss: 0.3162287175655365\n",
      "Epoch 2266, Loss: 0.7534874081611633, Final Batch Loss: 0.29931625723838806\n",
      "Epoch 2267, Loss: 0.7552139610052109, Final Batch Loss: 0.2599605321884155\n",
      "Epoch 2268, Loss: 0.7405190914869308, Final Batch Loss: 0.2530437111854553\n",
      "Epoch 2269, Loss: 0.8126990646123886, Final Batch Loss: 0.3361653983592987\n",
      "Epoch 2270, Loss: 0.7025938779115677, Final Batch Loss: 0.23838584125041962\n",
      "Epoch 2271, Loss: 0.7427858859300613, Final Batch Loss: 0.21638937294483185\n",
      "Epoch 2272, Loss: 0.7166544049978256, Final Batch Loss: 0.2298000305891037\n",
      "Epoch 2273, Loss: 0.7916027158498764, Final Batch Loss: 0.30565136671066284\n",
      "Epoch 2274, Loss: 0.7697633802890778, Final Batch Loss: 0.28176283836364746\n",
      "Epoch 2275, Loss: 0.6753972768783569, Final Batch Loss: 0.23750300705432892\n",
      "Epoch 2276, Loss: 0.8314195424318314, Final Batch Loss: 0.35804885625839233\n",
      "Epoch 2277, Loss: 0.7334466129541397, Final Batch Loss: 0.2884838581085205\n",
      "Epoch 2278, Loss: 0.7352936565876007, Final Batch Loss: 0.27202290296554565\n",
      "Epoch 2279, Loss: 0.7632813304662704, Final Batch Loss: 0.3010648787021637\n",
      "Epoch 2280, Loss: 0.8024611175060272, Final Batch Loss: 0.24158507585525513\n",
      "Epoch 2281, Loss: 0.7739422023296356, Final Batch Loss: 0.3347790539264679\n",
      "Epoch 2282, Loss: 0.6897246390581131, Final Batch Loss: 0.2510163187980652\n",
      "Epoch 2283, Loss: 0.7067960202693939, Final Batch Loss: 0.1644534021615982\n",
      "Epoch 2284, Loss: 0.6628663837909698, Final Batch Loss: 0.20285151898860931\n",
      "Epoch 2285, Loss: 0.6892821192741394, Final Batch Loss: 0.2332170456647873\n",
      "Epoch 2286, Loss: 0.6934016942977905, Final Batch Loss: 0.26366865634918213\n",
      "Epoch 2287, Loss: 0.7613353431224823, Final Batch Loss: 0.26551905274391174\n",
      "Epoch 2288, Loss: 0.6509521901607513, Final Batch Loss: 0.15566785633563995\n",
      "Epoch 2289, Loss: 0.8712057769298553, Final Batch Loss: 0.37282535433769226\n",
      "Epoch 2290, Loss: 0.6639496237039566, Final Batch Loss: 0.1810341626405716\n",
      "Epoch 2291, Loss: 0.6257492154836655, Final Batch Loss: 0.2019156962633133\n",
      "Epoch 2292, Loss: 0.6838866621255875, Final Batch Loss: 0.2447267323732376\n",
      "Epoch 2293, Loss: 0.7050175666809082, Final Batch Loss: 0.23544779419898987\n",
      "Epoch 2294, Loss: 0.7346947491168976, Final Batch Loss: 0.22492678463459015\n",
      "Epoch 2295, Loss: 0.7588039934635162, Final Batch Loss: 0.24551674723625183\n",
      "Epoch 2296, Loss: 0.7089101374149323, Final Batch Loss: 0.20335176587104797\n",
      "Epoch 2297, Loss: 0.6103218644857407, Final Batch Loss: 0.22052302956581116\n",
      "Epoch 2298, Loss: 0.7847360968589783, Final Batch Loss: 0.24230197072029114\n",
      "Epoch 2299, Loss: 0.6974076926708221, Final Batch Loss: 0.25452128052711487\n",
      "Epoch 2300, Loss: 0.691432997584343, Final Batch Loss: 0.23031072318553925\n",
      "Epoch 2301, Loss: 0.7428094446659088, Final Batch Loss: 0.2905673086643219\n",
      "Epoch 2302, Loss: 0.8007918149232864, Final Batch Loss: 0.29889488220214844\n",
      "Epoch 2303, Loss: 0.7617495805025101, Final Batch Loss: 0.22410304844379425\n",
      "Epoch 2304, Loss: 0.6521869152784348, Final Batch Loss: 0.2148110270500183\n",
      "Epoch 2305, Loss: 0.7483091056346893, Final Batch Loss: 0.20066581666469574\n",
      "Epoch 2306, Loss: 0.7312514036893845, Final Batch Loss: 0.1870218962430954\n",
      "Epoch 2307, Loss: 0.6793689876794815, Final Batch Loss: 0.24332363903522491\n",
      "Epoch 2308, Loss: 0.8081807941198349, Final Batch Loss: 0.3914567530155182\n",
      "Epoch 2309, Loss: 0.7299752831459045, Final Batch Loss: 0.2613603174686432\n",
      "Epoch 2310, Loss: 0.7465821802616119, Final Batch Loss: 0.2927533686161041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2311, Loss: 0.766742154955864, Final Batch Loss: 0.21327541768550873\n",
      "Epoch 2312, Loss: 0.6262113749980927, Final Batch Loss: 0.1961096227169037\n",
      "Epoch 2313, Loss: 0.7487515807151794, Final Batch Loss: 0.28387996554374695\n",
      "Epoch 2314, Loss: 0.6619409173727036, Final Batch Loss: 0.21028804779052734\n",
      "Epoch 2315, Loss: 0.645218551158905, Final Batch Loss: 0.20567812025547028\n",
      "Epoch 2316, Loss: 0.622096449136734, Final Batch Loss: 0.18514502048492432\n",
      "Epoch 2317, Loss: 0.7575526535511017, Final Batch Loss: 0.2373468428850174\n",
      "Epoch 2318, Loss: 0.7169069647789001, Final Batch Loss: 0.2785831689834595\n",
      "Epoch 2319, Loss: 0.7382105141878128, Final Batch Loss: 0.2554933428764343\n",
      "Epoch 2320, Loss: 0.7542780637741089, Final Batch Loss: 0.29407480359077454\n",
      "Epoch 2321, Loss: 0.6699286103248596, Final Batch Loss: 0.20146147906780243\n",
      "Epoch 2322, Loss: 0.7531049996614456, Final Batch Loss: 0.2955021262168884\n",
      "Epoch 2323, Loss: 0.7297664731740952, Final Batch Loss: 0.2335367202758789\n",
      "Epoch 2324, Loss: 0.7340914160013199, Final Batch Loss: 0.2148279994726181\n",
      "Epoch 2325, Loss: 0.7779716700315475, Final Batch Loss: 0.21950866281986237\n",
      "Epoch 2326, Loss: 0.7318840622901917, Final Batch Loss: 0.1981334686279297\n",
      "Epoch 2327, Loss: 0.7688811123371124, Final Batch Loss: 0.3122035264968872\n",
      "Epoch 2328, Loss: 0.6155927628278732, Final Batch Loss: 0.18444880843162537\n",
      "Epoch 2329, Loss: 0.7351706773042679, Final Batch Loss: 0.2310895472764969\n",
      "Epoch 2330, Loss: 0.7363906353712082, Final Batch Loss: 0.21303951740264893\n",
      "Epoch 2331, Loss: 0.7339483946561813, Final Batch Loss: 0.20421601831912994\n",
      "Epoch 2332, Loss: 0.7078901827335358, Final Batch Loss: 0.21816293895244598\n",
      "Epoch 2333, Loss: 0.7318648546934128, Final Batch Loss: 0.3280852735042572\n",
      "Epoch 2334, Loss: 0.6733066737651825, Final Batch Loss: 0.1768602877855301\n",
      "Epoch 2335, Loss: 0.679855689406395, Final Batch Loss: 0.16523821651935577\n",
      "Epoch 2336, Loss: 0.7740386426448822, Final Batch Loss: 0.27128979563713074\n",
      "Epoch 2337, Loss: 0.7508905529975891, Final Batch Loss: 0.2516927123069763\n",
      "Epoch 2338, Loss: 0.6170027554035187, Final Batch Loss: 0.15028159320354462\n",
      "Epoch 2339, Loss: 0.5935978889465332, Final Batch Loss: 0.1385682076215744\n",
      "Epoch 2340, Loss: 0.7087931483983994, Final Batch Loss: 0.24584224820137024\n",
      "Epoch 2341, Loss: 0.6527447253465652, Final Batch Loss: 0.19682061672210693\n",
      "Epoch 2342, Loss: 0.6698678284883499, Final Batch Loss: 0.17332084476947784\n",
      "Epoch 2343, Loss: 0.6804832220077515, Final Batch Loss: 0.2434503436088562\n",
      "Epoch 2344, Loss: 0.7345766425132751, Final Batch Loss: 0.2502686679363251\n",
      "Epoch 2345, Loss: 0.7534637153148651, Final Batch Loss: 0.2373887300491333\n",
      "Epoch 2346, Loss: 0.6602479666471481, Final Batch Loss: 0.24784906208515167\n",
      "Epoch 2347, Loss: 0.6737665086984634, Final Batch Loss: 0.26681283116340637\n",
      "Epoch 2348, Loss: 0.9009315669536591, Final Batch Loss: 0.37420013546943665\n",
      "Epoch 2349, Loss: 0.6897760033607483, Final Batch Loss: 0.20634053647518158\n",
      "Epoch 2350, Loss: 0.7100043445825577, Final Batch Loss: 0.23090405762195587\n",
      "Epoch 2351, Loss: 0.669305756688118, Final Batch Loss: 0.21595372259616852\n",
      "Epoch 2352, Loss: 0.6857793778181076, Final Batch Loss: 0.14798353612422943\n",
      "Epoch 2353, Loss: 0.6158378720283508, Final Batch Loss: 0.14928610622882843\n",
      "Epoch 2354, Loss: 0.6773233860731125, Final Batch Loss: 0.23657666146755219\n",
      "Epoch 2355, Loss: 0.6212608814239502, Final Batch Loss: 0.1549379974603653\n",
      "Epoch 2356, Loss: 0.7445182502269745, Final Batch Loss: 0.28638485074043274\n",
      "Epoch 2357, Loss: 0.6898083835840225, Final Batch Loss: 0.2405523955821991\n",
      "Epoch 2358, Loss: 0.6799181699752808, Final Batch Loss: 0.17087189853191376\n",
      "Epoch 2359, Loss: 0.7383583039045334, Final Batch Loss: 0.2529522180557251\n",
      "Epoch 2360, Loss: 0.6386419534683228, Final Batch Loss: 0.14864481985569\n",
      "Epoch 2361, Loss: 0.6310848593711853, Final Batch Loss: 0.1844802051782608\n",
      "Epoch 2362, Loss: 0.7313279062509537, Final Batch Loss: 0.2699393630027771\n",
      "Epoch 2363, Loss: 0.7417226880788803, Final Batch Loss: 0.3125600218772888\n",
      "Epoch 2364, Loss: 0.6808381229639053, Final Batch Loss: 0.19481155276298523\n",
      "Epoch 2365, Loss: 0.658888965845108, Final Batch Loss: 0.2060771882534027\n",
      "Epoch 2366, Loss: 0.6807162463665009, Final Batch Loss: 0.21035650372505188\n",
      "Epoch 2367, Loss: 0.6745186299085617, Final Batch Loss: 0.23553189635276794\n",
      "Epoch 2368, Loss: 0.6381860673427582, Final Batch Loss: 0.21481558680534363\n",
      "Epoch 2369, Loss: 0.724200427532196, Final Batch Loss: 0.2613421082496643\n",
      "Epoch 2370, Loss: 0.61488476395607, Final Batch Loss: 0.16540125012397766\n",
      "Epoch 2371, Loss: 0.6494933515787125, Final Batch Loss: 0.23386482894420624\n",
      "Epoch 2372, Loss: 0.6955196410417557, Final Batch Loss: 0.20981009304523468\n",
      "Epoch 2373, Loss: 0.7364697158336639, Final Batch Loss: 0.2554643750190735\n",
      "Epoch 2374, Loss: 0.7027438879013062, Final Batch Loss: 0.30844414234161377\n",
      "Epoch 2375, Loss: 0.6665161848068237, Final Batch Loss: 0.25252678990364075\n",
      "Epoch 2376, Loss: 0.5961558669805527, Final Batch Loss: 0.1925012320280075\n",
      "Epoch 2377, Loss: 0.7137490957975388, Final Batch Loss: 0.22731736302375793\n",
      "Epoch 2378, Loss: 0.7542766779661179, Final Batch Loss: 0.2351059466600418\n",
      "Epoch 2379, Loss: 0.8449434489011765, Final Batch Loss: 0.3340103328227997\n",
      "Epoch 2380, Loss: 0.6966779381036758, Final Batch Loss: 0.16428636014461517\n",
      "Epoch 2381, Loss: 0.7553018778562546, Final Batch Loss: 0.20291264355182648\n",
      "Epoch 2382, Loss: 0.6409794390201569, Final Batch Loss: 0.1954953819513321\n",
      "Epoch 2383, Loss: 0.6988728791475296, Final Batch Loss: 0.19188107550144196\n",
      "Epoch 2384, Loss: 0.7528970241546631, Final Batch Loss: 0.27572503685951233\n",
      "Epoch 2385, Loss: 0.7567335963249207, Final Batch Loss: 0.28696054220199585\n",
      "Epoch 2386, Loss: 0.7835336178541183, Final Batch Loss: 0.34250885248184204\n",
      "Epoch 2387, Loss: 0.6999188810586929, Final Batch Loss: 0.19910681247711182\n",
      "Epoch 2388, Loss: 0.7347007691860199, Final Batch Loss: 0.23623254895210266\n",
      "Epoch 2389, Loss: 0.7896012514829636, Final Batch Loss: 0.22982542216777802\n",
      "Epoch 2390, Loss: 0.7293575555086136, Final Batch Loss: 0.2567870318889618\n",
      "Epoch 2391, Loss: 0.732257604598999, Final Batch Loss: 0.3023768365383148\n",
      "Epoch 2392, Loss: 0.6779843717813492, Final Batch Loss: 0.23778994381427765\n",
      "Epoch 2393, Loss: 0.7734844386577606, Final Batch Loss: 0.27049776911735535\n",
      "Epoch 2394, Loss: 0.667720377445221, Final Batch Loss: 0.22627270221710205\n",
      "Epoch 2395, Loss: 0.6939685195684433, Final Batch Loss: 0.23047882318496704\n",
      "Epoch 2396, Loss: 0.7461619079113007, Final Batch Loss: 0.28106802701950073\n",
      "Epoch 2397, Loss: 0.7344821691513062, Final Batch Loss: 0.31212761998176575\n",
      "Epoch 2398, Loss: 0.6345934867858887, Final Batch Loss: 0.18334431946277618\n",
      "Epoch 2399, Loss: 0.6340946853160858, Final Batch Loss: 0.23197735846042633\n",
      "Epoch 2400, Loss: 0.6824035793542862, Final Batch Loss: 0.21531616151332855\n",
      "Epoch 2401, Loss: 0.7027326971292496, Final Batch Loss: 0.19142216444015503\n",
      "Epoch 2402, Loss: 0.7658702731132507, Final Batch Loss: 0.32836440205574036\n",
      "Epoch 2403, Loss: 0.7189215421676636, Final Batch Loss: 0.2530249357223511\n",
      "Epoch 2404, Loss: 0.6483982652425766, Final Batch Loss: 0.2308351844549179\n",
      "Epoch 2405, Loss: 0.5818361341953278, Final Batch Loss: 0.13543583452701569\n",
      "Epoch 2406, Loss: 0.6919710636138916, Final Batch Loss: 0.22626914083957672\n",
      "Epoch 2407, Loss: 0.7589689791202545, Final Batch Loss: 0.3114916980266571\n",
      "Epoch 2408, Loss: 0.7714544385671616, Final Batch Loss: 0.25181323289871216\n",
      "Epoch 2409, Loss: 0.632929652929306, Final Batch Loss: 0.21966935694217682\n",
      "Epoch 2410, Loss: 0.6880867183208466, Final Batch Loss: 0.2417895495891571\n",
      "Epoch 2411, Loss: 0.6030991673469543, Final Batch Loss: 0.17287121713161469\n",
      "Epoch 2412, Loss: 0.713677853345871, Final Batch Loss: 0.18250471353530884\n",
      "Epoch 2413, Loss: 0.8020792156457901, Final Batch Loss: 0.3593461513519287\n",
      "Epoch 2414, Loss: 0.676602840423584, Final Batch Loss: 0.13063570857048035\n",
      "Epoch 2415, Loss: 0.6476960331201553, Final Batch Loss: 0.14704494178295135\n",
      "Epoch 2416, Loss: 0.6644181609153748, Final Batch Loss: 0.17467676103115082\n",
      "Epoch 2417, Loss: 0.7494046986103058, Final Batch Loss: 0.19777531921863556\n",
      "Epoch 2418, Loss: 0.6814865171909332, Final Batch Loss: 0.20904429256916046\n",
      "Epoch 2419, Loss: 0.6560947597026825, Final Batch Loss: 0.2247360795736313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2420, Loss: 0.6155720353126526, Final Batch Loss: 0.1738131195306778\n",
      "Epoch 2421, Loss: 0.7713096141815186, Final Batch Loss: 0.2211567759513855\n",
      "Epoch 2422, Loss: 0.651869997382164, Final Batch Loss: 0.20950418710708618\n",
      "Epoch 2423, Loss: 0.612184002995491, Final Batch Loss: 0.17333148419857025\n",
      "Epoch 2424, Loss: 0.6701407581567764, Final Batch Loss: 0.1852349042892456\n",
      "Epoch 2425, Loss: 0.6536655277013779, Final Batch Loss: 0.20757028460502625\n",
      "Epoch 2426, Loss: 0.6523129045963287, Final Batch Loss: 0.2135273963212967\n",
      "Epoch 2427, Loss: 0.6753830015659332, Final Batch Loss: 0.190304696559906\n",
      "Epoch 2428, Loss: 0.6958848834037781, Final Batch Loss: 0.26743343472480774\n",
      "Epoch 2429, Loss: 0.6991533935070038, Final Batch Loss: 0.33021280169487\n",
      "Epoch 2430, Loss: 0.6600705236196518, Final Batch Loss: 0.22832222282886505\n",
      "Epoch 2431, Loss: 0.6407369077205658, Final Batch Loss: 0.24062742292881012\n",
      "Epoch 2432, Loss: 0.5631195604801178, Final Batch Loss: 0.1517128199338913\n",
      "Epoch 2433, Loss: 0.650131106376648, Final Batch Loss: 0.1856643408536911\n",
      "Epoch 2434, Loss: 0.671355664730072, Final Batch Loss: 0.1745743453502655\n",
      "Epoch 2435, Loss: 0.6666975915431976, Final Batch Loss: 0.2621210515499115\n",
      "Epoch 2436, Loss: 0.6177383214235306, Final Batch Loss: 0.19593018293380737\n",
      "Epoch 2437, Loss: 0.6127314567565918, Final Batch Loss: 0.15038157999515533\n",
      "Epoch 2438, Loss: 0.6634497046470642, Final Batch Loss: 0.17844559252262115\n",
      "Epoch 2439, Loss: 0.5226050168275833, Final Batch Loss: 0.17713044583797455\n",
      "Epoch 2440, Loss: 0.7764545381069183, Final Batch Loss: 0.3027544915676117\n",
      "Epoch 2441, Loss: 0.6654103994369507, Final Batch Loss: 0.2130894660949707\n",
      "Epoch 2442, Loss: 0.7799041867256165, Final Batch Loss: 0.3505895137786865\n",
      "Epoch 2443, Loss: 0.6712542921304703, Final Batch Loss: 0.21443277597427368\n",
      "Epoch 2444, Loss: 0.5968985557556152, Final Batch Loss: 0.19141428172588348\n",
      "Epoch 2445, Loss: 0.6380179151892662, Final Batch Loss: 0.12237916141748428\n",
      "Epoch 2446, Loss: 0.8029148578643799, Final Batch Loss: 0.3216123580932617\n",
      "Epoch 2447, Loss: 0.8861407339572906, Final Batch Loss: 0.49173152446746826\n",
      "Epoch 2448, Loss: 0.6747457087039948, Final Batch Loss: 0.19586127996444702\n",
      "Epoch 2449, Loss: 0.8023280203342438, Final Batch Loss: 0.31364721059799194\n",
      "Epoch 2450, Loss: 0.6392349302768707, Final Batch Loss: 0.23284012079238892\n",
      "Epoch 2451, Loss: 0.8536854088306427, Final Batch Loss: 0.29661011695861816\n",
      "Epoch 2452, Loss: 0.742960050702095, Final Batch Loss: 0.2612396776676178\n",
      "Epoch 2453, Loss: 0.6940378397703171, Final Batch Loss: 0.18588675558567047\n",
      "Epoch 2454, Loss: 0.7052398473024368, Final Batch Loss: 0.19628576934337616\n",
      "Epoch 2455, Loss: 0.634754553437233, Final Batch Loss: 0.2291124314069748\n",
      "Epoch 2456, Loss: 0.7194432765245438, Final Batch Loss: 0.20749612152576447\n",
      "Epoch 2457, Loss: 0.7025126069784164, Final Batch Loss: 0.28279995918273926\n",
      "Epoch 2458, Loss: 0.7123658359050751, Final Batch Loss: 0.2087671309709549\n",
      "Epoch 2459, Loss: 0.7004147171974182, Final Batch Loss: 0.2142978310585022\n",
      "Epoch 2460, Loss: 0.6367507725954056, Final Batch Loss: 0.19794239103794098\n",
      "Epoch 2461, Loss: 0.7344771772623062, Final Batch Loss: 0.26186561584472656\n",
      "Epoch 2462, Loss: 0.6913817226886749, Final Batch Loss: 0.2431754618883133\n",
      "Epoch 2463, Loss: 0.7684680968523026, Final Batch Loss: 0.22009535133838654\n",
      "Epoch 2464, Loss: 0.7232497781515121, Final Batch Loss: 0.2901335060596466\n",
      "Epoch 2465, Loss: 0.7439652532339096, Final Batch Loss: 0.25572505593299866\n",
      "Epoch 2466, Loss: 0.638785257935524, Final Batch Loss: 0.19836744666099548\n",
      "Epoch 2467, Loss: 0.7991896867752075, Final Batch Loss: 0.22647130489349365\n",
      "Epoch 2468, Loss: 0.7124883532524109, Final Batch Loss: 0.24194106459617615\n",
      "Epoch 2469, Loss: 0.7516708672046661, Final Batch Loss: 0.27659711241722107\n",
      "Epoch 2470, Loss: 0.6644426137208939, Final Batch Loss: 0.22067423164844513\n",
      "Epoch 2471, Loss: 0.6709536910057068, Final Batch Loss: 0.17737635970115662\n",
      "Epoch 2472, Loss: 0.6565837562084198, Final Batch Loss: 0.2637218236923218\n",
      "Epoch 2473, Loss: 0.6079995185136795, Final Batch Loss: 0.15475259721279144\n",
      "Epoch 2474, Loss: 0.6822544187307358, Final Batch Loss: 0.22284533083438873\n",
      "Epoch 2475, Loss: 0.647847905755043, Final Batch Loss: 0.24519981443881989\n",
      "Epoch 2476, Loss: 0.6506424695253372, Final Batch Loss: 0.27589330077171326\n",
      "Epoch 2477, Loss: 0.6823995560407639, Final Batch Loss: 0.19329850375652313\n",
      "Epoch 2478, Loss: 0.7668090611696243, Final Batch Loss: 0.3289293348789215\n",
      "Epoch 2479, Loss: 0.7023044228553772, Final Batch Loss: 0.21217621862888336\n",
      "Epoch 2480, Loss: 0.7037132531404495, Final Batch Loss: 0.23912313580513\n",
      "Epoch 2481, Loss: 0.7688813954591751, Final Batch Loss: 0.31216713786125183\n",
      "Epoch 2482, Loss: 0.7128366380929947, Final Batch Loss: 0.24426840245723724\n",
      "Epoch 2483, Loss: 0.643551230430603, Final Batch Loss: 0.23092179000377655\n",
      "Epoch 2484, Loss: 0.703743577003479, Final Batch Loss: 0.2625100016593933\n",
      "Epoch 2485, Loss: 0.6357321441173553, Final Batch Loss: 0.17469389736652374\n",
      "Epoch 2486, Loss: 0.6683278828859329, Final Batch Loss: 0.22368815541267395\n",
      "Epoch 2487, Loss: 0.7635954171419144, Final Batch Loss: 0.23302827775478363\n",
      "Epoch 2488, Loss: 0.5834808945655823, Final Batch Loss: 0.17625179886817932\n",
      "Epoch 2489, Loss: 0.6686133444309235, Final Batch Loss: 0.16694612801074982\n",
      "Epoch 2490, Loss: 0.8098515123128891, Final Batch Loss: 0.2893931567668915\n",
      "Epoch 2491, Loss: 0.6662776172161102, Final Batch Loss: 0.19234508275985718\n",
      "Epoch 2492, Loss: 0.766044408082962, Final Batch Loss: 0.2756703197956085\n",
      "Epoch 2493, Loss: 0.5790055096149445, Final Batch Loss: 0.15921658277511597\n",
      "Epoch 2494, Loss: 0.7493356168270111, Final Batch Loss: 0.249210387468338\n",
      "Epoch 2495, Loss: 0.6668974012136459, Final Batch Loss: 0.2788447141647339\n",
      "Epoch 2496, Loss: 0.6522899121046066, Final Batch Loss: 0.21135738492012024\n",
      "Epoch 2497, Loss: 0.6039951741695404, Final Batch Loss: 0.17887771129608154\n",
      "Epoch 2498, Loss: 0.6871443539857864, Final Batch Loss: 0.23154747486114502\n",
      "Epoch 2499, Loss: 0.7262190878391266, Final Batch Loss: 0.25705572962760925\n",
      "Epoch 2500, Loss: 0.6543485224246979, Final Batch Loss: 0.269746869802475\n",
      "Epoch 2501, Loss: 0.8143789768218994, Final Batch Loss: 0.2925029695034027\n",
      "Epoch 2502, Loss: 0.6409418433904648, Final Batch Loss: 0.2178114503622055\n",
      "Epoch 2503, Loss: 0.6421326249837875, Final Batch Loss: 0.2588556706905365\n",
      "Epoch 2504, Loss: 0.6860357969999313, Final Batch Loss: 0.22241723537445068\n",
      "Epoch 2505, Loss: 0.6699279993772507, Final Batch Loss: 0.2516992688179016\n",
      "Epoch 2506, Loss: 0.6401579529047012, Final Batch Loss: 0.24582035839557648\n",
      "Epoch 2507, Loss: 0.6959600746631622, Final Batch Loss: 0.21805138885974884\n",
      "Epoch 2508, Loss: 0.6489702761173248, Final Batch Loss: 0.1980353146791458\n",
      "Epoch 2509, Loss: 0.6898096948862076, Final Batch Loss: 0.28891921043395996\n",
      "Epoch 2510, Loss: 0.6831527203321457, Final Batch Loss: 0.21720968186855316\n",
      "Epoch 2511, Loss: 0.6621890217065811, Final Batch Loss: 0.20979736745357513\n",
      "Epoch 2512, Loss: 0.6765748411417007, Final Batch Loss: 0.20288175344467163\n",
      "Epoch 2513, Loss: 0.6805404275655746, Final Batch Loss: 0.19456371665000916\n",
      "Epoch 2514, Loss: 0.6204260289669037, Final Batch Loss: 0.1952994167804718\n",
      "Epoch 2515, Loss: 0.6959097236394882, Final Batch Loss: 0.19683200120925903\n",
      "Epoch 2516, Loss: 0.623922660946846, Final Batch Loss: 0.17888914048671722\n",
      "Epoch 2517, Loss: 0.6622446328401566, Final Batch Loss: 0.15535986423492432\n",
      "Epoch 2518, Loss: 0.6393412947654724, Final Batch Loss: 0.2010667622089386\n",
      "Epoch 2519, Loss: 0.6675107181072235, Final Batch Loss: 0.27887171506881714\n",
      "Epoch 2520, Loss: 0.6762404441833496, Final Batch Loss: 0.25706517696380615\n",
      "Epoch 2521, Loss: 0.6820236295461655, Final Batch Loss: 0.25342291593551636\n",
      "Epoch 2522, Loss: 0.6631283015012741, Final Batch Loss: 0.23846839368343353\n",
      "Epoch 2523, Loss: 0.7046866416931152, Final Batch Loss: 0.24590639770030975\n",
      "Epoch 2524, Loss: 0.6902618855237961, Final Batch Loss: 0.19950173795223236\n",
      "Epoch 2525, Loss: 0.6205219924449921, Final Batch Loss: 0.26937517523765564\n",
      "Epoch 2526, Loss: 0.6801359504461288, Final Batch Loss: 0.20683875679969788\n",
      "Epoch 2527, Loss: 0.6676518470048904, Final Batch Loss: 0.16349487006664276\n",
      "Epoch 2528, Loss: 0.7351649701595306, Final Batch Loss: 0.2686076760292053\n",
      "Epoch 2529, Loss: 0.623652994632721, Final Batch Loss: 0.23684702813625336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2530, Loss: 0.651115819811821, Final Batch Loss: 0.21584424376487732\n",
      "Epoch 2531, Loss: 0.7356705069541931, Final Batch Loss: 0.3317908048629761\n",
      "Epoch 2532, Loss: 0.6475357413291931, Final Batch Loss: 0.25074833631515503\n",
      "Epoch 2533, Loss: 0.6840713173151016, Final Batch Loss: 0.19037075340747833\n",
      "Epoch 2534, Loss: 0.6613915711641312, Final Batch Loss: 0.2959221303462982\n",
      "Epoch 2535, Loss: 0.6835393607616425, Final Batch Loss: 0.2983597218990326\n",
      "Epoch 2536, Loss: 0.6515334993600845, Final Batch Loss: 0.2426263689994812\n",
      "Epoch 2537, Loss: 0.6718145906925201, Final Batch Loss: 0.2041531205177307\n",
      "Epoch 2538, Loss: 0.7210784256458282, Final Batch Loss: 0.2073822021484375\n",
      "Epoch 2539, Loss: 0.6643838882446289, Final Batch Loss: 0.22484034299850464\n",
      "Epoch 2540, Loss: 0.7446051836013794, Final Batch Loss: 0.24605625867843628\n",
      "Epoch 2541, Loss: 0.5847625136375427, Final Batch Loss: 0.15383155643939972\n",
      "Epoch 2542, Loss: 0.5697299689054489, Final Batch Loss: 0.16083012521266937\n",
      "Epoch 2543, Loss: 0.6231634318828583, Final Batch Loss: 0.19347290694713593\n",
      "Epoch 2544, Loss: 0.6375646740198135, Final Batch Loss: 0.179491326212883\n",
      "Epoch 2545, Loss: 0.7990649044513702, Final Batch Loss: 0.34830886125564575\n",
      "Epoch 2546, Loss: 0.6229311525821686, Final Batch Loss: 0.21454760432243347\n",
      "Epoch 2547, Loss: 0.5614685863256454, Final Batch Loss: 0.14531241357326508\n",
      "Epoch 2548, Loss: 0.681889683008194, Final Batch Loss: 0.2653837203979492\n",
      "Epoch 2549, Loss: 0.767549067735672, Final Batch Loss: 0.25283995270729065\n",
      "Epoch 2550, Loss: 0.6221803575754166, Final Batch Loss: 0.14998823404312134\n",
      "Epoch 2551, Loss: 0.6254450082778931, Final Batch Loss: 0.19861914217472076\n",
      "Epoch 2552, Loss: 0.6232980340719223, Final Batch Loss: 0.23904548585414886\n",
      "Epoch 2553, Loss: 0.5735092908143997, Final Batch Loss: 0.23857367038726807\n",
      "Epoch 2554, Loss: 0.5863646119832993, Final Batch Loss: 0.19496150314807892\n",
      "Epoch 2555, Loss: 0.6746048331260681, Final Batch Loss: 0.275681734085083\n",
      "Epoch 2556, Loss: 0.6571486443281174, Final Batch Loss: 0.22872819006443024\n",
      "Epoch 2557, Loss: 0.6350830942392349, Final Batch Loss: 0.1983022689819336\n",
      "Epoch 2558, Loss: 0.6073289215564728, Final Batch Loss: 0.1704060286283493\n",
      "Epoch 2559, Loss: 0.6920004487037659, Final Batch Loss: 0.2723515033721924\n",
      "Epoch 2560, Loss: 0.6845250278711319, Final Batch Loss: 0.23577234148979187\n",
      "Epoch 2561, Loss: 0.5943699926137924, Final Batch Loss: 0.19593295454978943\n",
      "Epoch 2562, Loss: 0.6372304558753967, Final Batch Loss: 0.21825844049453735\n",
      "Epoch 2563, Loss: 0.6693318486213684, Final Batch Loss: 0.23588724434375763\n",
      "Epoch 2564, Loss: 0.6220991611480713, Final Batch Loss: 0.23329490423202515\n",
      "Epoch 2565, Loss: 0.5990912914276123, Final Batch Loss: 0.16048872470855713\n",
      "Epoch 2566, Loss: 0.7752977162599564, Final Batch Loss: 0.3040371835231781\n",
      "Epoch 2567, Loss: 0.6526843458414078, Final Batch Loss: 0.2400684356689453\n",
      "Epoch 2568, Loss: 0.6687749028205872, Final Batch Loss: 0.19219031929969788\n",
      "Epoch 2569, Loss: 0.7009131163358688, Final Batch Loss: 0.20883385837078094\n",
      "Epoch 2570, Loss: 0.5982653051614761, Final Batch Loss: 0.2156001627445221\n",
      "Epoch 2571, Loss: 0.6342428773641586, Final Batch Loss: 0.20067530870437622\n",
      "Epoch 2572, Loss: 0.628801628947258, Final Batch Loss: 0.1410401463508606\n",
      "Epoch 2573, Loss: 0.6212223172187805, Final Batch Loss: 0.16507010161876678\n",
      "Epoch 2574, Loss: 0.6307902485132217, Final Batch Loss: 0.20013171434402466\n",
      "Epoch 2575, Loss: 0.5234273225069046, Final Batch Loss: 0.16924573481082916\n",
      "Epoch 2576, Loss: 0.6919243931770325, Final Batch Loss: 0.2352537363767624\n",
      "Epoch 2577, Loss: 0.6973378211259842, Final Batch Loss: 0.21109166741371155\n",
      "Epoch 2578, Loss: 0.6573434919118881, Final Batch Loss: 0.2738814651966095\n",
      "Epoch 2579, Loss: 0.666423112154007, Final Batch Loss: 0.2033388912677765\n",
      "Epoch 2580, Loss: 0.6277751922607422, Final Batch Loss: 0.20170782506465912\n",
      "Epoch 2581, Loss: 0.669098362326622, Final Batch Loss: 0.2291197031736374\n",
      "Epoch 2582, Loss: 0.6886709928512573, Final Batch Loss: 0.22312909364700317\n",
      "Epoch 2583, Loss: 0.6196054369211197, Final Batch Loss: 0.17105403542518616\n",
      "Epoch 2584, Loss: 0.624357134103775, Final Batch Loss: 0.20655058324337006\n",
      "Epoch 2585, Loss: 0.720459520816803, Final Batch Loss: 0.24372951686382294\n",
      "Epoch 2586, Loss: 0.6427483856678009, Final Batch Loss: 0.1575019508600235\n",
      "Epoch 2587, Loss: 0.638652428984642, Final Batch Loss: 0.21245057880878448\n",
      "Epoch 2588, Loss: 0.7087909877300262, Final Batch Loss: 0.26009199023246765\n",
      "Epoch 2589, Loss: 0.7283150404691696, Final Batch Loss: 0.26183634996414185\n",
      "Epoch 2590, Loss: 0.7084566056728363, Final Batch Loss: 0.24812467396259308\n",
      "Epoch 2591, Loss: 0.6079683005809784, Final Batch Loss: 0.21454347670078278\n",
      "Epoch 2592, Loss: 0.6560198813676834, Final Batch Loss: 0.22226859629154205\n",
      "Epoch 2593, Loss: 0.6100838631391525, Final Batch Loss: 0.18880634009838104\n",
      "Epoch 2594, Loss: 0.6200166046619415, Final Batch Loss: 0.18886369466781616\n",
      "Epoch 2595, Loss: 0.6244705617427826, Final Batch Loss: 0.2454432249069214\n",
      "Epoch 2596, Loss: 0.5833174288272858, Final Batch Loss: 0.1511838585138321\n",
      "Epoch 2597, Loss: 0.5983518064022064, Final Batch Loss: 0.19179731607437134\n",
      "Epoch 2598, Loss: 0.5787340849637985, Final Batch Loss: 0.17106950283050537\n",
      "Epoch 2599, Loss: 0.5481983125209808, Final Batch Loss: 0.14705577492713928\n",
      "Epoch 2600, Loss: 0.5370669513940811, Final Batch Loss: 0.14566916227340698\n",
      "Epoch 2601, Loss: 0.6119411140680313, Final Batch Loss: 0.22233064472675323\n",
      "Epoch 2602, Loss: 0.6518541872501373, Final Batch Loss: 0.2431933581829071\n",
      "Epoch 2603, Loss: 0.6186317056417465, Final Batch Loss: 0.19399258494377136\n",
      "Epoch 2604, Loss: 0.6459642052650452, Final Batch Loss: 0.144472137093544\n",
      "Epoch 2605, Loss: 0.5761432349681854, Final Batch Loss: 0.13951195776462555\n",
      "Epoch 2606, Loss: 0.6997457444667816, Final Batch Loss: 0.26823973655700684\n",
      "Epoch 2607, Loss: 0.6083985418081284, Final Batch Loss: 0.15534336864948273\n",
      "Epoch 2608, Loss: 0.6932226717472076, Final Batch Loss: 0.2171856164932251\n",
      "Epoch 2609, Loss: 0.6102790385484695, Final Batch Loss: 0.18437014520168304\n",
      "Epoch 2610, Loss: 0.7019083350896835, Final Batch Loss: 0.22569172084331512\n",
      "Epoch 2611, Loss: 0.6028474271297455, Final Batch Loss: 0.17870280146598816\n",
      "Epoch 2612, Loss: 0.6836834996938705, Final Batch Loss: 0.25269848108291626\n",
      "Epoch 2613, Loss: 0.5610611587762833, Final Batch Loss: 0.19195204973220825\n",
      "Epoch 2614, Loss: 0.7249192148447037, Final Batch Loss: 0.25252658128738403\n",
      "Epoch 2615, Loss: 0.6438983678817749, Final Batch Loss: 0.20375150442123413\n",
      "Epoch 2616, Loss: 0.7354810535907745, Final Batch Loss: 0.2825779318809509\n",
      "Epoch 2617, Loss: 0.7671648859977722, Final Batch Loss: 0.2543676197528839\n",
      "Epoch 2618, Loss: 0.7555235326290131, Final Batch Loss: 0.24045540392398834\n",
      "Epoch 2619, Loss: 0.6305485218763351, Final Batch Loss: 0.228997141122818\n",
      "Epoch 2620, Loss: 0.6637258380651474, Final Batch Loss: 0.19381922483444214\n",
      "Epoch 2621, Loss: 0.5694693177938461, Final Batch Loss: 0.15474030375480652\n",
      "Epoch 2622, Loss: 0.6761806160211563, Final Batch Loss: 0.19381587207317352\n",
      "Epoch 2623, Loss: 0.742527648806572, Final Batch Loss: 0.23926401138305664\n",
      "Epoch 2624, Loss: 0.6236135512590408, Final Batch Loss: 0.25260674953460693\n",
      "Epoch 2625, Loss: 0.5786495208740234, Final Batch Loss: 0.19844825565814972\n",
      "Epoch 2626, Loss: 0.6166654676198959, Final Batch Loss: 0.23955942690372467\n",
      "Epoch 2627, Loss: 0.6525768935680389, Final Batch Loss: 0.22297577559947968\n",
      "Epoch 2628, Loss: 0.6062070727348328, Final Batch Loss: 0.20416489243507385\n",
      "Epoch 2629, Loss: 0.5796453207731247, Final Batch Loss: 0.20571529865264893\n",
      "Epoch 2630, Loss: 0.5412396341562271, Final Batch Loss: 0.16946622729301453\n",
      "Epoch 2631, Loss: 0.5785378366708755, Final Batch Loss: 0.2089843899011612\n",
      "Epoch 2632, Loss: 0.67893186211586, Final Batch Loss: 0.3047774136066437\n",
      "Epoch 2633, Loss: 0.6764156222343445, Final Batch Loss: 0.22135652601718903\n",
      "Epoch 2634, Loss: 0.6449405699968338, Final Batch Loss: 0.18994243443012238\n",
      "Epoch 2635, Loss: 0.5929978787899017, Final Batch Loss: 0.141603484749794\n",
      "Epoch 2636, Loss: 0.5431245863437653, Final Batch Loss: 0.20085258781909943\n",
      "Epoch 2637, Loss: 0.672868549823761, Final Batch Loss: 0.24667829275131226\n",
      "Epoch 2638, Loss: 0.6774562448263168, Final Batch Loss: 0.18548651039600372\n",
      "Epoch 2639, Loss: 0.5492484867572784, Final Batch Loss: 0.19260041415691376\n",
      "Epoch 2640, Loss: 0.6081590205430984, Final Batch Loss: 0.2168745994567871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2641, Loss: 0.5178978741168976, Final Batch Loss: 0.181404247879982\n",
      "Epoch 2642, Loss: 0.6678927689790726, Final Batch Loss: 0.24852217733860016\n",
      "Epoch 2643, Loss: 0.6385812610387802, Final Batch Loss: 0.25904181599617004\n",
      "Epoch 2644, Loss: 0.5640830546617508, Final Batch Loss: 0.16866697371006012\n",
      "Epoch 2645, Loss: 0.6494787633419037, Final Batch Loss: 0.1856290102005005\n",
      "Epoch 2646, Loss: 0.6306316256523132, Final Batch Loss: 0.2013707160949707\n",
      "Epoch 2647, Loss: 0.6042572855949402, Final Batch Loss: 0.18827058374881744\n",
      "Epoch 2648, Loss: 0.5565038770437241, Final Batch Loss: 0.20802931487560272\n",
      "Epoch 2649, Loss: 0.6049833595752716, Final Batch Loss: 0.17986223101615906\n",
      "Epoch 2650, Loss: 0.5599558651447296, Final Batch Loss: 0.13781258463859558\n",
      "Epoch 2651, Loss: 0.648108497262001, Final Batch Loss: 0.2872456908226013\n",
      "Epoch 2652, Loss: 0.658320352435112, Final Batch Loss: 0.19712339341640472\n",
      "Epoch 2653, Loss: 0.6371330767869949, Final Batch Loss: 0.22972966730594635\n",
      "Epoch 2654, Loss: 0.6168708801269531, Final Batch Loss: 0.17489919066429138\n",
      "Epoch 2655, Loss: 0.6043992042541504, Final Batch Loss: 0.21971572935581207\n",
      "Epoch 2656, Loss: 0.5496275871992111, Final Batch Loss: 0.17756253480911255\n",
      "Epoch 2657, Loss: 0.6714495420455933, Final Batch Loss: 0.20201236009597778\n",
      "Epoch 2658, Loss: 0.6273487061262131, Final Batch Loss: 0.1614571064710617\n",
      "Epoch 2659, Loss: 0.6140231490135193, Final Batch Loss: 0.20959322154521942\n",
      "Epoch 2660, Loss: 0.6935644149780273, Final Batch Loss: 0.1713712066411972\n",
      "Epoch 2661, Loss: 0.6944666504859924, Final Batch Loss: 0.20386531949043274\n",
      "Epoch 2662, Loss: 0.6702574491500854, Final Batch Loss: 0.24423165619373322\n",
      "Epoch 2663, Loss: 0.6521268934011459, Final Batch Loss: 0.2458828240633011\n",
      "Epoch 2664, Loss: 0.6022378355264664, Final Batch Loss: 0.2308110147714615\n",
      "Epoch 2665, Loss: 0.5775476470589638, Final Batch Loss: 0.11460109800100327\n",
      "Epoch 2666, Loss: 0.6790259331464767, Final Batch Loss: 0.17858591675758362\n",
      "Epoch 2667, Loss: 0.6495404839515686, Final Batch Loss: 0.1660790741443634\n",
      "Epoch 2668, Loss: 0.7000949829816818, Final Batch Loss: 0.27288734912872314\n",
      "Epoch 2669, Loss: 0.6228446662425995, Final Batch Loss: 0.1972094476222992\n",
      "Epoch 2670, Loss: 0.6621557474136353, Final Batch Loss: 0.272625207901001\n",
      "Epoch 2671, Loss: 0.6712173521518707, Final Batch Loss: 0.2189088761806488\n",
      "Epoch 2672, Loss: 0.6395771503448486, Final Batch Loss: 0.14202441275119781\n",
      "Epoch 2673, Loss: 0.6274594217538834, Final Batch Loss: 0.21483227610588074\n",
      "Epoch 2674, Loss: 0.6539033055305481, Final Batch Loss: 0.16611938178539276\n",
      "Epoch 2675, Loss: 0.6380306631326675, Final Batch Loss: 0.23566874861717224\n",
      "Epoch 2676, Loss: 0.5654982477426529, Final Batch Loss: 0.18177911639213562\n",
      "Epoch 2677, Loss: 0.6021558046340942, Final Batch Loss: 0.23702813684940338\n",
      "Epoch 2678, Loss: 0.7051438987255096, Final Batch Loss: 0.21285291016101837\n",
      "Epoch 2679, Loss: 0.6727133989334106, Final Batch Loss: 0.21915879845619202\n",
      "Epoch 2680, Loss: 0.5599620789289474, Final Batch Loss: 0.17901502549648285\n",
      "Epoch 2681, Loss: 0.6084568202495575, Final Batch Loss: 0.24070100486278534\n",
      "Epoch 2682, Loss: 0.47765302658081055, Final Batch Loss: 0.1312163919210434\n",
      "Epoch 2683, Loss: 0.6347267776727676, Final Batch Loss: 0.18369129300117493\n",
      "Epoch 2684, Loss: 0.6098921447992325, Final Batch Loss: 0.15446121990680695\n",
      "Epoch 2685, Loss: 0.5883534252643585, Final Batch Loss: 0.18147088587284088\n",
      "Epoch 2686, Loss: 0.7296123057603836, Final Batch Loss: 0.30797678232192993\n",
      "Epoch 2687, Loss: 0.6036653071641922, Final Batch Loss: 0.22590813040733337\n",
      "Epoch 2688, Loss: 0.6337096244096756, Final Batch Loss: 0.2323327362537384\n",
      "Epoch 2689, Loss: 0.5610078573226929, Final Batch Loss: 0.13665519654750824\n",
      "Epoch 2690, Loss: 0.5982021391391754, Final Batch Loss: 0.17395584285259247\n",
      "Epoch 2691, Loss: 0.6658441126346588, Final Batch Loss: 0.2474333792924881\n",
      "Epoch 2692, Loss: 0.6091274917125702, Final Batch Loss: 0.16347073018550873\n",
      "Epoch 2693, Loss: 0.527877926826477, Final Batch Loss: 0.20722950994968414\n",
      "Epoch 2694, Loss: 0.6786964386701584, Final Batch Loss: 0.2799723148345947\n",
      "Epoch 2695, Loss: 0.6568748950958252, Final Batch Loss: 0.1530274599790573\n",
      "Epoch 2696, Loss: 0.6295886039733887, Final Batch Loss: 0.17354126274585724\n",
      "Epoch 2697, Loss: 0.7201573997735977, Final Batch Loss: 0.27295419573783875\n",
      "Epoch 2698, Loss: 0.6711254119873047, Final Batch Loss: 0.23636271059513092\n",
      "Epoch 2699, Loss: 0.6053022891283035, Final Batch Loss: 0.17355431616306305\n",
      "Epoch 2700, Loss: 0.6581539958715439, Final Batch Loss: 0.19593928754329681\n",
      "Epoch 2701, Loss: 0.6773754358291626, Final Batch Loss: 0.2518673241138458\n",
      "Epoch 2702, Loss: 0.8137263059616089, Final Batch Loss: 0.33731546998023987\n",
      "Epoch 2703, Loss: 0.741977646946907, Final Batch Loss: 0.2557050287723541\n",
      "Epoch 2704, Loss: 0.889384001493454, Final Batch Loss: 0.3378416895866394\n",
      "Epoch 2705, Loss: 0.7440823316574097, Final Batch Loss: 0.26394522190093994\n",
      "Epoch 2706, Loss: 0.6995835155248642, Final Batch Loss: 0.23840413987636566\n",
      "Epoch 2707, Loss: 0.7162241041660309, Final Batch Loss: 0.31681570410728455\n",
      "Epoch 2708, Loss: 0.6586905270814896, Final Batch Loss: 0.2582554221153259\n",
      "Epoch 2709, Loss: 0.6461733281612396, Final Batch Loss: 0.22241610288619995\n",
      "Epoch 2710, Loss: 0.7004870921373367, Final Batch Loss: 0.24506230652332306\n",
      "Epoch 2711, Loss: 0.581516832113266, Final Batch Loss: 0.23319217562675476\n",
      "Epoch 2712, Loss: 0.5715828239917755, Final Batch Loss: 0.1381881684064865\n",
      "Epoch 2713, Loss: 0.5152486562728882, Final Batch Loss: 0.19445458054542542\n",
      "Epoch 2714, Loss: 0.5736893564462662, Final Batch Loss: 0.21324166655540466\n",
      "Epoch 2715, Loss: 0.6662020236253738, Final Batch Loss: 0.26745516061782837\n",
      "Epoch 2716, Loss: 0.5563549101352692, Final Batch Loss: 0.19851639866828918\n",
      "Epoch 2717, Loss: 0.504698857665062, Final Batch Loss: 0.15269309282302856\n",
      "Epoch 2718, Loss: 0.513524167239666, Final Batch Loss: 0.1157400980591774\n",
      "Epoch 2719, Loss: 0.7142298370599747, Final Batch Loss: 0.23852913081645966\n",
      "Epoch 2720, Loss: 0.6188322603702545, Final Batch Loss: 0.21632784605026245\n",
      "Epoch 2721, Loss: 0.5566758960485458, Final Batch Loss: 0.19093139469623566\n",
      "Epoch 2722, Loss: 0.7159168571233749, Final Batch Loss: 0.23842410743236542\n",
      "Epoch 2723, Loss: 0.5800998359918594, Final Batch Loss: 0.10979709029197693\n",
      "Epoch 2724, Loss: 0.6523330807685852, Final Batch Loss: 0.18091222643852234\n",
      "Epoch 2725, Loss: 0.6652954667806625, Final Batch Loss: 0.2103339582681656\n",
      "Epoch 2726, Loss: 0.6255831271409988, Final Batch Loss: 0.21895062923431396\n",
      "Epoch 2727, Loss: 0.590240865945816, Final Batch Loss: 0.2536030113697052\n",
      "Epoch 2728, Loss: 0.6324659436941147, Final Batch Loss: 0.21675686538219452\n",
      "Epoch 2729, Loss: 0.5744404643774033, Final Batch Loss: 0.15984077751636505\n",
      "Epoch 2730, Loss: 0.5921730548143387, Final Batch Loss: 0.21308575570583344\n",
      "Epoch 2731, Loss: 0.6080640703439713, Final Batch Loss: 0.20167066156864166\n",
      "Epoch 2732, Loss: 0.638266310095787, Final Batch Loss: 0.2733572721481323\n",
      "Epoch 2733, Loss: 0.542726069688797, Final Batch Loss: 0.16390304267406464\n",
      "Epoch 2734, Loss: 0.5184939950704575, Final Batch Loss: 0.14982590079307556\n",
      "Epoch 2735, Loss: 0.6049784272909164, Final Batch Loss: 0.2096070945262909\n",
      "Epoch 2736, Loss: 0.5191240608692169, Final Batch Loss: 0.15492340922355652\n",
      "Epoch 2737, Loss: 0.6308382451534271, Final Batch Loss: 0.2033451497554779\n",
      "Epoch 2738, Loss: 0.60857854783535, Final Batch Loss: 0.19319814443588257\n",
      "Epoch 2739, Loss: 0.5800033509731293, Final Batch Loss: 0.17413677275180817\n",
      "Epoch 2740, Loss: 0.5295621901750565, Final Batch Loss: 0.15590408444404602\n",
      "Epoch 2741, Loss: 0.5435212701559067, Final Batch Loss: 0.20791196823120117\n",
      "Epoch 2742, Loss: 0.5797977596521378, Final Batch Loss: 0.17756453156471252\n",
      "Epoch 2743, Loss: 0.536797508597374, Final Batch Loss: 0.14296215772628784\n",
      "Epoch 2744, Loss: 0.5542300194501877, Final Batch Loss: 0.1399325281381607\n",
      "Epoch 2745, Loss: 0.5351281315088272, Final Batch Loss: 0.19152666628360748\n",
      "Epoch 2746, Loss: 0.6832409352064133, Final Batch Loss: 0.1985158920288086\n",
      "Epoch 2747, Loss: 0.519681379199028, Final Batch Loss: 0.12936291098594666\n",
      "Epoch 2748, Loss: 0.6143767386674881, Final Batch Loss: 0.19640347361564636\n",
      "Epoch 2749, Loss: 0.5663978755474091, Final Batch Loss: 0.16055546700954437\n",
      "Epoch 2750, Loss: 0.6349058449268341, Final Batch Loss: 0.2258463352918625\n",
      "Epoch 2751, Loss: 0.6363916993141174, Final Batch Loss: 0.243289053440094\n",
      "Epoch 2752, Loss: 0.5629849284887314, Final Batch Loss: 0.1562526375055313\n",
      "Epoch 2753, Loss: 0.6697230339050293, Final Batch Loss: 0.2238805741071701\n",
      "Epoch 2754, Loss: 0.5616115629673004, Final Batch Loss: 0.17475587129592896\n",
      "Epoch 2755, Loss: 0.603279784321785, Final Batch Loss: 0.2149476408958435\n",
      "Epoch 2756, Loss: 0.577456995844841, Final Batch Loss: 0.2151002287864685\n",
      "Epoch 2757, Loss: 0.5506457984447479, Final Batch Loss: 0.1699056327342987\n",
      "Epoch 2758, Loss: 0.6239141672849655, Final Batch Loss: 0.2189740091562271\n",
      "Epoch 2759, Loss: 0.6594051122665405, Final Batch Loss: 0.21606555581092834\n",
      "Epoch 2760, Loss: 0.7203171849250793, Final Batch Loss: 0.18571364879608154\n",
      "Epoch 2761, Loss: 0.6878054738044739, Final Batch Loss: 0.21856342256069183\n",
      "Epoch 2762, Loss: 0.7918717861175537, Final Batch Loss: 0.2813044786453247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2763, Loss: 0.5814626216888428, Final Batch Loss: 0.18229785561561584\n",
      "Epoch 2764, Loss: 0.5937089174985886, Final Batch Loss: 0.16573938727378845\n",
      "Epoch 2765, Loss: 0.653744101524353, Final Batch Loss: 0.18505032360553741\n",
      "Epoch 2766, Loss: 0.615388348698616, Final Batch Loss: 0.27938202023506165\n",
      "Epoch 2767, Loss: 0.5702031999826431, Final Batch Loss: 0.1885003298521042\n",
      "Epoch 2768, Loss: 0.5331096351146698, Final Batch Loss: 0.15220464766025543\n",
      "Epoch 2769, Loss: 0.5562649965286255, Final Batch Loss: 0.16946007311344147\n",
      "Epoch 2770, Loss: 0.5301740616559982, Final Batch Loss: 0.16648969054222107\n",
      "Epoch 2771, Loss: 0.7466421574354172, Final Batch Loss: 0.3857390880584717\n",
      "Epoch 2772, Loss: 0.6780582219362259, Final Batch Loss: 0.28323790431022644\n",
      "Epoch 2773, Loss: 0.6478076726198196, Final Batch Loss: 0.19747813045978546\n",
      "Epoch 2774, Loss: 0.612275093793869, Final Batch Loss: 0.2554405927658081\n",
      "Epoch 2775, Loss: 0.7009997963905334, Final Batch Loss: 0.2588784992694855\n",
      "Epoch 2776, Loss: 0.5609244853258133, Final Batch Loss: 0.2247706800699234\n",
      "Epoch 2777, Loss: 0.6246747821569443, Final Batch Loss: 0.14892235398292542\n",
      "Epoch 2778, Loss: 0.6992224007844925, Final Batch Loss: 0.24641425907611847\n",
      "Epoch 2779, Loss: 0.6342107355594635, Final Batch Loss: 0.2693822383880615\n",
      "Epoch 2780, Loss: 0.6391119956970215, Final Batch Loss: 0.2887808084487915\n",
      "Epoch 2781, Loss: 0.5187011212110519, Final Batch Loss: 0.14720754325389862\n",
      "Epoch 2782, Loss: 0.5919044464826584, Final Batch Loss: 0.17021597921848297\n",
      "Epoch 2783, Loss: 0.5280535668134689, Final Batch Loss: 0.19210785627365112\n",
      "Epoch 2784, Loss: 0.5121223032474518, Final Batch Loss: 0.17006149888038635\n",
      "Epoch 2785, Loss: 0.5706975311040878, Final Batch Loss: 0.15667620301246643\n",
      "Epoch 2786, Loss: 0.5365902334451675, Final Batch Loss: 0.1690872311592102\n",
      "Epoch 2787, Loss: 0.5940778404474258, Final Batch Loss: 0.2581128776073456\n",
      "Epoch 2788, Loss: 0.6684958636760712, Final Batch Loss: 0.20343157649040222\n",
      "Epoch 2789, Loss: 0.5149331986904144, Final Batch Loss: 0.1976211965084076\n",
      "Epoch 2790, Loss: 0.7664373368024826, Final Batch Loss: 0.20834489166736603\n",
      "Epoch 2791, Loss: 0.6236969232559204, Final Batch Loss: 0.24333204329013824\n",
      "Epoch 2792, Loss: 0.5711907744407654, Final Batch Loss: 0.1576579064130783\n",
      "Epoch 2793, Loss: 0.6053027659654617, Final Batch Loss: 0.2377600371837616\n",
      "Epoch 2794, Loss: 0.594219908118248, Final Batch Loss: 0.18514671921730042\n",
      "Epoch 2795, Loss: 0.6123378425836563, Final Batch Loss: 0.24805086851119995\n",
      "Epoch 2796, Loss: 0.6187964528799057, Final Batch Loss: 0.18142913281917572\n",
      "Epoch 2797, Loss: 0.5370097011327744, Final Batch Loss: 0.1702459156513214\n",
      "Epoch 2798, Loss: 0.5951975882053375, Final Batch Loss: 0.16727353632450104\n",
      "Epoch 2799, Loss: 0.6038409173488617, Final Batch Loss: 0.22513924539089203\n",
      "Epoch 2800, Loss: 0.686702772974968, Final Batch Loss: 0.19934804737567902\n",
      "Epoch 2801, Loss: 0.6505377888679504, Final Batch Loss: 0.215279221534729\n",
      "Epoch 2802, Loss: 0.6380068212747574, Final Batch Loss: 0.24202601611614227\n",
      "Epoch 2803, Loss: 0.5689379870891571, Final Batch Loss: 0.22345227003097534\n",
      "Epoch 2804, Loss: 0.6737686693668365, Final Batch Loss: 0.28733372688293457\n",
      "Epoch 2805, Loss: 0.5777459740638733, Final Batch Loss: 0.22822216153144836\n",
      "Epoch 2806, Loss: 0.670081377029419, Final Batch Loss: 0.1769150197505951\n",
      "Epoch 2807, Loss: 0.5062600076198578, Final Batch Loss: 0.11696149408817291\n",
      "Epoch 2808, Loss: 0.6187367737293243, Final Batch Loss: 0.1483287215232849\n",
      "Epoch 2809, Loss: 0.5649338364601135, Final Batch Loss: 0.17305690050125122\n",
      "Epoch 2810, Loss: 0.6281567364931107, Final Batch Loss: 0.1873854249715805\n",
      "Epoch 2811, Loss: 0.505556121468544, Final Batch Loss: 0.1547035276889801\n",
      "Epoch 2812, Loss: 0.7058874666690826, Final Batch Loss: 0.29947134852409363\n",
      "Epoch 2813, Loss: 0.554488480091095, Final Batch Loss: 0.18103332817554474\n",
      "Epoch 2814, Loss: 0.6710091978311539, Final Batch Loss: 0.2251156121492386\n",
      "Epoch 2815, Loss: 0.5848253071308136, Final Batch Loss: 0.1432369500398636\n",
      "Epoch 2816, Loss: 0.6107805073261261, Final Batch Loss: 0.23409435153007507\n",
      "Epoch 2817, Loss: 0.5407124608755112, Final Batch Loss: 0.17124901711940765\n",
      "Epoch 2818, Loss: 0.6044210195541382, Final Batch Loss: 0.1775781810283661\n",
      "Epoch 2819, Loss: 0.5616797357797623, Final Batch Loss: 0.13969476521015167\n",
      "Epoch 2820, Loss: 0.7183678895235062, Final Batch Loss: 0.2699790298938751\n",
      "Epoch 2821, Loss: 0.6229328066110611, Final Batch Loss: 0.12684425711631775\n",
      "Epoch 2822, Loss: 0.5324398577213287, Final Batch Loss: 0.1477779746055603\n",
      "Epoch 2823, Loss: 0.5470748245716095, Final Batch Loss: 0.21163500845432281\n",
      "Epoch 2824, Loss: 0.6108542680740356, Final Batch Loss: 0.18741384148597717\n",
      "Epoch 2825, Loss: 0.6112611591815948, Final Batch Loss: 0.2333458960056305\n",
      "Epoch 2826, Loss: 0.5600255727767944, Final Batch Loss: 0.14345180988311768\n",
      "Epoch 2827, Loss: 0.6707265377044678, Final Batch Loss: 0.21855570375919342\n",
      "Epoch 2828, Loss: 0.6388684660196304, Final Batch Loss: 0.17760370671749115\n",
      "Epoch 2829, Loss: 0.6375031471252441, Final Batch Loss: 0.20593473315238953\n",
      "Epoch 2830, Loss: 0.5774038285017014, Final Batch Loss: 0.2466464787721634\n",
      "Epoch 2831, Loss: 0.6619376242160797, Final Batch Loss: 0.20819030702114105\n",
      "Epoch 2832, Loss: 0.5798683315515518, Final Batch Loss: 0.19636619091033936\n",
      "Epoch 2833, Loss: 0.5800627768039703, Final Batch Loss: 0.17317135632038116\n",
      "Epoch 2834, Loss: 0.6281633526086807, Final Batch Loss: 0.23191328346729279\n",
      "Epoch 2835, Loss: 0.6029188483953476, Final Batch Loss: 0.23065245151519775\n",
      "Epoch 2836, Loss: 0.6321501731872559, Final Batch Loss: 0.20362652838230133\n",
      "Epoch 2837, Loss: 0.623225137591362, Final Batch Loss: 0.27364370226860046\n",
      "Epoch 2838, Loss: 0.556741900742054, Final Batch Loss: 0.1052030548453331\n",
      "Epoch 2839, Loss: 0.607189804315567, Final Batch Loss: 0.18798884749412537\n",
      "Epoch 2840, Loss: 0.6753992885351181, Final Batch Loss: 0.20162996649742126\n",
      "Epoch 2841, Loss: 0.5586690455675125, Final Batch Loss: 0.15590223670005798\n",
      "Epoch 2842, Loss: 0.7347864061594009, Final Batch Loss: 0.2873038053512573\n",
      "Epoch 2843, Loss: 0.5864706486463547, Final Batch Loss: 0.21856597065925598\n",
      "Epoch 2844, Loss: 0.7290317863225937, Final Batch Loss: 0.2765403091907501\n",
      "Epoch 2845, Loss: 0.722025454044342, Final Batch Loss: 0.2566930949687958\n",
      "Epoch 2846, Loss: 0.7126561552286148, Final Batch Loss: 0.3018413782119751\n",
      "Epoch 2847, Loss: 0.6766716837882996, Final Batch Loss: 0.20922783017158508\n",
      "Epoch 2848, Loss: 0.7040166109800339, Final Batch Loss: 0.2969798743724823\n",
      "Epoch 2849, Loss: 0.5932847559452057, Final Batch Loss: 0.2206917256116867\n",
      "Epoch 2850, Loss: 0.5947589427232742, Final Batch Loss: 0.1625702679157257\n",
      "Epoch 2851, Loss: 0.6410797983407974, Final Batch Loss: 0.241101935505867\n",
      "Epoch 2852, Loss: 0.5334113240242004, Final Batch Loss: 0.16385386884212494\n",
      "Epoch 2853, Loss: 0.636580228805542, Final Batch Loss: 0.24068953096866608\n",
      "Epoch 2854, Loss: 0.699740394949913, Final Batch Loss: 0.22034458816051483\n",
      "Epoch 2855, Loss: 0.738688200712204, Final Batch Loss: 0.2914334237575531\n",
      "Epoch 2856, Loss: 0.5176786184310913, Final Batch Loss: 0.15405049920082092\n",
      "Epoch 2857, Loss: 0.64951092004776, Final Batch Loss: 0.22167670726776123\n",
      "Epoch 2858, Loss: 0.5566213577985764, Final Batch Loss: 0.2019622027873993\n",
      "Epoch 2859, Loss: 0.5799962729215622, Final Batch Loss: 0.2683952748775482\n",
      "Epoch 2860, Loss: 0.5424907207489014, Final Batch Loss: 0.13700278103351593\n",
      "Epoch 2861, Loss: 0.6492495983839035, Final Batch Loss: 0.2516968250274658\n",
      "Epoch 2862, Loss: 0.6058985441923141, Final Batch Loss: 0.16890574991703033\n",
      "Epoch 2863, Loss: 0.6664727628231049, Final Batch Loss: 0.20324021577835083\n",
      "Epoch 2864, Loss: 0.5391379445791245, Final Batch Loss: 0.16770121455192566\n",
      "Epoch 2865, Loss: 0.6398655623197556, Final Batch Loss: 0.2621914744377136\n",
      "Epoch 2866, Loss: 0.5775458514690399, Final Batch Loss: 0.13975445926189423\n",
      "Epoch 2867, Loss: 0.6391173750162125, Final Batch Loss: 0.19201761484146118\n",
      "Epoch 2868, Loss: 0.7261054068803787, Final Batch Loss: 0.2272229641675949\n",
      "Epoch 2869, Loss: 0.6849653869867325, Final Batch Loss: 0.1567908078432083\n",
      "Epoch 2870, Loss: 0.6671221405267715, Final Batch Loss: 0.23105387389659882\n",
      "Epoch 2871, Loss: 0.6583764851093292, Final Batch Loss: 0.21359778940677643\n",
      "Epoch 2872, Loss: 0.5604340881109238, Final Batch Loss: 0.1913950890302658\n",
      "Epoch 2873, Loss: 0.6646475195884705, Final Batch Loss: 0.2585909366607666\n",
      "Epoch 2874, Loss: 0.5548226833343506, Final Batch Loss: 0.17572040855884552\n",
      "Epoch 2875, Loss: 0.6364805549383163, Final Batch Loss: 0.22914792597293854\n",
      "Epoch 2876, Loss: 0.5349714756011963, Final Batch Loss: 0.17093190550804138\n",
      "Epoch 2877, Loss: 0.6181889921426773, Final Batch Loss: 0.1638820469379425\n",
      "Epoch 2878, Loss: 0.5891976952552795, Final Batch Loss: 0.22174790501594543\n",
      "Epoch 2879, Loss: 0.6036710441112518, Final Batch Loss: 0.1920970380306244\n",
      "Epoch 2880, Loss: 0.6051610261201859, Final Batch Loss: 0.15286855399608612\n",
      "Epoch 2881, Loss: 0.6881182193756104, Final Batch Loss: 0.21286916732788086\n",
      "Epoch 2882, Loss: 0.5855462700128555, Final Batch Loss: 0.1757740080356598\n",
      "Epoch 2883, Loss: 0.6069779843091965, Final Batch Loss: 0.17583094537258148\n",
      "Epoch 2884, Loss: 0.5500259399414062, Final Batch Loss: 0.17461465299129486\n",
      "Epoch 2885, Loss: 0.5406435430049896, Final Batch Loss: 0.15243113040924072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2886, Loss: 0.6182025820016861, Final Batch Loss: 0.1859690248966217\n",
      "Epoch 2887, Loss: 0.5713458508253098, Final Batch Loss: 0.18944229185581207\n",
      "Epoch 2888, Loss: 0.6113631576299667, Final Batch Loss: 0.24070146679878235\n",
      "Epoch 2889, Loss: 0.6118067502975464, Final Batch Loss: 0.1950417459011078\n",
      "Epoch 2890, Loss: 0.6095919013023376, Final Batch Loss: 0.16889743506908417\n",
      "Epoch 2891, Loss: 0.6449680924415588, Final Batch Loss: 0.21601587533950806\n",
      "Epoch 2892, Loss: 0.6050309240818024, Final Batch Loss: 0.2068716138601303\n",
      "Epoch 2893, Loss: 0.5107538253068924, Final Batch Loss: 0.18019221723079681\n",
      "Epoch 2894, Loss: 0.5784242302179337, Final Batch Loss: 0.1695987433195114\n",
      "Epoch 2895, Loss: 0.693726196885109, Final Batch Loss: 0.26679545640945435\n",
      "Epoch 2896, Loss: 0.5833477526903152, Final Batch Loss: 0.2507074475288391\n",
      "Epoch 2897, Loss: 0.573837473988533, Final Batch Loss: 0.19260798394680023\n",
      "Epoch 2898, Loss: 0.5153125375509262, Final Batch Loss: 0.1732700914144516\n",
      "Epoch 2899, Loss: 0.6521930992603302, Final Batch Loss: 0.20395581424236298\n",
      "Epoch 2900, Loss: 0.5170716047286987, Final Batch Loss: 0.1280258595943451\n",
      "Epoch 2901, Loss: 0.6302711218595505, Final Batch Loss: 0.2166583389043808\n",
      "Epoch 2902, Loss: 0.7156817764043808, Final Batch Loss: 0.21107251942157745\n",
      "Epoch 2903, Loss: 0.6345273405313492, Final Batch Loss: 0.23779402673244476\n",
      "Epoch 2904, Loss: 0.5828896015882492, Final Batch Loss: 0.2186620682477951\n",
      "Epoch 2905, Loss: 0.6936128735542297, Final Batch Loss: 0.2864501476287842\n",
      "Epoch 2906, Loss: 0.5657970607280731, Final Batch Loss: 0.13165034353733063\n",
      "Epoch 2907, Loss: 0.639016404747963, Final Batch Loss: 0.2105700522661209\n",
      "Epoch 2908, Loss: 0.6465121060609818, Final Batch Loss: 0.1767357587814331\n",
      "Epoch 2909, Loss: 0.6579194068908691, Final Batch Loss: 0.30225178599357605\n",
      "Epoch 2910, Loss: 0.6202222257852554, Final Batch Loss: 0.24310024082660675\n",
      "Epoch 2911, Loss: 0.6217622011899948, Final Batch Loss: 0.18827787041664124\n",
      "Epoch 2912, Loss: 0.5803875178098679, Final Batch Loss: 0.18661688268184662\n",
      "Epoch 2913, Loss: 0.5447567105293274, Final Batch Loss: 0.14569105207920074\n",
      "Epoch 2914, Loss: 0.6753263771533966, Final Batch Loss: 0.28988462686538696\n",
      "Epoch 2915, Loss: 0.5866626054048538, Final Batch Loss: 0.13890057802200317\n",
      "Epoch 2916, Loss: 0.6820956915616989, Final Batch Loss: 0.16111823916435242\n",
      "Epoch 2917, Loss: 0.5527157783508301, Final Batch Loss: 0.149214968085289\n",
      "Epoch 2918, Loss: 0.6539383828639984, Final Batch Loss: 0.27362099289894104\n",
      "Epoch 2919, Loss: 0.6785139292478561, Final Batch Loss: 0.2465319186449051\n",
      "Epoch 2920, Loss: 0.5987851917743683, Final Batch Loss: 0.20153875648975372\n",
      "Epoch 2921, Loss: 0.5778069645166397, Final Batch Loss: 0.1933998316526413\n",
      "Epoch 2922, Loss: 0.580283984541893, Final Batch Loss: 0.17623786628246307\n",
      "Epoch 2923, Loss: 0.5960621386766434, Final Batch Loss: 0.23307418823242188\n",
      "Epoch 2924, Loss: 0.5395256578922272, Final Batch Loss: 0.15280111134052277\n",
      "Epoch 2925, Loss: 0.5801528245210648, Final Batch Loss: 0.20411284267902374\n",
      "Epoch 2926, Loss: 0.6122492253780365, Final Batch Loss: 0.23137417435646057\n",
      "Epoch 2927, Loss: 0.5933960825204849, Final Batch Loss: 0.2515563368797302\n",
      "Epoch 2928, Loss: 0.5659570619463921, Final Batch Loss: 0.11206329613924026\n",
      "Epoch 2929, Loss: 0.57352215051651, Final Batch Loss: 0.16534094512462616\n",
      "Epoch 2930, Loss: 0.5691354274749756, Final Batch Loss: 0.23200753331184387\n",
      "Epoch 2931, Loss: 0.5042930692434311, Final Batch Loss: 0.14083297550678253\n",
      "Epoch 2932, Loss: 0.6449991762638092, Final Batch Loss: 0.20875392854213715\n",
      "Epoch 2933, Loss: 0.6482588648796082, Final Batch Loss: 0.20671488344669342\n",
      "Epoch 2934, Loss: 0.6467931717634201, Final Batch Loss: 0.22109900414943695\n",
      "Epoch 2935, Loss: 0.5658415257930756, Final Batch Loss: 0.20567263662815094\n",
      "Epoch 2936, Loss: 0.5341054350137711, Final Batch Loss: 0.17560571432113647\n",
      "Epoch 2937, Loss: 0.6512018889188766, Final Batch Loss: 0.2819673418998718\n",
      "Epoch 2938, Loss: 0.6816335767507553, Final Batch Loss: 0.1495380848646164\n",
      "Epoch 2939, Loss: 0.5499532222747803, Final Batch Loss: 0.17676784098148346\n",
      "Epoch 2940, Loss: 0.5268216282129288, Final Batch Loss: 0.16196323931217194\n",
      "Epoch 2941, Loss: 0.5756147801876068, Final Batch Loss: 0.19395676255226135\n",
      "Epoch 2942, Loss: 0.5848924815654755, Final Batch Loss: 0.17165885865688324\n",
      "Epoch 2943, Loss: 0.6295187473297119, Final Batch Loss: 0.17986227571964264\n",
      "Epoch 2944, Loss: 0.6257463544607162, Final Batch Loss: 0.21553508937358856\n",
      "Epoch 2945, Loss: 0.5849769562482834, Final Batch Loss: 0.23790483176708221\n",
      "Epoch 2946, Loss: 0.5451920330524445, Final Batch Loss: 0.20367196202278137\n",
      "Epoch 2947, Loss: 0.6273343563079834, Final Batch Loss: 0.2439441680908203\n",
      "Epoch 2948, Loss: 0.5176351964473724, Final Batch Loss: 0.17937126755714417\n",
      "Epoch 2949, Loss: 0.556283250451088, Final Batch Loss: 0.1519450545310974\n",
      "Epoch 2950, Loss: 0.536869466304779, Final Batch Loss: 0.18914207816123962\n",
      "Epoch 2951, Loss: 0.6071196794509888, Final Batch Loss: 0.17961467802524567\n",
      "Epoch 2952, Loss: 0.6463803797960281, Final Batch Loss: 0.1767023801803589\n",
      "Epoch 2953, Loss: 0.6334368139505386, Final Batch Loss: 0.23490148782730103\n",
      "Epoch 2954, Loss: 0.5778623223304749, Final Batch Loss: 0.1886845976114273\n",
      "Epoch 2955, Loss: 0.6161209642887115, Final Batch Loss: 0.24713116884231567\n",
      "Epoch 2956, Loss: 0.5402092337608337, Final Batch Loss: 0.19128485023975372\n",
      "Epoch 2957, Loss: 0.5091113597154617, Final Batch Loss: 0.1945122629404068\n",
      "Epoch 2958, Loss: 0.5357073396444321, Final Batch Loss: 0.1293826848268509\n",
      "Epoch 2959, Loss: 0.6154524832963943, Final Batch Loss: 0.18317197263240814\n",
      "Epoch 2960, Loss: 0.5006709694862366, Final Batch Loss: 0.16233521699905396\n",
      "Epoch 2961, Loss: 0.5182601660490036, Final Batch Loss: 0.19376704096794128\n",
      "Epoch 2962, Loss: 0.43841566145420074, Final Batch Loss: 0.1585850566625595\n",
      "Epoch 2963, Loss: 0.6074853390455246, Final Batch Loss: 0.2194550335407257\n",
      "Epoch 2964, Loss: 0.5704424977302551, Final Batch Loss: 0.20943313837051392\n",
      "Epoch 2965, Loss: 0.6465647965669632, Final Batch Loss: 0.2307840883731842\n",
      "Epoch 2966, Loss: 0.539768859744072, Final Batch Loss: 0.1745867282152176\n",
      "Epoch 2967, Loss: 0.6263580620288849, Final Batch Loss: 0.25794753432273865\n",
      "Epoch 2968, Loss: 0.5997349619865417, Final Batch Loss: 0.15923850238323212\n",
      "Epoch 2969, Loss: 0.5671752095222473, Final Batch Loss: 0.16458465158939362\n",
      "Epoch 2970, Loss: 0.7580516636371613, Final Batch Loss: 0.2739051580429077\n",
      "Epoch 2971, Loss: 0.7032641470432281, Final Batch Loss: 0.22420568764209747\n",
      "Epoch 2972, Loss: 0.5069763883948326, Final Batch Loss: 0.10392188280820847\n",
      "Epoch 2973, Loss: 0.6776387542486191, Final Batch Loss: 0.2377541959285736\n",
      "Epoch 2974, Loss: 0.6866608262062073, Final Batch Loss: 0.27202072739601135\n",
      "Epoch 2975, Loss: 0.5580329149961472, Final Batch Loss: 0.20730578899383545\n",
      "Epoch 2976, Loss: 0.660044327378273, Final Batch Loss: 0.21006138622760773\n",
      "Epoch 2977, Loss: 0.6423148363828659, Final Batch Loss: 0.21607084572315216\n",
      "Epoch 2978, Loss: 0.6539558172225952, Final Batch Loss: 0.23972606658935547\n",
      "Epoch 2979, Loss: 0.4846382439136505, Final Batch Loss: 0.1494331657886505\n",
      "Epoch 2980, Loss: 0.5723205655813217, Final Batch Loss: 0.23355001211166382\n",
      "Epoch 2981, Loss: 0.613600105047226, Final Batch Loss: 0.2098727524280548\n",
      "Epoch 2982, Loss: 0.6172769516706467, Final Batch Loss: 0.22464647889137268\n",
      "Epoch 2983, Loss: 0.617014929652214, Final Batch Loss: 0.21098628640174866\n",
      "Epoch 2984, Loss: 0.6597600281238556, Final Batch Loss: 0.1961478441953659\n",
      "Epoch 2985, Loss: 0.5180826410651207, Final Batch Loss: 0.11839386075735092\n",
      "Epoch 2986, Loss: 0.6705681532621384, Final Batch Loss: 0.22020071744918823\n",
      "Epoch 2987, Loss: 0.5560589730739594, Final Batch Loss: 0.17378665506839752\n",
      "Epoch 2988, Loss: 0.7001287192106247, Final Batch Loss: 0.280311644077301\n",
      "Epoch 2989, Loss: 0.5159965008497238, Final Batch Loss: 0.15389250218868256\n",
      "Epoch 2990, Loss: 0.7787212431430817, Final Batch Loss: 0.28504738211631775\n",
      "Epoch 2991, Loss: 0.5439753234386444, Final Batch Loss: 0.22217004001140594\n",
      "Epoch 2992, Loss: 0.6349535584449768, Final Batch Loss: 0.23996201157569885\n",
      "Epoch 2993, Loss: 0.5969915390014648, Final Batch Loss: 0.285429447889328\n",
      "Epoch 2994, Loss: 0.5770566761493683, Final Batch Loss: 0.215643972158432\n",
      "Epoch 2995, Loss: 0.5821320414543152, Final Batch Loss: 0.17303819954395294\n",
      "Epoch 2996, Loss: 0.7297124564647675, Final Batch Loss: 0.29687196016311646\n",
      "Epoch 2997, Loss: 0.6019912958145142, Final Batch Loss: 0.18514400720596313\n",
      "Epoch 2998, Loss: 0.5094752833247185, Final Batch Loss: 0.11471206694841385\n",
      "Epoch 2999, Loss: 0.7211913615465164, Final Batch Loss: 0.2950139343738556\n",
      "Epoch 3000, Loss: 0.5550623536109924, Final Batch Loss: 0.1477508246898651\n",
      "Epoch 3001, Loss: 0.5618075877428055, Final Batch Loss: 0.1544518768787384\n",
      "Epoch 3002, Loss: 0.511776477098465, Final Batch Loss: 0.13147462904453278\n",
      "Epoch 3003, Loss: 0.5678679794073105, Final Batch Loss: 0.21775761246681213\n",
      "Epoch 3004, Loss: 0.5850206017494202, Final Batch Loss: 0.19470149278640747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3005, Loss: 0.6032401770353317, Final Batch Loss: 0.19111944735050201\n",
      "Epoch 3006, Loss: 0.5817189365625381, Final Batch Loss: 0.16767558455467224\n",
      "Epoch 3007, Loss: 0.6162688881158829, Final Batch Loss: 0.25141099095344543\n",
      "Epoch 3008, Loss: 0.4985765069723129, Final Batch Loss: 0.1541912704706192\n",
      "Epoch 3009, Loss: 0.6214518845081329, Final Batch Loss: 0.22453537583351135\n",
      "Epoch 3010, Loss: 0.6500557959079742, Final Batch Loss: 0.14906956255435944\n",
      "Epoch 3011, Loss: 0.5998136699199677, Final Batch Loss: 0.24632340669631958\n",
      "Epoch 3012, Loss: 0.4950502812862396, Final Batch Loss: 0.14350871741771698\n",
      "Epoch 3013, Loss: 0.6274287700653076, Final Batch Loss: 0.22071777284145355\n",
      "Epoch 3014, Loss: 0.6200461685657501, Final Batch Loss: 0.2321564257144928\n",
      "Epoch 3015, Loss: 0.5526524633169174, Final Batch Loss: 0.1770578771829605\n",
      "Epoch 3016, Loss: 0.5322533249855042, Final Batch Loss: 0.135694220662117\n",
      "Epoch 3017, Loss: 0.47827789187431335, Final Batch Loss: 0.1436362862586975\n",
      "Epoch 3018, Loss: 0.6003251671791077, Final Batch Loss: 0.19692490994930267\n",
      "Epoch 3019, Loss: 0.6391185522079468, Final Batch Loss: 0.3518008589744568\n",
      "Epoch 3020, Loss: 0.4947420731186867, Final Batch Loss: 0.22284668684005737\n",
      "Epoch 3021, Loss: 0.597019612789154, Final Batch Loss: 0.2099711000919342\n",
      "Epoch 3022, Loss: 0.6638370305299759, Final Batch Loss: 0.1582251489162445\n",
      "Epoch 3023, Loss: 0.515690341591835, Final Batch Loss: 0.15966962277889252\n",
      "Epoch 3024, Loss: 0.4801572859287262, Final Batch Loss: 0.14573131501674652\n",
      "Epoch 3025, Loss: 0.7008860856294632, Final Batch Loss: 0.2281516194343567\n",
      "Epoch 3026, Loss: 0.6876452416181564, Final Batch Loss: 0.25780603289604187\n",
      "Epoch 3027, Loss: 0.653578132390976, Final Batch Loss: 0.24211497604846954\n",
      "Epoch 3028, Loss: 0.5723577588796616, Final Batch Loss: 0.20666740834712982\n",
      "Epoch 3029, Loss: 0.5046902149915695, Final Batch Loss: 0.16396647691726685\n",
      "Epoch 3030, Loss: 0.5724802166223526, Final Batch Loss: 0.18647915124893188\n",
      "Epoch 3031, Loss: 0.6335122585296631, Final Batch Loss: 0.2135888636112213\n",
      "Epoch 3032, Loss: 0.46498076617717743, Final Batch Loss: 0.11246545612812042\n",
      "Epoch 3033, Loss: 0.5540903359651566, Final Batch Loss: 0.2099495530128479\n",
      "Epoch 3034, Loss: 0.5596803426742554, Final Batch Loss: 0.19775868952274323\n",
      "Epoch 3035, Loss: 0.5662554949522018, Final Batch Loss: 0.15887804329395294\n",
      "Epoch 3036, Loss: 0.658122718334198, Final Batch Loss: 0.1802259087562561\n",
      "Epoch 3037, Loss: 0.633502870798111, Final Batch Loss: 0.25394704937934875\n",
      "Epoch 3038, Loss: 0.5446659028530121, Final Batch Loss: 0.1772061437368393\n",
      "Epoch 3039, Loss: 0.5790958255529404, Final Batch Loss: 0.20052975416183472\n",
      "Epoch 3040, Loss: 0.7479165345430374, Final Batch Loss: 0.3003600537776947\n",
      "Epoch 3041, Loss: 0.5860181897878647, Final Batch Loss: 0.22162514925003052\n",
      "Epoch 3042, Loss: 0.5490932166576385, Final Batch Loss: 0.20453926920890808\n",
      "Epoch 3043, Loss: 0.6264175474643707, Final Batch Loss: 0.1547682136297226\n",
      "Epoch 3044, Loss: 0.5368990302085876, Final Batch Loss: 0.16206733882427216\n",
      "Epoch 3045, Loss: 0.48359255492687225, Final Batch Loss: 0.1780461072921753\n",
      "Epoch 3046, Loss: 0.5880079865455627, Final Batch Loss: 0.15118923783302307\n",
      "Epoch 3047, Loss: 0.5748429596424103, Final Batch Loss: 0.2209128886461258\n",
      "Epoch 3048, Loss: 0.5440026968717575, Final Batch Loss: 0.196446031332016\n",
      "Epoch 3049, Loss: 0.5510554909706116, Final Batch Loss: 0.15816377103328705\n",
      "Epoch 3050, Loss: 0.5273584872484207, Final Batch Loss: 0.18845713138580322\n",
      "Epoch 3051, Loss: 0.5350931882858276, Final Batch Loss: 0.20973344147205353\n",
      "Epoch 3052, Loss: 0.6289552301168442, Final Batch Loss: 0.1512022167444229\n",
      "Epoch 3053, Loss: 0.6145612001419067, Final Batch Loss: 0.2403082698583603\n",
      "Epoch 3054, Loss: 0.5771775990724564, Final Batch Loss: 0.1993216723203659\n",
      "Epoch 3055, Loss: 0.5252373367547989, Final Batch Loss: 0.19141289591789246\n",
      "Epoch 3056, Loss: 0.5091976746916771, Final Batch Loss: 0.12497550994157791\n",
      "Epoch 3057, Loss: 0.5722442120313644, Final Batch Loss: 0.23228740692138672\n",
      "Epoch 3058, Loss: 0.5127094388008118, Final Batch Loss: 0.15563975274562836\n",
      "Epoch 3059, Loss: 0.60223788022995, Final Batch Loss: 0.2591543197631836\n",
      "Epoch 3060, Loss: 0.5915528386831284, Final Batch Loss: 0.1725558042526245\n",
      "Epoch 3061, Loss: 0.5495972633361816, Final Batch Loss: 0.18951410055160522\n",
      "Epoch 3062, Loss: 0.5870786607265472, Final Batch Loss: 0.18510036170482635\n",
      "Epoch 3063, Loss: 0.6671331822872162, Final Batch Loss: 0.2596912682056427\n",
      "Epoch 3064, Loss: 0.5693840235471725, Final Batch Loss: 0.16872693598270416\n",
      "Epoch 3065, Loss: 0.6396965980529785, Final Batch Loss: 0.24133825302124023\n",
      "Epoch 3066, Loss: 0.5776541978120804, Final Batch Loss: 0.2276538461446762\n",
      "Epoch 3067, Loss: 0.6347714364528656, Final Batch Loss: 0.17766432464122772\n",
      "Epoch 3068, Loss: 0.7144584506750107, Final Batch Loss: 0.2621893584728241\n",
      "Epoch 3069, Loss: 0.5551883280277252, Final Batch Loss: 0.18025396764278412\n",
      "Epoch 3070, Loss: 0.574146643280983, Final Batch Loss: 0.19402870535850525\n",
      "Epoch 3071, Loss: 0.5896041542291641, Final Batch Loss: 0.25044387578964233\n",
      "Epoch 3072, Loss: 0.6300981491804123, Final Batch Loss: 0.256853312253952\n",
      "Epoch 3073, Loss: 0.5824020057916641, Final Batch Loss: 0.16571278870105743\n",
      "Epoch 3074, Loss: 0.68000428378582, Final Batch Loss: 0.30227023363113403\n",
      "Epoch 3075, Loss: 0.5346036404371262, Final Batch Loss: 0.18651540577411652\n",
      "Epoch 3076, Loss: 0.6420686990022659, Final Batch Loss: 0.22390684485435486\n",
      "Epoch 3077, Loss: 0.6570972055196762, Final Batch Loss: 0.1822580099105835\n",
      "Epoch 3078, Loss: 0.5907061696052551, Final Batch Loss: 0.20315948128700256\n",
      "Epoch 3079, Loss: 0.5304999053478241, Final Batch Loss: 0.15988761186599731\n",
      "Epoch 3080, Loss: 0.5831293016672134, Final Batch Loss: 0.2641323506832123\n",
      "Epoch 3081, Loss: 0.5559830516576767, Final Batch Loss: 0.1324666142463684\n",
      "Epoch 3082, Loss: 0.48172110319137573, Final Batch Loss: 0.1672697216272354\n",
      "Epoch 3083, Loss: 0.5591854453086853, Final Batch Loss: 0.1783929020166397\n",
      "Epoch 3084, Loss: 0.5575123578310013, Final Batch Loss: 0.20293781161308289\n",
      "Epoch 3085, Loss: 0.5833850651979446, Final Batch Loss: 0.16371016204357147\n",
      "Epoch 3086, Loss: 0.6353756934404373, Final Batch Loss: 0.28871047496795654\n",
      "Epoch 3087, Loss: 0.6043308526277542, Final Batch Loss: 0.15830732882022858\n",
      "Epoch 3088, Loss: 0.5612712204456329, Final Batch Loss: 0.23114340007305145\n",
      "Epoch 3089, Loss: 0.47642579674720764, Final Batch Loss: 0.1392492651939392\n",
      "Epoch 3090, Loss: 0.518794447183609, Final Batch Loss: 0.13399334251880646\n",
      "Epoch 3091, Loss: 0.6167250573635101, Final Batch Loss: 0.24218706786632538\n",
      "Epoch 3092, Loss: 0.4733607620000839, Final Batch Loss: 0.15692497789859772\n",
      "Epoch 3093, Loss: 0.6031924784183502, Final Batch Loss: 0.18401919305324554\n",
      "Epoch 3094, Loss: 0.5563035607337952, Final Batch Loss: 0.2579292953014374\n",
      "Epoch 3095, Loss: 0.599875345826149, Final Batch Loss: 0.22127661108970642\n",
      "Epoch 3096, Loss: 0.5687336623668671, Final Batch Loss: 0.17795316874980927\n",
      "Epoch 3097, Loss: 0.4954017847776413, Final Batch Loss: 0.1430305689573288\n",
      "Epoch 3098, Loss: 0.6222761869430542, Final Batch Loss: 0.24128705263137817\n",
      "Epoch 3099, Loss: 0.48791123926639557, Final Batch Loss: 0.14582301676273346\n",
      "Epoch 3100, Loss: 0.4660458415746689, Final Batch Loss: 0.16247990727424622\n",
      "Epoch 3101, Loss: 0.6576534360647202, Final Batch Loss: 0.17898231744766235\n",
      "Epoch 3102, Loss: 0.49414973706007004, Final Batch Loss: 0.09857673197984695\n",
      "Epoch 3103, Loss: 0.5598702132701874, Final Batch Loss: 0.18264177441596985\n",
      "Epoch 3104, Loss: 0.4576938897371292, Final Batch Loss: 0.15061789751052856\n",
      "Epoch 3105, Loss: 0.4821223318576813, Final Batch Loss: 0.17388387024402618\n",
      "Epoch 3106, Loss: 0.6503896117210388, Final Batch Loss: 0.22992976009845734\n",
      "Epoch 3107, Loss: 0.5579629242420197, Final Batch Loss: 0.1770348697900772\n",
      "Epoch 3108, Loss: 0.69216188788414, Final Batch Loss: 0.2469291388988495\n",
      "Epoch 3109, Loss: 0.5401328653097153, Final Batch Loss: 0.17126402258872986\n",
      "Epoch 3110, Loss: 0.5399455577135086, Final Batch Loss: 0.14429086446762085\n",
      "Epoch 3111, Loss: 0.6778921037912369, Final Batch Loss: 0.3206559717655182\n",
      "Epoch 3112, Loss: 0.5174236595630646, Final Batch Loss: 0.16501052677631378\n",
      "Epoch 3113, Loss: 0.5505611002445221, Final Batch Loss: 0.21922567486763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3114, Loss: 0.5601495504379272, Final Batch Loss: 0.17250967025756836\n",
      "Epoch 3115, Loss: 0.5590023994445801, Final Batch Loss: 0.2748051881790161\n",
      "Epoch 3116, Loss: 0.6373803466558456, Final Batch Loss: 0.22926343977451324\n",
      "Epoch 3117, Loss: 0.5138902068138123, Final Batch Loss: 0.12555991113185883\n",
      "Epoch 3118, Loss: 0.6063959896564484, Final Batch Loss: 0.23826880753040314\n",
      "Epoch 3119, Loss: 0.6456785947084427, Final Batch Loss: 0.23202472925186157\n",
      "Epoch 3120, Loss: 0.5037553310394287, Final Batch Loss: 0.13438737392425537\n",
      "Epoch 3121, Loss: 0.5201957523822784, Final Batch Loss: 0.18890662491321564\n",
      "Epoch 3122, Loss: 0.5683938413858414, Final Batch Loss: 0.19081160426139832\n",
      "Epoch 3123, Loss: 0.5312375575304031, Final Batch Loss: 0.15634407103061676\n",
      "Epoch 3124, Loss: 0.5140338987112045, Final Batch Loss: 0.17229169607162476\n",
      "Epoch 3125, Loss: 0.5975111275911331, Final Batch Loss: 0.24375762045383453\n",
      "Epoch 3126, Loss: 0.5860400944948196, Final Batch Loss: 0.21292656660079956\n",
      "Epoch 3127, Loss: 0.5502475649118423, Final Batch Loss: 0.1664464920759201\n",
      "Epoch 3128, Loss: 0.47997988760471344, Final Batch Loss: 0.20882776379585266\n",
      "Epoch 3129, Loss: 0.46108806133270264, Final Batch Loss: 0.12916718423366547\n",
      "Epoch 3130, Loss: 0.49155616760253906, Final Batch Loss: 0.1690533310174942\n",
      "Epoch 3131, Loss: 0.47086425870656967, Final Batch Loss: 0.11610249429941177\n",
      "Epoch 3132, Loss: 0.700797900557518, Final Batch Loss: 0.3091905117034912\n",
      "Epoch 3133, Loss: 0.5166825205087662, Final Batch Loss: 0.1239970326423645\n",
      "Epoch 3134, Loss: 0.5890035927295685, Final Batch Loss: 0.20772358775138855\n",
      "Epoch 3135, Loss: 0.5576848536729813, Final Batch Loss: 0.1918768733739853\n",
      "Epoch 3136, Loss: 0.5387779027223587, Final Batch Loss: 0.19418004155158997\n",
      "Epoch 3137, Loss: 0.5362571775913239, Final Batch Loss: 0.16109545528888702\n",
      "Epoch 3138, Loss: 0.6218742579221725, Final Batch Loss: 0.22727914154529572\n",
      "Epoch 3139, Loss: 0.582975834608078, Final Batch Loss: 0.2214333564043045\n",
      "Epoch 3140, Loss: 0.5422084033489227, Final Batch Loss: 0.2423354536294937\n",
      "Epoch 3141, Loss: 0.5059742033481598, Final Batch Loss: 0.15415890514850616\n",
      "Epoch 3142, Loss: 0.5531109422445297, Final Batch Loss: 0.17659221589565277\n",
      "Epoch 3143, Loss: 0.5493704229593277, Final Batch Loss: 0.12784357368946075\n",
      "Epoch 3144, Loss: 0.5550137162208557, Final Batch Loss: 0.154750257730484\n",
      "Epoch 3145, Loss: 0.5349041074514389, Final Batch Loss: 0.18746207654476166\n",
      "Epoch 3146, Loss: 0.5727726072072983, Final Batch Loss: 0.1400301605463028\n",
      "Epoch 3147, Loss: 0.5779104232788086, Final Batch Loss: 0.22045756876468658\n",
      "Epoch 3148, Loss: 0.6040240377187729, Final Batch Loss: 0.2156781256198883\n",
      "Epoch 3149, Loss: 0.5060767978429794, Final Batch Loss: 0.1772512048482895\n",
      "Epoch 3150, Loss: 0.5718141049146652, Final Batch Loss: 0.19292323291301727\n",
      "Epoch 3151, Loss: 0.6329885572195053, Final Batch Loss: 0.18947623670101166\n",
      "Epoch 3152, Loss: 0.48436189442873, Final Batch Loss: 0.11654741317033768\n",
      "Epoch 3153, Loss: 0.57456935942173, Final Batch Loss: 0.21723319590091705\n",
      "Epoch 3154, Loss: 0.504296138882637, Final Batch Loss: 0.17900297045707703\n",
      "Epoch 3155, Loss: 0.485428586602211, Final Batch Loss: 0.1406281739473343\n",
      "Epoch 3156, Loss: 0.7104795128107071, Final Batch Loss: 0.3417888581752777\n",
      "Epoch 3157, Loss: 0.4745752215385437, Final Batch Loss: 0.17215444147586823\n",
      "Epoch 3158, Loss: 0.591001108288765, Final Batch Loss: 0.17994654178619385\n",
      "Epoch 3159, Loss: 0.46977169066667557, Final Batch Loss: 0.12043903023004532\n",
      "Epoch 3160, Loss: 0.5200570449233055, Final Batch Loss: 0.1186254695057869\n",
      "Epoch 3161, Loss: 0.4927051141858101, Final Batch Loss: 0.17958559095859528\n",
      "Epoch 3162, Loss: 0.5082428753376007, Final Batch Loss: 0.13783232867717743\n",
      "Epoch 3163, Loss: 0.5729403644800186, Final Batch Loss: 0.1806560903787613\n",
      "Epoch 3164, Loss: 0.4780830219388008, Final Batch Loss: 0.11824134737253189\n",
      "Epoch 3165, Loss: 0.5488796681165695, Final Batch Loss: 0.16277149319648743\n",
      "Epoch 3166, Loss: 0.5706805288791656, Final Batch Loss: 0.18188659846782684\n",
      "Epoch 3167, Loss: 0.577275350689888, Final Batch Loss: 0.27124449610710144\n",
      "Epoch 3168, Loss: 0.4363635778427124, Final Batch Loss: 0.12969030439853668\n",
      "Epoch 3169, Loss: 0.4745916575193405, Final Batch Loss: 0.1867196261882782\n",
      "Epoch 3170, Loss: 0.5398434698581696, Final Batch Loss: 0.1433180868625641\n",
      "Epoch 3171, Loss: 0.604847326874733, Final Batch Loss: 0.20361238718032837\n",
      "Epoch 3172, Loss: 0.481771856546402, Final Batch Loss: 0.18301570415496826\n",
      "Epoch 3173, Loss: 0.5118858963251114, Final Batch Loss: 0.2072879821062088\n",
      "Epoch 3174, Loss: 0.4332113191485405, Final Batch Loss: 0.12437557429075241\n",
      "Epoch 3175, Loss: 0.6077049821615219, Final Batch Loss: 0.22444425523281097\n",
      "Epoch 3176, Loss: 0.6118907332420349, Final Batch Loss: 0.2719224989414215\n",
      "Epoch 3177, Loss: 0.48598627746105194, Final Batch Loss: 0.12737660109996796\n",
      "Epoch 3178, Loss: 0.7494175881147385, Final Batch Loss: 0.29047891497612\n",
      "Epoch 3179, Loss: 0.6336674094200134, Final Batch Loss: 0.26942604780197144\n",
      "Epoch 3180, Loss: 0.5308525562286377, Final Batch Loss: 0.161577969789505\n",
      "Epoch 3181, Loss: 0.5239186435937881, Final Batch Loss: 0.20917847752571106\n",
      "Epoch 3182, Loss: 0.6325079947710037, Final Batch Loss: 0.20555411279201508\n",
      "Epoch 3183, Loss: 0.5079204142093658, Final Batch Loss: 0.21299220621585846\n",
      "Epoch 3184, Loss: 0.5759124308824539, Final Batch Loss: 0.22620487213134766\n",
      "Epoch 3185, Loss: 0.5911570489406586, Final Batch Loss: 0.17987287044525146\n",
      "Epoch 3186, Loss: 0.4732966721057892, Final Batch Loss: 0.13436494767665863\n",
      "Epoch 3187, Loss: 0.5401367992162704, Final Batch Loss: 0.17856712639331818\n",
      "Epoch 3188, Loss: 0.5060337632894516, Final Batch Loss: 0.1475154012441635\n",
      "Epoch 3189, Loss: 0.49105748534202576, Final Batch Loss: 0.14809788763523102\n",
      "Epoch 3190, Loss: 0.5307491570711136, Final Batch Loss: 0.15652573108673096\n",
      "Epoch 3191, Loss: 0.4957524463534355, Final Batch Loss: 0.11020305007696152\n",
      "Epoch 3192, Loss: 0.43496839702129364, Final Batch Loss: 0.11388468742370605\n",
      "Epoch 3193, Loss: 0.7158391028642654, Final Batch Loss: 0.3178218901157379\n",
      "Epoch 3194, Loss: 0.5147442743182182, Final Batch Loss: 0.12282391637563705\n",
      "Epoch 3195, Loss: 0.4838305115699768, Final Batch Loss: 0.15943239629268646\n",
      "Epoch 3196, Loss: 0.7001103907823563, Final Batch Loss: 0.32579416036605835\n",
      "Epoch 3197, Loss: 0.5360969752073288, Final Batch Loss: 0.1465836614370346\n",
      "Epoch 3198, Loss: 0.5648975968360901, Final Batch Loss: 0.1460529863834381\n",
      "Epoch 3199, Loss: 0.6401730626821518, Final Batch Loss: 0.2127208709716797\n",
      "Epoch 3200, Loss: 0.537511795759201, Final Batch Loss: 0.1464199274778366\n",
      "Epoch 3201, Loss: 0.5439641252160072, Final Batch Loss: 0.26309964060783386\n",
      "Epoch 3202, Loss: 0.5898914933204651, Final Batch Loss: 0.19316533207893372\n",
      "Epoch 3203, Loss: 0.5728430896997452, Final Batch Loss: 0.19380110502243042\n",
      "Epoch 3204, Loss: 0.5561105161905289, Final Batch Loss: 0.16508765518665314\n",
      "Epoch 3205, Loss: 0.57676962018013, Final Batch Loss: 0.17886094748973846\n",
      "Epoch 3206, Loss: 0.4482232853770256, Final Batch Loss: 0.1249232217669487\n",
      "Epoch 3207, Loss: 0.5073035359382629, Final Batch Loss: 0.20202575623989105\n",
      "Epoch 3208, Loss: 0.5292375832796097, Final Batch Loss: 0.23601900041103363\n",
      "Epoch 3209, Loss: 0.518877312541008, Final Batch Loss: 0.1655348390340805\n",
      "Epoch 3210, Loss: 0.5269916504621506, Final Batch Loss: 0.1375156044960022\n",
      "Epoch 3211, Loss: 0.6019204407930374, Final Batch Loss: 0.09265273809432983\n",
      "Epoch 3212, Loss: 0.5906022787094116, Final Batch Loss: 0.18504567444324493\n",
      "Epoch 3213, Loss: 0.513571985065937, Final Batch Loss: 0.11628466099500656\n",
      "Epoch 3214, Loss: 0.5450014621019363, Final Batch Loss: 0.13250437378883362\n",
      "Epoch 3215, Loss: 0.45129089057445526, Final Batch Loss: 0.1495857536792755\n",
      "Epoch 3216, Loss: 0.42396780848503113, Final Batch Loss: 0.12917613983154297\n",
      "Epoch 3217, Loss: 0.5568788945674896, Final Batch Loss: 0.2262127548456192\n",
      "Epoch 3218, Loss: 0.4635893404483795, Final Batch Loss: 0.1511211395263672\n",
      "Epoch 3219, Loss: 0.5027086138725281, Final Batch Loss: 0.12860701978206635\n",
      "Epoch 3220, Loss: 0.4960261806845665, Final Batch Loss: 0.10279203206300735\n",
      "Epoch 3221, Loss: 0.5194430649280548, Final Batch Loss: 0.1439577341079712\n",
      "Epoch 3222, Loss: 0.5688448697328568, Final Batch Loss: 0.1994737982749939\n",
      "Epoch 3223, Loss: 0.5504955947399139, Final Batch Loss: 0.19416312873363495\n",
      "Epoch 3224, Loss: 0.5286441072821617, Final Batch Loss: 0.10823420435190201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3225, Loss: 0.5855678468942642, Final Batch Loss: 0.18226896226406097\n",
      "Epoch 3226, Loss: 0.46378307044506073, Final Batch Loss: 0.1219828873872757\n",
      "Epoch 3227, Loss: 0.5513681620359421, Final Batch Loss: 0.24725301563739777\n",
      "Epoch 3228, Loss: 0.49416668713092804, Final Batch Loss: 0.14196452498435974\n",
      "Epoch 3229, Loss: 0.6313038617372513, Final Batch Loss: 0.2517279386520386\n",
      "Epoch 3230, Loss: 0.5703844204545021, Final Batch Loss: 0.22769640386104584\n",
      "Epoch 3231, Loss: 0.5908396244049072, Final Batch Loss: 0.2002304643392563\n",
      "Epoch 3232, Loss: 0.5675975382328033, Final Batch Loss: 0.1758955419063568\n",
      "Epoch 3233, Loss: 0.5669505298137665, Final Batch Loss: 0.26387009024620056\n",
      "Epoch 3234, Loss: 0.5697436630725861, Final Batch Loss: 0.2523976266384125\n",
      "Epoch 3235, Loss: 0.6249376386404037, Final Batch Loss: 0.19437441229820251\n",
      "Epoch 3236, Loss: 0.5872086584568024, Final Batch Loss: 0.21606552600860596\n",
      "Epoch 3237, Loss: 0.4642082266509533, Final Batch Loss: 0.06193571910262108\n",
      "Epoch 3238, Loss: 0.5760764181613922, Final Batch Loss: 0.18002934753894806\n",
      "Epoch 3239, Loss: 0.5884840488433838, Final Batch Loss: 0.2772614061832428\n",
      "Epoch 3240, Loss: 0.5004675835371017, Final Batch Loss: 0.12996070086956024\n",
      "Epoch 3241, Loss: 0.5669025331735611, Final Batch Loss: 0.17017218470573425\n",
      "Epoch 3242, Loss: 0.5981364697217941, Final Batch Loss: 0.2933503985404968\n",
      "Epoch 3243, Loss: 0.6228755116462708, Final Batch Loss: 0.1903703808784485\n",
      "Epoch 3244, Loss: 0.644622191786766, Final Batch Loss: 0.2248712182044983\n",
      "Epoch 3245, Loss: 0.5772275924682617, Final Batch Loss: 0.2112606018781662\n",
      "Epoch 3246, Loss: 0.6183087974786758, Final Batch Loss: 0.2518712878227234\n",
      "Epoch 3247, Loss: 0.5894595235586166, Final Batch Loss: 0.18906837701797485\n",
      "Epoch 3248, Loss: 0.5197448283433914, Final Batch Loss: 0.1526622772216797\n",
      "Epoch 3249, Loss: 0.5559534281492233, Final Batch Loss: 0.21939803659915924\n",
      "Epoch 3250, Loss: 0.60554139316082, Final Batch Loss: 0.22443132102489471\n",
      "Epoch 3251, Loss: 0.5690679848194122, Final Batch Loss: 0.2157619744539261\n",
      "Epoch 3252, Loss: 0.5420399755239487, Final Batch Loss: 0.1932990700006485\n",
      "Epoch 3253, Loss: 0.6344739496707916, Final Batch Loss: 0.23538149893283844\n",
      "Epoch 3254, Loss: 0.5042998492717743, Final Batch Loss: 0.17003659904003143\n",
      "Epoch 3255, Loss: 0.5509371906518936, Final Batch Loss: 0.19738972187042236\n",
      "Epoch 3256, Loss: 0.5008702874183655, Final Batch Loss: 0.1526375412940979\n",
      "Epoch 3257, Loss: 0.42939209938049316, Final Batch Loss: 0.1210581511259079\n",
      "Epoch 3258, Loss: 0.5428572744131088, Final Batch Loss: 0.21607309579849243\n",
      "Epoch 3259, Loss: 0.5821620300412178, Final Batch Loss: 0.10213574022054672\n",
      "Epoch 3260, Loss: 0.4382280558347702, Final Batch Loss: 0.12041088938713074\n",
      "Epoch 3261, Loss: 0.6176597774028778, Final Batch Loss: 0.1828373670578003\n",
      "Epoch 3262, Loss: 0.6169914603233337, Final Batch Loss: 0.22900518774986267\n",
      "Epoch 3263, Loss: 0.5424383580684662, Final Batch Loss: 0.13895168900489807\n",
      "Epoch 3264, Loss: 0.522494837641716, Final Batch Loss: 0.16054244339466095\n",
      "Epoch 3265, Loss: 0.5065464228391647, Final Batch Loss: 0.16332878172397614\n",
      "Epoch 3266, Loss: 0.5285459160804749, Final Batch Loss: 0.20859920978546143\n",
      "Epoch 3267, Loss: 0.5452992618083954, Final Batch Loss: 0.2551696002483368\n",
      "Epoch 3268, Loss: 0.48285044729709625, Final Batch Loss: 0.14524999260902405\n",
      "Epoch 3269, Loss: 0.5554460883140564, Final Batch Loss: 0.18467746675014496\n",
      "Epoch 3270, Loss: 0.5469405055046082, Final Batch Loss: 0.0988934338092804\n",
      "Epoch 3271, Loss: 0.5006008595228195, Final Batch Loss: 0.16697360575199127\n",
      "Epoch 3272, Loss: 0.5960386693477631, Final Batch Loss: 0.2435256987810135\n",
      "Epoch 3273, Loss: 0.6116279661655426, Final Batch Loss: 0.21785859763622284\n",
      "Epoch 3274, Loss: 0.46486788988113403, Final Batch Loss: 0.14890924096107483\n",
      "Epoch 3275, Loss: 0.5664681941270828, Final Batch Loss: 0.18025052547454834\n",
      "Epoch 3276, Loss: 0.5268641710281372, Final Batch Loss: 0.1950165182352066\n",
      "Epoch 3277, Loss: 0.5496083647012711, Final Batch Loss: 0.24726428091526031\n",
      "Epoch 3278, Loss: 0.4919556677341461, Final Batch Loss: 0.13237455487251282\n",
      "Epoch 3279, Loss: 0.5272775143384933, Final Batch Loss: 0.19671326875686646\n",
      "Epoch 3280, Loss: 0.615917444229126, Final Batch Loss: 0.2590707838535309\n",
      "Epoch 3281, Loss: 0.5093413144350052, Final Batch Loss: 0.17741595208644867\n",
      "Epoch 3282, Loss: 0.5481257438659668, Final Batch Loss: 0.20709256827831268\n",
      "Epoch 3283, Loss: 0.5142073035240173, Final Batch Loss: 0.18483096361160278\n",
      "Epoch 3284, Loss: 0.5217387452721596, Final Batch Loss: 0.11797144263982773\n",
      "Epoch 3285, Loss: 0.46742138266563416, Final Batch Loss: 0.13787415623664856\n",
      "Epoch 3286, Loss: 0.5505648404359818, Final Batch Loss: 0.1621435433626175\n",
      "Epoch 3287, Loss: 0.49382418394088745, Final Batch Loss: 0.13326695561408997\n",
      "Epoch 3288, Loss: 0.4578002840280533, Final Batch Loss: 0.12778142094612122\n",
      "Epoch 3289, Loss: 0.5259038060903549, Final Batch Loss: 0.17786531150341034\n",
      "Epoch 3290, Loss: 0.5301418304443359, Final Batch Loss: 0.17985641956329346\n",
      "Epoch 3291, Loss: 0.570075511932373, Final Batch Loss: 0.23729193210601807\n",
      "Epoch 3292, Loss: 0.4371299743652344, Final Batch Loss: 0.15096765756607056\n",
      "Epoch 3293, Loss: 0.6193768531084061, Final Batch Loss: 0.21585169434547424\n",
      "Epoch 3294, Loss: 0.5231729224324226, Final Batch Loss: 0.11951424926519394\n",
      "Epoch 3295, Loss: 0.5086470544338226, Final Batch Loss: 0.2002125382423401\n",
      "Epoch 3296, Loss: 0.50751693546772, Final Batch Loss: 0.1442870944738388\n",
      "Epoch 3297, Loss: 0.5646659433841705, Final Batch Loss: 0.2949622571468353\n",
      "Epoch 3298, Loss: 0.572664201259613, Final Batch Loss: 0.21827806532382965\n",
      "Epoch 3299, Loss: 0.5563846230506897, Final Batch Loss: 0.1890297383069992\n",
      "Epoch 3300, Loss: 0.45685213059186935, Final Batch Loss: 0.14256636798381805\n",
      "Epoch 3301, Loss: 0.5415032729506493, Final Batch Loss: 0.11641428619623184\n",
      "Epoch 3302, Loss: 0.45853928476572037, Final Batch Loss: 0.1574457585811615\n",
      "Epoch 3303, Loss: 0.43499191105365753, Final Batch Loss: 0.13361401855945587\n",
      "Epoch 3304, Loss: 0.6494264900684357, Final Batch Loss: 0.28200966119766235\n",
      "Epoch 3305, Loss: 0.5508645549416542, Final Batch Loss: 0.10433240979909897\n",
      "Epoch 3306, Loss: 0.5275622308254242, Final Batch Loss: 0.2111920416355133\n",
      "Epoch 3307, Loss: 0.572073444724083, Final Batch Loss: 0.19631770253181458\n",
      "Epoch 3308, Loss: 0.5378538519144058, Final Batch Loss: 0.17438767850399017\n",
      "Epoch 3309, Loss: 0.6697273701429367, Final Batch Loss: 0.1460643857717514\n",
      "Epoch 3310, Loss: 0.5354117900133133, Final Batch Loss: 0.18444953858852386\n",
      "Epoch 3311, Loss: 0.5764980018138885, Final Batch Loss: 0.15869024395942688\n",
      "Epoch 3312, Loss: 0.47545126080513, Final Batch Loss: 0.12876981496810913\n",
      "Epoch 3313, Loss: 0.5955504924058914, Final Batch Loss: 0.22806969285011292\n",
      "Epoch 3314, Loss: 0.47780777513980865, Final Batch Loss: 0.12786272168159485\n",
      "Epoch 3315, Loss: 0.49503718316555023, Final Batch Loss: 0.19051875174045563\n",
      "Epoch 3316, Loss: 0.47847069799900055, Final Batch Loss: 0.1672108918428421\n",
      "Epoch 3317, Loss: 0.5464340895414352, Final Batch Loss: 0.1703738272190094\n",
      "Epoch 3318, Loss: 0.49958762526512146, Final Batch Loss: 0.1529884785413742\n",
      "Epoch 3319, Loss: 0.46614638715982437, Final Batch Loss: 0.09925179928541183\n",
      "Epoch 3320, Loss: 0.5108251124620438, Final Batch Loss: 0.1764482706785202\n",
      "Epoch 3321, Loss: 0.517763614654541, Final Batch Loss: 0.1544685959815979\n",
      "Epoch 3322, Loss: 0.4340031296014786, Final Batch Loss: 0.12483717501163483\n",
      "Epoch 3323, Loss: 0.568110778927803, Final Batch Loss: 0.15676583349704742\n",
      "Epoch 3324, Loss: 0.4925101548433304, Final Batch Loss: 0.1549040526151657\n",
      "Epoch 3325, Loss: 0.489139661192894, Final Batch Loss: 0.19000014662742615\n",
      "Epoch 3326, Loss: 0.5648645460605621, Final Batch Loss: 0.21332748234272003\n",
      "Epoch 3327, Loss: 0.48579464107751846, Final Batch Loss: 0.10821922868490219\n",
      "Epoch 3328, Loss: 0.6153599917888641, Final Batch Loss: 0.22023212909698486\n",
      "Epoch 3329, Loss: 0.5615714937448502, Final Batch Loss: 0.196430504322052\n",
      "Epoch 3330, Loss: 0.7035346776247025, Final Batch Loss: 0.30577439069747925\n",
      "Epoch 3331, Loss: 0.5829377621412277, Final Batch Loss: 0.16669778525829315\n",
      "Epoch 3332, Loss: 0.5427553355693817, Final Batch Loss: 0.23595094680786133\n",
      "Epoch 3333, Loss: 0.5091433972120285, Final Batch Loss: 0.20545263588428497\n",
      "Epoch 3334, Loss: 0.5999104976654053, Final Batch Loss: 0.2568448483943939\n",
      "Epoch 3335, Loss: 0.5265795290470123, Final Batch Loss: 0.15532153844833374\n",
      "Epoch 3336, Loss: 0.558036595582962, Final Batch Loss: 0.19606848061084747\n",
      "Epoch 3337, Loss: 0.563706561923027, Final Batch Loss: 0.17938712239265442\n",
      "Epoch 3338, Loss: 0.5000876486301422, Final Batch Loss: 0.1982172131538391\n",
      "Epoch 3339, Loss: 0.5652498602867126, Final Batch Loss: 0.24716605246067047\n",
      "Epoch 3340, Loss: 0.576184555888176, Final Batch Loss: 0.1735232025384903\n",
      "Epoch 3341, Loss: 0.5364038348197937, Final Batch Loss: 0.16352668404579163\n",
      "Epoch 3342, Loss: 0.4737747311592102, Final Batch Loss: 0.12343229353427887\n",
      "Epoch 3343, Loss: 0.5095827877521515, Final Batch Loss: 0.14645543694496155\n",
      "Epoch 3344, Loss: 0.5215093195438385, Final Batch Loss: 0.21077801287174225\n",
      "Epoch 3345, Loss: 0.5299561619758606, Final Batch Loss: 0.2031341940164566\n",
      "Epoch 3346, Loss: 0.6458291262388229, Final Batch Loss: 0.28188520669937134\n",
      "Epoch 3347, Loss: 0.5821158289909363, Final Batch Loss: 0.18509440124034882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3348, Loss: 0.5028083026409149, Final Batch Loss: 0.1533428579568863\n",
      "Epoch 3349, Loss: 0.49957260489463806, Final Batch Loss: 0.19959264993667603\n",
      "Epoch 3350, Loss: 0.7305419147014618, Final Batch Loss: 0.2612849771976471\n",
      "Epoch 3351, Loss: 0.5402621775865555, Final Batch Loss: 0.18323145806789398\n",
      "Epoch 3352, Loss: 0.48173483461141586, Final Batch Loss: 0.16079260408878326\n",
      "Epoch 3353, Loss: 0.4706323593854904, Final Batch Loss: 0.13531270623207092\n",
      "Epoch 3354, Loss: 0.47186969220638275, Final Batch Loss: 0.18070392310619354\n",
      "Epoch 3355, Loss: 0.47029490768909454, Final Batch Loss: 0.13406485319137573\n",
      "Epoch 3356, Loss: 0.4868081882596016, Final Batch Loss: 0.11547961086034775\n",
      "Epoch 3357, Loss: 0.652227982878685, Final Batch Loss: 0.2590768039226532\n",
      "Epoch 3358, Loss: 0.5811456888914108, Final Batch Loss: 0.2612132728099823\n",
      "Epoch 3359, Loss: 0.4856712222099304, Final Batch Loss: 0.1407407969236374\n",
      "Epoch 3360, Loss: 0.5498418211936951, Final Batch Loss: 0.23329582810401917\n",
      "Epoch 3361, Loss: 0.5940249115228653, Final Batch Loss: 0.2419268786907196\n",
      "Epoch 3362, Loss: 0.5471583008766174, Final Batch Loss: 0.13799497485160828\n",
      "Epoch 3363, Loss: 0.5306040048599243, Final Batch Loss: 0.18271860480308533\n",
      "Epoch 3364, Loss: 0.4641530439257622, Final Batch Loss: 0.20171883702278137\n",
      "Epoch 3365, Loss: 0.499906562268734, Final Batch Loss: 0.15532582998275757\n",
      "Epoch 3366, Loss: 0.5282299742102623, Final Batch Loss: 0.12316098064184189\n",
      "Epoch 3367, Loss: 0.6154209673404694, Final Batch Loss: 0.2855702042579651\n",
      "Epoch 3368, Loss: 0.44335266947746277, Final Batch Loss: 0.1548556387424469\n",
      "Epoch 3369, Loss: 0.5975728332996368, Final Batch Loss: 0.17021530866622925\n",
      "Epoch 3370, Loss: 0.46442612260580063, Final Batch Loss: 0.12733477354049683\n",
      "Epoch 3371, Loss: 0.4378087967634201, Final Batch Loss: 0.14594897627830505\n",
      "Epoch 3372, Loss: 0.4991975575685501, Final Batch Loss: 0.1466962695121765\n",
      "Epoch 3373, Loss: 0.415522925555706, Final Batch Loss: 0.11907079070806503\n",
      "Epoch 3374, Loss: 0.5091772526502609, Final Batch Loss: 0.14860396087169647\n",
      "Epoch 3375, Loss: 0.40668249875307083, Final Batch Loss: 0.16101403534412384\n",
      "Epoch 3376, Loss: 0.5331450998783112, Final Batch Loss: 0.15343619883060455\n",
      "Epoch 3377, Loss: 0.6265523880720139, Final Batch Loss: 0.3203340470790863\n",
      "Epoch 3378, Loss: 0.5630704313516617, Final Batch Loss: 0.19194190204143524\n",
      "Epoch 3379, Loss: 0.44661541283130646, Final Batch Loss: 0.17971473932266235\n",
      "Epoch 3380, Loss: 0.528279721736908, Final Batch Loss: 0.1689167618751526\n",
      "Epoch 3381, Loss: 0.5848427712917328, Final Batch Loss: 0.1573781967163086\n",
      "Epoch 3382, Loss: 0.5567629933357239, Final Batch Loss: 0.18557395040988922\n",
      "Epoch 3383, Loss: 0.5858807861804962, Final Batch Loss: 0.15546320378780365\n",
      "Epoch 3384, Loss: 0.5690308511257172, Final Batch Loss: 0.21267323195934296\n",
      "Epoch 3385, Loss: 0.3849627822637558, Final Batch Loss: 0.08786021173000336\n",
      "Epoch 3386, Loss: 0.4206749349832535, Final Batch Loss: 0.07094931602478027\n",
      "Epoch 3387, Loss: 0.47432565689086914, Final Batch Loss: 0.1505766361951828\n",
      "Epoch 3388, Loss: 0.5525061935186386, Final Batch Loss: 0.267304390668869\n",
      "Epoch 3389, Loss: 0.4878230392932892, Final Batch Loss: 0.16191957890987396\n",
      "Epoch 3390, Loss: 0.48907627165317535, Final Batch Loss: 0.17047040164470673\n",
      "Epoch 3391, Loss: 0.432465136051178, Final Batch Loss: 0.12586307525634766\n",
      "Epoch 3392, Loss: 0.5197106972336769, Final Batch Loss: 0.11187496036291122\n",
      "Epoch 3393, Loss: 0.6893104016780853, Final Batch Loss: 0.33788472414016724\n",
      "Epoch 3394, Loss: 0.5862077921628952, Final Batch Loss: 0.16520246863365173\n",
      "Epoch 3395, Loss: 0.528785914182663, Final Batch Loss: 0.20523782074451447\n",
      "Epoch 3396, Loss: 0.5293980985879898, Final Batch Loss: 0.12534646689891815\n",
      "Epoch 3397, Loss: 0.47345608472824097, Final Batch Loss: 0.13899289071559906\n",
      "Epoch 3398, Loss: 0.5712826699018478, Final Batch Loss: 0.2581857740879059\n",
      "Epoch 3399, Loss: 0.4935483783483505, Final Batch Loss: 0.15038760006427765\n",
      "Epoch 3400, Loss: 0.5119023025035858, Final Batch Loss: 0.12631572782993317\n",
      "Epoch 3401, Loss: 0.48568885028362274, Final Batch Loss: 0.1814817488193512\n",
      "Epoch 3402, Loss: 0.5881720930337906, Final Batch Loss: 0.24798358976840973\n",
      "Epoch 3403, Loss: 0.620707705616951, Final Batch Loss: 0.21853864192962646\n",
      "Epoch 3404, Loss: 0.5537627041339874, Final Batch Loss: 0.17541183531284332\n",
      "Epoch 3405, Loss: 0.4359391778707504, Final Batch Loss: 0.14406758546829224\n",
      "Epoch 3406, Loss: 0.5019866824150085, Final Batch Loss: 0.1437603086233139\n",
      "Epoch 3407, Loss: 0.5454075634479523, Final Batch Loss: 0.1865086406469345\n",
      "Epoch 3408, Loss: 0.4829553812742233, Final Batch Loss: 0.1899033933877945\n",
      "Epoch 3409, Loss: 0.509423665702343, Final Batch Loss: 0.2050745189189911\n",
      "Epoch 3410, Loss: 0.5048387497663498, Final Batch Loss: 0.1559847891330719\n",
      "Epoch 3411, Loss: 0.47148701548576355, Final Batch Loss: 0.10466308891773224\n",
      "Epoch 3412, Loss: 0.5410965234041214, Final Batch Loss: 0.12910526990890503\n",
      "Epoch 3413, Loss: 0.45551227033138275, Final Batch Loss: 0.1267113834619522\n",
      "Epoch 3414, Loss: 0.6732757836580276, Final Batch Loss: 0.2295447140932083\n",
      "Epoch 3415, Loss: 0.5451138615608215, Final Batch Loss: 0.2041075974702835\n",
      "Epoch 3416, Loss: 0.5297040343284607, Final Batch Loss: 0.20783235132694244\n",
      "Epoch 3417, Loss: 0.5912735313177109, Final Batch Loss: 0.25440138578414917\n",
      "Epoch 3418, Loss: 0.5687538385391235, Final Batch Loss: 0.16523323953151703\n",
      "Epoch 3419, Loss: 0.6116188764572144, Final Batch Loss: 0.23137043416500092\n",
      "Epoch 3420, Loss: 0.5787869542837143, Final Batch Loss: 0.1438622623682022\n",
      "Epoch 3421, Loss: 0.6741043627262115, Final Batch Loss: 0.283625990152359\n",
      "Epoch 3422, Loss: 0.4770941138267517, Final Batch Loss: 0.1461711972951889\n",
      "Epoch 3423, Loss: 0.5657721310853958, Final Batch Loss: 0.19283916056156158\n",
      "Epoch 3424, Loss: 0.7260280400514603, Final Batch Loss: 0.28881099820137024\n",
      "Epoch 3425, Loss: 0.5527287423610687, Final Batch Loss: 0.21226471662521362\n",
      "Epoch 3426, Loss: 0.6623896509408951, Final Batch Loss: 0.22052820026874542\n",
      "Epoch 3427, Loss: 0.5050530433654785, Final Batch Loss: 0.13697770237922668\n",
      "Epoch 3428, Loss: 0.5863148123025894, Final Batch Loss: 0.1870712786912918\n",
      "Epoch 3429, Loss: 0.6009871363639832, Final Batch Loss: 0.19966156780719757\n",
      "Epoch 3430, Loss: 0.5854807645082474, Final Batch Loss: 0.25045424699783325\n",
      "Epoch 3431, Loss: 0.4950947016477585, Final Batch Loss: 0.13465511798858643\n",
      "Epoch 3432, Loss: 0.5339631289243698, Final Batch Loss: 0.17102405428886414\n",
      "Epoch 3433, Loss: 0.35682471096515656, Final Batch Loss: 0.1090860366821289\n",
      "Epoch 3434, Loss: 0.5174960792064667, Final Batch Loss: 0.15140892565250397\n",
      "Epoch 3435, Loss: 0.4720567390322685, Final Batch Loss: 0.09040742367506027\n",
      "Epoch 3436, Loss: 0.5676157623529434, Final Batch Loss: 0.17956958711147308\n",
      "Epoch 3437, Loss: 0.7123222351074219, Final Batch Loss: 0.30205827951431274\n",
      "Epoch 3438, Loss: 0.5129265487194061, Final Batch Loss: 0.15927180647850037\n",
      "Epoch 3439, Loss: 0.5471044778823853, Final Batch Loss: 0.20970815420150757\n",
      "Epoch 3440, Loss: 0.6091625690460205, Final Batch Loss: 0.29290449619293213\n",
      "Epoch 3441, Loss: 0.560907706618309, Final Batch Loss: 0.21432101726531982\n",
      "Epoch 3442, Loss: 0.46316292881965637, Final Batch Loss: 0.15699179470539093\n",
      "Epoch 3443, Loss: 0.5293442755937576, Final Batch Loss: 0.17425508797168732\n",
      "Epoch 3444, Loss: 0.5837782919406891, Final Batch Loss: 0.2684819996356964\n",
      "Epoch 3445, Loss: 0.5303380340337753, Final Batch Loss: 0.20864464342594147\n",
      "Epoch 3446, Loss: 0.5409993678331375, Final Batch Loss: 0.23136663436889648\n",
      "Epoch 3447, Loss: 0.5325107127428055, Final Batch Loss: 0.17676258087158203\n",
      "Epoch 3448, Loss: 0.6058645099401474, Final Batch Loss: 0.22041337192058563\n",
      "Epoch 3449, Loss: 0.4608234837651253, Final Batch Loss: 0.1467280089855194\n",
      "Epoch 3450, Loss: 0.5362352877855301, Final Batch Loss: 0.18336690962314606\n",
      "Epoch 3451, Loss: 0.433160200715065, Final Batch Loss: 0.17425277829170227\n",
      "Epoch 3452, Loss: 0.4942123144865036, Final Batch Loss: 0.12000606954097748\n",
      "Epoch 3453, Loss: 0.5908236354589462, Final Batch Loss: 0.23903000354766846\n",
      "Epoch 3454, Loss: 0.4807385057210922, Final Batch Loss: 0.12687304615974426\n",
      "Epoch 3455, Loss: 0.3964935913681984, Final Batch Loss: 0.12923739850521088\n",
      "Epoch 3456, Loss: 0.4718215838074684, Final Batch Loss: 0.19495993852615356\n",
      "Epoch 3457, Loss: 0.6140524297952652, Final Batch Loss: 0.20957602560520172\n",
      "Epoch 3458, Loss: 0.5963115692138672, Final Batch Loss: 0.22765213251113892\n",
      "Epoch 3459, Loss: 0.5920299142599106, Final Batch Loss: 0.18579764664173126\n",
      "Epoch 3460, Loss: 0.4372127056121826, Final Batch Loss: 0.11082226037979126\n",
      "Epoch 3461, Loss: 0.4423956125974655, Final Batch Loss: 0.17495958507061005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3462, Loss: 0.49235799908638, Final Batch Loss: 0.19012944400310516\n",
      "Epoch 3463, Loss: 0.5378333181142807, Final Batch Loss: 0.22791904211044312\n",
      "Epoch 3464, Loss: 0.5612405985593796, Final Batch Loss: 0.2211209088563919\n",
      "Epoch 3465, Loss: 0.7310007810592651, Final Batch Loss: 0.3156844973564148\n",
      "Epoch 3466, Loss: 0.5290388464927673, Final Batch Loss: 0.17680971324443817\n",
      "Epoch 3467, Loss: 0.5125718712806702, Final Batch Loss: 0.17204667627811432\n",
      "Epoch 3468, Loss: 0.497044637799263, Final Batch Loss: 0.15274590253829956\n",
      "Epoch 3469, Loss: 0.5414256155490875, Final Batch Loss: 0.20252707600593567\n",
      "Epoch 3470, Loss: 0.5584624260663986, Final Batch Loss: 0.2002437710762024\n",
      "Epoch 3471, Loss: 0.5371273905038834, Final Batch Loss: 0.17934083938598633\n",
      "Epoch 3472, Loss: 0.4172283262014389, Final Batch Loss: 0.12777236104011536\n",
      "Epoch 3473, Loss: 0.4762563109397888, Final Batch Loss: 0.14883360266685486\n",
      "Epoch 3474, Loss: 0.559834748506546, Final Batch Loss: 0.21441718935966492\n",
      "Epoch 3475, Loss: 0.5334785878658295, Final Batch Loss: 0.19688279926776886\n",
      "Epoch 3476, Loss: 0.5104115307331085, Final Batch Loss: 0.16229183971881866\n",
      "Epoch 3477, Loss: 0.5253684520721436, Final Batch Loss: 0.15311624109745026\n",
      "Epoch 3478, Loss: 0.5502451509237289, Final Batch Loss: 0.20309947431087494\n",
      "Epoch 3479, Loss: 0.6029635220766068, Final Batch Loss: 0.19341371953487396\n",
      "Epoch 3480, Loss: 0.46025609970092773, Final Batch Loss: 0.1708495169878006\n",
      "Epoch 3481, Loss: 0.4973384812474251, Final Batch Loss: 0.17474785447120667\n",
      "Epoch 3482, Loss: 0.5249618664383888, Final Batch Loss: 0.09023631364107132\n",
      "Epoch 3483, Loss: 0.5239918082952499, Final Batch Loss: 0.13826508820056915\n",
      "Epoch 3484, Loss: 0.5861834138631821, Final Batch Loss: 0.2596514821052551\n",
      "Epoch 3485, Loss: 0.6178193390369415, Final Batch Loss: 0.21446511149406433\n",
      "Epoch 3486, Loss: 0.5178228840231895, Final Batch Loss: 0.19542652368545532\n",
      "Epoch 3487, Loss: 0.6633897721767426, Final Batch Loss: 0.2651001811027527\n",
      "Epoch 3488, Loss: 0.6006222814321518, Final Batch Loss: 0.14311590790748596\n",
      "Epoch 3489, Loss: 0.6368343085050583, Final Batch Loss: 0.1694827526807785\n",
      "Epoch 3490, Loss: 0.5612602382898331, Final Batch Loss: 0.2178400456905365\n",
      "Epoch 3491, Loss: 0.5494452863931656, Final Batch Loss: 0.16835811734199524\n",
      "Epoch 3492, Loss: 0.5261026918888092, Final Batch Loss: 0.1941450536251068\n",
      "Epoch 3493, Loss: 0.47513270378112793, Final Batch Loss: 0.16924725472927094\n",
      "Epoch 3494, Loss: 0.527817040681839, Final Batch Loss: 0.13320031762123108\n",
      "Epoch 3495, Loss: 0.5071157813072205, Final Batch Loss: 0.12127327919006348\n",
      "Epoch 3496, Loss: 0.47530387341976166, Final Batch Loss: 0.15580978989601135\n",
      "Epoch 3497, Loss: 0.4754290133714676, Final Batch Loss: 0.12915371358394623\n",
      "Epoch 3498, Loss: 0.45923611521720886, Final Batch Loss: 0.160506933927536\n",
      "Epoch 3499, Loss: 0.5080719888210297, Final Batch Loss: 0.1427968293428421\n",
      "Epoch 3500, Loss: 0.44456279277801514, Final Batch Loss: 0.14158740639686584\n",
      "Epoch 3501, Loss: 0.48108603060245514, Final Batch Loss: 0.18766473233699799\n",
      "Epoch 3502, Loss: 0.5622449666261673, Final Batch Loss: 0.1398390531539917\n",
      "Epoch 3503, Loss: 0.5243227183818817, Final Batch Loss: 0.18133658170700073\n",
      "Epoch 3504, Loss: 0.49990883469581604, Final Batch Loss: 0.19017599523067474\n",
      "Epoch 3505, Loss: 0.556811511516571, Final Batch Loss: 0.22245822846889496\n",
      "Epoch 3506, Loss: 0.5300430059432983, Final Batch Loss: 0.14739544689655304\n",
      "Epoch 3507, Loss: 0.5259105414152145, Final Batch Loss: 0.17820753157138824\n",
      "Epoch 3508, Loss: 0.5386665016412735, Final Batch Loss: 0.14049042761325836\n",
      "Epoch 3509, Loss: 0.5807100683450699, Final Batch Loss: 0.1839897185564041\n",
      "Epoch 3510, Loss: 0.5259173363447189, Final Batch Loss: 0.18068085610866547\n",
      "Epoch 3511, Loss: 0.5451561659574509, Final Batch Loss: 0.1729499250650406\n",
      "Epoch 3512, Loss: 0.43674926459789276, Final Batch Loss: 0.1055959016084671\n",
      "Epoch 3513, Loss: 0.5355324149131775, Final Batch Loss: 0.2111484855413437\n",
      "Epoch 3514, Loss: 0.5208064764738083, Final Batch Loss: 0.1571536362171173\n",
      "Epoch 3515, Loss: 0.5584420710802078, Final Batch Loss: 0.2514428496360779\n",
      "Epoch 3516, Loss: 0.5296968519687653, Final Batch Loss: 0.18003185093402863\n",
      "Epoch 3517, Loss: 0.5799943506717682, Final Batch Loss: 0.18092140555381775\n",
      "Epoch 3518, Loss: 0.5344125330448151, Final Batch Loss: 0.1392650306224823\n",
      "Epoch 3519, Loss: 0.5537368804216385, Final Batch Loss: 0.16013608872890472\n",
      "Epoch 3520, Loss: 0.5391897261142731, Final Batch Loss: 0.1722477525472641\n",
      "Epoch 3521, Loss: 0.45941171050071716, Final Batch Loss: 0.17744866013526917\n",
      "Epoch 3522, Loss: 0.5421316996216774, Final Batch Loss: 0.20125755667686462\n",
      "Epoch 3523, Loss: 0.710348054766655, Final Batch Loss: 0.2913997769355774\n",
      "Epoch 3524, Loss: 0.5498606562614441, Final Batch Loss: 0.19629789888858795\n",
      "Epoch 3525, Loss: 0.45274604856967926, Final Batch Loss: 0.14744322001934052\n",
      "Epoch 3526, Loss: 0.45323728024959564, Final Batch Loss: 0.12372061610221863\n",
      "Epoch 3527, Loss: 0.49959057569503784, Final Batch Loss: 0.14444595575332642\n",
      "Epoch 3528, Loss: 0.49957892298698425, Final Batch Loss: 0.19885095953941345\n",
      "Epoch 3529, Loss: 0.6186076551675797, Final Batch Loss: 0.26469695568084717\n",
      "Epoch 3530, Loss: 0.5382596999406815, Final Batch Loss: 0.1773333102464676\n",
      "Epoch 3531, Loss: 0.5745324939489365, Final Batch Loss: 0.22133390605449677\n",
      "Epoch 3532, Loss: 0.5766154080629349, Final Batch Loss: 0.2173163741827011\n",
      "Epoch 3533, Loss: 0.556908130645752, Final Batch Loss: 0.19621245563030243\n",
      "Epoch 3534, Loss: 0.5819989889860153, Final Batch Loss: 0.19802990555763245\n",
      "Epoch 3535, Loss: 0.48239946365356445, Final Batch Loss: 0.1619422733783722\n",
      "Epoch 3536, Loss: 0.6027866005897522, Final Batch Loss: 0.13395604491233826\n",
      "Epoch 3537, Loss: 0.5574777126312256, Final Batch Loss: 0.15103358030319214\n",
      "Epoch 3538, Loss: 0.6518231779336929, Final Batch Loss: 0.2156207263469696\n",
      "Epoch 3539, Loss: 0.5300062894821167, Final Batch Loss: 0.22151127457618713\n",
      "Epoch 3540, Loss: 0.5183500051498413, Final Batch Loss: 0.16497783362865448\n",
      "Epoch 3541, Loss: 0.7355739772319794, Final Batch Loss: 0.3118540644645691\n",
      "Epoch 3542, Loss: 0.6269004493951797, Final Batch Loss: 0.25477010011672974\n",
      "Epoch 3543, Loss: 0.5487057864665985, Final Batch Loss: 0.21210293471813202\n",
      "Epoch 3544, Loss: 0.45652536302804947, Final Batch Loss: 0.10102377086877823\n",
      "Epoch 3545, Loss: 0.5691666603088379, Final Batch Loss: 0.2138812243938446\n",
      "Epoch 3546, Loss: 0.49610570073127747, Final Batch Loss: 0.14164039492607117\n",
      "Epoch 3547, Loss: 0.5904659926891327, Final Batch Loss: 0.19085311889648438\n",
      "Epoch 3548, Loss: 0.5314246490597725, Final Batch Loss: 0.21447092294692993\n",
      "Epoch 3549, Loss: 0.5833279937505722, Final Batch Loss: 0.19138889014720917\n",
      "Epoch 3550, Loss: 0.611550435423851, Final Batch Loss: 0.1842319369316101\n",
      "Epoch 3551, Loss: 0.4742076247930527, Final Batch Loss: 0.16078931093215942\n",
      "Epoch 3552, Loss: 0.5499793589115143, Final Batch Loss: 0.236852765083313\n",
      "Epoch 3553, Loss: 0.526022344827652, Final Batch Loss: 0.18618813157081604\n",
      "Epoch 3554, Loss: 0.5516024380922318, Final Batch Loss: 0.14555592834949493\n",
      "Epoch 3555, Loss: 0.5538893491029739, Final Batch Loss: 0.21060873568058014\n",
      "Epoch 3556, Loss: 0.5076202005147934, Final Batch Loss: 0.20480529963970184\n",
      "Epoch 3557, Loss: 0.47767870128154755, Final Batch Loss: 0.1421496421098709\n",
      "Epoch 3558, Loss: 0.46803198754787445, Final Batch Loss: 0.1480402946472168\n",
      "Epoch 3559, Loss: 0.5870677083730698, Final Batch Loss: 0.23453114926815033\n",
      "Epoch 3560, Loss: 0.4633590504527092, Final Batch Loss: 0.10577262192964554\n",
      "Epoch 3561, Loss: 0.5457238852977753, Final Batch Loss: 0.16158416867256165\n",
      "Epoch 3562, Loss: 0.5882050395011902, Final Batch Loss: 0.19701574742794037\n",
      "Epoch 3563, Loss: 0.42969395965337753, Final Batch Loss: 0.12037993222475052\n",
      "Epoch 3564, Loss: 0.4465135633945465, Final Batch Loss: 0.15418997406959534\n",
      "Epoch 3565, Loss: 0.5437445119023323, Final Batch Loss: 0.22937385737895966\n",
      "Epoch 3566, Loss: 0.6631890833377838, Final Batch Loss: 0.23995035886764526\n",
      "Epoch 3567, Loss: 0.5426813215017319, Final Batch Loss: 0.14623960852622986\n",
      "Epoch 3568, Loss: 0.5051415860652924, Final Batch Loss: 0.12960992753505707\n",
      "Epoch 3569, Loss: 0.5167177468538284, Final Batch Loss: 0.20348352193832397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3570, Loss: 0.4851186200976372, Final Batch Loss: 0.09839402884244919\n",
      "Epoch 3571, Loss: 0.6697506308555603, Final Batch Loss: 0.2987590730190277\n",
      "Epoch 3572, Loss: 0.5271546989679337, Final Batch Loss: 0.2002100944519043\n",
      "Epoch 3573, Loss: 0.5063388720154762, Final Batch Loss: 0.1954578161239624\n",
      "Epoch 3574, Loss: 0.6995884925127029, Final Batch Loss: 0.3565305471420288\n",
      "Epoch 3575, Loss: 0.5838978886604309, Final Batch Loss: 0.1648167222738266\n",
      "Epoch 3576, Loss: 0.4948253631591797, Final Batch Loss: 0.17033858597278595\n",
      "Epoch 3577, Loss: 0.4594881236553192, Final Batch Loss: 0.1514449566602707\n",
      "Epoch 3578, Loss: 0.5459912195801735, Final Batch Loss: 0.28562477231025696\n",
      "Epoch 3579, Loss: 0.462267741560936, Final Batch Loss: 0.14845512807369232\n",
      "Epoch 3580, Loss: 0.49182165414094925, Final Batch Loss: 0.2166435569524765\n",
      "Epoch 3581, Loss: 0.5579878240823746, Final Batch Loss: 0.14296852052211761\n",
      "Epoch 3582, Loss: 0.459506519138813, Final Batch Loss: 0.1103721633553505\n",
      "Epoch 3583, Loss: 0.48592450469732285, Final Batch Loss: 0.18987232446670532\n",
      "Epoch 3584, Loss: 0.4672214686870575, Final Batch Loss: 0.12615986168384552\n",
      "Epoch 3585, Loss: 0.46380941569805145, Final Batch Loss: 0.18188390135765076\n",
      "Epoch 3586, Loss: 0.5401423871517181, Final Batch Loss: 0.25579482316970825\n",
      "Epoch 3587, Loss: 0.5102799013257027, Final Batch Loss: 0.21123848855495453\n",
      "Epoch 3588, Loss: 0.5014201104640961, Final Batch Loss: 0.2162860482931137\n",
      "Epoch 3589, Loss: 0.4912145137786865, Final Batch Loss: 0.1929096281528473\n",
      "Epoch 3590, Loss: 0.6407460570335388, Final Batch Loss: 0.2574739158153534\n",
      "Epoch 3591, Loss: 0.4610466808080673, Final Batch Loss: 0.1440812051296234\n",
      "Epoch 3592, Loss: 0.5552589446306229, Final Batch Loss: 0.15225113928318024\n",
      "Epoch 3593, Loss: 0.572726234793663, Final Batch Loss: 0.15917983651161194\n",
      "Epoch 3594, Loss: 0.5241753607988358, Final Batch Loss: 0.1789608746767044\n",
      "Epoch 3595, Loss: 0.48760436475276947, Final Batch Loss: 0.14765475690364838\n",
      "Epoch 3596, Loss: 0.4845450296998024, Final Batch Loss: 0.14373166859149933\n",
      "Epoch 3597, Loss: 0.4547402411699295, Final Batch Loss: 0.1698717623949051\n",
      "Epoch 3598, Loss: 0.5229229927062988, Final Batch Loss: 0.17568965256214142\n",
      "Epoch 3599, Loss: 0.5495495647192001, Final Batch Loss: 0.17847296595573425\n",
      "Epoch 3600, Loss: 0.46090298891067505, Final Batch Loss: 0.16262362897396088\n",
      "Epoch 3601, Loss: 0.47640011459589005, Final Batch Loss: 0.0957576259970665\n",
      "Epoch 3602, Loss: 0.41587114334106445, Final Batch Loss: 0.13596580922603607\n",
      "Epoch 3603, Loss: 0.44206999987363815, Final Batch Loss: 0.17367558181285858\n",
      "Epoch 3604, Loss: 0.5575352013111115, Final Batch Loss: 0.20733417570590973\n",
      "Epoch 3605, Loss: 0.47188524901866913, Final Batch Loss: 0.16789260506629944\n",
      "Epoch 3606, Loss: 0.46198364347219467, Final Batch Loss: 0.11587720364332199\n",
      "Epoch 3607, Loss: 0.5036790817975998, Final Batch Loss: 0.19211439788341522\n",
      "Epoch 3608, Loss: 0.5071928203105927, Final Batch Loss: 0.17960800230503082\n",
      "Epoch 3609, Loss: 0.5804030448198318, Final Batch Loss: 0.18174587190151215\n",
      "Epoch 3610, Loss: 0.469076007604599, Final Batch Loss: 0.1374831646680832\n",
      "Epoch 3611, Loss: 0.43232713639736176, Final Batch Loss: 0.1413356363773346\n",
      "Epoch 3612, Loss: 0.6069532483816147, Final Batch Loss: 0.20774903893470764\n",
      "Epoch 3613, Loss: 0.507701613008976, Final Batch Loss: 0.2214868813753128\n",
      "Epoch 3614, Loss: 0.39879343658685684, Final Batch Loss: 0.11817069351673126\n",
      "Epoch 3615, Loss: 0.47349320352077484, Final Batch Loss: 0.13119496405124664\n",
      "Epoch 3616, Loss: 0.40945976227521896, Final Batch Loss: 0.15348055958747864\n",
      "Epoch 3617, Loss: 0.597015991806984, Final Batch Loss: 0.21195189654827118\n",
      "Epoch 3618, Loss: 0.37848518043756485, Final Batch Loss: 0.10380424559116364\n",
      "Epoch 3619, Loss: 0.5088085532188416, Final Batch Loss: 0.18079370260238647\n",
      "Epoch 3620, Loss: 0.5121087729930878, Final Batch Loss: 0.15555605292320251\n",
      "Epoch 3621, Loss: 0.5266003385186195, Final Batch Loss: 0.18765439093112946\n",
      "Epoch 3622, Loss: 0.4971914738416672, Final Batch Loss: 0.2290181964635849\n",
      "Epoch 3623, Loss: 0.5470453500747681, Final Batch Loss: 0.19925987720489502\n",
      "Epoch 3624, Loss: 0.5370799452066422, Final Batch Loss: 0.1634310930967331\n",
      "Epoch 3625, Loss: 0.5300342589616776, Final Batch Loss: 0.1644773781299591\n",
      "Epoch 3626, Loss: 0.5299647301435471, Final Batch Loss: 0.1912970244884491\n",
      "Epoch 3627, Loss: 0.5694112628698349, Final Batch Loss: 0.10185794532299042\n",
      "Epoch 3628, Loss: 0.4710347652435303, Final Batch Loss: 0.14630027115345\n",
      "Epoch 3629, Loss: 0.5621923953294754, Final Batch Loss: 0.19003841280937195\n",
      "Epoch 3630, Loss: 0.5077141523361206, Final Batch Loss: 0.11147408187389374\n",
      "Epoch 3631, Loss: 0.5840618014335632, Final Batch Loss: 0.15271608531475067\n",
      "Epoch 3632, Loss: 0.61660136282444, Final Batch Loss: 0.28048914670944214\n",
      "Epoch 3633, Loss: 0.4962165653705597, Final Batch Loss: 0.14157120883464813\n",
      "Epoch 3634, Loss: 0.48281318694353104, Final Batch Loss: 0.20766237378120422\n",
      "Epoch 3635, Loss: 0.565424919128418, Final Batch Loss: 0.23220114409923553\n",
      "Epoch 3636, Loss: 0.5305647701025009, Final Batch Loss: 0.18982459604740143\n",
      "Epoch 3637, Loss: 0.653243824839592, Final Batch Loss: 0.3208446800708771\n",
      "Epoch 3638, Loss: 0.5296276807785034, Final Batch Loss: 0.10735753178596497\n",
      "Epoch 3639, Loss: 0.4833749830722809, Final Batch Loss: 0.17332035303115845\n",
      "Epoch 3640, Loss: 0.5400295108556747, Final Batch Loss: 0.14124645292758942\n",
      "Epoch 3641, Loss: 0.38621632009744644, Final Batch Loss: 0.10112059861421585\n",
      "Epoch 3642, Loss: 0.42146509885787964, Final Batch Loss: 0.1416306346654892\n",
      "Epoch 3643, Loss: 0.4663799852132797, Final Batch Loss: 0.11364193260669708\n",
      "Epoch 3644, Loss: 0.41591811925172806, Final Batch Loss: 0.12099824100732803\n",
      "Epoch 3645, Loss: 0.6515555083751678, Final Batch Loss: 0.22954383492469788\n",
      "Epoch 3646, Loss: 0.40844277292490005, Final Batch Loss: 0.137682244181633\n",
      "Epoch 3647, Loss: 0.48139147460460663, Final Batch Loss: 0.1976316273212433\n",
      "Epoch 3648, Loss: 0.45242762565612793, Final Batch Loss: 0.13620604574680328\n",
      "Epoch 3649, Loss: 0.52749203145504, Final Batch Loss: 0.2004738301038742\n",
      "Epoch 3650, Loss: 0.4690195918083191, Final Batch Loss: 0.1709641069173813\n",
      "Epoch 3651, Loss: 0.5304324254393578, Final Batch Loss: 0.22729021310806274\n",
      "Epoch 3652, Loss: 0.4255095422267914, Final Batch Loss: 0.10928024351596832\n",
      "Epoch 3653, Loss: 0.531653881072998, Final Batch Loss: 0.22700966894626617\n",
      "Epoch 3654, Loss: 0.3993382602930069, Final Batch Loss: 0.15487144887447357\n",
      "Epoch 3655, Loss: 0.5484601706266403, Final Batch Loss: 0.13445036113262177\n",
      "Epoch 3656, Loss: 0.47327870875597, Final Batch Loss: 0.15190796554088593\n",
      "Epoch 3657, Loss: 0.6251881271600723, Final Batch Loss: 0.261501669883728\n",
      "Epoch 3658, Loss: 0.4163511246442795, Final Batch Loss: 0.1314546763896942\n",
      "Epoch 3659, Loss: 0.48661962896585464, Final Batch Loss: 0.1230221763253212\n",
      "Epoch 3660, Loss: 0.44198545813560486, Final Batch Loss: 0.125950887799263\n",
      "Epoch 3661, Loss: 0.48959896713495255, Final Batch Loss: 0.19726857542991638\n",
      "Epoch 3662, Loss: 0.3731970489025116, Final Batch Loss: 0.09805391728878021\n",
      "Epoch 3663, Loss: 0.5053147822618484, Final Batch Loss: 0.1712752878665924\n",
      "Epoch 3664, Loss: 0.37927087396383286, Final Batch Loss: 0.13030751049518585\n",
      "Epoch 3665, Loss: 0.5227327346801758, Final Batch Loss: 0.23185423016548157\n",
      "Epoch 3666, Loss: 0.5528166443109512, Final Batch Loss: 0.18199780583381653\n",
      "Epoch 3667, Loss: 0.4187280908226967, Final Batch Loss: 0.08983432501554489\n",
      "Epoch 3668, Loss: 0.47046107798814774, Final Batch Loss: 0.11859505623579025\n",
      "Epoch 3669, Loss: 0.5249985307455063, Final Batch Loss: 0.16587822139263153\n",
      "Epoch 3670, Loss: 0.4805161729454994, Final Batch Loss: 0.21724992990493774\n",
      "Epoch 3671, Loss: 0.5728665590286255, Final Batch Loss: 0.15646909177303314\n",
      "Epoch 3672, Loss: 0.4151746779680252, Final Batch Loss: 0.12288135290145874\n",
      "Epoch 3673, Loss: 0.4863632395863533, Final Batch Loss: 0.12282247096300125\n",
      "Epoch 3674, Loss: 0.6406673640012741, Final Batch Loss: 0.21281486749649048\n",
      "Epoch 3675, Loss: 0.4406992644071579, Final Batch Loss: 0.16489388048648834\n",
      "Epoch 3676, Loss: 0.45029790699481964, Final Batch Loss: 0.16423064470291138\n",
      "Epoch 3677, Loss: 0.4644726663827896, Final Batch Loss: 0.09312564134597778\n",
      "Epoch 3678, Loss: 0.5223523527383804, Final Batch Loss: 0.16461636126041412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3679, Loss: 0.4553346335887909, Final Batch Loss: 0.1254335343837738\n",
      "Epoch 3680, Loss: 0.5440092533826828, Final Batch Loss: 0.18926295638084412\n",
      "Epoch 3681, Loss: 0.5602239966392517, Final Batch Loss: 0.14170542359352112\n",
      "Epoch 3682, Loss: 0.5241209119558334, Final Batch Loss: 0.15484371781349182\n",
      "Epoch 3683, Loss: 0.5083244666457176, Final Batch Loss: 0.12132144719362259\n",
      "Epoch 3684, Loss: 0.5359160006046295, Final Batch Loss: 0.17365165054798126\n",
      "Epoch 3685, Loss: 0.7327101826667786, Final Batch Loss: 0.2624208629131317\n",
      "Epoch 3686, Loss: 0.5186684131622314, Final Batch Loss: 0.14684216678142548\n",
      "Epoch 3687, Loss: 0.46816253662109375, Final Batch Loss: 0.1269853264093399\n",
      "Epoch 3688, Loss: 0.5339975506067276, Final Batch Loss: 0.2972087860107422\n",
      "Epoch 3689, Loss: 0.5595390945672989, Final Batch Loss: 0.1740226149559021\n",
      "Epoch 3690, Loss: 0.48442913591861725, Final Batch Loss: 0.17902341485023499\n",
      "Epoch 3691, Loss: 0.4382068067789078, Final Batch Loss: 0.12959036231040955\n",
      "Epoch 3692, Loss: 0.4505889117717743, Final Batch Loss: 0.12856915593147278\n",
      "Epoch 3693, Loss: 0.4081834629178047, Final Batch Loss: 0.144684299826622\n",
      "Epoch 3694, Loss: 0.4797385632991791, Final Batch Loss: 0.11348207294940948\n",
      "Epoch 3695, Loss: 0.5059424340724945, Final Batch Loss: 0.15552659332752228\n",
      "Epoch 3696, Loss: 0.46514642238616943, Final Batch Loss: 0.13022279739379883\n",
      "Epoch 3697, Loss: 0.5380151271820068, Final Batch Loss: 0.11963477730751038\n",
      "Epoch 3698, Loss: 0.5119190514087677, Final Batch Loss: 0.13536915183067322\n",
      "Epoch 3699, Loss: 0.48286277055740356, Final Batch Loss: 0.1383989304304123\n",
      "Epoch 3700, Loss: 0.5240394473075867, Final Batch Loss: 0.18609198927879333\n",
      "Epoch 3701, Loss: 0.43780191242694855, Final Batch Loss: 0.13718673586845398\n",
      "Epoch 3702, Loss: 0.5745406448841095, Final Batch Loss: 0.24136650562286377\n",
      "Epoch 3703, Loss: 0.5583728402853012, Final Batch Loss: 0.24934227764606476\n",
      "Epoch 3704, Loss: 0.6633158624172211, Final Batch Loss: 0.2779883146286011\n",
      "Epoch 3705, Loss: 0.5772211998701096, Final Batch Loss: 0.19714125990867615\n",
      "Epoch 3706, Loss: 0.5639805495738983, Final Batch Loss: 0.25627994537353516\n",
      "Epoch 3707, Loss: 0.5912357866764069, Final Batch Loss: 0.22100074589252472\n",
      "Epoch 3708, Loss: 0.5975548624992371, Final Batch Loss: 0.29064124822616577\n",
      "Epoch 3709, Loss: 0.5857499837875366, Final Batch Loss: 0.16521237790584564\n",
      "Epoch 3710, Loss: 0.5556852370500565, Final Batch Loss: 0.20173099637031555\n",
      "Epoch 3711, Loss: 0.6141586303710938, Final Batch Loss: 0.24016869068145752\n",
      "Epoch 3712, Loss: 0.6467533856630325, Final Batch Loss: 0.2236257642507553\n",
      "Epoch 3713, Loss: 0.4917704164981842, Final Batch Loss: 0.1271919459104538\n",
      "Epoch 3714, Loss: 0.5642751008272171, Final Batch Loss: 0.1448456197977066\n",
      "Epoch 3715, Loss: 0.5663506537675858, Final Batch Loss: 0.24423153698444366\n",
      "Epoch 3716, Loss: 0.4775156229734421, Final Batch Loss: 0.18648186326026917\n",
      "Epoch 3717, Loss: 0.5340358316898346, Final Batch Loss: 0.15310035645961761\n",
      "Epoch 3718, Loss: 0.4896131753921509, Final Batch Loss: 0.12327469885349274\n",
      "Epoch 3719, Loss: 0.5562199056148529, Final Batch Loss: 0.17683178186416626\n",
      "Epoch 3720, Loss: 0.5209019929170609, Final Batch Loss: 0.14351902902126312\n",
      "Epoch 3721, Loss: 0.5231952220201492, Final Batch Loss: 0.27213233709335327\n",
      "Epoch 3722, Loss: 0.5457517951726913, Final Batch Loss: 0.19139830768108368\n",
      "Epoch 3723, Loss: 0.42822904884815216, Final Batch Loss: 0.1603373885154724\n",
      "Epoch 3724, Loss: 0.544145792722702, Final Batch Loss: 0.1722632497549057\n",
      "Epoch 3725, Loss: 0.44297248870134354, Final Batch Loss: 0.13120558857917786\n",
      "Epoch 3726, Loss: 0.5233786553144455, Final Batch Loss: 0.1885671615600586\n",
      "Epoch 3727, Loss: 0.5180065929889679, Final Batch Loss: 0.1982467919588089\n",
      "Epoch 3728, Loss: 0.47137876600027084, Final Batch Loss: 0.11694299429655075\n",
      "Epoch 3729, Loss: 0.4112735241651535, Final Batch Loss: 0.10316339135169983\n",
      "Epoch 3730, Loss: 0.4722762405872345, Final Batch Loss: 0.18743117153644562\n",
      "Epoch 3731, Loss: 0.4428357630968094, Final Batch Loss: 0.1351834088563919\n",
      "Epoch 3732, Loss: 0.4669906795024872, Final Batch Loss: 0.13505513966083527\n",
      "Epoch 3733, Loss: 0.44689473509788513, Final Batch Loss: 0.17836730182170868\n",
      "Epoch 3734, Loss: 0.503903329372406, Final Batch Loss: 0.1914142221212387\n",
      "Epoch 3735, Loss: 0.4020482376217842, Final Batch Loss: 0.09375422447919846\n",
      "Epoch 3736, Loss: 0.541484072804451, Final Batch Loss: 0.21508675813674927\n",
      "Epoch 3737, Loss: 0.516600638628006, Final Batch Loss: 0.14078320562839508\n",
      "Epoch 3738, Loss: 0.6218162477016449, Final Batch Loss: 0.22776541113853455\n",
      "Epoch 3739, Loss: 0.5530676543712616, Final Batch Loss: 0.23097270727157593\n",
      "Epoch 3740, Loss: 0.5978628695011139, Final Batch Loss: 0.2012847512960434\n",
      "Epoch 3741, Loss: 0.6189205497503281, Final Batch Loss: 0.26682984828948975\n",
      "Epoch 3742, Loss: 0.5598831921815872, Final Batch Loss: 0.20916369557380676\n",
      "Epoch 3743, Loss: 0.48775410652160645, Final Batch Loss: 0.15013402700424194\n",
      "Epoch 3744, Loss: 0.5426902323961258, Final Batch Loss: 0.13817225396633148\n",
      "Epoch 3745, Loss: 0.5396147668361664, Final Batch Loss: 0.17778755724430084\n",
      "Epoch 3746, Loss: 0.4850003868341446, Final Batch Loss: 0.161324143409729\n",
      "Epoch 3747, Loss: 0.5435153245925903, Final Batch Loss: 0.23360955715179443\n",
      "Epoch 3748, Loss: 0.5941242873668671, Final Batch Loss: 0.2637895345687866\n",
      "Epoch 3749, Loss: 0.5077738165855408, Final Batch Loss: 0.1973874866962433\n",
      "Epoch 3750, Loss: 0.5555823296308517, Final Batch Loss: 0.15087756514549255\n",
      "Epoch 3751, Loss: 0.6004755049943924, Final Batch Loss: 0.21355639398097992\n",
      "Epoch 3752, Loss: 0.5157905966043472, Final Batch Loss: 0.15603919327259064\n",
      "Epoch 3753, Loss: 0.6332665979862213, Final Batch Loss: 0.19037865102291107\n",
      "Epoch 3754, Loss: 0.45888742059469223, Final Batch Loss: 0.20704248547554016\n",
      "Epoch 3755, Loss: 0.5807991474866867, Final Batch Loss: 0.18578945100307465\n",
      "Epoch 3756, Loss: 0.5218486189842224, Final Batch Loss: 0.14890281856060028\n",
      "Epoch 3757, Loss: 0.5272713303565979, Final Batch Loss: 0.17281633615493774\n",
      "Epoch 3758, Loss: 0.4101671352982521, Final Batch Loss: 0.07032255083322525\n",
      "Epoch 3759, Loss: 0.4780062139034271, Final Batch Loss: 0.11446986347436905\n",
      "Epoch 3760, Loss: 0.4777528718113899, Final Batch Loss: 0.08348747342824936\n",
      "Epoch 3761, Loss: 0.5727401226758957, Final Batch Loss: 0.24753281474113464\n",
      "Epoch 3762, Loss: 0.4548325389623642, Final Batch Loss: 0.13221439719200134\n",
      "Epoch 3763, Loss: 0.5430473983287811, Final Batch Loss: 0.16342608630657196\n",
      "Epoch 3764, Loss: 0.5289015024900436, Final Batch Loss: 0.21338993310928345\n",
      "Epoch 3765, Loss: 0.4850686490535736, Final Batch Loss: 0.16357778012752533\n",
      "Epoch 3766, Loss: 0.405600942671299, Final Batch Loss: 0.2040659338235855\n",
      "Epoch 3767, Loss: 0.4498157650232315, Final Batch Loss: 0.09805463254451752\n",
      "Epoch 3768, Loss: 0.46188493072986603, Final Batch Loss: 0.144270122051239\n",
      "Epoch 3769, Loss: 0.4913337230682373, Final Batch Loss: 0.17071816325187683\n",
      "Epoch 3770, Loss: 0.4105165898799896, Final Batch Loss: 0.16085240244865417\n",
      "Epoch 3771, Loss: 0.46192292869091034, Final Batch Loss: 0.13552610576152802\n",
      "Epoch 3772, Loss: 0.4601560980081558, Final Batch Loss: 0.14878837764263153\n",
      "Epoch 3773, Loss: 0.5002445727586746, Final Batch Loss: 0.17438653111457825\n",
      "Epoch 3774, Loss: 0.3912912979722023, Final Batch Loss: 0.14023220539093018\n",
      "Epoch 3775, Loss: 0.45976459234952927, Final Batch Loss: 0.09694977849721909\n",
      "Epoch 3776, Loss: 0.5412046164274216, Final Batch Loss: 0.23259645700454712\n",
      "Epoch 3777, Loss: 0.4517109617590904, Final Batch Loss: 0.15747816860675812\n",
      "Epoch 3778, Loss: 0.41306132823228836, Final Batch Loss: 0.1370178759098053\n",
      "Epoch 3779, Loss: 0.5344151556491852, Final Batch Loss: 0.18521751463413239\n",
      "Epoch 3780, Loss: 0.39233362674713135, Final Batch Loss: 0.15987138450145721\n",
      "Epoch 3781, Loss: 0.4493379592895508, Final Batch Loss: 0.16323773562908173\n",
      "Epoch 3782, Loss: 0.5038354843854904, Final Batch Loss: 0.17320360243320465\n",
      "Epoch 3783, Loss: 0.4330046698451042, Final Batch Loss: 0.13351598381996155\n",
      "Epoch 3784, Loss: 0.4868573695421219, Final Batch Loss: 0.2039528787136078\n",
      "Epoch 3785, Loss: 0.5426871329545975, Final Batch Loss: 0.2389560341835022\n",
      "Epoch 3786, Loss: 0.5518207848072052, Final Batch Loss: 0.13461723923683167\n",
      "Epoch 3787, Loss: 0.447918064892292, Final Batch Loss: 0.17556636035442352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3788, Loss: 0.46175409853458405, Final Batch Loss: 0.16096356511116028\n",
      "Epoch 3789, Loss: 0.4069850444793701, Final Batch Loss: 0.1134975403547287\n",
      "Epoch 3790, Loss: 0.4952345937490463, Final Batch Loss: 0.16213971376419067\n",
      "Epoch 3791, Loss: 0.5075863674283028, Final Batch Loss: 0.18845075368881226\n",
      "Epoch 3792, Loss: 0.4829603284597397, Final Batch Loss: 0.17939426004886627\n",
      "Epoch 3793, Loss: 0.43675873428583145, Final Batch Loss: 0.10571705549955368\n",
      "Epoch 3794, Loss: 0.4232938289642334, Final Batch Loss: 0.09910815954208374\n",
      "Epoch 3795, Loss: 0.5105470716953278, Final Batch Loss: 0.22771534323692322\n",
      "Epoch 3796, Loss: 0.42082948982715607, Final Batch Loss: 0.16108039021492004\n",
      "Epoch 3797, Loss: 0.38380957394838333, Final Batch Loss: 0.15502049028873444\n",
      "Epoch 3798, Loss: 0.42237184941768646, Final Batch Loss: 0.11353598535060883\n",
      "Epoch 3799, Loss: 0.5099273547530174, Final Batch Loss: 0.22610056400299072\n",
      "Epoch 3800, Loss: 0.5351848304271698, Final Batch Loss: 0.19817467033863068\n",
      "Epoch 3801, Loss: 0.4626772552728653, Final Batch Loss: 0.20330853760242462\n",
      "Epoch 3802, Loss: 0.35914385318756104, Final Batch Loss: 0.10698188841342926\n",
      "Epoch 3803, Loss: 0.4588708281517029, Final Batch Loss: 0.18646647036075592\n",
      "Epoch 3804, Loss: 0.5675021857023239, Final Batch Loss: 0.14862069487571716\n",
      "Epoch 3805, Loss: 0.3603358492255211, Final Batch Loss: 0.11362933367490768\n",
      "Epoch 3806, Loss: 0.5337447077035904, Final Batch Loss: 0.14849624037742615\n",
      "Epoch 3807, Loss: 0.4942530319094658, Final Batch Loss: 0.12404318898916245\n",
      "Epoch 3808, Loss: 0.41519681364297867, Final Batch Loss: 0.18603041768074036\n",
      "Epoch 3809, Loss: 0.3754440173506737, Final Batch Loss: 0.07352136820554733\n",
      "Epoch 3810, Loss: 0.3538806736469269, Final Batch Loss: 0.11591699719429016\n",
      "Epoch 3811, Loss: 0.45372697710990906, Final Batch Loss: 0.13353054225444794\n",
      "Epoch 3812, Loss: 0.39661186933517456, Final Batch Loss: 0.1402847319841385\n",
      "Epoch 3813, Loss: 0.438508078455925, Final Batch Loss: 0.1578819900751114\n",
      "Epoch 3814, Loss: 0.4465259537100792, Final Batch Loss: 0.21329106390476227\n",
      "Epoch 3815, Loss: 0.5658486038446426, Final Batch Loss: 0.1953095942735672\n",
      "Epoch 3816, Loss: 0.4610435217618942, Final Batch Loss: 0.1366472840309143\n",
      "Epoch 3817, Loss: 0.4020863324403763, Final Batch Loss: 0.12416456639766693\n",
      "Epoch 3818, Loss: 0.530515730381012, Final Batch Loss: 0.17854776978492737\n",
      "Epoch 3819, Loss: 0.44239281117916107, Final Batch Loss: 0.09932838380336761\n",
      "Epoch 3820, Loss: 0.46178116649389267, Final Batch Loss: 0.15865793824195862\n",
      "Epoch 3821, Loss: 0.4267119765281677, Final Batch Loss: 0.12631788849830627\n",
      "Epoch 3822, Loss: 0.39807186275720596, Final Batch Loss: 0.08355274051427841\n",
      "Epoch 3823, Loss: 0.4238922819495201, Final Batch Loss: 0.15089911222457886\n",
      "Epoch 3824, Loss: 0.4988165497779846, Final Batch Loss: 0.14439329504966736\n",
      "Epoch 3825, Loss: 0.46825799345970154, Final Batch Loss: 0.18122245371341705\n",
      "Epoch 3826, Loss: 0.5002544820308685, Final Batch Loss: 0.17217858135700226\n",
      "Epoch 3827, Loss: 0.44376175850629807, Final Batch Loss: 0.11886154860258102\n",
      "Epoch 3828, Loss: 0.44595736265182495, Final Batch Loss: 0.1505333036184311\n",
      "Epoch 3829, Loss: 0.4398347809910774, Final Batch Loss: 0.1238982304930687\n",
      "Epoch 3830, Loss: 0.47879502177238464, Final Batch Loss: 0.14410234987735748\n",
      "Epoch 3831, Loss: 0.3860732540488243, Final Batch Loss: 0.12507560849189758\n",
      "Epoch 3832, Loss: 0.4511166140437126, Final Batch Loss: 0.1816592812538147\n",
      "Epoch 3833, Loss: 0.4611533135175705, Final Batch Loss: 0.20037807524204254\n",
      "Epoch 3834, Loss: 0.4150892049074173, Final Batch Loss: 0.16237245500087738\n",
      "Epoch 3835, Loss: 0.33543506264686584, Final Batch Loss: 0.10688378661870956\n",
      "Epoch 3836, Loss: 0.4918091893196106, Final Batch Loss: 0.18405653536319733\n",
      "Epoch 3837, Loss: 0.4925239309668541, Final Batch Loss: 0.17250016331672668\n",
      "Epoch 3838, Loss: 0.428835466504097, Final Batch Loss: 0.15063121914863586\n",
      "Epoch 3839, Loss: 0.45977938175201416, Final Batch Loss: 0.21042297780513763\n",
      "Epoch 3840, Loss: 0.45554187148809433, Final Batch Loss: 0.10994081944227219\n",
      "Epoch 3841, Loss: 0.4365855008363724, Final Batch Loss: 0.13803815841674805\n",
      "Epoch 3842, Loss: 0.5701736807823181, Final Batch Loss: 0.1814461052417755\n",
      "Epoch 3843, Loss: 0.5646800249814987, Final Batch Loss: 0.18697842955589294\n",
      "Epoch 3844, Loss: 0.5421333163976669, Final Batch Loss: 0.188519686460495\n",
      "Epoch 3845, Loss: 0.6789770126342773, Final Batch Loss: 0.2662803530693054\n",
      "Epoch 3846, Loss: 0.4900953322649002, Final Batch Loss: 0.1625138819217682\n",
      "Epoch 3847, Loss: 0.563061386346817, Final Batch Loss: 0.2623039782047272\n",
      "Epoch 3848, Loss: 0.4780421257019043, Final Batch Loss: 0.15311239659786224\n",
      "Epoch 3849, Loss: 0.5047555416822433, Final Batch Loss: 0.1336975246667862\n",
      "Epoch 3850, Loss: 0.4007408320903778, Final Batch Loss: 0.15723371505737305\n",
      "Epoch 3851, Loss: 0.4574150890111923, Final Batch Loss: 0.14489416778087616\n",
      "Epoch 3852, Loss: 0.4887537360191345, Final Batch Loss: 0.18035200238227844\n",
      "Epoch 3853, Loss: 0.5127453207969666, Final Batch Loss: 0.17968302965164185\n",
      "Epoch 3854, Loss: 0.5136234164237976, Final Batch Loss: 0.17066419124603271\n",
      "Epoch 3855, Loss: 0.4450055807828903, Final Batch Loss: 0.14459030330181122\n",
      "Epoch 3856, Loss: 0.45223749428987503, Final Batch Loss: 0.20793792605400085\n",
      "Epoch 3857, Loss: 0.4468447268009186, Final Batch Loss: 0.15279178321361542\n",
      "Epoch 3858, Loss: 0.44538261741399765, Final Batch Loss: 0.14454957842826843\n",
      "Epoch 3859, Loss: 0.4773295223712921, Final Batch Loss: 0.17068007588386536\n",
      "Epoch 3860, Loss: 0.3908068314194679, Final Batch Loss: 0.14247682690620422\n",
      "Epoch 3861, Loss: 0.4438210278749466, Final Batch Loss: 0.12720194458961487\n",
      "Epoch 3862, Loss: 0.45734134316444397, Final Batch Loss: 0.17094534635543823\n",
      "Epoch 3863, Loss: 0.40443890541791916, Final Batch Loss: 0.13501010835170746\n",
      "Epoch 3864, Loss: 0.4328063577413559, Final Batch Loss: 0.1300673633813858\n",
      "Epoch 3865, Loss: 0.44592268764972687, Final Batch Loss: 0.10344237089157104\n",
      "Epoch 3866, Loss: 0.42023369669914246, Final Batch Loss: 0.1465686857700348\n",
      "Epoch 3867, Loss: 0.36000802367925644, Final Batch Loss: 0.097458116710186\n",
      "Epoch 3868, Loss: 0.4244025945663452, Final Batch Loss: 0.13273756206035614\n",
      "Epoch 3869, Loss: 0.4504917412996292, Final Batch Loss: 0.17763057351112366\n",
      "Epoch 3870, Loss: 0.4886723980307579, Final Batch Loss: 0.24738214910030365\n",
      "Epoch 3871, Loss: 0.8024488687515259, Final Batch Loss: 0.27865853905677795\n",
      "Epoch 3872, Loss: 0.4588751196861267, Final Batch Loss: 0.2122168093919754\n",
      "Epoch 3873, Loss: 0.5602319985628128, Final Batch Loss: 0.21549199521541595\n",
      "Epoch 3874, Loss: 0.5381312444806099, Final Batch Loss: 0.12376011162996292\n",
      "Epoch 3875, Loss: 0.4560343474149704, Final Batch Loss: 0.16487416625022888\n",
      "Epoch 3876, Loss: 0.43312952667474747, Final Batch Loss: 0.1875673532485962\n",
      "Epoch 3877, Loss: 0.43839623034000397, Final Batch Loss: 0.13308945298194885\n",
      "Epoch 3878, Loss: 0.5260285586118698, Final Batch Loss: 0.23636740446090698\n",
      "Epoch 3879, Loss: 0.5051195621490479, Final Batch Loss: 0.1704205870628357\n",
      "Epoch 3880, Loss: 0.43490272760391235, Final Batch Loss: 0.14680111408233643\n",
      "Epoch 3881, Loss: 0.47358059138059616, Final Batch Loss: 0.2441757172346115\n",
      "Epoch 3882, Loss: 0.6276375204324722, Final Batch Loss: 0.2706765830516815\n",
      "Epoch 3883, Loss: 0.44710811227560043, Final Batch Loss: 0.0998212918639183\n",
      "Epoch 3884, Loss: 0.4330795258283615, Final Batch Loss: 0.14871267974376678\n",
      "Epoch 3885, Loss: 0.4824074059724808, Final Batch Loss: 0.2020268738269806\n",
      "Epoch 3886, Loss: 0.47144272923469543, Final Batch Loss: 0.128608837723732\n",
      "Epoch 3887, Loss: 0.4404262527823448, Final Batch Loss: 0.09980941563844681\n",
      "Epoch 3888, Loss: 0.41037970036268234, Final Batch Loss: 0.1058628186583519\n",
      "Epoch 3889, Loss: 0.39932240545749664, Final Batch Loss: 0.13816387951374054\n",
      "Epoch 3890, Loss: 0.4340973347425461, Final Batch Loss: 0.129159614443779\n",
      "Epoch 3891, Loss: 0.4537724703550339, Final Batch Loss: 0.16800855100154877\n",
      "Epoch 3892, Loss: 0.4430268704891205, Final Batch Loss: 0.17015114426612854\n",
      "Epoch 3893, Loss: 0.40695446729660034, Final Batch Loss: 0.11288067698478699\n",
      "Epoch 3894, Loss: 0.48297515511512756, Final Batch Loss: 0.15734528005123138\n",
      "Epoch 3895, Loss: 0.5859173238277435, Final Batch Loss: 0.19803805649280548\n",
      "Epoch 3896, Loss: 0.5247853994369507, Final Batch Loss: 0.2093266248703003\n",
      "Epoch 3897, Loss: 0.4115103557705879, Final Batch Loss: 0.15912646055221558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3898, Loss: 0.4519065394997597, Final Batch Loss: 0.11892367154359818\n",
      "Epoch 3899, Loss: 0.42820674926042557, Final Batch Loss: 0.14218489825725555\n",
      "Epoch 3900, Loss: 0.42760802060365677, Final Batch Loss: 0.15200552344322205\n",
      "Epoch 3901, Loss: 0.4271625727415085, Final Batch Loss: 0.15124478936195374\n",
      "Epoch 3902, Loss: 0.33109086006879807, Final Batch Loss: 0.09233862906694412\n",
      "Epoch 3903, Loss: 0.47081804275512695, Final Batch Loss: 0.20353016257286072\n",
      "Epoch 3904, Loss: 0.4609333872795105, Final Batch Loss: 0.12662920355796814\n",
      "Epoch 3905, Loss: 0.4374536722898483, Final Batch Loss: 0.14691099524497986\n",
      "Epoch 3906, Loss: 0.4981062114238739, Final Batch Loss: 0.21810382604599\n",
      "Epoch 3907, Loss: 0.41792964190244675, Final Batch Loss: 0.13663065433502197\n",
      "Epoch 3908, Loss: 0.5001213699579239, Final Batch Loss: 0.2126775085926056\n",
      "Epoch 3909, Loss: 0.44275645166635513, Final Batch Loss: 0.1455715298652649\n",
      "Epoch 3910, Loss: 0.5444146394729614, Final Batch Loss: 0.1868695318698883\n",
      "Epoch 3911, Loss: 0.5040246099233627, Final Batch Loss: 0.14203472435474396\n",
      "Epoch 3912, Loss: 0.5598119050264359, Final Batch Loss: 0.2661328911781311\n",
      "Epoch 3913, Loss: 0.589479461312294, Final Batch Loss: 0.22050173580646515\n",
      "Epoch 3914, Loss: 0.49742382019758224, Final Batch Loss: 0.11059539765119553\n",
      "Epoch 3915, Loss: 0.42721816897392273, Final Batch Loss: 0.13053978979587555\n",
      "Epoch 3916, Loss: 0.5066340118646622, Final Batch Loss: 0.21473126113414764\n",
      "Epoch 3917, Loss: 0.5220701396465302, Final Batch Loss: 0.20150312781333923\n",
      "Epoch 3918, Loss: 0.37872257083654404, Final Batch Loss: 0.1292630136013031\n",
      "Epoch 3919, Loss: 0.45033906400203705, Final Batch Loss: 0.1574399620294571\n",
      "Epoch 3920, Loss: 0.5183239579200745, Final Batch Loss: 0.16531416773796082\n",
      "Epoch 3921, Loss: 0.41277940571308136, Final Batch Loss: 0.1239982545375824\n",
      "Epoch 3922, Loss: 0.44787733256816864, Final Batch Loss: 0.15268021821975708\n",
      "Epoch 3923, Loss: 0.5964958369731903, Final Batch Loss: 0.3495106101036072\n",
      "Epoch 3924, Loss: 0.5609926879405975, Final Batch Loss: 0.20659926533699036\n",
      "Epoch 3925, Loss: 0.42691613733768463, Final Batch Loss: 0.12519626319408417\n",
      "Epoch 3926, Loss: 0.522495374083519, Final Batch Loss: 0.1359599381685257\n",
      "Epoch 3927, Loss: 0.5672426074743271, Final Batch Loss: 0.20051933825016022\n",
      "Epoch 3928, Loss: 0.49546606093645096, Final Batch Loss: 0.20009943842887878\n",
      "Epoch 3929, Loss: 0.6004308313131332, Final Batch Loss: 0.22971521317958832\n",
      "Epoch 3930, Loss: 0.45868580788373947, Final Batch Loss: 0.09576661139726639\n",
      "Epoch 3931, Loss: 0.49504856765270233, Final Batch Loss: 0.16643978655338287\n",
      "Epoch 3932, Loss: 0.5131412744522095, Final Batch Loss: 0.21470995247364044\n",
      "Epoch 3933, Loss: 0.5122484564781189, Final Batch Loss: 0.20376358926296234\n",
      "Epoch 3934, Loss: 0.5746107548475266, Final Batch Loss: 0.25870779156684875\n",
      "Epoch 3935, Loss: 0.5559380501508713, Final Batch Loss: 0.24871958792209625\n",
      "Epoch 3936, Loss: 0.3920421749353409, Final Batch Loss: 0.1290748566389084\n",
      "Epoch 3937, Loss: 0.5477121770381927, Final Batch Loss: 0.26259180903434753\n",
      "Epoch 3938, Loss: 0.6052066683769226, Final Batch Loss: 0.22141438722610474\n",
      "Epoch 3939, Loss: 0.5034571588039398, Final Batch Loss: 0.13972920179367065\n",
      "Epoch 3940, Loss: 0.6153011918067932, Final Batch Loss: 0.26562559604644775\n",
      "Epoch 3941, Loss: 0.5513733178377151, Final Batch Loss: 0.17720678448677063\n",
      "Epoch 3942, Loss: 0.49342571198940277, Final Batch Loss: 0.18070103228092194\n",
      "Epoch 3943, Loss: 0.5469556152820587, Final Batch Loss: 0.17969194054603577\n",
      "Epoch 3944, Loss: 0.534009113907814, Final Batch Loss: 0.22149108350276947\n",
      "Epoch 3945, Loss: 0.4652024209499359, Final Batch Loss: 0.1548384577035904\n",
      "Epoch 3946, Loss: 0.40274444967508316, Final Batch Loss: 0.17835839092731476\n",
      "Epoch 3947, Loss: 0.4905548021197319, Final Batch Loss: 0.1276409775018692\n",
      "Epoch 3948, Loss: 0.5204516053199768, Final Batch Loss: 0.24473896622657776\n",
      "Epoch 3949, Loss: 0.5564077198505402, Final Batch Loss: 0.14274711906909943\n",
      "Epoch 3950, Loss: 0.45786402374505997, Final Batch Loss: 0.11583610624074936\n",
      "Epoch 3951, Loss: 0.5376656651496887, Final Batch Loss: 0.11879442632198334\n",
      "Epoch 3952, Loss: 0.50107641518116, Final Batch Loss: 0.20216971635818481\n",
      "Epoch 3953, Loss: 0.43307603895664215, Final Batch Loss: 0.13021278381347656\n",
      "Epoch 3954, Loss: 0.4981343299150467, Final Batch Loss: 0.16721254587173462\n",
      "Epoch 3955, Loss: 0.5664565712213516, Final Batch Loss: 0.1993657499551773\n",
      "Epoch 3956, Loss: 0.42434291541576385, Final Batch Loss: 0.14854124188423157\n",
      "Epoch 3957, Loss: 0.4202127978205681, Final Batch Loss: 0.11806891113519669\n",
      "Epoch 3958, Loss: 0.4006263390183449, Final Batch Loss: 0.18174375593662262\n",
      "Epoch 3959, Loss: 0.4226000979542732, Final Batch Loss: 0.10839573293924332\n",
      "Epoch 3960, Loss: 0.4157233238220215, Final Batch Loss: 0.08767841756343842\n",
      "Epoch 3961, Loss: 0.4530894085764885, Final Batch Loss: 0.19857026636600494\n",
      "Epoch 3962, Loss: 0.44729314744472504, Final Batch Loss: 0.14722521603107452\n",
      "Epoch 3963, Loss: 0.4367539659142494, Final Batch Loss: 0.08627618104219437\n",
      "Epoch 3964, Loss: 0.48471927642822266, Final Batch Loss: 0.16657735407352448\n",
      "Epoch 3965, Loss: 0.45732367038726807, Final Batch Loss: 0.18107642233371735\n",
      "Epoch 3966, Loss: 0.3354436084628105, Final Batch Loss: 0.0849141925573349\n",
      "Epoch 3967, Loss: 0.6266887038946152, Final Batch Loss: 0.3407926559448242\n",
      "Epoch 3968, Loss: 0.522063359618187, Final Batch Loss: 0.18883121013641357\n",
      "Epoch 3969, Loss: 0.5770806819200516, Final Batch Loss: 0.2780822813510895\n",
      "Epoch 3970, Loss: 0.49118758738040924, Final Batch Loss: 0.13228727877140045\n",
      "Epoch 3971, Loss: 0.6079114824533463, Final Batch Loss: 0.25710803270339966\n",
      "Epoch 3972, Loss: 0.4121870771050453, Final Batch Loss: 0.08966667950153351\n",
      "Epoch 3973, Loss: 0.44175511598587036, Final Batch Loss: 0.12425830215215683\n",
      "Epoch 3974, Loss: 0.5617530643939972, Final Batch Loss: 0.17929193377494812\n",
      "Epoch 3975, Loss: 0.37670326977968216, Final Batch Loss: 0.13313999772071838\n",
      "Epoch 3976, Loss: 0.5204648077487946, Final Batch Loss: 0.1729632467031479\n",
      "Epoch 3977, Loss: 0.5843627452850342, Final Batch Loss: 0.2509179413318634\n",
      "Epoch 3978, Loss: 0.4860279858112335, Final Batch Loss: 0.111829474568367\n",
      "Epoch 3979, Loss: 0.5109559893608093, Final Batch Loss: 0.17218081653118134\n",
      "Epoch 3980, Loss: 0.4873943477869034, Final Batch Loss: 0.16822053492069244\n",
      "Epoch 3981, Loss: 0.5855509042739868, Final Batch Loss: 0.15073040127754211\n",
      "Epoch 3982, Loss: 0.624091386795044, Final Batch Loss: 0.15001168847084045\n",
      "Epoch 3983, Loss: 0.6220141500234604, Final Batch Loss: 0.17690172791481018\n",
      "Epoch 3984, Loss: 0.5832274407148361, Final Batch Loss: 0.19321870803833008\n",
      "Epoch 3985, Loss: 0.5057803094387054, Final Batch Loss: 0.22489839792251587\n",
      "Epoch 3986, Loss: 0.5689345151185989, Final Batch Loss: 0.22596228122711182\n",
      "Epoch 3987, Loss: 0.47229255735874176, Final Batch Loss: 0.12974928319454193\n",
      "Epoch 3988, Loss: 0.5407269597053528, Final Batch Loss: 0.24378015100955963\n",
      "Epoch 3989, Loss: 0.5065162777900696, Final Batch Loss: 0.192110076546669\n",
      "Epoch 3990, Loss: 0.47650450468063354, Final Batch Loss: 0.21267686784267426\n",
      "Epoch 3991, Loss: 0.501729741692543, Final Batch Loss: 0.20914125442504883\n",
      "Epoch 3992, Loss: 0.5605992674827576, Final Batch Loss: 0.18683721125125885\n",
      "Epoch 3993, Loss: 0.5595468282699585, Final Batch Loss: 0.21832667291164398\n",
      "Epoch 3994, Loss: 0.470150463283062, Final Batch Loss: 0.12138447910547256\n",
      "Epoch 3995, Loss: 0.5087360143661499, Final Batch Loss: 0.1771230399608612\n",
      "Epoch 3996, Loss: 0.5214704275131226, Final Batch Loss: 0.1960502564907074\n",
      "Epoch 3997, Loss: 0.4902701824903488, Final Batch Loss: 0.2084081470966339\n",
      "Epoch 3998, Loss: 0.4876209795475006, Final Batch Loss: 0.14719358086585999\n",
      "Epoch 3999, Loss: 0.6058281362056732, Final Batch Loss: 0.18015435338020325\n",
      "Epoch 4000, Loss: 0.4803867042064667, Final Batch Loss: 0.20711472630500793\n",
      "Epoch 4001, Loss: 0.4298417195677757, Final Batch Loss: 0.14546522498130798\n",
      "Epoch 4002, Loss: 0.5357940196990967, Final Batch Loss: 0.2383469194173813\n",
      "Epoch 4003, Loss: 0.5023753345012665, Final Batch Loss: 0.13973376154899597\n",
      "Epoch 4004, Loss: 0.5451083332300186, Final Batch Loss: 0.2077377885580063\n",
      "Epoch 4005, Loss: 0.43395447731018066, Final Batch Loss: 0.1630711704492569\n",
      "Epoch 4006, Loss: 0.40658654272556305, Final Batch Loss: 0.16964289546012878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4007, Loss: 0.543335884809494, Final Batch Loss: 0.20847295224666595\n",
      "Epoch 4008, Loss: 0.4515165835618973, Final Batch Loss: 0.10835012793540955\n",
      "Epoch 4009, Loss: 0.4309379979968071, Final Batch Loss: 0.11124373227357864\n",
      "Epoch 4010, Loss: 0.4552306979894638, Final Batch Loss: 0.1471346616744995\n",
      "Epoch 4011, Loss: 0.446282796561718, Final Batch Loss: 0.12014428526163101\n",
      "Epoch 4012, Loss: 0.441914938390255, Final Batch Loss: 0.1423381268978119\n",
      "Epoch 4013, Loss: 0.4219699501991272, Final Batch Loss: 0.14417992532253265\n",
      "Epoch 4014, Loss: 0.426721453666687, Final Batch Loss: 0.13865035772323608\n",
      "Epoch 4015, Loss: 0.48323754966259, Final Batch Loss: 0.17237450182437897\n",
      "Epoch 4016, Loss: 0.5264323502779007, Final Batch Loss: 0.21176740527153015\n",
      "Epoch 4017, Loss: 0.5340807288885117, Final Batch Loss: 0.2205374538898468\n",
      "Epoch 4018, Loss: 0.45605092495679855, Final Batch Loss: 0.09724047034978867\n",
      "Epoch 4019, Loss: 0.5344423204660416, Final Batch Loss: 0.21425755321979523\n",
      "Epoch 4020, Loss: 0.49667419493198395, Final Batch Loss: 0.18937821686267853\n",
      "Epoch 4021, Loss: 0.4610612913966179, Final Batch Loss: 0.17586804926395416\n",
      "Epoch 4022, Loss: 0.5509758144617081, Final Batch Loss: 0.22649070620536804\n",
      "Epoch 4023, Loss: 0.6648715138435364, Final Batch Loss: 0.22027237713336945\n",
      "Epoch 4024, Loss: 0.4935559928417206, Final Batch Loss: 0.09659411013126373\n",
      "Epoch 4025, Loss: 0.45054779201745987, Final Batch Loss: 0.09971662610769272\n",
      "Epoch 4026, Loss: 0.46732504665851593, Final Batch Loss: 0.13979902863502502\n",
      "Epoch 4027, Loss: 0.5160336494445801, Final Batch Loss: 0.1622529774904251\n",
      "Epoch 4028, Loss: 0.5229177102446556, Final Batch Loss: 0.25367042422294617\n",
      "Epoch 4029, Loss: 0.5172219723463058, Final Batch Loss: 0.10541664063930511\n",
      "Epoch 4030, Loss: 0.4745655357837677, Final Batch Loss: 0.12317334115505219\n",
      "Epoch 4031, Loss: 0.40525101125240326, Final Batch Loss: 0.1441948115825653\n",
      "Epoch 4032, Loss: 0.46776672452688217, Final Batch Loss: 0.11650270968675613\n",
      "Epoch 4033, Loss: 0.4871266931295395, Final Batch Loss: 0.1598171591758728\n",
      "Epoch 4034, Loss: 0.47554874420166016, Final Batch Loss: 0.14130601286888123\n",
      "Epoch 4035, Loss: 0.447342187166214, Final Batch Loss: 0.16641037166118622\n",
      "Epoch 4036, Loss: 0.43421435356140137, Final Batch Loss: 0.13232707977294922\n",
      "Epoch 4037, Loss: 0.44341475516557693, Final Batch Loss: 0.11291538923978806\n",
      "Epoch 4038, Loss: 0.5169894099235535, Final Batch Loss: 0.23461493849754333\n",
      "Epoch 4039, Loss: 0.4550698548555374, Final Batch Loss: 0.12694419920444489\n",
      "Epoch 4040, Loss: 0.42296820133924484, Final Batch Loss: 0.13510677218437195\n",
      "Epoch 4041, Loss: 0.3794822320342064, Final Batch Loss: 0.10432376712560654\n",
      "Epoch 4042, Loss: 0.39756131917238235, Final Batch Loss: 0.1440666913986206\n",
      "Epoch 4043, Loss: 0.4901205003261566, Final Batch Loss: 0.20143061876296997\n",
      "Epoch 4044, Loss: 0.44440290331840515, Final Batch Loss: 0.1670057624578476\n",
      "Epoch 4045, Loss: 0.401637464761734, Final Batch Loss: 0.1351025551557541\n",
      "Epoch 4046, Loss: 0.47057804465293884, Final Batch Loss: 0.17697228491306305\n",
      "Epoch 4047, Loss: 0.4328656941652298, Final Batch Loss: 0.1328786015510559\n",
      "Epoch 4048, Loss: 0.32940006256103516, Final Batch Loss: 0.0802607461810112\n",
      "Epoch 4049, Loss: 0.42281588912010193, Final Batch Loss: 0.11711005866527557\n",
      "Epoch 4050, Loss: 0.43629443645477295, Final Batch Loss: 0.10497598350048065\n",
      "Epoch 4051, Loss: 0.6074730455875397, Final Batch Loss: 0.2044270783662796\n",
      "Epoch 4052, Loss: 0.451741062104702, Final Batch Loss: 0.17870882153511047\n",
      "Epoch 4053, Loss: 0.49509255588054657, Final Batch Loss: 0.14046929776668549\n",
      "Epoch 4054, Loss: 0.43252406269311905, Final Batch Loss: 0.12127524614334106\n",
      "Epoch 4055, Loss: 0.40871595591306686, Final Batch Loss: 0.09417270869016647\n",
      "Epoch 4056, Loss: 0.46619534492492676, Final Batch Loss: 0.1479770690202713\n",
      "Epoch 4057, Loss: 0.43937546014785767, Final Batch Loss: 0.12969933450222015\n",
      "Epoch 4058, Loss: 0.5066950172185898, Final Batch Loss: 0.22170411050319672\n",
      "Epoch 4059, Loss: 0.4452877342700958, Final Batch Loss: 0.18884529173374176\n",
      "Epoch 4060, Loss: 0.5503122061491013, Final Batch Loss: 0.23420356214046478\n",
      "Epoch 4061, Loss: 0.36964040994644165, Final Batch Loss: 0.11334528028964996\n",
      "Epoch 4062, Loss: 0.46540728211402893, Final Batch Loss: 0.12096510827541351\n",
      "Epoch 4063, Loss: 0.4730066955089569, Final Batch Loss: 0.1877921223640442\n",
      "Epoch 4064, Loss: 0.4103035107254982, Final Batch Loss: 0.1730479598045349\n",
      "Epoch 4065, Loss: 0.4592274948954582, Final Batch Loss: 0.19546371698379517\n",
      "Epoch 4066, Loss: 0.41256873309612274, Final Batch Loss: 0.09509141743183136\n",
      "Epoch 4067, Loss: 0.3534023016691208, Final Batch Loss: 0.07508872449398041\n",
      "Epoch 4068, Loss: 0.49878254532814026, Final Batch Loss: 0.2174818217754364\n",
      "Epoch 4069, Loss: 0.3920287936925888, Final Batch Loss: 0.12205876410007477\n",
      "Epoch 4070, Loss: 0.5494628250598907, Final Batch Loss: 0.16931550204753876\n",
      "Epoch 4071, Loss: 0.3883986175060272, Final Batch Loss: 0.10193581134080887\n",
      "Epoch 4072, Loss: 0.4825879856944084, Final Batch Loss: 0.11558029800653458\n",
      "Epoch 4073, Loss: 0.42347466200590134, Final Batch Loss: 0.1220782920718193\n",
      "Epoch 4074, Loss: 0.4106680303812027, Final Batch Loss: 0.07502487301826477\n",
      "Epoch 4075, Loss: 0.587776780128479, Final Batch Loss: 0.3066856563091278\n",
      "Epoch 4076, Loss: 0.4700314998626709, Final Batch Loss: 0.16150008141994476\n",
      "Epoch 4077, Loss: 0.6303086578845978, Final Batch Loss: 0.26628851890563965\n",
      "Epoch 4078, Loss: 0.46781185269355774, Final Batch Loss: 0.17832818627357483\n",
      "Epoch 4079, Loss: 0.4583951383829117, Final Batch Loss: 0.13571473956108093\n",
      "Epoch 4080, Loss: 0.4242657721042633, Final Batch Loss: 0.1341753900051117\n",
      "Epoch 4081, Loss: 0.4085053876042366, Final Batch Loss: 0.10443732142448425\n",
      "Epoch 4082, Loss: 0.5532993227243423, Final Batch Loss: 0.1974766105413437\n",
      "Epoch 4083, Loss: 0.44353801384568214, Final Batch Loss: 0.0606641061604023\n",
      "Epoch 4084, Loss: 0.5535258948802948, Final Batch Loss: 0.15736953914165497\n",
      "Epoch 4085, Loss: 0.5336036831140518, Final Batch Loss: 0.23246759176254272\n",
      "Epoch 4086, Loss: 0.5641161352396011, Final Batch Loss: 0.2742309272289276\n",
      "Epoch 4087, Loss: 0.4708053469657898, Final Batch Loss: 0.11713021993637085\n",
      "Epoch 4088, Loss: 0.3813433274626732, Final Batch Loss: 0.06538588553667068\n",
      "Epoch 4089, Loss: 0.4895207956433296, Final Batch Loss: 0.11675991863012314\n",
      "Epoch 4090, Loss: 0.42517416179180145, Final Batch Loss: 0.15561804175376892\n",
      "Epoch 4091, Loss: 0.5006146803498268, Final Batch Loss: 0.20552518963813782\n",
      "Epoch 4092, Loss: 0.5012351870536804, Final Batch Loss: 0.1868751347064972\n",
      "Epoch 4093, Loss: 0.490026131272316, Final Batch Loss: 0.17839765548706055\n",
      "Epoch 4094, Loss: 0.4611210450530052, Final Batch Loss: 0.10496100038290024\n",
      "Epoch 4095, Loss: 0.4204206019639969, Final Batch Loss: 0.1270754635334015\n",
      "Epoch 4096, Loss: 0.4930511713027954, Final Batch Loss: 0.20711283385753632\n",
      "Epoch 4097, Loss: 0.36678895354270935, Final Batch Loss: 0.13827283680438995\n",
      "Epoch 4098, Loss: 0.5011477768421173, Final Batch Loss: 0.18375810980796814\n",
      "Epoch 4099, Loss: 0.7667962610721588, Final Batch Loss: 0.23430173099040985\n",
      "Epoch 4100, Loss: 0.541880413889885, Final Batch Loss: 0.17850716412067413\n",
      "Epoch 4101, Loss: 0.4909343868494034, Final Batch Loss: 0.17938877642154694\n",
      "Epoch 4102, Loss: 0.44940225780010223, Final Batch Loss: 0.13892705738544464\n",
      "Epoch 4103, Loss: 0.47489622235298157, Final Batch Loss: 0.1573706567287445\n",
      "Epoch 4104, Loss: 0.4108918681740761, Final Batch Loss: 0.0876045748591423\n",
      "Epoch 4105, Loss: 0.528288796544075, Final Batch Loss: 0.19631856679916382\n",
      "Epoch 4106, Loss: 0.4983993172645569, Final Batch Loss: 0.2144184112548828\n",
      "Epoch 4107, Loss: 0.43268977850675583, Final Batch Loss: 0.08945468813180923\n",
      "Epoch 4108, Loss: 0.5553885251283646, Final Batch Loss: 0.17722658812999725\n",
      "Epoch 4109, Loss: 0.5596655756235123, Final Batch Loss: 0.19181495904922485\n",
      "Epoch 4110, Loss: 0.47973938286304474, Final Batch Loss: 0.10297349095344543\n",
      "Epoch 4111, Loss: 0.458920881152153, Final Batch Loss: 0.16491754353046417\n",
      "Epoch 4112, Loss: 0.4015587940812111, Final Batch Loss: 0.1134461835026741\n",
      "Epoch 4113, Loss: 0.41828786581754684, Final Batch Loss: 0.1297033280134201\n",
      "Epoch 4114, Loss: 0.6213163807988167, Final Batch Loss: 0.3284659683704376\n",
      "Epoch 4115, Loss: 0.5112565904855728, Final Batch Loss: 0.16491419076919556\n",
      "Epoch 4116, Loss: 0.3820280134677887, Final Batch Loss: 0.13249541819095612\n",
      "Epoch 4117, Loss: 0.5557506084442139, Final Batch Loss: 0.21281734108924866\n",
      "Epoch 4118, Loss: 0.4808533787727356, Final Batch Loss: 0.180325448513031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4119, Loss: 0.49878621101379395, Final Batch Loss: 0.16423022747039795\n",
      "Epoch 4120, Loss: 0.46984555572271347, Final Batch Loss: 0.23200710117816925\n",
      "Epoch 4121, Loss: 0.4800773784518242, Final Batch Loss: 0.22297319769859314\n",
      "Epoch 4122, Loss: 0.5409907102584839, Final Batch Loss: 0.22176815569400787\n",
      "Epoch 4123, Loss: 0.5342096090316772, Final Batch Loss: 0.1629806011915207\n",
      "Epoch 4124, Loss: 0.4608801230788231, Final Batch Loss: 0.11143790930509567\n",
      "Epoch 4125, Loss: 0.5589602589607239, Final Batch Loss: 0.2353031188249588\n",
      "Epoch 4126, Loss: 0.4063858762383461, Final Batch Loss: 0.09365183860063553\n",
      "Epoch 4127, Loss: 0.467831552028656, Final Batch Loss: 0.15079601109027863\n",
      "Epoch 4128, Loss: 0.45847006142139435, Final Batch Loss: 0.1472208946943283\n",
      "Epoch 4129, Loss: 0.46377788484096527, Final Batch Loss: 0.1669694036245346\n",
      "Epoch 4130, Loss: 0.49492843449115753, Final Batch Loss: 0.1848868876695633\n",
      "Epoch 4131, Loss: 0.41188327968120575, Final Batch Loss: 0.1354351043701172\n",
      "Epoch 4132, Loss: 0.4682392030954361, Final Batch Loss: 0.1455681174993515\n",
      "Epoch 4133, Loss: 0.477583184838295, Final Batch Loss: 0.18548133969306946\n",
      "Epoch 4134, Loss: 0.5023837983608246, Final Batch Loss: 0.1901465207338333\n",
      "Epoch 4135, Loss: 0.4683670550584793, Final Batch Loss: 0.1521504521369934\n",
      "Epoch 4136, Loss: 0.4179770052433014, Final Batch Loss: 0.1422046422958374\n",
      "Epoch 4137, Loss: 0.41256438195705414, Final Batch Loss: 0.1774967610836029\n",
      "Epoch 4138, Loss: 0.31192851811647415, Final Batch Loss: 0.06541956961154938\n",
      "Epoch 4139, Loss: 0.5350942611694336, Final Batch Loss: 0.18791744112968445\n",
      "Epoch 4140, Loss: 0.47616320848464966, Final Batch Loss: 0.1189686506986618\n",
      "Epoch 4141, Loss: 0.41391170769929886, Final Batch Loss: 0.15180781483650208\n",
      "Epoch 4142, Loss: 0.4443543031811714, Final Batch Loss: 0.22960743308067322\n",
      "Epoch 4143, Loss: 0.5683843791484833, Final Batch Loss: 0.16860221326351166\n",
      "Epoch 4144, Loss: 0.4876033067703247, Final Batch Loss: 0.15277007222175598\n",
      "Epoch 4145, Loss: 0.5159935504198074, Final Batch Loss: 0.2227022796869278\n",
      "Epoch 4146, Loss: 0.42097392678260803, Final Batch Loss: 0.13085505366325378\n",
      "Epoch 4147, Loss: 0.40773817151784897, Final Batch Loss: 0.14776228368282318\n",
      "Epoch 4148, Loss: 0.4869536906480789, Final Batch Loss: 0.20675237476825714\n",
      "Epoch 4149, Loss: 0.5393741577863693, Final Batch Loss: 0.2461622655391693\n",
      "Epoch 4150, Loss: 0.4979564994573593, Final Batch Loss: 0.19160236418247223\n",
      "Epoch 4151, Loss: 0.39631202071905136, Final Batch Loss: 0.14788086712360382\n",
      "Epoch 4152, Loss: 0.4596639350056648, Final Batch Loss: 0.15118630230426788\n",
      "Epoch 4153, Loss: 0.472744345664978, Final Batch Loss: 0.15614154934883118\n",
      "Epoch 4154, Loss: 0.6001820862293243, Final Batch Loss: 0.2560831606388092\n",
      "Epoch 4155, Loss: 0.5052851364016533, Final Batch Loss: 0.21940650045871735\n",
      "Epoch 4156, Loss: 0.5133151561021805, Final Batch Loss: 0.09398049116134644\n",
      "Epoch 4157, Loss: 0.4722011983394623, Final Batch Loss: 0.1856047660112381\n",
      "Epoch 4158, Loss: 0.5475341081619263, Final Batch Loss: 0.21034467220306396\n",
      "Epoch 4159, Loss: 0.4442299157381058, Final Batch Loss: 0.16593211889266968\n",
      "Epoch 4160, Loss: 0.505019873380661, Final Batch Loss: 0.10119935870170593\n",
      "Epoch 4161, Loss: 0.5161696597933769, Final Batch Loss: 0.21163854002952576\n",
      "Epoch 4162, Loss: 0.5656357109546661, Final Batch Loss: 0.18752780556678772\n",
      "Epoch 4163, Loss: 0.5363174229860306, Final Batch Loss: 0.15903684496879578\n",
      "Epoch 4164, Loss: 0.4945996627211571, Final Batch Loss: 0.2289074957370758\n",
      "Epoch 4165, Loss: 0.3864300325512886, Final Batch Loss: 0.12305843085050583\n",
      "Epoch 4166, Loss: 0.47168800234794617, Final Batch Loss: 0.15908925235271454\n",
      "Epoch 4167, Loss: 0.5076809823513031, Final Batch Loss: 0.14143653213977814\n",
      "Epoch 4168, Loss: 0.38626257330179214, Final Batch Loss: 0.10120498389005661\n",
      "Epoch 4169, Loss: 0.47521425783634186, Final Batch Loss: 0.16322892904281616\n",
      "Epoch 4170, Loss: 0.4993465542793274, Final Batch Loss: 0.13746586441993713\n",
      "Epoch 4171, Loss: 0.548136293888092, Final Batch Loss: 0.183651864528656\n",
      "Epoch 4172, Loss: 0.44532468914985657, Final Batch Loss: 0.1490190625190735\n",
      "Epoch 4173, Loss: 0.4285692870616913, Final Batch Loss: 0.12388460338115692\n",
      "Epoch 4174, Loss: 0.46102527529001236, Final Batch Loss: 0.12457098811864853\n",
      "Epoch 4175, Loss: 0.5212863236665726, Final Batch Loss: 0.15062257647514343\n",
      "Epoch 4176, Loss: 0.4732344299554825, Final Batch Loss: 0.1929105818271637\n",
      "Epoch 4177, Loss: 0.42688602209091187, Final Batch Loss: 0.09403710067272186\n",
      "Epoch 4178, Loss: 0.47061652690172195, Final Batch Loss: 0.1081996038556099\n",
      "Epoch 4179, Loss: 0.4337485209107399, Final Batch Loss: 0.16346952319145203\n",
      "Epoch 4180, Loss: 0.5439325869083405, Final Batch Loss: 0.23981653153896332\n",
      "Epoch 4181, Loss: 0.4445612207055092, Final Batch Loss: 0.11952405422925949\n",
      "Epoch 4182, Loss: 0.37555990368127823, Final Batch Loss: 0.11051521450281143\n",
      "Epoch 4183, Loss: 0.35382796823978424, Final Batch Loss: 0.11037151515483856\n",
      "Epoch 4184, Loss: 0.437200129032135, Final Batch Loss: 0.09472298622131348\n",
      "Epoch 4185, Loss: 0.46415338665246964, Final Batch Loss: 0.1162625402212143\n",
      "Epoch 4186, Loss: 0.4240269064903259, Final Batch Loss: 0.09373229742050171\n",
      "Epoch 4187, Loss: 0.4826832786202431, Final Batch Loss: 0.09571949392557144\n",
      "Epoch 4188, Loss: 0.4970030337572098, Final Batch Loss: 0.2147873044013977\n",
      "Epoch 4189, Loss: 0.5569179803133011, Final Batch Loss: 0.1901049166917801\n",
      "Epoch 4190, Loss: 0.4220731407403946, Final Batch Loss: 0.14346197247505188\n",
      "Epoch 4191, Loss: 0.480825312435627, Final Batch Loss: 0.21566356718540192\n",
      "Epoch 4192, Loss: 0.4504866674542427, Final Batch Loss: 0.19678223133087158\n",
      "Epoch 4193, Loss: 0.37628933042287827, Final Batch Loss: 0.11398850381374359\n",
      "Epoch 4194, Loss: 0.47444622218608856, Final Batch Loss: 0.16176284849643707\n",
      "Epoch 4195, Loss: 0.5089525729417801, Final Batch Loss: 0.16946865618228912\n",
      "Epoch 4196, Loss: 0.37285637110471725, Final Batch Loss: 0.11545833200216293\n",
      "Epoch 4197, Loss: 0.404488280415535, Final Batch Loss: 0.06436100602149963\n",
      "Epoch 4198, Loss: 0.5341465473175049, Final Batch Loss: 0.15894855558872223\n",
      "Epoch 4199, Loss: 0.43987513333559036, Final Batch Loss: 0.10625917464494705\n",
      "Epoch 4200, Loss: 0.37565265595912933, Final Batch Loss: 0.061480000615119934\n",
      "Epoch 4201, Loss: 0.4544357880949974, Final Batch Loss: 0.06996966153383255\n",
      "Epoch 4202, Loss: 0.4459635838866234, Final Batch Loss: 0.12786628305912018\n",
      "Epoch 4203, Loss: 0.4081701412796974, Final Batch Loss: 0.12604838609695435\n",
      "Epoch 4204, Loss: 0.42082779109477997, Final Batch Loss: 0.13252504169940948\n",
      "Epoch 4205, Loss: 0.45839741826057434, Final Batch Loss: 0.19033615291118622\n",
      "Epoch 4206, Loss: 0.46901835501194, Final Batch Loss: 0.23744016885757446\n",
      "Epoch 4207, Loss: 0.3504917547106743, Final Batch Loss: 0.10630419105291367\n",
      "Epoch 4208, Loss: 0.40045348554849625, Final Batch Loss: 0.15258292853832245\n",
      "Epoch 4209, Loss: 0.4845026135444641, Final Batch Loss: 0.18940728902816772\n",
      "Epoch 4210, Loss: 0.49975746870040894, Final Batch Loss: 0.20147573947906494\n",
      "Epoch 4211, Loss: 0.5854965150356293, Final Batch Loss: 0.24612486362457275\n",
      "Epoch 4212, Loss: 0.36582019180059433, Final Batch Loss: 0.08410904556512833\n",
      "Epoch 4213, Loss: 0.4603486657142639, Final Batch Loss: 0.15702220797538757\n",
      "Epoch 4214, Loss: 0.45252835005521774, Final Batch Loss: 0.11530757695436478\n",
      "Epoch 4215, Loss: 0.4396273046731949, Final Batch Loss: 0.1726585328578949\n",
      "Epoch 4216, Loss: 0.4430926516652107, Final Batch Loss: 0.17507874965667725\n",
      "Epoch 4217, Loss: 0.4792461320757866, Final Batch Loss: 0.1874399483203888\n",
      "Epoch 4218, Loss: 0.4531712755560875, Final Batch Loss: 0.1424386203289032\n",
      "Epoch 4219, Loss: 0.4538693502545357, Final Batch Loss: 0.19841398298740387\n",
      "Epoch 4220, Loss: 0.4545027166604996, Final Batch Loss: 0.1796479970216751\n",
      "Epoch 4221, Loss: 0.43706436455249786, Final Batch Loss: 0.13489720225334167\n",
      "Epoch 4222, Loss: 0.48511528968811035, Final Batch Loss: 0.1798001527786255\n",
      "Epoch 4223, Loss: 0.44916145503520966, Final Batch Loss: 0.15961027145385742\n",
      "Epoch 4224, Loss: 0.3938899487257004, Final Batch Loss: 0.09705057740211487\n",
      "Epoch 4225, Loss: 0.4105374738574028, Final Batch Loss: 0.14470383524894714\n",
      "Epoch 4226, Loss: 0.4590856432914734, Final Batch Loss: 0.13806070387363434\n",
      "Epoch 4227, Loss: 0.5352800041437149, Final Batch Loss: 0.22687773406505585\n",
      "Epoch 4228, Loss: 0.5063109844923019, Final Batch Loss: 0.1360550820827484\n",
      "Epoch 4229, Loss: 0.558892086148262, Final Batch Loss: 0.27415844798088074\n",
      "Epoch 4230, Loss: 0.48918892443180084, Final Batch Loss: 0.15937280654907227\n",
      "Epoch 4231, Loss: 0.5256605446338654, Final Batch Loss: 0.13842783868312836\n",
      "Epoch 4232, Loss: 0.5382082462310791, Final Batch Loss: 0.2035185545682907\n",
      "Epoch 4233, Loss: 0.4020032584667206, Final Batch Loss: 0.15372779965400696\n",
      "Epoch 4234, Loss: 0.3348686322569847, Final Batch Loss: 0.12807965278625488\n",
      "Epoch 4235, Loss: 0.3904958665370941, Final Batch Loss: 0.16506162285804749\n",
      "Epoch 4236, Loss: 0.38020261377096176, Final Batch Loss: 0.10421347618103027\n",
      "Epoch 4237, Loss: 0.4796936511993408, Final Batch Loss: 0.18078167736530304\n",
      "Epoch 4238, Loss: 0.48706743121147156, Final Batch Loss: 0.16331081092357635\n",
      "Epoch 4239, Loss: 0.3874081000685692, Final Batch Loss: 0.10675344616174698\n",
      "Epoch 4240, Loss: 0.46767115592956543, Final Batch Loss: 0.18147452175617218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4241, Loss: 0.4818027690052986, Final Batch Loss: 0.16396573185920715\n",
      "Epoch 4242, Loss: 0.5551689118146896, Final Batch Loss: 0.1488662213087082\n",
      "Epoch 4243, Loss: 0.4221902936697006, Final Batch Loss: 0.12639859318733215\n",
      "Epoch 4244, Loss: 0.4179754704236984, Final Batch Loss: 0.20007048547267914\n",
      "Epoch 4245, Loss: 0.509505495429039, Final Batch Loss: 0.17010067403316498\n",
      "Epoch 4246, Loss: 0.46283090859651566, Final Batch Loss: 0.18938016891479492\n",
      "Epoch 4247, Loss: 0.4373399168252945, Final Batch Loss: 0.13538408279418945\n",
      "Epoch 4248, Loss: 0.3945862054824829, Final Batch Loss: 0.15776383876800537\n",
      "Epoch 4249, Loss: 0.4258541688323021, Final Batch Loss: 0.11438766866922379\n",
      "Epoch 4250, Loss: 0.46003973484039307, Final Batch Loss: 0.15005415678024292\n",
      "Epoch 4251, Loss: 0.5305577516555786, Final Batch Loss: 0.14641201496124268\n",
      "Epoch 4252, Loss: 0.45872293412685394, Final Batch Loss: 0.16653740406036377\n",
      "Epoch 4253, Loss: 0.5046360343694687, Final Batch Loss: 0.22177579998970032\n",
      "Epoch 4254, Loss: 0.5273076593875885, Final Batch Loss: 0.20920762419700623\n",
      "Epoch 4255, Loss: 0.44051624089479446, Final Batch Loss: 0.09102652221918106\n",
      "Epoch 4256, Loss: 0.5571544468402863, Final Batch Loss: 0.1602984368801117\n",
      "Epoch 4257, Loss: 0.4641505181789398, Final Batch Loss: 0.17922808229923248\n",
      "Epoch 4258, Loss: 0.46543239057064056, Final Batch Loss: 0.14826618134975433\n",
      "Epoch 4259, Loss: 0.5323183983564377, Final Batch Loss: 0.17637431621551514\n",
      "Epoch 4260, Loss: 0.44737233221530914, Final Batch Loss: 0.16149386763572693\n",
      "Epoch 4261, Loss: 0.5255250185728073, Final Batch Loss: 0.2173893004655838\n",
      "Epoch 4262, Loss: 0.42595501244068146, Final Batch Loss: 0.1428670585155487\n",
      "Epoch 4263, Loss: 0.4398963674902916, Final Batch Loss: 0.16018718481063843\n",
      "Epoch 4264, Loss: 0.460871659219265, Final Batch Loss: 0.11892854422330856\n",
      "Epoch 4265, Loss: 0.4708315432071686, Final Batch Loss: 0.1912822276353836\n",
      "Epoch 4266, Loss: 0.4694712311029434, Final Batch Loss: 0.13649946451187134\n",
      "Epoch 4267, Loss: 0.3534170165657997, Final Batch Loss: 0.13115762174129486\n",
      "Epoch 4268, Loss: 0.43647874146699905, Final Batch Loss: 0.16113637387752533\n",
      "Epoch 4269, Loss: 0.5349889099597931, Final Batch Loss: 0.20177564024925232\n",
      "Epoch 4270, Loss: 0.4613049104809761, Final Batch Loss: 0.19376109540462494\n",
      "Epoch 4271, Loss: 0.4412859156727791, Final Batch Loss: 0.10306032747030258\n",
      "Epoch 4272, Loss: 0.43735481798648834, Final Batch Loss: 0.13304080069065094\n",
      "Epoch 4273, Loss: 0.42318905889987946, Final Batch Loss: 0.13021434843540192\n",
      "Epoch 4274, Loss: 0.48734576255083084, Final Batch Loss: 0.18670973181724548\n",
      "Epoch 4275, Loss: 0.42733094841241837, Final Batch Loss: 0.1264691799879074\n",
      "Epoch 4276, Loss: 0.43985317647457123, Final Batch Loss: 0.16119401156902313\n",
      "Epoch 4277, Loss: 0.351369209587574, Final Batch Loss: 0.09924803674221039\n",
      "Epoch 4278, Loss: 0.4865669757127762, Final Batch Loss: 0.14326049387454987\n",
      "Epoch 4279, Loss: 0.4607169181108475, Final Batch Loss: 0.1868012398481369\n",
      "Epoch 4280, Loss: 0.33636241406202316, Final Batch Loss: 0.11630502343177795\n",
      "Epoch 4281, Loss: 0.4018041118979454, Final Batch Loss: 0.14224770665168762\n",
      "Epoch 4282, Loss: 0.4204453229904175, Final Batch Loss: 0.11180256307125092\n",
      "Epoch 4283, Loss: 0.4176024794578552, Final Batch Loss: 0.1252763420343399\n",
      "Epoch 4284, Loss: 0.4888901710510254, Final Batch Loss: 0.16259333491325378\n",
      "Epoch 4285, Loss: 0.4365784302353859, Final Batch Loss: 0.21323099732398987\n",
      "Epoch 4286, Loss: 0.4520236477255821, Final Batch Loss: 0.11564647406339645\n",
      "Epoch 4287, Loss: 0.38406437635421753, Final Batch Loss: 0.12759153544902802\n",
      "Epoch 4288, Loss: 0.31560391187667847, Final Batch Loss: 0.06872405856847763\n",
      "Epoch 4289, Loss: 0.500738263130188, Final Batch Loss: 0.15787354111671448\n",
      "Epoch 4290, Loss: 0.4511517956852913, Final Batch Loss: 0.1464865356683731\n",
      "Epoch 4291, Loss: 0.4077460318803787, Final Batch Loss: 0.15008889138698578\n",
      "Epoch 4292, Loss: 0.5764377564191818, Final Batch Loss: 0.19960512220859528\n",
      "Epoch 4293, Loss: 0.4444214105606079, Final Batch Loss: 0.10437348484992981\n",
      "Epoch 4294, Loss: 0.49130839109420776, Final Batch Loss: 0.13977588713169098\n",
      "Epoch 4295, Loss: 0.39577585458755493, Final Batch Loss: 0.07753273844718933\n",
      "Epoch 4296, Loss: 0.44655580073595047, Final Batch Loss: 0.11347950249910355\n",
      "Epoch 4297, Loss: 0.4891975075006485, Final Batch Loss: 0.16915792226791382\n",
      "Epoch 4298, Loss: 0.43267619609832764, Final Batch Loss: 0.14227674901485443\n",
      "Epoch 4299, Loss: 0.5409020185470581, Final Batch Loss: 0.18481913208961487\n",
      "Epoch 4300, Loss: 0.3918195143342018, Final Batch Loss: 0.1152670830488205\n",
      "Epoch 4301, Loss: 0.5980113595724106, Final Batch Loss: 0.19686561822891235\n",
      "Epoch 4302, Loss: 0.4857064187526703, Final Batch Loss: 0.1661638617515564\n",
      "Epoch 4303, Loss: 0.42143069952726364, Final Batch Loss: 0.12206598371267319\n",
      "Epoch 4304, Loss: 0.5469167232513428, Final Batch Loss: 0.20033252239227295\n",
      "Epoch 4305, Loss: 0.4744999259710312, Final Batch Loss: 0.1412132978439331\n",
      "Epoch 4306, Loss: 0.5408426523208618, Final Batch Loss: 0.23057642579078674\n",
      "Epoch 4307, Loss: 0.5315992385149002, Final Batch Loss: 0.18162895739078522\n",
      "Epoch 4308, Loss: 0.5280603021383286, Final Batch Loss: 0.1736249327659607\n",
      "Epoch 4309, Loss: 0.37866851687431335, Final Batch Loss: 0.12433350831270218\n",
      "Epoch 4310, Loss: 0.6303333044052124, Final Batch Loss: 0.27835068106651306\n",
      "Epoch 4311, Loss: 0.5531955361366272, Final Batch Loss: 0.14802689850330353\n",
      "Epoch 4312, Loss: 0.4364033639431, Final Batch Loss: 0.12505614757537842\n",
      "Epoch 4313, Loss: 0.500537782907486, Final Batch Loss: 0.20085719227790833\n",
      "Epoch 4314, Loss: 0.4419412910938263, Final Batch Loss: 0.12608012557029724\n",
      "Epoch 4315, Loss: 0.5315755978226662, Final Batch Loss: 0.2109500616788864\n",
      "Epoch 4316, Loss: 0.48710744082927704, Final Batch Loss: 0.22869226336479187\n",
      "Epoch 4317, Loss: 0.4262525141239166, Final Batch Loss: 0.22801969945430756\n",
      "Epoch 4318, Loss: 0.5493342727422714, Final Batch Loss: 0.1761966049671173\n",
      "Epoch 4319, Loss: 0.39787787944078445, Final Batch Loss: 0.17919029295444489\n",
      "Epoch 4320, Loss: 0.4166066274046898, Final Batch Loss: 0.11910922080278397\n",
      "Epoch 4321, Loss: 0.41938352584838867, Final Batch Loss: 0.1483461707830429\n",
      "Epoch 4322, Loss: 0.38098613172769547, Final Batch Loss: 0.0718037411570549\n",
      "Epoch 4323, Loss: 0.4297315627336502, Final Batch Loss: 0.15420754253864288\n",
      "Epoch 4324, Loss: 0.545057862997055, Final Batch Loss: 0.20340195298194885\n",
      "Epoch 4325, Loss: 0.5071627348661423, Final Batch Loss: 0.1617514044046402\n",
      "Epoch 4326, Loss: 0.4636565297842026, Final Batch Loss: 0.1506262719631195\n",
      "Epoch 4327, Loss: 0.40633517503738403, Final Batch Loss: 0.12960489094257355\n",
      "Epoch 4328, Loss: 0.5057327896356583, Final Batch Loss: 0.19917014241218567\n",
      "Epoch 4329, Loss: 0.4271141290664673, Final Batch Loss: 0.10363908112049103\n",
      "Epoch 4330, Loss: 0.42338908463716507, Final Batch Loss: 0.13588204979896545\n",
      "Epoch 4331, Loss: 0.47130514681339264, Final Batch Loss: 0.17625686526298523\n",
      "Epoch 4332, Loss: 0.4271867871284485, Final Batch Loss: 0.19278526306152344\n",
      "Epoch 4333, Loss: 0.45168250799179077, Final Batch Loss: 0.1101878434419632\n",
      "Epoch 4334, Loss: 0.33079197257757187, Final Batch Loss: 0.10240179300308228\n",
      "Epoch 4335, Loss: 0.4470900222659111, Final Batch Loss: 0.18482932448387146\n",
      "Epoch 4336, Loss: 0.42115965485572815, Final Batch Loss: 0.07641315460205078\n",
      "Epoch 4337, Loss: 0.46391797065734863, Final Batch Loss: 0.1792469322681427\n",
      "Epoch 4338, Loss: 0.47330421209335327, Final Batch Loss: 0.14838305115699768\n",
      "Epoch 4339, Loss: 0.539990097284317, Final Batch Loss: 0.21126002073287964\n",
      "Epoch 4340, Loss: 0.5508357286453247, Final Batch Loss: 0.11976809799671173\n",
      "Epoch 4341, Loss: 0.42606163769960403, Final Batch Loss: 0.0772298201918602\n",
      "Epoch 4342, Loss: 0.5702589005231857, Final Batch Loss: 0.16975627839565277\n",
      "Epoch 4343, Loss: 0.47173280268907547, Final Batch Loss: 0.13211430609226227\n",
      "Epoch 4344, Loss: 0.385396771132946, Final Batch Loss: 0.13366444408893585\n",
      "Epoch 4345, Loss: 0.4525570869445801, Final Batch Loss: 0.12813600897789001\n",
      "Epoch 4346, Loss: 0.44020290672779083, Final Batch Loss: 0.1046028882265091\n",
      "Epoch 4347, Loss: 0.6123258769512177, Final Batch Loss: 0.2823408544063568\n",
      "Epoch 4348, Loss: 0.3839927837252617, Final Batch Loss: 0.12669344246387482\n",
      "Epoch 4349, Loss: 0.3847833424806595, Final Batch Loss: 0.07832534611225128\n",
      "Epoch 4350, Loss: 0.3522684797644615, Final Batch Loss: 0.12593676149845123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4351, Loss: 0.36749112606048584, Final Batch Loss: 0.14817656576633453\n",
      "Epoch 4352, Loss: 0.382075272500515, Final Batch Loss: 0.13276712596416473\n",
      "Epoch 4353, Loss: 0.4659940227866173, Final Batch Loss: 0.1790516972541809\n",
      "Epoch 4354, Loss: 0.44725801050662994, Final Batch Loss: 0.15324996411800385\n",
      "Epoch 4355, Loss: 0.4459941238164902, Final Batch Loss: 0.1439828872680664\n",
      "Epoch 4356, Loss: 0.4533892720937729, Final Batch Loss: 0.14941100776195526\n",
      "Epoch 4357, Loss: 0.3789600431919098, Final Batch Loss: 0.14734874665737152\n",
      "Epoch 4358, Loss: 0.4624931067228317, Final Batch Loss: 0.14312821626663208\n",
      "Epoch 4359, Loss: 0.4624970704317093, Final Batch Loss: 0.14112521708011627\n",
      "Epoch 4360, Loss: 0.44034530222415924, Final Batch Loss: 0.11757165193557739\n",
      "Epoch 4361, Loss: 0.4389045238494873, Final Batch Loss: 0.15578539669513702\n",
      "Epoch 4362, Loss: 0.36707621812820435, Final Batch Loss: 0.07781621813774109\n",
      "Epoch 4363, Loss: 0.4041895344853401, Final Batch Loss: 0.13476814329624176\n",
      "Epoch 4364, Loss: 0.4925774037837982, Final Batch Loss: 0.17403839528560638\n",
      "Epoch 4365, Loss: 0.3323531448841095, Final Batch Loss: 0.11347269266843796\n",
      "Epoch 4366, Loss: 0.4693523794412613, Final Batch Loss: 0.1968805193901062\n",
      "Epoch 4367, Loss: 0.39947814494371414, Final Batch Loss: 0.11459597200155258\n",
      "Epoch 4368, Loss: 0.46564876288175583, Final Batch Loss: 0.12318568676710129\n",
      "Epoch 4369, Loss: 0.5023841559886932, Final Batch Loss: 0.13718189299106598\n",
      "Epoch 4370, Loss: 0.4786149635910988, Final Batch Loss: 0.17795182764530182\n",
      "Epoch 4371, Loss: 0.5369753539562225, Final Batch Loss: 0.2361380010843277\n",
      "Epoch 4372, Loss: 0.4076036959886551, Final Batch Loss: 0.12106551229953766\n",
      "Epoch 4373, Loss: 0.46948376297950745, Final Batch Loss: 0.17484045028686523\n",
      "Epoch 4374, Loss: 0.38935235887765884, Final Batch Loss: 0.06547413021326065\n",
      "Epoch 4375, Loss: 0.45166634768247604, Final Batch Loss: 0.15008622407913208\n",
      "Epoch 4376, Loss: 0.5376891866326332, Final Batch Loss: 0.2686803638935089\n",
      "Epoch 4377, Loss: 0.4500166028738022, Final Batch Loss: 0.14163827896118164\n",
      "Epoch 4378, Loss: 0.3682772293686867, Final Batch Loss: 0.09633397310972214\n",
      "Epoch 4379, Loss: 0.38673779368400574, Final Batch Loss: 0.166349396109581\n",
      "Epoch 4380, Loss: 0.46843670308589935, Final Batch Loss: 0.16033592820167542\n",
      "Epoch 4381, Loss: 0.41824304312467575, Final Batch Loss: 0.16101576387882233\n",
      "Epoch 4382, Loss: 0.47570979595184326, Final Batch Loss: 0.1344054937362671\n",
      "Epoch 4383, Loss: 0.4245765060186386, Final Batch Loss: 0.18760666251182556\n",
      "Epoch 4384, Loss: 0.5382249504327774, Final Batch Loss: 0.21010637283325195\n",
      "Epoch 4385, Loss: 0.4086053594946861, Final Batch Loss: 0.15946383774280548\n",
      "Epoch 4386, Loss: 0.4406315013766289, Final Batch Loss: 0.18396076560020447\n",
      "Epoch 4387, Loss: 0.32405727356672287, Final Batch Loss: 0.07004370540380478\n",
      "Epoch 4388, Loss: 0.48439735174179077, Final Batch Loss: 0.16154323518276215\n",
      "Epoch 4389, Loss: 0.46176260709762573, Final Batch Loss: 0.20729435980319977\n",
      "Epoch 4390, Loss: 0.49705734848976135, Final Batch Loss: 0.25055229663848877\n",
      "Epoch 4391, Loss: 0.446186788380146, Final Batch Loss: 0.11493974179029465\n",
      "Epoch 4392, Loss: 0.4162067621946335, Final Batch Loss: 0.13407142460346222\n",
      "Epoch 4393, Loss: 0.47219332307577133, Final Batch Loss: 0.19766393303871155\n",
      "Epoch 4394, Loss: 0.3927423059940338, Final Batch Loss: 0.11549455672502518\n",
      "Epoch 4395, Loss: 0.4616592526435852, Final Batch Loss: 0.12738879024982452\n",
      "Epoch 4396, Loss: 0.36720937490463257, Final Batch Loss: 0.09877479821443558\n",
      "Epoch 4397, Loss: 0.6789272427558899, Final Batch Loss: 0.24192996323108673\n",
      "Epoch 4398, Loss: 0.5167147815227509, Final Batch Loss: 0.21529057621955872\n",
      "Epoch 4399, Loss: 0.4392428696155548, Final Batch Loss: 0.14631246030330658\n",
      "Epoch 4400, Loss: 0.437542200088501, Final Batch Loss: 0.12861789762973785\n",
      "Epoch 4401, Loss: 0.49663911014795303, Final Batch Loss: 0.11075835675001144\n",
      "Epoch 4402, Loss: 0.4234326705336571, Final Batch Loss: 0.1090807095170021\n",
      "Epoch 4403, Loss: 0.4730628728866577, Final Batch Loss: 0.17757132649421692\n",
      "Epoch 4404, Loss: 0.4540211111307144, Final Batch Loss: 0.14839506149291992\n",
      "Epoch 4405, Loss: 0.4500920996069908, Final Batch Loss: 0.1613958477973938\n",
      "Epoch 4406, Loss: 0.4048565551638603, Final Batch Loss: 0.16702264547348022\n",
      "Epoch 4407, Loss: 0.4331635907292366, Final Batch Loss: 0.14346188306808472\n",
      "Epoch 4408, Loss: 0.4094398096203804, Final Batch Loss: 0.16170062124729156\n",
      "Epoch 4409, Loss: 0.4329680800437927, Final Batch Loss: 0.129953995347023\n",
      "Epoch 4410, Loss: 0.307437039911747, Final Batch Loss: 0.09351589530706406\n",
      "Epoch 4411, Loss: 0.4890202432870865, Final Batch Loss: 0.2025076150894165\n",
      "Epoch 4412, Loss: 0.3574058786034584, Final Batch Loss: 0.04648878425359726\n",
      "Epoch 4413, Loss: 0.4164779484272003, Final Batch Loss: 0.16118033230304718\n",
      "Epoch 4414, Loss: 0.42472127825021744, Final Batch Loss: 0.13749361038208008\n",
      "Epoch 4415, Loss: 0.4479156881570816, Final Batch Loss: 0.11513572931289673\n",
      "Epoch 4416, Loss: 0.5162187740206718, Final Batch Loss: 0.11209777742624283\n",
      "Epoch 4417, Loss: 0.5629786103963852, Final Batch Loss: 0.2765063941478729\n",
      "Epoch 4418, Loss: 0.4291898161172867, Final Batch Loss: 0.18039961159229279\n",
      "Epoch 4419, Loss: 0.5252061784267426, Final Batch Loss: 0.14634618163108826\n",
      "Epoch 4420, Loss: 0.4410364180803299, Final Batch Loss: 0.1494797170162201\n",
      "Epoch 4421, Loss: 0.5104061886668205, Final Batch Loss: 0.2503737509250641\n",
      "Epoch 4422, Loss: 0.5453167408704758, Final Batch Loss: 0.22771282494068146\n",
      "Epoch 4423, Loss: 0.3861754611134529, Final Batch Loss: 0.14804324507713318\n",
      "Epoch 4424, Loss: 0.5310467183589935, Final Batch Loss: 0.15216296911239624\n",
      "Epoch 4425, Loss: 0.3575281947851181, Final Batch Loss: 0.12237496674060822\n",
      "Epoch 4426, Loss: 0.5039387792348862, Final Batch Loss: 0.16446073353290558\n",
      "Epoch 4427, Loss: 0.399976022541523, Final Batch Loss: 0.11086560040712357\n",
      "Epoch 4428, Loss: 0.4703062102198601, Final Batch Loss: 0.082056425511837\n",
      "Epoch 4429, Loss: 0.35286614298820496, Final Batch Loss: 0.11577912420034409\n",
      "Epoch 4430, Loss: 0.4874066114425659, Final Batch Loss: 0.22669731080532074\n",
      "Epoch 4431, Loss: 0.5324973315000534, Final Batch Loss: 0.14482411742210388\n",
      "Epoch 4432, Loss: 0.4644700586795807, Final Batch Loss: 0.2089531570672989\n",
      "Epoch 4433, Loss: 0.4692112058401108, Final Batch Loss: 0.1571345031261444\n",
      "Epoch 4434, Loss: 0.36148015409708023, Final Batch Loss: 0.12786228954792023\n",
      "Epoch 4435, Loss: 0.40458060055971146, Final Batch Loss: 0.1629808098077774\n",
      "Epoch 4436, Loss: 0.40916235744953156, Final Batch Loss: 0.12604688107967377\n",
      "Epoch 4437, Loss: 0.4637391120195389, Final Batch Loss: 0.13664138317108154\n",
      "Epoch 4438, Loss: 0.5488798767328262, Final Batch Loss: 0.15871666371822357\n",
      "Epoch 4439, Loss: 0.48162229359149933, Final Batch Loss: 0.16550502181053162\n",
      "Epoch 4440, Loss: 0.5089656114578247, Final Batch Loss: 0.14329826831817627\n",
      "Epoch 4441, Loss: 0.39419347792863846, Final Batch Loss: 0.12760895490646362\n",
      "Epoch 4442, Loss: 0.48435281217098236, Final Batch Loss: 0.138041153550148\n",
      "Epoch 4443, Loss: 0.44127513468265533, Final Batch Loss: 0.14731989800930023\n",
      "Epoch 4444, Loss: 0.4277765601873398, Final Batch Loss: 0.13130392134189606\n",
      "Epoch 4445, Loss: 0.42629489302635193, Final Batch Loss: 0.16232892870903015\n",
      "Epoch 4446, Loss: 0.4149072542786598, Final Batch Loss: 0.1514914631843567\n",
      "Epoch 4447, Loss: 0.4429002106189728, Final Batch Loss: 0.19243834912776947\n",
      "Epoch 4448, Loss: 0.4065810889005661, Final Batch Loss: 0.1288224458694458\n",
      "Epoch 4449, Loss: 0.4897284358739853, Final Batch Loss: 0.1389307826757431\n",
      "Epoch 4450, Loss: 0.4737688899040222, Final Batch Loss: 0.14621113240718842\n",
      "Epoch 4451, Loss: 0.47572537511587143, Final Batch Loss: 0.20710572600364685\n",
      "Epoch 4452, Loss: 0.4598630368709564, Final Batch Loss: 0.206261545419693\n",
      "Epoch 4453, Loss: 0.5264477729797363, Final Batch Loss: 0.1983380913734436\n",
      "Epoch 4454, Loss: 0.4561353698372841, Final Batch Loss: 0.21100729703903198\n",
      "Epoch 4455, Loss: 0.6036653220653534, Final Batch Loss: 0.2630743384361267\n",
      "Epoch 4456, Loss: 0.35760563611984253, Final Batch Loss: 0.10623006522655487\n",
      "Epoch 4457, Loss: 0.5031238198280334, Final Batch Loss: 0.1909918338060379\n",
      "Epoch 4458, Loss: 0.46289463341236115, Final Batch Loss: 0.11420668661594391\n",
      "Epoch 4459, Loss: 0.4034230560064316, Final Batch Loss: 0.12712998688220978\n",
      "Epoch 4460, Loss: 0.4185432195663452, Final Batch Loss: 0.11108563840389252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4461, Loss: 0.5175869315862656, Final Batch Loss: 0.20400576293468475\n",
      "Epoch 4462, Loss: 0.48916900157928467, Final Batch Loss: 0.19591180980205536\n",
      "Epoch 4463, Loss: 0.3830753415822983, Final Batch Loss: 0.10857576876878738\n",
      "Epoch 4464, Loss: 0.3907480686903, Final Batch Loss: 0.12829622626304626\n",
      "Epoch 4465, Loss: 0.48197396099567413, Final Batch Loss: 0.17222222685813904\n",
      "Epoch 4466, Loss: 0.4444807320833206, Final Batch Loss: 0.2062644511461258\n",
      "Epoch 4467, Loss: 0.5025937408208847, Final Batch Loss: 0.15356917679309845\n",
      "Epoch 4468, Loss: 0.33970747888088226, Final Batch Loss: 0.08574207872152328\n",
      "Epoch 4469, Loss: 0.3707076385617256, Final Batch Loss: 0.18414358794689178\n",
      "Epoch 4470, Loss: 0.45024803280830383, Final Batch Loss: 0.1603337824344635\n",
      "Epoch 4471, Loss: 0.36999621242284775, Final Batch Loss: 0.09142584353685379\n",
      "Epoch 4472, Loss: 0.447088323533535, Final Batch Loss: 0.09512247890233994\n",
      "Epoch 4473, Loss: 0.4059614762663841, Final Batch Loss: 0.10668725520372391\n",
      "Epoch 4474, Loss: 0.3460822030901909, Final Batch Loss: 0.1153712272644043\n",
      "Epoch 4475, Loss: 0.4345710501074791, Final Batch Loss: 0.0701536014676094\n",
      "Epoch 4476, Loss: 0.38796280324459076, Final Batch Loss: 0.12860873341560364\n",
      "Epoch 4477, Loss: 0.4654870331287384, Final Batch Loss: 0.13467662036418915\n",
      "Epoch 4478, Loss: 0.4343551844358444, Final Batch Loss: 0.14005117118358612\n",
      "Epoch 4479, Loss: 0.5086385905742645, Final Batch Loss: 0.1871185004711151\n",
      "Epoch 4480, Loss: 0.3481130227446556, Final Batch Loss: 0.13658571243286133\n",
      "Epoch 4481, Loss: 0.3493167385458946, Final Batch Loss: 0.11574988812208176\n",
      "Epoch 4482, Loss: 0.5202611684799194, Final Batch Loss: 0.14557050168514252\n",
      "Epoch 4483, Loss: 0.5047391355037689, Final Batch Loss: 0.13040494918823242\n",
      "Epoch 4484, Loss: 0.553849384188652, Final Batch Loss: 0.14742885529994965\n",
      "Epoch 4485, Loss: 0.49960292130708694, Final Batch Loss: 0.10680856555700302\n",
      "Epoch 4486, Loss: 0.45000916719436646, Final Batch Loss: 0.16225586831569672\n",
      "Epoch 4487, Loss: 0.5886654853820801, Final Batch Loss: 0.1693771630525589\n",
      "Epoch 4488, Loss: 0.5182328671216965, Final Batch Loss: 0.09052608907222748\n",
      "Epoch 4489, Loss: 0.5321935713291168, Final Batch Loss: 0.1559252142906189\n",
      "Epoch 4490, Loss: 0.3791069909930229, Final Batch Loss: 0.1295715719461441\n",
      "Epoch 4491, Loss: 0.41105876863002777, Final Batch Loss: 0.06664755940437317\n",
      "Epoch 4492, Loss: 0.4014267474412918, Final Batch Loss: 0.10917013883590698\n",
      "Epoch 4493, Loss: 0.42377789318561554, Final Batch Loss: 0.08701963722705841\n",
      "Epoch 4494, Loss: 0.44527217745780945, Final Batch Loss: 0.1623699963092804\n",
      "Epoch 4495, Loss: 0.49550680816173553, Final Batch Loss: 0.18530547618865967\n",
      "Epoch 4496, Loss: 0.5083246678113937, Final Batch Loss: 0.20761017501354218\n",
      "Epoch 4497, Loss: 0.5266488045454025, Final Batch Loss: 0.19800499081611633\n",
      "Epoch 4498, Loss: 0.45039503276348114, Final Batch Loss: 0.1586935669183731\n",
      "Epoch 4499, Loss: 0.42834535241127014, Final Batch Loss: 0.1348467916250229\n",
      "Epoch 4500, Loss: 0.4959894195199013, Final Batch Loss: 0.22500333189964294\n",
      "Epoch 4501, Loss: 0.32345395535230637, Final Batch Loss: 0.0777161568403244\n",
      "Epoch 4502, Loss: 0.38865257799625397, Final Batch Loss: 0.07833841443061829\n",
      "Epoch 4503, Loss: 0.3825443759560585, Final Batch Loss: 0.08023806661367416\n",
      "Epoch 4504, Loss: 0.5458625853061676, Final Batch Loss: 0.1845751404762268\n",
      "Epoch 4505, Loss: 0.43493619561195374, Final Batch Loss: 0.18447448313236237\n",
      "Epoch 4506, Loss: 0.49690067768096924, Final Batch Loss: 0.20637677609920502\n",
      "Epoch 4507, Loss: 0.35100650787353516, Final Batch Loss: 0.15628570318222046\n",
      "Epoch 4508, Loss: 0.39404764771461487, Final Batch Loss: 0.1077403873205185\n",
      "Epoch 4509, Loss: 0.49113087356090546, Final Batch Loss: 0.18313676118850708\n",
      "Epoch 4510, Loss: 0.4348203092813492, Final Batch Loss: 0.1278974711894989\n",
      "Epoch 4511, Loss: 0.5193319022655487, Final Batch Loss: 0.16225285828113556\n",
      "Epoch 4512, Loss: 0.4514767676591873, Final Batch Loss: 0.13544036448001862\n",
      "Epoch 4513, Loss: 0.510238379240036, Final Batch Loss: 0.1303372085094452\n",
      "Epoch 4514, Loss: 0.4262552037835121, Final Batch Loss: 0.16074423491954803\n",
      "Epoch 4515, Loss: 0.40302515029907227, Final Batch Loss: 0.1007140725851059\n",
      "Epoch 4516, Loss: 0.3888663873076439, Final Batch Loss: 0.11774029582738876\n",
      "Epoch 4517, Loss: 0.3653419353067875, Final Batch Loss: 0.05804641172289848\n",
      "Epoch 4518, Loss: 0.45170243084430695, Final Batch Loss: 0.12569312751293182\n",
      "Epoch 4519, Loss: 0.3137897476553917, Final Batch Loss: 0.09238211065530777\n",
      "Epoch 4520, Loss: 0.36416228115558624, Final Batch Loss: 0.09418131411075592\n",
      "Epoch 4521, Loss: 0.3723418638110161, Final Batch Loss: 0.09519866853952408\n",
      "Epoch 4522, Loss: 0.5444283932447433, Final Batch Loss: 0.18082492053508759\n",
      "Epoch 4523, Loss: 0.45156094431877136, Final Batch Loss: 0.17689387500286102\n",
      "Epoch 4524, Loss: 0.4242151379585266, Final Batch Loss: 0.14320269227027893\n",
      "Epoch 4525, Loss: 0.43359143286943436, Final Batch Loss: 0.17987920343875885\n",
      "Epoch 4526, Loss: 0.4338124319911003, Final Batch Loss: 0.11939810961484909\n",
      "Epoch 4527, Loss: 0.5154650062322617, Final Batch Loss: 0.20811685919761658\n",
      "Epoch 4528, Loss: 0.47967788577079773, Final Batch Loss: 0.15350891649723053\n",
      "Epoch 4529, Loss: 0.4225648418068886, Final Batch Loss: 0.10580166429281235\n",
      "Epoch 4530, Loss: 0.4636502116918564, Final Batch Loss: 0.10275296866893768\n",
      "Epoch 4531, Loss: 0.5382324755191803, Final Batch Loss: 0.21877893805503845\n",
      "Epoch 4532, Loss: 0.4477725327014923, Final Batch Loss: 0.16828219592571259\n",
      "Epoch 4533, Loss: 0.3090357184410095, Final Batch Loss: 0.10310275107622147\n",
      "Epoch 4534, Loss: 0.41495269536972046, Final Batch Loss: 0.08881375193595886\n",
      "Epoch 4535, Loss: 0.44780465960502625, Final Batch Loss: 0.16660398244857788\n",
      "Epoch 4536, Loss: 0.49618759751319885, Final Batch Loss: 0.17843690514564514\n",
      "Epoch 4537, Loss: 0.3006017841398716, Final Batch Loss: 0.050499606877565384\n",
      "Epoch 4538, Loss: 0.40874431282281876, Final Batch Loss: 0.08918190747499466\n",
      "Epoch 4539, Loss: 0.48435428738594055, Final Batch Loss: 0.17506207525730133\n",
      "Epoch 4540, Loss: 0.3999413698911667, Final Batch Loss: 0.14930765330791473\n",
      "Epoch 4541, Loss: 0.42834941297769547, Final Batch Loss: 0.12887565791606903\n",
      "Epoch 4542, Loss: 0.4064113050699234, Final Batch Loss: 0.11660601198673248\n",
      "Epoch 4543, Loss: 0.481717012822628, Final Batch Loss: 0.18738335371017456\n",
      "Epoch 4544, Loss: 0.4187430590391159, Final Batch Loss: 0.09664623439311981\n",
      "Epoch 4545, Loss: 0.4514583945274353, Final Batch Loss: 0.17687290906906128\n",
      "Epoch 4546, Loss: 0.3841050863265991, Final Batch Loss: 0.13076083362102509\n",
      "Epoch 4547, Loss: 0.34394466131925583, Final Batch Loss: 0.1268182098865509\n",
      "Epoch 4548, Loss: 0.40812548249959946, Final Batch Loss: 0.18241603672504425\n",
      "Epoch 4549, Loss: 0.4492050111293793, Final Batch Loss: 0.12984533607959747\n",
      "Epoch 4550, Loss: 0.5838293433189392, Final Batch Loss: 0.22582322359085083\n",
      "Epoch 4551, Loss: 0.42802418023347855, Final Batch Loss: 0.10880777984857559\n",
      "Epoch 4552, Loss: 0.6605737209320068, Final Batch Loss: 0.2297617644071579\n",
      "Epoch 4553, Loss: 0.4731394350528717, Final Batch Loss: 0.1386181265115738\n",
      "Epoch 4554, Loss: 0.5068173259496689, Final Batch Loss: 0.16365107893943787\n",
      "Epoch 4555, Loss: 0.5422734841704369, Final Batch Loss: 0.20127402245998383\n",
      "Epoch 4556, Loss: 0.46551065146923065, Final Batch Loss: 0.19265444576740265\n",
      "Epoch 4557, Loss: 0.6227498352527618, Final Batch Loss: 0.19761048257350922\n",
      "Epoch 4558, Loss: 0.43870795518159866, Final Batch Loss: 0.09705062955617905\n",
      "Epoch 4559, Loss: 0.45712893456220627, Final Batch Loss: 0.12300295382738113\n",
      "Epoch 4560, Loss: 0.4976285696029663, Final Batch Loss: 0.13475210964679718\n",
      "Epoch 4561, Loss: 0.5292890518903732, Final Batch Loss: 0.21198244392871857\n",
      "Epoch 4562, Loss: 0.4978078603744507, Final Batch Loss: 0.17978285253047943\n",
      "Epoch 4563, Loss: 0.43079572916030884, Final Batch Loss: 0.14043232798576355\n",
      "Epoch 4564, Loss: 0.444869689643383, Final Batch Loss: 0.1678234487771988\n",
      "Epoch 4565, Loss: 0.3348904475569725, Final Batch Loss: 0.08469226956367493\n",
      "Epoch 4566, Loss: 0.52362160384655, Final Batch Loss: 0.1948106586933136\n",
      "Epoch 4567, Loss: 0.41972965747117996, Final Batch Loss: 0.16721071302890778\n",
      "Epoch 4568, Loss: 0.47951317578554153, Final Batch Loss: 0.1940992921590805\n",
      "Epoch 4569, Loss: 0.4385627284646034, Final Batch Loss: 0.14330804347991943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4570, Loss: 0.4024861827492714, Final Batch Loss: 0.09212318807840347\n",
      "Epoch 4571, Loss: 0.41857102513313293, Final Batch Loss: 0.1206682026386261\n",
      "Epoch 4572, Loss: 0.4701644256711006, Final Batch Loss: 0.21187938749790192\n",
      "Epoch 4573, Loss: 0.44288238883018494, Final Batch Loss: 0.11716386675834656\n",
      "Epoch 4574, Loss: 0.4317377880215645, Final Batch Loss: 0.12171999365091324\n",
      "Epoch 4575, Loss: 0.4335754066705704, Final Batch Loss: 0.09323610365390778\n",
      "Epoch 4576, Loss: 0.4734005033969879, Final Batch Loss: 0.14856591820716858\n",
      "Epoch 4577, Loss: 0.48505574464797974, Final Batch Loss: 0.22961847484111786\n",
      "Epoch 4578, Loss: 0.41743429005146027, Final Batch Loss: 0.14707739651203156\n",
      "Epoch 4579, Loss: 0.40979764610528946, Final Batch Loss: 0.11605644226074219\n",
      "Epoch 4580, Loss: 0.42518531531095505, Final Batch Loss: 0.16815723478794098\n",
      "Epoch 4581, Loss: 0.5007206425070763, Final Batch Loss: 0.22993361949920654\n",
      "Epoch 4582, Loss: 0.5386014729738235, Final Batch Loss: 0.15489190816879272\n",
      "Epoch 4583, Loss: 0.3191669434309006, Final Batch Loss: 0.11390598118305206\n",
      "Epoch 4584, Loss: 0.5135108679533005, Final Batch Loss: 0.19186675548553467\n",
      "Epoch 4585, Loss: 0.43557046353816986, Final Batch Loss: 0.12906093895435333\n",
      "Epoch 4586, Loss: 0.583266019821167, Final Batch Loss: 0.280411958694458\n",
      "Epoch 4587, Loss: 0.4139450192451477, Final Batch Loss: 0.10826271772384644\n",
      "Epoch 4588, Loss: 0.4484420716762543, Final Batch Loss: 0.11021801829338074\n",
      "Epoch 4589, Loss: 0.5052087903022766, Final Batch Loss: 0.13702666759490967\n",
      "Epoch 4590, Loss: 0.41254715621471405, Final Batch Loss: 0.13742341101169586\n",
      "Epoch 4591, Loss: 0.40275687724351883, Final Batch Loss: 0.1088181585073471\n",
      "Epoch 4592, Loss: 0.3323938101530075, Final Batch Loss: 0.08403974026441574\n",
      "Epoch 4593, Loss: 0.4124298691749573, Final Batch Loss: 0.11371681094169617\n",
      "Epoch 4594, Loss: 0.4491506665945053, Final Batch Loss: 0.15326592326164246\n",
      "Epoch 4595, Loss: 0.44479741156101227, Final Batch Loss: 0.13511885702610016\n",
      "Epoch 4596, Loss: 0.4285939782857895, Final Batch Loss: 0.16680343449115753\n",
      "Epoch 4597, Loss: 0.44370540976524353, Final Batch Loss: 0.1185416504740715\n",
      "Epoch 4598, Loss: 0.3962497338652611, Final Batch Loss: 0.10383965820074081\n",
      "Epoch 4599, Loss: 0.3677050694823265, Final Batch Loss: 0.10344905406236649\n",
      "Epoch 4600, Loss: 0.4798654764890671, Final Batch Loss: 0.17682035267353058\n",
      "Epoch 4601, Loss: 0.4904307425022125, Final Batch Loss: 0.14482417702674866\n",
      "Epoch 4602, Loss: 0.36942699551582336, Final Batch Loss: 0.10596918314695358\n",
      "Epoch 4603, Loss: 0.45556531846523285, Final Batch Loss: 0.1355934888124466\n",
      "Epoch 4604, Loss: 0.37109649926424026, Final Batch Loss: 0.1244274154305458\n",
      "Epoch 4605, Loss: 0.4331343472003937, Final Batch Loss: 0.15769970417022705\n",
      "Epoch 4606, Loss: 0.5183130949735641, Final Batch Loss: 0.1612500697374344\n",
      "Epoch 4607, Loss: 0.43928195536136627, Final Batch Loss: 0.13695313036441803\n",
      "Epoch 4608, Loss: 0.38175714761018753, Final Batch Loss: 0.11946775019168854\n",
      "Epoch 4609, Loss: 0.6019304245710373, Final Batch Loss: 0.3092964291572571\n",
      "Epoch 4610, Loss: 0.38823091983795166, Final Batch Loss: 0.1597038060426712\n",
      "Epoch 4611, Loss: 0.4341717064380646, Final Batch Loss: 0.0906868726015091\n",
      "Epoch 4612, Loss: 0.503708153963089, Final Batch Loss: 0.1379590928554535\n",
      "Epoch 4613, Loss: 0.5453696399927139, Final Batch Loss: 0.2420438528060913\n",
      "Epoch 4614, Loss: 0.4290539622306824, Final Batch Loss: 0.1379825323820114\n",
      "Epoch 4615, Loss: 0.4315721318125725, Final Batch Loss: 0.18983037769794464\n",
      "Epoch 4616, Loss: 0.4979529604315758, Final Batch Loss: 0.19111092388629913\n",
      "Epoch 4617, Loss: 0.37187163531780243, Final Batch Loss: 0.12982596457004547\n",
      "Epoch 4618, Loss: 0.4854418486356735, Final Batch Loss: 0.1803993582725525\n",
      "Epoch 4619, Loss: 0.39775367826223373, Final Batch Loss: 0.10560084134340286\n",
      "Epoch 4620, Loss: 0.42526647448539734, Final Batch Loss: 0.19589567184448242\n",
      "Epoch 4621, Loss: 0.3549075126647949, Final Batch Loss: 0.07881512492895126\n",
      "Epoch 4622, Loss: 0.3790487200021744, Final Batch Loss: 0.10406527668237686\n",
      "Epoch 4623, Loss: 0.41769488900899887, Final Batch Loss: 0.077250637114048\n",
      "Epoch 4624, Loss: 0.505413830280304, Final Batch Loss: 0.1713782399892807\n",
      "Epoch 4625, Loss: 0.3756835237145424, Final Batch Loss: 0.10009711235761642\n",
      "Epoch 4626, Loss: 0.3532736971974373, Final Batch Loss: 0.1371891051530838\n",
      "Epoch 4627, Loss: 0.3936309516429901, Final Batch Loss: 0.14213551580905914\n",
      "Epoch 4628, Loss: 0.40699247270822525, Final Batch Loss: 0.19365838170051575\n",
      "Epoch 4629, Loss: 0.3722652643918991, Final Batch Loss: 0.09112031757831573\n",
      "Epoch 4630, Loss: 0.5271861255168915, Final Batch Loss: 0.1578700691461563\n",
      "Epoch 4631, Loss: 0.5006507486104965, Final Batch Loss: 0.21329708397388458\n",
      "Epoch 4632, Loss: 0.4673370197415352, Final Batch Loss: 0.13930743932724\n",
      "Epoch 4633, Loss: 0.38355889916419983, Final Batch Loss: 0.12211652100086212\n",
      "Epoch 4634, Loss: 0.3716367483139038, Final Batch Loss: 0.09833690524101257\n",
      "Epoch 4635, Loss: 0.4846221059560776, Final Batch Loss: 0.1322893500328064\n",
      "Epoch 4636, Loss: 0.4436991810798645, Final Batch Loss: 0.13923411071300507\n",
      "Epoch 4637, Loss: 0.4049120992422104, Final Batch Loss: 0.165870800614357\n",
      "Epoch 4638, Loss: 0.4334639459848404, Final Batch Loss: 0.154791921377182\n",
      "Epoch 4639, Loss: 0.43468205630779266, Final Batch Loss: 0.11983035504817963\n",
      "Epoch 4640, Loss: 0.43391504138708115, Final Batch Loss: 0.15976397693157196\n",
      "Epoch 4641, Loss: 0.40077122300863266, Final Batch Loss: 0.1622357815504074\n",
      "Epoch 4642, Loss: 0.39422158151865005, Final Batch Loss: 0.15333110094070435\n",
      "Epoch 4643, Loss: 0.3383720591664314, Final Batch Loss: 0.09284067153930664\n",
      "Epoch 4644, Loss: 0.39958474785089493, Final Batch Loss: 0.16697752475738525\n",
      "Epoch 4645, Loss: 0.3812377452850342, Final Batch Loss: 0.11132949590682983\n",
      "Epoch 4646, Loss: 0.4574653282761574, Final Batch Loss: 0.21369904279708862\n",
      "Epoch 4647, Loss: 0.4535330608487129, Final Batch Loss: 0.1024162545800209\n",
      "Epoch 4648, Loss: 0.4634617865085602, Final Batch Loss: 0.1691475361585617\n",
      "Epoch 4649, Loss: 0.4439459815621376, Final Batch Loss: 0.08631157130002975\n",
      "Epoch 4650, Loss: 0.41966140270233154, Final Batch Loss: 0.1250762641429901\n",
      "Epoch 4651, Loss: 0.4358374699950218, Final Batch Loss: 0.20039622485637665\n",
      "Epoch 4652, Loss: 0.39939379692077637, Final Batch Loss: 0.08477993309497833\n",
      "Epoch 4653, Loss: 0.4585360586643219, Final Batch Loss: 0.1667354851961136\n",
      "Epoch 4654, Loss: 0.4594225585460663, Final Batch Loss: 0.16055911779403687\n",
      "Epoch 4655, Loss: 0.39561305195093155, Final Batch Loss: 0.11028201133012772\n",
      "Epoch 4656, Loss: 0.4083029255270958, Final Batch Loss: 0.1133253201842308\n",
      "Epoch 4657, Loss: 0.4625738263130188, Final Batch Loss: 0.18526867032051086\n",
      "Epoch 4658, Loss: 0.51326684653759, Final Batch Loss: 0.20626495778560638\n",
      "Epoch 4659, Loss: 0.3661767393350601, Final Batch Loss: 0.14074267446994781\n",
      "Epoch 4660, Loss: 0.38185862451791763, Final Batch Loss: 0.1207730695605278\n",
      "Epoch 4661, Loss: 0.38629237562417984, Final Batch Loss: 0.11086147278547287\n",
      "Epoch 4662, Loss: 0.36320604383945465, Final Batch Loss: 0.11536324769258499\n",
      "Epoch 4663, Loss: 0.5421662479639053, Final Batch Loss: 0.1827867329120636\n",
      "Epoch 4664, Loss: 0.38944708555936813, Final Batch Loss: 0.1364050656557083\n",
      "Epoch 4665, Loss: 0.31610437482595444, Final Batch Loss: 0.06985383480787277\n",
      "Epoch 4666, Loss: 0.5544346570968628, Final Batch Loss: 0.21803003549575806\n",
      "Epoch 4667, Loss: 0.3427915573120117, Final Batch Loss: 0.06645878404378891\n",
      "Epoch 4668, Loss: 0.47516272962093353, Final Batch Loss: 0.17859157919883728\n",
      "Epoch 4669, Loss: 0.49413515627384186, Final Batch Loss: 0.13013309240341187\n",
      "Epoch 4670, Loss: 0.5991840958595276, Final Batch Loss: 0.2352549433708191\n",
      "Epoch 4671, Loss: 0.463115394115448, Final Batch Loss: 0.13215769827365875\n",
      "Epoch 4672, Loss: 0.5021848902106285, Final Batch Loss: 0.16032034158706665\n",
      "Epoch 4673, Loss: 0.5147020816802979, Final Batch Loss: 0.24633632600307465\n",
      "Epoch 4674, Loss: 0.40539298206567764, Final Batch Loss: 0.15720263123512268\n",
      "Epoch 4675, Loss: 0.43450257182121277, Final Batch Loss: 0.11874191462993622\n",
      "Epoch 4676, Loss: 0.422367587685585, Final Batch Loss: 0.09444548189640045\n",
      "Epoch 4677, Loss: 0.3547111749649048, Final Batch Loss: 0.06346176564693451\n",
      "Epoch 4678, Loss: 0.40742506831884384, Final Batch Loss: 0.08041620254516602\n",
      "Epoch 4679, Loss: 0.3459508493542671, Final Batch Loss: 0.10058846324682236\n",
      "Epoch 4680, Loss: 0.4828195571899414, Final Batch Loss: 0.18064899742603302\n",
      "Epoch 4681, Loss: 0.5123939216136932, Final Batch Loss: 0.1994265764951706\n",
      "Epoch 4682, Loss: 0.3949204683303833, Final Batch Loss: 0.14791841804981232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4683, Loss: 0.47561295330524445, Final Batch Loss: 0.14840169250965118\n",
      "Epoch 4684, Loss: 0.40202050656080246, Final Batch Loss: 0.12505114078521729\n",
      "Epoch 4685, Loss: 0.43791109323501587, Final Batch Loss: 0.13643796741962433\n",
      "Epoch 4686, Loss: 0.277619831264019, Final Batch Loss: 0.0647888258099556\n",
      "Epoch 4687, Loss: 0.44400258362293243, Final Batch Loss: 0.11164264380931854\n",
      "Epoch 4688, Loss: 0.29399237036705017, Final Batch Loss: 0.09381839632987976\n",
      "Epoch 4689, Loss: 0.41566290706396103, Final Batch Loss: 0.10531271994113922\n",
      "Epoch 4690, Loss: 0.39718589931726456, Final Batch Loss: 0.14470864832401276\n",
      "Epoch 4691, Loss: 0.5647976100444794, Final Batch Loss: 0.26007816195487976\n",
      "Epoch 4692, Loss: 0.37194035947322845, Final Batch Loss: 0.0814846083521843\n",
      "Epoch 4693, Loss: 0.4268931895494461, Final Batch Loss: 0.1786159873008728\n",
      "Epoch 4694, Loss: 0.39203376322984695, Final Batch Loss: 0.10732672363519669\n",
      "Epoch 4695, Loss: 0.4080299362540245, Final Batch Loss: 0.0935375988483429\n",
      "Epoch 4696, Loss: 0.4330758973956108, Final Batch Loss: 0.14828573167324066\n",
      "Epoch 4697, Loss: 0.5376939028501511, Final Batch Loss: 0.14844056963920593\n",
      "Epoch 4698, Loss: 0.3781755417585373, Final Batch Loss: 0.14382140338420868\n",
      "Epoch 4699, Loss: 0.38600609451532364, Final Batch Loss: 0.13197822868824005\n",
      "Epoch 4700, Loss: 0.4253604933619499, Final Batch Loss: 0.1336747407913208\n",
      "Epoch 4701, Loss: 0.4361957013607025, Final Batch Loss: 0.14436528086662292\n",
      "Epoch 4702, Loss: 0.44005442410707474, Final Batch Loss: 0.17282003164291382\n",
      "Epoch 4703, Loss: 0.48107802867889404, Final Batch Loss: 0.17404606938362122\n",
      "Epoch 4704, Loss: 0.32031548023223877, Final Batch Loss: 0.08122222870588303\n",
      "Epoch 4705, Loss: 0.4407195746898651, Final Batch Loss: 0.09918883442878723\n",
      "Epoch 4706, Loss: 0.3276863545179367, Final Batch Loss: 0.09455186873674393\n",
      "Epoch 4707, Loss: 0.3955879583954811, Final Batch Loss: 0.15741614997386932\n",
      "Epoch 4708, Loss: 0.49754518270492554, Final Batch Loss: 0.17529810965061188\n",
      "Epoch 4709, Loss: 0.4147634133696556, Final Batch Loss: 0.182240828871727\n",
      "Epoch 4710, Loss: 0.4714297503232956, Final Batch Loss: 0.1899884194135666\n",
      "Epoch 4711, Loss: 0.48129206895828247, Final Batch Loss: 0.1716316193342209\n",
      "Epoch 4712, Loss: 0.4577881991863251, Final Batch Loss: 0.1821921020746231\n",
      "Epoch 4713, Loss: 0.4652566909790039, Final Batch Loss: 0.12253788113594055\n",
      "Epoch 4714, Loss: 0.4700670838356018, Final Batch Loss: 0.17450955510139465\n",
      "Epoch 4715, Loss: 0.4894174784421921, Final Batch Loss: 0.12352965772151947\n",
      "Epoch 4716, Loss: 0.4684748202562332, Final Batch Loss: 0.17765125632286072\n",
      "Epoch 4717, Loss: 0.5113696828484535, Final Batch Loss: 0.21063660085201263\n",
      "Epoch 4718, Loss: 0.3987911343574524, Final Batch Loss: 0.14862319827079773\n",
      "Epoch 4719, Loss: 0.4602860361337662, Final Batch Loss: 0.17771312594413757\n",
      "Epoch 4720, Loss: 0.43823473900556564, Final Batch Loss: 0.09499060362577438\n",
      "Epoch 4721, Loss: 0.35407257080078125, Final Batch Loss: 0.1183004081249237\n",
      "Epoch 4722, Loss: 0.4395383223891258, Final Batch Loss: 0.11844810098409653\n",
      "Epoch 4723, Loss: 0.37405814230442047, Final Batch Loss: 0.10277483612298965\n",
      "Epoch 4724, Loss: 0.48620517551898956, Final Batch Loss: 0.2193770855665207\n",
      "Epoch 4725, Loss: 0.44458699971437454, Final Batch Loss: 0.0696243867278099\n",
      "Epoch 4726, Loss: 0.453045591711998, Final Batch Loss: 0.1696140021085739\n",
      "Epoch 4727, Loss: 0.4417400360107422, Final Batch Loss: 0.15327532589435577\n",
      "Epoch 4728, Loss: 0.44757653027772903, Final Batch Loss: 0.1876462996006012\n",
      "Epoch 4729, Loss: 0.46813593804836273, Final Batch Loss: 0.17115925252437592\n",
      "Epoch 4730, Loss: 0.4261246472597122, Final Batch Loss: 0.16431105136871338\n",
      "Epoch 4731, Loss: 0.5153258442878723, Final Batch Loss: 0.15399450063705444\n",
      "Epoch 4732, Loss: 0.4607488662004471, Final Batch Loss: 0.13380476832389832\n",
      "Epoch 4733, Loss: 0.5392155647277832, Final Batch Loss: 0.24606654047966003\n",
      "Epoch 4734, Loss: 0.46633827686309814, Final Batch Loss: 0.1432841420173645\n",
      "Epoch 4735, Loss: 0.4134803041815758, Final Batch Loss: 0.17062917351722717\n",
      "Epoch 4736, Loss: 0.4455277919769287, Final Batch Loss: 0.14822086691856384\n",
      "Epoch 4737, Loss: 0.3939504697918892, Final Batch Loss: 0.08725421875715256\n",
      "Epoch 4738, Loss: 0.43575000017881393, Final Batch Loss: 0.12017377465963364\n",
      "Epoch 4739, Loss: 0.3487372025847435, Final Batch Loss: 0.11963170021772385\n",
      "Epoch 4740, Loss: 0.3447044864296913, Final Batch Loss: 0.11610420793294907\n",
      "Epoch 4741, Loss: 0.41943006217479706, Final Batch Loss: 0.1725153625011444\n",
      "Epoch 4742, Loss: 0.42053915560245514, Final Batch Loss: 0.12917354702949524\n",
      "Epoch 4743, Loss: 0.4903903603553772, Final Batch Loss: 0.133625328540802\n",
      "Epoch 4744, Loss: 0.40075379610061646, Final Batch Loss: 0.15174289047718048\n",
      "Epoch 4745, Loss: 0.3546510860323906, Final Batch Loss: 0.1018967404961586\n",
      "Epoch 4746, Loss: 0.46686066687107086, Final Batch Loss: 0.17363788187503815\n",
      "Epoch 4747, Loss: 0.42771904170513153, Final Batch Loss: 0.15257687866687775\n",
      "Epoch 4748, Loss: 0.5397891998291016, Final Batch Loss: 0.23569071292877197\n",
      "Epoch 4749, Loss: 0.46424400806427, Final Batch Loss: 0.18859636783599854\n",
      "Epoch 4750, Loss: 0.5010251402854919, Final Batch Loss: 0.2942847013473511\n",
      "Epoch 4751, Loss: 0.4196489229798317, Final Batch Loss: 0.14279918372631073\n",
      "Epoch 4752, Loss: 0.5033830106258392, Final Batch Loss: 0.2168211042881012\n",
      "Epoch 4753, Loss: 0.3460375443100929, Final Batch Loss: 0.12763018906116486\n",
      "Epoch 4754, Loss: 0.37913404405117035, Final Batch Loss: 0.14349013566970825\n",
      "Epoch 4755, Loss: 0.4921071380376816, Final Batch Loss: 0.14926837384700775\n",
      "Epoch 4756, Loss: 0.419454000890255, Final Batch Loss: 0.1446472406387329\n",
      "Epoch 4757, Loss: 0.5339071750640869, Final Batch Loss: 0.12945403158664703\n",
      "Epoch 4758, Loss: 0.5275120213627815, Final Batch Loss: 0.31670594215393066\n",
      "Epoch 4759, Loss: 0.45964476466178894, Final Batch Loss: 0.13548743724822998\n",
      "Epoch 4760, Loss: 0.44102347642183304, Final Batch Loss: 0.09261450916528702\n",
      "Epoch 4761, Loss: 0.5623701065778732, Final Batch Loss: 0.21187733113765717\n",
      "Epoch 4762, Loss: 0.3994600921869278, Final Batch Loss: 0.12507259845733643\n",
      "Epoch 4763, Loss: 0.4729599952697754, Final Batch Loss: 0.16044722497463226\n",
      "Epoch 4764, Loss: 0.3706640601158142, Final Batch Loss: 0.11803983151912689\n",
      "Epoch 4765, Loss: 0.5295313000679016, Final Batch Loss: 0.2546651363372803\n",
      "Epoch 4766, Loss: 0.49945540726184845, Final Batch Loss: 0.1642661988735199\n",
      "Epoch 4767, Loss: 0.45184075087308884, Final Batch Loss: 0.07803622633218765\n",
      "Epoch 4768, Loss: 0.5875633805990219, Final Batch Loss: 0.2524310350418091\n",
      "Epoch 4769, Loss: 0.3476303964853287, Final Batch Loss: 0.08908423781394958\n",
      "Epoch 4770, Loss: 0.44157470017671585, Final Batch Loss: 0.1830245852470398\n",
      "Epoch 4771, Loss: 0.319910429418087, Final Batch Loss: 0.09909509122371674\n",
      "Epoch 4772, Loss: 0.5051464736461639, Final Batch Loss: 0.13909390568733215\n",
      "Epoch 4773, Loss: 0.40267468988895416, Final Batch Loss: 0.09634487330913544\n",
      "Epoch 4774, Loss: 0.46015138924121857, Final Batch Loss: 0.1676020622253418\n",
      "Epoch 4775, Loss: 0.504366010427475, Final Batch Loss: 0.13833113014698029\n",
      "Epoch 4776, Loss: 0.31343771517276764, Final Batch Loss: 0.11405454576015472\n",
      "Epoch 4777, Loss: 0.3761543706059456, Final Batch Loss: 0.10201180726289749\n",
      "Epoch 4778, Loss: 0.3173481598496437, Final Batch Loss: 0.06421361118555069\n",
      "Epoch 4779, Loss: 0.5027413666248322, Final Batch Loss: 0.18784087896347046\n",
      "Epoch 4780, Loss: 0.3990722969174385, Final Batch Loss: 0.1351339966058731\n",
      "Epoch 4781, Loss: 0.4663514047861099, Final Batch Loss: 0.14892497658729553\n",
      "Epoch 4782, Loss: 0.4356187954545021, Final Batch Loss: 0.1547894924879074\n",
      "Epoch 4783, Loss: 0.4527312368154526, Final Batch Loss: 0.17610298097133636\n",
      "Epoch 4784, Loss: 0.2805648557841778, Final Batch Loss: 0.035179708153009415\n",
      "Epoch 4785, Loss: 0.39612001925706863, Final Batch Loss: 0.0943533256649971\n",
      "Epoch 4786, Loss: 0.44303659349679947, Final Batch Loss: 0.10434585064649582\n",
      "Epoch 4787, Loss: 0.47717802971601486, Final Batch Loss: 0.218398317694664\n",
      "Epoch 4788, Loss: 0.3643437698483467, Final Batch Loss: 0.07037868350744247\n",
      "Epoch 4789, Loss: 0.3866763785481453, Final Batch Loss: 0.10762793570756912\n",
      "Epoch 4790, Loss: 0.39187178015708923, Final Batch Loss: 0.09942495077848434\n",
      "Epoch 4791, Loss: 0.3851037248969078, Final Batch Loss: 0.10581453889608383\n",
      "Epoch 4792, Loss: 0.4742148816585541, Final Batch Loss: 0.1585865318775177\n",
      "Epoch 4793, Loss: 0.4196368381381035, Final Batch Loss: 0.11317545920610428\n",
      "Epoch 4794, Loss: 0.5056147575378418, Final Batch Loss: 0.20095893740653992\n",
      "Epoch 4795, Loss: 0.4016328677535057, Final Batch Loss: 0.10600090026855469\n",
      "Epoch 4796, Loss: 0.3474634438753128, Final Batch Loss: 0.10254328697919846\n",
      "Epoch 4797, Loss: 0.41427841782569885, Final Batch Loss: 0.12750773131847382\n",
      "Epoch 4798, Loss: 0.5069253593683243, Final Batch Loss: 0.16146747767925262\n",
      "Epoch 4799, Loss: 0.6359443515539169, Final Batch Loss: 0.23571738600730896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4800, Loss: 0.4411597102880478, Final Batch Loss: 0.11819339543581009\n",
      "Epoch 4801, Loss: 0.4539145976305008, Final Batch Loss: 0.1296539157629013\n",
      "Epoch 4802, Loss: 0.3793943151831627, Final Batch Loss: 0.08654855936765671\n",
      "Epoch 4803, Loss: 0.38016945868730545, Final Batch Loss: 0.1753162145614624\n",
      "Epoch 4804, Loss: 0.3695887625217438, Final Batch Loss: 0.1047154888510704\n",
      "Epoch 4805, Loss: 0.35786689817905426, Final Batch Loss: 0.11371342092752457\n",
      "Epoch 4806, Loss: 0.2856547236442566, Final Batch Loss: 0.10280506312847137\n",
      "Epoch 4807, Loss: 0.4458269402384758, Final Batch Loss: 0.08767689019441605\n",
      "Epoch 4808, Loss: 0.4701702296733856, Final Batch Loss: 0.12770985066890717\n",
      "Epoch 4809, Loss: 0.5321658924221992, Final Batch Loss: 0.23621977865695953\n",
      "Epoch 4810, Loss: 0.47701306641101837, Final Batch Loss: 0.1547253578901291\n",
      "Epoch 4811, Loss: 0.42499491572380066, Final Batch Loss: 0.14059363305568695\n",
      "Epoch 4812, Loss: 0.3802464008331299, Final Batch Loss: 0.11840929090976715\n",
      "Epoch 4813, Loss: 0.35741347819566727, Final Batch Loss: 0.10340467095375061\n",
      "Epoch 4814, Loss: 0.4514993876218796, Final Batch Loss: 0.1431668996810913\n",
      "Epoch 4815, Loss: 0.5037618055939674, Final Batch Loss: 0.2433861643075943\n",
      "Epoch 4816, Loss: 0.6095132976770401, Final Batch Loss: 0.22356067597866058\n",
      "Epoch 4817, Loss: 0.36104635149240494, Final Batch Loss: 0.11306175589561462\n",
      "Epoch 4818, Loss: 0.4327230527997017, Final Batch Loss: 0.1175786480307579\n",
      "Epoch 4819, Loss: 0.3800588473677635, Final Batch Loss: 0.14535857737064362\n",
      "Epoch 4820, Loss: 0.3700341358780861, Final Batch Loss: 0.10967279225587845\n",
      "Epoch 4821, Loss: 0.4797402173280716, Final Batch Loss: 0.1278408318758011\n",
      "Epoch 4822, Loss: 0.3922802656888962, Final Batch Loss: 0.12899918854236603\n",
      "Epoch 4823, Loss: 0.44950079917907715, Final Batch Loss: 0.15322959423065186\n",
      "Epoch 4824, Loss: 0.5378570631146431, Final Batch Loss: 0.28575393557548523\n",
      "Epoch 4825, Loss: 0.3671603500843048, Final Batch Loss: 0.13116440176963806\n",
      "Epoch 4826, Loss: 0.5441059917211533, Final Batch Loss: 0.23017697036266327\n",
      "Epoch 4827, Loss: 0.4700131192803383, Final Batch Loss: 0.11992790549993515\n",
      "Epoch 4828, Loss: 0.6049994081258774, Final Batch Loss: 0.19838190078735352\n",
      "Epoch 4829, Loss: 0.4029701203107834, Final Batch Loss: 0.14810962975025177\n",
      "Epoch 4830, Loss: 0.4106995388865471, Final Batch Loss: 0.11993696540594101\n",
      "Epoch 4831, Loss: 0.4179927557706833, Final Batch Loss: 0.1751910001039505\n",
      "Epoch 4832, Loss: 0.3462443873286247, Final Batch Loss: 0.08538257330656052\n",
      "Epoch 4833, Loss: 0.5237190127372742, Final Batch Loss: 0.23271989822387695\n",
      "Epoch 4834, Loss: 0.3610738441348076, Final Batch Loss: 0.10228642076253891\n",
      "Epoch 4835, Loss: 0.407527320086956, Final Batch Loss: 0.1245739609003067\n",
      "Epoch 4836, Loss: 0.37578848004341125, Final Batch Loss: 0.14377664029598236\n",
      "Epoch 4837, Loss: 0.3369176760315895, Final Batch Loss: 0.10725992918014526\n",
      "Epoch 4838, Loss: 0.40062249451875687, Final Batch Loss: 0.14785930514335632\n",
      "Epoch 4839, Loss: 0.46256326138973236, Final Batch Loss: 0.20264053344726562\n",
      "Epoch 4840, Loss: 0.5583556890487671, Final Batch Loss: 0.3001366853713989\n",
      "Epoch 4841, Loss: 0.39992276579141617, Final Batch Loss: 0.15191377699375153\n",
      "Epoch 4842, Loss: 0.4900788962841034, Final Batch Loss: 0.19026502966880798\n",
      "Epoch 4843, Loss: 0.39223767817020416, Final Batch Loss: 0.08276945352554321\n",
      "Epoch 4844, Loss: 0.34123480319976807, Final Batch Loss: 0.12267983704805374\n",
      "Epoch 4845, Loss: 0.3992554023861885, Final Batch Loss: 0.1648104041814804\n",
      "Epoch 4846, Loss: 0.4487520158290863, Final Batch Loss: 0.12112373113632202\n",
      "Epoch 4847, Loss: 0.4142019599676132, Final Batch Loss: 0.1602208912372589\n",
      "Epoch 4848, Loss: 0.3157579265534878, Final Batch Loss: 0.03735717758536339\n",
      "Epoch 4849, Loss: 0.3990558236837387, Final Batch Loss: 0.10263866186141968\n",
      "Epoch 4850, Loss: 0.41098660975694656, Final Batch Loss: 0.10636433213949203\n",
      "Epoch 4851, Loss: 0.39594855159521103, Final Batch Loss: 0.12358064204454422\n",
      "Epoch 4852, Loss: 0.43329907208681107, Final Batch Loss: 0.11924796551465988\n",
      "Epoch 4853, Loss: 0.41827958077192307, Final Batch Loss: 0.1589547097682953\n",
      "Epoch 4854, Loss: 0.4524535536766052, Final Batch Loss: 0.1864236295223236\n",
      "Epoch 4855, Loss: 0.36479032784700394, Final Batch Loss: 0.10930567979812622\n",
      "Epoch 4856, Loss: 0.30880067497491837, Final Batch Loss: 0.06637193262577057\n",
      "Epoch 4857, Loss: 0.3155914917588234, Final Batch Loss: 0.12023323774337769\n",
      "Epoch 4858, Loss: 0.4878809452056885, Final Batch Loss: 0.20019493997097015\n",
      "Epoch 4859, Loss: 0.3981817290186882, Final Batch Loss: 0.14755411446094513\n",
      "Epoch 4860, Loss: 0.46940848231315613, Final Batch Loss: 0.10599130392074585\n",
      "Epoch 4861, Loss: 0.4710906594991684, Final Batch Loss: 0.17440548539161682\n",
      "Epoch 4862, Loss: 0.3993833214044571, Final Batch Loss: 0.13847222924232483\n",
      "Epoch 4863, Loss: 0.31521178781986237, Final Batch Loss: 0.1204519271850586\n",
      "Epoch 4864, Loss: 0.4601432532072067, Final Batch Loss: 0.15269918739795685\n",
      "Epoch 4865, Loss: 0.49380891025066376, Final Batch Loss: 0.1411176174879074\n",
      "Epoch 4866, Loss: 0.33317504078149796, Final Batch Loss: 0.08199408650398254\n",
      "Epoch 4867, Loss: 0.3191351965069771, Final Batch Loss: 0.10461155325174332\n",
      "Epoch 4868, Loss: 0.3771269917488098, Final Batch Loss: 0.09712222218513489\n",
      "Epoch 4869, Loss: 0.3963182717561722, Final Batch Loss: 0.09239836037158966\n",
      "Epoch 4870, Loss: 0.4338073953986168, Final Batch Loss: 0.12583236396312714\n",
      "Epoch 4871, Loss: 0.33779066801071167, Final Batch Loss: 0.10376494377851486\n",
      "Epoch 4872, Loss: 0.4955455884337425, Final Batch Loss: 0.2506669759750366\n",
      "Epoch 4873, Loss: 0.4184004217386246, Final Batch Loss: 0.1468421071767807\n",
      "Epoch 4874, Loss: 0.45045482367277145, Final Batch Loss: 0.2119513899087906\n",
      "Epoch 4875, Loss: 0.4614991173148155, Final Batch Loss: 0.12936332821846008\n",
      "Epoch 4876, Loss: 0.4470674395561218, Final Batch Loss: 0.16878394782543182\n",
      "Epoch 4877, Loss: 0.4632110446691513, Final Batch Loss: 0.16201616823673248\n",
      "Epoch 4878, Loss: 0.49929215013980865, Final Batch Loss: 0.18065519630908966\n",
      "Epoch 4879, Loss: 0.38298796117305756, Final Batch Loss: 0.08718152344226837\n",
      "Epoch 4880, Loss: 0.4075523093342781, Final Batch Loss: 0.11310724169015884\n",
      "Epoch 4881, Loss: 0.525131031870842, Final Batch Loss: 0.1763557493686676\n",
      "Epoch 4882, Loss: 0.4884611815214157, Final Batch Loss: 0.13813833892345428\n",
      "Epoch 4883, Loss: 0.39336497336626053, Final Batch Loss: 0.12942162156105042\n",
      "Epoch 4884, Loss: 0.519779846072197, Final Batch Loss: 0.20592103898525238\n",
      "Epoch 4885, Loss: 0.4144045561552048, Final Batch Loss: 0.189747616648674\n",
      "Epoch 4886, Loss: 0.45930808782577515, Final Batch Loss: 0.17292343080043793\n",
      "Epoch 4887, Loss: 0.38500063866376877, Final Batch Loss: 0.06319541484117508\n",
      "Epoch 4888, Loss: 0.3631630316376686, Final Batch Loss: 0.07208787649869919\n",
      "Epoch 4889, Loss: 0.43846458196640015, Final Batch Loss: 0.15245626866817474\n",
      "Epoch 4890, Loss: 0.38813466578722, Final Batch Loss: 0.10655851662158966\n",
      "Epoch 4891, Loss: 0.43544574826955795, Final Batch Loss: 0.1959746778011322\n",
      "Epoch 4892, Loss: 0.4076738953590393, Final Batch Loss: 0.19077691435813904\n",
      "Epoch 4893, Loss: 0.4107002094388008, Final Batch Loss: 0.08885275572538376\n",
      "Epoch 4894, Loss: 0.4053723067045212, Final Batch Loss: 0.11993800103664398\n",
      "Epoch 4895, Loss: 0.40563104301691055, Final Batch Loss: 0.08435554057359695\n",
      "Epoch 4896, Loss: 0.44774533063173294, Final Batch Loss: 0.10132420808076859\n",
      "Epoch 4897, Loss: 0.2947476729750633, Final Batch Loss: 0.068653404712677\n",
      "Epoch 4898, Loss: 0.4035651236772537, Final Batch Loss: 0.14643631875514984\n",
      "Epoch 4899, Loss: 0.3415306285023689, Final Batch Loss: 0.09711343050003052\n",
      "Epoch 4900, Loss: 0.4067450389266014, Final Batch Loss: 0.13921180367469788\n",
      "Epoch 4901, Loss: 0.3236570581793785, Final Batch Loss: 0.08884421736001968\n",
      "Epoch 4902, Loss: 0.29480351507663727, Final Batch Loss: 0.10301665216684341\n",
      "Epoch 4903, Loss: 0.31494204699993134, Final Batch Loss: 0.08841706067323685\n",
      "Epoch 4904, Loss: 0.3299407698214054, Final Batch Loss: 0.051896389573812485\n",
      "Epoch 4905, Loss: 0.44067078828811646, Final Batch Loss: 0.15727074444293976\n",
      "Epoch 4906, Loss: 0.4189918637275696, Final Batch Loss: 0.09757837653160095\n",
      "Epoch 4907, Loss: 0.5455907583236694, Final Batch Loss: 0.18925639986991882\n",
      "Epoch 4908, Loss: 0.3117530718445778, Final Batch Loss: 0.1388598382472992\n",
      "Epoch 4909, Loss: 0.4484467953443527, Final Batch Loss: 0.12020386755466461\n",
      "Epoch 4910, Loss: 0.33104991912841797, Final Batch Loss: 0.0946926698088646\n",
      "Epoch 4911, Loss: 0.4232108145952225, Final Batch Loss: 0.09070998430252075\n",
      "Epoch 4912, Loss: 0.39922773838043213, Final Batch Loss: 0.11972732841968536\n",
      "Epoch 4913, Loss: 0.5082919746637344, Final Batch Loss: 0.194811150431633\n",
      "Epoch 4914, Loss: 0.4996063858270645, Final Batch Loss: 0.22000503540039062\n",
      "Epoch 4915, Loss: 0.40805812180042267, Final Batch Loss: 0.14272651076316833\n",
      "Epoch 4916, Loss: 0.42527269572019577, Final Batch Loss: 0.1845197081565857\n",
      "Epoch 4917, Loss: 0.460695244371891, Final Batch Loss: 0.18072539567947388\n",
      "Epoch 4918, Loss: 0.5612976104021072, Final Batch Loss: 0.22819335758686066\n",
      "Epoch 4919, Loss: 0.43176814168691635, Final Batch Loss: 0.11198372393846512\n",
      "Epoch 4920, Loss: 0.4464755430817604, Final Batch Loss: 0.1776074469089508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4921, Loss: 0.35542063415050507, Final Batch Loss: 0.09030670672655106\n",
      "Epoch 4922, Loss: 0.5786376595497131, Final Batch Loss: 0.24663984775543213\n",
      "Epoch 4923, Loss: 0.3579541891813278, Final Batch Loss: 0.10465724021196365\n",
      "Epoch 4924, Loss: 0.39362896978855133, Final Batch Loss: 0.12810534238815308\n",
      "Epoch 4925, Loss: 0.33039139956235886, Final Batch Loss: 0.13981077075004578\n",
      "Epoch 4926, Loss: 0.36929284781217575, Final Batch Loss: 0.07504294067621231\n",
      "Epoch 4927, Loss: 0.455357626080513, Final Batch Loss: 0.19964297115802765\n",
      "Epoch 4928, Loss: 0.3313605412840843, Final Batch Loss: 0.10697030276060104\n",
      "Epoch 4929, Loss: 0.36921604722738266, Final Batch Loss: 0.09644389897584915\n",
      "Epoch 4930, Loss: 0.34413255378603935, Final Batch Loss: 0.06044693663716316\n",
      "Epoch 4931, Loss: 0.33847104758024216, Final Batch Loss: 0.09608764946460724\n",
      "Epoch 4932, Loss: 0.3701123744249344, Final Batch Loss: 0.1406937539577484\n",
      "Epoch 4933, Loss: 0.4500255584716797, Final Batch Loss: 0.13939042389392853\n",
      "Epoch 4934, Loss: 0.45530203729867935, Final Batch Loss: 0.14163698256015778\n",
      "Epoch 4935, Loss: 0.3820168152451515, Final Batch Loss: 0.11834201961755753\n",
      "Epoch 4936, Loss: 0.5129038169980049, Final Batch Loss: 0.2080029994249344\n",
      "Epoch 4937, Loss: 0.41334566473960876, Final Batch Loss: 0.1651861071586609\n",
      "Epoch 4938, Loss: 0.4223180115222931, Final Batch Loss: 0.13258594274520874\n",
      "Epoch 4939, Loss: 0.44592058658599854, Final Batch Loss: 0.11437840759754181\n",
      "Epoch 4940, Loss: 0.568858414888382, Final Batch Loss: 0.2210901528596878\n",
      "Epoch 4941, Loss: 0.3637983575463295, Final Batch Loss: 0.14559729397296906\n",
      "Epoch 4942, Loss: 0.5236594676971436, Final Batch Loss: 0.17316490411758423\n",
      "Epoch 4943, Loss: 0.46013785153627396, Final Batch Loss: 0.12128522247076035\n",
      "Epoch 4944, Loss: 0.39159490168094635, Final Batch Loss: 0.10888330638408661\n",
      "Epoch 4945, Loss: 0.4135253354907036, Final Batch Loss: 0.11103295534849167\n",
      "Epoch 4946, Loss: 0.5017703026533127, Final Batch Loss: 0.13613572716712952\n",
      "Epoch 4947, Loss: 0.33140896260738373, Final Batch Loss: 0.06761356443166733\n",
      "Epoch 4948, Loss: 0.3902910128235817, Final Batch Loss: 0.09085756540298462\n",
      "Epoch 4949, Loss: 0.3682710975408554, Final Batch Loss: 0.127800852060318\n",
      "Epoch 4950, Loss: 0.5395305007696152, Final Batch Loss: 0.22036175429821014\n",
      "Epoch 4951, Loss: 0.4397624582052231, Final Batch Loss: 0.15040671825408936\n",
      "Epoch 4952, Loss: 0.37581195682287216, Final Batch Loss: 0.06694572418928146\n",
      "Epoch 4953, Loss: 0.47272925078868866, Final Batch Loss: 0.12930551171302795\n",
      "Epoch 4954, Loss: 0.45569731295108795, Final Batch Loss: 0.1936156451702118\n",
      "Epoch 4955, Loss: 0.38247203081846237, Final Batch Loss: 0.13331317901611328\n",
      "Epoch 4956, Loss: 0.39956868439912796, Final Batch Loss: 0.15909019112586975\n",
      "Epoch 4957, Loss: 0.4216664433479309, Final Batch Loss: 0.13692331314086914\n",
      "Epoch 4958, Loss: 0.41351955384016037, Final Batch Loss: 0.13327841460704803\n",
      "Epoch 4959, Loss: 0.4113285094499588, Final Batch Loss: 0.09923537075519562\n",
      "Epoch 4960, Loss: 0.43966638296842575, Final Batch Loss: 0.1004742756485939\n",
      "Epoch 4961, Loss: 0.45092642307281494, Final Batch Loss: 0.15009115636348724\n",
      "Epoch 4962, Loss: 0.44436370581388474, Final Batch Loss: 0.24624818563461304\n",
      "Epoch 4963, Loss: 0.3731196001172066, Final Batch Loss: 0.10590158402919769\n",
      "Epoch 4964, Loss: 0.4035180136561394, Final Batch Loss: 0.08874285966157913\n",
      "Epoch 4965, Loss: 0.42954517900943756, Final Batch Loss: 0.11031466722488403\n",
      "Epoch 4966, Loss: 0.4038158655166626, Final Batch Loss: 0.13210587203502655\n",
      "Epoch 4967, Loss: 0.40084998309612274, Final Batch Loss: 0.13222946226596832\n",
      "Epoch 4968, Loss: 0.44584667682647705, Final Batch Loss: 0.13445422053337097\n",
      "Epoch 4969, Loss: 0.557215116918087, Final Batch Loss: 0.29003047943115234\n",
      "Epoch 4970, Loss: 0.49361635744571686, Final Batch Loss: 0.1481419950723648\n",
      "Epoch 4971, Loss: 0.46441756188869476, Final Batch Loss: 0.1032530814409256\n",
      "Epoch 4972, Loss: 0.3514155298471451, Final Batch Loss: 0.09490681439638138\n",
      "Epoch 4973, Loss: 0.36264410614967346, Final Batch Loss: 0.12807628512382507\n",
      "Epoch 4974, Loss: 0.3938518613576889, Final Batch Loss: 0.14225462079048157\n",
      "Epoch 4975, Loss: 0.4562104195356369, Final Batch Loss: 0.19668062031269073\n",
      "Epoch 4976, Loss: 0.4680393561720848, Final Batch Loss: 0.19860942661762238\n",
      "Epoch 4977, Loss: 0.41707349568605423, Final Batch Loss: 0.1149260625243187\n",
      "Epoch 4978, Loss: 0.37280968576669693, Final Batch Loss: 0.09130685776472092\n",
      "Epoch 4979, Loss: 0.42361390590667725, Final Batch Loss: 0.07794779539108276\n",
      "Epoch 4980, Loss: 0.3780706897377968, Final Batch Loss: 0.07630402594804764\n",
      "Epoch 4981, Loss: 0.3178425133228302, Final Batch Loss: 0.07561908662319183\n",
      "Epoch 4982, Loss: 0.4308503568172455, Final Batch Loss: 0.12505367398262024\n",
      "Epoch 4983, Loss: 0.46440958976745605, Final Batch Loss: 0.24468715488910675\n",
      "Epoch 4984, Loss: 0.4401404410600662, Final Batch Loss: 0.15264929831027985\n",
      "Epoch 4985, Loss: 0.47866591811180115, Final Batch Loss: 0.16601479053497314\n",
      "Epoch 4986, Loss: 0.3690636605024338, Final Batch Loss: 0.13236917555332184\n",
      "Epoch 4987, Loss: 0.4284988343715668, Final Batch Loss: 0.13840040564537048\n",
      "Epoch 4988, Loss: 0.36934974044561386, Final Batch Loss: 0.11040005832910538\n",
      "Epoch 4989, Loss: 0.4749314934015274, Final Batch Loss: 0.13790951669216156\n",
      "Epoch 4990, Loss: 0.32542168349027634, Final Batch Loss: 0.08297824114561081\n",
      "Epoch 4991, Loss: 0.3291570693254471, Final Batch Loss: 0.06969024240970612\n",
      "Epoch 4992, Loss: 0.33958330750465393, Final Batch Loss: 0.14829353988170624\n",
      "Epoch 4993, Loss: 0.395504429936409, Final Batch Loss: 0.12633374333381653\n",
      "Epoch 4994, Loss: 0.3950464203953743, Final Batch Loss: 0.1612674593925476\n",
      "Epoch 4995, Loss: 0.34440355747938156, Final Batch Loss: 0.11622273176908493\n",
      "Epoch 4996, Loss: 0.3242071643471718, Final Batch Loss: 0.12829028069972992\n",
      "Epoch 4997, Loss: 0.4510146379470825, Final Batch Loss: 0.13772518932819366\n",
      "Epoch 4998, Loss: 0.34197673201560974, Final Batch Loss: 0.12820352613925934\n",
      "Epoch 4999, Loss: 0.32108552753925323, Final Batch Loss: 0.11618909239768982\n",
      "Epoch 5000, Loss: 0.31562717258930206, Final Batch Loss: 0.05623891204595566\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        features, labels = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = model_subject(features.float())\n",
    "        \n",
    "        loss = criterion(preds, labels.long()) \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, Loss: {total_loss}, Final Batch Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  0  0  0  0]\n",
      " [ 0 27  1  1  2]\n",
      " [ 0  1 33  0  0]\n",
      " [ 0  0  0 31  0]\n",
      " [ 2  0  2  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93548   1.00000   0.96667        29\n",
      "           1    0.96429   0.87097   0.91525        31\n",
      "           2    0.91667   0.97059   0.94286        34\n",
      "           3    0.96875   1.00000   0.98413        31\n",
      "           4    0.93333   0.87500   0.90323        32\n",
      "\n",
      "    accuracy                        0.94268       157\n",
      "   macro avg    0.94370   0.94331   0.94243       157\n",
      "weighted avg    0.94323   0.94268   0.94188       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "model_subject.eval()\n",
    "for batch in test_loader:\n",
    "    features, labels = batch\n",
    "    _, preds = torch.max(softmax(model_subject(features.float())), dim = 1)\n",
    "    print(metrics.confusion_matrix((labels).cpu(), preds.cpu()))\n",
    "    print(metrics.classification_report((labels).cpu(), preds.cpu(), digits = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_labels = [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples + [0] * n_samples + [1] * n_samples + [2] * n_samples + [3] * n_samples + [4] * n_samples\n",
    "fake_labels = np.asarray(fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  1  2  1  4]\n",
      " [ 1 23  0  2  4]\n",
      " [ 0  1 24  1  4]\n",
      " [ 0  4  5 20  1]\n",
      " [ 3  6  5  0 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84615   0.73333   0.78571        30\n",
      "           1    0.65714   0.76667   0.70769        30\n",
      "           2    0.66667   0.80000   0.72727        30\n",
      "           3    0.83333   0.66667   0.74074        30\n",
      "           4    0.55172   0.53333   0.54237        30\n",
      "\n",
      "    accuracy                        0.70000       150\n",
      "   macro avg    0.71100   0.70000   0.70076       150\n",
      "weighted avg    0.71100   0.70000   0.70076       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, preds = torch.max(softmax(model_subject(fake_features.float())), dim = 1)\n",
    "print(metrics.confusion_matrix(fake_labels, preds.cpu()))\n",
    "print(metrics.classification_report(fake_labels, preds.cpu(), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
